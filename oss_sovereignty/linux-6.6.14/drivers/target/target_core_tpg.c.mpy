{
  "module_name": "target_core_tpg.c",
  "hash_id": "4bd44f9fa9176eacc52e02be8f27628f2587d483f4e35e1af5711fa000aa008b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/target/target_core_tpg.c",
  "human_readable_source": "\n \n\n#include <linux/net.h>\n#include <linux/string.h>\n#include <linux/timer.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/in.h>\n#include <linux/export.h>\n#include <net/sock.h>\n#include <net/tcp.h>\n#include <scsi/scsi_proto.h>\n\n#include <target/target_core_base.h>\n#include <target/target_core_backend.h>\n#include <target/target_core_fabric.h>\n\n#include \"target_core_internal.h\"\n#include \"target_core_alua.h\"\n#include \"target_core_pr.h\"\n#include \"target_core_ua.h\"\n\nextern struct se_device *g_lun0_dev;\nstatic DEFINE_XARRAY_ALLOC(tpg_xa);\n\n \nstruct se_node_acl *__core_tpg_get_initiator_node_acl(\n\tstruct se_portal_group *tpg,\n\tconst char *initiatorname)\n{\n\tstruct se_node_acl *acl;\n\n\tlist_for_each_entry(acl, &tpg->acl_node_list, acl_list) {\n\t\tif (!strcmp(acl->initiatorname, initiatorname))\n\t\t\treturn acl;\n\t}\n\n\treturn NULL;\n}\n\n \nstruct se_node_acl *core_tpg_get_initiator_node_acl(\n\tstruct se_portal_group *tpg,\n\tunsigned char *initiatorname)\n{\n\tstruct se_node_acl *acl;\n\t \n\tmutex_lock(&tpg->acl_node_mutex);\n\tacl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);\n\tif (acl) {\n\t\tif (!kref_get_unless_zero(&acl->acl_kref))\n\t\t\tacl = NULL;\n\t}\n\tmutex_unlock(&tpg->acl_node_mutex);\n\n\treturn acl;\n}\nEXPORT_SYMBOL(core_tpg_get_initiator_node_acl);\n\nvoid core_allocate_nexus_loss_ua(\n\tstruct se_node_acl *nacl)\n{\n\tstruct se_dev_entry *deve;\n\n\tif (!nacl)\n\t\treturn;\n\n\trcu_read_lock();\n\thlist_for_each_entry_rcu(deve, &nacl->lun_entry_hlist, link)\n\t\tcore_scsi3_ua_allocate(deve, 0x29,\n\t\t\tASCQ_29H_NEXUS_LOSS_OCCURRED);\n\trcu_read_unlock();\n}\nEXPORT_SYMBOL(core_allocate_nexus_loss_ua);\n\n \nvoid core_tpg_add_node_to_devs(\n\tstruct se_node_acl *acl,\n\tstruct se_portal_group *tpg,\n\tstruct se_lun *lun_orig)\n{\n\tbool lun_access_ro = true;\n\tstruct se_lun *lun;\n\tstruct se_device *dev;\n\n\tmutex_lock(&tpg->tpg_lun_mutex);\n\thlist_for_each_entry_rcu(lun, &tpg->tpg_lun_hlist, link) {\n\t\tif (lun_orig && lun != lun_orig)\n\t\t\tcontinue;\n\n\t\tdev = rcu_dereference_check(lun->lun_se_dev,\n\t\t\t\t\t    lockdep_is_held(&tpg->tpg_lun_mutex));\n\t\t \n\t\tif (!tpg->se_tpg_tfo->tpg_check_demo_mode_write_protect(tpg)) {\n\t\t\tlun_access_ro = false;\n\t\t} else {\n\t\t\t \n\t\t\tif (dev->transport->get_device_type(dev) == TYPE_DISK)\n\t\t\t\tlun_access_ro = true;\n\t\t\telse\n\t\t\t\tlun_access_ro = false;\n\t\t}\n\n\t\tpr_debug(\"TARGET_CORE[%s]->TPG[%u]_LUN[%llu] - Adding %s\"\n\t\t\t\" access for LUN in Demo Mode\\n\",\n\t\t\ttpg->se_tpg_tfo->fabric_name,\n\t\t\ttpg->se_tpg_tfo->tpg_get_tag(tpg), lun->unpacked_lun,\n\t\t\tlun_access_ro ? \"READ-ONLY\" : \"READ-WRITE\");\n\n\t\tcore_enable_device_list_for_node(lun, NULL, lun->unpacked_lun,\n\t\t\t\t\t\t lun_access_ro, acl, tpg);\n\t\t \n\t\tcore_scsi3_check_aptpl_registration(dev, tpg, lun, acl,\n\t\t\t\t\t\t    lun->unpacked_lun);\n\t}\n\tmutex_unlock(&tpg->tpg_lun_mutex);\n}\n\nstatic void\ntarget_set_nacl_queue_depth(struct se_portal_group *tpg,\n\t\t\t    struct se_node_acl *acl, u32 queue_depth)\n{\n\tacl->queue_depth = queue_depth;\n\n\tif (!acl->queue_depth) {\n\t\tpr_warn(\"Queue depth for %s Initiator Node: %s is 0,\"\n\t\t\t\"defaulting to 1.\\n\", tpg->se_tpg_tfo->fabric_name,\n\t\t\tacl->initiatorname);\n\t\tacl->queue_depth = 1;\n\t}\n}\n\nstatic struct se_node_acl *target_alloc_node_acl(struct se_portal_group *tpg,\n\t\tconst unsigned char *initiatorname)\n{\n\tstruct se_node_acl *acl;\n\tu32 queue_depth;\n\n\tacl = kzalloc(max(sizeof(*acl), tpg->se_tpg_tfo->node_acl_size),\n\t\t\tGFP_KERNEL);\n\tif (!acl)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&acl->acl_list);\n\tINIT_LIST_HEAD(&acl->acl_sess_list);\n\tINIT_HLIST_HEAD(&acl->lun_entry_hlist);\n\tkref_init(&acl->acl_kref);\n\tinit_completion(&acl->acl_free_comp);\n\tspin_lock_init(&acl->nacl_sess_lock);\n\tmutex_init(&acl->lun_entry_mutex);\n\tatomic_set(&acl->acl_pr_ref_count, 0);\n\n\tif (tpg->se_tpg_tfo->tpg_get_default_depth)\n\t\tqueue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);\n\telse\n\t\tqueue_depth = 1;\n\ttarget_set_nacl_queue_depth(tpg, acl, queue_depth);\n\n\tsnprintf(acl->initiatorname, TRANSPORT_IQN_LEN, \"%s\", initiatorname);\n\tacl->se_tpg = tpg;\n\tacl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);\n\n\ttpg->se_tpg_tfo->set_default_node_attributes(acl);\n\n\treturn acl;\n}\n\nstatic void target_add_node_acl(struct se_node_acl *acl)\n{\n\tstruct se_portal_group *tpg = acl->se_tpg;\n\n\tmutex_lock(&tpg->acl_node_mutex);\n\tlist_add_tail(&acl->acl_list, &tpg->acl_node_list);\n\tmutex_unlock(&tpg->acl_node_mutex);\n\n\tpr_debug(\"%s_TPG[%hu] - Added %s ACL with TCQ Depth: %d for %s\"\n\t\t\" Initiator Node: %s\\n\",\n\t\ttpg->se_tpg_tfo->fabric_name,\n\t\ttpg->se_tpg_tfo->tpg_get_tag(tpg),\n\t\tacl->dynamic_node_acl ? \"DYNAMIC\" : \"\",\n\t\tacl->queue_depth,\n\t\ttpg->se_tpg_tfo->fabric_name,\n\t\tacl->initiatorname);\n}\n\nbool target_tpg_has_node_acl(struct se_portal_group *tpg,\n\t\t\t     const char *initiatorname)\n{\n\tstruct se_node_acl *acl;\n\tbool found = false;\n\n\tmutex_lock(&tpg->acl_node_mutex);\n\tlist_for_each_entry(acl, &tpg->acl_node_list, acl_list) {\n\t\tif (!strcmp(acl->initiatorname, initiatorname)) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&tpg->acl_node_mutex);\n\n\treturn found;\n}\nEXPORT_SYMBOL(target_tpg_has_node_acl);\n\nstruct se_node_acl *core_tpg_check_initiator_node_acl(\n\tstruct se_portal_group *tpg,\n\tunsigned char *initiatorname)\n{\n\tstruct se_node_acl *acl;\n\n\tacl = core_tpg_get_initiator_node_acl(tpg, initiatorname);\n\tif (acl)\n\t\treturn acl;\n\n\tif (!tpg->se_tpg_tfo->tpg_check_demo_mode(tpg))\n\t\treturn NULL;\n\n\tacl = target_alloc_node_acl(tpg, initiatorname);\n\tif (!acl)\n\t\treturn NULL;\n\t \n\tkref_get(&acl->acl_kref);\n\tacl->dynamic_node_acl = 1;\n\n\t \n\tif ((tpg->se_tpg_tfo->tpg_check_demo_mode_login_only == NULL) ||\n\t    (tpg->se_tpg_tfo->tpg_check_demo_mode_login_only(tpg) != 1))\n\t\tcore_tpg_add_node_to_devs(acl, tpg, NULL);\n\n\ttarget_add_node_acl(acl);\n\treturn acl;\n}\nEXPORT_SYMBOL(core_tpg_check_initiator_node_acl);\n\nvoid core_tpg_wait_for_nacl_pr_ref(struct se_node_acl *nacl)\n{\n\twhile (atomic_read(&nacl->acl_pr_ref_count) != 0)\n\t\tcpu_relax();\n}\n\nstruct se_node_acl *core_tpg_add_initiator_node_acl(\n\tstruct se_portal_group *tpg,\n\tconst char *initiatorname)\n{\n\tstruct se_node_acl *acl;\n\n\tmutex_lock(&tpg->acl_node_mutex);\n\tacl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);\n\tif (acl) {\n\t\tif (acl->dynamic_node_acl) {\n\t\t\tacl->dynamic_node_acl = 0;\n\t\t\tpr_debug(\"%s_TPG[%u] - Replacing dynamic ACL\"\n\t\t\t\t\" for %s\\n\", tpg->se_tpg_tfo->fabric_name,\n\t\t\t\ttpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);\n\t\t\tmutex_unlock(&tpg->acl_node_mutex);\n\t\t\treturn acl;\n\t\t}\n\n\t\tpr_err(\"ACL entry for %s Initiator\"\n\t\t\t\" Node %s already exists for TPG %u, ignoring\"\n\t\t\t\" request.\\n\",  tpg->se_tpg_tfo->fabric_name,\n\t\t\tinitiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));\n\t\tmutex_unlock(&tpg->acl_node_mutex);\n\t\treturn ERR_PTR(-EEXIST);\n\t}\n\tmutex_unlock(&tpg->acl_node_mutex);\n\n\tacl = target_alloc_node_acl(tpg, initiatorname);\n\tif (!acl)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\ttarget_add_node_acl(acl);\n\treturn acl;\n}\n\nstatic void target_shutdown_sessions(struct se_node_acl *acl)\n{\n\tstruct se_session *sess;\n\tunsigned long flags;\n\nrestart:\n\tspin_lock_irqsave(&acl->nacl_sess_lock, flags);\n\tlist_for_each_entry(sess, &acl->acl_sess_list, sess_acl_list) {\n\t\tif (sess->cmd_cnt && atomic_read(&sess->cmd_cnt->stopped))\n\t\t\tcontinue;\n\n\t\tlist_del_init(&sess->sess_acl_list);\n\t\tspin_unlock_irqrestore(&acl->nacl_sess_lock, flags);\n\n\t\tif (acl->se_tpg->se_tpg_tfo->close_session)\n\t\t\tacl->se_tpg->se_tpg_tfo->close_session(sess);\n\t\tgoto restart;\n\t}\n\tspin_unlock_irqrestore(&acl->nacl_sess_lock, flags);\n}\n\nvoid core_tpg_del_initiator_node_acl(struct se_node_acl *acl)\n{\n\tstruct se_portal_group *tpg = acl->se_tpg;\n\n\tmutex_lock(&tpg->acl_node_mutex);\n\tif (acl->dynamic_node_acl)\n\t\tacl->dynamic_node_acl = 0;\n\tlist_del_init(&acl->acl_list);\n\tmutex_unlock(&tpg->acl_node_mutex);\n\n\ttarget_shutdown_sessions(acl);\n\n\ttarget_put_nacl(acl);\n\t \n\twait_for_completion(&acl->acl_free_comp);\n\n\tcore_tpg_wait_for_nacl_pr_ref(acl);\n\tcore_free_device_list_for_node(acl, tpg);\n\n\tpr_debug(\"%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s\"\n\t\t\" Initiator Node: %s\\n\", tpg->se_tpg_tfo->fabric_name,\n\t\ttpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,\n\t\ttpg->se_tpg_tfo->fabric_name, acl->initiatorname);\n\n\tkfree(acl);\n}\n\n \nint core_tpg_set_initiator_node_queue_depth(\n\tstruct se_node_acl *acl,\n\tu32 queue_depth)\n{\n\tstruct se_portal_group *tpg = acl->se_tpg;\n\n\t \n\tif (acl->queue_depth == queue_depth)\n\t\treturn 0;\n\t \n\ttarget_set_nacl_queue_depth(tpg, acl, queue_depth);\n\n\t \n\ttarget_shutdown_sessions(acl);\n\n\tpr_debug(\"Successfully changed queue depth to: %d for Initiator\"\n\t\t\" Node: %s on %s Target Portal Group: %u\\n\", acl->queue_depth,\n\t\tacl->initiatorname, tpg->se_tpg_tfo->fabric_name,\n\t\ttpg->se_tpg_tfo->tpg_get_tag(tpg));\n\n\treturn 0;\n}\nEXPORT_SYMBOL(core_tpg_set_initiator_node_queue_depth);\n\n \nint core_tpg_set_initiator_node_tag(\n\tstruct se_portal_group *tpg,\n\tstruct se_node_acl *acl,\n\tconst char *new_tag)\n{\n\tif (strlen(new_tag) >= MAX_ACL_TAG_SIZE)\n\t\treturn -EINVAL;\n\n\tif (!strncmp(\"NULL\", new_tag, 4)) {\n\t\tacl->acl_tag[0] = '\\0';\n\t\treturn 0;\n\t}\n\n\treturn snprintf(acl->acl_tag, MAX_ACL_TAG_SIZE, \"%s\", new_tag);\n}\nEXPORT_SYMBOL(core_tpg_set_initiator_node_tag);\n\nstatic void core_tpg_lun_ref_release(struct percpu_ref *ref)\n{\n\tstruct se_lun *lun = container_of(ref, struct se_lun, lun_ref);\n\n\tcomplete(&lun->lun_shutdown_comp);\n}\n\nstatic int target_tpg_register_rtpi(struct se_portal_group *se_tpg)\n{\n\tu32 val;\n\tint ret;\n\n\tif (se_tpg->rtpi_manual) {\n\t\tret = xa_insert(&tpg_xa, se_tpg->tpg_rtpi, se_tpg, GFP_KERNEL);\n\t\tif (ret) {\n\t\t\tpr_info(\"%s_TPG[%hu] - Can not set RTPI %#x, it is already busy\",\n\t\t\t\tse_tpg->se_tpg_tfo->fabric_name,\n\t\t\t\tse_tpg->se_tpg_tfo->tpg_get_tag(se_tpg),\n\t\t\t\tse_tpg->tpg_rtpi);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tret = xa_alloc(&tpg_xa, &val, se_tpg,\n\t\t\t       XA_LIMIT(1, USHRT_MAX), GFP_KERNEL);\n\t\tif (!ret)\n\t\t\tse_tpg->tpg_rtpi = val;\n\t}\n\n\treturn ret;\n}\n\nstatic void target_tpg_deregister_rtpi(struct se_portal_group *se_tpg)\n{\n\tif (se_tpg->tpg_rtpi && se_tpg->enabled)\n\t\txa_erase(&tpg_xa, se_tpg->tpg_rtpi);\n}\n\nint target_tpg_enable(struct se_portal_group *se_tpg)\n{\n\tint ret;\n\n\tret = target_tpg_register_rtpi(se_tpg);\n\tif (ret)\n\t\treturn ret;\n\n\tret = se_tpg->se_tpg_tfo->fabric_enable_tpg(se_tpg, true);\n\tif (ret) {\n\t\ttarget_tpg_deregister_rtpi(se_tpg);\n\t\treturn ret;\n\t}\n\n\tse_tpg->enabled = true;\n\n\treturn 0;\n}\n\nint target_tpg_disable(struct se_portal_group *se_tpg)\n{\n\tint ret;\n\n\ttarget_tpg_deregister_rtpi(se_tpg);\n\n\tret = se_tpg->se_tpg_tfo->fabric_enable_tpg(se_tpg, false);\n\tif (!ret)\n\t\tse_tpg->enabled = false;\n\n\treturn ret;\n}\n\n \nint core_tpg_register(\n\tstruct se_wwn *se_wwn,\n\tstruct se_portal_group *se_tpg,\n\tint proto_id)\n{\n\tint ret;\n\n\tif (!se_tpg)\n\t\treturn -EINVAL;\n\t \n\tif (se_wwn)\n\t\tse_tpg->se_tpg_tfo = se_wwn->wwn_tf->tf_ops;\n\n\tif (!se_tpg->se_tpg_tfo) {\n\t\tpr_err(\"Unable to locate se_tpg->se_tpg_tfo pointer\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tINIT_HLIST_HEAD(&se_tpg->tpg_lun_hlist);\n\tse_tpg->proto_id = proto_id;\n\tse_tpg->se_tpg_wwn = se_wwn;\n\tatomic_set(&se_tpg->tpg_pr_ref_count, 0);\n\tINIT_LIST_HEAD(&se_tpg->acl_node_list);\n\tINIT_LIST_HEAD(&se_tpg->tpg_sess_list);\n\tspin_lock_init(&se_tpg->session_lock);\n\tmutex_init(&se_tpg->tpg_lun_mutex);\n\tmutex_init(&se_tpg->acl_node_mutex);\n\n\tif (se_tpg->proto_id >= 0) {\n\t\tse_tpg->tpg_virt_lun0 = core_tpg_alloc_lun(se_tpg, 0);\n\t\tif (IS_ERR(se_tpg->tpg_virt_lun0))\n\t\t\treturn PTR_ERR(se_tpg->tpg_virt_lun0);\n\n\t\tret = core_tpg_add_lun(se_tpg, se_tpg->tpg_virt_lun0,\n\t\t\t\ttrue, g_lun0_dev);\n\t\tif (ret < 0) {\n\t\t\tkfree(se_tpg->tpg_virt_lun0);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tpr_debug(\"TARGET_CORE[%s]: Allocated portal_group for endpoint: %s, \"\n\t\t \"Proto: %d, Portal Tag: %u\\n\", se_tpg->se_tpg_tfo->fabric_name,\n\t\tse_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg) ?\n\t\tse_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg) : NULL,\n\t\tse_tpg->proto_id, se_tpg->se_tpg_tfo->tpg_get_tag(se_tpg));\n\n\treturn 0;\n}\nEXPORT_SYMBOL(core_tpg_register);\n\nint core_tpg_deregister(struct se_portal_group *se_tpg)\n{\n\tconst struct target_core_fabric_ops *tfo = se_tpg->se_tpg_tfo;\n\tstruct se_node_acl *nacl, *nacl_tmp;\n\tLIST_HEAD(node_list);\n\n\tpr_debug(\"TARGET_CORE[%s]: Deallocating portal_group for endpoint: %s, \"\n\t\t \"Proto: %d, Portal Tag: %u\\n\", tfo->fabric_name,\n\t\ttfo->tpg_get_wwn(se_tpg) ? tfo->tpg_get_wwn(se_tpg) : NULL,\n\t\tse_tpg->proto_id, tfo->tpg_get_tag(se_tpg));\n\n\twhile (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)\n\t\tcpu_relax();\n\n\tmutex_lock(&se_tpg->acl_node_mutex);\n\tlist_splice_init(&se_tpg->acl_node_list, &node_list);\n\tmutex_unlock(&se_tpg->acl_node_mutex);\n\t \n\tlist_for_each_entry_safe(nacl, nacl_tmp, &node_list, acl_list) {\n\t\tlist_del_init(&nacl->acl_list);\n\n\t\tcore_tpg_wait_for_nacl_pr_ref(nacl);\n\t\tcore_free_device_list_for_node(nacl, se_tpg);\n\t\tkfree(nacl);\n\t}\n\n\tif (se_tpg->proto_id >= 0) {\n\t\tcore_tpg_remove_lun(se_tpg, se_tpg->tpg_virt_lun0);\n\t\tkfree_rcu(se_tpg->tpg_virt_lun0, rcu_head);\n\t}\n\n\ttarget_tpg_deregister_rtpi(se_tpg);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(core_tpg_deregister);\n\nstruct se_lun *core_tpg_alloc_lun(\n\tstruct se_portal_group *tpg,\n\tu64 unpacked_lun)\n{\n\tstruct se_lun *lun;\n\n\tlun = kzalloc(sizeof(*lun), GFP_KERNEL);\n\tif (!lun) {\n\t\tpr_err(\"Unable to allocate se_lun memory\\n\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tlun->unpacked_lun = unpacked_lun;\n\tatomic_set(&lun->lun_acl_count, 0);\n\tinit_completion(&lun->lun_shutdown_comp);\n\tINIT_LIST_HEAD(&lun->lun_deve_list);\n\tINIT_LIST_HEAD(&lun->lun_dev_link);\n\tatomic_set(&lun->lun_tg_pt_secondary_offline, 0);\n\tspin_lock_init(&lun->lun_deve_lock);\n\tmutex_init(&lun->lun_tg_pt_md_mutex);\n\tINIT_LIST_HEAD(&lun->lun_tg_pt_gp_link);\n\tspin_lock_init(&lun->lun_tg_pt_gp_lock);\n\tlun->lun_tpg = tpg;\n\n\treturn lun;\n}\n\nint core_tpg_add_lun(\n\tstruct se_portal_group *tpg,\n\tstruct se_lun *lun,\n\tbool lun_access_ro,\n\tstruct se_device *dev)\n{\n\tint ret;\n\n\tret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release, 0,\n\t\t\t      GFP_KERNEL);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tif (!(dev->transport_flags & TRANSPORT_FLAG_PASSTHROUGH_ALUA) &&\n\t    !(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))\n\t\ttarget_attach_tg_pt_gp(lun, dev->t10_alua.default_tg_pt_gp);\n\n\tmutex_lock(&tpg->tpg_lun_mutex);\n\n\tspin_lock(&dev->se_port_lock);\n\tlun->lun_index = dev->dev_index;\n\trcu_assign_pointer(lun->lun_se_dev, dev);\n\tdev->export_count++;\n\tlist_add_tail(&lun->lun_dev_link, &dev->dev_sep_list);\n\tspin_unlock(&dev->se_port_lock);\n\n\tif (dev->dev_flags & DF_READ_ONLY)\n\t\tlun->lun_access_ro = true;\n\telse\n\t\tlun->lun_access_ro = lun_access_ro;\n\tif (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))\n\t\thlist_add_head_rcu(&lun->link, &tpg->tpg_lun_hlist);\n\tmutex_unlock(&tpg->tpg_lun_mutex);\n\n\treturn 0;\n\nout:\n\treturn ret;\n}\n\nvoid core_tpg_remove_lun(\n\tstruct se_portal_group *tpg,\n\tstruct se_lun *lun)\n{\n\t \n\tstruct se_device *dev = rcu_dereference_raw(lun->lun_se_dev);\n\n\tlun->lun_shutdown = true;\n\n\tcore_clear_lun_from_tpg(lun, tpg);\n\t \n\ttransport_clear_lun_ref(lun);\n\n\tmutex_lock(&tpg->tpg_lun_mutex);\n\tif (lun->lun_se_dev) {\n\t\ttarget_detach_tg_pt_gp(lun);\n\n\t\tspin_lock(&dev->se_port_lock);\n\t\tlist_del(&lun->lun_dev_link);\n\t\tdev->export_count--;\n\t\trcu_assign_pointer(lun->lun_se_dev, NULL);\n\t\tspin_unlock(&dev->se_port_lock);\n\t}\n\tif (!(dev->se_hba->hba_flags & HBA_FLAGS_INTERNAL_USE))\n\t\thlist_del_rcu(&lun->link);\n\n\tlun->lun_shutdown = false;\n\tmutex_unlock(&tpg->tpg_lun_mutex);\n\n\tpercpu_ref_exit(&lun->lun_ref);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}