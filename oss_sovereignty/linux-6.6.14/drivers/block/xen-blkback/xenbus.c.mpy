{
  "module_name": "xenbus.c",
  "hash_id": "37d248a17c31e0e9c2f37c728dbce5138581d32a8a63d623c2752f397ce9822c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/block/xen-blkback/xenbus.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"xen-blkback: \" fmt\n\n#include <linux/module.h>\n#include <linux/kthread.h>\n#include <linux/pagemap.h>\n#include <xen/events.h>\n#include <xen/grant_table.h>\n#include \"common.h\"\n\n \n#define RINGREF_NAME_LEN (20)\n\nstruct backend_info {\n\tstruct xenbus_device\t*dev;\n\tstruct xen_blkif\t*blkif;\n\tstruct xenbus_watch\tbackend_watch;\n\tunsigned\t\tmajor;\n\tunsigned\t\tminor;\n\tchar\t\t\t*mode;\n};\n\nstatic struct kmem_cache *xen_blkif_cachep;\nstatic void connect(struct backend_info *);\nstatic int connect_ring(struct backend_info *);\nstatic void backend_changed(struct xenbus_watch *, const char *,\n\t\t\t    const char *);\nstatic void xen_blkif_free(struct xen_blkif *blkif);\nstatic void xen_vbd_free(struct xen_vbd *vbd);\n\nstruct xenbus_device *xen_blkbk_xenbus(struct backend_info *be)\n{\n\treturn be->dev;\n}\n\n \nstatic void xen_blkif_deferred_free(struct work_struct *work)\n{\n\tstruct xen_blkif *blkif;\n\n\tblkif = container_of(work, struct xen_blkif, free_work);\n\txen_blkif_free(blkif);\n}\n\nstatic int blkback_name(struct xen_blkif *blkif, char *buf)\n{\n\tchar *devpath, *devname;\n\tstruct xenbus_device *dev = blkif->be->dev;\n\n\tdevpath = xenbus_read(XBT_NIL, dev->nodename, \"dev\", NULL);\n\tif (IS_ERR(devpath))\n\t\treturn PTR_ERR(devpath);\n\n\tdevname = strstr(devpath, \"/dev/\");\n\tif (devname != NULL)\n\t\tdevname += strlen(\"/dev/\");\n\telse\n\t\tdevname  = devpath;\n\n\tsnprintf(buf, TASK_COMM_LEN, \"%d.%s\", blkif->domid, devname);\n\tkfree(devpath);\n\n\treturn 0;\n}\n\nstatic void xen_update_blkif_status(struct xen_blkif *blkif)\n{\n\tint err;\n\tchar name[TASK_COMM_LEN];\n\tstruct xen_blkif_ring *ring;\n\tint i;\n\n\t \n\tif (!blkif->rings || !blkif->rings[0].irq || !blkif->vbd.bdev)\n\t\treturn;\n\n\t \n\tif (blkif->be->dev->state == XenbusStateConnected)\n\t\treturn;\n\n\t \n\tconnect(blkif->be);\n\tif (blkif->be->dev->state != XenbusStateConnected)\n\t\treturn;\n\n\terr = blkback_name(blkif, name);\n\tif (err) {\n\t\txenbus_dev_error(blkif->be->dev, err, \"get blkback dev name\");\n\t\treturn;\n\t}\n\n\terr = sync_blockdev(blkif->vbd.bdev);\n\tif (err) {\n\t\txenbus_dev_error(blkif->be->dev, err, \"block flush\");\n\t\treturn;\n\t}\n\tinvalidate_inode_pages2(blkif->vbd.bdev->bd_inode->i_mapping);\n\n\tfor (i = 0; i < blkif->nr_rings; i++) {\n\t\tring = &blkif->rings[i];\n\t\tring->xenblkd = kthread_run(xen_blkif_schedule, ring, \"%s-%d\", name, i);\n\t\tif (IS_ERR(ring->xenblkd)) {\n\t\t\terr = PTR_ERR(ring->xenblkd);\n\t\t\tring->xenblkd = NULL;\n\t\t\txenbus_dev_fatal(blkif->be->dev, err,\n\t\t\t\t\t\"start %s-%d xenblkd\", name, i);\n\t\t\tgoto out;\n\t\t}\n\t}\n\treturn;\n\nout:\n\twhile (--i >= 0) {\n\t\tring = &blkif->rings[i];\n\t\tkthread_stop(ring->xenblkd);\n\t}\n\treturn;\n}\n\nstatic int xen_blkif_alloc_rings(struct xen_blkif *blkif)\n{\n\tunsigned int r;\n\n\tblkif->rings = kcalloc(blkif->nr_rings, sizeof(struct xen_blkif_ring),\n\t\t\t       GFP_KERNEL);\n\tif (!blkif->rings)\n\t\treturn -ENOMEM;\n\n\tfor (r = 0; r < blkif->nr_rings; r++) {\n\t\tstruct xen_blkif_ring *ring = &blkif->rings[r];\n\n\t\tspin_lock_init(&ring->blk_ring_lock);\n\t\tinit_waitqueue_head(&ring->wq);\n\t\tINIT_LIST_HEAD(&ring->pending_free);\n\t\tINIT_LIST_HEAD(&ring->persistent_purge_list);\n\t\tINIT_WORK(&ring->persistent_purge_work, xen_blkbk_unmap_purged_grants);\n\t\tgnttab_page_cache_init(&ring->free_pages);\n\n\t\tspin_lock_init(&ring->pending_free_lock);\n\t\tinit_waitqueue_head(&ring->pending_free_wq);\n\t\tinit_waitqueue_head(&ring->shutdown_wq);\n\t\tring->blkif = blkif;\n\t\tring->st_print = jiffies;\n\t\tring->active = true;\n\t}\n\n\treturn 0;\n}\n\n \nstatic bool feature_persistent = true;\nmodule_param(feature_persistent, bool, 0644);\nMODULE_PARM_DESC(feature_persistent, \"Enables the persistent grants feature\");\n\nstatic struct xen_blkif *xen_blkif_alloc(domid_t domid)\n{\n\tstruct xen_blkif *blkif;\n\n\tBUILD_BUG_ON(MAX_INDIRECT_PAGES > BLKIF_MAX_INDIRECT_PAGES_PER_REQUEST);\n\n\tblkif = kmem_cache_zalloc(xen_blkif_cachep, GFP_KERNEL);\n\tif (!blkif)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tblkif->domid = domid;\n\tatomic_set(&blkif->refcnt, 1);\n\tinit_completion(&blkif->drain_complete);\n\n\t \n\t__module_get(THIS_MODULE);\n\tINIT_WORK(&blkif->free_work, xen_blkif_deferred_free);\n\n\treturn blkif;\n}\n\nstatic int xen_blkif_map(struct xen_blkif_ring *ring, grant_ref_t *gref,\n\t\t\t unsigned int nr_grefs, unsigned int evtchn)\n{\n\tint err;\n\tstruct xen_blkif *blkif = ring->blkif;\n\tconst struct blkif_common_sring *sring_common;\n\tRING_IDX rsp_prod, req_prod;\n\tunsigned int size;\n\n\t \n\tif (ring->irq)\n\t\treturn 0;\n\n\terr = xenbus_map_ring_valloc(blkif->be->dev, gref, nr_grefs,\n\t\t\t\t     &ring->blk_ring);\n\tif (err < 0)\n\t\treturn err;\n\n\tsring_common = (struct blkif_common_sring *)ring->blk_ring;\n\trsp_prod = READ_ONCE(sring_common->rsp_prod);\n\treq_prod = READ_ONCE(sring_common->req_prod);\n\n\tswitch (blkif->blk_protocol) {\n\tcase BLKIF_PROTOCOL_NATIVE:\n\t{\n\t\tstruct blkif_sring *sring_native =\n\t\t\t(struct blkif_sring *)ring->blk_ring;\n\n\t\tBACK_RING_ATTACH(&ring->blk_rings.native, sring_native,\n\t\t\t\t rsp_prod, XEN_PAGE_SIZE * nr_grefs);\n\t\tsize = __RING_SIZE(sring_native, XEN_PAGE_SIZE * nr_grefs);\n\t\tbreak;\n\t}\n\tcase BLKIF_PROTOCOL_X86_32:\n\t{\n\t\tstruct blkif_x86_32_sring *sring_x86_32 =\n\t\t\t(struct blkif_x86_32_sring *)ring->blk_ring;\n\n\t\tBACK_RING_ATTACH(&ring->blk_rings.x86_32, sring_x86_32,\n\t\t\t\t rsp_prod, XEN_PAGE_SIZE * nr_grefs);\n\t\tsize = __RING_SIZE(sring_x86_32, XEN_PAGE_SIZE * nr_grefs);\n\t\tbreak;\n\t}\n\tcase BLKIF_PROTOCOL_X86_64:\n\t{\n\t\tstruct blkif_x86_64_sring *sring_x86_64 =\n\t\t\t(struct blkif_x86_64_sring *)ring->blk_ring;\n\n\t\tBACK_RING_ATTACH(&ring->blk_rings.x86_64, sring_x86_64,\n\t\t\t\t rsp_prod, XEN_PAGE_SIZE * nr_grefs);\n\t\tsize = __RING_SIZE(sring_x86_64, XEN_PAGE_SIZE * nr_grefs);\n\t\tbreak;\n\t}\n\tdefault:\n\t\tBUG();\n\t}\n\n\terr = -EIO;\n\tif (req_prod - rsp_prod > size)\n\t\tgoto fail;\n\n\terr = bind_interdomain_evtchn_to_irqhandler_lateeoi(blkif->be->dev,\n\t\t\tevtchn, xen_blkif_be_int, 0, \"blkif-backend\", ring);\n\tif (err < 0)\n\t\tgoto fail;\n\tring->irq = err;\n\n\treturn 0;\n\nfail:\n\txenbus_unmap_ring_vfree(blkif->be->dev, ring->blk_ring);\n\tring->blk_rings.common.sring = NULL;\n\treturn err;\n}\n\nstatic int xen_blkif_disconnect(struct xen_blkif *blkif)\n{\n\tstruct pending_req *req, *n;\n\tunsigned int j, r;\n\tbool busy = false;\n\n\tfor (r = 0; r < blkif->nr_rings; r++) {\n\t\tstruct xen_blkif_ring *ring = &blkif->rings[r];\n\t\tunsigned int i = 0;\n\n\t\tif (!ring->active)\n\t\t\tcontinue;\n\n\t\tif (ring->xenblkd) {\n\t\t\tkthread_stop(ring->xenblkd);\n\t\t\tring->xenblkd = NULL;\n\t\t\twake_up(&ring->shutdown_wq);\n\t\t}\n\n\t\t \n\t\tif (atomic_read(&ring->inflight) > 0) {\n\t\t\tbusy = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ring->irq) {\n\t\t\tunbind_from_irqhandler(ring->irq, ring);\n\t\t\tring->irq = 0;\n\t\t}\n\n\t\tif (ring->blk_rings.common.sring) {\n\t\t\txenbus_unmap_ring_vfree(blkif->be->dev, ring->blk_ring);\n\t\t\tring->blk_rings.common.sring = NULL;\n\t\t}\n\n\t\t \n\t\txen_blkbk_free_caches(ring);\n\n\t\t \n\t\tlist_for_each_entry_safe(req, n, &ring->pending_free, free_list) {\n\t\t\tlist_del(&req->free_list);\n\n\t\t\tfor (j = 0; j < MAX_INDIRECT_SEGMENTS; j++)\n\t\t\t\tkfree(req->segments[j]);\n\n\t\t\tfor (j = 0; j < MAX_INDIRECT_PAGES; j++)\n\t\t\t\tkfree(req->indirect_pages[j]);\n\n\t\t\tkfree(req);\n\t\t\ti++;\n\t\t}\n\n\t\tBUG_ON(atomic_read(&ring->persistent_gnt_in_use) != 0);\n\t\tBUG_ON(!list_empty(&ring->persistent_purge_list));\n\t\tBUG_ON(!RB_EMPTY_ROOT(&ring->persistent_gnts));\n\t\tBUG_ON(ring->free_pages.num_pages != 0);\n\t\tBUG_ON(ring->persistent_gnt_c != 0);\n\t\tWARN_ON(i != (XEN_BLKIF_REQS_PER_PAGE * blkif->nr_ring_pages));\n\t\tring->active = false;\n\t}\n\tif (busy)\n\t\treturn -EBUSY;\n\n\tblkif->nr_ring_pages = 0;\n\t \n\tkfree(blkif->rings);\n\tblkif->rings = NULL;\n\tblkif->nr_rings = 0;\n\n\treturn 0;\n}\n\nstatic void xen_blkif_free(struct xen_blkif *blkif)\n{\n\tWARN_ON(xen_blkif_disconnect(blkif));\n\txen_vbd_free(&blkif->vbd);\n\tkfree(blkif->be->mode);\n\tkfree(blkif->be);\n\n\t \n\tkmem_cache_free(xen_blkif_cachep, blkif);\n\tmodule_put(THIS_MODULE);\n}\n\nint __init xen_blkif_interface_init(void)\n{\n\txen_blkif_cachep = kmem_cache_create(\"blkif_cache\",\n\t\t\t\t\t     sizeof(struct xen_blkif),\n\t\t\t\t\t     0, 0, NULL);\n\tif (!xen_blkif_cachep)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nvoid xen_blkif_interface_fini(void)\n{\n\tkmem_cache_destroy(xen_blkif_cachep);\n\txen_blkif_cachep = NULL;\n}\n\n \n\n#define VBD_SHOW_ALLRING(name, format)\t\t\t\t\t\\\n\tstatic ssize_t show_##name(struct device *_dev,\t\t\t\\\n\t\t\t\t   struct device_attribute *attr,\t\\\n\t\t\t\t   char *buf)\t\t\t\t\\\n\t{\t\t\t\t\t\t\t\t\\\n\t\tstruct xenbus_device *dev = to_xenbus_device(_dev);\t\\\n\t\tstruct backend_info *be = dev_get_drvdata(&dev->dev);\t\\\n\t\tstruct xen_blkif *blkif = be->blkif;\t\t\t\\\n\t\tunsigned int i;\t\t\t\t\t\t\\\n\t\tunsigned long long result = 0;\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\tif (!blkif->rings)\t\t\t\t\\\n\t\t\tgoto out;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\tfor (i = 0; i < blkif->nr_rings; i++) {\t\t\\\n\t\t\tstruct xen_blkif_ring *ring = &blkif->rings[i];\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\t\tresult += ring->st_##name;\t\t\t\\\n\t\t}\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\nout:\t\t\t\t\t\t\t\t\t\\\n\t\treturn sprintf(buf, format, result);\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tstatic DEVICE_ATTR(name, 0444, show_##name, NULL)\n\nVBD_SHOW_ALLRING(oo_req,  \"%llu\\n\");\nVBD_SHOW_ALLRING(rd_req,  \"%llu\\n\");\nVBD_SHOW_ALLRING(wr_req,  \"%llu\\n\");\nVBD_SHOW_ALLRING(f_req,  \"%llu\\n\");\nVBD_SHOW_ALLRING(ds_req,  \"%llu\\n\");\nVBD_SHOW_ALLRING(rd_sect, \"%llu\\n\");\nVBD_SHOW_ALLRING(wr_sect, \"%llu\\n\");\n\nstatic struct attribute *xen_vbdstat_attrs[] = {\n\t&dev_attr_oo_req.attr,\n\t&dev_attr_rd_req.attr,\n\t&dev_attr_wr_req.attr,\n\t&dev_attr_f_req.attr,\n\t&dev_attr_ds_req.attr,\n\t&dev_attr_rd_sect.attr,\n\t&dev_attr_wr_sect.attr,\n\tNULL\n};\n\nstatic const struct attribute_group xen_vbdstat_group = {\n\t.name = \"statistics\",\n\t.attrs = xen_vbdstat_attrs,\n};\n\n#define VBD_SHOW(name, format, args...)\t\t\t\t\t\\\n\tstatic ssize_t show_##name(struct device *_dev,\t\t\t\\\n\t\t\t\t   struct device_attribute *attr,\t\\\n\t\t\t\t   char *buf)\t\t\t\t\\\n\t{\t\t\t\t\t\t\t\t\\\n\t\tstruct xenbus_device *dev = to_xenbus_device(_dev);\t\\\n\t\tstruct backend_info *be = dev_get_drvdata(&dev->dev);\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\treturn sprintf(buf, format, ##args);\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n\tstatic DEVICE_ATTR(name, 0444, show_##name, NULL)\n\nVBD_SHOW(physical_device, \"%x:%x\\n\", be->major, be->minor);\nVBD_SHOW(mode, \"%s\\n\", be->mode);\n\nstatic int xenvbd_sysfs_addif(struct xenbus_device *dev)\n{\n\tint error;\n\n\terror = device_create_file(&dev->dev, &dev_attr_physical_device);\n\tif (error)\n\t\tgoto fail1;\n\n\terror = device_create_file(&dev->dev, &dev_attr_mode);\n\tif (error)\n\t\tgoto fail2;\n\n\terror = sysfs_create_group(&dev->dev.kobj, &xen_vbdstat_group);\n\tif (error)\n\t\tgoto fail3;\n\n\treturn 0;\n\nfail3:\tsysfs_remove_group(&dev->dev.kobj, &xen_vbdstat_group);\nfail2:\tdevice_remove_file(&dev->dev, &dev_attr_mode);\nfail1:\tdevice_remove_file(&dev->dev, &dev_attr_physical_device);\n\treturn error;\n}\n\nstatic void xenvbd_sysfs_delif(struct xenbus_device *dev)\n{\n\tsysfs_remove_group(&dev->dev.kobj, &xen_vbdstat_group);\n\tdevice_remove_file(&dev->dev, &dev_attr_mode);\n\tdevice_remove_file(&dev->dev, &dev_attr_physical_device);\n}\n\nstatic void xen_vbd_free(struct xen_vbd *vbd)\n{\n\tif (vbd->bdev)\n\t\tblkdev_put(vbd->bdev, NULL);\n\tvbd->bdev = NULL;\n}\n\nstatic int xen_vbd_create(struct xen_blkif *blkif, blkif_vdev_t handle,\n\t\t\t  unsigned major, unsigned minor, int readonly,\n\t\t\t  int cdrom)\n{\n\tstruct xen_vbd *vbd;\n\tstruct block_device *bdev;\n\n\tvbd = &blkif->vbd;\n\tvbd->handle   = handle;\n\tvbd->readonly = readonly;\n\tvbd->type     = 0;\n\n\tvbd->pdevice  = MKDEV(major, minor);\n\n\tbdev = blkdev_get_by_dev(vbd->pdevice, vbd->readonly ?\n\t\t\t\t BLK_OPEN_READ : BLK_OPEN_WRITE, NULL, NULL);\n\n\tif (IS_ERR(bdev)) {\n\t\tpr_warn(\"xen_vbd_create: device %08x could not be opened\\n\",\n\t\t\tvbd->pdevice);\n\t\treturn -ENOENT;\n\t}\n\n\tvbd->bdev = bdev;\n\tif (vbd->bdev->bd_disk == NULL) {\n\t\tpr_warn(\"xen_vbd_create: device %08x doesn't exist\\n\",\n\t\t\tvbd->pdevice);\n\t\txen_vbd_free(vbd);\n\t\treturn -ENOENT;\n\t}\n\tvbd->size = vbd_sz(vbd);\n\n\tif (cdrom || disk_to_cdi(vbd->bdev->bd_disk))\n\t\tvbd->type |= VDISK_CDROM;\n\tif (vbd->bdev->bd_disk->flags & GENHD_FL_REMOVABLE)\n\t\tvbd->type |= VDISK_REMOVABLE;\n\n\tif (bdev_write_cache(bdev))\n\t\tvbd->flush_support = true;\n\tif (bdev_max_secure_erase_sectors(bdev))\n\t\tvbd->discard_secure = true;\n\n\tpr_debug(\"Successful creation of handle=%04x (dom=%u)\\n\",\n\t\thandle, blkif->domid);\n\treturn 0;\n}\n\nstatic void xen_blkbk_remove(struct xenbus_device *dev)\n{\n\tstruct backend_info *be = dev_get_drvdata(&dev->dev);\n\n\tpr_debug(\"%s %p %d\\n\", __func__, dev, dev->otherend_id);\n\n\tif (be->major || be->minor)\n\t\txenvbd_sysfs_delif(dev);\n\n\tif (be->backend_watch.node) {\n\t\tunregister_xenbus_watch(&be->backend_watch);\n\t\tkfree(be->backend_watch.node);\n\t\tbe->backend_watch.node = NULL;\n\t}\n\n\tdev_set_drvdata(&dev->dev, NULL);\n\n\tif (be->blkif) {\n\t\txen_blkif_disconnect(be->blkif);\n\n\t\t \n\t\txen_blkif_put(be->blkif);\n\t}\n}\n\nint xen_blkbk_flush_diskcache(struct xenbus_transaction xbt,\n\t\t\t      struct backend_info *be, int state)\n{\n\tstruct xenbus_device *dev = be->dev;\n\tint err;\n\n\terr = xenbus_printf(xbt, dev->nodename, \"feature-flush-cache\",\n\t\t\t    \"%d\", state);\n\tif (err)\n\t\tdev_warn(&dev->dev, \"writing feature-flush-cache (%d)\", err);\n\n\treturn err;\n}\n\nstatic void xen_blkbk_discard(struct xenbus_transaction xbt, struct backend_info *be)\n{\n\tstruct xenbus_device *dev = be->dev;\n\tstruct xen_blkif *blkif = be->blkif;\n\tint err;\n\tint state = 0;\n\tstruct block_device *bdev = be->blkif->vbd.bdev;\n\n\tif (!xenbus_read_unsigned(dev->nodename, \"discard-enable\", 1))\n\t\treturn;\n\n\tif (bdev_max_discard_sectors(bdev)) {\n\t\terr = xenbus_printf(xbt, dev->nodename,\n\t\t\t\"discard-granularity\", \"%u\",\n\t\t\tbdev_discard_granularity(bdev));\n\t\tif (err) {\n\t\t\tdev_warn(&dev->dev, \"writing discard-granularity (%d)\", err);\n\t\t\treturn;\n\t\t}\n\t\terr = xenbus_printf(xbt, dev->nodename,\n\t\t\t\"discard-alignment\", \"%u\",\n\t\t\tbdev_discard_alignment(bdev));\n\t\tif (err) {\n\t\t\tdev_warn(&dev->dev, \"writing discard-alignment (%d)\", err);\n\t\t\treturn;\n\t\t}\n\t\tstate = 1;\n\t\t \n\t\terr = xenbus_printf(xbt, dev->nodename,\n\t\t\t\t    \"discard-secure\", \"%d\",\n\t\t\t\t    blkif->vbd.discard_secure);\n\t\tif (err) {\n\t\t\tdev_warn(&dev->dev, \"writing discard-secure (%d)\", err);\n\t\t\treturn;\n\t\t}\n\t}\n\terr = xenbus_printf(xbt, dev->nodename, \"feature-discard\",\n\t\t\t    \"%d\", state);\n\tif (err)\n\t\tdev_warn(&dev->dev, \"writing feature-discard (%d)\", err);\n}\n\nint xen_blkbk_barrier(struct xenbus_transaction xbt,\n\t\t      struct backend_info *be, int state)\n{\n\tstruct xenbus_device *dev = be->dev;\n\tint err;\n\n\terr = xenbus_printf(xbt, dev->nodename, \"feature-barrier\",\n\t\t\t    \"%d\", state);\n\tif (err)\n\t\tdev_warn(&dev->dev, \"writing feature-barrier (%d)\", err);\n\n\treturn err;\n}\n\n \nstatic int xen_blkbk_probe(struct xenbus_device *dev,\n\t\t\t   const struct xenbus_device_id *id)\n{\n\tint err;\n\tstruct backend_info *be = kzalloc(sizeof(struct backend_info),\n\t\t\t\t\t  GFP_KERNEL);\n\n\t \n\tpr_debug(\"%s %p %d\\n\", __func__, dev, dev->otherend_id);\n\n\tif (!be) {\n\t\txenbus_dev_fatal(dev, -ENOMEM,\n\t\t\t\t \"allocating backend structure\");\n\t\treturn -ENOMEM;\n\t}\n\tbe->dev = dev;\n\tdev_set_drvdata(&dev->dev, be);\n\n\tbe->blkif = xen_blkif_alloc(dev->otherend_id);\n\tif (IS_ERR(be->blkif)) {\n\t\terr = PTR_ERR(be->blkif);\n\t\tbe->blkif = NULL;\n\t\txenbus_dev_fatal(dev, err, \"creating block interface\");\n\t\tgoto fail;\n\t}\n\n\terr = xenbus_printf(XBT_NIL, dev->nodename,\n\t\t\t    \"feature-max-indirect-segments\", \"%u\",\n\t\t\t    MAX_INDIRECT_SEGMENTS);\n\tif (err)\n\t\tdev_warn(&dev->dev,\n\t\t\t \"writing %s/feature-max-indirect-segments (%d)\",\n\t\t\t dev->nodename, err);\n\n\t \n\terr = xenbus_printf(XBT_NIL, dev->nodename,\n\t\t\t    \"multi-queue-max-queues\", \"%u\", xenblk_max_queues);\n\tif (err)\n\t\tpr_warn(\"Error writing multi-queue-max-queues\\n\");\n\n\t \n\tbe->blkif->be = be;\n\n\terr = xenbus_watch_pathfmt(dev, &be->backend_watch, NULL,\n\t\t\t\t   backend_changed,\n\t\t\t\t   \"%s/%s\", dev->nodename, \"physical-device\");\n\tif (err)\n\t\tgoto fail;\n\n\terr = xenbus_printf(XBT_NIL, dev->nodename, \"max-ring-page-order\", \"%u\",\n\t\t\t    xen_blkif_max_ring_order);\n\tif (err)\n\t\tpr_warn(\"%s write out 'max-ring-page-order' failed\\n\", __func__);\n\n\terr = xenbus_switch_state(dev, XenbusStateInitWait);\n\tif (err)\n\t\tgoto fail;\n\n\treturn 0;\n\nfail:\n\tpr_warn(\"%s failed\\n\", __func__);\n\txen_blkbk_remove(dev);\n\treturn err;\n}\n\n \nstatic void backend_changed(struct xenbus_watch *watch,\n\t\t\t    const char *path, const char *token)\n{\n\tint err;\n\tunsigned major;\n\tunsigned minor;\n\tstruct backend_info *be\n\t\t= container_of(watch, struct backend_info, backend_watch);\n\tstruct xenbus_device *dev = be->dev;\n\tint cdrom = 0;\n\tunsigned long handle;\n\tchar *device_type;\n\n\tpr_debug(\"%s %p %d\\n\", __func__, dev, dev->otherend_id);\n\n\terr = xenbus_scanf(XBT_NIL, dev->nodename, \"physical-device\", \"%x:%x\",\n\t\t\t   &major, &minor);\n\tif (XENBUS_EXIST_ERR(err)) {\n\t\t \n\t\treturn;\n\t}\n\tif (err != 2) {\n\t\txenbus_dev_fatal(dev, err, \"reading physical-device\");\n\t\treturn;\n\t}\n\n\tif (be->major | be->minor) {\n\t\tif (be->major != major || be->minor != minor)\n\t\t\tpr_warn(\"changing physical device (from %x:%x to %x:%x) not supported.\\n\",\n\t\t\t\tbe->major, be->minor, major, minor);\n\t\treturn;\n\t}\n\n\tbe->mode = xenbus_read(XBT_NIL, dev->nodename, \"mode\", NULL);\n\tif (IS_ERR(be->mode)) {\n\t\terr = PTR_ERR(be->mode);\n\t\tbe->mode = NULL;\n\t\txenbus_dev_fatal(dev, err, \"reading mode\");\n\t\treturn;\n\t}\n\n\tdevice_type = xenbus_read(XBT_NIL, dev->otherend, \"device-type\", NULL);\n\tif (!IS_ERR(device_type)) {\n\t\tcdrom = strcmp(device_type, \"cdrom\") == 0;\n\t\tkfree(device_type);\n\t}\n\n\t \n\terr = kstrtoul(strrchr(dev->otherend, '/') + 1, 0, &handle);\n\tif (err) {\n\t\tkfree(be->mode);\n\t\tbe->mode = NULL;\n\t\treturn;\n\t}\n\n\tbe->major = major;\n\tbe->minor = minor;\n\n\terr = xen_vbd_create(be->blkif, handle, major, minor,\n\t\t\t     !strchr(be->mode, 'w'), cdrom);\n\n\tif (err)\n\t\txenbus_dev_fatal(dev, err, \"creating vbd structure\");\n\telse {\n\t\terr = xenvbd_sysfs_addif(dev);\n\t\tif (err) {\n\t\t\txen_vbd_free(&be->blkif->vbd);\n\t\t\txenbus_dev_fatal(dev, err, \"creating sysfs entries\");\n\t\t}\n\t}\n\n\tif (err) {\n\t\tkfree(be->mode);\n\t\tbe->mode = NULL;\n\t\tbe->major = 0;\n\t\tbe->minor = 0;\n\t} else {\n\t\t \n\t\txen_update_blkif_status(be->blkif);\n\t}\n}\n\n \nstatic void frontend_changed(struct xenbus_device *dev,\n\t\t\t     enum xenbus_state frontend_state)\n{\n\tstruct backend_info *be = dev_get_drvdata(&dev->dev);\n\tint err;\n\n\tpr_debug(\"%s %p %s\\n\", __func__, dev, xenbus_strstate(frontend_state));\n\n\tswitch (frontend_state) {\n\tcase XenbusStateInitialising:\n\t\tif (dev->state == XenbusStateClosed) {\n\t\t\tpr_info(\"%s: prepare for reconnect\\n\", dev->nodename);\n\t\t\txenbus_switch_state(dev, XenbusStateInitWait);\n\t\t}\n\t\tbreak;\n\n\tcase XenbusStateInitialised:\n\tcase XenbusStateConnected:\n\t\t \n\t\tif (dev->state == XenbusStateConnected)\n\t\t\tbreak;\n\n\t\t \n\t\terr = xen_blkif_disconnect(be->blkif);\n\t\tif (err) {\n\t\t\txenbus_dev_fatal(dev, err, \"pending I/O\");\n\t\t\tbreak;\n\t\t}\n\n\t\terr = connect_ring(be);\n\t\tif (err) {\n\t\t\t \n\t\t\txen_blkif_disconnect(be->blkif);\n\t\t\tbreak;\n\t\t}\n\t\txen_update_blkif_status(be->blkif);\n\t\tbreak;\n\n\tcase XenbusStateClosing:\n\t\txenbus_switch_state(dev, XenbusStateClosing);\n\t\tbreak;\n\n\tcase XenbusStateClosed:\n\t\txen_blkif_disconnect(be->blkif);\n\t\txenbus_switch_state(dev, XenbusStateClosed);\n\t\tif (xenbus_dev_is_online(dev))\n\t\t\tbreak;\n\t\tfallthrough;\n\t\t \n\tcase XenbusStateUnknown:\n\t\t \n\t\tdevice_unregister(&dev->dev);\n\t\tbreak;\n\n\tdefault:\n\t\txenbus_dev_fatal(dev, -EINVAL, \"saw state %d at frontend\",\n\t\t\t\t frontend_state);\n\t\tbreak;\n\t}\n}\n\n \nstatic unsigned int buffer_squeeze_duration_ms = 10;\nmodule_param_named(buffer_squeeze_duration_ms,\n\t\tbuffer_squeeze_duration_ms, int, 0644);\nMODULE_PARM_DESC(buffer_squeeze_duration_ms,\n\"Duration in ms to squeeze pages buffer when a memory pressure is detected\");\n\n \nstatic void reclaim_memory(struct xenbus_device *dev)\n{\n\tstruct backend_info *be = dev_get_drvdata(&dev->dev);\n\n\tif (!be)\n\t\treturn;\n\tbe->blkif->buffer_squeeze_end = jiffies +\n\t\tmsecs_to_jiffies(buffer_squeeze_duration_ms);\n}\n\n \n\n \nstatic void connect(struct backend_info *be)\n{\n\tstruct xenbus_transaction xbt;\n\tint err;\n\tstruct xenbus_device *dev = be->dev;\n\n\tpr_debug(\"%s %s\\n\", __func__, dev->otherend);\n\n\t \nagain:\n\terr = xenbus_transaction_start(&xbt);\n\tif (err) {\n\t\txenbus_dev_fatal(dev, err, \"starting transaction\");\n\t\treturn;\n\t}\n\n\t \n\txen_blkbk_flush_diskcache(xbt, be, be->blkif->vbd.flush_support);\n\n\txen_blkbk_discard(xbt, be);\n\n\txen_blkbk_barrier(xbt, be, be->blkif->vbd.flush_support);\n\n\terr = xenbus_printf(xbt, dev->nodename, \"feature-persistent\", \"%u\",\n\t\t\tbe->blkif->vbd.feature_gnt_persistent_parm);\n\tif (err) {\n\t\txenbus_dev_fatal(dev, err, \"writing %s/feature-persistent\",\n\t\t\t\t dev->nodename);\n\t\tgoto abort;\n\t}\n\n\terr = xenbus_printf(xbt, dev->nodename, \"sectors\", \"%llu\",\n\t\t\t    (unsigned long long)vbd_sz(&be->blkif->vbd));\n\tif (err) {\n\t\txenbus_dev_fatal(dev, err, \"writing %s/sectors\",\n\t\t\t\t dev->nodename);\n\t\tgoto abort;\n\t}\n\n\t \n\terr = xenbus_printf(xbt, dev->nodename, \"info\", \"%u\",\n\t\t\t    be->blkif->vbd.type |\n\t\t\t    (be->blkif->vbd.readonly ? VDISK_READONLY : 0));\n\tif (err) {\n\t\txenbus_dev_fatal(dev, err, \"writing %s/info\",\n\t\t\t\t dev->nodename);\n\t\tgoto abort;\n\t}\n\terr = xenbus_printf(xbt, dev->nodename, \"sector-size\", \"%lu\",\n\t\t\t    (unsigned long)\n\t\t\t    bdev_logical_block_size(be->blkif->vbd.bdev));\n\tif (err) {\n\t\txenbus_dev_fatal(dev, err, \"writing %s/sector-size\",\n\t\t\t\t dev->nodename);\n\t\tgoto abort;\n\t}\n\terr = xenbus_printf(xbt, dev->nodename, \"physical-sector-size\", \"%u\",\n\t\t\t    bdev_physical_block_size(be->blkif->vbd.bdev));\n\tif (err)\n\t\txenbus_dev_error(dev, err, \"writing %s/physical-sector-size\",\n\t\t\t\t dev->nodename);\n\n\terr = xenbus_transaction_end(xbt, 0);\n\tif (err == -EAGAIN)\n\t\tgoto again;\n\tif (err)\n\t\txenbus_dev_fatal(dev, err, \"ending transaction\");\n\n\terr = xenbus_switch_state(dev, XenbusStateConnected);\n\tif (err)\n\t\txenbus_dev_fatal(dev, err, \"%s: switching to Connected state\",\n\t\t\t\t dev->nodename);\n\n\treturn;\n abort:\n\txenbus_transaction_end(xbt, 1);\n}\n\n \nstatic int read_per_ring_refs(struct xen_blkif_ring *ring, const char *dir)\n{\n\tunsigned int ring_ref[XENBUS_MAX_RING_GRANTS];\n\tstruct pending_req *req, *n;\n\tint err, i, j;\n\tstruct xen_blkif *blkif = ring->blkif;\n\tstruct xenbus_device *dev = blkif->be->dev;\n\tunsigned int nr_grefs, evtchn;\n\n\terr = xenbus_scanf(XBT_NIL, dir, \"event-channel\", \"%u\",\n\t\t\t  &evtchn);\n\tif (err != 1) {\n\t\terr = -EINVAL;\n\t\txenbus_dev_fatal(dev, err, \"reading %s/event-channel\", dir);\n\t\treturn err;\n\t}\n\n\tnr_grefs = blkif->nr_ring_pages;\n\n\tif (unlikely(!nr_grefs)) {\n\t\tWARN_ON(true);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < nr_grefs; i++) {\n\t\tchar ring_ref_name[RINGREF_NAME_LEN];\n\n\t\tif (blkif->multi_ref)\n\t\t\tsnprintf(ring_ref_name, RINGREF_NAME_LEN, \"ring-ref%u\", i);\n\t\telse {\n\t\t\tWARN_ON(i != 0);\n\t\t\tsnprintf(ring_ref_name, RINGREF_NAME_LEN, \"ring-ref\");\n\t\t}\n\n\t\terr = xenbus_scanf(XBT_NIL, dir, ring_ref_name,\n\t\t\t\t   \"%u\", &ring_ref[i]);\n\n\t\tif (err != 1) {\n\t\t\terr = -EINVAL;\n\t\t\txenbus_dev_fatal(dev, err, \"reading %s/%s\",\n\t\t\t\t\t dir, ring_ref_name);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\terr = -ENOMEM;\n\tfor (i = 0; i < nr_grefs * XEN_BLKIF_REQS_PER_PAGE; i++) {\n\t\treq = kzalloc(sizeof(*req), GFP_KERNEL);\n\t\tif (!req)\n\t\t\tgoto fail;\n\t\tlist_add_tail(&req->free_list, &ring->pending_free);\n\t\tfor (j = 0; j < MAX_INDIRECT_SEGMENTS; j++) {\n\t\t\treq->segments[j] = kzalloc(sizeof(*req->segments[0]), GFP_KERNEL);\n\t\t\tif (!req->segments[j])\n\t\t\t\tgoto fail;\n\t\t}\n\t\tfor (j = 0; j < MAX_INDIRECT_PAGES; j++) {\n\t\t\treq->indirect_pages[j] = kzalloc(sizeof(*req->indirect_pages[0]),\n\t\t\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (!req->indirect_pages[j])\n\t\t\t\tgoto fail;\n\t\t}\n\t}\n\n\t \n\terr = xen_blkif_map(ring, ring_ref, nr_grefs, evtchn);\n\tif (err) {\n\t\txenbus_dev_fatal(dev, err, \"mapping ring-ref port %u\", evtchn);\n\t\tgoto fail;\n\t}\n\n\treturn 0;\n\nfail:\n\tlist_for_each_entry_safe(req, n, &ring->pending_free, free_list) {\n\t\tlist_del(&req->free_list);\n\t\tfor (j = 0; j < MAX_INDIRECT_SEGMENTS; j++) {\n\t\t\tif (!req->segments[j])\n\t\t\t\tbreak;\n\t\t\tkfree(req->segments[j]);\n\t\t}\n\t\tfor (j = 0; j < MAX_INDIRECT_PAGES; j++) {\n\t\t\tif (!req->indirect_pages[j])\n\t\t\t\tbreak;\n\t\t\tkfree(req->indirect_pages[j]);\n\t\t}\n\t\tkfree(req);\n\t}\n\treturn err;\n}\n\nstatic int connect_ring(struct backend_info *be)\n{\n\tstruct xenbus_device *dev = be->dev;\n\tstruct xen_blkif *blkif = be->blkif;\n\tchar protocol[64] = \"\";\n\tint err, i;\n\tchar *xspath;\n\tsize_t xspathsize;\n\tconst size_t xenstore_path_ext_size = 11;  \n\tunsigned int requested_num_queues = 0;\n\tunsigned int ring_page_order;\n\n\tpr_debug(\"%s %s\\n\", __func__, dev->otherend);\n\n\tblkif->blk_protocol = BLKIF_PROTOCOL_DEFAULT;\n\terr = xenbus_scanf(XBT_NIL, dev->otherend, \"protocol\",\n\t\t\t   \"%63s\", protocol);\n\tif (err <= 0)\n\t\tstrcpy(protocol, \"unspecified, assuming default\");\n\telse if (0 == strcmp(protocol, XEN_IO_PROTO_ABI_NATIVE))\n\t\tblkif->blk_protocol = BLKIF_PROTOCOL_NATIVE;\n\telse if (0 == strcmp(protocol, XEN_IO_PROTO_ABI_X86_32))\n\t\tblkif->blk_protocol = BLKIF_PROTOCOL_X86_32;\n\telse if (0 == strcmp(protocol, XEN_IO_PROTO_ABI_X86_64))\n\t\tblkif->blk_protocol = BLKIF_PROTOCOL_X86_64;\n\telse {\n\t\txenbus_dev_fatal(dev, err, \"unknown fe protocol %s\", protocol);\n\t\treturn -ENOSYS;\n\t}\n\n\tblkif->vbd.feature_gnt_persistent_parm = feature_persistent;\n\tblkif->vbd.feature_gnt_persistent =\n\t\tblkif->vbd.feature_gnt_persistent_parm &&\n\t\txenbus_read_unsigned(dev->otherend, \"feature-persistent\", 0);\n\n\tblkif->vbd.overflow_max_grants = 0;\n\n\t \n\trequested_num_queues = xenbus_read_unsigned(dev->otherend,\n\t\t\t\t\t\t    \"multi-queue-num-queues\",\n\t\t\t\t\t\t    1);\n\tif (requested_num_queues > xenblk_max_queues\n\t    || requested_num_queues == 0) {\n\t\t \n\t\txenbus_dev_fatal(dev, err,\n\t\t\t\t\"guest requested %u queues, exceeding the maximum of %u.\",\n\t\t\t\trequested_num_queues, xenblk_max_queues);\n\t\treturn -ENOSYS;\n\t}\n\tblkif->nr_rings = requested_num_queues;\n\tif (xen_blkif_alloc_rings(blkif))\n\t\treturn -ENOMEM;\n\n\tpr_info(\"%s: using %d queues, protocol %d (%s) %s\\n\", dev->nodename,\n\t\t blkif->nr_rings, blkif->blk_protocol, protocol,\n\t\t blkif->vbd.feature_gnt_persistent ? \"persistent grants\" : \"\");\n\n\terr = xenbus_scanf(XBT_NIL, dev->otherend, \"ring-page-order\", \"%u\",\n\t\t\t   &ring_page_order);\n\tif (err != 1) {\n\t\tblkif->nr_ring_pages = 1;\n\t\tblkif->multi_ref = false;\n\t} else if (ring_page_order <= xen_blkif_max_ring_order) {\n\t\tblkif->nr_ring_pages = 1 << ring_page_order;\n\t\tblkif->multi_ref = true;\n\t} else {\n\t\terr = -EINVAL;\n\t\txenbus_dev_fatal(dev, err,\n\t\t\t\t \"requested ring page order %d exceed max:%d\",\n\t\t\t\t ring_page_order,\n\t\t\t\t xen_blkif_max_ring_order);\n\t\treturn err;\n\t}\n\n\tif (blkif->nr_rings == 1)\n\t\treturn read_per_ring_refs(&blkif->rings[0], dev->otherend);\n\telse {\n\t\txspathsize = strlen(dev->otherend) + xenstore_path_ext_size;\n\t\txspath = kmalloc(xspathsize, GFP_KERNEL);\n\t\tif (!xspath) {\n\t\t\txenbus_dev_fatal(dev, -ENOMEM, \"reading ring references\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tfor (i = 0; i < blkif->nr_rings; i++) {\n\t\t\tmemset(xspath, 0, xspathsize);\n\t\t\tsnprintf(xspath, xspathsize, \"%s/queue-%u\", dev->otherend, i);\n\t\t\terr = read_per_ring_refs(&blkif->rings[i], xspath);\n\t\t\tif (err) {\n\t\t\t\tkfree(xspath);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t\tkfree(xspath);\n\t}\n\treturn 0;\n}\n\nstatic const struct xenbus_device_id xen_blkbk_ids[] = {\n\t{ \"vbd\" },\n\t{ \"\" }\n};\n\nstatic struct xenbus_driver xen_blkbk_driver = {\n\t.ids  = xen_blkbk_ids,\n\t.probe = xen_blkbk_probe,\n\t.remove = xen_blkbk_remove,\n\t.otherend_changed = frontend_changed,\n\t.allow_rebind = true,\n\t.reclaim_memory = reclaim_memory,\n};\n\nint xen_blkif_xenbus_init(void)\n{\n\treturn xenbus_register_backend(&xen_blkbk_driver);\n}\n\nvoid xen_blkif_xenbus_fini(void)\n{\n\txenbus_unregister_driver(&xen_blkbk_driver);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}