{
  "module_name": "drbd_nl.c",
  "hash_id": "455e8fe4cee5ff6518dace4a7c47ca655bd4e80acb0be8cc139f8c9ef9d347d7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/block/drbd/drbd_nl.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\tKBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/drbd.h>\n#include <linux/in.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/slab.h>\n#include <linux/blkpg.h>\n#include <linux/cpumask.h>\n#include \"drbd_int.h\"\n#include \"drbd_protocol.h\"\n#include \"drbd_req.h\"\n#include \"drbd_state_change.h\"\n#include <asm/unaligned.h>\n#include <linux/drbd_limits.h>\n#include <linux/kthread.h>\n\n#include <net/genetlink.h>\n\n \n\n\n\nint drbd_adm_new_minor(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_del_minor(struct sk_buff *skb, struct genl_info *info);\n\nint drbd_adm_new_resource(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_del_resource(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_down(struct sk_buff *skb, struct genl_info *info);\n\nint drbd_adm_set_role(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_attach(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_disk_opts(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_detach(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_connect(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_net_opts(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_resize(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_start_ov(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_new_c_uuid(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_disconnect(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_invalidate(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_invalidate_peer(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_pause_sync(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_resume_sync(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_suspend_io(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_resume_io(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_outdate(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_resource_opts(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_get_status(struct sk_buff *skb, struct genl_info *info);\nint drbd_adm_get_timeout_type(struct sk_buff *skb, struct genl_info *info);\n \nint drbd_adm_get_status_all(struct sk_buff *skb, struct netlink_callback *cb);\nint drbd_adm_dump_resources(struct sk_buff *skb, struct netlink_callback *cb);\nint drbd_adm_dump_devices(struct sk_buff *skb, struct netlink_callback *cb);\nint drbd_adm_dump_devices_done(struct netlink_callback *cb);\nint drbd_adm_dump_connections(struct sk_buff *skb, struct netlink_callback *cb);\nint drbd_adm_dump_connections_done(struct netlink_callback *cb);\nint drbd_adm_dump_peer_devices(struct sk_buff *skb, struct netlink_callback *cb);\nint drbd_adm_dump_peer_devices_done(struct netlink_callback *cb);\nint drbd_adm_get_initial_state(struct sk_buff *skb, struct netlink_callback *cb);\n\n#include <linux/drbd_genl_api.h>\n#include \"drbd_nla.h\"\n#include <linux/genl_magic_func.h>\n\nstatic atomic_t drbd_genl_seq = ATOMIC_INIT(2);  \nstatic atomic_t notify_genl_seq = ATOMIC_INIT(2);  \n\nDEFINE_MUTEX(notification_mutex);\n\n \nstatic char *drbd_m_holder = \"Hands off! this is DRBD's meta data device.\";\n\nstatic void drbd_adm_send_reply(struct sk_buff *skb, struct genl_info *info)\n{\n\tgenlmsg_end(skb, genlmsg_data(nlmsg_data(nlmsg_hdr(skb))));\n\tif (genlmsg_reply(skb, info))\n\t\tpr_err(\"error sending genl reply\\n\");\n}\n\n \nstatic int drbd_msg_put_info(struct sk_buff *skb, const char *info)\n{\n\tstruct nlattr *nla;\n\tint err = -EMSGSIZE;\n\n\tif (!info || !info[0])\n\t\treturn 0;\n\n\tnla = nla_nest_start_noflag(skb, DRBD_NLA_CFG_REPLY);\n\tif (!nla)\n\t\treturn err;\n\n\terr = nla_put_string(skb, T_info_text, info);\n\tif (err) {\n\t\tnla_nest_cancel(skb, nla);\n\t\treturn err;\n\t} else\n\t\tnla_nest_end(skb, nla);\n\treturn 0;\n}\n\n__printf(2, 3)\nstatic int drbd_msg_sprintf_info(struct sk_buff *skb, const char *fmt, ...)\n{\n\tva_list args;\n\tstruct nlattr *nla, *txt;\n\tint err = -EMSGSIZE;\n\tint len;\n\n\tnla = nla_nest_start_noflag(skb, DRBD_NLA_CFG_REPLY);\n\tif (!nla)\n\t\treturn err;\n\n\ttxt = nla_reserve(skb, T_info_text, 256);\n\tif (!txt) {\n\t\tnla_nest_cancel(skb, nla);\n\t\treturn err;\n\t}\n\tva_start(args, fmt);\n\tlen = vscnprintf(nla_data(txt), 256, fmt, args);\n\tva_end(args);\n\n\t \n\ttxt->nla_len = nla_attr_size(len+1);\n\tnlmsg_trim(skb, (char*)txt + NLA_ALIGN(txt->nla_len));\n\tnla_nest_end(skb, nla);\n\n\treturn 0;\n}\n\n \n#define DRBD_ADM_NEED_MINOR\t1\n#define DRBD_ADM_NEED_RESOURCE\t2\n#define DRBD_ADM_NEED_CONNECTION 4\nstatic int drbd_adm_prepare(struct drbd_config_context *adm_ctx,\n\tstruct sk_buff *skb, struct genl_info *info, unsigned flags)\n{\n\tstruct drbd_genlmsghdr *d_in = genl_info_userhdr(info);\n\tconst u8 cmd = info->genlhdr->cmd;\n\tint err;\n\n\tmemset(adm_ctx, 0, sizeof(*adm_ctx));\n\n\t \n\tif (cmd != DRBD_ADM_GET_STATUS && !capable(CAP_NET_ADMIN))\n\t       return -EPERM;\n\n\tadm_ctx->reply_skb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);\n\tif (!adm_ctx->reply_skb) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\tadm_ctx->reply_dh = genlmsg_put_reply(adm_ctx->reply_skb,\n\t\t\t\t\tinfo, &drbd_genl_family, 0, cmd);\n\t \n\tif (!adm_ctx->reply_dh) {\n\t\terr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\tadm_ctx->reply_dh->minor = d_in->minor;\n\tadm_ctx->reply_dh->ret_code = NO_ERROR;\n\n\tadm_ctx->volume = VOLUME_UNSPECIFIED;\n\tif (info->attrs[DRBD_NLA_CFG_CONTEXT]) {\n\t\tstruct nlattr *nla;\n\t\t \n\t\terr = drbd_cfg_context_from_attrs(NULL, info);\n\t\tif (err)\n\t\t\tgoto fail;\n\n\t\t \n\t\terr = nla_put_nohdr(adm_ctx->reply_skb,\n\t\t\t\tinfo->attrs[DRBD_NLA_CFG_CONTEXT]->nla_len,\n\t\t\t\tinfo->attrs[DRBD_NLA_CFG_CONTEXT]);\n\t\tif (err)\n\t\t\tgoto fail;\n\n\t\t \n\t\tnla = nested_attr_tb[__nla_type(T_ctx_volume)];\n\t\tif (nla)\n\t\t\tadm_ctx->volume = nla_get_u32(nla);\n\t\tnla = nested_attr_tb[__nla_type(T_ctx_resource_name)];\n\t\tif (nla)\n\t\t\tadm_ctx->resource_name = nla_data(nla);\n\t\tadm_ctx->my_addr = nested_attr_tb[__nla_type(T_ctx_my_addr)];\n\t\tadm_ctx->peer_addr = nested_attr_tb[__nla_type(T_ctx_peer_addr)];\n\t\tif ((adm_ctx->my_addr &&\n\t\t     nla_len(adm_ctx->my_addr) > sizeof(adm_ctx->connection->my_addr)) ||\n\t\t    (adm_ctx->peer_addr &&\n\t\t     nla_len(adm_ctx->peer_addr) > sizeof(adm_ctx->connection->peer_addr))) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tadm_ctx->minor = d_in->minor;\n\tadm_ctx->device = minor_to_device(d_in->minor);\n\n\t \n\tif (adm_ctx->device)\n\t\tkref_get(&adm_ctx->device->kref);\n\n\tif (adm_ctx->resource_name) {\n\t\tadm_ctx->resource = drbd_find_resource(adm_ctx->resource_name);\n\t}\n\n\tif (!adm_ctx->device && (flags & DRBD_ADM_NEED_MINOR)) {\n\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"unknown minor\");\n\t\treturn ERR_MINOR_INVALID;\n\t}\n\tif (!adm_ctx->resource && (flags & DRBD_ADM_NEED_RESOURCE)) {\n\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"unknown resource\");\n\t\tif (adm_ctx->resource_name)\n\t\t\treturn ERR_RES_NOT_KNOWN;\n\t\treturn ERR_INVALID_REQUEST;\n\t}\n\n\tif (flags & DRBD_ADM_NEED_CONNECTION) {\n\t\tif (adm_ctx->resource) {\n\t\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"no resource name expected\");\n\t\t\treturn ERR_INVALID_REQUEST;\n\t\t}\n\t\tif (adm_ctx->device) {\n\t\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"no minor number expected\");\n\t\t\treturn ERR_INVALID_REQUEST;\n\t\t}\n\t\tif (adm_ctx->my_addr && adm_ctx->peer_addr)\n\t\t\tadm_ctx->connection = conn_get_by_addrs(nla_data(adm_ctx->my_addr),\n\t\t\t\t\t\t\t  nla_len(adm_ctx->my_addr),\n\t\t\t\t\t\t\t  nla_data(adm_ctx->peer_addr),\n\t\t\t\t\t\t\t  nla_len(adm_ctx->peer_addr));\n\t\tif (!adm_ctx->connection) {\n\t\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"unknown connection\");\n\t\t\treturn ERR_INVALID_REQUEST;\n\t\t}\n\t}\n\n\t \n\tif (adm_ctx->device && adm_ctx->resource &&\n\t    adm_ctx->device->resource != adm_ctx->resource) {\n\t\tpr_warn(\"request: minor=%u, resource=%s; but that minor belongs to resource %s\\n\",\n\t\t\tadm_ctx->minor, adm_ctx->resource->name,\n\t\t\tadm_ctx->device->resource->name);\n\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"minor exists in different resource\");\n\t\treturn ERR_INVALID_REQUEST;\n\t}\n\tif (adm_ctx->device &&\n\t    adm_ctx->volume != VOLUME_UNSPECIFIED &&\n\t    adm_ctx->volume != adm_ctx->device->vnr) {\n\t\tpr_warn(\"request: minor=%u, volume=%u; but that minor is volume %u in %s\\n\",\n\t\t\tadm_ctx->minor, adm_ctx->volume,\n\t\t\tadm_ctx->device->vnr, adm_ctx->device->resource->name);\n\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"minor exists as different volume\");\n\t\treturn ERR_INVALID_REQUEST;\n\t}\n\n\t \n\tif (!adm_ctx->resource) {\n\t\tadm_ctx->resource = adm_ctx->device ? adm_ctx->device->resource\n\t\t\t: adm_ctx->connection ? adm_ctx->connection->resource : NULL;\n\t\tif (adm_ctx->resource)\n\t\t\tkref_get(&adm_ctx->resource->kref);\n\t}\n\n\treturn NO_ERROR;\n\nfail:\n\tnlmsg_free(adm_ctx->reply_skb);\n\tadm_ctx->reply_skb = NULL;\n\treturn err;\n}\n\nstatic int drbd_adm_finish(struct drbd_config_context *adm_ctx,\n\tstruct genl_info *info, int retcode)\n{\n\tif (adm_ctx->device) {\n\t\tkref_put(&adm_ctx->device->kref, drbd_destroy_device);\n\t\tadm_ctx->device = NULL;\n\t}\n\tif (adm_ctx->connection) {\n\t\tkref_put(&adm_ctx->connection->kref, &drbd_destroy_connection);\n\t\tadm_ctx->connection = NULL;\n\t}\n\tif (adm_ctx->resource) {\n\t\tkref_put(&adm_ctx->resource->kref, drbd_destroy_resource);\n\t\tadm_ctx->resource = NULL;\n\t}\n\n\tif (!adm_ctx->reply_skb)\n\t\treturn -ENOMEM;\n\n\tadm_ctx->reply_dh->ret_code = retcode;\n\tdrbd_adm_send_reply(adm_ctx->reply_skb, info);\n\treturn 0;\n}\n\nstatic void setup_khelper_env(struct drbd_connection *connection, char **envp)\n{\n\tchar *afs;\n\n\t \n\tif (connection->my_addr_len == 0 || connection->peer_addr_len == 0)\n\t\treturn;\n\n\tswitch (((struct sockaddr *)&connection->peer_addr)->sa_family) {\n\tcase AF_INET6:\n\t\tafs = \"ipv6\";\n\t\tsnprintf(envp[4], 60, \"DRBD_PEER_ADDRESS=%pI6\",\n\t\t\t &((struct sockaddr_in6 *)&connection->peer_addr)->sin6_addr);\n\t\tbreak;\n\tcase AF_INET:\n\t\tafs = \"ipv4\";\n\t\tsnprintf(envp[4], 60, \"DRBD_PEER_ADDRESS=%pI4\",\n\t\t\t &((struct sockaddr_in *)&connection->peer_addr)->sin_addr);\n\t\tbreak;\n\tdefault:\n\t\tafs = \"ssocks\";\n\t\tsnprintf(envp[4], 60, \"DRBD_PEER_ADDRESS=%pI4\",\n\t\t\t &((struct sockaddr_in *)&connection->peer_addr)->sin_addr);\n\t}\n\tsnprintf(envp[3], 20, \"DRBD_PEER_AF=%s\", afs);\n}\n\nint drbd_khelper(struct drbd_device *device, char *cmd)\n{\n\tchar *envp[] = { \"HOME=/\",\n\t\t\t\"TERM=linux\",\n\t\t\t\"PATH=/sbin:/usr/sbin:/bin:/usr/bin\",\n\t\t\t (char[20]) { },  \n\t\t\t (char[60]) { },  \n\t\t\tNULL };\n\tchar mb[14];\n\tchar *argv[] = {drbd_usermode_helper, cmd, mb, NULL };\n\tstruct drbd_connection *connection = first_peer_device(device)->connection;\n\tstruct sib_info sib;\n\tint ret;\n\n\tif (current == connection->worker.task)\n\t\tset_bit(CALLBACK_PENDING, &connection->flags);\n\n\tsnprintf(mb, 14, \"minor-%d\", device_to_minor(device));\n\tsetup_khelper_env(connection, envp);\n\n\t \n\tdrbd_md_sync(device);\n\n\tdrbd_info(device, \"helper command: %s %s %s\\n\", drbd_usermode_helper, cmd, mb);\n\tsib.sib_reason = SIB_HELPER_PRE;\n\tsib.helper_name = cmd;\n\tdrbd_bcast_event(device, &sib);\n\tnotify_helper(NOTIFY_CALL, device, connection, cmd, 0);\n\tret = call_usermodehelper(drbd_usermode_helper, argv, envp, UMH_WAIT_PROC);\n\tif (ret)\n\t\tdrbd_warn(device, \"helper command: %s %s %s exit code %u (0x%x)\\n\",\n\t\t\t\tdrbd_usermode_helper, cmd, mb,\n\t\t\t\t(ret >> 8) & 0xff, ret);\n\telse\n\t\tdrbd_info(device, \"helper command: %s %s %s exit code %u (0x%x)\\n\",\n\t\t\t\tdrbd_usermode_helper, cmd, mb,\n\t\t\t\t(ret >> 8) & 0xff, ret);\n\tsib.sib_reason = SIB_HELPER_POST;\n\tsib.helper_exit_code = ret;\n\tdrbd_bcast_event(device, &sib);\n\tnotify_helper(NOTIFY_RESPONSE, device, connection, cmd, ret);\n\n\tif (current == connection->worker.task)\n\t\tclear_bit(CALLBACK_PENDING, &connection->flags);\n\n\tif (ret < 0)  \n\t\tret = 0;\n\n\treturn ret;\n}\n\nenum drbd_peer_state conn_khelper(struct drbd_connection *connection, char *cmd)\n{\n\tchar *envp[] = { \"HOME=/\",\n\t\t\t\"TERM=linux\",\n\t\t\t\"PATH=/sbin:/usr/sbin:/bin:/usr/bin\",\n\t\t\t (char[20]) { },  \n\t\t\t (char[60]) { },  \n\t\t\tNULL };\n\tchar *resource_name = connection->resource->name;\n\tchar *argv[] = {drbd_usermode_helper, cmd, resource_name, NULL };\n\tint ret;\n\n\tsetup_khelper_env(connection, envp);\n\tconn_md_sync(connection);\n\n\tdrbd_info(connection, \"helper command: %s %s %s\\n\", drbd_usermode_helper, cmd, resource_name);\n\t \n\tnotify_helper(NOTIFY_CALL, NULL, connection, cmd, 0);\n\n\tret = call_usermodehelper(drbd_usermode_helper, argv, envp, UMH_WAIT_PROC);\n\tif (ret)\n\t\tdrbd_warn(connection, \"helper command: %s %s %s exit code %u (0x%x)\\n\",\n\t\t\t  drbd_usermode_helper, cmd, resource_name,\n\t\t\t  (ret >> 8) & 0xff, ret);\n\telse\n\t\tdrbd_info(connection, \"helper command: %s %s %s exit code %u (0x%x)\\n\",\n\t\t\t  drbd_usermode_helper, cmd, resource_name,\n\t\t\t  (ret >> 8) & 0xff, ret);\n\t \n\tnotify_helper(NOTIFY_RESPONSE, NULL, connection, cmd, ret);\n\n\tif (ret < 0)  \n\t\tret = 0;\n\n\treturn ret;\n}\n\nstatic enum drbd_fencing_p highest_fencing_policy(struct drbd_connection *connection)\n{\n\tenum drbd_fencing_p fp = FP_NOT_AVAIL;\n\tstruct drbd_peer_device *peer_device;\n\tint vnr;\n\n\trcu_read_lock();\n\tidr_for_each_entry(&connection->peer_devices, peer_device, vnr) {\n\t\tstruct drbd_device *device = peer_device->device;\n\t\tif (get_ldev_if_state(device, D_CONSISTENT)) {\n\t\t\tstruct disk_conf *disk_conf =\n\t\t\t\trcu_dereference(peer_device->device->ldev->disk_conf);\n\t\t\tfp = max_t(enum drbd_fencing_p, fp, disk_conf->fencing);\n\t\t\tput_ldev(device);\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn fp;\n}\n\nstatic bool resource_is_supended(struct drbd_resource *resource)\n{\n\treturn resource->susp || resource->susp_fen || resource->susp_nod;\n}\n\nbool conn_try_outdate_peer(struct drbd_connection *connection)\n{\n\tstruct drbd_resource * const resource = connection->resource;\n\tunsigned int connect_cnt;\n\tunion drbd_state mask = { };\n\tunion drbd_state val = { };\n\tenum drbd_fencing_p fp;\n\tchar *ex_to_string;\n\tint r;\n\n\tspin_lock_irq(&resource->req_lock);\n\tif (connection->cstate >= C_WF_REPORT_PARAMS) {\n\t\tdrbd_err(connection, \"Expected cstate < C_WF_REPORT_PARAMS\\n\");\n\t\tspin_unlock_irq(&resource->req_lock);\n\t\treturn false;\n\t}\n\n\tconnect_cnt = connection->connect_cnt;\n\tspin_unlock_irq(&resource->req_lock);\n\n\tfp = highest_fencing_policy(connection);\n\tswitch (fp) {\n\tcase FP_NOT_AVAIL:\n\t\tdrbd_warn(connection, \"Not fencing peer, I'm not even Consistent myself.\\n\");\n\t\tspin_lock_irq(&resource->req_lock);\n\t\tif (connection->cstate < C_WF_REPORT_PARAMS) {\n\t\t\t_conn_request_state(connection,\n\t\t\t\t\t    (union drbd_state) { { .susp_fen = 1 } },\n\t\t\t\t\t    (union drbd_state) { { .susp_fen = 0 } },\n\t\t\t\t\t    CS_VERBOSE | CS_HARD | CS_DC_SUSP);\n\t\t\t \n\t\t\tif (!resource_is_supended(resource))\n\t\t\t\t_tl_restart(connection, CONNECTION_LOST_WHILE_PENDING);\n\t\t}\n\t\t \n\t\tspin_unlock_irq(&resource->req_lock);\n\t\treturn false;\n\n\tcase FP_DONT_CARE:\n\t\treturn true;\n\tdefault: ;\n\t}\n\n\tr = conn_khelper(connection, \"fence-peer\");\n\n\tswitch ((r>>8) & 0xff) {\n\tcase P_INCONSISTENT:  \n\t\tex_to_string = \"peer is inconsistent or worse\";\n\t\tmask.pdsk = D_MASK;\n\t\tval.pdsk = D_INCONSISTENT;\n\t\tbreak;\n\tcase P_OUTDATED:  \n\t\tex_to_string = \"peer was fenced\";\n\t\tmask.pdsk = D_MASK;\n\t\tval.pdsk = D_OUTDATED;\n\t\tbreak;\n\tcase P_DOWN:  \n\t\tif (conn_highest_disk(connection) == D_UP_TO_DATE) {\n\t\t\t \n\t\t\tex_to_string = \"peer is unreachable, assumed to be dead\";\n\t\t\tmask.pdsk = D_MASK;\n\t\t\tval.pdsk = D_OUTDATED;\n\t\t} else {\n\t\t\tex_to_string = \"peer unreachable, doing nothing since disk != UpToDate\";\n\t\t}\n\t\tbreak;\n\tcase P_PRIMARY:  \n\t\tex_to_string = \"peer is active\";\n\t\tdrbd_warn(connection, \"Peer is primary, outdating myself.\\n\");\n\t\tmask.disk = D_MASK;\n\t\tval.disk = D_OUTDATED;\n\t\tbreak;\n\tcase P_FENCING:\n\t\t \n\t\tif (fp != FP_STONITH)\n\t\t\tdrbd_err(connection, \"fence-peer() = 7 && fencing != Stonith !!!\\n\");\n\t\tex_to_string = \"peer was stonithed\";\n\t\tmask.pdsk = D_MASK;\n\t\tval.pdsk = D_OUTDATED;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tdrbd_err(connection, \"fence-peer helper broken, returned %d\\n\", (r>>8)&0xff);\n\t\treturn false;  \n\t}\n\n\tdrbd_info(connection, \"fence-peer helper returned %d (%s)\\n\",\n\t\t  (r>>8) & 0xff, ex_to_string);\n\n\t \n\tspin_lock_irq(&resource->req_lock);\n\tif (connection->cstate < C_WF_REPORT_PARAMS && !test_bit(STATE_SENT, &connection->flags)) {\n\t\tif (connection->connect_cnt != connect_cnt)\n\t\t\t \n\t\t\tdrbd_info(connection, \"Ignoring fence-peer exit code\\n\");\n\t\telse\n\t\t\t_conn_request_state(connection, mask, val, CS_VERBOSE);\n\t}\n\tspin_unlock_irq(&resource->req_lock);\n\n\treturn conn_highest_pdsk(connection) <= D_OUTDATED;\n}\n\nstatic int _try_outdate_peer_async(void *data)\n{\n\tstruct drbd_connection *connection = (struct drbd_connection *)data;\n\n\tconn_try_outdate_peer(connection);\n\n\tkref_put(&connection->kref, drbd_destroy_connection);\n\treturn 0;\n}\n\nvoid conn_try_outdate_peer_async(struct drbd_connection *connection)\n{\n\tstruct task_struct *opa;\n\n\tkref_get(&connection->kref);\n\t \n\tflush_signals(current);\n\topa = kthread_run(_try_outdate_peer_async, connection, \"drbd_async_h\");\n\tif (IS_ERR(opa)) {\n\t\tdrbd_err(connection, \"out of mem, failed to invoke fence-peer helper\\n\");\n\t\tkref_put(&connection->kref, drbd_destroy_connection);\n\t}\n}\n\nenum drbd_state_rv\ndrbd_set_role(struct drbd_device *const device, enum drbd_role new_role, int force)\n{\n\tstruct drbd_peer_device *const peer_device = first_peer_device(device);\n\tstruct drbd_connection *const connection = peer_device ? peer_device->connection : NULL;\n\tconst int max_tries = 4;\n\tenum drbd_state_rv rv = SS_UNKNOWN_ERROR;\n\tstruct net_conf *nc;\n\tint try = 0;\n\tint forced = 0;\n\tunion drbd_state mask, val;\n\n\tif (new_role == R_PRIMARY) {\n\t\tstruct drbd_connection *connection;\n\n\t\t \n\n\t\trcu_read_lock();\n\t\tfor_each_connection(connection, device->resource)\n\t\t\trequest_ping(connection);\n\t\trcu_read_unlock();\n\t}\n\n\tmutex_lock(device->state_mutex);\n\n\tmask.i = 0; mask.role = R_MASK;\n\tval.i  = 0; val.role  = new_role;\n\n\twhile (try++ < max_tries) {\n\t\trv = _drbd_request_state_holding_state_mutex(device, mask, val, CS_WAIT_COMPLETE);\n\n\t\t \n\t\tif (rv == SS_CW_FAILED_BY_PEER && mask.pdsk != 0) {\n\t\t\tval.pdsk = 0;\n\t\t\tmask.pdsk = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (rv == SS_NO_UP_TO_DATE_DISK && force &&\n\t\t    (device->state.disk < D_UP_TO_DATE &&\n\t\t     device->state.disk >= D_INCONSISTENT)) {\n\t\t\tmask.disk = D_MASK;\n\t\t\tval.disk  = D_UP_TO_DATE;\n\t\t\tforced = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (rv == SS_NO_UP_TO_DATE_DISK &&\n\t\t    device->state.disk == D_CONSISTENT && mask.pdsk == 0) {\n\t\t\tD_ASSERT(device, device->state.pdsk == D_UNKNOWN);\n\n\t\t\tif (conn_try_outdate_peer(connection)) {\n\t\t\t\tval.disk = D_UP_TO_DATE;\n\t\t\t\tmask.disk = D_MASK;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (rv == SS_NOTHING_TO_DO)\n\t\t\tgoto out;\n\t\tif (rv == SS_PRIMARY_NOP && mask.pdsk == 0) {\n\t\t\tif (!conn_try_outdate_peer(connection) && force) {\n\t\t\t\tdrbd_warn(device, \"Forced into split brain situation!\\n\");\n\t\t\t\tmask.pdsk = D_MASK;\n\t\t\t\tval.pdsk  = D_OUTDATED;\n\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tif (rv == SS_TWO_PRIMARIES) {\n\t\t\t \n\t\t\tif (try < max_tries) {\n\t\t\t\tint timeo;\n\t\t\t\ttry = max_tries - 1;\n\t\t\t\trcu_read_lock();\n\t\t\t\tnc = rcu_dereference(connection->net_conf);\n\t\t\t\ttimeo = nc ? (nc->ping_timeo + 1) * HZ / 10 : 1;\n\t\t\t\trcu_read_unlock();\n\t\t\t\tschedule_timeout_interruptible(timeo);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tif (rv < SS_SUCCESS) {\n\t\t\trv = _drbd_request_state(device, mask, val,\n\t\t\t\t\t\tCS_VERBOSE + CS_WAIT_COMPLETE);\n\t\t\tif (rv < SS_SUCCESS)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (rv < SS_SUCCESS)\n\t\tgoto out;\n\n\tif (forced)\n\t\tdrbd_warn(device, \"Forced to consider local data as UpToDate!\\n\");\n\n\t \n\twait_event(device->misc_wait, atomic_read(&device->ap_pending_cnt) == 0);\n\n\t \n\n\tif (new_role == R_SECONDARY) {\n\t\tif (get_ldev(device)) {\n\t\t\tdevice->ldev->md.uuid[UI_CURRENT] &= ~(u64)1;\n\t\t\tput_ldev(device);\n\t\t}\n\t} else {\n\t\tmutex_lock(&device->resource->conf_update);\n\t\tnc = connection->net_conf;\n\t\tif (nc)\n\t\t\tnc->discard_my_data = 0;  \n\t\tmutex_unlock(&device->resource->conf_update);\n\n\t\tif (get_ldev(device)) {\n\t\t\tif (((device->state.conn < C_CONNECTED ||\n\t\t\t       device->state.pdsk <= D_FAILED)\n\t\t\t      && device->ldev->md.uuid[UI_BITMAP] == 0) || forced)\n\t\t\t\tdrbd_uuid_new_current(device);\n\n\t\t\tdevice->ldev->md.uuid[UI_CURRENT] |=  (u64)1;\n\t\t\tput_ldev(device);\n\t\t}\n\t}\n\n\t \n\n\tif (device->state.conn >= C_WF_REPORT_PARAMS) {\n\t\t \n\t\tif (forced)\n\t\t\tdrbd_send_uuids(peer_device);\n\t\tdrbd_send_current_state(peer_device);\n\t}\n\n\tdrbd_md_sync(device);\n\tset_disk_ro(device->vdisk, new_role == R_SECONDARY);\n\tkobject_uevent(&disk_to_dev(device->vdisk)->kobj, KOBJ_CHANGE);\nout:\n\tmutex_unlock(device->state_mutex);\n\treturn rv;\n}\n\nstatic const char *from_attrs_err_to_txt(int err)\n{\n\treturn\terr == -ENOMSG ? \"required attribute missing\" :\n\t\terr == -EOPNOTSUPP ? \"unknown mandatory attribute\" :\n\t\terr == -EEXIST ? \"can not change invariant setting\" :\n\t\t\"invalid attribute value\";\n}\n\nint drbd_adm_set_role(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct set_role_parms parms;\n\tint err;\n\tenum drbd_ret_code retcode;\n\tenum drbd_state_rv rv;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tmemset(&parms, 0, sizeof(parms));\n\tif (info->attrs[DRBD_NLA_SET_ROLE_PARMS]) {\n\t\terr = set_role_parms_from_attrs(&parms, info);\n\t\tif (err) {\n\t\t\tretcode = ERR_MANDATORY_TAG;\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\t\tgoto out;\n\t\t}\n\t}\n\tgenl_unlock();\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\n\tif (info->genlhdr->cmd == DRBD_ADM_PRIMARY)\n\t\trv = drbd_set_role(adm_ctx.device, R_PRIMARY, parms.assume_uptodate);\n\telse\n\t\trv = drbd_set_role(adm_ctx.device, R_SECONDARY, 0);\n\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n\tgenl_lock();\n\tdrbd_adm_finish(&adm_ctx, info, rv);\n\treturn 0;\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\n \nstatic void drbd_md_set_sector_offsets(struct drbd_device *device,\n\t\t\t\t       struct drbd_backing_dev *bdev)\n{\n\tsector_t md_size_sect = 0;\n\tunsigned int al_size_sect = bdev->md.al_size_4k * 8;\n\n\tbdev->md.md_offset = drbd_md_ss(bdev);\n\n\tswitch (bdev->md.meta_dev_idx) {\n\tdefault:\n\t\t \n\t\tbdev->md.md_size_sect = MD_128MB_SECT;\n\t\tbdev->md.al_offset = MD_4kB_SECT;\n\t\tbdev->md.bm_offset = MD_4kB_SECT + al_size_sect;\n\t\tbreak;\n\tcase DRBD_MD_INDEX_FLEX_EXT:\n\t\t \n\t\tbdev->md.md_size_sect = drbd_get_capacity(bdev->md_bdev);\n\t\tbdev->md.al_offset = MD_4kB_SECT;\n\t\tbdev->md.bm_offset = MD_4kB_SECT + al_size_sect;\n\t\tbreak;\n\tcase DRBD_MD_INDEX_INTERNAL:\n\tcase DRBD_MD_INDEX_FLEX_INT:\n\t\t \n\t\tbdev->md.al_offset = -al_size_sect;\n\t\t \n\t\tmd_size_sect = drbd_get_capacity(bdev->backing_bdev);\n\t\tmd_size_sect = ALIGN(md_size_sect, BM_SECT_PER_EXT);\n\t\tmd_size_sect = BM_SECT_TO_EXT(md_size_sect);\n\t\tmd_size_sect = ALIGN(md_size_sect, 8);\n\n\t\t \n\t\tmd_size_sect += MD_4kB_SECT + al_size_sect;\n\n\t\tbdev->md.md_size_sect = md_size_sect;\n\t\t \n\t\tbdev->md.bm_offset   = -md_size_sect + MD_4kB_SECT;\n\t\tbreak;\n\t}\n}\n\n \nchar *ppsize(char *buf, unsigned long long size)\n{\n\t \n\tstatic char units[] = { 'K', 'M', 'G', 'T', 'P', 'E' };\n\tint base = 0;\n\twhile (size >= 10000 && base < sizeof(units)-1) {\n\t\t \n\t\tsize = (size >> 10) + !!(size & (1<<9));\n\t\tbase++;\n\t}\n\tsprintf(buf, \"%u %cB\", (unsigned)size, units[base]);\n\n\treturn buf;\n}\n\n \n \n \nvoid drbd_suspend_io(struct drbd_device *device)\n{\n\tatomic_inc(&device->suspend_cnt);\n\tif (drbd_suspended(device))\n\t\treturn;\n\twait_event(device->misc_wait, !atomic_read(&device->ap_bio_cnt));\n}\n\nvoid drbd_resume_io(struct drbd_device *device)\n{\n\tif (atomic_dec_and_test(&device->suspend_cnt))\n\t\twake_up(&device->misc_wait);\n}\n\n \nenum determine_dev_size\ndrbd_determine_dev_size(struct drbd_device *device, enum dds_flags flags, struct resize_parms *rs) __must_hold(local)\n{\n\tstruct md_offsets_and_sizes {\n\t\tu64 last_agreed_sect;\n\t\tu64 md_offset;\n\t\ts32 al_offset;\n\t\ts32 bm_offset;\n\t\tu32 md_size_sect;\n\n\t\tu32 al_stripes;\n\t\tu32 al_stripe_size_4k;\n\t} prev;\n\tsector_t u_size, size;\n\tstruct drbd_md *md = &device->ldev->md;\n\tvoid *buffer;\n\n\tint md_moved, la_size_changed;\n\tenum determine_dev_size rv = DS_UNCHANGED;\n\n\t \n\tdrbd_suspend_io(device);\n\tbuffer = drbd_md_get_buffer(device, __func__);  \n\tif (!buffer) {\n\t\tdrbd_resume_io(device);\n\t\treturn DS_ERROR;\n\t}\n\n\t \n\tprev.last_agreed_sect = md->la_size_sect;\n\tprev.md_offset = md->md_offset;\n\tprev.al_offset = md->al_offset;\n\tprev.bm_offset = md->bm_offset;\n\tprev.md_size_sect = md->md_size_sect;\n\tprev.al_stripes = md->al_stripes;\n\tprev.al_stripe_size_4k = md->al_stripe_size_4k;\n\n\tif (rs) {\n\t\t \n\t\tmd->al_stripes = rs->al_stripes;\n\t\tmd->al_stripe_size_4k = rs->al_stripe_size / 4;\n\t\tmd->al_size_4k = (u64)rs->al_stripes * rs->al_stripe_size / 4;\n\t}\n\n\tdrbd_md_set_sector_offsets(device, device->ldev);\n\n\trcu_read_lock();\n\tu_size = rcu_dereference(device->ldev->disk_conf)->disk_size;\n\trcu_read_unlock();\n\tsize = drbd_new_dev_size(device, device->ldev, u_size, flags & DDSF_FORCED);\n\n\tif (size < prev.last_agreed_sect) {\n\t\tif (rs && u_size == 0) {\n\t\t\t \n\t\t\tdrbd_warn(device, \"Implicit shrink not allowed. \"\n\t\t\t\t \"Use --size=%llus for explicit shrink.\\n\",\n\t\t\t\t (unsigned long long)size);\n\t\t\trv = DS_ERROR_SHRINK;\n\t\t}\n\t\tif (u_size > size)\n\t\t\trv = DS_ERROR_SPACE_MD;\n\t\tif (rv != DS_UNCHANGED)\n\t\t\tgoto err_out;\n\t}\n\n\tif (get_capacity(device->vdisk) != size ||\n\t    drbd_bm_capacity(device) != size) {\n\t\tint err;\n\t\terr = drbd_bm_resize(device, size, !(flags & DDSF_NO_RESYNC));\n\t\tif (unlikely(err)) {\n\t\t\t \n\t\t\tsize = drbd_bm_capacity(device);\n\t\t\tif (size == 0) {\n\t\t\t\tdrbd_err(device, \"OUT OF MEMORY! \"\n\t\t\t\t    \"Could not allocate bitmap!\\n\");\n\t\t\t} else {\n\t\t\t\tdrbd_err(device, \"BM resizing failed. \"\n\t\t\t\t    \"Leaving size unchanged\\n\");\n\t\t\t}\n\t\t\trv = DS_ERROR;\n\t\t}\n\t\t \n\t\tdrbd_set_my_capacity(device, size);\n\t\tmd->la_size_sect = size;\n\t}\n\tif (rv <= DS_ERROR)\n\t\tgoto err_out;\n\n\tla_size_changed = (prev.last_agreed_sect != md->la_size_sect);\n\n\tmd_moved = prev.md_offset    != md->md_offset\n\t\t|| prev.md_size_sect != md->md_size_sect;\n\n\tif (la_size_changed || md_moved || rs) {\n\t\tu32 prev_flags;\n\n\t\t \n\t\tdel_timer(&device->md_sync_timer);\n\n\t\t \n\t\twait_event(device->al_wait, lc_try_lock_for_transaction(device->act_log));\n\n\t\t \n\t\tprev_flags = md->flags;\n\t\tmd->flags |= MDF_FULL_SYNC | MDF_AL_DISABLED;\n\t\tdrbd_md_write(device, buffer);\n\n\t\tdrbd_al_initialize(device, buffer);\n\n\t\tdrbd_info(device, \"Writing the whole bitmap, %s\\n\",\n\t\t\t la_size_changed && md_moved ? \"size changed and md moved\" :\n\t\t\t la_size_changed ? \"size changed\" : \"md moved\");\n\t\t \n\t\tdrbd_bitmap_io(device, md_moved ? &drbd_bm_write_all : &drbd_bm_write,\n\t\t\t       \"size changed\", BM_LOCKED_MASK, NULL);\n\n\t\t \n\t\tmd->flags = prev_flags;\n\t\tdrbd_md_write(device, buffer);\n\n\t\tif (rs)\n\t\t\tdrbd_info(device, \"Changed AL layout to al-stripes = %d, al-stripe-size-kB = %d\\n\",\n\t\t\t\t  md->al_stripes, md->al_stripe_size_4k * 4);\n\t}\n\n\tif (size > prev.last_agreed_sect)\n\t\trv = prev.last_agreed_sect ? DS_GREW : DS_GREW_FROM_ZERO;\n\tif (size < prev.last_agreed_sect)\n\t\trv = DS_SHRUNK;\n\n\tif (0) {\n\terr_out:\n\t\t \n\t\tmd->la_size_sect = prev.last_agreed_sect;\n\t\tmd->md_offset = prev.md_offset;\n\t\tmd->al_offset = prev.al_offset;\n\t\tmd->bm_offset = prev.bm_offset;\n\t\tmd->md_size_sect = prev.md_size_sect;\n\t\tmd->al_stripes = prev.al_stripes;\n\t\tmd->al_stripe_size_4k = prev.al_stripe_size_4k;\n\t\tmd->al_size_4k = (u64)prev.al_stripes * prev.al_stripe_size_4k;\n\t}\n\tlc_unlock(device->act_log);\n\twake_up(&device->al_wait);\n\tdrbd_md_put_buffer(device);\n\tdrbd_resume_io(device);\n\n\treturn rv;\n}\n\nsector_t\ndrbd_new_dev_size(struct drbd_device *device, struct drbd_backing_dev *bdev,\n\t\t  sector_t u_size, int assume_peer_has_space)\n{\n\tsector_t p_size = device->p_size;    \n\tsector_t la_size_sect = bdev->md.la_size_sect;  \n\tsector_t m_size;  \n\tsector_t size = 0;\n\n\tm_size = drbd_get_max_capacity(bdev);\n\n\tif (device->state.conn < C_CONNECTED && assume_peer_has_space) {\n\t\tdrbd_warn(device, \"Resize while not connected was forced by the user!\\n\");\n\t\tp_size = m_size;\n\t}\n\n\tif (p_size && m_size) {\n\t\tsize = min_t(sector_t, p_size, m_size);\n\t} else {\n\t\tif (la_size_sect) {\n\t\t\tsize = la_size_sect;\n\t\t\tif (m_size && m_size < size)\n\t\t\t\tsize = m_size;\n\t\t\tif (p_size && p_size < size)\n\t\t\t\tsize = p_size;\n\t\t} else {\n\t\t\tif (m_size)\n\t\t\t\tsize = m_size;\n\t\t\tif (p_size)\n\t\t\t\tsize = p_size;\n\t\t}\n\t}\n\n\tif (size == 0)\n\t\tdrbd_err(device, \"Both nodes diskless!\\n\");\n\n\tif (u_size) {\n\t\tif (u_size > size)\n\t\t\tdrbd_err(device, \"Requested disk size is too big (%lu > %lu)\\n\",\n\t\t\t    (unsigned long)u_size>>1, (unsigned long)size>>1);\n\t\telse\n\t\t\tsize = u_size;\n\t}\n\n\treturn size;\n}\n\n \nstatic int drbd_check_al_size(struct drbd_device *device, struct disk_conf *dc)\n{\n\tstruct lru_cache *n, *t;\n\tstruct lc_element *e;\n\tunsigned int in_use;\n\tint i;\n\n\tif (device->act_log &&\n\t    device->act_log->nr_elements == dc->al_extents)\n\t\treturn 0;\n\n\tin_use = 0;\n\tt = device->act_log;\n\tn = lc_create(\"act_log\", drbd_al_ext_cache, AL_UPDATES_PER_TRANSACTION,\n\t\tdc->al_extents, sizeof(struct lc_element), 0);\n\n\tif (n == NULL) {\n\t\tdrbd_err(device, \"Cannot allocate act_log lru!\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tspin_lock_irq(&device->al_lock);\n\tif (t) {\n\t\tfor (i = 0; i < t->nr_elements; i++) {\n\t\t\te = lc_element_by_index(t, i);\n\t\t\tif (e->refcnt)\n\t\t\t\tdrbd_err(device, \"refcnt(%d)==%d\\n\",\n\t\t\t\t    e->lc_number, e->refcnt);\n\t\t\tin_use += e->refcnt;\n\t\t}\n\t}\n\tif (!in_use)\n\t\tdevice->act_log = n;\n\tspin_unlock_irq(&device->al_lock);\n\tif (in_use) {\n\t\tdrbd_err(device, \"Activity log still in use!\\n\");\n\t\tlc_destroy(n);\n\t\treturn -EBUSY;\n\t} else {\n\t\tlc_destroy(t);\n\t}\n\tdrbd_md_mark_dirty(device);  \n\treturn 0;\n}\n\nstatic void blk_queue_discard_granularity(struct request_queue *q, unsigned int granularity)\n{\n\tq->limits.discard_granularity = granularity;\n}\n\nstatic unsigned int drbd_max_discard_sectors(struct drbd_connection *connection)\n{\n\t \n\tif (connection->agreed_features & DRBD_FF_WSAME)\n\t\treturn DRBD_MAX_BBIO_SECTORS;\n\t \n\treturn AL_EXTENT_SIZE >> 9;\n}\n\nstatic void decide_on_discard_support(struct drbd_device *device,\n\t\tstruct drbd_backing_dev *bdev)\n{\n\tstruct drbd_connection *connection =\n\t\tfirst_peer_device(device)->connection;\n\tstruct request_queue *q = device->rq_queue;\n\tunsigned int max_discard_sectors;\n\n\tif (bdev && !bdev_max_discard_sectors(bdev->backing_bdev))\n\t\tgoto not_supported;\n\n\tif (connection->cstate >= C_CONNECTED &&\n\t    !(connection->agreed_features & DRBD_FF_TRIM)) {\n\t\tdrbd_info(connection,\n\t\t\t\"peer DRBD too old, does not support TRIM: disabling discards\\n\");\n\t\tgoto not_supported;\n\t}\n\n\t \n\tblk_queue_discard_granularity(q, 512);\n\tmax_discard_sectors = drbd_max_discard_sectors(connection);\n\tblk_queue_max_discard_sectors(q, max_discard_sectors);\n\tblk_queue_max_write_zeroes_sectors(q, max_discard_sectors);\n\treturn;\n\nnot_supported:\n\tblk_queue_discard_granularity(q, 0);\n\tblk_queue_max_discard_sectors(q, 0);\n}\n\nstatic void fixup_write_zeroes(struct drbd_device *device, struct request_queue *q)\n{\n\t \n\tstruct drbd_connection *connection = first_peer_device(device)->connection;\n\t \n\tif (connection->agreed_features & DRBD_FF_WZEROES)\n\t\tq->limits.max_write_zeroes_sectors = DRBD_MAX_BBIO_SECTORS;\n\telse\n\t\tq->limits.max_write_zeroes_sectors = 0;\n}\n\nstatic void fixup_discard_support(struct drbd_device *device, struct request_queue *q)\n{\n\tunsigned int max_discard = device->rq_queue->limits.max_discard_sectors;\n\tunsigned int discard_granularity =\n\t\tdevice->rq_queue->limits.discard_granularity >> SECTOR_SHIFT;\n\n\tif (discard_granularity > max_discard) {\n\t\tblk_queue_discard_granularity(q, 0);\n\t\tblk_queue_max_discard_sectors(q, 0);\n\t}\n}\n\nstatic void drbd_setup_queue_param(struct drbd_device *device, struct drbd_backing_dev *bdev,\n\t\t\t\t   unsigned int max_bio_size, struct o_qlim *o)\n{\n\tstruct request_queue * const q = device->rq_queue;\n\tunsigned int max_hw_sectors = max_bio_size >> 9;\n\tunsigned int max_segments = 0;\n\tstruct request_queue *b = NULL;\n\tstruct disk_conf *dc;\n\n\tif (bdev) {\n\t\tb = bdev->backing_bdev->bd_disk->queue;\n\n\t\tmax_hw_sectors = min(queue_max_hw_sectors(b), max_bio_size >> 9);\n\t\trcu_read_lock();\n\t\tdc = rcu_dereference(device->ldev->disk_conf);\n\t\tmax_segments = dc->max_bio_bvecs;\n\t\trcu_read_unlock();\n\n\t\tblk_set_stacking_limits(&q->limits);\n\t}\n\n\tblk_queue_max_hw_sectors(q, max_hw_sectors);\n\t \n\tblk_queue_max_segments(q, max_segments ? max_segments : BLK_MAX_SEGMENTS);\n\tblk_queue_segment_boundary(q, PAGE_SIZE-1);\n\tdecide_on_discard_support(device, bdev);\n\n\tif (b) {\n\t\tblk_stack_limits(&q->limits, &b->limits, 0);\n\t\tdisk_update_readahead(device->vdisk);\n\t}\n\tfixup_write_zeroes(device, q);\n\tfixup_discard_support(device, q);\n}\n\nvoid drbd_reconsider_queue_parameters(struct drbd_device *device, struct drbd_backing_dev *bdev, struct o_qlim *o)\n{\n\tunsigned int now, new, local, peer;\n\n\tnow = queue_max_hw_sectors(device->rq_queue) << 9;\n\tlocal = device->local_max_bio_size;  \n\tpeer = device->peer_max_bio_size;  \n\n\tif (bdev) {\n\t\tlocal = queue_max_hw_sectors(bdev->backing_bdev->bd_disk->queue) << 9;\n\t\tdevice->local_max_bio_size = local;\n\t}\n\tlocal = min(local, DRBD_MAX_BIO_SIZE);\n\n\t \n\tif (device->state.conn >= C_WF_REPORT_PARAMS) {\n\t\tif (first_peer_device(device)->connection->agreed_pro_version < 94)\n\t\t\tpeer = min(device->peer_max_bio_size, DRBD_MAX_SIZE_H80_PACKET);\n\t\t\t \n\t\telse if (first_peer_device(device)->connection->agreed_pro_version == 94)\n\t\t\tpeer = DRBD_MAX_SIZE_H80_PACKET;\n\t\telse if (first_peer_device(device)->connection->agreed_pro_version < 100)\n\t\t\tpeer = DRBD_MAX_BIO_SIZE_P95;   \n\t\telse\n\t\t\tpeer = DRBD_MAX_BIO_SIZE;\n\n\t\t \n\t\tif (peer > device->peer_max_bio_size)\n\t\t\tdevice->peer_max_bio_size = peer;\n\t}\n\tnew = min(local, peer);\n\n\tif (device->state.role == R_PRIMARY && new < now)\n\t\tdrbd_err(device, \"ASSERT FAILED new < now; (%u < %u)\\n\", new, now);\n\n\tif (new != now)\n\t\tdrbd_info(device, \"max BIO size = %u\\n\", new);\n\n\tdrbd_setup_queue_param(device, bdev, new, o);\n}\n\n \nstatic void conn_reconfig_start(struct drbd_connection *connection)\n{\n\tdrbd_thread_start(&connection->worker);\n\tdrbd_flush_workqueue(&connection->sender_work);\n}\n\n \nstatic void conn_reconfig_done(struct drbd_connection *connection)\n{\n\tbool stop_threads;\n\tspin_lock_irq(&connection->resource->req_lock);\n\tstop_threads = conn_all_vols_unconf(connection) &&\n\t\tconnection->cstate == C_STANDALONE;\n\tspin_unlock_irq(&connection->resource->req_lock);\n\tif (stop_threads) {\n\t\t \n\t\tdrbd_thread_stop(&connection->receiver);\n\t\tdrbd_thread_stop(&connection->worker);\n\t}\n}\n\n \nstatic void drbd_suspend_al(struct drbd_device *device)\n{\n\tint s = 0;\n\n\tif (!lc_try_lock(device->act_log)) {\n\t\tdrbd_warn(device, \"Failed to lock al in drbd_suspend_al()\\n\");\n\t\treturn;\n\t}\n\n\tdrbd_al_shrink(device);\n\tspin_lock_irq(&device->resource->req_lock);\n\tif (device->state.conn < C_CONNECTED)\n\t\ts = !test_and_set_bit(AL_SUSPENDED, &device->flags);\n\tspin_unlock_irq(&device->resource->req_lock);\n\tlc_unlock(device->act_log);\n\n\tif (s)\n\t\tdrbd_info(device, \"Suspended AL updates\\n\");\n}\n\n\nstatic bool should_set_defaults(struct genl_info *info)\n{\n\tstruct drbd_genlmsghdr *dh = genl_info_userhdr(info);\n\n\treturn 0 != (dh->flags & DRBD_GENL_F_SET_DEFAULTS);\n}\n\nstatic unsigned int drbd_al_extents_max(struct drbd_backing_dev *bdev)\n{\n\t \n\tconst unsigned int max_al_nr = DRBD_AL_EXTENTS_MAX;\n\tconst unsigned int sufficient_on_disk =\n\t\t(max_al_nr + AL_CONTEXT_PER_TRANSACTION -1)\n\t\t/AL_CONTEXT_PER_TRANSACTION;\n\n\tunsigned int al_size_4k = bdev->md.al_size_4k;\n\n\tif (al_size_4k > sufficient_on_disk)\n\t\treturn max_al_nr;\n\n\treturn (al_size_4k - 1) * AL_CONTEXT_PER_TRANSACTION;\n}\n\nstatic bool write_ordering_changed(struct disk_conf *a, struct disk_conf *b)\n{\n\treturn\ta->disk_barrier != b->disk_barrier ||\n\t\ta->disk_flushes != b->disk_flushes ||\n\t\ta->disk_drain != b->disk_drain;\n}\n\nstatic void sanitize_disk_conf(struct drbd_device *device, struct disk_conf *disk_conf,\n\t\t\t       struct drbd_backing_dev *nbc)\n{\n\tstruct block_device *bdev = nbc->backing_bdev;\n\n\tif (disk_conf->al_extents < DRBD_AL_EXTENTS_MIN)\n\t\tdisk_conf->al_extents = DRBD_AL_EXTENTS_MIN;\n\tif (disk_conf->al_extents > drbd_al_extents_max(nbc))\n\t\tdisk_conf->al_extents = drbd_al_extents_max(nbc);\n\n\tif (!bdev_max_discard_sectors(bdev)) {\n\t\tif (disk_conf->rs_discard_granularity) {\n\t\t\tdisk_conf->rs_discard_granularity = 0;  \n\t\t\tdrbd_info(device, \"rs_discard_granularity feature disabled\\n\");\n\t\t}\n\t}\n\n\tif (disk_conf->rs_discard_granularity) {\n\t\tint orig_value = disk_conf->rs_discard_granularity;\n\t\tsector_t discard_size = bdev_max_discard_sectors(bdev) << 9;\n\t\tunsigned int discard_granularity = bdev_discard_granularity(bdev);\n\t\tint remainder;\n\n\t\tif (discard_granularity > disk_conf->rs_discard_granularity)\n\t\t\tdisk_conf->rs_discard_granularity = discard_granularity;\n\n\t\tremainder = disk_conf->rs_discard_granularity %\n\t\t\t\tdiscard_granularity;\n\t\tdisk_conf->rs_discard_granularity += remainder;\n\n\t\tif (disk_conf->rs_discard_granularity > discard_size)\n\t\t\tdisk_conf->rs_discard_granularity = discard_size;\n\n\t\tif (disk_conf->rs_discard_granularity != orig_value)\n\t\t\tdrbd_info(device, \"rs_discard_granularity changed to %d\\n\",\n\t\t\t\t  disk_conf->rs_discard_granularity);\n\t}\n}\n\nstatic int disk_opts_check_al_size(struct drbd_device *device, struct disk_conf *dc)\n{\n\tint err = -EBUSY;\n\n\tif (device->act_log &&\n\t    device->act_log->nr_elements == dc->al_extents)\n\t\treturn 0;\n\n\tdrbd_suspend_io(device);\n\t \n\tif (atomic_read(&device->ap_bio_cnt))\n\t\tgoto out;\n\n\twait_event(device->al_wait, lc_try_lock(device->act_log));\n\tdrbd_al_shrink(device);\n\terr = drbd_check_al_size(device, dc);\n\tlc_unlock(device->act_log);\n\twake_up(&device->al_wait);\nout:\n\tdrbd_resume_io(device);\n\treturn err;\n}\n\nint drbd_adm_disk_opts(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\tstruct drbd_device *device;\n\tstruct disk_conf *new_disk_conf, *old_disk_conf;\n\tstruct fifo_buffer *old_plan = NULL, *new_plan = NULL;\n\tint err;\n\tunsigned int fifo_size;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto finish;\n\n\tdevice = adm_ctx.device;\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\n\t \n\tif (!get_ldev(device)) {\n\t\tretcode = ERR_NO_DISK;\n\t\tgoto out;\n\t}\n\n\tnew_disk_conf = kmalloc(sizeof(struct disk_conf), GFP_KERNEL);\n\tif (!new_disk_conf) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto fail;\n\t}\n\n\tmutex_lock(&device->resource->conf_update);\n\told_disk_conf = device->ldev->disk_conf;\n\t*new_disk_conf = *old_disk_conf;\n\tif (should_set_defaults(info))\n\t\tset_disk_conf_defaults(new_disk_conf);\n\n\terr = disk_conf_from_attrs_for_change(new_disk_conf, info);\n\tif (err && err != -ENOMSG) {\n\t\tretcode = ERR_MANDATORY_TAG;\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\tgoto fail_unlock;\n\t}\n\n\tif (!expect(device, new_disk_conf->resync_rate >= 1))\n\t\tnew_disk_conf->resync_rate = 1;\n\n\tsanitize_disk_conf(device, new_disk_conf, device->ldev);\n\n\tif (new_disk_conf->c_plan_ahead > DRBD_C_PLAN_AHEAD_MAX)\n\t\tnew_disk_conf->c_plan_ahead = DRBD_C_PLAN_AHEAD_MAX;\n\n\tfifo_size = (new_disk_conf->c_plan_ahead * 10 * SLEEP_TIME) / HZ;\n\tif (fifo_size != device->rs_plan_s->size) {\n\t\tnew_plan = fifo_alloc(fifo_size);\n\t\tif (!new_plan) {\n\t\t\tdrbd_err(device, \"kmalloc of fifo_buffer failed\");\n\t\t\tretcode = ERR_NOMEM;\n\t\t\tgoto fail_unlock;\n\t\t}\n\t}\n\n\terr = disk_opts_check_al_size(device, new_disk_conf);\n\tif (err) {\n\t\t \n\t\tdrbd_msg_put_info(adm_ctx.reply_skb,\n\t\t\t\"Try again without changing current al-extents setting\");\n\t\tretcode = ERR_NOMEM;\n\t\tgoto fail_unlock;\n\t}\n\n\tlock_all_resources();\n\tretcode = drbd_resync_after_valid(device, new_disk_conf->resync_after);\n\tif (retcode == NO_ERROR) {\n\t\trcu_assign_pointer(device->ldev->disk_conf, new_disk_conf);\n\t\tdrbd_resync_after_changed(device);\n\t}\n\tunlock_all_resources();\n\n\tif (retcode != NO_ERROR)\n\t\tgoto fail_unlock;\n\n\tif (new_plan) {\n\t\told_plan = device->rs_plan_s;\n\t\trcu_assign_pointer(device->rs_plan_s, new_plan);\n\t}\n\n\tmutex_unlock(&device->resource->conf_update);\n\n\tif (new_disk_conf->al_updates)\n\t\tdevice->ldev->md.flags &= ~MDF_AL_DISABLED;\n\telse\n\t\tdevice->ldev->md.flags |= MDF_AL_DISABLED;\n\n\tif (new_disk_conf->md_flushes)\n\t\tclear_bit(MD_NO_FUA, &device->flags);\n\telse\n\t\tset_bit(MD_NO_FUA, &device->flags);\n\n\tif (write_ordering_changed(old_disk_conf, new_disk_conf))\n\t\tdrbd_bump_write_ordering(device->resource, NULL, WO_BDEV_FLUSH);\n\n\tif (old_disk_conf->discard_zeroes_if_aligned !=\n\t    new_disk_conf->discard_zeroes_if_aligned)\n\t\tdrbd_reconsider_queue_parameters(device, device->ldev, NULL);\n\n\tdrbd_md_sync(device);\n\n\tif (device->state.conn >= C_CONNECTED) {\n\t\tstruct drbd_peer_device *peer_device;\n\n\t\tfor_each_peer_device(peer_device, device)\n\t\t\tdrbd_send_sync_param(peer_device);\n\t}\n\n\tkvfree_rcu_mightsleep(old_disk_conf);\n\tkfree(old_plan);\n\tmod_timer(&device->request_timer, jiffies + HZ);\n\tgoto success;\n\nfail_unlock:\n\tmutex_unlock(&device->resource->conf_update);\n fail:\n\tkfree(new_disk_conf);\n\tkfree(new_plan);\nsuccess:\n\tput_ldev(device);\n out:\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n finish:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic struct block_device *open_backing_dev(struct drbd_device *device,\n\t\tconst char *bdev_path, void *claim_ptr, bool do_bd_link)\n{\n\tstruct block_device *bdev;\n\tint err = 0;\n\n\tbdev = blkdev_get_by_path(bdev_path, BLK_OPEN_READ | BLK_OPEN_WRITE,\n\t\t\t\t  claim_ptr, NULL);\n\tif (IS_ERR(bdev)) {\n\t\tdrbd_err(device, \"open(\\\"%s\\\") failed with %ld\\n\",\n\t\t\t\tbdev_path, PTR_ERR(bdev));\n\t\treturn bdev;\n\t}\n\n\tif (!do_bd_link)\n\t\treturn bdev;\n\n\terr = bd_link_disk_holder(bdev, device->vdisk);\n\tif (err) {\n\t\tblkdev_put(bdev, claim_ptr);\n\t\tdrbd_err(device, \"bd_link_disk_holder(\\\"%s\\\", ...) failed with %d\\n\",\n\t\t\t\tbdev_path, err);\n\t\tbdev = ERR_PTR(err);\n\t}\n\treturn bdev;\n}\n\nstatic int open_backing_devices(struct drbd_device *device,\n\t\tstruct disk_conf *new_disk_conf,\n\t\tstruct drbd_backing_dev *nbc)\n{\n\tstruct block_device *bdev;\n\n\tbdev = open_backing_dev(device, new_disk_conf->backing_dev, device, true);\n\tif (IS_ERR(bdev))\n\t\treturn ERR_OPEN_DISK;\n\tnbc->backing_bdev = bdev;\n\n\t \n\tbdev = open_backing_dev(device, new_disk_conf->meta_dev,\n\t\t \n\t\t\t(new_disk_conf->meta_dev_idx < 0) ? (void*)device : (void*)drbd_m_holder,\n\t\t \n\t\t\t(new_disk_conf->meta_dev_idx != DRBD_MD_INDEX_FLEX_INT &&\n\t\t\t new_disk_conf->meta_dev_idx != DRBD_MD_INDEX_INTERNAL));\n\tif (IS_ERR(bdev))\n\t\treturn ERR_OPEN_MD_DISK;\n\tnbc->md_bdev = bdev;\n\treturn NO_ERROR;\n}\n\nstatic void close_backing_dev(struct drbd_device *device, struct block_device *bdev,\n\t\tvoid *claim_ptr, bool do_bd_unlink)\n{\n\tif (!bdev)\n\t\treturn;\n\tif (do_bd_unlink)\n\t\tbd_unlink_disk_holder(bdev, device->vdisk);\n\tblkdev_put(bdev, claim_ptr);\n}\n\nvoid drbd_backing_dev_free(struct drbd_device *device, struct drbd_backing_dev *ldev)\n{\n\tif (ldev == NULL)\n\t\treturn;\n\n\tclose_backing_dev(device, ldev->md_bdev,\n\t\t\t  ldev->md.meta_dev_idx < 0 ?\n\t\t\t\t(void *)device : (void *)drbd_m_holder,\n\t\t\t  ldev->md_bdev != ldev->backing_bdev);\n\tclose_backing_dev(device, ldev->backing_bdev, device, true);\n\n\tkfree(ldev->disk_conf);\n\tkfree(ldev);\n}\n\nint drbd_adm_attach(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_device *device;\n\tstruct drbd_peer_device *peer_device;\n\tstruct drbd_connection *connection;\n\tint err;\n\tenum drbd_ret_code retcode;\n\tenum determine_dev_size dd;\n\tsector_t max_possible_sectors;\n\tsector_t min_md_device_sectors;\n\tstruct drbd_backing_dev *nbc = NULL;  \n\tstruct disk_conf *new_disk_conf = NULL;\n\tstruct lru_cache *resync_lru = NULL;\n\tstruct fifo_buffer *new_plan = NULL;\n\tunion drbd_state ns, os;\n\tenum drbd_state_rv rv;\n\tstruct net_conf *nc;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto finish;\n\n\tdevice = adm_ctx.device;\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tpeer_device = first_peer_device(device);\n\tconnection = peer_device->connection;\n\tconn_reconfig_start(connection);\n\n\t \n\tif (device->state.disk > D_DISKLESS) {\n\t\tretcode = ERR_DISK_CONFIGURED;\n\t\tgoto fail;\n\t}\n\t \n\twait_event(device->misc_wait, !test_bit(GOING_DISKLESS, &device->flags));\n\n\t \n\tclear_bit(FORCE_DETACH, &device->flags);\n\tclear_bit(WAS_IO_ERROR, &device->flags);\n\tclear_bit(WAS_READ_ERROR, &device->flags);\n\n\t \n\tdevice->rs_total = 0;\n\tdevice->rs_failed = 0;\n\tatomic_set(&device->rs_pending_cnt, 0);\n\n\t \n\tnbc = kzalloc(sizeof(struct drbd_backing_dev), GFP_KERNEL);\n\tif (!nbc) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto fail;\n\t}\n\tspin_lock_init(&nbc->md.uuid_lock);\n\n\tnew_disk_conf = kzalloc(sizeof(struct disk_conf), GFP_KERNEL);\n\tif (!new_disk_conf) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto fail;\n\t}\n\tnbc->disk_conf = new_disk_conf;\n\n\tset_disk_conf_defaults(new_disk_conf);\n\terr = disk_conf_from_attrs(new_disk_conf, info);\n\tif (err) {\n\t\tretcode = ERR_MANDATORY_TAG;\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\tgoto fail;\n\t}\n\n\tif (new_disk_conf->c_plan_ahead > DRBD_C_PLAN_AHEAD_MAX)\n\t\tnew_disk_conf->c_plan_ahead = DRBD_C_PLAN_AHEAD_MAX;\n\n\tnew_plan = fifo_alloc((new_disk_conf->c_plan_ahead * 10 * SLEEP_TIME) / HZ);\n\tif (!new_plan) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto fail;\n\t}\n\n\tif (new_disk_conf->meta_dev_idx < DRBD_MD_INDEX_FLEX_INT) {\n\t\tretcode = ERR_MD_IDX_INVALID;\n\t\tgoto fail;\n\t}\n\n\trcu_read_lock();\n\tnc = rcu_dereference(connection->net_conf);\n\tif (nc) {\n\t\tif (new_disk_conf->fencing == FP_STONITH && nc->wire_protocol == DRBD_PROT_A) {\n\t\t\trcu_read_unlock();\n\t\t\tretcode = ERR_STONITH_AND_PROT_A;\n\t\t\tgoto fail;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tretcode = open_backing_devices(device, new_disk_conf, nbc);\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\tif ((nbc->backing_bdev == nbc->md_bdev) !=\n\t    (new_disk_conf->meta_dev_idx == DRBD_MD_INDEX_INTERNAL ||\n\t     new_disk_conf->meta_dev_idx == DRBD_MD_INDEX_FLEX_INT)) {\n\t\tretcode = ERR_MD_IDX_INVALID;\n\t\tgoto fail;\n\t}\n\n\tresync_lru = lc_create(\"resync\", drbd_bm_ext_cache,\n\t\t\t1, 61, sizeof(struct bm_extent),\n\t\t\toffsetof(struct bm_extent, lce));\n\tif (!resync_lru) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto fail;\n\t}\n\n\t \n\tretcode = drbd_md_read(device, nbc);\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\tsanitize_disk_conf(device, new_disk_conf, nbc);\n\n\tif (drbd_get_max_capacity(nbc) < new_disk_conf->disk_size) {\n\t\tdrbd_err(device, \"max capacity %llu smaller than disk size %llu\\n\",\n\t\t\t(unsigned long long) drbd_get_max_capacity(nbc),\n\t\t\t(unsigned long long) new_disk_conf->disk_size);\n\t\tretcode = ERR_DISK_TOO_SMALL;\n\t\tgoto fail;\n\t}\n\n\tif (new_disk_conf->meta_dev_idx < 0) {\n\t\tmax_possible_sectors = DRBD_MAX_SECTORS_FLEX;\n\t\t \n\t\tmin_md_device_sectors = (2<<10);\n\t} else {\n\t\tmax_possible_sectors = DRBD_MAX_SECTORS;\n\t\tmin_md_device_sectors = MD_128MB_SECT * (new_disk_conf->meta_dev_idx + 1);\n\t}\n\n\tif (drbd_get_capacity(nbc->md_bdev) < min_md_device_sectors) {\n\t\tretcode = ERR_MD_DISK_TOO_SMALL;\n\t\tdrbd_warn(device, \"refusing attach: md-device too small, \"\n\t\t     \"at least %llu sectors needed for this meta-disk type\\n\",\n\t\t     (unsigned long long) min_md_device_sectors);\n\t\tgoto fail;\n\t}\n\n\t \n\tif (drbd_get_max_capacity(nbc) < get_capacity(device->vdisk)) {\n\t\tretcode = ERR_DISK_TOO_SMALL;\n\t\tgoto fail;\n\t}\n\n\tnbc->known_size = drbd_get_capacity(nbc->backing_bdev);\n\n\tif (nbc->known_size > max_possible_sectors) {\n\t\tdrbd_warn(device, \"==> truncating very big lower level device \"\n\t\t\t\"to currently maximum possible %llu sectors <==\\n\",\n\t\t\t(unsigned long long) max_possible_sectors);\n\t\tif (new_disk_conf->meta_dev_idx >= 0)\n\t\t\tdrbd_warn(device, \"==>> using internal or flexible \"\n\t\t\t\t      \"meta data may help <<==\\n\");\n\t}\n\n\tdrbd_suspend_io(device);\n\t \n\t \n\twait_event(device->misc_wait, !atomic_read(&device->ap_pending_cnt) || drbd_suspended(device));\n\t \n\tdrbd_flush_workqueue(&connection->sender_work);\n\n\trv = _drbd_request_state(device, NS(disk, D_ATTACHING), CS_VERBOSE);\n\tretcode = (enum drbd_ret_code)rv;\n\tdrbd_resume_io(device);\n\tif (rv < SS_SUCCESS)\n\t\tgoto fail;\n\n\tif (!get_ldev_if_state(device, D_ATTACHING))\n\t\tgoto force_diskless;\n\n\tif (!device->bitmap) {\n\t\tif (drbd_bm_init(device)) {\n\t\t\tretcode = ERR_NOMEM;\n\t\t\tgoto force_diskless_dec;\n\t\t}\n\t}\n\n\tif (device->state.pdsk != D_UP_TO_DATE && device->ed_uuid &&\n\t    (device->state.role == R_PRIMARY || device->state.peer == R_PRIMARY) &&\n            (device->ed_uuid & ~((u64)1)) != (nbc->md.uuid[UI_CURRENT] & ~((u64)1))) {\n\t\tdrbd_err(device, \"Can only attach to data with current UUID=%016llX\\n\",\n\t\t    (unsigned long long)device->ed_uuid);\n\t\tretcode = ERR_DATA_NOT_CURRENT;\n\t\tgoto force_diskless_dec;\n\t}\n\n\t \n\tif (drbd_check_al_size(device, new_disk_conf)) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto force_diskless_dec;\n\t}\n\n\t \n\t{\n\tunsigned long long nsz = drbd_new_dev_size(device, nbc, nbc->disk_conf->disk_size, 0);\n\tunsigned long long eff = nbc->md.la_size_sect;\n\tif (drbd_md_test_flag(nbc, MDF_CONSISTENT) && nsz < eff) {\n\t\tif (nsz == nbc->disk_conf->disk_size) {\n\t\t\tdrbd_warn(device, \"truncating a consistent device during attach (%llu < %llu)\\n\", nsz, eff);\n\t\t} else {\n\t\t\tdrbd_warn(device, \"refusing to truncate a consistent device (%llu < %llu)\\n\", nsz, eff);\n\t\t\tdrbd_msg_sprintf_info(adm_ctx.reply_skb,\n\t\t\t\t\"To-be-attached device has last effective > current size, and is consistent\\n\"\n\t\t\t\t\"(%llu > %llu sectors). Refusing to attach.\", eff, nsz);\n\t\t\tretcode = ERR_IMPLICIT_SHRINK;\n\t\t\tgoto force_diskless_dec;\n\t\t}\n\t}\n\t}\n\n\tlock_all_resources();\n\tretcode = drbd_resync_after_valid(device, new_disk_conf->resync_after);\n\tif (retcode != NO_ERROR) {\n\t\tunlock_all_resources();\n\t\tgoto force_diskless_dec;\n\t}\n\n\t \n\tif (new_disk_conf->md_flushes)\n\t\tclear_bit(MD_NO_FUA, &device->flags);\n\telse\n\t\tset_bit(MD_NO_FUA, &device->flags);\n\n\t \n\tD_ASSERT(device, device->ldev == NULL);\n\tdevice->ldev = nbc;\n\tdevice->resync = resync_lru;\n\tdevice->rs_plan_s = new_plan;\n\tnbc = NULL;\n\tresync_lru = NULL;\n\tnew_disk_conf = NULL;\n\tnew_plan = NULL;\n\n\tdrbd_resync_after_changed(device);\n\tdrbd_bump_write_ordering(device->resource, device->ldev, WO_BDEV_FLUSH);\n\tunlock_all_resources();\n\n\tif (drbd_md_test_flag(device->ldev, MDF_CRASHED_PRIMARY))\n\t\tset_bit(CRASHED_PRIMARY, &device->flags);\n\telse\n\t\tclear_bit(CRASHED_PRIMARY, &device->flags);\n\n\tif (drbd_md_test_flag(device->ldev, MDF_PRIMARY_IND) &&\n\t    !(device->state.role == R_PRIMARY && device->resource->susp_nod))\n\t\tset_bit(CRASHED_PRIMARY, &device->flags);\n\n\tdevice->send_cnt = 0;\n\tdevice->recv_cnt = 0;\n\tdevice->read_cnt = 0;\n\tdevice->writ_cnt = 0;\n\n\tdrbd_reconsider_queue_parameters(device, device->ldev, NULL);\n\n\t \n\tclear_bit(USE_DEGR_WFC_T, &device->flags);\n\tif (device->state.role != R_PRIMARY &&\n\t     drbd_md_test_flag(device->ldev, MDF_PRIMARY_IND) &&\n\t    !drbd_md_test_flag(device->ldev, MDF_CONNECTED_IND))\n\t\tset_bit(USE_DEGR_WFC_T, &device->flags);\n\n\tdd = drbd_determine_dev_size(device, 0, NULL);\n\tif (dd <= DS_ERROR) {\n\t\tretcode = ERR_NOMEM_BITMAP;\n\t\tgoto force_diskless_dec;\n\t} else if (dd == DS_GREW)\n\t\tset_bit(RESYNC_AFTER_NEG, &device->flags);\n\n\tif (drbd_md_test_flag(device->ldev, MDF_FULL_SYNC) ||\n\t    (test_bit(CRASHED_PRIMARY, &device->flags) &&\n\t     drbd_md_test_flag(device->ldev, MDF_AL_DISABLED))) {\n\t\tdrbd_info(device, \"Assuming that all blocks are out of sync \"\n\t\t     \"(aka FullSync)\\n\");\n\t\tif (drbd_bitmap_io(device, &drbd_bmio_set_n_write,\n\t\t\t\"set_n_write from attaching\", BM_LOCKED_MASK,\n\t\t\tNULL)) {\n\t\t\tretcode = ERR_IO_MD_DISK;\n\t\t\tgoto force_diskless_dec;\n\t\t}\n\t} else {\n\t\tif (drbd_bitmap_io(device, &drbd_bm_read,\n\t\t\t\"read from attaching\", BM_LOCKED_MASK,\n\t\t\tNULL)) {\n\t\t\tretcode = ERR_IO_MD_DISK;\n\t\t\tgoto force_diskless_dec;\n\t\t}\n\t}\n\n\tif (_drbd_bm_total_weight(device) == drbd_bm_bits(device))\n\t\tdrbd_suspend_al(device);  \n\n\tspin_lock_irq(&device->resource->req_lock);\n\tos = drbd_read_state(device);\n\tns = os;\n\t \n\tif (drbd_md_test_flag(device->ldev, MDF_CONSISTENT)) {\n\t\tif (drbd_md_test_flag(device->ldev, MDF_WAS_UP_TO_DATE))\n\t\t\tns.disk = D_CONSISTENT;\n\t\telse\n\t\t\tns.disk = D_OUTDATED;\n\t} else {\n\t\tns.disk = D_INCONSISTENT;\n\t}\n\n\tif (drbd_md_test_flag(device->ldev, MDF_PEER_OUT_DATED))\n\t\tns.pdsk = D_OUTDATED;\n\n\trcu_read_lock();\n\tif (ns.disk == D_CONSISTENT &&\n\t    (ns.pdsk == D_OUTDATED || rcu_dereference(device->ldev->disk_conf)->fencing == FP_DONT_CARE))\n\t\tns.disk = D_UP_TO_DATE;\n\n\t \n\n\tif (rcu_dereference(device->ldev->disk_conf)->al_updates)\n\t\tdevice->ldev->md.flags &= ~MDF_AL_DISABLED;\n\telse\n\t\tdevice->ldev->md.flags |= MDF_AL_DISABLED;\n\n\trcu_read_unlock();\n\n\t \n\tif (device->state.conn == C_CONNECTED) {\n\t\tdevice->new_state_tmp.i = ns.i;\n\t\tns.i = os.i;\n\t\tns.disk = D_NEGOTIATING;\n\n\t\t \n\t\tkfree(device->p_uuid);\n\t\tdevice->p_uuid = NULL;\n\t}\n\n\trv = _drbd_set_state(device, ns, CS_VERBOSE, NULL);\n\tspin_unlock_irq(&device->resource->req_lock);\n\n\tif (rv < SS_SUCCESS)\n\t\tgoto force_diskless_dec;\n\n\tmod_timer(&device->request_timer, jiffies + HZ);\n\n\tif (device->state.role == R_PRIMARY)\n\t\tdevice->ldev->md.uuid[UI_CURRENT] |=  (u64)1;\n\telse\n\t\tdevice->ldev->md.uuid[UI_CURRENT] &= ~(u64)1;\n\n\tdrbd_md_mark_dirty(device);\n\tdrbd_md_sync(device);\n\n\tkobject_uevent(&disk_to_dev(device->vdisk)->kobj, KOBJ_CHANGE);\n\tput_ldev(device);\n\tconn_reconfig_done(connection);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n\n force_diskless_dec:\n\tput_ldev(device);\n force_diskless:\n\tdrbd_force_state(device, NS(disk, D_DISKLESS));\n\tdrbd_md_sync(device);\n fail:\n\tconn_reconfig_done(connection);\n\tif (nbc) {\n\t\tclose_backing_dev(device, nbc->md_bdev,\n\t\t\t  nbc->disk_conf->meta_dev_idx < 0 ?\n\t\t\t\t(void *)device : (void *)drbd_m_holder,\n\t\t\t  nbc->md_bdev != nbc->backing_bdev);\n\t\tclose_backing_dev(device, nbc->backing_bdev, device, true);\n\t\tkfree(nbc);\n\t}\n\tkfree(new_disk_conf);\n\tlc_destroy(resync_lru);\n\tkfree(new_plan);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n finish:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic int adm_detach(struct drbd_device *device, int force)\n{\n\tif (force) {\n\t\tset_bit(FORCE_DETACH, &device->flags);\n\t\tdrbd_force_state(device, NS(disk, D_FAILED));\n\t\treturn SS_SUCCESS;\n\t}\n\n\treturn drbd_request_detach_interruptible(device);\n}\n\n \nint drbd_adm_detach(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\tstruct detach_parms parms = { };\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tif (info->attrs[DRBD_NLA_DETACH_PARMS]) {\n\t\terr = detach_parms_from_attrs(&parms, info);\n\t\tif (err) {\n\t\t\tretcode = ERR_MANDATORY_TAG;\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tretcode = adm_detach(adm_ctx.device, parms.force_detach);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic bool conn_resync_running(struct drbd_connection *connection)\n{\n\tstruct drbd_peer_device *peer_device;\n\tbool rv = false;\n\tint vnr;\n\n\trcu_read_lock();\n\tidr_for_each_entry(&connection->peer_devices, peer_device, vnr) {\n\t\tstruct drbd_device *device = peer_device->device;\n\t\tif (device->state.conn == C_SYNC_SOURCE ||\n\t\t    device->state.conn == C_SYNC_TARGET ||\n\t\t    device->state.conn == C_PAUSED_SYNC_S ||\n\t\t    device->state.conn == C_PAUSED_SYNC_T) {\n\t\t\trv = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn rv;\n}\n\nstatic bool conn_ov_running(struct drbd_connection *connection)\n{\n\tstruct drbd_peer_device *peer_device;\n\tbool rv = false;\n\tint vnr;\n\n\trcu_read_lock();\n\tidr_for_each_entry(&connection->peer_devices, peer_device, vnr) {\n\t\tstruct drbd_device *device = peer_device->device;\n\t\tif (device->state.conn == C_VERIFY_S ||\n\t\t    device->state.conn == C_VERIFY_T) {\n\t\t\trv = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\treturn rv;\n}\n\nstatic enum drbd_ret_code\n_check_net_options(struct drbd_connection *connection, struct net_conf *old_net_conf, struct net_conf *new_net_conf)\n{\n\tstruct drbd_peer_device *peer_device;\n\tint i;\n\n\tif (old_net_conf && connection->cstate == C_WF_REPORT_PARAMS && connection->agreed_pro_version < 100) {\n\t\tif (new_net_conf->wire_protocol != old_net_conf->wire_protocol)\n\t\t\treturn ERR_NEED_APV_100;\n\n\t\tif (new_net_conf->two_primaries != old_net_conf->two_primaries)\n\t\t\treturn ERR_NEED_APV_100;\n\n\t\tif (strcmp(new_net_conf->integrity_alg, old_net_conf->integrity_alg))\n\t\t\treturn ERR_NEED_APV_100;\n\t}\n\n\tif (!new_net_conf->two_primaries &&\n\t    conn_highest_role(connection) == R_PRIMARY &&\n\t    conn_highest_peer(connection) == R_PRIMARY)\n\t\treturn ERR_NEED_ALLOW_TWO_PRI;\n\n\tif (new_net_conf->two_primaries &&\n\t    (new_net_conf->wire_protocol != DRBD_PROT_C))\n\t\treturn ERR_NOT_PROTO_C;\n\n\tidr_for_each_entry(&connection->peer_devices, peer_device, i) {\n\t\tstruct drbd_device *device = peer_device->device;\n\t\tif (get_ldev(device)) {\n\t\t\tenum drbd_fencing_p fp = rcu_dereference(device->ldev->disk_conf)->fencing;\n\t\t\tput_ldev(device);\n\t\t\tif (new_net_conf->wire_protocol == DRBD_PROT_A && fp == FP_STONITH)\n\t\t\t\treturn ERR_STONITH_AND_PROT_A;\n\t\t}\n\t\tif (device->state.role == R_PRIMARY && new_net_conf->discard_my_data)\n\t\t\treturn ERR_DISCARD_IMPOSSIBLE;\n\t}\n\n\tif (new_net_conf->on_congestion != OC_BLOCK && new_net_conf->wire_protocol != DRBD_PROT_A)\n\t\treturn ERR_CONG_NOT_PROTO_A;\n\n\treturn NO_ERROR;\n}\n\nstatic enum drbd_ret_code\ncheck_net_options(struct drbd_connection *connection, struct net_conf *new_net_conf)\n{\n\tenum drbd_ret_code rv;\n\tstruct drbd_peer_device *peer_device;\n\tint i;\n\n\trcu_read_lock();\n\trv = _check_net_options(connection, rcu_dereference(connection->net_conf), new_net_conf);\n\trcu_read_unlock();\n\n\t \n\tidr_for_each_entry(&connection->peer_devices, peer_device, i) {\n\t\tstruct drbd_device *device = peer_device->device;\n\t\tif (!device->bitmap) {\n\t\t\tif (drbd_bm_init(device))\n\t\t\t\treturn ERR_NOMEM;\n\t\t}\n\t}\n\n\treturn rv;\n}\n\nstruct crypto {\n\tstruct crypto_shash *verify_tfm;\n\tstruct crypto_shash *csums_tfm;\n\tstruct crypto_shash *cram_hmac_tfm;\n\tstruct crypto_shash *integrity_tfm;\n};\n\nstatic int\nalloc_shash(struct crypto_shash **tfm, char *tfm_name, int err_alg)\n{\n\tif (!tfm_name[0])\n\t\treturn NO_ERROR;\n\n\t*tfm = crypto_alloc_shash(tfm_name, 0, 0);\n\tif (IS_ERR(*tfm)) {\n\t\t*tfm = NULL;\n\t\treturn err_alg;\n\t}\n\n\treturn NO_ERROR;\n}\n\nstatic enum drbd_ret_code\nalloc_crypto(struct crypto *crypto, struct net_conf *new_net_conf)\n{\n\tchar hmac_name[CRYPTO_MAX_ALG_NAME];\n\tenum drbd_ret_code rv;\n\n\trv = alloc_shash(&crypto->csums_tfm, new_net_conf->csums_alg,\n\t\t\t ERR_CSUMS_ALG);\n\tif (rv != NO_ERROR)\n\t\treturn rv;\n\trv = alloc_shash(&crypto->verify_tfm, new_net_conf->verify_alg,\n\t\t\t ERR_VERIFY_ALG);\n\tif (rv != NO_ERROR)\n\t\treturn rv;\n\trv = alloc_shash(&crypto->integrity_tfm, new_net_conf->integrity_alg,\n\t\t\t ERR_INTEGRITY_ALG);\n\tif (rv != NO_ERROR)\n\t\treturn rv;\n\tif (new_net_conf->cram_hmac_alg[0] != 0) {\n\t\tsnprintf(hmac_name, CRYPTO_MAX_ALG_NAME, \"hmac(%s)\",\n\t\t\t new_net_conf->cram_hmac_alg);\n\n\t\trv = alloc_shash(&crypto->cram_hmac_tfm, hmac_name,\n\t\t\t\t ERR_AUTH_ALG);\n\t}\n\n\treturn rv;\n}\n\nstatic void free_crypto(struct crypto *crypto)\n{\n\tcrypto_free_shash(crypto->cram_hmac_tfm);\n\tcrypto_free_shash(crypto->integrity_tfm);\n\tcrypto_free_shash(crypto->csums_tfm);\n\tcrypto_free_shash(crypto->verify_tfm);\n}\n\nint drbd_adm_net_opts(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\tstruct drbd_connection *connection;\n\tstruct net_conf *old_net_conf, *new_net_conf = NULL;\n\tint err;\n\tint ovr;  \n\tint rsr;  \n\tstruct crypto crypto = { };\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_CONNECTION);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto finish;\n\n\tconnection = adm_ctx.connection;\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\n\tnew_net_conf = kzalloc(sizeof(struct net_conf), GFP_KERNEL);\n\tif (!new_net_conf) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto out;\n\t}\n\n\tconn_reconfig_start(connection);\n\n\tmutex_lock(&connection->data.mutex);\n\tmutex_lock(&connection->resource->conf_update);\n\told_net_conf = connection->net_conf;\n\n\tif (!old_net_conf) {\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"net conf missing, try connect\");\n\t\tretcode = ERR_INVALID_REQUEST;\n\t\tgoto fail;\n\t}\n\n\t*new_net_conf = *old_net_conf;\n\tif (should_set_defaults(info))\n\t\tset_net_conf_defaults(new_net_conf);\n\n\terr = net_conf_from_attrs_for_change(new_net_conf, info);\n\tif (err && err != -ENOMSG) {\n\t\tretcode = ERR_MANDATORY_TAG;\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\tgoto fail;\n\t}\n\n\tretcode = check_net_options(connection, new_net_conf);\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\t \n\trsr = conn_resync_running(connection);\n\tif (rsr && strcmp(new_net_conf->csums_alg, old_net_conf->csums_alg)) {\n\t\tretcode = ERR_CSUMS_RESYNC_RUNNING;\n\t\tgoto fail;\n\t}\n\n\t \n\tovr = conn_ov_running(connection);\n\tif (ovr && strcmp(new_net_conf->verify_alg, old_net_conf->verify_alg)) {\n\t\tretcode = ERR_VERIFY_RUNNING;\n\t\tgoto fail;\n\t}\n\n\tretcode = alloc_crypto(&crypto, new_net_conf);\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\trcu_assign_pointer(connection->net_conf, new_net_conf);\n\n\tif (!rsr) {\n\t\tcrypto_free_shash(connection->csums_tfm);\n\t\tconnection->csums_tfm = crypto.csums_tfm;\n\t\tcrypto.csums_tfm = NULL;\n\t}\n\tif (!ovr) {\n\t\tcrypto_free_shash(connection->verify_tfm);\n\t\tconnection->verify_tfm = crypto.verify_tfm;\n\t\tcrypto.verify_tfm = NULL;\n\t}\n\n\tcrypto_free_shash(connection->integrity_tfm);\n\tconnection->integrity_tfm = crypto.integrity_tfm;\n\tif (connection->cstate >= C_WF_REPORT_PARAMS && connection->agreed_pro_version >= 100)\n\t\t \n\t\t__drbd_send_protocol(connection, P_PROTOCOL_UPDATE);\n\n\tcrypto_free_shash(connection->cram_hmac_tfm);\n\tconnection->cram_hmac_tfm = crypto.cram_hmac_tfm;\n\n\tmutex_unlock(&connection->resource->conf_update);\n\tmutex_unlock(&connection->data.mutex);\n\tkvfree_rcu_mightsleep(old_net_conf);\n\n\tif (connection->cstate >= C_WF_REPORT_PARAMS) {\n\t\tstruct drbd_peer_device *peer_device;\n\t\tint vnr;\n\n\t\tidr_for_each_entry(&connection->peer_devices, peer_device, vnr)\n\t\t\tdrbd_send_sync_param(peer_device);\n\t}\n\n\tgoto done;\n\n fail:\n\tmutex_unlock(&connection->resource->conf_update);\n\tmutex_unlock(&connection->data.mutex);\n\tfree_crypto(&crypto);\n\tkfree(new_net_conf);\n done:\n\tconn_reconfig_done(connection);\n out:\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n finish:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic void connection_to_info(struct connection_info *info,\n\t\t\t       struct drbd_connection *connection)\n{\n\tinfo->conn_connection_state = connection->cstate;\n\tinfo->conn_role = conn_highest_peer(connection);\n}\n\nstatic void peer_device_to_info(struct peer_device_info *info,\n\t\t\t\tstruct drbd_peer_device *peer_device)\n{\n\tstruct drbd_device *device = peer_device->device;\n\n\tinfo->peer_repl_state =\n\t\tmax_t(enum drbd_conns, C_WF_REPORT_PARAMS, device->state.conn);\n\tinfo->peer_disk_state = device->state.pdsk;\n\tinfo->peer_resync_susp_user = device->state.user_isp;\n\tinfo->peer_resync_susp_peer = device->state.peer_isp;\n\tinfo->peer_resync_susp_dependency = device->state.aftr_isp;\n}\n\nint drbd_adm_connect(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct connection_info connection_info;\n\tenum drbd_notification_type flags;\n\tunsigned int peer_devices = 0;\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_peer_device *peer_device;\n\tstruct net_conf *old_net_conf, *new_net_conf = NULL;\n\tstruct crypto crypto = { };\n\tstruct drbd_resource *resource;\n\tstruct drbd_connection *connection;\n\tenum drbd_ret_code retcode;\n\tenum drbd_state_rv rv;\n\tint i;\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_RESOURCE);\n\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\tif (!(adm_ctx.my_addr && adm_ctx.peer_addr)) {\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"connection endpoint(s) missing\");\n\t\tretcode = ERR_INVALID_REQUEST;\n\t\tgoto out;\n\t}\n\n\t \n\tfor_each_resource(resource, &drbd_resources) {\n\t\tfor_each_connection(connection, resource) {\n\t\t\tif (nla_len(adm_ctx.my_addr) == connection->my_addr_len &&\n\t\t\t    !memcmp(nla_data(adm_ctx.my_addr), &connection->my_addr,\n\t\t\t\t    connection->my_addr_len)) {\n\t\t\t\tretcode = ERR_LOCAL_ADDR;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tif (nla_len(adm_ctx.peer_addr) == connection->peer_addr_len &&\n\t\t\t    !memcmp(nla_data(adm_ctx.peer_addr), &connection->peer_addr,\n\t\t\t\t    connection->peer_addr_len)) {\n\t\t\t\tretcode = ERR_PEER_ADDR;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tconnection = first_connection(adm_ctx.resource);\n\tconn_reconfig_start(connection);\n\n\tif (connection->cstate > C_STANDALONE) {\n\t\tretcode = ERR_NET_CONFIGURED;\n\t\tgoto fail;\n\t}\n\n\t \n\tnew_net_conf = kzalloc(sizeof(*new_net_conf), GFP_KERNEL);\n\tif (!new_net_conf) {\n\t\tretcode = ERR_NOMEM;\n\t\tgoto fail;\n\t}\n\n\tset_net_conf_defaults(new_net_conf);\n\n\terr = net_conf_from_attrs(new_net_conf, info);\n\tif (err && err != -ENOMSG) {\n\t\tretcode = ERR_MANDATORY_TAG;\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\tgoto fail;\n\t}\n\n\tretcode = check_net_options(connection, new_net_conf);\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\tretcode = alloc_crypto(&crypto, new_net_conf);\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\t((char *)new_net_conf->shared_secret)[SHARED_SECRET_MAX-1] = 0;\n\n\tdrbd_flush_workqueue(&connection->sender_work);\n\n\tmutex_lock(&adm_ctx.resource->conf_update);\n\told_net_conf = connection->net_conf;\n\tif (old_net_conf) {\n\t\tretcode = ERR_NET_CONFIGURED;\n\t\tmutex_unlock(&adm_ctx.resource->conf_update);\n\t\tgoto fail;\n\t}\n\trcu_assign_pointer(connection->net_conf, new_net_conf);\n\n\tconn_free_crypto(connection);\n\tconnection->cram_hmac_tfm = crypto.cram_hmac_tfm;\n\tconnection->integrity_tfm = crypto.integrity_tfm;\n\tconnection->csums_tfm = crypto.csums_tfm;\n\tconnection->verify_tfm = crypto.verify_tfm;\n\n\tconnection->my_addr_len = nla_len(adm_ctx.my_addr);\n\tmemcpy(&connection->my_addr, nla_data(adm_ctx.my_addr), connection->my_addr_len);\n\tconnection->peer_addr_len = nla_len(adm_ctx.peer_addr);\n\tmemcpy(&connection->peer_addr, nla_data(adm_ctx.peer_addr), connection->peer_addr_len);\n\n\tidr_for_each_entry(&connection->peer_devices, peer_device, i) {\n\t\tpeer_devices++;\n\t}\n\n\tconnection_to_info(&connection_info, connection);\n\tflags = (peer_devices--) ? NOTIFY_CONTINUES : 0;\n\tmutex_lock(&notification_mutex);\n\tnotify_connection_state(NULL, 0, connection, &connection_info, NOTIFY_CREATE | flags);\n\tidr_for_each_entry(&connection->peer_devices, peer_device, i) {\n\t\tstruct peer_device_info peer_device_info;\n\n\t\tpeer_device_to_info(&peer_device_info, peer_device);\n\t\tflags = (peer_devices--) ? NOTIFY_CONTINUES : 0;\n\t\tnotify_peer_device_state(NULL, 0, peer_device, &peer_device_info, NOTIFY_CREATE | flags);\n\t}\n\tmutex_unlock(&notification_mutex);\n\tmutex_unlock(&adm_ctx.resource->conf_update);\n\n\trcu_read_lock();\n\tidr_for_each_entry(&connection->peer_devices, peer_device, i) {\n\t\tstruct drbd_device *device = peer_device->device;\n\t\tdevice->send_cnt = 0;\n\t\tdevice->recv_cnt = 0;\n\t}\n\trcu_read_unlock();\n\n\trv = conn_request_state(connection, NS(conn, C_UNCONNECTED), CS_VERBOSE);\n\n\tconn_reconfig_done(connection);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n\tdrbd_adm_finish(&adm_ctx, info, rv);\n\treturn 0;\n\nfail:\n\tfree_crypto(&crypto);\n\tkfree(new_net_conf);\n\n\tconn_reconfig_done(connection);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic enum drbd_state_rv conn_try_disconnect(struct drbd_connection *connection, bool force)\n{\n\tenum drbd_conns cstate;\n\tenum drbd_state_rv rv;\n\nrepeat:\n\trv = conn_request_state(connection, NS(conn, C_DISCONNECTING),\n\t\t\tforce ? CS_HARD : 0);\n\n\tswitch (rv) {\n\tcase SS_NOTHING_TO_DO:\n\t\tbreak;\n\tcase SS_ALREADY_STANDALONE:\n\t\treturn SS_SUCCESS;\n\tcase SS_PRIMARY_NOP:\n\t\t \n\t\trv = conn_request_state(connection, NS2(conn, C_DISCONNECTING, pdsk, D_OUTDATED), 0);\n\n\t\tif (rv == SS_OUTDATE_WO_CONN)  \n\t\t\trv = conn_request_state(connection, NS(conn, C_DISCONNECTING), CS_VERBOSE);\n\n\t\tbreak;\n\tcase SS_CW_FAILED_BY_PEER:\n\t\tspin_lock_irq(&connection->resource->req_lock);\n\t\tcstate = connection->cstate;\n\t\tspin_unlock_irq(&connection->resource->req_lock);\n\t\tif (cstate <= C_WF_CONNECTION)\n\t\t\tgoto repeat;\n\t\t \n\t\trv = conn_request_state(connection, NS2(conn, C_DISCONNECTING,\n\t\t\t\t\t\t\tdisk, D_OUTDATED), 0);\n\t\tif (rv == SS_IS_DISKLESS || rv == SS_LOWER_THAN_OUTDATED) {\n\t\t\trv = conn_request_state(connection, NS(conn, C_DISCONNECTING),\n\t\t\t\t\tCS_HARD);\n\t\t}\n\t\tbreak;\n\tdefault:;\n\t\t \n\t}\n\n\tif (rv >= SS_SUCCESS) {\n\t\tenum drbd_state_rv rv2;\n\t\t \n\t\tdrbd_thread_stop(&connection->receiver);\n\n\t\t \n\t\trv2 = conn_request_state(connection, NS(conn, C_STANDALONE),\n\t\t\t\tCS_VERBOSE | CS_HARD);\n\t\tif (rv2 < SS_SUCCESS)\n\t\t\tdrbd_err(connection,\n\t\t\t\t\"unexpected rv2=%d in conn_try_disconnect()\\n\",\n\t\t\t\trv2);\n\t\t \n\t}\n\treturn rv;\n}\n\nint drbd_adm_disconnect(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct disconnect_parms parms;\n\tstruct drbd_connection *connection;\n\tenum drbd_state_rv rv;\n\tenum drbd_ret_code retcode;\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_CONNECTION);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\tconnection = adm_ctx.connection;\n\tmemset(&parms, 0, sizeof(parms));\n\tif (info->attrs[DRBD_NLA_DISCONNECT_PARMS]) {\n\t\terr = disconnect_parms_from_attrs(&parms, info);\n\t\tif (err) {\n\t\t\tretcode = ERR_MANDATORY_TAG;\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\trv = conn_try_disconnect(connection, parms.force_disconnect);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n\tif (rv < SS_SUCCESS) {\n\t\tdrbd_adm_finish(&adm_ctx, info, rv);\n\t\treturn 0;\n\t}\n\tretcode = NO_ERROR;\n fail:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nvoid resync_after_online_grow(struct drbd_device *device)\n{\n\tint iass;  \n\n\tdrbd_info(device, \"Resync of new storage after online grow\\n\");\n\tif (device->state.role != device->state.peer)\n\t\tiass = (device->state.role == R_PRIMARY);\n\telse\n\t\tiass = test_bit(RESOLVE_CONFLICTS, &first_peer_device(device)->connection->flags);\n\n\tif (iass)\n\t\tdrbd_start_resync(device, C_SYNC_SOURCE);\n\telse\n\t\t_drbd_request_state(device, NS(conn, C_WF_SYNC_UUID), CS_VERBOSE + CS_SERIALIZE);\n}\n\nint drbd_adm_resize(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct disk_conf *old_disk_conf, *new_disk_conf = NULL;\n\tstruct resize_parms rs;\n\tstruct drbd_device *device;\n\tenum drbd_ret_code retcode;\n\tenum determine_dev_size dd;\n\tbool change_al_layout = false;\n\tenum dds_flags ddsf;\n\tsector_t u_size;\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto finish;\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tdevice = adm_ctx.device;\n\tif (!get_ldev(device)) {\n\t\tretcode = ERR_NO_DISK;\n\t\tgoto fail;\n\t}\n\n\tmemset(&rs, 0, sizeof(struct resize_parms));\n\trs.al_stripes = device->ldev->md.al_stripes;\n\trs.al_stripe_size = device->ldev->md.al_stripe_size_4k * 4;\n\tif (info->attrs[DRBD_NLA_RESIZE_PARMS]) {\n\t\terr = resize_parms_from_attrs(&rs, info);\n\t\tif (err) {\n\t\t\tretcode = ERR_MANDATORY_TAG;\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\t\tgoto fail_ldev;\n\t\t}\n\t}\n\n\tif (device->state.conn > C_CONNECTED) {\n\t\tretcode = ERR_RESIZE_RESYNC;\n\t\tgoto fail_ldev;\n\t}\n\n\tif (device->state.role == R_SECONDARY &&\n\t    device->state.peer == R_SECONDARY) {\n\t\tretcode = ERR_NO_PRIMARY;\n\t\tgoto fail_ldev;\n\t}\n\n\tif (rs.no_resync && first_peer_device(device)->connection->agreed_pro_version < 93) {\n\t\tretcode = ERR_NEED_APV_93;\n\t\tgoto fail_ldev;\n\t}\n\n\trcu_read_lock();\n\tu_size = rcu_dereference(device->ldev->disk_conf)->disk_size;\n\trcu_read_unlock();\n\tif (u_size != (sector_t)rs.resize_size) {\n\t\tnew_disk_conf = kmalloc(sizeof(struct disk_conf), GFP_KERNEL);\n\t\tif (!new_disk_conf) {\n\t\t\tretcode = ERR_NOMEM;\n\t\t\tgoto fail_ldev;\n\t\t}\n\t}\n\n\tif (device->ldev->md.al_stripes != rs.al_stripes ||\n\t    device->ldev->md.al_stripe_size_4k != rs.al_stripe_size / 4) {\n\t\tu32 al_size_k = rs.al_stripes * rs.al_stripe_size;\n\n\t\tif (al_size_k > (16 * 1024 * 1024)) {\n\t\t\tretcode = ERR_MD_LAYOUT_TOO_BIG;\n\t\t\tgoto fail_ldev;\n\t\t}\n\n\t\tif (al_size_k < MD_32kB_SECT/2) {\n\t\t\tretcode = ERR_MD_LAYOUT_TOO_SMALL;\n\t\t\tgoto fail_ldev;\n\t\t}\n\n\t\tif (device->state.conn != C_CONNECTED && !rs.resize_force) {\n\t\t\tretcode = ERR_MD_LAYOUT_CONNECTED;\n\t\t\tgoto fail_ldev;\n\t\t}\n\n\t\tchange_al_layout = true;\n\t}\n\n\tif (device->ldev->known_size != drbd_get_capacity(device->ldev->backing_bdev))\n\t\tdevice->ldev->known_size = drbd_get_capacity(device->ldev->backing_bdev);\n\n\tif (new_disk_conf) {\n\t\tmutex_lock(&device->resource->conf_update);\n\t\told_disk_conf = device->ldev->disk_conf;\n\t\t*new_disk_conf = *old_disk_conf;\n\t\tnew_disk_conf->disk_size = (sector_t)rs.resize_size;\n\t\trcu_assign_pointer(device->ldev->disk_conf, new_disk_conf);\n\t\tmutex_unlock(&device->resource->conf_update);\n\t\tkvfree_rcu_mightsleep(old_disk_conf);\n\t\tnew_disk_conf = NULL;\n\t}\n\n\tddsf = (rs.resize_force ? DDSF_FORCED : 0) | (rs.no_resync ? DDSF_NO_RESYNC : 0);\n\tdd = drbd_determine_dev_size(device, ddsf, change_al_layout ? &rs : NULL);\n\tdrbd_md_sync(device);\n\tput_ldev(device);\n\tif (dd == DS_ERROR) {\n\t\tretcode = ERR_NOMEM_BITMAP;\n\t\tgoto fail;\n\t} else if (dd == DS_ERROR_SPACE_MD) {\n\t\tretcode = ERR_MD_LAYOUT_NO_FIT;\n\t\tgoto fail;\n\t} else if (dd == DS_ERROR_SHRINK) {\n\t\tretcode = ERR_IMPLICIT_SHRINK;\n\t\tgoto fail;\n\t}\n\n\tif (device->state.conn == C_CONNECTED) {\n\t\tif (dd == DS_GREW)\n\t\t\tset_bit(RESIZE_PENDING, &device->flags);\n\n\t\tdrbd_send_uuids(first_peer_device(device));\n\t\tdrbd_send_sizes(first_peer_device(device), 1, ddsf);\n\t}\n\n fail:\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n finish:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n\n fail_ldev:\n\tput_ldev(device);\n\tkfree(new_disk_conf);\n\tgoto fail;\n}\n\nint drbd_adm_resource_opts(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\tstruct res_opts res_opts;\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_RESOURCE);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto fail;\n\n\tres_opts = adm_ctx.resource->res_opts;\n\tif (should_set_defaults(info))\n\t\tset_res_opts_defaults(&res_opts);\n\n\terr = res_opts_from_attrs(&res_opts, info);\n\tif (err && err != -ENOMSG) {\n\t\tretcode = ERR_MANDATORY_TAG;\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\tgoto fail;\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\terr = set_resource_options(adm_ctx.resource, &res_opts);\n\tif (err) {\n\t\tretcode = ERR_INVALID_REQUEST;\n\t\tif (err == -ENOMEM)\n\t\t\tretcode = ERR_NOMEM;\n\t}\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n\nfail:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nint drbd_adm_invalidate(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_device *device;\n\tint retcode;  \n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tdevice = adm_ctx.device;\n\tif (!get_ldev(device)) {\n\t\tretcode = ERR_NO_DISK;\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\n\t \n\tdrbd_suspend_io(device);\n\twait_event(device->misc_wait, !test_bit(BITMAP_IO, &device->flags));\n\tdrbd_flush_workqueue(&first_peer_device(device)->connection->sender_work);\n\n\t \n\tif (device->state.conn == C_STANDALONE && device->state.role == R_SECONDARY) {\n\t\tretcode = drbd_request_state(device, NS(disk, D_INCONSISTENT));\n\t\tif (retcode >= SS_SUCCESS) {\n\t\t\tif (drbd_bitmap_io(device, &drbd_bmio_set_n_write,\n\t\t\t\t\"set_n_write from invalidate\", BM_LOCKED_MASK, NULL))\n\t\t\t\tretcode = ERR_IO_MD_DISK;\n\t\t}\n\t} else\n\t\tretcode = drbd_request_state(device, NS(conn, C_STARTING_SYNC_T));\n\tdrbd_resume_io(device);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n\tput_ldev(device);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic int drbd_adm_simple_request_state(struct sk_buff *skb, struct genl_info *info,\n\t\tunion drbd_state mask, union drbd_state val)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tretcode = drbd_request_state(adm_ctx.device, mask, val);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic int drbd_bmio_set_susp_al(struct drbd_device *device,\n\t\tstruct drbd_peer_device *peer_device) __must_hold(local)\n{\n\tint rv;\n\n\trv = drbd_bmio_set_n_write(device, peer_device);\n\tdrbd_suspend_al(device);\n\treturn rv;\n}\n\nint drbd_adm_invalidate_peer(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tint retcode;  \n\tstruct drbd_device *device;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tdevice = adm_ctx.device;\n\tif (!get_ldev(device)) {\n\t\tretcode = ERR_NO_DISK;\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\n\t \n\tdrbd_suspend_io(device);\n\twait_event(device->misc_wait, !test_bit(BITMAP_IO, &device->flags));\n\tdrbd_flush_workqueue(&first_peer_device(device)->connection->sender_work);\n\n\t \n\tif (device->state.conn == C_STANDALONE && device->state.role == R_PRIMARY) {\n\t\t \n\t\tretcode = drbd_request_state(device, NS(pdsk, D_INCONSISTENT));\n\t\tif (retcode >= SS_SUCCESS) {\n\t\t\tif (drbd_bitmap_io(device, &drbd_bmio_set_susp_al,\n\t\t\t\t\"set_n_write from invalidate_peer\",\n\t\t\t\tBM_LOCKED_SET_ALLOWED, NULL))\n\t\t\t\tretcode = ERR_IO_MD_DISK;\n\t\t}\n\t} else\n\t\tretcode = drbd_request_state(device, NS(conn, C_STARTING_SYNC_S));\n\tdrbd_resume_io(device);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\n\tput_ldev(device);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nint drbd_adm_pause_sync(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tif (drbd_request_state(adm_ctx.device, NS(user_isp, 1)) == SS_NOTHING_TO_DO)\n\t\tretcode = ERR_PAUSE_IS_SET;\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nint drbd_adm_resume_sync(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tunion drbd_dev_state s;\n\tenum drbd_ret_code retcode;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tif (drbd_request_state(adm_ctx.device, NS(user_isp, 0)) == SS_NOTHING_TO_DO) {\n\t\ts = adm_ctx.device->state;\n\t\tif (s.conn == C_PAUSED_SYNC_S || s.conn == C_PAUSED_SYNC_T) {\n\t\t\tretcode = s.aftr_isp ? ERR_PIC_AFTER_DEP :\n\t\t\t\t  s.peer_isp ? ERR_PIC_PEER_DEP : ERR_PAUSE_IS_CLEAR;\n\t\t} else {\n\t\t\tretcode = ERR_PAUSE_IS_CLEAR;\n\t\t}\n\t}\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nint drbd_adm_suspend_io(struct sk_buff *skb, struct genl_info *info)\n{\n\treturn drbd_adm_simple_request_state(skb, info, NS(susp, 1));\n}\n\nint drbd_adm_resume_io(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_device *device;\n\tint retcode;  \n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tdevice = adm_ctx.device;\n\tif (test_bit(NEW_CUR_UUID, &device->flags)) {\n\t\tif (get_ldev_if_state(device, D_ATTACHING)) {\n\t\t\tdrbd_uuid_new_current(device);\n\t\t\tput_ldev(device);\n\t\t} else {\n\t\t\t \n\t\t\tu64 val;\n\t\t\tget_random_bytes(&val, sizeof(u64));\n\t\t\tdrbd_set_ed_uuid(device, val);\n\t\t\tdrbd_warn(device, \"Resumed without access to data; please tear down before attempting to re-configure.\\n\");\n\t\t}\n\t\tclear_bit(NEW_CUR_UUID, &device->flags);\n\t}\n\tdrbd_suspend_io(device);\n\tretcode = drbd_request_state(device, NS3(susp, 0, susp_nod, 0, susp_fen, 0));\n\tif (retcode == SS_SUCCESS) {\n\t\tif (device->state.conn < C_CONNECTED)\n\t\t\ttl_clear(first_peer_device(device)->connection);\n\t\tif (device->state.disk == D_DISKLESS || device->state.disk == D_FAILED)\n\t\t\ttl_restart(first_peer_device(device)->connection, FAIL_FROZEN_DISK_IO);\n\t}\n\tdrbd_resume_io(device);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nint drbd_adm_outdate(struct sk_buff *skb, struct genl_info *info)\n{\n\treturn drbd_adm_simple_request_state(skb, info, NS(disk, D_OUTDATED));\n}\n\nstatic int nla_put_drbd_cfg_context(struct sk_buff *skb,\n\t\t\t\t    struct drbd_resource *resource,\n\t\t\t\t    struct drbd_connection *connection,\n\t\t\t\t    struct drbd_device *device)\n{\n\tstruct nlattr *nla;\n\tnla = nla_nest_start_noflag(skb, DRBD_NLA_CFG_CONTEXT);\n\tif (!nla)\n\t\tgoto nla_put_failure;\n\tif (device &&\n\t    nla_put_u32(skb, T_ctx_volume, device->vnr))\n\t\tgoto nla_put_failure;\n\tif (nla_put_string(skb, T_ctx_resource_name, resource->name))\n\t\tgoto nla_put_failure;\n\tif (connection) {\n\t\tif (connection->my_addr_len &&\n\t\t    nla_put(skb, T_ctx_my_addr, connection->my_addr_len, &connection->my_addr))\n\t\t\tgoto nla_put_failure;\n\t\tif (connection->peer_addr_len &&\n\t\t    nla_put(skb, T_ctx_peer_addr, connection->peer_addr_len, &connection->peer_addr))\n\t\t\tgoto nla_put_failure;\n\t}\n\tnla_nest_end(skb, nla);\n\treturn 0;\n\nnla_put_failure:\n\tif (nla)\n\t\tnla_nest_cancel(skb, nla);\n\treturn -EMSGSIZE;\n}\n\n \nstatic struct nlattr *find_cfg_context_attr(const struct nlmsghdr *nlh, int attr)\n{\n\tconst unsigned hdrlen = GENL_HDRLEN + GENL_MAGIC_FAMILY_HDRSZ;\n\tconst int maxtype = ARRAY_SIZE(drbd_cfg_context_nl_policy) - 1;\n\tstruct nlattr *nla;\n\n\tnla = nla_find(nlmsg_attrdata(nlh, hdrlen), nlmsg_attrlen(nlh, hdrlen),\n\t\t       DRBD_NLA_CFG_CONTEXT);\n\tif (!nla)\n\t\treturn NULL;\n\treturn drbd_nla_find_nested(maxtype, nla, __nla_type(attr));\n}\n\nstatic void resource_to_info(struct resource_info *, struct drbd_resource *);\n\nint drbd_adm_dump_resources(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct drbd_genlmsghdr *dh;\n\tstruct drbd_resource *resource;\n\tstruct resource_info resource_info;\n\tstruct resource_statistics resource_statistics;\n\tint err;\n\n\trcu_read_lock();\n\tif (cb->args[0]) {\n\t\tfor_each_resource_rcu(resource, &drbd_resources)\n\t\t\tif (resource == (struct drbd_resource *)cb->args[0])\n\t\t\t\tgoto found_resource;\n\t\terr = 0;   \n\t\tgoto out;\n\t}\n\tresource = list_entry(&drbd_resources,\n\t\t\t      struct drbd_resource, resources);\n\nfound_resource:\n\tlist_for_each_entry_continue_rcu(resource, &drbd_resources, resources) {\n\t\tgoto put_result;\n\t}\n\terr = 0;\n\tgoto out;\n\nput_result:\n\tdh = genlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\tcb->nlh->nlmsg_seq, &drbd_genl_family,\n\t\t\tNLM_F_MULTI, DRBD_ADM_GET_RESOURCES);\n\terr = -ENOMEM;\n\tif (!dh)\n\t\tgoto out;\n\tdh->minor = -1U;\n\tdh->ret_code = NO_ERROR;\n\terr = nla_put_drbd_cfg_context(skb, resource, NULL, NULL);\n\tif (err)\n\t\tgoto out;\n\terr = res_opts_to_skb(skb, &resource->res_opts, !capable(CAP_SYS_ADMIN));\n\tif (err)\n\t\tgoto out;\n\tresource_to_info(&resource_info, resource);\n\terr = resource_info_to_skb(skb, &resource_info, !capable(CAP_SYS_ADMIN));\n\tif (err)\n\t\tgoto out;\n\tresource_statistics.res_stat_write_ordering = resource->write_ordering;\n\terr = resource_statistics_to_skb(skb, &resource_statistics, !capable(CAP_SYS_ADMIN));\n\tif (err)\n\t\tgoto out;\n\tcb->args[0] = (long)resource;\n\tgenlmsg_end(skb, dh);\n\terr = 0;\n\nout:\n\trcu_read_unlock();\n\tif (err)\n\t\treturn err;\n\treturn skb->len;\n}\n\nstatic void device_to_statistics(struct device_statistics *s,\n\t\t\t\t struct drbd_device *device)\n{\n\tmemset(s, 0, sizeof(*s));\n\ts->dev_upper_blocked = !may_inc_ap_bio(device);\n\tif (get_ldev(device)) {\n\t\tstruct drbd_md *md = &device->ldev->md;\n\t\tu64 *history_uuids = (u64 *)s->history_uuids;\n\t\tint n;\n\n\t\tspin_lock_irq(&md->uuid_lock);\n\t\ts->dev_current_uuid = md->uuid[UI_CURRENT];\n\t\tBUILD_BUG_ON(sizeof(s->history_uuids) < UI_HISTORY_END - UI_HISTORY_START + 1);\n\t\tfor (n = 0; n < UI_HISTORY_END - UI_HISTORY_START + 1; n++)\n\t\t\thistory_uuids[n] = md->uuid[UI_HISTORY_START + n];\n\t\tfor (; n < HISTORY_UUIDS; n++)\n\t\t\thistory_uuids[n] = 0;\n\t\ts->history_uuids_len = HISTORY_UUIDS;\n\t\tspin_unlock_irq(&md->uuid_lock);\n\n\t\ts->dev_disk_flags = md->flags;\n\t\tput_ldev(device);\n\t}\n\ts->dev_size = get_capacity(device->vdisk);\n\ts->dev_read = device->read_cnt;\n\ts->dev_write = device->writ_cnt;\n\ts->dev_al_writes = device->al_writ_cnt;\n\ts->dev_bm_writes = device->bm_writ_cnt;\n\ts->dev_upper_pending = atomic_read(&device->ap_bio_cnt);\n\ts->dev_lower_pending = atomic_read(&device->local_cnt);\n\ts->dev_al_suspended = test_bit(AL_SUSPENDED, &device->flags);\n\ts->dev_exposed_data_uuid = device->ed_uuid;\n}\n\nstatic int put_resource_in_arg0(struct netlink_callback *cb, int holder_nr)\n{\n\tif (cb->args[0]) {\n\t\tstruct drbd_resource *resource =\n\t\t\t(struct drbd_resource *)cb->args[0];\n\t\tkref_put(&resource->kref, drbd_destroy_resource);\n\t}\n\n\treturn 0;\n}\n\nint drbd_adm_dump_devices_done(struct netlink_callback *cb) {\n\treturn put_resource_in_arg0(cb, 7);\n}\n\nstatic void device_to_info(struct device_info *, struct drbd_device *);\n\nint drbd_adm_dump_devices(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct nlattr *resource_filter;\n\tstruct drbd_resource *resource;\n\tstruct drbd_device *device;\n\tint minor, err, retcode;\n\tstruct drbd_genlmsghdr *dh;\n\tstruct device_info device_info;\n\tstruct device_statistics device_statistics;\n\tstruct idr *idr_to_search;\n\n\tresource = (struct drbd_resource *)cb->args[0];\n\tif (!cb->args[0] && !cb->args[1]) {\n\t\tresource_filter = find_cfg_context_attr(cb->nlh, T_ctx_resource_name);\n\t\tif (resource_filter) {\n\t\t\tretcode = ERR_RES_NOT_KNOWN;\n\t\t\tresource = drbd_find_resource(nla_data(resource_filter));\n\t\t\tif (!resource)\n\t\t\t\tgoto put_result;\n\t\t\tcb->args[0] = (long)resource;\n\t\t}\n\t}\n\n\trcu_read_lock();\n\tminor = cb->args[1];\n\tidr_to_search = resource ? &resource->devices : &drbd_devices;\n\tdevice = idr_get_next(idr_to_search, &minor);\n\tif (!device) {\n\t\terr = 0;\n\t\tgoto out;\n\t}\n\tidr_for_each_entry_continue(idr_to_search, device, minor) {\n\t\tretcode = NO_ERROR;\n\t\tgoto put_result;   \n\t}\n\terr = 0;\n\tgoto out;   \n\nput_result:\n\tdh = genlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\tcb->nlh->nlmsg_seq, &drbd_genl_family,\n\t\t\tNLM_F_MULTI, DRBD_ADM_GET_DEVICES);\n\terr = -ENOMEM;\n\tif (!dh)\n\t\tgoto out;\n\tdh->ret_code = retcode;\n\tdh->minor = -1U;\n\tif (retcode == NO_ERROR) {\n\t\tdh->minor = device->minor;\n\t\terr = nla_put_drbd_cfg_context(skb, device->resource, NULL, device);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tif (get_ldev(device)) {\n\t\t\tstruct disk_conf *disk_conf =\n\t\t\t\trcu_dereference(device->ldev->disk_conf);\n\n\t\t\terr = disk_conf_to_skb(skb, disk_conf, !capable(CAP_SYS_ADMIN));\n\t\t\tput_ldev(device);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\t\tdevice_to_info(&device_info, device);\n\t\terr = device_info_to_skb(skb, &device_info, !capable(CAP_SYS_ADMIN));\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tdevice_to_statistics(&device_statistics, device);\n\t\terr = device_statistics_to_skb(skb, &device_statistics, !capable(CAP_SYS_ADMIN));\n\t\tif (err)\n\t\t\tgoto out;\n\t\tcb->args[1] = minor + 1;\n\t}\n\tgenlmsg_end(skb, dh);\n\terr = 0;\n\nout:\n\trcu_read_unlock();\n\tif (err)\n\t\treturn err;\n\treturn skb->len;\n}\n\nint drbd_adm_dump_connections_done(struct netlink_callback *cb)\n{\n\treturn put_resource_in_arg0(cb, 6);\n}\n\nenum { SINGLE_RESOURCE, ITERATE_RESOURCES };\n\nint drbd_adm_dump_connections(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct nlattr *resource_filter;\n\tstruct drbd_resource *resource = NULL, *next_resource;\n\tstruct drbd_connection *connection;\n\tint err = 0, retcode;\n\tstruct drbd_genlmsghdr *dh;\n\tstruct connection_info connection_info;\n\tstruct connection_statistics connection_statistics;\n\n\trcu_read_lock();\n\tresource = (struct drbd_resource *)cb->args[0];\n\tif (!cb->args[0]) {\n\t\tresource_filter = find_cfg_context_attr(cb->nlh, T_ctx_resource_name);\n\t\tif (resource_filter) {\n\t\t\tretcode = ERR_RES_NOT_KNOWN;\n\t\t\tresource = drbd_find_resource(nla_data(resource_filter));\n\t\t\tif (!resource)\n\t\t\t\tgoto put_result;\n\t\t\tcb->args[0] = (long)resource;\n\t\t\tcb->args[1] = SINGLE_RESOURCE;\n\t\t}\n\t}\n\tif (!resource) {\n\t\tif (list_empty(&drbd_resources))\n\t\t\tgoto out;\n\t\tresource = list_first_entry(&drbd_resources, struct drbd_resource, resources);\n\t\tkref_get(&resource->kref);\n\t\tcb->args[0] = (long)resource;\n\t\tcb->args[1] = ITERATE_RESOURCES;\n\t}\n\n    next_resource:\n\trcu_read_unlock();\n\tmutex_lock(&resource->conf_update);\n\trcu_read_lock();\n\tif (cb->args[2]) {\n\t\tfor_each_connection_rcu(connection, resource)\n\t\t\tif (connection == (struct drbd_connection *)cb->args[2])\n\t\t\t\tgoto found_connection;\n\t\t \n\t\tgoto no_more_connections;\n\t}\n\tconnection = list_entry(&resource->connections, struct drbd_connection, connections);\n\nfound_connection:\n\tlist_for_each_entry_continue_rcu(connection, &resource->connections, connections) {\n\t\tif (!has_net_conf(connection))\n\t\t\tcontinue;\n\t\tretcode = NO_ERROR;\n\t\tgoto put_result;   \n\t}\n\nno_more_connections:\n\tif (cb->args[1] == ITERATE_RESOURCES) {\n\t\tfor_each_resource_rcu(next_resource, &drbd_resources) {\n\t\t\tif (next_resource == resource)\n\t\t\t\tgoto found_resource;\n\t\t}\n\t\t \n\t}\n\tgoto out;\n\nfound_resource:\n\tlist_for_each_entry_continue_rcu(next_resource, &drbd_resources, resources) {\n\t\tmutex_unlock(&resource->conf_update);\n\t\tkref_put(&resource->kref, drbd_destroy_resource);\n\t\tresource = next_resource;\n\t\tkref_get(&resource->kref);\n\t\tcb->args[0] = (long)resource;\n\t\tcb->args[2] = 0;\n\t\tgoto next_resource;\n\t}\n\tgoto out;   \n\nput_result:\n\tdh = genlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\tcb->nlh->nlmsg_seq, &drbd_genl_family,\n\t\t\tNLM_F_MULTI, DRBD_ADM_GET_CONNECTIONS);\n\terr = -ENOMEM;\n\tif (!dh)\n\t\tgoto out;\n\tdh->ret_code = retcode;\n\tdh->minor = -1U;\n\tif (retcode == NO_ERROR) {\n\t\tstruct net_conf *net_conf;\n\n\t\terr = nla_put_drbd_cfg_context(skb, resource, connection, NULL);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tnet_conf = rcu_dereference(connection->net_conf);\n\t\tif (net_conf) {\n\t\t\terr = net_conf_to_skb(skb, net_conf, !capable(CAP_SYS_ADMIN));\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\t\tconnection_to_info(&connection_info, connection);\n\t\terr = connection_info_to_skb(skb, &connection_info, !capable(CAP_SYS_ADMIN));\n\t\tif (err)\n\t\t\tgoto out;\n\t\tconnection_statistics.conn_congested = test_bit(NET_CONGESTED, &connection->flags);\n\t\terr = connection_statistics_to_skb(skb, &connection_statistics, !capable(CAP_SYS_ADMIN));\n\t\tif (err)\n\t\t\tgoto out;\n\t\tcb->args[2] = (long)connection;\n\t}\n\tgenlmsg_end(skb, dh);\n\terr = 0;\n\nout:\n\trcu_read_unlock();\n\tif (resource)\n\t\tmutex_unlock(&resource->conf_update);\n\tif (err)\n\t\treturn err;\n\treturn skb->len;\n}\n\nenum mdf_peer_flag {\n\tMDF_PEER_CONNECTED =\t1 << 0,\n\tMDF_PEER_OUTDATED =\t1 << 1,\n\tMDF_PEER_FENCING =\t1 << 2,\n\tMDF_PEER_FULL_SYNC =\t1 << 3,\n};\n\nstatic void peer_device_to_statistics(struct peer_device_statistics *s,\n\t\t\t\t      struct drbd_peer_device *peer_device)\n{\n\tstruct drbd_device *device = peer_device->device;\n\n\tmemset(s, 0, sizeof(*s));\n\ts->peer_dev_received = device->recv_cnt;\n\ts->peer_dev_sent = device->send_cnt;\n\ts->peer_dev_pending = atomic_read(&device->ap_pending_cnt) +\n\t\t\t      atomic_read(&device->rs_pending_cnt);\n\ts->peer_dev_unacked = atomic_read(&device->unacked_cnt);\n\ts->peer_dev_out_of_sync = drbd_bm_total_weight(device) << (BM_BLOCK_SHIFT - 9);\n\ts->peer_dev_resync_failed = device->rs_failed << (BM_BLOCK_SHIFT - 9);\n\tif (get_ldev(device)) {\n\t\tstruct drbd_md *md = &device->ldev->md;\n\n\t\tspin_lock_irq(&md->uuid_lock);\n\t\ts->peer_dev_bitmap_uuid = md->uuid[UI_BITMAP];\n\t\tspin_unlock_irq(&md->uuid_lock);\n\t\ts->peer_dev_flags =\n\t\t\t(drbd_md_test_flag(device->ldev, MDF_CONNECTED_IND) ?\n\t\t\t\tMDF_PEER_CONNECTED : 0) +\n\t\t\t(drbd_md_test_flag(device->ldev, MDF_CONSISTENT) &&\n\t\t\t !drbd_md_test_flag(device->ldev, MDF_WAS_UP_TO_DATE) ?\n\t\t\t\tMDF_PEER_OUTDATED : 0) +\n\t\t\t \n\t\t\t(drbd_md_test_flag(device->ldev, MDF_FULL_SYNC) ?\n\t\t\t\tMDF_PEER_FULL_SYNC : 0);\n\t\tput_ldev(device);\n\t}\n}\n\nint drbd_adm_dump_peer_devices_done(struct netlink_callback *cb)\n{\n\treturn put_resource_in_arg0(cb, 9);\n}\n\nint drbd_adm_dump_peer_devices(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct nlattr *resource_filter;\n\tstruct drbd_resource *resource;\n\tstruct drbd_device *device;\n\tstruct drbd_peer_device *peer_device = NULL;\n\tint minor, err, retcode;\n\tstruct drbd_genlmsghdr *dh;\n\tstruct idr *idr_to_search;\n\n\tresource = (struct drbd_resource *)cb->args[0];\n\tif (!cb->args[0] && !cb->args[1]) {\n\t\tresource_filter = find_cfg_context_attr(cb->nlh, T_ctx_resource_name);\n\t\tif (resource_filter) {\n\t\t\tretcode = ERR_RES_NOT_KNOWN;\n\t\t\tresource = drbd_find_resource(nla_data(resource_filter));\n\t\t\tif (!resource)\n\t\t\t\tgoto put_result;\n\t\t}\n\t\tcb->args[0] = (long)resource;\n\t}\n\n\trcu_read_lock();\n\tminor = cb->args[1];\n\tidr_to_search = resource ? &resource->devices : &drbd_devices;\n\tdevice = idr_find(idr_to_search, minor);\n\tif (!device) {\nnext_device:\n\t\tminor++;\n\t\tcb->args[2] = 0;\n\t\tdevice = idr_get_next(idr_to_search, &minor);\n\t\tif (!device) {\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif (cb->args[2]) {\n\t\tfor_each_peer_device(peer_device, device)\n\t\t\tif (peer_device == (struct drbd_peer_device *)cb->args[2])\n\t\t\t\tgoto found_peer_device;\n\t\t \n\t\tgoto next_device;\n\t}\n\t \n\tpeer_device = list_entry(&device->peer_devices, struct drbd_peer_device, peer_devices);\n\nfound_peer_device:\n\tlist_for_each_entry_continue_rcu(peer_device, &device->peer_devices, peer_devices) {\n\t\tif (!has_net_conf(peer_device->connection))\n\t\t\tcontinue;\n\t\tretcode = NO_ERROR;\n\t\tgoto put_result;   \n\t}\n\tgoto next_device;\n\nput_result:\n\tdh = genlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\tcb->nlh->nlmsg_seq, &drbd_genl_family,\n\t\t\tNLM_F_MULTI, DRBD_ADM_GET_PEER_DEVICES);\n\terr = -ENOMEM;\n\tif (!dh)\n\t\tgoto out;\n\tdh->ret_code = retcode;\n\tdh->minor = -1U;\n\tif (retcode == NO_ERROR) {\n\t\tstruct peer_device_info peer_device_info;\n\t\tstruct peer_device_statistics peer_device_statistics;\n\n\t\tdh->minor = minor;\n\t\terr = nla_put_drbd_cfg_context(skb, device->resource, peer_device->connection, device);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tpeer_device_to_info(&peer_device_info, peer_device);\n\t\terr = peer_device_info_to_skb(skb, &peer_device_info, !capable(CAP_SYS_ADMIN));\n\t\tif (err)\n\t\t\tgoto out;\n\t\tpeer_device_to_statistics(&peer_device_statistics, peer_device);\n\t\terr = peer_device_statistics_to_skb(skb, &peer_device_statistics, !capable(CAP_SYS_ADMIN));\n\t\tif (err)\n\t\t\tgoto out;\n\t\tcb->args[1] = minor;\n\t\tcb->args[2] = (long)peer_device;\n\t}\n\tgenlmsg_end(skb, dh);\n\terr = 0;\n\nout:\n\trcu_read_unlock();\n\tif (err)\n\t\treturn err;\n\treturn skb->len;\n}\n \nstatic struct drbd_connection *the_only_connection(struct drbd_resource *resource)\n{\n\tstruct list_head *connections = &resource->connections;\n\n\tif (list_empty(connections) || connections->next->next != connections)\n\t\treturn NULL;\n\treturn list_first_entry(&resource->connections, struct drbd_connection, connections);\n}\n\nstatic int nla_put_status_info(struct sk_buff *skb, struct drbd_device *device,\n\t\tconst struct sib_info *sib)\n{\n\tstruct drbd_resource *resource = device->resource;\n\tstruct state_info *si = NULL;  \n\tstruct nlattr *nla;\n\tint got_ldev;\n\tint err = 0;\n\tint exclude_sensitive;\n\n\t \n\texclude_sensitive = sib || !capable(CAP_SYS_ADMIN);\n\n\tgot_ldev = get_ldev(device);\n\n\t \n\tif (nla_put_drbd_cfg_context(skb, resource, the_only_connection(resource), device))\n\t\tgoto nla_put_failure;\n\n\tif (res_opts_to_skb(skb, &device->resource->res_opts, exclude_sensitive))\n\t\tgoto nla_put_failure;\n\n\trcu_read_lock();\n\tif (got_ldev) {\n\t\tstruct disk_conf *disk_conf;\n\n\t\tdisk_conf = rcu_dereference(device->ldev->disk_conf);\n\t\terr = disk_conf_to_skb(skb, disk_conf, exclude_sensitive);\n\t}\n\tif (!err) {\n\t\tstruct net_conf *nc;\n\n\t\tnc = rcu_dereference(first_peer_device(device)->connection->net_conf);\n\t\tif (nc)\n\t\t\terr = net_conf_to_skb(skb, nc, exclude_sensitive);\n\t}\n\trcu_read_unlock();\n\tif (err)\n\t\tgoto nla_put_failure;\n\n\tnla = nla_nest_start_noflag(skb, DRBD_NLA_STATE_INFO);\n\tif (!nla)\n\t\tgoto nla_put_failure;\n\tif (nla_put_u32(skb, T_sib_reason, sib ? sib->sib_reason : SIB_GET_STATUS_REPLY) ||\n\t    nla_put_u32(skb, T_current_state, device->state.i) ||\n\t    nla_put_u64_0pad(skb, T_ed_uuid, device->ed_uuid) ||\n\t    nla_put_u64_0pad(skb, T_capacity, get_capacity(device->vdisk)) ||\n\t    nla_put_u64_0pad(skb, T_send_cnt, device->send_cnt) ||\n\t    nla_put_u64_0pad(skb, T_recv_cnt, device->recv_cnt) ||\n\t    nla_put_u64_0pad(skb, T_read_cnt, device->read_cnt) ||\n\t    nla_put_u64_0pad(skb, T_writ_cnt, device->writ_cnt) ||\n\t    nla_put_u64_0pad(skb, T_al_writ_cnt, device->al_writ_cnt) ||\n\t    nla_put_u64_0pad(skb, T_bm_writ_cnt, device->bm_writ_cnt) ||\n\t    nla_put_u32(skb, T_ap_bio_cnt, atomic_read(&device->ap_bio_cnt)) ||\n\t    nla_put_u32(skb, T_ap_pending_cnt, atomic_read(&device->ap_pending_cnt)) ||\n\t    nla_put_u32(skb, T_rs_pending_cnt, atomic_read(&device->rs_pending_cnt)))\n\t\tgoto nla_put_failure;\n\n\tif (got_ldev) {\n\t\tint err;\n\n\t\tspin_lock_irq(&device->ldev->md.uuid_lock);\n\t\terr = nla_put(skb, T_uuids, sizeof(si->uuids), device->ldev->md.uuid);\n\t\tspin_unlock_irq(&device->ldev->md.uuid_lock);\n\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\n\t\tif (nla_put_u32(skb, T_disk_flags, device->ldev->md.flags) ||\n\t\t    nla_put_u64_0pad(skb, T_bits_total, drbd_bm_bits(device)) ||\n\t\t    nla_put_u64_0pad(skb, T_bits_oos,\n\t\t\t\t     drbd_bm_total_weight(device)))\n\t\t\tgoto nla_put_failure;\n\t\tif (C_SYNC_SOURCE <= device->state.conn &&\n\t\t    C_PAUSED_SYNC_T >= device->state.conn) {\n\t\t\tif (nla_put_u64_0pad(skb, T_bits_rs_total,\n\t\t\t\t\t     device->rs_total) ||\n\t\t\t    nla_put_u64_0pad(skb, T_bits_rs_failed,\n\t\t\t\t\t     device->rs_failed))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n\t}\n\n\tif (sib) {\n\t\tswitch(sib->sib_reason) {\n\t\tcase SIB_SYNC_PROGRESS:\n\t\tcase SIB_GET_STATUS_REPLY:\n\t\t\tbreak;\n\t\tcase SIB_STATE_CHANGE:\n\t\t\tif (nla_put_u32(skb, T_prev_state, sib->os.i) ||\n\t\t\t    nla_put_u32(skb, T_new_state, sib->ns.i))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tbreak;\n\t\tcase SIB_HELPER_POST:\n\t\t\tif (nla_put_u32(skb, T_helper_exit_code,\n\t\t\t\t\tsib->helper_exit_code))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tfallthrough;\n\t\tcase SIB_HELPER_PRE:\n\t\t\tif (nla_put_string(skb, T_helper, sib->helper_name))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tbreak;\n\t\t}\n\t}\n\tnla_nest_end(skb, nla);\n\n\tif (0)\nnla_put_failure:\n\t\terr = -EMSGSIZE;\n\tif (got_ldev)\n\t\tput_ldev(device);\n\treturn err;\n}\n\nint drbd_adm_get_status(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\terr = nla_put_status_info(adm_ctx.reply_skb, adm_ctx.device, NULL);\n\tif (err) {\n\t\tnlmsg_free(adm_ctx.reply_skb);\n\t\treturn err;\n\t}\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic int get_one_status(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct drbd_device *device;\n\tstruct drbd_genlmsghdr *dh;\n\tstruct drbd_resource *pos = (struct drbd_resource *)cb->args[0];\n\tstruct drbd_resource *resource = NULL;\n\tstruct drbd_resource *tmp;\n\tunsigned volume = cb->args[1];\n\n\t \n\n\t \n\trcu_read_lock();\n\t \n\tfor_each_resource_rcu(tmp, &drbd_resources) {\n\t\tif (pos == NULL) {\n\t\t\t \n\t\t\tpos = tmp;\n\t\t\tresource = pos;\n\t\t\tbreak;\n\t\t}\n\t\tif (tmp == pos) {\n\t\t\tresource = pos;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (resource) {\nnext_resource:\n\t\tdevice = idr_get_next(&resource->devices, &volume);\n\t\tif (!device) {\n\t\t\t \n\t\t\tpos = list_entry_rcu(resource->resources.next,\n\t\t\t\t\t     struct drbd_resource, resources);\n\t\t\t \n\t\t\tif (volume != 0) {\n\t\t\t\t \n\t\t\t\tif (&pos->resources == &drbd_resources || cb->args[2])\n\t\t\t\t\tgoto out;\n\t\t\t\tvolume = 0;\n\t\t\t\tresource = pos;\n\t\t\t\tgoto next_resource;\n\t\t\t}\n\t\t}\n\n\t\tdh = genlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\t\tcb->nlh->nlmsg_seq, &drbd_genl_family,\n\t\t\t\tNLM_F_MULTI, DRBD_ADM_GET_STATUS);\n\t\tif (!dh)\n\t\t\tgoto out;\n\n\t\tif (!device) {\n\t\t\t \n\t\t\tstruct drbd_connection *connection;\n\n\t\t\tdh->minor = -1U;\n\t\t\tdh->ret_code = NO_ERROR;\n\t\t\tconnection = the_only_connection(resource);\n\t\t\tif (nla_put_drbd_cfg_context(skb, resource, connection, NULL))\n\t\t\t\tgoto cancel;\n\t\t\tif (connection) {\n\t\t\t\tstruct net_conf *nc;\n\n\t\t\t\tnc = rcu_dereference(connection->net_conf);\n\t\t\t\tif (nc && net_conf_to_skb(skb, nc, 1) != 0)\n\t\t\t\t\tgoto cancel;\n\t\t\t}\n\t\t\tgoto done;\n\t\t}\n\n\t\tD_ASSERT(device, device->vnr == volume);\n\t\tD_ASSERT(device, device->resource == resource);\n\n\t\tdh->minor = device_to_minor(device);\n\t\tdh->ret_code = NO_ERROR;\n\n\t\tif (nla_put_status_info(skb, device, NULL)) {\ncancel:\n\t\t\tgenlmsg_cancel(skb, dh);\n\t\t\tgoto out;\n\t\t}\ndone:\n\t\tgenlmsg_end(skb, dh);\n\t}\n\nout:\n\trcu_read_unlock();\n\t \n\tcb->args[0] = (long)pos;\n\tcb->args[1] = (pos == resource) ? volume + 1 : 0;\n\n\t \n        return skb->len;\n}\n\n \nint drbd_adm_get_status_all(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tconst unsigned hdrlen = GENL_HDRLEN + GENL_MAGIC_FAMILY_HDRSZ;\n\tstruct nlattr *nla;\n\tconst char *resource_name;\n\tstruct drbd_resource *resource;\n\tint maxtype;\n\n\t \n\tif (cb->args[0]) {\n\t\t \n\t\tif (cb->args[2] && cb->args[2] != cb->args[0])\n\t\t\treturn 0;  \n\t\tgoto dump;\n\t}\n\n\t \n\tnla = nla_find(nlmsg_attrdata(cb->nlh, hdrlen),\n\t\t\tnlmsg_attrlen(cb->nlh, hdrlen),\n\t\t\tDRBD_NLA_CFG_CONTEXT);\n\n\t \n\tif (!nla)\n\t\tgoto dump;\n\tmaxtype = ARRAY_SIZE(drbd_cfg_context_nl_policy) - 1;\n\tnla = drbd_nla_find_nested(maxtype, nla, __nla_type(T_ctx_resource_name));\n\tif (IS_ERR(nla))\n\t\treturn PTR_ERR(nla);\n\t \n\tif (!nla)\n\t\treturn -EINVAL;\n\tresource_name = nla_data(nla);\n\tif (!*resource_name)\n\t\treturn -ENODEV;\n\tresource = drbd_find_resource(resource_name);\n\tif (!resource)\n\t\treturn -ENODEV;\n\n\tkref_put(&resource->kref, drbd_destroy_resource);  \n\n\t \n\tcb->args[0] = (long)resource;\n\t \n\tcb->args[2] = (long)resource;\n\ndump:\n\treturn get_one_status(skb, cb);\n}\n\nint drbd_adm_get_timeout_type(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\tstruct timeout_parms tp;\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\ttp.timeout_type =\n\t\tadm_ctx.device->state.pdsk == D_OUTDATED ? UT_PEER_OUTDATED :\n\t\ttest_bit(USE_DEGR_WFC_T, &adm_ctx.device->flags) ? UT_DEGRADED :\n\t\tUT_DEFAULT;\n\n\terr = timeout_parms_to_priv_skb(adm_ctx.reply_skb, &tp);\n\tif (err) {\n\t\tnlmsg_free(adm_ctx.reply_skb);\n\t\treturn err;\n\t}\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nint drbd_adm_start_ov(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_device *device;\n\tenum drbd_ret_code retcode;\n\tstruct start_ov_parms parms;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tdevice = adm_ctx.device;\n\n\t \n\tparms.ov_start_sector = device->ov_start_sector;\n\tparms.ov_stop_sector = ULLONG_MAX;\n\tif (info->attrs[DRBD_NLA_START_OV_PARMS]) {\n\t\tint err = start_ov_parms_from_attrs(&parms, info);\n\t\tif (err) {\n\t\t\tretcode = ERR_MANDATORY_TAG;\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\n\t \n\tdevice->ov_start_sector = parms.ov_start_sector & ~(BM_SECT_PER_BIT-1);\n\tdevice->ov_stop_sector = parms.ov_stop_sector;\n\n\t \n\tdrbd_suspend_io(device);\n\twait_event(device->misc_wait, !test_bit(BITMAP_IO, &device->flags));\n\tretcode = drbd_request_state(device, NS(conn, C_VERIFY_S));\n\tdrbd_resume_io(device);\n\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\n\nint drbd_adm_new_c_uuid(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_device *device;\n\tenum drbd_ret_code retcode;\n\tint skip_initial_sync = 0;\n\tint err;\n\tstruct new_c_uuid_parms args;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out_nolock;\n\n\tdevice = adm_ctx.device;\n\tmemset(&args, 0, sizeof(args));\n\tif (info->attrs[DRBD_NLA_NEW_C_UUID_PARMS]) {\n\t\terr = new_c_uuid_parms_from_attrs(&args, info);\n\t\tif (err) {\n\t\t\tretcode = ERR_MANDATORY_TAG;\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\t\tgoto out_nolock;\n\t\t}\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tmutex_lock(device->state_mutex);  \n\n\tif (!get_ldev(device)) {\n\t\tretcode = ERR_NO_DISK;\n\t\tgoto out;\n\t}\n\n\t \n\tif (device->state.conn == C_CONNECTED &&\n\t    first_peer_device(device)->connection->agreed_pro_version >= 90 &&\n\t    device->ldev->md.uuid[UI_CURRENT] == UUID_JUST_CREATED && args.clear_bm) {\n\t\tdrbd_info(device, \"Preparing to skip initial sync\\n\");\n\t\tskip_initial_sync = 1;\n\t} else if (device->state.conn != C_STANDALONE) {\n\t\tretcode = ERR_CONNECTED;\n\t\tgoto out_dec;\n\t}\n\n\tdrbd_uuid_set(device, UI_BITMAP, 0);  \n\tdrbd_uuid_new_current(device);  \n\n\tif (args.clear_bm) {\n\t\terr = drbd_bitmap_io(device, &drbd_bmio_clear_n_write,\n\t\t\t\"clear_n_write from new_c_uuid\", BM_LOCKED_MASK, NULL);\n\t\tif (err) {\n\t\t\tdrbd_err(device, \"Writing bitmap failed with %d\\n\", err);\n\t\t\tretcode = ERR_IO_MD_DISK;\n\t\t}\n\t\tif (skip_initial_sync) {\n\t\t\tdrbd_send_uuids_skip_initial_sync(first_peer_device(device));\n\t\t\t_drbd_uuid_set(device, UI_BITMAP, 0);\n\t\t\tdrbd_print_uuids(device, \"cleared bitmap UUID\");\n\t\t\tspin_lock_irq(&device->resource->req_lock);\n\t\t\t_drbd_set_state(_NS2(device, disk, D_UP_TO_DATE, pdsk, D_UP_TO_DATE),\n\t\t\t\t\tCS_VERBOSE, NULL);\n\t\t\tspin_unlock_irq(&device->resource->req_lock);\n\t\t}\n\t}\n\n\tdrbd_md_sync(device);\nout_dec:\n\tput_ldev(device);\nout:\n\tmutex_unlock(device->state_mutex);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout_nolock:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic enum drbd_ret_code\ndrbd_check_resource_name(struct drbd_config_context *adm_ctx)\n{\n\tconst char *name = adm_ctx->resource_name;\n\tif (!name || !name[0]) {\n\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"resource name missing\");\n\t\treturn ERR_MANDATORY_TAG;\n\t}\n\t \n\tif (strchr(name, '/')) {\n\t\tdrbd_msg_put_info(adm_ctx->reply_skb, \"invalid resource name\");\n\t\treturn ERR_INVALID_REQUEST;\n\t}\n\treturn NO_ERROR;\n}\n\nstatic void resource_to_info(struct resource_info *info,\n\t\t\t     struct drbd_resource *resource)\n{\n\tinfo->res_role = conn_highest_role(first_connection(resource));\n\tinfo->res_susp = resource->susp;\n\tinfo->res_susp_nod = resource->susp_nod;\n\tinfo->res_susp_fen = resource->susp_fen;\n}\n\nint drbd_adm_new_resource(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_connection *connection;\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\tstruct res_opts res_opts;\n\tint err;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, 0);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tset_res_opts_defaults(&res_opts);\n\terr = res_opts_from_attrs(&res_opts, info);\n\tif (err && err != -ENOMSG) {\n\t\tretcode = ERR_MANDATORY_TAG;\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, from_attrs_err_to_txt(err));\n\t\tgoto out;\n\t}\n\n\tretcode = drbd_check_resource_name(&adm_ctx);\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tif (adm_ctx.resource) {\n\t\tif (info->nlhdr->nlmsg_flags & NLM_F_EXCL) {\n\t\t\tretcode = ERR_INVALID_REQUEST;\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"resource exists\");\n\t\t}\n\t\t \n\t\tgoto out;\n\t}\n\n\t \n\tmutex_lock(&resources_mutex);\n\tconnection = conn_create(adm_ctx.resource_name, &res_opts);\n\tmutex_unlock(&resources_mutex);\n\n\tif (connection) {\n\t\tstruct resource_info resource_info;\n\n\t\tmutex_lock(&notification_mutex);\n\t\tresource_to_info(&resource_info, connection->resource);\n\t\tnotify_resource_state(NULL, 0, connection->resource,\n\t\t\t\t      &resource_info, NOTIFY_CREATE);\n\t\tmutex_unlock(&notification_mutex);\n\t} else\n\t\tretcode = ERR_NOMEM;\n\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic void device_to_info(struct device_info *info,\n\t\t\t   struct drbd_device *device)\n{\n\tinfo->dev_disk_state = device->state.disk;\n}\n\n\nint drbd_adm_new_minor(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_genlmsghdr *dh = genl_info_userhdr(info);\n\tenum drbd_ret_code retcode;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_RESOURCE);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tif (dh->minor > MINORMASK) {\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"requested minor out of range\");\n\t\tretcode = ERR_INVALID_REQUEST;\n\t\tgoto out;\n\t}\n\tif (adm_ctx.volume > DRBD_VOLUME_MAX) {\n\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"requested volume id out of range\");\n\t\tretcode = ERR_INVALID_REQUEST;\n\t\tgoto out;\n\t}\n\n\t \n\tif (adm_ctx.device) {\n\t\tif (info->nlhdr->nlmsg_flags & NLM_F_EXCL)\n\t\t\tretcode = ERR_MINOR_OR_VOLUME_EXISTS;\n\t\t \n\t\tgoto out;\n\t}\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tretcode = drbd_create_device(&adm_ctx, dh->minor);\n\tif (retcode == NO_ERROR) {\n\t\tstruct drbd_device *device;\n\t\tstruct drbd_peer_device *peer_device;\n\t\tstruct device_info info;\n\t\tunsigned int peer_devices = 0;\n\t\tenum drbd_notification_type flags;\n\n\t\tdevice = minor_to_device(dh->minor);\n\t\tfor_each_peer_device(peer_device, device) {\n\t\t\tif (!has_net_conf(peer_device->connection))\n\t\t\t\tcontinue;\n\t\t\tpeer_devices++;\n\t\t}\n\n\t\tdevice_to_info(&info, device);\n\t\tmutex_lock(&notification_mutex);\n\t\tflags = (peer_devices--) ? NOTIFY_CONTINUES : 0;\n\t\tnotify_device_state(NULL, 0, device, &info, NOTIFY_CREATE | flags);\n\t\tfor_each_peer_device(peer_device, device) {\n\t\t\tstruct peer_device_info peer_device_info;\n\n\t\t\tif (!has_net_conf(peer_device->connection))\n\t\t\t\tcontinue;\n\t\t\tpeer_device_to_info(&peer_device_info, peer_device);\n\t\t\tflags = (peer_devices--) ? NOTIFY_CONTINUES : 0;\n\t\t\tnotify_peer_device_state(NULL, 0, peer_device, &peer_device_info,\n\t\t\t\t\t\t NOTIFY_CREATE | flags);\n\t\t}\n\t\tmutex_unlock(&notification_mutex);\n\t}\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic enum drbd_ret_code adm_del_minor(struct drbd_device *device)\n{\n\tstruct drbd_peer_device *peer_device;\n\n\tif (device->state.disk == D_DISKLESS &&\n\t     \n\t    device->state.role == R_SECONDARY) {\n\t\tstruct drbd_connection *connection =\n\t\t\tfirst_connection(device->resource);\n\n\t\t_drbd_request_state(device, NS(conn, C_WF_REPORT_PARAMS),\n\t\t\t\t    CS_VERBOSE + CS_WAIT_COMPLETE);\n\n\t\t \n\t\tif (get_t_state(&connection->worker) == RUNNING)\n\t\t\tdrbd_flush_workqueue(&connection->sender_work);\n\n\t\tmutex_lock(&notification_mutex);\n\t\tfor_each_peer_device(peer_device, device) {\n\t\t\tif (!has_net_conf(peer_device->connection))\n\t\t\t\tcontinue;\n\t\t\tnotify_peer_device_state(NULL, 0, peer_device, NULL,\n\t\t\t\t\t\t NOTIFY_DESTROY | NOTIFY_CONTINUES);\n\t\t}\n\t\tnotify_device_state(NULL, 0, device, NULL, NOTIFY_DESTROY);\n\t\tmutex_unlock(&notification_mutex);\n\n\t\tdrbd_delete_device(device);\n\t\treturn NO_ERROR;\n\t} else\n\t\treturn ERR_MINOR_CONFIGURED;\n}\n\nint drbd_adm_del_minor(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tenum drbd_ret_code retcode;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_MINOR);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto out;\n\n\tmutex_lock(&adm_ctx.resource->adm_mutex);\n\tretcode = adm_del_minor(adm_ctx.device);\n\tmutex_unlock(&adm_ctx.resource->adm_mutex);\nout:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nstatic int adm_del_resource(struct drbd_resource *resource)\n{\n\tstruct drbd_connection *connection;\n\n\tfor_each_connection(connection, resource) {\n\t\tif (connection->cstate > C_STANDALONE)\n\t\t\treturn ERR_NET_CONFIGURED;\n\t}\n\tif (!idr_is_empty(&resource->devices))\n\t\treturn ERR_RES_IN_USE;\n\n\t \n\tmutex_lock(&notification_mutex);\n\tnotify_resource_state(NULL, 0, resource, NULL, NOTIFY_DESTROY);\n\tmutex_unlock(&notification_mutex);\n\n\tmutex_lock(&resources_mutex);\n\tlist_del_rcu(&resource->resources);\n\tmutex_unlock(&resources_mutex);\n\t \n\tlist_for_each_entry(connection, &resource->connections, connections)\n\t\tdrbd_thread_stop(&connection->worker);\n\tsynchronize_rcu();\n\tdrbd_free_resource(resource);\n\treturn NO_ERROR;\n}\n\nint drbd_adm_down(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_resource *resource;\n\tstruct drbd_connection *connection;\n\tstruct drbd_device *device;\n\tint retcode;  \n\tunsigned i;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_RESOURCE);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto finish;\n\n\tresource = adm_ctx.resource;\n\tmutex_lock(&resource->adm_mutex);\n\t \n\tfor_each_connection(connection, resource) {\n\t\tstruct drbd_peer_device *peer_device;\n\n\t\tidr_for_each_entry(&connection->peer_devices, peer_device, i) {\n\t\t\tretcode = drbd_set_role(peer_device->device, R_SECONDARY, 0);\n\t\t\tif (retcode < SS_SUCCESS) {\n\t\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"failed to demote\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tretcode = conn_try_disconnect(connection, 0);\n\t\tif (retcode < SS_SUCCESS) {\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"failed to disconnect\");\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tidr_for_each_entry(&resource->devices, device, i) {\n\t\tretcode = adm_detach(device, 0);\n\t\tif (retcode < SS_SUCCESS || retcode > NO_ERROR) {\n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"failed to detach\");\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t \n\tidr_for_each_entry(&resource->devices, device, i) {\n\t\tretcode = adm_del_minor(device);\n\t\tif (retcode != NO_ERROR) {\n\t\t\t \n\t\t\tdrbd_msg_put_info(adm_ctx.reply_skb, \"failed to delete volume\");\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tretcode = adm_del_resource(resource);\nout:\n\tmutex_unlock(&resource->adm_mutex);\nfinish:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nint drbd_adm_del_resource(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct drbd_config_context adm_ctx;\n\tstruct drbd_resource *resource;\n\tenum drbd_ret_code retcode;\n\n\tretcode = drbd_adm_prepare(&adm_ctx, skb, info, DRBD_ADM_NEED_RESOURCE);\n\tif (!adm_ctx.reply_skb)\n\t\treturn retcode;\n\tif (retcode != NO_ERROR)\n\t\tgoto finish;\n\tresource = adm_ctx.resource;\n\n\tmutex_lock(&resource->adm_mutex);\n\tretcode = adm_del_resource(resource);\n\tmutex_unlock(&resource->adm_mutex);\nfinish:\n\tdrbd_adm_finish(&adm_ctx, info, retcode);\n\treturn 0;\n}\n\nvoid drbd_bcast_event(struct drbd_device *device, const struct sib_info *sib)\n{\n\tstruct sk_buff *msg;\n\tstruct drbd_genlmsghdr *d_out;\n\tunsigned seq;\n\tint err = -ENOMEM;\n\n\tseq = atomic_inc_return(&drbd_genl_seq);\n\tmsg = genlmsg_new(NLMSG_GOODSIZE, GFP_NOIO);\n\tif (!msg)\n\t\tgoto failed;\n\n\terr = -EMSGSIZE;\n\td_out = genlmsg_put(msg, 0, seq, &drbd_genl_family, 0, DRBD_EVENT);\n\tif (!d_out)  \n\t\tgoto nla_put_failure;\n\td_out->minor = device_to_minor(device);\n\td_out->ret_code = NO_ERROR;\n\n\tif (nla_put_status_info(msg, device, sib))\n\t\tgoto nla_put_failure;\n\tgenlmsg_end(msg, d_out);\n\terr = drbd_genl_multicast_events(msg, GFP_NOWAIT);\n\t \n\tif (err && err != -ESRCH)\n\t\tgoto failed;\n\n\treturn;\n\nnla_put_failure:\n\tnlmsg_free(msg);\nfailed:\n\tdrbd_err(device, \"Error %d while broadcasting event. \"\n\t\t\t\"Event seq:%u sib_reason:%u\\n\",\n\t\t\terr, seq, sib->sib_reason);\n}\n\nstatic int nla_put_notification_header(struct sk_buff *msg,\n\t\t\t\t       enum drbd_notification_type type)\n{\n\tstruct drbd_notification_header nh = {\n\t\t.nh_type = type,\n\t};\n\n\treturn drbd_notification_header_to_skb(msg, &nh, true);\n}\n\nint notify_resource_state(struct sk_buff *skb,\n\t\t\t   unsigned int seq,\n\t\t\t   struct drbd_resource *resource,\n\t\t\t   struct resource_info *resource_info,\n\t\t\t   enum drbd_notification_type type)\n{\n\tstruct resource_statistics resource_statistics;\n\tstruct drbd_genlmsghdr *dh;\n\tbool multicast = false;\n\tint err;\n\n\tif (!skb) {\n\t\tseq = atomic_inc_return(&notify_genl_seq);\n\t\tskb = genlmsg_new(NLMSG_GOODSIZE, GFP_NOIO);\n\t\terr = -ENOMEM;\n\t\tif (!skb)\n\t\t\tgoto failed;\n\t\tmulticast = true;\n\t}\n\n\terr = -EMSGSIZE;\n\tdh = genlmsg_put(skb, 0, seq, &drbd_genl_family, 0, DRBD_RESOURCE_STATE);\n\tif (!dh)\n\t\tgoto nla_put_failure;\n\tdh->minor = -1U;\n\tdh->ret_code = NO_ERROR;\n\tif (nla_put_drbd_cfg_context(skb, resource, NULL, NULL) ||\n\t    nla_put_notification_header(skb, type) ||\n\t    ((type & ~NOTIFY_FLAGS) != NOTIFY_DESTROY &&\n\t     resource_info_to_skb(skb, resource_info, true)))\n\t\tgoto nla_put_failure;\n\tresource_statistics.res_stat_write_ordering = resource->write_ordering;\n\terr = resource_statistics_to_skb(skb, &resource_statistics, !capable(CAP_SYS_ADMIN));\n\tif (err)\n\t\tgoto nla_put_failure;\n\tgenlmsg_end(skb, dh);\n\tif (multicast) {\n\t\terr = drbd_genl_multicast_events(skb, GFP_NOWAIT);\n\t\t \n\t\tif (err && err != -ESRCH)\n\t\t\tgoto failed;\n\t}\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_free(skb);\nfailed:\n\tdrbd_err(resource, \"Error %d while broadcasting event. Event seq:%u\\n\",\n\t\t\terr, seq);\n\treturn err;\n}\n\nint notify_device_state(struct sk_buff *skb,\n\t\t\t unsigned int seq,\n\t\t\t struct drbd_device *device,\n\t\t\t struct device_info *device_info,\n\t\t\t enum drbd_notification_type type)\n{\n\tstruct device_statistics device_statistics;\n\tstruct drbd_genlmsghdr *dh;\n\tbool multicast = false;\n\tint err;\n\n\tif (!skb) {\n\t\tseq = atomic_inc_return(&notify_genl_seq);\n\t\tskb = genlmsg_new(NLMSG_GOODSIZE, GFP_NOIO);\n\t\terr = -ENOMEM;\n\t\tif (!skb)\n\t\t\tgoto failed;\n\t\tmulticast = true;\n\t}\n\n\terr = -EMSGSIZE;\n\tdh = genlmsg_put(skb, 0, seq, &drbd_genl_family, 0, DRBD_DEVICE_STATE);\n\tif (!dh)\n\t\tgoto nla_put_failure;\n\tdh->minor = device->minor;\n\tdh->ret_code = NO_ERROR;\n\tif (nla_put_drbd_cfg_context(skb, device->resource, NULL, device) ||\n\t    nla_put_notification_header(skb, type) ||\n\t    ((type & ~NOTIFY_FLAGS) != NOTIFY_DESTROY &&\n\t     device_info_to_skb(skb, device_info, true)))\n\t\tgoto nla_put_failure;\n\tdevice_to_statistics(&device_statistics, device);\n\tdevice_statistics_to_skb(skb, &device_statistics, !capable(CAP_SYS_ADMIN));\n\tgenlmsg_end(skb, dh);\n\tif (multicast) {\n\t\terr = drbd_genl_multicast_events(skb, GFP_NOWAIT);\n\t\t \n\t\tif (err && err != -ESRCH)\n\t\t\tgoto failed;\n\t}\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_free(skb);\nfailed:\n\tdrbd_err(device, \"Error %d while broadcasting event. Event seq:%u\\n\",\n\t\t err, seq);\n\treturn err;\n}\n\nint notify_connection_state(struct sk_buff *skb,\n\t\t\t     unsigned int seq,\n\t\t\t     struct drbd_connection *connection,\n\t\t\t     struct connection_info *connection_info,\n\t\t\t     enum drbd_notification_type type)\n{\n\tstruct connection_statistics connection_statistics;\n\tstruct drbd_genlmsghdr *dh;\n\tbool multicast = false;\n\tint err;\n\n\tif (!skb) {\n\t\tseq = atomic_inc_return(&notify_genl_seq);\n\t\tskb = genlmsg_new(NLMSG_GOODSIZE, GFP_NOIO);\n\t\terr = -ENOMEM;\n\t\tif (!skb)\n\t\t\tgoto failed;\n\t\tmulticast = true;\n\t}\n\n\terr = -EMSGSIZE;\n\tdh = genlmsg_put(skb, 0, seq, &drbd_genl_family, 0, DRBD_CONNECTION_STATE);\n\tif (!dh)\n\t\tgoto nla_put_failure;\n\tdh->minor = -1U;\n\tdh->ret_code = NO_ERROR;\n\tif (nla_put_drbd_cfg_context(skb, connection->resource, connection, NULL) ||\n\t    nla_put_notification_header(skb, type) ||\n\t    ((type & ~NOTIFY_FLAGS) != NOTIFY_DESTROY &&\n\t     connection_info_to_skb(skb, connection_info, true)))\n\t\tgoto nla_put_failure;\n\tconnection_statistics.conn_congested = test_bit(NET_CONGESTED, &connection->flags);\n\tconnection_statistics_to_skb(skb, &connection_statistics, !capable(CAP_SYS_ADMIN));\n\tgenlmsg_end(skb, dh);\n\tif (multicast) {\n\t\terr = drbd_genl_multicast_events(skb, GFP_NOWAIT);\n\t\t \n\t\tif (err && err != -ESRCH)\n\t\t\tgoto failed;\n\t}\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_free(skb);\nfailed:\n\tdrbd_err(connection, \"Error %d while broadcasting event. Event seq:%u\\n\",\n\t\t err, seq);\n\treturn err;\n}\n\nint notify_peer_device_state(struct sk_buff *skb,\n\t\t\t      unsigned int seq,\n\t\t\t      struct drbd_peer_device *peer_device,\n\t\t\t      struct peer_device_info *peer_device_info,\n\t\t\t      enum drbd_notification_type type)\n{\n\tstruct peer_device_statistics peer_device_statistics;\n\tstruct drbd_resource *resource = peer_device->device->resource;\n\tstruct drbd_genlmsghdr *dh;\n\tbool multicast = false;\n\tint err;\n\n\tif (!skb) {\n\t\tseq = atomic_inc_return(&notify_genl_seq);\n\t\tskb = genlmsg_new(NLMSG_GOODSIZE, GFP_NOIO);\n\t\terr = -ENOMEM;\n\t\tif (!skb)\n\t\t\tgoto failed;\n\t\tmulticast = true;\n\t}\n\n\terr = -EMSGSIZE;\n\tdh = genlmsg_put(skb, 0, seq, &drbd_genl_family, 0, DRBD_PEER_DEVICE_STATE);\n\tif (!dh)\n\t\tgoto nla_put_failure;\n\tdh->minor = -1U;\n\tdh->ret_code = NO_ERROR;\n\tif (nla_put_drbd_cfg_context(skb, resource, peer_device->connection, peer_device->device) ||\n\t    nla_put_notification_header(skb, type) ||\n\t    ((type & ~NOTIFY_FLAGS) != NOTIFY_DESTROY &&\n\t     peer_device_info_to_skb(skb, peer_device_info, true)))\n\t\tgoto nla_put_failure;\n\tpeer_device_to_statistics(&peer_device_statistics, peer_device);\n\tpeer_device_statistics_to_skb(skb, &peer_device_statistics, !capable(CAP_SYS_ADMIN));\n\tgenlmsg_end(skb, dh);\n\tif (multicast) {\n\t\terr = drbd_genl_multicast_events(skb, GFP_NOWAIT);\n\t\t \n\t\tif (err && err != -ESRCH)\n\t\t\tgoto failed;\n\t}\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_free(skb);\nfailed:\n\tdrbd_err(peer_device, \"Error %d while broadcasting event. Event seq:%u\\n\",\n\t\t err, seq);\n\treturn err;\n}\n\nvoid notify_helper(enum drbd_notification_type type,\n\t\t   struct drbd_device *device, struct drbd_connection *connection,\n\t\t   const char *name, int status)\n{\n\tstruct drbd_resource *resource = device ? device->resource : connection->resource;\n\tstruct drbd_helper_info helper_info;\n\tunsigned int seq = atomic_inc_return(&notify_genl_seq);\n\tstruct sk_buff *skb = NULL;\n\tstruct drbd_genlmsghdr *dh;\n\tint err;\n\n\tstrscpy(helper_info.helper_name, name, sizeof(helper_info.helper_name));\n\thelper_info.helper_name_len = min(strlen(name), sizeof(helper_info.helper_name));\n\thelper_info.helper_status = status;\n\n\tskb = genlmsg_new(NLMSG_GOODSIZE, GFP_NOIO);\n\terr = -ENOMEM;\n\tif (!skb)\n\t\tgoto fail;\n\n\terr = -EMSGSIZE;\n\tdh = genlmsg_put(skb, 0, seq, &drbd_genl_family, 0, DRBD_HELPER);\n\tif (!dh)\n\t\tgoto fail;\n\tdh->minor = device ? device->minor : -1;\n\tdh->ret_code = NO_ERROR;\n\tmutex_lock(&notification_mutex);\n\tif (nla_put_drbd_cfg_context(skb, resource, connection, device) ||\n\t    nla_put_notification_header(skb, type) ||\n\t    drbd_helper_info_to_skb(skb, &helper_info, true))\n\t\tgoto unlock_fail;\n\tgenlmsg_end(skb, dh);\n\terr = drbd_genl_multicast_events(skb, GFP_NOWAIT);\n\tskb = NULL;\n\t \n\tif (err && err != -ESRCH)\n\t\tgoto unlock_fail;\n\tmutex_unlock(&notification_mutex);\n\treturn;\n\nunlock_fail:\n\tmutex_unlock(&notification_mutex);\nfail:\n\tnlmsg_free(skb);\n\tdrbd_err(resource, \"Error %d while broadcasting event. Event seq:%u\\n\",\n\t\t err, seq);\n}\n\nstatic int notify_initial_state_done(struct sk_buff *skb, unsigned int seq)\n{\n\tstruct drbd_genlmsghdr *dh;\n\tint err;\n\n\terr = -EMSGSIZE;\n\tdh = genlmsg_put(skb, 0, seq, &drbd_genl_family, 0, DRBD_INITIAL_STATE_DONE);\n\tif (!dh)\n\t\tgoto nla_put_failure;\n\tdh->minor = -1U;\n\tdh->ret_code = NO_ERROR;\n\tif (nla_put_notification_header(skb, NOTIFY_EXISTS))\n\t\tgoto nla_put_failure;\n\tgenlmsg_end(skb, dh);\n\treturn 0;\n\nnla_put_failure:\n\tnlmsg_free(skb);\n\tpr_err(\"Error %d sending event. Event seq:%u\\n\", err, seq);\n\treturn err;\n}\n\nstatic void free_state_changes(struct list_head *list)\n{\n\twhile (!list_empty(list)) {\n\t\tstruct drbd_state_change *state_change =\n\t\t\tlist_first_entry(list, struct drbd_state_change, list);\n\t\tlist_del(&state_change->list);\n\t\tforget_state_change(state_change);\n\t}\n}\n\nstatic unsigned int notifications_for_state_change(struct drbd_state_change *state_change)\n{\n\treturn 1 +\n\t       state_change->n_connections +\n\t       state_change->n_devices +\n\t       state_change->n_devices * state_change->n_connections;\n}\n\nstatic int get_initial_state(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct drbd_state_change *state_change = (struct drbd_state_change *)cb->args[0];\n\tunsigned int seq = cb->args[2];\n\tunsigned int n;\n\tenum drbd_notification_type flags = 0;\n\tint err = 0;\n\n\t \n\n\tcb->args[5]--;\n\tif (cb->args[5] == 1) {\n\t\terr = notify_initial_state_done(skb, seq);\n\t\tgoto out;\n\t}\n\tn = cb->args[4]++;\n\tif (cb->args[4] < cb->args[3])\n\t\tflags |= NOTIFY_CONTINUES;\n\tif (n < 1) {\n\t\terr = notify_resource_state_change(skb, seq, state_change->resource,\n\t\t\t\t\t     NOTIFY_EXISTS | flags);\n\t\tgoto next;\n\t}\n\tn--;\n\tif (n < state_change->n_connections) {\n\t\terr = notify_connection_state_change(skb, seq, &state_change->connections[n],\n\t\t\t\t\t       NOTIFY_EXISTS | flags);\n\t\tgoto next;\n\t}\n\tn -= state_change->n_connections;\n\tif (n < state_change->n_devices) {\n\t\terr = notify_device_state_change(skb, seq, &state_change->devices[n],\n\t\t\t\t\t   NOTIFY_EXISTS | flags);\n\t\tgoto next;\n\t}\n\tn -= state_change->n_devices;\n\tif (n < state_change->n_devices * state_change->n_connections) {\n\t\terr = notify_peer_device_state_change(skb, seq, &state_change->peer_devices[n],\n\t\t\t\t\t\tNOTIFY_EXISTS | flags);\n\t\tgoto next;\n\t}\n\nnext:\n\tif (cb->args[4] == cb->args[3]) {\n\t\tstruct drbd_state_change *next_state_change =\n\t\t\tlist_entry(state_change->list.next,\n\t\t\t\t   struct drbd_state_change, list);\n\t\tcb->args[0] = (long)next_state_change;\n\t\tcb->args[3] = notifications_for_state_change(next_state_change);\n\t\tcb->args[4] = 0;\n\t}\nout:\n\tif (err)\n\t\treturn err;\n\telse\n\t\treturn skb->len;\n}\n\nint drbd_adm_get_initial_state(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct drbd_resource *resource;\n\tLIST_HEAD(head);\n\n\tif (cb->args[5] >= 1) {\n\t\tif (cb->args[5] > 1)\n\t\t\treturn get_initial_state(skb, cb);\n\t\tif (cb->args[0]) {\n\t\t\tstruct drbd_state_change *state_change =\n\t\t\t\t(struct drbd_state_change *)cb->args[0];\n\n\t\t\t \n\t\t\tlist_add(&head, &state_change->list);\n\t\t\tfree_state_changes(&head);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tcb->args[5] = 2;   \n\tmutex_lock(&resources_mutex);\n\tfor_each_resource(resource, &drbd_resources) {\n\t\tstruct drbd_state_change *state_change;\n\n\t\tstate_change = remember_old_state(resource, GFP_KERNEL);\n\t\tif (!state_change) {\n\t\t\tif (!list_empty(&head))\n\t\t\t\tfree_state_changes(&head);\n\t\t\tmutex_unlock(&resources_mutex);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tcopy_old_to_new_state_change(state_change);\n\t\tlist_add_tail(&state_change->list, &head);\n\t\tcb->args[5] += notifications_for_state_change(state_change);\n\t}\n\tmutex_unlock(&resources_mutex);\n\n\tif (!list_empty(&head)) {\n\t\tstruct drbd_state_change *state_change =\n\t\t\tlist_entry(head.next, struct drbd_state_change, list);\n\t\tcb->args[0] = (long)state_change;\n\t\tcb->args[3] = notifications_for_state_change(state_change);\n\t\tlist_del(&head);   \n\t}\n\n\tcb->args[2] = cb->nlh->nlmsg_seq;\n\treturn get_initial_state(skb, cb);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}