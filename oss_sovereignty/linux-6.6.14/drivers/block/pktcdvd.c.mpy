{
  "module_name": "pktcdvd.c",
  "hash_id": "070d7235df6d2a485bef13571cf3b39e20afd401f88e7754aadf31d44081ead5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/block/pktcdvd.c",
  "human_readable_source": " \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/backing-dev.h>\n#include <linux/compat.h>\n#include <linux/debugfs.h>\n#include <linux/device.h>\n#include <linux/errno.h>\n#include <linux/file.h>\n#include <linux/freezer.h>\n#include <linux/kernel.h>\n#include <linux/kthread.h>\n#include <linux/miscdevice.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/nospec.h>\n#include <linux/pktcdvd.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/types.h>\n#include <linux/uaccess.h>\n\n#include <scsi/scsi.h>\n#include <scsi/scsi_cmnd.h>\n#include <scsi/scsi_ioctl.h>\n\n#include <asm/unaligned.h>\n\n#define DRIVER_NAME\t\"pktcdvd\"\n\n#define MAX_SPEED 0xffff\n\nstatic DEFINE_MUTEX(pktcdvd_mutex);\nstatic struct pktcdvd_device *pkt_devs[MAX_WRITERS];\nstatic struct proc_dir_entry *pkt_proc;\nstatic int pktdev_major;\nstatic int write_congestion_on  = PKT_WRITE_CONGESTION_ON;\nstatic int write_congestion_off = PKT_WRITE_CONGESTION_OFF;\nstatic struct mutex ctl_mutex;\t \nstatic mempool_t psd_pool;\nstatic struct bio_set pkt_bio_set;\n\n \nstatic struct class\tclass_pktcdvd;\nstatic struct dentry\t*pkt_debugfs_root = NULL;  \n\n \nstatic int pkt_setup_dev(dev_t dev, dev_t* pkt_dev);\nstatic int pkt_remove_dev(dev_t pkt_dev);\n\nstatic sector_t get_zone(sector_t sector, struct pktcdvd_device *pd)\n{\n\treturn (sector + pd->offset) & ~(sector_t)(pd->settings.size - 1);\n}\n\n \n\nstatic ssize_t packets_started_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%lu\\n\", pd->stats.pkt_started);\n}\nstatic DEVICE_ATTR_RO(packets_started);\n\nstatic ssize_t packets_finished_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%lu\\n\", pd->stats.pkt_ended);\n}\nstatic DEVICE_ATTR_RO(packets_finished);\n\nstatic ssize_t kb_written_show(struct device *dev,\n\t\t\t       struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%lu\\n\", pd->stats.secs_w >> 1);\n}\nstatic DEVICE_ATTR_RO(kb_written);\n\nstatic ssize_t kb_read_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%lu\\n\", pd->stats.secs_r >> 1);\n}\nstatic DEVICE_ATTR_RO(kb_read);\n\nstatic ssize_t kb_read_gather_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%lu\\n\", pd->stats.secs_rg >> 1);\n}\nstatic DEVICE_ATTR_RO(kb_read_gather);\n\nstatic ssize_t reset_store(struct device *dev, struct device_attribute *attr,\n\t\t\t   const char *buf, size_t len)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\n\tif (len > 0) {\n\t\tpd->stats.pkt_started = 0;\n\t\tpd->stats.pkt_ended = 0;\n\t\tpd->stats.secs_w = 0;\n\t\tpd->stats.secs_rg = 0;\n\t\tpd->stats.secs_r = 0;\n\t}\n\treturn len;\n}\nstatic DEVICE_ATTR_WO(reset);\n\nstatic struct attribute *pkt_stat_attrs[] = {\n\t&dev_attr_packets_finished.attr,\n\t&dev_attr_packets_started.attr,\n\t&dev_attr_kb_read.attr,\n\t&dev_attr_kb_written.attr,\n\t&dev_attr_kb_read_gather.attr,\n\t&dev_attr_reset.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group pkt_stat_group = {\n\t.name = \"stat\",\n\t.attrs = pkt_stat_attrs,\n};\n\nstatic ssize_t size_show(struct device *dev,\n\t\t\t struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\tint n;\n\n\tspin_lock(&pd->lock);\n\tn = sysfs_emit(buf, \"%d\\n\", pd->bio_queue_size);\n\tspin_unlock(&pd->lock);\n\treturn n;\n}\nstatic DEVICE_ATTR_RO(size);\n\nstatic void init_write_congestion_marks(int* lo, int* hi)\n{\n\tif (*hi > 0) {\n\t\t*hi = max(*hi, 500);\n\t\t*hi = min(*hi, 1000000);\n\t\tif (*lo <= 0)\n\t\t\t*lo = *hi - 100;\n\t\telse {\n\t\t\t*lo = min(*lo, *hi - 100);\n\t\t\t*lo = max(*lo, 100);\n\t\t}\n\t} else {\n\t\t*hi = -1;\n\t\t*lo = -1;\n\t}\n}\n\nstatic ssize_t congestion_off_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\tint n;\n\n\tspin_lock(&pd->lock);\n\tn = sysfs_emit(buf, \"%d\\n\", pd->write_congestion_off);\n\tspin_unlock(&pd->lock);\n\treturn n;\n}\n\nstatic ssize_t congestion_off_store(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    const char *buf, size_t len)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\tint val, ret;\n\n\tret = kstrtoint(buf, 10, &val);\n\tif (ret)\n\t\treturn ret;\n\n\tspin_lock(&pd->lock);\n\tpd->write_congestion_off = val;\n\tinit_write_congestion_marks(&pd->write_congestion_off, &pd->write_congestion_on);\n\tspin_unlock(&pd->lock);\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(congestion_off);\n\nstatic ssize_t congestion_on_show(struct device *dev,\n\t\t\t\t  struct device_attribute *attr, char *buf)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\tint n;\n\n\tspin_lock(&pd->lock);\n\tn = sysfs_emit(buf, \"%d\\n\", pd->write_congestion_on);\n\tspin_unlock(&pd->lock);\n\treturn n;\n}\n\nstatic ssize_t congestion_on_store(struct device *dev,\n\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t   const char *buf, size_t len)\n{\n\tstruct pktcdvd_device *pd = dev_get_drvdata(dev);\n\tint val, ret;\n\n\tret = kstrtoint(buf, 10, &val);\n\tif (ret)\n\t\treturn ret;\n\n\tspin_lock(&pd->lock);\n\tpd->write_congestion_on = val;\n\tinit_write_congestion_marks(&pd->write_congestion_off, &pd->write_congestion_on);\n\tspin_unlock(&pd->lock);\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(congestion_on);\n\nstatic struct attribute *pkt_wq_attrs[] = {\n\t&dev_attr_congestion_on.attr,\n\t&dev_attr_congestion_off.attr,\n\t&dev_attr_size.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group pkt_wq_group = {\n\t.name = \"write_queue\",\n\t.attrs = pkt_wq_attrs,\n};\n\nstatic const struct attribute_group *pkt_groups[] = {\n\t&pkt_stat_group,\n\t&pkt_wq_group,\n\tNULL,\n};\n\nstatic void pkt_sysfs_dev_new(struct pktcdvd_device *pd)\n{\n\tif (class_is_registered(&class_pktcdvd)) {\n\t\tpd->dev = device_create_with_groups(&class_pktcdvd, NULL,\n\t\t\t\t\t\t    MKDEV(0, 0), pd, pkt_groups,\n\t\t\t\t\t\t    \"%s\", pd->disk->disk_name);\n\t\tif (IS_ERR(pd->dev))\n\t\t\tpd->dev = NULL;\n\t}\n}\n\nstatic void pkt_sysfs_dev_remove(struct pktcdvd_device *pd)\n{\n\tif (class_is_registered(&class_pktcdvd))\n\t\tdevice_unregister(pd->dev);\n}\n\n\n \n\nstatic ssize_t device_map_show(const struct class *c, const struct class_attribute *attr,\n\t\t\t       char *data)\n{\n\tint n = 0;\n\tint idx;\n\tmutex_lock_nested(&ctl_mutex, SINGLE_DEPTH_NESTING);\n\tfor (idx = 0; idx < MAX_WRITERS; idx++) {\n\t\tstruct pktcdvd_device *pd = pkt_devs[idx];\n\t\tif (!pd)\n\t\t\tcontinue;\n\t\tn += sysfs_emit_at(data, n, \"%s %u:%u %u:%u\\n\",\n\t\t\tpd->disk->disk_name,\n\t\t\tMAJOR(pd->pkt_dev), MINOR(pd->pkt_dev),\n\t\t\tMAJOR(pd->bdev->bd_dev),\n\t\t\tMINOR(pd->bdev->bd_dev));\n\t}\n\tmutex_unlock(&ctl_mutex);\n\treturn n;\n}\nstatic CLASS_ATTR_RO(device_map);\n\nstatic ssize_t add_store(const struct class *c, const struct class_attribute *attr,\n\t\t\t const char *buf, size_t count)\n{\n\tunsigned int major, minor;\n\n\tif (sscanf(buf, \"%u:%u\", &major, &minor) == 2) {\n\t\t \n\t\tif (!try_module_get(THIS_MODULE))\n\t\t\treturn -ENODEV;\n\n\t\tpkt_setup_dev(MKDEV(major, minor), NULL);\n\n\t\tmodule_put(THIS_MODULE);\n\n\t\treturn count;\n\t}\n\n\treturn -EINVAL;\n}\nstatic CLASS_ATTR_WO(add);\n\nstatic ssize_t remove_store(const struct class *c, const struct class_attribute *attr,\n\t\t\t    const char *buf, size_t count)\n{\n\tunsigned int major, minor;\n\tif (sscanf(buf, \"%u:%u\", &major, &minor) == 2) {\n\t\tpkt_remove_dev(MKDEV(major, minor));\n\t\treturn count;\n\t}\n\treturn -EINVAL;\n}\nstatic CLASS_ATTR_WO(remove);\n\nstatic struct attribute *class_pktcdvd_attrs[] = {\n\t&class_attr_add.attr,\n\t&class_attr_remove.attr,\n\t&class_attr_device_map.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(class_pktcdvd);\n\nstatic struct class class_pktcdvd = {\n\t.name\t\t= DRIVER_NAME,\n\t.class_groups\t= class_pktcdvd_groups,\n};\n\nstatic int pkt_sysfs_init(void)\n{\n\t \n\treturn class_register(&class_pktcdvd);\n}\n\nstatic void pkt_sysfs_cleanup(void)\n{\n\tclass_unregister(&class_pktcdvd);\n}\n\n \n\nstatic void pkt_count_states(struct pktcdvd_device *pd, int *states)\n{\n\tstruct packet_data *pkt;\n\tint i;\n\n\tfor (i = 0; i < PACKET_NUM_STATES; i++)\n\t\tstates[i] = 0;\n\n\tspin_lock(&pd->cdrw.active_list_lock);\n\tlist_for_each_entry(pkt, &pd->cdrw.pkt_active_list, list) {\n\t\tstates[pkt->state]++;\n\t}\n\tspin_unlock(&pd->cdrw.active_list_lock);\n}\n\nstatic int pkt_seq_show(struct seq_file *m, void *p)\n{\n\tstruct pktcdvd_device *pd = m->private;\n\tchar *msg;\n\tint states[PACKET_NUM_STATES];\n\n\tseq_printf(m, \"Writer %s mapped to %pg:\\n\", pd->disk->disk_name, pd->bdev);\n\n\tseq_printf(m, \"\\nSettings:\\n\");\n\tseq_printf(m, \"\\tpacket size:\\t\\t%dkB\\n\", pd->settings.size / 2);\n\n\tif (pd->settings.write_type == 0)\n\t\tmsg = \"Packet\";\n\telse\n\t\tmsg = \"Unknown\";\n\tseq_printf(m, \"\\twrite type:\\t\\t%s\\n\", msg);\n\n\tseq_printf(m, \"\\tpacket type:\\t\\t%s\\n\", pd->settings.fp ? \"Fixed\" : \"Variable\");\n\tseq_printf(m, \"\\tlink loss:\\t\\t%d\\n\", pd->settings.link_loss);\n\n\tseq_printf(m, \"\\ttrack mode:\\t\\t%d\\n\", pd->settings.track_mode);\n\n\tif (pd->settings.block_mode == PACKET_BLOCK_MODE1)\n\t\tmsg = \"Mode 1\";\n\telse if (pd->settings.block_mode == PACKET_BLOCK_MODE2)\n\t\tmsg = \"Mode 2\";\n\telse\n\t\tmsg = \"Unknown\";\n\tseq_printf(m, \"\\tblock mode:\\t\\t%s\\n\", msg);\n\n\tseq_printf(m, \"\\nStatistics:\\n\");\n\tseq_printf(m, \"\\tpackets started:\\t%lu\\n\", pd->stats.pkt_started);\n\tseq_printf(m, \"\\tpackets ended:\\t\\t%lu\\n\", pd->stats.pkt_ended);\n\tseq_printf(m, \"\\twritten:\\t\\t%lukB\\n\", pd->stats.secs_w >> 1);\n\tseq_printf(m, \"\\tread gather:\\t\\t%lukB\\n\", pd->stats.secs_rg >> 1);\n\tseq_printf(m, \"\\tread:\\t\\t\\t%lukB\\n\", pd->stats.secs_r >> 1);\n\n\tseq_printf(m, \"\\nMisc:\\n\");\n\tseq_printf(m, \"\\treference count:\\t%d\\n\", pd->refcnt);\n\tseq_printf(m, \"\\tflags:\\t\\t\\t0x%lx\\n\", pd->flags);\n\tseq_printf(m, \"\\tread speed:\\t\\t%ukB/s\\n\", pd->read_speed);\n\tseq_printf(m, \"\\twrite speed:\\t\\t%ukB/s\\n\", pd->write_speed);\n\tseq_printf(m, \"\\tstart offset:\\t\\t%lu\\n\", pd->offset);\n\tseq_printf(m, \"\\tmode page offset:\\t%u\\n\", pd->mode_offset);\n\n\tseq_printf(m, \"\\nQueue state:\\n\");\n\tseq_printf(m, \"\\tbios queued:\\t\\t%d\\n\", pd->bio_queue_size);\n\tseq_printf(m, \"\\tbios pending:\\t\\t%d\\n\", atomic_read(&pd->cdrw.pending_bios));\n\tseq_printf(m, \"\\tcurrent sector:\\t\\t0x%llx\\n\", pd->current_sector);\n\n\tpkt_count_states(pd, states);\n\tseq_printf(m, \"\\tstate:\\t\\t\\ti:%d ow:%d rw:%d ww:%d rec:%d fin:%d\\n\",\n\t\t   states[0], states[1], states[2], states[3], states[4], states[5]);\n\n\tseq_printf(m, \"\\twrite congestion marks:\\toff=%d on=%d\\n\",\n\t\t\tpd->write_congestion_off,\n\t\t\tpd->write_congestion_on);\n\treturn 0;\n}\nDEFINE_SHOW_ATTRIBUTE(pkt_seq);\n\nstatic void pkt_debugfs_dev_new(struct pktcdvd_device *pd)\n{\n\tif (!pkt_debugfs_root)\n\t\treturn;\n\tpd->dfs_d_root = debugfs_create_dir(pd->disk->disk_name, pkt_debugfs_root);\n\tif (!pd->dfs_d_root)\n\t\treturn;\n\n\tpd->dfs_f_info = debugfs_create_file(\"info\", 0444, pd->dfs_d_root,\n\t\t\t\t\t     pd, &pkt_seq_fops);\n}\n\nstatic void pkt_debugfs_dev_remove(struct pktcdvd_device *pd)\n{\n\tif (!pkt_debugfs_root)\n\t\treturn;\n\tdebugfs_remove(pd->dfs_f_info);\n\tdebugfs_remove(pd->dfs_d_root);\n\tpd->dfs_f_info = NULL;\n\tpd->dfs_d_root = NULL;\n}\n\nstatic void pkt_debugfs_init(void)\n{\n\tpkt_debugfs_root = debugfs_create_dir(DRIVER_NAME, NULL);\n}\n\nstatic void pkt_debugfs_cleanup(void)\n{\n\tdebugfs_remove(pkt_debugfs_root);\n\tpkt_debugfs_root = NULL;\n}\n\n \n\n\nstatic void pkt_bio_finished(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\n\tBUG_ON(atomic_read(&pd->cdrw.pending_bios) <= 0);\n\tif (atomic_dec_and_test(&pd->cdrw.pending_bios)) {\n\t\tdev_dbg(ddev, \"queue empty\\n\");\n\t\tatomic_set(&pd->iosched.attention, 1);\n\t\twake_up(&pd->wqueue);\n\t}\n}\n\n \nstatic struct packet_data *pkt_alloc_packet_data(int frames)\n{\n\tint i;\n\tstruct packet_data *pkt;\n\n\tpkt = kzalloc(sizeof(struct packet_data), GFP_KERNEL);\n\tif (!pkt)\n\t\tgoto no_pkt;\n\n\tpkt->frames = frames;\n\tpkt->w_bio = bio_kmalloc(frames, GFP_KERNEL);\n\tif (!pkt->w_bio)\n\t\tgoto no_bio;\n\n\tfor (i = 0; i < frames / FRAMES_PER_PAGE; i++) {\n\t\tpkt->pages[i] = alloc_page(GFP_KERNEL|__GFP_ZERO);\n\t\tif (!pkt->pages[i])\n\t\t\tgoto no_page;\n\t}\n\n\tspin_lock_init(&pkt->lock);\n\tbio_list_init(&pkt->orig_bios);\n\n\tfor (i = 0; i < frames; i++) {\n\t\tpkt->r_bios[i] = bio_kmalloc(1, GFP_KERNEL);\n\t\tif (!pkt->r_bios[i])\n\t\t\tgoto no_rd_bio;\n\t}\n\n\treturn pkt;\n\nno_rd_bio:\n\tfor (i = 0; i < frames; i++)\n\t\tkfree(pkt->r_bios[i]);\nno_page:\n\tfor (i = 0; i < frames / FRAMES_PER_PAGE; i++)\n\t\tif (pkt->pages[i])\n\t\t\t__free_page(pkt->pages[i]);\n\tkfree(pkt->w_bio);\nno_bio:\n\tkfree(pkt);\nno_pkt:\n\treturn NULL;\n}\n\n \nstatic void pkt_free_packet_data(struct packet_data *pkt)\n{\n\tint i;\n\n\tfor (i = 0; i < pkt->frames; i++)\n\t\tkfree(pkt->r_bios[i]);\n\tfor (i = 0; i < pkt->frames / FRAMES_PER_PAGE; i++)\n\t\t__free_page(pkt->pages[i]);\n\tkfree(pkt->w_bio);\n\tkfree(pkt);\n}\n\nstatic void pkt_shrink_pktlist(struct pktcdvd_device *pd)\n{\n\tstruct packet_data *pkt, *next;\n\n\tBUG_ON(!list_empty(&pd->cdrw.pkt_active_list));\n\n\tlist_for_each_entry_safe(pkt, next, &pd->cdrw.pkt_free_list, list) {\n\t\tpkt_free_packet_data(pkt);\n\t}\n\tINIT_LIST_HEAD(&pd->cdrw.pkt_free_list);\n}\n\nstatic int pkt_grow_pktlist(struct pktcdvd_device *pd, int nr_packets)\n{\n\tstruct packet_data *pkt;\n\n\tBUG_ON(!list_empty(&pd->cdrw.pkt_free_list));\n\n\twhile (nr_packets > 0) {\n\t\tpkt = pkt_alloc_packet_data(pd->settings.size >> 2);\n\t\tif (!pkt) {\n\t\t\tpkt_shrink_pktlist(pd);\n\t\t\treturn 0;\n\t\t}\n\t\tpkt->id = nr_packets;\n\t\tpkt->pd = pd;\n\t\tlist_add(&pkt->list, &pd->cdrw.pkt_free_list);\n\t\tnr_packets--;\n\t}\n\treturn 1;\n}\n\nstatic inline struct pkt_rb_node *pkt_rbtree_next(struct pkt_rb_node *node)\n{\n\tstruct rb_node *n = rb_next(&node->rb_node);\n\tif (!n)\n\t\treturn NULL;\n\treturn rb_entry(n, struct pkt_rb_node, rb_node);\n}\n\nstatic void pkt_rbtree_erase(struct pktcdvd_device *pd, struct pkt_rb_node *node)\n{\n\trb_erase(&node->rb_node, &pd->bio_queue);\n\tmempool_free(node, &pd->rb_pool);\n\tpd->bio_queue_size--;\n\tBUG_ON(pd->bio_queue_size < 0);\n}\n\n \nstatic struct pkt_rb_node *pkt_rbtree_find(struct pktcdvd_device *pd, sector_t s)\n{\n\tstruct rb_node *n = pd->bio_queue.rb_node;\n\tstruct rb_node *next;\n\tstruct pkt_rb_node *tmp;\n\n\tif (!n) {\n\t\tBUG_ON(pd->bio_queue_size > 0);\n\t\treturn NULL;\n\t}\n\n\tfor (;;) {\n\t\ttmp = rb_entry(n, struct pkt_rb_node, rb_node);\n\t\tif (s <= tmp->bio->bi_iter.bi_sector)\n\t\t\tnext = n->rb_left;\n\t\telse\n\t\t\tnext = n->rb_right;\n\t\tif (!next)\n\t\t\tbreak;\n\t\tn = next;\n\t}\n\n\tif (s > tmp->bio->bi_iter.bi_sector) {\n\t\ttmp = pkt_rbtree_next(tmp);\n\t\tif (!tmp)\n\t\t\treturn NULL;\n\t}\n\tBUG_ON(s > tmp->bio->bi_iter.bi_sector);\n\treturn tmp;\n}\n\n \nstatic void pkt_rbtree_insert(struct pktcdvd_device *pd, struct pkt_rb_node *node)\n{\n\tstruct rb_node **p = &pd->bio_queue.rb_node;\n\tstruct rb_node *parent = NULL;\n\tsector_t s = node->bio->bi_iter.bi_sector;\n\tstruct pkt_rb_node *tmp;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\ttmp = rb_entry(parent, struct pkt_rb_node, rb_node);\n\t\tif (s < tmp->bio->bi_iter.bi_sector)\n\t\t\tp = &(*p)->rb_left;\n\t\telse\n\t\t\tp = &(*p)->rb_right;\n\t}\n\trb_link_node(&node->rb_node, parent, p);\n\trb_insert_color(&node->rb_node, &pd->bio_queue);\n\tpd->bio_queue_size++;\n}\n\n \nstatic int pkt_generic_packet(struct pktcdvd_device *pd, struct packet_command *cgc)\n{\n\tstruct request_queue *q = bdev_get_queue(pd->bdev);\n\tstruct scsi_cmnd *scmd;\n\tstruct request *rq;\n\tint ret = 0;\n\n\trq = scsi_alloc_request(q, (cgc->data_direction == CGC_DATA_WRITE) ?\n\t\t\t     REQ_OP_DRV_OUT : REQ_OP_DRV_IN, 0);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\tscmd = blk_mq_rq_to_pdu(rq);\n\n\tif (cgc->buflen) {\n\t\tret = blk_rq_map_kern(q, rq, cgc->buffer, cgc->buflen,\n\t\t\t\t      GFP_NOIO);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tscmd->cmd_len = COMMAND_SIZE(cgc->cmd[0]);\n\tmemcpy(scmd->cmnd, cgc->cmd, CDROM_PACKET_SIZE);\n\n\trq->timeout = 60*HZ;\n\tif (cgc->quiet)\n\t\trq->rq_flags |= RQF_QUIET;\n\n\tblk_execute_rq(rq, false);\n\tif (scmd->result)\n\t\tret = -EIO;\nout:\n\tblk_mq_free_request(rq);\n\treturn ret;\n}\n\nstatic const char *sense_key_string(__u8 index)\n{\n\tstatic const char * const info[] = {\n\t\t\"No sense\", \"Recovered error\", \"Not ready\",\n\t\t\"Medium error\", \"Hardware error\", \"Illegal request\",\n\t\t\"Unit attention\", \"Data protect\", \"Blank check\",\n\t};\n\n\treturn index < ARRAY_SIZE(info) ? info[index] : \"INVALID\";\n}\n\n \nstatic void pkt_dump_sense(struct pktcdvd_device *pd,\n\t\t\t   struct packet_command *cgc)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct scsi_sense_hdr *sshdr = cgc->sshdr;\n\n\tif (sshdr)\n\t\tdev_err(ddev, \"%*ph - sense %02x.%02x.%02x (%s)\\n\",\n\t\t\tCDROM_PACKET_SIZE, cgc->cmd,\n\t\t\tsshdr->sense_key, sshdr->asc, sshdr->ascq,\n\t\t\tsense_key_string(sshdr->sense_key));\n\telse\n\t\tdev_err(ddev, \"%*ph - no sense\\n\", CDROM_PACKET_SIZE, cgc->cmd);\n}\n\n \nstatic int pkt_flush_cache(struct pktcdvd_device *pd)\n{\n\tstruct packet_command cgc;\n\n\tinit_cdrom_command(&cgc, NULL, 0, CGC_DATA_NONE);\n\tcgc.cmd[0] = GPCMD_FLUSH_CACHE;\n\tcgc.quiet = 1;\n\n\t \n#if 0\n\tcgc.cmd[1] = 1 << 1;\n#endif\n\treturn pkt_generic_packet(pd, &cgc);\n}\n\n \nstatic noinline_for_stack int pkt_set_speed(struct pktcdvd_device *pd,\n\t\t\t\tunsigned write_speed, unsigned read_speed)\n{\n\tstruct packet_command cgc;\n\tstruct scsi_sense_hdr sshdr;\n\tint ret;\n\n\tinit_cdrom_command(&cgc, NULL, 0, CGC_DATA_NONE);\n\tcgc.sshdr = &sshdr;\n\tcgc.cmd[0] = GPCMD_SET_SPEED;\n\tput_unaligned_be16(read_speed, &cgc.cmd[2]);\n\tput_unaligned_be16(write_speed, &cgc.cmd[4]);\n\n\tret = pkt_generic_packet(pd, &cgc);\n\tif (ret)\n\t\tpkt_dump_sense(pd, &cgc);\n\n\treturn ret;\n}\n\n \nstatic void pkt_queue_bio(struct pktcdvd_device *pd, struct bio *bio)\n{\n\tspin_lock(&pd->iosched.lock);\n\tif (bio_data_dir(bio) == READ)\n\t\tbio_list_add(&pd->iosched.read_queue, bio);\n\telse\n\t\tbio_list_add(&pd->iosched.write_queue, bio);\n\tspin_unlock(&pd->iosched.lock);\n\n\tatomic_set(&pd->iosched.attention, 1);\n\twake_up(&pd->wqueue);\n}\n\n \nstatic void pkt_iosched_process_queue(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\n\tif (atomic_read(&pd->iosched.attention) == 0)\n\t\treturn;\n\tatomic_set(&pd->iosched.attention, 0);\n\n\tfor (;;) {\n\t\tstruct bio *bio;\n\t\tint reads_queued, writes_queued;\n\n\t\tspin_lock(&pd->iosched.lock);\n\t\treads_queued = !bio_list_empty(&pd->iosched.read_queue);\n\t\twrites_queued = !bio_list_empty(&pd->iosched.write_queue);\n\t\tspin_unlock(&pd->iosched.lock);\n\n\t\tif (!reads_queued && !writes_queued)\n\t\t\tbreak;\n\n\t\tif (pd->iosched.writing) {\n\t\t\tint need_write_seek = 1;\n\t\t\tspin_lock(&pd->iosched.lock);\n\t\t\tbio = bio_list_peek(&pd->iosched.write_queue);\n\t\t\tspin_unlock(&pd->iosched.lock);\n\t\t\tif (bio && (bio->bi_iter.bi_sector ==\n\t\t\t\t    pd->iosched.last_write))\n\t\t\t\tneed_write_seek = 0;\n\t\t\tif (need_write_seek && reads_queued) {\n\t\t\t\tif (atomic_read(&pd->cdrw.pending_bios) > 0) {\n\t\t\t\t\tdev_dbg(ddev, \"write, waiting\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tpkt_flush_cache(pd);\n\t\t\t\tpd->iosched.writing = 0;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!reads_queued && writes_queued) {\n\t\t\t\tif (atomic_read(&pd->cdrw.pending_bios) > 0) {\n\t\t\t\t\tdev_dbg(ddev, \"read, waiting\\n\");\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tpd->iosched.writing = 1;\n\t\t\t}\n\t\t}\n\n\t\tspin_lock(&pd->iosched.lock);\n\t\tif (pd->iosched.writing)\n\t\t\tbio = bio_list_pop(&pd->iosched.write_queue);\n\t\telse\n\t\t\tbio = bio_list_pop(&pd->iosched.read_queue);\n\t\tspin_unlock(&pd->iosched.lock);\n\n\t\tif (!bio)\n\t\t\tcontinue;\n\n\t\tif (bio_data_dir(bio) == READ)\n\t\t\tpd->iosched.successive_reads +=\n\t\t\t\tbio->bi_iter.bi_size >> 10;\n\t\telse {\n\t\t\tpd->iosched.successive_reads = 0;\n\t\t\tpd->iosched.last_write = bio_end_sector(bio);\n\t\t}\n\t\tif (pd->iosched.successive_reads >= HI_SPEED_SWITCH) {\n\t\t\tif (pd->read_speed == pd->write_speed) {\n\t\t\t\tpd->read_speed = MAX_SPEED;\n\t\t\t\tpkt_set_speed(pd, pd->write_speed, pd->read_speed);\n\t\t\t}\n\t\t} else {\n\t\t\tif (pd->read_speed != pd->write_speed) {\n\t\t\t\tpd->read_speed = pd->write_speed;\n\t\t\t\tpkt_set_speed(pd, pd->write_speed, pd->read_speed);\n\t\t\t}\n\t\t}\n\n\t\tatomic_inc(&pd->cdrw.pending_bios);\n\t\tsubmit_bio_noacct(bio);\n\t}\n}\n\n \nstatic int pkt_set_segment_merging(struct pktcdvd_device *pd, struct request_queue *q)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\n\tif ((pd->settings.size << 9) / CD_FRAMESIZE <= queue_max_segments(q)) {\n\t\t \n\t\tclear_bit(PACKET_MERGE_SEGS, &pd->flags);\n\t\treturn 0;\n\t}\n\n\tif ((pd->settings.size << 9) / PAGE_SIZE <= queue_max_segments(q)) {\n\t\t \n\t\tset_bit(PACKET_MERGE_SEGS, &pd->flags);\n\t\treturn 0;\n\t}\n\n\tdev_err(ddev, \"cdrom max_phys_segments too small\\n\");\n\treturn -EIO;\n}\n\nstatic void pkt_end_io_read(struct bio *bio)\n{\n\tstruct packet_data *pkt = bio->bi_private;\n\tstruct pktcdvd_device *pd = pkt->pd;\n\tBUG_ON(!pd);\n\n\tdev_dbg(disk_to_dev(pd->disk), \"bio=%p sec0=%llx sec=%llx err=%d\\n\",\n\t\tbio, pkt->sector, bio->bi_iter.bi_sector, bio->bi_status);\n\n\tif (bio->bi_status)\n\t\tatomic_inc(&pkt->io_errors);\n\tbio_uninit(bio);\n\tif (atomic_dec_and_test(&pkt->io_wait)) {\n\t\tatomic_inc(&pkt->run_sm);\n\t\twake_up(&pd->wqueue);\n\t}\n\tpkt_bio_finished(pd);\n}\n\nstatic void pkt_end_io_packet_write(struct bio *bio)\n{\n\tstruct packet_data *pkt = bio->bi_private;\n\tstruct pktcdvd_device *pd = pkt->pd;\n\tBUG_ON(!pd);\n\n\tdev_dbg(disk_to_dev(pd->disk), \"id=%d, err=%d\\n\", pkt->id, bio->bi_status);\n\n\tpd->stats.pkt_ended++;\n\n\tbio_uninit(bio);\n\tpkt_bio_finished(pd);\n\tatomic_dec(&pkt->io_wait);\n\tatomic_inc(&pkt->run_sm);\n\twake_up(&pd->wqueue);\n}\n\n \nstatic void pkt_gather_data(struct pktcdvd_device *pd, struct packet_data *pkt)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tint frames_read = 0;\n\tstruct bio *bio;\n\tint f;\n\tchar written[PACKET_MAX_SIZE];\n\n\tBUG_ON(bio_list_empty(&pkt->orig_bios));\n\n\tatomic_set(&pkt->io_wait, 0);\n\tatomic_set(&pkt->io_errors, 0);\n\n\t \n\tmemset(written, 0, sizeof(written));\n\tspin_lock(&pkt->lock);\n\tbio_list_for_each(bio, &pkt->orig_bios) {\n\t\tint first_frame = (bio->bi_iter.bi_sector - pkt->sector) /\n\t\t\t(CD_FRAMESIZE >> 9);\n\t\tint num_frames = bio->bi_iter.bi_size / CD_FRAMESIZE;\n\t\tpd->stats.secs_w += num_frames * (CD_FRAMESIZE >> 9);\n\t\tBUG_ON(first_frame < 0);\n\t\tBUG_ON(first_frame + num_frames > pkt->frames);\n\t\tfor (f = first_frame; f < first_frame + num_frames; f++)\n\t\t\twritten[f] = 1;\n\t}\n\tspin_unlock(&pkt->lock);\n\n\tif (pkt->cache_valid) {\n\t\tdev_dbg(ddev, \"zone %llx cached\\n\", pkt->sector);\n\t\tgoto out_account;\n\t}\n\n\t \n\tfor (f = 0; f < pkt->frames; f++) {\n\t\tint p, offset;\n\n\t\tif (written[f])\n\t\t\tcontinue;\n\n\t\tbio = pkt->r_bios[f];\n\t\tbio_init(bio, pd->bdev, bio->bi_inline_vecs, 1, REQ_OP_READ);\n\t\tbio->bi_iter.bi_sector = pkt->sector + f * (CD_FRAMESIZE >> 9);\n\t\tbio->bi_end_io = pkt_end_io_read;\n\t\tbio->bi_private = pkt;\n\n\t\tp = (f * CD_FRAMESIZE) / PAGE_SIZE;\n\t\toffset = (f * CD_FRAMESIZE) % PAGE_SIZE;\n\t\tdev_dbg(ddev, \"Adding frame %d, page:%p offs:%d\\n\", f,\n\t\t\tpkt->pages[p], offset);\n\t\tif (!bio_add_page(bio, pkt->pages[p], CD_FRAMESIZE, offset))\n\t\t\tBUG();\n\n\t\tatomic_inc(&pkt->io_wait);\n\t\tpkt_queue_bio(pd, bio);\n\t\tframes_read++;\n\t}\n\nout_account:\n\tdev_dbg(ddev, \"need %d frames for zone %llx\\n\", frames_read, pkt->sector);\n\tpd->stats.pkt_started++;\n\tpd->stats.secs_rg += frames_read * (CD_FRAMESIZE >> 9);\n}\n\n \nstatic struct packet_data *pkt_get_packet_data(struct pktcdvd_device *pd, int zone)\n{\n\tstruct packet_data *pkt;\n\n\tlist_for_each_entry(pkt, &pd->cdrw.pkt_free_list, list) {\n\t\tif (pkt->sector == zone || pkt->list.next == &pd->cdrw.pkt_free_list) {\n\t\t\tlist_del_init(&pkt->list);\n\t\t\tif (pkt->sector != zone)\n\t\t\t\tpkt->cache_valid = 0;\n\t\t\treturn pkt;\n\t\t}\n\t}\n\tBUG();\n\treturn NULL;\n}\n\nstatic void pkt_put_packet_data(struct pktcdvd_device *pd, struct packet_data *pkt)\n{\n\tif (pkt->cache_valid) {\n\t\tlist_add(&pkt->list, &pd->cdrw.pkt_free_list);\n\t} else {\n\t\tlist_add_tail(&pkt->list, &pd->cdrw.pkt_free_list);\n\t}\n}\n\nstatic inline void pkt_set_state(struct device *ddev, struct packet_data *pkt,\n\t\t\t\t enum packet_data_state state)\n{\n\tstatic const char *state_name[] = {\n\t\t\"IDLE\", \"WAITING\", \"READ_WAIT\", \"WRITE_WAIT\", \"RECOVERY\", \"FINISHED\"\n\t};\n\tenum packet_data_state old_state = pkt->state;\n\n\tdev_dbg(ddev, \"pkt %2d : s=%6llx %s -> %s\\n\",\n\t\tpkt->id, pkt->sector, state_name[old_state], state_name[state]);\n\n\tpkt->state = state;\n}\n\n \nstatic int pkt_handle_queue(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_data *pkt, *p;\n\tstruct bio *bio = NULL;\n\tsector_t zone = 0;  \n\tstruct pkt_rb_node *node, *first_node;\n\tstruct rb_node *n;\n\n\tatomic_set(&pd->scan_queue, 0);\n\n\tif (list_empty(&pd->cdrw.pkt_free_list)) {\n\t\tdev_dbg(ddev, \"no pkt\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tspin_lock(&pd->lock);\n\tfirst_node = pkt_rbtree_find(pd, pd->current_sector);\n\tif (!first_node) {\n\t\tn = rb_first(&pd->bio_queue);\n\t\tif (n)\n\t\t\tfirst_node = rb_entry(n, struct pkt_rb_node, rb_node);\n\t}\n\tnode = first_node;\n\twhile (node) {\n\t\tbio = node->bio;\n\t\tzone = get_zone(bio->bi_iter.bi_sector, pd);\n\t\tlist_for_each_entry(p, &pd->cdrw.pkt_active_list, list) {\n\t\t\tif (p->sector == zone) {\n\t\t\t\tbio = NULL;\n\t\t\t\tgoto try_next_bio;\n\t\t\t}\n\t\t}\n\t\tbreak;\ntry_next_bio:\n\t\tnode = pkt_rbtree_next(node);\n\t\tif (!node) {\n\t\t\tn = rb_first(&pd->bio_queue);\n\t\t\tif (n)\n\t\t\t\tnode = rb_entry(n, struct pkt_rb_node, rb_node);\n\t\t}\n\t\tif (node == first_node)\n\t\t\tnode = NULL;\n\t}\n\tspin_unlock(&pd->lock);\n\tif (!bio) {\n\t\tdev_dbg(ddev, \"no bio\\n\");\n\t\treturn 0;\n\t}\n\n\tpkt = pkt_get_packet_data(pd, zone);\n\n\tpd->current_sector = zone + pd->settings.size;\n\tpkt->sector = zone;\n\tBUG_ON(pkt->frames != pd->settings.size >> 2);\n\tpkt->write_size = 0;\n\n\t \n\tspin_lock(&pd->lock);\n\tdev_dbg(ddev, \"looking for zone %llx\\n\", zone);\n\twhile ((node = pkt_rbtree_find(pd, zone)) != NULL) {\n\t\tsector_t tmp = get_zone(node->bio->bi_iter.bi_sector, pd);\n\n\t\tbio = node->bio;\n\t\tdev_dbg(ddev, \"found zone=%llx\\n\", tmp);\n\t\tif (tmp != zone)\n\t\t\tbreak;\n\t\tpkt_rbtree_erase(pd, node);\n\t\tspin_lock(&pkt->lock);\n\t\tbio_list_add(&pkt->orig_bios, bio);\n\t\tpkt->write_size += bio->bi_iter.bi_size / CD_FRAMESIZE;\n\t\tspin_unlock(&pkt->lock);\n\t}\n\t \n\tif (pd->congested &&\n\t    pd->bio_queue_size <= pd->write_congestion_off) {\n\t\tpd->congested = false;\n\t\twake_up_var(&pd->congested);\n\t}\n\tspin_unlock(&pd->lock);\n\n\tpkt->sleep_time = max(PACKET_WAIT_TIME, 1);\n\tpkt_set_state(ddev, pkt, PACKET_WAITING_STATE);\n\tatomic_set(&pkt->run_sm, 1);\n\n\tspin_lock(&pd->cdrw.active_list_lock);\n\tlist_add(&pkt->list, &pd->cdrw.pkt_active_list);\n\tspin_unlock(&pd->cdrw.active_list_lock);\n\n\treturn 1;\n}\n\n \nstatic void bio_list_copy_data(struct bio *dst, struct bio *src)\n{\n\tstruct bvec_iter src_iter = src->bi_iter;\n\tstruct bvec_iter dst_iter = dst->bi_iter;\n\n\twhile (1) {\n\t\tif (!src_iter.bi_size) {\n\t\t\tsrc = src->bi_next;\n\t\t\tif (!src)\n\t\t\t\tbreak;\n\n\t\t\tsrc_iter = src->bi_iter;\n\t\t}\n\n\t\tif (!dst_iter.bi_size) {\n\t\t\tdst = dst->bi_next;\n\t\t\tif (!dst)\n\t\t\t\tbreak;\n\n\t\t\tdst_iter = dst->bi_iter;\n\t\t}\n\n\t\tbio_copy_data_iter(dst, &dst_iter, src, &src_iter);\n\t}\n}\n\n \nstatic void pkt_start_write(struct pktcdvd_device *pd, struct packet_data *pkt)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tint f;\n\n\tbio_init(pkt->w_bio, pd->bdev, pkt->w_bio->bi_inline_vecs, pkt->frames,\n\t\t REQ_OP_WRITE);\n\tpkt->w_bio->bi_iter.bi_sector = pkt->sector;\n\tpkt->w_bio->bi_end_io = pkt_end_io_packet_write;\n\tpkt->w_bio->bi_private = pkt;\n\n\t \n\tfor (f = 0; f < pkt->frames; f++) {\n\t\tstruct page *page = pkt->pages[(f * CD_FRAMESIZE) / PAGE_SIZE];\n\t\tunsigned offset = (f * CD_FRAMESIZE) % PAGE_SIZE;\n\n\t\tif (!bio_add_page(pkt->w_bio, page, CD_FRAMESIZE, offset))\n\t\t\tBUG();\n\t}\n\tdev_dbg(ddev, \"vcnt=%d\\n\", pkt->w_bio->bi_vcnt);\n\n\t \n\tspin_lock(&pkt->lock);\n\tbio_list_copy_data(pkt->w_bio, pkt->orig_bios.head);\n\n\tpkt_set_state(ddev, pkt, PACKET_WRITE_WAIT_STATE);\n\tspin_unlock(&pkt->lock);\n\n\tdev_dbg(ddev, \"Writing %d frames for zone %llx\\n\", pkt->write_size, pkt->sector);\n\n\tif (test_bit(PACKET_MERGE_SEGS, &pd->flags) || (pkt->write_size < pkt->frames))\n\t\tpkt->cache_valid = 1;\n\telse\n\t\tpkt->cache_valid = 0;\n\n\t \n\tatomic_set(&pkt->io_wait, 1);\n\tpkt_queue_bio(pd, pkt->w_bio);\n}\n\nstatic void pkt_finish_packet(struct packet_data *pkt, blk_status_t status)\n{\n\tstruct bio *bio;\n\n\tif (status)\n\t\tpkt->cache_valid = 0;\n\n\t \n\twhile ((bio = bio_list_pop(&pkt->orig_bios))) {\n\t\tbio->bi_status = status;\n\t\tbio_endio(bio);\n\t}\n}\n\nstatic void pkt_run_state_machine(struct pktcdvd_device *pd, struct packet_data *pkt)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\n\tdev_dbg(ddev, \"pkt %d\\n\", pkt->id);\n\n\tfor (;;) {\n\t\tswitch (pkt->state) {\n\t\tcase PACKET_WAITING_STATE:\n\t\t\tif ((pkt->write_size < pkt->frames) && (pkt->sleep_time > 0))\n\t\t\t\treturn;\n\n\t\t\tpkt->sleep_time = 0;\n\t\t\tpkt_gather_data(pd, pkt);\n\t\t\tpkt_set_state(ddev, pkt, PACKET_READ_WAIT_STATE);\n\t\t\tbreak;\n\n\t\tcase PACKET_READ_WAIT_STATE:\n\t\t\tif (atomic_read(&pkt->io_wait) > 0)\n\t\t\t\treturn;\n\n\t\t\tif (atomic_read(&pkt->io_errors) > 0) {\n\t\t\t\tpkt_set_state(ddev, pkt, PACKET_RECOVERY_STATE);\n\t\t\t} else {\n\t\t\t\tpkt_start_write(pd, pkt);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PACKET_WRITE_WAIT_STATE:\n\t\t\tif (atomic_read(&pkt->io_wait) > 0)\n\t\t\t\treturn;\n\n\t\t\tif (!pkt->w_bio->bi_status) {\n\t\t\t\tpkt_set_state(ddev, pkt, PACKET_FINISHED_STATE);\n\t\t\t} else {\n\t\t\t\tpkt_set_state(ddev, pkt, PACKET_RECOVERY_STATE);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PACKET_RECOVERY_STATE:\n\t\t\tdev_dbg(ddev, \"No recovery possible\\n\");\n\t\t\tpkt_set_state(ddev, pkt, PACKET_FINISHED_STATE);\n\t\t\tbreak;\n\n\t\tcase PACKET_FINISHED_STATE:\n\t\t\tpkt_finish_packet(pkt, pkt->w_bio->bi_status);\n\t\t\treturn;\n\n\t\tdefault:\n\t\t\tBUG();\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void pkt_handle_packets(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_data *pkt, *next;\n\n\t \n\tlist_for_each_entry(pkt, &pd->cdrw.pkt_active_list, list) {\n\t\tif (atomic_read(&pkt->run_sm) > 0) {\n\t\t\tatomic_set(&pkt->run_sm, 0);\n\t\t\tpkt_run_state_machine(pd, pkt);\n\t\t}\n\t}\n\n\t \n\tspin_lock(&pd->cdrw.active_list_lock);\n\tlist_for_each_entry_safe(pkt, next, &pd->cdrw.pkt_active_list, list) {\n\t\tif (pkt->state == PACKET_FINISHED_STATE) {\n\t\t\tlist_del(&pkt->list);\n\t\t\tpkt_put_packet_data(pd, pkt);\n\t\t\tpkt_set_state(ddev, pkt, PACKET_IDLE_STATE);\n\t\t\tatomic_set(&pd->scan_queue, 1);\n\t\t}\n\t}\n\tspin_unlock(&pd->cdrw.active_list_lock);\n}\n\n \nstatic int kcdrwd(void *foobar)\n{\n\tstruct pktcdvd_device *pd = foobar;\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_data *pkt;\n\tint states[PACKET_NUM_STATES];\n\tlong min_sleep_time, residue;\n\n\tset_user_nice(current, MIN_NICE);\n\tset_freezable();\n\n\tfor (;;) {\n\t\tDECLARE_WAITQUEUE(wait, current);\n\n\t\t \n\t\tadd_wait_queue(&pd->wqueue, &wait);\n\t\tfor (;;) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t\t\t \n\t\t\tif (atomic_read(&pd->scan_queue) > 0)\n\t\t\t\tgoto work_to_do;\n\n\t\t\t \n\t\t\tlist_for_each_entry(pkt, &pd->cdrw.pkt_active_list, list) {\n\t\t\t\tif (atomic_read(&pkt->run_sm) > 0)\n\t\t\t\t\tgoto work_to_do;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (atomic_read(&pd->iosched.attention) != 0)\n\t\t\t\tgoto work_to_do;\n\n\t\t\t \n\t\t\tpkt_count_states(pd, states);\n\t\t\tdev_dbg(ddev, \"i:%d ow:%d rw:%d ww:%d rec:%d fin:%d\\n\",\n\t\t\t\tstates[0], states[1], states[2], states[3], states[4], states[5]);\n\n\t\t\tmin_sleep_time = MAX_SCHEDULE_TIMEOUT;\n\t\t\tlist_for_each_entry(pkt, &pd->cdrw.pkt_active_list, list) {\n\t\t\t\tif (pkt->sleep_time && pkt->sleep_time < min_sleep_time)\n\t\t\t\t\tmin_sleep_time = pkt->sleep_time;\n\t\t\t}\n\n\t\t\tdev_dbg(ddev, \"sleeping\\n\");\n\t\t\tresidue = schedule_timeout(min_sleep_time);\n\t\t\tdev_dbg(ddev, \"wake up\\n\");\n\n\t\t\t \n\t\t\ttry_to_freeze();\n\n\t\t\tlist_for_each_entry(pkt, &pd->cdrw.pkt_active_list, list) {\n\t\t\t\tif (!pkt->sleep_time)\n\t\t\t\t\tcontinue;\n\t\t\t\tpkt->sleep_time -= min_sleep_time - residue;\n\t\t\t\tif (pkt->sleep_time <= 0) {\n\t\t\t\t\tpkt->sleep_time = 0;\n\t\t\t\t\tatomic_inc(&pkt->run_sm);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (kthread_should_stop())\n\t\t\t\tbreak;\n\t\t}\nwork_to_do:\n\t\tset_current_state(TASK_RUNNING);\n\t\tremove_wait_queue(&pd->wqueue, &wait);\n\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\n\t\t \n\t\twhile (pkt_handle_queue(pd))\n\t\t\t;\n\n\t\t \n\t\tpkt_handle_packets(pd);\n\n\t\t \n\t\tpkt_iosched_process_queue(pd);\n\t}\n\n\treturn 0;\n}\n\nstatic void pkt_print_settings(struct pktcdvd_device *pd)\n{\n\tdev_info(disk_to_dev(pd->disk), \"%s packets, %u blocks, Mode-%c disc\\n\",\n\t\t pd->settings.fp ? \"Fixed\" : \"Variable\",\n\t\t pd->settings.size >> 2,\n\t\t pd->settings.block_mode == 8 ? '1' : '2');\n}\n\nstatic int pkt_mode_sense(struct pktcdvd_device *pd, struct packet_command *cgc, int page_code, int page_control)\n{\n\tmemset(cgc->cmd, 0, sizeof(cgc->cmd));\n\n\tcgc->cmd[0] = GPCMD_MODE_SENSE_10;\n\tcgc->cmd[2] = page_code | (page_control << 6);\n\tput_unaligned_be16(cgc->buflen, &cgc->cmd[7]);\n\tcgc->data_direction = CGC_DATA_READ;\n\treturn pkt_generic_packet(pd, cgc);\n}\n\nstatic int pkt_mode_select(struct pktcdvd_device *pd, struct packet_command *cgc)\n{\n\tmemset(cgc->cmd, 0, sizeof(cgc->cmd));\n\tmemset(cgc->buffer, 0, 2);\n\tcgc->cmd[0] = GPCMD_MODE_SELECT_10;\n\tcgc->cmd[1] = 0x10;\t\t \n\tput_unaligned_be16(cgc->buflen, &cgc->cmd[7]);\n\tcgc->data_direction = CGC_DATA_WRITE;\n\treturn pkt_generic_packet(pd, cgc);\n}\n\nstatic int pkt_get_disc_info(struct pktcdvd_device *pd, disc_information *di)\n{\n\tstruct packet_command cgc;\n\tint ret;\n\n\t \n\tinit_cdrom_command(&cgc, di, sizeof(*di), CGC_DATA_READ);\n\tcgc.cmd[0] = GPCMD_READ_DISC_INFO;\n\tcgc.cmd[8] = cgc.buflen = 2;\n\tcgc.quiet = 1;\n\n\tret = pkt_generic_packet(pd, &cgc);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tcgc.buflen = be16_to_cpu(di->disc_information_length) +\n\t\t     sizeof(di->disc_information_length);\n\n\tif (cgc.buflen > sizeof(disc_information))\n\t\tcgc.buflen = sizeof(disc_information);\n\n\tcgc.cmd[8] = cgc.buflen;\n\treturn pkt_generic_packet(pd, &cgc);\n}\n\nstatic int pkt_get_track_info(struct pktcdvd_device *pd, __u16 track, __u8 type, track_information *ti)\n{\n\tstruct packet_command cgc;\n\tint ret;\n\n\tinit_cdrom_command(&cgc, ti, 8, CGC_DATA_READ);\n\tcgc.cmd[0] = GPCMD_READ_TRACK_RZONE_INFO;\n\tcgc.cmd[1] = type & 3;\n\tput_unaligned_be16(track, &cgc.cmd[4]);\n\tcgc.cmd[8] = 8;\n\tcgc.quiet = 1;\n\n\tret = pkt_generic_packet(pd, &cgc);\n\tif (ret)\n\t\treturn ret;\n\n\tcgc.buflen = be16_to_cpu(ti->track_information_length) +\n\t\t     sizeof(ti->track_information_length);\n\n\tif (cgc.buflen > sizeof(track_information))\n\t\tcgc.buflen = sizeof(track_information);\n\n\tcgc.cmd[8] = cgc.buflen;\n\treturn pkt_generic_packet(pd, &cgc);\n}\n\nstatic noinline_for_stack int pkt_get_last_written(struct pktcdvd_device *pd,\n\t\t\t\t\t\tlong *last_written)\n{\n\tdisc_information di;\n\ttrack_information ti;\n\t__u32 last_track;\n\tint ret;\n\n\tret = pkt_get_disc_info(pd, &di);\n\tif (ret)\n\t\treturn ret;\n\n\tlast_track = (di.last_track_msb << 8) | di.last_track_lsb;\n\tret = pkt_get_track_info(pd, last_track, 1, &ti);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (ti.blank) {\n\t\tlast_track--;\n\t\tret = pkt_get_track_info(pd, last_track, 1, &ti);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t \n\tif (ti.lra_v) {\n\t\t*last_written = be32_to_cpu(ti.last_rec_address);\n\t} else {\n\t\t \n\t\t*last_written = be32_to_cpu(ti.track_start) +\n\t\t\t\tbe32_to_cpu(ti.track_size);\n\t\tif (ti.free_blocks)\n\t\t\t*last_written -= (be32_to_cpu(ti.free_blocks) + 7);\n\t}\n\treturn 0;\n}\n\n \nstatic noinline_for_stack int pkt_set_write_settings(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_command cgc;\n\tstruct scsi_sense_hdr sshdr;\n\twrite_param_page *wp;\n\tchar buffer[128];\n\tint ret, size;\n\n\t \n\tif ((pd->mmc3_profile == 0x1a) || (pd->mmc3_profile == 0x12))\n\t\treturn 0;\n\n\tmemset(buffer, 0, sizeof(buffer));\n\tinit_cdrom_command(&cgc, buffer, sizeof(*wp), CGC_DATA_READ);\n\tcgc.sshdr = &sshdr;\n\tret = pkt_mode_sense(pd, &cgc, GPMODE_WRITE_PARMS_PAGE, 0);\n\tif (ret) {\n\t\tpkt_dump_sense(pd, &cgc);\n\t\treturn ret;\n\t}\n\n\tsize = 2 + get_unaligned_be16(&buffer[0]);\n\tpd->mode_offset = get_unaligned_be16(&buffer[6]);\n\tif (size > sizeof(buffer))\n\t\tsize = sizeof(buffer);\n\n\t \n\tinit_cdrom_command(&cgc, buffer, size, CGC_DATA_READ);\n\tcgc.sshdr = &sshdr;\n\tret = pkt_mode_sense(pd, &cgc, GPMODE_WRITE_PARMS_PAGE, 0);\n\tif (ret) {\n\t\tpkt_dump_sense(pd, &cgc);\n\t\treturn ret;\n\t}\n\n\t \n\twp = (write_param_page *) &buffer[sizeof(struct mode_page_header) + pd->mode_offset];\n\n\twp->fp = pd->settings.fp;\n\twp->track_mode = pd->settings.track_mode;\n\twp->write_type = pd->settings.write_type;\n\twp->data_block_type = pd->settings.block_mode;\n\n\twp->multi_session = 0;\n\n#ifdef PACKET_USE_LS\n\twp->link_size = 7;\n\twp->ls_v = 1;\n#endif\n\n\tif (wp->data_block_type == PACKET_BLOCK_MODE1) {\n\t\twp->session_format = 0;\n\t\twp->subhdr2 = 0x20;\n\t} else if (wp->data_block_type == PACKET_BLOCK_MODE2) {\n\t\twp->session_format = 0x20;\n\t\twp->subhdr2 = 8;\n#if 0\n\t\twp->mcn[0] = 0x80;\n\t\tmemcpy(&wp->mcn[1], PACKET_MCN, sizeof(wp->mcn) - 1);\n#endif\n\t} else {\n\t\t \n\t\tdev_err(ddev, \"write mode wrong %d\\n\", wp->data_block_type);\n\t\treturn 1;\n\t}\n\twp->packet_size = cpu_to_be32(pd->settings.size >> 2);\n\n\tcgc.buflen = cgc.cmd[8] = size;\n\tret = pkt_mode_select(pd, &cgc);\n\tif (ret) {\n\t\tpkt_dump_sense(pd, &cgc);\n\t\treturn ret;\n\t}\n\n\tpkt_print_settings(pd);\n\treturn 0;\n}\n\n \nstatic int pkt_writable_track(struct pktcdvd_device *pd, track_information *ti)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\n\tswitch (pd->mmc3_profile) {\n\t\tcase 0x1a:  \n\t\tcase 0x12:  \n\t\t\t \n\t\t\treturn 1;\n\t\tdefault:\n\t\t\tbreak;\n\t}\n\n\tif (!ti->packet || !ti->fp)\n\t\treturn 0;\n\n\t \n\tif (ti->rt == 0 && ti->blank == 0)\n\t\treturn 1;\n\n\tif (ti->rt == 0 && ti->blank == 1)\n\t\treturn 1;\n\n\tif (ti->rt == 1 && ti->blank == 0)\n\t\treturn 1;\n\n\tdev_err(ddev, \"bad state %d-%d-%d\\n\", ti->rt, ti->blank, ti->packet);\n\treturn 0;\n}\n\n \nstatic int pkt_writable_disc(struct pktcdvd_device *pd, disc_information *di)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\n\tswitch (pd->mmc3_profile) {\n\t\tcase 0x0a:  \n\t\tcase 0xffff:  \n\t\t\tbreak;\n\t\tcase 0x1a:  \n\t\tcase 0x13:  \n\t\tcase 0x12:  \n\t\t\treturn 1;\n\t\tdefault:\n\t\t\tdev_dbg(ddev, \"Wrong disc profile (%x)\\n\", pd->mmc3_profile);\n\t\t\treturn 0;\n\t}\n\n\t \n\tif (di->disc_type == 0xff) {\n\t\tdev_notice(ddev, \"unknown disc - no track?\\n\");\n\t\treturn 0;\n\t}\n\n\tif (di->disc_type != 0x20 && di->disc_type != 0) {\n\t\tdev_err(ddev, \"wrong disc type (%x)\\n\", di->disc_type);\n\t\treturn 0;\n\t}\n\n\tif (di->erasable == 0) {\n\t\tdev_err(ddev, \"disc not erasable\\n\");\n\t\treturn 0;\n\t}\n\n\tif (di->border_status == PACKET_SESSION_RESERVED) {\n\t\tdev_err(ddev, \"can't write to last track (reserved)\\n\");\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic noinline_for_stack int pkt_probe_settings(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_command cgc;\n\tunsigned char buf[12];\n\tdisc_information di;\n\ttrack_information ti;\n\tint ret, track;\n\n\tinit_cdrom_command(&cgc, buf, sizeof(buf), CGC_DATA_READ);\n\tcgc.cmd[0] = GPCMD_GET_CONFIGURATION;\n\tcgc.cmd[8] = 8;\n\tret = pkt_generic_packet(pd, &cgc);\n\tpd->mmc3_profile = ret ? 0xffff : get_unaligned_be16(&buf[6]);\n\n\tmemset(&di, 0, sizeof(disc_information));\n\tmemset(&ti, 0, sizeof(track_information));\n\n\tret = pkt_get_disc_info(pd, &di);\n\tif (ret) {\n\t\tdev_err(ddev, \"failed get_disc\\n\");\n\t\treturn ret;\n\t}\n\n\tif (!pkt_writable_disc(pd, &di))\n\t\treturn -EROFS;\n\n\tpd->type = di.erasable ? PACKET_CDRW : PACKET_CDR;\n\n\ttrack = 1;  \n\tret = pkt_get_track_info(pd, track, 1, &ti);\n\tif (ret) {\n\t\tdev_err(ddev, \"failed get_track\\n\");\n\t\treturn ret;\n\t}\n\n\tif (!pkt_writable_track(pd, &ti)) {\n\t\tdev_err(ddev, \"can't write to this track\\n\");\n\t\treturn -EROFS;\n\t}\n\n\t \n\tpd->settings.size = be32_to_cpu(ti.fixed_packet_size) << 2;\n\tif (pd->settings.size == 0) {\n\t\tdev_notice(ddev, \"detected zero packet size!\\n\");\n\t\treturn -ENXIO;\n\t}\n\tif (pd->settings.size > PACKET_MAX_SECTORS) {\n\t\tdev_err(ddev, \"packet size is too big\\n\");\n\t\treturn -EROFS;\n\t}\n\tpd->settings.fp = ti.fp;\n\tpd->offset = (be32_to_cpu(ti.track_start) << 2) & (pd->settings.size - 1);\n\n\tif (ti.nwa_v) {\n\t\tpd->nwa = be32_to_cpu(ti.next_writable);\n\t\tset_bit(PACKET_NWA_VALID, &pd->flags);\n\t}\n\n\t \n\tif (ti.lra_v) {\n\t\tpd->lra = be32_to_cpu(ti.last_rec_address);\n\t\tset_bit(PACKET_LRA_VALID, &pd->flags);\n\t} else {\n\t\tpd->lra = 0xffffffff;\n\t\tset_bit(PACKET_LRA_VALID, &pd->flags);\n\t}\n\n\t \n\tpd->settings.link_loss = 7;\n\tpd->settings.write_type = 0;\t \n\tpd->settings.track_mode = ti.track_mode;\n\n\t \n\tswitch (ti.data_mode) {\n\t\tcase PACKET_MODE1:\n\t\t\tpd->settings.block_mode = PACKET_BLOCK_MODE1;\n\t\t\tbreak;\n\t\tcase PACKET_MODE2:\n\t\t\tpd->settings.block_mode = PACKET_BLOCK_MODE2;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(ddev, \"unknown data mode\\n\");\n\t\t\treturn -EROFS;\n\t}\n\treturn 0;\n}\n\n \nstatic noinline_for_stack int pkt_write_caching(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_command cgc;\n\tstruct scsi_sense_hdr sshdr;\n\tunsigned char buf[64];\n\tbool set = IS_ENABLED(CONFIG_CDROM_PKTCDVD_WCACHE);\n\tint ret;\n\n\tinit_cdrom_command(&cgc, buf, sizeof(buf), CGC_DATA_READ);\n\tcgc.sshdr = &sshdr;\n\tcgc.buflen = pd->mode_offset + 12;\n\n\t \n\tcgc.quiet = 1;\n\n\tret = pkt_mode_sense(pd, &cgc, GPMODE_WCACHING_PAGE, 0);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tbuf[pd->mode_offset + 10] |= (set << 2);\n\n\tcgc.buflen = cgc.cmd[8] = 2 + get_unaligned_be16(&buf[0]);\n\tret = pkt_mode_select(pd, &cgc);\n\tif (ret) {\n\t\tdev_err(ddev, \"write caching control failed\\n\");\n\t\tpkt_dump_sense(pd, &cgc);\n\t} else if (!ret && set)\n\t\tdev_notice(ddev, \"enabled write caching\\n\");\n\treturn ret;\n}\n\nstatic int pkt_lock_door(struct pktcdvd_device *pd, int lockflag)\n{\n\tstruct packet_command cgc;\n\n\tinit_cdrom_command(&cgc, NULL, 0, CGC_DATA_NONE);\n\tcgc.cmd[0] = GPCMD_PREVENT_ALLOW_MEDIUM_REMOVAL;\n\tcgc.cmd[4] = lockflag ? 1 : 0;\n\treturn pkt_generic_packet(pd, &cgc);\n}\n\n \nstatic noinline_for_stack int pkt_get_max_speed(struct pktcdvd_device *pd,\n\t\t\t\t\t\tunsigned *write_speed)\n{\n\tstruct packet_command cgc;\n\tstruct scsi_sense_hdr sshdr;\n\tunsigned char buf[256+18];\n\tunsigned char *cap_buf;\n\tint ret, offset;\n\n\tcap_buf = &buf[sizeof(struct mode_page_header) + pd->mode_offset];\n\tinit_cdrom_command(&cgc, buf, sizeof(buf), CGC_DATA_UNKNOWN);\n\tcgc.sshdr = &sshdr;\n\n\tret = pkt_mode_sense(pd, &cgc, GPMODE_CAPABILITIES_PAGE, 0);\n\tif (ret) {\n\t\tcgc.buflen = pd->mode_offset + cap_buf[1] + 2 +\n\t\t\t     sizeof(struct mode_page_header);\n\t\tret = pkt_mode_sense(pd, &cgc, GPMODE_CAPABILITIES_PAGE, 0);\n\t\tif (ret) {\n\t\t\tpkt_dump_sense(pd, &cgc);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\toffset = 20;\t\t\t     \n\tif (cap_buf[1] >= 28)\n\t\toffset = 28;\t\t     \n\tif (cap_buf[1] >= 30) {\n\t\t \n\t\tint num_spdb = get_unaligned_be16(&cap_buf[30]);\n\t\tif (num_spdb > 0)\n\t\t\toffset = 34;\n\t}\n\n\t*write_speed = get_unaligned_be16(&cap_buf[offset]);\n\treturn 0;\n}\n\n \n \nstatic char clv_to_speed[16] = {\n\t \n\t   0, 2, 4, 6, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n};\n \nstatic char hs_clv_to_speed[16] = {\n\t \n\t   0, 2, 4, 6, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n};\n \nstatic char us_clv_to_speed[16] = {\n\t \n\t   0, 2, 4, 8, 0, 0,16, 0,24,32,40,48, 0, 0, 0, 0\n};\n\n \nstatic noinline_for_stack int pkt_media_speed(struct pktcdvd_device *pd,\n\t\t\t\t\t\tunsigned *speed)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_command cgc;\n\tstruct scsi_sense_hdr sshdr;\n\tunsigned char buf[64];\n\tunsigned int size, st, sp;\n\tint ret;\n\n\tinit_cdrom_command(&cgc, buf, 2, CGC_DATA_READ);\n\tcgc.sshdr = &sshdr;\n\tcgc.cmd[0] = GPCMD_READ_TOC_PMA_ATIP;\n\tcgc.cmd[1] = 2;\n\tcgc.cmd[2] = 4;  \n\tcgc.cmd[8] = 2;\n\tret = pkt_generic_packet(pd, &cgc);\n\tif (ret) {\n\t\tpkt_dump_sense(pd, &cgc);\n\t\treturn ret;\n\t}\n\tsize = 2 + get_unaligned_be16(&buf[0]);\n\tif (size > sizeof(buf))\n\t\tsize = sizeof(buf);\n\n\tinit_cdrom_command(&cgc, buf, size, CGC_DATA_READ);\n\tcgc.sshdr = &sshdr;\n\tcgc.cmd[0] = GPCMD_READ_TOC_PMA_ATIP;\n\tcgc.cmd[1] = 2;\n\tcgc.cmd[2] = 4;\n\tcgc.cmd[8] = size;\n\tret = pkt_generic_packet(pd, &cgc);\n\tif (ret) {\n\t\tpkt_dump_sense(pd, &cgc);\n\t\treturn ret;\n\t}\n\n\tif (!(buf[6] & 0x40)) {\n\t\tdev_notice(ddev, \"disc type is not CD-RW\\n\");\n\t\treturn 1;\n\t}\n\tif (!(buf[6] & 0x4)) {\n\t\tdev_notice(ddev, \"A1 values on media are not valid, maybe not CDRW?\\n\");\n\t\treturn 1;\n\t}\n\n\tst = (buf[6] >> 3) & 0x7;  \n\n\tsp = buf[16] & 0xf;  \n\n\t \n\tswitch (st) {\n\t\tcase 0:  \n\t\t\t*speed = clv_to_speed[sp];\n\t\t\tbreak;\n\t\tcase 1:  \n\t\t\t*speed = hs_clv_to_speed[sp];\n\t\t\tbreak;\n\t\tcase 2:  \n\t\t\t*speed = us_clv_to_speed[sp];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_notice(ddev, \"unknown disc sub-type %d\\n\", st);\n\t\t\treturn 1;\n\t}\n\tif (*speed) {\n\t\tdev_info(ddev, \"maximum media speed: %d\\n\", *speed);\n\t\treturn 0;\n\t} else {\n\t\tdev_notice(ddev, \"unknown speed %d for sub-type %d\\n\", sp, st);\n\t\treturn 1;\n\t}\n}\n\nstatic noinline_for_stack int pkt_perform_opc(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct packet_command cgc;\n\tstruct scsi_sense_hdr sshdr;\n\tint ret;\n\n\tdev_dbg(ddev, \"Performing OPC\\n\");\n\n\tinit_cdrom_command(&cgc, NULL, 0, CGC_DATA_NONE);\n\tcgc.sshdr = &sshdr;\n\tcgc.timeout = 60*HZ;\n\tcgc.cmd[0] = GPCMD_SEND_OPC;\n\tcgc.cmd[1] = 1;\n\tret = pkt_generic_packet(pd, &cgc);\n\tif (ret)\n\t\tpkt_dump_sense(pd, &cgc);\n\treturn ret;\n}\n\nstatic int pkt_open_write(struct pktcdvd_device *pd)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tint ret;\n\tunsigned int write_speed, media_write_speed, read_speed;\n\n\tret = pkt_probe_settings(pd);\n\tif (ret) {\n\t\tdev_dbg(ddev, \"failed probe\\n\");\n\t\treturn ret;\n\t}\n\n\tret = pkt_set_write_settings(pd);\n\tif (ret) {\n\t\tdev_notice(ddev, \"failed saving write settings\\n\");\n\t\treturn -EIO;\n\t}\n\n\tpkt_write_caching(pd);\n\n\tret = pkt_get_max_speed(pd, &write_speed);\n\tif (ret)\n\t\twrite_speed = 16 * 177;\n\tswitch (pd->mmc3_profile) {\n\t\tcase 0x13:  \n\t\tcase 0x1a:  \n\t\tcase 0x12:  \n\t\t\tdev_notice(ddev, \"write speed %ukB/s\\n\", write_speed);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = pkt_media_speed(pd, &media_write_speed);\n\t\t\tif (ret)\n\t\t\t\tmedia_write_speed = 16;\n\t\t\twrite_speed = min(write_speed, media_write_speed * 177);\n\t\t\tdev_notice(ddev, \"write speed %ux\\n\", write_speed / 176);\n\t\t\tbreak;\n\t}\n\tread_speed = write_speed;\n\n\tret = pkt_set_speed(pd, write_speed, read_speed);\n\tif (ret) {\n\t\tdev_notice(ddev, \"couldn't set write speed\\n\");\n\t\treturn -EIO;\n\t}\n\tpd->write_speed = write_speed;\n\tpd->read_speed = read_speed;\n\n\tret = pkt_perform_opc(pd);\n\tif (ret)\n\t\tdev_notice(ddev, \"Optimum Power Calibration failed\\n\");\n\n\treturn 0;\n}\n\n \nstatic int pkt_open_dev(struct pktcdvd_device *pd, bool write)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tint ret;\n\tlong lba;\n\tstruct request_queue *q;\n\tstruct block_device *bdev;\n\n\t \n\tbdev = blkdev_get_by_dev(pd->bdev->bd_dev, BLK_OPEN_READ, pd, NULL);\n\tif (IS_ERR(bdev)) {\n\t\tret = PTR_ERR(bdev);\n\t\tgoto out;\n\t}\n\n\tret = pkt_get_last_written(pd, &lba);\n\tif (ret) {\n\t\tdev_err(ddev, \"pkt_get_last_written failed\\n\");\n\t\tgoto out_putdev;\n\t}\n\n\tset_capacity(pd->disk, lba << 2);\n\tset_capacity_and_notify(pd->bdev->bd_disk, lba << 2);\n\n\tq = bdev_get_queue(pd->bdev);\n\tif (write) {\n\t\tret = pkt_open_write(pd);\n\t\tif (ret)\n\t\t\tgoto out_putdev;\n\t\t \n\t\tblk_queue_max_hw_sectors(q, pd->settings.size);\n\t\tset_bit(PACKET_WRITABLE, &pd->flags);\n\t} else {\n\t\tpkt_set_speed(pd, MAX_SPEED, MAX_SPEED);\n\t\tclear_bit(PACKET_WRITABLE, &pd->flags);\n\t}\n\n\tret = pkt_set_segment_merging(pd, q);\n\tif (ret)\n\t\tgoto out_putdev;\n\n\tif (write) {\n\t\tif (!pkt_grow_pktlist(pd, CONFIG_CDROM_PKTCDVD_BUFFERS)) {\n\t\t\tdev_err(ddev, \"not enough memory for buffers\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_putdev;\n\t\t}\n\t\tdev_info(ddev, \"%lukB available on disc\\n\", lba << 1);\n\t}\n\n\treturn 0;\n\nout_putdev:\n\tblkdev_put(bdev, pd);\nout:\n\treturn ret;\n}\n\n \nstatic void pkt_release_dev(struct pktcdvd_device *pd, int flush)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\n\tif (flush && pkt_flush_cache(pd))\n\t\tdev_notice(ddev, \"not flushing cache\\n\");\n\n\tpkt_lock_door(pd, 0);\n\n\tpkt_set_speed(pd, MAX_SPEED, MAX_SPEED);\n\tblkdev_put(pd->bdev, pd);\n\n\tpkt_shrink_pktlist(pd);\n}\n\nstatic struct pktcdvd_device *pkt_find_dev_from_minor(unsigned int dev_minor)\n{\n\tif (dev_minor >= MAX_WRITERS)\n\t\treturn NULL;\n\n\tdev_minor = array_index_nospec(dev_minor, MAX_WRITERS);\n\treturn pkt_devs[dev_minor];\n}\n\nstatic int pkt_open(struct gendisk *disk, blk_mode_t mode)\n{\n\tstruct pktcdvd_device *pd = NULL;\n\tint ret;\n\n\tmutex_lock(&pktcdvd_mutex);\n\tmutex_lock(&ctl_mutex);\n\tpd = pkt_find_dev_from_minor(disk->first_minor);\n\tif (!pd) {\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\tBUG_ON(pd->refcnt < 0);\n\n\tpd->refcnt++;\n\tif (pd->refcnt > 1) {\n\t\tif ((mode & BLK_OPEN_WRITE) &&\n\t\t    !test_bit(PACKET_WRITABLE, &pd->flags)) {\n\t\t\tret = -EBUSY;\n\t\t\tgoto out_dec;\n\t\t}\n\t} else {\n\t\tret = pkt_open_dev(pd, mode & BLK_OPEN_WRITE);\n\t\tif (ret)\n\t\t\tgoto out_dec;\n\t\t \n\t\tset_blocksize(disk->part0, CD_FRAMESIZE);\n\t}\n\tmutex_unlock(&ctl_mutex);\n\tmutex_unlock(&pktcdvd_mutex);\n\treturn 0;\n\nout_dec:\n\tpd->refcnt--;\nout:\n\tmutex_unlock(&ctl_mutex);\n\tmutex_unlock(&pktcdvd_mutex);\n\treturn ret;\n}\n\nstatic void pkt_release(struct gendisk *disk)\n{\n\tstruct pktcdvd_device *pd = disk->private_data;\n\n\tmutex_lock(&pktcdvd_mutex);\n\tmutex_lock(&ctl_mutex);\n\tpd->refcnt--;\n\tBUG_ON(pd->refcnt < 0);\n\tif (pd->refcnt == 0) {\n\t\tint flush = test_bit(PACKET_WRITABLE, &pd->flags);\n\t\tpkt_release_dev(pd, flush);\n\t}\n\tmutex_unlock(&ctl_mutex);\n\tmutex_unlock(&pktcdvd_mutex);\n}\n\n\nstatic void pkt_end_io_read_cloned(struct bio *bio)\n{\n\tstruct packet_stacked_data *psd = bio->bi_private;\n\tstruct pktcdvd_device *pd = psd->pd;\n\n\tpsd->bio->bi_status = bio->bi_status;\n\tbio_put(bio);\n\tbio_endio(psd->bio);\n\tmempool_free(psd, &psd_pool);\n\tpkt_bio_finished(pd);\n}\n\nstatic void pkt_make_request_read(struct pktcdvd_device *pd, struct bio *bio)\n{\n\tstruct bio *cloned_bio =\n\t\tbio_alloc_clone(pd->bdev, bio, GFP_NOIO, &pkt_bio_set);\n\tstruct packet_stacked_data *psd = mempool_alloc(&psd_pool, GFP_NOIO);\n\n\tpsd->pd = pd;\n\tpsd->bio = bio;\n\tcloned_bio->bi_private = psd;\n\tcloned_bio->bi_end_io = pkt_end_io_read_cloned;\n\tpd->stats.secs_r += bio_sectors(bio);\n\tpkt_queue_bio(pd, cloned_bio);\n}\n\nstatic void pkt_make_request_write(struct request_queue *q, struct bio *bio)\n{\n\tstruct pktcdvd_device *pd = q->queuedata;\n\tsector_t zone;\n\tstruct packet_data *pkt;\n\tint was_empty, blocked_bio;\n\tstruct pkt_rb_node *node;\n\n\tzone = get_zone(bio->bi_iter.bi_sector, pd);\n\n\t \n\tspin_lock(&pd->cdrw.active_list_lock);\n\tblocked_bio = 0;\n\tlist_for_each_entry(pkt, &pd->cdrw.pkt_active_list, list) {\n\t\tif (pkt->sector == zone) {\n\t\t\tspin_lock(&pkt->lock);\n\t\t\tif ((pkt->state == PACKET_WAITING_STATE) ||\n\t\t\t    (pkt->state == PACKET_READ_WAIT_STATE)) {\n\t\t\t\tbio_list_add(&pkt->orig_bios, bio);\n\t\t\t\tpkt->write_size +=\n\t\t\t\t\tbio->bi_iter.bi_size / CD_FRAMESIZE;\n\t\t\t\tif ((pkt->write_size >= pkt->frames) &&\n\t\t\t\t    (pkt->state == PACKET_WAITING_STATE)) {\n\t\t\t\t\tatomic_inc(&pkt->run_sm);\n\t\t\t\t\twake_up(&pd->wqueue);\n\t\t\t\t}\n\t\t\t\tspin_unlock(&pkt->lock);\n\t\t\t\tspin_unlock(&pd->cdrw.active_list_lock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tblocked_bio = 1;\n\t\t\t}\n\t\t\tspin_unlock(&pkt->lock);\n\t\t}\n\t}\n\tspin_unlock(&pd->cdrw.active_list_lock);\n\n\t \n\tspin_lock(&pd->lock);\n\tif (pd->write_congestion_on > 0\n\t    && pd->bio_queue_size >= pd->write_congestion_on) {\n\t\tstruct wait_bit_queue_entry wqe;\n\n\t\tinit_wait_var_entry(&wqe, &pd->congested, 0);\n\t\tfor (;;) {\n\t\t\tprepare_to_wait_event(__var_waitqueue(&pd->congested),\n\t\t\t\t\t      &wqe.wq_entry,\n\t\t\t\t\t      TASK_UNINTERRUPTIBLE);\n\t\t\tif (pd->bio_queue_size <= pd->write_congestion_off)\n\t\t\t\tbreak;\n\t\t\tpd->congested = true;\n\t\t\tspin_unlock(&pd->lock);\n\t\t\tschedule();\n\t\t\tspin_lock(&pd->lock);\n\t\t}\n\t}\n\tspin_unlock(&pd->lock);\n\n\t \n\tnode = mempool_alloc(&pd->rb_pool, GFP_NOIO);\n\tnode->bio = bio;\n\tspin_lock(&pd->lock);\n\tBUG_ON(pd->bio_queue_size < 0);\n\twas_empty = (pd->bio_queue_size == 0);\n\tpkt_rbtree_insert(pd, node);\n\tspin_unlock(&pd->lock);\n\n\t \n\tatomic_set(&pd->scan_queue, 1);\n\tif (was_empty) {\n\t\t \n\t\twake_up(&pd->wqueue);\n\t} else if (!list_empty(&pd->cdrw.pkt_free_list) && !blocked_bio) {\n\t\t \n\t\twake_up(&pd->wqueue);\n\t}\n}\n\nstatic void pkt_submit_bio(struct bio *bio)\n{\n\tstruct pktcdvd_device *pd = bio->bi_bdev->bd_disk->queue->queuedata;\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tstruct bio *split;\n\n\tbio = bio_split_to_limits(bio);\n\tif (!bio)\n\t\treturn;\n\n\tdev_dbg(ddev, \"start = %6llx stop = %6llx\\n\",\n\t\tbio->bi_iter.bi_sector, bio_end_sector(bio));\n\n\t \n\tif (bio_data_dir(bio) == READ) {\n\t\tpkt_make_request_read(pd, bio);\n\t\treturn;\n\t}\n\n\tif (!test_bit(PACKET_WRITABLE, &pd->flags)) {\n\t\tdev_notice(ddev, \"WRITE for ro device (%llu)\\n\", bio->bi_iter.bi_sector);\n\t\tgoto end_io;\n\t}\n\n\tif (!bio->bi_iter.bi_size || (bio->bi_iter.bi_size % CD_FRAMESIZE)) {\n\t\tdev_err(ddev, \"wrong bio size\\n\");\n\t\tgoto end_io;\n\t}\n\n\tdo {\n\t\tsector_t zone = get_zone(bio->bi_iter.bi_sector, pd);\n\t\tsector_t last_zone = get_zone(bio_end_sector(bio) - 1, pd);\n\n\t\tif (last_zone != zone) {\n\t\t\tBUG_ON(last_zone != zone + pd->settings.size);\n\n\t\t\tsplit = bio_split(bio, last_zone -\n\t\t\t\t\t  bio->bi_iter.bi_sector,\n\t\t\t\t\t  GFP_NOIO, &pkt_bio_set);\n\t\t\tbio_chain(split, bio);\n\t\t} else {\n\t\t\tsplit = bio;\n\t\t}\n\n\t\tpkt_make_request_write(bio->bi_bdev->bd_disk->queue, split);\n\t} while (split != bio);\n\n\treturn;\nend_io:\n\tbio_io_error(bio);\n}\n\nstatic void pkt_init_queue(struct pktcdvd_device *pd)\n{\n\tstruct request_queue *q = pd->disk->queue;\n\n\tblk_queue_logical_block_size(q, CD_FRAMESIZE);\n\tblk_queue_max_hw_sectors(q, PACKET_MAX_SECTORS);\n\tq->queuedata = pd;\n}\n\nstatic int pkt_new_dev(struct pktcdvd_device *pd, dev_t dev)\n{\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tint i;\n\tstruct block_device *bdev;\n\tstruct scsi_device *sdev;\n\n\tif (pd->pkt_dev == dev) {\n\t\tdev_err(ddev, \"recursive setup not allowed\\n\");\n\t\treturn -EBUSY;\n\t}\n\tfor (i = 0; i < MAX_WRITERS; i++) {\n\t\tstruct pktcdvd_device *pd2 = pkt_devs[i];\n\t\tif (!pd2)\n\t\t\tcontinue;\n\t\tif (pd2->bdev->bd_dev == dev) {\n\t\t\tdev_err(ddev, \"%pg already setup\\n\", pd2->bdev);\n\t\t\treturn -EBUSY;\n\t\t}\n\t\tif (pd2->pkt_dev == dev) {\n\t\t\tdev_err(ddev, \"can't chain pktcdvd devices\\n\");\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\tbdev = blkdev_get_by_dev(dev, BLK_OPEN_READ | BLK_OPEN_NDELAY, NULL,\n\t\t\t\t NULL);\n\tif (IS_ERR(bdev))\n\t\treturn PTR_ERR(bdev);\n\tsdev = scsi_device_from_queue(bdev->bd_disk->queue);\n\tif (!sdev) {\n\t\tblkdev_put(bdev, NULL);\n\t\treturn -EINVAL;\n\t}\n\tput_device(&sdev->sdev_gendev);\n\n\t \n\t__module_get(THIS_MODULE);\n\n\tpd->bdev = bdev;\n\tset_blocksize(bdev, CD_FRAMESIZE);\n\n\tpkt_init_queue(pd);\n\n\tatomic_set(&pd->cdrw.pending_bios, 0);\n\tpd->cdrw.thread = kthread_run(kcdrwd, pd, \"%s\", pd->disk->disk_name);\n\tif (IS_ERR(pd->cdrw.thread)) {\n\t\tdev_err(ddev, \"can't start kernel thread\\n\");\n\t\tgoto out_mem;\n\t}\n\n\tproc_create_single_data(pd->disk->disk_name, 0, pkt_proc, pkt_seq_show, pd);\n\tdev_notice(ddev, \"writer mapped to %pg\\n\", bdev);\n\treturn 0;\n\nout_mem:\n\tblkdev_put(bdev, NULL);\n\t \n\tmodule_put(THIS_MODULE);\n\treturn -ENOMEM;\n}\n\nstatic int pkt_ioctl(struct block_device *bdev, blk_mode_t mode,\n\t\tunsigned int cmd, unsigned long arg)\n{\n\tstruct pktcdvd_device *pd = bdev->bd_disk->private_data;\n\tstruct device *ddev = disk_to_dev(pd->disk);\n\tint ret;\n\n\tdev_dbg(ddev, \"cmd %x, dev %d:%d\\n\", cmd, MAJOR(bdev->bd_dev), MINOR(bdev->bd_dev));\n\n\tmutex_lock(&pktcdvd_mutex);\n\tswitch (cmd) {\n\tcase CDROMEJECT:\n\t\t \n\t\tif (pd->refcnt == 1)\n\t\t\tpkt_lock_door(pd, 0);\n\t\tfallthrough;\n\t \n\tcase CDROMMULTISESSION:\n\tcase CDROMREADTOCENTRY:\n\tcase CDROM_LAST_WRITTEN:\n\tcase CDROM_SEND_PACKET:\n\tcase SCSI_IOCTL_SEND_COMMAND:\n\t\tif (!bdev->bd_disk->fops->ioctl)\n\t\t\tret = -ENOTTY;\n\t\telse\n\t\t\tret = bdev->bd_disk->fops->ioctl(bdev, mode, cmd, arg);\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(ddev, \"Unknown ioctl (%x)\\n\", cmd);\n\t\tret = -ENOTTY;\n\t}\n\tmutex_unlock(&pktcdvd_mutex);\n\n\treturn ret;\n}\n\nstatic unsigned int pkt_check_events(struct gendisk *disk,\n\t\t\t\t     unsigned int clearing)\n{\n\tstruct pktcdvd_device *pd = disk->private_data;\n\tstruct gendisk *attached_disk;\n\n\tif (!pd)\n\t\treturn 0;\n\tif (!pd->bdev)\n\t\treturn 0;\n\tattached_disk = pd->bdev->bd_disk;\n\tif (!attached_disk || !attached_disk->fops->check_events)\n\t\treturn 0;\n\treturn attached_disk->fops->check_events(attached_disk, clearing);\n}\n\nstatic char *pkt_devnode(struct gendisk *disk, umode_t *mode)\n{\n\treturn kasprintf(GFP_KERNEL, \"pktcdvd/%s\", disk->disk_name);\n}\n\nstatic const struct block_device_operations pktcdvd_ops = {\n\t.owner =\t\tTHIS_MODULE,\n\t.submit_bio =\t\tpkt_submit_bio,\n\t.open =\t\t\tpkt_open,\n\t.release =\t\tpkt_release,\n\t.ioctl =\t\tpkt_ioctl,\n\t.compat_ioctl =\t\tblkdev_compat_ptr_ioctl,\n\t.check_events =\t\tpkt_check_events,\n\t.devnode =\t\tpkt_devnode,\n};\n\n \nstatic int pkt_setup_dev(dev_t dev, dev_t* pkt_dev)\n{\n\tint idx;\n\tint ret = -ENOMEM;\n\tstruct pktcdvd_device *pd;\n\tstruct gendisk *disk;\n\n\tmutex_lock_nested(&ctl_mutex, SINGLE_DEPTH_NESTING);\n\n\tfor (idx = 0; idx < MAX_WRITERS; idx++)\n\t\tif (!pkt_devs[idx])\n\t\t\tbreak;\n\tif (idx == MAX_WRITERS) {\n\t\tpr_err(\"max %d writers supported\\n\", MAX_WRITERS);\n\t\tret = -EBUSY;\n\t\tgoto out_mutex;\n\t}\n\n\tpd = kzalloc(sizeof(struct pktcdvd_device), GFP_KERNEL);\n\tif (!pd)\n\t\tgoto out_mutex;\n\n\tret = mempool_init_kmalloc_pool(&pd->rb_pool, PKT_RB_POOL_SIZE,\n\t\t\t\t\tsizeof(struct pkt_rb_node));\n\tif (ret)\n\t\tgoto out_mem;\n\n\tINIT_LIST_HEAD(&pd->cdrw.pkt_free_list);\n\tINIT_LIST_HEAD(&pd->cdrw.pkt_active_list);\n\tspin_lock_init(&pd->cdrw.active_list_lock);\n\n\tspin_lock_init(&pd->lock);\n\tspin_lock_init(&pd->iosched.lock);\n\tbio_list_init(&pd->iosched.read_queue);\n\tbio_list_init(&pd->iosched.write_queue);\n\tinit_waitqueue_head(&pd->wqueue);\n\tpd->bio_queue = RB_ROOT;\n\n\tpd->write_congestion_on  = write_congestion_on;\n\tpd->write_congestion_off = write_congestion_off;\n\n\tret = -ENOMEM;\n\tdisk = blk_alloc_disk(NUMA_NO_NODE);\n\tif (!disk)\n\t\tgoto out_mem;\n\tpd->disk = disk;\n\tdisk->major = pktdev_major;\n\tdisk->first_minor = idx;\n\tdisk->minors = 1;\n\tdisk->fops = &pktcdvd_ops;\n\tdisk->flags = GENHD_FL_REMOVABLE | GENHD_FL_NO_PART;\n\tsnprintf(disk->disk_name, sizeof(disk->disk_name), DRIVER_NAME\"%d\", idx);\n\tdisk->private_data = pd;\n\n\tpd->pkt_dev = MKDEV(pktdev_major, idx);\n\tret = pkt_new_dev(pd, dev);\n\tif (ret)\n\t\tgoto out_mem2;\n\n\t \n\tdisk->events = pd->bdev->bd_disk->events;\n\n\tret = add_disk(disk);\n\tif (ret)\n\t\tgoto out_mem2;\n\n\tpkt_sysfs_dev_new(pd);\n\tpkt_debugfs_dev_new(pd);\n\n\tpkt_devs[idx] = pd;\n\tif (pkt_dev)\n\t\t*pkt_dev = pd->pkt_dev;\n\n\tmutex_unlock(&ctl_mutex);\n\treturn 0;\n\nout_mem2:\n\tput_disk(disk);\nout_mem:\n\tmempool_exit(&pd->rb_pool);\n\tkfree(pd);\nout_mutex:\n\tmutex_unlock(&ctl_mutex);\n\tpr_err(\"setup of pktcdvd device failed\\n\");\n\treturn ret;\n}\n\n \nstatic int pkt_remove_dev(dev_t pkt_dev)\n{\n\tstruct pktcdvd_device *pd;\n\tstruct device *ddev;\n\tint idx;\n\tint ret = 0;\n\n\tmutex_lock_nested(&ctl_mutex, SINGLE_DEPTH_NESTING);\n\n\tfor (idx = 0; idx < MAX_WRITERS; idx++) {\n\t\tpd = pkt_devs[idx];\n\t\tif (pd && (pd->pkt_dev == pkt_dev))\n\t\t\tbreak;\n\t}\n\tif (idx == MAX_WRITERS) {\n\t\tpr_debug(\"dev not setup\\n\");\n\t\tret = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (pd->refcnt > 0) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tddev = disk_to_dev(pd->disk);\n\n\tif (!IS_ERR(pd->cdrw.thread))\n\t\tkthread_stop(pd->cdrw.thread);\n\n\tpkt_devs[idx] = NULL;\n\n\tpkt_debugfs_dev_remove(pd);\n\tpkt_sysfs_dev_remove(pd);\n\n\tblkdev_put(pd->bdev, NULL);\n\n\tremove_proc_entry(pd->disk->disk_name, pkt_proc);\n\tdev_notice(ddev, \"writer unmapped\\n\");\n\n\tdel_gendisk(pd->disk);\n\tput_disk(pd->disk);\n\n\tmempool_exit(&pd->rb_pool);\n\tkfree(pd);\n\n\t \n\tmodule_put(THIS_MODULE);\n\nout:\n\tmutex_unlock(&ctl_mutex);\n\treturn ret;\n}\n\nstatic void pkt_get_status(struct pkt_ctrl_command *ctrl_cmd)\n{\n\tstruct pktcdvd_device *pd;\n\n\tmutex_lock_nested(&ctl_mutex, SINGLE_DEPTH_NESTING);\n\n\tpd = pkt_find_dev_from_minor(ctrl_cmd->dev_index);\n\tif (pd) {\n\t\tctrl_cmd->dev = new_encode_dev(pd->bdev->bd_dev);\n\t\tctrl_cmd->pkt_dev = new_encode_dev(pd->pkt_dev);\n\t} else {\n\t\tctrl_cmd->dev = 0;\n\t\tctrl_cmd->pkt_dev = 0;\n\t}\n\tctrl_cmd->num_devices = MAX_WRITERS;\n\n\tmutex_unlock(&ctl_mutex);\n}\n\nstatic long pkt_ctl_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tvoid __user *argp = (void __user *)arg;\n\tstruct pkt_ctrl_command ctrl_cmd;\n\tint ret = 0;\n\tdev_t pkt_dev = 0;\n\n\tif (cmd != PACKET_CTRL_CMD)\n\t\treturn -ENOTTY;\n\n\tif (copy_from_user(&ctrl_cmd, argp, sizeof(struct pkt_ctrl_command)))\n\t\treturn -EFAULT;\n\n\tswitch (ctrl_cmd.command) {\n\tcase PKT_CTRL_CMD_SETUP:\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tret = pkt_setup_dev(new_decode_dev(ctrl_cmd.dev), &pkt_dev);\n\t\tctrl_cmd.pkt_dev = new_encode_dev(pkt_dev);\n\t\tbreak;\n\tcase PKT_CTRL_CMD_TEARDOWN:\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tret = pkt_remove_dev(new_decode_dev(ctrl_cmd.pkt_dev));\n\t\tbreak;\n\tcase PKT_CTRL_CMD_STATUS:\n\t\tpkt_get_status(&ctrl_cmd);\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\tif (copy_to_user(argp, &ctrl_cmd, sizeof(struct pkt_ctrl_command)))\n\t\treturn -EFAULT;\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic long pkt_ctl_compat_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\treturn pkt_ctl_ioctl(file, cmd, (unsigned long)compat_ptr(arg));\n}\n#endif\n\nstatic const struct file_operations pkt_ctl_fops = {\n\t.open\t\t= nonseekable_open,\n\t.unlocked_ioctl\t= pkt_ctl_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl\t= pkt_ctl_compat_ioctl,\n#endif\n\t.owner\t\t= THIS_MODULE,\n\t.llseek\t\t= no_llseek,\n};\n\nstatic struct miscdevice pkt_misc = {\n\t.minor \t\t= MISC_DYNAMIC_MINOR,\n\t.name  \t\t= DRIVER_NAME,\n\t.nodename\t= \"pktcdvd/control\",\n\t.fops  \t\t= &pkt_ctl_fops\n};\n\nstatic int __init pkt_init(void)\n{\n\tint ret;\n\n\tmutex_init(&ctl_mutex);\n\n\tret = mempool_init_kmalloc_pool(&psd_pool, PSD_POOL_SIZE,\n\t\t\t\t    sizeof(struct packet_stacked_data));\n\tif (ret)\n\t\treturn ret;\n\tret = bioset_init(&pkt_bio_set, BIO_POOL_SIZE, 0, 0);\n\tif (ret) {\n\t\tmempool_exit(&psd_pool);\n\t\treturn ret;\n\t}\n\n\tret = register_blkdev(pktdev_major, DRIVER_NAME);\n\tif (ret < 0) {\n\t\tpr_err(\"unable to register block device\\n\");\n\t\tgoto out2;\n\t}\n\tif (!pktdev_major)\n\t\tpktdev_major = ret;\n\n\tret = pkt_sysfs_init();\n\tif (ret)\n\t\tgoto out;\n\n\tpkt_debugfs_init();\n\n\tret = misc_register(&pkt_misc);\n\tif (ret) {\n\t\tpr_err(\"unable to register misc device\\n\");\n\t\tgoto out_misc;\n\t}\n\n\tpkt_proc = proc_mkdir(\"driver/\"DRIVER_NAME, NULL);\n\n\treturn 0;\n\nout_misc:\n\tpkt_debugfs_cleanup();\n\tpkt_sysfs_cleanup();\nout:\n\tunregister_blkdev(pktdev_major, DRIVER_NAME);\nout2:\n\tmempool_exit(&psd_pool);\n\tbioset_exit(&pkt_bio_set);\n\treturn ret;\n}\n\nstatic void __exit pkt_exit(void)\n{\n\tremove_proc_entry(\"driver/\"DRIVER_NAME, NULL);\n\tmisc_deregister(&pkt_misc);\n\n\tpkt_debugfs_cleanup();\n\tpkt_sysfs_cleanup();\n\n\tunregister_blkdev(pktdev_major, DRIVER_NAME);\n\tmempool_exit(&psd_pool);\n\tbioset_exit(&pkt_bio_set);\n}\n\nMODULE_DESCRIPTION(\"Packet writing layer for CD/DVD drives\");\nMODULE_AUTHOR(\"Jens Axboe <axboe@suse.de>\");\nMODULE_LICENSE(\"GPL\");\n\nmodule_init(pkt_init);\nmodule_exit(pkt_exit);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}