{
  "module_name": "zoned.c",
  "hash_id": "b531f3d084fd6cdb149c2a42cf04788362b526f44f8ec9f7cc0054435346d0db",
  "original_prompt": "Ingested from linux-6.6.14/drivers/block/null_blk/zoned.c",
  "human_readable_source": "\n#include <linux/vmalloc.h>\n#include <linux/bitmap.h>\n#include \"null_blk.h\"\n\n#define CREATE_TRACE_POINTS\n#include \"trace.h\"\n\n#undef pr_fmt\n#define pr_fmt(fmt)\t\"null_blk: \" fmt\n\nstatic inline sector_t mb_to_sects(unsigned long mb)\n{\n\treturn ((sector_t)mb * SZ_1M) >> SECTOR_SHIFT;\n}\n\nstatic inline unsigned int null_zone_no(struct nullb_device *dev, sector_t sect)\n{\n\treturn sect >> ilog2(dev->zone_size_sects);\n}\n\nstatic inline void null_lock_zone_res(struct nullb_device *dev)\n{\n\tif (dev->need_zone_res_mgmt)\n\t\tspin_lock_irq(&dev->zone_res_lock);\n}\n\nstatic inline void null_unlock_zone_res(struct nullb_device *dev)\n{\n\tif (dev->need_zone_res_mgmt)\n\t\tspin_unlock_irq(&dev->zone_res_lock);\n}\n\nstatic inline void null_init_zone_lock(struct nullb_device *dev,\n\t\t\t\t       struct nullb_zone *zone)\n{\n\tif (!dev->memory_backed)\n\t\tspin_lock_init(&zone->spinlock);\n\telse\n\t\tmutex_init(&zone->mutex);\n}\n\nstatic inline void null_lock_zone(struct nullb_device *dev,\n\t\t\t\t  struct nullb_zone *zone)\n{\n\tif (!dev->memory_backed)\n\t\tspin_lock_irq(&zone->spinlock);\n\telse\n\t\tmutex_lock(&zone->mutex);\n}\n\nstatic inline void null_unlock_zone(struct nullb_device *dev,\n\t\t\t\t    struct nullb_zone *zone)\n{\n\tif (!dev->memory_backed)\n\t\tspin_unlock_irq(&zone->spinlock);\n\telse\n\t\tmutex_unlock(&zone->mutex);\n}\n\nint null_init_zoned_dev(struct nullb_device *dev, struct request_queue *q)\n{\n\tsector_t dev_capacity_sects, zone_capacity_sects;\n\tstruct nullb_zone *zone;\n\tsector_t sector = 0;\n\tunsigned int i;\n\n\tif (!is_power_of_2(dev->zone_size)) {\n\t\tpr_err(\"zone_size must be power-of-two\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (dev->zone_size > dev->size) {\n\t\tpr_err(\"Zone size larger than device capacity\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!dev->zone_capacity)\n\t\tdev->zone_capacity = dev->zone_size;\n\n\tif (dev->zone_capacity > dev->zone_size) {\n\t\tpr_err(\"zone capacity (%lu MB) larger than zone size (%lu MB)\\n\",\n\t\t       dev->zone_capacity, dev->zone_size);\n\t\treturn -EINVAL;\n\t}\n\n\tzone_capacity_sects = mb_to_sects(dev->zone_capacity);\n\tdev_capacity_sects = mb_to_sects(dev->size);\n\tdev->zone_size_sects = mb_to_sects(dev->zone_size);\n\tdev->nr_zones = round_up(dev_capacity_sects, dev->zone_size_sects)\n\t\t>> ilog2(dev->zone_size_sects);\n\n\tdev->zones = kvmalloc_array(dev->nr_zones, sizeof(struct nullb_zone),\n\t\t\t\t    GFP_KERNEL | __GFP_ZERO);\n\tif (!dev->zones)\n\t\treturn -ENOMEM;\n\n\tspin_lock_init(&dev->zone_res_lock);\n\n\tif (dev->zone_nr_conv >= dev->nr_zones) {\n\t\tdev->zone_nr_conv = dev->nr_zones - 1;\n\t\tpr_info(\"changed the number of conventional zones to %u\",\n\t\t\tdev->zone_nr_conv);\n\t}\n\n\t \n\tif (dev->zone_max_active >= dev->nr_zones - dev->zone_nr_conv) {\n\t\tdev->zone_max_active = 0;\n\t\tpr_info(\"zone_max_active limit disabled, limit >= zone count\\n\");\n\t}\n\n\t \n\tif (dev->zone_max_active && dev->zone_max_open > dev->zone_max_active) {\n\t\tdev->zone_max_open = dev->zone_max_active;\n\t\tpr_info(\"changed the maximum number of open zones to %u\\n\",\n\t\t\tdev->nr_zones);\n\t} else if (dev->zone_max_open >= dev->nr_zones - dev->zone_nr_conv) {\n\t\tdev->zone_max_open = 0;\n\t\tpr_info(\"zone_max_open limit disabled, limit >= zone count\\n\");\n\t}\n\tdev->need_zone_res_mgmt = dev->zone_max_active || dev->zone_max_open;\n\tdev->imp_close_zone_no = dev->zone_nr_conv;\n\n\tfor (i = 0; i <  dev->zone_nr_conv; i++) {\n\t\tzone = &dev->zones[i];\n\n\t\tnull_init_zone_lock(dev, zone);\n\t\tzone->start = sector;\n\t\tzone->len = dev->zone_size_sects;\n\t\tzone->capacity = zone->len;\n\t\tzone->wp = zone->start + zone->len;\n\t\tzone->type = BLK_ZONE_TYPE_CONVENTIONAL;\n\t\tzone->cond = BLK_ZONE_COND_NOT_WP;\n\n\t\tsector += dev->zone_size_sects;\n\t}\n\n\tfor (i = dev->zone_nr_conv; i < dev->nr_zones; i++) {\n\t\tzone = &dev->zones[i];\n\n\t\tnull_init_zone_lock(dev, zone);\n\t\tzone->start = zone->wp = sector;\n\t\tif (zone->start + dev->zone_size_sects > dev_capacity_sects)\n\t\t\tzone->len = dev_capacity_sects - zone->start;\n\t\telse\n\t\t\tzone->len = dev->zone_size_sects;\n\t\tzone->capacity =\n\t\t\tmin_t(sector_t, zone->len, zone_capacity_sects);\n\t\tzone->type = BLK_ZONE_TYPE_SEQWRITE_REQ;\n\t\tzone->cond = BLK_ZONE_COND_EMPTY;\n\n\t\tsector += dev->zone_size_sects;\n\t}\n\n\treturn 0;\n}\n\nint null_register_zoned_dev(struct nullb *nullb)\n{\n\tstruct nullb_device *dev = nullb->dev;\n\tstruct request_queue *q = nullb->q;\n\n\tdisk_set_zoned(nullb->disk, BLK_ZONED_HM);\n\tblk_queue_flag_set(QUEUE_FLAG_ZONE_RESETALL, q);\n\tblk_queue_required_elevator_features(q, ELEVATOR_F_ZBD_SEQ_WRITE);\n\tblk_queue_chunk_sectors(q, dev->zone_size_sects);\n\tnullb->disk->nr_zones = bdev_nr_zones(nullb->disk->part0);\n\tblk_queue_max_zone_append_sectors(q, dev->zone_size_sects);\n\tdisk_set_max_open_zones(nullb->disk, dev->zone_max_open);\n\tdisk_set_max_active_zones(nullb->disk, dev->zone_max_active);\n\n\tif (queue_is_mq(q))\n\t\treturn blk_revalidate_disk_zones(nullb->disk, NULL);\n\n\treturn 0;\n}\n\nvoid null_free_zoned_dev(struct nullb_device *dev)\n{\n\tkvfree(dev->zones);\n\tdev->zones = NULL;\n}\n\nint null_report_zones(struct gendisk *disk, sector_t sector,\n\t\tunsigned int nr_zones, report_zones_cb cb, void *data)\n{\n\tstruct nullb *nullb = disk->private_data;\n\tstruct nullb_device *dev = nullb->dev;\n\tunsigned int first_zone, i;\n\tstruct nullb_zone *zone;\n\tstruct blk_zone blkz;\n\tint error;\n\n\tfirst_zone = null_zone_no(dev, sector);\n\tif (first_zone >= dev->nr_zones)\n\t\treturn 0;\n\n\tnr_zones = min(nr_zones, dev->nr_zones - first_zone);\n\ttrace_nullb_report_zones(nullb, nr_zones);\n\n\tmemset(&blkz, 0, sizeof(struct blk_zone));\n\tzone = &dev->zones[first_zone];\n\tfor (i = 0; i < nr_zones; i++, zone++) {\n\t\t \n\t\tnull_lock_zone(dev, zone);\n\t\tblkz.start = zone->start;\n\t\tblkz.len = zone->len;\n\t\tblkz.wp = zone->wp;\n\t\tblkz.type = zone->type;\n\t\tblkz.cond = zone->cond;\n\t\tblkz.capacity = zone->capacity;\n\t\tnull_unlock_zone(dev, zone);\n\n\t\terror = cb(&blkz, i, data);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\treturn nr_zones;\n}\n\n \nsize_t null_zone_valid_read_len(struct nullb *nullb,\n\t\t\t\tsector_t sector, unsigned int len)\n{\n\tstruct nullb_device *dev = nullb->dev;\n\tstruct nullb_zone *zone = &dev->zones[null_zone_no(dev, sector)];\n\tunsigned int nr_sectors = len >> SECTOR_SHIFT;\n\n\t \n\tif (zone->type == BLK_ZONE_TYPE_CONVENTIONAL ||\n\t    sector + nr_sectors <= zone->wp)\n\t\treturn len;\n\n\tif (sector > zone->wp)\n\t\treturn 0;\n\n\treturn (zone->wp - sector) << SECTOR_SHIFT;\n}\n\nstatic blk_status_t __null_close_zone(struct nullb_device *dev,\n\t\t\t\t      struct nullb_zone *zone)\n{\n\tswitch (zone->cond) {\n\tcase BLK_ZONE_COND_CLOSED:\n\t\t \n\t\treturn BLK_STS_OK;\n\tcase BLK_ZONE_COND_IMP_OPEN:\n\t\tdev->nr_zones_imp_open--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_EXP_OPEN:\n\t\tdev->nr_zones_exp_open--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_EMPTY:\n\tcase BLK_ZONE_COND_FULL:\n\tdefault:\n\t\treturn BLK_STS_IOERR;\n\t}\n\n\tif (zone->wp == zone->start) {\n\t\tzone->cond = BLK_ZONE_COND_EMPTY;\n\t} else {\n\t\tzone->cond = BLK_ZONE_COND_CLOSED;\n\t\tdev->nr_zones_closed++;\n\t}\n\n\treturn BLK_STS_OK;\n}\n\nstatic void null_close_imp_open_zone(struct nullb_device *dev)\n{\n\tstruct nullb_zone *zone;\n\tunsigned int zno, i;\n\n\tzno = dev->imp_close_zone_no;\n\tif (zno >= dev->nr_zones)\n\t\tzno = dev->zone_nr_conv;\n\n\tfor (i = dev->zone_nr_conv; i < dev->nr_zones; i++) {\n\t\tzone = &dev->zones[zno];\n\t\tzno++;\n\t\tif (zno >= dev->nr_zones)\n\t\t\tzno = dev->zone_nr_conv;\n\n\t\tif (zone->cond == BLK_ZONE_COND_IMP_OPEN) {\n\t\t\t__null_close_zone(dev, zone);\n\t\t\tdev->imp_close_zone_no = zno;\n\t\t\treturn;\n\t\t}\n\t}\n}\n\nstatic blk_status_t null_check_active(struct nullb_device *dev)\n{\n\tif (!dev->zone_max_active)\n\t\treturn BLK_STS_OK;\n\n\tif (dev->nr_zones_exp_open + dev->nr_zones_imp_open +\n\t\t\tdev->nr_zones_closed < dev->zone_max_active)\n\t\treturn BLK_STS_OK;\n\n\treturn BLK_STS_ZONE_ACTIVE_RESOURCE;\n}\n\nstatic blk_status_t null_check_open(struct nullb_device *dev)\n{\n\tif (!dev->zone_max_open)\n\t\treturn BLK_STS_OK;\n\n\tif (dev->nr_zones_exp_open + dev->nr_zones_imp_open < dev->zone_max_open)\n\t\treturn BLK_STS_OK;\n\n\tif (dev->nr_zones_imp_open) {\n\t\tif (null_check_active(dev) == BLK_STS_OK) {\n\t\t\tnull_close_imp_open_zone(dev);\n\t\t\treturn BLK_STS_OK;\n\t\t}\n\t}\n\n\treturn BLK_STS_ZONE_OPEN_RESOURCE;\n}\n\n \nstatic blk_status_t null_check_zone_resources(struct nullb_device *dev,\n\t\t\t\t\t      struct nullb_zone *zone)\n{\n\tblk_status_t ret;\n\n\tswitch (zone->cond) {\n\tcase BLK_ZONE_COND_EMPTY:\n\t\tret = null_check_active(dev);\n\t\tif (ret != BLK_STS_OK)\n\t\t\treturn ret;\n\t\tfallthrough;\n\tcase BLK_ZONE_COND_CLOSED:\n\t\treturn null_check_open(dev);\n\tdefault:\n\t\t \n\t\tWARN_ON(1);\n\t\treturn BLK_STS_IOERR;\n\t}\n}\n\nstatic blk_status_t null_zone_write(struct nullb_cmd *cmd, sector_t sector,\n\t\t\t\t    unsigned int nr_sectors, bool append)\n{\n\tstruct nullb_device *dev = cmd->nq->dev;\n\tunsigned int zno = null_zone_no(dev, sector);\n\tstruct nullb_zone *zone = &dev->zones[zno];\n\tblk_status_t ret;\n\n\ttrace_nullb_zone_op(cmd, zno, zone->cond);\n\n\tif (zone->type == BLK_ZONE_TYPE_CONVENTIONAL) {\n\t\tif (append)\n\t\t\treturn BLK_STS_IOERR;\n\t\treturn null_process_cmd(cmd, REQ_OP_WRITE, sector, nr_sectors);\n\t}\n\n\tnull_lock_zone(dev, zone);\n\n\tif (zone->cond == BLK_ZONE_COND_FULL ||\n\t    zone->cond == BLK_ZONE_COND_READONLY ||\n\t    zone->cond == BLK_ZONE_COND_OFFLINE) {\n\t\t \n\t\tret = BLK_STS_IOERR;\n\t\tgoto unlock;\n\t}\n\n\t \n\tif (append) {\n\t\tsector = zone->wp;\n\t\tif (dev->queue_mode == NULL_Q_MQ)\n\t\t\tcmd->rq->__sector = sector;\n\t\telse\n\t\t\tcmd->bio->bi_iter.bi_sector = sector;\n\t} else if (sector != zone->wp) {\n\t\tret = BLK_STS_IOERR;\n\t\tgoto unlock;\n\t}\n\n\tif (zone->wp + nr_sectors > zone->start + zone->capacity) {\n\t\tret = BLK_STS_IOERR;\n\t\tgoto unlock;\n\t}\n\n\tif (zone->cond == BLK_ZONE_COND_CLOSED ||\n\t    zone->cond == BLK_ZONE_COND_EMPTY) {\n\t\tnull_lock_zone_res(dev);\n\n\t\tret = null_check_zone_resources(dev, zone);\n\t\tif (ret != BLK_STS_OK) {\n\t\t\tnull_unlock_zone_res(dev);\n\t\t\tgoto unlock;\n\t\t}\n\t\tif (zone->cond == BLK_ZONE_COND_CLOSED) {\n\t\t\tdev->nr_zones_closed--;\n\t\t\tdev->nr_zones_imp_open++;\n\t\t} else if (zone->cond == BLK_ZONE_COND_EMPTY) {\n\t\t\tdev->nr_zones_imp_open++;\n\t\t}\n\n\t\tif (zone->cond != BLK_ZONE_COND_EXP_OPEN)\n\t\t\tzone->cond = BLK_ZONE_COND_IMP_OPEN;\n\n\t\tnull_unlock_zone_res(dev);\n\t}\n\n\tret = null_process_cmd(cmd, REQ_OP_WRITE, sector, nr_sectors);\n\tif (ret != BLK_STS_OK)\n\t\tgoto unlock;\n\n\tzone->wp += nr_sectors;\n\tif (zone->wp == zone->start + zone->capacity) {\n\t\tnull_lock_zone_res(dev);\n\t\tif (zone->cond == BLK_ZONE_COND_EXP_OPEN)\n\t\t\tdev->nr_zones_exp_open--;\n\t\telse if (zone->cond == BLK_ZONE_COND_IMP_OPEN)\n\t\t\tdev->nr_zones_imp_open--;\n\t\tzone->cond = BLK_ZONE_COND_FULL;\n\t\tnull_unlock_zone_res(dev);\n\t}\n\n\tret = BLK_STS_OK;\n\nunlock:\n\tnull_unlock_zone(dev, zone);\n\n\treturn ret;\n}\n\nstatic blk_status_t null_open_zone(struct nullb_device *dev,\n\t\t\t\t   struct nullb_zone *zone)\n{\n\tblk_status_t ret = BLK_STS_OK;\n\n\tif (zone->type == BLK_ZONE_TYPE_CONVENTIONAL)\n\t\treturn BLK_STS_IOERR;\n\n\tnull_lock_zone_res(dev);\n\n\tswitch (zone->cond) {\n\tcase BLK_ZONE_COND_EXP_OPEN:\n\t\t \n\t\tgoto unlock;\n\tcase BLK_ZONE_COND_EMPTY:\n\t\tret = null_check_zone_resources(dev, zone);\n\t\tif (ret != BLK_STS_OK)\n\t\t\tgoto unlock;\n\t\tbreak;\n\tcase BLK_ZONE_COND_IMP_OPEN:\n\t\tdev->nr_zones_imp_open--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_CLOSED:\n\t\tret = null_check_zone_resources(dev, zone);\n\t\tif (ret != BLK_STS_OK)\n\t\t\tgoto unlock;\n\t\tdev->nr_zones_closed--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_FULL:\n\tdefault:\n\t\tret = BLK_STS_IOERR;\n\t\tgoto unlock;\n\t}\n\n\tzone->cond = BLK_ZONE_COND_EXP_OPEN;\n\tdev->nr_zones_exp_open++;\n\nunlock:\n\tnull_unlock_zone_res(dev);\n\n\treturn ret;\n}\n\nstatic blk_status_t null_close_zone(struct nullb_device *dev,\n\t\t\t\t    struct nullb_zone *zone)\n{\n\tblk_status_t ret;\n\n\tif (zone->type == BLK_ZONE_TYPE_CONVENTIONAL)\n\t\treturn BLK_STS_IOERR;\n\n\tnull_lock_zone_res(dev);\n\tret = __null_close_zone(dev, zone);\n\tnull_unlock_zone_res(dev);\n\n\treturn ret;\n}\n\nstatic blk_status_t null_finish_zone(struct nullb_device *dev,\n\t\t\t\t     struct nullb_zone *zone)\n{\n\tblk_status_t ret = BLK_STS_OK;\n\n\tif (zone->type == BLK_ZONE_TYPE_CONVENTIONAL)\n\t\treturn BLK_STS_IOERR;\n\n\tnull_lock_zone_res(dev);\n\n\tswitch (zone->cond) {\n\tcase BLK_ZONE_COND_FULL:\n\t\t \n\t\tgoto unlock;\n\tcase BLK_ZONE_COND_EMPTY:\n\t\tret = null_check_zone_resources(dev, zone);\n\t\tif (ret != BLK_STS_OK)\n\t\t\tgoto unlock;\n\t\tbreak;\n\tcase BLK_ZONE_COND_IMP_OPEN:\n\t\tdev->nr_zones_imp_open--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_EXP_OPEN:\n\t\tdev->nr_zones_exp_open--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_CLOSED:\n\t\tret = null_check_zone_resources(dev, zone);\n\t\tif (ret != BLK_STS_OK)\n\t\t\tgoto unlock;\n\t\tdev->nr_zones_closed--;\n\t\tbreak;\n\tdefault:\n\t\tret = BLK_STS_IOERR;\n\t\tgoto unlock;\n\t}\n\n\tzone->cond = BLK_ZONE_COND_FULL;\n\tzone->wp = zone->start + zone->len;\n\nunlock:\n\tnull_unlock_zone_res(dev);\n\n\treturn ret;\n}\n\nstatic blk_status_t null_reset_zone(struct nullb_device *dev,\n\t\t\t\t    struct nullb_zone *zone)\n{\n\tif (zone->type == BLK_ZONE_TYPE_CONVENTIONAL)\n\t\treturn BLK_STS_IOERR;\n\n\tnull_lock_zone_res(dev);\n\n\tswitch (zone->cond) {\n\tcase BLK_ZONE_COND_EMPTY:\n\t\t \n\t\tnull_unlock_zone_res(dev);\n\t\treturn BLK_STS_OK;\n\tcase BLK_ZONE_COND_IMP_OPEN:\n\t\tdev->nr_zones_imp_open--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_EXP_OPEN:\n\t\tdev->nr_zones_exp_open--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_CLOSED:\n\t\tdev->nr_zones_closed--;\n\t\tbreak;\n\tcase BLK_ZONE_COND_FULL:\n\t\tbreak;\n\tdefault:\n\t\tnull_unlock_zone_res(dev);\n\t\treturn BLK_STS_IOERR;\n\t}\n\n\tzone->cond = BLK_ZONE_COND_EMPTY;\n\tzone->wp = zone->start;\n\n\tnull_unlock_zone_res(dev);\n\n\tif (dev->memory_backed)\n\t\treturn null_handle_discard(dev, zone->start, zone->len);\n\n\treturn BLK_STS_OK;\n}\n\nstatic blk_status_t null_zone_mgmt(struct nullb_cmd *cmd, enum req_op op,\n\t\t\t\t   sector_t sector)\n{\n\tstruct nullb_device *dev = cmd->nq->dev;\n\tunsigned int zone_no;\n\tstruct nullb_zone *zone;\n\tblk_status_t ret;\n\tsize_t i;\n\n\tif (op == REQ_OP_ZONE_RESET_ALL) {\n\t\tfor (i = dev->zone_nr_conv; i < dev->nr_zones; i++) {\n\t\t\tzone = &dev->zones[i];\n\t\t\tnull_lock_zone(dev, zone);\n\t\t\tif (zone->cond != BLK_ZONE_COND_EMPTY &&\n\t\t\t    zone->cond != BLK_ZONE_COND_READONLY &&\n\t\t\t    zone->cond != BLK_ZONE_COND_OFFLINE) {\n\t\t\t\tnull_reset_zone(dev, zone);\n\t\t\t\ttrace_nullb_zone_op(cmd, i, zone->cond);\n\t\t\t}\n\t\t\tnull_unlock_zone(dev, zone);\n\t\t}\n\t\treturn BLK_STS_OK;\n\t}\n\n\tzone_no = null_zone_no(dev, sector);\n\tzone = &dev->zones[zone_no];\n\n\tnull_lock_zone(dev, zone);\n\n\tif (zone->cond == BLK_ZONE_COND_READONLY ||\n\t    zone->cond == BLK_ZONE_COND_OFFLINE) {\n\t\tret = BLK_STS_IOERR;\n\t\tgoto unlock;\n\t}\n\n\tswitch (op) {\n\tcase REQ_OP_ZONE_RESET:\n\t\tret = null_reset_zone(dev, zone);\n\t\tbreak;\n\tcase REQ_OP_ZONE_OPEN:\n\t\tret = null_open_zone(dev, zone);\n\t\tbreak;\n\tcase REQ_OP_ZONE_CLOSE:\n\t\tret = null_close_zone(dev, zone);\n\t\tbreak;\n\tcase REQ_OP_ZONE_FINISH:\n\t\tret = null_finish_zone(dev, zone);\n\t\tbreak;\n\tdefault:\n\t\tret = BLK_STS_NOTSUPP;\n\t\tbreak;\n\t}\n\n\tif (ret == BLK_STS_OK)\n\t\ttrace_nullb_zone_op(cmd, zone_no, zone->cond);\n\nunlock:\n\tnull_unlock_zone(dev, zone);\n\n\treturn ret;\n}\n\nblk_status_t null_process_zoned_cmd(struct nullb_cmd *cmd, enum req_op op,\n\t\t\t\t    sector_t sector, sector_t nr_sectors)\n{\n\tstruct nullb_device *dev;\n\tstruct nullb_zone *zone;\n\tblk_status_t sts;\n\n\tswitch (op) {\n\tcase REQ_OP_WRITE:\n\t\treturn null_zone_write(cmd, sector, nr_sectors, false);\n\tcase REQ_OP_ZONE_APPEND:\n\t\treturn null_zone_write(cmd, sector, nr_sectors, true);\n\tcase REQ_OP_ZONE_RESET:\n\tcase REQ_OP_ZONE_RESET_ALL:\n\tcase REQ_OP_ZONE_OPEN:\n\tcase REQ_OP_ZONE_CLOSE:\n\tcase REQ_OP_ZONE_FINISH:\n\t\treturn null_zone_mgmt(cmd, op, sector);\n\tdefault:\n\t\tdev = cmd->nq->dev;\n\t\tzone = &dev->zones[null_zone_no(dev, sector)];\n\t\tif (zone->cond == BLK_ZONE_COND_OFFLINE)\n\t\t\treturn BLK_STS_IOERR;\n\n\t\tnull_lock_zone(dev, zone);\n\t\tsts = null_process_cmd(cmd, op, sector, nr_sectors);\n\t\tnull_unlock_zone(dev, zone);\n\t\treturn sts;\n\t}\n}\n\n \nstatic void null_set_zone_cond(struct nullb_device *dev,\n\t\t\t       struct nullb_zone *zone, enum blk_zone_cond cond)\n{\n\tif (WARN_ON_ONCE(cond != BLK_ZONE_COND_READONLY &&\n\t\t\t cond != BLK_ZONE_COND_OFFLINE))\n\t\treturn;\n\n\tnull_lock_zone(dev, zone);\n\n\t \n\tif (zone->cond == cond) {\n\t\tzone->cond = BLK_ZONE_COND_EMPTY;\n\t\tzone->wp = zone->start;\n\t\tif (dev->memory_backed)\n\t\t\tnull_handle_discard(dev, zone->start, zone->len);\n\t} else {\n\t\tif (zone->cond != BLK_ZONE_COND_READONLY &&\n\t\t    zone->cond != BLK_ZONE_COND_OFFLINE)\n\t\t\tnull_finish_zone(dev, zone);\n\t\tzone->cond = cond;\n\t\tzone->wp = (sector_t)-1;\n\t}\n\n\tnull_unlock_zone(dev, zone);\n}\n\n \nssize_t zone_cond_store(struct nullb_device *dev, const char *page,\n\t\t\tsize_t count, enum blk_zone_cond cond)\n{\n\tunsigned long long sector;\n\tunsigned int zone_no;\n\tint ret;\n\n\tif (!dev->zoned) {\n\t\tpr_err(\"null_blk device is not zoned\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!dev->zones) {\n\t\tpr_err(\"null_blk device is not yet powered\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = kstrtoull(page, 0, &sector);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tzone_no = null_zone_no(dev, sector);\n\tif (zone_no >= dev->nr_zones) {\n\t\tpr_err(\"Sector out of range\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (dev->zones[zone_no].type == BLK_ZONE_TYPE_CONVENTIONAL) {\n\t\tpr_err(\"Can not change condition of conventional zones\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tnull_set_zone_cond(dev, &dev->zones[zone_no], cond);\n\n\treturn count;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}