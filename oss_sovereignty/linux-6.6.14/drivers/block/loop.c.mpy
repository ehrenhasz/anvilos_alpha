{
  "module_name": "loop.c",
  "hash_id": "575b28798a1b5821c51e052db49fd7035921f5dccad5259e75bbbadc0af722b5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/block/loop.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/sched.h>\n#include <linux/fs.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/stat.h>\n#include <linux/errno.h>\n#include <linux/major.h>\n#include <linux/wait.h>\n#include <linux/blkpg.h>\n#include <linux/init.h>\n#include <linux/swap.h>\n#include <linux/slab.h>\n#include <linux/compat.h>\n#include <linux/suspend.h>\n#include <linux/freezer.h>\n#include <linux/mutex.h>\n#include <linux/writeback.h>\n#include <linux/completion.h>\n#include <linux/highmem.h>\n#include <linux/splice.h>\n#include <linux/sysfs.h>\n#include <linux/miscdevice.h>\n#include <linux/falloc.h>\n#include <linux/uio.h>\n#include <linux/ioprio.h>\n#include <linux/blk-cgroup.h>\n#include <linux/sched/mm.h>\n#include <linux/statfs.h>\n#include <linux/uaccess.h>\n#include <linux/blk-mq.h>\n#include <linux/spinlock.h>\n#include <uapi/linux/loop.h>\n\n \nenum {\n\tLo_unbound,\n\tLo_bound,\n\tLo_rundown,\n\tLo_deleting,\n};\n\nstruct loop_func_table;\n\nstruct loop_device {\n\tint\t\tlo_number;\n\tloff_t\t\tlo_offset;\n\tloff_t\t\tlo_sizelimit;\n\tint\t\tlo_flags;\n\tchar\t\tlo_file_name[LO_NAME_SIZE];\n\n\tstruct file *\tlo_backing_file;\n\tstruct block_device *lo_device;\n\n\tgfp_t\t\told_gfp_mask;\n\n\tspinlock_t\t\tlo_lock;\n\tint\t\t\tlo_state;\n\tspinlock_t              lo_work_lock;\n\tstruct workqueue_struct *workqueue;\n\tstruct work_struct      rootcg_work;\n\tstruct list_head        rootcg_cmd_list;\n\tstruct list_head        idle_worker_list;\n\tstruct rb_root          worker_tree;\n\tstruct timer_list       timer;\n\tbool\t\t\tuse_dio;\n\tbool\t\t\tsysfs_inited;\n\n\tstruct request_queue\t*lo_queue;\n\tstruct blk_mq_tag_set\ttag_set;\n\tstruct gendisk\t\t*lo_disk;\n\tstruct mutex\t\tlo_mutex;\n\tbool\t\t\tidr_visible;\n};\n\nstruct loop_cmd {\n\tstruct list_head list_entry;\n\tbool use_aio;  \n\tatomic_t ref;  \n\tlong ret;\n\tstruct kiocb iocb;\n\tstruct bio_vec *bvec;\n\tstruct cgroup_subsys_state *blkcg_css;\n\tstruct cgroup_subsys_state *memcg_css;\n};\n\n#define LOOP_IDLE_WORKER_TIMEOUT (60 * HZ)\n#define LOOP_DEFAULT_HW_Q_DEPTH 128\n\nstatic DEFINE_IDR(loop_index_idr);\nstatic DEFINE_MUTEX(loop_ctl_mutex);\nstatic DEFINE_MUTEX(loop_validate_mutex);\n\n \nstatic int loop_global_lock_killable(struct loop_device *lo, bool global)\n{\n\tint err;\n\n\tif (global) {\n\t\terr = mutex_lock_killable(&loop_validate_mutex);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\terr = mutex_lock_killable(&lo->lo_mutex);\n\tif (err && global)\n\t\tmutex_unlock(&loop_validate_mutex);\n\treturn err;\n}\n\n \nstatic void loop_global_unlock(struct loop_device *lo, bool global)\n{\n\tmutex_unlock(&lo->lo_mutex);\n\tif (global)\n\t\tmutex_unlock(&loop_validate_mutex);\n}\n\nstatic int max_part;\nstatic int part_shift;\n\nstatic loff_t get_size(loff_t offset, loff_t sizelimit, struct file *file)\n{\n\tloff_t loopsize;\n\n\t \n\tloopsize = i_size_read(file->f_mapping->host);\n\tif (offset > 0)\n\t\tloopsize -= offset;\n\t \n\tif (loopsize < 0)\n\t\treturn 0;\n\n\tif (sizelimit > 0 && sizelimit < loopsize)\n\t\tloopsize = sizelimit;\n\t \n\treturn loopsize >> 9;\n}\n\nstatic loff_t get_loop_size(struct loop_device *lo, struct file *file)\n{\n\treturn get_size(lo->lo_offset, lo->lo_sizelimit, file);\n}\n\n \nstatic bool lo_bdev_can_use_dio(struct loop_device *lo,\n\t\tstruct block_device *backing_bdev)\n{\n\tunsigned short sb_bsize = bdev_logical_block_size(backing_bdev);\n\n\tif (queue_logical_block_size(lo->lo_queue) < sb_bsize)\n\t\treturn false;\n\tif (lo->lo_offset & (sb_bsize - 1))\n\t\treturn false;\n\treturn true;\n}\n\nstatic void __loop_update_dio(struct loop_device *lo, bool dio)\n{\n\tstruct file *file = lo->lo_backing_file;\n\tstruct inode *inode = file->f_mapping->host;\n\tstruct block_device *backing_bdev = NULL;\n\tbool use_dio;\n\n\tif (S_ISBLK(inode->i_mode))\n\t\tbacking_bdev = I_BDEV(inode);\n\telse if (inode->i_sb->s_bdev)\n\t\tbacking_bdev = inode->i_sb->s_bdev;\n\n\tuse_dio = dio && (file->f_mode & FMODE_CAN_ODIRECT) &&\n\t\t(!backing_bdev || lo_bdev_can_use_dio(lo, backing_bdev));\n\n\tif (lo->use_dio == use_dio)\n\t\treturn;\n\n\t \n\tvfs_fsync(file, 0);\n\n\t \n\tif (lo->lo_state == Lo_bound)\n\t\tblk_mq_freeze_queue(lo->lo_queue);\n\tlo->use_dio = use_dio;\n\tif (use_dio) {\n\t\tblk_queue_flag_clear(QUEUE_FLAG_NOMERGES, lo->lo_queue);\n\t\tlo->lo_flags |= LO_FLAGS_DIRECT_IO;\n\t} else {\n\t\tblk_queue_flag_set(QUEUE_FLAG_NOMERGES, lo->lo_queue);\n\t\tlo->lo_flags &= ~LO_FLAGS_DIRECT_IO;\n\t}\n\tif (lo->lo_state == Lo_bound)\n\t\tblk_mq_unfreeze_queue(lo->lo_queue);\n}\n\n \nstatic void loop_set_size(struct loop_device *lo, loff_t size)\n{\n\tif (!set_capacity_and_notify(lo->lo_disk, size))\n\t\tkobject_uevent(&disk_to_dev(lo->lo_disk)->kobj, KOBJ_CHANGE);\n}\n\nstatic int lo_write_bvec(struct file *file, struct bio_vec *bvec, loff_t *ppos)\n{\n\tstruct iov_iter i;\n\tssize_t bw;\n\n\tiov_iter_bvec(&i, ITER_SOURCE, bvec, 1, bvec->bv_len);\n\n\tfile_start_write(file);\n\tbw = vfs_iter_write(file, &i, ppos, 0);\n\tfile_end_write(file);\n\n\tif (likely(bw ==  bvec->bv_len))\n\t\treturn 0;\n\n\tprintk_ratelimited(KERN_ERR\n\t\t\"loop: Write error at byte offset %llu, length %i.\\n\",\n\t\t(unsigned long long)*ppos, bvec->bv_len);\n\tif (bw >= 0)\n\t\tbw = -EIO;\n\treturn bw;\n}\n\nstatic int lo_write_simple(struct loop_device *lo, struct request *rq,\n\t\tloff_t pos)\n{\n\tstruct bio_vec bvec;\n\tstruct req_iterator iter;\n\tint ret = 0;\n\n\trq_for_each_segment(bvec, rq, iter) {\n\t\tret = lo_write_bvec(lo->lo_backing_file, &bvec, &pos);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t\tcond_resched();\n\t}\n\n\treturn ret;\n}\n\nstatic int lo_read_simple(struct loop_device *lo, struct request *rq,\n\t\tloff_t pos)\n{\n\tstruct bio_vec bvec;\n\tstruct req_iterator iter;\n\tstruct iov_iter i;\n\tssize_t len;\n\n\trq_for_each_segment(bvec, rq, iter) {\n\t\tiov_iter_bvec(&i, ITER_DEST, &bvec, 1, bvec.bv_len);\n\t\tlen = vfs_iter_read(lo->lo_backing_file, &i, &pos, 0);\n\t\tif (len < 0)\n\t\t\treturn len;\n\n\t\tflush_dcache_page(bvec.bv_page);\n\n\t\tif (len != bvec.bv_len) {\n\t\t\tstruct bio *bio;\n\n\t\t\t__rq_for_each_bio(bio, rq)\n\t\t\t\tzero_fill_bio(bio);\n\t\t\tbreak;\n\t\t}\n\t\tcond_resched();\n\t}\n\n\treturn 0;\n}\n\nstatic int lo_fallocate(struct loop_device *lo, struct request *rq, loff_t pos,\n\t\t\tint mode)\n{\n\t \n\tstruct file *file = lo->lo_backing_file;\n\tint ret;\n\n\tmode |= FALLOC_FL_KEEP_SIZE;\n\n\tif (!bdev_max_discard_sectors(lo->lo_device))\n\t\treturn -EOPNOTSUPP;\n\n\tret = file->f_op->fallocate(file, mode, pos, blk_rq_bytes(rq));\n\tif (unlikely(ret && ret != -EINVAL && ret != -EOPNOTSUPP))\n\t\treturn -EIO;\n\treturn ret;\n}\n\nstatic int lo_req_flush(struct loop_device *lo, struct request *rq)\n{\n\tint ret = vfs_fsync(lo->lo_backing_file, 0);\n\tif (unlikely(ret && ret != -EINVAL))\n\t\tret = -EIO;\n\n\treturn ret;\n}\n\nstatic void lo_complete_rq(struct request *rq)\n{\n\tstruct loop_cmd *cmd = blk_mq_rq_to_pdu(rq);\n\tblk_status_t ret = BLK_STS_OK;\n\n\tif (!cmd->use_aio || cmd->ret < 0 || cmd->ret == blk_rq_bytes(rq) ||\n\t    req_op(rq) != REQ_OP_READ) {\n\t\tif (cmd->ret < 0)\n\t\t\tret = errno_to_blk_status(cmd->ret);\n\t\tgoto end_io;\n\t}\n\n\t \n\tif (cmd->ret) {\n\t\tblk_update_request(rq, BLK_STS_OK, cmd->ret);\n\t\tcmd->ret = 0;\n\t\tblk_mq_requeue_request(rq, true);\n\t} else {\n\t\tif (cmd->use_aio) {\n\t\t\tstruct bio *bio = rq->bio;\n\n\t\t\twhile (bio) {\n\t\t\t\tzero_fill_bio(bio);\n\t\t\t\tbio = bio->bi_next;\n\t\t\t}\n\t\t}\n\t\tret = BLK_STS_IOERR;\nend_io:\n\t\tblk_mq_end_request(rq, ret);\n\t}\n}\n\nstatic void lo_rw_aio_do_completion(struct loop_cmd *cmd)\n{\n\tstruct request *rq = blk_mq_rq_from_pdu(cmd);\n\n\tif (!atomic_dec_and_test(&cmd->ref))\n\t\treturn;\n\tkfree(cmd->bvec);\n\tcmd->bvec = NULL;\n\tif (likely(!blk_should_fake_timeout(rq->q)))\n\t\tblk_mq_complete_request(rq);\n}\n\nstatic void lo_rw_aio_complete(struct kiocb *iocb, long ret)\n{\n\tstruct loop_cmd *cmd = container_of(iocb, struct loop_cmd, iocb);\n\n\tcmd->ret = ret;\n\tlo_rw_aio_do_completion(cmd);\n}\n\nstatic int lo_rw_aio(struct loop_device *lo, struct loop_cmd *cmd,\n\t\t     loff_t pos, int rw)\n{\n\tstruct iov_iter iter;\n\tstruct req_iterator rq_iter;\n\tstruct bio_vec *bvec;\n\tstruct request *rq = blk_mq_rq_from_pdu(cmd);\n\tstruct bio *bio = rq->bio;\n\tstruct file *file = lo->lo_backing_file;\n\tstruct bio_vec tmp;\n\tunsigned int offset;\n\tint nr_bvec = 0;\n\tint ret;\n\n\trq_for_each_bvec(tmp, rq, rq_iter)\n\t\tnr_bvec++;\n\n\tif (rq->bio != rq->biotail) {\n\n\t\tbvec = kmalloc_array(nr_bvec, sizeof(struct bio_vec),\n\t\t\t\t     GFP_NOIO);\n\t\tif (!bvec)\n\t\t\treturn -EIO;\n\t\tcmd->bvec = bvec;\n\n\t\t \n\t\trq_for_each_bvec(tmp, rq, rq_iter) {\n\t\t\t*bvec = tmp;\n\t\t\tbvec++;\n\t\t}\n\t\tbvec = cmd->bvec;\n\t\toffset = 0;\n\t} else {\n\t\t \n\t\toffset = bio->bi_iter.bi_bvec_done;\n\t\tbvec = __bvec_iter_bvec(bio->bi_io_vec, bio->bi_iter);\n\t}\n\tatomic_set(&cmd->ref, 2);\n\n\tiov_iter_bvec(&iter, rw, bvec, nr_bvec, blk_rq_bytes(rq));\n\titer.iov_offset = offset;\n\n\tcmd->iocb.ki_pos = pos;\n\tcmd->iocb.ki_filp = file;\n\tcmd->iocb.ki_complete = lo_rw_aio_complete;\n\tcmd->iocb.ki_flags = IOCB_DIRECT;\n\tcmd->iocb.ki_ioprio = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_NONE, 0);\n\n\tif (rw == ITER_SOURCE)\n\t\tret = call_write_iter(file, &cmd->iocb, &iter);\n\telse\n\t\tret = call_read_iter(file, &cmd->iocb, &iter);\n\n\tlo_rw_aio_do_completion(cmd);\n\n\tif (ret != -EIOCBQUEUED)\n\t\tlo_rw_aio_complete(&cmd->iocb, ret);\n\treturn 0;\n}\n\nstatic int do_req_filebacked(struct loop_device *lo, struct request *rq)\n{\n\tstruct loop_cmd *cmd = blk_mq_rq_to_pdu(rq);\n\tloff_t pos = ((loff_t) blk_rq_pos(rq) << 9) + lo->lo_offset;\n\n\t \n\tswitch (req_op(rq)) {\n\tcase REQ_OP_FLUSH:\n\t\treturn lo_req_flush(lo, rq);\n\tcase REQ_OP_WRITE_ZEROES:\n\t\t \n\t\treturn lo_fallocate(lo, rq, pos,\n\t\t\t(rq->cmd_flags & REQ_NOUNMAP) ?\n\t\t\t\tFALLOC_FL_ZERO_RANGE :\n\t\t\t\tFALLOC_FL_PUNCH_HOLE);\n\tcase REQ_OP_DISCARD:\n\t\treturn lo_fallocate(lo, rq, pos, FALLOC_FL_PUNCH_HOLE);\n\tcase REQ_OP_WRITE:\n\t\tif (cmd->use_aio)\n\t\t\treturn lo_rw_aio(lo, cmd, pos, ITER_SOURCE);\n\t\telse\n\t\t\treturn lo_write_simple(lo, rq, pos);\n\tcase REQ_OP_READ:\n\t\tif (cmd->use_aio)\n\t\t\treturn lo_rw_aio(lo, cmd, pos, ITER_DEST);\n\t\telse\n\t\t\treturn lo_read_simple(lo, rq, pos);\n\tdefault:\n\t\tWARN_ON_ONCE(1);\n\t\treturn -EIO;\n\t}\n}\n\nstatic inline void loop_update_dio(struct loop_device *lo)\n{\n\t__loop_update_dio(lo, (lo->lo_backing_file->f_flags & O_DIRECT) |\n\t\t\t\tlo->use_dio);\n}\n\nstatic void loop_reread_partitions(struct loop_device *lo)\n{\n\tint rc;\n\n\tmutex_lock(&lo->lo_disk->open_mutex);\n\trc = bdev_disk_changed(lo->lo_disk, false);\n\tmutex_unlock(&lo->lo_disk->open_mutex);\n\tif (rc)\n\t\tpr_warn(\"%s: partition scan of loop%d (%s) failed (rc=%d)\\n\",\n\t\t\t__func__, lo->lo_number, lo->lo_file_name, rc);\n}\n\nstatic inline int is_loop_device(struct file *file)\n{\n\tstruct inode *i = file->f_mapping->host;\n\n\treturn i && S_ISBLK(i->i_mode) && imajor(i) == LOOP_MAJOR;\n}\n\nstatic int loop_validate_file(struct file *file, struct block_device *bdev)\n{\n\tstruct inode\t*inode = file->f_mapping->host;\n\tstruct file\t*f = file;\n\n\t \n\twhile (is_loop_device(f)) {\n\t\tstruct loop_device *l;\n\n\t\tlockdep_assert_held(&loop_validate_mutex);\n\t\tif (f->f_mapping->host->i_rdev == bdev->bd_dev)\n\t\t\treturn -EBADF;\n\n\t\tl = I_BDEV(f->f_mapping->host)->bd_disk->private_data;\n\t\tif (l->lo_state != Lo_bound)\n\t\t\treturn -EINVAL;\n\t\t \n\t\trmb();\n\t\tf = l->lo_backing_file;\n\t}\n\tif (!S_ISREG(inode->i_mode) && !S_ISBLK(inode->i_mode))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\n \nstatic int loop_change_fd(struct loop_device *lo, struct block_device *bdev,\n\t\t\t  unsigned int arg)\n{\n\tstruct file *file = fget(arg);\n\tstruct file *old_file;\n\tint error;\n\tbool partscan;\n\tbool is_loop;\n\n\tif (!file)\n\t\treturn -EBADF;\n\n\t \n\tdev_set_uevent_suppress(disk_to_dev(lo->lo_disk), 1);\n\n\tis_loop = is_loop_device(file);\n\terror = loop_global_lock_killable(lo, is_loop);\n\tif (error)\n\t\tgoto out_putf;\n\terror = -ENXIO;\n\tif (lo->lo_state != Lo_bound)\n\t\tgoto out_err;\n\n\t \n\terror = -EINVAL;\n\tif (!(lo->lo_flags & LO_FLAGS_READ_ONLY))\n\t\tgoto out_err;\n\n\terror = loop_validate_file(file, bdev);\n\tif (error)\n\t\tgoto out_err;\n\n\told_file = lo->lo_backing_file;\n\n\terror = -EINVAL;\n\n\t \n\tif (get_loop_size(lo, file) != get_loop_size(lo, old_file))\n\t\tgoto out_err;\n\n\t \n\tdisk_force_media_change(lo->lo_disk);\n\tblk_mq_freeze_queue(lo->lo_queue);\n\tmapping_set_gfp_mask(old_file->f_mapping, lo->old_gfp_mask);\n\tlo->lo_backing_file = file;\n\tlo->old_gfp_mask = mapping_gfp_mask(file->f_mapping);\n\tmapping_set_gfp_mask(file->f_mapping,\n\t\t\t     lo->old_gfp_mask & ~(__GFP_IO|__GFP_FS));\n\tloop_update_dio(lo);\n\tblk_mq_unfreeze_queue(lo->lo_queue);\n\tpartscan = lo->lo_flags & LO_FLAGS_PARTSCAN;\n\tloop_global_unlock(lo, is_loop);\n\n\t \n\tif (!is_loop) {\n\t\tmutex_lock(&loop_validate_mutex);\n\t\tmutex_unlock(&loop_validate_mutex);\n\t}\n\t \n\tfput(old_file);\n\tif (partscan)\n\t\tloop_reread_partitions(lo);\n\n\terror = 0;\ndone:\n\t \n\tdev_set_uevent_suppress(disk_to_dev(lo->lo_disk), 0);\n\treturn error;\n\nout_err:\n\tloop_global_unlock(lo, is_loop);\nout_putf:\n\tfput(file);\n\tgoto done;\n}\n\n \n\nstatic ssize_t loop_attr_show(struct device *dev, char *page,\n\t\t\t      ssize_t (*callback)(struct loop_device *, char *))\n{\n\tstruct gendisk *disk = dev_to_disk(dev);\n\tstruct loop_device *lo = disk->private_data;\n\n\treturn callback(lo, page);\n}\n\n#define LOOP_ATTR_RO(_name)\t\t\t\t\t\t\\\nstatic ssize_t loop_attr_##_name##_show(struct loop_device *, char *);\t\\\nstatic ssize_t loop_attr_do_show_##_name(struct device *d,\t\t\\\n\t\t\t\tstruct device_attribute *attr, char *b)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\treturn loop_attr_show(d, b, loop_attr_##_name##_show);\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic struct device_attribute loop_attr_##_name =\t\t\t\\\n\t__ATTR(_name, 0444, loop_attr_do_show_##_name, NULL);\n\nstatic ssize_t loop_attr_backing_file_show(struct loop_device *lo, char *buf)\n{\n\tssize_t ret;\n\tchar *p = NULL;\n\n\tspin_lock_irq(&lo->lo_lock);\n\tif (lo->lo_backing_file)\n\t\tp = file_path(lo->lo_backing_file, buf, PAGE_SIZE - 1);\n\tspin_unlock_irq(&lo->lo_lock);\n\n\tif (IS_ERR_OR_NULL(p))\n\t\tret = PTR_ERR(p);\n\telse {\n\t\tret = strlen(p);\n\t\tmemmove(buf, p, ret);\n\t\tbuf[ret++] = '\\n';\n\t\tbuf[ret] = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic ssize_t loop_attr_offset_show(struct loop_device *lo, char *buf)\n{\n\treturn sysfs_emit(buf, \"%llu\\n\", (unsigned long long)lo->lo_offset);\n}\n\nstatic ssize_t loop_attr_sizelimit_show(struct loop_device *lo, char *buf)\n{\n\treturn sysfs_emit(buf, \"%llu\\n\", (unsigned long long)lo->lo_sizelimit);\n}\n\nstatic ssize_t loop_attr_autoclear_show(struct loop_device *lo, char *buf)\n{\n\tint autoclear = (lo->lo_flags & LO_FLAGS_AUTOCLEAR);\n\n\treturn sysfs_emit(buf, \"%s\\n\", autoclear ? \"1\" : \"0\");\n}\n\nstatic ssize_t loop_attr_partscan_show(struct loop_device *lo, char *buf)\n{\n\tint partscan = (lo->lo_flags & LO_FLAGS_PARTSCAN);\n\n\treturn sysfs_emit(buf, \"%s\\n\", partscan ? \"1\" : \"0\");\n}\n\nstatic ssize_t loop_attr_dio_show(struct loop_device *lo, char *buf)\n{\n\tint dio = (lo->lo_flags & LO_FLAGS_DIRECT_IO);\n\n\treturn sysfs_emit(buf, \"%s\\n\", dio ? \"1\" : \"0\");\n}\n\nLOOP_ATTR_RO(backing_file);\nLOOP_ATTR_RO(offset);\nLOOP_ATTR_RO(sizelimit);\nLOOP_ATTR_RO(autoclear);\nLOOP_ATTR_RO(partscan);\nLOOP_ATTR_RO(dio);\n\nstatic struct attribute *loop_attrs[] = {\n\t&loop_attr_backing_file.attr,\n\t&loop_attr_offset.attr,\n\t&loop_attr_sizelimit.attr,\n\t&loop_attr_autoclear.attr,\n\t&loop_attr_partscan.attr,\n\t&loop_attr_dio.attr,\n\tNULL,\n};\n\nstatic struct attribute_group loop_attribute_group = {\n\t.name = \"loop\",\n\t.attrs= loop_attrs,\n};\n\nstatic void loop_sysfs_init(struct loop_device *lo)\n{\n\tlo->sysfs_inited = !sysfs_create_group(&disk_to_dev(lo->lo_disk)->kobj,\n\t\t\t\t\t\t&loop_attribute_group);\n}\n\nstatic void loop_sysfs_exit(struct loop_device *lo)\n{\n\tif (lo->sysfs_inited)\n\t\tsysfs_remove_group(&disk_to_dev(lo->lo_disk)->kobj,\n\t\t\t\t   &loop_attribute_group);\n}\n\nstatic void loop_config_discard(struct loop_device *lo)\n{\n\tstruct file *file = lo->lo_backing_file;\n\tstruct inode *inode = file->f_mapping->host;\n\tstruct request_queue *q = lo->lo_queue;\n\tu32 granularity, max_discard_sectors;\n\n\t \n\tif (S_ISBLK(inode->i_mode)) {\n\t\tstruct request_queue *backingq = bdev_get_queue(I_BDEV(inode));\n\n\t\tmax_discard_sectors = backingq->limits.max_write_zeroes_sectors;\n\t\tgranularity = bdev_discard_granularity(I_BDEV(inode)) ?:\n\t\t\tqueue_physical_block_size(backingq);\n\n\t \n\t} else if (!file->f_op->fallocate) {\n\t\tmax_discard_sectors = 0;\n\t\tgranularity = 0;\n\n\t} else {\n\t\tstruct kstatfs sbuf;\n\n\t\tmax_discard_sectors = UINT_MAX >> 9;\n\t\tif (!vfs_statfs(&file->f_path, &sbuf))\n\t\t\tgranularity = sbuf.f_bsize;\n\t\telse\n\t\t\tmax_discard_sectors = 0;\n\t}\n\n\tif (max_discard_sectors) {\n\t\tq->limits.discard_granularity = granularity;\n\t\tblk_queue_max_discard_sectors(q, max_discard_sectors);\n\t\tblk_queue_max_write_zeroes_sectors(q, max_discard_sectors);\n\t} else {\n\t\tq->limits.discard_granularity = 0;\n\t\tblk_queue_max_discard_sectors(q, 0);\n\t\tblk_queue_max_write_zeroes_sectors(q, 0);\n\t}\n}\n\nstruct loop_worker {\n\tstruct rb_node rb_node;\n\tstruct work_struct work;\n\tstruct list_head cmd_list;\n\tstruct list_head idle_list;\n\tstruct loop_device *lo;\n\tstruct cgroup_subsys_state *blkcg_css;\n\tunsigned long last_ran_at;\n};\n\nstatic void loop_workfn(struct work_struct *work);\n\n#ifdef CONFIG_BLK_CGROUP\nstatic inline int queue_on_root_worker(struct cgroup_subsys_state *css)\n{\n\treturn !css || css == blkcg_root_css;\n}\n#else\nstatic inline int queue_on_root_worker(struct cgroup_subsys_state *css)\n{\n\treturn !css;\n}\n#endif\n\nstatic void loop_queue_work(struct loop_device *lo, struct loop_cmd *cmd)\n{\n\tstruct rb_node **node, *parent = NULL;\n\tstruct loop_worker *cur_worker, *worker = NULL;\n\tstruct work_struct *work;\n\tstruct list_head *cmd_list;\n\n\tspin_lock_irq(&lo->lo_work_lock);\n\n\tif (queue_on_root_worker(cmd->blkcg_css))\n\t\tgoto queue_work;\n\n\tnode = &lo->worker_tree.rb_node;\n\n\twhile (*node) {\n\t\tparent = *node;\n\t\tcur_worker = container_of(*node, struct loop_worker, rb_node);\n\t\tif (cur_worker->blkcg_css == cmd->blkcg_css) {\n\t\t\tworker = cur_worker;\n\t\t\tbreak;\n\t\t} else if ((long)cur_worker->blkcg_css < (long)cmd->blkcg_css) {\n\t\t\tnode = &(*node)->rb_left;\n\t\t} else {\n\t\t\tnode = &(*node)->rb_right;\n\t\t}\n\t}\n\tif (worker)\n\t\tgoto queue_work;\n\n\tworker = kzalloc(sizeof(struct loop_worker), GFP_NOWAIT | __GFP_NOWARN);\n\t \n\tif (!worker) {\n\t\tcmd->blkcg_css = NULL;\n\t\tif (cmd->memcg_css)\n\t\t\tcss_put(cmd->memcg_css);\n\t\tcmd->memcg_css = NULL;\n\t\tgoto queue_work;\n\t}\n\n\tworker->blkcg_css = cmd->blkcg_css;\n\tcss_get(worker->blkcg_css);\n\tINIT_WORK(&worker->work, loop_workfn);\n\tINIT_LIST_HEAD(&worker->cmd_list);\n\tINIT_LIST_HEAD(&worker->idle_list);\n\tworker->lo = lo;\n\trb_link_node(&worker->rb_node, parent, node);\n\trb_insert_color(&worker->rb_node, &lo->worker_tree);\nqueue_work:\n\tif (worker) {\n\t\t \n\t\tif (!list_empty(&worker->idle_list))\n\t\t\tlist_del_init(&worker->idle_list);\n\t\twork = &worker->work;\n\t\tcmd_list = &worker->cmd_list;\n\t} else {\n\t\twork = &lo->rootcg_work;\n\t\tcmd_list = &lo->rootcg_cmd_list;\n\t}\n\tlist_add_tail(&cmd->list_entry, cmd_list);\n\tqueue_work(lo->workqueue, work);\n\tspin_unlock_irq(&lo->lo_work_lock);\n}\n\nstatic void loop_set_timer(struct loop_device *lo)\n{\n\ttimer_reduce(&lo->timer, jiffies + LOOP_IDLE_WORKER_TIMEOUT);\n}\n\nstatic void loop_free_idle_workers(struct loop_device *lo, bool delete_all)\n{\n\tstruct loop_worker *pos, *worker;\n\n\tspin_lock_irq(&lo->lo_work_lock);\n\tlist_for_each_entry_safe(worker, pos, &lo->idle_worker_list,\n\t\t\t\tidle_list) {\n\t\tif (!delete_all &&\n\t\t    time_is_after_jiffies(worker->last_ran_at +\n\t\t\t\t\t  LOOP_IDLE_WORKER_TIMEOUT))\n\t\t\tbreak;\n\t\tlist_del(&worker->idle_list);\n\t\trb_erase(&worker->rb_node, &lo->worker_tree);\n\t\tcss_put(worker->blkcg_css);\n\t\tkfree(worker);\n\t}\n\tif (!list_empty(&lo->idle_worker_list))\n\t\tloop_set_timer(lo);\n\tspin_unlock_irq(&lo->lo_work_lock);\n}\n\nstatic void loop_free_idle_workers_timer(struct timer_list *timer)\n{\n\tstruct loop_device *lo = container_of(timer, struct loop_device, timer);\n\n\treturn loop_free_idle_workers(lo, false);\n}\n\nstatic void loop_update_rotational(struct loop_device *lo)\n{\n\tstruct file *file = lo->lo_backing_file;\n\tstruct inode *file_inode = file->f_mapping->host;\n\tstruct block_device *file_bdev = file_inode->i_sb->s_bdev;\n\tstruct request_queue *q = lo->lo_queue;\n\tbool nonrot = true;\n\n\t \n\tif (file_bdev)\n\t\tnonrot = bdev_nonrot(file_bdev);\n\n\tif (nonrot)\n\t\tblk_queue_flag_set(QUEUE_FLAG_NONROT, q);\n\telse\n\t\tblk_queue_flag_clear(QUEUE_FLAG_NONROT, q);\n}\n\n \nstatic int\nloop_set_status_from_info(struct loop_device *lo,\n\t\t\t  const struct loop_info64 *info)\n{\n\tif ((unsigned int) info->lo_encrypt_key_size > LO_KEY_SIZE)\n\t\treturn -EINVAL;\n\n\tswitch (info->lo_encrypt_type) {\n\tcase LO_CRYPT_NONE:\n\t\tbreak;\n\tcase LO_CRYPT_XOR:\n\t\tpr_warn(\"support for the xor transformation has been removed.\\n\");\n\t\treturn -EINVAL;\n\tcase LO_CRYPT_CRYPTOAPI:\n\t\tpr_warn(\"support for cryptoloop has been removed.  Use dm-crypt instead.\\n\");\n\t\treturn -EINVAL;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (info->lo_offset > LLONG_MAX || info->lo_sizelimit > LLONG_MAX)\n\t\treturn -EOVERFLOW;\n\n\tlo->lo_offset = info->lo_offset;\n\tlo->lo_sizelimit = info->lo_sizelimit;\n\n\tmemcpy(lo->lo_file_name, info->lo_file_name, LO_NAME_SIZE);\n\tlo->lo_file_name[LO_NAME_SIZE-1] = 0;\n\tlo->lo_flags = info->lo_flags;\n\treturn 0;\n}\n\nstatic int loop_configure(struct loop_device *lo, blk_mode_t mode,\n\t\t\t  struct block_device *bdev,\n\t\t\t  const struct loop_config *config)\n{\n\tstruct file *file = fget(config->fd);\n\tstruct inode *inode;\n\tstruct address_space *mapping;\n\tint error;\n\tloff_t size;\n\tbool partscan;\n\tunsigned short bsize;\n\tbool is_loop;\n\n\tif (!file)\n\t\treturn -EBADF;\n\tis_loop = is_loop_device(file);\n\n\t \n\t__module_get(THIS_MODULE);\n\n\t \n\tif (!(mode & BLK_OPEN_EXCL)) {\n\t\terror = bd_prepare_to_claim(bdev, loop_configure, NULL);\n\t\tif (error)\n\t\t\tgoto out_putf;\n\t}\n\n\terror = loop_global_lock_killable(lo, is_loop);\n\tif (error)\n\t\tgoto out_bdev;\n\n\terror = -EBUSY;\n\tif (lo->lo_state != Lo_unbound)\n\t\tgoto out_unlock;\n\n\terror = loop_validate_file(file, bdev);\n\tif (error)\n\t\tgoto out_unlock;\n\n\tmapping = file->f_mapping;\n\tinode = mapping->host;\n\n\tif ((config->info.lo_flags & ~LOOP_CONFIGURE_SETTABLE_FLAGS) != 0) {\n\t\terror = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tif (config->block_size) {\n\t\terror = blk_validate_block_size(config->block_size);\n\t\tif (error)\n\t\t\tgoto out_unlock;\n\t}\n\n\terror = loop_set_status_from_info(lo, &config->info);\n\tif (error)\n\t\tgoto out_unlock;\n\n\tif (!(file->f_mode & FMODE_WRITE) || !(mode & BLK_OPEN_WRITE) ||\n\t    !file->f_op->write_iter)\n\t\tlo->lo_flags |= LO_FLAGS_READ_ONLY;\n\n\tif (!lo->workqueue) {\n\t\tlo->workqueue = alloc_workqueue(\"loop%d\",\n\t\t\t\t\t\tWQ_UNBOUND | WQ_FREEZABLE,\n\t\t\t\t\t\t0, lo->lo_number);\n\t\tif (!lo->workqueue) {\n\t\t\terror = -ENOMEM;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\t \n\tdev_set_uevent_suppress(disk_to_dev(lo->lo_disk), 1);\n\n\tdisk_force_media_change(lo->lo_disk);\n\tset_disk_ro(lo->lo_disk, (lo->lo_flags & LO_FLAGS_READ_ONLY) != 0);\n\n\tlo->use_dio = lo->lo_flags & LO_FLAGS_DIRECT_IO;\n\tlo->lo_device = bdev;\n\tlo->lo_backing_file = file;\n\tlo->old_gfp_mask = mapping_gfp_mask(mapping);\n\tmapping_set_gfp_mask(mapping, lo->old_gfp_mask & ~(__GFP_IO|__GFP_FS));\n\n\tif (!(lo->lo_flags & LO_FLAGS_READ_ONLY) && file->f_op->fsync)\n\t\tblk_queue_write_cache(lo->lo_queue, true, false);\n\n\tif (config->block_size)\n\t\tbsize = config->block_size;\n\telse if ((lo->lo_backing_file->f_flags & O_DIRECT) && inode->i_sb->s_bdev)\n\t\t \n\t\tbsize = bdev_logical_block_size(inode->i_sb->s_bdev);\n\telse\n\t\tbsize = 512;\n\n\tblk_queue_logical_block_size(lo->lo_queue, bsize);\n\tblk_queue_physical_block_size(lo->lo_queue, bsize);\n\tblk_queue_io_min(lo->lo_queue, bsize);\n\n\tloop_config_discard(lo);\n\tloop_update_rotational(lo);\n\tloop_update_dio(lo);\n\tloop_sysfs_init(lo);\n\n\tsize = get_loop_size(lo, file);\n\tloop_set_size(lo, size);\n\n\t \n\twmb();\n\n\tlo->lo_state = Lo_bound;\n\tif (part_shift)\n\t\tlo->lo_flags |= LO_FLAGS_PARTSCAN;\n\tpartscan = lo->lo_flags & LO_FLAGS_PARTSCAN;\n\tif (partscan)\n\t\tclear_bit(GD_SUPPRESS_PART_SCAN, &lo->lo_disk->state);\n\n\t \n\tdev_set_uevent_suppress(disk_to_dev(lo->lo_disk), 0);\n\n\tloop_global_unlock(lo, is_loop);\n\tif (partscan)\n\t\tloop_reread_partitions(lo);\n\n\tif (!(mode & BLK_OPEN_EXCL))\n\t\tbd_abort_claiming(bdev, loop_configure);\n\n\treturn 0;\n\nout_unlock:\n\tloop_global_unlock(lo, is_loop);\nout_bdev:\n\tif (!(mode & BLK_OPEN_EXCL))\n\t\tbd_abort_claiming(bdev, loop_configure);\nout_putf:\n\tfput(file);\n\t \n\tmodule_put(THIS_MODULE);\n\treturn error;\n}\n\nstatic void __loop_clr_fd(struct loop_device *lo, bool release)\n{\n\tstruct file *filp;\n\tgfp_t gfp = lo->old_gfp_mask;\n\n\tif (test_bit(QUEUE_FLAG_WC, &lo->lo_queue->queue_flags))\n\t\tblk_queue_write_cache(lo->lo_queue, false, false);\n\n\t \n\tif (!release)\n\t\tblk_mq_freeze_queue(lo->lo_queue);\n\n\tspin_lock_irq(&lo->lo_lock);\n\tfilp = lo->lo_backing_file;\n\tlo->lo_backing_file = NULL;\n\tspin_unlock_irq(&lo->lo_lock);\n\n\tlo->lo_device = NULL;\n\tlo->lo_offset = 0;\n\tlo->lo_sizelimit = 0;\n\tmemset(lo->lo_file_name, 0, LO_NAME_SIZE);\n\tblk_queue_logical_block_size(lo->lo_queue, 512);\n\tblk_queue_physical_block_size(lo->lo_queue, 512);\n\tblk_queue_io_min(lo->lo_queue, 512);\n\tinvalidate_disk(lo->lo_disk);\n\tloop_sysfs_exit(lo);\n\t \n\tkobject_uevent(&disk_to_dev(lo->lo_disk)->kobj, KOBJ_CHANGE);\n\tmapping_set_gfp_mask(filp->f_mapping, gfp);\n\t \n\tmodule_put(THIS_MODULE);\n\tif (!release)\n\t\tblk_mq_unfreeze_queue(lo->lo_queue);\n\n\tdisk_force_media_change(lo->lo_disk);\n\n\tif (lo->lo_flags & LO_FLAGS_PARTSCAN) {\n\t\tint err;\n\n\t\t \n\t\tif (!release)\n\t\t\tmutex_lock(&lo->lo_disk->open_mutex);\n\t\terr = bdev_disk_changed(lo->lo_disk, false);\n\t\tif (!release)\n\t\t\tmutex_unlock(&lo->lo_disk->open_mutex);\n\t\tif (err)\n\t\t\tpr_warn(\"%s: partition scan of loop%d failed (rc=%d)\\n\",\n\t\t\t\t__func__, lo->lo_number, err);\n\t\t \n\t}\n\n\t \n\tlo->lo_flags = 0;\n\tif (!part_shift)\n\t\tset_bit(GD_SUPPRESS_PART_SCAN, &lo->lo_disk->state);\n\tmutex_lock(&lo->lo_mutex);\n\tlo->lo_state = Lo_unbound;\n\tmutex_unlock(&lo->lo_mutex);\n\n\t \n\tfput(filp);\n}\n\nstatic int loop_clr_fd(struct loop_device *lo)\n{\n\tint err;\n\n\t \n\terr = loop_global_lock_killable(lo, true);\n\tif (err)\n\t\treturn err;\n\tif (lo->lo_state != Lo_bound) {\n\t\tloop_global_unlock(lo, true);\n\t\treturn -ENXIO;\n\t}\n\t \n\tif (disk_openers(lo->lo_disk) > 1) {\n\t\tlo->lo_flags |= LO_FLAGS_AUTOCLEAR;\n\t\tloop_global_unlock(lo, true);\n\t\treturn 0;\n\t}\n\tlo->lo_state = Lo_rundown;\n\tloop_global_unlock(lo, true);\n\n\t__loop_clr_fd(lo, false);\n\treturn 0;\n}\n\nstatic int\nloop_set_status(struct loop_device *lo, const struct loop_info64 *info)\n{\n\tint err;\n\tint prev_lo_flags;\n\tbool partscan = false;\n\tbool size_changed = false;\n\n\terr = mutex_lock_killable(&lo->lo_mutex);\n\tif (err)\n\t\treturn err;\n\tif (lo->lo_state != Lo_bound) {\n\t\terr = -ENXIO;\n\t\tgoto out_unlock;\n\t}\n\n\tif (lo->lo_offset != info->lo_offset ||\n\t    lo->lo_sizelimit != info->lo_sizelimit) {\n\t\tsize_changed = true;\n\t\tsync_blockdev(lo->lo_device);\n\t\tinvalidate_bdev(lo->lo_device);\n\t}\n\n\t \n\tblk_mq_freeze_queue(lo->lo_queue);\n\n\tprev_lo_flags = lo->lo_flags;\n\n\terr = loop_set_status_from_info(lo, info);\n\tif (err)\n\t\tgoto out_unfreeze;\n\n\t \n\tlo->lo_flags &= LOOP_SET_STATUS_SETTABLE_FLAGS;\n\t \n\tlo->lo_flags |= prev_lo_flags & ~LOOP_SET_STATUS_SETTABLE_FLAGS;\n\t \n\tlo->lo_flags |= prev_lo_flags & ~LOOP_SET_STATUS_CLEARABLE_FLAGS;\n\n\tif (size_changed) {\n\t\tloff_t new_size = get_size(lo->lo_offset, lo->lo_sizelimit,\n\t\t\t\t\t   lo->lo_backing_file);\n\t\tloop_set_size(lo, new_size);\n\t}\n\n\tloop_config_discard(lo);\n\n\t \n\t__loop_update_dio(lo, lo->use_dio);\n\nout_unfreeze:\n\tblk_mq_unfreeze_queue(lo->lo_queue);\n\n\tif (!err && (lo->lo_flags & LO_FLAGS_PARTSCAN) &&\n\t     !(prev_lo_flags & LO_FLAGS_PARTSCAN)) {\n\t\tclear_bit(GD_SUPPRESS_PART_SCAN, &lo->lo_disk->state);\n\t\tpartscan = true;\n\t}\nout_unlock:\n\tmutex_unlock(&lo->lo_mutex);\n\tif (partscan)\n\t\tloop_reread_partitions(lo);\n\n\treturn err;\n}\n\nstatic int\nloop_get_status(struct loop_device *lo, struct loop_info64 *info)\n{\n\tstruct path path;\n\tstruct kstat stat;\n\tint ret;\n\n\tret = mutex_lock_killable(&lo->lo_mutex);\n\tif (ret)\n\t\treturn ret;\n\tif (lo->lo_state != Lo_bound) {\n\t\tmutex_unlock(&lo->lo_mutex);\n\t\treturn -ENXIO;\n\t}\n\n\tmemset(info, 0, sizeof(*info));\n\tinfo->lo_number = lo->lo_number;\n\tinfo->lo_offset = lo->lo_offset;\n\tinfo->lo_sizelimit = lo->lo_sizelimit;\n\tinfo->lo_flags = lo->lo_flags;\n\tmemcpy(info->lo_file_name, lo->lo_file_name, LO_NAME_SIZE);\n\n\t \n\tpath = lo->lo_backing_file->f_path;\n\tpath_get(&path);\n\tmutex_unlock(&lo->lo_mutex);\n\tret = vfs_getattr(&path, &stat, STATX_INO, AT_STATX_SYNC_AS_STAT);\n\tif (!ret) {\n\t\tinfo->lo_device = huge_encode_dev(stat.dev);\n\t\tinfo->lo_inode = stat.ino;\n\t\tinfo->lo_rdevice = huge_encode_dev(stat.rdev);\n\t}\n\tpath_put(&path);\n\treturn ret;\n}\n\nstatic void\nloop_info64_from_old(const struct loop_info *info, struct loop_info64 *info64)\n{\n\tmemset(info64, 0, sizeof(*info64));\n\tinfo64->lo_number = info->lo_number;\n\tinfo64->lo_device = info->lo_device;\n\tinfo64->lo_inode = info->lo_inode;\n\tinfo64->lo_rdevice = info->lo_rdevice;\n\tinfo64->lo_offset = info->lo_offset;\n\tinfo64->lo_sizelimit = 0;\n\tinfo64->lo_flags = info->lo_flags;\n\tmemcpy(info64->lo_file_name, info->lo_name, LO_NAME_SIZE);\n}\n\nstatic int\nloop_info64_to_old(const struct loop_info64 *info64, struct loop_info *info)\n{\n\tmemset(info, 0, sizeof(*info));\n\tinfo->lo_number = info64->lo_number;\n\tinfo->lo_device = info64->lo_device;\n\tinfo->lo_inode = info64->lo_inode;\n\tinfo->lo_rdevice = info64->lo_rdevice;\n\tinfo->lo_offset = info64->lo_offset;\n\tinfo->lo_flags = info64->lo_flags;\n\tmemcpy(info->lo_name, info64->lo_file_name, LO_NAME_SIZE);\n\n\t \n\tif (info->lo_device != info64->lo_device ||\n\t    info->lo_rdevice != info64->lo_rdevice ||\n\t    info->lo_inode != info64->lo_inode ||\n\t    info->lo_offset != info64->lo_offset)\n\t\treturn -EOVERFLOW;\n\n\treturn 0;\n}\n\nstatic int\nloop_set_status_old(struct loop_device *lo, const struct loop_info __user *arg)\n{\n\tstruct loop_info info;\n\tstruct loop_info64 info64;\n\n\tif (copy_from_user(&info, arg, sizeof (struct loop_info)))\n\t\treturn -EFAULT;\n\tloop_info64_from_old(&info, &info64);\n\treturn loop_set_status(lo, &info64);\n}\n\nstatic int\nloop_set_status64(struct loop_device *lo, const struct loop_info64 __user *arg)\n{\n\tstruct loop_info64 info64;\n\n\tif (copy_from_user(&info64, arg, sizeof (struct loop_info64)))\n\t\treturn -EFAULT;\n\treturn loop_set_status(lo, &info64);\n}\n\nstatic int\nloop_get_status_old(struct loop_device *lo, struct loop_info __user *arg) {\n\tstruct loop_info info;\n\tstruct loop_info64 info64;\n\tint err;\n\n\tif (!arg)\n\t\treturn -EINVAL;\n\terr = loop_get_status(lo, &info64);\n\tif (!err)\n\t\terr = loop_info64_to_old(&info64, &info);\n\tif (!err && copy_to_user(arg, &info, sizeof(info)))\n\t\terr = -EFAULT;\n\n\treturn err;\n}\n\nstatic int\nloop_get_status64(struct loop_device *lo, struct loop_info64 __user *arg) {\n\tstruct loop_info64 info64;\n\tint err;\n\n\tif (!arg)\n\t\treturn -EINVAL;\n\terr = loop_get_status(lo, &info64);\n\tif (!err && copy_to_user(arg, &info64, sizeof(info64)))\n\t\terr = -EFAULT;\n\n\treturn err;\n}\n\nstatic int loop_set_capacity(struct loop_device *lo)\n{\n\tloff_t size;\n\n\tif (unlikely(lo->lo_state != Lo_bound))\n\t\treturn -ENXIO;\n\n\tsize = get_loop_size(lo, lo->lo_backing_file);\n\tloop_set_size(lo, size);\n\n\treturn 0;\n}\n\nstatic int loop_set_dio(struct loop_device *lo, unsigned long arg)\n{\n\tint error = -ENXIO;\n\tif (lo->lo_state != Lo_bound)\n\t\tgoto out;\n\n\t__loop_update_dio(lo, !!arg);\n\tif (lo->use_dio == !!arg)\n\t\treturn 0;\n\terror = -EINVAL;\n out:\n\treturn error;\n}\n\nstatic int loop_set_block_size(struct loop_device *lo, unsigned long arg)\n{\n\tint err = 0;\n\n\tif (lo->lo_state != Lo_bound)\n\t\treturn -ENXIO;\n\n\terr = blk_validate_block_size(arg);\n\tif (err)\n\t\treturn err;\n\n\tif (lo->lo_queue->limits.logical_block_size == arg)\n\t\treturn 0;\n\n\tsync_blockdev(lo->lo_device);\n\tinvalidate_bdev(lo->lo_device);\n\n\tblk_mq_freeze_queue(lo->lo_queue);\n\tblk_queue_logical_block_size(lo->lo_queue, arg);\n\tblk_queue_physical_block_size(lo->lo_queue, arg);\n\tblk_queue_io_min(lo->lo_queue, arg);\n\tloop_update_dio(lo);\n\tblk_mq_unfreeze_queue(lo->lo_queue);\n\n\treturn err;\n}\n\nstatic int lo_simple_ioctl(struct loop_device *lo, unsigned int cmd,\n\t\t\t   unsigned long arg)\n{\n\tint err;\n\n\terr = mutex_lock_killable(&lo->lo_mutex);\n\tif (err)\n\t\treturn err;\n\tswitch (cmd) {\n\tcase LOOP_SET_CAPACITY:\n\t\terr = loop_set_capacity(lo);\n\t\tbreak;\n\tcase LOOP_SET_DIRECT_IO:\n\t\terr = loop_set_dio(lo, arg);\n\t\tbreak;\n\tcase LOOP_SET_BLOCK_SIZE:\n\t\terr = loop_set_block_size(lo, arg);\n\t\tbreak;\n\tdefault:\n\t\terr = -EINVAL;\n\t}\n\tmutex_unlock(&lo->lo_mutex);\n\treturn err;\n}\n\nstatic int lo_ioctl(struct block_device *bdev, blk_mode_t mode,\n\tunsigned int cmd, unsigned long arg)\n{\n\tstruct loop_device *lo = bdev->bd_disk->private_data;\n\tvoid __user *argp = (void __user *) arg;\n\tint err;\n\n\tswitch (cmd) {\n\tcase LOOP_SET_FD: {\n\t\t \n\t\tstruct loop_config config;\n\n\t\tmemset(&config, 0, sizeof(config));\n\t\tconfig.fd = arg;\n\n\t\treturn loop_configure(lo, mode, bdev, &config);\n\t}\n\tcase LOOP_CONFIGURE: {\n\t\tstruct loop_config config;\n\n\t\tif (copy_from_user(&config, argp, sizeof(config)))\n\t\t\treturn -EFAULT;\n\n\t\treturn loop_configure(lo, mode, bdev, &config);\n\t}\n\tcase LOOP_CHANGE_FD:\n\t\treturn loop_change_fd(lo, bdev, arg);\n\tcase LOOP_CLR_FD:\n\t\treturn loop_clr_fd(lo);\n\tcase LOOP_SET_STATUS:\n\t\terr = -EPERM;\n\t\tif ((mode & BLK_OPEN_WRITE) || capable(CAP_SYS_ADMIN))\n\t\t\terr = loop_set_status_old(lo, argp);\n\t\tbreak;\n\tcase LOOP_GET_STATUS:\n\t\treturn loop_get_status_old(lo, argp);\n\tcase LOOP_SET_STATUS64:\n\t\terr = -EPERM;\n\t\tif ((mode & BLK_OPEN_WRITE) || capable(CAP_SYS_ADMIN))\n\t\t\terr = loop_set_status64(lo, argp);\n\t\tbreak;\n\tcase LOOP_GET_STATUS64:\n\t\treturn loop_get_status64(lo, argp);\n\tcase LOOP_SET_CAPACITY:\n\tcase LOOP_SET_DIRECT_IO:\n\tcase LOOP_SET_BLOCK_SIZE:\n\t\tif (!(mode & BLK_OPEN_WRITE) && !capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tfallthrough;\n\tdefault:\n\t\terr = lo_simple_ioctl(lo, cmd, arg);\n\t\tbreak;\n\t}\n\n\treturn err;\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_loop_info {\n\tcompat_int_t\tlo_number;       \n\tcompat_dev_t\tlo_device;       \n\tcompat_ulong_t\tlo_inode;        \n\tcompat_dev_t\tlo_rdevice;      \n\tcompat_int_t\tlo_offset;\n\tcompat_int_t\tlo_encrypt_type;         \n\tcompat_int_t\tlo_encrypt_key_size;     \n\tcompat_int_t\tlo_flags;        \n\tchar\t\tlo_name[LO_NAME_SIZE];\n\tunsigned char\tlo_encrypt_key[LO_KEY_SIZE];  \n\tcompat_ulong_t\tlo_init[2];\n\tchar\t\treserved[4];\n};\n\n \nstatic noinline int\nloop_info64_from_compat(const struct compat_loop_info __user *arg,\n\t\t\tstruct loop_info64 *info64)\n{\n\tstruct compat_loop_info info;\n\n\tif (copy_from_user(&info, arg, sizeof(info)))\n\t\treturn -EFAULT;\n\n\tmemset(info64, 0, sizeof(*info64));\n\tinfo64->lo_number = info.lo_number;\n\tinfo64->lo_device = info.lo_device;\n\tinfo64->lo_inode = info.lo_inode;\n\tinfo64->lo_rdevice = info.lo_rdevice;\n\tinfo64->lo_offset = info.lo_offset;\n\tinfo64->lo_sizelimit = 0;\n\tinfo64->lo_flags = info.lo_flags;\n\tmemcpy(info64->lo_file_name, info.lo_name, LO_NAME_SIZE);\n\treturn 0;\n}\n\n \nstatic noinline int\nloop_info64_to_compat(const struct loop_info64 *info64,\n\t\t      struct compat_loop_info __user *arg)\n{\n\tstruct compat_loop_info info;\n\n\tmemset(&info, 0, sizeof(info));\n\tinfo.lo_number = info64->lo_number;\n\tinfo.lo_device = info64->lo_device;\n\tinfo.lo_inode = info64->lo_inode;\n\tinfo.lo_rdevice = info64->lo_rdevice;\n\tinfo.lo_offset = info64->lo_offset;\n\tinfo.lo_flags = info64->lo_flags;\n\tmemcpy(info.lo_name, info64->lo_file_name, LO_NAME_SIZE);\n\n\t \n\tif (info.lo_device != info64->lo_device ||\n\t    info.lo_rdevice != info64->lo_rdevice ||\n\t    info.lo_inode != info64->lo_inode ||\n\t    info.lo_offset != info64->lo_offset)\n\t\treturn -EOVERFLOW;\n\n\tif (copy_to_user(arg, &info, sizeof(info)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int\nloop_set_status_compat(struct loop_device *lo,\n\t\t       const struct compat_loop_info __user *arg)\n{\n\tstruct loop_info64 info64;\n\tint ret;\n\n\tret = loop_info64_from_compat(arg, &info64);\n\tif (ret < 0)\n\t\treturn ret;\n\treturn loop_set_status(lo, &info64);\n}\n\nstatic int\nloop_get_status_compat(struct loop_device *lo,\n\t\t       struct compat_loop_info __user *arg)\n{\n\tstruct loop_info64 info64;\n\tint err;\n\n\tif (!arg)\n\t\treturn -EINVAL;\n\terr = loop_get_status(lo, &info64);\n\tif (!err)\n\t\terr = loop_info64_to_compat(&info64, arg);\n\treturn err;\n}\n\nstatic int lo_compat_ioctl(struct block_device *bdev, blk_mode_t mode,\n\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\tstruct loop_device *lo = bdev->bd_disk->private_data;\n\tint err;\n\n\tswitch(cmd) {\n\tcase LOOP_SET_STATUS:\n\t\terr = loop_set_status_compat(lo,\n\t\t\t     (const struct compat_loop_info __user *)arg);\n\t\tbreak;\n\tcase LOOP_GET_STATUS:\n\t\terr = loop_get_status_compat(lo,\n\t\t\t\t     (struct compat_loop_info __user *)arg);\n\t\tbreak;\n\tcase LOOP_SET_CAPACITY:\n\tcase LOOP_CLR_FD:\n\tcase LOOP_GET_STATUS64:\n\tcase LOOP_SET_STATUS64:\n\tcase LOOP_CONFIGURE:\n\t\targ = (unsigned long) compat_ptr(arg);\n\t\tfallthrough;\n\tcase LOOP_SET_FD:\n\tcase LOOP_CHANGE_FD:\n\tcase LOOP_SET_BLOCK_SIZE:\n\tcase LOOP_SET_DIRECT_IO:\n\t\terr = lo_ioctl(bdev, mode, cmd, arg);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOIOCTLCMD;\n\t\tbreak;\n\t}\n\treturn err;\n}\n#endif\n\nstatic void lo_release(struct gendisk *disk)\n{\n\tstruct loop_device *lo = disk->private_data;\n\n\tif (disk_openers(disk) > 0)\n\t\treturn;\n\n\tmutex_lock(&lo->lo_mutex);\n\tif (lo->lo_state == Lo_bound && (lo->lo_flags & LO_FLAGS_AUTOCLEAR)) {\n\t\tlo->lo_state = Lo_rundown;\n\t\tmutex_unlock(&lo->lo_mutex);\n\t\t \n\t\t__loop_clr_fd(lo, true);\n\t\treturn;\n\t}\n\tmutex_unlock(&lo->lo_mutex);\n}\n\nstatic void lo_free_disk(struct gendisk *disk)\n{\n\tstruct loop_device *lo = disk->private_data;\n\n\tif (lo->workqueue)\n\t\tdestroy_workqueue(lo->workqueue);\n\tloop_free_idle_workers(lo, true);\n\ttimer_shutdown_sync(&lo->timer);\n\tmutex_destroy(&lo->lo_mutex);\n\tkfree(lo);\n}\n\nstatic const struct block_device_operations lo_fops = {\n\t.owner =\tTHIS_MODULE,\n\t.release =\tlo_release,\n\t.ioctl =\tlo_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl =\tlo_compat_ioctl,\n#endif\n\t.free_disk =\tlo_free_disk,\n};\n\n \n\n \nstatic int max_loop = CONFIG_BLK_DEV_LOOP_MIN_COUNT;\n\n#ifdef CONFIG_BLOCK_LEGACY_AUTOLOAD\nstatic bool max_loop_specified;\n\nstatic int max_loop_param_set_int(const char *val,\n\t\t\t\t  const struct kernel_param *kp)\n{\n\tint ret;\n\n\tret = param_set_int(val, kp);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmax_loop_specified = true;\n\treturn 0;\n}\n\nstatic const struct kernel_param_ops max_loop_param_ops = {\n\t.set = max_loop_param_set_int,\n\t.get = param_get_int,\n};\n\nmodule_param_cb(max_loop, &max_loop_param_ops, &max_loop, 0444);\nMODULE_PARM_DESC(max_loop, \"Maximum number of loop devices\");\n#else\nmodule_param(max_loop, int, 0444);\nMODULE_PARM_DESC(max_loop, \"Initial number of loop devices\");\n#endif\n\nmodule_param(max_part, int, 0444);\nMODULE_PARM_DESC(max_part, \"Maximum number of partitions per loop device\");\n\nstatic int hw_queue_depth = LOOP_DEFAULT_HW_Q_DEPTH;\n\nstatic int loop_set_hw_queue_depth(const char *s, const struct kernel_param *p)\n{\n\tint qd, ret;\n\n\tret = kstrtoint(s, 0, &qd);\n\tif (ret < 0)\n\t\treturn ret;\n\tif (qd < 1)\n\t\treturn -EINVAL;\n\thw_queue_depth = qd;\n\treturn 0;\n}\n\nstatic const struct kernel_param_ops loop_hw_qdepth_param_ops = {\n\t.set\t= loop_set_hw_queue_depth,\n\t.get\t= param_get_int,\n};\n\ndevice_param_cb(hw_queue_depth, &loop_hw_qdepth_param_ops, &hw_queue_depth, 0444);\nMODULE_PARM_DESC(hw_queue_depth, \"Queue depth for each hardware queue. Default: \" __stringify(LOOP_DEFAULT_HW_Q_DEPTH));\n\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_BLOCKDEV_MAJOR(LOOP_MAJOR);\n\nstatic blk_status_t loop_queue_rq(struct blk_mq_hw_ctx *hctx,\n\t\tconst struct blk_mq_queue_data *bd)\n{\n\tstruct request *rq = bd->rq;\n\tstruct loop_cmd *cmd = blk_mq_rq_to_pdu(rq);\n\tstruct loop_device *lo = rq->q->queuedata;\n\n\tblk_mq_start_request(rq);\n\n\tif (lo->lo_state != Lo_bound)\n\t\treturn BLK_STS_IOERR;\n\n\tswitch (req_op(rq)) {\n\tcase REQ_OP_FLUSH:\n\tcase REQ_OP_DISCARD:\n\tcase REQ_OP_WRITE_ZEROES:\n\t\tcmd->use_aio = false;\n\t\tbreak;\n\tdefault:\n\t\tcmd->use_aio = lo->use_dio;\n\t\tbreak;\n\t}\n\n\t \n\tcmd->blkcg_css = NULL;\n\tcmd->memcg_css = NULL;\n#ifdef CONFIG_BLK_CGROUP\n\tif (rq->bio) {\n\t\tcmd->blkcg_css = bio_blkcg_css(rq->bio);\n#ifdef CONFIG_MEMCG\n\t\tif (cmd->blkcg_css) {\n\t\t\tcmd->memcg_css =\n\t\t\t\tcgroup_get_e_css(cmd->blkcg_css->cgroup,\n\t\t\t\t\t\t&memory_cgrp_subsys);\n\t\t}\n#endif\n\t}\n#endif\n\tloop_queue_work(lo, cmd);\n\n\treturn BLK_STS_OK;\n}\n\nstatic void loop_handle_cmd(struct loop_cmd *cmd)\n{\n\tstruct cgroup_subsys_state *cmd_blkcg_css = cmd->blkcg_css;\n\tstruct cgroup_subsys_state *cmd_memcg_css = cmd->memcg_css;\n\tstruct request *rq = blk_mq_rq_from_pdu(cmd);\n\tconst bool write = op_is_write(req_op(rq));\n\tstruct loop_device *lo = rq->q->queuedata;\n\tint ret = 0;\n\tstruct mem_cgroup *old_memcg = NULL;\n\tconst bool use_aio = cmd->use_aio;\n\n\tif (write && (lo->lo_flags & LO_FLAGS_READ_ONLY)) {\n\t\tret = -EIO;\n\t\tgoto failed;\n\t}\n\n\tif (cmd_blkcg_css)\n\t\tkthread_associate_blkcg(cmd_blkcg_css);\n\tif (cmd_memcg_css)\n\t\told_memcg = set_active_memcg(\n\t\t\tmem_cgroup_from_css(cmd_memcg_css));\n\n\t \n\tret = do_req_filebacked(lo, rq);\n\n\tif (cmd_blkcg_css)\n\t\tkthread_associate_blkcg(NULL);\n\n\tif (cmd_memcg_css) {\n\t\tset_active_memcg(old_memcg);\n\t\tcss_put(cmd_memcg_css);\n\t}\n failed:\n\t \n\tif (!use_aio || ret) {\n\t\tif (ret == -EOPNOTSUPP)\n\t\t\tcmd->ret = ret;\n\t\telse\n\t\t\tcmd->ret = ret ? -EIO : 0;\n\t\tif (likely(!blk_should_fake_timeout(rq->q)))\n\t\t\tblk_mq_complete_request(rq);\n\t}\n}\n\nstatic void loop_process_work(struct loop_worker *worker,\n\t\t\tstruct list_head *cmd_list, struct loop_device *lo)\n{\n\tint orig_flags = current->flags;\n\tstruct loop_cmd *cmd;\n\n\tcurrent->flags |= PF_LOCAL_THROTTLE | PF_MEMALLOC_NOIO;\n\tspin_lock_irq(&lo->lo_work_lock);\n\twhile (!list_empty(cmd_list)) {\n\t\tcmd = container_of(\n\t\t\tcmd_list->next, struct loop_cmd, list_entry);\n\t\tlist_del(cmd_list->next);\n\t\tspin_unlock_irq(&lo->lo_work_lock);\n\n\t\tloop_handle_cmd(cmd);\n\t\tcond_resched();\n\n\t\tspin_lock_irq(&lo->lo_work_lock);\n\t}\n\n\t \n\tif (worker && !work_pending(&worker->work)) {\n\t\tworker->last_ran_at = jiffies;\n\t\tlist_add_tail(&worker->idle_list, &lo->idle_worker_list);\n\t\tloop_set_timer(lo);\n\t}\n\tspin_unlock_irq(&lo->lo_work_lock);\n\tcurrent->flags = orig_flags;\n}\n\nstatic void loop_workfn(struct work_struct *work)\n{\n\tstruct loop_worker *worker =\n\t\tcontainer_of(work, struct loop_worker, work);\n\tloop_process_work(worker, &worker->cmd_list, worker->lo);\n}\n\nstatic void loop_rootcg_workfn(struct work_struct *work)\n{\n\tstruct loop_device *lo =\n\t\tcontainer_of(work, struct loop_device, rootcg_work);\n\tloop_process_work(NULL, &lo->rootcg_cmd_list, lo);\n}\n\nstatic const struct blk_mq_ops loop_mq_ops = {\n\t.queue_rq       = loop_queue_rq,\n\t.complete\t= lo_complete_rq,\n};\n\nstatic int loop_add(int i)\n{\n\tstruct loop_device *lo;\n\tstruct gendisk *disk;\n\tint err;\n\n\terr = -ENOMEM;\n\tlo = kzalloc(sizeof(*lo), GFP_KERNEL);\n\tif (!lo)\n\t\tgoto out;\n\tlo->worker_tree = RB_ROOT;\n\tINIT_LIST_HEAD(&lo->idle_worker_list);\n\ttimer_setup(&lo->timer, loop_free_idle_workers_timer, TIMER_DEFERRABLE);\n\tlo->lo_state = Lo_unbound;\n\n\terr = mutex_lock_killable(&loop_ctl_mutex);\n\tif (err)\n\t\tgoto out_free_dev;\n\n\t \n\tif (i >= 0) {\n\t\terr = idr_alloc(&loop_index_idr, lo, i, i + 1, GFP_KERNEL);\n\t\tif (err == -ENOSPC)\n\t\t\terr = -EEXIST;\n\t} else {\n\t\terr = idr_alloc(&loop_index_idr, lo, 0, 0, GFP_KERNEL);\n\t}\n\tmutex_unlock(&loop_ctl_mutex);\n\tif (err < 0)\n\t\tgoto out_free_dev;\n\ti = err;\n\n\tlo->tag_set.ops = &loop_mq_ops;\n\tlo->tag_set.nr_hw_queues = 1;\n\tlo->tag_set.queue_depth = hw_queue_depth;\n\tlo->tag_set.numa_node = NUMA_NO_NODE;\n\tlo->tag_set.cmd_size = sizeof(struct loop_cmd);\n\tlo->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_STACKING |\n\t\tBLK_MQ_F_NO_SCHED_BY_DEFAULT;\n\tlo->tag_set.driver_data = lo;\n\n\terr = blk_mq_alloc_tag_set(&lo->tag_set);\n\tif (err)\n\t\tgoto out_free_idr;\n\n\tdisk = lo->lo_disk = blk_mq_alloc_disk(&lo->tag_set, lo);\n\tif (IS_ERR(disk)) {\n\t\terr = PTR_ERR(disk);\n\t\tgoto out_cleanup_tags;\n\t}\n\tlo->lo_queue = lo->lo_disk->queue;\n\n\tblk_queue_max_hw_sectors(lo->lo_queue, BLK_DEF_MAX_SECTORS);\n\n\t \n\tblk_queue_flag_set(QUEUE_FLAG_NOMERGES, lo->lo_queue);\n\n\t \n\tif (!part_shift)\n\t\tset_bit(GD_SUPPRESS_PART_SCAN, &disk->state);\n\tmutex_init(&lo->lo_mutex);\n\tlo->lo_number\t\t= i;\n\tspin_lock_init(&lo->lo_lock);\n\tspin_lock_init(&lo->lo_work_lock);\n\tINIT_WORK(&lo->rootcg_work, loop_rootcg_workfn);\n\tINIT_LIST_HEAD(&lo->rootcg_cmd_list);\n\tdisk->major\t\t= LOOP_MAJOR;\n\tdisk->first_minor\t= i << part_shift;\n\tdisk->minors\t\t= 1 << part_shift;\n\tdisk->fops\t\t= &lo_fops;\n\tdisk->private_data\t= lo;\n\tdisk->queue\t\t= lo->lo_queue;\n\tdisk->events\t\t= DISK_EVENT_MEDIA_CHANGE;\n\tdisk->event_flags\t= DISK_EVENT_FLAG_UEVENT;\n\tsprintf(disk->disk_name, \"loop%d\", i);\n\t \n\terr = add_disk(disk);\n\tif (err)\n\t\tgoto out_cleanup_disk;\n\n\t \n\tmutex_lock(&loop_ctl_mutex);\n\tlo->idr_visible = true;\n\tmutex_unlock(&loop_ctl_mutex);\n\n\treturn i;\n\nout_cleanup_disk:\n\tput_disk(disk);\nout_cleanup_tags:\n\tblk_mq_free_tag_set(&lo->tag_set);\nout_free_idr:\n\tmutex_lock(&loop_ctl_mutex);\n\tidr_remove(&loop_index_idr, i);\n\tmutex_unlock(&loop_ctl_mutex);\nout_free_dev:\n\tkfree(lo);\nout:\n\treturn err;\n}\n\nstatic void loop_remove(struct loop_device *lo)\n{\n\t \n\tdel_gendisk(lo->lo_disk);\n\tblk_mq_free_tag_set(&lo->tag_set);\n\n\tmutex_lock(&loop_ctl_mutex);\n\tidr_remove(&loop_index_idr, lo->lo_number);\n\tmutex_unlock(&loop_ctl_mutex);\n\n\tput_disk(lo->lo_disk);\n}\n\n#ifdef CONFIG_BLOCK_LEGACY_AUTOLOAD\nstatic void loop_probe(dev_t dev)\n{\n\tint idx = MINOR(dev) >> part_shift;\n\n\tif (max_loop_specified && max_loop && idx >= max_loop)\n\t\treturn;\n\tloop_add(idx);\n}\n#else\n#define loop_probe NULL\n#endif  \n\nstatic int loop_control_remove(int idx)\n{\n\tstruct loop_device *lo;\n\tint ret;\n\n\tif (idx < 0) {\n\t\tpr_warn_once(\"deleting an unspecified loop device is not supported.\\n\");\n\t\treturn -EINVAL;\n\t}\n\t\t\n\t \n\tret = mutex_lock_killable(&loop_ctl_mutex);\n\tif (ret)\n\t\treturn ret;\n\tlo = idr_find(&loop_index_idr, idx);\n\tif (!lo || !lo->idr_visible)\n\t\tret = -ENODEV;\n\telse\n\t\tlo->idr_visible = false;\n\tmutex_unlock(&loop_ctl_mutex);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = mutex_lock_killable(&lo->lo_mutex);\n\tif (ret)\n\t\tgoto mark_visible;\n\tif (lo->lo_state != Lo_unbound || disk_openers(lo->lo_disk) > 0) {\n\t\tmutex_unlock(&lo->lo_mutex);\n\t\tret = -EBUSY;\n\t\tgoto mark_visible;\n\t}\n\t \n\tlo->lo_state = Lo_deleting;\n\tmutex_unlock(&lo->lo_mutex);\n\n\tloop_remove(lo);\n\treturn 0;\n\nmark_visible:\n\t \n\tmutex_lock(&loop_ctl_mutex);\n\tlo->idr_visible = true;\n\tmutex_unlock(&loop_ctl_mutex);\n\treturn ret;\n}\n\nstatic int loop_control_get_free(int idx)\n{\n\tstruct loop_device *lo;\n\tint id, ret;\n\n\tret = mutex_lock_killable(&loop_ctl_mutex);\n\tif (ret)\n\t\treturn ret;\n\tidr_for_each_entry(&loop_index_idr, lo, id) {\n\t\t \n\t\tif (lo->idr_visible && data_race(lo->lo_state) == Lo_unbound)\n\t\t\tgoto found;\n\t}\n\tmutex_unlock(&loop_ctl_mutex);\n\treturn loop_add(-1);\nfound:\n\tmutex_unlock(&loop_ctl_mutex);\n\treturn id;\n}\n\nstatic long loop_control_ioctl(struct file *file, unsigned int cmd,\n\t\t\t       unsigned long parm)\n{\n\tswitch (cmd) {\n\tcase LOOP_CTL_ADD:\n\t\treturn loop_add(parm);\n\tcase LOOP_CTL_REMOVE:\n\t\treturn loop_control_remove(parm);\n\tcase LOOP_CTL_GET_FREE:\n\t\treturn loop_control_get_free(parm);\n\tdefault:\n\t\treturn -ENOSYS;\n\t}\n}\n\nstatic const struct file_operations loop_ctl_fops = {\n\t.open\t\t= nonseekable_open,\n\t.unlocked_ioctl\t= loop_control_ioctl,\n\t.compat_ioctl\t= loop_control_ioctl,\n\t.owner\t\t= THIS_MODULE,\n\t.llseek\t\t= noop_llseek,\n};\n\nstatic struct miscdevice loop_misc = {\n\t.minor\t\t= LOOP_CTRL_MINOR,\n\t.name\t\t= \"loop-control\",\n\t.fops\t\t= &loop_ctl_fops,\n};\n\nMODULE_ALIAS_MISCDEV(LOOP_CTRL_MINOR);\nMODULE_ALIAS(\"devname:loop-control\");\n\nstatic int __init loop_init(void)\n{\n\tint i;\n\tint err;\n\n\tpart_shift = 0;\n\tif (max_part > 0) {\n\t\tpart_shift = fls(max_part);\n\n\t\t \n\t\tmax_part = (1UL << part_shift) - 1;\n\t}\n\n\tif ((1UL << part_shift) > DISK_MAX_PARTS) {\n\t\terr = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\tif (max_loop > 1UL << (MINORBITS - part_shift)) {\n\t\terr = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\terr = misc_register(&loop_misc);\n\tif (err < 0)\n\t\tgoto err_out;\n\n\n\tif (__register_blkdev(LOOP_MAJOR, \"loop\", loop_probe)) {\n\t\terr = -EIO;\n\t\tgoto misc_out;\n\t}\n\n\t \n\tfor (i = 0; i < max_loop; i++)\n\t\tloop_add(i);\n\n\tprintk(KERN_INFO \"loop: module loaded\\n\");\n\treturn 0;\n\nmisc_out:\n\tmisc_deregister(&loop_misc);\nerr_out:\n\treturn err;\n}\n\nstatic void __exit loop_exit(void)\n{\n\tstruct loop_device *lo;\n\tint id;\n\n\tunregister_blkdev(LOOP_MAJOR, \"loop\");\n\tmisc_deregister(&loop_misc);\n\n\t \n\tidr_for_each_entry(&loop_index_idr, lo, id)\n\t\tloop_remove(lo);\n\n\tidr_destroy(&loop_index_idr);\n}\n\nmodule_init(loop_init);\nmodule_exit(loop_exit);\n\n#ifndef MODULE\nstatic int __init max_loop_setup(char *str)\n{\n\tmax_loop = simple_strtol(str, NULL, 0);\n#ifdef CONFIG_BLOCK_LEGACY_AUTOLOAD\n\tmax_loop_specified = true;\n#endif\n\treturn 1;\n}\n\n__setup(\"max_loop=\", max_loop_setup);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}