{
  "module_name": "vhost.h",
  "hash_id": "ae37c86aa386d6832e1932911a47967bbcc3f9377bfabc026340dfa1730b029d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/vhost/vhost.h",
  "human_readable_source": " \n#ifndef _VHOST_H\n#define _VHOST_H\n\n#include <linux/eventfd.h>\n#include <linux/vhost.h>\n#include <linux/mm.h>\n#include <linux/mutex.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/uio.h>\n#include <linux/virtio_config.h>\n#include <linux/virtio_ring.h>\n#include <linux/atomic.h>\n#include <linux/vhost_iotlb.h>\n#include <linux/irqbypass.h>\n\nstruct vhost_work;\nstruct vhost_task;\ntypedef void (*vhost_work_fn_t)(struct vhost_work *work);\n\n#define VHOST_WORK_QUEUED 1\nstruct vhost_work {\n\tstruct llist_node\tnode;\n\tvhost_work_fn_t\t\tfn;\n\tunsigned long\t\tflags;\n};\n\nstruct vhost_worker {\n\tstruct vhost_task\t*vtsk;\n\t \n\tstruct mutex\t\tmutex;\n\tstruct llist_head\twork_list;\n\tu64\t\t\tkcov_handle;\n\tu32\t\t\tid;\n\tint\t\t\tattachment_cnt;\n};\n\n \n \nstruct vhost_poll {\n\tpoll_table\t\ttable;\n\twait_queue_head_t\t*wqh;\n\twait_queue_entry_t\twait;\n\tstruct vhost_work\twork;\n\t__poll_t\t\tmask;\n\tstruct vhost_dev\t*dev;\n\tstruct vhost_virtqueue\t*vq;\n};\n\nvoid vhost_poll_init(struct vhost_poll *poll, vhost_work_fn_t fn,\n\t\t     __poll_t mask, struct vhost_dev *dev,\n\t\t     struct vhost_virtqueue *vq);\nint vhost_poll_start(struct vhost_poll *poll, struct file *file);\nvoid vhost_poll_stop(struct vhost_poll *poll);\nvoid vhost_poll_queue(struct vhost_poll *poll);\n\nvoid vhost_work_init(struct vhost_work *work, vhost_work_fn_t fn);\nvoid vhost_dev_flush(struct vhost_dev *dev);\n\nstruct vhost_log {\n\tu64 addr;\n\tu64 len;\n};\n\nenum vhost_uaddr_type {\n\tVHOST_ADDR_DESC = 0,\n\tVHOST_ADDR_AVAIL = 1,\n\tVHOST_ADDR_USED = 2,\n\tVHOST_NUM_ADDRS = 3,\n};\n\nstruct vhost_vring_call {\n\tstruct eventfd_ctx *ctx;\n\tstruct irq_bypass_producer producer;\n};\n\n \nstruct vhost_virtqueue {\n\tstruct vhost_dev *dev;\n\tstruct vhost_worker __rcu *worker;\n\n\t \n\tstruct mutex mutex;\n\tunsigned int num;\n\tvring_desc_t __user *desc;\n\tvring_avail_t __user *avail;\n\tvring_used_t __user *used;\n\tconst struct vhost_iotlb_map *meta_iotlb[VHOST_NUM_ADDRS];\n\tstruct file *kick;\n\tstruct vhost_vring_call call_ctx;\n\tstruct eventfd_ctx *error_ctx;\n\tstruct eventfd_ctx *log_ctx;\n\n\tstruct vhost_poll poll;\n\n\t \n\tvhost_work_fn_t handle_kick;\n\n\t \n\tu16 last_avail_idx;\n\n\t \n\tu16 avail_idx;\n\n\t \n\tu16 last_used_idx;\n\n\t \n\tu16 used_flags;\n\n\t \n\tu16 signalled_used;\n\n\t \n\tbool signalled_used_valid;\n\n\t \n\tbool log_used;\n\tu64 log_addr;\n\n\tstruct iovec iov[UIO_MAXIOV];\n\tstruct iovec iotlb_iov[64];\n\tstruct iovec *indirect;\n\tstruct vring_used_elem *heads;\n\t \n\tstruct vhost_iotlb *umem;\n\tstruct vhost_iotlb *iotlb;\n\tvoid *private_data;\n\tu64 acked_features;\n\tu64 acked_backend_features;\n\t \n\tvoid __user *log_base;\n\tstruct vhost_log *log;\n\tstruct iovec log_iov[64];\n\n\t \n\tbool is_le;\n#ifdef CONFIG_VHOST_CROSS_ENDIAN_LEGACY\n\t \n\tbool user_be;\n#endif\n\tu32 busyloop_timeout;\n};\n\nstruct vhost_msg_node {\n  union {\n\t  struct vhost_msg msg;\n\t  struct vhost_msg_v2 msg_v2;\n  };\n  struct vhost_virtqueue *vq;\n  struct list_head node;\n};\n\nstruct vhost_dev {\n\tstruct mm_struct *mm;\n\tstruct mutex mutex;\n\tstruct vhost_virtqueue **vqs;\n\tint nvqs;\n\tstruct eventfd_ctx *log_ctx;\n\tstruct vhost_iotlb *umem;\n\tstruct vhost_iotlb *iotlb;\n\tspinlock_t iotlb_lock;\n\tstruct list_head read_list;\n\tstruct list_head pending_list;\n\twait_queue_head_t wait;\n\tint iov_limit;\n\tint weight;\n\tint byte_weight;\n\tstruct xarray worker_xa;\n\tbool use_worker;\n\tint (*msg_handler)(struct vhost_dev *dev, u32 asid,\n\t\t\t   struct vhost_iotlb_msg *msg);\n};\n\nbool vhost_exceeds_weight(struct vhost_virtqueue *vq, int pkts, int total_len);\nvoid vhost_dev_init(struct vhost_dev *, struct vhost_virtqueue **vqs,\n\t\t    int nvqs, int iov_limit, int weight, int byte_weight,\n\t\t    bool use_worker,\n\t\t    int (*msg_handler)(struct vhost_dev *dev, u32 asid,\n\t\t\t\t       struct vhost_iotlb_msg *msg));\nlong vhost_dev_set_owner(struct vhost_dev *dev);\nbool vhost_dev_has_owner(struct vhost_dev *dev);\nlong vhost_dev_check_owner(struct vhost_dev *);\nstruct vhost_iotlb *vhost_dev_reset_owner_prepare(void);\nvoid vhost_dev_reset_owner(struct vhost_dev *dev, struct vhost_iotlb *iotlb);\nvoid vhost_dev_cleanup(struct vhost_dev *);\nvoid vhost_dev_stop(struct vhost_dev *);\nlong vhost_dev_ioctl(struct vhost_dev *, unsigned int ioctl, void __user *argp);\nlong vhost_vring_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *argp);\nlong vhost_worker_ioctl(struct vhost_dev *dev, unsigned int ioctl,\n\t\t\tvoid __user *argp);\nbool vhost_vq_access_ok(struct vhost_virtqueue *vq);\nbool vhost_log_access_ok(struct vhost_dev *);\nvoid vhost_clear_msg(struct vhost_dev *dev);\n\nint vhost_get_vq_desc(struct vhost_virtqueue *,\n\t\t      struct iovec iov[], unsigned int iov_size,\n\t\t      unsigned int *out_num, unsigned int *in_num,\n\t\t      struct vhost_log *log, unsigned int *log_num);\nvoid vhost_discard_vq_desc(struct vhost_virtqueue *, int n);\n\nvoid vhost_vq_flush(struct vhost_virtqueue *vq);\nbool vhost_vq_work_queue(struct vhost_virtqueue *vq, struct vhost_work *work);\nbool vhost_vq_has_work(struct vhost_virtqueue *vq);\nbool vhost_vq_is_setup(struct vhost_virtqueue *vq);\nint vhost_vq_init_access(struct vhost_virtqueue *);\nint vhost_add_used(struct vhost_virtqueue *, unsigned int head, int len);\nint vhost_add_used_n(struct vhost_virtqueue *, struct vring_used_elem *heads,\n\t\t     unsigned count);\nvoid vhost_add_used_and_signal(struct vhost_dev *, struct vhost_virtqueue *,\n\t\t\t       unsigned int id, int len);\nvoid vhost_add_used_and_signal_n(struct vhost_dev *, struct vhost_virtqueue *,\n\t\t\t       struct vring_used_elem *heads, unsigned count);\nvoid vhost_signal(struct vhost_dev *, struct vhost_virtqueue *);\nvoid vhost_disable_notify(struct vhost_dev *, struct vhost_virtqueue *);\nbool vhost_vq_avail_empty(struct vhost_dev *, struct vhost_virtqueue *);\nbool vhost_enable_notify(struct vhost_dev *, struct vhost_virtqueue *);\n\nint vhost_log_write(struct vhost_virtqueue *vq, struct vhost_log *log,\n\t\t    unsigned int log_num, u64 len,\n\t\t    struct iovec *iov, int count);\nint vq_meta_prefetch(struct vhost_virtqueue *vq);\n\nstruct vhost_msg_node *vhost_new_msg(struct vhost_virtqueue *vq, int type);\nvoid vhost_enqueue_msg(struct vhost_dev *dev,\n\t\t       struct list_head *head,\n\t\t       struct vhost_msg_node *node);\nstruct vhost_msg_node *vhost_dequeue_msg(struct vhost_dev *dev,\n\t\t\t\t\t struct list_head *head);\nvoid vhost_set_backend_features(struct vhost_dev *dev, u64 features);\n\n__poll_t vhost_chr_poll(struct file *file, struct vhost_dev *dev,\n\t\t\t    poll_table *wait);\nssize_t vhost_chr_read_iter(struct vhost_dev *dev, struct iov_iter *to,\n\t\t\t    int noblock);\nssize_t vhost_chr_write_iter(struct vhost_dev *dev,\n\t\t\t     struct iov_iter *from);\nint vhost_init_device_iotlb(struct vhost_dev *d);\n\nvoid vhost_iotlb_map_free(struct vhost_iotlb *iotlb,\n\t\t\t  struct vhost_iotlb_map *map);\n\n#define vq_err(vq, fmt, ...) do {                                  \\\n\t\tpr_debug(pr_fmt(fmt), ##__VA_ARGS__);       \\\n\t\tif ((vq)->error_ctx)                               \\\n\t\t\t\teventfd_signal((vq)->error_ctx, 1);\\\n\t} while (0)\n\nenum {\n\tVHOST_FEATURES = (1ULL << VIRTIO_F_NOTIFY_ON_EMPTY) |\n\t\t\t (1ULL << VIRTIO_RING_F_INDIRECT_DESC) |\n\t\t\t (1ULL << VIRTIO_RING_F_EVENT_IDX) |\n\t\t\t (1ULL << VHOST_F_LOG_ALL) |\n\t\t\t (1ULL << VIRTIO_F_ANY_LAYOUT) |\n\t\t\t (1ULL << VIRTIO_F_VERSION_1)\n};\n\n \nstatic inline void vhost_vq_set_backend(struct vhost_virtqueue *vq,\n\t\t\t\t\tvoid *private_data)\n{\n\tvq->private_data = private_data;\n}\n\n \nstatic inline void *vhost_vq_get_backend(struct vhost_virtqueue *vq)\n{\n\treturn vq->private_data;\n}\n\nstatic inline bool vhost_has_feature(struct vhost_virtqueue *vq, int bit)\n{\n\treturn vq->acked_features & (1ULL << bit);\n}\n\nstatic inline bool vhost_backend_has_feature(struct vhost_virtqueue *vq, int bit)\n{\n\treturn vq->acked_backend_features & (1ULL << bit);\n}\n\n#ifdef CONFIG_VHOST_CROSS_ENDIAN_LEGACY\nstatic inline bool vhost_is_little_endian(struct vhost_virtqueue *vq)\n{\n\treturn vq->is_le;\n}\n#else\nstatic inline bool vhost_is_little_endian(struct vhost_virtqueue *vq)\n{\n\treturn virtio_legacy_is_little_endian() || vq->is_le;\n}\n#endif\n\n \nstatic inline u16 vhost16_to_cpu(struct vhost_virtqueue *vq, __virtio16 val)\n{\n\treturn __virtio16_to_cpu(vhost_is_little_endian(vq), val);\n}\n\nstatic inline __virtio16 cpu_to_vhost16(struct vhost_virtqueue *vq, u16 val)\n{\n\treturn __cpu_to_virtio16(vhost_is_little_endian(vq), val);\n}\n\nstatic inline u32 vhost32_to_cpu(struct vhost_virtqueue *vq, __virtio32 val)\n{\n\treturn __virtio32_to_cpu(vhost_is_little_endian(vq), val);\n}\n\nstatic inline __virtio32 cpu_to_vhost32(struct vhost_virtqueue *vq, u32 val)\n{\n\treturn __cpu_to_virtio32(vhost_is_little_endian(vq), val);\n}\n\nstatic inline u64 vhost64_to_cpu(struct vhost_virtqueue *vq, __virtio64 val)\n{\n\treturn __virtio64_to_cpu(vhost_is_little_endian(vq), val);\n}\n\nstatic inline __virtio64 cpu_to_vhost64(struct vhost_virtqueue *vq, u64 val)\n{\n\treturn __cpu_to_virtio64(vhost_is_little_endian(vq), val);\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}