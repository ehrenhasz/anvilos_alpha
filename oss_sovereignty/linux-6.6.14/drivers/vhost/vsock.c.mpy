{
  "module_name": "vsock.c",
  "hash_id": "1ca6bf043c3046eca5b049297632dfd70c9e58532f62d8fc7735fb2a5397afbd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/vhost/vsock.c",
  "human_readable_source": "\n \n#include <linux/miscdevice.h>\n#include <linux/atomic.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/vmalloc.h>\n#include <net/sock.h>\n#include <linux/virtio_vsock.h>\n#include <linux/vhost.h>\n#include <linux/hashtable.h>\n\n#include <net/af_vsock.h>\n#include \"vhost.h\"\n\n#define VHOST_VSOCK_DEFAULT_HOST_CID\t2\n \n#define VHOST_VSOCK_WEIGHT 0x80000\n \n#define VHOST_VSOCK_PKT_WEIGHT 256\n\nenum {\n\tVHOST_VSOCK_FEATURES = VHOST_FEATURES |\n\t\t\t       (1ULL << VIRTIO_F_ACCESS_PLATFORM) |\n\t\t\t       (1ULL << VIRTIO_VSOCK_F_SEQPACKET)\n};\n\nenum {\n\tVHOST_VSOCK_BACKEND_FEATURES = (1ULL << VHOST_BACKEND_F_IOTLB_MSG_V2)\n};\n\n \nstatic DEFINE_MUTEX(vhost_vsock_mutex);\nstatic DEFINE_READ_MOSTLY_HASHTABLE(vhost_vsock_hash, 8);\n\nstruct vhost_vsock {\n\tstruct vhost_dev dev;\n\tstruct vhost_virtqueue vqs[2];\n\n\t \n\tstruct hlist_node hash;\n\n\tstruct vhost_work send_pkt_work;\n\tstruct sk_buff_head send_pkt_queue;  \n\n\tatomic_t queued_replies;\n\n\tu32 guest_cid;\n\tbool seqpacket_allow;\n};\n\nstatic u32 vhost_transport_get_local_cid(void)\n{\n\treturn VHOST_VSOCK_DEFAULT_HOST_CID;\n}\n\n \nstatic struct vhost_vsock *vhost_vsock_get(u32 guest_cid)\n{\n\tstruct vhost_vsock *vsock;\n\n\thash_for_each_possible_rcu(vhost_vsock_hash, vsock, hash, guest_cid) {\n\t\tu32 other_cid = vsock->guest_cid;\n\n\t\t \n\t\tif (other_cid == 0)\n\t\t\tcontinue;\n\n\t\tif (other_cid == guest_cid)\n\t\t\treturn vsock;\n\n\t}\n\n\treturn NULL;\n}\n\nstatic void\nvhost_transport_do_send_pkt(struct vhost_vsock *vsock,\n\t\t\t    struct vhost_virtqueue *vq)\n{\n\tstruct vhost_virtqueue *tx_vq = &vsock->vqs[VSOCK_VQ_TX];\n\tint pkts = 0, total_len = 0;\n\tbool added = false;\n\tbool restart_tx = false;\n\n\tmutex_lock(&vq->mutex);\n\n\tif (!vhost_vq_get_backend(vq))\n\t\tgoto out;\n\n\tif (!vq_meta_prefetch(vq))\n\t\tgoto out;\n\n\t \n\tvhost_disable_notify(&vsock->dev, vq);\n\n\tdo {\n\t\tstruct virtio_vsock_hdr *hdr;\n\t\tsize_t iov_len, payload_len;\n\t\tstruct iov_iter iov_iter;\n\t\tu32 flags_to_restore = 0;\n\t\tstruct sk_buff *skb;\n\t\tunsigned out, in;\n\t\tsize_t nbytes;\n\t\tint head;\n\n\t\tskb = virtio_vsock_skb_dequeue(&vsock->send_pkt_queue);\n\n\t\tif (!skb) {\n\t\t\tvhost_enable_notify(&vsock->dev, vq);\n\t\t\tbreak;\n\t\t}\n\n\t\thead = vhost_get_vq_desc(vq, vq->iov, ARRAY_SIZE(vq->iov),\n\t\t\t\t\t &out, &in, NULL, NULL);\n\t\tif (head < 0) {\n\t\t\tvirtio_vsock_skb_queue_head(&vsock->send_pkt_queue, skb);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (head == vq->num) {\n\t\t\tvirtio_vsock_skb_queue_head(&vsock->send_pkt_queue, skb);\n\t\t\t \n\t\t\tif (unlikely(vhost_enable_notify(&vsock->dev, vq))) {\n\t\t\t\tvhost_disable_notify(&vsock->dev, vq);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tif (out) {\n\t\t\tkfree_skb(skb);\n\t\t\tvq_err(vq, \"Expected 0 output buffers, got %u\\n\", out);\n\t\t\tbreak;\n\t\t}\n\n\t\tiov_len = iov_length(&vq->iov[out], in);\n\t\tif (iov_len < sizeof(*hdr)) {\n\t\t\tkfree_skb(skb);\n\t\t\tvq_err(vq, \"Buffer len [%zu] too small\\n\", iov_len);\n\t\t\tbreak;\n\t\t}\n\n\t\tiov_iter_init(&iov_iter, ITER_DEST, &vq->iov[out], in, iov_len);\n\t\tpayload_len = skb->len;\n\t\thdr = virtio_vsock_hdr(skb);\n\n\t\t \n\t\tif (payload_len > iov_len - sizeof(*hdr)) {\n\t\t\tpayload_len = iov_len - sizeof(*hdr);\n\n\t\t\t \n\t\t\tif (le32_to_cpu(hdr->flags) & VIRTIO_VSOCK_SEQ_EOM) {\n\t\t\t\thdr->flags &= ~cpu_to_le32(VIRTIO_VSOCK_SEQ_EOM);\n\t\t\t\tflags_to_restore |= VIRTIO_VSOCK_SEQ_EOM;\n\n\t\t\t\tif (le32_to_cpu(hdr->flags) & VIRTIO_VSOCK_SEQ_EOR) {\n\t\t\t\t\thdr->flags &= ~cpu_to_le32(VIRTIO_VSOCK_SEQ_EOR);\n\t\t\t\t\tflags_to_restore |= VIRTIO_VSOCK_SEQ_EOR;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t \n\t\thdr->len = cpu_to_le32(payload_len);\n\n\t\tnbytes = copy_to_iter(hdr, sizeof(*hdr), &iov_iter);\n\t\tif (nbytes != sizeof(*hdr)) {\n\t\t\tkfree_skb(skb);\n\t\t\tvq_err(vq, \"Faulted on copying pkt hdr\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tnbytes = copy_to_iter(skb->data, payload_len, &iov_iter);\n\t\tif (nbytes != payload_len) {\n\t\t\tkfree_skb(skb);\n\t\t\tvq_err(vq, \"Faulted on copying pkt buf\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tvirtio_transport_deliver_tap_pkt(skb);\n\n\t\tvhost_add_used(vq, head, sizeof(*hdr) + payload_len);\n\t\tadded = true;\n\n\t\tskb_pull(skb, payload_len);\n\t\ttotal_len += payload_len;\n\n\t\t \n\t\tif (skb->len > 0) {\n\t\t\thdr->flags |= cpu_to_le32(flags_to_restore);\n\n\t\t\t \n\t\t\tvirtio_vsock_skb_clear_tap_delivered(skb);\n\t\t\tvirtio_vsock_skb_queue_head(&vsock->send_pkt_queue, skb);\n\t\t} else {\n\t\t\tif (virtio_vsock_skb_reply(skb)) {\n\t\t\t\tint val;\n\n\t\t\t\tval = atomic_dec_return(&vsock->queued_replies);\n\n\t\t\t\t \n\t\t\t\tif (val + 1 == tx_vq->num)\n\t\t\t\t\trestart_tx = true;\n\t\t\t}\n\n\t\t\tconsume_skb(skb);\n\t\t}\n\t} while(likely(!vhost_exceeds_weight(vq, ++pkts, total_len)));\n\tif (added)\n\t\tvhost_signal(&vsock->dev, vq);\n\nout:\n\tmutex_unlock(&vq->mutex);\n\n\tif (restart_tx)\n\t\tvhost_poll_queue(&tx_vq->poll);\n}\n\nstatic void vhost_transport_send_pkt_work(struct vhost_work *work)\n{\n\tstruct vhost_virtqueue *vq;\n\tstruct vhost_vsock *vsock;\n\n\tvsock = container_of(work, struct vhost_vsock, send_pkt_work);\n\tvq = &vsock->vqs[VSOCK_VQ_RX];\n\n\tvhost_transport_do_send_pkt(vsock, vq);\n}\n\nstatic int\nvhost_transport_send_pkt(struct sk_buff *skb)\n{\n\tstruct virtio_vsock_hdr *hdr = virtio_vsock_hdr(skb);\n\tstruct vhost_vsock *vsock;\n\tint len = skb->len;\n\n\trcu_read_lock();\n\n\t \n\tvsock = vhost_vsock_get(le64_to_cpu(hdr->dst_cid));\n\tif (!vsock) {\n\t\trcu_read_unlock();\n\t\tkfree_skb(skb);\n\t\treturn -ENODEV;\n\t}\n\n\tif (virtio_vsock_skb_reply(skb))\n\t\tatomic_inc(&vsock->queued_replies);\n\n\tvirtio_vsock_skb_queue_tail(&vsock->send_pkt_queue, skb);\n\tvhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);\n\n\trcu_read_unlock();\n\treturn len;\n}\n\nstatic int\nvhost_transport_cancel_pkt(struct vsock_sock *vsk)\n{\n\tstruct vhost_vsock *vsock;\n\tint cnt = 0;\n\tint ret = -ENODEV;\n\n\trcu_read_lock();\n\n\t \n\tvsock = vhost_vsock_get(vsk->remote_addr.svm_cid);\n\tif (!vsock)\n\t\tgoto out;\n\n\tcnt = virtio_transport_purge_skbs(vsk, &vsock->send_pkt_queue);\n\n\tif (cnt) {\n\t\tstruct vhost_virtqueue *tx_vq = &vsock->vqs[VSOCK_VQ_TX];\n\t\tint new_cnt;\n\n\t\tnew_cnt = atomic_sub_return(cnt, &vsock->queued_replies);\n\t\tif (new_cnt + cnt >= tx_vq->num && new_cnt < tx_vq->num)\n\t\t\tvhost_poll_queue(&tx_vq->poll);\n\t}\n\n\tret = 0;\nout:\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic struct sk_buff *\nvhost_vsock_alloc_skb(struct vhost_virtqueue *vq,\n\t\t      unsigned int out, unsigned int in)\n{\n\tstruct virtio_vsock_hdr *hdr;\n\tstruct iov_iter iov_iter;\n\tstruct sk_buff *skb;\n\tsize_t payload_len;\n\tsize_t nbytes;\n\tsize_t len;\n\n\tif (in != 0) {\n\t\tvq_err(vq, \"Expected 0 input buffers, got %u\\n\", in);\n\t\treturn NULL;\n\t}\n\n\tlen = iov_length(vq->iov, out);\n\n\t \n\tskb = virtio_vsock_alloc_skb(len, GFP_KERNEL);\n\tif (!skb)\n\t\treturn NULL;\n\n\tiov_iter_init(&iov_iter, ITER_SOURCE, vq->iov, out, len);\n\n\thdr = virtio_vsock_hdr(skb);\n\tnbytes = copy_from_iter(hdr, sizeof(*hdr), &iov_iter);\n\tif (nbytes != sizeof(*hdr)) {\n\t\tvq_err(vq, \"Expected %zu bytes for pkt->hdr, got %zu bytes\\n\",\n\t\t       sizeof(*hdr), nbytes);\n\t\tkfree_skb(skb);\n\t\treturn NULL;\n\t}\n\n\tpayload_len = le32_to_cpu(hdr->len);\n\n\t \n\tif (!payload_len)\n\t\treturn skb;\n\n\t \n\tif (payload_len > VIRTIO_VSOCK_MAX_PKT_BUF_SIZE ||\n\t    payload_len + sizeof(*hdr) > len) {\n\t\tkfree_skb(skb);\n\t\treturn NULL;\n\t}\n\n\tvirtio_vsock_skb_rx_put(skb);\n\n\tnbytes = copy_from_iter(skb->data, payload_len, &iov_iter);\n\tif (nbytes != payload_len) {\n\t\tvq_err(vq, \"Expected %zu byte payload, got %zu bytes\\n\",\n\t\t       payload_len, nbytes);\n\t\tkfree_skb(skb);\n\t\treturn NULL;\n\t}\n\n\treturn skb;\n}\n\n \nstatic bool vhost_vsock_more_replies(struct vhost_vsock *vsock)\n{\n\tstruct vhost_virtqueue *vq = &vsock->vqs[VSOCK_VQ_TX];\n\tint val;\n\n\tsmp_rmb();  \n\tval = atomic_read(&vsock->queued_replies);\n\n\treturn val < vq->num;\n}\n\nstatic bool vhost_transport_seqpacket_allow(u32 remote_cid);\n\nstatic struct virtio_transport vhost_transport = {\n\t.transport = {\n\t\t.module                   = THIS_MODULE,\n\n\t\t.get_local_cid            = vhost_transport_get_local_cid,\n\n\t\t.init                     = virtio_transport_do_socket_init,\n\t\t.destruct                 = virtio_transport_destruct,\n\t\t.release                  = virtio_transport_release,\n\t\t.connect                  = virtio_transport_connect,\n\t\t.shutdown                 = virtio_transport_shutdown,\n\t\t.cancel_pkt               = vhost_transport_cancel_pkt,\n\n\t\t.dgram_enqueue            = virtio_transport_dgram_enqueue,\n\t\t.dgram_dequeue            = virtio_transport_dgram_dequeue,\n\t\t.dgram_bind               = virtio_transport_dgram_bind,\n\t\t.dgram_allow              = virtio_transport_dgram_allow,\n\n\t\t.stream_enqueue           = virtio_transport_stream_enqueue,\n\t\t.stream_dequeue           = virtio_transport_stream_dequeue,\n\t\t.stream_has_data          = virtio_transport_stream_has_data,\n\t\t.stream_has_space         = virtio_transport_stream_has_space,\n\t\t.stream_rcvhiwat          = virtio_transport_stream_rcvhiwat,\n\t\t.stream_is_active         = virtio_transport_stream_is_active,\n\t\t.stream_allow             = virtio_transport_stream_allow,\n\n\t\t.seqpacket_dequeue        = virtio_transport_seqpacket_dequeue,\n\t\t.seqpacket_enqueue        = virtio_transport_seqpacket_enqueue,\n\t\t.seqpacket_allow          = vhost_transport_seqpacket_allow,\n\t\t.seqpacket_has_data       = virtio_transport_seqpacket_has_data,\n\n\t\t.notify_poll_in           = virtio_transport_notify_poll_in,\n\t\t.notify_poll_out          = virtio_transport_notify_poll_out,\n\t\t.notify_recv_init         = virtio_transport_notify_recv_init,\n\t\t.notify_recv_pre_block    = virtio_transport_notify_recv_pre_block,\n\t\t.notify_recv_pre_dequeue  = virtio_transport_notify_recv_pre_dequeue,\n\t\t.notify_recv_post_dequeue = virtio_transport_notify_recv_post_dequeue,\n\t\t.notify_send_init         = virtio_transport_notify_send_init,\n\t\t.notify_send_pre_block    = virtio_transport_notify_send_pre_block,\n\t\t.notify_send_pre_enqueue  = virtio_transport_notify_send_pre_enqueue,\n\t\t.notify_send_post_enqueue = virtio_transport_notify_send_post_enqueue,\n\t\t.notify_buffer_size       = virtio_transport_notify_buffer_size,\n\t\t.notify_set_rcvlowat      = virtio_transport_notify_set_rcvlowat,\n\n\t\t.read_skb = virtio_transport_read_skb,\n\t},\n\n\t.send_pkt = vhost_transport_send_pkt,\n};\n\nstatic bool vhost_transport_seqpacket_allow(u32 remote_cid)\n{\n\tstruct vhost_vsock *vsock;\n\tbool seqpacket_allow = false;\n\n\trcu_read_lock();\n\tvsock = vhost_vsock_get(remote_cid);\n\n\tif (vsock)\n\t\tseqpacket_allow = vsock->seqpacket_allow;\n\n\trcu_read_unlock();\n\n\treturn seqpacket_allow;\n}\n\nstatic void vhost_vsock_handle_tx_kick(struct vhost_work *work)\n{\n\tstruct vhost_virtqueue *vq = container_of(work, struct vhost_virtqueue,\n\t\t\t\t\t\t  poll.work);\n\tstruct vhost_vsock *vsock = container_of(vq->dev, struct vhost_vsock,\n\t\t\t\t\t\t dev);\n\tint head, pkts = 0, total_len = 0;\n\tunsigned int out, in;\n\tstruct sk_buff *skb;\n\tbool added = false;\n\n\tmutex_lock(&vq->mutex);\n\n\tif (!vhost_vq_get_backend(vq))\n\t\tgoto out;\n\n\tif (!vq_meta_prefetch(vq))\n\t\tgoto out;\n\n\tvhost_disable_notify(&vsock->dev, vq);\n\tdo {\n\t\tstruct virtio_vsock_hdr *hdr;\n\n\t\tif (!vhost_vsock_more_replies(vsock)) {\n\t\t\t \n\t\t\tgoto no_more_replies;\n\t\t}\n\n\t\thead = vhost_get_vq_desc(vq, vq->iov, ARRAY_SIZE(vq->iov),\n\t\t\t\t\t &out, &in, NULL, NULL);\n\t\tif (head < 0)\n\t\t\tbreak;\n\n\t\tif (head == vq->num) {\n\t\t\tif (unlikely(vhost_enable_notify(&vsock->dev, vq))) {\n\t\t\t\tvhost_disable_notify(&vsock->dev, vq);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tskb = vhost_vsock_alloc_skb(vq, out, in);\n\t\tif (!skb) {\n\t\t\tvq_err(vq, \"Faulted on pkt\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\ttotal_len += sizeof(*hdr) + skb->len;\n\n\t\t \n\t\tvirtio_transport_deliver_tap_pkt(skb);\n\n\t\thdr = virtio_vsock_hdr(skb);\n\n\t\t \n\t\tif (le64_to_cpu(hdr->src_cid) == vsock->guest_cid &&\n\t\t    le64_to_cpu(hdr->dst_cid) ==\n\t\t    vhost_transport_get_local_cid())\n\t\t\tvirtio_transport_recv_pkt(&vhost_transport, skb);\n\t\telse\n\t\t\tkfree_skb(skb);\n\n\t\tvhost_add_used(vq, head, 0);\n\t\tadded = true;\n\t} while(likely(!vhost_exceeds_weight(vq, ++pkts, total_len)));\n\nno_more_replies:\n\tif (added)\n\t\tvhost_signal(&vsock->dev, vq);\n\nout:\n\tmutex_unlock(&vq->mutex);\n}\n\nstatic void vhost_vsock_handle_rx_kick(struct vhost_work *work)\n{\n\tstruct vhost_virtqueue *vq = container_of(work, struct vhost_virtqueue,\n\t\t\t\t\t\tpoll.work);\n\tstruct vhost_vsock *vsock = container_of(vq->dev, struct vhost_vsock,\n\t\t\t\t\t\t dev);\n\n\tvhost_transport_do_send_pkt(vsock, vq);\n}\n\nstatic int vhost_vsock_start(struct vhost_vsock *vsock)\n{\n\tstruct vhost_virtqueue *vq;\n\tsize_t i;\n\tint ret;\n\n\tmutex_lock(&vsock->dev.mutex);\n\n\tret = vhost_dev_check_owner(&vsock->dev);\n\tif (ret)\n\t\tgoto err;\n\n\tfor (i = 0; i < ARRAY_SIZE(vsock->vqs); i++) {\n\t\tvq = &vsock->vqs[i];\n\n\t\tmutex_lock(&vq->mutex);\n\n\t\tif (!vhost_vq_access_ok(vq)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err_vq;\n\t\t}\n\n\t\tif (!vhost_vq_get_backend(vq)) {\n\t\t\tvhost_vq_set_backend(vq, vsock);\n\t\t\tret = vhost_vq_init_access(vq);\n\t\t\tif (ret)\n\t\t\t\tgoto err_vq;\n\t\t}\n\n\t\tmutex_unlock(&vq->mutex);\n\t}\n\n\t \n\tvhost_vq_work_queue(&vsock->vqs[VSOCK_VQ_RX], &vsock->send_pkt_work);\n\n\tmutex_unlock(&vsock->dev.mutex);\n\treturn 0;\n\nerr_vq:\n\tvhost_vq_set_backend(vq, NULL);\n\tmutex_unlock(&vq->mutex);\n\n\tfor (i = 0; i < ARRAY_SIZE(vsock->vqs); i++) {\n\t\tvq = &vsock->vqs[i];\n\n\t\tmutex_lock(&vq->mutex);\n\t\tvhost_vq_set_backend(vq, NULL);\n\t\tmutex_unlock(&vq->mutex);\n\t}\nerr:\n\tmutex_unlock(&vsock->dev.mutex);\n\treturn ret;\n}\n\nstatic int vhost_vsock_stop(struct vhost_vsock *vsock, bool check_owner)\n{\n\tsize_t i;\n\tint ret = 0;\n\n\tmutex_lock(&vsock->dev.mutex);\n\n\tif (check_owner) {\n\t\tret = vhost_dev_check_owner(&vsock->dev);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(vsock->vqs); i++) {\n\t\tstruct vhost_virtqueue *vq = &vsock->vqs[i];\n\n\t\tmutex_lock(&vq->mutex);\n\t\tvhost_vq_set_backend(vq, NULL);\n\t\tmutex_unlock(&vq->mutex);\n\t}\n\nerr:\n\tmutex_unlock(&vsock->dev.mutex);\n\treturn ret;\n}\n\nstatic void vhost_vsock_free(struct vhost_vsock *vsock)\n{\n\tkvfree(vsock);\n}\n\nstatic int vhost_vsock_dev_open(struct inode *inode, struct file *file)\n{\n\tstruct vhost_virtqueue **vqs;\n\tstruct vhost_vsock *vsock;\n\tint ret;\n\n\t \n\tvsock = kvmalloc(sizeof(*vsock), GFP_KERNEL | __GFP_RETRY_MAYFAIL);\n\tif (!vsock)\n\t\treturn -ENOMEM;\n\n\tvqs = kmalloc_array(ARRAY_SIZE(vsock->vqs), sizeof(*vqs), GFP_KERNEL);\n\tif (!vqs) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tvsock->guest_cid = 0;  \n\n\tatomic_set(&vsock->queued_replies, 0);\n\n\tvqs[VSOCK_VQ_TX] = &vsock->vqs[VSOCK_VQ_TX];\n\tvqs[VSOCK_VQ_RX] = &vsock->vqs[VSOCK_VQ_RX];\n\tvsock->vqs[VSOCK_VQ_TX].handle_kick = vhost_vsock_handle_tx_kick;\n\tvsock->vqs[VSOCK_VQ_RX].handle_kick = vhost_vsock_handle_rx_kick;\n\n\tvhost_dev_init(&vsock->dev, vqs, ARRAY_SIZE(vsock->vqs),\n\t\t       UIO_MAXIOV, VHOST_VSOCK_PKT_WEIGHT,\n\t\t       VHOST_VSOCK_WEIGHT, true, NULL);\n\n\tfile->private_data = vsock;\n\tskb_queue_head_init(&vsock->send_pkt_queue);\n\tvhost_work_init(&vsock->send_pkt_work, vhost_transport_send_pkt_work);\n\treturn 0;\n\nout:\n\tvhost_vsock_free(vsock);\n\treturn ret;\n}\n\nstatic void vhost_vsock_flush(struct vhost_vsock *vsock)\n{\n\tvhost_dev_flush(&vsock->dev);\n}\n\nstatic void vhost_vsock_reset_orphans(struct sock *sk)\n{\n\tstruct vsock_sock *vsk = vsock_sk(sk);\n\n\t \n\n\t \n\tif (vhost_vsock_get(vsk->remote_addr.svm_cid))\n\t\treturn;\n\n\t \n\tif (vsk->close_work_scheduled)\n\t\treturn;\n\n\tsock_set_flag(sk, SOCK_DONE);\n\tvsk->peer_shutdown = SHUTDOWN_MASK;\n\tsk->sk_state = SS_UNCONNECTED;\n\tsk->sk_err = ECONNRESET;\n\tsk_error_report(sk);\n}\n\nstatic int vhost_vsock_dev_release(struct inode *inode, struct file *file)\n{\n\tstruct vhost_vsock *vsock = file->private_data;\n\n\tmutex_lock(&vhost_vsock_mutex);\n\tif (vsock->guest_cid)\n\t\thash_del_rcu(&vsock->hash);\n\tmutex_unlock(&vhost_vsock_mutex);\n\n\t \n\tsynchronize_rcu();\n\n\t \n\tvsock_for_each_connected_socket(&vhost_transport.transport,\n\t\t\t\t\tvhost_vsock_reset_orphans);\n\n\t \n\tvhost_vsock_stop(vsock, false);\n\tvhost_vsock_flush(vsock);\n\tvhost_dev_stop(&vsock->dev);\n\n\tvirtio_vsock_skb_queue_purge(&vsock->send_pkt_queue);\n\n\tvhost_dev_cleanup(&vsock->dev);\n\tkfree(vsock->dev.vqs);\n\tvhost_vsock_free(vsock);\n\treturn 0;\n}\n\nstatic int vhost_vsock_set_cid(struct vhost_vsock *vsock, u64 guest_cid)\n{\n\tstruct vhost_vsock *other;\n\n\t \n\tif (guest_cid <= VMADDR_CID_HOST ||\n\t    guest_cid == U32_MAX)\n\t\treturn -EINVAL;\n\n\t \n\tif (guest_cid > U32_MAX)\n\t\treturn -EINVAL;\n\n\t \n\tif (vsock_find_cid(guest_cid))\n\t\treturn -EADDRINUSE;\n\n\t \n\tmutex_lock(&vhost_vsock_mutex);\n\tother = vhost_vsock_get(guest_cid);\n\tif (other && other != vsock) {\n\t\tmutex_unlock(&vhost_vsock_mutex);\n\t\treturn -EADDRINUSE;\n\t}\n\n\tif (vsock->guest_cid)\n\t\thash_del_rcu(&vsock->hash);\n\n\tvsock->guest_cid = guest_cid;\n\thash_add_rcu(vhost_vsock_hash, &vsock->hash, vsock->guest_cid);\n\tmutex_unlock(&vhost_vsock_mutex);\n\n\treturn 0;\n}\n\nstatic int vhost_vsock_set_features(struct vhost_vsock *vsock, u64 features)\n{\n\tstruct vhost_virtqueue *vq;\n\tint i;\n\n\tif (features & ~VHOST_VSOCK_FEATURES)\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&vsock->dev.mutex);\n\tif ((features & (1 << VHOST_F_LOG_ALL)) &&\n\t    !vhost_log_access_ok(&vsock->dev)) {\n\t\tgoto err;\n\t}\n\n\tif ((features & (1ULL << VIRTIO_F_ACCESS_PLATFORM))) {\n\t\tif (vhost_init_device_iotlb(&vsock->dev))\n\t\t\tgoto err;\n\t}\n\n\tif (features & (1ULL << VIRTIO_VSOCK_F_SEQPACKET))\n\t\tvsock->seqpacket_allow = true;\n\n\tfor (i = 0; i < ARRAY_SIZE(vsock->vqs); i++) {\n\t\tvq = &vsock->vqs[i];\n\t\tmutex_lock(&vq->mutex);\n\t\tvq->acked_features = features;\n\t\tmutex_unlock(&vq->mutex);\n\t}\n\tmutex_unlock(&vsock->dev.mutex);\n\treturn 0;\n\nerr:\n\tmutex_unlock(&vsock->dev.mutex);\n\treturn -EFAULT;\n}\n\nstatic long vhost_vsock_dev_ioctl(struct file *f, unsigned int ioctl,\n\t\t\t\t  unsigned long arg)\n{\n\tstruct vhost_vsock *vsock = f->private_data;\n\tvoid __user *argp = (void __user *)arg;\n\tu64 guest_cid;\n\tu64 features;\n\tint start;\n\tint r;\n\n\tswitch (ioctl) {\n\tcase VHOST_VSOCK_SET_GUEST_CID:\n\t\tif (copy_from_user(&guest_cid, argp, sizeof(guest_cid)))\n\t\t\treturn -EFAULT;\n\t\treturn vhost_vsock_set_cid(vsock, guest_cid);\n\tcase VHOST_VSOCK_SET_RUNNING:\n\t\tif (copy_from_user(&start, argp, sizeof(start)))\n\t\t\treturn -EFAULT;\n\t\tif (start)\n\t\t\treturn vhost_vsock_start(vsock);\n\t\telse\n\t\t\treturn vhost_vsock_stop(vsock, true);\n\tcase VHOST_GET_FEATURES:\n\t\tfeatures = VHOST_VSOCK_FEATURES;\n\t\tif (copy_to_user(argp, &features, sizeof(features)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\tcase VHOST_SET_FEATURES:\n\t\tif (copy_from_user(&features, argp, sizeof(features)))\n\t\t\treturn -EFAULT;\n\t\treturn vhost_vsock_set_features(vsock, features);\n\tcase VHOST_GET_BACKEND_FEATURES:\n\t\tfeatures = VHOST_VSOCK_BACKEND_FEATURES;\n\t\tif (copy_to_user(argp, &features, sizeof(features)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\tcase VHOST_SET_BACKEND_FEATURES:\n\t\tif (copy_from_user(&features, argp, sizeof(features)))\n\t\t\treturn -EFAULT;\n\t\tif (features & ~VHOST_VSOCK_BACKEND_FEATURES)\n\t\t\treturn -EOPNOTSUPP;\n\t\tvhost_set_backend_features(&vsock->dev, features);\n\t\treturn 0;\n\tdefault:\n\t\tmutex_lock(&vsock->dev.mutex);\n\t\tr = vhost_dev_ioctl(&vsock->dev, ioctl, argp);\n\t\tif (r == -ENOIOCTLCMD)\n\t\t\tr = vhost_vring_ioctl(&vsock->dev, ioctl, argp);\n\t\telse\n\t\t\tvhost_vsock_flush(vsock);\n\t\tmutex_unlock(&vsock->dev.mutex);\n\t\treturn r;\n\t}\n}\n\nstatic ssize_t vhost_vsock_chr_read_iter(struct kiocb *iocb, struct iov_iter *to)\n{\n\tstruct file *file = iocb->ki_filp;\n\tstruct vhost_vsock *vsock = file->private_data;\n\tstruct vhost_dev *dev = &vsock->dev;\n\tint noblock = file->f_flags & O_NONBLOCK;\n\n\treturn vhost_chr_read_iter(dev, to, noblock);\n}\n\nstatic ssize_t vhost_vsock_chr_write_iter(struct kiocb *iocb,\n\t\t\t\t\tstruct iov_iter *from)\n{\n\tstruct file *file = iocb->ki_filp;\n\tstruct vhost_vsock *vsock = file->private_data;\n\tstruct vhost_dev *dev = &vsock->dev;\n\n\treturn vhost_chr_write_iter(dev, from);\n}\n\nstatic __poll_t vhost_vsock_chr_poll(struct file *file, poll_table *wait)\n{\n\tstruct vhost_vsock *vsock = file->private_data;\n\tstruct vhost_dev *dev = &vsock->dev;\n\n\treturn vhost_chr_poll(file, dev, wait);\n}\n\nstatic const struct file_operations vhost_vsock_fops = {\n\t.owner          = THIS_MODULE,\n\t.open           = vhost_vsock_dev_open,\n\t.release        = vhost_vsock_dev_release,\n\t.llseek\t\t= noop_llseek,\n\t.unlocked_ioctl = vhost_vsock_dev_ioctl,\n\t.compat_ioctl   = compat_ptr_ioctl,\n\t.read_iter      = vhost_vsock_chr_read_iter,\n\t.write_iter     = vhost_vsock_chr_write_iter,\n\t.poll           = vhost_vsock_chr_poll,\n};\n\nstatic struct miscdevice vhost_vsock_misc = {\n\t.minor = VHOST_VSOCK_MINOR,\n\t.name = \"vhost-vsock\",\n\t.fops = &vhost_vsock_fops,\n};\n\nstatic int __init vhost_vsock_init(void)\n{\n\tint ret;\n\n\tret = vsock_core_register(&vhost_transport.transport,\n\t\t\t\t  VSOCK_TRANSPORT_F_H2G);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = misc_register(&vhost_vsock_misc);\n\tif (ret) {\n\t\tvsock_core_unregister(&vhost_transport.transport);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n};\n\nstatic void __exit vhost_vsock_exit(void)\n{\n\tmisc_deregister(&vhost_vsock_misc);\n\tvsock_core_unregister(&vhost_transport.transport);\n};\n\nmodule_init(vhost_vsock_init);\nmodule_exit(vhost_vsock_exit);\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Asias He\");\nMODULE_DESCRIPTION(\"vhost transport for vsock \");\nMODULE_ALIAS_MISCDEV(VHOST_VSOCK_MINOR);\nMODULE_ALIAS(\"devname:vhost-vsock\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}