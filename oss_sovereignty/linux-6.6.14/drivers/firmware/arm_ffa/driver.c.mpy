{
  "module_name": "driver.c",
  "hash_id": "a4b1d9ed82f0b6c67eadf9e6e78c765999913d43b57ab3b368b06555e97bc888",
  "original_prompt": "Ingested from linux-6.6.14/drivers/firmware/arm_ffa/driver.c",
  "human_readable_source": "\n \n\n#define DRIVER_NAME \"ARM FF-A\"\n#define pr_fmt(fmt) DRIVER_NAME \": \" fmt\n\n#include <linux/arm_ffa.h>\n#include <linux/bitfield.h>\n#include <linux/device.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/uuid.h>\n\n#include \"common.h\"\n\n#define FFA_DRIVER_VERSION\tFFA_VERSION_1_0\n#define FFA_MIN_VERSION\t\tFFA_VERSION_1_0\n\n#define SENDER_ID_MASK\t\tGENMASK(31, 16)\n#define RECEIVER_ID_MASK\tGENMASK(15, 0)\n#define SENDER_ID(x)\t\t((u16)(FIELD_GET(SENDER_ID_MASK, (x))))\n#define RECEIVER_ID(x)\t\t((u16)(FIELD_GET(RECEIVER_ID_MASK, (x))))\n#define PACK_TARGET_INFO(s, r)\t\t\\\n\t(FIELD_PREP(SENDER_ID_MASK, (s)) | FIELD_PREP(RECEIVER_ID_MASK, (r)))\n\n \n#define RXTX_BUFFER_SIZE\tSZ_4K\n\nstatic ffa_fn *invoke_ffa_fn;\n\nstatic const int ffa_linux_errmap[] = {\n\t \n\t0,\t\t \n\t-EOPNOTSUPP,\t \n\t-EINVAL,\t \n\t-ENOMEM,\t \n\t-EBUSY,\t\t \n\t-EINTR,\t\t \n\t-EACCES,\t \n\t-EAGAIN,\t \n\t-ECANCELED,\t \n};\n\nstatic inline int ffa_to_linux_errno(int errno)\n{\n\tint err_idx = -errno;\n\n\tif (err_idx >= 0 && err_idx < ARRAY_SIZE(ffa_linux_errmap))\n\t\treturn ffa_linux_errmap[err_idx];\n\treturn -EINVAL;\n}\n\nstruct ffa_drv_info {\n\tu32 version;\n\tu16 vm_id;\n\tstruct mutex rx_lock;  \n\tstruct mutex tx_lock;  \n\tvoid *rx_buffer;\n\tvoid *tx_buffer;\n\tbool mem_ops_native;\n};\n\nstatic struct ffa_drv_info *drv_info;\n\n \nstatic u32 ffa_compatible_version_find(u32 version)\n{\n\tu16 major = FFA_MAJOR_VERSION(version), minor = FFA_MINOR_VERSION(version);\n\tu16 drv_major = FFA_MAJOR_VERSION(FFA_DRIVER_VERSION);\n\tu16 drv_minor = FFA_MINOR_VERSION(FFA_DRIVER_VERSION);\n\n\tif ((major < drv_major) || (major == drv_major && minor <= drv_minor))\n\t\treturn version;\n\n\tpr_info(\"Firmware version higher than driver version, downgrading\\n\");\n\treturn FFA_DRIVER_VERSION;\n}\n\nstatic int ffa_version_check(u32 *version)\n{\n\tffa_value_t ver;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_VERSION, .a1 = FFA_DRIVER_VERSION,\n\t\t      }, &ver);\n\n\tif (ver.a0 == FFA_RET_NOT_SUPPORTED) {\n\t\tpr_info(\"FFA_VERSION returned not supported\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (ver.a0 < FFA_MIN_VERSION) {\n\t\tpr_err(\"Incompatible v%d.%d! Earliest supported v%d.%d\\n\",\n\t\t       FFA_MAJOR_VERSION(ver.a0), FFA_MINOR_VERSION(ver.a0),\n\t\t       FFA_MAJOR_VERSION(FFA_MIN_VERSION),\n\t\t       FFA_MINOR_VERSION(FFA_MIN_VERSION));\n\t\treturn -EINVAL;\n\t}\n\n\tpr_info(\"Driver version %d.%d\\n\", FFA_MAJOR_VERSION(FFA_DRIVER_VERSION),\n\t\tFFA_MINOR_VERSION(FFA_DRIVER_VERSION));\n\tpr_info(\"Firmware version %d.%d found\\n\", FFA_MAJOR_VERSION(ver.a0),\n\t\tFFA_MINOR_VERSION(ver.a0));\n\t*version = ffa_compatible_version_find(ver.a0);\n\n\treturn 0;\n}\n\nstatic int ffa_rx_release(void)\n{\n\tffa_value_t ret;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_RX_RELEASE,\n\t\t      }, &ret);\n\n\tif (ret.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)ret.a2);\n\n\t \n\n\treturn 0;\n}\n\nstatic int ffa_rxtx_map(phys_addr_t tx_buf, phys_addr_t rx_buf, u32 pg_cnt)\n{\n\tffa_value_t ret;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_FN_NATIVE(RXTX_MAP),\n\t\t      .a1 = tx_buf, .a2 = rx_buf, .a3 = pg_cnt,\n\t\t      }, &ret);\n\n\tif (ret.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)ret.a2);\n\n\treturn 0;\n}\n\nstatic int ffa_rxtx_unmap(u16 vm_id)\n{\n\tffa_value_t ret;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_RXTX_UNMAP, .a1 = PACK_TARGET_INFO(vm_id, 0),\n\t\t      }, &ret);\n\n\tif (ret.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)ret.a2);\n\n\treturn 0;\n}\n\n#define PARTITION_INFO_GET_RETURN_COUNT_ONLY\tBIT(0)\n\n \nstatic int\n__ffa_partition_info_get(u32 uuid0, u32 uuid1, u32 uuid2, u32 uuid3,\n\t\t\t struct ffa_partition_info *buffer, int num_partitions)\n{\n\tint idx, count, flags = 0, sz, buf_sz;\n\tffa_value_t partition_info;\n\n\tif (drv_info->version > FFA_VERSION_1_0 &&\n\t    (!buffer || !num_partitions))  \n\t\tflags = PARTITION_INFO_GET_RETURN_COUNT_ONLY;\n\n\tmutex_lock(&drv_info->rx_lock);\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_PARTITION_INFO_GET,\n\t\t      .a1 = uuid0, .a2 = uuid1, .a3 = uuid2, .a4 = uuid3,\n\t\t      .a5 = flags,\n\t\t      }, &partition_info);\n\n\tif (partition_info.a0 == FFA_ERROR) {\n\t\tmutex_unlock(&drv_info->rx_lock);\n\t\treturn ffa_to_linux_errno((int)partition_info.a2);\n\t}\n\n\tcount = partition_info.a2;\n\n\tif (drv_info->version > FFA_VERSION_1_0) {\n\t\tbuf_sz = sz = partition_info.a3;\n\t\tif (sz > sizeof(*buffer))\n\t\t\tbuf_sz = sizeof(*buffer);\n\t} else {\n\t\t \n\t\tbuf_sz = sz = 8;\n\t}\n\n\tif (buffer && count <= num_partitions)\n\t\tfor (idx = 0; idx < count; idx++)\n\t\t\tmemcpy(buffer + idx, drv_info->rx_buffer + idx * sz,\n\t\t\t       buf_sz);\n\n\tffa_rx_release();\n\n\tmutex_unlock(&drv_info->rx_lock);\n\n\treturn count;\n}\n\n \nstatic int\nffa_partition_probe(const uuid_t *uuid, struct ffa_partition_info **buffer)\n{\n\tint count;\n\tu32 uuid0_4[4];\n\tstruct ffa_partition_info *pbuf;\n\n\texport_uuid((u8 *)uuid0_4, uuid);\n\tcount = __ffa_partition_info_get(uuid0_4[0], uuid0_4[1], uuid0_4[2],\n\t\t\t\t\t uuid0_4[3], NULL, 0);\n\tif (count <= 0)\n\t\treturn count;\n\n\tpbuf = kcalloc(count, sizeof(*pbuf), GFP_KERNEL);\n\tif (!pbuf)\n\t\treturn -ENOMEM;\n\n\tcount = __ffa_partition_info_get(uuid0_4[0], uuid0_4[1], uuid0_4[2],\n\t\t\t\t\t uuid0_4[3], pbuf, count);\n\tif (count <= 0)\n\t\tkfree(pbuf);\n\telse\n\t\t*buffer = pbuf;\n\n\treturn count;\n}\n\n#define VM_ID_MASK\tGENMASK(15, 0)\nstatic int ffa_id_get(u16 *vm_id)\n{\n\tffa_value_t id;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_ID_GET,\n\t\t      }, &id);\n\n\tif (id.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)id.a2);\n\n\t*vm_id = FIELD_GET(VM_ID_MASK, (id.a2));\n\n\treturn 0;\n}\n\nstatic int ffa_msg_send_direct_req(u16 src_id, u16 dst_id, bool mode_32bit,\n\t\t\t\t   struct ffa_send_direct_data *data)\n{\n\tu32 req_id, resp_id, src_dst_ids = PACK_TARGET_INFO(src_id, dst_id);\n\tffa_value_t ret;\n\n\tif (mode_32bit) {\n\t\treq_id = FFA_MSG_SEND_DIRECT_REQ;\n\t\tresp_id = FFA_MSG_SEND_DIRECT_RESP;\n\t} else {\n\t\treq_id = FFA_FN_NATIVE(MSG_SEND_DIRECT_REQ);\n\t\tresp_id = FFA_FN_NATIVE(MSG_SEND_DIRECT_RESP);\n\t}\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = req_id, .a1 = src_dst_ids, .a2 = 0,\n\t\t      .a3 = data->data0, .a4 = data->data1, .a5 = data->data2,\n\t\t      .a6 = data->data3, .a7 = data->data4,\n\t\t      }, &ret);\n\n\twhile (ret.a0 == FFA_INTERRUPT)\n\t\tinvoke_ffa_fn((ffa_value_t){\n\t\t\t      .a0 = FFA_RUN, .a1 = ret.a1,\n\t\t\t      }, &ret);\n\n\tif (ret.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)ret.a2);\n\n\tif (ret.a0 == resp_id) {\n\t\tdata->data0 = ret.a3;\n\t\tdata->data1 = ret.a4;\n\t\tdata->data2 = ret.a5;\n\t\tdata->data3 = ret.a6;\n\t\tdata->data4 = ret.a7;\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int ffa_mem_first_frag(u32 func_id, phys_addr_t buf, u32 buf_sz,\n\t\t\t      u32 frag_len, u32 len, u64 *handle)\n{\n\tffa_value_t ret;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = func_id, .a1 = len, .a2 = frag_len,\n\t\t      .a3 = buf, .a4 = buf_sz,\n\t\t      }, &ret);\n\n\twhile (ret.a0 == FFA_MEM_OP_PAUSE)\n\t\tinvoke_ffa_fn((ffa_value_t){\n\t\t\t      .a0 = FFA_MEM_OP_RESUME,\n\t\t\t      .a1 = ret.a1, .a2 = ret.a2,\n\t\t\t      }, &ret);\n\n\tif (ret.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)ret.a2);\n\n\tif (ret.a0 == FFA_SUCCESS) {\n\t\tif (handle)\n\t\t\t*handle = PACK_HANDLE(ret.a2, ret.a3);\n\t} else if (ret.a0 == FFA_MEM_FRAG_RX) {\n\t\tif (handle)\n\t\t\t*handle = PACK_HANDLE(ret.a1, ret.a2);\n\t} else {\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn frag_len;\n}\n\nstatic int ffa_mem_next_frag(u64 handle, u32 frag_len)\n{\n\tffa_value_t ret;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_MEM_FRAG_TX,\n\t\t      .a1 = HANDLE_LOW(handle), .a2 = HANDLE_HIGH(handle),\n\t\t      .a3 = frag_len,\n\t\t      }, &ret);\n\n\twhile (ret.a0 == FFA_MEM_OP_PAUSE)\n\t\tinvoke_ffa_fn((ffa_value_t){\n\t\t\t      .a0 = FFA_MEM_OP_RESUME,\n\t\t\t      .a1 = ret.a1, .a2 = ret.a2,\n\t\t\t      }, &ret);\n\n\tif (ret.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)ret.a2);\n\n\tif (ret.a0 == FFA_MEM_FRAG_RX)\n\t\treturn ret.a3;\n\telse if (ret.a0 == FFA_SUCCESS)\n\t\treturn 0;\n\n\treturn -EOPNOTSUPP;\n}\n\nstatic int\nffa_transmit_fragment(u32 func_id, phys_addr_t buf, u32 buf_sz, u32 frag_len,\n\t\t      u32 len, u64 *handle, bool first)\n{\n\tif (!first)\n\t\treturn ffa_mem_next_frag(*handle, frag_len);\n\n\treturn ffa_mem_first_frag(func_id, buf, buf_sz, frag_len, len, handle);\n}\n\nstatic u32 ffa_get_num_pages_sg(struct scatterlist *sg)\n{\n\tu32 num_pages = 0;\n\n\tdo {\n\t\tnum_pages += sg->length / FFA_PAGE_SIZE;\n\t} while ((sg = sg_next(sg)));\n\n\treturn num_pages;\n}\n\nstatic u8 ffa_memory_attributes_get(u32 func_id)\n{\n\t \n\tif (func_id == FFA_FN_NATIVE(MEM_LEND) ||\n\t    func_id == FFA_MEM_LEND)\n\t\treturn 0;\n\n\treturn FFA_MEM_NORMAL | FFA_MEM_WRITE_BACK | FFA_MEM_INNER_SHAREABLE;\n}\n\nstatic int\nffa_setup_and_transmit(u32 func_id, void *buffer, u32 max_fragsize,\n\t\t       struct ffa_mem_ops_args *args)\n{\n\tint rc = 0;\n\tbool first = true;\n\tphys_addr_t addr = 0;\n\tstruct ffa_composite_mem_region *composite;\n\tstruct ffa_mem_region_addr_range *constituents;\n\tstruct ffa_mem_region_attributes *ep_mem_access;\n\tstruct ffa_mem_region *mem_region = buffer;\n\tu32 idx, frag_len, length, buf_sz = 0, num_entries = sg_nents(args->sg);\n\n\tmem_region->tag = args->tag;\n\tmem_region->flags = args->flags;\n\tmem_region->sender_id = drv_info->vm_id;\n\tmem_region->attributes = ffa_memory_attributes_get(func_id);\n\tep_mem_access = &mem_region->ep_mem_access[0];\n\n\tfor (idx = 0; idx < args->nattrs; idx++, ep_mem_access++) {\n\t\tep_mem_access->receiver = args->attrs[idx].receiver;\n\t\tep_mem_access->attrs = args->attrs[idx].attrs;\n\t\tep_mem_access->composite_off = COMPOSITE_OFFSET(args->nattrs);\n\t\tep_mem_access->flag = 0;\n\t\tep_mem_access->reserved = 0;\n\t}\n\tmem_region->handle = 0;\n\tmem_region->reserved_0 = 0;\n\tmem_region->reserved_1 = 0;\n\tmem_region->ep_count = args->nattrs;\n\n\tcomposite = buffer + COMPOSITE_OFFSET(args->nattrs);\n\tcomposite->total_pg_cnt = ffa_get_num_pages_sg(args->sg);\n\tcomposite->addr_range_cnt = num_entries;\n\tcomposite->reserved = 0;\n\n\tlength = COMPOSITE_CONSTITUENTS_OFFSET(args->nattrs, num_entries);\n\tfrag_len = COMPOSITE_CONSTITUENTS_OFFSET(args->nattrs, 0);\n\tif (frag_len > max_fragsize)\n\t\treturn -ENXIO;\n\n\tif (!args->use_txbuf) {\n\t\taddr = virt_to_phys(buffer);\n\t\tbuf_sz = max_fragsize / FFA_PAGE_SIZE;\n\t}\n\n\tconstituents = buffer + frag_len;\n\tidx = 0;\n\tdo {\n\t\tif (frag_len == max_fragsize) {\n\t\t\trc = ffa_transmit_fragment(func_id, addr, buf_sz,\n\t\t\t\t\t\t   frag_len, length,\n\t\t\t\t\t\t   &args->g_handle, first);\n\t\t\tif (rc < 0)\n\t\t\t\treturn -ENXIO;\n\n\t\t\tfirst = false;\n\t\t\tidx = 0;\n\t\t\tfrag_len = 0;\n\t\t\tconstituents = buffer;\n\t\t}\n\n\t\tif ((void *)constituents - buffer > max_fragsize) {\n\t\t\tpr_err(\"Memory Region Fragment > Tx Buffer size\\n\");\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tconstituents->address = sg_phys(args->sg);\n\t\tconstituents->pg_cnt = args->sg->length / FFA_PAGE_SIZE;\n\t\tconstituents->reserved = 0;\n\t\tconstituents++;\n\t\tfrag_len += sizeof(struct ffa_mem_region_addr_range);\n\t} while ((args->sg = sg_next(args->sg)));\n\n\treturn ffa_transmit_fragment(func_id, addr, buf_sz, frag_len,\n\t\t\t\t     length, &args->g_handle, first);\n}\n\nstatic int ffa_memory_ops(u32 func_id, struct ffa_mem_ops_args *args)\n{\n\tint ret;\n\tvoid *buffer;\n\n\tif (!args->use_txbuf) {\n\t\tbuffer = alloc_pages_exact(RXTX_BUFFER_SIZE, GFP_KERNEL);\n\t\tif (!buffer)\n\t\t\treturn -ENOMEM;\n\t} else {\n\t\tbuffer = drv_info->tx_buffer;\n\t\tmutex_lock(&drv_info->tx_lock);\n\t}\n\n\tret = ffa_setup_and_transmit(func_id, buffer, RXTX_BUFFER_SIZE, args);\n\n\tif (args->use_txbuf)\n\t\tmutex_unlock(&drv_info->tx_lock);\n\telse\n\t\tfree_pages_exact(buffer, RXTX_BUFFER_SIZE);\n\n\treturn ret < 0 ? ret : 0;\n}\n\nstatic int ffa_memory_reclaim(u64 g_handle, u32 flags)\n{\n\tffa_value_t ret;\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t      .a0 = FFA_MEM_RECLAIM,\n\t\t      .a1 = HANDLE_LOW(g_handle), .a2 = HANDLE_HIGH(g_handle),\n\t\t      .a3 = flags,\n\t\t      }, &ret);\n\n\tif (ret.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)ret.a2);\n\n\treturn 0;\n}\n\nstatic int ffa_features(u32 func_feat_id, u32 input_props,\n\t\t\tu32 *if_props_1, u32 *if_props_2)\n{\n\tffa_value_t id;\n\n\tif (!ARM_SMCCC_IS_FAST_CALL(func_feat_id) && input_props) {\n\t\tpr_err(\"%s: Invalid Parameters: %x, %x\", __func__,\n\t\t       func_feat_id, input_props);\n\t\treturn ffa_to_linux_errno(FFA_RET_INVALID_PARAMETERS);\n\t}\n\n\tinvoke_ffa_fn((ffa_value_t){\n\t\t.a0 = FFA_FEATURES, .a1 = func_feat_id, .a2 = input_props,\n\t\t}, &id);\n\n\tif (id.a0 == FFA_ERROR)\n\t\treturn ffa_to_linux_errno((int)id.a2);\n\n\tif (if_props_1)\n\t\t*if_props_1 = id.a2;\n\tif (if_props_2)\n\t\t*if_props_2 = id.a3;\n\n\treturn 0;\n}\n\nstatic void ffa_set_up_mem_ops_native_flag(void)\n{\n\tif (!ffa_features(FFA_FN_NATIVE(MEM_LEND), 0, NULL, NULL) ||\n\t    !ffa_features(FFA_FN_NATIVE(MEM_SHARE), 0, NULL, NULL))\n\t\tdrv_info->mem_ops_native = true;\n}\n\nstatic u32 ffa_api_version_get(void)\n{\n\treturn drv_info->version;\n}\n\nstatic int ffa_partition_info_get(const char *uuid_str,\n\t\t\t\t  struct ffa_partition_info *buffer)\n{\n\tint count;\n\tuuid_t uuid;\n\tstruct ffa_partition_info *pbuf;\n\n\tif (uuid_parse(uuid_str, &uuid)) {\n\t\tpr_err(\"invalid uuid (%s)\\n\", uuid_str);\n\t\treturn -ENODEV;\n\t}\n\n\tcount = ffa_partition_probe(&uuid, &pbuf);\n\tif (count <= 0)\n\t\treturn -ENOENT;\n\n\tmemcpy(buffer, pbuf, sizeof(*pbuf) * count);\n\tkfree(pbuf);\n\treturn 0;\n}\n\nstatic void ffa_mode_32bit_set(struct ffa_device *dev)\n{\n\tdev->mode_32bit = true;\n}\n\nstatic int ffa_sync_send_receive(struct ffa_device *dev,\n\t\t\t\t struct ffa_send_direct_data *data)\n{\n\treturn ffa_msg_send_direct_req(drv_info->vm_id, dev->vm_id,\n\t\t\t\t       dev->mode_32bit, data);\n}\n\nstatic int ffa_memory_share(struct ffa_mem_ops_args *args)\n{\n\tif (drv_info->mem_ops_native)\n\t\treturn ffa_memory_ops(FFA_FN_NATIVE(MEM_SHARE), args);\n\n\treturn ffa_memory_ops(FFA_MEM_SHARE, args);\n}\n\nstatic int ffa_memory_lend(struct ffa_mem_ops_args *args)\n{\n\t \n\tif (drv_info->mem_ops_native)\n\t\treturn ffa_memory_ops(FFA_FN_NATIVE(MEM_LEND), args);\n\n\treturn ffa_memory_ops(FFA_MEM_LEND, args);\n}\n\nstatic const struct ffa_info_ops ffa_drv_info_ops = {\n\t.api_version_get = ffa_api_version_get,\n\t.partition_info_get = ffa_partition_info_get,\n};\n\nstatic const struct ffa_msg_ops ffa_drv_msg_ops = {\n\t.mode_32bit_set = ffa_mode_32bit_set,\n\t.sync_send_receive = ffa_sync_send_receive,\n};\n\nstatic const struct ffa_mem_ops ffa_drv_mem_ops = {\n\t.memory_reclaim = ffa_memory_reclaim,\n\t.memory_share = ffa_memory_share,\n\t.memory_lend = ffa_memory_lend,\n};\n\nstatic const struct ffa_ops ffa_drv_ops = {\n\t.info_ops = &ffa_drv_info_ops,\n\t.msg_ops = &ffa_drv_msg_ops,\n\t.mem_ops = &ffa_drv_mem_ops,\n};\n\nvoid ffa_device_match_uuid(struct ffa_device *ffa_dev, const uuid_t *uuid)\n{\n\tint count, idx;\n\tstruct ffa_partition_info *pbuf, *tpbuf;\n\n\t \n\tif (drv_info->version > FFA_VERSION_1_0)\n\t\treturn;\n\n\tcount = ffa_partition_probe(uuid, &pbuf);\n\tif (count <= 0)\n\t\treturn;\n\n\tfor (idx = 0, tpbuf = pbuf; idx < count; idx++, tpbuf++)\n\t\tif (tpbuf->id == ffa_dev->vm_id)\n\t\t\tuuid_copy(&ffa_dev->uuid, uuid);\n\tkfree(pbuf);\n}\n\nstatic void ffa_setup_partitions(void)\n{\n\tint count, idx;\n\tuuid_t uuid;\n\tstruct ffa_device *ffa_dev;\n\tstruct ffa_partition_info *pbuf, *tpbuf;\n\n\tcount = ffa_partition_probe(&uuid_null, &pbuf);\n\tif (count <= 0) {\n\t\tpr_info(\"%s: No partitions found, error %d\\n\", __func__, count);\n\t\treturn;\n\t}\n\n\tfor (idx = 0, tpbuf = pbuf; idx < count; idx++, tpbuf++) {\n\t\timport_uuid(&uuid, (u8 *)tpbuf->uuid);\n\n\t\t \n\t\tffa_dev = ffa_device_register(&uuid, tpbuf->id, &ffa_drv_ops);\n\t\tif (!ffa_dev) {\n\t\t\tpr_err(\"%s: failed to register partition ID 0x%x\\n\",\n\t\t\t       __func__, tpbuf->id);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (drv_info->version > FFA_VERSION_1_0 &&\n\t\t    !(tpbuf->properties & FFA_PARTITION_AARCH64_EXEC))\n\t\t\tffa_mode_32bit_set(ffa_dev);\n\t}\n\tkfree(pbuf);\n}\n\nstatic int __init ffa_init(void)\n{\n\tint ret;\n\n\tret = ffa_transport_init(&invoke_ffa_fn);\n\tif (ret)\n\t\treturn ret;\n\n\tret = arm_ffa_bus_init();\n\tif (ret)\n\t\treturn ret;\n\n\tdrv_info = kzalloc(sizeof(*drv_info), GFP_KERNEL);\n\tif (!drv_info) {\n\t\tret = -ENOMEM;\n\t\tgoto ffa_bus_exit;\n\t}\n\n\tret = ffa_version_check(&drv_info->version);\n\tif (ret)\n\t\tgoto free_drv_info;\n\n\tif (ffa_id_get(&drv_info->vm_id)) {\n\t\tpr_err(\"failed to obtain VM id for self\\n\");\n\t\tret = -ENODEV;\n\t\tgoto free_drv_info;\n\t}\n\n\tdrv_info->rx_buffer = alloc_pages_exact(RXTX_BUFFER_SIZE, GFP_KERNEL);\n\tif (!drv_info->rx_buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto free_pages;\n\t}\n\n\tdrv_info->tx_buffer = alloc_pages_exact(RXTX_BUFFER_SIZE, GFP_KERNEL);\n\tif (!drv_info->tx_buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto free_pages;\n\t}\n\n\tret = ffa_rxtx_map(virt_to_phys(drv_info->tx_buffer),\n\t\t\t   virt_to_phys(drv_info->rx_buffer),\n\t\t\t   RXTX_BUFFER_SIZE / FFA_PAGE_SIZE);\n\tif (ret) {\n\t\tpr_err(\"failed to register FFA RxTx buffers\\n\");\n\t\tgoto free_pages;\n\t}\n\n\tmutex_init(&drv_info->rx_lock);\n\tmutex_init(&drv_info->tx_lock);\n\n\tffa_setup_partitions();\n\n\tffa_set_up_mem_ops_native_flag();\n\n\treturn 0;\nfree_pages:\n\tif (drv_info->tx_buffer)\n\t\tfree_pages_exact(drv_info->tx_buffer, RXTX_BUFFER_SIZE);\n\tfree_pages_exact(drv_info->rx_buffer, RXTX_BUFFER_SIZE);\nfree_drv_info:\n\tkfree(drv_info);\nffa_bus_exit:\n\tarm_ffa_bus_exit();\n\treturn ret;\n}\nsubsys_initcall(ffa_init);\n\nstatic void __exit ffa_exit(void)\n{\n\tffa_rxtx_unmap(drv_info->vm_id);\n\tfree_pages_exact(drv_info->tx_buffer, RXTX_BUFFER_SIZE);\n\tfree_pages_exact(drv_info->rx_buffer, RXTX_BUFFER_SIZE);\n\tkfree(drv_info);\n\tarm_ffa_bus_exit();\n}\nmodule_exit(ffa_exit);\n\nMODULE_ALIAS(\"arm-ffa\");\nMODULE_AUTHOR(\"Sudeep Holla <sudeep.holla@arm.com>\");\nMODULE_DESCRIPTION(\"Arm FF-A interface driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}