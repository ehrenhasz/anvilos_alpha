{
  "module_name": "virtio.c",
  "hash_id": "8654111ae3f945c387993744d094346e3be36a0a78d87bd9e00baabce673b0ac",
  "original_prompt": "Ingested from linux-6.6.14/drivers/firmware/arm_scmi/virtio.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/completion.h>\n#include <linux/errno.h>\n#include <linux/refcount.h>\n#include <linux/slab.h>\n#include <linux/virtio.h>\n#include <linux/virtio_config.h>\n\n#include <uapi/linux/virtio_ids.h>\n#include <uapi/linux/virtio_scmi.h>\n\n#include \"common.h\"\n\n#define VIRTIO_MAX_RX_TIMEOUT_MS\t60000\n#define VIRTIO_SCMI_MAX_MSG_SIZE 128  \n#define VIRTIO_SCMI_MAX_PDU_SIZE \\\n\t(VIRTIO_SCMI_MAX_MSG_SIZE + SCMI_MSG_MAX_PROT_OVERHEAD)\n#define DESCRIPTORS_PER_TX_MSG 2\n\n \nstruct scmi_vio_channel {\n\tstruct virtqueue *vqueue;\n\tstruct scmi_chan_info *cinfo;\n\t \n\tspinlock_t free_lock;\n\tstruct list_head free_list;\n\t \n\tspinlock_t pending_lock;\n\tstruct list_head pending_cmds_list;\n\tstruct work_struct deferred_tx_work;\n\tstruct workqueue_struct *deferred_tx_wq;\n\tbool is_rx;\n\tunsigned int max_msg;\n\t \n\tspinlock_t lock;\n\tstruct completion *shutdown_done;\n\trefcount_t users;\n};\n\nenum poll_states {\n\tVIO_MSG_NOT_POLLED,\n\tVIO_MSG_POLL_TIMEOUT,\n\tVIO_MSG_POLLING,\n\tVIO_MSG_POLL_DONE,\n};\n\n \nstruct scmi_vio_msg {\n\tstruct scmi_msg_payld *request;\n\tstruct scmi_msg_payld *input;\n\tstruct list_head list;\n\tunsigned int rx_len;\n\tunsigned int poll_idx;\n\tenum poll_states poll_status;\n\t \n\tspinlock_t poll_lock;\n\trefcount_t users;\n};\n\n \nstatic struct virtio_device *scmi_vdev;\n\nstatic void scmi_vio_channel_ready(struct scmi_vio_channel *vioch,\n\t\t\t\t   struct scmi_chan_info *cinfo)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&vioch->lock, flags);\n\tcinfo->transport_info = vioch;\n\t \n\tvioch->cinfo = cinfo;\n\tspin_unlock_irqrestore(&vioch->lock, flags);\n\n\trefcount_set(&vioch->users, 1);\n}\n\nstatic inline bool scmi_vio_channel_acquire(struct scmi_vio_channel *vioch)\n{\n\treturn refcount_inc_not_zero(&vioch->users);\n}\n\nstatic inline void scmi_vio_channel_release(struct scmi_vio_channel *vioch)\n{\n\tif (refcount_dec_and_test(&vioch->users)) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&vioch->lock, flags);\n\t\tif (vioch->shutdown_done) {\n\t\t\tvioch->cinfo = NULL;\n\t\t\tcomplete(vioch->shutdown_done);\n\t\t}\n\t\tspin_unlock_irqrestore(&vioch->lock, flags);\n\t}\n}\n\nstatic void scmi_vio_channel_cleanup_sync(struct scmi_vio_channel *vioch)\n{\n\tunsigned long flags;\n\tDECLARE_COMPLETION_ONSTACK(vioch_shutdown_done);\n\n\t \n\tspin_lock_irqsave(&vioch->lock, flags);\n\tif (!vioch->cinfo || vioch->shutdown_done) {\n\t\tspin_unlock_irqrestore(&vioch->lock, flags);\n\t\treturn;\n\t}\n\n\tvioch->shutdown_done = &vioch_shutdown_done;\n\tif (!vioch->is_rx && vioch->deferred_tx_wq)\n\t\t \n\t\tvioch->deferred_tx_wq = NULL;\n\tspin_unlock_irqrestore(&vioch->lock, flags);\n\n\tscmi_vio_channel_release(vioch);\n\n\t \n\twait_for_completion(vioch->shutdown_done);\n}\n\n \nstatic struct scmi_vio_msg *\nscmi_virtio_get_free_msg(struct scmi_vio_channel *vioch)\n{\n\tunsigned long flags;\n\tstruct scmi_vio_msg *msg;\n\n\tspin_lock_irqsave(&vioch->free_lock, flags);\n\tif (list_empty(&vioch->free_list)) {\n\t\tspin_unlock_irqrestore(&vioch->free_lock, flags);\n\t\treturn NULL;\n\t}\n\n\tmsg = list_first_entry(&vioch->free_list, typeof(*msg), list);\n\tlist_del_init(&msg->list);\n\tspin_unlock_irqrestore(&vioch->free_lock, flags);\n\n\t \n\tmsg->poll_status = VIO_MSG_NOT_POLLED;\n\trefcount_set(&msg->users, 1);\n\n\treturn msg;\n}\n\nstatic inline bool scmi_vio_msg_acquire(struct scmi_vio_msg *msg)\n{\n\treturn refcount_inc_not_zero(&msg->users);\n}\n\n \nstatic inline bool scmi_vio_msg_release(struct scmi_vio_channel *vioch,\n\t\t\t\t\tstruct scmi_vio_msg *msg)\n{\n\tbool ret;\n\n\tret = refcount_dec_and_test(&msg->users);\n\tif (ret) {\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&vioch->free_lock, flags);\n\t\tlist_add_tail(&msg->list, &vioch->free_list);\n\t\tspin_unlock_irqrestore(&vioch->free_lock, flags);\n\t}\n\n\treturn ret;\n}\n\nstatic bool scmi_vio_have_vq_rx(struct virtio_device *vdev)\n{\n\treturn virtio_has_feature(vdev, VIRTIO_SCMI_F_P2A_CHANNELS);\n}\n\nstatic int scmi_vio_feed_vq_rx(struct scmi_vio_channel *vioch,\n\t\t\t       struct scmi_vio_msg *msg)\n{\n\tstruct scatterlist sg_in;\n\tint rc;\n\tunsigned long flags;\n\tstruct device *dev = &vioch->vqueue->vdev->dev;\n\n\tsg_init_one(&sg_in, msg->input, VIRTIO_SCMI_MAX_PDU_SIZE);\n\n\tspin_lock_irqsave(&vioch->lock, flags);\n\n\trc = virtqueue_add_inbuf(vioch->vqueue, &sg_in, 1, msg, GFP_ATOMIC);\n\tif (rc)\n\t\tdev_err(dev, \"failed to add to RX virtqueue (%d)\\n\", rc);\n\telse\n\t\tvirtqueue_kick(vioch->vqueue);\n\n\tspin_unlock_irqrestore(&vioch->lock, flags);\n\n\treturn rc;\n}\n\n \nstatic void scmi_finalize_message(struct scmi_vio_channel *vioch,\n\t\t\t\t  struct scmi_vio_msg *msg)\n{\n\tif (vioch->is_rx)\n\t\tscmi_vio_feed_vq_rx(vioch, msg);\n\telse\n\t\tscmi_vio_msg_release(vioch, msg);\n}\n\nstatic void scmi_vio_complete_cb(struct virtqueue *vqueue)\n{\n\tunsigned long flags;\n\tunsigned int length;\n\tstruct scmi_vio_channel *vioch;\n\tstruct scmi_vio_msg *msg;\n\tbool cb_enabled = true;\n\n\tif (WARN_ON_ONCE(!vqueue->vdev->priv))\n\t\treturn;\n\tvioch = &((struct scmi_vio_channel *)vqueue->vdev->priv)[vqueue->index];\n\n\tfor (;;) {\n\t\tif (!scmi_vio_channel_acquire(vioch))\n\t\t\treturn;\n\n\t\tspin_lock_irqsave(&vioch->lock, flags);\n\t\tif (cb_enabled) {\n\t\t\tvirtqueue_disable_cb(vqueue);\n\t\t\tcb_enabled = false;\n\t\t}\n\n\t\tmsg = virtqueue_get_buf(vqueue, &length);\n\t\tif (!msg) {\n\t\t\tif (virtqueue_enable_cb(vqueue)) {\n\t\t\t\tspin_unlock_irqrestore(&vioch->lock, flags);\n\t\t\t\tscmi_vio_channel_release(vioch);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tcb_enabled = true;\n\t\t}\n\t\tspin_unlock_irqrestore(&vioch->lock, flags);\n\n\t\tif (msg) {\n\t\t\tmsg->rx_len = length;\n\t\t\tscmi_rx_callback(vioch->cinfo,\n\t\t\t\t\t msg_read_header(msg->input), msg);\n\n\t\t\tscmi_finalize_message(vioch, msg);\n\t\t}\n\n\t\t \n\t\tscmi_vio_channel_release(vioch);\n\t}\n}\n\nstatic void scmi_vio_deferred_tx_worker(struct work_struct *work)\n{\n\tunsigned long flags;\n\tstruct scmi_vio_channel *vioch;\n\tstruct scmi_vio_msg *msg, *tmp;\n\n\tvioch = container_of(work, struct scmi_vio_channel, deferred_tx_work);\n\n\tif (!scmi_vio_channel_acquire(vioch))\n\t\treturn;\n\n\t \n\tspin_lock_irqsave(&vioch->pending_lock, flags);\n\n\t \n\tlist_for_each_entry_safe(msg, tmp, &vioch->pending_cmds_list, list) {\n\t\tlist_del(&msg->list);\n\n\t\t \n\t\tif (msg->poll_status == VIO_MSG_NOT_POLLED)\n\t\t\tscmi_rx_callback(vioch->cinfo,\n\t\t\t\t\t msg_read_header(msg->input), msg);\n\n\t\t \n\t\tscmi_vio_msg_release(vioch, msg);\n\t}\n\n\tspin_unlock_irqrestore(&vioch->pending_lock, flags);\n\n\t \n\tscmi_vio_complete_cb(vioch->vqueue);\n\n\tscmi_vio_channel_release(vioch);\n}\n\nstatic const char *const scmi_vio_vqueue_names[] = { \"tx\", \"rx\" };\n\nstatic vq_callback_t *scmi_vio_complete_callbacks[] = {\n\tscmi_vio_complete_cb,\n\tscmi_vio_complete_cb\n};\n\nstatic unsigned int virtio_get_max_msg(struct scmi_chan_info *base_cinfo)\n{\n\tstruct scmi_vio_channel *vioch = base_cinfo->transport_info;\n\n\treturn vioch->max_msg;\n}\n\nstatic int virtio_link_supplier(struct device *dev)\n{\n\tif (!scmi_vdev) {\n\t\tdev_notice(dev,\n\t\t\t   \"Deferring probe after not finding a bound scmi-virtio device\\n\");\n\t\treturn -EPROBE_DEFER;\n\t}\n\n\tif (!device_link_add(dev, &scmi_vdev->dev,\n\t\t\t     DL_FLAG_AUTOREMOVE_CONSUMER)) {\n\t\tdev_err(dev, \"Adding link to supplier virtio device failed\\n\");\n\t\treturn -ECANCELED;\n\t}\n\n\treturn 0;\n}\n\nstatic bool virtio_chan_available(struct device_node *of_node, int idx)\n{\n\tstruct scmi_vio_channel *channels, *vioch = NULL;\n\n\tif (WARN_ON_ONCE(!scmi_vdev))\n\t\treturn false;\n\n\tchannels = (struct scmi_vio_channel *)scmi_vdev->priv;\n\n\tswitch (idx) {\n\tcase VIRTIO_SCMI_VQ_TX:\n\t\tvioch = &channels[VIRTIO_SCMI_VQ_TX];\n\t\tbreak;\n\tcase VIRTIO_SCMI_VQ_RX:\n\t\tif (scmi_vio_have_vq_rx(scmi_vdev))\n\t\t\tvioch = &channels[VIRTIO_SCMI_VQ_RX];\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\treturn vioch && !vioch->cinfo;\n}\n\nstatic void scmi_destroy_tx_workqueue(void *deferred_tx_wq)\n{\n\tdestroy_workqueue(deferred_tx_wq);\n}\n\nstatic int virtio_chan_setup(struct scmi_chan_info *cinfo, struct device *dev,\n\t\t\t     bool tx)\n{\n\tstruct scmi_vio_channel *vioch;\n\tint index = tx ? VIRTIO_SCMI_VQ_TX : VIRTIO_SCMI_VQ_RX;\n\tint i;\n\n\tif (!scmi_vdev)\n\t\treturn -EPROBE_DEFER;\n\n\tvioch = &((struct scmi_vio_channel *)scmi_vdev->priv)[index];\n\n\t \n\tif (tx && !vioch->deferred_tx_wq) {\n\t\tint ret;\n\n\t\tvioch->deferred_tx_wq =\n\t\t\talloc_workqueue(dev_name(&scmi_vdev->dev),\n\t\t\t\t\tWQ_UNBOUND | WQ_FREEZABLE | WQ_SYSFS,\n\t\t\t\t\t0);\n\t\tif (!vioch->deferred_tx_wq)\n\t\t\treturn -ENOMEM;\n\n\t\tret = devm_add_action_or_reset(dev, scmi_destroy_tx_workqueue,\n\t\t\t\t\t       vioch->deferred_tx_wq);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tINIT_WORK(&vioch->deferred_tx_work,\n\t\t\t  scmi_vio_deferred_tx_worker);\n\t}\n\n\tfor (i = 0; i < vioch->max_msg; i++) {\n\t\tstruct scmi_vio_msg *msg;\n\n\t\tmsg = devm_kzalloc(dev, sizeof(*msg), GFP_KERNEL);\n\t\tif (!msg)\n\t\t\treturn -ENOMEM;\n\n\t\tif (tx) {\n\t\t\tmsg->request = devm_kzalloc(dev,\n\t\t\t\t\t\t    VIRTIO_SCMI_MAX_PDU_SIZE,\n\t\t\t\t\t\t    GFP_KERNEL);\n\t\t\tif (!msg->request)\n\t\t\t\treturn -ENOMEM;\n\t\t\tspin_lock_init(&msg->poll_lock);\n\t\t\trefcount_set(&msg->users, 1);\n\t\t}\n\n\t\tmsg->input = devm_kzalloc(dev, VIRTIO_SCMI_MAX_PDU_SIZE,\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!msg->input)\n\t\t\treturn -ENOMEM;\n\n\t\tscmi_finalize_message(vioch, msg);\n\t}\n\n\tscmi_vio_channel_ready(vioch, cinfo);\n\n\treturn 0;\n}\n\nstatic int virtio_chan_free(int id, void *p, void *data)\n{\n\tstruct scmi_chan_info *cinfo = p;\n\tstruct scmi_vio_channel *vioch = cinfo->transport_info;\n\n\t \n\tvirtio_break_device(vioch->vqueue->vdev);\n\tscmi_vio_channel_cleanup_sync(vioch);\n\n\treturn 0;\n}\n\nstatic int virtio_send_message(struct scmi_chan_info *cinfo,\n\t\t\t       struct scmi_xfer *xfer)\n{\n\tstruct scmi_vio_channel *vioch = cinfo->transport_info;\n\tstruct scatterlist sg_out;\n\tstruct scatterlist sg_in;\n\tstruct scatterlist *sgs[DESCRIPTORS_PER_TX_MSG] = { &sg_out, &sg_in };\n\tunsigned long flags;\n\tint rc;\n\tstruct scmi_vio_msg *msg;\n\n\tif (!scmi_vio_channel_acquire(vioch))\n\t\treturn -EINVAL;\n\n\tmsg = scmi_virtio_get_free_msg(vioch);\n\tif (!msg) {\n\t\tscmi_vio_channel_release(vioch);\n\t\treturn -EBUSY;\n\t}\n\n\tmsg_tx_prepare(msg->request, xfer);\n\n\tsg_init_one(&sg_out, msg->request, msg_command_size(xfer));\n\tsg_init_one(&sg_in, msg->input, msg_response_size(xfer));\n\n\tspin_lock_irqsave(&vioch->lock, flags);\n\n\t \n\tif (xfer->hdr.poll_completion) {\n\t\tmsg->poll_idx = virtqueue_enable_cb_prepare(vioch->vqueue);\n\t\t \n\t\tmsg->poll_status = VIO_MSG_POLLING;\n\t\tscmi_vio_msg_acquire(msg);\n\t\t \n\t\tsmp_store_mb(xfer->priv, msg);\n\t}\n\n\trc = virtqueue_add_sgs(vioch->vqueue, sgs, 1, 1, msg, GFP_ATOMIC);\n\tif (rc)\n\t\tdev_err(vioch->cinfo->dev,\n\t\t\t\"failed to add to TX virtqueue (%d)\\n\", rc);\n\telse\n\t\tvirtqueue_kick(vioch->vqueue);\n\n\tspin_unlock_irqrestore(&vioch->lock, flags);\n\n\tif (rc) {\n\t\t \n\t\tsmp_store_mb(xfer->priv, NULL);\n\t\tif (xfer->hdr.poll_completion)\n\t\t\tscmi_vio_msg_release(vioch, msg);\n\t\tscmi_vio_msg_release(vioch, msg);\n\t}\n\n\tscmi_vio_channel_release(vioch);\n\n\treturn rc;\n}\n\nstatic void virtio_fetch_response(struct scmi_chan_info *cinfo,\n\t\t\t\t  struct scmi_xfer *xfer)\n{\n\tstruct scmi_vio_msg *msg = xfer->priv;\n\n\tif (msg)\n\t\tmsg_fetch_response(msg->input, msg->rx_len, xfer);\n}\n\nstatic void virtio_fetch_notification(struct scmi_chan_info *cinfo,\n\t\t\t\t      size_t max_len, struct scmi_xfer *xfer)\n{\n\tstruct scmi_vio_msg *msg = xfer->priv;\n\n\tif (msg)\n\t\tmsg_fetch_notification(msg->input, msg->rx_len, max_len, xfer);\n}\n\n \nstatic void virtio_mark_txdone(struct scmi_chan_info *cinfo, int ret,\n\t\t\t       struct scmi_xfer *xfer)\n{\n\tunsigned long flags;\n\tstruct scmi_vio_channel *vioch = cinfo->transport_info;\n\tstruct scmi_vio_msg *msg = xfer->priv;\n\n\tif (!msg || !scmi_vio_channel_acquire(vioch))\n\t\treturn;\n\n\t \n\tsmp_store_mb(xfer->priv, NULL);\n\n\t \n\tif (!xfer->hdr.poll_completion || scmi_vio_msg_release(vioch, msg)) {\n\t\tscmi_vio_channel_release(vioch);\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&msg->poll_lock, flags);\n\t \n\tif (ret != -ETIMEDOUT || msg->poll_status == VIO_MSG_POLL_DONE)\n\t\tscmi_vio_msg_release(vioch, msg);\n\telse if (msg->poll_status == VIO_MSG_POLLING)\n\t\tmsg->poll_status = VIO_MSG_POLL_TIMEOUT;\n\tspin_unlock_irqrestore(&msg->poll_lock, flags);\n\n\tscmi_vio_channel_release(vioch);\n}\n\n \nstatic bool virtio_poll_done(struct scmi_chan_info *cinfo,\n\t\t\t     struct scmi_xfer *xfer)\n{\n\tbool pending, found = false;\n\tunsigned int length, any_prefetched = 0;\n\tunsigned long flags;\n\tstruct scmi_vio_msg *next_msg, *msg = xfer->priv;\n\tstruct scmi_vio_channel *vioch = cinfo->transport_info;\n\n\tif (!msg)\n\t\treturn true;\n\n\t \n\tif (msg->poll_status == VIO_MSG_POLL_DONE)\n\t\treturn true;\n\n\tif (!scmi_vio_channel_acquire(vioch))\n\t\treturn true;\n\n\t \n\tpending = virtqueue_poll(vioch->vqueue, msg->poll_idx);\n\tif (!pending) {\n\t\tscmi_vio_channel_release(vioch);\n\t\treturn false;\n\t}\n\n\tspin_lock_irqsave(&vioch->lock, flags);\n\tvirtqueue_disable_cb(vioch->vqueue);\n\n\t \n\twhile ((next_msg = virtqueue_get_buf(vioch->vqueue, &length))) {\n\t\tbool next_msg_done = false;\n\n\t\t \n\t\tspin_lock(&next_msg->poll_lock);\n\t\tif (next_msg->poll_status == VIO_MSG_POLLING) {\n\t\t\tnext_msg->poll_status = VIO_MSG_POLL_DONE;\n\t\t\tnext_msg_done = true;\n\t\t}\n\t\tspin_unlock(&next_msg->poll_lock);\n\n\t\tnext_msg->rx_len = length;\n\t\t \n\t\tif (next_msg == msg) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t} else if (next_msg_done) {\n\t\t\t \n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tspin_lock(&next_msg->poll_lock);\n\t\tif (next_msg->poll_status == VIO_MSG_NOT_POLLED ||\n\t\t    next_msg->poll_status == VIO_MSG_POLL_TIMEOUT) {\n\t\t\tspin_unlock(&next_msg->poll_lock);\n\n\t\t\tany_prefetched++;\n\t\t\tspin_lock(&vioch->pending_lock);\n\t\t\tlist_add_tail(&next_msg->list,\n\t\t\t\t      &vioch->pending_cmds_list);\n\t\t\tspin_unlock(&vioch->pending_lock);\n\t\t} else {\n\t\t\tspin_unlock(&next_msg->poll_lock);\n\t\t}\n\t}\n\n\t \n\tif (found) {\n\t\tpending = !virtqueue_enable_cb(vioch->vqueue);\n\t} else {\n\t\tmsg->poll_idx = virtqueue_enable_cb_prepare(vioch->vqueue);\n\t\tpending = virtqueue_poll(vioch->vqueue, msg->poll_idx);\n\t}\n\n\tif (vioch->deferred_tx_wq && (any_prefetched || pending))\n\t\tqueue_work(vioch->deferred_tx_wq, &vioch->deferred_tx_work);\n\n\tspin_unlock_irqrestore(&vioch->lock, flags);\n\n\tscmi_vio_channel_release(vioch);\n\n\treturn found;\n}\n\nstatic const struct scmi_transport_ops scmi_virtio_ops = {\n\t.link_supplier = virtio_link_supplier,\n\t.chan_available = virtio_chan_available,\n\t.chan_setup = virtio_chan_setup,\n\t.chan_free = virtio_chan_free,\n\t.get_max_msg = virtio_get_max_msg,\n\t.send_message = virtio_send_message,\n\t.fetch_response = virtio_fetch_response,\n\t.fetch_notification = virtio_fetch_notification,\n\t.mark_txdone = virtio_mark_txdone,\n\t.poll_done = virtio_poll_done,\n};\n\nstatic int scmi_vio_probe(struct virtio_device *vdev)\n{\n\tstruct device *dev = &vdev->dev;\n\tstruct scmi_vio_channel *channels;\n\tbool have_vq_rx;\n\tint vq_cnt;\n\tint i;\n\tint ret;\n\tstruct virtqueue *vqs[VIRTIO_SCMI_VQ_MAX_CNT];\n\n\t \n\tif (scmi_vdev) {\n\t\tdev_err(dev,\n\t\t\t\"One SCMI Virtio device was already initialized: only one allowed.\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\thave_vq_rx = scmi_vio_have_vq_rx(vdev);\n\tvq_cnt = have_vq_rx ? VIRTIO_SCMI_VQ_MAX_CNT : 1;\n\n\tchannels = devm_kcalloc(dev, vq_cnt, sizeof(*channels), GFP_KERNEL);\n\tif (!channels)\n\t\treturn -ENOMEM;\n\n\tif (have_vq_rx)\n\t\tchannels[VIRTIO_SCMI_VQ_RX].is_rx = true;\n\n\tret = virtio_find_vqs(vdev, vq_cnt, vqs, scmi_vio_complete_callbacks,\n\t\t\t      scmi_vio_vqueue_names, NULL);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to get %d virtqueue(s)\\n\", vq_cnt);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < vq_cnt; i++) {\n\t\tunsigned int sz;\n\n\t\tspin_lock_init(&channels[i].lock);\n\t\tspin_lock_init(&channels[i].free_lock);\n\t\tINIT_LIST_HEAD(&channels[i].free_list);\n\t\tspin_lock_init(&channels[i].pending_lock);\n\t\tINIT_LIST_HEAD(&channels[i].pending_cmds_list);\n\t\tchannels[i].vqueue = vqs[i];\n\n\t\tsz = virtqueue_get_vring_size(channels[i].vqueue);\n\t\t \n\t\tif (!channels[i].is_rx)\n\t\t\tsz /= DESCRIPTORS_PER_TX_MSG;\n\n\t\tif (sz > MSG_TOKEN_MAX) {\n\t\t\tdev_info(dev,\n\t\t\t\t \"%s virtqueue could hold %d messages. Only %ld allowed to be pending.\\n\",\n\t\t\t\t channels[i].is_rx ? \"rx\" : \"tx\",\n\t\t\t\t sz, MSG_TOKEN_MAX);\n\t\t\tsz = MSG_TOKEN_MAX;\n\t\t}\n\t\tchannels[i].max_msg = sz;\n\t}\n\n\tvdev->priv = channels;\n\t \n\tsmp_store_mb(scmi_vdev, vdev);\n\n\treturn 0;\n}\n\nstatic void scmi_vio_remove(struct virtio_device *vdev)\n{\n\t \n\tvirtio_reset_device(vdev);\n\tvdev->config->del_vqs(vdev);\n\t \n\tsmp_store_mb(scmi_vdev, NULL);\n}\n\nstatic int scmi_vio_validate(struct virtio_device *vdev)\n{\n#ifdef CONFIG_ARM_SCMI_TRANSPORT_VIRTIO_VERSION1_COMPLIANCE\n\tif (!virtio_has_feature(vdev, VIRTIO_F_VERSION_1)) {\n\t\tdev_err(&vdev->dev,\n\t\t\t\"device does not comply with spec version 1.x\\n\");\n\t\treturn -EINVAL;\n\t}\n#endif\n\treturn 0;\n}\n\nstatic unsigned int features[] = {\n\tVIRTIO_SCMI_F_P2A_CHANNELS,\n};\n\nstatic const struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_SCMI, VIRTIO_DEV_ANY_ID },\n\t{ 0 }\n};\n\nstatic struct virtio_driver virtio_scmi_driver = {\n\t.driver.name = \"scmi-virtio\",\n\t.driver.owner = THIS_MODULE,\n\t.feature_table = features,\n\t.feature_table_size = ARRAY_SIZE(features),\n\t.id_table = id_table,\n\t.probe = scmi_vio_probe,\n\t.remove = scmi_vio_remove,\n\t.validate = scmi_vio_validate,\n};\n\nstatic int __init virtio_scmi_init(void)\n{\n\treturn register_virtio_driver(&virtio_scmi_driver);\n}\n\nstatic void virtio_scmi_exit(void)\n{\n\tunregister_virtio_driver(&virtio_scmi_driver);\n}\n\nconst struct scmi_desc scmi_virtio_desc = {\n\t.transport_init = virtio_scmi_init,\n\t.transport_exit = virtio_scmi_exit,\n\t.ops = &scmi_virtio_ops,\n\t \n\t.max_rx_timeout_ms = VIRTIO_MAX_RX_TIMEOUT_MS,\n\t.max_msg = 0,  \n\t.max_msg_size = VIRTIO_SCMI_MAX_MSG_SIZE,\n\t.atomic_enabled = IS_ENABLED(CONFIG_ARM_SCMI_TRANSPORT_VIRTIO_ATOMIC_ENABLE),\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}