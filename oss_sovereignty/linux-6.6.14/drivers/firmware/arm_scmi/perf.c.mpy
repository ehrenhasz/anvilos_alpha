{
  "module_name": "perf.c",
  "hash_id": "402ffbabf273ff0f3c923d2bd91a2c1774b320dd08a2a4c8e56dba14fa5edf8d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/firmware/arm_scmi/perf.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"SCMI Notifications PERF - \" fmt\n\n#include <linux/bits.h>\n#include <linux/hashtable.h>\n#include <linux/io.h>\n#include <linux/log2.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/pm_opp.h>\n#include <linux/scmi_protocol.h>\n#include <linux/sort.h>\n#include <linux/xarray.h>\n\n#include <trace/events/scmi.h>\n\n#include \"protocols.h\"\n#include \"notify.h\"\n\n#define MAX_OPPS\t\t16\n\nenum scmi_performance_protocol_cmd {\n\tPERF_DOMAIN_ATTRIBUTES = 0x3,\n\tPERF_DESCRIBE_LEVELS = 0x4,\n\tPERF_LIMITS_SET = 0x5,\n\tPERF_LIMITS_GET = 0x6,\n\tPERF_LEVEL_SET = 0x7,\n\tPERF_LEVEL_GET = 0x8,\n\tPERF_NOTIFY_LIMITS = 0x9,\n\tPERF_NOTIFY_LEVEL = 0xa,\n\tPERF_DESCRIBE_FASTCHANNEL = 0xb,\n\tPERF_DOMAIN_NAME_GET = 0xc,\n};\n\nenum {\n\tPERF_FC_LEVEL,\n\tPERF_FC_LIMIT,\n\tPERF_FC_MAX,\n};\n\nstruct scmi_opp {\n\tu32 perf;\n\tu32 power;\n\tu32 trans_latency_us;\n\tu32 indicative_freq;\n\tu32 level_index;\n\tstruct hlist_node hash;\n};\n\nstruct scmi_msg_resp_perf_attributes {\n\t__le16 num_domains;\n\t__le16 flags;\n#define POWER_SCALE_IN_MILLIWATT(x)\t((x) & BIT(0))\n#define POWER_SCALE_IN_MICROWATT(x)\t((x) & BIT(1))\n\t__le32 stats_addr_low;\n\t__le32 stats_addr_high;\n\t__le32 stats_size;\n};\n\nstruct scmi_msg_resp_perf_domain_attributes {\n\t__le32 flags;\n#define SUPPORTS_SET_LIMITS(x)\t\t((x) & BIT(31))\n#define SUPPORTS_SET_PERF_LVL(x)\t((x) & BIT(30))\n#define SUPPORTS_PERF_LIMIT_NOTIFY(x)\t((x) & BIT(29))\n#define SUPPORTS_PERF_LEVEL_NOTIFY(x)\t((x) & BIT(28))\n#define SUPPORTS_PERF_FASTCHANNELS(x)\t((x) & BIT(27))\n#define SUPPORTS_EXTENDED_NAMES(x)\t((x) & BIT(26))\n#define SUPPORTS_LEVEL_INDEXING(x)\t((x) & BIT(25))\n\t__le32 rate_limit_us;\n\t__le32 sustained_freq_khz;\n\t__le32 sustained_perf_level;\n\t    u8 name[SCMI_SHORT_NAME_MAX_SIZE];\n};\n\nstruct scmi_msg_perf_describe_levels {\n\t__le32 domain;\n\t__le32 level_index;\n};\n\nstruct scmi_perf_set_limits {\n\t__le32 domain;\n\t__le32 max_level;\n\t__le32 min_level;\n};\n\nstruct scmi_perf_get_limits {\n\t__le32 max_level;\n\t__le32 min_level;\n};\n\nstruct scmi_perf_set_level {\n\t__le32 domain;\n\t__le32 level;\n};\n\nstruct scmi_perf_notify_level_or_limits {\n\t__le32 domain;\n\t__le32 notify_enable;\n};\n\nstruct scmi_perf_limits_notify_payld {\n\t__le32 agent_id;\n\t__le32 domain_id;\n\t__le32 range_max;\n\t__le32 range_min;\n};\n\nstruct scmi_perf_level_notify_payld {\n\t__le32 agent_id;\n\t__le32 domain_id;\n\t__le32 performance_level;\n};\n\nstruct scmi_msg_resp_perf_describe_levels {\n\t__le16 num_returned;\n\t__le16 num_remaining;\n\tstruct {\n\t\t__le32 perf_val;\n\t\t__le32 power;\n\t\t__le16 transition_latency_us;\n\t\t__le16 reserved;\n\t} opp[];\n};\n\nstruct scmi_msg_resp_perf_describe_levels_v4 {\n\t__le16 num_returned;\n\t__le16 num_remaining;\n\tstruct {\n\t\t__le32 perf_val;\n\t\t__le32 power;\n\t\t__le16 transition_latency_us;\n\t\t__le16 reserved;\n\t\t__le32 indicative_freq;\n\t\t__le32 level_index;\n\t} opp[];\n};\n\nstruct perf_dom_info {\n\tu32 id;\n\tbool set_limits;\n\tbool perf_limit_notify;\n\tbool perf_level_notify;\n\tbool perf_fastchannels;\n\tbool level_indexing_mode;\n\tu32 opp_count;\n\tu32 sustained_freq_khz;\n\tu32 sustained_perf_level;\n\tunsigned long mult_factor;\n\tstruct scmi_perf_domain_info info;\n\tstruct scmi_opp opp[MAX_OPPS];\n\tstruct scmi_fc_info *fc_info;\n\tstruct xarray opps_by_idx;\n\tstruct xarray opps_by_lvl;\n\tDECLARE_HASHTABLE(opps_by_freq, ilog2(MAX_OPPS));\n};\n\n#define LOOKUP_BY_FREQ(__htp, __freq)\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\t\t \t\\\n\t\tu32 f_ = (u32)(__freq);\t\t\t\t\t\\\n\t\tstruct scmi_opp *_opp;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\t\thash_for_each_possible((__htp), _opp, hash, f_)\t\t\\\n\t\t\tif (_opp->indicative_freq == f_)\t\t\\\n\t\t\t\tbreak;\t\t\t\t\t\\\n\t\t_opp;\t\t\t\t\t\t\t\\\n})\n\nstruct scmi_perf_info {\n\tu32 version;\n\tu16 num_domains;\n\tenum scmi_power_scale power_scale;\n\tu64 stats_addr;\n\tu32 stats_size;\n\tstruct perf_dom_info *dom_info;\n};\n\nstatic enum scmi_performance_protocol_cmd evt_2_cmd[] = {\n\tPERF_NOTIFY_LIMITS,\n\tPERF_NOTIFY_LEVEL,\n};\n\nstatic int scmi_perf_attributes_get(const struct scmi_protocol_handle *ph,\n\t\t\t\t    struct scmi_perf_info *pi)\n{\n\tint ret;\n\tstruct scmi_xfer *t;\n\tstruct scmi_msg_resp_perf_attributes *attr;\n\n\tret = ph->xops->xfer_get_init(ph, PROTOCOL_ATTRIBUTES, 0,\n\t\t\t\t      sizeof(*attr), &t);\n\tif (ret)\n\t\treturn ret;\n\n\tattr = t->rx.buf;\n\n\tret = ph->xops->do_xfer(ph, t);\n\tif (!ret) {\n\t\tu16 flags = le16_to_cpu(attr->flags);\n\n\t\tpi->num_domains = le16_to_cpu(attr->num_domains);\n\n\t\tif (POWER_SCALE_IN_MILLIWATT(flags))\n\t\t\tpi->power_scale = SCMI_POWER_MILLIWATTS;\n\t\tif (PROTOCOL_REV_MAJOR(pi->version) >= 0x3)\n\t\t\tif (POWER_SCALE_IN_MICROWATT(flags))\n\t\t\t\tpi->power_scale = SCMI_POWER_MICROWATTS;\n\n\t\tpi->stats_addr = le32_to_cpu(attr->stats_addr_low) |\n\t\t\t\t(u64)le32_to_cpu(attr->stats_addr_high) << 32;\n\t\tpi->stats_size = le32_to_cpu(attr->stats_size);\n\t}\n\n\tph->xops->xfer_put(ph, t);\n\treturn ret;\n}\n\nstatic void scmi_perf_xa_destroy(void *data)\n{\n\tint domain;\n\tstruct scmi_perf_info *pinfo = data;\n\n\tfor (domain = 0; domain < pinfo->num_domains; domain++) {\n\t\txa_destroy(&((pinfo->dom_info + domain)->opps_by_idx));\n\t\txa_destroy(&((pinfo->dom_info + domain)->opps_by_lvl));\n\t}\n}\n\nstatic int\nscmi_perf_domain_attributes_get(const struct scmi_protocol_handle *ph,\n\t\t\t\tstruct perf_dom_info *dom_info,\n\t\t\t\tu32 version)\n{\n\tint ret;\n\tu32 flags;\n\tstruct scmi_xfer *t;\n\tstruct scmi_msg_resp_perf_domain_attributes *attr;\n\n\tret = ph->xops->xfer_get_init(ph, PERF_DOMAIN_ATTRIBUTES,\n\t\t\t\t      sizeof(dom_info->id), sizeof(*attr), &t);\n\tif (ret)\n\t\treturn ret;\n\n\tput_unaligned_le32(dom_info->id, t->tx.buf);\n\tattr = t->rx.buf;\n\n\tret = ph->xops->do_xfer(ph, t);\n\tif (!ret) {\n\t\tflags = le32_to_cpu(attr->flags);\n\n\t\tdom_info->set_limits = SUPPORTS_SET_LIMITS(flags);\n\t\tdom_info->info.set_perf = SUPPORTS_SET_PERF_LVL(flags);\n\t\tdom_info->perf_limit_notify = SUPPORTS_PERF_LIMIT_NOTIFY(flags);\n\t\tdom_info->perf_level_notify = SUPPORTS_PERF_LEVEL_NOTIFY(flags);\n\t\tdom_info->perf_fastchannels = SUPPORTS_PERF_FASTCHANNELS(flags);\n\t\tif (PROTOCOL_REV_MAJOR(version) >= 0x4)\n\t\t\tdom_info->level_indexing_mode =\n\t\t\t\tSUPPORTS_LEVEL_INDEXING(flags);\n\t\tdom_info->sustained_freq_khz =\n\t\t\t\t\tle32_to_cpu(attr->sustained_freq_khz);\n\t\tdom_info->sustained_perf_level =\n\t\t\t\t\tle32_to_cpu(attr->sustained_perf_level);\n\t\tif (!dom_info->sustained_freq_khz ||\n\t\t    !dom_info->sustained_perf_level ||\n\t\t    dom_info->level_indexing_mode)\n\t\t\t \n\t\t\tdom_info->mult_factor =\t1000;\n\t\telse\n\t\t\tdom_info->mult_factor =\n\t\t\t\t\t(dom_info->sustained_freq_khz * 1000UL)\n\t\t\t\t\t/ dom_info->sustained_perf_level;\n\t\tstrscpy(dom_info->info.name, attr->name,\n\t\t\tSCMI_SHORT_NAME_MAX_SIZE);\n\t}\n\n\tph->xops->xfer_put(ph, t);\n\n\t \n\tif (!ret && PROTOCOL_REV_MAJOR(version) >= 0x3 &&\n\t    SUPPORTS_EXTENDED_NAMES(flags))\n\t\tph->hops->extended_name_get(ph, PERF_DOMAIN_NAME_GET,\n\t\t\t\t\t    dom_info->id, dom_info->info.name,\n\t\t\t\t\t    SCMI_MAX_STR_SIZE);\n\n\tif (dom_info->level_indexing_mode) {\n\t\txa_init(&dom_info->opps_by_idx);\n\t\txa_init(&dom_info->opps_by_lvl);\n\t\thash_init(dom_info->opps_by_freq);\n\t}\n\n\treturn ret;\n}\n\nstatic int opp_cmp_func(const void *opp1, const void *opp2)\n{\n\tconst struct scmi_opp *t1 = opp1, *t2 = opp2;\n\n\treturn t1->perf - t2->perf;\n}\n\nstruct scmi_perf_ipriv {\n\tu32 version;\n\tstruct perf_dom_info *perf_dom;\n};\n\nstatic void iter_perf_levels_prepare_message(void *message,\n\t\t\t\t\t     unsigned int desc_index,\n\t\t\t\t\t     const void *priv)\n{\n\tstruct scmi_msg_perf_describe_levels *msg = message;\n\tconst struct scmi_perf_ipriv *p = priv;\n\n\tmsg->domain = cpu_to_le32(p->perf_dom->id);\n\t \n\tmsg->level_index = cpu_to_le32(desc_index);\n}\n\nstatic int iter_perf_levels_update_state(struct scmi_iterator_state *st,\n\t\t\t\t\t const void *response, void *priv)\n{\n\tconst struct scmi_msg_resp_perf_describe_levels *r = response;\n\n\tst->num_returned = le16_to_cpu(r->num_returned);\n\tst->num_remaining = le16_to_cpu(r->num_remaining);\n\n\treturn 0;\n}\n\nstatic inline void\nprocess_response_opp(struct scmi_opp *opp, unsigned int loop_idx,\n\t\t     const struct scmi_msg_resp_perf_describe_levels *r)\n{\n\topp->perf = le32_to_cpu(r->opp[loop_idx].perf_val);\n\topp->power = le32_to_cpu(r->opp[loop_idx].power);\n\topp->trans_latency_us =\n\t\tle16_to_cpu(r->opp[loop_idx].transition_latency_us);\n}\n\nstatic inline void\nprocess_response_opp_v4(struct perf_dom_info *dom, struct scmi_opp *opp,\n\t\t\tunsigned int loop_idx,\n\t\t\tconst struct scmi_msg_resp_perf_describe_levels_v4 *r)\n{\n\topp->perf = le32_to_cpu(r->opp[loop_idx].perf_val);\n\topp->power = le32_to_cpu(r->opp[loop_idx].power);\n\topp->trans_latency_us =\n\t\tle16_to_cpu(r->opp[loop_idx].transition_latency_us);\n\n\t \n\topp->indicative_freq = le32_to_cpu(r->opp[loop_idx].indicative_freq);\n\tif (dom->level_indexing_mode) {\n\t\topp->level_index = le32_to_cpu(r->opp[loop_idx].level_index);\n\n\t\txa_store(&dom->opps_by_idx, opp->level_index, opp, GFP_KERNEL);\n\t\txa_store(&dom->opps_by_lvl, opp->perf, opp, GFP_KERNEL);\n\t\thash_add(dom->opps_by_freq, &opp->hash, opp->indicative_freq);\n\t}\n}\n\nstatic int\niter_perf_levels_process_response(const struct scmi_protocol_handle *ph,\n\t\t\t\t  const void *response,\n\t\t\t\t  struct scmi_iterator_state *st, void *priv)\n{\n\tstruct scmi_opp *opp;\n\tstruct scmi_perf_ipriv *p = priv;\n\n\topp = &p->perf_dom->opp[st->desc_index + st->loop_idx];\n\tif (PROTOCOL_REV_MAJOR(p->version) <= 0x3)\n\t\tprocess_response_opp(opp, st->loop_idx, response);\n\telse\n\t\tprocess_response_opp_v4(p->perf_dom, opp, st->loop_idx,\n\t\t\t\t\tresponse);\n\tp->perf_dom->opp_count++;\n\n\tdev_dbg(ph->dev, \"Level %d Power %d Latency %dus Ifreq %d Index %d\\n\",\n\t\topp->perf, opp->power, opp->trans_latency_us,\n\t\topp->indicative_freq, opp->level_index);\n\n\treturn 0;\n}\n\nstatic int\nscmi_perf_describe_levels_get(const struct scmi_protocol_handle *ph,\n\t\t\t      struct perf_dom_info *perf_dom, u32 version)\n{\n\tint ret;\n\tvoid *iter;\n\tstruct scmi_iterator_ops ops = {\n\t\t.prepare_message = iter_perf_levels_prepare_message,\n\t\t.update_state = iter_perf_levels_update_state,\n\t\t.process_response = iter_perf_levels_process_response,\n\t};\n\tstruct scmi_perf_ipriv ppriv = {\n\t\t.version = version,\n\t\t.perf_dom = perf_dom,\n\t};\n\n\titer = ph->hops->iter_response_init(ph, &ops, MAX_OPPS,\n\t\t\t\t\t    PERF_DESCRIBE_LEVELS,\n\t\t\t\t\t    sizeof(struct scmi_msg_perf_describe_levels),\n\t\t\t\t\t    &ppriv);\n\tif (IS_ERR(iter))\n\t\treturn PTR_ERR(iter);\n\n\tret = ph->hops->iter_response_run(iter);\n\tif (ret)\n\t\treturn ret;\n\n\tif (perf_dom->opp_count)\n\t\tsort(perf_dom->opp, perf_dom->opp_count,\n\t\t     sizeof(struct scmi_opp), opp_cmp_func, NULL);\n\n\treturn ret;\n}\n\nstatic int scmi_perf_num_domains_get(const struct scmi_protocol_handle *ph)\n{\n\tstruct scmi_perf_info *pi = ph->get_priv(ph);\n\n\treturn pi->num_domains;\n}\n\nstatic inline struct perf_dom_info *\nscmi_perf_domain_lookup(const struct scmi_protocol_handle *ph, u32 domain)\n{\n\tstruct scmi_perf_info *pi = ph->get_priv(ph);\n\n\tif (domain >= pi->num_domains)\n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn pi->dom_info + domain;\n}\n\nstatic const struct scmi_perf_domain_info *\nscmi_perf_info_get(const struct scmi_protocol_handle *ph, u32 domain)\n{\n\tstruct perf_dom_info *dom;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn &dom->info;\n}\n\nstatic int scmi_perf_msg_limits_set(const struct scmi_protocol_handle *ph,\n\t\t\t\t    u32 domain, u32 max_perf, u32 min_perf)\n{\n\tint ret;\n\tstruct scmi_xfer *t;\n\tstruct scmi_perf_set_limits *limits;\n\n\tret = ph->xops->xfer_get_init(ph, PERF_LIMITS_SET,\n\t\t\t\t      sizeof(*limits), 0, &t);\n\tif (ret)\n\t\treturn ret;\n\n\tlimits = t->tx.buf;\n\tlimits->domain = cpu_to_le32(domain);\n\tlimits->max_level = cpu_to_le32(max_perf);\n\tlimits->min_level = cpu_to_le32(min_perf);\n\n\tret = ph->xops->do_xfer(ph, t);\n\n\tph->xops->xfer_put(ph, t);\n\treturn ret;\n}\n\nstatic int __scmi_perf_limits_set(const struct scmi_protocol_handle *ph,\n\t\t\t\t  struct perf_dom_info *dom, u32 max_perf,\n\t\t\t\t  u32 min_perf)\n{\n\tif (dom->fc_info && dom->fc_info[PERF_FC_LIMIT].set_addr) {\n\t\tstruct scmi_fc_info *fci = &dom->fc_info[PERF_FC_LIMIT];\n\n\t\ttrace_scmi_fc_call(SCMI_PROTOCOL_PERF, PERF_LIMITS_SET,\n\t\t\t\t   dom->id, min_perf, max_perf);\n\t\tiowrite32(max_perf, fci->set_addr);\n\t\tiowrite32(min_perf, fci->set_addr + 4);\n\t\tph->hops->fastchannel_db_ring(fci->set_db);\n\t\treturn 0;\n\t}\n\n\treturn scmi_perf_msg_limits_set(ph, dom->id, max_perf, min_perf);\n}\n\nstatic int scmi_perf_limits_set(const struct scmi_protocol_handle *ph,\n\t\t\t\tu32 domain, u32 max_perf, u32 min_perf)\n{\n\tstruct scmi_perf_info *pi = ph->get_priv(ph);\n\tstruct perf_dom_info *dom;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tif (PROTOCOL_REV_MAJOR(pi->version) >= 0x3 && !max_perf && !min_perf)\n\t\treturn -EINVAL;\n\n\tif (dom->level_indexing_mode) {\n\t\tstruct scmi_opp *opp;\n\n\t\tif (min_perf) {\n\t\t\topp = xa_load(&dom->opps_by_lvl, min_perf);\n\t\t\tif (!opp)\n\t\t\t\treturn -EIO;\n\n\t\t\tmin_perf = opp->level_index;\n\t\t}\n\n\t\tif (max_perf) {\n\t\t\topp = xa_load(&dom->opps_by_lvl, max_perf);\n\t\t\tif (!opp)\n\t\t\t\treturn -EIO;\n\n\t\t\tmax_perf = opp->level_index;\n\t\t}\n\t}\n\n\treturn __scmi_perf_limits_set(ph, dom, max_perf, min_perf);\n}\n\nstatic int scmi_perf_msg_limits_get(const struct scmi_protocol_handle *ph,\n\t\t\t\t    u32 domain, u32 *max_perf, u32 *min_perf)\n{\n\tint ret;\n\tstruct scmi_xfer *t;\n\tstruct scmi_perf_get_limits *limits;\n\n\tret = ph->xops->xfer_get_init(ph, PERF_LIMITS_GET,\n\t\t\t\t      sizeof(__le32), 0, &t);\n\tif (ret)\n\t\treturn ret;\n\n\tput_unaligned_le32(domain, t->tx.buf);\n\n\tret = ph->xops->do_xfer(ph, t);\n\tif (!ret) {\n\t\tlimits = t->rx.buf;\n\n\t\t*max_perf = le32_to_cpu(limits->max_level);\n\t\t*min_perf = le32_to_cpu(limits->min_level);\n\t}\n\n\tph->xops->xfer_put(ph, t);\n\treturn ret;\n}\n\nstatic int __scmi_perf_limits_get(const struct scmi_protocol_handle *ph,\n\t\t\t\t  struct perf_dom_info *dom, u32 *max_perf,\n\t\t\t\t  u32 *min_perf)\n{\n\tif (dom->fc_info && dom->fc_info[PERF_FC_LIMIT].get_addr) {\n\t\tstruct scmi_fc_info *fci = &dom->fc_info[PERF_FC_LIMIT];\n\n\t\t*max_perf = ioread32(fci->get_addr);\n\t\t*min_perf = ioread32(fci->get_addr + 4);\n\t\ttrace_scmi_fc_call(SCMI_PROTOCOL_PERF, PERF_LIMITS_GET,\n\t\t\t\t   dom->id, *min_perf, *max_perf);\n\t\treturn 0;\n\t}\n\n\treturn scmi_perf_msg_limits_get(ph, dom->id, max_perf, min_perf);\n}\n\nstatic int scmi_perf_limits_get(const struct scmi_protocol_handle *ph,\n\t\t\t\tu32 domain, u32 *max_perf, u32 *min_perf)\n{\n\tint ret;\n\tstruct perf_dom_info *dom;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tret = __scmi_perf_limits_get(ph, dom, max_perf, min_perf);\n\tif (ret)\n\t\treturn ret;\n\n\tif (dom->level_indexing_mode) {\n\t\tstruct scmi_opp *opp;\n\n\t\topp = xa_load(&dom->opps_by_idx, *min_perf);\n\t\tif (!opp)\n\t\t\treturn -EIO;\n\n\t\t*min_perf = opp->perf;\n\n\t\topp = xa_load(&dom->opps_by_idx, *max_perf);\n\t\tif (!opp)\n\t\t\treturn -EIO;\n\n\t\t*max_perf = opp->perf;\n\t}\n\n\treturn 0;\n}\n\nstatic int scmi_perf_msg_level_set(const struct scmi_protocol_handle *ph,\n\t\t\t\t   u32 domain, u32 level, bool poll)\n{\n\tint ret;\n\tstruct scmi_xfer *t;\n\tstruct scmi_perf_set_level *lvl;\n\n\tret = ph->xops->xfer_get_init(ph, PERF_LEVEL_SET, sizeof(*lvl), 0, &t);\n\tif (ret)\n\t\treturn ret;\n\n\tt->hdr.poll_completion = poll;\n\tlvl = t->tx.buf;\n\tlvl->domain = cpu_to_le32(domain);\n\tlvl->level = cpu_to_le32(level);\n\n\tret = ph->xops->do_xfer(ph, t);\n\n\tph->xops->xfer_put(ph, t);\n\treturn ret;\n}\n\nstatic int __scmi_perf_level_set(const struct scmi_protocol_handle *ph,\n\t\t\t\t struct perf_dom_info *dom, u32 level,\n\t\t\t\t bool poll)\n{\n\tif (dom->fc_info && dom->fc_info[PERF_FC_LEVEL].set_addr) {\n\t\tstruct scmi_fc_info *fci = &dom->fc_info[PERF_FC_LEVEL];\n\n\t\ttrace_scmi_fc_call(SCMI_PROTOCOL_PERF, PERF_LEVEL_SET,\n\t\t\t\t   dom->id, level, 0);\n\t\tiowrite32(level, fci->set_addr);\n\t\tph->hops->fastchannel_db_ring(fci->set_db);\n\t\treturn 0;\n\t}\n\n\treturn scmi_perf_msg_level_set(ph, dom->id, level, poll);\n}\n\nstatic int scmi_perf_level_set(const struct scmi_protocol_handle *ph,\n\t\t\t       u32 domain, u32 level, bool poll)\n{\n\tstruct perf_dom_info *dom;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tif (dom->level_indexing_mode) {\n\t\tstruct scmi_opp *opp;\n\n\t\topp = xa_load(&dom->opps_by_lvl, level);\n\t\tif (!opp)\n\t\t\treturn -EIO;\n\n\t\tlevel = opp->level_index;\n\t}\n\n\treturn __scmi_perf_level_set(ph, dom, level, poll);\n}\n\nstatic int scmi_perf_msg_level_get(const struct scmi_protocol_handle *ph,\n\t\t\t\t   u32 domain, u32 *level, bool poll)\n{\n\tint ret;\n\tstruct scmi_xfer *t;\n\n\tret = ph->xops->xfer_get_init(ph, PERF_LEVEL_GET,\n\t\t\t\t     sizeof(u32), sizeof(u32), &t);\n\tif (ret)\n\t\treturn ret;\n\n\tt->hdr.poll_completion = poll;\n\tput_unaligned_le32(domain, t->tx.buf);\n\n\tret = ph->xops->do_xfer(ph, t);\n\tif (!ret)\n\t\t*level = get_unaligned_le32(t->rx.buf);\n\n\tph->xops->xfer_put(ph, t);\n\treturn ret;\n}\n\nstatic int __scmi_perf_level_get(const struct scmi_protocol_handle *ph,\n\t\t\t\t struct perf_dom_info *dom, u32 *level,\n\t\t\t\t bool poll)\n{\n\tif (dom->fc_info && dom->fc_info[PERF_FC_LEVEL].get_addr) {\n\t\t*level = ioread32(dom->fc_info[PERF_FC_LEVEL].get_addr);\n\t\ttrace_scmi_fc_call(SCMI_PROTOCOL_PERF, PERF_LEVEL_GET,\n\t\t\t\t   dom->id, *level, 0);\n\t\treturn 0;\n\t}\n\n\treturn scmi_perf_msg_level_get(ph, dom->id, level, poll);\n}\n\nstatic int scmi_perf_level_get(const struct scmi_protocol_handle *ph,\n\t\t\t       u32 domain, u32 *level, bool poll)\n{\n\tint ret;\n\tstruct perf_dom_info *dom;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tret = __scmi_perf_level_get(ph, dom, level, poll);\n\tif (ret)\n\t\treturn ret;\n\n\tif (dom->level_indexing_mode) {\n\t\tstruct scmi_opp *opp;\n\n\t\topp = xa_load(&dom->opps_by_idx, *level);\n\t\tif (!opp)\n\t\t\treturn -EIO;\n\n\t\t*level = opp->perf;\n\t}\n\n\treturn 0;\n}\n\nstatic int scmi_perf_level_limits_notify(const struct scmi_protocol_handle *ph,\n\t\t\t\t\t u32 domain, int message_id,\n\t\t\t\t\t bool enable)\n{\n\tint ret;\n\tstruct scmi_xfer *t;\n\tstruct scmi_perf_notify_level_or_limits *notify;\n\n\tret = ph->xops->xfer_get_init(ph, message_id, sizeof(*notify), 0, &t);\n\tif (ret)\n\t\treturn ret;\n\n\tnotify = t->tx.buf;\n\tnotify->domain = cpu_to_le32(domain);\n\tnotify->notify_enable = enable ? cpu_to_le32(BIT(0)) : 0;\n\n\tret = ph->xops->do_xfer(ph, t);\n\n\tph->xops->xfer_put(ph, t);\n\treturn ret;\n}\n\nstatic void scmi_perf_domain_init_fc(const struct scmi_protocol_handle *ph,\n\t\t\t\t     u32 domain, struct scmi_fc_info **p_fc)\n{\n\tstruct scmi_fc_info *fc;\n\n\tfc = devm_kcalloc(ph->dev, PERF_FC_MAX, sizeof(*fc), GFP_KERNEL);\n\tif (!fc)\n\t\treturn;\n\n\tph->hops->fastchannel_init(ph, PERF_DESCRIBE_FASTCHANNEL,\n\t\t\t\t   PERF_LEVEL_SET, 4, domain,\n\t\t\t\t   &fc[PERF_FC_LEVEL].set_addr,\n\t\t\t\t   &fc[PERF_FC_LEVEL].set_db);\n\n\tph->hops->fastchannel_init(ph, PERF_DESCRIBE_FASTCHANNEL,\n\t\t\t\t   PERF_LEVEL_GET, 4, domain,\n\t\t\t\t   &fc[PERF_FC_LEVEL].get_addr, NULL);\n\n\tph->hops->fastchannel_init(ph, PERF_DESCRIBE_FASTCHANNEL,\n\t\t\t\t   PERF_LIMITS_SET, 8, domain,\n\t\t\t\t   &fc[PERF_FC_LIMIT].set_addr,\n\t\t\t\t   &fc[PERF_FC_LIMIT].set_db);\n\n\tph->hops->fastchannel_init(ph, PERF_DESCRIBE_FASTCHANNEL,\n\t\t\t\t   PERF_LIMITS_GET, 8, domain,\n\t\t\t\t   &fc[PERF_FC_LIMIT].get_addr, NULL);\n\n\t*p_fc = fc;\n}\n\n \nstatic int scmi_dev_domain_id(struct device *dev)\n{\n\tstruct of_phandle_args clkspec;\n\n\tif (of_parse_phandle_with_args(dev->of_node, \"clocks\", \"#clock-cells\",\n\t\t\t\t       0, &clkspec))\n\t\treturn -EINVAL;\n\n\treturn clkspec.args[0];\n}\n\nstatic int scmi_dvfs_device_opps_add(const struct scmi_protocol_handle *ph,\n\t\t\t\t     struct device *dev)\n{\n\tint idx, ret, domain;\n\tunsigned long freq;\n\tstruct perf_dom_info *dom;\n\n\tdomain = scmi_dev_domain_id(dev);\n\tif (domain < 0)\n\t\treturn -EINVAL;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tfor (idx = 0; idx < dom->opp_count; idx++) {\n\t\tif (!dom->level_indexing_mode)\n\t\t\tfreq = dom->opp[idx].perf * dom->mult_factor;\n\t\telse\n\t\t\tfreq = dom->opp[idx].indicative_freq * dom->mult_factor;\n\n\t\tret = dev_pm_opp_add(dev, freq, 0);\n\t\tif (ret) {\n\t\t\tdev_warn(dev, \"failed to add opp %luHz\\n\", freq);\n\t\t\tdev_pm_opp_remove_all_dynamic(dev);\n\t\t\treturn ret;\n\t\t}\n\n\t\tdev_dbg(dev, \"[%d][%s]:: Registered OPP[%d] %lu\\n\",\n\t\t\tdomain, dom->info.name, idx, freq);\n\t}\n\treturn 0;\n}\n\nstatic int\nscmi_dvfs_transition_latency_get(const struct scmi_protocol_handle *ph,\n\t\t\t\t struct device *dev)\n{\n\tint domain;\n\tstruct perf_dom_info *dom;\n\n\tdomain = scmi_dev_domain_id(dev);\n\tif (domain < 0)\n\t\treturn -EINVAL;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\t \n\treturn dom->opp[dom->opp_count - 1].trans_latency_us * 1000;\n}\n\nstatic int scmi_dvfs_freq_set(const struct scmi_protocol_handle *ph, u32 domain,\n\t\t\t      unsigned long freq, bool poll)\n{\n\tunsigned int level;\n\tstruct perf_dom_info *dom;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tif (!dom->level_indexing_mode) {\n\t\tlevel = freq / dom->mult_factor;\n\t} else {\n\t\tstruct scmi_opp *opp;\n\n\t\topp = LOOKUP_BY_FREQ(dom->opps_by_freq,\n\t\t\t\t     freq / dom->mult_factor);\n\t\tif (!opp)\n\t\t\treturn -EIO;\n\n\t\tlevel = opp->level_index;\n\t}\n\n\treturn __scmi_perf_level_set(ph, dom, level, poll);\n}\n\nstatic int scmi_dvfs_freq_get(const struct scmi_protocol_handle *ph, u32 domain,\n\t\t\t      unsigned long *freq, bool poll)\n{\n\tint ret;\n\tu32 level;\n\tstruct perf_dom_info *dom;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tret = __scmi_perf_level_get(ph, dom, &level, poll);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!dom->level_indexing_mode) {\n\t\t*freq = level * dom->mult_factor;\n\t} else {\n\t\tstruct scmi_opp *opp;\n\n\t\topp = xa_load(&dom->opps_by_idx, level);\n\t\tif (!opp)\n\t\t\treturn -EIO;\n\n\t\t*freq = opp->indicative_freq * dom->mult_factor;\n\t}\n\n\treturn ret;\n}\n\nstatic int scmi_dvfs_est_power_get(const struct scmi_protocol_handle *ph,\n\t\t\t\t   u32 domain, unsigned long *freq,\n\t\t\t\t   unsigned long *power)\n{\n\tstruct perf_dom_info *dom;\n\tunsigned long opp_freq;\n\tint idx, ret = -EINVAL;\n\tstruct scmi_opp *opp;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn PTR_ERR(dom);\n\n\tfor (opp = dom->opp, idx = 0; idx < dom->opp_count; idx++, opp++) {\n\t\tif (!dom->level_indexing_mode)\n\t\t\topp_freq = opp->perf * dom->mult_factor;\n\t\telse\n\t\t\topp_freq = opp->indicative_freq * dom->mult_factor;\n\n\t\tif (opp_freq < *freq)\n\t\t\tcontinue;\n\n\t\t*freq = opp_freq;\n\t\t*power = opp->power;\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic bool scmi_fast_switch_possible(const struct scmi_protocol_handle *ph,\n\t\t\t\t      struct device *dev)\n{\n\tint domain;\n\tstruct perf_dom_info *dom;\n\n\tdomain = scmi_dev_domain_id(dev);\n\tif (domain < 0)\n\t\treturn false;\n\n\tdom = scmi_perf_domain_lookup(ph, domain);\n\tif (IS_ERR(dom))\n\t\treturn false;\n\n\treturn dom->fc_info && dom->fc_info[PERF_FC_LEVEL].set_addr;\n}\n\nstatic enum scmi_power_scale\nscmi_power_scale_get(const struct scmi_protocol_handle *ph)\n{\n\tstruct scmi_perf_info *pi = ph->get_priv(ph);\n\n\treturn pi->power_scale;\n}\n\nstatic const struct scmi_perf_proto_ops perf_proto_ops = {\n\t.num_domains_get = scmi_perf_num_domains_get,\n\t.info_get = scmi_perf_info_get,\n\t.limits_set = scmi_perf_limits_set,\n\t.limits_get = scmi_perf_limits_get,\n\t.level_set = scmi_perf_level_set,\n\t.level_get = scmi_perf_level_get,\n\t.device_domain_id = scmi_dev_domain_id,\n\t.transition_latency_get = scmi_dvfs_transition_latency_get,\n\t.device_opps_add = scmi_dvfs_device_opps_add,\n\t.freq_set = scmi_dvfs_freq_set,\n\t.freq_get = scmi_dvfs_freq_get,\n\t.est_power_get = scmi_dvfs_est_power_get,\n\t.fast_switch_possible = scmi_fast_switch_possible,\n\t.power_scale_get = scmi_power_scale_get,\n};\n\nstatic int scmi_perf_set_notify_enabled(const struct scmi_protocol_handle *ph,\n\t\t\t\t\tu8 evt_id, u32 src_id, bool enable)\n{\n\tint ret, cmd_id;\n\n\tif (evt_id >= ARRAY_SIZE(evt_2_cmd))\n\t\treturn -EINVAL;\n\n\tcmd_id = evt_2_cmd[evt_id];\n\tret = scmi_perf_level_limits_notify(ph, src_id, cmd_id, enable);\n\tif (ret)\n\t\tpr_debug(\"FAIL_ENABLED - evt[%X] dom[%d] - ret:%d\\n\",\n\t\t\t evt_id, src_id, ret);\n\n\treturn ret;\n}\n\nstatic void *scmi_perf_fill_custom_report(const struct scmi_protocol_handle *ph,\n\t\t\t\t\t  u8 evt_id, ktime_t timestamp,\n\t\t\t\t\t  const void *payld, size_t payld_sz,\n\t\t\t\t\t  void *report, u32 *src_id)\n{\n\tvoid *rep = NULL;\n\n\tswitch (evt_id) {\n\tcase SCMI_EVENT_PERFORMANCE_LIMITS_CHANGED:\n\t{\n\t\tconst struct scmi_perf_limits_notify_payld *p = payld;\n\t\tstruct scmi_perf_limits_report *r = report;\n\n\t\tif (sizeof(*p) != payld_sz)\n\t\t\tbreak;\n\n\t\tr->timestamp = timestamp;\n\t\tr->agent_id = le32_to_cpu(p->agent_id);\n\t\tr->domain_id = le32_to_cpu(p->domain_id);\n\t\tr->range_max = le32_to_cpu(p->range_max);\n\t\tr->range_min = le32_to_cpu(p->range_min);\n\t\t*src_id = r->domain_id;\n\t\trep = r;\n\t\tbreak;\n\t}\n\tcase SCMI_EVENT_PERFORMANCE_LEVEL_CHANGED:\n\t{\n\t\tconst struct scmi_perf_level_notify_payld *p = payld;\n\t\tstruct scmi_perf_level_report *r = report;\n\n\t\tif (sizeof(*p) != payld_sz)\n\t\t\tbreak;\n\n\t\tr->timestamp = timestamp;\n\t\tr->agent_id = le32_to_cpu(p->agent_id);\n\t\tr->domain_id = le32_to_cpu(p->domain_id);\n\t\tr->performance_level = le32_to_cpu(p->performance_level);\n\t\t*src_id = r->domain_id;\n\t\trep = r;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn rep;\n}\n\nstatic int scmi_perf_get_num_sources(const struct scmi_protocol_handle *ph)\n{\n\tstruct scmi_perf_info *pi = ph->get_priv(ph);\n\n\tif (!pi)\n\t\treturn -EINVAL;\n\n\treturn pi->num_domains;\n}\n\nstatic const struct scmi_event perf_events[] = {\n\t{\n\t\t.id = SCMI_EVENT_PERFORMANCE_LIMITS_CHANGED,\n\t\t.max_payld_sz = sizeof(struct scmi_perf_limits_notify_payld),\n\t\t.max_report_sz = sizeof(struct scmi_perf_limits_report),\n\t},\n\t{\n\t\t.id = SCMI_EVENT_PERFORMANCE_LEVEL_CHANGED,\n\t\t.max_payld_sz = sizeof(struct scmi_perf_level_notify_payld),\n\t\t.max_report_sz = sizeof(struct scmi_perf_level_report),\n\t},\n};\n\nstatic const struct scmi_event_ops perf_event_ops = {\n\t.get_num_sources = scmi_perf_get_num_sources,\n\t.set_notify_enabled = scmi_perf_set_notify_enabled,\n\t.fill_custom_report = scmi_perf_fill_custom_report,\n};\n\nstatic const struct scmi_protocol_events perf_protocol_events = {\n\t.queue_sz = SCMI_PROTO_QUEUE_SZ,\n\t.ops = &perf_event_ops,\n\t.evts = perf_events,\n\t.num_events = ARRAY_SIZE(perf_events),\n};\n\nstatic int scmi_perf_protocol_init(const struct scmi_protocol_handle *ph)\n{\n\tint domain, ret;\n\tu32 version;\n\tstruct scmi_perf_info *pinfo;\n\n\tret = ph->xops->version_get(ph, &version);\n\tif (ret)\n\t\treturn ret;\n\n\tdev_dbg(ph->dev, \"Performance Version %d.%d\\n\",\n\t\tPROTOCOL_REV_MAJOR(version), PROTOCOL_REV_MINOR(version));\n\n\tpinfo = devm_kzalloc(ph->dev, sizeof(*pinfo), GFP_KERNEL);\n\tif (!pinfo)\n\t\treturn -ENOMEM;\n\n\tpinfo->version = version;\n\n\tret = scmi_perf_attributes_get(ph, pinfo);\n\tif (ret)\n\t\treturn ret;\n\n\tpinfo->dom_info = devm_kcalloc(ph->dev, pinfo->num_domains,\n\t\t\t\t       sizeof(*pinfo->dom_info), GFP_KERNEL);\n\tif (!pinfo->dom_info)\n\t\treturn -ENOMEM;\n\n\tfor (domain = 0; domain < pinfo->num_domains; domain++) {\n\t\tstruct perf_dom_info *dom = pinfo->dom_info + domain;\n\n\t\tdom->id = domain;\n\t\tscmi_perf_domain_attributes_get(ph, dom, version);\n\t\tscmi_perf_describe_levels_get(ph, dom, version);\n\n\t\tif (dom->perf_fastchannels)\n\t\t\tscmi_perf_domain_init_fc(ph, dom->id, &dom->fc_info);\n\t}\n\n\tret = devm_add_action_or_reset(ph->dev, scmi_perf_xa_destroy, pinfo);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ph->set_priv(ph, pinfo);\n}\n\nstatic const struct scmi_protocol scmi_perf = {\n\t.id = SCMI_PROTOCOL_PERF,\n\t.owner = THIS_MODULE,\n\t.instance_init = &scmi_perf_protocol_init,\n\t.ops = &perf_proto_ops,\n\t.events = &perf_protocol_events,\n};\n\nDEFINE_SCMI_PROTOCOL_REGISTER_UNREGISTER(perf, scmi_perf)\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}