{
  "module_name": "core.c",
  "hash_id": "03fce547a8f23e0bb7c284e7166643d2978073c2233faafcd3564edbbb11c88c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/nvmem/core.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/export.h>\n#include <linux/fs.h>\n#include <linux/idr.h>\n#include <linux/init.h>\n#include <linux/kref.h>\n#include <linux/module.h>\n#include <linux/nvmem-consumer.h>\n#include <linux/nvmem-provider.h>\n#include <linux/gpio/consumer.h>\n#include <linux/of.h>\n#include <linux/slab.h>\n\nstruct nvmem_device {\n\tstruct module\t\t*owner;\n\tstruct device\t\tdev;\n\tint\t\t\tstride;\n\tint\t\t\tword_size;\n\tint\t\t\tid;\n\tstruct kref\t\trefcnt;\n\tsize_t\t\t\tsize;\n\tbool\t\t\tread_only;\n\tbool\t\t\troot_only;\n\tint\t\t\tflags;\n\tenum nvmem_type\t\ttype;\n\tstruct bin_attribute\teeprom;\n\tstruct device\t\t*base_dev;\n\tstruct list_head\tcells;\n\tconst struct nvmem_keepout *keepout;\n\tunsigned int\t\tnkeepout;\n\tnvmem_reg_read_t\treg_read;\n\tnvmem_reg_write_t\treg_write;\n\tstruct gpio_desc\t*wp_gpio;\n\tstruct nvmem_layout\t*layout;\n\tvoid *priv;\n};\n\n#define to_nvmem_device(d) container_of(d, struct nvmem_device, dev)\n\n#define FLAG_COMPAT\t\tBIT(0)\nstruct nvmem_cell_entry {\n\tconst char\t\t*name;\n\tint\t\t\toffset;\n\tsize_t\t\t\traw_len;\n\tint\t\t\tbytes;\n\tint\t\t\tbit_offset;\n\tint\t\t\tnbits;\n\tnvmem_cell_post_process_t read_post_process;\n\tvoid\t\t\t*priv;\n\tstruct device_node\t*np;\n\tstruct nvmem_device\t*nvmem;\n\tstruct list_head\tnode;\n};\n\nstruct nvmem_cell {\n\tstruct nvmem_cell_entry *entry;\n\tconst char\t\t*id;\n\tint\t\t\tindex;\n};\n\nstatic DEFINE_MUTEX(nvmem_mutex);\nstatic DEFINE_IDA(nvmem_ida);\n\nstatic DEFINE_MUTEX(nvmem_cell_mutex);\nstatic LIST_HEAD(nvmem_cell_tables);\n\nstatic DEFINE_MUTEX(nvmem_lookup_mutex);\nstatic LIST_HEAD(nvmem_lookup_list);\n\nstatic BLOCKING_NOTIFIER_HEAD(nvmem_notifier);\n\nstatic DEFINE_SPINLOCK(nvmem_layout_lock);\nstatic LIST_HEAD(nvmem_layouts);\n\nstatic int __nvmem_reg_read(struct nvmem_device *nvmem, unsigned int offset,\n\t\t\t    void *val, size_t bytes)\n{\n\tif (nvmem->reg_read)\n\t\treturn nvmem->reg_read(nvmem->priv, offset, val, bytes);\n\n\treturn -EINVAL;\n}\n\nstatic int __nvmem_reg_write(struct nvmem_device *nvmem, unsigned int offset,\n\t\t\t     void *val, size_t bytes)\n{\n\tint ret;\n\n\tif (nvmem->reg_write) {\n\t\tgpiod_set_value_cansleep(nvmem->wp_gpio, 0);\n\t\tret = nvmem->reg_write(nvmem->priv, offset, val, bytes);\n\t\tgpiod_set_value_cansleep(nvmem->wp_gpio, 1);\n\t\treturn ret;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int nvmem_access_with_keepouts(struct nvmem_device *nvmem,\n\t\t\t\t      unsigned int offset, void *val,\n\t\t\t\t      size_t bytes, int write)\n{\n\n\tunsigned int end = offset + bytes;\n\tunsigned int kend, ksize;\n\tconst struct nvmem_keepout *keepout = nvmem->keepout;\n\tconst struct nvmem_keepout *keepoutend = keepout + nvmem->nkeepout;\n\tint rc;\n\n\t \n\twhile ((keepout < keepoutend) && (keepout->end <= offset))\n\t\tkeepout++;\n\n\twhile ((offset < end) && (keepout < keepoutend)) {\n\t\t \n\t\tif (offset < keepout->start) {\n\t\t\tkend = min(end, keepout->start);\n\t\t\tksize = kend - offset;\n\t\t\tif (write)\n\t\t\t\trc = __nvmem_reg_write(nvmem, offset, val, ksize);\n\t\t\telse\n\t\t\t\trc = __nvmem_reg_read(nvmem, offset, val, ksize);\n\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\n\t\t\toffset += ksize;\n\t\t\tval += ksize;\n\t\t}\n\n\t\t \n\t\tkend = min(end, keepout->end);\n\t\tksize = kend - offset;\n\t\tif (!write)\n\t\t\tmemset(val, keepout->value, ksize);\n\n\t\tval += ksize;\n\t\toffset += ksize;\n\t\tkeepout++;\n\t}\n\n\t \n\tif (offset < end) {\n\t\tksize = end - offset;\n\t\tif (write)\n\t\t\treturn __nvmem_reg_write(nvmem, offset, val, ksize);\n\t\telse\n\t\t\treturn __nvmem_reg_read(nvmem, offset, val, ksize);\n\t}\n\n\treturn 0;\n}\n\nstatic int nvmem_reg_read(struct nvmem_device *nvmem, unsigned int offset,\n\t\t\t  void *val, size_t bytes)\n{\n\tif (!nvmem->nkeepout)\n\t\treturn __nvmem_reg_read(nvmem, offset, val, bytes);\n\n\treturn nvmem_access_with_keepouts(nvmem, offset, val, bytes, false);\n}\n\nstatic int nvmem_reg_write(struct nvmem_device *nvmem, unsigned int offset,\n\t\t\t   void *val, size_t bytes)\n{\n\tif (!nvmem->nkeepout)\n\t\treturn __nvmem_reg_write(nvmem, offset, val, bytes);\n\n\treturn nvmem_access_with_keepouts(nvmem, offset, val, bytes, true);\n}\n\n#ifdef CONFIG_NVMEM_SYSFS\nstatic const char * const nvmem_type_str[] = {\n\t[NVMEM_TYPE_UNKNOWN] = \"Unknown\",\n\t[NVMEM_TYPE_EEPROM] = \"EEPROM\",\n\t[NVMEM_TYPE_OTP] = \"OTP\",\n\t[NVMEM_TYPE_BATTERY_BACKED] = \"Battery backed\",\n\t[NVMEM_TYPE_FRAM] = \"FRAM\",\n};\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nstatic struct lock_class_key eeprom_lock_key;\n#endif\n\nstatic ssize_t type_show(struct device *dev,\n\t\t\t struct device_attribute *attr, char *buf)\n{\n\tstruct nvmem_device *nvmem = to_nvmem_device(dev);\n\n\treturn sprintf(buf, \"%s\\n\", nvmem_type_str[nvmem->type]);\n}\n\nstatic DEVICE_ATTR_RO(type);\n\nstatic struct attribute *nvmem_attrs[] = {\n\t&dev_attr_type.attr,\n\tNULL,\n};\n\nstatic ssize_t bin_attr_nvmem_read(struct file *filp, struct kobject *kobj,\n\t\t\t\t   struct bin_attribute *attr, char *buf,\n\t\t\t\t   loff_t pos, size_t count)\n{\n\tstruct device *dev;\n\tstruct nvmem_device *nvmem;\n\tint rc;\n\n\tif (attr->private)\n\t\tdev = attr->private;\n\telse\n\t\tdev = kobj_to_dev(kobj);\n\tnvmem = to_nvmem_device(dev);\n\n\t \n\tif (pos >= nvmem->size)\n\t\treturn 0;\n\n\tif (!IS_ALIGNED(pos, nvmem->stride))\n\t\treturn -EINVAL;\n\n\tif (count < nvmem->word_size)\n\t\treturn -EINVAL;\n\n\tif (pos + count > nvmem->size)\n\t\tcount = nvmem->size - pos;\n\n\tcount = round_down(count, nvmem->word_size);\n\n\tif (!nvmem->reg_read)\n\t\treturn -EPERM;\n\n\trc = nvmem_reg_read(nvmem, pos, buf, count);\n\n\tif (rc)\n\t\treturn rc;\n\n\treturn count;\n}\n\nstatic ssize_t bin_attr_nvmem_write(struct file *filp, struct kobject *kobj,\n\t\t\t\t    struct bin_attribute *attr, char *buf,\n\t\t\t\t    loff_t pos, size_t count)\n{\n\tstruct device *dev;\n\tstruct nvmem_device *nvmem;\n\tint rc;\n\n\tif (attr->private)\n\t\tdev = attr->private;\n\telse\n\t\tdev = kobj_to_dev(kobj);\n\tnvmem = to_nvmem_device(dev);\n\n\t \n\tif (pos >= nvmem->size)\n\t\treturn -EFBIG;\n\n\tif (!IS_ALIGNED(pos, nvmem->stride))\n\t\treturn -EINVAL;\n\n\tif (count < nvmem->word_size)\n\t\treturn -EINVAL;\n\n\tif (pos + count > nvmem->size)\n\t\tcount = nvmem->size - pos;\n\n\tcount = round_down(count, nvmem->word_size);\n\n\tif (!nvmem->reg_write)\n\t\treturn -EPERM;\n\n\trc = nvmem_reg_write(nvmem, pos, buf, count);\n\n\tif (rc)\n\t\treturn rc;\n\n\treturn count;\n}\n\nstatic umode_t nvmem_bin_attr_get_umode(struct nvmem_device *nvmem)\n{\n\tumode_t mode = 0400;\n\n\tif (!nvmem->root_only)\n\t\tmode |= 0044;\n\n\tif (!nvmem->read_only)\n\t\tmode |= 0200;\n\n\tif (!nvmem->reg_write)\n\t\tmode &= ~0200;\n\n\tif (!nvmem->reg_read)\n\t\tmode &= ~0444;\n\n\treturn mode;\n}\n\nstatic umode_t nvmem_bin_attr_is_visible(struct kobject *kobj,\n\t\t\t\t\t struct bin_attribute *attr, int i)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct nvmem_device *nvmem = to_nvmem_device(dev);\n\n\tattr->size = nvmem->size;\n\n\treturn nvmem_bin_attr_get_umode(nvmem);\n}\n\n \nstatic struct bin_attribute bin_attr_rw_nvmem = {\n\t.attr\t= {\n\t\t.name\t= \"nvmem\",\n\t\t.mode\t= 0644,\n\t},\n\t.read\t= bin_attr_nvmem_read,\n\t.write\t= bin_attr_nvmem_write,\n};\n\nstatic struct bin_attribute *nvmem_bin_attributes[] = {\n\t&bin_attr_rw_nvmem,\n\tNULL,\n};\n\nstatic const struct attribute_group nvmem_bin_group = {\n\t.bin_attrs\t= nvmem_bin_attributes,\n\t.attrs\t\t= nvmem_attrs,\n\t.is_bin_visible = nvmem_bin_attr_is_visible,\n};\n\nstatic const struct attribute_group *nvmem_dev_groups[] = {\n\t&nvmem_bin_group,\n\tNULL,\n};\n\nstatic struct bin_attribute bin_attr_nvmem_eeprom_compat = {\n\t.attr\t= {\n\t\t.name\t= \"eeprom\",\n\t},\n\t.read\t= bin_attr_nvmem_read,\n\t.write\t= bin_attr_nvmem_write,\n};\n\n \nstatic int nvmem_sysfs_setup_compat(struct nvmem_device *nvmem,\n\t\t\t\t    const struct nvmem_config *config)\n{\n\tint rval;\n\n\tif (!config->compat)\n\t\treturn 0;\n\n\tif (!config->base_dev)\n\t\treturn -EINVAL;\n\n\tif (config->type == NVMEM_TYPE_FRAM)\n\t\tbin_attr_nvmem_eeprom_compat.attr.name = \"fram\";\n\n\tnvmem->eeprom = bin_attr_nvmem_eeprom_compat;\n\tnvmem->eeprom.attr.mode = nvmem_bin_attr_get_umode(nvmem);\n\tnvmem->eeprom.size = nvmem->size;\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tnvmem->eeprom.attr.key = &eeprom_lock_key;\n#endif\n\tnvmem->eeprom.private = &nvmem->dev;\n\tnvmem->base_dev = config->base_dev;\n\n\trval = device_create_bin_file(nvmem->base_dev, &nvmem->eeprom);\n\tif (rval) {\n\t\tdev_err(&nvmem->dev,\n\t\t\t\"Failed to create eeprom binary file %d\\n\", rval);\n\t\treturn rval;\n\t}\n\n\tnvmem->flags |= FLAG_COMPAT;\n\n\treturn 0;\n}\n\nstatic void nvmem_sysfs_remove_compat(struct nvmem_device *nvmem,\n\t\t\t      const struct nvmem_config *config)\n{\n\tif (config->compat)\n\t\tdevice_remove_bin_file(nvmem->base_dev, &nvmem->eeprom);\n}\n\n#else  \n\nstatic int nvmem_sysfs_setup_compat(struct nvmem_device *nvmem,\n\t\t\t\t    const struct nvmem_config *config)\n{\n\treturn -ENOSYS;\n}\nstatic void nvmem_sysfs_remove_compat(struct nvmem_device *nvmem,\n\t\t\t\t      const struct nvmem_config *config)\n{\n}\n\n#endif  \n\nstatic void nvmem_release(struct device *dev)\n{\n\tstruct nvmem_device *nvmem = to_nvmem_device(dev);\n\n\tida_free(&nvmem_ida, nvmem->id);\n\tgpiod_put(nvmem->wp_gpio);\n\tkfree(nvmem);\n}\n\nstatic const struct device_type nvmem_provider_type = {\n\t.release\t= nvmem_release,\n};\n\nstatic struct bus_type nvmem_bus_type = {\n\t.name\t\t= \"nvmem\",\n};\n\nstatic void nvmem_cell_entry_drop(struct nvmem_cell_entry *cell)\n{\n\tblocking_notifier_call_chain(&nvmem_notifier, NVMEM_CELL_REMOVE, cell);\n\tmutex_lock(&nvmem_mutex);\n\tlist_del(&cell->node);\n\tmutex_unlock(&nvmem_mutex);\n\tof_node_put(cell->np);\n\tkfree_const(cell->name);\n\tkfree(cell);\n}\n\nstatic void nvmem_device_remove_all_cells(const struct nvmem_device *nvmem)\n{\n\tstruct nvmem_cell_entry *cell, *p;\n\n\tlist_for_each_entry_safe(cell, p, &nvmem->cells, node)\n\t\tnvmem_cell_entry_drop(cell);\n}\n\nstatic void nvmem_cell_entry_add(struct nvmem_cell_entry *cell)\n{\n\tmutex_lock(&nvmem_mutex);\n\tlist_add_tail(&cell->node, &cell->nvmem->cells);\n\tmutex_unlock(&nvmem_mutex);\n\tblocking_notifier_call_chain(&nvmem_notifier, NVMEM_CELL_ADD, cell);\n}\n\nstatic int nvmem_cell_info_to_nvmem_cell_entry_nodup(struct nvmem_device *nvmem,\n\t\t\t\t\t\t     const struct nvmem_cell_info *info,\n\t\t\t\t\t\t     struct nvmem_cell_entry *cell)\n{\n\tcell->nvmem = nvmem;\n\tcell->offset = info->offset;\n\tcell->raw_len = info->raw_len ?: info->bytes;\n\tcell->bytes = info->bytes;\n\tcell->name = info->name;\n\tcell->read_post_process = info->read_post_process;\n\tcell->priv = info->priv;\n\n\tcell->bit_offset = info->bit_offset;\n\tcell->nbits = info->nbits;\n\tcell->np = info->np;\n\n\tif (cell->nbits)\n\t\tcell->bytes = DIV_ROUND_UP(cell->nbits + cell->bit_offset,\n\t\t\t\t\t   BITS_PER_BYTE);\n\n\tif (!IS_ALIGNED(cell->offset, nvmem->stride)) {\n\t\tdev_err(&nvmem->dev,\n\t\t\t\"cell %s unaligned to nvmem stride %d\\n\",\n\t\t\tcell->name ?: \"<unknown>\", nvmem->stride);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int nvmem_cell_info_to_nvmem_cell_entry(struct nvmem_device *nvmem,\n\t\t\t\t\t       const struct nvmem_cell_info *info,\n\t\t\t\t\t       struct nvmem_cell_entry *cell)\n{\n\tint err;\n\n\terr = nvmem_cell_info_to_nvmem_cell_entry_nodup(nvmem, info, cell);\n\tif (err)\n\t\treturn err;\n\n\tcell->name = kstrdup_const(info->name, GFP_KERNEL);\n\tif (!cell->name)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\n \nint nvmem_add_one_cell(struct nvmem_device *nvmem,\n\t\t       const struct nvmem_cell_info *info)\n{\n\tstruct nvmem_cell_entry *cell;\n\tint rval;\n\n\tcell = kzalloc(sizeof(*cell), GFP_KERNEL);\n\tif (!cell)\n\t\treturn -ENOMEM;\n\n\trval = nvmem_cell_info_to_nvmem_cell_entry(nvmem, info, cell);\n\tif (rval) {\n\t\tkfree(cell);\n\t\treturn rval;\n\t}\n\n\tnvmem_cell_entry_add(cell);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nvmem_add_one_cell);\n\n \nstatic int nvmem_add_cells(struct nvmem_device *nvmem,\n\t\t    const struct nvmem_cell_info *info,\n\t\t    int ncells)\n{\n\tint i, rval;\n\n\tfor (i = 0; i < ncells; i++) {\n\t\trval = nvmem_add_one_cell(nvmem, &info[i]);\n\t\tif (rval)\n\t\t\treturn rval;\n\t}\n\n\treturn 0;\n}\n\n \nint nvmem_register_notifier(struct notifier_block *nb)\n{\n\treturn blocking_notifier_chain_register(&nvmem_notifier, nb);\n}\nEXPORT_SYMBOL_GPL(nvmem_register_notifier);\n\n \nint nvmem_unregister_notifier(struct notifier_block *nb)\n{\n\treturn blocking_notifier_chain_unregister(&nvmem_notifier, nb);\n}\nEXPORT_SYMBOL_GPL(nvmem_unregister_notifier);\n\nstatic int nvmem_add_cells_from_table(struct nvmem_device *nvmem)\n{\n\tconst struct nvmem_cell_info *info;\n\tstruct nvmem_cell_table *table;\n\tstruct nvmem_cell_entry *cell;\n\tint rval = 0, i;\n\n\tmutex_lock(&nvmem_cell_mutex);\n\tlist_for_each_entry(table, &nvmem_cell_tables, node) {\n\t\tif (strcmp(nvmem_dev_name(nvmem), table->nvmem_name) == 0) {\n\t\t\tfor (i = 0; i < table->ncells; i++) {\n\t\t\t\tinfo = &table->cells[i];\n\n\t\t\t\tcell = kzalloc(sizeof(*cell), GFP_KERNEL);\n\t\t\t\tif (!cell) {\n\t\t\t\t\trval = -ENOMEM;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\trval = nvmem_cell_info_to_nvmem_cell_entry(nvmem, info, cell);\n\t\t\t\tif (rval) {\n\t\t\t\t\tkfree(cell);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tnvmem_cell_entry_add(cell);\n\t\t\t}\n\t\t}\n\t}\n\nout:\n\tmutex_unlock(&nvmem_cell_mutex);\n\treturn rval;\n}\n\nstatic struct nvmem_cell_entry *\nnvmem_find_cell_entry_by_name(struct nvmem_device *nvmem, const char *cell_id)\n{\n\tstruct nvmem_cell_entry *iter, *cell = NULL;\n\n\tmutex_lock(&nvmem_mutex);\n\tlist_for_each_entry(iter, &nvmem->cells, node) {\n\t\tif (strcmp(cell_id, iter->name) == 0) {\n\t\t\tcell = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&nvmem_mutex);\n\n\treturn cell;\n}\n\nstatic int nvmem_validate_keepouts(struct nvmem_device *nvmem)\n{\n\tunsigned int cur = 0;\n\tconst struct nvmem_keepout *keepout = nvmem->keepout;\n\tconst struct nvmem_keepout *keepoutend = keepout + nvmem->nkeepout;\n\n\twhile (keepout < keepoutend) {\n\t\t \n\t\tif (keepout->start < cur) {\n\t\t\tdev_err(&nvmem->dev,\n\t\t\t\t\"Keepout regions aren't sorted or overlap.\\n\");\n\n\t\t\treturn -ERANGE;\n\t\t}\n\n\t\tif (keepout->end < keepout->start) {\n\t\t\tdev_err(&nvmem->dev,\n\t\t\t\t\"Invalid keepout region.\\n\");\n\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif ((keepout->end - keepout->start < nvmem->word_size) ||\n\t\t    ((keepout->start != cur) &&\n\t\t     (keepout->start - cur < nvmem->word_size))) {\n\n\t\t\tdev_err(&nvmem->dev,\n\t\t\t\t\"Keepout regions violate word_size constraints.\\n\");\n\n\t\t\treturn -ERANGE;\n\t\t}\n\n\t\t \n\t\tif (!IS_ALIGNED(keepout->start, nvmem->stride) ||\n\t\t    !IS_ALIGNED(keepout->end, nvmem->stride)) {\n\n\t\t\tdev_err(&nvmem->dev,\n\t\t\t\t\"Keepout regions violate stride.\\n\");\n\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tcur = keepout->end;\n\t\tkeepout++;\n\t}\n\n\treturn 0;\n}\n\nstatic int nvmem_add_cells_from_dt(struct nvmem_device *nvmem, struct device_node *np)\n{\n\tstruct nvmem_layout *layout = nvmem->layout;\n\tstruct device *dev = &nvmem->dev;\n\tstruct device_node *child;\n\tconst __be32 *addr;\n\tint len, ret;\n\n\tfor_each_child_of_node(np, child) {\n\t\tstruct nvmem_cell_info info = {0};\n\n\t\taddr = of_get_property(child, \"reg\", &len);\n\t\tif (!addr)\n\t\t\tcontinue;\n\t\tif (len < 2 * sizeof(u32)) {\n\t\t\tdev_err(dev, \"nvmem: invalid reg on %pOF\\n\", child);\n\t\t\tof_node_put(child);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tinfo.offset = be32_to_cpup(addr++);\n\t\tinfo.bytes = be32_to_cpup(addr);\n\t\tinfo.name = kasprintf(GFP_KERNEL, \"%pOFn\", child);\n\n\t\taddr = of_get_property(child, \"bits\", &len);\n\t\tif (addr && len == (2 * sizeof(u32))) {\n\t\t\tinfo.bit_offset = be32_to_cpup(addr++);\n\t\t\tinfo.nbits = be32_to_cpup(addr);\n\t\t}\n\n\t\tinfo.np = of_node_get(child);\n\n\t\tif (layout && layout->fixup_cell_info)\n\t\t\tlayout->fixup_cell_info(nvmem, layout, &info);\n\n\t\tret = nvmem_add_one_cell(nvmem, &info);\n\t\tkfree(info.name);\n\t\tif (ret) {\n\t\t\tof_node_put(child);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int nvmem_add_cells_from_legacy_of(struct nvmem_device *nvmem)\n{\n\treturn nvmem_add_cells_from_dt(nvmem, nvmem->dev.of_node);\n}\n\nstatic int nvmem_add_cells_from_fixed_layout(struct nvmem_device *nvmem)\n{\n\tstruct device_node *layout_np;\n\tint err = 0;\n\n\tlayout_np = of_nvmem_layout_get_container(nvmem);\n\tif (!layout_np)\n\t\treturn 0;\n\n\tif (of_device_is_compatible(layout_np, \"fixed-layout\"))\n\t\terr = nvmem_add_cells_from_dt(nvmem, layout_np);\n\n\tof_node_put(layout_np);\n\n\treturn err;\n}\n\nint __nvmem_layout_register(struct nvmem_layout *layout, struct module *owner)\n{\n\tlayout->owner = owner;\n\n\tspin_lock(&nvmem_layout_lock);\n\tlist_add(&layout->node, &nvmem_layouts);\n\tspin_unlock(&nvmem_layout_lock);\n\n\tblocking_notifier_call_chain(&nvmem_notifier, NVMEM_LAYOUT_ADD, layout);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__nvmem_layout_register);\n\nvoid nvmem_layout_unregister(struct nvmem_layout *layout)\n{\n\tblocking_notifier_call_chain(&nvmem_notifier, NVMEM_LAYOUT_REMOVE, layout);\n\n\tspin_lock(&nvmem_layout_lock);\n\tlist_del(&layout->node);\n\tspin_unlock(&nvmem_layout_lock);\n}\nEXPORT_SYMBOL_GPL(nvmem_layout_unregister);\n\nstatic struct nvmem_layout *nvmem_layout_get(struct nvmem_device *nvmem)\n{\n\tstruct device_node *layout_np;\n\tstruct nvmem_layout *l, *layout = ERR_PTR(-EPROBE_DEFER);\n\n\tlayout_np = of_nvmem_layout_get_container(nvmem);\n\tif (!layout_np)\n\t\treturn NULL;\n\n\t \n\tif (of_device_is_compatible(layout_np, \"fixed-layout\")) {\n\t\tof_node_put(layout_np);\n\t\treturn NULL;\n\t}\n\n\t \n\tof_request_module(layout_np);\n\n\tspin_lock(&nvmem_layout_lock);\n\n\tlist_for_each_entry(l, &nvmem_layouts, node) {\n\t\tif (of_match_node(l->of_match_table, layout_np)) {\n\t\t\tif (try_module_get(l->owner))\n\t\t\t\tlayout = l;\n\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tspin_unlock(&nvmem_layout_lock);\n\tof_node_put(layout_np);\n\n\treturn layout;\n}\n\nstatic void nvmem_layout_put(struct nvmem_layout *layout)\n{\n\tif (layout)\n\t\tmodule_put(layout->owner);\n}\n\nstatic int nvmem_add_cells_from_layout(struct nvmem_device *nvmem)\n{\n\tstruct nvmem_layout *layout = nvmem->layout;\n\tint ret;\n\n\tif (layout && layout->add_cells) {\n\t\tret = layout->add_cells(&nvmem->dev, nvmem, layout);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n#if IS_ENABLED(CONFIG_OF)\n \nstruct device_node *of_nvmem_layout_get_container(struct nvmem_device *nvmem)\n{\n\treturn of_get_child_by_name(nvmem->dev.of_node, \"nvmem-layout\");\n}\nEXPORT_SYMBOL_GPL(of_nvmem_layout_get_container);\n#endif\n\nconst void *nvmem_layout_get_match_data(struct nvmem_device *nvmem,\n\t\t\t\t\tstruct nvmem_layout *layout)\n{\n\tstruct device_node __maybe_unused *layout_np;\n\tconst struct of_device_id *match;\n\n\tlayout_np = of_nvmem_layout_get_container(nvmem);\n\tmatch = of_match_node(layout->of_match_table, layout_np);\n\n\treturn match ? match->data : NULL;\n}\nEXPORT_SYMBOL_GPL(nvmem_layout_get_match_data);\n\n \n\nstruct nvmem_device *nvmem_register(const struct nvmem_config *config)\n{\n\tstruct nvmem_device *nvmem;\n\tint rval;\n\n\tif (!config->dev)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (!config->reg_read && !config->reg_write)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tnvmem = kzalloc(sizeof(*nvmem), GFP_KERNEL);\n\tif (!nvmem)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trval = ida_alloc(&nvmem_ida, GFP_KERNEL);\n\tif (rval < 0) {\n\t\tkfree(nvmem);\n\t\treturn ERR_PTR(rval);\n\t}\n\n\tnvmem->id = rval;\n\n\tnvmem->dev.type = &nvmem_provider_type;\n\tnvmem->dev.bus = &nvmem_bus_type;\n\tnvmem->dev.parent = config->dev;\n\n\tdevice_initialize(&nvmem->dev);\n\n\tif (!config->ignore_wp)\n\t\tnvmem->wp_gpio = gpiod_get_optional(config->dev, \"wp\",\n\t\t\t\t\t\t    GPIOD_OUT_HIGH);\n\tif (IS_ERR(nvmem->wp_gpio)) {\n\t\trval = PTR_ERR(nvmem->wp_gpio);\n\t\tnvmem->wp_gpio = NULL;\n\t\tgoto err_put_device;\n\t}\n\n\tkref_init(&nvmem->refcnt);\n\tINIT_LIST_HEAD(&nvmem->cells);\n\n\tnvmem->owner = config->owner;\n\tif (!nvmem->owner && config->dev->driver)\n\t\tnvmem->owner = config->dev->driver->owner;\n\tnvmem->stride = config->stride ?: 1;\n\tnvmem->word_size = config->word_size ?: 1;\n\tnvmem->size = config->size;\n\tnvmem->root_only = config->root_only;\n\tnvmem->priv = config->priv;\n\tnvmem->type = config->type;\n\tnvmem->reg_read = config->reg_read;\n\tnvmem->reg_write = config->reg_write;\n\tnvmem->keepout = config->keepout;\n\tnvmem->nkeepout = config->nkeepout;\n\tif (config->of_node)\n\t\tnvmem->dev.of_node = config->of_node;\n\telse if (!config->no_of_node)\n\t\tnvmem->dev.of_node = config->dev->of_node;\n\n\tswitch (config->id) {\n\tcase NVMEM_DEVID_NONE:\n\t\trval = dev_set_name(&nvmem->dev, \"%s\", config->name);\n\t\tbreak;\n\tcase NVMEM_DEVID_AUTO:\n\t\trval = dev_set_name(&nvmem->dev, \"%s%d\", config->name, nvmem->id);\n\t\tbreak;\n\tdefault:\n\t\trval = dev_set_name(&nvmem->dev, \"%s%d\",\n\t\t\t     config->name ? : \"nvmem\",\n\t\t\t     config->name ? config->id : nvmem->id);\n\t\tbreak;\n\t}\n\n\tif (rval)\n\t\tgoto err_put_device;\n\n\tnvmem->read_only = device_property_present(config->dev, \"read-only\") ||\n\t\t\t   config->read_only || !nvmem->reg_write;\n\n#ifdef CONFIG_NVMEM_SYSFS\n\tnvmem->dev.groups = nvmem_dev_groups;\n#endif\n\n\tif (nvmem->nkeepout) {\n\t\trval = nvmem_validate_keepouts(nvmem);\n\t\tif (rval)\n\t\t\tgoto err_put_device;\n\t}\n\n\tif (config->compat) {\n\t\trval = nvmem_sysfs_setup_compat(nvmem, config);\n\t\tif (rval)\n\t\t\tgoto err_put_device;\n\t}\n\n\t \n\tnvmem->layout = config->layout ?: nvmem_layout_get(nvmem);\n\tif (IS_ERR(nvmem->layout)) {\n\t\trval = PTR_ERR(nvmem->layout);\n\t\tnvmem->layout = NULL;\n\n\t\tif (rval == -EPROBE_DEFER)\n\t\t\tgoto err_teardown_compat;\n\t}\n\n\tif (config->cells) {\n\t\trval = nvmem_add_cells(nvmem, config->cells, config->ncells);\n\t\tif (rval)\n\t\t\tgoto err_remove_cells;\n\t}\n\n\trval = nvmem_add_cells_from_table(nvmem);\n\tif (rval)\n\t\tgoto err_remove_cells;\n\n\trval = nvmem_add_cells_from_legacy_of(nvmem);\n\tif (rval)\n\t\tgoto err_remove_cells;\n\n\trval = nvmem_add_cells_from_fixed_layout(nvmem);\n\tif (rval)\n\t\tgoto err_remove_cells;\n\n\trval = nvmem_add_cells_from_layout(nvmem);\n\tif (rval)\n\t\tgoto err_remove_cells;\n\n\tdev_dbg(&nvmem->dev, \"Registering nvmem device %s\\n\", config->name);\n\n\trval = device_add(&nvmem->dev);\n\tif (rval)\n\t\tgoto err_remove_cells;\n\n\tblocking_notifier_call_chain(&nvmem_notifier, NVMEM_ADD, nvmem);\n\n\treturn nvmem;\n\nerr_remove_cells:\n\tnvmem_device_remove_all_cells(nvmem);\n\tnvmem_layout_put(nvmem->layout);\nerr_teardown_compat:\n\tif (config->compat)\n\t\tnvmem_sysfs_remove_compat(nvmem, config);\nerr_put_device:\n\tput_device(&nvmem->dev);\n\n\treturn ERR_PTR(rval);\n}\nEXPORT_SYMBOL_GPL(nvmem_register);\n\nstatic void nvmem_device_release(struct kref *kref)\n{\n\tstruct nvmem_device *nvmem;\n\n\tnvmem = container_of(kref, struct nvmem_device, refcnt);\n\n\tblocking_notifier_call_chain(&nvmem_notifier, NVMEM_REMOVE, nvmem);\n\n\tif (nvmem->flags & FLAG_COMPAT)\n\t\tdevice_remove_bin_file(nvmem->base_dev, &nvmem->eeprom);\n\n\tnvmem_device_remove_all_cells(nvmem);\n\tnvmem_layout_put(nvmem->layout);\n\tdevice_unregister(&nvmem->dev);\n}\n\n \nvoid nvmem_unregister(struct nvmem_device *nvmem)\n{\n\tif (nvmem)\n\t\tkref_put(&nvmem->refcnt, nvmem_device_release);\n}\nEXPORT_SYMBOL_GPL(nvmem_unregister);\n\nstatic void devm_nvmem_unregister(void *nvmem)\n{\n\tnvmem_unregister(nvmem);\n}\n\n \nstruct nvmem_device *devm_nvmem_register(struct device *dev,\n\t\t\t\t\t const struct nvmem_config *config)\n{\n\tstruct nvmem_device *nvmem;\n\tint ret;\n\n\tnvmem = nvmem_register(config);\n\tif (IS_ERR(nvmem))\n\t\treturn nvmem;\n\n\tret = devm_add_action_or_reset(dev, devm_nvmem_unregister, nvmem);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\treturn nvmem;\n}\nEXPORT_SYMBOL_GPL(devm_nvmem_register);\n\nstatic struct nvmem_device *__nvmem_device_get(void *data,\n\t\t\tint (*match)(struct device *dev, const void *data))\n{\n\tstruct nvmem_device *nvmem = NULL;\n\tstruct device *dev;\n\n\tmutex_lock(&nvmem_mutex);\n\tdev = bus_find_device(&nvmem_bus_type, NULL, data, match);\n\tif (dev)\n\t\tnvmem = to_nvmem_device(dev);\n\tmutex_unlock(&nvmem_mutex);\n\tif (!nvmem)\n\t\treturn ERR_PTR(-EPROBE_DEFER);\n\n\tif (!try_module_get(nvmem->owner)) {\n\t\tdev_err(&nvmem->dev,\n\t\t\t\"could not increase module refcount for cell %s\\n\",\n\t\t\tnvmem_dev_name(nvmem));\n\n\t\tput_device(&nvmem->dev);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tkref_get(&nvmem->refcnt);\n\n\treturn nvmem;\n}\n\nstatic void __nvmem_device_put(struct nvmem_device *nvmem)\n{\n\tput_device(&nvmem->dev);\n\tmodule_put(nvmem->owner);\n\tkref_put(&nvmem->refcnt, nvmem_device_release);\n}\n\n#if IS_ENABLED(CONFIG_OF)\n \nstruct nvmem_device *of_nvmem_device_get(struct device_node *np, const char *id)\n{\n\n\tstruct device_node *nvmem_np;\n\tstruct nvmem_device *nvmem;\n\tint index = 0;\n\n\tif (id)\n\t\tindex = of_property_match_string(np, \"nvmem-names\", id);\n\n\tnvmem_np = of_parse_phandle(np, \"nvmem\", index);\n\tif (!nvmem_np)\n\t\treturn ERR_PTR(-ENOENT);\n\n\tnvmem = __nvmem_device_get(nvmem_np, device_match_of_node);\n\tof_node_put(nvmem_np);\n\treturn nvmem;\n}\nEXPORT_SYMBOL_GPL(of_nvmem_device_get);\n#endif\n\n \nstruct nvmem_device *nvmem_device_get(struct device *dev, const char *dev_name)\n{\n\tif (dev->of_node) {  \n\t\tstruct nvmem_device *nvmem;\n\n\t\tnvmem = of_nvmem_device_get(dev->of_node, dev_name);\n\n\t\tif (!IS_ERR(nvmem) || PTR_ERR(nvmem) == -EPROBE_DEFER)\n\t\t\treturn nvmem;\n\n\t}\n\n\treturn __nvmem_device_get((void *)dev_name, device_match_name);\n}\nEXPORT_SYMBOL_GPL(nvmem_device_get);\n\n \nstruct nvmem_device *nvmem_device_find(void *data,\n\t\t\tint (*match)(struct device *dev, const void *data))\n{\n\treturn __nvmem_device_get(data, match);\n}\nEXPORT_SYMBOL_GPL(nvmem_device_find);\n\nstatic int devm_nvmem_device_match(struct device *dev, void *res, void *data)\n{\n\tstruct nvmem_device **nvmem = res;\n\n\tif (WARN_ON(!nvmem || !*nvmem))\n\t\treturn 0;\n\n\treturn *nvmem == data;\n}\n\nstatic void devm_nvmem_device_release(struct device *dev, void *res)\n{\n\tnvmem_device_put(*(struct nvmem_device **)res);\n}\n\n \nvoid devm_nvmem_device_put(struct device *dev, struct nvmem_device *nvmem)\n{\n\tint ret;\n\n\tret = devres_release(dev, devm_nvmem_device_release,\n\t\t\t     devm_nvmem_device_match, nvmem);\n\n\tWARN_ON(ret);\n}\nEXPORT_SYMBOL_GPL(devm_nvmem_device_put);\n\n \nvoid nvmem_device_put(struct nvmem_device *nvmem)\n{\n\t__nvmem_device_put(nvmem);\n}\nEXPORT_SYMBOL_GPL(nvmem_device_put);\n\n \nstruct nvmem_device *devm_nvmem_device_get(struct device *dev, const char *id)\n{\n\tstruct nvmem_device **ptr, *nvmem;\n\n\tptr = devres_alloc(devm_nvmem_device_release, sizeof(*ptr), GFP_KERNEL);\n\tif (!ptr)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tnvmem = nvmem_device_get(dev, id);\n\tif (!IS_ERR(nvmem)) {\n\t\t*ptr = nvmem;\n\t\tdevres_add(dev, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn nvmem;\n}\nEXPORT_SYMBOL_GPL(devm_nvmem_device_get);\n\nstatic struct nvmem_cell *nvmem_create_cell(struct nvmem_cell_entry *entry,\n\t\t\t\t\t    const char *id, int index)\n{\n\tstruct nvmem_cell *cell;\n\tconst char *name = NULL;\n\n\tcell = kzalloc(sizeof(*cell), GFP_KERNEL);\n\tif (!cell)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (id) {\n\t\tname = kstrdup_const(id, GFP_KERNEL);\n\t\tif (!name) {\n\t\t\tkfree(cell);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t}\n\n\tcell->id = name;\n\tcell->entry = entry;\n\tcell->index = index;\n\n\treturn cell;\n}\n\nstatic struct nvmem_cell *\nnvmem_cell_get_from_lookup(struct device *dev, const char *con_id)\n{\n\tstruct nvmem_cell_entry *cell_entry;\n\tstruct nvmem_cell *cell = ERR_PTR(-ENOENT);\n\tstruct nvmem_cell_lookup *lookup;\n\tstruct nvmem_device *nvmem;\n\tconst char *dev_id;\n\n\tif (!dev)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tdev_id = dev_name(dev);\n\n\tmutex_lock(&nvmem_lookup_mutex);\n\n\tlist_for_each_entry(lookup, &nvmem_lookup_list, node) {\n\t\tif ((strcmp(lookup->dev_id, dev_id) == 0) &&\n\t\t    (strcmp(lookup->con_id, con_id) == 0)) {\n\t\t\t \n\t\t\tnvmem = __nvmem_device_get((void *)lookup->nvmem_name,\n\t\t\t\t\t\t   device_match_name);\n\t\t\tif (IS_ERR(nvmem)) {\n\t\t\t\t \n\t\t\t\tcell = ERR_CAST(nvmem);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tcell_entry = nvmem_find_cell_entry_by_name(nvmem,\n\t\t\t\t\t\t\t\t   lookup->cell_name);\n\t\t\tif (!cell_entry) {\n\t\t\t\t__nvmem_device_put(nvmem);\n\t\t\t\tcell = ERR_PTR(-ENOENT);\n\t\t\t} else {\n\t\t\t\tcell = nvmem_create_cell(cell_entry, con_id, 0);\n\t\t\t\tif (IS_ERR(cell))\n\t\t\t\t\t__nvmem_device_put(nvmem);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&nvmem_lookup_mutex);\n\treturn cell;\n}\n\n#if IS_ENABLED(CONFIG_OF)\nstatic struct nvmem_cell_entry *\nnvmem_find_cell_entry_by_node(struct nvmem_device *nvmem, struct device_node *np)\n{\n\tstruct nvmem_cell_entry *iter, *cell = NULL;\n\n\tmutex_lock(&nvmem_mutex);\n\tlist_for_each_entry(iter, &nvmem->cells, node) {\n\t\tif (np == iter->np) {\n\t\t\tcell = iter;\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&nvmem_mutex);\n\n\treturn cell;\n}\n\n \nstruct nvmem_cell *of_nvmem_cell_get(struct device_node *np, const char *id)\n{\n\tstruct device_node *cell_np, *nvmem_np;\n\tstruct nvmem_device *nvmem;\n\tstruct nvmem_cell_entry *cell_entry;\n\tstruct nvmem_cell *cell;\n\tstruct of_phandle_args cell_spec;\n\tint index = 0;\n\tint cell_index = 0;\n\tint ret;\n\n\t \n\tif (id)\n\t\tindex = of_property_match_string(np, \"nvmem-cell-names\", id);\n\n\tret = of_parse_phandle_with_optional_args(np, \"nvmem-cells\",\n\t\t\t\t\t\t  \"#nvmem-cell-cells\",\n\t\t\t\t\t\t  index, &cell_spec);\n\tif (ret)\n\t\treturn ERR_PTR(-ENOENT);\n\n\tif (cell_spec.args_count > 1)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcell_np = cell_spec.np;\n\tif (cell_spec.args_count)\n\t\tcell_index = cell_spec.args[0];\n\n\tnvmem_np = of_get_parent(cell_np);\n\tif (!nvmem_np) {\n\t\tof_node_put(cell_np);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\t \n\tif (of_node_name_eq(nvmem_np, \"nvmem-layout\")) {\n\t\tnvmem_np = of_get_next_parent(nvmem_np);\n\t\tif (!nvmem_np) {\n\t\t\tof_node_put(cell_np);\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\t}\n\n\tnvmem = __nvmem_device_get(nvmem_np, device_match_of_node);\n\tof_node_put(nvmem_np);\n\tif (IS_ERR(nvmem)) {\n\t\tof_node_put(cell_np);\n\t\treturn ERR_CAST(nvmem);\n\t}\n\n\tcell_entry = nvmem_find_cell_entry_by_node(nvmem, cell_np);\n\tof_node_put(cell_np);\n\tif (!cell_entry) {\n\t\t__nvmem_device_put(nvmem);\n\t\treturn ERR_PTR(-ENOENT);\n\t}\n\n\tcell = nvmem_create_cell(cell_entry, id, cell_index);\n\tif (IS_ERR(cell))\n\t\t__nvmem_device_put(nvmem);\n\n\treturn cell;\n}\nEXPORT_SYMBOL_GPL(of_nvmem_cell_get);\n#endif\n\n \nstruct nvmem_cell *nvmem_cell_get(struct device *dev, const char *id)\n{\n\tstruct nvmem_cell *cell;\n\n\tif (dev->of_node) {  \n\t\tcell = of_nvmem_cell_get(dev->of_node, id);\n\t\tif (!IS_ERR(cell) || PTR_ERR(cell) == -EPROBE_DEFER)\n\t\t\treturn cell;\n\t}\n\n\t \n\tif (!id)\n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn nvmem_cell_get_from_lookup(dev, id);\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_get);\n\nstatic void devm_nvmem_cell_release(struct device *dev, void *res)\n{\n\tnvmem_cell_put(*(struct nvmem_cell **)res);\n}\n\n \nstruct nvmem_cell *devm_nvmem_cell_get(struct device *dev, const char *id)\n{\n\tstruct nvmem_cell **ptr, *cell;\n\n\tptr = devres_alloc(devm_nvmem_cell_release, sizeof(*ptr), GFP_KERNEL);\n\tif (!ptr)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tcell = nvmem_cell_get(dev, id);\n\tif (!IS_ERR(cell)) {\n\t\t*ptr = cell;\n\t\tdevres_add(dev, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn cell;\n}\nEXPORT_SYMBOL_GPL(devm_nvmem_cell_get);\n\nstatic int devm_nvmem_cell_match(struct device *dev, void *res, void *data)\n{\n\tstruct nvmem_cell **c = res;\n\n\tif (WARN_ON(!c || !*c))\n\t\treturn 0;\n\n\treturn *c == data;\n}\n\n \nvoid devm_nvmem_cell_put(struct device *dev, struct nvmem_cell *cell)\n{\n\tint ret;\n\n\tret = devres_release(dev, devm_nvmem_cell_release,\n\t\t\t\tdevm_nvmem_cell_match, cell);\n\n\tWARN_ON(ret);\n}\nEXPORT_SYMBOL(devm_nvmem_cell_put);\n\n \nvoid nvmem_cell_put(struct nvmem_cell *cell)\n{\n\tstruct nvmem_device *nvmem = cell->entry->nvmem;\n\n\tif (cell->id)\n\t\tkfree_const(cell->id);\n\n\tkfree(cell);\n\t__nvmem_device_put(nvmem);\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_put);\n\nstatic void nvmem_shift_read_buffer_in_place(struct nvmem_cell_entry *cell, void *buf)\n{\n\tu8 *p, *b;\n\tint i, extra, bit_offset = cell->bit_offset;\n\n\tp = b = buf;\n\tif (bit_offset) {\n\t\t \n\t\t*b++ >>= bit_offset;\n\n\t\t \n\t\tfor (i = 1; i < cell->bytes; i++) {\n\t\t\t \n\t\t\t*p |= *b << (BITS_PER_BYTE - bit_offset);\n\n\t\t\tp = b;\n\t\t\t*b++ >>= bit_offset;\n\t\t}\n\t} else {\n\t\t \n\t\tp += cell->bytes - 1;\n\t}\n\n\t \n\textra = cell->bytes - DIV_ROUND_UP(cell->nbits, BITS_PER_BYTE);\n\twhile (--extra >= 0)\n\t\t*p-- = 0;\n\n\t \n\tif (cell->nbits % BITS_PER_BYTE)\n\t\t*p &= GENMASK((cell->nbits % BITS_PER_BYTE) - 1, 0);\n}\n\nstatic int __nvmem_cell_read(struct nvmem_device *nvmem,\n\t\t\t     struct nvmem_cell_entry *cell,\n\t\t\t     void *buf, size_t *len, const char *id, int index)\n{\n\tint rc;\n\n\trc = nvmem_reg_read(nvmem, cell->offset, buf, cell->raw_len);\n\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (cell->bit_offset || cell->nbits)\n\t\tnvmem_shift_read_buffer_in_place(cell, buf);\n\n\tif (cell->read_post_process) {\n\t\trc = cell->read_post_process(cell->priv, id, index,\n\t\t\t\t\t     cell->offset, buf, cell->raw_len);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tif (len)\n\t\t*len = cell->bytes;\n\n\treturn 0;\n}\n\n \nvoid *nvmem_cell_read(struct nvmem_cell *cell, size_t *len)\n{\n\tstruct nvmem_cell_entry *entry = cell->entry;\n\tstruct nvmem_device *nvmem = entry->nvmem;\n\tu8 *buf;\n\tint rc;\n\n\tif (!nvmem)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tbuf = kzalloc(max_t(size_t, entry->raw_len, entry->bytes), GFP_KERNEL);\n\tif (!buf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trc = __nvmem_cell_read(nvmem, cell->entry, buf, len, cell->id, cell->index);\n\tif (rc) {\n\t\tkfree(buf);\n\t\treturn ERR_PTR(rc);\n\t}\n\n\treturn buf;\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_read);\n\nstatic void *nvmem_cell_prepare_write_buffer(struct nvmem_cell_entry *cell,\n\t\t\t\t\t     u8 *_buf, int len)\n{\n\tstruct nvmem_device *nvmem = cell->nvmem;\n\tint i, rc, nbits, bit_offset = cell->bit_offset;\n\tu8 v, *p, *buf, *b, pbyte, pbits;\n\n\tnbits = cell->nbits;\n\tbuf = kzalloc(cell->bytes, GFP_KERNEL);\n\tif (!buf)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmemcpy(buf, _buf, len);\n\tp = b = buf;\n\n\tif (bit_offset) {\n\t\tpbyte = *b;\n\t\t*b <<= bit_offset;\n\n\t\t \n\t\trc = nvmem_reg_read(nvmem, cell->offset, &v, 1);\n\t\tif (rc)\n\t\t\tgoto err;\n\t\t*b++ |= GENMASK(bit_offset - 1, 0) & v;\n\n\t\t \n\t\tfor (i = 1; i < cell->bytes; i++) {\n\t\t\t \n\t\t\tpbits = pbyte >> (BITS_PER_BYTE - 1 - bit_offset);\n\t\t\tpbyte = *b;\n\t\t\tp = b;\n\t\t\t*b <<= bit_offset;\n\t\t\t*b++ |= pbits;\n\t\t}\n\t}\n\n\t \n\tif ((nbits + bit_offset) % BITS_PER_BYTE) {\n\t\t \n\t\trc = nvmem_reg_read(nvmem,\n\t\t\t\t    cell->offset + cell->bytes - 1, &v, 1);\n\t\tif (rc)\n\t\t\tgoto err;\n\t\t*p |= GENMASK(7, (nbits + bit_offset) % BITS_PER_BYTE) & v;\n\n\t}\n\n\treturn buf;\nerr:\n\tkfree(buf);\n\treturn ERR_PTR(rc);\n}\n\nstatic int __nvmem_cell_entry_write(struct nvmem_cell_entry *cell, void *buf, size_t len)\n{\n\tstruct nvmem_device *nvmem = cell->nvmem;\n\tint rc;\n\n\tif (!nvmem || nvmem->read_only ||\n\t    (cell->bit_offset == 0 && len != cell->bytes))\n\t\treturn -EINVAL;\n\n\t \n\tif (cell->read_post_process)\n\t\treturn -EINVAL;\n\n\tif (cell->bit_offset || cell->nbits) {\n\t\tbuf = nvmem_cell_prepare_write_buffer(cell, buf, len);\n\t\tif (IS_ERR(buf))\n\t\t\treturn PTR_ERR(buf);\n\t}\n\n\trc = nvmem_reg_write(nvmem, cell->offset, buf, cell->bytes);\n\n\t \n\tif (cell->bit_offset || cell->nbits)\n\t\tkfree(buf);\n\n\tif (rc)\n\t\treturn rc;\n\n\treturn len;\n}\n\n \nint nvmem_cell_write(struct nvmem_cell *cell, void *buf, size_t len)\n{\n\treturn __nvmem_cell_entry_write(cell->entry, buf, len);\n}\n\nEXPORT_SYMBOL_GPL(nvmem_cell_write);\n\nstatic int nvmem_cell_read_common(struct device *dev, const char *cell_id,\n\t\t\t\t  void *val, size_t count)\n{\n\tstruct nvmem_cell *cell;\n\tvoid *buf;\n\tsize_t len;\n\n\tcell = nvmem_cell_get(dev, cell_id);\n\tif (IS_ERR(cell))\n\t\treturn PTR_ERR(cell);\n\n\tbuf = nvmem_cell_read(cell, &len);\n\tif (IS_ERR(buf)) {\n\t\tnvmem_cell_put(cell);\n\t\treturn PTR_ERR(buf);\n\t}\n\tif (len != count) {\n\t\tkfree(buf);\n\t\tnvmem_cell_put(cell);\n\t\treturn -EINVAL;\n\t}\n\tmemcpy(val, buf, count);\n\tkfree(buf);\n\tnvmem_cell_put(cell);\n\n\treturn 0;\n}\n\n \nint nvmem_cell_read_u8(struct device *dev, const char *cell_id, u8 *val)\n{\n\treturn nvmem_cell_read_common(dev, cell_id, val, sizeof(*val));\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_read_u8);\n\n \nint nvmem_cell_read_u16(struct device *dev, const char *cell_id, u16 *val)\n{\n\treturn nvmem_cell_read_common(dev, cell_id, val, sizeof(*val));\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_read_u16);\n\n \nint nvmem_cell_read_u32(struct device *dev, const char *cell_id, u32 *val)\n{\n\treturn nvmem_cell_read_common(dev, cell_id, val, sizeof(*val));\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_read_u32);\n\n \nint nvmem_cell_read_u64(struct device *dev, const char *cell_id, u64 *val)\n{\n\treturn nvmem_cell_read_common(dev, cell_id, val, sizeof(*val));\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_read_u64);\n\nstatic const void *nvmem_cell_read_variable_common(struct device *dev,\n\t\t\t\t\t\t   const char *cell_id,\n\t\t\t\t\t\t   size_t max_len, size_t *len)\n{\n\tstruct nvmem_cell *cell;\n\tint nbits;\n\tvoid *buf;\n\n\tcell = nvmem_cell_get(dev, cell_id);\n\tif (IS_ERR(cell))\n\t\treturn cell;\n\n\tnbits = cell->entry->nbits;\n\tbuf = nvmem_cell_read(cell, len);\n\tnvmem_cell_put(cell);\n\tif (IS_ERR(buf))\n\t\treturn buf;\n\n\t \n\tif (nbits)\n\t\t*len = DIV_ROUND_UP(nbits, 8);\n\n\tif (*len > max_len) {\n\t\tkfree(buf);\n\t\treturn ERR_PTR(-ERANGE);\n\t}\n\n\treturn buf;\n}\n\n \nint nvmem_cell_read_variable_le_u32(struct device *dev, const char *cell_id,\n\t\t\t\t    u32 *val)\n{\n\tsize_t len;\n\tconst u8 *buf;\n\tint i;\n\n\tbuf = nvmem_cell_read_variable_common(dev, cell_id, sizeof(*val), &len);\n\tif (IS_ERR(buf))\n\t\treturn PTR_ERR(buf);\n\n\t \n\t*val = 0;\n\tfor (i = 0; i < len; i++)\n\t\t*val |= buf[i] << (8 * i);\n\n\tkfree(buf);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_read_variable_le_u32);\n\n \nint nvmem_cell_read_variable_le_u64(struct device *dev, const char *cell_id,\n\t\t\t\t    u64 *val)\n{\n\tsize_t len;\n\tconst u8 *buf;\n\tint i;\n\n\tbuf = nvmem_cell_read_variable_common(dev, cell_id, sizeof(*val), &len);\n\tif (IS_ERR(buf))\n\t\treturn PTR_ERR(buf);\n\n\t \n\t*val = 0;\n\tfor (i = 0; i < len; i++)\n\t\t*val |= (uint64_t)buf[i] << (8 * i);\n\n\tkfree(buf);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nvmem_cell_read_variable_le_u64);\n\n \nssize_t nvmem_device_cell_read(struct nvmem_device *nvmem,\n\t\t\t   struct nvmem_cell_info *info, void *buf)\n{\n\tstruct nvmem_cell_entry cell;\n\tint rc;\n\tssize_t len;\n\n\tif (!nvmem)\n\t\treturn -EINVAL;\n\n\trc = nvmem_cell_info_to_nvmem_cell_entry_nodup(nvmem, info, &cell);\n\tif (rc)\n\t\treturn rc;\n\n\trc = __nvmem_cell_read(nvmem, &cell, buf, &len, NULL, 0);\n\tif (rc)\n\t\treturn rc;\n\n\treturn len;\n}\nEXPORT_SYMBOL_GPL(nvmem_device_cell_read);\n\n \nint nvmem_device_cell_write(struct nvmem_device *nvmem,\n\t\t\t    struct nvmem_cell_info *info, void *buf)\n{\n\tstruct nvmem_cell_entry cell;\n\tint rc;\n\n\tif (!nvmem)\n\t\treturn -EINVAL;\n\n\trc = nvmem_cell_info_to_nvmem_cell_entry_nodup(nvmem, info, &cell);\n\tif (rc)\n\t\treturn rc;\n\n\treturn __nvmem_cell_entry_write(&cell, buf, cell.bytes);\n}\nEXPORT_SYMBOL_GPL(nvmem_device_cell_write);\n\n \nint nvmem_device_read(struct nvmem_device *nvmem,\n\t\t      unsigned int offset,\n\t\t      size_t bytes, void *buf)\n{\n\tint rc;\n\n\tif (!nvmem)\n\t\treturn -EINVAL;\n\n\trc = nvmem_reg_read(nvmem, offset, buf, bytes);\n\n\tif (rc)\n\t\treturn rc;\n\n\treturn bytes;\n}\nEXPORT_SYMBOL_GPL(nvmem_device_read);\n\n \nint nvmem_device_write(struct nvmem_device *nvmem,\n\t\t       unsigned int offset,\n\t\t       size_t bytes, void *buf)\n{\n\tint rc;\n\n\tif (!nvmem)\n\t\treturn -EINVAL;\n\n\trc = nvmem_reg_write(nvmem, offset, buf, bytes);\n\n\tif (rc)\n\t\treturn rc;\n\n\n\treturn bytes;\n}\nEXPORT_SYMBOL_GPL(nvmem_device_write);\n\n \nvoid nvmem_add_cell_table(struct nvmem_cell_table *table)\n{\n\tmutex_lock(&nvmem_cell_mutex);\n\tlist_add_tail(&table->node, &nvmem_cell_tables);\n\tmutex_unlock(&nvmem_cell_mutex);\n}\nEXPORT_SYMBOL_GPL(nvmem_add_cell_table);\n\n \nvoid nvmem_del_cell_table(struct nvmem_cell_table *table)\n{\n\tmutex_lock(&nvmem_cell_mutex);\n\tlist_del(&table->node);\n\tmutex_unlock(&nvmem_cell_mutex);\n}\nEXPORT_SYMBOL_GPL(nvmem_del_cell_table);\n\n \nvoid nvmem_add_cell_lookups(struct nvmem_cell_lookup *entries, size_t nentries)\n{\n\tint i;\n\n\tmutex_lock(&nvmem_lookup_mutex);\n\tfor (i = 0; i < nentries; i++)\n\t\tlist_add_tail(&entries[i].node, &nvmem_lookup_list);\n\tmutex_unlock(&nvmem_lookup_mutex);\n}\nEXPORT_SYMBOL_GPL(nvmem_add_cell_lookups);\n\n \nvoid nvmem_del_cell_lookups(struct nvmem_cell_lookup *entries, size_t nentries)\n{\n\tint i;\n\n\tmutex_lock(&nvmem_lookup_mutex);\n\tfor (i = 0; i < nentries; i++)\n\t\tlist_del(&entries[i].node);\n\tmutex_unlock(&nvmem_lookup_mutex);\n}\nEXPORT_SYMBOL_GPL(nvmem_del_cell_lookups);\n\n \nconst char *nvmem_dev_name(struct nvmem_device *nvmem)\n{\n\treturn dev_name(&nvmem->dev);\n}\nEXPORT_SYMBOL_GPL(nvmem_dev_name);\n\nstatic int __init nvmem_init(void)\n{\n\treturn bus_register(&nvmem_bus_type);\n}\n\nstatic void __exit nvmem_exit(void)\n{\n\tbus_unregister(&nvmem_bus_type);\n}\n\nsubsys_initcall(nvmem_init);\nmodule_exit(nvmem_exit);\n\nMODULE_AUTHOR(\"Srinivas Kandagatla <srinivas.kandagatla@linaro.org\");\nMODULE_AUTHOR(\"Maxime Ripard <maxime.ripard@free-electrons.com\");\nMODULE_DESCRIPTION(\"nvmem Driver Core\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}