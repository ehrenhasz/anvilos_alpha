{
  "module_name": "virtio_mmio.c",
  "hash_id": "b399595850f070cdb4047d15e4d3e4d9a6964e8a3b38659efcfe02384029ac6a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/virtio/virtio_mmio.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"virtio-mmio: \" fmt\n\n#include <linux/acpi.h>\n#include <linux/dma-mapping.h>\n#include <linux/highmem.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/pm.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/virtio.h>\n#include <linux/virtio_config.h>\n#include <uapi/linux/virtio_mmio.h>\n#include <linux/virtio_ring.h>\n\n\n\n \n#define VIRTIO_MMIO_VRING_ALIGN\t\tPAGE_SIZE\n\n\n\n#define to_virtio_mmio_device(_plat_dev) \\\n\tcontainer_of(_plat_dev, struct virtio_mmio_device, vdev)\n\nstruct virtio_mmio_device {\n\tstruct virtio_device vdev;\n\tstruct platform_device *pdev;\n\n\tvoid __iomem *base;\n\tunsigned long version;\n\n\t \n\tspinlock_t lock;\n\tstruct list_head virtqueues;\n};\n\nstruct virtio_mmio_vq_info {\n\t \n\tstruct virtqueue *vq;\n\n\t \n\tstruct list_head node;\n};\n\n\n\n \n\nstatic u64 vm_get_features(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\tu64 features;\n\n\twritel(1, vm_dev->base + VIRTIO_MMIO_DEVICE_FEATURES_SEL);\n\tfeatures = readl(vm_dev->base + VIRTIO_MMIO_DEVICE_FEATURES);\n\tfeatures <<= 32;\n\n\twritel(0, vm_dev->base + VIRTIO_MMIO_DEVICE_FEATURES_SEL);\n\tfeatures |= readl(vm_dev->base + VIRTIO_MMIO_DEVICE_FEATURES);\n\n\treturn features;\n}\n\nstatic int vm_finalize_features(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\t \n\tvring_transport_features(vdev);\n\n\t \n\tif (vm_dev->version == 2 &&\n\t\t\t!__virtio_test_bit(vdev, VIRTIO_F_VERSION_1)) {\n\t\tdev_err(&vdev->dev, \"New virtio-mmio devices (version 2) must provide VIRTIO_F_VERSION_1 feature!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\twritel(1, vm_dev->base + VIRTIO_MMIO_DRIVER_FEATURES_SEL);\n\twritel((u32)(vdev->features >> 32),\n\t\t\tvm_dev->base + VIRTIO_MMIO_DRIVER_FEATURES);\n\n\twritel(0, vm_dev->base + VIRTIO_MMIO_DRIVER_FEATURES_SEL);\n\twritel((u32)vdev->features,\n\t\t\tvm_dev->base + VIRTIO_MMIO_DRIVER_FEATURES);\n\n\treturn 0;\n}\n\nstatic void vm_get(struct virtio_device *vdev, unsigned int offset,\n\t\t   void *buf, unsigned int len)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\tvoid __iomem *base = vm_dev->base + VIRTIO_MMIO_CONFIG;\n\tu8 b;\n\t__le16 w;\n\t__le32 l;\n\n\tif (vm_dev->version == 1) {\n\t\tu8 *ptr = buf;\n\t\tint i;\n\n\t\tfor (i = 0; i < len; i++)\n\t\t\tptr[i] = readb(base + offset + i);\n\t\treturn;\n\t}\n\n\tswitch (len) {\n\tcase 1:\n\t\tb = readb(base + offset);\n\t\tmemcpy(buf, &b, sizeof b);\n\t\tbreak;\n\tcase 2:\n\t\tw = cpu_to_le16(readw(base + offset));\n\t\tmemcpy(buf, &w, sizeof w);\n\t\tbreak;\n\tcase 4:\n\t\tl = cpu_to_le32(readl(base + offset));\n\t\tmemcpy(buf, &l, sizeof l);\n\t\tbreak;\n\tcase 8:\n\t\tl = cpu_to_le32(readl(base + offset));\n\t\tmemcpy(buf, &l, sizeof l);\n\t\tl = cpu_to_le32(ioread32(base + offset + sizeof l));\n\t\tmemcpy(buf + sizeof l, &l, sizeof l);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic void vm_set(struct virtio_device *vdev, unsigned int offset,\n\t\t   const void *buf, unsigned int len)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\tvoid __iomem *base = vm_dev->base + VIRTIO_MMIO_CONFIG;\n\tu8 b;\n\t__le16 w;\n\t__le32 l;\n\n\tif (vm_dev->version == 1) {\n\t\tconst u8 *ptr = buf;\n\t\tint i;\n\n\t\tfor (i = 0; i < len; i++)\n\t\t\twriteb(ptr[i], base + offset + i);\n\n\t\treturn;\n\t}\n\n\tswitch (len) {\n\tcase 1:\n\t\tmemcpy(&b, buf, sizeof b);\n\t\twriteb(b, base + offset);\n\t\tbreak;\n\tcase 2:\n\t\tmemcpy(&w, buf, sizeof w);\n\t\twritew(le16_to_cpu(w), base + offset);\n\t\tbreak;\n\tcase 4:\n\t\tmemcpy(&l, buf, sizeof l);\n\t\twritel(le32_to_cpu(l), base + offset);\n\t\tbreak;\n\tcase 8:\n\t\tmemcpy(&l, buf, sizeof l);\n\t\twritel(le32_to_cpu(l), base + offset);\n\t\tmemcpy(&l, buf + sizeof l, sizeof l);\n\t\twritel(le32_to_cpu(l), base + offset + sizeof l);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic u32 vm_generation(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\tif (vm_dev->version == 1)\n\t\treturn 0;\n\telse\n\t\treturn readl(vm_dev->base + VIRTIO_MMIO_CONFIG_GENERATION);\n}\n\nstatic u8 vm_get_status(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\treturn readl(vm_dev->base + VIRTIO_MMIO_STATUS) & 0xff;\n}\n\nstatic void vm_set_status(struct virtio_device *vdev, u8 status)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\t \n\tBUG_ON(status == 0);\n\n\t \n\twritel(status, vm_dev->base + VIRTIO_MMIO_STATUS);\n}\n\nstatic void vm_reset(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\t \n\twritel(0, vm_dev->base + VIRTIO_MMIO_STATUS);\n}\n\n\n\n \n\n \nstatic bool vm_notify(struct virtqueue *vq)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vq->vdev);\n\n\t \n\twritel(vq->index, vm_dev->base + VIRTIO_MMIO_QUEUE_NOTIFY);\n\treturn true;\n}\n\nstatic bool vm_notify_with_data(struct virtqueue *vq)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vq->vdev);\n\tu32 data = vring_notification_data(vq);\n\n\twritel(data, vm_dev->base + VIRTIO_MMIO_QUEUE_NOTIFY);\n\n\treturn true;\n}\n\n \nstatic irqreturn_t vm_interrupt(int irq, void *opaque)\n{\n\tstruct virtio_mmio_device *vm_dev = opaque;\n\tstruct virtio_mmio_vq_info *info;\n\tunsigned long status;\n\tunsigned long flags;\n\tirqreturn_t ret = IRQ_NONE;\n\n\t \n\tstatus = readl(vm_dev->base + VIRTIO_MMIO_INTERRUPT_STATUS);\n\twritel(status, vm_dev->base + VIRTIO_MMIO_INTERRUPT_ACK);\n\n\tif (unlikely(status & VIRTIO_MMIO_INT_CONFIG)) {\n\t\tvirtio_config_changed(&vm_dev->vdev);\n\t\tret = IRQ_HANDLED;\n\t}\n\n\tif (likely(status & VIRTIO_MMIO_INT_VRING)) {\n\t\tspin_lock_irqsave(&vm_dev->lock, flags);\n\t\tlist_for_each_entry(info, &vm_dev->virtqueues, node)\n\t\t\tret |= vring_interrupt(irq, info->vq);\n\t\tspin_unlock_irqrestore(&vm_dev->lock, flags);\n\t}\n\n\treturn ret;\n}\n\n\n\nstatic void vm_del_vq(struct virtqueue *vq)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vq->vdev);\n\tstruct virtio_mmio_vq_info *info = vq->priv;\n\tunsigned long flags;\n\tunsigned int index = vq->index;\n\n\tspin_lock_irqsave(&vm_dev->lock, flags);\n\tlist_del(&info->node);\n\tspin_unlock_irqrestore(&vm_dev->lock, flags);\n\n\t \n\twritel(index, vm_dev->base + VIRTIO_MMIO_QUEUE_SEL);\n\tif (vm_dev->version == 1) {\n\t\twritel(0, vm_dev->base + VIRTIO_MMIO_QUEUE_PFN);\n\t} else {\n\t\twritel(0, vm_dev->base + VIRTIO_MMIO_QUEUE_READY);\n\t\tWARN_ON(readl(vm_dev->base + VIRTIO_MMIO_QUEUE_READY));\n\t}\n\n\tvring_del_virtqueue(vq);\n\n\tkfree(info);\n}\n\nstatic void vm_del_vqs(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\tstruct virtqueue *vq, *n;\n\n\tlist_for_each_entry_safe(vq, n, &vdev->vqs, list)\n\t\tvm_del_vq(vq);\n\n\tfree_irq(platform_get_irq(vm_dev->pdev, 0), vm_dev);\n}\n\nstatic void vm_synchronize_cbs(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\tsynchronize_irq(platform_get_irq(vm_dev->pdev, 0));\n}\n\nstatic struct virtqueue *vm_setup_vq(struct virtio_device *vdev, unsigned int index,\n\t\t\t\t  void (*callback)(struct virtqueue *vq),\n\t\t\t\t  const char *name, bool ctx)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\tbool (*notify)(struct virtqueue *vq);\n\tstruct virtio_mmio_vq_info *info;\n\tstruct virtqueue *vq;\n\tunsigned long flags;\n\tunsigned int num;\n\tint err;\n\n\tif (__virtio_test_bit(vdev, VIRTIO_F_NOTIFICATION_DATA))\n\t\tnotify = vm_notify_with_data;\n\telse\n\t\tnotify = vm_notify;\n\n\tif (!name)\n\t\treturn NULL;\n\n\t \n\twritel(index, vm_dev->base + VIRTIO_MMIO_QUEUE_SEL);\n\n\t \n\tif (readl(vm_dev->base + (vm_dev->version == 1 ?\n\t\t\tVIRTIO_MMIO_QUEUE_PFN : VIRTIO_MMIO_QUEUE_READY))) {\n\t\terr = -ENOENT;\n\t\tgoto error_available;\n\t}\n\n\t \n\tinfo = kmalloc(sizeof(*info), GFP_KERNEL);\n\tif (!info) {\n\t\terr = -ENOMEM;\n\t\tgoto error_kmalloc;\n\t}\n\n\tnum = readl(vm_dev->base + VIRTIO_MMIO_QUEUE_NUM_MAX);\n\tif (num == 0) {\n\t\terr = -ENOENT;\n\t\tgoto error_new_virtqueue;\n\t}\n\n\t \n\tvq = vring_create_virtqueue(index, num, VIRTIO_MMIO_VRING_ALIGN, vdev,\n\t\t\t\t true, true, ctx, notify, callback, name);\n\tif (!vq) {\n\t\terr = -ENOMEM;\n\t\tgoto error_new_virtqueue;\n\t}\n\n\tvq->num_max = num;\n\n\t \n\twritel(virtqueue_get_vring_size(vq), vm_dev->base + VIRTIO_MMIO_QUEUE_NUM);\n\tif (vm_dev->version == 1) {\n\t\tu64 q_pfn = virtqueue_get_desc_addr(vq) >> PAGE_SHIFT;\n\n\t\t \n\t\tif (q_pfn >> 32) {\n\t\t\tdev_err(&vdev->dev,\n\t\t\t\t\"platform bug: legacy virtio-mmio must not be used with RAM above 0x%llxGB\\n\",\n\t\t\t\t0x1ULL << (32 + PAGE_SHIFT - 30));\n\t\t\terr = -E2BIG;\n\t\t\tgoto error_bad_pfn;\n\t\t}\n\n\t\twritel(PAGE_SIZE, vm_dev->base + VIRTIO_MMIO_QUEUE_ALIGN);\n\t\twritel(q_pfn, vm_dev->base + VIRTIO_MMIO_QUEUE_PFN);\n\t} else {\n\t\tu64 addr;\n\n\t\taddr = virtqueue_get_desc_addr(vq);\n\t\twritel((u32)addr, vm_dev->base + VIRTIO_MMIO_QUEUE_DESC_LOW);\n\t\twritel((u32)(addr >> 32),\n\t\t\t\tvm_dev->base + VIRTIO_MMIO_QUEUE_DESC_HIGH);\n\n\t\taddr = virtqueue_get_avail_addr(vq);\n\t\twritel((u32)addr, vm_dev->base + VIRTIO_MMIO_QUEUE_AVAIL_LOW);\n\t\twritel((u32)(addr >> 32),\n\t\t\t\tvm_dev->base + VIRTIO_MMIO_QUEUE_AVAIL_HIGH);\n\n\t\taddr = virtqueue_get_used_addr(vq);\n\t\twritel((u32)addr, vm_dev->base + VIRTIO_MMIO_QUEUE_USED_LOW);\n\t\twritel((u32)(addr >> 32),\n\t\t\t\tvm_dev->base + VIRTIO_MMIO_QUEUE_USED_HIGH);\n\n\t\twritel(1, vm_dev->base + VIRTIO_MMIO_QUEUE_READY);\n\t}\n\n\tvq->priv = info;\n\tinfo->vq = vq;\n\n\tspin_lock_irqsave(&vm_dev->lock, flags);\n\tlist_add(&info->node, &vm_dev->virtqueues);\n\tspin_unlock_irqrestore(&vm_dev->lock, flags);\n\n\treturn vq;\n\nerror_bad_pfn:\n\tvring_del_virtqueue(vq);\nerror_new_virtqueue:\n\tif (vm_dev->version == 1) {\n\t\twritel(0, vm_dev->base + VIRTIO_MMIO_QUEUE_PFN);\n\t} else {\n\t\twritel(0, vm_dev->base + VIRTIO_MMIO_QUEUE_READY);\n\t\tWARN_ON(readl(vm_dev->base + VIRTIO_MMIO_QUEUE_READY));\n\t}\n\tkfree(info);\nerror_kmalloc:\nerror_available:\n\treturn ERR_PTR(err);\n}\n\nstatic int vm_find_vqs(struct virtio_device *vdev, unsigned int nvqs,\n\t\t       struct virtqueue *vqs[],\n\t\t       vq_callback_t *callbacks[],\n\t\t       const char * const names[],\n\t\t       const bool *ctx,\n\t\t       struct irq_affinity *desc)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\tint irq = platform_get_irq(vm_dev->pdev, 0);\n\tint i, err, queue_idx = 0;\n\n\tif (irq < 0)\n\t\treturn irq;\n\n\terr = request_irq(irq, vm_interrupt, IRQF_SHARED,\n\t\t\tdev_name(&vdev->dev), vm_dev);\n\tif (err)\n\t\treturn err;\n\n\tif (of_property_read_bool(vm_dev->pdev->dev.of_node, \"wakeup-source\"))\n\t\tenable_irq_wake(irq);\n\n\tfor (i = 0; i < nvqs; ++i) {\n\t\tif (!names[i]) {\n\t\t\tvqs[i] = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tvqs[i] = vm_setup_vq(vdev, queue_idx++, callbacks[i], names[i],\n\t\t\t\t     ctx ? ctx[i] : false);\n\t\tif (IS_ERR(vqs[i])) {\n\t\t\tvm_del_vqs(vdev);\n\t\t\treturn PTR_ERR(vqs[i]);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic const char *vm_bus_name(struct virtio_device *vdev)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\treturn vm_dev->pdev->name;\n}\n\nstatic bool vm_get_shm_region(struct virtio_device *vdev,\n\t\t\t      struct virtio_shm_region *region, u8 id)\n{\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\tu64 len, addr;\n\n\t \n\twritel(id, vm_dev->base + VIRTIO_MMIO_SHM_SEL);\n\n\t \n\tlen = (u64) readl(vm_dev->base + VIRTIO_MMIO_SHM_LEN_LOW);\n\tlen |= (u64) readl(vm_dev->base + VIRTIO_MMIO_SHM_LEN_HIGH) << 32;\n\n\tregion->len = len;\n\n\t \n\tif (len == ~(u64)0)\n\t\treturn false;\n\n\t \n\taddr = (u64) readl(vm_dev->base + VIRTIO_MMIO_SHM_BASE_LOW);\n\taddr |= (u64) readl(vm_dev->base + VIRTIO_MMIO_SHM_BASE_HIGH) << 32;\n\n\tregion->addr = addr;\n\n\treturn true;\n}\n\nstatic const struct virtio_config_ops virtio_mmio_config_ops = {\n\t.get\t\t= vm_get,\n\t.set\t\t= vm_set,\n\t.generation\t= vm_generation,\n\t.get_status\t= vm_get_status,\n\t.set_status\t= vm_set_status,\n\t.reset\t\t= vm_reset,\n\t.find_vqs\t= vm_find_vqs,\n\t.del_vqs\t= vm_del_vqs,\n\t.get_features\t= vm_get_features,\n\t.finalize_features = vm_finalize_features,\n\t.bus_name\t= vm_bus_name,\n\t.get_shm_region = vm_get_shm_region,\n\t.synchronize_cbs = vm_synchronize_cbs,\n};\n\n#ifdef CONFIG_PM_SLEEP\nstatic int virtio_mmio_freeze(struct device *dev)\n{\n\tstruct virtio_mmio_device *vm_dev = dev_get_drvdata(dev);\n\n\treturn virtio_device_freeze(&vm_dev->vdev);\n}\n\nstatic int virtio_mmio_restore(struct device *dev)\n{\n\tstruct virtio_mmio_device *vm_dev = dev_get_drvdata(dev);\n\n\tif (vm_dev->version == 1)\n\t\twritel(PAGE_SIZE, vm_dev->base + VIRTIO_MMIO_GUEST_PAGE_SIZE);\n\n\treturn virtio_device_restore(&vm_dev->vdev);\n}\n\nstatic const struct dev_pm_ops virtio_mmio_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(virtio_mmio_freeze, virtio_mmio_restore)\n};\n#endif\n\nstatic void virtio_mmio_release_dev(struct device *_d)\n{\n\tstruct virtio_device *vdev =\n\t\t\tcontainer_of(_d, struct virtio_device, dev);\n\tstruct virtio_mmio_device *vm_dev = to_virtio_mmio_device(vdev);\n\n\tkfree(vm_dev);\n}\n\n \n\nstatic int virtio_mmio_probe(struct platform_device *pdev)\n{\n\tstruct virtio_mmio_device *vm_dev;\n\tunsigned long magic;\n\tint rc;\n\n\tvm_dev = kzalloc(sizeof(*vm_dev), GFP_KERNEL);\n\tif (!vm_dev)\n\t\treturn -ENOMEM;\n\n\tvm_dev->vdev.dev.parent = &pdev->dev;\n\tvm_dev->vdev.dev.release = virtio_mmio_release_dev;\n\tvm_dev->vdev.config = &virtio_mmio_config_ops;\n\tvm_dev->pdev = pdev;\n\tINIT_LIST_HEAD(&vm_dev->virtqueues);\n\tspin_lock_init(&vm_dev->lock);\n\n\tvm_dev->base = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(vm_dev->base)) {\n\t\trc = PTR_ERR(vm_dev->base);\n\t\tgoto free_vm_dev;\n\t}\n\n\t \n\tmagic = readl(vm_dev->base + VIRTIO_MMIO_MAGIC_VALUE);\n\tif (magic != ('v' | 'i' << 8 | 'r' << 16 | 't' << 24)) {\n\t\tdev_warn(&pdev->dev, \"Wrong magic value 0x%08lx!\\n\", magic);\n\t\trc = -ENODEV;\n\t\tgoto free_vm_dev;\n\t}\n\n\t \n\tvm_dev->version = readl(vm_dev->base + VIRTIO_MMIO_VERSION);\n\tif (vm_dev->version < 1 || vm_dev->version > 2) {\n\t\tdev_err(&pdev->dev, \"Version %ld not supported!\\n\",\n\t\t\t\tvm_dev->version);\n\t\trc = -ENXIO;\n\t\tgoto free_vm_dev;\n\t}\n\n\tvm_dev->vdev.id.device = readl(vm_dev->base + VIRTIO_MMIO_DEVICE_ID);\n\tif (vm_dev->vdev.id.device == 0) {\n\t\t \n\t\trc = -ENODEV;\n\t\tgoto free_vm_dev;\n\t}\n\tvm_dev->vdev.id.vendor = readl(vm_dev->base + VIRTIO_MMIO_VENDOR_ID);\n\n\tif (vm_dev->version == 1) {\n\t\twritel(PAGE_SIZE, vm_dev->base + VIRTIO_MMIO_GUEST_PAGE_SIZE);\n\n\t\trc = dma_set_mask(&pdev->dev, DMA_BIT_MASK(64));\n\t\t \n\t\tif (!rc)\n\t\t\tdma_set_coherent_mask(&pdev->dev,\n\t\t\t\t\t      DMA_BIT_MASK(32 + PAGE_SHIFT));\n\t} else {\n\t\trc = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\t}\n\tif (rc)\n\t\trc = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (rc)\n\t\tdev_warn(&pdev->dev, \"Failed to enable 64-bit or 32-bit DMA.  Trying to continue, but this might not work.\\n\");\n\n\tplatform_set_drvdata(pdev, vm_dev);\n\n\trc = register_virtio_device(&vm_dev->vdev);\n\tif (rc)\n\t\tput_device(&vm_dev->vdev.dev);\n\n\treturn rc;\n\nfree_vm_dev:\n\tkfree(vm_dev);\n\treturn rc;\n}\n\nstatic int virtio_mmio_remove(struct platform_device *pdev)\n{\n\tstruct virtio_mmio_device *vm_dev = platform_get_drvdata(pdev);\n\tunregister_virtio_device(&vm_dev->vdev);\n\n\treturn 0;\n}\n\n\n\n \n\n#if defined(CONFIG_VIRTIO_MMIO_CMDLINE_DEVICES)\n\nstatic struct device vm_cmdline_parent = {\n\t.init_name = \"virtio-mmio-cmdline\",\n};\n\nstatic int vm_cmdline_parent_registered;\nstatic int vm_cmdline_id;\n\nstatic int vm_cmdline_set(const char *device,\n\t\tconst struct kernel_param *kp)\n{\n\tint err;\n\tstruct resource resources[2] = {};\n\tchar *str;\n\tlong long base, size;\n\tunsigned int irq;\n\tint processed, consumed = 0;\n\tstruct platform_device *pdev;\n\n\t \n\tsize = memparse(device, &str);\n\n\t \n\tprocessed = sscanf(str, \"@%lli:%u%n:%d%n\",\n\t\t\t&base, &irq, &consumed,\n\t\t\t&vm_cmdline_id, &consumed);\n\n\t \n\tif (processed < 2 || str[consumed] || irq == 0)\n\t\treturn -EINVAL;\n\n\tresources[0].flags = IORESOURCE_MEM;\n\tresources[0].start = base;\n\tresources[0].end = base + size - 1;\n\n\tresources[1].flags = IORESOURCE_IRQ;\n\tresources[1].start = resources[1].end = irq;\n\n\tif (!vm_cmdline_parent_registered) {\n\t\terr = device_register(&vm_cmdline_parent);\n\t\tif (err) {\n\t\t\tput_device(&vm_cmdline_parent);\n\t\t\tpr_err(\"Failed to register parent device!\\n\");\n\t\t\treturn err;\n\t\t}\n\t\tvm_cmdline_parent_registered = 1;\n\t}\n\n\tpr_info(\"Registering device virtio-mmio.%d at 0x%llx-0x%llx, IRQ %d.\\n\",\n\t\t       vm_cmdline_id,\n\t\t       (unsigned long long)resources[0].start,\n\t\t       (unsigned long long)resources[0].end,\n\t\t       (int)resources[1].start);\n\n\tpdev = platform_device_register_resndata(&vm_cmdline_parent,\n\t\t\t\"virtio-mmio\", vm_cmdline_id++,\n\t\t\tresources, ARRAY_SIZE(resources), NULL, 0);\n\n\treturn PTR_ERR_OR_ZERO(pdev);\n}\n\nstatic int vm_cmdline_get_device(struct device *dev, void *data)\n{\n\tchar *buffer = data;\n\tunsigned int len = strlen(buffer);\n\tstruct platform_device *pdev = to_platform_device(dev);\n\n\tsnprintf(buffer + len, PAGE_SIZE - len, \"0x%llx@0x%llx:%llu:%d\\n\",\n\t\t\tpdev->resource[0].end - pdev->resource[0].start + 1ULL,\n\t\t\t(unsigned long long)pdev->resource[0].start,\n\t\t\t(unsigned long long)pdev->resource[1].start,\n\t\t\tpdev->id);\n\treturn 0;\n}\n\nstatic int vm_cmdline_get(char *buffer, const struct kernel_param *kp)\n{\n\tbuffer[0] = '\\0';\n\tdevice_for_each_child(&vm_cmdline_parent, buffer,\n\t\t\tvm_cmdline_get_device);\n\treturn strlen(buffer) + 1;\n}\n\nstatic const struct kernel_param_ops vm_cmdline_param_ops = {\n\t.set = vm_cmdline_set,\n\t.get = vm_cmdline_get,\n};\n\ndevice_param_cb(device, &vm_cmdline_param_ops, NULL, S_IRUSR);\n\nstatic int vm_unregister_cmdline_device(struct device *dev,\n\t\tvoid *data)\n{\n\tplatform_device_unregister(to_platform_device(dev));\n\n\treturn 0;\n}\n\nstatic void vm_unregister_cmdline_devices(void)\n{\n\tif (vm_cmdline_parent_registered) {\n\t\tdevice_for_each_child(&vm_cmdline_parent, NULL,\n\t\t\t\tvm_unregister_cmdline_device);\n\t\tdevice_unregister(&vm_cmdline_parent);\n\t\tvm_cmdline_parent_registered = 0;\n\t}\n}\n\n#else\n\nstatic void vm_unregister_cmdline_devices(void)\n{\n}\n\n#endif\n\n \n\nstatic const struct of_device_id virtio_mmio_match[] = {\n\t{ .compatible = \"virtio,mmio\", },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, virtio_mmio_match);\n\n#ifdef CONFIG_ACPI\nstatic const struct acpi_device_id virtio_mmio_acpi_match[] = {\n\t{ \"LNRO0005\", },\n\t{ }\n};\nMODULE_DEVICE_TABLE(acpi, virtio_mmio_acpi_match);\n#endif\n\nstatic struct platform_driver virtio_mmio_driver = {\n\t.probe\t\t= virtio_mmio_probe,\n\t.remove\t\t= virtio_mmio_remove,\n\t.driver\t\t= {\n\t\t.name\t= \"virtio-mmio\",\n\t\t.of_match_table\t= virtio_mmio_match,\n\t\t.acpi_match_table = ACPI_PTR(virtio_mmio_acpi_match),\n#ifdef CONFIG_PM_SLEEP\n\t\t.pm\t= &virtio_mmio_pm_ops,\n#endif\n\t},\n};\n\nstatic int __init virtio_mmio_init(void)\n{\n\treturn platform_driver_register(&virtio_mmio_driver);\n}\n\nstatic void __exit virtio_mmio_exit(void)\n{\n\tplatform_driver_unregister(&virtio_mmio_driver);\n\tvm_unregister_cmdline_devices();\n}\n\nmodule_init(virtio_mmio_init);\nmodule_exit(virtio_mmio_exit);\n\nMODULE_AUTHOR(\"Pawel Moll <pawel.moll@arm.com>\");\nMODULE_DESCRIPTION(\"Platform bus driver for memory mapped virtio devices\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}