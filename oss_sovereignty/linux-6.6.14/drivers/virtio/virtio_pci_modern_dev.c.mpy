{
  "module_name": "virtio_pci_modern_dev.c",
  "hash_id": "28a60bbed009e90869554e57ef8a0cc274433c4bb277782d2dbc4d9254954376",
  "original_prompt": "Ingested from linux-6.6.14/drivers/virtio/virtio_pci_modern_dev.c",
  "human_readable_source": "\n\n#include <linux/virtio_pci_modern.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/delay.h>\n\n \nstatic void __iomem *\nvp_modern_map_capability(struct virtio_pci_modern_device *mdev, int off,\n\t\t\t size_t minlen, u32 align, u32 start, u32 size,\n\t\t\t size_t *len, resource_size_t *pa)\n{\n\tstruct pci_dev *dev = mdev->pci_dev;\n\tu8 bar;\n\tu32 offset, length;\n\tvoid __iomem *p;\n\n\tpci_read_config_byte(dev, off + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t bar),\n\t\t\t     &bar);\n\tpci_read_config_dword(dev, off + offsetof(struct virtio_pci_cap, offset),\n\t\t\t     &offset);\n\tpci_read_config_dword(dev, off + offsetof(struct virtio_pci_cap, length),\n\t\t\t      &length);\n\n\t \n\tif (bar >= PCI_STD_NUM_BARS || !(mdev->modern_bars & (1 << bar))) {\n\t\tdev_err(&dev->dev,\n\t\t\t\"virtio_pci: bar unexpectedly changed to %u\\n\", bar);\n\t\treturn NULL;\n\t}\n\n\tif (length <= start) {\n\t\tdev_err(&dev->dev,\n\t\t\t\"virtio_pci: bad capability len %u (>%u expected)\\n\",\n\t\t\tlength, start);\n\t\treturn NULL;\n\t}\n\n\tif (length - start < minlen) {\n\t\tdev_err(&dev->dev,\n\t\t\t\"virtio_pci: bad capability len %u (>=%zu expected)\\n\",\n\t\t\tlength, minlen);\n\t\treturn NULL;\n\t}\n\n\tlength -= start;\n\n\tif (start + offset < offset) {\n\t\tdev_err(&dev->dev,\n\t\t\t\"virtio_pci: map wrap-around %u+%u\\n\",\n\t\t\tstart, offset);\n\t\treturn NULL;\n\t}\n\n\toffset += start;\n\n\tif (offset & (align - 1)) {\n\t\tdev_err(&dev->dev,\n\t\t\t\"virtio_pci: offset %u not aligned to %u\\n\",\n\t\t\toffset, align);\n\t\treturn NULL;\n\t}\n\n\tif (length > size)\n\t\tlength = size;\n\n\tif (len)\n\t\t*len = length;\n\n\tif (minlen + offset < minlen ||\n\t    minlen + offset > pci_resource_len(dev, bar)) {\n\t\tdev_err(&dev->dev,\n\t\t\t\"virtio_pci: map virtio %zu@%u \"\n\t\t\t\"out of range on bar %i length %lu\\n\",\n\t\t\tminlen, offset,\n\t\t\tbar, (unsigned long)pci_resource_len(dev, bar));\n\t\treturn NULL;\n\t}\n\n\tp = pci_iomap_range(dev, bar, offset, length);\n\tif (!p)\n\t\tdev_err(&dev->dev,\n\t\t\t\"virtio_pci: unable to map virtio %u@%u on bar %i\\n\",\n\t\t\tlength, offset, bar);\n\telse if (pa)\n\t\t*pa = pci_resource_start(dev, bar) + offset;\n\n\treturn p;\n}\n\n \nstatic inline int virtio_pci_find_capability(struct pci_dev *dev, u8 cfg_type,\n\t\t\t\t\t     u32 ioresource_types, int *bars)\n{\n\tint pos;\n\n\tfor (pos = pci_find_capability(dev, PCI_CAP_ID_VNDR);\n\t     pos > 0;\n\t     pos = pci_find_next_capability(dev, pos, PCI_CAP_ID_VNDR)) {\n\t\tu8 type, bar;\n\t\tpci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t cfg_type),\n\t\t\t\t     &type);\n\t\tpci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t bar),\n\t\t\t\t     &bar);\n\n\t\t \n\t\tif (bar >= PCI_STD_NUM_BARS)\n\t\t\tcontinue;\n\n\t\tif (type == cfg_type) {\n\t\t\tif (pci_resource_len(dev, bar) &&\n\t\t\t    pci_resource_flags(dev, bar) & ioresource_types) {\n\t\t\t\t*bars |= (1 << bar);\n\t\t\t\treturn pos;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nstatic inline void check_offsets(void)\n{\n\t \n\tBUILD_BUG_ON(VIRTIO_PCI_CAP_VNDR !=\n\t\t     offsetof(struct virtio_pci_cap, cap_vndr));\n\tBUILD_BUG_ON(VIRTIO_PCI_CAP_NEXT !=\n\t\t     offsetof(struct virtio_pci_cap, cap_next));\n\tBUILD_BUG_ON(VIRTIO_PCI_CAP_LEN !=\n\t\t     offsetof(struct virtio_pci_cap, cap_len));\n\tBUILD_BUG_ON(VIRTIO_PCI_CAP_CFG_TYPE !=\n\t\t     offsetof(struct virtio_pci_cap, cfg_type));\n\tBUILD_BUG_ON(VIRTIO_PCI_CAP_BAR !=\n\t\t     offsetof(struct virtio_pci_cap, bar));\n\tBUILD_BUG_ON(VIRTIO_PCI_CAP_OFFSET !=\n\t\t     offsetof(struct virtio_pci_cap, offset));\n\tBUILD_BUG_ON(VIRTIO_PCI_CAP_LENGTH !=\n\t\t     offsetof(struct virtio_pci_cap, length));\n\tBUILD_BUG_ON(VIRTIO_PCI_NOTIFY_CAP_MULT !=\n\t\t     offsetof(struct virtio_pci_notify_cap,\n\t\t\t      notify_off_multiplier));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_DFSELECT !=\n\t\t     offsetof(struct virtio_pci_common_cfg,\n\t\t\t      device_feature_select));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_DF !=\n\t\t     offsetof(struct virtio_pci_common_cfg, device_feature));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_GFSELECT !=\n\t\t     offsetof(struct virtio_pci_common_cfg,\n\t\t\t      guest_feature_select));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_GF !=\n\t\t     offsetof(struct virtio_pci_common_cfg, guest_feature));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_MSIX !=\n\t\t     offsetof(struct virtio_pci_common_cfg, msix_config));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_NUMQ !=\n\t\t     offsetof(struct virtio_pci_common_cfg, num_queues));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_STATUS !=\n\t\t     offsetof(struct virtio_pci_common_cfg, device_status));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_CFGGENERATION !=\n\t\t     offsetof(struct virtio_pci_common_cfg, config_generation));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_SELECT !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_select));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_SIZE !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_size));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_MSIX !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_msix_vector));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_ENABLE !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_enable));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_NOFF !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_notify_off));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_DESCLO !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_desc_lo));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_DESCHI !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_desc_hi));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_AVAILLO !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_avail_lo));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_AVAILHI !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_avail_hi));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_USEDLO !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_used_lo));\n\tBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_USEDHI !=\n\t\t     offsetof(struct virtio_pci_common_cfg, queue_used_hi));\n}\n\n \nint vp_modern_probe(struct virtio_pci_modern_device *mdev)\n{\n\tstruct pci_dev *pci_dev = mdev->pci_dev;\n\tint err, common, isr, notify, device;\n\tu32 notify_length;\n\tu32 notify_offset;\n\tint devid;\n\n\tcheck_offsets();\n\n\tif (mdev->device_id_check) {\n\t\tdevid = mdev->device_id_check(pci_dev);\n\t\tif (devid < 0)\n\t\t\treturn devid;\n\t\tmdev->id.device = devid;\n\t} else {\n\t\t \n\t\tif (pci_dev->device < 0x1000 || pci_dev->device > 0x107f)\n\t\t\treturn -ENODEV;\n\n\t\tif (pci_dev->device < 0x1040) {\n\t\t\t \n\t\t\tmdev->id.device = pci_dev->subsystem_device;\n\t\t} else {\n\t\t\t \n\t\t\tmdev->id.device = pci_dev->device - 0x1040;\n\t\t}\n\t}\n\tmdev->id.vendor = pci_dev->subsystem_vendor;\n\n\t \n\tcommon = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_COMMON_CFG,\n\t\t\t\t\t    IORESOURCE_IO | IORESOURCE_MEM,\n\t\t\t\t\t    &mdev->modern_bars);\n\tif (!common) {\n\t\tdev_info(&pci_dev->dev,\n\t\t\t \"virtio_pci: leaving for legacy driver\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tisr = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_ISR_CFG,\n\t\t\t\t\t IORESOURCE_IO | IORESOURCE_MEM,\n\t\t\t\t\t &mdev->modern_bars);\n\tnotify = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_NOTIFY_CFG,\n\t\t\t\t\t    IORESOURCE_IO | IORESOURCE_MEM,\n\t\t\t\t\t    &mdev->modern_bars);\n\tif (!isr || !notify) {\n\t\tdev_err(&pci_dev->dev,\n\t\t\t\"virtio_pci: missing capabilities %i/%i/%i\\n\",\n\t\t\tcommon, isr, notify);\n\t\treturn -EINVAL;\n\t}\n\n\terr = dma_set_mask_and_coherent(&pci_dev->dev,\n\t\t\t\t\tmdev->dma_mask ? : DMA_BIT_MASK(64));\n\tif (err)\n\t\terr = dma_set_mask_and_coherent(&pci_dev->dev,\n\t\t\t\t\t\tDMA_BIT_MASK(32));\n\tif (err)\n\t\tdev_warn(&pci_dev->dev, \"Failed to enable 64-bit or 32-bit DMA.  Trying to continue, but this might not work.\\n\");\n\n\t \n\tdevice = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_DEVICE_CFG,\n\t\t\t\t\t    IORESOURCE_IO | IORESOURCE_MEM,\n\t\t\t\t\t    &mdev->modern_bars);\n\n\terr = pci_request_selected_regions(pci_dev, mdev->modern_bars,\n\t\t\t\t\t   \"virtio-pci-modern\");\n\tif (err)\n\t\treturn err;\n\n\terr = -EINVAL;\n\tmdev->common = vp_modern_map_capability(mdev, common,\n\t\t\t\t      sizeof(struct virtio_pci_common_cfg), 4,\n\t\t\t\t      0, sizeof(struct virtio_pci_modern_common_cfg),\n\t\t\t\t      NULL, NULL);\n\tif (!mdev->common)\n\t\tgoto err_map_common;\n\tmdev->isr = vp_modern_map_capability(mdev, isr, sizeof(u8), 1,\n\t\t\t\t\t     0, 1,\n\t\t\t\t\t     NULL, NULL);\n\tif (!mdev->isr)\n\t\tgoto err_map_isr;\n\n\t \n\tpci_read_config_dword(pci_dev,\n\t\t\t      notify + offsetof(struct virtio_pci_notify_cap,\n\t\t\t\t\t\tnotify_off_multiplier),\n\t\t\t      &mdev->notify_offset_multiplier);\n\t \n\tpci_read_config_dword(pci_dev,\n\t\t\t      notify + offsetof(struct virtio_pci_notify_cap,\n\t\t\t\t\t\tcap.length),\n\t\t\t      &notify_length);\n\n\tpci_read_config_dword(pci_dev,\n\t\t\t      notify + offsetof(struct virtio_pci_notify_cap,\n\t\t\t\t\t\tcap.offset),\n\t\t\t      &notify_offset);\n\n\t \n\tif ((u64)notify_length + (notify_offset % PAGE_SIZE) <= PAGE_SIZE) {\n\t\tmdev->notify_base = vp_modern_map_capability(mdev, notify,\n\t\t\t\t\t\t\t     2, 2,\n\t\t\t\t\t\t\t     0, notify_length,\n\t\t\t\t\t\t\t     &mdev->notify_len,\n\t\t\t\t\t\t\t     &mdev->notify_pa);\n\t\tif (!mdev->notify_base)\n\t\t\tgoto err_map_notify;\n\t} else {\n\t\tmdev->notify_map_cap = notify;\n\t}\n\n\t \n\tif (device) {\n\t\tmdev->device = vp_modern_map_capability(mdev, device, 0, 4,\n\t\t\t\t\t\t\t0, PAGE_SIZE,\n\t\t\t\t\t\t\t&mdev->device_len,\n\t\t\t\t\t\t\tNULL);\n\t\tif (!mdev->device)\n\t\t\tgoto err_map_device;\n\t}\n\n\treturn 0;\n\nerr_map_device:\n\tif (mdev->notify_base)\n\t\tpci_iounmap(pci_dev, mdev->notify_base);\nerr_map_notify:\n\tpci_iounmap(pci_dev, mdev->isr);\nerr_map_isr:\n\tpci_iounmap(pci_dev, mdev->common);\nerr_map_common:\n\tpci_release_selected_regions(pci_dev, mdev->modern_bars);\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(vp_modern_probe);\n\n \nvoid vp_modern_remove(struct virtio_pci_modern_device *mdev)\n{\n\tstruct pci_dev *pci_dev = mdev->pci_dev;\n\n\tif (mdev->device)\n\t\tpci_iounmap(pci_dev, mdev->device);\n\tif (mdev->notify_base)\n\t\tpci_iounmap(pci_dev, mdev->notify_base);\n\tpci_iounmap(pci_dev, mdev->isr);\n\tpci_iounmap(pci_dev, mdev->common);\n\tpci_release_selected_regions(pci_dev, mdev->modern_bars);\n}\nEXPORT_SYMBOL_GPL(vp_modern_remove);\n\n \nu64 vp_modern_get_features(struct virtio_pci_modern_device *mdev)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\tu64 features;\n\n\tvp_iowrite32(0, &cfg->device_feature_select);\n\tfeatures = vp_ioread32(&cfg->device_feature);\n\tvp_iowrite32(1, &cfg->device_feature_select);\n\tfeatures |= ((u64)vp_ioread32(&cfg->device_feature) << 32);\n\n\treturn features;\n}\nEXPORT_SYMBOL_GPL(vp_modern_get_features);\n\n \nu64 vp_modern_get_driver_features(struct virtio_pci_modern_device *mdev)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\tu64 features;\n\n\tvp_iowrite32(0, &cfg->guest_feature_select);\n\tfeatures = vp_ioread32(&cfg->guest_feature);\n\tvp_iowrite32(1, &cfg->guest_feature_select);\n\tfeatures |= ((u64)vp_ioread32(&cfg->guest_feature) << 32);\n\n\treturn features;\n}\nEXPORT_SYMBOL_GPL(vp_modern_get_driver_features);\n\n \nvoid vp_modern_set_features(struct virtio_pci_modern_device *mdev,\n\t\t\t    u64 features)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\tvp_iowrite32(0, &cfg->guest_feature_select);\n\tvp_iowrite32((u32)features, &cfg->guest_feature);\n\tvp_iowrite32(1, &cfg->guest_feature_select);\n\tvp_iowrite32(features >> 32, &cfg->guest_feature);\n}\nEXPORT_SYMBOL_GPL(vp_modern_set_features);\n\n \nu32 vp_modern_generation(struct virtio_pci_modern_device *mdev)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\treturn vp_ioread8(&cfg->config_generation);\n}\nEXPORT_SYMBOL_GPL(vp_modern_generation);\n\n \nu8 vp_modern_get_status(struct virtio_pci_modern_device *mdev)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\treturn vp_ioread8(&cfg->device_status);\n}\nEXPORT_SYMBOL_GPL(vp_modern_get_status);\n\n \nvoid vp_modern_set_status(struct virtio_pci_modern_device *mdev,\n\t\t\t\t u8 status)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\t \n\tvp_iowrite8(status, &cfg->device_status);\n}\nEXPORT_SYMBOL_GPL(vp_modern_set_status);\n\n \nint vp_modern_get_queue_reset(struct virtio_pci_modern_device *mdev, u16 index)\n{\n\tstruct virtio_pci_modern_common_cfg __iomem *cfg;\n\n\tcfg = (struct virtio_pci_modern_common_cfg __iomem *)mdev->common;\n\n\tvp_iowrite16(index, &cfg->cfg.queue_select);\n\treturn vp_ioread16(&cfg->queue_reset);\n}\nEXPORT_SYMBOL_GPL(vp_modern_get_queue_reset);\n\n \nvoid vp_modern_set_queue_reset(struct virtio_pci_modern_device *mdev, u16 index)\n{\n\tstruct virtio_pci_modern_common_cfg __iomem *cfg;\n\n\tcfg = (struct virtio_pci_modern_common_cfg __iomem *)mdev->common;\n\n\tvp_iowrite16(index, &cfg->cfg.queue_select);\n\tvp_iowrite16(1, &cfg->queue_reset);\n\n\twhile (vp_ioread16(&cfg->queue_reset))\n\t\tmsleep(1);\n\n\twhile (vp_ioread16(&cfg->cfg.queue_enable))\n\t\tmsleep(1);\n}\nEXPORT_SYMBOL_GPL(vp_modern_set_queue_reset);\n\n \nu16 vp_modern_queue_vector(struct virtio_pci_modern_device *mdev,\n\t\t\t   u16 index, u16 vector)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\tvp_iowrite16(index, &cfg->queue_select);\n\tvp_iowrite16(vector, &cfg->queue_msix_vector);\n\t \n\treturn vp_ioread16(&cfg->queue_msix_vector);\n}\nEXPORT_SYMBOL_GPL(vp_modern_queue_vector);\n\n \nu16 vp_modern_config_vector(struct virtio_pci_modern_device *mdev,\n\t\t\t    u16 vector)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\t \n\tvp_iowrite16(vector, &cfg->msix_config);\n\t \n\t \n\treturn vp_ioread16(&cfg->msix_config);\n}\nEXPORT_SYMBOL_GPL(vp_modern_config_vector);\n\n \nvoid vp_modern_queue_address(struct virtio_pci_modern_device *mdev,\n\t\t\t     u16 index, u64 desc_addr, u64 driver_addr,\n\t\t\t     u64 device_addr)\n{\n\tstruct virtio_pci_common_cfg __iomem *cfg = mdev->common;\n\n\tvp_iowrite16(index, &cfg->queue_select);\n\n\tvp_iowrite64_twopart(desc_addr, &cfg->queue_desc_lo,\n\t\t\t     &cfg->queue_desc_hi);\n\tvp_iowrite64_twopart(driver_addr, &cfg->queue_avail_lo,\n\t\t\t     &cfg->queue_avail_hi);\n\tvp_iowrite64_twopart(device_addr, &cfg->queue_used_lo,\n\t\t\t     &cfg->queue_used_hi);\n}\nEXPORT_SYMBOL_GPL(vp_modern_queue_address);\n\n \nvoid vp_modern_set_queue_enable(struct virtio_pci_modern_device *mdev,\n\t\t\t\tu16 index, bool enable)\n{\n\tvp_iowrite16(index, &mdev->common->queue_select);\n\tvp_iowrite16(enable, &mdev->common->queue_enable);\n}\nEXPORT_SYMBOL_GPL(vp_modern_set_queue_enable);\n\n \nbool vp_modern_get_queue_enable(struct virtio_pci_modern_device *mdev,\n\t\t\t\tu16 index)\n{\n\tvp_iowrite16(index, &mdev->common->queue_select);\n\n\treturn vp_ioread16(&mdev->common->queue_enable);\n}\nEXPORT_SYMBOL_GPL(vp_modern_get_queue_enable);\n\n \nvoid vp_modern_set_queue_size(struct virtio_pci_modern_device *mdev,\n\t\t\t      u16 index, u16 size)\n{\n\tvp_iowrite16(index, &mdev->common->queue_select);\n\tvp_iowrite16(size, &mdev->common->queue_size);\n\n}\nEXPORT_SYMBOL_GPL(vp_modern_set_queue_size);\n\n \nu16 vp_modern_get_queue_size(struct virtio_pci_modern_device *mdev,\n\t\t\t     u16 index)\n{\n\tvp_iowrite16(index, &mdev->common->queue_select);\n\n\treturn vp_ioread16(&mdev->common->queue_size);\n\n}\nEXPORT_SYMBOL_GPL(vp_modern_get_queue_size);\n\n \nu16 vp_modern_get_num_queues(struct virtio_pci_modern_device *mdev)\n{\n\treturn vp_ioread16(&mdev->common->num_queues);\n}\nEXPORT_SYMBOL_GPL(vp_modern_get_num_queues);\n\n \nstatic u16 vp_modern_get_queue_notify_off(struct virtio_pci_modern_device *mdev,\n\t\t\t\t\t  u16 index)\n{\n\tvp_iowrite16(index, &mdev->common->queue_select);\n\n\treturn vp_ioread16(&mdev->common->queue_notify_off);\n}\n\n \nvoid __iomem *vp_modern_map_vq_notify(struct virtio_pci_modern_device *mdev,\n\t\t\t\t      u16 index, resource_size_t *pa)\n{\n\tu16 off = vp_modern_get_queue_notify_off(mdev, index);\n\n\tif (mdev->notify_base) {\n\t\t \n\t\tif ((u64)off * mdev->notify_offset_multiplier + 2\n\t\t\t> mdev->notify_len) {\n\t\t\tdev_warn(&mdev->pci_dev->dev,\n\t\t\t\t \"bad notification offset %u (x %u) \"\n\t\t\t\t \"for queue %u > %zd\",\n\t\t\t\t off, mdev->notify_offset_multiplier,\n\t\t\t\t index, mdev->notify_len);\n\t\t\treturn NULL;\n\t\t}\n\t\tif (pa)\n\t\t\t*pa = mdev->notify_pa +\n\t\t\t      off * mdev->notify_offset_multiplier;\n\t\treturn mdev->notify_base + off * mdev->notify_offset_multiplier;\n\t} else {\n\t\treturn vp_modern_map_capability(mdev,\n\t\t\t\t       mdev->notify_map_cap, 2, 2,\n\t\t\t\t       off * mdev->notify_offset_multiplier, 2,\n\t\t\t\t       NULL, pa);\n\t}\n}\nEXPORT_SYMBOL_GPL(vp_modern_map_vq_notify);\n\nMODULE_VERSION(\"0.1\");\nMODULE_DESCRIPTION(\"Modern Virtio PCI Device\");\nMODULE_AUTHOR(\"Jason Wang <jasowang@redhat.com>\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}