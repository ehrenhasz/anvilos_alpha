{
  "module_name": "virtio_pci_modern.c",
  "hash_id": "e372937e7c4c9528e8e28b88064f52875f404bf14272f6eb7fc81487ecd4ec93",
  "original_prompt": "Ingested from linux-6.6.14/drivers/virtio/virtio_pci_modern.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#define VIRTIO_PCI_NO_LEGACY\n#define VIRTIO_RING_NO_LEGACY\n#include \"virtio_pci_common.h\"\n\nstatic u64 vp_get_features(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\n\treturn vp_modern_get_features(&vp_dev->mdev);\n}\n\nstatic void vp_transport_features(struct virtio_device *vdev, u64 features)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct pci_dev *pci_dev = vp_dev->pci_dev;\n\n\tif ((features & BIT_ULL(VIRTIO_F_SR_IOV)) &&\n\t\t\tpci_find_ext_capability(pci_dev, PCI_EXT_CAP_ID_SRIOV))\n\t\t__virtio_set_bit(vdev, VIRTIO_F_SR_IOV);\n\n\tif (features & BIT_ULL(VIRTIO_F_RING_RESET))\n\t\t__virtio_set_bit(vdev, VIRTIO_F_RING_RESET);\n}\n\n \nstatic int vp_finalize_features(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tu64 features = vdev->features;\n\n\t \n\tvring_transport_features(vdev);\n\n\t \n\tvp_transport_features(vdev, features);\n\n\tif (!__virtio_test_bit(vdev, VIRTIO_F_VERSION_1)) {\n\t\tdev_err(&vdev->dev, \"virtio: device uses modern interface \"\n\t\t\t\"but does not have VIRTIO_F_VERSION_1\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tvp_modern_set_features(&vp_dev->mdev, vdev->features);\n\n\treturn 0;\n}\n\n \nstatic void vp_get(struct virtio_device *vdev, unsigned int offset,\n\t\t   void *buf, unsigned int len)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\tvoid __iomem *device = mdev->device;\n\tu8 b;\n\t__le16 w;\n\t__le32 l;\n\n\tBUG_ON(offset + len > mdev->device_len);\n\n\tswitch (len) {\n\tcase 1:\n\t\tb = ioread8(device + offset);\n\t\tmemcpy(buf, &b, sizeof b);\n\t\tbreak;\n\tcase 2:\n\t\tw = cpu_to_le16(ioread16(device + offset));\n\t\tmemcpy(buf, &w, sizeof w);\n\t\tbreak;\n\tcase 4:\n\t\tl = cpu_to_le32(ioread32(device + offset));\n\t\tmemcpy(buf, &l, sizeof l);\n\t\tbreak;\n\tcase 8:\n\t\tl = cpu_to_le32(ioread32(device + offset));\n\t\tmemcpy(buf, &l, sizeof l);\n\t\tl = cpu_to_le32(ioread32(device + offset + sizeof l));\n\t\tmemcpy(buf + sizeof l, &l, sizeof l);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\n \nstatic void vp_set(struct virtio_device *vdev, unsigned int offset,\n\t\t   const void *buf, unsigned int len)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\tvoid __iomem *device = mdev->device;\n\tu8 b;\n\t__le16 w;\n\t__le32 l;\n\n\tBUG_ON(offset + len > mdev->device_len);\n\n\tswitch (len) {\n\tcase 1:\n\t\tmemcpy(&b, buf, sizeof b);\n\t\tiowrite8(b, device + offset);\n\t\tbreak;\n\tcase 2:\n\t\tmemcpy(&w, buf, sizeof w);\n\t\tiowrite16(le16_to_cpu(w), device + offset);\n\t\tbreak;\n\tcase 4:\n\t\tmemcpy(&l, buf, sizeof l);\n\t\tiowrite32(le32_to_cpu(l), device + offset);\n\t\tbreak;\n\tcase 8:\n\t\tmemcpy(&l, buf, sizeof l);\n\t\tiowrite32(le32_to_cpu(l), device + offset);\n\t\tmemcpy(&l, buf + sizeof l, sizeof l);\n\t\tiowrite32(le32_to_cpu(l), device + offset + sizeof l);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n}\n\nstatic u32 vp_generation(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\n\treturn vp_modern_generation(&vp_dev->mdev);\n}\n\n \nstatic u8 vp_get_status(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\n\treturn vp_modern_get_status(&vp_dev->mdev);\n}\n\nstatic void vp_set_status(struct virtio_device *vdev, u8 status)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\n\t \n\tBUG_ON(status == 0);\n\tvp_modern_set_status(&vp_dev->mdev, status);\n}\n\nstatic void vp_reset(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\n\t \n\tvp_modern_set_status(mdev, 0);\n\t \n\twhile (vp_modern_get_status(mdev))\n\t\tmsleep(1);\n\t \n\tvp_synchronize_vectors(vdev);\n}\n\nstatic int vp_active_vq(struct virtqueue *vq, u16 msix_vec)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\tunsigned long index;\n\n\tindex = vq->index;\n\n\t \n\tvp_modern_set_queue_size(mdev, index, virtqueue_get_vring_size(vq));\n\tvp_modern_queue_address(mdev, index, virtqueue_get_desc_addr(vq),\n\t\t\t\tvirtqueue_get_avail_addr(vq),\n\t\t\t\tvirtqueue_get_used_addr(vq));\n\n\tif (msix_vec != VIRTIO_MSI_NO_VECTOR) {\n\t\tmsix_vec = vp_modern_queue_vector(mdev, index, msix_vec);\n\t\tif (msix_vec == VIRTIO_MSI_NO_VECTOR)\n\t\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\nstatic int vp_modern_disable_vq_and_reset(struct virtqueue *vq)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\tstruct virtio_pci_vq_info *info;\n\tunsigned long flags;\n\n\tif (!virtio_has_feature(vq->vdev, VIRTIO_F_RING_RESET))\n\t\treturn -ENOENT;\n\n\tvp_modern_set_queue_reset(mdev, vq->index);\n\n\tinfo = vp_dev->vqs[vq->index];\n\n\t \n\tspin_lock_irqsave(&vp_dev->lock, flags);\n\tlist_del(&info->node);\n\tspin_unlock_irqrestore(&vp_dev->lock, flags);\n\n\tINIT_LIST_HEAD(&info->node);\n\n#ifdef CONFIG_VIRTIO_HARDEN_NOTIFICATION\n\t__virtqueue_break(vq);\n#endif\n\n\t \n\tif (vp_dev->per_vq_vectors && info->msix_vector != VIRTIO_MSI_NO_VECTOR)\n\t\tsynchronize_irq(pci_irq_vector(vp_dev->pci_dev, info->msix_vector));\n\n\tvq->reset = true;\n\n\treturn 0;\n}\n\nstatic int vp_modern_enable_vq_after_reset(struct virtqueue *vq)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\tstruct virtio_pci_vq_info *info;\n\tunsigned long flags, index;\n\tint err;\n\n\tif (!vq->reset)\n\t\treturn -EBUSY;\n\n\tindex = vq->index;\n\tinfo = vp_dev->vqs[index];\n\n\tif (vp_modern_get_queue_reset(mdev, index))\n\t\treturn -EBUSY;\n\n\tif (vp_modern_get_queue_enable(mdev, index))\n\t\treturn -EBUSY;\n\n\terr = vp_active_vq(vq, info->msix_vector);\n\tif (err)\n\t\treturn err;\n\n\tif (vq->callback) {\n\t\tspin_lock_irqsave(&vp_dev->lock, flags);\n\t\tlist_add(&info->node, &vp_dev->virtqueues);\n\t\tspin_unlock_irqrestore(&vp_dev->lock, flags);\n\t} else {\n\t\tINIT_LIST_HEAD(&info->node);\n\t}\n\n#ifdef CONFIG_VIRTIO_HARDEN_NOTIFICATION\n\t__virtqueue_unbreak(vq);\n#endif\n\n\tvp_modern_set_queue_enable(&vp_dev->mdev, index, true);\n\tvq->reset = false;\n\n\treturn 0;\n}\n\nstatic u16 vp_config_vector(struct virtio_pci_device *vp_dev, u16 vector)\n{\n\treturn vp_modern_config_vector(&vp_dev->mdev, vector);\n}\n\nstatic bool vp_notify_with_data(struct virtqueue *vq)\n{\n\tu32 data = vring_notification_data(vq);\n\n\tiowrite32(data, (void __iomem *)vq->priv);\n\n\treturn true;\n}\n\nstatic struct virtqueue *setup_vq(struct virtio_pci_device *vp_dev,\n\t\t\t\t  struct virtio_pci_vq_info *info,\n\t\t\t\t  unsigned int index,\n\t\t\t\t  void (*callback)(struct virtqueue *vq),\n\t\t\t\t  const char *name,\n\t\t\t\t  bool ctx,\n\t\t\t\t  u16 msix_vec)\n{\n\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\tbool (*notify)(struct virtqueue *vq);\n\tstruct virtqueue *vq;\n\tu16 num;\n\tint err;\n\n\tif (__virtio_test_bit(&vp_dev->vdev, VIRTIO_F_NOTIFICATION_DATA))\n\t\tnotify = vp_notify_with_data;\n\telse\n\t\tnotify = vp_notify;\n\n\tif (index >= vp_modern_get_num_queues(mdev))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t \n\tnum = vp_modern_get_queue_size(mdev, index);\n\tif (!num || vp_modern_get_queue_enable(mdev, index))\n\t\treturn ERR_PTR(-ENOENT);\n\n\tinfo->msix_vector = msix_vec;\n\n\t \n\tvq = vring_create_virtqueue(index, num,\n\t\t\t\t    SMP_CACHE_BYTES, &vp_dev->vdev,\n\t\t\t\t    true, true, ctx,\n\t\t\t\t    notify, callback, name);\n\tif (!vq)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tvq->num_max = num;\n\n\terr = vp_active_vq(vq, msix_vec);\n\tif (err)\n\t\tgoto err;\n\n\tvq->priv = (void __force *)vp_modern_map_vq_notify(mdev, index, NULL);\n\tif (!vq->priv) {\n\t\terr = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\treturn vq;\n\nerr:\n\tvring_del_virtqueue(vq);\n\treturn ERR_PTR(err);\n}\n\nstatic int vp_modern_find_vqs(struct virtio_device *vdev, unsigned int nvqs,\n\t\t\t      struct virtqueue *vqs[],\n\t\t\t      vq_callback_t *callbacks[],\n\t\t\t      const char * const names[], const bool *ctx,\n\t\t\t      struct irq_affinity *desc)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct virtqueue *vq;\n\tint rc = vp_find_vqs(vdev, nvqs, vqs, callbacks, names, ctx, desc);\n\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tlist_for_each_entry(vq, &vdev->vqs, list)\n\t\tvp_modern_set_queue_enable(&vp_dev->mdev, vq->index, true);\n\n\treturn 0;\n}\n\nstatic void del_vq(struct virtio_pci_vq_info *info)\n{\n\tstruct virtqueue *vq = info->vq;\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\n\tif (vp_dev->msix_enabled)\n\t\tvp_modern_queue_vector(mdev, vq->index,\n\t\t\t\t       VIRTIO_MSI_NO_VECTOR);\n\n\tif (!mdev->notify_base)\n\t\tpci_iounmap(mdev->pci_dev, (void __force __iomem *)vq->priv);\n\n\tvring_del_virtqueue(vq);\n}\n\nstatic int virtio_pci_find_shm_cap(struct pci_dev *dev, u8 required_id,\n\t\t\t\t   u8 *bar, u64 *offset, u64 *len)\n{\n\tint pos;\n\n\tfor (pos = pci_find_capability(dev, PCI_CAP_ID_VNDR); pos > 0;\n\t     pos = pci_find_next_capability(dev, pos, PCI_CAP_ID_VNDR)) {\n\t\tu8 type, cap_len, id, res_bar;\n\t\tu32 tmp32;\n\t\tu64 res_offset, res_length;\n\n\t\tpci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t cfg_type), &type);\n\t\tif (type != VIRTIO_PCI_CAP_SHARED_MEMORY_CFG)\n\t\t\tcontinue;\n\n\t\tpci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t cap_len), &cap_len);\n\t\tif (cap_len != sizeof(struct virtio_pci_cap64)) {\n\t\t\tdev_err(&dev->dev, \"%s: shm cap with bad size offset:\"\n\t\t\t\t\" %d size: %d\\n\", __func__, pos, cap_len);\n\t\t\tcontinue;\n\t\t}\n\n\t\tpci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t id), &id);\n\t\tif (id != required_id)\n\t\t\tcontinue;\n\n\t\tpci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t bar), &res_bar);\n\t\tif (res_bar >= PCI_STD_NUM_BARS)\n\t\t\tcontinue;\n\n\t\t \n\n\t\t \n\t\tpci_read_config_dword(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t  offset), &tmp32);\n\t\tres_offset = tmp32;\n\t\tpci_read_config_dword(dev, pos + offsetof(struct virtio_pci_cap,\n\t\t\t\t\t\t\t  length), &tmp32);\n\t\tres_length = tmp32;\n\n\t\t \n\t\tpci_read_config_dword(dev,\n\t\t\t\t      pos + offsetof(struct virtio_pci_cap64,\n\t\t\t\t\t\t     offset_hi), &tmp32);\n\t\tres_offset |= ((u64)tmp32) << 32;\n\t\tpci_read_config_dword(dev,\n\t\t\t\t      pos + offsetof(struct virtio_pci_cap64,\n\t\t\t\t\t\t     length_hi), &tmp32);\n\t\tres_length |= ((u64)tmp32) << 32;\n\n\t\t*bar = res_bar;\n\t\t*offset = res_offset;\n\t\t*len = res_length;\n\n\t\treturn pos;\n\t}\n\treturn 0;\n}\n\nstatic bool vp_get_shm_region(struct virtio_device *vdev,\n\t\t\t      struct virtio_shm_region *region, u8 id)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct pci_dev *pci_dev = vp_dev->pci_dev;\n\tu8 bar;\n\tu64 offset, len;\n\tphys_addr_t phys_addr;\n\tsize_t bar_len;\n\n\tif (!virtio_pci_find_shm_cap(pci_dev, id, &bar, &offset, &len))\n\t\treturn false;\n\n\tphys_addr = pci_resource_start(pci_dev, bar);\n\tbar_len = pci_resource_len(pci_dev, bar);\n\n\tif ((offset + len) < offset) {\n\t\tdev_err(&pci_dev->dev, \"%s: cap offset+len overflow detected\\n\",\n\t\t\t__func__);\n\t\treturn false;\n\t}\n\n\tif (offset + len > bar_len) {\n\t\tdev_err(&pci_dev->dev, \"%s: bar shorter than cap offset+len\\n\",\n\t\t\t__func__);\n\t\treturn false;\n\t}\n\n\tregion->len = len;\n\tregion->addr = (u64) phys_addr + offset;\n\n\treturn true;\n}\n\nstatic const struct virtio_config_ops virtio_pci_config_nodev_ops = {\n\t.get\t\t= NULL,\n\t.set\t\t= NULL,\n\t.generation\t= vp_generation,\n\t.get_status\t= vp_get_status,\n\t.set_status\t= vp_set_status,\n\t.reset\t\t= vp_reset,\n\t.find_vqs\t= vp_modern_find_vqs,\n\t.del_vqs\t= vp_del_vqs,\n\t.synchronize_cbs = vp_synchronize_vectors,\n\t.get_features\t= vp_get_features,\n\t.finalize_features = vp_finalize_features,\n\t.bus_name\t= vp_bus_name,\n\t.set_vq_affinity = vp_set_vq_affinity,\n\t.get_vq_affinity = vp_get_vq_affinity,\n\t.get_shm_region  = vp_get_shm_region,\n\t.disable_vq_and_reset = vp_modern_disable_vq_and_reset,\n\t.enable_vq_after_reset = vp_modern_enable_vq_after_reset,\n};\n\nstatic const struct virtio_config_ops virtio_pci_config_ops = {\n\t.get\t\t= vp_get,\n\t.set\t\t= vp_set,\n\t.generation\t= vp_generation,\n\t.get_status\t= vp_get_status,\n\t.set_status\t= vp_set_status,\n\t.reset\t\t= vp_reset,\n\t.find_vqs\t= vp_modern_find_vqs,\n\t.del_vqs\t= vp_del_vqs,\n\t.synchronize_cbs = vp_synchronize_vectors,\n\t.get_features\t= vp_get_features,\n\t.finalize_features = vp_finalize_features,\n\t.bus_name\t= vp_bus_name,\n\t.set_vq_affinity = vp_set_vq_affinity,\n\t.get_vq_affinity = vp_get_vq_affinity,\n\t.get_shm_region  = vp_get_shm_region,\n\t.disable_vq_and_reset = vp_modern_disable_vq_and_reset,\n\t.enable_vq_after_reset = vp_modern_enable_vq_after_reset,\n};\n\n \nint virtio_pci_modern_probe(struct virtio_pci_device *vp_dev)\n{\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\tstruct pci_dev *pci_dev = vp_dev->pci_dev;\n\tint err;\n\n\tmdev->pci_dev = pci_dev;\n\n\terr = vp_modern_probe(mdev);\n\tif (err)\n\t\treturn err;\n\n\tif (mdev->device)\n\t\tvp_dev->vdev.config = &virtio_pci_config_ops;\n\telse\n\t\tvp_dev->vdev.config = &virtio_pci_config_nodev_ops;\n\n\tvp_dev->config_vector = vp_config_vector;\n\tvp_dev->setup_vq = setup_vq;\n\tvp_dev->del_vq = del_vq;\n\tvp_dev->isr = mdev->isr;\n\tvp_dev->vdev.id = mdev->id;\n\n\treturn 0;\n}\n\nvoid virtio_pci_modern_remove(struct virtio_pci_device *vp_dev)\n{\n\tstruct virtio_pci_modern_device *mdev = &vp_dev->mdev;\n\n\tvp_modern_remove(mdev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}