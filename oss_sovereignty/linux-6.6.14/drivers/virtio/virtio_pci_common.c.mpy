{
  "module_name": "virtio_pci_common.c",
  "hash_id": "cc67632c3c52ef7dfedd81021d9949859d80d24424b340727c5ba59f76f4a120",
  "original_prompt": "Ingested from linux-6.6.14/drivers/virtio/virtio_pci_common.c",
  "human_readable_source": "\n \n\n#include \"virtio_pci_common.h\"\n\nstatic bool force_legacy = false;\n\n#if IS_ENABLED(CONFIG_VIRTIO_PCI_LEGACY)\nmodule_param(force_legacy, bool, 0444);\nMODULE_PARM_DESC(force_legacy,\n\t\t \"Force legacy mode for transitional virtio 1 devices\");\n#endif\n\n \nvoid vp_synchronize_vectors(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tint i;\n\n\tif (vp_dev->intx_enabled)\n\t\tsynchronize_irq(vp_dev->pci_dev->irq);\n\n\tfor (i = 0; i < vp_dev->msix_vectors; ++i)\n\t\tsynchronize_irq(pci_irq_vector(vp_dev->pci_dev, i));\n}\n\n \nbool vp_notify(struct virtqueue *vq)\n{\n\t \n\tiowrite16(vq->index, (void __iomem *)vq->priv);\n\treturn true;\n}\n\n \nstatic irqreturn_t vp_config_changed(int irq, void *opaque)\n{\n\tstruct virtio_pci_device *vp_dev = opaque;\n\n\tvirtio_config_changed(&vp_dev->vdev);\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t vp_vring_interrupt(int irq, void *opaque)\n{\n\tstruct virtio_pci_device *vp_dev = opaque;\n\tstruct virtio_pci_vq_info *info;\n\tirqreturn_t ret = IRQ_NONE;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&vp_dev->lock, flags);\n\tlist_for_each_entry(info, &vp_dev->virtqueues, node) {\n\t\tif (vring_interrupt(irq, info->vq) == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tspin_unlock_irqrestore(&vp_dev->lock, flags);\n\n\treturn ret;\n}\n\n \nstatic irqreturn_t vp_interrupt(int irq, void *opaque)\n{\n\tstruct virtio_pci_device *vp_dev = opaque;\n\tu8 isr;\n\n\t \n\tisr = ioread8(vp_dev->isr);\n\n\t \n\tif (!isr)\n\t\treturn IRQ_NONE;\n\n\t \n\tif (isr & VIRTIO_PCI_ISR_CONFIG)\n\t\tvp_config_changed(irq, opaque);\n\n\treturn vp_vring_interrupt(irq, opaque);\n}\n\nstatic int vp_request_msix_vectors(struct virtio_device *vdev, int nvectors,\n\t\t\t\t   bool per_vq_vectors, struct irq_affinity *desc)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tconst char *name = dev_name(&vp_dev->vdev.dev);\n\tunsigned int flags = PCI_IRQ_MSIX;\n\tunsigned int i, v;\n\tint err = -ENOMEM;\n\n\tvp_dev->msix_vectors = nvectors;\n\n\tvp_dev->msix_names = kmalloc_array(nvectors,\n\t\t\t\t\t   sizeof(*vp_dev->msix_names),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!vp_dev->msix_names)\n\t\tgoto error;\n\tvp_dev->msix_affinity_masks\n\t\t= kcalloc(nvectors, sizeof(*vp_dev->msix_affinity_masks),\n\t\t\t  GFP_KERNEL);\n\tif (!vp_dev->msix_affinity_masks)\n\t\tgoto error;\n\tfor (i = 0; i < nvectors; ++i)\n\t\tif (!alloc_cpumask_var(&vp_dev->msix_affinity_masks[i],\n\t\t\t\t\tGFP_KERNEL))\n\t\t\tgoto error;\n\n\tif (desc) {\n\t\tflags |= PCI_IRQ_AFFINITY;\n\t\tdesc->pre_vectors++;  \n\t}\n\n\terr = pci_alloc_irq_vectors_affinity(vp_dev->pci_dev, nvectors,\n\t\t\t\t\t     nvectors, flags, desc);\n\tif (err < 0)\n\t\tgoto error;\n\tvp_dev->msix_enabled = 1;\n\n\t \n\tv = vp_dev->msix_used_vectors;\n\tsnprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,\n\t\t \"%s-config\", name);\n\terr = request_irq(pci_irq_vector(vp_dev->pci_dev, v),\n\t\t\t  vp_config_changed, 0, vp_dev->msix_names[v],\n\t\t\t  vp_dev);\n\tif (err)\n\t\tgoto error;\n\t++vp_dev->msix_used_vectors;\n\n\tv = vp_dev->config_vector(vp_dev, v);\n\t \n\tif (v == VIRTIO_MSI_NO_VECTOR) {\n\t\terr = -EBUSY;\n\t\tgoto error;\n\t}\n\n\tif (!per_vq_vectors) {\n\t\t \n\t\tv = vp_dev->msix_used_vectors;\n\t\tsnprintf(vp_dev->msix_names[v], sizeof *vp_dev->msix_names,\n\t\t\t \"%s-virtqueues\", name);\n\t\terr = request_irq(pci_irq_vector(vp_dev->pci_dev, v),\n\t\t\t\t  vp_vring_interrupt, 0, vp_dev->msix_names[v],\n\t\t\t\t  vp_dev);\n\t\tif (err)\n\t\t\tgoto error;\n\t\t++vp_dev->msix_used_vectors;\n\t}\n\treturn 0;\nerror:\n\treturn err;\n}\n\nstatic struct virtqueue *vp_setup_vq(struct virtio_device *vdev, unsigned int index,\n\t\t\t\t     void (*callback)(struct virtqueue *vq),\n\t\t\t\t     const char *name,\n\t\t\t\t     bool ctx,\n\t\t\t\t     u16 msix_vec)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct virtio_pci_vq_info *info = kmalloc(sizeof *info, GFP_KERNEL);\n\tstruct virtqueue *vq;\n\tunsigned long flags;\n\n\t \n\tif (!info)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tvq = vp_dev->setup_vq(vp_dev, info, index, callback, name, ctx,\n\t\t\t      msix_vec);\n\tif (IS_ERR(vq))\n\t\tgoto out_info;\n\n\tinfo->vq = vq;\n\tif (callback) {\n\t\tspin_lock_irqsave(&vp_dev->lock, flags);\n\t\tlist_add(&info->node, &vp_dev->virtqueues);\n\t\tspin_unlock_irqrestore(&vp_dev->lock, flags);\n\t} else {\n\t\tINIT_LIST_HEAD(&info->node);\n\t}\n\n\tvp_dev->vqs[index] = info;\n\treturn vq;\n\nout_info:\n\tkfree(info);\n\treturn vq;\n}\n\nstatic void vp_del_vq(struct virtqueue *vq)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\n\tstruct virtio_pci_vq_info *info = vp_dev->vqs[vq->index];\n\tunsigned long flags;\n\n\t \n\tif (!vq->reset) {\n\t\tspin_lock_irqsave(&vp_dev->lock, flags);\n\t\tlist_del(&info->node);\n\t\tspin_unlock_irqrestore(&vp_dev->lock, flags);\n\t}\n\n\tvp_dev->del_vq(info);\n\tkfree(info);\n}\n\n \nvoid vp_del_vqs(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct virtqueue *vq, *n;\n\tint i;\n\n\tlist_for_each_entry_safe(vq, n, &vdev->vqs, list) {\n\t\tif (vp_dev->per_vq_vectors) {\n\t\t\tint v = vp_dev->vqs[vq->index]->msix_vector;\n\n\t\t\tif (v != VIRTIO_MSI_NO_VECTOR) {\n\t\t\t\tint irq = pci_irq_vector(vp_dev->pci_dev, v);\n\n\t\t\t\tirq_set_affinity_hint(irq, NULL);\n\t\t\t\tfree_irq(irq, vq);\n\t\t\t}\n\t\t}\n\t\tvp_del_vq(vq);\n\t}\n\tvp_dev->per_vq_vectors = false;\n\n\tif (vp_dev->intx_enabled) {\n\t\tfree_irq(vp_dev->pci_dev->irq, vp_dev);\n\t\tvp_dev->intx_enabled = 0;\n\t}\n\n\tfor (i = 0; i < vp_dev->msix_used_vectors; ++i)\n\t\tfree_irq(pci_irq_vector(vp_dev->pci_dev, i), vp_dev);\n\n\tif (vp_dev->msix_affinity_masks) {\n\t\tfor (i = 0; i < vp_dev->msix_vectors; i++)\n\t\t\tfree_cpumask_var(vp_dev->msix_affinity_masks[i]);\n\t}\n\n\tif (vp_dev->msix_enabled) {\n\t\t \n\t\tvp_dev->config_vector(vp_dev, VIRTIO_MSI_NO_VECTOR);\n\n\t\tpci_free_irq_vectors(vp_dev->pci_dev);\n\t\tvp_dev->msix_enabled = 0;\n\t}\n\n\tvp_dev->msix_vectors = 0;\n\tvp_dev->msix_used_vectors = 0;\n\tkfree(vp_dev->msix_names);\n\tvp_dev->msix_names = NULL;\n\tkfree(vp_dev->msix_affinity_masks);\n\tvp_dev->msix_affinity_masks = NULL;\n\tkfree(vp_dev->vqs);\n\tvp_dev->vqs = NULL;\n}\n\nstatic int vp_find_vqs_msix(struct virtio_device *vdev, unsigned int nvqs,\n\t\tstruct virtqueue *vqs[], vq_callback_t *callbacks[],\n\t\tconst char * const names[], bool per_vq_vectors,\n\t\tconst bool *ctx,\n\t\tstruct irq_affinity *desc)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tu16 msix_vec;\n\tint i, err, nvectors, allocated_vectors, queue_idx = 0;\n\n\tvp_dev->vqs = kcalloc(nvqs, sizeof(*vp_dev->vqs), GFP_KERNEL);\n\tif (!vp_dev->vqs)\n\t\treturn -ENOMEM;\n\n\tif (per_vq_vectors) {\n\t\t \n\t\tnvectors = 1;\n\t\tfor (i = 0; i < nvqs; ++i)\n\t\t\tif (names[i] && callbacks[i])\n\t\t\t\t++nvectors;\n\t} else {\n\t\t \n\t\tnvectors = 2;\n\t}\n\n\terr = vp_request_msix_vectors(vdev, nvectors, per_vq_vectors,\n\t\t\t\t      per_vq_vectors ? desc : NULL);\n\tif (err)\n\t\tgoto error_find;\n\n\tvp_dev->per_vq_vectors = per_vq_vectors;\n\tallocated_vectors = vp_dev->msix_used_vectors;\n\tfor (i = 0; i < nvqs; ++i) {\n\t\tif (!names[i]) {\n\t\t\tvqs[i] = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!callbacks[i])\n\t\t\tmsix_vec = VIRTIO_MSI_NO_VECTOR;\n\t\telse if (vp_dev->per_vq_vectors)\n\t\t\tmsix_vec = allocated_vectors++;\n\t\telse\n\t\t\tmsix_vec = VP_MSIX_VQ_VECTOR;\n\t\tvqs[i] = vp_setup_vq(vdev, queue_idx++, callbacks[i], names[i],\n\t\t\t\t     ctx ? ctx[i] : false,\n\t\t\t\t     msix_vec);\n\t\tif (IS_ERR(vqs[i])) {\n\t\t\terr = PTR_ERR(vqs[i]);\n\t\t\tgoto error_find;\n\t\t}\n\n\t\tif (!vp_dev->per_vq_vectors || msix_vec == VIRTIO_MSI_NO_VECTOR)\n\t\t\tcontinue;\n\n\t\t \n\t\tsnprintf(vp_dev->msix_names[msix_vec],\n\t\t\t sizeof *vp_dev->msix_names,\n\t\t\t \"%s-%s\",\n\t\t\t dev_name(&vp_dev->vdev.dev), names[i]);\n\t\terr = request_irq(pci_irq_vector(vp_dev->pci_dev, msix_vec),\n\t\t\t\t  vring_interrupt, 0,\n\t\t\t\t  vp_dev->msix_names[msix_vec],\n\t\t\t\t  vqs[i]);\n\t\tif (err)\n\t\t\tgoto error_find;\n\t}\n\treturn 0;\n\nerror_find:\n\tvp_del_vqs(vdev);\n\treturn err;\n}\n\nstatic int vp_find_vqs_intx(struct virtio_device *vdev, unsigned int nvqs,\n\t\tstruct virtqueue *vqs[], vq_callback_t *callbacks[],\n\t\tconst char * const names[], const bool *ctx)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tint i, err, queue_idx = 0;\n\n\tvp_dev->vqs = kcalloc(nvqs, sizeof(*vp_dev->vqs), GFP_KERNEL);\n\tif (!vp_dev->vqs)\n\t\treturn -ENOMEM;\n\n\terr = request_irq(vp_dev->pci_dev->irq, vp_interrupt, IRQF_SHARED,\n\t\t\tdev_name(&vdev->dev), vp_dev);\n\tif (err)\n\t\tgoto out_del_vqs;\n\n\tvp_dev->intx_enabled = 1;\n\tvp_dev->per_vq_vectors = false;\n\tfor (i = 0; i < nvqs; ++i) {\n\t\tif (!names[i]) {\n\t\t\tvqs[i] = NULL;\n\t\t\tcontinue;\n\t\t}\n\t\tvqs[i] = vp_setup_vq(vdev, queue_idx++, callbacks[i], names[i],\n\t\t\t\t     ctx ? ctx[i] : false,\n\t\t\t\t     VIRTIO_MSI_NO_VECTOR);\n\t\tif (IS_ERR(vqs[i])) {\n\t\t\terr = PTR_ERR(vqs[i]);\n\t\t\tgoto out_del_vqs;\n\t\t}\n\t}\n\n\treturn 0;\nout_del_vqs:\n\tvp_del_vqs(vdev);\n\treturn err;\n}\n\n \nint vp_find_vqs(struct virtio_device *vdev, unsigned int nvqs,\n\t\tstruct virtqueue *vqs[], vq_callback_t *callbacks[],\n\t\tconst char * const names[], const bool *ctx,\n\t\tstruct irq_affinity *desc)\n{\n\tint err;\n\n\t \n\terr = vp_find_vqs_msix(vdev, nvqs, vqs, callbacks, names, true, ctx, desc);\n\tif (!err)\n\t\treturn 0;\n\t \n\terr = vp_find_vqs_msix(vdev, nvqs, vqs, callbacks, names, false, ctx, desc);\n\tif (!err)\n\t\treturn 0;\n\t \n\tif (!(to_vp_device(vdev)->pci_dev->irq))\n\t\treturn err;\n\t \n\treturn vp_find_vqs_intx(vdev, nvqs, vqs, callbacks, names, ctx);\n}\n\nconst char *vp_bus_name(struct virtio_device *vdev)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\n\treturn pci_name(vp_dev->pci_dev);\n}\n\n \nint vp_set_vq_affinity(struct virtqueue *vq, const struct cpumask *cpu_mask)\n{\n\tstruct virtio_device *vdev = vq->vdev;\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\tstruct virtio_pci_vq_info *info = vp_dev->vqs[vq->index];\n\tstruct cpumask *mask;\n\tunsigned int irq;\n\n\tif (!vq->callback)\n\t\treturn -EINVAL;\n\n\tif (vp_dev->msix_enabled) {\n\t\tmask = vp_dev->msix_affinity_masks[info->msix_vector];\n\t\tirq = pci_irq_vector(vp_dev->pci_dev, info->msix_vector);\n\t\tif (!cpu_mask)\n\t\t\tirq_set_affinity_hint(irq, NULL);\n\t\telse {\n\t\t\tcpumask_copy(mask, cpu_mask);\n\t\t\tirq_set_affinity_hint(irq, mask);\n\t\t}\n\t}\n\treturn 0;\n}\n\nconst struct cpumask *vp_get_vq_affinity(struct virtio_device *vdev, int index)\n{\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\n\tif (!vp_dev->per_vq_vectors ||\n\t    vp_dev->vqs[index]->msix_vector == VIRTIO_MSI_NO_VECTOR)\n\t\treturn NULL;\n\n\treturn pci_irq_get_affinity(vp_dev->pci_dev,\n\t\t\t\t    vp_dev->vqs[index]->msix_vector);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int virtio_pci_freeze(struct device *dev)\n{\n\tstruct pci_dev *pci_dev = to_pci_dev(dev);\n\tstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\n\tint ret;\n\n\tret = virtio_device_freeze(&vp_dev->vdev);\n\n\tif (!ret)\n\t\tpci_disable_device(pci_dev);\n\treturn ret;\n}\n\nstatic int virtio_pci_restore(struct device *dev)\n{\n\tstruct pci_dev *pci_dev = to_pci_dev(dev);\n\tstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\n\tint ret;\n\n\tret = pci_enable_device(pci_dev);\n\tif (ret)\n\t\treturn ret;\n\n\tpci_set_master(pci_dev);\n\treturn virtio_device_restore(&vp_dev->vdev);\n}\n\nstatic const struct dev_pm_ops virtio_pci_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(virtio_pci_freeze, virtio_pci_restore)\n};\n#endif\n\n\n \nstatic const struct pci_device_id virtio_pci_id_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_REDHAT_QUMRANET, PCI_ANY_ID) },\n\t{ 0 }\n};\n\nMODULE_DEVICE_TABLE(pci, virtio_pci_id_table);\n\nstatic void virtio_pci_release_dev(struct device *_d)\n{\n\tstruct virtio_device *vdev = dev_to_virtio(_d);\n\tstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\n\n\t \n\tkfree(vp_dev);\n}\n\nstatic int virtio_pci_probe(struct pci_dev *pci_dev,\n\t\t\t    const struct pci_device_id *id)\n{\n\tstruct virtio_pci_device *vp_dev, *reg_dev = NULL;\n\tint rc;\n\n\t \n\tvp_dev = kzalloc(sizeof(struct virtio_pci_device), GFP_KERNEL);\n\tif (!vp_dev)\n\t\treturn -ENOMEM;\n\n\tpci_set_drvdata(pci_dev, vp_dev);\n\tvp_dev->vdev.dev.parent = &pci_dev->dev;\n\tvp_dev->vdev.dev.release = virtio_pci_release_dev;\n\tvp_dev->pci_dev = pci_dev;\n\tINIT_LIST_HEAD(&vp_dev->virtqueues);\n\tspin_lock_init(&vp_dev->lock);\n\n\t \n\trc = pci_enable_device(pci_dev);\n\tif (rc)\n\t\tgoto err_enable_device;\n\n\tif (force_legacy) {\n\t\trc = virtio_pci_legacy_probe(vp_dev);\n\t\t \n\t\tif (rc == -ENODEV || rc == -ENOMEM)\n\t\t\trc = virtio_pci_modern_probe(vp_dev);\n\t\tif (rc)\n\t\t\tgoto err_probe;\n\t} else {\n\t\trc = virtio_pci_modern_probe(vp_dev);\n\t\tif (rc == -ENODEV)\n\t\t\trc = virtio_pci_legacy_probe(vp_dev);\n\t\tif (rc)\n\t\t\tgoto err_probe;\n\t}\n\n\tpci_set_master(pci_dev);\n\n\trc = register_virtio_device(&vp_dev->vdev);\n\treg_dev = vp_dev;\n\tif (rc)\n\t\tgoto err_register;\n\n\treturn 0;\n\nerr_register:\n\tif (vp_dev->is_legacy)\n\t\tvirtio_pci_legacy_remove(vp_dev);\n\telse\n\t\tvirtio_pci_modern_remove(vp_dev);\nerr_probe:\n\tpci_disable_device(pci_dev);\nerr_enable_device:\n\tif (reg_dev)\n\t\tput_device(&vp_dev->vdev.dev);\n\telse\n\t\tkfree(vp_dev);\n\treturn rc;\n}\n\nstatic void virtio_pci_remove(struct pci_dev *pci_dev)\n{\n\tstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\n\tstruct device *dev = get_device(&vp_dev->vdev.dev);\n\n\t \n\tif (!pci_device_is_present(pci_dev))\n\t\tvirtio_break_device(&vp_dev->vdev);\n\n\tpci_disable_sriov(pci_dev);\n\n\tunregister_virtio_device(&vp_dev->vdev);\n\n\tif (vp_dev->is_legacy)\n\t\tvirtio_pci_legacy_remove(vp_dev);\n\telse\n\t\tvirtio_pci_modern_remove(vp_dev);\n\n\tpci_disable_device(pci_dev);\n\tput_device(dev);\n}\n\nstatic int virtio_pci_sriov_configure(struct pci_dev *pci_dev, int num_vfs)\n{\n\tstruct virtio_pci_device *vp_dev = pci_get_drvdata(pci_dev);\n\tstruct virtio_device *vdev = &vp_dev->vdev;\n\tint ret;\n\n\tif (!(vdev->config->get_status(vdev) & VIRTIO_CONFIG_S_DRIVER_OK))\n\t\treturn -EBUSY;\n\n\tif (!__virtio_test_bit(vdev, VIRTIO_F_SR_IOV))\n\t\treturn -EINVAL;\n\n\tif (pci_vfs_assigned(pci_dev))\n\t\treturn -EPERM;\n\n\tif (num_vfs == 0) {\n\t\tpci_disable_sriov(pci_dev);\n\t\treturn 0;\n\t}\n\n\tret = pci_enable_sriov(pci_dev, num_vfs);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn num_vfs;\n}\n\nstatic struct pci_driver virtio_pci_driver = {\n\t.name\t\t= \"virtio-pci\",\n\t.id_table\t= virtio_pci_id_table,\n\t.probe\t\t= virtio_pci_probe,\n\t.remove\t\t= virtio_pci_remove,\n#ifdef CONFIG_PM_SLEEP\n\t.driver.pm\t= &virtio_pci_pm_ops,\n#endif\n\t.sriov_configure = virtio_pci_sriov_configure,\n};\n\nmodule_pci_driver(virtio_pci_driver);\n\nMODULE_AUTHOR(\"Anthony Liguori <aliguori@us.ibm.com>\");\nMODULE_DESCRIPTION(\"virtio-pci\");\nMODULE_LICENSE(\"GPL\");\nMODULE_VERSION(\"1\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}