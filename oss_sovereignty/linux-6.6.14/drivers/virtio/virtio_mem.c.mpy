{
  "module_name": "virtio_mem.c",
  "hash_id": "9332bb067e19f876de8e7e78b9273963aa5965037abc4527c730d9fd7f925b2d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/virtio/virtio_mem.c",
  "human_readable_source": "\n \n\n#include <linux/virtio.h>\n#include <linux/virtio_mem.h>\n#include <linux/workqueue.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <linux/mm.h>\n#include <linux/memory_hotplug.h>\n#include <linux/memory.h>\n#include <linux/hrtimer.h>\n#include <linux/crash_dump.h>\n#include <linux/mutex.h>\n#include <linux/bitmap.h>\n#include <linux/lockdep.h>\n#include <linux/log2.h>\n\n#include <acpi/acpi_numa.h>\n\nstatic bool unplug_online = true;\nmodule_param(unplug_online, bool, 0644);\nMODULE_PARM_DESC(unplug_online, \"Try to unplug online memory\");\n\nstatic bool force_bbm;\nmodule_param(force_bbm, bool, 0444);\nMODULE_PARM_DESC(force_bbm,\n\t\t\"Force Big Block Mode. Default is 0 (auto-selection)\");\n\nstatic unsigned long bbm_block_size;\nmodule_param(bbm_block_size, ulong, 0444);\nMODULE_PARM_DESC(bbm_block_size,\n\t\t \"Big Block size in bytes. Default is 0 (auto-detection).\");\n\n \n\n \nenum virtio_mem_sbm_mb_state {\n\t \n\tVIRTIO_MEM_SBM_MB_UNUSED = 0,\n\t \n\tVIRTIO_MEM_SBM_MB_PLUGGED,\n\t \n\tVIRTIO_MEM_SBM_MB_OFFLINE,\n\t \n\tVIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL,\n\t \n\tVIRTIO_MEM_SBM_MB_KERNEL,\n\t \n\tVIRTIO_MEM_SBM_MB_KERNEL_PARTIAL,\n\t \n\tVIRTIO_MEM_SBM_MB_MOVABLE,\n\t \n\tVIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL,\n\tVIRTIO_MEM_SBM_MB_COUNT\n};\n\n \nenum virtio_mem_bbm_bb_state {\n\t \n\tVIRTIO_MEM_BBM_BB_UNUSED = 0,\n\t \n\tVIRTIO_MEM_BBM_BB_PLUGGED,\n\t \n\tVIRTIO_MEM_BBM_BB_ADDED,\n\t \n\tVIRTIO_MEM_BBM_BB_FAKE_OFFLINE,\n\tVIRTIO_MEM_BBM_BB_COUNT\n};\n\nstruct virtio_mem {\n\tstruct virtio_device *vdev;\n\n\t \n\tbool unplug_all_required;\n\n\t \n\tstruct work_struct wq;\n\tatomic_t wq_active;\n\tatomic_t config_changed;\n\n\t \n\tstruct virtqueue *vq;\n\n\t \n\twait_queue_head_t host_resp;\n\n\t \n\tstruct virtio_mem_req req;\n\tstruct virtio_mem_resp resp;\n\n\t \n\tuint64_t plugged_size;\n\t \n\tuint64_t requested_size;\n\n\t \n\tuint64_t device_block_size;\n\t \n\tint nid;\n\t \n\tuint64_t addr;\n\t \n\tuint64_t region_size;\n\n\t \n\tstruct resource *parent_resource;\n\t \n\tconst char *resource_name;\n\t \n\tint mgid;\n\n\t \n#define VIRTIO_MEM_DEFAULT_OFFLINE_THRESHOLD\t\t(1024 * 1024 * 1024)\n\tatomic64_t offline_size;\n\tuint64_t offline_threshold;\n\n\t \n\tbool in_sbm;\n\n\tunion {\n\t\tstruct {\n\t\t\t \n\t\t\tunsigned long first_mb_id;\n\t\t\t \n\t\t\tunsigned long last_usable_mb_id;\n\t\t\t \n\t\t\tunsigned long next_mb_id;\n\n\t\t\t \n\t\t\tuint64_t sb_size;\n\t\t\t \n\t\t\tuint32_t sbs_per_mb;\n\n\t\t\t \n\t\t\tbool have_unplugged_mb;\n\n\t\t\t \n\t\t\tunsigned long mb_count[VIRTIO_MEM_SBM_MB_COUNT];\n\n\t\t\t \n\t\t\tuint8_t *mb_states;\n\n\t\t\t \n\t\t\tunsigned long *sb_states;\n\t\t} sbm;\n\n\t\tstruct {\n\t\t\t \n\t\t\tunsigned long first_bb_id;\n\t\t\t \n\t\t\tunsigned long last_usable_bb_id;\n\t\t\t \n\t\t\tunsigned long next_bb_id;\n\n\t\t\t \n\t\t\tunsigned long bb_count[VIRTIO_MEM_BBM_BB_COUNT];\n\n\t\t\t \n\t\t\tuint8_t *bb_states;\n\n\t\t\t \n\t\t\tuint64_t bb_size;\n\t\t} bbm;\n\t};\n\n\t \n\tstruct mutex hotplug_mutex;\n\tbool hotplug_active;\n\n\t \n\tbool broken;\n\n\t \n\tbool in_kdump;\n\n\t \n\tspinlock_t removal_lock;\n\tbool removing;\n\n\t \n\tstruct hrtimer retry_timer;\n\tunsigned int retry_timer_ms;\n#define VIRTIO_MEM_RETRY_TIMER_MIN_MS\t\t50000\n#define VIRTIO_MEM_RETRY_TIMER_MAX_MS\t\t300000\n\n\t \n\tstruct notifier_block memory_notifier;\n\n#ifdef CONFIG_PROC_VMCORE\n\t \n\tstruct vmcore_cb vmcore_cb;\n\tuint64_t last_block_addr;\n\tbool last_block_plugged;\n#endif  \n\n\t \n\tstruct list_head next;\n};\n\n \nstatic DEFINE_MUTEX(virtio_mem_mutex);\nstatic LIST_HEAD(virtio_mem_devices);\n\nstatic void virtio_mem_online_page_cb(struct page *page, unsigned int order);\nstatic void virtio_mem_fake_offline_going_offline(unsigned long pfn,\n\t\t\t\t\t\t  unsigned long nr_pages);\nstatic void virtio_mem_fake_offline_cancel_offline(unsigned long pfn,\n\t\t\t\t\t\t   unsigned long nr_pages);\nstatic void virtio_mem_retry(struct virtio_mem *vm);\nstatic int virtio_mem_create_resource(struct virtio_mem *vm);\nstatic void virtio_mem_delete_resource(struct virtio_mem *vm);\n\n \nstatic int register_virtio_mem_device(struct virtio_mem *vm)\n{\n\tint rc = 0;\n\n\t \n\tmutex_lock(&virtio_mem_mutex);\n\tif (list_empty(&virtio_mem_devices))\n\t\trc = set_online_page_callback(&virtio_mem_online_page_cb);\n\tif (!rc)\n\t\tlist_add_rcu(&vm->next, &virtio_mem_devices);\n\tmutex_unlock(&virtio_mem_mutex);\n\n\treturn rc;\n}\n\n \nstatic void unregister_virtio_mem_device(struct virtio_mem *vm)\n{\n\t \n\tmutex_lock(&virtio_mem_mutex);\n\tlist_del_rcu(&vm->next);\n\tif (list_empty(&virtio_mem_devices))\n\t\trestore_online_page_callback(&virtio_mem_online_page_cb);\n\tmutex_unlock(&virtio_mem_mutex);\n\n\tsynchronize_rcu();\n}\n\n \nstatic unsigned long virtio_mem_phys_to_mb_id(unsigned long addr)\n{\n\treturn addr / memory_block_size_bytes();\n}\n\n \nstatic unsigned long virtio_mem_mb_id_to_phys(unsigned long mb_id)\n{\n\treturn mb_id * memory_block_size_bytes();\n}\n\n \nstatic unsigned long virtio_mem_phys_to_bb_id(struct virtio_mem *vm,\n\t\t\t\t\t      uint64_t addr)\n{\n\treturn addr / vm->bbm.bb_size;\n}\n\n \nstatic uint64_t virtio_mem_bb_id_to_phys(struct virtio_mem *vm,\n\t\t\t\t\t unsigned long bb_id)\n{\n\treturn bb_id * vm->bbm.bb_size;\n}\n\n \nstatic unsigned long virtio_mem_phys_to_sb_id(struct virtio_mem *vm,\n\t\t\t\t\t      unsigned long addr)\n{\n\tconst unsigned long mb_id = virtio_mem_phys_to_mb_id(addr);\n\tconst unsigned long mb_addr = virtio_mem_mb_id_to_phys(mb_id);\n\n\treturn (addr - mb_addr) / vm->sbm.sb_size;\n}\n\n \nstatic void virtio_mem_bbm_set_bb_state(struct virtio_mem *vm,\n\t\t\t\t\tunsigned long bb_id,\n\t\t\t\t\tenum virtio_mem_bbm_bb_state state)\n{\n\tconst unsigned long idx = bb_id - vm->bbm.first_bb_id;\n\tenum virtio_mem_bbm_bb_state old_state;\n\n\told_state = vm->bbm.bb_states[idx];\n\tvm->bbm.bb_states[idx] = state;\n\n\tBUG_ON(vm->bbm.bb_count[old_state] == 0);\n\tvm->bbm.bb_count[old_state]--;\n\tvm->bbm.bb_count[state]++;\n}\n\n \nstatic enum virtio_mem_bbm_bb_state virtio_mem_bbm_get_bb_state(struct virtio_mem *vm,\n\t\t\t\t\t\t\t\tunsigned long bb_id)\n{\n\treturn vm->bbm.bb_states[bb_id - vm->bbm.first_bb_id];\n}\n\n \nstatic int virtio_mem_bbm_bb_states_prepare_next_bb(struct virtio_mem *vm)\n{\n\tunsigned long old_bytes = vm->bbm.next_bb_id - vm->bbm.first_bb_id;\n\tunsigned long new_bytes = old_bytes + 1;\n\tint old_pages = PFN_UP(old_bytes);\n\tint new_pages = PFN_UP(new_bytes);\n\tuint8_t *new_array;\n\n\tif (vm->bbm.bb_states && old_pages == new_pages)\n\t\treturn 0;\n\n\tnew_array = vzalloc(new_pages * PAGE_SIZE);\n\tif (!new_array)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&vm->hotplug_mutex);\n\tif (vm->bbm.bb_states)\n\t\tmemcpy(new_array, vm->bbm.bb_states, old_pages * PAGE_SIZE);\n\tvfree(vm->bbm.bb_states);\n\tvm->bbm.bb_states = new_array;\n\tmutex_unlock(&vm->hotplug_mutex);\n\n\treturn 0;\n}\n\n#define virtio_mem_bbm_for_each_bb(_vm, _bb_id, _state) \\\n\tfor (_bb_id = vm->bbm.first_bb_id; \\\n\t     _bb_id < vm->bbm.next_bb_id && _vm->bbm.bb_count[_state]; \\\n\t     _bb_id++) \\\n\t\tif (virtio_mem_bbm_get_bb_state(_vm, _bb_id) == _state)\n\n#define virtio_mem_bbm_for_each_bb_rev(_vm, _bb_id, _state) \\\n\tfor (_bb_id = vm->bbm.next_bb_id - 1; \\\n\t     _bb_id >= vm->bbm.first_bb_id && _vm->bbm.bb_count[_state]; \\\n\t     _bb_id--) \\\n\t\tif (virtio_mem_bbm_get_bb_state(_vm, _bb_id) == _state)\n\n \nstatic void virtio_mem_sbm_set_mb_state(struct virtio_mem *vm,\n\t\t\t\t\tunsigned long mb_id, uint8_t state)\n{\n\tconst unsigned long idx = mb_id - vm->sbm.first_mb_id;\n\tuint8_t old_state;\n\n\told_state = vm->sbm.mb_states[idx];\n\tvm->sbm.mb_states[idx] = state;\n\n\tBUG_ON(vm->sbm.mb_count[old_state] == 0);\n\tvm->sbm.mb_count[old_state]--;\n\tvm->sbm.mb_count[state]++;\n}\n\n \nstatic uint8_t virtio_mem_sbm_get_mb_state(struct virtio_mem *vm,\n\t\t\t\t\t   unsigned long mb_id)\n{\n\tconst unsigned long idx = mb_id - vm->sbm.first_mb_id;\n\n\treturn vm->sbm.mb_states[idx];\n}\n\n \nstatic int virtio_mem_sbm_mb_states_prepare_next_mb(struct virtio_mem *vm)\n{\n\tint old_pages = PFN_UP(vm->sbm.next_mb_id - vm->sbm.first_mb_id);\n\tint new_pages = PFN_UP(vm->sbm.next_mb_id - vm->sbm.first_mb_id + 1);\n\tuint8_t *new_array;\n\n\tif (vm->sbm.mb_states && old_pages == new_pages)\n\t\treturn 0;\n\n\tnew_array = vzalloc(new_pages * PAGE_SIZE);\n\tif (!new_array)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&vm->hotplug_mutex);\n\tif (vm->sbm.mb_states)\n\t\tmemcpy(new_array, vm->sbm.mb_states, old_pages * PAGE_SIZE);\n\tvfree(vm->sbm.mb_states);\n\tvm->sbm.mb_states = new_array;\n\tmutex_unlock(&vm->hotplug_mutex);\n\n\treturn 0;\n}\n\n#define virtio_mem_sbm_for_each_mb(_vm, _mb_id, _state) \\\n\tfor (_mb_id = _vm->sbm.first_mb_id; \\\n\t     _mb_id < _vm->sbm.next_mb_id && _vm->sbm.mb_count[_state]; \\\n\t     _mb_id++) \\\n\t\tif (virtio_mem_sbm_get_mb_state(_vm, _mb_id) == _state)\n\n#define virtio_mem_sbm_for_each_mb_rev(_vm, _mb_id, _state) \\\n\tfor (_mb_id = _vm->sbm.next_mb_id - 1; \\\n\t     _mb_id >= _vm->sbm.first_mb_id && _vm->sbm.mb_count[_state]; \\\n\t     _mb_id--) \\\n\t\tif (virtio_mem_sbm_get_mb_state(_vm, _mb_id) == _state)\n\n \nstatic int virtio_mem_sbm_sb_state_bit_nr(struct virtio_mem *vm,\n\t\t\t\t\t  unsigned long mb_id, int sb_id)\n{\n\treturn (mb_id - vm->sbm.first_mb_id) * vm->sbm.sbs_per_mb + sb_id;\n}\n\n \nstatic void virtio_mem_sbm_set_sb_plugged(struct virtio_mem *vm,\n\t\t\t\t\t  unsigned long mb_id, int sb_id,\n\t\t\t\t\t  int count)\n{\n\tconst int bit = virtio_mem_sbm_sb_state_bit_nr(vm, mb_id, sb_id);\n\n\t__bitmap_set(vm->sbm.sb_states, bit, count);\n}\n\n \nstatic void virtio_mem_sbm_set_sb_unplugged(struct virtio_mem *vm,\n\t\t\t\t\t    unsigned long mb_id, int sb_id,\n\t\t\t\t\t    int count)\n{\n\tconst int bit = virtio_mem_sbm_sb_state_bit_nr(vm, mb_id, sb_id);\n\n\t__bitmap_clear(vm->sbm.sb_states, bit, count);\n}\n\n \nstatic bool virtio_mem_sbm_test_sb_plugged(struct virtio_mem *vm,\n\t\t\t\t\t   unsigned long mb_id, int sb_id,\n\t\t\t\t\t   int count)\n{\n\tconst int bit = virtio_mem_sbm_sb_state_bit_nr(vm, mb_id, sb_id);\n\n\tif (count == 1)\n\t\treturn test_bit(bit, vm->sbm.sb_states);\n\n\t \n\treturn find_next_zero_bit(vm->sbm.sb_states, bit + count, bit) >=\n\t       bit + count;\n}\n\n \nstatic bool virtio_mem_sbm_test_sb_unplugged(struct virtio_mem *vm,\n\t\t\t\t\t     unsigned long mb_id, int sb_id,\n\t\t\t\t\t     int count)\n{\n\tconst int bit = virtio_mem_sbm_sb_state_bit_nr(vm, mb_id, sb_id);\n\n\t \n\treturn find_next_bit(vm->sbm.sb_states, bit + count, bit) >=\n\t       bit + count;\n}\n\n \nstatic int virtio_mem_sbm_first_unplugged_sb(struct virtio_mem *vm,\n\t\t\t\t\t    unsigned long mb_id)\n{\n\tconst int bit = virtio_mem_sbm_sb_state_bit_nr(vm, mb_id, 0);\n\n\treturn find_next_zero_bit(vm->sbm.sb_states,\n\t\t\t\t  bit + vm->sbm.sbs_per_mb, bit) - bit;\n}\n\n \nstatic int virtio_mem_sbm_sb_states_prepare_next_mb(struct virtio_mem *vm)\n{\n\tconst unsigned long old_nb_mb = vm->sbm.next_mb_id - vm->sbm.first_mb_id;\n\tconst unsigned long old_nb_bits = old_nb_mb * vm->sbm.sbs_per_mb;\n\tconst unsigned long new_nb_bits = (old_nb_mb + 1) * vm->sbm.sbs_per_mb;\n\tint old_pages = PFN_UP(BITS_TO_LONGS(old_nb_bits) * sizeof(long));\n\tint new_pages = PFN_UP(BITS_TO_LONGS(new_nb_bits) * sizeof(long));\n\tunsigned long *new_bitmap, *old_bitmap;\n\n\tif (vm->sbm.sb_states && old_pages == new_pages)\n\t\treturn 0;\n\n\tnew_bitmap = vzalloc(new_pages * PAGE_SIZE);\n\tif (!new_bitmap)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&vm->hotplug_mutex);\n\tif (vm->sbm.sb_states)\n\t\tmemcpy(new_bitmap, vm->sbm.sb_states, old_pages * PAGE_SIZE);\n\n\told_bitmap = vm->sbm.sb_states;\n\tvm->sbm.sb_states = new_bitmap;\n\tmutex_unlock(&vm->hotplug_mutex);\n\n\tvfree(old_bitmap);\n\treturn 0;\n}\n\n \nstatic bool virtio_mem_could_add_memory(struct virtio_mem *vm, uint64_t size)\n{\n\tif (WARN_ON_ONCE(size > vm->offline_threshold))\n\t\treturn false;\n\n\treturn atomic64_read(&vm->offline_size) + size <= vm->offline_threshold;\n}\n\n \nstatic int virtio_mem_add_memory(struct virtio_mem *vm, uint64_t addr,\n\t\t\t\t uint64_t size)\n{\n\tint rc;\n\n\t \n\tif (!vm->resource_name) {\n\t\tvm->resource_name = kstrdup_const(\"System RAM (virtio_mem)\",\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!vm->resource_name)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tdev_dbg(&vm->vdev->dev, \"adding memory: 0x%llx - 0x%llx\\n\", addr,\n\t\taddr + size - 1);\n\t \n\tatomic64_add(size, &vm->offline_size);\n\trc = add_memory_driver_managed(vm->mgid, addr, size, vm->resource_name,\n\t\t\t\t       MHP_MERGE_RESOURCE | MHP_NID_IS_MGID);\n\tif (rc) {\n\t\tatomic64_sub(size, &vm->offline_size);\n\t\tdev_warn(&vm->vdev->dev, \"adding memory failed: %d\\n\", rc);\n\t\t \n\t}\n\treturn rc;\n}\n\n \nstatic int virtio_mem_sbm_add_mb(struct virtio_mem *vm, unsigned long mb_id)\n{\n\tconst uint64_t addr = virtio_mem_mb_id_to_phys(mb_id);\n\tconst uint64_t size = memory_block_size_bytes();\n\n\treturn virtio_mem_add_memory(vm, addr, size);\n}\n\n \nstatic int virtio_mem_bbm_add_bb(struct virtio_mem *vm, unsigned long bb_id)\n{\n\tconst uint64_t addr = virtio_mem_bb_id_to_phys(vm, bb_id);\n\tconst uint64_t size = vm->bbm.bb_size;\n\n\treturn virtio_mem_add_memory(vm, addr, size);\n}\n\n \nstatic int virtio_mem_remove_memory(struct virtio_mem *vm, uint64_t addr,\n\t\t\t\t    uint64_t size)\n{\n\tint rc;\n\n\tdev_dbg(&vm->vdev->dev, \"removing memory: 0x%llx - 0x%llx\\n\", addr,\n\t\taddr + size - 1);\n\trc = remove_memory(addr, size);\n\tif (!rc) {\n\t\tatomic64_sub(size, &vm->offline_size);\n\t\t \n\t\tvirtio_mem_retry(vm);\n\t} else {\n\t\tdev_dbg(&vm->vdev->dev, \"removing memory failed: %d\\n\", rc);\n\t}\n\treturn rc;\n}\n\n \nstatic int virtio_mem_sbm_remove_mb(struct virtio_mem *vm, unsigned long mb_id)\n{\n\tconst uint64_t addr = virtio_mem_mb_id_to_phys(mb_id);\n\tconst uint64_t size = memory_block_size_bytes();\n\n\treturn virtio_mem_remove_memory(vm, addr, size);\n}\n\n \nstatic int virtio_mem_offline_and_remove_memory(struct virtio_mem *vm,\n\t\t\t\t\t\tuint64_t addr,\n\t\t\t\t\t\tuint64_t size)\n{\n\tint rc;\n\n\tdev_dbg(&vm->vdev->dev,\n\t\t\"offlining and removing memory: 0x%llx - 0x%llx\\n\", addr,\n\t\taddr + size - 1);\n\n\trc = offline_and_remove_memory(addr, size);\n\tif (!rc) {\n\t\tatomic64_sub(size, &vm->offline_size);\n\t\t \n\t\tvirtio_mem_retry(vm);\n\t\treturn 0;\n\t}\n\tdev_dbg(&vm->vdev->dev, \"offlining and removing memory failed: %d\\n\", rc);\n\t \n\tWARN_ON_ONCE(rc != -ENOMEM && rc != -EBUSY);\n\treturn rc == -ENOMEM ? -ENOMEM : -EBUSY;\n}\n\n \nstatic int virtio_mem_sbm_offline_and_remove_mb(struct virtio_mem *vm,\n\t\t\t\t\t\tunsigned long mb_id)\n{\n\tconst uint64_t addr = virtio_mem_mb_id_to_phys(mb_id);\n\tconst uint64_t size = memory_block_size_bytes();\n\n\treturn virtio_mem_offline_and_remove_memory(vm, addr, size);\n}\n\n \nstatic int virtio_mem_sbm_try_remove_unplugged_mb(struct virtio_mem *vm,\n\t\t\t\t\t\t  unsigned long mb_id)\n{\n\tint rc;\n\n\t \n\tif (!virtio_mem_sbm_test_sb_unplugged(vm, mb_id, 0, vm->sbm.sbs_per_mb))\n\t\treturn 0;\n\n\t \n\tmutex_unlock(&vm->hotplug_mutex);\n\trc = virtio_mem_sbm_offline_and_remove_mb(vm, mb_id);\n\tmutex_lock(&vm->hotplug_mutex);\n\tif (!rc)\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_UNUSED);\n\treturn rc;\n}\n\n \nstatic int virtio_mem_bbm_offline_and_remove_bb(struct virtio_mem *vm,\n\t\t\t\t\t\tunsigned long bb_id)\n{\n\tconst uint64_t addr = virtio_mem_bb_id_to_phys(vm, bb_id);\n\tconst uint64_t size = vm->bbm.bb_size;\n\n\treturn virtio_mem_offline_and_remove_memory(vm, addr, size);\n}\n\n \nstatic void virtio_mem_retry(struct virtio_mem *vm)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&vm->removal_lock, flags);\n\tif (!vm->removing)\n\t\tqueue_work(system_freezable_wq, &vm->wq);\n\tspin_unlock_irqrestore(&vm->removal_lock, flags);\n}\n\nstatic int virtio_mem_translate_node_id(struct virtio_mem *vm, uint16_t node_id)\n{\n\tint node = NUMA_NO_NODE;\n\n#if defined(CONFIG_ACPI_NUMA)\n\tif (virtio_has_feature(vm->vdev, VIRTIO_MEM_F_ACPI_PXM))\n\t\tnode = pxm_to_node(node_id);\n#endif\n\treturn node;\n}\n\n \nstatic bool virtio_mem_overlaps_range(struct virtio_mem *vm, uint64_t start,\n\t\t\t\t      uint64_t size)\n{\n\treturn start < vm->addr + vm->region_size && vm->addr < start + size;\n}\n\n \nstatic bool virtio_mem_contains_range(struct virtio_mem *vm, uint64_t start,\n\t\t\t\t      uint64_t size)\n{\n\treturn start >= vm->addr && start + size <= vm->addr + vm->region_size;\n}\n\nstatic int virtio_mem_sbm_notify_going_online(struct virtio_mem *vm,\n\t\t\t\t\t      unsigned long mb_id)\n{\n\tswitch (virtio_mem_sbm_get_mb_state(vm, mb_id)) {\n\tcase VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL:\n\tcase VIRTIO_MEM_SBM_MB_OFFLINE:\n\t\treturn NOTIFY_OK;\n\tdefault:\n\t\tbreak;\n\t}\n\tdev_warn_ratelimited(&vm->vdev->dev,\n\t\t\t     \"memory block onlining denied\\n\");\n\treturn NOTIFY_BAD;\n}\n\nstatic void virtio_mem_sbm_notify_offline(struct virtio_mem *vm,\n\t\t\t\t\t  unsigned long mb_id)\n{\n\tswitch (virtio_mem_sbm_get_mb_state(vm, mb_id)) {\n\tcase VIRTIO_MEM_SBM_MB_KERNEL_PARTIAL:\n\tcase VIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL:\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL);\n\t\tbreak;\n\tcase VIRTIO_MEM_SBM_MB_KERNEL:\n\tcase VIRTIO_MEM_SBM_MB_MOVABLE:\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_OFFLINE);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t\tbreak;\n\t}\n}\n\nstatic void virtio_mem_sbm_notify_online(struct virtio_mem *vm,\n\t\t\t\t\t unsigned long mb_id,\n\t\t\t\t\t unsigned long start_pfn)\n{\n\tconst bool is_movable = is_zone_movable_page(pfn_to_page(start_pfn));\n\tint new_state;\n\n\tswitch (virtio_mem_sbm_get_mb_state(vm, mb_id)) {\n\tcase VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL:\n\t\tnew_state = VIRTIO_MEM_SBM_MB_KERNEL_PARTIAL;\n\t\tif (is_movable)\n\t\t\tnew_state = VIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL;\n\t\tbreak;\n\tcase VIRTIO_MEM_SBM_MB_OFFLINE:\n\t\tnew_state = VIRTIO_MEM_SBM_MB_KERNEL;\n\t\tif (is_movable)\n\t\t\tnew_state = VIRTIO_MEM_SBM_MB_MOVABLE;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t\tbreak;\n\t}\n\tvirtio_mem_sbm_set_mb_state(vm, mb_id, new_state);\n}\n\nstatic void virtio_mem_sbm_notify_going_offline(struct virtio_mem *vm,\n\t\t\t\t\t\tunsigned long mb_id)\n{\n\tconst unsigned long nr_pages = PFN_DOWN(vm->sbm.sb_size);\n\tunsigned long pfn;\n\tint sb_id;\n\n\tfor (sb_id = 0; sb_id < vm->sbm.sbs_per_mb; sb_id++) {\n\t\tif (virtio_mem_sbm_test_sb_plugged(vm, mb_id, sb_id, 1))\n\t\t\tcontinue;\n\t\tpfn = PFN_DOWN(virtio_mem_mb_id_to_phys(mb_id) +\n\t\t\t       sb_id * vm->sbm.sb_size);\n\t\tvirtio_mem_fake_offline_going_offline(pfn, nr_pages);\n\t}\n}\n\nstatic void virtio_mem_sbm_notify_cancel_offline(struct virtio_mem *vm,\n\t\t\t\t\t\t unsigned long mb_id)\n{\n\tconst unsigned long nr_pages = PFN_DOWN(vm->sbm.sb_size);\n\tunsigned long pfn;\n\tint sb_id;\n\n\tfor (sb_id = 0; sb_id < vm->sbm.sbs_per_mb; sb_id++) {\n\t\tif (virtio_mem_sbm_test_sb_plugged(vm, mb_id, sb_id, 1))\n\t\t\tcontinue;\n\t\tpfn = PFN_DOWN(virtio_mem_mb_id_to_phys(mb_id) +\n\t\t\t       sb_id * vm->sbm.sb_size);\n\t\tvirtio_mem_fake_offline_cancel_offline(pfn, nr_pages);\n\t}\n}\n\nstatic void virtio_mem_bbm_notify_going_offline(struct virtio_mem *vm,\n\t\t\t\t\t\tunsigned long bb_id,\n\t\t\t\t\t\tunsigned long pfn,\n\t\t\t\t\t\tunsigned long nr_pages)\n{\n\t \n\tif (virtio_mem_bbm_get_bb_state(vm, bb_id) !=\n\t    VIRTIO_MEM_BBM_BB_FAKE_OFFLINE)\n\t\treturn;\n\tvirtio_mem_fake_offline_going_offline(pfn, nr_pages);\n}\n\nstatic void virtio_mem_bbm_notify_cancel_offline(struct virtio_mem *vm,\n\t\t\t\t\t\t unsigned long bb_id,\n\t\t\t\t\t\t unsigned long pfn,\n\t\t\t\t\t\t unsigned long nr_pages)\n{\n\tif (virtio_mem_bbm_get_bb_state(vm, bb_id) !=\n\t    VIRTIO_MEM_BBM_BB_FAKE_OFFLINE)\n\t\treturn;\n\tvirtio_mem_fake_offline_cancel_offline(pfn, nr_pages);\n}\n\n \nstatic int virtio_mem_memory_notifier_cb(struct notifier_block *nb,\n\t\t\t\t\t unsigned long action, void *arg)\n{\n\tstruct virtio_mem *vm = container_of(nb, struct virtio_mem,\n\t\t\t\t\t     memory_notifier);\n\tstruct memory_notify *mhp = arg;\n\tconst unsigned long start = PFN_PHYS(mhp->start_pfn);\n\tconst unsigned long size = PFN_PHYS(mhp->nr_pages);\n\tint rc = NOTIFY_OK;\n\tunsigned long id;\n\n\tif (!virtio_mem_overlaps_range(vm, start, size))\n\t\treturn NOTIFY_DONE;\n\n\tif (vm->in_sbm) {\n\t\tid = virtio_mem_phys_to_mb_id(start);\n\t\t \n\t\tif (WARN_ON_ONCE(size != memory_block_size_bytes() ||\n\t\t\t\t !IS_ALIGNED(start, memory_block_size_bytes())))\n\t\t\treturn NOTIFY_BAD;\n\t} else {\n\t\tid = virtio_mem_phys_to_bb_id(vm, start);\n\t\t \n\t\tif (WARN_ON_ONCE(id != virtio_mem_phys_to_bb_id(vm, start + size - 1)))\n\t\t\treturn NOTIFY_BAD;\n\t}\n\n\t \n\tlockdep_off();\n\n\tswitch (action) {\n\tcase MEM_GOING_OFFLINE:\n\t\tmutex_lock(&vm->hotplug_mutex);\n\t\tif (vm->removing) {\n\t\t\trc = notifier_from_errno(-EBUSY);\n\t\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\t\tbreak;\n\t\t}\n\t\tvm->hotplug_active = true;\n\t\tif (vm->in_sbm)\n\t\t\tvirtio_mem_sbm_notify_going_offline(vm, id);\n\t\telse\n\t\t\tvirtio_mem_bbm_notify_going_offline(vm, id,\n\t\t\t\t\t\t\t    mhp->start_pfn,\n\t\t\t\t\t\t\t    mhp->nr_pages);\n\t\tbreak;\n\tcase MEM_GOING_ONLINE:\n\t\tmutex_lock(&vm->hotplug_mutex);\n\t\tif (vm->removing) {\n\t\t\trc = notifier_from_errno(-EBUSY);\n\t\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\t\tbreak;\n\t\t}\n\t\tvm->hotplug_active = true;\n\t\tif (vm->in_sbm)\n\t\t\trc = virtio_mem_sbm_notify_going_online(vm, id);\n\t\tbreak;\n\tcase MEM_OFFLINE:\n\t\tif (vm->in_sbm)\n\t\t\tvirtio_mem_sbm_notify_offline(vm, id);\n\n\t\tatomic64_add(size, &vm->offline_size);\n\t\t \n\t\tif (!unplug_online)\n\t\t\tvirtio_mem_retry(vm);\n\n\t\tvm->hotplug_active = false;\n\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\tbreak;\n\tcase MEM_ONLINE:\n\t\tif (vm->in_sbm)\n\t\t\tvirtio_mem_sbm_notify_online(vm, id, mhp->start_pfn);\n\n\t\tatomic64_sub(size, &vm->offline_size);\n\t\t \n\t\tif (!atomic_read(&vm->wq_active) &&\n\t\t    virtio_mem_could_add_memory(vm, vm->offline_threshold / 2))\n\t\t\tvirtio_mem_retry(vm);\n\n\t\tvm->hotplug_active = false;\n\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\tbreak;\n\tcase MEM_CANCEL_OFFLINE:\n\t\tif (!vm->hotplug_active)\n\t\t\tbreak;\n\t\tif (vm->in_sbm)\n\t\t\tvirtio_mem_sbm_notify_cancel_offline(vm, id);\n\t\telse\n\t\t\tvirtio_mem_bbm_notify_cancel_offline(vm, id,\n\t\t\t\t\t\t\t     mhp->start_pfn,\n\t\t\t\t\t\t\t     mhp->nr_pages);\n\t\tvm->hotplug_active = false;\n\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\tbreak;\n\tcase MEM_CANCEL_ONLINE:\n\t\tif (!vm->hotplug_active)\n\t\t\tbreak;\n\t\tvm->hotplug_active = false;\n\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tlockdep_on();\n\n\treturn rc;\n}\n\n \nstatic void virtio_mem_set_fake_offline(unsigned long pfn,\n\t\t\t\t\tunsigned long nr_pages, bool onlined)\n{\n\tpage_offline_begin();\n\tfor (; nr_pages--; pfn++) {\n\t\tstruct page *page = pfn_to_page(pfn);\n\n\t\t__SetPageOffline(page);\n\t\tif (!onlined) {\n\t\t\tSetPageDirty(page);\n\t\t\t \n\t\t\tClearPageReserved(page);\n\t\t}\n\t}\n\tpage_offline_end();\n}\n\n \nstatic void virtio_mem_clear_fake_offline(unsigned long pfn,\n\t\t\t\t\t  unsigned long nr_pages, bool onlined)\n{\n\tfor (; nr_pages--; pfn++) {\n\t\tstruct page *page = pfn_to_page(pfn);\n\n\t\t__ClearPageOffline(page);\n\t\tif (!onlined)\n\t\t\tClearPageDirty(page);\n\t}\n}\n\n \nstatic void virtio_mem_fake_online(unsigned long pfn, unsigned long nr_pages)\n{\n\tunsigned long order = MAX_ORDER;\n\tunsigned long i;\n\n\t \n\twhile (!IS_ALIGNED(pfn | nr_pages, 1 << order))\n\t\torder--;\n\n\tfor (i = 0; i < nr_pages; i += 1 << order) {\n\t\tstruct page *page = pfn_to_page(pfn + i);\n\n\t\t \n\t\tif (PageDirty(page)) {\n\t\t\tvirtio_mem_clear_fake_offline(pfn + i, 1 << order, false);\n\t\t\tgeneric_online_page(page, order);\n\t\t} else {\n\t\t\tvirtio_mem_clear_fake_offline(pfn + i, 1 << order, true);\n\t\t\tfree_contig_range(pfn + i, 1 << order);\n\t\t\tadjust_managed_page_count(page, 1 << order);\n\t\t}\n\t}\n}\n\n \nstatic int virtio_mem_fake_offline(struct virtio_mem *vm, unsigned long pfn,\n\t\t\t\t   unsigned long nr_pages)\n{\n\tconst bool is_movable = is_zone_movable_page(pfn_to_page(pfn));\n\tint rc, retry_count;\n\n\t \n\tfor (retry_count = 0; retry_count < 5; retry_count++) {\n\t\t \n\t\tif (atomic_read(&vm->config_changed))\n\t\t\treturn -EAGAIN;\n\n\t\trc = alloc_contig_range(pfn, pfn + nr_pages, MIGRATE_MOVABLE,\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (rc == -ENOMEM)\n\t\t\t \n\t\t\treturn rc;\n\t\telse if (rc && !is_movable)\n\t\t\tbreak;\n\t\telse if (rc)\n\t\t\tcontinue;\n\n\t\tvirtio_mem_set_fake_offline(pfn, nr_pages, true);\n\t\tadjust_managed_page_count(pfn_to_page(pfn), -nr_pages);\n\t\treturn 0;\n\t}\n\n\treturn -EBUSY;\n}\n\n \nstatic void virtio_mem_fake_offline_going_offline(unsigned long pfn,\n\t\t\t\t\t\t  unsigned long nr_pages)\n{\n\tstruct page *page;\n\tunsigned long i;\n\n\t \n\tadjust_managed_page_count(pfn_to_page(pfn), nr_pages);\n\t \n\tfor (i = 0; i < nr_pages; i++) {\n\t\tpage = pfn_to_page(pfn + i);\n\t\tif (WARN_ON(!page_ref_dec_and_test(page)))\n\t\t\tdump_page(page, \"fake-offline page referenced\");\n\t}\n}\n\n \nstatic void virtio_mem_fake_offline_cancel_offline(unsigned long pfn,\n\t\t\t\t\t\t   unsigned long nr_pages)\n{\n\tunsigned long i;\n\n\t \n\tadjust_managed_page_count(pfn_to_page(pfn), -nr_pages);\n\tfor (i = 0; i < nr_pages; i++)\n\t\tpage_ref_inc(pfn_to_page(pfn + i));\n}\n\nstatic void virtio_mem_online_page(struct virtio_mem *vm,\n\t\t\t\t   struct page *page, unsigned int order)\n{\n\tconst unsigned long start = page_to_phys(page);\n\tconst unsigned long end = start + PFN_PHYS(1 << order);\n\tunsigned long addr, next, id, sb_id, count;\n\tbool do_online;\n\n\t \n\tfor (addr = start; addr < end; ) {\n\t\tnext = addr + PFN_PHYS(1 << order);\n\n\t\tif (vm->in_sbm) {\n\t\t\tid = virtio_mem_phys_to_mb_id(addr);\n\t\t\tsb_id = virtio_mem_phys_to_sb_id(vm, addr);\n\t\t\tcount = virtio_mem_phys_to_sb_id(vm, next - 1) - sb_id + 1;\n\n\t\t\tif (virtio_mem_sbm_test_sb_plugged(vm, id, sb_id, count)) {\n\t\t\t\t \n\t\t\t\tdo_online = true;\n\t\t\t} else if (count == 1 ||\n\t\t\t\t   virtio_mem_sbm_test_sb_unplugged(vm, id, sb_id, count)) {\n\t\t\t\t \n\t\t\t\tdo_online = false;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\torder = ilog2(vm->sbm.sb_size) - PAGE_SHIFT;\n\t\t\t\tdo_online = virtio_mem_sbm_test_sb_plugged(vm, id, sb_id, 1);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tid = virtio_mem_phys_to_bb_id(vm, addr);\n\t\t\tdo_online = virtio_mem_bbm_get_bb_state(vm, id) !=\n\t\t\t\t    VIRTIO_MEM_BBM_BB_FAKE_OFFLINE;\n\t\t}\n\n\t\tif (do_online)\n\t\t\tgeneric_online_page(pfn_to_page(PFN_DOWN(addr)), order);\n\t\telse\n\t\t\tvirtio_mem_set_fake_offline(PFN_DOWN(addr), 1 << order,\n\t\t\t\t\t\t    false);\n\t\taddr = next;\n\t}\n}\n\nstatic void virtio_mem_online_page_cb(struct page *page, unsigned int order)\n{\n\tconst unsigned long addr = page_to_phys(page);\n\tstruct virtio_mem *vm;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(vm, &virtio_mem_devices, next) {\n\t\t \n\t\tif (!virtio_mem_contains_range(vm, addr, PFN_PHYS(1 << order)))\n\t\t\tcontinue;\n\n\t\t \n\t\trcu_read_unlock();\n\n\t\tvirtio_mem_online_page(vm, page, order);\n\t\treturn;\n\t}\n\trcu_read_unlock();\n\n\t \n\tgeneric_online_page(page, order);\n}\n\nstatic uint64_t virtio_mem_send_request(struct virtio_mem *vm,\n\t\t\t\t\tconst struct virtio_mem_req *req)\n{\n\tstruct scatterlist *sgs[2], sg_req, sg_resp;\n\tunsigned int len;\n\tint rc;\n\n\t \n\tvm->req = *req;\n\n\t \n\tsg_init_one(&sg_req, &vm->req, sizeof(vm->req));\n\tsgs[0] = &sg_req;\n\n\t \n\tsg_init_one(&sg_resp, &vm->resp, sizeof(vm->resp));\n\tsgs[1] = &sg_resp;\n\n\trc = virtqueue_add_sgs(vm->vq, sgs, 1, 1, vm, GFP_KERNEL);\n\tif (rc < 0)\n\t\treturn rc;\n\n\tvirtqueue_kick(vm->vq);\n\n\t \n\twait_event(vm->host_resp, virtqueue_get_buf(vm->vq, &len));\n\n\treturn virtio16_to_cpu(vm->vdev, vm->resp.type);\n}\n\nstatic int virtio_mem_send_plug_request(struct virtio_mem *vm, uint64_t addr,\n\t\t\t\t\tuint64_t size)\n{\n\tconst uint64_t nb_vm_blocks = size / vm->device_block_size;\n\tconst struct virtio_mem_req req = {\n\t\t.type = cpu_to_virtio16(vm->vdev, VIRTIO_MEM_REQ_PLUG),\n\t\t.u.plug.addr = cpu_to_virtio64(vm->vdev, addr),\n\t\t.u.plug.nb_blocks = cpu_to_virtio16(vm->vdev, nb_vm_blocks),\n\t};\n\tint rc = -ENOMEM;\n\n\tif (atomic_read(&vm->config_changed))\n\t\treturn -EAGAIN;\n\n\tdev_dbg(&vm->vdev->dev, \"plugging memory: 0x%llx - 0x%llx\\n\", addr,\n\t\taddr + size - 1);\n\n\tswitch (virtio_mem_send_request(vm, &req)) {\n\tcase VIRTIO_MEM_RESP_ACK:\n\t\tvm->plugged_size += size;\n\t\treturn 0;\n\tcase VIRTIO_MEM_RESP_NACK:\n\t\trc = -EAGAIN;\n\t\tbreak;\n\tcase VIRTIO_MEM_RESP_BUSY:\n\t\trc = -ETXTBSY;\n\t\tbreak;\n\tcase VIRTIO_MEM_RESP_ERROR:\n\t\trc = -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tdev_dbg(&vm->vdev->dev, \"plugging memory failed: %d\\n\", rc);\n\treturn rc;\n}\n\nstatic int virtio_mem_send_unplug_request(struct virtio_mem *vm, uint64_t addr,\n\t\t\t\t\t  uint64_t size)\n{\n\tconst uint64_t nb_vm_blocks = size / vm->device_block_size;\n\tconst struct virtio_mem_req req = {\n\t\t.type = cpu_to_virtio16(vm->vdev, VIRTIO_MEM_REQ_UNPLUG),\n\t\t.u.unplug.addr = cpu_to_virtio64(vm->vdev, addr),\n\t\t.u.unplug.nb_blocks = cpu_to_virtio16(vm->vdev, nb_vm_blocks),\n\t};\n\tint rc = -ENOMEM;\n\n\tif (atomic_read(&vm->config_changed))\n\t\treturn -EAGAIN;\n\n\tdev_dbg(&vm->vdev->dev, \"unplugging memory: 0x%llx - 0x%llx\\n\", addr,\n\t\taddr + size - 1);\n\n\tswitch (virtio_mem_send_request(vm, &req)) {\n\tcase VIRTIO_MEM_RESP_ACK:\n\t\tvm->plugged_size -= size;\n\t\treturn 0;\n\tcase VIRTIO_MEM_RESP_BUSY:\n\t\trc = -ETXTBSY;\n\t\tbreak;\n\tcase VIRTIO_MEM_RESP_ERROR:\n\t\trc = -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tdev_dbg(&vm->vdev->dev, \"unplugging memory failed: %d\\n\", rc);\n\treturn rc;\n}\n\nstatic int virtio_mem_send_unplug_all_request(struct virtio_mem *vm)\n{\n\tconst struct virtio_mem_req req = {\n\t\t.type = cpu_to_virtio16(vm->vdev, VIRTIO_MEM_REQ_UNPLUG_ALL),\n\t};\n\tint rc = -ENOMEM;\n\n\tdev_dbg(&vm->vdev->dev, \"unplugging all memory\");\n\n\tswitch (virtio_mem_send_request(vm, &req)) {\n\tcase VIRTIO_MEM_RESP_ACK:\n\t\tvm->unplug_all_required = false;\n\t\tvm->plugged_size = 0;\n\t\t \n\t\tatomic_set(&vm->config_changed, 1);\n\t\treturn 0;\n\tcase VIRTIO_MEM_RESP_BUSY:\n\t\trc = -ETXTBSY;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tdev_dbg(&vm->vdev->dev, \"unplugging all memory failed: %d\\n\", rc);\n\treturn rc;\n}\n\n \nstatic int virtio_mem_sbm_plug_sb(struct virtio_mem *vm, unsigned long mb_id,\n\t\t\t\t  int sb_id, int count)\n{\n\tconst uint64_t addr = virtio_mem_mb_id_to_phys(mb_id) +\n\t\t\t      sb_id * vm->sbm.sb_size;\n\tconst uint64_t size = count * vm->sbm.sb_size;\n\tint rc;\n\n\trc = virtio_mem_send_plug_request(vm, addr, size);\n\tif (!rc)\n\t\tvirtio_mem_sbm_set_sb_plugged(vm, mb_id, sb_id, count);\n\treturn rc;\n}\n\n \nstatic int virtio_mem_sbm_unplug_sb(struct virtio_mem *vm, unsigned long mb_id,\n\t\t\t\t    int sb_id, int count)\n{\n\tconst uint64_t addr = virtio_mem_mb_id_to_phys(mb_id) +\n\t\t\t      sb_id * vm->sbm.sb_size;\n\tconst uint64_t size = count * vm->sbm.sb_size;\n\tint rc;\n\n\trc = virtio_mem_send_unplug_request(vm, addr, size);\n\tif (!rc)\n\t\tvirtio_mem_sbm_set_sb_unplugged(vm, mb_id, sb_id, count);\n\treturn rc;\n}\n\n \nstatic int virtio_mem_bbm_unplug_bb(struct virtio_mem *vm, unsigned long bb_id)\n{\n\tconst uint64_t addr = virtio_mem_bb_id_to_phys(vm, bb_id);\n\tconst uint64_t size = vm->bbm.bb_size;\n\n\treturn virtio_mem_send_unplug_request(vm, addr, size);\n}\n\n \nstatic int virtio_mem_bbm_plug_bb(struct virtio_mem *vm, unsigned long bb_id)\n{\n\tconst uint64_t addr = virtio_mem_bb_id_to_phys(vm, bb_id);\n\tconst uint64_t size = vm->bbm.bb_size;\n\n\treturn virtio_mem_send_plug_request(vm, addr, size);\n}\n\n \nstatic int virtio_mem_sbm_unplug_any_sb_raw(struct virtio_mem *vm,\n\t\t\t\t\t    unsigned long mb_id, uint64_t *nb_sb)\n{\n\tint sb_id, count;\n\tint rc;\n\n\tsb_id = vm->sbm.sbs_per_mb - 1;\n\twhile (*nb_sb) {\n\t\t \n\t\twhile (sb_id >= 0 &&\n\t\t       virtio_mem_sbm_test_sb_unplugged(vm, mb_id, sb_id, 1))\n\t\t\tsb_id--;\n\t\tif (sb_id < 0)\n\t\t\tbreak;\n\t\t \n\t\tcount = 1;\n\t\twhile (count < *nb_sb && sb_id > 0 &&\n\t\t       virtio_mem_sbm_test_sb_plugged(vm, mb_id, sb_id - 1, 1)) {\n\t\t\tcount++;\n\t\t\tsb_id--;\n\t\t}\n\n\t\trc = virtio_mem_sbm_unplug_sb(vm, mb_id, sb_id, count);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\t*nb_sb -= count;\n\t\tsb_id--;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int virtio_mem_sbm_unplug_mb(struct virtio_mem *vm, unsigned long mb_id)\n{\n\tuint64_t nb_sb = vm->sbm.sbs_per_mb;\n\n\treturn virtio_mem_sbm_unplug_any_sb_raw(vm, mb_id, &nb_sb);\n}\n\n \nstatic int virtio_mem_sbm_prepare_next_mb(struct virtio_mem *vm,\n\t\t\t\t\t  unsigned long *mb_id)\n{\n\tint rc;\n\n\tif (vm->sbm.next_mb_id > vm->sbm.last_usable_mb_id)\n\t\treturn -ENOSPC;\n\n\t \n\trc = virtio_mem_sbm_mb_states_prepare_next_mb(vm);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trc = virtio_mem_sbm_sb_states_prepare_next_mb(vm);\n\tif (rc)\n\t\treturn rc;\n\n\tvm->sbm.mb_count[VIRTIO_MEM_SBM_MB_UNUSED]++;\n\t*mb_id = vm->sbm.next_mb_id++;\n\treturn 0;\n}\n\n \nstatic int virtio_mem_sbm_plug_and_add_mb(struct virtio_mem *vm,\n\t\t\t\t\t  unsigned long mb_id, uint64_t *nb_sb)\n{\n\tconst int count = min_t(int, *nb_sb, vm->sbm.sbs_per_mb);\n\tint rc;\n\n\tif (WARN_ON_ONCE(!count))\n\t\treturn -EINVAL;\n\n\t \n\trc = virtio_mem_sbm_plug_sb(vm, mb_id, 0, count);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (count == vm->sbm.sbs_per_mb)\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_OFFLINE);\n\telse\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL);\n\n\t \n\trc = virtio_mem_sbm_add_mb(vm, mb_id);\n\tif (rc) {\n\t\tint new_state = VIRTIO_MEM_SBM_MB_UNUSED;\n\n\t\tif (virtio_mem_sbm_unplug_sb(vm, mb_id, 0, count))\n\t\t\tnew_state = VIRTIO_MEM_SBM_MB_PLUGGED;\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id, new_state);\n\t\treturn rc;\n\t}\n\n\t*nb_sb -= count;\n\treturn 0;\n}\n\n \nstatic int virtio_mem_sbm_plug_any_sb(struct virtio_mem *vm,\n\t\t\t\t      unsigned long mb_id, uint64_t *nb_sb)\n{\n\tconst int old_state = virtio_mem_sbm_get_mb_state(vm, mb_id);\n\tunsigned long pfn, nr_pages;\n\tint sb_id, count;\n\tint rc;\n\n\tif (WARN_ON_ONCE(!*nb_sb))\n\t\treturn -EINVAL;\n\n\twhile (*nb_sb) {\n\t\tsb_id = virtio_mem_sbm_first_unplugged_sb(vm, mb_id);\n\t\tif (sb_id >= vm->sbm.sbs_per_mb)\n\t\t\tbreak;\n\t\tcount = 1;\n\t\twhile (count < *nb_sb &&\n\t\t       sb_id + count < vm->sbm.sbs_per_mb &&\n\t\t       !virtio_mem_sbm_test_sb_plugged(vm, mb_id, sb_id + count, 1))\n\t\t\tcount++;\n\n\t\trc = virtio_mem_sbm_plug_sb(vm, mb_id, sb_id, count);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\t*nb_sb -= count;\n\t\tif (old_state == VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL)\n\t\t\tcontinue;\n\n\t\t \n\t\tpfn = PFN_DOWN(virtio_mem_mb_id_to_phys(mb_id) +\n\t\t\t       sb_id * vm->sbm.sb_size);\n\t\tnr_pages = PFN_DOWN(count * vm->sbm.sb_size);\n\t\tvirtio_mem_fake_online(pfn, nr_pages);\n\t}\n\n\tif (virtio_mem_sbm_test_sb_plugged(vm, mb_id, 0, vm->sbm.sbs_per_mb))\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id, old_state - 1);\n\n\treturn 0;\n}\n\nstatic int virtio_mem_sbm_plug_request(struct virtio_mem *vm, uint64_t diff)\n{\n\tconst int mb_states[] = {\n\t\tVIRTIO_MEM_SBM_MB_KERNEL_PARTIAL,\n\t\tVIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL,\n\t\tVIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL,\n\t};\n\tuint64_t nb_sb = diff / vm->sbm.sb_size;\n\tunsigned long mb_id;\n\tint rc, i;\n\n\tif (!nb_sb)\n\t\treturn 0;\n\n\t \n\tmutex_lock(&vm->hotplug_mutex);\n\n\tfor (i = 0; i < ARRAY_SIZE(mb_states); i++) {\n\t\tvirtio_mem_sbm_for_each_mb(vm, mb_id, mb_states[i]) {\n\t\t\trc = virtio_mem_sbm_plug_any_sb(vm, mb_id, &nb_sb);\n\t\t\tif (rc || !nb_sb)\n\t\t\t\tgoto out_unlock;\n\t\t\tcond_resched();\n\t\t}\n\t}\n\n\t \n\tmutex_unlock(&vm->hotplug_mutex);\n\n\t \n\tvirtio_mem_sbm_for_each_mb(vm, mb_id, VIRTIO_MEM_SBM_MB_UNUSED) {\n\t\tif (!virtio_mem_could_add_memory(vm, memory_block_size_bytes()))\n\t\t\treturn -ENOSPC;\n\n\t\trc = virtio_mem_sbm_plug_and_add_mb(vm, mb_id, &nb_sb);\n\t\tif (rc || !nb_sb)\n\t\t\treturn rc;\n\t\tcond_resched();\n\t}\n\n\t \n\twhile (nb_sb) {\n\t\tif (!virtio_mem_could_add_memory(vm, memory_block_size_bytes()))\n\t\t\treturn -ENOSPC;\n\n\t\trc = virtio_mem_sbm_prepare_next_mb(vm, &mb_id);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\trc = virtio_mem_sbm_plug_and_add_mb(vm, mb_id, &nb_sb);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tcond_resched();\n\t}\n\n\treturn 0;\nout_unlock:\n\tmutex_unlock(&vm->hotplug_mutex);\n\treturn rc;\n}\n\n \nstatic int virtio_mem_bbm_plug_and_add_bb(struct virtio_mem *vm,\n\t\t\t\t\t  unsigned long bb_id)\n{\n\tint rc;\n\n\tif (WARN_ON_ONCE(virtio_mem_bbm_get_bb_state(vm, bb_id) !=\n\t\t\t VIRTIO_MEM_BBM_BB_UNUSED))\n\t\treturn -EINVAL;\n\n\trc = virtio_mem_bbm_plug_bb(vm, bb_id);\n\tif (rc)\n\t\treturn rc;\n\tvirtio_mem_bbm_set_bb_state(vm, bb_id, VIRTIO_MEM_BBM_BB_ADDED);\n\n\trc = virtio_mem_bbm_add_bb(vm, bb_id);\n\tif (rc) {\n\t\tif (!virtio_mem_bbm_unplug_bb(vm, bb_id))\n\t\t\tvirtio_mem_bbm_set_bb_state(vm, bb_id,\n\t\t\t\t\t\t    VIRTIO_MEM_BBM_BB_UNUSED);\n\t\telse\n\t\t\t \n\t\t\tvirtio_mem_bbm_set_bb_state(vm, bb_id,\n\t\t\t\t\t\t    VIRTIO_MEM_BBM_BB_PLUGGED);\n\t\treturn rc;\n\t}\n\treturn 0;\n}\n\n \nstatic int virtio_mem_bbm_prepare_next_bb(struct virtio_mem *vm,\n\t\t\t\t\t  unsigned long *bb_id)\n{\n\tint rc;\n\n\tif (vm->bbm.next_bb_id > vm->bbm.last_usable_bb_id)\n\t\treturn -ENOSPC;\n\n\t \n\trc = virtio_mem_bbm_bb_states_prepare_next_bb(vm);\n\tif (rc)\n\t\treturn rc;\n\n\tvm->bbm.bb_count[VIRTIO_MEM_BBM_BB_UNUSED]++;\n\t*bb_id = vm->bbm.next_bb_id;\n\tvm->bbm.next_bb_id++;\n\treturn 0;\n}\n\nstatic int virtio_mem_bbm_plug_request(struct virtio_mem *vm, uint64_t diff)\n{\n\tuint64_t nb_bb = diff / vm->bbm.bb_size;\n\tunsigned long bb_id;\n\tint rc;\n\n\tif (!nb_bb)\n\t\treturn 0;\n\n\t \n\tvirtio_mem_bbm_for_each_bb(vm, bb_id, VIRTIO_MEM_BBM_BB_UNUSED) {\n\t\tif (!virtio_mem_could_add_memory(vm, vm->bbm.bb_size))\n\t\t\treturn -ENOSPC;\n\n\t\trc = virtio_mem_bbm_plug_and_add_bb(vm, bb_id);\n\t\tif (!rc)\n\t\t\tnb_bb--;\n\t\tif (rc || !nb_bb)\n\t\t\treturn rc;\n\t\tcond_resched();\n\t}\n\n\t \n\twhile (nb_bb) {\n\t\tif (!virtio_mem_could_add_memory(vm, vm->bbm.bb_size))\n\t\t\treturn -ENOSPC;\n\n\t\trc = virtio_mem_bbm_prepare_next_bb(vm, &bb_id);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\trc = virtio_mem_bbm_plug_and_add_bb(vm, bb_id);\n\t\tif (!rc)\n\t\t\tnb_bb--;\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tcond_resched();\n\t}\n\n\treturn 0;\n}\n\n \nstatic int virtio_mem_plug_request(struct virtio_mem *vm, uint64_t diff)\n{\n\tif (vm->in_sbm)\n\t\treturn virtio_mem_sbm_plug_request(vm, diff);\n\treturn virtio_mem_bbm_plug_request(vm, diff);\n}\n\n \nstatic int virtio_mem_sbm_unplug_any_sb_offline(struct virtio_mem *vm,\n\t\t\t\t\t\tunsigned long mb_id,\n\t\t\t\t\t\tuint64_t *nb_sb)\n{\n\tint rc;\n\n\trc = virtio_mem_sbm_unplug_any_sb_raw(vm, mb_id, nb_sb);\n\n\t \n\tif (!virtio_mem_sbm_test_sb_plugged(vm, mb_id, 0, vm->sbm.sbs_per_mb))\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL);\n\tif (rc)\n\t\treturn rc;\n\n\tif (virtio_mem_sbm_test_sb_unplugged(vm, mb_id, 0, vm->sbm.sbs_per_mb)) {\n\t\t \n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_UNUSED);\n\n\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\trc = virtio_mem_sbm_remove_mb(vm, mb_id);\n\t\tBUG_ON(rc);\n\t\tmutex_lock(&vm->hotplug_mutex);\n\t}\n\treturn 0;\n}\n\n \nstatic int virtio_mem_sbm_unplug_sb_online(struct virtio_mem *vm,\n\t\t\t\t\t   unsigned long mb_id, int sb_id,\n\t\t\t\t\t   int count)\n{\n\tconst unsigned long nr_pages = PFN_DOWN(vm->sbm.sb_size) * count;\n\tconst int old_state = virtio_mem_sbm_get_mb_state(vm, mb_id);\n\tunsigned long start_pfn;\n\tint rc;\n\n\tstart_pfn = PFN_DOWN(virtio_mem_mb_id_to_phys(mb_id) +\n\t\t\t     sb_id * vm->sbm.sb_size);\n\n\trc = virtio_mem_fake_offline(vm, start_pfn, nr_pages);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trc = virtio_mem_sbm_unplug_sb(vm, mb_id, sb_id, count);\n\tif (rc) {\n\t\t \n\t\tvirtio_mem_fake_online(start_pfn, nr_pages);\n\t\treturn rc;\n\t}\n\n\tswitch (old_state) {\n\tcase VIRTIO_MEM_SBM_MB_KERNEL:\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_KERNEL_PARTIAL);\n\t\tbreak;\n\tcase VIRTIO_MEM_SBM_MB_MOVABLE:\n\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int virtio_mem_sbm_unplug_any_sb_online(struct virtio_mem *vm,\n\t\t\t\t\t       unsigned long mb_id,\n\t\t\t\t\t       uint64_t *nb_sb)\n{\n\tint rc, sb_id;\n\n\t \n\tif (*nb_sb >= vm->sbm.sbs_per_mb &&\n\t    virtio_mem_sbm_test_sb_plugged(vm, mb_id, 0, vm->sbm.sbs_per_mb)) {\n\t\trc = virtio_mem_sbm_unplug_sb_online(vm, mb_id, 0,\n\t\t\t\t\t\t     vm->sbm.sbs_per_mb);\n\t\tif (!rc) {\n\t\t\t*nb_sb -= vm->sbm.sbs_per_mb;\n\t\t\tgoto unplugged;\n\t\t} else if (rc != -EBUSY)\n\t\t\treturn rc;\n\t}\n\n\t \n\tfor (sb_id = vm->sbm.sbs_per_mb - 1; sb_id >= 0 && *nb_sb; sb_id--) {\n\t\t \n\t\twhile (sb_id >= 0 &&\n\t\t       !virtio_mem_sbm_test_sb_plugged(vm, mb_id, sb_id, 1))\n\t\t\tsb_id--;\n\t\tif (sb_id < 0)\n\t\t\tbreak;\n\n\t\trc = virtio_mem_sbm_unplug_sb_online(vm, mb_id, sb_id, 1);\n\t\tif (rc == -EBUSY)\n\t\t\tcontinue;\n\t\telse if (rc)\n\t\t\treturn rc;\n\t\t*nb_sb -= 1;\n\t}\n\nunplugged:\n\trc = virtio_mem_sbm_try_remove_unplugged_mb(vm, mb_id);\n\tif (rc)\n\t\tvm->sbm.have_unplugged_mb = 1;\n\t \n\treturn 0;\n}\n\n \nstatic int virtio_mem_sbm_unplug_any_sb(struct virtio_mem *vm,\n\t\t\t\t\tunsigned long mb_id,\n\t\t\t\t\tuint64_t *nb_sb)\n{\n\tconst int old_state = virtio_mem_sbm_get_mb_state(vm, mb_id);\n\n\tswitch (old_state) {\n\tcase VIRTIO_MEM_SBM_MB_KERNEL_PARTIAL:\n\tcase VIRTIO_MEM_SBM_MB_KERNEL:\n\tcase VIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL:\n\tcase VIRTIO_MEM_SBM_MB_MOVABLE:\n\t\treturn virtio_mem_sbm_unplug_any_sb_online(vm, mb_id, nb_sb);\n\tcase VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL:\n\tcase VIRTIO_MEM_SBM_MB_OFFLINE:\n\t\treturn virtio_mem_sbm_unplug_any_sb_offline(vm, mb_id, nb_sb);\n\t}\n\treturn -EINVAL;\n}\n\nstatic int virtio_mem_sbm_unplug_request(struct virtio_mem *vm, uint64_t diff)\n{\n\tconst int mb_states[] = {\n\t\tVIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL,\n\t\tVIRTIO_MEM_SBM_MB_OFFLINE,\n\t\tVIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL,\n\t\tVIRTIO_MEM_SBM_MB_KERNEL_PARTIAL,\n\t\tVIRTIO_MEM_SBM_MB_MOVABLE,\n\t\tVIRTIO_MEM_SBM_MB_KERNEL,\n\t};\n\tuint64_t nb_sb = diff / vm->sbm.sb_size;\n\tunsigned long mb_id;\n\tint rc, i;\n\n\tif (!nb_sb)\n\t\treturn 0;\n\n\t \n\tmutex_lock(&vm->hotplug_mutex);\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(mb_states); i++) {\n\t\tvirtio_mem_sbm_for_each_mb_rev(vm, mb_id, mb_states[i]) {\n\t\t\trc = virtio_mem_sbm_unplug_any_sb(vm, mb_id, &nb_sb);\n\t\t\tif (rc || !nb_sb)\n\t\t\t\tgoto out_unlock;\n\t\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\t\tcond_resched();\n\t\t\tmutex_lock(&vm->hotplug_mutex);\n\t\t}\n\t\tif (!unplug_online && i == 1) {\n\t\t\tmutex_unlock(&vm->hotplug_mutex);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tmutex_unlock(&vm->hotplug_mutex);\n\treturn nb_sb ? -EBUSY : 0;\nout_unlock:\n\tmutex_unlock(&vm->hotplug_mutex);\n\treturn rc;\n}\n\n \nstatic int virtio_mem_bbm_offline_remove_and_unplug_bb(struct virtio_mem *vm,\n\t\t\t\t\t\t       unsigned long bb_id)\n{\n\tconst unsigned long start_pfn = PFN_DOWN(virtio_mem_bb_id_to_phys(vm, bb_id));\n\tconst unsigned long nr_pages = PFN_DOWN(vm->bbm.bb_size);\n\tunsigned long end_pfn = start_pfn + nr_pages;\n\tunsigned long pfn;\n\tstruct page *page;\n\tint rc;\n\n\tif (WARN_ON_ONCE(virtio_mem_bbm_get_bb_state(vm, bb_id) !=\n\t\t\t VIRTIO_MEM_BBM_BB_ADDED))\n\t\treturn -EINVAL;\n\n\t \n\tmutex_lock(&vm->hotplug_mutex);\n\tvirtio_mem_bbm_set_bb_state(vm, bb_id, VIRTIO_MEM_BBM_BB_FAKE_OFFLINE);\n\n\tfor (pfn = start_pfn; pfn < end_pfn; pfn += PAGES_PER_SECTION) {\n\t\tpage = pfn_to_online_page(pfn);\n\t\tif (!page)\n\t\t\tcontinue;\n\n\t\trc = virtio_mem_fake_offline(vm, pfn, PAGES_PER_SECTION);\n\t\tif (rc) {\n\t\t\tend_pfn = pfn;\n\t\t\tgoto rollback;\n\t\t}\n\t}\n\tmutex_unlock(&vm->hotplug_mutex);\n\n\trc = virtio_mem_bbm_offline_and_remove_bb(vm, bb_id);\n\tif (rc) {\n\t\tmutex_lock(&vm->hotplug_mutex);\n\t\tgoto rollback;\n\t}\n\n\trc = virtio_mem_bbm_unplug_bb(vm, bb_id);\n\tif (rc)\n\t\tvirtio_mem_bbm_set_bb_state(vm, bb_id,\n\t\t\t\t\t    VIRTIO_MEM_BBM_BB_PLUGGED);\n\telse\n\t\tvirtio_mem_bbm_set_bb_state(vm, bb_id,\n\t\t\t\t\t    VIRTIO_MEM_BBM_BB_UNUSED);\n\treturn rc;\n\nrollback:\n\tfor (pfn = start_pfn; pfn < end_pfn; pfn += PAGES_PER_SECTION) {\n\t\tpage = pfn_to_online_page(pfn);\n\t\tif (!page)\n\t\t\tcontinue;\n\t\tvirtio_mem_fake_online(pfn, PAGES_PER_SECTION);\n\t}\n\tvirtio_mem_bbm_set_bb_state(vm, bb_id, VIRTIO_MEM_BBM_BB_ADDED);\n\tmutex_unlock(&vm->hotplug_mutex);\n\treturn rc;\n}\n\n \nstatic bool virtio_mem_bbm_bb_is_offline(struct virtio_mem *vm,\n\t\t\t\t\t unsigned long bb_id)\n{\n\tconst unsigned long start_pfn = PFN_DOWN(virtio_mem_bb_id_to_phys(vm, bb_id));\n\tconst unsigned long nr_pages = PFN_DOWN(vm->bbm.bb_size);\n\tunsigned long pfn;\n\n\tfor (pfn = start_pfn; pfn < start_pfn + nr_pages;\n\t     pfn += PAGES_PER_SECTION) {\n\t\tif (pfn_to_online_page(pfn))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic bool virtio_mem_bbm_bb_is_movable(struct virtio_mem *vm,\n\t\t\t\t\t unsigned long bb_id)\n{\n\tconst unsigned long start_pfn = PFN_DOWN(virtio_mem_bb_id_to_phys(vm, bb_id));\n\tconst unsigned long nr_pages = PFN_DOWN(vm->bbm.bb_size);\n\tstruct page *page;\n\tunsigned long pfn;\n\n\tfor (pfn = start_pfn; pfn < start_pfn + nr_pages;\n\t     pfn += PAGES_PER_SECTION) {\n\t\tpage = pfn_to_online_page(pfn);\n\t\tif (!page)\n\t\t\tcontinue;\n\t\tif (page_zonenum(page) != ZONE_MOVABLE)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic int virtio_mem_bbm_unplug_request(struct virtio_mem *vm, uint64_t diff)\n{\n\tuint64_t nb_bb = diff / vm->bbm.bb_size;\n\tuint64_t bb_id;\n\tint rc, i;\n\n\tif (!nb_bb)\n\t\treturn 0;\n\n\t \n\tfor (i = 0; i < 3; i++) {\n\t\tvirtio_mem_bbm_for_each_bb_rev(vm, bb_id, VIRTIO_MEM_BBM_BB_ADDED) {\n\t\t\tcond_resched();\n\n\t\t\t \n\t\t\tif (i == 0 && !virtio_mem_bbm_bb_is_offline(vm, bb_id))\n\t\t\t\tcontinue;\n\t\t\tif (i == 1 && !virtio_mem_bbm_bb_is_movable(vm, bb_id))\n\t\t\t\tcontinue;\n\t\t\trc = virtio_mem_bbm_offline_remove_and_unplug_bb(vm, bb_id);\n\t\t\tif (rc == -EBUSY)\n\t\t\t\tcontinue;\n\t\t\tif (!rc)\n\t\t\t\tnb_bb--;\n\t\t\tif (rc || !nb_bb)\n\t\t\t\treturn rc;\n\t\t}\n\t\tif (i == 0 && !unplug_online)\n\t\t\treturn 0;\n\t}\n\n\treturn nb_bb ? -EBUSY : 0;\n}\n\n \nstatic int virtio_mem_unplug_request(struct virtio_mem *vm, uint64_t diff)\n{\n\tif (vm->in_sbm)\n\t\treturn virtio_mem_sbm_unplug_request(vm, diff);\n\treturn virtio_mem_bbm_unplug_request(vm, diff);\n}\n\n \nstatic int virtio_mem_cleanup_pending_mb(struct virtio_mem *vm)\n{\n\tunsigned long id;\n\tint rc = 0;\n\n\tif (!vm->in_sbm) {\n\t\tvirtio_mem_bbm_for_each_bb(vm, id,\n\t\t\t\t\t   VIRTIO_MEM_BBM_BB_PLUGGED) {\n\t\t\trc = virtio_mem_bbm_unplug_bb(vm, id);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t\tvirtio_mem_bbm_set_bb_state(vm, id,\n\t\t\t\t\t\t    VIRTIO_MEM_BBM_BB_UNUSED);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tvirtio_mem_sbm_for_each_mb(vm, id, VIRTIO_MEM_SBM_MB_PLUGGED) {\n\t\trc = virtio_mem_sbm_unplug_mb(vm, id);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tvirtio_mem_sbm_set_mb_state(vm, id,\n\t\t\t\t\t    VIRTIO_MEM_SBM_MB_UNUSED);\n\t}\n\n\tif (!vm->sbm.have_unplugged_mb)\n\t\treturn 0;\n\n\t \n\tvm->sbm.have_unplugged_mb = false;\n\n\tmutex_lock(&vm->hotplug_mutex);\n\tvirtio_mem_sbm_for_each_mb(vm, id, VIRTIO_MEM_SBM_MB_MOVABLE_PARTIAL)\n\t\trc |= virtio_mem_sbm_try_remove_unplugged_mb(vm, id);\n\tvirtio_mem_sbm_for_each_mb(vm, id, VIRTIO_MEM_SBM_MB_KERNEL_PARTIAL)\n\t\trc |= virtio_mem_sbm_try_remove_unplugged_mb(vm, id);\n\tvirtio_mem_sbm_for_each_mb(vm, id, VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL)\n\t\trc |= virtio_mem_sbm_try_remove_unplugged_mb(vm, id);\n\tmutex_unlock(&vm->hotplug_mutex);\n\n\tif (rc)\n\t\tvm->sbm.have_unplugged_mb = true;\n\t \n\treturn 0;\n}\n\n \nstatic void virtio_mem_refresh_config(struct virtio_mem *vm)\n{\n\tconst struct range pluggable_range = mhp_get_pluggable_range(true);\n\tuint64_t new_plugged_size, usable_region_size, end_addr;\n\n\t \n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config, plugged_size,\n\t\t\t&new_plugged_size);\n\tif (WARN_ON_ONCE(new_plugged_size != vm->plugged_size))\n\t\tvm->plugged_size = new_plugged_size;\n\n\t \n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config,\n\t\t\tusable_region_size, &usable_region_size);\n\tend_addr = min(vm->addr + usable_region_size - 1,\n\t\t       pluggable_range.end);\n\n\tif (vm->in_sbm) {\n\t\tvm->sbm.last_usable_mb_id = virtio_mem_phys_to_mb_id(end_addr);\n\t\tif (!IS_ALIGNED(end_addr + 1, memory_block_size_bytes()))\n\t\t\tvm->sbm.last_usable_mb_id--;\n\t} else {\n\t\tvm->bbm.last_usable_bb_id = virtio_mem_phys_to_bb_id(vm,\n\t\t\t\t\t\t\t\t     end_addr);\n\t\tif (!IS_ALIGNED(end_addr + 1, vm->bbm.bb_size))\n\t\t\tvm->bbm.last_usable_bb_id--;\n\t}\n\t \n\n\t \n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config, requested_size,\n\t\t\t&vm->requested_size);\n\n\tdev_info(&vm->vdev->dev, \"plugged size: 0x%llx\", vm->plugged_size);\n\tdev_info(&vm->vdev->dev, \"requested size: 0x%llx\", vm->requested_size);\n}\n\n \nstatic void virtio_mem_run_wq(struct work_struct *work)\n{\n\tstruct virtio_mem *vm = container_of(work, struct virtio_mem, wq);\n\tuint64_t diff;\n\tint rc;\n\n\tif (unlikely(vm->in_kdump)) {\n\t\tdev_warn_once(&vm->vdev->dev,\n\t\t\t     \"unexpected workqueue run in kdump kernel\\n\");\n\t\treturn;\n\t}\n\n\thrtimer_cancel(&vm->retry_timer);\n\n\tif (vm->broken)\n\t\treturn;\n\n\tatomic_set(&vm->wq_active, 1);\nretry:\n\trc = 0;\n\n\t \n\tif (unlikely(vm->unplug_all_required))\n\t\trc = virtio_mem_send_unplug_all_request(vm);\n\n\tif (atomic_read(&vm->config_changed)) {\n\t\tatomic_set(&vm->config_changed, 0);\n\t\tvirtio_mem_refresh_config(vm);\n\t}\n\n\t \n\tif (!rc)\n\t\trc = virtio_mem_cleanup_pending_mb(vm);\n\n\tif (!rc && vm->requested_size != vm->plugged_size) {\n\t\tif (vm->requested_size > vm->plugged_size) {\n\t\t\tdiff = vm->requested_size - vm->plugged_size;\n\t\t\trc = virtio_mem_plug_request(vm, diff);\n\t\t} else {\n\t\t\tdiff = vm->plugged_size - vm->requested_size;\n\t\t\trc = virtio_mem_unplug_request(vm, diff);\n\t\t}\n\t}\n\n\t \n\tif (!rc && vm->in_sbm && vm->sbm.have_unplugged_mb)\n\t\trc = -EBUSY;\n\n\tswitch (rc) {\n\tcase 0:\n\t\tvm->retry_timer_ms = VIRTIO_MEM_RETRY_TIMER_MIN_MS;\n\t\tbreak;\n\tcase -ENOSPC:\n\t\t \n\t\tbreak;\n\tcase -ETXTBSY:\n\t\t \n\tcase -EBUSY:\n\t\t \n\tcase -ENOMEM:\n\t\t \n\t\thrtimer_start(&vm->retry_timer, ms_to_ktime(vm->retry_timer_ms),\n\t\t\t      HRTIMER_MODE_REL);\n\t\tbreak;\n\tcase -EAGAIN:\n\t\t \n\t\tgoto retry;\n\tdefault:\n\t\t \n\t\tdev_err(&vm->vdev->dev,\n\t\t\t\"unknown error, marking device broken: %d\\n\", rc);\n\t\tvm->broken = true;\n\t}\n\n\tatomic_set(&vm->wq_active, 0);\n}\n\nstatic enum hrtimer_restart virtio_mem_timer_expired(struct hrtimer *timer)\n{\n\tstruct virtio_mem *vm = container_of(timer, struct virtio_mem,\n\t\t\t\t\t     retry_timer);\n\n\tvirtio_mem_retry(vm);\n\tvm->retry_timer_ms = min_t(unsigned int, vm->retry_timer_ms * 2,\n\t\t\t\t   VIRTIO_MEM_RETRY_TIMER_MAX_MS);\n\treturn HRTIMER_NORESTART;\n}\n\nstatic void virtio_mem_handle_response(struct virtqueue *vq)\n{\n\tstruct virtio_mem *vm = vq->vdev->priv;\n\n\twake_up(&vm->host_resp);\n}\n\nstatic int virtio_mem_init_vq(struct virtio_mem *vm)\n{\n\tstruct virtqueue *vq;\n\n\tvq = virtio_find_single_vq(vm->vdev, virtio_mem_handle_response,\n\t\t\t\t   \"guest-request\");\n\tif (IS_ERR(vq))\n\t\treturn PTR_ERR(vq);\n\tvm->vq = vq;\n\n\treturn 0;\n}\n\nstatic int virtio_mem_init_hotplug(struct virtio_mem *vm)\n{\n\tconst struct range pluggable_range = mhp_get_pluggable_range(true);\n\tuint64_t unit_pages, sb_size, addr;\n\tint rc;\n\n\t \n\tif (!IS_ALIGNED(vm->addr, memory_block_size_bytes()))\n\t\tdev_warn(&vm->vdev->dev,\n\t\t\t \"The alignment of the physical start address can make some memory unusable.\\n\");\n\tif (!IS_ALIGNED(vm->addr + vm->region_size, memory_block_size_bytes()))\n\t\tdev_warn(&vm->vdev->dev,\n\t\t\t \"The alignment of the physical end address can make some memory unusable.\\n\");\n\tif (vm->addr < pluggable_range.start ||\n\t    vm->addr + vm->region_size - 1 > pluggable_range.end)\n\t\tdev_warn(&vm->vdev->dev,\n\t\t\t \"Some device memory is not addressable/pluggable. This can make some memory unusable.\\n\");\n\n\t \n\tvm->offline_threshold = max_t(uint64_t, 2 * memory_block_size_bytes(),\n\t\t\t\t      VIRTIO_MEM_DEFAULT_OFFLINE_THRESHOLD);\n\n\t \n\tsb_size = PAGE_SIZE * pageblock_nr_pages;\n\tsb_size = max_t(uint64_t, vm->device_block_size, sb_size);\n\n\tif (sb_size < memory_block_size_bytes() && !force_bbm) {\n\t\t \n\t\tvm->in_sbm = true;\n\t\tvm->sbm.sb_size = sb_size;\n\t\tvm->sbm.sbs_per_mb = memory_block_size_bytes() /\n\t\t\t\t     vm->sbm.sb_size;\n\n\t\t \n\t\taddr = max_t(uint64_t, vm->addr, pluggable_range.start) +\n\t\t       memory_block_size_bytes() - 1;\n\t\tvm->sbm.first_mb_id = virtio_mem_phys_to_mb_id(addr);\n\t\tvm->sbm.next_mb_id = vm->sbm.first_mb_id;\n\t} else {\n\t\t \n\t\tvm->bbm.bb_size = max_t(uint64_t, vm->device_block_size,\n\t\t\t\t\tmemory_block_size_bytes());\n\n\t\tif (bbm_block_size) {\n\t\t\tif (!is_power_of_2(bbm_block_size)) {\n\t\t\t\tdev_warn(&vm->vdev->dev,\n\t\t\t\t\t \"bbm_block_size is not a power of 2\");\n\t\t\t} else if (bbm_block_size < vm->bbm.bb_size) {\n\t\t\t\tdev_warn(&vm->vdev->dev,\n\t\t\t\t\t \"bbm_block_size is too small\");\n\t\t\t} else {\n\t\t\t\tvm->bbm.bb_size = bbm_block_size;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\taddr = max_t(uint64_t, vm->addr, pluggable_range.start) +\n\t\t       vm->bbm.bb_size - 1;\n\t\tvm->bbm.first_bb_id = virtio_mem_phys_to_bb_id(vm, addr);\n\t\tvm->bbm.next_bb_id = vm->bbm.first_bb_id;\n\n\t\t \n\t\tvm->offline_threshold = max_t(uint64_t, 2 * vm->bbm.bb_size,\n\t\t\t\t\t      vm->offline_threshold);\n\t}\n\n\tdev_info(&vm->vdev->dev, \"memory block size: 0x%lx\",\n\t\t memory_block_size_bytes());\n\tif (vm->in_sbm)\n\t\tdev_info(&vm->vdev->dev, \"subblock size: 0x%llx\",\n\t\t\t (unsigned long long)vm->sbm.sb_size);\n\telse\n\t\tdev_info(&vm->vdev->dev, \"big block size: 0x%llx\",\n\t\t\t (unsigned long long)vm->bbm.bb_size);\n\n\t \n\trc = virtio_mem_create_resource(vm);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (vm->in_sbm)\n\t\tunit_pages = PHYS_PFN(memory_block_size_bytes());\n\telse\n\t\tunit_pages = PHYS_PFN(vm->bbm.bb_size);\n\trc = memory_group_register_dynamic(vm->nid, unit_pages);\n\tif (rc < 0)\n\t\tgoto out_del_resource;\n\tvm->mgid = rc;\n\n\t \n\tif (vm->plugged_size) {\n\t\tvm->unplug_all_required = true;\n\t\tdev_info(&vm->vdev->dev, \"unplugging all memory is required\\n\");\n\t}\n\n\t \n\tvm->memory_notifier.notifier_call = virtio_mem_memory_notifier_cb;\n\trc = register_memory_notifier(&vm->memory_notifier);\n\tif (rc)\n\t\tgoto out_unreg_group;\n\trc = register_virtio_mem_device(vm);\n\tif (rc)\n\t\tgoto out_unreg_mem;\n\n\treturn 0;\nout_unreg_mem:\n\tunregister_memory_notifier(&vm->memory_notifier);\nout_unreg_group:\n\tmemory_group_unregister(vm->mgid);\nout_del_resource:\n\tvirtio_mem_delete_resource(vm);\n\treturn rc;\n}\n\n#ifdef CONFIG_PROC_VMCORE\nstatic int virtio_mem_send_state_request(struct virtio_mem *vm, uint64_t addr,\n\t\t\t\t\t uint64_t size)\n{\n\tconst uint64_t nb_vm_blocks = size / vm->device_block_size;\n\tconst struct virtio_mem_req req = {\n\t\t.type = cpu_to_virtio16(vm->vdev, VIRTIO_MEM_REQ_STATE),\n\t\t.u.state.addr = cpu_to_virtio64(vm->vdev, addr),\n\t\t.u.state.nb_blocks = cpu_to_virtio16(vm->vdev, nb_vm_blocks),\n\t};\n\tint rc = -ENOMEM;\n\n\tdev_dbg(&vm->vdev->dev, \"requesting state: 0x%llx - 0x%llx\\n\", addr,\n\t\taddr + size - 1);\n\n\tswitch (virtio_mem_send_request(vm, &req)) {\n\tcase VIRTIO_MEM_RESP_ACK:\n\t\treturn virtio16_to_cpu(vm->vdev, vm->resp.u.state.state);\n\tcase VIRTIO_MEM_RESP_ERROR:\n\t\trc = -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tdev_dbg(&vm->vdev->dev, \"requesting state failed: %d\\n\", rc);\n\treturn rc;\n}\n\nstatic bool virtio_mem_vmcore_pfn_is_ram(struct vmcore_cb *cb,\n\t\t\t\t\t unsigned long pfn)\n{\n\tstruct virtio_mem *vm = container_of(cb, struct virtio_mem,\n\t\t\t\t\t     vmcore_cb);\n\tuint64_t addr = PFN_PHYS(pfn);\n\tbool is_ram;\n\tint rc;\n\n\tif (!virtio_mem_contains_range(vm, addr, PAGE_SIZE))\n\t\treturn true;\n\tif (!vm->plugged_size)\n\t\treturn false;\n\n\t \n\tmutex_lock(&vm->hotplug_mutex);\n\n\taddr = ALIGN_DOWN(addr, vm->device_block_size);\n\tif (addr != vm->last_block_addr) {\n\t\trc = virtio_mem_send_state_request(vm, addr,\n\t\t\t\t\t\t   vm->device_block_size);\n\t\t \n\t\tif (rc == VIRTIO_MEM_STATE_PLUGGED)\n\t\t\tvm->last_block_plugged = true;\n\t\telse\n\t\t\tvm->last_block_plugged = false;\n\t\tvm->last_block_addr = addr;\n\t}\n\n\tis_ram = vm->last_block_plugged;\n\tmutex_unlock(&vm->hotplug_mutex);\n\treturn is_ram;\n}\n#endif  \n\nstatic int virtio_mem_init_kdump(struct virtio_mem *vm)\n{\n#ifdef CONFIG_PROC_VMCORE\n\tdev_info(&vm->vdev->dev, \"memory hot(un)plug disabled in kdump kernel\\n\");\n\tvm->vmcore_cb.pfn_is_ram = virtio_mem_vmcore_pfn_is_ram;\n\tregister_vmcore_cb(&vm->vmcore_cb);\n\treturn 0;\n#else  \n\tdev_warn(&vm->vdev->dev, \"disabled in kdump kernel without vmcore\\n\");\n\treturn -EBUSY;\n#endif  \n}\n\nstatic int virtio_mem_init(struct virtio_mem *vm)\n{\n\tuint16_t node_id;\n\n\tif (!vm->vdev->config->get) {\n\t\tdev_err(&vm->vdev->dev, \"config access disabled\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config, plugged_size,\n\t\t\t&vm->plugged_size);\n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config, block_size,\n\t\t\t&vm->device_block_size);\n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config, node_id,\n\t\t\t&node_id);\n\tvm->nid = virtio_mem_translate_node_id(vm, node_id);\n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config, addr, &vm->addr);\n\tvirtio_cread_le(vm->vdev, struct virtio_mem_config, region_size,\n\t\t\t&vm->region_size);\n\n\t \n\tif (vm->nid == NUMA_NO_NODE)\n\t\tvm->nid = memory_add_physaddr_to_nid(vm->addr);\n\n\tdev_info(&vm->vdev->dev, \"start address: 0x%llx\", vm->addr);\n\tdev_info(&vm->vdev->dev, \"region size: 0x%llx\", vm->region_size);\n\tdev_info(&vm->vdev->dev, \"device block size: 0x%llx\",\n\t\t (unsigned long long)vm->device_block_size);\n\tif (vm->nid != NUMA_NO_NODE && IS_ENABLED(CONFIG_NUMA))\n\t\tdev_info(&vm->vdev->dev, \"nid: %d\", vm->nid);\n\n\t \n\tif (vm->in_kdump)\n\t\treturn virtio_mem_init_kdump(vm);\n\treturn virtio_mem_init_hotplug(vm);\n}\n\nstatic int virtio_mem_create_resource(struct virtio_mem *vm)\n{\n\t \n\tconst char *name = kstrdup(dev_name(&vm->vdev->dev), GFP_KERNEL);\n\n\tif (!name)\n\t\treturn -ENOMEM;\n\n\t \n\tvm->parent_resource = __request_mem_region(vm->addr, vm->region_size,\n\t\t\t\t\t\t   name, IORESOURCE_SYSTEM_RAM |\n\t\t\t\t\t\t   IORESOURCE_EXCLUSIVE);\n\tif (!vm->parent_resource) {\n\t\tkfree(name);\n\t\tdev_warn(&vm->vdev->dev, \"could not reserve device region\\n\");\n\t\tdev_info(&vm->vdev->dev,\n\t\t\t \"reloading the driver is not supported\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tvm->parent_resource->flags &= ~IORESOURCE_BUSY;\n\treturn 0;\n}\n\nstatic void virtio_mem_delete_resource(struct virtio_mem *vm)\n{\n\tconst char *name;\n\n\tif (!vm->parent_resource)\n\t\treturn;\n\n\tname = vm->parent_resource->name;\n\trelease_resource(vm->parent_resource);\n\tkfree(vm->parent_resource);\n\tkfree(name);\n\tvm->parent_resource = NULL;\n}\n\nstatic int virtio_mem_range_has_system_ram(struct resource *res, void *arg)\n{\n\treturn 1;\n}\n\nstatic bool virtio_mem_has_memory_added(struct virtio_mem *vm)\n{\n\tconst unsigned long flags = IORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY;\n\n\treturn walk_iomem_res_desc(IORES_DESC_NONE, flags, vm->addr,\n\t\t\t\t   vm->addr + vm->region_size, NULL,\n\t\t\t\t   virtio_mem_range_has_system_ram) == 1;\n}\n\nstatic int virtio_mem_probe(struct virtio_device *vdev)\n{\n\tstruct virtio_mem *vm;\n\tint rc;\n\n\tBUILD_BUG_ON(sizeof(struct virtio_mem_req) != 24);\n\tBUILD_BUG_ON(sizeof(struct virtio_mem_resp) != 10);\n\n\tvdev->priv = vm = kzalloc(sizeof(*vm), GFP_KERNEL);\n\tif (!vm)\n\t\treturn -ENOMEM;\n\n\tinit_waitqueue_head(&vm->host_resp);\n\tvm->vdev = vdev;\n\tINIT_WORK(&vm->wq, virtio_mem_run_wq);\n\tmutex_init(&vm->hotplug_mutex);\n\tINIT_LIST_HEAD(&vm->next);\n\tspin_lock_init(&vm->removal_lock);\n\thrtimer_init(&vm->retry_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tvm->retry_timer.function = virtio_mem_timer_expired;\n\tvm->retry_timer_ms = VIRTIO_MEM_RETRY_TIMER_MIN_MS;\n\tvm->in_kdump = is_kdump_kernel();\n\n\t \n\trc = virtio_mem_init_vq(vm);\n\tif (rc)\n\t\tgoto out_free_vm;\n\n\t \n\trc = virtio_mem_init(vm);\n\tif (rc)\n\t\tgoto out_del_vq;\n\n\tvirtio_device_ready(vdev);\n\n\t \n\tif (!vm->in_kdump) {\n\t\tatomic_set(&vm->config_changed, 1);\n\t\tqueue_work(system_freezable_wq, &vm->wq);\n\t}\n\n\treturn 0;\nout_del_vq:\n\tvdev->config->del_vqs(vdev);\nout_free_vm:\n\tkfree(vm);\n\tvdev->priv = NULL;\n\n\treturn rc;\n}\n\nstatic void virtio_mem_deinit_hotplug(struct virtio_mem *vm)\n{\n\tunsigned long mb_id;\n\tint rc;\n\n\t \n\tmutex_lock(&vm->hotplug_mutex);\n\tspin_lock_irq(&vm->removal_lock);\n\tvm->removing = true;\n\tspin_unlock_irq(&vm->removal_lock);\n\tmutex_unlock(&vm->hotplug_mutex);\n\n\t \n\tcancel_work_sync(&vm->wq);\n\thrtimer_cancel(&vm->retry_timer);\n\n\tif (vm->in_sbm) {\n\t\t \n\t\tvirtio_mem_sbm_for_each_mb(vm, mb_id,\n\t\t\t\t\t   VIRTIO_MEM_SBM_MB_OFFLINE_PARTIAL) {\n\t\t\trc = virtio_mem_sbm_remove_mb(vm, mb_id);\n\t\t\tBUG_ON(rc);\n\t\t\tvirtio_mem_sbm_set_mb_state(vm, mb_id,\n\t\t\t\t\t\t    VIRTIO_MEM_SBM_MB_UNUSED);\n\t\t}\n\t\t \n\t}\n\n\t \n\tunregister_virtio_mem_device(vm);\n\tunregister_memory_notifier(&vm->memory_notifier);\n\n\t \n\tif (virtio_mem_has_memory_added(vm)) {\n\t\tdev_warn(&vm->vdev->dev,\n\t\t\t \"device still has system memory added\\n\");\n\t} else {\n\t\tvirtio_mem_delete_resource(vm);\n\t\tkfree_const(vm->resource_name);\n\t\tmemory_group_unregister(vm->mgid);\n\t}\n\n\t \n\tif (vm->in_sbm) {\n\t\tvfree(vm->sbm.mb_states);\n\t\tvfree(vm->sbm.sb_states);\n\t} else {\n\t\tvfree(vm->bbm.bb_states);\n\t}\n}\n\nstatic void virtio_mem_deinit_kdump(struct virtio_mem *vm)\n{\n#ifdef CONFIG_PROC_VMCORE\n\tunregister_vmcore_cb(&vm->vmcore_cb);\n#endif  \n}\n\nstatic void virtio_mem_remove(struct virtio_device *vdev)\n{\n\tstruct virtio_mem *vm = vdev->priv;\n\n\tif (vm->in_kdump)\n\t\tvirtio_mem_deinit_kdump(vm);\n\telse\n\t\tvirtio_mem_deinit_hotplug(vm);\n\n\t \n\tvirtio_reset_device(vdev);\n\tvdev->config->del_vqs(vdev);\n\n\tkfree(vm);\n\tvdev->priv = NULL;\n}\n\nstatic void virtio_mem_config_changed(struct virtio_device *vdev)\n{\n\tstruct virtio_mem *vm = vdev->priv;\n\n\tif (unlikely(vm->in_kdump))\n\t\treturn;\n\n\tatomic_set(&vm->config_changed, 1);\n\tvirtio_mem_retry(vm);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int virtio_mem_freeze(struct virtio_device *vdev)\n{\n\t \n\tdev_err(&vdev->dev, \"save/restore not supported.\\n\");\n\treturn -EPERM;\n}\n\nstatic int virtio_mem_restore(struct virtio_device *vdev)\n{\n\treturn -EPERM;\n}\n#endif\n\nstatic unsigned int virtio_mem_features[] = {\n#if defined(CONFIG_NUMA) && defined(CONFIG_ACPI_NUMA)\n\tVIRTIO_MEM_F_ACPI_PXM,\n#endif\n\tVIRTIO_MEM_F_UNPLUGGED_INACCESSIBLE,\n};\n\nstatic const struct virtio_device_id virtio_mem_id_table[] = {\n\t{ VIRTIO_ID_MEM, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\n\nstatic struct virtio_driver virtio_mem_driver = {\n\t.feature_table = virtio_mem_features,\n\t.feature_table_size = ARRAY_SIZE(virtio_mem_features),\n\t.driver.name = KBUILD_MODNAME,\n\t.driver.owner = THIS_MODULE,\n\t.id_table = virtio_mem_id_table,\n\t.probe = virtio_mem_probe,\n\t.remove = virtio_mem_remove,\n\t.config_changed = virtio_mem_config_changed,\n#ifdef CONFIG_PM_SLEEP\n\t.freeze\t=\tvirtio_mem_freeze,\n\t.restore =\tvirtio_mem_restore,\n#endif\n};\n\nmodule_virtio_driver(virtio_mem_driver);\nMODULE_DEVICE_TABLE(virtio, virtio_mem_id_table);\nMODULE_AUTHOR(\"David Hildenbrand <david@redhat.com>\");\nMODULE_DESCRIPTION(\"Virtio-mem driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}