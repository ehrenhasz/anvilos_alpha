{
  "module_name": "irq_helpers.c",
  "hash_id": "408791ccacb92721b4291ca9413fe6438ee9d10ab0f457f1744a96eca517b24b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/regulator/irq_helpers.c",
  "human_readable_source": "\n\n\n\n\n\n\n\n\n#include <linux/device.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/reboot.h>\n#include <linux/regmap.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/regulator/driver.h>\n\n#include \"internal.h\"\n\n#define REGULATOR_FORCED_SAFETY_SHUTDOWN_WAIT_MS 10000\n\nstruct regulator_irq {\n\tstruct regulator_irq_data rdata;\n\tstruct regulator_irq_desc desc;\n\tint irq;\n\tint retry_cnt;\n\tstruct delayed_work isr_work;\n};\n\n \nstatic void rdev_flag_err(struct regulator_dev *rdev, int err)\n{\n\tspin_lock(&rdev->err_lock);\n\trdev->cached_err |= err;\n\tspin_unlock(&rdev->err_lock);\n}\n\nstatic void rdev_clear_err(struct regulator_dev *rdev, int err)\n{\n\tspin_lock(&rdev->err_lock);\n\trdev->cached_err &= ~err;\n\tspin_unlock(&rdev->err_lock);\n}\n\nstatic void regulator_notifier_isr_work(struct work_struct *work)\n{\n\tstruct regulator_irq *h;\n\tstruct regulator_irq_desc *d;\n\tstruct regulator_irq_data *rid;\n\tint ret = 0;\n\tint tmo, i;\n\tint num_rdevs;\n\n\th = container_of(work, struct regulator_irq,\n\t\t\t    isr_work.work);\n\td = &h->desc;\n\trid = &h->rdata;\n\tnum_rdevs = rid->num_states;\n\nreread:\n\tif (d->fatal_cnt && h->retry_cnt > d->fatal_cnt) {\n\t\tif (!d->die)\n\t\t\treturn hw_protection_shutdown(\"Regulator HW failure? - no IC recovery\",\n\t\t\t\t\t\t      REGULATOR_FORCED_SAFETY_SHUTDOWN_WAIT_MS);\n\t\tret = d->die(rid);\n\t\t \n\t\tif (ret)\n\t\t\treturn hw_protection_shutdown(\"Regulator HW failure. IC recovery failed\",\n\t\t\t\t\t\t      REGULATOR_FORCED_SAFETY_SHUTDOWN_WAIT_MS);\n\n\t\t \n\t\tgoto enable_out;\n\t}\n\tif (d->renable) {\n\t\tret = d->renable(rid);\n\n\t\tif (ret == REGULATOR_FAILED_RETRY) {\n\t\t\t \n\t\t\th->retry_cnt++;\n\t\t\tif (!d->reread_ms)\n\t\t\t\tgoto reread;\n\n\t\t\ttmo = d->reread_ms;\n\t\t\tgoto reschedule;\n\t\t}\n\n\t\tif (ret) {\n\t\t\t \n\t\t\tfor (i = 0; i < num_rdevs; i++) {\n\t\t\t\tstruct regulator_err_state *stat;\n\t\t\t\tstruct regulator_dev *rdev;\n\n\t\t\t\tstat = &rid->states[i];\n\t\t\t\trdev = stat->rdev;\n\t\t\t\trdev_clear_err(rdev, (~stat->errors) &\n\t\t\t\t\t\t      stat->possible_errs);\n\t\t\t}\n\t\t\th->retry_cnt++;\n\t\t\t \n\t\t\ttmo = d->irq_off_ms;\n\t\t\tgoto reschedule;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < num_rdevs; i++) {\n\t\tstruct regulator_err_state *stat;\n\t\tstruct regulator_dev *rdev;\n\n\t\tstat = &rid->states[i];\n\t\trdev = stat->rdev;\n\t\trdev_clear_err(rdev, stat->possible_errs);\n\t}\n\n\t \n\th->retry_cnt = 0;\n\nenable_out:\n\tenable_irq(h->irq);\n\n\treturn;\n\nreschedule:\n\tif (!d->high_prio)\n\t\tmod_delayed_work(system_wq, &h->isr_work,\n\t\t\t\t msecs_to_jiffies(tmo));\n\telse\n\t\tmod_delayed_work(system_highpri_wq, &h->isr_work,\n\t\t\t\t msecs_to_jiffies(tmo));\n}\n\nstatic irqreturn_t regulator_notifier_isr(int irq, void *data)\n{\n\tstruct regulator_irq *h = data;\n\tstruct regulator_irq_desc *d;\n\tstruct regulator_irq_data *rid;\n\tunsigned long rdev_map = 0;\n\tint num_rdevs;\n\tint ret, i;\n\n\td = &h->desc;\n\trid = &h->rdata;\n\tnum_rdevs = rid->num_states;\n\n\tif (d->fatal_cnt)\n\t\th->retry_cnt++;\n\n\t \n\tret = d->map_event(irq, rid, &rdev_map);\n\n\t \n\tif (unlikely(ret == REGULATOR_FAILED_RETRY))\n\t\tgoto fail_out;\n\n\th->retry_cnt = 0;\n\t \n\tif (ret || !rdev_map)\n\t\treturn IRQ_NONE;\n\n\t \n\tif (d->skip_off) {\n\t\tfor_each_set_bit(i, &rdev_map, num_rdevs) {\n\t\t\tstruct regulator_dev *rdev;\n\t\t\tconst struct regulator_ops *ops;\n\n\t\t\trdev = rid->states[i].rdev;\n\t\t\tops = rdev->desc->ops;\n\n\t\t\t \n\t\t\tif (ops->is_enabled(rdev))\n\t\t\t\tbreak;\n\t\t}\n\t\tif (i == num_rdevs)\n\t\t\treturn IRQ_NONE;\n\t}\n\n\t \n\tif (d->irq_off_ms)\n\t\tdisable_irq_nosync(irq);\n\n\t \n\tfor_each_set_bit(i, &rdev_map, num_rdevs) {\n\t\tstruct regulator_err_state *stat;\n\t\tstruct regulator_dev *rdev;\n\n\t\tstat = &rid->states[i];\n\t\trdev = stat->rdev;\n\n\t\trdev_dbg(rdev, \"Sending regulator notification EVT 0x%lx\\n\",\n\t\t\t stat->notifs);\n\n\t\tregulator_notifier_call_chain(rdev, stat->notifs, NULL);\n\t\trdev_flag_err(rdev, stat->errors);\n\t}\n\n\tif (d->irq_off_ms) {\n\t\tif (!d->high_prio)\n\t\t\tschedule_delayed_work(&h->isr_work,\n\t\t\t\t\t      msecs_to_jiffies(d->irq_off_ms));\n\t\telse\n\t\t\tmod_delayed_work(system_highpri_wq,\n\t\t\t\t\t &h->isr_work,\n\t\t\t\t\t msecs_to_jiffies(d->irq_off_ms));\n\t}\n\n\treturn IRQ_HANDLED;\n\nfail_out:\n\tif (d->fatal_cnt && h->retry_cnt > d->fatal_cnt) {\n\t\t \n\t\tif (!d->die) {\n\t\t\thw_protection_shutdown(\"Regulator failure. Retry count exceeded\",\n\t\t\t\t\t       REGULATOR_FORCED_SAFETY_SHUTDOWN_WAIT_MS);\n\t\t} else {\n\t\t\tret = d->die(rid);\n\t\t\t \n\t\t\tif (ret)\n\t\t\t\thw_protection_shutdown(\"Regulator failure. Recovery failed\",\n\t\t\t\t\t\t       REGULATOR_FORCED_SAFETY_SHUTDOWN_WAIT_MS);\n\t\t}\n\t}\n\n\treturn IRQ_NONE;\n}\n\nstatic int init_rdev_state(struct device *dev, struct regulator_irq *h,\n\t\t\t   struct regulator_dev **rdev, int common_err,\n\t\t\t   int *rdev_err, int rdev_amount)\n{\n\tint i;\n\n\th->rdata.states = devm_kzalloc(dev, sizeof(*h->rdata.states) *\n\t\t\t\t       rdev_amount, GFP_KERNEL);\n\tif (!h->rdata.states)\n\t\treturn -ENOMEM;\n\n\th->rdata.num_states = rdev_amount;\n\th->rdata.data = h->desc.data;\n\n\tfor (i = 0; i < rdev_amount; i++) {\n\t\th->rdata.states[i].possible_errs = common_err;\n\t\tif (rdev_err)\n\t\t\th->rdata.states[i].possible_errs |= *rdev_err++;\n\t\th->rdata.states[i].rdev = *rdev++;\n\t}\n\n\treturn 0;\n}\n\nstatic void init_rdev_errors(struct regulator_irq *h)\n{\n\tint i;\n\n\tfor (i = 0; i < h->rdata.num_states; i++)\n\t\tif (h->rdata.states[i].possible_errs)\n\t\t\th->rdata.states[i].rdev->use_cached_err = true;\n}\n\n \nvoid *regulator_irq_helper(struct device *dev,\n\t\t\t   const struct regulator_irq_desc *d, int irq,\n\t\t\t   int irq_flags, int common_errs, int *per_rdev_errs,\n\t\t\t   struct regulator_dev **rdev, int rdev_amount)\n{\n\tstruct regulator_irq *h;\n\tint ret;\n\n\tif (!rdev_amount || !d || !d->map_event || !d->name)\n\t\treturn ERR_PTR(-EINVAL);\n\n\th = devm_kzalloc(dev, sizeof(*h), GFP_KERNEL);\n\tif (!h)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\th->irq = irq;\n\th->desc = *d;\n\n\tret = init_rdev_state(dev, h, rdev, common_errs, per_rdev_errs,\n\t\t\t      rdev_amount);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tinit_rdev_errors(h);\n\n\tif (h->desc.irq_off_ms)\n\t\tINIT_DELAYED_WORK(&h->isr_work, regulator_notifier_isr_work);\n\n\tret = request_threaded_irq(h->irq, NULL, regulator_notifier_isr,\n\t\t\t\t   IRQF_ONESHOT | irq_flags, h->desc.name, h);\n\tif (ret) {\n\t\tdev_err(dev, \"Failed to request IRQ %d\\n\", irq);\n\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn h;\n}\nEXPORT_SYMBOL_GPL(regulator_irq_helper);\n\n \nvoid regulator_irq_helper_cancel(void **handle)\n{\n\tif (handle && *handle) {\n\t\tstruct regulator_irq *h = *handle;\n\n\t\tfree_irq(h->irq, h);\n\t\tif (h->desc.irq_off_ms)\n\t\t\tcancel_delayed_work_sync(&h->isr_work);\n\n\t\th = NULL;\n\t}\n}\nEXPORT_SYMBOL_GPL(regulator_irq_helper_cancel);\n\n \nint regulator_irq_map_event_simple(int irq, struct regulator_irq_data *rid,\n\t\t\t    unsigned long *dev_mask)\n{\n\tint err = rid->states[0].possible_errs;\n\n\t*dev_mask = 1;\n\t \n\tif (WARN_ON(rid->num_states != 1 || hweight32(err) != 1))\n\t\treturn 0;\n\n\trid->states[0].errors = err;\n\trid->states[0].notifs = regulator_err2notif(err);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(regulator_irq_map_event_simple);\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}