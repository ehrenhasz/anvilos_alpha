{
  "module_name": "industrialio-buffer.c",
  "hash_id": "de5cbf90ce4027a6d05cc4b4832ae52ba5f5b4184df27d97065c7aed8cef08e1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iio/industrialio-buffer.c",
  "human_readable_source": "\n \n#include <linux/anon_inodes.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/file.h>\n#include <linux/fs.h>\n#include <linux/cdev.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/sched/signal.h>\n\n#include <linux/iio/iio.h>\n#include <linux/iio/iio-opaque.h>\n#include \"iio_core.h\"\n#include \"iio_core_trigger.h\"\n#include <linux/iio/sysfs.h>\n#include <linux/iio/buffer.h>\n#include <linux/iio/buffer_impl.h>\n\nstatic const char * const iio_endian_prefix[] = {\n\t[IIO_BE] = \"be\",\n\t[IIO_LE] = \"le\",\n};\n\nstatic bool iio_buffer_is_active(struct iio_buffer *buf)\n{\n\treturn !list_empty(&buf->buffer_list);\n}\n\nstatic size_t iio_buffer_data_available(struct iio_buffer *buf)\n{\n\treturn buf->access->data_available(buf);\n}\n\nstatic int iio_buffer_flush_hwfifo(struct iio_dev *indio_dev,\n\t\t\t\t   struct iio_buffer *buf, size_t required)\n{\n\tif (!indio_dev->info->hwfifo_flush_to_buffer)\n\t\treturn -ENODEV;\n\n\treturn indio_dev->info->hwfifo_flush_to_buffer(indio_dev, required);\n}\n\nstatic bool iio_buffer_ready(struct iio_dev *indio_dev, struct iio_buffer *buf,\n\t\t\t     size_t to_wait, int to_flush)\n{\n\tsize_t avail;\n\tint flushed = 0;\n\n\t \n\tif (!indio_dev->info)\n\t\treturn true;\n\n\t \n\tif (!iio_buffer_is_active(buf)) {\n\t\tto_wait = min_t(size_t, to_wait, 1);\n\t\tto_flush = 0;\n\t}\n\n\tavail = iio_buffer_data_available(buf);\n\n\tif (avail >= to_wait) {\n\t\t \n\t\tif (!to_wait && avail < to_flush)\n\t\t\tiio_buffer_flush_hwfifo(indio_dev, buf,\n\t\t\t\t\t\tto_flush - avail);\n\t\treturn true;\n\t}\n\n\tif (to_flush)\n\t\tflushed = iio_buffer_flush_hwfifo(indio_dev, buf,\n\t\t\t\t\t\t  to_wait - avail);\n\tif (flushed <= 0)\n\t\treturn false;\n\n\tif (avail + flushed >= to_wait)\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic ssize_t iio_buffer_read(struct file *filp, char __user *buf,\n\t\t\t       size_t n, loff_t *f_ps)\n{\n\tstruct iio_dev_buffer_pair *ib = filp->private_data;\n\tstruct iio_buffer *rb = ib->buffer;\n\tstruct iio_dev *indio_dev = ib->indio_dev;\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tsize_t datum_size;\n\tsize_t to_wait;\n\tint ret = 0;\n\n\tif (!indio_dev->info)\n\t\treturn -ENODEV;\n\n\tif (!rb || !rb->access->read)\n\t\treturn -EINVAL;\n\n\tif (rb->direction != IIO_BUFFER_DIRECTION_IN)\n\t\treturn -EPERM;\n\n\tdatum_size = rb->bytes_per_datum;\n\n\t \n\tif (!datum_size)\n\t\treturn 0;\n\n\tif (filp->f_flags & O_NONBLOCK)\n\t\tto_wait = 0;\n\telse\n\t\tto_wait = min_t(size_t, n / datum_size, rb->watermark);\n\n\tadd_wait_queue(&rb->pollq, &wait);\n\tdo {\n\t\tif (!indio_dev->info) {\n\t\t\tret = -ENODEV;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!iio_buffer_ready(indio_dev, rb, to_wait, n / datum_size)) {\n\t\t\tif (signal_pending(current)) {\n\t\t\t\tret = -ERESTARTSYS;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\twait_woken(&wait, TASK_INTERRUPTIBLE,\n\t\t\t\t   MAX_SCHEDULE_TIMEOUT);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = rb->access->read(rb, n, buf);\n\t\tif (ret == 0 && (filp->f_flags & O_NONBLOCK))\n\t\t\tret = -EAGAIN;\n\t} while (ret == 0);\n\tremove_wait_queue(&rb->pollq, &wait);\n\n\treturn ret;\n}\n\nstatic size_t iio_buffer_space_available(struct iio_buffer *buf)\n{\n\tif (buf->access->space_available)\n\t\treturn buf->access->space_available(buf);\n\n\treturn SIZE_MAX;\n}\n\nstatic ssize_t iio_buffer_write(struct file *filp, const char __user *buf,\n\t\t\t\tsize_t n, loff_t *f_ps)\n{\n\tstruct iio_dev_buffer_pair *ib = filp->private_data;\n\tstruct iio_buffer *rb = ib->buffer;\n\tstruct iio_dev *indio_dev = ib->indio_dev;\n\tDEFINE_WAIT_FUNC(wait, woken_wake_function);\n\tint ret = 0;\n\tsize_t written;\n\n\tif (!indio_dev->info)\n\t\treturn -ENODEV;\n\n\tif (!rb || !rb->access->write)\n\t\treturn -EINVAL;\n\n\tif (rb->direction != IIO_BUFFER_DIRECTION_OUT)\n\t\treturn -EPERM;\n\n\twritten = 0;\n\tadd_wait_queue(&rb->pollq, &wait);\n\tdo {\n\t\tif (!indio_dev->info)\n\t\t\treturn -ENODEV;\n\n\t\tif (!iio_buffer_space_available(rb)) {\n\t\t\tif (signal_pending(current)) {\n\t\t\t\tret = -ERESTARTSYS;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (filp->f_flags & O_NONBLOCK) {\n\t\t\t\tif (!written)\n\t\t\t\t\tret = -EAGAIN;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\twait_woken(&wait, TASK_INTERRUPTIBLE,\n\t\t\t\t   MAX_SCHEDULE_TIMEOUT);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = rb->access->write(rb, n - written, buf + written);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\twritten += ret;\n\n\t} while (written != n);\n\tremove_wait_queue(&rb->pollq, &wait);\n\n\treturn ret < 0 ? ret : written;\n}\n\n \nstatic __poll_t iio_buffer_poll(struct file *filp,\n\t\t\t\tstruct poll_table_struct *wait)\n{\n\tstruct iio_dev_buffer_pair *ib = filp->private_data;\n\tstruct iio_buffer *rb = ib->buffer;\n\tstruct iio_dev *indio_dev = ib->indio_dev;\n\n\tif (!indio_dev->info || !rb)\n\t\treturn 0;\n\n\tpoll_wait(filp, &rb->pollq, wait);\n\n\tswitch (rb->direction) {\n\tcase IIO_BUFFER_DIRECTION_IN:\n\t\tif (iio_buffer_ready(indio_dev, rb, rb->watermark, 0))\n\t\t\treturn EPOLLIN | EPOLLRDNORM;\n\t\tbreak;\n\tcase IIO_BUFFER_DIRECTION_OUT:\n\t\tif (iio_buffer_space_available(rb))\n\t\t\treturn EPOLLOUT | EPOLLWRNORM;\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nssize_t iio_buffer_read_wrapper(struct file *filp, char __user *buf,\n\t\t\t\tsize_t n, loff_t *f_ps)\n{\n\tstruct iio_dev_buffer_pair *ib = filp->private_data;\n\tstruct iio_buffer *rb = ib->buffer;\n\n\t \n\tif (test_bit(IIO_BUSY_BIT_POS, &rb->flags))\n\t\treturn -EBUSY;\n\n\treturn iio_buffer_read(filp, buf, n, f_ps);\n}\n\nssize_t iio_buffer_write_wrapper(struct file *filp, const char __user *buf,\n\t\t\t\t size_t n, loff_t *f_ps)\n{\n\tstruct iio_dev_buffer_pair *ib = filp->private_data;\n\tstruct iio_buffer *rb = ib->buffer;\n\n\t \n\tif (test_bit(IIO_BUSY_BIT_POS, &rb->flags))\n\t\treturn -EBUSY;\n\n\treturn iio_buffer_write(filp, buf, n, f_ps);\n}\n\n__poll_t iio_buffer_poll_wrapper(struct file *filp,\n\t\t\t\t struct poll_table_struct *wait)\n{\n\tstruct iio_dev_buffer_pair *ib = filp->private_data;\n\tstruct iio_buffer *rb = ib->buffer;\n\n\t \n\tif (test_bit(IIO_BUSY_BIT_POS, &rb->flags))\n\t\treturn 0;\n\n\treturn iio_buffer_poll(filp, wait);\n}\n\n \nvoid iio_buffer_wakeup_poll(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer;\n\tunsigned int i;\n\n\tfor (i = 0; i < iio_dev_opaque->attached_buffers_cnt; i++) {\n\t\tbuffer = iio_dev_opaque->attached_buffers[i];\n\t\twake_up(&buffer->pollq);\n\t}\n}\n\nint iio_pop_from_buffer(struct iio_buffer *buffer, void *data)\n{\n\tif (!buffer || !buffer->access || !buffer->access->remove_from)\n\t\treturn -EINVAL;\n\n\treturn buffer->access->remove_from(buffer, data);\n}\nEXPORT_SYMBOL_GPL(iio_pop_from_buffer);\n\nvoid iio_buffer_init(struct iio_buffer *buffer)\n{\n\tINIT_LIST_HEAD(&buffer->demux_list);\n\tINIT_LIST_HEAD(&buffer->buffer_list);\n\tinit_waitqueue_head(&buffer->pollq);\n\tkref_init(&buffer->ref);\n\tif (!buffer->watermark)\n\t\tbuffer->watermark = 1;\n}\nEXPORT_SYMBOL(iio_buffer_init);\n\nvoid iio_device_detach_buffers(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer;\n\tunsigned int i;\n\n\tfor (i = 0; i < iio_dev_opaque->attached_buffers_cnt; i++) {\n\t\tbuffer = iio_dev_opaque->attached_buffers[i];\n\t\tiio_buffer_put(buffer);\n\t}\n\n\tkfree(iio_dev_opaque->attached_buffers);\n}\n\nstatic ssize_t iio_show_scan_index(struct device *dev,\n\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t   char *buf)\n{\n\treturn sysfs_emit(buf, \"%u\\n\", to_iio_dev_attr(attr)->c->scan_index);\n}\n\nstatic ssize_t iio_show_fixed_type(struct device *dev,\n\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t   char *buf)\n{\n\tstruct iio_dev_attr *this_attr = to_iio_dev_attr(attr);\n\tu8 type = this_attr->c->scan_type.endianness;\n\n\tif (type == IIO_CPU) {\n#ifdef __LITTLE_ENDIAN\n\t\ttype = IIO_LE;\n#else\n\t\ttype = IIO_BE;\n#endif\n\t}\n\tif (this_attr->c->scan_type.repeat > 1)\n\t\treturn sysfs_emit(buf, \"%s:%c%d/%dX%d>>%u\\n\",\n\t\t       iio_endian_prefix[type],\n\t\t       this_attr->c->scan_type.sign,\n\t\t       this_attr->c->scan_type.realbits,\n\t\t       this_attr->c->scan_type.storagebits,\n\t\t       this_attr->c->scan_type.repeat,\n\t\t       this_attr->c->scan_type.shift);\n\telse\n\t\treturn sysfs_emit(buf, \"%s:%c%d/%d>>%u\\n\",\n\t\t       iio_endian_prefix[type],\n\t\t       this_attr->c->scan_type.sign,\n\t\t       this_attr->c->scan_type.realbits,\n\t\t       this_attr->c->scan_type.storagebits,\n\t\t       this_attr->c->scan_type.shift);\n}\n\nstatic ssize_t iio_scan_el_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr,\n\t\t\t\tchar *buf)\n{\n\tint ret;\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\n\t \n\tret = !!test_bit(to_iio_dev_attr(attr)->address,\n\t\t       buffer->scan_mask);\n\n\treturn sysfs_emit(buf, \"%d\\n\", ret);\n}\n\n \nstatic const unsigned long *iio_scan_mask_match(const unsigned long *av_masks,\n\t\t\t\t\t\tunsigned int masklength,\n\t\t\t\t\t\tconst unsigned long *mask,\n\t\t\t\t\t\tbool strict)\n{\n\tif (bitmap_empty(mask, masklength))\n\t\treturn NULL;\n\twhile (*av_masks) {\n\t\tif (strict) {\n\t\t\tif (bitmap_equal(mask, av_masks, masklength))\n\t\t\t\treturn av_masks;\n\t\t} else {\n\t\t\tif (bitmap_subset(mask, av_masks, masklength))\n\t\t\t\treturn av_masks;\n\t\t}\n\t\tav_masks += BITS_TO_LONGS(masklength);\n\t}\n\treturn NULL;\n}\n\nstatic bool iio_validate_scan_mask(struct iio_dev *indio_dev,\n\t\t\t\t   const unsigned long *mask)\n{\n\tif (!indio_dev->setup_ops->validate_scan_mask)\n\t\treturn true;\n\n\treturn indio_dev->setup_ops->validate_scan_mask(indio_dev, mask);\n}\n\n \nstatic int iio_scan_mask_set(struct iio_dev *indio_dev,\n\t\t\t     struct iio_buffer *buffer, int bit)\n{\n\tconst unsigned long *mask;\n\tunsigned long *trialmask;\n\n\tif (!indio_dev->masklength) {\n\t\tWARN(1, \"Trying to set scanmask prior to registering buffer\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ttrialmask = bitmap_alloc(indio_dev->masklength, GFP_KERNEL);\n\tif (!trialmask)\n\t\treturn -ENOMEM;\n\tbitmap_copy(trialmask, buffer->scan_mask, indio_dev->masklength);\n\tset_bit(bit, trialmask);\n\n\tif (!iio_validate_scan_mask(indio_dev, trialmask))\n\t\tgoto err_invalid_mask;\n\n\tif (indio_dev->available_scan_masks) {\n\t\tmask = iio_scan_mask_match(indio_dev->available_scan_masks,\n\t\t\t\t\t   indio_dev->masklength,\n\t\t\t\t\t   trialmask, false);\n\t\tif (!mask)\n\t\t\tgoto err_invalid_mask;\n\t}\n\tbitmap_copy(buffer->scan_mask, trialmask, indio_dev->masklength);\n\n\tbitmap_free(trialmask);\n\n\treturn 0;\n\nerr_invalid_mask:\n\tbitmap_free(trialmask);\n\treturn -EINVAL;\n}\n\nstatic int iio_scan_mask_clear(struct iio_buffer *buffer, int bit)\n{\n\tclear_bit(bit, buffer->scan_mask);\n\treturn 0;\n}\n\nstatic int iio_scan_mask_query(struct iio_dev *indio_dev,\n\t\t\t       struct iio_buffer *buffer, int bit)\n{\n\tif (bit > indio_dev->masklength)\n\t\treturn -EINVAL;\n\n\tif (!buffer->scan_mask)\n\t\treturn 0;\n\n\t \n\treturn !!test_bit(bit, buffer->scan_mask);\n};\n\nstatic ssize_t iio_scan_el_store(struct device *dev,\n\t\t\t\t struct device_attribute *attr,\n\t\t\t\t const char *buf,\n\t\t\t\t size_t len)\n{\n\tint ret;\n\tbool state;\n\tstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_dev_attr *this_attr = to_iio_dev_attr(attr);\n\tstruct iio_buffer *buffer = this_attr->buffer;\n\n\tret = kstrtobool(buf, &state);\n\tif (ret < 0)\n\t\treturn ret;\n\tmutex_lock(&iio_dev_opaque->mlock);\n\tif (iio_buffer_is_active(buffer)) {\n\t\tret = -EBUSY;\n\t\tgoto error_ret;\n\t}\n\tret = iio_scan_mask_query(indio_dev, buffer, this_attr->address);\n\tif (ret < 0)\n\t\tgoto error_ret;\n\tif (!state && ret) {\n\t\tret = iio_scan_mask_clear(buffer, this_attr->address);\n\t\tif (ret)\n\t\t\tgoto error_ret;\n\t} else if (state && !ret) {\n\t\tret = iio_scan_mask_set(indio_dev, buffer, this_attr->address);\n\t\tif (ret)\n\t\t\tgoto error_ret;\n\t}\n\nerror_ret:\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\n\treturn ret < 0 ? ret : len;\n}\n\nstatic ssize_t iio_scan_el_ts_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t   char *buf)\n{\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\n\treturn sysfs_emit(buf, \"%d\\n\", buffer->scan_timestamp);\n}\n\nstatic ssize_t iio_scan_el_ts_store(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    const char *buf,\n\t\t\t\t    size_t len)\n{\n\tint ret;\n\tstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\tbool state;\n\n\tret = kstrtobool(buf, &state);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&iio_dev_opaque->mlock);\n\tif (iio_buffer_is_active(buffer)) {\n\t\tret = -EBUSY;\n\t\tgoto error_ret;\n\t}\n\tbuffer->scan_timestamp = state;\nerror_ret:\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\n\treturn ret ? ret : len;\n}\n\nstatic int iio_buffer_add_channel_sysfs(struct iio_dev *indio_dev,\n\t\t\t\t\tstruct iio_buffer *buffer,\n\t\t\t\t\tconst struct iio_chan_spec *chan)\n{\n\tint ret, attrcount = 0;\n\n\tret = __iio_add_chan_devattr(\"index\",\n\t\t\t\t     chan,\n\t\t\t\t     &iio_show_scan_index,\n\t\t\t\t     NULL,\n\t\t\t\t     0,\n\t\t\t\t     IIO_SEPARATE,\n\t\t\t\t     &indio_dev->dev,\n\t\t\t\t     buffer,\n\t\t\t\t     &buffer->buffer_attr_list);\n\tif (ret)\n\t\treturn ret;\n\tattrcount++;\n\tret = __iio_add_chan_devattr(\"type\",\n\t\t\t\t     chan,\n\t\t\t\t     &iio_show_fixed_type,\n\t\t\t\t     NULL,\n\t\t\t\t     0,\n\t\t\t\t     0,\n\t\t\t\t     &indio_dev->dev,\n\t\t\t\t     buffer,\n\t\t\t\t     &buffer->buffer_attr_list);\n\tif (ret)\n\t\treturn ret;\n\tattrcount++;\n\tif (chan->type != IIO_TIMESTAMP)\n\t\tret = __iio_add_chan_devattr(\"en\",\n\t\t\t\t\t     chan,\n\t\t\t\t\t     &iio_scan_el_show,\n\t\t\t\t\t     &iio_scan_el_store,\n\t\t\t\t\t     chan->scan_index,\n\t\t\t\t\t     0,\n\t\t\t\t\t     &indio_dev->dev,\n\t\t\t\t\t     buffer,\n\t\t\t\t\t     &buffer->buffer_attr_list);\n\telse\n\t\tret = __iio_add_chan_devattr(\"en\",\n\t\t\t\t\t     chan,\n\t\t\t\t\t     &iio_scan_el_ts_show,\n\t\t\t\t\t     &iio_scan_el_ts_store,\n\t\t\t\t\t     chan->scan_index,\n\t\t\t\t\t     0,\n\t\t\t\t\t     &indio_dev->dev,\n\t\t\t\t\t     buffer,\n\t\t\t\t\t     &buffer->buffer_attr_list);\n\tif (ret)\n\t\treturn ret;\n\tattrcount++;\n\tret = attrcount;\n\treturn ret;\n}\n\nstatic ssize_t length_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\n\treturn sysfs_emit(buf, \"%d\\n\", buffer->length);\n}\n\nstatic ssize_t length_store(struct device *dev, struct device_attribute *attr,\n\t\t\t    const char *buf, size_t len)\n{\n\tstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\tunsigned int val;\n\tint ret;\n\n\tret = kstrtouint(buf, 10, &val);\n\tif (ret)\n\t\treturn ret;\n\n\tif (val == buffer->length)\n\t\treturn len;\n\n\tmutex_lock(&iio_dev_opaque->mlock);\n\tif (iio_buffer_is_active(buffer)) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tbuffer->access->set_length(buffer, val);\n\t\tret = 0;\n\t}\n\tif (ret)\n\t\tgoto out;\n\tif (buffer->length && buffer->length < buffer->watermark)\n\t\tbuffer->watermark = buffer->length;\nout:\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\n\treturn ret ? ret : len;\n}\n\nstatic ssize_t enable_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\n\treturn sysfs_emit(buf, \"%d\\n\", iio_buffer_is_active(buffer));\n}\n\nstatic unsigned int iio_storage_bytes_for_si(struct iio_dev *indio_dev,\n\t\t\t\t\t     unsigned int scan_index)\n{\n\tconst struct iio_chan_spec *ch;\n\tunsigned int bytes;\n\n\tch = iio_find_channel_from_si(indio_dev, scan_index);\n\tbytes = ch->scan_type.storagebits / 8;\n\tif (ch->scan_type.repeat > 1)\n\t\tbytes *= ch->scan_type.repeat;\n\treturn bytes;\n}\n\nstatic unsigned int iio_storage_bytes_for_timestamp(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\n\treturn iio_storage_bytes_for_si(indio_dev,\n\t\t\t\t\tiio_dev_opaque->scan_index_timestamp);\n}\n\nstatic int iio_compute_scan_bytes(struct iio_dev *indio_dev,\n\t\t\t\t  const unsigned long *mask, bool timestamp)\n{\n\tunsigned int bytes = 0;\n\tint length, i, largest = 0;\n\n\t \n\tfor_each_set_bit(i, mask,\n\t\t\t indio_dev->masklength) {\n\t\tlength = iio_storage_bytes_for_si(indio_dev, i);\n\t\tbytes = ALIGN(bytes, length);\n\t\tbytes += length;\n\t\tlargest = max(largest, length);\n\t}\n\n\tif (timestamp) {\n\t\tlength = iio_storage_bytes_for_timestamp(indio_dev);\n\t\tbytes = ALIGN(bytes, length);\n\t\tbytes += length;\n\t\tlargest = max(largest, length);\n\t}\n\n\tbytes = ALIGN(bytes, largest);\n\treturn bytes;\n}\n\nstatic void iio_buffer_activate(struct iio_dev *indio_dev,\n\t\t\t\tstruct iio_buffer *buffer)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\n\tiio_buffer_get(buffer);\n\tlist_add(&buffer->buffer_list, &iio_dev_opaque->buffer_list);\n}\n\nstatic void iio_buffer_deactivate(struct iio_buffer *buffer)\n{\n\tlist_del_init(&buffer->buffer_list);\n\twake_up_interruptible(&buffer->pollq);\n\tiio_buffer_put(buffer);\n}\n\nstatic void iio_buffer_deactivate_all(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer, *_buffer;\n\n\tlist_for_each_entry_safe(buffer, _buffer,\n\t\t\t\t &iio_dev_opaque->buffer_list, buffer_list)\n\t\tiio_buffer_deactivate(buffer);\n}\n\nstatic int iio_buffer_enable(struct iio_buffer *buffer,\n\t\t\t     struct iio_dev *indio_dev)\n{\n\tif (!buffer->access->enable)\n\t\treturn 0;\n\treturn buffer->access->enable(buffer, indio_dev);\n}\n\nstatic int iio_buffer_disable(struct iio_buffer *buffer,\n\t\t\t      struct iio_dev *indio_dev)\n{\n\tif (!buffer->access->disable)\n\t\treturn 0;\n\treturn buffer->access->disable(buffer, indio_dev);\n}\n\nstatic void iio_buffer_update_bytes_per_datum(struct iio_dev *indio_dev,\n\t\t\t\t\t      struct iio_buffer *buffer)\n{\n\tunsigned int bytes;\n\n\tif (!buffer->access->set_bytes_per_datum)\n\t\treturn;\n\n\tbytes = iio_compute_scan_bytes(indio_dev, buffer->scan_mask,\n\t\t\t\t       buffer->scan_timestamp);\n\n\tbuffer->access->set_bytes_per_datum(buffer, bytes);\n}\n\nstatic int iio_buffer_request_update(struct iio_dev *indio_dev,\n\t\t\t\t     struct iio_buffer *buffer)\n{\n\tint ret;\n\n\tiio_buffer_update_bytes_per_datum(indio_dev, buffer);\n\tif (buffer->access->request_update) {\n\t\tret = buffer->access->request_update(buffer);\n\t\tif (ret) {\n\t\t\tdev_dbg(&indio_dev->dev,\n\t\t\t\t\"Buffer not started: buffer parameter update failed (%d)\\n\",\n\t\t\t\tret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void iio_free_scan_mask(struct iio_dev *indio_dev,\n\t\t\t       const unsigned long *mask)\n{\n\t \n\tif (!indio_dev->available_scan_masks)\n\t\tbitmap_free(mask);\n}\n\nstruct iio_device_config {\n\tunsigned int mode;\n\tunsigned int watermark;\n\tconst unsigned long *scan_mask;\n\tunsigned int scan_bytes;\n\tbool scan_timestamp;\n};\n\nstatic int iio_verify_update(struct iio_dev *indio_dev,\n\t\t\t     struct iio_buffer *insert_buffer,\n\t\t\t     struct iio_buffer *remove_buffer,\n\t\t\t     struct iio_device_config *config)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tunsigned long *compound_mask;\n\tconst unsigned long *scan_mask;\n\tbool strict_scanmask = false;\n\tstruct iio_buffer *buffer;\n\tbool scan_timestamp;\n\tunsigned int modes;\n\n\tif (insert_buffer &&\n\t    bitmap_empty(insert_buffer->scan_mask, indio_dev->masklength)) {\n\t\tdev_dbg(&indio_dev->dev,\n\t\t\t\"At least one scan element must be enabled first\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(config, 0, sizeof(*config));\n\tconfig->watermark = ~0;\n\n\t \n\tif (remove_buffer && !insert_buffer &&\n\t    list_is_singular(&iio_dev_opaque->buffer_list))\n\t\treturn 0;\n\n\tmodes = indio_dev->modes;\n\n\tlist_for_each_entry(buffer, &iio_dev_opaque->buffer_list, buffer_list) {\n\t\tif (buffer == remove_buffer)\n\t\t\tcontinue;\n\t\tmodes &= buffer->access->modes;\n\t\tconfig->watermark = min(config->watermark, buffer->watermark);\n\t}\n\n\tif (insert_buffer) {\n\t\tmodes &= insert_buffer->access->modes;\n\t\tconfig->watermark = min(config->watermark,\n\t\t\t\t\tinsert_buffer->watermark);\n\t}\n\n\t \n\tif ((modes & INDIO_BUFFER_TRIGGERED) && indio_dev->trig) {\n\t\tconfig->mode = INDIO_BUFFER_TRIGGERED;\n\t} else if (modes & INDIO_BUFFER_HARDWARE) {\n\t\t \n\t\tif (insert_buffer && !list_empty(&iio_dev_opaque->buffer_list))\n\t\t\treturn -EINVAL;\n\t\tconfig->mode = INDIO_BUFFER_HARDWARE;\n\t\tstrict_scanmask = true;\n\t} else if (modes & INDIO_BUFFER_SOFTWARE) {\n\t\tconfig->mode = INDIO_BUFFER_SOFTWARE;\n\t} else {\n\t\t \n\t\tif (indio_dev->modes & INDIO_BUFFER_TRIGGERED)\n\t\t\tdev_dbg(&indio_dev->dev, \"Buffer not started: no trigger\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tcompound_mask = bitmap_zalloc(indio_dev->masklength, GFP_KERNEL);\n\tif (!compound_mask)\n\t\treturn -ENOMEM;\n\n\tscan_timestamp = false;\n\n\tlist_for_each_entry(buffer, &iio_dev_opaque->buffer_list, buffer_list) {\n\t\tif (buffer == remove_buffer)\n\t\t\tcontinue;\n\t\tbitmap_or(compound_mask, compound_mask, buffer->scan_mask,\n\t\t\t  indio_dev->masklength);\n\t\tscan_timestamp |= buffer->scan_timestamp;\n\t}\n\n\tif (insert_buffer) {\n\t\tbitmap_or(compound_mask, compound_mask,\n\t\t\t  insert_buffer->scan_mask, indio_dev->masklength);\n\t\tscan_timestamp |= insert_buffer->scan_timestamp;\n\t}\n\n\tif (indio_dev->available_scan_masks) {\n\t\tscan_mask = iio_scan_mask_match(indio_dev->available_scan_masks,\n\t\t\t\t\t\tindio_dev->masklength,\n\t\t\t\t\t\tcompound_mask,\n\t\t\t\t\t\tstrict_scanmask);\n\t\tbitmap_free(compound_mask);\n\t\tif (!scan_mask)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tscan_mask = compound_mask;\n\t}\n\n\tconfig->scan_bytes = iio_compute_scan_bytes(indio_dev,\n\t\t\t\t\t\t    scan_mask, scan_timestamp);\n\tconfig->scan_mask = scan_mask;\n\tconfig->scan_timestamp = scan_timestamp;\n\n\treturn 0;\n}\n\n \nstruct iio_demux_table {\n\tunsigned int from;\n\tunsigned int to;\n\tunsigned int length;\n\tstruct list_head l;\n};\n\nstatic void iio_buffer_demux_free(struct iio_buffer *buffer)\n{\n\tstruct iio_demux_table *p, *q;\n\n\tlist_for_each_entry_safe(p, q, &buffer->demux_list, l) {\n\t\tlist_del(&p->l);\n\t\tkfree(p);\n\t}\n}\n\nstatic int iio_buffer_add_demux(struct iio_buffer *buffer,\n\t\t\t\tstruct iio_demux_table **p, unsigned int in_loc,\n\t\t\t\tunsigned int out_loc,\n\t\t\t\tunsigned int length)\n{\n\tif (*p && (*p)->from + (*p)->length == in_loc &&\n\t    (*p)->to + (*p)->length == out_loc) {\n\t\t(*p)->length += length;\n\t} else {\n\t\t*p = kmalloc(sizeof(**p), GFP_KERNEL);\n\t\tif (!(*p))\n\t\t\treturn -ENOMEM;\n\t\t(*p)->from = in_loc;\n\t\t(*p)->to = out_loc;\n\t\t(*p)->length = length;\n\t\tlist_add_tail(&(*p)->l, &buffer->demux_list);\n\t}\n\n\treturn 0;\n}\n\nstatic int iio_buffer_update_demux(struct iio_dev *indio_dev,\n\t\t\t\t   struct iio_buffer *buffer)\n{\n\tint ret, in_ind = -1, out_ind, length;\n\tunsigned int in_loc = 0, out_loc = 0;\n\tstruct iio_demux_table *p = NULL;\n\n\t \n\tiio_buffer_demux_free(buffer);\n\tkfree(buffer->demux_bounce);\n\tbuffer->demux_bounce = NULL;\n\n\t \n\tif (bitmap_equal(indio_dev->active_scan_mask,\n\t\t\t buffer->scan_mask,\n\t\t\t indio_dev->masklength))\n\t\treturn 0;\n\n\t \n\tfor_each_set_bit(out_ind,\n\t\t\t buffer->scan_mask,\n\t\t\t indio_dev->masklength) {\n\t\tin_ind = find_next_bit(indio_dev->active_scan_mask,\n\t\t\t\t       indio_dev->masklength,\n\t\t\t\t       in_ind + 1);\n\t\twhile (in_ind != out_ind) {\n\t\t\tlength = iio_storage_bytes_for_si(indio_dev, in_ind);\n\t\t\t \n\t\t\tin_loc = roundup(in_loc, length) + length;\n\t\t\tin_ind = find_next_bit(indio_dev->active_scan_mask,\n\t\t\t\t\t       indio_dev->masklength,\n\t\t\t\t\t       in_ind + 1);\n\t\t}\n\t\tlength = iio_storage_bytes_for_si(indio_dev, in_ind);\n\t\tout_loc = roundup(out_loc, length);\n\t\tin_loc = roundup(in_loc, length);\n\t\tret = iio_buffer_add_demux(buffer, &p, in_loc, out_loc, length);\n\t\tif (ret)\n\t\t\tgoto error_clear_mux_table;\n\t\tout_loc += length;\n\t\tin_loc += length;\n\t}\n\t \n\tif (buffer->scan_timestamp) {\n\t\tlength = iio_storage_bytes_for_timestamp(indio_dev);\n\t\tout_loc = roundup(out_loc, length);\n\t\tin_loc = roundup(in_loc, length);\n\t\tret = iio_buffer_add_demux(buffer, &p, in_loc, out_loc, length);\n\t\tif (ret)\n\t\t\tgoto error_clear_mux_table;\n\t\tout_loc += length;\n\t}\n\tbuffer->demux_bounce = kzalloc(out_loc, GFP_KERNEL);\n\tif (!buffer->demux_bounce) {\n\t\tret = -ENOMEM;\n\t\tgoto error_clear_mux_table;\n\t}\n\treturn 0;\n\nerror_clear_mux_table:\n\tiio_buffer_demux_free(buffer);\n\n\treturn ret;\n}\n\nstatic int iio_update_demux(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer;\n\tint ret;\n\n\tlist_for_each_entry(buffer, &iio_dev_opaque->buffer_list, buffer_list) {\n\t\tret = iio_buffer_update_demux(indio_dev, buffer);\n\t\tif (ret < 0)\n\t\t\tgoto error_clear_mux_table;\n\t}\n\treturn 0;\n\nerror_clear_mux_table:\n\tlist_for_each_entry(buffer, &iio_dev_opaque->buffer_list, buffer_list)\n\t\tiio_buffer_demux_free(buffer);\n\n\treturn ret;\n}\n\nstatic int iio_enable_buffers(struct iio_dev *indio_dev,\n\t\t\t      struct iio_device_config *config)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer, *tmp = NULL;\n\tint ret;\n\n\tindio_dev->active_scan_mask = config->scan_mask;\n\tindio_dev->scan_timestamp = config->scan_timestamp;\n\tindio_dev->scan_bytes = config->scan_bytes;\n\tiio_dev_opaque->currentmode = config->mode;\n\n\tiio_update_demux(indio_dev);\n\n\t \n\tif (indio_dev->setup_ops->preenable) {\n\t\tret = indio_dev->setup_ops->preenable(indio_dev);\n\t\tif (ret) {\n\t\t\tdev_dbg(&indio_dev->dev,\n\t\t\t\t\"Buffer not started: buffer preenable failed (%d)\\n\", ret);\n\t\t\tgoto err_undo_config;\n\t\t}\n\t}\n\n\tif (indio_dev->info->update_scan_mode) {\n\t\tret = indio_dev->info\n\t\t\t->update_scan_mode(indio_dev,\n\t\t\t\t\t   indio_dev->active_scan_mask);\n\t\tif (ret < 0) {\n\t\t\tdev_dbg(&indio_dev->dev,\n\t\t\t\t\"Buffer not started: update scan mode failed (%d)\\n\",\n\t\t\t\tret);\n\t\t\tgoto err_run_postdisable;\n\t\t}\n\t}\n\n\tif (indio_dev->info->hwfifo_set_watermark)\n\t\tindio_dev->info->hwfifo_set_watermark(indio_dev,\n\t\t\tconfig->watermark);\n\n\tlist_for_each_entry(buffer, &iio_dev_opaque->buffer_list, buffer_list) {\n\t\tret = iio_buffer_enable(buffer, indio_dev);\n\t\tif (ret) {\n\t\t\ttmp = buffer;\n\t\t\tgoto err_disable_buffers;\n\t\t}\n\t}\n\n\tif (iio_dev_opaque->currentmode == INDIO_BUFFER_TRIGGERED) {\n\t\tret = iio_trigger_attach_poll_func(indio_dev->trig,\n\t\t\t\t\t\t   indio_dev->pollfunc);\n\t\tif (ret)\n\t\t\tgoto err_disable_buffers;\n\t}\n\n\tif (indio_dev->setup_ops->postenable) {\n\t\tret = indio_dev->setup_ops->postenable(indio_dev);\n\t\tif (ret) {\n\t\t\tdev_dbg(&indio_dev->dev,\n\t\t\t\t\"Buffer not started: postenable failed (%d)\\n\", ret);\n\t\t\tgoto err_detach_pollfunc;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_detach_pollfunc:\n\tif (iio_dev_opaque->currentmode == INDIO_BUFFER_TRIGGERED) {\n\t\tiio_trigger_detach_poll_func(indio_dev->trig,\n\t\t\t\t\t     indio_dev->pollfunc);\n\t}\nerr_disable_buffers:\n\tbuffer = list_prepare_entry(tmp, &iio_dev_opaque->buffer_list, buffer_list);\n\tlist_for_each_entry_continue_reverse(buffer, &iio_dev_opaque->buffer_list,\n\t\t\t\t\t     buffer_list)\n\t\tiio_buffer_disable(buffer, indio_dev);\nerr_run_postdisable:\n\tif (indio_dev->setup_ops->postdisable)\n\t\tindio_dev->setup_ops->postdisable(indio_dev);\nerr_undo_config:\n\tiio_dev_opaque->currentmode = INDIO_DIRECT_MODE;\n\tindio_dev->active_scan_mask = NULL;\n\n\treturn ret;\n}\n\nstatic int iio_disable_buffers(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer;\n\tint ret = 0;\n\tint ret2;\n\n\t \n\tif (list_empty(&iio_dev_opaque->buffer_list))\n\t\treturn 0;\n\n\t \n\n\tif (indio_dev->setup_ops->predisable) {\n\t\tret2 = indio_dev->setup_ops->predisable(indio_dev);\n\t\tif (ret2 && !ret)\n\t\t\tret = ret2;\n\t}\n\n\tif (iio_dev_opaque->currentmode == INDIO_BUFFER_TRIGGERED) {\n\t\tiio_trigger_detach_poll_func(indio_dev->trig,\n\t\t\t\t\t     indio_dev->pollfunc);\n\t}\n\n\tlist_for_each_entry(buffer, &iio_dev_opaque->buffer_list, buffer_list) {\n\t\tret2 = iio_buffer_disable(buffer, indio_dev);\n\t\tif (ret2 && !ret)\n\t\t\tret = ret2;\n\t}\n\n\tif (indio_dev->setup_ops->postdisable) {\n\t\tret2 = indio_dev->setup_ops->postdisable(indio_dev);\n\t\tif (ret2 && !ret)\n\t\t\tret = ret2;\n\t}\n\n\tiio_free_scan_mask(indio_dev, indio_dev->active_scan_mask);\n\tindio_dev->active_scan_mask = NULL;\n\tiio_dev_opaque->currentmode = INDIO_DIRECT_MODE;\n\n\treturn ret;\n}\n\nstatic int __iio_update_buffers(struct iio_dev *indio_dev,\n\t\t\t\tstruct iio_buffer *insert_buffer,\n\t\t\t\tstruct iio_buffer *remove_buffer)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_device_config new_config;\n\tint ret;\n\n\tret = iio_verify_update(indio_dev, insert_buffer, remove_buffer,\n\t\t\t\t&new_config);\n\tif (ret)\n\t\treturn ret;\n\n\tif (insert_buffer) {\n\t\tret = iio_buffer_request_update(indio_dev, insert_buffer);\n\t\tif (ret)\n\t\t\tgoto err_free_config;\n\t}\n\n\tret = iio_disable_buffers(indio_dev);\n\tif (ret)\n\t\tgoto err_deactivate_all;\n\n\tif (remove_buffer)\n\t\tiio_buffer_deactivate(remove_buffer);\n\tif (insert_buffer)\n\t\tiio_buffer_activate(indio_dev, insert_buffer);\n\n\t \n\tif (list_empty(&iio_dev_opaque->buffer_list))\n\t\treturn 0;\n\n\tret = iio_enable_buffers(indio_dev, &new_config);\n\tif (ret)\n\t\tgoto err_deactivate_all;\n\n\treturn 0;\n\nerr_deactivate_all:\n\t \n\tiio_buffer_deactivate_all(indio_dev);\n\nerr_free_config:\n\tiio_free_scan_mask(indio_dev, new_config.scan_mask);\n\treturn ret;\n}\n\nint iio_update_buffers(struct iio_dev *indio_dev,\n\t\t       struct iio_buffer *insert_buffer,\n\t\t       struct iio_buffer *remove_buffer)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tint ret;\n\n\tif (insert_buffer == remove_buffer)\n\t\treturn 0;\n\n\tif (insert_buffer &&\n\t    insert_buffer->direction == IIO_BUFFER_DIRECTION_OUT)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&iio_dev_opaque->info_exist_lock);\n\tmutex_lock(&iio_dev_opaque->mlock);\n\n\tif (insert_buffer && iio_buffer_is_active(insert_buffer))\n\t\tinsert_buffer = NULL;\n\n\tif (remove_buffer && !iio_buffer_is_active(remove_buffer))\n\t\tremove_buffer = NULL;\n\n\tif (!insert_buffer && !remove_buffer) {\n\t\tret = 0;\n\t\tgoto out_unlock;\n\t}\n\n\tif (!indio_dev->info) {\n\t\tret = -ENODEV;\n\t\tgoto out_unlock;\n\t}\n\n\tret = __iio_update_buffers(indio_dev, insert_buffer, remove_buffer);\n\nout_unlock:\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\tmutex_unlock(&iio_dev_opaque->info_exist_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(iio_update_buffers);\n\nvoid iio_disable_all_buffers(struct iio_dev *indio_dev)\n{\n\tiio_disable_buffers(indio_dev);\n\tiio_buffer_deactivate_all(indio_dev);\n}\n\nstatic ssize_t enable_store(struct device *dev, struct device_attribute *attr,\n\t\t\t    const char *buf, size_t len)\n{\n\tint ret;\n\tbool requested_state;\n\tstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\tbool inlist;\n\n\tret = kstrtobool(buf, &requested_state);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&iio_dev_opaque->mlock);\n\n\t \n\tinlist = iio_buffer_is_active(buffer);\n\t \n\tif (inlist == requested_state)\n\t\tgoto done;\n\n\tif (requested_state)\n\t\tret = __iio_update_buffers(indio_dev, buffer, NULL);\n\telse\n\t\tret = __iio_update_buffers(indio_dev, NULL, buffer);\n\ndone:\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\treturn (ret < 0) ? ret : len;\n}\n\nstatic ssize_t watermark_show(struct device *dev, struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\n\treturn sysfs_emit(buf, \"%u\\n\", buffer->watermark);\n}\n\nstatic ssize_t watermark_store(struct device *dev,\n\t\t\t       struct device_attribute *attr,\n\t\t\t       const char *buf, size_t len)\n{\n\tstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\tunsigned int val;\n\tint ret;\n\n\tret = kstrtouint(buf, 10, &val);\n\tif (ret)\n\t\treturn ret;\n\tif (!val)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&iio_dev_opaque->mlock);\n\n\tif (val > buffer->length) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (iio_buffer_is_active(buffer)) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tbuffer->watermark = val;\nout:\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\n\treturn ret ? ret : len;\n}\n\nstatic ssize_t data_available_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\n\treturn sysfs_emit(buf, \"%zu\\n\", iio_buffer_data_available(buffer));\n}\n\nstatic ssize_t direction_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct iio_buffer *buffer = to_iio_dev_attr(attr)->buffer;\n\n\tswitch (buffer->direction) {\n\tcase IIO_BUFFER_DIRECTION_IN:\n\t\treturn sysfs_emit(buf, \"in\\n\");\n\tcase IIO_BUFFER_DIRECTION_OUT:\n\t\treturn sysfs_emit(buf, \"out\\n\");\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic DEVICE_ATTR_RW(length);\nstatic struct device_attribute dev_attr_length_ro = __ATTR_RO(length);\nstatic DEVICE_ATTR_RW(enable);\nstatic DEVICE_ATTR_RW(watermark);\nstatic struct device_attribute dev_attr_watermark_ro = __ATTR_RO(watermark);\nstatic DEVICE_ATTR_RO(data_available);\nstatic DEVICE_ATTR_RO(direction);\n\n \nstatic struct attribute *iio_buffer_attrs[] = {\n\t&dev_attr_length.attr,\n\t&dev_attr_enable.attr,\n\t&dev_attr_watermark.attr,\n\t&dev_attr_data_available.attr,\n\t&dev_attr_direction.attr,\n};\n\n#define to_dev_attr(_attr) container_of(_attr, struct device_attribute, attr)\n\nstatic struct attribute *iio_buffer_wrap_attr(struct iio_buffer *buffer,\n\t\t\t\t\t      struct attribute *attr)\n{\n\tstruct device_attribute *dattr = to_dev_attr(attr);\n\tstruct iio_dev_attr *iio_attr;\n\n\tiio_attr = kzalloc(sizeof(*iio_attr), GFP_KERNEL);\n\tif (!iio_attr)\n\t\treturn NULL;\n\n\tiio_attr->buffer = buffer;\n\tmemcpy(&iio_attr->dev_attr, dattr, sizeof(iio_attr->dev_attr));\n\tiio_attr->dev_attr.attr.name = kstrdup_const(attr->name, GFP_KERNEL);\n\tif (!iio_attr->dev_attr.attr.name) {\n\t\tkfree(iio_attr);\n\t\treturn NULL;\n\t}\n\n\tsysfs_attr_init(&iio_attr->dev_attr.attr);\n\n\tlist_add(&iio_attr->l, &buffer->buffer_attr_list);\n\n\treturn &iio_attr->dev_attr.attr;\n}\n\nstatic int iio_buffer_register_legacy_sysfs_groups(struct iio_dev *indio_dev,\n\t\t\t\t\t\t   struct attribute **buffer_attrs,\n\t\t\t\t\t\t   int buffer_attrcount,\n\t\t\t\t\t\t   int scan_el_attrcount)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct attribute_group *group;\n\tstruct attribute **attrs;\n\tint ret;\n\n\tattrs = kcalloc(buffer_attrcount + 1, sizeof(*attrs), GFP_KERNEL);\n\tif (!attrs)\n\t\treturn -ENOMEM;\n\n\tmemcpy(attrs, buffer_attrs, buffer_attrcount * sizeof(*attrs));\n\n\tgroup = &iio_dev_opaque->legacy_buffer_group;\n\tgroup->attrs = attrs;\n\tgroup->name = \"buffer\";\n\n\tret = iio_device_register_sysfs_group(indio_dev, group);\n\tif (ret)\n\t\tgoto error_free_buffer_attrs;\n\n\tattrs = kcalloc(scan_el_attrcount + 1, sizeof(*attrs), GFP_KERNEL);\n\tif (!attrs) {\n\t\tret = -ENOMEM;\n\t\tgoto error_free_buffer_attrs;\n\t}\n\n\tmemcpy(attrs, &buffer_attrs[buffer_attrcount],\n\t       scan_el_attrcount * sizeof(*attrs));\n\n\tgroup = &iio_dev_opaque->legacy_scan_el_group;\n\tgroup->attrs = attrs;\n\tgroup->name = \"scan_elements\";\n\n\tret = iio_device_register_sysfs_group(indio_dev, group);\n\tif (ret)\n\t\tgoto error_free_scan_el_attrs;\n\n\treturn 0;\n\nerror_free_scan_el_attrs:\n\tkfree(iio_dev_opaque->legacy_scan_el_group.attrs);\nerror_free_buffer_attrs:\n\tkfree(iio_dev_opaque->legacy_buffer_group.attrs);\n\n\treturn ret;\n}\n\nstatic void iio_buffer_unregister_legacy_sysfs_groups(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\n\tkfree(iio_dev_opaque->legacy_buffer_group.attrs);\n\tkfree(iio_dev_opaque->legacy_scan_el_group.attrs);\n}\n\nstatic int iio_buffer_chrdev_release(struct inode *inode, struct file *filep)\n{\n\tstruct iio_dev_buffer_pair *ib = filep->private_data;\n\tstruct iio_dev *indio_dev = ib->indio_dev;\n\tstruct iio_buffer *buffer = ib->buffer;\n\n\twake_up(&buffer->pollq);\n\n\tkfree(ib);\n\tclear_bit(IIO_BUSY_BIT_POS, &buffer->flags);\n\tiio_device_put(indio_dev);\n\n\treturn 0;\n}\n\nstatic const struct file_operations iio_buffer_chrdev_fileops = {\n\t.owner = THIS_MODULE,\n\t.llseek = noop_llseek,\n\t.read = iio_buffer_read,\n\t.write = iio_buffer_write,\n\t.poll = iio_buffer_poll,\n\t.release = iio_buffer_chrdev_release,\n};\n\nstatic long iio_device_buffer_getfd(struct iio_dev *indio_dev, unsigned long arg)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tint __user *ival = (int __user *)arg;\n\tstruct iio_dev_buffer_pair *ib;\n\tstruct iio_buffer *buffer;\n\tint fd, idx, ret;\n\n\tif (copy_from_user(&idx, ival, sizeof(idx)))\n\t\treturn -EFAULT;\n\n\tif (idx >= iio_dev_opaque->attached_buffers_cnt)\n\t\treturn -ENODEV;\n\n\tiio_device_get(indio_dev);\n\n\tbuffer = iio_dev_opaque->attached_buffers[idx];\n\n\tif (test_and_set_bit(IIO_BUSY_BIT_POS, &buffer->flags)) {\n\t\tret = -EBUSY;\n\t\tgoto error_iio_dev_put;\n\t}\n\n\tib = kzalloc(sizeof(*ib), GFP_KERNEL);\n\tif (!ib) {\n\t\tret = -ENOMEM;\n\t\tgoto error_clear_busy_bit;\n\t}\n\n\tib->indio_dev = indio_dev;\n\tib->buffer = buffer;\n\n\tfd = anon_inode_getfd(\"iio:buffer\", &iio_buffer_chrdev_fileops,\n\t\t\t      ib, O_RDWR | O_CLOEXEC);\n\tif (fd < 0) {\n\t\tret = fd;\n\t\tgoto error_free_ib;\n\t}\n\n\tif (copy_to_user(ival, &fd, sizeof(fd))) {\n\t\t \n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n\nerror_free_ib:\n\tkfree(ib);\nerror_clear_busy_bit:\n\tclear_bit(IIO_BUSY_BIT_POS, &buffer->flags);\nerror_iio_dev_put:\n\tiio_device_put(indio_dev);\n\treturn ret;\n}\n\nstatic long iio_device_buffer_ioctl(struct iio_dev *indio_dev, struct file *filp,\n\t\t\t\t    unsigned int cmd, unsigned long arg)\n{\n\tswitch (cmd) {\n\tcase IIO_BUFFER_GET_FD_IOCTL:\n\t\treturn iio_device_buffer_getfd(indio_dev, arg);\n\tdefault:\n\t\treturn IIO_IOCTL_UNHANDLED;\n\t}\n}\n\nstatic int __iio_buffer_alloc_sysfs_and_mask(struct iio_buffer *buffer,\n\t\t\t\t\t     struct iio_dev *indio_dev,\n\t\t\t\t\t     int index)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_dev_attr *p;\n\tconst struct iio_dev_attr *id_attr;\n\tstruct attribute **attr;\n\tint ret, i, attrn, scan_el_attrcount, buffer_attrcount;\n\tconst struct iio_chan_spec *channels;\n\n\tbuffer_attrcount = 0;\n\tif (buffer->attrs) {\n\t\twhile (buffer->attrs[buffer_attrcount])\n\t\t\tbuffer_attrcount++;\n\t}\n\tbuffer_attrcount += ARRAY_SIZE(iio_buffer_attrs);\n\n\tscan_el_attrcount = 0;\n\tINIT_LIST_HEAD(&buffer->buffer_attr_list);\n\tchannels = indio_dev->channels;\n\tif (channels) {\n\t\t \n\t\tfor (i = 0; i < indio_dev->num_channels; i++) {\n\t\t\tif (channels[i].scan_index < 0)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (channels[i].scan_type.storagebits <\n\t\t\t    channels[i].scan_type.realbits +\n\t\t\t    channels[i].scan_type.shift) {\n\t\t\t\tdev_err(&indio_dev->dev,\n\t\t\t\t\t\"Channel %d storagebits (%d) < shifted realbits (%d + %d)\\n\",\n\t\t\t\t\ti, channels[i].scan_type.storagebits,\n\t\t\t\t\tchannels[i].scan_type.realbits,\n\t\t\t\t\tchannels[i].scan_type.shift);\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto error_cleanup_dynamic;\n\t\t\t}\n\n\t\t\tret = iio_buffer_add_channel_sysfs(indio_dev, buffer,\n\t\t\t\t\t\t\t   &channels[i]);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto error_cleanup_dynamic;\n\t\t\tscan_el_attrcount += ret;\n\t\t\tif (channels[i].type == IIO_TIMESTAMP)\n\t\t\t\tiio_dev_opaque->scan_index_timestamp =\n\t\t\t\t\tchannels[i].scan_index;\n\t\t}\n\t\tif (indio_dev->masklength && !buffer->scan_mask) {\n\t\t\tbuffer->scan_mask = bitmap_zalloc(indio_dev->masklength,\n\t\t\t\t\t\t\t  GFP_KERNEL);\n\t\t\tif (!buffer->scan_mask) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto error_cleanup_dynamic;\n\t\t\t}\n\t\t}\n\t}\n\n\tattrn = buffer_attrcount + scan_el_attrcount;\n\tattr = kcalloc(attrn + 1, sizeof(*attr), GFP_KERNEL);\n\tif (!attr) {\n\t\tret = -ENOMEM;\n\t\tgoto error_free_scan_mask;\n\t}\n\n\tmemcpy(attr, iio_buffer_attrs, sizeof(iio_buffer_attrs));\n\tif (!buffer->access->set_length)\n\t\tattr[0] = &dev_attr_length_ro.attr;\n\n\tif (buffer->access->flags & INDIO_BUFFER_FLAG_FIXED_WATERMARK)\n\t\tattr[2] = &dev_attr_watermark_ro.attr;\n\n\tif (buffer->attrs)\n\t\tfor (i = 0, id_attr = buffer->attrs[i];\n\t\t     (id_attr = buffer->attrs[i]); i++)\n\t\t\tattr[ARRAY_SIZE(iio_buffer_attrs) + i] =\n\t\t\t\t(struct attribute *)&id_attr->dev_attr.attr;\n\n\tbuffer->buffer_group.attrs = attr;\n\n\tfor (i = 0; i < buffer_attrcount; i++) {\n\t\tstruct attribute *wrapped;\n\n\t\twrapped = iio_buffer_wrap_attr(buffer, attr[i]);\n\t\tif (!wrapped) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto error_free_buffer_attrs;\n\t\t}\n\t\tattr[i] = wrapped;\n\t}\n\n\tattrn = 0;\n\tlist_for_each_entry(p, &buffer->buffer_attr_list, l)\n\t\tattr[attrn++] = &p->dev_attr.attr;\n\n\tbuffer->buffer_group.name = kasprintf(GFP_KERNEL, \"buffer%d\", index);\n\tif (!buffer->buffer_group.name) {\n\t\tret = -ENOMEM;\n\t\tgoto error_free_buffer_attrs;\n\t}\n\n\tret = iio_device_register_sysfs_group(indio_dev, &buffer->buffer_group);\n\tif (ret)\n\t\tgoto error_free_buffer_attr_group_name;\n\n\t \n\tif (index > 0)\n\t\treturn 0;\n\n\tret = iio_buffer_register_legacy_sysfs_groups(indio_dev, attr,\n\t\t\t\t\t\t      buffer_attrcount,\n\t\t\t\t\t\t      scan_el_attrcount);\n\tif (ret)\n\t\tgoto error_free_buffer_attr_group_name;\n\n\treturn 0;\n\nerror_free_buffer_attr_group_name:\n\tkfree(buffer->buffer_group.name);\nerror_free_buffer_attrs:\n\tkfree(buffer->buffer_group.attrs);\nerror_free_scan_mask:\n\tbitmap_free(buffer->scan_mask);\nerror_cleanup_dynamic:\n\tiio_free_chan_devattr_list(&buffer->buffer_attr_list);\n\n\treturn ret;\n}\n\nstatic void __iio_buffer_free_sysfs_and_mask(struct iio_buffer *buffer,\n\t\t\t\t\t     struct iio_dev *indio_dev,\n\t\t\t\t\t     int index)\n{\n\tif (index == 0)\n\t\tiio_buffer_unregister_legacy_sysfs_groups(indio_dev);\n\tbitmap_free(buffer->scan_mask);\n\tkfree(buffer->buffer_group.name);\n\tkfree(buffer->buffer_group.attrs);\n\tiio_free_chan_devattr_list(&buffer->buffer_attr_list);\n}\n\nint iio_buffers_alloc_sysfs_and_mask(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tconst struct iio_chan_spec *channels;\n\tstruct iio_buffer *buffer;\n\tint ret, i, idx;\n\tsize_t sz;\n\n\tchannels = indio_dev->channels;\n\tif (channels) {\n\t\tint ml = indio_dev->masklength;\n\n\t\tfor (i = 0; i < indio_dev->num_channels; i++)\n\t\t\tml = max(ml, channels[i].scan_index + 1);\n\t\tindio_dev->masklength = ml;\n\t}\n\n\tif (!iio_dev_opaque->attached_buffers_cnt)\n\t\treturn 0;\n\n\tfor (idx = 0; idx < iio_dev_opaque->attached_buffers_cnt; idx++) {\n\t\tbuffer = iio_dev_opaque->attached_buffers[idx];\n\t\tret = __iio_buffer_alloc_sysfs_and_mask(buffer, indio_dev, idx);\n\t\tif (ret)\n\t\t\tgoto error_unwind_sysfs_and_mask;\n\t}\n\n\tsz = sizeof(*iio_dev_opaque->buffer_ioctl_handler);\n\tiio_dev_opaque->buffer_ioctl_handler = kzalloc(sz, GFP_KERNEL);\n\tif (!iio_dev_opaque->buffer_ioctl_handler) {\n\t\tret = -ENOMEM;\n\t\tgoto error_unwind_sysfs_and_mask;\n\t}\n\n\tiio_dev_opaque->buffer_ioctl_handler->ioctl = iio_device_buffer_ioctl;\n\tiio_device_ioctl_handler_register(indio_dev,\n\t\t\t\t\t  iio_dev_opaque->buffer_ioctl_handler);\n\n\treturn 0;\n\nerror_unwind_sysfs_and_mask:\n\twhile (idx--) {\n\t\tbuffer = iio_dev_opaque->attached_buffers[idx];\n\t\t__iio_buffer_free_sysfs_and_mask(buffer, indio_dev, idx);\n\t}\n\treturn ret;\n}\n\nvoid iio_buffers_free_sysfs_and_mask(struct iio_dev *indio_dev)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer *buffer;\n\tint i;\n\n\tif (!iio_dev_opaque->attached_buffers_cnt)\n\t\treturn;\n\n\tiio_device_ioctl_handler_unregister(iio_dev_opaque->buffer_ioctl_handler);\n\tkfree(iio_dev_opaque->buffer_ioctl_handler);\n\n\tfor (i = iio_dev_opaque->attached_buffers_cnt - 1; i >= 0; i--) {\n\t\tbuffer = iio_dev_opaque->attached_buffers[i];\n\t\t__iio_buffer_free_sysfs_and_mask(buffer, indio_dev, i);\n\t}\n}\n\n \nbool iio_validate_scan_mask_onehot(struct iio_dev *indio_dev,\n\t\t\t\t   const unsigned long *mask)\n{\n\treturn bitmap_weight(mask, indio_dev->masklength) == 1;\n}\nEXPORT_SYMBOL_GPL(iio_validate_scan_mask_onehot);\n\nstatic const void *iio_demux(struct iio_buffer *buffer,\n\t\t\t     const void *datain)\n{\n\tstruct iio_demux_table *t;\n\n\tif (list_empty(&buffer->demux_list))\n\t\treturn datain;\n\tlist_for_each_entry(t, &buffer->demux_list, l)\n\t\tmemcpy(buffer->demux_bounce + t->to,\n\t\t       datain + t->from, t->length);\n\n\treturn buffer->demux_bounce;\n}\n\nstatic int iio_push_to_buffer(struct iio_buffer *buffer, const void *data)\n{\n\tconst void *dataout = iio_demux(buffer, data);\n\tint ret;\n\n\tret = buffer->access->store_to(buffer, dataout);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\twake_up_interruptible_poll(&buffer->pollq, EPOLLIN | EPOLLRDNORM);\n\treturn 0;\n}\n\n \nint iio_push_to_buffers(struct iio_dev *indio_dev, const void *data)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tint ret;\n\tstruct iio_buffer *buf;\n\n\tlist_for_each_entry(buf, &iio_dev_opaque->buffer_list, buffer_list) {\n\t\tret = iio_push_to_buffer(buf, data);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(iio_push_to_buffers);\n\n \nint iio_push_to_buffers_with_ts_unaligned(struct iio_dev *indio_dev,\n\t\t\t\t\t  const void *data,\n\t\t\t\t\t  size_t data_sz,\n\t\t\t\t\t  int64_t timestamp)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\n\t \n\tdata_sz = min_t(size_t, indio_dev->scan_bytes, data_sz);\n\tif (iio_dev_opaque->bounce_buffer_size !=  indio_dev->scan_bytes) {\n\t\tvoid *bb;\n\n\t\tbb = devm_krealloc(&indio_dev->dev,\n\t\t\t\t   iio_dev_opaque->bounce_buffer,\n\t\t\t\t   indio_dev->scan_bytes, GFP_KERNEL);\n\t\tif (!bb)\n\t\t\treturn -ENOMEM;\n\t\tiio_dev_opaque->bounce_buffer = bb;\n\t\tiio_dev_opaque->bounce_buffer_size = indio_dev->scan_bytes;\n\t}\n\tmemcpy(iio_dev_opaque->bounce_buffer, data, data_sz);\n\treturn iio_push_to_buffers_with_timestamp(indio_dev,\n\t\t\t\t\t\t  iio_dev_opaque->bounce_buffer,\n\t\t\t\t\t\t  timestamp);\n}\nEXPORT_SYMBOL_GPL(iio_push_to_buffers_with_ts_unaligned);\n\n \nstatic void iio_buffer_release(struct kref *ref)\n{\n\tstruct iio_buffer *buffer = container_of(ref, struct iio_buffer, ref);\n\n\tbuffer->access->release(buffer);\n}\n\n \nstruct iio_buffer *iio_buffer_get(struct iio_buffer *buffer)\n{\n\tif (buffer)\n\t\tkref_get(&buffer->ref);\n\n\treturn buffer;\n}\nEXPORT_SYMBOL_GPL(iio_buffer_get);\n\n \nvoid iio_buffer_put(struct iio_buffer *buffer)\n{\n\tif (buffer)\n\t\tkref_put(&buffer->ref, iio_buffer_release);\n}\nEXPORT_SYMBOL_GPL(iio_buffer_put);\n\n \nint iio_device_attach_buffer(struct iio_dev *indio_dev,\n\t\t\t     struct iio_buffer *buffer)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_buffer **new, **old = iio_dev_opaque->attached_buffers;\n\tunsigned int cnt = iio_dev_opaque->attached_buffers_cnt;\n\n\tcnt++;\n\n\tnew = krealloc(old, sizeof(*new) * cnt, GFP_KERNEL);\n\tif (!new)\n\t\treturn -ENOMEM;\n\tiio_dev_opaque->attached_buffers = new;\n\n\tbuffer = iio_buffer_get(buffer);\n\n\t \n\tif (!indio_dev->buffer)\n\t\tindio_dev->buffer = buffer;\n\n\tiio_dev_opaque->attached_buffers[cnt - 1] = buffer;\n\tiio_dev_opaque->attached_buffers_cnt = cnt;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(iio_device_attach_buffer);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}