{
  "module_name": "industrialio-trigger.c",
  "hash_id": "cec6d9bba07dc74481af5132e02a92263f73c942a3e5cfa3837b6a001d320fd2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/iio/industrialio-trigger.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/idr.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/slab.h>\n\n#include <linux/iio/iio.h>\n#include <linux/iio/iio-opaque.h>\n#include <linux/iio/trigger.h>\n#include \"iio_core.h\"\n#include \"iio_core_trigger.h\"\n#include <linux/iio/trigger_consumer.h>\n\n \n\nstatic DEFINE_IDA(iio_trigger_ida);\n\n \nstatic LIST_HEAD(iio_trigger_list);\nstatic DEFINE_MUTEX(iio_trigger_list_lock);\n\n \nstatic ssize_t name_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct iio_trigger *trig = to_iio_trigger(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", trig->name);\n}\n\nstatic DEVICE_ATTR_RO(name);\n\nstatic struct attribute *iio_trig_dev_attrs[] = {\n\t&dev_attr_name.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(iio_trig_dev);\n\nstatic struct iio_trigger *__iio_trigger_find_by_name(const char *name);\n\nint iio_trigger_register(struct iio_trigger *trig_info)\n{\n\tint ret;\n\n\ttrig_info->id = ida_alloc(&iio_trigger_ida, GFP_KERNEL);\n\tif (trig_info->id < 0)\n\t\treturn trig_info->id;\n\n\t \n\tdev_set_name(&trig_info->dev, \"trigger%d\", trig_info->id);\n\n\tret = device_add(&trig_info->dev);\n\tif (ret)\n\t\tgoto error_unregister_id;\n\n\t \n\tmutex_lock(&iio_trigger_list_lock);\n\tif (__iio_trigger_find_by_name(trig_info->name)) {\n\t\tpr_err(\"Duplicate trigger name '%s'\\n\", trig_info->name);\n\t\tret = -EEXIST;\n\t\tgoto error_device_del;\n\t}\n\tlist_add_tail(&trig_info->list, &iio_trigger_list);\n\tmutex_unlock(&iio_trigger_list_lock);\n\n\treturn 0;\n\nerror_device_del:\n\tmutex_unlock(&iio_trigger_list_lock);\n\tdevice_del(&trig_info->dev);\nerror_unregister_id:\n\tida_free(&iio_trigger_ida, trig_info->id);\n\treturn ret;\n}\nEXPORT_SYMBOL(iio_trigger_register);\n\nvoid iio_trigger_unregister(struct iio_trigger *trig_info)\n{\n\tmutex_lock(&iio_trigger_list_lock);\n\tlist_del(&trig_info->list);\n\tmutex_unlock(&iio_trigger_list_lock);\n\n\tida_free(&iio_trigger_ida, trig_info->id);\n\t \n\tdevice_del(&trig_info->dev);\n}\nEXPORT_SYMBOL(iio_trigger_unregister);\n\nint iio_trigger_set_immutable(struct iio_dev *indio_dev, struct iio_trigger *trig)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque;\n\n\tif (!indio_dev || !trig)\n\t\treturn -EINVAL;\n\n\tiio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tmutex_lock(&iio_dev_opaque->mlock);\n\tWARN_ON(iio_dev_opaque->trig_readonly);\n\n\tindio_dev->trig = iio_trigger_get(trig);\n\tiio_dev_opaque->trig_readonly = true;\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(iio_trigger_set_immutable);\n\n \nstatic struct iio_trigger *__iio_trigger_find_by_name(const char *name)\n{\n\tstruct iio_trigger *iter;\n\n\tlist_for_each_entry(iter, &iio_trigger_list, list)\n\t\tif (!strcmp(iter->name, name))\n\t\t\treturn iter;\n\n\treturn NULL;\n}\n\nstatic struct iio_trigger *iio_trigger_acquire_by_name(const char *name)\n{\n\tstruct iio_trigger *trig = NULL, *iter;\n\n\tmutex_lock(&iio_trigger_list_lock);\n\tlist_for_each_entry(iter, &iio_trigger_list, list)\n\t\tif (sysfs_streq(iter->name, name)) {\n\t\t\ttrig = iter;\n\t\t\tiio_trigger_get(trig);\n\t\t\tbreak;\n\t\t}\n\tmutex_unlock(&iio_trigger_list_lock);\n\n\treturn trig;\n}\n\nstatic void iio_reenable_work_fn(struct work_struct *work)\n{\n\tstruct iio_trigger *trig = container_of(work, struct iio_trigger,\n\t\t\t\t\t\treenable_work);\n\n\t \n\ttrig->ops->reenable(trig);\n}\n\n \nstatic void iio_trigger_notify_done_atomic(struct iio_trigger *trig)\n{\n\tif (atomic_dec_and_test(&trig->use_count) && trig->ops &&\n\t    trig->ops->reenable)\n\t\tschedule_work(&trig->reenable_work);\n}\n\n \nvoid iio_trigger_poll(struct iio_trigger *trig)\n{\n\tint i;\n\n\tif (!atomic_read(&trig->use_count)) {\n\t\tatomic_set(&trig->use_count, CONFIG_IIO_CONSUMERS_PER_TRIGGER);\n\n\t\tfor (i = 0; i < CONFIG_IIO_CONSUMERS_PER_TRIGGER; i++) {\n\t\t\tif (trig->subirqs[i].enabled)\n\t\t\t\tgeneric_handle_irq(trig->subirq_base + i);\n\t\t\telse\n\t\t\t\tiio_trigger_notify_done_atomic(trig);\n\t\t}\n\t}\n}\nEXPORT_SYMBOL(iio_trigger_poll);\n\nirqreturn_t iio_trigger_generic_data_rdy_poll(int irq, void *private)\n{\n\tiio_trigger_poll(private);\n\treturn IRQ_HANDLED;\n}\nEXPORT_SYMBOL(iio_trigger_generic_data_rdy_poll);\n\n \nvoid iio_trigger_poll_nested(struct iio_trigger *trig)\n{\n\tint i;\n\n\tif (!atomic_read(&trig->use_count)) {\n\t\tatomic_set(&trig->use_count, CONFIG_IIO_CONSUMERS_PER_TRIGGER);\n\n\t\tfor (i = 0; i < CONFIG_IIO_CONSUMERS_PER_TRIGGER; i++) {\n\t\t\tif (trig->subirqs[i].enabled)\n\t\t\t\thandle_nested_irq(trig->subirq_base + i);\n\t\t\telse\n\t\t\t\tiio_trigger_notify_done(trig);\n\t\t}\n\t}\n}\nEXPORT_SYMBOL(iio_trigger_poll_nested);\n\nvoid iio_trigger_notify_done(struct iio_trigger *trig)\n{\n\tif (atomic_dec_and_test(&trig->use_count) && trig->ops &&\n\t    trig->ops->reenable)\n\t\ttrig->ops->reenable(trig);\n}\nEXPORT_SYMBOL(iio_trigger_notify_done);\n\n \nstatic int iio_trigger_get_irq(struct iio_trigger *trig)\n{\n\tint ret;\n\n\tmutex_lock(&trig->pool_lock);\n\tret = bitmap_find_free_region(trig->pool,\n\t\t\t\t      CONFIG_IIO_CONSUMERS_PER_TRIGGER,\n\t\t\t\t      ilog2(1));\n\tmutex_unlock(&trig->pool_lock);\n\tif (ret >= 0)\n\t\tret += trig->subirq_base;\n\n\treturn ret;\n}\n\nstatic void iio_trigger_put_irq(struct iio_trigger *trig, int irq)\n{\n\tmutex_lock(&trig->pool_lock);\n\tclear_bit(irq - trig->subirq_base, trig->pool);\n\tmutex_unlock(&trig->pool_lock);\n}\n\n \n \nint iio_trigger_attach_poll_func(struct iio_trigger *trig,\n\t\t\t\t struct iio_poll_func *pf)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(pf->indio_dev);\n\tbool notinuse =\n\t\tbitmap_empty(trig->pool, CONFIG_IIO_CONSUMERS_PER_TRIGGER);\n\tint ret = 0;\n\n\t \n\t__module_get(iio_dev_opaque->driver_module);\n\n\t \n\tpf->irq = iio_trigger_get_irq(trig);\n\tif (pf->irq < 0) {\n\t\tpr_err(\"Could not find an available irq for trigger %s, CONFIG_IIO_CONSUMERS_PER_TRIGGER=%d limit might be exceeded\\n\",\n\t\t\ttrig->name, CONFIG_IIO_CONSUMERS_PER_TRIGGER);\n\t\tgoto out_put_module;\n\t}\n\n\t \n\tret = request_threaded_irq(pf->irq, pf->h, pf->thread,\n\t\t\t\t   pf->type, pf->name,\n\t\t\t\t   pf);\n\tif (ret < 0)\n\t\tgoto out_put_irq;\n\n\t \n\tif (trig->ops && trig->ops->set_trigger_state && notinuse) {\n\t\tret = trig->ops->set_trigger_state(trig, true);\n\t\tif (ret)\n\t\t\tgoto out_free_irq;\n\t}\n\n\t \n\tif (iio_validate_own_trigger(pf->indio_dev, trig))\n\t\ttrig->attached_own_device = true;\n\n\treturn ret;\n\nout_free_irq:\n\tfree_irq(pf->irq, pf);\nout_put_irq:\n\tiio_trigger_put_irq(trig, pf->irq);\nout_put_module:\n\tmodule_put(iio_dev_opaque->driver_module);\n\treturn ret;\n}\n\nint iio_trigger_detach_poll_func(struct iio_trigger *trig,\n\t\t\t\t struct iio_poll_func *pf)\n{\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(pf->indio_dev);\n\tbool no_other_users =\n\t\tbitmap_weight(trig->pool, CONFIG_IIO_CONSUMERS_PER_TRIGGER) == 1;\n\tint ret = 0;\n\n\tif (trig->ops && trig->ops->set_trigger_state && no_other_users) {\n\t\tret = trig->ops->set_trigger_state(trig, false);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\tif (pf->indio_dev->dev.parent == trig->dev.parent)\n\t\ttrig->attached_own_device = false;\n\tiio_trigger_put_irq(trig, pf->irq);\n\tfree_irq(pf->irq, pf);\n\tmodule_put(iio_dev_opaque->driver_module);\n\n\treturn ret;\n}\n\nirqreturn_t iio_pollfunc_store_time(int irq, void *p)\n{\n\tstruct iio_poll_func *pf = p;\n\n\tpf->timestamp = iio_get_time_ns(pf->indio_dev);\n\treturn IRQ_WAKE_THREAD;\n}\nEXPORT_SYMBOL(iio_pollfunc_store_time);\n\nstruct iio_poll_func\n*iio_alloc_pollfunc(irqreturn_t (*h)(int irq, void *p),\n\t\t    irqreturn_t (*thread)(int irq, void *p),\n\t\t    int type,\n\t\t    struct iio_dev *indio_dev,\n\t\t    const char *fmt,\n\t\t    ...)\n{\n\tva_list vargs;\n\tstruct iio_poll_func *pf;\n\n\tpf = kmalloc(sizeof(*pf), GFP_KERNEL);\n\tif (!pf)\n\t\treturn NULL;\n\tva_start(vargs, fmt);\n\tpf->name = kvasprintf(GFP_KERNEL, fmt, vargs);\n\tva_end(vargs);\n\tif (pf->name == NULL) {\n\t\tkfree(pf);\n\t\treturn NULL;\n\t}\n\tpf->h = h;\n\tpf->thread = thread;\n\tpf->type = type;\n\tpf->indio_dev = indio_dev;\n\n\treturn pf;\n}\nEXPORT_SYMBOL_GPL(iio_alloc_pollfunc);\n\nvoid iio_dealloc_pollfunc(struct iio_poll_func *pf)\n{\n\tkfree(pf->name);\n\tkfree(pf);\n}\nEXPORT_SYMBOL_GPL(iio_dealloc_pollfunc);\n\n \nstatic ssize_t current_trigger_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\n\n\tif (indio_dev->trig)\n\t\treturn sysfs_emit(buf, \"%s\\n\", indio_dev->trig->name);\n\treturn 0;\n}\n\n \nstatic ssize_t current_trigger_store(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t len)\n{\n\tstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\n\tstruct iio_dev_opaque *iio_dev_opaque = to_iio_dev_opaque(indio_dev);\n\tstruct iio_trigger *oldtrig = indio_dev->trig;\n\tstruct iio_trigger *trig;\n\tint ret;\n\n\tmutex_lock(&iio_dev_opaque->mlock);\n\tif (iio_dev_opaque->currentmode == INDIO_BUFFER_TRIGGERED) {\n\t\tmutex_unlock(&iio_dev_opaque->mlock);\n\t\treturn -EBUSY;\n\t}\n\tif (iio_dev_opaque->trig_readonly) {\n\t\tmutex_unlock(&iio_dev_opaque->mlock);\n\t\treturn -EPERM;\n\t}\n\tmutex_unlock(&iio_dev_opaque->mlock);\n\n\ttrig = iio_trigger_acquire_by_name(buf);\n\tif (oldtrig == trig) {\n\t\tret = len;\n\t\tgoto out_trigger_put;\n\t}\n\n\tif (trig && indio_dev->info->validate_trigger) {\n\t\tret = indio_dev->info->validate_trigger(indio_dev, trig);\n\t\tif (ret)\n\t\t\tgoto out_trigger_put;\n\t}\n\n\tif (trig && trig->ops && trig->ops->validate_device) {\n\t\tret = trig->ops->validate_device(trig, indio_dev);\n\t\tif (ret)\n\t\t\tgoto out_trigger_put;\n\t}\n\n\tindio_dev->trig = trig;\n\n\tif (oldtrig) {\n\t\tif (indio_dev->modes & INDIO_EVENT_TRIGGERED)\n\t\t\tiio_trigger_detach_poll_func(oldtrig,\n\t\t\t\t\t\t     indio_dev->pollfunc_event);\n\t\tiio_trigger_put(oldtrig);\n\t}\n\tif (indio_dev->trig) {\n\t\tif (indio_dev->modes & INDIO_EVENT_TRIGGERED)\n\t\t\tiio_trigger_attach_poll_func(indio_dev->trig,\n\t\t\t\t\t\t     indio_dev->pollfunc_event);\n\t}\n\n\treturn len;\n\nout_trigger_put:\n\tif (trig)\n\t\tiio_trigger_put(trig);\n\treturn ret;\n}\n\nstatic DEVICE_ATTR_RW(current_trigger);\n\nstatic struct attribute *iio_trigger_consumer_attrs[] = {\n\t&dev_attr_current_trigger.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group iio_trigger_consumer_attr_group = {\n\t.name = \"trigger\",\n\t.attrs = iio_trigger_consumer_attrs,\n};\n\nstatic void iio_trig_release(struct device *device)\n{\n\tstruct iio_trigger *trig = to_iio_trigger(device);\n\tint i;\n\n\tif (trig->subirq_base) {\n\t\tfor (i = 0; i < CONFIG_IIO_CONSUMERS_PER_TRIGGER; i++) {\n\t\t\tirq_modify_status(trig->subirq_base + i,\n\t\t\t\t\t  IRQ_NOAUTOEN,\n\t\t\t\t\t  IRQ_NOREQUEST | IRQ_NOPROBE);\n\t\t\tirq_set_chip(trig->subirq_base + i,\n\t\t\t\t     NULL);\n\t\t\tirq_set_handler(trig->subirq_base + i,\n\t\t\t\t\tNULL);\n\t\t}\n\n\t\tirq_free_descs(trig->subirq_base,\n\t\t\t       CONFIG_IIO_CONSUMERS_PER_TRIGGER);\n\t}\n\tkfree(trig->name);\n\tkfree(trig);\n}\n\nstatic const struct device_type iio_trig_type = {\n\t.release = iio_trig_release,\n\t.groups = iio_trig_dev_groups,\n};\n\nstatic void iio_trig_subirqmask(struct irq_data *d)\n{\n\tstruct irq_chip *chip = irq_data_get_irq_chip(d);\n\tstruct iio_trigger *trig = container_of(chip, struct iio_trigger, subirq_chip);\n\n\ttrig->subirqs[d->irq - trig->subirq_base].enabled = false;\n}\n\nstatic void iio_trig_subirqunmask(struct irq_data *d)\n{\n\tstruct irq_chip *chip = irq_data_get_irq_chip(d);\n\tstruct iio_trigger *trig = container_of(chip, struct iio_trigger, subirq_chip);\n\n\ttrig->subirqs[d->irq - trig->subirq_base].enabled = true;\n}\n\nstatic __printf(3, 0)\nstruct iio_trigger *viio_trigger_alloc(struct device *parent,\n\t\t\t\t       struct module *this_mod,\n\t\t\t\t       const char *fmt,\n\t\t\t\t       va_list vargs)\n{\n\tstruct iio_trigger *trig;\n\tint i;\n\n\ttrig = kzalloc(sizeof(*trig), GFP_KERNEL);\n\tif (!trig)\n\t\treturn NULL;\n\n\ttrig->dev.parent = parent;\n\ttrig->dev.type = &iio_trig_type;\n\ttrig->dev.bus = &iio_bus_type;\n\tdevice_initialize(&trig->dev);\n\tINIT_WORK(&trig->reenable_work, iio_reenable_work_fn);\n\n\tmutex_init(&trig->pool_lock);\n\ttrig->subirq_base = irq_alloc_descs(-1, 0,\n\t\t\t\t\t    CONFIG_IIO_CONSUMERS_PER_TRIGGER,\n\t\t\t\t\t    0);\n\tif (trig->subirq_base < 0)\n\t\tgoto free_trig;\n\n\ttrig->name = kvasprintf(GFP_KERNEL, fmt, vargs);\n\tif (trig->name == NULL)\n\t\tgoto free_descs;\n\n\tINIT_LIST_HEAD(&trig->list);\n\n\ttrig->owner = this_mod;\n\n\ttrig->subirq_chip.name = trig->name;\n\ttrig->subirq_chip.irq_mask = &iio_trig_subirqmask;\n\ttrig->subirq_chip.irq_unmask = &iio_trig_subirqunmask;\n\tfor (i = 0; i < CONFIG_IIO_CONSUMERS_PER_TRIGGER; i++) {\n\t\tirq_set_chip(trig->subirq_base + i, &trig->subirq_chip);\n\t\tirq_set_handler(trig->subirq_base + i, &handle_simple_irq);\n\t\tirq_modify_status(trig->subirq_base + i,\n\t\t\t\t  IRQ_NOREQUEST | IRQ_NOAUTOEN, IRQ_NOPROBE);\n\t}\n\n\treturn trig;\n\nfree_descs:\n\tirq_free_descs(trig->subirq_base, CONFIG_IIO_CONSUMERS_PER_TRIGGER);\nfree_trig:\n\tkfree(trig);\n\treturn NULL;\n}\n\n \nstruct iio_trigger *__iio_trigger_alloc(struct device *parent,\n\t\t\t\t\tstruct module *this_mod,\n\t\t\t\t\tconst char *fmt, ...)\n{\n\tstruct iio_trigger *trig;\n\tva_list vargs;\n\n\tva_start(vargs, fmt);\n\ttrig = viio_trigger_alloc(parent, this_mod, fmt, vargs);\n\tva_end(vargs);\n\n\treturn trig;\n}\nEXPORT_SYMBOL(__iio_trigger_alloc);\n\nvoid iio_trigger_free(struct iio_trigger *trig)\n{\n\tif (trig)\n\t\tput_device(&trig->dev);\n}\nEXPORT_SYMBOL(iio_trigger_free);\n\nstatic void devm_iio_trigger_release(struct device *dev, void *res)\n{\n\tiio_trigger_free(*(struct iio_trigger **)res);\n}\n\n \nstruct iio_trigger *__devm_iio_trigger_alloc(struct device *parent,\n\t\t\t\t\t     struct module *this_mod,\n\t\t\t\t\t     const char *fmt, ...)\n{\n\tstruct iio_trigger **ptr, *trig;\n\tva_list vargs;\n\n\tptr = devres_alloc(devm_iio_trigger_release, sizeof(*ptr),\n\t\t\t   GFP_KERNEL);\n\tif (!ptr)\n\t\treturn NULL;\n\n\t \n\tva_start(vargs, fmt);\n\ttrig = viio_trigger_alloc(parent, this_mod, fmt, vargs);\n\tva_end(vargs);\n\tif (trig) {\n\t\t*ptr = trig;\n\t\tdevres_add(parent, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn trig;\n}\nEXPORT_SYMBOL_GPL(__devm_iio_trigger_alloc);\n\nstatic void devm_iio_trigger_unreg(void *trigger_info)\n{\n\tiio_trigger_unregister(trigger_info);\n}\n\n \nint devm_iio_trigger_register(struct device *dev,\n\t\t\t      struct iio_trigger *trig_info)\n{\n\tint ret;\n\n\tret = iio_trigger_register(trig_info);\n\tif (ret)\n\t\treturn ret;\n\n\treturn devm_add_action_or_reset(dev, devm_iio_trigger_unreg, trig_info);\n}\nEXPORT_SYMBOL_GPL(devm_iio_trigger_register);\n\nbool iio_trigger_using_own(struct iio_dev *indio_dev)\n{\n\treturn indio_dev->trig->attached_own_device;\n}\nEXPORT_SYMBOL(iio_trigger_using_own);\n\n \nint iio_validate_own_trigger(struct iio_dev *idev, struct iio_trigger *trig)\n{\n\tif (idev->dev.parent != trig->dev.parent)\n\t\treturn -EINVAL;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(iio_validate_own_trigger);\n\n \nint iio_trigger_validate_own_device(struct iio_trigger *trig,\n\t\t\t\t    struct iio_dev *indio_dev)\n{\n\tif (indio_dev->dev.parent != trig->dev.parent)\n\t\treturn -EINVAL;\n\treturn 0;\n}\nEXPORT_SYMBOL(iio_trigger_validate_own_device);\n\nint iio_device_register_trigger_consumer(struct iio_dev *indio_dev)\n{\n\treturn iio_device_register_sysfs_group(indio_dev,\n\t\t\t\t\t       &iio_trigger_consumer_attr_group);\n}\n\nvoid iio_device_unregister_trigger_consumer(struct iio_dev *indio_dev)\n{\n\t \n\tif (indio_dev->trig)\n\t\tiio_trigger_put(indio_dev->trig);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}