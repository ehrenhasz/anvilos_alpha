{
  "module_name": "srq.c",
  "hash_id": "485396b33df9ba77ae3597271e487388b0f503627c5167c312b36527fe2dae7d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mlx4/srq.c",
  "human_readable_source": " \n\n#include <linux/mlx4/qp.h>\n#include <linux/mlx4/srq.h>\n#include <linux/slab.h>\n\n#include \"mlx4_ib.h\"\n#include <rdma/mlx4-abi.h>\n#include <rdma/uverbs_ioctl.h>\n\nstatic void *get_wqe(struct mlx4_ib_srq *srq, int n)\n{\n\treturn mlx4_buf_offset(&srq->buf, n << srq->msrq.wqe_shift);\n}\n\nstatic void mlx4_ib_srq_event(struct mlx4_srq *srq, enum mlx4_event type)\n{\n\tstruct ib_event event;\n\tstruct ib_srq *ibsrq = &to_mibsrq(srq)->ibsrq;\n\n\tif (ibsrq->event_handler) {\n\t\tevent.device      = ibsrq->device;\n\t\tevent.element.srq = ibsrq;\n\t\tswitch (type) {\n\t\tcase MLX4_EVENT_TYPE_SRQ_LIMIT:\n\t\t\tevent.event = IB_EVENT_SRQ_LIMIT_REACHED;\n\t\t\tbreak;\n\t\tcase MLX4_EVENT_TYPE_SRQ_CATAS_ERROR:\n\t\t\tevent.event = IB_EVENT_SRQ_ERR;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_warn(\"Unexpected event type %d \"\n\t\t\t       \"on SRQ %06x\\n\", type, srq->srqn);\n\t\t\treturn;\n\t\t}\n\n\t\tibsrq->event_handler(&event, ibsrq->srq_context);\n\t}\n}\n\nint mlx4_ib_create_srq(struct ib_srq *ib_srq,\n\t\t       struct ib_srq_init_attr *init_attr,\n\t\t       struct ib_udata *udata)\n{\n\tstruct mlx4_ib_dev *dev = to_mdev(ib_srq->device);\n\tstruct mlx4_ib_ucontext *ucontext = rdma_udata_to_drv_context(\n\t\tudata, struct mlx4_ib_ucontext, ibucontext);\n\tstruct mlx4_ib_srq *srq = to_msrq(ib_srq);\n\tstruct mlx4_wqe_srq_next_seg *next;\n\tstruct mlx4_wqe_data_seg *scatter;\n\tu32 cqn;\n\tu16 xrcdn;\n\tint desc_size;\n\tint buf_size;\n\tint err;\n\tint i;\n\n\tif (init_attr->srq_type != IB_SRQT_BASIC &&\n\t    init_attr->srq_type != IB_SRQT_XRC)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (init_attr->attr.max_wr  >= dev->dev->caps.max_srq_wqes ||\n\t    init_attr->attr.max_sge >  dev->dev->caps.max_srq_sge)\n\t\treturn -EINVAL;\n\n\tmutex_init(&srq->mutex);\n\tspin_lock_init(&srq->lock);\n\tsrq->msrq.max    = roundup_pow_of_two(init_attr->attr.max_wr + 1);\n\tsrq->msrq.max_gs = init_attr->attr.max_sge;\n\n\tdesc_size = max(32UL,\n\t\t\troundup_pow_of_two(sizeof (struct mlx4_wqe_srq_next_seg) +\n\t\t\t\t\t   srq->msrq.max_gs *\n\t\t\t\t\t   sizeof (struct mlx4_wqe_data_seg)));\n\tsrq->msrq.wqe_shift = ilog2(desc_size);\n\n\tbuf_size = srq->msrq.max * desc_size;\n\n\tif (udata) {\n\t\tstruct mlx4_ib_create_srq ucmd;\n\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd)))\n\t\t\treturn -EFAULT;\n\n\t\tsrq->umem =\n\t\t\tib_umem_get(ib_srq->device, ucmd.buf_addr, buf_size, 0);\n\t\tif (IS_ERR(srq->umem))\n\t\t\treturn PTR_ERR(srq->umem);\n\n\t\terr = mlx4_mtt_init(\n\t\t\tdev->dev, ib_umem_num_dma_blocks(srq->umem, PAGE_SIZE),\n\t\t\tPAGE_SHIFT, &srq->mtt);\n\t\tif (err)\n\t\t\tgoto err_buf;\n\n\t\terr = mlx4_ib_umem_write_mtt(dev, &srq->mtt, srq->umem);\n\t\tif (err)\n\t\t\tgoto err_mtt;\n\n\t\terr = mlx4_ib_db_map_user(udata, ucmd.db_addr, &srq->db);\n\t\tif (err)\n\t\t\tgoto err_mtt;\n\t} else {\n\t\terr = mlx4_db_alloc(dev->dev, &srq->db, 0);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t*srq->db.db = 0;\n\n\t\tif (mlx4_buf_alloc(dev->dev, buf_size, PAGE_SIZE * 2,\n\t\t\t\t   &srq->buf)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_db;\n\t\t}\n\n\t\tsrq->head    = 0;\n\t\tsrq->tail    = srq->msrq.max - 1;\n\t\tsrq->wqe_ctr = 0;\n\n\t\tfor (i = 0; i < srq->msrq.max; ++i) {\n\t\t\tnext = get_wqe(srq, i);\n\t\t\tnext->next_wqe_index =\n\t\t\t\tcpu_to_be16((i + 1) & (srq->msrq.max - 1));\n\n\t\t\tfor (scatter = (void *) (next + 1);\n\t\t\t     (void *) scatter < (void *) next + desc_size;\n\t\t\t     ++scatter)\n\t\t\t\tscatter->lkey = cpu_to_be32(MLX4_INVALID_LKEY);\n\t\t}\n\n\t\terr = mlx4_mtt_init(dev->dev, srq->buf.npages, srq->buf.page_shift,\n\t\t\t\t    &srq->mtt);\n\t\tif (err)\n\t\t\tgoto err_buf;\n\n\t\terr = mlx4_buf_write_mtt(dev->dev, &srq->mtt, &srq->buf);\n\t\tif (err)\n\t\t\tgoto err_mtt;\n\n\t\tsrq->wrid = kvmalloc_array(srq->msrq.max,\n\t\t\t\t\t   sizeof(u64), GFP_KERNEL);\n\t\tif (!srq->wrid) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err_mtt;\n\t\t}\n\t}\n\n\tcqn = ib_srq_has_cq(init_attr->srq_type) ?\n\t\tto_mcq(init_attr->ext.cq)->mcq.cqn : 0;\n\txrcdn = (init_attr->srq_type == IB_SRQT_XRC) ?\n\t\tto_mxrcd(init_attr->ext.xrc.xrcd)->xrcdn :\n\t\t(u16) dev->dev->caps.reserved_xrcds;\n\terr = mlx4_srq_alloc(dev->dev, to_mpd(ib_srq->pd)->pdn, cqn, xrcdn,\n\t\t\t     &srq->mtt, srq->db.dma, &srq->msrq);\n\tif (err)\n\t\tgoto err_wrid;\n\n\tsrq->msrq.event = mlx4_ib_srq_event;\n\tsrq->ibsrq.ext.xrc.srq_num = srq->msrq.srqn;\n\n\tif (udata)\n\t\tif (ib_copy_to_udata(udata, &srq->msrq.srqn, sizeof (__u32))) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto err_wrid;\n\t\t}\n\n\tinit_attr->attr.max_wr = srq->msrq.max - 1;\n\n\treturn 0;\n\nerr_wrid:\n\tif (udata)\n\t\tmlx4_ib_db_unmap_user(ucontext, &srq->db);\n\telse\n\t\tkvfree(srq->wrid);\n\nerr_mtt:\n\tmlx4_mtt_cleanup(dev->dev, &srq->mtt);\n\nerr_buf:\n\tif (!srq->umem)\n\t\tmlx4_buf_free(dev->dev, buf_size, &srq->buf);\n\tib_umem_release(srq->umem);\n\nerr_db:\n\tif (!udata)\n\t\tmlx4_db_free(dev->dev, &srq->db);\n\n\treturn err;\n}\n\nint mlx4_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,\n\t\t       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata)\n{\n\tstruct mlx4_ib_dev *dev = to_mdev(ibsrq->device);\n\tstruct mlx4_ib_srq *srq = to_msrq(ibsrq);\n\tint ret;\n\n\t \n\tif (attr_mask & IB_SRQ_MAX_WR)\n\t\treturn -EINVAL;\n\n\tif (attr_mask & IB_SRQ_LIMIT) {\n\t\tif (attr->srq_limit >= srq->msrq.max)\n\t\t\treturn -EINVAL;\n\n\t\tmutex_lock(&srq->mutex);\n\t\tret = mlx4_srq_arm(dev->dev, &srq->msrq, attr->srq_limit);\n\t\tmutex_unlock(&srq->mutex);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint mlx4_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr)\n{\n\tstruct mlx4_ib_dev *dev = to_mdev(ibsrq->device);\n\tstruct mlx4_ib_srq *srq = to_msrq(ibsrq);\n\tint ret;\n\tint limit_watermark;\n\n\tret = mlx4_srq_query(dev->dev, &srq->msrq, &limit_watermark);\n\tif (ret)\n\t\treturn ret;\n\n\tsrq_attr->srq_limit = limit_watermark;\n\tsrq_attr->max_wr    = srq->msrq.max - 1;\n\tsrq_attr->max_sge   = srq->msrq.max_gs;\n\n\treturn 0;\n}\n\nint mlx4_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata)\n{\n\tstruct mlx4_ib_dev *dev = to_mdev(srq->device);\n\tstruct mlx4_ib_srq *msrq = to_msrq(srq);\n\n\tmlx4_srq_free(dev->dev, &msrq->msrq);\n\tmlx4_mtt_cleanup(dev->dev, &msrq->mtt);\n\n\tif (udata) {\n\t\tmlx4_ib_db_unmap_user(\n\t\t\trdma_udata_to_drv_context(\n\t\t\t\tudata,\n\t\t\t\tstruct mlx4_ib_ucontext,\n\t\t\t\tibucontext),\n\t\t\t&msrq->db);\n\t} else {\n\t\tkvfree(msrq->wrid);\n\t\tmlx4_buf_free(dev->dev, msrq->msrq.max << msrq->msrq.wqe_shift,\n\t\t\t      &msrq->buf);\n\t\tmlx4_db_free(dev->dev, &msrq->db);\n\t}\n\tib_umem_release(msrq->umem);\n\treturn 0;\n}\n\nvoid mlx4_ib_free_srq_wqe(struct mlx4_ib_srq *srq, int wqe_index)\n{\n\tstruct mlx4_wqe_srq_next_seg *next;\n\n\t \n\tspin_lock(&srq->lock);\n\n\tnext = get_wqe(srq, srq->tail);\n\tnext->next_wqe_index = cpu_to_be16(wqe_index);\n\tsrq->tail = wqe_index;\n\n\tspin_unlock(&srq->lock);\n}\n\nint mlx4_ib_post_srq_recv(struct ib_srq *ibsrq, const struct ib_recv_wr *wr,\n\t\t\t  const struct ib_recv_wr **bad_wr)\n{\n\tstruct mlx4_ib_srq *srq = to_msrq(ibsrq);\n\tstruct mlx4_wqe_srq_next_seg *next;\n\tstruct mlx4_wqe_data_seg *scat;\n\tunsigned long flags;\n\tint err = 0;\n\tint nreq;\n\tint i;\n\tstruct mlx4_ib_dev *mdev = to_mdev(ibsrq->device);\n\n\tspin_lock_irqsave(&srq->lock, flags);\n\tif (mdev->dev->persist->state & MLX4_DEVICE_STATE_INTERNAL_ERROR) {\n\t\terr = -EIO;\n\t\t*bad_wr = wr;\n\t\tgoto out;\n\t}\n\n\tfor (nreq = 0; wr; ++nreq, wr = wr->next) {\n\t\tif (unlikely(wr->num_sge > srq->msrq.max_gs)) {\n\t\t\terr = -EINVAL;\n\t\t\t*bad_wr = wr;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (unlikely(srq->head == srq->tail)) {\n\t\t\terr = -ENOMEM;\n\t\t\t*bad_wr = wr;\n\t\t\tbreak;\n\t\t}\n\n\t\tsrq->wrid[srq->head] = wr->wr_id;\n\n\t\tnext      = get_wqe(srq, srq->head);\n\t\tsrq->head = be16_to_cpu(next->next_wqe_index);\n\t\tscat      = (struct mlx4_wqe_data_seg *) (next + 1);\n\n\t\tfor (i = 0; i < wr->num_sge; ++i) {\n\t\t\tscat[i].byte_count = cpu_to_be32(wr->sg_list[i].length);\n\t\t\tscat[i].lkey       = cpu_to_be32(wr->sg_list[i].lkey);\n\t\t\tscat[i].addr       = cpu_to_be64(wr->sg_list[i].addr);\n\t\t}\n\n\t\tif (i < srq->msrq.max_gs) {\n\t\t\tscat[i].byte_count = 0;\n\t\t\tscat[i].lkey       = cpu_to_be32(MLX4_INVALID_LKEY);\n\t\t\tscat[i].addr       = 0;\n\t\t}\n\t}\n\n\tif (likely(nreq)) {\n\t\tsrq->wqe_ctr += nreq;\n\n\t\t \n\t\twmb();\n\n\t\t*srq->db.db = cpu_to_be32(srq->wqe_ctr);\n\t}\nout:\n\n\tspin_unlock_irqrestore(&srq->lock, flags);\n\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}