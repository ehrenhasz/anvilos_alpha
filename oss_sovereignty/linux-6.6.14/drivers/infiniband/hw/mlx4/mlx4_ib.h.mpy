{
  "module_name": "mlx4_ib.h",
  "hash_id": "d68ea671a1cbac4221350625c5520a9e3a77c14625d84de5927b1ee071c8f6a2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mlx4/mlx4_ib.h",
  "human_readable_source": " \n\n#ifndef MLX4_IB_H\n#define MLX4_IB_H\n\n#include <linux/compiler.h>\n#include <linux/list.h>\n#include <linux/mutex.h>\n#include <linux/idr.h>\n#include <linux/notifier.h>\n\n#include <rdma/ib_verbs.h>\n#include <rdma/ib_umem.h>\n#include <rdma/ib_mad.h>\n#include <rdma/ib_sa.h>\n\n#include <linux/mlx4/device.h>\n#include <linux/mlx4/doorbell.h>\n#include <linux/mlx4/qp.h>\n#include <linux/mlx4/cq.h>\n\n#define MLX4_IB_DRV_NAME\t\"mlx4_ib\"\n\n#ifdef pr_fmt\n#undef pr_fmt\n#endif\n#define pr_fmt(fmt)\t\"<\" MLX4_IB_DRV_NAME \"> %s: \" fmt, __func__\n\n#define mlx4_ib_warn(ibdev, format, arg...) \\\n\tdev_warn((ibdev)->dev.parent, MLX4_IB_DRV_NAME \": \" format, ## arg)\n\nenum {\n\tMLX4_IB_SQ_MIN_WQE_SHIFT = 6,\n\tMLX4_IB_MAX_HEADROOM\t = 2048\n};\n\n#define MLX4_IB_SQ_HEADROOM(shift)\t((MLX4_IB_MAX_HEADROOM >> (shift)) + 1)\n#define MLX4_IB_SQ_MAX_SPARE\t\t(MLX4_IB_SQ_HEADROOM(MLX4_IB_SQ_MIN_WQE_SHIFT))\n\n \nextern int mlx4_ib_sm_guid_assign;\n\n#define MLX4_IB_UC_STEER_QPN_ALIGN 1\n#define MLX4_IB_UC_MAX_NUM_QPS     256\n\nenum hw_bar_type {\n\tHW_BAR_BF,\n\tHW_BAR_DB,\n\tHW_BAR_CLOCK,\n\tHW_BAR_COUNT\n};\n\nstruct mlx4_ib_ucontext {\n\tstruct ib_ucontext\tibucontext;\n\tstruct mlx4_uar\t\tuar;\n\tstruct list_head\tdb_page_list;\n\tstruct mutex\t\tdb_page_mutex;\n\tstruct list_head\twqn_ranges_list;\n\tstruct mutex\t\twqn_ranges_mutex;  \n};\n\nstruct mlx4_ib_pd {\n\tstruct ib_pd\t\tibpd;\n\tu32\t\t\tpdn;\n};\n\nstruct mlx4_ib_xrcd {\n\tstruct ib_xrcd\t\tibxrcd;\n\tu32\t\t\txrcdn;\n\tstruct ib_pd\t       *pd;\n\tstruct ib_cq\t       *cq;\n};\n\nstruct mlx4_ib_cq_buf {\n\tstruct mlx4_buf\t\tbuf;\n\tstruct mlx4_mtt\t\tmtt;\n\tint\t\t\tentry_size;\n};\n\nstruct mlx4_ib_cq_resize {\n\tstruct mlx4_ib_cq_buf\tbuf;\n\tint\t\t\tcqe;\n};\n\nstruct mlx4_ib_cq {\n\tstruct ib_cq\t\tibcq;\n\tstruct mlx4_cq\t\tmcq;\n\tstruct mlx4_ib_cq_buf\tbuf;\n\tstruct mlx4_ib_cq_resize *resize_buf;\n\tstruct mlx4_db\t\tdb;\n\tspinlock_t\t\tlock;\n\tstruct mutex\t\tresize_mutex;\n\tstruct ib_umem\t       *umem;\n\tstruct ib_umem\t       *resize_umem;\n\tint\t\t\tcreate_flags;\n\t \n\tstruct list_head\t\tsend_qp_list;\n\tstruct list_head\t\trecv_qp_list;\n};\n\n#define MLX4_MR_PAGES_ALIGN 0x40\n\nstruct mlx4_ib_mr {\n\tstruct ib_mr\t\tibmr;\n\t__be64\t\t\t*pages;\n\tdma_addr_t\t\tpage_map;\n\tu32\t\t\tnpages;\n\tu32\t\t\tmax_pages;\n\tstruct mlx4_mr\t\tmmr;\n\tstruct ib_umem\t       *umem;\n\tsize_t\t\t\tpage_map_size;\n};\n\nstruct mlx4_ib_mw {\n\tstruct ib_mw\t\tibmw;\n\tstruct mlx4_mw\t\tmmw;\n};\n\n#define MAX_REGS_PER_FLOW 2\n\nstruct mlx4_flow_reg_id {\n\tu64 id;\n\tu64 mirror;\n};\n\nstruct mlx4_ib_flow {\n\tstruct ib_flow ibflow;\n\t \n\tstruct mlx4_flow_reg_id reg_id[MAX_REGS_PER_FLOW];\n};\n\nstruct mlx4_ib_wq {\n\tu64\t\t       *wrid;\n\tspinlock_t\t\tlock;\n\tint\t\t\twqe_cnt;\n\tint\t\t\tmax_post;\n\tint\t\t\tmax_gs;\n\tint\t\t\toffset;\n\tint\t\t\twqe_shift;\n\tunsigned\t\thead;\n\tunsigned\t\ttail;\n};\n\nenum {\n\tMLX4_IB_QP_CREATE_ROCE_V2_GSI = IB_QP_CREATE_RESERVED_START\n};\n\nenum mlx4_ib_qp_flags {\n\tMLX4_IB_QP_LSO = IB_QP_CREATE_IPOIB_UD_LSO,\n\tMLX4_IB_QP_BLOCK_MULTICAST_LOOPBACK = IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK,\n\tMLX4_IB_QP_NETIF = IB_QP_CREATE_NETIF_QP,\n\tMLX4_IB_QP_SCATTER_FCS = IB_QP_CREATE_SCATTER_FCS,\n\n\t \n\tMLX4_IB_ROCE_V2_GSI_QP = MLX4_IB_QP_CREATE_ROCE_V2_GSI,\n\tMLX4_IB_SRIOV_TUNNEL_QP = 1 << 30,\n\tMLX4_IB_SRIOV_SQP = 1 << 31,\n};\n\nstruct mlx4_ib_gid_entry {\n\tstruct list_head\tlist;\n\tunion ib_gid\t\tgid;\n\tint\t\t\tadded;\n\tu8\t\t\tport;\n};\n\nenum mlx4_ib_qp_type {\n\t \n\tMLX4_IB_QPT_SMI = IB_QPT_SMI,\n\tMLX4_IB_QPT_GSI = IB_QPT_GSI,\n\n\tMLX4_IB_QPT_RC = IB_QPT_RC,\n\tMLX4_IB_QPT_UC = IB_QPT_UC,\n\tMLX4_IB_QPT_UD = IB_QPT_UD,\n\tMLX4_IB_QPT_RAW_IPV6 = IB_QPT_RAW_IPV6,\n\tMLX4_IB_QPT_RAW_ETHERTYPE = IB_QPT_RAW_ETHERTYPE,\n\tMLX4_IB_QPT_RAW_PACKET = IB_QPT_RAW_PACKET,\n\tMLX4_IB_QPT_XRC_INI = IB_QPT_XRC_INI,\n\tMLX4_IB_QPT_XRC_TGT = IB_QPT_XRC_TGT,\n\n\tMLX4_IB_QPT_PROXY_SMI_OWNER\t= 1 << 16,\n\tMLX4_IB_QPT_PROXY_SMI\t\t= 1 << 17,\n\tMLX4_IB_QPT_PROXY_GSI\t\t= 1 << 18,\n\tMLX4_IB_QPT_TUN_SMI_OWNER\t= 1 << 19,\n\tMLX4_IB_QPT_TUN_SMI\t\t= 1 << 20,\n\tMLX4_IB_QPT_TUN_GSI\t\t= 1 << 21,\n};\n\n#define MLX4_IB_QPT_ANY_SRIOV\t(MLX4_IB_QPT_PROXY_SMI_OWNER | \\\n\tMLX4_IB_QPT_PROXY_SMI | MLX4_IB_QPT_PROXY_GSI | MLX4_IB_QPT_TUN_SMI_OWNER | \\\n\tMLX4_IB_QPT_TUN_SMI | MLX4_IB_QPT_TUN_GSI)\n\nenum mlx4_ib_mad_ifc_flags {\n\tMLX4_MAD_IFC_IGNORE_MKEY\t= 1,\n\tMLX4_MAD_IFC_IGNORE_BKEY\t= 2,\n\tMLX4_MAD_IFC_IGNORE_KEYS\t= (MLX4_MAD_IFC_IGNORE_MKEY |\n\t\t\t\t\t   MLX4_MAD_IFC_IGNORE_BKEY),\n\tMLX4_MAD_IFC_NET_VIEW\t\t= 4,\n};\n\nenum {\n\tMLX4_NUM_TUNNEL_BUFS\t\t= 512,\n\tMLX4_NUM_WIRE_BUFS\t\t= 2048,\n};\n\nstruct mlx4_ib_tunnel_header {\n\tstruct mlx4_av av;\n\t__be32 remote_qpn;\n\t__be32 qkey;\n\t__be16 vlan;\n\tu8 mac[6];\n\t__be16 pkey_index;\n\tu8 reserved[6];\n};\n\nstruct mlx4_ib_buf {\n\tvoid *addr;\n\tdma_addr_t map;\n};\n\nstruct mlx4_rcv_tunnel_hdr {\n\t__be32 flags_src_qp;  \n\tu8 g_ml_path;  \n\tu8 reserved;\n\t__be16 pkey_index;\n\t__be16 sl_vid;\n\t__be16 slid_mac_47_32;\n\t__be32 mac_31_0;\n};\n\nstruct mlx4_ib_proxy_sqp_hdr {\n\tstruct ib_grh grh;\n\tstruct mlx4_rcv_tunnel_hdr tun;\n}  __packed;\n\nstruct mlx4_roce_smac_vlan_info {\n\tu64 smac;\n\tint smac_index;\n\tint smac_port;\n\tu64 candidate_smac;\n\tint candidate_smac_index;\n\tint candidate_smac_port;\n\tu16 vid;\n\tint vlan_index;\n\tint vlan_port;\n\tu16 candidate_vid;\n\tint candidate_vlan_index;\n\tint candidate_vlan_port;\n\tint update_vid;\n};\n\nstruct mlx4_wqn_range {\n\tint\t\t\tbase_wqn;\n\tint\t\t\tsize;\n\tint\t\t\trefcount;\n\tbool\t\t\tdirty;\n\tstruct list_head\tlist;\n};\n\nstruct mlx4_ib_rss {\n\tunsigned int\t\tbase_qpn_tbl_sz;\n\tu8\t\t\tflags;\n\tu8\t\t\trss_key[MLX4_EN_RSS_KEY_SIZE];\n};\n\nenum {\n\t \n\tMLX4_IB_UD_HEADER_SIZE\t\t= 82,\n\tMLX4_IB_LSO_HEADER_SPARE\t= 128,\n};\n\nstruct mlx4_ib_sqp {\n\tint pkey_index;\n\tu32 qkey;\n\tu32 send_psn;\n\tstruct ib_ud_header ud_header;\n\tu8 header_buf[MLX4_IB_UD_HEADER_SIZE];\n\tstruct ib_qp *roce_v2_gsi;\n};\n\nstruct mlx4_ib_qp {\n\tunion {\n\t\tstruct ib_qp\tibqp;\n\t\tstruct ib_wq\tibwq;\n\t};\n\tstruct mlx4_qp\t\tmqp;\n\tstruct mlx4_buf\t\tbuf;\n\n\tstruct mlx4_db\t\tdb;\n\tstruct mlx4_ib_wq\trq;\n\n\tu32\t\t\tdoorbell_qpn;\n\t__be32\t\t\tsq_signal_bits;\n\tunsigned\t\tsq_next_wqe;\n\tint\t\t\tsq_spare_wqes;\n\tstruct mlx4_ib_wq\tsq;\n\n\tenum mlx4_ib_qp_type\tmlx4_ib_qp_type;\n\tstruct ib_umem\t       *umem;\n\tstruct mlx4_mtt\t\tmtt;\n\tint\t\t\tbuf_size;\n\tstruct mutex\t\tmutex;\n\tu16\t\t\txrcdn;\n\tu32\t\t\tflags;\n\tu8\t\t\tport;\n\tu8\t\t\talt_port;\n\tu8\t\t\tatomic_rd_en;\n\tu8\t\t\tresp_depth;\n\tu8\t\t\tsq_no_prefetch;\n\tu8\t\t\tstate;\n\tint\t\t\tmlx_type;\n\tu32\t\t\tinl_recv_sz;\n\tstruct list_head\tgid_list;\n\tstruct list_head\tsteering_rules;\n\tstruct mlx4_ib_buf\t*sqp_proxy_rcv;\n\tstruct mlx4_roce_smac_vlan_info pri;\n\tstruct mlx4_roce_smac_vlan_info alt;\n\tu64\t\t\treg_id;\n\tstruct list_head\tqps_list;\n\tstruct list_head\tcq_recv_list;\n\tstruct list_head\tcq_send_list;\n\tstruct counter_index\t*counter_index;\n\tstruct mlx4_wqn_range\t*wqn_range;\n\t \n\tu32\t\t\trss_usecnt;\n\tunion {\n\t\tstruct mlx4_ib_rss *rss_ctx;\n\t\tstruct mlx4_ib_sqp *sqp;\n\t};\n};\n\nstruct mlx4_ib_srq {\n\tstruct ib_srq\t\tibsrq;\n\tstruct mlx4_srq\t\tmsrq;\n\tstruct mlx4_buf\t\tbuf;\n\tstruct mlx4_db\t\tdb;\n\tu64\t\t       *wrid;\n\tspinlock_t\t\tlock;\n\tint\t\t\thead;\n\tint\t\t\ttail;\n\tu16\t\t\twqe_ctr;\n\tstruct ib_umem\t       *umem;\n\tstruct mlx4_mtt\t\tmtt;\n\tstruct mutex\t\tmutex;\n};\n\nstruct mlx4_ib_ah {\n\tstruct ib_ah\t\tibah;\n\tunion mlx4_ext_av       av;\n};\n\nstruct mlx4_ib_rwq_ind_table {\n\tstruct ib_rwq_ind_table ib_rwq_ind_tbl;\n};\n\n \n \n \n#define NUM_PORT_ALIAS_GUID\t\t2\n#define NUM_ALIAS_GUID_IN_REC\t\t8\n#define NUM_ALIAS_GUID_REC_IN_PORT\t16\n#define GUID_REC_SIZE\t\t\t8\n#define NUM_ALIAS_GUID_PER_PORT\t\t128\n#define MLX4_NOT_SET_GUID\t\t(0x00LL)\n#define MLX4_GUID_FOR_DELETE_VAL\t(~(0x00LL))\n\nenum mlx4_guid_alias_rec_status {\n\tMLX4_GUID_INFO_STATUS_IDLE,\n\tMLX4_GUID_INFO_STATUS_SET,\n};\n\n#define GUID_STATE_NEED_PORT_INIT 0x01\n\nenum mlx4_guid_alias_rec_method {\n\tMLX4_GUID_INFO_RECORD_SET\t= IB_MGMT_METHOD_SET,\n\tMLX4_GUID_INFO_RECORD_DELETE\t= IB_SA_METHOD_DELETE,\n};\n\nstruct mlx4_sriov_alias_guid_info_rec_det {\n\tu8 all_recs[GUID_REC_SIZE * NUM_ALIAS_GUID_IN_REC];\n\tib_sa_comp_mask guid_indexes;  \n\tenum mlx4_guid_alias_rec_status status;  \n\tunsigned int guids_retry_schedule[NUM_ALIAS_GUID_IN_REC];\n\tu64 time_to_run;\n};\n\nstruct mlx4_sriov_alias_guid_port_rec_det {\n\tstruct mlx4_sriov_alias_guid_info_rec_det all_rec_per_port[NUM_ALIAS_GUID_REC_IN_PORT];\n\tstruct workqueue_struct *wq;\n\tstruct delayed_work alias_guid_work;\n\tu32 port;\n\tu32 state_flags;\n\tstruct mlx4_sriov_alias_guid *parent;\n\tstruct list_head cb_list;\n};\n\nstruct mlx4_sriov_alias_guid {\n\tstruct mlx4_sriov_alias_guid_port_rec_det ports_guid[MLX4_MAX_PORTS];\n\tspinlock_t ag_work_lock;\n\tstruct ib_sa_client *sa_client;\n};\n\nstruct mlx4_ib_demux_work {\n\tstruct work_struct\twork;\n\tstruct mlx4_ib_dev     *dev;\n\tint\t\t\tslave;\n\tint\t\t\tdo_init;\n\tu8\t\t\tport;\n\n};\n\nstruct mlx4_ib_tun_tx_buf {\n\tstruct mlx4_ib_buf buf;\n\tstruct ib_ah *ah;\n};\n\nstruct mlx4_ib_demux_pv_qp {\n\tstruct ib_qp *qp;\n\tenum ib_qp_type proxy_qpt;\n\tstruct mlx4_ib_buf *ring;\n\tstruct mlx4_ib_tun_tx_buf *tx_ring;\n\tspinlock_t tx_lock;\n\tunsigned tx_ix_head;\n\tunsigned tx_ix_tail;\n};\n\nenum mlx4_ib_demux_pv_state {\n\tDEMUX_PV_STATE_DOWN,\n\tDEMUX_PV_STATE_STARTING,\n\tDEMUX_PV_STATE_ACTIVE,\n\tDEMUX_PV_STATE_DOWNING,\n};\n\nstruct mlx4_ib_demux_pv_ctx {\n\tint port;\n\tint slave;\n\tenum mlx4_ib_demux_pv_state state;\n\tint has_smi;\n\tstruct ib_device *ib_dev;\n\tstruct ib_cq *cq;\n\tstruct ib_pd *pd;\n\tstruct work_struct work;\n\tstruct workqueue_struct *wq;\n\tstruct workqueue_struct *wi_wq;\n\tstruct mlx4_ib_demux_pv_qp qp[2];\n};\n\nstruct mlx4_ib_demux_ctx {\n\tstruct ib_device *ib_dev;\n\tint port;\n\tstruct workqueue_struct *wq;\n\tstruct workqueue_struct *wi_wq;\n\tstruct workqueue_struct *ud_wq;\n\tspinlock_t ud_lock;\n\tatomic64_t subnet_prefix;\n\t__be64 guid_cache[128];\n\tstruct mlx4_ib_dev *dev;\n\t \n\tstruct mutex\t\tmcg_table_lock;\n\tstruct rb_root\t\tmcg_table;\n\tstruct list_head\tmcg_mgid0_list;\n\tstruct workqueue_struct\t*mcg_wq;\n\tstruct mlx4_ib_demux_pv_ctx **tun;\n\tatomic_t tid;\n\tint    flushing;  \n};\n\nstruct mlx4_ib_sriov {\n\tstruct mlx4_ib_demux_ctx demux[MLX4_MAX_PORTS];\n\tstruct mlx4_ib_demux_pv_ctx *sqps[MLX4_MAX_PORTS];\n\t \n\tspinlock_t going_down_lock;\n\tint is_going_down;\n\n\tstruct mlx4_sriov_alias_guid alias_guid;\n\n\t \n\tstruct xarray pv_id_table;\n\tu32 pv_id_next;\n\tspinlock_t id_map_lock;\n\tstruct rb_root sl_id_map;\n\tstruct list_head cm_list;\n\tstruct xarray xa_rej_tmout;\n};\n\nstruct gid_cache_context {\n\tint real_index;\n\tint refcount;\n};\n\nstruct gid_entry {\n\tunion ib_gid\tgid;\n\tenum ib_gid_type gid_type;\n\tstruct gid_cache_context *ctx;\n\tu16 vlan_id;\n};\n\nstruct mlx4_port_gid_table {\n\tstruct gid_entry gids[MLX4_MAX_PORT_GIDS];\n};\n\nstruct mlx4_ib_iboe {\n\tspinlock_t\t\tlock;\n\tstruct net_device      *netdevs[MLX4_MAX_PORTS];\n\tatomic64_t\t\tmac[MLX4_MAX_PORTS];\n\tstruct notifier_block \tnb;\n\tstruct mlx4_port_gid_table gids[MLX4_MAX_PORTS];\n\tenum ib_port_state\tlast_port_state[MLX4_MAX_PORTS];\n};\n\nstruct pkey_mgt {\n\tu8\t\t\tvirt2phys_pkey[MLX4_MFUNC_MAX][MLX4_MAX_PORTS][MLX4_MAX_PORT_PKEYS];\n\tu16\t\t\tphys_pkey_cache[MLX4_MAX_PORTS][MLX4_MAX_PORT_PKEYS];\n\tstruct list_head\tpkey_port_list[MLX4_MFUNC_MAX];\n\tstruct kobject\t       *device_parent[MLX4_MFUNC_MAX];\n};\n\nstruct mlx4_ib_iov_sysfs_attr {\n\tvoid *ctx;\n\tstruct kobject *kobj;\n\tunsigned long data;\n\tu32 entry_num;\n\tchar name[15];\n\tstruct device_attribute dentry;\n\tstruct device *dev;\n};\n\nstruct mlx4_ib_iov_sysfs_attr_ar {\n\tstruct mlx4_ib_iov_sysfs_attr dentries[3 * NUM_ALIAS_GUID_PER_PORT + 1];\n};\n\nstruct mlx4_ib_iov_port {\n\tchar name[100];\n\tu8 num;\n\tstruct mlx4_ib_dev *dev;\n\tstruct list_head list;\n\tstruct mlx4_ib_iov_sysfs_attr_ar *dentr_ar;\n\tstruct ib_port_attr attr;\n\tstruct kobject\t*cur_port;\n\tstruct kobject\t*admin_alias_parent;\n\tstruct kobject\t*gids_parent;\n\tstruct kobject\t*pkeys_parent;\n\tstruct kobject\t*mcgs_parent;\n\tstruct mlx4_ib_iov_sysfs_attr mcg_dentry;\n};\n\nstruct counter_index {\n\tstruct  list_head       list;\n\tu32\t\tindex;\n\tu8\t\tallocated;\n};\n\nstruct mlx4_ib_counters {\n\tstruct list_head        counters_list;\n\tstruct mutex            mutex;  \n\tu32\t\t\tdefault_counter;\n};\n\n#define MLX4_DIAG_COUNTERS_TYPES 2\n\nstruct mlx4_ib_diag_counters {\n\tstruct rdma_stat_desc *descs;\n\tu32 *offset;\n\tu32 num_counters;\n};\n\nstruct mlx4_ib_dev {\n\tstruct ib_device\tib_dev;\n\tstruct mlx4_dev\t       *dev;\n\tint\t\t\tnum_ports;\n\tvoid __iomem\t       *uar_map;\n\n\tstruct mlx4_uar\t\tpriv_uar;\n\tu32\t\t\tpriv_pdn;\n\tMLX4_DECLARE_DOORBELL_LOCK(uar_lock);\n\n\tstruct ib_mad_agent    *send_agent[MLX4_MAX_PORTS][2];\n\tstruct ib_ah\t       *sm_ah[MLX4_MAX_PORTS];\n\tspinlock_t\t\tsm_lock;\n\tatomic64_t\t\tsl2vl[MLX4_MAX_PORTS];\n\tstruct mlx4_ib_sriov\tsriov;\n\n\tstruct mutex\t\tcap_mask_mutex;\n\tbool\t\t\tib_active;\n\tstruct mlx4_ib_iboe\tiboe;\n\tstruct mlx4_ib_counters counters_table[MLX4_MAX_PORTS];\n\tint\t\t       *eq_table;\n\tstruct kobject\t       *iov_parent;\n\tstruct kobject\t       *ports_parent;\n\tstruct kobject\t       *dev_ports_parent[MLX4_MFUNC_MAX];\n\tstruct mlx4_ib_iov_port\tiov_ports[MLX4_MAX_PORTS];\n\tstruct pkey_mgt\t\tpkeys;\n\tunsigned long *ib_uc_qpns_bitmap;\n\tint steer_qpn_count;\n\tint steer_qpn_base;\n\tint steering_support;\n\tstruct mlx4_ib_qp      *qp1_proxy[MLX4_MAX_PORTS];\n\t \n\tstruct mutex\t\tqp1_proxy_lock[MLX4_MAX_PORTS];\n\tu8\t\t\tbond_next_port;\n\t \n\tspinlock_t\t\treset_flow_resource_lock;\n\tstruct list_head\t\tqp_list;\n\tstruct mlx4_ib_diag_counters diag_counters[MLX4_DIAG_COUNTERS_TYPES];\n\tstruct notifier_block\tmlx_nb;\n};\n\nstruct ib_event_work {\n\tstruct work_struct\twork;\n\tstruct mlx4_ib_dev\t*ib_dev;\n\tstruct mlx4_eqe\t\tib_eqe;\n\tint\t\t\tport;\n};\n\nstruct mlx4_ib_qp_tunnel_init_attr {\n\tstruct ib_qp_init_attr init_attr;\n\tint slave;\n\tenum ib_qp_type proxy_qp_type;\n\tu32 port;\n};\n\nstruct mlx4_uverbs_ex_query_device {\n\t__u32 comp_mask;\n\t__u32 reserved;\n};\n\nstatic inline struct mlx4_ib_dev *to_mdev(struct ib_device *ibdev)\n{\n\treturn container_of(ibdev, struct mlx4_ib_dev, ib_dev);\n}\n\nstatic inline struct mlx4_ib_ucontext *to_mucontext(struct ib_ucontext *ibucontext)\n{\n\treturn container_of(ibucontext, struct mlx4_ib_ucontext, ibucontext);\n}\n\nstatic inline struct mlx4_ib_pd *to_mpd(struct ib_pd *ibpd)\n{\n\treturn container_of(ibpd, struct mlx4_ib_pd, ibpd);\n}\n\nstatic inline struct mlx4_ib_xrcd *to_mxrcd(struct ib_xrcd *ibxrcd)\n{\n\treturn container_of(ibxrcd, struct mlx4_ib_xrcd, ibxrcd);\n}\n\nstatic inline struct mlx4_ib_cq *to_mcq(struct ib_cq *ibcq)\n{\n\treturn container_of(ibcq, struct mlx4_ib_cq, ibcq);\n}\n\nstatic inline struct mlx4_ib_cq *to_mibcq(struct mlx4_cq *mcq)\n{\n\treturn container_of(mcq, struct mlx4_ib_cq, mcq);\n}\n\nstatic inline struct mlx4_ib_mr *to_mmr(struct ib_mr *ibmr)\n{\n\treturn container_of(ibmr, struct mlx4_ib_mr, ibmr);\n}\n\nstatic inline struct mlx4_ib_mw *to_mmw(struct ib_mw *ibmw)\n{\n\treturn container_of(ibmw, struct mlx4_ib_mw, ibmw);\n}\n\nstatic inline struct mlx4_ib_flow *to_mflow(struct ib_flow *ibflow)\n{\n\treturn container_of(ibflow, struct mlx4_ib_flow, ibflow);\n}\n\nstatic inline struct mlx4_ib_qp *to_mqp(struct ib_qp *ibqp)\n{\n\treturn container_of(ibqp, struct mlx4_ib_qp, ibqp);\n}\n\nstatic inline struct mlx4_ib_qp *to_mibqp(struct mlx4_qp *mqp)\n{\n\treturn container_of(mqp, struct mlx4_ib_qp, mqp);\n}\n\nstatic inline struct mlx4_ib_srq *to_msrq(struct ib_srq *ibsrq)\n{\n\treturn container_of(ibsrq, struct mlx4_ib_srq, ibsrq);\n}\n\nstatic inline struct mlx4_ib_srq *to_mibsrq(struct mlx4_srq *msrq)\n{\n\treturn container_of(msrq, struct mlx4_ib_srq, msrq);\n}\n\nstatic inline struct mlx4_ib_ah *to_mah(struct ib_ah *ibah)\n{\n\treturn container_of(ibah, struct mlx4_ib_ah, ibah);\n}\n\nstatic inline u8 mlx4_ib_bond_next_port(struct mlx4_ib_dev *dev)\n{\n\tdev->bond_next_port = (dev->bond_next_port + 1) % dev->num_ports;\n\n\treturn dev->bond_next_port + 1;\n}\n\nint mlx4_ib_init_sriov(struct mlx4_ib_dev *dev);\nvoid mlx4_ib_close_sriov(struct mlx4_ib_dev *dev);\n\nint mlx4_ib_db_map_user(struct ib_udata *udata, unsigned long virt,\n\t\t\tstruct mlx4_db *db);\nvoid mlx4_ib_db_unmap_user(struct mlx4_ib_ucontext *context, struct mlx4_db *db);\n\nstruct ib_mr *mlx4_ib_get_dma_mr(struct ib_pd *pd, int acc);\nint mlx4_ib_umem_write_mtt(struct mlx4_ib_dev *dev, struct mlx4_mtt *mtt,\n\t\t\t   struct ib_umem *umem);\nstruct ib_mr *mlx4_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,\n\t\t\t\t  u64 virt_addr, int access_flags,\n\t\t\t\t  struct ib_udata *udata);\nint mlx4_ib_dereg_mr(struct ib_mr *mr, struct ib_udata *udata);\nint mlx4_ib_alloc_mw(struct ib_mw *mw, struct ib_udata *udata);\nint mlx4_ib_dealloc_mw(struct ib_mw *mw);\nstruct ib_mr *mlx4_ib_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,\n\t\t\t       u32 max_num_sg);\nint mlx4_ib_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,\n\t\t      unsigned int *sg_offset);\nint mlx4_ib_modify_cq(struct ib_cq *cq, u16 cq_count, u16 cq_period);\nint mlx4_ib_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata);\nint mlx4_ib_create_cq(struct ib_cq *ibcq, const struct ib_cq_init_attr *attr,\n\t\t      struct ib_udata *udata);\nint mlx4_ib_destroy_cq(struct ib_cq *cq, struct ib_udata *udata);\nint mlx4_ib_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc);\nint mlx4_ib_arm_cq(struct ib_cq *cq, enum ib_cq_notify_flags flags);\nvoid __mlx4_ib_cq_clean(struct mlx4_ib_cq *cq, u32 qpn, struct mlx4_ib_srq *srq);\nvoid mlx4_ib_cq_clean(struct mlx4_ib_cq *cq, u32 qpn, struct mlx4_ib_srq *srq);\n\nint mlx4_ib_create_ah(struct ib_ah *ah, struct rdma_ah_init_attr *init_attr,\n\t\t      struct ib_udata *udata);\nint mlx4_ib_create_ah_slave(struct ib_ah *ah, struct rdma_ah_attr *ah_attr,\n\t\t\t    int slave_sgid_index, u8 *s_mac, u16 vlan_tag);\nint mlx4_ib_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);\nstatic inline int mlx4_ib_destroy_ah(struct ib_ah *ah, u32 flags)\n{\n\treturn 0;\n}\n\nint mlx4_ib_create_srq(struct ib_srq *srq, struct ib_srq_init_attr *init_attr,\n\t\t       struct ib_udata *udata);\nint mlx4_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,\n\t\t       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata);\nint mlx4_ib_query_srq(struct ib_srq *srq, struct ib_srq_attr *srq_attr);\nint mlx4_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata);\nvoid mlx4_ib_free_srq_wqe(struct mlx4_ib_srq *srq, int wqe_index);\nint mlx4_ib_post_srq_recv(struct ib_srq *ibsrq, const struct ib_recv_wr *wr,\n\t\t\t  const struct ib_recv_wr **bad_wr);\n\nint mlx4_ib_create_qp(struct ib_qp *qp, struct ib_qp_init_attr *init_attr,\n\t\t      struct ib_udata *udata);\nint mlx4_ib_destroy_qp(struct ib_qp *qp, struct ib_udata *udata);\nvoid mlx4_ib_drain_sq(struct ib_qp *qp);\nvoid mlx4_ib_drain_rq(struct ib_qp *qp);\nint mlx4_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,\n\t\t      int attr_mask, struct ib_udata *udata);\nint mlx4_ib_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *qp_attr, int qp_attr_mask,\n\t\t     struct ib_qp_init_attr *qp_init_attr);\nint mlx4_ib_post_send(struct ib_qp *ibqp, const struct ib_send_wr *wr,\n\t\t      const struct ib_send_wr **bad_wr);\nint mlx4_ib_post_recv(struct ib_qp *ibqp, const struct ib_recv_wr *wr,\n\t\t      const struct ib_recv_wr **bad_wr);\n\nint mlx4_MAD_IFC(struct mlx4_ib_dev *dev, int mad_ifc_flags,\n\t\t int port, const struct ib_wc *in_wc, const struct ib_grh *in_grh,\n\t\t const void *in_mad, void *response_mad);\nint mlx4_ib_process_mad(struct ib_device *ibdev, int mad_flags, u32 port_num,\n\t\t\tconst struct ib_wc *in_wc, const struct ib_grh *in_grh,\n\t\t\tconst struct ib_mad *in, struct ib_mad *out,\n\t\t\tsize_t *out_mad_size, u16 *out_mad_pkey_index);\nint mlx4_ib_mad_init(struct mlx4_ib_dev *dev);\nvoid mlx4_ib_mad_cleanup(struct mlx4_ib_dev *dev);\n\nint __mlx4_ib_query_port(struct ib_device *ibdev, u32 port,\n\t\t\t struct ib_port_attr *props, int netw_view);\nint __mlx4_ib_query_pkey(struct ib_device *ibdev, u32 port, u16 index,\n\t\t\t u16 *pkey, int netw_view);\n\nint __mlx4_ib_query_gid(struct ib_device *ibdev, u32 port, int index,\n\t\t\tunion ib_gid *gid, int netw_view);\n\nstatic inline bool mlx4_ib_ah_grh_present(struct mlx4_ib_ah *ah)\n{\n\tu32 port = be32_to_cpu(ah->av.ib.port_pd) >> 24 & 3;\n\n\tif (rdma_port_get_link_layer(ah->ibah.device, port) == IB_LINK_LAYER_ETHERNET)\n\t\treturn true;\n\n\treturn !!(ah->av.ib.g_slid & 0x80);\n}\n\nint mlx4_ib_mcg_port_init(struct mlx4_ib_demux_ctx *ctx);\nvoid mlx4_ib_mcg_port_cleanup(struct mlx4_ib_demux_ctx *ctx, int destroy_wq);\nvoid clean_vf_mcast(struct mlx4_ib_demux_ctx *ctx, int slave);\nint mlx4_ib_mcg_init(void);\nvoid mlx4_ib_mcg_destroy(void);\n\nint mlx4_ib_find_real_gid(struct ib_device *ibdev, u32 port, __be64 guid);\n\nint mlx4_ib_mcg_multiplex_handler(struct ib_device *ibdev, int port, int slave,\n\t\t\t\t  struct ib_sa_mad *sa_mad);\nint mlx4_ib_mcg_demux_handler(struct ib_device *ibdev, int port, int slave,\n\t\t\t      struct ib_sa_mad *mad);\n\nint mlx4_ib_add_mc(struct mlx4_ib_dev *mdev, struct mlx4_ib_qp *mqp,\n\t\t   union ib_gid *gid);\n\nvoid mlx4_ib_dispatch_event(struct mlx4_ib_dev *dev, u32 port_num,\n\t\t\t    enum ib_event_type type);\n\nvoid mlx4_ib_tunnels_update_work(struct work_struct *work);\n\nint mlx4_ib_send_to_slave(struct mlx4_ib_dev *dev, int slave, u32 port,\n\t\t\t  enum ib_qp_type qpt, struct ib_wc *wc,\n\t\t\t  struct ib_grh *grh, struct ib_mad *mad);\n\nint mlx4_ib_send_to_wire(struct mlx4_ib_dev *dev, int slave, u32 port,\n\t\t\t enum ib_qp_type dest_qpt, u16 pkey_index, u32 remote_qpn,\n\t\t\t u32 qkey, struct rdma_ah_attr *attr, u8 *s_mac,\n\t\t\t u16 vlan_id, struct ib_mad *mad);\n\n__be64 mlx4_ib_get_new_demux_tid(struct mlx4_ib_demux_ctx *ctx);\n\nint mlx4_ib_demux_cm_handler(struct ib_device *ibdev, int port, int *slave,\n\t\tstruct ib_mad *mad);\n\nint mlx4_ib_multiplex_cm_handler(struct ib_device *ibdev, int port, int slave_id,\n\t\tstruct ib_mad *mad);\n\nvoid mlx4_ib_cm_paravirt_init(struct mlx4_ib_dev *dev);\nvoid mlx4_ib_cm_paravirt_clean(struct mlx4_ib_dev *dev, int slave_id);\n\n \nvoid mlx4_ib_init_alias_guid_work(struct mlx4_ib_dev *dev, int port);\nint mlx4_ib_init_alias_guid_service(struct mlx4_ib_dev *dev);\nvoid mlx4_ib_destroy_alias_guid_service(struct mlx4_ib_dev *dev);\nvoid mlx4_ib_invalidate_all_guid_record(struct mlx4_ib_dev *dev, int port);\n\nvoid mlx4_ib_notify_slaves_on_guid_change(struct mlx4_ib_dev *dev,\n\t\t\t\t\t  int block_num,\n\t\t\t\t\t  u32 port_num, u8 *p_data);\n\nvoid mlx4_ib_update_cache_on_guid_change(struct mlx4_ib_dev *dev,\n\t\t\t\t\t int block_num, u32 port_num,\n\t\t\t\t\t u8 *p_data);\n\nint add_sysfs_port_mcg_attr(struct mlx4_ib_dev *device, int port_num,\n\t\t\t    struct attribute *attr);\nvoid del_sysfs_port_mcg_attr(struct mlx4_ib_dev *device, int port_num,\n\t\t\t     struct attribute *attr);\nib_sa_comp_mask mlx4_ib_get_aguid_comp_mask_from_ix(int index);\nvoid mlx4_ib_slave_alias_guid_event(struct mlx4_ib_dev *dev, int slave,\n\t\t\t\t    int port, int slave_init);\n\nint mlx4_ib_device_register_sysfs(struct mlx4_ib_dev *device) ;\n\nvoid mlx4_ib_device_unregister_sysfs(struct mlx4_ib_dev *device);\n\n__be64 mlx4_ib_gen_node_guid(void);\n\nint mlx4_ib_steer_qp_alloc(struct mlx4_ib_dev *dev, int count, int *qpn);\nvoid mlx4_ib_steer_qp_free(struct mlx4_ib_dev *dev, u32 qpn, int count);\nint mlx4_ib_steer_qp_reg(struct mlx4_ib_dev *mdev, struct mlx4_ib_qp *mqp,\n\t\t\t int is_attach);\nstruct ib_mr *mlx4_ib_rereg_user_mr(struct ib_mr *mr, int flags, u64 start,\n\t\t\t\t    u64 length, u64 virt_addr,\n\t\t\t\t    int mr_access_flags, struct ib_pd *pd,\n\t\t\t\t    struct ib_udata *udata);\nint mlx4_ib_gid_index_to_real_index(struct mlx4_ib_dev *ibdev,\n\t\t\t\t    const struct ib_gid_attr *attr);\n\nvoid mlx4_sched_ib_sl2vl_update_work(struct mlx4_ib_dev *ibdev,\n\t\t\t\t     int port);\n\nvoid mlx4_ib_sl2vl_update(struct mlx4_ib_dev *mdev, int port);\n\nstruct ib_wq *mlx4_ib_create_wq(struct ib_pd *pd,\n\t\t\t\tstruct ib_wq_init_attr *init_attr,\n\t\t\t\tstruct ib_udata *udata);\nint mlx4_ib_destroy_wq(struct ib_wq *wq, struct ib_udata *udata);\nint mlx4_ib_modify_wq(struct ib_wq *wq, struct ib_wq_attr *wq_attr,\n\t\t      u32 wq_attr_mask, struct ib_udata *udata);\n\nint mlx4_ib_create_rwq_ind_table(struct ib_rwq_ind_table *ib_rwq_ind_tbl,\n\t\t\t\t struct ib_rwq_ind_table_init_attr *init_attr,\n\t\t\t\t struct ib_udata *udata);\nstatic inline int\nmlx4_ib_destroy_rwq_ind_table(struct ib_rwq_ind_table *wq_ind_table)\n{\n\treturn 0;\n}\nint mlx4_ib_umem_calc_optimal_mtt_size(struct ib_umem *umem, u64 start_va,\n\t\t\t\t       int *num_of_mtts);\n\nint mlx4_ib_cm_init(void);\nvoid mlx4_ib_cm_destroy(void);\n\nint mlx4_ib_qp_event_init(void);\nvoid mlx4_ib_qp_event_cleanup(void);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}