{
  "module_name": "qib_verbs.h",
  "hash_id": "fc4f99ce2f9f7c73d7d3e2bb801e776786cc3e0026bac8ede9c31e8005e46c64",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/qib/qib_verbs.h",
  "human_readable_source": " \n\n#ifndef QIB_VERBS_H\n#define QIB_VERBS_H\n\n#include <linux/types.h>\n#include <linux/spinlock.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/kref.h>\n#include <linux/workqueue.h>\n#include <linux/kthread.h>\n#include <linux/completion.h>\n#include <rdma/ib_pack.h>\n#include <rdma/ib_user_verbs.h>\n#include <rdma/ib_hdrs.h>\n#include <rdma/rdmavt_qp.h>\n#include <rdma/rdmavt_cq.h>\n\nstruct qib_ctxtdata;\nstruct qib_pportdata;\nstruct qib_devdata;\nstruct qib_verbs_txreq;\n\n#define QIB_MAX_RDMA_ATOMIC     16\n#define QIB_GUIDS_PER_PORT\t5\n#define QIB_PSN_SHIFT\t\t8\n\n \n#define QIB_UVERBS_ABI_VERSION       2\n\n \n#define IB_PMA_SAMPLE_STATUS_DONE       0x00\n#define IB_PMA_SAMPLE_STATUS_STARTED    0x01\n#define IB_PMA_SAMPLE_STATUS_RUNNING    0x02\n\n \n#define IB_PMA_PORT_XMIT_DATA   cpu_to_be16(0x0001)\n#define IB_PMA_PORT_RCV_DATA    cpu_to_be16(0x0002)\n#define IB_PMA_PORT_XMIT_PKTS   cpu_to_be16(0x0003)\n#define IB_PMA_PORT_RCV_PKTS    cpu_to_be16(0x0004)\n#define IB_PMA_PORT_XMIT_WAIT   cpu_to_be16(0x0005)\n\n#define QIB_VENDOR_IPG\t\tcpu_to_be16(0xFFA0)\n\n#define IB_DEFAULT_GID_PREFIX\tcpu_to_be64(0xfe80000000000000ULL)\n\n \n#define IB_VL_VL0       1\n#define IB_VL_VL0_1     2\n#define IB_VL_VL0_3     3\n#define IB_VL_VL0_7     4\n#define IB_VL_VL0_14    5\n\nstatic inline int qib_num_vls(int vls)\n{\n\tswitch (vls) {\n\tdefault:\n\tcase IB_VL_VL0:\n\t\treturn 1;\n\tcase IB_VL_VL0_1:\n\t\treturn 2;\n\tcase IB_VL_VL0_3:\n\t\treturn 4;\n\tcase IB_VL_VL0_7:\n\t\treturn 8;\n\tcase IB_VL_VL0_14:\n\t\treturn 15;\n\t}\n}\n\nstruct qib_pio_header {\n\t__le32 pbc[2];\n\tstruct ib_header hdr;\n} __packed;\n\n \nstruct qib_qp_priv {\n\tstruct ib_header *s_hdr;         \n\tstruct list_head iowait;         \n\tatomic_t s_dma_busy;\n\tstruct qib_verbs_txreq *s_tx;\n\tstruct work_struct s_work;\n\twait_queue_head_t wait_dma;\n\tstruct rvt_qp *owner;\n};\n\n#define QIB_PSN_CREDIT  16\n\nstruct qib_opcode_stats {\n\tu64 n_packets;           \n\tu64 n_bytes;             \n};\n\nstruct qib_opcode_stats_perctx {\n\tstruct qib_opcode_stats stats[128];\n};\n\nstruct qib_pma_counters {\n\tu64 n_unicast_xmit;      \n\tu64 n_unicast_rcv;       \n\tu64 n_multicast_xmit;    \n\tu64 n_multicast_rcv;     \n};\n\nstruct qib_ibport {\n\tstruct rvt_ibport rvp;\n\tstruct rvt_ah *smi_ah;\n\t__be64 guids[QIB_GUIDS_PER_PORT\t- 1];\t \n\tstruct qib_pma_counters __percpu *pmastats;\n\tu64 z_unicast_xmit;      \n\tu64 z_unicast_rcv;       \n\tu64 z_multicast_xmit;    \n\tu64 z_multicast_rcv;     \n\tu64 z_symbol_error_counter;              \n\tu64 z_link_error_recovery_counter;       \n\tu64 z_link_downed_counter;               \n\tu64 z_port_rcv_errors;                   \n\tu64 z_port_rcv_remphys_errors;           \n\tu64 z_port_xmit_discards;                \n\tu64 z_port_xmit_data;                    \n\tu64 z_port_rcv_data;                     \n\tu64 z_port_xmit_packets;                 \n\tu64 z_port_rcv_packets;                  \n\tu32 z_local_link_integrity_errors;       \n\tu32 z_excessive_buffer_overrun_errors;   \n\tu32 z_vl15_dropped;                      \n\tu8 sl_to_vl[16];\n};\n\nstruct qib_ibdev {\n\tstruct rvt_dev_info rdi;\n\n\tstruct list_head piowait;        \n\tstruct list_head dmawait;\t \n\tstruct list_head txwait;         \n\tstruct list_head memwait;        \n\tstruct list_head txreq_free;\n\tstruct timer_list mem_timer;\n\tstruct qib_pio_header *pio_hdrs;\n\tdma_addr_t pio_hdrs_phys;\n\n\tu32 n_piowait;\n\tu32 n_txwait;\n\n#ifdef CONFIG_DEBUG_FS\n\t \n\tstruct dentry *qib_ibdev_dbg;\n#endif\n};\n\nstruct qib_verbs_counters {\n\tu64 symbol_error_counter;\n\tu64 link_error_recovery_counter;\n\tu64 link_downed_counter;\n\tu64 port_rcv_errors;\n\tu64 port_rcv_remphys_errors;\n\tu64 port_xmit_discards;\n\tu64 port_xmit_data;\n\tu64 port_rcv_data;\n\tu64 port_xmit_packets;\n\tu64 port_rcv_packets;\n\tu32 local_link_integrity_errors;\n\tu32 excessive_buffer_overrun_errors;\n\tu32 vl15_dropped;\n};\n\nstatic inline struct qib_ibdev *to_idev(struct ib_device *ibdev)\n{\n\tstruct rvt_dev_info *rdi;\n\n\trdi = container_of(ibdev, struct rvt_dev_info, ibdev);\n\treturn container_of(rdi, struct qib_ibdev, rdi);\n}\n\n \nstatic inline int qib_send_ok(struct rvt_qp *qp)\n{\n\treturn !(qp->s_flags & (RVT_S_BUSY | RVT_S_ANY_WAIT_IO)) &&\n\t\t(qp->s_hdrwords || (qp->s_flags & RVT_S_RESP_PENDING) ||\n\t\t !(qp->s_flags & RVT_S_ANY_WAIT_SEND));\n}\n\nbool _qib_schedule_send(struct rvt_qp *qp);\nbool qib_schedule_send(struct rvt_qp *qp);\n\nstatic inline int qib_pkey_ok(u16 pkey1, u16 pkey2)\n{\n\tu16 p1 = pkey1 & 0x7FFF;\n\tu16 p2 = pkey2 & 0x7FFF;\n\n\t \n\treturn p1 && p1 == p2 && ((__s16)pkey1 < 0 || (__s16)pkey2 < 0);\n}\n\nvoid qib_bad_pkey(struct qib_ibport *ibp, u32 key, u32 sl,\n\t\t  u32 qp1, u32 qp2, __be16 lid1, __be16 lid2);\nvoid qib_cap_mask_chg(struct rvt_dev_info *rdi, u32 port_num);\nvoid qib_sys_guid_chg(struct qib_ibport *ibp);\nvoid qib_node_desc_chg(struct qib_ibport *ibp);\nint qib_process_mad(struct ib_device *ibdev, int mad_flags, u32 port_num,\n\t\t    const struct ib_wc *in_wc, const struct ib_grh *in_grh,\n\t\t    const struct ib_mad *in, struct ib_mad *out,\n\t\t    size_t *out_mad_size, u16 *out_mad_pkey_index);\nvoid qib_notify_create_mad_agent(struct rvt_dev_info *rdi, int port_idx);\nvoid qib_notify_free_mad_agent(struct rvt_dev_info *rdi, int port_idx);\n\n \nstatic inline int qib_cmp24(u32 a, u32 b)\n{\n\treturn (((int) a) - ((int) b)) << 8;\n}\n\nint qib_snapshot_counters(struct qib_pportdata *ppd, u64 *swords,\n\t\t\t  u64 *rwords, u64 *spkts, u64 *rpkts,\n\t\t\t  u64 *xmit_wait);\n\nint qib_get_counters(struct qib_pportdata *ppd,\n\t\t     struct qib_verbs_counters *cntrs);\n\n \nunsigned qib_free_all_qps(struct rvt_dev_info *rdi);\nvoid *qib_qp_priv_alloc(struct rvt_dev_info *rdi, struct rvt_qp *qp);\nvoid qib_qp_priv_free(struct rvt_dev_info *rdi, struct rvt_qp *qp);\nvoid qib_notify_qp_reset(struct rvt_qp *qp);\nint qib_alloc_qpn(struct rvt_dev_info *rdi, struct rvt_qpn_table *qpt,\n\t\t  enum ib_qp_type type, u32 port);\nvoid qib_restart_rc(struct rvt_qp *qp, u32 psn, int wait);\n#ifdef CONFIG_DEBUG_FS\n\nvoid qib_qp_iter_print(struct seq_file *s, struct rvt_qp_iter *iter);\n\n#endif\n\nunsigned qib_pkt_delay(u32 plen, u8 snd_mult, u8 rcv_mult);\n\nvoid qib_verbs_sdma_desc_avail(struct qib_pportdata *ppd, unsigned avail);\n\nvoid qib_put_txreq(struct qib_verbs_txreq *tx);\n\nint qib_verbs_send(struct rvt_qp *qp, struct ib_header *hdr,\n\t\t   u32 hdrwords, struct rvt_sge_state *ss, u32 len);\n\nvoid qib_uc_rcv(struct qib_ibport *ibp, struct ib_header *hdr,\n\t\tint has_grh, void *data, u32 tlen, struct rvt_qp *qp);\n\nvoid qib_rc_rcv(struct qib_ctxtdata *rcd, struct ib_header *hdr,\n\t\tint has_grh, void *data, u32 tlen, struct rvt_qp *qp);\n\nint qib_check_ah(struct ib_device *ibdev, struct rdma_ah_attr *ah_attr);\n\nint qib_check_send_wqe(struct rvt_qp *qp, struct rvt_swqe *wqe,\n\t\t       bool *call_send);\n\nstruct ib_ah *qib_create_qp0_ah(struct qib_ibport *ibp, u16 dlid);\n\nvoid qib_rc_rnr_retry(unsigned long arg);\n\nvoid qib_rc_send_complete(struct rvt_qp *qp, struct ib_header *hdr);\n\nint qib_post_ud_send(struct rvt_qp *qp, const struct ib_send_wr *wr);\n\nvoid qib_ud_rcv(struct qib_ibport *ibp, struct ib_header *hdr,\n\t\tint has_grh, void *data, u32 tlen, struct rvt_qp *qp);\n\nvoid mr_rcu_callback(struct rcu_head *list);\n\nvoid qib_migrate_qp(struct rvt_qp *qp);\n\nint qib_ruc_check_hdr(struct qib_ibport *ibp, struct ib_header *hdr,\n\t\t      int has_grh, struct rvt_qp *qp, u32 bth0);\n\nu32 qib_make_grh(struct qib_ibport *ibp, struct ib_grh *hdr,\n\t\t const struct ib_global_route *grh, u32 hwords, u32 nwords);\n\nvoid qib_make_ruc_header(struct rvt_qp *qp, struct ib_other_headers *ohdr,\n\t\t\t u32 bth0, u32 bth2);\n\nvoid _qib_do_send(struct work_struct *work);\n\nvoid qib_do_send(struct rvt_qp *qp);\n\nvoid qib_send_rc_ack(struct rvt_qp *qp);\n\nint qib_make_rc_req(struct rvt_qp *qp, unsigned long *flags);\n\nint qib_make_uc_req(struct rvt_qp *qp, unsigned long *flags);\n\nint qib_make_ud_req(struct rvt_qp *qp, unsigned long *flags);\n\nint qib_register_ib_device(struct qib_devdata *);\n\nvoid qib_unregister_ib_device(struct qib_devdata *);\n\nvoid qib_ib_rcv(struct qib_ctxtdata *, void *, void *, u32);\n\nvoid qib_ib_piobufavail(struct qib_devdata *);\n\nunsigned qib_get_npkeys(struct qib_devdata *);\n\nunsigned qib_get_pkey(struct qib_ibport *, unsigned);\n\nextern const enum ib_wc_opcode ib_qib_wc_opcode[];\n\n \n#define IB_PHYSPORTSTATE_SLEEP 1\n#define IB_PHYSPORTSTATE_POLL 2\n#define IB_PHYSPORTSTATE_DISABLED 3\n#define IB_PHYSPORTSTATE_CFG_TRAIN 4\n#define IB_PHYSPORTSTATE_LINKUP 5\n#define IB_PHYSPORTSTATE_LINK_ERR_RECOVER 6\n#define IB_PHYSPORTSTATE_CFG_DEBOUNCE 8\n#define IB_PHYSPORTSTATE_CFG_IDLE 0xB\n#define IB_PHYSPORTSTATE_RECOVERY_RETRAIN 0xC\n#define IB_PHYSPORTSTATE_RECOVERY_WAITRMT 0xE\n#define IB_PHYSPORTSTATE_RECOVERY_IDLE 0xF\n#define IB_PHYSPORTSTATE_CFG_ENH 0x10\n#define IB_PHYSPORTSTATE_CFG_WAIT_ENH 0x13\n\nextern const int ib_rvt_state_ops[];\n\nextern __be64 ib_qib_sys_image_guid;     \n\nextern unsigned int ib_rvt_lkey_table_size;\n\nextern unsigned int ib_qib_max_cqes;\n\nextern unsigned int ib_qib_max_cqs;\n\nextern unsigned int ib_qib_max_qp_wrs;\n\nextern unsigned int ib_qib_max_qps;\n\nextern unsigned int ib_qib_max_sges;\n\nextern unsigned int ib_qib_max_mcast_grps;\n\nextern unsigned int ib_qib_max_mcast_qp_attached;\n\nextern unsigned int ib_qib_max_srqs;\n\nextern unsigned int ib_qib_max_srq_sges;\n\nextern unsigned int ib_qib_max_srq_wrs;\n\nextern const u32 ib_qib_rnr_table[];\n\nextern const struct rvt_operation_params qib_post_parms[];\n\n#endif                           \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}