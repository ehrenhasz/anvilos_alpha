{
  "module_name": "qib.h",
  "hash_id": "3db7dd8560fd36111d7c120b9cdbe831c0a1566454803880baea4d6ad89aa878",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/qib/qib.h",
  "human_readable_source": "#ifndef _QIB_KERNEL_H\n#define _QIB_KERNEL_H\n \n\n \n\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/dma-mapping.h>\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/io.h>\n#include <linux/fs.h>\n#include <linux/completion.h>\n#include <linux/kref.h>\n#include <linux/sched.h>\n#include <linux/kthread.h>\n#include <linux/xarray.h>\n#include <rdma/ib_hdrs.h>\n#include <rdma/rdma_vt.h>\n\n#include \"qib_common.h\"\n#include \"qib_verbs.h\"\n\n \n#define QIB_CHIP_VERS_MAJ 2U\n\n \n#define QIB_CHIP_VERS_MIN 0U\n\n \n#define QIB_OUI 0x001175\n#define QIB_OUI_LSB 40\n\n \nstruct qlogic_ib_stats {\n\t__u64 sps_ints;  \n\t__u64 sps_errints;  \n\t__u64 sps_txerrs;  \n\t__u64 sps_rcverrs;  \n\t__u64 sps_hwerrs;  \n\t__u64 sps_nopiobufs;  \n\t__u64 sps_ctxts;  \n\t__u64 sps_lenerrs;  \n\t__u64 sps_buffull;\n\t__u64 sps_hdrfull;\n};\n\nextern struct qlogic_ib_stats qib_stats;\nextern const struct pci_error_handlers qib_pci_err_handler;\n\n#define QIB_CHIP_SWVERSION QIB_CHIP_VERS_MAJ\n \n#define QIB_TRAFFIC_ACTIVE_THRESHOLD (2000)\n\n \n\n#ifdef CONFIG_DEBUG_FS\nstruct qib_opcode_stats_perctx;\n#endif\n\nstruct qib_ctxtdata {\n\tvoid **rcvegrbuf;\n\tdma_addr_t *rcvegrbuf_phys;\n\t \n\tvoid *rcvhdrq;\n\t \n\tvoid *rcvhdrtail_kvaddr;\n\t \n\tvoid *tid_pg_list;\n\t \n\tunsigned long *user_event_mask;\n\t \n\twait_queue_head_t wait;\n\t \n\tdma_addr_t rcvegr_phys;\n\t \n\tdma_addr_t rcvhdrq_phys;\n\tdma_addr_t rcvhdrqtailaddr_phys;\n\n\t \n\tint cnt;\n\t \n\t \n\tunsigned ctxt;\n\t \n\tint node_id;\n\t \n\tu16 subctxt_cnt;\n\t \n\tu16 subctxt_id;\n\t \n\tu16 rcvegrcnt;\n\t \n\tu16 rcvegr_tid_base;\n\t \n\tu32 piocnt;\n\t \n\tu32 pio_base;\n\t \n\tu32 piobufs;\n\t \n\tu32 rcvegrbuf_chunks;\n\t \n\tu16 rcvegrbufs_perchunk;\n\t \n\tu16 rcvegrbufs_perchunk_shift;\n\t \n\tsize_t rcvegrbuf_size;\n\t \n\tsize_t rcvhdrq_size;\n\t \n\tunsigned long flag;\n\t \n\tu32 tidcursor;\n\t \n\tu32 rcvwait_to;\n\t \n\tu32 piowait_to;\n\t \n\tu32 rcvnowait;\n\t \n\tu32 pionowait;\n\t \n\tu32 urgent;\n\t \n\tu32 urgent_poll;\n\t \n\tpid_t pid;\n\tpid_t subpid[QLOGIC_IB_MAX_SUBCTXT];\n\t \n\tchar comm[TASK_COMM_LEN];\n\t \n\tu16 pkeys[4];\n\t \n\tstruct qib_devdata *dd;\n\t \n\tstruct qib_pportdata *ppd;\n\t \n\tvoid *subctxt_uregbase;\n\t \n\tvoid *subctxt_rcvegrbuf;\n\t \n\tvoid *subctxt_rcvhdr_base;\n\t \n\tu32 userversion;\n\t \n\tu32 active_slaves;\n\t \n\tu16 poll_type;\n\t \n\tu8 seq_cnt;\n\tu8 redirect_seq_cnt;\n\t \n\tu32 head;\n\t \n\tstruct list_head qp_wait_list;\n#ifdef CONFIG_DEBUG_FS\n\t \n\tstruct qib_opcode_stats_perctx *opstats;\n#endif\n};\n\nstruct rvt_sge_state;\n\nstruct qib_sdma_txreq {\n\tint                 flags;\n\tint                 sg_count;\n\tdma_addr_t          addr;\n\tvoid              (*callback)(struct qib_sdma_txreq *, int);\n\tu16                 start_idx;   \n\tu16                 next_descq_idx;   \n\tstruct list_head    list;        \n};\n\nstruct qib_sdma_desc {\n\t__le64 qw[2];\n};\n\nstruct qib_verbs_txreq {\n\tstruct qib_sdma_txreq   txreq;\n\tstruct rvt_qp           *qp;\n\tstruct rvt_swqe         *wqe;\n\tu32                     dwords;\n\tu16                     hdr_dwords;\n\tu16                     hdr_inx;\n\tstruct qib_pio_header\t*align_buf;\n\tstruct rvt_mregion\t*mr;\n\tstruct rvt_sge_state    *ss;\n};\n\n#define QIB_SDMA_TXREQ_F_USELARGEBUF  0x1\n#define QIB_SDMA_TXREQ_F_HEADTOHOST   0x2\n#define QIB_SDMA_TXREQ_F_INTREQ       0x4\n#define QIB_SDMA_TXREQ_F_FREEBUF      0x8\n#define QIB_SDMA_TXREQ_F_FREEDESC     0x10\n\n#define QIB_SDMA_TXREQ_S_OK        0\n#define QIB_SDMA_TXREQ_S_SENDERROR 1\n#define QIB_SDMA_TXREQ_S_ABORTED   2\n#define QIB_SDMA_TXREQ_S_SHUTDOWN  3\n\n \n#define QIB_IB_CFG_LIDLMC 0  \n#define QIB_IB_CFG_LWID_ENB 2  \n#define QIB_IB_CFG_LWID 3  \n#define QIB_IB_CFG_SPD_ENB 4  \n#define QIB_IB_CFG_SPD 5  \n#define QIB_IB_CFG_RXPOL_ENB 6  \n#define QIB_IB_CFG_LREV_ENB 7  \n#define QIB_IB_CFG_LINKLATENCY 8  \n#define QIB_IB_CFG_HRTBT 9  \n#define QIB_IB_CFG_OP_VLS 10  \n#define QIB_IB_CFG_VL_HIGH_CAP 11  \n#define QIB_IB_CFG_VL_LOW_CAP 12  \n#define QIB_IB_CFG_OVERRUN_THRESH 13  \n#define QIB_IB_CFG_PHYERR_THRESH 14  \n#define QIB_IB_CFG_LINKDEFAULT 15  \n#define QIB_IB_CFG_PKEYS 16  \n#define QIB_IB_CFG_MTU 17  \n#define QIB_IB_CFG_LSTATE 18  \n#define QIB_IB_CFG_VL_HIGH_LIMIT 19\n#define QIB_IB_CFG_PMA_TICKS 20  \n#define QIB_IB_CFG_PORT 21  \n\n \n#define   IB_LINKCMD_DOWN   (0 << 16)\n#define   IB_LINKCMD_ARMED  (1 << 16)\n#define   IB_LINKCMD_ACTIVE (2 << 16)\n#define   IB_LINKINITCMD_NOP     0\n#define   IB_LINKINITCMD_POLL    1\n#define   IB_LINKINITCMD_SLEEP   2\n#define   IB_LINKINITCMD_DISABLE 3\n\n \n#define QIB_IB_LINKDOWN         0\n#define QIB_IB_LINKARM          1\n#define QIB_IB_LINKACTIVE       2\n#define QIB_IB_LINKDOWN_ONLY    3\n#define QIB_IB_LINKDOWN_SLEEP   4\n#define QIB_IB_LINKDOWN_DISABLE 5\n\n \n#define QIB_IB_SDR 1\n#define QIB_IB_DDR 2\n#define QIB_IB_QDR 4\n\n#define QIB_DEFAULT_MTU 4096\n\n \n#define QIB_MAX_IB_PORTS 2\n\n \n#define QIB_IB_TBL_VL_HIGH_ARB 1  \n#define QIB_IB_TBL_VL_LOW_ARB 2  \n\n \n#define QIB_RCVCTRL_TAILUPD_ENB 0x01\n#define QIB_RCVCTRL_TAILUPD_DIS 0x02\n#define QIB_RCVCTRL_CTXT_ENB 0x04\n#define QIB_RCVCTRL_CTXT_DIS 0x08\n#define QIB_RCVCTRL_INTRAVAIL_ENB 0x10\n#define QIB_RCVCTRL_INTRAVAIL_DIS 0x20\n#define QIB_RCVCTRL_PKEY_ENB 0x40   \n#define QIB_RCVCTRL_PKEY_DIS 0x80\n#define QIB_RCVCTRL_BP_ENB 0x0100\n#define QIB_RCVCTRL_BP_DIS 0x0200\n#define QIB_RCVCTRL_TIDFLOW_ENB 0x0400\n#define QIB_RCVCTRL_TIDFLOW_DIS 0x0800\n\n \n#define QIB_SENDCTRL_DISARM       (0x1000)\n#define QIB_SENDCTRL_DISARM_BUF(bufn) ((bufn) | QIB_SENDCTRL_DISARM)\n\t \n#define QIB_SENDCTRL_AVAIL_DIS    (0x4000)\n#define QIB_SENDCTRL_AVAIL_ENB    (0x8000)\n#define QIB_SENDCTRL_AVAIL_BLIP  (0x10000)\n#define QIB_SENDCTRL_SEND_DIS    (0x20000)\n#define QIB_SENDCTRL_SEND_ENB    (0x40000)\n#define QIB_SENDCTRL_FLUSH       (0x80000)\n#define QIB_SENDCTRL_CLEAR      (0x100000)\n#define QIB_SENDCTRL_DISARM_ALL (0x200000)\n\n \n \n#define QIBPORTCNTR_PKTSEND         0U\n#define QIBPORTCNTR_WORDSEND        1U\n#define QIBPORTCNTR_PSXMITDATA      2U\n#define QIBPORTCNTR_PSXMITPKTS      3U\n#define QIBPORTCNTR_PSXMITWAIT      4U\n#define QIBPORTCNTR_SENDSTALL       5U\n \n#define QIBPORTCNTR_PKTRCV          6U\n#define QIBPORTCNTR_PSRCVDATA       7U\n#define QIBPORTCNTR_PSRCVPKTS       8U\n#define QIBPORTCNTR_RCVEBP          9U\n#define QIBPORTCNTR_RCVOVFL         10U\n#define QIBPORTCNTR_WORDRCV         11U\n \n#define QIBPORTCNTR_RXLOCALPHYERR   12U\n#define QIBPORTCNTR_RXVLERR         13U\n#define QIBPORTCNTR_ERRICRC         14U\n#define QIBPORTCNTR_ERRVCRC         15U\n#define QIBPORTCNTR_ERRLPCRC        16U\n#define QIBPORTCNTR_BADFORMAT       17U\n#define QIBPORTCNTR_ERR_RLEN        18U\n#define QIBPORTCNTR_IBSYMBOLERR     19U\n#define QIBPORTCNTR_INVALIDRLEN     20U\n#define QIBPORTCNTR_UNSUPVL         21U\n#define QIBPORTCNTR_EXCESSBUFOVFL   22U\n#define QIBPORTCNTR_ERRLINK         23U\n#define QIBPORTCNTR_IBLINKDOWN      24U\n#define QIBPORTCNTR_IBLINKERRRECOV  25U\n#define QIBPORTCNTR_LLI             26U\n \n#define QIBPORTCNTR_RXDROPPKT       27U\n#define QIBPORTCNTR_VL15PKTDROP     28U\n#define QIBPORTCNTR_ERRPKEY         29U\n#define QIBPORTCNTR_KHDROVFL        30U\n \n#define QIBPORTCNTR_PSINTERVAL      31U\n#define QIBPORTCNTR_PSSTART         32U\n#define QIBPORTCNTR_PSSTAT          33U\n\n \n#define ACTIVITY_TIMER 5\n\n#define MAX_NAME_SIZE 64\n\n#ifdef CONFIG_INFINIBAND_QIB_DCA\nstruct qib_irq_notify;\n#endif\n\nstruct qib_msix_entry {\n\tvoid *arg;\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\tint dca;\n\tint rcv;\n\tstruct qib_irq_notify *notifier;\n#endif\n\tcpumask_var_t mask;\n};\n\n \nstruct qib_chip_specific;\nstruct qib_chipport_specific;\n\nenum qib_sdma_states {\n\tqib_sdma_state_s00_hw_down,\n\tqib_sdma_state_s10_hw_start_up_wait,\n\tqib_sdma_state_s20_idle,\n\tqib_sdma_state_s30_sw_clean_up_wait,\n\tqib_sdma_state_s40_hw_clean_up_wait,\n\tqib_sdma_state_s50_hw_halt_wait,\n\tqib_sdma_state_s99_running,\n};\n\nenum qib_sdma_events {\n\tqib_sdma_event_e00_go_hw_down,\n\tqib_sdma_event_e10_go_hw_start,\n\tqib_sdma_event_e20_hw_started,\n\tqib_sdma_event_e30_go_running,\n\tqib_sdma_event_e40_sw_cleaned,\n\tqib_sdma_event_e50_hw_cleaned,\n\tqib_sdma_event_e60_hw_halted,\n\tqib_sdma_event_e70_go_idle,\n\tqib_sdma_event_e7220_err_halted,\n\tqib_sdma_event_e7322_err_halted,\n\tqib_sdma_event_e90_timer_tick,\n};\n\nstruct sdma_set_state_action {\n\tunsigned op_enable:1;\n\tunsigned op_intenable:1;\n\tunsigned op_halt:1;\n\tunsigned op_drain:1;\n\tunsigned go_s99_running_tofalse:1;\n\tunsigned go_s99_running_totrue:1;\n};\n\nstruct qib_sdma_state {\n\tstruct kref          kref;\n\tstruct completion    comp;\n\tenum qib_sdma_states current_state;\n\tstruct sdma_set_state_action *set_state_action;\n\tunsigned             current_op;\n\tunsigned             go_s99_running;\n\tunsigned             first_sendbuf;\n\tunsigned             last_sendbuf;  \n\t \n\tenum qib_sdma_states previous_state;\n\tunsigned             previous_op;\n\tenum qib_sdma_events last_event;\n};\n\nstruct xmit_wait {\n\tstruct timer_list timer;\n\tu64 counter;\n\tu8 flags;\n\tstruct cache {\n\t\tu64 psxmitdata;\n\t\tu64 psrcvdata;\n\t\tu64 psxmitpkts;\n\t\tu64 psrcvpkts;\n\t\tu64 psxmitwait;\n\t} counter_cache;\n};\n\n \nstruct qib_pportdata {\n\tstruct qib_ibport ibport_data;\n\n\tstruct qib_devdata *dd;\n\tstruct qib_chippport_specific *cpspec;  \n\n\t \n\t__be64 guid;\n\n\t \n\tu32 lflags;\n\t \n\tu32 state_wanted;\n\tspinlock_t lflags_lock;\n\n\t \n\tatomic_t pkeyrefs[4];\n\n\t \n\tu64 *statusp;\n\n\t \n\n\t \n\tstruct qib_sdma_desc *sdma_descq;\n\tstruct workqueue_struct *qib_wq;\n\tstruct qib_sdma_state sdma_state;\n\tdma_addr_t       sdma_descq_phys;\n\tvolatile __le64 *sdma_head_dma;  \n\tdma_addr_t       sdma_head_phys;\n\tu16                   sdma_descq_cnt;\n\n\t \n\tspinlock_t            sdma_lock ____cacheline_aligned_in_smp;\n\tstruct list_head      sdma_activelist;\n\tstruct list_head      sdma_userpending;\n\tu64                   sdma_descq_added;\n\tu64                   sdma_descq_removed;\n\tu16                   sdma_descq_tail;\n\tu16                   sdma_descq_head;\n\tu8                    sdma_generation;\n\tu8                    sdma_intrequest;\n\n\tstruct tasklet_struct sdma_sw_clean_up_task\n\t\t____cacheline_aligned_in_smp;\n\n\twait_queue_head_t state_wait;  \n\n\t \n\tunsigned          hol_state;\n\tstruct timer_list hol_timer;\n\n\t \n\n\t \n\t \n\tu64 lastibcstat;\n\n\t \n\n\t \n\tunsigned long p_rcvctrl;  \n\tunsigned long p_sendctrl;  \n\n\tu32 ibmtu;  \n\t \n\tu32 ibmaxlen;\n\t \n\tu32 init_ibmaxlen;\n\t \n\tu16 lid;\n\t \n\tu16 pkeys[4];\n\t \n\tu8 lmc;\n\tu8 link_width_supported;\n\tu16 link_speed_supported;\n\tu8 link_width_enabled;\n\tu16 link_speed_enabled;\n\tu8 link_width_active;\n\tu16 link_speed_active;\n\tu8 vls_supported;\n\tu8 vls_operational;\n\t \n\tu8 rx_pol_inv;\n\n\tu8 hw_pidx;      \n\tu32 port;         \n\n\tu8 delay_mult;\n\n\t \n\tu8 led_override;   \n\tu16 led_override_timeoff;  \n\tu8 led_override_vals[2];  \n\tu8 led_override_phase;  \n\tatomic_t led_override_timer_active;\n\t \n\tstruct timer_list led_override_timer;\n\tstruct xmit_wait cong_stats;\n\tstruct timer_list symerr_clear_timer;\n\n\t \n\tspinlock_t cc_shadow_lock\n\t\t____cacheline_aligned_in_smp;\n\n\t \n\tstruct cc_table_shadow *ccti_entries_shadow;\n\n\t \n\tstruct ib_cc_congestion_setting_attr_shadow *congestion_entries_shadow;\n\n\t \n\tstruct ib_cc_table_entry_shadow *ccti_entries;\n\n\t \n\tstruct ib_cc_congestion_entry_shadow *congestion_entries;\n\n\t \n\tu16 cc_supported_table_entries;\n\n\t \n\tu16 total_cct_entry;\n\n\t \n\tu16 cc_sl_control_map;\n\n\t \n\tu16 ccti_limit;\n\n\t \n\tu8 cc_max_table_entries;\n};\n\n \n \nstruct diag_observer;\n\ntypedef int (*diag_hook) (struct qib_devdata *dd,\n\tconst struct diag_observer *op,\n\tu32 offs, u64 *data, u64 mask, int only_32);\n\nstruct diag_observer {\n\tdiag_hook hook;\n\tu32 bottom;\n\tu32 top;\n};\n\nextern int qib_register_observer(struct qib_devdata *dd,\n\tconst struct diag_observer *op);\n\n \nstruct diag_observer_list_elt;\n\n \nstruct qib_devdata {\n\tstruct qib_ibdev verbs_dev;      \n\tstruct list_head list;\n\t \n\t \n\tstruct pci_dev *pcidev;\n\tstruct cdev *user_cdev;\n\tstruct cdev *diag_cdev;\n\tstruct device *user_device;\n\tstruct device *diag_device;\n\n\t \n\tu64 __iomem *kregbase;\n\t \n\tu64 __iomem *kregend;\n\t \n\tresource_size_t physaddr;\n\t \n\tstruct qib_ctxtdata **rcd;  \n\n\t \n\tstruct qib_pportdata *pport;\n\tstruct qib_chip_specific *cspec;  \n\n\t \n\tvoid __iomem *pio2kbase;\n\t \n\tvoid __iomem *pio4kbase;\n\t \n\tvoid __iomem *piobase;\n\t \n\tu64 __iomem *userbase;\n\tvoid __iomem *piovl15base;  \n\t \n\tvolatile __le64 *pioavailregs_dma;  \n\t \n\tdma_addr_t pioavailregs_phys;\n\n\t \n\t \n\tint (*f_intr_fallback)(struct qib_devdata *);\n\t \n\tint (*f_reset)(struct qib_devdata *);\n\tvoid (*f_quiet_serdes)(struct qib_pportdata *);\n\tint (*f_bringup_serdes)(struct qib_pportdata *);\n\tint (*f_early_init)(struct qib_devdata *);\n\tvoid (*f_clear_tids)(struct qib_devdata *, struct qib_ctxtdata *);\n\tvoid (*f_put_tid)(struct qib_devdata *, u64 __iomem*,\n\t\t\t\tu32, unsigned long);\n\tvoid (*f_cleanup)(struct qib_devdata *);\n\tvoid (*f_setextled)(struct qib_pportdata *, u32);\n\t \n\tint (*f_get_base_info)(struct qib_ctxtdata *, struct qib_base_info *);\n\t \n\tvoid (*f_free_irq)(struct qib_devdata *);\n\tstruct qib_message_header *(*f_get_msgheader)\n\t\t\t\t\t(struct qib_devdata *, __le32 *);\n\tvoid (*f_config_ctxts)(struct qib_devdata *);\n\tint (*f_get_ib_cfg)(struct qib_pportdata *, int);\n\tint (*f_set_ib_cfg)(struct qib_pportdata *, int, u32);\n\tint (*f_set_ib_loopback)(struct qib_pportdata *, const char *);\n\tint (*f_get_ib_table)(struct qib_pportdata *, int, void *);\n\tint (*f_set_ib_table)(struct qib_pportdata *, int, void *);\n\tu32 (*f_iblink_state)(u64);\n\tu8 (*f_ibphys_portstate)(u64);\n\tvoid (*f_xgxs_reset)(struct qib_pportdata *);\n\t \n\tint (*f_ib_updown)(struct qib_pportdata *, int, u64);\n\tu32 __iomem *(*f_getsendbuf)(struct qib_pportdata *, u64, u32 *);\n\t \n\tint (*f_gpio_mod)(struct qib_devdata *dd, u32 out, u32 dir,\n\t\tu32 mask);\n\t \n\tint (*f_eeprom_wen)(struct qib_devdata *dd, int wen);\n\t \n\tvoid (*f_rcvctrl)(struct qib_pportdata *, unsigned int op,\n\t\tint ctxt);\n\t \n\tvoid (*f_sendctrl)(struct qib_pportdata *, u32 op);\n\tvoid (*f_set_intr_state)(struct qib_devdata *, u32);\n\tvoid (*f_set_armlaunch)(struct qib_devdata *, u32);\n\tvoid (*f_wantpiobuf_intr)(struct qib_devdata *, u32);\n\tint (*f_late_initreg)(struct qib_devdata *);\n\tint (*f_init_sdma_regs)(struct qib_pportdata *);\n\tu16 (*f_sdma_gethead)(struct qib_pportdata *);\n\tint (*f_sdma_busy)(struct qib_pportdata *);\n\tvoid (*f_sdma_update_tail)(struct qib_pportdata *, u16);\n\tvoid (*f_sdma_set_desc_cnt)(struct qib_pportdata *, unsigned);\n\tvoid (*f_sdma_sendctrl)(struct qib_pportdata *, unsigned);\n\tvoid (*f_sdma_hw_clean_up)(struct qib_pportdata *);\n\tvoid (*f_sdma_hw_start_up)(struct qib_pportdata *);\n\tvoid (*f_sdma_init_early)(struct qib_pportdata *);\n\tvoid (*f_set_cntr_sample)(struct qib_pportdata *, u32, u32);\n\tvoid (*f_update_usrhead)(struct qib_ctxtdata *, u64, u32, u32, u32);\n\tu32 (*f_hdrqempty)(struct qib_ctxtdata *);\n\tu64 (*f_portcntr)(struct qib_pportdata *, u32);\n\tu32 (*f_read_cntrs)(struct qib_devdata *, loff_t, char **,\n\t\tu64 **);\n\tu32 (*f_read_portcntrs)(struct qib_devdata *, loff_t, u32,\n\t\tchar **, u64 **);\n\tu32 (*f_setpbc_control)(struct qib_pportdata *, u32, u8, u8);\n\tvoid (*f_initvl15_bufs)(struct qib_devdata *);\n\tvoid (*f_init_ctxt)(struct qib_ctxtdata *);\n\tvoid (*f_txchk_change)(struct qib_devdata *, u32, u32, u32,\n\t\tstruct qib_ctxtdata *);\n\tvoid (*f_writescratch)(struct qib_devdata *, u32);\n\tint (*f_tempsense_rd)(struct qib_devdata *, int regnum);\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\tint (*f_notify_dca)(struct qib_devdata *, unsigned long event);\n#endif\n\n\tchar *boardname;  \n\n\t \n\tu64 tidtemplate;\n\t \n\tu64 tidinvalid;\n\n\t \n\tu32 pioavregs;\n\t \n\tu32 flags;\n\t \n\tu32 lastctxt_piobuf;\n\n\t \n\tu64 z_int_counter;\n\t \n\tu64 __percpu *int_counter;\n\n\t \n\tu32 pbufsctxt;\n\t \n\tu32 ctxts_extrabuf;\n\t \n\tu32 cfgctxts;\n\t \n\tu32 freectxts;\n\n\t \n\tu32 upd_pio_shadow;\n\n\t \n\tu32 maxpkts_call;\n\tu32 avgpkts_call;\n\tu64 nopiobufs;\n\n\t \n\tu16 vendorid;\n\t \n\tu16 deviceid;\n\t \n\tint wc_cookie;\n\tunsigned long wc_base;\n\tunsigned long wc_len;\n\n\t \n\tstruct page **pageshadow;\n\t \n\tdma_addr_t *physshadow;\n\tu64 __iomem *egrtidbase;\n\tspinlock_t sendctrl_lock;  \n\t \n\tspinlock_t uctxt_lock;  \n\t \n\tu64 *devstatusp;\n\tchar *freezemsg;  \n\tu32 freezelen;  \n\t \n\tstruct timer_list stats_timer;\n\n\t \n\tstruct timer_list intrchk_timer;\n\tunsigned long ureg_align;  \n\n\t \n\tspinlock_t pioavail_lock;\n\t \n\tu32 last_pio;\n\t \n\tu32 min_kernel_pio;\n\t \n\n\t \n\n\tunsigned long pioavailshadow[6];\n\t \n\tunsigned long pioavailkernel[6];\n\t \n\tunsigned long pio_need_disarm[3];\n\t \n\tunsigned long pio_writing[3];\n\t \n\tu64 revision;\n\t \n\t__be64 base_guid;\n\n\t \n\tu64 piobufbase;\n\tu32 pio2k_bufbase;\n\n\t \n\n\t \n\tu32 nguid;\n\t \n\tunsigned long rcvctrl;  \n\tunsigned long sendctrl;  \n\n\t \n\tu32 rcvhdrcnt;\n\t \n\tu32 rcvhdrsize;\n\t \n\tu32 rcvhdrentsize;\n\t \n\tu32 ctxtcnt;\n\t \n\tu32 palign;\n\t \n\tu32 piobcnt2k;\n\t \n\tu32 piosize2k;\n\t \n\tu32 piosize2kmax_dwords;\n\t \n\tu32 piobcnt4k;\n\t \n\tu32 piosize4k;\n\t \n\tu32 rcvegrbase;\n\t \n\tu32 rcvtidbase;\n\t \n\tu32 rcvtidcnt;\n\t \n\tu32 uregbase;\n\t \n\tu32 control;\n\n\t \n\tu32 align4k;\n\t \n\tu16 rcvegrbufsize;\n\t \n\tu16 rcvegrbufsize_shift;\n\t \n\tu32 lbus_width;\n\t \n\tu32 lbus_speed;\n\tint unit;  \n\n\t \n\t \n\tu32 msi_lo;\n\t \n\tu32 msi_hi;\n\t \n\tu16 msi_data;\n\t \n\tu32 pcibar0;\n\t \n\tu32 pcibar1;\n\tu64 rhdrhead_intr_off;\n\n\t \n\tu8 serial[16];\n\t \n\tu8 boardversion[96];\n\tu8 lbus_info[32];  \n\t \n\tu8 majrev;\n\t \n\tu8 minrev;\n\n\t \n\t \n\tu8 num_pports;\n\t \n\tu8 first_user_ctxt;\n\tu8 n_krcv_queues;\n\tu8 qpn_mask;\n\tu8 skip_kctxt_mask;\n\n\tu16 rhf_offset;  \n\n\t \n\tu8 gpio_sda_num;\n\tu8 gpio_scl_num;\n\tu8 twsi_eeprom_dev;\n\tu8 board_atten;\n\n\t \n\t \n\tspinlock_t eep_st_lock;\n\t \n\tstruct mutex eep_lock;\n\tuint64_t traffic_wds;\n\tstruct qib_diag_client *diag_client;\n\tspinlock_t qib_diag_trans_lock;  \n\tstruct diag_observer_list_elt *diag_observer_list;\n\n\tu8 psxmitwait_supported;\n\t \n\tu16 psxmitwait_check_rate;\n\t \n\tstruct tasklet_struct error_tasklet;\n\n\tint assigned_node_id;  \n};\n\n \n#define QIB_HOL_UP       0\n#define QIB_HOL_INIT     1\n\n#define QIB_SDMA_SENDCTRL_OP_ENABLE    (1U << 0)\n#define QIB_SDMA_SENDCTRL_OP_INTENABLE (1U << 1)\n#define QIB_SDMA_SENDCTRL_OP_HALT      (1U << 2)\n#define QIB_SDMA_SENDCTRL_OP_CLEANUP   (1U << 3)\n#define QIB_SDMA_SENDCTRL_OP_DRAIN     (1U << 4)\n\n \n#define TXCHK_CHG_TYPE_DIS1  3\n#define TXCHK_CHG_TYPE_ENAB1 2\n#define TXCHK_CHG_TYPE_KERN  1\n#define TXCHK_CHG_TYPE_USER  0\n\n#define QIB_CHASE_TIME msecs_to_jiffies(145)\n#define QIB_CHASE_DIS_TIME msecs_to_jiffies(160)\n\n \nstruct qib_filedata {\n\tstruct qib_ctxtdata *rcd;\n\tunsigned subctxt;\n\tunsigned tidcursor;\n\tstruct qib_user_sdma_queue *pq;\n\tint rec_cpu_num;  \n};\n\nextern struct xarray qib_dev_table;\nextern struct qib_devdata *qib_lookup(int unit);\nextern u32 qib_cpulist_count;\nextern unsigned long *qib_cpulist;\nextern unsigned qib_cc_table_size;\n\nint qib_init(struct qib_devdata *, int);\nint init_chip_wc_pat(struct qib_devdata *dd, u32);\nint qib_enable_wc(struct qib_devdata *dd);\nvoid qib_disable_wc(struct qib_devdata *dd);\nint qib_count_units(int *npresentp, int *nupp);\nint qib_count_active_units(void);\n\nint qib_cdev_init(int minor, const char *name,\n\t\t  const struct file_operations *fops,\n\t\t  struct cdev **cdevp, struct device **devp);\nvoid qib_cdev_cleanup(struct cdev **cdevp, struct device **devp);\nint qib_dev_init(void);\nvoid qib_dev_cleanup(void);\n\nint qib_diag_add(struct qib_devdata *);\nvoid qib_diag_remove(struct qib_devdata *);\nvoid qib_handle_e_ibstatuschanged(struct qib_pportdata *, u64);\nvoid qib_sdma_update_tail(struct qib_pportdata *, u16);  \n\nint qib_decode_err(struct qib_devdata *dd, char *buf, size_t blen, u64 err);\nvoid qib_bad_intrstatus(struct qib_devdata *);\nvoid qib_handle_urcv(struct qib_devdata *, u64);\n\n \nvoid qib_chip_cleanup(struct qib_devdata *);\n \nvoid qib_chip_done(void);\n\n \nint qib_unordered_wc(void);\nvoid qib_pio_copy(void __iomem *to, const void *from, size_t count);\n\nvoid qib_disarm_piobufs(struct qib_devdata *, unsigned, unsigned);\nint qib_disarm_piobufs_ifneeded(struct qib_ctxtdata *);\nvoid qib_disarm_piobufs_set(struct qib_devdata *, unsigned long *, unsigned);\nvoid qib_cancel_sends(struct qib_pportdata *);\n\nint qib_create_rcvhdrq(struct qib_devdata *, struct qib_ctxtdata *);\nint qib_setup_eagerbufs(struct qib_ctxtdata *);\nvoid qib_set_ctxtcnt(struct qib_devdata *);\nint qib_create_ctxts(struct qib_devdata *dd);\nstruct qib_ctxtdata *qib_create_ctxtdata(struct qib_pportdata *, u32, int);\nint qib_init_pportdata(struct qib_pportdata *, struct qib_devdata *, u8, u8);\nvoid qib_free_ctxtdata(struct qib_devdata *, struct qib_ctxtdata *);\n\nu32 qib_kreceive(struct qib_ctxtdata *, u32 *, u32 *);\nint qib_reset_device(int);\nint qib_wait_linkstate(struct qib_pportdata *, u32, int);\nint qib_set_linkstate(struct qib_pportdata *, u8);\nint qib_set_mtu(struct qib_pportdata *, u16);\nint qib_set_lid(struct qib_pportdata *, u32, u8);\nvoid qib_hol_down(struct qib_pportdata *);\nvoid qib_hol_init(struct qib_pportdata *);\nvoid qib_hol_up(struct qib_pportdata *);\nvoid qib_hol_event(struct timer_list *);\nvoid qib_disable_after_error(struct qib_devdata *);\nint qib_set_uevent_bits(struct qib_pportdata *, const int);\n\n \n#define ctxt_fp(fp) \\\n\t(((struct qib_filedata *)(fp)->private_data)->rcd)\n#define subctxt_fp(fp) \\\n\t(((struct qib_filedata *)(fp)->private_data)->subctxt)\n#define tidcursor_fp(fp) \\\n\t(((struct qib_filedata *)(fp)->private_data)->tidcursor)\n#define user_sdma_queue_fp(fp) \\\n\t(((struct qib_filedata *)(fp)->private_data)->pq)\n\nstatic inline struct qib_devdata *dd_from_ppd(struct qib_pportdata *ppd)\n{\n\treturn ppd->dd;\n}\n\nstatic inline struct qib_devdata *dd_from_dev(struct qib_ibdev *dev)\n{\n\treturn container_of(dev, struct qib_devdata, verbs_dev);\n}\n\nstatic inline struct qib_devdata *dd_from_ibdev(struct ib_device *ibdev)\n{\n\treturn dd_from_dev(to_idev(ibdev));\n}\n\nstatic inline struct qib_pportdata *ppd_from_ibp(struct qib_ibport *ibp)\n{\n\treturn container_of(ibp, struct qib_pportdata, ibport_data);\n}\n\nstatic inline struct qib_ibport *to_iport(struct ib_device *ibdev, u32 port)\n{\n\tstruct qib_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 pidx = port - 1;  \n\n\tWARN_ON(pidx >= dd->num_pports);\n\treturn &dd->pport[pidx].ibport_data;\n}\n\n \n#define QIB_HAS_LINK_LATENCY  0x1  \n#define QIB_INITTED           0x2  \n#define QIB_DOING_RESET       0x4   \n#define QIB_PRESENT           0x8   \n#define QIB_PIO_FLUSH_WC      0x10  \n#define QIB_HAS_THRESH_UPDATE 0x40\n#define QIB_HAS_SDMA_TIMEOUT  0x80\n#define QIB_USE_SPCL_TRIG     0x100  \n#define QIB_NODMA_RTAIL       0x200  \n#define QIB_HAS_INTX          0x800  \n#define QIB_HAS_SEND_DMA      0x1000  \n#define QIB_HAS_VLSUPP        0x2000  \n#define QIB_HAS_HDRSUPP       0x4000  \n#define QIB_BADINTR           0x8000  \n#define QIB_DCA_ENABLED       0x10000  \n#define QIB_HAS_QSFP          0x20000  \n#define QIB_SHUTDOWN          0x40000  \n\n \n#define QIBL_LINKV             0x1  \n#define QIBL_LINKDOWN          0x8  \n#define QIBL_LINKINIT          0x10  \n#define QIBL_LINKARMED         0x20  \n#define QIBL_LINKACTIVE        0x40  \n \n#define QIBL_IB_AUTONEG_INPROG 0x1000  \n#define QIBL_IB_AUTONEG_FAILED 0x2000  \n#define QIBL_IB_LINK_DISABLED  0x4000  \n#define QIBL_IB_FORCE_NOTIFY   0x8000  \n\n \n#define QIB_PBC_LENGTH_MASK                     ((1 << 11) - 1)\n\n\n \n\t\t \n#define QIB_CTXT_WAITING_RCV   2\n\t\t \n#define QIB_CTXT_MASTER_UNINIT 4\n\t\t \n#define QIB_CTXT_WAITING_URG 5\n\n \nvoid qib_free_data(struct qib_ctxtdata *dd);\nvoid qib_chg_pioavailkernel(struct qib_devdata *, unsigned, unsigned,\n\t\t\t    u32, struct qib_ctxtdata *);\nstruct qib_devdata *qib_init_iba7322_funcs(struct pci_dev *,\n\t\t\t\t\t   const struct pci_device_id *);\nstruct qib_devdata *qib_init_iba7220_funcs(struct pci_dev *,\n\t\t\t\t\t   const struct pci_device_id *);\nstruct qib_devdata *qib_init_iba6120_funcs(struct pci_dev *,\n\t\t\t\t\t   const struct pci_device_id *);\nvoid qib_free_devdata(struct qib_devdata *);\nstruct qib_devdata *qib_alloc_devdata(struct pci_dev *pdev, size_t extra);\n\n#define QIB_TWSI_NO_DEV 0xFF\n \nint qib_twsi_reset(struct qib_devdata *dd);\nint qib_twsi_blk_rd(struct qib_devdata *dd, int dev, int addr, void *buffer,\n\t\t    int len);\nint qib_twsi_blk_wr(struct qib_devdata *dd, int dev, int addr,\n\t\t    const void *buffer, int len);\nvoid qib_get_eeprom_info(struct qib_devdata *);\nvoid qib_dump_lookup_output_queue(struct qib_devdata *);\nvoid qib_force_pio_avail_update(struct qib_devdata *);\nvoid qib_clear_symerror_on_linkup(struct timer_list *t);\n\n \n#define QIB_LED_PHYS 1  \n#define QIB_LED_LOG 2   \nvoid qib_set_led_override(struct qib_pportdata *ppd, unsigned int val);\n\n \nint qib_setup_sdma(struct qib_pportdata *);\nvoid qib_teardown_sdma(struct qib_pportdata *);\nvoid __qib_sdma_intr(struct qib_pportdata *);\nvoid qib_sdma_intr(struct qib_pportdata *);\nvoid qib_user_sdma_send_desc(struct qib_pportdata *dd,\n\t\t\tstruct list_head *pktlist);\nint qib_sdma_verbs_send(struct qib_pportdata *, struct rvt_sge_state *,\n\t\t\tu32, struct qib_verbs_txreq *);\n \nint qib_sdma_make_progress(struct qib_pportdata *dd);\n\n \nstatic inline u16 qib_sdma_descq_freecnt(const struct qib_pportdata *ppd)\n{\n\treturn ppd->sdma_descq_cnt -\n\t\t(ppd->sdma_descq_added - ppd->sdma_descq_removed) - 1;\n}\n\nstatic inline int __qib_sdma_running(struct qib_pportdata *ppd)\n{\n\treturn ppd->sdma_state.current_state == qib_sdma_state_s99_running;\n}\nint qib_sdma_running(struct qib_pportdata *);\nvoid dump_sdma_state(struct qib_pportdata *ppd);\nvoid __qib_sdma_process_event(struct qib_pportdata *, enum qib_sdma_events);\nvoid qib_sdma_process_event(struct qib_pportdata *, enum qib_sdma_events);\n\n \n#define QIB_DFLT_RCVHDRSIZE 9\n\n \n#define QIB_RCVHDR_ENTSIZE 32\n\nint qib_get_user_pages(unsigned long, size_t, struct page **);\nvoid qib_release_user_pages(struct page **, size_t);\nint qib_eeprom_read(struct qib_devdata *, u8, void *, int);\nint qib_eeprom_write(struct qib_devdata *, u8, const void *, int);\nu32 __iomem *qib_getsendbuf_range(struct qib_devdata *, u32 *, u32, u32);\nvoid qib_sendbuf_done(struct qib_devdata *, unsigned);\n\nstatic inline void qib_clear_rcvhdrtail(const struct qib_ctxtdata *rcd)\n{\n\t*((u64 *) rcd->rcvhdrtail_kvaddr) = 0ULL;\n}\n\nstatic inline u32 qib_get_rcvhdrtail(const struct qib_ctxtdata *rcd)\n{\n\t \n\treturn (u32) le64_to_cpu(\n\t\t*((volatile __le64 *)rcd->rcvhdrtail_kvaddr));  \n}\n\n \n\nextern const char ib_qib_version[];\nextern const struct attribute_group qib_attr_group;\nextern const struct attribute_group *qib_attr_port_groups[];\n\nint qib_device_create(struct qib_devdata *);\nvoid qib_device_remove(struct qib_devdata *);\n\n \nextern int qib_qsfp_dump(struct qib_pportdata *ppd, char *buf, int len);\n\nint __init qib_init_qibfs(void);\nint __exit qib_exit_qibfs(void);\n\nint qibfs_add(struct qib_devdata *);\nint qibfs_remove(struct qib_devdata *);\n\nint qib_pcie_init(struct pci_dev *, const struct pci_device_id *);\nint qib_pcie_ddinit(struct qib_devdata *, struct pci_dev *,\n\t\t    const struct pci_device_id *);\nvoid qib_pcie_ddcleanup(struct qib_devdata *);\nint qib_pcie_params(struct qib_devdata *dd, u32 minw, u32 *nent);\nvoid qib_free_irq(struct qib_devdata *dd);\nint qib_reinit_intr(struct qib_devdata *dd);\nvoid qib_pcie_getcmd(struct qib_devdata *, u16 *, u8 *, u8 *);\nvoid qib_pcie_reenable(struct qib_devdata *, u16, u8, u8);\n \nu64 qib_int_counter(struct qib_devdata *);\n \nu64 qib_sps_ints(void);\n\n \nint qib_map_page(struct pci_dev *d, struct page *p, dma_addr_t *daddr);\nstruct pci_dev *qib_get_pci_dev(struct rvt_dev_info *rdi);\n\n \nstatic inline void qib_flush_wc(void)\n{\n#if defined(CONFIG_X86_64)\n\tasm volatile(\"sfence\" : : : \"memory\");\n#else\n\twmb();  \n#endif\n}\n\n \nextern unsigned qib_ibmtu;\nextern ushort qib_cfgctxts;\nextern ushort qib_num_cfg_vls;\nextern ushort qib_mini_init;  \nextern unsigned qib_n_krcv_queues;\nextern unsigned qib_sdma_fetch_arb;\nextern unsigned qib_compat_ddr_negotiate;\nextern int qib_special_trigger;\nextern unsigned qib_numa_aware;\n\nextern struct mutex qib_mutex;\n\n \n#define STATUS_TIMEOUT 60\n\n#define QIB_DRV_NAME            \"ib_qib\"\n#define QIB_USER_MINOR_BASE     0\n#define QIB_TRACE_MINOR         127\n#define QIB_DIAGPKT_MINOR       128\n#define QIB_DIAG_MINOR_BASE     129\n#define QIB_NMINORS             255\n\n#define PCI_VENDOR_ID_PATHSCALE 0x1fc1\n#define PCI_VENDOR_ID_QLOGIC 0x1077\n#define PCI_DEVICE_ID_QLOGIC_IB_6120 0x10\n#define PCI_DEVICE_ID_QLOGIC_IB_7220 0x7220\n#define PCI_DEVICE_ID_QLOGIC_IB_7322 0x7322\n\n \n#define qib_early_err(dev, fmt, ...) \\\n\tdev_err(dev, fmt, ##__VA_ARGS__)\n\n#define qib_dev_err(dd, fmt, ...) \\\n\tdev_err(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\trvt_get_ibdev_name(&(dd)->verbs_dev.rdi), ##__VA_ARGS__)\n\n#define qib_dev_warn(dd, fmt, ...) \\\n\tdev_warn(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\t rvt_get_ibdev_name(&(dd)->verbs_dev.rdi), ##__VA_ARGS__)\n\n#define qib_dev_porterr(dd, port, fmt, ...) \\\n\tdev_err(&(dd)->pcidev->dev, \"%s: IB%u:%u \" fmt, \\\n\t\trvt_get_ibdev_name(&(dd)->verbs_dev.rdi), (dd)->unit, (port), \\\n\t\t##__VA_ARGS__)\n\n#define qib_devinfo(pcidev, fmt, ...) \\\n\tdev_info(&(pcidev)->dev, fmt, ##__VA_ARGS__)\n\n \nstruct qib_hwerror_msgs {\n\tu64 mask;\n\tconst char *msg;\n\tsize_t sz;\n};\n\n#define QLOGIC_IB_HWE_MSG(a, b) { .mask = a, .msg = b }\n\n \nvoid qib_format_hwerrors(u64 hwerrs,\n\t\t\t const struct qib_hwerror_msgs *hwerrmsgs,\n\t\t\t size_t nhwerrmsgs, char *msg, size_t lmsg);\n\nvoid qib_stop_send_queue(struct rvt_qp *qp);\nvoid qib_quiesce_qp(struct rvt_qp *qp);\nvoid qib_flush_qp_waiters(struct rvt_qp *qp);\nint qib_mtu_to_path_mtu(u32 mtu);\nu32 qib_mtu_from_qp(struct rvt_dev_info *rdi, struct rvt_qp *qp, u32 pmtu);\nvoid qib_notify_error_qp(struct rvt_qp *qp);\nint qib_get_pmtu_from_attr(struct rvt_dev_info *rdi, struct rvt_qp *qp,\n\t\t\t   struct ib_qp_attr *attr);\n\n#endif                           \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}