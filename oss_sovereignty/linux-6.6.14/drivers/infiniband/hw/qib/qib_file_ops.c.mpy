{
  "module_name": "qib_file_ops.c",
  "hash_id": "ec01bdb9f37b5047a9bdd6ba9562f06b39c934502058e7519e02179039ef74e6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/qib/qib_file_ops.c",
  "human_readable_source": " \n\n#include <linux/pci.h>\n#include <linux/poll.h>\n#include <linux/cdev.h>\n#include <linux/swap.h>\n#include <linux/vmalloc.h>\n#include <linux/highmem.h>\n#include <linux/io.h>\n#include <linux/jiffies.h>\n#include <linux/delay.h>\n#include <linux/export.h>\n#include <linux/uio.h>\n#include <linux/pgtable.h>\n\n#include <rdma/ib.h>\n\n#include \"qib.h\"\n#include \"qib_common.h\"\n#include \"qib_user_sdma.h\"\n\n#undef pr_fmt\n#define pr_fmt(fmt) QIB_DRV_NAME \": \" fmt\n\nstatic int qib_open(struct inode *, struct file *);\nstatic int qib_close(struct inode *, struct file *);\nstatic ssize_t qib_write(struct file *, const char __user *, size_t, loff_t *);\nstatic ssize_t qib_write_iter(struct kiocb *, struct iov_iter *);\nstatic __poll_t qib_poll(struct file *, struct poll_table_struct *);\nstatic int qib_mmapf(struct file *, struct vm_area_struct *);\n\n \nstatic const struct file_operations qib_file_ops = {\n\t.owner = THIS_MODULE,\n\t.write = qib_write,\n\t.write_iter = qib_write_iter,\n\t.open = qib_open,\n\t.release = qib_close,\n\t.poll = qib_poll,\n\t.mmap = qib_mmapf,\n\t.llseek = noop_llseek,\n};\n\n \nstatic u64 cvt_kvaddr(void *p)\n{\n\tstruct page *page;\n\tu64 paddr = 0;\n\n\tpage = vmalloc_to_page(p);\n\tif (page)\n\t\tpaddr = page_to_pfn(page) << PAGE_SHIFT;\n\n\treturn paddr;\n}\n\nstatic int qib_get_base_info(struct file *fp, void __user *ubase,\n\t\t\t     size_t ubase_size)\n{\n\tstruct qib_ctxtdata *rcd = ctxt_fp(fp);\n\tint ret = 0;\n\tstruct qib_base_info *kinfo = NULL;\n\tstruct qib_devdata *dd = rcd->dd;\n\tstruct qib_pportdata *ppd = rcd->ppd;\n\tunsigned subctxt_cnt;\n\tint shared, master;\n\tsize_t sz;\n\n\tsubctxt_cnt = rcd->subctxt_cnt;\n\tif (!subctxt_cnt) {\n\t\tshared = 0;\n\t\tmaster = 0;\n\t\tsubctxt_cnt = 1;\n\t} else {\n\t\tshared = 1;\n\t\tmaster = !subctxt_fp(fp);\n\t}\n\n\tsz = sizeof(*kinfo);\n\t \n\tif (!shared)\n\t\tsz -= 7 * sizeof(u64);\n\tif (ubase_size < sz) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tkinfo = kzalloc(sizeof(*kinfo), GFP_KERNEL);\n\tif (kinfo == NULL) {\n\t\tret = -ENOMEM;\n\t\tgoto bail;\n\t}\n\n\tret = dd->f_get_base_info(rcd, kinfo);\n\tif (ret < 0)\n\t\tgoto bail;\n\n\tkinfo->spi_rcvhdr_cnt = dd->rcvhdrcnt;\n\tkinfo->spi_rcvhdrent_size = dd->rcvhdrentsize;\n\tkinfo->spi_tidegrcnt = rcd->rcvegrcnt;\n\tkinfo->spi_rcv_egrbufsize = dd->rcvegrbufsize;\n\t \n\tkinfo->spi_rcv_egrbuftotlen =\n\t\trcd->rcvegrbuf_chunks * rcd->rcvegrbuf_size;\n\tkinfo->spi_rcv_egrperchunk = rcd->rcvegrbufs_perchunk;\n\tkinfo->spi_rcv_egrchunksize = kinfo->spi_rcv_egrbuftotlen /\n\t\trcd->rcvegrbuf_chunks;\n\tkinfo->spi_tidcnt = dd->rcvtidcnt / subctxt_cnt;\n\tif (master)\n\t\tkinfo->spi_tidcnt += dd->rcvtidcnt % subctxt_cnt;\n\t \n\tkinfo->spi_nctxts = dd->cfgctxts;\n\t \n\tkinfo->spi_unit = dd->unit;\n\tkinfo->spi_port = ppd->port;\n\t \n\tkinfo->spi_tid_maxsize = PAGE_SIZE;\n\n\t \n\tkinfo->spi_rcvhdr_base = (u64) rcd->rcvhdrq_phys;\n\tkinfo->spi_rcvhdr_tailaddr = (u64) rcd->rcvhdrqtailaddr_phys;\n\tkinfo->spi_rhf_offset = dd->rhf_offset;\n\tkinfo->spi_rcv_egrbufs = (u64) rcd->rcvegr_phys;\n\tkinfo->spi_pioavailaddr = (u64) dd->pioavailregs_phys;\n\t \n\tkinfo->spi_status = (u64) kinfo->spi_pioavailaddr +\n\t\t(char *) ppd->statusp -\n\t\t(char *) dd->pioavailregs_dma;\n\tkinfo->spi_uregbase = (u64) dd->uregbase + dd->ureg_align * rcd->ctxt;\n\tif (!shared) {\n\t\tkinfo->spi_piocnt = rcd->piocnt;\n\t\tkinfo->spi_piobufbase = (u64) rcd->piobufs;\n\t\tkinfo->spi_sendbuf_status = cvt_kvaddr(rcd->user_event_mask);\n\t} else if (master) {\n\t\tkinfo->spi_piocnt = (rcd->piocnt / subctxt_cnt) +\n\t\t\t\t    (rcd->piocnt % subctxt_cnt);\n\t\t \n\t\tkinfo->spi_piobufbase = (u64) rcd->piobufs +\n\t\t\tdd->palign *\n\t\t\t(rcd->piocnt - kinfo->spi_piocnt);\n\t} else {\n\t\tunsigned slave = subctxt_fp(fp) - 1;\n\n\t\tkinfo->spi_piocnt = rcd->piocnt / subctxt_cnt;\n\t\tkinfo->spi_piobufbase = (u64) rcd->piobufs +\n\t\t\tdd->palign * kinfo->spi_piocnt * slave;\n\t}\n\n\tif (shared) {\n\t\tkinfo->spi_sendbuf_status =\n\t\t\tcvt_kvaddr(&rcd->user_event_mask[subctxt_fp(fp)]);\n\t\t \n\t\tkinfo->spi_subctxt_uregbase = cvt_kvaddr(rcd->subctxt_uregbase);\n\n\t\tkinfo->spi_subctxt_rcvegrbuf =\n\t\t\tcvt_kvaddr(rcd->subctxt_rcvegrbuf);\n\t\tkinfo->spi_subctxt_rcvhdr_base =\n\t\t\tcvt_kvaddr(rcd->subctxt_rcvhdr_base);\n\t}\n\n\t \n\tkinfo->spi_pioindex = (kinfo->spi_piobufbase - dd->pio2k_bufbase) /\n\t\tdd->palign;\n\tkinfo->spi_pioalign = dd->palign;\n\tkinfo->spi_qpair = QIB_KD_QP;\n\t \n\tkinfo->spi_piosize = dd->piosize2k - 2 * sizeof(u32);\n\tkinfo->spi_mtu = ppd->ibmaxlen;  \n\tkinfo->spi_ctxt = rcd->ctxt;\n\tkinfo->spi_subctxt = subctxt_fp(fp);\n\tkinfo->spi_sw_version = QIB_KERN_SWVERSION;\n\tkinfo->spi_sw_version |= 1U << 31;  \n\tkinfo->spi_hw_version = dd->revision;\n\n\tif (master)\n\t\tkinfo->spi_runtime_flags |= QIB_RUNTIME_MASTER;\n\n\tsz = (ubase_size < sizeof(*kinfo)) ? ubase_size : sizeof(*kinfo);\n\tif (copy_to_user(ubase, kinfo, sz))\n\t\tret = -EFAULT;\nbail:\n\tkfree(kinfo);\n\treturn ret;\n}\n\n \nstatic int qib_tid_update(struct qib_ctxtdata *rcd, struct file *fp,\n\t\t\t  const struct qib_tid_info *ti)\n{\n\tint ret = 0, ntids;\n\tu32 tid, ctxttid, cnt, i, tidcnt, tidoff;\n\tu16 *tidlist;\n\tstruct qib_devdata *dd = rcd->dd;\n\tu64 physaddr;\n\tunsigned long vaddr;\n\tu64 __iomem *tidbase;\n\tunsigned long tidmap[8];\n\tstruct page **pagep = NULL;\n\tunsigned subctxt = subctxt_fp(fp);\n\n\tif (!dd->pageshadow) {\n\t\tret = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\tcnt = ti->tidcnt;\n\tif (!cnt) {\n\t\tret = -EFAULT;\n\t\tgoto done;\n\t}\n\tctxttid = rcd->ctxt * dd->rcvtidcnt;\n\tif (!rcd->subctxt_cnt) {\n\t\ttidcnt = dd->rcvtidcnt;\n\t\ttid = rcd->tidcursor;\n\t\ttidoff = 0;\n\t} else if (!subctxt) {\n\t\ttidcnt = (dd->rcvtidcnt / rcd->subctxt_cnt) +\n\t\t\t (dd->rcvtidcnt % rcd->subctxt_cnt);\n\t\ttidoff = dd->rcvtidcnt - tidcnt;\n\t\tctxttid += tidoff;\n\t\ttid = tidcursor_fp(fp);\n\t} else {\n\t\ttidcnt = dd->rcvtidcnt / rcd->subctxt_cnt;\n\t\ttidoff = tidcnt * (subctxt - 1);\n\t\tctxttid += tidoff;\n\t\ttid = tidcursor_fp(fp);\n\t}\n\tif (cnt > tidcnt) {\n\t\t \n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"Process tried to allocate %u TIDs, only trying max (%u)\\n\",\n\t\t\tcnt, tidcnt);\n\t\tcnt = tidcnt;\n\t}\n\tpagep = (struct page **) rcd->tid_pg_list;\n\ttidlist = (u16 *) &pagep[dd->rcvtidcnt];\n\tpagep += tidoff;\n\ttidlist += tidoff;\n\n\tmemset(tidmap, 0, sizeof(tidmap));\n\t \n\tntids = tidcnt;\n\ttidbase = (u64 __iomem *) (((char __iomem *) dd->kregbase) +\n\t\t\t\t   dd->rcvtidbase +\n\t\t\t\t   ctxttid * sizeof(*tidbase));\n\n\t \n\tvaddr = ti->tidvaddr;\n\tif (!access_ok((void __user *) vaddr,\n\t\t       cnt * PAGE_SIZE)) {\n\t\tret = -EFAULT;\n\t\tgoto done;\n\t}\n\tret = qib_get_user_pages(vaddr, cnt, pagep);\n\tif (ret) {\n\t\t \n\t\tqib_devinfo(\n\t\t\tdd->pcidev,\n\t\t\t\"Failed to lock addr %p, %u pages: errno %d\\n\",\n\t\t\t(void *) vaddr, cnt, -ret);\n\t\tgoto done;\n\t}\n\tfor (i = 0; i < cnt; i++, vaddr += PAGE_SIZE) {\n\t\tdma_addr_t daddr;\n\n\t\tfor (; ntids--; tid++) {\n\t\t\tif (tid == tidcnt)\n\t\t\t\ttid = 0;\n\t\t\tif (!dd->pageshadow[ctxttid + tid])\n\t\t\t\tbreak;\n\t\t}\n\t\tif (ntids < 0) {\n\t\t\t \n\t\t\ti--;     \n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\tret = qib_map_page(dd->pcidev, pagep[i], &daddr);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\ttidlist[i] = tid + tidoff;\n\t\t \n\t\tdd->pageshadow[ctxttid + tid] = pagep[i];\n\t\tdd->physshadow[ctxttid + tid] = daddr;\n\t\t \n\t\t__set_bit(tid, tidmap);\n\t\tphysaddr = dd->physshadow[ctxttid + tid];\n\t\t \n\t\tdd->f_put_tid(dd, &tidbase[tid],\n\t\t\t\t  RCVHQ_RCV_TYPE_EXPECTED, physaddr);\n\t\t \n\t\ttid++;\n\t}\n\n\tif (ret) {\n\t\tu32 limit;\ncleanup:\n\t\t \n\t\t \n\t\tlimit = sizeof(tidmap) * BITS_PER_BYTE;\n\t\tif (limit > tidcnt)\n\t\t\t \n\t\t\tlimit = tidcnt;\n\t\ttid = find_first_bit((const unsigned long *)tidmap, limit);\n\t\tfor (; tid < limit; tid++) {\n\t\t\tif (!test_bit(tid, tidmap))\n\t\t\t\tcontinue;\n\t\t\tif (dd->pageshadow[ctxttid + tid]) {\n\t\t\t\tdma_addr_t phys;\n\n\t\t\t\tphys = dd->physshadow[ctxttid + tid];\n\t\t\t\tdd->physshadow[ctxttid + tid] = dd->tidinvalid;\n\t\t\t\t \n\t\t\t\tdd->f_put_tid(dd, &tidbase[tid],\n\t\t\t\t\t      RCVHQ_RCV_TYPE_EXPECTED,\n\t\t\t\t\t      dd->tidinvalid);\n\t\t\t\tdma_unmap_page(&dd->pcidev->dev, phys,\n\t\t\t\t\t       PAGE_SIZE, DMA_FROM_DEVICE);\n\t\t\t\tdd->pageshadow[ctxttid + tid] = NULL;\n\t\t\t}\n\t\t}\n\t\tqib_release_user_pages(pagep, cnt);\n\t} else {\n\t\t \n\t\tif (copy_to_user((void __user *)\n\t\t\t\t (unsigned long) ti->tidlist,\n\t\t\t\t tidlist, cnt * sizeof(*tidlist))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto cleanup;\n\t\t}\n\t\tif (copy_to_user(u64_to_user_ptr(ti->tidmap),\n\t\t\t\t tidmap, sizeof(tidmap))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto cleanup;\n\t\t}\n\t\tif (tid == tidcnt)\n\t\t\ttid = 0;\n\t\tif (!rcd->subctxt_cnt)\n\t\t\trcd->tidcursor = tid;\n\t\telse\n\t\t\ttidcursor_fp(fp) = tid;\n\t}\n\ndone:\n\treturn ret;\n}\n\n \nstatic int qib_tid_free(struct qib_ctxtdata *rcd, unsigned subctxt,\n\t\t\tconst struct qib_tid_info *ti)\n{\n\tint ret = 0;\n\tu32 tid, ctxttid, limit, tidcnt;\n\tstruct qib_devdata *dd = rcd->dd;\n\tu64 __iomem *tidbase;\n\tunsigned long tidmap[8];\n\n\tif (!dd->pageshadow) {\n\t\tret = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\tif (copy_from_user(tidmap, u64_to_user_ptr(ti->tidmap),\n\t\t\t   sizeof(tidmap))) {\n\t\tret = -EFAULT;\n\t\tgoto done;\n\t}\n\n\tctxttid = rcd->ctxt * dd->rcvtidcnt;\n\tif (!rcd->subctxt_cnt)\n\t\ttidcnt = dd->rcvtidcnt;\n\telse if (!subctxt) {\n\t\ttidcnt = (dd->rcvtidcnt / rcd->subctxt_cnt) +\n\t\t\t (dd->rcvtidcnt % rcd->subctxt_cnt);\n\t\tctxttid += dd->rcvtidcnt - tidcnt;\n\t} else {\n\t\ttidcnt = dd->rcvtidcnt / rcd->subctxt_cnt;\n\t\tctxttid += tidcnt * (subctxt - 1);\n\t}\n\ttidbase = (u64 __iomem *) ((char __iomem *)(dd->kregbase) +\n\t\t\t\t   dd->rcvtidbase +\n\t\t\t\t   ctxttid * sizeof(*tidbase));\n\n\tlimit = sizeof(tidmap) * BITS_PER_BYTE;\n\tif (limit > tidcnt)\n\t\t \n\t\tlimit = tidcnt;\n\ttid = find_first_bit(tidmap, limit);\n\tfor (; tid < limit; tid++) {\n\t\t \n\t\tif (!test_bit(tid, tidmap))\n\t\t\tcontinue;\n\n\t\tif (dd->pageshadow[ctxttid + tid]) {\n\t\t\tstruct page *p;\n\t\t\tdma_addr_t phys;\n\n\t\t\tp = dd->pageshadow[ctxttid + tid];\n\t\t\tdd->pageshadow[ctxttid + tid] = NULL;\n\t\t\tphys = dd->physshadow[ctxttid + tid];\n\t\t\tdd->physshadow[ctxttid + tid] = dd->tidinvalid;\n\t\t\t \n\t\t\tdd->f_put_tid(dd, &tidbase[tid],\n\t\t\t\t      RCVHQ_RCV_TYPE_EXPECTED, dd->tidinvalid);\n\t\t\tdma_unmap_page(&dd->pcidev->dev, phys, PAGE_SIZE,\n\t\t\t\t       DMA_FROM_DEVICE);\n\t\t\tqib_release_user_pages(&p, 1);\n\t\t}\n\t}\ndone:\n\treturn ret;\n}\n\n \nstatic int qib_set_part_key(struct qib_ctxtdata *rcd, u16 key)\n{\n\tstruct qib_pportdata *ppd = rcd->ppd;\n\tint i, pidx = -1;\n\tbool any = false;\n\tu16 lkey = key & 0x7FFF;\n\n\tif (lkey == (QIB_DEFAULT_P_KEY & 0x7FFF))\n\t\t \n\t\treturn 0;\n\n\tif (!lkey)\n\t\treturn -EINVAL;\n\n\t \n\tkey |= 0x8000;\n\n\tfor (i = 0; i < ARRAY_SIZE(rcd->pkeys); i++) {\n\t\tif (!rcd->pkeys[i] && pidx == -1)\n\t\t\tpidx = i;\n\t\tif (rcd->pkeys[i] == key)\n\t\t\treturn -EEXIST;\n\t}\n\tif (pidx == -1)\n\t\treturn -EBUSY;\n\tfor (i = 0; i < ARRAY_SIZE(ppd->pkeys); i++) {\n\t\tif (!ppd->pkeys[i]) {\n\t\t\tany = true;\n\t\t\tcontinue;\n\t\t}\n\t\tif (ppd->pkeys[i] == key) {\n\t\t\tatomic_t *pkrefs = &ppd->pkeyrefs[i];\n\n\t\t\tif (atomic_inc_return(pkrefs) > 1) {\n\t\t\t\trcd->pkeys[pidx] = key;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\t \n\t\t\tatomic_dec(pkrefs);\n\t\t\tany = true;\n\t\t}\n\t\tif ((ppd->pkeys[i] & 0x7FFF) == lkey)\n\t\t\t \n\t\t\treturn -EEXIST;\n\t}\n\tif (!any)\n\t\treturn -EBUSY;\n\tfor (i = 0; i < ARRAY_SIZE(ppd->pkeys); i++) {\n\t\tif (!ppd->pkeys[i] &&\n\t\t    atomic_inc_return(&ppd->pkeyrefs[i]) == 1) {\n\t\t\trcd->pkeys[pidx] = key;\n\t\t\tppd->pkeys[i] = key;\n\t\t\t(void) ppd->dd->f_set_ib_cfg(ppd, QIB_IB_CFG_PKEYS, 0);\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -EBUSY;\n}\n\n \nstatic int qib_manage_rcvq(struct qib_ctxtdata *rcd, unsigned subctxt,\n\t\t\t   int start_stop)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tunsigned int rcvctrl_op;\n\n\tif (subctxt)\n\t\tgoto bail;\n\t \n\tif (start_stop) {\n\t\t \n\t\tif (rcd->rcvhdrtail_kvaddr)\n\t\t\tqib_clear_rcvhdrtail(rcd);\n\t\trcvctrl_op = QIB_RCVCTRL_CTXT_ENB;\n\t} else\n\t\trcvctrl_op = QIB_RCVCTRL_CTXT_DIS;\n\tdd->f_rcvctrl(rcd->ppd, rcvctrl_op, rcd->ctxt);\n\t \nbail:\n\treturn 0;\n}\n\nstatic void qib_clean_part_key(struct qib_ctxtdata *rcd,\n\t\t\t       struct qib_devdata *dd)\n{\n\tint i, j, pchanged = 0;\n\tstruct qib_pportdata *ppd = rcd->ppd;\n\n\tfor (i = 0; i < ARRAY_SIZE(rcd->pkeys); i++) {\n\t\tif (!rcd->pkeys[i])\n\t\t\tcontinue;\n\t\tfor (j = 0; j < ARRAY_SIZE(ppd->pkeys); j++) {\n\t\t\t \n\t\t\tif ((ppd->pkeys[j] & 0x7fff) !=\n\t\t\t    (rcd->pkeys[i] & 0x7fff))\n\t\t\t\tcontinue;\n\t\t\tif (atomic_dec_and_test(&ppd->pkeyrefs[j])) {\n\t\t\t\tppd->pkeys[j] = 0;\n\t\t\t\tpchanged++;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\trcd->pkeys[i] = 0;\n\t}\n\tif (pchanged)\n\t\t(void) ppd->dd->f_set_ib_cfg(ppd, QIB_IB_CFG_PKEYS, 0);\n}\n\n \nstatic int qib_mmap_mem(struct vm_area_struct *vma, struct qib_ctxtdata *rcd,\n\t\t\tunsigned len, void *kvaddr, u32 write_ok, char *what)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tunsigned long pfn;\n\tint ret;\n\n\tif ((vma->vm_end - vma->vm_start) > len) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t \"FAIL on %s: len %lx > %x\\n\", what,\n\t\t\t vma->vm_end - vma->vm_start, len);\n\t\tret = -EFAULT;\n\t\tgoto bail;\n\t}\n\n\t \n\tif (!write_ok) {\n\t\tif (vma->vm_flags & VM_WRITE) {\n\t\t\tqib_devinfo(dd->pcidev,\n\t\t\t\t \"%s must be mapped readonly\\n\", what);\n\t\t\tret = -EPERM;\n\t\t\tgoto bail;\n\t\t}\n\n\t\t \n\t\tvm_flags_clear(vma, VM_MAYWRITE);\n\t}\n\n\tpfn = virt_to_phys(kvaddr) >> PAGE_SHIFT;\n\tret = remap_pfn_range(vma, vma->vm_start, pfn,\n\t\t\t      len, vma->vm_page_prot);\n\tif (ret)\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"%s ctxt%u mmap of %lx, %x bytes failed: %d\\n\",\n\t\t\twhat, rcd->ctxt, pfn, len, ret);\nbail:\n\treturn ret;\n}\n\nstatic int mmap_ureg(struct vm_area_struct *vma, struct qib_devdata *dd,\n\t\t     u64 ureg)\n{\n\tunsigned long phys;\n\tunsigned long sz;\n\tint ret;\n\n\t \n\tsz = dd->flags & QIB_HAS_HDRSUPP ? 2 * PAGE_SIZE : PAGE_SIZE;\n\tif ((vma->vm_end - vma->vm_start) > sz) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"FAIL mmap userreg: reqlen %lx > PAGE\\n\",\n\t\t\tvma->vm_end - vma->vm_start);\n\t\tret = -EFAULT;\n\t} else {\n\t\tphys = dd->physaddr + ureg;\n\t\tvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\n\n\t\tvm_flags_set(vma, VM_DONTCOPY | VM_DONTEXPAND);\n\t\tret = io_remap_pfn_range(vma, vma->vm_start,\n\t\t\t\t\t phys >> PAGE_SHIFT,\n\t\t\t\t\t vma->vm_end - vma->vm_start,\n\t\t\t\t\t vma->vm_page_prot);\n\t}\n\treturn ret;\n}\n\nstatic int mmap_piobufs(struct vm_area_struct *vma,\n\t\t\tstruct qib_devdata *dd,\n\t\t\tstruct qib_ctxtdata *rcd,\n\t\t\tunsigned piobufs, unsigned piocnt)\n{\n\tunsigned long phys;\n\tint ret;\n\n\t \n\tif ((vma->vm_end - vma->vm_start) > (piocnt * dd->palign)) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"FAIL mmap piobufs: reqlen %lx > PAGE\\n\",\n\t\t\t vma->vm_end - vma->vm_start);\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tphys = dd->physaddr + piobufs;\n\n#if defined(__powerpc__)\n\tvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\n#endif\n\n\t \n\tvm_flags_mod(vma, VM_DONTCOPY | VM_DONTEXPAND, VM_MAYREAD);\n\n\t \n\tif (!dd->wc_cookie)\n\t\tvma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);\n\n\tret = io_remap_pfn_range(vma, vma->vm_start, phys >> PAGE_SHIFT,\n\t\t\t\t vma->vm_end - vma->vm_start,\n\t\t\t\t vma->vm_page_prot);\nbail:\n\treturn ret;\n}\n\nstatic int mmap_rcvegrbufs(struct vm_area_struct *vma,\n\t\t\t   struct qib_ctxtdata *rcd)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tunsigned long start, size;\n\tsize_t total_size, i;\n\tunsigned long pfn;\n\tint ret;\n\n\tsize = rcd->rcvegrbuf_size;\n\ttotal_size = rcd->rcvegrbuf_chunks * size;\n\tif ((vma->vm_end - vma->vm_start) > total_size) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"FAIL on egr bufs: reqlen %lx > actual %lx\\n\",\n\t\t\t vma->vm_end - vma->vm_start,\n\t\t\t (unsigned long) total_size);\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tif (vma->vm_flags & VM_WRITE) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"Can't map eager buffers as writable (flags=%lx)\\n\",\n\t\t\tvma->vm_flags);\n\t\tret = -EPERM;\n\t\tgoto bail;\n\t}\n\t \n\tvm_flags_clear(vma, VM_MAYWRITE);\n\n\tstart = vma->vm_start;\n\n\tfor (i = 0; i < rcd->rcvegrbuf_chunks; i++, start += size) {\n\t\tpfn = virt_to_phys(rcd->rcvegrbuf[i]) >> PAGE_SHIFT;\n\t\tret = remap_pfn_range(vma, start, pfn, size,\n\t\t\t\t      vma->vm_page_prot);\n\t\tif (ret < 0)\n\t\t\tgoto bail;\n\t}\n\tret = 0;\n\nbail:\n\treturn ret;\n}\n\n \nstatic vm_fault_t qib_file_vma_fault(struct vm_fault *vmf)\n{\n\tstruct page *page;\n\n\tpage = vmalloc_to_page((void *)(vmf->pgoff << PAGE_SHIFT));\n\tif (!page)\n\t\treturn VM_FAULT_SIGBUS;\n\n\tget_page(page);\n\tvmf->page = page;\n\n\treturn 0;\n}\n\nstatic const struct vm_operations_struct qib_file_vm_ops = {\n\t.fault = qib_file_vma_fault,\n};\n\nstatic int mmap_kvaddr(struct vm_area_struct *vma, u64 pgaddr,\n\t\t       struct qib_ctxtdata *rcd, unsigned subctxt)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tunsigned subctxt_cnt;\n\tunsigned long len;\n\tvoid *addr;\n\tsize_t size;\n\tint ret = 0;\n\n\tsubctxt_cnt = rcd->subctxt_cnt;\n\tsize = rcd->rcvegrbuf_chunks * rcd->rcvegrbuf_size;\n\n\t \n\tif (pgaddr == cvt_kvaddr(rcd->subctxt_uregbase)) {\n\t\taddr = rcd->subctxt_uregbase;\n\t\tsize = PAGE_SIZE * subctxt_cnt;\n\t} else if (pgaddr == cvt_kvaddr(rcd->subctxt_rcvhdr_base)) {\n\t\taddr = rcd->subctxt_rcvhdr_base;\n\t\tsize = rcd->rcvhdrq_size * subctxt_cnt;\n\t} else if (pgaddr == cvt_kvaddr(rcd->subctxt_rcvegrbuf)) {\n\t\taddr = rcd->subctxt_rcvegrbuf;\n\t\tsize *= subctxt_cnt;\n\t} else if (pgaddr == cvt_kvaddr(rcd->subctxt_uregbase +\n\t\t\t\t\tPAGE_SIZE * subctxt)) {\n\t\taddr = rcd->subctxt_uregbase + PAGE_SIZE * subctxt;\n\t\tsize = PAGE_SIZE;\n\t} else if (pgaddr == cvt_kvaddr(rcd->subctxt_rcvhdr_base +\n\t\t\t\t\trcd->rcvhdrq_size * subctxt)) {\n\t\taddr = rcd->subctxt_rcvhdr_base +\n\t\t\trcd->rcvhdrq_size * subctxt;\n\t\tsize = rcd->rcvhdrq_size;\n\t} else if (pgaddr == cvt_kvaddr(&rcd->user_event_mask[subctxt])) {\n\t\taddr = rcd->user_event_mask;\n\t\tsize = PAGE_SIZE;\n\t} else if (pgaddr == cvt_kvaddr(rcd->subctxt_rcvegrbuf +\n\t\t\t\t\tsize * subctxt)) {\n\t\taddr = rcd->subctxt_rcvegrbuf + size * subctxt;\n\t\t \n\t\tif (vma->vm_flags & VM_WRITE) {\n\t\t\tqib_devinfo(dd->pcidev,\n\t\t\t\t \"Can't map eager buffers as writable (flags=%lx)\\n\",\n\t\t\t\t vma->vm_flags);\n\t\t\tret = -EPERM;\n\t\t\tgoto bail;\n\t\t}\n\t\t \n\t\tvm_flags_clear(vma, VM_MAYWRITE);\n\t} else\n\t\tgoto bail;\n\tlen = vma->vm_end - vma->vm_start;\n\tif (len > size) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tvma->vm_pgoff = (unsigned long) addr >> PAGE_SHIFT;\n\tvma->vm_ops = &qib_file_vm_ops;\n\tvm_flags_set(vma, VM_DONTEXPAND | VM_DONTDUMP);\n\tret = 1;\n\nbail:\n\treturn ret;\n}\n\n \nstatic int qib_mmapf(struct file *fp, struct vm_area_struct *vma)\n{\n\tstruct qib_ctxtdata *rcd;\n\tstruct qib_devdata *dd;\n\tu64 pgaddr, ureg;\n\tunsigned piobufs, piocnt;\n\tint ret, match = 1;\n\n\trcd = ctxt_fp(fp);\n\tif (!rcd || !(vma->vm_flags & VM_SHARED)) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\tdd = rcd->dd;\n\n\t \n\tpgaddr = vma->vm_pgoff << PAGE_SHIFT;\n\n\t \n\tif (!pgaddr)  {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\t \n\tret = mmap_kvaddr(vma, pgaddr, rcd, subctxt_fp(fp));\n\tif (ret) {\n\t\tif (ret > 0)\n\t\t\tret = 0;\n\t\tgoto bail;\n\t}\n\n\tureg = dd->uregbase + dd->ureg_align * rcd->ctxt;\n\tif (!rcd->subctxt_cnt) {\n\t\t \n\t\tpiocnt = rcd->piocnt;\n\t\tpiobufs = rcd->piobufs;\n\t} else if (!subctxt_fp(fp)) {\n\t\t \n\t\tpiocnt = (rcd->piocnt / rcd->subctxt_cnt) +\n\t\t\t (rcd->piocnt % rcd->subctxt_cnt);\n\t\tpiobufs = rcd->piobufs +\n\t\t\tdd->palign * (rcd->piocnt - piocnt);\n\t} else {\n\t\tunsigned slave = subctxt_fp(fp) - 1;\n\n\t\t \n\t\tpiocnt = rcd->piocnt / rcd->subctxt_cnt;\n\t\tpiobufs = rcd->piobufs + dd->palign * piocnt * slave;\n\t}\n\n\tif (pgaddr == ureg)\n\t\tret = mmap_ureg(vma, dd, ureg);\n\telse if (pgaddr == piobufs)\n\t\tret = mmap_piobufs(vma, dd, rcd, piobufs, piocnt);\n\telse if (pgaddr == dd->pioavailregs_phys)\n\t\t \n\t\tret = qib_mmap_mem(vma, rcd, PAGE_SIZE,\n\t\t\t\t   (void *) dd->pioavailregs_dma, 0,\n\t\t\t\t   \"pioavail registers\");\n\telse if (pgaddr == rcd->rcvegr_phys)\n\t\tret = mmap_rcvegrbufs(vma, rcd);\n\telse if (pgaddr == (u64) rcd->rcvhdrq_phys)\n\t\t \n\t\tret = qib_mmap_mem(vma, rcd, rcd->rcvhdrq_size,\n\t\t\t\t   rcd->rcvhdrq, 1, \"rcvhdrq\");\n\telse if (pgaddr == (u64) rcd->rcvhdrqtailaddr_phys)\n\t\t \n\t\tret = qib_mmap_mem(vma, rcd, PAGE_SIZE,\n\t\t\t\t   rcd->rcvhdrtail_kvaddr, 0,\n\t\t\t\t   \"rcvhdrq tail\");\n\telse\n\t\tmatch = 0;\n\tif (!match)\n\t\tret = -EINVAL;\n\n\tvma->vm_private_data = NULL;\n\n\tif (ret < 0)\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t \"mmap Failure %d: off %llx len %lx\\n\",\n\t\t\t -ret, (unsigned long long)pgaddr,\n\t\t\t vma->vm_end - vma->vm_start);\nbail:\n\treturn ret;\n}\n\nstatic __poll_t qib_poll_urgent(struct qib_ctxtdata *rcd,\n\t\t\t\t    struct file *fp,\n\t\t\t\t    struct poll_table_struct *pt)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\t__poll_t pollflag;\n\n\tpoll_wait(fp, &rcd->wait, pt);\n\n\tspin_lock_irq(&dd->uctxt_lock);\n\tif (rcd->urgent != rcd->urgent_poll) {\n\t\tpollflag = EPOLLIN | EPOLLRDNORM;\n\t\trcd->urgent_poll = rcd->urgent;\n\t} else {\n\t\tpollflag = 0;\n\t\tset_bit(QIB_CTXT_WAITING_URG, &rcd->flag);\n\t}\n\tspin_unlock_irq(&dd->uctxt_lock);\n\n\treturn pollflag;\n}\n\nstatic __poll_t qib_poll_next(struct qib_ctxtdata *rcd,\n\t\t\t\t  struct file *fp,\n\t\t\t\t  struct poll_table_struct *pt)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\t__poll_t pollflag;\n\n\tpoll_wait(fp, &rcd->wait, pt);\n\n\tspin_lock_irq(&dd->uctxt_lock);\n\tif (dd->f_hdrqempty(rcd)) {\n\t\tset_bit(QIB_CTXT_WAITING_RCV, &rcd->flag);\n\t\tdd->f_rcvctrl(rcd->ppd, QIB_RCVCTRL_INTRAVAIL_ENB, rcd->ctxt);\n\t\tpollflag = 0;\n\t} else\n\t\tpollflag = EPOLLIN | EPOLLRDNORM;\n\tspin_unlock_irq(&dd->uctxt_lock);\n\n\treturn pollflag;\n}\n\nstatic __poll_t qib_poll(struct file *fp, struct poll_table_struct *pt)\n{\n\tstruct qib_ctxtdata *rcd;\n\t__poll_t pollflag;\n\n\trcd = ctxt_fp(fp);\n\tif (!rcd)\n\t\tpollflag = EPOLLERR;\n\telse if (rcd->poll_type == QIB_POLL_TYPE_URGENT)\n\t\tpollflag = qib_poll_urgent(rcd, fp, pt);\n\telse  if (rcd->poll_type == QIB_POLL_TYPE_ANYRCV)\n\t\tpollflag = qib_poll_next(rcd, fp, pt);\n\telse  \n\t\tpollflag = EPOLLERR;\n\n\treturn pollflag;\n}\n\nstatic void assign_ctxt_affinity(struct file *fp, struct qib_devdata *dd)\n{\n\tstruct qib_filedata *fd = fp->private_data;\n\tconst unsigned int weight = current->nr_cpus_allowed;\n\tconst struct cpumask *local_mask = cpumask_of_pcibus(dd->pcidev->bus);\n\tint local_cpu;\n\n\t \n\tif ((weight >= qib_cpulist_count) &&\n\t\t(cpumask_weight(local_mask) <= qib_cpulist_count)) {\n\t\tfor_each_cpu(local_cpu, local_mask)\n\t\t\tif (!test_and_set_bit(local_cpu, qib_cpulist)) {\n\t\t\t\tfd->rec_cpu_num = local_cpu;\n\t\t\t\treturn;\n\t\t\t}\n\t}\n\n\t \n\tif (weight >= qib_cpulist_count) {\n\t\tint cpu;\n\n\t\tcpu = find_first_zero_bit(qib_cpulist,\n\t\t\t\t\t  qib_cpulist_count);\n\t\tif (cpu == qib_cpulist_count)\n\t\t\tqib_dev_err(dd,\n\t\t\t\"no cpus avail for affinity PID %u\\n\",\n\t\t\tcurrent->pid);\n\t\telse {\n\t\t\t__set_bit(cpu, qib_cpulist);\n\t\t\tfd->rec_cpu_num = cpu;\n\t\t}\n\t}\n}\n\n \nstatic int qib_compatible_subctxts(int user_swmajor, int user_swminor)\n{\n\t \n\tif (QIB_USER_SWMAJOR != user_swmajor) {\n\t\t \n\t\treturn 0;\n\t}\n\tif (QIB_USER_SWMAJOR == 1) {\n\t\tswitch (QIB_USER_SWMINOR) {\n\t\tcase 0:\n\t\tcase 1:\n\t\tcase 2:\n\t\t\t \n\t\t\treturn 0;\n\t\tcase 3:\n\t\t\t \n\t\t\treturn user_swminor == 3;\n\t\tdefault:\n\t\t\t \n\t\t\treturn user_swminor <= QIB_USER_SWMINOR;\n\t\t}\n\t}\n\t \n\treturn 0;\n}\n\nstatic int init_subctxts(struct qib_devdata *dd,\n\t\t\t struct qib_ctxtdata *rcd,\n\t\t\t const struct qib_user_info *uinfo)\n{\n\tint ret = 0;\n\tunsigned num_subctxts;\n\tsize_t size;\n\n\t \n\tif (uinfo->spu_subctxt_cnt <= 0)\n\t\tgoto bail;\n\tnum_subctxts = uinfo->spu_subctxt_cnt;\n\n\t \n\tif (!qib_compatible_subctxts(uinfo->spu_userversion >> 16,\n\t\tuinfo->spu_userversion & 0xffff)) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t \"Mismatched user version (%d.%d) and driver version (%d.%d) while context sharing. Ensure that driver and library are from the same release.\\n\",\n\t\t\t (int) (uinfo->spu_userversion >> 16),\n\t\t\t (int) (uinfo->spu_userversion & 0xffff),\n\t\t\t QIB_USER_SWMAJOR, QIB_USER_SWMINOR);\n\t\tgoto bail;\n\t}\n\tif (num_subctxts > QLOGIC_IB_MAX_SUBCTXT) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\trcd->subctxt_uregbase = vmalloc_user(PAGE_SIZE * num_subctxts);\n\tif (!rcd->subctxt_uregbase) {\n\t\tret = -ENOMEM;\n\t\tgoto bail;\n\t}\n\t \n\tsize = ALIGN(dd->rcvhdrcnt * dd->rcvhdrentsize *\n\t\t     sizeof(u32), PAGE_SIZE) * num_subctxts;\n\trcd->subctxt_rcvhdr_base = vmalloc_user(size);\n\tif (!rcd->subctxt_rcvhdr_base) {\n\t\tret = -ENOMEM;\n\t\tgoto bail_ureg;\n\t}\n\n\trcd->subctxt_rcvegrbuf = vmalloc_user(rcd->rcvegrbuf_chunks *\n\t\t\t\t\t      rcd->rcvegrbuf_size *\n\t\t\t\t\t      num_subctxts);\n\tif (!rcd->subctxt_rcvegrbuf) {\n\t\tret = -ENOMEM;\n\t\tgoto bail_rhdr;\n\t}\n\n\trcd->subctxt_cnt = uinfo->spu_subctxt_cnt;\n\trcd->subctxt_id = uinfo->spu_subctxt_id;\n\trcd->active_slaves = 1;\n\trcd->redirect_seq_cnt = 1;\n\tset_bit(QIB_CTXT_MASTER_UNINIT, &rcd->flag);\n\tgoto bail;\n\nbail_rhdr:\n\tvfree(rcd->subctxt_rcvhdr_base);\nbail_ureg:\n\tvfree(rcd->subctxt_uregbase);\n\trcd->subctxt_uregbase = NULL;\nbail:\n\treturn ret;\n}\n\nstatic int setup_ctxt(struct qib_pportdata *ppd, int ctxt,\n\t\t      struct file *fp, const struct qib_user_info *uinfo)\n{\n\tstruct qib_filedata *fd = fp->private_data;\n\tstruct qib_devdata *dd = ppd->dd;\n\tstruct qib_ctxtdata *rcd;\n\tvoid *ptmp = NULL;\n\tint ret;\n\tint numa_id;\n\n\tassign_ctxt_affinity(fp, dd);\n\n\tnuma_id = qib_numa_aware ? ((fd->rec_cpu_num != -1) ?\n\t\tcpu_to_node(fd->rec_cpu_num) :\n\t\tnuma_node_id()) : dd->assigned_node_id;\n\n\trcd = qib_create_ctxtdata(ppd, ctxt, numa_id);\n\n\t \n\tif (rcd)\n\t\tptmp = kmalloc(dd->rcvtidcnt * sizeof(u16) +\n\t\t\t       dd->rcvtidcnt * sizeof(struct page **),\n\t\t\t       GFP_KERNEL);\n\n\tif (!rcd || !ptmp) {\n\t\tqib_dev_err(dd,\n\t\t\t\"Unable to allocate ctxtdata memory, failing open\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto bailerr;\n\t}\n\trcd->userversion = uinfo->spu_userversion;\n\tret = init_subctxts(dd, rcd, uinfo);\n\tif (ret)\n\t\tgoto bailerr;\n\trcd->tid_pg_list = ptmp;\n\trcd->pid = current->pid;\n\tinit_waitqueue_head(&dd->rcd[ctxt]->wait);\n\tget_task_comm(rcd->comm, current);\n\tctxt_fp(fp) = rcd;\n\tqib_stats.sps_ctxts++;\n\tdd->freectxts--;\n\tret = 0;\n\tgoto bail;\n\nbailerr:\n\tif (fd->rec_cpu_num != -1)\n\t\t__clear_bit(fd->rec_cpu_num, qib_cpulist);\n\n\tdd->rcd[ctxt] = NULL;\n\tkfree(rcd);\n\tkfree(ptmp);\nbail:\n\treturn ret;\n}\n\nstatic inline int usable(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\n\treturn dd && (dd->flags & QIB_PRESENT) && dd->kregbase && ppd->lid &&\n\t\t(ppd->lflags & QIBL_LINKACTIVE);\n}\n\n \nstatic int choose_port_ctxt(struct file *fp, struct qib_devdata *dd, u32 port,\n\t\t\t    const struct qib_user_info *uinfo)\n{\n\tstruct qib_pportdata *ppd = NULL;\n\tint ret, ctxt;\n\n\tif (port) {\n\t\tif (!usable(dd->pport + port - 1)) {\n\t\t\tret = -ENETDOWN;\n\t\t\tgoto done;\n\t\t} else\n\t\t\tppd = dd->pport + port - 1;\n\t}\n\tfor (ctxt = dd->first_user_ctxt; ctxt < dd->cfgctxts && dd->rcd[ctxt];\n\t     ctxt++)\n\t\t;\n\tif (ctxt == dd->cfgctxts) {\n\t\tret = -EBUSY;\n\t\tgoto done;\n\t}\n\tif (!ppd) {\n\t\tu32 pidx = ctxt % dd->num_pports;\n\n\t\tif (usable(dd->pport + pidx))\n\t\t\tppd = dd->pport + pidx;\n\t\telse {\n\t\t\tfor (pidx = 0; pidx < dd->num_pports && !ppd;\n\t\t\t     pidx++)\n\t\t\t\tif (usable(dd->pport + pidx))\n\t\t\t\t\tppd = dd->pport + pidx;\n\t\t}\n\t}\n\tret = ppd ? setup_ctxt(ppd, ctxt, fp, uinfo) : -ENETDOWN;\ndone:\n\treturn ret;\n}\n\nstatic int find_free_ctxt(int unit, struct file *fp,\n\t\t\t  const struct qib_user_info *uinfo)\n{\n\tstruct qib_devdata *dd = qib_lookup(unit);\n\tint ret;\n\n\tif (!dd || (uinfo->spu_port && uinfo->spu_port > dd->num_pports))\n\t\tret = -ENODEV;\n\telse\n\t\tret = choose_port_ctxt(fp, dd, uinfo->spu_port, uinfo);\n\n\treturn ret;\n}\n\nstatic int get_a_ctxt(struct file *fp, const struct qib_user_info *uinfo,\n\t\t      unsigned alg)\n{\n\tstruct qib_devdata *udd = NULL;\n\tint ret = 0, devmax, npresent, nup, ndev, dusable = 0, i;\n\tu32 port = uinfo->spu_port, ctxt;\n\n\tdevmax = qib_count_units(&npresent, &nup);\n\tif (!npresent) {\n\t\tret = -ENXIO;\n\t\tgoto done;\n\t}\n\tif (nup == 0) {\n\t\tret = -ENETDOWN;\n\t\tgoto done;\n\t}\n\n\tif (alg == QIB_PORT_ALG_ACROSS) {\n\t\tunsigned inuse = ~0U;\n\n\t\t \n\t\tfor (ndev = 0; ndev < devmax; ndev++) {\n\t\t\tstruct qib_devdata *dd = qib_lookup(ndev);\n\t\t\tunsigned cused = 0, cfree = 0, pusable = 0;\n\n\t\t\tif (!dd)\n\t\t\t\tcontinue;\n\t\t\tif (port && port <= dd->num_pports &&\n\t\t\t    usable(dd->pport + port - 1))\n\t\t\t\tpusable = 1;\n\t\t\telse\n\t\t\t\tfor (i = 0; i < dd->num_pports; i++)\n\t\t\t\t\tif (usable(dd->pport + i))\n\t\t\t\t\t\tpusable++;\n\t\t\tif (!pusable)\n\t\t\t\tcontinue;\n\t\t\tfor (ctxt = dd->first_user_ctxt; ctxt < dd->cfgctxts;\n\t\t\t     ctxt++)\n\t\t\t\tif (dd->rcd[ctxt])\n\t\t\t\t\tcused++;\n\t\t\t\telse\n\t\t\t\t\tcfree++;\n\t\t\tif (cfree && cused < inuse) {\n\t\t\t\tudd = dd;\n\t\t\t\tinuse = cused;\n\t\t\t}\n\t\t}\n\t\tif (udd) {\n\t\t\tret = choose_port_ctxt(fp, udd, port, uinfo);\n\t\t\tgoto done;\n\t\t}\n\t} else {\n\t\tfor (ndev = 0; ndev < devmax; ndev++) {\n\t\t\tstruct qib_devdata *dd = qib_lookup(ndev);\n\n\t\t\tif (dd) {\n\t\t\t\tret = choose_port_ctxt(fp, dd, port, uinfo);\n\t\t\t\tif (!ret)\n\t\t\t\t\tgoto done;\n\t\t\t\tif (ret == -EBUSY)\n\t\t\t\t\tdusable++;\n\t\t\t}\n\t\t}\n\t}\n\tret = dusable ? -EBUSY : -ENETDOWN;\n\ndone:\n\treturn ret;\n}\n\nstatic int find_shared_ctxt(struct file *fp,\n\t\t\t    const struct qib_user_info *uinfo)\n{\n\tint devmax, ndev, i;\n\tint ret = 0;\n\n\tdevmax = qib_count_units(NULL, NULL);\n\n\tfor (ndev = 0; ndev < devmax; ndev++) {\n\t\tstruct qib_devdata *dd = qib_lookup(ndev);\n\n\t\t \n\t\tif (!(dd && (dd->flags & QIB_PRESENT) && dd->kregbase))\n\t\t\tcontinue;\n\t\tfor (i = dd->first_user_ctxt; i < dd->cfgctxts; i++) {\n\t\t\tstruct qib_ctxtdata *rcd = dd->rcd[i];\n\n\t\t\t \n\t\t\tif (!rcd || !rcd->cnt)\n\t\t\t\tcontinue;\n\t\t\t \n\t\t\tif (rcd->subctxt_id != uinfo->spu_subctxt_id)\n\t\t\t\tcontinue;\n\t\t\t \n\t\t\tif (rcd->subctxt_cnt != uinfo->spu_subctxt_cnt ||\n\t\t\t    rcd->userversion != uinfo->spu_userversion ||\n\t\t\t    rcd->cnt >= rcd->subctxt_cnt) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tctxt_fp(fp) = rcd;\n\t\t\tsubctxt_fp(fp) = rcd->cnt++;\n\t\t\trcd->subpid[subctxt_fp(fp)] = current->pid;\n\t\t\ttidcursor_fp(fp) = 0;\n\t\t\trcd->active_slaves |= 1 << subctxt_fp(fp);\n\t\t\tret = 1;\n\t\t\tgoto done;\n\t\t}\n\t}\n\ndone:\n\treturn ret;\n}\n\nstatic int qib_open(struct inode *in, struct file *fp)\n{\n\t \n\tfp->private_data = kzalloc(sizeof(struct qib_filedata), GFP_KERNEL);\n\tif (fp->private_data)  \n\t\t((struct qib_filedata *)fp->private_data)->rec_cpu_num = -1;\n\treturn fp->private_data ? 0 : -ENOMEM;\n}\n\nstatic int find_hca(unsigned int cpu, int *unit)\n{\n\tint ret = 0, devmax, npresent, nup, ndev;\n\n\t*unit = -1;\n\n\tdevmax = qib_count_units(&npresent, &nup);\n\tif (!npresent) {\n\t\tret = -ENXIO;\n\t\tgoto done;\n\t}\n\tif (!nup) {\n\t\tret = -ENETDOWN;\n\t\tgoto done;\n\t}\n\tfor (ndev = 0; ndev < devmax; ndev++) {\n\t\tstruct qib_devdata *dd = qib_lookup(ndev);\n\n\t\tif (dd) {\n\t\t\tif (pcibus_to_node(dd->pcidev->bus) < 0) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tif (cpu_to_node(cpu) ==\n\t\t\t\tpcibus_to_node(dd->pcidev->bus)) {\n\t\t\t\t*unit = ndev;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\ndone:\n\treturn ret;\n}\n\nstatic int do_qib_user_sdma_queue_create(struct file *fp)\n{\n\tstruct qib_filedata *fd = fp->private_data;\n\tstruct qib_ctxtdata *rcd = fd->rcd;\n\tstruct qib_devdata *dd = rcd->dd;\n\n\tif (dd->flags & QIB_HAS_SEND_DMA) {\n\n\t\tfd->pq = qib_user_sdma_queue_create(&dd->pcidev->dev,\n\t\t\t\t\t\t    dd->unit,\n\t\t\t\t\t\t    rcd->ctxt,\n\t\t\t\t\t\t    fd->subctxt);\n\t\tif (!fd->pq)\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int qib_assign_ctxt(struct file *fp, const struct qib_user_info *uinfo)\n{\n\tint ret;\n\tint i_minor;\n\tunsigned swmajor, swminor, alg = QIB_PORT_ALG_ACROSS;\n\n\t \n\tif (ctxt_fp(fp)) {\n\t\tret = -EINVAL;\n\t\tgoto done;\n\t}\n\n\t \n\tswmajor = uinfo->spu_userversion >> 16;\n\tif (swmajor != QIB_USER_SWMAJOR) {\n\t\tret = -ENODEV;\n\t\tgoto done;\n\t}\n\n\tswminor = uinfo->spu_userversion & 0xffff;\n\n\tif (swminor >= 11 && uinfo->spu_port_alg < QIB_PORT_ALG_COUNT)\n\t\talg = uinfo->spu_port_alg;\n\n\tmutex_lock(&qib_mutex);\n\n\tif (qib_compatible_subctxts(swmajor, swminor) &&\n\t    uinfo->spu_subctxt_cnt) {\n\t\tret = find_shared_ctxt(fp, uinfo);\n\t\tif (ret > 0) {\n\t\t\tret = do_qib_user_sdma_queue_create(fp);\n\t\t\tif (!ret)\n\t\t\t\tassign_ctxt_affinity(fp, (ctxt_fp(fp))->dd);\n\t\t\tgoto done_ok;\n\t\t}\n\t}\n\n\ti_minor = iminor(file_inode(fp)) - QIB_USER_MINOR_BASE;\n\tif (i_minor)\n\t\tret = find_free_ctxt(i_minor - 1, fp, uinfo);\n\telse {\n\t\tint unit;\n\t\tconst unsigned int cpu = cpumask_first(current->cpus_ptr);\n\t\tconst unsigned int weight = current->nr_cpus_allowed;\n\n\t\tif (weight == 1 && !test_bit(cpu, qib_cpulist))\n\t\t\tif (!find_hca(cpu, &unit) && unit >= 0)\n\t\t\t\tif (!find_free_ctxt(unit, fp, uinfo)) {\n\t\t\t\t\tret = 0;\n\t\t\t\t\tgoto done_chk_sdma;\n\t\t\t\t}\n\t\tret = get_a_ctxt(fp, uinfo, alg);\n\t}\n\ndone_chk_sdma:\n\tif (!ret)\n\t\tret = do_qib_user_sdma_queue_create(fp);\ndone_ok:\n\tmutex_unlock(&qib_mutex);\n\ndone:\n\treturn ret;\n}\n\n\nstatic int qib_do_user_init(struct file *fp,\n\t\t\t    const struct qib_user_info *uinfo)\n{\n\tint ret;\n\tstruct qib_ctxtdata *rcd = ctxt_fp(fp);\n\tstruct qib_devdata *dd;\n\tunsigned uctxt;\n\n\t \n\tif (subctxt_fp(fp)) {\n\t\tret = wait_event_interruptible(rcd->wait,\n\t\t\t!test_bit(QIB_CTXT_MASTER_UNINIT, &rcd->flag));\n\t\tgoto bail;\n\t}\n\n\tdd = rcd->dd;\n\n\t \n\tuctxt = rcd->ctxt - dd->first_user_ctxt;\n\tif (uctxt < dd->ctxts_extrabuf) {\n\t\trcd->piocnt = dd->pbufsctxt + 1;\n\t\trcd->pio_base = rcd->piocnt * uctxt;\n\t} else {\n\t\trcd->piocnt = dd->pbufsctxt;\n\t\trcd->pio_base = rcd->piocnt * uctxt +\n\t\t\tdd->ctxts_extrabuf;\n\t}\n\n\t \n\tif ((rcd->pio_base + rcd->piocnt) > dd->piobcnt2k) {\n\t\tif (rcd->pio_base >= dd->piobcnt2k) {\n\t\t\tqib_dev_err(dd,\n\t\t\t\t    \"%u:ctxt%u: no 2KB buffers available\\n\",\n\t\t\t\t    dd->unit, rcd->ctxt);\n\t\t\tret = -ENOBUFS;\n\t\t\tgoto bail;\n\t\t}\n\t\trcd->piocnt = dd->piobcnt2k - rcd->pio_base;\n\t\tqib_dev_err(dd, \"Ctxt%u: would use 4KB bufs, using %u\\n\",\n\t\t\t    rcd->ctxt, rcd->piocnt);\n\t}\n\n\trcd->piobufs = dd->pio2k_bufbase + rcd->pio_base * dd->palign;\n\tqib_chg_pioavailkernel(dd, rcd->pio_base, rcd->piocnt,\n\t\t\t       TXCHK_CHG_TYPE_USER, rcd);\n\t \n\tdd->f_sendctrl(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\n\n\t \n\tret = qib_create_rcvhdrq(dd, rcd);\n\tif (!ret)\n\t\tret = qib_setup_eagerbufs(rcd);\n\tif (ret)\n\t\tgoto bail_pio;\n\n\trcd->tidcursor = 0;  \n\n\t \n\trcd->urgent = 0;\n\trcd->urgent_poll = 0;\n\n\t \n\tif (rcd->rcvhdrtail_kvaddr)\n\t\tqib_clear_rcvhdrtail(rcd);\n\n\tdd->f_rcvctrl(rcd->ppd, QIB_RCVCTRL_CTXT_ENB | QIB_RCVCTRL_TIDFLOW_ENB,\n\t\t      rcd->ctxt);\n\n\t \n\tif (rcd->subctxt_cnt) {\n\t\tclear_bit(QIB_CTXT_MASTER_UNINIT, &rcd->flag);\n\t\twake_up(&rcd->wait);\n\t}\n\treturn 0;\n\nbail_pio:\n\tqib_chg_pioavailkernel(dd, rcd->pio_base, rcd->piocnt,\n\t\t\t       TXCHK_CHG_TYPE_KERN, rcd);\nbail:\n\treturn ret;\n}\n\n \nstatic void unlock_expected_tids(struct qib_ctxtdata *rcd)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tint ctxt_tidbase = rcd->ctxt * dd->rcvtidcnt;\n\tint i, maxtid = ctxt_tidbase + dd->rcvtidcnt;\n\n\tfor (i = ctxt_tidbase; i < maxtid; i++) {\n\t\tstruct page *p = dd->pageshadow[i];\n\t\tdma_addr_t phys;\n\n\t\tif (!p)\n\t\t\tcontinue;\n\n\t\tphys = dd->physshadow[i];\n\t\tdd->physshadow[i] = dd->tidinvalid;\n\t\tdd->pageshadow[i] = NULL;\n\t\tdma_unmap_page(&dd->pcidev->dev, phys, PAGE_SIZE,\n\t\t\t       DMA_FROM_DEVICE);\n\t\tqib_release_user_pages(&p, 1);\n\t}\n}\n\nstatic int qib_close(struct inode *in, struct file *fp)\n{\n\tstruct qib_filedata *fd;\n\tstruct qib_ctxtdata *rcd;\n\tstruct qib_devdata *dd;\n\tunsigned long flags;\n\tunsigned ctxt;\n\n\tmutex_lock(&qib_mutex);\n\n\tfd = fp->private_data;\n\tfp->private_data = NULL;\n\trcd = fd->rcd;\n\tif (!rcd) {\n\t\tmutex_unlock(&qib_mutex);\n\t\tgoto bail;\n\t}\n\n\tdd = rcd->dd;\n\n\t \n\tqib_flush_wc();\n\n\t \n\tif (fd->pq) {\n\t\tqib_user_sdma_queue_drain(rcd->ppd, fd->pq);\n\t\tqib_user_sdma_queue_destroy(fd->pq);\n\t}\n\n\tif (fd->rec_cpu_num != -1)\n\t\t__clear_bit(fd->rec_cpu_num, qib_cpulist);\n\n\tif (--rcd->cnt) {\n\t\t \n\t\trcd->active_slaves &= ~(1 << fd->subctxt);\n\t\trcd->subpid[fd->subctxt] = 0;\n\t\tmutex_unlock(&qib_mutex);\n\t\tgoto bail;\n\t}\n\n\t \n\tspin_lock_irqsave(&dd->uctxt_lock, flags);\n\tctxt = rcd->ctxt;\n\tdd->rcd[ctxt] = NULL;\n\trcd->pid = 0;\n\tspin_unlock_irqrestore(&dd->uctxt_lock, flags);\n\n\tif (rcd->rcvwait_to || rcd->piowait_to ||\n\t    rcd->rcvnowait || rcd->pionowait) {\n\t\trcd->rcvwait_to = 0;\n\t\trcd->piowait_to = 0;\n\t\trcd->rcvnowait = 0;\n\t\trcd->pionowait = 0;\n\t}\n\tif (rcd->flag)\n\t\trcd->flag = 0;\n\n\tif (dd->kregbase) {\n\t\t \n\t\tdd->f_rcvctrl(rcd->ppd, QIB_RCVCTRL_CTXT_DIS |\n\t\t\t\t  QIB_RCVCTRL_INTRAVAIL_DIS, ctxt);\n\n\t\t \n\t\tqib_clean_part_key(rcd, dd);\n\t\tqib_disarm_piobufs(dd, rcd->pio_base, rcd->piocnt);\n\t\tqib_chg_pioavailkernel(dd, rcd->pio_base,\n\t\t\t\t       rcd->piocnt, TXCHK_CHG_TYPE_KERN, NULL);\n\n\t\tdd->f_clear_tids(dd, rcd);\n\n\t\tif (dd->pageshadow)\n\t\t\tunlock_expected_tids(rcd);\n\t\tqib_stats.sps_ctxts--;\n\t\tdd->freectxts++;\n\t}\n\n\tmutex_unlock(&qib_mutex);\n\tqib_free_ctxtdata(dd, rcd);  \n\nbail:\n\tkfree(fd);\n\treturn 0;\n}\n\nstatic int qib_ctxt_info(struct file *fp, struct qib_ctxt_info __user *uinfo)\n{\n\tstruct qib_ctxt_info info;\n\tint ret;\n\tsize_t sz;\n\tstruct qib_ctxtdata *rcd = ctxt_fp(fp);\n\tstruct qib_filedata *fd;\n\n\tfd = fp->private_data;\n\n\tinfo.num_active = qib_count_active_units();\n\tinfo.unit = rcd->dd->unit;\n\tinfo.port = rcd->ppd->port;\n\tinfo.ctxt = rcd->ctxt;\n\tinfo.subctxt =  subctxt_fp(fp);\n\t \n\tinfo.num_ctxts = rcd->dd->cfgctxts - rcd->dd->first_user_ctxt;\n\tinfo.num_subctxts = rcd->subctxt_cnt;\n\tinfo.rec_cpu = fd->rec_cpu_num;\n\tsz = sizeof(info);\n\n\tif (copy_to_user(uinfo, &info, sz)) {\n\t\tret = -EFAULT;\n\t\tgoto bail;\n\t}\n\tret = 0;\n\nbail:\n\treturn ret;\n}\n\nstatic int qib_sdma_get_inflight(struct qib_user_sdma_queue *pq,\n\t\t\t\t u32 __user *inflightp)\n{\n\tconst u32 val = qib_user_sdma_inflight_counter(pq);\n\n\tif (put_user(val, inflightp))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int qib_sdma_get_complete(struct qib_pportdata *ppd,\n\t\t\t\t struct qib_user_sdma_queue *pq,\n\t\t\t\t u32 __user *completep)\n{\n\tu32 val;\n\tint err;\n\n\tif (!pq)\n\t\treturn -EINVAL;\n\n\terr = qib_user_sdma_make_progress(ppd, pq);\n\tif (err < 0)\n\t\treturn err;\n\n\tval = qib_user_sdma_complete_counter(pq);\n\tif (put_user(val, completep))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int disarm_req_delay(struct qib_ctxtdata *rcd)\n{\n\tint ret = 0;\n\n\tif (!usable(rcd->ppd)) {\n\t\tint i;\n\t\t \n\t\tif (rcd->user_event_mask) {\n\t\t\t \n\t\t\tset_bit(_QIB_EVENT_DISARM_BUFS_BIT,\n\t\t\t\t&rcd->user_event_mask[0]);\n\t\t\tfor (i = 1; i < rcd->subctxt_cnt; i++)\n\t\t\t\tset_bit(_QIB_EVENT_DISARM_BUFS_BIT,\n\t\t\t\t\t&rcd->user_event_mask[i]);\n\t\t}\n\t\tfor (i = 0; !usable(rcd->ppd) && i < 300; i++)\n\t\t\tmsleep(100);\n\t\tret = -ENETDOWN;\n\t}\n\treturn ret;\n}\n\n \nint qib_set_uevent_bits(struct qib_pportdata *ppd, const int evtbit)\n{\n\tstruct qib_ctxtdata *rcd;\n\tunsigned ctxt;\n\tint ret = 0;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ppd->dd->uctxt_lock, flags);\n\tfor (ctxt = ppd->dd->first_user_ctxt; ctxt < ppd->dd->cfgctxts;\n\t     ctxt++) {\n\t\trcd = ppd->dd->rcd[ctxt];\n\t\tif (!rcd)\n\t\t\tcontinue;\n\t\tif (rcd->user_event_mask) {\n\t\t\tint i;\n\t\t\t \n\t\t\tset_bit(evtbit, &rcd->user_event_mask[0]);\n\t\t\tfor (i = 1; i < rcd->subctxt_cnt; i++)\n\t\t\t\tset_bit(evtbit, &rcd->user_event_mask[i]);\n\t\t}\n\t\tret = 1;\n\t\tbreak;\n\t}\n\tspin_unlock_irqrestore(&ppd->dd->uctxt_lock, flags);\n\n\treturn ret;\n}\n\n \nstatic int qib_user_event_ack(struct qib_ctxtdata *rcd, int subctxt,\n\t\t\t      unsigned long events)\n{\n\tint ret = 0, i;\n\n\tfor (i = 0; i <= _QIB_MAX_EVENT_BIT; i++) {\n\t\tif (!test_bit(i, &events))\n\t\t\tcontinue;\n\t\tif (i == _QIB_EVENT_DISARM_BUFS_BIT) {\n\t\t\t(void)qib_disarm_piobufs_ifneeded(rcd);\n\t\t\tret = disarm_req_delay(rcd);\n\t\t} else\n\t\t\tclear_bit(i, &rcd->user_event_mask[subctxt]);\n\t}\n\treturn ret;\n}\n\nstatic ssize_t qib_write(struct file *fp, const char __user *data,\n\t\t\t size_t count, loff_t *off)\n{\n\tconst struct qib_cmd __user *ucmd;\n\tstruct qib_ctxtdata *rcd;\n\tconst void __user *src;\n\tsize_t consumed, copy = 0;\n\tstruct qib_cmd cmd;\n\tssize_t ret = 0;\n\tvoid *dest;\n\n\tif (!ib_safe_file_access(fp)) {\n\t\tpr_err_once(\"qib_write: process %d (%s) changed security contexts after opening file descriptor, this is not allowed.\\n\",\n\t\t\t    task_tgid_vnr(current), current->comm);\n\t\treturn -EACCES;\n\t}\n\n\tif (count < sizeof(cmd.type)) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tucmd = (const struct qib_cmd __user *) data;\n\n\tif (copy_from_user(&cmd.type, &ucmd->type, sizeof(cmd.type))) {\n\t\tret = -EFAULT;\n\t\tgoto bail;\n\t}\n\n\tconsumed = sizeof(cmd.type);\n\n\tswitch (cmd.type) {\n\tcase QIB_CMD_ASSIGN_CTXT:\n\tcase QIB_CMD_USER_INIT:\n\t\tcopy = sizeof(cmd.cmd.user_info);\n\t\tdest = &cmd.cmd.user_info;\n\t\tsrc = &ucmd->cmd.user_info;\n\t\tbreak;\n\n\tcase QIB_CMD_RECV_CTRL:\n\t\tcopy = sizeof(cmd.cmd.recv_ctrl);\n\t\tdest = &cmd.cmd.recv_ctrl;\n\t\tsrc = &ucmd->cmd.recv_ctrl;\n\t\tbreak;\n\n\tcase QIB_CMD_CTXT_INFO:\n\t\tcopy = sizeof(cmd.cmd.ctxt_info);\n\t\tdest = &cmd.cmd.ctxt_info;\n\t\tsrc = &ucmd->cmd.ctxt_info;\n\t\tbreak;\n\n\tcase QIB_CMD_TID_UPDATE:\n\tcase QIB_CMD_TID_FREE:\n\t\tcopy = sizeof(cmd.cmd.tid_info);\n\t\tdest = &cmd.cmd.tid_info;\n\t\tsrc = &ucmd->cmd.tid_info;\n\t\tbreak;\n\n\tcase QIB_CMD_SET_PART_KEY:\n\t\tcopy = sizeof(cmd.cmd.part_key);\n\t\tdest = &cmd.cmd.part_key;\n\t\tsrc = &ucmd->cmd.part_key;\n\t\tbreak;\n\n\tcase QIB_CMD_DISARM_BUFS:\n\tcase QIB_CMD_PIOAVAILUPD:  \n\t\tcopy = 0;\n\t\tsrc = NULL;\n\t\tdest = NULL;\n\t\tbreak;\n\n\tcase QIB_CMD_POLL_TYPE:\n\t\tcopy = sizeof(cmd.cmd.poll_type);\n\t\tdest = &cmd.cmd.poll_type;\n\t\tsrc = &ucmd->cmd.poll_type;\n\t\tbreak;\n\n\tcase QIB_CMD_ARMLAUNCH_CTRL:\n\t\tcopy = sizeof(cmd.cmd.armlaunch_ctrl);\n\t\tdest = &cmd.cmd.armlaunch_ctrl;\n\t\tsrc = &ucmd->cmd.armlaunch_ctrl;\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_INFLIGHT:\n\t\tcopy = sizeof(cmd.cmd.sdma_inflight);\n\t\tdest = &cmd.cmd.sdma_inflight;\n\t\tsrc = &ucmd->cmd.sdma_inflight;\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_COMPLETE:\n\t\tcopy = sizeof(cmd.cmd.sdma_complete);\n\t\tdest = &cmd.cmd.sdma_complete;\n\t\tsrc = &ucmd->cmd.sdma_complete;\n\t\tbreak;\n\n\tcase QIB_CMD_ACK_EVENT:\n\t\tcopy = sizeof(cmd.cmd.event_mask);\n\t\tdest = &cmd.cmd.event_mask;\n\t\tsrc = &ucmd->cmd.event_mask;\n\t\tbreak;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tif (copy) {\n\t\tif ((count - consumed) < copy) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto bail;\n\t\t}\n\t\tif (copy_from_user(dest, src, copy)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto bail;\n\t\t}\n\t\tconsumed += copy;\n\t}\n\n\trcd = ctxt_fp(fp);\n\tif (!rcd && cmd.type != QIB_CMD_ASSIGN_CTXT) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tswitch (cmd.type) {\n\tcase QIB_CMD_ASSIGN_CTXT:\n\t\tif (rcd) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto bail;\n\t\t}\n\n\t\tret = qib_assign_ctxt(fp, &cmd.cmd.user_info);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tbreak;\n\n\tcase QIB_CMD_USER_INIT:\n\t\tret = qib_do_user_init(fp, &cmd.cmd.user_info);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tret = qib_get_base_info(fp, u64_to_user_ptr(\n\t\t\t\t\t  cmd.cmd.user_info.spu_base_info),\n\t\t\t\t\tcmd.cmd.user_info.spu_base_info_size);\n\t\tbreak;\n\n\tcase QIB_CMD_RECV_CTRL:\n\t\tret = qib_manage_rcvq(rcd, subctxt_fp(fp), cmd.cmd.recv_ctrl);\n\t\tbreak;\n\n\tcase QIB_CMD_CTXT_INFO:\n\t\tret = qib_ctxt_info(fp, (struct qib_ctxt_info __user *)\n\t\t\t\t    (unsigned long) cmd.cmd.ctxt_info);\n\t\tbreak;\n\n\tcase QIB_CMD_TID_UPDATE:\n\t\tret = qib_tid_update(rcd, fp, &cmd.cmd.tid_info);\n\t\tbreak;\n\n\tcase QIB_CMD_TID_FREE:\n\t\tret = qib_tid_free(rcd, subctxt_fp(fp), &cmd.cmd.tid_info);\n\t\tbreak;\n\n\tcase QIB_CMD_SET_PART_KEY:\n\t\tret = qib_set_part_key(rcd, cmd.cmd.part_key);\n\t\tbreak;\n\n\tcase QIB_CMD_DISARM_BUFS:\n\t\t(void)qib_disarm_piobufs_ifneeded(rcd);\n\t\tret = disarm_req_delay(rcd);\n\t\tbreak;\n\n\tcase QIB_CMD_PIOAVAILUPD:\n\t\tqib_force_pio_avail_update(rcd->dd);\n\t\tbreak;\n\n\tcase QIB_CMD_POLL_TYPE:\n\t\trcd->poll_type = cmd.cmd.poll_type;\n\t\tbreak;\n\n\tcase QIB_CMD_ARMLAUNCH_CTRL:\n\t\trcd->dd->f_set_armlaunch(rcd->dd, cmd.cmd.armlaunch_ctrl);\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_INFLIGHT:\n\t\tret = qib_sdma_get_inflight(user_sdma_queue_fp(fp),\n\t\t\t\t\t    (u32 __user *) (unsigned long)\n\t\t\t\t\t    cmd.cmd.sdma_inflight);\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_COMPLETE:\n\t\tret = qib_sdma_get_complete(rcd->ppd,\n\t\t\t\t\t    user_sdma_queue_fp(fp),\n\t\t\t\t\t    (u32 __user *) (unsigned long)\n\t\t\t\t\t    cmd.cmd.sdma_complete);\n\t\tbreak;\n\n\tcase QIB_CMD_ACK_EVENT:\n\t\tret = qib_user_event_ack(rcd, subctxt_fp(fp),\n\t\t\t\t\t cmd.cmd.event_mask);\n\t\tbreak;\n\t}\n\n\tif (ret >= 0)\n\t\tret = consumed;\n\nbail:\n\treturn ret;\n}\n\nstatic ssize_t qib_write_iter(struct kiocb *iocb, struct iov_iter *from)\n{\n\tstruct qib_filedata *fp = iocb->ki_filp->private_data;\n\tstruct qib_ctxtdata *rcd = ctxt_fp(iocb->ki_filp);\n\tstruct qib_user_sdma_queue *pq = fp->pq;\n\n\tif (!from->user_backed || !from->nr_segs || !pq)\n\t\treturn -EINVAL;\n\n\treturn qib_user_sdma_writev(rcd, pq, iter_iov(from), from->nr_segs);\n}\n\nstatic const struct class qib_class = {\n\t.name = \"ipath\",\n};\nstatic dev_t qib_dev;\n\nint qib_cdev_init(int minor, const char *name,\n\t\t  const struct file_operations *fops,\n\t\t  struct cdev **cdevp, struct device **devp)\n{\n\tconst dev_t dev = MKDEV(MAJOR(qib_dev), minor);\n\tstruct cdev *cdev;\n\tstruct device *device = NULL;\n\tint ret;\n\n\tcdev = cdev_alloc();\n\tif (!cdev) {\n\t\tpr_err(\"Could not allocate cdev for minor %d, %s\\n\",\n\t\t       minor, name);\n\t\tret = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\tcdev->owner = THIS_MODULE;\n\tcdev->ops = fops;\n\tkobject_set_name(&cdev->kobj, name);\n\n\tret = cdev_add(cdev, dev, 1);\n\tif (ret < 0) {\n\t\tpr_err(\"Could not add cdev for minor %d, %s (err %d)\\n\",\n\t\t       minor, name, -ret);\n\t\tgoto err_cdev;\n\t}\n\n\tdevice = device_create(&qib_class, NULL, dev, NULL, \"%s\", name);\n\tif (!IS_ERR(device))\n\t\tgoto done;\n\tret = PTR_ERR(device);\n\tdevice = NULL;\n\tpr_err(\"Could not create device for minor %d, %s (err %d)\\n\",\n\t       minor, name, -ret);\nerr_cdev:\n\tcdev_del(cdev);\n\tcdev = NULL;\ndone:\n\t*cdevp = cdev;\n\t*devp = device;\n\treturn ret;\n}\n\nvoid qib_cdev_cleanup(struct cdev **cdevp, struct device **devp)\n{\n\tstruct device *device = *devp;\n\n\tif (device) {\n\t\tdevice_unregister(device);\n\t\t*devp = NULL;\n\t}\n\n\tif (*cdevp) {\n\t\tcdev_del(*cdevp);\n\t\t*cdevp = NULL;\n\t}\n}\n\nstatic struct cdev *wildcard_cdev;\nstatic struct device *wildcard_device;\n\nint __init qib_dev_init(void)\n{\n\tint ret;\n\n\tret = alloc_chrdev_region(&qib_dev, 0, QIB_NMINORS, QIB_DRV_NAME);\n\tif (ret < 0) {\n\t\tpr_err(\"Could not allocate chrdev region (err %d)\\n\", -ret);\n\t\tgoto done;\n\t}\n\n\tret = class_register(&qib_class);\n\tif (ret) {\n\t\tpr_err(\"Could not create device class (err %d)\\n\", -ret);\n\t\tunregister_chrdev_region(qib_dev, QIB_NMINORS);\n\t}\n\ndone:\n\treturn ret;\n}\n\nvoid qib_dev_cleanup(void)\n{\n\tif (class_is_registered(&qib_class))\n\t\tclass_unregister(&qib_class);\n\n\tunregister_chrdev_region(qib_dev, QIB_NMINORS);\n}\n\nstatic atomic_t user_count = ATOMIC_INIT(0);\n\nstatic void qib_user_remove(struct qib_devdata *dd)\n{\n\tif (atomic_dec_return(&user_count) == 0)\n\t\tqib_cdev_cleanup(&wildcard_cdev, &wildcard_device);\n\n\tqib_cdev_cleanup(&dd->user_cdev, &dd->user_device);\n}\n\nstatic int qib_user_add(struct qib_devdata *dd)\n{\n\tchar name[10];\n\tint ret;\n\n\tif (atomic_inc_return(&user_count) == 1) {\n\t\tret = qib_cdev_init(0, \"ipath\", &qib_file_ops,\n\t\t\t\t    &wildcard_cdev, &wildcard_device);\n\t\tif (ret)\n\t\t\tgoto done;\n\t}\n\n\tsnprintf(name, sizeof(name), \"ipath%d\", dd->unit);\n\tret = qib_cdev_init(dd->unit + 1, name, &qib_file_ops,\n\t\t\t    &dd->user_cdev, &dd->user_device);\n\tif (ret)\n\t\tqib_user_remove(dd);\ndone:\n\treturn ret;\n}\n\n \nint qib_device_create(struct qib_devdata *dd)\n{\n\tint r, ret;\n\n\tr = qib_user_add(dd);\n\tret = qib_diag_add(dd);\n\tif (r && !ret)\n\t\tret = r;\n\treturn ret;\n}\n\n \nvoid qib_device_remove(struct qib_devdata *dd)\n{\n\tqib_user_remove(dd);\n\tqib_diag_remove(dd);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}