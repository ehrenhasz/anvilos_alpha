{
  "module_name": "qib_iba7322.c",
  "hash_id": "2811af9afefcf4340542d031b5cf54db4df8626dcb3eff8b814e0d2f0012fb0f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/qib/qib_iba7322.c",
  "human_readable_source": " \n\n \n\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/delay.h>\n#include <linux/io.h>\n#include <linux/jiffies.h>\n#include <linux/module.h>\n#include <rdma/ib_verbs.h>\n#include <rdma/ib_smi.h>\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n#include <linux/dca.h>\n#endif\n\n#include \"qib.h\"\n#include \"qib_7322_regs.h\"\n#include \"qib_qsfp.h\"\n\n#include \"qib_mad.h\"\n#include \"qib_verbs.h\"\n\n#undef pr_fmt\n#define pr_fmt(fmt) QIB_DRV_NAME \" \" fmt\n\nstatic void qib_setup_7322_setextled(struct qib_pportdata *, u32);\nstatic void qib_7322_handle_hwerrors(struct qib_devdata *, char *, size_t);\nstatic void sendctrl_7322_mod(struct qib_pportdata *ppd, u32 op);\nstatic irqreturn_t qib_7322intr(int irq, void *data);\nstatic irqreturn_t qib_7322bufavail(int irq, void *data);\nstatic irqreturn_t sdma_intr(int irq, void *data);\nstatic irqreturn_t sdma_idle_intr(int irq, void *data);\nstatic irqreturn_t sdma_progress_intr(int irq, void *data);\nstatic irqreturn_t sdma_cleanup_intr(int irq, void *data);\nstatic void qib_7322_txchk_change(struct qib_devdata *, u32, u32, u32,\n\t\t\t\t  struct qib_ctxtdata *rcd);\nstatic u8 qib_7322_phys_portstate(u64);\nstatic u32 qib_7322_iblink_state(u64);\nstatic void qib_set_ib_7322_lstate(struct qib_pportdata *ppd, u16 linkcmd,\n\t\t\t\t   u16 linitcmd);\nstatic void force_h1(struct qib_pportdata *);\nstatic void adj_tx_serdes(struct qib_pportdata *);\nstatic u32 qib_7322_setpbc_control(struct qib_pportdata *, u32, u8, u8);\nstatic void qib_7322_mini_pcs_reset(struct qib_pportdata *);\n\nstatic u32 ahb_mod(struct qib_devdata *, int, int, int, u32, u32);\nstatic void ibsd_wr_allchans(struct qib_pportdata *, int, unsigned, unsigned);\nstatic void serdes_7322_los_enable(struct qib_pportdata *, int);\nstatic int serdes_7322_init_old(struct qib_pportdata *);\nstatic int serdes_7322_init_new(struct qib_pportdata *);\nstatic void dump_sdma_7322_state(struct qib_pportdata *);\n\n#define BMASK(msb, lsb) (((1 << ((msb) + 1 - (lsb))) - 1) << (lsb))\n\n \n#define LE2_DEFAULT 5\n#define LE2_5m 4\n#define LE2_QME 0\n\n \n#define IBSD(hw_pidx) (hw_pidx + 2)\n\n \nstatic const unsigned rcv_int_timeout = 375;\nstatic const unsigned rcv_int_count = 16;\nstatic const unsigned sdma_idle_cnt = 64;\n\n \n#define RXEQ_DISABLE_MSECS 2500\n\n \nushort qib_num_cfg_vls = 2;\nmodule_param_named(num_vls, qib_num_cfg_vls, ushort, S_IRUGO);\nMODULE_PARM_DESC(num_vls, \"Set number of Virtual Lanes to use (1-8)\");\n\nstatic ushort qib_chase = 1;\nmodule_param_named(chase, qib_chase, ushort, S_IRUGO);\nMODULE_PARM_DESC(chase, \"Enable state chase handling\");\n\nstatic ushort qib_long_atten = 10;  \nmodule_param_named(long_attenuation, qib_long_atten, ushort, S_IRUGO);\nMODULE_PARM_DESC(long_attenuation,\n\t\t \"attenuation cutoff (dB) for long copper cable setup\");\n\nstatic ushort qib_singleport;\nmodule_param_named(singleport, qib_singleport, ushort, S_IRUGO);\nMODULE_PARM_DESC(singleport, \"Use only IB port 1; more per-port buffer space\");\n\nstatic ushort qib_krcvq01_no_msi;\nmodule_param_named(krcvq01_no_msi, qib_krcvq01_no_msi, ushort, S_IRUGO);\nMODULE_PARM_DESC(krcvq01_no_msi, \"No MSI for kctx < 2\");\n\n \nstatic unsigned qib_rcvhdrcnt;\nmodule_param_named(rcvhdrcnt, qib_rcvhdrcnt, uint, S_IRUGO);\nMODULE_PARM_DESC(rcvhdrcnt, \"receive header count\");\n\nstatic unsigned qib_rcvhdrsize;\nmodule_param_named(rcvhdrsize, qib_rcvhdrsize, uint, S_IRUGO);\nMODULE_PARM_DESC(rcvhdrsize, \"receive header size in 32-bit words\");\n\nstatic unsigned qib_rcvhdrentsize;\nmodule_param_named(rcvhdrentsize, qib_rcvhdrentsize, uint, S_IRUGO);\nMODULE_PARM_DESC(rcvhdrentsize, \"receive header entry size in 32-bit words\");\n\n#define MAX_ATTEN_LEN 64  \n \nstatic char txselect_list[MAX_ATTEN_LEN] = \"10\";\nstatic struct kparam_string kp_txselect = {\n\t.string = txselect_list,\n\t.maxlen = MAX_ATTEN_LEN\n};\nstatic int  setup_txselect(const char *, const struct kernel_param *);\nmodule_param_call(txselect, setup_txselect, param_get_string,\n\t\t  &kp_txselect, S_IWUSR | S_IRUGO);\nMODULE_PARM_DESC(txselect,\n\t\t \"Tx serdes indices (for no QSFP or invalid QSFP data)\");\n\n#define BOARD_QME7342 5\n#define BOARD_QMH7342 6\n#define BOARD_QMH7360 9\n#define IS_QMH(dd) (SYM_FIELD((dd)->revision, Revision, BoardID) == \\\n\t\t    BOARD_QMH7342)\n#define IS_QME(dd) (SYM_FIELD((dd)->revision, Revision, BoardID) == \\\n\t\t    BOARD_QME7342)\n\n#define KREG_IDX(regname)     (QIB_7322_##regname##_OFFS / sizeof(u64))\n\n#define KREG_IBPORT_IDX(regname) ((QIB_7322_##regname##_0_OFFS / sizeof(u64)))\n\n#define MASK_ACROSS(lsb, msb) \\\n\t(((1ULL << ((msb) + 1 - (lsb))) - 1) << (lsb))\n\n#define SYM_RMASK(regname, fldname) ((u64)              \\\n\tQIB_7322_##regname##_##fldname##_RMASK)\n\n#define SYM_MASK(regname, fldname) ((u64)               \\\n\tQIB_7322_##regname##_##fldname##_RMASK <<       \\\n\t QIB_7322_##regname##_##fldname##_LSB)\n\n#define SYM_FIELD(value, regname, fldname) ((u64)\t\\\n\t(((value) >> SYM_LSB(regname, fldname)) &\t\\\n\t SYM_RMASK(regname, fldname)))\n\n \n#define SYM_FIELD_ACROSS(value, regname, fldname, nbits) \\\n\t(((value) >> SYM_LSB(regname, fldname)) & MASK_ACROSS(0, nbits))\n\n#define HWE_MASK(fldname) SYM_MASK(HwErrMask, fldname##Mask)\n#define ERR_MASK(fldname) SYM_MASK(ErrMask, fldname##Mask)\n#define ERR_MASK_N(fldname) SYM_MASK(ErrMask_0, fldname##Mask)\n#define INT_MASK(fldname) SYM_MASK(IntMask, fldname##IntMask)\n#define INT_MASK_P(fldname, port) SYM_MASK(IntMask, fldname##IntMask##_##port)\n \n#define INT_MASK_PM(fldname, port) SYM_MASK(IntMask, fldname##Mask##_##port)\n\n\n#define SYM_LSB(regname, fldname) (QIB_7322_##regname##_##fldname##_LSB)\n\n \n#define IBA7322_TID_SZ_SHIFT QIB_7322_RcvTIDArray0_RT_BufSize_LSB\n#define IBA7322_TID_SZ_2K (1UL<<IBA7322_TID_SZ_SHIFT)  \n#define IBA7322_TID_SZ_4K (2UL<<IBA7322_TID_SZ_SHIFT)  \n#define IBA7322_TID_PA_SHIFT 11U  \n\n#define SendIBSLIDAssignMask \\\n\tQIB_7322_SendIBSLIDAssign_0_SendIBSLIDAssign_15_0_RMASK\n#define SendIBSLMCMask \\\n\tQIB_7322_SendIBSLIDMask_0_SendIBSLIDMask_15_0_RMASK\n\n#define ExtLED_IB1_YEL SYM_MASK(EXTCtrl, LEDPort0YellowOn)\n#define ExtLED_IB1_GRN SYM_MASK(EXTCtrl, LEDPort0GreenOn)\n#define ExtLED_IB2_YEL SYM_MASK(EXTCtrl, LEDPort1YellowOn)\n#define ExtLED_IB2_GRN SYM_MASK(EXTCtrl, LEDPort1GreenOn)\n#define ExtLED_IB1_MASK (ExtLED_IB1_YEL | ExtLED_IB1_GRN)\n#define ExtLED_IB2_MASK (ExtLED_IB2_YEL | ExtLED_IB2_GRN)\n\n#define _QIB_GPIO_SDA_NUM 1\n#define _QIB_GPIO_SCL_NUM 0\n#define QIB_EEPROM_WEN_NUM 14\n#define QIB_TWSI_EEPROM_DEV 0xA2  \n\n \n#define QIB_7322_PSXMITWAIT_CHECK_RATE 4000\n\n \n#define PORT_SPD_CAP (QIB_IB_SDR | QIB_IB_DDR | QIB_IB_QDR)\n#define PORT_SPD_CAP_SHIFT 3\n\n \n#define DUAL_PORT_CAP (PORT_SPD_CAP | (PORT_SPD_CAP << PORT_SPD_CAP_SHIFT))\n\n \n\n \n#define kr_contextcnt KREG_IDX(ContextCnt)\n#define kr_control KREG_IDX(Control)\n#define kr_counterregbase KREG_IDX(CntrRegBase)\n#define kr_errclear KREG_IDX(ErrClear)\n#define kr_errmask KREG_IDX(ErrMask)\n#define kr_errstatus KREG_IDX(ErrStatus)\n#define kr_extctrl KREG_IDX(EXTCtrl)\n#define kr_extstatus KREG_IDX(EXTStatus)\n#define kr_gpio_clear KREG_IDX(GPIOClear)\n#define kr_gpio_mask KREG_IDX(GPIOMask)\n#define kr_gpio_out KREG_IDX(GPIOOut)\n#define kr_gpio_status KREG_IDX(GPIOStatus)\n#define kr_hwdiagctrl KREG_IDX(HwDiagCtrl)\n#define kr_debugportval KREG_IDX(DebugPortValueReg)\n#define kr_fmask KREG_IDX(feature_mask)\n#define kr_act_fmask KREG_IDX(active_feature_mask)\n#define kr_hwerrclear KREG_IDX(HwErrClear)\n#define kr_hwerrmask KREG_IDX(HwErrMask)\n#define kr_hwerrstatus KREG_IDX(HwErrStatus)\n#define kr_intclear KREG_IDX(IntClear)\n#define kr_intmask KREG_IDX(IntMask)\n#define kr_intredirect KREG_IDX(IntRedirect0)\n#define kr_intstatus KREG_IDX(IntStatus)\n#define kr_pagealign KREG_IDX(PageAlign)\n#define kr_rcvavailtimeout KREG_IDX(RcvAvailTimeOut0)\n#define kr_rcvctrl KREG_IDX(RcvCtrl)  \n#define kr_rcvegrbase KREG_IDX(RcvEgrBase)\n#define kr_rcvegrcnt KREG_IDX(RcvEgrCnt)\n#define kr_rcvhdrcnt KREG_IDX(RcvHdrCnt)\n#define kr_rcvhdrentsize KREG_IDX(RcvHdrEntSize)\n#define kr_rcvhdrsize KREG_IDX(RcvHdrSize)\n#define kr_rcvtidbase KREG_IDX(RcvTIDBase)\n#define kr_rcvtidcnt KREG_IDX(RcvTIDCnt)\n#define kr_revision KREG_IDX(Revision)\n#define kr_scratch KREG_IDX(Scratch)\n#define kr_sendbuffererror KREG_IDX(SendBufErr0)  \n#define kr_sendcheckmask KREG_IDX(SendCheckMask0)  \n#define kr_sendctrl KREG_IDX(SendCtrl)\n#define kr_sendgrhcheckmask KREG_IDX(SendGRHCheckMask0)  \n#define kr_sendibpktmask KREG_IDX(SendIBPacketMask0)  \n#define kr_sendpioavailaddr KREG_IDX(SendBufAvailAddr)\n#define kr_sendpiobufbase KREG_IDX(SendBufBase)\n#define kr_sendpiobufcnt KREG_IDX(SendBufCnt)\n#define kr_sendpiosize KREG_IDX(SendBufSize)\n#define kr_sendregbase KREG_IDX(SendRegBase)\n#define kr_sendbufavail0 KREG_IDX(SendBufAvail0)\n#define kr_userregbase KREG_IDX(UserRegBase)\n#define kr_intgranted KREG_IDX(Int_Granted)\n#define kr_vecclr_wo_int KREG_IDX(vec_clr_without_int)\n#define kr_intblocked KREG_IDX(IntBlocked)\n#define kr_r_access KREG_IDX(SPC_JTAG_ACCESS_REG)\n\n \n#define krp_errclear KREG_IBPORT_IDX(ErrClear)\n#define krp_errmask KREG_IBPORT_IDX(ErrMask)\n#define krp_errstatus KREG_IBPORT_IDX(ErrStatus)\n#define krp_highprio_0 KREG_IBPORT_IDX(HighPriority0)\n#define krp_highprio_limit KREG_IBPORT_IDX(HighPriorityLimit)\n#define krp_hrtbt_guid KREG_IBPORT_IDX(HRTBT_GUID)\n#define krp_ib_pcsconfig KREG_IBPORT_IDX(IBPCSConfig)\n#define krp_ibcctrl_a KREG_IBPORT_IDX(IBCCtrlA)\n#define krp_ibcctrl_b KREG_IBPORT_IDX(IBCCtrlB)\n#define krp_ibcctrl_c KREG_IBPORT_IDX(IBCCtrlC)\n#define krp_ibcstatus_a KREG_IBPORT_IDX(IBCStatusA)\n#define krp_ibcstatus_b KREG_IBPORT_IDX(IBCStatusB)\n#define krp_txestatus KREG_IBPORT_IDX(TXEStatus)\n#define krp_lowprio_0 KREG_IBPORT_IDX(LowPriority0)\n#define krp_ncmodectrl KREG_IBPORT_IDX(IBNCModeCtrl)\n#define krp_partitionkey KREG_IBPORT_IDX(RcvPartitionKey)\n#define krp_psinterval KREG_IBPORT_IDX(PSInterval)\n#define krp_psstart KREG_IBPORT_IDX(PSStart)\n#define krp_psstat KREG_IBPORT_IDX(PSStat)\n#define krp_rcvbthqp KREG_IBPORT_IDX(RcvBTHQP)\n#define krp_rcvctrl KREG_IBPORT_IDX(RcvCtrl)\n#define krp_rcvpktledcnt KREG_IBPORT_IDX(RcvPktLEDCnt)\n#define krp_rcvqpmaptable KREG_IBPORT_IDX(RcvQPMapTableA)\n#define krp_rxcreditvl0 KREG_IBPORT_IDX(RxCreditVL0)\n#define krp_rxcreditvl15 (KREG_IBPORT_IDX(RxCreditVL0)+15)\n#define krp_sendcheckcontrol KREG_IBPORT_IDX(SendCheckControl)\n#define krp_sendctrl KREG_IBPORT_IDX(SendCtrl)\n#define krp_senddmabase KREG_IBPORT_IDX(SendDmaBase)\n#define krp_senddmabufmask0 KREG_IBPORT_IDX(SendDmaBufMask0)\n#define krp_senddmabufmask1 (KREG_IBPORT_IDX(SendDmaBufMask0) + 1)\n#define krp_senddmabufmask2 (KREG_IBPORT_IDX(SendDmaBufMask0) + 2)\n#define krp_senddmabuf_use0 KREG_IBPORT_IDX(SendDmaBufUsed0)\n#define krp_senddmabuf_use1 (KREG_IBPORT_IDX(SendDmaBufUsed0) + 1)\n#define krp_senddmabuf_use2 (KREG_IBPORT_IDX(SendDmaBufUsed0) + 2)\n#define krp_senddmadesccnt KREG_IBPORT_IDX(SendDmaDescCnt)\n#define krp_senddmahead KREG_IBPORT_IDX(SendDmaHead)\n#define krp_senddmaheadaddr KREG_IBPORT_IDX(SendDmaHeadAddr)\n#define krp_senddmaidlecnt KREG_IBPORT_IDX(SendDmaIdleCnt)\n#define krp_senddmalengen KREG_IBPORT_IDX(SendDmaLenGen)\n#define krp_senddmaprioritythld KREG_IBPORT_IDX(SendDmaPriorityThld)\n#define krp_senddmareloadcnt KREG_IBPORT_IDX(SendDmaReloadCnt)\n#define krp_senddmastatus KREG_IBPORT_IDX(SendDmaStatus)\n#define krp_senddmatail KREG_IBPORT_IDX(SendDmaTail)\n#define krp_sendhdrsymptom KREG_IBPORT_IDX(SendHdrErrSymptom)\n#define krp_sendslid KREG_IBPORT_IDX(SendIBSLIDAssign)\n#define krp_sendslidmask KREG_IBPORT_IDX(SendIBSLIDMask)\n#define krp_ibsdtestiftx KREG_IBPORT_IDX(IB_SDTEST_IF_TX)\n#define krp_adapt_dis_timer KREG_IBPORT_IDX(ADAPT_DISABLE_TIMER_THRESHOLD)\n#define krp_tx_deemph_override KREG_IBPORT_IDX(IBSD_TX_DEEMPHASIS_OVERRIDE)\n#define krp_serdesctrl KREG_IBPORT_IDX(IBSerdesCtrl)\n\n \n#define krc_rcvhdraddr KREG_IDX(RcvHdrAddr0)\n#define krc_rcvhdrtailaddr KREG_IDX(RcvHdrTailAddr0)\n\n \n#define NUM_TIDFLOWS_CTXT 0x20  \n#define ur_rcvflowtable (KREG_IDX(RcvTIDFlowTable0) - KREG_IDX(RcvHdrTail0))\n\n \n#define TIDFLOW_ERRBITS  ( \\\n\t(SYM_MASK(RcvTIDFlowTable0, GenMismatch) << \\\n\tSYM_LSB(RcvTIDFlowTable0, GenMismatch)) | \\\n\t(SYM_MASK(RcvTIDFlowTable0, SeqMismatch) << \\\n\tSYM_LSB(RcvTIDFlowTable0, SeqMismatch)))\n\n \n#define CREG_IDX(regname) \\\n((QIB_7322_##regname##_0_OFFS - QIB_7322_LBIntCnt_OFFS) / sizeof(u64))\n\n#define crp_badformat CREG_IDX(RxVersionErrCnt)\n#define crp_err_rlen CREG_IDX(RxLenErrCnt)\n#define crp_erricrc CREG_IDX(RxICRCErrCnt)\n#define crp_errlink CREG_IDX(RxLinkMalformCnt)\n#define crp_errlpcrc CREG_IDX(RxLPCRCErrCnt)\n#define crp_errpkey CREG_IDX(RxPKeyMismatchCnt)\n#define crp_errvcrc CREG_IDX(RxVCRCErrCnt)\n#define crp_excessbufferovfl CREG_IDX(ExcessBufferOvflCnt)\n#define crp_iblinkdown CREG_IDX(IBLinkDownedCnt)\n#define crp_iblinkerrrecov CREG_IDX(IBLinkErrRecoveryCnt)\n#define crp_ibstatuschange CREG_IDX(IBStatusChangeCnt)\n#define crp_ibsymbolerr CREG_IDX(IBSymbolErrCnt)\n#define crp_invalidrlen CREG_IDX(RxMaxMinLenErrCnt)\n#define crp_locallinkintegrityerr CREG_IDX(LocalLinkIntegrityErrCnt)\n#define crp_pktrcv CREG_IDX(RxDataPktCnt)\n#define crp_pktrcvflowctrl CREG_IDX(RxFlowPktCnt)\n#define crp_pktsend CREG_IDX(TxDataPktCnt)\n#define crp_pktsendflow CREG_IDX(TxFlowPktCnt)\n#define crp_psrcvdatacount CREG_IDX(PSRcvDataCount)\n#define crp_psrcvpktscount CREG_IDX(PSRcvPktsCount)\n#define crp_psxmitdatacount CREG_IDX(PSXmitDataCount)\n#define crp_psxmitpktscount CREG_IDX(PSXmitPktsCount)\n#define crp_psxmitwaitcount CREG_IDX(PSXmitWaitCount)\n#define crp_rcvebp CREG_IDX(RxEBPCnt)\n#define crp_rcvflowctrlviol CREG_IDX(RxFlowCtrlViolCnt)\n#define crp_rcvovfl CREG_IDX(RxBufOvflCnt)\n#define crp_rxdlidfltr CREG_IDX(RxDlidFltrCnt)\n#define crp_rxdroppkt CREG_IDX(RxDroppedPktCnt)\n#define crp_rxotherlocalphyerr CREG_IDX(RxOtherLocalPhyErrCnt)\n#define crp_rxqpinvalidctxt CREG_IDX(RxQPInvalidContextCnt)\n#define crp_rxvlerr CREG_IDX(RxVlErrCnt)\n#define crp_sendstall CREG_IDX(TxFlowStallCnt)\n#define crp_txdroppedpkt CREG_IDX(TxDroppedPktCnt)\n#define crp_txhdrerr CREG_IDX(TxHeadersErrCnt)\n#define crp_txlenerr CREG_IDX(TxLenErrCnt)\n#define crp_txminmaxlenerr CREG_IDX(TxMaxMinLenErrCnt)\n#define crp_txsdmadesc CREG_IDX(TxSDmaDescCnt)\n#define crp_txunderrun CREG_IDX(TxUnderrunCnt)\n#define crp_txunsupvl CREG_IDX(TxUnsupVLErrCnt)\n#define crp_vl15droppedpkt CREG_IDX(RxVL15DroppedPktCnt)\n#define crp_wordrcv CREG_IDX(RxDwordCnt)\n#define crp_wordsend CREG_IDX(TxDwordCnt)\n#define crp_tx_creditstalls CREG_IDX(TxCreditUpToDateTimeOut)\n\n \n#define CREG_DEVIDX(regname) ((QIB_7322_##regname##_OFFS - \\\n\t\t\tQIB_7322_LBIntCnt_OFFS) / sizeof(u64))\n#define cr_base_egrovfl CREG_DEVIDX(RxP0HdrEgrOvflCnt)\n#define cr_lbint CREG_DEVIDX(LBIntCnt)\n#define cr_lbstall CREG_DEVIDX(LBFlowStallCnt)\n#define cr_pcieretrydiag CREG_DEVIDX(PcieRetryBufDiagQwordCnt)\n#define cr_rxtidflowdrop CREG_DEVIDX(RxTidFlowDropCnt)\n#define cr_tidfull CREG_DEVIDX(RxTIDFullErrCnt)\n#define cr_tidinvalid CREG_DEVIDX(RxTIDValidErrCnt)\n\n \n#define NUM_IB_PORTS 2\n\n \n#define NUM_VL15_BUFS NUM_IB_PORTS\n\n \n#define KCTXT0_EGRCNT 2048\n\n \n#define PBC_PORT_SEL_LSB 26\n#define PBC_PORT_SEL_RMASK 1\n#define PBC_VL_NUM_LSB 27\n#define PBC_VL_NUM_RMASK 7\n#define PBC_7322_VL15_SEND (1ULL << 63)  \n#define PBC_7322_VL15_SEND_CTRL (1ULL << 31)  \n\nstatic u8 ib_rate_to_delay[IB_RATE_120_GBPS + 1] = {\n\t[IB_RATE_2_5_GBPS] = 16,\n\t[IB_RATE_5_GBPS] = 8,\n\t[IB_RATE_10_GBPS] = 4,\n\t[IB_RATE_20_GBPS] = 2,\n\t[IB_RATE_30_GBPS] = 2,\n\t[IB_RATE_40_GBPS] = 1\n};\n\nstatic const char * const qib_sdma_state_names[] = {\n\t[qib_sdma_state_s00_hw_down]          = \"s00_HwDown\",\n\t[qib_sdma_state_s10_hw_start_up_wait] = \"s10_HwStartUpWait\",\n\t[qib_sdma_state_s20_idle]             = \"s20_Idle\",\n\t[qib_sdma_state_s30_sw_clean_up_wait] = \"s30_SwCleanUpWait\",\n\t[qib_sdma_state_s40_hw_clean_up_wait] = \"s40_HwCleanUpWait\",\n\t[qib_sdma_state_s50_hw_halt_wait]     = \"s50_HwHaltWait\",\n\t[qib_sdma_state_s99_running]          = \"s99_Running\",\n};\n\n#define IBA7322_LINKSPEED_SHIFT SYM_LSB(IBCStatusA_0, LinkSpeedActive)\n#define IBA7322_LINKWIDTH_SHIFT SYM_LSB(IBCStatusA_0, LinkWidthActive)\n\n \n#define IB_7322_LT_STATE_DISABLED        0x00\n#define IB_7322_LT_STATE_LINKUP          0x01\n#define IB_7322_LT_STATE_POLLACTIVE      0x02\n#define IB_7322_LT_STATE_POLLQUIET       0x03\n#define IB_7322_LT_STATE_SLEEPDELAY      0x04\n#define IB_7322_LT_STATE_SLEEPQUIET      0x05\n#define IB_7322_LT_STATE_CFGDEBOUNCE     0x08\n#define IB_7322_LT_STATE_CFGRCVFCFG      0x09\n#define IB_7322_LT_STATE_CFGWAITRMT      0x0a\n#define IB_7322_LT_STATE_CFGIDLE         0x0b\n#define IB_7322_LT_STATE_RECOVERRETRAIN  0x0c\n#define IB_7322_LT_STATE_TXREVLANES      0x0d\n#define IB_7322_LT_STATE_RECOVERWAITRMT  0x0e\n#define IB_7322_LT_STATE_RECOVERIDLE     0x0f\n#define IB_7322_LT_STATE_CFGENH          0x10\n#define IB_7322_LT_STATE_CFGTEST         0x11\n#define IB_7322_LT_STATE_CFGWAITRMTTEST  0x12\n#define IB_7322_LT_STATE_CFGWAITENH      0x13\n\n \n#define IB_7322_L_STATE_DOWN             0x0\n#define IB_7322_L_STATE_INIT             0x1\n#define IB_7322_L_STATE_ARM              0x2\n#define IB_7322_L_STATE_ACTIVE           0x3\n#define IB_7322_L_STATE_ACT_DEFER        0x4\n\nstatic const u8 qib_7322_physportstate[0x20] = {\n\t[IB_7322_LT_STATE_DISABLED] = IB_PHYSPORTSTATE_DISABLED,\n\t[IB_7322_LT_STATE_LINKUP] = IB_PHYSPORTSTATE_LINKUP,\n\t[IB_7322_LT_STATE_POLLACTIVE] = IB_PHYSPORTSTATE_POLL,\n\t[IB_7322_LT_STATE_POLLQUIET] = IB_PHYSPORTSTATE_POLL,\n\t[IB_7322_LT_STATE_SLEEPDELAY] = IB_PHYSPORTSTATE_SLEEP,\n\t[IB_7322_LT_STATE_SLEEPQUIET] = IB_PHYSPORTSTATE_SLEEP,\n\t[IB_7322_LT_STATE_CFGDEBOUNCE] = IB_PHYSPORTSTATE_CFG_TRAIN,\n\t[IB_7322_LT_STATE_CFGRCVFCFG] =\n\t\tIB_PHYSPORTSTATE_CFG_TRAIN,\n\t[IB_7322_LT_STATE_CFGWAITRMT] =\n\t\tIB_PHYSPORTSTATE_CFG_TRAIN,\n\t[IB_7322_LT_STATE_CFGIDLE] = IB_PHYSPORTSTATE_CFG_IDLE,\n\t[IB_7322_LT_STATE_RECOVERRETRAIN] =\n\t\tIB_PHYSPORTSTATE_LINK_ERR_RECOVER,\n\t[IB_7322_LT_STATE_RECOVERWAITRMT] =\n\t\tIB_PHYSPORTSTATE_LINK_ERR_RECOVER,\n\t[IB_7322_LT_STATE_RECOVERIDLE] =\n\t\tIB_PHYSPORTSTATE_LINK_ERR_RECOVER,\n\t[IB_7322_LT_STATE_CFGENH] = IB_PHYSPORTSTATE_CFG_ENH,\n\t[IB_7322_LT_STATE_CFGTEST] = IB_PHYSPORTSTATE_CFG_TRAIN,\n\t[IB_7322_LT_STATE_CFGWAITRMTTEST] =\n\t\tIB_PHYSPORTSTATE_CFG_TRAIN,\n\t[IB_7322_LT_STATE_CFGWAITENH] =\n\t\tIB_PHYSPORTSTATE_CFG_WAIT_ENH,\n\t[0x14] = IB_PHYSPORTSTATE_CFG_TRAIN,\n\t[0x15] = IB_PHYSPORTSTATE_CFG_TRAIN,\n\t[0x16] = IB_PHYSPORTSTATE_CFG_TRAIN,\n\t[0x17] = IB_PHYSPORTSTATE_CFG_TRAIN\n};\n\n#ifdef CONFIG_INFINIBAND_QIB_DCA\nstruct qib_irq_notify {\n\tint rcv;\n\tvoid *arg;\n\tstruct irq_affinity_notify notify;\n};\n#endif\n\nstruct qib_chip_specific {\n\tu64 __iomem *cregbase;\n\tu64 *cntrs;\n\tspinlock_t rcvmod_lock;  \n\tspinlock_t gpio_lock;  \n\tu64 main_int_mask;       \n\tu64 int_enable_mask;   \n\tu64 errormask;\n\tu64 hwerrmask;\n\tu64 gpio_out;  \n\tu64 gpio_mask;  \n\tu64 extctrl;  \n\tu32 ncntrs;\n\tu32 nportcntrs;\n\tu32 cntrnamelen;\n\tu32 portcntrnamelen;\n\tu32 numctxts;\n\tu32 rcvegrcnt;\n\tu32 updthresh;  \n\tu32 updthresh_dflt;  \n\tu32 r1;\n\tu32 num_msix_entries;\n\tu32 sdmabufcnt;\n\tu32 lastbuf_for_pio;\n\tu32 stay_in_freeze;\n\tu32 recovery_ports_initted;\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\tu32 dca_ctrl;\n\tint rhdr_cpu[18];\n\tint sdma_cpu[2];\n\tu64 dca_rcvhdr_ctrl[5];  \n#endif\n\tstruct qib_msix_entry *msix_entries;\n\tunsigned long *sendchkenable;\n\tunsigned long *sendgrhchk;\n\tunsigned long *sendibchk;\n\tu32 rcvavail_timeout[18];\n\tchar emsgbuf[128];  \n};\n\n \nstruct txdds_ent {\n\tu8 amp;\n\tu8 pre;\n\tu8 main;\n\tu8 post;\n};\n\nstruct vendor_txdds_ent {\n\tu8 oui[QSFP_VOUI_LEN];\n\tu8 *partnum;\n\tstruct txdds_ent sdr;\n\tstruct txdds_ent ddr;\n\tstruct txdds_ent qdr;\n};\n\nstatic void write_tx_serdes_param(struct qib_pportdata *, struct txdds_ent *);\n\n#define TXDDS_TABLE_SZ 16  \n#define TXDDS_EXTRA_SZ 18  \n#define TXDDS_MFG_SZ 2     \n#define SERDES_CHANS 4  \n\n#define H1_FORCE_VAL 8\n#define H1_FORCE_QME 1  \n#define H1_FORCE_QMH 7  \n\n \n#define krp_static_adapt_dis(spd) (KREG_IBPORT_IDX(ADAPT_DISABLE_STATIC_SDR) \\\n\t+ ((spd) * 2))\n\n#define QDR_DFE_DISABLE_DELAY 4000  \n#define QDR_STATIC_ADAPT_DOWN 0xf0f0f0f0ULL  \n#define QDR_STATIC_ADAPT_DOWN_R1 0ULL  \n#define QDR_STATIC_ADAPT_INIT 0xffffffffffULL  \n#define QDR_STATIC_ADAPT_INIT_R1 0xf0ffffffffULL  \n\nstruct qib_chippport_specific {\n\tu64 __iomem *kpregbase;\n\tu64 __iomem *cpregbase;\n\tu64 *portcntrs;\n\tstruct qib_pportdata *ppd;\n\twait_queue_head_t autoneg_wait;\n\tstruct delayed_work autoneg_work;\n\tstruct delayed_work ipg_work;\n\tstruct timer_list chase_timer;\n\t \n\tu64 ibdeltainprog;\n\tu64 ibsymdelta;\n\tu64 ibsymsnap;\n\tu64 iblnkerrdelta;\n\tu64 iblnkerrsnap;\n\tu64 iblnkdownsnap;\n\tu64 iblnkdowndelta;\n\tu64 ibmalfdelta;\n\tu64 ibmalfsnap;\n\tu64 ibcctrl_a;  \n\tu64 ibcctrl_b;  \n\tunsigned long qdr_dfe_time;\n\tunsigned long chase_end;\n\tu32 autoneg_tries;\n\tu32 recovery_init;\n\tu32 qdr_dfe_on;\n\tu32 qdr_reforce;\n\t \n\tu8 h1_val;\n\tu8 no_eep;   \n\tu8 ipg_tries;\n\tu8 ibmalfusesnap;\n\tstruct qib_qsfp_data qsfp_data;\n\tchar epmsgbuf[192];  \n\tchar sdmamsgbuf[192];  \n};\n\nstatic struct {\n\tconst char *name;\n\tirq_handler_t handler;\n\tint lsb;\n\tint port;  \n\tint dca;\n} irq_table[] = {\n\t{ \"\", qib_7322intr, -1, 0, 0 },\n\t{ \" (buf avail)\", qib_7322bufavail,\n\t\tSYM_LSB(IntStatus, SendBufAvail), 0, 0},\n\t{ \" (sdma 0)\", sdma_intr,\n\t\tSYM_LSB(IntStatus, SDmaInt_0), 1, 1 },\n\t{ \" (sdma 1)\", sdma_intr,\n\t\tSYM_LSB(IntStatus, SDmaInt_1), 2, 1 },\n\t{ \" (sdmaI 0)\", sdma_idle_intr,\n\t\tSYM_LSB(IntStatus, SDmaIdleInt_0), 1, 1},\n\t{ \" (sdmaI 1)\", sdma_idle_intr,\n\t\tSYM_LSB(IntStatus, SDmaIdleInt_1), 2, 1},\n\t{ \" (sdmaP 0)\", sdma_progress_intr,\n\t\tSYM_LSB(IntStatus, SDmaProgressInt_0), 1, 1 },\n\t{ \" (sdmaP 1)\", sdma_progress_intr,\n\t\tSYM_LSB(IntStatus, SDmaProgressInt_1), 2, 1 },\n\t{ \" (sdmaC 0)\", sdma_cleanup_intr,\n\t\tSYM_LSB(IntStatus, SDmaCleanupDone_0), 1, 0 },\n\t{ \" (sdmaC 1)\", sdma_cleanup_intr,\n\t\tSYM_LSB(IntStatus, SDmaCleanupDone_1), 2 , 0},\n};\n\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\nstatic const struct dca_reg_map {\n\tint     shadow_inx;\n\tint     lsb;\n\tu64     mask;\n\tu16     regno;\n} dca_rcvhdr_reg_map[] = {\n\t{ 0, SYM_LSB(DCACtrlB, RcvHdrq0DCAOPH),\n\t   ~SYM_MASK(DCACtrlB, RcvHdrq0DCAOPH) , KREG_IDX(DCACtrlB) },\n\t{ 0, SYM_LSB(DCACtrlB, RcvHdrq1DCAOPH),\n\t   ~SYM_MASK(DCACtrlB, RcvHdrq1DCAOPH) , KREG_IDX(DCACtrlB) },\n\t{ 0, SYM_LSB(DCACtrlB, RcvHdrq2DCAOPH),\n\t   ~SYM_MASK(DCACtrlB, RcvHdrq2DCAOPH) , KREG_IDX(DCACtrlB) },\n\t{ 0, SYM_LSB(DCACtrlB, RcvHdrq3DCAOPH),\n\t   ~SYM_MASK(DCACtrlB, RcvHdrq3DCAOPH) , KREG_IDX(DCACtrlB) },\n\t{ 1, SYM_LSB(DCACtrlC, RcvHdrq4DCAOPH),\n\t   ~SYM_MASK(DCACtrlC, RcvHdrq4DCAOPH) , KREG_IDX(DCACtrlC) },\n\t{ 1, SYM_LSB(DCACtrlC, RcvHdrq5DCAOPH),\n\t   ~SYM_MASK(DCACtrlC, RcvHdrq5DCAOPH) , KREG_IDX(DCACtrlC) },\n\t{ 1, SYM_LSB(DCACtrlC, RcvHdrq6DCAOPH),\n\t   ~SYM_MASK(DCACtrlC, RcvHdrq6DCAOPH) , KREG_IDX(DCACtrlC) },\n\t{ 1, SYM_LSB(DCACtrlC, RcvHdrq7DCAOPH),\n\t   ~SYM_MASK(DCACtrlC, RcvHdrq7DCAOPH) , KREG_IDX(DCACtrlC) },\n\t{ 2, SYM_LSB(DCACtrlD, RcvHdrq8DCAOPH),\n\t   ~SYM_MASK(DCACtrlD, RcvHdrq8DCAOPH) , KREG_IDX(DCACtrlD) },\n\t{ 2, SYM_LSB(DCACtrlD, RcvHdrq9DCAOPH),\n\t   ~SYM_MASK(DCACtrlD, RcvHdrq9DCAOPH) , KREG_IDX(DCACtrlD) },\n\t{ 2, SYM_LSB(DCACtrlD, RcvHdrq10DCAOPH),\n\t   ~SYM_MASK(DCACtrlD, RcvHdrq10DCAOPH) , KREG_IDX(DCACtrlD) },\n\t{ 2, SYM_LSB(DCACtrlD, RcvHdrq11DCAOPH),\n\t   ~SYM_MASK(DCACtrlD, RcvHdrq11DCAOPH) , KREG_IDX(DCACtrlD) },\n\t{ 3, SYM_LSB(DCACtrlE, RcvHdrq12DCAOPH),\n\t   ~SYM_MASK(DCACtrlE, RcvHdrq12DCAOPH) , KREG_IDX(DCACtrlE) },\n\t{ 3, SYM_LSB(DCACtrlE, RcvHdrq13DCAOPH),\n\t   ~SYM_MASK(DCACtrlE, RcvHdrq13DCAOPH) , KREG_IDX(DCACtrlE) },\n\t{ 3, SYM_LSB(DCACtrlE, RcvHdrq14DCAOPH),\n\t   ~SYM_MASK(DCACtrlE, RcvHdrq14DCAOPH) , KREG_IDX(DCACtrlE) },\n\t{ 3, SYM_LSB(DCACtrlE, RcvHdrq15DCAOPH),\n\t   ~SYM_MASK(DCACtrlE, RcvHdrq15DCAOPH) , KREG_IDX(DCACtrlE) },\n\t{ 4, SYM_LSB(DCACtrlF, RcvHdrq16DCAOPH),\n\t   ~SYM_MASK(DCACtrlF, RcvHdrq16DCAOPH) , KREG_IDX(DCACtrlF) },\n\t{ 4, SYM_LSB(DCACtrlF, RcvHdrq17DCAOPH),\n\t   ~SYM_MASK(DCACtrlF, RcvHdrq17DCAOPH) , KREG_IDX(DCACtrlF) },\n};\n#endif\n\n \n#define QLOGIC_IB_IBCC_LINKINITCMD_DISABLE 1\n \n#define QLOGIC_IB_IBCC_LINKINITCMD_POLL 2\n \n#define QLOGIC_IB_IBCC_LINKINITCMD_SLEEP 3\n#define QLOGIC_IB_IBCC_LINKINITCMD_SHIFT 16\n\n#define QLOGIC_IB_IBCC_LINKCMD_DOWN 1            \n#define QLOGIC_IB_IBCC_LINKCMD_ARMED 2           \n#define QLOGIC_IB_IBCC_LINKCMD_ACTIVE 3  \n\n#define BLOB_7322_IBCHG 0x101\n\nstatic inline void qib_write_kreg(const struct qib_devdata *dd,\n\t\t\t\t  const u32 regno, u64 value);\nstatic inline u32 qib_read_kreg32(const struct qib_devdata *, const u32);\nstatic void write_7322_initregs(struct qib_devdata *);\nstatic void write_7322_init_portregs(struct qib_pportdata *);\nstatic void setup_7322_link_recovery(struct qib_pportdata *, u32);\nstatic void check_7322_rxe_status(struct qib_pportdata *);\nstatic u32 __iomem *qib_7322_getsendbuf(struct qib_pportdata *, u64, u32 *);\n#ifdef CONFIG_INFINIBAND_QIB_DCA\nstatic void qib_setup_dca(struct qib_devdata *dd);\nstatic void setup_dca_notifier(struct qib_devdata *dd, int msixnum);\nstatic void reset_dca_notifier(struct qib_devdata *dd, int msixnum);\n#endif\n\n \nstatic inline u32 qib_read_ureg32(const struct qib_devdata *dd,\n\t\t\t\t  enum qib_ureg regno, int ctxt)\n{\n\tif (!dd->kregbase || !(dd->flags & QIB_PRESENT))\n\t\treturn 0;\n\treturn readl(regno + (u64 __iomem *)(\n\t\t(dd->ureg_align * ctxt) + (dd->userbase ?\n\t\t (char __iomem *)dd->userbase :\n\t\t (char __iomem *)dd->kregbase + dd->uregbase)));\n}\n\n \nstatic inline void qib_write_ureg(const struct qib_devdata *dd,\n\t\t\t\t  enum qib_ureg regno, u64 value, int ctxt)\n{\n\tu64 __iomem *ubase;\n\n\tif (dd->userbase)\n\t\tubase = (u64 __iomem *)\n\t\t\t((char __iomem *) dd->userbase +\n\t\t\t dd->ureg_align * ctxt);\n\telse\n\t\tubase = (u64 __iomem *)\n\t\t\t(dd->uregbase +\n\t\t\t (char __iomem *) dd->kregbase +\n\t\t\t dd->ureg_align * ctxt);\n\n\tif (dd->kregbase && (dd->flags & QIB_PRESENT))\n\t\twriteq(value, &ubase[regno]);\n}\n\nstatic inline u32 qib_read_kreg32(const struct qib_devdata *dd,\n\t\t\t\t  const u32 regno)\n{\n\tif (!dd->kregbase || !(dd->flags & QIB_PRESENT))\n\t\treturn -1;\n\treturn readl((u32 __iomem *) &dd->kregbase[regno]);\n}\n\nstatic inline u64 qib_read_kreg64(const struct qib_devdata *dd,\n\t\t\t\t  const u32 regno)\n{\n\tif (!dd->kregbase || !(dd->flags & QIB_PRESENT))\n\t\treturn -1;\n\treturn readq(&dd->kregbase[regno]);\n}\n\nstatic inline void qib_write_kreg(const struct qib_devdata *dd,\n\t\t\t\t  const u32 regno, u64 value)\n{\n\tif (dd->kregbase && (dd->flags & QIB_PRESENT))\n\t\twriteq(value, &dd->kregbase[regno]);\n}\n\n \nstatic inline u64 qib_read_kreg_port(const struct qib_pportdata *ppd,\n\t\t\t\t     const u16 regno)\n{\n\tif (!ppd->cpspec->kpregbase || !(ppd->dd->flags & QIB_PRESENT))\n\t\treturn 0ULL;\n\treturn readq(&ppd->cpspec->kpregbase[regno]);\n}\n\nstatic inline void qib_write_kreg_port(const struct qib_pportdata *ppd,\n\t\t\t\t       const u16 regno, u64 value)\n{\n\tif (ppd->cpspec && ppd->dd && ppd->cpspec->kpregbase &&\n\t    (ppd->dd->flags & QIB_PRESENT))\n\t\twriteq(value, &ppd->cpspec->kpregbase[regno]);\n}\n\n \nstatic inline void qib_write_kreg_ctxt(const struct qib_devdata *dd,\n\t\t\t\t       const u16 regno, unsigned ctxt,\n\t\t\t\t       u64 value)\n{\n\tqib_write_kreg(dd, regno + ctxt, value);\n}\n\nstatic inline u64 read_7322_creg(const struct qib_devdata *dd, u16 regno)\n{\n\tif (!dd->cspec->cregbase || !(dd->flags & QIB_PRESENT))\n\t\treturn 0;\n\treturn readq(&dd->cspec->cregbase[regno]);\n\n\n}\n\nstatic inline u32 read_7322_creg32(const struct qib_devdata *dd, u16 regno)\n{\n\tif (!dd->cspec->cregbase || !(dd->flags & QIB_PRESENT))\n\t\treturn 0;\n\treturn readl(&dd->cspec->cregbase[regno]);\n\n\n}\n\nstatic inline void write_7322_creg_port(const struct qib_pportdata *ppd,\n\t\t\t\t\tu16 regno, u64 value)\n{\n\tif (ppd->cpspec && ppd->cpspec->cpregbase &&\n\t    (ppd->dd->flags & QIB_PRESENT))\n\t\twriteq(value, &ppd->cpspec->cpregbase[regno]);\n}\n\nstatic inline u64 read_7322_creg_port(const struct qib_pportdata *ppd,\n\t\t\t\t      u16 regno)\n{\n\tif (!ppd->cpspec || !ppd->cpspec->cpregbase ||\n\t    !(ppd->dd->flags & QIB_PRESENT))\n\t\treturn 0;\n\treturn readq(&ppd->cpspec->cpregbase[regno]);\n}\n\nstatic inline u32 read_7322_creg32_port(const struct qib_pportdata *ppd,\n\t\t\t\t\tu16 regno)\n{\n\tif (!ppd->cpspec || !ppd->cpspec->cpregbase ||\n\t    !(ppd->dd->flags & QIB_PRESENT))\n\t\treturn 0;\n\treturn readl(&ppd->cpspec->cpregbase[regno]);\n}\n\n \n#define QLOGIC_IB_C_RESET SYM_MASK(Control, SyncReset)\n#define QLOGIC_IB_C_SDMAFETCHPRIOEN SYM_MASK(Control, SDmaDescFetchPriorityEn)\n\n \n#define QIB_I_RCVURG_LSB SYM_LSB(IntMask, RcvUrg0IntMask)\n#define QIB_I_RCVURG_RMASK MASK_ACROSS(0, 17)\n#define QIB_I_RCVURG_MASK (QIB_I_RCVURG_RMASK << QIB_I_RCVURG_LSB)\n#define QIB_I_RCVAVAIL_LSB SYM_LSB(IntMask, RcvAvail0IntMask)\n#define QIB_I_RCVAVAIL_RMASK MASK_ACROSS(0, 17)\n#define QIB_I_RCVAVAIL_MASK (QIB_I_RCVAVAIL_RMASK << QIB_I_RCVAVAIL_LSB)\n#define QIB_I_C_ERROR INT_MASK(Err)\n\n#define QIB_I_SPIOSENT (INT_MASK_P(SendDone, 0) | INT_MASK_P(SendDone, 1))\n#define QIB_I_SPIOBUFAVAIL INT_MASK(SendBufAvail)\n#define QIB_I_GPIO INT_MASK(AssertGPIO)\n#define QIB_I_P_SDMAINT(pidx) \\\n\t(INT_MASK_P(SDma, pidx) | INT_MASK_P(SDmaIdle, pidx) | \\\n\t INT_MASK_P(SDmaProgress, pidx) | \\\n\t INT_MASK_PM(SDmaCleanupDone, pidx))\n\n \n#define QIB_I_P_BITSEXTANT(pidx) \\\n\t(INT_MASK_P(Err, pidx) | INT_MASK_P(SendDone, pidx) | \\\n\tINT_MASK_P(SDma, pidx) | INT_MASK_P(SDmaIdle, pidx) | \\\n\tINT_MASK_P(SDmaProgress, pidx) | \\\n\tINT_MASK_PM(SDmaCleanupDone, pidx))\n\n \n \n#define QIB_I_C_BITSEXTANT \\\n\t(QIB_I_RCVURG_MASK | QIB_I_RCVAVAIL_MASK | \\\n\tQIB_I_SPIOSENT | \\\n\tQIB_I_C_ERROR | QIB_I_SPIOBUFAVAIL | QIB_I_GPIO)\n\n#define QIB_I_BITSEXTANT (QIB_I_C_BITSEXTANT | \\\n\tQIB_I_P_BITSEXTANT(0) | QIB_I_P_BITSEXTANT(1))\n\n \n#define QIB_E_P_IBSTATUSCHANGED ERR_MASK_N(IBStatusChanged)\n#define QIB_E_P_SHDR ERR_MASK_N(SHeadersErr)\n#define QIB_E_P_VL15_BUF_MISUSE ERR_MASK_N(VL15BufMisuseErr)\n#define QIB_E_P_SND_BUF_MISUSE ERR_MASK_N(SendBufMisuseErr)\n#define QIB_E_P_SUNSUPVL ERR_MASK_N(SendUnsupportedVLErr)\n#define QIB_E_P_SUNEXP_PKTNUM ERR_MASK_N(SendUnexpectedPktNumErr)\n#define QIB_E_P_SDROP_DATA ERR_MASK_N(SendDroppedDataPktErr)\n#define QIB_E_P_SDROP_SMP ERR_MASK_N(SendDroppedSmpPktErr)\n#define QIB_E_P_SPKTLEN ERR_MASK_N(SendPktLenErr)\n#define QIB_E_P_SUNDERRUN ERR_MASK_N(SendUnderRunErr)\n#define QIB_E_P_SMAXPKTLEN ERR_MASK_N(SendMaxPktLenErr)\n#define QIB_E_P_SMINPKTLEN ERR_MASK_N(SendMinPktLenErr)\n#define QIB_E_P_RIBLOSTLINK ERR_MASK_N(RcvIBLostLinkErr)\n#define QIB_E_P_RHDR ERR_MASK_N(RcvHdrErr)\n#define QIB_E_P_RHDRLEN ERR_MASK_N(RcvHdrLenErr)\n#define QIB_E_P_RBADTID ERR_MASK_N(RcvBadTidErr)\n#define QIB_E_P_RBADVERSION ERR_MASK_N(RcvBadVersionErr)\n#define QIB_E_P_RIBFLOW ERR_MASK_N(RcvIBFlowErr)\n#define QIB_E_P_REBP ERR_MASK_N(RcvEBPErr)\n#define QIB_E_P_RUNSUPVL ERR_MASK_N(RcvUnsupportedVLErr)\n#define QIB_E_P_RUNEXPCHAR ERR_MASK_N(RcvUnexpectedCharErr)\n#define QIB_E_P_RSHORTPKTLEN ERR_MASK_N(RcvShortPktLenErr)\n#define QIB_E_P_RLONGPKTLEN ERR_MASK_N(RcvLongPktLenErr)\n#define QIB_E_P_RMAXPKTLEN ERR_MASK_N(RcvMaxPktLenErr)\n#define QIB_E_P_RMINPKTLEN ERR_MASK_N(RcvMinPktLenErr)\n#define QIB_E_P_RICRC ERR_MASK_N(RcvICRCErr)\n#define QIB_E_P_RVCRC ERR_MASK_N(RcvVCRCErr)\n#define QIB_E_P_RFORMATERR ERR_MASK_N(RcvFormatErr)\n\n#define QIB_E_P_SDMA1STDESC ERR_MASK_N(SDma1stDescErr)\n#define QIB_E_P_SDMABASE ERR_MASK_N(SDmaBaseErr)\n#define QIB_E_P_SDMADESCADDRMISALIGN ERR_MASK_N(SDmaDescAddrMisalignErr)\n#define QIB_E_P_SDMADWEN ERR_MASK_N(SDmaDwEnErr)\n#define QIB_E_P_SDMAGENMISMATCH ERR_MASK_N(SDmaGenMismatchErr)\n#define QIB_E_P_SDMAHALT ERR_MASK_N(SDmaHaltErr)\n#define QIB_E_P_SDMAMISSINGDW ERR_MASK_N(SDmaMissingDwErr)\n#define QIB_E_P_SDMAOUTOFBOUND ERR_MASK_N(SDmaOutOfBoundErr)\n#define QIB_E_P_SDMARPYTAG ERR_MASK_N(SDmaRpyTagErr)\n#define QIB_E_P_SDMATAILOUTOFBOUND ERR_MASK_N(SDmaTailOutOfBoundErr)\n#define QIB_E_P_SDMAUNEXPDATA ERR_MASK_N(SDmaUnexpDataErr)\n\n \n#define QIB_E_RESET ERR_MASK(ResetNegated)\n#define QIB_E_HARDWARE ERR_MASK(HardwareErr)\n#define QIB_E_INVALIDADDR ERR_MASK(InvalidAddrErr)\n\n\n \n#define QIB_E_SBUF_VL15_MISUSE ERR_MASK(SBufVL15MisUseErr)\n#define QIB_E_BADEEP ERR_MASK(InvalidEEPCmd)\n#define QIB_E_VLMISMATCH ERR_MASK(SendVLMismatchErr)\n#define QIB_E_ARMLAUNCH ERR_MASK(SendArmLaunchErr)\n#define QIB_E_SPCLTRIG ERR_MASK(SendSpecialTriggerErr)\n#define QIB_E_RRCVHDRFULL ERR_MASK(RcvHdrFullErr)\n#define QIB_E_RRCVEGRFULL ERR_MASK(RcvEgrFullErr)\n#define QIB_E_RCVCTXTSHARE ERR_MASK(RcvContextShareErr)\n\n \n#define QIB_E_SDMA_VL15 ERR_MASK(SDmaVL15Err)\n#define QIB_E_SDMA_WRONG_PORT ERR_MASK(SDmaWrongPortErr)\n#define QIB_E_SDMA_BUF_DUP ERR_MASK(SDmaBufMaskDuplicateErr)\n\n \n#define QIB_E_P_PKTERRS (QIB_E_P_SPKTLEN |\\\n\tQIB_E_P_SDROP_DATA | QIB_E_P_RVCRC |\\\n\tQIB_E_P_RICRC | QIB_E_P_RSHORTPKTLEN |\\\n\tQIB_E_P_VL15_BUF_MISUSE | QIB_E_P_SHDR | \\\n\tQIB_E_P_REBP)\n\n \n#define QIB_E_P_RPKTERRS (\\\n\tQIB_E_P_RHDRLEN | QIB_E_P_RBADTID | \\\n\tQIB_E_P_RBADVERSION | QIB_E_P_RHDR | \\\n\tQIB_E_P_RLONGPKTLEN | QIB_E_P_RSHORTPKTLEN |\\\n\tQIB_E_P_RMAXPKTLEN | QIB_E_P_RMINPKTLEN | \\\n\tQIB_E_P_RFORMATERR | QIB_E_P_RUNSUPVL | \\\n\tQIB_E_P_RUNEXPCHAR | QIB_E_P_RIBFLOW | QIB_E_P_REBP)\n\n \n#define QIB_E_P_SPKTERRS (\\\n\tQIB_E_P_SUNEXP_PKTNUM |\\\n\tQIB_E_P_SDROP_DATA | QIB_E_P_SDROP_SMP |\\\n\tQIB_E_P_SMAXPKTLEN |\\\n\tQIB_E_P_VL15_BUF_MISUSE | QIB_E_P_SHDR | \\\n\tQIB_E_P_SMINPKTLEN | QIB_E_P_SPKTLEN | \\\n\tQIB_E_P_SND_BUF_MISUSE | QIB_E_P_SUNSUPVL)\n\n#define QIB_E_SPKTERRS ( \\\n\t\tQIB_E_SBUF_VL15_MISUSE | QIB_E_VLMISMATCH | \\\n\t\tERR_MASK_N(SendUnsupportedVLErr) |\t\t\t\\\n\t\tQIB_E_SPCLTRIG | QIB_E_SDMA_VL15 | QIB_E_SDMA_WRONG_PORT)\n\n#define QIB_E_P_SDMAERRS ( \\\n\tQIB_E_P_SDMAHALT | \\\n\tQIB_E_P_SDMADESCADDRMISALIGN | \\\n\tQIB_E_P_SDMAUNEXPDATA | \\\n\tQIB_E_P_SDMAMISSINGDW | \\\n\tQIB_E_P_SDMADWEN | \\\n\tQIB_E_P_SDMARPYTAG | \\\n\tQIB_E_P_SDMA1STDESC | \\\n\tQIB_E_P_SDMABASE | \\\n\tQIB_E_P_SDMATAILOUTOFBOUND | \\\n\tQIB_E_P_SDMAOUTOFBOUND | \\\n\tQIB_E_P_SDMAGENMISMATCH)\n\n \n#define QIB_E_P_BITSEXTANT ( \\\n\tQIB_E_P_SPKTERRS | QIB_E_P_PKTERRS | QIB_E_P_RPKTERRS | \\\n\tQIB_E_P_RIBLOSTLINK | QIB_E_P_IBSTATUSCHANGED | \\\n\tQIB_E_P_SND_BUF_MISUSE | QIB_E_P_SUNDERRUN | \\\n\tQIB_E_P_SHDR | QIB_E_P_VL15_BUF_MISUSE | QIB_E_P_SDMAERRS \\\n\t)\n\n \n#define QIB_E_P_LINK_PKTERRS (\\\n\tQIB_E_P_SDROP_DATA | QIB_E_P_SDROP_SMP |\\\n\tQIB_E_P_SMINPKTLEN | QIB_E_P_SPKTLEN |\\\n\tQIB_E_P_RSHORTPKTLEN | QIB_E_P_RMINPKTLEN |\\\n\tQIB_E_P_RUNEXPCHAR)\n\n \n#define QIB_E_C_BITSEXTANT (\\\n\tQIB_E_HARDWARE | QIB_E_INVALIDADDR | QIB_E_BADEEP |\\\n\tQIB_E_ARMLAUNCH | QIB_E_VLMISMATCH | QIB_E_RRCVHDRFULL |\\\n\tQIB_E_RRCVEGRFULL | QIB_E_RESET | QIB_E_SBUF_VL15_MISUSE)\n\n \n#define E_SPKT_ERRS_IGNORE 0\n\n#define QIB_EXTS_MEMBIST_DISABLED \\\n\tSYM_MASK(EXTStatus, MemBISTDisabled)\n#define QIB_EXTS_MEMBIST_ENDTEST \\\n\tSYM_MASK(EXTStatus, MemBISTEndTest)\n\n#define QIB_E_SPIOARMLAUNCH \\\n\tERR_MASK(SendArmLaunchErr)\n\n#define IBA7322_IBCC_LINKINITCMD_MASK SYM_RMASK(IBCCtrlA_0, LinkInitCmd)\n#define IBA7322_IBCC_LINKCMD_SHIFT SYM_LSB(IBCCtrlA_0, LinkCmd)\n\n \n#define IBA7322_IBC_IBTA_1_2_MASK SYM_MASK(IBCCtrlB_0, IB_ENHANCED_MODE)\n#define IBA7322_IBC_MAX_SPEED_MASK SYM_MASK(IBCCtrlB_0, SD_SPEED)\n#define IBA7322_IBC_SPEED_QDR SYM_MASK(IBCCtrlB_0, SD_SPEED_QDR)\n#define IBA7322_IBC_SPEED_DDR SYM_MASK(IBCCtrlB_0, SD_SPEED_DDR)\n#define IBA7322_IBC_SPEED_SDR SYM_MASK(IBCCtrlB_0, SD_SPEED_SDR)\n#define IBA7322_IBC_SPEED_MASK (SYM_MASK(IBCCtrlB_0, SD_SPEED_SDR) | \\\n\tSYM_MASK(IBCCtrlB_0, SD_SPEED_DDR) | SYM_MASK(IBCCtrlB_0, SD_SPEED_QDR))\n#define IBA7322_IBC_SPEED_LSB SYM_LSB(IBCCtrlB_0, SD_SPEED_SDR)\n\n#define IBA7322_LEDBLINK_OFF_SHIFT SYM_LSB(RcvPktLEDCnt_0, OFFperiod)\n#define IBA7322_LEDBLINK_ON_SHIFT SYM_LSB(RcvPktLEDCnt_0, ONperiod)\n\n#define IBA7322_IBC_WIDTH_AUTONEG SYM_MASK(IBCCtrlB_0, IB_NUM_CHANNELS)\n#define IBA7322_IBC_WIDTH_4X_ONLY (1<<SYM_LSB(IBCCtrlB_0, IB_NUM_CHANNELS))\n#define IBA7322_IBC_WIDTH_1X_ONLY (0<<SYM_LSB(IBCCtrlB_0, IB_NUM_CHANNELS))\n\n#define IBA7322_IBC_RXPOL_MASK SYM_MASK(IBCCtrlB_0, IB_POLARITY_REV_SUPP)\n#define IBA7322_IBC_RXPOL_LSB SYM_LSB(IBCCtrlB_0, IB_POLARITY_REV_SUPP)\n#define IBA7322_IBC_HRTBT_MASK (SYM_MASK(IBCCtrlB_0, HRTBT_AUTO) | \\\n\tSYM_MASK(IBCCtrlB_0, HRTBT_ENB))\n#define IBA7322_IBC_HRTBT_RMASK (IBA7322_IBC_HRTBT_MASK >> \\\n\tSYM_LSB(IBCCtrlB_0, HRTBT_ENB))\n#define IBA7322_IBC_HRTBT_LSB SYM_LSB(IBCCtrlB_0, HRTBT_ENB)\n\n#define IBA7322_REDIRECT_VEC_PER_REG 12\n\n#define IBA7322_SENDCHK_PKEY SYM_MASK(SendCheckControl_0, PKey_En)\n#define IBA7322_SENDCHK_BTHQP SYM_MASK(SendCheckControl_0, BTHQP_En)\n#define IBA7322_SENDCHK_SLID SYM_MASK(SendCheckControl_0, SLID_En)\n#define IBA7322_SENDCHK_RAW_IPV6 SYM_MASK(SendCheckControl_0, RawIPV6_En)\n#define IBA7322_SENDCHK_MINSZ SYM_MASK(SendCheckControl_0, PacketTooSmall_En)\n\n#define AUTONEG_TRIES 3  \n\n#define HWE_AUTO(fldname) { .mask = SYM_MASK(HwErrMask, fldname##Mask), \\\n\t.msg = #fldname , .sz = sizeof(#fldname) }\n#define HWE_AUTO_P(fldname, port) { .mask = SYM_MASK(HwErrMask, \\\n\tfldname##Mask##_##port), .msg = #fldname , .sz = sizeof(#fldname) }\nstatic const struct qib_hwerror_msgs qib_7322_hwerror_msgs[] = {\n\tHWE_AUTO_P(IBSerdesPClkNotDetect, 1),\n\tHWE_AUTO_P(IBSerdesPClkNotDetect, 0),\n\tHWE_AUTO(PCIESerdesPClkNotDetect),\n\tHWE_AUTO(PowerOnBISTFailed),\n\tHWE_AUTO(TempsenseTholdReached),\n\tHWE_AUTO(MemoryErr),\n\tHWE_AUTO(PCIeBusParityErr),\n\tHWE_AUTO(PcieCplTimeout),\n\tHWE_AUTO(PciePoisonedTLP),\n\tHWE_AUTO_P(SDmaMemReadErr, 1),\n\tHWE_AUTO_P(SDmaMemReadErr, 0),\n\tHWE_AUTO_P(IBCBusFromSPCParityErr, 1),\n\tHWE_AUTO_P(IBCBusToSPCParityErr, 1),\n\tHWE_AUTO_P(IBCBusFromSPCParityErr, 0),\n\tHWE_AUTO(statusValidNoEop),\n\tHWE_AUTO(LATriggered),\n\t{ .mask = 0, .sz = 0 }\n};\n\n#define E_AUTO(fldname) { .mask = SYM_MASK(ErrMask, fldname##Mask), \\\n\t.msg = #fldname, .sz = sizeof(#fldname) }\n#define E_P_AUTO(fldname) { .mask = SYM_MASK(ErrMask_0, fldname##Mask), \\\n\t.msg = #fldname, .sz = sizeof(#fldname) }\nstatic const struct qib_hwerror_msgs qib_7322error_msgs[] = {\n\tE_AUTO(RcvEgrFullErr),\n\tE_AUTO(RcvHdrFullErr),\n\tE_AUTO(ResetNegated),\n\tE_AUTO(HardwareErr),\n\tE_AUTO(InvalidAddrErr),\n\tE_AUTO(SDmaVL15Err),\n\tE_AUTO(SBufVL15MisUseErr),\n\tE_AUTO(InvalidEEPCmd),\n\tE_AUTO(RcvContextShareErr),\n\tE_AUTO(SendVLMismatchErr),\n\tE_AUTO(SendArmLaunchErr),\n\tE_AUTO(SendSpecialTriggerErr),\n\tE_AUTO(SDmaWrongPortErr),\n\tE_AUTO(SDmaBufMaskDuplicateErr),\n\t{ .mask = 0, .sz = 0 }\n};\n\nstatic const struct  qib_hwerror_msgs qib_7322p_error_msgs[] = {\n\tE_P_AUTO(IBStatusChanged),\n\tE_P_AUTO(SHeadersErr),\n\tE_P_AUTO(VL15BufMisuseErr),\n\t \n\t{.mask = SYM_MASK(ErrMask_0, SDmaHaltErrMask), .msg = \"SDmaHalted\",\n\t\t.sz = 11},\n\tE_P_AUTO(SDmaDescAddrMisalignErr),\n\tE_P_AUTO(SDmaUnexpDataErr),\n\tE_P_AUTO(SDmaMissingDwErr),\n\tE_P_AUTO(SDmaDwEnErr),\n\tE_P_AUTO(SDmaRpyTagErr),\n\tE_P_AUTO(SDma1stDescErr),\n\tE_P_AUTO(SDmaBaseErr),\n\tE_P_AUTO(SDmaTailOutOfBoundErr),\n\tE_P_AUTO(SDmaOutOfBoundErr),\n\tE_P_AUTO(SDmaGenMismatchErr),\n\tE_P_AUTO(SendBufMisuseErr),\n\tE_P_AUTO(SendUnsupportedVLErr),\n\tE_P_AUTO(SendUnexpectedPktNumErr),\n\tE_P_AUTO(SendDroppedDataPktErr),\n\tE_P_AUTO(SendDroppedSmpPktErr),\n\tE_P_AUTO(SendPktLenErr),\n\tE_P_AUTO(SendUnderRunErr),\n\tE_P_AUTO(SendMaxPktLenErr),\n\tE_P_AUTO(SendMinPktLenErr),\n\tE_P_AUTO(RcvIBLostLinkErr),\n\tE_P_AUTO(RcvHdrErr),\n\tE_P_AUTO(RcvHdrLenErr),\n\tE_P_AUTO(RcvBadTidErr),\n\tE_P_AUTO(RcvBadVersionErr),\n\tE_P_AUTO(RcvIBFlowErr),\n\tE_P_AUTO(RcvEBPErr),\n\tE_P_AUTO(RcvUnsupportedVLErr),\n\tE_P_AUTO(RcvUnexpectedCharErr),\n\tE_P_AUTO(RcvShortPktLenErr),\n\tE_P_AUTO(RcvLongPktLenErr),\n\tE_P_AUTO(RcvMaxPktLenErr),\n\tE_P_AUTO(RcvMinPktLenErr),\n\tE_P_AUTO(RcvICRCErr),\n\tE_P_AUTO(RcvVCRCErr),\n\tE_P_AUTO(RcvFormatErr),\n\t{ .mask = 0, .sz = 0 }\n};\n\n \n#define INTR_AUTO(fldname) { .mask = SYM_MASK(IntMask, fldname##Mask), \\\n\t.msg = #fldname, .sz = sizeof(#fldname) }\n \n#define INTR_AUTO_P(fldname) { .mask = MASK_ACROSS(\\\n\tSYM_LSB(IntMask, fldname##Mask##_0), \\\n\tSYM_LSB(IntMask, fldname##Mask##_1)), \\\n\t.msg = #fldname \"_P\", .sz = sizeof(#fldname \"_P\") }\n \n#define INTR_AUTO_PI(fldname) { .mask = MASK_ACROSS(\\\n\tSYM_LSB(IntMask, fldname##Mask##_1), \\\n\tSYM_LSB(IntMask, fldname##Mask##_0)), \\\n\t.msg = #fldname \"_P\", .sz = sizeof(#fldname \"_P\") }\n \n#define INTR_AUTO_C(fldname) { .mask = MASK_ACROSS(\\\n\tSYM_LSB(IntMask, fldname##0IntMask), \\\n\tSYM_LSB(IntMask, fldname##17IntMask)), \\\n\t.msg = #fldname \"_C\", .sz = sizeof(#fldname \"_C\") }\n\n#define TXSYMPTOM_AUTO_P(fldname) \\\n\t{ .mask = SYM_MASK(SendHdrErrSymptom_0, fldname), \\\n\t.msg = #fldname, .sz = sizeof(#fldname) }\nstatic const struct  qib_hwerror_msgs hdrchk_msgs[] = {\n\tTXSYMPTOM_AUTO_P(NonKeyPacket),\n\tTXSYMPTOM_AUTO_P(GRHFail),\n\tTXSYMPTOM_AUTO_P(PkeyFail),\n\tTXSYMPTOM_AUTO_P(QPFail),\n\tTXSYMPTOM_AUTO_P(SLIDFail),\n\tTXSYMPTOM_AUTO_P(RawIPV6),\n\tTXSYMPTOM_AUTO_P(PacketTooSmall),\n\t{ .mask = 0, .sz = 0 }\n};\n\n#define IBA7322_HDRHEAD_PKTINT_SHIFT 32  \n\n \nstatic void qib_disarm_7322_senderrbufs(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu32 i;\n\tint any;\n\tu32 piobcnt = dd->piobcnt2k + dd->piobcnt4k + NUM_VL15_BUFS;\n\tu32 regcnt = (piobcnt + BITS_PER_LONG - 1) / BITS_PER_LONG;\n\tunsigned long sbuf[4];\n\n\t \n\tany = 0;\n\tfor (i = 0; i < regcnt; ++i) {\n\t\tsbuf[i] = qib_read_kreg64(dd, kr_sendbuffererror + i);\n\t\tif (sbuf[i]) {\n\t\t\tany = 1;\n\t\t\tqib_write_kreg(dd, kr_sendbuffererror + i, sbuf[i]);\n\t\t}\n\t}\n\n\tif (any)\n\t\tqib_disarm_piobufs_set(dd, sbuf, piobcnt);\n}\n\n \n\n \nstatic void err_decode(char *msg, size_t len, u64 errs,\n\t\t       const struct qib_hwerror_msgs *msp)\n{\n\tu64 these, lmask;\n\tint took, multi, n = 0;\n\n\twhile (errs && msp && msp->mask) {\n\t\tmulti = (msp->mask & (msp->mask - 1));\n\t\twhile (errs & msp->mask) {\n\t\t\tthese = (errs & msp->mask);\n\t\t\tlmask = (these & (these - 1)) ^ these;\n\t\t\tif (len) {\n\t\t\t\tif (n++) {\n\t\t\t\t\t \n\t\t\t\t\t*msg++ = ',';\n\t\t\t\t\tlen--;\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\ttook = min_t(size_t, msp->sz - (size_t)1, len);\n\t\t\t\tmemcpy(msg,  msp->msg, took);\n\t\t\t\tlen -= took;\n\t\t\t\tmsg += took;\n\t\t\t\tif (len)\n\t\t\t\t\t*msg = '\\0';\n\t\t\t}\n\t\t\terrs &= ~lmask;\n\t\t\tif (len && multi) {\n\t\t\t\t \n\t\t\t\tint idx = -1;\n\n\t\t\t\twhile (lmask & msp->mask) {\n\t\t\t\t\t++idx;\n\t\t\t\t\tlmask >>= 1;\n\t\t\t\t}\n\t\t\t\ttook = scnprintf(msg, len, \"_%d\", idx);\n\t\t\t\tlen -= took;\n\t\t\t\tmsg += took;\n\t\t\t}\n\t\t}\n\t\t++msp;\n\t}\n\t \n\tif (len && errs)\n\t\tsnprintf(msg, len, \"%sMORE:%llX\", n ? \",\" : \"\",\n\t\t\t(unsigned long long) errs);\n}\n\n \nstatic void flush_fifo(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu32 __iomem *piobuf;\n\tu32 bufn;\n\tu32 *hdr;\n\tu64 pbc;\n\tconst unsigned hdrwords = 7;\n\tstatic struct ib_header ibhdr = {\n\t\t.lrh[0] = cpu_to_be16(0xF000 | QIB_LRH_BTH),\n\t\t.lrh[1] = IB_LID_PERMISSIVE,\n\t\t.lrh[2] = cpu_to_be16(hdrwords + SIZE_OF_CRC),\n\t\t.lrh[3] = IB_LID_PERMISSIVE,\n\t\t.u.oth.bth[0] = cpu_to_be32(\n\t\t\t(IB_OPCODE_UD_SEND_ONLY << 24) | QIB_DEFAULT_P_KEY),\n\t\t.u.oth.bth[1] = cpu_to_be32(0),\n\t\t.u.oth.bth[2] = cpu_to_be32(0),\n\t\t.u.oth.u.ud.deth[0] = cpu_to_be32(0),\n\t\t.u.oth.u.ud.deth[1] = cpu_to_be32(0),\n\t};\n\n\t \n\tpbc = PBC_7322_VL15_SEND |\n\t\t(((u64)ppd->hw_pidx) << (PBC_PORT_SEL_LSB + 32)) |\n\t\t(hdrwords + SIZE_OF_CRC);\n\tpiobuf = qib_7322_getsendbuf(ppd, pbc, &bufn);\n\tif (!piobuf)\n\t\treturn;\n\twriteq(pbc, piobuf);\n\thdr = (u32 *) &ibhdr;\n\tif (dd->flags & QIB_PIO_FLUSH_WC) {\n\t\tqib_flush_wc();\n\t\tqib_pio_copy(piobuf + 2, hdr, hdrwords - 1);\n\t\tqib_flush_wc();\n\t\t__raw_writel(hdr[hdrwords - 1], piobuf + hdrwords + 1);\n\t\tqib_flush_wc();\n\t} else\n\t\tqib_pio_copy(piobuf + 2, hdr, hdrwords);\n\tqib_sendbuf_done(dd, bufn);\n}\n\n \nstatic void qib_7322_sdma_sendctrl(struct qib_pportdata *ppd, unsigned op)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 set_sendctrl = 0;\n\tu64 clr_sendctrl = 0;\n\n\tif (op & QIB_SDMA_SENDCTRL_OP_ENABLE)\n\t\tset_sendctrl |= SYM_MASK(SendCtrl_0, SDmaEnable);\n\telse\n\t\tclr_sendctrl |= SYM_MASK(SendCtrl_0, SDmaEnable);\n\n\tif (op & QIB_SDMA_SENDCTRL_OP_INTENABLE)\n\t\tset_sendctrl |= SYM_MASK(SendCtrl_0, SDmaIntEnable);\n\telse\n\t\tclr_sendctrl |= SYM_MASK(SendCtrl_0, SDmaIntEnable);\n\n\tif (op & QIB_SDMA_SENDCTRL_OP_HALT)\n\t\tset_sendctrl |= SYM_MASK(SendCtrl_0, SDmaHalt);\n\telse\n\t\tclr_sendctrl |= SYM_MASK(SendCtrl_0, SDmaHalt);\n\n\tif (op & QIB_SDMA_SENDCTRL_OP_DRAIN)\n\t\tset_sendctrl |= SYM_MASK(SendCtrl_0, TxeBypassIbc) |\n\t\t\t\tSYM_MASK(SendCtrl_0, TxeAbortIbc) |\n\t\t\t\tSYM_MASK(SendCtrl_0, TxeDrainRmFifo);\n\telse\n\t\tclr_sendctrl |= SYM_MASK(SendCtrl_0, TxeBypassIbc) |\n\t\t\t\tSYM_MASK(SendCtrl_0, TxeAbortIbc) |\n\t\t\t\tSYM_MASK(SendCtrl_0, TxeDrainRmFifo);\n\n\tspin_lock(&dd->sendctrl_lock);\n\n\t \n\tif (op & QIB_SDMA_SENDCTRL_OP_DRAIN) {\n\t\tppd->p_sendctrl &= ~SYM_MASK(SendCtrl_0, SendEnable);\n\t\tqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\n\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t}\n\n\tppd->p_sendctrl |= set_sendctrl;\n\tppd->p_sendctrl &= ~clr_sendctrl;\n\n\tif (op & QIB_SDMA_SENDCTRL_OP_CLEANUP)\n\t\tqib_write_kreg_port(ppd, krp_sendctrl,\n\t\t\t\t    ppd->p_sendctrl |\n\t\t\t\t    SYM_MASK(SendCtrl_0, SDmaCleanup));\n\telse\n\t\tqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\n\tqib_write_kreg(dd, kr_scratch, 0);\n\n\tif (op & QIB_SDMA_SENDCTRL_OP_DRAIN) {\n\t\tppd->p_sendctrl |= SYM_MASK(SendCtrl_0, SendEnable);\n\t\tqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\n\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t}\n\n\tspin_unlock(&dd->sendctrl_lock);\n\n\tif ((op & QIB_SDMA_SENDCTRL_OP_DRAIN) && ppd->dd->cspec->r1)\n\t\tflush_fifo(ppd);\n}\n\nstatic void qib_7322_sdma_hw_clean_up(struct qib_pportdata *ppd)\n{\n\t__qib_sdma_process_event(ppd, qib_sdma_event_e50_hw_cleaned);\n}\n\nstatic void qib_sdma_7322_setlengen(struct qib_pportdata *ppd)\n{\n\t \n\tqib_write_kreg_port(ppd, krp_senddmalengen, ppd->sdma_descq_cnt);\n\tqib_write_kreg_port(ppd, krp_senddmalengen,\n\t\t\t    ppd->sdma_descq_cnt |\n\t\t\t    (1ULL << QIB_7322_SendDmaLenGen_0_Generation_MSB));\n}\n\n \nstatic void qib_sdma_update_7322_tail(struct qib_pportdata *ppd, u16 tail)\n{\n\t \n\twmb();\n\tppd->sdma_descq_tail = tail;\n\tqib_write_kreg_port(ppd, krp_senddmatail, tail);\n}\n\n \nstatic void qib_7322_sdma_hw_start_up(struct qib_pportdata *ppd)\n{\n\t \n\tsendctrl_7322_mod(ppd, QIB_SENDCTRL_FLUSH);\n\n\tqib_sdma_7322_setlengen(ppd);\n\tqib_sdma_update_7322_tail(ppd, 0);  \n\tppd->sdma_head_dma[0] = 0;\n\tqib_7322_sdma_sendctrl(ppd,\n\t\tppd->sdma_state.current_op | QIB_SDMA_SENDCTRL_OP_CLEANUP);\n}\n\n#define DISABLES_SDMA ( \\\n\tQIB_E_P_SDMAHALT | \\\n\tQIB_E_P_SDMADESCADDRMISALIGN | \\\n\tQIB_E_P_SDMAMISSINGDW | \\\n\tQIB_E_P_SDMADWEN | \\\n\tQIB_E_P_SDMARPYTAG | \\\n\tQIB_E_P_SDMA1STDESC | \\\n\tQIB_E_P_SDMABASE | \\\n\tQIB_E_P_SDMATAILOUTOFBOUND | \\\n\tQIB_E_P_SDMAOUTOFBOUND | \\\n\tQIB_E_P_SDMAGENMISMATCH)\n\nstatic void sdma_7322_p_errors(struct qib_pportdata *ppd, u64 errs)\n{\n\tunsigned long flags;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\terrs &= QIB_E_P_SDMAERRS;\n\terr_decode(ppd->cpspec->sdmamsgbuf, sizeof(ppd->cpspec->sdmamsgbuf),\n\t\t   errs, qib_7322p_error_msgs);\n\n\tif (errs & QIB_E_P_SDMAUNEXPDATA)\n\t\tqib_dev_err(dd, \"IB%u:%u SDmaUnexpData\\n\", dd->unit,\n\t\t\t    ppd->port);\n\n\tspin_lock_irqsave(&ppd->sdma_lock, flags);\n\n\tif (errs != QIB_E_P_SDMAHALT) {\n\t\t \n\t\tqib_dev_porterr(dd, ppd->port,\n\t\t\t\"SDMA %s 0x%016llx %s\\n\",\n\t\t\tqib_sdma_state_names[ppd->sdma_state.current_state],\n\t\t\terrs, ppd->cpspec->sdmamsgbuf);\n\t\tdump_sdma_7322_state(ppd);\n\t}\n\n\tswitch (ppd->sdma_state.current_state) {\n\tcase qib_sdma_state_s00_hw_down:\n\t\tbreak;\n\n\tcase qib_sdma_state_s10_hw_start_up_wait:\n\t\tif (errs & QIB_E_P_SDMAHALT)\n\t\t\t__qib_sdma_process_event(ppd,\n\t\t\t\tqib_sdma_event_e20_hw_started);\n\t\tbreak;\n\n\tcase qib_sdma_state_s20_idle:\n\t\tbreak;\n\n\tcase qib_sdma_state_s30_sw_clean_up_wait:\n\t\tbreak;\n\n\tcase qib_sdma_state_s40_hw_clean_up_wait:\n\t\tif (errs & QIB_E_P_SDMAHALT)\n\t\t\t__qib_sdma_process_event(ppd,\n\t\t\t\tqib_sdma_event_e50_hw_cleaned);\n\t\tbreak;\n\n\tcase qib_sdma_state_s50_hw_halt_wait:\n\t\tif (errs & QIB_E_P_SDMAHALT)\n\t\t\t__qib_sdma_process_event(ppd,\n\t\t\t\tqib_sdma_event_e60_hw_halted);\n\t\tbreak;\n\n\tcase qib_sdma_state_s99_running:\n\t\t__qib_sdma_process_event(ppd, qib_sdma_event_e7322_err_halted);\n\t\t__qib_sdma_process_event(ppd, qib_sdma_event_e60_hw_halted);\n\t\tbreak;\n\t}\n\n\tspin_unlock_irqrestore(&ppd->sdma_lock, flags);\n}\n\n \nstatic noinline void handle_7322_errors(struct qib_devdata *dd)\n{\n\tchar *msg;\n\tu64 iserr = 0;\n\tu64 errs;\n\tu64 mask;\n\n\tqib_stats.sps_errints++;\n\terrs = qib_read_kreg64(dd, kr_errstatus);\n\tif (!errs) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"device error interrupt, but no error bits set!\\n\");\n\t\tgoto done;\n\t}\n\n\t \n\terrs &= dd->cspec->errormask;\n\tmsg = dd->cspec->emsgbuf;\n\n\t \n\tif (errs & QIB_E_HARDWARE) {\n\t\t*msg = '\\0';\n\t\tqib_7322_handle_hwerrors(dd, msg, sizeof(dd->cspec->emsgbuf));\n\t}\n\n\tif (errs & QIB_E_SPKTERRS) {\n\t\tqib_disarm_7322_senderrbufs(dd->pport);\n\t\tqib_stats.sps_txerrs++;\n\t} else if (errs & QIB_E_INVALIDADDR)\n\t\tqib_stats.sps_txerrs++;\n\telse if (errs & QIB_E_ARMLAUNCH) {\n\t\tqib_stats.sps_txerrs++;\n\t\tqib_disarm_7322_senderrbufs(dd->pport);\n\t}\n\tqib_write_kreg(dd, kr_errclear, errs);\n\n\t \n\tmask = QIB_E_HARDWARE;\n\t*msg = '\\0';\n\n\terr_decode(msg, sizeof(dd->cspec->emsgbuf), errs & ~mask,\n\t\t   qib_7322error_msgs);\n\n\t \n\tif (errs & QIB_E_RESET) {\n\t\tint pidx;\n\n\t\tqib_dev_err(dd,\n\t\t\t\"Got reset, requires re-init (unload and reload driver)\\n\");\n\t\tdd->flags &= ~QIB_INITTED;   \n\t\t \n\t\t*dd->devstatusp |= QIB_STATUS_HWERROR;\n\t\tfor (pidx = 0; pidx < dd->num_pports; ++pidx)\n\t\t\tif (dd->pport[pidx].link_speed_supported)\n\t\t\t\t*dd->pport[pidx].statusp &= ~QIB_STATUS_IB_CONF;\n\t}\n\n\tif (*msg && iserr)\n\t\tqib_dev_err(dd, \"%s error\\n\", msg);\n\n\t \n\tif (errs & (ERR_MASK(RcvEgrFullErr) | ERR_MASK(RcvHdrFullErr))) {\n\t\tqib_handle_urcv(dd, ~0U);\n\t\tif (errs & ERR_MASK(RcvEgrFullErr))\n\t\t\tqib_stats.sps_buffull++;\n\t\telse\n\t\t\tqib_stats.sps_hdrfull++;\n\t}\n\ndone:\n\treturn;\n}\n\nstatic void qib_error_tasklet(struct tasklet_struct *t)\n{\n\tstruct qib_devdata *dd = from_tasklet(dd, t, error_tasklet);\n\n\thandle_7322_errors(dd);\n\tqib_write_kreg(dd, kr_errmask, dd->cspec->errormask);\n}\n\nstatic void reenable_chase(struct timer_list *t)\n{\n\tstruct qib_chippport_specific *cp = from_timer(cp, t, chase_timer);\n\tstruct qib_pportdata *ppd = cp->ppd;\n\n\tppd->cpspec->chase_timer.expires = 0;\n\tqib_set_ib_7322_lstate(ppd, QLOGIC_IB_IBCC_LINKCMD_DOWN,\n\t\tQLOGIC_IB_IBCC_LINKINITCMD_POLL);\n}\n\nstatic void disable_chase(struct qib_pportdata *ppd, unsigned long tnow,\n\t\tu8 ibclt)\n{\n\tppd->cpspec->chase_end = 0;\n\n\tif (!qib_chase)\n\t\treturn;\n\n\tqib_set_ib_7322_lstate(ppd, QLOGIC_IB_IBCC_LINKCMD_DOWN,\n\t\tQLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\n\tppd->cpspec->chase_timer.expires = jiffies + QIB_CHASE_DIS_TIME;\n\tadd_timer(&ppd->cpspec->chase_timer);\n}\n\nstatic void handle_serdes_issues(struct qib_pportdata *ppd, u64 ibcst)\n{\n\tu8 ibclt;\n\tunsigned long tnow;\n\n\tibclt = (u8)SYM_FIELD(ibcst, IBCStatusA_0, LinkTrainingState);\n\n\t \n\tswitch (ibclt) {\n\tcase IB_7322_LT_STATE_CFGRCVFCFG:\n\tcase IB_7322_LT_STATE_CFGWAITRMT:\n\tcase IB_7322_LT_STATE_TXREVLANES:\n\tcase IB_7322_LT_STATE_CFGENH:\n\t\ttnow = jiffies;\n\t\tif (ppd->cpspec->chase_end &&\n\t\t     time_after(tnow, ppd->cpspec->chase_end))\n\t\t\tdisable_chase(ppd, tnow, ibclt);\n\t\telse if (!ppd->cpspec->chase_end)\n\t\t\tppd->cpspec->chase_end = tnow + QIB_CHASE_TIME;\n\t\tbreak;\n\tdefault:\n\t\tppd->cpspec->chase_end = 0;\n\t\tbreak;\n\t}\n\n\tif (((ibclt >= IB_7322_LT_STATE_CFGTEST &&\n\t      ibclt <= IB_7322_LT_STATE_CFGWAITENH) ||\n\t     ibclt == IB_7322_LT_STATE_LINKUP) &&\n\t    (ibcst & SYM_MASK(IBCStatusA_0, LinkSpeedQDR))) {\n\t\tforce_h1(ppd);\n\t\tppd->cpspec->qdr_reforce = 1;\n\t\tif (!ppd->dd->cspec->r1)\n\t\t\tserdes_7322_los_enable(ppd, 0);\n\t} else if (ppd->cpspec->qdr_reforce &&\n\t\t(ibcst & SYM_MASK(IBCStatusA_0, LinkSpeedQDR)) &&\n\t\t (ibclt == IB_7322_LT_STATE_CFGENH ||\n\t\tibclt == IB_7322_LT_STATE_CFGIDLE ||\n\t\tibclt == IB_7322_LT_STATE_LINKUP))\n\t\tforce_h1(ppd);\n\n\tif ((IS_QMH(ppd->dd) || IS_QME(ppd->dd)) &&\n\t    ppd->link_speed_enabled == QIB_IB_QDR &&\n\t    (ibclt == IB_7322_LT_STATE_CFGTEST ||\n\t     ibclt == IB_7322_LT_STATE_CFGENH ||\n\t     (ibclt >= IB_7322_LT_STATE_POLLACTIVE &&\n\t      ibclt <= IB_7322_LT_STATE_SLEEPQUIET)))\n\t\tadj_tx_serdes(ppd);\n\n\tif (ibclt != IB_7322_LT_STATE_LINKUP) {\n\t\tu8 ltstate = qib_7322_phys_portstate(ibcst);\n\t\tu8 pibclt = (u8)SYM_FIELD(ppd->lastibcstat, IBCStatusA_0,\n\t\t\t\t\t  LinkTrainingState);\n\t\tif (!ppd->dd->cspec->r1 &&\n\t\t    pibclt == IB_7322_LT_STATE_LINKUP &&\n\t\t    ltstate != IB_PHYSPORTSTATE_LINK_ERR_RECOVER &&\n\t\t    ltstate != IB_PHYSPORTSTATE_RECOVERY_RETRAIN &&\n\t\t    ltstate != IB_PHYSPORTSTATE_RECOVERY_WAITRMT &&\n\t\t    ltstate != IB_PHYSPORTSTATE_RECOVERY_IDLE)\n\t\t\t \n\t\t\tserdes_7322_los_enable(ppd, 1);\n\t\tif (!ppd->cpspec->qdr_dfe_on &&\n\t\t    ibclt <= IB_7322_LT_STATE_SLEEPQUIET) {\n\t\t\tppd->cpspec->qdr_dfe_on = 1;\n\t\t\tppd->cpspec->qdr_dfe_time = 0;\n\t\t\t \n\t\t\tqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\n\t\t\t\t\t    ppd->dd->cspec->r1 ?\n\t\t\t\t\t    QDR_STATIC_ADAPT_DOWN_R1 :\n\t\t\t\t\t    QDR_STATIC_ADAPT_DOWN);\n\t\t\tpr_info(\n\t\t\t\t\"IB%u:%u re-enabled QDR adaptation ibclt %x\\n\",\n\t\t\t\tppd->dd->unit, ppd->port, ibclt);\n\t\t}\n\t}\n}\n\nstatic int qib_7322_set_ib_cfg(struct qib_pportdata *, int, u32);\n\n \nstatic noinline void handle_7322_p_errors(struct qib_pportdata *ppd)\n{\n\tchar *msg;\n\tu64 ignore_this_time = 0, iserr = 0, errs, fmask;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\t \n\tfmask = qib_read_kreg64(dd, kr_act_fmask);\n\tif (!fmask)\n\t\tcheck_7322_rxe_status(ppd);\n\n\terrs = qib_read_kreg_port(ppd, krp_errstatus);\n\tif (!errs)\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t \"Port%d error interrupt, but no error bits set!\\n\",\n\t\t\t ppd->port);\n\tif (!fmask)\n\t\terrs &= ~QIB_E_P_IBSTATUSCHANGED;\n\tif (!errs)\n\t\tgoto done;\n\n\tmsg = ppd->cpspec->epmsgbuf;\n\t*msg = '\\0';\n\n\tif (errs & ~QIB_E_P_BITSEXTANT) {\n\t\terr_decode(msg, sizeof(ppd->cpspec->epmsgbuf),\n\t\t\t   errs & ~QIB_E_P_BITSEXTANT, qib_7322p_error_msgs);\n\t\tif (!*msg)\n\t\t\tsnprintf(msg, sizeof(ppd->cpspec->epmsgbuf),\n\t\t\t\t \"no others\");\n\t\tqib_dev_porterr(dd, ppd->port,\n\t\t\t\"error interrupt with unknown errors 0x%016Lx set (and %s)\\n\",\n\t\t\t(errs & ~QIB_E_P_BITSEXTANT), msg);\n\t\t*msg = '\\0';\n\t}\n\n\tif (errs & QIB_E_P_SHDR) {\n\t\tu64 symptom;\n\n\t\t \n\t\tsymptom = qib_read_kreg_port(ppd, krp_sendhdrsymptom);\n\t\tqib_write_kreg_port(ppd, krp_sendhdrsymptom, 0);\n\t\terr_decode(msg, sizeof(ppd->cpspec->epmsgbuf), symptom,\n\t\t\t   hdrchk_msgs);\n\t\t*msg = '\\0';\n\t\t \n\t}\n\n\tif (errs & QIB_E_P_SPKTERRS) {\n\t\tif ((errs & QIB_E_P_LINK_PKTERRS) &&\n\t\t    !(ppd->lflags & QIBL_LINKACTIVE)) {\n\t\t\t \n\t\t\terr_decode(msg, sizeof(ppd->cpspec->epmsgbuf),\n\t\t\t\t   (errs & QIB_E_P_LINK_PKTERRS),\n\t\t\t\t   qib_7322p_error_msgs);\n\t\t\t*msg = '\\0';\n\t\t\tignore_this_time = errs & QIB_E_P_LINK_PKTERRS;\n\t\t}\n\t\tqib_disarm_7322_senderrbufs(ppd);\n\t} else if ((errs & QIB_E_P_LINK_PKTERRS) &&\n\t\t   !(ppd->lflags & QIBL_LINKACTIVE)) {\n\t\t \n\t\terr_decode(msg, sizeof(ppd->cpspec->epmsgbuf), errs,\n\t\t\t   qib_7322p_error_msgs);\n\t\tignore_this_time = errs & QIB_E_P_LINK_PKTERRS;\n\t\t*msg = '\\0';\n\t}\n\n\tqib_write_kreg_port(ppd, krp_errclear, errs);\n\n\terrs &= ~ignore_this_time;\n\tif (!errs)\n\t\tgoto done;\n\n\tif (errs & QIB_E_P_RPKTERRS)\n\t\tqib_stats.sps_rcverrs++;\n\tif (errs & QIB_E_P_SPKTERRS)\n\t\tqib_stats.sps_txerrs++;\n\n\tiserr = errs & ~(QIB_E_P_RPKTERRS | QIB_E_P_PKTERRS);\n\n\tif (errs & QIB_E_P_SDMAERRS)\n\t\tsdma_7322_p_errors(ppd, errs);\n\n\tif (errs & QIB_E_P_IBSTATUSCHANGED) {\n\t\tu64 ibcs;\n\t\tu8 ltstate;\n\n\t\tibcs = qib_read_kreg_port(ppd, krp_ibcstatus_a);\n\t\tltstate = qib_7322_phys_portstate(ibcs);\n\n\t\tif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG))\n\t\t\thandle_serdes_issues(ppd, ibcs);\n\t\tif (!(ppd->cpspec->ibcctrl_a &\n\t\t      SYM_MASK(IBCCtrlA_0, IBStatIntReductionEn))) {\n\t\t\t \n\t\t\tppd->cpspec->ibcctrl_a |=\n\t\t\t\tSYM_MASK(IBCCtrlA_0, IBStatIntReductionEn);\n\t\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a,\n\t\t\t\t\t    ppd->cpspec->ibcctrl_a);\n\t\t}\n\n\t\t \n\t\tppd->link_width_active =\n\t\t\t(ibcs & SYM_MASK(IBCStatusA_0, LinkWidthActive)) ?\n\t\t\t    IB_WIDTH_4X : IB_WIDTH_1X;\n\t\tppd->link_speed_active = (ibcs & SYM_MASK(IBCStatusA_0,\n\t\t\tLinkSpeedQDR)) ? QIB_IB_QDR : (ibcs &\n\t\t\t  SYM_MASK(IBCStatusA_0, LinkSpeedActive)) ?\n\t\t\t\t   QIB_IB_DDR : QIB_IB_SDR;\n\n\t\tif ((ppd->lflags & QIBL_IB_LINK_DISABLED) && ltstate !=\n\t\t    IB_PHYSPORTSTATE_DISABLED)\n\t\t\tqib_set_ib_7322_lstate(ppd, 0,\n\t\t\t       QLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\n\t\telse\n\t\t\t \n\t\t\tif (ltstate != IB_PHYSPORTSTATE_LINK_ERR_RECOVER &&\n\t\t\t    ltstate != IB_PHYSPORTSTATE_RECOVERY_RETRAIN &&\n\t\t\t    ltstate != IB_PHYSPORTSTATE_RECOVERY_WAITRMT &&\n\t\t\t    ltstate != IB_PHYSPORTSTATE_RECOVERY_IDLE)\n\t\t\t\tqib_handle_e_ibstatuschanged(ppd, ibcs);\n\t}\n\tif (*msg && iserr)\n\t\tqib_dev_porterr(dd, ppd->port, \"%s error\\n\", msg);\n\n\tif (ppd->state_wanted & ppd->lflags)\n\t\twake_up_interruptible(&ppd->state_wait);\ndone:\n\treturn;\n}\n\n \nstatic void qib_7322_set_intr_state(struct qib_devdata *dd, u32 enable)\n{\n\tif (enable) {\n\t\tif (dd->flags & QIB_BADINTR)\n\t\t\treturn;\n\t\tqib_write_kreg(dd, kr_intmask, dd->cspec->int_enable_mask);\n\t\t \n\t\tqib_write_kreg(dd, kr_intclear, 0ULL);\n\t\tif (dd->cspec->num_msix_entries) {\n\t\t\t \n\t\t\tu64 val = qib_read_kreg64(dd, kr_intgranted);\n\n\t\t\tif (val)\n\t\t\t\tqib_write_kreg(dd, kr_intgranted, val);\n\t\t}\n\t} else\n\t\tqib_write_kreg(dd, kr_intmask, 0ULL);\n}\n\n \nstatic void qib_7322_clear_freeze(struct qib_devdata *dd)\n{\n\tint pidx;\n\n\t \n\tqib_write_kreg(dd, kr_errmask, 0ULL);\n\n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx)\n\t\tif (dd->pport[pidx].link_speed_supported)\n\t\t\tqib_write_kreg_port(dd->pport + pidx, krp_errmask,\n\t\t\t\t\t    0ULL);\n\n\t \n\tqib_7322_set_intr_state(dd, 0);\n\n\t \n\tqib_write_kreg(dd, kr_control, dd->control);\n\tqib_read_kreg32(dd, kr_scratch);\n\n\t \n\tqib_write_kreg(dd, kr_hwerrclear, 0ULL);\n\tqib_write_kreg(dd, kr_errclear, E_SPKT_ERRS_IGNORE);\n\tqib_write_kreg(dd, kr_errmask, dd->cspec->errormask);\n\t \n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\n\t\tif (!dd->pport[pidx].link_speed_supported)\n\t\t\tcontinue;\n\t\tqib_write_kreg_port(dd->pport + pidx, krp_errclear, ~0Ull);\n\t\tqib_write_kreg_port(dd->pport + pidx, krp_errmask, ~0Ull);\n\t}\n\tqib_7322_set_intr_state(dd, 1);\n}\n\n \n \nstatic void qib_7322_handle_hwerrors(struct qib_devdata *dd, char *msg,\n\t\t\t\t     size_t msgl)\n{\n\tu64 hwerrs;\n\tu32 ctrl;\n\tint isfatal = 0;\n\n\thwerrs = qib_read_kreg64(dd, kr_hwerrstatus);\n\tif (!hwerrs)\n\t\tgoto bail;\n\tif (hwerrs == ~0ULL) {\n\t\tqib_dev_err(dd,\n\t\t\t\"Read of hardware error status failed (all bits set); ignoring\\n\");\n\t\tgoto bail;\n\t}\n\tqib_stats.sps_hwerrs++;\n\n\t \n\tqib_write_kreg(dd, kr_hwerrclear, hwerrs &\n\t\t       ~HWE_MASK(PowerOnBISTFailed));\n\n\thwerrs &= dd->cspec->hwerrmask;\n\n\t \n\n\tif (hwerrs)\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"Hardware error: hwerr=0x%llx (cleared)\\n\",\n\t\t\t(unsigned long long) hwerrs);\n\n\tctrl = qib_read_kreg32(dd, kr_control);\n\tif ((ctrl & SYM_MASK(Control, FreezeMode)) && !dd->diag_client) {\n\t\t \n\t\tif ((hwerrs & ~HWE_MASK(LATriggered)) ||\n\t\t    dd->cspec->stay_in_freeze) {\n\t\t\t \n\t\t\tif (dd->flags & QIB_INITTED)\n\t\t\t\tisfatal = 1;\n\t\t} else\n\t\t\tqib_7322_clear_freeze(dd);\n\t}\n\n\tif (hwerrs & HWE_MASK(PowerOnBISTFailed)) {\n\t\tisfatal = 1;\n\t\tstrscpy(msg,\n\t\t\t\"[Memory BIST test failed, InfiniPath hardware unusable]\",\n\t\t\tmsgl);\n\t\t \n\t\tdd->cspec->hwerrmask &= ~HWE_MASK(PowerOnBISTFailed);\n\t\tqib_write_kreg(dd, kr_hwerrmask, dd->cspec->hwerrmask);\n\t}\n\n\terr_decode(msg, msgl, hwerrs, qib_7322_hwerror_msgs);\n\n\t \n\n\tqib_dev_err(dd, \"%s hardware error\\n\", msg);\n\n\tif (hwerrs &\n\t\t   (SYM_MASK(HwErrMask, SDmaMemReadErrMask_0) |\n\t\t    SYM_MASK(HwErrMask, SDmaMemReadErrMask_1))) {\n\t\tint pidx = 0;\n\t\tint err;\n\t\tunsigned long flags;\n\t\tstruct qib_pportdata *ppd = dd->pport;\n\n\t\tfor (; pidx < dd->num_pports; ++pidx, ppd++) {\n\t\t\terr = 0;\n\t\t\tif (pidx == 0 && (hwerrs &\n\t\t\t\tSYM_MASK(HwErrMask, SDmaMemReadErrMask_0)))\n\t\t\t\terr++;\n\t\t\tif (pidx == 1 && (hwerrs &\n\t\t\t\tSYM_MASK(HwErrMask, SDmaMemReadErrMask_1)))\n\t\t\t\terr++;\n\t\t\tif (err) {\n\t\t\t\tspin_lock_irqsave(&ppd->sdma_lock, flags);\n\t\t\t\tdump_sdma_7322_state(ppd);\n\t\t\t\tspin_unlock_irqrestore(&ppd->sdma_lock, flags);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (isfatal && !dd->diag_client) {\n\t\tqib_dev_err(dd,\n\t\t\t\"Fatal Hardware Error, no longer usable, SN %.16s\\n\",\n\t\t\tdd->serial);\n\t\t \n\t\tif (dd->freezemsg)\n\t\t\tsnprintf(dd->freezemsg, dd->freezelen,\n\t\t\t\t \"{%s}\", msg);\n\t\tqib_disable_after_error(dd);\n\t}\nbail:;\n}\n\n \nstatic void qib_7322_init_hwerrors(struct qib_devdata *dd)\n{\n\tint pidx;\n\tu64 extsval;\n\n\textsval = qib_read_kreg64(dd, kr_extstatus);\n\tif (!(extsval & (QIB_EXTS_MEMBIST_DISABLED |\n\t\t\t QIB_EXTS_MEMBIST_ENDTEST)))\n\t\tqib_dev_err(dd, \"MemBIST did not complete!\\n\");\n\n\t \n\tqib_write_kreg(dd, kr_hwerrclear, ~HWE_MASK(PowerOnBISTFailed));\n\tqib_write_kreg(dd, kr_hwerrmask, dd->cspec->hwerrmask);\n\n\t \n\tqib_write_kreg(dd, kr_errclear, ~0ULL);\n\t \n\tqib_write_kreg(dd, kr_errmask, ~0ULL);\n\tdd->cspec->errormask = qib_read_kreg64(dd, kr_errmask);\n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx)\n\t\tif (dd->pport[pidx].link_speed_supported)\n\t\t\tqib_write_kreg_port(dd->pport + pidx, krp_errmask,\n\t\t\t\t\t    ~0ULL);\n}\n\n \nstatic void qib_set_7322_armlaunch(struct qib_devdata *dd, u32 enable)\n{\n\tif (enable) {\n\t\tqib_write_kreg(dd, kr_errclear, QIB_E_SPIOARMLAUNCH);\n\t\tdd->cspec->errormask |= QIB_E_SPIOARMLAUNCH;\n\t} else\n\t\tdd->cspec->errormask &= ~QIB_E_SPIOARMLAUNCH;\n\tqib_write_kreg(dd, kr_errmask, dd->cspec->errormask);\n}\n\n \nstatic void qib_set_ib_7322_lstate(struct qib_pportdata *ppd, u16 linkcmd,\n\t\t\t\t   u16 linitcmd)\n{\n\tu64 mod_wd;\n\tstruct qib_devdata *dd = ppd->dd;\n\tunsigned long flags;\n\n\tif (linitcmd == QLOGIC_IB_IBCC_LINKINITCMD_DISABLE) {\n\t\t \n\t\tqib_7322_mini_pcs_reset(ppd);\n\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\tppd->lflags |= QIBL_IB_LINK_DISABLED;\n\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t} else if (linitcmd || linkcmd == QLOGIC_IB_IBCC_LINKCMD_DOWN) {\n\t\t \n\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\tppd->lflags &= ~QIBL_IB_LINK_DISABLED;\n\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t\t \n\t\tppd->cpspec->ibcctrl_a &=\n\t\t\t~SYM_MASK(IBCCtrlA_0, IBStatIntReductionEn);\n\t}\n\n\tmod_wd = (linkcmd << IBA7322_IBCC_LINKCMD_SHIFT) |\n\t\t(linitcmd << QLOGIC_IB_IBCC_LINKINITCMD_SHIFT);\n\n\tqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a |\n\t\t\t    mod_wd);\n\t \n\tqib_write_kreg(dd, kr_scratch, 0);\n\n}\n\n \n#define RCV_BUF_UNITSZ 64\n#define NUM_RCV_BUF_UNITS(dd) ((64 * 1024) / (RCV_BUF_UNITSZ * dd->num_pports))\n\nstatic void set_vls(struct qib_pportdata *ppd)\n{\n\tint i, numvls, totcred, cred_vl, vl0extra;\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 val;\n\n\tnumvls = qib_num_vls(ppd->vls_operational);\n\n\t \n\t \n\ttotcred = NUM_RCV_BUF_UNITS(dd);\n\tcred_vl = (2 * 288 + RCV_BUF_UNITSZ - 1) / RCV_BUF_UNITSZ;\n\ttotcred -= cred_vl;\n\tqib_write_kreg_port(ppd, krp_rxcreditvl15, (u64) cred_vl);\n\tcred_vl = totcred / numvls;\n\tvl0extra = totcred - cred_vl * numvls;\n\tqib_write_kreg_port(ppd, krp_rxcreditvl0, cred_vl + vl0extra);\n\tfor (i = 1; i < numvls; i++)\n\t\tqib_write_kreg_port(ppd, krp_rxcreditvl0 + i, cred_vl);\n\tfor (; i < 8; i++)  \n\t\tqib_write_kreg_port(ppd, krp_rxcreditvl0 + i, 0);\n\n\t \n\tval = qib_read_kreg_port(ppd, krp_ibsdtestiftx);\n\tval |= SYM_MASK(IB_SDTEST_IF_TX_0, CREDIT_CHANGE);\n\tqib_write_kreg_port(ppd, krp_ibsdtestiftx, val);\n\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\tval &= ~SYM_MASK(IB_SDTEST_IF_TX_0, CREDIT_CHANGE);\n\tqib_write_kreg_port(ppd, krp_ibsdtestiftx, val);\n\n\tfor (i = 0; i < numvls; i++)\n\t\tval = qib_read_kreg_port(ppd, krp_rxcreditvl0 + i);\n\tval = qib_read_kreg_port(ppd, krp_rxcreditvl15);\n\n\t \n\tppd->cpspec->ibcctrl_a = (ppd->cpspec->ibcctrl_a &\n\t\t\t\t~SYM_MASK(IBCCtrlA_0, NumVLane)) |\n\t\t((u64)(numvls - 1) << SYM_LSB(IBCCtrlA_0, NumVLane));\n\tqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\n\tqib_write_kreg(dd, kr_scratch, 0ULL);\n}\n\n \nstatic int serdes_7322_init(struct qib_pportdata *ppd);\n\n \nstatic int qib_7322_bringup_serdes(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 val, guid, ibc;\n\tunsigned long flags;\n\n\t \n\t \n\tppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0, IBLinkEn);\n\tqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\n\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\n\t \n\tqib_write_kreg_port(ppd, krp_tx_deemph_override,\n\t\tSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\treset_tx_deemphasis_override));\n\n\tif (qib_compat_ddr_negotiate) {\n\t\tppd->cpspec->ibdeltainprog = 1;\n\t\tppd->cpspec->ibsymsnap = read_7322_creg32_port(ppd,\n\t\t\t\t\t\tcrp_ibsymbolerr);\n\t\tppd->cpspec->iblnkerrsnap = read_7322_creg32_port(ppd,\n\t\t\t\t\t\tcrp_iblinkerrrecov);\n\t}\n\n\t \n\tibc = 0x5ULL << SYM_LSB(IBCCtrlA_0, FlowCtrlWaterMark);\n\t \n\tibc |= 24ULL << SYM_LSB(IBCCtrlA_0, FlowCtrlPeriod);\n\t \n\tibc |= 0xfULL << SYM_LSB(IBCCtrlA_0, PhyerrThreshold);\n\t \n\tibc |= 0xfULL << SYM_LSB(IBCCtrlA_0, OverrunThreshold);\n\t \n\tibc |= ((u64)(ppd->ibmaxlen >> 2) + 1) <<\n\t\tSYM_LSB(IBCCtrlA_0, MaxPktLen);\n\tppd->cpspec->ibcctrl_a = ibc;  \n\n\t \n\tqib_7322_mini_pcs_reset(ppd);\n\n\tif (!ppd->cpspec->ibcctrl_b) {\n\t\tunsigned lse = ppd->link_speed_enabled;\n\n\t\t \n\t\tppd->cpspec->ibcctrl_b = qib_read_kreg_port(ppd,\n\t\t\t\t\t\t\t     krp_ibcctrl_b);\n\t\tppd->cpspec->ibcctrl_b &= ~(IBA7322_IBC_SPEED_QDR |\n\t\t\t\tIBA7322_IBC_SPEED_DDR |\n\t\t\t\tIBA7322_IBC_SPEED_SDR |\n\t\t\t\tIBA7322_IBC_WIDTH_AUTONEG |\n\t\t\t\tSYM_MASK(IBCCtrlB_0, IB_LANE_REV_SUPPORTED));\n\t\tif (lse & (lse - 1))  \n\t\t\tppd->cpspec->ibcctrl_b |=\n\t\t\t\t(lse << IBA7322_IBC_SPEED_LSB) |\n\t\t\t\tIBA7322_IBC_IBTA_1_2_MASK |\n\t\t\t\tIBA7322_IBC_MAX_SPEED_MASK;\n\t\telse\n\t\t\tppd->cpspec->ibcctrl_b |= (lse == QIB_IB_QDR) ?\n\t\t\t\tIBA7322_IBC_SPEED_QDR |\n\t\t\t\t IBA7322_IBC_IBTA_1_2_MASK :\n\t\t\t\t(lse == QIB_IB_DDR) ?\n\t\t\t\t\tIBA7322_IBC_SPEED_DDR :\n\t\t\t\t\tIBA7322_IBC_SPEED_SDR;\n\t\tif ((ppd->link_width_enabled & (IB_WIDTH_1X | IB_WIDTH_4X)) ==\n\t\t    (IB_WIDTH_1X | IB_WIDTH_4X))\n\t\t\tppd->cpspec->ibcctrl_b |= IBA7322_IBC_WIDTH_AUTONEG;\n\t\telse\n\t\t\tppd->cpspec->ibcctrl_b |=\n\t\t\t\tppd->link_width_enabled == IB_WIDTH_4X ?\n\t\t\t\tIBA7322_IBC_WIDTH_4X_ONLY :\n\t\t\t\tIBA7322_IBC_WIDTH_1X_ONLY;\n\n\t\t \n\t\tppd->cpspec->ibcctrl_b |= (IBA7322_IBC_RXPOL_MASK |\n\t\t\tIBA7322_IBC_HRTBT_MASK);\n\t}\n\tqib_write_kreg_port(ppd, krp_ibcctrl_b, ppd->cpspec->ibcctrl_b);\n\n\t \n\tval = qib_read_kreg_port(ppd, krp_ibcctrl_c);\n\tval &= ~SYM_MASK(IBCCtrlC_0, IB_FRONT_PORCH);\n\tval |= 0xfULL << SYM_LSB(IBCCtrlC_0, IB_FRONT_PORCH);\n\tqib_write_kreg_port(ppd, krp_ibcctrl_c, val);\n\n\tserdes_7322_init(ppd);\n\n\tguid = be64_to_cpu(ppd->guid);\n\tif (!guid) {\n\t\tif (dd->base_guid)\n\t\t\tguid = be64_to_cpu(dd->base_guid) + ppd->port - 1;\n\t\tppd->guid = cpu_to_be64(guid);\n\t}\n\n\tqib_write_kreg_port(ppd, krp_hrtbt_guid, guid);\n\t \n\tqib_write_kreg(dd, kr_scratch, 0);\n\n\t \n\tppd->cpspec->ibcctrl_a |= SYM_MASK(IBCCtrlA_0, IBLinkEn);\n\tset_vls(ppd);\n\n\t \n\tval = ppd->cpspec->ibcctrl_a | (QLOGIC_IB_IBCC_LINKINITCMD_DISABLE <<\n\t\t\t\t\tQLOGIC_IB_IBCC_LINKINITCMD_SHIFT);\n\tqib_write_kreg_port(ppd, krp_ibcctrl_a, val);\n\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\t \n\tppd->cpspec->ibcctrl_a = val & ~SYM_MASK(IBCCtrlA_0, LinkInitCmd);\n\n\t \n\tspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\n\tppd->p_rcvctrl |= SYM_MASK(RcvCtrl_0, RcvIBPortEnable);\n\tqib_write_kreg_port(ppd, krp_rcvctrl, ppd->p_rcvctrl);\n\tspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\n\n\t \n\tval = qib_read_kreg_port(ppd, krp_errmask);\n\tqib_write_kreg_port(ppd, krp_errmask,\n\t\tval | ERR_MASK_N(IBStatusChanged));\n\n\t \n\treturn 0;\n}\n\n \nstatic void qib_7322_mini_quiet_serdes(struct qib_pportdata *ppd)\n{\n\tu64 val;\n\tunsigned long flags;\n\n\tqib_set_ib_7322_lstate(ppd, 0, QLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\n\n\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\tppd->lflags &= ~QIBL_IB_AUTONEG_INPROG;\n\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\twake_up(&ppd->cpspec->autoneg_wait);\n\tcancel_delayed_work_sync(&ppd->cpspec->autoneg_work);\n\tif (ppd->dd->cspec->r1)\n\t\tcancel_delayed_work_sync(&ppd->cpspec->ipg_work);\n\n\tppd->cpspec->chase_end = 0;\n\tif (ppd->cpspec->chase_timer.function)  \n\t\tdel_timer_sync(&ppd->cpspec->chase_timer);\n\n\t \n\tppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0, IBLinkEn);\n\tqib_7322_mini_pcs_reset(ppd);\n\n\t \n\tif (ppd->cpspec->ibsymdelta || ppd->cpspec->iblnkerrdelta ||\n\t    ppd->cpspec->ibdeltainprog || ppd->cpspec->iblnkdowndelta) {\n\t\tstruct qib_devdata *dd = ppd->dd;\n\t\tu64 diagc;\n\n\t\t \n\t\tdiagc = qib_read_kreg64(dd, kr_hwdiagctrl);\n\t\tqib_write_kreg(dd, kr_hwdiagctrl,\n\t\t\t       diagc | SYM_MASK(HwDiagCtrl, CounterWrEnable));\n\n\t\tif (ppd->cpspec->ibsymdelta || ppd->cpspec->ibdeltainprog) {\n\t\t\tval = read_7322_creg32_port(ppd, crp_ibsymbolerr);\n\t\t\tif (ppd->cpspec->ibdeltainprog)\n\t\t\t\tval -= val - ppd->cpspec->ibsymsnap;\n\t\t\tval -= ppd->cpspec->ibsymdelta;\n\t\t\twrite_7322_creg_port(ppd, crp_ibsymbolerr, val);\n\t\t}\n\t\tif (ppd->cpspec->iblnkerrdelta || ppd->cpspec->ibdeltainprog) {\n\t\t\tval = read_7322_creg32_port(ppd, crp_iblinkerrrecov);\n\t\t\tif (ppd->cpspec->ibdeltainprog)\n\t\t\t\tval -= val - ppd->cpspec->iblnkerrsnap;\n\t\t\tval -= ppd->cpspec->iblnkerrdelta;\n\t\t\twrite_7322_creg_port(ppd, crp_iblinkerrrecov, val);\n\t\t}\n\t\tif (ppd->cpspec->iblnkdowndelta) {\n\t\t\tval = read_7322_creg32_port(ppd, crp_iblinkdown);\n\t\t\tval += ppd->cpspec->iblnkdowndelta;\n\t\t\twrite_7322_creg_port(ppd, crp_iblinkdown, val);\n\t\t}\n\t\t \n\n\t\t \n\t\tqib_write_kreg(dd, kr_hwdiagctrl, diagc);\n\t}\n}\n\n \nstatic void qib_setup_7322_setextled(struct qib_pportdata *ppd, u32 on)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 extctl, ledblink = 0, val;\n\tunsigned long flags;\n\tint yel, grn;\n\n\t \n\tif (dd->diag_client)\n\t\treturn;\n\n\t \n\tif (ppd->led_override) {\n\t\tgrn = (ppd->led_override & QIB_LED_PHYS);\n\t\tyel = (ppd->led_override & QIB_LED_LOG);\n\t} else if (on) {\n\t\tval = qib_read_kreg_port(ppd, krp_ibcstatus_a);\n\t\tgrn = qib_7322_phys_portstate(val) ==\n\t\t\tIB_PHYSPORTSTATE_LINKUP;\n\t\tyel = qib_7322_iblink_state(val) == IB_PORT_ACTIVE;\n\t} else {\n\t\tgrn = 0;\n\t\tyel = 0;\n\t}\n\n\tspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\n\textctl = dd->cspec->extctrl & (ppd->port == 1 ?\n\t\t~ExtLED_IB1_MASK : ~ExtLED_IB2_MASK);\n\tif (grn) {\n\t\textctl |= ppd->port == 1 ? ExtLED_IB1_GRN : ExtLED_IB2_GRN;\n\t\t \n\t\tledblink = ((66600 * 1000UL / 4) << IBA7322_LEDBLINK_ON_SHIFT) |\n\t\t\t((187500 * 1000UL / 4) << IBA7322_LEDBLINK_OFF_SHIFT);\n\t}\n\tif (yel)\n\t\textctl |= ppd->port == 1 ? ExtLED_IB1_YEL : ExtLED_IB2_YEL;\n\tdd->cspec->extctrl = extctl;\n\tqib_write_kreg(dd, kr_extctrl, dd->cspec->extctrl);\n\tspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\n\n\tif (ledblink)  \n\t\tqib_write_kreg_port(ppd, krp_rcvpktledcnt, ledblink);\n}\n\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\nstatic int qib_7322_notify_dca(struct qib_devdata *dd, unsigned long event)\n{\n\tswitch (event) {\n\tcase DCA_PROVIDER_ADD:\n\t\tif (dd->flags & QIB_DCA_ENABLED)\n\t\t\tbreak;\n\t\tif (!dca_add_requester(&dd->pcidev->dev)) {\n\t\t\tqib_devinfo(dd->pcidev, \"DCA enabled\\n\");\n\t\t\tdd->flags |= QIB_DCA_ENABLED;\n\t\t\tqib_setup_dca(dd);\n\t\t}\n\t\tbreak;\n\tcase DCA_PROVIDER_REMOVE:\n\t\tif (dd->flags & QIB_DCA_ENABLED) {\n\t\t\tdca_remove_requester(&dd->pcidev->dev);\n\t\t\tdd->flags &= ~QIB_DCA_ENABLED;\n\t\t\tdd->cspec->dca_ctrl = 0;\n\t\t\tqib_write_kreg(dd, KREG_IDX(DCACtrlA),\n\t\t\t\tdd->cspec->dca_ctrl);\n\t\t}\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void qib_update_rhdrq_dca(struct qib_ctxtdata *rcd, int cpu)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tstruct qib_chip_specific *cspec = dd->cspec;\n\n\tif (!(dd->flags & QIB_DCA_ENABLED))\n\t\treturn;\n\tif (cspec->rhdr_cpu[rcd->ctxt] != cpu) {\n\t\tconst struct dca_reg_map *rmp;\n\n\t\tcspec->rhdr_cpu[rcd->ctxt] = cpu;\n\t\trmp = &dca_rcvhdr_reg_map[rcd->ctxt];\n\t\tcspec->dca_rcvhdr_ctrl[rmp->shadow_inx] &= rmp->mask;\n\t\tcspec->dca_rcvhdr_ctrl[rmp->shadow_inx] |=\n\t\t\t(u64) dca3_get_tag(&dd->pcidev->dev, cpu) << rmp->lsb;\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"Ctxt %d cpu %d dca %llx\\n\", rcd->ctxt, cpu,\n\t\t\t(long long) cspec->dca_rcvhdr_ctrl[rmp->shadow_inx]);\n\t\tqib_write_kreg(dd, rmp->regno,\n\t\t\t       cspec->dca_rcvhdr_ctrl[rmp->shadow_inx]);\n\t\tcspec->dca_ctrl |= SYM_MASK(DCACtrlA, RcvHdrqDCAEnable);\n\t\tqib_write_kreg(dd, KREG_IDX(DCACtrlA), cspec->dca_ctrl);\n\t}\n}\n\nstatic void qib_update_sdma_dca(struct qib_pportdata *ppd, int cpu)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tstruct qib_chip_specific *cspec = dd->cspec;\n\tunsigned pidx = ppd->port - 1;\n\n\tif (!(dd->flags & QIB_DCA_ENABLED))\n\t\treturn;\n\tif (cspec->sdma_cpu[pidx] != cpu) {\n\t\tcspec->sdma_cpu[pidx] = cpu;\n\t\tcspec->dca_rcvhdr_ctrl[4] &= ~(ppd->hw_pidx ?\n\t\t\tSYM_MASK(DCACtrlF, SendDma1DCAOPH) :\n\t\t\tSYM_MASK(DCACtrlF, SendDma0DCAOPH));\n\t\tcspec->dca_rcvhdr_ctrl[4] |=\n\t\t\t(u64) dca3_get_tag(&dd->pcidev->dev, cpu) <<\n\t\t\t\t(ppd->hw_pidx ?\n\t\t\t\t\tSYM_LSB(DCACtrlF, SendDma1DCAOPH) :\n\t\t\t\t\tSYM_LSB(DCACtrlF, SendDma0DCAOPH));\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"sdma %d cpu %d dca %llx\\n\", ppd->hw_pidx, cpu,\n\t\t\t(long long) cspec->dca_rcvhdr_ctrl[4]);\n\t\tqib_write_kreg(dd, KREG_IDX(DCACtrlF),\n\t\t\t       cspec->dca_rcvhdr_ctrl[4]);\n\t\tcspec->dca_ctrl |= ppd->hw_pidx ?\n\t\t\tSYM_MASK(DCACtrlA, SendDMAHead1DCAEnable) :\n\t\t\tSYM_MASK(DCACtrlA, SendDMAHead0DCAEnable);\n\t\tqib_write_kreg(dd, KREG_IDX(DCACtrlA), cspec->dca_ctrl);\n\t}\n}\n\nstatic void qib_setup_dca(struct qib_devdata *dd)\n{\n\tstruct qib_chip_specific *cspec = dd->cspec;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(cspec->rhdr_cpu); i++)\n\t\tcspec->rhdr_cpu[i] = -1;\n\tfor (i = 0; i < ARRAY_SIZE(cspec->sdma_cpu); i++)\n\t\tcspec->sdma_cpu[i] = -1;\n\tcspec->dca_rcvhdr_ctrl[0] =\n\t\t(1ULL << SYM_LSB(DCACtrlB, RcvHdrq0DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlB, RcvHdrq1DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlB, RcvHdrq2DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlB, RcvHdrq3DCAXfrCnt));\n\tcspec->dca_rcvhdr_ctrl[1] =\n\t\t(1ULL << SYM_LSB(DCACtrlC, RcvHdrq4DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlC, RcvHdrq5DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlC, RcvHdrq6DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlC, RcvHdrq7DCAXfrCnt));\n\tcspec->dca_rcvhdr_ctrl[2] =\n\t\t(1ULL << SYM_LSB(DCACtrlD, RcvHdrq8DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlD, RcvHdrq9DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlD, RcvHdrq10DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlD, RcvHdrq11DCAXfrCnt));\n\tcspec->dca_rcvhdr_ctrl[3] =\n\t\t(1ULL << SYM_LSB(DCACtrlE, RcvHdrq12DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlE, RcvHdrq13DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlE, RcvHdrq14DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlE, RcvHdrq15DCAXfrCnt));\n\tcspec->dca_rcvhdr_ctrl[4] =\n\t\t(1ULL << SYM_LSB(DCACtrlF, RcvHdrq16DCAXfrCnt)) |\n\t\t(1ULL << SYM_LSB(DCACtrlF, RcvHdrq17DCAXfrCnt));\n\tfor (i = 0; i < ARRAY_SIZE(cspec->sdma_cpu); i++)\n\t\tqib_write_kreg(dd, KREG_IDX(DCACtrlB) + i,\n\t\t\t       cspec->dca_rcvhdr_ctrl[i]);\n\tfor (i = 0; i < cspec->num_msix_entries; i++)\n\t\tsetup_dca_notifier(dd, i);\n}\n\nstatic void qib_irq_notifier_notify(struct irq_affinity_notify *notify,\n\t\t\t     const cpumask_t *mask)\n{\n\tstruct qib_irq_notify *n =\n\t\tcontainer_of(notify, struct qib_irq_notify, notify);\n\tint cpu = cpumask_first(mask);\n\n\tif (n->rcv) {\n\t\tstruct qib_ctxtdata *rcd = (struct qib_ctxtdata *)n->arg;\n\n\t\tqib_update_rhdrq_dca(rcd, cpu);\n\t} else {\n\t\tstruct qib_pportdata *ppd = (struct qib_pportdata *)n->arg;\n\n\t\tqib_update_sdma_dca(ppd, cpu);\n\t}\n}\n\nstatic void qib_irq_notifier_release(struct kref *ref)\n{\n\tstruct qib_irq_notify *n =\n\t\tcontainer_of(ref, struct qib_irq_notify, notify.kref);\n\tstruct qib_devdata *dd;\n\n\tif (n->rcv) {\n\t\tstruct qib_ctxtdata *rcd = (struct qib_ctxtdata *)n->arg;\n\n\t\tdd = rcd->dd;\n\t} else {\n\t\tstruct qib_pportdata *ppd = (struct qib_pportdata *)n->arg;\n\n\t\tdd = ppd->dd;\n\t}\n\tqib_devinfo(dd->pcidev,\n\t\t\"release on HCA notify 0x%p n 0x%p\\n\", ref, n);\n\tkfree(n);\n}\n#endif\n\nstatic void qib_7322_free_irq(struct qib_devdata *dd)\n{\n\tu64 intgranted;\n\tint i;\n\n\tdd->cspec->main_int_mask = ~0ULL;\n\n\tfor (i = 0; i < dd->cspec->num_msix_entries; i++) {\n\t\t \n\t\tif (dd->cspec->msix_entries[i].arg) {\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\t\t\treset_dca_notifier(dd, i);\n#endif\n\t\t\tirq_set_affinity_hint(pci_irq_vector(dd->pcidev, i),\n\t\t\t\t\t      NULL);\n\t\t\tfree_cpumask_var(dd->cspec->msix_entries[i].mask);\n\t\t\tpci_free_irq(dd->pcidev, i,\n\t\t\t\t     dd->cspec->msix_entries[i].arg);\n\t\t}\n\t}\n\n\t \n\tif (!dd->cspec->num_msix_entries)\n\t\tpci_free_irq(dd->pcidev, 0, dd);\n\telse\n\t\tdd->cspec->num_msix_entries = 0;\n\n\tpci_free_irq_vectors(dd->pcidev);\n\n\t \n\tintgranted = qib_read_kreg64(dd, kr_intgranted);\n\tif (intgranted)\n\t\tqib_write_kreg(dd, kr_intgranted, intgranted);\n}\n\nstatic void qib_setup_7322_cleanup(struct qib_devdata *dd)\n{\n\tint i;\n\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\tif (dd->flags & QIB_DCA_ENABLED) {\n\t\tdca_remove_requester(&dd->pcidev->dev);\n\t\tdd->flags &= ~QIB_DCA_ENABLED;\n\t\tdd->cspec->dca_ctrl = 0;\n\t\tqib_write_kreg(dd, KREG_IDX(DCACtrlA), dd->cspec->dca_ctrl);\n\t}\n#endif\n\n\tqib_7322_free_irq(dd);\n\tkfree(dd->cspec->cntrs);\n\tbitmap_free(dd->cspec->sendchkenable);\n\tbitmap_free(dd->cspec->sendgrhchk);\n\tbitmap_free(dd->cspec->sendibchk);\n\tkfree(dd->cspec->msix_entries);\n\tfor (i = 0; i < dd->num_pports; i++) {\n\t\tunsigned long flags;\n\t\tu32 mask = QSFP_GPIO_MOD_PRS_N |\n\t\t\t(QSFP_GPIO_MOD_PRS_N << QSFP_GPIO_PORT2_SHIFT);\n\n\t\tkfree(dd->pport[i].cpspec->portcntrs);\n\t\tif (dd->flags & QIB_HAS_QSFP) {\n\t\t\tspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\n\t\t\tdd->cspec->gpio_mask &= ~mask;\n\t\t\tqib_write_kreg(dd, kr_gpio_mask, dd->cspec->gpio_mask);\n\t\t\tspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\n\t\t}\n\t}\n}\n\n \nstatic void sdma_7322_intr(struct qib_devdata *dd, u64 istat)\n{\n\tstruct qib_pportdata *ppd0 = &dd->pport[0];\n\tstruct qib_pportdata *ppd1 = &dd->pport[1];\n\tu64 intr0 = istat & (INT_MASK_P(SDma, 0) |\n\t\tINT_MASK_P(SDmaIdle, 0) | INT_MASK_P(SDmaProgress, 0));\n\tu64 intr1 = istat & (INT_MASK_P(SDma, 1) |\n\t\tINT_MASK_P(SDmaIdle, 1) | INT_MASK_P(SDmaProgress, 1));\n\n\tif (intr0)\n\t\tqib_sdma_intr(ppd0);\n\tif (intr1)\n\t\tqib_sdma_intr(ppd1);\n\n\tif (istat & INT_MASK_PM(SDmaCleanupDone, 0))\n\t\tqib_sdma_process_event(ppd0, qib_sdma_event_e20_hw_started);\n\tif (istat & INT_MASK_PM(SDmaCleanupDone, 1))\n\t\tqib_sdma_process_event(ppd1, qib_sdma_event_e20_hw_started);\n}\n\n \nstatic void qib_wantpiobuf_7322_intr(struct qib_devdata *dd, u32 needint)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dd->sendctrl_lock, flags);\n\tif (needint)\n\t\tdd->sendctrl |= SYM_MASK(SendCtrl, SendIntBufAvail);\n\telse\n\t\tdd->sendctrl &= ~SYM_MASK(SendCtrl, SendIntBufAvail);\n\tqib_write_kreg(dd, kr_sendctrl, dd->sendctrl);\n\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\tspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\n}\n\n \nstatic noinline void unknown_7322_ibits(struct qib_devdata *dd, u64 istat)\n{\n\tu64 kills;\n\tchar msg[128];\n\n\tkills = istat & ~QIB_I_BITSEXTANT;\n\tqib_dev_err(dd,\n\t\t\"Clearing reserved interrupt(s) 0x%016llx: %s\\n\",\n\t\t(unsigned long long) kills, msg);\n\tqib_write_kreg(dd, kr_intmask, (dd->cspec->int_enable_mask & ~kills));\n}\n\n \nstatic noinline void unknown_7322_gpio_intr(struct qib_devdata *dd)\n{\n\tu32 gpiostatus;\n\tint handled = 0;\n\tint pidx;\n\n\t \n\tgpiostatus = qib_read_kreg32(dd, kr_gpio_status);\n\t \n\tqib_write_kreg(dd, kr_gpio_clear, gpiostatus);\n\t \n\tfor (pidx = 0; pidx < dd->num_pports && (dd->flags & QIB_HAS_QSFP);\n\t     ++pidx) {\n\t\tstruct qib_pportdata *ppd;\n\t\tstruct qib_qsfp_data *qd;\n\t\tu32 mask;\n\n\t\tif (!dd->pport[pidx].link_speed_supported)\n\t\t\tcontinue;\n\t\tmask = QSFP_GPIO_MOD_PRS_N;\n\t\tppd = dd->pport + pidx;\n\t\tmask <<= (QSFP_GPIO_PORT2_SHIFT * ppd->hw_pidx);\n\t\tif (gpiostatus & dd->cspec->gpio_mask & mask) {\n\t\t\tu64 pins;\n\n\t\t\tqd = &ppd->cpspec->qsfp_data;\n\t\t\tgpiostatus &= ~mask;\n\t\t\tpins = qib_read_kreg64(dd, kr_extstatus);\n\t\t\tpins >>= SYM_LSB(EXTStatus, GPIOIn);\n\t\t\tif (!(pins & mask)) {\n\t\t\t\t++handled;\n\t\t\t\tqd->t_insert = jiffies;\n\t\t\t\tqueue_work(ib_wq, &qd->work);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (gpiostatus && !handled) {\n\t\tconst u32 mask = qib_read_kreg32(dd, kr_gpio_mask);\n\t\tu32 gpio_irq = mask & gpiostatus;\n\n\t\t \n\t\tdd->cspec->gpio_mask &= ~gpio_irq;\n\t\tqib_write_kreg(dd, kr_gpio_mask, dd->cspec->gpio_mask);\n\t}\n}\n\n \nstatic noinline void unlikely_7322_intr(struct qib_devdata *dd, u64 istat)\n{\n\tif (istat & ~QIB_I_BITSEXTANT)\n\t\tunknown_7322_ibits(dd, istat);\n\tif (istat & QIB_I_GPIO)\n\t\tunknown_7322_gpio_intr(dd);\n\tif (istat & QIB_I_C_ERROR) {\n\t\tqib_write_kreg(dd, kr_errmask, 0ULL);\n\t\ttasklet_schedule(&dd->error_tasklet);\n\t}\n\tif (istat & INT_MASK_P(Err, 0) && dd->rcd[0])\n\t\thandle_7322_p_errors(dd->rcd[0]->ppd);\n\tif (istat & INT_MASK_P(Err, 1) && dd->rcd[1])\n\t\thandle_7322_p_errors(dd->rcd[1]->ppd);\n}\n\n \nstatic void adjust_rcv_timeout(struct qib_ctxtdata *rcd, int npkts)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tu32 timeout = dd->cspec->rcvavail_timeout[rcd->ctxt];\n\n\t \n\tif (npkts < rcv_int_count && timeout > 2)\n\t\ttimeout >>= 1;\n\telse if (npkts >= rcv_int_count && timeout < rcv_int_timeout)\n\t\ttimeout = min(timeout << 1, rcv_int_timeout);\n\telse\n\t\treturn;\n\n\tdd->cspec->rcvavail_timeout[rcd->ctxt] = timeout;\n\tqib_write_kreg(dd, kr_rcvavailtimeout + rcd->ctxt, timeout);\n}\n\n \nstatic irqreturn_t qib_7322intr(int irq, void *data)\n{\n\tstruct qib_devdata *dd = data;\n\tirqreturn_t ret;\n\tu64 istat;\n\tu64 ctxtrbits;\n\tu64 rmask;\n\tunsigned i;\n\tu32 npkts;\n\n\tif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT) {\n\t\t \n\t\tret = IRQ_HANDLED;\n\t\tgoto bail;\n\t}\n\n\tistat = qib_read_kreg64(dd, kr_intstatus);\n\n\tif (unlikely(istat == ~0ULL)) {\n\t\tqib_bad_intrstatus(dd);\n\t\tqib_dev_err(dd, \"Interrupt status all f's, skipping\\n\");\n\t\t \n\t\tret = IRQ_NONE;\n\t\tgoto bail;\n\t}\n\n\tistat &= dd->cspec->main_int_mask;\n\tif (unlikely(!istat)) {\n\t\t \n\t\tret = IRQ_NONE;\n\t\tgoto bail;\n\t}\n\n\tthis_cpu_inc(*dd->int_counter);\n\n\t \n\tif (unlikely(istat & (~QIB_I_BITSEXTANT | QIB_I_GPIO |\n\t\t\t      QIB_I_C_ERROR | INT_MASK_P(Err, 0) |\n\t\t\t      INT_MASK_P(Err, 1))))\n\t\tunlikely_7322_intr(dd, istat);\n\n\t \n\tqib_write_kreg(dd, kr_intclear, istat);\n\n\t \n\tctxtrbits = istat & (QIB_I_RCVAVAIL_MASK | QIB_I_RCVURG_MASK);\n\tif (ctxtrbits) {\n\t\trmask = (1ULL << QIB_I_RCVAVAIL_LSB) |\n\t\t\t(1ULL << QIB_I_RCVURG_LSB);\n\t\tfor (i = 0; i < dd->first_user_ctxt; i++) {\n\t\t\tif (ctxtrbits & rmask) {\n\t\t\t\tctxtrbits &= ~rmask;\n\t\t\t\tif (dd->rcd[i])\n\t\t\t\t\tqib_kreceive(dd->rcd[i], NULL, &npkts);\n\t\t\t}\n\t\t\trmask <<= 1;\n\t\t}\n\t\tif (ctxtrbits) {\n\t\t\tctxtrbits = (ctxtrbits >> QIB_I_RCVAVAIL_LSB) |\n\t\t\t\t(ctxtrbits >> QIB_I_RCVURG_LSB);\n\t\t\tqib_handle_urcv(dd, ctxtrbits);\n\t\t}\n\t}\n\n\tif (istat & (QIB_I_P_SDMAINT(0) | QIB_I_P_SDMAINT(1)))\n\t\tsdma_7322_intr(dd, istat);\n\n\tif ((istat & QIB_I_SPIOBUFAVAIL) && (dd->flags & QIB_INITTED))\n\t\tqib_ib_piobufavail(dd);\n\n\tret = IRQ_HANDLED;\nbail:\n\treturn ret;\n}\n\n \nstatic irqreturn_t qib_7322pintr(int irq, void *data)\n{\n\tstruct qib_ctxtdata *rcd = data;\n\tstruct qib_devdata *dd = rcd->dd;\n\tu32 npkts;\n\n\tif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\n\t\t \n\t\treturn IRQ_HANDLED;\n\n\tthis_cpu_inc(*dd->int_counter);\n\n\t \n\tqib_write_kreg(dd, kr_intclear, ((1ULL << QIB_I_RCVAVAIL_LSB) |\n\t\t       (1ULL << QIB_I_RCVURG_LSB)) << rcd->ctxt);\n\n\tqib_kreceive(rcd, NULL, &npkts);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t qib_7322bufavail(int irq, void *data)\n{\n\tstruct qib_devdata *dd = data;\n\n\tif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\n\t\t \n\t\treturn IRQ_HANDLED;\n\n\tthis_cpu_inc(*dd->int_counter);\n\n\t \n\tqib_write_kreg(dd, kr_intclear, QIB_I_SPIOBUFAVAIL);\n\n\t \n\tif (dd->flags & QIB_INITTED)\n\t\tqib_ib_piobufavail(dd);\n\telse\n\t\tqib_wantpiobuf_7322_intr(dd, 0);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t sdma_intr(int irq, void *data)\n{\n\tstruct qib_pportdata *ppd = data;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\tif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\n\t\t \n\t\treturn IRQ_HANDLED;\n\n\tthis_cpu_inc(*dd->int_counter);\n\n\t \n\tqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\n\t\t       INT_MASK_P(SDma, 1) : INT_MASK_P(SDma, 0));\n\tqib_sdma_intr(ppd);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t sdma_idle_intr(int irq, void *data)\n{\n\tstruct qib_pportdata *ppd = data;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\tif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\n\t\t \n\t\treturn IRQ_HANDLED;\n\n\tthis_cpu_inc(*dd->int_counter);\n\n\t \n\tqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\n\t\t       INT_MASK_P(SDmaIdle, 1) : INT_MASK_P(SDmaIdle, 0));\n\tqib_sdma_intr(ppd);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t sdma_progress_intr(int irq, void *data)\n{\n\tstruct qib_pportdata *ppd = data;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\tif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\n\t\t \n\t\treturn IRQ_HANDLED;\n\n\tthis_cpu_inc(*dd->int_counter);\n\n\t \n\tqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\n\t\t       INT_MASK_P(SDmaProgress, 1) :\n\t\t       INT_MASK_P(SDmaProgress, 0));\n\tqib_sdma_intr(ppd);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic irqreturn_t sdma_cleanup_intr(int irq, void *data)\n{\n\tstruct qib_pportdata *ppd = data;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\tif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\n\t\t \n\t\treturn IRQ_HANDLED;\n\n\tthis_cpu_inc(*dd->int_counter);\n\n\t \n\tqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\n\t\t       INT_MASK_PM(SDmaCleanupDone, 1) :\n\t\t       INT_MASK_PM(SDmaCleanupDone, 0));\n\tqib_sdma_process_event(ppd, qib_sdma_event_e20_hw_started);\n\n\treturn IRQ_HANDLED;\n}\n\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\nstatic void reset_dca_notifier(struct qib_devdata *dd, int msixnum)\n{\n\tif (!dd->cspec->msix_entries[msixnum].dca)\n\t\treturn;\n\n\tqib_devinfo(dd->pcidev, \"Disabling notifier on HCA %d irq %d\\n\",\n\t\t    dd->unit, pci_irq_vector(dd->pcidev, msixnum));\n\tirq_set_affinity_notifier(pci_irq_vector(dd->pcidev, msixnum), NULL);\n\tdd->cspec->msix_entries[msixnum].notifier = NULL;\n}\n\nstatic void setup_dca_notifier(struct qib_devdata *dd, int msixnum)\n{\n\tstruct qib_msix_entry *m = &dd->cspec->msix_entries[msixnum];\n\tstruct qib_irq_notify *n;\n\n\tif (!m->dca)\n\t\treturn;\n\tn = kzalloc(sizeof(*n), GFP_KERNEL);\n\tif (n) {\n\t\tint ret;\n\n\t\tm->notifier = n;\n\t\tn->notify.irq = pci_irq_vector(dd->pcidev, msixnum);\n\t\tn->notify.notify = qib_irq_notifier_notify;\n\t\tn->notify.release = qib_irq_notifier_release;\n\t\tn->arg = m->arg;\n\t\tn->rcv = m->rcv;\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t\"set notifier irq %d rcv %d notify %p\\n\",\n\t\t\tn->notify.irq, n->rcv, &n->notify);\n\t\tret = irq_set_affinity_notifier(\n\t\t\t\tn->notify.irq,\n\t\t\t\t&n->notify);\n\t\tif (ret) {\n\t\t\tm->notifier = NULL;\n\t\t\tkfree(n);\n\t\t}\n\t}\n}\n\n#endif\n\n \nstatic void qib_setup_7322_interrupt(struct qib_devdata *dd, int clearpend)\n{\n\tint ret, i, msixnum;\n\tu64 redirect[6];\n\tu64 mask;\n\tconst struct cpumask *local_mask;\n\tint firstcpu, secondcpu = 0, currrcvcpu = 0;\n\n\tif (!dd->num_pports)\n\t\treturn;\n\n\tif (clearpend) {\n\t\t \n\t\tqib_7322_set_intr_state(dd, 0);\n\n\t\t \n\t\tqib_7322_init_hwerrors(dd);\n\n\t\t \n\t\tqib_write_kreg(dd, kr_intclear, ~0ULL);\n\n\t\t \n\t\tqib_write_kreg(dd, kr_intgranted, ~0ULL);\n\t\tqib_write_kreg(dd, kr_vecclr_wo_int, ~0ULL);\n\t}\n\n\tif (!dd->cspec->num_msix_entries) {\n\t\t \ntry_intx:\n\t\tret = pci_request_irq(dd->pcidev, 0, qib_7322intr, NULL, dd,\n\t\t\t\t      QIB_DRV_NAME);\n\t\tif (ret) {\n\t\t\tqib_dev_err(\n\t\t\t\tdd,\n\t\t\t\t\"Couldn't setup INTx interrupt (irq=%d): %d\\n\",\n\t\t\t\tpci_irq_vector(dd->pcidev, 0), ret);\n\t\t\treturn;\n\t\t}\n\t\tdd->cspec->main_int_mask = ~0ULL;\n\t\treturn;\n\t}\n\n\t \n\tmemset(redirect, 0, sizeof(redirect));\n\tmask = ~0ULL;\n\tmsixnum = 0;\n\tlocal_mask = cpumask_of_pcibus(dd->pcidev->bus);\n\tfirstcpu = cpumask_first(local_mask);\n\tif (firstcpu >= nr_cpu_ids ||\n\t\t\tcpumask_weight(local_mask) == num_online_cpus()) {\n\t\tlocal_mask = topology_core_cpumask(0);\n\t\tfirstcpu = cpumask_first(local_mask);\n\t}\n\tif (firstcpu < nr_cpu_ids) {\n\t\tsecondcpu = cpumask_next(firstcpu, local_mask);\n\t\tif (secondcpu >= nr_cpu_ids)\n\t\t\tsecondcpu = firstcpu;\n\t\tcurrrcvcpu = secondcpu;\n\t}\n\tfor (i = 0; msixnum < dd->cspec->num_msix_entries; i++) {\n\t\tirq_handler_t handler;\n\t\tvoid *arg;\n\t\tint lsb, reg, sh;\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\t\tint dca = 0;\n#endif\n\t\tif (i < ARRAY_SIZE(irq_table)) {\n\t\t\tif (irq_table[i].port) {\n\t\t\t\t \n\t\t\t\tif (irq_table[i].port > dd->num_pports)\n\t\t\t\t\tcontinue;\n\t\t\t\targ = dd->pport + irq_table[i].port - 1;\n\t\t\t} else\n\t\t\t\targ = dd;\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\t\t\tdca = irq_table[i].dca;\n#endif\n\t\t\tlsb = irq_table[i].lsb;\n\t\t\thandler = irq_table[i].handler;\n\t\t\tret = pci_request_irq(dd->pcidev, msixnum, handler,\n\t\t\t\t\t      NULL, arg, QIB_DRV_NAME \"%d%s\",\n\t\t\t\t\t      dd->unit,\n\t\t\t\t\t      irq_table[i].name);\n\t\t} else {\n\t\t\tunsigned ctxt;\n\n\t\t\tctxt = i - ARRAY_SIZE(irq_table);\n\t\t\t \n\t\t\targ = dd->rcd[ctxt];\n\t\t\tif (!arg)\n\t\t\t\tcontinue;\n\t\t\tif (qib_krcvq01_no_msi && ctxt < 2)\n\t\t\t\tcontinue;\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\t\t\tdca = 1;\n#endif\n\t\t\tlsb = QIB_I_RCVAVAIL_LSB + ctxt;\n\t\t\thandler = qib_7322pintr;\n\t\t\tret = pci_request_irq(dd->pcidev, msixnum, handler,\n\t\t\t\t\t      NULL, arg,\n\t\t\t\t\t      QIB_DRV_NAME \"%d (kctx)\",\n\t\t\t\t\t      dd->unit);\n\t\t}\n\n\t\tif (ret) {\n\t\t\t \n\t\t\tqib_dev_err(dd,\n\t\t\t\t    \"Couldn't setup MSIx interrupt (vec=%d, irq=%d): %d\\n\",\n\t\t\t\t    msixnum,\n\t\t\t\t    pci_irq_vector(dd->pcidev, msixnum),\n\t\t\t\t    ret);\n\t\t\tqib_7322_free_irq(dd);\n\t\t\tpci_alloc_irq_vectors(dd->pcidev, 1, 1,\n\t\t\t\t\t      PCI_IRQ_LEGACY);\n\t\t\tgoto try_intx;\n\t\t}\n\t\tdd->cspec->msix_entries[msixnum].arg = arg;\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\t\tdd->cspec->msix_entries[msixnum].dca = dca;\n\t\tdd->cspec->msix_entries[msixnum].rcv =\n\t\t\thandler == qib_7322pintr;\n#endif\n\t\tif (lsb >= 0) {\n\t\t\treg = lsb / IBA7322_REDIRECT_VEC_PER_REG;\n\t\t\tsh = (lsb % IBA7322_REDIRECT_VEC_PER_REG) *\n\t\t\t\tSYM_LSB(IntRedirect0, vec1);\n\t\t\tmask &= ~(1ULL << lsb);\n\t\t\tredirect[reg] |= ((u64) msixnum) << sh;\n\t\t}\n\t\tqib_read_kreg64(dd, 2 * msixnum + 1 +\n\t\t\t\t(QIB_7322_MsixTable_OFFS / sizeof(u64)));\n\t\tif (firstcpu < nr_cpu_ids &&\n\t\t\tzalloc_cpumask_var(\n\t\t\t\t&dd->cspec->msix_entries[msixnum].mask,\n\t\t\t\tGFP_KERNEL)) {\n\t\t\tif (handler == qib_7322pintr) {\n\t\t\t\tcpumask_set_cpu(currrcvcpu,\n\t\t\t\t\tdd->cspec->msix_entries[msixnum].mask);\n\t\t\t\tcurrrcvcpu = cpumask_next(currrcvcpu,\n\t\t\t\t\tlocal_mask);\n\t\t\t\tif (currrcvcpu >= nr_cpu_ids)\n\t\t\t\t\tcurrrcvcpu = secondcpu;\n\t\t\t} else {\n\t\t\t\tcpumask_set_cpu(firstcpu,\n\t\t\t\t\tdd->cspec->msix_entries[msixnum].mask);\n\t\t\t}\n\t\t\tirq_set_affinity_hint(\n\t\t\t\tpci_irq_vector(dd->pcidev, msixnum),\n\t\t\t\tdd->cspec->msix_entries[msixnum].mask);\n\t\t}\n\t\tmsixnum++;\n\t}\n\t \n\tfor (i = 0; i < ARRAY_SIZE(redirect); i++)\n\t\tqib_write_kreg(dd, kr_intredirect + i, redirect[i]);\n\tdd->cspec->main_int_mask = mask;\n\ttasklet_setup(&dd->error_tasklet, qib_error_tasklet);\n}\n\n \nstatic unsigned qib_7322_boardname(struct qib_devdata *dd)\n{\n\t \n\tu32 boardid;\n\tunsigned int features = DUAL_PORT_CAP;\n\n\tboardid = SYM_FIELD(dd->revision, Revision, BoardID);\n\n\tswitch (boardid) {\n\tcase 0:\n\t\tdd->boardname = \"InfiniPath_QLE7342_Emulation\";\n\t\tbreak;\n\tcase 1:\n\t\tdd->boardname = \"InfiniPath_QLE7340\";\n\t\tdd->flags |= QIB_HAS_QSFP;\n\t\tfeatures = PORT_SPD_CAP;\n\t\tbreak;\n\tcase 2:\n\t\tdd->boardname = \"InfiniPath_QLE7342\";\n\t\tdd->flags |= QIB_HAS_QSFP;\n\t\tbreak;\n\tcase 3:\n\t\tdd->boardname = \"InfiniPath_QMI7342\";\n\t\tbreak;\n\tcase 4:\n\t\tdd->boardname = \"InfiniPath_Unsupported7342\";\n\t\tqib_dev_err(dd, \"Unsupported version of QMH7342\\n\");\n\t\tfeatures = 0;\n\t\tbreak;\n\tcase BOARD_QMH7342:\n\t\tdd->boardname = \"InfiniPath_QMH7342\";\n\t\tfeatures = 0x24;\n\t\tbreak;\n\tcase BOARD_QME7342:\n\t\tdd->boardname = \"InfiniPath_QME7342\";\n\t\tbreak;\n\tcase 8:\n\t\tdd->boardname = \"InfiniPath_QME7362\";\n\t\tdd->flags |= QIB_HAS_QSFP;\n\t\tbreak;\n\tcase BOARD_QMH7360:\n\t\tdd->boardname = \"Intel IB QDR 1P FLR-QSFP Adptr\";\n\t\tdd->flags |= QIB_HAS_QSFP;\n\t\tbreak;\n\tcase 15:\n\t\tdd->boardname = \"InfiniPath_QLE7342_TEST\";\n\t\tdd->flags |= QIB_HAS_QSFP;\n\t\tbreak;\n\tdefault:\n\t\tdd->boardname = \"InfiniPath_QLE73xy_UNKNOWN\";\n\t\tqib_dev_err(dd, \"Unknown 7322 board type %u\\n\", boardid);\n\t\tbreak;\n\t}\n\tdd->board_atten = 1;  \n\n\tsnprintf(dd->boardversion, sizeof(dd->boardversion),\n\t\t \"ChipABI %u.%u, %s, InfiniPath%u %u.%u, SW Compat %u\\n\",\n\t\t QIB_CHIP_VERS_MAJ, QIB_CHIP_VERS_MIN, dd->boardname,\n\t\t (unsigned int)SYM_FIELD(dd->revision, Revision_R, Arch),\n\t\t dd->majrev, dd->minrev,\n\t\t (unsigned int)SYM_FIELD(dd->revision, Revision_R, SW));\n\n\tif (qib_singleport && (features >> PORT_SPD_CAP_SHIFT) & PORT_SPD_CAP) {\n\t\tqib_devinfo(dd->pcidev,\n\t\t\t    \"IB%u: Forced to single port mode by module parameter\\n\",\n\t\t\t    dd->unit);\n\t\tfeatures &= PORT_SPD_CAP;\n\t}\n\n\treturn features;\n}\n\n \nstatic int qib_do_7322_reset(struct qib_devdata *dd)\n{\n\tu64 val;\n\tu64 *msix_vecsave = NULL;\n\tint i, msix_entries, ret = 1;\n\tu16 cmdval;\n\tu8 int_line, clinesz;\n\tunsigned long flags;\n\n\t \n\tqib_dev_err(dd, \"Resetting InfiniPath unit %u\\n\", dd->unit);\n\n\tqib_pcie_getcmd(dd, &cmdval, &int_line, &clinesz);\n\n\tmsix_entries = dd->cspec->num_msix_entries;\n\n\t \n\tqib_7322_set_intr_state(dd, 0);\n\n\tqib_7322_free_irq(dd);\n\n\tif (msix_entries) {\n\t\t \n\t\tmsix_vecsave = kmalloc_array(2 * dd->cspec->num_msix_entries,\n\t\t\t\t\t     sizeof(u64),\n\t\t\t\t\t     GFP_KERNEL);\n\t}\n\n\t \n\tfor (i = 0; i < msix_entries; i++) {\n\t\tu64 vecaddr, vecdata;\n\n\t\tvecaddr = qib_read_kreg64(dd, 2 * i +\n\t\t\t\t  (QIB_7322_MsixTable_OFFS / sizeof(u64)));\n\t\tvecdata = qib_read_kreg64(dd, 1 + 2 * i +\n\t\t\t\t  (QIB_7322_MsixTable_OFFS / sizeof(u64)));\n\t\tif (msix_vecsave) {\n\t\t\tmsix_vecsave[2 * i] = vecaddr;\n\t\t\t \n\t\t\tmsix_vecsave[1 + 2 * i] = vecdata & ~0x100000000ULL;\n\t\t}\n\t}\n\n\tdd->pport->cpspec->ibdeltainprog = 0;\n\tdd->pport->cpspec->ibsymdelta = 0;\n\tdd->pport->cpspec->iblnkerrdelta = 0;\n\tdd->pport->cpspec->ibmalfdelta = 0;\n\t \n\tdd->z_int_counter = qib_int_counter(dd);\n\n\t \n\tdd->flags &= ~(QIB_INITTED | QIB_PRESENT | QIB_BADINTR);\n\tdd->flags |= QIB_DOING_RESET;\n\tval = dd->control | QLOGIC_IB_C_RESET;\n\twriteq(val, &dd->kregbase[kr_control]);\n\n\tfor (i = 1; i <= 5; i++) {\n\t\t \n\t\tmsleep(1000 + (1 + i) * 3000);\n\n\t\tqib_pcie_reenable(dd, cmdval, int_line, clinesz);\n\n\t\t \n\t\tval = readq(&dd->kregbase[kr_revision]);\n\t\tif (val == dd->revision)\n\t\t\tbreak;\n\t\tif (i == 5) {\n\t\t\tqib_dev_err(dd,\n\t\t\t\t\"Failed to initialize after reset, unusable\\n\");\n\t\t\tret = 0;\n\t\t\tgoto  bail;\n\t\t}\n\t}\n\n\tdd->flags |= QIB_PRESENT;  \n\n\tif (msix_entries) {\n\t\t \n\t\tfor (i = 0; i < msix_entries; i++) {\n\t\t\tif (!msix_vecsave || !msix_vecsave[2 * i])\n\t\t\t\tcontinue;\n\t\t\tqib_write_kreg(dd, 2 * i +\n\t\t\t\t(QIB_7322_MsixTable_OFFS / sizeof(u64)),\n\t\t\t\tmsix_vecsave[2 * i]);\n\t\t\tqib_write_kreg(dd, 1 + 2 * i +\n\t\t\t\t(QIB_7322_MsixTable_OFFS / sizeof(u64)),\n\t\t\t\tmsix_vecsave[1 + 2 * i]);\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < dd->num_pports; ++i)\n\t\twrite_7322_init_portregs(&dd->pport[i]);\n\twrite_7322_initregs(dd);\n\n\tif (qib_pcie_params(dd, dd->lbus_width, &msix_entries))\n\t\tqib_dev_err(dd,\n\t\t\t\"Reset failed to setup PCIe or interrupts; continuing anyway\\n\");\n\n\tdd->cspec->num_msix_entries = msix_entries;\n\tqib_setup_7322_interrupt(dd, 1);\n\n\tfor (i = 0; i < dd->num_pports; ++i) {\n\t\tstruct qib_pportdata *ppd = &dd->pport[i];\n\n\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\tppd->lflags |= QIBL_IB_FORCE_NOTIFY;\n\t\tppd->lflags &= ~QIBL_IB_AUTONEG_FAILED;\n\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t}\n\nbail:\n\tdd->flags &= ~QIB_DOING_RESET;  \n\tkfree(msix_vecsave);\n\treturn ret;\n}\n\n \nstatic void qib_7322_put_tid(struct qib_devdata *dd, u64 __iomem *tidptr,\n\t\t\t     u32 type, unsigned long pa)\n{\n\tif (!(dd->flags & QIB_PRESENT))\n\t\treturn;\n\tif (pa != dd->tidinvalid) {\n\t\tu64 chippa = pa >> IBA7322_TID_PA_SHIFT;\n\n\t\t \n\t\tif (pa != (chippa << IBA7322_TID_PA_SHIFT)) {\n\t\t\tqib_dev_err(dd, \"Physaddr %lx not 2KB aligned!\\n\",\n\t\t\t\t    pa);\n\t\t\treturn;\n\t\t}\n\t\tif (chippa >= (1UL << IBA7322_TID_SZ_SHIFT)) {\n\t\t\tqib_dev_err(dd,\n\t\t\t\t\"Physical page address 0x%lx larger than supported\\n\",\n\t\t\t\tpa);\n\t\t\treturn;\n\t\t}\n\n\t\tif (type == RCVHQ_RCV_TYPE_EAGER)\n\t\t\tchippa |= dd->tidtemplate;\n\t\telse  \n\t\t\tchippa |= IBA7322_TID_SZ_4K;\n\t\tpa = chippa;\n\t}\n\twriteq(pa, tidptr);\n}\n\n \nstatic void qib_7322_clear_tids(struct qib_devdata *dd,\n\t\t\t\tstruct qib_ctxtdata *rcd)\n{\n\tu64 __iomem *tidbase;\n\tunsigned long tidinv;\n\tu32 ctxt;\n\tint i;\n\n\tif (!dd->kregbase || !rcd)\n\t\treturn;\n\n\tctxt = rcd->ctxt;\n\n\ttidinv = dd->tidinvalid;\n\ttidbase = (u64 __iomem *)\n\t\t((char __iomem *) dd->kregbase +\n\t\t dd->rcvtidbase +\n\t\t ctxt * dd->rcvtidcnt * sizeof(*tidbase));\n\n\tfor (i = 0; i < dd->rcvtidcnt; i++)\n\t\tqib_7322_put_tid(dd, &tidbase[i], RCVHQ_RCV_TYPE_EXPECTED,\n\t\t\t\t tidinv);\n\n\ttidbase = (u64 __iomem *)\n\t\t((char __iomem *) dd->kregbase +\n\t\t dd->rcvegrbase +\n\t\t rcd->rcvegr_tid_base * sizeof(*tidbase));\n\n\tfor (i = 0; i < rcd->rcvegrcnt; i++)\n\t\tqib_7322_put_tid(dd, &tidbase[i], RCVHQ_RCV_TYPE_EAGER,\n\t\t\t\t tidinv);\n}\n\n \nstatic void qib_7322_tidtemplate(struct qib_devdata *dd)\n{\n\t \n\tif (dd->rcvegrbufsize == 2048)\n\t\tdd->tidtemplate = IBA7322_TID_SZ_2K;\n\telse if (dd->rcvegrbufsize == 4096)\n\t\tdd->tidtemplate = IBA7322_TID_SZ_4K;\n\tdd->tidinvalid = 0;\n}\n\n \n\nstatic int qib_7322_get_base_info(struct qib_ctxtdata *rcd,\n\t\t\t\t  struct qib_base_info *kinfo)\n{\n\tkinfo->spi_runtime_flags |= QIB_RUNTIME_CTXT_MSB_IN_QP |\n\t\tQIB_RUNTIME_PCIE | QIB_RUNTIME_NODMA_RTAIL |\n\t\tQIB_RUNTIME_HDRSUPP | QIB_RUNTIME_SDMA;\n\tif (rcd->dd->cspec->r1)\n\t\tkinfo->spi_runtime_flags |= QIB_RUNTIME_RCHK;\n\tif (rcd->dd->flags & QIB_USE_SPCL_TRIG)\n\t\tkinfo->spi_runtime_flags |= QIB_RUNTIME_SPECIAL_TRIGGER;\n\n\treturn 0;\n}\n\nstatic struct qib_message_header *\nqib_7322_get_msgheader(struct qib_devdata *dd, __le32 *rhf_addr)\n{\n\tu32 offset = qib_hdrget_offset(rhf_addr);\n\n\treturn (struct qib_message_header *)\n\t\t(rhf_addr - dd->rhf_offset + offset);\n}\n\n \nstatic void qib_7322_config_ctxts(struct qib_devdata *dd)\n{\n\tunsigned long flags;\n\tu32 nchipctxts;\n\n\tnchipctxts = qib_read_kreg32(dd, kr_contextcnt);\n\tdd->cspec->numctxts = nchipctxts;\n\tif (qib_n_krcv_queues > 1 && dd->num_pports) {\n\t\tdd->first_user_ctxt = NUM_IB_PORTS +\n\t\t\t(qib_n_krcv_queues - 1) * dd->num_pports;\n\t\tif (dd->first_user_ctxt > nchipctxts)\n\t\t\tdd->first_user_ctxt = nchipctxts;\n\t\tdd->n_krcv_queues = dd->first_user_ctxt / dd->num_pports;\n\t} else {\n\t\tdd->first_user_ctxt = NUM_IB_PORTS;\n\t\tdd->n_krcv_queues = 1;\n\t}\n\n\tif (!qib_cfgctxts) {\n\t\tint nctxts = dd->first_user_ctxt + num_online_cpus();\n\n\t\tif (nctxts <= 6)\n\t\t\tdd->ctxtcnt = 6;\n\t\telse if (nctxts <= 10)\n\t\t\tdd->ctxtcnt = 10;\n\t\telse if (nctxts <= nchipctxts)\n\t\t\tdd->ctxtcnt = nchipctxts;\n\t} else if (qib_cfgctxts < dd->num_pports)\n\t\tdd->ctxtcnt = dd->num_pports;\n\telse if (qib_cfgctxts <= nchipctxts)\n\t\tdd->ctxtcnt = qib_cfgctxts;\n\tif (!dd->ctxtcnt)  \n\t\tdd->ctxtcnt = nchipctxts;\n\n\t \n\tspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\n\tif (dd->ctxtcnt > 10)\n\t\tdd->rcvctrl |= 2ULL << SYM_LSB(RcvCtrl, ContextCfg);\n\telse if (dd->ctxtcnt > 6)\n\t\tdd->rcvctrl |= 1ULL << SYM_LSB(RcvCtrl, ContextCfg);\n\t \n\n\t \n\tdd->rcvctrl |= 5ULL << SYM_LSB(RcvCtrl, XrcTypeCode);\n\n\t \n\tqib_write_kreg(dd, kr_rcvctrl, dd->rcvctrl);\n\tspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\n\n\t \n\tdd->cspec->rcvegrcnt = qib_read_kreg32(dd, kr_rcvegrcnt);\n\tif (qib_rcvhdrcnt)\n\t\tdd->rcvhdrcnt = max(dd->cspec->rcvegrcnt, qib_rcvhdrcnt);\n\telse\n\t\tdd->rcvhdrcnt = 2 * max(dd->cspec->rcvegrcnt,\n\t\t\t\t    dd->num_pports > 1 ? 1024U : 2048U);\n}\n\nstatic int qib_7322_get_ib_cfg(struct qib_pportdata *ppd, int which)\n{\n\n\tint lsb, ret = 0;\n\tu64 maskr;  \n\n\tswitch (which) {\n\n\tcase QIB_IB_CFG_LWID_ENB:  \n\t\tret = ppd->link_width_enabled;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_LWID:  \n\t\tret = ppd->link_width_active;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_SPD_ENB:  \n\t\tret = ppd->link_speed_enabled;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_SPD:  \n\t\tret = ppd->link_speed_active;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_RXPOL_ENB:  \n\t\tlsb = SYM_LSB(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\n\t\tmaskr = SYM_RMASK(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\n\t\tbreak;\n\n\tcase QIB_IB_CFG_LREV_ENB:  \n\t\tlsb = SYM_LSB(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\n\t\tmaskr = SYM_RMASK(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\n\t\tbreak;\n\n\tcase QIB_IB_CFG_LINKLATENCY:\n\t\tret = qib_read_kreg_port(ppd, krp_ibcstatus_b) &\n\t\t\tSYM_MASK(IBCStatusB_0, LinkRoundTripLatency);\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_OP_VLS:\n\t\tret = ppd->vls_operational;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_VL_HIGH_CAP:\n\t\tret = 16;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_VL_LOW_CAP:\n\t\tret = 16;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_OVERRUN_THRESH:  \n\t\tret = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\n\t\t\t\tOverrunThreshold);\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_PHYERR_THRESH:  \n\t\tret = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\n\t\t\t\tPhyerrThreshold);\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_LINKDEFAULT:  \n\t\t \n\t\tret = (ppd->cpspec->ibcctrl_a &\n\t\t       SYM_MASK(IBCCtrlA_0, LinkDownDefaultState)) ?\n\t\t\tIB_LINKINITCMD_SLEEP : IB_LINKINITCMD_POLL;\n\t\tgoto done;\n\n\tcase QIB_IB_CFG_HRTBT:  \n\t\tlsb = IBA7322_IBC_HRTBT_LSB;\n\t\tmaskr = IBA7322_IBC_HRTBT_RMASK;  \n\t\tbreak;\n\n\tcase QIB_IB_CFG_PMA_TICKS:\n\t\t \n\t\tif (ppd->link_speed_active == QIB_IB_QDR)\n\t\t\tret = 3;\n\t\telse if (ppd->link_speed_active == QIB_IB_DDR)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t\tgoto done;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto done;\n\t}\n\tret = (int)((ppd->cpspec->ibcctrl_b >> lsb) & maskr);\ndone:\n\treturn ret;\n}\n\n \n#define IBA7322_IBC_DLIDLMC_SHIFT QIB_7322_IBCCtrlB_0_IB_DLID_LSB\n#define IBA7322_IBC_DLIDLMC_MASK (QIB_7322_IBCCtrlB_0_IB_DLID_RMASK \\\n\t| (QIB_7322_IBCCtrlB_0_IB_DLID_MASK_RMASK << 16))\n\nstatic int qib_7322_set_ib_cfg(struct qib_pportdata *ppd, int which, u32 val)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 maskr;  \n\tint lsb, ret = 0;\n\tu16 lcmd, licmd;\n\tunsigned long flags;\n\n\tswitch (which) {\n\tcase QIB_IB_CFG_LIDLMC:\n\t\t \n\t\tlsb = IBA7322_IBC_DLIDLMC_SHIFT;\n\t\tmaskr = IBA7322_IBC_DLIDLMC_MASK;\n\t\t \n\t\tqib_write_kreg_port(ppd, krp_sendslid,\n\t\t\t\t    val & (val >> 16) & SendIBSLIDAssignMask);\n\t\tqib_write_kreg_port(ppd, krp_sendslidmask,\n\t\t\t\t    (val >> 16) & SendIBSLMCMask);\n\t\tbreak;\n\n\tcase QIB_IB_CFG_LWID_ENB:  \n\t\tppd->link_width_enabled = val;\n\t\t \n\t\tif (val == IB_WIDTH_1X)\n\t\t\tval = 0;\n\t\telse if (val == IB_WIDTH_4X)\n\t\t\tval = 1;\n\t\telse\n\t\t\tval = 3;\n\t\tmaskr = SYM_RMASK(IBCCtrlB_0, IB_NUM_CHANNELS);\n\t\tlsb = SYM_LSB(IBCCtrlB_0, IB_NUM_CHANNELS);\n\t\tbreak;\n\n\tcase QIB_IB_CFG_SPD_ENB:  \n\t\t \n\t\tppd->link_speed_enabled = val;\n\t\tval <<= IBA7322_IBC_SPEED_LSB;\n\t\tmaskr = IBA7322_IBC_SPEED_MASK | IBA7322_IBC_IBTA_1_2_MASK |\n\t\t\tIBA7322_IBC_MAX_SPEED_MASK;\n\t\tif (val & (val - 1)) {\n\t\t\t \n\t\t\tval |= IBA7322_IBC_IBTA_1_2_MASK |\n\t\t\t\tIBA7322_IBC_MAX_SPEED_MASK;\n\t\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\t\tppd->lflags &= ~QIBL_IB_AUTONEG_FAILED;\n\t\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t\t} else if (val & IBA7322_IBC_SPEED_QDR)\n\t\t\tval |= IBA7322_IBC_IBTA_1_2_MASK;\n\t\t \n\t\tlsb = SYM_LSB(IBCCtrlB_0, IB_ENHANCED_MODE);\n\t\tbreak;\n\n\tcase QIB_IB_CFG_RXPOL_ENB:  \n\t\tlsb = SYM_LSB(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\n\t\tmaskr = SYM_RMASK(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\n\t\tbreak;\n\n\tcase QIB_IB_CFG_LREV_ENB:  \n\t\tlsb = SYM_LSB(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\n\t\tmaskr = SYM_RMASK(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\n\t\tbreak;\n\n\tcase QIB_IB_CFG_OVERRUN_THRESH:  \n\t\tmaskr = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\n\t\t\t\t  OverrunThreshold);\n\t\tif (maskr != val) {\n\t\t\tppd->cpspec->ibcctrl_a &=\n\t\t\t\t~SYM_MASK(IBCCtrlA_0, OverrunThreshold);\n\t\t\tppd->cpspec->ibcctrl_a |= (u64) val <<\n\t\t\t\tSYM_LSB(IBCCtrlA_0, OverrunThreshold);\n\t\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a,\n\t\t\t\t\t    ppd->cpspec->ibcctrl_a);\n\t\t\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\t\t}\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_PHYERR_THRESH:  \n\t\tmaskr = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\n\t\t\t\t  PhyerrThreshold);\n\t\tif (maskr != val) {\n\t\t\tppd->cpspec->ibcctrl_a &=\n\t\t\t\t~SYM_MASK(IBCCtrlA_0, PhyerrThreshold);\n\t\t\tppd->cpspec->ibcctrl_a |= (u64) val <<\n\t\t\t\tSYM_LSB(IBCCtrlA_0, PhyerrThreshold);\n\t\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a,\n\t\t\t\t\t    ppd->cpspec->ibcctrl_a);\n\t\t\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\t\t}\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_PKEYS:  \n\t\tmaskr = (u64) ppd->pkeys[0] | ((u64) ppd->pkeys[1] << 16) |\n\t\t\t((u64) ppd->pkeys[2] << 32) |\n\t\t\t((u64) ppd->pkeys[3] << 48);\n\t\tqib_write_kreg_port(ppd, krp_partitionkey, maskr);\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_LINKDEFAULT:  \n\t\t \n\t\tif (val == IB_LINKINITCMD_POLL)\n\t\t\tppd->cpspec->ibcctrl_a &=\n\t\t\t\t~SYM_MASK(IBCCtrlA_0, LinkDownDefaultState);\n\t\telse  \n\t\t\tppd->cpspec->ibcctrl_a |=\n\t\t\t\tSYM_MASK(IBCCtrlA_0, LinkDownDefaultState);\n\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\n\t\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_MTU:  \n\t\t \n\t\tval = (ppd->ibmaxlen >> 2) + 1;\n\t\tppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0, MaxPktLen);\n\t\tppd->cpspec->ibcctrl_a |= (u64)val <<\n\t\t\tSYM_LSB(IBCCtrlA_0, MaxPktLen);\n\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a,\n\t\t\t\t    ppd->cpspec->ibcctrl_a);\n\t\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_LSTATE:  \n\t\tswitch (val & 0xffff0000) {\n\t\tcase IB_LINKCMD_DOWN:\n\t\t\tlcmd = QLOGIC_IB_IBCC_LINKCMD_DOWN;\n\t\t\tppd->cpspec->ibmalfusesnap = 1;\n\t\t\tppd->cpspec->ibmalfsnap = read_7322_creg32_port(ppd,\n\t\t\t\tcrp_errlink);\n\t\t\tif (!ppd->cpspec->ibdeltainprog &&\n\t\t\t    qib_compat_ddr_negotiate) {\n\t\t\t\tppd->cpspec->ibdeltainprog = 1;\n\t\t\t\tppd->cpspec->ibsymsnap =\n\t\t\t\t\tread_7322_creg32_port(ppd,\n\t\t\t\t\t\t\t      crp_ibsymbolerr);\n\t\t\t\tppd->cpspec->iblnkerrsnap =\n\t\t\t\t\tread_7322_creg32_port(ppd,\n\t\t\t\t\t\t      crp_iblinkerrrecov);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase IB_LINKCMD_ARMED:\n\t\t\tlcmd = QLOGIC_IB_IBCC_LINKCMD_ARMED;\n\t\t\tif (ppd->cpspec->ibmalfusesnap) {\n\t\t\t\tppd->cpspec->ibmalfusesnap = 0;\n\t\t\t\tppd->cpspec->ibmalfdelta +=\n\t\t\t\t\tread_7322_creg32_port(ppd,\n\t\t\t\t\t\t\t      crp_errlink) -\n\t\t\t\t\tppd->cpspec->ibmalfsnap;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase IB_LINKCMD_ACTIVE:\n\t\t\tlcmd = QLOGIC_IB_IBCC_LINKCMD_ACTIVE;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tqib_dev_err(dd, \"bad linkcmd req 0x%x\\n\", val >> 16);\n\t\t\tgoto bail;\n\t\t}\n\t\tswitch (val & 0xffff) {\n\t\tcase IB_LINKINITCMD_NOP:\n\t\t\tlicmd = 0;\n\t\t\tbreak;\n\n\t\tcase IB_LINKINITCMD_POLL:\n\t\t\tlicmd = QLOGIC_IB_IBCC_LINKINITCMD_POLL;\n\t\t\tbreak;\n\n\t\tcase IB_LINKINITCMD_SLEEP:\n\t\t\tlicmd = QLOGIC_IB_IBCC_LINKINITCMD_SLEEP;\n\t\t\tbreak;\n\n\t\tcase IB_LINKINITCMD_DISABLE:\n\t\t\tlicmd = QLOGIC_IB_IBCC_LINKINITCMD_DISABLE;\n\t\t\tppd->cpspec->chase_end = 0;\n\t\t\t \n\t\t\tif (ppd->cpspec->chase_timer.expires) {\n\t\t\t\tdel_timer_sync(&ppd->cpspec->chase_timer);\n\t\t\t\tppd->cpspec->chase_timer.expires = 0;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tqib_dev_err(dd, \"bad linkinitcmd req 0x%x\\n\",\n\t\t\t\t    val & 0xffff);\n\t\t\tgoto bail;\n\t\t}\n\t\tqib_set_ib_7322_lstate(ppd, lcmd, licmd);\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_OP_VLS:\n\t\tif (ppd->vls_operational != val) {\n\t\t\tppd->vls_operational = val;\n\t\t\tset_vls(ppd);\n\t\t}\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_VL_HIGH_LIMIT:\n\t\tqib_write_kreg_port(ppd, krp_highprio_limit, val);\n\t\tgoto bail;\n\n\tcase QIB_IB_CFG_HRTBT:  \n\t\tif (val > 3) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto bail;\n\t\t}\n\t\tlsb = IBA7322_IBC_HRTBT_LSB;\n\t\tmaskr = IBA7322_IBC_HRTBT_RMASK;  \n\t\tbreak;\n\n\tcase QIB_IB_CFG_PORT:\n\t\t \n\t\tif (ppd->dd->cspec->r1) {\n\t\t\tcancel_delayed_work(&ppd->cpspec->ipg_work);\n\t\t\tppd->cpspec->ipg_tries = 0;\n\t\t}\n\t\tgoto bail;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\tppd->cpspec->ibcctrl_b &= ~(maskr << lsb);\n\tppd->cpspec->ibcctrl_b |= (((u64) val & maskr) << lsb);\n\tqib_write_kreg_port(ppd, krp_ibcctrl_b, ppd->cpspec->ibcctrl_b);\n\tqib_write_kreg(dd, kr_scratch, 0);\nbail:\n\treturn ret;\n}\n\nstatic int qib_7322_set_loopback(struct qib_pportdata *ppd, const char *what)\n{\n\tint ret = 0;\n\tu64 val, ctrlb;\n\n\t \n\tif (!strncmp(what, \"ibc\", 3)) {\n\t\tppd->cpspec->ibcctrl_a |= SYM_MASK(IBCCtrlA_0,\n\t\t\t\t\t\t       Loopback);\n\t\tval = 0;  \n\t\tqib_devinfo(ppd->dd->pcidev, \"Enabling IB%u:%u IBC loopback\\n\",\n\t\t\t ppd->dd->unit, ppd->port);\n\t} else if (!strncmp(what, \"off\", 3)) {\n\t\tppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0,\n\t\t\t\t\t\t\tLoopback);\n\t\t \n\t\tval = IBA7322_IBC_HRTBT_RMASK << IBA7322_IBC_HRTBT_LSB;\n\t\tqib_devinfo(ppd->dd->pcidev,\n\t\t\t\"Disabling IB%u:%u IBC loopback (normal)\\n\",\n\t\t\tppd->dd->unit, ppd->port);\n\t} else\n\t\tret = -EINVAL;\n\tif (!ret) {\n\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a,\n\t\t\t\t    ppd->cpspec->ibcctrl_a);\n\t\tctrlb = ppd->cpspec->ibcctrl_b & ~(IBA7322_IBC_HRTBT_MASK\n\t\t\t\t\t     << IBA7322_IBC_HRTBT_LSB);\n\t\tppd->cpspec->ibcctrl_b = ctrlb | val;\n\t\tqib_write_kreg_port(ppd, krp_ibcctrl_b,\n\t\t\t\t    ppd->cpspec->ibcctrl_b);\n\t\tqib_write_kreg(ppd->dd, kr_scratch, 0);\n\t}\n\treturn ret;\n}\n\nstatic void get_vl_weights(struct qib_pportdata *ppd, unsigned regno,\n\t\t\t   struct ib_vl_weight_elem *vl)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < 16; i++, regno++, vl++) {\n\t\tu32 val = qib_read_kreg_port(ppd, regno);\n\n\t\tvl->vl = (val >> SYM_LSB(LowPriority0_0, VirtualLane)) &\n\t\t\tSYM_RMASK(LowPriority0_0, VirtualLane);\n\t\tvl->weight = (val >> SYM_LSB(LowPriority0_0, Weight)) &\n\t\t\tSYM_RMASK(LowPriority0_0, Weight);\n\t}\n}\n\nstatic void set_vl_weights(struct qib_pportdata *ppd, unsigned regno,\n\t\t\t   struct ib_vl_weight_elem *vl)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < 16; i++, regno++, vl++) {\n\t\tu64 val;\n\n\t\tval = ((vl->vl & SYM_RMASK(LowPriority0_0, VirtualLane)) <<\n\t\t\tSYM_LSB(LowPriority0_0, VirtualLane)) |\n\t\t      ((vl->weight & SYM_RMASK(LowPriority0_0, Weight)) <<\n\t\t\tSYM_LSB(LowPriority0_0, Weight));\n\t\tqib_write_kreg_port(ppd, regno, val);\n\t}\n\tif (!(ppd->p_sendctrl & SYM_MASK(SendCtrl_0, IBVLArbiterEn))) {\n\t\tstruct qib_devdata *dd = ppd->dd;\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&dd->sendctrl_lock, flags);\n\t\tppd->p_sendctrl |= SYM_MASK(SendCtrl_0, IBVLArbiterEn);\n\t\tqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\n\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t\tspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\n\t}\n}\n\nstatic int qib_7322_get_ib_table(struct qib_pportdata *ppd, int which, void *t)\n{\n\tswitch (which) {\n\tcase QIB_IB_TBL_VL_HIGH_ARB:\n\t\tget_vl_weights(ppd, krp_highprio_0, t);\n\t\tbreak;\n\n\tcase QIB_IB_TBL_VL_LOW_ARB:\n\t\tget_vl_weights(ppd, krp_lowprio_0, t);\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int qib_7322_set_ib_table(struct qib_pportdata *ppd, int which, void *t)\n{\n\tswitch (which) {\n\tcase QIB_IB_TBL_VL_HIGH_ARB:\n\t\tset_vl_weights(ppd, krp_highprio_0, t);\n\t\tbreak;\n\n\tcase QIB_IB_TBL_VL_LOW_ARB:\n\t\tset_vl_weights(ppd, krp_lowprio_0, t);\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic void qib_update_7322_usrhead(struct qib_ctxtdata *rcd, u64 hd,\n\t\t\t\t    u32 updegr, u32 egrhd, u32 npkts)\n{\n\t \n\tif (hd >> IBA7322_HDRHEAD_PKTINT_SHIFT)\n\t\tadjust_rcv_timeout(rcd, npkts);\n\tif (updegr)\n\t\tqib_write_ureg(rcd->dd, ur_rcvegrindexhead, egrhd, rcd->ctxt);\n\tqib_write_ureg(rcd->dd, ur_rcvhdrhead, hd, rcd->ctxt);\n\tqib_write_ureg(rcd->dd, ur_rcvhdrhead, hd, rcd->ctxt);\n}\n\nstatic u32 qib_7322_hdrqempty(struct qib_ctxtdata *rcd)\n{\n\tu32 head, tail;\n\n\thead = qib_read_ureg32(rcd->dd, ur_rcvhdrhead, rcd->ctxt);\n\tif (rcd->rcvhdrtail_kvaddr)\n\t\ttail = qib_get_rcvhdrtail(rcd);\n\telse\n\t\ttail = qib_read_ureg32(rcd->dd, ur_rcvhdrtail, rcd->ctxt);\n\treturn head == tail;\n}\n\n#define RCVCTRL_COMMON_MODS (QIB_RCVCTRL_CTXT_ENB | \\\n\tQIB_RCVCTRL_CTXT_DIS | \\\n\tQIB_RCVCTRL_TIDFLOW_ENB | \\\n\tQIB_RCVCTRL_TIDFLOW_DIS | \\\n\tQIB_RCVCTRL_TAILUPD_ENB | \\\n\tQIB_RCVCTRL_TAILUPD_DIS | \\\n\tQIB_RCVCTRL_INTRAVAIL_ENB | \\\n\tQIB_RCVCTRL_INTRAVAIL_DIS | \\\n\tQIB_RCVCTRL_BP_ENB | \\\n\tQIB_RCVCTRL_BP_DIS)\n\n#define RCVCTRL_PORT_MODS (QIB_RCVCTRL_CTXT_ENB | \\\n\tQIB_RCVCTRL_CTXT_DIS | \\\n\tQIB_RCVCTRL_PKEY_DIS | \\\n\tQIB_RCVCTRL_PKEY_ENB)\n\n \nstatic void rcvctrl_7322_mod(struct qib_pportdata *ppd, unsigned int op,\n\t\t\t     int ctxt)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tstruct qib_ctxtdata *rcd;\n\tu64 mask, val;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\n\n\tif (op & QIB_RCVCTRL_TIDFLOW_ENB)\n\t\tdd->rcvctrl |= SYM_MASK(RcvCtrl, TidFlowEnable);\n\tif (op & QIB_RCVCTRL_TIDFLOW_DIS)\n\t\tdd->rcvctrl &= ~SYM_MASK(RcvCtrl, TidFlowEnable);\n\tif (op & QIB_RCVCTRL_TAILUPD_ENB)\n\t\tdd->rcvctrl |= SYM_MASK(RcvCtrl, TailUpd);\n\tif (op & QIB_RCVCTRL_TAILUPD_DIS)\n\t\tdd->rcvctrl &= ~SYM_MASK(RcvCtrl, TailUpd);\n\tif (op & QIB_RCVCTRL_PKEY_ENB)\n\t\tppd->p_rcvctrl &= ~SYM_MASK(RcvCtrl_0, RcvPartitionKeyDisable);\n\tif (op & QIB_RCVCTRL_PKEY_DIS)\n\t\tppd->p_rcvctrl |= SYM_MASK(RcvCtrl_0, RcvPartitionKeyDisable);\n\tif (ctxt < 0) {\n\t\tmask = (1ULL << dd->ctxtcnt) - 1;\n\t\trcd = NULL;\n\t} else {\n\t\tmask = (1ULL << ctxt);\n\t\trcd = dd->rcd[ctxt];\n\t}\n\tif ((op & QIB_RCVCTRL_CTXT_ENB) && rcd) {\n\t\tppd->p_rcvctrl |=\n\t\t\t(mask << SYM_LSB(RcvCtrl_0, ContextEnableKernel));\n\t\tif (!(dd->flags & QIB_NODMA_RTAIL)) {\n\t\t\top |= QIB_RCVCTRL_TAILUPD_ENB;  \n\t\t\tdd->rcvctrl |= SYM_MASK(RcvCtrl, TailUpd);\n\t\t}\n\t\t \n\t\tqib_write_kreg_ctxt(dd, krc_rcvhdrtailaddr, ctxt,\n\t\t\t\t    rcd->rcvhdrqtailaddr_phys);\n\t\tqib_write_kreg_ctxt(dd, krc_rcvhdraddr, ctxt,\n\t\t\t\t    rcd->rcvhdrq_phys);\n\t\trcd->seq_cnt = 1;\n\t}\n\tif (op & QIB_RCVCTRL_CTXT_DIS)\n\t\tppd->p_rcvctrl &=\n\t\t\t~(mask << SYM_LSB(RcvCtrl_0, ContextEnableKernel));\n\tif (op & QIB_RCVCTRL_BP_ENB)\n\t\tdd->rcvctrl |= mask << SYM_LSB(RcvCtrl, dontDropRHQFull);\n\tif (op & QIB_RCVCTRL_BP_DIS)\n\t\tdd->rcvctrl &= ~(mask << SYM_LSB(RcvCtrl, dontDropRHQFull));\n\tif (op & QIB_RCVCTRL_INTRAVAIL_ENB)\n\t\tdd->rcvctrl |= (mask << SYM_LSB(RcvCtrl, IntrAvail));\n\tif (op & QIB_RCVCTRL_INTRAVAIL_DIS)\n\t\tdd->rcvctrl &= ~(mask << SYM_LSB(RcvCtrl, IntrAvail));\n\t \n\tif (op == 0 || (op & RCVCTRL_COMMON_MODS))\n\t\tqib_write_kreg(dd, kr_rcvctrl, dd->rcvctrl);\n\tif (op == 0 || (op & RCVCTRL_PORT_MODS))\n\t\tqib_write_kreg_port(ppd, krp_rcvctrl, ppd->p_rcvctrl);\n\tif ((op & QIB_RCVCTRL_CTXT_ENB) && dd->rcd[ctxt]) {\n\t\t \n\t\tval = qib_read_ureg32(dd, ur_rcvegrindextail, ctxt);\n\t\tqib_write_ureg(dd, ur_rcvegrindexhead, val, ctxt);\n\n\t\t \n\t\t(void) qib_read_kreg32(dd, kr_scratch);\n\t\tval = qib_read_ureg32(dd, ur_rcvhdrtail, ctxt);\n\t\tdd->rcd[ctxt]->head = val;\n\t\t \n\t\tif (ctxt < dd->first_user_ctxt)\n\t\t\tval |= dd->rhdrhead_intr_off;\n\t\tqib_write_ureg(dd, ur_rcvhdrhead, val, ctxt);\n\t} else if ((op & QIB_RCVCTRL_INTRAVAIL_ENB) &&\n\t\tdd->rcd[ctxt] && dd->rhdrhead_intr_off) {\n\t\t \n\t\tval = dd->rcd[ctxt]->head | dd->rhdrhead_intr_off;\n\t\tqib_write_ureg(dd, ur_rcvhdrhead, val, ctxt);\n\t}\n\tif (op & QIB_RCVCTRL_CTXT_DIS) {\n\t\tunsigned f;\n\n\t\t \n\t\tif (ctxt >= 0) {\n\t\t\tqib_write_kreg_ctxt(dd, krc_rcvhdrtailaddr, ctxt, 0);\n\t\t\tqib_write_kreg_ctxt(dd, krc_rcvhdraddr, ctxt, 0);\n\t\t\tfor (f = 0; f < NUM_TIDFLOWS_CTXT; f++)\n\t\t\t\tqib_write_ureg(dd, ur_rcvflowtable + f,\n\t\t\t\t\t       TIDFLOW_ERRBITS, ctxt);\n\t\t} else {\n\t\t\tunsigned i;\n\n\t\t\tfor (i = 0; i < dd->cfgctxts; i++) {\n\t\t\t\tqib_write_kreg_ctxt(dd, krc_rcvhdrtailaddr,\n\t\t\t\t\t\t    i, 0);\n\t\t\t\tqib_write_kreg_ctxt(dd, krc_rcvhdraddr, i, 0);\n\t\t\t\tfor (f = 0; f < NUM_TIDFLOWS_CTXT; f++)\n\t\t\t\t\tqib_write_ureg(dd, ur_rcvflowtable + f,\n\t\t\t\t\t\t       TIDFLOW_ERRBITS, i);\n\t\t\t}\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\n}\n\n \n#define SENDCTRL_COMMON_MODS (\\\n\tQIB_SENDCTRL_CLEAR | \\\n\tQIB_SENDCTRL_AVAIL_DIS | \\\n\tQIB_SENDCTRL_AVAIL_ENB | \\\n\tQIB_SENDCTRL_AVAIL_BLIP | \\\n\tQIB_SENDCTRL_DISARM | \\\n\tQIB_SENDCTRL_DISARM_ALL | \\\n\tQIB_SENDCTRL_SEND_ENB)\n\n#define SENDCTRL_PORT_MODS (\\\n\tQIB_SENDCTRL_CLEAR | \\\n\tQIB_SENDCTRL_SEND_ENB | \\\n\tQIB_SENDCTRL_SEND_DIS | \\\n\tQIB_SENDCTRL_FLUSH)\n\nstatic void sendctrl_7322_mod(struct qib_pportdata *ppd, u32 op)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 tmp_dd_sendctrl;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dd->sendctrl_lock, flags);\n\n\t \n\tif (op & QIB_SENDCTRL_CLEAR)\n\t\tdd->sendctrl = 0;\n\tif (op & QIB_SENDCTRL_AVAIL_DIS)\n\t\tdd->sendctrl &= ~SYM_MASK(SendCtrl, SendBufAvailUpd);\n\telse if (op & QIB_SENDCTRL_AVAIL_ENB) {\n\t\tdd->sendctrl |= SYM_MASK(SendCtrl, SendBufAvailUpd);\n\t\tif (dd->flags & QIB_USE_SPCL_TRIG)\n\t\t\tdd->sendctrl |= SYM_MASK(SendCtrl, SpecialTriggerEn);\n\t}\n\n\t \n\tif (op & QIB_SENDCTRL_SEND_DIS)\n\t\tppd->p_sendctrl &= ~SYM_MASK(SendCtrl_0, SendEnable);\n\telse if (op & QIB_SENDCTRL_SEND_ENB)\n\t\tppd->p_sendctrl |= SYM_MASK(SendCtrl_0, SendEnable);\n\n\tif (op & QIB_SENDCTRL_DISARM_ALL) {\n\t\tu32 i, last;\n\n\t\ttmp_dd_sendctrl = dd->sendctrl;\n\t\tlast = dd->piobcnt2k + dd->piobcnt4k + NUM_VL15_BUFS;\n\t\t \n\t\ttmp_dd_sendctrl &= ~SYM_MASK(SendCtrl, SendBufAvailUpd);\n\t\tfor (i = 0; i < last; i++) {\n\t\t\tqib_write_kreg(dd, kr_sendctrl,\n\t\t\t\t       tmp_dd_sendctrl |\n\t\t\t\t       SYM_MASK(SendCtrl, Disarm) | i);\n\t\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t\t}\n\t}\n\n\tif (op & QIB_SENDCTRL_FLUSH) {\n\t\tu64 tmp_ppd_sendctrl = ppd->p_sendctrl;\n\n\t\t \n\t\ttmp_ppd_sendctrl |=\n\t\t\tSYM_MASK(SendCtrl_0, TxeDrainRmFifo) |\n\t\t\tSYM_MASK(SendCtrl_0, TxeDrainLaFifo) |\n\t\t\tSYM_MASK(SendCtrl_0, TxeBypassIbc);\n\t\tqib_write_kreg_port(ppd, krp_sendctrl, tmp_ppd_sendctrl);\n\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t}\n\n\ttmp_dd_sendctrl = dd->sendctrl;\n\n\tif (op & QIB_SENDCTRL_DISARM)\n\t\ttmp_dd_sendctrl |= SYM_MASK(SendCtrl, Disarm) |\n\t\t\t((op & QIB_7322_SendCtrl_DisarmSendBuf_RMASK) <<\n\t\t\t SYM_LSB(SendCtrl, DisarmSendBuf));\n\tif ((op & QIB_SENDCTRL_AVAIL_BLIP) &&\n\t    (dd->sendctrl & SYM_MASK(SendCtrl, SendBufAvailUpd)))\n\t\ttmp_dd_sendctrl &= ~SYM_MASK(SendCtrl, SendBufAvailUpd);\n\n\tif (op == 0 || (op & SENDCTRL_COMMON_MODS)) {\n\t\tqib_write_kreg(dd, kr_sendctrl, tmp_dd_sendctrl);\n\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t}\n\n\tif (op == 0 || (op & SENDCTRL_PORT_MODS)) {\n\t\tqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\n\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t}\n\n\tif (op & QIB_SENDCTRL_AVAIL_BLIP) {\n\t\tqib_write_kreg(dd, kr_sendctrl, dd->sendctrl);\n\t\tqib_write_kreg(dd, kr_scratch, 0);\n\t}\n\n\tspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\n\n\tif (op & QIB_SENDCTRL_FLUSH) {\n\t\tu32 v;\n\t\t \n\t\tv = qib_read_kreg32(dd, kr_scratch);\n\t\tqib_write_kreg(dd, kr_scratch, v);\n\t\tv = qib_read_kreg32(dd, kr_scratch);\n\t\tqib_write_kreg(dd, kr_scratch, v);\n\t\tqib_read_kreg32(dd, kr_scratch);\n\t}\n}\n\n#define _PORT_VIRT_FLAG 0x8000U  \n#define _PORT_64BIT_FLAG 0x10000U  \n#define _PORT_CNTR_IDXMASK 0x7fffU  \n\n \nstatic u64 qib_portcntr_7322(struct qib_pportdata *ppd, u32 reg)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 ret = 0ULL;\n\tu16 creg;\n\t \n\tstatic const u32 xlator[] = {\n\t\t[QIBPORTCNTR_PKTSEND] = crp_pktsend | _PORT_64BIT_FLAG,\n\t\t[QIBPORTCNTR_WORDSEND] = crp_wordsend | _PORT_64BIT_FLAG,\n\t\t[QIBPORTCNTR_PSXMITDATA] = crp_psxmitdatacount,\n\t\t[QIBPORTCNTR_PSXMITPKTS] = crp_psxmitpktscount,\n\t\t[QIBPORTCNTR_PSXMITWAIT] = crp_psxmitwaitcount,\n\t\t[QIBPORTCNTR_SENDSTALL] = crp_sendstall,\n\t\t[QIBPORTCNTR_PKTRCV] = crp_pktrcv | _PORT_64BIT_FLAG,\n\t\t[QIBPORTCNTR_PSRCVDATA] = crp_psrcvdatacount,\n\t\t[QIBPORTCNTR_PSRCVPKTS] = crp_psrcvpktscount,\n\t\t[QIBPORTCNTR_RCVEBP] = crp_rcvebp,\n\t\t[QIBPORTCNTR_RCVOVFL] = crp_rcvovfl,\n\t\t[QIBPORTCNTR_WORDRCV] = crp_wordrcv | _PORT_64BIT_FLAG,\n\t\t[QIBPORTCNTR_RXDROPPKT] = 0xffff,  \n\t\t[QIBPORTCNTR_RXLOCALPHYERR] = crp_rxotherlocalphyerr,\n\t\t[QIBPORTCNTR_RXVLERR] = crp_rxvlerr,\n\t\t[QIBPORTCNTR_ERRICRC] = crp_erricrc,\n\t\t[QIBPORTCNTR_ERRVCRC] = crp_errvcrc,\n\t\t[QIBPORTCNTR_ERRLPCRC] = crp_errlpcrc,\n\t\t[QIBPORTCNTR_BADFORMAT] = crp_badformat,\n\t\t[QIBPORTCNTR_ERR_RLEN] = crp_err_rlen,\n\t\t[QIBPORTCNTR_IBSYMBOLERR] = crp_ibsymbolerr,\n\t\t[QIBPORTCNTR_INVALIDRLEN] = crp_invalidrlen,\n\t\t[QIBPORTCNTR_UNSUPVL] = crp_txunsupvl,\n\t\t[QIBPORTCNTR_EXCESSBUFOVFL] = crp_excessbufferovfl,\n\t\t[QIBPORTCNTR_ERRLINK] = crp_errlink,\n\t\t[QIBPORTCNTR_IBLINKDOWN] = crp_iblinkdown,\n\t\t[QIBPORTCNTR_IBLINKERRRECOV] = crp_iblinkerrrecov,\n\t\t[QIBPORTCNTR_LLI] = crp_locallinkintegrityerr,\n\t\t[QIBPORTCNTR_VL15PKTDROP] = crp_vl15droppedpkt,\n\t\t[QIBPORTCNTR_ERRPKEY] = crp_errpkey,\n\t\t \n\t\t[QIBPORTCNTR_PSINTERVAL] = krp_psinterval,\n\t\t[QIBPORTCNTR_PSSTART] = krp_psstart,\n\t\t[QIBPORTCNTR_PSSTAT] = krp_psstat,\n\t\t \n\t\t[QIBPORTCNTR_KHDROVFL] = 0xffff,\n\t};\n\n\tif (reg >= ARRAY_SIZE(xlator)) {\n\t\tqib_devinfo(ppd->dd->pcidev,\n\t\t\t \"Unimplemented portcounter %u\\n\", reg);\n\t\tgoto done;\n\t}\n\tcreg = xlator[reg] & _PORT_CNTR_IDXMASK;\n\n\t \n\tif (reg == QIBPORTCNTR_KHDROVFL) {\n\t\tint i;\n\n\t\t \n\t\tfor (i = 0; dd->rcd && i < dd->first_user_ctxt; i++) {\n\t\t\tstruct qib_ctxtdata *rcd = dd->rcd[i];\n\n\t\t\tif (!rcd || rcd->ppd != ppd)\n\t\t\t\tcontinue;\n\t\t\tret += read_7322_creg32(dd, cr_base_egrovfl + i);\n\t\t}\n\t\tgoto done;\n\t} else if (reg == QIBPORTCNTR_RXDROPPKT) {\n\t\t \n\t\tgoto done;\n\t} else if (reg == QIBPORTCNTR_PSINTERVAL ||\n\t\t   reg == QIBPORTCNTR_PSSTART || reg == QIBPORTCNTR_PSSTAT) {\n\t\t \n\t\tret = qib_read_kreg_port(ppd, creg);\n\t\tgoto done;\n\t}\n\n\t \n\tif (xlator[reg] & _PORT_64BIT_FLAG)\n\t\tret = read_7322_creg_port(ppd, creg);\n\telse\n\t\tret = read_7322_creg32_port(ppd, creg);\n\tif (creg == crp_ibsymbolerr) {\n\t\tif (ppd->cpspec->ibdeltainprog)\n\t\t\tret -= ret - ppd->cpspec->ibsymsnap;\n\t\tret -= ppd->cpspec->ibsymdelta;\n\t} else if (creg == crp_iblinkerrrecov) {\n\t\tif (ppd->cpspec->ibdeltainprog)\n\t\t\tret -= ret - ppd->cpspec->iblnkerrsnap;\n\t\tret -= ppd->cpspec->iblnkerrdelta;\n\t} else if (creg == crp_errlink)\n\t\tret -= ppd->cpspec->ibmalfdelta;\n\telse if (creg == crp_iblinkdown)\n\t\tret += ppd->cpspec->iblnkdowndelta;\ndone:\n\treturn ret;\n}\n\n \nstatic const char cntr7322names[] =\n\t\"Interrupts\\n\"\n\t\"HostBusStall\\n\"\n\t\"E RxTIDFull\\n\"\n\t\"RxTIDInvalid\\n\"\n\t\"RxTIDFloDrop\\n\"  \n\t\"Ctxt0EgrOvfl\\n\"\n\t\"Ctxt1EgrOvfl\\n\"\n\t\"Ctxt2EgrOvfl\\n\"\n\t\"Ctxt3EgrOvfl\\n\"\n\t\"Ctxt4EgrOvfl\\n\"\n\t\"Ctxt5EgrOvfl\\n\"\n\t\"Ctxt6EgrOvfl\\n\"\n\t\"Ctxt7EgrOvfl\\n\"\n\t\"Ctxt8EgrOvfl\\n\"\n\t\"Ctxt9EgrOvfl\\n\"\n\t\"Ctx10EgrOvfl\\n\"\n\t\"Ctx11EgrOvfl\\n\"\n\t\"Ctx12EgrOvfl\\n\"\n\t\"Ctx13EgrOvfl\\n\"\n\t\"Ctx14EgrOvfl\\n\"\n\t\"Ctx15EgrOvfl\\n\"\n\t\"Ctx16EgrOvfl\\n\"\n\t\"Ctx17EgrOvfl\\n\"\n\t;\n\nstatic const u32 cntr7322indices[] = {\n\tcr_lbint | _PORT_64BIT_FLAG,\n\tcr_lbstall | _PORT_64BIT_FLAG,\n\tcr_tidfull,\n\tcr_tidinvalid,\n\tcr_rxtidflowdrop,\n\tcr_base_egrovfl + 0,\n\tcr_base_egrovfl + 1,\n\tcr_base_egrovfl + 2,\n\tcr_base_egrovfl + 3,\n\tcr_base_egrovfl + 4,\n\tcr_base_egrovfl + 5,\n\tcr_base_egrovfl + 6,\n\tcr_base_egrovfl + 7,\n\tcr_base_egrovfl + 8,\n\tcr_base_egrovfl + 9,\n\tcr_base_egrovfl + 10,\n\tcr_base_egrovfl + 11,\n\tcr_base_egrovfl + 12,\n\tcr_base_egrovfl + 13,\n\tcr_base_egrovfl + 14,\n\tcr_base_egrovfl + 15,\n\tcr_base_egrovfl + 16,\n\tcr_base_egrovfl + 17,\n};\n\n \nstatic const char portcntr7322names[] =\n\t\"TxPkt\\n\"\n\t\"TxFlowPkt\\n\"\n\t\"TxWords\\n\"\n\t\"RxPkt\\n\"\n\t\"RxFlowPkt\\n\"\n\t\"RxWords\\n\"\n\t\"TxFlowStall\\n\"\n\t\"TxDmaDesc\\n\"   \n\t\"E RxDlidFltr\\n\"   \n\t\"IBStatusChng\\n\"\n\t\"IBLinkDown\\n\"\n\t\"IBLnkRecov\\n\"\n\t\"IBRxLinkErr\\n\"\n\t\"IBSymbolErr\\n\"\n\t\"RxLLIErr\\n\"\n\t\"RxBadFormat\\n\"\n\t\"RxBadLen\\n\"\n\t\"RxBufOvrfl\\n\"\n\t\"RxEBP\\n\"\n\t\"RxFlowCtlErr\\n\"\n\t\"RxICRCerr\\n\"\n\t\"RxLPCRCerr\\n\"\n\t\"RxVCRCerr\\n\"\n\t\"RxInvalLen\\n\"\n\t\"RxInvalPKey\\n\"\n\t\"RxPktDropped\\n\"\n\t\"TxBadLength\\n\"\n\t\"TxDropped\\n\"\n\t\"TxInvalLen\\n\"\n\t\"TxUnderrun\\n\"\n\t\"TxUnsupVL\\n\"\n\t\"RxLclPhyErr\\n\"  \n\t\"RxVL15Drop\\n\"\n\t\"RxVlErr\\n\"\n\t\"XcessBufOvfl\\n\"\n\t\"RxQPBadCtxt\\n\"  \n\t\"TXBadHeader\\n\"\n\t;\n\nstatic const u32 portcntr7322indices[] = {\n\tQIBPORTCNTR_PKTSEND | _PORT_VIRT_FLAG,\n\tcrp_pktsendflow,\n\tQIBPORTCNTR_WORDSEND | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_PKTRCV | _PORT_VIRT_FLAG,\n\tcrp_pktrcvflowctrl,\n\tQIBPORTCNTR_WORDRCV | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_SENDSTALL | _PORT_VIRT_FLAG,\n\tcrp_txsdmadesc | _PORT_64BIT_FLAG,\n\tcrp_rxdlidfltr,\n\tcrp_ibstatuschange,\n\tQIBPORTCNTR_IBLINKDOWN | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_IBLINKERRRECOV | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_ERRLINK | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_IBSYMBOLERR | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_LLI | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_BADFORMAT | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_ERR_RLEN | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_RCVOVFL | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_RCVEBP | _PORT_VIRT_FLAG,\n\tcrp_rcvflowctrlviol,\n\tQIBPORTCNTR_ERRICRC | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_ERRLPCRC | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_ERRVCRC | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_INVALIDRLEN | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_ERRPKEY | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_RXDROPPKT | _PORT_VIRT_FLAG,\n\tcrp_txminmaxlenerr,\n\tcrp_txdroppedpkt,\n\tcrp_txlenerr,\n\tcrp_txunderrun,\n\tcrp_txunsupvl,\n\tQIBPORTCNTR_RXLOCALPHYERR | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_VL15PKTDROP | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_RXVLERR | _PORT_VIRT_FLAG,\n\tQIBPORTCNTR_EXCESSBUFOVFL | _PORT_VIRT_FLAG,\n\tcrp_rxqpinvalidctxt,\n\tcrp_txhdrerr,\n};\n\n \nstatic void init_7322_cntrnames(struct qib_devdata *dd)\n{\n\tint i, j = 0;\n\tchar *s;\n\n\tfor (i = 0, s = (char *)cntr7322names; s && j <= dd->cfgctxts;\n\t     i++) {\n\t\t \n\t\tif (!j && !strncmp(\"Ctxt0EgrOvfl\", s + 1, 12))\n\t\t\tj = 1;\n\t\ts = strchr(s + 1, '\\n');\n\t\tif (s && j)\n\t\t\tj++;\n\t}\n\tdd->cspec->ncntrs = i;\n\tif (!s)\n\t\t \n\t\tdd->cspec->cntrnamelen = sizeof(cntr7322names) - 1;\n\telse\n\t\tdd->cspec->cntrnamelen = 1 + s - cntr7322names;\n\tdd->cspec->cntrs = kmalloc_array(dd->cspec->ncntrs, sizeof(u64),\n\t\t\t\t\t GFP_KERNEL);\n\n\tfor (i = 0, s = (char *)portcntr7322names; s; i++)\n\t\ts = strchr(s + 1, '\\n');\n\tdd->cspec->nportcntrs = i - 1;\n\tdd->cspec->portcntrnamelen = sizeof(portcntr7322names) - 1;\n\tfor (i = 0; i < dd->num_pports; ++i) {\n\t\tdd->pport[i].cpspec->portcntrs =\n\t\t\tkmalloc_array(dd->cspec->nportcntrs, sizeof(u64),\n\t\t\t\t      GFP_KERNEL);\n\t}\n}\n\nstatic u32 qib_read_7322cntrs(struct qib_devdata *dd, loff_t pos, char **namep,\n\t\t\t      u64 **cntrp)\n{\n\tu32 ret;\n\n\tif (namep) {\n\t\tret = dd->cspec->cntrnamelen;\n\t\tif (pos >= ret)\n\t\t\tret = 0;  \n\t\telse\n\t\t\t*namep = (char *) cntr7322names;\n\t} else {\n\t\tu64 *cntr = dd->cspec->cntrs;\n\t\tint i;\n\n\t\tret = dd->cspec->ncntrs * sizeof(u64);\n\t\tif (!cntr || pos >= ret) {\n\t\t\t \n\t\t\tret = 0;\n\t\t\tgoto done;\n\t\t}\n\t\t*cntrp = cntr;\n\t\tfor (i = 0; i < dd->cspec->ncntrs; i++)\n\t\t\tif (cntr7322indices[i] & _PORT_64BIT_FLAG)\n\t\t\t\t*cntr++ = read_7322_creg(dd,\n\t\t\t\t\t\t\t cntr7322indices[i] &\n\t\t\t\t\t\t\t _PORT_CNTR_IDXMASK);\n\t\t\telse\n\t\t\t\t*cntr++ = read_7322_creg32(dd,\n\t\t\t\t\t\t\t   cntr7322indices[i]);\n\t}\ndone:\n\treturn ret;\n}\n\nstatic u32 qib_read_7322portcntrs(struct qib_devdata *dd, loff_t pos, u32 port,\n\t\t\t\t  char **namep, u64 **cntrp)\n{\n\tu32 ret;\n\n\tif (namep) {\n\t\tret = dd->cspec->portcntrnamelen;\n\t\tif (pos >= ret)\n\t\t\tret = 0;  \n\t\telse\n\t\t\t*namep = (char *)portcntr7322names;\n\t} else {\n\t\tstruct qib_pportdata *ppd = &dd->pport[port];\n\t\tu64 *cntr = ppd->cpspec->portcntrs;\n\t\tint i;\n\n\t\tret = dd->cspec->nportcntrs * sizeof(u64);\n\t\tif (!cntr || pos >= ret) {\n\t\t\t \n\t\t\tret = 0;\n\t\t\tgoto done;\n\t\t}\n\t\t*cntrp = cntr;\n\t\tfor (i = 0; i < dd->cspec->nportcntrs; i++) {\n\t\t\tif (portcntr7322indices[i] & _PORT_VIRT_FLAG)\n\t\t\t\t*cntr++ = qib_portcntr_7322(ppd,\n\t\t\t\t\tportcntr7322indices[i] &\n\t\t\t\t\t_PORT_CNTR_IDXMASK);\n\t\t\telse if (portcntr7322indices[i] & _PORT_64BIT_FLAG)\n\t\t\t\t*cntr++ = read_7322_creg_port(ppd,\n\t\t\t\t\t   portcntr7322indices[i] &\n\t\t\t\t\t    _PORT_CNTR_IDXMASK);\n\t\t\telse\n\t\t\t\t*cntr++ = read_7322_creg32_port(ppd,\n\t\t\t\t\t   portcntr7322indices[i]);\n\t\t}\n\t}\ndone:\n\treturn ret;\n}\n\n \nstatic void qib_get_7322_faststats(struct timer_list *t)\n{\n\tstruct qib_devdata *dd = from_timer(dd, t, stats_timer);\n\tstruct qib_pportdata *ppd;\n\tunsigned long flags;\n\tu64 traffic_wds;\n\tint pidx;\n\n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\n\t\tppd = dd->pport + pidx;\n\n\t\t \n\t\tif (!ppd->link_speed_supported || !(dd->flags & QIB_INITTED)\n\t\t    || dd->diag_client)\n\t\t\tcontinue;\n\n\t\t \n\t\ttraffic_wds = qib_portcntr_7322(ppd, QIBPORTCNTR_WORDRCV) +\n\t\t\tqib_portcntr_7322(ppd, QIBPORTCNTR_WORDSEND);\n\t\tspin_lock_irqsave(&ppd->dd->eep_st_lock, flags);\n\t\ttraffic_wds -= ppd->dd->traffic_wds;\n\t\tppd->dd->traffic_wds += traffic_wds;\n\t\tspin_unlock_irqrestore(&ppd->dd->eep_st_lock, flags);\n\t\tif (ppd->cpspec->qdr_dfe_on && (ppd->link_speed_active &\n\t\t\t\t\t\tQIB_IB_QDR) &&\n\t\t    (ppd->lflags & (QIBL_LINKINIT | QIBL_LINKARMED |\n\t\t\t\t    QIBL_LINKACTIVE)) &&\n\t\t    ppd->cpspec->qdr_dfe_time &&\n\t\t    time_is_before_jiffies(ppd->cpspec->qdr_dfe_time)) {\n\t\t\tppd->cpspec->qdr_dfe_on = 0;\n\n\t\t\tqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\n\t\t\t\t\t    ppd->dd->cspec->r1 ?\n\t\t\t\t\t    QDR_STATIC_ADAPT_INIT_R1 :\n\t\t\t\t\t    QDR_STATIC_ADAPT_INIT);\n\t\t\tforce_h1(ppd);\n\t\t}\n\t}\n\tmod_timer(&dd->stats_timer, jiffies + HZ * ACTIVITY_TIMER);\n}\n\n \nstatic int qib_7322_intr_fallback(struct qib_devdata *dd)\n{\n\tif (!dd->cspec->num_msix_entries)\n\t\treturn 0;  \n\n\tqib_devinfo(dd->pcidev,\n\t\t\"MSIx interrupt not detected, trying INTx interrupts\\n\");\n\tqib_7322_free_irq(dd);\n\tif (pci_alloc_irq_vectors(dd->pcidev, 1, 1, PCI_IRQ_LEGACY) < 0)\n\t\tqib_dev_err(dd, \"Failed to enable INTx\\n\");\n\tqib_setup_7322_interrupt(dd, 0);\n\treturn 1;\n}\n\n \nstatic void qib_7322_mini_pcs_reset(struct qib_pportdata *ppd)\n{\n\tu64 val;\n\tstruct qib_devdata *dd = ppd->dd;\n\tconst u64 reset_bits = SYM_MASK(IBPCSConfig_0, xcv_rreset) |\n\t\tSYM_MASK(IBPCSConfig_0, xcv_treset) |\n\t\tSYM_MASK(IBPCSConfig_0, tx_rx_reset);\n\n\tval = qib_read_kreg_port(ppd, krp_ib_pcsconfig);\n\tqib_write_kreg(dd, kr_hwerrmask,\n\t\t       dd->cspec->hwerrmask & ~HWE_MASK(statusValidNoEop));\n\tqib_write_kreg_port(ppd, krp_ibcctrl_a,\n\t\t\t    ppd->cpspec->ibcctrl_a &\n\t\t\t    ~SYM_MASK(IBCCtrlA_0, IBLinkEn));\n\n\tqib_write_kreg_port(ppd, krp_ib_pcsconfig, val | reset_bits);\n\tqib_read_kreg32(dd, kr_scratch);\n\tqib_write_kreg_port(ppd, krp_ib_pcsconfig, val & ~reset_bits);\n\tqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\n\tqib_write_kreg(dd, kr_scratch, 0ULL);\n\tqib_write_kreg(dd, kr_hwerrclear,\n\t\t       SYM_MASK(HwErrClear, statusValidNoEopClear));\n\tqib_write_kreg(dd, kr_hwerrmask, dd->cspec->hwerrmask);\n}\n\n \nstatic void autoneg_7322_sendpkt(struct qib_pportdata *ppd, u32 *hdr,\n\t\t\t\t u32 dcnt, u32 *data)\n{\n\tint i;\n\tu64 pbc;\n\tu32 __iomem *piobuf;\n\tu32 pnum, control, len;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\ti = 0;\n\tlen = 7 + dcnt + 1;  \n\tcontrol = qib_7322_setpbc_control(ppd, len, 0, 15);\n\tpbc = ((u64) control << 32) | len;\n\twhile (!(piobuf = qib_7322_getsendbuf(ppd, pbc, &pnum))) {\n\t\tif (i++ > 15)\n\t\t\treturn;\n\t\tudelay(2);\n\t}\n\t \n\tdd->f_txchk_change(dd, pnum, 1, TXCHK_CHG_TYPE_DIS1, NULL);\n\twriteq(pbc, piobuf);\n\tqib_flush_wc();\n\tqib_pio_copy(piobuf + 2, hdr, 7);\n\tqib_pio_copy(piobuf + 9, data, dcnt);\n\tif (dd->flags & QIB_USE_SPCL_TRIG) {\n\t\tu32 spcl_off = (pnum >= dd->piobcnt2k) ? 2047 : 1023;\n\n\t\tqib_flush_wc();\n\t\t__raw_writel(0xaebecede, piobuf + spcl_off);\n\t}\n\tqib_flush_wc();\n\tqib_sendbuf_done(dd, pnum);\n\t \n\tdd->f_txchk_change(dd, pnum, 1, TXCHK_CHG_TYPE_ENAB1, NULL);\n}\n\n \nstatic void qib_autoneg_7322_send(struct qib_pportdata *ppd, int which)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tstatic u32 swapped;\n\tu32 dw, i, hcnt, dcnt, *data;\n\tstatic u32 hdr[7] = { 0xf002ffff, 0x48ffff, 0x6400abba };\n\tstatic u32 madpayload_start[0x40] = {\n\t\t0x1810103, 0x1, 0x0, 0x0, 0x2c90000, 0x2c9, 0x0, 0x0,\n\t\t0xffffffff, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n\t\t0x1, 0x1388, 0x15e, 0x1,  \n\t\t};\n\tstatic u32 madpayload_done[0x40] = {\n\t\t0x1810103, 0x1, 0x0, 0x0, 0x2c90000, 0x2c9, 0x0, 0x0,\n\t\t0xffffffff, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\n\t\t0x40000001, 0x1388, 0x15e,  \n\t\t};\n\n\tdcnt = ARRAY_SIZE(madpayload_start);\n\thcnt = ARRAY_SIZE(hdr);\n\tif (!swapped) {\n\t\t \n\t\tfor (i = 0; i < hcnt; i++) {\n\t\t\tdw = (__force u32) cpu_to_be32(hdr[i]);\n\t\t\thdr[i] = dw;\n\t\t}\n\t\tfor (i = 0; i < dcnt; i++) {\n\t\t\tdw = (__force u32) cpu_to_be32(madpayload_start[i]);\n\t\t\tmadpayload_start[i] = dw;\n\t\t\tdw = (__force u32) cpu_to_be32(madpayload_done[i]);\n\t\t\tmadpayload_done[i] = dw;\n\t\t}\n\t\tswapped = 1;\n\t}\n\n\tdata = which ? madpayload_done : madpayload_start;\n\n\tautoneg_7322_sendpkt(ppd, hdr, dcnt, data);\n\tqib_read_kreg64(dd, kr_scratch);\n\tudelay(2);\n\tautoneg_7322_sendpkt(ppd, hdr, dcnt, data);\n\tqib_read_kreg64(dd, kr_scratch);\n\tudelay(2);\n}\n\n \nstatic void set_7322_ibspeed_fast(struct qib_pportdata *ppd, u32 speed)\n{\n\tu64 newctrlb;\n\n\tnewctrlb = ppd->cpspec->ibcctrl_b & ~(IBA7322_IBC_SPEED_MASK |\n\t\t\t\t    IBA7322_IBC_IBTA_1_2_MASK |\n\t\t\t\t    IBA7322_IBC_MAX_SPEED_MASK);\n\n\tif (speed & (speed - 1))  \n\t\tnewctrlb |= (speed << IBA7322_IBC_SPEED_LSB) |\n\t\t\t\t    IBA7322_IBC_IBTA_1_2_MASK |\n\t\t\t\t    IBA7322_IBC_MAX_SPEED_MASK;\n\telse\n\t\tnewctrlb |= speed == QIB_IB_QDR ?\n\t\t\tIBA7322_IBC_SPEED_QDR | IBA7322_IBC_IBTA_1_2_MASK :\n\t\t\t((speed == QIB_IB_DDR ?\n\t\t\t  IBA7322_IBC_SPEED_DDR : IBA7322_IBC_SPEED_SDR));\n\n\tif (newctrlb == ppd->cpspec->ibcctrl_b)\n\t\treturn;\n\n\tppd->cpspec->ibcctrl_b = newctrlb;\n\tqib_write_kreg_port(ppd, krp_ibcctrl_b, ppd->cpspec->ibcctrl_b);\n\tqib_write_kreg(ppd->dd, kr_scratch, 0);\n}\n\n \nstatic void try_7322_autoneg(struct qib_pportdata *ppd)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\tppd->lflags |= QIBL_IB_AUTONEG_INPROG;\n\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\tqib_autoneg_7322_send(ppd, 0);\n\tset_7322_ibspeed_fast(ppd, QIB_IB_DDR);\n\tqib_7322_mini_pcs_reset(ppd);\n\t \n\tqueue_delayed_work(ib_wq, &ppd->cpspec->autoneg_work,\n\t\t\t   msecs_to_jiffies(2));\n}\n\n \nstatic void autoneg_7322_work(struct work_struct *work)\n{\n\tstruct qib_pportdata *ppd;\n\tu32 i;\n\tunsigned long flags;\n\n\tppd = container_of(work, struct qib_chippport_specific,\n\t\t\t    autoneg_work.work)->ppd;\n\n\t \n\tfor (i = 0; i < 25; i++) {\n\t\tif (SYM_FIELD(ppd->lastibcstat, IBCStatusA_0, LinkState)\n\t\t     == IB_7322_LT_STATE_POLLQUIET) {\n\t\t\tqib_set_linkstate(ppd, QIB_IB_LINKDOWN_DISABLE);\n\t\t\tbreak;\n\t\t}\n\t\tudelay(100);\n\t}\n\n\tif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG))\n\t\tgoto done;  \n\n\t \n\tif (wait_event_timeout(ppd->cpspec->autoneg_wait,\n\t\t\t       !(ppd->lflags & QIBL_IB_AUTONEG_INPROG),\n\t\t\t       msecs_to_jiffies(90)))\n\t\tgoto done;\n\tqib_7322_mini_pcs_reset(ppd);\n\n\t \n\tif (wait_event_timeout(ppd->cpspec->autoneg_wait,\n\t\t\t       !(ppd->lflags & QIBL_IB_AUTONEG_INPROG),\n\t\t\t       msecs_to_jiffies(1700)))\n\t\tgoto done;\n\tqib_7322_mini_pcs_reset(ppd);\n\n\tset_7322_ibspeed_fast(ppd, QIB_IB_SDR);\n\n\t \n\twait_event_timeout(ppd->cpspec->autoneg_wait,\n\t\t!(ppd->lflags & QIBL_IB_AUTONEG_INPROG),\n\t\tmsecs_to_jiffies(250));\ndone:\n\tif (ppd->lflags & QIBL_IB_AUTONEG_INPROG) {\n\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\tppd->lflags &= ~QIBL_IB_AUTONEG_INPROG;\n\t\tif (ppd->cpspec->autoneg_tries == AUTONEG_TRIES) {\n\t\t\tppd->lflags |= QIBL_IB_AUTONEG_FAILED;\n\t\t\tppd->cpspec->autoneg_tries = 0;\n\t\t}\n\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t\tset_7322_ibspeed_fast(ppd, ppd->link_speed_enabled);\n\t}\n}\n\n \nstatic void try_7322_ipg(struct qib_pportdata *ppd)\n{\n\tstruct qib_ibport *ibp = &ppd->ibport_data;\n\tstruct ib_mad_send_buf *send_buf;\n\tstruct ib_mad_agent *agent;\n\tstruct ib_smp *smp;\n\tunsigned delay;\n\tint ret;\n\n\tagent = ibp->rvp.send_agent;\n\tif (!agent)\n\t\tgoto retry;\n\n\tsend_buf = ib_create_send_mad(agent, 0, 0, 0, IB_MGMT_MAD_HDR,\n\t\t\t\t      IB_MGMT_MAD_DATA, GFP_ATOMIC,\n\t\t\t\t      IB_MGMT_BASE_VERSION);\n\tif (IS_ERR(send_buf))\n\t\tgoto retry;\n\n\tif (!ibp->smi_ah) {\n\t\tstruct ib_ah *ah;\n\n\t\tah = qib_create_qp0_ah(ibp, be16_to_cpu(IB_LID_PERMISSIVE));\n\t\tif (IS_ERR(ah))\n\t\t\tret = PTR_ERR(ah);\n\t\telse {\n\t\t\tsend_buf->ah = ah;\n\t\t\tibp->smi_ah = ibah_to_rvtah(ah);\n\t\t\tret = 0;\n\t\t}\n\t} else {\n\t\tsend_buf->ah = &ibp->smi_ah->ibah;\n\t\tret = 0;\n\t}\n\n\tsmp = send_buf->mad;\n\tsmp->base_version = IB_MGMT_BASE_VERSION;\n\tsmp->mgmt_class = IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE;\n\tsmp->class_version = 1;\n\tsmp->method = IB_MGMT_METHOD_SEND;\n\tsmp->hop_cnt = 1;\n\tsmp->attr_id = QIB_VENDOR_IPG;\n\tsmp->attr_mod = 0;\n\n\tif (!ret)\n\t\tret = ib_post_send_mad(send_buf, NULL);\n\tif (ret)\n\t\tib_free_send_mad(send_buf);\nretry:\n\tdelay = 2 << ppd->cpspec->ipg_tries;\n\tqueue_delayed_work(ib_wq, &ppd->cpspec->ipg_work,\n\t\t\t   msecs_to_jiffies(delay));\n}\n\n \nstatic void ipg_7322_work(struct work_struct *work)\n{\n\tstruct qib_pportdata *ppd;\n\n\tppd = container_of(work, struct qib_chippport_specific,\n\t\t\t   ipg_work.work)->ppd;\n\tif ((ppd->lflags & (QIBL_LINKINIT | QIBL_LINKARMED | QIBL_LINKACTIVE))\n\t    && ++ppd->cpspec->ipg_tries <= 10)\n\t\ttry_7322_ipg(ppd);\n}\n\nstatic u32 qib_7322_iblink_state(u64 ibcs)\n{\n\tu32 state = (u32)SYM_FIELD(ibcs, IBCStatusA_0, LinkState);\n\n\tswitch (state) {\n\tcase IB_7322_L_STATE_INIT:\n\t\tstate = IB_PORT_INIT;\n\t\tbreak;\n\tcase IB_7322_L_STATE_ARM:\n\t\tstate = IB_PORT_ARMED;\n\t\tbreak;\n\tcase IB_7322_L_STATE_ACTIVE:\n\tcase IB_7322_L_STATE_ACT_DEFER:\n\t\tstate = IB_PORT_ACTIVE;\n\t\tbreak;\n\tdefault:\n\t\tfallthrough;\n\tcase IB_7322_L_STATE_DOWN:\n\t\tstate = IB_PORT_DOWN;\n\t\tbreak;\n\t}\n\treturn state;\n}\n\n \nstatic u8 qib_7322_phys_portstate(u64 ibcs)\n{\n\tu8 state = (u8)SYM_FIELD(ibcs, IBCStatusA_0, LinkTrainingState);\n\treturn qib_7322_physportstate[state];\n}\n\nstatic int qib_7322_ib_updown(struct qib_pportdata *ppd, int ibup, u64 ibcs)\n{\n\tint ret = 0, symadj = 0;\n\tunsigned long flags;\n\tint mult;\n\n\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\tppd->lflags &= ~QIBL_IB_FORCE_NOTIFY;\n\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\n\t \n\tif (ibcs & SYM_MASK(IBCStatusA_0, LinkSpeedQDR)) {\n\t\tppd->link_speed_active = QIB_IB_QDR;\n\t\tmult = 4;\n\t} else if (ibcs & SYM_MASK(IBCStatusA_0, LinkSpeedActive)) {\n\t\tppd->link_speed_active = QIB_IB_DDR;\n\t\tmult = 2;\n\t} else {\n\t\tppd->link_speed_active = QIB_IB_SDR;\n\t\tmult = 1;\n\t}\n\tif (ibcs & SYM_MASK(IBCStatusA_0, LinkWidthActive)) {\n\t\tppd->link_width_active = IB_WIDTH_4X;\n\t\tmult *= 4;\n\t} else\n\t\tppd->link_width_active = IB_WIDTH_1X;\n\tppd->delay_mult = ib_rate_to_delay[mult_to_ib_rate(mult)];\n\n\tif (!ibup) {\n\t\tu64 clr;\n\n\t\t \n\t\t \n\t\tppd->cpspec->ipg_tries = 0;\n\t\tclr = qib_read_kreg_port(ppd, krp_ibcstatus_b) &\n\t\t\t(SYM_MASK(IBCStatusB_0, heartbeat_timed_out) |\n\t\t\t SYM_MASK(IBCStatusB_0, heartbeat_crosstalk));\n\t\tif (clr)\n\t\t\tqib_write_kreg_port(ppd, krp_ibcstatus_b, clr);\n\t\tif (!(ppd->lflags & (QIBL_IB_AUTONEG_FAILED |\n\t\t\t\t     QIBL_IB_AUTONEG_INPROG)))\n\t\t\tset_7322_ibspeed_fast(ppd, ppd->link_speed_enabled);\n\t\tif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG)) {\n\t\t\tstruct qib_qsfp_data *qd =\n\t\t\t\t&ppd->cpspec->qsfp_data;\n\t\t\t \n\t\t\tqib_write_kreg_port(ppd, krp_tx_deemph_override,\n\t\t\t\tSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t\t\treset_tx_deemphasis_override));\n\t\t\tqib_cancel_sends(ppd);\n\t\t\t \n\t\t\tqib_7322_mini_pcs_reset(ppd);\n\t\t\t \n\t\t\tif (ppd->dd->flags & QIB_HAS_QSFP) {\n\t\t\t\tqd->t_insert = jiffies;\n\t\t\t\tqueue_work(ib_wq, &qd->work);\n\t\t\t}\n\t\t\tspin_lock_irqsave(&ppd->sdma_lock, flags);\n\t\t\tif (__qib_sdma_running(ppd))\n\t\t\t\t__qib_sdma_process_event(ppd,\n\t\t\t\t\tqib_sdma_event_e70_go_idle);\n\t\t\tspin_unlock_irqrestore(&ppd->sdma_lock, flags);\n\t\t}\n\t\tclr = read_7322_creg32_port(ppd, crp_iblinkdown);\n\t\tif (clr == ppd->cpspec->iblnkdownsnap)\n\t\t\tppd->cpspec->iblnkdowndelta++;\n\t} else {\n\t\tif (qib_compat_ddr_negotiate &&\n\t\t    !(ppd->lflags & (QIBL_IB_AUTONEG_FAILED |\n\t\t\t\t     QIBL_IB_AUTONEG_INPROG)) &&\n\t\t    ppd->link_speed_active == QIB_IB_SDR &&\n\t\t    (ppd->link_speed_enabled & QIB_IB_DDR)\n\t\t    && ppd->cpspec->autoneg_tries < AUTONEG_TRIES) {\n\t\t\t \n\t\t\t++ppd->cpspec->autoneg_tries;\n\t\t\tif (!ppd->cpspec->ibdeltainprog) {\n\t\t\t\tppd->cpspec->ibdeltainprog = 1;\n\t\t\t\tppd->cpspec->ibsymdelta +=\n\t\t\t\t\tread_7322_creg32_port(ppd,\n\t\t\t\t\t\tcrp_ibsymbolerr) -\n\t\t\t\t\t\tppd->cpspec->ibsymsnap;\n\t\t\t\tppd->cpspec->iblnkerrdelta +=\n\t\t\t\t\tread_7322_creg32_port(ppd,\n\t\t\t\t\t\tcrp_iblinkerrrecov) -\n\t\t\t\t\t\tppd->cpspec->iblnkerrsnap;\n\t\t\t}\n\t\t\ttry_7322_autoneg(ppd);\n\t\t\tret = 1;  \n\t\t} else if ((ppd->lflags & QIBL_IB_AUTONEG_INPROG) &&\n\t\t\t   ppd->link_speed_active == QIB_IB_SDR) {\n\t\t\tqib_autoneg_7322_send(ppd, 1);\n\t\t\tset_7322_ibspeed_fast(ppd, QIB_IB_DDR);\n\t\t\tqib_7322_mini_pcs_reset(ppd);\n\t\t\tudelay(2);\n\t\t\tret = 1;  \n\t\t} else if ((ppd->lflags & QIBL_IB_AUTONEG_INPROG) &&\n\t\t\t   (ppd->link_speed_active & QIB_IB_DDR)) {\n\t\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\t\tppd->lflags &= ~(QIBL_IB_AUTONEG_INPROG |\n\t\t\t\t\t QIBL_IB_AUTONEG_FAILED);\n\t\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t\t\tppd->cpspec->autoneg_tries = 0;\n\t\t\t \n\t\t\tset_7322_ibspeed_fast(ppd, ppd->link_speed_enabled);\n\t\t\twake_up(&ppd->cpspec->autoneg_wait);\n\t\t\tsymadj = 1;\n\t\t} else if (ppd->lflags & QIBL_IB_AUTONEG_FAILED) {\n\t\t\t \n\t\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\t\tppd->lflags &= ~QIBL_IB_AUTONEG_FAILED;\n\t\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t\t\tppd->cpspec->ibcctrl_b |= IBA7322_IBC_IBTA_1_2_MASK;\n\t\t\tsymadj = 1;\n\t\t}\n\t\tif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG)) {\n\t\t\tsymadj = 1;\n\t\t\tif (ppd->dd->cspec->r1 && ppd->cpspec->ipg_tries <= 10)\n\t\t\t\ttry_7322_ipg(ppd);\n\t\t\tif (!ppd->cpspec->recovery_init)\n\t\t\t\tsetup_7322_link_recovery(ppd, 0);\n\t\t\tppd->cpspec->qdr_dfe_time = jiffies +\n\t\t\t\tmsecs_to_jiffies(QDR_DFE_DISABLE_DELAY);\n\t\t}\n\t\tppd->cpspec->ibmalfusesnap = 0;\n\t\tppd->cpspec->ibmalfsnap = read_7322_creg32_port(ppd,\n\t\t\tcrp_errlink);\n\t}\n\tif (symadj) {\n\t\tppd->cpspec->iblnkdownsnap =\n\t\t\tread_7322_creg32_port(ppd, crp_iblinkdown);\n\t\tif (ppd->cpspec->ibdeltainprog) {\n\t\t\tppd->cpspec->ibdeltainprog = 0;\n\t\t\tppd->cpspec->ibsymdelta += read_7322_creg32_port(ppd,\n\t\t\t\tcrp_ibsymbolerr) - ppd->cpspec->ibsymsnap;\n\t\t\tppd->cpspec->iblnkerrdelta += read_7322_creg32_port(ppd,\n\t\t\t\tcrp_iblinkerrrecov) - ppd->cpspec->iblnkerrsnap;\n\t\t}\n\t} else if (!ibup && qib_compat_ddr_negotiate &&\n\t\t   !ppd->cpspec->ibdeltainprog &&\n\t\t\t!(ppd->lflags & QIBL_IB_AUTONEG_INPROG)) {\n\t\tppd->cpspec->ibdeltainprog = 1;\n\t\tppd->cpspec->ibsymsnap = read_7322_creg32_port(ppd,\n\t\t\tcrp_ibsymbolerr);\n\t\tppd->cpspec->iblnkerrsnap = read_7322_creg32_port(ppd,\n\t\t\tcrp_iblinkerrrecov);\n\t}\n\n\tif (!ret)\n\t\tqib_setup_7322_setextled(ppd, ibup);\n\treturn ret;\n}\n\n \nstatic int gpio_7322_mod(struct qib_devdata *dd, u32 out, u32 dir, u32 mask)\n{\n\tu64 read_val, new_out;\n\tunsigned long flags;\n\n\tif (mask) {\n\t\t \n\t\tdir &= mask;\n\t\tout &= mask;\n\t\tspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\n\t\tdd->cspec->extctrl &= ~((u64)mask << SYM_LSB(EXTCtrl, GPIOOe));\n\t\tdd->cspec->extctrl |= ((u64) dir << SYM_LSB(EXTCtrl, GPIOOe));\n\t\tnew_out = (dd->cspec->gpio_out & ~mask) | out;\n\n\t\tqib_write_kreg(dd, kr_extctrl, dd->cspec->extctrl);\n\t\tqib_write_kreg(dd, kr_gpio_out, new_out);\n\t\tdd->cspec->gpio_out = new_out;\n\t\tspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\n\t}\n\t \n\tread_val = qib_read_kreg64(dd, kr_extstatus);\n\treturn SYM_FIELD(read_val, EXTStatus, GPIOIn);\n}\n\n \nstatic int qib_7322_eeprom_wen(struct qib_devdata *dd, int wen)\n{\n\tint prev_wen;\n\tu32 mask;\n\n\tmask = 1 << QIB_EEPROM_WEN_NUM;\n\tprev_wen = ~gpio_7322_mod(dd, 0, 0, 0) >> QIB_EEPROM_WEN_NUM;\n\tgpio_7322_mod(dd, wen ? 0 : mask, mask, mask);\n\n\treturn prev_wen & 1;\n}\n\n \nstatic void get_7322_chip_params(struct qib_devdata *dd)\n{\n\tu64 val;\n\tu32 piobufs;\n\tint mtu;\n\n\tdd->palign = qib_read_kreg32(dd, kr_pagealign);\n\n\tdd->uregbase = qib_read_kreg32(dd, kr_userregbase);\n\n\tdd->rcvtidcnt = qib_read_kreg32(dd, kr_rcvtidcnt);\n\tdd->rcvtidbase = qib_read_kreg32(dd, kr_rcvtidbase);\n\tdd->rcvegrbase = qib_read_kreg32(dd, kr_rcvegrbase);\n\tdd->piobufbase = qib_read_kreg64(dd, kr_sendpiobufbase);\n\tdd->pio2k_bufbase = dd->piobufbase & 0xffffffff;\n\n\tval = qib_read_kreg64(dd, kr_sendpiobufcnt);\n\tdd->piobcnt2k = val & ~0U;\n\tdd->piobcnt4k = val >> 32;\n\tval = qib_read_kreg64(dd, kr_sendpiosize);\n\tdd->piosize2k = val & ~0U;\n\tdd->piosize4k = val >> 32;\n\n\tmtu = ib_mtu_enum_to_int(qib_ibmtu);\n\tif (mtu == -1)\n\t\tmtu = QIB_DEFAULT_MTU;\n\tdd->pport[0].ibmtu = (u32)mtu;\n\tdd->pport[1].ibmtu = (u32)mtu;\n\n\t \n\tdd->pio2kbase = (u32 __iomem *)\n\t\t((char __iomem *) dd->kregbase + dd->pio2k_bufbase);\n\tdd->pio4kbase = (u32 __iomem *)\n\t\t((char __iomem *) dd->kregbase +\n\t\t (dd->piobufbase >> 32));\n\t \n\tdd->align4k = ALIGN(dd->piosize4k, dd->palign);\n\n\tpiobufs = dd->piobcnt4k + dd->piobcnt2k + NUM_VL15_BUFS;\n\n\tdd->pioavregs = ALIGN(piobufs, sizeof(u64) * BITS_PER_BYTE / 2) /\n\t\t(sizeof(u64) * BITS_PER_BYTE / 2);\n}\n\n \nstatic void qib_7322_set_baseaddrs(struct qib_devdata *dd)\n{\n\tu32 cregbase;\n\n\tcregbase = qib_read_kreg32(dd, kr_counterregbase);\n\n\tdd->cspec->cregbase = (u64 __iomem *)(cregbase +\n\t\t(char __iomem *)dd->kregbase);\n\n\tdd->egrtidbase = (u64 __iomem *)\n\t\t((char __iomem *) dd->kregbase + dd->rcvegrbase);\n\n\t \n\tdd->pport[0].cpspec->kpregbase =\n\t\t(u64 __iomem *)((char __iomem *)dd->kregbase);\n\tdd->pport[1].cpspec->kpregbase =\n\t\t(u64 __iomem *)(dd->palign +\n\t\t(char __iomem *)dd->kregbase);\n\tdd->pport[0].cpspec->cpregbase =\n\t\t(u64 __iomem *)(qib_read_kreg_port(&dd->pport[0],\n\t\tkr_counterregbase) + (char __iomem *)dd->kregbase);\n\tdd->pport[1].cpspec->cpregbase =\n\t\t(u64 __iomem *)(qib_read_kreg_port(&dd->pport[1],\n\t\tkr_counterregbase) + (char __iomem *)dd->kregbase);\n}\n\n \n\n#define SENDCTRL_SHADOWED (SYM_MASK(SendCtrl_0, SendEnable) |\t\t\\\n\t\t\t   SYM_MASK(SendCtrl_0, SDmaEnable) |\t\t\\\n\t\t\t   SYM_MASK(SendCtrl_0, SDmaIntEnable) |\t\\\n\t\t\t   SYM_MASK(SendCtrl_0, SDmaSingleDescriptor) | \\\n\t\t\t   SYM_MASK(SendCtrl_0, SDmaHalt) |\t\t\\\n\t\t\t   SYM_MASK(SendCtrl_0, IBVLArbiterEn) |\t\\\n\t\t\t   SYM_MASK(SendCtrl_0, ForceCreditUpToDate))\n\nstatic int sendctrl_hook(struct qib_devdata *dd,\n\t\t\t const struct diag_observer *op, u32 offs,\n\t\t\t u64 *data, u64 mask, int only_32)\n{\n\tunsigned long flags;\n\tunsigned idx;\n\tunsigned pidx;\n\tstruct qib_pportdata *ppd = NULL;\n\tu64 local_data, all_bits;\n\n\t \n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\n\t\tu64 __iomem *psptr;\n\t\tu32 psoffs;\n\n\t\tppd = dd->pport + pidx;\n\t\tif (!ppd->cpspec->kpregbase)\n\t\t\tcontinue;\n\n\t\tpsptr = ppd->cpspec->kpregbase + krp_sendctrl;\n\t\tpsoffs = (u32) (psptr - dd->kregbase) * sizeof(*psptr);\n\t\tif (psoffs == offs)\n\t\t\tbreak;\n\t}\n\n\t \n\tif (pidx >= dd->num_pports)\n\t\tppd = NULL;\n\n\t \n\tidx = offs / sizeof(u64);\n\n\tall_bits = ~0ULL;\n\tif (only_32)\n\t\tall_bits >>= 32;\n\n\tspin_lock_irqsave(&dd->sendctrl_lock, flags);\n\tif (!ppd || (mask & all_bits) != all_bits) {\n\t\t \n\t\tif (only_32)\n\t\t\tlocal_data = (u64)qib_read_kreg32(dd, idx);\n\t\telse\n\t\t\tlocal_data = qib_read_kreg64(dd, idx);\n\t\t*data = (local_data & ~mask) | (*data & mask);\n\t}\n\tif (mask) {\n\t\t \n\t\tu64 sval, tval;  \n\n\t\t \n\t\tif (ppd) {\n\t\t\tsval = ppd->p_sendctrl & ~mask;\n\t\t\tsval |= *data & SENDCTRL_SHADOWED & mask;\n\t\t\tppd->p_sendctrl = sval;\n\t\t} else\n\t\t\tsval = *data & SENDCTRL_SHADOWED & mask;\n\t\ttval = sval | (*data & ~SENDCTRL_SHADOWED & mask);\n\t\tqib_write_kreg(dd, idx, tval);\n\t\tqib_write_kreg(dd, kr_scratch, 0Ull);\n\t}\n\tspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\n\treturn only_32 ? 4 : 8;\n}\n\nstatic const struct diag_observer sendctrl_0_observer = {\n\tsendctrl_hook, KREG_IDX(SendCtrl_0) * sizeof(u64),\n\tKREG_IDX(SendCtrl_0) * sizeof(u64)\n};\n\nstatic const struct diag_observer sendctrl_1_observer = {\n\tsendctrl_hook, KREG_IDX(SendCtrl_1) * sizeof(u64),\n\tKREG_IDX(SendCtrl_1) * sizeof(u64)\n};\n\nstatic ushort sdma_fetch_prio = 8;\nmodule_param_named(sdma_fetch_prio, sdma_fetch_prio, ushort, S_IRUGO);\nMODULE_PARM_DESC(sdma_fetch_prio, \"SDMA descriptor fetch priority\");\n\n \nstatic void init_txdds_table(struct qib_pportdata *ppd, int override);\n\nstatic void qsfp_7322_event(struct work_struct *work)\n{\n\tstruct qib_qsfp_data *qd;\n\tstruct qib_pportdata *ppd;\n\tunsigned long pwrup;\n\tunsigned long flags;\n\tint ret;\n\tu32 le2;\n\n\tqd = container_of(work, struct qib_qsfp_data, work);\n\tppd = qd->ppd;\n\tpwrup = qd->t_insert +\n\t\tmsecs_to_jiffies(QSFP_PWR_LAG_MSEC - QSFP_MODPRS_LAG_MSEC);\n\n\t \n\tmdelay(QSFP_MODPRS_LAG_MSEC);\n\n\tif (!qib_qsfp_mod_present(ppd)) {\n\t\tppd->cpspec->qsfp_data.modpresent = 0;\n\t\t \n\t\tqib_set_ib_7322_lstate(ppd, 0,\n\t\t\t\t       QLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\n\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\tppd->lflags &= ~QIBL_LINKV;\n\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t} else {\n\t\t \n\t\twhile (1) {\n\t\t\tif (time_is_before_jiffies(pwrup))\n\t\t\t\tbreak;\n\t\t\tmsleep(20);\n\t\t}\n\n\t\tret = qib_refresh_qsfp_cache(ppd, &qd->cache);\n\n\t\t \n\t\tif (!ret && !ppd->dd->cspec->r1) {\n\t\t\tif (QSFP_IS_ACTIVE_FAR(qd->cache.tech))\n\t\t\t\tle2 = LE2_QME;\n\t\t\telse if (qd->cache.atten[1] >= qib_long_atten &&\n\t\t\t\t QSFP_IS_CU(qd->cache.tech))\n\t\t\t\tle2 = LE2_5m;\n\t\t\telse\n\t\t\t\tle2 = LE2_DEFAULT;\n\t\t} else\n\t\t\tle2 = LE2_DEFAULT;\n\t\tibsd_wr_allchans(ppd, 13, (le2 << 7), BMASK(9, 7));\n\t\t \n\t\tinit_txdds_table(ppd, 0);\n\t\t \n\t\tif (!ppd->cpspec->qsfp_data.modpresent &&\n\t\t    (ppd->lflags & (QIBL_LINKV | QIBL_IB_LINK_DISABLED))) {\n\t\t\tppd->cpspec->qsfp_data.modpresent = 1;\n\t\t\tqib_set_ib_7322_lstate(ppd, 0,\n\t\t\t\tQLOGIC_IB_IBCC_LINKINITCMD_SLEEP);\n\t\t\tspin_lock_irqsave(&ppd->lflags_lock, flags);\n\t\t\tppd->lflags |= QIBL_LINKV;\n\t\t\tspin_unlock_irqrestore(&ppd->lflags_lock, flags);\n\t\t}\n\t}\n}\n\n \nstatic void qib_init_7322_qsfp(struct qib_pportdata *ppd)\n{\n\tunsigned long flags;\n\tstruct qib_qsfp_data *qd = &ppd->cpspec->qsfp_data;\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 mod_prs_bit = QSFP_GPIO_MOD_PRS_N;\n\n\tmod_prs_bit <<= (QSFP_GPIO_PORT2_SHIFT * ppd->hw_pidx);\n\tqd->ppd = ppd;\n\tqib_qsfp_init(qd, qsfp_7322_event);\n\tspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\n\tdd->cspec->extctrl |= (mod_prs_bit << SYM_LSB(EXTCtrl, GPIOInvert));\n\tdd->cspec->gpio_mask |= mod_prs_bit;\n\tqib_write_kreg(dd, kr_extctrl, dd->cspec->extctrl);\n\tqib_write_kreg(dd, kr_gpio_mask, dd->cspec->gpio_mask);\n\tspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\n}\n\n \nstatic void set_no_qsfp_atten(struct qib_devdata *dd, int change)\n{\n\tchar *nxt, *str;\n\tu32 pidx, unit, port, deflt, h1;\n\tunsigned long val;\n\tint any = 0, seth1;\n\tint txdds_size;\n\n\tstr = txselect_list;\n\n\t \n\tdeflt = simple_strtoul(str, &nxt, 0);\n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx)\n\t\tdd->pport[pidx].cpspec->no_eep = deflt;\n\n\ttxdds_size = TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ;\n\tif (IS_QME(dd) || IS_QMH(dd))\n\t\ttxdds_size += TXDDS_MFG_SZ;\n\n\twhile (*nxt && nxt[1]) {\n\t\tstr = ++nxt;\n\t\tunit = simple_strtoul(str, &nxt, 0);\n\t\tif (nxt == str || !*nxt || *nxt != ',') {\n\t\t\twhile (*nxt && *nxt++ != ' ')  \n\t\t\t\t;\n\t\t\tcontinue;\n\t\t}\n\t\tstr = ++nxt;\n\t\tport = simple_strtoul(str, &nxt, 0);\n\t\tif (nxt == str || *nxt != '=') {\n\t\t\twhile (*nxt && *nxt++ != ' ')  \n\t\t\t\t;\n\t\t\tcontinue;\n\t\t}\n\t\tstr = ++nxt;\n\t\tval = simple_strtoul(str, &nxt, 0);\n\t\tif (nxt == str) {\n\t\t\twhile (*nxt && *nxt++ != ' ')  \n\t\t\t\t;\n\t\t\tcontinue;\n\t\t}\n\t\tif (val >= txdds_size)\n\t\t\tcontinue;\n\t\tseth1 = 0;\n\t\th1 = 0;  \n\t\tif (*nxt == ',' && nxt[1]) {\n\t\t\tstr = ++nxt;\n\t\t\th1 = (u32)simple_strtoul(str, &nxt, 0);\n\t\t\tif (nxt == str)\n\t\t\t\twhile (*nxt && *nxt++ != ' ')  \n\t\t\t\t\t;\n\t\t\telse\n\t\t\t\tseth1 = 1;\n\t\t}\n\t\tfor (pidx = 0; dd->unit == unit && pidx < dd->num_pports;\n\t\t     ++pidx) {\n\t\t\tstruct qib_pportdata *ppd = &dd->pport[pidx];\n\n\t\t\tif (ppd->port != port || !ppd->link_speed_supported)\n\t\t\t\tcontinue;\n\t\t\tppd->cpspec->no_eep = val;\n\t\t\tif (seth1)\n\t\t\t\tppd->cpspec->h1_val = h1;\n\t\t\t \n\t\t\tinit_txdds_table(ppd, 1);\n\t\t\t \n\t\t\tif (IS_QMH(dd) || IS_QME(dd))\n\t\t\t\tqib_set_ib_7322_lstate(ppd, 0,\n\t\t\t\t\t    QLOGIC_IB_IBCC_LINKINITCMD_SLEEP);\n\t\t\tany++;\n\t\t}\n\t\tif (*nxt == '\\n')\n\t\t\tbreak;  \n\t}\n\tif (change && !any) {\n\t\t \n\t\tfor (pidx = 0; pidx < dd->num_pports; ++pidx)\n\t\t\tif (dd->pport[pidx].link_speed_supported)\n\t\t\t\tinit_txdds_table(&dd->pport[pidx], 0);\n\t}\n}\n\n \nstatic int setup_txselect(const char *str, const struct kernel_param *kp)\n{\n\tstruct qib_devdata *dd;\n\tunsigned long index, val;\n\tchar *n;\n\n\tif (strlen(str) >= ARRAY_SIZE(txselect_list)) {\n\t\tpr_info(\"txselect_values string too long\\n\");\n\t\treturn -ENOSPC;\n\t}\n\tval = simple_strtoul(str, &n, 0);\n\tif (n == str || val >= (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ +\n\t\t\t\tTXDDS_MFG_SZ)) {\n\t\tpr_info(\"txselect_values must start with a number < %d\\n\",\n\t\t\tTXDDS_TABLE_SZ + TXDDS_EXTRA_SZ + TXDDS_MFG_SZ);\n\t\treturn -EINVAL;\n\t}\n\tstrncpy(txselect_list, str, ARRAY_SIZE(txselect_list) - 1);\n\n\txa_for_each(&qib_dev_table, index, dd)\n\t\tif (dd->deviceid == PCI_DEVICE_ID_QLOGIC_IB_7322)\n\t\t\tset_no_qsfp_atten(dd, 1);\n\treturn 0;\n}\n\n \nstatic int qib_late_7322_initreg(struct qib_devdata *dd)\n{\n\tint ret = 0, n;\n\tu64 val;\n\n\tqib_write_kreg(dd, kr_rcvhdrentsize, dd->rcvhdrentsize);\n\tqib_write_kreg(dd, kr_rcvhdrsize, dd->rcvhdrsize);\n\tqib_write_kreg(dd, kr_rcvhdrcnt, dd->rcvhdrcnt);\n\tqib_write_kreg(dd, kr_sendpioavailaddr, dd->pioavailregs_phys);\n\tval = qib_read_kreg64(dd, kr_sendpioavailaddr);\n\tif (val != dd->pioavailregs_phys) {\n\t\tqib_dev_err(dd,\n\t\t\t\"Catastrophic software error, SendPIOAvailAddr written as %lx, read back as %llx\\n\",\n\t\t\t(unsigned long) dd->pioavailregs_phys,\n\t\t\t(unsigned long long) val);\n\t\tret = -EINVAL;\n\t}\n\n\tn = dd->piobcnt2k + dd->piobcnt4k + NUM_VL15_BUFS;\n\tqib_7322_txchk_change(dd, 0, n, TXCHK_CHG_TYPE_KERN, NULL);\n\t \n\tqib_7322_txchk_change(dd, 0, n, TXCHK_CHG_TYPE_ENAB1, NULL);\n\n\tqib_register_observer(dd, &sendctrl_0_observer);\n\tqib_register_observer(dd, &sendctrl_1_observer);\n\n\tdd->control &= ~QLOGIC_IB_C_SDMAFETCHPRIOEN;\n\tqib_write_kreg(dd, kr_control, dd->control);\n\t \n\tset_no_qsfp_atten(dd, 0);\n\tfor (n = 0; n < dd->num_pports; ++n) {\n\t\tstruct qib_pportdata *ppd = dd->pport + n;\n\n\t\tqib_write_kreg_port(ppd, krp_senddmaprioritythld,\n\t\t\t\t    sdma_fetch_prio & 0xf);\n\t\t \n\t\tif (dd->flags & QIB_HAS_QSFP)\n\t\t\tqib_init_7322_qsfp(ppd);\n\t}\n\tdd->control |= QLOGIC_IB_C_SDMAFETCHPRIOEN;\n\tqib_write_kreg(dd, kr_control, dd->control);\n\n\treturn ret;\n}\n\n \n#define SENDCTRL_PIBP (MASK_ACROSS(0, 1) | MASK_ACROSS(3, 3) | \\\n\tMASK_ACROSS(8, 15))\n#define RCVCTRL_PIBP (MASK_ACROSS(0, 17) | MASK_ACROSS(39, 41))\n#define ERRS_PIBP (MASK_ACROSS(57, 58) | MASK_ACROSS(54, 54) | \\\n\tMASK_ACROSS(36, 49) | MASK_ACROSS(29, 34) | MASK_ACROSS(14, 17) | \\\n\tMASK_ACROSS(0, 11))\n\n \nstatic void write_7322_init_portregs(struct qib_pportdata *ppd)\n{\n\tu64 val;\n\tint i;\n\n\tif (!ppd->link_speed_supported) {\n\t\t \n\t\tfor (i = 1; i < 8; i++)\n\t\t\tqib_write_kreg_port(ppd, krp_rxcreditvl0 + i, 0);\n\t\tqib_write_kreg_port(ppd, krp_ibcctrl_b, 0);\n\t\tqib_write_kreg(ppd->dd, kr_scratch, 0);\n\t\treturn;\n\t}\n\n\t \n\tval = qib_read_kreg_port(ppd, krp_ibsdtestiftx);\n\tval &= ~SYM_MASK(IB_SDTEST_IF_TX_0, VL_CAP);\n\tval |= (u64)(ppd->vls_supported - 1) <<\n\t\tSYM_LSB(IB_SDTEST_IF_TX_0, VL_CAP);\n\tqib_write_kreg_port(ppd, krp_ibsdtestiftx, val);\n\n\tqib_write_kreg_port(ppd, krp_rcvbthqp, QIB_KD_QP);\n\n\t \n\tqib_write_kreg_port(ppd, krp_sendcheckcontrol, IBA7322_SENDCHK_PKEY |\n\t\t\t    IBA7322_SENDCHK_BTHQP | IBA7322_SENDCHK_SLID |\n\t\t\t    IBA7322_SENDCHK_RAW_IPV6 | IBA7322_SENDCHK_MINSZ);\n\n\tqib_write_kreg_port(ppd, krp_ncmodectrl,\n\t\tSYM_MASK(IBNCModeCtrl_0, ScrambleCapLocal));\n\n\t \n\tqib_write_kreg_port(ppd, krp_senddmabufmask0, 0);\n\tqib_write_kreg_port(ppd, krp_senddmabufmask1, 0);\n\tqib_write_kreg_port(ppd, krp_senddmabufmask2, 0);\n\tif (ppd->dd->cspec->r1)\n\t\tppd->p_sendctrl |= SYM_MASK(SendCtrl_0, ForceCreditUpToDate);\n}\n\n \nstatic void write_7322_initregs(struct qib_devdata *dd)\n{\n\tstruct qib_pportdata *ppd;\n\tint i, pidx;\n\tu64 val;\n\n\t \n\tqib_write_kreg(dd, KREG_IDX(RcvQPMulticastContext_1), 1);\n\n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\n\t\tunsigned n, regno;\n\t\tunsigned long flags;\n\n\t\tif (dd->n_krcv_queues < 2 ||\n\t\t\t!dd->pport[pidx].link_speed_supported)\n\t\t\tcontinue;\n\n\t\tppd = &dd->pport[pidx];\n\n\t\t \n\t\tspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\n\t\tppd->p_rcvctrl |= SYM_MASK(RcvCtrl_0, RcvQPMapEnable);\n\t\tspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\n\n\t\t \n\t\tregno = krp_rcvqpmaptable;\n\t\tval = 0;\n\t\tif (dd->num_pports > 1)\n\t\t\tn = dd->first_user_ctxt / dd->num_pports;\n\t\telse\n\t\t\tn = dd->first_user_ctxt - 1;\n\t\tfor (i = 0; i < 32; ) {\n\t\t\tunsigned ctxt;\n\n\t\t\tif (dd->num_pports > 1)\n\t\t\t\tctxt = (i % n) * dd->num_pports + pidx;\n\t\t\telse if (i % n)\n\t\t\t\tctxt = (i % n) + 1;\n\t\t\telse\n\t\t\t\tctxt = ppd->hw_pidx;\n\t\t\tval |= ctxt << (5 * (i % 6));\n\t\t\ti++;\n\t\t\tif (i % 6 == 0) {\n\t\t\t\tqib_write_kreg_port(ppd, regno, val);\n\t\t\t\tval = 0;\n\t\t\t\tregno++;\n\t\t\t}\n\t\t}\n\t\tqib_write_kreg_port(ppd, regno, val);\n\t}\n\n\t \n\tfor (i = 0; i < dd->first_user_ctxt; i++) {\n\t\tdd->cspec->rcvavail_timeout[i] = rcv_int_timeout;\n\t\tqib_write_kreg(dd, kr_rcvavailtimeout + i, rcv_int_timeout);\n\t}\n\n\t \n\tval = TIDFLOW_ERRBITS;  \n\tfor (i = 0; i < dd->cfgctxts; i++) {\n\t\tint flow;\n\n\t\tfor (flow = 0; flow < NUM_TIDFLOWS_CTXT; flow++)\n\t\t\tqib_write_ureg(dd, ur_rcvflowtable+flow, val, i);\n\t}\n\n\t \n\tif (dd->num_pports)\n\t\tsetup_7322_link_recovery(dd->pport, dd->num_pports > 1);\n}\n\nstatic int qib_init_7322_variables(struct qib_devdata *dd)\n{\n\tstruct qib_pportdata *ppd;\n\tunsigned features, pidx, sbufcnt;\n\tint ret, mtu;\n\tu32 sbufs, updthresh;\n\tresource_size_t vl15off;\n\n\t \n\tppd = (struct qib_pportdata *)(dd + 1);\n\tdd->pport = ppd;\n\tppd[0].dd = dd;\n\tppd[1].dd = dd;\n\n\tdd->cspec = (struct qib_chip_specific *)(ppd + 2);\n\n\tppd[0].cpspec = (struct qib_chippport_specific *)(dd->cspec + 1);\n\tppd[1].cpspec = &ppd[0].cpspec[1];\n\tppd[0].cpspec->ppd = &ppd[0];  \n\tppd[1].cpspec->ppd = &ppd[1];  \n\n\tspin_lock_init(&dd->cspec->rcvmod_lock);\n\tspin_lock_init(&dd->cspec->gpio_lock);\n\n\t \n\tdd->revision = readq(&dd->kregbase[kr_revision]);\n\n\tif ((dd->revision & 0xffffffffU) == 0xffffffffU) {\n\t\tqib_dev_err(dd,\n\t\t\t\"Revision register read failure, giving up initialization\\n\");\n\t\tret = -ENODEV;\n\t\tgoto bail;\n\t}\n\tdd->flags |= QIB_PRESENT;   \n\n\tdd->majrev = (u8) SYM_FIELD(dd->revision, Revision_R, ChipRevMajor);\n\tdd->minrev = (u8) SYM_FIELD(dd->revision, Revision_R, ChipRevMinor);\n\tdd->cspec->r1 = dd->minrev == 1;\n\n\tget_7322_chip_params(dd);\n\tfeatures = qib_7322_boardname(dd);\n\n\t \n\tsbufcnt = dd->piobcnt2k + dd->piobcnt4k + NUM_VL15_BUFS;\n\n\tdd->cspec->sendchkenable = bitmap_zalloc(sbufcnt, GFP_KERNEL);\n\tdd->cspec->sendgrhchk = bitmap_zalloc(sbufcnt, GFP_KERNEL);\n\tdd->cspec->sendibchk = bitmap_zalloc(sbufcnt, GFP_KERNEL);\n\tif (!dd->cspec->sendchkenable || !dd->cspec->sendgrhchk ||\n\t\t!dd->cspec->sendibchk) {\n\t\tret = -ENOMEM;\n\t\tgoto bail;\n\t}\n\n\tppd = dd->pport;\n\n\t \n\tdd->gpio_sda_num = _QIB_GPIO_SDA_NUM;\n\tdd->gpio_scl_num = _QIB_GPIO_SCL_NUM;\n\tdd->twsi_eeprom_dev = QIB_TWSI_EEPROM_DEV;\n\n\tdd->flags |= QIB_HAS_INTX | QIB_HAS_LINK_LATENCY |\n\t\tQIB_NODMA_RTAIL | QIB_HAS_VLSUPP | QIB_HAS_HDRSUPP |\n\t\tQIB_HAS_THRESH_UPDATE |\n\t\t(sdma_idle_cnt ? QIB_HAS_SDMA_TIMEOUT : 0);\n\tdd->flags |= qib_special_trigger ?\n\t\tQIB_USE_SPCL_TRIG : QIB_HAS_SEND_DMA;\n\n\t \n\tqib_7322_set_baseaddrs(dd);\n\n\tmtu = ib_mtu_enum_to_int(qib_ibmtu);\n\tif (mtu == -1)\n\t\tmtu = QIB_DEFAULT_MTU;\n\n\tdd->cspec->int_enable_mask = QIB_I_BITSEXTANT;\n\t \n\tdd->cspec->hwerrmask = ~0ULL;\n\t \n\tdd->cspec->hwerrmask &=\n\t\t~(SYM_MASK(HwErrMask, IBSerdesPClkNotDetectMask_0) |\n\t\t  SYM_MASK(HwErrMask, IBSerdesPClkNotDetectMask_1) |\n\t\t  HWE_MASK(LATriggered));\n\n\tfor (pidx = 0; pidx < NUM_IB_PORTS; ++pidx) {\n\t\tstruct qib_chippport_specific *cp = ppd->cpspec;\n\n\t\tppd->link_speed_supported = features & PORT_SPD_CAP;\n\t\tfeatures >>=  PORT_SPD_CAP_SHIFT;\n\t\tif (!ppd->link_speed_supported) {\n\t\t\t \n\t\t\tdd->skip_kctxt_mask |= 1 << pidx;\n\t\t\tif (pidx == 0) {\n\t\t\t\t \n\t\t\t\tqib_write_kreg_port(ppd, krp_rcvctrl, 0);\n\t\t\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a, 0);\n\t\t\t\tppd[0] = ppd[1];\n\t\t\t\tdd->cspec->hwerrmask &= ~(SYM_MASK(HwErrMask,\n\t\t\t\t\t\t  IBSerdesPClkNotDetectMask_0)\n\t\t\t\t\t\t  | SYM_MASK(HwErrMask,\n\t\t\t\t\t\t  SDmaMemReadErrMask_0));\n\t\t\t\tdd->cspec->int_enable_mask &= ~(\n\t\t\t\t     SYM_MASK(IntMask, SDmaCleanupDoneMask_0) |\n\t\t\t\t     SYM_MASK(IntMask, SDmaIdleIntMask_0) |\n\t\t\t\t     SYM_MASK(IntMask, SDmaProgressIntMask_0) |\n\t\t\t\t     SYM_MASK(IntMask, SDmaIntMask_0) |\n\t\t\t\t     SYM_MASK(IntMask, ErrIntMask_0) |\n\t\t\t\t     SYM_MASK(IntMask, SendDoneIntMask_0));\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tqib_write_kreg_port(ppd, krp_rcvctrl, 0);\n\t\t\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a, 0);\n\t\t\t\tdd->cspec->hwerrmask &= ~(SYM_MASK(HwErrMask,\n\t\t\t\t\t\t  IBSerdesPClkNotDetectMask_1)\n\t\t\t\t\t\t  | SYM_MASK(HwErrMask,\n\t\t\t\t\t\t  SDmaMemReadErrMask_1));\n\t\t\t\tdd->cspec->int_enable_mask &= ~(\n\t\t\t\t     SYM_MASK(IntMask, SDmaCleanupDoneMask_1) |\n\t\t\t\t     SYM_MASK(IntMask, SDmaIdleIntMask_1) |\n\t\t\t\t     SYM_MASK(IntMask, SDmaProgressIntMask_1) |\n\t\t\t\t     SYM_MASK(IntMask, SDmaIntMask_1) |\n\t\t\t\t     SYM_MASK(IntMask, ErrIntMask_1) |\n\t\t\t\t     SYM_MASK(IntMask, SendDoneIntMask_1));\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tdd->num_pports++;\n\t\tret = qib_init_pportdata(ppd, dd, pidx, dd->num_pports);\n\t\tif (ret) {\n\t\t\tdd->num_pports--;\n\t\t\tgoto bail;\n\t\t}\n\n\t\tppd->link_width_supported = IB_WIDTH_1X | IB_WIDTH_4X;\n\t\tppd->link_width_enabled = IB_WIDTH_4X;\n\t\tppd->link_speed_enabled = ppd->link_speed_supported;\n\t\t \n\t\tppd->link_width_active = IB_WIDTH_4X;\n\t\tppd->link_speed_active = QIB_IB_SDR;\n\t\tppd->delay_mult = ib_rate_to_delay[IB_RATE_10_GBPS];\n\t\tswitch (qib_num_cfg_vls) {\n\t\tcase 1:\n\t\t\tppd->vls_supported = IB_VL_VL0;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tppd->vls_supported = IB_VL_VL0_1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tqib_devinfo(dd->pcidev,\n\t\t\t\t    \"Invalid num_vls %u, using 4 VLs\\n\",\n\t\t\t\t    qib_num_cfg_vls);\n\t\t\tqib_num_cfg_vls = 4;\n\t\t\tfallthrough;\n\t\tcase 4:\n\t\t\tppd->vls_supported = IB_VL_VL0_3;\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tif (mtu <= 2048)\n\t\t\t\tppd->vls_supported = IB_VL_VL0_7;\n\t\t\telse {\n\t\t\t\tqib_devinfo(dd->pcidev,\n\t\t\t\t\t    \"Invalid num_vls %u for MTU %d , using 4 VLs\\n\",\n\t\t\t\t\t    qib_num_cfg_vls, mtu);\n\t\t\t\tppd->vls_supported = IB_VL_VL0_3;\n\t\t\t\tqib_num_cfg_vls = 4;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tppd->vls_operational = ppd->vls_supported;\n\n\t\tinit_waitqueue_head(&cp->autoneg_wait);\n\t\tINIT_DELAYED_WORK(&cp->autoneg_work,\n\t\t\t\t  autoneg_7322_work);\n\t\tif (ppd->dd->cspec->r1)\n\t\t\tINIT_DELAYED_WORK(&cp->ipg_work, ipg_7322_work);\n\n\t\t \n\t\tif (!(dd->flags & QIB_HAS_QSFP)) {\n\t\t\tif (!IS_QMH(dd) && !IS_QME(dd))\n\t\t\t\tqib_devinfo(dd->pcidev,\n\t\t\t\t\t\"IB%u:%u: Unknown mezzanine card type\\n\",\n\t\t\t\t\tdd->unit, ppd->port);\n\t\t\tcp->h1_val = IS_QMH(dd) ? H1_FORCE_QMH : H1_FORCE_QME;\n\t\t\t \n\t\t\tppd->cpspec->no_eep = IS_QMH(dd) ?\n\t\t\t\tTXDDS_TABLE_SZ + 2 : TXDDS_TABLE_SZ + 4;\n\t\t} else\n\t\t\tcp->h1_val = H1_FORCE_VAL;\n\n\t\t \n\t\tif (!qib_mini_init)\n\t\t\twrite_7322_init_portregs(ppd);\n\n\t\ttimer_setup(&cp->chase_timer, reenable_chase, 0);\n\n\t\tppd++;\n\t}\n\n\tdd->rcvhdrentsize = qib_rcvhdrentsize ?\n\t\tqib_rcvhdrentsize : QIB_RCVHDR_ENTSIZE;\n\tdd->rcvhdrsize = qib_rcvhdrsize ?\n\t\tqib_rcvhdrsize : QIB_DFLT_RCVHDRSIZE;\n\tdd->rhf_offset = dd->rcvhdrentsize - sizeof(u64) / sizeof(u32);\n\n\t \n\tdd->rcvegrbufsize = max(mtu, 2048);\n\tdd->rcvegrbufsize_shift = ilog2(dd->rcvegrbufsize);\n\n\tqib_7322_tidtemplate(dd);\n\n\t \n\tdd->rhdrhead_intr_off =\n\t\t(u64) rcv_int_count << IBA7322_HDRHEAD_PKTINT_SHIFT;\n\n\t \n\ttimer_setup(&dd->stats_timer, qib_get_7322_faststats, 0);\n\n\tdd->ureg_align = 0x10000;   \n\n\tdd->piosize2kmax_dwords = dd->piosize2k >> 2;\n\n\tqib_7322_config_ctxts(dd);\n\tqib_set_ctxtcnt(dd);\n\n\t \n\tret = init_chip_wc_pat(dd, 0);\n\tif (ret)\n\t\tgoto bail;\n\n\t \n\tvl15off = dd->physaddr + (dd->piobufbase >> 32) +\n\t\t  dd->piobcnt4k * dd->align4k;\n\tdd->piovl15base\t= ioremap(vl15off,\n\t\t\t\t\t  NUM_VL15_BUFS * dd->align4k);\n\tif (!dd->piovl15base) {\n\t\tret = -ENOMEM;\n\t\tgoto bail;\n\t}\n\n\tqib_7322_set_baseaddrs(dd);  \n\n\tret = 0;\n\tif (qib_mini_init)\n\t\tgoto bail;\n\tif (!dd->num_pports) {\n\t\tqib_dev_err(dd, \"No ports enabled, giving up initialization\\n\");\n\t\tgoto bail;  \n\t}\n\n\twrite_7322_initregs(dd);\n\tret = qib_create_ctxts(dd);\n\tinit_7322_cntrnames(dd);\n\n\tupdthresh = 8U;  \n\n\t \n\tif (dd->flags & QIB_HAS_SEND_DMA) {\n\t\tdd->cspec->sdmabufcnt = dd->piobcnt4k;\n\t\tsbufs = updthresh > 3 ? updthresh : 3;\n\t} else {\n\t\tdd->cspec->sdmabufcnt = 0;\n\t\tsbufs = dd->piobcnt4k;\n\t}\n\tdd->cspec->lastbuf_for_pio = dd->piobcnt2k + dd->piobcnt4k -\n\t\tdd->cspec->sdmabufcnt;\n\tdd->lastctxt_piobuf = dd->cspec->lastbuf_for_pio - sbufs;\n\tdd->cspec->lastbuf_for_pio--;  \n\tdd->last_pio = dd->cspec->lastbuf_for_pio;\n\tdd->pbufsctxt = (dd->cfgctxts > dd->first_user_ctxt) ?\n\t\tdd->lastctxt_piobuf / (dd->cfgctxts - dd->first_user_ctxt) : 0;\n\n\t \n\tif (dd->pbufsctxt >= 2 && dd->pbufsctxt - 2 < updthresh)\n\t\tupdthresh = dd->pbufsctxt - 2;\n\tdd->cspec->updthresh_dflt = updthresh;\n\tdd->cspec->updthresh = updthresh;\n\n\t \n\tdd->sendctrl |= ((updthresh & SYM_RMASK(SendCtrl, AvailUpdThld))\n\t\t\t     << SYM_LSB(SendCtrl, AvailUpdThld)) |\n\t\t\tSYM_MASK(SendCtrl, SendBufAvailPad64Byte);\n\n\tdd->psxmitwait_supported = 1;\n\tdd->psxmitwait_check_rate = QIB_7322_PSXMITWAIT_CHECK_RATE;\nbail:\n\tif (!dd->ctxtcnt)\n\t\tdd->ctxtcnt = 1;  \n\n\treturn ret;\n}\n\nstatic u32 __iomem *qib_7322_getsendbuf(struct qib_pportdata *ppd, u64 pbc,\n\t\t\t\t\tu32 *pbufnum)\n{\n\tu32 first, last, plen = pbc & QIB_PBC_LENGTH_MASK;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\t \n\tif (pbc & PBC_7322_VL15_SEND) {\n\t\tfirst = dd->piobcnt2k + dd->piobcnt4k + ppd->hw_pidx;\n\t\tlast = first;\n\t} else {\n\t\tif ((plen + 1) > dd->piosize2kmax_dwords)\n\t\t\tfirst = dd->piobcnt2k;\n\t\telse\n\t\t\tfirst = 0;\n\t\tlast = dd->cspec->lastbuf_for_pio;\n\t}\n\treturn qib_getsendbuf_range(dd, pbufnum, first, last);\n}\n\nstatic void qib_set_cntr_7322_sample(struct qib_pportdata *ppd, u32 intv,\n\t\t\t\t     u32 start)\n{\n\tqib_write_kreg_port(ppd, krp_psinterval, intv);\n\tqib_write_kreg_port(ppd, krp_psstart, start);\n}\n\n \nstatic void qib_sdma_set_7322_desc_cnt(struct qib_pportdata *ppd, unsigned cnt)\n{\n\tqib_write_kreg_port(ppd, krp_senddmadesccnt, cnt);\n}\n\n \nstatic void dump_sdma_7322_state(struct qib_pportdata *ppd)\n{\n\tu64 reg, reg1, reg2;\n\n\treg = qib_read_kreg_port(ppd, krp_senddmastatus);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmastatus: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_sendctrl);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA sendctrl: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmabase);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmabase: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmabufmask0);\n\treg1 = qib_read_kreg_port(ppd, krp_senddmabufmask1);\n\treg2 = qib_read_kreg_port(ppd, krp_senddmabufmask2);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmabufmask 0:%llx  1:%llx  2:%llx\\n\",\n\t\t reg, reg1, reg2);\n\n\t \n\treg = qib_read_kreg_port(ppd, krp_senddmabuf_use0);\n\tqib_write_kreg_port(ppd, krp_senddmabuf_use0, reg);\n\treg1 = qib_read_kreg_port(ppd, krp_senddmabuf_use1);\n\tqib_write_kreg_port(ppd, krp_senddmabuf_use0, reg1);\n\treg2 = qib_read_kreg_port(ppd, krp_senddmabuf_use2);\n\tqib_write_kreg_port(ppd, krp_senddmabuf_use0, reg2);\n\t \n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t \"SDMA current senddmabuf_use 0:%llx  1:%llx  2:%llx\\n\",\n\t\t reg, reg1, reg2);\n\treg = qib_read_kreg_port(ppd, krp_senddmabuf_use0);\n\treg1 = qib_read_kreg_port(ppd, krp_senddmabuf_use1);\n\treg2 = qib_read_kreg_port(ppd, krp_senddmabuf_use2);\n\t \n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t \"SDMA cleared senddmabuf_use 0:%llx  1:%llx  2:%llx\\n\",\n\t\t reg, reg1, reg2);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmatail);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmatail: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmahead);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmahead: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmaheadaddr);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmaheadaddr: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmalengen);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmalengen: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmadesccnt);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmadesccnt: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmaidlecnt);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmaidlecnt: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmaprioritythld);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmapriorityhld: 0x%016llx\\n\", reg);\n\n\treg = qib_read_kreg_port(ppd, krp_senddmareloadcnt);\n\tqib_dev_porterr(ppd->dd, ppd->port,\n\t\t\"SDMA senddmareloadcnt: 0x%016llx\\n\", reg);\n\n\tdump_sdma_state(ppd);\n}\n\nstatic struct sdma_set_state_action sdma_7322_action_table[] = {\n\t[qib_sdma_state_s00_hw_down] = {\n\t\t.go_s99_running_tofalse = 1,\n\t\t.op_enable = 0,\n\t\t.op_intenable = 0,\n\t\t.op_halt = 0,\n\t\t.op_drain = 0,\n\t},\n\t[qib_sdma_state_s10_hw_start_up_wait] = {\n\t\t.op_enable = 0,\n\t\t.op_intenable = 1,\n\t\t.op_halt = 1,\n\t\t.op_drain = 0,\n\t},\n\t[qib_sdma_state_s20_idle] = {\n\t\t.op_enable = 1,\n\t\t.op_intenable = 1,\n\t\t.op_halt = 1,\n\t\t.op_drain = 0,\n\t},\n\t[qib_sdma_state_s30_sw_clean_up_wait] = {\n\t\t.op_enable = 0,\n\t\t.op_intenable = 1,\n\t\t.op_halt = 1,\n\t\t.op_drain = 0,\n\t},\n\t[qib_sdma_state_s40_hw_clean_up_wait] = {\n\t\t.op_enable = 1,\n\t\t.op_intenable = 1,\n\t\t.op_halt = 1,\n\t\t.op_drain = 0,\n\t},\n\t[qib_sdma_state_s50_hw_halt_wait] = {\n\t\t.op_enable = 1,\n\t\t.op_intenable = 1,\n\t\t.op_halt = 1,\n\t\t.op_drain = 1,\n\t},\n\t[qib_sdma_state_s99_running] = {\n\t\t.op_enable = 1,\n\t\t.op_intenable = 1,\n\t\t.op_halt = 0,\n\t\t.op_drain = 0,\n\t\t.go_s99_running_totrue = 1,\n\t},\n};\n\nstatic void qib_7322_sdma_init_early(struct qib_pportdata *ppd)\n{\n\tppd->sdma_state.set_state_action = sdma_7322_action_table;\n}\n\nstatic int init_sdma_7322_regs(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tunsigned lastbuf, erstbuf;\n\tu64 senddmabufmask[3] = { 0 };\n\tint n;\n\n\tqib_write_kreg_port(ppd, krp_senddmabase, ppd->sdma_descq_phys);\n\tqib_sdma_7322_setlengen(ppd);\n\tqib_sdma_update_7322_tail(ppd, 0);  \n\tqib_write_kreg_port(ppd, krp_senddmareloadcnt, sdma_idle_cnt);\n\tqib_write_kreg_port(ppd, krp_senddmadesccnt, 0);\n\tqib_write_kreg_port(ppd, krp_senddmaheadaddr, ppd->sdma_head_phys);\n\n\tif (dd->num_pports)\n\t\tn = dd->cspec->sdmabufcnt / dd->num_pports;  \n\telse\n\t\tn = dd->cspec->sdmabufcnt;  \n\terstbuf = (dd->piobcnt2k + dd->piobcnt4k) -\n\t\t((dd->num_pports == 1 || ppd->port == 2) ? n :\n\t\tdd->cspec->sdmabufcnt);\n\tlastbuf = erstbuf + n;\n\n\tppd->sdma_state.first_sendbuf = erstbuf;\n\tppd->sdma_state.last_sendbuf = lastbuf;\n\tfor (; erstbuf < lastbuf; ++erstbuf) {\n\t\tunsigned word = erstbuf / BITS_PER_LONG;\n\t\tunsigned bit = erstbuf & (BITS_PER_LONG - 1);\n\n\t\tsenddmabufmask[word] |= 1ULL << bit;\n\t}\n\tqib_write_kreg_port(ppd, krp_senddmabufmask0, senddmabufmask[0]);\n\tqib_write_kreg_port(ppd, krp_senddmabufmask1, senddmabufmask[1]);\n\tqib_write_kreg_port(ppd, krp_senddmabufmask2, senddmabufmask[2]);\n\treturn 0;\n}\n\n \nstatic u16 qib_sdma_7322_gethead(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tint sane;\n\tint use_dmahead;\n\tu16 swhead;\n\tu16 swtail;\n\tu16 cnt;\n\tu16 hwhead;\n\n\tuse_dmahead = __qib_sdma_running(ppd) &&\n\t\t(dd->flags & QIB_HAS_SDMA_TIMEOUT);\nretry:\n\thwhead = use_dmahead ?\n\t\t(u16) le64_to_cpu(*ppd->sdma_head_dma) :\n\t\t(u16) qib_read_kreg_port(ppd, krp_senddmahead);\n\n\tswhead = ppd->sdma_descq_head;\n\tswtail = ppd->sdma_descq_tail;\n\tcnt = ppd->sdma_descq_cnt;\n\n\tif (swhead < swtail)\n\t\t \n\t\tsane = (hwhead >= swhead) & (hwhead <= swtail);\n\telse if (swhead > swtail)\n\t\t \n\t\tsane = ((hwhead >= swhead) && (hwhead < cnt)) ||\n\t\t\t(hwhead <= swtail);\n\telse\n\t\t \n\t\tsane = (hwhead == swhead);\n\n\tif (unlikely(!sane)) {\n\t\tif (use_dmahead) {\n\t\t\t \n\t\t\tuse_dmahead = 0;\n\t\t\tgoto retry;\n\t\t}\n\t\t \n\t\thwhead = swhead;\n\t}\n\n\treturn hwhead;\n}\n\nstatic int qib_sdma_7322_busy(struct qib_pportdata *ppd)\n{\n\tu64 hwstatus = qib_read_kreg_port(ppd, krp_senddmastatus);\n\n\treturn (hwstatus & SYM_MASK(SendDmaStatus_0, ScoreBoardDrainInProg)) ||\n\t       (hwstatus & SYM_MASK(SendDmaStatus_0, HaltInProg)) ||\n\t       !(hwstatus & SYM_MASK(SendDmaStatus_0, InternalSDmaHalt)) ||\n\t       !(hwstatus & SYM_MASK(SendDmaStatus_0, ScbEmpty));\n}\n\n \nstatic u32 qib_7322_setpbc_control(struct qib_pportdata *ppd, u32 plen,\n\t\t\t\t   u8 srate, u8 vl)\n{\n\tu8 snd_mult = ppd->delay_mult;\n\tu8 rcv_mult = ib_rate_to_delay[srate];\n\tu32 ret;\n\n\tret = rcv_mult > snd_mult ? ((plen + 1) >> 1) * snd_mult : 0;\n\n\t \n\tif (vl == 15)\n\t\tret |= PBC_7322_VL15_SEND_CTRL;\n\telse\n\t\tret |= vl << PBC_VL_NUM_LSB;\n\tret |= ((u32)(ppd->hw_pidx)) << PBC_PORT_SEL_LSB;\n\n\treturn ret;\n}\n\n \nstatic void qib_7322_initvl15_bufs(struct qib_devdata *dd)\n{\n\tunsigned vl15bufs;\n\n\tvl15bufs = dd->piobcnt2k + dd->piobcnt4k;\n\tqib_chg_pioavailkernel(dd, vl15bufs, NUM_VL15_BUFS,\n\t\t\t       TXCHK_CHG_TYPE_KERN, NULL);\n}\n\nstatic void qib_7322_init_ctxt(struct qib_ctxtdata *rcd)\n{\n\tif (rcd->ctxt < NUM_IB_PORTS) {\n\t\tif (rcd->dd->num_pports > 1) {\n\t\t\trcd->rcvegrcnt = KCTXT0_EGRCNT / 2;\n\t\t\trcd->rcvegr_tid_base = rcd->ctxt ? rcd->rcvegrcnt : 0;\n\t\t} else {\n\t\t\trcd->rcvegrcnt = KCTXT0_EGRCNT;\n\t\t\trcd->rcvegr_tid_base = 0;\n\t\t}\n\t} else {\n\t\trcd->rcvegrcnt = rcd->dd->cspec->rcvegrcnt;\n\t\trcd->rcvegr_tid_base = KCTXT0_EGRCNT +\n\t\t\t(rcd->ctxt - NUM_IB_PORTS) * rcd->rcvegrcnt;\n\t}\n}\n\n#define QTXSLEEPS 5000\nstatic void qib_7322_txchk_change(struct qib_devdata *dd, u32 start,\n\t\t\t\t  u32 len, u32 which, struct qib_ctxtdata *rcd)\n{\n\tint i;\n\tconst int last = start + len - 1;\n\tconst int lastr = last / BITS_PER_LONG;\n\tu32 sleeps = 0;\n\tint wait = rcd != NULL;\n\tunsigned long flags;\n\n\twhile (wait) {\n\t\tunsigned long shadow = 0;\n\t\tint cstart, previ = -1;\n\n\t\t \n\t\tfor (cstart = start; cstart <= last; cstart++) {\n\t\t\ti = ((2 * cstart) + QLOGIC_IB_SENDPIOAVAIL_BUSY_SHIFT)\n\t\t\t\t/ BITS_PER_LONG;\n\t\t\tif (i != previ) {\n\t\t\t\tshadow = (unsigned long)\n\t\t\t\t\tle64_to_cpu(dd->pioavailregs_dma[i]);\n\t\t\t\tprevi = i;\n\t\t\t}\n\t\t\tif (test_bit(((2 * cstart) +\n\t\t\t\t      QLOGIC_IB_SENDPIOAVAIL_BUSY_SHIFT)\n\t\t\t\t     % BITS_PER_LONG, &shadow))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (cstart > last)\n\t\t\tbreak;\n\n\t\tif (sleeps == QTXSLEEPS)\n\t\t\tbreak;\n\t\t \n\t\tsendctrl_7322_mod(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\n\t\tsleeps++;\n\t\tmsleep(20);\n\t}\n\n\tswitch (which) {\n\tcase TXCHK_CHG_TYPE_DIS1:\n\t\t \n\t\tfor (i = start; i <= last; i++)\n\t\t\tclear_bit(i, dd->cspec->sendchkenable);\n\t\tbreak;\n\n\tcase TXCHK_CHG_TYPE_ENAB1:\n\t\t \n\t\tqib_read_kreg32(dd, kr_scratch);\n\t\tfor (i = start; i <= last; i++)\n\t\t\tset_bit(i, dd->cspec->sendchkenable);\n\t\tbreak;\n\n\tcase TXCHK_CHG_TYPE_KERN:\n\t\t \n\t\tfor (i = start; i <= last; i++) {\n\t\t\tset_bit(i, dd->cspec->sendibchk);\n\t\t\tclear_bit(i, dd->cspec->sendgrhchk);\n\t\t}\n\t\tspin_lock_irqsave(&dd->uctxt_lock, flags);\n\t\t \n\t\tfor (i = dd->first_user_ctxt;\n\t\t     dd->cspec->updthresh != dd->cspec->updthresh_dflt\n\t\t     && i < dd->cfgctxts; i++)\n\t\t\tif (dd->rcd[i] && dd->rcd[i]->subctxt_cnt &&\n\t\t\t   ((dd->rcd[i]->piocnt / dd->rcd[i]->subctxt_cnt) - 1)\n\t\t\t   < dd->cspec->updthresh_dflt)\n\t\t\t\tbreak;\n\t\tspin_unlock_irqrestore(&dd->uctxt_lock, flags);\n\t\tif (i == dd->cfgctxts) {\n\t\t\tspin_lock_irqsave(&dd->sendctrl_lock, flags);\n\t\t\tdd->cspec->updthresh = dd->cspec->updthresh_dflt;\n\t\t\tdd->sendctrl &= ~SYM_MASK(SendCtrl, AvailUpdThld);\n\t\t\tdd->sendctrl |= (dd->cspec->updthresh &\n\t\t\t\t\t SYM_RMASK(SendCtrl, AvailUpdThld)) <<\n\t\t\t\t\t   SYM_LSB(SendCtrl, AvailUpdThld);\n\t\t\tspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\n\t\t\tsendctrl_7322_mod(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\n\t\t}\n\t\tbreak;\n\n\tcase TXCHK_CHG_TYPE_USER:\n\t\t \n\t\tfor (i = start; i <= last; i++) {\n\t\t\tclear_bit(i, dd->cspec->sendibchk);\n\t\t\tset_bit(i, dd->cspec->sendgrhchk);\n\t\t}\n\t\tspin_lock_irqsave(&dd->sendctrl_lock, flags);\n\t\tif (rcd && rcd->subctxt_cnt && ((rcd->piocnt\n\t\t\t/ rcd->subctxt_cnt) - 1) < dd->cspec->updthresh) {\n\t\t\tdd->cspec->updthresh = (rcd->piocnt /\n\t\t\t\t\t\trcd->subctxt_cnt) - 1;\n\t\t\tdd->sendctrl &= ~SYM_MASK(SendCtrl, AvailUpdThld);\n\t\t\tdd->sendctrl |= (dd->cspec->updthresh &\n\t\t\t\t\tSYM_RMASK(SendCtrl, AvailUpdThld))\n\t\t\t\t\t<< SYM_LSB(SendCtrl, AvailUpdThld);\n\t\t\tspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\n\t\t\tsendctrl_7322_mod(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\n\t\t} else\n\t\t\tspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tfor (i = start / BITS_PER_LONG; which >= 2 && i <= lastr; ++i)\n\t\tqib_write_kreg(dd, kr_sendcheckmask + i,\n\t\t\t       dd->cspec->sendchkenable[i]);\n\n\tfor (i = start / BITS_PER_LONG; which < 2 && i <= lastr; ++i) {\n\t\tqib_write_kreg(dd, kr_sendgrhcheckmask + i,\n\t\t\t       dd->cspec->sendgrhchk[i]);\n\t\tqib_write_kreg(dd, kr_sendibpktmask + i,\n\t\t\t       dd->cspec->sendibchk[i]);\n\t}\n\n\t \n\tqib_read_kreg32(dd, kr_scratch);\n}\n\n\n \nstatic void writescratch(struct qib_devdata *dd, u32 val)\n{\n\tqib_write_kreg(dd, kr_scratch, val);\n}\n\n \nstatic int qib_7322_tempsense_rd(struct qib_devdata *dd, int regnum)\n{\n\treturn -ENXIO;\n}\n\n \nstruct qib_devdata *qib_init_iba7322_funcs(struct pci_dev *pdev,\n\t\t\t\t\t   const struct pci_device_id *ent)\n{\n\tstruct qib_devdata *dd;\n\tint ret, i;\n\tu32 tabsize, actual_cnt = 0;\n\n\tdd = qib_alloc_devdata(pdev,\n\t\tNUM_IB_PORTS * sizeof(struct qib_pportdata) +\n\t\tsizeof(struct qib_chip_specific) +\n\t\tNUM_IB_PORTS * sizeof(struct qib_chippport_specific));\n\tif (IS_ERR(dd))\n\t\tgoto bail;\n\n\tdd->f_bringup_serdes    = qib_7322_bringup_serdes;\n\tdd->f_cleanup           = qib_setup_7322_cleanup;\n\tdd->f_clear_tids        = qib_7322_clear_tids;\n\tdd->f_free_irq          = qib_7322_free_irq;\n\tdd->f_get_base_info     = qib_7322_get_base_info;\n\tdd->f_get_msgheader     = qib_7322_get_msgheader;\n\tdd->f_getsendbuf        = qib_7322_getsendbuf;\n\tdd->f_gpio_mod          = gpio_7322_mod;\n\tdd->f_eeprom_wen        = qib_7322_eeprom_wen;\n\tdd->f_hdrqempty         = qib_7322_hdrqempty;\n\tdd->f_ib_updown         = qib_7322_ib_updown;\n\tdd->f_init_ctxt         = qib_7322_init_ctxt;\n\tdd->f_initvl15_bufs     = qib_7322_initvl15_bufs;\n\tdd->f_intr_fallback     = qib_7322_intr_fallback;\n\tdd->f_late_initreg      = qib_late_7322_initreg;\n\tdd->f_setpbc_control    = qib_7322_setpbc_control;\n\tdd->f_portcntr          = qib_portcntr_7322;\n\tdd->f_put_tid           = qib_7322_put_tid;\n\tdd->f_quiet_serdes      = qib_7322_mini_quiet_serdes;\n\tdd->f_rcvctrl           = rcvctrl_7322_mod;\n\tdd->f_read_cntrs        = qib_read_7322cntrs;\n\tdd->f_read_portcntrs    = qib_read_7322portcntrs;\n\tdd->f_reset             = qib_do_7322_reset;\n\tdd->f_init_sdma_regs    = init_sdma_7322_regs;\n\tdd->f_sdma_busy         = qib_sdma_7322_busy;\n\tdd->f_sdma_gethead      = qib_sdma_7322_gethead;\n\tdd->f_sdma_sendctrl     = qib_7322_sdma_sendctrl;\n\tdd->f_sdma_set_desc_cnt = qib_sdma_set_7322_desc_cnt;\n\tdd->f_sdma_update_tail  = qib_sdma_update_7322_tail;\n\tdd->f_sendctrl          = sendctrl_7322_mod;\n\tdd->f_set_armlaunch     = qib_set_7322_armlaunch;\n\tdd->f_set_cntr_sample   = qib_set_cntr_7322_sample;\n\tdd->f_iblink_state      = qib_7322_iblink_state;\n\tdd->f_ibphys_portstate  = qib_7322_phys_portstate;\n\tdd->f_get_ib_cfg        = qib_7322_get_ib_cfg;\n\tdd->f_set_ib_cfg        = qib_7322_set_ib_cfg;\n\tdd->f_set_ib_loopback   = qib_7322_set_loopback;\n\tdd->f_get_ib_table      = qib_7322_get_ib_table;\n\tdd->f_set_ib_table      = qib_7322_set_ib_table;\n\tdd->f_set_intr_state    = qib_7322_set_intr_state;\n\tdd->f_setextled         = qib_setup_7322_setextled;\n\tdd->f_txchk_change      = qib_7322_txchk_change;\n\tdd->f_update_usrhead    = qib_update_7322_usrhead;\n\tdd->f_wantpiobuf_intr   = qib_wantpiobuf_7322_intr;\n\tdd->f_xgxs_reset        = qib_7322_mini_pcs_reset;\n\tdd->f_sdma_hw_clean_up  = qib_7322_sdma_hw_clean_up;\n\tdd->f_sdma_hw_start_up  = qib_7322_sdma_hw_start_up;\n\tdd->f_sdma_init_early   = qib_7322_sdma_init_early;\n\tdd->f_writescratch      = writescratch;\n\tdd->f_tempsense_rd\t= qib_7322_tempsense_rd;\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\tdd->f_notify_dca\t= qib_7322_notify_dca;\n#endif\n\t \n\tret = qib_pcie_ddinit(dd, pdev, ent);\n\tif (ret < 0)\n\t\tgoto bail_free;\n\n\t \n\tret = qib_init_7322_variables(dd);\n\tif (ret)\n\t\tgoto bail_cleanup;\n\n\tif (qib_mini_init || !dd->num_pports)\n\t\tgoto bail;\n\n\t \n\ttabsize = dd->first_user_ctxt + ARRAY_SIZE(irq_table);\n\tfor (i = 0; i < tabsize; i++)\n\t\tif ((i < ARRAY_SIZE(irq_table) &&\n\t\t     irq_table[i].port <= dd->num_pports) ||\n\t\t    (i >= ARRAY_SIZE(irq_table) &&\n\t\t     dd->rcd[i - ARRAY_SIZE(irq_table)]))\n\t\t\tactual_cnt++;\n\t \n\tif (qib_krcvq01_no_msi)\n\t\tactual_cnt -= dd->num_pports;\n\n\ttabsize = actual_cnt;\n\tdd->cspec->msix_entries = kcalloc(tabsize,\n\t\t\t\t\t  sizeof(struct qib_msix_entry),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!dd->cspec->msix_entries)\n\t\ttabsize = 0;\n\n\tif (qib_pcie_params(dd, 8, &tabsize))\n\t\tqib_dev_err(dd,\n\t\t\t\"Failed to setup PCIe or interrupts; continuing anyway\\n\");\n\t \n\tdd->cspec->num_msix_entries = tabsize;\n\n\t \n\tqib_setup_7322_interrupt(dd, 1);\n\n\t \n\tqib_write_kreg(dd, kr_hwdiagctrl, 0);\n#ifdef CONFIG_INFINIBAND_QIB_DCA\n\tif (!dca_add_requester(&pdev->dev)) {\n\t\tqib_devinfo(dd->pcidev, \"DCA enabled\\n\");\n\t\tdd->flags |= QIB_DCA_ENABLED;\n\t\tqib_setup_dca(dd);\n\t}\n#endif\n\tgoto bail;\n\nbail_cleanup:\n\tqib_pcie_ddcleanup(dd);\nbail_free:\n\tqib_free_devdata(dd);\n\tdd = ERR_PTR(ret);\nbail:\n\treturn dd;\n}\n\n \n#define DDS_ENT_AMP_LSB 14\n#define DDS_ENT_MAIN_LSB 9\n#define DDS_ENT_POST_LSB 5\n#define DDS_ENT_PRE_XTRA_LSB 3\n#define DDS_ENT_PRE_LSB 0\n\n \nstatic void set_txdds(struct qib_pportdata *ppd, int ridx,\n\t\t      const struct txdds_ent *tp)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu32 pack_ent;\n\tint regidx;\n\n\t \n\tregidx = KREG_IBPORT_IDX(IBSD_DDS_MAP_TABLE) + ridx;\n\t \n\tif (ppd->hw_pidx)\n\t\tregidx += (dd->palign / sizeof(u64));\n\n\tpack_ent = tp->amp << DDS_ENT_AMP_LSB;\n\tpack_ent |= tp->main << DDS_ENT_MAIN_LSB;\n\tpack_ent |= tp->pre << DDS_ENT_PRE_LSB;\n\tpack_ent |= tp->post << DDS_ENT_POST_LSB;\n\tqib_write_kreg(dd, regidx, pack_ent);\n\t \n\tqib_write_kreg(ppd->dd, kr_scratch, 0);\n}\n\nstatic const struct vendor_txdds_ent vendor_txdds[] = {\n\t{  \n\t\t{ 0x41, 0x50, 0x48 }, \"584470002       \",\n\t\t{ 10,  0,  0,  5 }, { 10,  0,  0,  9 }, {  7,  1,  0, 13 },\n\t},\n\t{  \n\t\t{ 0x41, 0x50, 0x48 }, \"584470004       \",\n\t\t{  0,  0,  0,  8 }, {  0,  0,  0, 11 }, {  0,  1,  7, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x90, 0x65 }, \"FCBG410QB1C03-QL\",\n\t\t{  0,  0,  0,  3 }, {  0,  0,  0,  4 }, {  0,  0,  0, 13 },\n\t},\n\t{  \n\t\t{ 0x00, 0x90, 0x65 }, \"FCBG410QB1C30-QL\",\n\t\t{  0,  0,  0,  1 }, {  0,  0,  0,  5 }, {  0,  0,  0, 11 },\n\t},\n\t{  \n\t\t{ 0x00, 0x90, 0x65 }, NULL,\n\t\t{  0,  0,  0,  2 }, {  0,  0,  0,  5 }, {  0,  0,  0, 12 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN3300-1       \",\n\t\t{  0,  0,  0,  6 }, {  0,  0,  0,  9 }, {  0,  1,  0, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN3300-2       \",\n\t\t{  0,  0,  0,  8 }, {  0,  0,  0, 10 }, {  0,  1,  7, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN3800-1       \",\n\t\t{  0,  0,  0,  6 }, {  0,  0,  0,  8 }, {  0,  1,  0, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN3800-3       \",\n\t\t{  0,  0,  0,  9 }, {  0,  0,  0, 13 }, {  0,  1,  7, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN7000-5       \",\n\t\t{  0,  0,  0,  7 }, {  0,  0,  0,  9 }, {  0,  1,  3, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN7000-7       \",\n\t\t{  0,  0,  0,  9 }, {  0,  0,  0, 11 }, {  0,  2,  6, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN7600-5       \",\n\t\t{  0,  0,  0,  8 }, {  0,  0,  0, 11 }, {  0,  1,  9, 13 },\n\t},\n\t{  \n\t\t{ 0x00, 0x21, 0x77 }, \"QSN7600-7       \",\n\t\t{  0,  0,  0,  8 }, {  0,  0,  0, 11 }, {  10,  1,  8, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x30, 0xB4 }, \"QLX4000CQSFP1224\",\n\t\t{  0,  0,  0,  2 }, {  0,  0,  0,  5 }, {  0,  3,  0,  9 },\n\t},\n\t{  \n\t\t{ 0x00, 0x30, 0xB4 }, \"QLX4000CQSFP1028\",\n\t\t{  0,  0,  0,  6 }, {  0,  0,  0,  4 }, {  0,  2,  0,  2 },\n\t},\n\t{  \n\t\t{ 0x00, 0x30, 0xB4 }, \"QLX4000CQSFP0730\",\n\t\t{  0,  0,  0,  6 }, {  0,  0,  0,  4 }, {  0,  1,  0,  3 },\n\t},\n\t{  \n\t\t{ 0x00, 0x30, 0xB4 }, \"QLX4000CQSFP0532\",\n\t\t{  0,  0,  0,  6 }, {  0,  0,  0,  6 }, {  0,  2,  0,  8 },\n\t},\n\t{  \n\t\t{ 0x00, 0x30, 0xB4 }, NULL,\n\t\t{  0,  0,  0,  6 }, {  0,  0,  0,  5 }, {  0,  2,  0,  5 },\n\t},\n\t{  \n\t\t{ 0x00, 0x25, 0x63 }, NULL,\n\t\t{  0,  0,  0,  5 }, {  0,  0,  0,  8 }, {  0,  2,  0,  12 },\n\t},\n\t{  \n\t\t{ 0x00, 0x09, 0x3A }, \"74763-0025      \",\n\t\t{  2,  2,  6, 15 }, {  2,  2,  6, 15 }, {  2,  2,  6, 15 },\n\t},\n\t{  \n\t\t{ 0x00, 0x09, 0x3A }, \"74757-2201      \",\n\t\t{  0,  0,  0,  6 }, {  0,  0,  0,  9 }, {  0,  1,  1, 15 },\n\t},\n};\n\nstatic const struct txdds_ent txdds_sdr[TXDDS_TABLE_SZ] = {\n\t \n\t{  2, 2, 15,  6 },\t \n\t{  0, 0,  0,  1 },\t \n\t{  0, 0,  0,  2 },\t \n\t{  0, 0,  0,  3 },\t \n\t{  0, 0,  0,  4 },\t \n\t{  0, 0,  0,  5 },\t \n\t{  0, 0,  0,  6 },\t \n\t{  0, 0,  0,  7 },\t \n\t{  0, 0,  0,  8 },\t \n\t{  0, 0,  0,  9 },\t \n\t{  0, 0,  0, 10 },\t \n\t{  0, 0,  0, 11 },\t \n\t{  0, 0,  0, 12 },\t \n\t{  0, 0,  0, 13 },\t \n\t{  0, 0,  0, 14 },\t \n\t{  0, 0,  0, 15 },\t \n};\n\nstatic const struct txdds_ent txdds_ddr[TXDDS_TABLE_SZ] = {\n\t \n\t{  2, 2, 15,  6 },\t \n\t{  0, 0,  0,  8 },\t \n\t{  0, 0,  0,  8 },\t \n\t{  0, 0,  0,  9 },\t \n\t{  0, 0,  0,  9 },\t \n\t{  0, 0,  0, 10 },\t \n\t{  0, 0,  0, 10 },\t \n\t{  0, 0,  0, 11 },\t \n\t{  0, 0,  0, 11 },\t \n\t{  0, 0,  0, 12 },\t \n\t{  0, 0,  0, 12 },\t \n\t{  0, 0,  0, 13 },\t \n\t{  0, 0,  0, 13 },\t \n\t{  0, 0,  0, 14 },\t \n\t{  0, 0,  0, 14 },\t \n\t{  0, 0,  0, 15 },\t \n};\n\nstatic const struct txdds_ent txdds_qdr[TXDDS_TABLE_SZ] = {\n\t \n\t{  2, 2, 15,  6 },\t \n\t{  0, 1,  0,  7 },\t \n\t{  0, 1,  0,  9 },\t \n\t{  0, 1,  0, 11 },\t \n\t{  0, 1,  0, 13 },\t \n\t{  0, 1,  0, 15 },\t \n\t{  0, 1,  3, 15 },\t \n\t{  0, 1,  7, 15 },\t \n\t{  0, 1,  7, 15 },\t \n\t{  0, 1,  8, 15 },\t \n\t{  0, 1,  9, 15 },\t \n\t{  0, 1, 10, 15 },\t \n\t{  0, 2,  6, 15 },\t \n\t{  0, 2,  7, 15 },\t \n\t{  0, 2,  8, 15 },\t \n\t{  0, 2,  9, 15 },\t \n};\n\n \nstatic const struct txdds_ent txdds_extra_sdr[TXDDS_EXTRA_SZ] = {\n\t \n\t{  0, 0, 0,  1 },\t \n\t{  0, 0, 0,  1 },\t \n\t{  0, 0, 0,  2 },\t \n\t{  0, 0, 0,  2 },\t \n\t{  0, 0, 0,  3 },\t \n\t{  0, 0, 0,  4 },\t \n\t{  0, 1, 4, 15 },\t \n\t{  0, 1, 3, 15 },\t \n\t{  0, 1, 0, 12 },\t \n\t{  0, 1, 0, 11 },\t \n\t{  0, 1, 0,  9 },\t \n\t{  0, 1, 0, 14 },\t \n\t{  0, 1, 2, 15 },\t \n\t{  0, 1, 0, 11 },        \n\t{  0, 1, 0,  7 },        \n\t{  0, 1, 0,  9 },        \n\t{  0, 1, 0,  6 },        \n\t{  0, 1, 0,  8 },        \n};\n\nstatic const struct txdds_ent txdds_extra_ddr[TXDDS_EXTRA_SZ] = {\n\t \n\t{  0, 0, 0,  7 },\t \n\t{  0, 0, 0,  7 },\t \n\t{  0, 0, 0,  8 },\t \n\t{  0, 0, 0,  8 },\t \n\t{  0, 0, 0,  9 },\t \n\t{  0, 0, 0, 10 },\t \n\t{  0, 1, 4, 15 },\t \n\t{  0, 1, 3, 15 },\t \n\t{  0, 1, 0, 12 },\t \n\t{  0, 1, 0, 11 },\t \n\t{  0, 1, 0,  9 },\t \n\t{  0, 1, 0, 14 },\t \n\t{  0, 1, 2, 15 },\t \n\t{  0, 1, 0, 11 },        \n\t{  0, 1, 0,  7 },        \n\t{  0, 1, 0,  9 },        \n\t{  0, 1, 0,  6 },        \n\t{  0, 1, 0,  8 },        \n};\n\nstatic const struct txdds_ent txdds_extra_qdr[TXDDS_EXTRA_SZ] = {\n\t \n\t{  0, 1,  0,  4 },\t \n\t{  0, 1,  0,  5 },\t \n\t{  0, 1,  0,  6 },\t \n\t{  0, 1,  0,  8 },\t \n\t{  0, 1,  0, 10 },\t \n\t{  0, 1,  0, 12 },\t \n\t{  0, 1,  4, 15 },\t \n\t{  0, 1,  3, 15 },\t \n\t{  0, 1,  0, 12 },\t \n\t{  0, 1,  0, 11 },\t \n\t{  0, 1,  0,  9 },\t \n\t{  0, 1,  0, 14 },\t \n\t{  0, 1,  2, 15 },\t \n\t{  0, 1,  0, 11 },       \n\t{  0, 1,  0,  7 },       \n\t{  0, 1,  0,  9 },       \n\t{  0, 1,  0,  6 },       \n\t{  0, 1,  0,  8 },       \n};\n\nstatic const struct txdds_ent txdds_extra_mfg[TXDDS_MFG_SZ] = {\n\t \n\t{ 0, 0, 0, 0 },          \n\t{ 0, 0, 0, 6 },          \n};\n\nstatic const struct txdds_ent *get_atten_table(const struct txdds_ent *txdds,\n\t\t\t\t\t       unsigned atten)\n{\n\t \n\tif (atten <= 2)\n\t\tatten = 1;\n\telse if (atten > TXDDS_TABLE_SZ)\n\t\tatten = TXDDS_TABLE_SZ - 1;\n\telse\n\t\tatten--;\n\treturn txdds + atten;\n}\n\n \nstatic void find_best_ent(struct qib_pportdata *ppd,\n\t\t\t  const struct txdds_ent **sdr_dds,\n\t\t\t  const struct txdds_ent **ddr_dds,\n\t\t\t  const struct txdds_ent **qdr_dds, int override)\n{\n\tstruct qib_qsfp_cache *qd = &ppd->cpspec->qsfp_data.cache;\n\tint idx;\n\n\t \n\tfor (idx = 0; !override && idx < ARRAY_SIZE(vendor_txdds); ++idx) {\n\t\tconst struct vendor_txdds_ent *v = vendor_txdds + idx;\n\n\t\tif (!memcmp(v->oui, qd->oui, QSFP_VOUI_LEN) &&\n\t\t    (!v->partnum ||\n\t\t     !memcmp(v->partnum, qd->partnum, QSFP_PN_LEN))) {\n\t\t\t*sdr_dds = &v->sdr;\n\t\t\t*ddr_dds = &v->ddr;\n\t\t\t*qdr_dds = &v->qdr;\n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tif (!override && QSFP_IS_ACTIVE(qd->tech)) {\n\t\t*sdr_dds = txdds_sdr + ppd->dd->board_atten;\n\t\t*ddr_dds = txdds_ddr + ppd->dd->board_atten;\n\t\t*qdr_dds = txdds_qdr + ppd->dd->board_atten;\n\t\treturn;\n\t}\n\n\tif (!override && QSFP_HAS_ATTEN(qd->tech) && (qd->atten[0] ||\n\t\t\t\t\t\t      qd->atten[1])) {\n\t\t*sdr_dds = get_atten_table(txdds_sdr, qd->atten[0]);\n\t\t*ddr_dds = get_atten_table(txdds_ddr, qd->atten[0]);\n\t\t*qdr_dds = get_atten_table(txdds_qdr, qd->atten[1]);\n\t\treturn;\n\t} else if (ppd->cpspec->no_eep < TXDDS_TABLE_SZ) {\n\t\t \n\t\tidx = ppd->cpspec->no_eep;\n\t\t*sdr_dds = &txdds_sdr[idx];\n\t\t*ddr_dds = &txdds_ddr[idx];\n\t\t*qdr_dds = &txdds_qdr[idx];\n\t} else if (ppd->cpspec->no_eep < (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ)) {\n\t\t \n\t\tidx = ppd->cpspec->no_eep - TXDDS_TABLE_SZ;\n\t\t*sdr_dds = &txdds_extra_sdr[idx];\n\t\t*ddr_dds = &txdds_extra_ddr[idx];\n\t\t*qdr_dds = &txdds_extra_qdr[idx];\n\t} else if ((IS_QME(ppd->dd) || IS_QMH(ppd->dd)) &&\n\t\t   ppd->cpspec->no_eep < (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ +\n\t\t\t\t\t  TXDDS_MFG_SZ)) {\n\t\tidx = ppd->cpspec->no_eep - (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ);\n\t\tpr_info(\"IB%u:%u use idx %u into txdds_mfg\\n\",\n\t\t\tppd->dd->unit, ppd->port, idx);\n\t\t*sdr_dds = &txdds_extra_mfg[idx];\n\t\t*ddr_dds = &txdds_extra_mfg[idx];\n\t\t*qdr_dds = &txdds_extra_mfg[idx];\n\t} else {\n\t\t \n\t\t*sdr_dds = txdds_sdr + qib_long_atten;\n\t\t*ddr_dds = txdds_ddr + qib_long_atten;\n\t\t*qdr_dds = txdds_qdr + qib_long_atten;\n\t}\n}\n\nstatic void init_txdds_table(struct qib_pportdata *ppd, int override)\n{\n\tconst struct txdds_ent *sdr_dds, *ddr_dds, *qdr_dds;\n\tstruct txdds_ent *dds;\n\tint idx;\n\tint single_ent = 0;\n\n\tfind_best_ent(ppd, &sdr_dds, &ddr_dds, &qdr_dds, override);\n\n\t \n\tif (!(ppd->dd->flags & QIB_HAS_QSFP) || override)\n\t\tsingle_ent = 1;\n\n\t \n\tset_txdds(ppd, 0, sdr_dds);\n\tset_txdds(ppd, TXDDS_TABLE_SZ, ddr_dds);\n\tset_txdds(ppd, 2 * TXDDS_TABLE_SZ, qdr_dds);\n\tif (ppd->lflags & (QIBL_LINKINIT | QIBL_LINKARMED |\n\t\tQIBL_LINKACTIVE)) {\n\t\tdds = (struct txdds_ent *)(ppd->link_speed_active ==\n\t\t\t\t\t   QIB_IB_QDR ?  qdr_dds :\n\t\t\t\t\t   (ppd->link_speed_active ==\n\t\t\t\t\t    QIB_IB_DDR ? ddr_dds : sdr_dds));\n\t\twrite_tx_serdes_param(ppd, dds);\n\t}\n\n\t \n\tfor (idx = 1; idx < ARRAY_SIZE(txdds_sdr); ++idx) {\n\t\tset_txdds(ppd, idx, single_ent ? sdr_dds : txdds_sdr + idx);\n\t\tset_txdds(ppd, idx + TXDDS_TABLE_SZ,\n\t\t\t  single_ent ? ddr_dds : txdds_ddr + idx);\n\t\tset_txdds(ppd, idx + 2 * TXDDS_TABLE_SZ,\n\t\t\t  single_ent ? qdr_dds : txdds_qdr + idx);\n\t}\n}\n\n#define KR_AHB_ACC KREG_IDX(ahb_access_ctrl)\n#define KR_AHB_TRANS KREG_IDX(ahb_transaction_reg)\n#define AHB_TRANS_RDY SYM_MASK(ahb_transaction_reg, ahb_rdy)\n#define AHB_ADDR_LSB SYM_LSB(ahb_transaction_reg, ahb_address)\n#define AHB_DATA_LSB SYM_LSB(ahb_transaction_reg, ahb_data)\n#define AHB_WR SYM_MASK(ahb_transaction_reg, write_not_read)\n#define AHB_TRANS_TRIES 10\n\n \nstatic u32 ahb_mod(struct qib_devdata *dd, int quad, int chan, int addr,\n\t\t    u32 data, u32 mask)\n{\n\tu32 rd_data, wr_data, sz_mask;\n\tu64 trans, acc, prev_acc;\n\tu32 ret = 0xBAD0BAD;\n\tint tries;\n\n\tprev_acc = qib_read_kreg64(dd, KR_AHB_ACC);\n\t \n\tacc = (quad << 1) | 1;\n\tqib_write_kreg(dd, KR_AHB_ACC, acc);\n\n\tfor (tries = 1; tries < AHB_TRANS_TRIES; ++tries) {\n\t\ttrans = qib_read_kreg64(dd, KR_AHB_TRANS);\n\t\tif (trans & AHB_TRANS_RDY)\n\t\t\tbreak;\n\t}\n\tif (tries >= AHB_TRANS_TRIES) {\n\t\tqib_dev_err(dd, \"No ahb_rdy in %d tries\\n\", AHB_TRANS_TRIES);\n\t\tgoto bail;\n\t}\n\n\t \n\tsz_mask = (1UL << ((quad == 1) ? 32 : 16)) - 1;\n\twr_data = data & mask & sz_mask;\n\tif ((~mask & sz_mask) != 0) {\n\t\ttrans = ((chan << 6) | addr) << (AHB_ADDR_LSB + 1);\n\t\tqib_write_kreg(dd, KR_AHB_TRANS, trans);\n\n\t\tfor (tries = 1; tries < AHB_TRANS_TRIES; ++tries) {\n\t\t\ttrans = qib_read_kreg64(dd, KR_AHB_TRANS);\n\t\t\tif (trans & AHB_TRANS_RDY)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (tries >= AHB_TRANS_TRIES) {\n\t\t\tqib_dev_err(dd, \"No Rd ahb_rdy in %d tries\\n\",\n\t\t\t\t    AHB_TRANS_TRIES);\n\t\t\tgoto bail;\n\t\t}\n\t\t \n\t\ttrans = qib_read_kreg64(dd, KR_AHB_TRANS);\n\t\trd_data = (uint32_t)(trans >> AHB_DATA_LSB);\n\t\twr_data |= (rd_data & ~mask & sz_mask);\n\t}\n\n\t \n\tif (mask & sz_mask) {\n\t\ttrans = ((chan << 6) | addr) << (AHB_ADDR_LSB + 1);\n\t\ttrans |= ((uint64_t)wr_data << AHB_DATA_LSB);\n\t\ttrans |= AHB_WR;\n\t\tqib_write_kreg(dd, KR_AHB_TRANS, trans);\n\n\t\tfor (tries = 1; tries < AHB_TRANS_TRIES; ++tries) {\n\t\t\ttrans = qib_read_kreg64(dd, KR_AHB_TRANS);\n\t\t\tif (trans & AHB_TRANS_RDY)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (tries >= AHB_TRANS_TRIES) {\n\t\t\tqib_dev_err(dd, \"No Wr ahb_rdy in %d tries\\n\",\n\t\t\t\t    AHB_TRANS_TRIES);\n\t\t\tgoto bail;\n\t\t}\n\t}\n\tret = wr_data;\nbail:\n\tqib_write_kreg(dd, KR_AHB_ACC, prev_acc);\n\treturn ret;\n}\n\nstatic void ibsd_wr_allchans(struct qib_pportdata *ppd, int addr, unsigned data,\n\t\t\t     unsigned mask)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tint chan;\n\n\tfor (chan = 0; chan < SERDES_CHANS; ++chan) {\n\t\tahb_mod(dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)), addr,\n\t\t\tdata, mask);\n\t\tahb_mod(dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)), addr,\n\t\t\t0, 0);\n\t}\n}\n\nstatic void serdes_7322_los_enable(struct qib_pportdata *ppd, int enable)\n{\n\tu64 data = qib_read_kreg_port(ppd, krp_serdesctrl);\n\tu8 state = SYM_FIELD(data, IBSerdesCtrl_0, RXLOSEN);\n\n\tif (enable && !state) {\n\t\tpr_info(\"IB%u:%u Turning LOS on\\n\",\n\t\t\tppd->dd->unit, ppd->port);\n\t\tdata |= SYM_MASK(IBSerdesCtrl_0, RXLOSEN);\n\t} else if (!enable && state) {\n\t\tpr_info(\"IB%u:%u Turning LOS off\\n\",\n\t\t\tppd->dd->unit, ppd->port);\n\t\tdata &= ~SYM_MASK(IBSerdesCtrl_0, RXLOSEN);\n\t}\n\tqib_write_kreg_port(ppd, krp_serdesctrl, data);\n}\n\nstatic int serdes_7322_init(struct qib_pportdata *ppd)\n{\n\tint ret = 0;\n\n\tif (ppd->dd->cspec->r1)\n\t\tret = serdes_7322_init_old(ppd);\n\telse\n\t\tret = serdes_7322_init_new(ppd);\n\treturn ret;\n}\n\nstatic int serdes_7322_init_old(struct qib_pportdata *ppd)\n{\n\tu32 le_val;\n\n\t \n\tinit_txdds_table(ppd, 0);\n\n\t \n\tqib_write_kreg_port(ppd, krp_tx_deemph_override,\n\t\tSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\treset_tx_deemphasis_override));\n\n\t \n\t \n\tibsd_wr_allchans(ppd, 2, 0, BMASK(11, 9));\n\n\t \n\tibsd_wr_allchans(ppd, 11, (1 << 11), BMASK(12, 11));\n\t \n\tibsd_wr_allchans(ppd, 13, (1 << 6), (1 << 6));\n\n\t \n\tle_val = IS_QME(ppd->dd) ? LE2_QME : LE2_DEFAULT;\n\tibsd_wr_allchans(ppd, 13, (le_val << 7), BMASK(9, 7));\n\n\t \n\tle_val = IS_QME(ppd->dd) ? 0 : 1;\n\tibsd_wr_allchans(ppd, 13, (le_val << 5), (1 << 5));\n\n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 0 << 14, 1 << 14);\n\n\t \n\tibsd_wr_allchans(ppd, 5, (0 << 8), BMASK(9, 8));\n\n\t \n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 5, 8 << 11, BMASK(14, 11));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 8 << 4, BMASK(7, 4));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 8, 8 << 11, BMASK(14, 11));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 8 << 4, BMASK(7, 4));\n\n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 6, 4 << 0, BMASK(3, 0));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 4 << 8, BMASK(11, 8));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 4 << 0, BMASK(3, 0));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 4 << 8, BMASK(11, 8));\n\n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 1 << 15, 1 << 15);\n\n\t \n\tibsd_wr_allchans(ppd, 14, (1 << 3), BMASK(5, 3));  \n\tibsd_wr_allchans(ppd, 20, (2 << 10), BMASK(12, 10));  \n\tibsd_wr_allchans(ppd, 20, (4 << 13), BMASK(15, 13));  \n\n\tserdes_7322_los_enable(ppd, 1);\n\n\t \n\tibsd_wr_allchans(ppd, 9, 0 << 15, 1 << 15);\n\n\t \n\tibsd_wr_allchans(ppd, 16, 0 << 0, BMASK(1, 0));\n\n\t \n\tle_val = (ppd->dd->cspec->r1 || IS_QME(ppd->dd)) ? 0xb6c0 : 0x6bac;\n\tibsd_wr_allchans(ppd, 21, le_val, 0xfffe);\n\n\t \n\tqib_write_kreg_port(ppd, krp_static_adapt_dis(0), 0ULL);\n\tqib_write_kreg_port(ppd, krp_static_adapt_dis(1), 0ULL);\n\tqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\n\t\t\t    ppd->dd->cspec->r1 ?\n\t\t\t    QDR_STATIC_ADAPT_DOWN_R1 : QDR_STATIC_ADAPT_DOWN);\n\tppd->cpspec->qdr_dfe_on = 1;\n\n\t \n\tibsd_wr_allchans(ppd, 38, 0 << 10, 1 << 10);\n\n\t \n\tibsd_wr_allchans(ppd, 12, 1 << 4, 1 << 4);\n\n\tif (!ppd->dd->cspec->r1) {\n\t\tibsd_wr_allchans(ppd, 12, 1 << 12, 1 << 12);\n\t\tibsd_wr_allchans(ppd, 12, 2 << 8, 0x0f << 8);\n\t}\n\n\t \n\tibsd_wr_allchans(ppd, 2, 15 << 5, BMASK(8, 5));\n\n\treturn 0;\n}\n\nstatic int serdes_7322_init_new(struct qib_pportdata *ppd)\n{\n\tunsigned long tend;\n\tu32 le_val, rxcaldone;\n\tint chan, chan_done = (1 << SERDES_CHANS) - 1;\n\n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 0 << 14, 1 << 14);\n\n\t \n\tqib_write_kreg_port(ppd, krp_tx_deemph_override,\n\t\tSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\treset_tx_deemphasis_override));\n\n\t \n\t \n\t \n\tibsd_wr_allchans(ppd, 1, 0, BMASK(9, 1));\n\t \n\tibsd_wr_allchans(ppd, 13, 0, BMASK(5, 5));\n\t \n\tibsd_wr_allchans(ppd, 1, 0, BMASK(15, 15));\n\t \n\tibsd_wr_allchans(ppd, 13, 0, BMASK(6, 6));\n\t \n\tibsd_wr_allchans(ppd, 5, 0, BMASK(0, 0));\n\t \n\tibsd_wr_allchans(ppd, 12, 0, BMASK(12, 12));\n\t \n\tibsd_wr_allchans(ppd, 2, 0, BMASK(3, 3));\n\t \n\tibsd_wr_allchans(ppd, 2, 0, BMASK(4, 4));\n\t \n\tibsd_wr_allchans(ppd, 13, 0, BMASK(13, 13));\n\t \n\tibsd_wr_allchans(ppd, 4, 0, BMASK(10, 10));\n\t \n\tibsd_wr_allchans(ppd, 12, 0, BMASK(4, 4));\n\t \n\tibsd_wr_allchans(ppd, 2, (1 << 15), BMASK(15, 15));\n\t \n\tibsd_wr_allchans(ppd, 5, 0, BMASK(9, 8));\n\t \n\tibsd_wr_allchans(ppd, 12, (1 << 5), BMASK(5, 5));\n\t \n\tibsd_wr_allchans(ppd, 2, (4 << 12), BMASK(14, 12));\n\t \n\tibsd_wr_allchans(ppd, 16, 0, BMASK(1, 0));\n\t \n\tif (!ppd->dd->cspec->r1) {\n\t\tibsd_wr_allchans(ppd, 12, 1 << 12, BMASK(12, 12));\n\t\tibsd_wr_allchans(ppd, 12, 2 << 8, BMASK(11, 8));\n\t} else {\n\t\tibsd_wr_allchans(ppd, 19, (3 << 11), BMASK(13, 11));\n\t}\n\t \n\t \n\t \n\t \n\n\t \n\t \n\t \n\t \n\tibsd_wr_allchans(ppd, 0, 0, BMASK(15, 13));\n\tmsleep(20);\n\t \n\tibsd_wr_allchans(ppd, 0, (1 << 14), BMASK(14, 14));\n\tmsleep(20);\n\t \n\tibsd_wr_allchans(ppd, 0, (1 << 13), BMASK(13, 13));\n\tmsleep(20);\n\n\t \n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 5, 8 << 11, BMASK(14, 11));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 8 << 4, BMASK(7, 4));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 8, 8 << 11, BMASK(14, 11));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 8 << 4, BMASK(7, 4));\n\n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 6, 4 << 0, BMASK(3, 0));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 4 << 8, BMASK(11, 8));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 4 << 0, BMASK(3, 0));\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 4 << 8, BMASK(11, 8));\n\n\t \n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 1 << 15, 1 << 15);\n\n\t \n\tibsd_wr_allchans(ppd, 14, (1 << 3), BMASK(5, 3));  \n\tibsd_wr_allchans(ppd, 20, (2 << 10), BMASK(12, 10));  \n\tibsd_wr_allchans(ppd, 20, (4 << 13), BMASK(15, 13));  \n\n\t \n\tserdes_7322_los_enable(ppd, 1);\n\t \n\tibsd_wr_allchans(ppd, 38, 0 << 10, 1 << 10);\n\n\t \n\t \n\tibsd_wr_allchans(ppd, 15, 1, BMASK(0, 0));\n\t \n\tibsd_wr_allchans(ppd, 12, (1 << 4), BMASK(4, 4));\n\tmsleep(20);\n\t \n\tibsd_wr_allchans(ppd, 4, (1 << 10), BMASK(10, 10));\n\ttend = jiffies + msecs_to_jiffies(500);\n\twhile (chan_done && !time_is_before_jiffies(tend)) {\n\t\tmsleep(20);\n\t\tfor (chan = 0; chan < SERDES_CHANS; ++chan) {\n\t\t\trxcaldone = ahb_mod(ppd->dd, IBSD(ppd->hw_pidx),\n\t\t\t\t\t    (chan + (chan >> 1)),\n\t\t\t\t\t    25, 0, 0);\n\t\t\tif ((~rxcaldone & (u32)BMASK(9, 9)) == 0 &&\n\t\t\t    (~chan_done & (1 << chan)) == 0)\n\t\t\t\tchan_done &= ~(1 << chan);\n\t\t}\n\t}\n\tif (chan_done) {\n\t\tpr_info(\"Serdes %d calibration not done after .5 sec: 0x%x\\n\",\n\t\t\t IBSD(ppd->hw_pidx), chan_done);\n\t} else {\n\t\tfor (chan = 0; chan < SERDES_CHANS; ++chan) {\n\t\t\trxcaldone = ahb_mod(ppd->dd, IBSD(ppd->hw_pidx),\n\t\t\t\t\t    (chan + (chan >> 1)),\n\t\t\t\t\t    25, 0, 0);\n\t\t\tif ((~rxcaldone & (u32)BMASK(10, 10)) == 0)\n\t\t\t\tpr_info(\"Serdes %d chan %d calibration failed\\n\",\n\t\t\t\t\tIBSD(ppd->hw_pidx), chan);\n\t\t}\n\t}\n\n\t \n\tibsd_wr_allchans(ppd, 4, 0, BMASK(10, 10));\n\tmsleep(20);\n\n\t \n\t \n\tle_val = IS_QME(ppd->dd) ? LE2_QME : LE2_DEFAULT;\n\tibsd_wr_allchans(ppd, 13, (le_val << 7), BMASK(9, 7));\n\t \n\tibsd_wr_allchans(ppd, 3, (7 << 5), BMASK(7, 5));\n\t \n\tibsd_wr_allchans(ppd, 13, (1 << 6), BMASK(6, 6));\n\tmsleep(20);\n\t \n\tibsd_wr_allchans(ppd, 1, 1, BMASK(9, 1));\n\t \n\tle_val = (ppd->dd->cspec->r1 || IS_QME(ppd->dd)) ? 0xb6c0 : 0x6bac;\n\tibsd_wr_allchans(ppd, 21, le_val, 0xfffe);\n\t \n\tibsd_wr_allchans(ppd, 5, 0, BMASK(0, 0));\n\tmsleep(20);\n\t \n\tibsd_wr_allchans(ppd, 2, (15 << 5), BMASK(8, 5));\n\t \n\tibsd_wr_allchans(ppd, 2, (1 << 4), BMASK(4, 4));\n\t \n\tibsd_wr_allchans(ppd, 2, 0, BMASK(11, 9));\n\t \n\tibsd_wr_allchans(ppd, 2, (1 << 3), BMASK(3, 3));\n\tmsleep(50);\n\t \n\tqib_write_kreg_port(ppd, krp_static_adapt_dis(0), 0ULL);\n\tqib_write_kreg_port(ppd, krp_static_adapt_dis(1), 0ULL);\n\tqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\n\t\t\t    ppd->dd->cspec->r1 ?\n\t\t\t    QDR_STATIC_ADAPT_DOWN_R1 : QDR_STATIC_ADAPT_DOWN);\n\tppd->cpspec->qdr_dfe_on = 1;\n\t \n\tibsd_wr_allchans(ppd, 13, (0 << 5), (1 << 5));\n\t \n\tibsd_wr_allchans(ppd, 1, (0 << 15), BMASK(15, 15));\n\tmsleep(20);\n\t \n\tibsd_wr_allchans(ppd, 12, (1 << 12), BMASK(12, 12));\n\t \n\tibsd_wr_allchans(ppd, 12, (1 << 13), BMASK(13, 13));\n\t \n\tibsd_wr_allchans(ppd, 11, (1 << 11), BMASK(12, 11));\n\t \n\tibsd_wr_allchans(ppd, 12, (3 << 2), BMASK(3, 2));\n\n\t \n\tinit_txdds_table(ppd, 0);\n\n\treturn 0;\n}\n\n \n\nstatic void set_man_code(struct qib_pportdata *ppd, int chan, int code)\n{\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\n\t\t9, code << 9, 0x3f << 9);\n}\n\nstatic void set_man_mode_h1(struct qib_pportdata *ppd, int chan,\n\tint enable, u32 tapenable)\n{\n\tif (enable)\n\t\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\n\t\t\t1, 3 << 10, 0x1f << 10);\n\telse\n\t\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\n\t\t\t1, 0, 0x1f << 10);\n}\n\n \nstatic void clock_man(struct qib_pportdata *ppd, int chan)\n{\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\n\t\t4, 0x4000, 0x4000);\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\n\t\t4, 0, 0x4000);\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\n\t\t4, 0x4000, 0x4000);\n\tahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\n\t\t4, 0, 0x4000);\n}\n\n \nstatic void write_tx_serdes_param(struct qib_pportdata *ppd,\n\t\t\t\t  struct txdds_ent *txdds)\n{\n\tu64 deemph;\n\n\tdeemph = qib_read_kreg_port(ppd, krp_tx_deemph_override);\n\t \n\tdeemph &= ~(SYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txampcntl_d2a) |\n\t\t    SYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txc0_ena) |\n\t\t    SYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txcp1_ena) |\n\t\t    SYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txcn1_ena));\n\n\tdeemph |= SYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t\t   tx_override_deemphasis_select);\n\tdeemph |= (txdds->amp & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t    txampcntl_d2a)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t\t\t       txampcntl_d2a);\n\tdeemph |= (txdds->main & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t     txc0_ena)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t\t\t   txc0_ena);\n\tdeemph |= (txdds->post & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t     txcp1_ena)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t\t\t    txcp1_ena);\n\tdeemph |= (txdds->pre & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t     txcn1_ena)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\n\t\t\t\t    txcn1_ena);\n\tqib_write_kreg_port(ppd, krp_tx_deemph_override, deemph);\n}\n\n \nstatic void adj_tx_serdes(struct qib_pportdata *ppd)\n{\n\tconst struct txdds_ent *sdr_dds, *ddr_dds, *qdr_dds;\n\tstruct txdds_ent *dds;\n\n\tfind_best_ent(ppd, &sdr_dds, &ddr_dds, &qdr_dds, 1);\n\tdds = (struct txdds_ent *)(ppd->link_speed_active == QIB_IB_QDR ?\n\t\tqdr_dds : (ppd->link_speed_active == QIB_IB_DDR ?\n\t\t\t\tddr_dds : sdr_dds));\n\twrite_tx_serdes_param(ppd, dds);\n}\n\n \nstatic void force_h1(struct qib_pportdata *ppd)\n{\n\tint chan;\n\n\tppd->cpspec->qdr_reforce = 0;\n\tif (!ppd->dd->cspec->r1)\n\t\treturn;\n\n\tfor (chan = 0; chan < SERDES_CHANS; chan++) {\n\t\tset_man_mode_h1(ppd, chan, 1, 0);\n\t\tset_man_code(ppd, chan, ppd->cpspec->h1_val);\n\t\tclock_man(ppd, chan);\n\t\tset_man_mode_h1(ppd, chan, 0, 0);\n\t}\n}\n\n#define SJA_EN SYM_MASK(SPC_JTAG_ACCESS_REG, SPC_JTAG_ACCESS_EN)\n#define BISTEN_LSB SYM_LSB(SPC_JTAG_ACCESS_REG, bist_en)\n\n#define R_OPCODE_LSB 3\n#define R_OP_NOP 0\n#define R_OP_SHIFT 2\n#define R_OP_UPDATE 3\n#define R_TDI_LSB 2\n#define R_TDO_LSB 1\n#define R_RDY 1\n\nstatic int qib_r_grab(struct qib_devdata *dd)\n{\n\tu64 val = SJA_EN;\n\n\tqib_write_kreg(dd, kr_r_access, val);\n\tqib_read_kreg32(dd, kr_scratch);\n\treturn 0;\n}\n\n \nstatic int qib_r_wait_for_rdy(struct qib_devdata *dd)\n{\n\tu64 val;\n\tint timeout;\n\n\tfor (timeout = 0; timeout < 100 ; ++timeout) {\n\t\tval = qib_read_kreg32(dd, kr_r_access);\n\t\tif (val & R_RDY)\n\t\t\treturn (val >> R_TDO_LSB) & 1;\n\t}\n\treturn -1;\n}\n\nstatic int qib_r_shift(struct qib_devdata *dd, int bisten,\n\t\t       int len, u8 *inp, u8 *outp)\n{\n\tu64 valbase, val;\n\tint ret, pos;\n\n\tvalbase = SJA_EN | (bisten << BISTEN_LSB) |\n\t\t(R_OP_SHIFT << R_OPCODE_LSB);\n\tret = qib_r_wait_for_rdy(dd);\n\tif (ret < 0)\n\t\tgoto bail;\n\tfor (pos = 0; pos < len; ++pos) {\n\t\tval = valbase;\n\t\tif (outp) {\n\t\t\toutp[pos >> 3] &= ~(1 << (pos & 7));\n\t\t\toutp[pos >> 3] |= (ret << (pos & 7));\n\t\t}\n\t\tif (inp) {\n\t\t\tint tdi = inp[pos >> 3] >> (pos & 7);\n\n\t\t\tval |= ((tdi & 1) << R_TDI_LSB);\n\t\t}\n\t\tqib_write_kreg(dd, kr_r_access, val);\n\t\tqib_read_kreg32(dd, kr_scratch);\n\t\tret = qib_r_wait_for_rdy(dd);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\t}\n\t \n\tval =  SJA_EN | (bisten << BISTEN_LSB);\n\tqib_write_kreg(dd, kr_r_access, val);\n\tqib_read_kreg32(dd, kr_scratch);\n\tret = qib_r_wait_for_rdy(dd);\n\n\tif (ret >= 0)\n\t\tret = pos;\nbail:\n\treturn ret;\n}\n\nstatic int qib_r_update(struct qib_devdata *dd, int bisten)\n{\n\tu64 val;\n\tint ret;\n\n\tval = SJA_EN | (bisten << BISTEN_LSB) | (R_OP_UPDATE << R_OPCODE_LSB);\n\tret = qib_r_wait_for_rdy(dd);\n\tif (ret >= 0) {\n\t\tqib_write_kreg(dd, kr_r_access, val);\n\t\tqib_read_kreg32(dd, kr_scratch);\n\t}\n\treturn ret;\n}\n\n#define BISTEN_PORT_SEL 15\n#define LEN_PORT_SEL 625\n#define BISTEN_AT 17\n#define LEN_AT 156\n#define BISTEN_ETM 16\n#define LEN_ETM 632\n\n#define BIT2BYTE(x) (((x) +  BITS_PER_BYTE - 1) / BITS_PER_BYTE)\n\n \nstatic u8 reset_at[BIT2BYTE(LEN_AT)] = {\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x20, 0x00,\n};\nstatic u8 reset_atetm[BIT2BYTE(LEN_ETM)] = {\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x80, 0xe3, 0x81, 0x73, 0x3c, 0x70, 0x8e,\n\t0x07, 0xce, 0xf1, 0xc0, 0x39, 0x1e, 0x38, 0xc7, 0x03, 0xe7,\n\t0x78, 0xe0, 0x1c, 0x0f, 0x9c, 0x7f, 0x80, 0x73, 0x0f, 0x70,\n\t0xde, 0x01, 0xce, 0x39, 0xc0, 0xf9, 0x06, 0x38, 0xd7, 0x00,\n\t0xe7, 0x19, 0xe0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n};\nstatic u8 at[BIT2BYTE(LEN_AT)] = {\n\t0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x20, 0x00,\n};\n\n \nstatic u8 atetm_1port[BIT2BYTE(LEN_ETM)] = {\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x10, 0xf2, 0x80, 0x83, 0x1e, 0x38, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x50, 0xf4, 0x41, 0x00, 0x18, 0x78, 0xc8, 0x03,\n\t0x07, 0x7b, 0xa0, 0x3e, 0x00, 0x02, 0x00, 0x00, 0x18, 0x00,\n\t0x18, 0x00, 0x00, 0x00, 0x00, 0x4b, 0x00, 0x00, 0x00,\n};\n\n \nstatic u8 atetm_2port[BIT2BYTE(LEN_ETM)] = {\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x79,\n\t0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n\t0x00, 0x00, 0xf8, 0x80, 0x83, 0x1e, 0x38, 0xe0, 0x03, 0x05,\n\t0x7b, 0xa0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x80,\n\t0xa2, 0x0f, 0x50, 0xf4, 0x41, 0x00, 0x18, 0x78, 0xd1, 0x07,\n\t0x02, 0x7c, 0x80, 0x3e, 0x00, 0x02, 0x00, 0x00, 0x3e, 0x00,\n\t0x02, 0x00, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00,\n};\n\n \nstatic u8 portsel_port1[BIT2BYTE(LEN_PORT_SEL)] = {\n\t0x32, 0x65, 0xa4, 0x7b, 0x10, 0x98, 0xdc, 0xfe, 0x13, 0x13,\n\t0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x73, 0x0c, 0x0c, 0x0c,\n\t0x0c, 0x0c, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13,\n\t0x13, 0x78, 0x78, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13,\n\t0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x74, 0x32,\n\t0x32, 0x32, 0x32, 0x32, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14,\n\t0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14,\n\t0x14, 0x14, 0x9f, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00,\n};\n\n \nstatic u8 portsel_port2[BIT2BYTE(LEN_PORT_SEL)] = {\n\t0x32, 0x65, 0xa4, 0x7b, 0x10, 0x98, 0xdc, 0xfe, 0x39, 0x39,\n\t0x39, 0x39, 0x39, 0x39, 0x39, 0x39, 0x73, 0x32, 0x32, 0x32,\n\t0x32, 0x32, 0x39, 0x39, 0x39, 0x39, 0x39, 0x39, 0x39, 0x39,\n\t0x39, 0x78, 0x78, 0x39, 0x39, 0x39, 0x39, 0x39, 0x39, 0x39,\n\t0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x74, 0x32,\n\t0x32, 0x32, 0x32, 0x32, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a,\n\t0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a, 0x3a,\n\t0x3a, 0x3a, 0x9f, 0x01, 0x00, 0x00, 0x00, 0x00, 0x01,\n};\n\n \nstatic u8 portsel_2port[BIT2BYTE(LEN_PORT_SEL)] = {\n\t0x32, 0xba, 0x54, 0x76, 0x10, 0x98, 0xdc, 0xfe, 0x13, 0x13,\n\t0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x73, 0x0c, 0x0c, 0x0c,\n\t0x0c, 0x0c, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13,\n\t0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13, 0x13,\n\t0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x74, 0x32,\n\t0x32, 0x32, 0x32, 0x32, 0x14, 0x14, 0x14, 0x14, 0x14, 0x3a,\n\t0x3a, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14, 0x14,\n\t0x14, 0x14, 0x9f, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00,\n};\n\n \nstatic void setup_7322_link_recovery(struct qib_pportdata *ppd, u32 both)\n{\n\tu8 *portsel, *etm;\n\tstruct qib_devdata *dd = ppd->dd;\n\n\tif (!ppd->dd->cspec->r1)\n\t\treturn;\n\tif (!both) {\n\t\tdd->cspec->recovery_ports_initted++;\n\t\tppd->cpspec->recovery_init = 1;\n\t}\n\tif (!both && dd->cspec->recovery_ports_initted == 1) {\n\t\tportsel = ppd->port == 1 ? portsel_port1 : portsel_port2;\n\t\tetm = atetm_1port;\n\t} else {\n\t\tportsel = portsel_2port;\n\t\tetm = atetm_2port;\n\t}\n\n\tif (qib_r_grab(dd) < 0 ||\n\t\tqib_r_shift(dd, BISTEN_ETM, LEN_ETM, reset_atetm, NULL) < 0 ||\n\t\tqib_r_update(dd, BISTEN_ETM) < 0 ||\n\t\tqib_r_shift(dd, BISTEN_AT, LEN_AT, reset_at, NULL) < 0 ||\n\t\tqib_r_update(dd, BISTEN_AT) < 0 ||\n\t\tqib_r_shift(dd, BISTEN_PORT_SEL, LEN_PORT_SEL,\n\t\t\t    portsel, NULL) < 0 ||\n\t\tqib_r_update(dd, BISTEN_PORT_SEL) < 0 ||\n\t\tqib_r_shift(dd, BISTEN_AT, LEN_AT, at, NULL) < 0 ||\n\t\tqib_r_update(dd, BISTEN_AT) < 0 ||\n\t\tqib_r_shift(dd, BISTEN_ETM, LEN_ETM, etm, NULL) < 0 ||\n\t\tqib_r_update(dd, BISTEN_ETM) < 0)\n\t\tqib_dev_err(dd, \"Failed IB link recovery setup\\n\");\n}\n\nstatic void check_7322_rxe_status(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tu64 fmask;\n\n\tif (dd->cspec->recovery_ports_initted != 1)\n\t\treturn;  \n\tqib_write_kreg(dd, kr_control, dd->control |\n\t\t       SYM_MASK(Control, FreezeMode));\n\t(void)qib_read_kreg64(dd, kr_scratch);\n\tudelay(3);  \n\tfmask = qib_read_kreg64(dd, kr_act_fmask);\n\tif (!fmask) {\n\t\t \n\t\tppd->dd->cspec->stay_in_freeze = 1;\n\t\tqib_7322_set_intr_state(ppd->dd, 0);\n\t\tqib_write_kreg(dd, kr_fmask, 0ULL);\n\t\tqib_dev_err(dd, \"HCA unusable until powercycled\\n\");\n\t\treturn;  \n\t}\n\n\tqib_write_kreg(ppd->dd, kr_hwerrclear,\n\t    SYM_MASK(HwErrClear, IBSerdesPClkNotDetectClear_1));\n\n\t \n\tqib_write_kreg(dd, kr_control, dd->control);\n\tqib_read_kreg32(dd, kr_scratch);\n\t \n\tif (ppd->link_speed_supported) {\n\t\tppd->cpspec->ibcctrl_a &=\n\t\t\t~SYM_MASK(IBCCtrlA_0, IBStatIntReductionEn);\n\t\tqib_write_kreg_port(ppd, krp_ibcctrl_a,\n\t\t\t\t    ppd->cpspec->ibcctrl_a);\n\t\tqib_read_kreg32(dd, kr_scratch);\n\t\tif (ppd->lflags & QIBL_IB_LINK_DISABLED)\n\t\t\tqib_set_ib_7322_lstate(ppd, 0,\n\t\t\t\tQLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}