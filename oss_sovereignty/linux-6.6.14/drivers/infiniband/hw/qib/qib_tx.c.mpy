{
  "module_name": "qib_tx.c",
  "hash_id": "6aedb3331d1ab169cbd7ae1197fca129917b2b94eaa641c06a19f19bdd0b0a6b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/qib/qib_tx.c",
  "human_readable_source": " \n\n#include <linux/spinlock.h>\n#include <linux/pci.h>\n#include <linux/io.h>\n#include <linux/delay.h>\n#include <linux/netdevice.h>\n#include <linux/vmalloc.h>\n#include <linux/moduleparam.h>\n\n#include \"qib.h\"\n\nstatic unsigned qib_hol_timeout_ms = 3000;\nmodule_param_named(hol_timeout_ms, qib_hol_timeout_ms, uint, S_IRUGO);\nMODULE_PARM_DESC(hol_timeout_ms,\n\t\t \"duration of user app suspension after link failure\");\n\nunsigned qib_sdma_fetch_arb = 1;\nmodule_param_named(fetch_arb, qib_sdma_fetch_arb, uint, S_IRUGO);\nMODULE_PARM_DESC(fetch_arb, \"IBA7220: change SDMA descriptor arbitration\");\n\n \nvoid qib_disarm_piobufs(struct qib_devdata *dd, unsigned first, unsigned cnt)\n{\n\tunsigned long flags;\n\tunsigned i;\n\tunsigned last;\n\n\tlast = first + cnt;\n\tspin_lock_irqsave(&dd->pioavail_lock, flags);\n\tfor (i = first; i < last; i++) {\n\t\t__clear_bit(i, dd->pio_need_disarm);\n\t\tdd->f_sendctrl(dd->pport, QIB_SENDCTRL_DISARM_BUF(i));\n\t}\n\tspin_unlock_irqrestore(&dd->pioavail_lock, flags);\n}\n\n \nint qib_disarm_piobufs_ifneeded(struct qib_ctxtdata *rcd)\n{\n\tstruct qib_devdata *dd = rcd->dd;\n\tunsigned i;\n\tunsigned last;\n\n\tlast = rcd->pio_base + rcd->piocnt;\n\t \n\tif (rcd->user_event_mask) {\n\t\t \n\t\tclear_bit(_QIB_EVENT_DISARM_BUFS_BIT, &rcd->user_event_mask[0]);\n\t\tfor (i = 1; i < rcd->subctxt_cnt; i++)\n\t\t\tclear_bit(_QIB_EVENT_DISARM_BUFS_BIT,\n\t\t\t\t  &rcd->user_event_mask[i]);\n\t}\n\tspin_lock_irq(&dd->pioavail_lock);\n\tfor (i = rcd->pio_base; i < last; i++) {\n\t\tif (__test_and_clear_bit(i, dd->pio_need_disarm))\n\t\t\tdd->f_sendctrl(rcd->ppd, QIB_SENDCTRL_DISARM_BUF(i));\n\t}\n\tspin_unlock_irq(&dd->pioavail_lock);\n\treturn 0;\n}\n\nstatic struct qib_pportdata *is_sdma_buf(struct qib_devdata *dd, unsigned i)\n{\n\tstruct qib_pportdata *ppd;\n\tunsigned pidx;\n\n\tfor (pidx = 0; pidx < dd->num_pports; pidx++) {\n\t\tppd = dd->pport + pidx;\n\t\tif (i >= ppd->sdma_state.first_sendbuf &&\n\t\t    i < ppd->sdma_state.last_sendbuf)\n\t\t\treturn ppd;\n\t}\n\treturn NULL;\n}\n\n \nstatic int find_ctxt(struct qib_devdata *dd, unsigned bufn)\n{\n\tstruct qib_ctxtdata *rcd;\n\tunsigned ctxt;\n\tint ret = 0;\n\n\tspin_lock(&dd->uctxt_lock);\n\tfor (ctxt = dd->first_user_ctxt; ctxt < dd->cfgctxts; ctxt++) {\n\t\trcd = dd->rcd[ctxt];\n\t\tif (!rcd || bufn < rcd->pio_base ||\n\t\t    bufn >= rcd->pio_base + rcd->piocnt)\n\t\t\tcontinue;\n\t\tif (rcd->user_event_mask) {\n\t\t\tint i;\n\t\t\t \n\t\t\tset_bit(_QIB_EVENT_DISARM_BUFS_BIT,\n\t\t\t\t&rcd->user_event_mask[0]);\n\t\t\tfor (i = 1; i < rcd->subctxt_cnt; i++)\n\t\t\t\tset_bit(_QIB_EVENT_DISARM_BUFS_BIT,\n\t\t\t\t\t&rcd->user_event_mask[i]);\n\t\t}\n\t\tret = 1;\n\t\tbreak;\n\t}\n\tspin_unlock(&dd->uctxt_lock);\n\n\treturn ret;\n}\n\n \nvoid qib_disarm_piobufs_set(struct qib_devdata *dd, unsigned long *mask,\n\t\t\t    unsigned cnt)\n{\n\tstruct qib_pportdata *ppd, *pppd[QIB_MAX_IB_PORTS];\n\tunsigned i;\n\tunsigned long flags;\n\n\tfor (i = 0; i < dd->num_pports; i++)\n\t\tpppd[i] = NULL;\n\n\tfor (i = 0; i < cnt; i++) {\n\t\tif (!test_bit(i, mask))\n\t\t\tcontinue;\n\t\t \n\t\tppd = is_sdma_buf(dd, i);\n\t\tif (ppd) {\n\t\t\tpppd[ppd->port] = ppd;\n\t\t\tcontinue;\n\t\t}\n\t\t \n\t\tspin_lock_irqsave(&dd->pioavail_lock, flags);\n\t\tif (test_bit(i, dd->pio_writing) ||\n\t\t    (!test_bit(i << 1, dd->pioavailkernel) &&\n\t\t     find_ctxt(dd, i))) {\n\t\t\t__set_bit(i, dd->pio_need_disarm);\n\t\t} else {\n\t\t\tdd->f_sendctrl(dd->pport, QIB_SENDCTRL_DISARM_BUF(i));\n\t\t}\n\t\tspin_unlock_irqrestore(&dd->pioavail_lock, flags);\n\t}\n\n\t \n\tfor (i = 0; i < dd->num_pports; i++)\n\t\tif (pppd[i])\n\t\t\tqib_cancel_sends(pppd[i]);\n}\n\n \nstatic void update_send_bufs(struct qib_devdata *dd)\n{\n\tunsigned long flags;\n\tunsigned i;\n\tconst unsigned piobregs = dd->pioavregs;\n\n\t \n\tif (!dd->pioavailregs_dma)\n\t\treturn;\n\tspin_lock_irqsave(&dd->pioavail_lock, flags);\n\tfor (i = 0; i < piobregs; i++) {\n\t\tu64 pchbusy, pchg, piov, pnew;\n\n\t\tpiov = le64_to_cpu(dd->pioavailregs_dma[i]);\n\t\tpchg = dd->pioavailkernel[i] &\n\t\t\t~(dd->pioavailshadow[i] ^ piov);\n\t\tpchbusy = pchg << QLOGIC_IB_SENDPIOAVAIL_BUSY_SHIFT;\n\t\tif (pchg && (pchbusy & dd->pioavailshadow[i])) {\n\t\t\tpnew = dd->pioavailshadow[i] & ~pchbusy;\n\t\t\tpnew |= piov & pchbusy;\n\t\t\tdd->pioavailshadow[i] = pnew;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&dd->pioavail_lock, flags);\n}\n\n \nstatic noinline void no_send_bufs(struct qib_devdata *dd)\n{\n\tdd->upd_pio_shadow = 1;\n\n\t \n\tqib_stats.sps_nopiobufs++;\n}\n\n \nu32 __iomem *qib_getsendbuf_range(struct qib_devdata *dd, u32 *pbufnum,\n\t\t\t\t  u32 first, u32 last)\n{\n\tunsigned i, j, updated = 0;\n\tunsigned nbufs;\n\tunsigned long flags;\n\tunsigned long *shadow = dd->pioavailshadow;\n\tu32 __iomem *buf;\n\n\tif (!(dd->flags & QIB_PRESENT))\n\t\treturn NULL;\n\n\tnbufs = last - first + 1;  \n\tif (dd->upd_pio_shadow) {\nupdate_shadow:\n\t\t \n\t\tupdate_send_bufs(dd);\n\t\tupdated++;\n\t}\n\ti = first;\n\t \n\tspin_lock_irqsave(&dd->pioavail_lock, flags);\n\tif (dd->last_pio >= first && dd->last_pio <= last)\n\t\ti = dd->last_pio + 1;\n\tif (!first)\n\t\t \n\t\tnbufs = last - dd->min_kernel_pio + 1;\n\tfor (j = 0; j < nbufs; j++, i++) {\n\t\tif (i > last)\n\t\t\ti = !first ? dd->min_kernel_pio : first;\n\t\tif (__test_and_set_bit((2 * i) + 1, shadow))\n\t\t\tcontinue;\n\t\t \n\t\t__change_bit(2 * i, shadow);\n\t\t \n\t\t__set_bit(i, dd->pio_writing);\n\t\tif (!first && first != last)  \n\t\t\tdd->last_pio = i;\n\t\tbreak;\n\t}\n\tspin_unlock_irqrestore(&dd->pioavail_lock, flags);\n\n\tif (j == nbufs) {\n\t\tif (!updated)\n\t\t\t \n\t\t\tgoto update_shadow;\n\t\tno_send_bufs(dd);\n\t\tbuf = NULL;\n\t} else {\n\t\tif (i < dd->piobcnt2k)\n\t\t\tbuf = (u32 __iomem *)(dd->pio2kbase +\n\t\t\t\ti * dd->palign);\n\t\telse if (i < dd->piobcnt2k + dd->piobcnt4k || !dd->piovl15base)\n\t\t\tbuf = (u32 __iomem *)(dd->pio4kbase +\n\t\t\t\t(i - dd->piobcnt2k) * dd->align4k);\n\t\telse\n\t\t\tbuf = (u32 __iomem *)(dd->piovl15base +\n\t\t\t\t(i - (dd->piobcnt2k + dd->piobcnt4k)) *\n\t\t\t\tdd->align4k);\n\t\tif (pbufnum)\n\t\t\t*pbufnum = i;\n\t\tdd->upd_pio_shadow = 0;\n\t}\n\n\treturn buf;\n}\n\n \nvoid qib_sendbuf_done(struct qib_devdata *dd, unsigned n)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dd->pioavail_lock, flags);\n\t__clear_bit(n, dd->pio_writing);\n\tif (__test_and_clear_bit(n, dd->pio_need_disarm))\n\t\tdd->f_sendctrl(dd->pport, QIB_SENDCTRL_DISARM_BUF(n));\n\tspin_unlock_irqrestore(&dd->pioavail_lock, flags);\n}\n\n \nvoid qib_chg_pioavailkernel(struct qib_devdata *dd, unsigned start,\n\tunsigned len, u32 avail, struct qib_ctxtdata *rcd)\n{\n\tunsigned long flags;\n\tunsigned end;\n\tunsigned ostart = start;\n\n\t \n\tstart *= 2;\n\tend = start + len * 2;\n\n\tspin_lock_irqsave(&dd->pioavail_lock, flags);\n\t \n\twhile (start < end) {\n\t\tif (avail) {\n\t\t\tunsigned long dma;\n\t\t\tint i;\n\n\t\t\t \n\t\t\ti = start / BITS_PER_LONG;\n\t\t\t__clear_bit(QLOGIC_IB_SENDPIOAVAIL_BUSY_SHIFT + start,\n\t\t\t\t    dd->pioavailshadow);\n\t\t\tdma = (unsigned long)\n\t\t\t\tle64_to_cpu(dd->pioavailregs_dma[i]);\n\t\t\tif (test_bit((QLOGIC_IB_SENDPIOAVAIL_CHECK_SHIFT +\n\t\t\t\t      start) % BITS_PER_LONG, &dma))\n\t\t\t\t__set_bit(QLOGIC_IB_SENDPIOAVAIL_CHECK_SHIFT +\n\t\t\t\t\t  start, dd->pioavailshadow);\n\t\t\telse\n\t\t\t\t__clear_bit(QLOGIC_IB_SENDPIOAVAIL_CHECK_SHIFT\n\t\t\t\t\t    + start, dd->pioavailshadow);\n\t\t\t__set_bit(start, dd->pioavailkernel);\n\t\t\tif ((start >> 1) < dd->min_kernel_pio)\n\t\t\t\tdd->min_kernel_pio = start >> 1;\n\t\t} else {\n\t\t\t__set_bit(start + QLOGIC_IB_SENDPIOAVAIL_BUSY_SHIFT,\n\t\t\t\t  dd->pioavailshadow);\n\t\t\t__clear_bit(start, dd->pioavailkernel);\n\t\t\tif ((start >> 1) > dd->min_kernel_pio)\n\t\t\t\tdd->min_kernel_pio = start >> 1;\n\t\t}\n\t\tstart += 2;\n\t}\n\n\tif (dd->min_kernel_pio > 0 && dd->last_pio < dd->min_kernel_pio - 1)\n\t\tdd->last_pio = dd->min_kernel_pio - 1;\n\tspin_unlock_irqrestore(&dd->pioavail_lock, flags);\n\n\tdd->f_txchk_change(dd, ostart, len, avail, rcd);\n}\n\n \nvoid qib_cancel_sends(struct qib_pportdata *ppd)\n{\n\tstruct qib_devdata *dd = ppd->dd;\n\tstruct qib_ctxtdata *rcd;\n\tunsigned long flags;\n\tunsigned ctxt;\n\tunsigned i;\n\tunsigned last;\n\n\t \n\tfor (ctxt = dd->first_user_ctxt; ctxt < dd->cfgctxts; ctxt++) {\n\t\tspin_lock_irqsave(&dd->uctxt_lock, flags);\n\t\trcd = dd->rcd[ctxt];\n\t\tif (rcd && rcd->ppd == ppd) {\n\t\t\tlast = rcd->pio_base + rcd->piocnt;\n\t\t\tif (rcd->user_event_mask) {\n\t\t\t\t \n\t\t\t\tset_bit(_QIB_EVENT_DISARM_BUFS_BIT,\n\t\t\t\t\t&rcd->user_event_mask[0]);\n\t\t\t\tfor (i = 1; i < rcd->subctxt_cnt; i++)\n\t\t\t\t\tset_bit(_QIB_EVENT_DISARM_BUFS_BIT,\n\t\t\t\t\t\t&rcd->user_event_mask[i]);\n\t\t\t}\n\t\t\ti = rcd->pio_base;\n\t\t\tspin_unlock_irqrestore(&dd->uctxt_lock, flags);\n\t\t\tspin_lock_irqsave(&dd->pioavail_lock, flags);\n\t\t\tfor (; i < last; i++)\n\t\t\t\t__set_bit(i, dd->pio_need_disarm);\n\t\t\tspin_unlock_irqrestore(&dd->pioavail_lock, flags);\n\t\t} else\n\t\t\tspin_unlock_irqrestore(&dd->uctxt_lock, flags);\n\t}\n\n\tif (!(dd->flags & QIB_HAS_SEND_DMA))\n\t\tdd->f_sendctrl(ppd, QIB_SENDCTRL_DISARM_ALL |\n\t\t\t\t    QIB_SENDCTRL_FLUSH);\n}\n\n \nvoid qib_force_pio_avail_update(struct qib_devdata *dd)\n{\n\tdd->f_sendctrl(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\n}\n\nvoid qib_hol_down(struct qib_pportdata *ppd)\n{\n\t \n\tif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG))\n\t\tqib_cancel_sends(ppd);\n}\n\n \nvoid qib_hol_init(struct qib_pportdata *ppd)\n{\n\tif (ppd->hol_state != QIB_HOL_INIT) {\n\t\tppd->hol_state = QIB_HOL_INIT;\n\t\tmod_timer(&ppd->hol_timer,\n\t\t\t  jiffies + msecs_to_jiffies(qib_hol_timeout_ms));\n\t}\n}\n\n \nvoid qib_hol_up(struct qib_pportdata *ppd)\n{\n\tppd->hol_state = QIB_HOL_UP;\n}\n\n \nvoid qib_hol_event(struct timer_list *t)\n{\n\tstruct qib_pportdata *ppd = from_timer(ppd, t, hol_timer);\n\n\t \n\tif (!(ppd->dd->flags & QIB_INITTED))\n\t\treturn;\n\n\tif (ppd->hol_state != QIB_HOL_UP) {\n\t\t \n\t\tqib_hol_down(ppd);\n\t\tmod_timer(&ppd->hol_timer,\n\t\t\t  jiffies + msecs_to_jiffies(qib_hol_timeout_ms));\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}