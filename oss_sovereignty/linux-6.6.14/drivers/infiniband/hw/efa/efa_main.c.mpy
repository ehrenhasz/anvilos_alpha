{
  "module_name": "efa_main.c",
  "hash_id": "0c4311583bd189a6f188c2d8fbdcb1751c552feb625e0df1202d8aba7b8882b4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/efa/efa_main.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/utsname.h>\n#include <linux/version.h>\n\n#include <rdma/ib_user_verbs.h>\n\n#include \"efa.h\"\n\n#define PCI_DEV_ID_EFA0_VF 0xefa0\n#define PCI_DEV_ID_EFA1_VF 0xefa1\n#define PCI_DEV_ID_EFA2_VF 0xefa2\n\nstatic const struct pci_device_id efa_pci_tbl[] = {\n\t{ PCI_VDEVICE(AMAZON, PCI_DEV_ID_EFA0_VF) },\n\t{ PCI_VDEVICE(AMAZON, PCI_DEV_ID_EFA1_VF) },\n\t{ PCI_VDEVICE(AMAZON, PCI_DEV_ID_EFA2_VF) },\n\t{ }\n};\n\nMODULE_AUTHOR(\"Amazon.com, Inc. or its affiliates\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_DESCRIPTION(DEVICE_NAME);\nMODULE_DEVICE_TABLE(pci, efa_pci_tbl);\n\n#define EFA_REG_BAR 0\n#define EFA_MEM_BAR 2\n#define EFA_BASE_BAR_MASK (BIT(EFA_REG_BAR) | BIT(EFA_MEM_BAR))\n\n#define EFA_AENQ_ENABLED_GROUPS \\\n\t(BIT(EFA_ADMIN_FATAL_ERROR) | BIT(EFA_ADMIN_WARNING) | \\\n\t BIT(EFA_ADMIN_NOTIFICATION) | BIT(EFA_ADMIN_KEEP_ALIVE))\n\n \nstatic void unimplemented_aenq_handler(void *data,\n\t\t\t\t       struct efa_admin_aenq_entry *aenq_e)\n{\n\tstruct efa_dev *dev = (struct efa_dev *)data;\n\n\tibdev_err(&dev->ibdev,\n\t\t  \"Unknown event was received or event with unimplemented handler\\n\");\n}\n\nstatic void efa_keep_alive(void *data, struct efa_admin_aenq_entry *aenq_e)\n{\n\tstruct efa_dev *dev = (struct efa_dev *)data;\n\n\tatomic64_inc(&dev->stats.keep_alive_rcvd);\n}\n\nstatic struct efa_aenq_handlers aenq_handlers = {\n\t.handlers = {\n\t\t[EFA_ADMIN_KEEP_ALIVE] = efa_keep_alive,\n\t},\n\t.unimplemented_handler = unimplemented_aenq_handler\n};\n\nstatic void efa_release_bars(struct efa_dev *dev, int bars_mask)\n{\n\tstruct pci_dev *pdev = dev->pdev;\n\tint release_bars;\n\n\trelease_bars = pci_select_bars(pdev, IORESOURCE_MEM) & bars_mask;\n\tpci_release_selected_regions(pdev, release_bars);\n}\n\nstatic void efa_process_comp_eqe(struct efa_dev *dev, struct efa_admin_eqe *eqe)\n{\n\tu16 cqn = eqe->u.comp_event.cqn;\n\tstruct efa_cq *cq;\n\n\t \n\tcq = xa_load(&dev->cqs_xa, cqn);\n\tif (unlikely(!cq)) {\n\t\tibdev_err_ratelimited(&dev->ibdev,\n\t\t\t\t      \"Completion event on non-existent CQ[%u]\",\n\t\t\t\t      cqn);\n\t\treturn;\n\t}\n\n\tcq->ibcq.comp_handler(&cq->ibcq, cq->ibcq.cq_context);\n}\n\nstatic void efa_process_eqe(struct efa_com_eq *eeq, struct efa_admin_eqe *eqe)\n{\n\tstruct efa_dev *dev = container_of(eeq->edev, struct efa_dev, edev);\n\n\tif (likely(EFA_GET(&eqe->common, EFA_ADMIN_EQE_EVENT_TYPE) ==\n\t\t\t   EFA_ADMIN_EQE_EVENT_TYPE_COMPLETION))\n\t\tefa_process_comp_eqe(dev, eqe);\n\telse\n\t\tibdev_err_ratelimited(&dev->ibdev,\n\t\t\t\t      \"Unknown event type received %lu\",\n\t\t\t\t      EFA_GET(&eqe->common,\n\t\t\t\t\t      EFA_ADMIN_EQE_EVENT_TYPE));\n}\n\nstatic irqreturn_t efa_intr_msix_comp(int irq, void *data)\n{\n\tstruct efa_eq *eq = data;\n\tstruct efa_com_dev *edev = eq->eeq.edev;\n\n\tefa_com_eq_comp_intr_handler(edev, &eq->eeq);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t efa_intr_msix_mgmnt(int irq, void *data)\n{\n\tstruct efa_dev *dev = data;\n\n\tefa_com_admin_q_comp_intr_handler(&dev->edev);\n\tefa_com_aenq_intr_handler(&dev->edev, data);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int efa_request_irq(struct efa_dev *dev, struct efa_irq *irq)\n{\n\tint err;\n\n\terr = request_irq(irq->irqn, irq->handler, 0, irq->name, irq->data);\n\tif (err) {\n\t\tdev_err(&dev->pdev->dev, \"Failed to request irq %s (%d)\\n\",\n\t\t\tirq->name, err);\n\t\treturn err;\n\t}\n\n\tirq_set_affinity_hint(irq->irqn, &irq->affinity_hint_mask);\n\n\treturn 0;\n}\n\nstatic void efa_setup_comp_irq(struct efa_dev *dev, struct efa_eq *eq,\n\t\t\t       int vector)\n{\n\tu32 cpu;\n\n\tcpu = vector - EFA_COMP_EQS_VEC_BASE;\n\tsnprintf(eq->irq.name, EFA_IRQNAME_SIZE, \"efa-comp%d@pci:%s\", cpu,\n\t\t pci_name(dev->pdev));\n\teq->irq.handler = efa_intr_msix_comp;\n\teq->irq.data = eq;\n\teq->irq.vector = vector;\n\teq->irq.irqn = pci_irq_vector(dev->pdev, vector);\n\tcpumask_set_cpu(cpu, &eq->irq.affinity_hint_mask);\n}\n\nstatic void efa_free_irq(struct efa_dev *dev, struct efa_irq *irq)\n{\n\tirq_set_affinity_hint(irq->irqn, NULL);\n\tfree_irq(irq->irqn, irq->data);\n}\n\nstatic void efa_setup_mgmnt_irq(struct efa_dev *dev)\n{\n\tu32 cpu;\n\n\tsnprintf(dev->admin_irq.name, EFA_IRQNAME_SIZE,\n\t\t \"efa-mgmnt@pci:%s\", pci_name(dev->pdev));\n\tdev->admin_irq.handler = efa_intr_msix_mgmnt;\n\tdev->admin_irq.data = dev;\n\tdev->admin_irq.vector = dev->admin_msix_vector_idx;\n\tdev->admin_irq.irqn = pci_irq_vector(dev->pdev,\n\t\t\t\t\t     dev->admin_msix_vector_idx);\n\tcpu = cpumask_first(cpu_online_mask);\n\tcpumask_set_cpu(cpu,\n\t\t\t&dev->admin_irq.affinity_hint_mask);\n\tdev_info(&dev->pdev->dev, \"Setup irq:%d name:%s\\n\",\n\t\t dev->admin_irq.irqn,\n\t\t dev->admin_irq.name);\n}\n\nstatic int efa_set_mgmnt_irq(struct efa_dev *dev)\n{\n\tefa_setup_mgmnt_irq(dev);\n\n\treturn efa_request_irq(dev, &dev->admin_irq);\n}\n\nstatic int efa_request_doorbell_bar(struct efa_dev *dev)\n{\n\tu8 db_bar_idx = dev->dev_attr.db_bar;\n\tstruct pci_dev *pdev = dev->pdev;\n\tint bars;\n\tint err;\n\n\tif (!(BIT(db_bar_idx) & EFA_BASE_BAR_MASK)) {\n\t\tbars = pci_select_bars(pdev, IORESOURCE_MEM) & BIT(db_bar_idx);\n\n\t\terr = pci_request_selected_regions(pdev, bars, DRV_MODULE_NAME);\n\t\tif (err) {\n\t\t\tdev_err(&dev->pdev->dev,\n\t\t\t\t\"pci_request_selected_regions for bar %d failed %d\\n\",\n\t\t\t\tdb_bar_idx, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tdev->db_bar_addr = pci_resource_start(dev->pdev, db_bar_idx);\n\tdev->db_bar_len = pci_resource_len(dev->pdev, db_bar_idx);\n\n\treturn 0;\n}\n\nstatic void efa_release_doorbell_bar(struct efa_dev *dev)\n{\n\tif (!(BIT(dev->dev_attr.db_bar) & EFA_BASE_BAR_MASK))\n\t\tefa_release_bars(dev, BIT(dev->dev_attr.db_bar));\n}\n\nstatic void efa_update_hw_hints(struct efa_dev *dev,\n\t\t\t\tstruct efa_com_get_hw_hints_result *hw_hints)\n{\n\tstruct efa_com_dev *edev = &dev->edev;\n\n\tif (hw_hints->mmio_read_timeout)\n\t\tedev->mmio_read.mmio_read_timeout =\n\t\t\thw_hints->mmio_read_timeout * 1000;\n\n\tif (hw_hints->poll_interval)\n\t\tedev->aq.poll_interval = hw_hints->poll_interval;\n\n\tif (hw_hints->admin_completion_timeout)\n\t\tedev->aq.completion_timeout =\n\t\t\thw_hints->admin_completion_timeout;\n}\n\nstatic void efa_stats_init(struct efa_dev *dev)\n{\n\tatomic64_t *s = (atomic64_t *)&dev->stats;\n\tint i;\n\n\tfor (i = 0; i < sizeof(dev->stats) / sizeof(*s); i++, s++)\n\t\tatomic64_set(s, 0);\n}\n\nstatic void efa_set_host_info(struct efa_dev *dev)\n{\n\tstruct efa_admin_set_feature_resp resp = {};\n\tstruct efa_admin_set_feature_cmd cmd = {};\n\tstruct efa_admin_host_info *hinf;\n\tu32 bufsz = sizeof(*hinf);\n\tdma_addr_t hinf_dma;\n\n\tif (!efa_com_check_supported_feature_id(&dev->edev,\n\t\t\t\t\t\tEFA_ADMIN_HOST_INFO))\n\t\treturn;\n\n\t \n\thinf = dma_alloc_coherent(&dev->pdev->dev, bufsz, &hinf_dma,\n\t\t\t\t  GFP_KERNEL);\n\tif (!hinf)\n\t\treturn;\n\n\tstrscpy(hinf->os_dist_str, utsname()->release,\n\t\tsizeof(hinf->os_dist_str));\n\thinf->os_type = EFA_ADMIN_OS_LINUX;\n\tstrscpy(hinf->kernel_ver_str, utsname()->version,\n\t\tsizeof(hinf->kernel_ver_str));\n\thinf->kernel_ver = LINUX_VERSION_CODE;\n\tEFA_SET(&hinf->driver_ver, EFA_ADMIN_HOST_INFO_DRIVER_MAJOR, 0);\n\tEFA_SET(&hinf->driver_ver, EFA_ADMIN_HOST_INFO_DRIVER_MINOR, 0);\n\tEFA_SET(&hinf->driver_ver, EFA_ADMIN_HOST_INFO_DRIVER_SUB_MINOR, 0);\n\tEFA_SET(&hinf->driver_ver, EFA_ADMIN_HOST_INFO_DRIVER_MODULE_TYPE, 0);\n\tEFA_SET(&hinf->bdf, EFA_ADMIN_HOST_INFO_BUS, dev->pdev->bus->number);\n\tEFA_SET(&hinf->bdf, EFA_ADMIN_HOST_INFO_DEVICE,\n\t\tPCI_SLOT(dev->pdev->devfn));\n\tEFA_SET(&hinf->bdf, EFA_ADMIN_HOST_INFO_FUNCTION,\n\t\tPCI_FUNC(dev->pdev->devfn));\n\tEFA_SET(&hinf->spec_ver, EFA_ADMIN_HOST_INFO_SPEC_MAJOR,\n\t\tEFA_COMMON_SPEC_VERSION_MAJOR);\n\tEFA_SET(&hinf->spec_ver, EFA_ADMIN_HOST_INFO_SPEC_MINOR,\n\t\tEFA_COMMON_SPEC_VERSION_MINOR);\n\tEFA_SET(&hinf->flags, EFA_ADMIN_HOST_INFO_INTREE, 1);\n\tEFA_SET(&hinf->flags, EFA_ADMIN_HOST_INFO_GDR, 0);\n\n\tefa_com_set_feature_ex(&dev->edev, &resp, &cmd, EFA_ADMIN_HOST_INFO,\n\t\t\t       hinf_dma, bufsz);\n\n\tdma_free_coherent(&dev->pdev->dev, bufsz, hinf, hinf_dma);\n}\n\nstatic void efa_destroy_eq(struct efa_dev *dev, struct efa_eq *eq)\n{\n\tefa_com_eq_destroy(&dev->edev, &eq->eeq);\n\tefa_free_irq(dev, &eq->irq);\n}\n\nstatic int efa_create_eq(struct efa_dev *dev, struct efa_eq *eq, u8 msix_vec)\n{\n\tint err;\n\n\tefa_setup_comp_irq(dev, eq, msix_vec);\n\terr = efa_request_irq(dev, &eq->irq);\n\tif (err)\n\t\treturn err;\n\n\terr = efa_com_eq_init(&dev->edev, &eq->eeq, efa_process_eqe,\n\t\t\t      dev->dev_attr.max_eq_depth, msix_vec);\n\tif (err)\n\t\tgoto err_free_comp_irq;\n\n\treturn 0;\n\nerr_free_comp_irq:\n\tefa_free_irq(dev, &eq->irq);\n\treturn err;\n}\n\nstatic int efa_create_eqs(struct efa_dev *dev)\n{\n\tunsigned int neqs = dev->dev_attr.max_eq;\n\tint err;\n\tint i;\n\n\tneqs = min_t(unsigned int, neqs, num_online_cpus());\n\tdev->neqs = neqs;\n\tdev->eqs = kcalloc(neqs, sizeof(*dev->eqs), GFP_KERNEL);\n\tif (!dev->eqs)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < neqs; i++) {\n\t\terr = efa_create_eq(dev, &dev->eqs[i],\n\t\t\t\t    i + EFA_COMP_EQS_VEC_BASE);\n\t\tif (err)\n\t\t\tgoto err_destroy_eqs;\n\t}\n\n\treturn 0;\n\nerr_destroy_eqs:\n\tfor (i--; i >= 0; i--)\n\t\tefa_destroy_eq(dev, &dev->eqs[i]);\n\tkfree(dev->eqs);\n\n\treturn err;\n}\n\nstatic void efa_destroy_eqs(struct efa_dev *dev)\n{\n\tint i;\n\n\tfor (i = 0; i < dev->neqs; i++)\n\t\tefa_destroy_eq(dev, &dev->eqs[i]);\n\n\tkfree(dev->eqs);\n}\n\nstatic const struct ib_device_ops efa_dev_ops = {\n\t.owner = THIS_MODULE,\n\t.driver_id = RDMA_DRIVER_EFA,\n\t.uverbs_abi_ver = EFA_UVERBS_ABI_VERSION,\n\n\t.alloc_hw_port_stats = efa_alloc_hw_port_stats,\n\t.alloc_hw_device_stats = efa_alloc_hw_device_stats,\n\t.alloc_pd = efa_alloc_pd,\n\t.alloc_ucontext = efa_alloc_ucontext,\n\t.create_cq = efa_create_cq,\n\t.create_qp = efa_create_qp,\n\t.create_user_ah = efa_create_ah,\n\t.dealloc_pd = efa_dealloc_pd,\n\t.dealloc_ucontext = efa_dealloc_ucontext,\n\t.dereg_mr = efa_dereg_mr,\n\t.destroy_ah = efa_destroy_ah,\n\t.destroy_cq = efa_destroy_cq,\n\t.destroy_qp = efa_destroy_qp,\n\t.get_hw_stats = efa_get_hw_stats,\n\t.get_link_layer = efa_port_link_layer,\n\t.get_port_immutable = efa_get_port_immutable,\n\t.mmap = efa_mmap,\n\t.mmap_free = efa_mmap_free,\n\t.modify_qp = efa_modify_qp,\n\t.query_device = efa_query_device,\n\t.query_gid = efa_query_gid,\n\t.query_pkey = efa_query_pkey,\n\t.query_port = efa_query_port,\n\t.query_qp = efa_query_qp,\n\t.reg_user_mr = efa_reg_mr,\n\t.reg_user_mr_dmabuf = efa_reg_user_mr_dmabuf,\n\n\tINIT_RDMA_OBJ_SIZE(ib_ah, efa_ah, ibah),\n\tINIT_RDMA_OBJ_SIZE(ib_cq, efa_cq, ibcq),\n\tINIT_RDMA_OBJ_SIZE(ib_pd, efa_pd, ibpd),\n\tINIT_RDMA_OBJ_SIZE(ib_qp, efa_qp, ibqp),\n\tINIT_RDMA_OBJ_SIZE(ib_ucontext, efa_ucontext, ibucontext),\n};\n\nstatic int efa_ib_device_add(struct efa_dev *dev)\n{\n\tstruct efa_com_get_hw_hints_result hw_hints;\n\tstruct pci_dev *pdev = dev->pdev;\n\tint err;\n\n\tefa_stats_init(dev);\n\n\terr = efa_com_get_device_attr(&dev->edev, &dev->dev_attr);\n\tif (err)\n\t\treturn err;\n\n\tdev_dbg(&dev->pdev->dev, \"Doorbells bar (%d)\\n\", dev->dev_attr.db_bar);\n\terr = efa_request_doorbell_bar(dev);\n\tif (err)\n\t\treturn err;\n\n\terr = efa_com_get_hw_hints(&dev->edev, &hw_hints);\n\tif (err)\n\t\tgoto err_release_doorbell_bar;\n\n\tefa_update_hw_hints(dev, &hw_hints);\n\n\t \n\terr = efa_com_set_aenq_config(&dev->edev, EFA_AENQ_ENABLED_GROUPS);\n\tif (err)\n\t\tgoto err_release_doorbell_bar;\n\n\terr = efa_create_eqs(dev);\n\tif (err)\n\t\tgoto err_release_doorbell_bar;\n\n\tefa_set_host_info(dev);\n\n\tdev->ibdev.node_type = RDMA_NODE_UNSPECIFIED;\n\tdev->ibdev.phys_port_cnt = 1;\n\tdev->ibdev.num_comp_vectors = dev->neqs ?: 1;\n\tdev->ibdev.dev.parent = &pdev->dev;\n\n\tib_set_device_ops(&dev->ibdev, &efa_dev_ops);\n\n\terr = ib_register_device(&dev->ibdev, \"efa_%d\", &pdev->dev);\n\tif (err)\n\t\tgoto err_destroy_eqs;\n\n\tibdev_info(&dev->ibdev, \"IB device registered\\n\");\n\n\treturn 0;\n\nerr_destroy_eqs:\n\tefa_destroy_eqs(dev);\nerr_release_doorbell_bar:\n\tefa_release_doorbell_bar(dev);\n\treturn err;\n}\n\nstatic void efa_ib_device_remove(struct efa_dev *dev)\n{\n\tibdev_info(&dev->ibdev, \"Unregister ib device\\n\");\n\tib_unregister_device(&dev->ibdev);\n\tefa_destroy_eqs(dev);\n\tefa_com_dev_reset(&dev->edev, EFA_REGS_RESET_NORMAL);\n\tefa_release_doorbell_bar(dev);\n}\n\nstatic void efa_disable_msix(struct efa_dev *dev)\n{\n\tpci_free_irq_vectors(dev->pdev);\n}\n\nstatic int efa_enable_msix(struct efa_dev *dev)\n{\n\tint msix_vecs, irq_num;\n\n\t \n\tmsix_vecs = min_t(int, pci_msix_vec_count(dev->pdev),\n\t\t\t  num_online_cpus() + 1);\n\tdev_dbg(&dev->pdev->dev, \"Trying to enable MSI-X, vectors %d\\n\",\n\t\tmsix_vecs);\n\n\tdev->admin_msix_vector_idx = EFA_MGMNT_MSIX_VEC_IDX;\n\tirq_num = pci_alloc_irq_vectors(dev->pdev, msix_vecs,\n\t\t\t\t\tmsix_vecs, PCI_IRQ_MSIX);\n\n\tif (irq_num < 0) {\n\t\tdev_err(&dev->pdev->dev, \"Failed to enable MSI-X. irq_num %d\\n\",\n\t\t\tirq_num);\n\t\treturn -ENOSPC;\n\t}\n\n\tif (irq_num != msix_vecs) {\n\t\tefa_disable_msix(dev);\n\t\tdev_err(&dev->pdev->dev,\n\t\t\t\"Allocated %d MSI-X (out of %d requested)\\n\",\n\t\t\tirq_num, msix_vecs);\n\t\treturn -ENOSPC;\n\t}\n\n\treturn 0;\n}\n\nstatic int efa_device_init(struct efa_com_dev *edev, struct pci_dev *pdev)\n{\n\tint dma_width;\n\tint err;\n\n\terr = efa_com_dev_reset(edev, EFA_REGS_RESET_NORMAL);\n\tif (err)\n\t\treturn err;\n\n\terr = efa_com_validate_version(edev);\n\tif (err)\n\t\treturn err;\n\n\tdma_width = efa_com_get_dma_width(edev);\n\tif (dma_width < 0) {\n\t\terr = dma_width;\n\t\treturn err;\n\t}\n\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(dma_width));\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"dma_set_mask_and_coherent failed %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tdma_set_max_seg_size(&pdev->dev, UINT_MAX);\n\treturn 0;\n}\n\nstatic struct efa_dev *efa_probe_device(struct pci_dev *pdev)\n{\n\tstruct efa_com_dev *edev;\n\tstruct efa_dev *dev;\n\tint bars;\n\tint err;\n\n\terr = pci_enable_device_mem(pdev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"pci_enable_device_mem() failed!\\n\");\n\t\treturn ERR_PTR(err);\n\t}\n\n\tpci_set_master(pdev);\n\n\tdev = ib_alloc_device(efa_dev, ibdev);\n\tif (!dev) {\n\t\tdev_err(&pdev->dev, \"Device alloc failed\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_disable_device;\n\t}\n\n\tpci_set_drvdata(pdev, dev);\n\tedev = &dev->edev;\n\tedev->efa_dev = dev;\n\tedev->dmadev = &pdev->dev;\n\tdev->pdev = pdev;\n\txa_init(&dev->cqs_xa);\n\n\tbars = pci_select_bars(pdev, IORESOURCE_MEM) & EFA_BASE_BAR_MASK;\n\terr = pci_request_selected_regions(pdev, bars, DRV_MODULE_NAME);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"pci_request_selected_regions failed %d\\n\",\n\t\t\terr);\n\t\tgoto err_ibdev_destroy;\n\t}\n\n\tdev->reg_bar_addr = pci_resource_start(pdev, EFA_REG_BAR);\n\tdev->reg_bar_len = pci_resource_len(pdev, EFA_REG_BAR);\n\tdev->mem_bar_addr = pci_resource_start(pdev, EFA_MEM_BAR);\n\tdev->mem_bar_len = pci_resource_len(pdev, EFA_MEM_BAR);\n\n\tedev->reg_bar = devm_ioremap(&pdev->dev,\n\t\t\t\t     dev->reg_bar_addr,\n\t\t\t\t     dev->reg_bar_len);\n\tif (!edev->reg_bar) {\n\t\tdev_err(&pdev->dev, \"Failed to remap register bar\\n\");\n\t\terr = -EFAULT;\n\t\tgoto err_release_bars;\n\t}\n\n\terr = efa_com_mmio_reg_read_init(edev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Failed to init readless MMIO\\n\");\n\t\tgoto err_iounmap;\n\t}\n\n\terr = efa_device_init(edev, pdev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"EFA device init failed\\n\");\n\t\tif (err == -ETIME)\n\t\t\terr = -EPROBE_DEFER;\n\t\tgoto err_reg_read_destroy;\n\t}\n\n\terr = efa_enable_msix(dev);\n\tif (err)\n\t\tgoto err_reg_read_destroy;\n\n\tedev->aq.msix_vector_idx = dev->admin_msix_vector_idx;\n\tedev->aenq.msix_vector_idx = dev->admin_msix_vector_idx;\n\n\terr = efa_set_mgmnt_irq(dev);\n\tif (err)\n\t\tgoto err_disable_msix;\n\n\terr = efa_com_admin_init(edev, &aenq_handlers);\n\tif (err)\n\t\tgoto err_free_mgmnt_irq;\n\n\treturn dev;\n\nerr_free_mgmnt_irq:\n\tefa_free_irq(dev, &dev->admin_irq);\nerr_disable_msix:\n\tefa_disable_msix(dev);\nerr_reg_read_destroy:\n\tefa_com_mmio_reg_read_destroy(edev);\nerr_iounmap:\n\tdevm_iounmap(&pdev->dev, edev->reg_bar);\nerr_release_bars:\n\tefa_release_bars(dev, EFA_BASE_BAR_MASK);\nerr_ibdev_destroy:\n\tib_dealloc_device(&dev->ibdev);\nerr_disable_device:\n\tpci_disable_device(pdev);\n\treturn ERR_PTR(err);\n}\n\nstatic void efa_remove_device(struct pci_dev *pdev)\n{\n\tstruct efa_dev *dev = pci_get_drvdata(pdev);\n\tstruct efa_com_dev *edev;\n\n\tedev = &dev->edev;\n\tefa_com_admin_destroy(edev);\n\tefa_free_irq(dev, &dev->admin_irq);\n\tefa_disable_msix(dev);\n\tefa_com_mmio_reg_read_destroy(edev);\n\tdevm_iounmap(&pdev->dev, edev->reg_bar);\n\tefa_release_bars(dev, EFA_BASE_BAR_MASK);\n\txa_destroy(&dev->cqs_xa);\n\tib_dealloc_device(&dev->ibdev);\n\tpci_disable_device(pdev);\n}\n\nstatic int efa_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct efa_dev *dev;\n\tint err;\n\n\tdev = efa_probe_device(pdev);\n\tif (IS_ERR(dev))\n\t\treturn PTR_ERR(dev);\n\n\terr = efa_ib_device_add(dev);\n\tif (err)\n\t\tgoto err_remove_device;\n\n\treturn 0;\n\nerr_remove_device:\n\tefa_remove_device(pdev);\n\treturn err;\n}\n\nstatic void efa_remove(struct pci_dev *pdev)\n{\n\tstruct efa_dev *dev = pci_get_drvdata(pdev);\n\n\tefa_ib_device_remove(dev);\n\tefa_remove_device(pdev);\n}\n\nstatic struct pci_driver efa_pci_driver = {\n\t.name           = DRV_MODULE_NAME,\n\t.id_table       = efa_pci_tbl,\n\t.probe          = efa_probe,\n\t.remove         = efa_remove,\n};\n\nmodule_pci_driver(efa_pci_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}