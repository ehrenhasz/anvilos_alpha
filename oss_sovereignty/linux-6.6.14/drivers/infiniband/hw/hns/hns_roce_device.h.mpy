{
  "module_name": "hns_roce_device.h",
  "hash_id": "71a32ea5445b39586ea73b6cd83213e370e24a81370950be31cc9dfdc56a4a04",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/hns/hns_roce_device.h",
  "human_readable_source": " \n\n#ifndef _HNS_ROCE_DEVICE_H\n#define _HNS_ROCE_DEVICE_H\n\n#include <rdma/ib_verbs.h>\n#include <rdma/hns-abi.h>\n\n#define PCI_REVISION_ID_HIP08\t\t\t0x21\n#define PCI_REVISION_ID_HIP09\t\t\t0x30\n\n#define HNS_ROCE_MAX_MSG_LEN\t\t\t0x80000000\n\n#define HNS_ROCE_IB_MIN_SQ_STRIDE\t\t6\n\n#define BA_BYTE_LEN\t\t\t\t8\n\n#define HNS_ROCE_MIN_CQE_NUM\t\t\t0x40\n#define HNS_ROCE_MIN_SRQ_WQE_NUM\t\t1\n\n#define HNS_ROCE_MAX_IRQ_NUM\t\t\t128\n\n#define HNS_ROCE_SGE_IN_WQE\t\t\t2\n#define HNS_ROCE_SGE_SHIFT\t\t\t4\n\n#define EQ_ENABLE\t\t\t\t1\n#define EQ_DISABLE\t\t\t\t0\n\n#define HNS_ROCE_CEQ\t\t\t\t0\n#define HNS_ROCE_AEQ\t\t\t\t1\n\n#define HNS_ROCE_CEQE_SIZE 0x4\n#define HNS_ROCE_AEQE_SIZE 0x10\n\n#define HNS_ROCE_V3_EQE_SIZE 0x40\n\n#define HNS_ROCE_V2_CQE_SIZE 32\n#define HNS_ROCE_V3_CQE_SIZE 64\n\n#define HNS_ROCE_V2_QPC_SZ 256\n#define HNS_ROCE_V3_QPC_SZ 512\n\n#define HNS_ROCE_MAX_PORTS\t\t\t6\n#define HNS_ROCE_GID_SIZE\t\t\t16\n#define HNS_ROCE_SGE_SIZE\t\t\t16\n#define HNS_ROCE_DWQE_SIZE\t\t\t65536\n\n#define HNS_ROCE_HOP_NUM_0\t\t\t0xff\n\n#define MR_TYPE_MR\t\t\t\t0x00\n#define MR_TYPE_FRMR\t\t\t\t0x01\n#define MR_TYPE_DMA\t\t\t\t0x03\n\n#define HNS_ROCE_FRMR_MAX_PA\t\t\t512\n\n#define PKEY_ID\t\t\t\t\t0xffff\n#define NODE_DESC_SIZE\t\t\t\t64\n#define DB_REG_OFFSET\t\t\t\t0x1000\n\n \n#define PG_SHIFT_OFFSET\t\t\t\t(PAGE_SHIFT - 12)\n\n#define HNS_ROCE_IDX_QUE_ENTRY_SZ\t\t4\n#define SRQ_DB_REG\t\t\t\t0x230\n\n#define HNS_ROCE_QP_BANK_NUM 8\n#define HNS_ROCE_CQ_BANK_NUM 4\n\n#define CQ_BANKID_SHIFT 2\n#define CQ_BANKID_MASK GENMASK(1, 0)\n\nenum {\n\tSERV_TYPE_RC,\n\tSERV_TYPE_UC,\n\tSERV_TYPE_RD,\n\tSERV_TYPE_UD,\n\tSERV_TYPE_XRC = 5,\n};\n\nenum hns_roce_event {\n\tHNS_ROCE_EVENT_TYPE_PATH_MIG                  = 0x01,\n\tHNS_ROCE_EVENT_TYPE_PATH_MIG_FAILED           = 0x02,\n\tHNS_ROCE_EVENT_TYPE_COMM_EST                  = 0x03,\n\tHNS_ROCE_EVENT_TYPE_SQ_DRAINED                = 0x04,\n\tHNS_ROCE_EVENT_TYPE_WQ_CATAS_ERROR            = 0x05,\n\tHNS_ROCE_EVENT_TYPE_INV_REQ_LOCAL_WQ_ERROR    = 0x06,\n\tHNS_ROCE_EVENT_TYPE_LOCAL_WQ_ACCESS_ERROR     = 0x07,\n\tHNS_ROCE_EVENT_TYPE_SRQ_LIMIT_REACH           = 0x08,\n\tHNS_ROCE_EVENT_TYPE_SRQ_LAST_WQE_REACH        = 0x09,\n\tHNS_ROCE_EVENT_TYPE_SRQ_CATAS_ERROR           = 0x0a,\n\tHNS_ROCE_EVENT_TYPE_CQ_ACCESS_ERROR           = 0x0b,\n\tHNS_ROCE_EVENT_TYPE_CQ_OVERFLOW               = 0x0c,\n\tHNS_ROCE_EVENT_TYPE_CQ_ID_INVALID             = 0x0d,\n\tHNS_ROCE_EVENT_TYPE_PORT_CHANGE               = 0x0f,\n\t \n\tHNS_ROCE_EVENT_TYPE_DB_OVERFLOW               = 0x12,\n\tHNS_ROCE_EVENT_TYPE_MB                        = 0x13,\n\tHNS_ROCE_EVENT_TYPE_FLR\t\t\t      = 0x15,\n\tHNS_ROCE_EVENT_TYPE_XRCD_VIOLATION\t      = 0x16,\n\tHNS_ROCE_EVENT_TYPE_INVALID_XRCETH\t      = 0x17,\n};\n\nenum {\n\tHNS_ROCE_CAP_FLAG_REREG_MR\t\t= BIT(0),\n\tHNS_ROCE_CAP_FLAG_ROCE_V1_V2\t\t= BIT(1),\n\tHNS_ROCE_CAP_FLAG_RQ_INLINE\t\t= BIT(2),\n\tHNS_ROCE_CAP_FLAG_CQ_RECORD_DB\t\t= BIT(3),\n\tHNS_ROCE_CAP_FLAG_QP_RECORD_DB\t\t= BIT(4),\n\tHNS_ROCE_CAP_FLAG_SRQ\t\t\t= BIT(5),\n\tHNS_ROCE_CAP_FLAG_XRC\t\t\t= BIT(6),\n\tHNS_ROCE_CAP_FLAG_MW\t\t\t= BIT(7),\n\tHNS_ROCE_CAP_FLAG_FRMR                  = BIT(8),\n\tHNS_ROCE_CAP_FLAG_QP_FLOW_CTRL\t\t= BIT(9),\n\tHNS_ROCE_CAP_FLAG_ATOMIC\t\t= BIT(10),\n\tHNS_ROCE_CAP_FLAG_DIRECT_WQE\t\t= BIT(12),\n\tHNS_ROCE_CAP_FLAG_SDI_MODE\t\t= BIT(14),\n\tHNS_ROCE_CAP_FLAG_STASH\t\t\t= BIT(17),\n\tHNS_ROCE_CAP_FLAG_CQE_INLINE\t\t= BIT(19),\n};\n\n#define HNS_ROCE_DB_TYPE_COUNT\t\t\t2\n#define HNS_ROCE_DB_UNIT_SIZE\t\t\t4\n\nenum {\n\tHNS_ROCE_DB_PER_PAGE = PAGE_SIZE / 4\n};\n\nenum hns_roce_reset_stage {\n\tHNS_ROCE_STATE_NON_RST,\n\tHNS_ROCE_STATE_RST_BEF_DOWN,\n\tHNS_ROCE_STATE_RST_DOWN,\n\tHNS_ROCE_STATE_RST_UNINIT,\n\tHNS_ROCE_STATE_RST_INIT,\n\tHNS_ROCE_STATE_RST_INITED,\n};\n\nenum hns_roce_instance_state {\n\tHNS_ROCE_STATE_NON_INIT,\n\tHNS_ROCE_STATE_INIT,\n\tHNS_ROCE_STATE_INITED,\n\tHNS_ROCE_STATE_UNINIT,\n};\n\nenum {\n\tHNS_ROCE_RST_DIRECT_RETURN\t\t= 0,\n};\n\n#define HNS_ROCE_CMD_SUCCESS\t\t\t1\n\n \n#define HNS_HW_PAGE_SHIFT\t\t\t12\n#define HNS_HW_PAGE_SIZE\t\t\t(1 << HNS_HW_PAGE_SHIFT)\n\nstruct hns_roce_uar {\n\tu64\t\tpfn;\n\tunsigned long\tindex;\n\tunsigned long\tlogic_idx;\n};\n\nenum hns_roce_mmap_type {\n\tHNS_ROCE_MMAP_TYPE_DB = 1,\n\tHNS_ROCE_MMAP_TYPE_DWQE,\n};\n\nstruct hns_user_mmap_entry {\n\tstruct rdma_user_mmap_entry rdma_entry;\n\tenum hns_roce_mmap_type mmap_type;\n\tu64 address;\n};\n\nstruct hns_roce_ucontext {\n\tstruct ib_ucontext\tibucontext;\n\tstruct hns_roce_uar\tuar;\n\tstruct list_head\tpage_list;\n\tstruct mutex\t\tpage_mutex;\n\tstruct hns_user_mmap_entry *db_mmap_entry;\n\tu32\t\t\tconfig;\n};\n\nstruct hns_roce_pd {\n\tstruct ib_pd\t\tibpd;\n\tunsigned long\t\tpdn;\n};\n\nstruct hns_roce_xrcd {\n\tstruct ib_xrcd ibxrcd;\n\tu32 xrcdn;\n};\n\nstruct hns_roce_bitmap {\n\t \n\tunsigned long\t\tlast;\n\tunsigned long\t\ttop;\n\tunsigned long\t\tmax;\n\tunsigned long\t\treserved_top;\n\tunsigned long\t\tmask;\n\tspinlock_t\t\tlock;\n\tunsigned long\t\t*table;\n};\n\nstruct hns_roce_ida {\n\tstruct ida ida;\n\tu32 min;  \n\tu32 max;  \n};\n\n \nstruct hns_roce_hem_table {\n\t \n\tu32\t\ttype;\n\t \n\tunsigned long\tnum_hem;\n\t \n\tunsigned long\tobj_size;\n\tunsigned long\ttable_chunk_size;\n\tstruct mutex\tmutex;\n\tstruct hns_roce_hem **hem;\n\tu64\t\t**bt_l1;\n\tdma_addr_t\t*bt_l1_dma_addr;\n\tu64\t\t**bt_l0;\n\tdma_addr_t\t*bt_l0_dma_addr;\n};\n\nstruct hns_roce_buf_region {\n\tu32 offset;  \n\tu32 count;  \n\tint hopnum;  \n};\n\n#define HNS_ROCE_MAX_BT_REGION\t3\n#define HNS_ROCE_MAX_BT_LEVEL\t3\nstruct hns_roce_hem_list {\n\tstruct list_head root_bt;\n\t \n\tstruct list_head mid_bt[HNS_ROCE_MAX_BT_REGION][HNS_ROCE_MAX_BT_LEVEL];\n\tstruct list_head btm_bt;  \n\tdma_addr_t root_ba;  \n};\n\nstruct hns_roce_buf_attr {\n\tstruct {\n\t\tsize_t\tsize;   \n\t\tint\thopnum;  \n\t} region[HNS_ROCE_MAX_BT_REGION];\n\tunsigned int region_count;  \n\tunsigned int page_shift;   \n\tunsigned int user_access;  \n\tbool mtt_only;  \n};\n\nstruct hns_roce_hem_cfg {\n\tdma_addr_t\troot_ba;  \n\tbool\t\tis_direct;  \n\tunsigned int\tba_pg_shift;  \n\tunsigned int\tbuf_pg_shift;  \n\tunsigned int\tbuf_pg_count;   \n\tstruct hns_roce_buf_region region[HNS_ROCE_MAX_BT_REGION];\n\tunsigned int\tregion_count;\n};\n\n \nstruct hns_roce_mtr {\n\tstruct hns_roce_hem_list hem_list;  \n\tstruct ib_umem\t\t*umem;  \n\tstruct hns_roce_buf\t*kmem;  \n\tstruct hns_roce_hem_cfg  hem_cfg;  \n};\n\nstruct hns_roce_mw {\n\tstruct ib_mw\t\tibmw;\n\tu32\t\t\tpdn;\n\tu32\t\t\trkey;\n\tint\t\t\tenabled;  \n\tu32\t\t\tpbl_hop_num;\n\tu32\t\t\tpbl_ba_pg_sz;\n\tu32\t\t\tpbl_buf_pg_sz;\n};\n\nstruct hns_roce_mr {\n\tstruct ib_mr\t\tibmr;\n\tu64\t\t\tiova;  \n\tu64\t\t\tsize;  \n\tu32\t\t\tkey;  \n\tu32\t\t\tpd;    \n\tu32\t\t\taccess;  \n\tint\t\t\tenabled;  \n\tint\t\t\ttype;  \n\tu32\t\t\tpbl_hop_num;  \n\tstruct hns_roce_mtr\tpbl_mtr;\n\tu32\t\t\tnpages;\n\tdma_addr_t\t\t*page_list;\n};\n\nstruct hns_roce_mr_table {\n\tstruct hns_roce_ida mtpt_ida;\n\tstruct hns_roce_hem_table\tmtpt_table;\n};\n\nstruct hns_roce_wq {\n\tu64\t\t*wrid;      \n\tspinlock_t\tlock;\n\tu32\t\twqe_cnt;   \n\tu32\t\tmax_gs;\n\tu32\t\trsv_sge;\n\tu32\t\toffset;\n\tu32\t\twqe_shift;  \n\tu32\t\thead;\n\tu32\t\ttail;\n\tvoid __iomem\t*db_reg;\n\tu32\t\text_sge_cnt;\n};\n\nstruct hns_roce_sge {\n\tunsigned int\tsge_cnt;  \n\tu32\t\toffset;\n\tu32\t\tsge_shift;  \n};\n\nstruct hns_roce_buf_list {\n\tvoid\t\t*buf;\n\tdma_addr_t\tmap;\n};\n\n \nenum {\n\tHNS_ROCE_BUF_DIRECT = BIT(0),\n\tHNS_ROCE_BUF_NOSLEEP = BIT(1),\n\tHNS_ROCE_BUF_NOFAIL = BIT(2),\n};\n\nstruct hns_roce_buf {\n\tstruct hns_roce_buf_list\t*trunk_list;\n\tu32\t\t\t\tntrunks;\n\tu32\t\t\t\tnpages;\n\tunsigned int\t\t\ttrunk_shift;\n\tunsigned int\t\t\tpage_shift;\n};\n\nstruct hns_roce_db_pgdir {\n\tstruct list_head\tlist;\n\tDECLARE_BITMAP(order0, HNS_ROCE_DB_PER_PAGE);\n\tDECLARE_BITMAP(order1, HNS_ROCE_DB_PER_PAGE / HNS_ROCE_DB_TYPE_COUNT);\n\tunsigned long\t\t*bits[HNS_ROCE_DB_TYPE_COUNT];\n\tu32\t\t\t*page;\n\tdma_addr_t\t\tdb_dma;\n};\n\nstruct hns_roce_user_db_page {\n\tstruct list_head\tlist;\n\tstruct ib_umem\t\t*umem;\n\tunsigned long\t\tuser_virt;\n\trefcount_t\t\trefcount;\n};\n\nstruct hns_roce_db {\n\tu32\t\t*db_record;\n\tunion {\n\t\tstruct hns_roce_db_pgdir *pgdir;\n\t\tstruct hns_roce_user_db_page *user_page;\n\t} u;\n\tdma_addr_t\tdma;\n\tvoid\t\t*virt_addr;\n\tunsigned long\tindex;\n\tunsigned long\torder;\n};\n\nstruct hns_roce_cq {\n\tstruct ib_cq\t\t\tib_cq;\n\tstruct hns_roce_mtr\t\tmtr;\n\tstruct hns_roce_db\t\tdb;\n\tu32\t\t\t\tflags;\n\tspinlock_t\t\t\tlock;\n\tu32\t\t\t\tcq_depth;\n\tu32\t\t\t\tcons_index;\n\tu32\t\t\t\t*set_ci_db;\n\tvoid __iomem\t\t\t*db_reg;\n\tint\t\t\t\tarm_sn;\n\tint\t\t\t\tcqe_size;\n\tunsigned long\t\t\tcqn;\n\tu32\t\t\t\tvector;\n\trefcount_t\t\t\trefcount;\n\tstruct completion\t\tfree;\n\tstruct list_head\t\tsq_list;  \n\tstruct list_head\t\trq_list;  \n\tint\t\t\t\tis_armed;  \n\tstruct list_head\t\tnode;  \n};\n\nstruct hns_roce_idx_que {\n\tstruct hns_roce_mtr\t\tmtr;\n\tu32\t\t\t\tentry_shift;\n\tunsigned long\t\t\t*bitmap;\n\tu32\t\t\t\thead;\n\tu32\t\t\t\ttail;\n};\n\nstruct hns_roce_srq {\n\tstruct ib_srq\t\tibsrq;\n\tunsigned long\t\tsrqn;\n\tu32\t\t\twqe_cnt;\n\tint\t\t\tmax_gs;\n\tu32\t\t\trsv_sge;\n\tu32\t\t\twqe_shift;\n\tu32\t\t\tcqn;\n\tu32\t\t\txrcdn;\n\tvoid __iomem\t\t*db_reg;\n\n\trefcount_t\t\trefcount;\n\tstruct completion\tfree;\n\n\tstruct hns_roce_mtr\tbuf_mtr;\n\n\tu64\t\t       *wrid;\n\tstruct hns_roce_idx_que idx_que;\n\tspinlock_t\t\tlock;\n\tstruct mutex\t\tmutex;\n\tvoid (*event)(struct hns_roce_srq *srq, enum hns_roce_event event);\n};\n\nstruct hns_roce_uar_table {\n\tstruct hns_roce_bitmap bitmap;\n};\n\nstruct hns_roce_bank {\n\tstruct ida ida;\n\tu32 inuse;  \n\tu32 min;  \n\tu32 max;  \n\tu32 next;  \n};\n\nstruct hns_roce_idx_table {\n\tu32 *spare_idx;\n\tu32 head;\n\tu32 tail;\n};\n\nstruct hns_roce_qp_table {\n\tstruct hns_roce_hem_table\tqp_table;\n\tstruct hns_roce_hem_table\tirrl_table;\n\tstruct hns_roce_hem_table\ttrrl_table;\n\tstruct hns_roce_hem_table\tsccc_table;\n\tstruct mutex\t\t\tscc_mutex;\n\tstruct hns_roce_bank bank[HNS_ROCE_QP_BANK_NUM];\n\tstruct mutex bank_mutex;\n\tstruct hns_roce_idx_table\tidx_table;\n};\n\nstruct hns_roce_cq_table {\n\tstruct xarray\t\t\tarray;\n\tstruct hns_roce_hem_table\ttable;\n\tstruct hns_roce_bank bank[HNS_ROCE_CQ_BANK_NUM];\n\tstruct mutex\t\t\tbank_mutex;\n};\n\nstruct hns_roce_srq_table {\n\tstruct hns_roce_ida\t\tsrq_ida;\n\tstruct xarray\t\t\txa;\n\tstruct hns_roce_hem_table\ttable;\n};\n\nstruct hns_roce_av {\n\tu8 port;\n\tu8 gid_index;\n\tu8 stat_rate;\n\tu8 hop_limit;\n\tu32 flowlabel;\n\tu16 udp_sport;\n\tu8 sl;\n\tu8 tclass;\n\tu8 dgid[HNS_ROCE_GID_SIZE];\n\tu8 mac[ETH_ALEN];\n\tu16 vlan_id;\n\tu8 vlan_en;\n};\n\nstruct hns_roce_ah {\n\tstruct ib_ah\t\tibah;\n\tstruct hns_roce_av\tav;\n};\n\nstruct hns_roce_cmd_context {\n\tstruct completion\tdone;\n\tint\t\t\tresult;\n\tint\t\t\tnext;\n\tu64\t\t\tout_param;\n\tu16\t\t\ttoken;\n\tu16\t\t\tbusy;\n};\n\nenum hns_roce_cmdq_state {\n\tHNS_ROCE_CMDQ_STATE_NORMAL,\n\tHNS_ROCE_CMDQ_STATE_FATAL_ERR,\n};\n\nstruct hns_roce_cmdq {\n\tstruct dma_pool\t\t*pool;\n\tstruct semaphore\tpoll_sem;\n\t \n\tstruct semaphore\tevent_sem;\n\tint\t\t\tmax_cmds;\n\tspinlock_t\t\tcontext_lock;\n\tint\t\t\tfree_head;\n\tstruct hns_roce_cmd_context *context;\n\t \n\tu8\t\t\tuse_events;\n\tenum hns_roce_cmdq_state state;\n};\n\nstruct hns_roce_cmd_mailbox {\n\tvoid\t\t       *buf;\n\tdma_addr_t\t\tdma;\n};\n\nstruct hns_roce_mbox_msg {\n\tu64 in_param;\n\tu64 out_param;\n\tu8 cmd;\n\tu32 tag;\n\tu16 token;\n\tu8 event_en;\n};\n\nstruct hns_roce_dev;\n\nenum {\n\tHNS_ROCE_FLUSH_FLAG = 0,\n};\n\nstruct hns_roce_work {\n\tstruct hns_roce_dev *hr_dev;\n\tstruct work_struct work;\n\tint event_type;\n\tint sub_type;\n\tu32 queue_num;\n};\n\nstruct hns_roce_qp {\n\tstruct ib_qp\t\tibqp;\n\tstruct hns_roce_wq\trq;\n\tstruct hns_roce_db\trdb;\n\tstruct hns_roce_db\tsdb;\n\tunsigned long\t\ten_flags;\n\tenum ib_sig_type\tsq_signal_bits;\n\tstruct hns_roce_wq\tsq;\n\n\tstruct hns_roce_mtr\tmtr;\n\n\tu32\t\t\tbuff_size;\n\tstruct mutex\t\tmutex;\n\tu8\t\t\tport;\n\tu8\t\t\tphy_port;\n\tu8\t\t\tsl;\n\tu8\t\t\tresp_depth;\n\tu8\t\t\tstate;\n\tu32                     atomic_rd_en;\n\tu32\t\t\tqkey;\n\tvoid\t\t\t(*event)(struct hns_roce_qp *qp,\n\t\t\t\t\t enum hns_roce_event event_type);\n\tunsigned long\t\tqpn;\n\n\tu32\t\t\txrcdn;\n\n\trefcount_t\t\trefcount;\n\tstruct completion\tfree;\n\n\tstruct hns_roce_sge\tsge;\n\tu32\t\t\tnext_sge;\n\tenum ib_mtu\t\tpath_mtu;\n\tu32\t\t\tmax_inline_data;\n\tu8\t\t\tfree_mr_en;\n\n\t \n\tunsigned long\t\tflush_flag;\n\tstruct hns_roce_work\tflush_work;\n\tstruct list_head\tnode;  \n\tstruct list_head\trq_node;  \n\tstruct list_head\tsq_node;  \n\tstruct hns_user_mmap_entry *dwqe_mmap_entry;\n\tu32\t\t\tconfig;\n};\n\nstruct hns_roce_ib_iboe {\n\tspinlock_t\t\tlock;\n\tstruct net_device      *netdevs[HNS_ROCE_MAX_PORTS];\n\tstruct notifier_block\tnb;\n\tu8\t\t\tphy_port[HNS_ROCE_MAX_PORTS];\n};\n\nstruct hns_roce_ceqe {\n\t__le32\tcomp;\n\t__le32\trsv[15];\n};\n\n#define CEQE_FIELD_LOC(h, l) FIELD_LOC(struct hns_roce_ceqe, h, l)\n\n#define CEQE_CQN CEQE_FIELD_LOC(23, 0)\n#define CEQE_OWNER CEQE_FIELD_LOC(31, 31)\n\nstruct hns_roce_aeqe {\n\t__le32 asyn;\n\tunion {\n\t\tstruct {\n\t\t\t__le32 num;\n\t\t\tu32 rsv0;\n\t\t\tu32 rsv1;\n\t\t} queue_event;\n\n\t\tstruct {\n\t\t\t__le64  out_param;\n\t\t\t__le16  token;\n\t\t\tu8\tstatus;\n\t\t\tu8\trsv0;\n\t\t} __packed cmd;\n\t } event;\n\t__le32 rsv[12];\n};\n\n#define AEQE_FIELD_LOC(h, l) FIELD_LOC(struct hns_roce_aeqe, h, l)\n\n#define AEQE_EVENT_TYPE AEQE_FIELD_LOC(7, 0)\n#define AEQE_SUB_TYPE AEQE_FIELD_LOC(15, 8)\n#define AEQE_OWNER AEQE_FIELD_LOC(31, 31)\n#define AEQE_EVENT_QUEUE_NUM AEQE_FIELD_LOC(55, 32)\n\nstruct hns_roce_eq {\n\tstruct hns_roce_dev\t\t*hr_dev;\n\tvoid __iomem\t\t\t*db_reg;\n\n\tint\t\t\t\ttype_flag;  \n\tint\t\t\t\teqn;\n\tu32\t\t\t\tentries;\n\tint\t\t\t\teqe_size;\n\tint\t\t\t\tirq;\n\tu32\t\t\t\tcons_index;\n\tint\t\t\t\tover_ignore;\n\tint\t\t\t\tcoalesce;\n\tint\t\t\t\tarm_st;\n\tint\t\t\t\thop_num;\n\tstruct hns_roce_mtr\t\tmtr;\n\tu16\t\t\t\teq_max_cnt;\n\tu32\t\t\t\teq_period;\n\tint\t\t\t\tshift;\n\tint\t\t\t\tevent_type;\n\tint\t\t\t\tsub_type;\n};\n\nstruct hns_roce_eq_table {\n\tstruct hns_roce_eq\t*eq;\n};\n\nenum cong_type {\n\tCONG_TYPE_DCQCN,\n\tCONG_TYPE_LDCP,\n\tCONG_TYPE_HC3,\n\tCONG_TYPE_DIP,\n};\n\nstruct hns_roce_caps {\n\tu64\t\tfw_ver;\n\tu8\t\tnum_ports;\n\tint\t\tgid_table_len[HNS_ROCE_MAX_PORTS];\n\tint\t\tpkey_table_len[HNS_ROCE_MAX_PORTS];\n\tint\t\tlocal_ca_ack_delay;\n\tint\t\tnum_uars;\n\tu32\t\tphy_num_uars;\n\tu32\t\tmax_sq_sg;\n\tu32\t\tmax_sq_inline;\n\tu32\t\tmax_rq_sg;\n\tu32\t\trsv0;\n\tu32\t\tnum_qps;\n\tu32\t\treserved_qps;\n\tu32\t\tnum_srqs;\n\tu32\t\tmax_wqes;\n\tu32\t\tmax_srq_wrs;\n\tu32\t\tmax_srq_sges;\n\tu32\t\tmax_sq_desc_sz;\n\tu32\t\tmax_rq_desc_sz;\n\tu32\t\trsv2;\n\tint\t\tmax_qp_init_rdma;\n\tint\t\tmax_qp_dest_rdma;\n\tu32\t\tnum_cqs;\n\tu32\t\tmax_cqes;\n\tu32\t\tmin_cqes;\n\tu32\t\tmin_wqes;\n\tu32\t\treserved_cqs;\n\tu32\t\treserved_srqs;\n\tint\t\tnum_aeq_vectors;\n\tint\t\tnum_comp_vectors;\n\tint\t\tnum_other_vectors;\n\tu32\t\tnum_mtpts;\n\tu32\t\trsv1;\n\tu32\t\tnum_srqwqe_segs;\n\tu32\t\tnum_idx_segs;\n\tint\t\treserved_mrws;\n\tint\t\treserved_uars;\n\tint\t\tnum_pds;\n\tint\t\treserved_pds;\n\tu32\t\tnum_xrcds;\n\tu32\t\treserved_xrcds;\n\tu32\t\tmtt_entry_sz;\n\tu32\t\tcqe_sz;\n\tu32\t\tpage_size_cap;\n\tu32\t\treserved_lkey;\n\tint\t\tmtpt_entry_sz;\n\tint\t\tqpc_sz;\n\tint\t\tirrl_entry_sz;\n\tint\t\ttrrl_entry_sz;\n\tint\t\tcqc_entry_sz;\n\tint\t\tsccc_sz;\n\tint\t\tqpc_timer_entry_sz;\n\tint\t\tcqc_timer_entry_sz;\n\tint\t\tsrqc_entry_sz;\n\tint\t\tidx_entry_sz;\n\tu32\t\tpbl_ba_pg_sz;\n\tu32\t\tpbl_buf_pg_sz;\n\tu32\t\tpbl_hop_num;\n\tint\t\taeqe_depth;\n\tint\t\tceqe_depth;\n\tu32\t\taeqe_size;\n\tu32\t\tceqe_size;\n\tenum ib_mtu\tmax_mtu;\n\tu32\t\tqpc_bt_num;\n\tu32\t\tqpc_timer_bt_num;\n\tu32\t\tsrqc_bt_num;\n\tu32\t\tcqc_bt_num;\n\tu32\t\tcqc_timer_bt_num;\n\tu32\t\tmpt_bt_num;\n\tu32\t\teqc_bt_num;\n\tu32\t\tsmac_bt_num;\n\tu32\t\tsgid_bt_num;\n\tu32\t\tsccc_bt_num;\n\tu32\t\tgmv_bt_num;\n\tu32\t\tqpc_ba_pg_sz;\n\tu32\t\tqpc_buf_pg_sz;\n\tu32\t\tqpc_hop_num;\n\tu32\t\tsrqc_ba_pg_sz;\n\tu32\t\tsrqc_buf_pg_sz;\n\tu32\t\tsrqc_hop_num;\n\tu32\t\tcqc_ba_pg_sz;\n\tu32\t\tcqc_buf_pg_sz;\n\tu32\t\tcqc_hop_num;\n\tu32\t\tmpt_ba_pg_sz;\n\tu32\t\tmpt_buf_pg_sz;\n\tu32\t\tmpt_hop_num;\n\tu32\t\tmtt_ba_pg_sz;\n\tu32\t\tmtt_buf_pg_sz;\n\tu32\t\tmtt_hop_num;\n\tu32\t\twqe_sq_hop_num;\n\tu32\t\twqe_sge_hop_num;\n\tu32\t\twqe_rq_hop_num;\n\tu32\t\tsccc_ba_pg_sz;\n\tu32\t\tsccc_buf_pg_sz;\n\tu32\t\tsccc_hop_num;\n\tu32\t\tqpc_timer_ba_pg_sz;\n\tu32\t\tqpc_timer_buf_pg_sz;\n\tu32\t\tqpc_timer_hop_num;\n\tu32\t\tcqc_timer_ba_pg_sz;\n\tu32\t\tcqc_timer_buf_pg_sz;\n\tu32\t\tcqc_timer_hop_num;\n\tu32\t\tcqe_ba_pg_sz;  \n\tu32\t\tcqe_buf_pg_sz;\n\tu32\t\tcqe_hop_num;\n\tu32\t\tsrqwqe_ba_pg_sz;\n\tu32\t\tsrqwqe_buf_pg_sz;\n\tu32\t\tsrqwqe_hop_num;\n\tu32\t\tidx_ba_pg_sz;\n\tu32\t\tidx_buf_pg_sz;\n\tu32\t\tidx_hop_num;\n\tu32\t\teqe_ba_pg_sz;\n\tu32\t\teqe_buf_pg_sz;\n\tu32\t\teqe_hop_num;\n\tu32\t\tgmv_entry_num;\n\tu32\t\tgmv_entry_sz;\n\tu32\t\tgmv_ba_pg_sz;\n\tu32\t\tgmv_buf_pg_sz;\n\tu32\t\tgmv_hop_num;\n\tu32\t\tsl_num;\n\tu32\t\tllm_buf_pg_sz;\n\tu32\t\tchunk_sz;  \n\tu64\t\tflags;\n\tu16\t\tdefault_ceq_max_cnt;\n\tu16\t\tdefault_ceq_period;\n\tu16\t\tdefault_aeq_max_cnt;\n\tu16\t\tdefault_aeq_period;\n\tu16\t\tdefault_aeq_arm_st;\n\tu16\t\tdefault_ceq_arm_st;\n\tenum cong_type\tcong_type;\n};\n\nenum hns_roce_device_state {\n\tHNS_ROCE_DEVICE_STATE_INITED,\n\tHNS_ROCE_DEVICE_STATE_RST_DOWN,\n\tHNS_ROCE_DEVICE_STATE_UNINIT,\n};\n\nenum hns_roce_hw_pkt_stat_index {\n\tHNS_ROCE_HW_RX_RC_PKT_CNT,\n\tHNS_ROCE_HW_RX_UC_PKT_CNT,\n\tHNS_ROCE_HW_RX_UD_PKT_CNT,\n\tHNS_ROCE_HW_RX_XRC_PKT_CNT,\n\tHNS_ROCE_HW_RX_PKT_CNT,\n\tHNS_ROCE_HW_RX_ERR_PKT_CNT,\n\tHNS_ROCE_HW_RX_CNP_PKT_CNT,\n\tHNS_ROCE_HW_TX_RC_PKT_CNT,\n\tHNS_ROCE_HW_TX_UC_PKT_CNT,\n\tHNS_ROCE_HW_TX_UD_PKT_CNT,\n\tHNS_ROCE_HW_TX_XRC_PKT_CNT,\n\tHNS_ROCE_HW_TX_PKT_CNT,\n\tHNS_ROCE_HW_TX_ERR_PKT_CNT,\n\tHNS_ROCE_HW_TX_CNP_PKT_CNT,\n\tHNS_ROCE_HW_TRP_GET_MPT_ERR_PKT_CNT,\n\tHNS_ROCE_HW_TRP_GET_IRRL_ERR_PKT_CNT,\n\tHNS_ROCE_HW_ECN_DB_CNT,\n\tHNS_ROCE_HW_RX_BUF_CNT,\n\tHNS_ROCE_HW_TRP_RX_SOF_CNT,\n\tHNS_ROCE_HW_CQ_CQE_CNT,\n\tHNS_ROCE_HW_CQ_POE_CNT,\n\tHNS_ROCE_HW_CQ_NOTIFY_CNT,\n\tHNS_ROCE_HW_CNT_TOTAL\n};\n\nstruct hns_roce_hw {\n\tint (*cmq_init)(struct hns_roce_dev *hr_dev);\n\tvoid (*cmq_exit)(struct hns_roce_dev *hr_dev);\n\tint (*hw_profile)(struct hns_roce_dev *hr_dev);\n\tint (*hw_init)(struct hns_roce_dev *hr_dev);\n\tvoid (*hw_exit)(struct hns_roce_dev *hr_dev);\n\tint (*post_mbox)(struct hns_roce_dev *hr_dev,\n\t\t\t struct hns_roce_mbox_msg *mbox_msg);\n\tint (*poll_mbox_done)(struct hns_roce_dev *hr_dev);\n\tbool (*chk_mbox_avail)(struct hns_roce_dev *hr_dev, bool *is_busy);\n\tint (*set_gid)(struct hns_roce_dev *hr_dev, int gid_index,\n\t\t       const union ib_gid *gid, const struct ib_gid_attr *attr);\n\tint (*set_mac)(struct hns_roce_dev *hr_dev, u8 phy_port,\n\t\t       const u8 *addr);\n\tint (*write_mtpt)(struct hns_roce_dev *hr_dev, void *mb_buf,\n\t\t\t  struct hns_roce_mr *mr);\n\tint (*rereg_write_mtpt)(struct hns_roce_dev *hr_dev,\n\t\t\t\tstruct hns_roce_mr *mr, int flags,\n\t\t\t\tvoid *mb_buf);\n\tint (*frmr_write_mtpt)(struct hns_roce_dev *hr_dev, void *mb_buf,\n\t\t\t       struct hns_roce_mr *mr);\n\tint (*mw_write_mtpt)(void *mb_buf, struct hns_roce_mw *mw);\n\tvoid (*write_cqc)(struct hns_roce_dev *hr_dev,\n\t\t\t  struct hns_roce_cq *hr_cq, void *mb_buf, u64 *mtts,\n\t\t\t  dma_addr_t dma_handle);\n\tint (*set_hem)(struct hns_roce_dev *hr_dev,\n\t\t       struct hns_roce_hem_table *table, int obj, u32 step_idx);\n\tint (*clear_hem)(struct hns_roce_dev *hr_dev,\n\t\t\t struct hns_roce_hem_table *table, int obj,\n\t\t\t u32 step_idx);\n\tint (*modify_qp)(struct ib_qp *ibqp, const struct ib_qp_attr *attr,\n\t\t\t int attr_mask, enum ib_qp_state cur_state,\n\t\t\t enum ib_qp_state new_state, struct ib_udata *udata);\n\tint (*qp_flow_control_init)(struct hns_roce_dev *hr_dev,\n\t\t\t struct hns_roce_qp *hr_qp);\n\tvoid (*dereg_mr)(struct hns_roce_dev *hr_dev);\n\tint (*init_eq)(struct hns_roce_dev *hr_dev);\n\tvoid (*cleanup_eq)(struct hns_roce_dev *hr_dev);\n\tint (*write_srqc)(struct hns_roce_srq *srq, void *mb_buf);\n\tint (*query_cqc)(struct hns_roce_dev *hr_dev, u32 cqn, void *buffer);\n\tint (*query_qpc)(struct hns_roce_dev *hr_dev, u32 qpn, void *buffer);\n\tint (*query_mpt)(struct hns_roce_dev *hr_dev, u32 key, void *buffer);\n\tint (*query_hw_counter)(struct hns_roce_dev *hr_dev,\n\t\t\t\tu64 *stats, u32 port, int *hw_counters);\n\tconst struct ib_device_ops *hns_roce_dev_ops;\n\tconst struct ib_device_ops *hns_roce_dev_srq_ops;\n};\n\nstruct hns_roce_dev {\n\tstruct ib_device\tib_dev;\n\tstruct pci_dev\t\t*pci_dev;\n\tstruct device\t\t*dev;\n\tstruct hns_roce_uar     priv_uar;\n\tconst char\t\t*irq_names[HNS_ROCE_MAX_IRQ_NUM];\n\tspinlock_t\t\tsm_lock;\n\tbool\t\t\tactive;\n\tbool\t\t\tis_reset;\n\tbool\t\t\tdis_db;\n\tunsigned long\t\treset_cnt;\n\tstruct hns_roce_ib_iboe iboe;\n\tenum hns_roce_device_state state;\n\tstruct list_head\tqp_list;  \n\tspinlock_t\t\tqp_list_lock;  \n\tstruct list_head\tdip_list;  \n\tspinlock_t\t\tdip_list_lock;  \n\n\tstruct list_head        pgdir_list;\n\tstruct mutex            pgdir_mutex;\n\tint\t\t\tirq[HNS_ROCE_MAX_IRQ_NUM];\n\tu8 __iomem\t\t*reg_base;\n\tvoid __iomem\t\t*mem_base;\n\tstruct hns_roce_caps\tcaps;\n\tstruct xarray\t\tqp_table_xa;\n\n\tunsigned char\tdev_addr[HNS_ROCE_MAX_PORTS][ETH_ALEN];\n\tu64\t\t\tsys_image_guid;\n\tu32                     vendor_id;\n\tu32                     vendor_part_id;\n\tu32                     hw_rev;\n\tvoid __iomem            *priv_addr;\n\n\tstruct hns_roce_cmdq\tcmd;\n\tstruct hns_roce_ida pd_ida;\n\tstruct hns_roce_ida xrcd_ida;\n\tstruct hns_roce_ida uar_ida;\n\tstruct hns_roce_mr_table  mr_table;\n\tstruct hns_roce_cq_table  cq_table;\n\tstruct hns_roce_srq_table srq_table;\n\tstruct hns_roce_qp_table  qp_table;\n\tstruct hns_roce_eq_table  eq_table;\n\tstruct hns_roce_hem_table  qpc_timer_table;\n\tstruct hns_roce_hem_table  cqc_timer_table;\n\t \n\tstruct hns_roce_hem_table  gmv_table;\n\n\tint\t\t\tcmd_mod;\n\tint\t\t\tloop_idc;\n\tu32\t\t\tsdb_offset;\n\tu32\t\t\todb_offset;\n\tconst struct hns_roce_hw *hw;\n\tvoid\t\t\t*priv;\n\tstruct workqueue_struct *irq_workq;\n\tstruct work_struct ecc_work;\n\tu32 func_num;\n\tu32 is_vf;\n\tu32 cong_algo_tmpl_id;\n\tu64 dwqe_page;\n};\n\nstatic inline struct hns_roce_dev *to_hr_dev(struct ib_device *ib_dev)\n{\n\treturn container_of(ib_dev, struct hns_roce_dev, ib_dev);\n}\n\nstatic inline struct hns_roce_ucontext\n\t\t\t*to_hr_ucontext(struct ib_ucontext *ibucontext)\n{\n\treturn container_of(ibucontext, struct hns_roce_ucontext, ibucontext);\n}\n\nstatic inline struct hns_roce_pd *to_hr_pd(struct ib_pd *ibpd)\n{\n\treturn container_of(ibpd, struct hns_roce_pd, ibpd);\n}\n\nstatic inline struct hns_roce_xrcd *to_hr_xrcd(struct ib_xrcd *ibxrcd)\n{\n\treturn container_of(ibxrcd, struct hns_roce_xrcd, ibxrcd);\n}\n\nstatic inline struct hns_roce_ah *to_hr_ah(struct ib_ah *ibah)\n{\n\treturn container_of(ibah, struct hns_roce_ah, ibah);\n}\n\nstatic inline struct hns_roce_mr *to_hr_mr(struct ib_mr *ibmr)\n{\n\treturn container_of(ibmr, struct hns_roce_mr, ibmr);\n}\n\nstatic inline struct hns_roce_mw *to_hr_mw(struct ib_mw *ibmw)\n{\n\treturn container_of(ibmw, struct hns_roce_mw, ibmw);\n}\n\nstatic inline struct hns_roce_qp *to_hr_qp(struct ib_qp *ibqp)\n{\n\treturn container_of(ibqp, struct hns_roce_qp, ibqp);\n}\n\nstatic inline struct hns_roce_cq *to_hr_cq(struct ib_cq *ib_cq)\n{\n\treturn container_of(ib_cq, struct hns_roce_cq, ib_cq);\n}\n\nstatic inline struct hns_roce_srq *to_hr_srq(struct ib_srq *ibsrq)\n{\n\treturn container_of(ibsrq, struct hns_roce_srq, ibsrq);\n}\n\nstatic inline struct hns_user_mmap_entry *\nto_hns_mmap(struct rdma_user_mmap_entry *rdma_entry)\n{\n\treturn container_of(rdma_entry, struct hns_user_mmap_entry, rdma_entry);\n}\n\nstatic inline void hns_roce_write64_k(__le32 val[2], void __iomem *dest)\n{\n\twriteq(*(u64 *)val, dest);\n}\n\nstatic inline struct hns_roce_qp\n\t*__hns_roce_qp_lookup(struct hns_roce_dev *hr_dev, u32 qpn)\n{\n\treturn xa_load(&hr_dev->qp_table_xa, qpn);\n}\n\nstatic inline void *hns_roce_buf_offset(struct hns_roce_buf *buf,\n\t\t\t\t\tunsigned int offset)\n{\n\treturn (char *)(buf->trunk_list[offset >> buf->trunk_shift].buf) +\n\t\t\t(offset & ((1 << buf->trunk_shift) - 1));\n}\n\nstatic inline dma_addr_t hns_roce_buf_dma_addr(struct hns_roce_buf *buf,\n\t\t\t\t\t       unsigned int offset)\n{\n\treturn buf->trunk_list[offset >> buf->trunk_shift].map +\n\t\t\t(offset & ((1 << buf->trunk_shift) - 1));\n}\n\nstatic inline dma_addr_t hns_roce_buf_page(struct hns_roce_buf *buf, u32 idx)\n{\n\treturn hns_roce_buf_dma_addr(buf, idx << buf->page_shift);\n}\n\n#define hr_hw_page_align(x)\t\tALIGN(x, 1 << HNS_HW_PAGE_SHIFT)\n\nstatic inline u64 to_hr_hw_page_addr(u64 addr)\n{\n\treturn addr >> HNS_HW_PAGE_SHIFT;\n}\n\nstatic inline u32 to_hr_hw_page_shift(u32 page_shift)\n{\n\treturn page_shift - HNS_HW_PAGE_SHIFT;\n}\n\nstatic inline u32 to_hr_hem_hopnum(u32 hopnum, u32 count)\n{\n\tif (count > 0)\n\t\treturn hopnum == HNS_ROCE_HOP_NUM_0 ? 0 : hopnum;\n\n\treturn 0;\n}\n\nstatic inline u32 to_hr_hem_entries_size(u32 count, u32 buf_shift)\n{\n\treturn hr_hw_page_align(count << buf_shift);\n}\n\nstatic inline u32 to_hr_hem_entries_count(u32 count, u32 buf_shift)\n{\n\treturn hr_hw_page_align(count << buf_shift) >> buf_shift;\n}\n\nstatic inline u32 to_hr_hem_entries_shift(u32 count, u32 buf_shift)\n{\n\tif (!count)\n\t\treturn 0;\n\n\treturn ilog2(to_hr_hem_entries_count(count, buf_shift));\n}\n\n#define DSCP_SHIFT 2\n\nstatic inline u8 get_tclass(const struct ib_global_route *grh)\n{\n\treturn grh->sgid_attr->gid_type == IB_GID_TYPE_ROCE_UDP_ENCAP ?\n\t       grh->traffic_class >> DSCP_SHIFT : grh->traffic_class;\n}\n\nvoid hns_roce_init_uar_table(struct hns_roce_dev *dev);\nint hns_roce_uar_alloc(struct hns_roce_dev *dev, struct hns_roce_uar *uar);\n\nint hns_roce_cmd_init(struct hns_roce_dev *hr_dev);\nvoid hns_roce_cmd_cleanup(struct hns_roce_dev *hr_dev);\nvoid hns_roce_cmd_event(struct hns_roce_dev *hr_dev, u16 token, u8 status,\n\t\t\tu64 out_param);\nint hns_roce_cmd_use_events(struct hns_roce_dev *hr_dev);\nvoid hns_roce_cmd_use_polling(struct hns_roce_dev *hr_dev);\n\n \n#define MTT_MIN_COUNT\t 2\nint hns_roce_mtr_find(struct hns_roce_dev *hr_dev, struct hns_roce_mtr *mtr,\n\t\t      u32 offset, u64 *mtt_buf, int mtt_max, u64 *base_addr);\nint hns_roce_mtr_create(struct hns_roce_dev *hr_dev, struct hns_roce_mtr *mtr,\n\t\t\tstruct hns_roce_buf_attr *buf_attr,\n\t\t\tunsigned int page_shift, struct ib_udata *udata,\n\t\t\tunsigned long user_addr);\nvoid hns_roce_mtr_destroy(struct hns_roce_dev *hr_dev,\n\t\t\t  struct hns_roce_mtr *mtr);\nint hns_roce_mtr_map(struct hns_roce_dev *hr_dev, struct hns_roce_mtr *mtr,\n\t\t     dma_addr_t *pages, unsigned int page_cnt);\n\nvoid hns_roce_init_pd_table(struct hns_roce_dev *hr_dev);\nvoid hns_roce_init_mr_table(struct hns_roce_dev *hr_dev);\nvoid hns_roce_init_cq_table(struct hns_roce_dev *hr_dev);\nint hns_roce_init_qp_table(struct hns_roce_dev *hr_dev);\nvoid hns_roce_init_srq_table(struct hns_roce_dev *hr_dev);\nvoid hns_roce_init_xrcd_table(struct hns_roce_dev *hr_dev);\n\nvoid hns_roce_cleanup_cq_table(struct hns_roce_dev *hr_dev);\nvoid hns_roce_cleanup_qp_table(struct hns_roce_dev *hr_dev);\n\nvoid hns_roce_cleanup_bitmap(struct hns_roce_dev *hr_dev);\n\nint hns_roce_create_ah(struct ib_ah *ah, struct rdma_ah_init_attr *init_attr,\n\t\t       struct ib_udata *udata);\nint hns_roce_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);\nstatic inline int hns_roce_destroy_ah(struct ib_ah *ah, u32 flags)\n{\n\treturn 0;\n}\n\nint hns_roce_alloc_pd(struct ib_pd *pd, struct ib_udata *udata);\nint hns_roce_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata);\n\nstruct ib_mr *hns_roce_get_dma_mr(struct ib_pd *pd, int acc);\nstruct ib_mr *hns_roce_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,\n\t\t\t\t   u64 virt_addr, int access_flags,\n\t\t\t\t   struct ib_udata *udata);\nstruct ib_mr *hns_roce_rereg_user_mr(struct ib_mr *mr, int flags, u64 start,\n\t\t\t\t     u64 length, u64 virt_addr,\n\t\t\t\t     int mr_access_flags, struct ib_pd *pd,\n\t\t\t\t     struct ib_udata *udata);\nstruct ib_mr *hns_roce_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,\n\t\t\t\tu32 max_num_sg);\nint hns_roce_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,\n\t\t       unsigned int *sg_offset);\nint hns_roce_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata);\nunsigned long key_to_hw_index(u32 key);\n\nint hns_roce_alloc_mw(struct ib_mw *mw, struct ib_udata *udata);\nint hns_roce_dealloc_mw(struct ib_mw *ibmw);\n\nvoid hns_roce_buf_free(struct hns_roce_dev *hr_dev, struct hns_roce_buf *buf);\nstruct hns_roce_buf *hns_roce_buf_alloc(struct hns_roce_dev *hr_dev, u32 size,\n\t\t\t\t\tu32 page_shift, u32 flags);\n\nint hns_roce_get_kmem_bufs(struct hns_roce_dev *hr_dev, dma_addr_t *bufs,\n\t\t\t   int buf_cnt, struct hns_roce_buf *buf,\n\t\t\t   unsigned int page_shift);\nint hns_roce_get_umem_bufs(struct hns_roce_dev *hr_dev, dma_addr_t *bufs,\n\t\t\t   int buf_cnt, struct ib_umem *umem,\n\t\t\t   unsigned int page_shift);\n\nint hns_roce_create_srq(struct ib_srq *srq,\n\t\t\tstruct ib_srq_init_attr *srq_init_attr,\n\t\t\tstruct ib_udata *udata);\nint hns_roce_destroy_srq(struct ib_srq *ibsrq, struct ib_udata *udata);\n\nint hns_roce_alloc_xrcd(struct ib_xrcd *ib_xrcd, struct ib_udata *udata);\nint hns_roce_dealloc_xrcd(struct ib_xrcd *ib_xrcd, struct ib_udata *udata);\n\nint hns_roce_create_qp(struct ib_qp *ib_qp, struct ib_qp_init_attr *init_attr,\n\t\t       struct ib_udata *udata);\nint hns_roce_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,\n\t\t       int attr_mask, struct ib_udata *udata);\nvoid init_flush_work(struct hns_roce_dev *hr_dev, struct hns_roce_qp *hr_qp);\nvoid *hns_roce_get_recv_wqe(struct hns_roce_qp *hr_qp, unsigned int n);\nvoid *hns_roce_get_send_wqe(struct hns_roce_qp *hr_qp, unsigned int n);\nvoid *hns_roce_get_extend_sge(struct hns_roce_qp *hr_qp, unsigned int n);\nbool hns_roce_wq_overflow(struct hns_roce_wq *hr_wq, u32 nreq,\n\t\t\t  struct ib_cq *ib_cq);\nvoid hns_roce_lock_cqs(struct hns_roce_cq *send_cq,\n\t\t       struct hns_roce_cq *recv_cq);\nvoid hns_roce_unlock_cqs(struct hns_roce_cq *send_cq,\n\t\t\t struct hns_roce_cq *recv_cq);\nvoid hns_roce_qp_remove(struct hns_roce_dev *hr_dev, struct hns_roce_qp *hr_qp);\nvoid hns_roce_qp_destroy(struct hns_roce_dev *hr_dev, struct hns_roce_qp *hr_qp,\n\t\t\t struct ib_udata *udata);\n__be32 send_ieth(const struct ib_send_wr *wr);\nint to_hr_qp_type(int qp_type);\n\nint hns_roce_create_cq(struct ib_cq *ib_cq, const struct ib_cq_init_attr *attr,\n\t\t       struct ib_udata *udata);\n\nint hns_roce_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata);\nint hns_roce_db_map_user(struct hns_roce_ucontext *context, unsigned long virt,\n\t\t\t struct hns_roce_db *db);\nvoid hns_roce_db_unmap_user(struct hns_roce_ucontext *context,\n\t\t\t    struct hns_roce_db *db);\nint hns_roce_alloc_db(struct hns_roce_dev *hr_dev, struct hns_roce_db *db,\n\t\t      int order);\nvoid hns_roce_free_db(struct hns_roce_dev *hr_dev, struct hns_roce_db *db);\n\nvoid hns_roce_cq_completion(struct hns_roce_dev *hr_dev, u32 cqn);\nvoid hns_roce_cq_event(struct hns_roce_dev *hr_dev, u32 cqn, int event_type);\nvoid flush_cqe(struct hns_roce_dev *dev, struct hns_roce_qp *qp);\nvoid hns_roce_qp_event(struct hns_roce_dev *hr_dev, u32 qpn, int event_type);\nvoid hns_roce_srq_event(struct hns_roce_dev *hr_dev, u32 srqn, int event_type);\nvoid hns_roce_handle_device_err(struct hns_roce_dev *hr_dev);\nint hns_roce_init(struct hns_roce_dev *hr_dev);\nvoid hns_roce_exit(struct hns_roce_dev *hr_dev);\nint hns_roce_fill_res_cq_entry(struct sk_buff *msg, struct ib_cq *ib_cq);\nint hns_roce_fill_res_cq_entry_raw(struct sk_buff *msg, struct ib_cq *ib_cq);\nint hns_roce_fill_res_qp_entry(struct sk_buff *msg, struct ib_qp *ib_qp);\nint hns_roce_fill_res_qp_entry_raw(struct sk_buff *msg, struct ib_qp *ib_qp);\nint hns_roce_fill_res_mr_entry(struct sk_buff *msg, struct ib_mr *ib_mr);\nint hns_roce_fill_res_mr_entry_raw(struct sk_buff *msg, struct ib_mr *ib_mr);\nstruct hns_user_mmap_entry *\nhns_roce_user_mmap_entry_insert(struct ib_ucontext *ucontext, u64 address,\n\t\t\t\tsize_t length,\n\t\t\t\tenum hns_roce_mmap_type mmap_type);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}