{
  "module_name": "hns_roce_pd.c",
  "hash_id": "3d74d593dc5a924e2c7ee8920bdbe4b62c8e6fe68b5f1ad91995b02fc6d2ecd5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/hns/hns_roce_pd.c",
  "human_readable_source": " \n\n#include <linux/pci.h>\n#include \"hns_roce_device.h\"\n\nvoid hns_roce_init_pd_table(struct hns_roce_dev *hr_dev)\n{\n\tstruct hns_roce_ida *pd_ida = &hr_dev->pd_ida;\n\n\tida_init(&pd_ida->ida);\n\tpd_ida->max = hr_dev->caps.num_pds - 1;\n\tpd_ida->min = hr_dev->caps.reserved_pds;\n}\n\nint hns_roce_alloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)\n{\n\tstruct ib_device *ib_dev = ibpd->device;\n\tstruct hns_roce_dev *hr_dev = to_hr_dev(ib_dev);\n\tstruct hns_roce_ida *pd_ida = &hr_dev->pd_ida;\n\tstruct hns_roce_pd *pd = to_hr_pd(ibpd);\n\tint ret = 0;\n\tint id;\n\n\tid = ida_alloc_range(&pd_ida->ida, pd_ida->min, pd_ida->max,\n\t\t\t     GFP_KERNEL);\n\tif (id < 0) {\n\t\tibdev_err(ib_dev, \"failed to alloc pd, id = %d.\\n\", id);\n\t\treturn -ENOMEM;\n\t}\n\tpd->pdn = (unsigned long)id;\n\n\tif (udata) {\n\t\tstruct hns_roce_ib_alloc_pd_resp resp = {.pdn = pd->pdn};\n\n\t\tret = ib_copy_to_udata(udata, &resp,\n\t\t\t\t       min(udata->outlen, sizeof(resp)));\n\t\tif (ret) {\n\t\t\tida_free(&pd_ida->ida, id);\n\t\t\tibdev_err(ib_dev, \"failed to copy to udata, ret = %d\\n\", ret);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nint hns_roce_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)\n{\n\tstruct hns_roce_dev *hr_dev = to_hr_dev(pd->device);\n\n\tida_free(&hr_dev->pd_ida.ida, (int)to_hr_pd(pd)->pdn);\n\n\treturn 0;\n}\n\nint hns_roce_uar_alloc(struct hns_roce_dev *hr_dev, struct hns_roce_uar *uar)\n{\n\tstruct hns_roce_ida *uar_ida = &hr_dev->uar_ida;\n\tint id;\n\n\t \n\tid = ida_alloc_range(&uar_ida->ida, uar_ida->min, uar_ida->max,\n\t\t\t     GFP_KERNEL);\n\tif (id < 0) {\n\t\tibdev_err(&hr_dev->ib_dev, \"failed to alloc uar id(%d).\\n\", id);\n\t\treturn -ENOMEM;\n\t}\n\tuar->logic_idx = (unsigned long)id;\n\n\tif (uar->logic_idx > 0 && hr_dev->caps.phy_num_uars > 1)\n\t\tuar->index = (uar->logic_idx - 1) %\n\t\t\t     (hr_dev->caps.phy_num_uars - 1) + 1;\n\telse\n\t\tuar->index = 0;\n\n\tuar->pfn = ((pci_resource_start(hr_dev->pci_dev, 2)) >> PAGE_SHIFT);\n\tif (hr_dev->caps.flags & HNS_ROCE_CAP_FLAG_DIRECT_WQE)\n\t\thr_dev->dwqe_page = pci_resource_start(hr_dev->pci_dev, 4);\n\n\treturn 0;\n}\n\nvoid hns_roce_init_uar_table(struct hns_roce_dev *hr_dev)\n{\n\tstruct hns_roce_ida *uar_ida = &hr_dev->uar_ida;\n\n\tida_init(&uar_ida->ida);\n\tuar_ida->max = hr_dev->caps.num_uars - 1;\n\tuar_ida->min = hr_dev->caps.reserved_uars;\n}\n\nstatic int hns_roce_xrcd_alloc(struct hns_roce_dev *hr_dev, u32 *xrcdn)\n{\n\tstruct hns_roce_ida *xrcd_ida = &hr_dev->xrcd_ida;\n\tint id;\n\n\tid = ida_alloc_range(&xrcd_ida->ida, xrcd_ida->min, xrcd_ida->max,\n\t\t\t     GFP_KERNEL);\n\tif (id < 0) {\n\t\tibdev_err(&hr_dev->ib_dev, \"failed to alloc xrcdn(%d).\\n\", id);\n\t\treturn -ENOMEM;\n\t}\n\t*xrcdn = (u32)id;\n\n\treturn 0;\n}\n\nvoid hns_roce_init_xrcd_table(struct hns_roce_dev *hr_dev)\n{\n\tstruct hns_roce_ida *xrcd_ida = &hr_dev->xrcd_ida;\n\n\tida_init(&xrcd_ida->ida);\n\txrcd_ida->max = hr_dev->caps.num_xrcds - 1;\n\txrcd_ida->min = hr_dev->caps.reserved_xrcds;\n}\n\nint hns_roce_alloc_xrcd(struct ib_xrcd *ib_xrcd, struct ib_udata *udata)\n{\n\tstruct hns_roce_dev *hr_dev = to_hr_dev(ib_xrcd->device);\n\tstruct hns_roce_xrcd *xrcd = to_hr_xrcd(ib_xrcd);\n\tint ret;\n\n\tif (!(hr_dev->caps.flags & HNS_ROCE_CAP_FLAG_XRC))\n\t\treturn -EOPNOTSUPP;\n\n\tret = hns_roce_xrcd_alloc(hr_dev, &xrcd->xrcdn);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nint hns_roce_dealloc_xrcd(struct ib_xrcd *ib_xrcd, struct ib_udata *udata)\n{\n\tstruct hns_roce_dev *hr_dev = to_hr_dev(ib_xrcd->device);\n\tu32 xrcdn = to_hr_xrcd(ib_xrcd)->xrcdn;\n\n\tida_free(&hr_dev->xrcd_ida.ida, (int)xrcdn);\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}