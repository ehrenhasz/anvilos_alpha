{
  "module_name": "driver.c",
  "hash_id": "c154cd93667055525da5c4c6ae8c0d4f37a219f2583e7786f25669de913c394e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/hfi1/driver.c",
  "human_readable_source": "\n \n\n#include <linux/spinlock.h>\n#include <linux/pci.h>\n#include <linux/io.h>\n#include <linux/delay.h>\n#include <linux/netdevice.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/prefetch.h>\n#include <rdma/ib_verbs.h>\n#include <linux/etherdevice.h>\n\n#include \"hfi.h\"\n#include \"trace.h\"\n#include \"qp.h\"\n#include \"sdma.h\"\n#include \"debugfs.h\"\n#include \"vnic.h\"\n#include \"fault.h\"\n\n#include \"ipoib.h\"\n#include \"netdev.h\"\n\n#undef pr_fmt\n#define pr_fmt(fmt) DRIVER_NAME \": \" fmt\n\nDEFINE_MUTEX(hfi1_mutex);\t \n\nunsigned int hfi1_max_mtu = HFI1_DEFAULT_MAX_MTU;\nmodule_param_named(max_mtu, hfi1_max_mtu, uint, S_IRUGO);\nMODULE_PARM_DESC(max_mtu, \"Set max MTU bytes, default is \" __stringify(\n\t\t HFI1_DEFAULT_MAX_MTU));\n\nunsigned int hfi1_cu = 1;\nmodule_param_named(cu, hfi1_cu, uint, S_IRUGO);\nMODULE_PARM_DESC(cu, \"Credit return units\");\n\nunsigned long hfi1_cap_mask = HFI1_CAP_MASK_DEFAULT;\nstatic int hfi1_caps_set(const char *val, const struct kernel_param *kp);\nstatic int hfi1_caps_get(char *buffer, const struct kernel_param *kp);\nstatic const struct kernel_param_ops cap_ops = {\n\t.set = hfi1_caps_set,\n\t.get = hfi1_caps_get\n};\nmodule_param_cb(cap_mask, &cap_ops, &hfi1_cap_mask, S_IWUSR | S_IRUGO);\nMODULE_PARM_DESC(cap_mask, \"Bit mask of enabled/disabled HW features\");\n\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_DESCRIPTION(\"Cornelis Omni-Path Express driver\");\n\n \n#define MAX_PKT_RECV 64\n \n#define MAX_PKT_RECV_THREAD (MAX_PKT_RECV * 4)\n#define EGR_HEAD_UPDATE_THRESHOLD 16\n\nstruct hfi1_ib_stats hfi1_stats;\n\nstatic int hfi1_caps_set(const char *val, const struct kernel_param *kp)\n{\n\tint ret = 0;\n\tunsigned long *cap_mask_ptr = (unsigned long *)kp->arg,\n\t\tcap_mask = *cap_mask_ptr, value, diff,\n\t\twrite_mask = ((HFI1_CAP_WRITABLE_MASK << HFI1_CAP_USER_SHIFT) |\n\t\t\t      HFI1_CAP_WRITABLE_MASK);\n\n\tret = kstrtoul(val, 0, &value);\n\tif (ret) {\n\t\tpr_warn(\"Invalid module parameter value for 'cap_mask'\\n\");\n\t\tgoto done;\n\t}\n\t \n\tdiff = value ^ (cap_mask & ~HFI1_CAP_LOCKED_SMASK);\n\n\t \n\tif (HFI1_CAP_LOCKED() && (diff & ~write_mask)) {\n\t\tpr_warn(\"Ignoring non-writable capability bits %#lx\\n\",\n\t\t\tdiff & ~write_mask);\n\t\tdiff &= write_mask;\n\t}\n\n\t \n\tdiff &= ~HFI1_CAP_RESERVED_MASK;\n\t \n\tcap_mask &= ~diff;\n\t \n\tcap_mask |= (value & diff);\n\t \n\tdiff = (cap_mask & (HFI1_CAP_MUST_HAVE_KERN << HFI1_CAP_USER_SHIFT)) ^\n\t\t((cap_mask & HFI1_CAP_MUST_HAVE_KERN) << HFI1_CAP_USER_SHIFT);\n\tcap_mask &= ~diff;\n\t \n\t*cap_mask_ptr = cap_mask;\ndone:\n\treturn ret;\n}\n\nstatic int hfi1_caps_get(char *buffer, const struct kernel_param *kp)\n{\n\tunsigned long cap_mask = *(unsigned long *)kp->arg;\n\n\tcap_mask &= ~HFI1_CAP_LOCKED_SMASK;\n\tcap_mask |= ((cap_mask & HFI1_CAP_K2U) << HFI1_CAP_USER_SHIFT);\n\n\treturn sysfs_emit(buffer, \"0x%lx\\n\", cap_mask);\n}\n\nstruct pci_dev *get_pci_dev(struct rvt_dev_info *rdi)\n{\n\tstruct hfi1_ibdev *ibdev = container_of(rdi, struct hfi1_ibdev, rdi);\n\tstruct hfi1_devdata *dd = container_of(ibdev,\n\t\t\t\t\t       struct hfi1_devdata, verbs_dev);\n\treturn dd->pcidev;\n}\n\n \nint hfi1_count_active_units(void)\n{\n\tstruct hfi1_devdata *dd;\n\tstruct hfi1_pportdata *ppd;\n\tunsigned long index, flags;\n\tint pidx, nunits_active = 0;\n\n\txa_lock_irqsave(&hfi1_dev_table, flags);\n\txa_for_each(&hfi1_dev_table, index, dd) {\n\t\tif (!(dd->flags & HFI1_PRESENT) || !dd->kregbase1)\n\t\t\tcontinue;\n\t\tfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\n\t\t\tppd = dd->pport + pidx;\n\t\t\tif (ppd->lid && ppd->linkup) {\n\t\t\t\tnunits_active++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\txa_unlock_irqrestore(&hfi1_dev_table, flags);\n\treturn nunits_active;\n}\n\n \nstatic inline void *get_egrbuf(const struct hfi1_ctxtdata *rcd, u64 rhf,\n\t\t\t       u8 *update)\n{\n\tu32 idx = rhf_egr_index(rhf), offset = rhf_egr_buf_offset(rhf);\n\n\t*update |= !(idx & (rcd->egrbufs.threshold - 1)) && !offset;\n\treturn (void *)(((u64)(rcd->egrbufs.rcvtids[idx].addr)) +\n\t\t\t(offset * RCV_BUF_BLOCK_SIZE));\n}\n\nstatic inline void *hfi1_get_header(struct hfi1_ctxtdata *rcd,\n\t\t\t\t    __le32 *rhf_addr)\n{\n\tu32 offset = rhf_hdrq_offset(rhf_to_cpu(rhf_addr));\n\n\treturn (void *)(rhf_addr - rcd->rhf_offset + offset);\n}\n\nstatic inline struct ib_header *hfi1_get_msgheader(struct hfi1_ctxtdata *rcd,\n\t\t\t\t\t\t   __le32 *rhf_addr)\n{\n\treturn (struct ib_header *)hfi1_get_header(rcd, rhf_addr);\n}\n\nstatic inline struct hfi1_16b_header\n\t\t*hfi1_get_16B_header(struct hfi1_ctxtdata *rcd,\n\t\t\t\t     __le32 *rhf_addr)\n{\n\treturn (struct hfi1_16b_header *)hfi1_get_header(rcd, rhf_addr);\n}\n\n \nint hfi1_rcvbuf_validate(u32 size, u8 type, u16 *encoded)\n{\n\tif (unlikely(!PAGE_ALIGNED(size)))\n\t\treturn 0;\n\tif (unlikely(size < MIN_EAGER_BUFFER))\n\t\treturn 0;\n\tif (size >\n\t    (type == PT_EAGER ? MAX_EAGER_BUFFER : MAX_EXPECTED_BUFFER))\n\t\treturn 0;\n\tif (encoded)\n\t\t*encoded = ilog2(size / PAGE_SIZE) + 1;\n\treturn 1;\n}\n\nstatic void rcv_hdrerr(struct hfi1_ctxtdata *rcd, struct hfi1_pportdata *ppd,\n\t\t       struct hfi1_packet *packet)\n{\n\tstruct ib_header *rhdr = packet->hdr;\n\tu32 rte = rhf_rcv_type_err(packet->rhf);\n\tu32 mlid_base;\n\tstruct hfi1_ibport *ibp = rcd_to_iport(rcd);\n\tstruct hfi1_devdata *dd = ppd->dd;\n\tstruct hfi1_ibdev *verbs_dev = &dd->verbs_dev;\n\tstruct rvt_dev_info *rdi = &verbs_dev->rdi;\n\n\tif ((packet->rhf & RHF_DC_ERR) &&\n\t    hfi1_dbg_fault_suppress_err(verbs_dev))\n\t\treturn;\n\n\tif (packet->rhf & RHF_ICRC_ERR)\n\t\treturn;\n\n\tif (packet->etype == RHF_RCV_TYPE_BYPASS) {\n\t\tgoto drop;\n\t} else {\n\t\tu8 lnh = ib_get_lnh(rhdr);\n\n\t\tmlid_base = be16_to_cpu(IB_MULTICAST_LID_BASE);\n\t\tif (lnh == HFI1_LRH_BTH) {\n\t\t\tpacket->ohdr = &rhdr->u.oth;\n\t\t} else if (lnh == HFI1_LRH_GRH) {\n\t\t\tpacket->ohdr = &rhdr->u.l.oth;\n\t\t\tpacket->grh = &rhdr->u.l.grh;\n\t\t} else {\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\tif (packet->rhf & RHF_TID_ERR) {\n\t\t \n\t\tu32 tlen = rhf_pkt_len(packet->rhf);  \n\t\tu32 dlid = ib_get_dlid(rhdr);\n\t\tu32 qp_num;\n\n\t\t \n\t\tif (tlen < 24)\n\t\t\tgoto drop;\n\n\t\t \n\t\tif (packet->grh) {\n\t\t\tu32 vtf;\n\t\t\tstruct ib_grh *grh = packet->grh;\n\n\t\t\tif (grh->next_hdr != IB_GRH_NEXT_HDR)\n\t\t\t\tgoto drop;\n\t\t\tvtf = be32_to_cpu(grh->version_tclass_flow);\n\t\t\tif ((vtf >> IB_GRH_VERSION_SHIFT) != IB_GRH_VERSION)\n\t\t\t\tgoto drop;\n\t\t}\n\n\t\t \n\t\tqp_num = ib_bth_get_qpn(packet->ohdr);\n\t\tif (dlid < mlid_base) {\n\t\t\tstruct rvt_qp *qp;\n\t\t\tunsigned long flags;\n\n\t\t\trcu_read_lock();\n\t\t\tqp = rvt_lookup_qpn(rdi, &ibp->rvp, qp_num);\n\t\t\tif (!qp) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\tgoto drop;\n\t\t\t}\n\n\t\t\t \n\t\t\tspin_lock_irqsave(&qp->r_lock, flags);\n\n\t\t\t \n\t\t\tif (!(ib_rvt_state_ops[qp->state] &\n\t\t\t      RVT_PROCESS_RECV_OK)) {\n\t\t\t\tibp->rvp.n_pkt_drops++;\n\t\t\t}\n\n\t\t\tswitch (qp->ibqp.qp_type) {\n\t\t\tcase IB_QPT_RC:\n\t\t\t\thfi1_rc_hdrerr(rcd, packet, qp);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tspin_unlock_irqrestore(&qp->r_lock, flags);\n\t\t\trcu_read_unlock();\n\t\t}  \n\t}  \n\n\t \n\tswitch (rte) {\n\tcase RHF_RTE_ERROR_OP_CODE_ERR:\n\t{\n\t\tvoid *ebuf = NULL;\n\t\tu8 opcode;\n\n\t\tif (rhf_use_egr_bfr(packet->rhf))\n\t\t\tebuf = packet->ebuf;\n\n\t\tif (!ebuf)\n\t\t\tgoto drop;  \n\n\t\topcode = ib_bth_get_opcode(packet->ohdr);\n\t\tif (opcode == IB_OPCODE_CNP) {\n\t\t\t \n\t\t\tstruct rvt_qp *qp = NULL;\n\t\t\tu32 lqpn, rqpn;\n\t\t\tu16 rlid;\n\t\t\tu8 svc_type, sl, sc5;\n\n\t\t\tsc5 = hfi1_9B_get_sc5(rhdr, packet->rhf);\n\t\t\tsl = ibp->sc_to_sl[sc5];\n\n\t\t\tlqpn = ib_bth_get_qpn(packet->ohdr);\n\t\t\trcu_read_lock();\n\t\t\tqp = rvt_lookup_qpn(rdi, &ibp->rvp, lqpn);\n\t\t\tif (!qp) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\tgoto drop;\n\t\t\t}\n\n\t\t\tswitch (qp->ibqp.qp_type) {\n\t\t\tcase IB_QPT_UD:\n\t\t\t\trlid = 0;\n\t\t\t\trqpn = 0;\n\t\t\t\tsvc_type = IB_CC_SVCTYPE_UD;\n\t\t\t\tbreak;\n\t\t\tcase IB_QPT_UC:\n\t\t\t\trlid = ib_get_slid(rhdr);\n\t\t\t\trqpn = qp->remote_qpn;\n\t\t\t\tsvc_type = IB_CC_SVCTYPE_UC;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\trcu_read_unlock();\n\t\t\t\tgoto drop;\n\t\t\t}\n\n\t\t\tprocess_becn(ppd, sl, rlid, lqpn, rqpn, svc_type);\n\t\t\trcu_read_unlock();\n\t\t}\n\n\t\tpacket->rhf &= ~RHF_RCV_TYPE_ERR_SMASK;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\ndrop:\n\treturn;\n}\n\nstatic inline void init_packet(struct hfi1_ctxtdata *rcd,\n\t\t\t       struct hfi1_packet *packet)\n{\n\tpacket->rsize = get_hdrqentsize(rcd);  \n\tpacket->maxcnt = get_hdrq_cnt(rcd) * packet->rsize;  \n\tpacket->rcd = rcd;\n\tpacket->updegr = 0;\n\tpacket->etail = -1;\n\tpacket->rhf_addr = get_rhf_addr(rcd);\n\tpacket->rhf = rhf_to_cpu(packet->rhf_addr);\n\tpacket->rhqoff = hfi1_rcd_head(rcd);\n\tpacket->numpkt = 0;\n}\n\n \nstatic const hfi1_handle_cnp hfi1_handle_cnp_tbl[2] = {\n\t[HFI1_PKT_TYPE_9B] = &return_cnp,\n\t[HFI1_PKT_TYPE_16B] = &return_cnp_16B\n};\n\n \nbool hfi1_process_ecn_slowpath(struct rvt_qp *qp, struct hfi1_packet *pkt,\n\t\t\t       bool prescan)\n{\n\tstruct hfi1_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tstruct ib_other_headers *ohdr = pkt->ohdr;\n\tstruct ib_grh *grh = pkt->grh;\n\tu32 rqpn = 0;\n\tu16 pkey;\n\tu32 rlid, slid, dlid = 0;\n\tu8 hdr_type, sc, svc_type, opcode;\n\tbool is_mcast = false, ignore_fecn = false, do_cnp = false,\n\t\tfecn, becn;\n\n\t \n\tif (pkt->etype == RHF_RCV_TYPE_BYPASS) {\n\t\tpkey = hfi1_16B_get_pkey(pkt->hdr);\n\t\tsc = hfi1_16B_get_sc(pkt->hdr);\n\t\tdlid = hfi1_16B_get_dlid(pkt->hdr);\n\t\tslid = hfi1_16B_get_slid(pkt->hdr);\n\t\tis_mcast = hfi1_is_16B_mcast(dlid);\n\t\topcode = ib_bth_get_opcode(ohdr);\n\t\thdr_type = HFI1_PKT_TYPE_16B;\n\t\tfecn = hfi1_16B_get_fecn(pkt->hdr);\n\t\tbecn = hfi1_16B_get_becn(pkt->hdr);\n\t} else {\n\t\tpkey = ib_bth_get_pkey(ohdr);\n\t\tsc = hfi1_9B_get_sc5(pkt->hdr, pkt->rhf);\n\t\tdlid = qp->ibqp.qp_type != IB_QPT_UD ? ib_get_dlid(pkt->hdr) :\n\t\t\tppd->lid;\n\t\tslid = ib_get_slid(pkt->hdr);\n\t\tis_mcast = (dlid > be16_to_cpu(IB_MULTICAST_LID_BASE)) &&\n\t\t\t   (dlid != be16_to_cpu(IB_LID_PERMISSIVE));\n\t\topcode = ib_bth_get_opcode(ohdr);\n\t\thdr_type = HFI1_PKT_TYPE_9B;\n\t\tfecn = ib_bth_get_fecn(ohdr);\n\t\tbecn = ib_bth_get_becn(ohdr);\n\t}\n\n\tswitch (qp->ibqp.qp_type) {\n\tcase IB_QPT_UD:\n\t\trlid = slid;\n\t\trqpn = ib_get_sqpn(pkt->ohdr);\n\t\tsvc_type = IB_CC_SVCTYPE_UD;\n\t\tbreak;\n\tcase IB_QPT_SMI:\n\tcase IB_QPT_GSI:\n\t\trlid = slid;\n\t\trqpn = ib_get_sqpn(pkt->ohdr);\n\t\tsvc_type = IB_CC_SVCTYPE_UD;\n\t\tbreak;\n\tcase IB_QPT_UC:\n\t\trlid = rdma_ah_get_dlid(&qp->remote_ah_attr);\n\t\trqpn = qp->remote_qpn;\n\t\tsvc_type = IB_CC_SVCTYPE_UC;\n\t\tbreak;\n\tcase IB_QPT_RC:\n\t\trlid = rdma_ah_get_dlid(&qp->remote_ah_attr);\n\t\trqpn = qp->remote_qpn;\n\t\tsvc_type = IB_CC_SVCTYPE_RC;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\tignore_fecn = is_mcast || (opcode == IB_OPCODE_CNP) ||\n\t\t(opcode == IB_OPCODE_RC_ACKNOWLEDGE);\n\t \n\tdo_cnp = prescan ||\n\t\t(opcode >= IB_OPCODE_RC_RDMA_READ_RESPONSE_FIRST &&\n\t\t opcode <= IB_OPCODE_RC_ATOMIC_ACKNOWLEDGE) ||\n\t\topcode == TID_OP(READ_RESP) ||\n\t\topcode == TID_OP(ACK);\n\n\t \n\tif (!ignore_fecn && do_cnp && fecn)\n\t\thfi1_handle_cnp_tbl[hdr_type](ibp, qp, rqpn, pkey,\n\t\t\t\t\t      dlid, rlid, sc, grh);\n\n\tif (becn) {\n\t\tu32 lqpn = be32_to_cpu(ohdr->bth[1]) & RVT_QPN_MASK;\n\t\tu8 sl = ibp->sc_to_sl[sc];\n\n\t\tprocess_becn(ppd, sl, rlid, lqpn, rqpn, svc_type);\n\t}\n\treturn !ignore_fecn && fecn;\n}\n\nstruct ps_mdata {\n\tstruct hfi1_ctxtdata *rcd;\n\tu32 rsize;\n\tu32 maxcnt;\n\tu32 ps_head;\n\tu32 ps_tail;\n\tu32 ps_seq;\n};\n\nstatic inline void init_ps_mdata(struct ps_mdata *mdata,\n\t\t\t\t struct hfi1_packet *packet)\n{\n\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\n\tmdata->rcd = rcd;\n\tmdata->rsize = packet->rsize;\n\tmdata->maxcnt = packet->maxcnt;\n\tmdata->ps_head = packet->rhqoff;\n\n\tif (get_dma_rtail_setting(rcd)) {\n\t\tmdata->ps_tail = get_rcvhdrtail(rcd);\n\t\tif (rcd->ctxt == HFI1_CTRL_CTXT)\n\t\t\tmdata->ps_seq = hfi1_seq_cnt(rcd);\n\t\telse\n\t\t\tmdata->ps_seq = 0;  \n\t} else {\n\t\tmdata->ps_tail = 0;  \n\t\tmdata->ps_seq = hfi1_seq_cnt(rcd);\n\t}\n}\n\nstatic inline int ps_done(struct ps_mdata *mdata, u64 rhf,\n\t\t\t  struct hfi1_ctxtdata *rcd)\n{\n\tif (get_dma_rtail_setting(rcd))\n\t\treturn mdata->ps_head == mdata->ps_tail;\n\treturn mdata->ps_seq != rhf_rcv_seq(rhf);\n}\n\nstatic inline int ps_skip(struct ps_mdata *mdata, u64 rhf,\n\t\t\t  struct hfi1_ctxtdata *rcd)\n{\n\t \n\tif ((rcd->ctxt == HFI1_CTRL_CTXT) && (mdata->ps_head != mdata->ps_tail))\n\t\treturn mdata->ps_seq != rhf_rcv_seq(rhf);\n\n\treturn 0;\n}\n\nstatic inline void update_ps_mdata(struct ps_mdata *mdata,\n\t\t\t\t   struct hfi1_ctxtdata *rcd)\n{\n\tmdata->ps_head += mdata->rsize;\n\tif (mdata->ps_head >= mdata->maxcnt)\n\t\tmdata->ps_head = 0;\n\n\t \n\tif (!get_dma_rtail_setting(rcd) ||\n\t    rcd->ctxt == HFI1_CTRL_CTXT)\n\t\tmdata->ps_seq = hfi1_seq_incr_wrap(mdata->ps_seq);\n}\n\n \n#define prescan_rxq(rcd, packet) \\\n\tdo { \\\n\t\tif (rcd->ppd->cc_prescan) \\\n\t\t\t__prescan_rxq(packet); \\\n\t} while (0)\nstatic void __prescan_rxq(struct hfi1_packet *packet)\n{\n\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\tstruct ps_mdata mdata;\n\n\tinit_ps_mdata(&mdata, packet);\n\n\twhile (1) {\n\t\tstruct hfi1_ibport *ibp = rcd_to_iport(rcd);\n\t\t__le32 *rhf_addr = (__le32 *)rcd->rcvhdrq + mdata.ps_head +\n\t\t\t\t\t packet->rcd->rhf_offset;\n\t\tstruct rvt_qp *qp;\n\t\tstruct ib_header *hdr;\n\t\tstruct rvt_dev_info *rdi = &rcd->dd->verbs_dev.rdi;\n\t\tu64 rhf = rhf_to_cpu(rhf_addr);\n\t\tu32 etype = rhf_rcv_type(rhf), qpn, bth1;\n\t\tu8 lnh;\n\n\t\tif (ps_done(&mdata, rhf, rcd))\n\t\t\tbreak;\n\n\t\tif (ps_skip(&mdata, rhf, rcd))\n\t\t\tgoto next;\n\n\t\tif (etype != RHF_RCV_TYPE_IB)\n\t\t\tgoto next;\n\n\t\tpacket->hdr = hfi1_get_msgheader(packet->rcd, rhf_addr);\n\t\thdr = packet->hdr;\n\t\tlnh = ib_get_lnh(hdr);\n\n\t\tif (lnh == HFI1_LRH_BTH) {\n\t\t\tpacket->ohdr = &hdr->u.oth;\n\t\t\tpacket->grh = NULL;\n\t\t} else if (lnh == HFI1_LRH_GRH) {\n\t\t\tpacket->ohdr = &hdr->u.l.oth;\n\t\t\tpacket->grh = &hdr->u.l.grh;\n\t\t} else {\n\t\t\tgoto next;  \n\t\t}\n\n\t\tif (!hfi1_may_ecn(packet))\n\t\t\tgoto next;\n\n\t\tbth1 = be32_to_cpu(packet->ohdr->bth[1]);\n\t\tqpn = bth1 & RVT_QPN_MASK;\n\t\trcu_read_lock();\n\t\tqp = rvt_lookup_qpn(rdi, &ibp->rvp, qpn);\n\n\t\tif (!qp) {\n\t\t\trcu_read_unlock();\n\t\t\tgoto next;\n\t\t}\n\n\t\thfi1_process_ecn_slowpath(qp, packet, true);\n\t\trcu_read_unlock();\n\n\t\t \n\t\tbth1 &= ~(IB_FECN_SMASK | IB_BECN_SMASK);\n\t\tpacket->ohdr->bth[1] = cpu_to_be32(bth1);\nnext:\n\t\tupdate_ps_mdata(&mdata, rcd);\n\t}\n}\n\nstatic void process_rcv_qp_work(struct hfi1_packet *packet)\n{\n\tstruct rvt_qp *qp, *nqp;\n\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\n\t \n\tlist_for_each_entry_safe(qp, nqp, &rcd->qp_wait_list, rspwait) {\n\t\tlist_del_init(&qp->rspwait);\n\t\tif (qp->r_flags & RVT_R_RSP_NAK) {\n\t\t\tqp->r_flags &= ~RVT_R_RSP_NAK;\n\t\t\tpacket->qp = qp;\n\t\t\thfi1_send_rc_ack(packet, 0);\n\t\t}\n\t\tif (qp->r_flags & RVT_R_RSP_SEND) {\n\t\t\tunsigned long flags;\n\n\t\t\tqp->r_flags &= ~RVT_R_RSP_SEND;\n\t\t\tspin_lock_irqsave(&qp->s_lock, flags);\n\t\t\tif (ib_rvt_state_ops[qp->state] &\n\t\t\t\t\tRVT_PROCESS_OR_FLUSH_SEND)\n\t\t\t\thfi1_schedule_send(qp);\n\t\t\tspin_unlock_irqrestore(&qp->s_lock, flags);\n\t\t}\n\t\trvt_put_qp(qp);\n\t}\n}\n\nstatic noinline int max_packet_exceeded(struct hfi1_packet *packet, int thread)\n{\n\tif (thread) {\n\t\tif ((packet->numpkt & (MAX_PKT_RECV_THREAD - 1)) == 0)\n\t\t\t \n\t\t\tprocess_rcv_qp_work(packet);\n\t\tcond_resched();\n\t\treturn RCV_PKT_OK;\n\t} else {\n\t\tthis_cpu_inc(*packet->rcd->dd->rcv_limit);\n\t\treturn RCV_PKT_LIMIT;\n\t}\n}\n\nstatic inline int check_max_packet(struct hfi1_packet *packet, int thread)\n{\n\tint ret = RCV_PKT_OK;\n\n\tif (unlikely((packet->numpkt & (MAX_PKT_RECV - 1)) == 0))\n\t\tret = max_packet_exceeded(packet, thread);\n\treturn ret;\n}\n\nstatic noinline int skip_rcv_packet(struct hfi1_packet *packet, int thread)\n{\n\tint ret;\n\n\tpacket->rcd->dd->ctx0_seq_drop++;\n\t \n\tpacket->rhqoff += packet->rsize;\n\tif (packet->rhqoff >= packet->maxcnt)\n\t\tpacket->rhqoff = 0;\n\n\tpacket->numpkt++;\n\tret = check_max_packet(packet, thread);\n\n\tpacket->rhf_addr = (__le32 *)packet->rcd->rcvhdrq + packet->rhqoff +\n\t\t\t\t     packet->rcd->rhf_offset;\n\tpacket->rhf = rhf_to_cpu(packet->rhf_addr);\n\n\treturn ret;\n}\n\nstatic void process_rcv_packet_napi(struct hfi1_packet *packet)\n{\n\tpacket->etype = rhf_rcv_type(packet->rhf);\n\n\t \n\tpacket->tlen = rhf_pkt_len(packet->rhf);  \n\t \n\tpacket->etail = rhf_egr_index(packet->rhf);\n\tpacket->ebuf = get_egrbuf(packet->rcd, packet->rhf,\n\t\t\t\t  &packet->updegr);\n\t \n\tprefetch_range(packet->ebuf,\n\t\t       packet->tlen - ((packet->rcd->rcvhdrqentsize -\n\t\t\t\t       (rhf_hdrq_offset(packet->rhf)\n\t\t\t\t\t+ 2)) * 4));\n\n\tpacket->rcd->rhf_rcv_function_map[packet->etype](packet);\n\tpacket->numpkt++;\n\n\t \n\tpacket->rhqoff += packet->rsize;\n\tif (packet->rhqoff >= packet->maxcnt)\n\t\tpacket->rhqoff = 0;\n\n\tpacket->rhf_addr = (__le32 *)packet->rcd->rcvhdrq + packet->rhqoff +\n\t\t\t\t      packet->rcd->rhf_offset;\n\tpacket->rhf = rhf_to_cpu(packet->rhf_addr);\n}\n\nstatic inline int process_rcv_packet(struct hfi1_packet *packet, int thread)\n{\n\tint ret;\n\n\tpacket->etype = rhf_rcv_type(packet->rhf);\n\n\t \n\tpacket->tlen = rhf_pkt_len(packet->rhf);  \n\t \n\tpacket->ebuf = NULL;\n\tif (rhf_use_egr_bfr(packet->rhf)) {\n\t\tpacket->etail = rhf_egr_index(packet->rhf);\n\t\tpacket->ebuf = get_egrbuf(packet->rcd, packet->rhf,\n\t\t\t\t &packet->updegr);\n\t\t \n\t\tprefetch_range(packet->ebuf,\n\t\t\t       packet->tlen - ((get_hdrqentsize(packet->rcd) -\n\t\t\t\t\t       (rhf_hdrq_offset(packet->rhf)\n\t\t\t\t\t\t+ 2)) * 4));\n\t}\n\n\t \n\tpacket->rcd->rhf_rcv_function_map[packet->etype](packet);\n\tpacket->numpkt++;\n\n\t \n\tpacket->rhqoff += packet->rsize;\n\tif (packet->rhqoff >= packet->maxcnt)\n\t\tpacket->rhqoff = 0;\n\n\tret = check_max_packet(packet, thread);\n\n\tpacket->rhf_addr = (__le32 *)packet->rcd->rcvhdrq + packet->rhqoff +\n\t\t\t\t      packet->rcd->rhf_offset;\n\tpacket->rhf = rhf_to_cpu(packet->rhf_addr);\n\n\treturn ret;\n}\n\nstatic inline void process_rcv_update(int last, struct hfi1_packet *packet)\n{\n\t \n\tif (!last && !(packet->numpkt & 0xf)) {\n\t\tupdate_usrhead(packet->rcd, packet->rhqoff, packet->updegr,\n\t\t\t       packet->etail, 0, 0);\n\t\tpacket->updegr = 0;\n\t}\n\tpacket->grh = NULL;\n}\n\nstatic inline void finish_packet(struct hfi1_packet *packet)\n{\n\t \n\tupdate_usrhead(packet->rcd, hfi1_rcd_head(packet->rcd), packet->updegr,\n\t\t       packet->etail, rcv_intr_dynamic, packet->numpkt);\n}\n\n \nint handle_receive_interrupt_napi_fp(struct hfi1_ctxtdata *rcd, int budget)\n{\n\tstruct hfi1_packet packet;\n\n\tinit_packet(rcd, &packet);\n\tif (last_rcv_seq(rcd, rhf_rcv_seq(packet.rhf)))\n\t\tgoto bail;\n\n\twhile (packet.numpkt < budget) {\n\t\tprocess_rcv_packet_napi(&packet);\n\t\tif (hfi1_seq_incr(rcd, rhf_rcv_seq(packet.rhf)))\n\t\t\tbreak;\n\n\t\tprocess_rcv_update(0, &packet);\n\t}\n\thfi1_set_rcd_head(rcd, packet.rhqoff);\nbail:\n\tfinish_packet(&packet);\n\treturn packet.numpkt;\n}\n\n \nint handle_receive_interrupt_nodma_rtail(struct hfi1_ctxtdata *rcd, int thread)\n{\n\tint last = RCV_PKT_OK;\n\tstruct hfi1_packet packet;\n\n\tinit_packet(rcd, &packet);\n\tif (last_rcv_seq(rcd, rhf_rcv_seq(packet.rhf))) {\n\t\tlast = RCV_PKT_DONE;\n\t\tgoto bail;\n\t}\n\n\tprescan_rxq(rcd, &packet);\n\n\twhile (last == RCV_PKT_OK) {\n\t\tlast = process_rcv_packet(&packet, thread);\n\t\tif (hfi1_seq_incr(rcd, rhf_rcv_seq(packet.rhf)))\n\t\t\tlast = RCV_PKT_DONE;\n\t\tprocess_rcv_update(last, &packet);\n\t}\n\tprocess_rcv_qp_work(&packet);\n\thfi1_set_rcd_head(rcd, packet.rhqoff);\nbail:\n\tfinish_packet(&packet);\n\treturn last;\n}\n\nint handle_receive_interrupt_dma_rtail(struct hfi1_ctxtdata *rcd, int thread)\n{\n\tu32 hdrqtail;\n\tint last = RCV_PKT_OK;\n\tstruct hfi1_packet packet;\n\n\tinit_packet(rcd, &packet);\n\thdrqtail = get_rcvhdrtail(rcd);\n\tif (packet.rhqoff == hdrqtail) {\n\t\tlast = RCV_PKT_DONE;\n\t\tgoto bail;\n\t}\n\tsmp_rmb();   \n\n\tprescan_rxq(rcd, &packet);\n\n\twhile (last == RCV_PKT_OK) {\n\t\tlast = process_rcv_packet(&packet, thread);\n\t\tif (packet.rhqoff == hdrqtail)\n\t\t\tlast = RCV_PKT_DONE;\n\t\tprocess_rcv_update(last, &packet);\n\t}\n\tprocess_rcv_qp_work(&packet);\n\thfi1_set_rcd_head(rcd, packet.rhqoff);\nbail:\n\tfinish_packet(&packet);\n\treturn last;\n}\n\nstatic void set_all_fastpath(struct hfi1_devdata *dd, struct hfi1_ctxtdata *rcd)\n{\n\tu16 i;\n\n\t \n\tif (rcd->ctxt >= dd->first_dyn_alloc_ctxt && !rcd->is_vnic) {\n\t\thfi1_rcd_get(rcd);\n\t\thfi1_set_fast(rcd);\n\t\thfi1_rcd_put(rcd);\n\t\treturn;\n\t}\n\n\tfor (i = HFI1_CTRL_CTXT + 1; i < dd->num_rcv_contexts; i++) {\n\t\trcd = hfi1_rcd_get_by_index(dd, i);\n\t\tif (rcd && (i < dd->first_dyn_alloc_ctxt || rcd->is_vnic))\n\t\t\thfi1_set_fast(rcd);\n\t\thfi1_rcd_put(rcd);\n\t}\n}\n\nvoid set_all_slowpath(struct hfi1_devdata *dd)\n{\n\tstruct hfi1_ctxtdata *rcd;\n\tu16 i;\n\n\t \n\tfor (i = HFI1_CTRL_CTXT + 1; i < dd->num_rcv_contexts; i++) {\n\t\trcd = hfi1_rcd_get_by_index(dd, i);\n\t\tif (!rcd)\n\t\t\tcontinue;\n\t\tif (i < dd->first_dyn_alloc_ctxt || rcd->is_vnic)\n\t\t\trcd->do_interrupt = rcd->slow_handler;\n\n\t\thfi1_rcd_put(rcd);\n\t}\n}\n\nstatic bool __set_armed_to_active(struct hfi1_packet *packet)\n{\n\tu8 etype = rhf_rcv_type(packet->rhf);\n\tu8 sc = SC15_PACKET;\n\n\tif (etype == RHF_RCV_TYPE_IB) {\n\t\tstruct ib_header *hdr = hfi1_get_msgheader(packet->rcd,\n\t\t\t\t\t\t\t   packet->rhf_addr);\n\t\tsc = hfi1_9B_get_sc5(hdr, packet->rhf);\n\t} else if (etype == RHF_RCV_TYPE_BYPASS) {\n\t\tstruct hfi1_16b_header *hdr = hfi1_get_16B_header(\n\t\t\t\t\t\tpacket->rcd,\n\t\t\t\t\t\tpacket->rhf_addr);\n\t\tsc = hfi1_16B_get_sc(hdr);\n\t}\n\tif (sc != SC15_PACKET) {\n\t\tint hwstate = driver_lstate(packet->rcd->ppd);\n\t\tstruct work_struct *lsaw =\n\t\t\t\t&packet->rcd->ppd->linkstate_active_work;\n\n\t\tif (hwstate != IB_PORT_ACTIVE) {\n\t\t\tdd_dev_info(packet->rcd->dd,\n\t\t\t\t    \"Unexpected link state %s\\n\",\n\t\t\t\t    opa_lstate_name(hwstate));\n\t\t\treturn false;\n\t\t}\n\n\t\tqueue_work(packet->rcd->ppd->link_wq, lsaw);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic bool set_armed_to_active(struct hfi1_packet *packet)\n{\n\tif (likely(packet->rcd->ppd->host_link_state != HLS_UP_ARMED))\n\t\treturn false;\n\treturn __set_armed_to_active(packet);\n}\n\n \nint handle_receive_interrupt(struct hfi1_ctxtdata *rcd, int thread)\n{\n\tstruct hfi1_devdata *dd = rcd->dd;\n\tu32 hdrqtail;\n\tint needset, last = RCV_PKT_OK;\n\tstruct hfi1_packet packet;\n\tint skip_pkt = 0;\n\n\tif (!rcd->rcvhdrq)\n\t\treturn RCV_PKT_OK;\n\t \n\tneedset = (rcd->ctxt == HFI1_CTRL_CTXT) ? 0 : 1;\n\n\tinit_packet(rcd, &packet);\n\n\tif (!get_dma_rtail_setting(rcd)) {\n\t\tif (last_rcv_seq(rcd, rhf_rcv_seq(packet.rhf))) {\n\t\t\tlast = RCV_PKT_DONE;\n\t\t\tgoto bail;\n\t\t}\n\t\thdrqtail = 0;\n\t} else {\n\t\thdrqtail = get_rcvhdrtail(rcd);\n\t\tif (packet.rhqoff == hdrqtail) {\n\t\t\tlast = RCV_PKT_DONE;\n\t\t\tgoto bail;\n\t\t}\n\t\tsmp_rmb();   \n\n\t\t \n\t\tif (rcd->ctxt == HFI1_CTRL_CTXT)\n\t\t\tif (last_rcv_seq(rcd, rhf_rcv_seq(packet.rhf)))\n\t\t\t\tskip_pkt = 1;\n\t}\n\n\tprescan_rxq(rcd, &packet);\n\n\twhile (last == RCV_PKT_OK) {\n\t\tif (hfi1_need_drop(dd)) {\n\t\t\t \n\t\t\tpacket.rhqoff += packet.rsize;\n\t\t\tpacket.rhf_addr = (__le32 *)rcd->rcvhdrq +\n\t\t\t\t\t  packet.rhqoff +\n\t\t\t\t\t  rcd->rhf_offset;\n\t\t\tpacket.rhf = rhf_to_cpu(packet.rhf_addr);\n\n\t\t} else if (skip_pkt) {\n\t\t\tlast = skip_rcv_packet(&packet, thread);\n\t\t\tskip_pkt = 0;\n\t\t} else {\n\t\t\tif (set_armed_to_active(&packet))\n\t\t\t\tgoto bail;\n\t\t\tlast = process_rcv_packet(&packet, thread);\n\t\t}\n\n\t\tif (!get_dma_rtail_setting(rcd)) {\n\t\t\tif (hfi1_seq_incr(rcd, rhf_rcv_seq(packet.rhf)))\n\t\t\t\tlast = RCV_PKT_DONE;\n\t\t} else {\n\t\t\tif (packet.rhqoff == hdrqtail)\n\t\t\t\tlast = RCV_PKT_DONE;\n\t\t\t \n\t\t\tif (rcd->ctxt == HFI1_CTRL_CTXT) {\n\t\t\t\tbool lseq;\n\n\t\t\t\tlseq = hfi1_seq_incr(rcd,\n\t\t\t\t\t\t     rhf_rcv_seq(packet.rhf));\n\t\t\t\tif (!last && lseq)\n\t\t\t\t\tskip_pkt = 1;\n\t\t\t}\n\t\t}\n\n\t\tif (needset) {\n\t\t\tneedset = false;\n\t\t\tset_all_fastpath(dd, rcd);\n\t\t}\n\t\tprocess_rcv_update(last, &packet);\n\t}\n\n\tprocess_rcv_qp_work(&packet);\n\thfi1_set_rcd_head(rcd, packet.rhqoff);\n\nbail:\n\t \n\tfinish_packet(&packet);\n\treturn last;\n}\n\n \nint handle_receive_interrupt_napi_sp(struct hfi1_ctxtdata *rcd, int budget)\n{\n\tstruct hfi1_devdata *dd = rcd->dd;\n\tint last = RCV_PKT_OK;\n\tbool needset = true;\n\tstruct hfi1_packet packet;\n\n\tinit_packet(rcd, &packet);\n\tif (last_rcv_seq(rcd, rhf_rcv_seq(packet.rhf)))\n\t\tgoto bail;\n\n\twhile (last != RCV_PKT_DONE && packet.numpkt < budget) {\n\t\tif (hfi1_need_drop(dd)) {\n\t\t\t \n\t\t\tpacket.rhqoff += packet.rsize;\n\t\t\tpacket.rhf_addr = (__le32 *)rcd->rcvhdrq +\n\t\t\t\t\t  packet.rhqoff +\n\t\t\t\t\t  rcd->rhf_offset;\n\t\t\tpacket.rhf = rhf_to_cpu(packet.rhf_addr);\n\n\t\t} else {\n\t\t\tif (set_armed_to_active(&packet))\n\t\t\t\tgoto bail;\n\t\t\tprocess_rcv_packet_napi(&packet);\n\t\t}\n\n\t\tif (hfi1_seq_incr(rcd, rhf_rcv_seq(packet.rhf)))\n\t\t\tlast = RCV_PKT_DONE;\n\n\t\tif (needset) {\n\t\t\tneedset = false;\n\t\t\tset_all_fastpath(dd, rcd);\n\t\t}\n\n\t\tprocess_rcv_update(last, &packet);\n\t}\n\n\thfi1_set_rcd_head(rcd, packet.rhqoff);\n\nbail:\n\t \n\tfinish_packet(&packet);\n\treturn packet.numpkt;\n}\n\n \nvoid receive_interrupt_work(struct work_struct *work)\n{\n\tstruct hfi1_pportdata *ppd = container_of(work, struct hfi1_pportdata,\n\t\t\t\t\t\t  linkstate_active_work);\n\tstruct hfi1_devdata *dd = ppd->dd;\n\tstruct hfi1_ctxtdata *rcd;\n\tu16 i;\n\n\t \n\tppd->neighbor_normal = 1;\n\tset_link_state(ppd, HLS_UP_ACTIVE);\n\n\t \n\tfor (i = HFI1_CTRL_CTXT; i < dd->first_dyn_alloc_ctxt; i++) {\n\t\trcd = hfi1_rcd_get_by_index(dd, i);\n\t\tif (rcd)\n\t\t\tforce_recv_intr(rcd);\n\t\thfi1_rcd_put(rcd);\n\t}\n}\n\n \nint mtu_to_enum(u32 mtu, int default_if_bad)\n{\n\tswitch (mtu) {\n\tcase     0: return OPA_MTU_0;\n\tcase   256: return OPA_MTU_256;\n\tcase   512: return OPA_MTU_512;\n\tcase  1024: return OPA_MTU_1024;\n\tcase  2048: return OPA_MTU_2048;\n\tcase  4096: return OPA_MTU_4096;\n\tcase  8192: return OPA_MTU_8192;\n\tcase 10240: return OPA_MTU_10240;\n\t}\n\treturn default_if_bad;\n}\n\nu16 enum_to_mtu(int mtu)\n{\n\tswitch (mtu) {\n\tcase OPA_MTU_0:     return 0;\n\tcase OPA_MTU_256:   return 256;\n\tcase OPA_MTU_512:   return 512;\n\tcase OPA_MTU_1024:  return 1024;\n\tcase OPA_MTU_2048:  return 2048;\n\tcase OPA_MTU_4096:  return 4096;\n\tcase OPA_MTU_8192:  return 8192;\n\tcase OPA_MTU_10240: return 10240;\n\tdefault: return 0xffff;\n\t}\n}\n\n \nint set_mtu(struct hfi1_pportdata *ppd)\n{\n\tstruct hfi1_devdata *dd = ppd->dd;\n\tint i, drain, ret = 0, is_up = 0;\n\n\tppd->ibmtu = 0;\n\tfor (i = 0; i < ppd->vls_supported; i++)\n\t\tif (ppd->ibmtu < dd->vld[i].mtu)\n\t\t\tppd->ibmtu = dd->vld[i].mtu;\n\tppd->ibmaxlen = ppd->ibmtu + lrh_max_header_bytes(ppd->dd);\n\n\tmutex_lock(&ppd->hls_lock);\n\tif (ppd->host_link_state == HLS_UP_INIT ||\n\t    ppd->host_link_state == HLS_UP_ARMED ||\n\t    ppd->host_link_state == HLS_UP_ACTIVE)\n\t\tis_up = 1;\n\n\tdrain = !is_ax(dd) && is_up;\n\n\tif (drain)\n\t\t \n\t\tret = stop_drain_data_vls(dd);\n\n\tif (ret) {\n\t\tdd_dev_err(dd, \"%s: cannot stop/drain VLs - refusing to change per-VL MTUs\\n\",\n\t\t\t   __func__);\n\t\tgoto err;\n\t}\n\n\thfi1_set_ib_cfg(ppd, HFI1_IB_CFG_MTU, 0);\n\n\tif (drain)\n\t\topen_fill_data_vls(dd);  \n\nerr:\n\tmutex_unlock(&ppd->hls_lock);\n\n\treturn ret;\n}\n\nint hfi1_set_lid(struct hfi1_pportdata *ppd, u32 lid, u8 lmc)\n{\n\tstruct hfi1_devdata *dd = ppd->dd;\n\n\tppd->lid = lid;\n\tppd->lmc = lmc;\n\thfi1_set_ib_cfg(ppd, HFI1_IB_CFG_LIDLMC, 0);\n\n\tdd_dev_info(dd, \"port %u: got a lid: 0x%x\\n\", ppd->port, lid);\n\n\treturn 0;\n}\n\nvoid shutdown_led_override(struct hfi1_pportdata *ppd)\n{\n\tstruct hfi1_devdata *dd = ppd->dd;\n\n\t \n\tsmp_rmb();\n\tif (atomic_read(&ppd->led_override_timer_active)) {\n\t\tdel_timer_sync(&ppd->led_override_timer);\n\t\tatomic_set(&ppd->led_override_timer_active, 0);\n\t\t \n\t\tsmp_wmb();\n\t}\n\n\t \n\twrite_csr(dd, DCC_CFG_LED_CNTRL, 0);\n}\n\nstatic void run_led_override(struct timer_list *t)\n{\n\tstruct hfi1_pportdata *ppd = from_timer(ppd, t, led_override_timer);\n\tstruct hfi1_devdata *dd = ppd->dd;\n\tunsigned long timeout;\n\tint phase_idx;\n\n\tif (!(dd->flags & HFI1_INITTED))\n\t\treturn;\n\n\tphase_idx = ppd->led_override_phase & 1;\n\n\tsetextled(dd, phase_idx);\n\n\ttimeout = ppd->led_override_vals[phase_idx];\n\n\t \n\tppd->led_override_phase = !ppd->led_override_phase;\n\n\tmod_timer(&ppd->led_override_timer, jiffies + timeout);\n}\n\n \nvoid hfi1_start_led_override(struct hfi1_pportdata *ppd, unsigned int timeon,\n\t\t\t     unsigned int timeoff)\n{\n\tif (!(ppd->dd->flags & HFI1_INITTED))\n\t\treturn;\n\n\t \n\tppd->led_override_vals[0] = msecs_to_jiffies(timeoff);\n\tppd->led_override_vals[1] = msecs_to_jiffies(timeon);\n\n\t \n\tppd->led_override_phase = 1;\n\n\t \n\tif (!timer_pending(&ppd->led_override_timer)) {\n\t\ttimer_setup(&ppd->led_override_timer, run_led_override, 0);\n\t\tppd->led_override_timer.expires = jiffies + 1;\n\t\tadd_timer(&ppd->led_override_timer);\n\t\tatomic_set(&ppd->led_override_timer_active, 1);\n\t\t \n\t\tsmp_wmb();\n\t}\n}\n\n \nint hfi1_reset_device(int unit)\n{\n\tint ret;\n\tstruct hfi1_devdata *dd = hfi1_lookup(unit);\n\tstruct hfi1_pportdata *ppd;\n\tint pidx;\n\n\tif (!dd) {\n\t\tret = -ENODEV;\n\t\tgoto bail;\n\t}\n\n\tdd_dev_info(dd, \"Reset on unit %u requested\\n\", unit);\n\n\tif (!dd->kregbase1 || !(dd->flags & HFI1_PRESENT)) {\n\t\tdd_dev_info(dd,\n\t\t\t    \"Invalid unit number %u or not initialized or not present\\n\",\n\t\t\t    unit);\n\t\tret = -ENXIO;\n\t\tgoto bail;\n\t}\n\n\t \n\tmutex_lock(&hfi1_mutex);\n\tif (dd->rcd)\n\t\tif (hfi1_stats.sps_ctxts) {\n\t\t\tmutex_unlock(&hfi1_mutex);\n\t\t\tret = -EBUSY;\n\t\t\tgoto bail;\n\t\t}\n\tmutex_unlock(&hfi1_mutex);\n\n\tfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\n\t\tppd = dd->pport + pidx;\n\n\t\tshutdown_led_override(ppd);\n\t}\n\tif (dd->flags & HFI1_HAS_SEND_DMA)\n\t\tsdma_exit(dd);\n\n\thfi1_reset_cpu_counters(dd);\n\n\tret = hfi1_init(dd, 1);\n\n\tif (ret)\n\t\tdd_dev_err(dd,\n\t\t\t   \"Reinitialize unit %u after reset failed with %d\\n\",\n\t\t\t   unit, ret);\n\telse\n\t\tdd_dev_info(dd, \"Reinitialized unit %u after resetting\\n\",\n\t\t\t    unit);\n\nbail:\n\treturn ret;\n}\n\nstatic inline void hfi1_setup_ib_header(struct hfi1_packet *packet)\n{\n\tpacket->hdr = (struct hfi1_ib_message_header *)\n\t\t\thfi1_get_msgheader(packet->rcd,\n\t\t\t\t\t   packet->rhf_addr);\n\tpacket->hlen = (u8 *)packet->rhf_addr - (u8 *)packet->hdr;\n}\n\nstatic int hfi1_bypass_ingress_pkt_check(struct hfi1_packet *packet)\n{\n\tstruct hfi1_pportdata *ppd = packet->rcd->ppd;\n\n\t \n\tif ((!packet->slid) || (!packet->dlid))\n\t\treturn -EINVAL;\n\n\t \n\tif ((!(hfi1_is_16B_mcast(packet->dlid))) &&\n\t    (packet->dlid !=\n\t\topa_get_lid(be32_to_cpu(OPA_LID_PERMISSIVE), 16B))) {\n\t\tif ((packet->dlid & ~((1 << ppd->lmc) - 1)) != ppd->lid)\n\t\t\treturn -EINVAL;\n\t}\n\n\t \n\tif ((hfi1_is_16B_mcast(packet->dlid)) && (packet->sc == 0xF))\n\t\treturn -EINVAL;\n\n\t \n\tif ((packet->dlid == opa_get_lid(be32_to_cpu(OPA_LID_PERMISSIVE),\n\t\t\t\t\t 16B)) &&\n\t    (packet->sc != 0xF))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int hfi1_setup_9B_packet(struct hfi1_packet *packet)\n{\n\tstruct hfi1_ibport *ibp = rcd_to_iport(packet->rcd);\n\tstruct ib_header *hdr;\n\tu8 lnh;\n\n\thfi1_setup_ib_header(packet);\n\thdr = packet->hdr;\n\n\tlnh = ib_get_lnh(hdr);\n\tif (lnh == HFI1_LRH_BTH) {\n\t\tpacket->ohdr = &hdr->u.oth;\n\t\tpacket->grh = NULL;\n\t} else if (lnh == HFI1_LRH_GRH) {\n\t\tu32 vtf;\n\n\t\tpacket->ohdr = &hdr->u.l.oth;\n\t\tpacket->grh = &hdr->u.l.grh;\n\t\tif (packet->grh->next_hdr != IB_GRH_NEXT_HDR)\n\t\t\tgoto drop;\n\t\tvtf = be32_to_cpu(packet->grh->version_tclass_flow);\n\t\tif ((vtf >> IB_GRH_VERSION_SHIFT) != IB_GRH_VERSION)\n\t\t\tgoto drop;\n\t} else {\n\t\tgoto drop;\n\t}\n\n\t \n\tpacket->payload = packet->ebuf;\n\tpacket->opcode = ib_bth_get_opcode(packet->ohdr);\n\tpacket->slid = ib_get_slid(hdr);\n\tpacket->dlid = ib_get_dlid(hdr);\n\tif (unlikely((packet->dlid >= be16_to_cpu(IB_MULTICAST_LID_BASE)) &&\n\t\t     (packet->dlid != be16_to_cpu(IB_LID_PERMISSIVE))))\n\t\tpacket->dlid += opa_get_mcast_base(OPA_MCAST_NR) -\n\t\t\t\tbe16_to_cpu(IB_MULTICAST_LID_BASE);\n\tpacket->sl = ib_get_sl(hdr);\n\tpacket->sc = hfi1_9B_get_sc5(hdr, packet->rhf);\n\tpacket->pad = ib_bth_get_pad(packet->ohdr);\n\tpacket->extra_byte = 0;\n\tpacket->pkey = ib_bth_get_pkey(packet->ohdr);\n\tpacket->migrated = ib_bth_is_migration(packet->ohdr);\n\n\treturn 0;\ndrop:\n\tibp->rvp.n_pkt_drops++;\n\treturn -EINVAL;\n}\n\nstatic int hfi1_setup_bypass_packet(struct hfi1_packet *packet)\n{\n\t \n\n\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\tstruct hfi1_pportdata *ppd = rcd->ppd;\n\tstruct hfi1_ibport *ibp = &ppd->ibport_data;\n\tu8 l4;\n\n\tpacket->hdr = (struct hfi1_16b_header *)\n\t\t\thfi1_get_16B_header(packet->rcd,\n\t\t\t\t\t    packet->rhf_addr);\n\tl4 = hfi1_16B_get_l4(packet->hdr);\n\tif (l4 == OPA_16B_L4_IB_LOCAL) {\n\t\tpacket->ohdr = packet->ebuf;\n\t\tpacket->grh = NULL;\n\t\tpacket->opcode = ib_bth_get_opcode(packet->ohdr);\n\t\tpacket->pad = hfi1_16B_bth_get_pad(packet->ohdr);\n\t\t \n\t\tpacket->hlen = hdr_len_by_opcode[packet->opcode] +\n\t\t\t(LRH_16B_BYTES - LRH_9B_BYTES);\n\t\tpacket->migrated = opa_bth_is_migration(packet->ohdr);\n\t} else if (l4 == OPA_16B_L4_IB_GLOBAL) {\n\t\tu32 vtf;\n\t\tu8 grh_len = sizeof(struct ib_grh);\n\n\t\tpacket->ohdr = packet->ebuf + grh_len;\n\t\tpacket->grh = packet->ebuf;\n\t\tpacket->opcode = ib_bth_get_opcode(packet->ohdr);\n\t\tpacket->pad = hfi1_16B_bth_get_pad(packet->ohdr);\n\t\t \n\t\tpacket->hlen = hdr_len_by_opcode[packet->opcode] +\n\t\t\t(LRH_16B_BYTES - LRH_9B_BYTES) + grh_len;\n\t\tpacket->migrated = opa_bth_is_migration(packet->ohdr);\n\n\t\tif (packet->grh->next_hdr != IB_GRH_NEXT_HDR)\n\t\t\tgoto drop;\n\t\tvtf = be32_to_cpu(packet->grh->version_tclass_flow);\n\t\tif ((vtf >> IB_GRH_VERSION_SHIFT) != IB_GRH_VERSION)\n\t\t\tgoto drop;\n\t} else if (l4 == OPA_16B_L4_FM) {\n\t\tpacket->mgmt = packet->ebuf;\n\t\tpacket->ohdr = NULL;\n\t\tpacket->grh = NULL;\n\t\tpacket->opcode = IB_OPCODE_UD_SEND_ONLY;\n\t\tpacket->pad = OPA_16B_L4_FM_PAD;\n\t\tpacket->hlen = OPA_16B_L4_FM_HLEN;\n\t\tpacket->migrated = false;\n\t} else {\n\t\tgoto drop;\n\t}\n\n\t \n\tpacket->payload = packet->ebuf + packet->hlen - LRH_16B_BYTES;\n\tpacket->slid = hfi1_16B_get_slid(packet->hdr);\n\tpacket->dlid = hfi1_16B_get_dlid(packet->hdr);\n\tif (unlikely(hfi1_is_16B_mcast(packet->dlid)))\n\t\tpacket->dlid += opa_get_mcast_base(OPA_MCAST_NR) -\n\t\t\t\topa_get_lid(opa_get_mcast_base(OPA_MCAST_NR),\n\t\t\t\t\t    16B);\n\tpacket->sc = hfi1_16B_get_sc(packet->hdr);\n\tpacket->sl = ibp->sc_to_sl[packet->sc];\n\tpacket->extra_byte = SIZE_OF_LT;\n\tpacket->pkey = hfi1_16B_get_pkey(packet->hdr);\n\n\tif (hfi1_bypass_ingress_pkt_check(packet))\n\t\tgoto drop;\n\n\treturn 0;\ndrop:\n\thfi1_cdbg(PKT, \"%s: packet dropped\", __func__);\n\tibp->rvp.n_pkt_drops++;\n\treturn -EINVAL;\n}\n\nstatic void show_eflags_errs(struct hfi1_packet *packet)\n{\n\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\tu32 rte = rhf_rcv_type_err(packet->rhf);\n\n\tdd_dev_err(rcd->dd,\n\t\t   \"receive context %d: rhf 0x%016llx, errs [ %s%s%s%s%s%s%s] rte 0x%x\\n\",\n\t\t   rcd->ctxt, packet->rhf,\n\t\t   packet->rhf & RHF_K_HDR_LEN_ERR ? \"k_hdr_len \" : \"\",\n\t\t   packet->rhf & RHF_DC_UNC_ERR ? \"dc_unc \" : \"\",\n\t\t   packet->rhf & RHF_DC_ERR ? \"dc \" : \"\",\n\t\t   packet->rhf & RHF_TID_ERR ? \"tid \" : \"\",\n\t\t   packet->rhf & RHF_LEN_ERR ? \"len \" : \"\",\n\t\t   packet->rhf & RHF_ECC_ERR ? \"ecc \" : \"\",\n\t\t   packet->rhf & RHF_ICRC_ERR ? \"icrc \" : \"\",\n\t\t   rte);\n}\n\nvoid handle_eflags(struct hfi1_packet *packet)\n{\n\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\n\trcv_hdrerr(rcd, rcd->ppd, packet);\n\tif (rhf_err_flags(packet->rhf))\n\t\tshow_eflags_errs(packet);\n}\n\nstatic void hfi1_ipoib_ib_rcv(struct hfi1_packet *packet)\n{\n\tstruct hfi1_ibport *ibp;\n\tstruct net_device *netdev;\n\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\tstruct napi_struct *napi = rcd->napi;\n\tstruct sk_buff *skb;\n\tstruct hfi1_netdev_rxq *rxq = container_of(napi,\n\t\t\tstruct hfi1_netdev_rxq, napi);\n\tu32 extra_bytes;\n\tu32 tlen, qpnum;\n\tbool do_work, do_cnp;\n\n\ttrace_hfi1_rcvhdr(packet);\n\n\thfi1_setup_ib_header(packet);\n\n\tpacket->ohdr = &((struct ib_header *)packet->hdr)->u.oth;\n\tpacket->grh = NULL;\n\n\tif (unlikely(rhf_err_flags(packet->rhf))) {\n\t\thandle_eflags(packet);\n\t\treturn;\n\t}\n\n\tqpnum = ib_bth_get_qpn(packet->ohdr);\n\tnetdev = hfi1_netdev_get_data(rcd->dd, qpnum);\n\tif (!netdev)\n\t\tgoto drop_no_nd;\n\n\ttrace_input_ibhdr(rcd->dd, packet, !!(rhf_dc_info(packet->rhf)));\n\ttrace_ctxt_rsm_hist(rcd->ctxt);\n\n\t \n\tdo_work = hfi1_may_ecn(packet);\n\tif (unlikely(do_work)) {\n\t\tdo_cnp = (packet->opcode != IB_OPCODE_CNP);\n\t\t(void)hfi1_process_ecn_slowpath(hfi1_ipoib_priv(netdev)->qp,\n\t\t\t\t\t\t packet, do_cnp);\n\t}\n\n\t \n\ttlen = packet->tlen;\n\textra_bytes = ib_bth_get_pad(packet->ohdr) + (SIZE_OF_CRC << 2) +\n\t\t\tpacket->hlen;\n\tif (unlikely(tlen < extra_bytes))\n\t\tgoto drop;\n\n\ttlen -= extra_bytes;\n\n\tskb = hfi1_ipoib_prepare_skb(rxq, tlen, packet->ebuf);\n\tif (unlikely(!skb))\n\t\tgoto drop;\n\n\tdev_sw_netstats_rx_add(netdev, skb->len);\n\n\tskb->dev = netdev;\n\tskb->pkt_type = PACKET_HOST;\n\tnetif_receive_skb(skb);\n\n\treturn;\n\ndrop:\n\t++netdev->stats.rx_dropped;\ndrop_no_nd:\n\tibp = rcd_to_iport(packet->rcd);\n\t++ibp->rvp.n_pkt_drops;\n}\n\n \nstatic void process_receive_ib(struct hfi1_packet *packet)\n{\n\tif (hfi1_setup_9B_packet(packet))\n\t\treturn;\n\n\tif (unlikely(hfi1_dbg_should_fault_rx(packet)))\n\t\treturn;\n\n\ttrace_hfi1_rcvhdr(packet);\n\n\tif (unlikely(rhf_err_flags(packet->rhf))) {\n\t\thandle_eflags(packet);\n\t\treturn;\n\t}\n\n\thfi1_ib_rcv(packet);\n}\n\nstatic void process_receive_bypass(struct hfi1_packet *packet)\n{\n\tstruct hfi1_devdata *dd = packet->rcd->dd;\n\n\tif (hfi1_setup_bypass_packet(packet))\n\t\treturn;\n\n\ttrace_hfi1_rcvhdr(packet);\n\n\tif (unlikely(rhf_err_flags(packet->rhf))) {\n\t\thandle_eflags(packet);\n\t\treturn;\n\t}\n\n\tif (hfi1_16B_get_l2(packet->hdr) == 0x2) {\n\t\thfi1_16B_rcv(packet);\n\t} else {\n\t\tdd_dev_err(dd,\n\t\t\t   \"Bypass packets other than 16B are not supported in normal operation. Dropping\\n\");\n\t\tincr_cntr64(&dd->sw_rcv_bypass_packet_errors);\n\t\tif (!(dd->err_info_rcvport.status_and_code &\n\t\t      OPA_EI_STATUS_SMASK)) {\n\t\t\tu64 *flits = packet->ebuf;\n\n\t\t\tif (flits && !(packet->rhf & RHF_LEN_ERR)) {\n\t\t\t\tdd->err_info_rcvport.packet_flit1 = flits[0];\n\t\t\t\tdd->err_info_rcvport.packet_flit2 =\n\t\t\t\t\tpacket->tlen > sizeof(flits[0]) ?\n\t\t\t\t\tflits[1] : 0;\n\t\t\t}\n\t\t\tdd->err_info_rcvport.status_and_code |=\n\t\t\t\t(OPA_EI_STATUS_SMASK | BAD_L2_ERR);\n\t\t}\n\t}\n}\n\nstatic void process_receive_error(struct hfi1_packet *packet)\n{\n\t \n\tif (unlikely(\n\t\t hfi1_dbg_fault_suppress_err(&packet->rcd->dd->verbs_dev) &&\n\t\t (rhf_rcv_type_err(packet->rhf) == RHF_RCV_TYPE_ERROR ||\n\t\t  packet->rhf & RHF_DC_ERR)))\n\t\treturn;\n\n\thfi1_setup_ib_header(packet);\n\thandle_eflags(packet);\n\n\tif (unlikely(rhf_err_flags(packet->rhf)))\n\t\tdd_dev_err(packet->rcd->dd,\n\t\t\t   \"Unhandled error packet received. Dropping.\\n\");\n}\n\nstatic void kdeth_process_expected(struct hfi1_packet *packet)\n{\n\thfi1_setup_9B_packet(packet);\n\tif (unlikely(hfi1_dbg_should_fault_rx(packet)))\n\t\treturn;\n\n\tif (unlikely(rhf_err_flags(packet->rhf))) {\n\t\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\n\t\tif (hfi1_handle_kdeth_eflags(rcd, rcd->ppd, packet))\n\t\t\treturn;\n\t}\n\n\thfi1_kdeth_expected_rcv(packet);\n}\n\nstatic void kdeth_process_eager(struct hfi1_packet *packet)\n{\n\thfi1_setup_9B_packet(packet);\n\tif (unlikely(hfi1_dbg_should_fault_rx(packet)))\n\t\treturn;\n\n\ttrace_hfi1_rcvhdr(packet);\n\tif (unlikely(rhf_err_flags(packet->rhf))) {\n\t\tstruct hfi1_ctxtdata *rcd = packet->rcd;\n\n\t\tshow_eflags_errs(packet);\n\t\tif (hfi1_handle_kdeth_eflags(rcd, rcd->ppd, packet))\n\t\t\treturn;\n\t}\n\n\thfi1_kdeth_eager_rcv(packet);\n}\n\nstatic void process_receive_invalid(struct hfi1_packet *packet)\n{\n\tdd_dev_err(packet->rcd->dd, \"Invalid packet type %d. Dropping\\n\",\n\t\t   rhf_rcv_type(packet->rhf));\n}\n\n#define HFI1_RCVHDR_DUMP_MAX\t5\n\nvoid seqfile_dump_rcd(struct seq_file *s, struct hfi1_ctxtdata *rcd)\n{\n\tstruct hfi1_packet packet;\n\tstruct ps_mdata mdata;\n\tint i;\n\n\tseq_printf(s, \"Rcd %u: RcvHdr cnt %u entsize %u %s ctrl 0x%08llx status 0x%08llx, head %llu tail %llu  sw head %u\\n\",\n\t\t   rcd->ctxt, get_hdrq_cnt(rcd), get_hdrqentsize(rcd),\n\t\t   get_dma_rtail_setting(rcd) ?\n\t\t   \"dma_rtail\" : \"nodma_rtail\",\n\t\t   read_kctxt_csr(rcd->dd, rcd->ctxt, RCV_CTXT_CTRL),\n\t\t   read_kctxt_csr(rcd->dd, rcd->ctxt, RCV_CTXT_STATUS),\n\t\t   read_uctxt_csr(rcd->dd, rcd->ctxt, RCV_HDR_HEAD) &\n\t\t   RCV_HDR_HEAD_HEAD_MASK,\n\t\t   read_uctxt_csr(rcd->dd, rcd->ctxt, RCV_HDR_TAIL),\n\t\t   rcd->head);\n\n\tinit_packet(rcd, &packet);\n\tinit_ps_mdata(&mdata, &packet);\n\n\tfor (i = 0; i < HFI1_RCVHDR_DUMP_MAX; i++) {\n\t\t__le32 *rhf_addr = (__le32 *)rcd->rcvhdrq + mdata.ps_head +\n\t\t\t\t\t rcd->rhf_offset;\n\t\tstruct ib_header *hdr;\n\t\tu64 rhf = rhf_to_cpu(rhf_addr);\n\t\tu32 etype = rhf_rcv_type(rhf), qpn;\n\t\tu8 opcode;\n\t\tu32 psn;\n\t\tu8 lnh;\n\n\t\tif (ps_done(&mdata, rhf, rcd))\n\t\t\tbreak;\n\n\t\tif (ps_skip(&mdata, rhf, rcd))\n\t\t\tgoto next;\n\n\t\tif (etype > RHF_RCV_TYPE_IB)\n\t\t\tgoto next;\n\n\t\tpacket.hdr = hfi1_get_msgheader(rcd, rhf_addr);\n\t\thdr = packet.hdr;\n\n\t\tlnh = be16_to_cpu(hdr->lrh[0]) & 3;\n\n\t\tif (lnh == HFI1_LRH_BTH)\n\t\t\tpacket.ohdr = &hdr->u.oth;\n\t\telse if (lnh == HFI1_LRH_GRH)\n\t\t\tpacket.ohdr = &hdr->u.l.oth;\n\t\telse\n\t\t\tgoto next;  \n\n\t\topcode = (be32_to_cpu(packet.ohdr->bth[0]) >> 24);\n\t\tqpn = be32_to_cpu(packet.ohdr->bth[1]) & RVT_QPN_MASK;\n\t\tpsn = mask_psn(be32_to_cpu(packet.ohdr->bth[2]));\n\n\t\tseq_printf(s, \"\\tEnt %u: opcode 0x%x, qpn 0x%x, psn 0x%x\\n\",\n\t\t\t   mdata.ps_head, opcode, qpn, psn);\nnext:\n\t\tupdate_ps_mdata(&mdata, rcd);\n\t}\n}\n\nconst rhf_rcv_function_ptr normal_rhf_rcv_functions[] = {\n\t[RHF_RCV_TYPE_EXPECTED] = kdeth_process_expected,\n\t[RHF_RCV_TYPE_EAGER] = kdeth_process_eager,\n\t[RHF_RCV_TYPE_IB] = process_receive_ib,\n\t[RHF_RCV_TYPE_ERROR] = process_receive_error,\n\t[RHF_RCV_TYPE_BYPASS] = process_receive_bypass,\n\t[RHF_RCV_TYPE_INVALID5] = process_receive_invalid,\n\t[RHF_RCV_TYPE_INVALID6] = process_receive_invalid,\n\t[RHF_RCV_TYPE_INVALID7] = process_receive_invalid,\n};\n\nconst rhf_rcv_function_ptr netdev_rhf_rcv_functions[] = {\n\t[RHF_RCV_TYPE_EXPECTED] = process_receive_invalid,\n\t[RHF_RCV_TYPE_EAGER] = process_receive_invalid,\n\t[RHF_RCV_TYPE_IB] = hfi1_ipoib_ib_rcv,\n\t[RHF_RCV_TYPE_ERROR] = process_receive_error,\n\t[RHF_RCV_TYPE_BYPASS] = hfi1_vnic_bypass_rcv,\n\t[RHF_RCV_TYPE_INVALID5] = process_receive_invalid,\n\t[RHF_RCV_TYPE_INVALID6] = process_receive_invalid,\n\t[RHF_RCV_TYPE_INVALID7] = process_receive_invalid,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}