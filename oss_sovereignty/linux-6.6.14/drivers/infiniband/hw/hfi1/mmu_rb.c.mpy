{
  "module_name": "mmu_rb.c",
  "hash_id": "800b1e200edc298cdf5c662c4e3c8024f7404ee267d9a1387eff55357802fbbe",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/hfi1/mmu_rb.c",
  "human_readable_source": "\n \n\n#include <linux/list.h>\n#include <linux/rculist.h>\n#include <linux/mmu_notifier.h>\n#include <linux/interval_tree_generic.h>\n#include <linux/sched/mm.h>\n\n#include \"mmu_rb.h\"\n#include \"trace.h\"\n\nstatic unsigned long mmu_node_start(struct mmu_rb_node *);\nstatic unsigned long mmu_node_last(struct mmu_rb_node *);\nstatic int mmu_notifier_range_start(struct mmu_notifier *,\n\t\tconst struct mmu_notifier_range *);\nstatic struct mmu_rb_node *__mmu_rb_search(struct mmu_rb_handler *,\n\t\t\t\t\t   unsigned long, unsigned long);\nstatic void release_immediate(struct kref *refcount);\nstatic void handle_remove(struct work_struct *work);\n\nstatic const struct mmu_notifier_ops mn_opts = {\n\t.invalidate_range_start = mmu_notifier_range_start,\n};\n\nINTERVAL_TREE_DEFINE(struct mmu_rb_node, node, unsigned long, __last,\n\t\t     mmu_node_start, mmu_node_last, static, __mmu_int_rb);\n\nstatic unsigned long mmu_node_start(struct mmu_rb_node *node)\n{\n\treturn node->addr & PAGE_MASK;\n}\n\nstatic unsigned long mmu_node_last(struct mmu_rb_node *node)\n{\n\treturn PAGE_ALIGN(node->addr + node->len) - 1;\n}\n\nint hfi1_mmu_rb_register(void *ops_arg,\n\t\t\t struct mmu_rb_ops *ops,\n\t\t\t struct workqueue_struct *wq,\n\t\t\t struct mmu_rb_handler **handler)\n{\n\tstruct mmu_rb_handler *h;\n\tvoid *free_ptr;\n\tint ret;\n\n\tfree_ptr = kzalloc(sizeof(*h) + cache_line_size() - 1, GFP_KERNEL);\n\tif (!free_ptr)\n\t\treturn -ENOMEM;\n\n\th = PTR_ALIGN(free_ptr, cache_line_size());\n\th->root = RB_ROOT_CACHED;\n\th->ops = ops;\n\th->ops_arg = ops_arg;\n\tINIT_HLIST_NODE(&h->mn.hlist);\n\tspin_lock_init(&h->lock);\n\th->mn.ops = &mn_opts;\n\tINIT_WORK(&h->del_work, handle_remove);\n\tINIT_LIST_HEAD(&h->del_list);\n\tINIT_LIST_HEAD(&h->lru_list);\n\th->wq = wq;\n\th->free_ptr = free_ptr;\n\n\tret = mmu_notifier_register(&h->mn, current->mm);\n\tif (ret) {\n\t\tkfree(free_ptr);\n\t\treturn ret;\n\t}\n\n\t*handler = h;\n\treturn 0;\n}\n\nvoid hfi1_mmu_rb_unregister(struct mmu_rb_handler *handler)\n{\n\tstruct mmu_rb_node *rbnode;\n\tstruct rb_node *node;\n\tunsigned long flags;\n\tstruct list_head del_list;\n\n\t \n\tmmgrab(handler->mn.mm);\n\n\t \n\tmmu_notifier_unregister(&handler->mn, handler->mn.mm);\n\n\t \n\tflush_work(&handler->del_work);\n\n\tINIT_LIST_HEAD(&del_list);\n\n\tspin_lock_irqsave(&handler->lock, flags);\n\twhile ((node = rb_first_cached(&handler->root))) {\n\t\trbnode = rb_entry(node, struct mmu_rb_node, node);\n\t\trb_erase_cached(node, &handler->root);\n\t\t \n\t\tlist_move(&rbnode->list, &del_list);\n\t}\n\tspin_unlock_irqrestore(&handler->lock, flags);\n\n\twhile (!list_empty(&del_list)) {\n\t\trbnode = list_first_entry(&del_list, struct mmu_rb_node, list);\n\t\tlist_del(&rbnode->list);\n\t\tkref_put(&rbnode->refcount, release_immediate);\n\t}\n\n\t \n\tmmdrop(handler->mn.mm);\n\n\tkfree(handler->free_ptr);\n}\n\nint hfi1_mmu_rb_insert(struct mmu_rb_handler *handler,\n\t\t       struct mmu_rb_node *mnode)\n{\n\tstruct mmu_rb_node *node;\n\tunsigned long flags;\n\tint ret = 0;\n\n\ttrace_hfi1_mmu_rb_insert(mnode);\n\n\tif (current->mm != handler->mn.mm)\n\t\treturn -EPERM;\n\n\tspin_lock_irqsave(&handler->lock, flags);\n\tnode = __mmu_rb_search(handler, mnode->addr, mnode->len);\n\tif (node) {\n\t\tret = -EEXIST;\n\t\tgoto unlock;\n\t}\n\t__mmu_int_rb_insert(mnode, &handler->root);\n\tlist_add_tail(&mnode->list, &handler->lru_list);\n\tmnode->handler = handler;\nunlock:\n\tspin_unlock_irqrestore(&handler->lock, flags);\n\treturn ret;\n}\n\n \nstruct mmu_rb_node *hfi1_mmu_rb_get_first(struct mmu_rb_handler *handler,\n\t\t\t\t\t  unsigned long addr, unsigned long len)\n{\n\tstruct mmu_rb_node *node;\n\n\ttrace_hfi1_mmu_rb_search(addr, len);\n\tnode = __mmu_int_rb_iter_first(&handler->root, addr, (addr + len) - 1);\n\tif (node)\n\t\tlist_move_tail(&node->list, &handler->lru_list);\n\treturn node;\n}\n\n \nstatic struct mmu_rb_node *__mmu_rb_search(struct mmu_rb_handler *handler,\n\t\t\t\t\t   unsigned long addr,\n\t\t\t\t\t   unsigned long len)\n{\n\tstruct mmu_rb_node *node = NULL;\n\n\ttrace_hfi1_mmu_rb_search(addr, len);\n\tif (!handler->ops->filter) {\n\t\tnode = __mmu_int_rb_iter_first(&handler->root, addr,\n\t\t\t\t\t       (addr + len) - 1);\n\t} else {\n\t\tfor (node = __mmu_int_rb_iter_first(&handler->root, addr,\n\t\t\t\t\t\t    (addr + len) - 1);\n\t\t     node;\n\t\t     node = __mmu_int_rb_iter_next(node, addr,\n\t\t\t\t\t\t   (addr + len) - 1)) {\n\t\t\tif (handler->ops->filter(node, addr, len))\n\t\t\t\treturn node;\n\t\t}\n\t}\n\treturn node;\n}\n\n \nstatic void release_immediate(struct kref *refcount)\n{\n\tstruct mmu_rb_node *mnode =\n\t\tcontainer_of(refcount, struct mmu_rb_node, refcount);\n\ttrace_hfi1_mmu_release_node(mnode);\n\tmnode->handler->ops->remove(mnode->handler->ops_arg, mnode);\n}\n\n \nstatic void release_nolock(struct kref *refcount)\n{\n\tstruct mmu_rb_node *mnode =\n\t\tcontainer_of(refcount, struct mmu_rb_node, refcount);\n\tlist_move(&mnode->list, &mnode->handler->del_list);\n\tqueue_work(mnode->handler->wq, &mnode->handler->del_work);\n}\n\n \nvoid hfi1_mmu_rb_release(struct kref *refcount)\n{\n\tstruct mmu_rb_node *mnode =\n\t\tcontainer_of(refcount, struct mmu_rb_node, refcount);\n\tstruct mmu_rb_handler *handler = mnode->handler;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&handler->lock, flags);\n\tlist_move(&mnode->list, &mnode->handler->del_list);\n\tspin_unlock_irqrestore(&handler->lock, flags);\n\tqueue_work(handler->wq, &handler->del_work);\n}\n\nvoid hfi1_mmu_rb_evict(struct mmu_rb_handler *handler, void *evict_arg)\n{\n\tstruct mmu_rb_node *rbnode, *ptr;\n\tstruct list_head del_list;\n\tunsigned long flags;\n\tbool stop = false;\n\n\tif (current->mm != handler->mn.mm)\n\t\treturn;\n\n\tINIT_LIST_HEAD(&del_list);\n\n\tspin_lock_irqsave(&handler->lock, flags);\n\tlist_for_each_entry_safe(rbnode, ptr, &handler->lru_list, list) {\n\t\t \n\t\tif (kref_read(&rbnode->refcount) > 1)\n\t\t\tcontinue;\n\n\t\tif (handler->ops->evict(handler->ops_arg, rbnode, evict_arg,\n\t\t\t\t\t&stop)) {\n\t\t\t__mmu_int_rb_remove(rbnode, &handler->root);\n\t\t\t \n\t\t\tlist_move(&rbnode->list, &del_list);\n\t\t}\n\t\tif (stop)\n\t\t\tbreak;\n\t}\n\tspin_unlock_irqrestore(&handler->lock, flags);\n\n\tlist_for_each_entry_safe(rbnode, ptr, &del_list, list) {\n\t\ttrace_hfi1_mmu_rb_evict(rbnode);\n\t\tkref_put(&rbnode->refcount, release_immediate);\n\t}\n}\n\nstatic int mmu_notifier_range_start(struct mmu_notifier *mn,\n\t\tconst struct mmu_notifier_range *range)\n{\n\tstruct mmu_rb_handler *handler =\n\t\tcontainer_of(mn, struct mmu_rb_handler, mn);\n\tstruct rb_root_cached *root = &handler->root;\n\tstruct mmu_rb_node *node, *ptr = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&handler->lock, flags);\n\tfor (node = __mmu_int_rb_iter_first(root, range->start, range->end-1);\n\t     node; node = ptr) {\n\t\t \n\t\tptr = __mmu_int_rb_iter_next(node, range->start,\n\t\t\t\t\t     range->end - 1);\n\t\ttrace_hfi1_mmu_mem_invalidate(node);\n\t\t \n\t\t__mmu_int_rb_remove(node, root);\n\t\tlist_del_init(&node->list);\n\t\tkref_put(&node->refcount, release_nolock);\n\t}\n\tspin_unlock_irqrestore(&handler->lock, flags);\n\n\treturn 0;\n}\n\n \nstatic void handle_remove(struct work_struct *work)\n{\n\tstruct mmu_rb_handler *handler = container_of(work,\n\t\t\t\t\t\tstruct mmu_rb_handler,\n\t\t\t\t\t\tdel_work);\n\tstruct list_head del_list;\n\tunsigned long flags;\n\tstruct mmu_rb_node *node;\n\n\t \n\tspin_lock_irqsave(&handler->lock, flags);\n\tlist_replace_init(&handler->del_list, &del_list);\n\tspin_unlock_irqrestore(&handler->lock, flags);\n\n\twhile (!list_empty(&del_list)) {\n\t\tnode = list_first_entry(&del_list, struct mmu_rb_node, list);\n\t\tlist_del(&node->list);\n\t\ttrace_hfi1_mmu_release_node(node);\n\t\thandler->ops->remove(handler->ops_arg, node);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}