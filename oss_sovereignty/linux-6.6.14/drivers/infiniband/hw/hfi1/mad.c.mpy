{
  "module_name": "mad.c",
  "hash_id": "31a9d0cdf586941c7d1f11a6fdef6642a02dcd025ef321a9d1cfbdccecad5f2a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/hfi1/mad.c",
  "human_readable_source": "\n \n\n#include <linux/net.h>\n#include <rdma/opa_addr.h>\n#define OPA_NUM_PKEY_BLOCKS_PER_SMP (OPA_SMP_DR_DATA_SIZE \\\n\t\t\t/ (OPA_PARTITION_TABLE_BLK_SIZE * sizeof(u16)))\n\n#include \"hfi.h\"\n#include \"mad.h\"\n#include \"trace.h\"\n#include \"qp.h\"\n#include \"vnic.h\"\n\n \n#define OPA_LINK_WIDTH_RESET_OLD 0x0fff\n#define OPA_LINK_WIDTH_RESET 0xffff\n\nstruct trap_node {\n\tstruct list_head list;\n\tstruct opa_mad_notice_attr data;\n\t__be64 tid;\n\tint len;\n\tu32 retry;\n\tu8 in_use;\n\tu8 repress;\n};\n\nstatic int smp_length_check(u32 data_size, u32 request_len)\n{\n\tif (unlikely(request_len < data_size))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int reply(struct ib_mad_hdr *smp)\n{\n\t \n\tsmp->method = IB_MGMT_METHOD_GET_RESP;\n\tif (smp->mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE)\n\t\tsmp->status |= IB_SMP_DIRECTION;\n\treturn IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_REPLY;\n}\n\nstatic inline void clear_opa_smp_data(struct opa_smp *smp)\n{\n\tvoid *data = opa_get_smp_data(smp);\n\tsize_t size = opa_get_smp_data_size(smp);\n\n\tmemset(data, 0, size);\n}\n\nstatic u16 hfi1_lookup_pkey_value(struct hfi1_ibport *ibp, int pkey_idx)\n{\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\n\tif (pkey_idx < ARRAY_SIZE(ppd->pkeys))\n\t\treturn ppd->pkeys[pkey_idx];\n\n\treturn 0;\n}\n\nvoid hfi1_event_pkey_change(struct hfi1_devdata *dd, u32 port)\n{\n\tstruct ib_event event;\n\n\tevent.event = IB_EVENT_PKEY_CHANGE;\n\tevent.device = &dd->verbs_dev.rdi.ibdev;\n\tevent.element.port_num = port;\n\tib_dispatch_event(&event);\n}\n\n \nstatic void cleanup_traps(struct hfi1_ibport *ibp, struct trap_node *trap)\n{\n\tstruct trap_node *node, *q;\n\tunsigned long flags;\n\tstruct list_head trap_list;\n\tint i;\n\n\tfor (i = 0; i < RVT_MAX_TRAP_LISTS; i++) {\n\t\tspin_lock_irqsave(&ibp->rvp.lock, flags);\n\t\tlist_replace_init(&ibp->rvp.trap_lists[i].list, &trap_list);\n\t\tibp->rvp.trap_lists[i].list_len = 0;\n\t\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\n\t\t \n\t\tlist_for_each_entry_safe(node, q, &trap_list, list) {\n\t\t\tlist_del(&node->list);\n\t\t\tif (node != trap)\n\t\t\t\tkfree(node);\n\t\t}\n\t}\n\n\t \n\tkfree(trap);\n}\n\nstatic struct trap_node *check_and_add_trap(struct hfi1_ibport *ibp,\n\t\t\t\t\t    struct trap_node *trap)\n{\n\tstruct trap_node *node;\n\tstruct trap_list *trap_list;\n\tunsigned long flags;\n\tunsigned long timeout;\n\tint found = 0;\n\tunsigned int queue_id;\n\tstatic int trap_count;\n\n\tqueue_id = trap->data.generic_type & 0x0F;\n\tif (queue_id >= RVT_MAX_TRAP_LISTS) {\n\t\ttrap_count++;\n\t\tpr_err_ratelimited(\"hfi1: Invalid trap 0x%0x dropped. Total dropped: %d\\n\",\n\t\t\t\t   trap->data.generic_type, trap_count);\n\t\tkfree(trap);\n\t\treturn NULL;\n\t}\n\n\t \n\tspin_lock_irqsave(&ibp->rvp.lock, flags);\n\ttrap_list = &ibp->rvp.trap_lists[queue_id];\n\n\tlist_for_each_entry(node, &trap_list->list, list) {\n\t\tif (node == trap) {\n\t\t\tnode->retry++;\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (!found) {\n\t\tif (trap_list->list_len < RVT_MAX_TRAP_LEN) {\n\t\t\ttrap_list->list_len++;\n\t\t\tlist_add_tail(&trap->list, &trap_list->list);\n\t\t} else {\n\t\t\tpr_warn_ratelimited(\"hfi1: Maximum trap limit reached for 0x%0x traps\\n\",\n\t\t\t\t\t    trap->data.generic_type);\n\t\t\tkfree(trap);\n\t\t}\n\t}\n\n\t \n\tnode = NULL;\n\tif (!timer_pending(&ibp->rvp.trap_timer)) {\n\t\t \n\t\ttimeout = (RVT_TRAP_TIMEOUT *\n\t\t\t   (1UL << ibp->rvp.subnet_timeout)) / 1000;\n\t\tmod_timer(&ibp->rvp.trap_timer,\n\t\t\t  jiffies + usecs_to_jiffies(timeout));\n\t\tnode = list_first_entry(&trap_list->list, struct trap_node,\n\t\t\t\t\tlist);\n\t\tnode->in_use = 1;\n\t}\n\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\n\treturn node;\n}\n\nstatic void subn_handle_opa_trap_repress(struct hfi1_ibport *ibp,\n\t\t\t\t\t struct opa_smp *smp)\n{\n\tstruct trap_list *trap_list;\n\tstruct trap_node *trap;\n\tunsigned long flags;\n\tint i;\n\n\tif (smp->attr_id != IB_SMP_ATTR_NOTICE)\n\t\treturn;\n\n\tspin_lock_irqsave(&ibp->rvp.lock, flags);\n\tfor (i = 0; i < RVT_MAX_TRAP_LISTS; i++) {\n\t\ttrap_list = &ibp->rvp.trap_lists[i];\n\t\ttrap = list_first_entry_or_null(&trap_list->list,\n\t\t\t\t\t\tstruct trap_node, list);\n\t\tif (trap && trap->tid == smp->tid) {\n\t\t\tif (trap->in_use) {\n\t\t\t\ttrap->repress = 1;\n\t\t\t} else {\n\t\t\t\ttrap_list->list_len--;\n\t\t\t\tlist_del(&trap->list);\n\t\t\t\tkfree(trap);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n}\n\nstatic void hfi1_update_sm_ah_attr(struct hfi1_ibport *ibp,\n\t\t\t\t   struct rdma_ah_attr *attr, u32 dlid)\n{\n\trdma_ah_set_dlid(attr, dlid);\n\trdma_ah_set_port_num(attr, ppd_from_ibp(ibp)->port);\n\tif (dlid >= be16_to_cpu(IB_MULTICAST_LID_BASE)) {\n\t\tstruct ib_global_route *grh = rdma_ah_retrieve_grh(attr);\n\n\t\trdma_ah_set_ah_flags(attr, IB_AH_GRH);\n\t\tgrh->sgid_index = 0;\n\t\tgrh->hop_limit = 1;\n\t\tgrh->dgid.global.subnet_prefix =\n\t\t\tibp->rvp.gid_prefix;\n\t\tgrh->dgid.global.interface_id = OPA_MAKE_ID(dlid);\n\t}\n}\n\nstatic int hfi1_modify_qp0_ah(struct hfi1_ibport *ibp,\n\t\t\t      struct rvt_ah *ah, u32 dlid)\n{\n\tstruct rdma_ah_attr attr;\n\tstruct rvt_qp *qp0;\n\tint ret = -EINVAL;\n\n\tmemset(&attr, 0, sizeof(attr));\n\tattr.type = ah->ibah.type;\n\thfi1_update_sm_ah_attr(ibp, &attr, dlid);\n\trcu_read_lock();\n\tqp0 = rcu_dereference(ibp->rvp.qp[0]);\n\tif (qp0)\n\t\tret = rdma_modify_ah(&ah->ibah, &attr);\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic struct ib_ah *hfi1_create_qp0_ah(struct hfi1_ibport *ibp, u32 dlid)\n{\n\tstruct rdma_ah_attr attr;\n\tstruct ib_ah *ah = ERR_PTR(-EINVAL);\n\tstruct rvt_qp *qp0;\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tstruct hfi1_devdata *dd = dd_from_ppd(ppd);\n\tu32 port_num = ppd->port;\n\n\tmemset(&attr, 0, sizeof(attr));\n\tattr.type = rdma_ah_find_type(&dd->verbs_dev.rdi.ibdev, port_num);\n\thfi1_update_sm_ah_attr(ibp, &attr, dlid);\n\trcu_read_lock();\n\tqp0 = rcu_dereference(ibp->rvp.qp[0]);\n\tif (qp0)\n\t\tah = rdma_create_ah(qp0->ibqp.pd, &attr, 0);\n\trcu_read_unlock();\n\treturn ah;\n}\n\nstatic void send_trap(struct hfi1_ibport *ibp, struct trap_node *trap)\n{\n\tstruct ib_mad_send_buf *send_buf;\n\tstruct ib_mad_agent *agent;\n\tstruct opa_smp *smp;\n\tunsigned long flags;\n\tint pkey_idx;\n\tu32 qpn = ppd_from_ibp(ibp)->sm_trap_qp;\n\n\tagent = ibp->rvp.send_agent;\n\tif (!agent) {\n\t\tcleanup_traps(ibp, trap);\n\t\treturn;\n\t}\n\n\t \n\tif (driver_lstate(ppd_from_ibp(ibp)) != IB_PORT_ACTIVE) {\n\t\tcleanup_traps(ibp, trap);\n\t\treturn;\n\t}\n\n\t \n\ttrap = check_and_add_trap(ibp, trap);\n\tif (!trap)\n\t\treturn;\n\n\tpkey_idx = hfi1_lookup_pkey_idx(ibp, LIM_MGMT_P_KEY);\n\tif (pkey_idx < 0) {\n\t\tpr_warn(\"%s: failed to find limited mgmt pkey, defaulting 0x%x\\n\",\n\t\t\t__func__, hfi1_get_pkey(ibp, 1));\n\t\tpkey_idx = 1;\n\t}\n\n\tsend_buf = ib_create_send_mad(agent, qpn, pkey_idx, 0,\n\t\t\t\t      IB_MGMT_MAD_HDR, IB_MGMT_MAD_DATA,\n\t\t\t\t      GFP_ATOMIC, IB_MGMT_BASE_VERSION);\n\tif (IS_ERR(send_buf))\n\t\treturn;\n\n\tsmp = send_buf->mad;\n\tsmp->base_version = OPA_MGMT_BASE_VERSION;\n\tsmp->mgmt_class = IB_MGMT_CLASS_SUBN_LID_ROUTED;\n\tsmp->class_version = OPA_SM_CLASS_VERSION;\n\tsmp->method = IB_MGMT_METHOD_TRAP;\n\n\t \n\tif (trap->tid == 0) {\n\t\tibp->rvp.tid++;\n\t\t \n\t\tif (ibp->rvp.tid == 0)\n\t\t\tibp->rvp.tid++;\n\t\ttrap->tid = cpu_to_be64(ibp->rvp.tid);\n\t}\n\tsmp->tid = trap->tid;\n\n\tsmp->attr_id = IB_SMP_ATTR_NOTICE;\n\t \n\n\tmemcpy(smp->route.lid.data, &trap->data, trap->len);\n\n\tspin_lock_irqsave(&ibp->rvp.lock, flags);\n\tif (!ibp->rvp.sm_ah) {\n\t\tif (ibp->rvp.sm_lid != be16_to_cpu(IB_LID_PERMISSIVE)) {\n\t\t\tstruct ib_ah *ah;\n\n\t\t\tah = hfi1_create_qp0_ah(ibp, ibp->rvp.sm_lid);\n\t\t\tif (IS_ERR(ah)) {\n\t\t\t\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tsend_buf->ah = ah;\n\t\t\tibp->rvp.sm_ah = ibah_to_rvtah(ah);\n\t\t} else {\n\t\t\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\tsend_buf->ah = &ibp->rvp.sm_ah->ibah;\n\t}\n\n\t \n\tif (trap->repress) {\n\t\tlist_del(&trap->list);\n\t\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\t\tkfree(trap);\n\t\tib_free_send_mad(send_buf);\n\t\treturn;\n\t}\n\n\ttrap->in_use = 0;\n\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\n\tif (ib_post_send_mad(send_buf, NULL))\n\t\tib_free_send_mad(send_buf);\n}\n\nvoid hfi1_handle_trap_timer(struct timer_list *t)\n{\n\tstruct hfi1_ibport *ibp = from_timer(ibp, t, rvp.trap_timer);\n\tstruct trap_node *trap = NULL;\n\tunsigned long flags;\n\tint i;\n\n\t \n\tspin_lock_irqsave(&ibp->rvp.lock, flags);\n\tfor (i = 0; !trap && i < RVT_MAX_TRAP_LISTS; i++) {\n\t\ttrap = list_first_entry_or_null(&ibp->rvp.trap_lists[i].list,\n\t\t\t\t\t\tstruct trap_node, list);\n\t}\n\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\n\tif (trap)\n\t\tsend_trap(ibp, trap);\n}\n\nstatic struct trap_node *create_trap_node(u8 type, __be16 trap_num, u32 lid)\n{\n\tstruct trap_node *trap;\n\n\ttrap = kzalloc(sizeof(*trap), GFP_ATOMIC);\n\tif (!trap)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&trap->list);\n\ttrap->data.generic_type = type;\n\ttrap->data.prod_type_lsb = IB_NOTICE_PROD_CA;\n\ttrap->data.trap_num = trap_num;\n\ttrap->data.issuer_lid = cpu_to_be32(lid);\n\n\treturn trap;\n}\n\n \nvoid hfi1_bad_pkey(struct hfi1_ibport *ibp, u32 key, u32 sl,\n\t\t   u32 qp1, u32 qp2, u32 lid1, u32 lid2)\n{\n\tstruct trap_node *trap;\n\tu32 lid = ppd_from_ibp(ibp)->lid;\n\n\tibp->rvp.n_pkt_drops++;\n\tibp->rvp.pkey_violations++;\n\n\ttrap = create_trap_node(IB_NOTICE_TYPE_SECURITY, OPA_TRAP_BAD_P_KEY,\n\t\t\t\tlid);\n\tif (!trap)\n\t\treturn;\n\n\t \n\ttrap->data.ntc_257_258.lid1 = cpu_to_be32(lid1);\n\ttrap->data.ntc_257_258.lid2 = cpu_to_be32(lid2);\n\ttrap->data.ntc_257_258.key = cpu_to_be32(key);\n\ttrap->data.ntc_257_258.sl = sl << 3;\n\ttrap->data.ntc_257_258.qp1 = cpu_to_be32(qp1);\n\ttrap->data.ntc_257_258.qp2 = cpu_to_be32(qp2);\n\n\ttrap->len = sizeof(trap->data);\n\tsend_trap(ibp, trap);\n}\n\n \nstatic void bad_mkey(struct hfi1_ibport *ibp, struct ib_mad_hdr *mad,\n\t\t     __be64 mkey, __be32 dr_slid, u8 return_path[], u8 hop_cnt)\n{\n\tstruct trap_node *trap;\n\tu32 lid = ppd_from_ibp(ibp)->lid;\n\n\ttrap = create_trap_node(IB_NOTICE_TYPE_SECURITY, OPA_TRAP_BAD_M_KEY,\n\t\t\t\tlid);\n\tif (!trap)\n\t\treturn;\n\n\t \n\ttrap->data.ntc_256.lid = trap->data.issuer_lid;\n\ttrap->data.ntc_256.method = mad->method;\n\ttrap->data.ntc_256.attr_id = mad->attr_id;\n\ttrap->data.ntc_256.attr_mod = mad->attr_mod;\n\ttrap->data.ntc_256.mkey = mkey;\n\tif (mad->mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) {\n\t\ttrap->data.ntc_256.dr_slid = dr_slid;\n\t\ttrap->data.ntc_256.dr_trunc_hop = IB_NOTICE_TRAP_DR_NOTICE;\n\t\tif (hop_cnt > ARRAY_SIZE(trap->data.ntc_256.dr_rtn_path)) {\n\t\t\ttrap->data.ntc_256.dr_trunc_hop |=\n\t\t\t\tIB_NOTICE_TRAP_DR_TRUNC;\n\t\t\thop_cnt = ARRAY_SIZE(trap->data.ntc_256.dr_rtn_path);\n\t\t}\n\t\ttrap->data.ntc_256.dr_trunc_hop |= hop_cnt;\n\t\tmemcpy(trap->data.ntc_256.dr_rtn_path, return_path,\n\t\t       hop_cnt);\n\t}\n\n\ttrap->len = sizeof(trap->data);\n\n\tsend_trap(ibp, trap);\n}\n\n \nvoid hfi1_cap_mask_chg(struct rvt_dev_info *rdi, u32 port_num)\n{\n\tstruct trap_node *trap;\n\tstruct hfi1_ibdev *verbs_dev = dev_from_rdi(rdi);\n\tstruct hfi1_devdata *dd = dd_from_dev(verbs_dev);\n\tstruct hfi1_ibport *ibp = &dd->pport[port_num - 1].ibport_data;\n\tu32 lid = ppd_from_ibp(ibp)->lid;\n\n\ttrap = create_trap_node(IB_NOTICE_TYPE_INFO,\n\t\t\t\tOPA_TRAP_CHANGE_CAPABILITY,\n\t\t\t\tlid);\n\tif (!trap)\n\t\treturn;\n\n\ttrap->data.ntc_144.lid = trap->data.issuer_lid;\n\ttrap->data.ntc_144.new_cap_mask = cpu_to_be32(ibp->rvp.port_cap_flags);\n\ttrap->data.ntc_144.cap_mask3 = cpu_to_be16(ibp->rvp.port_cap3_flags);\n\n\ttrap->len = sizeof(trap->data);\n\tsend_trap(ibp, trap);\n}\n\n \nvoid hfi1_sys_guid_chg(struct hfi1_ibport *ibp)\n{\n\tstruct trap_node *trap;\n\tu32 lid = ppd_from_ibp(ibp)->lid;\n\n\ttrap = create_trap_node(IB_NOTICE_TYPE_INFO, OPA_TRAP_CHANGE_SYSGUID,\n\t\t\t\tlid);\n\tif (!trap)\n\t\treturn;\n\n\ttrap->data.ntc_145.new_sys_guid = ib_hfi1_sys_image_guid;\n\ttrap->data.ntc_145.lid = trap->data.issuer_lid;\n\n\ttrap->len = sizeof(trap->data);\n\tsend_trap(ibp, trap);\n}\n\n \nvoid hfi1_node_desc_chg(struct hfi1_ibport *ibp)\n{\n\tstruct trap_node *trap;\n\tu32 lid = ppd_from_ibp(ibp)->lid;\n\n\ttrap = create_trap_node(IB_NOTICE_TYPE_INFO,\n\t\t\t\tOPA_TRAP_CHANGE_CAPABILITY,\n\t\t\t\tlid);\n\tif (!trap)\n\t\treturn;\n\n\ttrap->data.ntc_144.lid = trap->data.issuer_lid;\n\ttrap->data.ntc_144.change_flags =\n\t\tcpu_to_be16(OPA_NOTICE_TRAP_NODE_DESC_CHG);\n\n\ttrap->len = sizeof(trap->data);\n\tsend_trap(ibp, trap);\n}\n\nstatic int __subn_get_opa_nodedesc(struct opa_smp *smp, u32 am,\n\t\t\t\t   u8 *data, struct ib_device *ibdev,\n\t\t\t\t   u32 port, u32 *resp_len, u32 max_len)\n{\n\tstruct opa_node_description *nd;\n\n\tif (am || smp_length_check(sizeof(*nd), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tnd = (struct opa_node_description *)data;\n\n\tmemcpy(nd->data, ibdev->node_desc, sizeof(nd->data));\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(*nd);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_get_opa_nodeinfo(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct opa_node_info *ni;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 pidx = port - 1;  \n\n\tni = (struct opa_node_info *)data;\n\n\t \n\tif (am || pidx >= dd->num_pports || ibdev->node_guid == 0 ||\n\t    smp_length_check(sizeof(*ni), max_len) ||\n\t    get_sguid(to_iport(ibdev, port), HFI1_PORT_GUID_INDEX) == 0) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tni->port_guid = get_sguid(to_iport(ibdev, port), HFI1_PORT_GUID_INDEX);\n\tni->base_version = OPA_MGMT_BASE_VERSION;\n\tni->class_version = OPA_SM_CLASS_VERSION;\n\tni->node_type = 1;      \n\tni->num_ports = ibdev->phys_port_cnt;\n\t \n\tni->system_image_guid = ib_hfi1_sys_image_guid;\n\tni->node_guid = ibdev->node_guid;\n\tni->partition_cap = cpu_to_be16(hfi1_get_npkeys(dd));\n\tni->device_id = cpu_to_be16(dd->pcidev->device);\n\tni->revision = cpu_to_be32(dd->minrev);\n\tni->local_port_num = port;\n\tni->vendor_id[0] = dd->oui1;\n\tni->vendor_id[1] = dd->oui2;\n\tni->vendor_id[2] = dd->oui3;\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(*ni);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int subn_get_nodeinfo(struct ib_smp *smp, struct ib_device *ibdev,\n\t\t\t     u32 port)\n{\n\tstruct ib_node_info *nip = (struct ib_node_info *)&smp->data;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 pidx = port - 1;  \n\n\t \n\tif (smp->attr_mod || pidx >= dd->num_pports ||\n\t    ibdev->node_guid == 0 ||\n\t    get_sguid(to_iport(ibdev, port), HFI1_PORT_GUID_INDEX) == 0) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tnip->port_guid = get_sguid(to_iport(ibdev, port), HFI1_PORT_GUID_INDEX);\n\tnip->base_version = OPA_MGMT_BASE_VERSION;\n\tnip->class_version = OPA_SM_CLASS_VERSION;\n\tnip->node_type = 1;      \n\tnip->num_ports = ibdev->phys_port_cnt;\n\t \n\tnip->sys_guid = ib_hfi1_sys_image_guid;\n\tnip->node_guid = ibdev->node_guid;\n\tnip->partition_cap = cpu_to_be16(hfi1_get_npkeys(dd));\n\tnip->device_id = cpu_to_be16(dd->pcidev->device);\n\tnip->revision = cpu_to_be32(dd->minrev);\n\tnip->local_port_num = port;\n\tnip->vendor_id[0] = dd->oui1;\n\tnip->vendor_id[1] = dd->oui2;\n\tnip->vendor_id[2] = dd->oui3;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic void set_link_width_enabled(struct hfi1_pportdata *ppd, u32 w)\n{\n\t(void)hfi1_set_ib_cfg(ppd, HFI1_IB_CFG_LWID_ENB, w);\n}\n\nstatic void set_link_width_downgrade_enabled(struct hfi1_pportdata *ppd, u32 w)\n{\n\t(void)hfi1_set_ib_cfg(ppd, HFI1_IB_CFG_LWID_DG_ENB, w);\n}\n\nstatic void set_link_speed_enabled(struct hfi1_pportdata *ppd, u32 s)\n{\n\t(void)hfi1_set_ib_cfg(ppd, HFI1_IB_CFG_SPD_ENB, s);\n}\n\nstatic int check_mkey(struct hfi1_ibport *ibp, struct ib_mad_hdr *mad,\n\t\t      int mad_flags, __be64 mkey, __be32 dr_slid,\n\t\t      u8 return_path[], u8 hop_cnt)\n{\n\tint valid_mkey = 0;\n\tint ret = 0;\n\n\t \n\tif (ibp->rvp.mkey_lease_timeout &&\n\t    time_after_eq(jiffies, ibp->rvp.mkey_lease_timeout)) {\n\t\t \n\t\tibp->rvp.mkey_lease_timeout = 0;\n\t\tibp->rvp.mkeyprot = 0;\n\t}\n\n\tif ((mad_flags & IB_MAD_IGNORE_MKEY) ||  ibp->rvp.mkey == 0 ||\n\t    ibp->rvp.mkey == mkey)\n\t\tvalid_mkey = 1;\n\n\t \n\tif (valid_mkey && ibp->rvp.mkey_lease_timeout &&\n\t    (mad->method == IB_MGMT_METHOD_GET ||\n\t     mad->method == IB_MGMT_METHOD_SET ||\n\t     mad->method == IB_MGMT_METHOD_TRAP_REPRESS))\n\t\tibp->rvp.mkey_lease_timeout = 0;\n\n\tif (!valid_mkey) {\n\t\tswitch (mad->method) {\n\t\tcase IB_MGMT_METHOD_GET:\n\t\t\t \n\t\t\tif (ibp->rvp.mkeyprot < 2)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tcase IB_MGMT_METHOD_SET:\n\t\tcase IB_MGMT_METHOD_TRAP_REPRESS:\n\t\t\tif (ibp->rvp.mkey_violations != 0xFFFF)\n\t\t\t\t++ibp->rvp.mkey_violations;\n\t\t\tif (!ibp->rvp.mkey_lease_timeout &&\n\t\t\t    ibp->rvp.mkey_lease_period)\n\t\t\t\tibp->rvp.mkey_lease_timeout = jiffies +\n\t\t\t\t\tibp->rvp.mkey_lease_period * HZ;\n\t\t\t \n\t\t\tbad_mkey(ibp, mad, mkey, dr_slid, return_path,\n\t\t\t\t hop_cnt);\n\t\t\tret = 1;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\n \nstruct lcb_datum {\n\tu32 off;\n\tu64 val;\n};\n\nstatic struct lcb_datum lcb_cache[] = {\n\t{ DC_LCB_STS_ROUND_TRIP_LTP_CNT, 0 },\n};\n\nstatic int write_lcb_cache(u32 off, u64 val)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(lcb_cache); i++) {\n\t\tif (lcb_cache[i].off == off) {\n\t\t\tlcb_cache[i].val = val;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tpr_warn(\"%s bad offset 0x%x\\n\", __func__, off);\n\treturn -1;\n}\n\nstatic int read_lcb_cache(u32 off, u64 *val)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(lcb_cache); i++) {\n\t\tif (lcb_cache[i].off == off) {\n\t\t\t*val = lcb_cache[i].val;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tpr_warn(\"%s bad offset 0x%x\\n\", __func__, off);\n\treturn -1;\n}\n\nvoid read_ltp_rtt(struct hfi1_devdata *dd)\n{\n\tu64 reg;\n\n\tif (read_lcb_csr(dd, DC_LCB_STS_ROUND_TRIP_LTP_CNT, &reg))\n\t\tdd_dev_err(dd, \"%s: unable to read LTP RTT\\n\", __func__);\n\telse\n\t\twrite_lcb_cache(DC_LCB_STS_ROUND_TRIP_LTP_CNT, reg);\n}\n\nstatic int __subn_get_opa_portinfo(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tint i;\n\tstruct hfi1_devdata *dd;\n\tstruct hfi1_pportdata *ppd;\n\tstruct hfi1_ibport *ibp;\n\tstruct opa_port_info *pi = (struct opa_port_info *)data;\n\tu8 mtu;\n\tu8 credit_rate;\n\tu8 is_beaconing_active;\n\tu32 state;\n\tu32 num_ports = OPA_AM_NPORT(am);\n\tu32 start_of_sm_config = OPA_AM_START_SM_CFG(am);\n\tu32 buffer_units;\n\tu64 tmp = 0;\n\n\tif (num_ports != 1 || smp_length_check(sizeof(*pi), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tdd = dd_from_ibdev(ibdev);\n\t \n\tppd = dd->pport + (port - 1);\n\tibp = &ppd->ibport_data;\n\n\tif (ppd->vls_supported / 2 > ARRAY_SIZE(pi->neigh_mtu.pvlx_to_mtu) ||\n\t    ppd->vls_supported > ARRAY_SIZE(dd->vld)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tpi->lid = cpu_to_be32(ppd->lid);\n\n\t \n\tif (!(smp->method == IB_MGMT_METHOD_GET &&\n\t      ibp->rvp.mkey != smp->mkey &&\n\t      ibp->rvp.mkeyprot == 1))\n\t\tpi->mkey = ibp->rvp.mkey;\n\n\tpi->subnet_prefix = ibp->rvp.gid_prefix;\n\tpi->sm_lid = cpu_to_be32(ibp->rvp.sm_lid);\n\tpi->ib_cap_mask = cpu_to_be32(ibp->rvp.port_cap_flags);\n\tpi->mkey_lease_period = cpu_to_be16(ibp->rvp.mkey_lease_period);\n\tpi->sm_trap_qp = cpu_to_be32(ppd->sm_trap_qp);\n\tpi->sa_qp = cpu_to_be32(ppd->sa_qp);\n\n\tpi->link_width.enabled = cpu_to_be16(ppd->link_width_enabled);\n\tpi->link_width.supported = cpu_to_be16(ppd->link_width_supported);\n\tpi->link_width.active = cpu_to_be16(ppd->link_width_active);\n\n\tpi->link_width_downgrade.supported =\n\t\t\tcpu_to_be16(ppd->link_width_downgrade_supported);\n\tpi->link_width_downgrade.enabled =\n\t\t\tcpu_to_be16(ppd->link_width_downgrade_enabled);\n\tpi->link_width_downgrade.tx_active =\n\t\t\tcpu_to_be16(ppd->link_width_downgrade_tx_active);\n\tpi->link_width_downgrade.rx_active =\n\t\t\tcpu_to_be16(ppd->link_width_downgrade_rx_active);\n\n\tpi->link_speed.supported = cpu_to_be16(ppd->link_speed_supported);\n\tpi->link_speed.active = cpu_to_be16(ppd->link_speed_active);\n\tpi->link_speed.enabled = cpu_to_be16(ppd->link_speed_enabled);\n\n\tstate = driver_lstate(ppd);\n\n\tif (start_of_sm_config && (state == IB_PORT_INIT))\n\t\tppd->is_sm_config_started = 1;\n\n\tpi->port_phys_conf = (ppd->port_type & 0xf);\n\n\tpi->port_states.ledenable_offlinereason = ppd->neighbor_normal << 4;\n\tpi->port_states.ledenable_offlinereason |=\n\t\tppd->is_sm_config_started << 5;\n\t \n\tsmp_rmb();\n\tis_beaconing_active = !!atomic_read(&ppd->led_override_timer_active);\n\tpi->port_states.ledenable_offlinereason |= is_beaconing_active << 6;\n\tpi->port_states.ledenable_offlinereason |=\n\t\tppd->offline_disabled_reason;\n\n\tpi->port_states.portphysstate_portstate =\n\t\t(driver_pstate(ppd) << 4) | state;\n\n\tpi->mkeyprotect_lmc = (ibp->rvp.mkeyprot << 6) | ppd->lmc;\n\n\tmemset(pi->neigh_mtu.pvlx_to_mtu, 0, sizeof(pi->neigh_mtu.pvlx_to_mtu));\n\tfor (i = 0; i < ppd->vls_supported; i++) {\n\t\tmtu = mtu_to_enum(dd->vld[i].mtu, HFI1_DEFAULT_ACTIVE_MTU);\n\t\tif ((i % 2) == 0)\n\t\t\tpi->neigh_mtu.pvlx_to_mtu[i / 2] |= (mtu << 4);\n\t\telse\n\t\t\tpi->neigh_mtu.pvlx_to_mtu[i / 2] |= mtu;\n\t}\n\t \n\tmtu = mtu_to_enum(dd->vld[15].mtu, 2048);\n\tpi->neigh_mtu.pvlx_to_mtu[15 / 2] |= mtu;\n\tpi->smsl = ibp->rvp.sm_sl & OPA_PI_MASK_SMSL;\n\tpi->operational_vls = hfi1_get_ib_cfg(ppd, HFI1_IB_CFG_OP_VLS);\n\tpi->partenforce_filterraw |=\n\t\t(ppd->linkinit_reason & OPA_PI_MASK_LINKINIT_REASON);\n\tif (ppd->part_enforce & HFI1_PART_ENFORCE_IN)\n\t\tpi->partenforce_filterraw |= OPA_PI_MASK_PARTITION_ENFORCE_IN;\n\tif (ppd->part_enforce & HFI1_PART_ENFORCE_OUT)\n\t\tpi->partenforce_filterraw |= OPA_PI_MASK_PARTITION_ENFORCE_OUT;\n\tpi->mkey_violations = cpu_to_be16(ibp->rvp.mkey_violations);\n\t \n\tpi->pkey_violations = cpu_to_be16(ibp->rvp.pkey_violations);\n\tpi->qkey_violations = cpu_to_be16(ibp->rvp.qkey_violations);\n\n\tpi->vl.cap = ppd->vls_supported;\n\tpi->vl.high_limit = cpu_to_be16(ibp->rvp.vl_high_limit);\n\tpi->vl.arb_high_cap = (u8)hfi1_get_ib_cfg(ppd, HFI1_IB_CFG_VL_HIGH_CAP);\n\tpi->vl.arb_low_cap = (u8)hfi1_get_ib_cfg(ppd, HFI1_IB_CFG_VL_LOW_CAP);\n\n\tpi->clientrereg_subnettimeout = ibp->rvp.subnet_timeout;\n\n\tpi->port_link_mode  = cpu_to_be16(OPA_PORT_LINK_MODE_OPA << 10 |\n\t\t\t\t\t  OPA_PORT_LINK_MODE_OPA << 5 |\n\t\t\t\t\t  OPA_PORT_LINK_MODE_OPA);\n\n\tpi->port_ltp_crc_mode = cpu_to_be16(ppd->port_ltp_crc_mode);\n\n\tpi->port_mode = cpu_to_be16(\n\t\t\t\tppd->is_active_optimize_enabled ?\n\t\t\t\t\tOPA_PI_MASK_PORT_ACTIVE_OPTOMIZE : 0);\n\n\tpi->port_packet_format.supported =\n\t\tcpu_to_be16(OPA_PORT_PACKET_FORMAT_9B |\n\t\t\t    OPA_PORT_PACKET_FORMAT_16B);\n\tpi->port_packet_format.enabled =\n\t\tcpu_to_be16(OPA_PORT_PACKET_FORMAT_9B |\n\t\t\t    OPA_PORT_PACKET_FORMAT_16B);\n\n\t \n\tpi->flit_control.interleave = cpu_to_be16(0x1400);\n\n\tpi->link_down_reason = ppd->local_link_down_reason.sma;\n\tpi->neigh_link_down_reason = ppd->neigh_link_down_reason.sma;\n\tpi->port_error_action = cpu_to_be32(ppd->port_error_action);\n\tpi->mtucap = mtu_to_enum(hfi1_max_mtu, IB_MTU_4096);\n\n\t \n\tpi->resptimevalue = 3;\n\n\tpi->local_port_num = port;\n\n\t \n\tpi->overall_buffer_space = cpu_to_be16(dd->link_credits);\n\n\tpi->neigh_node_guid = cpu_to_be64(ppd->neighbor_guid);\n\tpi->neigh_port_num = ppd->neighbor_port_number;\n\tpi->port_neigh_mode =\n\t\t(ppd->neighbor_type & OPA_PI_MASK_NEIGH_NODE_TYPE) |\n\t\t(ppd->mgmt_allowed ? OPA_PI_MASK_NEIGH_MGMT_ALLOWED : 0) |\n\t\t(ppd->neighbor_fm_security ?\n\t\t\tOPA_PI_MASK_NEIGH_FW_AUTH_BYPASS : 0);\n\n\t \n\tcredit_rate = 0;\n\tbuffer_units  = (dd->vau) & OPA_PI_MASK_BUF_UNIT_BUF_ALLOC;\n\tbuffer_units |= (dd->vcu << 3) & OPA_PI_MASK_BUF_UNIT_CREDIT_ACK;\n\tbuffer_units |= (credit_rate << 6) &\n\t\t\t\tOPA_PI_MASK_BUF_UNIT_VL15_CREDIT_RATE;\n\tbuffer_units |= (dd->vl15_init << 11) & OPA_PI_MASK_BUF_UNIT_VL15_INIT;\n\tpi->buffer_units = cpu_to_be32(buffer_units);\n\n\tpi->opa_cap_mask = cpu_to_be16(ibp->rvp.port_cap3_flags);\n\tpi->collectivemask_multicastmask = ((OPA_COLLECTIVE_NR & 0x7)\n\t\t\t\t\t    << 3 | (OPA_MCAST_NR & 0x7));\n\n\t \n\tpi->replay_depth.buffer = 0x80;\n\t \n\tread_lcb_cache(DC_LCB_STS_ROUND_TRIP_LTP_CNT, &tmp);\n\n\t \n\tif (tmp > 0xff)\n\t\ttmp = 0xff;\n\tpi->replay_depth.wire = tmp;\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(struct opa_port_info);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\n \nstatic int get_pkeys(struct hfi1_devdata *dd, u32 port, u16 *pkeys)\n{\n\tstruct hfi1_pportdata *ppd = dd->pport + port - 1;\n\n\tmemcpy(pkeys, ppd->pkeys, sizeof(ppd->pkeys));\n\n\treturn 0;\n}\n\nstatic int __subn_get_opa_pkeytable(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t    struct ib_device *ibdev, u32 port,\n\t\t\t\t    u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 n_blocks_req = OPA_AM_NBLK(am);\n\tu32 start_block = am & 0x7ff;\n\t__be16 *p;\n\tu16 *q;\n\tint i;\n\tu16 n_blocks_avail;\n\tunsigned npkeys = hfi1_get_npkeys(dd);\n\tsize_t size;\n\n\tif (n_blocks_req == 0) {\n\t\tpr_warn(\"OPA Get PKey AM Invalid : P = %d; B = 0x%x; N = 0x%x\\n\",\n\t\t\tport, start_block, n_blocks_req);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tn_blocks_avail = (u16)(npkeys / OPA_PARTITION_TABLE_BLK_SIZE) + 1;\n\n\tsize = (n_blocks_req * OPA_PARTITION_TABLE_BLK_SIZE) * sizeof(u16);\n\n\tif (smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tif (start_block + n_blocks_req > n_blocks_avail ||\n\t    n_blocks_req > OPA_NUM_PKEY_BLOCKS_PER_SMP) {\n\t\tpr_warn(\"OPA Get PKey AM Invalid : s 0x%x; req 0x%x; \"\n\t\t\t\"avail 0x%x; blk/smp 0x%lx\\n\",\n\t\t\tstart_block, n_blocks_req, n_blocks_avail,\n\t\t\tOPA_NUM_PKEY_BLOCKS_PER_SMP);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tp = (__be16 *)data;\n\tq = (u16 *)data;\n\t \n\tif (start_block == 0) {\n\t\tget_pkeys(dd, port, q);\n\t\tfor (i = 0; i < npkeys; i++)\n\t\t\tp[i] = cpu_to_be16(q[i]);\n\t\tif (resp_len)\n\t\t\t*resp_len += size;\n\t} else {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t}\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nenum {\n\tHFI_TRANSITION_DISALLOWED,\n\tHFI_TRANSITION_IGNORED,\n\tHFI_TRANSITION_ALLOWED,\n\tHFI_TRANSITION_UNDEFINED,\n};\n\n \nenum {\n\t__D = HFI_TRANSITION_DISALLOWED,\n\t__I = HFI_TRANSITION_IGNORED,\n\t__A = HFI_TRANSITION_ALLOWED,\n\t__U = HFI_TRANSITION_UNDEFINED,\n};\n\n \n#define __N_PHYSTATES (OPA_PORTPHYSSTATE_MAX - IB_PORTPHYSSTATE_POLLING + 1)\n\n \nstatic const struct {\n\tu8 allowed[__N_PHYSTATES][__N_PHYSTATES];\n} physical_state_transitions = {\n\t{\n\t\t \n\t \t{ __A, __A, __D, __D, __D, __D, __D, __D, __D, __D },\n\t \t{ __A, __I, __D, __D, __D, __D, __D, __D, __D, __A },\n\t \t{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },\n\t \t{ __A, __A, __D, __I, __D, __D, __D, __D, __D, __D },\n\t \t{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },\n\t \t{ __D, __A, __D, __D, __D, __I, __D, __D, __D, __D },\n\t \t{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },\n\t \t{ __I, __A, __D, __D, __D, __D, __D, __I, __D, __D },\n\t \t{ __U, __U, __U, __U, __U, __U, __U, __U, __U, __U },\n\t \t{ __D, __A, __D, __D, __D, __D, __D, __D, __D, __I },\n\t}\n};\n\n \n\n#define __N_LOGICAL_STATES (IB_PORT_ACTIVE_DEFER - IB_PORT_DOWN + 1)\n\n \nstatic const struct {\n\tu8 allowed[__N_LOGICAL_STATES][__N_LOGICAL_STATES];\n} logical_state_transitions = {\n\t{\n\t\t \n\t \t{ __I, __D, __D, __D, __U},\n\t \t{ __D, __I, __A, __D, __U},\n\t \t{ __D, __D, __I, __A, __U},\n\t \t{ __D, __D, __I, __I, __U},\n\t \t{ __U, __U, __U, __U, __U},\n\t}\n};\n\nstatic int logical_transition_allowed(int old, int new)\n{\n\tif (old < IB_PORT_NOP || old > IB_PORT_ACTIVE_DEFER ||\n\t    new < IB_PORT_NOP || new > IB_PORT_ACTIVE_DEFER) {\n\t\tpr_warn(\"invalid logical state(s) (old %d new %d)\\n\",\n\t\t\told, new);\n\t\treturn HFI_TRANSITION_UNDEFINED;\n\t}\n\n\tif (new == IB_PORT_NOP)\n\t\treturn HFI_TRANSITION_ALLOWED;  \n\n\t \n\told -= IB_PORT_DOWN;\n\tnew -= IB_PORT_DOWN;\n\n\tif (old < 0 || new < 0)\n\t\treturn HFI_TRANSITION_UNDEFINED;\n\treturn logical_state_transitions.allowed[old][new];\n}\n\nstatic int physical_transition_allowed(int old, int new)\n{\n\tif (old < IB_PORTPHYSSTATE_NOP || old > OPA_PORTPHYSSTATE_MAX ||\n\t    new < IB_PORTPHYSSTATE_NOP || new > OPA_PORTPHYSSTATE_MAX) {\n\t\tpr_warn(\"invalid physical state(s) (old %d new %d)\\n\",\n\t\t\told, new);\n\t\treturn HFI_TRANSITION_UNDEFINED;\n\t}\n\n\tif (new == IB_PORTPHYSSTATE_NOP)\n\t\treturn HFI_TRANSITION_ALLOWED;  \n\n\t \n\told -= IB_PORTPHYSSTATE_POLLING;\n\tnew -= IB_PORTPHYSSTATE_POLLING;\n\n\tif (old < 0 || new < 0)\n\t\treturn HFI_TRANSITION_UNDEFINED;\n\treturn physical_state_transitions.allowed[old][new];\n}\n\nstatic int port_states_transition_allowed(struct hfi1_pportdata *ppd,\n\t\t\t\t\t  u32 logical_new, u32 physical_new)\n{\n\tu32 physical_old = driver_pstate(ppd);\n\tu32 logical_old = driver_lstate(ppd);\n\tint ret, logical_allowed, physical_allowed;\n\n\tret = logical_transition_allowed(logical_old, logical_new);\n\tlogical_allowed = ret;\n\n\tif (ret == HFI_TRANSITION_DISALLOWED ||\n\t    ret == HFI_TRANSITION_UNDEFINED) {\n\t\tpr_warn(\"invalid logical state transition %s -> %s\\n\",\n\t\t\topa_lstate_name(logical_old),\n\t\t\topa_lstate_name(logical_new));\n\t\treturn ret;\n\t}\n\n\tret = physical_transition_allowed(physical_old, physical_new);\n\tphysical_allowed = ret;\n\n\tif (ret == HFI_TRANSITION_DISALLOWED ||\n\t    ret == HFI_TRANSITION_UNDEFINED) {\n\t\tpr_warn(\"invalid physical state transition %s -> %s\\n\",\n\t\t\topa_pstate_name(physical_old),\n\t\t\topa_pstate_name(physical_new));\n\t\treturn ret;\n\t}\n\n\tif (logical_allowed == HFI_TRANSITION_IGNORED &&\n\t    physical_allowed == HFI_TRANSITION_IGNORED)\n\t\treturn HFI_TRANSITION_IGNORED;\n\n\t \n\tif ((physical_old == OPA_PORTPHYSSTATE_OFFLINE) &&\n\t    (physical_new == IB_PORTPHYSSTATE_POLLING))\n\t\treturn HFI_TRANSITION_IGNORED;\n\n\t \n\treturn HFI_TRANSITION_ALLOWED;\n}\n\nstatic int set_port_states(struct hfi1_pportdata *ppd, struct opa_smp *smp,\n\t\t\t   u32 logical_state, u32 phys_state, int local_mad)\n{\n\tstruct hfi1_devdata *dd = ppd->dd;\n\tu32 link_state;\n\tint ret;\n\n\tret = port_states_transition_allowed(ppd, logical_state, phys_state);\n\tif (ret == HFI_TRANSITION_DISALLOWED ||\n\t    ret == HFI_TRANSITION_UNDEFINED) {\n\t\t \n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn 0;\n\t}\n\n\tif (ret == HFI_TRANSITION_IGNORED)\n\t\treturn 0;\n\n\tif ((phys_state != IB_PORTPHYSSTATE_NOP) &&\n\t    !(logical_state == IB_PORT_DOWN ||\n\t      logical_state == IB_PORT_NOP)){\n\t\tpr_warn(\"SubnSet(OPA_PortInfo) port state invalid: logical_state 0x%x physical_state 0x%x\\n\",\n\t\t\tlogical_state, phys_state);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t}\n\n\t \n\tswitch (logical_state) {\n\tcase IB_PORT_NOP:\n\t\tif (phys_state == IB_PORTPHYSSTATE_NOP)\n\t\t\tbreak;\n\t\tfallthrough;\n\tcase IB_PORT_DOWN:\n\t\tif (phys_state == IB_PORTPHYSSTATE_NOP) {\n\t\t\tlink_state = HLS_DN_DOWNDEF;\n\t\t} else if (phys_state == IB_PORTPHYSSTATE_POLLING) {\n\t\t\tlink_state = HLS_DN_POLL;\n\t\t\tset_link_down_reason(ppd, OPA_LINKDOWN_REASON_FM_BOUNCE,\n\t\t\t\t\t     0, OPA_LINKDOWN_REASON_FM_BOUNCE);\n\t\t} else if (phys_state == IB_PORTPHYSSTATE_DISABLED) {\n\t\t\tlink_state = HLS_DN_DISABLE;\n\t\t} else {\n\t\t\tpr_warn(\"SubnSet(OPA_PortInfo) invalid physical state 0x%x\\n\",\n\t\t\t\tphys_state);\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((link_state == HLS_DN_POLL ||\n\t\t     link_state == HLS_DN_DOWNDEF)) {\n\t\t\t \n\t\t\tset_link_state(ppd, HLS_DN_OFFLINE);\n\t\t\tstart_link(ppd);\n\t\t} else {\n\t\t\tset_link_state(ppd, link_state);\n\t\t}\n\t\tif (link_state == HLS_DN_DISABLE &&\n\t\t    (ppd->offline_disabled_reason >\n\t\t     HFI1_ODR_MASK(OPA_LINKDOWN_REASON_SMA_DISABLED) ||\n\t\t     ppd->offline_disabled_reason ==\n\t\t     HFI1_ODR_MASK(OPA_LINKDOWN_REASON_NONE)))\n\t\t\tppd->offline_disabled_reason =\n\t\t\tHFI1_ODR_MASK(OPA_LINKDOWN_REASON_SMA_DISABLED);\n\t\t \n\t\tif (link_state == HLS_DN_DISABLE && !local_mad)\n\t\t\treturn IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_CONSUMED;\n\t\tbreak;\n\tcase IB_PORT_ARMED:\n\t\tret = set_link_state(ppd, HLS_UP_ARMED);\n\t\tif (!ret)\n\t\t\tsend_idle_sma(dd, SMA_IDLE_ARM);\n\t\tbreak;\n\tcase IB_PORT_ACTIVE:\n\t\tif (ppd->neighbor_normal) {\n\t\t\tret = set_link_state(ppd, HLS_UP_ACTIVE);\n\t\t\tif (ret == 0)\n\t\t\t\tsend_idle_sma(dd, SMA_IDLE_ACTIVE);\n\t\t} else {\n\t\t\tpr_warn(\"SubnSet(OPA_PortInfo) Cannot move to Active with NeighborNormal 0\\n\");\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"SubnSet(OPA_PortInfo) invalid logical state 0x%x\\n\",\n\t\t\tlogical_state);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int __subn_set_opa_portinfo(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len, int local_mad)\n{\n\tstruct opa_port_info *pi = (struct opa_port_info *)data;\n\tstruct ib_event event;\n\tstruct hfi1_devdata *dd;\n\tstruct hfi1_pportdata *ppd;\n\tstruct hfi1_ibport *ibp;\n\tu8 clientrereg;\n\tunsigned long flags;\n\tu32 smlid;\n\tu32 lid;\n\tu8 ls_old, ls_new, ps_new;\n\tu8 vls;\n\tu8 msl;\n\tu8 crc_enabled;\n\tu16 lse, lwe, mtu;\n\tu32 num_ports = OPA_AM_NPORT(am);\n\tu32 start_of_sm_config = OPA_AM_START_SM_CFG(am);\n\tint ret, i, invalid = 0, call_set_mtu = 0;\n\tint call_link_downgrade_policy = 0;\n\n\tif (num_ports != 1 ||\n\t    smp_length_check(sizeof(*pi), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tlid = be32_to_cpu(pi->lid);\n\tif (lid & 0xFF000000) {\n\t\tpr_warn(\"OPA_PortInfo lid out of range: %X\\n\", lid);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\tgoto get_only;\n\t}\n\n\n\tsmlid = be32_to_cpu(pi->sm_lid);\n\tif (smlid & 0xFF000000) {\n\t\tpr_warn(\"OPA_PortInfo SM lid out of range: %X\\n\", smlid);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\tgoto get_only;\n\t}\n\n\tclientrereg = (pi->clientrereg_subnettimeout &\n\t\t\tOPA_PI_MASK_CLIENT_REREGISTER);\n\n\tdd = dd_from_ibdev(ibdev);\n\t \n\tppd = dd->pport + (port - 1);\n\tibp = &ppd->ibport_data;\n\tevent.device = ibdev;\n\tevent.element.port_num = port;\n\n\tls_old = driver_lstate(ppd);\n\n\tibp->rvp.mkey = pi->mkey;\n\tif (ibp->rvp.gid_prefix != pi->subnet_prefix) {\n\t\tibp->rvp.gid_prefix = pi->subnet_prefix;\n\t\tevent.event = IB_EVENT_GID_CHANGE;\n\t\tib_dispatch_event(&event);\n\t}\n\tibp->rvp.mkey_lease_period = be16_to_cpu(pi->mkey_lease_period);\n\n\t \n\tif ((lid == 0 && ls_old > IB_PORT_INIT) ||\n\t     (hfi1_is_16B_mcast(lid))) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\tpr_warn(\"SubnSet(OPA_PortInfo) lid invalid 0x%x\\n\",\n\t\t\tlid);\n\t} else if (ppd->lid != lid ||\n\t\t ppd->lmc != (pi->mkeyprotect_lmc & OPA_PI_MASK_LMC)) {\n\t\tif (ppd->lid != lid)\n\t\t\thfi1_set_uevent_bits(ppd, _HFI1_EVENT_LID_CHANGE_BIT);\n\t\tif (ppd->lmc != (pi->mkeyprotect_lmc & OPA_PI_MASK_LMC))\n\t\t\thfi1_set_uevent_bits(ppd, _HFI1_EVENT_LMC_CHANGE_BIT);\n\t\thfi1_set_lid(ppd, lid, pi->mkeyprotect_lmc & OPA_PI_MASK_LMC);\n\t\tevent.event = IB_EVENT_LID_CHANGE;\n\t\tib_dispatch_event(&event);\n\n\t\tif (HFI1_PORT_GUID_INDEX + 1 < HFI1_GUIDS_PER_PORT) {\n\t\t\t \n\t\t\tppd->guids[HFI1_PORT_GUID_INDEX + 1] =\n\t\t\t\tbe64_to_cpu(OPA_MAKE_ID(lid));\n\t\t\tevent.event = IB_EVENT_GID_CHANGE;\n\t\t\tib_dispatch_event(&event);\n\t\t}\n\t}\n\n\tmsl = pi->smsl & OPA_PI_MASK_SMSL;\n\tif (pi->partenforce_filterraw & OPA_PI_MASK_LINKINIT_REASON)\n\t\tppd->linkinit_reason =\n\t\t\t(pi->partenforce_filterraw &\n\t\t\t OPA_PI_MASK_LINKINIT_REASON);\n\n\t \n\tif ((smlid == 0 && ls_old > IB_PORT_INIT) ||\n\t     (hfi1_is_16B_mcast(smlid))) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\tpr_warn(\"SubnSet(OPA_PortInfo) smlid invalid 0x%x\\n\", smlid);\n\t} else if (smlid != ibp->rvp.sm_lid || msl != ibp->rvp.sm_sl) {\n\t\tpr_warn(\"SubnSet(OPA_PortInfo) smlid 0x%x\\n\", smlid);\n\t\tspin_lock_irqsave(&ibp->rvp.lock, flags);\n\t\tif (ibp->rvp.sm_ah) {\n\t\t\tif (smlid != ibp->rvp.sm_lid)\n\t\t\t\thfi1_modify_qp0_ah(ibp, ibp->rvp.sm_ah, smlid);\n\t\t\tif (msl != ibp->rvp.sm_sl)\n\t\t\t\trdma_ah_set_sl(&ibp->rvp.sm_ah->attr, msl);\n\t\t}\n\t\tspin_unlock_irqrestore(&ibp->rvp.lock, flags);\n\t\tif (smlid != ibp->rvp.sm_lid)\n\t\t\tibp->rvp.sm_lid = smlid;\n\t\tif (msl != ibp->rvp.sm_sl)\n\t\t\tibp->rvp.sm_sl = msl;\n\t\tevent.event = IB_EVENT_SM_CHANGE;\n\t\tib_dispatch_event(&event);\n\t}\n\n\tif (pi->link_down_reason == 0) {\n\t\tppd->local_link_down_reason.sma = 0;\n\t\tppd->local_link_down_reason.latest = 0;\n\t}\n\n\tif (pi->neigh_link_down_reason == 0) {\n\t\tppd->neigh_link_down_reason.sma = 0;\n\t\tppd->neigh_link_down_reason.latest = 0;\n\t}\n\n\tppd->sm_trap_qp = be32_to_cpu(pi->sm_trap_qp);\n\tppd->sa_qp = be32_to_cpu(pi->sa_qp);\n\n\tppd->port_error_action = be32_to_cpu(pi->port_error_action);\n\tlwe = be16_to_cpu(pi->link_width.enabled);\n\tif (lwe) {\n\t\tif (lwe == OPA_LINK_WIDTH_RESET ||\n\t\t    lwe == OPA_LINK_WIDTH_RESET_OLD)\n\t\t\tset_link_width_enabled(ppd, ppd->link_width_supported);\n\t\telse if ((lwe & ~ppd->link_width_supported) == 0)\n\t\t\tset_link_width_enabled(ppd, lwe);\n\t\telse\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t}\n\tlwe = be16_to_cpu(pi->link_width_downgrade.enabled);\n\t \n\tif (lwe == OPA_LINK_WIDTH_RESET ||\n\t    lwe == OPA_LINK_WIDTH_RESET_OLD) {\n\t\tset_link_width_downgrade_enabled(ppd,\n\t\t\t\t\t\t ppd->\n\t\t\t\t\t\t link_width_downgrade_supported\n\t\t\t\t\t\t );\n\t} else if ((lwe & ~ppd->link_width_downgrade_supported) == 0) {\n\t\t \n\t\tif (lwe != ppd->link_width_downgrade_enabled) {\n\t\t\tset_link_width_downgrade_enabled(ppd, lwe);\n\t\t\tcall_link_downgrade_policy = 1;\n\t\t}\n\t} else {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t}\n\tlse = be16_to_cpu(pi->link_speed.enabled);\n\tif (lse) {\n\t\tif (lse & be16_to_cpu(pi->link_speed.supported))\n\t\t\tset_link_speed_enabled(ppd, lse);\n\t\telse\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t}\n\n\tibp->rvp.mkeyprot =\n\t\t(pi->mkeyprotect_lmc & OPA_PI_MASK_MKEY_PROT_BIT) >> 6;\n\tibp->rvp.vl_high_limit = be16_to_cpu(pi->vl.high_limit) & 0xFF;\n\t(void)hfi1_set_ib_cfg(ppd, HFI1_IB_CFG_VL_HIGH_LIMIT,\n\t\t\t\t    ibp->rvp.vl_high_limit);\n\n\tif (ppd->vls_supported / 2 > ARRAY_SIZE(pi->neigh_mtu.pvlx_to_mtu) ||\n\t    ppd->vls_supported > ARRAY_SIZE(dd->vld)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\tfor (i = 0; i < ppd->vls_supported; i++) {\n\t\tif ((i % 2) == 0)\n\t\t\tmtu = enum_to_mtu((pi->neigh_mtu.pvlx_to_mtu[i / 2] >>\n\t\t\t\t\t   4) & 0xF);\n\t\telse\n\t\t\tmtu = enum_to_mtu(pi->neigh_mtu.pvlx_to_mtu[i / 2] &\n\t\t\t\t\t  0xF);\n\t\tif (mtu == 0xffff) {\n\t\t\tpr_warn(\"SubnSet(OPA_PortInfo) mtu invalid %d (0x%x)\\n\",\n\t\t\t\tmtu,\n\t\t\t\t(pi->neigh_mtu.pvlx_to_mtu[0] >> 4) & 0xF);\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t\tmtu = hfi1_max_mtu;  \n\t\t}\n\t\tif (dd->vld[i].mtu != mtu) {\n\t\t\tdd_dev_info(dd,\n\t\t\t\t    \"MTU change on vl %d from %d to %d\\n\",\n\t\t\t\t    i, dd->vld[i].mtu, mtu);\n\t\t\tdd->vld[i].mtu = mtu;\n\t\t\tcall_set_mtu++;\n\t\t}\n\t}\n\t \n\tmtu = enum_to_mtu(pi->neigh_mtu.pvlx_to_mtu[15 / 2] & 0xF);\n\tif (mtu < 2048 || mtu == 0xffff)\n\t\tmtu = 2048;\n\tif (dd->vld[15].mtu != mtu) {\n\t\tdd_dev_info(dd,\n\t\t\t    \"MTU change on vl 15 from %d to %d\\n\",\n\t\t\t    dd->vld[15].mtu, mtu);\n\t\tdd->vld[15].mtu = mtu;\n\t\tcall_set_mtu++;\n\t}\n\tif (call_set_mtu)\n\t\tset_mtu(ppd);\n\n\t \n\tvls = pi->operational_vls & OPA_PI_MASK_OPERATIONAL_VL;\n\tif (vls) {\n\t\tif (vls > ppd->vls_supported) {\n\t\t\tpr_warn(\"SubnSet(OPA_PortInfo) VL's supported invalid %d\\n\",\n\t\t\t\tpi->operational_vls);\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t} else {\n\t\t\tif (hfi1_set_ib_cfg(ppd, HFI1_IB_CFG_OP_VLS,\n\t\t\t\t\t    vls) == -EINVAL)\n\t\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t}\n\t}\n\n\tif (pi->mkey_violations == 0)\n\t\tibp->rvp.mkey_violations = 0;\n\n\tif (pi->pkey_violations == 0)\n\t\tibp->rvp.pkey_violations = 0;\n\n\tif (pi->qkey_violations == 0)\n\t\tibp->rvp.qkey_violations = 0;\n\n\tibp->rvp.subnet_timeout =\n\t\tpi->clientrereg_subnettimeout & OPA_PI_MASK_SUBNET_TIMEOUT;\n\n\tcrc_enabled = be16_to_cpu(pi->port_ltp_crc_mode);\n\tcrc_enabled >>= 4;\n\tcrc_enabled &= 0xf;\n\n\tif (crc_enabled != 0)\n\t\tppd->port_crc_mode_enabled = port_ltp_to_cap(crc_enabled);\n\n\tppd->is_active_optimize_enabled =\n\t\t\t!!(be16_to_cpu(pi->port_mode)\n\t\t\t\t\t& OPA_PI_MASK_PORT_ACTIVE_OPTOMIZE);\n\n\tls_new = pi->port_states.portphysstate_portstate &\n\t\t\tOPA_PI_MASK_PORT_STATE;\n\tps_new = (pi->port_states.portphysstate_portstate &\n\t\t\tOPA_PI_MASK_PORT_PHYSICAL_STATE) >> 4;\n\n\tif (ls_old == IB_PORT_INIT) {\n\t\tif (start_of_sm_config) {\n\t\t\tif (ls_new == ls_old || (ls_new == IB_PORT_ARMED))\n\t\t\t\tppd->is_sm_config_started = 1;\n\t\t} else if (ls_new == IB_PORT_ARMED) {\n\t\t\tif (ppd->is_sm_config_started == 0) {\n\t\t\t\tinvalid = 1;\n\t\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (clientrereg) {\n\t\tevent.event = IB_EVENT_CLIENT_REREGISTER;\n\t\tib_dispatch_event(&event);\n\t}\n\n\t \n\n\tif (!invalid) {\n\t\tret = set_port_states(ppd, smp, ls_new, ps_new, local_mad);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = __subn_get_opa_portinfo(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t      max_len);\n\n\t \n\tpi->clientrereg_subnettimeout |= clientrereg;\n\n\t \n\tif (call_link_downgrade_policy)\n\t\tapply_link_downgrade_policy(ppd, 0);\n\n\treturn ret;\n\nget_only:\n\treturn __subn_get_opa_portinfo(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t       max_len);\n}\n\n \nstatic int set_pkeys(struct hfi1_devdata *dd, u32 port, u16 *pkeys)\n{\n\tstruct hfi1_pportdata *ppd;\n\tint i;\n\tint changed = 0;\n\tint update_includes_mgmt_partition = 0;\n\n\t \n\tppd = dd->pport + (port - 1);\n\t \n\tfor (i = 0; i < ARRAY_SIZE(ppd->pkeys); i++) {\n\t\tif (pkeys[i] == LIM_MGMT_P_KEY) {\n\t\t\tupdate_includes_mgmt_partition = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!update_includes_mgmt_partition)\n\t\treturn 1;\n\n\tfor (i = 0; i < ARRAY_SIZE(ppd->pkeys); i++) {\n\t\tu16 key = pkeys[i];\n\t\tu16 okey = ppd->pkeys[i];\n\n\t\tif (key == okey)\n\t\t\tcontinue;\n\t\t \n\t\tppd->pkeys[i] = key;\n\t\tchanged = 1;\n\t}\n\n\tif (changed) {\n\t\t(void)hfi1_set_ib_cfg(ppd, HFI1_IB_CFG_PKEYS, 0);\n\t\thfi1_event_pkey_change(dd, port);\n\t}\n\n\treturn 0;\n}\n\nstatic int __subn_set_opa_pkeytable(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t    struct ib_device *ibdev, u32 port,\n\t\t\t\t    u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 n_blocks_sent = OPA_AM_NBLK(am);\n\tu32 start_block = am & 0x7ff;\n\tu16 *p = (u16 *)data;\n\t__be16 *q = (__be16 *)data;\n\tint i;\n\tu16 n_blocks_avail;\n\tunsigned npkeys = hfi1_get_npkeys(dd);\n\tu32 size = 0;\n\n\tif (n_blocks_sent == 0) {\n\t\tpr_warn(\"OPA Get PKey AM Invalid : P = %u; B = 0x%x; N = 0x%x\\n\",\n\t\t\tport, start_block, n_blocks_sent);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tn_blocks_avail = (u16)(npkeys / OPA_PARTITION_TABLE_BLK_SIZE) + 1;\n\n\tsize = sizeof(u16) * (n_blocks_sent * OPA_PARTITION_TABLE_BLK_SIZE);\n\n\tif (smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tif (start_block + n_blocks_sent > n_blocks_avail ||\n\t    n_blocks_sent > OPA_NUM_PKEY_BLOCKS_PER_SMP) {\n\t\tpr_warn(\"OPA Set PKey AM Invalid : s 0x%x; req 0x%x; avail 0x%x; blk/smp 0x%lx\\n\",\n\t\t\tstart_block, n_blocks_sent, n_blocks_avail,\n\t\t\tOPA_NUM_PKEY_BLOCKS_PER_SMP);\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tfor (i = 0; i < n_blocks_sent * OPA_PARTITION_TABLE_BLK_SIZE; i++)\n\t\tp[i] = be16_to_cpu(q[i]);\n\n\tif (start_block == 0 && set_pkeys(dd, port, p) != 0) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\treturn __subn_get_opa_pkeytable(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t\tmax_len);\n}\n\n#define ILLEGAL_VL 12\n \nstatic void filter_sc2vlt(void *data, bool set)\n{\n\tint i;\n\tu8 *pd = data;\n\n\tfor (i = 0; i < OPA_MAX_SCS; i++) {\n\t\tif (i == 15)\n\t\t\tcontinue;\n\n\t\tif (set) {\n\t\t\tif ((pd[i] & 0x1f) == 0xf)\n\t\t\t\tpd[i] = ILLEGAL_VL;\n\t\t} else {\n\t\t\tif ((pd[i] & 0x1f) == ILLEGAL_VL)\n\t\t\t\tpd[i] = 0xf;\n\t\t}\n\t}\n}\n\nstatic int set_sc2vlt_tables(struct hfi1_devdata *dd, void *data)\n{\n\tu64 *val = data;\n\n\tfilter_sc2vlt(data, true);\n\n\twrite_csr(dd, SEND_SC2VLT0, *val++);\n\twrite_csr(dd, SEND_SC2VLT1, *val++);\n\twrite_csr(dd, SEND_SC2VLT2, *val++);\n\twrite_csr(dd, SEND_SC2VLT3, *val++);\n\twrite_seqlock_irq(&dd->sc2vl_lock);\n\tmemcpy(dd->sc2vl, data, sizeof(dd->sc2vl));\n\twrite_sequnlock_irq(&dd->sc2vl_lock);\n\treturn 0;\n}\n\nstatic int get_sc2vlt_tables(struct hfi1_devdata *dd, void *data)\n{\n\tu64 *val = (u64 *)data;\n\n\t*val++ = read_csr(dd, SEND_SC2VLT0);\n\t*val++ = read_csr(dd, SEND_SC2VLT1);\n\t*val++ = read_csr(dd, SEND_SC2VLT2);\n\t*val++ = read_csr(dd, SEND_SC2VLT3);\n\n\tfilter_sc2vlt((u64 *)data, false);\n\treturn 0;\n}\n\nstatic int __subn_get_opa_sl_to_sc(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tu8 *p = data;\n\tsize_t size = ARRAY_SIZE(ibp->sl_to_sc);  \n\tunsigned i;\n\n\tif (am || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(ibp->sl_to_sc); i++)\n\t\t*p++ = ibp->sl_to_sc[i];\n\n\tif (resp_len)\n\t\t*resp_len += size;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_sl_to_sc(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tu8 *p = data;\n\tsize_t size = ARRAY_SIZE(ibp->sl_to_sc);\n\tint i;\n\tu8 sc;\n\n\tif (am || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tfor (i = 0; i <  ARRAY_SIZE(ibp->sl_to_sc); i++) {\n\t\tsc = *p++;\n\t\tif (ibp->sl_to_sc[i] != sc) {\n\t\t\tibp->sl_to_sc[i] = sc;\n\n\t\t\t \n\t\t\thfi1_error_port_qps(ibp, i);\n\t\t}\n\t}\n\n\treturn __subn_get_opa_sl_to_sc(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t       max_len);\n}\n\nstatic int __subn_get_opa_sc_to_sl(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tu8 *p = data;\n\tsize_t size = ARRAY_SIZE(ibp->sc_to_sl);  \n\tunsigned i;\n\n\tif (am || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(ibp->sc_to_sl); i++)\n\t\t*p++ = ibp->sc_to_sl[i];\n\n\tif (resp_len)\n\t\t*resp_len += size;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_sc_to_sl(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tsize_t size = ARRAY_SIZE(ibp->sc_to_sl);\n\tu8 *p = data;\n\tint i;\n\n\tif (am || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(ibp->sc_to_sl); i++)\n\t\tibp->sc_to_sl[i] = *p++;\n\n\treturn __subn_get_opa_sc_to_sl(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t       max_len);\n}\n\nstatic int __subn_get_opa_sc_to_vlt(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t    struct ib_device *ibdev, u32 port,\n\t\t\t\t    u32 *resp_len, u32 max_len)\n{\n\tu32 n_blocks = OPA_AM_NBLK(am);\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tvoid *vp = (void *)data;\n\tsize_t size = 4 * sizeof(u64);\n\n\tif (n_blocks != 1 || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tget_sc2vlt_tables(dd, vp);\n\n\tif (resp_len)\n\t\t*resp_len += size;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_sc_to_vlt(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t    struct ib_device *ibdev, u32 port,\n\t\t\t\t    u32 *resp_len, u32 max_len)\n{\n\tu32 n_blocks = OPA_AM_NBLK(am);\n\tint async_update = OPA_AM_ASYNC(am);\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tvoid *vp = (void *)data;\n\tstruct hfi1_pportdata *ppd;\n\tint lstate;\n\t \n\tsize_t size = 4 * sizeof(u64);\n\n\tif (n_blocks != 1 || async_update || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\t \n\tppd = dd->pport + (port - 1);\n\tlstate = driver_lstate(ppd);\n\t \n\tif (!async_update &&\n\t    (lstate == IB_PORT_ARMED || lstate == IB_PORT_ACTIVE)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tset_sc2vlt_tables(dd, vp);\n\n\treturn __subn_get_opa_sc_to_vlt(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t\tmax_len);\n}\n\nstatic int __subn_get_opa_sc_to_vlnt(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t     struct ib_device *ibdev, u32 port,\n\t\t\t\t     u32 *resp_len, u32 max_len)\n{\n\tu32 n_blocks = OPA_AM_NPORT(am);\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_pportdata *ppd;\n\tvoid *vp = (void *)data;\n\tint size = sizeof(struct sc2vlnt);\n\n\tif (n_blocks != 1 || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tppd = dd->pport + (port - 1);\n\n\tfm_get_table(ppd, FM_TBL_SC2VLNT, vp);\n\n\tif (resp_len)\n\t\t*resp_len += size;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_sc_to_vlnt(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t     struct ib_device *ibdev, u32 port,\n\t\t\t\t     u32 *resp_len, u32 max_len)\n{\n\tu32 n_blocks = OPA_AM_NPORT(am);\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_pportdata *ppd;\n\tvoid *vp = (void *)data;\n\tint lstate;\n\tint size = sizeof(struct sc2vlnt);\n\n\tif (n_blocks != 1 || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\t \n\tppd = dd->pport + (port - 1);\n\tlstate = driver_lstate(ppd);\n\tif (lstate == IB_PORT_ARMED || lstate == IB_PORT_ACTIVE) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tppd = dd->pport + (port - 1);\n\n\tfm_set_table(ppd, FM_TBL_SC2VLNT, vp);\n\n\treturn __subn_get_opa_sc_to_vlnt(smp, am, data, ibdev, port,\n\t\t\t\t\t resp_len, max_len);\n}\n\nstatic int __subn_get_opa_psi(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t      struct ib_device *ibdev, u32 port,\n\t\t\t      u32 *resp_len, u32 max_len)\n{\n\tu32 nports = OPA_AM_NPORT(am);\n\tu32 start_of_sm_config = OPA_AM_START_SM_CFG(am);\n\tu32 lstate;\n\tstruct hfi1_ibport *ibp;\n\tstruct hfi1_pportdata *ppd;\n\tstruct opa_port_state_info *psi = (struct opa_port_state_info *)data;\n\n\tif (nports != 1 || smp_length_check(sizeof(*psi), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tibp = to_iport(ibdev, port);\n\tppd = ppd_from_ibp(ibp);\n\n\tlstate = driver_lstate(ppd);\n\n\tif (start_of_sm_config && (lstate == IB_PORT_INIT))\n\t\tppd->is_sm_config_started = 1;\n\n\tpsi->port_states.ledenable_offlinereason = ppd->neighbor_normal << 4;\n\tpsi->port_states.ledenable_offlinereason |=\n\t\tppd->is_sm_config_started << 5;\n\tpsi->port_states.ledenable_offlinereason |=\n\t\tppd->offline_disabled_reason;\n\n\tpsi->port_states.portphysstate_portstate =\n\t\t(driver_pstate(ppd) << 4) | (lstate & 0xf);\n\tpsi->link_width_downgrade_tx_active =\n\t\tcpu_to_be16(ppd->link_width_downgrade_tx_active);\n\tpsi->link_width_downgrade_rx_active =\n\t\tcpu_to_be16(ppd->link_width_downgrade_rx_active);\n\tif (resp_len)\n\t\t*resp_len += sizeof(struct opa_port_state_info);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_psi(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t      struct ib_device *ibdev, u32 port,\n\t\t\t      u32 *resp_len, u32 max_len, int local_mad)\n{\n\tu32 nports = OPA_AM_NPORT(am);\n\tu32 start_of_sm_config = OPA_AM_START_SM_CFG(am);\n\tu32 ls_old;\n\tu8 ls_new, ps_new;\n\tstruct hfi1_ibport *ibp;\n\tstruct hfi1_pportdata *ppd;\n\tstruct opa_port_state_info *psi = (struct opa_port_state_info *)data;\n\tint ret, invalid = 0;\n\n\tif (nports != 1 || smp_length_check(sizeof(*psi), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tibp = to_iport(ibdev, port);\n\tppd = ppd_from_ibp(ibp);\n\n\tls_old = driver_lstate(ppd);\n\n\tls_new = port_states_to_logical_state(&psi->port_states);\n\tps_new = port_states_to_phys_state(&psi->port_states);\n\n\tif (ls_old == IB_PORT_INIT) {\n\t\tif (start_of_sm_config) {\n\t\t\tif (ls_new == ls_old || (ls_new == IB_PORT_ARMED))\n\t\t\t\tppd->is_sm_config_started = 1;\n\t\t} else if (ls_new == IB_PORT_ARMED) {\n\t\t\tif (ppd->is_sm_config_started == 0) {\n\t\t\t\tinvalid = 1;\n\t\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!invalid) {\n\t\tret = set_port_states(ppd, smp, ls_new, ps_new, local_mad);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn __subn_get_opa_psi(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t  max_len);\n}\n\nstatic int __subn_get_opa_cable_info(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t     struct ib_device *ibdev, u32 port,\n\t\t\t\t     u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 addr = OPA_AM_CI_ADDR(am);\n\tu32 len = OPA_AM_CI_LEN(am) + 1;\n\tint ret;\n\n\tif (dd->pport->port_type != PORT_TYPE_QSFP ||\n\t    smp_length_check(len, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n#define __CI_PAGE_SIZE BIT(7)  \n#define __CI_PAGE_MASK ~(__CI_PAGE_SIZE - 1)\n#define __CI_PAGE_NUM(a) ((a) & __CI_PAGE_MASK)\n\n\t \n\tif (addr >= 4096 ||\n\t    (__CI_PAGE_NUM(addr) != __CI_PAGE_NUM(addr + len - 1))) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tret = get_cable_info(dd, port, addr, len, data);\n\n\tif (ret == -ENODEV) {\n\t\tsmp->status |= IB_SMP_UNSUP_METH_ATTR;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\t \n\tif (ret < 0 && ret != -ERANGE) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tif (resp_len)\n\t\t*resp_len += len;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_get_opa_bct(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t      struct ib_device *ibdev, u32 port, u32 *resp_len,\n\t\t\t      u32 max_len)\n{\n\tu32 num_ports = OPA_AM_NPORT(am);\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_pportdata *ppd;\n\tstruct buffer_control *p = (struct buffer_control *)data;\n\tint size = sizeof(struct buffer_control);\n\n\tif (num_ports != 1 || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tppd = dd->pport + (port - 1);\n\tfm_get_table(ppd, FM_TBL_BUFFER_CONTROL, p);\n\ttrace_bct_get(dd, p);\n\tif (resp_len)\n\t\t*resp_len += size;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_bct(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t      struct ib_device *ibdev, u32 port, u32 *resp_len,\n\t\t\t      u32 max_len)\n{\n\tu32 num_ports = OPA_AM_NPORT(am);\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_pportdata *ppd;\n\tstruct buffer_control *p = (struct buffer_control *)data;\n\n\tif (num_ports != 1 || smp_length_check(sizeof(*p), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\tppd = dd->pport + (port - 1);\n\ttrace_bct_set(dd, p);\n\tif (fm_set_table(ppd, FM_TBL_BUFFER_CONTROL, p) < 0) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\treturn __subn_get_opa_bct(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t  max_len);\n}\n\nstatic int __subn_get_opa_vl_arb(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t struct ib_device *ibdev, u32 port,\n\t\t\t\t u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(to_iport(ibdev, port));\n\tu32 num_ports = OPA_AM_NPORT(am);\n\tu8 section = (am & 0x00ff0000) >> 16;\n\tu8 *p = data;\n\tint size = 256;\n\n\tif (num_ports != 1 || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tswitch (section) {\n\tcase OPA_VLARB_LOW_ELEMENTS:\n\t\tfm_get_table(ppd, FM_TBL_VL_LOW_ARB, p);\n\t\tbreak;\n\tcase OPA_VLARB_HIGH_ELEMENTS:\n\t\tfm_get_table(ppd, FM_TBL_VL_HIGH_ARB, p);\n\t\tbreak;\n\tcase OPA_VLARB_PREEMPT_ELEMENTS:\n\t\tfm_get_table(ppd, FM_TBL_VL_PREEMPT_ELEMS, p);\n\t\tbreak;\n\tcase OPA_VLARB_PREEMPT_MATRIX:\n\t\tfm_get_table(ppd, FM_TBL_VL_PREEMPT_MATRIX, p);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"OPA SubnGet(VL Arb) AM Invalid : 0x%x\\n\",\n\t\t\tbe32_to_cpu(smp->attr_mod));\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\tsize = 0;\n\t\tbreak;\n\t}\n\n\tif (size > 0 && resp_len)\n\t\t*resp_len += size;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_vl_arb(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t struct ib_device *ibdev, u32 port,\n\t\t\t\t u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(to_iport(ibdev, port));\n\tu32 num_ports = OPA_AM_NPORT(am);\n\tu8 section = (am & 0x00ff0000) >> 16;\n\tu8 *p = data;\n\tint size = 256;\n\n\tif (num_ports != 1 || smp_length_check(size, max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tswitch (section) {\n\tcase OPA_VLARB_LOW_ELEMENTS:\n\t\t(void)fm_set_table(ppd, FM_TBL_VL_LOW_ARB, p);\n\t\tbreak;\n\tcase OPA_VLARB_HIGH_ELEMENTS:\n\t\t(void)fm_set_table(ppd, FM_TBL_VL_HIGH_ARB, p);\n\t\tbreak;\n\t \n\tcase OPA_VLARB_PREEMPT_ELEMENTS:\n\tcase OPA_VLARB_PREEMPT_MATRIX:\n\t\tsmp->status |= IB_SMP_UNSUP_METH_ATTR;\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"OPA SubnSet(VL Arb) AM Invalid : 0x%x\\n\",\n\t\t\tbe32_to_cpu(smp->attr_mod));\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\tbreak;\n\t}\n\n\treturn __subn_get_opa_vl_arb(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t     max_len);\n}\n\nstruct opa_pma_mad {\n\tstruct ib_mad_hdr mad_hdr;\n\tu8 data[2024];\n} __packed;\n\nstruct opa_port_status_req {\n\t__u8 port_num;\n\t__u8 reserved[3];\n\t__be32 vl_select_mask;\n};\n\n#define VL_MASK_ALL\t\t0x00000000000080ffUL\n\nstruct opa_port_status_rsp {\n\t__u8 port_num;\n\t__u8 reserved[3];\n\t__be32  vl_select_mask;\n\n\t \n\t__be64 port_xmit_data;\n\t__be64 port_rcv_data;\n\t__be64 port_xmit_pkts;\n\t__be64 port_rcv_pkts;\n\t__be64 port_multicast_xmit_pkts;\n\t__be64 port_multicast_rcv_pkts;\n\t__be64 port_xmit_wait;\n\t__be64 sw_port_congestion;\n\t__be64 port_rcv_fecn;\n\t__be64 port_rcv_becn;\n\t__be64 port_xmit_time_cong;\n\t__be64 port_xmit_wasted_bw;\n\t__be64 port_xmit_wait_data;\n\t__be64 port_rcv_bubble;\n\t__be64 port_mark_fecn;\n\t \n\t__be64 port_rcv_constraint_errors;\n\t__be64 port_rcv_switch_relay_errors;\n\t__be64 port_xmit_discards;\n\t__be64 port_xmit_constraint_errors;\n\t__be64 port_rcv_remote_physical_errors;\n\t__be64 local_link_integrity_errors;\n\t__be64 port_rcv_errors;\n\t__be64 excessive_buffer_overruns;\n\t__be64 fm_config_errors;\n\t__be32 link_error_recovery;\n\t__be32 link_downed;\n\tu8 uncorrectable_errors;\n\n\tu8 link_quality_indicator;  \n\tu8 res2[6];\n\tstruct _vls_pctrs {\n\t\t \n\t\t__be64 port_vl_xmit_data;\n\t\t__be64 port_vl_rcv_data;\n\t\t__be64 port_vl_xmit_pkts;\n\t\t__be64 port_vl_rcv_pkts;\n\t\t__be64 port_vl_xmit_wait;\n\t\t__be64 sw_port_vl_congestion;\n\t\t__be64 port_vl_rcv_fecn;\n\t\t__be64 port_vl_rcv_becn;\n\t\t__be64 port_xmit_time_cong;\n\t\t__be64 port_vl_xmit_wasted_bw;\n\t\t__be64 port_vl_xmit_wait_data;\n\t\t__be64 port_vl_rcv_bubble;\n\t\t__be64 port_vl_mark_fecn;\n\t\t__be64 port_vl_xmit_discards;\n\t} vls[];  \n};\n\nenum counter_selects {\n\tCS_PORT_XMIT_DATA\t\t\t= (1 << 31),\n\tCS_PORT_RCV_DATA\t\t\t= (1 << 30),\n\tCS_PORT_XMIT_PKTS\t\t\t= (1 << 29),\n\tCS_PORT_RCV_PKTS\t\t\t= (1 << 28),\n\tCS_PORT_MCAST_XMIT_PKTS\t\t\t= (1 << 27),\n\tCS_PORT_MCAST_RCV_PKTS\t\t\t= (1 << 26),\n\tCS_PORT_XMIT_WAIT\t\t\t= (1 << 25),\n\tCS_SW_PORT_CONGESTION\t\t\t= (1 << 24),\n\tCS_PORT_RCV_FECN\t\t\t= (1 << 23),\n\tCS_PORT_RCV_BECN\t\t\t= (1 << 22),\n\tCS_PORT_XMIT_TIME_CONG\t\t\t= (1 << 21),\n\tCS_PORT_XMIT_WASTED_BW\t\t\t= (1 << 20),\n\tCS_PORT_XMIT_WAIT_DATA\t\t\t= (1 << 19),\n\tCS_PORT_RCV_BUBBLE\t\t\t= (1 << 18),\n\tCS_PORT_MARK_FECN\t\t\t= (1 << 17),\n\tCS_PORT_RCV_CONSTRAINT_ERRORS\t\t= (1 << 16),\n\tCS_PORT_RCV_SWITCH_RELAY_ERRORS\t\t= (1 << 15),\n\tCS_PORT_XMIT_DISCARDS\t\t\t= (1 << 14),\n\tCS_PORT_XMIT_CONSTRAINT_ERRORS\t\t= (1 << 13),\n\tCS_PORT_RCV_REMOTE_PHYSICAL_ERRORS\t= (1 << 12),\n\tCS_LOCAL_LINK_INTEGRITY_ERRORS\t\t= (1 << 11),\n\tCS_PORT_RCV_ERRORS\t\t\t= (1 << 10),\n\tCS_EXCESSIVE_BUFFER_OVERRUNS\t\t= (1 << 9),\n\tCS_FM_CONFIG_ERRORS\t\t\t= (1 << 8),\n\tCS_LINK_ERROR_RECOVERY\t\t\t= (1 << 7),\n\tCS_LINK_DOWNED\t\t\t\t= (1 << 6),\n\tCS_UNCORRECTABLE_ERRORS\t\t\t= (1 << 5),\n};\n\nstruct opa_clear_port_status {\n\t__be64 port_select_mask[4];\n\t__be32 counter_select_mask;\n};\n\nstruct opa_aggregate {\n\t__be16 attr_id;\n\t__be16 err_reqlength;\t \n\t__be32 attr_mod;\n\tu8 data[];\n};\n\n#define MSK_LLI 0x000000f0\n#define MSK_LLI_SFT 4\n#define MSK_LER 0x0000000f\n#define MSK_LER_SFT 0\n#define ADD_LLI 8\n#define ADD_LER 2\n\n \nstruct opa_port_data_counters_msg {\n\t__be64 port_select_mask[4];\n\t__be32 vl_select_mask;\n\t__be32 resolution;\n\n\t \n\tstruct _port_dctrs {\n\t\tu8 port_number;\n\t\tu8 reserved2[3];\n\t\t__be32 link_quality_indicator;  \n\n\t\t \n\t\t__be64 port_xmit_data;\n\t\t__be64 port_rcv_data;\n\t\t__be64 port_xmit_pkts;\n\t\t__be64 port_rcv_pkts;\n\t\t__be64 port_multicast_xmit_pkts;\n\t\t__be64 port_multicast_rcv_pkts;\n\t\t__be64 port_xmit_wait;\n\t\t__be64 sw_port_congestion;\n\t\t__be64 port_rcv_fecn;\n\t\t__be64 port_rcv_becn;\n\t\t__be64 port_xmit_time_cong;\n\t\t__be64 port_xmit_wasted_bw;\n\t\t__be64 port_xmit_wait_data;\n\t\t__be64 port_rcv_bubble;\n\t\t__be64 port_mark_fecn;\n\n\t\t__be64 port_error_counter_summary;\n\t\t \n\n\t\tstruct _vls_dctrs {\n\t\t\t \n\t\t\t__be64 port_vl_xmit_data;\n\t\t\t__be64 port_vl_rcv_data;\n\t\t\t__be64 port_vl_xmit_pkts;\n\t\t\t__be64 port_vl_rcv_pkts;\n\t\t\t__be64 port_vl_xmit_wait;\n\t\t\t__be64 sw_port_vl_congestion;\n\t\t\t__be64 port_vl_rcv_fecn;\n\t\t\t__be64 port_vl_rcv_becn;\n\t\t\t__be64 port_xmit_time_cong;\n\t\t\t__be64 port_vl_xmit_wasted_bw;\n\t\t\t__be64 port_vl_xmit_wait_data;\n\t\t\t__be64 port_vl_rcv_bubble;\n\t\t\t__be64 port_vl_mark_fecn;\n\t\t} vls[];\n\t\t \n\t} port;\n};\n\nstruct opa_port_error_counters64_msg {\n\t \n\t__be64 port_select_mask[4];\n\t__be32 vl_select_mask;\n\n\t \n\t__be32 reserved1;\n\tstruct _port_ectrs {\n\t\tu8 port_number;\n\t\tu8 reserved2[7];\n\t\t__be64 port_rcv_constraint_errors;\n\t\t__be64 port_rcv_switch_relay_errors;\n\t\t__be64 port_xmit_discards;\n\t\t__be64 port_xmit_constraint_errors;\n\t\t__be64 port_rcv_remote_physical_errors;\n\t\t__be64 local_link_integrity_errors;\n\t\t__be64 port_rcv_errors;\n\t\t__be64 excessive_buffer_overruns;\n\t\t__be64 fm_config_errors;\n\t\t__be32 link_error_recovery;\n\t\t__be32 link_downed;\n\t\tu8 uncorrectable_errors;\n\t\tu8 reserved3[7];\n\t\tstruct _vls_ectrs {\n\t\t\t__be64 port_vl_xmit_discards;\n\t\t} vls[];\n\t\t \n\t} port;\n};\n\nstruct opa_port_error_info_msg {\n\t__be64 port_select_mask[4];\n\t__be32 error_info_select_mask;\n\t__be32 reserved1;\n\tstruct _port_ei {\n\t\tu8 port_number;\n\t\tu8 reserved2[7];\n\n\t\t \n\t\tstruct {\n\t\t\tu8 status_and_code;\n\t\t\tunion {\n\t\t\t\tu8 raw[17];\n\t\t\t\tstruct {\n\t\t\t\t\t \n\t\t\t\t\tu8 packet_flit1[8];\n\t\t\t\t\tu8 packet_flit2[8];\n\t\t\t\t\tu8 remaining_flit_bits12;\n\t\t\t\t} ei1to12;\n\t\t\t\tstruct {\n\t\t\t\t\tu8 packet_bytes[8];\n\t\t\t\t\tu8 remaining_flit_bits;\n\t\t\t\t} ei13;\n\t\t\t} ei;\n\t\t\tu8 reserved3[6];\n\t\t} __packed port_rcv_ei;\n\n\t\t \n\t\tstruct {\n\t\t\tu8 status_and_sc;\n\t\t\tu8 reserved4[7];\n\t\t} __packed excessive_buffer_overrun_ei;\n\n\t\t \n\t\tstruct {\n\t\t\tu8 status;\n\t\t\tu8 reserved5;\n\t\t\t__be16 pkey;\n\t\t\t__be32 slid;\n\t\t} __packed port_xmit_constraint_ei;\n\n\t\t \n\t\tstruct {\n\t\t\tu8 status;\n\t\t\tu8 reserved6;\n\t\t\t__be16 pkey;\n\t\t\t__be32 slid;\n\t\t} __packed port_rcv_constraint_ei;\n\n\t\t \n\t\tstruct {\n\t\t\tu8 status_and_code;\n\t\t\tu8 reserved7[3];\n\t\t\t__u32 error_info;\n\t\t} __packed port_rcv_switch_relay_ei;\n\n\t\t \n\t\tstruct {\n\t\t\tu8 status_and_code;\n\t\t\tu8 reserved8;\n\t\t} __packed uncorrectable_ei;\n\n\t\t \n\t\tstruct {\n\t\t\tu8 status_and_code;\n\t\t\tu8 error_info;\n\t\t} __packed fm_config_ei;\n\t\t__u32 reserved9;\n\t} port;\n};\n\n \nenum error_info_selects {\n\tES_PORT_RCV_ERROR_INFO\t\t\t= (1 << 31),\n\tES_EXCESSIVE_BUFFER_OVERRUN_INFO\t= (1 << 30),\n\tES_PORT_XMIT_CONSTRAINT_ERROR_INFO\t= (1 << 29),\n\tES_PORT_RCV_CONSTRAINT_ERROR_INFO\t= (1 << 28),\n\tES_PORT_RCV_SWITCH_RELAY_ERROR_INFO\t= (1 << 27),\n\tES_UNCORRECTABLE_ERROR_INFO\t\t= (1 << 26),\n\tES_FM_CONFIG_ERROR_INFO\t\t\t= (1 << 25)\n};\n\nstatic int pma_get_opa_classportinfo(struct opa_pma_mad *pmp,\n\t\t\t\t     struct ib_device *ibdev, u32 *resp_len)\n{\n\tstruct opa_class_port_info *p =\n\t\t(struct opa_class_port_info *)pmp->data;\n\n\tmemset(pmp->data, 0, sizeof(pmp->data));\n\n\tif (pmp->mad_hdr.attr_mod != 0)\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\n\tp->base_version = OPA_MGMT_BASE_VERSION;\n\tp->class_version = OPA_SM_CLASS_VERSION;\n\t \n\tp->cap_mask2_resp_time = cpu_to_be32(18);\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(*p);\n\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic void a0_portstatus(struct hfi1_pportdata *ppd,\n\t\t\t  struct opa_port_status_rsp *rsp)\n{\n\tif (!is_bx(ppd->dd)) {\n\t\tunsigned long vl;\n\t\tu64 sum_vl_xmit_wait = 0;\n\t\tunsigned long vl_all_mask = VL_MASK_ALL;\n\n\t\tfor_each_set_bit(vl, &vl_all_mask, BITS_PER_LONG) {\n\t\t\tu64 tmp = sum_vl_xmit_wait +\n\t\t\t\t  read_port_cntr(ppd, C_TX_WAIT_VL,\n\t\t\t\t\t\t idx_from_vl(vl));\n\t\t\tif (tmp < sum_vl_xmit_wait) {\n\t\t\t\t \n\t\t\t\tsum_vl_xmit_wait = (u64)~0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsum_vl_xmit_wait = tmp;\n\t\t}\n\t\tif (be64_to_cpu(rsp->port_xmit_wait) > sum_vl_xmit_wait)\n\t\t\trsp->port_xmit_wait = cpu_to_be64(sum_vl_xmit_wait);\n\t}\n}\n\n \nu16 tx_link_width(u16 link_width)\n{\n\tint n = LINK_WIDTH_DEFAULT;\n\tu16 tx_width = n;\n\n\twhile (link_width && n) {\n\t\tif (link_width & (1 << (n - 1))) {\n\t\t\ttx_width = n;\n\t\t\tbreak;\n\t\t}\n\t\tn--;\n\t}\n\n\treturn tx_width;\n}\n\n \nu64 get_xmit_wait_counters(struct hfi1_pportdata *ppd,\n\t\t\t   u16 link_width, u16 link_speed, int vl)\n{\n\tu64 port_vl_xmit_wait_curr;\n\tu64 delta_vl_xmit_wait;\n\tu64 xmit_wait_val;\n\n\tif (vl > C_VL_COUNT)\n\t\treturn  0;\n\tif (vl < C_VL_COUNT)\n\t\tport_vl_xmit_wait_curr =\n\t\t\tread_port_cntr(ppd, C_TX_WAIT_VL, vl);\n\telse\n\t\tport_vl_xmit_wait_curr =\n\t\t\tread_port_cntr(ppd, C_TX_WAIT, CNTR_INVALID_VL);\n\n\txmit_wait_val =\n\t\tport_vl_xmit_wait_curr -\n\t\tppd->port_vl_xmit_wait_last[vl];\n\tdelta_vl_xmit_wait =\n\t\tconvert_xmit_counter(xmit_wait_val,\n\t\t\t\t     ppd->prev_link_width,\n\t\t\t\t     link_speed);\n\n\tppd->vl_xmit_flit_cnt[vl] += delta_vl_xmit_wait;\n\tppd->port_vl_xmit_wait_last[vl] = port_vl_xmit_wait_curr;\n\tppd->prev_link_width = link_width;\n\n\treturn ppd->vl_xmit_flit_cnt[vl];\n}\n\nstatic int pma_get_opa_portstatus(struct opa_pma_mad *pmp,\n\t\t\t\t  struct ib_device *ibdev,\n\t\t\t\t  u32 port, u32 *resp_len)\n{\n\tstruct opa_port_status_req *req =\n\t\t(struct opa_port_status_req *)pmp->data;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct opa_port_status_rsp *rsp;\n\tunsigned long vl_select_mask = be32_to_cpu(req->vl_select_mask);\n\tunsigned long vl;\n\tsize_t response_data_size;\n\tu32 nports = be32_to_cpu(pmp->mad_hdr.attr_mod) >> 24;\n\tu32 port_num = req->port_num;\n\tu8 num_vls = hweight64(vl_select_mask);\n\tstruct _vls_pctrs *vlinfo;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tint vfi;\n\tu64 tmp, tmp2;\n\tu16 link_width;\n\tu16 link_speed;\n\n\tresponse_data_size = struct_size(rsp, vls, num_vls);\n\tif (response_data_size > sizeof(pmp->data)) {\n\t\tpmp->mad_hdr.status |= OPA_PM_STATUS_REQUEST_TOO_LARGE;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\tif (nports != 1 || (port_num && port_num != port) ||\n\t    num_vls > OPA_MAX_VLS || (vl_select_mask & ~VL_MASK_ALL)) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\tmemset(pmp->data, 0, sizeof(pmp->data));\n\n\trsp = (struct opa_port_status_rsp *)pmp->data;\n\tif (port_num)\n\t\trsp->port_num = port_num;\n\telse\n\t\trsp->port_num = port;\n\n\trsp->port_rcv_constraint_errors =\n\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_RCV_CSTR_ERR,\n\t\t\t\t\t   CNTR_INVALID_VL));\n\n\thfi1_read_link_quality(dd, &rsp->link_quality_indicator);\n\n\trsp->vl_select_mask = cpu_to_be32((u32)vl_select_mask);\n\trsp->port_xmit_data = cpu_to_be64(read_dev_cntr(dd, C_DC_XMIT_FLITS,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->port_rcv_data = cpu_to_be64(read_dev_cntr(dd, C_DC_RCV_FLITS,\n\t\t\t\t\t CNTR_INVALID_VL));\n\trsp->port_xmit_pkts = cpu_to_be64(read_dev_cntr(dd, C_DC_XMIT_PKTS,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->port_rcv_pkts = cpu_to_be64(read_dev_cntr(dd, C_DC_RCV_PKTS,\n\t\t\t\t\t CNTR_INVALID_VL));\n\trsp->port_multicast_xmit_pkts =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_MC_XMIT_PKTS,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->port_multicast_rcv_pkts =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_MC_RCV_PKTS,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\t \n\tlink_width =\n\t\ttx_link_width(ppd->link_width_downgrade_tx_active);\n\tlink_speed = get_link_speed(ppd->link_speed_active);\n\trsp->port_xmit_wait =\n\t\tcpu_to_be64(get_xmit_wait_counters(ppd, link_width,\n\t\t\t\t\t\t   link_speed, C_VL_COUNT));\n\trsp->port_rcv_fecn =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_FCN, CNTR_INVALID_VL));\n\trsp->port_rcv_becn =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_BCN, CNTR_INVALID_VL));\n\trsp->port_xmit_discards =\n\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_XMIT_DSCD,\n\t\t\t\t\t   CNTR_INVALID_VL));\n\trsp->port_xmit_constraint_errors =\n\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_XMIT_CSTR_ERR,\n\t\t\t\t\t   CNTR_INVALID_VL));\n\trsp->port_rcv_remote_physical_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RMT_PHY_ERR,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->local_link_integrity_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RX_REPLAY,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\ttmp = read_dev_cntr(dd, C_DC_SEQ_CRC_CNT, CNTR_INVALID_VL);\n\ttmp2 = tmp + read_dev_cntr(dd, C_DC_REINIT_FROM_PEER_CNT,\n\t\t\t\t   CNTR_INVALID_VL);\n\tif (tmp2 > (u32)UINT_MAX || tmp2 < tmp) {\n\t\t \n\t\trsp->link_error_recovery = cpu_to_be32(~0);\n\t} else {\n\t\trsp->link_error_recovery = cpu_to_be32(tmp2);\n\t}\n\trsp->port_rcv_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_ERR, CNTR_INVALID_VL));\n\trsp->excessive_buffer_overruns =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_RCV_OVF, CNTR_INVALID_VL));\n\trsp->fm_config_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_FM_CFG_ERR,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->link_downed = cpu_to_be32(read_port_cntr(ppd, C_SW_LINK_DOWN,\n\t\t\t\t\t\t      CNTR_INVALID_VL));\n\n\t \n\ttmp = read_dev_cntr(dd, C_DC_UNC_ERR, CNTR_INVALID_VL);\n\trsp->uncorrectable_errors = tmp < 0x100 ? (tmp & 0xff) : 0xff;\n\n\tvlinfo = &rsp->vls[0];\n\tvfi = 0;\n\t \n\tfor_each_set_bit(vl, &vl_select_mask, BITS_PER_LONG) {\n\t\tmemset(vlinfo, 0, sizeof(*vlinfo));\n\n\t\ttmp = read_dev_cntr(dd, C_DC_RX_FLIT_VL, idx_from_vl(vl));\n\t\trsp->vls[vfi].port_vl_rcv_data = cpu_to_be64(tmp);\n\n\t\trsp->vls[vfi].port_vl_rcv_pkts =\n\t\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RX_PKT_VL,\n\t\t\t\t\t\t  idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_xmit_data =\n\t\t\tcpu_to_be64(read_port_cntr(ppd, C_TX_FLIT_VL,\n\t\t\t\t\t\t   idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_xmit_pkts =\n\t\t\tcpu_to_be64(read_port_cntr(ppd, C_TX_PKT_VL,\n\t\t\t\t\t\t   idx_from_vl(vl)));\n\t\t \n\t\trsp->vls[vfi].port_vl_xmit_wait =\n\t\t\tcpu_to_be64(get_xmit_wait_counters(ppd, link_width,\n\t\t\t\t\t\t\t   link_speed,\n\t\t\t\t\t\t\t   idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_rcv_fecn =\n\t\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_FCN_VL,\n\t\t\t\t\t\t  idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_rcv_becn =\n\t\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_BCN_VL,\n\t\t\t\t\t\t  idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_xmit_discards =\n\t\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_XMIT_DSCD_VL,\n\t\t\t\t\t\t   idx_from_vl(vl)));\n\t\tvlinfo++;\n\t\tvfi++;\n\t}\n\n\ta0_portstatus(ppd, rsp);\n\n\tif (resp_len)\n\t\t*resp_len += response_data_size;\n\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic u64 get_error_counter_summary(struct ib_device *ibdev, u32 port,\n\t\t\t\t     u8 res_lli, u8 res_ler)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tu64 error_counter_summary = 0, tmp;\n\n\terror_counter_summary += read_port_cntr(ppd, C_SW_RCV_CSTR_ERR,\n\t\t\t\t\t\tCNTR_INVALID_VL);\n\t \n\terror_counter_summary += read_port_cntr(ppd, C_SW_XMIT_DSCD,\n\t\t\t\t\t\tCNTR_INVALID_VL);\n\terror_counter_summary += read_port_cntr(ppd, C_SW_XMIT_CSTR_ERR,\n\t\t\t\t\t\tCNTR_INVALID_VL);\n\terror_counter_summary += read_dev_cntr(dd, C_DC_RMT_PHY_ERR,\n\t\t\t\t\t       CNTR_INVALID_VL);\n\t \n\terror_counter_summary += (read_dev_cntr(dd, C_DC_RX_REPLAY,\n\t\t\t\t\t\tCNTR_INVALID_VL) >> res_lli);\n\t \n\ttmp = read_dev_cntr(dd, C_DC_SEQ_CRC_CNT, CNTR_INVALID_VL);\n\ttmp += read_dev_cntr(dd, C_DC_REINIT_FROM_PEER_CNT, CNTR_INVALID_VL);\n\terror_counter_summary += (tmp >> res_ler);\n\terror_counter_summary += read_dev_cntr(dd, C_DC_RCV_ERR,\n\t\t\t\t\t       CNTR_INVALID_VL);\n\terror_counter_summary += read_dev_cntr(dd, C_RCV_OVF, CNTR_INVALID_VL);\n\terror_counter_summary += read_dev_cntr(dd, C_DC_FM_CFG_ERR,\n\t\t\t\t\t       CNTR_INVALID_VL);\n\t \n\terror_counter_summary += read_port_cntr(ppd, C_SW_LINK_DOWN,\n\t\t\t\t\t\tCNTR_INVALID_VL);\n\ttmp = read_dev_cntr(dd, C_DC_UNC_ERR, CNTR_INVALID_VL);\n\t \n\terror_counter_summary += tmp < 0x100 ? (tmp & 0xff) : 0xff;\n\n\treturn error_counter_summary;\n}\n\nstatic void a0_datacounters(struct hfi1_pportdata *ppd, struct _port_dctrs *rsp)\n{\n\tif (!is_bx(ppd->dd)) {\n\t\tunsigned long vl;\n\t\tu64 sum_vl_xmit_wait = 0;\n\t\tunsigned long vl_all_mask = VL_MASK_ALL;\n\n\t\tfor_each_set_bit(vl, &vl_all_mask, BITS_PER_LONG) {\n\t\t\tu64 tmp = sum_vl_xmit_wait +\n\t\t\t\t  read_port_cntr(ppd, C_TX_WAIT_VL,\n\t\t\t\t\t\t idx_from_vl(vl));\n\t\t\tif (tmp < sum_vl_xmit_wait) {\n\t\t\t\t \n\t\t\t\tsum_vl_xmit_wait = (u64)~0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsum_vl_xmit_wait = tmp;\n\t\t}\n\t\tif (be64_to_cpu(rsp->port_xmit_wait) > sum_vl_xmit_wait)\n\t\t\trsp->port_xmit_wait = cpu_to_be64(sum_vl_xmit_wait);\n\t}\n}\n\nstatic void pma_get_opa_port_dctrs(struct ib_device *ibdev,\n\t\t\t\t   struct _port_dctrs *rsp)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\n\trsp->port_xmit_data = cpu_to_be64(read_dev_cntr(dd, C_DC_XMIT_FLITS,\n\t\t\t\t\t\tCNTR_INVALID_VL));\n\trsp->port_rcv_data = cpu_to_be64(read_dev_cntr(dd, C_DC_RCV_FLITS,\n\t\t\t\t\t\tCNTR_INVALID_VL));\n\trsp->port_xmit_pkts = cpu_to_be64(read_dev_cntr(dd, C_DC_XMIT_PKTS,\n\t\t\t\t\t\tCNTR_INVALID_VL));\n\trsp->port_rcv_pkts = cpu_to_be64(read_dev_cntr(dd, C_DC_RCV_PKTS,\n\t\t\t\t\t\tCNTR_INVALID_VL));\n\trsp->port_multicast_xmit_pkts =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_MC_XMIT_PKTS,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->port_multicast_rcv_pkts =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_MC_RCV_PKTS,\n\t\t\t\t\t  CNTR_INVALID_VL));\n}\n\nstatic int pma_get_opa_datacounters(struct opa_pma_mad *pmp,\n\t\t\t\t    struct ib_device *ibdev,\n\t\t\t\t    u32 port, u32 *resp_len)\n{\n\tstruct opa_port_data_counters_msg *req =\n\t\t(struct opa_port_data_counters_msg *)pmp->data;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tstruct _port_dctrs *rsp;\n\tstruct _vls_dctrs *vlinfo;\n\tsize_t response_data_size;\n\tu32 num_ports;\n\tu8 lq, num_vls;\n\tu8 res_lli, res_ler;\n\tu64 port_mask;\n\tu32 port_num;\n\tunsigned long vl;\n\tunsigned long vl_select_mask;\n\tint vfi;\n\tu16 link_width;\n\tu16 link_speed;\n\n\tnum_ports = be32_to_cpu(pmp->mad_hdr.attr_mod) >> 24;\n\tnum_vls = hweight32(be32_to_cpu(req->vl_select_mask));\n\tvl_select_mask = be32_to_cpu(req->vl_select_mask);\n\tres_lli = (u8)(be32_to_cpu(req->resolution) & MSK_LLI) >> MSK_LLI_SFT;\n\tres_lli = res_lli ? res_lli + ADD_LLI : 0;\n\tres_ler = (u8)(be32_to_cpu(req->resolution) & MSK_LER) >> MSK_LER_SFT;\n\tres_ler = res_ler ? res_ler + ADD_LER : 0;\n\n\tif (num_ports != 1 || (vl_select_mask & ~VL_MASK_ALL)) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\t \n\tresponse_data_size = struct_size(req, port.vls, num_vls);\n\n\tif (response_data_size > sizeof(pmp->data)) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\t \n\tport_mask = be64_to_cpu(req->port_select_mask[3]);\n\tport_num = find_first_bit((unsigned long *)&port_mask,\n\t\t\t\t  sizeof(port_mask) * 8);\n\n\tif (port_num != port) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\trsp = &req->port;\n\tmemset(rsp, 0, sizeof(*rsp));\n\n\trsp->port_number = port;\n\t \n\thfi1_read_link_quality(dd, &lq);\n\trsp->link_quality_indicator = cpu_to_be32((u32)lq);\n\tpma_get_opa_port_dctrs(ibdev, rsp);\n\n\t \n\tlink_width =\n\t\ttx_link_width(ppd->link_width_downgrade_tx_active);\n\tlink_speed = get_link_speed(ppd->link_speed_active);\n\trsp->port_xmit_wait =\n\t\tcpu_to_be64(get_xmit_wait_counters(ppd, link_width,\n\t\t\t\t\t\t   link_speed, C_VL_COUNT));\n\trsp->port_rcv_fecn =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_FCN, CNTR_INVALID_VL));\n\trsp->port_rcv_becn =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_BCN, CNTR_INVALID_VL));\n\trsp->port_error_counter_summary =\n\t\tcpu_to_be64(get_error_counter_summary(ibdev, port,\n\t\t\t\t\t\t      res_lli, res_ler));\n\n\tvlinfo = &rsp->vls[0];\n\tvfi = 0;\n\t \n\tfor_each_set_bit(vl, &vl_select_mask, BITS_PER_LONG) {\n\t\tmemset(vlinfo, 0, sizeof(*vlinfo));\n\n\t\trsp->vls[vfi].port_vl_xmit_data =\n\t\t\tcpu_to_be64(read_port_cntr(ppd, C_TX_FLIT_VL,\n\t\t\t\t\t\t   idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_rcv_data =\n\t\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RX_FLIT_VL,\n\t\t\t\t\t\t  idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_xmit_pkts =\n\t\t\tcpu_to_be64(read_port_cntr(ppd, C_TX_PKT_VL,\n\t\t\t\t\t\t   idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_rcv_pkts =\n\t\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RX_PKT_VL,\n\t\t\t\t\t\t  idx_from_vl(vl)));\n\n\t\t \n\t\trsp->vls[vfi].port_vl_xmit_wait =\n\t\t\tcpu_to_be64(get_xmit_wait_counters(ppd, link_width,\n\t\t\t\t\t\t\t   link_speed,\n\t\t\t\t\t\t\t   idx_from_vl(vl)));\n\n\t\trsp->vls[vfi].port_vl_rcv_fecn =\n\t\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_FCN_VL,\n\t\t\t\t\t\t  idx_from_vl(vl)));\n\t\trsp->vls[vfi].port_vl_rcv_becn =\n\t\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_BCN_VL,\n\t\t\t\t\t\t  idx_from_vl(vl)));\n\n\t\t \n\t\t \n\t\t \n\t\t \n\t\tvlinfo++;\n\t\tvfi++;\n\t}\n\n\ta0_datacounters(ppd, rsp);\n\n\tif (resp_len)\n\t\t*resp_len += response_data_size;\n\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic int pma_get_ib_portcounters_ext(struct ib_pma_mad *pmp,\n\t\t\t\t       struct ib_device *ibdev, u32 port)\n{\n\tstruct ib_pma_portcounters_ext *p = (struct ib_pma_portcounters_ext *)\n\t\t\t\t\t\tpmp->data;\n\tstruct _port_dctrs rsp;\n\n\tif (pmp->mad_hdr.attr_mod != 0 || p->port_select != port) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\tgoto bail;\n\t}\n\n\tmemset(&rsp, 0, sizeof(rsp));\n\tpma_get_opa_port_dctrs(ibdev, &rsp);\n\n\tp->port_xmit_data = rsp.port_xmit_data;\n\tp->port_rcv_data = rsp.port_rcv_data;\n\tp->port_xmit_packets = rsp.port_xmit_pkts;\n\tp->port_rcv_packets = rsp.port_rcv_pkts;\n\tp->port_unicast_xmit_packets = 0;\n\tp->port_unicast_rcv_packets =  0;\n\tp->port_multicast_xmit_packets = rsp.port_multicast_xmit_pkts;\n\tp->port_multicast_rcv_packets = rsp.port_multicast_rcv_pkts;\n\nbail:\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic void pma_get_opa_port_ectrs(struct ib_device *ibdev,\n\t\t\t\t   struct _port_ectrs *rsp, u32 port)\n{\n\tu64 tmp, tmp2;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\n\ttmp = read_dev_cntr(dd, C_DC_SEQ_CRC_CNT, CNTR_INVALID_VL);\n\ttmp2 = tmp + read_dev_cntr(dd, C_DC_REINIT_FROM_PEER_CNT,\n\t\t\t\t\tCNTR_INVALID_VL);\n\tif (tmp2 > (u32)UINT_MAX || tmp2 < tmp) {\n\t\t \n\t\trsp->link_error_recovery = cpu_to_be32(~0);\n\t} else {\n\t\trsp->link_error_recovery = cpu_to_be32(tmp2);\n\t}\n\n\trsp->link_downed = cpu_to_be32(read_port_cntr(ppd, C_SW_LINK_DOWN,\n\t\t\t\t\t\tCNTR_INVALID_VL));\n\trsp->port_rcv_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_ERR, CNTR_INVALID_VL));\n\trsp->port_rcv_remote_physical_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RMT_PHY_ERR,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->port_rcv_switch_relay_errors = 0;\n\trsp->port_xmit_discards =\n\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_XMIT_DSCD,\n\t\t\t\t\t   CNTR_INVALID_VL));\n\trsp->port_xmit_constraint_errors =\n\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_XMIT_CSTR_ERR,\n\t\t\t\t\t   CNTR_INVALID_VL));\n\trsp->port_rcv_constraint_errors =\n\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_RCV_CSTR_ERR,\n\t\t\t\t\t   CNTR_INVALID_VL));\n\trsp->local_link_integrity_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RX_REPLAY,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->excessive_buffer_overruns =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_RCV_OVF, CNTR_INVALID_VL));\n}\n\nstatic int pma_get_opa_porterrors(struct opa_pma_mad *pmp,\n\t\t\t\t  struct ib_device *ibdev,\n\t\t\t\t  u32 port, u32 *resp_len)\n{\n\tsize_t response_data_size;\n\tstruct _port_ectrs *rsp;\n\tu32 port_num;\n\tstruct opa_port_error_counters64_msg *req;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 num_ports;\n\tu8 num_pslm;\n\tu8 num_vls;\n\tstruct hfi1_ibport *ibp;\n\tstruct hfi1_pportdata *ppd;\n\tstruct _vls_ectrs *vlinfo;\n\tunsigned long vl;\n\tu64 port_mask, tmp;\n\tunsigned long vl_select_mask;\n\tint vfi;\n\n\treq = (struct opa_port_error_counters64_msg *)pmp->data;\n\n\tnum_ports = be32_to_cpu(pmp->mad_hdr.attr_mod) >> 24;\n\n\tnum_pslm = hweight64(be64_to_cpu(req->port_select_mask[3]));\n\tnum_vls = hweight32(be32_to_cpu(req->vl_select_mask));\n\n\tif (num_ports != 1 || num_ports != num_pslm) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\tresponse_data_size = struct_size(req, port.vls, num_vls);\n\n\tif (response_data_size > sizeof(pmp->data)) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\t \n\tport_mask = be64_to_cpu(req->port_select_mask[3]);\n\tport_num = find_first_bit((unsigned long *)&port_mask,\n\t\t\t\t  sizeof(port_mask) * 8);\n\n\tif (port_num != port) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\trsp = &req->port;\n\n\tibp = to_iport(ibdev, port_num);\n\tppd = ppd_from_ibp(ibp);\n\n\tmemset(rsp, 0, sizeof(*rsp));\n\trsp->port_number = port_num;\n\n\tpma_get_opa_port_ectrs(ibdev, rsp, port_num);\n\n\trsp->port_rcv_remote_physical_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RMT_PHY_ERR,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\trsp->fm_config_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_FM_CFG_ERR,\n\t\t\t\t\t  CNTR_INVALID_VL));\n\ttmp = read_dev_cntr(dd, C_DC_UNC_ERR, CNTR_INVALID_VL);\n\n\trsp->uncorrectable_errors = tmp < 0x100 ? (tmp & 0xff) : 0xff;\n\trsp->port_rcv_errors =\n\t\tcpu_to_be64(read_dev_cntr(dd, C_DC_RCV_ERR, CNTR_INVALID_VL));\n\tvlinfo = &rsp->vls[0];\n\tvfi = 0;\n\tvl_select_mask = be32_to_cpu(req->vl_select_mask);\n\tfor_each_set_bit(vl, &vl_select_mask, BITS_PER_LONG) {\n\t\tmemset(vlinfo, 0, sizeof(*vlinfo));\n\t\trsp->vls[vfi].port_vl_xmit_discards =\n\t\t\tcpu_to_be64(read_port_cntr(ppd, C_SW_XMIT_DSCD_VL,\n\t\t\t\t\t\t   idx_from_vl(vl)));\n\t\tvlinfo += 1;\n\t\tvfi++;\n\t}\n\n\tif (resp_len)\n\t\t*resp_len += response_data_size;\n\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic int pma_get_ib_portcounters(struct ib_pma_mad *pmp,\n\t\t\t\t   struct ib_device *ibdev, u32 port)\n{\n\tstruct ib_pma_portcounters *p = (struct ib_pma_portcounters *)\n\t\tpmp->data;\n\tstruct _port_ectrs rsp;\n\tu64 temp_link_overrun_errors;\n\tu64 temp_64;\n\tu32 temp_32;\n\n\tmemset(&rsp, 0, sizeof(rsp));\n\tpma_get_opa_port_ectrs(ibdev, &rsp, port);\n\n\tif (pmp->mad_hdr.attr_mod != 0 || p->port_select != port) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\tgoto bail;\n\t}\n\n\tp->symbol_error_counter = 0;  \n\n\ttemp_32 = be32_to_cpu(rsp.link_error_recovery);\n\tif (temp_32 > 0xFFUL)\n\t\tp->link_error_recovery_counter = 0xFF;\n\telse\n\t\tp->link_error_recovery_counter = (u8)temp_32;\n\n\ttemp_32 = be32_to_cpu(rsp.link_downed);\n\tif (temp_32 > 0xFFUL)\n\t\tp->link_downed_counter = 0xFF;\n\telse\n\t\tp->link_downed_counter = (u8)temp_32;\n\n\ttemp_64 = be64_to_cpu(rsp.port_rcv_errors);\n\tif (temp_64 > 0xFFFFUL)\n\t\tp->port_rcv_errors = cpu_to_be16(0xFFFF);\n\telse\n\t\tp->port_rcv_errors = cpu_to_be16((u16)temp_64);\n\n\ttemp_64 = be64_to_cpu(rsp.port_rcv_remote_physical_errors);\n\tif (temp_64 > 0xFFFFUL)\n\t\tp->port_rcv_remphys_errors = cpu_to_be16(0xFFFF);\n\telse\n\t\tp->port_rcv_remphys_errors = cpu_to_be16((u16)temp_64);\n\n\ttemp_64 = be64_to_cpu(rsp.port_rcv_switch_relay_errors);\n\tp->port_rcv_switch_relay_errors = cpu_to_be16((u16)temp_64);\n\n\ttemp_64 = be64_to_cpu(rsp.port_xmit_discards);\n\tif (temp_64 > 0xFFFFUL)\n\t\tp->port_xmit_discards = cpu_to_be16(0xFFFF);\n\telse\n\t\tp->port_xmit_discards = cpu_to_be16((u16)temp_64);\n\n\ttemp_64 = be64_to_cpu(rsp.port_xmit_constraint_errors);\n\tif (temp_64 > 0xFFUL)\n\t\tp->port_xmit_constraint_errors = 0xFF;\n\telse\n\t\tp->port_xmit_constraint_errors = (u8)temp_64;\n\n\ttemp_64 = be64_to_cpu(rsp.port_rcv_constraint_errors);\n\tif (temp_64 > 0xFFUL)\n\t\tp->port_rcv_constraint_errors = 0xFFUL;\n\telse\n\t\tp->port_rcv_constraint_errors = (u8)temp_64;\n\n\t \n\ttemp_64 = be64_to_cpu(rsp.local_link_integrity_errors);\n\tif (temp_64 > 0xFUL)\n\t\ttemp_64 = 0xFUL;\n\n\ttemp_link_overrun_errors = temp_64 << 4;\n\n\ttemp_64 = be64_to_cpu(rsp.excessive_buffer_overruns);\n\tif (temp_64 > 0xFUL)\n\t\ttemp_64 = 0xFUL;\n\ttemp_link_overrun_errors |= temp_64;\n\n\tp->link_overrun_errors = (u8)temp_link_overrun_errors;\n\n\tp->vl15_dropped = 0;  \n\nbail:\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic int pma_get_opa_errorinfo(struct opa_pma_mad *pmp,\n\t\t\t\t struct ib_device *ibdev,\n\t\t\t\t u32 port, u32 *resp_len)\n{\n\tsize_t response_data_size;\n\tstruct _port_ei *rsp;\n\tstruct opa_port_error_info_msg *req;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu64 port_mask;\n\tu32 num_ports;\n\tu32 port_num;\n\tu8 num_pslm;\n\tu64 reg;\n\n\treq = (struct opa_port_error_info_msg *)pmp->data;\n\trsp = &req->port;\n\n\tnum_ports = OPA_AM_NPORT(be32_to_cpu(pmp->mad_hdr.attr_mod));\n\tnum_pslm = hweight64(be64_to_cpu(req->port_select_mask[3]));\n\n\tmemset(rsp, 0, sizeof(*rsp));\n\n\tif (num_ports != 1 || num_ports != num_pslm) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\t \n\tresponse_data_size = sizeof(struct opa_port_error_info_msg);\n\n\tif (response_data_size > sizeof(pmp->data)) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\t \n\tport_mask = be64_to_cpu(req->port_select_mask[3]);\n\tport_num = find_first_bit((unsigned long *)&port_mask,\n\t\t\t\t  sizeof(port_mask) * 8);\n\n\tif (port_num != port) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\trsp->port_number = port;\n\n\t \n\trsp->port_rcv_ei.status_and_code =\n\t\tdd->err_info_rcvport.status_and_code;\n\tmemcpy(&rsp->port_rcv_ei.ei.ei1to12.packet_flit1,\n\t       &dd->err_info_rcvport.packet_flit1, sizeof(u64));\n\tmemcpy(&rsp->port_rcv_ei.ei.ei1to12.packet_flit2,\n\t       &dd->err_info_rcvport.packet_flit2, sizeof(u64));\n\n\t \n\treg = read_csr(dd, RCV_ERR_INFO);\n\tif (reg & RCV_ERR_INFO_RCV_EXCESS_BUFFER_OVERRUN_SMASK) {\n\t\t \n\t\tu8 tmp = (u8)reg;\n\n\t\ttmp &=  RCV_ERR_INFO_RCV_EXCESS_BUFFER_OVERRUN_SC_SMASK;\n\t\ttmp <<= 2;\n\t\trsp->excessive_buffer_overrun_ei.status_and_sc = tmp;\n\t\t \n\t\trsp->excessive_buffer_overrun_ei.status_and_sc |= 0x80;\n\t}\n\n\trsp->port_xmit_constraint_ei.status =\n\t\tdd->err_info_xmit_constraint.status;\n\trsp->port_xmit_constraint_ei.pkey =\n\t\tcpu_to_be16(dd->err_info_xmit_constraint.pkey);\n\trsp->port_xmit_constraint_ei.slid =\n\t\tcpu_to_be32(dd->err_info_xmit_constraint.slid);\n\n\trsp->port_rcv_constraint_ei.status =\n\t\tdd->err_info_rcv_constraint.status;\n\trsp->port_rcv_constraint_ei.pkey =\n\t\tcpu_to_be16(dd->err_info_rcv_constraint.pkey);\n\trsp->port_rcv_constraint_ei.slid =\n\t\tcpu_to_be32(dd->err_info_rcv_constraint.slid);\n\n\t \n\trsp->uncorrectable_ei.status_and_code = dd->err_info_uncorrectable;\n\n\t \n\trsp->fm_config_ei.status_and_code = dd->err_info_fmconfig;\n\n\tif (resp_len)\n\t\t*resp_len += response_data_size;\n\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic int pma_set_opa_portstatus(struct opa_pma_mad *pmp,\n\t\t\t\t  struct ib_device *ibdev,\n\t\t\t\t  u32 port, u32 *resp_len)\n{\n\tstruct opa_clear_port_status *req =\n\t\t(struct opa_clear_port_status *)pmp->data;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tu32 nports = be32_to_cpu(pmp->mad_hdr.attr_mod) >> 24;\n\tu64 portn = be64_to_cpu(req->port_select_mask[3]);\n\tu32 counter_select = be32_to_cpu(req->counter_select_mask);\n\tunsigned long vl_select_mask = VL_MASK_ALL;  \n\tunsigned long vl;\n\n\tif ((nports != 1) || (portn != 1 << port)) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\t \n\n\tif (counter_select & CS_PORT_XMIT_DATA)\n\t\twrite_dev_cntr(dd, C_DC_XMIT_FLITS, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_RCV_DATA)\n\t\twrite_dev_cntr(dd, C_DC_RCV_FLITS, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_XMIT_PKTS)\n\t\twrite_dev_cntr(dd, C_DC_XMIT_PKTS, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_RCV_PKTS)\n\t\twrite_dev_cntr(dd, C_DC_RCV_PKTS, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_MCAST_XMIT_PKTS)\n\t\twrite_dev_cntr(dd, C_DC_MC_XMIT_PKTS, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_MCAST_RCV_PKTS)\n\t\twrite_dev_cntr(dd, C_DC_MC_RCV_PKTS, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_XMIT_WAIT) {\n\t\twrite_port_cntr(ppd, C_TX_WAIT, CNTR_INVALID_VL, 0);\n\t\tppd->port_vl_xmit_wait_last[C_VL_COUNT] = 0;\n\t\tppd->vl_xmit_flit_cnt[C_VL_COUNT] = 0;\n\t}\n\t \n\n\tif (counter_select & CS_PORT_RCV_FECN)\n\t\twrite_dev_cntr(dd, C_DC_RCV_FCN, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_RCV_BECN)\n\t\twrite_dev_cntr(dd, C_DC_RCV_BCN, CNTR_INVALID_VL, 0);\n\n\t \n\t \n\t \n\tif (counter_select & CS_PORT_RCV_BUBBLE)\n\t\twrite_dev_cntr(dd, C_DC_RCV_BBL, CNTR_INVALID_VL, 0);\n\n\t \n\t \n\n\tif (counter_select & CS_PORT_RCV_CONSTRAINT_ERRORS)\n\t\twrite_port_cntr(ppd, C_SW_RCV_CSTR_ERR, CNTR_INVALID_VL, 0);\n\n\t \n\tif (counter_select & CS_PORT_XMIT_DISCARDS)\n\t\twrite_port_cntr(ppd, C_SW_XMIT_DSCD, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_XMIT_CONSTRAINT_ERRORS)\n\t\twrite_port_cntr(ppd, C_SW_XMIT_CSTR_ERR, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_PORT_RCV_REMOTE_PHYSICAL_ERRORS)\n\t\twrite_dev_cntr(dd, C_DC_RMT_PHY_ERR, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_LOCAL_LINK_INTEGRITY_ERRORS)\n\t\twrite_dev_cntr(dd, C_DC_RX_REPLAY, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_LINK_ERROR_RECOVERY) {\n\t\twrite_dev_cntr(dd, C_DC_SEQ_CRC_CNT, CNTR_INVALID_VL, 0);\n\t\twrite_dev_cntr(dd, C_DC_REINIT_FROM_PEER_CNT,\n\t\t\t       CNTR_INVALID_VL, 0);\n\t}\n\n\tif (counter_select & CS_PORT_RCV_ERRORS)\n\t\twrite_dev_cntr(dd, C_DC_RCV_ERR, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_EXCESSIVE_BUFFER_OVERRUNS) {\n\t\twrite_dev_cntr(dd, C_RCV_OVF, CNTR_INVALID_VL, 0);\n\t\tdd->rcv_ovfl_cnt = 0;\n\t}\n\n\tif (counter_select & CS_FM_CONFIG_ERRORS)\n\t\twrite_dev_cntr(dd, C_DC_FM_CFG_ERR, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_LINK_DOWNED)\n\t\twrite_port_cntr(ppd, C_SW_LINK_DOWN, CNTR_INVALID_VL, 0);\n\n\tif (counter_select & CS_UNCORRECTABLE_ERRORS)\n\t\twrite_dev_cntr(dd, C_DC_UNC_ERR, CNTR_INVALID_VL, 0);\n\n\tfor_each_set_bit(vl, &vl_select_mask, BITS_PER_LONG) {\n\t\tif (counter_select & CS_PORT_XMIT_DATA)\n\t\t\twrite_port_cntr(ppd, C_TX_FLIT_VL, idx_from_vl(vl), 0);\n\n\t\tif (counter_select & CS_PORT_RCV_DATA)\n\t\t\twrite_dev_cntr(dd, C_DC_RX_FLIT_VL, idx_from_vl(vl), 0);\n\n\t\tif (counter_select & CS_PORT_XMIT_PKTS)\n\t\t\twrite_port_cntr(ppd, C_TX_PKT_VL, idx_from_vl(vl), 0);\n\n\t\tif (counter_select & CS_PORT_RCV_PKTS)\n\t\t\twrite_dev_cntr(dd, C_DC_RX_PKT_VL, idx_from_vl(vl), 0);\n\n\t\tif (counter_select & CS_PORT_XMIT_WAIT) {\n\t\t\twrite_port_cntr(ppd, C_TX_WAIT_VL, idx_from_vl(vl), 0);\n\t\t\tppd->port_vl_xmit_wait_last[idx_from_vl(vl)] = 0;\n\t\t\tppd->vl_xmit_flit_cnt[idx_from_vl(vl)] = 0;\n\t\t}\n\n\t\t \n\t\tif (counter_select & CS_PORT_RCV_FECN)\n\t\t\twrite_dev_cntr(dd, C_DC_RCV_FCN_VL, idx_from_vl(vl), 0);\n\n\t\tif (counter_select & CS_PORT_RCV_BECN)\n\t\t\twrite_dev_cntr(dd, C_DC_RCV_BCN_VL, idx_from_vl(vl), 0);\n\n\t\t \n\t\t \n\t\t \n\t\tif (counter_select & CS_PORT_RCV_BUBBLE)\n\t\t\twrite_dev_cntr(dd, C_DC_RCV_BBL_VL, idx_from_vl(vl), 0);\n\n\t\t \n\t\tif (counter_select & C_SW_XMIT_DSCD_VL)\n\t\t\twrite_port_cntr(ppd, C_SW_XMIT_DSCD_VL,\n\t\t\t\t\tidx_from_vl(vl), 0);\n\t}\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(*req);\n\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstatic int pma_set_opa_errorinfo(struct opa_pma_mad *pmp,\n\t\t\t\t struct ib_device *ibdev,\n\t\t\t\t u32 port, u32 *resp_len)\n{\n\tstruct _port_ei *rsp;\n\tstruct opa_port_error_info_msg *req;\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu64 port_mask;\n\tu32 num_ports;\n\tu32 port_num;\n\tu8 num_pslm;\n\tu32 error_info_select;\n\n\treq = (struct opa_port_error_info_msg *)pmp->data;\n\trsp = &req->port;\n\n\tnum_ports = OPA_AM_NPORT(be32_to_cpu(pmp->mad_hdr.attr_mod));\n\tnum_pslm = hweight64(be64_to_cpu(req->port_select_mask[3]));\n\n\tmemset(rsp, 0, sizeof(*rsp));\n\n\tif (num_ports != 1 || num_ports != num_pslm) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\t \n\tport_mask = be64_to_cpu(req->port_select_mask[3]);\n\tport_num = find_first_bit((unsigned long *)&port_mask,\n\t\t\t\t  sizeof(port_mask) * 8);\n\n\tif (port_num != port) {\n\t\tpmp->mad_hdr.status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\terror_info_select = be32_to_cpu(req->error_info_select_mask);\n\n\t \n\tif (error_info_select & ES_PORT_RCV_ERROR_INFO)\n\t\t \n\t\tdd->err_info_rcvport.status_and_code &= ~OPA_EI_STATUS_SMASK;\n\n\t \n\tif (error_info_select & ES_EXCESSIVE_BUFFER_OVERRUN_INFO)\n\t\t \n\t\twrite_csr(dd, RCV_ERR_INFO,\n\t\t\t  RCV_ERR_INFO_RCV_EXCESS_BUFFER_OVERRUN_SMASK);\n\n\tif (error_info_select & ES_PORT_XMIT_CONSTRAINT_ERROR_INFO)\n\t\tdd->err_info_xmit_constraint.status &= ~OPA_EI_STATUS_SMASK;\n\n\tif (error_info_select & ES_PORT_RCV_CONSTRAINT_ERROR_INFO)\n\t\tdd->err_info_rcv_constraint.status &= ~OPA_EI_STATUS_SMASK;\n\n\t \n\tif (error_info_select & ES_UNCORRECTABLE_ERROR_INFO)\n\t\t \n\t\tdd->err_info_uncorrectable &= ~OPA_EI_STATUS_SMASK;\n\n\t \n\tif (error_info_select & ES_FM_CONFIG_ERROR_INFO)\n\t\t \n\t\tdd->err_info_fmconfig &= ~OPA_EI_STATUS_SMASK;\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(*req);\n\n\treturn reply((struct ib_mad_hdr *)pmp);\n}\n\nstruct opa_congestion_info_attr {\n\t__be16 congestion_info;\n\tu8 control_table_cap;\t \n\tu8 congestion_log_length;\n} __packed;\n\nstatic int __subn_get_opa_cong_info(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t    struct ib_device *ibdev, u32 port,\n\t\t\t\t    u32 *resp_len, u32 max_len)\n{\n\tstruct opa_congestion_info_attr *p =\n\t\t(struct opa_congestion_info_attr *)data;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\n\tif (smp_length_check(sizeof(*p), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tp->congestion_info = 0;\n\tp->control_table_cap = ppd->cc_max_table_entries;\n\tp->congestion_log_length = OPA_CONG_LOG_ELEMS;\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(*p);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_get_opa_cong_setting(struct opa_smp *smp, u32 am,\n\t\t\t\t       u8 *data, struct ib_device *ibdev,\n\t\t\t\t       u32 port, u32 *resp_len, u32 max_len)\n{\n\tint i;\n\tstruct opa_congestion_setting_attr *p =\n\t\t(struct opa_congestion_setting_attr *)data;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tstruct opa_congestion_setting_entry_shadow *entries;\n\tstruct cc_state *cc_state;\n\n\tif (smp_length_check(sizeof(*p), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\trcu_read_lock();\n\n\tcc_state = get_cc_state(ppd);\n\n\tif (!cc_state) {\n\t\trcu_read_unlock();\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tentries = cc_state->cong_setting.entries;\n\tp->port_control = cpu_to_be16(cc_state->cong_setting.port_control);\n\tp->control_map = cpu_to_be32(cc_state->cong_setting.control_map);\n\tfor (i = 0; i < OPA_MAX_SLS; i++) {\n\t\tp->entries[i].ccti_increase = entries[i].ccti_increase;\n\t\tp->entries[i].ccti_timer = cpu_to_be16(entries[i].ccti_timer);\n\t\tp->entries[i].trigger_threshold =\n\t\t\tentries[i].trigger_threshold;\n\t\tp->entries[i].ccti_min = entries[i].ccti_min;\n\t}\n\n\trcu_read_unlock();\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(*p);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\n \nstatic void apply_cc_state(struct hfi1_pportdata *ppd)\n{\n\tstruct cc_state *old_cc_state, *new_cc_state;\n\n\tnew_cc_state = kzalloc(sizeof(*new_cc_state), GFP_KERNEL);\n\tif (!new_cc_state)\n\t\treturn;\n\n\t \n\tspin_lock(&ppd->cc_state_lock);\n\n\told_cc_state = get_cc_state_protected(ppd);\n\tif (!old_cc_state) {\n\t\t \n\t\tspin_unlock(&ppd->cc_state_lock);\n\t\tkfree(new_cc_state);\n\t\treturn;\n\t}\n\n\t*new_cc_state = *old_cc_state;\n\n\tif (ppd->total_cct_entry)\n\t\tnew_cc_state->cct.ccti_limit = ppd->total_cct_entry - 1;\n\telse\n\t\tnew_cc_state->cct.ccti_limit = 0;\n\n\tmemcpy(new_cc_state->cct.entries, ppd->ccti_entries,\n\t       ppd->total_cct_entry * sizeof(struct ib_cc_table_entry));\n\n\tnew_cc_state->cong_setting.port_control = IB_CC_CCS_PC_SL_BASED;\n\tnew_cc_state->cong_setting.control_map = ppd->cc_sl_control_map;\n\tmemcpy(new_cc_state->cong_setting.entries, ppd->congestion_entries,\n\t       OPA_MAX_SLS * sizeof(struct opa_congestion_setting_entry));\n\n\trcu_assign_pointer(ppd->cc_state, new_cc_state);\n\n\tspin_unlock(&ppd->cc_state_lock);\n\n\tkfree_rcu(old_cc_state, rcu);\n}\n\nstatic int __subn_set_opa_cong_setting(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t       struct ib_device *ibdev, u32 port,\n\t\t\t\t       u32 *resp_len, u32 max_len)\n{\n\tstruct opa_congestion_setting_attr *p =\n\t\t(struct opa_congestion_setting_attr *)data;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tstruct opa_congestion_setting_entry_shadow *entries;\n\tint i;\n\n\tif (smp_length_check(sizeof(*p), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\t \n\tspin_lock(&ppd->cc_state_lock);\n\tppd->cc_sl_control_map = be32_to_cpu(p->control_map);\n\n\tentries = ppd->congestion_entries;\n\tfor (i = 0; i < OPA_MAX_SLS; i++) {\n\t\tentries[i].ccti_increase = p->entries[i].ccti_increase;\n\t\tentries[i].ccti_timer = be16_to_cpu(p->entries[i].ccti_timer);\n\t\tentries[i].trigger_threshold =\n\t\t\tp->entries[i].trigger_threshold;\n\t\tentries[i].ccti_min = p->entries[i].ccti_min;\n\t}\n\tspin_unlock(&ppd->cc_state_lock);\n\n\t \n\tapply_cc_state(ppd);\n\n\treturn __subn_get_opa_cong_setting(smp, am, data, ibdev, port,\n\t\t\t\t\t   resp_len, max_len);\n}\n\nstatic int __subn_get_opa_hfi1_cong_log(struct opa_smp *smp, u32 am,\n\t\t\t\t\tu8 *data, struct ib_device *ibdev,\n\t\t\t\t\tu32 port, u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tstruct opa_hfi1_cong_log *cong_log = (struct opa_hfi1_cong_log *)data;\n\tu64 ts;\n\tint i;\n\n\tif (am || smp_length_check(sizeof(*cong_log), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tspin_lock_irq(&ppd->cc_log_lock);\n\n\tcong_log->log_type = OPA_CC_LOG_TYPE_HFI;\n\tcong_log->congestion_flags = 0;\n\tcong_log->threshold_event_counter =\n\t\tcpu_to_be16(ppd->threshold_event_counter);\n\tmemcpy(cong_log->threshold_cong_event_map,\n\t       ppd->threshold_cong_event_map,\n\t       sizeof(cong_log->threshold_cong_event_map));\n\t \n\tts = ktime_get_ns() / 1024;\n\tcong_log->current_time_stamp = cpu_to_be32(ts);\n\tfor (i = 0; i < OPA_CONG_LOG_ELEMS; i++) {\n\t\tstruct opa_hfi1_cong_log_event_internal *cce =\n\t\t\t&ppd->cc_events[ppd->cc_mad_idx++];\n\t\tif (ppd->cc_mad_idx == OPA_CONG_LOG_ELEMS)\n\t\t\tppd->cc_mad_idx = 0;\n\t\t \n\t\tif ((ts - cce->timestamp) / 2 > U32_MAX)\n\t\t\tcontinue;\n\t\tmemcpy(cong_log->events[i].local_qp_cn_entry, &cce->lqpn, 3);\n\t\tmemcpy(cong_log->events[i].remote_qp_number_cn_entry,\n\t\t       &cce->rqpn, 3);\n\t\tcong_log->events[i].sl_svc_type_cn_entry =\n\t\t\t((cce->sl & 0x1f) << 3) | (cce->svc_type & 0x7);\n\t\tcong_log->events[i].remote_lid_cn_entry =\n\t\t\tcpu_to_be32(cce->rlid);\n\t\tcong_log->events[i].timestamp_cn_entry =\n\t\t\tcpu_to_be32(cce->timestamp);\n\t}\n\n\t \n\tmemset(ppd->threshold_cong_event_map, 0x0,\n\t       sizeof(ppd->threshold_cong_event_map));\n\tppd->threshold_event_counter = 0;\n\n\tspin_unlock_irq(&ppd->cc_log_lock);\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(struct opa_hfi1_cong_log);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_get_opa_cc_table(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct ib_cc_table_attr *cc_table_attr =\n\t\t(struct ib_cc_table_attr *)data;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tu32 start_block = OPA_AM_START_BLK(am);\n\tu32 n_blocks = OPA_AM_NBLK(am);\n\tstruct ib_cc_table_entry_shadow *entries;\n\tint i, j;\n\tu32 sentry, eentry;\n\tstruct cc_state *cc_state;\n\tu32 size = sizeof(u16) * (IB_CCT_ENTRIES * n_blocks + 1);\n\n\t \n\tif (n_blocks == 0 || smp_length_check(size, max_len) ||\n\t    start_block + n_blocks > ppd->cc_max_table_entries) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\trcu_read_lock();\n\n\tcc_state = get_cc_state(ppd);\n\n\tif (!cc_state) {\n\t\trcu_read_unlock();\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tsentry = start_block * IB_CCT_ENTRIES;\n\teentry = sentry + (IB_CCT_ENTRIES * n_blocks);\n\n\tcc_table_attr->ccti_limit = cpu_to_be16(cc_state->cct.ccti_limit);\n\n\tentries = cc_state->cct.entries;\n\n\t \n\tfor (j = 0, i = sentry; i < eentry; j++, i++)\n\t\tcc_table_attr->ccti_entries[j].entry =\n\t\t\tcpu_to_be16(entries[i].entry);\n\n\trcu_read_unlock();\n\n\tif (resp_len)\n\t\t*resp_len += size;\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_cc_table(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct ib_cc_table_attr *p = (struct ib_cc_table_attr *)data;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tu32 start_block = OPA_AM_START_BLK(am);\n\tu32 n_blocks = OPA_AM_NBLK(am);\n\tstruct ib_cc_table_entry_shadow *entries;\n\tint i, j;\n\tu32 sentry, eentry;\n\tu16 ccti_limit;\n\tu32 size = sizeof(u16) * (IB_CCT_ENTRIES * n_blocks + 1);\n\n\t \n\tif (n_blocks == 0 || smp_length_check(size, max_len) ||\n\t    start_block + n_blocks > ppd->cc_max_table_entries) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tsentry = start_block * IB_CCT_ENTRIES;\n\teentry = sentry + ((n_blocks - 1) * IB_CCT_ENTRIES) +\n\t\t (be16_to_cpu(p->ccti_limit)) % IB_CCT_ENTRIES + 1;\n\n\t \n\tccti_limit = be16_to_cpu(p->ccti_limit);\n\tif (ccti_limit + 1 > eentry) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\t \n\tspin_lock(&ppd->cc_state_lock);\n\tppd->total_cct_entry = ccti_limit + 1;\n\tentries = ppd->ccti_entries;\n\tfor (j = 0, i = sentry; i < eentry; j++, i++)\n\t\tentries[i].entry = be16_to_cpu(p->ccti_entries[j].entry);\n\tspin_unlock(&ppd->cc_state_lock);\n\n\t \n\tapply_cc_state(ppd);\n\n\treturn __subn_get_opa_cc_table(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t       max_len);\n}\n\nstruct opa_led_info {\n\t__be32 rsvd_led_mask;\n\t__be32 rsvd;\n};\n\n#define OPA_LED_SHIFT\t31\n#define OPA_LED_MASK\tBIT(OPA_LED_SHIFT)\n\nstatic int __subn_get_opa_led_info(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct hfi1_pportdata *ppd = dd->pport;\n\tstruct opa_led_info *p = (struct opa_led_info *)data;\n\tu32 nport = OPA_AM_NPORT(am);\n\tu32 is_beaconing_active;\n\n\tif (nport != 1 || smp_length_check(sizeof(*p), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\t \n\tsmp_rmb();\n\tis_beaconing_active = !!atomic_read(&ppd->led_override_timer_active);\n\tp->rsvd_led_mask = cpu_to_be32(is_beaconing_active << OPA_LED_SHIFT);\n\n\tif (resp_len)\n\t\t*resp_len += sizeof(struct opa_led_info);\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int __subn_set_opa_led_info(struct opa_smp *smp, u32 am, u8 *data,\n\t\t\t\t   struct ib_device *ibdev, u32 port,\n\t\t\t\t   u32 *resp_len, u32 max_len)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tstruct opa_led_info *p = (struct opa_led_info *)data;\n\tu32 nport = OPA_AM_NPORT(am);\n\tint on = !!(be32_to_cpu(p->rsvd_led_mask) & OPA_LED_MASK);\n\n\tif (nport != 1 || smp_length_check(sizeof(*p), max_len)) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tif (on)\n\t\thfi1_start_led_override(dd->pport, 2000, 1500);\n\telse\n\t\tshutdown_led_override(dd->pport);\n\n\treturn __subn_get_opa_led_info(smp, am, data, ibdev, port, resp_len,\n\t\t\t\t       max_len);\n}\n\nstatic int subn_get_opa_sma(__be16 attr_id, struct opa_smp *smp, u32 am,\n\t\t\t    u8 *data, struct ib_device *ibdev, u32 port,\n\t\t\t    u32 *resp_len, u32 max_len)\n{\n\tint ret;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\n\tswitch (attr_id) {\n\tcase IB_SMP_ATTR_NODE_DESC:\n\t\tret = __subn_get_opa_nodedesc(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_NODE_INFO:\n\t\tret = __subn_get_opa_nodeinfo(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_PORT_INFO:\n\t\tret = __subn_get_opa_portinfo(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_PKEY_TABLE:\n\t\tret = __subn_get_opa_pkeytable(smp, am, data, ibdev, port,\n\t\t\t\t\t       resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SL_TO_SC_MAP:\n\t\tret = __subn_get_opa_sl_to_sc(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SC_TO_SL_MAP:\n\t\tret = __subn_get_opa_sc_to_sl(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SC_TO_VLT_MAP:\n\t\tret = __subn_get_opa_sc_to_vlt(smp, am, data, ibdev, port,\n\t\t\t\t\t       resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SC_TO_VLNT_MAP:\n\t\tret = __subn_get_opa_sc_to_vlnt(smp, am, data, ibdev, port,\n\t\t\t\t\t\tresp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_PORT_STATE_INFO:\n\t\tret = __subn_get_opa_psi(smp, am, data, ibdev, port,\n\t\t\t\t\t resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_BUFFER_CONTROL_TABLE:\n\t\tret = __subn_get_opa_bct(smp, am, data, ibdev, port,\n\t\t\t\t\t resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_CABLE_INFO:\n\t\tret = __subn_get_opa_cable_info(smp, am, data, ibdev, port,\n\t\t\t\t\t\tresp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_VL_ARB_TABLE:\n\t\tret = __subn_get_opa_vl_arb(smp, am, data, ibdev, port,\n\t\t\t\t\t    resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_CONGESTION_INFO:\n\t\tret = __subn_get_opa_cong_info(smp, am, data, ibdev, port,\n\t\t\t\t\t       resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_HFI_CONGESTION_SETTING:\n\t\tret = __subn_get_opa_cong_setting(smp, am, data, ibdev,\n\t\t\t\t\t\t  port, resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_HFI_CONGESTION_LOG:\n\t\tret = __subn_get_opa_hfi1_cong_log(smp, am, data, ibdev,\n\t\t\t\t\t\t   port, resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_CONGESTION_CONTROL_TABLE:\n\t\tret = __subn_get_opa_cc_table(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_LED_INFO:\n\t\tret = __subn_get_opa_led_info(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_SM_INFO:\n\t\tif (ibp->rvp.port_cap_flags & IB_PORT_SM_DISABLED)\n\t\t\treturn IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_CONSUMED;\n\t\tif (ibp->rvp.port_cap_flags & IB_PORT_SM)\n\t\t\treturn IB_MAD_RESULT_SUCCESS;\n\t\tfallthrough;\n\tdefault:\n\t\tsmp->status |= IB_SMP_UNSUP_METH_ATTR;\n\t\tret = reply((struct ib_mad_hdr *)smp);\n\t\tbreak;\n\t}\n\treturn ret;\n}\n\nstatic int subn_set_opa_sma(__be16 attr_id, struct opa_smp *smp, u32 am,\n\t\t\t    u8 *data, struct ib_device *ibdev, u32 port,\n\t\t\t    u32 *resp_len, u32 max_len, int local_mad)\n{\n\tint ret;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\n\tswitch (attr_id) {\n\tcase IB_SMP_ATTR_PORT_INFO:\n\t\tret = __subn_set_opa_portinfo(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len, local_mad);\n\t\tbreak;\n\tcase IB_SMP_ATTR_PKEY_TABLE:\n\t\tret = __subn_set_opa_pkeytable(smp, am, data, ibdev, port,\n\t\t\t\t\t       resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SL_TO_SC_MAP:\n\t\tret = __subn_set_opa_sl_to_sc(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SC_TO_SL_MAP:\n\t\tret = __subn_set_opa_sc_to_sl(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SC_TO_VLT_MAP:\n\t\tret = __subn_set_opa_sc_to_vlt(smp, am, data, ibdev, port,\n\t\t\t\t\t       resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_SC_TO_VLNT_MAP:\n\t\tret = __subn_set_opa_sc_to_vlnt(smp, am, data, ibdev, port,\n\t\t\t\t\t\tresp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_PORT_STATE_INFO:\n\t\tret = __subn_set_opa_psi(smp, am, data, ibdev, port,\n\t\t\t\t\t resp_len, max_len, local_mad);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_BUFFER_CONTROL_TABLE:\n\t\tret = __subn_set_opa_bct(smp, am, data, ibdev, port,\n\t\t\t\t\t resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_VL_ARB_TABLE:\n\t\tret = __subn_set_opa_vl_arb(smp, am, data, ibdev, port,\n\t\t\t\t\t    resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_HFI_CONGESTION_SETTING:\n\t\tret = __subn_set_opa_cong_setting(smp, am, data, ibdev,\n\t\t\t\t\t\t  port, resp_len, max_len);\n\t\tbreak;\n\tcase OPA_ATTRIB_ID_CONGESTION_CONTROL_TABLE:\n\t\tret = __subn_set_opa_cc_table(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_LED_INFO:\n\t\tret = __subn_set_opa_led_info(smp, am, data, ibdev, port,\n\t\t\t\t\t      resp_len, max_len);\n\t\tbreak;\n\tcase IB_SMP_ATTR_SM_INFO:\n\t\tif (ibp->rvp.port_cap_flags & IB_PORT_SM_DISABLED)\n\t\t\treturn IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_CONSUMED;\n\t\tif (ibp->rvp.port_cap_flags & IB_PORT_SM)\n\t\t\treturn IB_MAD_RESULT_SUCCESS;\n\t\tfallthrough;\n\tdefault:\n\t\tsmp->status |= IB_SMP_UNSUP_METH_ATTR;\n\t\tret = reply((struct ib_mad_hdr *)smp);\n\t\tbreak;\n\t}\n\treturn ret;\n}\n\nstatic inline void set_aggr_error(struct opa_aggregate *ag)\n{\n\tag->err_reqlength |= cpu_to_be16(0x8000);\n}\n\nstatic int subn_get_opa_aggregate(struct opa_smp *smp,\n\t\t\t\t  struct ib_device *ibdev, u32 port,\n\t\t\t\t  u32 *resp_len)\n{\n\tint i;\n\tu32 num_attr = be32_to_cpu(smp->attr_mod) & 0x000000ff;\n\tu8 *next_smp = opa_get_smp_data(smp);\n\n\tif (num_attr < 1 || num_attr > 117) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tfor (i = 0; i < num_attr; i++) {\n\t\tstruct opa_aggregate *agg;\n\t\tsize_t agg_data_len;\n\t\tsize_t agg_size;\n\t\tu32 am;\n\n\t\tagg = (struct opa_aggregate *)next_smp;\n\t\tagg_data_len = (be16_to_cpu(agg->err_reqlength) & 0x007f) * 8;\n\t\tagg_size = sizeof(*agg) + agg_data_len;\n\t\tam = be32_to_cpu(agg->attr_mod);\n\n\t\t*resp_len += agg_size;\n\n\t\tif (next_smp + agg_size > ((u8 *)smp) + sizeof(*smp)) {\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t\treturn reply((struct ib_mad_hdr *)smp);\n\t\t}\n\n\t\t \n\t\tmemset(next_smp + sizeof(*agg), 0, agg_data_len);\n\n\t\t(void)subn_get_opa_sma(agg->attr_id, smp, am, agg->data,\n\t\t\t\t       ibdev, port, NULL, (u32)agg_data_len);\n\n\t\tif (smp->status & IB_SMP_INVALID_FIELD)\n\t\t\tbreak;\n\t\tif (smp->status & ~IB_SMP_DIRECTION) {\n\t\t\tset_aggr_error(agg);\n\t\t\treturn reply((struct ib_mad_hdr *)smp);\n\t\t}\n\t\tnext_smp += agg_size;\n\t}\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\nstatic int subn_set_opa_aggregate(struct opa_smp *smp,\n\t\t\t\t  struct ib_device *ibdev, u32 port,\n\t\t\t\t  u32 *resp_len, int local_mad)\n{\n\tint i;\n\tu32 num_attr = be32_to_cpu(smp->attr_mod) & 0x000000ff;\n\tu8 *next_smp = opa_get_smp_data(smp);\n\n\tif (num_attr < 1 || num_attr > 117) {\n\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\treturn reply((struct ib_mad_hdr *)smp);\n\t}\n\n\tfor (i = 0; i < num_attr; i++) {\n\t\tstruct opa_aggregate *agg;\n\t\tsize_t agg_data_len;\n\t\tsize_t agg_size;\n\t\tu32 am;\n\n\t\tagg = (struct opa_aggregate *)next_smp;\n\t\tagg_data_len = (be16_to_cpu(agg->err_reqlength) & 0x007f) * 8;\n\t\tagg_size = sizeof(*agg) + agg_data_len;\n\t\tam = be32_to_cpu(agg->attr_mod);\n\n\t\t*resp_len += agg_size;\n\n\t\tif (next_smp + agg_size > ((u8 *)smp) + sizeof(*smp)) {\n\t\t\tsmp->status |= IB_SMP_INVALID_FIELD;\n\t\t\treturn reply((struct ib_mad_hdr *)smp);\n\t\t}\n\n\t\t(void)subn_set_opa_sma(agg->attr_id, smp, am, agg->data,\n\t\t\t\t       ibdev, port, NULL, (u32)agg_data_len,\n\t\t\t\t       local_mad);\n\n\t\tif (smp->status & IB_SMP_INVALID_FIELD)\n\t\t\tbreak;\n\t\tif (smp->status & ~IB_SMP_DIRECTION) {\n\t\t\tset_aggr_error(agg);\n\t\t\treturn reply((struct ib_mad_hdr *)smp);\n\t\t}\n\t\tnext_smp += agg_size;\n\t}\n\n\treturn reply((struct ib_mad_hdr *)smp);\n}\n\n \nvoid clear_linkup_counters(struct hfi1_devdata *dd)\n{\n\t \n\twrite_dev_cntr(dd, C_DC_RCV_ERR, CNTR_INVALID_VL, 0);\n\tdd->err_info_rcvport.status_and_code &= ~OPA_EI_STATUS_SMASK;\n\t \n\twrite_dev_cntr(dd, C_DC_SEQ_CRC_CNT, CNTR_INVALID_VL, 0);\n\twrite_dev_cntr(dd, C_DC_REINIT_FROM_PEER_CNT, CNTR_INVALID_VL, 0);\n\t \n\twrite_dev_cntr(dd, C_DC_RX_REPLAY, CNTR_INVALID_VL, 0);\n\t \n\twrite_dev_cntr(dd, C_RCV_OVF, CNTR_INVALID_VL, 0);\n\tdd->rcv_ovfl_cnt = 0;\n\tdd->err_info_xmit_constraint.status &= ~OPA_EI_STATUS_SMASK;\n}\n\nstatic int is_full_mgmt_pkey_in_table(struct hfi1_ibport *ibp)\n{\n\tunsigned int i;\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\n\tfor (i = 0; i < ARRAY_SIZE(ppd->pkeys); ++i)\n\t\tif (ppd->pkeys[i] == FULL_MGMT_P_KEY)\n\t\t\treturn 1;\n\n\treturn 0;\n}\n\n \nstatic int is_local_mad(struct hfi1_ibport *ibp, const struct opa_mad *mad,\n\t\t\tconst struct ib_wc *in_wc)\n{\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tconst struct opa_smp *smp = (const struct opa_smp *)mad;\n\n\tif (smp->mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) {\n\t\treturn (smp->hop_cnt == 0 &&\n\t\t\tsmp->route.dr.dr_slid == OPA_LID_PERMISSIVE &&\n\t\t\tsmp->route.dr.dr_dlid == OPA_LID_PERMISSIVE);\n\t}\n\n\treturn (in_wc->slid == ppd->lid);\n}\n\n \nstatic int opa_local_smp_check(struct hfi1_ibport *ibp,\n\t\t\t       const struct ib_wc *in_wc)\n{\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tu16 pkey;\n\n\tif (in_wc->pkey_index >= ARRAY_SIZE(ppd->pkeys))\n\t\treturn 1;\n\n\tpkey = ppd->pkeys[in_wc->pkey_index];\n\t \n\tif (pkey == LIM_MGMT_P_KEY || pkey == FULL_MGMT_P_KEY)\n\t\treturn 0;\n\tingress_pkey_table_fail(ppd, pkey, in_wc->slid);\n\treturn 1;\n}\n\n \nstatic int hfi1_pkey_validation_pma(struct hfi1_ibport *ibp,\n\t\t\t\t    const struct opa_mad *in_mad,\n\t\t\t\t    const struct ib_wc *in_wc)\n{\n\tu16 pkey_value = hfi1_lookup_pkey_value(ibp, in_wc->pkey_index);\n\n\t \n\tif (!is_local_mad(ibp, in_mad, in_wc) &&\n\t    pkey_value != LIM_MGMT_P_KEY &&\n\t    pkey_value != FULL_MGMT_P_KEY)\n\t\treturn -EINVAL;\n\n\t \n\tif (pkey_value == LIM_MGMT_P_KEY &&\n\t    is_full_mgmt_pkey_in_table(ibp))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int process_subn_opa(struct ib_device *ibdev, int mad_flags,\n\t\t\t    u32 port, const struct opa_mad *in_mad,\n\t\t\t    struct opa_mad *out_mad,\n\t\t\t    u32 *resp_len, int local_mad)\n{\n\tstruct opa_smp *smp = (struct opa_smp *)out_mad;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tu8 *data;\n\tu32 am, data_size;\n\t__be16 attr_id;\n\tint ret;\n\n\t*out_mad = *in_mad;\n\tdata = opa_get_smp_data(smp);\n\tdata_size = (u32)opa_get_smp_data_size(smp);\n\n\tam = be32_to_cpu(smp->attr_mod);\n\tattr_id = smp->attr_id;\n\tif (smp->class_version != OPA_SM_CLASS_VERSION) {\n\t\tsmp->status |= IB_SMP_UNSUP_VERSION;\n\t\tret = reply((struct ib_mad_hdr *)smp);\n\t\treturn ret;\n\t}\n\tret = check_mkey(ibp, (struct ib_mad_hdr *)smp, mad_flags, smp->mkey,\n\t\t\t smp->route.dr.dr_slid, smp->route.dr.return_path,\n\t\t\t smp->hop_cnt);\n\tif (ret) {\n\t\tu32 port_num = be32_to_cpu(smp->attr_mod);\n\n\t\t \n\t\tif (attr_id == IB_SMP_ATTR_PORT_INFO &&\n\t\t    (smp->method == IB_MGMT_METHOD_GET ||\n\t\t     smp->method == IB_MGMT_METHOD_SET) &&\n\t\t    port_num && port_num <= ibdev->phys_port_cnt &&\n\t\t    port != port_num)\n\t\t\t(void)check_mkey(to_iport(ibdev, port_num),\n\t\t\t\t\t  (struct ib_mad_hdr *)smp, 0,\n\t\t\t\t\t  smp->mkey, smp->route.dr.dr_slid,\n\t\t\t\t\t  smp->route.dr.return_path,\n\t\t\t\t\t  smp->hop_cnt);\n\t\tret = IB_MAD_RESULT_FAILURE;\n\t\treturn ret;\n\t}\n\n\t*resp_len = opa_get_smp_header_size(smp);\n\n\tswitch (smp->method) {\n\tcase IB_MGMT_METHOD_GET:\n\t\tswitch (attr_id) {\n\t\tdefault:\n\t\t\tclear_opa_smp_data(smp);\n\t\t\tret = subn_get_opa_sma(attr_id, smp, am, data,\n\t\t\t\t\t       ibdev, port, resp_len,\n\t\t\t\t\t       data_size);\n\t\t\tbreak;\n\t\tcase OPA_ATTRIB_ID_AGGREGATE:\n\t\t\tret = subn_get_opa_aggregate(smp, ibdev, port,\n\t\t\t\t\t\t     resp_len);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase IB_MGMT_METHOD_SET:\n\t\tswitch (attr_id) {\n\t\tdefault:\n\t\t\tret = subn_set_opa_sma(attr_id, smp, am, data,\n\t\t\t\t\t       ibdev, port, resp_len,\n\t\t\t\t\t       data_size, local_mad);\n\t\t\tbreak;\n\t\tcase OPA_ATTRIB_ID_AGGREGATE:\n\t\t\tret = subn_set_opa_aggregate(smp, ibdev, port,\n\t\t\t\t\t\t     resp_len, local_mad);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase IB_MGMT_METHOD_TRAP:\n\tcase IB_MGMT_METHOD_REPORT:\n\tcase IB_MGMT_METHOD_REPORT_RESP:\n\tcase IB_MGMT_METHOD_GET_RESP:\n\t\t \n\t\tret = IB_MAD_RESULT_SUCCESS;\n\t\tbreak;\n\tcase IB_MGMT_METHOD_TRAP_REPRESS:\n\t\tsubn_handle_opa_trap_repress(ibp, smp);\n\t\t \n\t\tret = IB_MAD_RESULT_SUCCESS;\n\t\tbreak;\n\tdefault:\n\t\tsmp->status |= IB_SMP_UNSUP_METHOD;\n\t\tret = reply((struct ib_mad_hdr *)smp);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int process_subn(struct ib_device *ibdev, int mad_flags,\n\t\t\tu32 port, const struct ib_mad *in_mad,\n\t\t\tstruct ib_mad *out_mad)\n{\n\tstruct ib_smp *smp = (struct ib_smp *)out_mad;\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\tint ret;\n\n\t*out_mad = *in_mad;\n\tif (smp->class_version != 1) {\n\t\tsmp->status |= IB_SMP_UNSUP_VERSION;\n\t\tret = reply((struct ib_mad_hdr *)smp);\n\t\treturn ret;\n\t}\n\n\tret = check_mkey(ibp, (struct ib_mad_hdr *)smp, mad_flags,\n\t\t\t smp->mkey, (__force __be32)smp->dr_slid,\n\t\t\t smp->return_path, smp->hop_cnt);\n\tif (ret) {\n\t\tu32 port_num = be32_to_cpu(smp->attr_mod);\n\n\t\t \n\t\tif (in_mad->mad_hdr.attr_id == IB_SMP_ATTR_PORT_INFO &&\n\t\t    (smp->method == IB_MGMT_METHOD_GET ||\n\t\t     smp->method == IB_MGMT_METHOD_SET) &&\n\t\t    port_num && port_num <= ibdev->phys_port_cnt &&\n\t\t    port != port_num)\n\t\t\t(void)check_mkey(to_iport(ibdev, port_num),\n\t\t\t\t\t (struct ib_mad_hdr *)smp, 0,\n\t\t\t\t\t smp->mkey,\n\t\t\t\t\t (__force __be32)smp->dr_slid,\n\t\t\t\t\t smp->return_path, smp->hop_cnt);\n\t\tret = IB_MAD_RESULT_FAILURE;\n\t\treturn ret;\n\t}\n\n\tswitch (smp->method) {\n\tcase IB_MGMT_METHOD_GET:\n\t\tswitch (smp->attr_id) {\n\t\tcase IB_SMP_ATTR_NODE_INFO:\n\t\t\tret = subn_get_nodeinfo(smp, ibdev, port);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tsmp->status |= IB_SMP_UNSUP_METH_ATTR;\n\t\t\tret = reply((struct ib_mad_hdr *)smp);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int process_perf(struct ib_device *ibdev, u32 port,\n\t\t\tconst struct ib_mad *in_mad,\n\t\t\tstruct ib_mad *out_mad)\n{\n\tstruct ib_pma_mad *pmp = (struct ib_pma_mad *)out_mad;\n\tstruct ib_class_port_info *cpi = (struct ib_class_port_info *)\n\t\t\t\t\t\t&pmp->data;\n\tint ret = IB_MAD_RESULT_FAILURE;\n\n\t*out_mad = *in_mad;\n\tif (pmp->mad_hdr.class_version != 1) {\n\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_VERSION;\n\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\treturn ret;\n\t}\n\n\tswitch (pmp->mad_hdr.method) {\n\tcase IB_MGMT_METHOD_GET:\n\t\tswitch (pmp->mad_hdr.attr_id) {\n\t\tcase IB_PMA_PORT_COUNTERS:\n\t\t\tret = pma_get_ib_portcounters(pmp, ibdev, port);\n\t\t\tbreak;\n\t\tcase IB_PMA_PORT_COUNTERS_EXT:\n\t\t\tret = pma_get_ib_portcounters_ext(pmp, ibdev, port);\n\t\t\tbreak;\n\t\tcase IB_PMA_CLASS_PORT_INFO:\n\t\t\tcpi->capability_mask = IB_PMA_CLASS_CAP_EXT_WIDTH;\n\t\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_METH_ATTR;\n\t\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase IB_MGMT_METHOD_SET:\n\t\tif (pmp->mad_hdr.attr_id) {\n\t\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_METH_ATTR;\n\t\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\t}\n\t\tbreak;\n\n\tcase IB_MGMT_METHOD_TRAP:\n\tcase IB_MGMT_METHOD_GET_RESP:\n\t\t \n\t\tret = IB_MAD_RESULT_SUCCESS;\n\t\tbreak;\n\n\tdefault:\n\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_METHOD;\n\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int process_perf_opa(struct ib_device *ibdev, u32 port,\n\t\t\t    const struct opa_mad *in_mad,\n\t\t\t    struct opa_mad *out_mad, u32 *resp_len)\n{\n\tstruct opa_pma_mad *pmp = (struct opa_pma_mad *)out_mad;\n\tint ret;\n\n\t*out_mad = *in_mad;\n\n\tif (pmp->mad_hdr.class_version != OPA_SM_CLASS_VERSION) {\n\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_VERSION;\n\t\treturn reply((struct ib_mad_hdr *)pmp);\n\t}\n\n\t*resp_len = sizeof(pmp->mad_hdr);\n\n\tswitch (pmp->mad_hdr.method) {\n\tcase IB_MGMT_METHOD_GET:\n\t\tswitch (pmp->mad_hdr.attr_id) {\n\t\tcase IB_PMA_CLASS_PORT_INFO:\n\t\t\tret = pma_get_opa_classportinfo(pmp, ibdev, resp_len);\n\t\t\tbreak;\n\t\tcase OPA_PM_ATTRIB_ID_PORT_STATUS:\n\t\t\tret = pma_get_opa_portstatus(pmp, ibdev, port,\n\t\t\t\t\t\t     resp_len);\n\t\t\tbreak;\n\t\tcase OPA_PM_ATTRIB_ID_DATA_PORT_COUNTERS:\n\t\t\tret = pma_get_opa_datacounters(pmp, ibdev, port,\n\t\t\t\t\t\t       resp_len);\n\t\t\tbreak;\n\t\tcase OPA_PM_ATTRIB_ID_ERROR_PORT_COUNTERS:\n\t\t\tret = pma_get_opa_porterrors(pmp, ibdev, port,\n\t\t\t\t\t\t     resp_len);\n\t\t\tbreak;\n\t\tcase OPA_PM_ATTRIB_ID_ERROR_INFO:\n\t\t\tret = pma_get_opa_errorinfo(pmp, ibdev, port,\n\t\t\t\t\t\t    resp_len);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_METH_ATTR;\n\t\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase IB_MGMT_METHOD_SET:\n\t\tswitch (pmp->mad_hdr.attr_id) {\n\t\tcase OPA_PM_ATTRIB_ID_CLEAR_PORT_STATUS:\n\t\t\tret = pma_set_opa_portstatus(pmp, ibdev, port,\n\t\t\t\t\t\t     resp_len);\n\t\t\tbreak;\n\t\tcase OPA_PM_ATTRIB_ID_ERROR_INFO:\n\t\t\tret = pma_set_opa_errorinfo(pmp, ibdev, port,\n\t\t\t\t\t\t    resp_len);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_METH_ATTR;\n\t\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase IB_MGMT_METHOD_TRAP:\n\tcase IB_MGMT_METHOD_GET_RESP:\n\t\t \n\t\tret = IB_MAD_RESULT_SUCCESS;\n\t\tbreak;\n\n\tdefault:\n\t\tpmp->mad_hdr.status |= IB_SMP_UNSUP_METHOD;\n\t\tret = reply((struct ib_mad_hdr *)pmp);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int hfi1_process_opa_mad(struct ib_device *ibdev, int mad_flags,\n\t\t\t\tu32 port, const struct ib_wc *in_wc,\n\t\t\t\tconst struct ib_grh *in_grh,\n\t\t\t\tconst struct opa_mad *in_mad,\n\t\t\t\tstruct opa_mad *out_mad, size_t *out_mad_size,\n\t\t\t\tu16 *out_mad_pkey_index)\n{\n\tint ret;\n\tint pkey_idx;\n\tint local_mad = 0;\n\tu32 resp_len = in_wc->byte_len - sizeof(*in_grh);\n\tstruct hfi1_ibport *ibp = to_iport(ibdev, port);\n\n\tpkey_idx = hfi1_lookup_pkey_idx(ibp, LIM_MGMT_P_KEY);\n\tif (pkey_idx < 0) {\n\t\tpr_warn(\"failed to find limited mgmt pkey, defaulting 0x%x\\n\",\n\t\t\thfi1_get_pkey(ibp, 1));\n\t\tpkey_idx = 1;\n\t}\n\t*out_mad_pkey_index = (u16)pkey_idx;\n\n\tswitch (in_mad->mad_hdr.mgmt_class) {\n\tcase IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE:\n\tcase IB_MGMT_CLASS_SUBN_LID_ROUTED:\n\t\tlocal_mad = is_local_mad(ibp, in_mad, in_wc);\n\t\tif (local_mad) {\n\t\t\tret = opa_local_smp_check(ibp, in_wc);\n\t\t\tif (ret)\n\t\t\t\treturn IB_MAD_RESULT_FAILURE;\n\t\t}\n\t\tret = process_subn_opa(ibdev, mad_flags, port, in_mad,\n\t\t\t\t       out_mad, &resp_len, local_mad);\n\t\tgoto bail;\n\tcase IB_MGMT_CLASS_PERF_MGMT:\n\t\tret = hfi1_pkey_validation_pma(ibp, in_mad, in_wc);\n\t\tif (ret)\n\t\t\treturn IB_MAD_RESULT_FAILURE;\n\n\t\tret = process_perf_opa(ibdev, port, in_mad, out_mad, &resp_len);\n\t\tgoto bail;\n\n\tdefault:\n\t\tret = IB_MAD_RESULT_SUCCESS;\n\t}\n\nbail:\n\tif (ret & IB_MAD_RESULT_REPLY)\n\t\t*out_mad_size = round_up(resp_len, 8);\n\telse if (ret & IB_MAD_RESULT_SUCCESS)\n\t\t*out_mad_size = in_wc->byte_len - sizeof(struct ib_grh);\n\n\treturn ret;\n}\n\nstatic int hfi1_process_ib_mad(struct ib_device *ibdev, int mad_flags, u32 port,\n\t\t\t       const struct ib_wc *in_wc,\n\t\t\t       const struct ib_grh *in_grh,\n\t\t\t       const struct ib_mad *in_mad,\n\t\t\t       struct ib_mad *out_mad)\n{\n\tint ret;\n\n\tswitch (in_mad->mad_hdr.mgmt_class) {\n\tcase IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE:\n\tcase IB_MGMT_CLASS_SUBN_LID_ROUTED:\n\t\tret = process_subn(ibdev, mad_flags, port, in_mad, out_mad);\n\t\tbreak;\n\tcase IB_MGMT_CLASS_PERF_MGMT:\n\t\tret = process_perf(ibdev, port, in_mad, out_mad);\n\t\tbreak;\n\tdefault:\n\t\tret = IB_MAD_RESULT_SUCCESS;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n \nint hfi1_process_mad(struct ib_device *ibdev, int mad_flags, u32 port,\n\t\t     const struct ib_wc *in_wc, const struct ib_grh *in_grh,\n\t\t     const struct ib_mad *in_mad, struct ib_mad *out_mad,\n\t\t     size_t *out_mad_size, u16 *out_mad_pkey_index)\n{\n\tswitch (in_mad->mad_hdr.base_version) {\n\tcase OPA_MGMT_BASE_VERSION:\n\t\treturn hfi1_process_opa_mad(ibdev, mad_flags, port,\n\t\t\t\t\t    in_wc, in_grh,\n\t\t\t\t\t    (struct opa_mad *)in_mad,\n\t\t\t\t\t    (struct opa_mad *)out_mad,\n\t\t\t\t\t    out_mad_size,\n\t\t\t\t\t    out_mad_pkey_index);\n\tcase IB_MGMT_BASE_VERSION:\n\t\treturn hfi1_process_ib_mad(ibdev, mad_flags, port, in_wc,\n\t\t\t\t\t   in_grh, in_mad, out_mad);\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn IB_MAD_RESULT_FAILURE;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}