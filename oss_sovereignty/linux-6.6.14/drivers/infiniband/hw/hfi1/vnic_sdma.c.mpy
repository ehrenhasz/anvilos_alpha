{
  "module_name": "vnic_sdma.c",
  "hash_id": "e2edbbdf9a4833dfddafaeacce0bf74de38067fbfb6a9b8521e7630dcfbf8b09",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/hfi1/vnic_sdma.c",
  "human_readable_source": "\n \n\n \n\n#include \"sdma.h\"\n#include \"vnic.h\"\n\n#define HFI1_VNIC_SDMA_Q_ACTIVE   BIT(0)\n#define HFI1_VNIC_SDMA_Q_DEFERRED BIT(1)\n\n#define HFI1_VNIC_TXREQ_NAME_LEN   32\n#define HFI1_VNIC_SDMA_DESC_WTRMRK 64\n\n \nstruct vnic_txreq {\n\tstruct sdma_txreq       txreq;\n\tstruct hfi1_vnic_sdma   *sdma;\n\n\tstruct sk_buff         *skb;\n\tunsigned char           pad[HFI1_VNIC_MAX_PAD];\n\tu16                     plen;\n\t__le64                  pbc_val;\n};\n\nstatic void vnic_sdma_complete(struct sdma_txreq *txreq,\n\t\t\t       int status)\n{\n\tstruct vnic_txreq *tx = container_of(txreq, struct vnic_txreq, txreq);\n\tstruct hfi1_vnic_sdma *vnic_sdma = tx->sdma;\n\n\tsdma_txclean(vnic_sdma->dd, txreq);\n\tdev_kfree_skb_any(tx->skb);\n\tkmem_cache_free(vnic_sdma->dd->vnic.txreq_cache, tx);\n}\n\nstatic noinline int build_vnic_ulp_payload(struct sdma_engine *sde,\n\t\t\t\t\t   struct vnic_txreq *tx)\n{\n\tint i, ret = 0;\n\n\tret = sdma_txadd_kvaddr(\n\t\tsde->dd,\n\t\t&tx->txreq,\n\t\ttx->skb->data,\n\t\tskb_headlen(tx->skb));\n\tif (unlikely(ret))\n\t\tgoto bail_txadd;\n\n\tfor (i = 0; i < skb_shinfo(tx->skb)->nr_frags; i++) {\n\t\tskb_frag_t *frag = &skb_shinfo(tx->skb)->frags[i];\n\n\t\t \n\t\tret = sdma_txadd_page(sde->dd,\n\t\t\t\t      &tx->txreq,\n\t\t\t\t      skb_frag_page(frag),\n\t\t\t\t      skb_frag_off(frag),\n\t\t\t\t      skb_frag_size(frag),\n\t\t\t\t      NULL, NULL, NULL);\n\t\tif (unlikely(ret))\n\t\t\tgoto bail_txadd;\n\t}\n\n\tif (tx->plen)\n\t\tret = sdma_txadd_kvaddr(sde->dd, &tx->txreq,\n\t\t\t\t\ttx->pad + HFI1_VNIC_MAX_PAD - tx->plen,\n\t\t\t\t\ttx->plen);\n\nbail_txadd:\n\treturn ret;\n}\n\nstatic int build_vnic_tx_desc(struct sdma_engine *sde,\n\t\t\t      struct vnic_txreq *tx,\n\t\t\t      u64 pbc)\n{\n\tint ret = 0;\n\tu16 hdrbytes = 2 << 2;   \n\n\tret = sdma_txinit_ahg(\n\t\t&tx->txreq,\n\t\t0,\n\t\thdrbytes + tx->skb->len + tx->plen,\n\t\t0,\n\t\t0,\n\t\tNULL,\n\t\t0,\n\t\tvnic_sdma_complete);\n\tif (unlikely(ret))\n\t\tgoto bail_txadd;\n\n\t \n\ttx->pbc_val = cpu_to_le64(pbc);\n\tret = sdma_txadd_kvaddr(\n\t\tsde->dd,\n\t\t&tx->txreq,\n\t\t&tx->pbc_val,\n\t\thdrbytes);\n\tif (unlikely(ret))\n\t\tgoto bail_txadd;\n\n\t \n\tret = build_vnic_ulp_payload(sde, tx);\nbail_txadd:\n\treturn ret;\n}\n\n \nstatic inline void hfi1_vnic_update_pad(unsigned char *pad, u8 plen)\n{\n\tpad[HFI1_VNIC_MAX_PAD - 1] = plen - OPA_VNIC_ICRC_TAIL_LEN;\n}\n\nint hfi1_vnic_send_dma(struct hfi1_devdata *dd, u8 q_idx,\n\t\t       struct hfi1_vnic_vport_info *vinfo,\n\t\t       struct sk_buff *skb, u64 pbc, u8 plen)\n{\n\tstruct hfi1_vnic_sdma *vnic_sdma = &vinfo->sdma[q_idx];\n\tstruct sdma_engine *sde = vnic_sdma->sde;\n\tstruct vnic_txreq *tx;\n\tint ret = -ECOMM;\n\n\tif (unlikely(READ_ONCE(vnic_sdma->state) != HFI1_VNIC_SDMA_Q_ACTIVE))\n\t\tgoto tx_err;\n\n\tif (unlikely(!sde || !sdma_running(sde)))\n\t\tgoto tx_err;\n\n\ttx = kmem_cache_alloc(dd->vnic.txreq_cache, GFP_ATOMIC);\n\tif (unlikely(!tx)) {\n\t\tret = -ENOMEM;\n\t\tgoto tx_err;\n\t}\n\n\ttx->sdma = vnic_sdma;\n\ttx->skb = skb;\n\thfi1_vnic_update_pad(tx->pad, plen);\n\ttx->plen = plen;\n\tret = build_vnic_tx_desc(sde, tx, pbc);\n\tif (unlikely(ret))\n\t\tgoto free_desc;\n\n\tret = sdma_send_txreq(sde, iowait_get_ib_work(&vnic_sdma->wait),\n\t\t\t      &tx->txreq, vnic_sdma->pkts_sent);\n\t \n\tif (unlikely(ret && unlikely(ret != -ECOMM)))\n\t\tgoto free_desc;\n\n\tif (!ret) {\n\t\tvnic_sdma->pkts_sent = true;\n\t\tiowait_starve_clear(vnic_sdma->pkts_sent, &vnic_sdma->wait);\n\t}\n\treturn ret;\n\nfree_desc:\n\tsdma_txclean(dd, &tx->txreq);\n\tkmem_cache_free(dd->vnic.txreq_cache, tx);\ntx_err:\n\tif (ret != -EBUSY)\n\t\tdev_kfree_skb_any(skb);\n\telse\n\t\tvnic_sdma->pkts_sent = false;\n\treturn ret;\n}\n\n \nstatic int hfi1_vnic_sdma_sleep(struct sdma_engine *sde,\n\t\t\t\tstruct iowait_work *wait,\n\t\t\t\tstruct sdma_txreq *txreq,\n\t\t\t\tuint seq,\n\t\t\t\tbool pkts_sent)\n{\n\tstruct hfi1_vnic_sdma *vnic_sdma =\n\t\tcontainer_of(wait->iow, struct hfi1_vnic_sdma, wait);\n\n\twrite_seqlock(&sde->waitlock);\n\tif (sdma_progress(sde, seq, txreq)) {\n\t\twrite_sequnlock(&sde->waitlock);\n\t\treturn -EAGAIN;\n\t}\n\n\tvnic_sdma->state = HFI1_VNIC_SDMA_Q_DEFERRED;\n\tif (list_empty(&vnic_sdma->wait.list)) {\n\t\tiowait_get_priority(wait->iow);\n\t\tiowait_queue(pkts_sent, wait->iow, &sde->dmawait);\n\t}\n\twrite_sequnlock(&sde->waitlock);\n\treturn -EBUSY;\n}\n\n \nstatic void hfi1_vnic_sdma_wakeup(struct iowait *wait, int reason)\n{\n\tstruct hfi1_vnic_sdma *vnic_sdma =\n\t\tcontainer_of(wait, struct hfi1_vnic_sdma, wait);\n\tstruct hfi1_vnic_vport_info *vinfo = vnic_sdma->vinfo;\n\n\tvnic_sdma->state = HFI1_VNIC_SDMA_Q_ACTIVE;\n\tif (__netif_subqueue_stopped(vinfo->netdev, vnic_sdma->q_idx))\n\t\tnetif_wake_subqueue(vinfo->netdev, vnic_sdma->q_idx);\n};\n\ninline bool hfi1_vnic_sdma_write_avail(struct hfi1_vnic_vport_info *vinfo,\n\t\t\t\t       u8 q_idx)\n{\n\tstruct hfi1_vnic_sdma *vnic_sdma = &vinfo->sdma[q_idx];\n\n\treturn (READ_ONCE(vnic_sdma->state) == HFI1_VNIC_SDMA_Q_ACTIVE);\n}\n\nvoid hfi1_vnic_sdma_init(struct hfi1_vnic_vport_info *vinfo)\n{\n\tint i;\n\n\tfor (i = 0; i < vinfo->num_tx_q; i++) {\n\t\tstruct hfi1_vnic_sdma *vnic_sdma = &vinfo->sdma[i];\n\n\t\tiowait_init(&vnic_sdma->wait, 0, NULL, NULL,\n\t\t\t    hfi1_vnic_sdma_sleep,\n\t\t\t    hfi1_vnic_sdma_wakeup, NULL, NULL);\n\t\tvnic_sdma->sde = &vinfo->dd->per_sdma[i];\n\t\tvnic_sdma->dd = vinfo->dd;\n\t\tvnic_sdma->vinfo = vinfo;\n\t\tvnic_sdma->q_idx = i;\n\t\tvnic_sdma->state = HFI1_VNIC_SDMA_Q_ACTIVE;\n\n\t\t \n\t\tif (vnic_sdma->sde->descq_cnt > HFI1_VNIC_SDMA_DESC_WTRMRK) {\n\t\t\tstruct iowait_work *work;\n\n\t\t\tINIT_LIST_HEAD(&vnic_sdma->stx.list);\n\t\t\tvnic_sdma->stx.num_desc = HFI1_VNIC_SDMA_DESC_WTRMRK;\n\t\t\twork = iowait_get_ib_work(&vnic_sdma->wait);\n\t\t\tlist_add_tail(&vnic_sdma->stx.list, &work->tx_head);\n\t\t}\n\t}\n}\n\nint hfi1_vnic_txreq_init(struct hfi1_devdata *dd)\n{\n\tchar buf[HFI1_VNIC_TXREQ_NAME_LEN];\n\n\tsnprintf(buf, sizeof(buf), \"hfi1_%u_vnic_txreq_cache\", dd->unit);\n\tdd->vnic.txreq_cache = kmem_cache_create(buf,\n\t\t\t\t\t\t sizeof(struct vnic_txreq),\n\t\t\t\t\t\t 0, SLAB_HWCACHE_ALIGN,\n\t\t\t\t\t\t NULL);\n\tif (!dd->vnic.txreq_cache)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nvoid hfi1_vnic_txreq_deinit(struct hfi1_devdata *dd)\n{\n\tkmem_cache_destroy(dd->vnic.txreq_cache);\n\tdd->vnic.txreq_cache = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}