{
  "module_name": "hfi.h",
  "hash_id": "25ea5f626eade18680be949fdf7cbbe656fc03b3158b0b0cbddc6aee94b6927e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/hfi1/hfi.h",
  "human_readable_source": " \n \n\n#ifndef _HFI1_KERNEL_H\n#define _HFI1_KERNEL_H\n\n#include <linux/refcount.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/dma-mapping.h>\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/io.h>\n#include <linux/fs.h>\n#include <linux/completion.h>\n#include <linux/kref.h>\n#include <linux/sched.h>\n#include <linux/cdev.h>\n#include <linux/delay.h>\n#include <linux/kthread.h>\n#include <linux/i2c.h>\n#include <linux/i2c-algo-bit.h>\n#include <linux/xarray.h>\n#include <rdma/ib_hdrs.h>\n#include <rdma/opa_addr.h>\n#include <linux/rhashtable.h>\n#include <rdma/rdma_vt.h>\n\n#include \"chip_registers.h\"\n#include \"common.h\"\n#include \"opfn.h\"\n#include \"verbs.h\"\n#include \"pio.h\"\n#include \"chip.h\"\n#include \"mad.h\"\n#include \"qsfp.h\"\n#include \"platform.h\"\n#include \"affinity.h\"\n#include \"msix.h\"\n\n \n#define HFI1_CHIP_VERS_MAJ 3U\n\n \n#define HFI1_CHIP_VERS_MIN 0U\n\n \n#define HFI1_OUI 0x001175\n#define HFI1_OUI_LSB 40\n\n#define DROP_PACKET_OFF\t\t0\n#define DROP_PACKET_ON\t\t1\n\n#define NEIGHBOR_TYPE_HFI\t\t0\n#define NEIGHBOR_TYPE_SWITCH\t1\n\n#define HFI1_MAX_ACTIVE_WORKQUEUE_ENTRIES 5\n\nextern unsigned long hfi1_cap_mask;\n#define HFI1_CAP_KGET_MASK(mask, cap) ((mask) & HFI1_CAP_##cap)\n#define HFI1_CAP_UGET_MASK(mask, cap) \\\n\t(((mask) >> HFI1_CAP_USER_SHIFT) & HFI1_CAP_##cap)\n#define HFI1_CAP_KGET(cap) (HFI1_CAP_KGET_MASK(hfi1_cap_mask, cap))\n#define HFI1_CAP_UGET(cap) (HFI1_CAP_UGET_MASK(hfi1_cap_mask, cap))\n#define HFI1_CAP_IS_KSET(cap) (!!HFI1_CAP_KGET(cap))\n#define HFI1_CAP_IS_USET(cap) (!!HFI1_CAP_UGET(cap))\n#define HFI1_MISC_GET() ((hfi1_cap_mask >> HFI1_CAP_MISC_SHIFT) & \\\n\t\t\tHFI1_CAP_MISC_MASK)\n \n#define HFI1_ODR_MASK(rsn) ((rsn) & OPA_PI_MASK_OFFLINE_REASON)\n\n \n#define HFI1_CTRL_CTXT    0\n\n \n#define NUM_CCE_ERR_STATUS_COUNTERS 41\n#define NUM_RCV_ERR_STATUS_COUNTERS 64\n#define NUM_MISC_ERR_STATUS_COUNTERS 13\n#define NUM_SEND_PIO_ERR_STATUS_COUNTERS 36\n#define NUM_SEND_DMA_ERR_STATUS_COUNTERS 4\n#define NUM_SEND_EGRESS_ERR_STATUS_COUNTERS 64\n#define NUM_SEND_ERR_STATUS_COUNTERS 3\n#define NUM_SEND_CTXT_ERR_STATUS_COUNTERS 5\n#define NUM_SEND_DMA_ENG_ERR_STATUS_COUNTERS 24\n\n \nstruct hfi1_ib_stats {\n\t__u64 sps_ints;  \n\t__u64 sps_errints;  \n\t__u64 sps_txerrs;  \n\t__u64 sps_rcverrs;  \n\t__u64 sps_hwerrs;  \n\t__u64 sps_nopiobufs;  \n\t__u64 sps_ctxts;  \n\t__u64 sps_lenerrs;  \n\t__u64 sps_buffull;\n\t__u64 sps_hdrfull;\n};\n\nextern struct hfi1_ib_stats hfi1_stats;\nextern const struct pci_error_handlers hfi1_pci_err_handler;\n\nextern int num_driver_cntrs;\n\n \n#define HFI1_TRAFFIC_ACTIVE_THRESHOLD (2000)\n\n \n\nstruct hfi1_opcode_stats_perctx;\n\nstruct ctxt_eager_bufs {\n\tstruct eager_buffer {\n\t\tvoid *addr;\n\t\tdma_addr_t dma;\n\t\tssize_t len;\n\t} *buffers;\n\tstruct {\n\t\tvoid *addr;\n\t\tdma_addr_t dma;\n\t} *rcvtids;\n\tu32 size;                 \n\tu32 rcvtid_size;          \n\tu16 count;                \n\tu16 numbufs;              \n\tu16 alloced;              \n\tu16 threshold;            \n};\n\nstruct exp_tid_set {\n\tstruct list_head list;\n\tu32 count;\n};\n\nstruct hfi1_ctxtdata;\ntypedef int (*intr_handler)(struct hfi1_ctxtdata *rcd, int data);\ntypedef void (*rhf_rcv_function_ptr)(struct hfi1_packet *packet);\n\nstruct tid_queue {\n\tstruct list_head queue_head;\n\t\t\t \n\tu32 enqueue;\t \n\tu32 dequeue;\t \n};\n\nstruct hfi1_ctxtdata {\n\t \n\tvoid *rcvhdrq;\n\t \n\tvolatile __le64 *rcvhdrtail_kvaddr;\n\t \n\tstruct hfi1_pportdata *ppd;\n\t \n\tstruct hfi1_devdata *dd;\n\t \n\tstruct send_context *sc;\n\t \n\tconst rhf_rcv_function_ptr *rhf_rcv_function_map;\n\t \n\tintr_handler do_interrupt;\n\t \n\tintr_handler fast_handler;\n\t \n\tintr_handler slow_handler;\n\t \n\tstruct napi_struct *napi;\n\t \n\tstruct hfi1_opcode_stats_perctx *opstats;\n\t \n\tu64 imask;\n\t \n\tu32 head;\n\t \n\tu16 rcvhdrq_cnt;\n\tu8 ireg;\t \n\t \n\tu8 seq_cnt;\n\t \n\tu8 rcvhdrqentsize;\n\t \n\tu8 rhf_offset;\n\t \n\tu8 rcvavail_timeout;\n\t \n\tbool is_vnic;\n\t \n\tu8 vnic_q_idx;\n\t \n\tbool aspm_intr_supported;\n\t \n\tbool aspm_enabled;\n\t \n\tbool aspm_intr_enable;\n\tstruct ctxt_eager_bufs egrbufs;\n\t \n\tstruct list_head qp_wait_list;\n\t \n\tstruct exp_tid_set tid_group_list;\n\tstruct exp_tid_set tid_used_list;\n\tstruct exp_tid_set tid_full_list;\n\n\t \n\tstruct timer_list aspm_timer;\n\t \n\tunsigned long flags;\n\t \n\tstruct tid_group  *groups;\n\t \n\tdma_addr_t rcvhdrq_dma;\n\tdma_addr_t rcvhdrqtailaddr_dma;\n\t \n\tktime_t aspm_ts_last_intr;\n\t \n\tktime_t aspm_ts_timer_sched;\n\t \n\tspinlock_t aspm_lock;\n\t \n\tstruct kref kref;\n\t \n\tint numa_id;\n\t \n\ts16 msix_intr;\n\t \n\tu16 jkey;\n\t \n\tu16 rcv_array_groups;\n\t \n\tu16 eager_base;\n\t \n\tu16 expected_count;\n\t \n\tu16 expected_base;\n\t \n\tu8 ctxt;\n\n\t \n\t \n\tstruct mutex exp_mutex;\n\t \n\tspinlock_t exp_lock;\n\t \n\tstruct tid_queue flow_queue;\n\t \n\tstruct tid_queue rarr_queue;\n\t \n\twait_queue_head_t wait;\n\t \n\tu8 uuid[16];\n\t \n\tchar comm[TASK_COMM_LEN];\n\t \n\tDECLARE_BITMAP(in_use_ctxts, HFI1_MAX_SHARED_CTXTS);\n\t \n\tunsigned long event_flags;\n\t \n\tvoid *subctxt_uregbase;\n\t \n\tvoid *subctxt_rcvegrbuf;\n\t \n\tvoid *subctxt_rcvhdr_base;\n\t \n\tu32 urgent;\n\t \n\tu32 urgent_poll;\n\t \n\tu16 poll_type;\n\t \n\tu16 subctxt_id;\n\t \n\tu32 userversion;\n\t \n\tu8 subctxt_cnt;\n\n\t \n\tunsigned long flow_mask;\n\tstruct tid_flow_state flows[RXE_NUM_TID_FLOWS];\n};\n\n \nstatic inline u32 rcvhdrq_size(struct hfi1_ctxtdata *rcd)\n{\n\treturn PAGE_ALIGN(rcd->rcvhdrq_cnt *\n\t\t\t  rcd->rcvhdrqentsize * sizeof(u32));\n}\n\n \nstruct hfi1_packet {\n\tvoid *ebuf;\n\tvoid *hdr;\n\tvoid *payload;\n\tstruct hfi1_ctxtdata *rcd;\n\t__le32 *rhf_addr;\n\tstruct rvt_qp *qp;\n\tstruct ib_other_headers *ohdr;\n\tstruct ib_grh *grh;\n\tstruct opa_16b_mgmt *mgmt;\n\tu64 rhf;\n\tu32 maxcnt;\n\tu32 rhqoff;\n\tu32 dlid;\n\tu32 slid;\n\tint numpkt;\n\tu16 tlen;\n\ts16 etail;\n\tu16 pkey;\n\tu8 hlen;\n\tu8 rsize;\n\tu8 updegr;\n\tu8 etype;\n\tu8 extra_byte;\n\tu8 pad;\n\tu8 sc;\n\tu8 sl;\n\tu8 opcode;\n\tbool migrated;\n};\n\n \n#define HFI1_PKT_TYPE_9B  0\n#define HFI1_PKT_TYPE_16B 1\n\n \n#define OPA_16B_L4_MASK\t\t0xFFull\n#define OPA_16B_SC_MASK\t\t0x1F00000ull\n#define OPA_16B_SC_SHIFT\t20\n#define OPA_16B_LID_MASK\t0xFFFFFull\n#define OPA_16B_DLID_MASK\t0xF000ull\n#define OPA_16B_DLID_SHIFT\t20\n#define OPA_16B_DLID_HIGH_SHIFT\t12\n#define OPA_16B_SLID_MASK\t0xF00ull\n#define OPA_16B_SLID_SHIFT\t20\n#define OPA_16B_SLID_HIGH_SHIFT\t8\n#define OPA_16B_BECN_MASK       0x80000000ull\n#define OPA_16B_BECN_SHIFT      31\n#define OPA_16B_FECN_MASK       0x10000000ull\n#define OPA_16B_FECN_SHIFT      28\n#define OPA_16B_L2_MASK\t\t0x60000000ull\n#define OPA_16B_L2_SHIFT\t29\n#define OPA_16B_PKEY_MASK\t0xFFFF0000ull\n#define OPA_16B_PKEY_SHIFT\t16\n#define OPA_16B_LEN_MASK\t0x7FF00000ull\n#define OPA_16B_LEN_SHIFT\t20\n#define OPA_16B_RC_MASK\t\t0xE000000ull\n#define OPA_16B_RC_SHIFT\t25\n#define OPA_16B_AGE_MASK\t0xFF0000ull\n#define OPA_16B_AGE_SHIFT\t16\n#define OPA_16B_ENTROPY_MASK\t0xFFFFull\n\n \n#define OPA_16B_L4_9B\t\t0x00\n#define OPA_16B_L2_TYPE\t\t0x02\n#define OPA_16B_L4_FM\t\t0x08\n#define OPA_16B_L4_IB_LOCAL\t0x09\n#define OPA_16B_L4_IB_GLOBAL\t0x0A\n#define OPA_16B_L4_ETHR\t\tOPA_VNIC_L4_ETHR\n\n \n#define OPA_16B_L4_FM_PAD\t3   \n#define OPA_16B_L4_FM_HLEN\t24  \n\nstatic inline u8 hfi1_16B_get_l4(struct hfi1_16b_header *hdr)\n{\n\treturn (u8)(hdr->lrh[2] & OPA_16B_L4_MASK);\n}\n\nstatic inline u8 hfi1_16B_get_sc(struct hfi1_16b_header *hdr)\n{\n\treturn (u8)((hdr->lrh[1] & OPA_16B_SC_MASK) >> OPA_16B_SC_SHIFT);\n}\n\nstatic inline u32 hfi1_16B_get_dlid(struct hfi1_16b_header *hdr)\n{\n\treturn (u32)((hdr->lrh[1] & OPA_16B_LID_MASK) |\n\t\t     (((hdr->lrh[2] & OPA_16B_DLID_MASK) >>\n\t\t     OPA_16B_DLID_HIGH_SHIFT) << OPA_16B_DLID_SHIFT));\n}\n\nstatic inline u32 hfi1_16B_get_slid(struct hfi1_16b_header *hdr)\n{\n\treturn (u32)((hdr->lrh[0] & OPA_16B_LID_MASK) |\n\t\t     (((hdr->lrh[2] & OPA_16B_SLID_MASK) >>\n\t\t     OPA_16B_SLID_HIGH_SHIFT) << OPA_16B_SLID_SHIFT));\n}\n\nstatic inline u8 hfi1_16B_get_becn(struct hfi1_16b_header *hdr)\n{\n\treturn (u8)((hdr->lrh[0] & OPA_16B_BECN_MASK) >> OPA_16B_BECN_SHIFT);\n}\n\nstatic inline u8 hfi1_16B_get_fecn(struct hfi1_16b_header *hdr)\n{\n\treturn (u8)((hdr->lrh[1] & OPA_16B_FECN_MASK) >> OPA_16B_FECN_SHIFT);\n}\n\nstatic inline u8 hfi1_16B_get_l2(struct hfi1_16b_header *hdr)\n{\n\treturn (u8)((hdr->lrh[1] & OPA_16B_L2_MASK) >> OPA_16B_L2_SHIFT);\n}\n\nstatic inline u16 hfi1_16B_get_pkey(struct hfi1_16b_header *hdr)\n{\n\treturn (u16)((hdr->lrh[2] & OPA_16B_PKEY_MASK) >> OPA_16B_PKEY_SHIFT);\n}\n\nstatic inline u8 hfi1_16B_get_rc(struct hfi1_16b_header *hdr)\n{\n\treturn (u8)((hdr->lrh[1] & OPA_16B_RC_MASK) >> OPA_16B_RC_SHIFT);\n}\n\nstatic inline u8 hfi1_16B_get_age(struct hfi1_16b_header *hdr)\n{\n\treturn (u8)((hdr->lrh[3] & OPA_16B_AGE_MASK) >> OPA_16B_AGE_SHIFT);\n}\n\nstatic inline u16 hfi1_16B_get_len(struct hfi1_16b_header *hdr)\n{\n\treturn (u16)((hdr->lrh[0] & OPA_16B_LEN_MASK) >> OPA_16B_LEN_SHIFT);\n}\n\nstatic inline u16 hfi1_16B_get_entropy(struct hfi1_16b_header *hdr)\n{\n\treturn (u16)(hdr->lrh[3] & OPA_16B_ENTROPY_MASK);\n}\n\n#define OPA_16B_MAKE_QW(low_dw, high_dw) (((u64)(high_dw) << 32) | (low_dw))\n\n \n#define OPA_16B_BTH_PAD_MASK\t7\nstatic inline u8 hfi1_16B_bth_get_pad(struct ib_other_headers *ohdr)\n{\n\treturn (u8)((be32_to_cpu(ohdr->bth[0]) >> IB_BTH_PAD_SHIFT) &\n\t\t   OPA_16B_BTH_PAD_MASK);\n}\n\n \n#define OPA_16B_MGMT_QPN_MASK\t0xFFFFFF\nstatic inline u32 hfi1_16B_get_dest_qpn(struct opa_16b_mgmt *mgmt)\n{\n\treturn be32_to_cpu(mgmt->dest_qpn) & OPA_16B_MGMT_QPN_MASK;\n}\n\nstatic inline u32 hfi1_16B_get_src_qpn(struct opa_16b_mgmt *mgmt)\n{\n\treturn be32_to_cpu(mgmt->src_qpn) & OPA_16B_MGMT_QPN_MASK;\n}\n\nstatic inline void hfi1_16B_set_qpn(struct opa_16b_mgmt *mgmt,\n\t\t\t\t    u32 dest_qp, u32 src_qp)\n{\n\tmgmt->dest_qpn = cpu_to_be32(dest_qp & OPA_16B_MGMT_QPN_MASK);\n\tmgmt->src_qpn = cpu_to_be32(src_qp & OPA_16B_MGMT_QPN_MASK);\n}\n\n \nstatic inline struct ib_other_headers *\nhfi1_get_rc_ohdr(struct hfi1_opa_header *opah)\n{\n\tstruct ib_other_headers *ohdr;\n\tstruct ib_header *hdr = NULL;\n\tstruct hfi1_16b_header *hdr_16b = NULL;\n\n\t \n\tif (opah->hdr_type == HFI1_PKT_TYPE_9B) {\n\t\thdr = &opah->ibh;\n\t\tif (ib_get_lnh(hdr) == HFI1_LRH_BTH)\n\t\t\tohdr = &hdr->u.oth;\n\t\telse\n\t\t\tohdr = &hdr->u.l.oth;\n\t} else {\n\t\tu8 l4;\n\n\t\thdr_16b = &opah->opah;\n\t\tl4  = hfi1_16B_get_l4(hdr_16b);\n\t\tif (l4 == OPA_16B_L4_IB_LOCAL)\n\t\t\tohdr = &hdr_16b->u.oth;\n\t\telse\n\t\t\tohdr = &hdr_16b->u.l.oth;\n\t}\n\treturn ohdr;\n}\n\nstruct rvt_sge_state;\n\n \n#define HFI1_IB_CFG_LIDLMC 0  \n#define HFI1_IB_CFG_LWID_DG_ENB 1  \n#define HFI1_IB_CFG_LWID_ENB 2  \n#define HFI1_IB_CFG_LWID 3  \n#define HFI1_IB_CFG_SPD_ENB 4  \n#define HFI1_IB_CFG_SPD 5  \n#define HFI1_IB_CFG_RXPOL_ENB 6  \n#define HFI1_IB_CFG_LREV_ENB 7  \n#define HFI1_IB_CFG_LINKLATENCY 8  \n#define HFI1_IB_CFG_HRTBT 9  \n#define HFI1_IB_CFG_OP_VLS 10  \n#define HFI1_IB_CFG_VL_HIGH_CAP 11  \n#define HFI1_IB_CFG_VL_LOW_CAP 12  \n#define HFI1_IB_CFG_OVERRUN_THRESH 13  \n#define HFI1_IB_CFG_PHYERR_THRESH 14  \n#define HFI1_IB_CFG_LINKDEFAULT 15  \n#define HFI1_IB_CFG_PKEYS 16  \n#define HFI1_IB_CFG_MTU 17  \n#define HFI1_IB_CFG_VL_HIGH_LIMIT 19\n#define HFI1_IB_CFG_PMA_TICKS 20  \n#define HFI1_IB_CFG_PORT 21  \n\n \n#define __HLS_UP_INIT_BP\t0\n#define __HLS_UP_ARMED_BP\t1\n#define __HLS_UP_ACTIVE_BP\t2\n#define __HLS_DN_DOWNDEF_BP\t3\t \n#define __HLS_DN_POLL_BP\t4\n#define __HLS_DN_DISABLE_BP\t5\n#define __HLS_DN_OFFLINE_BP\t6\n#define __HLS_VERIFY_CAP_BP\t7\n#define __HLS_GOING_UP_BP\t8\n#define __HLS_GOING_OFFLINE_BP  9\n#define __HLS_LINK_COOLDOWN_BP 10\n\n#define HLS_UP_INIT\t  BIT(__HLS_UP_INIT_BP)\n#define HLS_UP_ARMED\t  BIT(__HLS_UP_ARMED_BP)\n#define HLS_UP_ACTIVE\t  BIT(__HLS_UP_ACTIVE_BP)\n#define HLS_DN_DOWNDEF\t  BIT(__HLS_DN_DOWNDEF_BP)  \n#define HLS_DN_POLL\t  BIT(__HLS_DN_POLL_BP)\n#define HLS_DN_DISABLE\t  BIT(__HLS_DN_DISABLE_BP)\n#define HLS_DN_OFFLINE\t  BIT(__HLS_DN_OFFLINE_BP)\n#define HLS_VERIFY_CAP\t  BIT(__HLS_VERIFY_CAP_BP)\n#define HLS_GOING_UP\t  BIT(__HLS_GOING_UP_BP)\n#define HLS_GOING_OFFLINE BIT(__HLS_GOING_OFFLINE_BP)\n#define HLS_LINK_COOLDOWN BIT(__HLS_LINK_COOLDOWN_BP)\n\n#define HLS_UP (HLS_UP_INIT | HLS_UP_ARMED | HLS_UP_ACTIVE)\n#define HLS_DOWN ~(HLS_UP)\n\n#define HLS_DEFAULT HLS_DN_POLL\n\n \n#define HFI1_DEFAULT_ACTIVE_MTU 10240\n \n#define HFI1_DEFAULT_MAX_MTU 10240\n \n#define DEFAULT_PKEY 0xffff\n\n \n#define FM_TBL_VL_HIGH_ARB\t\t1  \n#define FM_TBL_VL_LOW_ARB\t\t2  \n#define FM_TBL_BUFFER_CONTROL\t\t3  \n#define FM_TBL_SC2VLNT\t\t\t4  \n#define FM_TBL_VL_PREEMPT_ELEMS\t\t5  \n#define FM_TBL_VL_PREEMPT_MATRIX\t6  \n\n \n#define HFI1_RCVCTRL_TAILUPD_ENB 0x01\n#define HFI1_RCVCTRL_TAILUPD_DIS 0x02\n#define HFI1_RCVCTRL_CTXT_ENB 0x04\n#define HFI1_RCVCTRL_CTXT_DIS 0x08\n#define HFI1_RCVCTRL_INTRAVAIL_ENB 0x10\n#define HFI1_RCVCTRL_INTRAVAIL_DIS 0x20\n#define HFI1_RCVCTRL_PKEY_ENB 0x40   \n#define HFI1_RCVCTRL_PKEY_DIS 0x80\n#define HFI1_RCVCTRL_TIDFLOW_ENB 0x0400\n#define HFI1_RCVCTRL_TIDFLOW_DIS 0x0800\n#define HFI1_RCVCTRL_ONE_PKT_EGR_ENB 0x1000\n#define HFI1_RCVCTRL_ONE_PKT_EGR_DIS 0x2000\n#define HFI1_RCVCTRL_NO_RHQ_DROP_ENB 0x4000\n#define HFI1_RCVCTRL_NO_RHQ_DROP_DIS 0x8000\n#define HFI1_RCVCTRL_NO_EGR_DROP_ENB 0x10000\n#define HFI1_RCVCTRL_NO_EGR_DROP_DIS 0x20000\n#define HFI1_RCVCTRL_URGENT_ENB 0x40000\n#define HFI1_RCVCTRL_URGENT_DIS 0x80000\n\n \n#define HFI1_PART_ENFORCE_IN\t0x1\n#define HFI1_PART_ENFORCE_OUT\t0x2\n\n \n#define SYNTH_CNT_TIME 3\n\n \n#define CNTR_NORMAL\t\t0x0  \n#define CNTR_SYNTH\t\t0x1  \n#define CNTR_DISABLED\t\t0x2  \n#define CNTR_32BIT\t\t0x4  \n#define CNTR_VL\t\t\t0x8  \n#define CNTR_SDMA              0x10\n#define CNTR_INVALID_VL\t\t-1   \n#define CNTR_MODE_W\t\t0x0\n#define CNTR_MODE_R\t\t0x1\n\n \n#define HFI1_MIN_VLS_SUPPORTED 1\n#define HFI1_MAX_VLS_SUPPORTED 8\n\n#define HFI1_GUIDS_PER_PORT  5\n#define HFI1_PORT_GUID_INDEX 0\n\nstatic inline void incr_cntr64(u64 *cntr)\n{\n\tif (*cntr < (u64)-1LL)\n\t\t(*cntr)++;\n}\n\n#define MAX_NAME_SIZE 64\nstruct hfi1_msix_entry {\n\tenum irq_type type;\n\tint irq;\n\tvoid *arg;\n\tcpumask_t mask;\n\tstruct irq_affinity_notify notify;\n};\n\nstruct hfi1_msix_info {\n\t \n\tspinlock_t msix_lock;\n\tDECLARE_BITMAP(in_use_msix, CCE_NUM_MSIX_VECTORS);\n\tstruct hfi1_msix_entry *msix_entries;\n\tu16 max_requested;\n};\n\n \nstruct cca_timer {\n\tstruct hrtimer hrtimer;\n\tstruct hfi1_pportdata *ppd;  \n\tint sl;  \n\tu16 ccti;  \n};\n\nstruct link_down_reason {\n\t \n\tu8 sma;\n\tu8 latest;\n};\n\nenum {\n\tLO_PRIO_TABLE,\n\tHI_PRIO_TABLE,\n\tMAX_PRIO_TABLE\n};\n\nstruct vl_arb_cache {\n\t \n\tspinlock_t lock;\n\tstruct ib_vl_weight_elem table[VL_ARB_TABLE_SIZE];\n};\n\n \nstruct hfi1_pportdata {\n\tstruct hfi1_ibport ibport_data;\n\n\tstruct hfi1_devdata *dd;\n\n\t \n\tstruct qsfp_data qsfp_info;\n\t \n\tu32 port_type;\n\tu32 tx_preset_eq;\n\tu32 tx_preset_noeq;\n\tu32 rx_preset;\n\tu8  local_atten;\n\tu8  remote_atten;\n\tu8  default_atten;\n\tu8  max_power_class;\n\n\t \n\tbool config_from_scratch;\n\n\t \n\tu64 guids[HFI1_GUIDS_PER_PORT];\n\n\t \n\tu64 neighbor_guid;\n\n\t \n\tu32 linkup;\n\n\t \n\tu64 *statusp;\n\n\t \n\n\tstruct workqueue_struct *hfi1_wq;\n\tstruct workqueue_struct *link_wq;\n\n\t \n\tstruct work_struct link_vc_work;\n\tstruct work_struct link_up_work;\n\tstruct work_struct link_down_work;\n\tstruct work_struct sma_message_work;\n\tstruct work_struct freeze_work;\n\tstruct work_struct link_downgrade_work;\n\tstruct work_struct link_bounce_work;\n\tstruct delayed_work start_link_work;\n\t \n\tstruct mutex hls_lock;\n\tu32 host_link_state;\n\n\t \n\n\tu32 ibmtu;  \n\t \n\tu32 ibmaxlen;\n\tu32 current_egress_rate;  \n\t \n\tu32 lid;\n\t \n\tu16 pkeys[MAX_PKEY_VALUES];\n\tu16 link_width_supported;\n\tu16 link_width_downgrade_supported;\n\tu16 link_speed_supported;\n\tu16 link_width_enabled;\n\tu16 link_width_downgrade_enabled;\n\tu16 link_speed_enabled;\n\tu16 link_width_active;\n\tu16 link_width_downgrade_tx_active;\n\tu16 link_width_downgrade_rx_active;\n\tu16 link_speed_active;\n\tu8 vls_supported;\n\tu8 vls_operational;\n\tu8 actual_vls_operational;\n\t \n\tu8 lmc;\n\t \n\tu8 rx_pol_inv;\n\n\tu8 hw_pidx;      \n\tu32 port;         \n\t \n\tu8 neighbor_type;\n\tu8 neighbor_normal;\n\tu8 neighbor_fm_security;  \n\tu8 neighbor_port_number;\n\tu8 is_sm_config_started;\n\tu8 offline_disabled_reason;\n\tu8 is_active_optimize_enabled;\n\tu8 driver_link_ready;\t \n\tu8 link_enabled;\t \n\tu8 linkinit_reason;\n\tu8 local_tx_rate;\t \n\tu8 qsfp_retry_count;\n\n\t \n\tu8 overrun_threshold;\n\tu8 phy_error_threshold;\n\tunsigned int is_link_down_queued;\n\n\t \n\t \n\tunsigned long led_override_vals[2];\n\tu8 led_override_phase;  \n\tatomic_t led_override_timer_active;\n\t \n\tstruct timer_list led_override_timer;\n\n\tu32 sm_trap_qp;\n\tu32 sa_qp;\n\n\t \n\tspinlock_t cca_timer_lock ____cacheline_aligned_in_smp;\n\tstruct cca_timer cca_timer[OPA_MAX_SLS];\n\n\t \n\tstruct ib_cc_table_entry_shadow ccti_entries[CC_TABLE_SHADOW_MAX];\n\n\t \n\tstruct opa_congestion_setting_entry_shadow\n\t\tcongestion_entries[OPA_MAX_SLS];\n\n\t \n\tspinlock_t cc_state_lock ____cacheline_aligned_in_smp;\n\n\tstruct cc_state __rcu *cc_state;\n\n\t \n\tu16 total_cct_entry;\n\n\t \n\tu32 cc_sl_control_map;\n\n\t \n\tu8 cc_max_table_entries;\n\n\t \n\tspinlock_t cc_log_lock ____cacheline_aligned_in_smp;\n\tu8 threshold_cong_event_map[OPA_MAX_SLS / 8];\n\tu16 threshold_event_counter;\n\tstruct opa_hfi1_cong_log_event_internal cc_events[OPA_CONG_LOG_ELEMS];\n\tint cc_log_idx;  \n\tint cc_mad_idx;  \n\t \n\n\tstruct vl_arb_cache vl_arb_cache[MAX_PRIO_TABLE];\n\n\t \n\tu64 *cntrs;\n\t \n\tu64 *scntrs;\n\t \n\tu64 port_xmit_discards;\n\tu64 port_xmit_discards_vl[C_VL_COUNT];\n\tu64 port_xmit_constraint_errors;\n\tu64 port_rcv_constraint_errors;\n\t \n\tu64 link_downed;\n\t \n\tu64 link_up;\n\t \n\tu64 unknown_frame_count;\n\t \n\tu16 port_ltp_crc_mode;\n\t \n\tu8 port_crc_mode_enabled;\n\t \n\tu8 mgmt_allowed;\n\tu8 part_enforce;  \n\tstruct link_down_reason local_link_down_reason;\n\tstruct link_down_reason neigh_link_down_reason;\n\t \n\tu8 remote_link_down_reason;\n\t \n\tu32 port_error_action;\n\tstruct work_struct linkstate_active_work;\n\t \n\tbool cc_prescan;\n\t \n\tu64 port_vl_xmit_wait_last[C_VL_COUNT + 1];\n\tu16 prev_link_width;\n\tu64 vl_xmit_flit_cnt[C_VL_COUNT + 1];\n};\n\ntypedef void (*opcode_handler)(struct hfi1_packet *packet);\ntypedef void (*hfi1_make_req)(struct rvt_qp *qp,\n\t\t\t      struct hfi1_pkt_state *ps,\n\t\t\t      struct rvt_swqe *wqe);\nextern const rhf_rcv_function_ptr normal_rhf_rcv_functions[];\nextern const rhf_rcv_function_ptr netdev_rhf_rcv_functions[];\n\n \n#define RHF_RCV_CONTINUE  0\t \n#define RHF_RCV_DONE\t  1\t \n#define RHF_RCV_REPROCESS 2\t \n\nstruct rcv_array_data {\n\tu16 ngroups;\n\tu16 nctxt_extra;\n\tu8 group_size;\n};\n\nstruct per_vl_data {\n\tu16 mtu;\n\tstruct send_context *sc;\n};\n\n \n#define PER_VL_SEND_CONTEXTS 16\n\nstruct err_info_rcvport {\n\tu8 status_and_code;\n\tu64 packet_flit1;\n\tu64 packet_flit2;\n};\n\nstruct err_info_constraint {\n\tu8 status;\n\tu16 pkey;\n\tu32 slid;\n};\n\nstruct hfi1_temp {\n\tunsigned int curr;        \n\tunsigned int lo_lim;      \n\tunsigned int hi_lim;      \n\tunsigned int crit_lim;    \n\tu8 triggers;       \n};\n\nstruct hfi1_i2c_bus {\n\tstruct hfi1_devdata *controlling_dd;  \n\tstruct i2c_adapter adapter;\t \n\tstruct i2c_algo_bit_data algo;\t \n\tint num;\t\t\t \n};\n\n \nstruct hfi1_asic_data {\n\tstruct hfi1_devdata *dds[2];\t \n\tstruct mutex asic_resource_mutex;\n\tstruct hfi1_i2c_bus *i2c_bus0;\n\tstruct hfi1_i2c_bus *i2c_bus1;\n};\n\n \n#define NUM_MAP_ENTRIES\t 256\n#define NUM_MAP_REGS      32\n\n \nstruct hfi1_vnic_data {\n\tstruct kmem_cache *txreq_cache;\n\tu8 num_vports;\n};\n\nstruct hfi1_vnic_vport_info;\n\n \nstruct sdma_engine;\nstruct sdma_vl_map;\n\n#define BOARD_VERS_MAX 96  \n#define SERIAL_MAX 16  \n\ntypedef int (*send_routine)(struct rvt_qp *, struct hfi1_pkt_state *, u64);\nstruct hfi1_netdev_rx;\nstruct hfi1_devdata {\n\tstruct hfi1_ibdev verbs_dev;      \n\t \n\t \n\tstruct pci_dev *pcidev;\n\tstruct cdev user_cdev;\n\tstruct cdev diag_cdev;\n\tstruct cdev ui_cdev;\n\tstruct device *user_device;\n\tstruct device *diag_device;\n\tstruct device *ui_device;\n\n\t \n\tu8 __iomem *kregbase1;\n\tresource_size_t physaddr;\n\n\t \n\tu8 __iomem *kregbase2;\n\t \n\tu32 base2_start;\n\n\t \n\tstruct per_vl_data vld[PER_VL_SEND_CONTEXTS];\n\t \n\tstruct send_context_info *send_contexts;\n\t \n\tu8 *hw_to_sw;\n\t \n\tspinlock_t sc_lock;\n\t \n\tspinlock_t pio_map_lock;\n\t \n\tspinlock_t sc_init_lock;\n\t \n\tspinlock_t                          sde_map_lock;\n\t \n\tstruct send_context **kernel_send_context;\n\t \n\tstruct pio_vl_map __rcu *pio_map;\n\t \n\tu64 default_desc1;\n\n\t \n\n\tvolatile __le64                    *sdma_heads_dma;  \n\tdma_addr_t                          sdma_heads_phys;\n\tvoid                               *sdma_pad_dma;  \n\tdma_addr_t                          sdma_pad_phys;\n\t \n\tsize_t                              sdma_heads_size;\n\t \n\tu32                                 num_sdma;\n\t \n\tstruct sdma_engine                 *per_sdma;\n\t \n\tstruct sdma_vl_map __rcu           *sdma_map;\n\t \n\twait_queue_head_t\t\t  sdma_unfreeze_wq;\n\tatomic_t\t\t\t  sdma_unfreeze_count;\n\n\tu32 lcb_access_count;\t\t \n\n\t \n\tstruct hfi1_asic_data *asic_data;\n\n\t \n\tvoid __iomem *piobase;\n\t \n\tvoid __iomem *rcvarray_wc;\n\t \n\tstruct credit_return_base *cr_base;\n\n\t \n\tstruct sc_config_sizes sc_sizes[SC_MAX];\n\n\tchar *boardname;  \n\n\tu64 ctx0_seq_drop;\n\n\t \n\tu64 z_int_counter;\n\tu64 z_rcv_limit;\n\tu64 z_send_schedule;\n\n\tu64 __percpu *send_schedule;\n\t \n\tu16 num_netdev_contexts;\n\t \n\tu32 num_rcv_contexts;\n\t \n\tu32 num_send_contexts;\n\t \n\tu32 freectxts;\n\t \n\tu32 num_user_contexts;\n\t \n\tu32 rcv_intr_timeout_csr;\n\n\tspinlock_t sendctrl_lock;  \n\tspinlock_t rcvctrl_lock;  \n\tspinlock_t uctxt_lock;  \n\tstruct mutex dc8051_lock;  \n\tstruct workqueue_struct *update_cntr_wq;\n\tstruct work_struct update_cntr_work;\n\t \n\tspinlock_t dc8051_memlock;\n\tint dc8051_timed_out;\t \n\t \n\tunsigned long *events;\n\t \n\tstruct hfi1_status *status;\n\n\t \n\tu64 revision;\n\t \n\tu64 base_guid;\n\n\t \n\tu8 link_gen3_capable;\n\tu8 dc_shutdown;\n\t \n\tu32 lbus_width;\n\t \n\tu32 lbus_speed;\n\tint unit;  \n\tint node;  \n\n\t \n\tu32 pcibar0;\n\tu32 pcibar1;\n\tu32 pci_rom;\n\tu16 pci_command;\n\tu16 pcie_devctl;\n\tu16 pcie_lnkctl;\n\tu16 pcie_devctl2;\n\tu32 pci_msix0;\n\tu32 pci_tph2;\n\n\t \n\tu8 serial[SERIAL_MAX];\n\t \n\tu8 boardversion[BOARD_VERS_MAX];\n\tu8 lbus_info[32];  \n\t \n\tu8 majrev;\n\t \n\tu8 minrev;\n\t \n\tu8 hfi1_id;\n\t \n\tu8 icode;\n\t \n\tu8 vau;\n\t \n\tu8 vcu;\n\t \n\tu16 link_credits;\n\t \n\tu16 vl15_init;\n\n\t \n\tu16 vl15buf_cached;\n\n\t \n\tu8 n_krcv_queues;\n\tu8 qos_shift;\n\n\tu16 irev;\t \n\tu32 dc8051_ver;  \n\n\tspinlock_t hfi1_diag_trans_lock;  \n\tstruct platform_config platform_config;\n\tstruct platform_config_cache pcfg_cache;\n\n\tstruct diag_client *diag_client;\n\n\t \n\tu64 gi_mask[CCE_NUM_INT_CSRS];\n\n\tstruct rcv_array_data rcv_entries;\n\n\t \n\tu16 psxmitwait_check_rate;\n\n\t \n\tstruct timer_list synth_stats_timer;\n\n\t \n\tstruct hfi1_msix_info msix_info;\n\n\t \n\tchar *cntrnames;\n\tsize_t cntrnameslen;\n\tsize_t ndevcntrs;\n\tu64 *cntrs;\n\tu64 *scntrs;\n\n\t \n\tu64 last_tx;\n\tu64 last_rx;\n\n\t \n\tsize_t nportcntrs;\n\tchar *portcntrnames;\n\tsize_t portcntrnameslen;\n\n\tstruct err_info_rcvport err_info_rcvport;\n\tstruct err_info_constraint err_info_rcv_constraint;\n\tstruct err_info_constraint err_info_xmit_constraint;\n\n\tatomic_t drop_packet;\n\tbool do_drop;\n\tu8 err_info_uncorrectable;\n\tu8 err_info_fmconfig;\n\n\t \n\tu64 cce_err_status_cnt[NUM_CCE_ERR_STATUS_COUNTERS];\n\tu64 rcv_err_status_cnt[NUM_RCV_ERR_STATUS_COUNTERS];\n\tu64 misc_err_status_cnt[NUM_MISC_ERR_STATUS_COUNTERS];\n\tu64 send_pio_err_status_cnt[NUM_SEND_PIO_ERR_STATUS_COUNTERS];\n\tu64 send_dma_err_status_cnt[NUM_SEND_DMA_ERR_STATUS_COUNTERS];\n\tu64 send_egress_err_status_cnt[NUM_SEND_EGRESS_ERR_STATUS_COUNTERS];\n\tu64 send_err_status_cnt[NUM_SEND_ERR_STATUS_COUNTERS];\n\n\t \n\tu64 sw_ctxt_err_status_cnt[NUM_SEND_CTXT_ERR_STATUS_COUNTERS];\n\t \n\tu64 sw_send_dma_eng_err_status_cnt[\n\t\tNUM_SEND_DMA_ENG_ERR_STATUS_COUNTERS];\n\t \n\tu64 sw_cce_err_status_aggregate;\n\t \n\tu64 sw_rcv_bypass_packet_errors;\n\n\t \n\tu64 lcb_err_en;\n\tstruct cpu_mask_set *comp_vect;\n\tint *comp_vect_mappings;\n\tu32 comp_vect_possible_cpus;\n\n\t \n\tsend_routine process_pio_send ____cacheline_aligned_in_smp;\n\tsend_routine process_dma_send;\n\tvoid (*pio_inline_send)(struct hfi1_devdata *dd, struct pio_buf *pbuf,\n\t\t\t\tu64 pbc, const void *from, size_t count);\n\tint (*process_vnic_dma_send)(struct hfi1_devdata *dd, u8 q_idx,\n\t\t\t\t     struct hfi1_vnic_vport_info *vinfo,\n\t\t\t\t     struct sk_buff *skb, u64 pbc, u8 plen);\n\t \n\tstruct hfi1_pportdata *pport;\n\t \n\tstruct hfi1_ctxtdata **rcd;\n\tu64 __percpu *int_counter;\n\t \n\tstruct hfi1_opcode_stats_perctx __percpu *tx_opstats;\n\t \n\tu16 flags;\n\t \n\tu8 num_pports;\n\t \n\tu8 first_dyn_alloc_ctxt;\n\t \n\n\t \n\tseqlock_t sc2vl_lock ____cacheline_aligned_in_smp;\n\tu64 sc2vl[4];\n\tu64 __percpu *rcv_limit;\n\t \n\n\t \n\tu8 oui1;\n\tu8 oui2;\n\tu8 oui3;\n\n\t \n\tstruct timer_list rcverr_timer;\n\n\twait_queue_head_t event_queue;\n\n\t \n\t__le64 *rcvhdrtail_dummy_kvaddr;\n\tdma_addr_t rcvhdrtail_dummy_dma;\n\n\tu32 rcv_ovfl_cnt;\n\t \n\tspinlock_t aspm_lock;\n\t \n\tatomic_t aspm_disabled_cnt;\n\t \n\trefcount_t user_refcount;\n\t \n\tstruct completion user_comp;\n\n\tbool eprom_available;\t \n\tbool aspm_supported;\t \n\tbool aspm_enabled;\t \n\tstruct rhashtable *sdma_rht;\n\n\t \n\tstruct hfi1_vnic_data vnic;\n\t \n\tspinlock_t irq_src_lock;\n\tint vnic_num_vports;\n\tstruct hfi1_netdev_rx *netdev_rx;\n\tstruct hfi1_affinity_node *affinity_entry;\n\n\t \n\tatomic_t ipoib_rsm_usr_num;\n};\n\n \n#define dc8051_ver(a, b, c) ((a) << 16 | (b) << 8 | (c))\n#define dc8051_ver_maj(a) (((a) & 0xff0000) >> 16)\n#define dc8051_ver_min(a) (((a) & 0x00ff00) >> 8)\n#define dc8051_ver_patch(a) ((a) & 0x0000ff)\n\n \n#define PT_EXPECTED       0\n#define PT_EAGER          1\n#define PT_INVALID_FLUSH  2\n#define PT_INVALID        3\n\nstruct tid_rb_node;\n\n \nstruct hfi1_filedata {\n\tstruct srcu_struct pq_srcu;\n\tstruct hfi1_devdata *dd;\n\tstruct hfi1_ctxtdata *uctxt;\n\tstruct hfi1_user_sdma_comp_q *cq;\n\t \n\tspinlock_t pq_rcu_lock;\n\tstruct hfi1_user_sdma_pkt_q __rcu *pq;\n\tu16 subctxt;\n\t \n\tint rec_cpu_num;\n\tu32 tid_n_pinned;\n\tbool use_mn;\n\tstruct tid_rb_node **entry_to_rb;\n\tspinlock_t tid_lock;  \n\tu32 tid_limit;\n\tu32 tid_used;\n\tu32 *invalid_tids;\n\tu32 invalid_tid_idx;\n\t \n\tspinlock_t invalid_lock;\n};\n\nextern struct xarray hfi1_dev_table;\nstruct hfi1_devdata *hfi1_lookup(int unit);\n\nstatic inline unsigned long uctxt_offset(struct hfi1_ctxtdata *uctxt)\n{\n\treturn (uctxt->ctxt - uctxt->dd->first_dyn_alloc_ctxt) *\n\t\tHFI1_MAX_SHARED_CTXTS;\n}\n\nint hfi1_init(struct hfi1_devdata *dd, int reinit);\nint hfi1_count_active_units(void);\n\nint hfi1_diag_add(struct hfi1_devdata *dd);\nvoid hfi1_diag_remove(struct hfi1_devdata *dd);\nvoid handle_linkup_change(struct hfi1_devdata *dd, u32 linkup);\n\nvoid handle_user_interrupt(struct hfi1_ctxtdata *rcd);\n\nint hfi1_create_rcvhdrq(struct hfi1_devdata *dd, struct hfi1_ctxtdata *rcd);\nint hfi1_setup_eagerbufs(struct hfi1_ctxtdata *rcd);\nint hfi1_create_kctxts(struct hfi1_devdata *dd);\nint hfi1_create_ctxtdata(struct hfi1_pportdata *ppd, int numa,\n\t\t\t struct hfi1_ctxtdata **rcd);\nvoid hfi1_free_ctxt(struct hfi1_ctxtdata *rcd);\nvoid hfi1_init_pportdata(struct pci_dev *pdev, struct hfi1_pportdata *ppd,\n\t\t\t struct hfi1_devdata *dd, u8 hw_pidx, u32 port);\nvoid hfi1_free_ctxtdata(struct hfi1_devdata *dd, struct hfi1_ctxtdata *rcd);\nint hfi1_rcd_put(struct hfi1_ctxtdata *rcd);\nint hfi1_rcd_get(struct hfi1_ctxtdata *rcd);\nstruct hfi1_ctxtdata *hfi1_rcd_get_by_index_safe(struct hfi1_devdata *dd,\n\t\t\t\t\t\t u16 ctxt);\nstruct hfi1_ctxtdata *hfi1_rcd_get_by_index(struct hfi1_devdata *dd, u16 ctxt);\nint handle_receive_interrupt(struct hfi1_ctxtdata *rcd, int thread);\nint handle_receive_interrupt_nodma_rtail(struct hfi1_ctxtdata *rcd, int thread);\nint handle_receive_interrupt_dma_rtail(struct hfi1_ctxtdata *rcd, int thread);\nint handle_receive_interrupt_napi_fp(struct hfi1_ctxtdata *rcd, int budget);\nint handle_receive_interrupt_napi_sp(struct hfi1_ctxtdata *rcd, int budget);\nvoid set_all_slowpath(struct hfi1_devdata *dd);\n\nextern const struct pci_device_id hfi1_pci_tbl[];\nvoid hfi1_make_ud_req_9B(struct rvt_qp *qp,\n\t\t\t struct hfi1_pkt_state *ps,\n\t\t\t struct rvt_swqe *wqe);\n\nvoid hfi1_make_ud_req_16B(struct rvt_qp *qp,\n\t\t\t  struct hfi1_pkt_state *ps,\n\t\t\t  struct rvt_swqe *wqe);\n\n \n#define RCV_PKT_OK      0x0  \n#define RCV_PKT_LIMIT   0x1  \n#define RCV_PKT_DONE    0x2  \n\n \nstatic inline u32 hfi1_rcd_head(struct hfi1_ctxtdata *rcd)\n{\n\treturn rcd->head;\n}\n\n \nstatic inline void hfi1_set_rcd_head(struct hfi1_ctxtdata *rcd, u32 head)\n{\n\trcd->head = head;\n}\n\n \nstatic inline __le32 *get_rhf_addr(struct hfi1_ctxtdata *rcd)\n{\n\treturn (__le32 *)rcd->rcvhdrq + rcd->head + rcd->rhf_offset;\n}\n\n \nstatic inline bool get_dma_rtail_setting(struct hfi1_ctxtdata *rcd)\n{\n\treturn !!HFI1_CAP_KGET_MASK(rcd->flags, DMA_RTAIL);\n}\n\n \nstatic inline u8 hfi1_seq_incr_wrap(u8 seq)\n{\n\tif (++seq > RHF_MAX_SEQ)\n\t\tseq = 1;\n\treturn seq;\n}\n\n \nstatic inline u8 hfi1_seq_cnt(struct hfi1_ctxtdata *rcd)\n{\n\treturn rcd->seq_cnt;\n}\n\n \nstatic inline void hfi1_set_seq_cnt(struct hfi1_ctxtdata *rcd, u8 cnt)\n{\n\trcd->seq_cnt = cnt;\n}\n\n \nstatic inline bool last_rcv_seq(struct hfi1_ctxtdata *rcd, u32 seq)\n{\n\treturn seq != rcd->seq_cnt;\n}\n\n \nstatic inline bool hfi1_seq_incr(struct hfi1_ctxtdata *rcd, u32 seq)\n{\n\trcd->seq_cnt = hfi1_seq_incr_wrap(rcd->seq_cnt);\n\treturn last_rcv_seq(rcd, seq);\n}\n\n \nstatic inline u8 get_hdrqentsize(struct hfi1_ctxtdata *rcd)\n{\n\treturn rcd->rcvhdrqentsize;\n}\n\n \nstatic inline u16 get_hdrq_cnt(struct hfi1_ctxtdata *rcd)\n{\n\treturn rcd->rcvhdrq_cnt;\n}\n\n \nstatic inline bool hfi1_is_slowpath(struct hfi1_ctxtdata *rcd)\n{\n\treturn rcd->do_interrupt == rcd->slow_handler;\n}\n\n \nstatic inline bool hfi1_is_fastpath(struct hfi1_ctxtdata *rcd)\n{\n\tif (rcd->ctxt == HFI1_CTRL_CTXT)\n\t\treturn false;\n\n\treturn rcd->do_interrupt == rcd->fast_handler;\n}\n\n \nstatic inline void hfi1_set_fast(struct hfi1_ctxtdata *rcd)\n{\n\tif (unlikely(!rcd))\n\t\treturn;\n\tif (unlikely(!hfi1_is_fastpath(rcd)))\n\t\trcd->do_interrupt = rcd->fast_handler;\n}\n\nint hfi1_reset_device(int);\n\nvoid receive_interrupt_work(struct work_struct *work);\n\n \nstatic inline int hfi1_9B_get_sc5(struct ib_header *hdr, u64 rhf)\n{\n\treturn ib_get_sc(hdr) | ((!!(rhf_dc_info(rhf))) << 4);\n}\n\n#define HFI1_JKEY_WIDTH       16\n#define HFI1_JKEY_MASK        (BIT(16) - 1)\n#define HFI1_ADMIN_JKEY_RANGE 32\n\n \nstatic inline u16 generate_jkey(kuid_t uid)\n{\n\tu16 jkey = from_kuid(current_user_ns(), uid) & HFI1_JKEY_MASK;\n\n\tif (capable(CAP_SYS_ADMIN))\n\t\tjkey &= HFI1_ADMIN_JKEY_RANGE - 1;\n\telse if (jkey < 64)\n\t\tjkey |= BIT(HFI1_JKEY_WIDTH - 1);\n\n\treturn jkey;\n}\n\n \nstatic inline u32 active_egress_rate(struct hfi1_pportdata *ppd)\n{\n\tu16 link_speed = ppd->link_speed_active;\n\tu16 link_width = ppd->link_width_active;\n\tu32 egress_rate;\n\n\tif (link_speed == OPA_LINK_SPEED_25G)\n\t\tegress_rate = 25000;\n\telse  \n\t\tegress_rate = 12500;\n\n\tswitch (link_width) {\n\tcase OPA_LINK_WIDTH_4X:\n\t\tegress_rate *= 4;\n\t\tbreak;\n\tcase OPA_LINK_WIDTH_3X:\n\t\tegress_rate *= 3;\n\t\tbreak;\n\tcase OPA_LINK_WIDTH_2X:\n\t\tegress_rate *= 2;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\n\treturn egress_rate;\n}\n\n \nstatic inline u32 egress_cycles(u32 len, u32 rate)\n{\n\tu32 cycles;\n\n\t \n\n\tcycles = len * 8;  \n\tcycles *= 805;\n\tcycles /= rate;\n\n\treturn cycles;\n}\n\nvoid set_link_ipg(struct hfi1_pportdata *ppd);\nvoid process_becn(struct hfi1_pportdata *ppd, u8 sl, u32 rlid, u32 lqpn,\n\t\t  u32 rqpn, u8 svc_type);\nvoid return_cnp(struct hfi1_ibport *ibp, struct rvt_qp *qp, u32 remote_qpn,\n\t\tu16 pkey, u32 slid, u32 dlid, u8 sc5,\n\t\tconst struct ib_grh *old_grh);\nvoid return_cnp_16B(struct hfi1_ibport *ibp, struct rvt_qp *qp,\n\t\t    u32 remote_qpn, u16 pkey, u32 slid, u32 dlid,\n\t\t    u8 sc5, const struct ib_grh *old_grh);\ntypedef void (*hfi1_handle_cnp)(struct hfi1_ibport *ibp, struct rvt_qp *qp,\n\t\t\t\tu32 remote_qpn, u16 pkey, u32 slid, u32 dlid,\n\t\t\t\tu8 sc5, const struct ib_grh *old_grh);\n\n#define PKEY_CHECK_INVALID -1\nint egress_pkey_check(struct hfi1_pportdata *ppd, u32 slid, u16 pkey,\n\t\t      u8 sc5, int8_t s_pkey_index);\n\n#define PACKET_EGRESS_TIMEOUT 350\nstatic inline void pause_for_credit_return(struct hfi1_devdata *dd)\n{\n\t \n\tu32 usec = cclock_to_ns(dd, PACKET_EGRESS_TIMEOUT) / 1000;\n\n\tudelay(usec ? usec : 1);\n}\n\n \nstatic inline u8 sc_to_vlt(struct hfi1_devdata *dd, u8 sc5)\n{\n\tunsigned seq;\n\tu8 rval;\n\n\tif (sc5 >= OPA_MAX_SCS)\n\t\treturn (u8)(0xff);\n\n\tdo {\n\t\tseq = read_seqbegin(&dd->sc2vl_lock);\n\t\trval = *(((u8 *)dd->sc2vl) + sc5);\n\t} while (read_seqretry(&dd->sc2vl_lock, seq));\n\n\treturn rval;\n}\n\n#define PKEY_MEMBER_MASK 0x8000\n#define PKEY_LOW_15_MASK 0x7fff\n\n \nstatic inline int ingress_pkey_matches_entry(u16 pkey, u16 ent)\n{\n\tu16 mkey = pkey & PKEY_LOW_15_MASK;\n\tu16 ment = ent & PKEY_LOW_15_MASK;\n\n\tif (mkey == ment) {\n\t\t \n\t\tif (!(pkey & PKEY_MEMBER_MASK))\n\t\t\treturn !!(ent & PKEY_MEMBER_MASK);\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\n \nstatic int ingress_pkey_table_search(struct hfi1_pportdata *ppd, u16 pkey)\n{\n\tint i;\n\n\tfor (i = 0; i < MAX_PKEY_VALUES; i++) {\n\t\tif (ingress_pkey_matches_entry(pkey, ppd->pkeys[i]))\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\n \nstatic void ingress_pkey_table_fail(struct hfi1_pportdata *ppd, u16 pkey,\n\t\t\t\t    u32 slid)\n{\n\tstruct hfi1_devdata *dd = ppd->dd;\n\n\tincr_cntr64(&ppd->port_rcv_constraint_errors);\n\tif (!(dd->err_info_rcv_constraint.status & OPA_EI_STATUS_SMASK)) {\n\t\tdd->err_info_rcv_constraint.status |= OPA_EI_STATUS_SMASK;\n\t\tdd->err_info_rcv_constraint.slid = slid;\n\t\tdd->err_info_rcv_constraint.pkey = pkey;\n\t}\n}\n\n \nstatic inline int ingress_pkey_check(struct hfi1_pportdata *ppd, u16 pkey,\n\t\t\t\t     u8 sc5, u8 idx, u32 slid, bool force)\n{\n\tif (!(force) && !(ppd->part_enforce & HFI1_PART_ENFORCE_IN))\n\t\treturn 0;\n\n\t \n\tif ((sc5 == 0xf) && ((pkey & PKEY_LOW_15_MASK) != PKEY_LOW_15_MASK))\n\t\tgoto bad;\n\n\t \n\tif ((pkey & PKEY_LOW_15_MASK) == 0)\n\t\tgoto bad;\n\n\t \n\tif (ingress_pkey_matches_entry(pkey, ppd->pkeys[idx]))\n\t\treturn 0;\n\n\t \n\tif (!ingress_pkey_table_search(ppd, pkey))\n\t\treturn 0;\n\nbad:\n\tingress_pkey_table_fail(ppd, pkey, slid);\n\treturn 1;\n}\n\n \nstatic inline int rcv_pkey_check(struct hfi1_pportdata *ppd, u16 pkey,\n\t\t\t\t u8 sc5, u16 slid)\n{\n\tif (!(ppd->part_enforce & HFI1_PART_ENFORCE_IN))\n\t\treturn 0;\n\n\t \n\tif ((sc5 == 0xf) && ((pkey & PKEY_LOW_15_MASK) != PKEY_LOW_15_MASK))\n\t\tgoto bad;\n\n\treturn 0;\nbad:\n\tingress_pkey_table_fail(ppd, pkey, slid);\n\treturn 1;\n}\n\n \n\n \n#define OPA_MTU_0     0\n#define OPA_MTU_256   1\n#define OPA_MTU_512   2\n#define OPA_MTU_1024  3\n#define OPA_MTU_2048  4\n#define OPA_MTU_4096  5\n\nu32 lrh_max_header_bytes(struct hfi1_devdata *dd);\nint mtu_to_enum(u32 mtu, int default_if_bad);\nu16 enum_to_mtu(int mtu);\nstatic inline int valid_ib_mtu(unsigned int mtu)\n{\n\treturn mtu == 256 || mtu == 512 ||\n\t\tmtu == 1024 || mtu == 2048 ||\n\t\tmtu == 4096;\n}\n\nstatic inline int valid_opa_max_mtu(unsigned int mtu)\n{\n\treturn mtu >= 2048 &&\n\t\t(valid_ib_mtu(mtu) || mtu == 8192 || mtu == 10240);\n}\n\nint set_mtu(struct hfi1_pportdata *ppd);\n\nint hfi1_set_lid(struct hfi1_pportdata *ppd, u32 lid, u8 lmc);\nvoid hfi1_disable_after_error(struct hfi1_devdata *dd);\nint hfi1_set_uevent_bits(struct hfi1_pportdata *ppd, const int evtbit);\nint hfi1_rcvbuf_validate(u32 size, u8 type, u16 *encode);\n\nint fm_get_table(struct hfi1_pportdata *ppd, int which, void *t);\nint fm_set_table(struct hfi1_pportdata *ppd, int which, void *t);\n\nvoid set_up_vau(struct hfi1_devdata *dd, u8 vau);\nvoid set_up_vl15(struct hfi1_devdata *dd, u16 vl15buf);\nvoid reset_link_credits(struct hfi1_devdata *dd);\nvoid assign_remote_cm_au_table(struct hfi1_devdata *dd, u8 vcu);\n\nint set_buffer_control(struct hfi1_pportdata *ppd, struct buffer_control *bc);\n\nstatic inline struct hfi1_devdata *dd_from_ppd(struct hfi1_pportdata *ppd)\n{\n\treturn ppd->dd;\n}\n\nstatic inline struct hfi1_devdata *dd_from_dev(struct hfi1_ibdev *dev)\n{\n\treturn container_of(dev, struct hfi1_devdata, verbs_dev);\n}\n\nstatic inline struct hfi1_devdata *dd_from_ibdev(struct ib_device *ibdev)\n{\n\treturn dd_from_dev(to_idev(ibdev));\n}\n\nstatic inline struct hfi1_pportdata *ppd_from_ibp(struct hfi1_ibport *ibp)\n{\n\treturn container_of(ibp, struct hfi1_pportdata, ibport_data);\n}\n\nstatic inline struct hfi1_ibdev *dev_from_rdi(struct rvt_dev_info *rdi)\n{\n\treturn container_of(rdi, struct hfi1_ibdev, rdi);\n}\n\nstatic inline struct hfi1_ibport *to_iport(struct ib_device *ibdev, u32 port)\n{\n\tstruct hfi1_devdata *dd = dd_from_ibdev(ibdev);\n\tu32 pidx = port - 1;  \n\n\tWARN_ON(pidx >= dd->num_pports);\n\treturn &dd->pport[pidx].ibport_data;\n}\n\nstatic inline struct hfi1_ibport *rcd_to_iport(struct hfi1_ctxtdata *rcd)\n{\n\treturn &rcd->ppd->ibport_data;\n}\n\n \nstatic inline bool hfi1_may_ecn(struct hfi1_packet *pkt)\n{\n\tbool fecn, becn;\n\n\tif (pkt->etype == RHF_RCV_TYPE_BYPASS) {\n\t\tfecn = hfi1_16B_get_fecn(pkt->hdr);\n\t\tbecn = hfi1_16B_get_becn(pkt->hdr);\n\t} else {\n\t\tfecn = ib_bth_get_fecn(pkt->ohdr);\n\t\tbecn = ib_bth_get_becn(pkt->ohdr);\n\t}\n\treturn fecn || becn;\n}\n\nbool hfi1_process_ecn_slowpath(struct rvt_qp *qp, struct hfi1_packet *pkt,\n\t\t\t       bool prescan);\nstatic inline bool process_ecn(struct rvt_qp *qp, struct hfi1_packet *pkt)\n{\n\tbool do_work;\n\n\tdo_work = hfi1_may_ecn(pkt);\n\tif (unlikely(do_work))\n\t\treturn hfi1_process_ecn_slowpath(qp, pkt, false);\n\treturn false;\n}\n\n \nstatic inline u16 hfi1_get_pkey(struct hfi1_ibport *ibp, unsigned index)\n{\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\tu16 ret;\n\n\tif (index >= ARRAY_SIZE(ppd->pkeys))\n\t\tret = 0;\n\telse\n\t\tret = ppd->pkeys[index];\n\n\treturn ret;\n}\n\n \nstatic inline __be64 get_sguid(struct hfi1_ibport *ibp, unsigned int index)\n{\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\n\tWARN_ON(index >= HFI1_GUIDS_PER_PORT);\n\treturn cpu_to_be64(ppd->guids[index]);\n}\n\n \nstatic inline struct cc_state *get_cc_state(struct hfi1_pportdata *ppd)\n{\n\treturn rcu_dereference(ppd->cc_state);\n}\n\n \nstatic inline\nstruct cc_state *get_cc_state_protected(struct hfi1_pportdata *ppd)\n{\n\treturn rcu_dereference_protected(ppd->cc_state,\n\t\t\t\t\t lockdep_is_held(&ppd->cc_state_lock));\n}\n\n \n#define HFI1_INITTED           0x1     \n#define HFI1_PRESENT           0x2     \n#define HFI1_FROZEN            0x4     \n#define HFI1_HAS_SDMA_TIMEOUT  0x8\n#define HFI1_HAS_SEND_DMA      0x10    \n#define HFI1_FORCED_FREEZE     0x80    \n#define HFI1_SHUTDOWN          0x100   \n\n \n#define HFI1_PBC_LENGTH_MASK                     ((1 << 11) - 1)\n\n \n\t\t \n#define HFI1_CTXT_BASE_UNINIT 1\n\t\t \n#define HFI1_CTXT_BASE_FAILED 2\n\t\t \n#define HFI1_CTXT_WAITING_RCV 3\n\t\t \n#define HFI1_CTXT_WAITING_URG 4\n\n \nint hfi1_init_dd(struct hfi1_devdata *dd);\nvoid hfi1_free_devdata(struct hfi1_devdata *dd);\n\n \nvoid hfi1_start_led_override(struct hfi1_pportdata *ppd, unsigned int timeon,\n\t\t\t     unsigned int timeoff);\nvoid shutdown_led_override(struct hfi1_pportdata *ppd);\n\n#define HFI1_CREDIT_RETURN_RATE (100)\n\n \n#define DEFAULT_RCVHDRSIZE 9\n\n \n#define DEFAULT_RCVHDR_ENTSIZE 32\n\nbool hfi1_can_pin_pages(struct hfi1_devdata *dd, struct mm_struct *mm,\n\t\t\tu32 nlocked, u32 npages);\nint hfi1_acquire_user_pages(struct mm_struct *mm, unsigned long vaddr,\n\t\t\t    size_t npages, bool writable, struct page **pages);\nvoid hfi1_release_user_pages(struct mm_struct *mm, struct page **p,\n\t\t\t     size_t npages, bool dirty);\n\n \nstatic inline __le64 *hfi1_rcvhdrtail_kvaddr(const struct hfi1_ctxtdata *rcd)\n{\n\treturn (__le64 *)rcd->rcvhdrtail_kvaddr;\n}\n\nstatic inline void clear_rcvhdrtail(const struct hfi1_ctxtdata *rcd)\n{\n\tu64 *kv = (u64 *)hfi1_rcvhdrtail_kvaddr(rcd);\n\n\tif (kv)\n\t\t*kv = 0ULL;\n}\n\nstatic inline u32 get_rcvhdrtail(const struct hfi1_ctxtdata *rcd)\n{\n\t \n\treturn (u32)le64_to_cpu(*hfi1_rcvhdrtail_kvaddr(rcd));\n}\n\nstatic inline bool hfi1_packet_present(struct hfi1_ctxtdata *rcd)\n{\n\tif (likely(!rcd->rcvhdrtail_kvaddr)) {\n\t\tu32 seq = rhf_rcv_seq(rhf_to_cpu(get_rhf_addr(rcd)));\n\n\t\treturn !last_rcv_seq(rcd, seq);\n\t}\n\treturn hfi1_rcd_head(rcd) != get_rcvhdrtail(rcd);\n}\n\n \n\nextern const char ib_hfi1_version[];\nextern const struct attribute_group ib_hfi1_attr_group;\nextern const struct attribute_group *hfi1_attr_port_groups[];\n\nint hfi1_device_create(struct hfi1_devdata *dd);\nvoid hfi1_device_remove(struct hfi1_devdata *dd);\n\nint hfi1_verbs_register_sysfs(struct hfi1_devdata *dd);\nvoid hfi1_verbs_unregister_sysfs(struct hfi1_devdata *dd);\n \nint qsfp_dump(struct hfi1_pportdata *ppd, char *buf, int len);\n\nint hfi1_pcie_init(struct hfi1_devdata *dd);\nvoid hfi1_pcie_cleanup(struct pci_dev *pdev);\nint hfi1_pcie_ddinit(struct hfi1_devdata *dd, struct pci_dev *pdev);\nvoid hfi1_pcie_ddcleanup(struct hfi1_devdata *);\nint pcie_speeds(struct hfi1_devdata *dd);\nint restore_pci_variables(struct hfi1_devdata *dd);\nint save_pci_variables(struct hfi1_devdata *dd);\nint do_pcie_gen3_transition(struct hfi1_devdata *dd);\nvoid tune_pcie_caps(struct hfi1_devdata *dd);\nint parse_platform_config(struct hfi1_devdata *dd);\nint get_platform_config_field(struct hfi1_devdata *dd,\n\t\t\t      enum platform_config_table_type_encoding\n\t\t\t      table_type, int table_index, int field_index,\n\t\t\t      u32 *data, u32 len);\n\nstruct pci_dev *get_pci_dev(struct rvt_dev_info *rdi);\n\n \nstatic inline void flush_wc(void)\n{\n\tasm volatile(\"sfence\" : : : \"memory\");\n}\n\nvoid handle_eflags(struct hfi1_packet *packet);\nvoid seqfile_dump_rcd(struct seq_file *s, struct hfi1_ctxtdata *rcd);\n\n \nextern unsigned int hfi1_max_mtu;\nextern unsigned int hfi1_cu;\nextern unsigned int user_credit_return_threshold;\nextern int num_user_contexts;\nextern unsigned long n_krcvqs;\nextern uint krcvqs[];\nextern int krcvqsset;\nextern uint loopback;\nextern uint quick_linkup;\nextern uint rcv_intr_timeout;\nextern uint rcv_intr_count;\nextern uint rcv_intr_dynamic;\nextern ushort link_crc_mask;\n\nextern struct mutex hfi1_mutex;\n\n \n#define STATUS_TIMEOUT 60\n\n#define DRIVER_NAME\t\t\"hfi1\"\n#define HFI1_USER_MINOR_BASE     0\n#define HFI1_TRACE_MINOR         127\n#define HFI1_NMINORS             255\n\n#define PCI_VENDOR_ID_INTEL 0x8086\n#define PCI_DEVICE_ID_INTEL0 0x24f0\n#define PCI_DEVICE_ID_INTEL1 0x24f1\n\n#define HFI1_PKT_USER_SC_INTEGRITY\t\t\t\t\t    \\\n\t(SEND_CTXT_CHECK_ENABLE_DISALLOW_NON_KDETH_PACKETS_SMASK\t    \\\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_KDETH_PACKETS_SMASK\t\t\\\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_BYPASS_SMASK\t\t    \\\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_GRH_SMASK)\n\n#define HFI1_PKT_KERNEL_SC_INTEGRITY\t\t\t\t\t    \\\n\t(SEND_CTXT_CHECK_ENABLE_DISALLOW_KDETH_PACKETS_SMASK)\n\nstatic inline u64 hfi1_pkt_default_send_ctxt_mask(struct hfi1_devdata *dd,\n\t\t\t\t\t\t  u16 ctxt_type)\n{\n\tu64 base_sc_integrity;\n\n\t \n\tif (HFI1_CAP_IS_KSET(NO_INTEGRITY))\n\t\treturn 0;\n\n\tbase_sc_integrity =\n\tSEND_CTXT_CHECK_ENABLE_DISALLOW_BYPASS_BAD_PKT_LEN_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_PBC_STATIC_RATE_CONTROL_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_TOO_LONG_BYPASS_PACKETS_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_TOO_LONG_IB_PACKETS_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_BAD_PKT_LEN_SMASK\n#ifndef CONFIG_FAULT_INJECTION\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_PBC_TEST_SMASK\n#endif\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_TOO_SMALL_BYPASS_PACKETS_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_TOO_SMALL_IB_PACKETS_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_RAW_IPV6_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_DISALLOW_RAW_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_CHECK_BYPASS_VL_MAPPING_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_CHECK_VL_MAPPING_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_CHECK_OPCODE_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_CHECK_SLID_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_CHECK_VL_SMASK\n\t| SEND_CTXT_CHECK_ENABLE_CHECK_ENABLE_SMASK;\n\n\tif (ctxt_type == SC_USER)\n\t\tbase_sc_integrity |=\n#ifndef CONFIG_FAULT_INJECTION\n\t\t\tSEND_CTXT_CHECK_ENABLE_DISALLOW_PBC_TEST_SMASK |\n#endif\n\t\t\tHFI1_PKT_USER_SC_INTEGRITY;\n\telse if (ctxt_type != SC_KERNEL)\n\t\tbase_sc_integrity |= HFI1_PKT_KERNEL_SC_INTEGRITY;\n\n\t \n\tif (!is_ax(dd))\n\t\tbase_sc_integrity |= SEND_CTXT_CHECK_ENABLE_CHECK_JOB_KEY_SMASK;\n\n\treturn base_sc_integrity;\n}\n\nstatic inline u64 hfi1_pkt_base_sdma_integrity(struct hfi1_devdata *dd)\n{\n\tu64 base_sdma_integrity;\n\n\t \n\tif (HFI1_CAP_IS_KSET(NO_INTEGRITY))\n\t\treturn 0;\n\n\tbase_sdma_integrity =\n\tSEND_DMA_CHECK_ENABLE_DISALLOW_BYPASS_BAD_PKT_LEN_SMASK\n\t| SEND_DMA_CHECK_ENABLE_DISALLOW_TOO_LONG_BYPASS_PACKETS_SMASK\n\t| SEND_DMA_CHECK_ENABLE_DISALLOW_TOO_LONG_IB_PACKETS_SMASK\n\t| SEND_DMA_CHECK_ENABLE_DISALLOW_BAD_PKT_LEN_SMASK\n\t| SEND_DMA_CHECK_ENABLE_DISALLOW_TOO_SMALL_BYPASS_PACKETS_SMASK\n\t| SEND_DMA_CHECK_ENABLE_DISALLOW_TOO_SMALL_IB_PACKETS_SMASK\n\t| SEND_DMA_CHECK_ENABLE_DISALLOW_RAW_IPV6_SMASK\n\t| SEND_DMA_CHECK_ENABLE_DISALLOW_RAW_SMASK\n\t| SEND_DMA_CHECK_ENABLE_CHECK_BYPASS_VL_MAPPING_SMASK\n\t| SEND_DMA_CHECK_ENABLE_CHECK_VL_MAPPING_SMASK\n\t| SEND_DMA_CHECK_ENABLE_CHECK_OPCODE_SMASK\n\t| SEND_DMA_CHECK_ENABLE_CHECK_SLID_SMASK\n\t| SEND_DMA_CHECK_ENABLE_CHECK_VL_SMASK\n\t| SEND_DMA_CHECK_ENABLE_CHECK_ENABLE_SMASK;\n\n\tif (!HFI1_CAP_IS_KSET(STATIC_RATE_CTRL))\n\t\tbase_sdma_integrity |=\n\t\tSEND_DMA_CHECK_ENABLE_DISALLOW_PBC_STATIC_RATE_CONTROL_SMASK;\n\n\t \n\tif (!is_ax(dd))\n\t\tbase_sdma_integrity |=\n\t\t\tSEND_DMA_CHECK_ENABLE_CHECK_JOB_KEY_SMASK;\n\n\treturn base_sdma_integrity;\n}\n\n#define dd_dev_emerg(dd, fmt, ...) \\\n\tdev_emerg(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\t  rvt_get_ibdev_name(&(dd)->verbs_dev.rdi), ##__VA_ARGS__)\n\n#define dd_dev_err(dd, fmt, ...) \\\n\tdev_err(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\trvt_get_ibdev_name(&(dd)->verbs_dev.rdi), ##__VA_ARGS__)\n\n#define dd_dev_err_ratelimited(dd, fmt, ...) \\\n\tdev_err_ratelimited(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\t\t    rvt_get_ibdev_name(&(dd)->verbs_dev.rdi), \\\n\t\t\t    ##__VA_ARGS__)\n\n#define dd_dev_warn(dd, fmt, ...) \\\n\tdev_warn(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\t rvt_get_ibdev_name(&(dd)->verbs_dev.rdi), ##__VA_ARGS__)\n\n#define dd_dev_warn_ratelimited(dd, fmt, ...) \\\n\tdev_warn_ratelimited(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\t\t     rvt_get_ibdev_name(&(dd)->verbs_dev.rdi), \\\n\t\t\t     ##__VA_ARGS__)\n\n#define dd_dev_info(dd, fmt, ...) \\\n\tdev_info(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\t rvt_get_ibdev_name(&(dd)->verbs_dev.rdi), ##__VA_ARGS__)\n\n#define dd_dev_info_ratelimited(dd, fmt, ...) \\\n\tdev_info_ratelimited(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\t\t     rvt_get_ibdev_name(&(dd)->verbs_dev.rdi), \\\n\t\t\t     ##__VA_ARGS__)\n\n#define dd_dev_dbg(dd, fmt, ...) \\\n\tdev_dbg(&(dd)->pcidev->dev, \"%s: \" fmt, \\\n\t\trvt_get_ibdev_name(&(dd)->verbs_dev.rdi), ##__VA_ARGS__)\n\n#define hfi1_dev_porterr(dd, port, fmt, ...) \\\n\tdev_err(&(dd)->pcidev->dev, \"%s: port %u: \" fmt, \\\n\t\trvt_get_ibdev_name(&(dd)->verbs_dev.rdi), (port), ##__VA_ARGS__)\n\n \nstruct hfi1_hwerror_msgs {\n\tu64 mask;\n\tconst char *msg;\n\tsize_t sz;\n};\n\n \nvoid hfi1_format_hwerrors(u64 hwerrs,\n\t\t\t  const struct hfi1_hwerror_msgs *hwerrmsgs,\n\t\t\t  size_t nhwerrmsgs, char *msg, size_t lmsg);\n\n#define USER_OPCODE_CHECK_VAL 0xC0\n#define USER_OPCODE_CHECK_MASK 0xC0\n#define OPCODE_CHECK_VAL_DISABLED 0x0\n#define OPCODE_CHECK_MASK_DISABLED 0x0\n\nstatic inline void hfi1_reset_cpu_counters(struct hfi1_devdata *dd)\n{\n\tstruct hfi1_pportdata *ppd;\n\tint i;\n\n\tdd->z_int_counter = get_all_cpu_total(dd->int_counter);\n\tdd->z_rcv_limit = get_all_cpu_total(dd->rcv_limit);\n\tdd->z_send_schedule = get_all_cpu_total(dd->send_schedule);\n\n\tppd = (struct hfi1_pportdata *)(dd + 1);\n\tfor (i = 0; i < dd->num_pports; i++, ppd++) {\n\t\tppd->ibport_data.rvp.z_rc_acks =\n\t\t\tget_all_cpu_total(ppd->ibport_data.rvp.rc_acks);\n\t\tppd->ibport_data.rvp.z_rc_qacks =\n\t\t\tget_all_cpu_total(ppd->ibport_data.rvp.rc_qacks);\n\t}\n}\n\n \nstatic inline void setextled(struct hfi1_devdata *dd, u32 on)\n{\n\tif (on)\n\t\twrite_csr(dd, DCC_CFG_LED_CNTRL, 0x1F);\n\telse\n\t\twrite_csr(dd, DCC_CFG_LED_CNTRL, 0x10);\n}\n\n \nstatic inline u32 i2c_target(u32 target)\n{\n\treturn target ? CR_I2C2 : CR_I2C1;\n}\n\n \nstatic inline u32 qsfp_resource(struct hfi1_devdata *dd)\n{\n\treturn i2c_target(dd->hfi1_id);\n}\n\n \nstatic inline bool is_integrated(struct hfi1_devdata *dd)\n{\n\treturn dd->pcidev->device == PCI_DEVICE_ID_INTEL1;\n}\n\n \nstatic inline bool hfi1_need_drop(struct hfi1_devdata *dd)\n{\n\tif (unlikely(dd->do_drop &&\n\t\t     atomic_xchg(&dd->drop_packet, DROP_PACKET_OFF) ==\n\t\t     DROP_PACKET_ON)) {\n\t\tdd->do_drop = false;\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nint hfi1_tempsense_rd(struct hfi1_devdata *dd, struct hfi1_temp *temp);\n\n#define DD_DEV_ENTRY(dd)       __string(dev, dev_name(&(dd)->pcidev->dev))\n#define DD_DEV_ASSIGN(dd)      __assign_str(dev, dev_name(&(dd)->pcidev->dev))\n\nstatic inline void hfi1_update_ah_attr(struct ib_device *ibdev,\n\t\t\t\t       struct rdma_ah_attr *attr)\n{\n\tstruct hfi1_pportdata *ppd;\n\tstruct hfi1_ibport *ibp;\n\tu32 dlid = rdma_ah_get_dlid(attr);\n\n\t \n\tibp = to_iport(ibdev, rdma_ah_get_port_num(attr));\n\tppd = ppd_from_ibp(ibp);\n\tif ((((dlid >= be16_to_cpu(IB_MULTICAST_LID_BASE)) ||\n\t      (ppd->lid >= be16_to_cpu(IB_MULTICAST_LID_BASE))) &&\n\t    (dlid != be32_to_cpu(OPA_LID_PERMISSIVE)) &&\n\t    (dlid != be16_to_cpu(IB_LID_PERMISSIVE)) &&\n\t    (!(rdma_ah_get_ah_flags(attr) & IB_AH_GRH))) ||\n\t    (rdma_ah_get_make_grd(attr))) {\n\t\trdma_ah_set_ah_flags(attr, IB_AH_GRH);\n\t\trdma_ah_set_interface_id(attr, OPA_MAKE_ID(dlid));\n\t\trdma_ah_set_subnet_prefix(attr, ibp->rvp.gid_prefix);\n\t}\n}\n\n \nstatic inline bool hfi1_check_mcast(u32 lid)\n{\n\treturn ((lid >= opa_get_mcast_base(OPA_MCAST_NR)) &&\n\t\t(lid != be32_to_cpu(OPA_LID_PERMISSIVE)));\n}\n\n#define opa_get_lid(lid, format)\t\\\n\t__opa_get_lid(lid, OPA_PORT_PACKET_FORMAT_##format)\n\n \nstatic inline u32 __opa_get_lid(u32 lid, u8 format)\n{\n\tbool is_mcast = hfi1_check_mcast(lid);\n\n\tswitch (format) {\n\tcase OPA_PORT_PACKET_FORMAT_8B:\n\tcase OPA_PORT_PACKET_FORMAT_10B:\n\t\tif (is_mcast)\n\t\t\treturn (lid - opa_get_mcast_base(OPA_MCAST_NR) +\n\t\t\t\t0xF0000);\n\t\treturn lid & 0xFFFFF;\n\tcase OPA_PORT_PACKET_FORMAT_16B:\n\t\tif (is_mcast)\n\t\t\treturn (lid - opa_get_mcast_base(OPA_MCAST_NR) +\n\t\t\t\t0xF00000);\n\t\treturn lid & 0xFFFFFF;\n\tcase OPA_PORT_PACKET_FORMAT_9B:\n\t\tif (is_mcast)\n\t\t\treturn (lid -\n\t\t\t\topa_get_mcast_base(OPA_MCAST_NR) +\n\t\t\t\tbe16_to_cpu(IB_MULTICAST_LID_BASE));\n\t\telse\n\t\t\treturn lid & 0xFFFF;\n\tdefault:\n\t\treturn lid;\n\t}\n}\n\n \nstatic inline bool hfi1_is_16B_mcast(u32 lid)\n{\n\treturn ((lid >=\n\t\topa_get_lid(opa_get_mcast_base(OPA_MCAST_NR), 16B)) &&\n\t\t(lid != opa_get_lid(be32_to_cpu(OPA_LID_PERMISSIVE), 16B)));\n}\n\nstatic inline void hfi1_make_opa_lid(struct rdma_ah_attr *attr)\n{\n\tconst struct ib_global_route *grh = rdma_ah_read_grh(attr);\n\tu32 dlid = rdma_ah_get_dlid(attr);\n\n\t \n\tif (ib_is_opa_gid(&grh->dgid))\n\t\tdlid = opa_get_lid_from_gid(&grh->dgid);\n\telse if ((dlid >= be16_to_cpu(IB_MULTICAST_LID_BASE)) &&\n\t\t (dlid != be16_to_cpu(IB_LID_PERMISSIVE)) &&\n\t\t (dlid != be32_to_cpu(OPA_LID_PERMISSIVE)))\n\t\tdlid = dlid - be16_to_cpu(IB_MULTICAST_LID_BASE) +\n\t\t\topa_get_mcast_base(OPA_MCAST_NR);\n\telse if (dlid == be16_to_cpu(IB_LID_PERMISSIVE))\n\t\tdlid = be32_to_cpu(OPA_LID_PERMISSIVE);\n\n\trdma_ah_set_dlid(attr, dlid);\n}\n\nstatic inline u8 hfi1_get_packet_type(u32 lid)\n{\n\t \n\tif (lid >= opa_get_mcast_base(OPA_MCAST_NR))\n\t\treturn HFI1_PKT_TYPE_9B;\n\n\t \n\tif (lid >= opa_get_lid(opa_get_mcast_base(OPA_MCAST_NR), 9B))\n\t\treturn HFI1_PKT_TYPE_16B;\n\n\treturn HFI1_PKT_TYPE_9B;\n}\n\nstatic inline bool hfi1_get_hdr_type(u32 lid, struct rdma_ah_attr *attr)\n{\n\t \n\tif (rdma_ah_get_dlid(attr) == be32_to_cpu(OPA_LID_PERMISSIVE))\n\t\treturn (ib_is_opa_gid(&rdma_ah_read_grh(attr)->dgid)) ?\n\t\t\tHFI1_PKT_TYPE_16B : HFI1_PKT_TYPE_9B;\n\n\t \n\tif (hfi1_get_packet_type(rdma_ah_get_dlid(attr)) == HFI1_PKT_TYPE_16B)\n\t\treturn HFI1_PKT_TYPE_16B;\n\n\treturn hfi1_get_packet_type(lid);\n}\n\nstatic inline void hfi1_make_ext_grh(struct hfi1_packet *packet,\n\t\t\t\t     struct ib_grh *grh, u32 slid,\n\t\t\t\t     u32 dlid)\n{\n\tstruct hfi1_ibport *ibp = &packet->rcd->ppd->ibport_data;\n\tstruct hfi1_pportdata *ppd = ppd_from_ibp(ibp);\n\n\tif (!ibp)\n\t\treturn;\n\n\tgrh->hop_limit = 1;\n\tgrh->sgid.global.subnet_prefix = ibp->rvp.gid_prefix;\n\tif (slid == opa_get_lid(be32_to_cpu(OPA_LID_PERMISSIVE), 16B))\n\t\tgrh->sgid.global.interface_id =\n\t\t\tOPA_MAKE_ID(be32_to_cpu(OPA_LID_PERMISSIVE));\n\telse\n\t\tgrh->sgid.global.interface_id = OPA_MAKE_ID(slid);\n\n\t \n\tgrh->dgid.global.subnet_prefix = ibp->rvp.gid_prefix;\n\tgrh->dgid.global.interface_id =\n\t\tcpu_to_be64(ppd->guids[HFI1_PORT_GUID_INDEX]);\n}\n\nstatic inline int hfi1_get_16b_padding(u32 hdr_size, u32 payload)\n{\n\treturn -(hdr_size + payload + (SIZE_OF_CRC << 2) +\n\t\t     SIZE_OF_LT) & 0x7;\n}\n\nstatic inline void hfi1_make_ib_hdr(struct ib_header *hdr,\n\t\t\t\t    u16 lrh0, u16 len,\n\t\t\t\t    u16 dlid, u16 slid)\n{\n\thdr->lrh[0] = cpu_to_be16(lrh0);\n\thdr->lrh[1] = cpu_to_be16(dlid);\n\thdr->lrh[2] = cpu_to_be16(len);\n\thdr->lrh[3] = cpu_to_be16(slid);\n}\n\nstatic inline void hfi1_make_16b_hdr(struct hfi1_16b_header *hdr,\n\t\t\t\t     u32 slid, u32 dlid,\n\t\t\t\t     u16 len, u16 pkey,\n\t\t\t\t     bool becn, bool fecn, u8 l4,\n\t\t\t\t     u8 sc)\n{\n\tu32 lrh0 = 0;\n\tu32 lrh1 = 0x40000000;\n\tu32 lrh2 = 0;\n\tu32 lrh3 = 0;\n\n\tlrh0 = (lrh0 & ~OPA_16B_BECN_MASK) | (becn << OPA_16B_BECN_SHIFT);\n\tlrh0 = (lrh0 & ~OPA_16B_LEN_MASK) | (len << OPA_16B_LEN_SHIFT);\n\tlrh0 = (lrh0 & ~OPA_16B_LID_MASK)  | (slid & OPA_16B_LID_MASK);\n\tlrh1 = (lrh1 & ~OPA_16B_FECN_MASK) | (fecn << OPA_16B_FECN_SHIFT);\n\tlrh1 = (lrh1 & ~OPA_16B_SC_MASK) | (sc << OPA_16B_SC_SHIFT);\n\tlrh1 = (lrh1 & ~OPA_16B_LID_MASK) | (dlid & OPA_16B_LID_MASK);\n\tlrh2 = (lrh2 & ~OPA_16B_SLID_MASK) |\n\t\t((slid >> OPA_16B_SLID_SHIFT) << OPA_16B_SLID_HIGH_SHIFT);\n\tlrh2 = (lrh2 & ~OPA_16B_DLID_MASK) |\n\t\t((dlid >> OPA_16B_DLID_SHIFT) << OPA_16B_DLID_HIGH_SHIFT);\n\tlrh2 = (lrh2 & ~OPA_16B_PKEY_MASK) | ((u32)pkey << OPA_16B_PKEY_SHIFT);\n\tlrh2 = (lrh2 & ~OPA_16B_L4_MASK) | l4;\n\n\thdr->lrh[0] = lrh0;\n\thdr->lrh[1] = lrh1;\n\thdr->lrh[2] = lrh2;\n\thdr->lrh[3] = lrh3;\n}\n#endif                           \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}