{
  "module_name": "ib_verbs.h",
  "hash_id": "c1c898b333fa283a8a32840fecea893a02daa7e4b0f5a7db6f07b95a6ada3d5f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/bnxt_re/ib_verbs.h",
  "human_readable_source": " \n\n#ifndef __BNXT_RE_IB_VERBS_H__\n#define __BNXT_RE_IB_VERBS_H__\n\nstruct bnxt_re_gid_ctx {\n\tu32\t\t\tidx;\n\tu32\t\t\trefcnt;\n};\n\n#define BNXT_RE_FENCE_BYTES\t64\nstruct bnxt_re_fence_data {\n\tu32 size;\n\tu8 va[BNXT_RE_FENCE_BYTES];\n\tdma_addr_t dma_addr;\n\tstruct bnxt_re_mr *mr;\n\tstruct ib_mw *mw;\n\tstruct bnxt_qplib_swqe bind_wqe;\n\tu32 bind_rkey;\n};\n\nstruct bnxt_re_pd {\n\tstruct ib_pd            ib_pd;\n\tstruct bnxt_re_dev\t*rdev;\n\tstruct bnxt_qplib_pd\tqplib_pd;\n\tstruct bnxt_re_fence_data fence;\n\tstruct rdma_user_mmap_entry *pd_db_mmap;\n\tstruct rdma_user_mmap_entry *pd_wcdb_mmap;\n};\n\nstruct bnxt_re_ah {\n\tstruct ib_ah\t\tib_ah;\n\tstruct bnxt_re_dev\t*rdev;\n\tstruct bnxt_qplib_ah\tqplib_ah;\n};\n\nstruct bnxt_re_srq {\n\tstruct ib_srq\t\tib_srq;\n\tstruct bnxt_re_dev\t*rdev;\n\tu32\t\t\tsrq_limit;\n\tstruct bnxt_qplib_srq\tqplib_srq;\n\tstruct ib_umem\t\t*umem;\n\tspinlock_t\t\tlock;\t\t \n};\n\nstruct bnxt_re_qp {\n\tstruct ib_qp\t\tib_qp;\n\tstruct list_head\tlist;\n\tstruct bnxt_re_dev\t*rdev;\n\tspinlock_t\t\tsq_lock;\t \n\tspinlock_t\t\trq_lock;\t \n\tstruct bnxt_qplib_qp\tqplib_qp;\n\tstruct ib_umem\t\t*sumem;\n\tstruct ib_umem\t\t*rumem;\n\t \n\tu32\t\t\tsend_psn;\n\tstruct ib_ud_header\tqp1_hdr;\n\tstruct bnxt_re_cq\t*scq;\n\tstruct bnxt_re_cq\t*rcq;\n};\n\nstruct bnxt_re_cq {\n\tstruct ib_cq\t\tib_cq;\n\tstruct bnxt_re_dev\t*rdev;\n\tspinlock_t              cq_lock;\t \n\tu16\t\t\tcq_count;\n\tu16\t\t\tcq_period;\n\tstruct bnxt_qplib_cq\tqplib_cq;\n\tstruct bnxt_qplib_cqe\t*cql;\n#define MAX_CQL_PER_POLL\t1024\n\tu32\t\t\tmax_cql;\n\tstruct ib_umem\t\t*umem;\n\tstruct ib_umem\t\t*resize_umem;\n\tint\t\t\tresize_cqe;\n};\n\nstruct bnxt_re_mr {\n\tstruct bnxt_re_dev\t*rdev;\n\tstruct ib_mr\t\tib_mr;\n\tstruct ib_umem\t\t*ib_umem;\n\tstruct bnxt_qplib_mrw\tqplib_mr;\n\tu32\t\t\tnpages;\n\tu64\t\t\t*pages;\n\tstruct bnxt_qplib_frpl\tqplib_frpl;\n};\n\nstruct bnxt_re_frpl {\n\tstruct bnxt_re_dev\t\t*rdev;\n\tstruct bnxt_qplib_frpl\t\tqplib_frpl;\n\tu64\t\t\t\t*page_list;\n};\n\nstruct bnxt_re_mw {\n\tstruct bnxt_re_dev\t*rdev;\n\tstruct ib_mw\t\tib_mw;\n\tstruct bnxt_qplib_mrw\tqplib_mw;\n};\n\nstruct bnxt_re_ucontext {\n\tstruct ib_ucontext      ib_uctx;\n\tstruct bnxt_re_dev\t*rdev;\n\tstruct bnxt_qplib_dpi\tdpi;\n\tstruct bnxt_qplib_dpi   wcdpi;\n\tvoid\t\t\t*shpg;\n\tspinlock_t\t\tsh_lock;\t \n\tstruct rdma_user_mmap_entry *shpage_mmap;\n};\n\nenum bnxt_re_mmap_flag {\n\tBNXT_RE_MMAP_SH_PAGE,\n\tBNXT_RE_MMAP_UC_DB,\n\tBNXT_RE_MMAP_WC_DB,\n\tBNXT_RE_MMAP_DBR_PAGE,\n\tBNXT_RE_MMAP_DBR_BAR,\n};\n\nstruct bnxt_re_user_mmap_entry {\n\tstruct rdma_user_mmap_entry rdma_entry;\n\tstruct bnxt_re_ucontext *uctx;\n\tu64 mem_offset;\n\tu8 mmap_flag;\n};\n\nstatic inline u16 bnxt_re_get_swqe_size(int nsge)\n{\n\treturn sizeof(struct sq_send_hdr) + nsge * sizeof(struct sq_sge);\n}\n\nstatic inline u16 bnxt_re_get_rwqe_size(int nsge)\n{\n\treturn sizeof(struct rq_wqe_hdr) + (nsge * sizeof(struct sq_sge));\n}\n\nint bnxt_re_query_device(struct ib_device *ibdev,\n\t\t\t struct ib_device_attr *ib_attr,\n\t\t\t struct ib_udata *udata);\nint bnxt_re_query_port(struct ib_device *ibdev, u32 port_num,\n\t\t       struct ib_port_attr *port_attr);\nint bnxt_re_get_port_immutable(struct ib_device *ibdev, u32 port_num,\n\t\t\t       struct ib_port_immutable *immutable);\nvoid bnxt_re_query_fw_str(struct ib_device *ibdev, char *str);\nint bnxt_re_query_pkey(struct ib_device *ibdev, u32 port_num,\n\t\t       u16 index, u16 *pkey);\nint bnxt_re_del_gid(const struct ib_gid_attr *attr, void **context);\nint bnxt_re_add_gid(const struct ib_gid_attr *attr, void **context);\nint bnxt_re_query_gid(struct ib_device *ibdev, u32 port_num,\n\t\t      int index, union ib_gid *gid);\nenum rdma_link_layer bnxt_re_get_link_layer(struct ib_device *ibdev,\n\t\t\t\t\t    u32 port_num);\nint bnxt_re_alloc_pd(struct ib_pd *pd, struct ib_udata *udata);\nint bnxt_re_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata);\nint bnxt_re_create_ah(struct ib_ah *ah, struct rdma_ah_init_attr *init_attr,\n\t\t      struct ib_udata *udata);\nint bnxt_re_query_ah(struct ib_ah *ah, struct rdma_ah_attr *ah_attr);\nint bnxt_re_destroy_ah(struct ib_ah *ah, u32 flags);\nint bnxt_re_create_srq(struct ib_srq *srq,\n\t\t       struct ib_srq_init_attr *srq_init_attr,\n\t\t       struct ib_udata *udata);\nint bnxt_re_modify_srq(struct ib_srq *srq, struct ib_srq_attr *srq_attr,\n\t\t       enum ib_srq_attr_mask srq_attr_mask,\n\t\t       struct ib_udata *udata);\nint bnxt_re_query_srq(struct ib_srq *srq, struct ib_srq_attr *srq_attr);\nint bnxt_re_destroy_srq(struct ib_srq *srq, struct ib_udata *udata);\nint bnxt_re_post_srq_recv(struct ib_srq *srq, const struct ib_recv_wr *recv_wr,\n\t\t\t  const struct ib_recv_wr **bad_recv_wr);\nint bnxt_re_create_qp(struct ib_qp *qp, struct ib_qp_init_attr *qp_init_attr,\n\t\t      struct ib_udata *udata);\nint bnxt_re_modify_qp(struct ib_qp *qp, struct ib_qp_attr *qp_attr,\n\t\t      int qp_attr_mask, struct ib_udata *udata);\nint bnxt_re_query_qp(struct ib_qp *qp, struct ib_qp_attr *qp_attr,\n\t\t     int qp_attr_mask, struct ib_qp_init_attr *qp_init_attr);\nint bnxt_re_destroy_qp(struct ib_qp *qp, struct ib_udata *udata);\nint bnxt_re_post_send(struct ib_qp *qp, const struct ib_send_wr *send_wr,\n\t\t      const struct ib_send_wr **bad_send_wr);\nint bnxt_re_post_recv(struct ib_qp *qp, const struct ib_recv_wr *recv_wr,\n\t\t      const struct ib_recv_wr **bad_recv_wr);\nint bnxt_re_create_cq(struct ib_cq *ibcq, const struct ib_cq_init_attr *attr,\n\t\t      struct ib_udata *udata);\nint bnxt_re_resize_cq(struct ib_cq *ibcq, int cqe, struct ib_udata *udata);\nint bnxt_re_destroy_cq(struct ib_cq *cq, struct ib_udata *udata);\nint bnxt_re_poll_cq(struct ib_cq *cq, int num_entries, struct ib_wc *wc);\nint bnxt_re_req_notify_cq(struct ib_cq *cq, enum ib_cq_notify_flags flags);\nstruct ib_mr *bnxt_re_get_dma_mr(struct ib_pd *pd, int mr_access_flags);\n\nint bnxt_re_map_mr_sg(struct ib_mr *ib_mr, struct scatterlist *sg, int sg_nents,\n\t\t      unsigned int *sg_offset);\nstruct ib_mr *bnxt_re_alloc_mr(struct ib_pd *ib_pd, enum ib_mr_type mr_type,\n\t\t\t       u32 max_num_sg);\nint bnxt_re_dereg_mr(struct ib_mr *mr, struct ib_udata *udata);\nstruct ib_mw *bnxt_re_alloc_mw(struct ib_pd *ib_pd, enum ib_mw_type type,\n\t\t\t       struct ib_udata *udata);\nint bnxt_re_dealloc_mw(struct ib_mw *mw);\nstruct ib_mr *bnxt_re_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,\n\t\t\t\t  u64 virt_addr, int mr_access_flags,\n\t\t\t\t  struct ib_udata *udata);\nstruct ib_mr *bnxt_re_reg_user_mr_dmabuf(struct ib_pd *ib_pd, u64 start,\n\t\t\t\t\t u64 length, u64 virt_addr,\n\t\t\t\t\t int fd, int mr_access_flags,\n\t\t\t\t\t struct ib_udata *udata);\nint bnxt_re_alloc_ucontext(struct ib_ucontext *ctx, struct ib_udata *udata);\nvoid bnxt_re_dealloc_ucontext(struct ib_ucontext *context);\nint bnxt_re_mmap(struct ib_ucontext *context, struct vm_area_struct *vma);\nvoid bnxt_re_mmap_free(struct rdma_user_mmap_entry *rdma_entry);\n\n\nunsigned long bnxt_re_lock_cqs(struct bnxt_re_qp *qp);\nvoid bnxt_re_unlock_cqs(struct bnxt_re_qp *qp, unsigned long flags);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}