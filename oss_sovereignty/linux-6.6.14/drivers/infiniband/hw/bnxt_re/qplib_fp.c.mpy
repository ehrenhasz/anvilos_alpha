{
  "module_name": "qplib_fp.c",
  "hash_id": "10aa5b9e8737e1657d116aa25f36690e2644e7a804ac405738f2b3fa714b473d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/bnxt_re/qplib_fp.c",
  "human_readable_source": " \n\n#define dev_fmt(fmt) \"QPLIB: \" fmt\n\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/pci.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <linux/if_ether.h>\n#include <rdma/ib_mad.h>\n\n#include \"roce_hsi.h\"\n\n#include \"qplib_res.h\"\n#include \"qplib_rcfw.h\"\n#include \"qplib_sp.h\"\n#include \"qplib_fp.h\"\n\nstatic void __clean_cq(struct bnxt_qplib_cq *cq, u64 qp);\n\nstatic void bnxt_qplib_cancel_phantom_processing(struct bnxt_qplib_qp *qp)\n{\n\tqp->sq.condition = false;\n\tqp->sq.send_phantom = false;\n\tqp->sq.single = false;\n}\n\n \nstatic void __bnxt_qplib_add_flush_qp(struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_cq *scq, *rcq;\n\n\tscq = qp->scq;\n\trcq = qp->rcq;\n\n\tif (!qp->sq.flushed) {\n\t\tdev_dbg(&scq->hwq.pdev->dev,\n\t\t\t\"FP: Adding to SQ Flush list = %p\\n\", qp);\n\t\tbnxt_qplib_cancel_phantom_processing(qp);\n\t\tlist_add_tail(&qp->sq_flush, &scq->sqf_head);\n\t\tqp->sq.flushed = true;\n\t}\n\tif (!qp->srq) {\n\t\tif (!qp->rq.flushed) {\n\t\t\tdev_dbg(&rcq->hwq.pdev->dev,\n\t\t\t\t\"FP: Adding to RQ Flush list = %p\\n\", qp);\n\t\t\tlist_add_tail(&qp->rq_flush, &rcq->rqf_head);\n\t\t\tqp->rq.flushed = true;\n\t\t}\n\t}\n}\n\nstatic void bnxt_qplib_acquire_cq_flush_locks(struct bnxt_qplib_qp *qp,\n\t\t\t\t       unsigned long *flags)\n\t__acquires(&qp->scq->flush_lock) __acquires(&qp->rcq->flush_lock)\n{\n\tspin_lock_irqsave(&qp->scq->flush_lock, *flags);\n\tif (qp->scq == qp->rcq)\n\t\t__acquire(&qp->rcq->flush_lock);\n\telse\n\t\tspin_lock(&qp->rcq->flush_lock);\n}\n\nstatic void bnxt_qplib_release_cq_flush_locks(struct bnxt_qplib_qp *qp,\n\t\t\t\t       unsigned long *flags)\n\t__releases(&qp->scq->flush_lock) __releases(&qp->rcq->flush_lock)\n{\n\tif (qp->scq == qp->rcq)\n\t\t__release(&qp->rcq->flush_lock);\n\telse\n\t\tspin_unlock(&qp->rcq->flush_lock);\n\tspin_unlock_irqrestore(&qp->scq->flush_lock, *flags);\n}\n\nvoid bnxt_qplib_add_flush_qp(struct bnxt_qplib_qp *qp)\n{\n\tunsigned long flags;\n\n\tbnxt_qplib_acquire_cq_flush_locks(qp, &flags);\n\t__bnxt_qplib_add_flush_qp(qp);\n\tbnxt_qplib_release_cq_flush_locks(qp, &flags);\n}\n\nstatic void __bnxt_qplib_del_flush_qp(struct bnxt_qplib_qp *qp)\n{\n\tif (qp->sq.flushed) {\n\t\tqp->sq.flushed = false;\n\t\tlist_del(&qp->sq_flush);\n\t}\n\tif (!qp->srq) {\n\t\tif (qp->rq.flushed) {\n\t\t\tqp->rq.flushed = false;\n\t\t\tlist_del(&qp->rq_flush);\n\t\t}\n\t}\n}\n\nvoid bnxt_qplib_clean_qp(struct bnxt_qplib_qp *qp)\n{\n\tunsigned long flags;\n\n\tbnxt_qplib_acquire_cq_flush_locks(qp, &flags);\n\t__clean_cq(qp->scq, (u64)(unsigned long)qp);\n\tqp->sq.hwq.prod = 0;\n\tqp->sq.hwq.cons = 0;\n\t__clean_cq(qp->rcq, (u64)(unsigned long)qp);\n\tqp->rq.hwq.prod = 0;\n\tqp->rq.hwq.cons = 0;\n\n\t__bnxt_qplib_del_flush_qp(qp);\n\tbnxt_qplib_release_cq_flush_locks(qp, &flags);\n}\n\nstatic void bnxt_qpn_cqn_sched_task(struct work_struct *work)\n{\n\tstruct bnxt_qplib_nq_work *nq_work =\n\t\t\tcontainer_of(work, struct bnxt_qplib_nq_work, work);\n\n\tstruct bnxt_qplib_cq *cq = nq_work->cq;\n\tstruct bnxt_qplib_nq *nq = nq_work->nq;\n\n\tif (cq && nq) {\n\t\tspin_lock_bh(&cq->compl_lock);\n\t\tif (atomic_read(&cq->arm_state) && nq->cqn_handler) {\n\t\t\tdev_dbg(&nq->pdev->dev,\n\t\t\t\t\"%s:Trigger cq  = %p event nq = %p\\n\",\n\t\t\t\t__func__, cq, nq);\n\t\t\tnq->cqn_handler(nq, cq);\n\t\t}\n\t\tspin_unlock_bh(&cq->compl_lock);\n\t}\n\tkfree(nq_work);\n}\n\nstatic void bnxt_qplib_free_qp_hdr_buf(struct bnxt_qplib_res *res,\n\t\t\t\t       struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\n\tif (qp->rq_hdr_buf)\n\t\tdma_free_coherent(&res->pdev->dev,\n\t\t\t\t  rq->max_wqe * qp->rq_hdr_buf_size,\n\t\t\t\t  qp->rq_hdr_buf, qp->rq_hdr_buf_map);\n\tif (qp->sq_hdr_buf)\n\t\tdma_free_coherent(&res->pdev->dev,\n\t\t\t\t  sq->max_wqe * qp->sq_hdr_buf_size,\n\t\t\t\t  qp->sq_hdr_buf, qp->sq_hdr_buf_map);\n\tqp->rq_hdr_buf = NULL;\n\tqp->sq_hdr_buf = NULL;\n\tqp->rq_hdr_buf_map = 0;\n\tqp->sq_hdr_buf_map = 0;\n\tqp->sq_hdr_buf_size = 0;\n\tqp->rq_hdr_buf_size = 0;\n}\n\nstatic int bnxt_qplib_alloc_qp_hdr_buf(struct bnxt_qplib_res *res,\n\t\t\t\t       struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\tint rc = 0;\n\n\tif (qp->sq_hdr_buf_size && sq->max_wqe) {\n\t\tqp->sq_hdr_buf = dma_alloc_coherent(&res->pdev->dev,\n\t\t\t\t\tsq->max_wqe * qp->sq_hdr_buf_size,\n\t\t\t\t\t&qp->sq_hdr_buf_map, GFP_KERNEL);\n\t\tif (!qp->sq_hdr_buf) {\n\t\t\trc = -ENOMEM;\n\t\t\tdev_err(&res->pdev->dev,\n\t\t\t\t\"Failed to create sq_hdr_buf\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tif (qp->rq_hdr_buf_size && rq->max_wqe) {\n\t\tqp->rq_hdr_buf = dma_alloc_coherent(&res->pdev->dev,\n\t\t\t\t\t\t    rq->max_wqe *\n\t\t\t\t\t\t    qp->rq_hdr_buf_size,\n\t\t\t\t\t\t    &qp->rq_hdr_buf_map,\n\t\t\t\t\t\t    GFP_KERNEL);\n\t\tif (!qp->rq_hdr_buf) {\n\t\t\trc = -ENOMEM;\n\t\t\tdev_err(&res->pdev->dev,\n\t\t\t\t\"Failed to create rq_hdr_buf\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\treturn 0;\n\nfail:\n\tbnxt_qplib_free_qp_hdr_buf(res, qp);\n\treturn rc;\n}\n\nstatic void clean_nq(struct bnxt_qplib_nq *nq, struct bnxt_qplib_cq *cq)\n{\n\tstruct bnxt_qplib_hwq *hwq = &nq->hwq;\n\tstruct nq_base *nqe, **nq_ptr;\n\tint budget = nq->budget;\n\tu32 sw_cons, raw_cons;\n\tuintptr_t q_handle;\n\tu16 type;\n\n\tspin_lock_bh(&hwq->lock);\n\t \n\traw_cons = hwq->cons;\n\twhile (budget--) {\n\t\tsw_cons = HWQ_CMP(raw_cons, hwq);\n\t\tnq_ptr = (struct nq_base **)hwq->pbl_ptr;\n\t\tnqe = &nq_ptr[NQE_PG(sw_cons)][NQE_IDX(sw_cons)];\n\t\tif (!NQE_CMP_VALID(nqe, raw_cons, hwq->max_elements))\n\t\t\tbreak;\n\n\t\t \n\t\tdma_rmb();\n\n\t\ttype = le16_to_cpu(nqe->info10_type) & NQ_BASE_TYPE_MASK;\n\t\tswitch (type) {\n\t\tcase NQ_BASE_TYPE_CQ_NOTIFICATION:\n\t\t{\n\t\t\tstruct nq_cn *nqcne = (struct nq_cn *)nqe;\n\n\t\t\tq_handle = le32_to_cpu(nqcne->cq_handle_low);\n\t\t\tq_handle |= (u64)le32_to_cpu(nqcne->cq_handle_high)\n\t\t\t\t\t\t     << 32;\n\t\t\tif ((unsigned long)cq == q_handle) {\n\t\t\t\tnqcne->cq_handle_low = 0;\n\t\t\t\tnqcne->cq_handle_high = 0;\n\t\t\t\tcq->cnq_events++;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\traw_cons++;\n\t}\n\tspin_unlock_bh(&hwq->lock);\n}\n\n \nstatic void __wait_for_all_nqes(struct bnxt_qplib_cq *cq, u16 cnq_events)\n{\n\tu32 retry_cnt = 100;\n\n\twhile (retry_cnt--) {\n\t\tif (cnq_events == cq->cnq_events)\n\t\t\treturn;\n\t\tusleep_range(50, 100);\n\t\tclean_nq(cq->nq, cq);\n\t}\n}\n\nstatic void bnxt_qplib_service_nq(struct tasklet_struct *t)\n{\n\tstruct bnxt_qplib_nq *nq = from_tasklet(nq, t, nq_tasklet);\n\tstruct bnxt_qplib_hwq *hwq = &nq->hwq;\n\tstruct bnxt_qplib_cq *cq;\n\tint budget = nq->budget;\n\tu32 sw_cons, raw_cons;\n\tstruct nq_base *nqe;\n\tuintptr_t q_handle;\n\tu16 type;\n\n\tspin_lock_bh(&hwq->lock);\n\t \n\traw_cons = hwq->cons;\n\twhile (budget--) {\n\t\tsw_cons = HWQ_CMP(raw_cons, hwq);\n\t\tnqe = bnxt_qplib_get_qe(hwq, sw_cons, NULL);\n\t\tif (!NQE_CMP_VALID(nqe, raw_cons, hwq->max_elements))\n\t\t\tbreak;\n\n\t\t \n\t\tdma_rmb();\n\n\t\ttype = le16_to_cpu(nqe->info10_type) & NQ_BASE_TYPE_MASK;\n\t\tswitch (type) {\n\t\tcase NQ_BASE_TYPE_CQ_NOTIFICATION:\n\t\t{\n\t\t\tstruct nq_cn *nqcne = (struct nq_cn *)nqe;\n\n\t\t\tq_handle = le32_to_cpu(nqcne->cq_handle_low);\n\t\t\tq_handle |= (u64)le32_to_cpu(nqcne->cq_handle_high)\n\t\t\t\t\t\t     << 32;\n\t\t\tcq = (struct bnxt_qplib_cq *)(unsigned long)q_handle;\n\t\t\tif (!cq)\n\t\t\t\tbreak;\n\t\t\tbnxt_qplib_armen_db(&cq->dbinfo,\n\t\t\t\t\t    DBC_DBC_TYPE_CQ_ARMENA);\n\t\t\tspin_lock_bh(&cq->compl_lock);\n\t\t\tatomic_set(&cq->arm_state, 0);\n\t\t\tif (nq->cqn_handler(nq, (cq)))\n\t\t\t\tdev_warn(&nq->pdev->dev,\n\t\t\t\t\t \"cqn - type 0x%x not handled\\n\", type);\n\t\t\tcq->cnq_events++;\n\t\t\tspin_unlock_bh(&cq->compl_lock);\n\t\t\tbreak;\n\t\t}\n\t\tcase NQ_BASE_TYPE_SRQ_EVENT:\n\t\t{\n\t\t\tstruct bnxt_qplib_srq *srq;\n\t\t\tstruct nq_srq_event *nqsrqe =\n\t\t\t\t\t\t(struct nq_srq_event *)nqe;\n\n\t\t\tq_handle = le32_to_cpu(nqsrqe->srq_handle_low);\n\t\t\tq_handle |= (u64)le32_to_cpu(nqsrqe->srq_handle_high)\n\t\t\t\t     << 32;\n\t\t\tsrq = (struct bnxt_qplib_srq *)q_handle;\n\t\t\tbnxt_qplib_armen_db(&srq->dbinfo,\n\t\t\t\t\t    DBC_DBC_TYPE_SRQ_ARMENA);\n\t\t\tif (nq->srqn_handler(nq,\n\t\t\t\t\t     (struct bnxt_qplib_srq *)q_handle,\n\t\t\t\t\t     nqsrqe->event))\n\t\t\t\tdev_warn(&nq->pdev->dev,\n\t\t\t\t\t \"SRQ event 0x%x not handled\\n\",\n\t\t\t\t\t nqsrqe->event);\n\t\t\tbreak;\n\t\t}\n\t\tcase NQ_BASE_TYPE_DBQ_EVENT:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_warn(&nq->pdev->dev,\n\t\t\t\t \"nqe with type = 0x%x not handled\\n\", type);\n\t\t\tbreak;\n\t\t}\n\t\traw_cons++;\n\t}\n\tif (hwq->cons != raw_cons) {\n\t\thwq->cons = raw_cons;\n\t\tbnxt_qplib_ring_nq_db(&nq->nq_db.dbinfo, nq->res->cctx, true);\n\t}\n\tspin_unlock_bh(&hwq->lock);\n}\n\n \n\nvoid bnxt_re_synchronize_nq(struct bnxt_qplib_nq *nq)\n{\n\tint budget = nq->budget;\n\n\tnq->budget = nq->hwq.max_elements;\n\tbnxt_qplib_service_nq(&nq->nq_tasklet);\n\tnq->budget = budget;\n}\n\nstatic irqreturn_t bnxt_qplib_nq_irq(int irq, void *dev_instance)\n{\n\tstruct bnxt_qplib_nq *nq = dev_instance;\n\tstruct bnxt_qplib_hwq *hwq = &nq->hwq;\n\tu32 sw_cons;\n\n\t \n\tsw_cons = HWQ_CMP(hwq->cons, hwq);\n\tprefetch(bnxt_qplib_get_qe(hwq, sw_cons, NULL));\n\n\t \n\ttasklet_schedule(&nq->nq_tasklet);\n\n\treturn IRQ_HANDLED;\n}\n\nvoid bnxt_qplib_nq_stop_irq(struct bnxt_qplib_nq *nq, bool kill)\n{\n\tif (!nq->requested)\n\t\treturn;\n\n\tnq->requested = false;\n\t \n\tbnxt_qplib_ring_nq_db(&nq->nq_db.dbinfo, nq->res->cctx, false);\n\t \n\tsynchronize_irq(nq->msix_vec);\n\tirq_set_affinity_hint(nq->msix_vec, NULL);\n\tfree_irq(nq->msix_vec, nq);\n\tkfree(nq->name);\n\tnq->name = NULL;\n\n\tif (kill)\n\t\ttasklet_kill(&nq->nq_tasklet);\n\ttasklet_disable(&nq->nq_tasklet);\n}\n\nvoid bnxt_qplib_disable_nq(struct bnxt_qplib_nq *nq)\n{\n\tif (nq->cqn_wq) {\n\t\tdestroy_workqueue(nq->cqn_wq);\n\t\tnq->cqn_wq = NULL;\n\t}\n\n\t \n\tbnxt_qplib_nq_stop_irq(nq, true);\n\n\tif (nq->nq_db.reg.bar_reg) {\n\t\tiounmap(nq->nq_db.reg.bar_reg);\n\t\tnq->nq_db.reg.bar_reg = NULL;\n\t}\n\n\tnq->cqn_handler = NULL;\n\tnq->srqn_handler = NULL;\n\tnq->msix_vec = 0;\n}\n\nint bnxt_qplib_nq_start_irq(struct bnxt_qplib_nq *nq, int nq_indx,\n\t\t\t    int msix_vector, bool need_init)\n{\n\tstruct bnxt_qplib_res *res = nq->res;\n\tint rc;\n\n\tif (nq->requested)\n\t\treturn -EFAULT;\n\n\tnq->msix_vec = msix_vector;\n\tif (need_init)\n\t\ttasklet_setup(&nq->nq_tasklet, bnxt_qplib_service_nq);\n\telse\n\t\ttasklet_enable(&nq->nq_tasklet);\n\n\tnq->name = kasprintf(GFP_KERNEL, \"bnxt_re-nq-%d@pci:%s\",\n\t\t\t     nq_indx, pci_name(res->pdev));\n\tif (!nq->name)\n\t\treturn -ENOMEM;\n\trc = request_irq(nq->msix_vec, bnxt_qplib_nq_irq, 0, nq->name, nq);\n\tif (rc) {\n\t\tkfree(nq->name);\n\t\tnq->name = NULL;\n\t\ttasklet_disable(&nq->nq_tasklet);\n\t\treturn rc;\n\t}\n\n\tcpumask_clear(&nq->mask);\n\tcpumask_set_cpu(nq_indx, &nq->mask);\n\trc = irq_set_affinity_hint(nq->msix_vec, &nq->mask);\n\tif (rc) {\n\t\tdev_warn(&nq->pdev->dev,\n\t\t\t \"set affinity failed; vector: %d nq_idx: %d\\n\",\n\t\t\t nq->msix_vec, nq_indx);\n\t}\n\tnq->requested = true;\n\tbnxt_qplib_ring_nq_db(&nq->nq_db.dbinfo, res->cctx, true);\n\n\treturn rc;\n}\n\nstatic int bnxt_qplib_map_nq_db(struct bnxt_qplib_nq *nq,  u32 reg_offt)\n{\n\tresource_size_t reg_base;\n\tstruct bnxt_qplib_nq_db *nq_db;\n\tstruct pci_dev *pdev;\n\n\tpdev = nq->pdev;\n\tnq_db = &nq->nq_db;\n\n\tnq_db->reg.bar_id = NQ_CONS_PCI_BAR_REGION;\n\tnq_db->reg.bar_base = pci_resource_start(pdev, nq_db->reg.bar_id);\n\tif (!nq_db->reg.bar_base) {\n\t\tdev_err(&pdev->dev, \"QPLIB: NQ BAR region %d resc start is 0!\",\n\t\t\tnq_db->reg.bar_id);\n\t\treturn -ENOMEM;\n\t}\n\n\treg_base = nq_db->reg.bar_base + reg_offt;\n\t \n\tnq_db->reg.len = 8;\n\tnq_db->reg.bar_reg = ioremap(reg_base, nq_db->reg.len);\n\tif (!nq_db->reg.bar_reg) {\n\t\tdev_err(&pdev->dev, \"QPLIB: NQ BAR region %d mapping failed\",\n\t\t\tnq_db->reg.bar_id);\n\t\treturn -ENOMEM;\n\t}\n\n\tnq_db->dbinfo.db = nq_db->reg.bar_reg;\n\tnq_db->dbinfo.hwq = &nq->hwq;\n\tnq_db->dbinfo.xid = nq->ring_id;\n\n\treturn 0;\n}\n\nint bnxt_qplib_enable_nq(struct pci_dev *pdev, struct bnxt_qplib_nq *nq,\n\t\t\t int nq_idx, int msix_vector, int bar_reg_offset,\n\t\t\t cqn_handler_t cqn_handler,\n\t\t\t srqn_handler_t srqn_handler)\n{\n\tint rc;\n\n\tnq->pdev = pdev;\n\tnq->cqn_handler = cqn_handler;\n\tnq->srqn_handler = srqn_handler;\n\n\t \n\tnq->cqn_wq  = create_singlethread_workqueue(\"bnxt_qplib_nq\");\n\tif (!nq->cqn_wq)\n\t\treturn -ENOMEM;\n\n\trc = bnxt_qplib_map_nq_db(nq, bar_reg_offset);\n\tif (rc)\n\t\tgoto fail;\n\n\trc = bnxt_qplib_nq_start_irq(nq, nq_idx, msix_vector, true);\n\tif (rc) {\n\t\tdev_err(&nq->pdev->dev,\n\t\t\t\"Failed to request irq for nq-idx %d\\n\", nq_idx);\n\t\tgoto fail;\n\t}\n\n\treturn 0;\nfail:\n\tbnxt_qplib_disable_nq(nq);\n\treturn rc;\n}\n\nvoid bnxt_qplib_free_nq(struct bnxt_qplib_nq *nq)\n{\n\tif (nq->hwq.max_elements) {\n\t\tbnxt_qplib_free_hwq(nq->res, &nq->hwq);\n\t\tnq->hwq.max_elements = 0;\n\t}\n}\n\nint bnxt_qplib_alloc_nq(struct bnxt_qplib_res *res, struct bnxt_qplib_nq *nq)\n{\n\tstruct bnxt_qplib_hwq_attr hwq_attr = {};\n\tstruct bnxt_qplib_sg_info sginfo = {};\n\n\tnq->pdev = res->pdev;\n\tnq->res = res;\n\tif (!nq->hwq.max_elements ||\n\t    nq->hwq.max_elements > BNXT_QPLIB_NQE_MAX_CNT)\n\t\tnq->hwq.max_elements = BNXT_QPLIB_NQE_MAX_CNT;\n\n\tsginfo.pgsize = PAGE_SIZE;\n\tsginfo.pgshft = PAGE_SHIFT;\n\thwq_attr.res = res;\n\thwq_attr.sginfo = &sginfo;\n\thwq_attr.depth = nq->hwq.max_elements;\n\thwq_attr.stride = sizeof(struct nq_base);\n\thwq_attr.type = bnxt_qplib_get_hwq_type(nq->res);\n\tif (bnxt_qplib_alloc_init_hwq(&nq->hwq, &hwq_attr)) {\n\t\tdev_err(&nq->pdev->dev, \"FP NQ allocation failed\");\n\t\treturn -ENOMEM;\n\t}\n\tnq->budget = 8;\n\treturn 0;\n}\n\n \nvoid bnxt_qplib_destroy_srq(struct bnxt_qplib_res *res,\n\t\t\t   struct bnxt_qplib_srq *srq)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_destroy_srq_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct cmdq_destroy_srq req = {};\n\tint rc;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_DESTROY_SRQ,\n\t\t\t\t sizeof(req));\n\n\t \n\treq.srq_cid = cpu_to_le32(srq->id);\n\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req), sizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tkfree(srq->swq);\n\tif (rc)\n\t\treturn;\n\tbnxt_qplib_free_hwq(res, &srq->hwq);\n}\n\nint bnxt_qplib_create_srq(struct bnxt_qplib_res *res,\n\t\t\t  struct bnxt_qplib_srq *srq)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct bnxt_qplib_hwq_attr hwq_attr = {};\n\tstruct creq_create_srq_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct cmdq_create_srq req = {};\n\tstruct bnxt_qplib_pbl *pbl;\n\tu16 pg_sz_lvl;\n\tint rc, idx;\n\n\thwq_attr.res = res;\n\thwq_attr.sginfo = &srq->sg_info;\n\thwq_attr.depth = srq->max_wqe;\n\thwq_attr.stride = srq->wqe_size;\n\thwq_attr.type = HWQ_TYPE_QUEUE;\n\trc = bnxt_qplib_alloc_init_hwq(&srq->hwq, &hwq_attr);\n\tif (rc)\n\t\treturn rc;\n\n\tsrq->swq = kcalloc(srq->hwq.max_elements, sizeof(*srq->swq),\n\t\t\t   GFP_KERNEL);\n\tif (!srq->swq) {\n\t\trc = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_CREATE_SRQ,\n\t\t\t\t sizeof(req));\n\n\t \n\treq.dpi = cpu_to_le32(srq->dpi->dpi);\n\treq.srq_handle = cpu_to_le64((uintptr_t)srq);\n\n\treq.srq_size = cpu_to_le16((u16)srq->hwq.max_elements);\n\tpbl = &srq->hwq.pbl[PBL_LVL_0];\n\tpg_sz_lvl = ((u16)bnxt_qplib_base_pg_size(&srq->hwq) <<\n\t\t     CMDQ_CREATE_SRQ_PG_SIZE_SFT);\n\tpg_sz_lvl |= (srq->hwq.level & CMDQ_CREATE_SRQ_LVL_MASK) <<\n\t\t      CMDQ_CREATE_SRQ_LVL_SFT;\n\treq.pg_size_lvl = cpu_to_le16(pg_sz_lvl);\n\treq.pbl = cpu_to_le64(pbl->pg_map_arr[0]);\n\treq.pd_id = cpu_to_le32(srq->pd->id);\n\treq.eventq_id = cpu_to_le16(srq->eventq_hw_ring_id);\n\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req), sizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc)\n\t\tgoto fail;\n\n\tspin_lock_init(&srq->lock);\n\tsrq->start_idx = 0;\n\tsrq->last_idx = srq->hwq.max_elements - 1;\n\tfor (idx = 0; idx < srq->hwq.max_elements; idx++)\n\t\tsrq->swq[idx].next_idx = idx + 1;\n\tsrq->swq[srq->last_idx].next_idx = -1;\n\n\tsrq->id = le32_to_cpu(resp.xid);\n\tsrq->dbinfo.hwq = &srq->hwq;\n\tsrq->dbinfo.xid = srq->id;\n\tsrq->dbinfo.db = srq->dpi->dbr;\n\tsrq->dbinfo.max_slot = 1;\n\tsrq->dbinfo.priv_db = res->dpi_tbl.priv_db;\n\tif (srq->threshold)\n\t\tbnxt_qplib_armen_db(&srq->dbinfo, DBC_DBC_TYPE_SRQ_ARMENA);\n\tsrq->arm_req = false;\n\n\treturn 0;\nfail:\n\tbnxt_qplib_free_hwq(res, &srq->hwq);\n\tkfree(srq->swq);\n\n\treturn rc;\n}\n\nint bnxt_qplib_modify_srq(struct bnxt_qplib_res *res,\n\t\t\t  struct bnxt_qplib_srq *srq)\n{\n\tstruct bnxt_qplib_hwq *srq_hwq = &srq->hwq;\n\tu32 sw_prod, sw_cons, count = 0;\n\n\tsw_prod = HWQ_CMP(srq_hwq->prod, srq_hwq);\n\tsw_cons = HWQ_CMP(srq_hwq->cons, srq_hwq);\n\n\tcount = sw_prod > sw_cons ? sw_prod - sw_cons :\n\t\t\t\t    srq_hwq->max_elements - sw_cons + sw_prod;\n\tif (count > srq->threshold) {\n\t\tsrq->arm_req = false;\n\t\tbnxt_qplib_srq_arm_db(&srq->dbinfo, srq->threshold);\n\t} else {\n\t\t \n\t\tsrq->arm_req = true;\n\t}\n\n\treturn 0;\n}\n\nint bnxt_qplib_query_srq(struct bnxt_qplib_res *res,\n\t\t\t struct bnxt_qplib_srq *srq)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_query_srq_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct bnxt_qplib_rcfw_sbuf sbuf;\n\tstruct creq_query_srq_resp_sb *sb;\n\tstruct cmdq_query_srq req = {};\n\tint rc;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_QUERY_SRQ,\n\t\t\t\t sizeof(req));\n\n\t \n\tsbuf.size = ALIGN(sizeof(*sb), BNXT_QPLIB_CMDQE_UNITS);\n\tsbuf.sb = dma_alloc_coherent(&rcfw->pdev->dev, sbuf.size,\n\t\t\t\t     &sbuf.dma_addr, GFP_KERNEL);\n\tif (!sbuf.sb)\n\t\treturn -ENOMEM;\n\treq.resp_size = sbuf.size / BNXT_QPLIB_CMDQE_UNITS;\n\treq.srq_cid = cpu_to_le32(srq->id);\n\tsb = sbuf.sb;\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, &sbuf, sizeof(req),\n\t\t\t\tsizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tsrq->threshold = le16_to_cpu(sb->srq_limit);\n\tdma_free_coherent(&rcfw->pdev->dev, sbuf.size,\n\t\t\t  sbuf.sb, sbuf.dma_addr);\n\n\treturn rc;\n}\n\nint bnxt_qplib_post_srq_recv(struct bnxt_qplib_srq *srq,\n\t\t\t     struct bnxt_qplib_swqe *wqe)\n{\n\tstruct bnxt_qplib_hwq *srq_hwq = &srq->hwq;\n\tstruct rq_wqe *srqe;\n\tstruct sq_sge *hw_sge;\n\tu32 sw_prod, sw_cons, count = 0;\n\tint i, next;\n\n\tspin_lock(&srq_hwq->lock);\n\tif (srq->start_idx == srq->last_idx) {\n\t\tdev_err(&srq_hwq->pdev->dev,\n\t\t\t\"FP: SRQ (0x%x) is full!\\n\", srq->id);\n\t\tspin_unlock(&srq_hwq->lock);\n\t\treturn -EINVAL;\n\t}\n\tnext = srq->start_idx;\n\tsrq->start_idx = srq->swq[next].next_idx;\n\tspin_unlock(&srq_hwq->lock);\n\n\tsw_prod = HWQ_CMP(srq_hwq->prod, srq_hwq);\n\tsrqe = bnxt_qplib_get_qe(srq_hwq, sw_prod, NULL);\n\tmemset(srqe, 0, srq->wqe_size);\n\t \n\tfor (i = 0, hw_sge = (struct sq_sge *)srqe->data;\n\t     i < wqe->num_sge; i++, hw_sge++) {\n\t\thw_sge->va_or_pa = cpu_to_le64(wqe->sg_list[i].addr);\n\t\thw_sge->l_key = cpu_to_le32(wqe->sg_list[i].lkey);\n\t\thw_sge->size = cpu_to_le32(wqe->sg_list[i].size);\n\t}\n\tsrqe->wqe_type = wqe->type;\n\tsrqe->flags = wqe->flags;\n\tsrqe->wqe_size = wqe->num_sge +\n\t\t\t((offsetof(typeof(*srqe), data) + 15) >> 4);\n\tsrqe->wr_id[0] = cpu_to_le32((u32)next);\n\tsrq->swq[next].wr_id = wqe->wr_id;\n\n\tsrq_hwq->prod++;\n\n\tspin_lock(&srq_hwq->lock);\n\tsw_prod = HWQ_CMP(srq_hwq->prod, srq_hwq);\n\t \n\tsw_cons = HWQ_CMP(srq_hwq->cons, srq_hwq);\n\tcount = sw_prod > sw_cons ? sw_prod - sw_cons :\n\t\t\t\t    srq_hwq->max_elements - sw_cons + sw_prod;\n\tspin_unlock(&srq_hwq->lock);\n\t \n\tbnxt_qplib_ring_prod_db(&srq->dbinfo, DBC_DBC_TYPE_SRQ);\n\tif (srq->arm_req == true && count > srq->threshold) {\n\t\tsrq->arm_req = false;\n\t\tbnxt_qplib_srq_arm_db(&srq->dbinfo, srq->threshold);\n\t}\n\n\treturn 0;\n}\n\n \n\nstatic int bnxt_qplib_alloc_init_swq(struct bnxt_qplib_q *que)\n{\n\tint indx;\n\n\tque->swq = kcalloc(que->max_wqe, sizeof(*que->swq), GFP_KERNEL);\n\tif (!que->swq)\n\t\treturn -ENOMEM;\n\n\tque->swq_start = 0;\n\tque->swq_last = que->max_wqe - 1;\n\tfor (indx = 0; indx < que->max_wqe; indx++)\n\t\tque->swq[indx].next_idx = indx + 1;\n\tque->swq[que->swq_last].next_idx = 0;  \n\tque->swq_last = 0;\n\n\treturn 0;\n}\n\nint bnxt_qplib_create_qp1(struct bnxt_qplib_res *res, struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_hwq_attr hwq_attr = {};\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_create_qp1_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\tstruct cmdq_create_qp1 req = {};\n\tstruct bnxt_qplib_pbl *pbl;\n\tu32 qp_flags = 0;\n\tu8 pg_sz_lvl;\n\tu32 tbl_indx;\n\tint rc;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_CREATE_QP1,\n\t\t\t\t sizeof(req));\n\t \n\treq.type = qp->type;\n\treq.dpi = cpu_to_le32(qp->dpi->dpi);\n\treq.qp_handle = cpu_to_le64(qp->qp_handle);\n\n\t \n\thwq_attr.res = res;\n\thwq_attr.sginfo = &sq->sg_info;\n\thwq_attr.stride = sizeof(struct sq_sge);\n\thwq_attr.depth = bnxt_qplib_get_depth(sq);\n\thwq_attr.type = HWQ_TYPE_QUEUE;\n\trc = bnxt_qplib_alloc_init_hwq(&sq->hwq, &hwq_attr);\n\tif (rc)\n\t\treturn rc;\n\n\trc = bnxt_qplib_alloc_init_swq(sq);\n\tif (rc)\n\t\tgoto fail_sq;\n\n\treq.sq_size = cpu_to_le32(bnxt_qplib_set_sq_size(sq, qp->wqe_mode));\n\tpbl = &sq->hwq.pbl[PBL_LVL_0];\n\treq.sq_pbl = cpu_to_le64(pbl->pg_map_arr[0]);\n\tpg_sz_lvl = (bnxt_qplib_base_pg_size(&sq->hwq) <<\n\t\t     CMDQ_CREATE_QP1_SQ_PG_SIZE_SFT);\n\tpg_sz_lvl |= (sq->hwq.level & CMDQ_CREATE_QP1_SQ_LVL_MASK);\n\treq.sq_pg_size_sq_lvl = pg_sz_lvl;\n\treq.sq_fwo_sq_sge =\n\t\tcpu_to_le16((sq->max_sge & CMDQ_CREATE_QP1_SQ_SGE_MASK) <<\n\t\t\t     CMDQ_CREATE_QP1_SQ_SGE_SFT);\n\treq.scq_cid = cpu_to_le32(qp->scq->id);\n\n\t \n\tif (rq->max_wqe) {\n\t\thwq_attr.res = res;\n\t\thwq_attr.sginfo = &rq->sg_info;\n\t\thwq_attr.stride = sizeof(struct sq_sge);\n\t\thwq_attr.depth = bnxt_qplib_get_depth(rq);\n\t\thwq_attr.type = HWQ_TYPE_QUEUE;\n\t\trc = bnxt_qplib_alloc_init_hwq(&rq->hwq, &hwq_attr);\n\t\tif (rc)\n\t\t\tgoto sq_swq;\n\t\trc = bnxt_qplib_alloc_init_swq(rq);\n\t\tif (rc)\n\t\t\tgoto fail_rq;\n\t\treq.rq_size = cpu_to_le32(rq->max_wqe);\n\t\tpbl = &rq->hwq.pbl[PBL_LVL_0];\n\t\treq.rq_pbl = cpu_to_le64(pbl->pg_map_arr[0]);\n\t\tpg_sz_lvl = (bnxt_qplib_base_pg_size(&rq->hwq) <<\n\t\t\t     CMDQ_CREATE_QP1_RQ_PG_SIZE_SFT);\n\t\tpg_sz_lvl |= (rq->hwq.level & CMDQ_CREATE_QP1_RQ_LVL_MASK);\n\t\treq.rq_pg_size_rq_lvl = pg_sz_lvl;\n\t\treq.rq_fwo_rq_sge =\n\t\t\tcpu_to_le16((rq->max_sge &\n\t\t\t\t     CMDQ_CREATE_QP1_RQ_SGE_MASK) <<\n\t\t\t\t    CMDQ_CREATE_QP1_RQ_SGE_SFT);\n\t}\n\treq.rcq_cid = cpu_to_le32(qp->rcq->id);\n\t \n\trc = bnxt_qplib_alloc_qp_hdr_buf(res, qp);\n\tif (rc) {\n\t\trc = -ENOMEM;\n\t\tgoto rq_rwq;\n\t}\n\tqp_flags |= CMDQ_CREATE_QP1_QP_FLAGS_RESERVED_LKEY_ENABLE;\n\treq.qp_flags = cpu_to_le32(qp_flags);\n\treq.pd_id = cpu_to_le32(qp->pd->id);\n\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req), sizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc)\n\t\tgoto fail;\n\n\tqp->id = le32_to_cpu(resp.xid);\n\tqp->cur_qp_state = CMDQ_MODIFY_QP_NEW_STATE_RESET;\n\tqp->cctx = res->cctx;\n\tsq->dbinfo.hwq = &sq->hwq;\n\tsq->dbinfo.xid = qp->id;\n\tsq->dbinfo.db = qp->dpi->dbr;\n\tsq->dbinfo.max_slot = bnxt_qplib_set_sq_max_slot(qp->wqe_mode);\n\tif (rq->max_wqe) {\n\t\trq->dbinfo.hwq = &rq->hwq;\n\t\trq->dbinfo.xid = qp->id;\n\t\trq->dbinfo.db = qp->dpi->dbr;\n\t\trq->dbinfo.max_slot = bnxt_qplib_set_rq_max_slot(rq->wqe_size);\n\t}\n\ttbl_indx = map_qp_id_to_tbl_indx(qp->id, rcfw);\n\trcfw->qp_tbl[tbl_indx].qp_id = qp->id;\n\trcfw->qp_tbl[tbl_indx].qp_handle = (void *)qp;\n\n\treturn 0;\n\nfail:\n\tbnxt_qplib_free_qp_hdr_buf(res, qp);\nrq_rwq:\n\tkfree(rq->swq);\nfail_rq:\n\tbnxt_qplib_free_hwq(res, &rq->hwq);\nsq_swq:\n\tkfree(sq->swq);\nfail_sq:\n\tbnxt_qplib_free_hwq(res, &sq->hwq);\n\treturn rc;\n}\n\nstatic void bnxt_qplib_init_psn_ptr(struct bnxt_qplib_qp *qp, int size)\n{\n\tstruct bnxt_qplib_hwq *hwq;\n\tstruct bnxt_qplib_q *sq;\n\tu64 fpsne, psn_pg;\n\tu16 indx_pad = 0;\n\n\tsq = &qp->sq;\n\thwq = &sq->hwq;\n\t \n\tfpsne = (u64)bnxt_qplib_get_qe(hwq, hwq->depth, &psn_pg);\n\tif (!IS_ALIGNED(fpsne, PAGE_SIZE))\n\t\tindx_pad = (fpsne & ~PAGE_MASK) / size;\n\thwq->pad_pgofft = indx_pad;\n\thwq->pad_pg = (u64 *)psn_pg;\n\thwq->pad_stride = size;\n}\n\nint bnxt_qplib_create_qp(struct bnxt_qplib_res *res, struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct bnxt_qplib_hwq_attr hwq_attr = {};\n\tstruct bnxt_qplib_sg_info sginfo = {};\n\tstruct creq_create_qp_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\tstruct cmdq_create_qp req = {};\n\tint rc, req_size, psn_sz = 0;\n\tstruct bnxt_qplib_hwq *xrrq;\n\tstruct bnxt_qplib_pbl *pbl;\n\tu32 qp_flags = 0;\n\tu8 pg_sz_lvl;\n\tu32 tbl_indx;\n\tu16 nsge;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_CREATE_QP,\n\t\t\t\t sizeof(req));\n\n\t \n\treq.type = qp->type;\n\treq.dpi = cpu_to_le32(qp->dpi->dpi);\n\treq.qp_handle = cpu_to_le64(qp->qp_handle);\n\n\t \n\tif (qp->type == CMDQ_CREATE_QP_TYPE_RC) {\n\t\tpsn_sz = bnxt_qplib_is_chip_gen_p5(res->cctx) ?\n\t\t\t sizeof(struct sq_psn_search_ext) :\n\t\t\t sizeof(struct sq_psn_search);\n\t}\n\n\thwq_attr.res = res;\n\thwq_attr.sginfo = &sq->sg_info;\n\thwq_attr.stride = sizeof(struct sq_sge);\n\thwq_attr.depth = bnxt_qplib_get_depth(sq);\n\thwq_attr.aux_stride = psn_sz;\n\thwq_attr.aux_depth = bnxt_qplib_set_sq_size(sq, qp->wqe_mode);\n\thwq_attr.type = HWQ_TYPE_QUEUE;\n\trc = bnxt_qplib_alloc_init_hwq(&sq->hwq, &hwq_attr);\n\tif (rc)\n\t\treturn rc;\n\n\trc = bnxt_qplib_alloc_init_swq(sq);\n\tif (rc)\n\t\tgoto fail_sq;\n\n\tif (psn_sz)\n\t\tbnxt_qplib_init_psn_ptr(qp, psn_sz);\n\n\treq.sq_size = cpu_to_le32(bnxt_qplib_set_sq_size(sq, qp->wqe_mode));\n\tpbl = &sq->hwq.pbl[PBL_LVL_0];\n\treq.sq_pbl = cpu_to_le64(pbl->pg_map_arr[0]);\n\tpg_sz_lvl = (bnxt_qplib_base_pg_size(&sq->hwq) <<\n\t\t     CMDQ_CREATE_QP_SQ_PG_SIZE_SFT);\n\tpg_sz_lvl |= (sq->hwq.level & CMDQ_CREATE_QP_SQ_LVL_MASK);\n\treq.sq_pg_size_sq_lvl = pg_sz_lvl;\n\treq.sq_fwo_sq_sge =\n\t\tcpu_to_le16(((sq->max_sge & CMDQ_CREATE_QP_SQ_SGE_MASK) <<\n\t\t\t     CMDQ_CREATE_QP_SQ_SGE_SFT) | 0);\n\treq.scq_cid = cpu_to_le32(qp->scq->id);\n\n\t \n\tif (!qp->srq) {\n\t\thwq_attr.res = res;\n\t\thwq_attr.sginfo = &rq->sg_info;\n\t\thwq_attr.stride = sizeof(struct sq_sge);\n\t\thwq_attr.depth = bnxt_qplib_get_depth(rq);\n\t\thwq_attr.aux_stride = 0;\n\t\thwq_attr.aux_depth = 0;\n\t\thwq_attr.type = HWQ_TYPE_QUEUE;\n\t\trc = bnxt_qplib_alloc_init_hwq(&rq->hwq, &hwq_attr);\n\t\tif (rc)\n\t\t\tgoto sq_swq;\n\t\trc = bnxt_qplib_alloc_init_swq(rq);\n\t\tif (rc)\n\t\t\tgoto fail_rq;\n\n\t\treq.rq_size = cpu_to_le32(rq->max_wqe);\n\t\tpbl = &rq->hwq.pbl[PBL_LVL_0];\n\t\treq.rq_pbl = cpu_to_le64(pbl->pg_map_arr[0]);\n\t\tpg_sz_lvl = (bnxt_qplib_base_pg_size(&rq->hwq) <<\n\t\t\t     CMDQ_CREATE_QP_RQ_PG_SIZE_SFT);\n\t\tpg_sz_lvl |= (rq->hwq.level & CMDQ_CREATE_QP_RQ_LVL_MASK);\n\t\treq.rq_pg_size_rq_lvl = pg_sz_lvl;\n\t\tnsge = (qp->wqe_mode == BNXT_QPLIB_WQE_MODE_STATIC) ?\n\t\t\t6 : rq->max_sge;\n\t\treq.rq_fwo_rq_sge =\n\t\t\tcpu_to_le16(((nsge &\n\t\t\t\t      CMDQ_CREATE_QP_RQ_SGE_MASK) <<\n\t\t\t\t     CMDQ_CREATE_QP_RQ_SGE_SFT) | 0);\n\t} else {\n\t\t \n\t\tqp_flags |= CMDQ_CREATE_QP_QP_FLAGS_SRQ_USED;\n\t\treq.srq_cid = cpu_to_le32(qp->srq->id);\n\t}\n\treq.rcq_cid = cpu_to_le32(qp->rcq->id);\n\n\tqp_flags |= CMDQ_CREATE_QP_QP_FLAGS_RESERVED_LKEY_ENABLE;\n\tqp_flags |= CMDQ_CREATE_QP_QP_FLAGS_FR_PMR_ENABLED;\n\tif (qp->sig_type)\n\t\tqp_flags |= CMDQ_CREATE_QP_QP_FLAGS_FORCE_COMPLETION;\n\tif (qp->wqe_mode == BNXT_QPLIB_WQE_MODE_VARIABLE)\n\t\tqp_flags |= CMDQ_CREATE_QP_QP_FLAGS_VARIABLE_SIZED_WQE_ENABLED;\n\tif (_is_ext_stats_supported(res->dattr->dev_cap_flags) && !res->is_vf)\n\t\tqp_flags |= CMDQ_CREATE_QP_QP_FLAGS_EXT_STATS_ENABLED;\n\n\treq.qp_flags = cpu_to_le32(qp_flags);\n\n\t \n\tif (psn_sz) {\n\t\txrrq = &qp->orrq;\n\t\txrrq->max_elements =\n\t\t\tORD_LIMIT_TO_ORRQ_SLOTS(qp->max_rd_atomic);\n\t\treq_size = xrrq->max_elements *\n\t\t\t   BNXT_QPLIB_MAX_ORRQE_ENTRY_SIZE + PAGE_SIZE - 1;\n\t\treq_size &= ~(PAGE_SIZE - 1);\n\t\tsginfo.pgsize = req_size;\n\t\tsginfo.pgshft = PAGE_SHIFT;\n\n\t\thwq_attr.res = res;\n\t\thwq_attr.sginfo = &sginfo;\n\t\thwq_attr.depth = xrrq->max_elements;\n\t\thwq_attr.stride = BNXT_QPLIB_MAX_ORRQE_ENTRY_SIZE;\n\t\thwq_attr.aux_stride = 0;\n\t\thwq_attr.aux_depth = 0;\n\t\thwq_attr.type = HWQ_TYPE_CTX;\n\t\trc = bnxt_qplib_alloc_init_hwq(xrrq, &hwq_attr);\n\t\tif (rc)\n\t\t\tgoto rq_swq;\n\t\tpbl = &xrrq->pbl[PBL_LVL_0];\n\t\treq.orrq_addr = cpu_to_le64(pbl->pg_map_arr[0]);\n\n\t\txrrq = &qp->irrq;\n\t\txrrq->max_elements = IRD_LIMIT_TO_IRRQ_SLOTS(\n\t\t\t\t\t\tqp->max_dest_rd_atomic);\n\t\treq_size = xrrq->max_elements *\n\t\t\t   BNXT_QPLIB_MAX_IRRQE_ENTRY_SIZE + PAGE_SIZE - 1;\n\t\treq_size &= ~(PAGE_SIZE - 1);\n\t\tsginfo.pgsize = req_size;\n\t\thwq_attr.depth =  xrrq->max_elements;\n\t\thwq_attr.stride = BNXT_QPLIB_MAX_IRRQE_ENTRY_SIZE;\n\t\trc = bnxt_qplib_alloc_init_hwq(xrrq, &hwq_attr);\n\t\tif (rc)\n\t\t\tgoto fail_orrq;\n\n\t\tpbl = &xrrq->pbl[PBL_LVL_0];\n\t\treq.irrq_addr = cpu_to_le64(pbl->pg_map_arr[0]);\n\t}\n\treq.pd_id = cpu_to_le32(qp->pd->id);\n\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req),\n\t\t\t\tsizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc)\n\t\tgoto fail;\n\n\tqp->id = le32_to_cpu(resp.xid);\n\tqp->cur_qp_state = CMDQ_MODIFY_QP_NEW_STATE_RESET;\n\tINIT_LIST_HEAD(&qp->sq_flush);\n\tINIT_LIST_HEAD(&qp->rq_flush);\n\tqp->cctx = res->cctx;\n\tsq->dbinfo.hwq = &sq->hwq;\n\tsq->dbinfo.xid = qp->id;\n\tsq->dbinfo.db = qp->dpi->dbr;\n\tsq->dbinfo.max_slot = bnxt_qplib_set_sq_max_slot(qp->wqe_mode);\n\tif (rq->max_wqe) {\n\t\trq->dbinfo.hwq = &rq->hwq;\n\t\trq->dbinfo.xid = qp->id;\n\t\trq->dbinfo.db = qp->dpi->dbr;\n\t\trq->dbinfo.max_slot = bnxt_qplib_set_rq_max_slot(rq->wqe_size);\n\t}\n\ttbl_indx = map_qp_id_to_tbl_indx(qp->id, rcfw);\n\trcfw->qp_tbl[tbl_indx].qp_id = qp->id;\n\trcfw->qp_tbl[tbl_indx].qp_handle = (void *)qp;\n\n\treturn 0;\nfail:\n\tbnxt_qplib_free_hwq(res, &qp->irrq);\nfail_orrq:\n\tbnxt_qplib_free_hwq(res, &qp->orrq);\nrq_swq:\n\tkfree(rq->swq);\nfail_rq:\n\tbnxt_qplib_free_hwq(res, &rq->hwq);\nsq_swq:\n\tkfree(sq->swq);\nfail_sq:\n\tbnxt_qplib_free_hwq(res, &sq->hwq);\n\treturn rc;\n}\n\nstatic void __modify_flags_from_init_state(struct bnxt_qplib_qp *qp)\n{\n\tswitch (qp->state) {\n\tcase CMDQ_MODIFY_QP_NEW_STATE_RTR:\n\t\t \n\t\tif (!(qp->modify_flags &\n\t\t    CMDQ_MODIFY_QP_MODIFY_MASK_PATH_MTU)) {\n\t\t\tqp->modify_flags |=\n\t\t\t\tCMDQ_MODIFY_QP_MODIFY_MASK_PATH_MTU;\n\t\t\tqp->path_mtu =\n\t\t\t\tCMDQ_MODIFY_QP_PATH_MTU_MTU_2048;\n\t\t}\n\t\tqp->modify_flags &=\n\t\t\t~CMDQ_MODIFY_QP_MODIFY_MASK_VLAN_ID;\n\t\t \n\t\tif (qp->max_dest_rd_atomic < 1)\n\t\t\tqp->max_dest_rd_atomic = 1;\n\t\tqp->modify_flags &= ~CMDQ_MODIFY_QP_MODIFY_MASK_SRC_MAC;\n\t\t \n\t\tif (!(qp->modify_flags &\n\t\t    CMDQ_MODIFY_QP_MODIFY_MASK_SGID_INDEX)) {\n\t\t\tqp->modify_flags |=\n\t\t\t\tCMDQ_MODIFY_QP_MODIFY_MASK_SGID_INDEX;\n\t\t\tqp->ah.sgid_index = 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void __modify_flags_from_rtr_state(struct bnxt_qplib_qp *qp)\n{\n\tswitch (qp->state) {\n\tcase CMDQ_MODIFY_QP_NEW_STATE_RTS:\n\t\t \n\t\tif (qp->max_rd_atomic < 1)\n\t\t\tqp->max_rd_atomic = 1;\n\t\t \n\t\tqp->modify_flags &=\n\t\t\t~(CMDQ_MODIFY_QP_MODIFY_MASK_PKEY |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_DGID |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_FLOW_LABEL |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_SGID_INDEX |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_HOP_LIMIT |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_TRAFFIC_CLASS |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_DEST_MAC |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_PATH_MTU |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_RQ_PSN |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_MIN_RNR_TIMER |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_MAX_DEST_RD_ATOMIC |\n\t\t\t  CMDQ_MODIFY_QP_MODIFY_MASK_DEST_QP_ID);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void __filter_modify_flags(struct bnxt_qplib_qp *qp)\n{\n\tswitch (qp->cur_qp_state) {\n\tcase CMDQ_MODIFY_QP_NEW_STATE_RESET:\n\t\tbreak;\n\tcase CMDQ_MODIFY_QP_NEW_STATE_INIT:\n\t\t__modify_flags_from_init_state(qp);\n\t\tbreak;\n\tcase CMDQ_MODIFY_QP_NEW_STATE_RTR:\n\t\t__modify_flags_from_rtr_state(qp);\n\t\tbreak;\n\tcase CMDQ_MODIFY_QP_NEW_STATE_RTS:\n\t\tbreak;\n\tcase CMDQ_MODIFY_QP_NEW_STATE_SQD:\n\t\tbreak;\n\tcase CMDQ_MODIFY_QP_NEW_STATE_SQE:\n\t\tbreak;\n\tcase CMDQ_MODIFY_QP_NEW_STATE_ERR:\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nint bnxt_qplib_modify_qp(struct bnxt_qplib_res *res, struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_modify_qp_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct cmdq_modify_qp req = {};\n\tu32 temp32[4];\n\tu32 bmask;\n\tint rc;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_MODIFY_QP,\n\t\t\t\t sizeof(req));\n\n\t \n\t__filter_modify_flags(qp);\n\tbmask = qp->modify_flags;\n\treq.modify_mask = cpu_to_le32(qp->modify_flags);\n\treq.qp_cid = cpu_to_le32(qp->id);\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_STATE) {\n\t\treq.network_type_en_sqd_async_notify_new_state =\n\t\t\t\t(qp->state & CMDQ_MODIFY_QP_NEW_STATE_MASK) |\n\t\t\t\t(qp->en_sqd_async_notify ?\n\t\t\t\t\tCMDQ_MODIFY_QP_EN_SQD_ASYNC_NOTIFY : 0);\n\t}\n\treq.network_type_en_sqd_async_notify_new_state |= qp->nw_type;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_ACCESS)\n\t\treq.access = qp->access;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_PKEY)\n\t\treq.pkey = cpu_to_le16(IB_DEFAULT_PKEY_FULL);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_QKEY)\n\t\treq.qkey = cpu_to_le32(qp->qkey);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_DGID) {\n\t\tmemcpy(temp32, qp->ah.dgid.data, sizeof(struct bnxt_qplib_gid));\n\t\treq.dgid[0] = cpu_to_le32(temp32[0]);\n\t\treq.dgid[1] = cpu_to_le32(temp32[1]);\n\t\treq.dgid[2] = cpu_to_le32(temp32[2]);\n\t\treq.dgid[3] = cpu_to_le32(temp32[3]);\n\t}\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_FLOW_LABEL)\n\t\treq.flow_label = cpu_to_le32(qp->ah.flow_label);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_SGID_INDEX)\n\t\treq.sgid_index = cpu_to_le16(res->sgid_tbl.hw_id\n\t\t\t\t\t     [qp->ah.sgid_index]);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_HOP_LIMIT)\n\t\treq.hop_limit = qp->ah.hop_limit;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_TRAFFIC_CLASS)\n\t\treq.traffic_class = qp->ah.traffic_class;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_DEST_MAC)\n\t\tmemcpy(req.dest_mac, qp->ah.dmac, 6);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_PATH_MTU)\n\t\treq.path_mtu_pingpong_push_enable |= qp->path_mtu;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_TIMEOUT)\n\t\treq.timeout = qp->timeout;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_RETRY_CNT)\n\t\treq.retry_cnt = qp->retry_cnt;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_RNR_RETRY)\n\t\treq.rnr_retry = qp->rnr_retry;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_MIN_RNR_TIMER)\n\t\treq.min_rnr_timer = qp->min_rnr_timer;\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_RQ_PSN)\n\t\treq.rq_psn = cpu_to_le32(qp->rq.psn);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_SQ_PSN)\n\t\treq.sq_psn = cpu_to_le32(qp->sq.psn);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_MAX_RD_ATOMIC)\n\t\treq.max_rd_atomic =\n\t\t\tORD_LIMIT_TO_ORRQ_SLOTS(qp->max_rd_atomic);\n\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_MAX_DEST_RD_ATOMIC)\n\t\treq.max_dest_rd_atomic =\n\t\t\tIRD_LIMIT_TO_IRRQ_SLOTS(qp->max_dest_rd_atomic);\n\n\treq.sq_size = cpu_to_le32(qp->sq.hwq.max_elements);\n\treq.rq_size = cpu_to_le32(qp->rq.hwq.max_elements);\n\treq.sq_sge = cpu_to_le16(qp->sq.max_sge);\n\treq.rq_sge = cpu_to_le16(qp->rq.max_sge);\n\treq.max_inline_data = cpu_to_le32(qp->max_inline_data);\n\tif (bmask & CMDQ_MODIFY_QP_MODIFY_MASK_DEST_QP_ID)\n\t\treq.dest_qp_id = cpu_to_le32(qp->dest_qpn);\n\n\treq.vlan_pcp_vlan_dei_vlan_id = cpu_to_le16(qp->vlan_id);\n\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req),  sizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc)\n\t\treturn rc;\n\tqp->cur_qp_state = qp->state;\n\treturn 0;\n}\n\nint bnxt_qplib_query_qp(struct bnxt_qplib_res *res, struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_query_qp_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct bnxt_qplib_rcfw_sbuf sbuf;\n\tstruct creq_query_qp_resp_sb *sb;\n\tstruct cmdq_query_qp req = {};\n\tu32 temp32[4];\n\tint i, rc;\n\n\tsbuf.size = ALIGN(sizeof(*sb), BNXT_QPLIB_CMDQE_UNITS);\n\tsbuf.sb = dma_alloc_coherent(&rcfw->pdev->dev, sbuf.size,\n\t\t\t\t     &sbuf.dma_addr, GFP_KERNEL);\n\tif (!sbuf.sb)\n\t\treturn -ENOMEM;\n\tsb = sbuf.sb;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_QUERY_QP,\n\t\t\t\t sizeof(req));\n\n\treq.qp_cid = cpu_to_le32(qp->id);\n\treq.resp_size = sbuf.size / BNXT_QPLIB_CMDQE_UNITS;\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, &sbuf, sizeof(req),\n\t\t\t\tsizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc)\n\t\tgoto bail;\n\t \n\tqp->state = sb->en_sqd_async_notify_state &\n\t\t\tCREQ_QUERY_QP_RESP_SB_STATE_MASK;\n\tqp->en_sqd_async_notify = sb->en_sqd_async_notify_state &\n\t\t\t\t  CREQ_QUERY_QP_RESP_SB_EN_SQD_ASYNC_NOTIFY;\n\tqp->access = sb->access;\n\tqp->pkey_index = le16_to_cpu(sb->pkey);\n\tqp->qkey = le32_to_cpu(sb->qkey);\n\n\ttemp32[0] = le32_to_cpu(sb->dgid[0]);\n\ttemp32[1] = le32_to_cpu(sb->dgid[1]);\n\ttemp32[2] = le32_to_cpu(sb->dgid[2]);\n\ttemp32[3] = le32_to_cpu(sb->dgid[3]);\n\tmemcpy(qp->ah.dgid.data, temp32, sizeof(qp->ah.dgid.data));\n\n\tqp->ah.flow_label = le32_to_cpu(sb->flow_label);\n\n\tqp->ah.sgid_index = 0;\n\tfor (i = 0; i < res->sgid_tbl.max; i++) {\n\t\tif (res->sgid_tbl.hw_id[i] == le16_to_cpu(sb->sgid_index)) {\n\t\t\tqp->ah.sgid_index = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (i == res->sgid_tbl.max)\n\t\tdev_warn(&res->pdev->dev, \"SGID not found??\\n\");\n\n\tqp->ah.hop_limit = sb->hop_limit;\n\tqp->ah.traffic_class = sb->traffic_class;\n\tmemcpy(qp->ah.dmac, sb->dest_mac, 6);\n\tqp->ah.vlan_id = (le16_to_cpu(sb->path_mtu_dest_vlan_id) &\n\t\t\t\tCREQ_QUERY_QP_RESP_SB_VLAN_ID_MASK) >>\n\t\t\t\tCREQ_QUERY_QP_RESP_SB_VLAN_ID_SFT;\n\tqp->path_mtu = (le16_to_cpu(sb->path_mtu_dest_vlan_id) &\n\t\t\t\t    CREQ_QUERY_QP_RESP_SB_PATH_MTU_MASK) >>\n\t\t\t\t    CREQ_QUERY_QP_RESP_SB_PATH_MTU_SFT;\n\tqp->timeout = sb->timeout;\n\tqp->retry_cnt = sb->retry_cnt;\n\tqp->rnr_retry = sb->rnr_retry;\n\tqp->min_rnr_timer = sb->min_rnr_timer;\n\tqp->rq.psn = le32_to_cpu(sb->rq_psn);\n\tqp->max_rd_atomic = ORRQ_SLOTS_TO_ORD_LIMIT(sb->max_rd_atomic);\n\tqp->sq.psn = le32_to_cpu(sb->sq_psn);\n\tqp->max_dest_rd_atomic =\n\t\t\tIRRQ_SLOTS_TO_IRD_LIMIT(sb->max_dest_rd_atomic);\n\tqp->sq.max_wqe = qp->sq.hwq.max_elements;\n\tqp->rq.max_wqe = qp->rq.hwq.max_elements;\n\tqp->sq.max_sge = le16_to_cpu(sb->sq_sge);\n\tqp->rq.max_sge = le16_to_cpu(sb->rq_sge);\n\tqp->max_inline_data = le32_to_cpu(sb->max_inline_data);\n\tqp->dest_qpn = le32_to_cpu(sb->dest_qp_id);\n\tmemcpy(qp->smac, sb->src_mac, 6);\n\tqp->vlan_id = le16_to_cpu(sb->vlan_pcp_vlan_dei_vlan_id);\nbail:\n\tdma_free_coherent(&rcfw->pdev->dev, sbuf.size,\n\t\t\t  sbuf.sb, sbuf.dma_addr);\n\treturn rc;\n}\n\nstatic void __clean_cq(struct bnxt_qplib_cq *cq, u64 qp)\n{\n\tstruct bnxt_qplib_hwq *cq_hwq = &cq->hwq;\n\tstruct cq_base *hw_cqe;\n\tint i;\n\n\tfor (i = 0; i < cq_hwq->max_elements; i++) {\n\t\thw_cqe = bnxt_qplib_get_qe(cq_hwq, i, NULL);\n\t\tif (!CQE_CMP_VALID(hw_cqe, i, cq_hwq->max_elements))\n\t\t\tcontinue;\n\t\t \n\t\tdma_rmb();\n\t\tswitch (hw_cqe->cqe_type_toggle & CQ_BASE_CQE_TYPE_MASK) {\n\t\tcase CQ_BASE_CQE_TYPE_REQ:\n\t\tcase CQ_BASE_CQE_TYPE_TERMINAL:\n\t\t{\n\t\t\tstruct cq_req *cqe = (struct cq_req *)hw_cqe;\n\n\t\t\tif (qp == le64_to_cpu(cqe->qp_handle))\n\t\t\t\tcqe->qp_handle = 0;\n\t\t\tbreak;\n\t\t}\n\t\tcase CQ_BASE_CQE_TYPE_RES_RC:\n\t\tcase CQ_BASE_CQE_TYPE_RES_UD:\n\t\tcase CQ_BASE_CQE_TYPE_RES_RAWETH_QP1:\n\t\t{\n\t\t\tstruct cq_res_rc *cqe = (struct cq_res_rc *)hw_cqe;\n\n\t\t\tif (qp == le64_to_cpu(cqe->qp_handle))\n\t\t\t\tcqe->qp_handle = 0;\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nint bnxt_qplib_destroy_qp(struct bnxt_qplib_res *res,\n\t\t\t  struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_destroy_qp_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct cmdq_destroy_qp req = {};\n\tu32 tbl_indx;\n\tint rc;\n\n\ttbl_indx = map_qp_id_to_tbl_indx(qp->id, rcfw);\n\trcfw->qp_tbl[tbl_indx].qp_id = BNXT_QPLIB_QP_ID_INVALID;\n\trcfw->qp_tbl[tbl_indx].qp_handle = NULL;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_DESTROY_QP,\n\t\t\t\t sizeof(req));\n\n\treq.qp_cid = cpu_to_le32(qp->id);\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req),\n\t\t\t\tsizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc) {\n\t\trcfw->qp_tbl[tbl_indx].qp_id = qp->id;\n\t\trcfw->qp_tbl[tbl_indx].qp_handle = qp;\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nvoid bnxt_qplib_free_qp_res(struct bnxt_qplib_res *res,\n\t\t\t    struct bnxt_qplib_qp *qp)\n{\n\tbnxt_qplib_free_qp_hdr_buf(res, qp);\n\tbnxt_qplib_free_hwq(res, &qp->sq.hwq);\n\tkfree(qp->sq.swq);\n\n\tbnxt_qplib_free_hwq(res, &qp->rq.hwq);\n\tkfree(qp->rq.swq);\n\n\tif (qp->irrq.max_elements)\n\t\tbnxt_qplib_free_hwq(res, &qp->irrq);\n\tif (qp->orrq.max_elements)\n\t\tbnxt_qplib_free_hwq(res, &qp->orrq);\n\n}\n\nvoid *bnxt_qplib_get_qp1_sq_buf(struct bnxt_qplib_qp *qp,\n\t\t\t\tstruct bnxt_qplib_sge *sge)\n{\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\tu32 sw_prod;\n\n\tmemset(sge, 0, sizeof(*sge));\n\n\tif (qp->sq_hdr_buf) {\n\t\tsw_prod = sq->swq_start;\n\t\tsge->addr = (dma_addr_t)(qp->sq_hdr_buf_map +\n\t\t\t\t\t sw_prod * qp->sq_hdr_buf_size);\n\t\tsge->lkey = 0xFFFFFFFF;\n\t\tsge->size = qp->sq_hdr_buf_size;\n\t\treturn qp->sq_hdr_buf + sw_prod * sge->size;\n\t}\n\treturn NULL;\n}\n\nu32 bnxt_qplib_get_rq_prod_index(struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\n\treturn rq->swq_start;\n}\n\ndma_addr_t bnxt_qplib_get_qp_buf_from_index(struct bnxt_qplib_qp *qp, u32 index)\n{\n\treturn (qp->rq_hdr_buf_map + index * qp->rq_hdr_buf_size);\n}\n\nvoid *bnxt_qplib_get_qp1_rq_buf(struct bnxt_qplib_qp *qp,\n\t\t\t\tstruct bnxt_qplib_sge *sge)\n{\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\tu32 sw_prod;\n\n\tmemset(sge, 0, sizeof(*sge));\n\n\tif (qp->rq_hdr_buf) {\n\t\tsw_prod = rq->swq_start;\n\t\tsge->addr = (dma_addr_t)(qp->rq_hdr_buf_map +\n\t\t\t\t\t sw_prod * qp->rq_hdr_buf_size);\n\t\tsge->lkey = 0xFFFFFFFF;\n\t\tsge->size = qp->rq_hdr_buf_size;\n\t\treturn qp->rq_hdr_buf + sw_prod * sge->size;\n\t}\n\treturn NULL;\n}\n\nstatic void bnxt_qplib_fill_psn_search(struct bnxt_qplib_qp *qp,\n\t\t\t\t       struct bnxt_qplib_swqe *wqe,\n\t\t\t\t       struct bnxt_qplib_swq *swq)\n{\n\tstruct sq_psn_search_ext *psns_ext;\n\tstruct sq_psn_search *psns;\n\tu32 flg_npsn;\n\tu32 op_spsn;\n\n\tif (!swq->psn_search)\n\t\treturn;\n\tpsns = swq->psn_search;\n\tpsns_ext = swq->psn_ext;\n\n\top_spsn = ((swq->start_psn << SQ_PSN_SEARCH_START_PSN_SFT) &\n\t\t    SQ_PSN_SEARCH_START_PSN_MASK);\n\top_spsn |= ((wqe->type << SQ_PSN_SEARCH_OPCODE_SFT) &\n\t\t     SQ_PSN_SEARCH_OPCODE_MASK);\n\tflg_npsn = ((swq->next_psn << SQ_PSN_SEARCH_NEXT_PSN_SFT) &\n\t\t     SQ_PSN_SEARCH_NEXT_PSN_MASK);\n\n\tif (bnxt_qplib_is_chip_gen_p5(qp->cctx)) {\n\t\tpsns_ext->opcode_start_psn = cpu_to_le32(op_spsn);\n\t\tpsns_ext->flags_next_psn = cpu_to_le32(flg_npsn);\n\t\tpsns_ext->start_slot_idx = cpu_to_le16(swq->slot_idx);\n\t} else {\n\t\tpsns->opcode_start_psn = cpu_to_le32(op_spsn);\n\t\tpsns->flags_next_psn = cpu_to_le32(flg_npsn);\n\t}\n}\n\nstatic int bnxt_qplib_put_inline(struct bnxt_qplib_qp *qp,\n\t\t\t\t struct bnxt_qplib_swqe *wqe,\n\t\t\t\t u16 *idx)\n{\n\tstruct bnxt_qplib_hwq *hwq;\n\tint len, t_len, offt;\n\tbool pull_dst = true;\n\tvoid *il_dst = NULL;\n\tvoid *il_src = NULL;\n\tint t_cplen, cplen;\n\tint indx;\n\n\thwq = &qp->sq.hwq;\n\tt_len = 0;\n\tfor (indx = 0; indx < wqe->num_sge; indx++) {\n\t\tlen = wqe->sg_list[indx].size;\n\t\til_src = (void *)wqe->sg_list[indx].addr;\n\t\tt_len += len;\n\t\tif (t_len > qp->max_inline_data)\n\t\t\treturn -ENOMEM;\n\t\twhile (len) {\n\t\t\tif (pull_dst) {\n\t\t\t\tpull_dst = false;\n\t\t\t\til_dst = bnxt_qplib_get_prod_qe(hwq, *idx);\n\t\t\t\t(*idx)++;\n\t\t\t\tt_cplen = 0;\n\t\t\t\tofft = 0;\n\t\t\t}\n\t\t\tcplen = min_t(int, len, sizeof(struct sq_sge));\n\t\t\tcplen = min_t(int, cplen,\n\t\t\t\t\t(sizeof(struct sq_sge) - offt));\n\t\t\tmemcpy(il_dst, il_src, cplen);\n\t\t\tt_cplen += cplen;\n\t\t\til_src += cplen;\n\t\t\til_dst += cplen;\n\t\t\tofft += cplen;\n\t\t\tlen -= cplen;\n\t\t\tif (t_cplen == sizeof(struct sq_sge))\n\t\t\t\tpull_dst = true;\n\t\t}\n\t}\n\n\treturn t_len;\n}\n\nstatic u32 bnxt_qplib_put_sges(struct bnxt_qplib_hwq *hwq,\n\t\t\t       struct bnxt_qplib_sge *ssge,\n\t\t\t       u16 nsge, u16 *idx)\n{\n\tstruct sq_sge *dsge;\n\tint indx, len = 0;\n\n\tfor (indx = 0; indx < nsge; indx++, (*idx)++) {\n\t\tdsge = bnxt_qplib_get_prod_qe(hwq, *idx);\n\t\tdsge->va_or_pa = cpu_to_le64(ssge[indx].addr);\n\t\tdsge->l_key = cpu_to_le32(ssge[indx].lkey);\n\t\tdsge->size = cpu_to_le32(ssge[indx].size);\n\t\tlen += ssge[indx].size;\n\t}\n\n\treturn len;\n}\n\nstatic u16 bnxt_qplib_required_slots(struct bnxt_qplib_qp *qp,\n\t\t\t\t     struct bnxt_qplib_swqe *wqe,\n\t\t\t\t     u16 *wqe_sz, u16 *qdf, u8 mode)\n{\n\tu32 ilsize, bytes;\n\tu16 nsge;\n\tu16 slot;\n\n\tnsge = wqe->num_sge;\n\t \n\tbytes = sizeof(struct sq_send_hdr) + nsge * sizeof(struct sq_sge);\n\tif (wqe->flags & BNXT_QPLIB_SWQE_FLAGS_INLINE) {\n\t\tilsize = bnxt_qplib_calc_ilsize(wqe, qp->max_inline_data);\n\t\tbytes = ALIGN(ilsize, sizeof(struct sq_sge));\n\t\tbytes += sizeof(struct sq_send_hdr);\n\t}\n\n\t*qdf =  __xlate_qfd(qp->sq.q_full_delta, bytes);\n\tslot = bytes >> 4;\n\t*wqe_sz = slot;\n\tif (mode == BNXT_QPLIB_WQE_MODE_STATIC)\n\t\tslot = 8;\n\treturn slot;\n}\n\nstatic void bnxt_qplib_pull_psn_buff(struct bnxt_qplib_q *sq,\n\t\t\t\t     struct bnxt_qplib_swq *swq)\n{\n\tstruct bnxt_qplib_hwq *hwq;\n\tu32 pg_num, pg_indx;\n\tvoid *buff;\n\tu32 tail;\n\n\thwq = &sq->hwq;\n\tif (!hwq->pad_pg)\n\t\treturn;\n\ttail = swq->slot_idx / sq->dbinfo.max_slot;\n\tpg_num = (tail + hwq->pad_pgofft) / (PAGE_SIZE / hwq->pad_stride);\n\tpg_indx = (tail + hwq->pad_pgofft) % (PAGE_SIZE / hwq->pad_stride);\n\tbuff = (void *)(hwq->pad_pg[pg_num] + pg_indx * hwq->pad_stride);\n\tswq->psn_ext = buff;\n\tswq->psn_search = buff;\n}\n\nvoid bnxt_qplib_post_send_db(struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\n\tbnxt_qplib_ring_prod_db(&sq->dbinfo, DBC_DBC_TYPE_SQ);\n}\n\nint bnxt_qplib_post_send(struct bnxt_qplib_qp *qp,\n\t\t\t struct bnxt_qplib_swqe *wqe)\n{\n\tstruct bnxt_qplib_nq_work *nq_work = NULL;\n\tint i, rc = 0, data_len = 0, pkt_num = 0;\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\tstruct bnxt_qplib_hwq *hwq;\n\tstruct bnxt_qplib_swq *swq;\n\tbool sch_handler = false;\n\tu16 wqe_sz, qdf = 0;\n\tvoid *base_hdr;\n\tvoid *ext_hdr;\n\t__le32 temp32;\n\tu32 wqe_idx;\n\tu32 slots;\n\tu16 idx;\n\n\thwq = &sq->hwq;\n\tif (qp->state != CMDQ_MODIFY_QP_NEW_STATE_RTS &&\n\t    qp->state != CMDQ_MODIFY_QP_NEW_STATE_ERR) {\n\t\tdev_err(&hwq->pdev->dev,\n\t\t\t\"QPLIB: FP: QP (0x%x) is in the 0x%x state\",\n\t\t\tqp->id, qp->state);\n\t\trc = -EINVAL;\n\t\tgoto done;\n\t}\n\n\tslots = bnxt_qplib_required_slots(qp, wqe, &wqe_sz, &qdf, qp->wqe_mode);\n\tif (bnxt_qplib_queue_full(sq, slots + qdf)) {\n\t\tdev_err(&hwq->pdev->dev,\n\t\t\t\"prod = %#x cons = %#x qdepth = %#x delta = %#x\\n\",\n\t\t\thwq->prod, hwq->cons, hwq->depth, sq->q_full_delta);\n\t\trc = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\tswq = bnxt_qplib_get_swqe(sq, &wqe_idx);\n\tbnxt_qplib_pull_psn_buff(sq, swq);\n\n\tidx = 0;\n\tswq->slot_idx = hwq->prod;\n\tswq->slots = slots;\n\tswq->wr_id = wqe->wr_id;\n\tswq->type = wqe->type;\n\tswq->flags = wqe->flags;\n\tswq->start_psn = sq->psn & BTH_PSN_MASK;\n\tif (qp->sig_type)\n\t\tswq->flags |= SQ_SEND_FLAGS_SIGNAL_COMP;\n\n\tif (qp->state == CMDQ_MODIFY_QP_NEW_STATE_ERR) {\n\t\tsch_handler = true;\n\t\tdev_dbg(&hwq->pdev->dev,\n\t\t\t\"%s Error QP. Scheduling for poll_cq\\n\", __func__);\n\t\tgoto queue_err;\n\t}\n\n\tbase_hdr = bnxt_qplib_get_prod_qe(hwq, idx++);\n\text_hdr = bnxt_qplib_get_prod_qe(hwq, idx++);\n\tmemset(base_hdr, 0, sizeof(struct sq_sge));\n\tmemset(ext_hdr, 0, sizeof(struct sq_sge));\n\n\tif (wqe->flags & BNXT_QPLIB_SWQE_FLAGS_INLINE)\n\t\t \n\t\tdata_len = bnxt_qplib_put_inline(qp, wqe, &idx);\n\telse\n\t\tdata_len = bnxt_qplib_put_sges(hwq, wqe->sg_list, wqe->num_sge,\n\t\t\t\t\t       &idx);\n\tif (data_len < 0)\n\t\tgoto queue_err;\n\t \n\tswitch (wqe->type) {\n\tcase BNXT_QPLIB_SWQE_TYPE_SEND:\n\t\tif (qp->type == CMDQ_CREATE_QP1_TYPE_GSI) {\n\t\t\tstruct sq_send_raweth_qp1_hdr *sqe = base_hdr;\n\t\t\tstruct sq_raw_ext_hdr *ext_sqe = ext_hdr;\n\t\t\t \n\n\t\t\tsqe->wqe_type = wqe->type;\n\t\t\tsqe->flags = wqe->flags;\n\t\t\tsqe->wqe_size = wqe_sz;\n\t\t\tsqe->cfa_action = cpu_to_le16(wqe->rawqp1.cfa_action);\n\t\t\tsqe->lflags = cpu_to_le16(wqe->rawqp1.lflags);\n\t\t\tsqe->length = cpu_to_le32(data_len);\n\t\t\text_sqe->cfa_meta = cpu_to_le32((wqe->rawqp1.cfa_meta &\n\t\t\t\tSQ_SEND_RAWETH_QP1_CFA_META_VLAN_VID_MASK) <<\n\t\t\t\tSQ_SEND_RAWETH_QP1_CFA_META_VLAN_VID_SFT);\n\n\t\t\tbreak;\n\t\t}\n\t\tfallthrough;\n\tcase BNXT_QPLIB_SWQE_TYPE_SEND_WITH_IMM:\n\tcase BNXT_QPLIB_SWQE_TYPE_SEND_WITH_INV:\n\t{\n\t\tstruct sq_ud_ext_hdr *ext_sqe = ext_hdr;\n\t\tstruct sq_send_hdr *sqe = base_hdr;\n\n\t\tsqe->wqe_type = wqe->type;\n\t\tsqe->flags = wqe->flags;\n\t\tsqe->wqe_size = wqe_sz;\n\t\tsqe->inv_key_or_imm_data = cpu_to_le32(wqe->send.inv_key);\n\t\tif (qp->type == CMDQ_CREATE_QP_TYPE_UD ||\n\t\t    qp->type == CMDQ_CREATE_QP_TYPE_GSI) {\n\t\t\tsqe->q_key = cpu_to_le32(wqe->send.q_key);\n\t\t\tsqe->length = cpu_to_le32(data_len);\n\t\t\tsq->psn = (sq->psn + 1) & BTH_PSN_MASK;\n\t\t\text_sqe->dst_qp = cpu_to_le32(wqe->send.dst_qp &\n\t\t\t\t\t\t      SQ_SEND_DST_QP_MASK);\n\t\t\text_sqe->avid = cpu_to_le32(wqe->send.avid &\n\t\t\t\t\t\t    SQ_SEND_AVID_MASK);\n\t\t} else {\n\t\t\tsqe->length = cpu_to_le32(data_len);\n\t\t\tif (qp->mtu)\n\t\t\t\tpkt_num = (data_len + qp->mtu - 1) / qp->mtu;\n\t\t\tif (!pkt_num)\n\t\t\t\tpkt_num = 1;\n\t\t\tsq->psn = (sq->psn + pkt_num) & BTH_PSN_MASK;\n\t\t}\n\t\tbreak;\n\t}\n\tcase BNXT_QPLIB_SWQE_TYPE_RDMA_WRITE:\n\tcase BNXT_QPLIB_SWQE_TYPE_RDMA_WRITE_WITH_IMM:\n\tcase BNXT_QPLIB_SWQE_TYPE_RDMA_READ:\n\t{\n\t\tstruct sq_rdma_ext_hdr *ext_sqe = ext_hdr;\n\t\tstruct sq_rdma_hdr *sqe = base_hdr;\n\n\t\tsqe->wqe_type = wqe->type;\n\t\tsqe->flags = wqe->flags;\n\t\tsqe->wqe_size = wqe_sz;\n\t\tsqe->imm_data = cpu_to_le32(wqe->rdma.inv_key);\n\t\tsqe->length = cpu_to_le32((u32)data_len);\n\t\text_sqe->remote_va = cpu_to_le64(wqe->rdma.remote_va);\n\t\text_sqe->remote_key = cpu_to_le32(wqe->rdma.r_key);\n\t\tif (qp->mtu)\n\t\t\tpkt_num = (data_len + qp->mtu - 1) / qp->mtu;\n\t\tif (!pkt_num)\n\t\t\tpkt_num = 1;\n\t\tsq->psn = (sq->psn + pkt_num) & BTH_PSN_MASK;\n\t\tbreak;\n\t}\n\tcase BNXT_QPLIB_SWQE_TYPE_ATOMIC_CMP_AND_SWP:\n\tcase BNXT_QPLIB_SWQE_TYPE_ATOMIC_FETCH_AND_ADD:\n\t{\n\t\tstruct sq_atomic_ext_hdr *ext_sqe = ext_hdr;\n\t\tstruct sq_atomic_hdr *sqe = base_hdr;\n\n\t\tsqe->wqe_type = wqe->type;\n\t\tsqe->flags = wqe->flags;\n\t\tsqe->remote_key = cpu_to_le32(wqe->atomic.r_key);\n\t\tsqe->remote_va = cpu_to_le64(wqe->atomic.remote_va);\n\t\text_sqe->swap_data = cpu_to_le64(wqe->atomic.swap_data);\n\t\text_sqe->cmp_data = cpu_to_le64(wqe->atomic.cmp_data);\n\t\tif (qp->mtu)\n\t\t\tpkt_num = (data_len + qp->mtu - 1) / qp->mtu;\n\t\tif (!pkt_num)\n\t\t\tpkt_num = 1;\n\t\tsq->psn = (sq->psn + pkt_num) & BTH_PSN_MASK;\n\t\tbreak;\n\t}\n\tcase BNXT_QPLIB_SWQE_TYPE_LOCAL_INV:\n\t{\n\t\tstruct sq_localinvalidate *sqe = base_hdr;\n\n\t\tsqe->wqe_type = wqe->type;\n\t\tsqe->flags = wqe->flags;\n\t\tsqe->inv_l_key = cpu_to_le32(wqe->local_inv.inv_l_key);\n\n\t\tbreak;\n\t}\n\tcase BNXT_QPLIB_SWQE_TYPE_FAST_REG_MR:\n\t{\n\t\tstruct sq_fr_pmr_ext_hdr *ext_sqe = ext_hdr;\n\t\tstruct sq_fr_pmr_hdr *sqe = base_hdr;\n\n\t\tsqe->wqe_type = wqe->type;\n\t\tsqe->flags = wqe->flags;\n\t\tsqe->access_cntl = wqe->frmr.access_cntl |\n\t\t\t\t   SQ_FR_PMR_ACCESS_CNTL_LOCAL_WRITE;\n\t\tsqe->zero_based_page_size_log =\n\t\t\t(wqe->frmr.pg_sz_log & SQ_FR_PMR_PAGE_SIZE_LOG_MASK) <<\n\t\t\tSQ_FR_PMR_PAGE_SIZE_LOG_SFT |\n\t\t\t(wqe->frmr.zero_based ? SQ_FR_PMR_ZERO_BASED : 0);\n\t\tsqe->l_key = cpu_to_le32(wqe->frmr.l_key);\n\t\ttemp32 = cpu_to_le32(wqe->frmr.length);\n\t\tmemcpy(sqe->length, &temp32, sizeof(wqe->frmr.length));\n\t\tsqe->numlevels_pbl_page_size_log =\n\t\t\t((wqe->frmr.pbl_pg_sz_log <<\n\t\t\t\t\tSQ_FR_PMR_PBL_PAGE_SIZE_LOG_SFT) &\n\t\t\t\t\tSQ_FR_PMR_PBL_PAGE_SIZE_LOG_MASK) |\n\t\t\t((wqe->frmr.levels << SQ_FR_PMR_NUMLEVELS_SFT) &\n\t\t\t\t\tSQ_FR_PMR_NUMLEVELS_MASK);\n\n\t\tfor (i = 0; i < wqe->frmr.page_list_len; i++)\n\t\t\twqe->frmr.pbl_ptr[i] = cpu_to_le64(\n\t\t\t\t\t\twqe->frmr.page_list[i] |\n\t\t\t\t\t\tPTU_PTE_VALID);\n\t\text_sqe->pblptr = cpu_to_le64(wqe->frmr.pbl_dma_ptr);\n\t\text_sqe->va = cpu_to_le64(wqe->frmr.va);\n\n\t\tbreak;\n\t}\n\tcase BNXT_QPLIB_SWQE_TYPE_BIND_MW:\n\t{\n\t\tstruct sq_bind_ext_hdr *ext_sqe = ext_hdr;\n\t\tstruct sq_bind_hdr *sqe = base_hdr;\n\n\t\tsqe->wqe_type = wqe->type;\n\t\tsqe->flags = wqe->flags;\n\t\tsqe->access_cntl = wqe->bind.access_cntl;\n\t\tsqe->mw_type_zero_based = wqe->bind.mw_type |\n\t\t\t(wqe->bind.zero_based ? SQ_BIND_ZERO_BASED : 0);\n\t\tsqe->parent_l_key = cpu_to_le32(wqe->bind.parent_l_key);\n\t\tsqe->l_key = cpu_to_le32(wqe->bind.r_key);\n\t\text_sqe->va = cpu_to_le64(wqe->bind.va);\n\t\text_sqe->length_lo = cpu_to_le32(wqe->bind.length);\n\t\tbreak;\n\t}\n\tdefault:\n\t\t \n\t\trc = -EINVAL;\n\t\tgoto done;\n\t}\n\tswq->next_psn = sq->psn & BTH_PSN_MASK;\n\tbnxt_qplib_fill_psn_search(qp, wqe, swq);\nqueue_err:\n\tbnxt_qplib_swq_mod_start(sq, wqe_idx);\n\tbnxt_qplib_hwq_incr_prod(hwq, swq->slots);\n\tqp->wqe_cnt++;\ndone:\n\tif (sch_handler) {\n\t\tnq_work = kzalloc(sizeof(*nq_work), GFP_ATOMIC);\n\t\tif (nq_work) {\n\t\t\tnq_work->cq = qp->scq;\n\t\t\tnq_work->nq = qp->scq->nq;\n\t\t\tINIT_WORK(&nq_work->work, bnxt_qpn_cqn_sched_task);\n\t\t\tqueue_work(qp->scq->nq->cqn_wq, &nq_work->work);\n\t\t} else {\n\t\t\tdev_err(&hwq->pdev->dev,\n\t\t\t\t\"FP: Failed to allocate SQ nq_work!\\n\");\n\t\t\trc = -ENOMEM;\n\t\t}\n\t}\n\treturn rc;\n}\n\nvoid bnxt_qplib_post_recv_db(struct bnxt_qplib_qp *qp)\n{\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\n\tbnxt_qplib_ring_prod_db(&rq->dbinfo, DBC_DBC_TYPE_RQ);\n}\n\nint bnxt_qplib_post_recv(struct bnxt_qplib_qp *qp,\n\t\t\t struct bnxt_qplib_swqe *wqe)\n{\n\tstruct bnxt_qplib_nq_work *nq_work = NULL;\n\tstruct bnxt_qplib_q *rq = &qp->rq;\n\tstruct rq_wqe_hdr *base_hdr;\n\tstruct rq_ext_hdr *ext_hdr;\n\tstruct bnxt_qplib_hwq *hwq;\n\tstruct bnxt_qplib_swq *swq;\n\tbool sch_handler = false;\n\tu16 wqe_sz, idx;\n\tu32 wqe_idx;\n\tint rc = 0;\n\n\thwq = &rq->hwq;\n\tif (qp->state == CMDQ_MODIFY_QP_NEW_STATE_RESET) {\n\t\tdev_err(&hwq->pdev->dev,\n\t\t\t\"QPLIB: FP: QP (0x%x) is in the 0x%x state\",\n\t\t\tqp->id, qp->state);\n\t\trc = -EINVAL;\n\t\tgoto done;\n\t}\n\n\tif (bnxt_qplib_queue_full(rq, rq->dbinfo.max_slot)) {\n\t\tdev_err(&hwq->pdev->dev,\n\t\t\t\"FP: QP (0x%x) RQ is full!\\n\", qp->id);\n\t\trc = -EINVAL;\n\t\tgoto done;\n\t}\n\n\tswq = bnxt_qplib_get_swqe(rq, &wqe_idx);\n\tswq->wr_id = wqe->wr_id;\n\tswq->slots = rq->dbinfo.max_slot;\n\n\tif (qp->state == CMDQ_MODIFY_QP_NEW_STATE_ERR) {\n\t\tsch_handler = true;\n\t\tdev_dbg(&hwq->pdev->dev,\n\t\t\t\"%s: Error QP. Scheduling for poll_cq\\n\", __func__);\n\t\tgoto queue_err;\n\t}\n\n\tidx = 0;\n\tbase_hdr = bnxt_qplib_get_prod_qe(hwq, idx++);\n\text_hdr = bnxt_qplib_get_prod_qe(hwq, idx++);\n\tmemset(base_hdr, 0, sizeof(struct sq_sge));\n\tmemset(ext_hdr, 0, sizeof(struct sq_sge));\n\twqe_sz = (sizeof(struct rq_wqe_hdr) +\n\twqe->num_sge * sizeof(struct sq_sge)) >> 4;\n\tbnxt_qplib_put_sges(hwq, wqe->sg_list, wqe->num_sge, &idx);\n\tif (!wqe->num_sge) {\n\t\tstruct sq_sge *sge;\n\n\t\tsge = bnxt_qplib_get_prod_qe(hwq, idx++);\n\t\tsge->size = 0;\n\t\twqe_sz++;\n\t}\n\tbase_hdr->wqe_type = wqe->type;\n\tbase_hdr->flags = wqe->flags;\n\tbase_hdr->wqe_size = wqe_sz;\n\tbase_hdr->wr_id[0] = cpu_to_le32(wqe_idx);\nqueue_err:\n\tbnxt_qplib_swq_mod_start(rq, wqe_idx);\n\tbnxt_qplib_hwq_incr_prod(hwq, swq->slots);\ndone:\n\tif (sch_handler) {\n\t\tnq_work = kzalloc(sizeof(*nq_work), GFP_ATOMIC);\n\t\tif (nq_work) {\n\t\t\tnq_work->cq = qp->rcq;\n\t\t\tnq_work->nq = qp->rcq->nq;\n\t\t\tINIT_WORK(&nq_work->work, bnxt_qpn_cqn_sched_task);\n\t\t\tqueue_work(qp->rcq->nq->cqn_wq, &nq_work->work);\n\t\t} else {\n\t\t\tdev_err(&hwq->pdev->dev,\n\t\t\t\t\"FP: Failed to allocate RQ nq_work!\\n\");\n\t\t\trc = -ENOMEM;\n\t\t}\n\t}\n\n\treturn rc;\n}\n\n \nint bnxt_qplib_create_cq(struct bnxt_qplib_res *res, struct bnxt_qplib_cq *cq)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct bnxt_qplib_hwq_attr hwq_attr = {};\n\tstruct creq_create_cq_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct cmdq_create_cq req = {};\n\tstruct bnxt_qplib_pbl *pbl;\n\tu32 pg_sz_lvl;\n\tint rc;\n\n\tif (!cq->dpi) {\n\t\tdev_err(&rcfw->pdev->dev,\n\t\t\t\"FP: CREATE_CQ failed due to NULL DPI\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\thwq_attr.res = res;\n\thwq_attr.depth = cq->max_wqe;\n\thwq_attr.stride = sizeof(struct cq_base);\n\thwq_attr.type = HWQ_TYPE_QUEUE;\n\thwq_attr.sginfo = &cq->sg_info;\n\trc = bnxt_qplib_alloc_init_hwq(&cq->hwq, &hwq_attr);\n\tif (rc)\n\t\treturn rc;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_CREATE_CQ,\n\t\t\t\t sizeof(req));\n\n\treq.dpi = cpu_to_le32(cq->dpi->dpi);\n\treq.cq_handle = cpu_to_le64(cq->cq_handle);\n\treq.cq_size = cpu_to_le32(cq->hwq.max_elements);\n\tpbl = &cq->hwq.pbl[PBL_LVL_0];\n\tpg_sz_lvl = (bnxt_qplib_base_pg_size(&cq->hwq) <<\n\t\t     CMDQ_CREATE_CQ_PG_SIZE_SFT);\n\tpg_sz_lvl |= (cq->hwq.level & CMDQ_CREATE_CQ_LVL_MASK);\n\treq.pg_size_lvl = cpu_to_le32(pg_sz_lvl);\n\treq.pbl = cpu_to_le64(pbl->pg_map_arr[0]);\n\treq.cq_fco_cnq_id = cpu_to_le32(\n\t\t\t(cq->cnq_hw_ring_id & CMDQ_CREATE_CQ_CNQ_ID_MASK) <<\n\t\t\t CMDQ_CREATE_CQ_CNQ_ID_SFT);\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req),\n\t\t\t\tsizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc)\n\t\tgoto fail;\n\n\tcq->id = le32_to_cpu(resp.xid);\n\tcq->period = BNXT_QPLIB_QUEUE_START_PERIOD;\n\tinit_waitqueue_head(&cq->waitq);\n\tINIT_LIST_HEAD(&cq->sqf_head);\n\tINIT_LIST_HEAD(&cq->rqf_head);\n\tspin_lock_init(&cq->compl_lock);\n\tspin_lock_init(&cq->flush_lock);\n\n\tcq->dbinfo.hwq = &cq->hwq;\n\tcq->dbinfo.xid = cq->id;\n\tcq->dbinfo.db = cq->dpi->dbr;\n\tcq->dbinfo.priv_db = res->dpi_tbl.priv_db;\n\n\tbnxt_qplib_armen_db(&cq->dbinfo, DBC_DBC_TYPE_CQ_ARMENA);\n\n\treturn 0;\n\nfail:\n\tbnxt_qplib_free_hwq(res, &cq->hwq);\n\treturn rc;\n}\n\nvoid bnxt_qplib_resize_cq_complete(struct bnxt_qplib_res *res,\n\t\t\t\t   struct bnxt_qplib_cq *cq)\n{\n\tbnxt_qplib_free_hwq(res, &cq->hwq);\n\tmemcpy(&cq->hwq, &cq->resize_hwq, sizeof(cq->hwq));\n}\n\nint bnxt_qplib_resize_cq(struct bnxt_qplib_res *res, struct bnxt_qplib_cq *cq,\n\t\t\t int new_cqes)\n{\n\tstruct bnxt_qplib_hwq_attr hwq_attr = {};\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_resize_cq_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct cmdq_resize_cq req = {};\n\tstruct bnxt_qplib_pbl *pbl;\n\tu32 pg_sz, lvl, new_sz;\n\tint rc;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_RESIZE_CQ,\n\t\t\t\t sizeof(req));\n\thwq_attr.sginfo = &cq->sg_info;\n\thwq_attr.res = res;\n\thwq_attr.depth = new_cqes;\n\thwq_attr.stride = sizeof(struct cq_base);\n\thwq_attr.type = HWQ_TYPE_QUEUE;\n\trc = bnxt_qplib_alloc_init_hwq(&cq->resize_hwq, &hwq_attr);\n\tif (rc)\n\t\treturn rc;\n\n\treq.cq_cid = cpu_to_le32(cq->id);\n\tpbl = &cq->resize_hwq.pbl[PBL_LVL_0];\n\tpg_sz = bnxt_qplib_base_pg_size(&cq->resize_hwq);\n\tlvl = (cq->resize_hwq.level << CMDQ_RESIZE_CQ_LVL_SFT) &\n\t\t\t\t       CMDQ_RESIZE_CQ_LVL_MASK;\n\tnew_sz = (new_cqes << CMDQ_RESIZE_CQ_NEW_CQ_SIZE_SFT) &\n\t\t  CMDQ_RESIZE_CQ_NEW_CQ_SIZE_MASK;\n\treq.new_cq_size_pg_size_lvl = cpu_to_le32(new_sz | pg_sz | lvl);\n\treq.new_pbl = cpu_to_le64(pbl->pg_map_arr[0]);\n\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req),\n\t\t\t\tsizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\treturn rc;\n}\n\nint bnxt_qplib_destroy_cq(struct bnxt_qplib_res *res, struct bnxt_qplib_cq *cq)\n{\n\tstruct bnxt_qplib_rcfw *rcfw = res->rcfw;\n\tstruct creq_destroy_cq_resp resp = {};\n\tstruct bnxt_qplib_cmdqmsg msg = {};\n\tstruct cmdq_destroy_cq req = {};\n\tu16 total_cnq_events;\n\tint rc;\n\n\tbnxt_qplib_rcfw_cmd_prep((struct cmdq_base *)&req,\n\t\t\t\t CMDQ_BASE_OPCODE_DESTROY_CQ,\n\t\t\t\t sizeof(req));\n\n\treq.cq_cid = cpu_to_le32(cq->id);\n\tbnxt_qplib_fill_cmdqmsg(&msg, &req, &resp, NULL, sizeof(req),\n\t\t\t\tsizeof(resp), 0);\n\trc = bnxt_qplib_rcfw_send_message(rcfw, &msg);\n\tif (rc)\n\t\treturn rc;\n\ttotal_cnq_events = le16_to_cpu(resp.total_cnq_events);\n\t__wait_for_all_nqes(cq, total_cnq_events);\n\tbnxt_qplib_free_hwq(res, &cq->hwq);\n\treturn 0;\n}\n\nstatic int __flush_sq(struct bnxt_qplib_q *sq, struct bnxt_qplib_qp *qp,\n\t\t      struct bnxt_qplib_cqe **pcqe, int *budget)\n{\n\tstruct bnxt_qplib_cqe *cqe;\n\tu32 start, last;\n\tint rc = 0;\n\n\t \n\tstart = sq->swq_start;\n\tcqe = *pcqe;\n\twhile (*budget) {\n\t\tlast = sq->swq_last;\n\t\tif (start == last)\n\t\t\tbreak;\n\t\t \n\t\tif (sq->swq[last].wr_id == BNXT_QPLIB_FENCE_WRID) {\n\t\t\tbnxt_qplib_cancel_phantom_processing(qp);\n\t\t\tgoto skip_compl;\n\t\t}\n\t\tmemset(cqe, 0, sizeof(*cqe));\n\t\tcqe->status = CQ_REQ_STATUS_WORK_REQUEST_FLUSHED_ERR;\n\t\tcqe->opcode = CQ_BASE_CQE_TYPE_REQ;\n\t\tcqe->qp_handle = (u64)(unsigned long)qp;\n\t\tcqe->wr_id = sq->swq[last].wr_id;\n\t\tcqe->src_qp = qp->id;\n\t\tcqe->type = sq->swq[last].type;\n\t\tcqe++;\n\t\t(*budget)--;\nskip_compl:\n\t\tbnxt_qplib_hwq_incr_cons(&sq->hwq, sq->swq[last].slots);\n\t\tsq->swq_last = sq->swq[last].next_idx;\n\t}\n\t*pcqe = cqe;\n\tif (!(*budget) && sq->swq_last != start)\n\t\t \n\t\trc = -EAGAIN;\n\n\treturn rc;\n}\n\nstatic int __flush_rq(struct bnxt_qplib_q *rq, struct bnxt_qplib_qp *qp,\n\t\t      struct bnxt_qplib_cqe **pcqe, int *budget)\n{\n\tstruct bnxt_qplib_cqe *cqe;\n\tu32 start, last;\n\tint opcode = 0;\n\tint rc = 0;\n\n\tswitch (qp->type) {\n\tcase CMDQ_CREATE_QP1_TYPE_GSI:\n\t\topcode = CQ_BASE_CQE_TYPE_RES_RAWETH_QP1;\n\t\tbreak;\n\tcase CMDQ_CREATE_QP_TYPE_RC:\n\t\topcode = CQ_BASE_CQE_TYPE_RES_RC;\n\t\tbreak;\n\tcase CMDQ_CREATE_QP_TYPE_UD:\n\tcase CMDQ_CREATE_QP_TYPE_GSI:\n\t\topcode = CQ_BASE_CQE_TYPE_RES_UD;\n\t\tbreak;\n\t}\n\n\t \n\tstart = rq->swq_start;\n\tcqe = *pcqe;\n\twhile (*budget) {\n\t\tlast = rq->swq_last;\n\t\tif (last == start)\n\t\t\tbreak;\n\t\tmemset(cqe, 0, sizeof(*cqe));\n\t\tcqe->status =\n\t\t    CQ_RES_RC_STATUS_WORK_REQUEST_FLUSHED_ERR;\n\t\tcqe->opcode = opcode;\n\t\tcqe->qp_handle = (unsigned long)qp;\n\t\tcqe->wr_id = rq->swq[last].wr_id;\n\t\tcqe++;\n\t\t(*budget)--;\n\t\tbnxt_qplib_hwq_incr_cons(&rq->hwq, rq->swq[last].slots);\n\t\trq->swq_last = rq->swq[last].next_idx;\n\t}\n\t*pcqe = cqe;\n\tif (!*budget && rq->swq_last != start)\n\t\t \n\t\trc = -EAGAIN;\n\n\treturn rc;\n}\n\nvoid bnxt_qplib_mark_qp_error(void *qp_handle)\n{\n\tstruct bnxt_qplib_qp *qp = qp_handle;\n\n\tif (!qp)\n\t\treturn;\n\n\t \n\tqp->state = CMDQ_MODIFY_QP_NEW_STATE_ERR;\n\tbnxt_qplib_cancel_phantom_processing(qp);\n}\n\n \nstatic int do_wa9060(struct bnxt_qplib_qp *qp, struct bnxt_qplib_cq *cq,\n\t\t     u32 cq_cons, u32 swq_last, u32 cqe_sq_cons)\n{\n\tu32 peek_sw_cq_cons, peek_raw_cq_cons, peek_sq_cons_idx;\n\tstruct bnxt_qplib_q *sq = &qp->sq;\n\tstruct cq_req *peek_req_hwcqe;\n\tstruct bnxt_qplib_qp *peek_qp;\n\tstruct bnxt_qplib_q *peek_sq;\n\tstruct bnxt_qplib_swq *swq;\n\tstruct cq_base *peek_hwcqe;\n\tint i, rc = 0;\n\n\t \n\t \n\tswq = &sq->swq[swq_last];\n\tif (swq->psn_search &&\n\t    le32_to_cpu(swq->psn_search->flags_next_psn) & 0x80000000) {\n\t\t \n\t\tswq->psn_search->flags_next_psn = cpu_to_le32\n\t\t\t(le32_to_cpu(swq->psn_search->flags_next_psn)\n\t\t\t\t     & ~0x80000000);\n\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\"FP: Process Req cq_cons=0x%x qp=0x%x sq cons sw=0x%x cqe=0x%x marked!\\n\",\n\t\t\tcq_cons, qp->id, swq_last, cqe_sq_cons);\n\t\tsq->condition = true;\n\t\tsq->send_phantom = true;\n\n\t\t \n\t\tbnxt_qplib_ring_db(&cq->dbinfo, DBC_DBC_TYPE_CQ_ARMALL);\n\t\trc = -EAGAIN;\n\t\tgoto out;\n\t}\n\tif (sq->condition) {\n\t\t \n\t\tpeek_raw_cq_cons = cq->hwq.cons;\n\t\tpeek_sw_cq_cons = cq_cons;\n\t\ti = cq->hwq.max_elements;\n\t\twhile (i--) {\n\t\t\tpeek_sw_cq_cons = HWQ_CMP((peek_sw_cq_cons), &cq->hwq);\n\t\t\tpeek_hwcqe = bnxt_qplib_get_qe(&cq->hwq,\n\t\t\t\t\t\t       peek_sw_cq_cons, NULL);\n\t\t\t \n\t\t\tif (CQE_CMP_VALID(peek_hwcqe, peek_raw_cq_cons,\n\t\t\t\t\t  cq->hwq.max_elements)) {\n\t\t\t \n\t\t\t\tdma_rmb();\n\t\t\t\t \n\t\t\t\tif ((peek_hwcqe->cqe_type_toggle &\n\t\t\t\t    CQ_BASE_CQE_TYPE_MASK) ==\n\t\t\t\t    CQ_BASE_CQE_TYPE_REQ) {\n\t\t\t\t\tpeek_req_hwcqe = (struct cq_req *)\n\t\t\t\t\t\t\t peek_hwcqe;\n\t\t\t\t\tpeek_qp = (struct bnxt_qplib_qp *)\n\t\t\t\t\t\t((unsigned long)\n\t\t\t\t\t\t le64_to_cpu\n\t\t\t\t\t\t (peek_req_hwcqe->qp_handle));\n\t\t\t\t\tpeek_sq = &peek_qp->sq;\n\t\t\t\t\tpeek_sq_cons_idx =\n\t\t\t\t\t\t((le16_to_cpu(\n\t\t\t\t\t\t  peek_req_hwcqe->sq_cons_idx)\n\t\t\t\t\t\t  - 1) % sq->max_wqe);\n\t\t\t\t\t \n\t\t\t\t\tif (peek_sq == sq &&\n\t\t\t\t\t    sq->swq[peek_sq_cons_idx].wr_id ==\n\t\t\t\t\t    BNXT_QPLIB_FENCE_WRID) {\n\t\t\t\t\t\t \n\t\t\t\t\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\t\t\t\t\"FP: Got Phantom CQE\\n\");\n\t\t\t\t\t\tsq->condition = false;\n\t\t\t\t\t\tsq->single = true;\n\t\t\t\t\t\trc = 0;\n\t\t\t\t\t\tgoto out;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t \n\t\t\t} else {\n\t\t\t\t \n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tpeek_sw_cq_cons++;\n\t\t\tpeek_raw_cq_cons++;\n\t\t}\n\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\"Should not have come here! cq_cons=0x%x qp=0x%x sq cons sw=0x%x hw=0x%x\\n\",\n\t\t\tcq_cons, qp->id, swq_last, cqe_sq_cons);\n\t\trc = -EINVAL;\n\t}\nout:\n\treturn rc;\n}\n\nstatic int bnxt_qplib_cq_process_req(struct bnxt_qplib_cq *cq,\n\t\t\t\t     struct cq_req *hwcqe,\n\t\t\t\t     struct bnxt_qplib_cqe **pcqe, int *budget,\n\t\t\t\t     u32 cq_cons, struct bnxt_qplib_qp **lib_qp)\n{\n\tstruct bnxt_qplib_swq *swq;\n\tstruct bnxt_qplib_cqe *cqe;\n\tstruct bnxt_qplib_qp *qp;\n\tstruct bnxt_qplib_q *sq;\n\tu32 cqe_sq_cons;\n\tint rc = 0;\n\n\tqp = (struct bnxt_qplib_qp *)((unsigned long)\n\t\t\t\t      le64_to_cpu(hwcqe->qp_handle));\n\tif (!qp) {\n\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\"FP: Process Req qp is NULL\\n\");\n\t\treturn -EINVAL;\n\t}\n\tsq = &qp->sq;\n\n\tcqe_sq_cons = le16_to_cpu(hwcqe->sq_cons_idx) % sq->max_wqe;\n\tif (qp->sq.flushed) {\n\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\"%s: QP in Flush QP = %p\\n\", __func__, qp);\n\t\tgoto done;\n\t}\n\t \n\tcqe = *pcqe;\n\twhile (*budget) {\n\t\tif (sq->swq_last == cqe_sq_cons)\n\t\t\t \n\t\t\tbreak;\n\n\t\tswq = &sq->swq[sq->swq_last];\n\t\tmemset(cqe, 0, sizeof(*cqe));\n\t\tcqe->opcode = CQ_BASE_CQE_TYPE_REQ;\n\t\tcqe->qp_handle = (u64)(unsigned long)qp;\n\t\tcqe->src_qp = qp->id;\n\t\tcqe->wr_id = swq->wr_id;\n\t\tif (cqe->wr_id == BNXT_QPLIB_FENCE_WRID)\n\t\t\tgoto skip;\n\t\tcqe->type = swq->type;\n\n\t\t \n\t\tif (swq->next_idx == cqe_sq_cons &&\n\t\t    hwcqe->status != CQ_REQ_STATUS_OK) {\n\t\t\tcqe->status = hwcqe->status;\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: CQ Processed Req wr_id[%d] = 0x%llx with status 0x%x\\n\",\n\t\t\t\tsq->swq_last, cqe->wr_id, cqe->status);\n\t\t\tcqe++;\n\t\t\t(*budget)--;\n\t\t\tbnxt_qplib_mark_qp_error(qp);\n\t\t\t \n\t\t\tbnxt_qplib_add_flush_qp(qp);\n\t\t} else {\n\t\t\t \n\t\t\tif (do_wa9060(qp, cq, cq_cons, sq->swq_last,\n\t\t\t\t      cqe_sq_cons)) {\n\t\t\t\t*lib_qp = qp;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (swq->flags & SQ_SEND_FLAGS_SIGNAL_COMP) {\n\t\t\t\tcqe->status = CQ_REQ_STATUS_OK;\n\t\t\t\tcqe++;\n\t\t\t\t(*budget)--;\n\t\t\t}\n\t\t}\nskip:\n\t\tbnxt_qplib_hwq_incr_cons(&sq->hwq, swq->slots);\n\t\tsq->swq_last = swq->next_idx;\n\t\tif (sq->single)\n\t\t\tbreak;\n\t}\nout:\n\t*pcqe = cqe;\n\tif (sq->swq_last != cqe_sq_cons) {\n\t\t \n\t\trc = -EAGAIN;\n\t\tgoto done;\n\t}\n\t \n\tsq->single = false;\ndone:\n\treturn rc;\n}\n\nstatic void bnxt_qplib_release_srqe(struct bnxt_qplib_srq *srq, u32 tag)\n{\n\tspin_lock(&srq->hwq.lock);\n\tsrq->swq[srq->last_idx].next_idx = (int)tag;\n\tsrq->last_idx = (int)tag;\n\tsrq->swq[srq->last_idx].next_idx = -1;\n\tsrq->hwq.cons++;  \n\tspin_unlock(&srq->hwq.lock);\n}\n\nstatic int bnxt_qplib_cq_process_res_rc(struct bnxt_qplib_cq *cq,\n\t\t\t\t\tstruct cq_res_rc *hwcqe,\n\t\t\t\t\tstruct bnxt_qplib_cqe **pcqe,\n\t\t\t\t\tint *budget)\n{\n\tstruct bnxt_qplib_srq *srq;\n\tstruct bnxt_qplib_cqe *cqe;\n\tstruct bnxt_qplib_qp *qp;\n\tstruct bnxt_qplib_q *rq;\n\tu32 wr_id_idx;\n\n\tqp = (struct bnxt_qplib_qp *)((unsigned long)\n\t\t\t\t      le64_to_cpu(hwcqe->qp_handle));\n\tif (!qp) {\n\t\tdev_err(&cq->hwq.pdev->dev, \"process_cq RC qp is NULL\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (qp->rq.flushed) {\n\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\"%s: QP in Flush QP = %p\\n\", __func__, qp);\n\t\treturn 0;\n\t}\n\n\tcqe = *pcqe;\n\tcqe->opcode = hwcqe->cqe_type_toggle & CQ_BASE_CQE_TYPE_MASK;\n\tcqe->length = le32_to_cpu(hwcqe->length);\n\tcqe->invrkey = le32_to_cpu(hwcqe->imm_data_or_inv_r_key);\n\tcqe->mr_handle = le64_to_cpu(hwcqe->mr_handle);\n\tcqe->flags = le16_to_cpu(hwcqe->flags);\n\tcqe->status = hwcqe->status;\n\tcqe->qp_handle = (u64)(unsigned long)qp;\n\n\twr_id_idx = le32_to_cpu(hwcqe->srq_or_rq_wr_id) &\n\t\t\t\tCQ_RES_RC_SRQ_OR_RQ_WR_ID_MASK;\n\tif (cqe->flags & CQ_RES_RC_FLAGS_SRQ_SRQ) {\n\t\tsrq = qp->srq;\n\t\tif (!srq)\n\t\t\treturn -EINVAL;\n\t\tif (wr_id_idx >= srq->hwq.max_elements) {\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: CQ Process RC wr_id idx 0x%x exceeded SRQ max 0x%x\\n\",\n\t\t\t\twr_id_idx, srq->hwq.max_elements);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tcqe->wr_id = srq->swq[wr_id_idx].wr_id;\n\t\tbnxt_qplib_release_srqe(srq, wr_id_idx);\n\t\tcqe++;\n\t\t(*budget)--;\n\t\t*pcqe = cqe;\n\t} else {\n\t\tstruct bnxt_qplib_swq *swq;\n\n\t\trq = &qp->rq;\n\t\tif (wr_id_idx > (rq->max_wqe - 1)) {\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: CQ Process RC wr_id idx 0x%x exceeded RQ max 0x%x\\n\",\n\t\t\t\twr_id_idx, rq->max_wqe);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (wr_id_idx != rq->swq_last)\n\t\t\treturn -EINVAL;\n\t\tswq = &rq->swq[rq->swq_last];\n\t\tcqe->wr_id = swq->wr_id;\n\t\tcqe++;\n\t\t(*budget)--;\n\t\tbnxt_qplib_hwq_incr_cons(&rq->hwq, swq->slots);\n\t\trq->swq_last = swq->next_idx;\n\t\t*pcqe = cqe;\n\n\t\tif (hwcqe->status != CQ_RES_RC_STATUS_OK) {\n\t\t\tqp->state = CMDQ_MODIFY_QP_NEW_STATE_ERR;\n\t\t\t \n\t\t\tbnxt_qplib_add_flush_qp(qp);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int bnxt_qplib_cq_process_res_ud(struct bnxt_qplib_cq *cq,\n\t\t\t\t\tstruct cq_res_ud *hwcqe,\n\t\t\t\t\tstruct bnxt_qplib_cqe **pcqe,\n\t\t\t\t\tint *budget)\n{\n\tstruct bnxt_qplib_srq *srq;\n\tstruct bnxt_qplib_cqe *cqe;\n\tstruct bnxt_qplib_qp *qp;\n\tstruct bnxt_qplib_q *rq;\n\tu32 wr_id_idx;\n\n\tqp = (struct bnxt_qplib_qp *)((unsigned long)\n\t\t\t\t      le64_to_cpu(hwcqe->qp_handle));\n\tif (!qp) {\n\t\tdev_err(&cq->hwq.pdev->dev, \"process_cq UD qp is NULL\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (qp->rq.flushed) {\n\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\"%s: QP in Flush QP = %p\\n\", __func__, qp);\n\t\treturn 0;\n\t}\n\tcqe = *pcqe;\n\tcqe->opcode = hwcqe->cqe_type_toggle & CQ_BASE_CQE_TYPE_MASK;\n\tcqe->length = le16_to_cpu(hwcqe->length) & CQ_RES_UD_LENGTH_MASK;\n\tcqe->cfa_meta = le16_to_cpu(hwcqe->cfa_metadata);\n\tcqe->invrkey = le32_to_cpu(hwcqe->imm_data);\n\tcqe->flags = le16_to_cpu(hwcqe->flags);\n\tcqe->status = hwcqe->status;\n\tcqe->qp_handle = (u64)(unsigned long)qp;\n\t \n\tmemcpy(cqe->smac, hwcqe->src_mac, ETH_ALEN);\n\twr_id_idx = le32_to_cpu(hwcqe->src_qp_high_srq_or_rq_wr_id)\n\t\t\t\t& CQ_RES_UD_SRQ_OR_RQ_WR_ID_MASK;\n\tcqe->src_qp = le16_to_cpu(hwcqe->src_qp_low) |\n\t\t\t\t  ((le32_to_cpu(\n\t\t\t\t  hwcqe->src_qp_high_srq_or_rq_wr_id) &\n\t\t\t\t CQ_RES_UD_SRC_QP_HIGH_MASK) >> 8);\n\n\tif (cqe->flags & CQ_RES_RC_FLAGS_SRQ_SRQ) {\n\t\tsrq = qp->srq;\n\t\tif (!srq)\n\t\t\treturn -EINVAL;\n\n\t\tif (wr_id_idx >= srq->hwq.max_elements) {\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: CQ Process UD wr_id idx 0x%x exceeded SRQ max 0x%x\\n\",\n\t\t\t\twr_id_idx, srq->hwq.max_elements);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tcqe->wr_id = srq->swq[wr_id_idx].wr_id;\n\t\tbnxt_qplib_release_srqe(srq, wr_id_idx);\n\t\tcqe++;\n\t\t(*budget)--;\n\t\t*pcqe = cqe;\n\t} else {\n\t\tstruct bnxt_qplib_swq *swq;\n\n\t\trq = &qp->rq;\n\t\tif (wr_id_idx > (rq->max_wqe - 1)) {\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: CQ Process UD wr_id idx 0x%x exceeded RQ max 0x%x\\n\",\n\t\t\t\twr_id_idx, rq->max_wqe);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (rq->swq_last != wr_id_idx)\n\t\t\treturn -EINVAL;\n\t\tswq = &rq->swq[rq->swq_last];\n\t\tcqe->wr_id = swq->wr_id;\n\t\tcqe++;\n\t\t(*budget)--;\n\t\tbnxt_qplib_hwq_incr_cons(&rq->hwq, swq->slots);\n\t\trq->swq_last = swq->next_idx;\n\t\t*pcqe = cqe;\n\n\t\tif (hwcqe->status != CQ_RES_RC_STATUS_OK) {\n\t\t\tqp->state = CMDQ_MODIFY_QP_NEW_STATE_ERR;\n\t\t\t \n\t\t\tbnxt_qplib_add_flush_qp(qp);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nbool bnxt_qplib_is_cq_empty(struct bnxt_qplib_cq *cq)\n{\n\tstruct cq_base *hw_cqe;\n\tu32 sw_cons, raw_cons;\n\tbool rc = true;\n\n\traw_cons = cq->hwq.cons;\n\tsw_cons = HWQ_CMP(raw_cons, &cq->hwq);\n\thw_cqe = bnxt_qplib_get_qe(&cq->hwq, sw_cons, NULL);\n\t  \n\trc = !CQE_CMP_VALID(hw_cqe, raw_cons, cq->hwq.max_elements);\n\treturn rc;\n}\n\nstatic int bnxt_qplib_cq_process_res_raweth_qp1(struct bnxt_qplib_cq *cq,\n\t\t\t\t\t\tstruct cq_res_raweth_qp1 *hwcqe,\n\t\t\t\t\t\tstruct bnxt_qplib_cqe **pcqe,\n\t\t\t\t\t\tint *budget)\n{\n\tstruct bnxt_qplib_qp *qp;\n\tstruct bnxt_qplib_q *rq;\n\tstruct bnxt_qplib_srq *srq;\n\tstruct bnxt_qplib_cqe *cqe;\n\tu32 wr_id_idx;\n\n\tqp = (struct bnxt_qplib_qp *)((unsigned long)\n\t\t\t\t      le64_to_cpu(hwcqe->qp_handle));\n\tif (!qp) {\n\t\tdev_err(&cq->hwq.pdev->dev, \"process_cq Raw/QP1 qp is NULL\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (qp->rq.flushed) {\n\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\"%s: QP in Flush QP = %p\\n\", __func__, qp);\n\t\treturn 0;\n\t}\n\tcqe = *pcqe;\n\tcqe->opcode = hwcqe->cqe_type_toggle & CQ_BASE_CQE_TYPE_MASK;\n\tcqe->flags = le16_to_cpu(hwcqe->flags);\n\tcqe->qp_handle = (u64)(unsigned long)qp;\n\n\twr_id_idx =\n\t\tle32_to_cpu(hwcqe->raweth_qp1_payload_offset_srq_or_rq_wr_id)\n\t\t\t\t& CQ_RES_RAWETH_QP1_SRQ_OR_RQ_WR_ID_MASK;\n\tcqe->src_qp = qp->id;\n\tif (qp->id == 1 && !cqe->length) {\n\t\t \n\t\tcqe->length = 296;\n\t} else {\n\t\tcqe->length = le16_to_cpu(hwcqe->length);\n\t}\n\tcqe->pkey_index = qp->pkey_index;\n\tmemcpy(cqe->smac, qp->smac, 6);\n\n\tcqe->raweth_qp1_flags = le16_to_cpu(hwcqe->raweth_qp1_flags);\n\tcqe->raweth_qp1_flags2 = le32_to_cpu(hwcqe->raweth_qp1_flags2);\n\tcqe->raweth_qp1_metadata = le32_to_cpu(hwcqe->raweth_qp1_metadata);\n\n\tif (cqe->flags & CQ_RES_RAWETH_QP1_FLAGS_SRQ_SRQ) {\n\t\tsrq = qp->srq;\n\t\tif (!srq) {\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: SRQ used but not defined??\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (wr_id_idx >= srq->hwq.max_elements) {\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: CQ Process Raw/QP1 wr_id idx 0x%x exceeded SRQ max 0x%x\\n\",\n\t\t\t\twr_id_idx, srq->hwq.max_elements);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tcqe->wr_id = srq->swq[wr_id_idx].wr_id;\n\t\tbnxt_qplib_release_srqe(srq, wr_id_idx);\n\t\tcqe++;\n\t\t(*budget)--;\n\t\t*pcqe = cqe;\n\t} else {\n\t\tstruct bnxt_qplib_swq *swq;\n\n\t\trq = &qp->rq;\n\t\tif (wr_id_idx > (rq->max_wqe - 1)) {\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"FP: CQ Process Raw/QP1 RQ wr_id idx 0x%x exceeded RQ max 0x%x\\n\",\n\t\t\t\twr_id_idx, rq->max_wqe);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (rq->swq_last != wr_id_idx)\n\t\t\treturn -EINVAL;\n\t\tswq = &rq->swq[rq->swq_last];\n\t\tcqe->wr_id = swq->wr_id;\n\t\tcqe++;\n\t\t(*budget)--;\n\t\tbnxt_qplib_hwq_incr_cons(&rq->hwq, swq->slots);\n\t\trq->swq_last = swq->next_idx;\n\t\t*pcqe = cqe;\n\n\t\tif (hwcqe->status != CQ_RES_RC_STATUS_OK) {\n\t\t\tqp->state = CMDQ_MODIFY_QP_NEW_STATE_ERR;\n\t\t\t \n\t\t\tbnxt_qplib_add_flush_qp(qp);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int bnxt_qplib_cq_process_terminal(struct bnxt_qplib_cq *cq,\n\t\t\t\t\t  struct cq_terminal *hwcqe,\n\t\t\t\t\t  struct bnxt_qplib_cqe **pcqe,\n\t\t\t\t\t  int *budget)\n{\n\tstruct bnxt_qplib_qp *qp;\n\tstruct bnxt_qplib_q *sq, *rq;\n\tstruct bnxt_qplib_cqe *cqe;\n\tu32 swq_last = 0, cqe_cons;\n\tint rc = 0;\n\n\t \n\tif (hwcqe->status != CQ_TERMINAL_STATUS_OK)\n\t\tdev_warn(&cq->hwq.pdev->dev,\n\t\t\t \"FP: CQ Process Terminal Error status = 0x%x\\n\",\n\t\t\t hwcqe->status);\n\n\tqp = (struct bnxt_qplib_qp *)((unsigned long)\n\t\t\t\t      le64_to_cpu(hwcqe->qp_handle));\n\tif (!qp)\n\t\treturn -EINVAL;\n\n\t \n\tqp->state = CMDQ_MODIFY_QP_NEW_STATE_ERR;\n\n\tsq = &qp->sq;\n\trq = &qp->rq;\n\n\tcqe_cons = le16_to_cpu(hwcqe->sq_cons_idx);\n\tif (cqe_cons == 0xFFFF)\n\t\tgoto do_rq;\n\tcqe_cons %= sq->max_wqe;\n\n\tif (qp->sq.flushed) {\n\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\"%s: QP in Flush QP = %p\\n\", __func__, qp);\n\t\tgoto sq_done;\n\t}\n\n\t \n\tcqe = *pcqe;\n\twhile (*budget) {\n\t\tswq_last = sq->swq_last;\n\t\tif (swq_last == cqe_cons)\n\t\t\tbreak;\n\t\tif (sq->swq[swq_last].flags & SQ_SEND_FLAGS_SIGNAL_COMP) {\n\t\t\tmemset(cqe, 0, sizeof(*cqe));\n\t\t\tcqe->status = CQ_REQ_STATUS_OK;\n\t\t\tcqe->opcode = CQ_BASE_CQE_TYPE_REQ;\n\t\t\tcqe->qp_handle = (u64)(unsigned long)qp;\n\t\t\tcqe->src_qp = qp->id;\n\t\t\tcqe->wr_id = sq->swq[swq_last].wr_id;\n\t\t\tcqe->type = sq->swq[swq_last].type;\n\t\t\tcqe++;\n\t\t\t(*budget)--;\n\t\t}\n\t\tbnxt_qplib_hwq_incr_cons(&sq->hwq, sq->swq[swq_last].slots);\n\t\tsq->swq_last = sq->swq[swq_last].next_idx;\n\t}\n\t*pcqe = cqe;\n\tif (!(*budget) && swq_last != cqe_cons) {\n\t\t \n\t\trc = -EAGAIN;\n\t\tgoto sq_done;\n\t}\nsq_done:\n\tif (rc)\n\t\treturn rc;\ndo_rq:\n\tcqe_cons = le16_to_cpu(hwcqe->rq_cons_idx);\n\tif (cqe_cons == 0xFFFF) {\n\t\tgoto done;\n\t} else if (cqe_cons > rq->max_wqe - 1) {\n\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\"FP: CQ Processed terminal reported rq_cons_idx 0x%x exceeds max 0x%x\\n\",\n\t\t\tcqe_cons, rq->max_wqe);\n\t\trc = -EINVAL;\n\t\tgoto done;\n\t}\n\n\tif (qp->rq.flushed) {\n\t\tdev_dbg(&cq->hwq.pdev->dev,\n\t\t\t\"%s: QP in Flush QP = %p\\n\", __func__, qp);\n\t\trc = 0;\n\t\tgoto done;\n\t}\n\n\t \n\n\t \n\tbnxt_qplib_add_flush_qp(qp);\ndone:\n\treturn rc;\n}\n\nstatic int bnxt_qplib_cq_process_cutoff(struct bnxt_qplib_cq *cq,\n\t\t\t\t\tstruct cq_cutoff *hwcqe)\n{\n\t \n\tif (hwcqe->status != CQ_CUTOFF_STATUS_OK) {\n\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\"FP: CQ Process Cutoff Error status = 0x%x\\n\",\n\t\t\thwcqe->status);\n\t\treturn -EINVAL;\n\t}\n\tclear_bit(CQ_FLAGS_RESIZE_IN_PROG, &cq->flags);\n\twake_up_interruptible(&cq->waitq);\n\n\treturn 0;\n}\n\nint bnxt_qplib_process_flush_list(struct bnxt_qplib_cq *cq,\n\t\t\t\t  struct bnxt_qplib_cqe *cqe,\n\t\t\t\t  int num_cqes)\n{\n\tstruct bnxt_qplib_qp *qp = NULL;\n\tu32 budget = num_cqes;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cq->flush_lock, flags);\n\tlist_for_each_entry(qp, &cq->sqf_head, sq_flush) {\n\t\tdev_dbg(&cq->hwq.pdev->dev, \"FP: Flushing SQ QP= %p\\n\", qp);\n\t\t__flush_sq(&qp->sq, qp, &cqe, &budget);\n\t}\n\n\tlist_for_each_entry(qp, &cq->rqf_head, rq_flush) {\n\t\tdev_dbg(&cq->hwq.pdev->dev, \"FP: Flushing RQ QP= %p\\n\", qp);\n\t\t__flush_rq(&qp->rq, qp, &cqe, &budget);\n\t}\n\tspin_unlock_irqrestore(&cq->flush_lock, flags);\n\n\treturn num_cqes - budget;\n}\n\nint bnxt_qplib_poll_cq(struct bnxt_qplib_cq *cq, struct bnxt_qplib_cqe *cqe,\n\t\t       int num_cqes, struct bnxt_qplib_qp **lib_qp)\n{\n\tstruct cq_base *hw_cqe;\n\tu32 sw_cons, raw_cons;\n\tint budget, rc = 0;\n\tu8 type;\n\n\traw_cons = cq->hwq.cons;\n\tbudget = num_cqes;\n\n\twhile (budget) {\n\t\tsw_cons = HWQ_CMP(raw_cons, &cq->hwq);\n\t\thw_cqe = bnxt_qplib_get_qe(&cq->hwq, sw_cons, NULL);\n\n\t\t \n\t\tif (!CQE_CMP_VALID(hw_cqe, raw_cons, cq->hwq.max_elements))\n\t\t\tbreak;\n\n\t\t \n\t\tdma_rmb();\n\t\t \n\t\ttype = hw_cqe->cqe_type_toggle & CQ_BASE_CQE_TYPE_MASK;\n\t\tswitch (type) {\n\t\tcase CQ_BASE_CQE_TYPE_REQ:\n\t\t\trc = bnxt_qplib_cq_process_req(cq,\n\t\t\t\t\t\t       (struct cq_req *)hw_cqe,\n\t\t\t\t\t\t       &cqe, &budget,\n\t\t\t\t\t\t       sw_cons, lib_qp);\n\t\t\tbreak;\n\t\tcase CQ_BASE_CQE_TYPE_RES_RC:\n\t\t\trc = bnxt_qplib_cq_process_res_rc(cq,\n\t\t\t\t\t\t\t  (struct cq_res_rc *)\n\t\t\t\t\t\t\t  hw_cqe, &cqe,\n\t\t\t\t\t\t\t  &budget);\n\t\t\tbreak;\n\t\tcase CQ_BASE_CQE_TYPE_RES_UD:\n\t\t\trc = bnxt_qplib_cq_process_res_ud\n\t\t\t\t\t(cq, (struct cq_res_ud *)hw_cqe, &cqe,\n\t\t\t\t\t &budget);\n\t\t\tbreak;\n\t\tcase CQ_BASE_CQE_TYPE_RES_RAWETH_QP1:\n\t\t\trc = bnxt_qplib_cq_process_res_raweth_qp1\n\t\t\t\t\t(cq, (struct cq_res_raweth_qp1 *)\n\t\t\t\t\t hw_cqe, &cqe, &budget);\n\t\t\tbreak;\n\t\tcase CQ_BASE_CQE_TYPE_TERMINAL:\n\t\t\trc = bnxt_qplib_cq_process_terminal\n\t\t\t\t\t(cq, (struct cq_terminal *)hw_cqe,\n\t\t\t\t\t &cqe, &budget);\n\t\t\tbreak;\n\t\tcase CQ_BASE_CQE_TYPE_CUT_OFF:\n\t\t\tbnxt_qplib_cq_process_cutoff\n\t\t\t\t\t(cq, (struct cq_cutoff *)hw_cqe);\n\t\t\t \n\t\t\tgoto exit;\n\t\tdefault:\n\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\"process_cq unknown type 0x%lx\\n\",\n\t\t\t\thw_cqe->cqe_type_toggle &\n\t\t\t\tCQ_BASE_CQE_TYPE_MASK);\n\t\t\trc = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (rc < 0) {\n\t\t\tif (rc == -EAGAIN)\n\t\t\t\tbreak;\n\t\t\t \n\t\t\tif (type != CQ_BASE_CQE_TYPE_TERMINAL)\n\t\t\t\tdev_err(&cq->hwq.pdev->dev,\n\t\t\t\t\t\"process_cqe error rc = 0x%x\\n\", rc);\n\t\t}\n\t\traw_cons++;\n\t}\n\tif (cq->hwq.cons != raw_cons) {\n\t\tcq->hwq.cons = raw_cons;\n\t\tbnxt_qplib_ring_db(&cq->dbinfo, DBC_DBC_TYPE_CQ);\n\t}\nexit:\n\treturn num_cqes - budget;\n}\n\nvoid bnxt_qplib_req_notify_cq(struct bnxt_qplib_cq *cq, u32 arm_type)\n{\n\tif (arm_type)\n\t\tbnxt_qplib_ring_db(&cq->dbinfo, arm_type);\n\t \n\tatomic_set(&cq->arm_state, 1);\n}\n\nvoid bnxt_qplib_flush_cqn_wq(struct bnxt_qplib_qp *qp)\n{\n\tflush_workqueue(qp->scq->nq->cqn_wq);\n\tif (qp->scq != qp->rcq)\n\t\tflush_workqueue(qp->rcq->nq->cqn_wq);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}