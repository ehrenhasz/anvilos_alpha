{
  "module_name": "mthca_provider.c",
  "hash_id": "fdab3dd5b33be712d7b9bf84b6b9782de8fbe25d64bd21e3cd09bb53019b2cfb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mthca/mthca_provider.c",
  "human_readable_source": " \n\n#include <rdma/ib_smi.h>\n#include <rdma/ib_umem.h>\n#include <rdma/ib_user_verbs.h>\n#include <rdma/uverbs_ioctl.h>\n\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/stat.h>\n#include <linux/mm.h>\n#include <linux/export.h>\n\n#include \"mthca_dev.h\"\n#include \"mthca_cmd.h\"\n#include <rdma/mthca-abi.h>\n#include \"mthca_memfree.h\"\n\nstatic int mthca_query_device(struct ib_device *ibdev, struct ib_device_attr *props,\n\t\t\t      struct ib_udata *uhw)\n{\n\tstruct ib_smp *in_mad;\n\tstruct ib_smp *out_mad;\n\tint err = -ENOMEM;\n\tstruct mthca_dev *mdev = to_mdev(ibdev);\n\n\tif (uhw->inlen || uhw->outlen)\n\t\treturn -EINVAL;\n\n\tin_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);\n\tout_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);\n\tif (!in_mad || !out_mad)\n\t\tgoto out;\n\n\tmemset(props, 0, sizeof *props);\n\n\tprops->fw_ver              = mdev->fw_ver;\n\n\tib_init_query_mad(in_mad);\n\tin_mad->attr_id = IB_SMP_ATTR_NODE_INFO;\n\n\terr = mthca_MAD_IFC(mdev, 1, 1,\n\t\t\t    1, NULL, NULL, in_mad, out_mad);\n\tif (err)\n\t\tgoto out;\n\n\tprops->device_cap_flags    = mdev->device_cap_flags;\n\tprops->vendor_id           = be32_to_cpup((__be32 *) (out_mad->data + 36)) &\n\t\t0xffffff;\n\tprops->vendor_part_id      = be16_to_cpup((__be16 *) (out_mad->data + 30));\n\tprops->hw_ver              = be32_to_cpup((__be32 *) (out_mad->data + 32));\n\tmemcpy(&props->sys_image_guid, out_mad->data +  4, 8);\n\n\tprops->max_mr_size         = ~0ull;\n\tprops->page_size_cap       = mdev->limits.page_size_cap;\n\tprops->max_qp              = mdev->limits.num_qps - mdev->limits.reserved_qps;\n\tprops->max_qp_wr           = mdev->limits.max_wqes;\n\tprops->max_send_sge        = mdev->limits.max_sg;\n\tprops->max_recv_sge        = mdev->limits.max_sg;\n\tprops->max_sge_rd          = mdev->limits.max_sg;\n\tprops->max_cq              = mdev->limits.num_cqs - mdev->limits.reserved_cqs;\n\tprops->max_cqe             = mdev->limits.max_cqes;\n\tprops->max_mr              = mdev->limits.num_mpts - mdev->limits.reserved_mrws;\n\tprops->max_pd              = mdev->limits.num_pds - mdev->limits.reserved_pds;\n\tprops->max_qp_rd_atom      = 1 << mdev->qp_table.rdb_shift;\n\tprops->max_qp_init_rd_atom = mdev->limits.max_qp_init_rdma;\n\tprops->max_res_rd_atom     = props->max_qp_rd_atom * props->max_qp;\n\tprops->max_srq             = mdev->limits.num_srqs - mdev->limits.reserved_srqs;\n\tprops->max_srq_wr          = mdev->limits.max_srq_wqes;\n\tprops->max_srq_sge         = mdev->limits.max_srq_sge;\n\tprops->local_ca_ack_delay  = mdev->limits.local_ca_ack_delay;\n\tprops->atomic_cap          = mdev->limits.flags & DEV_LIM_FLAG_ATOMIC ?\n\t\t\t\t\tIB_ATOMIC_HCA : IB_ATOMIC_NONE;\n\tprops->max_pkeys           = mdev->limits.pkey_table_len;\n\tprops->max_mcast_grp       = mdev->limits.num_mgms + mdev->limits.num_amgms;\n\tprops->max_mcast_qp_attach = MTHCA_QP_PER_MGM;\n\tprops->max_total_mcast_qp_attach = props->max_mcast_qp_attach *\n\t\t\t\t\t   props->max_mcast_grp;\n\n\terr = 0;\n out:\n\tkfree(in_mad);\n\tkfree(out_mad);\n\treturn err;\n}\n\nstatic int mthca_query_port(struct ib_device *ibdev,\n\t\t\t    u32 port, struct ib_port_attr *props)\n{\n\tstruct ib_smp *in_mad;\n\tstruct ib_smp *out_mad;\n\tint err = -ENOMEM;\n\n\tin_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);\n\tout_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);\n\tif (!in_mad || !out_mad)\n\t\tgoto out;\n\n\t \n\n\tib_init_query_mad(in_mad);\n\tin_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;\n\tin_mad->attr_mod = cpu_to_be32(port);\n\n\terr = mthca_MAD_IFC(to_mdev(ibdev), 1, 1,\n\t\t\t    port, NULL, NULL, in_mad, out_mad);\n\tif (err)\n\t\tgoto out;\n\n\tprops->lid               = be16_to_cpup((__be16 *) (out_mad->data + 16));\n\tprops->lmc               = out_mad->data[34] & 0x7;\n\tprops->sm_lid            = be16_to_cpup((__be16 *) (out_mad->data + 18));\n\tprops->sm_sl             = out_mad->data[36] & 0xf;\n\tprops->state             = out_mad->data[32] & 0xf;\n\tprops->phys_state        = out_mad->data[33] >> 4;\n\tprops->port_cap_flags    = be32_to_cpup((__be32 *) (out_mad->data + 20));\n\tprops->gid_tbl_len       = to_mdev(ibdev)->limits.gid_table_len;\n\tprops->max_msg_sz        = 0x80000000;\n\tprops->pkey_tbl_len      = to_mdev(ibdev)->limits.pkey_table_len;\n\tprops->bad_pkey_cntr     = be16_to_cpup((__be16 *) (out_mad->data + 46));\n\tprops->qkey_viol_cntr    = be16_to_cpup((__be16 *) (out_mad->data + 48));\n\tprops->active_width      = out_mad->data[31] & 0xf;\n\tprops->active_speed      = out_mad->data[35] >> 4;\n\tprops->max_mtu           = out_mad->data[41] & 0xf;\n\tprops->active_mtu        = out_mad->data[36] >> 4;\n\tprops->subnet_timeout    = out_mad->data[51] & 0x1f;\n\tprops->max_vl_num        = out_mad->data[37] >> 4;\n\tprops->init_type_reply   = out_mad->data[41] >> 4;\n\n out:\n\tkfree(in_mad);\n\tkfree(out_mad);\n\treturn err;\n}\n\nstatic int mthca_modify_device(struct ib_device *ibdev,\n\t\t\t       int mask,\n\t\t\t       struct ib_device_modify *props)\n{\n\tif (mask & ~IB_DEVICE_MODIFY_NODE_DESC)\n\t\treturn -EOPNOTSUPP;\n\n\tif (mask & IB_DEVICE_MODIFY_NODE_DESC) {\n\t\tif (mutex_lock_interruptible(&to_mdev(ibdev)->cap_mask_mutex))\n\t\t\treturn -ERESTARTSYS;\n\t\tmemcpy(ibdev->node_desc, props->node_desc,\n\t\t       IB_DEVICE_NODE_DESC_MAX);\n\t\tmutex_unlock(&to_mdev(ibdev)->cap_mask_mutex);\n\t}\n\n\treturn 0;\n}\n\nstatic int mthca_modify_port(struct ib_device *ibdev,\n\t\t\t     u32 port, int port_modify_mask,\n\t\t\t     struct ib_port_modify *props)\n{\n\tstruct mthca_set_ib_param set_ib;\n\tstruct ib_port_attr attr;\n\tint err;\n\n\tif (mutex_lock_interruptible(&to_mdev(ibdev)->cap_mask_mutex))\n\t\treturn -ERESTARTSYS;\n\n\terr = ib_query_port(ibdev, port, &attr);\n\tif (err)\n\t\tgoto out;\n\n\tset_ib.set_si_guid     = 0;\n\tset_ib.reset_qkey_viol = !!(port_modify_mask & IB_PORT_RESET_QKEY_CNTR);\n\n\tset_ib.cap_mask = (attr.port_cap_flags | props->set_port_cap_mask) &\n\t\t~props->clr_port_cap_mask;\n\n\terr = mthca_SET_IB(to_mdev(ibdev), &set_ib, port);\n\tif (err)\n\t\tgoto out;\nout:\n\tmutex_unlock(&to_mdev(ibdev)->cap_mask_mutex);\n\treturn err;\n}\n\nstatic int mthca_query_pkey(struct ib_device *ibdev,\n\t\t\t    u32 port, u16 index, u16 *pkey)\n{\n\tstruct ib_smp *in_mad;\n\tstruct ib_smp *out_mad;\n\tint err = -ENOMEM;\n\n\tin_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);\n\tout_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);\n\tif (!in_mad || !out_mad)\n\t\tgoto out;\n\n\tib_init_query_mad(in_mad);\n\tin_mad->attr_id  = IB_SMP_ATTR_PKEY_TABLE;\n\tin_mad->attr_mod = cpu_to_be32(index / 32);\n\n\terr = mthca_MAD_IFC(to_mdev(ibdev), 1, 1,\n\t\t\t    port, NULL, NULL, in_mad, out_mad);\n\tif (err)\n\t\tgoto out;\n\n\t*pkey = be16_to_cpu(((__be16 *) out_mad->data)[index % 32]);\n\n out:\n\tkfree(in_mad);\n\tkfree(out_mad);\n\treturn err;\n}\n\nstatic int mthca_query_gid(struct ib_device *ibdev, u32 port,\n\t\t\t   int index, union ib_gid *gid)\n{\n\tstruct ib_smp *in_mad;\n\tstruct ib_smp *out_mad;\n\tint err = -ENOMEM;\n\n\tin_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);\n\tout_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);\n\tif (!in_mad || !out_mad)\n\t\tgoto out;\n\n\tib_init_query_mad(in_mad);\n\tin_mad->attr_id  = IB_SMP_ATTR_PORT_INFO;\n\tin_mad->attr_mod = cpu_to_be32(port);\n\n\terr = mthca_MAD_IFC(to_mdev(ibdev), 1, 1,\n\t\t\t    port, NULL, NULL, in_mad, out_mad);\n\tif (err)\n\t\tgoto out;\n\n\tmemcpy(gid->raw, out_mad->data + 8, 8);\n\n\tib_init_query_mad(in_mad);\n\tin_mad->attr_id  = IB_SMP_ATTR_GUID_INFO;\n\tin_mad->attr_mod = cpu_to_be32(index / 8);\n\n\terr = mthca_MAD_IFC(to_mdev(ibdev), 1, 1,\n\t\t\t    port, NULL, NULL, in_mad, out_mad);\n\tif (err)\n\t\tgoto out;\n\n\tmemcpy(gid->raw + 8, out_mad->data + (index % 8) * 8, 8);\n\n out:\n\tkfree(in_mad);\n\tkfree(out_mad);\n\treturn err;\n}\n\nstatic int mthca_alloc_ucontext(struct ib_ucontext *uctx,\n\t\t\t\tstruct ib_udata *udata)\n{\n\tstruct ib_device *ibdev = uctx->device;\n\tstruct mthca_alloc_ucontext_resp uresp = {};\n\tstruct mthca_ucontext *context = to_mucontext(uctx);\n\tint                              err;\n\n\tif (!(to_mdev(ibdev)->active))\n\t\treturn -EAGAIN;\n\n\turesp.qp_tab_size = to_mdev(ibdev)->limits.num_qps;\n\tif (mthca_is_memfree(to_mdev(ibdev)))\n\t\turesp.uarc_size = to_mdev(ibdev)->uar_table.uarc_size;\n\telse\n\t\turesp.uarc_size = 0;\n\n\terr = mthca_uar_alloc(to_mdev(ibdev), &context->uar);\n\tif (err)\n\t\treturn err;\n\n\tcontext->db_tab = mthca_init_user_db_tab(to_mdev(ibdev));\n\tif (IS_ERR(context->db_tab)) {\n\t\terr = PTR_ERR(context->db_tab);\n\t\tmthca_uar_free(to_mdev(ibdev), &context->uar);\n\t\treturn err;\n\t}\n\n\tif (ib_copy_to_udata(udata, &uresp, sizeof(uresp))) {\n\t\tmthca_cleanup_user_db_tab(to_mdev(ibdev), &context->uar, context->db_tab);\n\t\tmthca_uar_free(to_mdev(ibdev), &context->uar);\n\t\treturn -EFAULT;\n\t}\n\n\tcontext->reg_mr_warned = 0;\n\n\treturn 0;\n}\n\nstatic void mthca_dealloc_ucontext(struct ib_ucontext *context)\n{\n\tmthca_cleanup_user_db_tab(to_mdev(context->device), &to_mucontext(context)->uar,\n\t\t\t\t  to_mucontext(context)->db_tab);\n\tmthca_uar_free(to_mdev(context->device), &to_mucontext(context)->uar);\n}\n\nstatic int mthca_mmap_uar(struct ib_ucontext *context,\n\t\t\t  struct vm_area_struct *vma)\n{\n\tif (vma->vm_end - vma->vm_start != PAGE_SIZE)\n\t\treturn -EINVAL;\n\n\tvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\n\n\tif (io_remap_pfn_range(vma, vma->vm_start,\n\t\t\t       to_mucontext(context)->uar.pfn,\n\t\t\t       PAGE_SIZE, vma->vm_page_prot))\n\t\treturn -EAGAIN;\n\n\treturn 0;\n}\n\nstatic int mthca_alloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)\n{\n\tstruct ib_device *ibdev = ibpd->device;\n\tstruct mthca_pd *pd = to_mpd(ibpd);\n\tint err;\n\n\terr = mthca_pd_alloc(to_mdev(ibdev), !udata, pd);\n\tif (err)\n\t\treturn err;\n\n\tif (udata) {\n\t\tif (ib_copy_to_udata(udata, &pd->pd_num, sizeof (__u32))) {\n\t\t\tmthca_pd_free(to_mdev(ibdev), pd);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int mthca_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)\n{\n\tmthca_pd_free(to_mdev(pd->device), to_mpd(pd));\n\treturn 0;\n}\n\nstatic int mthca_ah_create(struct ib_ah *ibah,\n\t\t\t   struct rdma_ah_init_attr *init_attr,\n\t\t\t   struct ib_udata *udata)\n\n{\n\tstruct mthca_ah *ah = to_mah(ibah);\n\n\treturn mthca_create_ah(to_mdev(ibah->device), to_mpd(ibah->pd),\n\t\t\t       init_attr->ah_attr, ah);\n}\n\nstatic int mthca_ah_destroy(struct ib_ah *ah, u32 flags)\n{\n\tmthca_destroy_ah(to_mdev(ah->device), to_mah(ah));\n\treturn 0;\n}\n\nstatic int mthca_create_srq(struct ib_srq *ibsrq,\n\t\t\t    struct ib_srq_init_attr *init_attr,\n\t\t\t    struct ib_udata *udata)\n{\n\tstruct mthca_create_srq ucmd;\n\tstruct mthca_ucontext *context = rdma_udata_to_drv_context(\n\t\tudata, struct mthca_ucontext, ibucontext);\n\tstruct mthca_srq *srq = to_msrq(ibsrq);\n\tint err;\n\n\tif (init_attr->srq_type != IB_SRQT_BASIC)\n\t\treturn -EOPNOTSUPP;\n\n\tif (udata) {\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd)))\n\t\t\treturn -EFAULT;\n\n\t\terr = mthca_map_user_db(to_mdev(ibsrq->device), &context->uar,\n\t\t\t\t\tcontext->db_tab, ucmd.db_index,\n\t\t\t\t\tucmd.db_page);\n\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tsrq->mr.ibmr.lkey = ucmd.lkey;\n\t\tsrq->db_index     = ucmd.db_index;\n\t}\n\n\terr = mthca_alloc_srq(to_mdev(ibsrq->device), to_mpd(ibsrq->pd),\n\t\t\t      &init_attr->attr, srq, udata);\n\n\tif (err && udata)\n\t\tmthca_unmap_user_db(to_mdev(ibsrq->device), &context->uar,\n\t\t\t\t    context->db_tab, ucmd.db_index);\n\n\tif (err)\n\t\treturn err;\n\n\tif (context && ib_copy_to_udata(udata, &srq->srqn, sizeof(__u32))) {\n\t\tmthca_free_srq(to_mdev(ibsrq->device), srq);\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nstatic int mthca_destroy_srq(struct ib_srq *srq, struct ib_udata *udata)\n{\n\tif (udata) {\n\t\tstruct mthca_ucontext *context =\n\t\t\trdma_udata_to_drv_context(\n\t\t\t\tudata,\n\t\t\t\tstruct mthca_ucontext,\n\t\t\t\tibucontext);\n\n\t\tmthca_unmap_user_db(to_mdev(srq->device), &context->uar,\n\t\t\t\t    context->db_tab, to_msrq(srq)->db_index);\n\t}\n\n\tmthca_free_srq(to_mdev(srq->device), to_msrq(srq));\n\treturn 0;\n}\n\nstatic int mthca_create_qp(struct ib_qp *ibqp,\n\t\t\t   struct ib_qp_init_attr *init_attr,\n\t\t\t   struct ib_udata *udata)\n{\n\tstruct mthca_ucontext *context = rdma_udata_to_drv_context(\n\t\tudata, struct mthca_ucontext, ibucontext);\n\tstruct mthca_create_qp ucmd;\n\tstruct mthca_qp *qp = to_mqp(ibqp);\n\tstruct mthca_dev *dev = to_mdev(ibqp->device);\n\tint err;\n\n\tif (init_attr->create_flags)\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (init_attr->qp_type) {\n\tcase IB_QPT_RC:\n\tcase IB_QPT_UC:\n\tcase IB_QPT_UD:\n\t{\n\t\tif (udata) {\n\t\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd)))\n\t\t\t\treturn -EFAULT;\n\n\t\t\terr = mthca_map_user_db(dev, &context->uar,\n\t\t\t\t\t\tcontext->db_tab,\n\t\t\t\t\t\tucmd.sq_db_index,\n\t\t\t\t\t\tucmd.sq_db_page);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\terr = mthca_map_user_db(dev, &context->uar,\n\t\t\t\t\t\tcontext->db_tab,\n\t\t\t\t\t\tucmd.rq_db_index,\n\t\t\t\t\t\tucmd.rq_db_page);\n\t\t\tif (err) {\n\t\t\t\tmthca_unmap_user_db(dev, &context->uar,\n\t\t\t\t\t\t    context->db_tab,\n\t\t\t\t\t\t    ucmd.sq_db_index);\n\t\t\t\treturn err;\n\t\t\t}\n\n\t\t\tqp->mr.ibmr.lkey = ucmd.lkey;\n\t\t\tqp->sq.db_index  = ucmd.sq_db_index;\n\t\t\tqp->rq.db_index  = ucmd.rq_db_index;\n\t\t}\n\n\t\terr = mthca_alloc_qp(dev, to_mpd(ibqp->pd),\n\t\t\t\t     to_mcq(init_attr->send_cq),\n\t\t\t\t     to_mcq(init_attr->recv_cq),\n\t\t\t\t     init_attr->qp_type, init_attr->sq_sig_type,\n\t\t\t\t     &init_attr->cap, qp, udata);\n\n\t\tif (err && udata) {\n\t\t\tmthca_unmap_user_db(dev, &context->uar, context->db_tab,\n\t\t\t\t\t    ucmd.sq_db_index);\n\t\t\tmthca_unmap_user_db(dev, &context->uar, context->db_tab,\n\t\t\t\t\t    ucmd.rq_db_index);\n\t\t}\n\n\t\tqp->ibqp.qp_num = qp->qpn;\n\t\tbreak;\n\t}\n\tcase IB_QPT_SMI:\n\tcase IB_QPT_GSI:\n\t{\n\t\tqp->sqp = kzalloc(sizeof(struct mthca_sqp), GFP_KERNEL);\n\t\tif (!qp->sqp)\n\t\t\treturn -ENOMEM;\n\n\t\tqp->ibqp.qp_num = init_attr->qp_type == IB_QPT_SMI ? 0 : 1;\n\n\t\terr = mthca_alloc_sqp(dev, to_mpd(ibqp->pd),\n\t\t\t\t      to_mcq(init_attr->send_cq),\n\t\t\t\t      to_mcq(init_attr->recv_cq),\n\t\t\t\t      init_attr->sq_sig_type, &init_attr->cap,\n\t\t\t\t      qp->ibqp.qp_num, init_attr->port_num, qp,\n\t\t\t\t      udata);\n\t\tbreak;\n\t}\n\tdefault:\n\t\t \n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (err) {\n\t\tkfree(qp->sqp);\n\t\treturn err;\n\t}\n\n\tinit_attr->cap.max_send_wr     = qp->sq.max;\n\tinit_attr->cap.max_recv_wr     = qp->rq.max;\n\tinit_attr->cap.max_send_sge    = qp->sq.max_gs;\n\tinit_attr->cap.max_recv_sge    = qp->rq.max_gs;\n\tinit_attr->cap.max_inline_data = qp->max_inline_data;\n\n\treturn 0;\n}\n\nstatic int mthca_destroy_qp(struct ib_qp *qp, struct ib_udata *udata)\n{\n\tif (udata) {\n\t\tstruct mthca_ucontext *context =\n\t\t\trdma_udata_to_drv_context(\n\t\t\t\tudata,\n\t\t\t\tstruct mthca_ucontext,\n\t\t\t\tibucontext);\n\n\t\tmthca_unmap_user_db(to_mdev(qp->device),\n\t\t\t\t    &context->uar,\n\t\t\t\t    context->db_tab,\n\t\t\t\t    to_mqp(qp)->sq.db_index);\n\t\tmthca_unmap_user_db(to_mdev(qp->device),\n\t\t\t\t    &context->uar,\n\t\t\t\t    context->db_tab,\n\t\t\t\t    to_mqp(qp)->rq.db_index);\n\t}\n\tmthca_free_qp(to_mdev(qp->device), to_mqp(qp));\n\tkfree(to_mqp(qp)->sqp);\n\treturn 0;\n}\n\nstatic int mthca_create_cq(struct ib_cq *ibcq,\n\t\t\t   const struct ib_cq_init_attr *attr,\n\t\t\t   struct ib_udata *udata)\n{\n\tstruct ib_device *ibdev = ibcq->device;\n\tint entries = attr->cqe;\n\tstruct mthca_create_cq ucmd;\n\tstruct mthca_cq *cq;\n\tint nent;\n\tint err;\n\tstruct mthca_ucontext *context = rdma_udata_to_drv_context(\n\t\tudata, struct mthca_ucontext, ibucontext);\n\n\tif (attr->flags)\n\t\treturn -EOPNOTSUPP;\n\n\tif (entries < 1 || entries > to_mdev(ibdev)->limits.max_cqes)\n\t\treturn -EINVAL;\n\n\tif (udata) {\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd)))\n\t\t\treturn -EFAULT;\n\n\t\terr = mthca_map_user_db(to_mdev(ibdev), &context->uar,\n\t\t\t\t\tcontext->db_tab, ucmd.set_db_index,\n\t\t\t\t\tucmd.set_db_page);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = mthca_map_user_db(to_mdev(ibdev), &context->uar,\n\t\t\t\t\tcontext->db_tab, ucmd.arm_db_index,\n\t\t\t\t\tucmd.arm_db_page);\n\t\tif (err)\n\t\t\tgoto err_unmap_set;\n\t}\n\n\tcq = to_mcq(ibcq);\n\n\tif (udata) {\n\t\tcq->buf.mr.ibmr.lkey = ucmd.lkey;\n\t\tcq->set_ci_db_index  = ucmd.set_db_index;\n\t\tcq->arm_db_index     = ucmd.arm_db_index;\n\t}\n\n\tfor (nent = 1; nent <= entries; nent <<= 1)\n\t\t;  \n\n\terr = mthca_init_cq(to_mdev(ibdev), nent, context,\n\t\t\t    udata ? ucmd.pdn : to_mdev(ibdev)->driver_pd.pd_num,\n\t\t\t    cq);\n\tif (err)\n\t\tgoto err_unmap_arm;\n\n\tif (udata && ib_copy_to_udata(udata, &cq->cqn, sizeof(__u32))) {\n\t\tmthca_free_cq(to_mdev(ibdev), cq);\n\t\terr = -EFAULT;\n\t\tgoto err_unmap_arm;\n\t}\n\n\tcq->resize_buf = NULL;\n\n\treturn 0;\n\nerr_unmap_arm:\n\tif (udata)\n\t\tmthca_unmap_user_db(to_mdev(ibdev), &context->uar,\n\t\t\t\t    context->db_tab, ucmd.arm_db_index);\n\nerr_unmap_set:\n\tif (udata)\n\t\tmthca_unmap_user_db(to_mdev(ibdev), &context->uar,\n\t\t\t\t    context->db_tab, ucmd.set_db_index);\n\n\treturn err;\n}\n\nstatic int mthca_alloc_resize_buf(struct mthca_dev *dev, struct mthca_cq *cq,\n\t\t\t\t  int entries)\n{\n\tint ret;\n\n\tspin_lock_irq(&cq->lock);\n\tif (cq->resize_buf) {\n\t\tret = -EBUSY;\n\t\tgoto unlock;\n\t}\n\n\tcq->resize_buf = kmalloc(sizeof *cq->resize_buf, GFP_ATOMIC);\n\tif (!cq->resize_buf) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock;\n\t}\n\n\tcq->resize_buf->state = CQ_RESIZE_ALLOC;\n\n\tret = 0;\n\nunlock:\n\tspin_unlock_irq(&cq->lock);\n\n\tif (ret)\n\t\treturn ret;\n\n\tret = mthca_alloc_cq_buf(dev, &cq->resize_buf->buf, entries);\n\tif (ret) {\n\t\tspin_lock_irq(&cq->lock);\n\t\tkfree(cq->resize_buf);\n\t\tcq->resize_buf = NULL;\n\t\tspin_unlock_irq(&cq->lock);\n\t\treturn ret;\n\t}\n\n\tcq->resize_buf->cqe = entries - 1;\n\n\tspin_lock_irq(&cq->lock);\n\tcq->resize_buf->state = CQ_RESIZE_READY;\n\tspin_unlock_irq(&cq->lock);\n\n\treturn 0;\n}\n\nstatic int mthca_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata)\n{\n\tstruct mthca_dev *dev = to_mdev(ibcq->device);\n\tstruct mthca_cq *cq = to_mcq(ibcq);\n\tstruct mthca_resize_cq ucmd;\n\tu32 lkey;\n\tint ret;\n\n\tif (entries < 1 || entries > dev->limits.max_cqes)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&cq->mutex);\n\n\tentries = roundup_pow_of_two(entries + 1);\n\tif (entries == ibcq->cqe + 1) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tif (cq->is_kernel) {\n\t\tret = mthca_alloc_resize_buf(dev, cq, entries);\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tlkey = cq->resize_buf->buf.mr.ibmr.lkey;\n\t} else {\n\t\tif (ib_copy_from_udata(&ucmd, udata, sizeof ucmd)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t\tlkey = ucmd.lkey;\n\t}\n\n\tret = mthca_RESIZE_CQ(dev, cq->cqn, lkey, ilog2(entries));\n\n\tif (ret) {\n\t\tif (cq->resize_buf) {\n\t\t\tmthca_free_cq_buf(dev, &cq->resize_buf->buf,\n\t\t\t\t\t  cq->resize_buf->cqe);\n\t\t\tkfree(cq->resize_buf);\n\t\t\tspin_lock_irq(&cq->lock);\n\t\t\tcq->resize_buf = NULL;\n\t\t\tspin_unlock_irq(&cq->lock);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tif (cq->is_kernel) {\n\t\tstruct mthca_cq_buf tbuf;\n\t\tint tcqe;\n\n\t\tspin_lock_irq(&cq->lock);\n\t\tif (cq->resize_buf->state == CQ_RESIZE_READY) {\n\t\t\tmthca_cq_resize_copy_cqes(cq);\n\t\t\ttbuf         = cq->buf;\n\t\t\ttcqe         = cq->ibcq.cqe;\n\t\t\tcq->buf      = cq->resize_buf->buf;\n\t\t\tcq->ibcq.cqe = cq->resize_buf->cqe;\n\t\t} else {\n\t\t\ttbuf = cq->resize_buf->buf;\n\t\t\ttcqe = cq->resize_buf->cqe;\n\t\t}\n\n\t\tkfree(cq->resize_buf);\n\t\tcq->resize_buf = NULL;\n\t\tspin_unlock_irq(&cq->lock);\n\n\t\tmthca_free_cq_buf(dev, &tbuf, tcqe);\n\t} else\n\t\tibcq->cqe = entries - 1;\n\nout:\n\tmutex_unlock(&cq->mutex);\n\n\treturn ret;\n}\n\nstatic int mthca_destroy_cq(struct ib_cq *cq, struct ib_udata *udata)\n{\n\tif (udata) {\n\t\tstruct mthca_ucontext *context =\n\t\t\trdma_udata_to_drv_context(\n\t\t\t\tudata,\n\t\t\t\tstruct mthca_ucontext,\n\t\t\t\tibucontext);\n\n\t\tmthca_unmap_user_db(to_mdev(cq->device),\n\t\t\t\t    &context->uar,\n\t\t\t\t    context->db_tab,\n\t\t\t\t    to_mcq(cq)->arm_db_index);\n\t\tmthca_unmap_user_db(to_mdev(cq->device),\n\t\t\t\t    &context->uar,\n\t\t\t\t    context->db_tab,\n\t\t\t\t    to_mcq(cq)->set_ci_db_index);\n\t}\n\tmthca_free_cq(to_mdev(cq->device), to_mcq(cq));\n\treturn 0;\n}\n\nstatic inline u32 convert_access(int acc)\n{\n\treturn (acc & IB_ACCESS_REMOTE_ATOMIC ? MTHCA_MPT_FLAG_ATOMIC       : 0) |\n\t       (acc & IB_ACCESS_REMOTE_WRITE  ? MTHCA_MPT_FLAG_REMOTE_WRITE : 0) |\n\t       (acc & IB_ACCESS_REMOTE_READ   ? MTHCA_MPT_FLAG_REMOTE_READ  : 0) |\n\t       (acc & IB_ACCESS_LOCAL_WRITE   ? MTHCA_MPT_FLAG_LOCAL_WRITE  : 0) |\n\t       MTHCA_MPT_FLAG_LOCAL_READ;\n}\n\nstatic struct ib_mr *mthca_get_dma_mr(struct ib_pd *pd, int acc)\n{\n\tstruct mthca_mr *mr;\n\tint err;\n\n\tmr = kmalloc(sizeof *mr, GFP_KERNEL);\n\tif (!mr)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\terr = mthca_mr_alloc_notrans(to_mdev(pd->device),\n\t\t\t\t     to_mpd(pd)->pd_num,\n\t\t\t\t     convert_access(acc), mr);\n\n\tif (err) {\n\t\tkfree(mr);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tmr->umem = NULL;\n\n\treturn &mr->ibmr;\n}\n\nstatic struct ib_mr *mthca_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,\n\t\t\t\t       u64 virt, int acc, struct ib_udata *udata)\n{\n\tstruct mthca_dev *dev = to_mdev(pd->device);\n\tstruct ib_block_iter biter;\n\tstruct mthca_ucontext *context = rdma_udata_to_drv_context(\n\t\tudata, struct mthca_ucontext, ibucontext);\n\tstruct mthca_mr *mr;\n\tstruct mthca_reg_mr ucmd;\n\tu64 *pages;\n\tint n, i;\n\tint err = 0;\n\tint write_mtt_size;\n\n\tif (udata->inlen < sizeof ucmd) {\n\t\tif (!context->reg_mr_warned) {\n\t\t\tmthca_warn(dev, \"Process '%s' did not pass in MR attrs.\\n\",\n\t\t\t\t   current->comm);\n\t\t\tmthca_warn(dev, \"  Update libmthca to fix this.\\n\");\n\t\t}\n\t\t++context->reg_mr_warned;\n\t\tucmd.mr_attrs = 0;\n\t} else if (ib_copy_from_udata(&ucmd, udata, sizeof ucmd))\n\t\treturn ERR_PTR(-EFAULT);\n\n\tmr = kmalloc(sizeof *mr, GFP_KERNEL);\n\tif (!mr)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmr->umem = ib_umem_get(pd->device, start, length, acc);\n\tif (IS_ERR(mr->umem)) {\n\t\terr = PTR_ERR(mr->umem);\n\t\tgoto err;\n\t}\n\n\tn = ib_umem_num_dma_blocks(mr->umem, PAGE_SIZE);\n\n\tmr->mtt = mthca_alloc_mtt(dev, n);\n\tif (IS_ERR(mr->mtt)) {\n\t\terr = PTR_ERR(mr->mtt);\n\t\tgoto err_umem;\n\t}\n\n\tpages = (u64 *) __get_free_page(GFP_KERNEL);\n\tif (!pages) {\n\t\terr = -ENOMEM;\n\t\tgoto err_mtt;\n\t}\n\n\ti = n = 0;\n\n\twrite_mtt_size = min(mthca_write_mtt_size(dev), (int) (PAGE_SIZE / sizeof *pages));\n\n\trdma_umem_for_each_dma_block(mr->umem, &biter, PAGE_SIZE) {\n\t\tpages[i++] = rdma_block_iter_dma_address(&biter);\n\n\t\t \n\t\tif (i == write_mtt_size) {\n\t\t\terr = mthca_write_mtt(dev, mr->mtt, n, pages, i);\n\t\t\tif (err)\n\t\t\t\tgoto mtt_done;\n\t\t\tn += i;\n\t\t\ti = 0;\n\t\t}\n\t}\n\n\tif (i)\n\t\terr = mthca_write_mtt(dev, mr->mtt, n, pages, i);\nmtt_done:\n\tfree_page((unsigned long) pages);\n\tif (err)\n\t\tgoto err_mtt;\n\n\terr = mthca_mr_alloc(dev, to_mpd(pd)->pd_num, PAGE_SHIFT, virt, length,\n\t\t\t     convert_access(acc), mr);\n\n\tif (err)\n\t\tgoto err_mtt;\n\n\treturn &mr->ibmr;\n\nerr_mtt:\n\tmthca_free_mtt(dev, mr->mtt);\n\nerr_umem:\n\tib_umem_release(mr->umem);\n\nerr:\n\tkfree(mr);\n\treturn ERR_PTR(err);\n}\n\nstatic int mthca_dereg_mr(struct ib_mr *mr, struct ib_udata *udata)\n{\n\tstruct mthca_mr *mmr = to_mmr(mr);\n\n\tmthca_free_mr(to_mdev(mr->device), mmr);\n\tib_umem_release(mmr->umem);\n\tkfree(mmr);\n\n\treturn 0;\n}\n\nstatic ssize_t hw_rev_show(struct device *device,\n\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct mthca_dev *dev =\n\t\trdma_device_to_drv_device(device, struct mthca_dev, ib_dev);\n\n\treturn sysfs_emit(buf, \"%x\\n\", dev->rev_id);\n}\nstatic DEVICE_ATTR_RO(hw_rev);\n\nstatic const char *hca_type_string(int hca_type)\n{\n\tswitch (hca_type) {\n\tcase PCI_DEVICE_ID_MELLANOX_TAVOR:\n\t\treturn \"MT23108\";\n\tcase PCI_DEVICE_ID_MELLANOX_ARBEL_COMPAT:\n\t\treturn \"MT25208 (MT23108 compat mode)\";\n\tcase PCI_DEVICE_ID_MELLANOX_ARBEL:\n\t\treturn \"MT25208\";\n\tcase PCI_DEVICE_ID_MELLANOX_SINAI:\n\tcase PCI_DEVICE_ID_MELLANOX_SINAI_OLD:\n\t\treturn \"MT25204\";\n\t}\n\n\treturn \"unknown\";\n}\n\nstatic ssize_t hca_type_show(struct device *device,\n\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct mthca_dev *dev =\n\t\trdma_device_to_drv_device(device, struct mthca_dev, ib_dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", hca_type_string(dev->pdev->device));\n}\nstatic DEVICE_ATTR_RO(hca_type);\n\nstatic ssize_t board_id_show(struct device *device,\n\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct mthca_dev *dev =\n\t\trdma_device_to_drv_device(device, struct mthca_dev, ib_dev);\n\n\treturn sysfs_emit(buf, \"%.*s\\n\", MTHCA_BOARD_ID_LEN, dev->board_id);\n}\nstatic DEVICE_ATTR_RO(board_id);\n\nstatic struct attribute *mthca_dev_attributes[] = {\n\t&dev_attr_hw_rev.attr,\n\t&dev_attr_hca_type.attr,\n\t&dev_attr_board_id.attr,\n\tNULL\n};\n\nstatic const struct attribute_group mthca_attr_group = {\n\t.attrs = mthca_dev_attributes,\n};\n\nstatic int mthca_init_node_data(struct mthca_dev *dev)\n{\n\tstruct ib_smp *in_mad;\n\tstruct ib_smp *out_mad;\n\tint err = -ENOMEM;\n\n\tin_mad  = kzalloc(sizeof *in_mad, GFP_KERNEL);\n\tout_mad = kmalloc(sizeof *out_mad, GFP_KERNEL);\n\tif (!in_mad || !out_mad)\n\t\tgoto out;\n\n\tib_init_query_mad(in_mad);\n\tin_mad->attr_id = IB_SMP_ATTR_NODE_DESC;\n\n\terr = mthca_MAD_IFC(dev, 1, 1,\n\t\t\t    1, NULL, NULL, in_mad, out_mad);\n\tif (err)\n\t\tgoto out;\n\n\tmemcpy(dev->ib_dev.node_desc, out_mad->data, IB_DEVICE_NODE_DESC_MAX);\n\n\tin_mad->attr_id = IB_SMP_ATTR_NODE_INFO;\n\n\terr = mthca_MAD_IFC(dev, 1, 1,\n\t\t\t    1, NULL, NULL, in_mad, out_mad);\n\tif (err)\n\t\tgoto out;\n\n\tif (mthca_is_memfree(dev))\n\t\tdev->rev_id = be32_to_cpup((__be32 *) (out_mad->data + 32));\n\tmemcpy(&dev->ib_dev.node_guid, out_mad->data + 12, 8);\n\nout:\n\tkfree(in_mad);\n\tkfree(out_mad);\n\treturn err;\n}\n\nstatic int mthca_port_immutable(struct ib_device *ibdev, u32 port_num,\n\t\t\t        struct ib_port_immutable *immutable)\n{\n\tstruct ib_port_attr attr;\n\tint err;\n\n\timmutable->core_cap_flags = RDMA_CORE_PORT_IBA_IB;\n\n\terr = ib_query_port(ibdev, port_num, &attr);\n\tif (err)\n\t\treturn err;\n\n\timmutable->pkey_tbl_len = attr.pkey_tbl_len;\n\timmutable->gid_tbl_len = attr.gid_tbl_len;\n\timmutable->max_mad_size = IB_MGMT_MAD_SIZE;\n\n\treturn 0;\n}\n\nstatic void get_dev_fw_str(struct ib_device *device, char *str)\n{\n\tstruct mthca_dev *dev =\n\t\tcontainer_of(device, struct mthca_dev, ib_dev);\n\tsnprintf(str, IB_FW_VERSION_NAME_MAX, \"%d.%d.%d\",\n\t\t (int) (dev->fw_ver >> 32),\n\t\t (int) (dev->fw_ver >> 16) & 0xffff,\n\t\t (int) dev->fw_ver & 0xffff);\n}\n\nstatic const struct ib_device_ops mthca_dev_ops = {\n\t.owner = THIS_MODULE,\n\t.driver_id = RDMA_DRIVER_MTHCA,\n\t.uverbs_abi_ver = MTHCA_UVERBS_ABI_VERSION,\n\t.uverbs_no_driver_id_binding = 1,\n\n\t.alloc_pd = mthca_alloc_pd,\n\t.alloc_ucontext = mthca_alloc_ucontext,\n\t.attach_mcast = mthca_multicast_attach,\n\t.create_ah = mthca_ah_create,\n\t.create_cq = mthca_create_cq,\n\t.create_qp = mthca_create_qp,\n\t.dealloc_pd = mthca_dealloc_pd,\n\t.dealloc_ucontext = mthca_dealloc_ucontext,\n\t.dereg_mr = mthca_dereg_mr,\n\t.destroy_ah = mthca_ah_destroy,\n\t.destroy_cq = mthca_destroy_cq,\n\t.destroy_qp = mthca_destroy_qp,\n\t.detach_mcast = mthca_multicast_detach,\n\t.device_group = &mthca_attr_group,\n\t.get_dev_fw_str = get_dev_fw_str,\n\t.get_dma_mr = mthca_get_dma_mr,\n\t.get_port_immutable = mthca_port_immutable,\n\t.mmap = mthca_mmap_uar,\n\t.modify_device = mthca_modify_device,\n\t.modify_port = mthca_modify_port,\n\t.modify_qp = mthca_modify_qp,\n\t.poll_cq = mthca_poll_cq,\n\t.process_mad = mthca_process_mad,\n\t.query_ah = mthca_ah_query,\n\t.query_device = mthca_query_device,\n\t.query_gid = mthca_query_gid,\n\t.query_pkey = mthca_query_pkey,\n\t.query_port = mthca_query_port,\n\t.query_qp = mthca_query_qp,\n\t.reg_user_mr = mthca_reg_user_mr,\n\t.resize_cq = mthca_resize_cq,\n\n\tINIT_RDMA_OBJ_SIZE(ib_ah, mthca_ah, ibah),\n\tINIT_RDMA_OBJ_SIZE(ib_cq, mthca_cq, ibcq),\n\tINIT_RDMA_OBJ_SIZE(ib_pd, mthca_pd, ibpd),\n\tINIT_RDMA_OBJ_SIZE(ib_qp, mthca_qp, ibqp),\n\tINIT_RDMA_OBJ_SIZE(ib_ucontext, mthca_ucontext, ibucontext),\n};\n\nstatic const struct ib_device_ops mthca_dev_arbel_srq_ops = {\n\t.create_srq = mthca_create_srq,\n\t.destroy_srq = mthca_destroy_srq,\n\t.modify_srq = mthca_modify_srq,\n\t.post_srq_recv = mthca_arbel_post_srq_recv,\n\t.query_srq = mthca_query_srq,\n\n\tINIT_RDMA_OBJ_SIZE(ib_srq, mthca_srq, ibsrq),\n};\n\nstatic const struct ib_device_ops mthca_dev_tavor_srq_ops = {\n\t.create_srq = mthca_create_srq,\n\t.destroy_srq = mthca_destroy_srq,\n\t.modify_srq = mthca_modify_srq,\n\t.post_srq_recv = mthca_tavor_post_srq_recv,\n\t.query_srq = mthca_query_srq,\n\n\tINIT_RDMA_OBJ_SIZE(ib_srq, mthca_srq, ibsrq),\n};\n\nstatic const struct ib_device_ops mthca_dev_arbel_ops = {\n\t.post_recv = mthca_arbel_post_receive,\n\t.post_send = mthca_arbel_post_send,\n\t.req_notify_cq = mthca_arbel_arm_cq,\n};\n\nstatic const struct ib_device_ops mthca_dev_tavor_ops = {\n\t.post_recv = mthca_tavor_post_receive,\n\t.post_send = mthca_tavor_post_send,\n\t.req_notify_cq = mthca_tavor_arm_cq,\n};\n\nint mthca_register_device(struct mthca_dev *dev)\n{\n\tint ret;\n\n\tret = mthca_init_node_data(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tdev->ib_dev.node_type            = RDMA_NODE_IB_CA;\n\tdev->ib_dev.phys_port_cnt        = dev->limits.num_ports;\n\tdev->ib_dev.num_comp_vectors     = 1;\n\tdev->ib_dev.dev.parent           = &dev->pdev->dev;\n\n\tif (dev->mthca_flags & MTHCA_FLAG_SRQ) {\n\t\tif (mthca_is_memfree(dev))\n\t\t\tib_set_device_ops(&dev->ib_dev,\n\t\t\t\t\t  &mthca_dev_arbel_srq_ops);\n\t\telse\n\t\t\tib_set_device_ops(&dev->ib_dev,\n\t\t\t\t\t  &mthca_dev_tavor_srq_ops);\n\t}\n\n\tib_set_device_ops(&dev->ib_dev, &mthca_dev_ops);\n\n\tif (mthca_is_memfree(dev))\n\t\tib_set_device_ops(&dev->ib_dev, &mthca_dev_arbel_ops);\n\telse\n\t\tib_set_device_ops(&dev->ib_dev, &mthca_dev_tavor_ops);\n\n\tmutex_init(&dev->cap_mask_mutex);\n\n\tret = ib_register_device(&dev->ib_dev, \"mthca%d\", &dev->pdev->dev);\n\tif (ret)\n\t\treturn ret;\n\n\tmthca_start_catas_poll(dev);\n\n\treturn 0;\n}\n\nvoid mthca_unregister_device(struct mthca_dev *dev)\n{\n\tmthca_stop_catas_poll(dev);\n\tib_unregister_device(&dev->ib_dev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}