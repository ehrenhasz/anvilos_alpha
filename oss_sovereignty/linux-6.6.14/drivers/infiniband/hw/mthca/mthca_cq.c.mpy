{
  "module_name": "mthca_cq.c",
  "hash_id": "2ccd66b04493c2b3a43ca42041d60a25884b374da8c491c0d037e0d8f1ce9dea",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mthca/mthca_cq.c",
  "human_readable_source": " \n\n#include <linux/gfp.h>\n#include <linux/hardirq.h>\n#include <linux/sched.h>\n\n#include <asm/io.h>\n\n#include <rdma/ib_pack.h>\n\n#include \"mthca_dev.h\"\n#include \"mthca_cmd.h\"\n#include \"mthca_memfree.h\"\n\nenum {\n\tMTHCA_MAX_DIRECT_CQ_SIZE = 4 * PAGE_SIZE\n};\n\nenum {\n\tMTHCA_CQ_ENTRY_SIZE = 0x20\n};\n\nenum {\n\tMTHCA_ATOMIC_BYTE_LEN = 8\n};\n\n \nstruct mthca_cq_context {\n\t__be32 flags;\n\t__be64 start;\n\t__be32 logsize_usrpage;\n\t__be32 error_eqn;\t \n\t__be32 comp_eqn;\n\t__be32 pd;\n\t__be32 lkey;\n\t__be32 last_notified_index;\n\t__be32 solicit_producer_index;\n\t__be32 consumer_index;\n\t__be32 producer_index;\n\t__be32 cqn;\n\t__be32 ci_db;\t\t \n\t__be32 state_db;\t \n\tu32    reserved;\n} __packed;\n\n#define MTHCA_CQ_STATUS_OK          ( 0 << 28)\n#define MTHCA_CQ_STATUS_OVERFLOW    ( 9 << 28)\n#define MTHCA_CQ_STATUS_WRITE_FAIL  (10 << 28)\n#define MTHCA_CQ_FLAG_TR            ( 1 << 18)\n#define MTHCA_CQ_FLAG_OI            ( 1 << 17)\n#define MTHCA_CQ_STATE_DISARMED     ( 0 <<  8)\n#define MTHCA_CQ_STATE_ARMED        ( 1 <<  8)\n#define MTHCA_CQ_STATE_ARMED_SOL    ( 4 <<  8)\n#define MTHCA_EQ_STATE_FIRED        (10 <<  8)\n\nenum {\n\tMTHCA_ERROR_CQE_OPCODE_MASK = 0xfe\n};\n\nenum {\n\tSYNDROME_LOCAL_LENGTH_ERR \t = 0x01,\n\tSYNDROME_LOCAL_QP_OP_ERR  \t = 0x02,\n\tSYNDROME_LOCAL_EEC_OP_ERR \t = 0x03,\n\tSYNDROME_LOCAL_PROT_ERR   \t = 0x04,\n\tSYNDROME_WR_FLUSH_ERR     \t = 0x05,\n\tSYNDROME_MW_BIND_ERR      \t = 0x06,\n\tSYNDROME_BAD_RESP_ERR     \t = 0x10,\n\tSYNDROME_LOCAL_ACCESS_ERR \t = 0x11,\n\tSYNDROME_REMOTE_INVAL_REQ_ERR \t = 0x12,\n\tSYNDROME_REMOTE_ACCESS_ERR \t = 0x13,\n\tSYNDROME_REMOTE_OP_ERR     \t = 0x14,\n\tSYNDROME_RETRY_EXC_ERR \t\t = 0x15,\n\tSYNDROME_RNR_RETRY_EXC_ERR \t = 0x16,\n\tSYNDROME_LOCAL_RDD_VIOL_ERR \t = 0x20,\n\tSYNDROME_REMOTE_INVAL_RD_REQ_ERR = 0x21,\n\tSYNDROME_REMOTE_ABORTED_ERR \t = 0x22,\n\tSYNDROME_INVAL_EECN_ERR \t = 0x23,\n\tSYNDROME_INVAL_EEC_STATE_ERR \t = 0x24\n};\n\nstruct mthca_cqe {\n\t__be32 my_qpn;\n\t__be32 my_ee;\n\t__be32 rqpn;\n\tu8     sl_ipok;\n\tu8     g_mlpath;\n\t__be16 rlid;\n\t__be32 imm_etype_pkey_eec;\n\t__be32 byte_cnt;\n\t__be32 wqe;\n\tu8     opcode;\n\tu8     is_send;\n\tu8     reserved;\n\tu8     owner;\n};\n\nstruct mthca_err_cqe {\n\t__be32 my_qpn;\n\tu32    reserved1[3];\n\tu8     syndrome;\n\tu8     vendor_err;\n\t__be16 db_cnt;\n\tu32    reserved2;\n\t__be32 wqe;\n\tu8     opcode;\n\tu8     reserved3[2];\n\tu8     owner;\n};\n\n#define MTHCA_CQ_ENTRY_OWNER_SW      (0 << 7)\n#define MTHCA_CQ_ENTRY_OWNER_HW      (1 << 7)\n\n#define MTHCA_TAVOR_CQ_DB_INC_CI       (1 << 24)\n#define MTHCA_TAVOR_CQ_DB_REQ_NOT      (2 << 24)\n#define MTHCA_TAVOR_CQ_DB_REQ_NOT_SOL  (3 << 24)\n#define MTHCA_TAVOR_CQ_DB_SET_CI       (4 << 24)\n#define MTHCA_TAVOR_CQ_DB_REQ_NOT_MULT (5 << 24)\n\n#define MTHCA_ARBEL_CQ_DB_REQ_NOT_SOL  (1 << 24)\n#define MTHCA_ARBEL_CQ_DB_REQ_NOT      (2 << 24)\n#define MTHCA_ARBEL_CQ_DB_REQ_NOT_MULT (3 << 24)\n\nstatic inline struct mthca_cqe *get_cqe_from_buf(struct mthca_cq_buf *buf,\n\t\t\t\t\t\t int entry)\n{\n\tif (buf->is_direct)\n\t\treturn buf->queue.direct.buf + (entry * MTHCA_CQ_ENTRY_SIZE);\n\telse\n\t\treturn buf->queue.page_list[entry * MTHCA_CQ_ENTRY_SIZE / PAGE_SIZE].buf\n\t\t\t+ (entry * MTHCA_CQ_ENTRY_SIZE) % PAGE_SIZE;\n}\n\nstatic inline struct mthca_cqe *get_cqe(struct mthca_cq *cq, int entry)\n{\n\treturn get_cqe_from_buf(&cq->buf, entry);\n}\n\nstatic inline struct mthca_cqe *cqe_sw(struct mthca_cqe *cqe)\n{\n\treturn MTHCA_CQ_ENTRY_OWNER_HW & cqe->owner ? NULL : cqe;\n}\n\nstatic inline struct mthca_cqe *next_cqe_sw(struct mthca_cq *cq)\n{\n\treturn cqe_sw(get_cqe(cq, cq->cons_index & cq->ibcq.cqe));\n}\n\nstatic inline void set_cqe_hw(struct mthca_cqe *cqe)\n{\n\tcqe->owner = MTHCA_CQ_ENTRY_OWNER_HW;\n}\n\nstatic void dump_cqe(struct mthca_dev *dev, void *cqe_ptr)\n{\n\t__be32 *cqe = cqe_ptr;\n\n\t(void) cqe;\t \n\tmthca_dbg(dev, \"CQE contents %08x %08x %08x %08x %08x %08x %08x %08x\\n\",\n\t\t  be32_to_cpu(cqe[0]), be32_to_cpu(cqe[1]), be32_to_cpu(cqe[2]),\n\t\t  be32_to_cpu(cqe[3]), be32_to_cpu(cqe[4]), be32_to_cpu(cqe[5]),\n\t\t  be32_to_cpu(cqe[6]), be32_to_cpu(cqe[7]));\n}\n\n \nstatic inline void update_cons_index(struct mthca_dev *dev, struct mthca_cq *cq,\n\t\t\t\t     int incr)\n{\n\tif (mthca_is_memfree(dev)) {\n\t\t*cq->set_ci_db = cpu_to_be32(cq->cons_index);\n\t\twmb();\n\t} else {\n\t\tmthca_write64(MTHCA_TAVOR_CQ_DB_INC_CI | cq->cqn, incr - 1,\n\t\t\t      dev->kar + MTHCA_CQ_DOORBELL,\n\t\t\t      MTHCA_GET_DOORBELL_LOCK(&dev->doorbell_lock));\n\t}\n}\n\nvoid mthca_cq_completion(struct mthca_dev *dev, u32 cqn)\n{\n\tstruct mthca_cq *cq;\n\n\tcq = mthca_array_get(&dev->cq_table.cq, cqn & (dev->limits.num_cqs - 1));\n\n\tif (!cq) {\n\t\tmthca_warn(dev, \"Completion event for bogus CQ %08x\\n\", cqn);\n\t\treturn;\n\t}\n\n\t++cq->arm_sn;\n\n\tcq->ibcq.comp_handler(&cq->ibcq, cq->ibcq.cq_context);\n}\n\nvoid mthca_cq_event(struct mthca_dev *dev, u32 cqn,\n\t\t    enum ib_event_type event_type)\n{\n\tstruct mthca_cq *cq;\n\tstruct ib_event event;\n\n\tspin_lock(&dev->cq_table.lock);\n\n\tcq = mthca_array_get(&dev->cq_table.cq, cqn & (dev->limits.num_cqs - 1));\n\tif (cq)\n\t\t++cq->refcount;\n\n\tspin_unlock(&dev->cq_table.lock);\n\n\tif (!cq) {\n\t\tmthca_warn(dev, \"Async event for bogus CQ %08x\\n\", cqn);\n\t\treturn;\n\t}\n\n\tevent.device      = &dev->ib_dev;\n\tevent.event       = event_type;\n\tevent.element.cq  = &cq->ibcq;\n\tif (cq->ibcq.event_handler)\n\t\tcq->ibcq.event_handler(&event, cq->ibcq.cq_context);\n\n\tspin_lock(&dev->cq_table.lock);\n\tif (!--cq->refcount)\n\t\twake_up(&cq->wait);\n\tspin_unlock(&dev->cq_table.lock);\n}\n\nstatic inline int is_recv_cqe(struct mthca_cqe *cqe)\n{\n\tif ((cqe->opcode & MTHCA_ERROR_CQE_OPCODE_MASK) ==\n\t    MTHCA_ERROR_CQE_OPCODE_MASK)\n\t\treturn !(cqe->opcode & 0x01);\n\telse\n\t\treturn !(cqe->is_send & 0x80);\n}\n\nvoid mthca_cq_clean(struct mthca_dev *dev, struct mthca_cq *cq, u32 qpn,\n\t\t    struct mthca_srq *srq)\n{\n\tstruct mthca_cqe *cqe;\n\tu32 prod_index;\n\tint i, nfreed = 0;\n\n\tspin_lock_irq(&cq->lock);\n\n\t \n\tfor (prod_index = cq->cons_index;\n\t     cqe_sw(get_cqe(cq, prod_index & cq->ibcq.cqe));\n\t     ++prod_index)\n\t\tif (prod_index == cq->cons_index + cq->ibcq.cqe)\n\t\t\tbreak;\n\n\tif (0)\n\t\tmthca_dbg(dev, \"Cleaning QPN %06x from CQN %06x; ci %d, pi %d\\n\",\n\t\t\t  qpn, cq->cqn, cq->cons_index, prod_index);\n\n\t \n\twhile ((int) --prod_index - (int) cq->cons_index >= 0) {\n\t\tcqe = get_cqe(cq, prod_index & cq->ibcq.cqe);\n\t\tif (cqe->my_qpn == cpu_to_be32(qpn)) {\n\t\t\tif (srq && is_recv_cqe(cqe))\n\t\t\t\tmthca_free_srq_wqe(srq, be32_to_cpu(cqe->wqe));\n\t\t\t++nfreed;\n\t\t} else if (nfreed)\n\t\t\tmemcpy(get_cqe(cq, (prod_index + nfreed) & cq->ibcq.cqe),\n\t\t\t       cqe, MTHCA_CQ_ENTRY_SIZE);\n\t}\n\n\tif (nfreed) {\n\t\tfor (i = 0; i < nfreed; ++i)\n\t\t\tset_cqe_hw(get_cqe(cq, (cq->cons_index + i) & cq->ibcq.cqe));\n\t\twmb();\n\t\tcq->cons_index += nfreed;\n\t\tupdate_cons_index(dev, cq, nfreed);\n\t}\n\n\tspin_unlock_irq(&cq->lock);\n}\n\nvoid mthca_cq_resize_copy_cqes(struct mthca_cq *cq)\n{\n\tint i;\n\n\t \n\tif (!mthca_is_memfree(to_mdev(cq->ibcq.device)) &&\n\t    cq->ibcq.cqe < cq->resize_buf->cqe) {\n\t\tcq->cons_index &= cq->ibcq.cqe;\n\t\tif (cqe_sw(get_cqe(cq, cq->ibcq.cqe)))\n\t\t\tcq->cons_index -= cq->ibcq.cqe + 1;\n\t}\n\n\tfor (i = cq->cons_index; cqe_sw(get_cqe(cq, i & cq->ibcq.cqe)); ++i)\n\t\tmemcpy(get_cqe_from_buf(&cq->resize_buf->buf,\n\t\t\t\t\ti & cq->resize_buf->cqe),\n\t\t       get_cqe(cq, i & cq->ibcq.cqe), MTHCA_CQ_ENTRY_SIZE);\n}\n\nint mthca_alloc_cq_buf(struct mthca_dev *dev, struct mthca_cq_buf *buf, int nent)\n{\n\tint ret;\n\tint i;\n\n\tret = mthca_buf_alloc(dev, nent * MTHCA_CQ_ENTRY_SIZE,\n\t\t\t      MTHCA_MAX_DIRECT_CQ_SIZE,\n\t\t\t      &buf->queue, &buf->is_direct,\n\t\t\t      &dev->driver_pd, 1, &buf->mr);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < nent; ++i)\n\t\tset_cqe_hw(get_cqe_from_buf(buf, i));\n\n\treturn 0;\n}\n\nvoid mthca_free_cq_buf(struct mthca_dev *dev, struct mthca_cq_buf *buf, int cqe)\n{\n\tmthca_buf_free(dev, (cqe + 1) * MTHCA_CQ_ENTRY_SIZE, &buf->queue,\n\t\t       buf->is_direct, &buf->mr);\n}\n\nstatic void handle_error_cqe(struct mthca_dev *dev, struct mthca_cq *cq,\n\t\t\t     struct mthca_qp *qp, int wqe_index, int is_send,\n\t\t\t     struct mthca_err_cqe *cqe,\n\t\t\t     struct ib_wc *entry, int *free_cqe)\n{\n\tint dbd;\n\t__be32 new_wqe;\n\n\tif (cqe->syndrome == SYNDROME_LOCAL_QP_OP_ERR) {\n\t\tmthca_dbg(dev, \"local QP operation err \"\n\t\t\t  \"(QPN %06x, WQE @ %08x, CQN %06x, index %d)\\n\",\n\t\t\t  be32_to_cpu(cqe->my_qpn), be32_to_cpu(cqe->wqe),\n\t\t\t  cq->cqn, cq->cons_index);\n\t\tdump_cqe(dev, cqe);\n\t}\n\n\t \n\tswitch (cqe->syndrome) {\n\tcase SYNDROME_LOCAL_LENGTH_ERR:\n\t\tentry->status = IB_WC_LOC_LEN_ERR;\n\t\tbreak;\n\tcase SYNDROME_LOCAL_QP_OP_ERR:\n\t\tentry->status = IB_WC_LOC_QP_OP_ERR;\n\t\tbreak;\n\tcase SYNDROME_LOCAL_EEC_OP_ERR:\n\t\tentry->status = IB_WC_LOC_EEC_OP_ERR;\n\t\tbreak;\n\tcase SYNDROME_LOCAL_PROT_ERR:\n\t\tentry->status = IB_WC_LOC_PROT_ERR;\n\t\tbreak;\n\tcase SYNDROME_WR_FLUSH_ERR:\n\t\tentry->status = IB_WC_WR_FLUSH_ERR;\n\t\tbreak;\n\tcase SYNDROME_MW_BIND_ERR:\n\t\tentry->status = IB_WC_MW_BIND_ERR;\n\t\tbreak;\n\tcase SYNDROME_BAD_RESP_ERR:\n\t\tentry->status = IB_WC_BAD_RESP_ERR;\n\t\tbreak;\n\tcase SYNDROME_LOCAL_ACCESS_ERR:\n\t\tentry->status = IB_WC_LOC_ACCESS_ERR;\n\t\tbreak;\n\tcase SYNDROME_REMOTE_INVAL_REQ_ERR:\n\t\tentry->status = IB_WC_REM_INV_REQ_ERR;\n\t\tbreak;\n\tcase SYNDROME_REMOTE_ACCESS_ERR:\n\t\tentry->status = IB_WC_REM_ACCESS_ERR;\n\t\tbreak;\n\tcase SYNDROME_REMOTE_OP_ERR:\n\t\tentry->status = IB_WC_REM_OP_ERR;\n\t\tbreak;\n\tcase SYNDROME_RETRY_EXC_ERR:\n\t\tentry->status = IB_WC_RETRY_EXC_ERR;\n\t\tbreak;\n\tcase SYNDROME_RNR_RETRY_EXC_ERR:\n\t\tentry->status = IB_WC_RNR_RETRY_EXC_ERR;\n\t\tbreak;\n\tcase SYNDROME_LOCAL_RDD_VIOL_ERR:\n\t\tentry->status = IB_WC_LOC_RDD_VIOL_ERR;\n\t\tbreak;\n\tcase SYNDROME_REMOTE_INVAL_RD_REQ_ERR:\n\t\tentry->status = IB_WC_REM_INV_RD_REQ_ERR;\n\t\tbreak;\n\tcase SYNDROME_REMOTE_ABORTED_ERR:\n\t\tentry->status = IB_WC_REM_ABORT_ERR;\n\t\tbreak;\n\tcase SYNDROME_INVAL_EECN_ERR:\n\t\tentry->status = IB_WC_INV_EECN_ERR;\n\t\tbreak;\n\tcase SYNDROME_INVAL_EEC_STATE_ERR:\n\t\tentry->status = IB_WC_INV_EEC_STATE_ERR;\n\t\tbreak;\n\tdefault:\n\t\tentry->status = IB_WC_GENERAL_ERR;\n\t\tbreak;\n\t}\n\n\tentry->vendor_err = cqe->vendor_err;\n\n\t \n\tif (mthca_is_memfree(dev))\n\t\treturn;\n\n\tmthca_free_err_wqe(dev, qp, is_send, wqe_index, &dbd, &new_wqe);\n\n\t \n\tif (!(new_wqe & cpu_to_be32(0x3f)) || (!cqe->db_cnt && dbd))\n\t\treturn;\n\n\tbe16_add_cpu(&cqe->db_cnt, -dbd);\n\tcqe->wqe      = new_wqe;\n\tcqe->syndrome = SYNDROME_WR_FLUSH_ERR;\n\n\t*free_cqe = 0;\n}\n\nstatic inline int mthca_poll_one(struct mthca_dev *dev,\n\t\t\t\t struct mthca_cq *cq,\n\t\t\t\t struct mthca_qp **cur_qp,\n\t\t\t\t int *freed,\n\t\t\t\t struct ib_wc *entry)\n{\n\tstruct mthca_wq *wq;\n\tstruct mthca_cqe *cqe;\n\tint wqe_index;\n\tint is_error;\n\tint is_send;\n\tint free_cqe = 1;\n\tint err = 0;\n\tu16 checksum;\n\n\tcqe = next_cqe_sw(cq);\n\tif (!cqe)\n\t\treturn -EAGAIN;\n\n\t \n\trmb();\n\n\tif (0) {\n\t\tmthca_dbg(dev, \"%x/%d: CQE -> QPN %06x, WQE @ %08x\\n\",\n\t\t\t  cq->cqn, cq->cons_index, be32_to_cpu(cqe->my_qpn),\n\t\t\t  be32_to_cpu(cqe->wqe));\n\t\tdump_cqe(dev, cqe);\n\t}\n\n\tis_error = (cqe->opcode & MTHCA_ERROR_CQE_OPCODE_MASK) ==\n\t\tMTHCA_ERROR_CQE_OPCODE_MASK;\n\tis_send  = is_error ? cqe->opcode & 0x01 : cqe->is_send & 0x80;\n\n\tif (!*cur_qp || be32_to_cpu(cqe->my_qpn) != (*cur_qp)->qpn) {\n\t\t \n\t\t*cur_qp = mthca_array_get(&dev->qp_table.qp,\n\t\t\t\t\t  be32_to_cpu(cqe->my_qpn) &\n\t\t\t\t\t  (dev->limits.num_qps - 1));\n\t\tif (!*cur_qp) {\n\t\t\tmthca_warn(dev, \"CQ entry for unknown QP %06x\\n\",\n\t\t\t\t   be32_to_cpu(cqe->my_qpn) & 0xffffff);\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tentry->qp = &(*cur_qp)->ibqp;\n\n\tif (is_send) {\n\t\twq = &(*cur_qp)->sq;\n\t\twqe_index = ((be32_to_cpu(cqe->wqe) - (*cur_qp)->send_wqe_offset)\n\t\t\t     >> wq->wqe_shift);\n\t\tentry->wr_id = (*cur_qp)->wrid[wqe_index +\n\t\t\t\t\t       (*cur_qp)->rq.max];\n\t} else if ((*cur_qp)->ibqp.srq) {\n\t\tstruct mthca_srq *srq = to_msrq((*cur_qp)->ibqp.srq);\n\t\tu32 wqe = be32_to_cpu(cqe->wqe);\n\t\twq = NULL;\n\t\twqe_index = wqe >> srq->wqe_shift;\n\t\tentry->wr_id = srq->wrid[wqe_index];\n\t\tmthca_free_srq_wqe(srq, wqe);\n\t} else {\n\t\ts32 wqe;\n\t\twq = &(*cur_qp)->rq;\n\t\twqe = be32_to_cpu(cqe->wqe);\n\t\twqe_index = wqe >> wq->wqe_shift;\n\t\t \n\t\tif (unlikely(wqe_index < 0))\n\t\t\twqe_index = wq->max - 1;\n\t\tentry->wr_id = (*cur_qp)->wrid[wqe_index];\n\t}\n\n\tif (wq) {\n\t\tif (wq->last_comp < wqe_index)\n\t\t\twq->tail += wqe_index - wq->last_comp;\n\t\telse\n\t\t\twq->tail += wqe_index + wq->max - wq->last_comp;\n\n\t\twq->last_comp = wqe_index;\n\t}\n\n\tif (is_error) {\n\t\thandle_error_cqe(dev, cq, *cur_qp, wqe_index, is_send,\n\t\t\t\t (struct mthca_err_cqe *) cqe,\n\t\t\t\t entry, &free_cqe);\n\t\tgoto out;\n\t}\n\n\tif (is_send) {\n\t\tentry->wc_flags = 0;\n\t\tswitch (cqe->opcode) {\n\t\tcase MTHCA_OPCODE_RDMA_WRITE:\n\t\t\tentry->opcode    = IB_WC_RDMA_WRITE;\n\t\t\tbreak;\n\t\tcase MTHCA_OPCODE_RDMA_WRITE_IMM:\n\t\t\tentry->opcode    = IB_WC_RDMA_WRITE;\n\t\t\tentry->wc_flags |= IB_WC_WITH_IMM;\n\t\t\tbreak;\n\t\tcase MTHCA_OPCODE_SEND:\n\t\t\tentry->opcode    = IB_WC_SEND;\n\t\t\tbreak;\n\t\tcase MTHCA_OPCODE_SEND_IMM:\n\t\t\tentry->opcode    = IB_WC_SEND;\n\t\t\tentry->wc_flags |= IB_WC_WITH_IMM;\n\t\t\tbreak;\n\t\tcase MTHCA_OPCODE_RDMA_READ:\n\t\t\tentry->opcode    = IB_WC_RDMA_READ;\n\t\t\tentry->byte_len  = be32_to_cpu(cqe->byte_cnt);\n\t\t\tbreak;\n\t\tcase MTHCA_OPCODE_ATOMIC_CS:\n\t\t\tentry->opcode    = IB_WC_COMP_SWAP;\n\t\t\tentry->byte_len  = MTHCA_ATOMIC_BYTE_LEN;\n\t\t\tbreak;\n\t\tcase MTHCA_OPCODE_ATOMIC_FA:\n\t\t\tentry->opcode    = IB_WC_FETCH_ADD;\n\t\t\tentry->byte_len  = MTHCA_ATOMIC_BYTE_LEN;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tentry->opcode = 0xFF;\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tentry->byte_len = be32_to_cpu(cqe->byte_cnt);\n\t\tswitch (cqe->opcode & 0x1f) {\n\t\tcase IB_OPCODE_SEND_LAST_WITH_IMMEDIATE:\n\t\tcase IB_OPCODE_SEND_ONLY_WITH_IMMEDIATE:\n\t\t\tentry->wc_flags = IB_WC_WITH_IMM;\n\t\t\tentry->ex.imm_data = cqe->imm_etype_pkey_eec;\n\t\t\tentry->opcode = IB_WC_RECV;\n\t\t\tbreak;\n\t\tcase IB_OPCODE_RDMA_WRITE_LAST_WITH_IMMEDIATE:\n\t\tcase IB_OPCODE_RDMA_WRITE_ONLY_WITH_IMMEDIATE:\n\t\t\tentry->wc_flags = IB_WC_WITH_IMM;\n\t\t\tentry->ex.imm_data = cqe->imm_etype_pkey_eec;\n\t\t\tentry->opcode = IB_WC_RECV_RDMA_WITH_IMM;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tentry->wc_flags = 0;\n\t\t\tentry->opcode = IB_WC_RECV;\n\t\t\tbreak;\n\t\t}\n\t\tentry->slid \t   = be16_to_cpu(cqe->rlid);\n\t\tentry->sl   \t   = cqe->sl_ipok >> 4;\n\t\tentry->src_qp \t   = be32_to_cpu(cqe->rqpn) & 0xffffff;\n\t\tentry->dlid_path_bits = cqe->g_mlpath & 0x7f;\n\t\tentry->pkey_index  = be32_to_cpu(cqe->imm_etype_pkey_eec) >> 16;\n\t\tentry->wc_flags   |= cqe->g_mlpath & 0x80 ? IB_WC_GRH : 0;\n\t\tchecksum = (be32_to_cpu(cqe->rqpn) >> 24) |\n\t\t\t\t((be32_to_cpu(cqe->my_ee) >> 16) & 0xff00);\n\t\tentry->wc_flags\t  |=  (cqe->sl_ipok & 1 && checksum == 0xffff) ?\n\t\t\t\t\t\t\tIB_WC_IP_CSUM_OK : 0;\n\t}\n\n\tentry->status = IB_WC_SUCCESS;\n\n out:\n\tif (likely(free_cqe)) {\n\t\tset_cqe_hw(cqe);\n\t\t++(*freed);\n\t\t++cq->cons_index;\n\t}\n\n\treturn err;\n}\n\nint mthca_poll_cq(struct ib_cq *ibcq, int num_entries,\n\t\t  struct ib_wc *entry)\n{\n\tstruct mthca_dev *dev = to_mdev(ibcq->device);\n\tstruct mthca_cq *cq = to_mcq(ibcq);\n\tstruct mthca_qp *qp = NULL;\n\tunsigned long flags;\n\tint err = 0;\n\tint freed = 0;\n\tint npolled;\n\n\tspin_lock_irqsave(&cq->lock, flags);\n\n\tnpolled = 0;\nrepoll:\n\twhile (npolled < num_entries) {\n\t\terr = mthca_poll_one(dev, cq, &qp,\n\t\t\t\t     &freed, entry + npolled);\n\t\tif (err)\n\t\t\tbreak;\n\t\t++npolled;\n\t}\n\n\tif (freed) {\n\t\twmb();\n\t\tupdate_cons_index(dev, cq, freed);\n\t}\n\n\t \n\tif (unlikely(err == -EAGAIN && cq->resize_buf &&\n\t\t     cq->resize_buf->state == CQ_RESIZE_READY)) {\n\t\t \n\t\tif (!mthca_is_memfree(dev))\n\t\t\tcq->cons_index &= cq->ibcq.cqe;\n\n\t\tif (cqe_sw(get_cqe_from_buf(&cq->resize_buf->buf,\n\t\t\t\t\t    cq->cons_index & cq->resize_buf->cqe))) {\n\t\t\tstruct mthca_cq_buf tbuf;\n\t\t\tint tcqe;\n\n\t\t\ttbuf         = cq->buf;\n\t\t\ttcqe         = cq->ibcq.cqe;\n\t\t\tcq->buf      = cq->resize_buf->buf;\n\t\t\tcq->ibcq.cqe = cq->resize_buf->cqe;\n\n\t\t\tcq->resize_buf->buf   = tbuf;\n\t\t\tcq->resize_buf->cqe   = tcqe;\n\t\t\tcq->resize_buf->state = CQ_RESIZE_SWAPPED;\n\n\t\t\tgoto repoll;\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&cq->lock, flags);\n\n\treturn err == 0 || err == -EAGAIN ? npolled : err;\n}\n\nint mthca_tavor_arm_cq(struct ib_cq *cq, enum ib_cq_notify_flags flags)\n{\n\tu32 dbhi = ((flags & IB_CQ_SOLICITED_MASK) == IB_CQ_SOLICITED ?\n\t\t    MTHCA_TAVOR_CQ_DB_REQ_NOT_SOL :\n\t\t    MTHCA_TAVOR_CQ_DB_REQ_NOT) |\n\t\tto_mcq(cq)->cqn;\n\n\tmthca_write64(dbhi, 0xffffffff, to_mdev(cq->device)->kar + MTHCA_CQ_DOORBELL,\n\t\t      MTHCA_GET_DOORBELL_LOCK(&to_mdev(cq->device)->doorbell_lock));\n\n\treturn 0;\n}\n\nint mthca_arbel_arm_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags flags)\n{\n\tstruct mthca_cq *cq = to_mcq(ibcq);\n\t__be32 db_rec[2];\n\tu32 dbhi;\n\tu32 sn = cq->arm_sn & 3;\n\n\tdb_rec[0] = cpu_to_be32(cq->cons_index);\n\tdb_rec[1] = cpu_to_be32((cq->cqn << 8) | (2 << 5) | (sn << 3) |\n\t\t\t\t((flags & IB_CQ_SOLICITED_MASK) ==\n\t\t\t\t IB_CQ_SOLICITED ? 1 : 2));\n\n\tmthca_write_db_rec(db_rec, cq->arm_db);\n\n\t \n\twmb();\n\n\tdbhi = (sn << 28) |\n\t\t((flags & IB_CQ_SOLICITED_MASK) == IB_CQ_SOLICITED ?\n\t\t MTHCA_ARBEL_CQ_DB_REQ_NOT_SOL :\n\t\t MTHCA_ARBEL_CQ_DB_REQ_NOT) | cq->cqn;\n\n\tmthca_write64(dbhi, cq->cons_index,\n\t\t      to_mdev(ibcq->device)->kar + MTHCA_CQ_DOORBELL,\n\t\t      MTHCA_GET_DOORBELL_LOCK(&to_mdev(ibcq->device)->doorbell_lock));\n\n\treturn 0;\n}\n\nint mthca_init_cq(struct mthca_dev *dev, int nent,\n\t\t  struct mthca_ucontext *ctx, u32 pdn,\n\t\t  struct mthca_cq *cq)\n{\n\tstruct mthca_mailbox *mailbox;\n\tstruct mthca_cq_context *cq_context;\n\tint err = -ENOMEM;\n\n\tcq->ibcq.cqe  = nent - 1;\n\tcq->is_kernel = !ctx;\n\n\tcq->cqn = mthca_alloc(&dev->cq_table.alloc);\n\tif (cq->cqn == -1)\n\t\treturn -ENOMEM;\n\n\tif (mthca_is_memfree(dev)) {\n\t\terr = mthca_table_get(dev, dev->cq_table.table, cq->cqn);\n\t\tif (err)\n\t\t\tgoto err_out;\n\n\t\tif (cq->is_kernel) {\n\t\t\tcq->arm_sn = 1;\n\n\t\t\terr = -ENOMEM;\n\n\t\t\tcq->set_ci_db_index = mthca_alloc_db(dev, MTHCA_DB_TYPE_CQ_SET_CI,\n\t\t\t\t\t\t\t     cq->cqn, &cq->set_ci_db);\n\t\t\tif (cq->set_ci_db_index < 0)\n\t\t\t\tgoto err_out_icm;\n\n\t\t\tcq->arm_db_index = mthca_alloc_db(dev, MTHCA_DB_TYPE_CQ_ARM,\n\t\t\t\t\t\t\t  cq->cqn, &cq->arm_db);\n\t\t\tif (cq->arm_db_index < 0)\n\t\t\t\tgoto err_out_ci;\n\t\t}\n\t}\n\n\tmailbox = mthca_alloc_mailbox(dev, GFP_KERNEL);\n\tif (IS_ERR(mailbox)) {\n\t\terr = PTR_ERR(mailbox);\n\t\tgoto err_out_arm;\n\t}\n\n\tcq_context = mailbox->buf;\n\n\tif (cq->is_kernel) {\n\t\terr = mthca_alloc_cq_buf(dev, &cq->buf, nent);\n\t\tif (err)\n\t\t\tgoto err_out_mailbox;\n\t}\n\n\tspin_lock_init(&cq->lock);\n\tcq->refcount = 1;\n\tinit_waitqueue_head(&cq->wait);\n\tmutex_init(&cq->mutex);\n\n\tmemset(cq_context, 0, sizeof *cq_context);\n\tcq_context->flags           = cpu_to_be32(MTHCA_CQ_STATUS_OK      |\n\t\t\t\t\t\t  MTHCA_CQ_STATE_DISARMED |\n\t\t\t\t\t\t  MTHCA_CQ_FLAG_TR);\n\tcq_context->logsize_usrpage = cpu_to_be32((ffs(nent) - 1) << 24);\n\tif (ctx)\n\t\tcq_context->logsize_usrpage |= cpu_to_be32(ctx->uar.index);\n\telse\n\t\tcq_context->logsize_usrpage |= cpu_to_be32(dev->driver_uar.index);\n\tcq_context->error_eqn       = cpu_to_be32(dev->eq_table.eq[MTHCA_EQ_ASYNC].eqn);\n\tcq_context->comp_eqn        = cpu_to_be32(dev->eq_table.eq[MTHCA_EQ_COMP].eqn);\n\tcq_context->pd              = cpu_to_be32(pdn);\n\tcq_context->lkey            = cpu_to_be32(cq->buf.mr.ibmr.lkey);\n\tcq_context->cqn             = cpu_to_be32(cq->cqn);\n\n\tif (mthca_is_memfree(dev)) {\n\t\tcq_context->ci_db    = cpu_to_be32(cq->set_ci_db_index);\n\t\tcq_context->state_db = cpu_to_be32(cq->arm_db_index);\n\t}\n\n\terr = mthca_SW2HW_CQ(dev, mailbox, cq->cqn);\n\tif (err) {\n\t\tmthca_warn(dev, \"SW2HW_CQ failed (%d)\\n\", err);\n\t\tgoto err_out_free_mr;\n\t}\n\n\tspin_lock_irq(&dev->cq_table.lock);\n\terr = mthca_array_set(&dev->cq_table.cq,\n\t\t\t      cq->cqn & (dev->limits.num_cqs - 1), cq);\n\tif (err) {\n\t\tspin_unlock_irq(&dev->cq_table.lock);\n\t\tgoto err_out_free_mr;\n\t}\n\tspin_unlock_irq(&dev->cq_table.lock);\n\n\tcq->cons_index = 0;\n\n\tmthca_free_mailbox(dev, mailbox);\n\n\treturn 0;\n\nerr_out_free_mr:\n\tif (cq->is_kernel)\n\t\tmthca_free_cq_buf(dev, &cq->buf, cq->ibcq.cqe);\n\nerr_out_mailbox:\n\tmthca_free_mailbox(dev, mailbox);\n\nerr_out_arm:\n\tif (cq->is_kernel && mthca_is_memfree(dev))\n\t\tmthca_free_db(dev, MTHCA_DB_TYPE_CQ_ARM, cq->arm_db_index);\n\nerr_out_ci:\n\tif (cq->is_kernel && mthca_is_memfree(dev))\n\t\tmthca_free_db(dev, MTHCA_DB_TYPE_CQ_SET_CI, cq->set_ci_db_index);\n\nerr_out_icm:\n\tmthca_table_put(dev, dev->cq_table.table, cq->cqn);\n\nerr_out:\n\tmthca_free(&dev->cq_table.alloc, cq->cqn);\n\n\treturn err;\n}\n\nstatic inline int get_cq_refcount(struct mthca_dev *dev, struct mthca_cq *cq)\n{\n\tint c;\n\n\tspin_lock_irq(&dev->cq_table.lock);\n\tc = cq->refcount;\n\tspin_unlock_irq(&dev->cq_table.lock);\n\n\treturn c;\n}\n\nvoid mthca_free_cq(struct mthca_dev *dev,\n\t\t   struct mthca_cq *cq)\n{\n\tstruct mthca_mailbox *mailbox;\n\tint err;\n\n\tmailbox = mthca_alloc_mailbox(dev, GFP_KERNEL);\n\tif (IS_ERR(mailbox)) {\n\t\tmthca_warn(dev, \"No memory for mailbox to free CQ.\\n\");\n\t\treturn;\n\t}\n\n\terr = mthca_HW2SW_CQ(dev, mailbox, cq->cqn);\n\tif (err)\n\t\tmthca_warn(dev, \"HW2SW_CQ failed (%d)\\n\", err);\n\n\tif (0) {\n\t\t__be32 *ctx = mailbox->buf;\n\t\tint j;\n\n\t\tprintk(KERN_ERR \"context for CQN %x (cons index %x, next sw %d)\\n\",\n\t\t       cq->cqn, cq->cons_index,\n\t\t       cq->is_kernel ? !!next_cqe_sw(cq) : 0);\n\t\tfor (j = 0; j < 16; ++j)\n\t\t\tprintk(KERN_ERR \"[%2x] %08x\\n\", j * 4, be32_to_cpu(ctx[j]));\n\t}\n\n\tspin_lock_irq(&dev->cq_table.lock);\n\tmthca_array_clear(&dev->cq_table.cq,\n\t\t\t  cq->cqn & (dev->limits.num_cqs - 1));\n\t--cq->refcount;\n\tspin_unlock_irq(&dev->cq_table.lock);\n\n\tif (dev->mthca_flags & MTHCA_FLAG_MSI_X)\n\t\tsynchronize_irq(dev->eq_table.eq[MTHCA_EQ_COMP].msi_x_vector);\n\telse\n\t\tsynchronize_irq(dev->pdev->irq);\n\n\twait_event(cq->wait, !get_cq_refcount(dev, cq));\n\n\tif (cq->is_kernel) {\n\t\tmthca_free_cq_buf(dev, &cq->buf, cq->ibcq.cqe);\n\t\tif (mthca_is_memfree(dev)) {\n\t\t\tmthca_free_db(dev, MTHCA_DB_TYPE_CQ_ARM,    cq->arm_db_index);\n\t\t\tmthca_free_db(dev, MTHCA_DB_TYPE_CQ_SET_CI, cq->set_ci_db_index);\n\t\t}\n\t}\n\n\tmthca_table_put(dev, dev->cq_table.table, cq->cqn);\n\tmthca_free(&dev->cq_table.alloc, cq->cqn);\n\tmthca_free_mailbox(dev, mailbox);\n}\n\nint mthca_init_cq_table(struct mthca_dev *dev)\n{\n\tint err;\n\n\tspin_lock_init(&dev->cq_table.lock);\n\n\terr = mthca_alloc_init(&dev->cq_table.alloc,\n\t\t\t       dev->limits.num_cqs,\n\t\t\t       (1 << 24) - 1,\n\t\t\t       dev->limits.reserved_cqs);\n\tif (err)\n\t\treturn err;\n\n\terr = mthca_array_init(&dev->cq_table.cq,\n\t\t\t       dev->limits.num_cqs);\n\tif (err)\n\t\tmthca_alloc_cleanup(&dev->cq_table.alloc);\n\n\treturn err;\n}\n\nvoid mthca_cleanup_cq_table(struct mthca_dev *dev)\n{\n\tmthca_array_cleanup(&dev->cq_table.cq, dev->limits.num_cqs);\n\tmthca_alloc_cleanup(&dev->cq_table.alloc);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}