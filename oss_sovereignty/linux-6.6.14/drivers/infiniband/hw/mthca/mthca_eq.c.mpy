{
  "module_name": "mthca_eq.c",
  "hash_id": "f6fe01eb5588ac44463d8daecbf3d84a98a5094354f387a29e6d983eba181ce7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mthca/mthca_eq.c",
  "human_readable_source": " \n\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n\n#include \"mthca_dev.h\"\n#include \"mthca_cmd.h\"\n#include \"mthca_config_reg.h\"\n\nenum {\n\tMTHCA_NUM_ASYNC_EQE = 0x80,\n\tMTHCA_NUM_CMD_EQE   = 0x80,\n\tMTHCA_NUM_SPARE_EQE = 0x80,\n\tMTHCA_EQ_ENTRY_SIZE = 0x20\n};\n\n \nstruct mthca_eq_context {\n\t__be32 flags;\n\t__be64 start;\n\t__be32 logsize_usrpage;\n\t__be32 tavor_pd;\t \n\tu8     reserved1[3];\n\tu8     intr;\n\t__be32 arbel_pd;\t \n\t__be32 lkey;\n\tu32    reserved2[2];\n\t__be32 consumer_index;\n\t__be32 producer_index;\n\tu32    reserved3[4];\n} __packed;\n\n#define MTHCA_EQ_STATUS_OK          ( 0 << 28)\n#define MTHCA_EQ_STATUS_OVERFLOW    ( 9 << 28)\n#define MTHCA_EQ_STATUS_WRITE_FAIL  (10 << 28)\n#define MTHCA_EQ_OWNER_SW           ( 0 << 24)\n#define MTHCA_EQ_OWNER_HW           ( 1 << 24)\n#define MTHCA_EQ_FLAG_TR            ( 1 << 18)\n#define MTHCA_EQ_FLAG_OI            ( 1 << 17)\n#define MTHCA_EQ_STATE_ARMED        ( 1 <<  8)\n#define MTHCA_EQ_STATE_FIRED        ( 2 <<  8)\n#define MTHCA_EQ_STATE_ALWAYS_ARMED ( 3 <<  8)\n#define MTHCA_EQ_STATE_ARBEL        ( 8 <<  8)\n\nenum {\n\tMTHCA_EVENT_TYPE_COMP       \t    = 0x00,\n\tMTHCA_EVENT_TYPE_PATH_MIG   \t    = 0x01,\n\tMTHCA_EVENT_TYPE_COMM_EST   \t    = 0x02,\n\tMTHCA_EVENT_TYPE_SQ_DRAINED \t    = 0x03,\n\tMTHCA_EVENT_TYPE_SRQ_QP_LAST_WQE    = 0x13,\n\tMTHCA_EVENT_TYPE_SRQ_LIMIT\t    = 0x14,\n\tMTHCA_EVENT_TYPE_CQ_ERROR   \t    = 0x04,\n\tMTHCA_EVENT_TYPE_WQ_CATAS_ERROR     = 0x05,\n\tMTHCA_EVENT_TYPE_EEC_CATAS_ERROR    = 0x06,\n\tMTHCA_EVENT_TYPE_PATH_MIG_FAILED    = 0x07,\n\tMTHCA_EVENT_TYPE_WQ_INVAL_REQ_ERROR = 0x10,\n\tMTHCA_EVENT_TYPE_WQ_ACCESS_ERROR    = 0x11,\n\tMTHCA_EVENT_TYPE_SRQ_CATAS_ERROR    = 0x12,\n\tMTHCA_EVENT_TYPE_LOCAL_CATAS_ERROR  = 0x08,\n\tMTHCA_EVENT_TYPE_PORT_CHANGE        = 0x09,\n\tMTHCA_EVENT_TYPE_EQ_OVERFLOW        = 0x0f,\n\tMTHCA_EVENT_TYPE_ECC_DETECT         = 0x0e,\n\tMTHCA_EVENT_TYPE_CMD                = 0x0a\n};\n\n#define MTHCA_ASYNC_EVENT_MASK ((1ULL << MTHCA_EVENT_TYPE_PATH_MIG)           | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_COMM_EST)           | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_SQ_DRAINED)         | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_CQ_ERROR)           | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_WQ_CATAS_ERROR)     | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_EEC_CATAS_ERROR)    | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_PATH_MIG_FAILED)    | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_WQ_INVAL_REQ_ERROR) | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_WQ_ACCESS_ERROR)    | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_LOCAL_CATAS_ERROR)  | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_PORT_CHANGE)        | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_ECC_DETECT))\n#define MTHCA_SRQ_EVENT_MASK   ((1ULL << MTHCA_EVENT_TYPE_SRQ_CATAS_ERROR)    | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_SRQ_QP_LAST_WQE)    | \\\n\t\t\t\t(1ULL << MTHCA_EVENT_TYPE_SRQ_LIMIT))\n#define MTHCA_CMD_EVENT_MASK    (1ULL << MTHCA_EVENT_TYPE_CMD)\n\n#define MTHCA_EQ_DB_INC_CI     (1 << 24)\n#define MTHCA_EQ_DB_REQ_NOT    (2 << 24)\n#define MTHCA_EQ_DB_DISARM_CQ  (3 << 24)\n#define MTHCA_EQ_DB_SET_CI     (4 << 24)\n#define MTHCA_EQ_DB_ALWAYS_ARM (5 << 24)\n\nstruct mthca_eqe {\n\tu8 reserved1;\n\tu8 type;\n\tu8 reserved2;\n\tu8 subtype;\n\tunion {\n\t\tu32 raw[6];\n\t\tstruct {\n\t\t\t__be32 cqn;\n\t\t} __packed comp;\n\t\tstruct {\n\t\t\tu16    reserved1;\n\t\t\t__be16 token;\n\t\t\tu32    reserved2;\n\t\t\tu8     reserved3[3];\n\t\t\tu8     status;\n\t\t\t__be64 out_param;\n\t\t} __packed cmd;\n\t\tstruct {\n\t\t\t__be32 qpn;\n\t\t} __packed qp;\n\t\tstruct {\n\t\t\t__be32 srqn;\n\t\t} __packed srq;\n\t\tstruct {\n\t\t\t__be32 cqn;\n\t\t\tu32    reserved1;\n\t\t\tu8     reserved2[3];\n\t\t\tu8     syndrome;\n\t\t} __packed cq_err;\n\t\tstruct {\n\t\t\tu32    reserved1[2];\n\t\t\t__be32 port;\n\t\t} __packed port_change;\n\t} event;\n\tu8 reserved3[3];\n\tu8 owner;\n} __packed;\n\n#define  MTHCA_EQ_ENTRY_OWNER_SW      (0 << 7)\n#define  MTHCA_EQ_ENTRY_OWNER_HW      (1 << 7)\n\nstatic inline u64 async_mask(struct mthca_dev *dev)\n{\n\treturn dev->mthca_flags & MTHCA_FLAG_SRQ ?\n\t\tMTHCA_ASYNC_EVENT_MASK | MTHCA_SRQ_EVENT_MASK :\n\t\tMTHCA_ASYNC_EVENT_MASK;\n}\n\nstatic inline void tavor_set_eq_ci(struct mthca_dev *dev, struct mthca_eq *eq, u32 ci)\n{\n\t \n\twmb();\n\tmthca_write64(MTHCA_EQ_DB_SET_CI | eq->eqn, ci & (eq->nent - 1),\n\t\t      dev->kar + MTHCA_EQ_DOORBELL,\n\t\t      MTHCA_GET_DOORBELL_LOCK(&dev->doorbell_lock));\n}\n\nstatic inline void arbel_set_eq_ci(struct mthca_dev *dev, struct mthca_eq *eq, u32 ci)\n{\n\t \n\twmb();\n\t__raw_writel((__force u32) cpu_to_be32(ci),\n\t\t     dev->eq_regs.arbel.eq_set_ci_base + eq->eqn * 8);\n\t \n\tmb();\n}\n\nstatic inline void set_eq_ci(struct mthca_dev *dev, struct mthca_eq *eq, u32 ci)\n{\n\tif (mthca_is_memfree(dev))\n\t\tarbel_set_eq_ci(dev, eq, ci);\n\telse\n\t\ttavor_set_eq_ci(dev, eq, ci);\n}\n\nstatic inline void tavor_eq_req_not(struct mthca_dev *dev, int eqn)\n{\n\tmthca_write64(MTHCA_EQ_DB_REQ_NOT | eqn, 0,\n\t\t      dev->kar + MTHCA_EQ_DOORBELL,\n\t\t      MTHCA_GET_DOORBELL_LOCK(&dev->doorbell_lock));\n}\n\nstatic inline void arbel_eq_req_not(struct mthca_dev *dev, u32 eqn_mask)\n{\n\twritel(eqn_mask, dev->eq_regs.arbel.eq_arm);\n}\n\nstatic inline void disarm_cq(struct mthca_dev *dev, int eqn, int cqn)\n{\n\tif (!mthca_is_memfree(dev)) {\n\t\tmthca_write64(MTHCA_EQ_DB_DISARM_CQ | eqn, cqn,\n\t\t\t      dev->kar + MTHCA_EQ_DOORBELL,\n\t\t\t      MTHCA_GET_DOORBELL_LOCK(&dev->doorbell_lock));\n\t}\n}\n\nstatic inline struct mthca_eqe *get_eqe(struct mthca_eq *eq, u32 entry)\n{\n\tunsigned long off = (entry & (eq->nent - 1)) * MTHCA_EQ_ENTRY_SIZE;\n\treturn eq->page_list[off / PAGE_SIZE].buf + off % PAGE_SIZE;\n}\n\nstatic inline struct mthca_eqe *next_eqe_sw(struct mthca_eq *eq)\n{\n\tstruct mthca_eqe *eqe;\n\teqe = get_eqe(eq, eq->cons_index);\n\treturn (MTHCA_EQ_ENTRY_OWNER_HW & eqe->owner) ? NULL : eqe;\n}\n\nstatic inline void set_eqe_hw(struct mthca_eqe *eqe)\n{\n\teqe->owner =  MTHCA_EQ_ENTRY_OWNER_HW;\n}\n\nstatic void port_change(struct mthca_dev *dev, int port, int active)\n{\n\tstruct ib_event record;\n\n\tmthca_dbg(dev, \"Port change to %s for port %d\\n\",\n\t\t  active ? \"active\" : \"down\", port);\n\n\trecord.device = &dev->ib_dev;\n\trecord.event  = active ? IB_EVENT_PORT_ACTIVE : IB_EVENT_PORT_ERR;\n\trecord.element.port_num = port;\n\n\tib_dispatch_event(&record);\n}\n\nstatic int mthca_eq_int(struct mthca_dev *dev, struct mthca_eq *eq)\n{\n\tstruct mthca_eqe *eqe;\n\tint disarm_cqn;\n\tint eqes_found = 0;\n\tint set_ci = 0;\n\n\twhile ((eqe = next_eqe_sw(eq))) {\n\t\t \n\t\trmb();\n\n\t\tswitch (eqe->type) {\n\t\tcase MTHCA_EVENT_TYPE_COMP:\n\t\t\tdisarm_cqn = be32_to_cpu(eqe->event.comp.cqn) & 0xffffff;\n\t\t\tdisarm_cq(dev, eq->eqn, disarm_cqn);\n\t\t\tmthca_cq_completion(dev, disarm_cqn);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_PATH_MIG:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_PATH_MIG);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_COMM_EST:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_COMM_EST);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_SQ_DRAINED:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_SQ_DRAINED);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_SRQ_QP_LAST_WQE:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_QP_LAST_WQE_REACHED);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_SRQ_LIMIT:\n\t\t\tmthca_srq_event(dev, be32_to_cpu(eqe->event.srq.srqn) & 0xffffff,\n\t\t\t\t\tIB_EVENT_SRQ_LIMIT_REACHED);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_WQ_CATAS_ERROR:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_QP_FATAL);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_PATH_MIG_FAILED:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_PATH_MIG_ERR);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_WQ_INVAL_REQ_ERROR:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_QP_REQ_ERR);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_WQ_ACCESS_ERROR:\n\t\t\tmthca_qp_event(dev, be32_to_cpu(eqe->event.qp.qpn) & 0xffffff,\n\t\t\t\t       IB_EVENT_QP_ACCESS_ERR);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_CMD:\n\t\t\tmthca_cmd_event(dev,\n\t\t\t\t\tbe16_to_cpu(eqe->event.cmd.token),\n\t\t\t\t\teqe->event.cmd.status,\n\t\t\t\t\tbe64_to_cpu(eqe->event.cmd.out_param));\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_PORT_CHANGE:\n\t\t\tport_change(dev,\n\t\t\t\t    (be32_to_cpu(eqe->event.port_change.port) >> 28) & 3,\n\t\t\t\t    eqe->subtype == 0x4);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_CQ_ERROR:\n\t\t\tmthca_warn(dev, \"CQ %s on CQN %06x\\n\",\n\t\t\t\t   eqe->event.cq_err.syndrome == 1 ?\n\t\t\t\t   \"overrun\" : \"access violation\",\n\t\t\t\t   be32_to_cpu(eqe->event.cq_err.cqn) & 0xffffff);\n\t\t\tmthca_cq_event(dev, be32_to_cpu(eqe->event.cq_err.cqn),\n\t\t\t\t       IB_EVENT_CQ_ERR);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_EQ_OVERFLOW:\n\t\t\tmthca_warn(dev, \"EQ overrun on EQN %d\\n\", eq->eqn);\n\t\t\tbreak;\n\n\t\tcase MTHCA_EVENT_TYPE_EEC_CATAS_ERROR:\n\t\tcase MTHCA_EVENT_TYPE_SRQ_CATAS_ERROR:\n\t\tcase MTHCA_EVENT_TYPE_LOCAL_CATAS_ERROR:\n\t\tcase MTHCA_EVENT_TYPE_ECC_DETECT:\n\t\tdefault:\n\t\t\tmthca_warn(dev, \"Unhandled event %02x(%02x) on EQ %d\\n\",\n\t\t\t\t   eqe->type, eqe->subtype, eq->eqn);\n\t\t\tbreak;\n\t\t}\n\n\t\tset_eqe_hw(eqe);\n\t\t++eq->cons_index;\n\t\teqes_found = 1;\n\t\t++set_ci;\n\n\t\t \n\t\tif (unlikely(set_ci >= MTHCA_NUM_SPARE_EQE)) {\n\t\t\t \n\t\t\tset_eq_ci(dev, eq, eq->cons_index);\n\t\t\tset_ci = 0;\n\t\t}\n\t}\n\n\t \n\treturn eqes_found;\n}\n\nstatic irqreturn_t mthca_tavor_interrupt(int irq, void *dev_ptr)\n{\n\tstruct mthca_dev *dev = dev_ptr;\n\tu32 ecr;\n\tint i;\n\n\tif (dev->eq_table.clr_mask)\n\t\twritel(dev->eq_table.clr_mask, dev->eq_table.clr_int);\n\n\tecr = readl(dev->eq_regs.tavor.ecr_base + 4);\n\tif (!ecr)\n\t\treturn IRQ_NONE;\n\n\twritel(ecr, dev->eq_regs.tavor.ecr_base +\n\t       MTHCA_ECR_CLR_BASE - MTHCA_ECR_BASE + 4);\n\n\tfor (i = 0; i < MTHCA_NUM_EQ; ++i)\n\t\tif (ecr & dev->eq_table.eq[i].eqn_mask) {\n\t\t\tif (mthca_eq_int(dev, &dev->eq_table.eq[i]))\n\t\t\t\ttavor_set_eq_ci(dev, &dev->eq_table.eq[i],\n\t\t\t\t\t\tdev->eq_table.eq[i].cons_index);\n\t\t\ttavor_eq_req_not(dev, dev->eq_table.eq[i].eqn);\n\t\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t mthca_tavor_msi_x_interrupt(int irq, void *eq_ptr)\n{\n\tstruct mthca_eq  *eq  = eq_ptr;\n\tstruct mthca_dev *dev = eq->dev;\n\n\tmthca_eq_int(dev, eq);\n\ttavor_set_eq_ci(dev, eq, eq->cons_index);\n\ttavor_eq_req_not(dev, eq->eqn);\n\n\t \n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t mthca_arbel_interrupt(int irq, void *dev_ptr)\n{\n\tstruct mthca_dev *dev = dev_ptr;\n\tint work = 0;\n\tint i;\n\n\tif (dev->eq_table.clr_mask)\n\t\twritel(dev->eq_table.clr_mask, dev->eq_table.clr_int);\n\n\tfor (i = 0; i < MTHCA_NUM_EQ; ++i)\n\t\tif (mthca_eq_int(dev, &dev->eq_table.eq[i])) {\n\t\t\twork = 1;\n\t\t\tarbel_set_eq_ci(dev, &dev->eq_table.eq[i],\n\t\t\t\t\tdev->eq_table.eq[i].cons_index);\n\t\t}\n\n\tarbel_eq_req_not(dev, dev->eq_table.arm_mask);\n\n\treturn IRQ_RETVAL(work);\n}\n\nstatic irqreturn_t mthca_arbel_msi_x_interrupt(int irq, void *eq_ptr)\n{\n\tstruct mthca_eq  *eq  = eq_ptr;\n\tstruct mthca_dev *dev = eq->dev;\n\n\tmthca_eq_int(dev, eq);\n\tarbel_set_eq_ci(dev, eq, eq->cons_index);\n\tarbel_eq_req_not(dev, eq->eqn_mask);\n\n\t \n\treturn IRQ_HANDLED;\n}\n\nstatic int mthca_create_eq(struct mthca_dev *dev,\n\t\t\t   int nent,\n\t\t\t   u8 intr,\n\t\t\t   struct mthca_eq *eq)\n{\n\tint npages;\n\tu64 *dma_list = NULL;\n\tdma_addr_t t;\n\tstruct mthca_mailbox *mailbox;\n\tstruct mthca_eq_context *eq_context;\n\tint err = -ENOMEM;\n\tint i;\n\n\teq->dev  = dev;\n\teq->nent = roundup_pow_of_two(max(nent, 2));\n\tnpages = ALIGN(eq->nent * MTHCA_EQ_ENTRY_SIZE, PAGE_SIZE) / PAGE_SIZE;\n\n\teq->page_list = kmalloc_array(npages, sizeof(*eq->page_list),\n\t\t\t\t      GFP_KERNEL);\n\tif (!eq->page_list)\n\t\tgoto err_out;\n\n\tfor (i = 0; i < npages; ++i)\n\t\teq->page_list[i].buf = NULL;\n\n\tdma_list = kmalloc_array(npages, sizeof(*dma_list), GFP_KERNEL);\n\tif (!dma_list)\n\t\tgoto err_out_free;\n\n\tmailbox = mthca_alloc_mailbox(dev, GFP_KERNEL);\n\tif (IS_ERR(mailbox))\n\t\tgoto err_out_free;\n\teq_context = mailbox->buf;\n\n\tfor (i = 0; i < npages; ++i) {\n\t\teq->page_list[i].buf = dma_alloc_coherent(&dev->pdev->dev,\n\t\t\t\t\t\t\t  PAGE_SIZE, &t, GFP_KERNEL);\n\t\tif (!eq->page_list[i].buf)\n\t\t\tgoto err_out_free_pages;\n\n\t\tdma_list[i] = t;\n\t\tdma_unmap_addr_set(&eq->page_list[i], mapping, t);\n\n\t\tclear_page(eq->page_list[i].buf);\n\t}\n\n\tfor (i = 0; i < eq->nent; ++i)\n\t\tset_eqe_hw(get_eqe(eq, i));\n\n\teq->eqn = mthca_alloc(&dev->eq_table.alloc);\n\tif (eq->eqn == -1)\n\t\tgoto err_out_free_pages;\n\n\terr = mthca_mr_alloc_phys(dev, dev->driver_pd.pd_num,\n\t\t\t\t  dma_list, PAGE_SHIFT, npages,\n\t\t\t\t  0, npages * PAGE_SIZE,\n\t\t\t\t  MTHCA_MPT_FLAG_LOCAL_WRITE |\n\t\t\t\t  MTHCA_MPT_FLAG_LOCAL_READ,\n\t\t\t\t  &eq->mr);\n\tif (err)\n\t\tgoto err_out_free_eq;\n\n\tmemset(eq_context, 0, sizeof *eq_context);\n\teq_context->flags           = cpu_to_be32(MTHCA_EQ_STATUS_OK   |\n\t\t\t\t\t\t  MTHCA_EQ_OWNER_HW    |\n\t\t\t\t\t\t  MTHCA_EQ_STATE_ARMED |\n\t\t\t\t\t\t  MTHCA_EQ_FLAG_TR);\n\tif (mthca_is_memfree(dev))\n\t\teq_context->flags  |= cpu_to_be32(MTHCA_EQ_STATE_ARBEL);\n\n\teq_context->logsize_usrpage = cpu_to_be32((ffs(eq->nent) - 1) << 24);\n\tif (mthca_is_memfree(dev)) {\n\t\teq_context->arbel_pd = cpu_to_be32(dev->driver_pd.pd_num);\n\t} else {\n\t\teq_context->logsize_usrpage |= cpu_to_be32(dev->driver_uar.index);\n\t\teq_context->tavor_pd         = cpu_to_be32(dev->driver_pd.pd_num);\n\t}\n\teq_context->intr            = intr;\n\teq_context->lkey            = cpu_to_be32(eq->mr.ibmr.lkey);\n\n\terr = mthca_SW2HW_EQ(dev, mailbox, eq->eqn);\n\tif (err) {\n\t\tmthca_warn(dev, \"SW2HW_EQ returned %d\\n\", err);\n\t\tgoto err_out_free_mr;\n\t}\n\n\tkfree(dma_list);\n\tmthca_free_mailbox(dev, mailbox);\n\n\teq->eqn_mask   = swab32(1 << eq->eqn);\n\teq->cons_index = 0;\n\n\tdev->eq_table.arm_mask |= eq->eqn_mask;\n\n\tmthca_dbg(dev, \"Allocated EQ %d with %d entries\\n\",\n\t\t  eq->eqn, eq->nent);\n\n\treturn err;\n\n err_out_free_mr:\n\tmthca_free_mr(dev, &eq->mr);\n\n err_out_free_eq:\n\tmthca_free(&dev->eq_table.alloc, eq->eqn);\n\n err_out_free_pages:\n\tfor (i = 0; i < npages; ++i)\n\t\tif (eq->page_list[i].buf)\n\t\t\tdma_free_coherent(&dev->pdev->dev, PAGE_SIZE,\n\t\t\t\t\t  eq->page_list[i].buf,\n\t\t\t\t\t  dma_unmap_addr(&eq->page_list[i],\n\t\t\t\t\t\t\t mapping));\n\n\tmthca_free_mailbox(dev, mailbox);\n\n err_out_free:\n\tkfree(eq->page_list);\n\tkfree(dma_list);\n\n err_out:\n\treturn err;\n}\n\nstatic void mthca_free_eq(struct mthca_dev *dev,\n\t\t\t  struct mthca_eq *eq)\n{\n\tstruct mthca_mailbox *mailbox;\n\tint err;\n\tint npages = (eq->nent * MTHCA_EQ_ENTRY_SIZE + PAGE_SIZE - 1) /\n\t\tPAGE_SIZE;\n\tint i;\n\n\tmailbox = mthca_alloc_mailbox(dev, GFP_KERNEL);\n\tif (IS_ERR(mailbox))\n\t\treturn;\n\n\terr = mthca_HW2SW_EQ(dev, mailbox, eq->eqn);\n\tif (err)\n\t\tmthca_warn(dev, \"HW2SW_EQ returned %d\\n\", err);\n\n\tdev->eq_table.arm_mask &= ~eq->eqn_mask;\n\n\tif (0) {\n\t\tmthca_dbg(dev, \"Dumping EQ context %02x:\\n\", eq->eqn);\n\t\tfor (i = 0; i < sizeof (struct mthca_eq_context) / 4; ++i) {\n\t\t\tif (i % 4 == 0)\n\t\t\t\tprintk(\"[%02x] \", i * 4);\n\t\t\tprintk(\" %08x\", be32_to_cpup(mailbox->buf + i * 4));\n\t\t\tif ((i + 1) % 4 == 0)\n\t\t\t\tprintk(\"\\n\");\n\t\t}\n\t}\n\n\tmthca_free_mr(dev, &eq->mr);\n\tfor (i = 0; i < npages; ++i)\n\t\tdma_free_coherent(&dev->pdev->dev, PAGE_SIZE,\n\t\t\t\t  eq->page_list[i].buf,\n\t\t\t\t  dma_unmap_addr(&eq->page_list[i], mapping));\n\n\tkfree(eq->page_list);\n\tmthca_free_mailbox(dev, mailbox);\n}\n\nstatic void mthca_free_irqs(struct mthca_dev *dev)\n{\n\tint i;\n\n\tif (dev->eq_table.have_irq)\n\t\tfree_irq(dev->pdev->irq, dev);\n\tfor (i = 0; i < MTHCA_NUM_EQ; ++i)\n\t\tif (dev->eq_table.eq[i].have_irq) {\n\t\t\tfree_irq(dev->eq_table.eq[i].msi_x_vector,\n\t\t\t\t dev->eq_table.eq + i);\n\t\t\tdev->eq_table.eq[i].have_irq = 0;\n\t\t}\n}\n\nstatic int mthca_map_reg(struct mthca_dev *dev,\n\t\t\t unsigned long offset, unsigned long size,\n\t\t\t void __iomem **map)\n{\n\tphys_addr_t base = pci_resource_start(dev->pdev, 0);\n\n\t*map = ioremap(base + offset, size);\n\tif (!*map)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int mthca_map_eq_regs(struct mthca_dev *dev)\n{\n\tif (mthca_is_memfree(dev)) {\n\t\t \n\t\tif (mthca_map_reg(dev, (pci_resource_len(dev->pdev, 0) - 1) &\n\t\t\t\t  dev->fw.arbel.clr_int_base, MTHCA_CLR_INT_SIZE,\n\t\t\t\t  &dev->clr_base)) {\n\t\t\tmthca_err(dev, \"Couldn't map interrupt clear register, \"\n\t\t\t\t  \"aborting.\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tif (mthca_map_reg(dev, ((pci_resource_len(dev->pdev, 0) - 1) &\n\t\t\t\t\tdev->fw.arbel.eq_arm_base) + 4, 4,\n\t\t\t\t  &dev->eq_regs.arbel.eq_arm)) {\n\t\t\tmthca_err(dev, \"Couldn't map EQ arm register, aborting.\\n\");\n\t\t\tiounmap(dev->clr_base);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (mthca_map_reg(dev, (pci_resource_len(dev->pdev, 0) - 1) &\n\t\t\t\t  dev->fw.arbel.eq_set_ci_base,\n\t\t\t\t  MTHCA_EQ_SET_CI_SIZE,\n\t\t\t\t  &dev->eq_regs.arbel.eq_set_ci_base)) {\n\t\t\tmthca_err(dev, \"Couldn't map EQ CI register, aborting.\\n\");\n\t\t\tiounmap(dev->eq_regs.arbel.eq_arm);\n\t\t\tiounmap(dev->clr_base);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t} else {\n\t\tif (mthca_map_reg(dev, MTHCA_CLR_INT_BASE, MTHCA_CLR_INT_SIZE,\n\t\t\t\t  &dev->clr_base)) {\n\t\t\tmthca_err(dev, \"Couldn't map interrupt clear register, \"\n\t\t\t\t  \"aborting.\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (mthca_map_reg(dev, MTHCA_ECR_BASE,\n\t\t\t\t  MTHCA_ECR_SIZE + MTHCA_ECR_CLR_SIZE,\n\t\t\t\t  &dev->eq_regs.tavor.ecr_base)) {\n\t\t\tmthca_err(dev, \"Couldn't map ecr register, \"\n\t\t\t\t  \"aborting.\\n\");\n\t\t\tiounmap(dev->clr_base);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\treturn 0;\n\n}\n\nstatic void mthca_unmap_eq_regs(struct mthca_dev *dev)\n{\n\tif (mthca_is_memfree(dev)) {\n\t\tiounmap(dev->eq_regs.arbel.eq_set_ci_base);\n\t\tiounmap(dev->eq_regs.arbel.eq_arm);\n\t\tiounmap(dev->clr_base);\n\t} else {\n\t\tiounmap(dev->eq_regs.tavor.ecr_base);\n\t\tiounmap(dev->clr_base);\n\t}\n}\n\nint mthca_map_eq_icm(struct mthca_dev *dev, u64 icm_virt)\n{\n\tint ret;\n\n\t \n\tdev->eq_table.icm_virt = icm_virt;\n\tdev->eq_table.icm_page = alloc_page(GFP_HIGHUSER);\n\tif (!dev->eq_table.icm_page)\n\t\treturn -ENOMEM;\n\tdev->eq_table.icm_dma =\n\t\tdma_map_page(&dev->pdev->dev, dev->eq_table.icm_page, 0,\n\t\t\t     PAGE_SIZE, DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(&dev->pdev->dev, dev->eq_table.icm_dma)) {\n\t\t__free_page(dev->eq_table.icm_page);\n\t\treturn -ENOMEM;\n\t}\n\n\tret = mthca_MAP_ICM_page(dev, dev->eq_table.icm_dma, icm_virt);\n\tif (ret) {\n\t\tdma_unmap_page(&dev->pdev->dev, dev->eq_table.icm_dma,\n\t\t\t       PAGE_SIZE, DMA_BIDIRECTIONAL);\n\t\t__free_page(dev->eq_table.icm_page);\n\t}\n\n\treturn ret;\n}\n\nvoid mthca_unmap_eq_icm(struct mthca_dev *dev)\n{\n\tmthca_UNMAP_ICM(dev, dev->eq_table.icm_virt, 1);\n\tdma_unmap_page(&dev->pdev->dev, dev->eq_table.icm_dma, PAGE_SIZE,\n\t\t       DMA_BIDIRECTIONAL);\n\t__free_page(dev->eq_table.icm_page);\n}\n\nint mthca_init_eq_table(struct mthca_dev *dev)\n{\n\tint err;\n\tu8 intr;\n\tint i;\n\n\terr = mthca_alloc_init(&dev->eq_table.alloc,\n\t\t\t       dev->limits.num_eqs,\n\t\t\t       dev->limits.num_eqs - 1,\n\t\t\t       dev->limits.reserved_eqs);\n\tif (err)\n\t\treturn err;\n\n\terr = mthca_map_eq_regs(dev);\n\tif (err)\n\t\tgoto err_out_free;\n\n\tif (dev->mthca_flags & MTHCA_FLAG_MSI_X) {\n\t\tdev->eq_table.clr_mask = 0;\n\t} else {\n\t\tdev->eq_table.clr_mask =\n\t\t\tswab32(1 << (dev->eq_table.inta_pin & 31));\n\t\tdev->eq_table.clr_int  = dev->clr_base +\n\t\t\t(dev->eq_table.inta_pin < 32 ? 4 : 0);\n\t}\n\n\tdev->eq_table.arm_mask = 0;\n\n\tintr = dev->eq_table.inta_pin;\n\n\terr = mthca_create_eq(dev, dev->limits.num_cqs + MTHCA_NUM_SPARE_EQE,\n\t\t\t      (dev->mthca_flags & MTHCA_FLAG_MSI_X) ? 128 : intr,\n\t\t\t      &dev->eq_table.eq[MTHCA_EQ_COMP]);\n\tif (err)\n\t\tgoto err_out_unmap;\n\n\terr = mthca_create_eq(dev, MTHCA_NUM_ASYNC_EQE + MTHCA_NUM_SPARE_EQE,\n\t\t\t      (dev->mthca_flags & MTHCA_FLAG_MSI_X) ? 129 : intr,\n\t\t\t      &dev->eq_table.eq[MTHCA_EQ_ASYNC]);\n\tif (err)\n\t\tgoto err_out_comp;\n\n\terr = mthca_create_eq(dev, MTHCA_NUM_CMD_EQE + MTHCA_NUM_SPARE_EQE,\n\t\t\t      (dev->mthca_flags & MTHCA_FLAG_MSI_X) ? 130 : intr,\n\t\t\t      &dev->eq_table.eq[MTHCA_EQ_CMD]);\n\tif (err)\n\t\tgoto err_out_async;\n\n\tif (dev->mthca_flags & MTHCA_FLAG_MSI_X) {\n\t\tstatic const char *eq_name[] = {\n\t\t\t[MTHCA_EQ_COMP]  = DRV_NAME \"-comp\",\n\t\t\t[MTHCA_EQ_ASYNC] = DRV_NAME \"-async\",\n\t\t\t[MTHCA_EQ_CMD]   = DRV_NAME \"-cmd\"\n\t\t};\n\n\t\tfor (i = 0; i < MTHCA_NUM_EQ; ++i) {\n\t\t\tsnprintf(dev->eq_table.eq[i].irq_name,\n\t\t\t\t IB_DEVICE_NAME_MAX,\n\t\t\t\t \"%s@pci:%s\", eq_name[i],\n\t\t\t\t pci_name(dev->pdev));\n\t\t\terr = request_irq(dev->eq_table.eq[i].msi_x_vector,\n\t\t\t\t\t  mthca_is_memfree(dev) ?\n\t\t\t\t\t  mthca_arbel_msi_x_interrupt :\n\t\t\t\t\t  mthca_tavor_msi_x_interrupt,\n\t\t\t\t\t  0, dev->eq_table.eq[i].irq_name,\n\t\t\t\t\t  dev->eq_table.eq + i);\n\t\t\tif (err)\n\t\t\t\tgoto err_out_cmd;\n\t\t\tdev->eq_table.eq[i].have_irq = 1;\n\t\t}\n\t} else {\n\t\tsnprintf(dev->eq_table.eq[0].irq_name, IB_DEVICE_NAME_MAX,\n\t\t\t DRV_NAME \"@pci:%s\", pci_name(dev->pdev));\n\t\terr = request_irq(dev->pdev->irq,\n\t\t\t\t  mthca_is_memfree(dev) ?\n\t\t\t\t  mthca_arbel_interrupt :\n\t\t\t\t  mthca_tavor_interrupt,\n\t\t\t\t  IRQF_SHARED, dev->eq_table.eq[0].irq_name, dev);\n\t\tif (err)\n\t\t\tgoto err_out_cmd;\n\t\tdev->eq_table.have_irq = 1;\n\t}\n\n\terr = mthca_MAP_EQ(dev, async_mask(dev),\n\t\t\t   0, dev->eq_table.eq[MTHCA_EQ_ASYNC].eqn);\n\tif (err)\n\t\tmthca_warn(dev, \"MAP_EQ for async EQ %d failed (%d)\\n\",\n\t\t\t   dev->eq_table.eq[MTHCA_EQ_ASYNC].eqn, err);\n\n\terr = mthca_MAP_EQ(dev, MTHCA_CMD_EVENT_MASK,\n\t\t\t   0, dev->eq_table.eq[MTHCA_EQ_CMD].eqn);\n\tif (err)\n\t\tmthca_warn(dev, \"MAP_EQ for cmd EQ %d failed (%d)\\n\",\n\t\t\t   dev->eq_table.eq[MTHCA_EQ_CMD].eqn, err);\n\n\tfor (i = 0; i < MTHCA_NUM_EQ; ++i)\n\t\tif (mthca_is_memfree(dev))\n\t\t\tarbel_eq_req_not(dev, dev->eq_table.eq[i].eqn_mask);\n\t\telse\n\t\t\ttavor_eq_req_not(dev, dev->eq_table.eq[i].eqn);\n\n\treturn 0;\n\nerr_out_cmd:\n\tmthca_free_irqs(dev);\n\tmthca_free_eq(dev, &dev->eq_table.eq[MTHCA_EQ_CMD]);\n\nerr_out_async:\n\tmthca_free_eq(dev, &dev->eq_table.eq[MTHCA_EQ_ASYNC]);\n\nerr_out_comp:\n\tmthca_free_eq(dev, &dev->eq_table.eq[MTHCA_EQ_COMP]);\n\nerr_out_unmap:\n\tmthca_unmap_eq_regs(dev);\n\nerr_out_free:\n\tmthca_alloc_cleanup(&dev->eq_table.alloc);\n\treturn err;\n}\n\nvoid mthca_cleanup_eq_table(struct mthca_dev *dev)\n{\n\tint i;\n\n\tmthca_free_irqs(dev);\n\n\tmthca_MAP_EQ(dev, async_mask(dev),\n\t\t     1, dev->eq_table.eq[MTHCA_EQ_ASYNC].eqn);\n\tmthca_MAP_EQ(dev, MTHCA_CMD_EVENT_MASK,\n\t\t     1, dev->eq_table.eq[MTHCA_EQ_CMD].eqn);\n\n\tfor (i = 0; i < MTHCA_NUM_EQ; ++i)\n\t\tmthca_free_eq(dev, &dev->eq_table.eq[i]);\n\n\tmthca_unmap_eq_regs(dev);\n\n\tmthca_alloc_cleanup(&dev->eq_table.alloc);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}