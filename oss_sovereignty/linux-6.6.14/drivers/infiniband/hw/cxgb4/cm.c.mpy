{
  "module_name": "cm.c",
  "hash_id": "a611ed082596c9d01cab9f3af8e3be4cf00e57404df7872cbf3f99807f02447c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/cxgb4/cm.c",
  "human_readable_source": " \n#include <linux/module.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/skbuff.h>\n#include <linux/timer.h>\n#include <linux/notifier.h>\n#include <linux/inetdevice.h>\n#include <linux/ip.h>\n#include <linux/tcp.h>\n#include <linux/if_vlan.h>\n\n#include <net/neighbour.h>\n#include <net/netevent.h>\n#include <net/route.h>\n#include <net/tcp.h>\n#include <net/ip6_route.h>\n#include <net/addrconf.h>\n\n#include <rdma/ib_addr.h>\n\n#include <libcxgb_cm.h>\n#include \"iw_cxgb4.h\"\n#include \"clip_tbl.h\"\n\nstatic char *states[] = {\n\t\"idle\",\n\t\"listen\",\n\t\"connecting\",\n\t\"mpa_wait_req\",\n\t\"mpa_req_sent\",\n\t\"mpa_req_rcvd\",\n\t\"mpa_rep_sent\",\n\t\"fpdu_mode\",\n\t\"aborting\",\n\t\"closing\",\n\t\"moribund\",\n\t\"dead\",\n\tNULL,\n};\n\nstatic int nocong;\nmodule_param(nocong, int, 0644);\nMODULE_PARM_DESC(nocong, \"Turn of congestion control (default=0)\");\n\nstatic int enable_ecn;\nmodule_param(enable_ecn, int, 0644);\nMODULE_PARM_DESC(enable_ecn, \"Enable ECN (default=0/disabled)\");\n\nstatic int dack_mode;\nmodule_param(dack_mode, int, 0644);\nMODULE_PARM_DESC(dack_mode, \"Delayed ack mode (default=0)\");\n\nuint c4iw_max_read_depth = 32;\nmodule_param(c4iw_max_read_depth, int, 0644);\nMODULE_PARM_DESC(c4iw_max_read_depth,\n\t\t \"Per-connection max ORD/IRD (default=32)\");\n\nstatic int enable_tcp_timestamps;\nmodule_param(enable_tcp_timestamps, int, 0644);\nMODULE_PARM_DESC(enable_tcp_timestamps, \"Enable tcp timestamps (default=0)\");\n\nstatic int enable_tcp_sack;\nmodule_param(enable_tcp_sack, int, 0644);\nMODULE_PARM_DESC(enable_tcp_sack, \"Enable tcp SACK (default=0)\");\n\nstatic int enable_tcp_window_scaling = 1;\nmodule_param(enable_tcp_window_scaling, int, 0644);\nMODULE_PARM_DESC(enable_tcp_window_scaling,\n\t\t \"Enable tcp window scaling (default=1)\");\n\nstatic int peer2peer = 1;\nmodule_param(peer2peer, int, 0644);\nMODULE_PARM_DESC(peer2peer, \"Support peer2peer ULPs (default=1)\");\n\nstatic int p2p_type = FW_RI_INIT_P2PTYPE_READ_REQ;\nmodule_param(p2p_type, int, 0644);\nMODULE_PARM_DESC(p2p_type, \"RDMAP opcode to use for the RTR message: \"\n\t\t\t   \"1=RDMA_READ 0=RDMA_WRITE (default 1)\");\n\nstatic int ep_timeout_secs = 60;\nmodule_param(ep_timeout_secs, int, 0644);\nMODULE_PARM_DESC(ep_timeout_secs, \"CM Endpoint operation timeout \"\n\t\t\t\t   \"in seconds (default=60)\");\n\nstatic int mpa_rev = 2;\nmodule_param(mpa_rev, int, 0644);\nMODULE_PARM_DESC(mpa_rev, \"MPA Revision, 0 supports amso1100, \"\n\t\t\"1 is RFC5044 spec compliant, 2 is IETF MPA Peer Connect Draft\"\n\t\t\" compliant (default=2)\");\n\nstatic int markers_enabled;\nmodule_param(markers_enabled, int, 0644);\nMODULE_PARM_DESC(markers_enabled, \"Enable MPA MARKERS (default(0)=disabled)\");\n\nstatic int crc_enabled = 1;\nmodule_param(crc_enabled, int, 0644);\nMODULE_PARM_DESC(crc_enabled, \"Enable MPA CRC (default(1)=enabled)\");\n\nstatic int rcv_win = 256 * 1024;\nmodule_param(rcv_win, int, 0644);\nMODULE_PARM_DESC(rcv_win, \"TCP receive window in bytes (default=256KB)\");\n\nstatic int snd_win = 128 * 1024;\nmodule_param(snd_win, int, 0644);\nMODULE_PARM_DESC(snd_win, \"TCP send window in bytes (default=128KB)\");\n\nstatic struct workqueue_struct *workq;\n\nstatic struct sk_buff_head rxq;\n\nstatic struct sk_buff *get_skb(struct sk_buff *skb, int len, gfp_t gfp);\nstatic void ep_timeout(struct timer_list *t);\nstatic void connect_reply_upcall(struct c4iw_ep *ep, int status);\nstatic int sched(struct c4iw_dev *dev, struct sk_buff *skb);\n\nstatic LIST_HEAD(timeout_list);\nstatic DEFINE_SPINLOCK(timeout_lock);\n\nstatic void deref_cm_id(struct c4iw_ep_common *epc)\n{\n\tepc->cm_id->rem_ref(epc->cm_id);\n\tepc->cm_id = NULL;\n\tset_bit(CM_ID_DEREFED, &epc->history);\n}\n\nstatic void ref_cm_id(struct c4iw_ep_common *epc)\n{\n\tset_bit(CM_ID_REFED, &epc->history);\n\tepc->cm_id->add_ref(epc->cm_id);\n}\n\nstatic void deref_qp(struct c4iw_ep *ep)\n{\n\tc4iw_qp_rem_ref(&ep->com.qp->ibqp);\n\tclear_bit(QP_REFERENCED, &ep->com.flags);\n\tset_bit(QP_DEREFED, &ep->com.history);\n}\n\nstatic void ref_qp(struct c4iw_ep *ep)\n{\n\tset_bit(QP_REFERENCED, &ep->com.flags);\n\tset_bit(QP_REFED, &ep->com.history);\n\tc4iw_qp_add_ref(&ep->com.qp->ibqp);\n}\n\nstatic void start_ep_timer(struct c4iw_ep *ep)\n{\n\tpr_debug(\"ep %p\\n\", ep);\n\tif (timer_pending(&ep->timer)) {\n\t\tpr_err(\"%s timer already started! ep %p\\n\",\n\t\t       __func__, ep);\n\t\treturn;\n\t}\n\tclear_bit(TIMEOUT, &ep->com.flags);\n\tc4iw_get_ep(&ep->com);\n\tep->timer.expires = jiffies + ep_timeout_secs * HZ;\n\tadd_timer(&ep->timer);\n}\n\nstatic int stop_ep_timer(struct c4iw_ep *ep)\n{\n\tpr_debug(\"ep %p stopping\\n\", ep);\n\tdel_timer_sync(&ep->timer);\n\tif (!test_and_set_bit(TIMEOUT, &ep->com.flags)) {\n\t\tc4iw_put_ep(&ep->com);\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic int c4iw_l2t_send(struct c4iw_rdev *rdev, struct sk_buff *skb,\n\t\t  struct l2t_entry *l2e)\n{\n\tint\terror = 0;\n\n\tif (c4iw_fatal_error(rdev)) {\n\t\tkfree_skb(skb);\n\t\tpr_err(\"%s - device in error state - dropping\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\terror = cxgb4_l2t_send(rdev->lldi.ports[0], skb, l2e);\n\tif (error < 0)\n\t\tkfree_skb(skb);\n\telse if (error == NET_XMIT_DROP)\n\t\treturn -ENOMEM;\n\treturn error < 0 ? error : 0;\n}\n\nint c4iw_ofld_send(struct c4iw_rdev *rdev, struct sk_buff *skb)\n{\n\tint\terror = 0;\n\n\tif (c4iw_fatal_error(rdev)) {\n\t\tkfree_skb(skb);\n\t\tpr_err(\"%s - device in error state - dropping\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\terror = cxgb4_ofld_send(rdev->lldi.ports[0], skb);\n\tif (error < 0)\n\t\tkfree_skb(skb);\n\treturn error < 0 ? error : 0;\n}\n\nstatic void release_tid(struct c4iw_rdev *rdev, u32 hwtid, struct sk_buff *skb)\n{\n\tu32 len = roundup(sizeof(struct cpl_tid_release), 16);\n\n\tskb = get_skb(skb, len, GFP_KERNEL);\n\tif (!skb)\n\t\treturn;\n\n\tcxgb_mk_tid_release(skb, len, hwtid, 0);\n\tc4iw_ofld_send(rdev, skb);\n\treturn;\n}\n\nstatic void set_emss(struct c4iw_ep *ep, u16 opt)\n{\n\tep->emss = ep->com.dev->rdev.lldi.mtus[TCPOPT_MSS_G(opt)] -\n\t\t   ((AF_INET == ep->com.remote_addr.ss_family) ?\n\t\t    sizeof(struct iphdr) : sizeof(struct ipv6hdr)) -\n\t\t   sizeof(struct tcphdr);\n\tep->mss = ep->emss;\n\tif (TCPOPT_TSTAMP_G(opt))\n\t\tep->emss -= round_up(TCPOLEN_TIMESTAMP, 4);\n\tif (ep->emss < 128)\n\t\tep->emss = 128;\n\tif (ep->emss & 7)\n\t\tpr_debug(\"Warning: misaligned mtu idx %u mss %u emss=%u\\n\",\n\t\t\t TCPOPT_MSS_G(opt), ep->mss, ep->emss);\n\tpr_debug(\"mss_idx %u mss %u emss=%u\\n\", TCPOPT_MSS_G(opt), ep->mss,\n\t\t ep->emss);\n}\n\nstatic enum c4iw_ep_state state_read(struct c4iw_ep_common *epc)\n{\n\tenum c4iw_ep_state state;\n\n\tmutex_lock(&epc->mutex);\n\tstate = epc->state;\n\tmutex_unlock(&epc->mutex);\n\treturn state;\n}\n\nstatic void __state_set(struct c4iw_ep_common *epc, enum c4iw_ep_state new)\n{\n\tepc->state = new;\n}\n\nstatic void state_set(struct c4iw_ep_common *epc, enum c4iw_ep_state new)\n{\n\tmutex_lock(&epc->mutex);\n\tpr_debug(\"%s -> %s\\n\", states[epc->state], states[new]);\n\t__state_set(epc, new);\n\tmutex_unlock(&epc->mutex);\n\treturn;\n}\n\nstatic int alloc_ep_skb_list(struct sk_buff_head *ep_skb_list, int size)\n{\n\tstruct sk_buff *skb;\n\tunsigned int i;\n\tsize_t len;\n\n\tlen = roundup(sizeof(union cpl_wr_size), 16);\n\tfor (i = 0; i < size; i++) {\n\t\tskb = alloc_skb(len, GFP_KERNEL);\n\t\tif (!skb)\n\t\t\tgoto fail;\n\t\tskb_queue_tail(ep_skb_list, skb);\n\t}\n\treturn 0;\nfail:\n\tskb_queue_purge(ep_skb_list);\n\treturn -ENOMEM;\n}\n\nstatic void *alloc_ep(int size, gfp_t gfp)\n{\n\tstruct c4iw_ep_common *epc;\n\n\tepc = kzalloc(size, gfp);\n\tif (epc) {\n\t\tepc->wr_waitp = c4iw_alloc_wr_wait(gfp);\n\t\tif (!epc->wr_waitp) {\n\t\t\tkfree(epc);\n\t\t\tepc = NULL;\n\t\t\tgoto out;\n\t\t}\n\t\tkref_init(&epc->kref);\n\t\tmutex_init(&epc->mutex);\n\t\tc4iw_init_wr_wait(epc->wr_waitp);\n\t}\n\tpr_debug(\"alloc ep %p\\n\", epc);\nout:\n\treturn epc;\n}\n\nstatic void remove_ep_tid(struct c4iw_ep *ep)\n{\n\tunsigned long flags;\n\n\txa_lock_irqsave(&ep->com.dev->hwtids, flags);\n\t__xa_erase(&ep->com.dev->hwtids, ep->hwtid);\n\tif (xa_empty(&ep->com.dev->hwtids))\n\t\twake_up(&ep->com.dev->wait);\n\txa_unlock_irqrestore(&ep->com.dev->hwtids, flags);\n}\n\nstatic int insert_ep_tid(struct c4iw_ep *ep)\n{\n\tunsigned long flags;\n\tint err;\n\n\txa_lock_irqsave(&ep->com.dev->hwtids, flags);\n\terr = __xa_insert(&ep->com.dev->hwtids, ep->hwtid, ep, GFP_KERNEL);\n\txa_unlock_irqrestore(&ep->com.dev->hwtids, flags);\n\n\treturn err;\n}\n\n \nstatic struct c4iw_ep *get_ep_from_tid(struct c4iw_dev *dev, unsigned int tid)\n{\n\tstruct c4iw_ep *ep;\n\tunsigned long flags;\n\n\txa_lock_irqsave(&dev->hwtids, flags);\n\tep = xa_load(&dev->hwtids, tid);\n\tif (ep)\n\t\tc4iw_get_ep(&ep->com);\n\txa_unlock_irqrestore(&dev->hwtids, flags);\n\treturn ep;\n}\n\n \nstatic struct c4iw_listen_ep *get_ep_from_stid(struct c4iw_dev *dev,\n\t\t\t\t\t       unsigned int stid)\n{\n\tstruct c4iw_listen_ep *ep;\n\tunsigned long flags;\n\n\txa_lock_irqsave(&dev->stids, flags);\n\tep = xa_load(&dev->stids, stid);\n\tif (ep)\n\t\tc4iw_get_ep(&ep->com);\n\txa_unlock_irqrestore(&dev->stids, flags);\n\treturn ep;\n}\n\nvoid _c4iw_free_ep(struct kref *kref)\n{\n\tstruct c4iw_ep *ep;\n\n\tep = container_of(kref, struct c4iw_ep, com.kref);\n\tpr_debug(\"ep %p state %s\\n\", ep, states[ep->com.state]);\n\tif (test_bit(QP_REFERENCED, &ep->com.flags))\n\t\tderef_qp(ep);\n\tif (test_bit(RELEASE_RESOURCES, &ep->com.flags)) {\n\t\tif (ep->com.remote_addr.ss_family == AF_INET6) {\n\t\t\tstruct sockaddr_in6 *sin6 =\n\t\t\t\t\t(struct sockaddr_in6 *)\n\t\t\t\t\t&ep->com.local_addr;\n\n\t\t\tcxgb4_clip_release(\n\t\t\t\t\tep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t\t(const u32 *)&sin6->sin6_addr.s6_addr,\n\t\t\t\t\t1);\n\t\t}\n\t\tcxgb4_remove_tid(ep->com.dev->rdev.lldi.tids, 0, ep->hwtid,\n\t\t\t\t ep->com.local_addr.ss_family);\n\t\tdst_release(ep->dst);\n\t\tcxgb4_l2t_release(ep->l2t);\n\t\tkfree_skb(ep->mpa_skb);\n\t}\n\tif (!skb_queue_empty(&ep->com.ep_skb_list))\n\t\tskb_queue_purge(&ep->com.ep_skb_list);\n\tc4iw_put_wr_wait(ep->com.wr_waitp);\n\tkfree(ep);\n}\n\nstatic void release_ep_resources(struct c4iw_ep *ep)\n{\n\tset_bit(RELEASE_RESOURCES, &ep->com.flags);\n\n\t \n\tif (ep->hwtid != -1)\n\t\tremove_ep_tid(ep);\n\tc4iw_put_ep(&ep->com);\n}\n\nstatic int status2errno(int status)\n{\n\tswitch (status) {\n\tcase CPL_ERR_NONE:\n\t\treturn 0;\n\tcase CPL_ERR_CONN_RESET:\n\t\treturn -ECONNRESET;\n\tcase CPL_ERR_ARP_MISS:\n\t\treturn -EHOSTUNREACH;\n\tcase CPL_ERR_CONN_TIMEDOUT:\n\t\treturn -ETIMEDOUT;\n\tcase CPL_ERR_TCAM_FULL:\n\t\treturn -ENOMEM;\n\tcase CPL_ERR_CONN_EXIST:\n\t\treturn -EADDRINUSE;\n\tdefault:\n\t\treturn -EIO;\n\t}\n}\n\n \nstatic struct sk_buff *get_skb(struct sk_buff *skb, int len, gfp_t gfp)\n{\n\tif (skb && !skb_is_nonlinear(skb) && !skb_cloned(skb)) {\n\t\tskb_trim(skb, 0);\n\t\tskb_get(skb);\n\t\tskb_reset_transport_header(skb);\n\t} else {\n\t\tskb = alloc_skb(len, gfp);\n\t\tif (!skb)\n\t\t\treturn NULL;\n\t}\n\tt4_set_arp_err_handler(skb, NULL, NULL);\n\treturn skb;\n}\n\nstatic struct net_device *get_real_dev(struct net_device *egress_dev)\n{\n\treturn rdma_vlan_dev_real_dev(egress_dev) ? : egress_dev;\n}\n\nstatic void arp_failure_discard(void *handle, struct sk_buff *skb)\n{\n\tpr_err(\"ARP failure\\n\");\n\tkfree_skb(skb);\n}\n\nstatic void mpa_start_arp_failure(void *handle, struct sk_buff *skb)\n{\n\tpr_err(\"ARP failure during MPA Negotiation - Closing Connection\\n\");\n}\n\nenum {\n\tNUM_FAKE_CPLS = 2,\n\tFAKE_CPL_PUT_EP_SAFE = NUM_CPL_CMDS + 0,\n\tFAKE_CPL_PASS_PUT_EP_SAFE = NUM_CPL_CMDS + 1,\n};\n\nstatic int _put_ep_safe(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\n\tep = *((struct c4iw_ep **)(skb->cb + 2 * sizeof(void *)));\n\trelease_ep_resources(ep);\n\treturn 0;\n}\n\nstatic int _put_pass_ep_safe(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\n\tep = *((struct c4iw_ep **)(skb->cb + 2 * sizeof(void *)));\n\tc4iw_put_ep(&ep->parent_ep->com);\n\trelease_ep_resources(ep);\n\treturn 0;\n}\n\n \nstatic void queue_arp_failure_cpl(struct c4iw_ep *ep, struct sk_buff *skb,\n\t\t\t\t  int cpl)\n{\n\tstruct cpl_act_establish *rpl = cplhdr(skb);\n\n\t \n\trpl->ot.opcode = cpl;\n\n\t \n\t*((struct c4iw_ep **)(skb->cb + 2 * sizeof(void *))) = ep;\n\tsched(ep->com.dev, skb);\n}\n\n \nstatic void pass_accept_rpl_arp_failure(void *handle, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep = handle;\n\n\tpr_err(\"ARP failure during accept - tid %u - dropping connection\\n\",\n\t       ep->hwtid);\n\n\t__state_set(&ep->com, DEAD);\n\tqueue_arp_failure_cpl(ep, skb, FAKE_CPL_PASS_PUT_EP_SAFE);\n}\n\n \nstatic void act_open_req_arp_failure(void *handle, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep = handle;\n\n\tpr_err(\"ARP failure during connect\\n\");\n\tconnect_reply_upcall(ep, -EHOSTUNREACH);\n\t__state_set(&ep->com, DEAD);\n\tif (ep->com.remote_addr.ss_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *sin6 =\n\t\t\t(struct sockaddr_in6 *)&ep->com.local_addr;\n\t\tcxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t   (const u32 *)&sin6->sin6_addr.s6_addr, 1);\n\t}\n\txa_erase_irq(&ep->com.dev->atids, ep->atid);\n\tcxgb4_free_atid(ep->com.dev->rdev.lldi.tids, ep->atid);\n\tqueue_arp_failure_cpl(ep, skb, FAKE_CPL_PUT_EP_SAFE);\n}\n\n \nstatic void abort_arp_failure(void *handle, struct sk_buff *skb)\n{\n\tint ret;\n\tstruct c4iw_ep *ep = handle;\n\tstruct c4iw_rdev *rdev = &ep->com.dev->rdev;\n\tstruct cpl_abort_req *req = cplhdr(skb);\n\n\tpr_debug(\"rdev %p\\n\", rdev);\n\treq->cmd = CPL_ABORT_NO_RST;\n\tskb_get(skb);\n\tret = c4iw_ofld_send(rdev, skb);\n\tif (ret) {\n\t\t__state_set(&ep->com, DEAD);\n\t\tqueue_arp_failure_cpl(ep, skb, FAKE_CPL_PUT_EP_SAFE);\n\t} else\n\t\tkfree_skb(skb);\n}\n\nstatic int send_flowc(struct c4iw_ep *ep)\n{\n\tstruct fw_flowc_wr *flowc;\n\tstruct sk_buff *skb = skb_dequeue(&ep->com.ep_skb_list);\n\tu16 vlan = ep->l2t->vlan;\n\tint nparams;\n\tint flowclen, flowclen16;\n\n\tif (WARN_ON(!skb))\n\t\treturn -ENOMEM;\n\n\tif (vlan == CPL_L2T_VLAN_NONE)\n\t\tnparams = 9;\n\telse\n\t\tnparams = 10;\n\n\tflowclen = offsetof(struct fw_flowc_wr, mnemval[nparams]);\n\tflowclen16 = DIV_ROUND_UP(flowclen, 16);\n\tflowclen = flowclen16 * 16;\n\n\tflowc = __skb_put(skb, flowclen);\n\tmemset(flowc, 0, flowclen);\n\n\tflowc->op_to_nparams = cpu_to_be32(FW_WR_OP_V(FW_FLOWC_WR) |\n\t\t\t\t\t   FW_FLOWC_WR_NPARAMS_V(nparams));\n\tflowc->flowid_len16 = cpu_to_be32(FW_WR_LEN16_V(flowclen16) |\n\t\t\t\t\t  FW_WR_FLOWID_V(ep->hwtid));\n\n\tflowc->mnemval[0].mnemonic = FW_FLOWC_MNEM_PFNVFN;\n\tflowc->mnemval[0].val = cpu_to_be32(FW_PFVF_CMD_PFN_V\n\t\t\t\t\t    (ep->com.dev->rdev.lldi.pf));\n\tflowc->mnemval[1].mnemonic = FW_FLOWC_MNEM_CH;\n\tflowc->mnemval[1].val = cpu_to_be32(ep->tx_chan);\n\tflowc->mnemval[2].mnemonic = FW_FLOWC_MNEM_PORT;\n\tflowc->mnemval[2].val = cpu_to_be32(ep->tx_chan);\n\tflowc->mnemval[3].mnemonic = FW_FLOWC_MNEM_IQID;\n\tflowc->mnemval[3].val = cpu_to_be32(ep->rss_qid);\n\tflowc->mnemval[4].mnemonic = FW_FLOWC_MNEM_SNDNXT;\n\tflowc->mnemval[4].val = cpu_to_be32(ep->snd_seq);\n\tflowc->mnemval[5].mnemonic = FW_FLOWC_MNEM_RCVNXT;\n\tflowc->mnemval[5].val = cpu_to_be32(ep->rcv_seq);\n\tflowc->mnemval[6].mnemonic = FW_FLOWC_MNEM_SNDBUF;\n\tflowc->mnemval[6].val = cpu_to_be32(ep->snd_win);\n\tflowc->mnemval[7].mnemonic = FW_FLOWC_MNEM_MSS;\n\tflowc->mnemval[7].val = cpu_to_be32(ep->emss);\n\tflowc->mnemval[8].mnemonic = FW_FLOWC_MNEM_RCV_SCALE;\n\tflowc->mnemval[8].val = cpu_to_be32(ep->snd_wscale);\n\tif (nparams == 10) {\n\t\tu16 pri;\n\t\tpri = (vlan & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;\n\t\tflowc->mnemval[9].mnemonic = FW_FLOWC_MNEM_SCHEDCLASS;\n\t\tflowc->mnemval[9].val = cpu_to_be32(pri);\n\t}\n\n\tset_wr_txq(skb, CPL_PRIORITY_DATA, ep->txq_idx);\n\treturn c4iw_ofld_send(&ep->com.dev->rdev, skb);\n}\n\nstatic int send_halfclose(struct c4iw_ep *ep)\n{\n\tstruct sk_buff *skb = skb_dequeue(&ep->com.ep_skb_list);\n\tu32 wrlen = roundup(sizeof(struct cpl_close_con_req), 16);\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tif (WARN_ON(!skb))\n\t\treturn -ENOMEM;\n\n\tcxgb_mk_close_con_req(skb, wrlen, ep->hwtid, ep->txq_idx,\n\t\t\t      NULL, arp_failure_discard);\n\n\treturn c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);\n}\n\nstatic void read_tcb(struct c4iw_ep *ep)\n{\n\tstruct sk_buff *skb;\n\tstruct cpl_get_tcb *req;\n\tint wrlen = roundup(sizeof(*req), 16);\n\n\tskb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\n\tif (WARN_ON(!skb))\n\t\treturn;\n\n\tset_wr_txq(skb, CPL_PRIORITY_CONTROL, ep->ctrlq_idx);\n\treq = (struct cpl_get_tcb *) skb_put(skb, wrlen);\n\tmemset(req, 0, wrlen);\n\tINIT_TP_WR(req, ep->hwtid);\n\tOPCODE_TID(req) = cpu_to_be32(MK_OPCODE_TID(CPL_GET_TCB, ep->hwtid));\n\treq->reply_ctrl = htons(REPLY_CHAN_V(0) | QUEUENO_V(ep->rss_qid));\n\n\t \n\tc4iw_get_ep(&ep->com);\n\tif (WARN_ON(c4iw_ofld_send(&ep->com.dev->rdev, skb)))\n\t\tc4iw_put_ep(&ep->com);\n}\n\nstatic int send_abort_req(struct c4iw_ep *ep)\n{\n\tu32 wrlen = roundup(sizeof(struct cpl_abort_req), 16);\n\tstruct sk_buff *req_skb = skb_dequeue(&ep->com.ep_skb_list);\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tif (WARN_ON(!req_skb))\n\t\treturn -ENOMEM;\n\n\tcxgb_mk_abort_req(req_skb, wrlen, ep->hwtid, ep->txq_idx,\n\t\t\t  ep, abort_arp_failure);\n\n\treturn c4iw_l2t_send(&ep->com.dev->rdev, req_skb, ep->l2t);\n}\n\nstatic int send_abort(struct c4iw_ep *ep)\n{\n\tif (!ep->com.qp || !ep->com.qp->srq) {\n\t\tsend_abort_req(ep);\n\t\treturn 0;\n\t}\n\tset_bit(ABORT_REQ_IN_PROGRESS, &ep->com.flags);\n\tread_tcb(ep);\n\treturn 0;\n}\n\nstatic int send_connect(struct c4iw_ep *ep)\n{\n\tstruct cpl_act_open_req *req = NULL;\n\tstruct cpl_t5_act_open_req *t5req = NULL;\n\tstruct cpl_t6_act_open_req *t6req = NULL;\n\tstruct cpl_act_open_req6 *req6 = NULL;\n\tstruct cpl_t5_act_open_req6 *t5req6 = NULL;\n\tstruct cpl_t6_act_open_req6 *t6req6 = NULL;\n\tstruct sk_buff *skb;\n\tu64 opt0;\n\tu32 opt2;\n\tunsigned int mtu_idx;\n\tu32 wscale;\n\tint win, sizev4, sizev6, wrlen;\n\tstruct sockaddr_in *la = (struct sockaddr_in *)\n\t\t\t\t &ep->com.local_addr;\n\tstruct sockaddr_in *ra = (struct sockaddr_in *)\n\t\t\t\t &ep->com.remote_addr;\n\tstruct sockaddr_in6 *la6 = (struct sockaddr_in6 *)\n\t\t\t\t   &ep->com.local_addr;\n\tstruct sockaddr_in6 *ra6 = (struct sockaddr_in6 *)\n\t\t\t\t   &ep->com.remote_addr;\n\tint ret;\n\tenum chip_type adapter_type = ep->com.dev->rdev.lldi.adapter_type;\n\tu32 isn = (get_random_u32() & ~7UL) - 1;\n\tstruct net_device *netdev;\n\tu64 params;\n\n\tnetdev = ep->com.dev->rdev.lldi.ports[0];\n\n\tswitch (CHELSIO_CHIP_VERSION(adapter_type)) {\n\tcase CHELSIO_T4:\n\t\tsizev4 = sizeof(struct cpl_act_open_req);\n\t\tsizev6 = sizeof(struct cpl_act_open_req6);\n\t\tbreak;\n\tcase CHELSIO_T5:\n\t\tsizev4 = sizeof(struct cpl_t5_act_open_req);\n\t\tsizev6 = sizeof(struct cpl_t5_act_open_req6);\n\t\tbreak;\n\tcase CHELSIO_T6:\n\t\tsizev4 = sizeof(struct cpl_t6_act_open_req);\n\t\tsizev6 = sizeof(struct cpl_t6_act_open_req6);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"T%d Chip is not supported\\n\",\n\t\t       CHELSIO_CHIP_VERSION(adapter_type));\n\t\treturn -EINVAL;\n\t}\n\n\twrlen = (ep->com.remote_addr.ss_family == AF_INET) ?\n\t\t\troundup(sizev4, 16) :\n\t\t\troundup(sizev6, 16);\n\n\tpr_debug(\"ep %p atid %u\\n\", ep, ep->atid);\n\n\tskb = get_skb(NULL, wrlen, GFP_KERNEL);\n\tif (!skb) {\n\t\tpr_err(\"%s - failed to alloc skb\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\tset_wr_txq(skb, CPL_PRIORITY_SETUP, ep->ctrlq_idx);\n\n\tcxgb_best_mtu(ep->com.dev->rdev.lldi.mtus, ep->mtu, &mtu_idx,\n\t\t      enable_tcp_timestamps,\n\t\t      (ep->com.remote_addr.ss_family == AF_INET) ? 0 : 1);\n\twscale = cxgb_compute_wscale(rcv_win);\n\n\t \n\twin = ep->rcv_win >> 10;\n\tif (win > RCV_BUFSIZ_M)\n\t\twin = RCV_BUFSIZ_M;\n\n\topt0 = (nocong ? NO_CONG_F : 0) |\n\t       KEEP_ALIVE_F |\n\t       DELACK_F |\n\t       WND_SCALE_V(wscale) |\n\t       MSS_IDX_V(mtu_idx) |\n\t       L2T_IDX_V(ep->l2t->idx) |\n\t       TX_CHAN_V(ep->tx_chan) |\n\t       SMAC_SEL_V(ep->smac_idx) |\n\t       DSCP_V(ep->tos >> 2) |\n\t       ULP_MODE_V(ULP_MODE_TCPDDP) |\n\t       RCV_BUFSIZ_V(win);\n\topt2 = RX_CHANNEL_V(0) |\n\t       CCTRL_ECN_V(enable_ecn) |\n\t       RSS_QUEUE_VALID_F | RSS_QUEUE_V(ep->rss_qid);\n\tif (enable_tcp_timestamps)\n\t\topt2 |= TSTAMPS_EN_F;\n\tif (enable_tcp_sack)\n\t\topt2 |= SACK_EN_F;\n\tif (wscale && enable_tcp_window_scaling)\n\t\topt2 |= WND_SCALE_EN_F;\n\tif (CHELSIO_CHIP_VERSION(adapter_type) > CHELSIO_T4) {\n\t\tif (peer2peer)\n\t\t\tisn += 4;\n\n\t\topt2 |= T5_OPT_2_VALID_F;\n\t\topt2 |= CONG_CNTRL_V(CONG_ALG_TAHOE);\n\t\topt2 |= T5_ISS_F;\n\t}\n\n\tparams = cxgb4_select_ntuple(netdev, ep->l2t);\n\n\tif (ep->com.remote_addr.ss_family == AF_INET6)\n\t\tcxgb4_clip_get(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t       (const u32 *)&la6->sin6_addr.s6_addr, 1);\n\n\tt4_set_arp_err_handler(skb, ep, act_open_req_arp_failure);\n\n\tif (ep->com.remote_addr.ss_family == AF_INET) {\n\t\tswitch (CHELSIO_CHIP_VERSION(adapter_type)) {\n\t\tcase CHELSIO_T4:\n\t\t\treq = skb_put(skb, wrlen);\n\t\t\tINIT_TP_WR(req, 0);\n\t\t\tbreak;\n\t\tcase CHELSIO_T5:\n\t\t\tt5req = skb_put(skb, wrlen);\n\t\t\tINIT_TP_WR(t5req, 0);\n\t\t\treq = (struct cpl_act_open_req *)t5req;\n\t\t\tbreak;\n\t\tcase CHELSIO_T6:\n\t\t\tt6req = skb_put(skb, wrlen);\n\t\t\tINIT_TP_WR(t6req, 0);\n\t\t\treq = (struct cpl_act_open_req *)t6req;\n\t\t\tt5req = (struct cpl_t5_act_open_req *)t6req;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"T%d Chip is not supported\\n\",\n\t\t\t       CHELSIO_CHIP_VERSION(adapter_type));\n\t\t\tret = -EINVAL;\n\t\t\tgoto clip_release;\n\t\t}\n\n\t\tOPCODE_TID(req) = cpu_to_be32(MK_OPCODE_TID(CPL_ACT_OPEN_REQ,\n\t\t\t\t\t((ep->rss_qid<<14) | ep->atid)));\n\t\treq->local_port = la->sin_port;\n\t\treq->peer_port = ra->sin_port;\n\t\treq->local_ip = la->sin_addr.s_addr;\n\t\treq->peer_ip = ra->sin_addr.s_addr;\n\t\treq->opt0 = cpu_to_be64(opt0);\n\n\t\tif (is_t4(ep->com.dev->rdev.lldi.adapter_type)) {\n\t\t\treq->params = cpu_to_be32(params);\n\t\t\treq->opt2 = cpu_to_be32(opt2);\n\t\t} else {\n\t\t\tif (is_t5(ep->com.dev->rdev.lldi.adapter_type)) {\n\t\t\t\tt5req->params =\n\t\t\t\t\t  cpu_to_be64(FILTER_TUPLE_V(params));\n\t\t\t\tt5req->rsvd = cpu_to_be32(isn);\n\t\t\t\tpr_debug(\"snd_isn %u\\n\", t5req->rsvd);\n\t\t\t\tt5req->opt2 = cpu_to_be32(opt2);\n\t\t\t} else {\n\t\t\t\tt6req->params =\n\t\t\t\t\t  cpu_to_be64(FILTER_TUPLE_V(params));\n\t\t\t\tt6req->rsvd = cpu_to_be32(isn);\n\t\t\t\tpr_debug(\"snd_isn %u\\n\", t6req->rsvd);\n\t\t\t\tt6req->opt2 = cpu_to_be32(opt2);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tswitch (CHELSIO_CHIP_VERSION(adapter_type)) {\n\t\tcase CHELSIO_T4:\n\t\t\treq6 = skb_put(skb, wrlen);\n\t\t\tINIT_TP_WR(req6, 0);\n\t\t\tbreak;\n\t\tcase CHELSIO_T5:\n\t\t\tt5req6 = skb_put(skb, wrlen);\n\t\t\tINIT_TP_WR(t5req6, 0);\n\t\t\treq6 = (struct cpl_act_open_req6 *)t5req6;\n\t\t\tbreak;\n\t\tcase CHELSIO_T6:\n\t\t\tt6req6 = skb_put(skb, wrlen);\n\t\t\tINIT_TP_WR(t6req6, 0);\n\t\t\treq6 = (struct cpl_act_open_req6 *)t6req6;\n\t\t\tt5req6 = (struct cpl_t5_act_open_req6 *)t6req6;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"T%d Chip is not supported\\n\",\n\t\t\t       CHELSIO_CHIP_VERSION(adapter_type));\n\t\t\tret = -EINVAL;\n\t\t\tgoto clip_release;\n\t\t}\n\n\t\tOPCODE_TID(req6) = cpu_to_be32(MK_OPCODE_TID(CPL_ACT_OPEN_REQ6,\n\t\t\t\t\t((ep->rss_qid<<14)|ep->atid)));\n\t\treq6->local_port = la6->sin6_port;\n\t\treq6->peer_port = ra6->sin6_port;\n\t\treq6->local_ip_hi = *((__be64 *)(la6->sin6_addr.s6_addr));\n\t\treq6->local_ip_lo = *((__be64 *)(la6->sin6_addr.s6_addr + 8));\n\t\treq6->peer_ip_hi = *((__be64 *)(ra6->sin6_addr.s6_addr));\n\t\treq6->peer_ip_lo = *((__be64 *)(ra6->sin6_addr.s6_addr + 8));\n\t\treq6->opt0 = cpu_to_be64(opt0);\n\n\t\tif (is_t4(ep->com.dev->rdev.lldi.adapter_type)) {\n\t\t\treq6->params = cpu_to_be32(cxgb4_select_ntuple(netdev,\n\t\t\t\t\t\t\t\t      ep->l2t));\n\t\t\treq6->opt2 = cpu_to_be32(opt2);\n\t\t} else {\n\t\t\tif (is_t5(ep->com.dev->rdev.lldi.adapter_type)) {\n\t\t\t\tt5req6->params =\n\t\t\t\t\t    cpu_to_be64(FILTER_TUPLE_V(params));\n\t\t\t\tt5req6->rsvd = cpu_to_be32(isn);\n\t\t\t\tpr_debug(\"snd_isn %u\\n\", t5req6->rsvd);\n\t\t\t\tt5req6->opt2 = cpu_to_be32(opt2);\n\t\t\t} else {\n\t\t\t\tt6req6->params =\n\t\t\t\t\t    cpu_to_be64(FILTER_TUPLE_V(params));\n\t\t\t\tt6req6->rsvd = cpu_to_be32(isn);\n\t\t\t\tpr_debug(\"snd_isn %u\\n\", t6req6->rsvd);\n\t\t\t\tt6req6->opt2 = cpu_to_be32(opt2);\n\t\t\t}\n\n\t\t}\n\t}\n\n\tset_bit(ACT_OPEN_REQ, &ep->com.history);\n\tret = c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);\nclip_release:\n\tif (ret && ep->com.remote_addr.ss_family == AF_INET6)\n\t\tcxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t   (const u32 *)&la6->sin6_addr.s6_addr, 1);\n\treturn ret;\n}\n\nstatic int send_mpa_req(struct c4iw_ep *ep, struct sk_buff *skb,\n\t\t\tu8 mpa_rev_to_use)\n{\n\tint mpalen, wrlen, ret;\n\tstruct fw_ofld_tx_data_wr *req;\n\tstruct mpa_message *mpa;\n\tstruct mpa_v2_conn_params mpa_v2_params;\n\n\tpr_debug(\"ep %p tid %u pd_len %d\\n\",\n\t\t ep, ep->hwtid, ep->plen);\n\n\tmpalen = sizeof(*mpa) + ep->plen;\n\tif (mpa_rev_to_use == 2)\n\t\tmpalen += sizeof(struct mpa_v2_conn_params);\n\twrlen = roundup(mpalen + sizeof(*req), 16);\n\tskb = get_skb(skb, wrlen, GFP_KERNEL);\n\tif (!skb) {\n\t\tconnect_reply_upcall(ep, -ENOMEM);\n\t\treturn -ENOMEM;\n\t}\n\tset_wr_txq(skb, CPL_PRIORITY_DATA, ep->txq_idx);\n\n\treq = skb_put_zero(skb, wrlen);\n\treq->op_to_immdlen = cpu_to_be32(\n\t\tFW_WR_OP_V(FW_OFLD_TX_DATA_WR) |\n\t\tFW_WR_COMPL_F |\n\t\tFW_WR_IMMDLEN_V(mpalen));\n\treq->flowid_len16 = cpu_to_be32(\n\t\tFW_WR_FLOWID_V(ep->hwtid) |\n\t\tFW_WR_LEN16_V(wrlen >> 4));\n\treq->plen = cpu_to_be32(mpalen);\n\treq->tunnel_to_proxy = cpu_to_be32(\n\t\tFW_OFLD_TX_DATA_WR_FLUSH_F |\n\t\tFW_OFLD_TX_DATA_WR_SHOVE_F);\n\n\tmpa = (struct mpa_message *)(req + 1);\n\tmemcpy(mpa->key, MPA_KEY_REQ, sizeof(mpa->key));\n\n\tmpa->flags = 0;\n\tif (crc_enabled)\n\t\tmpa->flags |= MPA_CRC;\n\tif (markers_enabled) {\n\t\tmpa->flags |= MPA_MARKERS;\n\t\tep->mpa_attr.recv_marker_enabled = 1;\n\t} else {\n\t\tep->mpa_attr.recv_marker_enabled = 0;\n\t}\n\tif (mpa_rev_to_use == 2)\n\t\tmpa->flags |= MPA_ENHANCED_RDMA_CONN;\n\n\tmpa->private_data_size = htons(ep->plen);\n\tmpa->revision = mpa_rev_to_use;\n\tif (mpa_rev_to_use == 1) {\n\t\tep->tried_with_mpa_v1 = 1;\n\t\tep->retry_with_mpa_v1 = 0;\n\t}\n\n\tif (mpa_rev_to_use == 2) {\n\t\tmpa->private_data_size =\n\t\t\thtons(ntohs(mpa->private_data_size) +\n\t\t\t      sizeof(struct mpa_v2_conn_params));\n\t\tpr_debug(\"initiator ird %u ord %u\\n\", ep->ird,\n\t\t\t ep->ord);\n\t\tmpa_v2_params.ird = htons((u16)ep->ird);\n\t\tmpa_v2_params.ord = htons((u16)ep->ord);\n\n\t\tif (peer2peer) {\n\t\t\tmpa_v2_params.ird |= htons(MPA_V2_PEER2PEER_MODEL);\n\t\t\tif (p2p_type == FW_RI_INIT_P2PTYPE_RDMA_WRITE)\n\t\t\t\tmpa_v2_params.ord |=\n\t\t\t\t\thtons(MPA_V2_RDMA_WRITE_RTR);\n\t\t\telse if (p2p_type == FW_RI_INIT_P2PTYPE_READ_REQ)\n\t\t\t\tmpa_v2_params.ord |=\n\t\t\t\t\thtons(MPA_V2_RDMA_READ_RTR);\n\t\t}\n\t\tmemcpy(mpa->private_data, &mpa_v2_params,\n\t\t       sizeof(struct mpa_v2_conn_params));\n\n\t\tif (ep->plen)\n\t\t\tmemcpy(mpa->private_data +\n\t\t\t       sizeof(struct mpa_v2_conn_params),\n\t\t\t       ep->mpa_pkt + sizeof(*mpa), ep->plen);\n\t} else\n\t\tif (ep->plen)\n\t\t\tmemcpy(mpa->private_data,\n\t\t\t\t\tep->mpa_pkt + sizeof(*mpa), ep->plen);\n\n\t \n\tskb_get(skb);\n\tt4_set_arp_err_handler(skb, NULL, arp_failure_discard);\n\tep->mpa_skb = skb;\n\tret = c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);\n\tif (ret)\n\t\treturn ret;\n\tstart_ep_timer(ep);\n\t__state_set(&ep->com, MPA_REQ_SENT);\n\tep->mpa_attr.initiator = 1;\n\tep->snd_seq += mpalen;\n\treturn ret;\n}\n\nstatic int send_mpa_reject(struct c4iw_ep *ep, const void *pdata, u8 plen)\n{\n\tint mpalen, wrlen;\n\tstruct fw_ofld_tx_data_wr *req;\n\tstruct mpa_message *mpa;\n\tstruct sk_buff *skb;\n\tstruct mpa_v2_conn_params mpa_v2_params;\n\n\tpr_debug(\"ep %p tid %u pd_len %d\\n\",\n\t\t ep, ep->hwtid, ep->plen);\n\n\tmpalen = sizeof(*mpa) + plen;\n\tif (ep->mpa_attr.version == 2 && ep->mpa_attr.enhanced_rdma_conn)\n\t\tmpalen += sizeof(struct mpa_v2_conn_params);\n\twrlen = roundup(mpalen + sizeof(*req), 16);\n\n\tskb = get_skb(NULL, wrlen, GFP_KERNEL);\n\tif (!skb) {\n\t\tpr_err(\"%s - cannot alloc skb!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\tset_wr_txq(skb, CPL_PRIORITY_DATA, ep->txq_idx);\n\n\treq = skb_put_zero(skb, wrlen);\n\treq->op_to_immdlen = cpu_to_be32(\n\t\tFW_WR_OP_V(FW_OFLD_TX_DATA_WR) |\n\t\tFW_WR_COMPL_F |\n\t\tFW_WR_IMMDLEN_V(mpalen));\n\treq->flowid_len16 = cpu_to_be32(\n\t\tFW_WR_FLOWID_V(ep->hwtid) |\n\t\tFW_WR_LEN16_V(wrlen >> 4));\n\treq->plen = cpu_to_be32(mpalen);\n\treq->tunnel_to_proxy = cpu_to_be32(\n\t\tFW_OFLD_TX_DATA_WR_FLUSH_F |\n\t\tFW_OFLD_TX_DATA_WR_SHOVE_F);\n\n\tmpa = (struct mpa_message *)(req + 1);\n\tmemset(mpa, 0, sizeof(*mpa));\n\tmemcpy(mpa->key, MPA_KEY_REP, sizeof(mpa->key));\n\tmpa->flags = MPA_REJECT;\n\tmpa->revision = ep->mpa_attr.version;\n\tmpa->private_data_size = htons(plen);\n\n\tif (ep->mpa_attr.version == 2 && ep->mpa_attr.enhanced_rdma_conn) {\n\t\tmpa->flags |= MPA_ENHANCED_RDMA_CONN;\n\t\tmpa->private_data_size =\n\t\t\thtons(ntohs(mpa->private_data_size) +\n\t\t\t      sizeof(struct mpa_v2_conn_params));\n\t\tmpa_v2_params.ird = htons(((u16)ep->ird) |\n\t\t\t\t\t  (peer2peer ? MPA_V2_PEER2PEER_MODEL :\n\t\t\t\t\t   0));\n\t\tmpa_v2_params.ord = htons(((u16)ep->ord) | (peer2peer ?\n\t\t\t\t\t  (p2p_type ==\n\t\t\t\t\t   FW_RI_INIT_P2PTYPE_RDMA_WRITE ?\n\t\t\t\t\t   MPA_V2_RDMA_WRITE_RTR : p2p_type ==\n\t\t\t\t\t   FW_RI_INIT_P2PTYPE_READ_REQ ?\n\t\t\t\t\t   MPA_V2_RDMA_READ_RTR : 0) : 0));\n\t\tmemcpy(mpa->private_data, &mpa_v2_params,\n\t\t       sizeof(struct mpa_v2_conn_params));\n\n\t\tif (ep->plen)\n\t\t\tmemcpy(mpa->private_data +\n\t\t\t       sizeof(struct mpa_v2_conn_params), pdata, plen);\n\t} else\n\t\tif (plen)\n\t\t\tmemcpy(mpa->private_data, pdata, plen);\n\n\t \n\tskb_get(skb);\n\tset_wr_txq(skb, CPL_PRIORITY_DATA, ep->txq_idx);\n\tt4_set_arp_err_handler(skb, NULL, mpa_start_arp_failure);\n\tep->mpa_skb = skb;\n\tep->snd_seq += mpalen;\n\treturn c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);\n}\n\nstatic int send_mpa_reply(struct c4iw_ep *ep, const void *pdata, u8 plen)\n{\n\tint mpalen, wrlen;\n\tstruct fw_ofld_tx_data_wr *req;\n\tstruct mpa_message *mpa;\n\tstruct sk_buff *skb;\n\tstruct mpa_v2_conn_params mpa_v2_params;\n\n\tpr_debug(\"ep %p tid %u pd_len %d\\n\",\n\t\t ep, ep->hwtid, ep->plen);\n\n\tmpalen = sizeof(*mpa) + plen;\n\tif (ep->mpa_attr.version == 2 && ep->mpa_attr.enhanced_rdma_conn)\n\t\tmpalen += sizeof(struct mpa_v2_conn_params);\n\twrlen = roundup(mpalen + sizeof(*req), 16);\n\n\tskb = get_skb(NULL, wrlen, GFP_KERNEL);\n\tif (!skb) {\n\t\tpr_err(\"%s - cannot alloc skb!\\n\", __func__);\n\t\treturn -ENOMEM;\n\t}\n\tset_wr_txq(skb, CPL_PRIORITY_DATA, ep->txq_idx);\n\n\treq = skb_put_zero(skb, wrlen);\n\treq->op_to_immdlen = cpu_to_be32(\n\t\tFW_WR_OP_V(FW_OFLD_TX_DATA_WR) |\n\t\tFW_WR_COMPL_F |\n\t\tFW_WR_IMMDLEN_V(mpalen));\n\treq->flowid_len16 = cpu_to_be32(\n\t\tFW_WR_FLOWID_V(ep->hwtid) |\n\t\tFW_WR_LEN16_V(wrlen >> 4));\n\treq->plen = cpu_to_be32(mpalen);\n\treq->tunnel_to_proxy = cpu_to_be32(\n\t\tFW_OFLD_TX_DATA_WR_FLUSH_F |\n\t\tFW_OFLD_TX_DATA_WR_SHOVE_F);\n\n\tmpa = (struct mpa_message *)(req + 1);\n\tmemset(mpa, 0, sizeof(*mpa));\n\tmemcpy(mpa->key, MPA_KEY_REP, sizeof(mpa->key));\n\tmpa->flags = 0;\n\tif (ep->mpa_attr.crc_enabled)\n\t\tmpa->flags |= MPA_CRC;\n\tif (ep->mpa_attr.recv_marker_enabled)\n\t\tmpa->flags |= MPA_MARKERS;\n\tmpa->revision = ep->mpa_attr.version;\n\tmpa->private_data_size = htons(plen);\n\n\tif (ep->mpa_attr.version == 2 && ep->mpa_attr.enhanced_rdma_conn) {\n\t\tmpa->flags |= MPA_ENHANCED_RDMA_CONN;\n\t\tmpa->private_data_size =\n\t\t\thtons(ntohs(mpa->private_data_size) +\n\t\t\t      sizeof(struct mpa_v2_conn_params));\n\t\tmpa_v2_params.ird = htons((u16)ep->ird);\n\t\tmpa_v2_params.ord = htons((u16)ep->ord);\n\t\tif (peer2peer && (ep->mpa_attr.p2p_type !=\n\t\t\t\t\tFW_RI_INIT_P2PTYPE_DISABLED)) {\n\t\t\tmpa_v2_params.ird |= htons(MPA_V2_PEER2PEER_MODEL);\n\n\t\t\tif (p2p_type == FW_RI_INIT_P2PTYPE_RDMA_WRITE)\n\t\t\t\tmpa_v2_params.ord |=\n\t\t\t\t\thtons(MPA_V2_RDMA_WRITE_RTR);\n\t\t\telse if (p2p_type == FW_RI_INIT_P2PTYPE_READ_REQ)\n\t\t\t\tmpa_v2_params.ord |=\n\t\t\t\t\thtons(MPA_V2_RDMA_READ_RTR);\n\t\t}\n\n\t\tmemcpy(mpa->private_data, &mpa_v2_params,\n\t\t       sizeof(struct mpa_v2_conn_params));\n\n\t\tif (ep->plen)\n\t\t\tmemcpy(mpa->private_data +\n\t\t\t       sizeof(struct mpa_v2_conn_params), pdata, plen);\n\t} else\n\t\tif (plen)\n\t\t\tmemcpy(mpa->private_data, pdata, plen);\n\n\t \n\tskb_get(skb);\n\tt4_set_arp_err_handler(skb, NULL, mpa_start_arp_failure);\n\tep->mpa_skb = skb;\n\t__state_set(&ep->com, MPA_REP_SENT);\n\tep->snd_seq += mpalen;\n\treturn c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);\n}\n\nstatic int act_establish(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\tstruct cpl_act_establish *req = cplhdr(skb);\n\tunsigned short tcp_opt = ntohs(req->tcp_opt);\n\tunsigned int tid = GET_TID(req);\n\tunsigned int atid = TID_TID_G(ntohl(req->tos_atid));\n\tstruct tid_info *t = dev->rdev.lldi.tids;\n\tint ret;\n\n\tep = lookup_atid(t, atid);\n\n\tpr_debug(\"ep %p tid %u snd_isn %u rcv_isn %u\\n\", ep, tid,\n\t\t be32_to_cpu(req->snd_isn), be32_to_cpu(req->rcv_isn));\n\n\tmutex_lock(&ep->com.mutex);\n\tdst_confirm(ep->dst);\n\n\t \n\tep->hwtid = tid;\n\tcxgb4_insert_tid(t, ep, tid, ep->com.local_addr.ss_family);\n\tinsert_ep_tid(ep);\n\n\tep->snd_seq = be32_to_cpu(req->snd_isn);\n\tep->rcv_seq = be32_to_cpu(req->rcv_isn);\n\tep->snd_wscale = TCPOPT_SND_WSCALE_G(tcp_opt);\n\n\tset_emss(ep, tcp_opt);\n\n\t \n\txa_erase_irq(&ep->com.dev->atids, atid);\n\tcxgb4_free_atid(t, atid);\n\tset_bit(ACT_ESTAB, &ep->com.history);\n\n\t \n\tret = send_flowc(ep);\n\tif (ret)\n\t\tgoto err;\n\tif (ep->retry_with_mpa_v1)\n\t\tret = send_mpa_req(ep, skb, 1);\n\telse\n\t\tret = send_mpa_req(ep, skb, mpa_rev);\n\tif (ret)\n\t\tgoto err;\n\tmutex_unlock(&ep->com.mutex);\n\treturn 0;\nerr:\n\tmutex_unlock(&ep->com.mutex);\n\tconnect_reply_upcall(ep, -ENOMEM);\n\tc4iw_ep_disconnect(ep, 0, GFP_KERNEL);\n\treturn 0;\n}\n\nstatic void close_complete_upcall(struct c4iw_ep *ep, int status)\n{\n\tstruct iw_cm_event event;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tmemset(&event, 0, sizeof(event));\n\tevent.event = IW_CM_EVENT_CLOSE;\n\tevent.status = status;\n\tif (ep->com.cm_id) {\n\t\tpr_debug(\"close complete delivered ep %p cm_id %p tid %u\\n\",\n\t\t\t ep, ep->com.cm_id, ep->hwtid);\n\t\tep->com.cm_id->event_handler(ep->com.cm_id, &event);\n\t\tderef_cm_id(&ep->com);\n\t\tset_bit(CLOSE_UPCALL, &ep->com.history);\n\t}\n}\n\nstatic void peer_close_upcall(struct c4iw_ep *ep)\n{\n\tstruct iw_cm_event event;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tmemset(&event, 0, sizeof(event));\n\tevent.event = IW_CM_EVENT_DISCONNECT;\n\tif (ep->com.cm_id) {\n\t\tpr_debug(\"peer close delivered ep %p cm_id %p tid %u\\n\",\n\t\t\t ep, ep->com.cm_id, ep->hwtid);\n\t\tep->com.cm_id->event_handler(ep->com.cm_id, &event);\n\t\tset_bit(DISCONN_UPCALL, &ep->com.history);\n\t}\n}\n\nstatic void peer_abort_upcall(struct c4iw_ep *ep)\n{\n\tstruct iw_cm_event event;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tmemset(&event, 0, sizeof(event));\n\tevent.event = IW_CM_EVENT_CLOSE;\n\tevent.status = -ECONNRESET;\n\tif (ep->com.cm_id) {\n\t\tpr_debug(\"abort delivered ep %p cm_id %p tid %u\\n\", ep,\n\t\t\t ep->com.cm_id, ep->hwtid);\n\t\tep->com.cm_id->event_handler(ep->com.cm_id, &event);\n\t\tderef_cm_id(&ep->com);\n\t\tset_bit(ABORT_UPCALL, &ep->com.history);\n\t}\n}\n\nstatic void connect_reply_upcall(struct c4iw_ep *ep, int status)\n{\n\tstruct iw_cm_event event;\n\n\tpr_debug(\"ep %p tid %u status %d\\n\",\n\t\t ep, ep->hwtid, status);\n\tmemset(&event, 0, sizeof(event));\n\tevent.event = IW_CM_EVENT_CONNECT_REPLY;\n\tevent.status = status;\n\tmemcpy(&event.local_addr, &ep->com.local_addr,\n\t       sizeof(ep->com.local_addr));\n\tmemcpy(&event.remote_addr, &ep->com.remote_addr,\n\t       sizeof(ep->com.remote_addr));\n\n\tif ((status == 0) || (status == -ECONNREFUSED)) {\n\t\tif (!ep->tried_with_mpa_v1) {\n\t\t\t \n\t\t\tevent.ord = ep->ird;\n\t\t\tevent.ird = ep->ord;\n\t\t\tevent.private_data_len = ep->plen -\n\t\t\t\tsizeof(struct mpa_v2_conn_params);\n\t\t\tevent.private_data = ep->mpa_pkt +\n\t\t\t\tsizeof(struct mpa_message) +\n\t\t\t\tsizeof(struct mpa_v2_conn_params);\n\t\t} else {\n\t\t\t \n\t\t\tevent.ord = cur_max_read_depth(ep->com.dev);\n\t\t\tevent.ird = cur_max_read_depth(ep->com.dev);\n\t\t\tevent.private_data_len = ep->plen;\n\t\t\tevent.private_data = ep->mpa_pkt +\n\t\t\t\tsizeof(struct mpa_message);\n\t\t}\n\t}\n\n\tpr_debug(\"ep %p tid %u status %d\\n\", ep,\n\t\t ep->hwtid, status);\n\tset_bit(CONN_RPL_UPCALL, &ep->com.history);\n\tep->com.cm_id->event_handler(ep->com.cm_id, &event);\n\n\tif (status < 0)\n\t\tderef_cm_id(&ep->com);\n}\n\nstatic int connect_request_upcall(struct c4iw_ep *ep)\n{\n\tstruct iw_cm_event event;\n\tint ret;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tmemset(&event, 0, sizeof(event));\n\tevent.event = IW_CM_EVENT_CONNECT_REQUEST;\n\tmemcpy(&event.local_addr, &ep->com.local_addr,\n\t       sizeof(ep->com.local_addr));\n\tmemcpy(&event.remote_addr, &ep->com.remote_addr,\n\t       sizeof(ep->com.remote_addr));\n\tevent.provider_data = ep;\n\tif (!ep->tried_with_mpa_v1) {\n\t\t \n\t\tevent.ord = ep->ord;\n\t\tevent.ird = ep->ird;\n\t\tevent.private_data_len = ep->plen -\n\t\t\tsizeof(struct mpa_v2_conn_params);\n\t\tevent.private_data = ep->mpa_pkt + sizeof(struct mpa_message) +\n\t\t\tsizeof(struct mpa_v2_conn_params);\n\t} else {\n\t\t \n\t\tevent.ord = cur_max_read_depth(ep->com.dev);\n\t\tevent.ird = cur_max_read_depth(ep->com.dev);\n\t\tevent.private_data_len = ep->plen;\n\t\tevent.private_data = ep->mpa_pkt + sizeof(struct mpa_message);\n\t}\n\tc4iw_get_ep(&ep->com);\n\tret = ep->parent_ep->com.cm_id->event_handler(ep->parent_ep->com.cm_id,\n\t\t\t\t\t\t      &event);\n\tif (ret)\n\t\tc4iw_put_ep(&ep->com);\n\tset_bit(CONNREQ_UPCALL, &ep->com.history);\n\tc4iw_put_ep(&ep->parent_ep->com);\n\treturn ret;\n}\n\nstatic void established_upcall(struct c4iw_ep *ep)\n{\n\tstruct iw_cm_event event;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tmemset(&event, 0, sizeof(event));\n\tevent.event = IW_CM_EVENT_ESTABLISHED;\n\tevent.ird = ep->ord;\n\tevent.ord = ep->ird;\n\tif (ep->com.cm_id) {\n\t\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\t\tep->com.cm_id->event_handler(ep->com.cm_id, &event);\n\t\tset_bit(ESTAB_UPCALL, &ep->com.history);\n\t}\n}\n\nstatic int update_rx_credits(struct c4iw_ep *ep, u32 credits)\n{\n\tstruct sk_buff *skb;\n\tu32 wrlen = roundup(sizeof(struct cpl_rx_data_ack), 16);\n\tu32 credit_dack;\n\n\tpr_debug(\"ep %p tid %u credits %u\\n\",\n\t\t ep, ep->hwtid, credits);\n\tskb = get_skb(NULL, wrlen, GFP_KERNEL);\n\tif (!skb) {\n\t\tpr_err(\"update_rx_credits - cannot alloc skb!\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tif (ep->rcv_win > RCV_BUFSIZ_M * 1024)\n\t\tcredits += ep->rcv_win - RCV_BUFSIZ_M * 1024;\n\n\tcredit_dack = credits | RX_FORCE_ACK_F | RX_DACK_CHANGE_F |\n\t\t      RX_DACK_MODE_V(dack_mode);\n\n\tcxgb_mk_rx_data_ack(skb, wrlen, ep->hwtid, ep->ctrlq_idx,\n\t\t\t    credit_dack);\n\n\tc4iw_ofld_send(&ep->com.dev->rdev, skb);\n\treturn credits;\n}\n\n#define RELAXED_IRD_NEGOTIATION 1\n\n \nstatic int process_mpa_reply(struct c4iw_ep *ep, struct sk_buff *skb)\n{\n\tstruct mpa_message *mpa;\n\tstruct mpa_v2_conn_params *mpa_v2_params;\n\tu16 plen;\n\tu16 resp_ird, resp_ord;\n\tu8 rtr_mismatch = 0, insuff_ird = 0;\n\tstruct c4iw_qp_attributes attrs;\n\tenum c4iw_qp_attr_mask mask;\n\tint err;\n\tint disconnect = 0;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\n\t \n\tif (ep->mpa_pkt_len + skb->len > sizeof(ep->mpa_pkt)) {\n\t\terr = -EINVAL;\n\t\tgoto err_stop_timer;\n\t}\n\n\t \n\tskb_copy_from_linear_data(skb, &(ep->mpa_pkt[ep->mpa_pkt_len]),\n\t\t\t\t  skb->len);\n\tep->mpa_pkt_len += skb->len;\n\n\t \n\tif (ep->mpa_pkt_len < sizeof(*mpa))\n\t\treturn 0;\n\tmpa = (struct mpa_message *) ep->mpa_pkt;\n\n\t \n\tif (mpa->revision > mpa_rev) {\n\t\tpr_err(\"%s MPA version mismatch. Local = %d, Received = %d\\n\",\n\t\t       __func__, mpa_rev, mpa->revision);\n\t\terr = -EPROTO;\n\t\tgoto err_stop_timer;\n\t}\n\tif (memcmp(mpa->key, MPA_KEY_REP, sizeof(mpa->key))) {\n\t\terr = -EPROTO;\n\t\tgoto err_stop_timer;\n\t}\n\n\tplen = ntohs(mpa->private_data_size);\n\n\t \n\tif (plen > MPA_MAX_PRIVATE_DATA) {\n\t\terr = -EPROTO;\n\t\tgoto err_stop_timer;\n\t}\n\n\t \n\tif (ep->mpa_pkt_len > (sizeof(*mpa) + plen)) {\n\t\terr = -EPROTO;\n\t\tgoto err_stop_timer;\n\t}\n\n\tep->plen = (u8) plen;\n\n\t \n\tif (ep->mpa_pkt_len < (sizeof(*mpa) + plen))\n\t\treturn 0;\n\n\tif (mpa->flags & MPA_REJECT) {\n\t\terr = -ECONNREFUSED;\n\t\tgoto err_stop_timer;\n\t}\n\n\t \n\tif (stop_ep_timer(ep))\n\t\treturn 0;\n\n\t \n\t__state_set(&ep->com, FPDU_MODE);\n\tep->mpa_attr.crc_enabled = (mpa->flags & MPA_CRC) | crc_enabled ? 1 : 0;\n\tep->mpa_attr.xmit_marker_enabled = mpa->flags & MPA_MARKERS ? 1 : 0;\n\tep->mpa_attr.version = mpa->revision;\n\tep->mpa_attr.p2p_type = FW_RI_INIT_P2PTYPE_DISABLED;\n\n\tif (mpa->revision == 2) {\n\t\tep->mpa_attr.enhanced_rdma_conn =\n\t\t\tmpa->flags & MPA_ENHANCED_RDMA_CONN ? 1 : 0;\n\t\tif (ep->mpa_attr.enhanced_rdma_conn) {\n\t\t\tmpa_v2_params = (struct mpa_v2_conn_params *)\n\t\t\t\t(ep->mpa_pkt + sizeof(*mpa));\n\t\t\tresp_ird = ntohs(mpa_v2_params->ird) &\n\t\t\t\tMPA_V2_IRD_ORD_MASK;\n\t\t\tresp_ord = ntohs(mpa_v2_params->ord) &\n\t\t\t\tMPA_V2_IRD_ORD_MASK;\n\t\t\tpr_debug(\"responder ird %u ord %u ep ird %u ord %u\\n\",\n\t\t\t\t resp_ird, resp_ord, ep->ird, ep->ord);\n\n\t\t\t \n\t\t\tif (ep->ird < resp_ord) {\n\t\t\t\tif (RELAXED_IRD_NEGOTIATION && resp_ord <=\n\t\t\t\t    ep->com.dev->rdev.lldi.max_ordird_qp)\n\t\t\t\t\tep->ird = resp_ord;\n\t\t\t\telse\n\t\t\t\t\tinsuff_ird = 1;\n\t\t\t} else if (ep->ird > resp_ord) {\n\t\t\t\tep->ird = resp_ord;\n\t\t\t}\n\t\t\tif (ep->ord > resp_ird) {\n\t\t\t\tif (RELAXED_IRD_NEGOTIATION)\n\t\t\t\t\tep->ord = resp_ird;\n\t\t\t\telse\n\t\t\t\t\tinsuff_ird = 1;\n\t\t\t}\n\t\t\tif (insuff_ird) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tep->ird = resp_ord;\n\t\t\t\tep->ord = resp_ird;\n\t\t\t}\n\n\t\t\tif (ntohs(mpa_v2_params->ird) &\n\t\t\t\t\tMPA_V2_PEER2PEER_MODEL) {\n\t\t\t\tif (ntohs(mpa_v2_params->ord) &\n\t\t\t\t\t\tMPA_V2_RDMA_WRITE_RTR)\n\t\t\t\t\tep->mpa_attr.p2p_type =\n\t\t\t\t\t\tFW_RI_INIT_P2PTYPE_RDMA_WRITE;\n\t\t\t\telse if (ntohs(mpa_v2_params->ord) &\n\t\t\t\t\t\tMPA_V2_RDMA_READ_RTR)\n\t\t\t\t\tep->mpa_attr.p2p_type =\n\t\t\t\t\t\tFW_RI_INIT_P2PTYPE_READ_REQ;\n\t\t\t}\n\t\t}\n\t} else if (mpa->revision == 1)\n\t\tif (peer2peer)\n\t\t\tep->mpa_attr.p2p_type = p2p_type;\n\n\tpr_debug(\"crc_enabled=%d, recv_marker_enabled=%d, xmit_marker_enabled=%d, version=%d p2p_type=%d local-p2p_type = %d\\n\",\n\t\t ep->mpa_attr.crc_enabled,\n\t\t ep->mpa_attr.recv_marker_enabled,\n\t\t ep->mpa_attr.xmit_marker_enabled, ep->mpa_attr.version,\n\t\t ep->mpa_attr.p2p_type, p2p_type);\n\n\t \n\tif ((ep->mpa_attr.version == 2) && peer2peer &&\n\t\t\t(ep->mpa_attr.p2p_type != p2p_type)) {\n\t\tep->mpa_attr.p2p_type = FW_RI_INIT_P2PTYPE_DISABLED;\n\t\trtr_mismatch = 1;\n\t}\n\n\tattrs.mpa_attr = ep->mpa_attr;\n\tattrs.max_ird = ep->ird;\n\tattrs.max_ord = ep->ord;\n\tattrs.llp_stream_handle = ep;\n\tattrs.next_state = C4IW_QP_STATE_RTS;\n\n\tmask = C4IW_QP_ATTR_NEXT_STATE |\n\t    C4IW_QP_ATTR_LLP_STREAM_HANDLE | C4IW_QP_ATTR_MPA_ATTR |\n\t    C4IW_QP_ATTR_MAX_IRD | C4IW_QP_ATTR_MAX_ORD;\n\n\t \n\terr = c4iw_modify_qp(ep->com.qp->rhp,\n\t\t\t     ep->com.qp, mask, &attrs, 1);\n\tif (err)\n\t\tgoto err;\n\n\t \n\tif (rtr_mismatch) {\n\t\tpr_err(\"%s: RTR mismatch, sending TERM\\n\", __func__);\n\t\tattrs.layer_etype = LAYER_MPA | DDP_LLP;\n\t\tattrs.ecode = MPA_NOMATCH_RTR;\n\t\tattrs.next_state = C4IW_QP_STATE_TERMINATE;\n\t\tattrs.send_term = 1;\n\t\terr = c4iw_modify_qp(ep->com.qp->rhp, ep->com.qp,\n\t\t\t\tC4IW_QP_ATTR_NEXT_STATE, &attrs, 1);\n\t\terr = -ENOMEM;\n\t\tdisconnect = 1;\n\t\tgoto out;\n\t}\n\n\t \n\tif (insuff_ird) {\n\t\tpr_err(\"%s: Insufficient IRD, sending TERM\\n\", __func__);\n\t\tattrs.layer_etype = LAYER_MPA | DDP_LLP;\n\t\tattrs.ecode = MPA_INSUFF_IRD;\n\t\tattrs.next_state = C4IW_QP_STATE_TERMINATE;\n\t\tattrs.send_term = 1;\n\t\terr = c4iw_modify_qp(ep->com.qp->rhp, ep->com.qp,\n\t\t\t\tC4IW_QP_ATTR_NEXT_STATE, &attrs, 1);\n\t\terr = -ENOMEM;\n\t\tdisconnect = 1;\n\t\tgoto out;\n\t}\n\tgoto out;\nerr_stop_timer:\n\tstop_ep_timer(ep);\nerr:\n\tdisconnect = 2;\nout:\n\tconnect_reply_upcall(ep, err);\n\treturn disconnect;\n}\n\n \nstatic int process_mpa_request(struct c4iw_ep *ep, struct sk_buff *skb)\n{\n\tstruct mpa_message *mpa;\n\tstruct mpa_v2_conn_params *mpa_v2_params;\n\tu16 plen;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\n\t \n\tif (ep->mpa_pkt_len + skb->len > sizeof(ep->mpa_pkt))\n\t\tgoto err_stop_timer;\n\n\tpr_debug(\"enter (%s line %u)\\n\", __FILE__, __LINE__);\n\n\t \n\tskb_copy_from_linear_data(skb, &(ep->mpa_pkt[ep->mpa_pkt_len]),\n\t\t\t\t  skb->len);\n\tep->mpa_pkt_len += skb->len;\n\n\t \n\tif (ep->mpa_pkt_len < sizeof(*mpa))\n\t\treturn 0;\n\n\tpr_debug(\"enter (%s line %u)\\n\", __FILE__, __LINE__);\n\tmpa = (struct mpa_message *) ep->mpa_pkt;\n\n\t \n\tif (mpa->revision > mpa_rev) {\n\t\tpr_err(\"%s MPA version mismatch. Local = %d, Received = %d\\n\",\n\t\t       __func__, mpa_rev, mpa->revision);\n\t\tgoto err_stop_timer;\n\t}\n\n\tif (memcmp(mpa->key, MPA_KEY_REQ, sizeof(mpa->key)))\n\t\tgoto err_stop_timer;\n\n\tplen = ntohs(mpa->private_data_size);\n\n\t \n\tif (plen > MPA_MAX_PRIVATE_DATA)\n\t\tgoto err_stop_timer;\n\n\t \n\tif (ep->mpa_pkt_len > (sizeof(*mpa) + plen))\n\t\tgoto err_stop_timer;\n\tep->plen = (u8) plen;\n\n\t \n\tif (ep->mpa_pkt_len < (sizeof(*mpa) + plen))\n\t\treturn 0;\n\n\t \n\tep->mpa_attr.initiator = 0;\n\tep->mpa_attr.crc_enabled = (mpa->flags & MPA_CRC) | crc_enabled ? 1 : 0;\n\tep->mpa_attr.recv_marker_enabled = markers_enabled;\n\tep->mpa_attr.xmit_marker_enabled = mpa->flags & MPA_MARKERS ? 1 : 0;\n\tep->mpa_attr.version = mpa->revision;\n\tif (mpa->revision == 1)\n\t\tep->tried_with_mpa_v1 = 1;\n\tep->mpa_attr.p2p_type = FW_RI_INIT_P2PTYPE_DISABLED;\n\n\tif (mpa->revision == 2) {\n\t\tep->mpa_attr.enhanced_rdma_conn =\n\t\t\tmpa->flags & MPA_ENHANCED_RDMA_CONN ? 1 : 0;\n\t\tif (ep->mpa_attr.enhanced_rdma_conn) {\n\t\t\tmpa_v2_params = (struct mpa_v2_conn_params *)\n\t\t\t\t(ep->mpa_pkt + sizeof(*mpa));\n\t\t\tep->ird = ntohs(mpa_v2_params->ird) &\n\t\t\t\tMPA_V2_IRD_ORD_MASK;\n\t\t\tep->ird = min_t(u32, ep->ird,\n\t\t\t\t\tcur_max_read_depth(ep->com.dev));\n\t\t\tep->ord = ntohs(mpa_v2_params->ord) &\n\t\t\t\tMPA_V2_IRD_ORD_MASK;\n\t\t\tep->ord = min_t(u32, ep->ord,\n\t\t\t\t\tcur_max_read_depth(ep->com.dev));\n\t\t\tpr_debug(\"initiator ird %u ord %u\\n\",\n\t\t\t\t ep->ird, ep->ord);\n\t\t\tif (ntohs(mpa_v2_params->ird) & MPA_V2_PEER2PEER_MODEL)\n\t\t\t\tif (peer2peer) {\n\t\t\t\t\tif (ntohs(mpa_v2_params->ord) &\n\t\t\t\t\t\t\tMPA_V2_RDMA_WRITE_RTR)\n\t\t\t\t\t\tep->mpa_attr.p2p_type =\n\t\t\t\t\t\tFW_RI_INIT_P2PTYPE_RDMA_WRITE;\n\t\t\t\t\telse if (ntohs(mpa_v2_params->ord) &\n\t\t\t\t\t\t\tMPA_V2_RDMA_READ_RTR)\n\t\t\t\t\t\tep->mpa_attr.p2p_type =\n\t\t\t\t\t\tFW_RI_INIT_P2PTYPE_READ_REQ;\n\t\t\t\t}\n\t\t}\n\t} else if (mpa->revision == 1)\n\t\tif (peer2peer)\n\t\t\tep->mpa_attr.p2p_type = p2p_type;\n\n\tpr_debug(\"crc_enabled=%d, recv_marker_enabled=%d, xmit_marker_enabled=%d, version=%d p2p_type=%d\\n\",\n\t\t ep->mpa_attr.crc_enabled, ep->mpa_attr.recv_marker_enabled,\n\t\t ep->mpa_attr.xmit_marker_enabled, ep->mpa_attr.version,\n\t\t ep->mpa_attr.p2p_type);\n\n\t__state_set(&ep->com, MPA_REQ_RCVD);\n\n\t \n\tmutex_lock_nested(&ep->parent_ep->com.mutex, SINGLE_DEPTH_NESTING);\n\tif (ep->parent_ep->com.state != DEAD) {\n\t\tif (connect_request_upcall(ep))\n\t\t\tgoto err_unlock_parent;\n\t} else {\n\t\tgoto err_unlock_parent;\n\t}\n\tmutex_unlock(&ep->parent_ep->com.mutex);\n\treturn 0;\n\nerr_unlock_parent:\n\tmutex_unlock(&ep->parent_ep->com.mutex);\n\tgoto err_out;\nerr_stop_timer:\n\t(void)stop_ep_timer(ep);\nerr_out:\n\treturn 2;\n}\n\nstatic int rx_data(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\tstruct cpl_rx_data *hdr = cplhdr(skb);\n\tunsigned int dlen = ntohs(hdr->len);\n\tunsigned int tid = GET_TID(hdr);\n\t__u8 status = hdr->status;\n\tint disconnect = 0;\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep)\n\t\treturn 0;\n\tpr_debug(\"ep %p tid %u dlen %u\\n\", ep, ep->hwtid, dlen);\n\tskb_pull(skb, sizeof(*hdr));\n\tskb_trim(skb, dlen);\n\tmutex_lock(&ep->com.mutex);\n\n\tswitch (ep->com.state) {\n\tcase MPA_REQ_SENT:\n\t\tupdate_rx_credits(ep, dlen);\n\t\tep->rcv_seq += dlen;\n\t\tdisconnect = process_mpa_reply(ep, skb);\n\t\tbreak;\n\tcase MPA_REQ_WAIT:\n\t\tupdate_rx_credits(ep, dlen);\n\t\tep->rcv_seq += dlen;\n\t\tdisconnect = process_mpa_request(ep, skb);\n\t\tbreak;\n\tcase FPDU_MODE: {\n\t\tstruct c4iw_qp_attributes attrs;\n\n\t\tupdate_rx_credits(ep, dlen);\n\t\tif (status)\n\t\t\tpr_err(\"%s Unexpected streaming data.\" \\\n\t\t\t       \" qpid %u ep %p state %d tid %u status %d\\n\",\n\t\t\t       __func__, ep->com.qp->wq.sq.qid, ep,\n\t\t\t       ep->com.state, ep->hwtid, status);\n\t\tattrs.next_state = C4IW_QP_STATE_TERMINATE;\n\t\tc4iw_modify_qp(ep->com.qp->rhp, ep->com.qp,\n\t\t\t       C4IW_QP_ATTR_NEXT_STATE, &attrs, 1);\n\t\tdisconnect = 1;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tmutex_unlock(&ep->com.mutex);\n\tif (disconnect)\n\t\tc4iw_ep_disconnect(ep, disconnect == 2, GFP_KERNEL);\n\tc4iw_put_ep(&ep->com);\n\treturn 0;\n}\n\nstatic void complete_cached_srq_buffers(struct c4iw_ep *ep, u32 srqidx)\n{\n\tenum chip_type adapter_type;\n\n\tadapter_type = ep->com.dev->rdev.lldi.adapter_type;\n\n\t \n\tif (CHELSIO_CHIP_VERSION(adapter_type) > CHELSIO_T5 && srqidx) {\n\t\tif (ep->com.qp->ibqp.uobject)\n\t\t\tt4_set_wq_in_error(&ep->com.qp->wq, srqidx);\n\t\telse\n\t\t\tc4iw_flush_srqidx(ep->com.qp, srqidx);\n\t}\n}\n\nstatic int abort_rpl(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tu32 srqidx;\n\tstruct c4iw_ep *ep;\n\tstruct cpl_abort_rpl_rss6 *rpl = cplhdr(skb);\n\tint release = 0;\n\tunsigned int tid = GET_TID(rpl);\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep) {\n\t\tpr_warn(\"Abort rpl to freed endpoint\\n\");\n\t\treturn 0;\n\t}\n\n\tif (ep->com.qp && ep->com.qp->srq) {\n\t\tsrqidx = ABORT_RSS_SRQIDX_G(be32_to_cpu(rpl->srqidx_status));\n\t\tcomplete_cached_srq_buffers(ep, srqidx ? srqidx : ep->srqe_idx);\n\t}\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tmutex_lock(&ep->com.mutex);\n\tswitch (ep->com.state) {\n\tcase ABORTING:\n\t\tc4iw_wake_up_noref(ep->com.wr_waitp, -ECONNRESET);\n\t\t__state_set(&ep->com, DEAD);\n\t\trelease = 1;\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s ep %p state %d\\n\", __func__, ep, ep->com.state);\n\t\tbreak;\n\t}\n\tmutex_unlock(&ep->com.mutex);\n\n\tif (release) {\n\t\tclose_complete_upcall(ep, -ECONNRESET);\n\t\trelease_ep_resources(ep);\n\t}\n\tc4iw_put_ep(&ep->com);\n\treturn 0;\n}\n\nstatic int send_fw_act_open_req(struct c4iw_ep *ep, unsigned int atid)\n{\n\tstruct sk_buff *skb;\n\tstruct fw_ofld_connection_wr *req;\n\tunsigned int mtu_idx;\n\tu32 wscale;\n\tstruct sockaddr_in *sin;\n\tint win;\n\n\tskb = get_skb(NULL, sizeof(*req), GFP_KERNEL);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\treq = __skb_put_zero(skb, sizeof(*req));\n\treq->op_compl = htonl(WR_OP_V(FW_OFLD_CONNECTION_WR));\n\treq->len16_pkd = htonl(FW_WR_LEN16_V(DIV_ROUND_UP(sizeof(*req), 16)));\n\treq->le.filter = cpu_to_be32(cxgb4_select_ntuple(\n\t\t\t\t     ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t     ep->l2t));\n\tsin = (struct sockaddr_in *)&ep->com.local_addr;\n\treq->le.lport = sin->sin_port;\n\treq->le.u.ipv4.lip = sin->sin_addr.s_addr;\n\tsin = (struct sockaddr_in *)&ep->com.remote_addr;\n\treq->le.pport = sin->sin_port;\n\treq->le.u.ipv4.pip = sin->sin_addr.s_addr;\n\treq->tcb.t_state_to_astid =\n\t\t\thtonl(FW_OFLD_CONNECTION_WR_T_STATE_V(TCP_SYN_SENT) |\n\t\t\tFW_OFLD_CONNECTION_WR_ASTID_V(atid));\n\treq->tcb.cplrxdataack_cplpassacceptrpl =\n\t\t\thtons(FW_OFLD_CONNECTION_WR_CPLRXDATAACK_F);\n\treq->tcb.tx_max = (__force __be32) jiffies;\n\treq->tcb.rcv_adv = htons(1);\n\tcxgb_best_mtu(ep->com.dev->rdev.lldi.mtus, ep->mtu, &mtu_idx,\n\t\t      enable_tcp_timestamps,\n\t\t      (ep->com.remote_addr.ss_family == AF_INET) ? 0 : 1);\n\twscale = cxgb_compute_wscale(rcv_win);\n\n\t \n\twin = ep->rcv_win >> 10;\n\tif (win > RCV_BUFSIZ_M)\n\t\twin = RCV_BUFSIZ_M;\n\n\treq->tcb.opt0 = (__force __be64) (TCAM_BYPASS_F |\n\t\t(nocong ? NO_CONG_F : 0) |\n\t\tKEEP_ALIVE_F |\n\t\tDELACK_F |\n\t\tWND_SCALE_V(wscale) |\n\t\tMSS_IDX_V(mtu_idx) |\n\t\tL2T_IDX_V(ep->l2t->idx) |\n\t\tTX_CHAN_V(ep->tx_chan) |\n\t\tSMAC_SEL_V(ep->smac_idx) |\n\t\tDSCP_V(ep->tos >> 2) |\n\t\tULP_MODE_V(ULP_MODE_TCPDDP) |\n\t\tRCV_BUFSIZ_V(win));\n\treq->tcb.opt2 = (__force __be32) (PACE_V(1) |\n\t\tTX_QUEUE_V(ep->com.dev->rdev.lldi.tx_modq[ep->tx_chan]) |\n\t\tRX_CHANNEL_V(0) |\n\t\tCCTRL_ECN_V(enable_ecn) |\n\t\tRSS_QUEUE_VALID_F | RSS_QUEUE_V(ep->rss_qid));\n\tif (enable_tcp_timestamps)\n\t\treq->tcb.opt2 |= (__force __be32)TSTAMPS_EN_F;\n\tif (enable_tcp_sack)\n\t\treq->tcb.opt2 |= (__force __be32)SACK_EN_F;\n\tif (wscale && enable_tcp_window_scaling)\n\t\treq->tcb.opt2 |= (__force __be32)WND_SCALE_EN_F;\n\treq->tcb.opt0 = cpu_to_be64((__force u64)req->tcb.opt0);\n\treq->tcb.opt2 = cpu_to_be32((__force u32)req->tcb.opt2);\n\tset_wr_txq(skb, CPL_PRIORITY_CONTROL, ep->ctrlq_idx);\n\tset_bit(ACT_OFLD_CONN, &ep->com.history);\n\treturn c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);\n}\n\n \nstatic inline int act_open_has_tid(int status)\n{\n\treturn (status != CPL_ERR_TCAM_PARITY &&\n\t\tstatus != CPL_ERR_TCAM_MISS &&\n\t\tstatus != CPL_ERR_TCAM_FULL &&\n\t\tstatus != CPL_ERR_CONN_EXIST_SYNRECV &&\n\t\tstatus != CPL_ERR_CONN_EXIST);\n}\n\nstatic char *neg_adv_str(unsigned int status)\n{\n\tswitch (status) {\n\tcase CPL_ERR_RTX_NEG_ADVICE:\n\t\treturn \"Retransmit timeout\";\n\tcase CPL_ERR_PERSIST_NEG_ADVICE:\n\t\treturn \"Persist timeout\";\n\tcase CPL_ERR_KEEPALV_NEG_ADVICE:\n\t\treturn \"Keepalive timeout\";\n\tdefault:\n\t\treturn \"Unknown\";\n\t}\n}\n\nstatic void set_tcp_window(struct c4iw_ep *ep, struct port_info *pi)\n{\n\tep->snd_win = snd_win;\n\tep->rcv_win = rcv_win;\n\tpr_debug(\"snd_win %d rcv_win %d\\n\",\n\t\t ep->snd_win, ep->rcv_win);\n}\n\n#define ACT_OPEN_RETRY_COUNT 2\n\nstatic int import_ep(struct c4iw_ep *ep, int iptype, __u8 *peer_ip,\n\t\t     struct dst_entry *dst, struct c4iw_dev *cdev,\n\t\t     bool clear_mpa_v1, enum chip_type adapter_type, u8 tos)\n{\n\tstruct neighbour *n;\n\tint err, step;\n\tstruct net_device *pdev;\n\n\tn = dst_neigh_lookup(dst, peer_ip);\n\tif (!n)\n\t\treturn -ENODEV;\n\n\trcu_read_lock();\n\terr = -ENOMEM;\n\tif (n->dev->flags & IFF_LOOPBACK) {\n\t\tif (iptype == 4)\n\t\t\tpdev = ip_dev_find(&init_net, *(__be32 *)peer_ip);\n\t\telse if (IS_ENABLED(CONFIG_IPV6))\n\t\t\tfor_each_netdev(&init_net, pdev) {\n\t\t\t\tif (ipv6_chk_addr(&init_net,\n\t\t\t\t\t\t  (struct in6_addr *)peer_ip,\n\t\t\t\t\t\t  pdev, 1))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\telse\n\t\t\tpdev = NULL;\n\n\t\tif (!pdev) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto out;\n\t\t}\n\t\tep->l2t = cxgb4_l2t_get(cdev->rdev.lldi.l2t,\n\t\t\t\t\tn, pdev, rt_tos2priority(tos));\n\t\tif (!ep->l2t) {\n\t\t\tdev_put(pdev);\n\t\t\tgoto out;\n\t\t}\n\t\tep->mtu = pdev->mtu;\n\t\tep->tx_chan = cxgb4_port_chan(pdev);\n\t\tep->smac_idx = ((struct port_info *)netdev_priv(pdev))->smt_idx;\n\t\tstep = cdev->rdev.lldi.ntxq /\n\t\t\tcdev->rdev.lldi.nchan;\n\t\tep->txq_idx = cxgb4_port_idx(pdev) * step;\n\t\tstep = cdev->rdev.lldi.nrxq /\n\t\t\tcdev->rdev.lldi.nchan;\n\t\tep->ctrlq_idx = cxgb4_port_idx(pdev);\n\t\tep->rss_qid = cdev->rdev.lldi.rxq_ids[\n\t\t\tcxgb4_port_idx(pdev) * step];\n\t\tset_tcp_window(ep, (struct port_info *)netdev_priv(pdev));\n\t\tdev_put(pdev);\n\t} else {\n\t\tpdev = get_real_dev(n->dev);\n\t\tep->l2t = cxgb4_l2t_get(cdev->rdev.lldi.l2t,\n\t\t\t\t\tn, pdev, rt_tos2priority(tos));\n\t\tif (!ep->l2t)\n\t\t\tgoto out;\n\t\tep->mtu = dst_mtu(dst);\n\t\tep->tx_chan = cxgb4_port_chan(pdev);\n\t\tep->smac_idx = ((struct port_info *)netdev_priv(pdev))->smt_idx;\n\t\tstep = cdev->rdev.lldi.ntxq /\n\t\t\tcdev->rdev.lldi.nchan;\n\t\tep->txq_idx = cxgb4_port_idx(pdev) * step;\n\t\tep->ctrlq_idx = cxgb4_port_idx(pdev);\n\t\tstep = cdev->rdev.lldi.nrxq /\n\t\t\tcdev->rdev.lldi.nchan;\n\t\tep->rss_qid = cdev->rdev.lldi.rxq_ids[\n\t\t\tcxgb4_port_idx(pdev) * step];\n\t\tset_tcp_window(ep, (struct port_info *)netdev_priv(pdev));\n\n\t\tif (clear_mpa_v1) {\n\t\t\tep->retry_with_mpa_v1 = 0;\n\t\t\tep->tried_with_mpa_v1 = 0;\n\t\t}\n\t}\n\terr = 0;\nout:\n\trcu_read_unlock();\n\n\tneigh_release(n);\n\n\treturn err;\n}\n\nstatic int c4iw_reconnect(struct c4iw_ep *ep)\n{\n\tint err = 0;\n\tint size = 0;\n\tstruct sockaddr_in *laddr = (struct sockaddr_in *)\n\t\t\t\t    &ep->com.cm_id->m_local_addr;\n\tstruct sockaddr_in *raddr = (struct sockaddr_in *)\n\t\t\t\t    &ep->com.cm_id->m_remote_addr;\n\tstruct sockaddr_in6 *laddr6 = (struct sockaddr_in6 *)\n\t\t\t\t      &ep->com.cm_id->m_local_addr;\n\tstruct sockaddr_in6 *raddr6 = (struct sockaddr_in6 *)\n\t\t\t\t      &ep->com.cm_id->m_remote_addr;\n\tint iptype;\n\t__u8 *ra;\n\n\tpr_debug(\"qp %p cm_id %p\\n\", ep->com.qp, ep->com.cm_id);\n\tc4iw_init_wr_wait(ep->com.wr_waitp);\n\n\t \n\tsize = (CN_MAX_CON_BUF - skb_queue_len(&ep->com.ep_skb_list));\n\tif (alloc_ep_skb_list(&ep->com.ep_skb_list, size)) {\n\t\terr = -ENOMEM;\n\t\tgoto fail1;\n\t}\n\n\t \n\tep->atid = cxgb4_alloc_atid(ep->com.dev->rdev.lldi.tids, ep);\n\tif (ep->atid == -1) {\n\t\tpr_err(\"%s - cannot alloc atid\\n\", __func__);\n\t\terr = -ENOMEM;\n\t\tgoto fail2;\n\t}\n\terr = xa_insert_irq(&ep->com.dev->atids, ep->atid, ep, GFP_KERNEL);\n\tif (err)\n\t\tgoto fail2a;\n\n\t \n\tif (ep->com.cm_id->m_local_addr.ss_family == AF_INET) {\n\t\tep->dst = cxgb_find_route(&ep->com.dev->rdev.lldi, get_real_dev,\n\t\t\t\t\t  laddr->sin_addr.s_addr,\n\t\t\t\t\t  raddr->sin_addr.s_addr,\n\t\t\t\t\t  laddr->sin_port,\n\t\t\t\t\t  raddr->sin_port, ep->com.cm_id->tos);\n\t\tiptype = 4;\n\t\tra = (__u8 *)&raddr->sin_addr;\n\t} else {\n\t\tep->dst = cxgb_find_route6(&ep->com.dev->rdev.lldi,\n\t\t\t\t\t   get_real_dev,\n\t\t\t\t\t   laddr6->sin6_addr.s6_addr,\n\t\t\t\t\t   raddr6->sin6_addr.s6_addr,\n\t\t\t\t\t   laddr6->sin6_port,\n\t\t\t\t\t   raddr6->sin6_port,\n\t\t\t\t\t   ep->com.cm_id->tos,\n\t\t\t\t\t   raddr6->sin6_scope_id);\n\t\tiptype = 6;\n\t\tra = (__u8 *)&raddr6->sin6_addr;\n\t}\n\tif (!ep->dst) {\n\t\tpr_err(\"%s - cannot find route\\n\", __func__);\n\t\terr = -EHOSTUNREACH;\n\t\tgoto fail3;\n\t}\n\terr = import_ep(ep, iptype, ra, ep->dst, ep->com.dev, false,\n\t\t\tep->com.dev->rdev.lldi.adapter_type,\n\t\t\tep->com.cm_id->tos);\n\tif (err) {\n\t\tpr_err(\"%s - cannot alloc l2e\\n\", __func__);\n\t\tgoto fail4;\n\t}\n\n\tpr_debug(\"txq_idx %u tx_chan %u smac_idx %u rss_qid %u l2t_idx %u\\n\",\n\t\t ep->txq_idx, ep->tx_chan, ep->smac_idx, ep->rss_qid,\n\t\t ep->l2t->idx);\n\n\tstate_set(&ep->com, CONNECTING);\n\tep->tos = ep->com.cm_id->tos;\n\n\t \n\terr = send_connect(ep);\n\tif (!err)\n\t\tgoto out;\n\n\tcxgb4_l2t_release(ep->l2t);\nfail4:\n\tdst_release(ep->dst);\nfail3:\n\txa_erase_irq(&ep->com.dev->atids, ep->atid);\nfail2a:\n\tcxgb4_free_atid(ep->com.dev->rdev.lldi.tids, ep->atid);\nfail2:\n\t \n\tconnect_reply_upcall(ep, -ECONNRESET);\nfail1:\n\tc4iw_put_ep(&ep->com);\nout:\n\treturn err;\n}\n\nstatic int act_open_rpl(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\tstruct cpl_act_open_rpl *rpl = cplhdr(skb);\n\tunsigned int atid = TID_TID_G(AOPEN_ATID_G(\n\t\t\t\t      ntohl(rpl->atid_status)));\n\tstruct tid_info *t = dev->rdev.lldi.tids;\n\tint status = AOPEN_STATUS_G(ntohl(rpl->atid_status));\n\tstruct sockaddr_in *la;\n\tstruct sockaddr_in *ra;\n\tstruct sockaddr_in6 *la6;\n\tstruct sockaddr_in6 *ra6;\n\tint ret = 0;\n\n\tep = lookup_atid(t, atid);\n\tla = (struct sockaddr_in *)&ep->com.local_addr;\n\tra = (struct sockaddr_in *)&ep->com.remote_addr;\n\tla6 = (struct sockaddr_in6 *)&ep->com.local_addr;\n\tra6 = (struct sockaddr_in6 *)&ep->com.remote_addr;\n\n\tpr_debug(\"ep %p atid %u status %u errno %d\\n\", ep, atid,\n\t\t status, status2errno(status));\n\n\tif (cxgb_is_neg_adv(status)) {\n\t\tpr_debug(\"Connection problems for atid %u status %u (%s)\\n\",\n\t\t\t atid, status, neg_adv_str(status));\n\t\tep->stats.connect_neg_adv++;\n\t\tmutex_lock(&dev->rdev.stats.lock);\n\t\tdev->rdev.stats.neg_adv++;\n\t\tmutex_unlock(&dev->rdev.stats.lock);\n\t\treturn 0;\n\t}\n\n\tset_bit(ACT_OPEN_RPL, &ep->com.history);\n\n\t \n\tswitch (status) {\n\tcase CPL_ERR_CONN_RESET:\n\tcase CPL_ERR_CONN_TIMEDOUT:\n\t\tbreak;\n\tcase CPL_ERR_TCAM_FULL:\n\t\tmutex_lock(&dev->rdev.stats.lock);\n\t\tdev->rdev.stats.tcam_full++;\n\t\tmutex_unlock(&dev->rdev.stats.lock);\n\t\tif (ep->com.local_addr.ss_family == AF_INET &&\n\t\t    dev->rdev.lldi.enable_fw_ofld_conn) {\n\t\t\tret = send_fw_act_open_req(ep, TID_TID_G(AOPEN_ATID_G(\n\t\t\t\t\t\t   ntohl(rpl->atid_status))));\n\t\t\tif (ret)\n\t\t\t\tgoto fail;\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tcase CPL_ERR_CONN_EXIST:\n\t\tif (ep->retry_count++ < ACT_OPEN_RETRY_COUNT) {\n\t\t\tset_bit(ACT_RETRY_INUSE, &ep->com.history);\n\t\t\tif (ep->com.remote_addr.ss_family == AF_INET6) {\n\t\t\t\tstruct sockaddr_in6 *sin6 =\n\t\t\t\t\t\t(struct sockaddr_in6 *)\n\t\t\t\t\t\t&ep->com.local_addr;\n\t\t\t\tcxgb4_clip_release(\n\t\t\t\t\t\tep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t\t\t(const u32 *)\n\t\t\t\t\t\t&sin6->sin6_addr.s6_addr, 1);\n\t\t\t}\n\t\t\txa_erase_irq(&ep->com.dev->atids, atid);\n\t\t\tcxgb4_free_atid(t, atid);\n\t\t\tdst_release(ep->dst);\n\t\t\tcxgb4_l2t_release(ep->l2t);\n\t\t\tc4iw_reconnect(ep);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tif (ep->com.local_addr.ss_family == AF_INET) {\n\t\t\tpr_info(\"Active open failure - atid %u status %u errno %d %pI4:%u->%pI4:%u\\n\",\n\t\t\t\tatid, status, status2errno(status),\n\t\t\t\t&la->sin_addr.s_addr, ntohs(la->sin_port),\n\t\t\t\t&ra->sin_addr.s_addr, ntohs(ra->sin_port));\n\t\t} else {\n\t\t\tpr_info(\"Active open failure - atid %u status %u errno %d %pI6:%u->%pI6:%u\\n\",\n\t\t\t\tatid, status, status2errno(status),\n\t\t\t\tla6->sin6_addr.s6_addr, ntohs(la6->sin6_port),\n\t\t\t\tra6->sin6_addr.s6_addr, ntohs(ra6->sin6_port));\n\t\t}\n\t\tbreak;\n\t}\n\nfail:\n\tconnect_reply_upcall(ep, status2errno(status));\n\tstate_set(&ep->com, DEAD);\n\n\tif (ep->com.remote_addr.ss_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *sin6 =\n\t\t\t(struct sockaddr_in6 *)&ep->com.local_addr;\n\t\tcxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t   (const u32 *)&sin6->sin6_addr.s6_addr, 1);\n\t}\n\tif (status && act_open_has_tid(status))\n\t\tcxgb4_remove_tid(ep->com.dev->rdev.lldi.tids, 0, GET_TID(rpl),\n\t\t\t\t ep->com.local_addr.ss_family);\n\n\txa_erase_irq(&ep->com.dev->atids, atid);\n\tcxgb4_free_atid(t, atid);\n\tdst_release(ep->dst);\n\tcxgb4_l2t_release(ep->l2t);\n\tc4iw_put_ep(&ep->com);\n\n\treturn 0;\n}\n\nstatic int pass_open_rpl(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_pass_open_rpl *rpl = cplhdr(skb);\n\tunsigned int stid = GET_TID(rpl);\n\tstruct c4iw_listen_ep *ep = get_ep_from_stid(dev, stid);\n\n\tif (!ep) {\n\t\tpr_warn(\"%s stid %d lookup failure!\\n\", __func__, stid);\n\t\tgoto out;\n\t}\n\tpr_debug(\"ep %p status %d error %d\\n\", ep,\n\t\t rpl->status, status2errno(rpl->status));\n\tc4iw_wake_up_noref(ep->com.wr_waitp, status2errno(rpl->status));\n\tc4iw_put_ep(&ep->com);\nout:\n\treturn 0;\n}\n\nstatic int close_listsrv_rpl(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_close_listsvr_rpl *rpl = cplhdr(skb);\n\tunsigned int stid = GET_TID(rpl);\n\tstruct c4iw_listen_ep *ep = get_ep_from_stid(dev, stid);\n\n\tif (!ep) {\n\t\tpr_warn(\"%s stid %d lookup failure!\\n\", __func__, stid);\n\t\tgoto out;\n\t}\n\tpr_debug(\"ep %p\\n\", ep);\n\tc4iw_wake_up_noref(ep->com.wr_waitp, status2errno(rpl->status));\n\tc4iw_put_ep(&ep->com);\nout:\n\treturn 0;\n}\n\nstatic int accept_cr(struct c4iw_ep *ep, struct sk_buff *skb,\n\t\t     struct cpl_pass_accept_req *req)\n{\n\tstruct cpl_pass_accept_rpl *rpl;\n\tunsigned int mtu_idx;\n\tu64 opt0;\n\tu32 opt2;\n\tu32 wscale;\n\tstruct cpl_t5_pass_accept_rpl *rpl5 = NULL;\n\tint win;\n\tenum chip_type adapter_type = ep->com.dev->rdev.lldi.adapter_type;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tcxgb_best_mtu(ep->com.dev->rdev.lldi.mtus, ep->mtu, &mtu_idx,\n\t\t      enable_tcp_timestamps && req->tcpopt.tstamp,\n\t\t      (ep->com.remote_addr.ss_family == AF_INET) ? 0 : 1);\n\twscale = cxgb_compute_wscale(rcv_win);\n\n\t \n\twin = ep->rcv_win >> 10;\n\tif (win > RCV_BUFSIZ_M)\n\t\twin = RCV_BUFSIZ_M;\n\topt0 = (nocong ? NO_CONG_F : 0) |\n\t       KEEP_ALIVE_F |\n\t       DELACK_F |\n\t       WND_SCALE_V(wscale) |\n\t       MSS_IDX_V(mtu_idx) |\n\t       L2T_IDX_V(ep->l2t->idx) |\n\t       TX_CHAN_V(ep->tx_chan) |\n\t       SMAC_SEL_V(ep->smac_idx) |\n\t       DSCP_V(ep->tos >> 2) |\n\t       ULP_MODE_V(ULP_MODE_TCPDDP) |\n\t       RCV_BUFSIZ_V(win);\n\topt2 = RX_CHANNEL_V(0) |\n\t       RSS_QUEUE_VALID_F | RSS_QUEUE_V(ep->rss_qid);\n\n\tif (enable_tcp_timestamps && req->tcpopt.tstamp)\n\t\topt2 |= TSTAMPS_EN_F;\n\tif (enable_tcp_sack && req->tcpopt.sack)\n\t\topt2 |= SACK_EN_F;\n\tif (wscale && enable_tcp_window_scaling)\n\t\topt2 |= WND_SCALE_EN_F;\n\tif (enable_ecn) {\n\t\tconst struct tcphdr *tcph;\n\t\tu32 hlen = ntohl(req->hdr_len);\n\n\t\tif (CHELSIO_CHIP_VERSION(adapter_type) <= CHELSIO_T5)\n\t\t\ttcph = (const void *)(req + 1) + ETH_HDR_LEN_G(hlen) +\n\t\t\t\tIP_HDR_LEN_G(hlen);\n\t\telse\n\t\t\ttcph = (const void *)(req + 1) +\n\t\t\t\tT6_ETH_HDR_LEN_G(hlen) + T6_IP_HDR_LEN_G(hlen);\n\t\tif (tcph->ece && tcph->cwr)\n\t\t\topt2 |= CCTRL_ECN_V(1);\n\t}\n\n\tif (!is_t4(adapter_type)) {\n\t\tu32 isn = (get_random_u32() & ~7UL) - 1;\n\n\t\tskb = get_skb(skb, roundup(sizeof(*rpl5), 16), GFP_KERNEL);\n\t\trpl5 = __skb_put_zero(skb, roundup(sizeof(*rpl5), 16));\n\t\trpl = (void *)rpl5;\n\t\tINIT_TP_WR_CPL(rpl5, CPL_PASS_ACCEPT_RPL, ep->hwtid);\n\t\topt2 |= T5_OPT_2_VALID_F;\n\t\topt2 |= CONG_CNTRL_V(CONG_ALG_TAHOE);\n\t\topt2 |= T5_ISS_F;\n\t\tif (peer2peer)\n\t\t\tisn += 4;\n\t\trpl5->iss = cpu_to_be32(isn);\n\t\tpr_debug(\"iss %u\\n\", be32_to_cpu(rpl5->iss));\n\t} else {\n\t\tskb = get_skb(skb, sizeof(*rpl), GFP_KERNEL);\n\t\trpl = __skb_put_zero(skb, sizeof(*rpl));\n\t\tINIT_TP_WR_CPL(rpl, CPL_PASS_ACCEPT_RPL, ep->hwtid);\n\t}\n\n\trpl->opt0 = cpu_to_be64(opt0);\n\trpl->opt2 = cpu_to_be32(opt2);\n\tset_wr_txq(skb, CPL_PRIORITY_SETUP, ep->ctrlq_idx);\n\tt4_set_arp_err_handler(skb, ep, pass_accept_rpl_arp_failure);\n\n\treturn c4iw_l2t_send(&ep->com.dev->rdev, skb, ep->l2t);\n}\n\nstatic void reject_cr(struct c4iw_dev *dev, u32 hwtid, struct sk_buff *skb)\n{\n\tpr_debug(\"c4iw_dev %p tid %u\\n\", dev, hwtid);\n\tskb_trim(skb, sizeof(struct cpl_tid_release));\n\trelease_tid(&dev->rdev, hwtid, skb);\n\treturn;\n}\n\nstatic int pass_accept_req(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *child_ep = NULL, *parent_ep;\n\tstruct cpl_pass_accept_req *req = cplhdr(skb);\n\tunsigned int stid = PASS_OPEN_TID_G(ntohl(req->tos_stid));\n\tstruct tid_info *t = dev->rdev.lldi.tids;\n\tunsigned int hwtid = GET_TID(req);\n\tstruct dst_entry *dst;\n\t__u8 local_ip[16], peer_ip[16];\n\t__be16 local_port, peer_port;\n\tstruct sockaddr_in6 *sin6;\n\tint err;\n\tu16 peer_mss = ntohs(req->tcpopt.mss);\n\tint iptype;\n\tunsigned short hdrs;\n\tu8 tos;\n\n\tparent_ep = (struct c4iw_ep *)get_ep_from_stid(dev, stid);\n\tif (!parent_ep) {\n\t\tpr_err(\"%s connect request on invalid stid %d\\n\",\n\t\t       __func__, stid);\n\t\tgoto reject;\n\t}\n\n\tif (state_read(&parent_ep->com) != LISTEN) {\n\t\tpr_err(\"%s - listening ep not in LISTEN\\n\", __func__);\n\t\tgoto reject;\n\t}\n\n\tif (parent_ep->com.cm_id->tos_set)\n\t\ttos = parent_ep->com.cm_id->tos;\n\telse\n\t\ttos = PASS_OPEN_TOS_G(ntohl(req->tos_stid));\n\n\tcxgb_get_4tuple(req, parent_ep->com.dev->rdev.lldi.adapter_type,\n\t\t\t&iptype, local_ip, peer_ip, &local_port, &peer_port);\n\n\t \n\tif (iptype == 4)  {\n\t\tpr_debug(\"parent ep %p hwtid %u laddr %pI4 raddr %pI4 lport %d rport %d peer_mss %d\\n\"\n\t\t\t , parent_ep, hwtid,\n\t\t\t local_ip, peer_ip, ntohs(local_port),\n\t\t\t ntohs(peer_port), peer_mss);\n\t\tdst = cxgb_find_route(&dev->rdev.lldi, get_real_dev,\n\t\t\t\t      *(__be32 *)local_ip, *(__be32 *)peer_ip,\n\t\t\t\t      local_port, peer_port, tos);\n\t} else {\n\t\tpr_debug(\"parent ep %p hwtid %u laddr %pI6 raddr %pI6 lport %d rport %d peer_mss %d\\n\"\n\t\t\t , parent_ep, hwtid,\n\t\t\t local_ip, peer_ip, ntohs(local_port),\n\t\t\t ntohs(peer_port), peer_mss);\n\t\tdst = cxgb_find_route6(&dev->rdev.lldi, get_real_dev,\n\t\t\t\tlocal_ip, peer_ip, local_port, peer_port,\n\t\t\t\ttos,\n\t\t\t\t((struct sockaddr_in6 *)\n\t\t\t\t &parent_ep->com.local_addr)->sin6_scope_id);\n\t}\n\tif (!dst) {\n\t\tpr_err(\"%s - failed to find dst entry!\\n\", __func__);\n\t\tgoto reject;\n\t}\n\n\tchild_ep = alloc_ep(sizeof(*child_ep), GFP_KERNEL);\n\tif (!child_ep) {\n\t\tpr_err(\"%s - failed to allocate ep entry!\\n\", __func__);\n\t\tdst_release(dst);\n\t\tgoto reject;\n\t}\n\n\terr = import_ep(child_ep, iptype, peer_ip, dst, dev, false,\n\t\t\tparent_ep->com.dev->rdev.lldi.adapter_type, tos);\n\tif (err) {\n\t\tpr_err(\"%s - failed to allocate l2t entry!\\n\", __func__);\n\t\tdst_release(dst);\n\t\tkfree(child_ep);\n\t\tgoto reject;\n\t}\n\n\thdrs = ((iptype == 4) ? sizeof(struct iphdr) : sizeof(struct ipv6hdr)) +\n\t       sizeof(struct tcphdr) +\n\t       ((enable_tcp_timestamps && req->tcpopt.tstamp) ? 12 : 0);\n\tif (peer_mss && child_ep->mtu > (peer_mss + hdrs))\n\t\tchild_ep->mtu = peer_mss + hdrs;\n\n\tskb_queue_head_init(&child_ep->com.ep_skb_list);\n\tif (alloc_ep_skb_list(&child_ep->com.ep_skb_list, CN_MAX_CON_BUF))\n\t\tgoto fail;\n\n\tstate_set(&child_ep->com, CONNECTING);\n\tchild_ep->com.dev = dev;\n\tchild_ep->com.cm_id = NULL;\n\n\tif (iptype == 4) {\n\t\tstruct sockaddr_in *sin = (struct sockaddr_in *)\n\t\t\t&child_ep->com.local_addr;\n\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_port = local_port;\n\t\tsin->sin_addr.s_addr = *(__be32 *)local_ip;\n\n\t\tsin = (struct sockaddr_in *)&child_ep->com.local_addr;\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_port = ((struct sockaddr_in *)\n\t\t\t\t &parent_ep->com.local_addr)->sin_port;\n\t\tsin->sin_addr.s_addr = *(__be32 *)local_ip;\n\n\t\tsin = (struct sockaddr_in *)&child_ep->com.remote_addr;\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_port = peer_port;\n\t\tsin->sin_addr.s_addr = *(__be32 *)peer_ip;\n\t} else {\n\t\tsin6 = (struct sockaddr_in6 *)&child_ep->com.local_addr;\n\t\tsin6->sin6_family = PF_INET6;\n\t\tsin6->sin6_port = local_port;\n\t\tmemcpy(sin6->sin6_addr.s6_addr, local_ip, 16);\n\n\t\tsin6 = (struct sockaddr_in6 *)&child_ep->com.local_addr;\n\t\tsin6->sin6_family = PF_INET6;\n\t\tsin6->sin6_port = ((struct sockaddr_in6 *)\n\t\t\t\t   &parent_ep->com.local_addr)->sin6_port;\n\t\tmemcpy(sin6->sin6_addr.s6_addr, local_ip, 16);\n\n\t\tsin6 = (struct sockaddr_in6 *)&child_ep->com.remote_addr;\n\t\tsin6->sin6_family = PF_INET6;\n\t\tsin6->sin6_port = peer_port;\n\t\tmemcpy(sin6->sin6_addr.s6_addr, peer_ip, 16);\n\t}\n\n\tc4iw_get_ep(&parent_ep->com);\n\tchild_ep->parent_ep = parent_ep;\n\tchild_ep->tos = tos;\n\tchild_ep->dst = dst;\n\tchild_ep->hwtid = hwtid;\n\n\tpr_debug(\"tx_chan %u smac_idx %u rss_qid %u\\n\",\n\t\t child_ep->tx_chan, child_ep->smac_idx, child_ep->rss_qid);\n\n\ttimer_setup(&child_ep->timer, ep_timeout, 0);\n\tcxgb4_insert_tid(t, child_ep, hwtid,\n\t\t\t child_ep->com.local_addr.ss_family);\n\tinsert_ep_tid(child_ep);\n\tif (accept_cr(child_ep, skb, req)) {\n\t\tc4iw_put_ep(&parent_ep->com);\n\t\trelease_ep_resources(child_ep);\n\t} else {\n\t\tset_bit(PASS_ACCEPT_REQ, &child_ep->com.history);\n\t}\n\tif (iptype == 6) {\n\t\tsin6 = (struct sockaddr_in6 *)&child_ep->com.local_addr;\n\t\tcxgb4_clip_get(child_ep->com.dev->rdev.lldi.ports[0],\n\t\t\t       (const u32 *)&sin6->sin6_addr.s6_addr, 1);\n\t}\n\tgoto out;\nfail:\n\tc4iw_put_ep(&child_ep->com);\nreject:\n\treject_cr(dev, hwtid, skb);\nout:\n\tif (parent_ep)\n\t\tc4iw_put_ep(&parent_ep->com);\n\treturn 0;\n}\n\nstatic int pass_establish(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\tstruct cpl_pass_establish *req = cplhdr(skb);\n\tunsigned int tid = GET_TID(req);\n\tint ret;\n\tu16 tcp_opt = ntohs(req->tcp_opt);\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep)\n\t\treturn 0;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tep->snd_seq = be32_to_cpu(req->snd_isn);\n\tep->rcv_seq = be32_to_cpu(req->rcv_isn);\n\tep->snd_wscale = TCPOPT_SND_WSCALE_G(tcp_opt);\n\n\tpr_debug(\"ep %p hwtid %u tcp_opt 0x%02x\\n\", ep, tid, tcp_opt);\n\n\tset_emss(ep, tcp_opt);\n\n\tdst_confirm(ep->dst);\n\tmutex_lock(&ep->com.mutex);\n\tep->com.state = MPA_REQ_WAIT;\n\tstart_ep_timer(ep);\n\tset_bit(PASS_ESTAB, &ep->com.history);\n\tret = send_flowc(ep);\n\tmutex_unlock(&ep->com.mutex);\n\tif (ret)\n\t\tc4iw_ep_disconnect(ep, 1, GFP_KERNEL);\n\tc4iw_put_ep(&ep->com);\n\n\treturn 0;\n}\n\nstatic int peer_close(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_peer_close *hdr = cplhdr(skb);\n\tstruct c4iw_ep *ep;\n\tstruct c4iw_qp_attributes attrs;\n\tint disconnect = 1;\n\tint release = 0;\n\tunsigned int tid = GET_TID(hdr);\n\tint ret;\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep)\n\t\treturn 0;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\tdst_confirm(ep->dst);\n\n\tset_bit(PEER_CLOSE, &ep->com.history);\n\tmutex_lock(&ep->com.mutex);\n\tswitch (ep->com.state) {\n\tcase MPA_REQ_WAIT:\n\t\t__state_set(&ep->com, CLOSING);\n\t\tbreak;\n\tcase MPA_REQ_SENT:\n\t\t__state_set(&ep->com, CLOSING);\n\t\tconnect_reply_upcall(ep, -ECONNRESET);\n\t\tbreak;\n\tcase MPA_REQ_RCVD:\n\n\t\t \n\t\t__state_set(&ep->com, CLOSING);\n\t\tpr_debug(\"waking up ep %p tid %u\\n\", ep, ep->hwtid);\n\t\tc4iw_wake_up_noref(ep->com.wr_waitp, -ECONNRESET);\n\t\tbreak;\n\tcase MPA_REP_SENT:\n\t\t__state_set(&ep->com, CLOSING);\n\t\tpr_debug(\"waking up ep %p tid %u\\n\", ep, ep->hwtid);\n\t\tc4iw_wake_up_noref(ep->com.wr_waitp, -ECONNRESET);\n\t\tbreak;\n\tcase FPDU_MODE:\n\t\tstart_ep_timer(ep);\n\t\t__state_set(&ep->com, CLOSING);\n\t\tattrs.next_state = C4IW_QP_STATE_CLOSING;\n\t\tret = c4iw_modify_qp(ep->com.qp->rhp, ep->com.qp,\n\t\t\t\t       C4IW_QP_ATTR_NEXT_STATE, &attrs, 1);\n\t\tif (ret != -ECONNRESET) {\n\t\t\tpeer_close_upcall(ep);\n\t\t\tdisconnect = 1;\n\t\t}\n\t\tbreak;\n\tcase ABORTING:\n\t\tdisconnect = 0;\n\t\tbreak;\n\tcase CLOSING:\n\t\t__state_set(&ep->com, MORIBUND);\n\t\tdisconnect = 0;\n\t\tbreak;\n\tcase MORIBUND:\n\t\t(void)stop_ep_timer(ep);\n\t\tif (ep->com.cm_id && ep->com.qp) {\n\t\t\tattrs.next_state = C4IW_QP_STATE_IDLE;\n\t\t\tc4iw_modify_qp(ep->com.qp->rhp, ep->com.qp,\n\t\t\t\t       C4IW_QP_ATTR_NEXT_STATE, &attrs, 1);\n\t\t}\n\t\tclose_complete_upcall(ep, 0);\n\t\t__state_set(&ep->com, DEAD);\n\t\trelease = 1;\n\t\tdisconnect = 0;\n\t\tbreak;\n\tcase DEAD:\n\t\tdisconnect = 0;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ONCE(1, \"Bad endpoint state %u\\n\", ep->com.state);\n\t}\n\tmutex_unlock(&ep->com.mutex);\n\tif (disconnect)\n\t\tc4iw_ep_disconnect(ep, 0, GFP_KERNEL);\n\tif (release)\n\t\trelease_ep_resources(ep);\n\tc4iw_put_ep(&ep->com);\n\treturn 0;\n}\n\nstatic void finish_peer_abort(struct c4iw_dev *dev, struct c4iw_ep *ep)\n{\n\tcomplete_cached_srq_buffers(ep, ep->srqe_idx);\n\tif (ep->com.cm_id && ep->com.qp) {\n\t\tstruct c4iw_qp_attributes attrs;\n\n\t\tattrs.next_state = C4IW_QP_STATE_ERROR;\n\t\tc4iw_modify_qp(ep->com.qp->rhp, ep->com.qp,\n\t\t\t       C4IW_QP_ATTR_NEXT_STATE,\t&attrs, 1);\n\t}\n\tpeer_abort_upcall(ep);\n\trelease_ep_resources(ep);\n\tc4iw_put_ep(&ep->com);\n}\n\nstatic int peer_abort(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_abort_req_rss6 *req = cplhdr(skb);\n\tstruct c4iw_ep *ep;\n\tstruct sk_buff *rpl_skb;\n\tstruct c4iw_qp_attributes attrs;\n\tint ret;\n\tint release = 0;\n\tunsigned int tid = GET_TID(req);\n\tu8 status;\n\tu32 srqidx;\n\n\tu32 len = roundup(sizeof(struct cpl_abort_rpl), 16);\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep)\n\t\treturn 0;\n\n\tstatus = ABORT_RSS_STATUS_G(be32_to_cpu(req->srqidx_status));\n\n\tif (cxgb_is_neg_adv(status)) {\n\t\tpr_debug(\"Negative advice on abort- tid %u status %d (%s)\\n\",\n\t\t\t ep->hwtid, status, neg_adv_str(status));\n\t\tep->stats.abort_neg_adv++;\n\t\tmutex_lock(&dev->rdev.stats.lock);\n\t\tdev->rdev.stats.neg_adv++;\n\t\tmutex_unlock(&dev->rdev.stats.lock);\n\t\tgoto deref_ep;\n\t}\n\n\tpr_debug(\"ep %p tid %u state %u\\n\", ep, ep->hwtid,\n\t\t ep->com.state);\n\tset_bit(PEER_ABORT, &ep->com.history);\n\n\t \n\tif (ep->com.state != MPA_REQ_SENT)\n\t\tc4iw_wake_up_noref(ep->com.wr_waitp, -ECONNRESET);\n\n\tmutex_lock(&ep->com.mutex);\n\tswitch (ep->com.state) {\n\tcase CONNECTING:\n\t\tc4iw_put_ep(&ep->parent_ep->com);\n\t\tbreak;\n\tcase MPA_REQ_WAIT:\n\t\t(void)stop_ep_timer(ep);\n\t\tbreak;\n\tcase MPA_REQ_SENT:\n\t\t(void)stop_ep_timer(ep);\n\t\tif (status != CPL_ERR_CONN_RESET || mpa_rev == 1 ||\n\t\t    (mpa_rev == 2 && ep->tried_with_mpa_v1))\n\t\t\tconnect_reply_upcall(ep, -ECONNRESET);\n\t\telse {\n\t\t\t \n\t\t\tpr_info(\"%s: mpa_rev=%d. Retrying with mpav1\\n\",\n\t\t\t\t__func__, mpa_rev);\n\t\t\tep->retry_with_mpa_v1 = 1;\n\t\t}\n\t\tbreak;\n\tcase MPA_REP_SENT:\n\t\tbreak;\n\tcase MPA_REQ_RCVD:\n\t\tbreak;\n\tcase MORIBUND:\n\tcase CLOSING:\n\t\tstop_ep_timer(ep);\n\t\tfallthrough;\n\tcase FPDU_MODE:\n\t\tif (ep->com.qp && ep->com.qp->srq) {\n\t\t\tsrqidx = ABORT_RSS_SRQIDX_G(\n\t\t\t\t\tbe32_to_cpu(req->srqidx_status));\n\t\t\tif (srqidx) {\n\t\t\t\tcomplete_cached_srq_buffers(ep, srqidx);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tc4iw_get_ep(&ep->com);\n\t\t\t\t__state_set(&ep->com, ABORTING);\n\t\t\t\tset_bit(PEER_ABORT_IN_PROGRESS, &ep->com.flags);\n\t\t\t\tread_tcb(ep);\n\t\t\t\tbreak;\n\n\t\t\t}\n\t\t}\n\n\t\tif (ep->com.cm_id && ep->com.qp) {\n\t\t\tattrs.next_state = C4IW_QP_STATE_ERROR;\n\t\t\tret = c4iw_modify_qp(ep->com.qp->rhp,\n\t\t\t\t     ep->com.qp, C4IW_QP_ATTR_NEXT_STATE,\n\t\t\t\t     &attrs, 1);\n\t\t\tif (ret)\n\t\t\t\tpr_err(\"%s - qp <- error failed!\\n\", __func__);\n\t\t}\n\t\tpeer_abort_upcall(ep);\n\t\tbreak;\n\tcase ABORTING:\n\t\tbreak;\n\tcase DEAD:\n\t\tpr_warn(\"%s PEER_ABORT IN DEAD STATE!!!!\\n\", __func__);\n\t\tmutex_unlock(&ep->com.mutex);\n\t\tgoto deref_ep;\n\tdefault:\n\t\tWARN_ONCE(1, \"Bad endpoint state %u\\n\", ep->com.state);\n\t\tbreak;\n\t}\n\tdst_confirm(ep->dst);\n\tif (ep->com.state != ABORTING) {\n\t\t__state_set(&ep->com, DEAD);\n\t\t \n\t\tif (!ep->retry_with_mpa_v1)\n\t\t\trelease = 1;\n\t}\n\tmutex_unlock(&ep->com.mutex);\n\n\trpl_skb = skb_dequeue(&ep->com.ep_skb_list);\n\tif (WARN_ON(!rpl_skb)) {\n\t\trelease = 1;\n\t\tgoto out;\n\t}\n\n\tcxgb_mk_abort_rpl(rpl_skb, len, ep->hwtid, ep->txq_idx);\n\n\tc4iw_ofld_send(&ep->com.dev->rdev, rpl_skb);\nout:\n\tif (release)\n\t\trelease_ep_resources(ep);\n\telse if (ep->retry_with_mpa_v1) {\n\t\tif (ep->com.remote_addr.ss_family == AF_INET6) {\n\t\t\tstruct sockaddr_in6 *sin6 =\n\t\t\t\t\t(struct sockaddr_in6 *)\n\t\t\t\t\t&ep->com.local_addr;\n\t\t\tcxgb4_clip_release(\n\t\t\t\t\tep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t\t(const u32 *)&sin6->sin6_addr.s6_addr,\n\t\t\t\t\t1);\n\t\t}\n\t\txa_erase_irq(&ep->com.dev->hwtids, ep->hwtid);\n\t\tcxgb4_remove_tid(ep->com.dev->rdev.lldi.tids, 0, ep->hwtid,\n\t\t\t\t ep->com.local_addr.ss_family);\n\t\tdst_release(ep->dst);\n\t\tcxgb4_l2t_release(ep->l2t);\n\t\tc4iw_reconnect(ep);\n\t}\n\nderef_ep:\n\tc4iw_put_ep(&ep->com);\n\t \n\tc4iw_put_ep(&ep->com);\n\treturn 0;\n}\n\nstatic int close_con_rpl(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\tstruct c4iw_qp_attributes attrs;\n\tstruct cpl_close_con_rpl *rpl = cplhdr(skb);\n\tint release = 0;\n\tunsigned int tid = GET_TID(rpl);\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep)\n\t\treturn 0;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\n\t \n\tmutex_lock(&ep->com.mutex);\n\tset_bit(CLOSE_CON_RPL, &ep->com.history);\n\tswitch (ep->com.state) {\n\tcase CLOSING:\n\t\t__state_set(&ep->com, MORIBUND);\n\t\tbreak;\n\tcase MORIBUND:\n\t\t(void)stop_ep_timer(ep);\n\t\tif ((ep->com.cm_id) && (ep->com.qp)) {\n\t\t\tattrs.next_state = C4IW_QP_STATE_IDLE;\n\t\t\tc4iw_modify_qp(ep->com.qp->rhp,\n\t\t\t\t\t     ep->com.qp,\n\t\t\t\t\t     C4IW_QP_ATTR_NEXT_STATE,\n\t\t\t\t\t     &attrs, 1);\n\t\t}\n\t\tclose_complete_upcall(ep, 0);\n\t\t__state_set(&ep->com, DEAD);\n\t\trelease = 1;\n\t\tbreak;\n\tcase ABORTING:\n\tcase DEAD:\n\t\tbreak;\n\tdefault:\n\t\tWARN_ONCE(1, \"Bad endpoint state %u\\n\", ep->com.state);\n\t\tbreak;\n\t}\n\tmutex_unlock(&ep->com.mutex);\n\tif (release)\n\t\trelease_ep_resources(ep);\n\tc4iw_put_ep(&ep->com);\n\treturn 0;\n}\n\nstatic int terminate(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_rdma_terminate *rpl = cplhdr(skb);\n\tunsigned int tid = GET_TID(rpl);\n\tstruct c4iw_ep *ep;\n\tstruct c4iw_qp_attributes attrs;\n\n\tep = get_ep_from_tid(dev, tid);\n\n\tif (ep) {\n\t\tif (ep->com.qp) {\n\t\t\tpr_warn(\"TERM received tid %u qpid %u\\n\", tid,\n\t\t\t\tep->com.qp->wq.sq.qid);\n\t\t\tattrs.next_state = C4IW_QP_STATE_TERMINATE;\n\t\t\tc4iw_modify_qp(ep->com.qp->rhp, ep->com.qp,\n\t\t\t\t       C4IW_QP_ATTR_NEXT_STATE, &attrs, 1);\n\t\t}\n\n\t\t \n\t\tc4iw_ep_disconnect(ep, 1, GFP_KERNEL);\n\t\tc4iw_put_ep(&ep->com);\n\t} else\n\t\tpr_warn(\"TERM received tid %u no ep/qp\\n\", tid);\n\n\treturn 0;\n}\n\n \nstatic int fw4_ack(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct c4iw_ep *ep;\n\tstruct cpl_fw4_ack *hdr = cplhdr(skb);\n\tu8 credits = hdr->credits;\n\tunsigned int tid = GET_TID(hdr);\n\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep)\n\t\treturn 0;\n\tpr_debug(\"ep %p tid %u credits %u\\n\",\n\t\t ep, ep->hwtid, credits);\n\tif (credits == 0) {\n\t\tpr_debug(\"0 credit ack ep %p tid %u state %u\\n\",\n\t\t\t ep, ep->hwtid, state_read(&ep->com));\n\t\tgoto out;\n\t}\n\n\tdst_confirm(ep->dst);\n\tif (ep->mpa_skb) {\n\t\tpr_debug(\"last streaming msg ack ep %p tid %u state %u initiator %u freeing skb\\n\",\n\t\t\t ep, ep->hwtid, state_read(&ep->com),\n\t\t\t ep->mpa_attr.initiator ? 1 : 0);\n\t\tmutex_lock(&ep->com.mutex);\n\t\tkfree_skb(ep->mpa_skb);\n\t\tep->mpa_skb = NULL;\n\t\tif (test_bit(STOP_MPA_TIMER, &ep->com.flags))\n\t\t\tstop_ep_timer(ep);\n\t\tmutex_unlock(&ep->com.mutex);\n\t}\nout:\n\tc4iw_put_ep(&ep->com);\n\treturn 0;\n}\n\nint c4iw_reject_cr(struct iw_cm_id *cm_id, const void *pdata, u8 pdata_len)\n{\n\tint abort;\n\tstruct c4iw_ep *ep = to_ep(cm_id);\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\n\tmutex_lock(&ep->com.mutex);\n\tif (ep->com.state != MPA_REQ_RCVD) {\n\t\tmutex_unlock(&ep->com.mutex);\n\t\tc4iw_put_ep(&ep->com);\n\t\treturn -ECONNRESET;\n\t}\n\tset_bit(ULP_REJECT, &ep->com.history);\n\tif (mpa_rev == 0)\n\t\tabort = 1;\n\telse\n\t\tabort = send_mpa_reject(ep, pdata, pdata_len);\n\tmutex_unlock(&ep->com.mutex);\n\n\tstop_ep_timer(ep);\n\tc4iw_ep_disconnect(ep, abort != 0, GFP_KERNEL);\n\tc4iw_put_ep(&ep->com);\n\treturn 0;\n}\n\nint c4iw_accept_cr(struct iw_cm_id *cm_id, struct iw_cm_conn_param *conn_param)\n{\n\tint err;\n\tstruct c4iw_qp_attributes attrs;\n\tenum c4iw_qp_attr_mask mask;\n\tstruct c4iw_ep *ep = to_ep(cm_id);\n\tstruct c4iw_dev *h = to_c4iw_dev(cm_id->device);\n\tstruct c4iw_qp *qp = get_qhp(h, conn_param->qpn);\n\tint abort = 0;\n\n\tpr_debug(\"ep %p tid %u\\n\", ep, ep->hwtid);\n\n\tmutex_lock(&ep->com.mutex);\n\tif (ep->com.state != MPA_REQ_RCVD) {\n\t\terr = -ECONNRESET;\n\t\tgoto err_out;\n\t}\n\n\tif (!qp) {\n\t\terr = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\tset_bit(ULP_ACCEPT, &ep->com.history);\n\tif ((conn_param->ord > cur_max_read_depth(ep->com.dev)) ||\n\t    (conn_param->ird > cur_max_read_depth(ep->com.dev))) {\n\t\terr = -EINVAL;\n\t\tgoto err_abort;\n\t}\n\n\tif (ep->mpa_attr.version == 2 && ep->mpa_attr.enhanced_rdma_conn) {\n\t\tif (conn_param->ord > ep->ird) {\n\t\t\tif (RELAXED_IRD_NEGOTIATION) {\n\t\t\t\tconn_param->ord = ep->ird;\n\t\t\t} else {\n\t\t\t\tep->ird = conn_param->ird;\n\t\t\t\tep->ord = conn_param->ord;\n\t\t\t\tsend_mpa_reject(ep, conn_param->private_data,\n\t\t\t\t\t\tconn_param->private_data_len);\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto err_abort;\n\t\t\t}\n\t\t}\n\t\tif (conn_param->ird < ep->ord) {\n\t\t\tif (RELAXED_IRD_NEGOTIATION &&\n\t\t\t    ep->ord <= h->rdev.lldi.max_ordird_qp) {\n\t\t\t\tconn_param->ird = ep->ord;\n\t\t\t} else {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto err_abort;\n\t\t\t}\n\t\t}\n\t}\n\tep->ird = conn_param->ird;\n\tep->ord = conn_param->ord;\n\n\tif (ep->mpa_attr.version == 1) {\n\t\tif (peer2peer && ep->ird == 0)\n\t\t\tep->ird = 1;\n\t} else {\n\t\tif (peer2peer &&\n\t\t    (ep->mpa_attr.p2p_type != FW_RI_INIT_P2PTYPE_DISABLED) &&\n\t\t    (p2p_type == FW_RI_INIT_P2PTYPE_READ_REQ) && ep->ird == 0)\n\t\t\tep->ird = 1;\n\t}\n\n\tpr_debug(\"ird %d ord %d\\n\", ep->ird, ep->ord);\n\n\tep->com.cm_id = cm_id;\n\tref_cm_id(&ep->com);\n\tep->com.qp = qp;\n\tref_qp(ep);\n\n\t \n\tattrs.mpa_attr = ep->mpa_attr;\n\tattrs.max_ird = ep->ird;\n\tattrs.max_ord = ep->ord;\n\tattrs.llp_stream_handle = ep;\n\tattrs.next_state = C4IW_QP_STATE_RTS;\n\n\t \n\tmask = C4IW_QP_ATTR_NEXT_STATE |\n\t\t\t     C4IW_QP_ATTR_LLP_STREAM_HANDLE |\n\t\t\t     C4IW_QP_ATTR_MPA_ATTR |\n\t\t\t     C4IW_QP_ATTR_MAX_IRD |\n\t\t\t     C4IW_QP_ATTR_MAX_ORD;\n\n\terr = c4iw_modify_qp(ep->com.qp->rhp,\n\t\t\t     ep->com.qp, mask, &attrs, 1);\n\tif (err)\n\t\tgoto err_deref_cm_id;\n\n\tset_bit(STOP_MPA_TIMER, &ep->com.flags);\n\terr = send_mpa_reply(ep, conn_param->private_data,\n\t\t\t     conn_param->private_data_len);\n\tif (err)\n\t\tgoto err_deref_cm_id;\n\n\t__state_set(&ep->com, FPDU_MODE);\n\testablished_upcall(ep);\n\tmutex_unlock(&ep->com.mutex);\n\tc4iw_put_ep(&ep->com);\n\treturn 0;\nerr_deref_cm_id:\n\tderef_cm_id(&ep->com);\nerr_abort:\n\tabort = 1;\nerr_out:\n\tmutex_unlock(&ep->com.mutex);\n\tif (abort)\n\t\tc4iw_ep_disconnect(ep, 1, GFP_KERNEL);\n\tc4iw_put_ep(&ep->com);\n\treturn err;\n}\n\nstatic int pick_local_ipaddrs(struct c4iw_dev *dev, struct iw_cm_id *cm_id)\n{\n\tstruct in_device *ind;\n\tint found = 0;\n\tstruct sockaddr_in *laddr = (struct sockaddr_in *)&cm_id->m_local_addr;\n\tstruct sockaddr_in *raddr = (struct sockaddr_in *)&cm_id->m_remote_addr;\n\tconst struct in_ifaddr *ifa;\n\n\tind = in_dev_get(dev->rdev.lldi.ports[0]);\n\tif (!ind)\n\t\treturn -EADDRNOTAVAIL;\n\trcu_read_lock();\n\tin_dev_for_each_ifa_rcu(ifa, ind) {\n\t\tif (ifa->ifa_flags & IFA_F_SECONDARY)\n\t\t\tcontinue;\n\t\tladdr->sin_addr.s_addr = ifa->ifa_address;\n\t\traddr->sin_addr.s_addr = ifa->ifa_address;\n\t\tfound = 1;\n\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\tin_dev_put(ind);\n\treturn found ? 0 : -EADDRNOTAVAIL;\n}\n\nstatic int get_lladdr(struct net_device *dev, struct in6_addr *addr,\n\t\t      unsigned char banned_flags)\n{\n\tstruct inet6_dev *idev;\n\tint err = -EADDRNOTAVAIL;\n\n\trcu_read_lock();\n\tidev = __in6_dev_get(dev);\n\tif (idev != NULL) {\n\t\tstruct inet6_ifaddr *ifp;\n\n\t\tread_lock_bh(&idev->lock);\n\t\tlist_for_each_entry(ifp, &idev->addr_list, if_list) {\n\t\t\tif (ifp->scope == IFA_LINK &&\n\t\t\t    !(ifp->flags & banned_flags)) {\n\t\t\t\tmemcpy(addr, &ifp->addr, 16);\n\t\t\t\terr = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tread_unlock_bh(&idev->lock);\n\t}\n\trcu_read_unlock();\n\treturn err;\n}\n\nstatic int pick_local_ip6addrs(struct c4iw_dev *dev, struct iw_cm_id *cm_id)\n{\n\tstruct in6_addr addr;\n\tstruct sockaddr_in6 *la6 = (struct sockaddr_in6 *)&cm_id->m_local_addr;\n\tstruct sockaddr_in6 *ra6 = (struct sockaddr_in6 *)&cm_id->m_remote_addr;\n\n\tif (!get_lladdr(dev->rdev.lldi.ports[0], &addr, IFA_F_TENTATIVE)) {\n\t\tmemcpy(la6->sin6_addr.s6_addr, &addr, 16);\n\t\tmemcpy(ra6->sin6_addr.s6_addr, &addr, 16);\n\t\treturn 0;\n\t}\n\treturn -EADDRNOTAVAIL;\n}\n\nint c4iw_connect(struct iw_cm_id *cm_id, struct iw_cm_conn_param *conn_param)\n{\n\tstruct c4iw_dev *dev = to_c4iw_dev(cm_id->device);\n\tstruct c4iw_ep *ep;\n\tint err = 0;\n\tstruct sockaddr_in *laddr;\n\tstruct sockaddr_in *raddr;\n\tstruct sockaddr_in6 *laddr6;\n\tstruct sockaddr_in6 *raddr6;\n\t__u8 *ra;\n\tint iptype;\n\n\tif ((conn_param->ord > cur_max_read_depth(dev)) ||\n\t    (conn_param->ird > cur_max_read_depth(dev))) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\tep = alloc_ep(sizeof(*ep), GFP_KERNEL);\n\tif (!ep) {\n\t\tpr_err(\"%s - cannot alloc ep\\n\", __func__);\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tskb_queue_head_init(&ep->com.ep_skb_list);\n\tif (alloc_ep_skb_list(&ep->com.ep_skb_list, CN_MAX_CON_BUF)) {\n\t\terr = -ENOMEM;\n\t\tgoto fail1;\n\t}\n\n\ttimer_setup(&ep->timer, ep_timeout, 0);\n\tep->plen = conn_param->private_data_len;\n\tif (ep->plen)\n\t\tmemcpy(ep->mpa_pkt + sizeof(struct mpa_message),\n\t\t       conn_param->private_data, ep->plen);\n\tep->ird = conn_param->ird;\n\tep->ord = conn_param->ord;\n\n\tif (peer2peer && ep->ord == 0)\n\t\tep->ord = 1;\n\n\tep->com.cm_id = cm_id;\n\tref_cm_id(&ep->com);\n\tcm_id->provider_data = ep;\n\tep->com.dev = dev;\n\tep->com.qp = get_qhp(dev, conn_param->qpn);\n\tif (!ep->com.qp) {\n\t\tpr_warn(\"%s qpn 0x%x not found!\\n\", __func__, conn_param->qpn);\n\t\terr = -EINVAL;\n\t\tgoto fail2;\n\t}\n\tref_qp(ep);\n\tpr_debug(\"qpn 0x%x qp %p cm_id %p\\n\", conn_param->qpn,\n\t\t ep->com.qp, cm_id);\n\n\t \n\tep->atid = cxgb4_alloc_atid(dev->rdev.lldi.tids, ep);\n\tif (ep->atid == -1) {\n\t\tpr_err(\"%s - cannot alloc atid\\n\", __func__);\n\t\terr = -ENOMEM;\n\t\tgoto fail2;\n\t}\n\terr = xa_insert_irq(&dev->atids, ep->atid, ep, GFP_KERNEL);\n\tif (err)\n\t\tgoto fail5;\n\n\tmemcpy(&ep->com.local_addr, &cm_id->m_local_addr,\n\t       sizeof(ep->com.local_addr));\n\tmemcpy(&ep->com.remote_addr, &cm_id->m_remote_addr,\n\t       sizeof(ep->com.remote_addr));\n\n\tladdr = (struct sockaddr_in *)&ep->com.local_addr;\n\traddr = (struct sockaddr_in *)&ep->com.remote_addr;\n\tladdr6 = (struct sockaddr_in6 *)&ep->com.local_addr;\n\traddr6 = (struct sockaddr_in6 *) &ep->com.remote_addr;\n\n\tif (cm_id->m_remote_addr.ss_family == AF_INET) {\n\t\tiptype = 4;\n\t\tra = (__u8 *)&raddr->sin_addr;\n\n\t\t \n\t\tif (raddr->sin_addr.s_addr == htonl(INADDR_ANY)) {\n\t\t\terr = pick_local_ipaddrs(dev, cm_id);\n\t\t\tif (err)\n\t\t\t\tgoto fail3;\n\t\t}\n\n\t\t \n\t\tpr_debug(\"saddr %pI4 sport 0x%x raddr %pI4 rport 0x%x\\n\",\n\t\t\t &laddr->sin_addr, ntohs(laddr->sin_port),\n\t\t\t ra, ntohs(raddr->sin_port));\n\t\tep->dst = cxgb_find_route(&dev->rdev.lldi, get_real_dev,\n\t\t\t\t\t  laddr->sin_addr.s_addr,\n\t\t\t\t\t  raddr->sin_addr.s_addr,\n\t\t\t\t\t  laddr->sin_port,\n\t\t\t\t\t  raddr->sin_port, cm_id->tos);\n\t} else {\n\t\tiptype = 6;\n\t\tra = (__u8 *)&raddr6->sin6_addr;\n\n\t\t \n\t\tif (ipv6_addr_type(&raddr6->sin6_addr) == IPV6_ADDR_ANY) {\n\t\t\terr = pick_local_ip6addrs(dev, cm_id);\n\t\t\tif (err)\n\t\t\t\tgoto fail3;\n\t\t}\n\n\t\t \n\t\tpr_debug(\"saddr %pI6 sport 0x%x raddr %pI6 rport 0x%x\\n\",\n\t\t\t laddr6->sin6_addr.s6_addr,\n\t\t\t ntohs(laddr6->sin6_port),\n\t\t\t raddr6->sin6_addr.s6_addr, ntohs(raddr6->sin6_port));\n\t\tep->dst = cxgb_find_route6(&dev->rdev.lldi, get_real_dev,\n\t\t\t\t\t   laddr6->sin6_addr.s6_addr,\n\t\t\t\t\t   raddr6->sin6_addr.s6_addr,\n\t\t\t\t\t   laddr6->sin6_port,\n\t\t\t\t\t   raddr6->sin6_port, cm_id->tos,\n\t\t\t\t\t   raddr6->sin6_scope_id);\n\t}\n\tif (!ep->dst) {\n\t\tpr_err(\"%s - cannot find route\\n\", __func__);\n\t\terr = -EHOSTUNREACH;\n\t\tgoto fail3;\n\t}\n\n\terr = import_ep(ep, iptype, ra, ep->dst, ep->com.dev, true,\n\t\t\tep->com.dev->rdev.lldi.adapter_type, cm_id->tos);\n\tif (err) {\n\t\tpr_err(\"%s - cannot alloc l2e\\n\", __func__);\n\t\tgoto fail4;\n\t}\n\n\tpr_debug(\"txq_idx %u tx_chan %u smac_idx %u rss_qid %u l2t_idx %u\\n\",\n\t\t ep->txq_idx, ep->tx_chan, ep->smac_idx, ep->rss_qid,\n\t\t ep->l2t->idx);\n\n\tstate_set(&ep->com, CONNECTING);\n\tep->tos = cm_id->tos;\n\n\t \n\terr = send_connect(ep);\n\tif (!err)\n\t\tgoto out;\n\n\tcxgb4_l2t_release(ep->l2t);\nfail4:\n\tdst_release(ep->dst);\nfail3:\n\txa_erase_irq(&ep->com.dev->atids, ep->atid);\nfail5:\n\tcxgb4_free_atid(ep->com.dev->rdev.lldi.tids, ep->atid);\nfail2:\n\tskb_queue_purge(&ep->com.ep_skb_list);\n\tderef_cm_id(&ep->com);\nfail1:\n\tc4iw_put_ep(&ep->com);\nout:\n\treturn err;\n}\n\nstatic int create_server6(struct c4iw_dev *dev, struct c4iw_listen_ep *ep)\n{\n\tint err;\n\tstruct sockaddr_in6 *sin6 = (struct sockaddr_in6 *)\n\t\t\t\t    &ep->com.local_addr;\n\n\tif (ipv6_addr_type(&sin6->sin6_addr) != IPV6_ADDR_ANY) {\n\t\terr = cxgb4_clip_get(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t     (const u32 *)&sin6->sin6_addr.s6_addr, 1);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\tc4iw_init_wr_wait(ep->com.wr_waitp);\n\terr = cxgb4_create_server6(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t   ep->stid, &sin6->sin6_addr,\n\t\t\t\t   sin6->sin6_port,\n\t\t\t\t   ep->com.dev->rdev.lldi.rxq_ids[0]);\n\tif (!err)\n\t\terr = c4iw_wait_for_reply(&ep->com.dev->rdev,\n\t\t\t\t\t  ep->com.wr_waitp,\n\t\t\t\t\t  0, 0, __func__);\n\telse if (err > 0)\n\t\terr = net_xmit_errno(err);\n\tif (err) {\n\t\tcxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t   (const u32 *)&sin6->sin6_addr.s6_addr, 1);\n\t\tpr_err(\"cxgb4_create_server6/filter failed err %d stid %d laddr %pI6 lport %d\\n\",\n\t\t       err, ep->stid,\n\t\t       sin6->sin6_addr.s6_addr, ntohs(sin6->sin6_port));\n\t}\n\treturn err;\n}\n\nstatic int create_server4(struct c4iw_dev *dev, struct c4iw_listen_ep *ep)\n{\n\tint err;\n\tstruct sockaddr_in *sin = (struct sockaddr_in *)\n\t\t\t\t  &ep->com.local_addr;\n\n\tif (dev->rdev.lldi.enable_fw_ofld_conn) {\n\t\tdo {\n\t\t\terr = cxgb4_create_server_filter(\n\t\t\t\tep->com.dev->rdev.lldi.ports[0], ep->stid,\n\t\t\t\tsin->sin_addr.s_addr, sin->sin_port, 0,\n\t\t\t\tep->com.dev->rdev.lldi.rxq_ids[0], 0, 0);\n\t\t\tif (err == -EBUSY) {\n\t\t\t\tif (c4iw_fatal_error(&ep->com.dev->rdev)) {\n\t\t\t\t\terr = -EIO;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\t\tschedule_timeout(usecs_to_jiffies(100));\n\t\t\t}\n\t\t} while (err == -EBUSY);\n\t} else {\n\t\tc4iw_init_wr_wait(ep->com.wr_waitp);\n\t\terr = cxgb4_create_server(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\tep->stid, sin->sin_addr.s_addr, sin->sin_port,\n\t\t\t\t0, ep->com.dev->rdev.lldi.rxq_ids[0]);\n\t\tif (!err)\n\t\t\terr = c4iw_wait_for_reply(&ep->com.dev->rdev,\n\t\t\t\t\t\t  ep->com.wr_waitp,\n\t\t\t\t\t\t  0, 0, __func__);\n\t\telse if (err > 0)\n\t\t\terr = net_xmit_errno(err);\n\t}\n\tif (err)\n\t\tpr_err(\"cxgb4_create_server/filter failed err %d stid %d laddr %pI4 lport %d\\n\"\n\t\t       , err, ep->stid,\n\t\t       &sin->sin_addr, ntohs(sin->sin_port));\n\treturn err;\n}\n\nint c4iw_create_listen(struct iw_cm_id *cm_id, int backlog)\n{\n\tint err = 0;\n\tstruct c4iw_dev *dev = to_c4iw_dev(cm_id->device);\n\tstruct c4iw_listen_ep *ep;\n\n\tmight_sleep();\n\n\tep = alloc_ep(sizeof(*ep), GFP_KERNEL);\n\tif (!ep) {\n\t\tpr_err(\"%s - cannot alloc ep\\n\", __func__);\n\t\terr = -ENOMEM;\n\t\tgoto fail1;\n\t}\n\tskb_queue_head_init(&ep->com.ep_skb_list);\n\tpr_debug(\"ep %p\\n\", ep);\n\tep->com.cm_id = cm_id;\n\tref_cm_id(&ep->com);\n\tep->com.dev = dev;\n\tep->backlog = backlog;\n\tmemcpy(&ep->com.local_addr, &cm_id->m_local_addr,\n\t       sizeof(ep->com.local_addr));\n\n\t \n\tif (dev->rdev.lldi.enable_fw_ofld_conn &&\n\t    ep->com.local_addr.ss_family == AF_INET)\n\t\tep->stid = cxgb4_alloc_sftid(dev->rdev.lldi.tids,\n\t\t\t\t\t     cm_id->m_local_addr.ss_family, ep);\n\telse\n\t\tep->stid = cxgb4_alloc_stid(dev->rdev.lldi.tids,\n\t\t\t\t\t    cm_id->m_local_addr.ss_family, ep);\n\n\tif (ep->stid == -1) {\n\t\tpr_err(\"%s - cannot alloc stid\\n\", __func__);\n\t\terr = -ENOMEM;\n\t\tgoto fail2;\n\t}\n\terr = xa_insert_irq(&dev->stids, ep->stid, ep, GFP_KERNEL);\n\tif (err)\n\t\tgoto fail3;\n\n\tstate_set(&ep->com, LISTEN);\n\tif (ep->com.local_addr.ss_family == AF_INET)\n\t\terr = create_server4(dev, ep);\n\telse\n\t\terr = create_server6(dev, ep);\n\tif (!err) {\n\t\tcm_id->provider_data = ep;\n\t\tgoto out;\n\t}\n\txa_erase_irq(&ep->com.dev->stids, ep->stid);\nfail3:\n\tcxgb4_free_stid(ep->com.dev->rdev.lldi.tids, ep->stid,\n\t\t\tep->com.local_addr.ss_family);\nfail2:\n\tderef_cm_id(&ep->com);\n\tc4iw_put_ep(&ep->com);\nfail1:\nout:\n\treturn err;\n}\n\nint c4iw_destroy_listen(struct iw_cm_id *cm_id)\n{\n\tint err;\n\tstruct c4iw_listen_ep *ep = to_listen_ep(cm_id);\n\n\tpr_debug(\"ep %p\\n\", ep);\n\n\tmight_sleep();\n\tstate_set(&ep->com, DEAD);\n\tif (ep->com.dev->rdev.lldi.enable_fw_ofld_conn &&\n\t    ep->com.local_addr.ss_family == AF_INET) {\n\t\terr = cxgb4_remove_server_filter(\n\t\t\tep->com.dev->rdev.lldi.ports[0], ep->stid,\n\t\t\tep->com.dev->rdev.lldi.rxq_ids[0], false);\n\t} else {\n\t\tstruct sockaddr_in6 *sin6;\n\t\tc4iw_init_wr_wait(ep->com.wr_waitp);\n\t\terr = cxgb4_remove_server(\n\t\t\t\tep->com.dev->rdev.lldi.ports[0], ep->stid,\n\t\t\t\tep->com.dev->rdev.lldi.rxq_ids[0],\n\t\t\t\tep->com.local_addr.ss_family == AF_INET6);\n\t\tif (err)\n\t\t\tgoto done;\n\t\terr = c4iw_wait_for_reply(&ep->com.dev->rdev, ep->com.wr_waitp,\n\t\t\t\t\t  0, 0, __func__);\n\t\tsin6 = (struct sockaddr_in6 *)&ep->com.local_addr;\n\t\tcxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t   (const u32 *)&sin6->sin6_addr.s6_addr, 1);\n\t}\n\txa_erase_irq(&ep->com.dev->stids, ep->stid);\n\tcxgb4_free_stid(ep->com.dev->rdev.lldi.tids, ep->stid,\n\t\t\tep->com.local_addr.ss_family);\ndone:\n\tderef_cm_id(&ep->com);\n\tc4iw_put_ep(&ep->com);\n\treturn err;\n}\n\nint c4iw_ep_disconnect(struct c4iw_ep *ep, int abrupt, gfp_t gfp)\n{\n\tint ret = 0;\n\tint close = 0;\n\tint fatal = 0;\n\tstruct c4iw_rdev *rdev;\n\n\tmutex_lock(&ep->com.mutex);\n\n\tpr_debug(\"ep %p state %s, abrupt %d\\n\", ep,\n\t\t states[ep->com.state], abrupt);\n\n\t \n\tc4iw_get_ep(&ep->com);\n\n\trdev = &ep->com.dev->rdev;\n\tif (c4iw_fatal_error(rdev)) {\n\t\tfatal = 1;\n\t\tclose_complete_upcall(ep, -EIO);\n\t\tep->com.state = DEAD;\n\t}\n\tswitch (ep->com.state) {\n\tcase MPA_REQ_WAIT:\n\tcase MPA_REQ_SENT:\n\tcase MPA_REQ_RCVD:\n\tcase MPA_REP_SENT:\n\tcase FPDU_MODE:\n\tcase CONNECTING:\n\t\tclose = 1;\n\t\tif (abrupt)\n\t\t\tep->com.state = ABORTING;\n\t\telse {\n\t\t\tep->com.state = CLOSING;\n\n\t\t\t \n\t\t\tif (ep->mpa_skb &&\n\t\t\t    test_bit(STOP_MPA_TIMER, &ep->com.flags)) {\n\t\t\t\tclear_bit(STOP_MPA_TIMER, &ep->com.flags);\n\t\t\t\tstop_ep_timer(ep);\n\t\t\t}\n\t\t\tstart_ep_timer(ep);\n\t\t}\n\t\tset_bit(CLOSE_SENT, &ep->com.flags);\n\t\tbreak;\n\tcase CLOSING:\n\t\tif (!test_and_set_bit(CLOSE_SENT, &ep->com.flags)) {\n\t\t\tclose = 1;\n\t\t\tif (abrupt) {\n\t\t\t\t(void)stop_ep_timer(ep);\n\t\t\t\tep->com.state = ABORTING;\n\t\t\t} else\n\t\t\t\tep->com.state = MORIBUND;\n\t\t}\n\t\tbreak;\n\tcase MORIBUND:\n\tcase ABORTING:\n\tcase DEAD:\n\t\tpr_debug(\"ignoring disconnect ep %p state %u\\n\",\n\t\t\t ep, ep->com.state);\n\t\tbreak;\n\tdefault:\n\t\tWARN_ONCE(1, \"Bad endpoint state %u\\n\", ep->com.state);\n\t\tbreak;\n\t}\n\n\tif (close) {\n\t\tif (abrupt) {\n\t\t\tset_bit(EP_DISC_ABORT, &ep->com.history);\n\t\t\tret = send_abort(ep);\n\t\t} else {\n\t\t\tset_bit(EP_DISC_CLOSE, &ep->com.history);\n\t\t\tret = send_halfclose(ep);\n\t\t}\n\t\tif (ret) {\n\t\t\tset_bit(EP_DISC_FAIL, &ep->com.history);\n\t\t\tif (!abrupt) {\n\t\t\t\tstop_ep_timer(ep);\n\t\t\t\tclose_complete_upcall(ep, -EIO);\n\t\t\t}\n\t\t\tif (ep->com.qp) {\n\t\t\t\tstruct c4iw_qp_attributes attrs;\n\n\t\t\t\tattrs.next_state = C4IW_QP_STATE_ERROR;\n\t\t\t\tret = c4iw_modify_qp(ep->com.qp->rhp,\n\t\t\t\t\t\t     ep->com.qp,\n\t\t\t\t\t\t     C4IW_QP_ATTR_NEXT_STATE,\n\t\t\t\t\t\t     &attrs, 1);\n\t\t\t\tif (ret)\n\t\t\t\t\tpr_err(\"%s - qp <- error failed!\\n\",\n\t\t\t\t\t       __func__);\n\t\t\t}\n\t\t\tfatal = 1;\n\t\t}\n\t}\n\tmutex_unlock(&ep->com.mutex);\n\tc4iw_put_ep(&ep->com);\n\tif (fatal)\n\t\trelease_ep_resources(ep);\n\treturn ret;\n}\n\nstatic void active_ofld_conn_reply(struct c4iw_dev *dev, struct sk_buff *skb,\n\t\t\tstruct cpl_fw6_msg_ofld_connection_wr_rpl *req)\n{\n\tstruct c4iw_ep *ep;\n\tint atid = be32_to_cpu(req->tid);\n\n\tep = (struct c4iw_ep *)lookup_atid(dev->rdev.lldi.tids,\n\t\t\t\t\t   (__force u32) req->tid);\n\tif (!ep)\n\t\treturn;\n\n\tswitch (req->retval) {\n\tcase FW_ENOMEM:\n\t\tset_bit(ACT_RETRY_NOMEM, &ep->com.history);\n\t\tif (ep->retry_count++ < ACT_OPEN_RETRY_COUNT) {\n\t\t\tsend_fw_act_open_req(ep, atid);\n\t\t\treturn;\n\t\t}\n\t\tfallthrough;\n\tcase FW_EADDRINUSE:\n\t\tset_bit(ACT_RETRY_INUSE, &ep->com.history);\n\t\tif (ep->retry_count++ < ACT_OPEN_RETRY_COUNT) {\n\t\t\tsend_fw_act_open_req(ep, atid);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tpr_info(\"%s unexpected ofld conn wr retval %d\\n\",\n\t\t       __func__, req->retval);\n\t\tbreak;\n\t}\n\tpr_err(\"active ofld_connect_wr failure %d atid %d\\n\",\n\t       req->retval, atid);\n\tmutex_lock(&dev->rdev.stats.lock);\n\tdev->rdev.stats.act_ofld_conn_fails++;\n\tmutex_unlock(&dev->rdev.stats.lock);\n\tconnect_reply_upcall(ep, status2errno(req->retval));\n\tstate_set(&ep->com, DEAD);\n\tif (ep->com.remote_addr.ss_family == AF_INET6) {\n\t\tstruct sockaddr_in6 *sin6 =\n\t\t\t(struct sockaddr_in6 *)&ep->com.local_addr;\n\t\tcxgb4_clip_release(ep->com.dev->rdev.lldi.ports[0],\n\t\t\t\t   (const u32 *)&sin6->sin6_addr.s6_addr, 1);\n\t}\n\txa_erase_irq(&dev->atids, atid);\n\tcxgb4_free_atid(dev->rdev.lldi.tids, atid);\n\tdst_release(ep->dst);\n\tcxgb4_l2t_release(ep->l2t);\n\tc4iw_put_ep(&ep->com);\n}\n\nstatic void passive_ofld_conn_reply(struct c4iw_dev *dev, struct sk_buff *skb,\n\t\t\tstruct cpl_fw6_msg_ofld_connection_wr_rpl *req)\n{\n\tstruct sk_buff *rpl_skb;\n\tstruct cpl_pass_accept_req *cpl;\n\tint ret;\n\n\trpl_skb = (struct sk_buff *)(unsigned long)req->cookie;\n\tif (req->retval) {\n\t\tpr_err(\"%s passive open failure %d\\n\", __func__, req->retval);\n\t\tmutex_lock(&dev->rdev.stats.lock);\n\t\tdev->rdev.stats.pas_ofld_conn_fails++;\n\t\tmutex_unlock(&dev->rdev.stats.lock);\n\t\tkfree_skb(rpl_skb);\n\t} else {\n\t\tcpl = (struct cpl_pass_accept_req *)cplhdr(rpl_skb);\n\t\tOPCODE_TID(cpl) = htonl(MK_OPCODE_TID(CPL_PASS_ACCEPT_REQ,\n\t\t\t\t\t(__force u32) htonl(\n\t\t\t\t\t(__force u32) req->tid)));\n\t\tret = pass_accept_req(dev, rpl_skb);\n\t\tif (!ret)\n\t\t\tkfree_skb(rpl_skb);\n\t}\n\treturn;\n}\n\nstatic inline u64 t4_tcb_get_field64(__be64 *tcb, u16 word)\n{\n\tu64 tlo = be64_to_cpu(tcb[((31 - word) / 2)]);\n\tu64 thi = be64_to_cpu(tcb[((31 - word) / 2) - 1]);\n\tu64 t;\n\tu32 shift = 32;\n\n\tt = (thi << shift) | (tlo >> shift);\n\n\treturn t;\n}\n\nstatic inline u32 t4_tcb_get_field32(__be64 *tcb, u16 word, u32 mask, u32 shift)\n{\n\tu32 v;\n\tu64 t = be64_to_cpu(tcb[(31 - word) / 2]);\n\n\tif (word & 0x1)\n\t\tshift += 32;\n\tv = (t >> shift) & mask;\n\treturn v;\n}\n\nstatic int read_tcb_rpl(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_get_tcb_rpl *rpl = cplhdr(skb);\n\t__be64 *tcb = (__be64 *)(rpl + 1);\n\tunsigned int tid = GET_TID(rpl);\n\tstruct c4iw_ep *ep;\n\tu64 t_flags_64;\n\tu32 rx_pdu_out;\n\n\tep = get_ep_from_tid(dev, tid);\n\tif (!ep)\n\t\treturn 0;\n\t \n\n\tt_flags_64 = t4_tcb_get_field64(tcb, TCB_T_FLAGS_W);\n\trx_pdu_out = (t_flags_64 & TF_RX_PDU_OUT_V(1)) >> TF_RX_PDU_OUT_S;\n\n\tc4iw_put_ep(&ep->com);  \n\tc4iw_put_ep(&ep->com);  \n\n\t \n\tif (rx_pdu_out) {\n\t\tif (++ep->rx_pdu_out_cnt >= 2) {\n\t\t\tWARN_ONCE(1, \"tcb re-read() reached the guard limit, finishing the cleanup\\n\");\n\t\t\tgoto cleanup;\n\t\t}\n\t\tread_tcb(ep);\n\t\treturn 0;\n\t}\n\n\tep->srqe_idx = t4_tcb_get_field32(tcb, TCB_RQ_START_W, TCB_RQ_START_M,\n\t\t\t\t\t  TCB_RQ_START_S);\ncleanup:\n\tpr_debug(\"ep %p tid %u %016x\\n\", ep, ep->hwtid, ep->srqe_idx);\n\n\tif (test_bit(PEER_ABORT_IN_PROGRESS, &ep->com.flags))\n\t\tfinish_peer_abort(dev, ep);\n\telse if (test_bit(ABORT_REQ_IN_PROGRESS, &ep->com.flags))\n\t\tsend_abort_req(ep);\n\telse\n\t\tWARN_ONCE(1, \"unexpected state!\");\n\n\treturn 0;\n}\n\nstatic int deferred_fw6_msg(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_fw6_msg *rpl = cplhdr(skb);\n\tstruct cpl_fw6_msg_ofld_connection_wr_rpl *req;\n\n\tswitch (rpl->type) {\n\tcase FW6_TYPE_CQE:\n\t\tc4iw_ev_dispatch(dev, (struct t4_cqe *)&rpl->data[0]);\n\t\tbreak;\n\tcase FW6_TYPE_OFLD_CONNECTION_WR_RPL:\n\t\treq = (struct cpl_fw6_msg_ofld_connection_wr_rpl *)rpl->data;\n\t\tswitch (req->t_state) {\n\t\tcase TCP_SYN_SENT:\n\t\t\tactive_ofld_conn_reply(dev, skb, req);\n\t\t\tbreak;\n\t\tcase TCP_SYN_RECV:\n\t\t\tpassive_ofld_conn_reply(dev, skb, req);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"%s unexpected ofld conn wr state %d\\n\",\n\t\t\t       __func__, req->t_state);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void build_cpl_pass_accept_req(struct sk_buff *skb, int stid , u8 tos)\n{\n\t__be32 l2info;\n\t__be16 hdr_len, vlantag, len;\n\tu16 eth_hdr_len;\n\tint tcp_hdr_len, ip_hdr_len;\n\tu8 intf;\n\tstruct cpl_rx_pkt *cpl = cplhdr(skb);\n\tstruct cpl_pass_accept_req *req;\n\tstruct tcp_options_received tmp_opt;\n\tstruct c4iw_dev *dev;\n\tenum chip_type type;\n\n\tdev = *((struct c4iw_dev **) (skb->cb + sizeof(void *)));\n\t \n\tvlantag = cpl->vlan;\n\tlen = cpl->len;\n\tl2info  = cpl->l2info;\n\thdr_len = cpl->hdr_len;\n\tintf = cpl->iff;\n\n\t__skb_pull(skb, sizeof(*req) + sizeof(struct rss_header));\n\n\t \n\tmemset(&tmp_opt, 0, sizeof(tmp_opt));\n\ttcp_clear_options(&tmp_opt);\n\ttcp_parse_options(&init_net, skb, &tmp_opt, 0, NULL);\n\n\treq = __skb_push(skb, sizeof(*req));\n\tmemset(req, 0, sizeof(*req));\n\treq->l2info = cpu_to_be16(SYN_INTF_V(intf) |\n\t\t\t SYN_MAC_IDX_V(RX_MACIDX_G(\n\t\t\t be32_to_cpu(l2info))) |\n\t\t\t SYN_XACT_MATCH_F);\n\ttype = dev->rdev.lldi.adapter_type;\n\ttcp_hdr_len = RX_TCPHDR_LEN_G(be16_to_cpu(hdr_len));\n\tip_hdr_len = RX_IPHDR_LEN_G(be16_to_cpu(hdr_len));\n\treq->hdr_len =\n\t\tcpu_to_be32(SYN_RX_CHAN_V(RX_CHAN_G(be32_to_cpu(l2info))));\n\tif (CHELSIO_CHIP_VERSION(type) <= CHELSIO_T5) {\n\t\teth_hdr_len = is_t4(type) ?\n\t\t\t\tRX_ETHHDR_LEN_G(be32_to_cpu(l2info)) :\n\t\t\t\tRX_T5_ETHHDR_LEN_G(be32_to_cpu(l2info));\n\t\treq->hdr_len |= cpu_to_be32(TCP_HDR_LEN_V(tcp_hdr_len) |\n\t\t\t\t\t    IP_HDR_LEN_V(ip_hdr_len) |\n\t\t\t\t\t    ETH_HDR_LEN_V(eth_hdr_len));\n\t} else {  \n\t\teth_hdr_len = RX_T6_ETHHDR_LEN_G(be32_to_cpu(l2info));\n\t\treq->hdr_len |= cpu_to_be32(T6_TCP_HDR_LEN_V(tcp_hdr_len) |\n\t\t\t\t\t    T6_IP_HDR_LEN_V(ip_hdr_len) |\n\t\t\t\t\t    T6_ETH_HDR_LEN_V(eth_hdr_len));\n\t}\n\treq->vlan = vlantag;\n\treq->len = len;\n\treq->tos_stid = cpu_to_be32(PASS_OPEN_TID_V(stid) |\n\t\t\t\t    PASS_OPEN_TOS_V(tos));\n\treq->tcpopt.mss = htons(tmp_opt.mss_clamp);\n\tif (tmp_opt.wscale_ok)\n\t\treq->tcpopt.wsf = tmp_opt.snd_wscale;\n\treq->tcpopt.tstamp = tmp_opt.saw_tstamp;\n\tif (tmp_opt.sack_ok)\n\t\treq->tcpopt.sack = 1;\n\tOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_PASS_ACCEPT_REQ, 0));\n\treturn;\n}\n\nstatic void send_fw_pass_open_req(struct c4iw_dev *dev, struct sk_buff *skb,\n\t\t\t\t  __be32 laddr, __be16 lport,\n\t\t\t\t  __be32 raddr, __be16 rport,\n\t\t\t\t  u32 rcv_isn, u32 filter, u16 window,\n\t\t\t\t  u32 rss_qid, u8 port_id)\n{\n\tstruct sk_buff *req_skb;\n\tstruct fw_ofld_connection_wr *req;\n\tstruct cpl_pass_accept_req *cpl = cplhdr(skb);\n\tint ret;\n\n\treq_skb = alloc_skb(sizeof(struct fw_ofld_connection_wr), GFP_KERNEL);\n\tif (!req_skb)\n\t\treturn;\n\treq = __skb_put_zero(req_skb, sizeof(*req));\n\treq->op_compl = htonl(WR_OP_V(FW_OFLD_CONNECTION_WR) | FW_WR_COMPL_F);\n\treq->len16_pkd = htonl(FW_WR_LEN16_V(DIV_ROUND_UP(sizeof(*req), 16)));\n\treq->le.version_cpl = htonl(FW_OFLD_CONNECTION_WR_CPL_F);\n\treq->le.filter = (__force __be32) filter;\n\treq->le.lport = lport;\n\treq->le.pport = rport;\n\treq->le.u.ipv4.lip = laddr;\n\treq->le.u.ipv4.pip = raddr;\n\treq->tcb.rcv_nxt = htonl(rcv_isn + 1);\n\treq->tcb.rcv_adv = htons(window);\n\treq->tcb.t_state_to_astid =\n\t\t htonl(FW_OFLD_CONNECTION_WR_T_STATE_V(TCP_SYN_RECV) |\n\t\t\tFW_OFLD_CONNECTION_WR_RCV_SCALE_V(cpl->tcpopt.wsf) |\n\t\t\tFW_OFLD_CONNECTION_WR_ASTID_V(\n\t\t\tPASS_OPEN_TID_G(ntohl(cpl->tos_stid))));\n\n\t \n\treq->tcb.opt2 = htonl(RSS_QUEUE_V(rss_qid));\n\n\t \n\treq->tcb.opt0 = cpu_to_be64(MSS_IDX_V(0xF));\n\treq->cookie = (uintptr_t)skb;\n\n\tset_wr_txq(req_skb, CPL_PRIORITY_CONTROL, port_id);\n\tret = cxgb4_ofld_send(dev->rdev.lldi.ports[0], req_skb);\n\tif (ret < 0) {\n\t\tpr_err(\"%s - cxgb4_ofld_send error %d - dropping\\n\", __func__,\n\t\t       ret);\n\t\tkfree_skb(skb);\n\t\tkfree_skb(req_skb);\n\t}\n}\n\n \nstatic int rx_pkt(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tint stid;\n\tunsigned int filter;\n\tstruct ethhdr *eh = NULL;\n\tstruct vlan_ethhdr *vlan_eh = NULL;\n\tstruct iphdr *iph;\n\tstruct tcphdr *tcph;\n\tstruct rss_header *rss = (void *)skb->data;\n\tstruct cpl_rx_pkt *cpl = (void *)skb->data;\n\tstruct cpl_pass_accept_req *req = (void *)(rss + 1);\n\tstruct l2t_entry *e;\n\tstruct dst_entry *dst;\n\tstruct c4iw_ep *lep = NULL;\n\tu16 window;\n\tstruct port_info *pi;\n\tstruct net_device *pdev;\n\tu16 rss_qid, eth_hdr_len;\n\tint step;\n\tstruct neighbour *neigh;\n\n\t \n\tif (!(cpl->l2info & cpu_to_be32(RXF_SYN_F)))\n\t\tgoto reject;\n\n\t \n\tif (!(rss->filter_hit && rss->filter_tid))\n\t\tgoto reject;\n\n\t \n\tstid = (__force int) cpu_to_be32((__force u32) rss->hash_val);\n\n\tlep = (struct c4iw_ep *)get_ep_from_stid(dev, stid);\n\tif (!lep) {\n\t\tpr_warn(\"%s connect request on invalid stid %d\\n\",\n\t\t\t__func__, stid);\n\t\tgoto reject;\n\t}\n\n\tswitch (CHELSIO_CHIP_VERSION(dev->rdev.lldi.adapter_type)) {\n\tcase CHELSIO_T4:\n\t\teth_hdr_len = RX_ETHHDR_LEN_G(be32_to_cpu(cpl->l2info));\n\t\tbreak;\n\tcase CHELSIO_T5:\n\t\teth_hdr_len = RX_T5_ETHHDR_LEN_G(be32_to_cpu(cpl->l2info));\n\t\tbreak;\n\tcase CHELSIO_T6:\n\t\teth_hdr_len = RX_T6_ETHHDR_LEN_G(be32_to_cpu(cpl->l2info));\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"T%d Chip is not supported\\n\",\n\t\t       CHELSIO_CHIP_VERSION(dev->rdev.lldi.adapter_type));\n\t\tgoto reject;\n\t}\n\n\tif (eth_hdr_len == ETH_HLEN) {\n\t\teh = (struct ethhdr *)(req + 1);\n\t\tiph = (struct iphdr *)(eh + 1);\n\t} else {\n\t\tvlan_eh = (struct vlan_ethhdr *)(req + 1);\n\t\tiph = (struct iphdr *)(vlan_eh + 1);\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), ntohs(cpl->vlan));\n\t}\n\n\tif (iph->version != 0x4)\n\t\tgoto reject;\n\n\ttcph = (struct tcphdr *)(iph + 1);\n\tskb_set_network_header(skb, (void *)iph - (void *)rss);\n\tskb_set_transport_header(skb, (void *)tcph - (void *)rss);\n\tskb_get(skb);\n\n\tpr_debug(\"lip 0x%x lport %u pip 0x%x pport %u tos %d\\n\",\n\t\t ntohl(iph->daddr), ntohs(tcph->dest), ntohl(iph->saddr),\n\t\t ntohs(tcph->source), iph->tos);\n\n\tdst = cxgb_find_route(&dev->rdev.lldi, get_real_dev,\n\t\t\t      iph->daddr, iph->saddr, tcph->dest,\n\t\t\t      tcph->source, iph->tos);\n\tif (!dst) {\n\t\tpr_err(\"%s - failed to find dst entry!\\n\", __func__);\n\t\tgoto reject;\n\t}\n\tneigh = dst_neigh_lookup_skb(dst, skb);\n\n\tif (!neigh) {\n\t\tpr_err(\"%s - failed to allocate neigh!\\n\", __func__);\n\t\tgoto free_dst;\n\t}\n\n\tif (neigh->dev->flags & IFF_LOOPBACK) {\n\t\tpdev = ip_dev_find(&init_net, iph->daddr);\n\t\tif (!pdev) {\n\t\t\tpr_err(\"%s - failed to find device!\\n\", __func__);\n\t\t\tgoto free_dst;\n\t\t}\n\t\te = cxgb4_l2t_get(dev->rdev.lldi.l2t, neigh,\n\t\t\t\t    pdev, 0);\n\t\tpi = (struct port_info *)netdev_priv(pdev);\n\t\tdev_put(pdev);\n\t} else {\n\t\tpdev = get_real_dev(neigh->dev);\n\t\te = cxgb4_l2t_get(dev->rdev.lldi.l2t, neigh,\n\t\t\t\t\tpdev, 0);\n\t\tpi = (struct port_info *)netdev_priv(pdev);\n\t}\n\tneigh_release(neigh);\n\tif (!e) {\n\t\tpr_err(\"%s - failed to allocate l2t entry!\\n\",\n\t\t       __func__);\n\t\tgoto free_dst;\n\t}\n\n\tstep = dev->rdev.lldi.nrxq / dev->rdev.lldi.nchan;\n\trss_qid = dev->rdev.lldi.rxq_ids[pi->port_id * step];\n\twindow = (__force u16) htons((__force u16)tcph->window);\n\n\t \n\tfilter = (__force unsigned int) cpu_to_be32(cxgb4_select_ntuple(\n\t\t\t\t\t\t    dev->rdev.lldi.ports[0],\n\t\t\t\t\t\t    e));\n\n\t \n\tbuild_cpl_pass_accept_req(skb, stid, iph->tos);\n\tsend_fw_pass_open_req(dev, skb, iph->daddr, tcph->dest, iph->saddr,\n\t\t\t      tcph->source, ntohl(tcph->seq), filter, window,\n\t\t\t      rss_qid, pi->port_id);\n\tcxgb4_l2t_release(e);\nfree_dst:\n\tdst_release(dst);\nreject:\n\tif (lep)\n\t\tc4iw_put_ep(&lep->com);\n\treturn 0;\n}\n\n \nstatic c4iw_handler_func work_handlers[NUM_CPL_CMDS + NUM_FAKE_CPLS] = {\n\t[CPL_ACT_ESTABLISH] = act_establish,\n\t[CPL_ACT_OPEN_RPL] = act_open_rpl,\n\t[CPL_RX_DATA] = rx_data,\n\t[CPL_ABORT_RPL_RSS] = abort_rpl,\n\t[CPL_ABORT_RPL] = abort_rpl,\n\t[CPL_PASS_OPEN_RPL] = pass_open_rpl,\n\t[CPL_CLOSE_LISTSRV_RPL] = close_listsrv_rpl,\n\t[CPL_PASS_ACCEPT_REQ] = pass_accept_req,\n\t[CPL_PASS_ESTABLISH] = pass_establish,\n\t[CPL_PEER_CLOSE] = peer_close,\n\t[CPL_ABORT_REQ_RSS] = peer_abort,\n\t[CPL_CLOSE_CON_RPL] = close_con_rpl,\n\t[CPL_RDMA_TERMINATE] = terminate,\n\t[CPL_FW4_ACK] = fw4_ack,\n\t[CPL_GET_TCB_RPL] = read_tcb_rpl,\n\t[CPL_FW6_MSG] = deferred_fw6_msg,\n\t[CPL_RX_PKT] = rx_pkt,\n\t[FAKE_CPL_PUT_EP_SAFE] = _put_ep_safe,\n\t[FAKE_CPL_PASS_PUT_EP_SAFE] = _put_pass_ep_safe\n};\n\nstatic void process_timeout(struct c4iw_ep *ep)\n{\n\tstruct c4iw_qp_attributes attrs;\n\tint abort = 1;\n\n\tmutex_lock(&ep->com.mutex);\n\tpr_debug(\"ep %p tid %u state %d\\n\", ep, ep->hwtid, ep->com.state);\n\tset_bit(TIMEDOUT, &ep->com.history);\n\tswitch (ep->com.state) {\n\tcase MPA_REQ_SENT:\n\t\tconnect_reply_upcall(ep, -ETIMEDOUT);\n\t\tbreak;\n\tcase MPA_REQ_WAIT:\n\tcase MPA_REQ_RCVD:\n\tcase MPA_REP_SENT:\n\tcase FPDU_MODE:\n\t\tbreak;\n\tcase CLOSING:\n\tcase MORIBUND:\n\t\tif (ep->com.cm_id && ep->com.qp) {\n\t\t\tattrs.next_state = C4IW_QP_STATE_ERROR;\n\t\t\tc4iw_modify_qp(ep->com.qp->rhp,\n\t\t\t\t     ep->com.qp, C4IW_QP_ATTR_NEXT_STATE,\n\t\t\t\t     &attrs, 1);\n\t\t}\n\t\tclose_complete_upcall(ep, -ETIMEDOUT);\n\t\tbreak;\n\tcase ABORTING:\n\tcase DEAD:\n\n\t\t \n\t\tabort = 0;\n\t\tbreak;\n\tdefault:\n\t\tWARN(1, \"%s unexpected state ep %p tid %u state %u\\n\",\n\t\t\t__func__, ep, ep->hwtid, ep->com.state);\n\t\tabort = 0;\n\t}\n\tmutex_unlock(&ep->com.mutex);\n\tif (abort)\n\t\tc4iw_ep_disconnect(ep, 1, GFP_KERNEL);\n\tc4iw_put_ep(&ep->com);\n}\n\nstatic void process_timedout_eps(void)\n{\n\tstruct c4iw_ep *ep;\n\n\tspin_lock_irq(&timeout_lock);\n\twhile (!list_empty(&timeout_list)) {\n\t\tstruct list_head *tmp;\n\n\t\ttmp = timeout_list.next;\n\t\tlist_del(tmp);\n\t\ttmp->next = NULL;\n\t\ttmp->prev = NULL;\n\t\tspin_unlock_irq(&timeout_lock);\n\t\tep = list_entry(tmp, struct c4iw_ep, entry);\n\t\tprocess_timeout(ep);\n\t\tspin_lock_irq(&timeout_lock);\n\t}\n\tspin_unlock_irq(&timeout_lock);\n}\n\nstatic void process_work(struct work_struct *work)\n{\n\tstruct sk_buff *skb = NULL;\n\tstruct c4iw_dev *dev;\n\tstruct cpl_act_establish *rpl;\n\tunsigned int opcode;\n\tint ret;\n\n\tprocess_timedout_eps();\n\twhile ((skb = skb_dequeue(&rxq))) {\n\t\trpl = cplhdr(skb);\n\t\tdev = *((struct c4iw_dev **) (skb->cb + sizeof(void *)));\n\t\topcode = rpl->ot.opcode;\n\n\t\tif (opcode >= ARRAY_SIZE(work_handlers) ||\n\t\t    !work_handlers[opcode]) {\n\t\t\tpr_err(\"No handler for opcode 0x%x.\\n\", opcode);\n\t\t\tkfree_skb(skb);\n\t\t} else {\n\t\t\tret = work_handlers[opcode](dev, skb);\n\t\t\tif (!ret)\n\t\t\t\tkfree_skb(skb);\n\t\t}\n\t\tprocess_timedout_eps();\n\t}\n}\n\nstatic DECLARE_WORK(skb_work, process_work);\n\nstatic void ep_timeout(struct timer_list *t)\n{\n\tstruct c4iw_ep *ep = from_timer(ep, t, timer);\n\tint kickit = 0;\n\n\tspin_lock(&timeout_lock);\n\tif (!test_and_set_bit(TIMEOUT, &ep->com.flags)) {\n\t\t \n\t\tif (!ep->entry.next) {\n\t\t\tlist_add_tail(&ep->entry, &timeout_list);\n\t\t\tkickit = 1;\n\t\t}\n\t}\n\tspin_unlock(&timeout_lock);\n\tif (kickit)\n\t\tqueue_work(workq, &skb_work);\n}\n\n \nstatic int sched(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\n\t \n\t*((struct c4iw_dev **) (skb->cb + sizeof(void *))) = dev;\n\n\t \n\tskb_queue_tail(&rxq, skb);\n\tqueue_work(workq, &skb_work);\n\treturn 0;\n}\n\nstatic int set_tcb_rpl(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_set_tcb_rpl *rpl = cplhdr(skb);\n\n\tif (rpl->status != CPL_ERR_NONE) {\n\t\tpr_err(\"Unexpected SET_TCB_RPL status %u for tid %u\\n\",\n\t\t       rpl->status, GET_TID(rpl));\n\t}\n\tkfree_skb(skb);\n\treturn 0;\n}\n\nstatic int fw6_msg(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_fw6_msg *rpl = cplhdr(skb);\n\tstruct c4iw_wr_wait *wr_waitp;\n\tint ret;\n\n\tpr_debug(\"type %u\\n\", rpl->type);\n\n\tswitch (rpl->type) {\n\tcase FW6_TYPE_WR_RPL:\n\t\tret = (int)((be64_to_cpu(rpl->data[0]) >> 8) & 0xff);\n\t\twr_waitp = (struct c4iw_wr_wait *)(__force unsigned long) rpl->data[1];\n\t\tpr_debug(\"wr_waitp %p ret %u\\n\", wr_waitp, ret);\n\t\tif (wr_waitp)\n\t\t\tc4iw_wake_up_deref(wr_waitp, ret ? -ret : 0);\n\t\tkfree_skb(skb);\n\t\tbreak;\n\tcase FW6_TYPE_CQE:\n\tcase FW6_TYPE_OFLD_CONNECTION_WR_RPL:\n\t\tsched(dev, skb);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s unexpected fw6 msg type %u\\n\",\n\t\t       __func__, rpl->type);\n\t\tkfree_skb(skb);\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int peer_abort_intr(struct c4iw_dev *dev, struct sk_buff *skb)\n{\n\tstruct cpl_abort_req_rss *req = cplhdr(skb);\n\tstruct c4iw_ep *ep;\n\tunsigned int tid = GET_TID(req);\n\n\tep = get_ep_from_tid(dev, tid);\n\t \n\tif (!ep) {\n\t\tpr_warn(\"Abort on non-existent endpoint, tid %d\\n\", tid);\n\t\tkfree_skb(skb);\n\t\treturn 0;\n\t}\n\tif (cxgb_is_neg_adv(req->status)) {\n\t\tpr_debug(\"Negative advice on abort- tid %u status %d (%s)\\n\",\n\t\t\t ep->hwtid, req->status,\n\t\t\t neg_adv_str(req->status));\n\t\tgoto out;\n\t}\n\tpr_debug(\"ep %p tid %u state %u\\n\", ep, ep->hwtid, ep->com.state);\n\n\tc4iw_wake_up_noref(ep->com.wr_waitp, -ECONNRESET);\nout:\n\tsched(dev, skb);\n\treturn 0;\n}\n\n \nc4iw_handler_func c4iw_handlers[NUM_CPL_CMDS] = {\n\t[CPL_ACT_ESTABLISH] = sched,\n\t[CPL_ACT_OPEN_RPL] = sched,\n\t[CPL_RX_DATA] = sched,\n\t[CPL_ABORT_RPL_RSS] = sched,\n\t[CPL_ABORT_RPL] = sched,\n\t[CPL_PASS_OPEN_RPL] = sched,\n\t[CPL_CLOSE_LISTSRV_RPL] = sched,\n\t[CPL_PASS_ACCEPT_REQ] = sched,\n\t[CPL_PASS_ESTABLISH] = sched,\n\t[CPL_PEER_CLOSE] = sched,\n\t[CPL_CLOSE_CON_RPL] = sched,\n\t[CPL_ABORT_REQ_RSS] = peer_abort_intr,\n\t[CPL_RDMA_TERMINATE] = sched,\n\t[CPL_FW4_ACK] = sched,\n\t[CPL_SET_TCB_RPL] = set_tcb_rpl,\n\t[CPL_GET_TCB_RPL] = sched,\n\t[CPL_FW6_MSG] = fw6_msg,\n\t[CPL_RX_PKT] = sched\n};\n\nint __init c4iw_cm_init(void)\n{\n\tskb_queue_head_init(&rxq);\n\n\tworkq = alloc_ordered_workqueue(\"iw_cxgb4\", WQ_MEM_RECLAIM);\n\tif (!workq)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nvoid c4iw_cm_term(void)\n{\n\tWARN_ON(!list_empty(&timeout_list));\n\tdestroy_workqueue(workq);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}