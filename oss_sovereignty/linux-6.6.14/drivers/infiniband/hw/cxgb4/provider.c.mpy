{
  "module_name": "provider.c",
  "hash_id": "d73ec872558f77b00e5df23d6eea31d55db747ac3195a31f2a3c9dce7089d974",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/cxgb4/provider.c",
  "human_readable_source": " \n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/device.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/delay.h>\n#include <linux/errno.h>\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/ethtool.h>\n#include <linux/rtnetlink.h>\n#include <linux/inetdevice.h>\n#include <net/addrconf.h>\n#include <linux/io.h>\n\n#include <asm/irq.h>\n#include <asm/byteorder.h>\n\n#include <rdma/iw_cm.h>\n#include <rdma/ib_verbs.h>\n#include <rdma/ib_smi.h>\n#include <rdma/ib_umem.h>\n#include <rdma/ib_user_verbs.h>\n\n#include \"iw_cxgb4.h\"\n\nstatic int fastreg_support = 1;\nmodule_param(fastreg_support, int, 0644);\nMODULE_PARM_DESC(fastreg_support, \"Advertise fastreg support (default=1)\");\n\nstatic void c4iw_dealloc_ucontext(struct ib_ucontext *context)\n{\n\tstruct c4iw_ucontext *ucontext = to_c4iw_ucontext(context);\n\tstruct c4iw_dev *rhp;\n\tstruct c4iw_mm_entry *mm, *tmp;\n\n\tpr_debug(\"context %p\\n\", context);\n\trhp = to_c4iw_dev(ucontext->ibucontext.device);\n\n\tlist_for_each_entry_safe(mm, tmp, &ucontext->mmaps, entry)\n\t\tkfree(mm);\n\tc4iw_release_dev_ucontext(&rhp->rdev, &ucontext->uctx);\n}\n\nstatic int c4iw_alloc_ucontext(struct ib_ucontext *ucontext,\n\t\t\t       struct ib_udata *udata)\n{\n\tstruct ib_device *ibdev = ucontext->device;\n\tstruct c4iw_ucontext *context = to_c4iw_ucontext(ucontext);\n\tstruct c4iw_dev *rhp = to_c4iw_dev(ibdev);\n\tstruct c4iw_alloc_ucontext_resp uresp;\n\tint ret = 0;\n\tstruct c4iw_mm_entry *mm = NULL;\n\n\tpr_debug(\"ibdev %p\\n\", ibdev);\n\tc4iw_init_dev_ucontext(&rhp->rdev, &context->uctx);\n\tINIT_LIST_HEAD(&context->mmaps);\n\tspin_lock_init(&context->mmap_lock);\n\n\tif (udata->outlen < sizeof(uresp) - sizeof(uresp.reserved)) {\n\t\tpr_err_once(\"Warning - downlevel libcxgb4 (non-fatal), device status page disabled\\n\");\n\t\trhp->rdev.flags |= T4_STATUS_PAGE_DISABLED;\n\t} else {\n\t\tmm = kmalloc(sizeof(*mm), GFP_KERNEL);\n\t\tif (!mm) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\turesp.status_page_size = PAGE_SIZE;\n\n\t\tspin_lock(&context->mmap_lock);\n\t\turesp.status_page_key = context->key;\n\t\tcontext->key += PAGE_SIZE;\n\t\tspin_unlock(&context->mmap_lock);\n\n\t\tret = ib_copy_to_udata(udata, &uresp,\n\t\t\t\t       sizeof(uresp) - sizeof(uresp.reserved));\n\t\tif (ret)\n\t\t\tgoto err_mm;\n\n\t\tmm->key = uresp.status_page_key;\n\t\tmm->addr = virt_to_phys(rhp->rdev.status_page);\n\t\tmm->len = PAGE_SIZE;\n\t\tinsert_mmap(context, mm);\n\t}\n\treturn 0;\nerr_mm:\n\tkfree(mm);\nerr:\n\treturn ret;\n}\n\nstatic int c4iw_mmap(struct ib_ucontext *context, struct vm_area_struct *vma)\n{\n\tint len = vma->vm_end - vma->vm_start;\n\tu32 key = vma->vm_pgoff << PAGE_SHIFT;\n\tstruct c4iw_rdev *rdev;\n\tint ret = 0;\n\tstruct c4iw_mm_entry *mm;\n\tstruct c4iw_ucontext *ucontext;\n\tu64 addr;\n\n\tpr_debug(\"pgoff 0x%lx key 0x%x len %d\\n\", vma->vm_pgoff,\n\t\t key, len);\n\n\tif (vma->vm_start & (PAGE_SIZE-1))\n\t\treturn -EINVAL;\n\n\trdev = &(to_c4iw_dev(context->device)->rdev);\n\tucontext = to_c4iw_ucontext(context);\n\n\tmm = remove_mmap(ucontext, key, len);\n\tif (!mm)\n\t\treturn -EINVAL;\n\taddr = mm->addr;\n\tkfree(mm);\n\n\tif ((addr >= pci_resource_start(rdev->lldi.pdev, 0)) &&\n\t    (addr < (pci_resource_start(rdev->lldi.pdev, 0) +\n\t\t    pci_resource_len(rdev->lldi.pdev, 0)))) {\n\n\t\t \n\t\tvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\n\t\tret = io_remap_pfn_range(vma, vma->vm_start,\n\t\t\t\t\t addr >> PAGE_SHIFT,\n\t\t\t\t\t len, vma->vm_page_prot);\n\t} else if ((addr >= pci_resource_start(rdev->lldi.pdev, 2)) &&\n\t\t   (addr < (pci_resource_start(rdev->lldi.pdev, 2) +\n\t\t    pci_resource_len(rdev->lldi.pdev, 2)))) {\n\n\t\t \n\t\tif (addr >= rdev->oc_mw_pa)\n\t\t\tvma->vm_page_prot = t4_pgprot_wc(vma->vm_page_prot);\n\t\telse {\n\t\t\tif (!is_t4(rdev->lldi.adapter_type))\n\t\t\t\tvma->vm_page_prot =\n\t\t\t\t\tt4_pgprot_wc(vma->vm_page_prot);\n\t\t\telse\n\t\t\t\tvma->vm_page_prot =\n\t\t\t\t\tpgprot_noncached(vma->vm_page_prot);\n\t\t}\n\t\tret = io_remap_pfn_range(vma, vma->vm_start,\n\t\t\t\t\t addr >> PAGE_SHIFT,\n\t\t\t\t\t len, vma->vm_page_prot);\n\t} else {\n\n\t\t \n\t\tret = remap_pfn_range(vma, vma->vm_start,\n\t\t\t\t      addr >> PAGE_SHIFT,\n\t\t\t\t      len, vma->vm_page_prot);\n\t}\n\n\treturn ret;\n}\n\nstatic int c4iw_deallocate_pd(struct ib_pd *pd, struct ib_udata *udata)\n{\n\tstruct c4iw_dev *rhp;\n\tstruct c4iw_pd *php;\n\n\tphp = to_c4iw_pd(pd);\n\trhp = php->rhp;\n\tpr_debug(\"ibpd %p pdid 0x%x\\n\", pd, php->pdid);\n\tc4iw_put_resource(&rhp->rdev.resource.pdid_table, php->pdid);\n\tmutex_lock(&rhp->rdev.stats.lock);\n\trhp->rdev.stats.pd.cur--;\n\tmutex_unlock(&rhp->rdev.stats.lock);\n\treturn 0;\n}\n\nstatic int c4iw_allocate_pd(struct ib_pd *pd, struct ib_udata *udata)\n{\n\tstruct c4iw_pd *php = to_c4iw_pd(pd);\n\tstruct ib_device *ibdev = pd->device;\n\tu32 pdid;\n\tstruct c4iw_dev *rhp;\n\n\tpr_debug(\"ibdev %p\\n\", ibdev);\n\trhp = (struct c4iw_dev *) ibdev;\n\tpdid =  c4iw_get_resource(&rhp->rdev.resource.pdid_table);\n\tif (!pdid)\n\t\treturn -EINVAL;\n\n\tphp->pdid = pdid;\n\tphp->rhp = rhp;\n\tif (udata) {\n\t\tstruct c4iw_alloc_pd_resp uresp = {.pdid = php->pdid};\n\n\t\tif (ib_copy_to_udata(udata, &uresp, sizeof(uresp))) {\n\t\t\tc4iw_deallocate_pd(&php->ibpd, udata);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\tmutex_lock(&rhp->rdev.stats.lock);\n\trhp->rdev.stats.pd.cur++;\n\tif (rhp->rdev.stats.pd.cur > rhp->rdev.stats.pd.max)\n\t\trhp->rdev.stats.pd.max = rhp->rdev.stats.pd.cur;\n\tmutex_unlock(&rhp->rdev.stats.lock);\n\tpr_debug(\"pdid 0x%0x ptr 0x%p\\n\", pdid, php);\n\treturn 0;\n}\n\nstatic int c4iw_query_gid(struct ib_device *ibdev, u32 port, int index,\n\t\t\t  union ib_gid *gid)\n{\n\tstruct c4iw_dev *dev;\n\n\tpr_debug(\"ibdev %p, port %u, index %d, gid %p\\n\",\n\t\t ibdev, port, index, gid);\n\tif (!port)\n\t\treturn -EINVAL;\n\tdev = to_c4iw_dev(ibdev);\n\tmemset(&(gid->raw[0]), 0, sizeof(gid->raw));\n\tmemcpy(&(gid->raw[0]), dev->rdev.lldi.ports[port-1]->dev_addr, 6);\n\treturn 0;\n}\n\nstatic int c4iw_query_device(struct ib_device *ibdev, struct ib_device_attr *props,\n\t\t\t     struct ib_udata *uhw)\n{\n\n\tstruct c4iw_dev *dev;\n\n\tpr_debug(\"ibdev %p\\n\", ibdev);\n\n\tif (uhw->inlen || uhw->outlen)\n\t\treturn -EINVAL;\n\n\tdev = to_c4iw_dev(ibdev);\n\taddrconf_addr_eui48((u8 *)&props->sys_image_guid,\n\t\t\t    dev->rdev.lldi.ports[0]->dev_addr);\n\tprops->hw_ver = CHELSIO_CHIP_RELEASE(dev->rdev.lldi.adapter_type);\n\tprops->fw_ver = dev->rdev.lldi.fw_vers;\n\tprops->device_cap_flags = IB_DEVICE_MEM_WINDOW;\n\tprops->kernel_cap_flags = IBK_LOCAL_DMA_LKEY;\n\tif (fastreg_support)\n\t\tprops->device_cap_flags |= IB_DEVICE_MEM_MGT_EXTENSIONS;\n\tprops->page_size_cap = T4_PAGESIZE_MASK;\n\tprops->vendor_id = (u32)dev->rdev.lldi.pdev->vendor;\n\tprops->vendor_part_id = (u32)dev->rdev.lldi.pdev->device;\n\tprops->max_mr_size = T4_MAX_MR_SIZE;\n\tprops->max_qp = dev->rdev.lldi.vr->qp.size / 2;\n\tprops->max_srq = dev->rdev.lldi.vr->srq.size;\n\tprops->max_qp_wr = dev->rdev.hw_queue.t4_max_qp_depth;\n\tprops->max_srq_wr = dev->rdev.hw_queue.t4_max_qp_depth;\n\tprops->max_send_sge = min(T4_MAX_SEND_SGE, T4_MAX_WRITE_SGE);\n\tprops->max_recv_sge = T4_MAX_RECV_SGE;\n\tprops->max_srq_sge = T4_MAX_RECV_SGE;\n\tprops->max_sge_rd = 1;\n\tprops->max_res_rd_atom = dev->rdev.lldi.max_ird_adapter;\n\tprops->max_qp_rd_atom = min(dev->rdev.lldi.max_ordird_qp,\n\t\t\t\t    c4iw_max_read_depth);\n\tprops->max_qp_init_rd_atom = props->max_qp_rd_atom;\n\tprops->max_cq = dev->rdev.lldi.vr->qp.size;\n\tprops->max_cqe = dev->rdev.hw_queue.t4_max_cq_depth;\n\tprops->max_mr = c4iw_num_stags(&dev->rdev);\n\tprops->max_pd = T4_MAX_NUM_PD;\n\tprops->local_ca_ack_delay = 0;\n\tprops->max_fast_reg_page_list_len =\n\t\tt4_max_fr_depth(dev->rdev.lldi.ulptx_memwrite_dsgl && use_dsgl);\n\n\treturn 0;\n}\n\nstatic int c4iw_query_port(struct ib_device *ibdev, u32 port,\n\t\t\t   struct ib_port_attr *props)\n{\n\tint ret = 0;\n\tpr_debug(\"ibdev %p\\n\", ibdev);\n\tret = ib_get_eth_speed(ibdev, port, &props->active_speed,\n\t\t\t       &props->active_width);\n\n\tprops->port_cap_flags =\n\t    IB_PORT_CM_SUP |\n\t    IB_PORT_SNMP_TUNNEL_SUP |\n\t    IB_PORT_REINIT_SUP |\n\t    IB_PORT_DEVICE_MGMT_SUP |\n\t    IB_PORT_VENDOR_CLASS_SUP | IB_PORT_BOOT_MGMT_SUP;\n\tprops->gid_tbl_len = 1;\n\tprops->max_msg_sz = -1;\n\n\treturn ret;\n}\n\nstatic ssize_t hw_rev_show(struct device *dev,\n\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct c4iw_dev *c4iw_dev =\n\t\t\trdma_device_to_drv_device(dev, struct c4iw_dev, ibdev);\n\n\tpr_debug(\"dev 0x%p\\n\", dev);\n\treturn sysfs_emit(\n\t\tbuf, \"%d\\n\",\n\t\tCHELSIO_CHIP_RELEASE(c4iw_dev->rdev.lldi.adapter_type));\n}\nstatic DEVICE_ATTR_RO(hw_rev);\n\nstatic ssize_t hca_type_show(struct device *dev,\n\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct c4iw_dev *c4iw_dev =\n\t\t\trdma_device_to_drv_device(dev, struct c4iw_dev, ibdev);\n\tstruct ethtool_drvinfo info;\n\tstruct net_device *lldev = c4iw_dev->rdev.lldi.ports[0];\n\n\tpr_debug(\"dev 0x%p\\n\", dev);\n\tlldev->ethtool_ops->get_drvinfo(lldev, &info);\n\treturn sysfs_emit(buf, \"%s\\n\", info.driver);\n}\nstatic DEVICE_ATTR_RO(hca_type);\n\nstatic ssize_t board_id_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct c4iw_dev *c4iw_dev =\n\t\t\trdma_device_to_drv_device(dev, struct c4iw_dev, ibdev);\n\n\tpr_debug(\"dev 0x%p\\n\", dev);\n\treturn sysfs_emit(buf, \"%x.%x\\n\", c4iw_dev->rdev.lldi.pdev->vendor,\n\t\t\t  c4iw_dev->rdev.lldi.pdev->device);\n}\nstatic DEVICE_ATTR_RO(board_id);\n\nenum counters {\n\tIP4INSEGS,\n\tIP4OUTSEGS,\n\tIP4RETRANSSEGS,\n\tIP4OUTRSTS,\n\tIP6INSEGS,\n\tIP6OUTSEGS,\n\tIP6RETRANSSEGS,\n\tIP6OUTRSTS,\n\tNR_COUNTERS\n};\n\nstatic const struct rdma_stat_desc cxgb4_descs[] = {\n\t[IP4INSEGS].name = \"ip4InSegs\",\n\t[IP4OUTSEGS].name = \"ip4OutSegs\",\n\t[IP4RETRANSSEGS].name = \"ip4RetransSegs\",\n\t[IP4OUTRSTS].name = \"ip4OutRsts\",\n\t[IP6INSEGS].name = \"ip6InSegs\",\n\t[IP6OUTSEGS].name = \"ip6OutSegs\",\n\t[IP6RETRANSSEGS].name = \"ip6RetransSegs\",\n\t[IP6OUTRSTS].name = \"ip6OutRsts\"\n};\n\nstatic struct rdma_hw_stats *c4iw_alloc_device_stats(struct ib_device *ibdev)\n{\n\tBUILD_BUG_ON(ARRAY_SIZE(cxgb4_descs) != NR_COUNTERS);\n\n\t \n\treturn rdma_alloc_hw_stats_struct(cxgb4_descs, NR_COUNTERS,\n\t\t\t\t\t  RDMA_HW_STATS_DEFAULT_LIFESPAN);\n}\n\nstatic int c4iw_get_mib(struct ib_device *ibdev,\n\t\t\tstruct rdma_hw_stats *stats,\n\t\t\tu32 port, int index)\n{\n\tstruct tp_tcp_stats v4, v6;\n\tstruct c4iw_dev *c4iw_dev = to_c4iw_dev(ibdev);\n\n\tcxgb4_get_tcp_stats(c4iw_dev->rdev.lldi.pdev, &v4, &v6);\n\tstats->value[IP4INSEGS] = v4.tcp_in_segs;\n\tstats->value[IP4OUTSEGS] = v4.tcp_out_segs;\n\tstats->value[IP4RETRANSSEGS] = v4.tcp_retrans_segs;\n\tstats->value[IP4OUTRSTS] = v4.tcp_out_rsts;\n\tstats->value[IP6INSEGS] = v6.tcp_in_segs;\n\tstats->value[IP6OUTSEGS] = v6.tcp_out_segs;\n\tstats->value[IP6RETRANSSEGS] = v6.tcp_retrans_segs;\n\tstats->value[IP6OUTRSTS] = v6.tcp_out_rsts;\n\n\treturn stats->num_counters;\n}\n\nstatic struct attribute *c4iw_class_attributes[] = {\n\t&dev_attr_hw_rev.attr,\n\t&dev_attr_hca_type.attr,\n\t&dev_attr_board_id.attr,\n\tNULL\n};\n\nstatic const struct attribute_group c4iw_attr_group = {\n\t.attrs = c4iw_class_attributes,\n};\n\nstatic int c4iw_port_immutable(struct ib_device *ibdev, u32 port_num,\n\t\t\t       struct ib_port_immutable *immutable)\n{\n\tstruct ib_port_attr attr;\n\tint err;\n\n\timmutable->core_cap_flags = RDMA_CORE_PORT_IWARP;\n\n\terr = ib_query_port(ibdev, port_num, &attr);\n\tif (err)\n\t\treturn err;\n\n\timmutable->gid_tbl_len = attr.gid_tbl_len;\n\n\treturn 0;\n}\n\nstatic void get_dev_fw_str(struct ib_device *dev, char *str)\n{\n\tstruct c4iw_dev *c4iw_dev = container_of(dev, struct c4iw_dev,\n\t\t\t\t\t\t ibdev);\n\tpr_debug(\"dev 0x%p\\n\", dev);\n\n\tsnprintf(str, IB_FW_VERSION_NAME_MAX, \"%u.%u.%u.%u\",\n\t\t FW_HDR_FW_VER_MAJOR_G(c4iw_dev->rdev.lldi.fw_vers),\n\t\t FW_HDR_FW_VER_MINOR_G(c4iw_dev->rdev.lldi.fw_vers),\n\t\t FW_HDR_FW_VER_MICRO_G(c4iw_dev->rdev.lldi.fw_vers),\n\t\t FW_HDR_FW_VER_BUILD_G(c4iw_dev->rdev.lldi.fw_vers));\n}\n\nstatic const struct ib_device_ops c4iw_dev_ops = {\n\t.owner = THIS_MODULE,\n\t.driver_id = RDMA_DRIVER_CXGB4,\n\t.uverbs_abi_ver = C4IW_UVERBS_ABI_VERSION,\n\n\t.alloc_hw_device_stats = c4iw_alloc_device_stats,\n\t.alloc_mr = c4iw_alloc_mr,\n\t.alloc_pd = c4iw_allocate_pd,\n\t.alloc_ucontext = c4iw_alloc_ucontext,\n\t.create_cq = c4iw_create_cq,\n\t.create_qp = c4iw_create_qp,\n\t.create_srq = c4iw_create_srq,\n\t.dealloc_pd = c4iw_deallocate_pd,\n\t.dealloc_ucontext = c4iw_dealloc_ucontext,\n\t.dereg_mr = c4iw_dereg_mr,\n\t.destroy_cq = c4iw_destroy_cq,\n\t.destroy_qp = c4iw_destroy_qp,\n\t.destroy_srq = c4iw_destroy_srq,\n\t.device_group = &c4iw_attr_group,\n\t.fill_res_cq_entry = c4iw_fill_res_cq_entry,\n\t.fill_res_cm_id_entry = c4iw_fill_res_cm_id_entry,\n\t.fill_res_mr_entry = c4iw_fill_res_mr_entry,\n\t.get_dev_fw_str = get_dev_fw_str,\n\t.get_dma_mr = c4iw_get_dma_mr,\n\t.get_hw_stats = c4iw_get_mib,\n\t.get_port_immutable = c4iw_port_immutable,\n\t.iw_accept = c4iw_accept_cr,\n\t.iw_add_ref = c4iw_qp_add_ref,\n\t.iw_connect = c4iw_connect,\n\t.iw_create_listen = c4iw_create_listen,\n\t.iw_destroy_listen = c4iw_destroy_listen,\n\t.iw_get_qp = c4iw_get_qp,\n\t.iw_reject = c4iw_reject_cr,\n\t.iw_rem_ref = c4iw_qp_rem_ref,\n\t.map_mr_sg = c4iw_map_mr_sg,\n\t.mmap = c4iw_mmap,\n\t.modify_qp = c4iw_ib_modify_qp,\n\t.modify_srq = c4iw_modify_srq,\n\t.poll_cq = c4iw_poll_cq,\n\t.post_recv = c4iw_post_receive,\n\t.post_send = c4iw_post_send,\n\t.post_srq_recv = c4iw_post_srq_recv,\n\t.query_device = c4iw_query_device,\n\t.query_gid = c4iw_query_gid,\n\t.query_port = c4iw_query_port,\n\t.query_qp = c4iw_ib_query_qp,\n\t.reg_user_mr = c4iw_reg_user_mr,\n\t.req_notify_cq = c4iw_arm_cq,\n\n\tINIT_RDMA_OBJ_SIZE(ib_cq, c4iw_cq, ibcq),\n\tINIT_RDMA_OBJ_SIZE(ib_mw, c4iw_mw, ibmw),\n\tINIT_RDMA_OBJ_SIZE(ib_pd, c4iw_pd, ibpd),\n\tINIT_RDMA_OBJ_SIZE(ib_qp, c4iw_qp, ibqp),\n\tINIT_RDMA_OBJ_SIZE(ib_srq, c4iw_srq, ibsrq),\n\tINIT_RDMA_OBJ_SIZE(ib_ucontext, c4iw_ucontext, ibucontext),\n};\n\nstatic int set_netdevs(struct ib_device *ib_dev, struct c4iw_rdev *rdev)\n{\n\tint ret;\n\tint i;\n\n\tfor (i = 0; i < rdev->lldi.nports; i++) {\n\t\tret = ib_device_set_netdev(ib_dev, rdev->lldi.ports[i],\n\t\t\t\t\t   i + 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nvoid c4iw_register_device(struct work_struct *work)\n{\n\tint ret;\n\tstruct uld_ctx *ctx = container_of(work, struct uld_ctx, reg_work);\n\tstruct c4iw_dev *dev = ctx->dev;\n\n\tpr_debug(\"c4iw_dev %p\\n\", dev);\n\taddrconf_addr_eui48((u8 *)&dev->ibdev.node_guid,\n\t\t\t    dev->rdev.lldi.ports[0]->dev_addr);\n\tdev->ibdev.local_dma_lkey = 0;\n\tdev->ibdev.node_type = RDMA_NODE_RNIC;\n\tBUILD_BUG_ON(sizeof(C4IW_NODE_DESC) > IB_DEVICE_NODE_DESC_MAX);\n\tmemcpy(dev->ibdev.node_desc, C4IW_NODE_DESC, sizeof(C4IW_NODE_DESC));\n\tdev->ibdev.phys_port_cnt = dev->rdev.lldi.nports;\n\tdev->ibdev.num_comp_vectors =  dev->rdev.lldi.nciq;\n\tdev->ibdev.dev.parent = &dev->rdev.lldi.pdev->dev;\n\n\tmemcpy(dev->ibdev.iw_ifname, dev->rdev.lldi.ports[0]->name,\n\t       sizeof(dev->ibdev.iw_ifname));\n\n\tib_set_device_ops(&dev->ibdev, &c4iw_dev_ops);\n\tret = set_netdevs(&dev->ibdev, &dev->rdev);\n\tif (ret)\n\t\tgoto err_dealloc_ctx;\n\tdma_set_max_seg_size(&dev->rdev.lldi.pdev->dev, UINT_MAX);\n\tret = ib_register_device(&dev->ibdev, \"cxgb4_%d\",\n\t\t\t\t &dev->rdev.lldi.pdev->dev);\n\tif (ret)\n\t\tgoto err_dealloc_ctx;\n\treturn;\n\nerr_dealloc_ctx:\n\tpr_err(\"%s - Failed registering iwarp device: %d\\n\",\n\t       pci_name(ctx->lldi.pdev), ret);\n\tc4iw_dealloc(ctx);\n\treturn;\n}\n\nvoid c4iw_unregister_device(struct c4iw_dev *dev)\n{\n\tpr_debug(\"c4iw_dev %p\\n\", dev);\n\tib_unregister_device(&dev->ibdev);\n\treturn;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}