{
  "module_name": "device.c",
  "hash_id": "26e99e9f5e4ec740ac937ac85afb01f50fb8c5cff615ce426e0b900f19a8b05a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/cxgb4/device.c",
  "human_readable_source": " \n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/debugfs.h>\n#include <linux/vmalloc.h>\n#include <linux/math64.h>\n\n#include <rdma/ib_verbs.h>\n\n#include \"iw_cxgb4.h\"\n\n#define DRV_VERSION \"0.1\"\n\nMODULE_AUTHOR(\"Steve Wise\");\nMODULE_DESCRIPTION(\"Chelsio T4/T5 RDMA Driver\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n\nstatic int allow_db_fc_on_t5;\nmodule_param(allow_db_fc_on_t5, int, 0644);\nMODULE_PARM_DESC(allow_db_fc_on_t5,\n\t\t \"Allow DB Flow Control on T5 (default = 0)\");\n\nstatic int allow_db_coalescing_on_t5;\nmodule_param(allow_db_coalescing_on_t5, int, 0644);\nMODULE_PARM_DESC(allow_db_coalescing_on_t5,\n\t\t \"Allow DB Coalescing on T5 (default = 0)\");\n\nint c4iw_wr_log = 0;\nmodule_param(c4iw_wr_log, int, 0444);\nMODULE_PARM_DESC(c4iw_wr_log, \"Enables logging of work request timing data.\");\n\nstatic int c4iw_wr_log_size_order = 12;\nmodule_param(c4iw_wr_log_size_order, int, 0444);\nMODULE_PARM_DESC(c4iw_wr_log_size_order,\n\t\t \"Number of entries (log2) in the work request timing log.\");\n\nstatic LIST_HEAD(uld_ctx_list);\nstatic DEFINE_MUTEX(dev_mutex);\nstatic struct workqueue_struct *reg_workq;\n\n#define DB_FC_RESUME_SIZE 64\n#define DB_FC_RESUME_DELAY 1\n#define DB_FC_DRAIN_THRESH 0\n\nstatic struct dentry *c4iw_debugfs_root;\n\nstruct c4iw_debugfs_data {\n\tstruct c4iw_dev *devp;\n\tchar *buf;\n\tint bufsize;\n\tint pos;\n};\n\nstatic ssize_t debugfs_read(struct file *file, char __user *buf, size_t count,\n\t\t\t    loff_t *ppos)\n{\n\tstruct c4iw_debugfs_data *d = file->private_data;\n\n\treturn simple_read_from_buffer(buf, count, ppos, d->buf, d->pos);\n}\n\nvoid c4iw_log_wr_stats(struct t4_wq *wq, struct t4_cqe *cqe)\n{\n\tstruct wr_log_entry le;\n\tint idx;\n\n\tif (!wq->rdev->wr_log)\n\t\treturn;\n\n\tidx = (atomic_inc_return(&wq->rdev->wr_log_idx) - 1) &\n\t\t(wq->rdev->wr_log_size - 1);\n\tle.poll_sge_ts = cxgb4_read_sge_timestamp(wq->rdev->lldi.ports[0]);\n\tle.poll_host_time = ktime_get();\n\tle.valid = 1;\n\tle.cqe_sge_ts = CQE_TS(cqe);\n\tif (SQ_TYPE(cqe)) {\n\t\tle.qid = wq->sq.qid;\n\t\tle.opcode = CQE_OPCODE(cqe);\n\t\tle.post_host_time = wq->sq.sw_sq[wq->sq.cidx].host_time;\n\t\tle.post_sge_ts = wq->sq.sw_sq[wq->sq.cidx].sge_ts;\n\t\tle.wr_id = CQE_WRID_SQ_IDX(cqe);\n\t} else {\n\t\tle.qid = wq->rq.qid;\n\t\tle.opcode = FW_RI_RECEIVE;\n\t\tle.post_host_time = wq->rq.sw_rq[wq->rq.cidx].host_time;\n\t\tle.post_sge_ts = wq->rq.sw_rq[wq->rq.cidx].sge_ts;\n\t\tle.wr_id = CQE_WRID_MSN(cqe);\n\t}\n\twq->rdev->wr_log[idx] = le;\n}\n\nstatic int wr_log_show(struct seq_file *seq, void *v)\n{\n\tstruct c4iw_dev *dev = seq->private;\n\tktime_t prev_time;\n\tstruct wr_log_entry *lep;\n\tint prev_time_set = 0;\n\tint idx, end;\n\n#define ts2ns(ts) div64_u64((ts) * dev->rdev.lldi.cclk_ps, 1000)\n\n\tidx = atomic_read(&dev->rdev.wr_log_idx) &\n\t\t(dev->rdev.wr_log_size - 1);\n\tend = idx - 1;\n\tif (end < 0)\n\t\tend = dev->rdev.wr_log_size - 1;\n\tlep = &dev->rdev.wr_log[idx];\n\twhile (idx != end) {\n\t\tif (lep->valid) {\n\t\t\tif (!prev_time_set) {\n\t\t\t\tprev_time_set = 1;\n\t\t\t\tprev_time = lep->poll_host_time;\n\t\t\t}\n\t\t\tseq_printf(seq, \"%04u: nsec %llu qid %u opcode \"\n\t\t\t\t   \"%u %s 0x%x host_wr_delta nsec %llu \"\n\t\t\t\t   \"post_sge_ts 0x%llx cqe_sge_ts 0x%llx \"\n\t\t\t\t   \"poll_sge_ts 0x%llx post_poll_delta_ns %llu \"\n\t\t\t\t   \"cqe_poll_delta_ns %llu\\n\",\n\t\t\t\t   idx,\n\t\t\t\t   ktime_to_ns(ktime_sub(lep->poll_host_time,\n\t\t\t\t\t\t\t prev_time)),\n\t\t\t\t   lep->qid, lep->opcode,\n\t\t\t\t   lep->opcode == FW_RI_RECEIVE ?\n\t\t\t\t\t\t\t\"msn\" : \"wrid\",\n\t\t\t\t   lep->wr_id,\n\t\t\t\t   ktime_to_ns(ktime_sub(lep->poll_host_time,\n\t\t\t\t\t\t\t lep->post_host_time)),\n\t\t\t\t   lep->post_sge_ts, lep->cqe_sge_ts,\n\t\t\t\t   lep->poll_sge_ts,\n\t\t\t\t   ts2ns(lep->poll_sge_ts - lep->post_sge_ts),\n\t\t\t\t   ts2ns(lep->poll_sge_ts - lep->cqe_sge_ts));\n\t\t\tprev_time = lep->poll_host_time;\n\t\t}\n\t\tidx++;\n\t\tif (idx > (dev->rdev.wr_log_size - 1))\n\t\t\tidx = 0;\n\t\tlep = &dev->rdev.wr_log[idx];\n\t}\n#undef ts2ns\n\treturn 0;\n}\n\nstatic int wr_log_open(struct inode *inode, struct file *file)\n{\n\treturn single_open(file, wr_log_show, inode->i_private);\n}\n\nstatic ssize_t wr_log_clear(struct file *file, const char __user *buf,\n\t\t\t    size_t count, loff_t *pos)\n{\n\tstruct c4iw_dev *dev = ((struct seq_file *)file->private_data)->private;\n\tint i;\n\n\tif (dev->rdev.wr_log)\n\t\tfor (i = 0; i < dev->rdev.wr_log_size; i++)\n\t\t\tdev->rdev.wr_log[i].valid = 0;\n\treturn count;\n}\n\nstatic const struct file_operations wr_log_debugfs_fops = {\n\t.owner   = THIS_MODULE,\n\t.open    = wr_log_open,\n\t.release = single_release,\n\t.read    = seq_read,\n\t.llseek  = seq_lseek,\n\t.write   = wr_log_clear,\n};\n\nstatic struct sockaddr_in zero_sin = {\n\t.sin_family = AF_INET,\n};\n\nstatic struct sockaddr_in6 zero_sin6 = {\n\t.sin6_family = AF_INET6,\n};\n\nstatic void set_ep_sin_addrs(struct c4iw_ep *ep,\n\t\t\t     struct sockaddr_in **lsin,\n\t\t\t     struct sockaddr_in **rsin,\n\t\t\t     struct sockaddr_in **m_lsin,\n\t\t\t     struct sockaddr_in **m_rsin)\n{\n\tstruct iw_cm_id *id = ep->com.cm_id;\n\n\t*m_lsin = (struct sockaddr_in *)&ep->com.local_addr;\n\t*m_rsin = (struct sockaddr_in *)&ep->com.remote_addr;\n\tif (id) {\n\t\t*lsin = (struct sockaddr_in *)&id->local_addr;\n\t\t*rsin = (struct sockaddr_in *)&id->remote_addr;\n\t} else {\n\t\t*lsin = &zero_sin;\n\t\t*rsin = &zero_sin;\n\t}\n}\n\nstatic void set_ep_sin6_addrs(struct c4iw_ep *ep,\n\t\t\t      struct sockaddr_in6 **lsin6,\n\t\t\t      struct sockaddr_in6 **rsin6,\n\t\t\t      struct sockaddr_in6 **m_lsin6,\n\t\t\t      struct sockaddr_in6 **m_rsin6)\n{\n\tstruct iw_cm_id *id = ep->com.cm_id;\n\n\t*m_lsin6 = (struct sockaddr_in6 *)&ep->com.local_addr;\n\t*m_rsin6 = (struct sockaddr_in6 *)&ep->com.remote_addr;\n\tif (id) {\n\t\t*lsin6 = (struct sockaddr_in6 *)&id->local_addr;\n\t\t*rsin6 = (struct sockaddr_in6 *)&id->remote_addr;\n\t} else {\n\t\t*lsin6 = &zero_sin6;\n\t\t*rsin6 = &zero_sin6;\n\t}\n}\n\nstatic int dump_qp(unsigned long id, struct c4iw_qp *qp,\n\t\t   struct c4iw_debugfs_data *qpd)\n{\n\tint space;\n\tint cc;\n\tif (id != qp->wq.sq.qid)\n\t\treturn 0;\n\n\tspace = qpd->bufsize - qpd->pos - 1;\n\tif (space == 0)\n\t\treturn 1;\n\n\tif (qp->ep) {\n\t\tstruct c4iw_ep *ep = qp->ep;\n\n\t\tif (ep->com.local_addr.ss_family == AF_INET) {\n\t\t\tstruct sockaddr_in *lsin;\n\t\t\tstruct sockaddr_in *rsin;\n\t\t\tstruct sockaddr_in *m_lsin;\n\t\t\tstruct sockaddr_in *m_rsin;\n\n\t\t\tset_ep_sin_addrs(ep, &lsin, &rsin, &m_lsin, &m_rsin);\n\t\t\tcc = snprintf(qpd->buf + qpd->pos, space,\n\t\t\t\t      \"rc qp sq id %u %s id %u state %u \"\n\t\t\t\t      \"onchip %u ep tid %u state %u \"\n\t\t\t\t      \"%pI4:%u/%u->%pI4:%u/%u\\n\",\n\t\t\t\t      qp->wq.sq.qid, qp->srq ? \"srq\" : \"rq\",\n\t\t\t\t      qp->srq ? qp->srq->idx : qp->wq.rq.qid,\n\t\t\t\t      (int)qp->attr.state,\n\t\t\t\t      qp->wq.sq.flags & T4_SQ_ONCHIP,\n\t\t\t\t      ep->hwtid, (int)ep->com.state,\n\t\t\t\t      &lsin->sin_addr, ntohs(lsin->sin_port),\n\t\t\t\t      ntohs(m_lsin->sin_port),\n\t\t\t\t      &rsin->sin_addr, ntohs(rsin->sin_port),\n\t\t\t\t      ntohs(m_rsin->sin_port));\n\t\t} else {\n\t\t\tstruct sockaddr_in6 *lsin6;\n\t\t\tstruct sockaddr_in6 *rsin6;\n\t\t\tstruct sockaddr_in6 *m_lsin6;\n\t\t\tstruct sockaddr_in6 *m_rsin6;\n\n\t\t\tset_ep_sin6_addrs(ep, &lsin6, &rsin6, &m_lsin6,\n\t\t\t\t\t  &m_rsin6);\n\t\t\tcc = snprintf(qpd->buf + qpd->pos, space,\n\t\t\t\t      \"rc qp sq id %u rq id %u state %u \"\n\t\t\t\t      \"onchip %u ep tid %u state %u \"\n\t\t\t\t      \"%pI6:%u/%u->%pI6:%u/%u\\n\",\n\t\t\t\t      qp->wq.sq.qid, qp->wq.rq.qid,\n\t\t\t\t      (int)qp->attr.state,\n\t\t\t\t      qp->wq.sq.flags & T4_SQ_ONCHIP,\n\t\t\t\t      ep->hwtid, (int)ep->com.state,\n\t\t\t\t      &lsin6->sin6_addr,\n\t\t\t\t      ntohs(lsin6->sin6_port),\n\t\t\t\t      ntohs(m_lsin6->sin6_port),\n\t\t\t\t      &rsin6->sin6_addr,\n\t\t\t\t      ntohs(rsin6->sin6_port),\n\t\t\t\t      ntohs(m_rsin6->sin6_port));\n\t\t}\n\t} else\n\t\tcc = snprintf(qpd->buf + qpd->pos, space,\n\t\t\t     \"qp sq id %u rq id %u state %u onchip %u\\n\",\n\t\t\t      qp->wq.sq.qid, qp->wq.rq.qid,\n\t\t\t      (int)qp->attr.state,\n\t\t\t      qp->wq.sq.flags & T4_SQ_ONCHIP);\n\tif (cc < space)\n\t\tqpd->pos += cc;\n\treturn 0;\n}\n\nstatic int qp_release(struct inode *inode, struct file *file)\n{\n\tstruct c4iw_debugfs_data *qpd = file->private_data;\n\tif (!qpd) {\n\t\tpr_info(\"%s null qpd?\\n\", __func__);\n\t\treturn 0;\n\t}\n\tvfree(qpd->buf);\n\tkfree(qpd);\n\treturn 0;\n}\n\nstatic int qp_open(struct inode *inode, struct file *file)\n{\n\tstruct c4iw_qp *qp;\n\tstruct c4iw_debugfs_data *qpd;\n\tunsigned long index;\n\tint count = 1;\n\n\tqpd = kmalloc(sizeof(*qpd), GFP_KERNEL);\n\tif (!qpd)\n\t\treturn -ENOMEM;\n\n\tqpd->devp = inode->i_private;\n\tqpd->pos = 0;\n\n\t \n\txa_for_each(&qpd->devp->qps, index, qp)\n\t\tcount++;\n\n\tqpd->bufsize = count * 180;\n\tqpd->buf = vmalloc(qpd->bufsize);\n\tif (!qpd->buf) {\n\t\tkfree(qpd);\n\t\treturn -ENOMEM;\n\t}\n\n\txa_lock_irq(&qpd->devp->qps);\n\txa_for_each(&qpd->devp->qps, index, qp)\n\t\tdump_qp(index, qp, qpd);\n\txa_unlock_irq(&qpd->devp->qps);\n\n\tqpd->buf[qpd->pos++] = 0;\n\tfile->private_data = qpd;\n\treturn 0;\n}\n\nstatic const struct file_operations qp_debugfs_fops = {\n\t.owner   = THIS_MODULE,\n\t.open    = qp_open,\n\t.release = qp_release,\n\t.read    = debugfs_read,\n\t.llseek  = default_llseek,\n};\n\nstatic int dump_stag(unsigned long id, struct c4iw_debugfs_data *stagd)\n{\n\tint space;\n\tint cc;\n\tstruct fw_ri_tpte tpte;\n\tint ret;\n\n\tspace = stagd->bufsize - stagd->pos - 1;\n\tif (space == 0)\n\t\treturn 1;\n\n\tret = cxgb4_read_tpte(stagd->devp->rdev.lldi.ports[0], (u32)id<<8,\n\t\t\t      (__be32 *)&tpte);\n\tif (ret) {\n\t\tdev_err(&stagd->devp->rdev.lldi.pdev->dev,\n\t\t\t\"%s cxgb4_read_tpte err %d\\n\", __func__, ret);\n\t\treturn ret;\n\t}\n\tcc = snprintf(stagd->buf + stagd->pos, space,\n\t\t      \"stag: idx 0x%x valid %d key 0x%x state %d pdid %d \"\n\t\t      \"perm 0x%x ps %d len 0x%llx va 0x%llx\\n\",\n\t\t      (u32)id<<8,\n\t\t      FW_RI_TPTE_VALID_G(ntohl(tpte.valid_to_pdid)),\n\t\t      FW_RI_TPTE_STAGKEY_G(ntohl(tpte.valid_to_pdid)),\n\t\t      FW_RI_TPTE_STAGSTATE_G(ntohl(tpte.valid_to_pdid)),\n\t\t      FW_RI_TPTE_PDID_G(ntohl(tpte.valid_to_pdid)),\n\t\t      FW_RI_TPTE_PERM_G(ntohl(tpte.locread_to_qpid)),\n\t\t      FW_RI_TPTE_PS_G(ntohl(tpte.locread_to_qpid)),\n\t\t      ((u64)ntohl(tpte.len_hi) << 32) | ntohl(tpte.len_lo),\n\t\t      ((u64)ntohl(tpte.va_hi) << 32) | ntohl(tpte.va_lo_fbo));\n\tif (cc < space)\n\t\tstagd->pos += cc;\n\treturn 0;\n}\n\nstatic int stag_release(struct inode *inode, struct file *file)\n{\n\tstruct c4iw_debugfs_data *stagd = file->private_data;\n\tif (!stagd) {\n\t\tpr_info(\"%s null stagd?\\n\", __func__);\n\t\treturn 0;\n\t}\n\tvfree(stagd->buf);\n\tkfree(stagd);\n\treturn 0;\n}\n\nstatic int stag_open(struct inode *inode, struct file *file)\n{\n\tstruct c4iw_debugfs_data *stagd;\n\tvoid *p;\n\tunsigned long index;\n\tint ret = 0;\n\tint count = 1;\n\n\tstagd = kmalloc(sizeof(*stagd), GFP_KERNEL);\n\tif (!stagd) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tstagd->devp = inode->i_private;\n\tstagd->pos = 0;\n\n\txa_for_each(&stagd->devp->mrs, index, p)\n\t\tcount++;\n\n\tstagd->bufsize = count * 256;\n\tstagd->buf = vmalloc(stagd->bufsize);\n\tif (!stagd->buf) {\n\t\tret = -ENOMEM;\n\t\tgoto err1;\n\t}\n\n\txa_lock_irq(&stagd->devp->mrs);\n\txa_for_each(&stagd->devp->mrs, index, p)\n\t\tdump_stag(index, stagd);\n\txa_unlock_irq(&stagd->devp->mrs);\n\n\tstagd->buf[stagd->pos++] = 0;\n\tfile->private_data = stagd;\n\tgoto out;\nerr1:\n\tkfree(stagd);\nout:\n\treturn ret;\n}\n\nstatic const struct file_operations stag_debugfs_fops = {\n\t.owner   = THIS_MODULE,\n\t.open    = stag_open,\n\t.release = stag_release,\n\t.read    = debugfs_read,\n\t.llseek  = default_llseek,\n};\n\nstatic char *db_state_str[] = {\"NORMAL\", \"FLOW_CONTROL\", \"RECOVERY\", \"STOPPED\"};\n\nstatic int stats_show(struct seq_file *seq, void *v)\n{\n\tstruct c4iw_dev *dev = seq->private;\n\n\tseq_printf(seq, \"   Object: %10s %10s %10s %10s\\n\", \"Total\", \"Current\",\n\t\t   \"Max\", \"Fail\");\n\tseq_printf(seq, \"     PDID: %10llu %10llu %10llu %10llu\\n\",\n\t\t\tdev->rdev.stats.pd.total, dev->rdev.stats.pd.cur,\n\t\t\tdev->rdev.stats.pd.max, dev->rdev.stats.pd.fail);\n\tseq_printf(seq, \"      QID: %10llu %10llu %10llu %10llu\\n\",\n\t\t\tdev->rdev.stats.qid.total, dev->rdev.stats.qid.cur,\n\t\t\tdev->rdev.stats.qid.max, dev->rdev.stats.qid.fail);\n\tseq_printf(seq, \"     SRQS: %10llu %10llu %10llu %10llu\\n\",\n\t\t   dev->rdev.stats.srqt.total, dev->rdev.stats.srqt.cur,\n\t\t\tdev->rdev.stats.srqt.max, dev->rdev.stats.srqt.fail);\n\tseq_printf(seq, \"   TPTMEM: %10llu %10llu %10llu %10llu\\n\",\n\t\t\tdev->rdev.stats.stag.total, dev->rdev.stats.stag.cur,\n\t\t\tdev->rdev.stats.stag.max, dev->rdev.stats.stag.fail);\n\tseq_printf(seq, \"   PBLMEM: %10llu %10llu %10llu %10llu\\n\",\n\t\t\tdev->rdev.stats.pbl.total, dev->rdev.stats.pbl.cur,\n\t\t\tdev->rdev.stats.pbl.max, dev->rdev.stats.pbl.fail);\n\tseq_printf(seq, \"   RQTMEM: %10llu %10llu %10llu %10llu\\n\",\n\t\t\tdev->rdev.stats.rqt.total, dev->rdev.stats.rqt.cur,\n\t\t\tdev->rdev.stats.rqt.max, dev->rdev.stats.rqt.fail);\n\tseq_printf(seq, \"  OCQPMEM: %10llu %10llu %10llu %10llu\\n\",\n\t\t\tdev->rdev.stats.ocqp.total, dev->rdev.stats.ocqp.cur,\n\t\t\tdev->rdev.stats.ocqp.max, dev->rdev.stats.ocqp.fail);\n\tseq_printf(seq, \"  DB FULL: %10llu\\n\", dev->rdev.stats.db_full);\n\tseq_printf(seq, \" DB EMPTY: %10llu\\n\", dev->rdev.stats.db_empty);\n\tseq_printf(seq, \"  DB DROP: %10llu\\n\", dev->rdev.stats.db_drop);\n\tseq_printf(seq, \" DB State: %s Transitions %llu FC Interruptions %llu\\n\",\n\t\t   db_state_str[dev->db_state],\n\t\t   dev->rdev.stats.db_state_transitions,\n\t\t   dev->rdev.stats.db_fc_interruptions);\n\tseq_printf(seq, \"TCAM_FULL: %10llu\\n\", dev->rdev.stats.tcam_full);\n\tseq_printf(seq, \"ACT_OFLD_CONN_FAILS: %10llu\\n\",\n\t\t   dev->rdev.stats.act_ofld_conn_fails);\n\tseq_printf(seq, \"PAS_OFLD_CONN_FAILS: %10llu\\n\",\n\t\t   dev->rdev.stats.pas_ofld_conn_fails);\n\tseq_printf(seq, \"NEG_ADV_RCVD: %10llu\\n\", dev->rdev.stats.neg_adv);\n\tseq_printf(seq, \"AVAILABLE IRD: %10u\\n\", dev->avail_ird);\n\treturn 0;\n}\n\nstatic int stats_open(struct inode *inode, struct file *file)\n{\n\treturn single_open(file, stats_show, inode->i_private);\n}\n\nstatic ssize_t stats_clear(struct file *file, const char __user *buf,\n\t\tsize_t count, loff_t *pos)\n{\n\tstruct c4iw_dev *dev = ((struct seq_file *)file->private_data)->private;\n\n\tmutex_lock(&dev->rdev.stats.lock);\n\tdev->rdev.stats.pd.max = 0;\n\tdev->rdev.stats.pd.fail = 0;\n\tdev->rdev.stats.qid.max = 0;\n\tdev->rdev.stats.qid.fail = 0;\n\tdev->rdev.stats.stag.max = 0;\n\tdev->rdev.stats.stag.fail = 0;\n\tdev->rdev.stats.pbl.max = 0;\n\tdev->rdev.stats.pbl.fail = 0;\n\tdev->rdev.stats.rqt.max = 0;\n\tdev->rdev.stats.rqt.fail = 0;\n\tdev->rdev.stats.rqt.max = 0;\n\tdev->rdev.stats.rqt.fail = 0;\n\tdev->rdev.stats.ocqp.max = 0;\n\tdev->rdev.stats.ocqp.fail = 0;\n\tdev->rdev.stats.db_full = 0;\n\tdev->rdev.stats.db_empty = 0;\n\tdev->rdev.stats.db_drop = 0;\n\tdev->rdev.stats.db_state_transitions = 0;\n\tdev->rdev.stats.tcam_full = 0;\n\tdev->rdev.stats.act_ofld_conn_fails = 0;\n\tdev->rdev.stats.pas_ofld_conn_fails = 0;\n\tmutex_unlock(&dev->rdev.stats.lock);\n\treturn count;\n}\n\nstatic const struct file_operations stats_debugfs_fops = {\n\t.owner   = THIS_MODULE,\n\t.open    = stats_open,\n\t.release = single_release,\n\t.read    = seq_read,\n\t.llseek  = seq_lseek,\n\t.write   = stats_clear,\n};\n\nstatic int dump_ep(struct c4iw_ep *ep, struct c4iw_debugfs_data *epd)\n{\n\tint space;\n\tint cc;\n\n\tspace = epd->bufsize - epd->pos - 1;\n\tif (space == 0)\n\t\treturn 1;\n\n\tif (ep->com.local_addr.ss_family == AF_INET) {\n\t\tstruct sockaddr_in *lsin;\n\t\tstruct sockaddr_in *rsin;\n\t\tstruct sockaddr_in *m_lsin;\n\t\tstruct sockaddr_in *m_rsin;\n\n\t\tset_ep_sin_addrs(ep, &lsin, &rsin, &m_lsin, &m_rsin);\n\t\tcc = snprintf(epd->buf + epd->pos, space,\n\t\t\t      \"ep %p cm_id %p qp %p state %d flags 0x%lx \"\n\t\t\t      \"history 0x%lx hwtid %d atid %d \"\n\t\t\t      \"conn_na %u abort_na %u \"\n\t\t\t      \"%pI4:%d/%d <-> %pI4:%d/%d\\n\",\n\t\t\t      ep, ep->com.cm_id, ep->com.qp,\n\t\t\t      (int)ep->com.state, ep->com.flags,\n\t\t\t      ep->com.history, ep->hwtid, ep->atid,\n\t\t\t      ep->stats.connect_neg_adv,\n\t\t\t      ep->stats.abort_neg_adv,\n\t\t\t      &lsin->sin_addr, ntohs(lsin->sin_port),\n\t\t\t      ntohs(m_lsin->sin_port),\n\t\t\t      &rsin->sin_addr, ntohs(rsin->sin_port),\n\t\t\t      ntohs(m_rsin->sin_port));\n\t} else {\n\t\tstruct sockaddr_in6 *lsin6;\n\t\tstruct sockaddr_in6 *rsin6;\n\t\tstruct sockaddr_in6 *m_lsin6;\n\t\tstruct sockaddr_in6 *m_rsin6;\n\n\t\tset_ep_sin6_addrs(ep, &lsin6, &rsin6, &m_lsin6, &m_rsin6);\n\t\tcc = snprintf(epd->buf + epd->pos, space,\n\t\t\t      \"ep %p cm_id %p qp %p state %d flags 0x%lx \"\n\t\t\t      \"history 0x%lx hwtid %d atid %d \"\n\t\t\t      \"conn_na %u abort_na %u \"\n\t\t\t      \"%pI6:%d/%d <-> %pI6:%d/%d\\n\",\n\t\t\t      ep, ep->com.cm_id, ep->com.qp,\n\t\t\t      (int)ep->com.state, ep->com.flags,\n\t\t\t      ep->com.history, ep->hwtid, ep->atid,\n\t\t\t      ep->stats.connect_neg_adv,\n\t\t\t      ep->stats.abort_neg_adv,\n\t\t\t      &lsin6->sin6_addr, ntohs(lsin6->sin6_port),\n\t\t\t      ntohs(m_lsin6->sin6_port),\n\t\t\t      &rsin6->sin6_addr, ntohs(rsin6->sin6_port),\n\t\t\t      ntohs(m_rsin6->sin6_port));\n\t}\n\tif (cc < space)\n\t\tepd->pos += cc;\n\treturn 0;\n}\n\nstatic\nint dump_listen_ep(struct c4iw_listen_ep *ep, struct c4iw_debugfs_data *epd)\n{\n\tint space;\n\tint cc;\n\n\tspace = epd->bufsize - epd->pos - 1;\n\tif (space == 0)\n\t\treturn 1;\n\n\tif (ep->com.local_addr.ss_family == AF_INET) {\n\t\tstruct sockaddr_in *lsin = (struct sockaddr_in *)\n\t\t\t&ep->com.cm_id->local_addr;\n\t\tstruct sockaddr_in *m_lsin = (struct sockaddr_in *)\n\t\t\t&ep->com.cm_id->m_local_addr;\n\n\t\tcc = snprintf(epd->buf + epd->pos, space,\n\t\t\t      \"ep %p cm_id %p state %d flags 0x%lx stid %d \"\n\t\t\t      \"backlog %d %pI4:%d/%d\\n\",\n\t\t\t      ep, ep->com.cm_id, (int)ep->com.state,\n\t\t\t      ep->com.flags, ep->stid, ep->backlog,\n\t\t\t      &lsin->sin_addr, ntohs(lsin->sin_port),\n\t\t\t      ntohs(m_lsin->sin_port));\n\t} else {\n\t\tstruct sockaddr_in6 *lsin6 = (struct sockaddr_in6 *)\n\t\t\t&ep->com.cm_id->local_addr;\n\t\tstruct sockaddr_in6 *m_lsin6 = (struct sockaddr_in6 *)\n\t\t\t&ep->com.cm_id->m_local_addr;\n\n\t\tcc = snprintf(epd->buf + epd->pos, space,\n\t\t\t      \"ep %p cm_id %p state %d flags 0x%lx stid %d \"\n\t\t\t      \"backlog %d %pI6:%d/%d\\n\",\n\t\t\t      ep, ep->com.cm_id, (int)ep->com.state,\n\t\t\t      ep->com.flags, ep->stid, ep->backlog,\n\t\t\t      &lsin6->sin6_addr, ntohs(lsin6->sin6_port),\n\t\t\t      ntohs(m_lsin6->sin6_port));\n\t}\n\tif (cc < space)\n\t\tepd->pos += cc;\n\treturn 0;\n}\n\nstatic int ep_release(struct inode *inode, struct file *file)\n{\n\tstruct c4iw_debugfs_data *epd = file->private_data;\n\tif (!epd) {\n\t\tpr_info(\"%s null qpd?\\n\", __func__);\n\t\treturn 0;\n\t}\n\tvfree(epd->buf);\n\tkfree(epd);\n\treturn 0;\n}\n\nstatic int ep_open(struct inode *inode, struct file *file)\n{\n\tstruct c4iw_ep *ep;\n\tstruct c4iw_listen_ep *lep;\n\tunsigned long index;\n\tstruct c4iw_debugfs_data *epd;\n\tint ret = 0;\n\tint count = 1;\n\n\tepd = kmalloc(sizeof(*epd), GFP_KERNEL);\n\tif (!epd) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tepd->devp = inode->i_private;\n\tepd->pos = 0;\n\n\txa_for_each(&epd->devp->hwtids, index, ep)\n\t\tcount++;\n\txa_for_each(&epd->devp->atids, index, ep)\n\t\tcount++;\n\txa_for_each(&epd->devp->stids, index, lep)\n\t\tcount++;\n\n\tepd->bufsize = count * 240;\n\tepd->buf = vmalloc(epd->bufsize);\n\tif (!epd->buf) {\n\t\tret = -ENOMEM;\n\t\tgoto err1;\n\t}\n\n\txa_lock_irq(&epd->devp->hwtids);\n\txa_for_each(&epd->devp->hwtids, index, ep)\n\t\tdump_ep(ep, epd);\n\txa_unlock_irq(&epd->devp->hwtids);\n\txa_lock_irq(&epd->devp->atids);\n\txa_for_each(&epd->devp->atids, index, ep)\n\t\tdump_ep(ep, epd);\n\txa_unlock_irq(&epd->devp->atids);\n\txa_lock_irq(&epd->devp->stids);\n\txa_for_each(&epd->devp->stids, index, lep)\n\t\tdump_listen_ep(lep, epd);\n\txa_unlock_irq(&epd->devp->stids);\n\n\tfile->private_data = epd;\n\tgoto out;\nerr1:\n\tkfree(epd);\nout:\n\treturn ret;\n}\n\nstatic const struct file_operations ep_debugfs_fops = {\n\t.owner   = THIS_MODULE,\n\t.open    = ep_open,\n\t.release = ep_release,\n\t.read    = debugfs_read,\n};\n\nstatic void setup_debugfs(struct c4iw_dev *devp)\n{\n\tdebugfs_create_file_size(\"qps\", S_IWUSR, devp->debugfs_root,\n\t\t\t\t (void *)devp, &qp_debugfs_fops, 4096);\n\n\tdebugfs_create_file_size(\"stags\", S_IWUSR, devp->debugfs_root,\n\t\t\t\t (void *)devp, &stag_debugfs_fops, 4096);\n\n\tdebugfs_create_file_size(\"stats\", S_IWUSR, devp->debugfs_root,\n\t\t\t\t (void *)devp, &stats_debugfs_fops, 4096);\n\n\tdebugfs_create_file_size(\"eps\", S_IWUSR, devp->debugfs_root,\n\t\t\t\t (void *)devp, &ep_debugfs_fops, 4096);\n\n\tif (c4iw_wr_log)\n\t\tdebugfs_create_file_size(\"wr_log\", S_IWUSR, devp->debugfs_root,\n\t\t\t\t\t (void *)devp, &wr_log_debugfs_fops, 4096);\n}\n\nvoid c4iw_release_dev_ucontext(struct c4iw_rdev *rdev,\n\t\t\t       struct c4iw_dev_ucontext *uctx)\n{\n\tstruct list_head *pos, *nxt;\n\tstruct c4iw_qid_list *entry;\n\n\tmutex_lock(&uctx->lock);\n\tlist_for_each_safe(pos, nxt, &uctx->qpids) {\n\t\tentry = list_entry(pos, struct c4iw_qid_list, entry);\n\t\tlist_del_init(&entry->entry);\n\t\tif (!(entry->qid & rdev->qpmask)) {\n\t\t\tc4iw_put_resource(&rdev->resource.qid_table,\n\t\t\t\t\t  entry->qid);\n\t\t\tmutex_lock(&rdev->stats.lock);\n\t\t\trdev->stats.qid.cur -= rdev->qpmask + 1;\n\t\t\tmutex_unlock(&rdev->stats.lock);\n\t\t}\n\t\tkfree(entry);\n\t}\n\n\tlist_for_each_safe(pos, nxt, &uctx->cqids) {\n\t\tentry = list_entry(pos, struct c4iw_qid_list, entry);\n\t\tlist_del_init(&entry->entry);\n\t\tkfree(entry);\n\t}\n\tmutex_unlock(&uctx->lock);\n}\n\nvoid c4iw_init_dev_ucontext(struct c4iw_rdev *rdev,\n\t\t\t    struct c4iw_dev_ucontext *uctx)\n{\n\tINIT_LIST_HEAD(&uctx->qpids);\n\tINIT_LIST_HEAD(&uctx->cqids);\n\tmutex_init(&uctx->lock);\n}\n\n \nstatic int c4iw_rdev_open(struct c4iw_rdev *rdev)\n{\n\tint err;\n\tunsigned int factor;\n\n\tc4iw_init_dev_ucontext(rdev, &rdev->uctx);\n\n\t \n\tif (rdev->lldi.udb_density != rdev->lldi.ucq_density) {\n\t\tpr_err(\"%s: unsupported udb/ucq densities %u/%u\\n\",\n\t\t       pci_name(rdev->lldi.pdev), rdev->lldi.udb_density,\n\t\t       rdev->lldi.ucq_density);\n\t\treturn -EINVAL;\n\t}\n\tif (rdev->lldi.vr->qp.start != rdev->lldi.vr->cq.start ||\n\t    rdev->lldi.vr->qp.size != rdev->lldi.vr->cq.size) {\n\t\tpr_err(\"%s: unsupported qp and cq id ranges qp start %u size %u cq start %u size %u\\n\",\n\t\t       pci_name(rdev->lldi.pdev), rdev->lldi.vr->qp.start,\n\t\t       rdev->lldi.vr->qp.size, rdev->lldi.vr->cq.size,\n\t\t       rdev->lldi.vr->cq.size);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (rdev->lldi.sge_host_page_size > PAGE_SIZE) {\n\t\tpr_err(\"%s: unsupported sge host page size %u\\n\",\n\t\t       pci_name(rdev->lldi.pdev),\n\t\t       rdev->lldi.sge_host_page_size);\n\t\treturn -EINVAL;\n\t}\n\n\tfactor = PAGE_SIZE / rdev->lldi.sge_host_page_size;\n\trdev->qpmask = (rdev->lldi.udb_density * factor) - 1;\n\trdev->cqmask = (rdev->lldi.ucq_density * factor) - 1;\n\n\tpr_debug(\"dev %s stag start 0x%0x size 0x%0x num stags %d pbl start 0x%0x size 0x%0x rq start 0x%0x size 0x%0x qp qid start %u size %u cq qid start %u size %u srq size %u\\n\",\n\t\t pci_name(rdev->lldi.pdev), rdev->lldi.vr->stag.start,\n\t\t rdev->lldi.vr->stag.size, c4iw_num_stags(rdev),\n\t\t rdev->lldi.vr->pbl.start,\n\t\t rdev->lldi.vr->pbl.size, rdev->lldi.vr->rq.start,\n\t\t rdev->lldi.vr->rq.size,\n\t\t rdev->lldi.vr->qp.start,\n\t\t rdev->lldi.vr->qp.size,\n\t\t rdev->lldi.vr->cq.start,\n\t\t rdev->lldi.vr->cq.size,\n\t\t rdev->lldi.vr->srq.size);\n\tpr_debug(\"udb %pR db_reg %p gts_reg %p qpmask 0x%x cqmask 0x%x\\n\",\n\t\t &rdev->lldi.pdev->resource[2],\n\t\t rdev->lldi.db_reg, rdev->lldi.gts_reg,\n\t\t rdev->qpmask, rdev->cqmask);\n\n\tif (c4iw_num_stags(rdev) == 0)\n\t\treturn -EINVAL;\n\n\trdev->stats.pd.total = T4_MAX_NUM_PD;\n\trdev->stats.stag.total = rdev->lldi.vr->stag.size;\n\trdev->stats.pbl.total = rdev->lldi.vr->pbl.size;\n\trdev->stats.rqt.total = rdev->lldi.vr->rq.size;\n\trdev->stats.srqt.total = rdev->lldi.vr->srq.size;\n\trdev->stats.ocqp.total = rdev->lldi.vr->ocq.size;\n\trdev->stats.qid.total = rdev->lldi.vr->qp.size;\n\n\terr = c4iw_init_resource(rdev, c4iw_num_stags(rdev),\n\t\t\t\t T4_MAX_NUM_PD, rdev->lldi.vr->srq.size);\n\tif (err) {\n\t\tpr_err(\"error %d initializing resources\\n\", err);\n\t\treturn err;\n\t}\n\terr = c4iw_pblpool_create(rdev);\n\tif (err) {\n\t\tpr_err(\"error %d initializing pbl pool\\n\", err);\n\t\tgoto destroy_resource;\n\t}\n\terr = c4iw_rqtpool_create(rdev);\n\tif (err) {\n\t\tpr_err(\"error %d initializing rqt pool\\n\", err);\n\t\tgoto destroy_pblpool;\n\t}\n\terr = c4iw_ocqp_pool_create(rdev);\n\tif (err) {\n\t\tpr_err(\"error %d initializing ocqp pool\\n\", err);\n\t\tgoto destroy_rqtpool;\n\t}\n\trdev->status_page = (struct t4_dev_status_page *)\n\t\t\t    __get_free_page(GFP_KERNEL);\n\tif (!rdev->status_page) {\n\t\terr = -ENOMEM;\n\t\tgoto destroy_ocqp_pool;\n\t}\n\trdev->status_page->qp_start = rdev->lldi.vr->qp.start;\n\trdev->status_page->qp_size = rdev->lldi.vr->qp.size;\n\trdev->status_page->cq_start = rdev->lldi.vr->cq.start;\n\trdev->status_page->cq_size = rdev->lldi.vr->cq.size;\n\trdev->status_page->write_cmpl_supported = rdev->lldi.write_cmpl_support;\n\n\tif (c4iw_wr_log) {\n\t\trdev->wr_log = kcalloc(1 << c4iw_wr_log_size_order,\n\t\t\t\t       sizeof(*rdev->wr_log),\n\t\t\t\t       GFP_KERNEL);\n\t\tif (rdev->wr_log) {\n\t\t\trdev->wr_log_size = 1 << c4iw_wr_log_size_order;\n\t\t\tatomic_set(&rdev->wr_log_idx, 0);\n\t\t}\n\t}\n\n\trdev->free_workq = create_singlethread_workqueue(\"iw_cxgb4_free\");\n\tif (!rdev->free_workq) {\n\t\terr = -ENOMEM;\n\t\tgoto err_free_status_page_and_wr_log;\n\t}\n\n\trdev->status_page->db_off = 0;\n\n\tinit_completion(&rdev->rqt_compl);\n\tinit_completion(&rdev->pbl_compl);\n\tkref_init(&rdev->rqt_kref);\n\tkref_init(&rdev->pbl_kref);\n\n\treturn 0;\nerr_free_status_page_and_wr_log:\n\tif (c4iw_wr_log && rdev->wr_log)\n\t\tkfree(rdev->wr_log);\n\tfree_page((unsigned long)rdev->status_page);\ndestroy_ocqp_pool:\n\tc4iw_ocqp_pool_destroy(rdev);\ndestroy_rqtpool:\n\tc4iw_rqtpool_destroy(rdev);\ndestroy_pblpool:\n\tc4iw_pblpool_destroy(rdev);\ndestroy_resource:\n\tc4iw_destroy_resource(&rdev->resource);\n\treturn err;\n}\n\nstatic void c4iw_rdev_close(struct c4iw_rdev *rdev)\n{\n\tkfree(rdev->wr_log);\n\tc4iw_release_dev_ucontext(rdev, &rdev->uctx);\n\tfree_page((unsigned long)rdev->status_page);\n\tc4iw_pblpool_destroy(rdev);\n\tc4iw_rqtpool_destroy(rdev);\n\twait_for_completion(&rdev->pbl_compl);\n\twait_for_completion(&rdev->rqt_compl);\n\tc4iw_ocqp_pool_destroy(rdev);\n\tdestroy_workqueue(rdev->free_workq);\n\tc4iw_destroy_resource(&rdev->resource);\n}\n\nvoid c4iw_dealloc(struct uld_ctx *ctx)\n{\n\tc4iw_rdev_close(&ctx->dev->rdev);\n\tWARN_ON(!xa_empty(&ctx->dev->cqs));\n\tWARN_ON(!xa_empty(&ctx->dev->qps));\n\tWARN_ON(!xa_empty(&ctx->dev->mrs));\n\twait_event(ctx->dev->wait, xa_empty(&ctx->dev->hwtids));\n\tWARN_ON(!xa_empty(&ctx->dev->stids));\n\tWARN_ON(!xa_empty(&ctx->dev->atids));\n\tif (ctx->dev->rdev.bar2_kva)\n\t\tiounmap(ctx->dev->rdev.bar2_kva);\n\tif (ctx->dev->rdev.oc_mw_kva)\n\t\tiounmap(ctx->dev->rdev.oc_mw_kva);\n\tib_dealloc_device(&ctx->dev->ibdev);\n\tctx->dev = NULL;\n}\n\nstatic void c4iw_remove(struct uld_ctx *ctx)\n{\n\tpr_debug(\"c4iw_dev %p\\n\", ctx->dev);\n\tdebugfs_remove_recursive(ctx->dev->debugfs_root);\n\tc4iw_unregister_device(ctx->dev);\n\tc4iw_dealloc(ctx);\n}\n\nstatic int rdma_supported(const struct cxgb4_lld_info *infop)\n{\n\treturn infop->vr->stag.size > 0 && infop->vr->pbl.size > 0 &&\n\t       infop->vr->rq.size > 0 && infop->vr->qp.size > 0 &&\n\t       infop->vr->cq.size > 0;\n}\n\nstatic struct c4iw_dev *c4iw_alloc(const struct cxgb4_lld_info *infop)\n{\n\tstruct c4iw_dev *devp;\n\tint ret;\n\n\tif (!rdma_supported(infop)) {\n\t\tpr_info(\"%s: RDMA not supported on this device\\n\",\n\t\t\tpci_name(infop->pdev));\n\t\treturn ERR_PTR(-ENOSYS);\n\t}\n\tif (!ocqp_supported(infop))\n\t\tpr_info(\"%s: On-Chip Queues not supported on this device\\n\",\n\t\t\tpci_name(infop->pdev));\n\n\tdevp = ib_alloc_device(c4iw_dev, ibdev);\n\tif (!devp) {\n\t\tpr_err(\"Cannot allocate ib device\\n\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tdevp->rdev.lldi = *infop;\n\n\t \n\tpr_debug(\"Ing. padding boundary is %d, egrsstatuspagesize = %d\\n\",\n\t\t devp->rdev.lldi.sge_ingpadboundary,\n\t\t devp->rdev.lldi.sge_egrstatuspagesize);\n\n\tdevp->rdev.hw_queue.t4_eq_status_entries =\n\t\tdevp->rdev.lldi.sge_egrstatuspagesize / 64;\n\tdevp->rdev.hw_queue.t4_max_eq_size = 65520;\n\tdevp->rdev.hw_queue.t4_max_iq_size = 65520;\n\tdevp->rdev.hw_queue.t4_max_rq_size = 8192 -\n\t\tdevp->rdev.hw_queue.t4_eq_status_entries - 1;\n\tdevp->rdev.hw_queue.t4_max_sq_size =\n\t\tdevp->rdev.hw_queue.t4_max_eq_size -\n\t\tdevp->rdev.hw_queue.t4_eq_status_entries - 1;\n\tdevp->rdev.hw_queue.t4_max_qp_depth =\n\t\tdevp->rdev.hw_queue.t4_max_rq_size;\n\tdevp->rdev.hw_queue.t4_max_cq_depth =\n\t\tdevp->rdev.hw_queue.t4_max_iq_size - 2;\n\tdevp->rdev.hw_queue.t4_stat_len =\n\t\tdevp->rdev.lldi.sge_egrstatuspagesize;\n\n\t \n\tdevp->rdev.bar2_pa = pci_resource_start(devp->rdev.lldi.pdev, 2);\n\tif (!is_t4(devp->rdev.lldi.adapter_type)) {\n\t\tdevp->rdev.bar2_kva = ioremap_wc(devp->rdev.bar2_pa,\n\t\t\tpci_resource_len(devp->rdev.lldi.pdev, 2));\n\t\tif (!devp->rdev.bar2_kva) {\n\t\t\tpr_err(\"Unable to ioremap BAR2\\n\");\n\t\t\tib_dealloc_device(&devp->ibdev);\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\t} else if (ocqp_supported(infop)) {\n\t\tdevp->rdev.oc_mw_pa =\n\t\t\tpci_resource_start(devp->rdev.lldi.pdev, 2) +\n\t\t\tpci_resource_len(devp->rdev.lldi.pdev, 2) -\n\t\t\troundup_pow_of_two(devp->rdev.lldi.vr->ocq.size);\n\t\tdevp->rdev.oc_mw_kva = ioremap_wc(devp->rdev.oc_mw_pa,\n\t\t\tdevp->rdev.lldi.vr->ocq.size);\n\t\tif (!devp->rdev.oc_mw_kva) {\n\t\t\tpr_err(\"Unable to ioremap onchip mem\\n\");\n\t\t\tib_dealloc_device(&devp->ibdev);\n\t\t\treturn ERR_PTR(-EINVAL);\n\t\t}\n\t}\n\n\tpr_debug(\"ocq memory: hw_start 0x%x size %u mw_pa 0x%lx mw_kva %p\\n\",\n\t\t devp->rdev.lldi.vr->ocq.start, devp->rdev.lldi.vr->ocq.size,\n\t\t devp->rdev.oc_mw_pa, devp->rdev.oc_mw_kva);\n\n\tret = c4iw_rdev_open(&devp->rdev);\n\tif (ret) {\n\t\tpr_err(\"Unable to open CXIO rdev err %d\\n\", ret);\n\t\tib_dealloc_device(&devp->ibdev);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\txa_init_flags(&devp->cqs, XA_FLAGS_LOCK_IRQ);\n\txa_init_flags(&devp->qps, XA_FLAGS_LOCK_IRQ);\n\txa_init_flags(&devp->mrs, XA_FLAGS_LOCK_IRQ);\n\txa_init_flags(&devp->hwtids, XA_FLAGS_LOCK_IRQ);\n\txa_init_flags(&devp->atids, XA_FLAGS_LOCK_IRQ);\n\txa_init_flags(&devp->stids, XA_FLAGS_LOCK_IRQ);\n\tmutex_init(&devp->rdev.stats.lock);\n\tmutex_init(&devp->db_mutex);\n\tINIT_LIST_HEAD(&devp->db_fc_list);\n\tinit_waitqueue_head(&devp->wait);\n\tdevp->avail_ird = devp->rdev.lldi.max_ird_adapter;\n\n\tif (c4iw_debugfs_root) {\n\t\tdevp->debugfs_root = debugfs_create_dir(\n\t\t\t\t\tpci_name(devp->rdev.lldi.pdev),\n\t\t\t\t\tc4iw_debugfs_root);\n\t\tsetup_debugfs(devp);\n\t}\n\n\n\treturn devp;\n}\n\nstatic void *c4iw_uld_add(const struct cxgb4_lld_info *infop)\n{\n\tstruct uld_ctx *ctx;\n\tstatic int vers_printed;\n\tint i;\n\n\tif (!vers_printed++)\n\t\tpr_info(\"Chelsio T4/T5 RDMA Driver - version %s\\n\",\n\t\t\tDRV_VERSION);\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx) {\n\t\tctx = ERR_PTR(-ENOMEM);\n\t\tgoto out;\n\t}\n\tctx->lldi = *infop;\n\n\tpr_debug(\"found device %s nchan %u nrxq %u ntxq %u nports %u\\n\",\n\t\t pci_name(ctx->lldi.pdev),\n\t\t ctx->lldi.nchan, ctx->lldi.nrxq,\n\t\t ctx->lldi.ntxq, ctx->lldi.nports);\n\n\tmutex_lock(&dev_mutex);\n\tlist_add_tail(&ctx->entry, &uld_ctx_list);\n\tmutex_unlock(&dev_mutex);\n\n\tfor (i = 0; i < ctx->lldi.nrxq; i++)\n\t\tpr_debug(\"rxqid[%u] %u\\n\", i, ctx->lldi.rxq_ids[i]);\nout:\n\treturn ctx;\n}\n\nstatic inline struct sk_buff *copy_gl_to_skb_pkt(const struct pkt_gl *gl,\n\t\t\t\t\t\t const __be64 *rsp,\n\t\t\t\t\t\t u32 pktshift)\n{\n\tstruct sk_buff *skb;\n\n\t \n\tskb = alloc_skb(gl->tot_len + sizeof(struct cpl_pass_accept_req) +\n\t\t\tsizeof(struct rss_header) - pktshift, GFP_ATOMIC);\n\tif (unlikely(!skb))\n\t\treturn NULL;\n\n\t__skb_put(skb, gl->tot_len + sizeof(struct cpl_pass_accept_req) +\n\t\t  sizeof(struct rss_header) - pktshift);\n\n\t \n\tskb_copy_to_linear_data(skb, rsp, sizeof(struct cpl_pass_accept_req) +\n\t\t\t\tsizeof(struct rss_header));\n\tskb_copy_to_linear_data_offset(skb, sizeof(struct rss_header) +\n\t\t\t\t       sizeof(struct cpl_pass_accept_req),\n\t\t\t\t       gl->va + pktshift,\n\t\t\t\t       gl->tot_len - pktshift);\n\treturn skb;\n}\n\nstatic inline int recv_rx_pkt(struct c4iw_dev *dev, const struct pkt_gl *gl,\n\t\t\t   const __be64 *rsp)\n{\n\tunsigned int opcode = *(u8 *)rsp;\n\tstruct sk_buff *skb;\n\n\tif (opcode != CPL_RX_PKT)\n\t\tgoto out;\n\n\tskb = copy_gl_to_skb_pkt(gl , rsp, dev->rdev.lldi.sge_pktshift);\n\tif (skb == NULL)\n\t\tgoto out;\n\n\tif (c4iw_handlers[opcode] == NULL) {\n\t\tpr_info(\"%s no handler opcode 0x%x...\\n\", __func__, opcode);\n\t\tkfree_skb(skb);\n\t\tgoto out;\n\t}\n\tc4iw_handlers[opcode](dev, skb);\n\treturn 1;\nout:\n\treturn 0;\n}\n\nstatic int c4iw_uld_rx_handler(void *handle, const __be64 *rsp,\n\t\t\tconst struct pkt_gl *gl)\n{\n\tstruct uld_ctx *ctx = handle;\n\tstruct c4iw_dev *dev = ctx->dev;\n\tstruct sk_buff *skb;\n\tu8 opcode;\n\n\tif (gl == NULL) {\n\t\t \n\t\tunsigned int len = 64 - sizeof(struct rsp_ctrl) - 8;\n\n\t\tskb = alloc_skb(256, GFP_ATOMIC);\n\t\tif (!skb)\n\t\t\tgoto nomem;\n\t\t__skb_put(skb, len);\n\t\tskb_copy_to_linear_data(skb, &rsp[1], len);\n\t} else if (gl == CXGB4_MSG_AN) {\n\t\tconst struct rsp_ctrl *rc = (void *)rsp;\n\n\t\tu32 qid = be32_to_cpu(rc->pldbuflen_qid);\n\t\tc4iw_ev_handler(dev, qid);\n\t\treturn 0;\n\t} else if (unlikely(*(u8 *)rsp != *(u8 *)gl->va)) {\n\t\tif (recv_rx_pkt(dev, gl, rsp))\n\t\t\treturn 0;\n\n\t\tpr_info(\"%s: unexpected FL contents at %p, RSS %#llx, FL %#llx, len %u\\n\",\n\t\t\tpci_name(ctx->lldi.pdev), gl->va,\n\t\t\tbe64_to_cpu(*rsp),\n\t\t\tbe64_to_cpu(*(__force __be64 *)gl->va),\n\t\t\tgl->tot_len);\n\n\t\treturn 0;\n\t} else {\n\t\tskb = cxgb4_pktgl_to_skb(gl, 128, 128);\n\t\tif (unlikely(!skb))\n\t\t\tgoto nomem;\n\t}\n\n\topcode = *(u8 *)rsp;\n\tif (c4iw_handlers[opcode]) {\n\t\tc4iw_handlers[opcode](dev, skb);\n\t} else {\n\t\tpr_info(\"%s no handler opcode 0x%x...\\n\", __func__, opcode);\n\t\tkfree_skb(skb);\n\t}\n\n\treturn 0;\nnomem:\n\treturn -1;\n}\n\nstatic int c4iw_uld_state_change(void *handle, enum cxgb4_state new_state)\n{\n\tstruct uld_ctx *ctx = handle;\n\n\tpr_debug(\"new_state %u\\n\", new_state);\n\tswitch (new_state) {\n\tcase CXGB4_STATE_UP:\n\t\tpr_info(\"%s: Up\\n\", pci_name(ctx->lldi.pdev));\n\t\tif (!ctx->dev) {\n\t\t\tctx->dev = c4iw_alloc(&ctx->lldi);\n\t\t\tif (IS_ERR(ctx->dev)) {\n\t\t\t\tpr_err(\"%s: initialization failed: %ld\\n\",\n\t\t\t\t       pci_name(ctx->lldi.pdev),\n\t\t\t\t       PTR_ERR(ctx->dev));\n\t\t\t\tctx->dev = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tINIT_WORK(&ctx->reg_work, c4iw_register_device);\n\t\t\tqueue_work(reg_workq, &ctx->reg_work);\n\t\t}\n\t\tbreak;\n\tcase CXGB4_STATE_DOWN:\n\t\tpr_info(\"%s: Down\\n\", pci_name(ctx->lldi.pdev));\n\t\tif (ctx->dev)\n\t\t\tc4iw_remove(ctx);\n\t\tbreak;\n\tcase CXGB4_STATE_FATAL_ERROR:\n\tcase CXGB4_STATE_START_RECOVERY:\n\t\tpr_info(\"%s: Fatal Error\\n\", pci_name(ctx->lldi.pdev));\n\t\tif (ctx->dev) {\n\t\t\tstruct ib_event event = {};\n\n\t\t\tctx->dev->rdev.flags |= T4_FATAL_ERROR;\n\t\t\tevent.event  = IB_EVENT_DEVICE_FATAL;\n\t\t\tevent.device = &ctx->dev->ibdev;\n\t\t\tib_dispatch_event(&event);\n\t\t\tc4iw_remove(ctx);\n\t\t}\n\t\tbreak;\n\tcase CXGB4_STATE_DETACH:\n\t\tpr_info(\"%s: Detach\\n\", pci_name(ctx->lldi.pdev));\n\t\tif (ctx->dev)\n\t\t\tc4iw_remove(ctx);\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void stop_queues(struct uld_ctx *ctx)\n{\n\tstruct c4iw_qp *qp;\n\tunsigned long index, flags;\n\n\txa_lock_irqsave(&ctx->dev->qps, flags);\n\tctx->dev->rdev.stats.db_state_transitions++;\n\tctx->dev->db_state = STOPPED;\n\tif (ctx->dev->rdev.flags & T4_STATUS_PAGE_DISABLED) {\n\t\txa_for_each(&ctx->dev->qps, index, qp)\n\t\t\tt4_disable_wq_db(&qp->wq);\n\t} else {\n\t\tctx->dev->rdev.status_page->db_off = 1;\n\t}\n\txa_unlock_irqrestore(&ctx->dev->qps, flags);\n}\n\nstatic void resume_rc_qp(struct c4iw_qp *qp)\n{\n\tspin_lock(&qp->lock);\n\tt4_ring_sq_db(&qp->wq, qp->wq.sq.wq_pidx_inc, NULL);\n\tqp->wq.sq.wq_pidx_inc = 0;\n\tt4_ring_rq_db(&qp->wq, qp->wq.rq.wq_pidx_inc, NULL);\n\tqp->wq.rq.wq_pidx_inc = 0;\n\tspin_unlock(&qp->lock);\n}\n\nstatic void resume_a_chunk(struct uld_ctx *ctx)\n{\n\tint i;\n\tstruct c4iw_qp *qp;\n\n\tfor (i = 0; i < DB_FC_RESUME_SIZE; i++) {\n\t\tqp = list_first_entry(&ctx->dev->db_fc_list, struct c4iw_qp,\n\t\t\t\t      db_fc_entry);\n\t\tlist_del_init(&qp->db_fc_entry);\n\t\tresume_rc_qp(qp);\n\t\tif (list_empty(&ctx->dev->db_fc_list))\n\t\t\tbreak;\n\t}\n}\n\nstatic void resume_queues(struct uld_ctx *ctx)\n{\n\txa_lock_irq(&ctx->dev->qps);\n\tif (ctx->dev->db_state != STOPPED)\n\t\tgoto out;\n\tctx->dev->db_state = FLOW_CONTROL;\n\twhile (1) {\n\t\tif (list_empty(&ctx->dev->db_fc_list)) {\n\t\t\tstruct c4iw_qp *qp;\n\t\t\tunsigned long index;\n\n\t\t\tWARN_ON(ctx->dev->db_state != FLOW_CONTROL);\n\t\t\tctx->dev->db_state = NORMAL;\n\t\t\tctx->dev->rdev.stats.db_state_transitions++;\n\t\t\tif (ctx->dev->rdev.flags & T4_STATUS_PAGE_DISABLED) {\n\t\t\t\txa_for_each(&ctx->dev->qps, index, qp)\n\t\t\t\t\tt4_enable_wq_db(&qp->wq);\n\t\t\t} else {\n\t\t\t\tctx->dev->rdev.status_page->db_off = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t} else {\n\t\t\tif (cxgb4_dbfifo_count(ctx->dev->rdev.lldi.ports[0], 1)\n\t\t\t    < (ctx->dev->rdev.lldi.dbfifo_int_thresh <<\n\t\t\t       DB_FC_DRAIN_THRESH)) {\n\t\t\t\tresume_a_chunk(ctx);\n\t\t\t}\n\t\t\tif (!list_empty(&ctx->dev->db_fc_list)) {\n\t\t\t\txa_unlock_irq(&ctx->dev->qps);\n\t\t\t\tif (DB_FC_RESUME_DELAY) {\n\t\t\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\t\t\tschedule_timeout(DB_FC_RESUME_DELAY);\n\t\t\t\t}\n\t\t\t\txa_lock_irq(&ctx->dev->qps);\n\t\t\t\tif (ctx->dev->db_state != FLOW_CONTROL)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\nout:\n\tif (ctx->dev->db_state != NORMAL)\n\t\tctx->dev->rdev.stats.db_fc_interruptions++;\n\txa_unlock_irq(&ctx->dev->qps);\n}\n\nstruct qp_list {\n\tunsigned idx;\n\tstruct c4iw_qp **qps;\n};\n\nstatic void deref_qps(struct qp_list *qp_list)\n{\n\tint idx;\n\n\tfor (idx = 0; idx < qp_list->idx; idx++)\n\t\tc4iw_qp_rem_ref(&qp_list->qps[idx]->ibqp);\n}\n\nstatic void recover_lost_dbs(struct uld_ctx *ctx, struct qp_list *qp_list)\n{\n\tint idx;\n\tint ret;\n\n\tfor (idx = 0; idx < qp_list->idx; idx++) {\n\t\tstruct c4iw_qp *qp = qp_list->qps[idx];\n\n\t\txa_lock_irq(&qp->rhp->qps);\n\t\tspin_lock(&qp->lock);\n\t\tret = cxgb4_sync_txq_pidx(qp->rhp->rdev.lldi.ports[0],\n\t\t\t\t\t  qp->wq.sq.qid,\n\t\t\t\t\t  t4_sq_host_wq_pidx(&qp->wq),\n\t\t\t\t\t  t4_sq_wq_size(&qp->wq));\n\t\tif (ret) {\n\t\t\tpr_err(\"%s: Fatal error - DB overflow recovery failed - error syncing SQ qid %u\\n\",\n\t\t\t       pci_name(ctx->lldi.pdev), qp->wq.sq.qid);\n\t\t\tspin_unlock(&qp->lock);\n\t\t\txa_unlock_irq(&qp->rhp->qps);\n\t\t\treturn;\n\t\t}\n\t\tqp->wq.sq.wq_pidx_inc = 0;\n\n\t\tret = cxgb4_sync_txq_pidx(qp->rhp->rdev.lldi.ports[0],\n\t\t\t\t\t  qp->wq.rq.qid,\n\t\t\t\t\t  t4_rq_host_wq_pidx(&qp->wq),\n\t\t\t\t\t  t4_rq_wq_size(&qp->wq));\n\n\t\tif (ret) {\n\t\t\tpr_err(\"%s: Fatal error - DB overflow recovery failed - error syncing RQ qid %u\\n\",\n\t\t\t       pci_name(ctx->lldi.pdev), qp->wq.rq.qid);\n\t\t\tspin_unlock(&qp->lock);\n\t\t\txa_unlock_irq(&qp->rhp->qps);\n\t\t\treturn;\n\t\t}\n\t\tqp->wq.rq.wq_pidx_inc = 0;\n\t\tspin_unlock(&qp->lock);\n\t\txa_unlock_irq(&qp->rhp->qps);\n\n\t\t \n\t\twhile (cxgb4_dbfifo_count(qp->rhp->rdev.lldi.ports[0], 1) > 0) {\n\t\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\t\tschedule_timeout(usecs_to_jiffies(10));\n\t\t}\n\t}\n}\n\nstatic void recover_queues(struct uld_ctx *ctx)\n{\n\tstruct c4iw_qp *qp;\n\tunsigned long index;\n\tint count = 0;\n\tstruct qp_list qp_list;\n\tint ret;\n\n\t \n\tset_current_state(TASK_UNINTERRUPTIBLE);\n\tschedule_timeout(usecs_to_jiffies(1000));\n\n\t \n\tret = cxgb4_flush_eq_cache(ctx->dev->rdev.lldi.ports[0]);\n\tif (ret) {\n\t\tpr_err(\"%s: Fatal error - DB overflow recovery failed\\n\",\n\t\t       pci_name(ctx->lldi.pdev));\n\t\treturn;\n\t}\n\n\t \n\txa_lock_irq(&ctx->dev->qps);\n\tWARN_ON(ctx->dev->db_state != STOPPED);\n\tctx->dev->db_state = RECOVERY;\n\txa_for_each(&ctx->dev->qps, index, qp)\n\t\tcount++;\n\n\tqp_list.qps = kcalloc(count, sizeof(*qp_list.qps), GFP_ATOMIC);\n\tif (!qp_list.qps) {\n\t\txa_unlock_irq(&ctx->dev->qps);\n\t\treturn;\n\t}\n\tqp_list.idx = 0;\n\n\t \n\txa_for_each(&ctx->dev->qps, index, qp) {\n\t\tc4iw_qp_add_ref(&qp->ibqp);\n\t\tqp_list.qps[qp_list.idx++] = qp;\n\t}\n\n\txa_unlock_irq(&ctx->dev->qps);\n\n\t \n\trecover_lost_dbs(ctx, &qp_list);\n\n\t \n\tderef_qps(&qp_list);\n\tkfree(qp_list.qps);\n\n\txa_lock_irq(&ctx->dev->qps);\n\tWARN_ON(ctx->dev->db_state != RECOVERY);\n\tctx->dev->db_state = STOPPED;\n\txa_unlock_irq(&ctx->dev->qps);\n}\n\nstatic int c4iw_uld_control(void *handle, enum cxgb4_control control, ...)\n{\n\tstruct uld_ctx *ctx = handle;\n\n\tswitch (control) {\n\tcase CXGB4_CONTROL_DB_FULL:\n\t\tstop_queues(ctx);\n\t\tctx->dev->rdev.stats.db_full++;\n\t\tbreak;\n\tcase CXGB4_CONTROL_DB_EMPTY:\n\t\tresume_queues(ctx);\n\t\tmutex_lock(&ctx->dev->rdev.stats.lock);\n\t\tctx->dev->rdev.stats.db_empty++;\n\t\tmutex_unlock(&ctx->dev->rdev.stats.lock);\n\t\tbreak;\n\tcase CXGB4_CONTROL_DB_DROP:\n\t\trecover_queues(ctx);\n\t\tmutex_lock(&ctx->dev->rdev.stats.lock);\n\t\tctx->dev->rdev.stats.db_drop++;\n\t\tmutex_unlock(&ctx->dev->rdev.stats.lock);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"%s: unknown control cmd %u\\n\",\n\t\t\tpci_name(ctx->lldi.pdev), control);\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic struct cxgb4_uld_info c4iw_uld_info = {\n\t.name = DRV_NAME,\n\t.nrxq = MAX_ULD_QSETS,\n\t.ntxq = MAX_ULD_QSETS,\n\t.rxq_size = 511,\n\t.ciq = true,\n\t.lro = false,\n\t.add = c4iw_uld_add,\n\t.rx_handler = c4iw_uld_rx_handler,\n\t.state_change = c4iw_uld_state_change,\n\t.control = c4iw_uld_control,\n};\n\nvoid _c4iw_free_wr_wait(struct kref *kref)\n{\n\tstruct c4iw_wr_wait *wr_waitp;\n\n\twr_waitp = container_of(kref, struct c4iw_wr_wait, kref);\n\tpr_debug(\"Free wr_wait %p\\n\", wr_waitp);\n\tkfree(wr_waitp);\n}\n\nstruct c4iw_wr_wait *c4iw_alloc_wr_wait(gfp_t gfp)\n{\n\tstruct c4iw_wr_wait *wr_waitp;\n\n\twr_waitp = kzalloc(sizeof(*wr_waitp), gfp);\n\tif (wr_waitp) {\n\t\tkref_init(&wr_waitp->kref);\n\t\tpr_debug(\"wr_wait %p\\n\", wr_waitp);\n\t}\n\treturn wr_waitp;\n}\n\nstatic int __init c4iw_init_module(void)\n{\n\tint err;\n\n\terr = c4iw_cm_init();\n\tif (err)\n\t\treturn err;\n\n\tc4iw_debugfs_root = debugfs_create_dir(DRV_NAME, NULL);\n\n\treg_workq = create_singlethread_workqueue(\"Register_iWARP_device\");\n\tif (!reg_workq) {\n\t\tpr_err(\"Failed creating workqueue to register iwarp device\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tcxgb4_register_uld(CXGB4_ULD_RDMA, &c4iw_uld_info);\n\n\treturn 0;\n}\n\nstatic void __exit c4iw_exit_module(void)\n{\n\tstruct uld_ctx *ctx, *tmp;\n\n\tmutex_lock(&dev_mutex);\n\tlist_for_each_entry_safe(ctx, tmp, &uld_ctx_list, entry) {\n\t\tif (ctx->dev)\n\t\t\tc4iw_remove(ctx);\n\t\tkfree(ctx);\n\t}\n\tmutex_unlock(&dev_mutex);\n\tdestroy_workqueue(reg_workq);\n\tcxgb4_unregister_uld(CXGB4_ULD_RDMA);\n\tc4iw_cm_term();\n\tdebugfs_remove_recursive(c4iw_debugfs_root);\n}\n\nmodule_init(c4iw_init_module);\nmodule_exit(c4iw_exit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}