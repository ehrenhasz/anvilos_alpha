{
  "module_name": "erdma_main.c",
  "hash_id": "f543ade2ef9793a1cfa8611d8dfa238509fc76147c1c6e393ef68beb11e8664f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/erdma/erdma_main.c",
  "human_readable_source": "\n\n \n \n \n\n#include <linux/module.h>\n#include <net/addrconf.h>\n#include <rdma/erdma-abi.h>\n\n#include \"erdma.h\"\n#include \"erdma_cm.h\"\n#include \"erdma_verbs.h\"\n\nMODULE_AUTHOR(\"Cheng Xu <chengyou@linux.alibaba.com>\");\nMODULE_DESCRIPTION(\"Alibaba elasticRDMA adapter driver\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n\nstatic int erdma_netdev_event(struct notifier_block *nb, unsigned long event,\n\t\t\t      void *arg)\n{\n\tstruct net_device *netdev = netdev_notifier_info_to_dev(arg);\n\tstruct erdma_dev *dev = container_of(nb, struct erdma_dev, netdev_nb);\n\n\tif (dev->netdev == NULL || dev->netdev != netdev)\n\t\tgoto done;\n\n\tswitch (event) {\n\tcase NETDEV_UP:\n\t\tdev->state = IB_PORT_ACTIVE;\n\t\terdma_port_event(dev, IB_EVENT_PORT_ACTIVE);\n\t\tbreak;\n\tcase NETDEV_DOWN:\n\t\tdev->state = IB_PORT_DOWN;\n\t\terdma_port_event(dev, IB_EVENT_PORT_ERR);\n\t\tbreak;\n\tcase NETDEV_CHANGEMTU:\n\t\tif (dev->mtu != netdev->mtu) {\n\t\t\terdma_set_mtu(dev, netdev->mtu);\n\t\t\tdev->mtu = netdev->mtu;\n\t\t}\n\t\tbreak;\n\tcase NETDEV_REGISTER:\n\tcase NETDEV_UNREGISTER:\n\tcase NETDEV_CHANGEADDR:\n\tcase NETDEV_GOING_DOWN:\n\tcase NETDEV_CHANGE:\n\tdefault:\n\t\tbreak;\n\t}\n\ndone:\n\treturn NOTIFY_OK;\n}\n\nstatic int erdma_enum_and_get_netdev(struct erdma_dev *dev)\n{\n\tstruct net_device *netdev;\n\tint ret = -EPROBE_DEFER;\n\n\t \n\tif (dev->netdev)\n\t\treturn 0;\n\n\trtnl_lock();\n\tfor_each_netdev(&init_net, netdev) {\n\t\t \n\t\tif (ether_addr_equal_unaligned(netdev->perm_addr,\n\t\t\t\t\t       dev->attrs.peer_addr)) {\n\t\t\tret = ib_device_set_netdev(&dev->ibdev, netdev, 1);\n\t\t\tif (ret) {\n\t\t\t\trtnl_unlock();\n\t\t\t\tibdev_warn(&dev->ibdev,\n\t\t\t\t\t   \"failed (%d) to link netdev\", ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tdev->netdev = netdev;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\trtnl_unlock();\n\n\treturn ret;\n}\n\nstatic int erdma_device_register(struct erdma_dev *dev)\n{\n\tstruct ib_device *ibdev = &dev->ibdev;\n\tint ret;\n\n\tret = erdma_enum_and_get_netdev(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tdev->mtu = dev->netdev->mtu;\n\taddrconf_addr_eui48((u8 *)&ibdev->node_guid, dev->netdev->dev_addr);\n\n\tret = ib_register_device(ibdev, \"erdma_%d\", &dev->pdev->dev);\n\tif (ret) {\n\t\tdev_err(&dev->pdev->dev,\n\t\t\t\"ib_register_device failed: ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tdev->netdev_nb.notifier_call = erdma_netdev_event;\n\tret = register_netdevice_notifier(&dev->netdev_nb);\n\tif (ret) {\n\t\tibdev_err(&dev->ibdev, \"failed to register notifier.\\n\");\n\t\tib_unregister_device(ibdev);\n\t}\n\n\treturn ret;\n}\n\nstatic irqreturn_t erdma_comm_irq_handler(int irq, void *data)\n{\n\tstruct erdma_dev *dev = data;\n\n\terdma_cmdq_completion_handler(&dev->cmdq);\n\terdma_aeq_event_handler(dev);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int erdma_request_vectors(struct erdma_dev *dev)\n{\n\tint expect_irq_num = min(num_possible_cpus() + 1, ERDMA_NUM_MSIX_VEC);\n\tint ret;\n\n\tret = pci_alloc_irq_vectors(dev->pdev, 1, expect_irq_num, PCI_IRQ_MSIX);\n\tif (ret < 0) {\n\t\tdev_err(&dev->pdev->dev, \"request irq vectors failed(%d)\\n\",\n\t\t\tret);\n\t\treturn ret;\n\t}\n\tdev->attrs.irq_num = ret;\n\n\treturn 0;\n}\n\nstatic int erdma_comm_irq_init(struct erdma_dev *dev)\n{\n\tsnprintf(dev->comm_irq.name, ERDMA_IRQNAME_SIZE, \"erdma-common@pci:%s\",\n\t\t pci_name(dev->pdev));\n\tdev->comm_irq.msix_vector =\n\t\tpci_irq_vector(dev->pdev, ERDMA_MSIX_VECTOR_CMDQ);\n\n\tcpumask_set_cpu(cpumask_first(cpumask_of_pcibus(dev->pdev->bus)),\n\t\t\t&dev->comm_irq.affinity_hint_mask);\n\tirq_set_affinity_hint(dev->comm_irq.msix_vector,\n\t\t\t      &dev->comm_irq.affinity_hint_mask);\n\n\treturn request_irq(dev->comm_irq.msix_vector, erdma_comm_irq_handler, 0,\n\t\t\t   dev->comm_irq.name, dev);\n}\n\nstatic void erdma_comm_irq_uninit(struct erdma_dev *dev)\n{\n\tirq_set_affinity_hint(dev->comm_irq.msix_vector, NULL);\n\tfree_irq(dev->comm_irq.msix_vector, dev);\n}\n\nstatic int erdma_device_init(struct erdma_dev *dev, struct pci_dev *pdev)\n{\n\tint ret;\n\n\tret = dma_set_mask_and_coherent(&pdev->dev,\n\t\t\t\t\tDMA_BIT_MASK(ERDMA_PCI_WIDTH));\n\tif (ret)\n\t\treturn ret;\n\n\tdma_set_max_seg_size(&pdev->dev, UINT_MAX);\n\n\treturn 0;\n}\n\nstatic void erdma_hw_reset(struct erdma_dev *dev)\n{\n\tu32 ctrl = FIELD_PREP(ERDMA_REG_DEV_CTRL_RESET_MASK, 1);\n\n\terdma_reg_write32(dev, ERDMA_REGS_DEV_CTRL_REG, ctrl);\n}\n\nstatic int erdma_wait_hw_init_done(struct erdma_dev *dev)\n{\n\tint i;\n\n\terdma_reg_write32(dev, ERDMA_REGS_DEV_CTRL_REG,\n\t\t\t  FIELD_PREP(ERDMA_REG_DEV_CTRL_INIT_MASK, 1));\n\n\tfor (i = 0; i < ERDMA_WAIT_DEV_DONE_CNT; i++) {\n\t\tif (erdma_reg_read32_filed(dev, ERDMA_REGS_DEV_ST_REG,\n\t\t\t\t\t   ERDMA_REG_DEV_ST_INIT_DONE_MASK))\n\t\t\tbreak;\n\n\t\tmsleep(ERDMA_REG_ACCESS_WAIT_MS);\n\t}\n\n\tif (i == ERDMA_WAIT_DEV_DONE_CNT) {\n\t\tdev_err(&dev->pdev->dev, \"wait init done failed.\\n\");\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct pci_device_id erdma_pci_tbl[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_ALIBABA, 0x107f) },\n\t{}\n};\n\nstatic int erdma_probe_dev(struct pci_dev *pdev)\n{\n\tstruct erdma_dev *dev;\n\tint bars, err;\n\tu32 version;\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"pci_enable_device failed(%d)\\n\", err);\n\t\treturn err;\n\t}\n\n\tpci_set_master(pdev);\n\n\tdev = ib_alloc_device(erdma_dev, ibdev);\n\tif (!dev) {\n\t\tdev_err(&pdev->dev, \"ib_alloc_device failed\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_disable_device;\n\t}\n\n\tpci_set_drvdata(pdev, dev);\n\tdev->pdev = pdev;\n\tdev->attrs.numa_node = dev_to_node(&pdev->dev);\n\n\tbars = pci_select_bars(pdev, IORESOURCE_MEM);\n\terr = pci_request_selected_regions(pdev, bars, DRV_MODULE_NAME);\n\tif (bars != ERDMA_BAR_MASK || err) {\n\t\terr = err ? err : -EINVAL;\n\t\tgoto err_ib_device_release;\n\t}\n\n\tdev->func_bar_addr = pci_resource_start(pdev, ERDMA_FUNC_BAR);\n\tdev->func_bar_len = pci_resource_len(pdev, ERDMA_FUNC_BAR);\n\n\tdev->func_bar =\n\t\tdevm_ioremap(&pdev->dev, dev->func_bar_addr, dev->func_bar_len);\n\tif (!dev->func_bar) {\n\t\tdev_err(&pdev->dev, \"devm_ioremap failed.\\n\");\n\t\terr = -EFAULT;\n\t\tgoto err_release_bars;\n\t}\n\n\tversion = erdma_reg_read32(dev, ERDMA_REGS_VERSION_REG);\n\tif (version == 0) {\n\t\t \n\t\terr = -ENODEV;\n\t\tgoto err_iounmap_func_bar;\n\t}\n\n\terr = erdma_device_init(dev, pdev);\n\tif (err)\n\t\tgoto err_iounmap_func_bar;\n\n\terr = erdma_request_vectors(dev);\n\tif (err)\n\t\tgoto err_iounmap_func_bar;\n\n\terr = erdma_comm_irq_init(dev);\n\tif (err)\n\t\tgoto err_free_vectors;\n\n\terr = erdma_aeq_init(dev);\n\tif (err)\n\t\tgoto err_uninit_comm_irq;\n\n\terr = erdma_cmdq_init(dev);\n\tif (err)\n\t\tgoto err_uninit_aeq;\n\n\terr = erdma_wait_hw_init_done(dev);\n\tif (err)\n\t\tgoto err_uninit_cmdq;\n\n\terr = erdma_ceqs_init(dev);\n\tif (err)\n\t\tgoto err_reset_hw;\n\n\terdma_finish_cmdq_init(dev);\n\n\treturn 0;\n\nerr_reset_hw:\n\terdma_hw_reset(dev);\n\nerr_uninit_cmdq:\n\terdma_cmdq_destroy(dev);\n\nerr_uninit_aeq:\n\terdma_aeq_destroy(dev);\n\nerr_uninit_comm_irq:\n\terdma_comm_irq_uninit(dev);\n\nerr_free_vectors:\n\tpci_free_irq_vectors(dev->pdev);\n\nerr_iounmap_func_bar:\n\tdevm_iounmap(&pdev->dev, dev->func_bar);\n\nerr_release_bars:\n\tpci_release_selected_regions(pdev, bars);\n\nerr_ib_device_release:\n\tib_dealloc_device(&dev->ibdev);\n\nerr_disable_device:\n\tpci_disable_device(pdev);\n\n\treturn err;\n}\n\nstatic void erdma_remove_dev(struct pci_dev *pdev)\n{\n\tstruct erdma_dev *dev = pci_get_drvdata(pdev);\n\n\terdma_ceqs_uninit(dev);\n\terdma_hw_reset(dev);\n\terdma_cmdq_destroy(dev);\n\terdma_aeq_destroy(dev);\n\terdma_comm_irq_uninit(dev);\n\tpci_free_irq_vectors(dev->pdev);\n\n\tdevm_iounmap(&pdev->dev, dev->func_bar);\n\tpci_release_selected_regions(pdev, ERDMA_BAR_MASK);\n\n\tib_dealloc_device(&dev->ibdev);\n\n\tpci_disable_device(pdev);\n}\n\n#define ERDMA_GET_CAP(name, cap) FIELD_GET(ERDMA_CMD_DEV_CAP_##name##_MASK, cap)\n\nstatic int erdma_dev_attrs_init(struct erdma_dev *dev)\n{\n\tint err;\n\tu64 req_hdr, cap0, cap1;\n\n\terdma_cmdq_build_reqhdr(&req_hdr, CMDQ_SUBMOD_RDMA,\n\t\t\t\tCMDQ_OPCODE_QUERY_DEVICE);\n\n\terr = erdma_post_cmd_wait(&dev->cmdq, &req_hdr, sizeof(req_hdr), &cap0,\n\t\t\t\t  &cap1);\n\tif (err)\n\t\treturn err;\n\n\tdev->attrs.max_cqe = 1 << ERDMA_GET_CAP(MAX_CQE, cap0);\n\tdev->attrs.max_mr_size = 1ULL << ERDMA_GET_CAP(MAX_MR_SIZE, cap0);\n\tdev->attrs.max_mw = 1 << ERDMA_GET_CAP(MAX_MW, cap1);\n\tdev->attrs.max_recv_wr = 1 << ERDMA_GET_CAP(MAX_RECV_WR, cap0);\n\tdev->attrs.local_dma_key = ERDMA_GET_CAP(DMA_LOCAL_KEY, cap1);\n\tdev->attrs.cc = ERDMA_GET_CAP(DEFAULT_CC, cap1);\n\tdev->attrs.max_qp = ERDMA_NQP_PER_QBLOCK * ERDMA_GET_CAP(QBLOCK, cap1);\n\tdev->attrs.max_mr = dev->attrs.max_qp << 1;\n\tdev->attrs.max_cq = dev->attrs.max_qp << 1;\n\tdev->attrs.cap_flags = ERDMA_GET_CAP(FLAGS, cap0);\n\n\tdev->attrs.max_send_wr = ERDMA_MAX_SEND_WR;\n\tdev->attrs.max_ord = ERDMA_MAX_ORD;\n\tdev->attrs.max_ird = ERDMA_MAX_IRD;\n\tdev->attrs.max_send_sge = ERDMA_MAX_SEND_SGE;\n\tdev->attrs.max_recv_sge = ERDMA_MAX_RECV_SGE;\n\tdev->attrs.max_sge_rd = ERDMA_MAX_SGE_RD;\n\tdev->attrs.max_pd = ERDMA_MAX_PD;\n\n\tdev->res_cb[ERDMA_RES_TYPE_PD].max_cap = ERDMA_MAX_PD;\n\tdev->res_cb[ERDMA_RES_TYPE_STAG_IDX].max_cap = dev->attrs.max_mr;\n\n\terdma_cmdq_build_reqhdr(&req_hdr, CMDQ_SUBMOD_COMMON,\n\t\t\t\tCMDQ_OPCODE_QUERY_FW_INFO);\n\n\terr = erdma_post_cmd_wait(&dev->cmdq, &req_hdr, sizeof(req_hdr), &cap0,\n\t\t\t\t  &cap1);\n\tif (!err)\n\t\tdev->attrs.fw_version =\n\t\t\tFIELD_GET(ERDMA_CMD_INFO0_FW_VER_MASK, cap0);\n\n\treturn err;\n}\n\nstatic int erdma_device_config(struct erdma_dev *dev)\n{\n\tstruct erdma_cmdq_config_device_req req = {};\n\n\tif (!(dev->attrs.cap_flags & ERDMA_DEV_CAP_FLAGS_EXTEND_DB))\n\t\treturn 0;\n\n\terdma_cmdq_build_reqhdr(&req.hdr, CMDQ_SUBMOD_COMMON,\n\t\t\t\tCMDQ_OPCODE_CONF_DEVICE);\n\n\treq.cfg = FIELD_PREP(ERDMA_CMD_CONFIG_DEVICE_PGSHIFT_MASK, PAGE_SHIFT) |\n\t\t  FIELD_PREP(ERDMA_CMD_CONFIG_DEVICE_PS_EN_MASK, 1);\n\n\treturn erdma_post_cmd_wait(&dev->cmdq, &req, sizeof(req), NULL, NULL);\n}\n\nstatic int erdma_res_cb_init(struct erdma_dev *dev)\n{\n\tint i, j;\n\n\tfor (i = 0; i < ERDMA_RES_CNT; i++) {\n\t\tdev->res_cb[i].next_alloc_idx = 1;\n\t\tspin_lock_init(&dev->res_cb[i].lock);\n\t\tdev->res_cb[i].bitmap =\n\t\t\tbitmap_zalloc(dev->res_cb[i].max_cap, GFP_KERNEL);\n\t\tif (!dev->res_cb[i].bitmap)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (j = 0; j < i; j++)\n\t\tbitmap_free(dev->res_cb[j].bitmap);\n\n\treturn -ENOMEM;\n}\n\nstatic void erdma_res_cb_free(struct erdma_dev *dev)\n{\n\tint i;\n\n\tfor (i = 0; i < ERDMA_RES_CNT; i++)\n\t\tbitmap_free(dev->res_cb[i].bitmap);\n}\n\nstatic const struct ib_device_ops erdma_device_ops = {\n\t.owner = THIS_MODULE,\n\t.driver_id = RDMA_DRIVER_ERDMA,\n\t.uverbs_abi_ver = ERDMA_ABI_VERSION,\n\n\t.alloc_mr = erdma_ib_alloc_mr,\n\t.alloc_pd = erdma_alloc_pd,\n\t.alloc_ucontext = erdma_alloc_ucontext,\n\t.create_cq = erdma_create_cq,\n\t.create_qp = erdma_create_qp,\n\t.dealloc_pd = erdma_dealloc_pd,\n\t.dealloc_ucontext = erdma_dealloc_ucontext,\n\t.dereg_mr = erdma_dereg_mr,\n\t.destroy_cq = erdma_destroy_cq,\n\t.destroy_qp = erdma_destroy_qp,\n\t.get_dma_mr = erdma_get_dma_mr,\n\t.get_port_immutable = erdma_get_port_immutable,\n\t.iw_accept = erdma_accept,\n\t.iw_add_ref = erdma_qp_get_ref,\n\t.iw_connect = erdma_connect,\n\t.iw_create_listen = erdma_create_listen,\n\t.iw_destroy_listen = erdma_destroy_listen,\n\t.iw_get_qp = erdma_get_ibqp,\n\t.iw_reject = erdma_reject,\n\t.iw_rem_ref = erdma_qp_put_ref,\n\t.map_mr_sg = erdma_map_mr_sg,\n\t.mmap = erdma_mmap,\n\t.mmap_free = erdma_mmap_free,\n\t.modify_qp = erdma_modify_qp,\n\t.post_recv = erdma_post_recv,\n\t.post_send = erdma_post_send,\n\t.poll_cq = erdma_poll_cq,\n\t.query_device = erdma_query_device,\n\t.query_gid = erdma_query_gid,\n\t.query_port = erdma_query_port,\n\t.query_qp = erdma_query_qp,\n\t.req_notify_cq = erdma_req_notify_cq,\n\t.reg_user_mr = erdma_reg_user_mr,\n\n\tINIT_RDMA_OBJ_SIZE(ib_cq, erdma_cq, ibcq),\n\tINIT_RDMA_OBJ_SIZE(ib_pd, erdma_pd, ibpd),\n\tINIT_RDMA_OBJ_SIZE(ib_ucontext, erdma_ucontext, ibucontext),\n\tINIT_RDMA_OBJ_SIZE(ib_qp, erdma_qp, ibqp),\n};\n\nstatic int erdma_ib_device_add(struct pci_dev *pdev)\n{\n\tstruct erdma_dev *dev = pci_get_drvdata(pdev);\n\tstruct ib_device *ibdev = &dev->ibdev;\n\tu64 mac;\n\tint ret;\n\n\tret = erdma_dev_attrs_init(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = erdma_device_config(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tibdev->node_type = RDMA_NODE_RNIC;\n\tmemcpy(ibdev->node_desc, ERDMA_NODE_DESC, sizeof(ERDMA_NODE_DESC));\n\n\t \n\tibdev->phys_port_cnt = 1;\n\tibdev->num_comp_vectors = dev->attrs.irq_num - 1;\n\n\tib_set_device_ops(ibdev, &erdma_device_ops);\n\n\tINIT_LIST_HEAD(&dev->cep_list);\n\n\tspin_lock_init(&dev->lock);\n\txa_init_flags(&dev->qp_xa, XA_FLAGS_ALLOC1);\n\txa_init_flags(&dev->cq_xa, XA_FLAGS_ALLOC1);\n\tdev->next_alloc_cqn = 1;\n\tdev->next_alloc_qpn = 1;\n\n\tret = erdma_res_cb_init(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tatomic_set(&dev->num_ctx, 0);\n\n\tmac = erdma_reg_read32(dev, ERDMA_REGS_NETDEV_MAC_L_REG);\n\tmac |= (u64)erdma_reg_read32(dev, ERDMA_REGS_NETDEV_MAC_H_REG) << 32;\n\n\tu64_to_ether_addr(mac, dev->attrs.peer_addr);\n\n\tdev->reflush_wq = alloc_workqueue(\"erdma-reflush-wq\", WQ_UNBOUND,\n\t\t\t\t\t  WQ_UNBOUND_MAX_ACTIVE);\n\tif (!dev->reflush_wq) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc_workqueue;\n\t}\n\n\tret = erdma_device_register(dev);\n\tif (ret)\n\t\tgoto err_register;\n\n\treturn 0;\n\nerr_register:\n\tdestroy_workqueue(dev->reflush_wq);\nerr_alloc_workqueue:\n\txa_destroy(&dev->qp_xa);\n\txa_destroy(&dev->cq_xa);\n\n\terdma_res_cb_free(dev);\n\n\treturn ret;\n}\n\nstatic void erdma_ib_device_remove(struct pci_dev *pdev)\n{\n\tstruct erdma_dev *dev = pci_get_drvdata(pdev);\n\n\tunregister_netdevice_notifier(&dev->netdev_nb);\n\tib_unregister_device(&dev->ibdev);\n\n\tdestroy_workqueue(dev->reflush_wq);\n\terdma_res_cb_free(dev);\n\txa_destroy(&dev->qp_xa);\n\txa_destroy(&dev->cq_xa);\n}\n\nstatic int erdma_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tint ret;\n\n\tret = erdma_probe_dev(pdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = erdma_ib_device_add(pdev);\n\tif (ret) {\n\t\terdma_remove_dev(pdev);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void erdma_remove(struct pci_dev *pdev)\n{\n\terdma_ib_device_remove(pdev);\n\terdma_remove_dev(pdev);\n}\n\nstatic struct pci_driver erdma_pci_driver = {\n\t.name = DRV_MODULE_NAME,\n\t.id_table = erdma_pci_tbl,\n\t.probe = erdma_probe,\n\t.remove = erdma_remove\n};\n\nMODULE_DEVICE_TABLE(pci, erdma_pci_tbl);\n\nstatic __init int erdma_init_module(void)\n{\n\tint ret;\n\n\tret = erdma_cm_init();\n\tif (ret)\n\t\treturn ret;\n\n\tret = pci_register_driver(&erdma_pci_driver);\n\tif (ret)\n\t\terdma_cm_exit();\n\n\treturn ret;\n}\n\nstatic void __exit erdma_exit_module(void)\n{\n\tpci_unregister_driver(&erdma_pci_driver);\n\n\terdma_cm_exit();\n}\n\nmodule_init(erdma_init_module);\nmodule_exit(erdma_exit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}