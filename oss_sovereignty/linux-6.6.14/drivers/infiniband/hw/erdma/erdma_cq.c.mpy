{
  "module_name": "erdma_cq.c",
  "hash_id": "7eec5de6e793bb3eb1e562dd6336b7034e8562354fc3ea5390f7ccd170ca6741",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/erdma/erdma_cq.c",
  "human_readable_source": "\n\n \n \n \n\n#include \"erdma_verbs.h\"\n\nstatic void *get_next_valid_cqe(struct erdma_cq *cq)\n{\n\t__be32 *cqe = get_queue_entry(cq->kern_cq.qbuf, cq->kern_cq.ci,\n\t\t\t\t      cq->depth, CQE_SHIFT);\n\tu32 owner = FIELD_GET(ERDMA_CQE_HDR_OWNER_MASK,\n\t\t\t      be32_to_cpu(READ_ONCE(*cqe)));\n\n\treturn owner ^ !!(cq->kern_cq.ci & cq->depth) ? cqe : NULL;\n}\n\nstatic void notify_cq(struct erdma_cq *cq, u8 solcitied)\n{\n\tu64 db_data =\n\t\tFIELD_PREP(ERDMA_CQDB_IDX_MASK, (cq->kern_cq.notify_cnt)) |\n\t\tFIELD_PREP(ERDMA_CQDB_CQN_MASK, cq->cqn) |\n\t\tFIELD_PREP(ERDMA_CQDB_ARM_MASK, 1) |\n\t\tFIELD_PREP(ERDMA_CQDB_SOL_MASK, solcitied) |\n\t\tFIELD_PREP(ERDMA_CQDB_CMDSN_MASK, cq->kern_cq.cmdsn) |\n\t\tFIELD_PREP(ERDMA_CQDB_CI_MASK, cq->kern_cq.ci);\n\n\t*cq->kern_cq.db_record = db_data;\n\twriteq(db_data, cq->kern_cq.db);\n}\n\nint erdma_req_notify_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags flags)\n{\n\tstruct erdma_cq *cq = to_ecq(ibcq);\n\tunsigned long irq_flags;\n\tint ret = 0;\n\n\tspin_lock_irqsave(&cq->kern_cq.lock, irq_flags);\n\n\tnotify_cq(cq, (flags & IB_CQ_SOLICITED_MASK) == IB_CQ_SOLICITED);\n\n\tif ((flags & IB_CQ_REPORT_MISSED_EVENTS) && get_next_valid_cqe(cq))\n\t\tret = 1;\n\n\tcq->kern_cq.notify_cnt++;\n\n\tspin_unlock_irqrestore(&cq->kern_cq.lock, irq_flags);\n\n\treturn ret;\n}\n\nstatic const enum ib_wc_opcode wc_mapping_table[ERDMA_NUM_OPCODES] = {\n\t[ERDMA_OP_WRITE] = IB_WC_RDMA_WRITE,\n\t[ERDMA_OP_READ] = IB_WC_RDMA_READ,\n\t[ERDMA_OP_SEND] = IB_WC_SEND,\n\t[ERDMA_OP_SEND_WITH_IMM] = IB_WC_SEND,\n\t[ERDMA_OP_RECEIVE] = IB_WC_RECV,\n\t[ERDMA_OP_RECV_IMM] = IB_WC_RECV_RDMA_WITH_IMM,\n\t[ERDMA_OP_RECV_INV] = IB_WC_RECV,\n\t[ERDMA_OP_WRITE_WITH_IMM] = IB_WC_RDMA_WRITE,\n\t[ERDMA_OP_RSP_SEND_IMM] = IB_WC_RECV,\n\t[ERDMA_OP_SEND_WITH_INV] = IB_WC_SEND,\n\t[ERDMA_OP_REG_MR] = IB_WC_REG_MR,\n\t[ERDMA_OP_LOCAL_INV] = IB_WC_LOCAL_INV,\n\t[ERDMA_OP_READ_WITH_INV] = IB_WC_RDMA_READ,\n\t[ERDMA_OP_ATOMIC_CAS] = IB_WC_COMP_SWAP,\n\t[ERDMA_OP_ATOMIC_FAA] = IB_WC_FETCH_ADD,\n};\n\nstatic const struct {\n\tenum erdma_wc_status erdma;\n\tenum ib_wc_status base;\n\tenum erdma_vendor_err vendor;\n} map_cqe_status[ERDMA_NUM_WC_STATUS] = {\n\t{ ERDMA_WC_SUCCESS, IB_WC_SUCCESS, ERDMA_WC_VENDOR_NO_ERR },\n\t{ ERDMA_WC_GENERAL_ERR, IB_WC_GENERAL_ERR, ERDMA_WC_VENDOR_NO_ERR },\n\t{ ERDMA_WC_RECV_WQE_FORMAT_ERR, IB_WC_GENERAL_ERR,\n\t  ERDMA_WC_VENDOR_INVALID_RQE },\n\t{ ERDMA_WC_RECV_STAG_INVALID_ERR, IB_WC_REM_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_RQE_INVALID_STAG },\n\t{ ERDMA_WC_RECV_ADDR_VIOLATION_ERR, IB_WC_REM_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_RQE_ADDR_VIOLATION },\n\t{ ERDMA_WC_RECV_RIGHT_VIOLATION_ERR, IB_WC_REM_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_RQE_ACCESS_RIGHT_ERR },\n\t{ ERDMA_WC_RECV_PDID_ERR, IB_WC_REM_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_RQE_INVALID_PD },\n\t{ ERDMA_WC_RECV_WARRPING_ERR, IB_WC_REM_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_RQE_WRAP_ERR },\n\t{ ERDMA_WC_SEND_WQE_FORMAT_ERR, IB_WC_LOC_QP_OP_ERR,\n\t  ERDMA_WC_VENDOR_INVALID_SQE },\n\t{ ERDMA_WC_SEND_WQE_ORD_EXCEED, IB_WC_GENERAL_ERR,\n\t  ERDMA_WC_VENDOR_ZERO_ORD },\n\t{ ERDMA_WC_SEND_STAG_INVALID_ERR, IB_WC_LOC_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_SQE_INVALID_STAG },\n\t{ ERDMA_WC_SEND_ADDR_VIOLATION_ERR, IB_WC_LOC_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_SQE_ADDR_VIOLATION },\n\t{ ERDMA_WC_SEND_RIGHT_VIOLATION_ERR, IB_WC_LOC_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_SQE_ACCESS_ERR },\n\t{ ERDMA_WC_SEND_PDID_ERR, IB_WC_LOC_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_SQE_INVALID_PD },\n\t{ ERDMA_WC_SEND_WARRPING_ERR, IB_WC_LOC_ACCESS_ERR,\n\t  ERDMA_WC_VENDOR_SQE_WARP_ERR },\n\t{ ERDMA_WC_FLUSH_ERR, IB_WC_WR_FLUSH_ERR, ERDMA_WC_VENDOR_NO_ERR },\n\t{ ERDMA_WC_RETRY_EXC_ERR, IB_WC_RETRY_EXC_ERR, ERDMA_WC_VENDOR_NO_ERR },\n};\n\n#define ERDMA_POLLCQ_NO_QP 1\n\nstatic int erdma_poll_one_cqe(struct erdma_cq *cq, struct ib_wc *wc)\n{\n\tstruct erdma_dev *dev = to_edev(cq->ibcq.device);\n\tu8 opcode, syndrome, qtype;\n\tstruct erdma_kqp *kern_qp;\n\tstruct erdma_cqe *cqe;\n\tstruct erdma_qp *qp;\n\tu16 wqe_idx, depth;\n\tu32 qpn, cqe_hdr;\n\tu64 *id_table;\n\tu64 *wqe_hdr;\n\n\tcqe = get_next_valid_cqe(cq);\n\tif (!cqe)\n\t\treturn -EAGAIN;\n\n\tcq->kern_cq.ci++;\n\n\t \n\tdma_rmb();\n\n\tqpn = be32_to_cpu(cqe->qpn);\n\twqe_idx = be32_to_cpu(cqe->qe_idx);\n\tcqe_hdr = be32_to_cpu(cqe->hdr);\n\n\tqp = find_qp_by_qpn(dev, qpn);\n\tif (!qp)\n\t\treturn ERDMA_POLLCQ_NO_QP;\n\n\tkern_qp = &qp->kern_qp;\n\n\tqtype = FIELD_GET(ERDMA_CQE_HDR_QTYPE_MASK, cqe_hdr);\n\tsyndrome = FIELD_GET(ERDMA_CQE_HDR_SYNDROME_MASK, cqe_hdr);\n\topcode = FIELD_GET(ERDMA_CQE_HDR_OPCODE_MASK, cqe_hdr);\n\n\tif (qtype == ERDMA_CQE_QTYPE_SQ) {\n\t\tid_table = kern_qp->swr_tbl;\n\t\tdepth = qp->attrs.sq_size;\n\t\twqe_hdr = get_queue_entry(qp->kern_qp.sq_buf, wqe_idx,\n\t\t\t\t\t  qp->attrs.sq_size, SQEBB_SHIFT);\n\t\tkern_qp->sq_ci =\n\t\t\tFIELD_GET(ERDMA_SQE_HDR_WQEBB_CNT_MASK, *wqe_hdr) +\n\t\t\twqe_idx + 1;\n\t} else {\n\t\tid_table = kern_qp->rwr_tbl;\n\t\tdepth = qp->attrs.rq_size;\n\t}\n\twc->wr_id = id_table[wqe_idx & (depth - 1)];\n\twc->byte_len = be32_to_cpu(cqe->size);\n\n\twc->wc_flags = 0;\n\n\twc->opcode = wc_mapping_table[opcode];\n\tif (opcode == ERDMA_OP_RECV_IMM || opcode == ERDMA_OP_RSP_SEND_IMM) {\n\t\twc->ex.imm_data = cpu_to_be32(le32_to_cpu(cqe->imm_data));\n\t\twc->wc_flags |= IB_WC_WITH_IMM;\n\t} else if (opcode == ERDMA_OP_RECV_INV) {\n\t\twc->ex.invalidate_rkey = be32_to_cpu(cqe->inv_rkey);\n\t\twc->wc_flags |= IB_WC_WITH_INVALIDATE;\n\t}\n\n\tif (syndrome >= ERDMA_NUM_WC_STATUS)\n\t\tsyndrome = ERDMA_WC_GENERAL_ERR;\n\n\twc->status = map_cqe_status[syndrome].base;\n\twc->vendor_err = map_cqe_status[syndrome].vendor;\n\twc->qp = &qp->ibqp;\n\n\treturn 0;\n}\n\nint erdma_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc)\n{\n\tstruct erdma_cq *cq = to_ecq(ibcq);\n\tunsigned long flags;\n\tint npolled, ret;\n\n\tspin_lock_irqsave(&cq->kern_cq.lock, flags);\n\n\tfor (npolled = 0; npolled < num_entries;) {\n\t\tret = erdma_poll_one_cqe(cq, wc + npolled);\n\n\t\tif (ret == -EAGAIN)  \n\t\t\tbreak;\n\t\telse if (ret)  \n\t\t\tcontinue;\n\n\t\tnpolled++;\n\t}\n\n\tspin_unlock_irqrestore(&cq->kern_cq.lock, flags);\n\n\treturn npolled;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}