{
  "module_name": "main.c",
  "hash_id": "725e99434a80c6f8847149ebba1594f37d20c7a60433bac734e5460a615e14bc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/irdma/main.c",
  "human_readable_source": "\n \n#include \"main.h\"\n#include \"../../../net/ethernet/intel/ice/ice.h\"\n\nMODULE_ALIAS(\"i40iw\");\nMODULE_AUTHOR(\"Intel Corporation, <e1000-rdma@lists.sourceforge.net>\");\nMODULE_DESCRIPTION(\"Intel(R) Ethernet Protocol Driver for RDMA\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n\nstatic struct notifier_block irdma_inetaddr_notifier = {\n\t.notifier_call = irdma_inetaddr_event\n};\n\nstatic struct notifier_block irdma_inetaddr6_notifier = {\n\t.notifier_call = irdma_inet6addr_event\n};\n\nstatic struct notifier_block irdma_net_notifier = {\n\t.notifier_call = irdma_net_event\n};\n\nstatic struct notifier_block irdma_netdevice_notifier = {\n\t.notifier_call = irdma_netdevice_event\n};\n\nstatic void irdma_register_notifiers(void)\n{\n\tregister_inetaddr_notifier(&irdma_inetaddr_notifier);\n\tregister_inet6addr_notifier(&irdma_inetaddr6_notifier);\n\tregister_netevent_notifier(&irdma_net_notifier);\n\tregister_netdevice_notifier(&irdma_netdevice_notifier);\n}\n\nstatic void irdma_unregister_notifiers(void)\n{\n\tunregister_netevent_notifier(&irdma_net_notifier);\n\tunregister_inetaddr_notifier(&irdma_inetaddr_notifier);\n\tunregister_inet6addr_notifier(&irdma_inetaddr6_notifier);\n\tunregister_netdevice_notifier(&irdma_netdevice_notifier);\n}\n\nstatic void irdma_prep_tc_change(struct irdma_device *iwdev)\n{\n\tiwdev->vsi.tc_change_pending = true;\n\tirdma_sc_suspend_resume_qps(&iwdev->vsi, IRDMA_OP_SUSPEND);\n\n\t \n\twait_event_timeout(iwdev->suspend_wq,\n\t\t\t   !atomic_read(&iwdev->vsi.qp_suspend_reqs),\n\t\t\t   msecs_to_jiffies(IRDMA_EVENT_TIMEOUT_MS));\n\tirdma_ws_reset(&iwdev->vsi);\n}\n\nstatic void irdma_log_invalid_mtu(u16 mtu, struct irdma_sc_dev *dev)\n{\n\tif (mtu < IRDMA_MIN_MTU_IPV4)\n\t\tibdev_warn(to_ibdev(dev), \"MTU setting [%d] too low for RDMA traffic. Minimum MTU is 576 for IPv4\\n\", mtu);\n\telse if (mtu < IRDMA_MIN_MTU_IPV6)\n\t\tibdev_warn(to_ibdev(dev), \"MTU setting [%d] too low for RDMA traffic. Minimum MTU is 1280 for IPv6\\\\n\", mtu);\n}\n\nstatic void irdma_fill_qos_info(struct irdma_l2params *l2params,\n\t\t\t\tstruct iidc_qos_params *qos_info)\n{\n\tint i;\n\n\tl2params->num_tc = qos_info->num_tc;\n\tl2params->vsi_prio_type = qos_info->vport_priority_type;\n\tl2params->vsi_rel_bw = qos_info->vport_relative_bw;\n\tfor (i = 0; i < l2params->num_tc; i++) {\n\t\tl2params->tc_info[i].egress_virt_up =\n\t\t\tqos_info->tc_info[i].egress_virt_up;\n\t\tl2params->tc_info[i].ingress_virt_up =\n\t\t\tqos_info->tc_info[i].ingress_virt_up;\n\t\tl2params->tc_info[i].prio_type = qos_info->tc_info[i].prio_type;\n\t\tl2params->tc_info[i].rel_bw = qos_info->tc_info[i].rel_bw;\n\t\tl2params->tc_info[i].tc_ctx = qos_info->tc_info[i].tc_ctx;\n\t}\n\tfor (i = 0; i < IIDC_MAX_USER_PRIORITY; i++)\n\t\tl2params->up2tc[i] = qos_info->up2tc[i];\n\tif (qos_info->pfc_mode == IIDC_DSCP_PFC_MODE) {\n\t\tl2params->dscp_mode = true;\n\t\tmemcpy(l2params->dscp_map, qos_info->dscp_map, sizeof(l2params->dscp_map));\n\t}\n}\n\nstatic void irdma_iidc_event_handler(struct ice_pf *pf, struct iidc_event *event)\n{\n\tstruct irdma_device *iwdev = dev_get_drvdata(&pf->adev->dev);\n\tstruct irdma_l2params l2params = {};\n\n\tif (*event->type & BIT(IIDC_EVENT_AFTER_MTU_CHANGE)) {\n\t\tibdev_dbg(&iwdev->ibdev, \"CLNT: new MTU = %d\\n\", iwdev->netdev->mtu);\n\t\tif (iwdev->vsi.mtu != iwdev->netdev->mtu) {\n\t\t\tl2params.mtu = iwdev->netdev->mtu;\n\t\t\tl2params.mtu_changed = true;\n\t\t\tirdma_log_invalid_mtu(l2params.mtu, &iwdev->rf->sc_dev);\n\t\t\tirdma_change_l2params(&iwdev->vsi, &l2params);\n\t\t}\n\t} else if (*event->type & BIT(IIDC_EVENT_BEFORE_TC_CHANGE)) {\n\t\tif (iwdev->vsi.tc_change_pending)\n\t\t\treturn;\n\n\t\tirdma_prep_tc_change(iwdev);\n\t} else if (*event->type & BIT(IIDC_EVENT_AFTER_TC_CHANGE)) {\n\t\tstruct iidc_qos_params qos_info = {};\n\n\t\tif (!iwdev->vsi.tc_change_pending)\n\t\t\treturn;\n\n\t\tl2params.tc_changed = true;\n\t\tibdev_dbg(&iwdev->ibdev, \"CLNT: TC Change\\n\");\n\t\tice_get_qos_params(pf, &qos_info);\n\t\tirdma_fill_qos_info(&l2params, &qos_info);\n\t\tif (iwdev->rf->protocol_used != IRDMA_IWARP_PROTOCOL_ONLY)\n\t\t\tiwdev->dcb_vlan_mode = qos_info.num_tc > 1 && !l2params.dscp_mode;\n\t\tirdma_change_l2params(&iwdev->vsi, &l2params);\n\t} else if (*event->type & BIT(IIDC_EVENT_CRIT_ERR)) {\n\t\tibdev_warn(&iwdev->ibdev, \"ICE OICR event notification: oicr = 0x%08x\\n\",\n\t\t\t   event->reg);\n\t\tif (event->reg & IRDMAPFINT_OICR_PE_CRITERR_M) {\n\t\t\tu32 pe_criterr;\n\n\t\t\tpe_criterr = readl(iwdev->rf->sc_dev.hw_regs[IRDMA_GLPE_CRITERR]);\n#define IRDMA_Q1_RESOURCE_ERR 0x0001024d\n\t\t\tif (pe_criterr != IRDMA_Q1_RESOURCE_ERR) {\n\t\t\t\tibdev_err(&iwdev->ibdev, \"critical PE Error, GLPE_CRITERR=0x%08x\\n\",\n\t\t\t\t\t  pe_criterr);\n\t\t\t\tiwdev->rf->reset = true;\n\t\t\t} else {\n\t\t\t\tibdev_warn(&iwdev->ibdev, \"Q1 Resource Check\\n\");\n\t\t\t}\n\t\t}\n\t\tif (event->reg & IRDMAPFINT_OICR_HMC_ERR_M) {\n\t\t\tibdev_err(&iwdev->ibdev, \"HMC Error\\n\");\n\t\t\tiwdev->rf->reset = true;\n\t\t}\n\t\tif (event->reg & IRDMAPFINT_OICR_PE_PUSH_M) {\n\t\t\tibdev_err(&iwdev->ibdev, \"PE Push Error\\n\");\n\t\t\tiwdev->rf->reset = true;\n\t\t}\n\t\tif (iwdev->rf->reset)\n\t\t\tiwdev->rf->gen_ops.request_reset(iwdev->rf);\n\t}\n}\n\n \nstatic void irdma_request_reset(struct irdma_pci_f *rf)\n{\n\tstruct ice_pf *pf = rf->cdev;\n\n\tibdev_warn(&rf->iwdev->ibdev, \"Requesting a reset\\n\");\n\tice_rdma_request_reset(pf, IIDC_PFR);\n}\n\n \nstatic int irdma_lan_register_qset(struct irdma_sc_vsi *vsi,\n\t\t\t\t   struct irdma_ws_node *tc_node)\n{\n\tstruct irdma_device *iwdev = vsi->back_vsi;\n\tstruct ice_pf *pf = iwdev->rf->cdev;\n\tstruct iidc_rdma_qset_params qset = {};\n\tint ret;\n\n\tqset.qs_handle = tc_node->qs_handle;\n\tqset.tc = tc_node->traffic_class;\n\tqset.vport_id = vsi->vsi_idx;\n\tret = ice_add_rdma_qset(pf, &qset);\n\tif (ret) {\n\t\tibdev_dbg(&iwdev->ibdev, \"WS: LAN alloc_res for rdma qset failed.\\n\");\n\t\treturn ret;\n\t}\n\n\ttc_node->l2_sched_node_id = qset.teid;\n\tvsi->qos[tc_node->user_pri].l2_sched_node_id = qset.teid;\n\n\treturn 0;\n}\n\n \nstatic void irdma_lan_unregister_qset(struct irdma_sc_vsi *vsi,\n\t\t\t\t      struct irdma_ws_node *tc_node)\n{\n\tstruct irdma_device *iwdev = vsi->back_vsi;\n\tstruct ice_pf *pf = iwdev->rf->cdev;\n\tstruct iidc_rdma_qset_params qset = {};\n\n\tqset.qs_handle = tc_node->qs_handle;\n\tqset.tc = tc_node->traffic_class;\n\tqset.vport_id = vsi->vsi_idx;\n\tqset.teid = tc_node->l2_sched_node_id;\n\n\tif (ice_del_rdma_qset(pf, &qset))\n\t\tibdev_dbg(&iwdev->ibdev, \"WS: LAN free_res for rdma qset failed.\\n\");\n}\n\nstatic void irdma_remove(struct auxiliary_device *aux_dev)\n{\n\tstruct iidc_auxiliary_dev *iidc_adev = container_of(aux_dev,\n\t\t\t\t\t\t\t    struct iidc_auxiliary_dev,\n\t\t\t\t\t\t\t    adev);\n\tstruct ice_pf *pf = iidc_adev->pf;\n\tstruct irdma_device *iwdev = auxiliary_get_drvdata(aux_dev);\n\n\tirdma_ib_unregister_device(iwdev);\n\tice_rdma_update_vsi_filter(pf, iwdev->vsi_num, false);\n\n\tpr_debug(\"INIT: Gen2 PF[%d] device remove success\\n\", PCI_FUNC(pf->pdev->devfn));\n}\n\nstatic void irdma_fill_device_info(struct irdma_device *iwdev, struct ice_pf *pf,\n\t\t\t\t   struct ice_vsi *vsi)\n{\n\tstruct irdma_pci_f *rf = iwdev->rf;\n\n\trf->cdev = pf;\n\trf->gen_ops.register_qset = irdma_lan_register_qset;\n\trf->gen_ops.unregister_qset = irdma_lan_unregister_qset;\n\trf->hw.hw_addr = pf->hw.hw_addr;\n\trf->pcidev = pf->pdev;\n\trf->msix_count =  pf->num_rdma_msix;\n\trf->pf_id = pf->hw.pf_id;\n\trf->msix_entries = &pf->msix_entries[pf->rdma_base_vector];\n\trf->default_vsi.vsi_idx = vsi->vsi_num;\n\trf->protocol_used = pf->rdma_mode & IIDC_RDMA_PROTOCOL_ROCEV2 ?\n\t\t\t    IRDMA_ROCE_PROTOCOL_ONLY : IRDMA_IWARP_PROTOCOL_ONLY;\n\trf->rdma_ver = IRDMA_GEN_2;\n\trf->rsrc_profile = IRDMA_HMC_PROFILE_DEFAULT;\n\trf->rst_to = IRDMA_RST_TIMEOUT_HZ;\n\trf->gen_ops.request_reset = irdma_request_reset;\n\trf->limits_sel = 7;\n\trf->iwdev = iwdev;\n\tmutex_init(&iwdev->ah_tbl_lock);\n\tiwdev->netdev = vsi->netdev;\n\tiwdev->vsi_num = vsi->vsi_num;\n\tiwdev->init_state = INITIAL_STATE;\n\tiwdev->roce_cwnd = IRDMA_ROCE_CWND_DEFAULT;\n\tiwdev->roce_ackcreds = IRDMA_ROCE_ACKCREDS_DEFAULT;\n\tiwdev->rcv_wnd = IRDMA_CM_DEFAULT_RCV_WND_SCALED;\n\tiwdev->rcv_wscale = IRDMA_CM_DEFAULT_RCV_WND_SCALE;\n\tif (rf->protocol_used == IRDMA_ROCE_PROTOCOL_ONLY)\n\t\tiwdev->roce_mode = true;\n}\n\nstatic int irdma_probe(struct auxiliary_device *aux_dev, const struct auxiliary_device_id *id)\n{\n\tstruct iidc_auxiliary_dev *iidc_adev = container_of(aux_dev,\n\t\t\t\t\t\t\t    struct iidc_auxiliary_dev,\n\t\t\t\t\t\t\t    adev);\n\tstruct ice_pf *pf = iidc_adev->pf;\n\tstruct ice_vsi *vsi = ice_get_main_vsi(pf);\n\tstruct iidc_qos_params qos_info = {};\n\tstruct irdma_device *iwdev;\n\tstruct irdma_pci_f *rf;\n\tstruct irdma_l2params l2params = {};\n\tint err;\n\n\tif (!vsi)\n\t\treturn -EIO;\n\tiwdev = ib_alloc_device(irdma_device, ibdev);\n\tif (!iwdev)\n\t\treturn -ENOMEM;\n\tiwdev->rf = kzalloc(sizeof(*rf), GFP_KERNEL);\n\tif (!iwdev->rf) {\n\t\tib_dealloc_device(&iwdev->ibdev);\n\t\treturn -ENOMEM;\n\t}\n\n\tirdma_fill_device_info(iwdev, pf, vsi);\n\trf = iwdev->rf;\n\n\terr = irdma_ctrl_init_hw(rf);\n\tif (err)\n\t\tgoto err_ctrl_init;\n\n\tl2params.mtu = iwdev->netdev->mtu;\n\tice_get_qos_params(pf, &qos_info);\n\tirdma_fill_qos_info(&l2params, &qos_info);\n\tif (iwdev->rf->protocol_used != IRDMA_IWARP_PROTOCOL_ONLY)\n\t\tiwdev->dcb_vlan_mode = l2params.num_tc > 1 && !l2params.dscp_mode;\n\n\terr = irdma_rt_init_hw(iwdev, &l2params);\n\tif (err)\n\t\tgoto err_rt_init;\n\n\terr = irdma_ib_register_device(iwdev);\n\tif (err)\n\t\tgoto err_ibreg;\n\n\tice_rdma_update_vsi_filter(pf, iwdev->vsi_num, true);\n\n\tibdev_dbg(&iwdev->ibdev, \"INIT: Gen2 PF[%d] device probe success\\n\", PCI_FUNC(rf->pcidev->devfn));\n\tauxiliary_set_drvdata(aux_dev, iwdev);\n\n\treturn 0;\n\nerr_ibreg:\n\tirdma_rt_deinit_hw(iwdev);\nerr_rt_init:\n\tirdma_ctrl_deinit_hw(rf);\nerr_ctrl_init:\n\tkfree(iwdev->rf);\n\tib_dealloc_device(&iwdev->ibdev);\n\n\treturn err;\n}\n\nstatic const struct auxiliary_device_id irdma_auxiliary_id_table[] = {\n\t{.name = \"ice.iwarp\", },\n\t{.name = \"ice.roce\", },\n\t{},\n};\n\nMODULE_DEVICE_TABLE(auxiliary, irdma_auxiliary_id_table);\n\nstatic struct iidc_auxiliary_drv irdma_auxiliary_drv = {\n\t.adrv = {\n\t    .id_table = irdma_auxiliary_id_table,\n\t    .probe = irdma_probe,\n\t    .remove = irdma_remove,\n\t},\n\t.event_handler = irdma_iidc_event_handler,\n};\n\nstatic int __init irdma_init_module(void)\n{\n\tint ret;\n\n\tret = auxiliary_driver_register(&i40iw_auxiliary_drv);\n\tif (ret) {\n\t\tpr_err(\"Failed i40iw(gen_1) auxiliary_driver_register() ret=%d\\n\",\n\t\t       ret);\n\t\treturn ret;\n\t}\n\n\tret = auxiliary_driver_register(&irdma_auxiliary_drv.adrv);\n\tif (ret) {\n\t\tauxiliary_driver_unregister(&i40iw_auxiliary_drv);\n\t\tpr_err(\"Failed irdma auxiliary_driver_register() ret=%d\\n\",\n\t\t       ret);\n\t\treturn ret;\n\t}\n\n\tirdma_register_notifiers();\n\n\treturn 0;\n}\n\nstatic void __exit irdma_exit_module(void)\n{\n\tirdma_unregister_notifiers();\n\tauxiliary_driver_unregister(&irdma_auxiliary_drv.adrv);\n\tauxiliary_driver_unregister(&i40iw_auxiliary_drv);\n}\n\nmodule_init(irdma_init_module);\nmodule_exit(irdma_exit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}