{
  "module_name": "main.h",
  "hash_id": "d0c46768f7f450f0ee1ad51f862d52de763db0af08ac7ea00ed0fc45b811e506",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/irdma/main.h",
  "human_readable_source": " \n \n#ifndef IRDMA_MAIN_H\n#define IRDMA_MAIN_H\n\n#include <linux/ip.h>\n#include <linux/tcp.h>\n#include <linux/if_vlan.h>\n#include <net/addrconf.h>\n#include <net/netevent.h>\n#include <net/tcp.h>\n#include <net/ip6_route.h>\n#include <net/flow.h>\n#include <net/secure_seq.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/inetdevice.h>\n#include <linux/spinlock.h>\n#include <linux/kernel.h>\n#include <linux/delay.h>\n#include <linux/pci.h>\n#include <linux/dma-mapping.h>\n#include <linux/workqueue.h>\n#include <linux/slab.h>\n#include <linux/io.h>\n#include <linux/crc32c.h>\n#include <linux/kthread.h>\n#ifndef CONFIG_64BIT\n#include <linux/io-64-nonatomic-lo-hi.h>\n#endif\n#include <linux/auxiliary_bus.h>\n#include <linux/net/intel/iidc.h>\n#include <crypto/hash.h>\n#include <rdma/ib_smi.h>\n#include <rdma/ib_verbs.h>\n#include <rdma/ib_pack.h>\n#include <rdma/rdma_cm.h>\n#include <rdma/iw_cm.h>\n#include <rdma/ib_user_verbs.h>\n#include <rdma/ib_umem.h>\n#include <rdma/ib_cache.h>\n#include <rdma/uverbs_ioctl.h>\n#include \"osdep.h\"\n#include \"defs.h\"\n#include \"hmc.h\"\n#include \"type.h\"\n#include \"ws.h\"\n#include \"protos.h\"\n#include \"pble.h\"\n#include \"cm.h\"\n#include <rdma/irdma-abi.h>\n#include \"verbs.h\"\n#include \"user.h\"\n#include \"puda.h\"\n\nextern struct auxiliary_driver i40iw_auxiliary_drv;\n\n#define IRDMA_FW_VER_DEFAULT\t2\n#define IRDMA_HW_VER\t        2\n\n#define IRDMA_ARP_ADD\t\t1\n#define IRDMA_ARP_DELETE\t2\n#define IRDMA_ARP_RESOLVE\t3\n\n#define IRDMA_MACIP_ADD\t\t1\n#define IRDMA_MACIP_DELETE\t2\n\n#define IW_CCQ_SIZE\t(IRDMA_CQP_SW_SQSIZE_2048 + 1)\n#define IW_CEQ_SIZE\t2048\n#define IW_AEQ_SIZE\t2048\n\n#define RX_BUF_SIZE\t(1536 + 8)\n#define IW_REG0_SIZE\t(4 * 1024)\n#define IW_TX_TIMEOUT\t(6 * HZ)\n#define IW_FIRST_QPN\t1\n\n#define IW_SW_CONTEXT_ALIGN\t1024\n\n#define MAX_DPC_ITERATIONS\t128\n\n#define IRDMA_EVENT_TIMEOUT_MS\t\t5000\n#define IRDMA_VCHNL_EVENT_TIMEOUT\t100000\n#define IRDMA_RST_TIMEOUT_HZ\t\t4\n\n#define\tIRDMA_NO_QSET\t0xffff\n\n#define IW_CFG_FPM_QP_COUNT\t\t32768\n#define IRDMA_MAX_PAGES_PER_FMR\t\t262144\n#define IRDMA_MIN_PAGES_PER_FMR\t\t1\n#define IRDMA_CQP_COMPL_RQ_WQE_FLUSHED\t2\n#define IRDMA_CQP_COMPL_SQ_WQE_FLUSHED\t3\n\n#define IRDMA_Q_TYPE_PE_AEQ\t0x80\n#define IRDMA_Q_INVALID_IDX\t0xffff\n#define IRDMA_REM_ENDPOINT_TRK_QPID\t3\n\n#define IRDMA_DRV_OPT_ENA_MPA_VER_0\t\t0x00000001\n#define IRDMA_DRV_OPT_DISABLE_MPA_CRC\t\t0x00000002\n#define IRDMA_DRV_OPT_DISABLE_FIRST_WRITE\t0x00000004\n#define IRDMA_DRV_OPT_DISABLE_INTF\t\t0x00000008\n#define IRDMA_DRV_OPT_ENA_MSI\t\t\t0x00000010\n#define IRDMA_DRV_OPT_DUAL_LOGICAL_PORT\t\t0x00000020\n#define IRDMA_DRV_OPT_NO_INLINE_DATA\t\t0x00000080\n#define IRDMA_DRV_OPT_DISABLE_INT_MOD\t\t0x00000100\n#define IRDMA_DRV_OPT_DISABLE_VIRT_WQ\t\t0x00000200\n#define IRDMA_DRV_OPT_ENA_PAU\t\t\t0x00000400\n#define IRDMA_DRV_OPT_MCAST_LOGPORT_MAP\t\t0x00000800\n\n#define IW_HMC_OBJ_TYPE_NUM\tARRAY_SIZE(iw_hmc_obj_types)\n#define IRDMA_ROCE_CWND_DEFAULT\t\t\t0x400\n#define IRDMA_ROCE_ACKCREDS_DEFAULT\t\t0x1E\n\n#define IRDMA_FLUSH_SQ\t\tBIT(0)\n#define IRDMA_FLUSH_RQ\t\tBIT(1)\n#define IRDMA_REFLUSH\t\tBIT(2)\n#define IRDMA_FLUSH_WAIT\tBIT(3)\n\n#define IRDMA_IRQ_NAME_STR_LEN (64)\n\nenum init_completion_state {\n\tINVALID_STATE = 0,\n\tINITIAL_STATE,\n\tCQP_CREATED,\n\tHMC_OBJS_CREATED,\n\tHW_RSRC_INITIALIZED,\n\tCCQ_CREATED,\n\tCEQ0_CREATED,  \n\tILQ_CREATED,\n\tIEQ_CREATED,\n\tCEQS_CREATED,\n\tPBLE_CHUNK_MEM,\n\tAEQ_CREATED,\n\tIP_ADDR_REGISTERED,   \n};\n\nstruct irdma_rsrc_limits {\n\tu32 qplimit;\n\tu32 mrlimit;\n\tu32 cqlimit;\n};\n\nstruct irdma_cqp_err_info {\n\tu16 maj;\n\tu16 min;\n\tconst char *desc;\n};\n\nstruct irdma_cqp_compl_info {\n\tu32 op_ret_val;\n\tu16 maj_err_code;\n\tu16 min_err_code;\n\tbool error;\n\tu8 op_code;\n};\n\nstruct irdma_cqp_request {\n\tstruct cqp_cmds_info info;\n\twait_queue_head_t waitq;\n\tstruct list_head list;\n\trefcount_t refcnt;\n\tvoid (*callback_fcn)(struct irdma_cqp_request *cqp_request);\n\tvoid *param;\n\tstruct irdma_cqp_compl_info compl_info;\n\tbool request_done;  \n\tbool waiting:1;\n\tbool dynamic:1;\n};\n\nstruct irdma_cqp {\n\tstruct irdma_sc_cqp sc_cqp;\n\tspinlock_t req_lock;  \n\tspinlock_t compl_lock;  \n\twait_queue_head_t waitq;\n\twait_queue_head_t remove_wq;\n\tstruct irdma_dma_mem sq;\n\tstruct irdma_dma_mem host_ctx;\n\tu64 *scratch_array;\n\tstruct irdma_cqp_request *cqp_requests;\n\tstruct list_head cqp_avail_reqs;\n\tstruct list_head cqp_pending_reqs;\n};\n\nstruct irdma_ccq {\n\tstruct irdma_sc_cq sc_cq;\n\tstruct irdma_dma_mem mem_cq;\n\tstruct irdma_dma_mem shadow_area;\n};\n\nstruct irdma_ceq {\n\tstruct irdma_sc_ceq sc_ceq;\n\tstruct irdma_dma_mem mem;\n\tu32 irq;\n\tu32 msix_idx;\n\tstruct irdma_pci_f *rf;\n\tstruct tasklet_struct dpc_tasklet;\n\tspinlock_t ce_lock;  \n};\n\nstruct irdma_aeq {\n\tstruct irdma_sc_aeq sc_aeq;\n\tstruct irdma_dma_mem mem;\n\tstruct irdma_pble_alloc palloc;\n\tbool virtual_map;\n};\n\nstruct irdma_arp_entry {\n\tu32 ip_addr[4];\n\tu8 mac_addr[ETH_ALEN];\n};\n\nstruct irdma_msix_vector {\n\tu32 idx;\n\tu32 irq;\n\tu32 cpu_affinity;\n\tu32 ceq_id;\n\tcpumask_t mask;\n\tchar name[IRDMA_IRQ_NAME_STR_LEN];\n};\n\nstruct irdma_mc_table_info {\n\tu32 mgn;\n\tu32 dest_ip[4];\n\tbool lan_fwd:1;\n\tbool ipv4_valid:1;\n};\n\nstruct mc_table_list {\n\tstruct list_head list;\n\tstruct irdma_mc_table_info mc_info;\n\tstruct irdma_mcast_grp_info mc_grp_ctx;\n};\n\nstruct irdma_qv_info {\n\tu32 v_idx;  \n\tu16 ceq_idx;\n\tu16 aeq_idx;\n\tu8 itr_idx;\n};\n\nstruct irdma_qvlist_info {\n\tu32 num_vectors;\n\tstruct irdma_qv_info qv_info[];\n};\n\nstruct irdma_gen_ops {\n\tvoid (*request_reset)(struct irdma_pci_f *rf);\n\tint (*register_qset)(struct irdma_sc_vsi *vsi,\n\t\t\t     struct irdma_ws_node *tc_node);\n\tvoid (*unregister_qset)(struct irdma_sc_vsi *vsi,\n\t\t\t\tstruct irdma_ws_node *tc_node);\n};\n\nstruct irdma_pci_f {\n\tbool reset:1;\n\tbool rsrc_created:1;\n\tbool msix_shared:1;\n\tu8 rsrc_profile;\n\tu8 *hmc_info_mem;\n\tu8 *mem_rsrc;\n\tu8 rdma_ver;\n\tu8 rst_to;\n\tu8 pf_id;\n\tenum irdma_protocol_used protocol_used;\n\tu32 sd_type;\n\tu32 msix_count;\n\tu32 max_mr;\n\tu32 max_qp;\n\tu32 max_cq;\n\tu32 max_ah;\n\tu32 next_ah;\n\tu32 max_mcg;\n\tu32 next_mcg;\n\tu32 max_pd;\n\tu32 next_qp;\n\tu32 next_cq;\n\tu32 next_pd;\n\tu32 max_mr_size;\n\tu32 max_cqe;\n\tu32 mr_stagmask;\n\tu32 used_pds;\n\tu32 used_cqs;\n\tu32 used_mrs;\n\tu32 used_qps;\n\tu32 arp_table_size;\n\tu32 next_arp_index;\n\tu32 ceqs_count;\n\tu32 next_ws_node_id;\n\tu32 max_ws_node_id;\n\tu32 limits_sel;\n\tunsigned long *allocated_ws_nodes;\n\tunsigned long *allocated_qps;\n\tunsigned long *allocated_cqs;\n\tunsigned long *allocated_mrs;\n\tunsigned long *allocated_pds;\n\tunsigned long *allocated_mcgs;\n\tunsigned long *allocated_ahs;\n\tunsigned long *allocated_arps;\n\tenum init_completion_state init_state;\n\tstruct irdma_sc_dev sc_dev;\n\tstruct pci_dev *pcidev;\n\tvoid *cdev;\n\tstruct irdma_hw hw;\n\tstruct irdma_cqp cqp;\n\tstruct irdma_ccq ccq;\n\tstruct irdma_aeq aeq;\n\tstruct irdma_ceq *ceqlist;\n\tstruct irdma_hmc_pble_rsrc *pble_rsrc;\n\tstruct irdma_arp_entry *arp_table;\n\tspinlock_t arp_lock;  \n\tspinlock_t rsrc_lock;  \n\tspinlock_t qptable_lock;  \n\tspinlock_t cqtable_lock;  \n\tstruct irdma_qp **qp_table;\n\tstruct irdma_cq **cq_table;\n\tspinlock_t qh_list_lock;  \n\tstruct mc_table_list mc_qht_list;\n\tstruct irdma_msix_vector *iw_msixtbl;\n\tstruct irdma_qvlist_info *iw_qvlist;\n\tstruct tasklet_struct dpc_tasklet;\n\tstruct msix_entry *msix_entries;\n\tstruct irdma_dma_mem obj_mem;\n\tstruct irdma_dma_mem obj_next;\n\tatomic_t vchnl_msgs;\n\twait_queue_head_t vchnl_waitq;\n\tstruct workqueue_struct *cqp_cmpl_wq;\n\tstruct work_struct cqp_cmpl_work;\n\tstruct irdma_sc_vsi default_vsi;\n\tvoid *back_fcn;\n\tstruct irdma_gen_ops gen_ops;\n\tstruct irdma_device *iwdev;\n};\n\nstruct irdma_device {\n\tstruct ib_device ibdev;\n\tstruct irdma_pci_f *rf;\n\tstruct net_device *netdev;\n\tstruct workqueue_struct *cleanup_wq;\n\tstruct irdma_sc_vsi vsi;\n\tstruct irdma_cm_core cm_core;\n\tDECLARE_HASHTABLE(ah_hash_tbl, 8);\n\tstruct mutex ah_tbl_lock;  \n\tu32 roce_cwnd;\n\tu32 roce_ackcreds;\n\tu32 vendor_id;\n\tu32 vendor_part_id;\n\tu32 push_mode;\n\tu32 rcv_wnd;\n\tu16 mac_ip_table_idx;\n\tu16 vsi_num;\n\tu8 rcv_wscale;\n\tu8 iw_status;\n\tbool roce_mode:1;\n\tbool roce_dcqcn_en:1;\n\tbool dcb_vlan_mode:1;\n\tbool iw_ooo:1;\n\tenum init_completion_state init_state;\n\n\twait_queue_head_t suspend_wq;\n};\n\nstatic inline struct irdma_device *to_iwdev(struct ib_device *ibdev)\n{\n\treturn container_of(ibdev, struct irdma_device, ibdev);\n}\n\nstatic inline struct irdma_ucontext *to_ucontext(struct ib_ucontext *ibucontext)\n{\n\treturn container_of(ibucontext, struct irdma_ucontext, ibucontext);\n}\n\nstatic inline struct irdma_user_mmap_entry *\nto_irdma_mmap_entry(struct rdma_user_mmap_entry *rdma_entry)\n{\n\treturn container_of(rdma_entry, struct irdma_user_mmap_entry,\n\t\t\t    rdma_entry);\n}\n\nstatic inline struct irdma_pd *to_iwpd(struct ib_pd *ibpd)\n{\n\treturn container_of(ibpd, struct irdma_pd, ibpd);\n}\n\nstatic inline struct irdma_ah *to_iwah(struct ib_ah *ibah)\n{\n\treturn container_of(ibah, struct irdma_ah, ibah);\n}\n\nstatic inline struct irdma_mr *to_iwmr(struct ib_mr *ibmr)\n{\n\treturn container_of(ibmr, struct irdma_mr, ibmr);\n}\n\nstatic inline struct irdma_mr *to_iwmw(struct ib_mw *ibmw)\n{\n\treturn container_of(ibmw, struct irdma_mr, ibmw);\n}\n\nstatic inline struct irdma_cq *to_iwcq(struct ib_cq *ibcq)\n{\n\treturn container_of(ibcq, struct irdma_cq, ibcq);\n}\n\nstatic inline struct irdma_qp *to_iwqp(struct ib_qp *ibqp)\n{\n\treturn container_of(ibqp, struct irdma_qp, ibqp);\n}\n\nstatic inline struct irdma_pci_f *dev_to_rf(struct irdma_sc_dev *dev)\n{\n\treturn container_of(dev, struct irdma_pci_f, sc_dev);\n}\n\n \nstatic inline int irdma_alloc_rsrc(struct irdma_pci_f *rf,\n\t\t\t\t   unsigned long *rsrc_array, u32 max_rsrc,\n\t\t\t\t   u32 *req_rsrc_num, u32 *next)\n{\n\tu32 rsrc_num;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rf->rsrc_lock, flags);\n\trsrc_num = find_next_zero_bit(rsrc_array, max_rsrc, *next);\n\tif (rsrc_num >= max_rsrc) {\n\t\trsrc_num = find_first_zero_bit(rsrc_array, max_rsrc);\n\t\tif (rsrc_num >= max_rsrc) {\n\t\t\tspin_unlock_irqrestore(&rf->rsrc_lock, flags);\n\t\t\tibdev_dbg(&rf->iwdev->ibdev,\n\t\t\t\t  \"ERR: resource [%d] allocation failed\\n\",\n\t\t\t\t  rsrc_num);\n\t\t\treturn -EOVERFLOW;\n\t\t}\n\t}\n\t__set_bit(rsrc_num, rsrc_array);\n\t*next = rsrc_num + 1;\n\tif (*next == max_rsrc)\n\t\t*next = 0;\n\t*req_rsrc_num = rsrc_num;\n\tspin_unlock_irqrestore(&rf->rsrc_lock, flags);\n\n\treturn 0;\n}\n\n \nstatic inline void irdma_free_rsrc(struct irdma_pci_f *rf,\n\t\t\t\t   unsigned long *rsrc_array, u32 rsrc_num)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rf->rsrc_lock, flags);\n\t__clear_bit(rsrc_num, rsrc_array);\n\tspin_unlock_irqrestore(&rf->rsrc_lock, flags);\n}\n\nint irdma_ctrl_init_hw(struct irdma_pci_f *rf);\nvoid irdma_ctrl_deinit_hw(struct irdma_pci_f *rf);\nint irdma_rt_init_hw(struct irdma_device *iwdev,\n\t\t     struct irdma_l2params *l2params);\nvoid irdma_rt_deinit_hw(struct irdma_device *iwdev);\nvoid irdma_qp_add_ref(struct ib_qp *ibqp);\nvoid irdma_qp_rem_ref(struct ib_qp *ibqp);\nvoid irdma_free_lsmm_rsrc(struct irdma_qp *iwqp);\nstruct ib_qp *irdma_get_qp(struct ib_device *ibdev, int qpn);\nvoid irdma_flush_wqes(struct irdma_qp *iwqp, u32 flush_mask);\nvoid irdma_manage_arp_cache(struct irdma_pci_f *rf,\n\t\t\t    const unsigned char *mac_addr,\n\t\t\t    u32 *ip_addr, bool ipv4, u32 action);\nstruct irdma_apbvt_entry *irdma_add_apbvt(struct irdma_device *iwdev, u16 port);\nvoid irdma_del_apbvt(struct irdma_device *iwdev,\n\t\t     struct irdma_apbvt_entry *entry);\nstruct irdma_cqp_request *irdma_alloc_and_get_cqp_request(struct irdma_cqp *cqp,\n\t\t\t\t\t\t\t  bool wait);\nvoid irdma_free_cqp_request(struct irdma_cqp *cqp,\n\t\t\t    struct irdma_cqp_request *cqp_request);\nvoid irdma_put_cqp_request(struct irdma_cqp *cqp,\n\t\t\t   struct irdma_cqp_request *cqp_request);\nint irdma_alloc_local_mac_entry(struct irdma_pci_f *rf, u16 *mac_tbl_idx);\nint irdma_add_local_mac_entry(struct irdma_pci_f *rf, const u8 *mac_addr, u16 idx);\nvoid irdma_del_local_mac_entry(struct irdma_pci_f *rf, u16 idx);\n\nu32 irdma_initialize_hw_rsrc(struct irdma_pci_f *rf);\nvoid irdma_port_ibevent(struct irdma_device *iwdev);\nvoid irdma_cm_disconn(struct irdma_qp *qp);\n\nbool irdma_cqp_crit_err(struct irdma_sc_dev *dev, u8 cqp_cmd,\n\t\t\tu16 maj_err_code, u16 min_err_code);\nint irdma_handle_cqp_op(struct irdma_pci_f *rf,\n\t\t\tstruct irdma_cqp_request *cqp_request);\n\nint irdma_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr, int attr_mask,\n\t\t    struct ib_udata *udata);\nint irdma_modify_qp_roce(struct ib_qp *ibqp, struct ib_qp_attr *attr,\n\t\t\t int attr_mask, struct ib_udata *udata);\nvoid irdma_cq_add_ref(struct ib_cq *ibcq);\nvoid irdma_cq_rem_ref(struct ib_cq *ibcq);\nvoid irdma_cq_wq_destroy(struct irdma_pci_f *rf, struct irdma_sc_cq *cq);\n\nvoid irdma_cleanup_pending_cqp_op(struct irdma_pci_f *rf);\nint irdma_hw_modify_qp(struct irdma_device *iwdev, struct irdma_qp *iwqp,\n\t\t       struct irdma_modify_qp_info *info, bool wait);\nint irdma_qp_suspend_resume(struct irdma_sc_qp *qp, bool suspend);\nint irdma_manage_qhash(struct irdma_device *iwdev, struct irdma_cm_info *cminfo,\n\t\t       enum irdma_quad_entry_type etype,\n\t\t       enum irdma_quad_hash_manage_type mtype, void *cmnode,\n\t\t       bool wait);\nvoid irdma_receive_ilq(struct irdma_sc_vsi *vsi, struct irdma_puda_buf *rbuf);\nvoid irdma_free_sqbuf(struct irdma_sc_vsi *vsi, void *bufp);\nvoid irdma_free_qp_rsrc(struct irdma_qp *iwqp);\nint irdma_setup_cm_core(struct irdma_device *iwdev, u8 ver);\nvoid irdma_cleanup_cm_core(struct irdma_cm_core *cm_core);\nvoid irdma_next_iw_state(struct irdma_qp *iwqp, u8 state, u8 del_hash, u8 term,\n\t\t\t u8 term_len);\nint irdma_send_syn(struct irdma_cm_node *cm_node, u32 sendack);\nint irdma_send_reset(struct irdma_cm_node *cm_node);\nstruct irdma_cm_node *irdma_find_node(struct irdma_cm_core *cm_core,\n\t\t\t\t      u16 rem_port, u32 *rem_addr, u16 loc_port,\n\t\t\t\t      u32 *loc_addr, u16 vlan_id);\nint irdma_hw_flush_wqes(struct irdma_pci_f *rf, struct irdma_sc_qp *qp,\n\t\t\tstruct irdma_qp_flush_info *info, bool wait);\nvoid irdma_gen_ae(struct irdma_pci_f *rf, struct irdma_sc_qp *qp,\n\t\t  struct irdma_gen_ae_info *info, bool wait);\nvoid irdma_copy_ip_ntohl(u32 *dst, __be32 *src);\nvoid irdma_copy_ip_htonl(__be32 *dst, u32 *src);\nu16 irdma_get_vlan_ipv4(u32 *addr);\nvoid irdma_get_vlan_mac_ipv6(u32 *addr, u16 *vlan_id, u8 *mac);\nstruct ib_mr *irdma_reg_phys_mr(struct ib_pd *ib_pd, u64 addr, u64 size,\n\t\t\t\tint acc, u64 *iova_start);\nint irdma_upload_qp_context(struct irdma_qp *iwqp, bool freeze, bool raw);\nvoid irdma_cqp_ce_handler(struct irdma_pci_f *rf, struct irdma_sc_cq *cq);\nint irdma_ah_cqp_op(struct irdma_pci_f *rf, struct irdma_sc_ah *sc_ah, u8 cmd,\n\t\t    bool wait,\n\t\t    void (*callback_fcn)(struct irdma_cqp_request *cqp_request),\n\t\t    void *cb_param);\nvoid irdma_gsi_ud_qp_ah_cb(struct irdma_cqp_request *cqp_request);\nbool irdma_cq_empty(struct irdma_cq *iwcq);\nint irdma_inetaddr_event(struct notifier_block *notifier, unsigned long event,\n\t\t\t void *ptr);\nint irdma_inet6addr_event(struct notifier_block *notifier, unsigned long event,\n\t\t\t  void *ptr);\nint irdma_net_event(struct notifier_block *notifier, unsigned long event,\n\t\t    void *ptr);\nint irdma_netdevice_event(struct notifier_block *notifier, unsigned long event,\n\t\t\t  void *ptr);\nvoid irdma_add_ip(struct irdma_device *iwdev);\nvoid cqp_compl_worker(struct work_struct *work);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}