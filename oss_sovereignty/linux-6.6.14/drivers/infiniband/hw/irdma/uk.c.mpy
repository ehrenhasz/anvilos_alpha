{
  "module_name": "uk.c",
  "hash_id": "53d35e62228580cc9de35ec5b95a866b5af3d609684252912df81017489fe662",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/irdma/uk.c",
  "human_readable_source": "\n \n#include \"osdep.h\"\n#include \"defs.h\"\n#include \"user.h\"\n#include \"irdma.h\"\n\n \nstatic void irdma_set_fragment(__le64 *wqe, u32 offset, struct ib_sge *sge,\n\t\t\t       u8 valid)\n{\n\tif (sge) {\n\t\tset_64bit_val(wqe, offset,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_FRAG_TO, sge->addr));\n\t\tset_64bit_val(wqe, offset + 8,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_VALID, valid) |\n\t\t\t      FIELD_PREP(IRDMAQPSQ_FRAG_LEN, sge->length) |\n\t\t\t      FIELD_PREP(IRDMAQPSQ_FRAG_STAG, sge->lkey));\n\t} else {\n\t\tset_64bit_val(wqe, offset, 0);\n\t\tset_64bit_val(wqe, offset + 8,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_VALID, valid));\n\t}\n}\n\n \nstatic void irdma_set_fragment_gen_1(__le64 *wqe, u32 offset,\n\t\t\t\t     struct ib_sge *sge, u8 valid)\n{\n\tif (sge) {\n\t\tset_64bit_val(wqe, offset,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_FRAG_TO, sge->addr));\n\t\tset_64bit_val(wqe, offset + 8,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_GEN1_FRAG_LEN, sge->length) |\n\t\t\t      FIELD_PREP(IRDMAQPSQ_GEN1_FRAG_STAG, sge->lkey));\n\t} else {\n\t\tset_64bit_val(wqe, offset, 0);\n\t\tset_64bit_val(wqe, offset + 8, 0);\n\t}\n}\n\n \nstatic int irdma_nop_1(struct irdma_qp_uk *qp)\n{\n\tu64 hdr;\n\t__le64 *wqe;\n\tu32 wqe_idx;\n\tbool signaled = false;\n\n\tif (!qp->sq_ring.head)\n\t\treturn -EINVAL;\n\n\twqe_idx = IRDMA_RING_CURRENT_HEAD(qp->sq_ring);\n\twqe = qp->sq_base[wqe_idx].elem;\n\n\tqp->sq_wrtrk_array[wqe_idx].quanta = IRDMA_QP_WQE_MIN_QUANTA;\n\n\tset_64bit_val(wqe, 0, 0);\n\tset_64bit_val(wqe, 8, 0);\n\tset_64bit_val(wqe, 16, 0);\n\n\thdr = FIELD_PREP(IRDMAQPSQ_OPCODE, IRDMAQP_OP_NOP) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\t \n\tdma_wmb();\n\n\tset_64bit_val(wqe, 24, hdr);\n\n\treturn 0;\n}\n\n \nvoid irdma_clr_wqes(struct irdma_qp_uk *qp, u32 qp_wqe_idx)\n{\n\tstruct irdma_qp_quanta *sq;\n\tu32 wqe_idx;\n\n\tif (!(qp_wqe_idx & 0x7F)) {\n\t\twqe_idx = (qp_wqe_idx + 128) % qp->sq_ring.size;\n\t\tsq = qp->sq_base + wqe_idx;\n\t\tif (wqe_idx)\n\t\t\tmemset(sq, qp->swqe_polarity ? 0 : 0xFF,\n\t\t\t       128 * sizeof(*sq));\n\t\telse\n\t\t\tmemset(sq, qp->swqe_polarity ? 0xFF : 0,\n\t\t\t       128 * sizeof(*sq));\n\t}\n}\n\n \nvoid irdma_uk_qp_post_wr(struct irdma_qp_uk *qp)\n{\n\tu64 temp;\n\tu32 hw_sq_tail;\n\tu32 sw_sq_head;\n\n\t \n\tmb();\n\n\t \n\tget_64bit_val(qp->shadow_area, 0, &temp);\n\n\thw_sq_tail = (u32)FIELD_GET(IRDMA_QP_DBSA_HW_SQ_TAIL, temp);\n\tsw_sq_head = IRDMA_RING_CURRENT_HEAD(qp->sq_ring);\n\tif (sw_sq_head != qp->initial_ring.head) {\n\t\tif (sw_sq_head != hw_sq_tail) {\n\t\t\tif (sw_sq_head > qp->initial_ring.head) {\n\t\t\t\tif (hw_sq_tail >= qp->initial_ring.head &&\n\t\t\t\t    hw_sq_tail < sw_sq_head)\n\t\t\t\t\twritel(qp->qp_id, qp->wqe_alloc_db);\n\t\t\t} else {\n\t\t\t\tif (hw_sq_tail >= qp->initial_ring.head ||\n\t\t\t\t    hw_sq_tail < sw_sq_head)\n\t\t\t\t\twritel(qp->qp_id, qp->wqe_alloc_db);\n\t\t\t}\n\t\t}\n\t}\n\n\tqp->initial_ring.head = qp->sq_ring.head;\n}\n\n \n__le64 *irdma_qp_get_next_send_wqe(struct irdma_qp_uk *qp, u32 *wqe_idx,\n\t\t\t\t   u16 quanta, u32 total_size,\n\t\t\t\t   struct irdma_post_sq_info *info)\n{\n\t__le64 *wqe;\n\t__le64 *wqe_0 = NULL;\n\tu16 avail_quanta;\n\tu16 i;\n\n\tavail_quanta = qp->uk_attrs->max_hw_sq_chunk -\n\t\t       (IRDMA_RING_CURRENT_HEAD(qp->sq_ring) %\n\t\t       qp->uk_attrs->max_hw_sq_chunk);\n\tif (quanta <= avail_quanta) {\n\t\t \n\t\tif (quanta > IRDMA_SQ_RING_FREE_QUANTA(qp->sq_ring))\n\t\t\treturn NULL;\n\t} else {\n\t\t \n\t\tif (quanta + avail_quanta >\n\t\t\tIRDMA_SQ_RING_FREE_QUANTA(qp->sq_ring))\n\t\t\treturn NULL;\n\n\t\tfor (i = 0; i < avail_quanta; i++) {\n\t\t\tirdma_nop_1(qp);\n\t\t\tIRDMA_RING_MOVE_HEAD_NOCHECK(qp->sq_ring);\n\t\t}\n\t}\n\n\t*wqe_idx = IRDMA_RING_CURRENT_HEAD(qp->sq_ring);\n\tif (!*wqe_idx)\n\t\tqp->swqe_polarity = !qp->swqe_polarity;\n\n\tIRDMA_RING_MOVE_HEAD_BY_COUNT_NOCHECK(qp->sq_ring, quanta);\n\n\twqe = qp->sq_base[*wqe_idx].elem;\n\tif (qp->uk_attrs->hw_rev == IRDMA_GEN_1 && quanta == 1 &&\n\t    (IRDMA_RING_CURRENT_HEAD(qp->sq_ring) & 1)) {\n\t\twqe_0 = qp->sq_base[IRDMA_RING_CURRENT_HEAD(qp->sq_ring)].elem;\n\t\twqe_0[3] = cpu_to_le64(FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity ? 0 : 1));\n\t}\n\tqp->sq_wrtrk_array[*wqe_idx].wrid = info->wr_id;\n\tqp->sq_wrtrk_array[*wqe_idx].wr_len = total_size;\n\tqp->sq_wrtrk_array[*wqe_idx].quanta = quanta;\n\n\treturn wqe;\n}\n\n \n__le64 *irdma_qp_get_next_recv_wqe(struct irdma_qp_uk *qp, u32 *wqe_idx)\n{\n\t__le64 *wqe;\n\tint ret_code;\n\n\tif (IRDMA_RING_FULL_ERR(qp->rq_ring))\n\t\treturn NULL;\n\n\tIRDMA_ATOMIC_RING_MOVE_HEAD(qp->rq_ring, *wqe_idx, ret_code);\n\tif (ret_code)\n\t\treturn NULL;\n\n\tif (!*wqe_idx)\n\t\tqp->rwqe_polarity = !qp->rwqe_polarity;\n\t \n\twqe = qp->rq_base[*wqe_idx * qp->rq_wqe_size_multiplier].elem;\n\n\treturn wqe;\n}\n\n \nint irdma_uk_rdma_write(struct irdma_qp_uk *qp, struct irdma_post_sq_info *info,\n\t\t\tbool post_sq)\n{\n\tu64 hdr;\n\t__le64 *wqe;\n\tstruct irdma_rdma_write *op_info;\n\tu32 i, wqe_idx;\n\tu32 total_size = 0, byte_off;\n\tint ret_code;\n\tu32 frag_cnt, addl_frag_cnt;\n\tbool read_fence = false;\n\tu16 quanta;\n\n\top_info = &info->op.rdma_write;\n\tif (op_info->num_lo_sges > qp->max_sq_frag_cnt)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < op_info->num_lo_sges; i++)\n\t\ttotal_size += op_info->lo_sg_list[i].length;\n\n\tread_fence |= info->read_fence;\n\n\tif (info->imm_data_valid)\n\t\tfrag_cnt = op_info->num_lo_sges + 1;\n\telse\n\t\tfrag_cnt = op_info->num_lo_sges;\n\taddl_frag_cnt = frag_cnt > 1 ? (frag_cnt - 1) : 0;\n\tret_code = irdma_fragcnt_to_quanta_sq(frag_cnt, &quanta);\n\tif (ret_code)\n\t\treturn ret_code;\n\n\twqe = irdma_qp_get_next_send_wqe(qp, &wqe_idx, quanta, total_size,\n\t\t\t\t\t info);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tirdma_clr_wqes(qp, wqe_idx);\n\n\tset_64bit_val(wqe, 16,\n\t\t      FIELD_PREP(IRDMAQPSQ_FRAG_TO, op_info->rem_addr.addr));\n\n\tif (info->imm_data_valid) {\n\t\tset_64bit_val(wqe, 0,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_IMMDATA, info->imm_data));\n\t\ti = 0;\n\t} else {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, 0,\n\t\t\t\t\t    op_info->lo_sg_list,\n\t\t\t\t\t    qp->swqe_polarity);\n\t\ti = 1;\n\t}\n\n\tfor (byte_off = 32; i < op_info->num_lo_sges; i++) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off,\n\t\t\t\t\t    &op_info->lo_sg_list[i],\n\t\t\t\t\t    qp->swqe_polarity);\n\t\tbyte_off += 16;\n\t}\n\n\t \n\tif (qp->uk_attrs->hw_rev >= IRDMA_GEN_2 && !(frag_cnt & 0x01) &&\n\t    frag_cnt) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off, NULL,\n\t\t\t\t\t    qp->swqe_polarity);\n\t\tif (qp->uk_attrs->hw_rev == IRDMA_GEN_2)\n\t\t\t++addl_frag_cnt;\n\t}\n\n\thdr = FIELD_PREP(IRDMAQPSQ_REMSTAG, op_info->rem_addr.lkey) |\n\t      FIELD_PREP(IRDMAQPSQ_OPCODE, info->op_type) |\n\t      FIELD_PREP(IRDMAQPSQ_IMMDATAFLAG, info->imm_data_valid) |\n\t      FIELD_PREP(IRDMAQPSQ_REPORTRTT, info->report_rtt) |\n\t      FIELD_PREP(IRDMAQPSQ_ADDFRAGCNT, addl_frag_cnt) |\n\t      FIELD_PREP(IRDMAQPSQ_READFENCE, read_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_LOCALFENCE, info->local_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, info->signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\n\tif (post_sq)\n\t\tirdma_uk_qp_post_wr(qp);\n\n\treturn 0;\n}\n\n \nint irdma_uk_rdma_read(struct irdma_qp_uk *qp, struct irdma_post_sq_info *info,\n\t\t       bool inv_stag, bool post_sq)\n{\n\tstruct irdma_rdma_read *op_info;\n\tint ret_code;\n\tu32 i, byte_off, total_size = 0;\n\tbool local_fence = false;\n\tu32 addl_frag_cnt;\n\t__le64 *wqe;\n\tu32 wqe_idx;\n\tu16 quanta;\n\tu64 hdr;\n\n\top_info = &info->op.rdma_read;\n\tif (qp->max_sq_frag_cnt < op_info->num_lo_sges)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < op_info->num_lo_sges; i++)\n\t\ttotal_size += op_info->lo_sg_list[i].length;\n\n\tret_code = irdma_fragcnt_to_quanta_sq(op_info->num_lo_sges, &quanta);\n\tif (ret_code)\n\t\treturn ret_code;\n\n\twqe = irdma_qp_get_next_send_wqe(qp, &wqe_idx, quanta, total_size,\n\t\t\t\t\t info);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tirdma_clr_wqes(qp, wqe_idx);\n\n\taddl_frag_cnt = op_info->num_lo_sges > 1 ?\n\t\t\t(op_info->num_lo_sges - 1) : 0;\n\tlocal_fence |= info->local_fence;\n\n\tqp->wqe_ops.iw_set_fragment(wqe, 0, op_info->lo_sg_list,\n\t\t\t\t    qp->swqe_polarity);\n\tfor (i = 1, byte_off = 32; i < op_info->num_lo_sges; ++i) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off,\n\t\t\t\t\t    &op_info->lo_sg_list[i],\n\t\t\t\t\t    qp->swqe_polarity);\n\t\tbyte_off += 16;\n\t}\n\n\t \n\tif (qp->uk_attrs->hw_rev >= IRDMA_GEN_2 &&\n\t    !(op_info->num_lo_sges & 0x01) && op_info->num_lo_sges) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off, NULL,\n\t\t\t\t\t    qp->swqe_polarity);\n\t\tif (qp->uk_attrs->hw_rev == IRDMA_GEN_2)\n\t\t\t++addl_frag_cnt;\n\t}\n\tset_64bit_val(wqe, 16,\n\t\t      FIELD_PREP(IRDMAQPSQ_FRAG_TO, op_info->rem_addr.addr));\n\thdr = FIELD_PREP(IRDMAQPSQ_REMSTAG, op_info->rem_addr.lkey) |\n\t      FIELD_PREP(IRDMAQPSQ_REPORTRTT, (info->report_rtt ? 1 : 0)) |\n\t      FIELD_PREP(IRDMAQPSQ_ADDFRAGCNT, addl_frag_cnt) |\n\t      FIELD_PREP(IRDMAQPSQ_OPCODE,\n\t\t\t (inv_stag ? IRDMAQP_OP_RDMA_READ_LOC_INV : IRDMAQP_OP_RDMA_READ)) |\n\t      FIELD_PREP(IRDMAQPSQ_READFENCE, info->read_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_LOCALFENCE, local_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, info->signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\n\tif (post_sq)\n\t\tirdma_uk_qp_post_wr(qp);\n\n\treturn 0;\n}\n\n \nint irdma_uk_send(struct irdma_qp_uk *qp, struct irdma_post_sq_info *info,\n\t\t  bool post_sq)\n{\n\t__le64 *wqe;\n\tstruct irdma_post_send *op_info;\n\tu64 hdr;\n\tu32 i, wqe_idx, total_size = 0, byte_off;\n\tint ret_code;\n\tu32 frag_cnt, addl_frag_cnt;\n\tbool read_fence = false;\n\tu16 quanta;\n\n\top_info = &info->op.send;\n\tif (qp->max_sq_frag_cnt < op_info->num_sges)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < op_info->num_sges; i++)\n\t\ttotal_size += op_info->sg_list[i].length;\n\n\tif (info->imm_data_valid)\n\t\tfrag_cnt = op_info->num_sges + 1;\n\telse\n\t\tfrag_cnt = op_info->num_sges;\n\tret_code = irdma_fragcnt_to_quanta_sq(frag_cnt, &quanta);\n\tif (ret_code)\n\t\treturn ret_code;\n\n\twqe = irdma_qp_get_next_send_wqe(qp, &wqe_idx, quanta, total_size,\n\t\t\t\t\t info);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tirdma_clr_wqes(qp, wqe_idx);\n\n\tread_fence |= info->read_fence;\n\taddl_frag_cnt = frag_cnt > 1 ? (frag_cnt - 1) : 0;\n\tif (info->imm_data_valid) {\n\t\tset_64bit_val(wqe, 0,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_IMMDATA, info->imm_data));\n\t\ti = 0;\n\t} else {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, 0,\n\t\t\t\t\t    frag_cnt ? op_info->sg_list : NULL,\n\t\t\t\t\t    qp->swqe_polarity);\n\t\ti = 1;\n\t}\n\n\tfor (byte_off = 32; i < op_info->num_sges; i++) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off, &op_info->sg_list[i],\n\t\t\t\t\t    qp->swqe_polarity);\n\t\tbyte_off += 16;\n\t}\n\n\t \n\tif (qp->uk_attrs->hw_rev >= IRDMA_GEN_2 && !(frag_cnt & 0x01) &&\n\t    frag_cnt) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off, NULL,\n\t\t\t\t\t    qp->swqe_polarity);\n\t\tif (qp->uk_attrs->hw_rev == IRDMA_GEN_2)\n\t\t\t++addl_frag_cnt;\n\t}\n\n\tset_64bit_val(wqe, 16,\n\t\t      FIELD_PREP(IRDMAQPSQ_DESTQKEY, op_info->qkey) |\n\t\t      FIELD_PREP(IRDMAQPSQ_DESTQPN, op_info->dest_qp));\n\thdr = FIELD_PREP(IRDMAQPSQ_REMSTAG, info->stag_to_inv) |\n\t      FIELD_PREP(IRDMAQPSQ_AHID, op_info->ah_id) |\n\t      FIELD_PREP(IRDMAQPSQ_IMMDATAFLAG,\n\t\t\t (info->imm_data_valid ? 1 : 0)) |\n\t      FIELD_PREP(IRDMAQPSQ_REPORTRTT, (info->report_rtt ? 1 : 0)) |\n\t      FIELD_PREP(IRDMAQPSQ_OPCODE, info->op_type) |\n\t      FIELD_PREP(IRDMAQPSQ_ADDFRAGCNT, addl_frag_cnt) |\n\t      FIELD_PREP(IRDMAQPSQ_READFENCE, read_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_LOCALFENCE, info->local_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, info->signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_UDPHEADER, info->udp_hdr) |\n\t      FIELD_PREP(IRDMAQPSQ_L4LEN, info->l4len) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\n\tif (post_sq)\n\t\tirdma_uk_qp_post_wr(qp);\n\n\treturn 0;\n}\n\n \nstatic void irdma_set_mw_bind_wqe_gen_1(__le64 *wqe,\n\t\t\t\t\tstruct irdma_bind_window *op_info)\n{\n\tset_64bit_val(wqe, 0, (uintptr_t)op_info->va);\n\tset_64bit_val(wqe, 8,\n\t\t      FIELD_PREP(IRDMAQPSQ_PARENTMRSTAG, op_info->mw_stag) |\n\t\t      FIELD_PREP(IRDMAQPSQ_MWSTAG, op_info->mr_stag));\n\tset_64bit_val(wqe, 16, op_info->bind_len);\n}\n\n \nstatic void irdma_copy_inline_data_gen_1(u8 *wqe, struct ib_sge *sge_list,\n\t\t\t\t\t u32 num_sges, u8 polarity)\n{\n\tu32 quanta_bytes_remaining = 16;\n\tint i;\n\n\tfor (i = 0; i < num_sges; i++) {\n\t\tu8 *cur_sge = (u8 *)(uintptr_t)sge_list[i].addr;\n\t\tu32 sge_len = sge_list[i].length;\n\n\t\twhile (sge_len) {\n\t\t\tu32 bytes_copied;\n\n\t\t\tbytes_copied = min(sge_len, quanta_bytes_remaining);\n\t\t\tmemcpy(wqe, cur_sge, bytes_copied);\n\t\t\twqe += bytes_copied;\n\t\t\tcur_sge += bytes_copied;\n\t\t\tquanta_bytes_remaining -= bytes_copied;\n\t\t\tsge_len -= bytes_copied;\n\n\t\t\tif (!quanta_bytes_remaining) {\n\t\t\t\t \n\t\t\t\twqe += 16;\n\t\t\t\tquanta_bytes_remaining = 32;\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic inline u16 irdma_inline_data_size_to_quanta_gen_1(u32 data_size)\n{\n\treturn data_size <= 16 ? IRDMA_QP_WQE_MIN_QUANTA : 2;\n}\n\n \nstatic void irdma_set_mw_bind_wqe(__le64 *wqe,\n\t\t\t\t  struct irdma_bind_window *op_info)\n{\n\tset_64bit_val(wqe, 0, (uintptr_t)op_info->va);\n\tset_64bit_val(wqe, 8,\n\t\t      FIELD_PREP(IRDMAQPSQ_PARENTMRSTAG, op_info->mr_stag) |\n\t\t      FIELD_PREP(IRDMAQPSQ_MWSTAG, op_info->mw_stag));\n\tset_64bit_val(wqe, 16, op_info->bind_len);\n}\n\n \nstatic void irdma_copy_inline_data(u8 *wqe, struct ib_sge *sge_list,\n\t\t\t\t   u32 num_sges, u8 polarity)\n{\n\tu8 inline_valid = polarity << IRDMA_INLINE_VALID_S;\n\tu32 quanta_bytes_remaining = 8;\n\tbool first_quanta = true;\n\tint i;\n\n\twqe += 8;\n\n\tfor (i = 0; i < num_sges; i++) {\n\t\tu8 *cur_sge = (u8 *)(uintptr_t)sge_list[i].addr;\n\t\tu32 sge_len = sge_list[i].length;\n\n\t\twhile (sge_len) {\n\t\t\tu32 bytes_copied;\n\n\t\t\tbytes_copied = min(sge_len, quanta_bytes_remaining);\n\t\t\tmemcpy(wqe, cur_sge, bytes_copied);\n\t\t\twqe += bytes_copied;\n\t\t\tcur_sge += bytes_copied;\n\t\t\tquanta_bytes_remaining -= bytes_copied;\n\t\t\tsge_len -= bytes_copied;\n\n\t\t\tif (!quanta_bytes_remaining) {\n\t\t\t\tquanta_bytes_remaining = 31;\n\n\t\t\t\t \n\t\t\t\tif (first_quanta) {\n\t\t\t\t\tfirst_quanta = false;\n\t\t\t\t\twqe += 16;\n\t\t\t\t} else {\n\t\t\t\t\t*wqe = inline_valid;\n\t\t\t\t\twqe++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif (!first_quanta && quanta_bytes_remaining < 31)\n\t\t*(wqe + quanta_bytes_remaining) = inline_valid;\n}\n\n \nstatic u16 irdma_inline_data_size_to_quanta(u32 data_size)\n{\n\tif (data_size <= 8)\n\t\treturn IRDMA_QP_WQE_MIN_QUANTA;\n\telse if (data_size <= 39)\n\t\treturn 2;\n\telse if (data_size <= 70)\n\t\treturn 3;\n\telse if (data_size <= 101)\n\t\treturn 4;\n\telse if (data_size <= 132)\n\t\treturn 5;\n\telse if (data_size <= 163)\n\t\treturn 6;\n\telse if (data_size <= 194)\n\t\treturn 7;\n\telse\n\t\treturn 8;\n}\n\n \nint irdma_uk_inline_rdma_write(struct irdma_qp_uk *qp,\n\t\t\t       struct irdma_post_sq_info *info, bool post_sq)\n{\n\t__le64 *wqe;\n\tstruct irdma_rdma_write *op_info;\n\tu64 hdr = 0;\n\tu32 wqe_idx;\n\tbool read_fence = false;\n\tu32 i, total_size = 0;\n\tu16 quanta;\n\n\top_info = &info->op.rdma_write;\n\n\tif (unlikely(qp->max_sq_frag_cnt < op_info->num_lo_sges))\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < op_info->num_lo_sges; i++)\n\t\ttotal_size += op_info->lo_sg_list[i].length;\n\n\tif (unlikely(total_size > qp->max_inline_data))\n\t\treturn -EINVAL;\n\n\tquanta = qp->wqe_ops.iw_inline_data_size_to_quanta(total_size);\n\twqe = irdma_qp_get_next_send_wqe(qp, &wqe_idx, quanta, total_size,\n\t\t\t\t\t info);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tirdma_clr_wqes(qp, wqe_idx);\n\n\tread_fence |= info->read_fence;\n\tset_64bit_val(wqe, 16,\n\t\t      FIELD_PREP(IRDMAQPSQ_FRAG_TO, op_info->rem_addr.addr));\n\n\thdr = FIELD_PREP(IRDMAQPSQ_REMSTAG, op_info->rem_addr.lkey) |\n\t      FIELD_PREP(IRDMAQPSQ_OPCODE, info->op_type) |\n\t      FIELD_PREP(IRDMAQPSQ_INLINEDATALEN, total_size) |\n\t      FIELD_PREP(IRDMAQPSQ_REPORTRTT, info->report_rtt ? 1 : 0) |\n\t      FIELD_PREP(IRDMAQPSQ_INLINEDATAFLAG, 1) |\n\t      FIELD_PREP(IRDMAQPSQ_IMMDATAFLAG, info->imm_data_valid ? 1 : 0) |\n\t      FIELD_PREP(IRDMAQPSQ_READFENCE, read_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_LOCALFENCE, info->local_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, info->signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\tif (info->imm_data_valid)\n\t\tset_64bit_val(wqe, 0,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_IMMDATA, info->imm_data));\n\n\tqp->wqe_ops.iw_copy_inline_data((u8 *)wqe, op_info->lo_sg_list,\n\t\t\t\t\top_info->num_lo_sges,\n\t\t\t\t\tqp->swqe_polarity);\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\n\tif (post_sq)\n\t\tirdma_uk_qp_post_wr(qp);\n\n\treturn 0;\n}\n\n \nint irdma_uk_inline_send(struct irdma_qp_uk *qp,\n\t\t\t struct irdma_post_sq_info *info, bool post_sq)\n{\n\t__le64 *wqe;\n\tstruct irdma_post_send *op_info;\n\tu64 hdr;\n\tu32 wqe_idx;\n\tbool read_fence = false;\n\tu32 i, total_size = 0;\n\tu16 quanta;\n\n\top_info = &info->op.send;\n\n\tif (unlikely(qp->max_sq_frag_cnt < op_info->num_sges))\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < op_info->num_sges; i++)\n\t\ttotal_size += op_info->sg_list[i].length;\n\n\tif (unlikely(total_size > qp->max_inline_data))\n\t\treturn -EINVAL;\n\n\tquanta = qp->wqe_ops.iw_inline_data_size_to_quanta(total_size);\n\twqe = irdma_qp_get_next_send_wqe(qp, &wqe_idx, quanta, total_size,\n\t\t\t\t\t info);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tirdma_clr_wqes(qp, wqe_idx);\n\n\tset_64bit_val(wqe, 16,\n\t\t      FIELD_PREP(IRDMAQPSQ_DESTQKEY, op_info->qkey) |\n\t\t      FIELD_PREP(IRDMAQPSQ_DESTQPN, op_info->dest_qp));\n\n\tread_fence |= info->read_fence;\n\thdr = FIELD_PREP(IRDMAQPSQ_REMSTAG, info->stag_to_inv) |\n\t      FIELD_PREP(IRDMAQPSQ_AHID, op_info->ah_id) |\n\t      FIELD_PREP(IRDMAQPSQ_OPCODE, info->op_type) |\n\t      FIELD_PREP(IRDMAQPSQ_INLINEDATALEN, total_size) |\n\t      FIELD_PREP(IRDMAQPSQ_IMMDATAFLAG,\n\t\t\t (info->imm_data_valid ? 1 : 0)) |\n\t      FIELD_PREP(IRDMAQPSQ_REPORTRTT, (info->report_rtt ? 1 : 0)) |\n\t      FIELD_PREP(IRDMAQPSQ_INLINEDATAFLAG, 1) |\n\t      FIELD_PREP(IRDMAQPSQ_READFENCE, read_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_LOCALFENCE, info->local_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, info->signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_UDPHEADER, info->udp_hdr) |\n\t      FIELD_PREP(IRDMAQPSQ_L4LEN, info->l4len) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\tif (info->imm_data_valid)\n\t\tset_64bit_val(wqe, 0,\n\t\t\t      FIELD_PREP(IRDMAQPSQ_IMMDATA, info->imm_data));\n\tqp->wqe_ops.iw_copy_inline_data((u8 *)wqe, op_info->sg_list,\n\t\t\t\t\top_info->num_sges, qp->swqe_polarity);\n\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\n\tif (post_sq)\n\t\tirdma_uk_qp_post_wr(qp);\n\n\treturn 0;\n}\n\n \nint irdma_uk_stag_local_invalidate(struct irdma_qp_uk *qp,\n\t\t\t\t   struct irdma_post_sq_info *info,\n\t\t\t\t   bool post_sq)\n{\n\t__le64 *wqe;\n\tstruct irdma_inv_local_stag *op_info;\n\tu64 hdr;\n\tu32 wqe_idx;\n\tbool local_fence = false;\n\tstruct ib_sge sge = {};\n\n\top_info = &info->op.inv_local_stag;\n\tlocal_fence = info->local_fence;\n\n\twqe = irdma_qp_get_next_send_wqe(qp, &wqe_idx, IRDMA_QP_WQE_MIN_QUANTA,\n\t\t\t\t\t 0, info);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tirdma_clr_wqes(qp, wqe_idx);\n\n\tsge.lkey = op_info->target_stag;\n\tqp->wqe_ops.iw_set_fragment(wqe, 0, &sge, 0);\n\n\tset_64bit_val(wqe, 16, 0);\n\n\thdr = FIELD_PREP(IRDMAQPSQ_OPCODE, IRDMA_OP_TYPE_INV_STAG) |\n\t      FIELD_PREP(IRDMAQPSQ_READFENCE, info->read_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_LOCALFENCE, local_fence) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, info->signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\n\tif (post_sq)\n\t\tirdma_uk_qp_post_wr(qp);\n\n\treturn 0;\n}\n\n \nint irdma_uk_post_receive(struct irdma_qp_uk *qp,\n\t\t\t  struct irdma_post_rq_info *info)\n{\n\tu32 wqe_idx, i, byte_off;\n\tu32 addl_frag_cnt;\n\t__le64 *wqe;\n\tu64 hdr;\n\n\tif (qp->max_rq_frag_cnt < info->num_sges)\n\t\treturn -EINVAL;\n\n\twqe = irdma_qp_get_next_recv_wqe(qp, &wqe_idx);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tqp->rq_wrid_array[wqe_idx] = info->wr_id;\n\taddl_frag_cnt = info->num_sges > 1 ? (info->num_sges - 1) : 0;\n\tqp->wqe_ops.iw_set_fragment(wqe, 0, info->sg_list,\n\t\t\t\t    qp->rwqe_polarity);\n\n\tfor (i = 1, byte_off = 32; i < info->num_sges; i++) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off, &info->sg_list[i],\n\t\t\t\t\t    qp->rwqe_polarity);\n\t\tbyte_off += 16;\n\t}\n\n\t \n\tif (qp->uk_attrs->hw_rev >= IRDMA_GEN_2 && !(info->num_sges & 0x01) &&\n\t    info->num_sges) {\n\t\tqp->wqe_ops.iw_set_fragment(wqe, byte_off, NULL,\n\t\t\t\t\t    qp->rwqe_polarity);\n\t\tif (qp->uk_attrs->hw_rev == IRDMA_GEN_2)\n\t\t\t++addl_frag_cnt;\n\t}\n\n\tset_64bit_val(wqe, 16, 0);\n\thdr = FIELD_PREP(IRDMAQPSQ_ADDFRAGCNT, addl_frag_cnt) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->rwqe_polarity);\n\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\n\treturn 0;\n}\n\n \nvoid irdma_uk_cq_resize(struct irdma_cq_uk *cq, void *cq_base, int cq_size)\n{\n\tcq->cq_base = cq_base;\n\tcq->cq_size = cq_size;\n\tIRDMA_RING_INIT(cq->cq_ring, cq->cq_size);\n\tcq->polarity = 1;\n}\n\n \nvoid irdma_uk_cq_set_resized_cnt(struct irdma_cq_uk *cq, u16 cq_cnt)\n{\n\tu64 temp_val;\n\tu16 sw_cq_sel;\n\tu8 arm_next_se;\n\tu8 arm_next;\n\tu8 arm_seq_num;\n\n\tget_64bit_val(cq->shadow_area, 32, &temp_val);\n\n\tsw_cq_sel = (u16)FIELD_GET(IRDMA_CQ_DBSA_SW_CQ_SELECT, temp_val);\n\tsw_cq_sel += cq_cnt;\n\n\tarm_seq_num = (u8)FIELD_GET(IRDMA_CQ_DBSA_ARM_SEQ_NUM, temp_val);\n\tarm_next_se = (u8)FIELD_GET(IRDMA_CQ_DBSA_ARM_NEXT_SE, temp_val);\n\tarm_next = (u8)FIELD_GET(IRDMA_CQ_DBSA_ARM_NEXT, temp_val);\n\n\ttemp_val = FIELD_PREP(IRDMA_CQ_DBSA_ARM_SEQ_NUM, arm_seq_num) |\n\t\t   FIELD_PREP(IRDMA_CQ_DBSA_SW_CQ_SELECT, sw_cq_sel) |\n\t\t   FIELD_PREP(IRDMA_CQ_DBSA_ARM_NEXT_SE, arm_next_se) |\n\t\t   FIELD_PREP(IRDMA_CQ_DBSA_ARM_NEXT, arm_next);\n\n\tset_64bit_val(cq->shadow_area, 32, temp_val);\n}\n\n \nvoid irdma_uk_cq_request_notification(struct irdma_cq_uk *cq,\n\t\t\t\t      enum irdma_cmpl_notify cq_notify)\n{\n\tu64 temp_val;\n\tu16 sw_cq_sel;\n\tu8 arm_next_se = 0;\n\tu8 arm_next = 0;\n\tu8 arm_seq_num;\n\n\tget_64bit_val(cq->shadow_area, 32, &temp_val);\n\tarm_seq_num = (u8)FIELD_GET(IRDMA_CQ_DBSA_ARM_SEQ_NUM, temp_val);\n\tarm_seq_num++;\n\tsw_cq_sel = (u16)FIELD_GET(IRDMA_CQ_DBSA_SW_CQ_SELECT, temp_val);\n\tarm_next_se = (u8)FIELD_GET(IRDMA_CQ_DBSA_ARM_NEXT_SE, temp_val);\n\tarm_next_se |= 1;\n\tif (cq_notify == IRDMA_CQ_COMPL_EVENT)\n\t\tarm_next = 1;\n\ttemp_val = FIELD_PREP(IRDMA_CQ_DBSA_ARM_SEQ_NUM, arm_seq_num) |\n\t\t   FIELD_PREP(IRDMA_CQ_DBSA_SW_CQ_SELECT, sw_cq_sel) |\n\t\t   FIELD_PREP(IRDMA_CQ_DBSA_ARM_NEXT_SE, arm_next_se) |\n\t\t   FIELD_PREP(IRDMA_CQ_DBSA_ARM_NEXT, arm_next);\n\n\tset_64bit_val(cq->shadow_area, 32, temp_val);\n\n\tdma_wmb();  \n\n\twritel(cq->cq_id, cq->cqe_alloc_db);\n}\n\n \nint irdma_uk_cq_poll_cmpl(struct irdma_cq_uk *cq,\n\t\t\t  struct irdma_cq_poll_info *info)\n{\n\tu64 comp_ctx, qword0, qword2, qword3;\n\t__le64 *cqe;\n\tstruct irdma_qp_uk *qp;\n\tstruct irdma_ring *pring = NULL;\n\tu32 wqe_idx;\n\tint ret_code;\n\tbool move_cq_head = true;\n\tu8 polarity;\n\tbool ext_valid;\n\t__le64 *ext_cqe;\n\n\tif (cq->avoid_mem_cflct)\n\t\tcqe = IRDMA_GET_CURRENT_EXTENDED_CQ_ELEM(cq);\n\telse\n\t\tcqe = IRDMA_GET_CURRENT_CQ_ELEM(cq);\n\n\tget_64bit_val(cqe, 24, &qword3);\n\tpolarity = (u8)FIELD_GET(IRDMA_CQ_VALID, qword3);\n\tif (polarity != cq->polarity)\n\t\treturn -ENOENT;\n\n\t \n\tdma_rmb();\n\n\text_valid = (bool)FIELD_GET(IRDMA_CQ_EXTCQE, qword3);\n\tif (ext_valid) {\n\t\tu64 qword6, qword7;\n\t\tu32 peek_head;\n\n\t\tif (cq->avoid_mem_cflct) {\n\t\t\text_cqe = (__le64 *)((u8 *)cqe + 32);\n\t\t\tget_64bit_val(ext_cqe, 24, &qword7);\n\t\t\tpolarity = (u8)FIELD_GET(IRDMA_CQ_VALID, qword7);\n\t\t} else {\n\t\t\tpeek_head = (cq->cq_ring.head + 1) % cq->cq_ring.size;\n\t\t\text_cqe = cq->cq_base[peek_head].buf;\n\t\t\tget_64bit_val(ext_cqe, 24, &qword7);\n\t\t\tpolarity = (u8)FIELD_GET(IRDMA_CQ_VALID, qword7);\n\t\t\tif (!peek_head)\n\t\t\t\tpolarity ^= 1;\n\t\t}\n\t\tif (polarity != cq->polarity)\n\t\t\treturn -ENOENT;\n\n\t\t \n\t\tdma_rmb();\n\n\t\tinfo->imm_valid = (bool)FIELD_GET(IRDMA_CQ_IMMVALID, qword7);\n\t\tif (info->imm_valid) {\n\t\t\tu64 qword4;\n\n\t\t\tget_64bit_val(ext_cqe, 0, &qword4);\n\t\t\tinfo->imm_data = (u32)FIELD_GET(IRDMA_CQ_IMMDATALOW32, qword4);\n\t\t}\n\t\tinfo->ud_smac_valid = (bool)FIELD_GET(IRDMA_CQ_UDSMACVALID, qword7);\n\t\tinfo->ud_vlan_valid = (bool)FIELD_GET(IRDMA_CQ_UDVLANVALID, qword7);\n\t\tif (info->ud_smac_valid || info->ud_vlan_valid) {\n\t\t\tget_64bit_val(ext_cqe, 16, &qword6);\n\t\t\tif (info->ud_vlan_valid)\n\t\t\t\tinfo->ud_vlan = (u16)FIELD_GET(IRDMA_CQ_UDVLAN, qword6);\n\t\t\tif (info->ud_smac_valid) {\n\t\t\t\tinfo->ud_smac[5] = qword6 & 0xFF;\n\t\t\t\tinfo->ud_smac[4] = (qword6 >> 8) & 0xFF;\n\t\t\t\tinfo->ud_smac[3] = (qword6 >> 16) & 0xFF;\n\t\t\t\tinfo->ud_smac[2] = (qword6 >> 24) & 0xFF;\n\t\t\t\tinfo->ud_smac[1] = (qword6 >> 32) & 0xFF;\n\t\t\t\tinfo->ud_smac[0] = (qword6 >> 40) & 0xFF;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tinfo->imm_valid = false;\n\t\tinfo->ud_smac_valid = false;\n\t\tinfo->ud_vlan_valid = false;\n\t}\n\n\tinfo->q_type = (u8)FIELD_GET(IRDMA_CQ_SQ, qword3);\n\tinfo->error = (bool)FIELD_GET(IRDMA_CQ_ERROR, qword3);\n\tinfo->ipv4 = (bool)FIELD_GET(IRDMACQ_IPV4, qword3);\n\tif (info->error) {\n\t\tinfo->major_err = FIELD_GET(IRDMA_CQ_MAJERR, qword3);\n\t\tinfo->minor_err = FIELD_GET(IRDMA_CQ_MINERR, qword3);\n\t\tif (info->major_err == IRDMA_FLUSH_MAJOR_ERR) {\n\t\t\tinfo->comp_status = IRDMA_COMPL_STATUS_FLUSHED;\n\t\t\t \n\t\t\tif (info->minor_err != FLUSH_GENERAL_ERR) {\n\t\t\t\tqword3 &= ~IRDMA_CQ_MINERR;\n\t\t\t\tqword3 |= FIELD_PREP(IRDMA_CQ_MINERR, FLUSH_GENERAL_ERR);\n\t\t\t\tset_64bit_val(cqe, 24, qword3);\n\t\t\t}\n\t\t} else {\n\t\t\tinfo->comp_status = IRDMA_COMPL_STATUS_UNKNOWN;\n\t\t}\n\t} else {\n\t\tinfo->comp_status = IRDMA_COMPL_STATUS_SUCCESS;\n\t}\n\n\tget_64bit_val(cqe, 0, &qword0);\n\tget_64bit_val(cqe, 16, &qword2);\n\n\tinfo->tcp_seq_num_rtt = (u32)FIELD_GET(IRDMACQ_TCPSEQNUMRTT, qword0);\n\tinfo->qp_id = (u32)FIELD_GET(IRDMACQ_QPID, qword2);\n\tinfo->ud_src_qpn = (u32)FIELD_GET(IRDMACQ_UDSRCQPN, qword2);\n\n\tget_64bit_val(cqe, 8, &comp_ctx);\n\n\tinfo->solicited_event = (bool)FIELD_GET(IRDMACQ_SOEVENT, qword3);\n\tqp = (struct irdma_qp_uk *)(unsigned long)comp_ctx;\n\tif (!qp || qp->destroy_pending) {\n\t\tret_code = -EFAULT;\n\t\tgoto exit;\n\t}\n\twqe_idx = (u32)FIELD_GET(IRDMA_CQ_WQEIDX, qword3);\n\tinfo->qp_handle = (irdma_qp_handle)(unsigned long)qp;\n\tinfo->op_type = (u8)FIELD_GET(IRDMACQ_OP, qword3);\n\n\tif (info->q_type == IRDMA_CQE_QTYPE_RQ) {\n\t\tu32 array_idx;\n\n\t\tarray_idx = wqe_idx / qp->rq_wqe_size_multiplier;\n\n\t\tif (info->comp_status == IRDMA_COMPL_STATUS_FLUSHED ||\n\t\t    info->comp_status == IRDMA_COMPL_STATUS_UNKNOWN) {\n\t\t\tif (!IRDMA_RING_MORE_WORK(qp->rq_ring)) {\n\t\t\t\tret_code = -ENOENT;\n\t\t\t\tgoto exit;\n\t\t\t}\n\n\t\t\tinfo->wr_id = qp->rq_wrid_array[qp->rq_ring.tail];\n\t\t\tarray_idx = qp->rq_ring.tail;\n\t\t} else {\n\t\t\tinfo->wr_id = qp->rq_wrid_array[array_idx];\n\t\t}\n\n\t\tinfo->bytes_xfered = (u32)FIELD_GET(IRDMACQ_PAYLDLEN, qword0);\n\n\t\tif (qword3 & IRDMACQ_STAG) {\n\t\t\tinfo->stag_invalid_set = true;\n\t\t\tinfo->inv_stag = (u32)FIELD_GET(IRDMACQ_INVSTAG, qword2);\n\t\t} else {\n\t\t\tinfo->stag_invalid_set = false;\n\t\t}\n\t\tIRDMA_RING_SET_TAIL(qp->rq_ring, array_idx + 1);\n\t\tif (info->comp_status == IRDMA_COMPL_STATUS_FLUSHED) {\n\t\t\tqp->rq_flush_seen = true;\n\t\t\tif (!IRDMA_RING_MORE_WORK(qp->rq_ring))\n\t\t\t\tqp->rq_flush_complete = true;\n\t\t\telse\n\t\t\t\tmove_cq_head = false;\n\t\t}\n\t\tpring = &qp->rq_ring;\n\t} else {  \n\t\tif (qp->first_sq_wq) {\n\t\t\tif (wqe_idx + 1 >= qp->conn_wqes)\n\t\t\t\tqp->first_sq_wq = false;\n\n\t\t\tif (wqe_idx < qp->conn_wqes && qp->sq_ring.head == qp->sq_ring.tail) {\n\t\t\t\tIRDMA_RING_MOVE_HEAD_NOCHECK(cq->cq_ring);\n\t\t\t\tIRDMA_RING_MOVE_TAIL(cq->cq_ring);\n\t\t\t\tset_64bit_val(cq->shadow_area, 0,\n\t\t\t\t\t      IRDMA_RING_CURRENT_HEAD(cq->cq_ring));\n\t\t\t\tmemset(info, 0,\n\t\t\t\t       sizeof(struct irdma_cq_poll_info));\n\t\t\t\treturn irdma_uk_cq_poll_cmpl(cq, info);\n\t\t\t}\n\t\t}\n\t\tif (info->comp_status != IRDMA_COMPL_STATUS_FLUSHED) {\n\t\t\tinfo->wr_id = qp->sq_wrtrk_array[wqe_idx].wrid;\n\t\t\tif (!info->comp_status)\n\t\t\t\tinfo->bytes_xfered = qp->sq_wrtrk_array[wqe_idx].wr_len;\n\t\t\tinfo->op_type = (u8)FIELD_GET(IRDMACQ_OP, qword3);\n\t\t\tIRDMA_RING_SET_TAIL(qp->sq_ring,\n\t\t\t\t\t    wqe_idx + qp->sq_wrtrk_array[wqe_idx].quanta);\n\t\t} else {\n\t\t\tif (!IRDMA_RING_MORE_WORK(qp->sq_ring)) {\n\t\t\t\tret_code = -ENOENT;\n\t\t\t\tgoto exit;\n\t\t\t}\n\n\t\t\tdo {\n\t\t\t\t__le64 *sw_wqe;\n\t\t\t\tu64 wqe_qword;\n\t\t\t\tu32 tail;\n\n\t\t\t\ttail = qp->sq_ring.tail;\n\t\t\t\tsw_wqe = qp->sq_base[tail].elem;\n\t\t\t\tget_64bit_val(sw_wqe, 24,\n\t\t\t\t\t      &wqe_qword);\n\t\t\t\tinfo->op_type = (u8)FIELD_GET(IRDMAQPSQ_OPCODE,\n\t\t\t\t\t\t\t      wqe_qword);\n\t\t\t\tIRDMA_RING_SET_TAIL(qp->sq_ring,\n\t\t\t\t\t\t    tail + qp->sq_wrtrk_array[tail].quanta);\n\t\t\t\tif (info->op_type != IRDMAQP_OP_NOP) {\n\t\t\t\t\tinfo->wr_id = qp->sq_wrtrk_array[tail].wrid;\n\t\t\t\t\tinfo->bytes_xfered = qp->sq_wrtrk_array[tail].wr_len;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} while (1);\n\t\t\tif (info->op_type == IRDMA_OP_TYPE_BIND_MW &&\n\t\t\t    info->minor_err == FLUSH_PROT_ERR)\n\t\t\t\tinfo->minor_err = FLUSH_MW_BIND_ERR;\n\t\t\tqp->sq_flush_seen = true;\n\t\t\tif (!IRDMA_RING_MORE_WORK(qp->sq_ring))\n\t\t\t\tqp->sq_flush_complete = true;\n\t\t}\n\t\tpring = &qp->sq_ring;\n\t}\n\n\tret_code = 0;\n\nexit:\n\tif (!ret_code && info->comp_status == IRDMA_COMPL_STATUS_FLUSHED)\n\t\tif (pring && IRDMA_RING_MORE_WORK(*pring))\n\t\t\tmove_cq_head = false;\n\n\tif (move_cq_head) {\n\t\tIRDMA_RING_MOVE_HEAD_NOCHECK(cq->cq_ring);\n\t\tif (!IRDMA_RING_CURRENT_HEAD(cq->cq_ring))\n\t\t\tcq->polarity ^= 1;\n\n\t\tif (ext_valid && !cq->avoid_mem_cflct) {\n\t\t\tIRDMA_RING_MOVE_HEAD_NOCHECK(cq->cq_ring);\n\t\t\tif (!IRDMA_RING_CURRENT_HEAD(cq->cq_ring))\n\t\t\t\tcq->polarity ^= 1;\n\t\t}\n\n\t\tIRDMA_RING_MOVE_TAIL(cq->cq_ring);\n\t\tif (!cq->avoid_mem_cflct && ext_valid)\n\t\t\tIRDMA_RING_MOVE_TAIL(cq->cq_ring);\n\t\tset_64bit_val(cq->shadow_area, 0,\n\t\t\t      IRDMA_RING_CURRENT_HEAD(cq->cq_ring));\n\t} else {\n\t\tqword3 &= ~IRDMA_CQ_WQEIDX;\n\t\tqword3 |= FIELD_PREP(IRDMA_CQ_WQEIDX, pring->tail);\n\t\tset_64bit_val(cqe, 24, qword3);\n\t}\n\n\treturn ret_code;\n}\n\n \nstatic int irdma_qp_round_up(u32 wqdepth)\n{\n\tint scount = 1;\n\n\tfor (wqdepth--; scount <= 16; scount *= 2)\n\t\twqdepth |= wqdepth >> scount;\n\n\treturn ++wqdepth;\n}\n\n \nvoid irdma_get_wqe_shift(struct irdma_uk_attrs *uk_attrs, u32 sge,\n\t\t\t u32 inline_data, u8 *shift)\n{\n\t*shift = 0;\n\tif (uk_attrs->hw_rev >= IRDMA_GEN_2) {\n\t\tif (sge > 1 || inline_data > 8) {\n\t\t\tif (sge < 4 && inline_data <= 39)\n\t\t\t\t*shift = 1;\n\t\t\telse if (sge < 8 && inline_data <= 101)\n\t\t\t\t*shift = 2;\n\t\t\telse\n\t\t\t\t*shift = 3;\n\t\t}\n\t} else if (sge > 1 || inline_data > 16) {\n\t\t*shift = (sge < 4 && inline_data <= 48) ? 1 : 2;\n\t}\n}\n\n \nint irdma_get_sqdepth(struct irdma_uk_attrs *uk_attrs, u32 sq_size, u8 shift,\n\t\t      u32 *sqdepth)\n{\n\tu32 min_size = (u32)uk_attrs->min_hw_wq_size << shift;\n\n\t*sqdepth = irdma_qp_round_up((sq_size << shift) + IRDMA_SQ_RSVD);\n\n\tif (*sqdepth < min_size)\n\t\t*sqdepth = min_size;\n\telse if (*sqdepth > uk_attrs->max_hw_wq_quanta)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\n \nint irdma_get_rqdepth(struct irdma_uk_attrs *uk_attrs, u32 rq_size, u8 shift,\n\t\t      u32 *rqdepth)\n{\n\tu32 min_size = (u32)uk_attrs->min_hw_wq_size << shift;\n\n\t*rqdepth = irdma_qp_round_up((rq_size << shift) + IRDMA_RQ_RSVD);\n\n\tif (*rqdepth < min_size)\n\t\t*rqdepth = min_size;\n\telse if (*rqdepth > uk_attrs->max_hw_rq_quanta)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic const struct irdma_wqe_uk_ops iw_wqe_uk_ops = {\n\t.iw_copy_inline_data = irdma_copy_inline_data,\n\t.iw_inline_data_size_to_quanta = irdma_inline_data_size_to_quanta,\n\t.iw_set_fragment = irdma_set_fragment,\n\t.iw_set_mw_bind_wqe = irdma_set_mw_bind_wqe,\n};\n\nstatic const struct irdma_wqe_uk_ops iw_wqe_uk_ops_gen_1 = {\n\t.iw_copy_inline_data = irdma_copy_inline_data_gen_1,\n\t.iw_inline_data_size_to_quanta = irdma_inline_data_size_to_quanta_gen_1,\n\t.iw_set_fragment = irdma_set_fragment_gen_1,\n\t.iw_set_mw_bind_wqe = irdma_set_mw_bind_wqe_gen_1,\n};\n\n \nstatic void irdma_setup_connection_wqes(struct irdma_qp_uk *qp,\n\t\t\t\t\tstruct irdma_qp_uk_init_info *info)\n{\n\tu16 move_cnt = 1;\n\n\tif (!info->legacy_mode &&\n\t    (qp->uk_attrs->feature_flags & IRDMA_FEATURE_RTS_AE))\n\t\tmove_cnt = 3;\n\n\tqp->conn_wqes = move_cnt;\n\tIRDMA_RING_MOVE_HEAD_BY_COUNT_NOCHECK(qp->sq_ring, move_cnt);\n\tIRDMA_RING_MOVE_TAIL_BY_COUNT(qp->sq_ring, move_cnt);\n\tIRDMA_RING_MOVE_HEAD_BY_COUNT_NOCHECK(qp->initial_ring, move_cnt);\n}\n\n \nvoid irdma_uk_calc_shift_wq(struct irdma_qp_uk_init_info *ukinfo, u8 *sq_shift,\n\t\t\t    u8 *rq_shift)\n{\n\tbool imm_support = ukinfo->uk_attrs->hw_rev >= IRDMA_GEN_2;\n\n\tirdma_get_wqe_shift(ukinfo->uk_attrs,\n\t\t\t    imm_support ? ukinfo->max_sq_frag_cnt + 1 :\n\t\t\t\t\t  ukinfo->max_sq_frag_cnt,\n\t\t\t    ukinfo->max_inline_data, sq_shift);\n\n\tirdma_get_wqe_shift(ukinfo->uk_attrs, ukinfo->max_rq_frag_cnt, 0,\n\t\t\t    rq_shift);\n\n\tif (ukinfo->uk_attrs->hw_rev == IRDMA_GEN_1) {\n\t\tif (ukinfo->abi_ver > 4)\n\t\t\t*rq_shift = IRDMA_MAX_RQ_WQE_SHIFT_GEN1;\n\t}\n}\n\n \nint irdma_uk_calc_depth_shift_sq(struct irdma_qp_uk_init_info *ukinfo,\n\t\t\t\t u32 *sq_depth, u8 *sq_shift)\n{\n\tbool imm_support = ukinfo->uk_attrs->hw_rev >= IRDMA_GEN_2;\n\tint status;\n\n\tirdma_get_wqe_shift(ukinfo->uk_attrs,\n\t\t\t    imm_support ? ukinfo->max_sq_frag_cnt + 1 :\n\t\t\t    ukinfo->max_sq_frag_cnt,\n\t\t\t    ukinfo->max_inline_data, sq_shift);\n\tstatus = irdma_get_sqdepth(ukinfo->uk_attrs, ukinfo->sq_size,\n\t\t\t\t   *sq_shift, sq_depth);\n\n\treturn status;\n}\n\n \nint irdma_uk_calc_depth_shift_rq(struct irdma_qp_uk_init_info *ukinfo,\n\t\t\t\t u32 *rq_depth, u8 *rq_shift)\n{\n\tint status;\n\n\tirdma_get_wqe_shift(ukinfo->uk_attrs, ukinfo->max_rq_frag_cnt, 0,\n\t\t\t    rq_shift);\n\n\tif (ukinfo->uk_attrs->hw_rev == IRDMA_GEN_1) {\n\t\tif (ukinfo->abi_ver > 4)\n\t\t\t*rq_shift = IRDMA_MAX_RQ_WQE_SHIFT_GEN1;\n\t}\n\n\tstatus = irdma_get_rqdepth(ukinfo->uk_attrs, ukinfo->rq_size,\n\t\t\t\t   *rq_shift, rq_depth);\n\n\treturn status;\n}\n\n \nint irdma_uk_qp_init(struct irdma_qp_uk *qp, struct irdma_qp_uk_init_info *info)\n{\n\tint ret_code = 0;\n\tu32 sq_ring_size;\n\n\tqp->uk_attrs = info->uk_attrs;\n\tif (info->max_sq_frag_cnt > qp->uk_attrs->max_hw_wq_frags ||\n\t    info->max_rq_frag_cnt > qp->uk_attrs->max_hw_wq_frags)\n\t\treturn -EINVAL;\n\n\tqp->qp_caps = info->qp_caps;\n\tqp->sq_base = info->sq;\n\tqp->rq_base = info->rq;\n\tqp->qp_type = info->type ? info->type : IRDMA_QP_TYPE_IWARP;\n\tqp->shadow_area = info->shadow_area;\n\tqp->sq_wrtrk_array = info->sq_wrtrk_array;\n\n\tqp->rq_wrid_array = info->rq_wrid_array;\n\tqp->wqe_alloc_db = info->wqe_alloc_db;\n\tqp->qp_id = info->qp_id;\n\tqp->sq_size = info->sq_size;\n\tqp->max_sq_frag_cnt = info->max_sq_frag_cnt;\n\tsq_ring_size = qp->sq_size << info->sq_shift;\n\tIRDMA_RING_INIT(qp->sq_ring, sq_ring_size);\n\tIRDMA_RING_INIT(qp->initial_ring, sq_ring_size);\n\tif (info->first_sq_wq) {\n\t\tirdma_setup_connection_wqes(qp, info);\n\t\tqp->swqe_polarity = 1;\n\t\tqp->first_sq_wq = true;\n\t} else {\n\t\tqp->swqe_polarity = 0;\n\t}\n\tqp->swqe_polarity_deferred = 1;\n\tqp->rwqe_polarity = 0;\n\tqp->rq_size = info->rq_size;\n\tqp->max_rq_frag_cnt = info->max_rq_frag_cnt;\n\tqp->max_inline_data = info->max_inline_data;\n\tqp->rq_wqe_size = info->rq_shift;\n\tIRDMA_RING_INIT(qp->rq_ring, qp->rq_size);\n\tqp->rq_wqe_size_multiplier = 1 << info->rq_shift;\n\tif (qp->uk_attrs->hw_rev == IRDMA_GEN_1)\n\t\tqp->wqe_ops = iw_wqe_uk_ops_gen_1;\n\telse\n\t\tqp->wqe_ops = iw_wqe_uk_ops;\n\treturn ret_code;\n}\n\n \nvoid irdma_uk_cq_init(struct irdma_cq_uk *cq,\n\t\t      struct irdma_cq_uk_init_info *info)\n{\n\tcq->cq_base = info->cq_base;\n\tcq->cq_id = info->cq_id;\n\tcq->cq_size = info->cq_size;\n\tcq->cqe_alloc_db = info->cqe_alloc_db;\n\tcq->cq_ack_db = info->cq_ack_db;\n\tcq->shadow_area = info->shadow_area;\n\tcq->avoid_mem_cflct = info->avoid_mem_cflct;\n\tIRDMA_RING_INIT(cq->cq_ring, cq->cq_size);\n\tcq->polarity = 1;\n}\n\n \nvoid irdma_uk_clean_cq(void *q, struct irdma_cq_uk *cq)\n{\n\t__le64 *cqe;\n\tu64 qword3, comp_ctx;\n\tu32 cq_head;\n\tu8 polarity, temp;\n\n\tcq_head = cq->cq_ring.head;\n\ttemp = cq->polarity;\n\tdo {\n\t\tif (cq->avoid_mem_cflct)\n\t\t\tcqe = ((struct irdma_extended_cqe *)(cq->cq_base))[cq_head].buf;\n\t\telse\n\t\t\tcqe = cq->cq_base[cq_head].buf;\n\t\tget_64bit_val(cqe, 24, &qword3);\n\t\tpolarity = (u8)FIELD_GET(IRDMA_CQ_VALID, qword3);\n\n\t\tif (polarity != temp)\n\t\t\tbreak;\n\n\t\t \n\t\tdma_rmb();\n\n\t\tget_64bit_val(cqe, 8, &comp_ctx);\n\t\tif ((void *)(unsigned long)comp_ctx == q)\n\t\t\tset_64bit_val(cqe, 8, 0);\n\n\t\tcq_head = (cq_head + 1) % cq->cq_ring.size;\n\t\tif (!cq_head)\n\t\t\ttemp ^= 1;\n\t} while (true);\n}\n\n \nint irdma_nop(struct irdma_qp_uk *qp, u64 wr_id, bool signaled, bool post_sq)\n{\n\t__le64 *wqe;\n\tu64 hdr;\n\tu32 wqe_idx;\n\tstruct irdma_post_sq_info info = {};\n\n\tinfo.wr_id = wr_id;\n\twqe = irdma_qp_get_next_send_wqe(qp, &wqe_idx, IRDMA_QP_WQE_MIN_QUANTA,\n\t\t\t\t\t 0, &info);\n\tif (!wqe)\n\t\treturn -ENOMEM;\n\n\tirdma_clr_wqes(qp, wqe_idx);\n\n\tset_64bit_val(wqe, 0, 0);\n\tset_64bit_val(wqe, 8, 0);\n\tset_64bit_val(wqe, 16, 0);\n\n\thdr = FIELD_PREP(IRDMAQPSQ_OPCODE, IRDMAQP_OP_NOP) |\n\t      FIELD_PREP(IRDMAQPSQ_SIGCOMPL, signaled) |\n\t      FIELD_PREP(IRDMAQPSQ_VALID, qp->swqe_polarity);\n\n\tdma_wmb();  \n\n\tset_64bit_val(wqe, 24, hdr);\n\tif (post_sq)\n\t\tirdma_uk_qp_post_wr(qp);\n\n\treturn 0;\n}\n\n \nint irdma_fragcnt_to_quanta_sq(u32 frag_cnt, u16 *quanta)\n{\n\tswitch (frag_cnt) {\n\tcase 0:\n\tcase 1:\n\t\t*quanta = IRDMA_QP_WQE_MIN_QUANTA;\n\t\tbreak;\n\tcase 2:\n\tcase 3:\n\t\t*quanta = 2;\n\t\tbreak;\n\tcase 4:\n\tcase 5:\n\t\t*quanta = 3;\n\t\tbreak;\n\tcase 6:\n\tcase 7:\n\t\t*quanta = 4;\n\t\tbreak;\n\tcase 8:\n\tcase 9:\n\t\t*quanta = 5;\n\t\tbreak;\n\tcase 10:\n\tcase 11:\n\t\t*quanta = 6;\n\t\tbreak;\n\tcase 12:\n\tcase 13:\n\t\t*quanta = 7;\n\t\tbreak;\n\tcase 14:\n\tcase 15:  \n\t\t*quanta = 8;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nint irdma_fragcnt_to_wqesize_rq(u32 frag_cnt, u16 *wqe_size)\n{\n\tswitch (frag_cnt) {\n\tcase 0:\n\tcase 1:\n\t\t*wqe_size = 32;\n\t\tbreak;\n\tcase 2:\n\tcase 3:\n\t\t*wqe_size = 64;\n\t\tbreak;\n\tcase 4:\n\tcase 5:\n\tcase 6:\n\tcase 7:\n\t\t*wqe_size = 128;\n\t\tbreak;\n\tcase 8:\n\tcase 9:\n\tcase 10:\n\tcase 11:\n\tcase 12:\n\tcase 13:\n\tcase 14:\n\t\t*wqe_size = 256;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}