{
  "module_name": "ocrdma.h",
  "hash_id": "476e730edf505d3bef716eb125c6e79650c9a500bde8923a5879f6fc90c6971c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/ocrdma/ocrdma.h",
  "human_readable_source": " \n\n#ifndef __OCRDMA_H__\n#define __OCRDMA_H__\n\n#include <linux/mutex.h>\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/pci.h>\n\n#include <rdma/ib_verbs.h>\n#include <rdma/ib_user_verbs.h>\n#include <rdma/ib_addr.h>\n\n#include <be_roce.h>\n#include \"ocrdma_sli.h\"\n\n#define OCRDMA_ROCE_DRV_VERSION \"11.0.0.0\"\n\n#define OCRDMA_ROCE_DRV_DESC \"Emulex OneConnect RoCE Driver\"\n#define OCRDMA_NODE_DESC \"Emulex OneConnect RoCE HCA\"\n\n#define OC_NAME_SH\tOCRDMA_NODE_DESC \"(Skyhawk)\"\n#define OC_NAME_UNKNOWN OCRDMA_NODE_DESC \"(Unknown)\"\n\n#define OC_SKH_DEVICE_PF 0x720\n#define OC_SKH_DEVICE_VF 0x728\n#define OCRDMA_MAX_AH 512\n\n#define OCRDMA_UVERBS(CMD_NAME) (1ull << IB_USER_VERBS_CMD_##CMD_NAME)\n\n#define convert_to_64bit(lo, hi) ((u64)hi << 32 | (u64)lo)\n#define EQ_INTR_PER_SEC_THRSH_HI 150000\n#define EQ_INTR_PER_SEC_THRSH_LOW 100000\n#define EQ_AIC_MAX_EQD 20\n#define EQ_AIC_MIN_EQD 0\n\nvoid ocrdma_eqd_set_task(struct work_struct *work);\n\nstruct ocrdma_dev_attr {\n\tu8 fw_ver[32];\n\tu32 vendor_id;\n\tu32 device_id;\n\tu16 max_pd;\n\tu16 max_dpp_pds;\n\tu16 max_cq;\n\tu16 max_cqe;\n\tu16 max_qp;\n\tu16 max_wqe;\n\tu16 max_rqe;\n\tu16 max_srq;\n\tu32 max_inline_data;\n\tint max_send_sge;\n\tint max_recv_sge;\n\tint max_srq_sge;\n\tint max_rdma_sge;\n\tint max_mr;\n\tu64 max_mr_size;\n\tu32 max_num_mr_pbl;\n\tint max_mw;\n\tint max_map_per_fmr;\n\tint max_pages_per_frmr;\n\tu16 max_ord_per_qp;\n\tu16 max_ird_per_qp;\n\n\tint device_cap_flags;\n\tu8 cq_overflow_detect;\n\tu8 srq_supported;\n\n\tu32 wqe_size;\n\tu32 rqe_size;\n\tu32 ird_page_size;\n\tu8 local_ca_ack_delay;\n\tu8 ird;\n\tu8 num_ird_pages;\n\tu8 udp_encap;\n};\n\nstruct ocrdma_dma_mem {\n\tvoid *va;\n\tdma_addr_t pa;\n\tu32 size;\n};\n\nstruct ocrdma_pbl {\n\tvoid *va;\n\tdma_addr_t pa;\n};\n\nstruct ocrdma_queue_info {\n\tvoid *va;\n\tdma_addr_t dma;\n\tu32 size;\n\tu16 len;\n\tu16 entry_size;\t\t \n\tu16 id;\t\t\t \n\tu16 head, tail;\n\tbool created;\n};\n\nstruct ocrdma_aic_obj {          \n\tu32 prev_eqd;\n\tu64 eq_intr_cnt;\n\tu64 prev_eq_intr_cnt;\n};\n\nstruct ocrdma_eq {\n\tstruct ocrdma_queue_info q;\n\tu32 vector;\n\tint cq_cnt;\n\tstruct ocrdma_dev *dev;\n\tchar irq_name[32];\n\tstruct ocrdma_aic_obj aic_obj;\n};\n\nstruct ocrdma_mq {\n\tstruct ocrdma_queue_info sq;\n\tstruct ocrdma_queue_info cq;\n\tbool rearm_cq;\n};\n\nstruct mqe_ctx {\n\tstruct mutex lock;  \n\twait_queue_head_t cmd_wait;\n\tu32 tag;\n\tu16 cqe_status;\n\tu16 ext_status;\n\tbool cmd_done;\n\tbool fw_error_state;\n};\n\nstruct ocrdma_hw_mr {\n\tu32 lkey;\n\tu8 fr_mr;\n\tu8 remote_atomic;\n\tu8 remote_rd;\n\tu8 remote_wr;\n\tu8 local_rd;\n\tu8 local_wr;\n\tu8 mw_bind;\n\tu8 rsvd;\n\tu64 len;\n\tstruct ocrdma_pbl *pbl_table;\n\tu32 num_pbls;\n\tu32 num_pbes;\n\tu32 pbl_size;\n\tu32 pbe_size;\n\tu64 va;\n};\n\nstruct ocrdma_mr {\n\tstruct ib_mr ibmr;\n\tstruct ib_umem *umem;\n\tstruct ocrdma_hw_mr hwmr;\n\tu64 *pages;\n\tu32 npages;\n};\n\nstruct ocrdma_stats {\n\tu8 type;\n\tstruct ocrdma_dev *dev;\n};\n\nstruct ocrdma_pd_resource_mgr {\n\tu32 pd_norm_start;\n\tu16 pd_norm_count;\n\tu16 pd_norm_thrsh;\n\tu16 max_normal_pd;\n\tu32 pd_dpp_start;\n\tu16 pd_dpp_count;\n\tu16 pd_dpp_thrsh;\n\tu16 max_dpp_pd;\n\tu16 dpp_page_index;\n\tunsigned long *pd_norm_bitmap;\n\tunsigned long *pd_dpp_bitmap;\n\tbool pd_prealloc_valid;\n};\n\nstruct stats_mem {\n\tstruct ocrdma_mqe mqe;\n\tvoid *va;\n\tdma_addr_t pa;\n\tu32 size;\n\tchar *debugfs_mem;\n};\n\nstruct phy_info {\n\tu16 auto_speeds_supported;\n\tu16 fixed_speeds_supported;\n\tu16 phy_type;\n\tu16 interface_type;\n};\n\nenum ocrdma_flags {\n\tOCRDMA_FLAGS_LINK_STATUS_INIT = 0x01\n};\n\nstruct ocrdma_dev {\n\tstruct ib_device ibdev;\n\tstruct ocrdma_dev_attr attr;\n\n\tstruct mutex dev_lock;  \n\tspinlock_t flush_q_lock ____cacheline_aligned;\n\n\tstruct ocrdma_cq **cq_tbl;\n\tstruct ocrdma_qp **qp_tbl;\n\n\tstruct ocrdma_eq *eq_tbl;\n\tint eq_cnt;\n\tstruct delayed_work eqd_work;\n\tu16 base_eqid;\n\tu16 max_eq;\n\n\t \n\tspinlock_t sgid_lock;\n\n\tint gsi_qp_created;\n\tstruct ocrdma_cq *gsi_sqcq;\n\tstruct ocrdma_cq *gsi_rqcq;\n\n\tstruct {\n\t\tstruct ocrdma_av *va;\n\t\tdma_addr_t pa;\n\t\tu32 size;\n\t\tu32 num_ah;\n\t\t \n\t\tspinlock_t lock;\n\t\tu32 ahid;\n\t\tstruct ocrdma_pbl pbl;\n\t} av_tbl;\n\n\tvoid *mbx_cmd;\n\tstruct ocrdma_mq mq;\n\tstruct mqe_ctx mqe_ctx;\n\n\tstruct be_dev_info nic_info;\n\tstruct phy_info phy;\n\tchar model_number[32];\n\tu32 hba_port_num;\n\n\tstruct list_head entry;\n\tint id;\n\tu64 *stag_arr;\n\tu8 sl;  \n\tbool pfc_state;\n\tatomic_t update_sl;\n\tu16 pvid;\n\tu32 asic_id;\n\tu32 flags;\n\n\tulong last_stats_time;\n\tstruct mutex stats_lock;  \n\tstruct stats_mem stats_mem;\n\tstruct ocrdma_stats rsrc_stats;\n\tstruct ocrdma_stats rx_stats;\n\tstruct ocrdma_stats wqe_stats;\n\tstruct ocrdma_stats tx_stats;\n\tstruct ocrdma_stats db_err_stats;\n\tstruct ocrdma_stats tx_qp_err_stats;\n\tstruct ocrdma_stats rx_qp_err_stats;\n\tstruct ocrdma_stats tx_dbg_stats;\n\tstruct ocrdma_stats rx_dbg_stats;\n\tstruct ocrdma_stats driver_stats;\n\tstruct ocrdma_stats reset_stats;\n\tstruct dentry *dir;\n\tatomic_t async_err_stats[OCRDMA_MAX_ASYNC_ERRORS];\n\tatomic_t cqe_err_stats[OCRDMA_MAX_CQE_ERR];\n\tstruct ocrdma_pd_resource_mgr *pd_mgr;\n};\n\nstruct ocrdma_cq {\n\tstruct ib_cq ibcq;\n\tstruct ocrdma_cqe *va;\n\tu32 phase;\n\tu32 getp;\t \n\tu32 max_hw_cqe;\n\tbool phase_change;\n\tspinlock_t cq_lock ____cacheline_aligned;  \n\t \n\tspinlock_t comp_handler_lock ____cacheline_aligned;\n\tu16 id;\n\tu16 eqn;\n\n\tstruct ocrdma_ucontext *ucontext;\n\tdma_addr_t pa;\n\tu32 len;\n\tu32 cqe_cnt;\n\n\t \n\tstruct list_head sq_head, rq_head;\n};\n\nstruct ocrdma_pd {\n\tstruct ib_pd ibpd;\n\tstruct ocrdma_ucontext *uctx;\n\tu32 id;\n\tint num_dpp_qp;\n\tu32 dpp_page;\n\tbool dpp_enabled;\n};\n\nstruct ocrdma_ah {\n\tstruct ib_ah ibah;\n\tstruct ocrdma_av *av;\n\tu16 sgid_index;\n\tu32 id;\n\tu8 hdr_type;\n};\n\nstruct ocrdma_qp_hwq_info {\n\tu8 *va;\t\t\t \n\tu32 max_sges;\n\tu32 head, tail;\n\tu32 entry_size;\n\tu32 max_cnt;\n\tu32 max_wqe_idx;\n\tu16 dbid;\t\t \n\tu32 len;\n\tdma_addr_t pa;\n};\n\nstruct ocrdma_srq {\n\tstruct ib_srq ibsrq;\n\tu8 __iomem *db;\n\tstruct ocrdma_qp_hwq_info rq;\n\tu64 *rqe_wr_id_tbl;\n\tu32 *idx_bit_fields;\n\tu32 bit_fields_len;\n\n\t \n\tspinlock_t q_lock ____cacheline_aligned;\n\n\tstruct ocrdma_pd *pd;\n\tu32 id;\n};\n\nstruct ocrdma_qp {\n\tstruct ib_qp ibqp;\n\n\tu8 __iomem *sq_db;\n\tstruct ocrdma_qp_hwq_info sq;\n\tstruct {\n\t\tuint64_t wrid;\n\t\tuint16_t dpp_wqe_idx;\n\t\tuint16_t dpp_wqe;\n\t\tuint8_t  signaled;\n\t\tuint8_t  rsvd[3];\n\t} *wqe_wr_id_tbl;\n\tu32 max_inline_data;\n\n\t \n\tspinlock_t q_lock ____cacheline_aligned;\n\tstruct ocrdma_cq *sq_cq;\n\t \n\tstruct list_head sq_entry;\n\n\tu8 __iomem *rq_db;\n\tstruct ocrdma_qp_hwq_info rq;\n\tu64 *rqe_wr_id_tbl;\n\tstruct ocrdma_cq *rq_cq;\n\tstruct ocrdma_srq *srq;\n\t \n\tstruct list_head rq_entry;\n\n\tenum ocrdma_qp_state state;\t \n\tint cap_flags;\n\tu32 max_ord, max_ird;\n\n\tu32 id;\n\tstruct ocrdma_pd *pd;\n\n\tenum ib_qp_type qp_type;\n\n\tint sgid_idx;\n\tu32 qkey;\n\tbool dpp_enabled;\n\tu8 *ird_q_va;\n\tbool signaled;\n};\n\nstruct ocrdma_ucontext {\n\tstruct ib_ucontext ibucontext;\n\n\tstruct list_head mm_head;\n\tstruct mutex mm_list_lock;  \n\tstruct ocrdma_pd *cntxt_pd;\n\tint pd_in_use;\n\n\tstruct {\n\t\tu32 *va;\n\t\tdma_addr_t pa;\n\t\tu32 len;\n\t} ah_tbl;\n};\n\nstruct ocrdma_mm {\n\tstruct {\n\t\tu64 phy_addr;\n\t\tunsigned long len;\n\t} key;\n\tstruct list_head entry;\n};\n\nstatic inline struct ocrdma_dev *get_ocrdma_dev(struct ib_device *ibdev)\n{\n\treturn container_of(ibdev, struct ocrdma_dev, ibdev);\n}\n\nstatic inline struct ocrdma_ucontext *get_ocrdma_ucontext(struct ib_ucontext\n\t\t\t\t\t\t\t  *ibucontext)\n{\n\treturn container_of(ibucontext, struct ocrdma_ucontext, ibucontext);\n}\n\nstatic inline struct ocrdma_pd *get_ocrdma_pd(struct ib_pd *ibpd)\n{\n\treturn container_of(ibpd, struct ocrdma_pd, ibpd);\n}\n\nstatic inline struct ocrdma_cq *get_ocrdma_cq(struct ib_cq *ibcq)\n{\n\treturn container_of(ibcq, struct ocrdma_cq, ibcq);\n}\n\nstatic inline struct ocrdma_qp *get_ocrdma_qp(struct ib_qp *ibqp)\n{\n\treturn container_of(ibqp, struct ocrdma_qp, ibqp);\n}\n\nstatic inline struct ocrdma_mr *get_ocrdma_mr(struct ib_mr *ibmr)\n{\n\treturn container_of(ibmr, struct ocrdma_mr, ibmr);\n}\n\nstatic inline struct ocrdma_ah *get_ocrdma_ah(struct ib_ah *ibah)\n{\n\treturn container_of(ibah, struct ocrdma_ah, ibah);\n}\n\nstatic inline struct ocrdma_srq *get_ocrdma_srq(struct ib_srq *ibsrq)\n{\n\treturn container_of(ibsrq, struct ocrdma_srq, ibsrq);\n}\n\nstatic inline int is_cqe_valid(struct ocrdma_cq *cq, struct ocrdma_cqe *cqe)\n{\n\tint cqe_valid;\n\tcqe_valid = le32_to_cpu(cqe->flags_status_srcqpn) & OCRDMA_CQE_VALID;\n\treturn (cqe_valid == cq->phase);\n}\n\nstatic inline int is_cqe_for_sq(struct ocrdma_cqe *cqe)\n{\n\treturn (le32_to_cpu(cqe->flags_status_srcqpn) &\n\t\tOCRDMA_CQE_QTYPE) ? 0 : 1;\n}\n\nstatic inline int is_cqe_invalidated(struct ocrdma_cqe *cqe)\n{\n\treturn (le32_to_cpu(cqe->flags_status_srcqpn) &\n\t\tOCRDMA_CQE_INVALIDATE) ? 1 : 0;\n}\n\nstatic inline int is_cqe_imm(struct ocrdma_cqe *cqe)\n{\n\treturn (le32_to_cpu(cqe->flags_status_srcqpn) &\n\t\tOCRDMA_CQE_IMM) ? 1 : 0;\n}\n\nstatic inline int is_cqe_wr_imm(struct ocrdma_cqe *cqe)\n{\n\treturn (le32_to_cpu(cqe->flags_status_srcqpn) &\n\t\tOCRDMA_CQE_WRITE_IMM) ? 1 : 0;\n}\n\nstatic inline int ocrdma_resolve_dmac(struct ocrdma_dev *dev,\n\t\tstruct rdma_ah_attr *ah_attr, u8 *mac_addr)\n{\n\tstruct in6_addr in6;\n\n\tmemcpy(&in6, rdma_ah_read_grh(ah_attr)->dgid.raw, sizeof(in6));\n\tif (rdma_is_multicast_addr(&in6))\n\t\trdma_get_mcast_mac(&in6, mac_addr);\n\telse if (rdma_link_local_addr(&in6))\n\t\trdma_get_ll_mac(&in6, mac_addr);\n\telse\n\t\tmemcpy(mac_addr, ah_attr->roce.dmac, ETH_ALEN);\n\treturn 0;\n}\n\nstatic inline char *hca_name(struct ocrdma_dev *dev)\n{\n\tswitch (dev->nic_info.pdev->device) {\n\tcase OC_SKH_DEVICE_PF:\n\tcase OC_SKH_DEVICE_VF:\n\t\treturn OC_NAME_SH;\n\tdefault:\n\t\treturn OC_NAME_UNKNOWN;\n\t}\n}\n\nstatic inline int ocrdma_get_eq_table_index(struct ocrdma_dev *dev,\n\t\tint eqid)\n{\n\tint indx;\n\n\tfor (indx = 0; indx < dev->eq_cnt; indx++) {\n\t\tif (dev->eq_tbl[indx].q.id == eqid)\n\t\t\treturn indx;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic inline u8 ocrdma_get_asic_type(struct ocrdma_dev *dev)\n{\n\tif (dev->nic_info.dev_family == 0xF && !dev->asic_id) {\n\t\tpci_read_config_dword(\n\t\t\tdev->nic_info.pdev,\n\t\t\tOCRDMA_SLI_ASIC_ID_OFFSET, &dev->asic_id);\n\t}\n\n\treturn (dev->asic_id & OCRDMA_SLI_ASIC_GEN_NUM_MASK) >>\n\t\t\t\tOCRDMA_SLI_ASIC_GEN_NUM_SHIFT;\n}\n\nstatic inline u8 ocrdma_get_pfc_prio(u8 *pfc, u8 prio)\n{\n\treturn *(pfc + prio);\n}\n\nstatic inline u8 ocrdma_get_app_prio(u8 *app_prio, u8 prio)\n{\n\treturn *(app_prio + prio);\n}\n\nstatic inline u8 ocrdma_is_enabled_and_synced(u32 state)\n{\t \n\treturn (state & OCRDMA_STATE_FLAG_ENABLED) &&\n\t\t(state & OCRDMA_STATE_FLAG_SYNC);\n}\n\nstatic inline u8 ocrdma_get_ae_link_state(u32 ae_state)\n{\n\treturn ((ae_state & OCRDMA_AE_LSC_LS_MASK) >> OCRDMA_AE_LSC_LS_SHIFT);\n}\n\nstatic inline bool ocrdma_is_udp_encap_supported(struct ocrdma_dev *dev)\n{\n\treturn (dev->attr.udp_encap & OCRDMA_L3_TYPE_IPV4) ||\n\t       (dev->attr.udp_encap & OCRDMA_L3_TYPE_IPV6);\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}