{
  "module_name": "pvrdma.h",
  "hash_id": "6512b99b6adfa6d7a0e3a3ed90394868088b8234b485d87e14f52e05bb2dcd7d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/vmw_pvrdma/pvrdma.h",
  "human_readable_source": " \n\n#ifndef __PVRDMA_H__\n#define __PVRDMA_H__\n\n#include <linux/compiler.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/mutex.h>\n#include <linux/pci.h>\n#include <linux/semaphore.h>\n#include <linux/workqueue.h>\n#include <rdma/ib_umem.h>\n#include <rdma/ib_verbs.h>\n#include <rdma/vmw_pvrdma-abi.h>\n\n#include \"pvrdma_ring.h\"\n#include \"pvrdma_dev_api.h\"\n#include \"pvrdma_verbs.h\"\n\n \n#define PVRDMA_MASK(n) ((n << 1) - 1)\n\n \n#define PCI_DEVICE_ID_VMWARE_PVRDMA\t0x0820\n\n#define PVRDMA_NUM_RING_PAGES\t\t4\n#define PVRDMA_QP_NUM_HEADER_PAGES\t1\n\nstruct pvrdma_dev;\n\nstruct pvrdma_page_dir {\n\tdma_addr_t dir_dma;\n\tu64 *dir;\n\tint ntables;\n\tu64 **tables;\n\tu64 npages;\n\tvoid **pages;\n};\n\nstruct pvrdma_cq {\n\tstruct ib_cq ibcq;\n\tint offset;\n\tspinlock_t cq_lock;  \n\tstruct pvrdma_uar_map *uar;\n\tstruct ib_umem *umem;\n\tstruct pvrdma_ring_state *ring_state;\n\tstruct pvrdma_page_dir pdir;\n\tu32 cq_handle;\n\tbool is_kernel;\n\trefcount_t refcnt;\n\tstruct completion free;\n};\n\nstruct pvrdma_id_table {\n\tu32 last;\n\tu32 top;\n\tu32 max;\n\tu32 mask;\n\tspinlock_t lock;  \n\tunsigned long *table;\n};\n\nstruct pvrdma_uar_map {\n\tunsigned long pfn;\n\tvoid __iomem *map;\n\tint index;\n};\n\nstruct pvrdma_uar_table {\n\tstruct pvrdma_id_table tbl;\n\tint size;\n};\n\nstruct pvrdma_ucontext {\n\tstruct ib_ucontext ibucontext;\n\tstruct pvrdma_dev *dev;\n\tstruct pvrdma_uar_map uar;\n\tu64 ctx_handle;\n};\n\nstruct pvrdma_pd {\n\tstruct ib_pd ibpd;\n\tu32 pdn;\n\tu32 pd_handle;\n\tint privileged;\n};\n\nstruct pvrdma_mr {\n\tu32 mr_handle;\n\tu64 iova;\n\tu64 size;\n};\n\nstruct pvrdma_user_mr {\n\tstruct ib_mr ibmr;\n\tstruct ib_umem *umem;\n\tstruct pvrdma_mr mmr;\n\tstruct pvrdma_page_dir pdir;\n\tu64 *pages;\n\tu32 npages;\n\tu32 max_pages;\n\tu32 page_shift;\n};\n\nstruct pvrdma_wq {\n\tstruct pvrdma_ring *ring;\n\tspinlock_t lock;  \n\tint wqe_cnt;\n\tint wqe_size;\n\tint max_sg;\n\tint offset;\n};\n\nstruct pvrdma_ah {\n\tstruct ib_ah ibah;\n\tstruct pvrdma_av av;\n};\n\nstruct pvrdma_srq {\n\tstruct ib_srq ibsrq;\n\tint offset;\n\tspinlock_t lock;  \n\tint wqe_cnt;\n\tint wqe_size;\n\tint max_gs;\n\tstruct ib_umem *umem;\n\tstruct pvrdma_ring_state *ring;\n\tstruct pvrdma_page_dir pdir;\n\tu32 srq_handle;\n\tint npages;\n\trefcount_t refcnt;\n\tstruct completion free;\n};\n\nstruct pvrdma_qp {\n\tstruct ib_qp ibqp;\n\tu32 qp_handle;\n\tu32 qkey;\n\tstruct pvrdma_wq sq;\n\tstruct pvrdma_wq rq;\n\tstruct ib_umem *rumem;\n\tstruct ib_umem *sumem;\n\tstruct pvrdma_page_dir pdir;\n\tstruct pvrdma_srq *srq;\n\tint npages;\n\tint npages_send;\n\tint npages_recv;\n\tu32 flags;\n\tu8 port;\n\tu8 state;\n\tbool is_kernel;\n\tstruct mutex mutex;  \n\trefcount_t refcnt;\n\tstruct completion free;\n};\n\nstruct pvrdma_dev {\n\t \n\tstruct ib_device ib_dev;\n\tstruct pci_dev *pdev;\n\tvoid __iomem *regs;\n\tstruct pvrdma_device_shared_region *dsr;  \n\tdma_addr_t dsrbase;  \n\tvoid *cmd_slot;\n\tvoid *resp_slot;\n\tunsigned long flags;\n\tstruct list_head device_link;\n\tunsigned int dsr_version;\n\n\t \n\tspinlock_t cmd_lock;  \n\tstruct semaphore cmd_sema;\n\tstruct completion cmd_done;\n\tunsigned int nr_vectors;\n\n\t \n\tunion ib_gid *sgid_tbl;\n\tstruct pvrdma_ring_state *async_ring_state;\n\tstruct pvrdma_page_dir async_pdir;\n\tstruct pvrdma_ring_state *cq_ring_state;\n\tstruct pvrdma_page_dir cq_pdir;\n\tstruct pvrdma_cq **cq_tbl;\n\tspinlock_t cq_tbl_lock;\n\tstruct pvrdma_srq **srq_tbl;\n\tspinlock_t srq_tbl_lock;\n\tstruct pvrdma_qp **qp_tbl;\n\tspinlock_t qp_tbl_lock;\n\tstruct pvrdma_uar_table uar_table;\n\tstruct pvrdma_uar_map driver_uar;\n\t__be64 sys_image_guid;\n\tspinlock_t desc_lock;  \n\tu32 port_cap_mask;\n\tstruct mutex port_mutex;  \n\tbool ib_active;\n\tatomic_t num_qps;\n\tatomic_t num_cqs;\n\tatomic_t num_srqs;\n\tatomic_t num_pds;\n\tatomic_t num_ahs;\n\n\t \n\tstruct net_device *netdev;\n\tstruct notifier_block nb_netdev;\n};\n\nstruct pvrdma_netdevice_work {\n\tstruct work_struct work;\n\tstruct net_device *event_netdev;\n\tunsigned long event;\n};\n\nstatic inline struct pvrdma_dev *to_vdev(struct ib_device *ibdev)\n{\n\treturn container_of(ibdev, struct pvrdma_dev, ib_dev);\n}\n\nstatic inline struct\npvrdma_ucontext *to_vucontext(struct ib_ucontext *ibucontext)\n{\n\treturn container_of(ibucontext, struct pvrdma_ucontext, ibucontext);\n}\n\nstatic inline struct pvrdma_pd *to_vpd(struct ib_pd *ibpd)\n{\n\treturn container_of(ibpd, struct pvrdma_pd, ibpd);\n}\n\nstatic inline struct pvrdma_cq *to_vcq(struct ib_cq *ibcq)\n{\n\treturn container_of(ibcq, struct pvrdma_cq, ibcq);\n}\n\nstatic inline struct pvrdma_srq *to_vsrq(struct ib_srq *ibsrq)\n{\n\treturn container_of(ibsrq, struct pvrdma_srq, ibsrq);\n}\n\nstatic inline struct pvrdma_user_mr *to_vmr(struct ib_mr *ibmr)\n{\n\treturn container_of(ibmr, struct pvrdma_user_mr, ibmr);\n}\n\nstatic inline struct pvrdma_qp *to_vqp(struct ib_qp *ibqp)\n{\n\treturn container_of(ibqp, struct pvrdma_qp, ibqp);\n}\n\nstatic inline struct pvrdma_ah *to_vah(struct ib_ah *ibah)\n{\n\treturn container_of(ibah, struct pvrdma_ah, ibah);\n}\n\nstatic inline void pvrdma_write_reg(struct pvrdma_dev *dev, u32 reg, u32 val)\n{\n\twritel(cpu_to_le32(val), dev->regs + reg);\n}\n\nstatic inline u32 pvrdma_read_reg(struct pvrdma_dev *dev, u32 reg)\n{\n\treturn le32_to_cpu(readl(dev->regs + reg));\n}\n\nstatic inline void pvrdma_write_uar_cq(struct pvrdma_dev *dev, u32 val)\n{\n\twritel(cpu_to_le32(val), dev->driver_uar.map + PVRDMA_UAR_CQ_OFFSET);\n}\n\nstatic inline void pvrdma_write_uar_qp(struct pvrdma_dev *dev, u32 val)\n{\n\twritel(cpu_to_le32(val), dev->driver_uar.map + PVRDMA_UAR_QP_OFFSET);\n}\n\nstatic inline void *pvrdma_page_dir_get_ptr(struct pvrdma_page_dir *pdir,\n\t\t\t\t\t    u64 offset)\n{\n\treturn pdir->pages[offset / PAGE_SIZE] + (offset % PAGE_SIZE);\n}\n\nstatic inline enum pvrdma_mtu ib_mtu_to_pvrdma(enum ib_mtu mtu)\n{\n\treturn (enum pvrdma_mtu)mtu;\n}\n\nstatic inline enum ib_mtu pvrdma_mtu_to_ib(enum pvrdma_mtu mtu)\n{\n\treturn (enum ib_mtu)mtu;\n}\n\nstatic inline enum pvrdma_port_state ib_port_state_to_pvrdma(\n\t\t\t\t\tenum ib_port_state state)\n{\n\treturn (enum pvrdma_port_state)state;\n}\n\nstatic inline enum ib_port_state pvrdma_port_state_to_ib(\n\t\t\t\t\tenum pvrdma_port_state state)\n{\n\treturn (enum ib_port_state)state;\n}\n\nstatic inline int pvrdma_port_cap_flags_to_ib(int flags)\n{\n\treturn flags;\n}\n\nstatic inline enum pvrdma_port_width ib_port_width_to_pvrdma(\n\t\t\t\t\tenum ib_port_width width)\n{\n\treturn (enum pvrdma_port_width)width;\n}\n\nstatic inline enum ib_port_width pvrdma_port_width_to_ib(\n\t\t\t\t\tenum pvrdma_port_width width)\n{\n\treturn (enum ib_port_width)width;\n}\n\nstatic inline enum pvrdma_port_speed ib_port_speed_to_pvrdma(\n\t\t\t\t\tenum ib_port_speed speed)\n{\n\treturn (enum pvrdma_port_speed)speed;\n}\n\nstatic inline enum ib_port_speed pvrdma_port_speed_to_ib(\n\t\t\t\t\tenum pvrdma_port_speed speed)\n{\n\treturn (enum ib_port_speed)speed;\n}\n\nstatic inline int ib_qp_attr_mask_to_pvrdma(int attr_mask)\n{\n\treturn attr_mask & PVRDMA_MASK(PVRDMA_QP_ATTR_MASK_MAX);\n}\n\nstatic inline enum pvrdma_mig_state ib_mig_state_to_pvrdma(\n\t\t\t\t\tenum ib_mig_state state)\n{\n\treturn (enum pvrdma_mig_state)state;\n}\n\nstatic inline enum ib_mig_state pvrdma_mig_state_to_ib(\n\t\t\t\t\tenum pvrdma_mig_state state)\n{\n\treturn (enum ib_mig_state)state;\n}\n\nstatic inline int ib_access_flags_to_pvrdma(int flags)\n{\n\treturn flags;\n}\n\nstatic inline int pvrdma_access_flags_to_ib(int flags)\n{\n\treturn flags & PVRDMA_MASK(PVRDMA_ACCESS_FLAGS_MAX);\n}\n\nstatic inline enum pvrdma_qp_type ib_qp_type_to_pvrdma(enum ib_qp_type type)\n{\n\treturn (enum pvrdma_qp_type)type;\n}\n\nstatic inline enum pvrdma_qp_state ib_qp_state_to_pvrdma(enum ib_qp_state state)\n{\n\treturn (enum pvrdma_qp_state)state;\n}\n\nstatic inline enum ib_qp_state pvrdma_qp_state_to_ib(enum pvrdma_qp_state state)\n{\n\treturn (enum ib_qp_state)state;\n}\n\nstatic inline enum pvrdma_wr_opcode ib_wr_opcode_to_pvrdma(enum ib_wr_opcode op)\n{\n\tswitch (op) {\n\tcase IB_WR_RDMA_WRITE:\n\t\treturn PVRDMA_WR_RDMA_WRITE;\n\tcase IB_WR_RDMA_WRITE_WITH_IMM:\n\t\treturn PVRDMA_WR_RDMA_WRITE_WITH_IMM;\n\tcase IB_WR_SEND:\n\t\treturn PVRDMA_WR_SEND;\n\tcase IB_WR_SEND_WITH_IMM:\n\t\treturn PVRDMA_WR_SEND_WITH_IMM;\n\tcase IB_WR_RDMA_READ:\n\t\treturn PVRDMA_WR_RDMA_READ;\n\tcase IB_WR_ATOMIC_CMP_AND_SWP:\n\t\treturn PVRDMA_WR_ATOMIC_CMP_AND_SWP;\n\tcase IB_WR_ATOMIC_FETCH_AND_ADD:\n\t\treturn PVRDMA_WR_ATOMIC_FETCH_AND_ADD;\n\tcase IB_WR_LSO:\n\t\treturn PVRDMA_WR_LSO;\n\tcase IB_WR_SEND_WITH_INV:\n\t\treturn PVRDMA_WR_SEND_WITH_INV;\n\tcase IB_WR_RDMA_READ_WITH_INV:\n\t\treturn PVRDMA_WR_RDMA_READ_WITH_INV;\n\tcase IB_WR_LOCAL_INV:\n\t\treturn PVRDMA_WR_LOCAL_INV;\n\tcase IB_WR_REG_MR:\n\t\treturn PVRDMA_WR_FAST_REG_MR;\n\tcase IB_WR_MASKED_ATOMIC_CMP_AND_SWP:\n\t\treturn PVRDMA_WR_MASKED_ATOMIC_CMP_AND_SWP;\n\tcase IB_WR_MASKED_ATOMIC_FETCH_AND_ADD:\n\t\treturn PVRDMA_WR_MASKED_ATOMIC_FETCH_AND_ADD;\n\tcase IB_WR_REG_MR_INTEGRITY:\n\t\treturn PVRDMA_WR_REG_SIG_MR;\n\tdefault:\n\t\treturn PVRDMA_WR_ERROR;\n\t}\n}\n\nstatic inline enum ib_wc_status pvrdma_wc_status_to_ib(\n\t\t\t\t\tenum pvrdma_wc_status status)\n{\n\treturn (enum ib_wc_status)status;\n}\n\nstatic inline int pvrdma_wc_opcode_to_ib(unsigned int opcode)\n{\n\tswitch (opcode) {\n\tcase PVRDMA_WC_SEND:\n\t\treturn IB_WC_SEND;\n\tcase PVRDMA_WC_RDMA_WRITE:\n\t\treturn IB_WC_RDMA_WRITE;\n\tcase PVRDMA_WC_RDMA_READ:\n\t\treturn IB_WC_RDMA_READ;\n\tcase PVRDMA_WC_COMP_SWAP:\n\t\treturn IB_WC_COMP_SWAP;\n\tcase PVRDMA_WC_FETCH_ADD:\n\t\treturn IB_WC_FETCH_ADD;\n\tcase PVRDMA_WC_LOCAL_INV:\n\t\treturn IB_WC_LOCAL_INV;\n\tcase PVRDMA_WC_FAST_REG_MR:\n\t\treturn IB_WC_REG_MR;\n\tcase PVRDMA_WC_MASKED_COMP_SWAP:\n\t\treturn IB_WC_MASKED_COMP_SWAP;\n\tcase PVRDMA_WC_MASKED_FETCH_ADD:\n\t\treturn IB_WC_MASKED_FETCH_ADD;\n\tcase PVRDMA_WC_RECV:\n\t\treturn IB_WC_RECV;\n\tcase PVRDMA_WC_RECV_RDMA_WITH_IMM:\n\t\treturn IB_WC_RECV_RDMA_WITH_IMM;\n\tdefault:\n\t\treturn IB_WC_SEND;\n\t}\n}\n\nstatic inline int pvrdma_wc_flags_to_ib(int flags)\n{\n\treturn flags;\n}\n\nstatic inline int ib_send_flags_to_pvrdma(int flags)\n{\n\treturn flags & PVRDMA_MASK(PVRDMA_SEND_FLAGS_MAX);\n}\n\nstatic inline int pvrdma_network_type_to_ib(enum pvrdma_network_type type)\n{\n\tswitch (type) {\n\tcase PVRDMA_NETWORK_ROCE_V1:\n\t\treturn RDMA_NETWORK_ROCE_V1;\n\tcase PVRDMA_NETWORK_IPV4:\n\t\treturn RDMA_NETWORK_IPV4;\n\tcase PVRDMA_NETWORK_IPV6:\n\t\treturn RDMA_NETWORK_IPV6;\n\tdefault:\n\t\treturn RDMA_NETWORK_IPV6;\n\t}\n}\n\nvoid pvrdma_qp_cap_to_ib(struct ib_qp_cap *dst,\n\t\t\t const struct pvrdma_qp_cap *src);\nvoid ib_qp_cap_to_pvrdma(struct pvrdma_qp_cap *dst,\n\t\t\t const struct ib_qp_cap *src);\nvoid pvrdma_gid_to_ib(union ib_gid *dst, const union pvrdma_gid *src);\nvoid ib_gid_to_pvrdma(union pvrdma_gid *dst, const union ib_gid *src);\nvoid pvrdma_global_route_to_ib(struct ib_global_route *dst,\n\t\t\t       const struct pvrdma_global_route *src);\nvoid ib_global_route_to_pvrdma(struct pvrdma_global_route *dst,\n\t\t\t       const struct ib_global_route *src);\nvoid pvrdma_ah_attr_to_rdma(struct rdma_ah_attr *dst,\n\t\t\t    const struct pvrdma_ah_attr *src);\nvoid rdma_ah_attr_to_pvrdma(struct pvrdma_ah_attr *dst,\n\t\t\t    const struct rdma_ah_attr *src);\nu8 ib_gid_type_to_pvrdma(enum ib_gid_type gid_type);\n\nint pvrdma_uar_table_init(struct pvrdma_dev *dev);\nvoid pvrdma_uar_table_cleanup(struct pvrdma_dev *dev);\n\nint pvrdma_uar_alloc(struct pvrdma_dev *dev, struct pvrdma_uar_map *uar);\nvoid pvrdma_uar_free(struct pvrdma_dev *dev, struct pvrdma_uar_map *uar);\n\nvoid _pvrdma_flush_cqe(struct pvrdma_qp *qp, struct pvrdma_cq *cq);\n\nint pvrdma_page_dir_init(struct pvrdma_dev *dev, struct pvrdma_page_dir *pdir,\n\t\t\t u64 npages, bool alloc_pages);\nvoid pvrdma_page_dir_cleanup(struct pvrdma_dev *dev,\n\t\t\t     struct pvrdma_page_dir *pdir);\nint pvrdma_page_dir_insert_dma(struct pvrdma_page_dir *pdir, u64 idx,\n\t\t\t       dma_addr_t daddr);\nint pvrdma_page_dir_insert_umem(struct pvrdma_page_dir *pdir,\n\t\t\t\tstruct ib_umem *umem, u64 offset);\ndma_addr_t pvrdma_page_dir_get_dma(struct pvrdma_page_dir *pdir, u64 idx);\nint pvrdma_page_dir_insert_page_list(struct pvrdma_page_dir *pdir,\n\t\t\t\t     u64 *page_list, int num_pages);\n\nint pvrdma_cmd_post(struct pvrdma_dev *dev, union pvrdma_cmd_req *req,\n\t\t    union pvrdma_cmd_resp *rsp, unsigned resp_code);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}