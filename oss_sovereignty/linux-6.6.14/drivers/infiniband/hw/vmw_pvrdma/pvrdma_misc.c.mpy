{
  "module_name": "pvrdma_misc.c",
  "hash_id": "bb43e924598b48887e0ebd5eeeda1b15dc25a8e93b2f04f042da1366bd228cb5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/vmw_pvrdma/pvrdma_misc.c",
  "human_readable_source": " \n\n#include <linux/errno.h>\n#include <linux/slab.h>\n#include <linux/bitmap.h>\n\n#include \"pvrdma.h\"\n\nint pvrdma_page_dir_init(struct pvrdma_dev *dev, struct pvrdma_page_dir *pdir,\n\t\t\t u64 npages, bool alloc_pages)\n{\n\tu64 i;\n\n\tif (npages > PVRDMA_PAGE_DIR_MAX_PAGES)\n\t\treturn -EINVAL;\n\n\tmemset(pdir, 0, sizeof(*pdir));\n\n\tpdir->dir = dma_alloc_coherent(&dev->pdev->dev, PAGE_SIZE,\n\t\t\t\t       &pdir->dir_dma, GFP_KERNEL);\n\tif (!pdir->dir)\n\t\tgoto err;\n\n\tpdir->ntables = PVRDMA_PAGE_DIR_TABLE(npages - 1) + 1;\n\tpdir->tables = kcalloc(pdir->ntables, sizeof(*pdir->tables),\n\t\t\t       GFP_KERNEL);\n\tif (!pdir->tables)\n\t\tgoto err;\n\n\tfor (i = 0; i < pdir->ntables; i++) {\n\t\tpdir->tables[i] = dma_alloc_coherent(&dev->pdev->dev, PAGE_SIZE,\n\t\t\t\t\t\t(dma_addr_t *)&pdir->dir[i],\n\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (!pdir->tables[i])\n\t\t\tgoto err;\n\t}\n\n\tpdir->npages = npages;\n\n\tif (alloc_pages) {\n\t\tpdir->pages = kcalloc(npages, sizeof(*pdir->pages),\n\t\t\t\t      GFP_KERNEL);\n\t\tif (!pdir->pages)\n\t\t\tgoto err;\n\n\t\tfor (i = 0; i < pdir->npages; i++) {\n\t\t\tdma_addr_t page_dma;\n\n\t\t\tpdir->pages[i] = dma_alloc_coherent(&dev->pdev->dev,\n\t\t\t\t\t\t\t    PAGE_SIZE,\n\t\t\t\t\t\t\t    &page_dma,\n\t\t\t\t\t\t\t    GFP_KERNEL);\n\t\t\tif (!pdir->pages[i])\n\t\t\t\tgoto err;\n\n\t\t\tpvrdma_page_dir_insert_dma(pdir, i, page_dma);\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\tpvrdma_page_dir_cleanup(dev, pdir);\n\n\treturn -ENOMEM;\n}\n\nstatic u64 *pvrdma_page_dir_table(struct pvrdma_page_dir *pdir, u64 idx)\n{\n\treturn pdir->tables[PVRDMA_PAGE_DIR_TABLE(idx)];\n}\n\ndma_addr_t pvrdma_page_dir_get_dma(struct pvrdma_page_dir *pdir, u64 idx)\n{\n\treturn pvrdma_page_dir_table(pdir, idx)[PVRDMA_PAGE_DIR_PAGE(idx)];\n}\n\nstatic void pvrdma_page_dir_cleanup_pages(struct pvrdma_dev *dev,\n\t\t\t\t\t  struct pvrdma_page_dir *pdir)\n{\n\tif (pdir->pages) {\n\t\tu64 i;\n\n\t\tfor (i = 0; i < pdir->npages && pdir->pages[i]; i++) {\n\t\t\tdma_addr_t page_dma = pvrdma_page_dir_get_dma(pdir, i);\n\n\t\t\tdma_free_coherent(&dev->pdev->dev, PAGE_SIZE,\n\t\t\t\t\t  pdir->pages[i], page_dma);\n\t\t}\n\n\t\tkfree(pdir->pages);\n\t}\n}\n\nstatic void pvrdma_page_dir_cleanup_tables(struct pvrdma_dev *dev,\n\t\t\t\t\t   struct pvrdma_page_dir *pdir)\n{\n\tif (pdir->tables) {\n\t\tint i;\n\n\t\tpvrdma_page_dir_cleanup_pages(dev, pdir);\n\n\t\tfor (i = 0; i < pdir->ntables; i++) {\n\t\t\tu64 *table = pdir->tables[i];\n\n\t\t\tif (table)\n\t\t\t\tdma_free_coherent(&dev->pdev->dev, PAGE_SIZE,\n\t\t\t\t\t\t  table, pdir->dir[i]);\n\t\t}\n\n\t\tkfree(pdir->tables);\n\t}\n}\n\nvoid pvrdma_page_dir_cleanup(struct pvrdma_dev *dev,\n\t\t\t     struct pvrdma_page_dir *pdir)\n{\n\tif (pdir->dir) {\n\t\tpvrdma_page_dir_cleanup_tables(dev, pdir);\n\t\tdma_free_coherent(&dev->pdev->dev, PAGE_SIZE,\n\t\t\t\t  pdir->dir, pdir->dir_dma);\n\t}\n}\n\nint pvrdma_page_dir_insert_dma(struct pvrdma_page_dir *pdir, u64 idx,\n\t\t\t       dma_addr_t daddr)\n{\n\tu64 *table;\n\n\tif (idx >= pdir->npages)\n\t\treturn -EINVAL;\n\n\ttable = pvrdma_page_dir_table(pdir, idx);\n\ttable[PVRDMA_PAGE_DIR_PAGE(idx)] = daddr;\n\n\treturn 0;\n}\n\nint pvrdma_page_dir_insert_umem(struct pvrdma_page_dir *pdir,\n\t\t\t\tstruct ib_umem *umem, u64 offset)\n{\n\tstruct ib_block_iter biter;\n\tu64 i = offset;\n\tint ret = 0;\n\n\tif (offset >= pdir->npages)\n\t\treturn -EINVAL;\n\n\trdma_umem_for_each_dma_block (umem, &biter, PAGE_SIZE) {\n\t\tret = pvrdma_page_dir_insert_dma(\n\t\t\tpdir, i, rdma_block_iter_dma_address(&biter));\n\t\tif (ret)\n\t\t\tgoto exit;\n\n\t\ti++;\n\t}\n\nexit:\n\treturn ret;\n}\n\nint pvrdma_page_dir_insert_page_list(struct pvrdma_page_dir *pdir,\n\t\t\t\t     u64 *page_list,\n\t\t\t\t     int num_pages)\n{\n\tint i;\n\tint ret;\n\n\tif (num_pages > pdir->npages)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < num_pages; i++) {\n\t\tret = pvrdma_page_dir_insert_dma(pdir, i, page_list[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nvoid pvrdma_qp_cap_to_ib(struct ib_qp_cap *dst, const struct pvrdma_qp_cap *src)\n{\n\tdst->max_send_wr = src->max_send_wr;\n\tdst->max_recv_wr = src->max_recv_wr;\n\tdst->max_send_sge = src->max_send_sge;\n\tdst->max_recv_sge = src->max_recv_sge;\n\tdst->max_inline_data = src->max_inline_data;\n}\n\nvoid ib_qp_cap_to_pvrdma(struct pvrdma_qp_cap *dst, const struct ib_qp_cap *src)\n{\n\tdst->max_send_wr = src->max_send_wr;\n\tdst->max_recv_wr = src->max_recv_wr;\n\tdst->max_send_sge = src->max_send_sge;\n\tdst->max_recv_sge = src->max_recv_sge;\n\tdst->max_inline_data = src->max_inline_data;\n}\n\nvoid pvrdma_gid_to_ib(union ib_gid *dst, const union pvrdma_gid *src)\n{\n\tBUILD_BUG_ON(sizeof(union pvrdma_gid) != sizeof(union ib_gid));\n\tmemcpy(dst, src, sizeof(*src));\n}\n\nvoid ib_gid_to_pvrdma(union pvrdma_gid *dst, const union ib_gid *src)\n{\n\tBUILD_BUG_ON(sizeof(union pvrdma_gid) != sizeof(union ib_gid));\n\tmemcpy(dst, src, sizeof(*src));\n}\n\nvoid pvrdma_global_route_to_ib(struct ib_global_route *dst,\n\t\t\t       const struct pvrdma_global_route *src)\n{\n\tpvrdma_gid_to_ib(&dst->dgid, &src->dgid);\n\tdst->flow_label = src->flow_label;\n\tdst->sgid_index = src->sgid_index;\n\tdst->hop_limit = src->hop_limit;\n\tdst->traffic_class = src->traffic_class;\n}\n\nvoid ib_global_route_to_pvrdma(struct pvrdma_global_route *dst,\n\t\t\t       const struct ib_global_route *src)\n{\n\tib_gid_to_pvrdma(&dst->dgid, &src->dgid);\n\tdst->flow_label = src->flow_label;\n\tdst->sgid_index = src->sgid_index;\n\tdst->hop_limit = src->hop_limit;\n\tdst->traffic_class = src->traffic_class;\n}\n\nvoid pvrdma_ah_attr_to_rdma(struct rdma_ah_attr *dst,\n\t\t\t    const struct pvrdma_ah_attr *src)\n{\n\tdst->type = RDMA_AH_ATTR_TYPE_ROCE;\n\tpvrdma_global_route_to_ib(rdma_ah_retrieve_grh(dst), &src->grh);\n\trdma_ah_set_dlid(dst, src->dlid);\n\trdma_ah_set_sl(dst, src->sl);\n\trdma_ah_set_path_bits(dst, src->src_path_bits);\n\trdma_ah_set_static_rate(dst, src->static_rate);\n\trdma_ah_set_ah_flags(dst, src->ah_flags);\n\trdma_ah_set_port_num(dst, src->port_num);\n\tmemcpy(dst->roce.dmac, &src->dmac, ETH_ALEN);\n}\n\nvoid rdma_ah_attr_to_pvrdma(struct pvrdma_ah_attr *dst,\n\t\t\t    const struct rdma_ah_attr *src)\n{\n\tib_global_route_to_pvrdma(&dst->grh, rdma_ah_read_grh(src));\n\tdst->dlid = rdma_ah_get_dlid(src);\n\tdst->sl = rdma_ah_get_sl(src);\n\tdst->src_path_bits = rdma_ah_get_path_bits(src);\n\tdst->static_rate = rdma_ah_get_static_rate(src);\n\tdst->ah_flags = rdma_ah_get_ah_flags(src);\n\tdst->port_num = rdma_ah_get_port_num(src);\n\tmemcpy(&dst->dmac, src->roce.dmac, sizeof(dst->dmac));\n}\n\nu8 ib_gid_type_to_pvrdma(enum ib_gid_type gid_type)\n{\n\treturn (gid_type == IB_GID_TYPE_ROCE_UDP_ENCAP) ?\n\t\tPVRDMA_GID_TYPE_FLAG_ROCE_V2 :\n\t\tPVRDMA_GID_TYPE_FLAG_ROCE_V1;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}