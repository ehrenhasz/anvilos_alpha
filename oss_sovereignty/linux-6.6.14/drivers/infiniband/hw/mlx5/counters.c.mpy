{
  "module_name": "counters.c",
  "hash_id": "bb05c6cbda19d1e0d15ea6e8093ef6fbc42beb95bc63cbd5ff038de72503e6d5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mlx5/counters.c",
  "human_readable_source": "\n \n\n#include \"mlx5_ib.h\"\n#include <linux/mlx5/eswitch.h>\n#include <linux/mlx5/vport.h>\n#include \"counters.h\"\n#include \"ib_rep.h\"\n#include \"qp.h\"\n\nstruct mlx5_ib_counter {\n\tconst char *name;\n\tsize_t offset;\n\tu32 type;\n};\n\n#define INIT_Q_COUNTER(_name)\t\t\\\n\t{ .name = #_name, .offset = MLX5_BYTE_OFF(query_q_counter_out, _name)}\n\n#define INIT_VPORT_Q_COUNTER(_name)\t\t\\\n\t{ .name = \"vport_\" #_name, .offset =\t\\\n\t\tMLX5_BYTE_OFF(query_q_counter_out, _name)}\n\nstatic const struct mlx5_ib_counter basic_q_cnts[] = {\n\tINIT_Q_COUNTER(rx_write_requests),\n\tINIT_Q_COUNTER(rx_read_requests),\n\tINIT_Q_COUNTER(rx_atomic_requests),\n\tINIT_Q_COUNTER(rx_dct_connect),\n\tINIT_Q_COUNTER(out_of_buffer),\n};\n\nstatic const struct mlx5_ib_counter out_of_seq_q_cnts[] = {\n\tINIT_Q_COUNTER(out_of_sequence),\n};\n\nstatic const struct mlx5_ib_counter retrans_q_cnts[] = {\n\tINIT_Q_COUNTER(duplicate_request),\n\tINIT_Q_COUNTER(rnr_nak_retry_err),\n\tINIT_Q_COUNTER(packet_seq_err),\n\tINIT_Q_COUNTER(implied_nak_seq_err),\n\tINIT_Q_COUNTER(local_ack_timeout_err),\n};\n\nstatic const struct mlx5_ib_counter vport_basic_q_cnts[] = {\n\tINIT_VPORT_Q_COUNTER(rx_write_requests),\n\tINIT_VPORT_Q_COUNTER(rx_read_requests),\n\tINIT_VPORT_Q_COUNTER(rx_atomic_requests),\n\tINIT_VPORT_Q_COUNTER(rx_dct_connect),\n\tINIT_VPORT_Q_COUNTER(out_of_buffer),\n};\n\nstatic const struct mlx5_ib_counter vport_out_of_seq_q_cnts[] = {\n\tINIT_VPORT_Q_COUNTER(out_of_sequence),\n};\n\nstatic const struct mlx5_ib_counter vport_retrans_q_cnts[] = {\n\tINIT_VPORT_Q_COUNTER(duplicate_request),\n\tINIT_VPORT_Q_COUNTER(rnr_nak_retry_err),\n\tINIT_VPORT_Q_COUNTER(packet_seq_err),\n\tINIT_VPORT_Q_COUNTER(implied_nak_seq_err),\n\tINIT_VPORT_Q_COUNTER(local_ack_timeout_err),\n};\n\n#define INIT_CONG_COUNTER(_name)\t\t\\\n\t{ .name = #_name, .offset =\t\\\n\t\tMLX5_BYTE_OFF(query_cong_statistics_out, _name ## _high)}\n\nstatic const struct mlx5_ib_counter cong_cnts[] = {\n\tINIT_CONG_COUNTER(rp_cnp_ignored),\n\tINIT_CONG_COUNTER(rp_cnp_handled),\n\tINIT_CONG_COUNTER(np_ecn_marked_roce_packets),\n\tINIT_CONG_COUNTER(np_cnp_sent),\n};\n\nstatic const struct mlx5_ib_counter extended_err_cnts[] = {\n\tINIT_Q_COUNTER(resp_local_length_error),\n\tINIT_Q_COUNTER(resp_cqe_error),\n\tINIT_Q_COUNTER(req_cqe_error),\n\tINIT_Q_COUNTER(req_remote_invalid_request),\n\tINIT_Q_COUNTER(req_remote_access_errors),\n\tINIT_Q_COUNTER(resp_remote_access_errors),\n\tINIT_Q_COUNTER(resp_cqe_flush_error),\n\tINIT_Q_COUNTER(req_cqe_flush_error),\n};\n\nstatic const struct mlx5_ib_counter roce_accl_cnts[] = {\n\tINIT_Q_COUNTER(roce_adp_retrans),\n\tINIT_Q_COUNTER(roce_adp_retrans_to),\n\tINIT_Q_COUNTER(roce_slow_restart),\n\tINIT_Q_COUNTER(roce_slow_restart_cnps),\n\tINIT_Q_COUNTER(roce_slow_restart_trans),\n};\n\nstatic const struct mlx5_ib_counter vport_extended_err_cnts[] = {\n\tINIT_VPORT_Q_COUNTER(resp_local_length_error),\n\tINIT_VPORT_Q_COUNTER(resp_cqe_error),\n\tINIT_VPORT_Q_COUNTER(req_cqe_error),\n\tINIT_VPORT_Q_COUNTER(req_remote_invalid_request),\n\tINIT_VPORT_Q_COUNTER(req_remote_access_errors),\n\tINIT_VPORT_Q_COUNTER(resp_remote_access_errors),\n\tINIT_VPORT_Q_COUNTER(resp_cqe_flush_error),\n\tINIT_VPORT_Q_COUNTER(req_cqe_flush_error),\n};\n\nstatic const struct mlx5_ib_counter vport_roce_accl_cnts[] = {\n\tINIT_VPORT_Q_COUNTER(roce_adp_retrans),\n\tINIT_VPORT_Q_COUNTER(roce_adp_retrans_to),\n\tINIT_VPORT_Q_COUNTER(roce_slow_restart),\n\tINIT_VPORT_Q_COUNTER(roce_slow_restart_cnps),\n\tINIT_VPORT_Q_COUNTER(roce_slow_restart_trans),\n};\n\n#define INIT_EXT_PPCNT_COUNTER(_name)\t\t\\\n\t{ .name = #_name, .offset =\t\\\n\tMLX5_BYTE_OFF(ppcnt_reg, \\\n\t\t      counter_set.eth_extended_cntrs_grp_data_layout._name##_high)}\n\nstatic const struct mlx5_ib_counter ext_ppcnt_cnts[] = {\n\tINIT_EXT_PPCNT_COUNTER(rx_icrc_encapsulated),\n};\n\n#define INIT_OP_COUNTER(_name, _type)\t\t\\\n\t{ .name = #_name, .type = MLX5_IB_OPCOUNTER_##_type}\n\nstatic const struct mlx5_ib_counter basic_op_cnts[] = {\n\tINIT_OP_COUNTER(cc_rx_ce_pkts, CC_RX_CE_PKTS),\n};\n\nstatic const struct mlx5_ib_counter rdmarx_cnp_op_cnts[] = {\n\tINIT_OP_COUNTER(cc_rx_cnp_pkts, CC_RX_CNP_PKTS),\n};\n\nstatic const struct mlx5_ib_counter rdmatx_cnp_op_cnts[] = {\n\tINIT_OP_COUNTER(cc_tx_cnp_pkts, CC_TX_CNP_PKTS),\n};\n\nstatic int mlx5_ib_read_counters(struct ib_counters *counters,\n\t\t\t\t struct ib_counters_read_attr *read_attr,\n\t\t\t\t struct uverbs_attr_bundle *attrs)\n{\n\tstruct mlx5_ib_mcounters *mcounters = to_mcounters(counters);\n\tstruct mlx5_read_counters_attr mread_attr = {};\n\tstruct mlx5_ib_flow_counters_desc *desc;\n\tint ret, i;\n\n\tmutex_lock(&mcounters->mcntrs_mutex);\n\tif (mcounters->cntrs_max_index > read_attr->ncounters) {\n\t\tret = -EINVAL;\n\t\tgoto err_bound;\n\t}\n\n\tmread_attr.out = kcalloc(mcounters->counters_num, sizeof(u64),\n\t\t\t\t GFP_KERNEL);\n\tif (!mread_attr.out) {\n\t\tret = -ENOMEM;\n\t\tgoto err_bound;\n\t}\n\n\tmread_attr.hw_cntrs_hndl = mcounters->hw_cntrs_hndl;\n\tmread_attr.flags = read_attr->flags;\n\tret = mcounters->read_counters(counters->device, &mread_attr);\n\tif (ret)\n\t\tgoto err_read;\n\n\t \n\tdesc = mcounters->counters_data;\n\tfor (i = 0; i < mcounters->ncounters; i++)\n\t\tread_attr->counters_buff[desc[i].index] += mread_attr.out[desc[i].description];\n\nerr_read:\n\tkfree(mread_attr.out);\nerr_bound:\n\tmutex_unlock(&mcounters->mcntrs_mutex);\n\treturn ret;\n}\n\nstatic int mlx5_ib_destroy_counters(struct ib_counters *counters)\n{\n\tstruct mlx5_ib_mcounters *mcounters = to_mcounters(counters);\n\n\tmlx5_ib_counters_clear_description(counters);\n\tif (mcounters->hw_cntrs_hndl)\n\t\tmlx5_fc_destroy(to_mdev(counters->device)->mdev,\n\t\t\t\tmcounters->hw_cntrs_hndl);\n\treturn 0;\n}\n\nstatic int mlx5_ib_create_counters(struct ib_counters *counters,\n\t\t\t\t   struct uverbs_attr_bundle *attrs)\n{\n\tstruct mlx5_ib_mcounters *mcounters = to_mcounters(counters);\n\n\tmutex_init(&mcounters->mcntrs_mutex);\n\treturn 0;\n}\n\nstatic bool vport_qcounters_supported(struct mlx5_ib_dev *dev)\n{\n\treturn MLX5_CAP_GEN(dev->mdev, q_counter_other_vport) &&\n\t       MLX5_CAP_GEN(dev->mdev, q_counter_aggregation);\n}\n\nstatic const struct mlx5_ib_counters *get_counters(struct mlx5_ib_dev *dev,\n\t\t\t\t\t\t   u32 port_num)\n{\n\tif ((is_mdev_switchdev_mode(dev->mdev) &&\n\t     !vport_qcounters_supported(dev)) || !port_num)\n\t\treturn &dev->port[0].cnts;\n\n\treturn is_mdev_switchdev_mode(dev->mdev) ?\n\t       &dev->port[1].cnts : &dev->port[port_num - 1].cnts;\n}\n\n \nu16 mlx5_ib_get_counters_id(struct mlx5_ib_dev *dev, u32 port_num)\n{\n\tconst struct mlx5_ib_counters *cnts = get_counters(dev, port_num + 1);\n\n\treturn cnts->set_id;\n}\n\nstatic struct rdma_hw_stats *do_alloc_stats(const struct mlx5_ib_counters *cnts)\n{\n\tstruct rdma_hw_stats *stats;\n\tu32 num_hw_counters;\n\tint i;\n\n\tnum_hw_counters = cnts->num_q_counters + cnts->num_cong_counters +\n\t\t\t  cnts->num_ext_ppcnt_counters;\n\tstats = rdma_alloc_hw_stats_struct(cnts->descs,\n\t\t\t\t\t   num_hw_counters +\n\t\t\t\t\t   cnts->num_op_counters,\n\t\t\t\t\t   RDMA_HW_STATS_DEFAULT_LIFESPAN);\n\tif (!stats)\n\t\treturn NULL;\n\n\tfor (i = 0; i < cnts->num_op_counters; i++)\n\t\tset_bit(num_hw_counters + i, stats->is_disabled);\n\n\treturn stats;\n}\n\nstatic struct rdma_hw_stats *\nmlx5_ib_alloc_hw_device_stats(struct ib_device *ibdev)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ibdev);\n\tconst struct mlx5_ib_counters *cnts = &dev->port[0].cnts;\n\n\treturn do_alloc_stats(cnts);\n}\n\nstatic struct rdma_hw_stats *\nmlx5_ib_alloc_hw_port_stats(struct ib_device *ibdev, u32 port_num)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ibdev);\n\tconst struct mlx5_ib_counters *cnts = get_counters(dev, port_num);\n\n\treturn do_alloc_stats(cnts);\n}\n\nstatic int mlx5_ib_query_q_counters(struct mlx5_core_dev *mdev,\n\t\t\t\t    const struct mlx5_ib_counters *cnts,\n\t\t\t\t    struct rdma_hw_stats *stats,\n\t\t\t\t    u16 set_id)\n{\n\tu32 out[MLX5_ST_SZ_DW(query_q_counter_out)] = {};\n\tu32 in[MLX5_ST_SZ_DW(query_q_counter_in)] = {};\n\t__be32 val;\n\tint ret, i;\n\n\tMLX5_SET(query_q_counter_in, in, opcode, MLX5_CMD_OP_QUERY_Q_COUNTER);\n\tMLX5_SET(query_q_counter_in, in, counter_set_id, set_id);\n\tret = mlx5_cmd_exec_inout(mdev, query_q_counter, in, out);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < cnts->num_q_counters; i++) {\n\t\tval = *(__be32 *)((void *)out + cnts->offsets[i]);\n\t\tstats->value[i] = (u64)be32_to_cpu(val);\n\t}\n\n\treturn 0;\n}\n\nstatic int mlx5_ib_query_ext_ppcnt_counters(struct mlx5_ib_dev *dev,\n\t\t\t\t\t    const struct mlx5_ib_counters *cnts,\n\t\t\t\t\t    struct rdma_hw_stats *stats)\n{\n\tint offset = cnts->num_q_counters + cnts->num_cong_counters;\n\tu32 in[MLX5_ST_SZ_DW(ppcnt_reg)] = {};\n\tint sz = MLX5_ST_SZ_BYTES(ppcnt_reg);\n\tint ret, i;\n\tvoid *out;\n\n\tout = kvzalloc(sz, GFP_KERNEL);\n\tif (!out)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(ppcnt_reg, in, local_port, 1);\n\tMLX5_SET(ppcnt_reg, in, grp, MLX5_ETHERNET_EXTENDED_COUNTERS_GROUP);\n\tret = mlx5_core_access_reg(dev->mdev, in, sz, out, sz, MLX5_REG_PPCNT,\n\t\t\t\t   0, 0);\n\tif (ret)\n\t\tgoto free;\n\n\tfor (i = 0; i < cnts->num_ext_ppcnt_counters; i++)\n\t\tstats->value[i + offset] =\n\t\t\tbe64_to_cpup((__be64 *)(out +\n\t\t\t\t    cnts->offsets[i + offset]));\nfree:\n\tkvfree(out);\n\treturn ret;\n}\n\nstatic int mlx5_ib_query_q_counters_vport(struct mlx5_ib_dev *dev,\n\t\t\t\t\t  u32 port_num,\n\t\t\t\t\t  const struct mlx5_ib_counters *cnts,\n\t\t\t\t\t  struct rdma_hw_stats *stats)\n\n{\n\tu32 out[MLX5_ST_SZ_DW(query_q_counter_out)] = {};\n\tu32 in[MLX5_ST_SZ_DW(query_q_counter_in)] = {};\n\tstruct mlx5_core_dev *mdev;\n\t__be32 val;\n\tint ret, i;\n\n\tif (!dev->port[port_num].rep ||\n\t    dev->port[port_num].rep->vport == MLX5_VPORT_UPLINK)\n\t\treturn 0;\n\n\tmdev = mlx5_eswitch_get_core_dev(dev->port[port_num].rep->esw);\n\tif (!mdev)\n\t\treturn -EOPNOTSUPP;\n\n\tMLX5_SET(query_q_counter_in, in, opcode, MLX5_CMD_OP_QUERY_Q_COUNTER);\n\tMLX5_SET(query_q_counter_in, in, other_vport, 1);\n\tMLX5_SET(query_q_counter_in, in, vport_number,\n\t\t dev->port[port_num].rep->vport);\n\tMLX5_SET(query_q_counter_in, in, aggregate, 1);\n\tret = mlx5_cmd_exec_inout(mdev, query_q_counter, in, out);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < cnts->num_q_counters; i++) {\n\t\tval = *(__be32 *)((void *)out + cnts->offsets[i]);\n\t\tstats->value[i] = (u64)be32_to_cpu(val);\n\t}\n\n\treturn 0;\n}\n\nstatic int do_get_hw_stats(struct ib_device *ibdev,\n\t\t\t   struct rdma_hw_stats *stats,\n\t\t\t   u32 port_num, int index)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ibdev);\n\tconst struct mlx5_ib_counters *cnts = get_counters(dev, port_num);\n\tstruct mlx5_core_dev *mdev;\n\tint ret, num_counters;\n\n\tif (!stats)\n\t\treturn -EINVAL;\n\n\tnum_counters = cnts->num_q_counters +\n\t\t       cnts->num_cong_counters +\n\t\t       cnts->num_ext_ppcnt_counters;\n\n\tif (is_mdev_switchdev_mode(dev->mdev) && dev->is_rep && port_num != 0)\n\t\tret = mlx5_ib_query_q_counters_vport(dev, port_num - 1, cnts,\n\t\t\t\t\t\t     stats);\n\telse\n\t\tret = mlx5_ib_query_q_counters(dev->mdev, cnts, stats,\n\t\t\t\t\t       cnts->set_id);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (is_mdev_switchdev_mode(dev->mdev) && port_num != 0)\n\t\tgoto done;\n\n\tif (MLX5_CAP_PCAM_FEATURE(dev->mdev, rx_icrc_encapsulated_counter)) {\n\t\tret =  mlx5_ib_query_ext_ppcnt_counters(dev, cnts, stats);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (MLX5_CAP_GEN(dev->mdev, cc_query_allowed)) {\n\t\tif (!port_num)\n\t\t\tport_num = 1;\n\t\tmdev = mlx5_ib_get_native_port_mdev(dev, port_num, NULL);\n\t\tif (!mdev) {\n\t\t\t \n\t\t\tgoto done;\n\t\t}\n\t\tret = mlx5_lag_query_cong_counters(dev->mdev,\n\t\t\t\t\t\t   stats->value +\n\t\t\t\t\t\t   cnts->num_q_counters,\n\t\t\t\t\t\t   cnts->num_cong_counters,\n\t\t\t\t\t\t   cnts->offsets +\n\t\t\t\t\t\t   cnts->num_q_counters);\n\n\t\tmlx5_ib_put_native_port_mdev(dev, port_num);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\ndone:\n\treturn num_counters;\n}\n\nstatic int do_get_op_stat(struct ib_device *ibdev,\n\t\t\t  struct rdma_hw_stats *stats,\n\t\t\t  u32 port_num, int index)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ibdev);\n\tconst struct mlx5_ib_counters *cnts;\n\tconst struct mlx5_ib_op_fc *opfcs;\n\tu64 packets = 0, bytes;\n\tu32 type;\n\tint ret;\n\n\tcnts = get_counters(dev, port_num);\n\n\topfcs = cnts->opfcs;\n\ttype = *(u32 *)cnts->descs[index].priv;\n\tif (type >= MLX5_IB_OPCOUNTER_MAX)\n\t\treturn -EINVAL;\n\n\tif (!opfcs[type].fc)\n\t\tgoto out;\n\n\tret = mlx5_fc_query(dev->mdev, opfcs[type].fc,\n\t\t\t    &packets, &bytes);\n\tif (ret)\n\t\treturn ret;\n\nout:\n\tstats->value[index] = packets;\n\treturn index;\n}\n\nstatic int do_get_op_stats(struct ib_device *ibdev,\n\t\t\t   struct rdma_hw_stats *stats,\n\t\t\t   u32 port_num)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ibdev);\n\tconst struct mlx5_ib_counters *cnts;\n\tint index, ret, num_hw_counters;\n\n\tcnts = get_counters(dev, port_num);\n\tnum_hw_counters = cnts->num_q_counters + cnts->num_cong_counters +\n\t\t\t  cnts->num_ext_ppcnt_counters;\n\tfor (index = num_hw_counters;\n\t     index < (num_hw_counters + cnts->num_op_counters); index++) {\n\t\tret = do_get_op_stat(ibdev, stats, port_num, index);\n\t\tif (ret != index)\n\t\t\treturn ret;\n\t}\n\n\treturn cnts->num_op_counters;\n}\n\nstatic int mlx5_ib_get_hw_stats(struct ib_device *ibdev,\n\t\t\t\tstruct rdma_hw_stats *stats,\n\t\t\t\tu32 port_num, int index)\n{\n\tint num_counters, num_hw_counters, num_op_counters;\n\tstruct mlx5_ib_dev *dev = to_mdev(ibdev);\n\tconst struct mlx5_ib_counters *cnts;\n\n\tcnts = get_counters(dev, port_num);\n\tnum_hw_counters = cnts->num_q_counters + cnts->num_cong_counters +\n\t\tcnts->num_ext_ppcnt_counters;\n\tnum_counters = num_hw_counters + cnts->num_op_counters;\n\n\tif (index < 0 || index > num_counters)\n\t\treturn -EINVAL;\n\telse if (index > 0 && index < num_hw_counters)\n\t\treturn do_get_hw_stats(ibdev, stats, port_num, index);\n\telse if (index >= num_hw_counters && index < num_counters)\n\t\treturn do_get_op_stat(ibdev, stats, port_num, index);\n\n\tnum_hw_counters = do_get_hw_stats(ibdev, stats, port_num, index);\n\tif (num_hw_counters < 0)\n\t\treturn num_hw_counters;\n\n\tnum_op_counters = do_get_op_stats(ibdev, stats, port_num);\n\tif (num_op_counters < 0)\n\t\treturn num_op_counters;\n\n\treturn num_hw_counters + num_op_counters;\n}\n\nstatic struct rdma_hw_stats *\nmlx5_ib_counter_alloc_stats(struct rdma_counter *counter)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(counter->device);\n\tconst struct mlx5_ib_counters *cnts = get_counters(dev, counter->port);\n\n\treturn do_alloc_stats(cnts);\n}\n\nstatic int mlx5_ib_counter_update_stats(struct rdma_counter *counter)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(counter->device);\n\tconst struct mlx5_ib_counters *cnts = get_counters(dev, counter->port);\n\n\treturn mlx5_ib_query_q_counters(dev->mdev, cnts,\n\t\t\t\t\tcounter->stats, counter->id);\n}\n\nstatic int mlx5_ib_counter_dealloc(struct rdma_counter *counter)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(counter->device);\n\tu32 in[MLX5_ST_SZ_DW(dealloc_q_counter_in)] = {};\n\n\tif (!counter->id)\n\t\treturn 0;\n\n\tMLX5_SET(dealloc_q_counter_in, in, opcode,\n\t\t MLX5_CMD_OP_DEALLOC_Q_COUNTER);\n\tMLX5_SET(dealloc_q_counter_in, in, counter_set_id, counter->id);\n\treturn mlx5_cmd_exec_in(dev->mdev, dealloc_q_counter, in);\n}\n\nstatic int mlx5_ib_counter_bind_qp(struct rdma_counter *counter,\n\t\t\t\t   struct ib_qp *qp)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(qp->device);\n\tint err;\n\n\tif (!counter->id) {\n\t\tu32 out[MLX5_ST_SZ_DW(alloc_q_counter_out)] = {};\n\t\tu32 in[MLX5_ST_SZ_DW(alloc_q_counter_in)] = {};\n\n\t\tMLX5_SET(alloc_q_counter_in, in, opcode,\n\t\t\t MLX5_CMD_OP_ALLOC_Q_COUNTER);\n\t\tMLX5_SET(alloc_q_counter_in, in, uid, MLX5_SHARED_RESOURCE_UID);\n\t\terr = mlx5_cmd_exec_inout(dev->mdev, alloc_q_counter, in, out);\n\t\tif (err)\n\t\t\treturn err;\n\t\tcounter->id =\n\t\t\tMLX5_GET(alloc_q_counter_out, out, counter_set_id);\n\t}\n\n\terr = mlx5_ib_qp_set_counter(qp, counter);\n\tif (err)\n\t\tgoto fail_set_counter;\n\n\treturn 0;\n\nfail_set_counter:\n\tmlx5_ib_counter_dealloc(counter);\n\tcounter->id = 0;\n\n\treturn err;\n}\n\nstatic int mlx5_ib_counter_unbind_qp(struct ib_qp *qp)\n{\n\treturn mlx5_ib_qp_set_counter(qp, NULL);\n}\n\nstatic void mlx5_ib_fill_counters(struct mlx5_ib_dev *dev,\n\t\t\t\t  struct rdma_stat_desc *descs, size_t *offsets,\n\t\t\t\t  u32 port_num)\n{\n\tbool is_vport = is_mdev_switchdev_mode(dev->mdev) &&\n\t\t\tport_num != MLX5_VPORT_PF;\n\tconst struct mlx5_ib_counter *names;\n\tint j = 0, i, size;\n\n\tnames = is_vport ? vport_basic_q_cnts : basic_q_cnts;\n\tsize = is_vport ? ARRAY_SIZE(vport_basic_q_cnts) :\n\t\t\t  ARRAY_SIZE(basic_q_cnts);\n\tfor (i = 0; i < size; i++, j++) {\n\t\tdescs[j].name = names[i].name;\n\t\toffsets[j] = names[i].offset;\n\t}\n\n\tnames = is_vport ? vport_out_of_seq_q_cnts : out_of_seq_q_cnts;\n\tsize = is_vport ? ARRAY_SIZE(vport_out_of_seq_q_cnts) :\n\t\t\t  ARRAY_SIZE(out_of_seq_q_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, out_of_seq_cnt)) {\n\t\tfor (i = 0; i < size; i++, j++) {\n\t\t\tdescs[j].name = names[i].name;\n\t\t\toffsets[j] = names[i].offset;\n\t\t}\n\t}\n\n\tnames = is_vport ? vport_retrans_q_cnts : retrans_q_cnts;\n\tsize = is_vport ? ARRAY_SIZE(vport_retrans_q_cnts) :\n\t\t\t  ARRAY_SIZE(retrans_q_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, retransmission_q_counters)) {\n\t\tfor (i = 0; i < size; i++, j++) {\n\t\t\tdescs[j].name = names[i].name;\n\t\t\toffsets[j] = names[i].offset;\n\t\t}\n\t}\n\n\tnames = is_vport ? vport_extended_err_cnts : extended_err_cnts;\n\tsize = is_vport ? ARRAY_SIZE(vport_extended_err_cnts) :\n\t\t\t  ARRAY_SIZE(extended_err_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, enhanced_error_q_counters)) {\n\t\tfor (i = 0; i < size; i++, j++) {\n\t\t\tdescs[j].name = names[i].name;\n\t\t\toffsets[j] = names[i].offset;\n\t\t}\n\t}\n\n\tnames = is_vport ? vport_roce_accl_cnts : roce_accl_cnts;\n\tsize = is_vport ? ARRAY_SIZE(vport_roce_accl_cnts) :\n\t\t\t  ARRAY_SIZE(roce_accl_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, roce_accl)) {\n\t\tfor (i = 0; i < size; i++, j++) {\n\t\t\tdescs[j].name = names[i].name;\n\t\t\toffsets[j] = names[i].offset;\n\t\t}\n\t}\n\n\tif (is_vport)\n\t\treturn;\n\n\tif (MLX5_CAP_GEN(dev->mdev, cc_query_allowed)) {\n\t\tfor (i = 0; i < ARRAY_SIZE(cong_cnts); i++, j++) {\n\t\t\tdescs[j].name = cong_cnts[i].name;\n\t\t\toffsets[j] = cong_cnts[i].offset;\n\t\t}\n\t}\n\n\tif (MLX5_CAP_PCAM_FEATURE(dev->mdev, rx_icrc_encapsulated_counter)) {\n\t\tfor (i = 0; i < ARRAY_SIZE(ext_ppcnt_cnts); i++, j++) {\n\t\t\tdescs[j].name = ext_ppcnt_cnts[i].name;\n\t\t\toffsets[j] = ext_ppcnt_cnts[i].offset;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(basic_op_cnts); i++, j++) {\n\t\tdescs[j].name = basic_op_cnts[i].name;\n\t\tdescs[j].flags |= IB_STAT_FLAG_OPTIONAL;\n\t\tdescs[j].priv = &basic_op_cnts[i].type;\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE(dev->mdev,\n\t\t\t       ft_field_support_2_nic_receive_rdma.bth_opcode)) {\n\t\tfor (i = 0; i < ARRAY_SIZE(rdmarx_cnp_op_cnts); i++, j++) {\n\t\t\tdescs[j].name = rdmarx_cnp_op_cnts[i].name;\n\t\t\tdescs[j].flags |= IB_STAT_FLAG_OPTIONAL;\n\t\t\tdescs[j].priv = &rdmarx_cnp_op_cnts[i].type;\n\t\t}\n\t}\n\n\tif (MLX5_CAP_FLOWTABLE(dev->mdev,\n\t\t\t       ft_field_support_2_nic_transmit_rdma.bth_opcode)) {\n\t\tfor (i = 0; i < ARRAY_SIZE(rdmatx_cnp_op_cnts); i++, j++) {\n\t\t\tdescs[j].name = rdmatx_cnp_op_cnts[i].name;\n\t\t\tdescs[j].flags |= IB_STAT_FLAG_OPTIONAL;\n\t\t\tdescs[j].priv = &rdmatx_cnp_op_cnts[i].type;\n\t\t}\n\t}\n}\n\n\nstatic int __mlx5_ib_alloc_counters(struct mlx5_ib_dev *dev,\n\t\t\t\t    struct mlx5_ib_counters *cnts, u32 port_num)\n{\n\tbool is_vport = is_mdev_switchdev_mode(dev->mdev) &&\n\t\t\tport_num != MLX5_VPORT_PF;\n\tu32 num_counters, num_op_counters = 0, size;\n\n\tsize = is_vport ? ARRAY_SIZE(vport_basic_q_cnts) :\n\t\t\t  ARRAY_SIZE(basic_q_cnts);\n\tnum_counters = size;\n\n\tsize = is_vport ? ARRAY_SIZE(vport_out_of_seq_q_cnts) :\n\t\t\t  ARRAY_SIZE(out_of_seq_q_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, out_of_seq_cnt))\n\t\tnum_counters += size;\n\n\tsize = is_vport ? ARRAY_SIZE(vport_retrans_q_cnts) :\n\t\t\t  ARRAY_SIZE(retrans_q_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, retransmission_q_counters))\n\t\tnum_counters += size;\n\n\tsize = is_vport ? ARRAY_SIZE(vport_extended_err_cnts) :\n\t\t\t  ARRAY_SIZE(extended_err_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, enhanced_error_q_counters))\n\t\tnum_counters += size;\n\n\tsize = is_vport ? ARRAY_SIZE(vport_roce_accl_cnts) :\n\t\t\t  ARRAY_SIZE(roce_accl_cnts);\n\tif (MLX5_CAP_GEN(dev->mdev, roce_accl))\n\t\tnum_counters += size;\n\n\tcnts->num_q_counters = num_counters;\n\n\tif (is_vport)\n\t\tgoto skip_non_qcounters;\n\n\tif (MLX5_CAP_GEN(dev->mdev, cc_query_allowed)) {\n\t\tcnts->num_cong_counters = ARRAY_SIZE(cong_cnts);\n\t\tnum_counters += ARRAY_SIZE(cong_cnts);\n\t}\n\tif (MLX5_CAP_PCAM_FEATURE(dev->mdev, rx_icrc_encapsulated_counter)) {\n\t\tcnts->num_ext_ppcnt_counters = ARRAY_SIZE(ext_ppcnt_cnts);\n\t\tnum_counters += ARRAY_SIZE(ext_ppcnt_cnts);\n\t}\n\n\tnum_op_counters = ARRAY_SIZE(basic_op_cnts);\n\n\tif (MLX5_CAP_FLOWTABLE(dev->mdev,\n\t\t\t       ft_field_support_2_nic_receive_rdma.bth_opcode))\n\t\tnum_op_counters += ARRAY_SIZE(rdmarx_cnp_op_cnts);\n\n\tif (MLX5_CAP_FLOWTABLE(dev->mdev,\n\t\t\t       ft_field_support_2_nic_transmit_rdma.bth_opcode))\n\t\tnum_op_counters += ARRAY_SIZE(rdmatx_cnp_op_cnts);\n\nskip_non_qcounters:\n\tcnts->num_op_counters = num_op_counters;\n\tnum_counters += num_op_counters;\n\tcnts->descs = kcalloc(num_counters,\n\t\t\t      sizeof(struct rdma_stat_desc), GFP_KERNEL);\n\tif (!cnts->descs)\n\t\treturn -ENOMEM;\n\n\tcnts->offsets = kcalloc(num_counters,\n\t\t\t\tsizeof(*cnts->offsets), GFP_KERNEL);\n\tif (!cnts->offsets)\n\t\tgoto err;\n\n\treturn 0;\n\nerr:\n\tkfree(cnts->descs);\n\tcnts->descs = NULL;\n\treturn -ENOMEM;\n}\n\nstatic void mlx5_ib_dealloc_counters(struct mlx5_ib_dev *dev)\n{\n\tu32 in[MLX5_ST_SZ_DW(dealloc_q_counter_in)] = {};\n\tint num_cnt_ports = dev->num_ports;\n\tint i, j;\n\n\tif (is_mdev_switchdev_mode(dev->mdev))\n\t\tnum_cnt_ports = min(2, num_cnt_ports);\n\n\tMLX5_SET(dealloc_q_counter_in, in, opcode,\n\t\t MLX5_CMD_OP_DEALLOC_Q_COUNTER);\n\n\tfor (i = 0; i < num_cnt_ports; i++) {\n\t\tif (dev->port[i].cnts.set_id) {\n\t\t\tMLX5_SET(dealloc_q_counter_in, in, counter_set_id,\n\t\t\t\t dev->port[i].cnts.set_id);\n\t\t\tmlx5_cmd_exec_in(dev->mdev, dealloc_q_counter, in);\n\t\t}\n\t\tkfree(dev->port[i].cnts.descs);\n\t\tkfree(dev->port[i].cnts.offsets);\n\n\t\tfor (j = 0; j < MLX5_IB_OPCOUNTER_MAX; j++) {\n\t\t\tif (!dev->port[i].cnts.opfcs[j].fc)\n\t\t\t\tcontinue;\n\n\t\t\tif (IS_ENABLED(CONFIG_INFINIBAND_USER_ACCESS))\n\t\t\t\tmlx5_ib_fs_remove_op_fc(dev,\n\t\t\t\t\t&dev->port[i].cnts.opfcs[j], j);\n\t\t\tmlx5_fc_destroy(dev->mdev,\n\t\t\t\t\tdev->port[i].cnts.opfcs[j].fc);\n\t\t\tdev->port[i].cnts.opfcs[j].fc = NULL;\n\t\t}\n\t}\n}\n\nstatic int mlx5_ib_alloc_counters(struct mlx5_ib_dev *dev)\n{\n\tu32 out[MLX5_ST_SZ_DW(alloc_q_counter_out)] = {};\n\tu32 in[MLX5_ST_SZ_DW(alloc_q_counter_in)] = {};\n\tint num_cnt_ports = dev->num_ports;\n\tint err = 0;\n\tint i;\n\tbool is_shared;\n\n\tMLX5_SET(alloc_q_counter_in, in, opcode, MLX5_CMD_OP_ALLOC_Q_COUNTER);\n\tis_shared = MLX5_CAP_GEN(dev->mdev, log_max_uctx) != 0;\n\n\t \n\tif (is_mdev_switchdev_mode(dev->mdev))\n\t\tnum_cnt_ports = min(2, num_cnt_ports);\n\n\tfor (i = 0; i < num_cnt_ports; i++) {\n\t\terr = __mlx5_ib_alloc_counters(dev, &dev->port[i].cnts, i);\n\t\tif (err)\n\t\t\tgoto err_alloc;\n\n\t\tmlx5_ib_fill_counters(dev, dev->port[i].cnts.descs,\n\t\t\t\t      dev->port[i].cnts.offsets, i);\n\n\t\tMLX5_SET(alloc_q_counter_in, in, uid,\n\t\t\t is_shared ? MLX5_SHARED_RESOURCE_UID : 0);\n\n\t\terr = mlx5_cmd_exec_inout(dev->mdev, alloc_q_counter, in, out);\n\t\tif (err) {\n\t\t\tmlx5_ib_warn(dev,\n\t\t\t\t     \"couldn't allocate queue counter for port %d, err %d\\n\",\n\t\t\t\t     i + 1, err);\n\t\t\tgoto err_alloc;\n\t\t}\n\n\t\tdev->port[i].cnts.set_id =\n\t\t\tMLX5_GET(alloc_q_counter_out, out, counter_set_id);\n\t}\n\treturn 0;\n\nerr_alloc:\n\tmlx5_ib_dealloc_counters(dev);\n\treturn err;\n}\n\nstatic int read_flow_counters(struct ib_device *ibdev,\n\t\t\t      struct mlx5_read_counters_attr *read_attr)\n{\n\tstruct mlx5_fc *fc = read_attr->hw_cntrs_hndl;\n\tstruct mlx5_ib_dev *dev = to_mdev(ibdev);\n\n\treturn mlx5_fc_query(dev->mdev, fc,\n\t\t\t     &read_attr->out[IB_COUNTER_PACKETS],\n\t\t\t     &read_attr->out[IB_COUNTER_BYTES]);\n}\n\n \n#define FLOW_COUNTERS_NUM 2\nstatic int counters_set_description(\n\tstruct ib_counters *counters, enum mlx5_ib_counters_type counters_type,\n\tstruct mlx5_ib_flow_counters_desc *desc_data, u32 ncounters)\n{\n\tstruct mlx5_ib_mcounters *mcounters = to_mcounters(counters);\n\tu32 cntrs_max_index = 0;\n\tint i;\n\n\tif (counters_type != MLX5_IB_COUNTERS_FLOW)\n\t\treturn -EINVAL;\n\n\t \n\tmcounters->type = counters_type;\n\tmcounters->read_counters = read_flow_counters;\n\tmcounters->counters_num = FLOW_COUNTERS_NUM;\n\tmcounters->ncounters = ncounters;\n\t \n\tfor (i = 0; i < ncounters; i++) {\n\t\tif (desc_data[i].description > IB_COUNTER_BYTES)\n\t\t\treturn -EINVAL;\n\n\t\tif (cntrs_max_index <= desc_data[i].index)\n\t\t\tcntrs_max_index = desc_data[i].index + 1;\n\t}\n\n\tmutex_lock(&mcounters->mcntrs_mutex);\n\tmcounters->counters_data = desc_data;\n\tmcounters->cntrs_max_index = cntrs_max_index;\n\tmutex_unlock(&mcounters->mcntrs_mutex);\n\n\treturn 0;\n}\n\n#define MAX_COUNTERS_NUM (USHRT_MAX / (sizeof(u32) * 2))\nint mlx5_ib_flow_counters_set_data(struct ib_counters *ibcounters,\n\t\t\t\t   struct mlx5_ib_create_flow *ucmd)\n{\n\tstruct mlx5_ib_mcounters *mcounters = to_mcounters(ibcounters);\n\tstruct mlx5_ib_flow_counters_data *cntrs_data = NULL;\n\tstruct mlx5_ib_flow_counters_desc *desc_data = NULL;\n\tbool hw_hndl = false;\n\tint ret = 0;\n\n\tif (ucmd && ucmd->ncounters_data != 0) {\n\t\tcntrs_data = ucmd->data;\n\t\tif (cntrs_data->ncounters > MAX_COUNTERS_NUM)\n\t\t\treturn -EINVAL;\n\n\t\tdesc_data = kcalloc(cntrs_data->ncounters,\n\t\t\t\t    sizeof(*desc_data),\n\t\t\t\t    GFP_KERNEL);\n\t\tif (!desc_data)\n\t\t\treturn  -ENOMEM;\n\n\t\tif (copy_from_user(desc_data,\n\t\t\t\t   u64_to_user_ptr(cntrs_data->counters_data),\n\t\t\t\t   sizeof(*desc_data) * cntrs_data->ncounters)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free;\n\t\t}\n\t}\n\n\tif (!mcounters->hw_cntrs_hndl) {\n\t\tmcounters->hw_cntrs_hndl = mlx5_fc_create(\n\t\t\tto_mdev(ibcounters->device)->mdev, false);\n\t\tif (IS_ERR(mcounters->hw_cntrs_hndl)) {\n\t\t\tret = PTR_ERR(mcounters->hw_cntrs_hndl);\n\t\t\tgoto free;\n\t\t}\n\t\thw_hndl = true;\n\t}\n\n\tif (desc_data) {\n\t\t \n\t\tif (mcounters->cntrs_max_index) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto free_hndl;\n\t\t}\n\n\t\tret = counters_set_description(ibcounters,\n\t\t\t\t\t       MLX5_IB_COUNTERS_FLOW,\n\t\t\t\t\t       desc_data,\n\t\t\t\t\t       cntrs_data->ncounters);\n\t\tif (ret)\n\t\t\tgoto free_hndl;\n\n\t} else if (!mcounters->cntrs_max_index) {\n\t\t \n\t\tret = -EINVAL;\n\t\tgoto free_hndl;\n\t}\n\n\treturn 0;\n\nfree_hndl:\n\tif (hw_hndl) {\n\t\tmlx5_fc_destroy(to_mdev(ibcounters->device)->mdev,\n\t\t\t\tmcounters->hw_cntrs_hndl);\n\t\tmcounters->hw_cntrs_hndl = NULL;\n\t}\nfree:\n\tkfree(desc_data);\n\treturn ret;\n}\n\nvoid mlx5_ib_counters_clear_description(struct ib_counters *counters)\n{\n\tstruct mlx5_ib_mcounters *mcounters;\n\n\tif (!counters || atomic_read(&counters->usecnt) != 1)\n\t\treturn;\n\n\tmcounters = to_mcounters(counters);\n\n\tmutex_lock(&mcounters->mcntrs_mutex);\n\tkfree(mcounters->counters_data);\n\tmcounters->counters_data = NULL;\n\tmcounters->cntrs_max_index = 0;\n\tmutex_unlock(&mcounters->mcntrs_mutex);\n}\n\nstatic int mlx5_ib_modify_stat(struct ib_device *device, u32 port,\n\t\t\t       unsigned int index, bool enable)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(device);\n\tstruct mlx5_ib_counters *cnts;\n\tstruct mlx5_ib_op_fc *opfc;\n\tu32 num_hw_counters, type;\n\tint ret;\n\n\tcnts = &dev->port[port - 1].cnts;\n\tnum_hw_counters = cnts->num_q_counters + cnts->num_cong_counters +\n\t\tcnts->num_ext_ppcnt_counters;\n\tif (index < num_hw_counters ||\n\t    index >= (num_hw_counters + cnts->num_op_counters))\n\t\treturn -EINVAL;\n\n\tif (!(cnts->descs[index].flags & IB_STAT_FLAG_OPTIONAL))\n\t\treturn -EINVAL;\n\n\ttype = *(u32 *)cnts->descs[index].priv;\n\tif (type >= MLX5_IB_OPCOUNTER_MAX)\n\t\treturn -EINVAL;\n\n\topfc = &cnts->opfcs[type];\n\n\tif (enable) {\n\t\tif (opfc->fc)\n\t\t\treturn -EEXIST;\n\n\t\topfc->fc = mlx5_fc_create(dev->mdev, false);\n\t\tif (IS_ERR(opfc->fc))\n\t\t\treturn PTR_ERR(opfc->fc);\n\n\t\tret = mlx5_ib_fs_add_op_fc(dev, port, opfc, type);\n\t\tif (ret) {\n\t\t\tmlx5_fc_destroy(dev->mdev, opfc->fc);\n\t\t\topfc->fc = NULL;\n\t\t}\n\t\treturn ret;\n\t}\n\n\tif (!opfc->fc)\n\t\treturn -EINVAL;\n\n\tmlx5_ib_fs_remove_op_fc(dev, opfc, type);\n\tmlx5_fc_destroy(dev->mdev, opfc->fc);\n\topfc->fc = NULL;\n\treturn 0;\n}\n\nstatic const struct ib_device_ops hw_stats_ops = {\n\t.alloc_hw_port_stats = mlx5_ib_alloc_hw_port_stats,\n\t.get_hw_stats = mlx5_ib_get_hw_stats,\n\t.counter_bind_qp = mlx5_ib_counter_bind_qp,\n\t.counter_unbind_qp = mlx5_ib_counter_unbind_qp,\n\t.counter_dealloc = mlx5_ib_counter_dealloc,\n\t.counter_alloc_stats = mlx5_ib_counter_alloc_stats,\n\t.counter_update_stats = mlx5_ib_counter_update_stats,\n\t.modify_hw_stat = IS_ENABLED(CONFIG_INFINIBAND_USER_ACCESS) ?\n\t\t\t  mlx5_ib_modify_stat : NULL,\n};\n\nstatic const struct ib_device_ops hw_switchdev_vport_op = {\n\t.alloc_hw_port_stats = mlx5_ib_alloc_hw_port_stats,\n};\n\nstatic const struct ib_device_ops hw_switchdev_stats_ops = {\n\t.alloc_hw_device_stats = mlx5_ib_alloc_hw_device_stats,\n\t.get_hw_stats = mlx5_ib_get_hw_stats,\n\t.counter_bind_qp = mlx5_ib_counter_bind_qp,\n\t.counter_unbind_qp = mlx5_ib_counter_unbind_qp,\n\t.counter_dealloc = mlx5_ib_counter_dealloc,\n\t.counter_alloc_stats = mlx5_ib_counter_alloc_stats,\n\t.counter_update_stats = mlx5_ib_counter_update_stats,\n};\n\nstatic const struct ib_device_ops counters_ops = {\n\t.create_counters = mlx5_ib_create_counters,\n\t.destroy_counters = mlx5_ib_destroy_counters,\n\t.read_counters = mlx5_ib_read_counters,\n\n\tINIT_RDMA_OBJ_SIZE(ib_counters, mlx5_ib_mcounters, ibcntrs),\n};\n\nint mlx5_ib_counters_init(struct mlx5_ib_dev *dev)\n{\n\tib_set_device_ops(&dev->ib_dev, &counters_ops);\n\n\tif (!MLX5_CAP_GEN(dev->mdev, max_qp_cnt))\n\t\treturn 0;\n\n\tif (is_mdev_switchdev_mode(dev->mdev)) {\n\t\tib_set_device_ops(&dev->ib_dev, &hw_switchdev_stats_ops);\n\t\tif (vport_qcounters_supported(dev))\n\t\t\tib_set_device_ops(&dev->ib_dev, &hw_switchdev_vport_op);\n\t} else\n\t\tib_set_device_ops(&dev->ib_dev, &hw_stats_ops);\n\treturn mlx5_ib_alloc_counters(dev);\n}\n\nvoid mlx5_ib_counters_cleanup(struct mlx5_ib_dev *dev)\n{\n\tif (!MLX5_CAP_GEN(dev->mdev, max_qp_cnt))\n\t\treturn;\n\n\tmlx5_ib_dealloc_counters(dev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}