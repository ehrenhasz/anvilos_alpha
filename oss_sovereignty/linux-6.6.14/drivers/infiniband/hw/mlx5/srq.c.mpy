{
  "module_name": "srq.c",
  "hash_id": "115c876a4891f579dea5f32db3cd59316ad113f8f72fda88180d196ed8a51a85",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mlx5/srq.c",
  "human_readable_source": "\n \n\n#include <linux/mlx5/qp.h>\n#include <linux/slab.h>\n#include <rdma/ib_umem.h>\n#include <rdma/ib_user_verbs.h>\n#include \"mlx5_ib.h\"\n#include \"srq.h\"\n\nstatic void *get_wqe(struct mlx5_ib_srq *srq, int n)\n{\n\treturn mlx5_frag_buf_get_wqe(&srq->fbc, n);\n}\n\nstatic void mlx5_ib_srq_event(struct mlx5_core_srq *srq, enum mlx5_event type)\n{\n\tstruct ib_event event;\n\tstruct ib_srq *ibsrq = &to_mibsrq(srq)->ibsrq;\n\n\tif (ibsrq->event_handler) {\n\t\tevent.device      = ibsrq->device;\n\t\tevent.element.srq = ibsrq;\n\t\tswitch (type) {\n\t\tcase MLX5_EVENT_TYPE_SRQ_RQ_LIMIT:\n\t\t\tevent.event = IB_EVENT_SRQ_LIMIT_REACHED;\n\t\t\tbreak;\n\t\tcase MLX5_EVENT_TYPE_SRQ_CATAS_ERROR:\n\t\t\tevent.event = IB_EVENT_SRQ_ERR;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_warn(\"mlx5_ib: Unexpected event type %d on SRQ %06x\\n\",\n\t\t\t\ttype, srq->srqn);\n\t\t\treturn;\n\t\t}\n\n\t\tibsrq->event_handler(&event, ibsrq->srq_context);\n\t}\n}\n\nstatic int create_srq_user(struct ib_pd *pd, struct mlx5_ib_srq *srq,\n\t\t\t   struct mlx5_srq_attr *in,\n\t\t\t   struct ib_udata *udata, int buf_size)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(pd->device);\n\tstruct mlx5_ib_create_srq ucmd = {};\n\tstruct mlx5_ib_ucontext *ucontext = rdma_udata_to_drv_context(\n\t\tudata, struct mlx5_ib_ucontext, ibucontext);\n\tsize_t ucmdlen;\n\tint err;\n\tu32 uidx = MLX5_IB_DEFAULT_UIDX;\n\n\tucmdlen = min(udata->inlen, sizeof(ucmd));\n\n\tif (ib_copy_from_udata(&ucmd, udata, ucmdlen)) {\n\t\tmlx5_ib_dbg(dev, \"failed copy udata\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tif (ucmd.reserved0 || ucmd.reserved1)\n\t\treturn -EINVAL;\n\n\tif (udata->inlen > sizeof(ucmd) &&\n\t    !ib_is_udata_cleared(udata, sizeof(ucmd),\n\t\t\t\t udata->inlen - sizeof(ucmd)))\n\t\treturn -EINVAL;\n\n\tif (in->type != IB_SRQT_BASIC) {\n\t\terr = get_srq_user_index(ucontext, &ucmd, udata->inlen, &uidx);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tsrq->wq_sig = !!(ucmd.flags & MLX5_SRQ_FLAG_SIGNATURE);\n\n\tsrq->umem = ib_umem_get(pd->device, ucmd.buf_addr, buf_size, 0);\n\tif (IS_ERR(srq->umem)) {\n\t\tmlx5_ib_dbg(dev, \"failed umem get, size %d\\n\", buf_size);\n\t\terr = PTR_ERR(srq->umem);\n\t\treturn err;\n\t}\n\tin->umem = srq->umem;\n\n\terr = mlx5_ib_db_map_user(ucontext, ucmd.db_addr, &srq->db);\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"map doorbell failed\\n\");\n\t\tgoto err_umem;\n\t}\n\n\tin->uid = (in->type != IB_SRQT_XRC) ?  to_mpd(pd)->uid : 0;\n\tif (MLX5_CAP_GEN(dev->mdev, cqe_version) == MLX5_CQE_VERSION_V1 &&\n\t    in->type != IB_SRQT_BASIC)\n\t\tin->user_index = uidx;\n\n\treturn 0;\n\nerr_umem:\n\tib_umem_release(srq->umem);\n\n\treturn err;\n}\n\nstatic int create_srq_kernel(struct mlx5_ib_dev *dev, struct mlx5_ib_srq *srq,\n\t\t\t     struct mlx5_srq_attr *in, int buf_size)\n{\n\tint err;\n\tint i;\n\tstruct mlx5_wqe_srq_next_seg *next;\n\n\terr = mlx5_db_alloc(dev->mdev, &srq->db);\n\tif (err) {\n\t\tmlx5_ib_warn(dev, \"alloc dbell rec failed\\n\");\n\t\treturn err;\n\t}\n\n\tif (mlx5_frag_buf_alloc_node(dev->mdev, buf_size, &srq->buf,\n\t\t\t\t     dev->mdev->priv.numa_node)) {\n\t\tmlx5_ib_dbg(dev, \"buf alloc failed\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto err_db;\n\t}\n\n\tmlx5_init_fbc(srq->buf.frags, srq->msrq.wqe_shift, ilog2(srq->msrq.max),\n\t\t      &srq->fbc);\n\n\tsrq->head    = 0;\n\tsrq->tail    = srq->msrq.max - 1;\n\tsrq->wqe_ctr = 0;\n\n\tfor (i = 0; i < srq->msrq.max; i++) {\n\t\tnext = get_wqe(srq, i);\n\t\tnext->next_wqe_index =\n\t\t\tcpu_to_be16((i + 1) & (srq->msrq.max - 1));\n\t}\n\n\tmlx5_ib_dbg(dev, \"srq->buf.page_shift = %d\\n\", srq->buf.page_shift);\n\tin->pas = kvcalloc(srq->buf.npages, sizeof(*in->pas), GFP_KERNEL);\n\tif (!in->pas) {\n\t\terr = -ENOMEM;\n\t\tgoto err_buf;\n\t}\n\tmlx5_fill_page_frag_array(&srq->buf, in->pas);\n\n\tsrq->wrid = kvmalloc_array(srq->msrq.max, sizeof(u64), GFP_KERNEL);\n\tif (!srq->wrid) {\n\t\terr = -ENOMEM;\n\t\tgoto err_in;\n\t}\n\tsrq->wq_sig = 0;\n\n\tin->log_page_size = srq->buf.page_shift - MLX5_ADAPTER_PAGE_SHIFT;\n\tif (MLX5_CAP_GEN(dev->mdev, cqe_version) == MLX5_CQE_VERSION_V1 &&\n\t    in->type != IB_SRQT_BASIC)\n\t\tin->user_index = MLX5_IB_DEFAULT_UIDX;\n\n\treturn 0;\n\nerr_in:\n\tkvfree(in->pas);\n\nerr_buf:\n\tmlx5_frag_buf_free(dev->mdev, &srq->buf);\n\nerr_db:\n\tmlx5_db_free(dev->mdev, &srq->db);\n\treturn err;\n}\n\nstatic void destroy_srq_user(struct ib_pd *pd, struct mlx5_ib_srq *srq,\n\t\t\t     struct ib_udata *udata)\n{\n\tmlx5_ib_db_unmap_user(\n\t\trdma_udata_to_drv_context(\n\t\t\tudata,\n\t\t\tstruct mlx5_ib_ucontext,\n\t\t\tibucontext),\n\t\t&srq->db);\n\tib_umem_release(srq->umem);\n}\n\n\nstatic void destroy_srq_kernel(struct mlx5_ib_dev *dev, struct mlx5_ib_srq *srq)\n{\n\tkvfree(srq->wrid);\n\tmlx5_frag_buf_free(dev->mdev, &srq->buf);\n\tmlx5_db_free(dev->mdev, &srq->db);\n}\n\nint mlx5_ib_create_srq(struct ib_srq *ib_srq,\n\t\t       struct ib_srq_init_attr *init_attr,\n\t\t       struct ib_udata *udata)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ib_srq->device);\n\tstruct mlx5_ib_srq *srq = to_msrq(ib_srq);\n\tsize_t desc_size;\n\tsize_t buf_size;\n\tint err;\n\tstruct mlx5_srq_attr in = {};\n\t__u32 max_srq_wqes = 1 << MLX5_CAP_GEN(dev->mdev, log_max_srq_sz);\n\n\tif (init_attr->srq_type != IB_SRQT_BASIC &&\n\t    init_attr->srq_type != IB_SRQT_XRC &&\n\t    init_attr->srq_type != IB_SRQT_TM)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (init_attr->attr.max_wr >= max_srq_wqes) {\n\t\tmlx5_ib_dbg(dev, \"max_wr %d, cap %d\\n\",\n\t\t\t    init_attr->attr.max_wr,\n\t\t\t    max_srq_wqes);\n\t\treturn -EINVAL;\n\t}\n\n\tmutex_init(&srq->mutex);\n\tspin_lock_init(&srq->lock);\n\tsrq->msrq.max    = roundup_pow_of_two(init_attr->attr.max_wr + 1);\n\tsrq->msrq.max_gs = init_attr->attr.max_sge;\n\n\tdesc_size = sizeof(struct mlx5_wqe_srq_next_seg) +\n\t\t    srq->msrq.max_gs * sizeof(struct mlx5_wqe_data_seg);\n\tif (desc_size == 0 || srq->msrq.max_gs > desc_size)\n\t\treturn -EINVAL;\n\n\tdesc_size = roundup_pow_of_two(desc_size);\n\tdesc_size = max_t(size_t, 32, desc_size);\n\tif (desc_size < sizeof(struct mlx5_wqe_srq_next_seg))\n\t\treturn -EINVAL;\n\n\tsrq->msrq.max_avail_gather = (desc_size - sizeof(struct mlx5_wqe_srq_next_seg)) /\n\t\tsizeof(struct mlx5_wqe_data_seg);\n\tsrq->msrq.wqe_shift = ilog2(desc_size);\n\tbuf_size = srq->msrq.max * desc_size;\n\tif (buf_size < desc_size)\n\t\treturn -EINVAL;\n\n\tin.type = init_attr->srq_type;\n\n\tif (udata)\n\t\terr = create_srq_user(ib_srq->pd, srq, &in, udata, buf_size);\n\telse\n\t\terr = create_srq_kernel(dev, srq, &in, buf_size);\n\n\tif (err) {\n\t\tmlx5_ib_warn(dev, \"create srq %s failed, err %d\\n\",\n\t\t\t     udata ? \"user\" : \"kernel\", err);\n\t\treturn err;\n\t}\n\n\tin.log_size = ilog2(srq->msrq.max);\n\tin.wqe_shift = srq->msrq.wqe_shift - 4;\n\tif (srq->wq_sig)\n\t\tin.flags |= MLX5_SRQ_FLAG_WQ_SIG;\n\n\tif (init_attr->srq_type == IB_SRQT_XRC && init_attr->ext.xrc.xrcd)\n\t\tin.xrcd = to_mxrcd(init_attr->ext.xrc.xrcd)->xrcdn;\n\telse\n\t\tin.xrcd = dev->devr.xrcdn0;\n\n\tif (init_attr->srq_type == IB_SRQT_TM) {\n\t\tin.tm_log_list_size =\n\t\t\tilog2(init_attr->ext.tag_matching.max_num_tags) + 1;\n\t\tif (in.tm_log_list_size >\n\t\t    MLX5_CAP_GEN(dev->mdev, log_tag_matching_list_sz)) {\n\t\t\tmlx5_ib_dbg(dev, \"TM SRQ max_num_tags exceeding limit\\n\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto err_usr_kern_srq;\n\t\t}\n\t\tin.flags |= MLX5_SRQ_FLAG_RNDV;\n\t}\n\n\tif (ib_srq_has_cq(init_attr->srq_type))\n\t\tin.cqn = to_mcq(init_attr->ext.cq)->mcq.cqn;\n\telse\n\t\tin.cqn = to_mcq(dev->devr.c0)->mcq.cqn;\n\n\tin.pd = to_mpd(ib_srq->pd)->pdn;\n\tin.db_record = srq->db.dma;\n\terr = mlx5_cmd_create_srq(dev, &srq->msrq, &in);\n\tkvfree(in.pas);\n\tif (err) {\n\t\tmlx5_ib_dbg(dev, \"create SRQ failed, err %d\\n\", err);\n\t\tgoto err_usr_kern_srq;\n\t}\n\n\tmlx5_ib_dbg(dev, \"create SRQ with srqn 0x%x\\n\", srq->msrq.srqn);\n\n\tsrq->msrq.event = mlx5_ib_srq_event;\n\tsrq->ibsrq.ext.xrc.srq_num = srq->msrq.srqn;\n\n\tif (udata) {\n\t\tstruct mlx5_ib_create_srq_resp resp = {\n\t\t\t.srqn = srq->msrq.srqn,\n\t\t};\n\n\t\tif (ib_copy_to_udata(udata, &resp, min(udata->outlen,\n\t\t\t\t     sizeof(resp)))) {\n\t\t\tmlx5_ib_dbg(dev, \"copy to user failed\\n\");\n\t\t\terr = -EFAULT;\n\t\t\tgoto err_core;\n\t\t}\n\t}\n\n\tinit_attr->attr.max_wr = srq->msrq.max - 1;\n\n\treturn 0;\n\nerr_core:\n\tmlx5_cmd_destroy_srq(dev, &srq->msrq);\n\nerr_usr_kern_srq:\n\tif (udata)\n\t\tdestroy_srq_user(ib_srq->pd, srq, udata);\n\telse\n\t\tdestroy_srq_kernel(dev, srq);\n\n\treturn err;\n}\n\nint mlx5_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,\n\t\t       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ibsrq->device);\n\tstruct mlx5_ib_srq *srq = to_msrq(ibsrq);\n\tint ret;\n\n\t \n\tif (attr_mask & IB_SRQ_MAX_WR)\n\t\treturn -EINVAL;\n\n\tif (attr_mask & IB_SRQ_LIMIT) {\n\t\tif (attr->srq_limit >= srq->msrq.max)\n\t\t\treturn -EINVAL;\n\n\t\tmutex_lock(&srq->mutex);\n\t\tret = mlx5_cmd_arm_srq(dev, &srq->msrq, attr->srq_limit, 1);\n\t\tmutex_unlock(&srq->mutex);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint mlx5_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(ibsrq->device);\n\tstruct mlx5_ib_srq *srq = to_msrq(ibsrq);\n\tint ret;\n\tstruct mlx5_srq_attr *out;\n\n\tout = kzalloc(sizeof(*out), GFP_KERNEL);\n\tif (!out)\n\t\treturn -ENOMEM;\n\n\tret = mlx5_cmd_query_srq(dev, &srq->msrq, out);\n\tif (ret)\n\t\tgoto out_box;\n\n\tsrq_attr->srq_limit = out->lwm;\n\tsrq_attr->max_wr    = srq->msrq.max - 1;\n\tsrq_attr->max_sge   = srq->msrq.max_gs;\n\nout_box:\n\tkfree(out);\n\treturn ret;\n}\n\nint mlx5_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(srq->device);\n\tstruct mlx5_ib_srq *msrq = to_msrq(srq);\n\tint ret;\n\n\tret = mlx5_cmd_destroy_srq(dev, &msrq->msrq);\n\tif (ret)\n\t\treturn ret;\n\n\tif (udata)\n\t\tdestroy_srq_user(srq->pd, msrq, udata);\n\telse\n\t\tdestroy_srq_kernel(dev, msrq);\n\treturn 0;\n}\n\nvoid mlx5_ib_free_srq_wqe(struct mlx5_ib_srq *srq, int wqe_index)\n{\n\tstruct mlx5_wqe_srq_next_seg *next;\n\n\t \n\tspin_lock(&srq->lock);\n\n\tnext = get_wqe(srq, srq->tail);\n\tnext->next_wqe_index = cpu_to_be16(wqe_index);\n\tsrq->tail = wqe_index;\n\n\tspin_unlock(&srq->lock);\n}\n\nint mlx5_ib_post_srq_recv(struct ib_srq *ibsrq, const struct ib_recv_wr *wr,\n\t\t\t  const struct ib_recv_wr **bad_wr)\n{\n\tstruct mlx5_ib_srq *srq = to_msrq(ibsrq);\n\tstruct mlx5_wqe_srq_next_seg *next;\n\tstruct mlx5_wqe_data_seg *scat;\n\tstruct mlx5_ib_dev *dev = to_mdev(ibsrq->device);\n\tstruct mlx5_core_dev *mdev = dev->mdev;\n\tunsigned long flags;\n\tint err = 0;\n\tint nreq;\n\tint i;\n\n\tspin_lock_irqsave(&srq->lock, flags);\n\n\tif (mdev->state == MLX5_DEVICE_STATE_INTERNAL_ERROR) {\n\t\terr = -EIO;\n\t\t*bad_wr = wr;\n\t\tgoto out;\n\t}\n\n\tfor (nreq = 0; wr; nreq++, wr = wr->next) {\n\t\tif (unlikely(wr->num_sge > srq->msrq.max_gs)) {\n\t\t\terr = -EINVAL;\n\t\t\t*bad_wr = wr;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (unlikely(srq->head == srq->tail)) {\n\t\t\terr = -ENOMEM;\n\t\t\t*bad_wr = wr;\n\t\t\tbreak;\n\t\t}\n\n\t\tsrq->wrid[srq->head] = wr->wr_id;\n\n\t\tnext      = get_wqe(srq, srq->head);\n\t\tsrq->head = be16_to_cpu(next->next_wqe_index);\n\t\tscat      = (struct mlx5_wqe_data_seg *)(next + 1);\n\n\t\tfor (i = 0; i < wr->num_sge; i++) {\n\t\t\tscat[i].byte_count = cpu_to_be32(wr->sg_list[i].length);\n\t\t\tscat[i].lkey       = cpu_to_be32(wr->sg_list[i].lkey);\n\t\t\tscat[i].addr       = cpu_to_be64(wr->sg_list[i].addr);\n\t\t}\n\n\t\tif (i < srq->msrq.max_avail_gather) {\n\t\t\tscat[i].byte_count = 0;\n\t\t\tscat[i].lkey = dev->mkeys.terminate_scatter_list_mkey;\n\t\t\tscat[i].addr       = 0;\n\t\t}\n\t}\n\n\tif (likely(nreq)) {\n\t\tsrq->wqe_ctr += nreq;\n\n\t\t \n\t\twmb();\n\n\t\t*srq->db.db = cpu_to_be32(srq->wqe_ctr);\n\t}\nout:\n\tspin_unlock_irqrestore(&srq->lock, flags);\n\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}