{
  "module_name": "mlx5_ib.h",
  "hash_id": "33eb70aecbf1557542fc537272bf4161c56db457a8a594273439c5bd590fa461",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mlx5/mlx5_ib.h",
  "human_readable_source": " \n \n\n#ifndef MLX5_IB_H\n#define MLX5_IB_H\n\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <rdma/ib_verbs.h>\n#include <rdma/ib_umem.h>\n#include <rdma/ib_smi.h>\n#include <linux/mlx5/driver.h>\n#include <linux/mlx5/cq.h>\n#include <linux/mlx5/fs.h>\n#include <linux/mlx5/qp.h>\n#include <linux/types.h>\n#include <linux/mlx5/transobj.h>\n#include <rdma/ib_user_verbs.h>\n#include <rdma/mlx5-abi.h>\n#include <rdma/uverbs_ioctl.h>\n#include <rdma/mlx5_user_ioctl_cmds.h>\n#include <rdma/mlx5_user_ioctl_verbs.h>\n\n#include \"srq.h\"\n#include \"qp.h\"\n#include \"macsec.h\"\n\n#define mlx5_ib_dbg(_dev, format, arg...)                                      \\\n\tdev_dbg(&(_dev)->ib_dev.dev, \"%s:%d:(pid %d): \" format, __func__,      \\\n\t\t__LINE__, current->pid, ##arg)\n\n#define mlx5_ib_err(_dev, format, arg...)                                      \\\n\tdev_err(&(_dev)->ib_dev.dev, \"%s:%d:(pid %d): \" format, __func__,      \\\n\t\t__LINE__, current->pid, ##arg)\n\n#define mlx5_ib_warn(_dev, format, arg...)                                     \\\n\tdev_warn(&(_dev)->ib_dev.dev, \"%s:%d:(pid %d): \" format, __func__,     \\\n\t\t __LINE__, current->pid, ##arg)\n\n#define mlx5_ib_log(lvl, _dev, format, arg...)                                 \\\n\tdev_printk(lvl, &(_dev)->ib_dev.dev,  \"%s:%d:(pid %d): \" format,       \\\n\t\t   __func__, __LINE__, current->pid, ##arg)\n\n#define MLX5_IB_DEFAULT_UIDX 0xffffff\n#define MLX5_USER_ASSIGNED_UIDX_MASK __mlx5_mask(qpc, user_index)\n\nstatic __always_inline unsigned long\n__mlx5_log_page_size_to_bitmap(unsigned int log_pgsz_bits,\n\t\t\t       unsigned int pgsz_shift)\n{\n\tunsigned int largest_pg_shift =\n\t\tmin_t(unsigned long, (1ULL << log_pgsz_bits) - 1 + pgsz_shift,\n\t\t      BITS_PER_LONG - 1);\n\n\t \n\tpgsz_shift = max_t(unsigned int, MLX5_ADAPTER_PAGE_SHIFT, pgsz_shift);\n\treturn GENMASK(largest_pg_shift, pgsz_shift);\n}\n\n \n#define mlx5_umem_find_best_pgsz(umem, typ, log_pgsz_fld, pgsz_shift, iova)    \\\n\tib_umem_find_best_pgsz(umem,                                           \\\n\t\t\t       __mlx5_log_page_size_to_bitmap(                 \\\n\t\t\t\t       __mlx5_bit_sz(typ, log_pgsz_fld),       \\\n\t\t\t\t       pgsz_shift),                            \\\n\t\t\t       iova)\n\nstatic __always_inline unsigned long\n__mlx5_page_offset_to_bitmask(unsigned int page_offset_bits,\n\t\t\t      unsigned int offset_shift)\n{\n\tunsigned int largest_offset_shift =\n\t\tmin_t(unsigned long, page_offset_bits - 1 + offset_shift,\n\t\t      BITS_PER_LONG - 1);\n\n\treturn GENMASK(largest_offset_shift, offset_shift);\n}\n\n \nunsigned long __mlx5_umem_find_best_quantized_pgoff(\n\tstruct ib_umem *umem, unsigned long pgsz_bitmap,\n\tunsigned int page_offset_bits, u64 pgoff_bitmask, unsigned int scale,\n\tunsigned int *page_offset_quantized);\n#define mlx5_umem_find_best_quantized_pgoff(umem, typ, log_pgsz_fld,           \\\n\t\t\t\t\t    pgsz_shift, page_offset_fld,       \\\n\t\t\t\t\t    scale, page_offset_quantized)      \\\n\t__mlx5_umem_find_best_quantized_pgoff(                                 \\\n\t\tumem,                                                          \\\n\t\t__mlx5_log_page_size_to_bitmap(                                \\\n\t\t\t__mlx5_bit_sz(typ, log_pgsz_fld), pgsz_shift),         \\\n\t\t__mlx5_bit_sz(typ, page_offset_fld),                           \\\n\t\tGENMASK(31, order_base_2(scale)), scale,                       \\\n\t\tpage_offset_quantized)\n\n#define mlx5_umem_find_best_cq_quantized_pgoff(umem, typ, log_pgsz_fld,        \\\n\t\t\t\t\t       pgsz_shift, page_offset_fld,    \\\n\t\t\t\t\t       scale, page_offset_quantized)   \\\n\t__mlx5_umem_find_best_quantized_pgoff(                                 \\\n\t\tumem,                                                          \\\n\t\t__mlx5_log_page_size_to_bitmap(                                \\\n\t\t\t__mlx5_bit_sz(typ, log_pgsz_fld), pgsz_shift),         \\\n\t\t__mlx5_bit_sz(typ, page_offset_fld), 0, scale,                 \\\n\t\tpage_offset_quantized)\n\nenum {\n\tMLX5_IB_MMAP_OFFSET_START = 9,\n\tMLX5_IB_MMAP_OFFSET_END = 255,\n};\n\nenum {\n\tMLX5_IB_MMAP_CMD_SHIFT\t= 8,\n\tMLX5_IB_MMAP_CMD_MASK\t= 0xff,\n};\n\nenum {\n\tMLX5_RES_SCAT_DATA32_CQE\t= 0x1,\n\tMLX5_RES_SCAT_DATA64_CQE\t= 0x2,\n\tMLX5_REQ_SCAT_DATA32_CQE\t= 0x11,\n\tMLX5_REQ_SCAT_DATA64_CQE\t= 0x22,\n};\n\nenum mlx5_ib_mad_ifc_flags {\n\tMLX5_MAD_IFC_IGNORE_MKEY\t= 1,\n\tMLX5_MAD_IFC_IGNORE_BKEY\t= 2,\n\tMLX5_MAD_IFC_NET_VIEW\t\t= 4,\n};\n\nenum {\n\tMLX5_CROSS_CHANNEL_BFREG         = 0,\n};\n\nenum {\n\tMLX5_CQE_VERSION_V0,\n\tMLX5_CQE_VERSION_V1,\n};\n\nenum {\n\tMLX5_TM_MAX_RNDV_MSG_SIZE\t= 64,\n\tMLX5_TM_MAX_SGE\t\t\t= 1,\n};\n\nenum {\n\tMLX5_IB_INVALID_UAR_INDEX\t= BIT(31),\n\tMLX5_IB_INVALID_BFREG\t\t= BIT(31),\n};\n\nenum {\n\tMLX5_MAX_MEMIC_PAGES = 0x100,\n\tMLX5_MEMIC_ALLOC_SIZE_MASK = 0x3f,\n};\n\nenum {\n\tMLX5_MEMIC_BASE_ALIGN\t= 6,\n\tMLX5_MEMIC_BASE_SIZE\t= 1 << MLX5_MEMIC_BASE_ALIGN,\n};\n\nenum mlx5_ib_mmap_type {\n\tMLX5_IB_MMAP_TYPE_MEMIC = 1,\n\tMLX5_IB_MMAP_TYPE_VAR = 2,\n\tMLX5_IB_MMAP_TYPE_UAR_WC = 3,\n\tMLX5_IB_MMAP_TYPE_UAR_NC = 4,\n\tMLX5_IB_MMAP_TYPE_MEMIC_OP = 5,\n};\n\nstruct mlx5_bfreg_info {\n\tu32 *sys_pages;\n\tint num_low_latency_bfregs;\n\tunsigned int *count;\n\n\t \n\tstruct mutex lock;\n\tu32 ver;\n\tu8 lib_uar_4k : 1;\n\tu8 lib_uar_dyn : 1;\n\tu32 num_sys_pages;\n\tu32 num_static_sys_pages;\n\tu32 total_num_bfregs;\n\tu32 num_dyn_bfregs;\n};\n\nstruct mlx5_ib_ucontext {\n\tstruct ib_ucontext\tibucontext;\n\tstruct list_head\tdb_page_list;\n\n\t \n\tstruct mutex\t\tdb_page_mutex;\n\tstruct mlx5_bfreg_info\tbfregi;\n\tu8\t\t\tcqe_version;\n\t \n\tu32\t\t\ttdn;\n\n\tu64\t\t\tlib_caps;\n\tu16\t\t\tdevx_uid;\n\t \n\tatomic_t\t\ttx_port_affinity;\n};\n\nstatic inline struct mlx5_ib_ucontext *to_mucontext(struct ib_ucontext *ibucontext)\n{\n\treturn container_of(ibucontext, struct mlx5_ib_ucontext, ibucontext);\n}\n\nstruct mlx5_ib_pd {\n\tstruct ib_pd\t\tibpd;\n\tu32\t\t\tpdn;\n\tu16\t\t\tuid;\n};\n\nenum {\n\tMLX5_IB_FLOW_ACTION_MODIFY_HEADER,\n\tMLX5_IB_FLOW_ACTION_PACKET_REFORMAT,\n\tMLX5_IB_FLOW_ACTION_DECAP,\n};\n\n#define MLX5_IB_FLOW_MCAST_PRIO\t\t(MLX5_BY_PASS_NUM_PRIOS - 1)\n#define MLX5_IB_FLOW_LAST_PRIO\t\t(MLX5_BY_PASS_NUM_REGULAR_PRIOS - 1)\n#if (MLX5_IB_FLOW_LAST_PRIO <= 0)\n#error \"Invalid number of bypass priorities\"\n#endif\n#define MLX5_IB_FLOW_LEFTOVERS_PRIO\t(MLX5_IB_FLOW_MCAST_PRIO + 1)\n\n#define MLX5_IB_NUM_FLOW_FT\t\t(MLX5_IB_FLOW_LEFTOVERS_PRIO + 1)\n#define MLX5_IB_NUM_SNIFFER_FTS\t\t2\n#define MLX5_IB_NUM_EGRESS_FTS\t\t1\n#define MLX5_IB_NUM_FDB_FTS\t\tMLX5_BY_PASS_NUM_REGULAR_PRIOS\n\nstruct mlx5_ib_anchor {\n\tstruct mlx5_flow_table *ft;\n\tstruct mlx5_flow_group *fg_goto_table;\n\tstruct mlx5_flow_group *fg_drop;\n\tstruct mlx5_flow_handle *rule_goto_table;\n\tstruct mlx5_flow_handle *rule_drop;\n\tunsigned int rule_goto_table_ref;\n};\n\nstruct mlx5_ib_flow_prio {\n\tstruct mlx5_flow_table\t\t*flow_table;\n\tstruct mlx5_ib_anchor\t\tanchor;\n\tunsigned int\t\t\trefcount;\n};\n\nstruct mlx5_ib_flow_handler {\n\tstruct list_head\t\tlist;\n\tstruct ib_flow\t\t\tibflow;\n\tstruct mlx5_ib_flow_prio\t*prio;\n\tstruct mlx5_flow_handle\t\t*rule;\n\tstruct ib_counters\t\t*ibcounters;\n\tstruct mlx5_ib_dev\t\t*dev;\n\tstruct mlx5_ib_flow_matcher\t*flow_matcher;\n};\n\nstruct mlx5_ib_flow_matcher {\n\tstruct mlx5_ib_match_params matcher_mask;\n\tint\t\t\tmask_len;\n\tenum mlx5_ib_flow_type\tflow_type;\n\tenum mlx5_flow_namespace_type ns_type;\n\tu16\t\t\tpriority;\n\tstruct mlx5_core_dev\t*mdev;\n\tatomic_t\t\tusecnt;\n\tu8\t\t\tmatch_criteria_enable;\n};\n\nstruct mlx5_ib_steering_anchor {\n\tstruct mlx5_ib_flow_prio *ft_prio;\n\tstruct mlx5_ib_dev *dev;\n\tatomic_t usecnt;\n};\n\nstruct mlx5_ib_pp {\n\tu16 index;\n\tstruct mlx5_core_dev *mdev;\n};\n\nenum mlx5_ib_optional_counter_type {\n\tMLX5_IB_OPCOUNTER_CC_RX_CE_PKTS,\n\tMLX5_IB_OPCOUNTER_CC_RX_CNP_PKTS,\n\tMLX5_IB_OPCOUNTER_CC_TX_CNP_PKTS,\n\n\tMLX5_IB_OPCOUNTER_MAX,\n};\n\nstruct mlx5_ib_flow_db {\n\tstruct mlx5_ib_flow_prio\tprios[MLX5_IB_NUM_FLOW_FT];\n\tstruct mlx5_ib_flow_prio\tegress_prios[MLX5_IB_NUM_FLOW_FT];\n\tstruct mlx5_ib_flow_prio\tsniffer[MLX5_IB_NUM_SNIFFER_FTS];\n\tstruct mlx5_ib_flow_prio\tegress[MLX5_IB_NUM_EGRESS_FTS];\n\tstruct mlx5_ib_flow_prio\tfdb[MLX5_IB_NUM_FDB_FTS];\n\tstruct mlx5_ib_flow_prio\trdma_rx[MLX5_IB_NUM_FLOW_FT];\n\tstruct mlx5_ib_flow_prio\trdma_tx[MLX5_IB_NUM_FLOW_FT];\n\tstruct mlx5_ib_flow_prio\topfcs[MLX5_IB_OPCOUNTER_MAX];\n\tstruct mlx5_flow_table\t\t*lag_demux_ft;\n\t \n\tstruct mutex\t\t\tlock;\n};\n\n \n\n#define MLX5_IB_QPT_REG_UMR\tIB_QPT_RESERVED1\n \n#define MLX5_IB_QPT_HW_GSI\tIB_QPT_RESERVED2\n#define MLX5_IB_QPT_DCI\t\tIB_QPT_RESERVED3\n#define MLX5_IB_QPT_DCT\t\tIB_QPT_RESERVED4\n#define MLX5_IB_WR_UMR\t\tIB_WR_RESERVED1\n\n#define MLX5_IB_UPD_XLT_ZAP\t      BIT(0)\n#define MLX5_IB_UPD_XLT_ENABLE\t      BIT(1)\n#define MLX5_IB_UPD_XLT_ATOMIC\t      BIT(2)\n#define MLX5_IB_UPD_XLT_ADDR\t      BIT(3)\n#define MLX5_IB_UPD_XLT_PD\t      BIT(4)\n#define MLX5_IB_UPD_XLT_ACCESS\t      BIT(5)\n#define MLX5_IB_UPD_XLT_INDIRECT      BIT(6)\n\n \n#define MLX5_IB_QP_CREATE_SQPN_QP1\tIB_QP_CREATE_RESERVED_START\n#define MLX5_IB_QP_CREATE_WC_TEST\t(IB_QP_CREATE_RESERVED_START << 1)\n\nstruct wr_list {\n\tu16\topcode;\n\tu16\tnext;\n};\n\nenum mlx5_ib_rq_flags {\n\tMLX5_IB_RQ_CVLAN_STRIPPING\t= 1 << 0,\n\tMLX5_IB_RQ_PCI_WRITE_END_PADDING\t= 1 << 1,\n};\n\nstruct mlx5_ib_wq {\n\tstruct mlx5_frag_buf_ctrl fbc;\n\tu64\t\t       *wrid;\n\tu32\t\t       *wr_data;\n\tstruct wr_list\t       *w_list;\n\tunsigned\t       *wqe_head;\n\tu16\t\t        unsig_count;\n\n\t \n\tspinlock_t\t\tlock;\n\tint\t\t\twqe_cnt;\n\tint\t\t\tmax_post;\n\tint\t\t\tmax_gs;\n\tint\t\t\toffset;\n\tint\t\t\twqe_shift;\n\tunsigned\t\thead;\n\tunsigned\t\ttail;\n\tu16\t\t\tcur_post;\n\tu16\t\t\tlast_poll;\n\tvoid\t\t\t*cur_edge;\n};\n\nenum mlx5_ib_wq_flags {\n\tMLX5_IB_WQ_FLAGS_DELAY_DROP = 0x1,\n\tMLX5_IB_WQ_FLAGS_STRIDING_RQ = 0x2,\n};\n\n#define MLX5_MIN_SINGLE_WQE_LOG_NUM_STRIDES 9\n#define MLX5_MAX_SINGLE_WQE_LOG_NUM_STRIDES 16\n#define MLX5_MIN_SINGLE_STRIDE_LOG_NUM_BYTES 6\n#define MLX5_MAX_SINGLE_STRIDE_LOG_NUM_BYTES 13\n#define MLX5_EXT_MIN_SINGLE_WQE_LOG_NUM_STRIDES 3\n\nstruct mlx5_ib_rwq {\n\tstruct ib_wq\t\tibwq;\n\tstruct mlx5_core_qp\tcore_qp;\n\tu32\t\t\trq_num_pas;\n\tu32\t\t\tlog_rq_stride;\n\tu32\t\t\tlog_rq_size;\n\tu32\t\t\trq_page_offset;\n\tu32\t\t\tlog_page_size;\n\tu32\t\t\tlog_num_strides;\n\tu32\t\t\ttwo_byte_shift_en;\n\tu32\t\t\tsingle_stride_log_num_of_bytes;\n\tstruct ib_umem\t\t*umem;\n\tsize_t\t\t\tbuf_size;\n\tunsigned int\t\tpage_shift;\n\tstruct mlx5_db\t\tdb;\n\tu32\t\t\tuser_index;\n\tu32\t\t\twqe_count;\n\tu32\t\t\twqe_shift;\n\tint\t\t\twq_sig;\n\tu32\t\t\tcreate_flags;  \n};\n\nstruct mlx5_ib_rwq_ind_table {\n\tstruct ib_rwq_ind_table ib_rwq_ind_tbl;\n\tu32\t\t\trqtn;\n\tu16\t\t\tuid;\n};\n\nstruct mlx5_ib_ubuffer {\n\tstruct ib_umem\t       *umem;\n\tint\t\t\tbuf_size;\n\tu64\t\t\tbuf_addr;\n};\n\nstruct mlx5_ib_qp_base {\n\tstruct mlx5_ib_qp\t*container_mibqp;\n\tstruct mlx5_core_qp\tmqp;\n\tstruct mlx5_ib_ubuffer\tubuffer;\n};\n\nstruct mlx5_ib_qp_trans {\n\tstruct mlx5_ib_qp_base\tbase;\n\tu16\t\t\txrcdn;\n\tu32\t\t\talt_port;\n\tu8\t\t\tatomic_rd_en;\n\tu8\t\t\tresp_depth;\n};\n\nstruct mlx5_ib_rss_qp {\n\tu32\ttirn;\n};\n\nstruct mlx5_ib_rq {\n\tstruct mlx5_ib_qp_base base;\n\tstruct mlx5_ib_wq\t*rq;\n\tstruct mlx5_ib_ubuffer\tubuffer;\n\tstruct mlx5_db\t\t*doorbell;\n\tu32\t\t\ttirn;\n\tu8\t\t\tstate;\n\tu32\t\t\tflags;\n};\n\nstruct mlx5_ib_sq {\n\tstruct mlx5_ib_qp_base base;\n\tstruct mlx5_ib_wq\t*sq;\n\tstruct mlx5_ib_ubuffer  ubuffer;\n\tstruct mlx5_db\t\t*doorbell;\n\tstruct mlx5_flow_handle\t*flow_rule;\n\tu32\t\t\ttisn;\n\tu8\t\t\tstate;\n};\n\nstruct mlx5_ib_raw_packet_qp {\n\tstruct mlx5_ib_sq sq;\n\tstruct mlx5_ib_rq rq;\n};\n\nstruct mlx5_bf {\n\tint\t\t\tbuf_size;\n\tunsigned long\t\toffset;\n\tstruct mlx5_sq_bfreg   *bfreg;\n};\n\nstruct mlx5_ib_dct {\n\tstruct mlx5_core_dct    mdct;\n\tu32                     *in;\n};\n\nstruct mlx5_ib_gsi_qp {\n\tstruct ib_qp *rx_qp;\n\tu32 port_num;\n\tstruct ib_qp_cap cap;\n\tstruct ib_cq *cq;\n\tstruct mlx5_ib_gsi_wr *outstanding_wrs;\n\tu32 outstanding_pi, outstanding_ci;\n\tint num_qps;\n\t \n\tspinlock_t lock;\n\tstruct ib_qp **tx_qps;\n};\n\nstruct mlx5_ib_qp {\n\tstruct ib_qp\t\tibqp;\n\tunion {\n\t\tstruct mlx5_ib_qp_trans trans_qp;\n\t\tstruct mlx5_ib_raw_packet_qp raw_packet_qp;\n\t\tstruct mlx5_ib_rss_qp rss_qp;\n\t\tstruct mlx5_ib_dct dct;\n\t\tstruct mlx5_ib_gsi_qp gsi;\n\t};\n\tstruct mlx5_frag_buf\tbuf;\n\n\tstruct mlx5_db\t\tdb;\n\tstruct mlx5_ib_wq\trq;\n\n\tu8\t\t\tsq_signal_bits;\n\tu8\t\t\tnext_fence;\n\tstruct mlx5_ib_wq\tsq;\n\n\t \n\tstruct mutex\t\tmutex;\n\t \n\tu32\t\t\tflags;\n\tu32\t\t\tport;\n\tu8\t\t\tstate;\n\tint\t\t\tmax_inline_data;\n\tstruct mlx5_bf\t        bf;\n\tu8\t\t\thas_rq:1;\n\tu8\t\t\tis_rss:1;\n\n\t \n\tint\t\t\tbfregn;\n\n\tstruct list_head\tqps_list;\n\tstruct list_head\tcq_recv_list;\n\tstruct list_head\tcq_send_list;\n\tstruct mlx5_rate_limit\trl;\n\tu32                     underlay_qpn;\n\tu32\t\t\tflags_en;\n\t \n\tenum ib_qp_type\t\ttype;\n\t \n\tu32                     counter_pending;\n\tu16\t\t\tgsi_lag_port;\n};\n\nstruct mlx5_ib_cq_buf {\n\tstruct mlx5_frag_buf_ctrl fbc;\n\tstruct mlx5_frag_buf    frag_buf;\n\tstruct ib_umem\t\t*umem;\n\tint\t\t\tcqe_size;\n\tint\t\t\tnent;\n};\n\nenum mlx5_ib_cq_pr_flags {\n\tMLX5_IB_CQ_PR_FLAGS_CQE_128_PAD\t= 1 << 0,\n\tMLX5_IB_CQ_PR_FLAGS_REAL_TIME_TS = 1 << 1,\n};\n\nstruct mlx5_ib_cq {\n\tstruct ib_cq\t\tibcq;\n\tstruct mlx5_core_cq\tmcq;\n\tstruct mlx5_ib_cq_buf\tbuf;\n\tstruct mlx5_db\t\tdb;\n\n\t \n\tspinlock_t\t\tlock;\n\n\t \n\tstruct mutex\t\tresize_mutex;\n\tstruct mlx5_ib_cq_buf  *resize_buf;\n\tstruct ib_umem\t       *resize_umem;\n\tint\t\t\tcqe_size;\n\tstruct list_head\tlist_send_qp;\n\tstruct list_head\tlist_recv_qp;\n\tu32\t\t\tcreate_flags;\n\tstruct list_head\twc_list;\n\tenum ib_cq_notify_flags notify_flags;\n\tstruct work_struct\tnotify_work;\n\tu16\t\t\tprivate_flags;  \n};\n\nstruct mlx5_ib_wc {\n\tstruct ib_wc wc;\n\tstruct list_head list;\n};\n\nstruct mlx5_ib_srq {\n\tstruct ib_srq\t\tibsrq;\n\tstruct mlx5_core_srq\tmsrq;\n\tstruct mlx5_frag_buf\tbuf;\n\tstruct mlx5_db\t\tdb;\n\tstruct mlx5_frag_buf_ctrl fbc;\n\tu64\t\t       *wrid;\n\t \n\tspinlock_t\t\tlock;\n\tint\t\t\thead;\n\tint\t\t\ttail;\n\tu16\t\t\twqe_ctr;\n\tstruct ib_umem\t       *umem;\n\t \n\tstruct mutex\t\tmutex;\n\tint\t\t\twq_sig;\n};\n\nstruct mlx5_ib_xrcd {\n\tstruct ib_xrcd\t\tibxrcd;\n\tu32\t\t\txrcdn;\n};\n\nenum mlx5_ib_mtt_access_flags {\n\tMLX5_IB_MTT_READ  = (1 << 0),\n\tMLX5_IB_MTT_WRITE = (1 << 1),\n};\n\nstruct mlx5_user_mmap_entry {\n\tstruct rdma_user_mmap_entry rdma_entry;\n\tu8 mmap_flag;\n\tu64 address;\n\tu32 page_idx;\n};\n\nenum mlx5_mkey_type {\n\tMLX5_MKEY_MR = 1,\n\tMLX5_MKEY_MW,\n\tMLX5_MKEY_INDIRECT_DEVX,\n};\n\nstruct mlx5r_cache_rb_key {\n\tu8 ats:1;\n\tunsigned int access_mode;\n\tunsigned int access_flags;\n\tunsigned int ndescs;\n};\n\nstruct mlx5_ib_mkey {\n\tu32 key;\n\tenum mlx5_mkey_type type;\n\tunsigned int ndescs;\n\tstruct wait_queue_head wait;\n\trefcount_t usecount;\n\t \n\tstruct mlx5r_cache_rb_key rb_key;\n\tstruct mlx5_cache_ent *cache_ent;\n};\n\n#define MLX5_IB_MTT_PRESENT (MLX5_IB_MTT_READ | MLX5_IB_MTT_WRITE)\n\n#define MLX5_IB_DM_MEMIC_ALLOWED_ACCESS (IB_ACCESS_LOCAL_WRITE   |\\\n\t\t\t\t\t IB_ACCESS_REMOTE_WRITE  |\\\n\t\t\t\t\t IB_ACCESS_REMOTE_READ   |\\\n\t\t\t\t\t IB_ACCESS_REMOTE_ATOMIC |\\\n\t\t\t\t\t IB_ZERO_BASED)\n\n#define MLX5_IB_DM_SW_ICM_ALLOWED_ACCESS (IB_ACCESS_LOCAL_WRITE   |\\\n\t\t\t\t\t  IB_ACCESS_REMOTE_WRITE  |\\\n\t\t\t\t\t  IB_ACCESS_REMOTE_READ   |\\\n\t\t\t\t\t  IB_ZERO_BASED)\n\n#define mlx5_update_odp_stats(mr, counter_name, value)\t\t\\\n\tatomic64_add(value, &((mr)->odp_stats.counter_name))\n\nstruct mlx5_ib_mr {\n\tstruct ib_mr ibmr;\n\tstruct mlx5_ib_mkey mmkey;\n\n\tstruct ib_umem *umem;\n\n\tunion {\n\t\t \n\t\tstruct {\n\t\t\tvoid *descs;\n\t\t\tvoid *descs_alloc;\n\t\t\tdma_addr_t desc_map;\n\t\t\tint max_descs;\n\t\t\tint desc_size;\n\t\t\tint access_mode;\n\n\t\t\t \n\t\t\tstruct mlx5_core_sig_ctx *sig;\n\t\t\tstruct mlx5_ib_mr *pi_mr;\n\t\t\tstruct mlx5_ib_mr *klm_mr;\n\t\t\tstruct mlx5_ib_mr *mtt_mr;\n\t\t\tu64 data_iova;\n\t\t\tu64 pi_iova;\n\t\t\tint meta_ndescs;\n\t\t\tint meta_length;\n\t\t\tint data_length;\n\t\t};\n\n\t\t \n\t\tstruct {\n\t\t\tunsigned int page_shift;\n\t\t\t \n\t\t\tint access_flags;\n\n\t\t\t \n\t\t\tstruct mlx5_ib_mr *parent;\n\t\t\tstruct xarray implicit_children;\n\t\t\tunion {\n\t\t\t\tstruct work_struct work;\n\t\t\t} odp_destroy;\n\t\t\tstruct ib_odp_counters odp_stats;\n\t\t\tbool is_odp_implicit;\n\t\t};\n\t};\n};\n\nstatic inline bool is_odp_mr(struct mlx5_ib_mr *mr)\n{\n\treturn IS_ENABLED(CONFIG_INFINIBAND_ON_DEMAND_PAGING) && mr->umem &&\n\t       mr->umem->is_odp;\n}\n\nstatic inline bool is_dmabuf_mr(struct mlx5_ib_mr *mr)\n{\n\treturn IS_ENABLED(CONFIG_INFINIBAND_ON_DEMAND_PAGING) && mr->umem &&\n\t       mr->umem->is_dmabuf;\n}\n\nstruct mlx5_ib_mw {\n\tstruct ib_mw\t\tibmw;\n\tstruct mlx5_ib_mkey\tmmkey;\n};\n\nstruct mlx5_ib_umr_context {\n\tstruct ib_cqe\t\tcqe;\n\tenum ib_wc_status\tstatus;\n\tstruct completion\tdone;\n};\n\nenum {\n\tMLX5_UMR_STATE_UNINIT,\n\tMLX5_UMR_STATE_ACTIVE,\n\tMLX5_UMR_STATE_RECOVER,\n\tMLX5_UMR_STATE_ERR,\n};\n\nstruct umr_common {\n\tstruct ib_pd\t*pd;\n\tstruct ib_cq\t*cq;\n\tstruct ib_qp\t*qp;\n\t \n\tstruct semaphore\tsem;\n\t \n\tstruct mutex lock;\n\tunsigned int state;\n};\n\nstruct mlx5_cache_ent {\n\tstruct xarray\t\tmkeys;\n\tunsigned long\t\tstored;\n\tunsigned long\t\treserved;\n\n\tchar                    name[4];\n\n\tstruct rb_node\t\tnode;\n\tstruct mlx5r_cache_rb_key rb_key;\n\n\tu8 is_tmp:1;\n\tu8 disabled:1;\n\tu8 fill_to_high_water:1;\n\n\t \n\tu32 in_use;\n\tu32 limit;\n\n\t \n\tu32                     miss;\n\n\tstruct mlx5_ib_dev     *dev;\n\tstruct delayed_work\tdwork;\n};\n\nstruct mlx5r_async_create_mkey {\n\tunion {\n\t\tu32 in[MLX5_ST_SZ_BYTES(create_mkey_in)];\n\t\tu32 out[MLX5_ST_SZ_DW(create_mkey_out)];\n\t};\n\tstruct mlx5_async_work cb_work;\n\tstruct mlx5_cache_ent *ent;\n\tu32 mkey;\n};\n\nstruct mlx5_mkey_cache {\n\tstruct workqueue_struct *wq;\n\tstruct rb_root\t\trb_root;\n\tstruct mutex\t\trb_lock;\n\tstruct dentry\t\t*fs_root;\n\tunsigned long\t\tlast_add;\n\tstruct delayed_work\tremove_ent_dwork;\n};\n\nstruct mlx5_ib_port_resources {\n\tstruct mlx5_ib_gsi_qp *gsi;\n\tstruct work_struct pkey_change_work;\n};\n\nstruct mlx5_ib_resources {\n\tstruct ib_cq\t*c0;\n\tu32 xrcdn0;\n\tu32 xrcdn1;\n\tstruct ib_pd\t*p0;\n\tstruct ib_srq\t*s0;\n\tstruct ib_srq\t*s1;\n\tstruct mlx5_ib_port_resources ports[2];\n};\n\n#define MAX_OPFC_RULES 2\n\nstruct mlx5_ib_op_fc {\n\tstruct mlx5_fc *fc;\n\tstruct mlx5_flow_handle *rule[MAX_OPFC_RULES];\n};\n\nstruct mlx5_ib_counters {\n\tstruct rdma_stat_desc *descs;\n\tsize_t *offsets;\n\tu32 num_q_counters;\n\tu32 num_cong_counters;\n\tu32 num_ext_ppcnt_counters;\n\tu32 num_op_counters;\n\tu16 set_id;\n\tstruct mlx5_ib_op_fc opfcs[MLX5_IB_OPCOUNTER_MAX];\n};\n\nint mlx5_ib_fs_add_op_fc(struct mlx5_ib_dev *dev, u32 port_num,\n\t\t\t struct mlx5_ib_op_fc *opfc,\n\t\t\t enum mlx5_ib_optional_counter_type type);\n\nvoid mlx5_ib_fs_remove_op_fc(struct mlx5_ib_dev *dev,\n\t\t\t     struct mlx5_ib_op_fc *opfc,\n\t\t\t     enum mlx5_ib_optional_counter_type type);\n\nstruct mlx5_ib_multiport_info;\n\nstruct mlx5_ib_multiport {\n\tstruct mlx5_ib_multiport_info *mpi;\n\t \n\tspinlock_t mpi_lock;\n};\n\nstruct mlx5_roce {\n\t \n\trwlock_t\t\tnetdev_lock;\n\tstruct net_device\t*netdev;\n\tstruct notifier_block\tnb;\n\tstruct netdev_net_notifier nn;\n\tstruct notifier_block\tmdev_nb;\n\tstruct net_device\t*tracking_netdev;\n\tatomic_t\t\ttx_port_affinity;\n\tenum ib_port_state last_port_state;\n\tstruct mlx5_ib_dev\t*dev;\n\tu32\t\t\tnative_port_num;\n};\n\nstruct mlx5_ib_port {\n\tstruct mlx5_ib_counters cnts;\n\tstruct mlx5_ib_multiport mp;\n\tstruct mlx5_ib_dbg_cc_params *dbg_cc_params;\n\tstruct mlx5_roce roce;\n\tstruct mlx5_eswitch_rep\t\t*rep;\n#ifdef CONFIG_MLX5_MACSEC\n\tstruct mlx5_reserved_gids *reserved_gids;\n#endif\n};\n\nstruct mlx5_ib_dbg_param {\n\tint\t\t\toffset;\n\tstruct mlx5_ib_dev\t*dev;\n\tstruct dentry\t\t*dentry;\n\tu32\t\t\tport_num;\n};\n\nenum mlx5_ib_dbg_cc_types {\n\tMLX5_IB_DBG_CC_RP_CLAMP_TGT_RATE,\n\tMLX5_IB_DBG_CC_RP_CLAMP_TGT_RATE_ATI,\n\tMLX5_IB_DBG_CC_RP_TIME_RESET,\n\tMLX5_IB_DBG_CC_RP_BYTE_RESET,\n\tMLX5_IB_DBG_CC_RP_THRESHOLD,\n\tMLX5_IB_DBG_CC_RP_AI_RATE,\n\tMLX5_IB_DBG_CC_RP_MAX_RATE,\n\tMLX5_IB_DBG_CC_RP_HAI_RATE,\n\tMLX5_IB_DBG_CC_RP_MIN_DEC_FAC,\n\tMLX5_IB_DBG_CC_RP_MIN_RATE,\n\tMLX5_IB_DBG_CC_RP_RATE_TO_SET_ON_FIRST_CNP,\n\tMLX5_IB_DBG_CC_RP_DCE_TCP_G,\n\tMLX5_IB_DBG_CC_RP_DCE_TCP_RTT,\n\tMLX5_IB_DBG_CC_RP_RATE_REDUCE_MONITOR_PERIOD,\n\tMLX5_IB_DBG_CC_RP_INITIAL_ALPHA_VALUE,\n\tMLX5_IB_DBG_CC_RP_GD,\n\tMLX5_IB_DBG_CC_NP_MIN_TIME_BETWEEN_CNPS,\n\tMLX5_IB_DBG_CC_NP_CNP_DSCP,\n\tMLX5_IB_DBG_CC_NP_CNP_PRIO_MODE,\n\tMLX5_IB_DBG_CC_NP_CNP_PRIO,\n\tMLX5_IB_DBG_CC_GENERAL_RTT_RESP_DSCP_VALID,\n\tMLX5_IB_DBG_CC_GENERAL_RTT_RESP_DSCP,\n\tMLX5_IB_DBG_CC_MAX,\n};\n\nstruct mlx5_ib_dbg_cc_params {\n\tstruct dentry\t\t\t*root;\n\tstruct mlx5_ib_dbg_param\tparams[MLX5_IB_DBG_CC_MAX];\n};\n\nenum {\n\tMLX5_MAX_DELAY_DROP_TIMEOUT_MS = 100,\n};\n\nstruct mlx5_ib_delay_drop {\n\tstruct mlx5_ib_dev     *dev;\n\tstruct work_struct\tdelay_drop_work;\n\t \n\tstruct mutex\t\tlock;\n\tu32\t\t\ttimeout;\n\tbool\t\t\tactivate;\n\tatomic_t\t\tevents_cnt;\n\tatomic_t\t\trqs_cnt;\n\tstruct dentry\t\t*dir_debugfs;\n};\n\nenum mlx5_ib_stages {\n\tMLX5_IB_STAGE_INIT,\n\tMLX5_IB_STAGE_FS,\n\tMLX5_IB_STAGE_CAPS,\n\tMLX5_IB_STAGE_NON_DEFAULT_CB,\n\tMLX5_IB_STAGE_ROCE,\n\tMLX5_IB_STAGE_QP,\n\tMLX5_IB_STAGE_SRQ,\n\tMLX5_IB_STAGE_DEVICE_RESOURCES,\n\tMLX5_IB_STAGE_DEVICE_NOTIFIER,\n\tMLX5_IB_STAGE_ODP,\n\tMLX5_IB_STAGE_COUNTERS,\n\tMLX5_IB_STAGE_CONG_DEBUGFS,\n\tMLX5_IB_STAGE_UAR,\n\tMLX5_IB_STAGE_BFREG,\n\tMLX5_IB_STAGE_PRE_IB_REG_UMR,\n\tMLX5_IB_STAGE_WHITELIST_UID,\n\tMLX5_IB_STAGE_IB_REG,\n\tMLX5_IB_STAGE_POST_IB_REG_UMR,\n\tMLX5_IB_STAGE_DELAY_DROP,\n\tMLX5_IB_STAGE_RESTRACK,\n\tMLX5_IB_STAGE_MAX,\n};\n\nstruct mlx5_ib_stage {\n\tint (*init)(struct mlx5_ib_dev *dev);\n\tvoid (*cleanup)(struct mlx5_ib_dev *dev);\n};\n\n#define STAGE_CREATE(_stage, _init, _cleanup) \\\n\t.stage[_stage] = {.init = _init, .cleanup = _cleanup}\n\nstruct mlx5_ib_profile {\n\tstruct mlx5_ib_stage stage[MLX5_IB_STAGE_MAX];\n};\n\nstruct mlx5_ib_multiport_info {\n\tstruct list_head list;\n\tstruct mlx5_ib_dev *ibdev;\n\tstruct mlx5_core_dev *mdev;\n\tstruct notifier_block mdev_events;\n\tstruct completion unref_comp;\n\tu64 sys_image_guid;\n\tu32 mdev_refcnt;\n\tbool is_master;\n\tbool unaffiliate;\n};\n\nstruct mlx5_ib_flow_action {\n\tstruct ib_flow_action\t\tib_action;\n\tunion {\n\t\tstruct {\n\t\t\tu64\t\t\t    ib_flags;\n\t\t\tstruct mlx5_accel_esp_xfrm *ctx;\n\t\t} esp_aes_gcm;\n\t\tstruct {\n\t\t\tstruct mlx5_ib_dev *dev;\n\t\t\tu32 sub_type;\n\t\t\tunion {\n\t\t\t\tstruct mlx5_modify_hdr *modify_hdr;\n\t\t\t\tstruct mlx5_pkt_reformat *pkt_reformat;\n\t\t\t};\n\t\t} flow_action_raw;\n\t};\n};\n\nstruct mlx5_dm {\n\tstruct mlx5_core_dev *dev;\n\t \n\tspinlock_t lock;\n\tDECLARE_BITMAP(memic_alloc_pages, MLX5_MAX_MEMIC_PAGES);\n};\n\nstruct mlx5_read_counters_attr {\n\tstruct mlx5_fc *hw_cntrs_hndl;\n\tu64 *out;\n\tu32 flags;\n};\n\nenum mlx5_ib_counters_type {\n\tMLX5_IB_COUNTERS_FLOW,\n};\n\nstruct mlx5_ib_mcounters {\n\tstruct ib_counters ibcntrs;\n\tenum mlx5_ib_counters_type type;\n\t \n\tu32 counters_num;\n\tstruct mlx5_fc *hw_cntrs_hndl;\n\t \n\tint (*read_counters)(struct ib_device *ibdev,\n\t\t\t     struct mlx5_read_counters_attr *read_attr);\n\t \n\tu32 cntrs_max_index;\n\t \n\tu32 ncounters;\n\t \n\tstruct mlx5_ib_flow_counters_desc *counters_data;\n\t \n\tstruct mutex mcntrs_mutex;\n};\n\nstatic inline struct mlx5_ib_mcounters *\nto_mcounters(struct ib_counters *ibcntrs)\n{\n\treturn container_of(ibcntrs, struct mlx5_ib_mcounters, ibcntrs);\n}\n\nint parse_flow_flow_action(struct mlx5_ib_flow_action *maction,\n\t\t\t   bool is_egress,\n\t\t\t   struct mlx5_flow_act *action);\nstruct mlx5_ib_lb_state {\n\t \n\tstruct mutex\t\tmutex;\n\tu32\t\t\tuser_td;\n\tint\t\t\tqps;\n\tbool\t\t\tenabled;\n};\n\nstruct mlx5_ib_pf_eq {\n\tstruct notifier_block irq_nb;\n\tstruct mlx5_ib_dev *dev;\n\tstruct mlx5_eq *core;\n\tstruct work_struct work;\n\tspinlock_t lock;  \n\tstruct workqueue_struct *wq;\n\tmempool_t *pool;\n};\n\nstruct mlx5_devx_event_table {\n\tstruct mlx5_nb devx_nb;\n\t \n\tstruct mutex event_xa_lock;\n\tstruct xarray event_xa;\n};\n\nstruct mlx5_var_table {\n\t \n\tstruct mutex bitmap_lock;\n\tunsigned long *bitmap;\n\tu64 hw_start_addr;\n\tu32 stride_size;\n\tu64 num_var_hw_entries;\n};\n\nstruct mlx5_port_caps {\n\tbool has_smi;\n\tu8 ext_port_cap;\n};\n\n\nstruct mlx5_special_mkeys {\n\tu32 dump_fill_mkey;\n\t__be32 null_mkey;\n\t__be32 terminate_scatter_list_mkey;\n};\n\nstruct mlx5_macsec {\n\tstruct mutex lock;  \n\tstruct list_head macsec_devices_list;\n\tstruct notifier_block blocking_events_nb;\n};\n\nstruct mlx5_ib_dev {\n\tstruct ib_device\t\tib_dev;\n\tstruct mlx5_core_dev\t\t*mdev;\n\tstruct notifier_block\t\tmdev_events;\n\tint\t\t\t\tnum_ports;\n\t \n\tstruct mutex\t\t\tcap_mask_mutex;\n\tu8\t\t\t\tib_active:1;\n\tu8\t\t\t\tis_rep:1;\n\tu8\t\t\t\tlag_active:1;\n\tu8\t\t\t\twc_support:1;\n\tu8\t\t\t\tfill_delay;\n\tstruct umr_common\t\tumrc;\n\t \n\tstruct mlx5_ib_resources\tdevr;\n\n\tatomic_t\t\t\tmkey_var;\n\tstruct mlx5_mkey_cache\t\tcache;\n\tstruct timer_list\t\tdelay_timer;\n\t \n\tstruct mutex\t\t\tslow_path_mutex;\n\tstruct ib_odp_caps\todp_caps;\n\tu64\t\t\todp_max_size;\n\tstruct mutex\t\todp_eq_mutex;\n\tstruct mlx5_ib_pf_eq\todp_pf_eq;\n\n\tstruct xarray\t\todp_mkeys;\n\n\tstruct mlx5_ib_flow_db\t*flow_db;\n\t \n\tspinlock_t\t\treset_flow_resource_lock;\n\tstruct list_head\tqp_list;\n\t \n\tstruct mlx5_ib_port\t*port;\n\tstruct mlx5_sq_bfreg\tbfreg;\n\tstruct mlx5_sq_bfreg\twc_bfreg;\n\tstruct mlx5_sq_bfreg\tfp_bfreg;\n\tstruct mlx5_ib_delay_drop\tdelay_drop;\n\tconst struct mlx5_ib_profile\t*profile;\n\n\tstruct mlx5_ib_lb_state\t\tlb;\n\tu8\t\t\tumr_fence;\n\tstruct list_head\tib_dev_list;\n\tu64\t\t\tsys_image_guid;\n\tstruct mlx5_dm\t\tdm;\n\tu16\t\t\tdevx_whitelist_uid;\n\tstruct mlx5_srq_table   srq_table;\n\tstruct mlx5_qp_table    qp_table;\n\tstruct mlx5_async_ctx   async_ctx;\n\tstruct mlx5_devx_event_table devx_event_table;\n\tstruct mlx5_var_table var_table;\n\n\tstruct xarray sig_mrs;\n\tstruct mlx5_port_caps port_caps[MLX5_MAX_PORTS];\n\tu16 pkey_table_len;\n\tu8 lag_ports;\n\tstruct mlx5_special_mkeys mkeys;\n\n#ifdef CONFIG_MLX5_MACSEC\n\tstruct mlx5_macsec macsec;\n#endif\n};\n\nstatic inline struct mlx5_ib_cq *to_mibcq(struct mlx5_core_cq *mcq)\n{\n\treturn container_of(mcq, struct mlx5_ib_cq, mcq);\n}\n\nstatic inline struct mlx5_ib_xrcd *to_mxrcd(struct ib_xrcd *ibxrcd)\n{\n\treturn container_of(ibxrcd, struct mlx5_ib_xrcd, ibxrcd);\n}\n\nstatic inline struct mlx5_ib_dev *to_mdev(struct ib_device *ibdev)\n{\n\treturn container_of(ibdev, struct mlx5_ib_dev, ib_dev);\n}\n\nstatic inline struct mlx5_ib_dev *mr_to_mdev(struct mlx5_ib_mr *mr)\n{\n\treturn to_mdev(mr->ibmr.device);\n}\n\nstatic inline struct mlx5_ib_dev *mlx5_udata_to_mdev(struct ib_udata *udata)\n{\n\tstruct mlx5_ib_ucontext *context = rdma_udata_to_drv_context(\n\t\tudata, struct mlx5_ib_ucontext, ibucontext);\n\n\treturn to_mdev(context->ibucontext.device);\n}\n\nstatic inline struct mlx5_ib_cq *to_mcq(struct ib_cq *ibcq)\n{\n\treturn container_of(ibcq, struct mlx5_ib_cq, ibcq);\n}\n\nstatic inline struct mlx5_ib_qp *to_mibqp(struct mlx5_core_qp *mqp)\n{\n\treturn container_of(mqp, struct mlx5_ib_qp_base, mqp)->container_mibqp;\n}\n\nstatic inline struct mlx5_ib_rwq *to_mibrwq(struct mlx5_core_qp *core_qp)\n{\n\treturn container_of(core_qp, struct mlx5_ib_rwq, core_qp);\n}\n\nstatic inline struct mlx5_ib_pd *to_mpd(struct ib_pd *ibpd)\n{\n\treturn container_of(ibpd, struct mlx5_ib_pd, ibpd);\n}\n\nstatic inline struct mlx5_ib_srq *to_msrq(struct ib_srq *ibsrq)\n{\n\treturn container_of(ibsrq, struct mlx5_ib_srq, ibsrq);\n}\n\nstatic inline struct mlx5_ib_qp *to_mqp(struct ib_qp *ibqp)\n{\n\treturn container_of(ibqp, struct mlx5_ib_qp, ibqp);\n}\n\nstatic inline struct mlx5_ib_rwq *to_mrwq(struct ib_wq *ibwq)\n{\n\treturn container_of(ibwq, struct mlx5_ib_rwq, ibwq);\n}\n\nstatic inline struct mlx5_ib_rwq_ind_table *to_mrwq_ind_table(struct ib_rwq_ind_table *ib_rwq_ind_tbl)\n{\n\treturn container_of(ib_rwq_ind_tbl, struct mlx5_ib_rwq_ind_table, ib_rwq_ind_tbl);\n}\n\nstatic inline struct mlx5_ib_srq *to_mibsrq(struct mlx5_core_srq *msrq)\n{\n\treturn container_of(msrq, struct mlx5_ib_srq, msrq);\n}\n\nstatic inline struct mlx5_ib_mr *to_mmr(struct ib_mr *ibmr)\n{\n\treturn container_of(ibmr, struct mlx5_ib_mr, ibmr);\n}\n\nstatic inline struct mlx5_ib_mw *to_mmw(struct ib_mw *ibmw)\n{\n\treturn container_of(ibmw, struct mlx5_ib_mw, ibmw);\n}\n\nstatic inline struct mlx5_ib_flow_action *\nto_mflow_act(struct ib_flow_action *ibact)\n{\n\treturn container_of(ibact, struct mlx5_ib_flow_action, ib_action);\n}\n\nstatic inline struct mlx5_user_mmap_entry *\nto_mmmap(struct rdma_user_mmap_entry *rdma_entry)\n{\n\treturn container_of(rdma_entry,\n\t\tstruct mlx5_user_mmap_entry, rdma_entry);\n}\n\nint mlx5_ib_db_map_user(struct mlx5_ib_ucontext *context, unsigned long virt,\n\t\t\tstruct mlx5_db *db);\nvoid mlx5_ib_db_unmap_user(struct mlx5_ib_ucontext *context, struct mlx5_db *db);\nvoid __mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 qpn, struct mlx5_ib_srq *srq);\nvoid mlx5_ib_cq_clean(struct mlx5_ib_cq *cq, u32 qpn, struct mlx5_ib_srq *srq);\nvoid mlx5_ib_free_srq_wqe(struct mlx5_ib_srq *srq, int wqe_index);\nint mlx5_ib_create_ah(struct ib_ah *ah, struct rdma_ah_init_attr *init_attr,\n\t\t      struct ib_udata *udata);\nint mlx5_ib_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);\nstatic inline int mlx5_ib_destroy_ah(struct ib_ah *ah, u32 flags)\n{\n\treturn 0;\n}\nint mlx5_ib_create_srq(struct ib_srq *srq, struct ib_srq_init_attr *init_attr,\n\t\t       struct ib_udata *udata);\nint mlx5_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,\n\t\t       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata);\nint mlx5_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr);\nint mlx5_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata);\nint mlx5_ib_post_srq_recv(struct ib_srq *ibsrq, const struct ib_recv_wr *wr,\n\t\t\t  const struct ib_recv_wr **bad_wr);\nint mlx5_ib_enable_lb(struct mlx5_ib_dev *dev, bool td, bool qp);\nvoid mlx5_ib_disable_lb(struct mlx5_ib_dev *dev, bool td, bool qp);\nint mlx5_ib_create_qp(struct ib_qp *qp, struct ib_qp_init_attr *init_attr,\n\t\t      struct ib_udata *udata);\nint mlx5_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,\n\t\t      int attr_mask, struct ib_udata *udata);\nint mlx5_ib_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *qp_attr, int qp_attr_mask,\n\t\t     struct ib_qp_init_attr *qp_init_attr);\nint mlx5_ib_destroy_qp(struct ib_qp *qp, struct ib_udata *udata);\nvoid mlx5_ib_drain_sq(struct ib_qp *qp);\nvoid mlx5_ib_drain_rq(struct ib_qp *qp);\nint mlx5_ib_read_wqe_sq(struct mlx5_ib_qp *qp, int wqe_index, void *buffer,\n\t\t\tsize_t buflen, size_t *bc);\nint mlx5_ib_read_wqe_rq(struct mlx5_ib_qp *qp, int wqe_index, void *buffer,\n\t\t\tsize_t buflen, size_t *bc);\nint mlx5_ib_read_wqe_srq(struct mlx5_ib_srq *srq, int wqe_index, void *buffer,\n\t\t\t size_t buflen, size_t *bc);\nint mlx5_ib_create_cq(struct ib_cq *ibcq, const struct ib_cq_init_attr *attr,\n\t\t      struct ib_udata *udata);\nint mlx5_ib_destroy_cq(struct ib_cq *cq, struct ib_udata *udata);\nint mlx5_ib_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc);\nint mlx5_ib_arm_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags flags);\nint mlx5_ib_modify_cq(struct ib_cq *cq, u16 cq_count, u16 cq_period);\nint mlx5_ib_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata);\nstruct ib_mr *mlx5_ib_get_dma_mr(struct ib_pd *pd, int acc);\nstruct ib_mr *mlx5_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,\n\t\t\t\t  u64 virt_addr, int access_flags,\n\t\t\t\t  struct ib_udata *udata);\nstruct ib_mr *mlx5_ib_reg_user_mr_dmabuf(struct ib_pd *pd, u64 start,\n\t\t\t\t\t u64 length, u64 virt_addr,\n\t\t\t\t\t int fd, int access_flags,\n\t\t\t\t\t struct ib_udata *udata);\nint mlx5_ib_advise_mr(struct ib_pd *pd,\n\t\t      enum ib_uverbs_advise_mr_advice advice,\n\t\t      u32 flags,\n\t\t      struct ib_sge *sg_list,\n\t\t      u32 num_sge,\n\t\t      struct uverbs_attr_bundle *attrs);\nint mlx5_ib_alloc_mw(struct ib_mw *mw, struct ib_udata *udata);\nint mlx5_ib_dealloc_mw(struct ib_mw *mw);\nstruct mlx5_ib_mr *mlx5_ib_alloc_implicit_mr(struct mlx5_ib_pd *pd,\n\t\t\t\t\t     int access_flags);\nvoid mlx5_ib_free_implicit_mr(struct mlx5_ib_mr *mr);\nvoid mlx5_ib_free_odp_mr(struct mlx5_ib_mr *mr);\nstruct ib_mr *mlx5_ib_rereg_user_mr(struct ib_mr *ib_mr, int flags, u64 start,\n\t\t\t\t    u64 length, u64 virt_addr, int access_flags,\n\t\t\t\t    struct ib_pd *pd, struct ib_udata *udata);\nint mlx5_ib_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata);\nstruct ib_mr *mlx5_ib_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,\n\t\t\t       u32 max_num_sg);\nstruct ib_mr *mlx5_ib_alloc_mr_integrity(struct ib_pd *pd,\n\t\t\t\t\t u32 max_num_sg,\n\t\t\t\t\t u32 max_num_meta_sg);\nint mlx5_ib_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,\n\t\t      unsigned int *sg_offset);\nint mlx5_ib_map_mr_sg_pi(struct ib_mr *ibmr, struct scatterlist *data_sg,\n\t\t\t int data_sg_nents, unsigned int *data_sg_offset,\n\t\t\t struct scatterlist *meta_sg, int meta_sg_nents,\n\t\t\t unsigned int *meta_sg_offset);\nint mlx5_ib_process_mad(struct ib_device *ibdev, int mad_flags, u32 port_num,\n\t\t\tconst struct ib_wc *in_wc, const struct ib_grh *in_grh,\n\t\t\tconst struct ib_mad *in, struct ib_mad *out,\n\t\t\tsize_t *out_mad_size, u16 *out_mad_pkey_index);\nint mlx5_ib_alloc_xrcd(struct ib_xrcd *xrcd, struct ib_udata *udata);\nint mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd, struct ib_udata *udata);\nint mlx5_query_ext_port_caps(struct mlx5_ib_dev *dev, unsigned int port);\nint mlx5_query_mad_ifc_system_image_guid(struct ib_device *ibdev,\n\t\t\t\t\t __be64 *sys_image_guid);\nint mlx5_query_mad_ifc_max_pkeys(struct ib_device *ibdev,\n\t\t\t\t u16 *max_pkeys);\nint mlx5_query_mad_ifc_vendor_id(struct ib_device *ibdev,\n\t\t\t\t u32 *vendor_id);\nint mlx5_query_mad_ifc_node_desc(struct mlx5_ib_dev *dev, char *node_desc);\nint mlx5_query_mad_ifc_node_guid(struct mlx5_ib_dev *dev, __be64 *node_guid);\nint mlx5_query_mad_ifc_pkey(struct ib_device *ibdev, u32 port, u16 index,\n\t\t\t    u16 *pkey);\nint mlx5_query_mad_ifc_gids(struct ib_device *ibdev, u32 port, int index,\n\t\t\t    union ib_gid *gid);\nint mlx5_query_mad_ifc_port(struct ib_device *ibdev, u32 port,\n\t\t\t    struct ib_port_attr *props);\nint mlx5_ib_query_port(struct ib_device *ibdev, u32 port,\n\t\t       struct ib_port_attr *props);\nvoid mlx5_ib_populate_pas(struct ib_umem *umem, size_t page_size, __be64 *pas,\n\t\t\t  u64 access_flags);\nvoid mlx5_ib_copy_pas(u64 *old, u64 *new, int step, int num);\nint mlx5_ib_get_cqe_size(struct ib_cq *ibcq);\nint mlx5_mkey_cache_init(struct mlx5_ib_dev *dev);\nvoid mlx5_mkey_cache_cleanup(struct mlx5_ib_dev *dev);\nstruct mlx5_cache_ent *\nmlx5r_cache_create_ent_locked(struct mlx5_ib_dev *dev,\n\t\t\t      struct mlx5r_cache_rb_key rb_key,\n\t\t\t      bool persistent_entry);\n\nstruct mlx5_ib_mr *mlx5_mr_cache_alloc(struct mlx5_ib_dev *dev,\n\t\t\t\t       int access_flags, int access_mode,\n\t\t\t\t       int ndescs);\n\nint mlx5_ib_check_mr_status(struct ib_mr *ibmr, u32 check_mask,\n\t\t\t    struct ib_mr_status *mr_status);\nstruct ib_wq *mlx5_ib_create_wq(struct ib_pd *pd,\n\t\t\t\tstruct ib_wq_init_attr *init_attr,\n\t\t\t\tstruct ib_udata *udata);\nint mlx5_ib_destroy_wq(struct ib_wq *wq, struct ib_udata *udata);\nint mlx5_ib_modify_wq(struct ib_wq *wq, struct ib_wq_attr *wq_attr,\n\t\t      u32 wq_attr_mask, struct ib_udata *udata);\nint mlx5_ib_create_rwq_ind_table(struct ib_rwq_ind_table *ib_rwq_ind_table,\n\t\t\t\t struct ib_rwq_ind_table_init_attr *init_attr,\n\t\t\t\t struct ib_udata *udata);\nint mlx5_ib_destroy_rwq_ind_table(struct ib_rwq_ind_table *wq_ind_table);\nstruct ib_mr *mlx5_ib_reg_dm_mr(struct ib_pd *pd, struct ib_dm *dm,\n\t\t\t\tstruct ib_dm_mr_attr *attr,\n\t\t\t\tstruct uverbs_attr_bundle *attrs);\n\n#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING\nint mlx5_ib_odp_init_one(struct mlx5_ib_dev *ibdev);\nint mlx5r_odp_create_eq(struct mlx5_ib_dev *dev, struct mlx5_ib_pf_eq *eq);\nvoid mlx5_ib_odp_cleanup_one(struct mlx5_ib_dev *ibdev);\nint __init mlx5_ib_odp_init(void);\nvoid mlx5_ib_odp_cleanup(void);\nint mlx5_odp_init_mkey_cache(struct mlx5_ib_dev *dev);\nvoid mlx5_odp_populate_xlt(void *xlt, size_t idx, size_t nentries,\n\t\t\t   struct mlx5_ib_mr *mr, int flags);\n\nint mlx5_ib_advise_mr_prefetch(struct ib_pd *pd,\n\t\t\t       enum ib_uverbs_advise_mr_advice advice,\n\t\t\t       u32 flags, struct ib_sge *sg_list, u32 num_sge);\nint mlx5_ib_init_odp_mr(struct mlx5_ib_mr *mr);\nint mlx5_ib_init_dmabuf_mr(struct mlx5_ib_mr *mr);\n#else  \nstatic inline int mlx5_ib_odp_init_one(struct mlx5_ib_dev *ibdev) { return 0; }\nstatic inline int mlx5r_odp_create_eq(struct mlx5_ib_dev *dev,\n\t\t\t\t      struct mlx5_ib_pf_eq *eq)\n{\n\treturn 0;\n}\nstatic inline void mlx5_ib_odp_cleanup_one(struct mlx5_ib_dev *ibdev) {}\nstatic inline int mlx5_ib_odp_init(void) { return 0; }\nstatic inline void mlx5_ib_odp_cleanup(void)\t\t\t\t    {}\nstatic inline int mlx5_odp_init_mkey_cache(struct mlx5_ib_dev *dev)\n{\n\treturn 0;\n}\nstatic inline void mlx5_odp_populate_xlt(void *xlt, size_t idx, size_t nentries,\n\t\t\t\t\t struct mlx5_ib_mr *mr, int flags) {}\n\nstatic inline int\nmlx5_ib_advise_mr_prefetch(struct ib_pd *pd,\n\t\t\t   enum ib_uverbs_advise_mr_advice advice, u32 flags,\n\t\t\t   struct ib_sge *sg_list, u32 num_sge)\n{\n\treturn -EOPNOTSUPP;\n}\nstatic inline int mlx5_ib_init_odp_mr(struct mlx5_ib_mr *mr)\n{\n\treturn -EOPNOTSUPP;\n}\nstatic inline int mlx5_ib_init_dmabuf_mr(struct mlx5_ib_mr *mr)\n{\n\treturn -EOPNOTSUPP;\n}\n#endif  \n\nextern const struct mmu_interval_notifier_ops mlx5_mn_ops;\n\n \nvoid __mlx5_ib_remove(struct mlx5_ib_dev *dev,\n\t\t      const struct mlx5_ib_profile *profile,\n\t\t      int stage);\nint __mlx5_ib_add(struct mlx5_ib_dev *dev,\n\t\t  const struct mlx5_ib_profile *profile);\n\nint mlx5_ib_get_vf_config(struct ib_device *device, int vf,\n\t\t\t  u32 port, struct ifla_vf_info *info);\nint mlx5_ib_set_vf_link_state(struct ib_device *device, int vf,\n\t\t\t      u32 port, int state);\nint mlx5_ib_get_vf_stats(struct ib_device *device, int vf,\n\t\t\t u32 port, struct ifla_vf_stats *stats);\nint mlx5_ib_get_vf_guid(struct ib_device *device, int vf, u32 port,\n\t\t\tstruct ifla_vf_guid *node_guid,\n\t\t\tstruct ifla_vf_guid *port_guid);\nint mlx5_ib_set_vf_guid(struct ib_device *device, int vf, u32 port,\n\t\t\tu64 guid, int type);\n\n__be16 mlx5_get_roce_udp_sport_min(const struct mlx5_ib_dev *dev,\n\t\t\t\t   const struct ib_gid_attr *attr);\n\nvoid mlx5_ib_cleanup_cong_debugfs(struct mlx5_ib_dev *dev, u32 port_num);\nvoid mlx5_ib_init_cong_debugfs(struct mlx5_ib_dev *dev, u32 port_num);\n\n \nint mlx5_ib_create_gsi(struct ib_pd *pd, struct mlx5_ib_qp *mqp,\n\t\t       struct ib_qp_init_attr *attr);\nint mlx5_ib_destroy_gsi(struct mlx5_ib_qp *mqp);\nint mlx5_ib_gsi_modify_qp(struct ib_qp *qp, struct ib_qp_attr *attr,\n\t\t\t  int attr_mask);\nint mlx5_ib_gsi_query_qp(struct ib_qp *qp, struct ib_qp_attr *qp_attr,\n\t\t\t int qp_attr_mask,\n\t\t\t struct ib_qp_init_attr *qp_init_attr);\nint mlx5_ib_gsi_post_send(struct ib_qp *qp, const struct ib_send_wr *wr,\n\t\t\t  const struct ib_send_wr **bad_wr);\nint mlx5_ib_gsi_post_recv(struct ib_qp *qp, const struct ib_recv_wr *wr,\n\t\t\t  const struct ib_recv_wr **bad_wr);\nvoid mlx5_ib_gsi_pkey_change(struct mlx5_ib_gsi_qp *gsi);\n\nint mlx5_ib_generate_wc(struct ib_cq *ibcq, struct ib_wc *wc);\n\nvoid mlx5_ib_free_bfreg(struct mlx5_ib_dev *dev, struct mlx5_bfreg_info *bfregi,\n\t\t\tint bfregn);\nstruct mlx5_ib_dev *mlx5_ib_get_ibdev_from_mpi(struct mlx5_ib_multiport_info *mpi);\nstruct mlx5_core_dev *mlx5_ib_get_native_port_mdev(struct mlx5_ib_dev *dev,\n\t\t\t\t\t\t   u32 ib_port_num,\n\t\t\t\t\t\t   u32 *native_port_num);\nvoid mlx5_ib_put_native_port_mdev(struct mlx5_ib_dev *dev,\n\t\t\t\t  u32 port_num);\n\nextern const struct uapi_definition mlx5_ib_devx_defs[];\nextern const struct uapi_definition mlx5_ib_flow_defs[];\nextern const struct uapi_definition mlx5_ib_qos_defs[];\nextern const struct uapi_definition mlx5_ib_std_types_defs[];\n\nstatic inline int is_qp1(enum ib_qp_type qp_type)\n{\n\treturn qp_type == MLX5_IB_QPT_HW_GSI || qp_type == IB_QPT_GSI;\n}\n\nstatic inline u32 check_cq_create_flags(u32 flags)\n{\n\t \n\treturn (flags & ~(IB_UVERBS_CQ_FLAGS_IGNORE_OVERRUN |\n\t\t\t  IB_UVERBS_CQ_FLAGS_TIMESTAMP_COMPLETION));\n}\n\nstatic inline int verify_assign_uidx(u8 cqe_version, u32 cmd_uidx,\n\t\t\t\t     u32 *user_index)\n{\n\tif (cqe_version) {\n\t\tif ((cmd_uidx == MLX5_IB_DEFAULT_UIDX) ||\n\t\t    (cmd_uidx & ~MLX5_USER_ASSIGNED_UIDX_MASK))\n\t\t\treturn -EINVAL;\n\t\t*user_index = cmd_uidx;\n\t} else {\n\t\t*user_index = MLX5_IB_DEFAULT_UIDX;\n\t}\n\n\treturn 0;\n}\n\nstatic inline int get_qp_user_index(struct mlx5_ib_ucontext *ucontext,\n\t\t\t\t    struct mlx5_ib_create_qp *ucmd,\n\t\t\t\t    int inlen,\n\t\t\t\t    u32 *user_index)\n{\n\tu8 cqe_version = ucontext->cqe_version;\n\n\tif ((offsetofend(typeof(*ucmd), uidx) <= inlen) && !cqe_version &&\n\t    (ucmd->uidx == MLX5_IB_DEFAULT_UIDX))\n\t\treturn 0;\n\n\tif ((offsetofend(typeof(*ucmd), uidx) <= inlen) != !!cqe_version)\n\t\treturn -EINVAL;\n\n\treturn verify_assign_uidx(cqe_version, ucmd->uidx, user_index);\n}\n\nstatic inline int get_srq_user_index(struct mlx5_ib_ucontext *ucontext,\n\t\t\t\t     struct mlx5_ib_create_srq *ucmd,\n\t\t\t\t     int inlen,\n\t\t\t\t     u32 *user_index)\n{\n\tu8 cqe_version = ucontext->cqe_version;\n\n\tif ((offsetofend(typeof(*ucmd), uidx) <= inlen) && !cqe_version &&\n\t    (ucmd->uidx == MLX5_IB_DEFAULT_UIDX))\n\t\treturn 0;\n\n\tif ((offsetofend(typeof(*ucmd), uidx) <= inlen) != !!cqe_version)\n\t\treturn -EINVAL;\n\n\treturn verify_assign_uidx(cqe_version, ucmd->uidx, user_index);\n}\n\nstatic inline int get_uars_per_sys_page(struct mlx5_ib_dev *dev, bool lib_support)\n{\n\treturn lib_support && MLX5_CAP_GEN(dev->mdev, uar_4k) ?\n\t\t\t\tMLX5_UARS_IN_PAGE : 1;\n}\n\nextern void *xlt_emergency_page;\n\nint bfregn_to_uar_index(struct mlx5_ib_dev *dev,\n\t\t\tstruct mlx5_bfreg_info *bfregi, u32 bfregn,\n\t\t\tbool dyn_bfreg);\n\nstatic inline int mlx5r_store_odp_mkey(struct mlx5_ib_dev *dev,\n\t\t\t\t       struct mlx5_ib_mkey *mmkey)\n{\n\trefcount_set(&mmkey->usecount, 1);\n\n\treturn xa_err(xa_store(&dev->odp_mkeys, mlx5_base_mkey(mmkey->key),\n\t\t\t       mmkey, GFP_KERNEL));\n}\n\n \nstatic inline void mlx5r_deref_odp_mkey(struct mlx5_ib_mkey *mmkey)\n{\n\tif (refcount_dec_and_test(&mmkey->usecount))\n\t\twake_up(&mmkey->wait);\n}\n\n \nstatic inline void mlx5r_deref_wait_odp_mkey(struct mlx5_ib_mkey *mmkey)\n{\n\tmlx5r_deref_odp_mkey(mmkey);\n\twait_event(mmkey->wait, refcount_read(&mmkey->usecount) == 0);\n}\n\nint mlx5_ib_test_wc(struct mlx5_ib_dev *dev);\n\nstatic inline bool mlx5_ib_lag_should_assign_affinity(struct mlx5_ib_dev *dev)\n{\n\t \n\tif (dev->lag_active &&\n\t    mlx5_lag_mode_is_hash(dev->mdev) &&\n\t    MLX5_CAP_PORT_SELECTION(dev->mdev, port_select_flow_table_bypass))\n\t\treturn 0;\n\n\tif (mlx5_lag_is_lacp_owner(dev->mdev) && !dev->lag_active)\n\t\treturn 0;\n\n\treturn dev->lag_active ||\n\t\t(MLX5_CAP_GEN(dev->mdev, num_lag_ports) > 1 &&\n\t\t MLX5_CAP_GEN(dev->mdev, lag_tx_port_affinity));\n}\n\nstatic inline bool rt_supported(int ts_cap)\n{\n\treturn ts_cap == MLX5_TIMESTAMP_FORMAT_CAP_REAL_TIME ||\n\t       ts_cap == MLX5_TIMESTAMP_FORMAT_CAP_FREE_RUNNING_AND_REAL_TIME;\n}\n\n \nstatic inline bool mlx5_umem_needs_ats(struct mlx5_ib_dev *dev,\n\t\t\t\t       struct ib_umem *umem, int access_flags)\n{\n\tif (!MLX5_CAP_GEN(dev->mdev, ats) || !umem->is_dmabuf)\n\t\treturn false;\n\treturn access_flags & IB_ACCESS_RELAXED_ORDERING;\n}\n\nint set_roce_addr(struct mlx5_ib_dev *dev, u32 port_num,\n\t\t  unsigned int index, const union ib_gid *gid,\n\t\t  const struct ib_gid_attr *attr);\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}