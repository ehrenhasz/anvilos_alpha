{
  "module_name": "srq_cmd.c",
  "hash_id": "3a5c094002e07be581c551e52cb80db1b3b7b597f408fc1028cc3b4ed4e81913",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mlx5/srq_cmd.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/mlx5/driver.h>\n#include \"mlx5_ib.h\"\n#include \"srq.h\"\n#include \"qp.h\"\n\nstatic int get_pas_size(struct mlx5_srq_attr *in)\n{\n\tu32 log_page_size = in->log_page_size + 12;\n\tu32 log_srq_size  = in->log_size;\n\tu32 log_rq_stride = in->wqe_shift;\n\tu32 page_offset   = in->page_offset;\n\tu32 po_quanta\t  = 1 << (log_page_size - 6);\n\tu32 rq_sz\t  = 1 << (log_srq_size + 4 + log_rq_stride);\n\tu32 page_size\t  = 1 << log_page_size;\n\tu32 rq_sz_po      = rq_sz + (page_offset * po_quanta);\n\tu32 rq_num_pas    = DIV_ROUND_UP(rq_sz_po, page_size);\n\n\treturn rq_num_pas * sizeof(u64);\n}\n\nstatic void set_wq(void *wq, struct mlx5_srq_attr *in)\n{\n\tMLX5_SET(wq,   wq, wq_signature,  !!(in->flags\n\t\t & MLX5_SRQ_FLAG_WQ_SIG));\n\tMLX5_SET(wq,   wq, log_wq_pg_sz,  in->log_page_size);\n\tMLX5_SET(wq,   wq, log_wq_stride, in->wqe_shift + 4);\n\tMLX5_SET(wq,   wq, log_wq_sz,     in->log_size);\n\tMLX5_SET(wq,   wq, page_offset,   in->page_offset);\n\tMLX5_SET(wq,   wq, lwm,\t\t  in->lwm);\n\tMLX5_SET(wq,   wq, pd,\t\t  in->pd);\n\tMLX5_SET64(wq, wq, dbr_addr,\t  in->db_record);\n}\n\nstatic void set_srqc(void *srqc, struct mlx5_srq_attr *in)\n{\n\tMLX5_SET(srqc,   srqc, wq_signature,  !!(in->flags\n\t\t & MLX5_SRQ_FLAG_WQ_SIG));\n\tMLX5_SET(srqc,   srqc, log_page_size, in->log_page_size);\n\tMLX5_SET(srqc,   srqc, log_rq_stride, in->wqe_shift);\n\tMLX5_SET(srqc,   srqc, log_srq_size,  in->log_size);\n\tMLX5_SET(srqc,   srqc, page_offset,   in->page_offset);\n\tMLX5_SET(srqc,\t srqc, lwm,\t      in->lwm);\n\tMLX5_SET(srqc,\t srqc, pd,\t      in->pd);\n\tMLX5_SET64(srqc, srqc, dbr_addr,      in->db_record);\n\tMLX5_SET(srqc,\t srqc, xrcd,\t      in->xrcd);\n\tMLX5_SET(srqc,\t srqc, cqn,\t      in->cqn);\n}\n\nstatic void get_wq(void *wq, struct mlx5_srq_attr *in)\n{\n\tif (MLX5_GET(wq, wq, wq_signature))\n\t\tin->flags &= MLX5_SRQ_FLAG_WQ_SIG;\n\tin->log_page_size = MLX5_GET(wq,   wq, log_wq_pg_sz);\n\tin->wqe_shift\t  = MLX5_GET(wq,   wq, log_wq_stride) - 4;\n\tin->log_size\t  = MLX5_GET(wq,   wq, log_wq_sz);\n\tin->page_offset   = MLX5_GET(wq,   wq, page_offset);\n\tin->lwm\t\t  = MLX5_GET(wq,   wq, lwm);\n\tin->pd\t\t  = MLX5_GET(wq,   wq, pd);\n\tin->db_record\t  = MLX5_GET64(wq, wq, dbr_addr);\n}\n\nstatic void get_srqc(void *srqc, struct mlx5_srq_attr *in)\n{\n\tif (MLX5_GET(srqc, srqc, wq_signature))\n\t\tin->flags &= MLX5_SRQ_FLAG_WQ_SIG;\n\tin->log_page_size = MLX5_GET(srqc,   srqc, log_page_size);\n\tin->wqe_shift\t  = MLX5_GET(srqc,   srqc, log_rq_stride);\n\tin->log_size\t  = MLX5_GET(srqc,   srqc, log_srq_size);\n\tin->page_offset   = MLX5_GET(srqc,   srqc, page_offset);\n\tin->lwm\t\t  = MLX5_GET(srqc,   srqc, lwm);\n\tin->pd\t\t  = MLX5_GET(srqc,   srqc, pd);\n\tin->db_record\t  = MLX5_GET64(srqc, srqc, dbr_addr);\n}\n\nstruct mlx5_core_srq *mlx5_cmd_get_srq(struct mlx5_ib_dev *dev, u32 srqn)\n{\n\tstruct mlx5_srq_table *table = &dev->srq_table;\n\tstruct mlx5_core_srq *srq;\n\n\txa_lock_irq(&table->array);\n\tsrq = xa_load(&table->array, srqn);\n\tif (srq)\n\t\trefcount_inc(&srq->common.refcount);\n\txa_unlock_irq(&table->array);\n\n\treturn srq;\n}\n\nstatic int __set_srq_page_size(struct mlx5_srq_attr *in,\n\t\t\t       unsigned long page_size)\n{\n\tif (!page_size)\n\t\treturn -EINVAL;\n\tin->log_page_size = order_base_2(page_size) - MLX5_ADAPTER_PAGE_SHIFT;\n\n\tif (WARN_ON(get_pas_size(in) !=\n\t\t    ib_umem_num_dma_blocks(in->umem, page_size) * sizeof(u64)))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\n#define set_srq_page_size(in, typ, log_pgsz_fld)                               \\\n\t__set_srq_page_size(in, mlx5_umem_find_best_quantized_pgoff(           \\\n\t\t\t\t\t(in)->umem, typ, log_pgsz_fld,         \\\n\t\t\t\t\tMLX5_ADAPTER_PAGE_SHIFT, page_offset,  \\\n\t\t\t\t\t64, &(in)->page_offset))\n\nstatic int create_srq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t  struct mlx5_srq_attr *in)\n{\n\tu32 create_out[MLX5_ST_SZ_DW(create_srq_out)] = {0};\n\tvoid *create_in;\n\tvoid *srqc;\n\tvoid *pas;\n\tint pas_size;\n\tint inlen;\n\tint err;\n\n\tif (in->umem) {\n\t\terr = set_srq_page_size(in, srqc, log_page_size);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tpas_size  = get_pas_size(in);\n\tinlen\t  = MLX5_ST_SZ_BYTES(create_srq_in) + pas_size;\n\tcreate_in = kvzalloc(inlen, GFP_KERNEL);\n\tif (!create_in)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(create_srq_in, create_in, uid, in->uid);\n\tsrqc = MLX5_ADDR_OF(create_srq_in, create_in, srq_context_entry);\n\tpas = MLX5_ADDR_OF(create_srq_in, create_in, pas);\n\n\tset_srqc(srqc, in);\n\tif (in->umem)\n\t\tmlx5_ib_populate_pas(\n\t\t\tin->umem,\n\t\t\t1UL << (in->log_page_size + MLX5_ADAPTER_PAGE_SHIFT),\n\t\t\tpas, 0);\n\telse\n\t\tmemcpy(pas, in->pas, pas_size);\n\n\tMLX5_SET(create_srq_in, create_in, opcode,\n\t\t MLX5_CMD_OP_CREATE_SRQ);\n\n\terr = mlx5_cmd_exec(dev->mdev, create_in, inlen, create_out,\n\t\t\t    sizeof(create_out));\n\tkvfree(create_in);\n\tif (!err) {\n\t\tsrq->srqn = MLX5_GET(create_srq_out, create_out, srqn);\n\t\tsrq->uid = in->uid;\n\t}\n\n\treturn err;\n}\n\nstatic int destroy_srq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq)\n{\n\tu32 in[MLX5_ST_SZ_DW(destroy_srq_in)] = {};\n\n\tMLX5_SET(destroy_srq_in, in, opcode, MLX5_CMD_OP_DESTROY_SRQ);\n\tMLX5_SET(destroy_srq_in, in, srqn, srq->srqn);\n\tMLX5_SET(destroy_srq_in, in, uid, srq->uid);\n\n\treturn mlx5_cmd_exec_in(dev->mdev, destroy_srq, in);\n}\n\nstatic int arm_srq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t       u16 lwm, int is_srq)\n{\n\tu32 in[MLX5_ST_SZ_DW(arm_rq_in)] = {};\n\n\tMLX5_SET(arm_rq_in, in, opcode, MLX5_CMD_OP_ARM_RQ);\n\tMLX5_SET(arm_rq_in, in, op_mod, MLX5_ARM_RQ_IN_OP_MOD_SRQ);\n\tMLX5_SET(arm_rq_in, in, srq_number, srq->srqn);\n\tMLX5_SET(arm_rq_in, in, lwm, lwm);\n\tMLX5_SET(arm_rq_in, in, uid, srq->uid);\n\n\treturn mlx5_cmd_exec_in(dev->mdev, arm_rq, in);\n}\n\nstatic int query_srq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t struct mlx5_srq_attr *out)\n{\n\tu32 in[MLX5_ST_SZ_DW(query_srq_in)] = {};\n\tu32 *srq_out;\n\tvoid *srqc;\n\tint err;\n\n\tsrq_out = kvzalloc(MLX5_ST_SZ_BYTES(query_srq_out), GFP_KERNEL);\n\tif (!srq_out)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(query_srq_in, in, opcode, MLX5_CMD_OP_QUERY_SRQ);\n\tMLX5_SET(query_srq_in, in, srqn, srq->srqn);\n\terr = mlx5_cmd_exec_inout(dev->mdev, query_srq, in, srq_out);\n\tif (err)\n\t\tgoto out;\n\n\tsrqc = MLX5_ADDR_OF(query_srq_out, srq_out, srq_context_entry);\n\tget_srqc(srqc, out);\n\tif (MLX5_GET(srqc, srqc, state) != MLX5_SRQC_STATE_GOOD)\n\t\tout->flags |= MLX5_SRQ_FLAG_ERR;\nout:\n\tkvfree(srq_out);\n\treturn err;\n}\n\nstatic int create_xrc_srq_cmd(struct mlx5_ib_dev *dev,\n\t\t\t      struct mlx5_core_srq *srq,\n\t\t\t      struct mlx5_srq_attr *in)\n{\n\tu32 create_out[MLX5_ST_SZ_DW(create_xrc_srq_out)];\n\tvoid *create_in;\n\tvoid *xrc_srqc;\n\tvoid *pas;\n\tint pas_size;\n\tint inlen;\n\tint err;\n\n\tif (in->umem) {\n\t\terr = set_srq_page_size(in, xrc_srqc, log_page_size);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tpas_size  = get_pas_size(in);\n\tinlen\t  = MLX5_ST_SZ_BYTES(create_xrc_srq_in) + pas_size;\n\tcreate_in = kvzalloc(inlen, GFP_KERNEL);\n\tif (!create_in)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(create_xrc_srq_in, create_in, uid, in->uid);\n\txrc_srqc = MLX5_ADDR_OF(create_xrc_srq_in, create_in,\n\t\t\t\txrc_srq_context_entry);\n\tpas\t = MLX5_ADDR_OF(create_xrc_srq_in, create_in, pas);\n\n\tset_srqc(xrc_srqc, in);\n\tMLX5_SET(xrc_srqc, xrc_srqc, user_index, in->user_index);\n\tif (in->umem)\n\t\tmlx5_ib_populate_pas(\n\t\t\tin->umem,\n\t\t\t1UL << (in->log_page_size + MLX5_ADAPTER_PAGE_SHIFT),\n\t\t\tpas, 0);\n\telse\n\t\tmemcpy(pas, in->pas, pas_size);\n\tMLX5_SET(create_xrc_srq_in, create_in, opcode,\n\t\t MLX5_CMD_OP_CREATE_XRC_SRQ);\n\n\tmemset(create_out, 0, sizeof(create_out));\n\terr = mlx5_cmd_exec(dev->mdev, create_in, inlen, create_out,\n\t\t\t    sizeof(create_out));\n\tif (err)\n\t\tgoto out;\n\n\tsrq->srqn = MLX5_GET(create_xrc_srq_out, create_out, xrc_srqn);\n\tsrq->uid = in->uid;\nout:\n\tkvfree(create_in);\n\treturn err;\n}\n\nstatic int destroy_xrc_srq_cmd(struct mlx5_ib_dev *dev,\n\t\t\t       struct mlx5_core_srq *srq)\n{\n\tu32 in[MLX5_ST_SZ_DW(destroy_xrc_srq_in)] = {};\n\n\tMLX5_SET(destroy_xrc_srq_in, in, opcode, MLX5_CMD_OP_DESTROY_XRC_SRQ);\n\tMLX5_SET(destroy_xrc_srq_in, in, xrc_srqn, srq->srqn);\n\tMLX5_SET(destroy_xrc_srq_in, in, uid, srq->uid);\n\n\treturn mlx5_cmd_exec_in(dev->mdev, destroy_xrc_srq, in);\n}\n\nstatic int arm_xrc_srq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t   u16 lwm)\n{\n\tu32 in[MLX5_ST_SZ_DW(arm_xrc_srq_in)] = {};\n\n\tMLX5_SET(arm_xrc_srq_in, in, opcode, MLX5_CMD_OP_ARM_XRC_SRQ);\n\tMLX5_SET(arm_xrc_srq_in, in, op_mod,\n\t\t MLX5_ARM_XRC_SRQ_IN_OP_MOD_XRC_SRQ);\n\tMLX5_SET(arm_xrc_srq_in, in, xrc_srqn, srq->srqn);\n\tMLX5_SET(arm_xrc_srq_in, in, lwm, lwm);\n\tMLX5_SET(arm_xrc_srq_in, in, uid, srq->uid);\n\n\treturn  mlx5_cmd_exec_in(dev->mdev, arm_xrc_srq, in);\n}\n\nstatic int query_xrc_srq_cmd(struct mlx5_ib_dev *dev,\n\t\t\t     struct mlx5_core_srq *srq,\n\t\t\t     struct mlx5_srq_attr *out)\n{\n\tu32 in[MLX5_ST_SZ_DW(query_xrc_srq_in)] = {};\n\tu32 *xrcsrq_out;\n\tvoid *xrc_srqc;\n\tint err;\n\n\txrcsrq_out = kvzalloc(MLX5_ST_SZ_BYTES(query_xrc_srq_out), GFP_KERNEL);\n\tif (!xrcsrq_out)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(query_xrc_srq_in, in, opcode, MLX5_CMD_OP_QUERY_XRC_SRQ);\n\tMLX5_SET(query_xrc_srq_in, in, xrc_srqn, srq->srqn);\n\n\terr = mlx5_cmd_exec_inout(dev->mdev, query_xrc_srq, in, xrcsrq_out);\n\tif (err)\n\t\tgoto out;\n\n\txrc_srqc = MLX5_ADDR_OF(query_xrc_srq_out, xrcsrq_out,\n\t\t\t\txrc_srq_context_entry);\n\tget_srqc(xrc_srqc, out);\n\tif (MLX5_GET(xrc_srqc, xrc_srqc, state) != MLX5_XRC_SRQC_STATE_GOOD)\n\t\tout->flags |= MLX5_SRQ_FLAG_ERR;\n\nout:\n\tkvfree(xrcsrq_out);\n\treturn err;\n}\n\nstatic int create_rmp_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t  struct mlx5_srq_attr *in)\n{\n\tvoid *create_out = NULL;\n\tvoid *create_in = NULL;\n\tvoid *rmpc;\n\tvoid *wq;\n\tvoid *pas;\n\tint pas_size;\n\tint outlen;\n\tint inlen;\n\tint err;\n\n\tif (in->umem) {\n\t\terr = set_srq_page_size(in, wq, log_wq_pg_sz);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tpas_size = get_pas_size(in);\n\tinlen = MLX5_ST_SZ_BYTES(create_rmp_in) + pas_size;\n\toutlen = MLX5_ST_SZ_BYTES(create_rmp_out);\n\tcreate_in = kvzalloc(inlen, GFP_KERNEL);\n\tcreate_out = kvzalloc(outlen, GFP_KERNEL);\n\tif (!create_in || !create_out) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trmpc = MLX5_ADDR_OF(create_rmp_in, create_in, ctx);\n\twq = MLX5_ADDR_OF(rmpc, rmpc, wq);\n\n\tMLX5_SET(rmpc, rmpc, state, MLX5_RMPC_STATE_RDY);\n\tMLX5_SET(create_rmp_in, create_in, uid, in->uid);\n\tpas = MLX5_ADDR_OF(rmpc, rmpc, wq.pas);\n\n\tset_wq(wq, in);\n\tif (in->umem)\n\t\tmlx5_ib_populate_pas(\n\t\t\tin->umem,\n\t\t\t1UL << (in->log_page_size + MLX5_ADAPTER_PAGE_SHIFT),\n\t\t\tpas, 0);\n\telse\n\t\tmemcpy(pas, in->pas, pas_size);\n\n\tMLX5_SET(create_rmp_in, create_in, opcode, MLX5_CMD_OP_CREATE_RMP);\n\terr = mlx5_cmd_exec(dev->mdev, create_in, inlen, create_out, outlen);\n\tif (!err) {\n\t\tsrq->srqn = MLX5_GET(create_rmp_out, create_out, rmpn);\n\t\tsrq->uid = in->uid;\n\t}\n\nout:\n\tkvfree(create_in);\n\tkvfree(create_out);\n\treturn err;\n}\n\nstatic int destroy_rmp_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq)\n{\n\tu32 in[MLX5_ST_SZ_DW(destroy_rmp_in)] = {};\n\n\tMLX5_SET(destroy_rmp_in, in, opcode, MLX5_CMD_OP_DESTROY_RMP);\n\tMLX5_SET(destroy_rmp_in, in, rmpn, srq->srqn);\n\tMLX5_SET(destroy_rmp_in, in, uid, srq->uid);\n\treturn mlx5_cmd_exec_in(dev->mdev, destroy_rmp, in);\n}\n\nstatic int arm_rmp_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t       u16 lwm)\n{\n\tvoid *out = NULL;\n\tvoid *in = NULL;\n\tvoid *rmpc;\n\tvoid *wq;\n\tvoid *bitmask;\n\tint outlen;\n\tint inlen;\n\tint err;\n\n\tinlen = MLX5_ST_SZ_BYTES(modify_rmp_in);\n\toutlen = MLX5_ST_SZ_BYTES(modify_rmp_out);\n\n\tin = kvzalloc(inlen, GFP_KERNEL);\n\tout = kvzalloc(outlen, GFP_KERNEL);\n\tif (!in || !out) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trmpc =\t  MLX5_ADDR_OF(modify_rmp_in,   in,   ctx);\n\tbitmask = MLX5_ADDR_OF(modify_rmp_in,   in,   bitmask);\n\twq   =\t  MLX5_ADDR_OF(rmpc,\t        rmpc, wq);\n\n\tMLX5_SET(modify_rmp_in, in,\t rmp_state, MLX5_RMPC_STATE_RDY);\n\tMLX5_SET(modify_rmp_in, in,\t rmpn,      srq->srqn);\n\tMLX5_SET(modify_rmp_in, in, uid, srq->uid);\n\tMLX5_SET(wq,\t\twq,\t lwm,\t    lwm);\n\tMLX5_SET(rmp_bitmask,\tbitmask, lwm,\t    1);\n\tMLX5_SET(rmpc, rmpc, state, MLX5_RMPC_STATE_RDY);\n\tMLX5_SET(modify_rmp_in, in, opcode, MLX5_CMD_OP_MODIFY_RMP);\n\n\terr = mlx5_cmd_exec_inout(dev->mdev, modify_rmp, in, out);\n\nout:\n\tkvfree(in);\n\tkvfree(out);\n\treturn err;\n}\n\nstatic int query_rmp_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t struct mlx5_srq_attr *out)\n{\n\tu32 *rmp_out = NULL;\n\tu32 *rmp_in = NULL;\n\tvoid *rmpc;\n\tint outlen;\n\tint inlen;\n\tint err;\n\n\toutlen = MLX5_ST_SZ_BYTES(query_rmp_out);\n\tinlen = MLX5_ST_SZ_BYTES(query_rmp_in);\n\n\trmp_out = kvzalloc(outlen, GFP_KERNEL);\n\trmp_in = kvzalloc(inlen, GFP_KERNEL);\n\tif (!rmp_out || !rmp_in) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tMLX5_SET(query_rmp_in, rmp_in, opcode, MLX5_CMD_OP_QUERY_RMP);\n\tMLX5_SET(query_rmp_in, rmp_in, rmpn,   srq->srqn);\n\terr = mlx5_cmd_exec_inout(dev->mdev, query_rmp, rmp_in, rmp_out);\n\tif (err)\n\t\tgoto out;\n\n\trmpc = MLX5_ADDR_OF(query_rmp_out, rmp_out, rmp_context);\n\tget_wq(MLX5_ADDR_OF(rmpc, rmpc, wq), out);\n\tif (MLX5_GET(rmpc, rmpc, state) != MLX5_RMPC_STATE_RDY)\n\t\tout->flags |= MLX5_SRQ_FLAG_ERR;\n\nout:\n\tkvfree(rmp_out);\n\tkvfree(rmp_in);\n\treturn err;\n}\n\nstatic int create_xrq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t  struct mlx5_srq_attr *in)\n{\n\tu32 create_out[MLX5_ST_SZ_DW(create_xrq_out)] = {0};\n\tvoid *create_in;\n\tvoid *xrqc;\n\tvoid *wq;\n\tvoid *pas;\n\tint pas_size;\n\tint inlen;\n\tint err;\n\n\tif (in->umem) {\n\t\terr = set_srq_page_size(in, wq, log_wq_pg_sz);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tpas_size = get_pas_size(in);\n\tinlen = MLX5_ST_SZ_BYTES(create_xrq_in) + pas_size;\n\tcreate_in = kvzalloc(inlen, GFP_KERNEL);\n\tif (!create_in)\n\t\treturn -ENOMEM;\n\n\txrqc = MLX5_ADDR_OF(create_xrq_in, create_in, xrq_context);\n\twq = MLX5_ADDR_OF(xrqc, xrqc, wq);\n\tpas = MLX5_ADDR_OF(xrqc, xrqc, wq.pas);\n\n\tset_wq(wq, in);\n\tif (in->umem)\n\t\tmlx5_ib_populate_pas(\n\t\t\tin->umem,\n\t\t\t1UL << (in->log_page_size + MLX5_ADAPTER_PAGE_SHIFT),\n\t\t\tpas, 0);\n\telse\n\t\tmemcpy(pas, in->pas, pas_size);\n\n\tif (in->type == IB_SRQT_TM) {\n\t\tMLX5_SET(xrqc, xrqc, topology, MLX5_XRQC_TOPOLOGY_TAG_MATCHING);\n\t\tif (in->flags & MLX5_SRQ_FLAG_RNDV)\n\t\t\tMLX5_SET(xrqc, xrqc, offload, MLX5_XRQC_OFFLOAD_RNDV);\n\t\tMLX5_SET(xrqc, xrqc,\n\t\t\t tag_matching_topology_context.log_matching_list_sz,\n\t\t\t in->tm_log_list_size);\n\t}\n\tMLX5_SET(xrqc, xrqc, user_index, in->user_index);\n\tMLX5_SET(xrqc, xrqc, cqn, in->cqn);\n\tMLX5_SET(create_xrq_in, create_in, opcode, MLX5_CMD_OP_CREATE_XRQ);\n\tMLX5_SET(create_xrq_in, create_in, uid, in->uid);\n\terr = mlx5_cmd_exec(dev->mdev, create_in, inlen, create_out,\n\t\t\t    sizeof(create_out));\n\tkvfree(create_in);\n\tif (!err) {\n\t\tsrq->srqn = MLX5_GET(create_xrq_out, create_out, xrqn);\n\t\tsrq->uid = in->uid;\n\t}\n\n\treturn err;\n}\n\nstatic int destroy_xrq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq)\n{\n\tu32 in[MLX5_ST_SZ_DW(destroy_xrq_in)] = {};\n\n\tMLX5_SET(destroy_xrq_in, in, opcode, MLX5_CMD_OP_DESTROY_XRQ);\n\tMLX5_SET(destroy_xrq_in, in, xrqn, srq->srqn);\n\tMLX5_SET(destroy_xrq_in, in, uid, srq->uid);\n\n\treturn mlx5_cmd_exec_in(dev->mdev, destroy_xrq, in);\n}\n\nstatic int arm_xrq_cmd(struct mlx5_ib_dev *dev,\n\t\t       struct mlx5_core_srq *srq,\n\t\t       u16 lwm)\n{\n\tu32 in[MLX5_ST_SZ_DW(arm_rq_in)] = {};\n\n\tMLX5_SET(arm_rq_in, in, opcode, MLX5_CMD_OP_ARM_RQ);\n\tMLX5_SET(arm_rq_in, in, op_mod, MLX5_ARM_RQ_IN_OP_MOD_XRQ);\n\tMLX5_SET(arm_rq_in, in, srq_number, srq->srqn);\n\tMLX5_SET(arm_rq_in, in, lwm, lwm);\n\tMLX5_SET(arm_rq_in, in, uid, srq->uid);\n\n\treturn mlx5_cmd_exec_in(dev->mdev, arm_rq, in);\n}\n\nstatic int query_xrq_cmd(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t struct mlx5_srq_attr *out)\n{\n\tu32 in[MLX5_ST_SZ_DW(query_xrq_in)] = {};\n\tu32 *xrq_out;\n\tint outlen = MLX5_ST_SZ_BYTES(query_xrq_out);\n\tvoid *xrqc;\n\tint err;\n\n\txrq_out = kvzalloc(outlen, GFP_KERNEL);\n\tif (!xrq_out)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(query_xrq_in, in, opcode, MLX5_CMD_OP_QUERY_XRQ);\n\tMLX5_SET(query_xrq_in, in, xrqn, srq->srqn);\n\n\terr = mlx5_cmd_exec_inout(dev->mdev, query_xrq, in, xrq_out);\n\tif (err)\n\t\tgoto out;\n\n\txrqc = MLX5_ADDR_OF(query_xrq_out, xrq_out, xrq_context);\n\tget_wq(MLX5_ADDR_OF(xrqc, xrqc, wq), out);\n\tif (MLX5_GET(xrqc, xrqc, state) != MLX5_XRQC_STATE_GOOD)\n\t\tout->flags |= MLX5_SRQ_FLAG_ERR;\n\tout->tm_next_tag =\n\t\tMLX5_GET(xrqc, xrqc,\n\t\t\t tag_matching_topology_context.append_next_index);\n\tout->tm_hw_phase_cnt =\n\t\tMLX5_GET(xrqc, xrqc,\n\t\t\t tag_matching_topology_context.hw_phase_cnt);\n\tout->tm_sw_phase_cnt =\n\t\tMLX5_GET(xrqc, xrqc,\n\t\t\t tag_matching_topology_context.sw_phase_cnt);\n\nout:\n\tkvfree(xrq_out);\n\treturn err;\n}\n\nstatic int create_srq_split(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\t    struct mlx5_srq_attr *in)\n{\n\tif (!dev->mdev->issi)\n\t\treturn create_srq_cmd(dev, srq, in);\n\tswitch (srq->common.res) {\n\tcase MLX5_RES_XSRQ:\n\t\treturn create_xrc_srq_cmd(dev, srq, in);\n\tcase MLX5_RES_XRQ:\n\t\treturn create_xrq_cmd(dev, srq, in);\n\tdefault:\n\t\treturn create_rmp_cmd(dev, srq, in);\n\t}\n}\n\nstatic int destroy_srq_split(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq)\n{\n\tif (!dev->mdev->issi)\n\t\treturn destroy_srq_cmd(dev, srq);\n\tswitch (srq->common.res) {\n\tcase MLX5_RES_XSRQ:\n\t\treturn destroy_xrc_srq_cmd(dev, srq);\n\tcase MLX5_RES_XRQ:\n\t\treturn destroy_xrq_cmd(dev, srq);\n\tdefault:\n\t\treturn destroy_rmp_cmd(dev, srq);\n\t}\n}\n\nint mlx5_cmd_create_srq(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t\tstruct mlx5_srq_attr *in)\n{\n\tstruct mlx5_srq_table *table = &dev->srq_table;\n\tint err;\n\n\tswitch (in->type) {\n\tcase IB_SRQT_XRC:\n\t\tsrq->common.res = MLX5_RES_XSRQ;\n\t\tbreak;\n\tcase IB_SRQT_TM:\n\t\tsrq->common.res = MLX5_RES_XRQ;\n\t\tbreak;\n\tdefault:\n\t\tsrq->common.res = MLX5_RES_SRQ;\n\t}\n\n\terr = create_srq_split(dev, srq, in);\n\tif (err)\n\t\treturn err;\n\n\trefcount_set(&srq->common.refcount, 1);\n\tinit_completion(&srq->common.free);\n\n\terr = xa_err(xa_store_irq(&table->array, srq->srqn, srq, GFP_KERNEL));\n\tif (err)\n\t\tgoto err_destroy_srq_split;\n\n\treturn 0;\n\nerr_destroy_srq_split:\n\tdestroy_srq_split(dev, srq);\n\n\treturn err;\n}\n\nint mlx5_cmd_destroy_srq(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq)\n{\n\tstruct mlx5_srq_table *table = &dev->srq_table;\n\tstruct mlx5_core_srq *tmp;\n\tint err;\n\n\t \n\ttmp = xa_cmpxchg_irq(&table->array, srq->srqn, srq, XA_ZERO_ENTRY, 0);\n\tif (WARN_ON(tmp != srq))\n\t\treturn xa_err(tmp) ?: -EINVAL;\n\n\terr = destroy_srq_split(dev, srq);\n\tif (err) {\n\t\t \n\t\txa_cmpxchg_irq(&table->array, srq->srqn, XA_ZERO_ENTRY, srq, 0);\n\t\treturn err;\n\t}\n\txa_erase_irq(&table->array, srq->srqn);\n\n\tmlx5_core_res_put(&srq->common);\n\twait_for_completion(&srq->common.free);\n\treturn 0;\n}\n\nint mlx5_cmd_query_srq(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t       struct mlx5_srq_attr *out)\n{\n\tif (!dev->mdev->issi)\n\t\treturn query_srq_cmd(dev, srq, out);\n\tswitch (srq->common.res) {\n\tcase MLX5_RES_XSRQ:\n\t\treturn query_xrc_srq_cmd(dev, srq, out);\n\tcase MLX5_RES_XRQ:\n\t\treturn query_xrq_cmd(dev, srq, out);\n\tdefault:\n\t\treturn query_rmp_cmd(dev, srq, out);\n\t}\n}\n\nint mlx5_cmd_arm_srq(struct mlx5_ib_dev *dev, struct mlx5_core_srq *srq,\n\t\t     u16 lwm, int is_srq)\n{\n\tif (!dev->mdev->issi)\n\t\treturn arm_srq_cmd(dev, srq, lwm, is_srq);\n\tswitch (srq->common.res) {\n\tcase MLX5_RES_XSRQ:\n\t\treturn arm_xrc_srq_cmd(dev, srq, lwm);\n\tcase MLX5_RES_XRQ:\n\t\treturn arm_xrq_cmd(dev, srq, lwm);\n\tdefault:\n\t\treturn arm_rmp_cmd(dev, srq, lwm);\n\t}\n}\n\nstatic int srq_event_notifier(struct notifier_block *nb,\n\t\t\t      unsigned long type, void *data)\n{\n\tstruct mlx5_srq_table *table;\n\tstruct mlx5_core_srq *srq;\n\tstruct mlx5_eqe *eqe;\n\tu32 srqn;\n\n\tif (type != MLX5_EVENT_TYPE_SRQ_CATAS_ERROR &&\n\t    type != MLX5_EVENT_TYPE_SRQ_RQ_LIMIT)\n\t\treturn NOTIFY_DONE;\n\n\ttable = container_of(nb, struct mlx5_srq_table, nb);\n\n\teqe = data;\n\tsrqn = be32_to_cpu(eqe->data.qp_srq.qp_srq_n) & 0xffffff;\n\n\txa_lock(&table->array);\n\tsrq = xa_load(&table->array, srqn);\n\tif (srq)\n\t\trefcount_inc(&srq->common.refcount);\n\txa_unlock(&table->array);\n\n\tif (!srq)\n\t\treturn NOTIFY_OK;\n\n\tsrq->event(srq, eqe->type);\n\n\tmlx5_core_res_put(&srq->common);\n\n\treturn NOTIFY_OK;\n}\n\nint mlx5_init_srq_table(struct mlx5_ib_dev *dev)\n{\n\tstruct mlx5_srq_table *table = &dev->srq_table;\n\n\tmemset(table, 0, sizeof(*table));\n\txa_init_flags(&table->array, XA_FLAGS_LOCK_IRQ);\n\n\ttable->nb.notifier_call = srq_event_notifier;\n\tmlx5_notifier_register(dev->mdev, &table->nb);\n\n\treturn 0;\n}\n\nvoid mlx5_cleanup_srq_table(struct mlx5_ib_dev *dev)\n{\n\tstruct mlx5_srq_table *table = &dev->srq_table;\n\n\tmlx5_notifier_unregister(dev->mdev, &table->nb);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}