{
  "module_name": "devx.c",
  "hash_id": "200cecaee66c901ec763f2fff6ead12c3ea533d2befc9f6587020b36c69696f6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/hw/mlx5/devx.c",
  "human_readable_source": "\n \n\n#include <rdma/ib_user_verbs.h>\n#include <rdma/ib_verbs.h>\n#include <rdma/uverbs_types.h>\n#include <rdma/uverbs_ioctl.h>\n#include <rdma/mlx5_user_ioctl_cmds.h>\n#include <rdma/mlx5_user_ioctl_verbs.h>\n#include <rdma/ib_umem.h>\n#include <rdma/uverbs_std_types.h>\n#include <linux/mlx5/driver.h>\n#include <linux/mlx5/fs.h>\n#include \"mlx5_ib.h\"\n#include \"devx.h\"\n#include \"qp.h\"\n#include <linux/xarray.h>\n\n#define UVERBS_MODULE_NAME mlx5_ib\n#include <rdma/uverbs_named_ioctl.h>\n\nstatic void dispatch_event_fd(struct list_head *fd_list, const void *data);\n\nenum devx_obj_flags {\n\tDEVX_OBJ_FLAGS_INDIRECT_MKEY = 1 << 0,\n\tDEVX_OBJ_FLAGS_DCT = 1 << 1,\n\tDEVX_OBJ_FLAGS_CQ = 1 << 2,\n};\n\nstruct devx_async_data {\n\tstruct mlx5_ib_dev *mdev;\n\tstruct list_head list;\n\tstruct devx_async_cmd_event_file *ev_file;\n\tstruct mlx5_async_work cb_work;\n\tu16 cmd_out_len;\n\t \n\tstruct mlx5_ib_uapi_devx_async_cmd_hdr hdr;\n};\n\nstruct devx_async_event_data {\n\tstruct list_head list;  \n\tstruct mlx5_ib_uapi_devx_async_event_hdr hdr;\n};\n\n \nstruct devx_event {\n\tstruct xarray object_ids;  \n\tstruct list_head unaffiliated_list;\n};\n\n \nstruct devx_obj_event {\n\tstruct rcu_head rcu;\n\tstruct list_head obj_sub_list;\n};\n\nstruct devx_event_subscription {\n\tstruct list_head file_list;  \n\tstruct list_head xa_list;  \n\tstruct list_head obj_list;  \n\tstruct list_head event_list;  \n\n\tu8 is_cleaned:1;\n\tu32 xa_key_level1;\n\tu32 xa_key_level2;\n\tstruct rcu_head\trcu;\n\tu64 cookie;\n\tstruct devx_async_event_file *ev_file;\n\tstruct eventfd_ctx *eventfd;\n};\n\nstruct devx_async_event_file {\n\tstruct ib_uobject uobj;\n\t \n\tstruct list_head subscribed_events_list;\n\tspinlock_t lock;\n\twait_queue_head_t poll_wait;\n\tstruct list_head event_list;\n\tstruct mlx5_ib_dev *dev;\n\tu8 omit_data:1;\n\tu8 is_overflow_err:1;\n\tu8 is_destroyed:1;\n};\n\nstruct devx_umem {\n\tstruct mlx5_core_dev\t\t*mdev;\n\tstruct ib_umem\t\t\t*umem;\n\tu32\t\t\t\tdinlen;\n\tu32\t\t\t\tdinbox[MLX5_ST_SZ_DW(destroy_umem_in)];\n};\n\nstruct devx_umem_reg_cmd {\n\tvoid\t\t\t\t*in;\n\tu32\t\t\t\tinlen;\n\tu32\t\t\t\tout[MLX5_ST_SZ_DW(create_umem_out)];\n};\n\nstatic struct mlx5_ib_ucontext *\ndevx_ufile2uctx(const struct uverbs_attr_bundle *attrs)\n{\n\treturn to_mucontext(ib_uverbs_get_ucontext(attrs));\n}\n\nint mlx5_ib_devx_create(struct mlx5_ib_dev *dev, bool is_user)\n{\n\tu32 in[MLX5_ST_SZ_DW(create_uctx_in)] = {};\n\tu32 out[MLX5_ST_SZ_DW(create_uctx_out)] = {};\n\tvoid *uctx;\n\tint err;\n\tu16 uid;\n\tu32 cap = 0;\n\n\t \n\tif (!MLX5_CAP_GEN(dev->mdev, log_max_uctx))\n\t\treturn -EINVAL;\n\n\tuctx = MLX5_ADDR_OF(create_uctx_in, in, uctx);\n\tif (is_user && capable(CAP_NET_RAW) &&\n\t    (MLX5_CAP_GEN(dev->mdev, uctx_cap) & MLX5_UCTX_CAP_RAW_TX))\n\t\tcap |= MLX5_UCTX_CAP_RAW_TX;\n\tif (is_user && capable(CAP_SYS_RAWIO) &&\n\t    (MLX5_CAP_GEN(dev->mdev, uctx_cap) &\n\t     MLX5_UCTX_CAP_INTERNAL_DEV_RES))\n\t\tcap |= MLX5_UCTX_CAP_INTERNAL_DEV_RES;\n\n\tMLX5_SET(create_uctx_in, in, opcode, MLX5_CMD_OP_CREATE_UCTX);\n\tMLX5_SET(uctx, uctx, cap, cap);\n\n\terr = mlx5_cmd_exec(dev->mdev, in, sizeof(in), out, sizeof(out));\n\tif (err)\n\t\treturn err;\n\n\tuid = MLX5_GET(create_uctx_out, out, uid);\n\treturn uid;\n}\n\nvoid mlx5_ib_devx_destroy(struct mlx5_ib_dev *dev, u16 uid)\n{\n\tu32 in[MLX5_ST_SZ_DW(destroy_uctx_in)] = {};\n\tu32 out[MLX5_ST_SZ_DW(destroy_uctx_out)] = {};\n\n\tMLX5_SET(destroy_uctx_in, in, opcode, MLX5_CMD_OP_DESTROY_UCTX);\n\tMLX5_SET(destroy_uctx_in, in, uid, uid);\n\n\tmlx5_cmd_exec(dev->mdev, in, sizeof(in), out, sizeof(out));\n}\n\nstatic bool is_legacy_unaffiliated_event_num(u16 event_num)\n{\n\tswitch (event_num) {\n\tcase MLX5_EVENT_TYPE_PORT_CHANGE:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic bool is_legacy_obj_event_num(u16 event_num)\n{\n\tswitch (event_num) {\n\tcase MLX5_EVENT_TYPE_PATH_MIG:\n\tcase MLX5_EVENT_TYPE_COMM_EST:\n\tcase MLX5_EVENT_TYPE_SQ_DRAINED:\n\tcase MLX5_EVENT_TYPE_SRQ_LAST_WQE:\n\tcase MLX5_EVENT_TYPE_SRQ_RQ_LIMIT:\n\tcase MLX5_EVENT_TYPE_CQ_ERROR:\n\tcase MLX5_EVENT_TYPE_WQ_CATAS_ERROR:\n\tcase MLX5_EVENT_TYPE_PATH_MIG_FAILED:\n\tcase MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR:\n\tcase MLX5_EVENT_TYPE_WQ_ACCESS_ERROR:\n\tcase MLX5_EVENT_TYPE_SRQ_CATAS_ERROR:\n\tcase MLX5_EVENT_TYPE_DCT_DRAINED:\n\tcase MLX5_EVENT_TYPE_COMP:\n\tcase MLX5_EVENT_TYPE_DCT_KEY_VIOLATION:\n\tcase MLX5_EVENT_TYPE_XRQ_ERROR:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic u16 get_legacy_obj_type(u16 opcode)\n{\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_CREATE_RQ:\n\t\treturn MLX5_EVENT_QUEUE_TYPE_RQ;\n\tcase MLX5_CMD_OP_CREATE_QP:\n\t\treturn MLX5_EVENT_QUEUE_TYPE_QP;\n\tcase MLX5_CMD_OP_CREATE_SQ:\n\t\treturn MLX5_EVENT_QUEUE_TYPE_SQ;\n\tcase MLX5_CMD_OP_CREATE_DCT:\n\t\treturn MLX5_EVENT_QUEUE_TYPE_DCT;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic u16 get_dec_obj_type(struct devx_obj *obj, u16 event_num)\n{\n\tu16 opcode;\n\n\topcode = (obj->obj_id >> 32) & 0xffff;\n\n\tif (is_legacy_obj_event_num(event_num))\n\t\treturn get_legacy_obj_type(opcode);\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_CREATE_GENERAL_OBJECT:\n\t\treturn (obj->obj_id >> 48);\n\tcase MLX5_CMD_OP_CREATE_RQ:\n\t\treturn MLX5_OBJ_TYPE_RQ;\n\tcase MLX5_CMD_OP_CREATE_QP:\n\t\treturn MLX5_OBJ_TYPE_QP;\n\tcase MLX5_CMD_OP_CREATE_SQ:\n\t\treturn MLX5_OBJ_TYPE_SQ;\n\tcase MLX5_CMD_OP_CREATE_DCT:\n\t\treturn MLX5_OBJ_TYPE_DCT;\n\tcase MLX5_CMD_OP_CREATE_TIR:\n\t\treturn MLX5_OBJ_TYPE_TIR;\n\tcase MLX5_CMD_OP_CREATE_TIS:\n\t\treturn MLX5_OBJ_TYPE_TIS;\n\tcase MLX5_CMD_OP_CREATE_PSV:\n\t\treturn MLX5_OBJ_TYPE_PSV;\n\tcase MLX5_OBJ_TYPE_MKEY:\n\t\treturn MLX5_OBJ_TYPE_MKEY;\n\tcase MLX5_CMD_OP_CREATE_RMP:\n\t\treturn MLX5_OBJ_TYPE_RMP;\n\tcase MLX5_CMD_OP_CREATE_XRC_SRQ:\n\t\treturn MLX5_OBJ_TYPE_XRC_SRQ;\n\tcase MLX5_CMD_OP_CREATE_XRQ:\n\t\treturn MLX5_OBJ_TYPE_XRQ;\n\tcase MLX5_CMD_OP_CREATE_RQT:\n\t\treturn MLX5_OBJ_TYPE_RQT;\n\tcase MLX5_CMD_OP_ALLOC_FLOW_COUNTER:\n\t\treturn MLX5_OBJ_TYPE_FLOW_COUNTER;\n\tcase MLX5_CMD_OP_CREATE_CQ:\n\t\treturn MLX5_OBJ_TYPE_CQ;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic u16 get_event_obj_type(unsigned long event_type, struct mlx5_eqe *eqe)\n{\n\tswitch (event_type) {\n\tcase MLX5_EVENT_TYPE_WQ_CATAS_ERROR:\n\tcase MLX5_EVENT_TYPE_WQ_ACCESS_ERROR:\n\tcase MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR:\n\tcase MLX5_EVENT_TYPE_SRQ_LAST_WQE:\n\tcase MLX5_EVENT_TYPE_PATH_MIG:\n\tcase MLX5_EVENT_TYPE_PATH_MIG_FAILED:\n\tcase MLX5_EVENT_TYPE_COMM_EST:\n\tcase MLX5_EVENT_TYPE_SQ_DRAINED:\n\tcase MLX5_EVENT_TYPE_SRQ_RQ_LIMIT:\n\tcase MLX5_EVENT_TYPE_SRQ_CATAS_ERROR:\n\t\treturn eqe->data.qp_srq.type;\n\tcase MLX5_EVENT_TYPE_CQ_ERROR:\n\tcase MLX5_EVENT_TYPE_XRQ_ERROR:\n\t\treturn 0;\n\tcase MLX5_EVENT_TYPE_DCT_DRAINED:\n\tcase MLX5_EVENT_TYPE_DCT_KEY_VIOLATION:\n\t\treturn MLX5_EVENT_QUEUE_TYPE_DCT;\n\tdefault:\n\t\treturn MLX5_GET(affiliated_event_header, &eqe->data, obj_type);\n\t}\n}\n\nstatic u32 get_dec_obj_id(u64 obj_id)\n{\n\treturn (obj_id & 0xffffffff);\n}\n\n \nstatic u64 get_enc_obj_id(u32 opcode, u32 obj_id)\n{\n\treturn ((u64)opcode << 32) | obj_id;\n}\n\nstatic u32 devx_get_created_obj_id(const void *in, const void *out, u16 opcode)\n{\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_CREATE_GENERAL_OBJECT:\n\t\treturn MLX5_GET(general_obj_out_cmd_hdr, out, obj_id);\n\tcase MLX5_CMD_OP_CREATE_UMEM:\n\t\treturn MLX5_GET(create_umem_out, out, umem_id);\n\tcase MLX5_CMD_OP_CREATE_MKEY:\n\t\treturn MLX5_GET(create_mkey_out, out, mkey_index);\n\tcase MLX5_CMD_OP_CREATE_CQ:\n\t\treturn MLX5_GET(create_cq_out, out, cqn);\n\tcase MLX5_CMD_OP_ALLOC_PD:\n\t\treturn MLX5_GET(alloc_pd_out, out, pd);\n\tcase MLX5_CMD_OP_ALLOC_TRANSPORT_DOMAIN:\n\t\treturn MLX5_GET(alloc_transport_domain_out, out,\n\t\t\t\ttransport_domain);\n\tcase MLX5_CMD_OP_CREATE_RMP:\n\t\treturn MLX5_GET(create_rmp_out, out, rmpn);\n\tcase MLX5_CMD_OP_CREATE_SQ:\n\t\treturn MLX5_GET(create_sq_out, out, sqn);\n\tcase MLX5_CMD_OP_CREATE_RQ:\n\t\treturn MLX5_GET(create_rq_out, out, rqn);\n\tcase MLX5_CMD_OP_CREATE_RQT:\n\t\treturn MLX5_GET(create_rqt_out, out, rqtn);\n\tcase MLX5_CMD_OP_CREATE_TIR:\n\t\treturn MLX5_GET(create_tir_out, out, tirn);\n\tcase MLX5_CMD_OP_CREATE_TIS:\n\t\treturn MLX5_GET(create_tis_out, out, tisn);\n\tcase MLX5_CMD_OP_ALLOC_Q_COUNTER:\n\t\treturn MLX5_GET(alloc_q_counter_out, out, counter_set_id);\n\tcase MLX5_CMD_OP_CREATE_FLOW_TABLE:\n\t\treturn MLX5_GET(create_flow_table_out, out, table_id);\n\tcase MLX5_CMD_OP_CREATE_FLOW_GROUP:\n\t\treturn MLX5_GET(create_flow_group_out, out, group_id);\n\tcase MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY:\n\t\treturn MLX5_GET(set_fte_in, in, flow_index);\n\tcase MLX5_CMD_OP_ALLOC_FLOW_COUNTER:\n\t\treturn MLX5_GET(alloc_flow_counter_out, out, flow_counter_id);\n\tcase MLX5_CMD_OP_ALLOC_PACKET_REFORMAT_CONTEXT:\n\t\treturn MLX5_GET(alloc_packet_reformat_context_out, out,\n\t\t\t\tpacket_reformat_id);\n\tcase MLX5_CMD_OP_ALLOC_MODIFY_HEADER_CONTEXT:\n\t\treturn MLX5_GET(alloc_modify_header_context_out, out,\n\t\t\t\tmodify_header_id);\n\tcase MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT:\n\t\treturn MLX5_GET(create_scheduling_element_out, out,\n\t\t\t\tscheduling_element_id);\n\tcase MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT:\n\t\treturn MLX5_GET(add_vxlan_udp_dport_in, in, vxlan_udp_port);\n\tcase MLX5_CMD_OP_SET_L2_TABLE_ENTRY:\n\t\treturn MLX5_GET(set_l2_table_entry_in, in, table_index);\n\tcase MLX5_CMD_OP_CREATE_QP:\n\t\treturn MLX5_GET(create_qp_out, out, qpn);\n\tcase MLX5_CMD_OP_CREATE_SRQ:\n\t\treturn MLX5_GET(create_srq_out, out, srqn);\n\tcase MLX5_CMD_OP_CREATE_XRC_SRQ:\n\t\treturn MLX5_GET(create_xrc_srq_out, out, xrc_srqn);\n\tcase MLX5_CMD_OP_CREATE_DCT:\n\t\treturn MLX5_GET(create_dct_out, out, dctn);\n\tcase MLX5_CMD_OP_CREATE_XRQ:\n\t\treturn MLX5_GET(create_xrq_out, out, xrqn);\n\tcase MLX5_CMD_OP_ATTACH_TO_MCG:\n\t\treturn MLX5_GET(attach_to_mcg_in, in, qpn);\n\tcase MLX5_CMD_OP_ALLOC_XRCD:\n\t\treturn MLX5_GET(alloc_xrcd_out, out, xrcd);\n\tcase MLX5_CMD_OP_CREATE_PSV:\n\t\treturn MLX5_GET(create_psv_out, out, psv0_index);\n\tdefault:\n\t\t \n\t\tWARN_ON(true);\n\t\treturn 0;\n\t}\n}\n\nstatic u64 devx_get_obj_id(const void *in)\n{\n\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\tu64 obj_id;\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_MODIFY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_QUERY_GENERAL_OBJECT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_GENERAL_OBJECT |\n\t\t\t\t\tMLX5_GET(general_obj_in_cmd_hdr, in,\n\t\t\t\t\t\t obj_type) << 16,\n\t\t\t\t\tMLX5_GET(general_obj_in_cmd_hdr, in,\n\t\t\t\t\t\t obj_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_MKEY:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_MKEY,\n\t\t\t\t\tMLX5_GET(query_mkey_in, in,\n\t\t\t\t\t\t mkey_index));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_CQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_CQ,\n\t\t\t\t\tMLX5_GET(query_cq_in, in, cqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_CQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_CQ,\n\t\t\t\t\tMLX5_GET(modify_cq_in, in, cqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_SQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_SQ,\n\t\t\t\t\tMLX5_GET(query_sq_in, in, sqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_SQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_SQ,\n\t\t\t\t\tMLX5_GET(modify_sq_in, in, sqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_RQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_RQ,\n\t\t\t\t\tMLX5_GET(query_rq_in, in, rqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_RQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_RQ,\n\t\t\t\t\tMLX5_GET(modify_rq_in, in, rqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_RMP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_RMP,\n\t\t\t\t\tMLX5_GET(query_rmp_in, in, rmpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_RMP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_RMP,\n\t\t\t\t\tMLX5_GET(modify_rmp_in, in, rmpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_RQT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_RQT,\n\t\t\t\t\tMLX5_GET(query_rqt_in, in, rqtn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_RQT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_RQT,\n\t\t\t\t\tMLX5_GET(modify_rqt_in, in, rqtn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_TIR:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_TIR,\n\t\t\t\t\tMLX5_GET(query_tir_in, in, tirn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_TIR:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_TIR,\n\t\t\t\t\tMLX5_GET(modify_tir_in, in, tirn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_TIS:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_TIS,\n\t\t\t\t\tMLX5_GET(query_tis_in, in, tisn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_TIS:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_TIS,\n\t\t\t\t\tMLX5_GET(modify_tis_in, in, tisn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_FLOW_TABLE:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_FLOW_TABLE,\n\t\t\t\t\tMLX5_GET(query_flow_table_in, in,\n\t\t\t\t\t\t table_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_FLOW_TABLE:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_FLOW_TABLE,\n\t\t\t\t\tMLX5_GET(modify_flow_table_in, in,\n\t\t\t\t\t\t table_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_FLOW_GROUP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_FLOW_GROUP,\n\t\t\t\t\tMLX5_GET(query_flow_group_in, in,\n\t\t\t\t\t\t group_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_FLOW_TABLE_ENTRY:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY,\n\t\t\t\t\tMLX5_GET(query_fte_in, in,\n\t\t\t\t\t\t flow_index));\n\t\tbreak;\n\tcase MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY,\n\t\t\t\t\tMLX5_GET(set_fte_in, in, flow_index));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_Q_COUNTER:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_ALLOC_Q_COUNTER,\n\t\t\t\t\tMLX5_GET(query_q_counter_in, in,\n\t\t\t\t\t\t counter_set_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_FLOW_COUNTER:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_ALLOC_FLOW_COUNTER,\n\t\t\t\t\tMLX5_GET(query_flow_counter_in, in,\n\t\t\t\t\t\t flow_counter_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_MODIFY_HEADER_CONTEXT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_ALLOC_MODIFY_HEADER_CONTEXT,\n\t\t\t\t\tMLX5_GET(query_modify_header_context_in,\n\t\t\t\t\t\t in, modify_header_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_SCHEDULING_ELEMENT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT,\n\t\t\t\t\tMLX5_GET(query_scheduling_element_in,\n\t\t\t\t\t\t in, scheduling_element_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_MODIFY_SCHEDULING_ELEMENT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT,\n\t\t\t\t\tMLX5_GET(modify_scheduling_element_in,\n\t\t\t\t\t\t in, scheduling_element_id));\n\t\tbreak;\n\tcase MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT,\n\t\t\t\t\tMLX5_GET(add_vxlan_udp_dport_in, in,\n\t\t\t\t\t\t vxlan_udp_port));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_L2_TABLE_ENTRY:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_SET_L2_TABLE_ENTRY,\n\t\t\t\t\tMLX5_GET(query_l2_table_entry_in, in,\n\t\t\t\t\t\t table_index));\n\t\tbreak;\n\tcase MLX5_CMD_OP_SET_L2_TABLE_ENTRY:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_SET_L2_TABLE_ENTRY,\n\t\t\t\t\tMLX5_GET(set_l2_table_entry_in, in,\n\t\t\t\t\t\t table_index));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(query_qp_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_RST2INIT_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(rst2init_qp_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_INIT2INIT_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(init2init_qp_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_INIT2RTR_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(init2rtr_qp_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_RTR2RTS_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(rtr2rts_qp_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_RTS2RTS_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(rts2rts_qp_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_SQERR2RTS_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(sqerr2rts_qp_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_2ERR_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(qp_2err_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_2RST_QP:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t\tMLX5_GET(qp_2rst_in, in, qpn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_DCT:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_DCT,\n\t\t\t\t\tMLX5_GET(query_dct_in, in, dctn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_XRQ:\n\tcase MLX5_CMD_OP_QUERY_XRQ_DC_PARAMS_ENTRY:\n\tcase MLX5_CMD_OP_QUERY_XRQ_ERROR_PARAMS:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_XRQ,\n\t\t\t\t\tMLX5_GET(query_xrq_in, in, xrqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_XRC_SRQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_XRC_SRQ,\n\t\t\t\t\tMLX5_GET(query_xrc_srq_in, in,\n\t\t\t\t\t\t xrc_srqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_ARM_XRC_SRQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_XRC_SRQ,\n\t\t\t\t\tMLX5_GET(arm_xrc_srq_in, in, xrc_srqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_SRQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_SRQ,\n\t\t\t\t\tMLX5_GET(query_srq_in, in, srqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_ARM_RQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_RQ,\n\t\t\t\t\tMLX5_GET(arm_rq_in, in, srq_number));\n\t\tbreak;\n\tcase MLX5_CMD_OP_ARM_DCT_FOR_KEY_VIOLATION:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_DCT,\n\t\t\t\t\tMLX5_GET(drain_dct_in, in, dctn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_ARM_XRQ:\n\tcase MLX5_CMD_OP_SET_XRQ_DC_PARAMS_ENTRY:\n\tcase MLX5_CMD_OP_RELEASE_XRQ_ERROR:\n\tcase MLX5_CMD_OP_MODIFY_XRQ:\n\t\tobj_id = get_enc_obj_id(MLX5_CMD_OP_CREATE_XRQ,\n\t\t\t\t\tMLX5_GET(arm_xrq_in, in, xrqn));\n\t\tbreak;\n\tcase MLX5_CMD_OP_QUERY_PACKET_REFORMAT_CONTEXT:\n\t\tobj_id = get_enc_obj_id\n\t\t\t\t(MLX5_CMD_OP_ALLOC_PACKET_REFORMAT_CONTEXT,\n\t\t\t\t MLX5_GET(query_packet_reformat_context_in,\n\t\t\t\t\t  in, packet_reformat_id));\n\t\tbreak;\n\tdefault:\n\t\tobj_id = 0;\n\t}\n\n\treturn obj_id;\n}\n\nstatic bool devx_is_valid_obj_id(struct uverbs_attr_bundle *attrs,\n\t\t\t\t struct ib_uobject *uobj, const void *in)\n{\n\tstruct mlx5_ib_dev *dev = mlx5_udata_to_mdev(&attrs->driver_udata);\n\tu64 obj_id = devx_get_obj_id(in);\n\n\tif (!obj_id)\n\t\treturn false;\n\n\tswitch (uobj_get_object_id(uobj)) {\n\tcase UVERBS_OBJECT_CQ:\n\t\treturn get_enc_obj_id(MLX5_CMD_OP_CREATE_CQ,\n\t\t\t\t      to_mcq(uobj->object)->mcq.cqn) ==\n\t\t\t\t      obj_id;\n\n\tcase UVERBS_OBJECT_SRQ:\n\t{\n\t\tstruct mlx5_core_srq *srq = &(to_msrq(uobj->object)->msrq);\n\t\tu16 opcode;\n\n\t\tswitch (srq->common.res) {\n\t\tcase MLX5_RES_XSRQ:\n\t\t\topcode = MLX5_CMD_OP_CREATE_XRC_SRQ;\n\t\t\tbreak;\n\t\tcase MLX5_RES_XRQ:\n\t\t\topcode = MLX5_CMD_OP_CREATE_XRQ;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (!dev->mdev->issi)\n\t\t\t\topcode = MLX5_CMD_OP_CREATE_SRQ;\n\t\t\telse\n\t\t\t\topcode = MLX5_CMD_OP_CREATE_RMP;\n\t\t}\n\n\t\treturn get_enc_obj_id(opcode,\n\t\t\t\t      to_msrq(uobj->object)->msrq.srqn) ==\n\t\t\t\t      obj_id;\n\t}\n\n\tcase UVERBS_OBJECT_QP:\n\t{\n\t\tstruct mlx5_ib_qp *qp = to_mqp(uobj->object);\n\n\t\tif (qp->type == IB_QPT_RAW_PACKET ||\n\t\t    (qp->flags & IB_QP_CREATE_SOURCE_QPN)) {\n\t\t\tstruct mlx5_ib_raw_packet_qp *raw_packet_qp =\n\t\t\t\t\t\t\t &qp->raw_packet_qp;\n\t\t\tstruct mlx5_ib_rq *rq = &raw_packet_qp->rq;\n\t\t\tstruct mlx5_ib_sq *sq = &raw_packet_qp->sq;\n\n\t\t\treturn (get_enc_obj_id(MLX5_CMD_OP_CREATE_RQ,\n\t\t\t\t\t       rq->base.mqp.qpn) == obj_id ||\n\t\t\t\tget_enc_obj_id(MLX5_CMD_OP_CREATE_SQ,\n\t\t\t\t\t       sq->base.mqp.qpn) == obj_id ||\n\t\t\t\tget_enc_obj_id(MLX5_CMD_OP_CREATE_TIR,\n\t\t\t\t\t       rq->tirn) == obj_id ||\n\t\t\t\tget_enc_obj_id(MLX5_CMD_OP_CREATE_TIS,\n\t\t\t\t\t       sq->tisn) == obj_id);\n\t\t}\n\n\t\tif (qp->type == MLX5_IB_QPT_DCT)\n\t\t\treturn get_enc_obj_id(MLX5_CMD_OP_CREATE_DCT,\n\t\t\t\t\t      qp->dct.mdct.mqp.qpn) == obj_id;\n\t\treturn get_enc_obj_id(MLX5_CMD_OP_CREATE_QP,\n\t\t\t\t      qp->ibqp.qp_num) == obj_id;\n\t}\n\n\tcase UVERBS_OBJECT_WQ:\n\t\treturn get_enc_obj_id(MLX5_CMD_OP_CREATE_RQ,\n\t\t\t\t      to_mrwq(uobj->object)->core_qp.qpn) ==\n\t\t\t\t      obj_id;\n\n\tcase UVERBS_OBJECT_RWQ_IND_TBL:\n\t\treturn get_enc_obj_id(MLX5_CMD_OP_CREATE_RQT,\n\t\t\t\t      to_mrwq_ind_table(uobj->object)->rqtn) ==\n\t\t\t\t      obj_id;\n\n\tcase MLX5_IB_OBJECT_DEVX_OBJ:\n\t{\n\t\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\t\tstruct devx_obj *devx_uobj = uobj->object;\n\n\t\tif (opcode == MLX5_CMD_OP_QUERY_FLOW_COUNTER &&\n\t\t    devx_uobj->flow_counter_bulk_size) {\n\t\t\tu64 end;\n\n\t\t\tend = devx_uobj->obj_id +\n\t\t\t\tdevx_uobj->flow_counter_bulk_size;\n\t\t\treturn devx_uobj->obj_id <= obj_id && end > obj_id;\n\t\t}\n\n\t\treturn devx_uobj->obj_id == obj_id;\n\t}\n\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic void devx_set_umem_valid(const void *in)\n{\n\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_CREATE_MKEY:\n\t\tMLX5_SET(create_mkey_in, in, mkey_umem_valid, 1);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_CQ:\n\t{\n\t\tvoid *cqc;\n\n\t\tMLX5_SET(create_cq_in, in, cq_umem_valid, 1);\n\t\tcqc = MLX5_ADDR_OF(create_cq_in, in, cq_context);\n\t\tMLX5_SET(cqc, cqc, dbr_umem_valid, 1);\n\t\tbreak;\n\t}\n\tcase MLX5_CMD_OP_CREATE_QP:\n\t{\n\t\tvoid *qpc;\n\n\t\tqpc = MLX5_ADDR_OF(create_qp_in, in, qpc);\n\t\tMLX5_SET(qpc, qpc, dbr_umem_valid, 1);\n\t\tMLX5_SET(create_qp_in, in, wq_umem_valid, 1);\n\t\tbreak;\n\t}\n\n\tcase MLX5_CMD_OP_CREATE_RQ:\n\t{\n\t\tvoid *rqc, *wq;\n\n\t\trqc = MLX5_ADDR_OF(create_rq_in, in, ctx);\n\t\twq  = MLX5_ADDR_OF(rqc, rqc, wq);\n\t\tMLX5_SET(wq, wq, dbr_umem_valid, 1);\n\t\tMLX5_SET(wq, wq, wq_umem_valid, 1);\n\t\tbreak;\n\t}\n\n\tcase MLX5_CMD_OP_CREATE_SQ:\n\t{\n\t\tvoid *sqc, *wq;\n\n\t\tsqc = MLX5_ADDR_OF(create_sq_in, in, ctx);\n\t\twq = MLX5_ADDR_OF(sqc, sqc, wq);\n\t\tMLX5_SET(wq, wq, dbr_umem_valid, 1);\n\t\tMLX5_SET(wq, wq, wq_umem_valid, 1);\n\t\tbreak;\n\t}\n\n\tcase MLX5_CMD_OP_MODIFY_CQ:\n\t\tMLX5_SET(modify_cq_in, in, cq_umem_valid, 1);\n\t\tbreak;\n\n\tcase MLX5_CMD_OP_CREATE_RMP:\n\t{\n\t\tvoid *rmpc, *wq;\n\n\t\trmpc = MLX5_ADDR_OF(create_rmp_in, in, ctx);\n\t\twq = MLX5_ADDR_OF(rmpc, rmpc, wq);\n\t\tMLX5_SET(wq, wq, dbr_umem_valid, 1);\n\t\tMLX5_SET(wq, wq, wq_umem_valid, 1);\n\t\tbreak;\n\t}\n\n\tcase MLX5_CMD_OP_CREATE_XRQ:\n\t{\n\t\tvoid *xrqc, *wq;\n\n\t\txrqc = MLX5_ADDR_OF(create_xrq_in, in, xrq_context);\n\t\twq = MLX5_ADDR_OF(xrqc, xrqc, wq);\n\t\tMLX5_SET(wq, wq, dbr_umem_valid, 1);\n\t\tMLX5_SET(wq, wq, wq_umem_valid, 1);\n\t\tbreak;\n\t}\n\n\tcase MLX5_CMD_OP_CREATE_XRC_SRQ:\n\t{\n\t\tvoid *xrc_srqc;\n\n\t\tMLX5_SET(create_xrc_srq_in, in, xrc_srq_umem_valid, 1);\n\t\txrc_srqc = MLX5_ADDR_OF(create_xrc_srq_in, in,\n\t\t\t\t\txrc_srq_context_entry);\n\t\tMLX5_SET(xrc_srqc, xrc_srqc, dbr_umem_valid, 1);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\treturn;\n\t}\n}\n\nstatic bool devx_is_obj_create_cmd(const void *in, u16 *opcode)\n{\n\t*opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\n\tswitch (*opcode) {\n\tcase MLX5_CMD_OP_CREATE_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_CREATE_MKEY:\n\tcase MLX5_CMD_OP_CREATE_CQ:\n\tcase MLX5_CMD_OP_ALLOC_PD:\n\tcase MLX5_CMD_OP_ALLOC_TRANSPORT_DOMAIN:\n\tcase MLX5_CMD_OP_CREATE_RMP:\n\tcase MLX5_CMD_OP_CREATE_SQ:\n\tcase MLX5_CMD_OP_CREATE_RQ:\n\tcase MLX5_CMD_OP_CREATE_RQT:\n\tcase MLX5_CMD_OP_CREATE_TIR:\n\tcase MLX5_CMD_OP_CREATE_TIS:\n\tcase MLX5_CMD_OP_ALLOC_Q_COUNTER:\n\tcase MLX5_CMD_OP_CREATE_FLOW_TABLE:\n\tcase MLX5_CMD_OP_CREATE_FLOW_GROUP:\n\tcase MLX5_CMD_OP_ALLOC_FLOW_COUNTER:\n\tcase MLX5_CMD_OP_ALLOC_PACKET_REFORMAT_CONTEXT:\n\tcase MLX5_CMD_OP_ALLOC_MODIFY_HEADER_CONTEXT:\n\tcase MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT:\n\tcase MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT:\n\tcase MLX5_CMD_OP_SET_L2_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_CREATE_QP:\n\tcase MLX5_CMD_OP_CREATE_SRQ:\n\tcase MLX5_CMD_OP_CREATE_XRC_SRQ:\n\tcase MLX5_CMD_OP_CREATE_DCT:\n\tcase MLX5_CMD_OP_CREATE_XRQ:\n\tcase MLX5_CMD_OP_ATTACH_TO_MCG:\n\tcase MLX5_CMD_OP_ALLOC_XRCD:\n\t\treturn true;\n\tcase MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY:\n\t{\n\t\tu16 op_mod = MLX5_GET(set_fte_in, in, op_mod);\n\t\tif (op_mod == 0)\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\tcase MLX5_CMD_OP_CREATE_PSV:\n\t{\n\t\tu8 num_psv = MLX5_GET(create_psv_in, in, num_psv);\n\n\t\tif (num_psv == 1)\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic bool devx_is_obj_modify_cmd(const void *in)\n{\n\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_MODIFY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_MODIFY_CQ:\n\tcase MLX5_CMD_OP_MODIFY_RMP:\n\tcase MLX5_CMD_OP_MODIFY_SQ:\n\tcase MLX5_CMD_OP_MODIFY_RQ:\n\tcase MLX5_CMD_OP_MODIFY_RQT:\n\tcase MLX5_CMD_OP_MODIFY_TIR:\n\tcase MLX5_CMD_OP_MODIFY_TIS:\n\tcase MLX5_CMD_OP_MODIFY_FLOW_TABLE:\n\tcase MLX5_CMD_OP_MODIFY_SCHEDULING_ELEMENT:\n\tcase MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT:\n\tcase MLX5_CMD_OP_SET_L2_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_RST2INIT_QP:\n\tcase MLX5_CMD_OP_INIT2RTR_QP:\n\tcase MLX5_CMD_OP_INIT2INIT_QP:\n\tcase MLX5_CMD_OP_RTR2RTS_QP:\n\tcase MLX5_CMD_OP_RTS2RTS_QP:\n\tcase MLX5_CMD_OP_SQERR2RTS_QP:\n\tcase MLX5_CMD_OP_2ERR_QP:\n\tcase MLX5_CMD_OP_2RST_QP:\n\tcase MLX5_CMD_OP_ARM_XRC_SRQ:\n\tcase MLX5_CMD_OP_ARM_RQ:\n\tcase MLX5_CMD_OP_ARM_DCT_FOR_KEY_VIOLATION:\n\tcase MLX5_CMD_OP_ARM_XRQ:\n\tcase MLX5_CMD_OP_SET_XRQ_DC_PARAMS_ENTRY:\n\tcase MLX5_CMD_OP_RELEASE_XRQ_ERROR:\n\tcase MLX5_CMD_OP_MODIFY_XRQ:\n\t\treturn true;\n\tcase MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY:\n\t{\n\t\tu16 op_mod = MLX5_GET(set_fte_in, in, op_mod);\n\n\t\tif (op_mod == 1)\n\t\t\treturn true;\n\t\treturn false;\n\t}\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic bool devx_is_obj_query_cmd(const void *in)\n{\n\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_QUERY_GENERAL_OBJECT:\n\tcase MLX5_CMD_OP_QUERY_MKEY:\n\tcase MLX5_CMD_OP_QUERY_CQ:\n\tcase MLX5_CMD_OP_QUERY_RMP:\n\tcase MLX5_CMD_OP_QUERY_SQ:\n\tcase MLX5_CMD_OP_QUERY_RQ:\n\tcase MLX5_CMD_OP_QUERY_RQT:\n\tcase MLX5_CMD_OP_QUERY_TIR:\n\tcase MLX5_CMD_OP_QUERY_TIS:\n\tcase MLX5_CMD_OP_QUERY_Q_COUNTER:\n\tcase MLX5_CMD_OP_QUERY_FLOW_TABLE:\n\tcase MLX5_CMD_OP_QUERY_FLOW_GROUP:\n\tcase MLX5_CMD_OP_QUERY_FLOW_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_QUERY_FLOW_COUNTER:\n\tcase MLX5_CMD_OP_QUERY_MODIFY_HEADER_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_SCHEDULING_ELEMENT:\n\tcase MLX5_CMD_OP_QUERY_L2_TABLE_ENTRY:\n\tcase MLX5_CMD_OP_QUERY_QP:\n\tcase MLX5_CMD_OP_QUERY_SRQ:\n\tcase MLX5_CMD_OP_QUERY_XRC_SRQ:\n\tcase MLX5_CMD_OP_QUERY_DCT:\n\tcase MLX5_CMD_OP_QUERY_XRQ:\n\tcase MLX5_CMD_OP_QUERY_XRQ_DC_PARAMS_ENTRY:\n\tcase MLX5_CMD_OP_QUERY_XRQ_ERROR_PARAMS:\n\tcase MLX5_CMD_OP_QUERY_PACKET_REFORMAT_CONTEXT:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic bool devx_is_whitelist_cmd(void *in)\n{\n\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_QUERY_HCA_CAP:\n\tcase MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_ESW_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_ESW_FUNCTIONS:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic int devx_get_uid(struct mlx5_ib_ucontext *c, void *cmd_in)\n{\n\tif (devx_is_whitelist_cmd(cmd_in)) {\n\t\tstruct mlx5_ib_dev *dev;\n\n\t\tif (c->devx_uid)\n\t\t\treturn c->devx_uid;\n\n\t\tdev = to_mdev(c->ibucontext.device);\n\t\tif (dev->devx_whitelist_uid)\n\t\t\treturn dev->devx_whitelist_uid;\n\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif (!c->devx_uid)\n\t\treturn -EINVAL;\n\n\treturn c->devx_uid;\n}\n\nstatic bool devx_is_general_cmd(void *in, struct mlx5_ib_dev *dev)\n{\n\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\n\t \n\tif ((MLX5_CAP_GEN_64(dev->mdev, vhca_tunnel_commands) &&\n\t     MLX5_GET(general_obj_in_cmd_hdr, in, vhca_tunnel_id)) ||\n\t    (opcode >= MLX5_CMD_OP_GENERAL_START &&\n\t     opcode < MLX5_CMD_OP_GENERAL_END))\n\t\treturn true;\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_QUERY_HCA_CAP:\n\tcase MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_ESW_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_VPORT_STATE:\n\tcase MLX5_CMD_OP_QUERY_ADAPTER:\n\tcase MLX5_CMD_OP_QUERY_ISSI:\n\tcase MLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT:\n\tcase MLX5_CMD_OP_QUERY_ROCE_ADDRESS:\n\tcase MLX5_CMD_OP_QUERY_VNIC_ENV:\n\tcase MLX5_CMD_OP_QUERY_VPORT_COUNTER:\n\tcase MLX5_CMD_OP_GET_DROPPED_PACKET_LOG:\n\tcase MLX5_CMD_OP_NOP:\n\tcase MLX5_CMD_OP_QUERY_CONG_STATUS:\n\tcase MLX5_CMD_OP_QUERY_CONG_PARAMS:\n\tcase MLX5_CMD_OP_QUERY_CONG_STATISTICS:\n\tcase MLX5_CMD_OP_QUERY_LAG:\n\tcase MLX5_CMD_OP_QUERY_ESW_FUNCTIONS:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_QUERY_EQN)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tstruct mlx5_ib_ucontext *c;\n\tstruct mlx5_ib_dev *dev;\n\tint user_vector;\n\tint dev_eqn;\n\tint err;\n\n\tif (uverbs_copy_from(&user_vector, attrs,\n\t\t\t     MLX5_IB_ATTR_DEVX_QUERY_EQN_USER_VEC))\n\t\treturn -EFAULT;\n\n\tc = devx_ufile2uctx(attrs);\n\tif (IS_ERR(c))\n\t\treturn PTR_ERR(c);\n\tdev = to_mdev(c->ibucontext.device);\n\n\terr = mlx5_comp_eqn_get(dev->mdev, user_vector, &dev_eqn);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_QUERY_EQN_DEV_EQN,\n\t\t\t   &dev_eqn, sizeof(dev_eqn)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\n \nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_QUERY_UAR)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tstruct mlx5_ib_ucontext *c;\n\tstruct mlx5_ib_dev *dev;\n\tu32 user_idx;\n\ts32 dev_idx;\n\n\tc = devx_ufile2uctx(attrs);\n\tif (IS_ERR(c))\n\t\treturn PTR_ERR(c);\n\tdev = to_mdev(c->ibucontext.device);\n\n\tif (uverbs_copy_from(&user_idx, attrs,\n\t\t\t     MLX5_IB_ATTR_DEVX_QUERY_UAR_USER_IDX))\n\t\treturn -EFAULT;\n\n\tdev_idx = bfregn_to_uar_index(dev, &c->bfregi, user_idx, true);\n\tif (dev_idx < 0)\n\t\treturn dev_idx;\n\n\tif (uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_QUERY_UAR_DEV_IDX,\n\t\t\t   &dev_idx, sizeof(dev_idx)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_OTHER)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tstruct mlx5_ib_ucontext *c;\n\tstruct mlx5_ib_dev *dev;\n\tvoid *cmd_in = uverbs_attr_get_alloced_ptr(\n\t\tattrs, MLX5_IB_ATTR_DEVX_OTHER_CMD_IN);\n\tint cmd_out_len = uverbs_attr_get_len(attrs,\n\t\t\t\t\tMLX5_IB_ATTR_DEVX_OTHER_CMD_OUT);\n\tvoid *cmd_out;\n\tint err, err2;\n\tint uid;\n\n\tc = devx_ufile2uctx(attrs);\n\tif (IS_ERR(c))\n\t\treturn PTR_ERR(c);\n\tdev = to_mdev(c->ibucontext.device);\n\n\tuid = devx_get_uid(c, cmd_in);\n\tif (uid < 0)\n\t\treturn uid;\n\n\t \n\tif (!devx_is_general_cmd(cmd_in, dev))\n\t\treturn -EINVAL;\n\n\tcmd_out = uverbs_zalloc(attrs, cmd_out_len);\n\tif (IS_ERR(cmd_out))\n\t\treturn PTR_ERR(cmd_out);\n\n\tMLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);\n\terr = mlx5_cmd_do(dev->mdev, cmd_in,\n\t\t\t  uverbs_attr_get_len(attrs, MLX5_IB_ATTR_DEVX_OTHER_CMD_IN),\n\t\t\t  cmd_out, cmd_out_len);\n\tif (err && err != -EREMOTEIO)\n\t\treturn err;\n\n\terr2 = uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_OTHER_CMD_OUT, cmd_out,\n\t\t\t      cmd_out_len);\n\n\treturn err2 ?: err;\n}\n\nstatic void devx_obj_build_destroy_cmd(void *in, void *out, void *din,\n\t\t\t\t       u32 *dinlen,\n\t\t\t\t       u32 *obj_id)\n{\n\tu16 opcode = MLX5_GET(general_obj_in_cmd_hdr, in, opcode);\n\tu16 uid = MLX5_GET(general_obj_in_cmd_hdr, in, uid);\n\n\t*obj_id = devx_get_created_obj_id(in, out, opcode);\n\t*dinlen = MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr);\n\tMLX5_SET(general_obj_in_cmd_hdr, din, uid, uid);\n\n\tswitch (opcode) {\n\tcase MLX5_CMD_OP_CREATE_GENERAL_OBJECT:\n\t\tMLX5_SET(general_obj_in_cmd_hdr, din, opcode, MLX5_CMD_OP_DESTROY_GENERAL_OBJECT);\n\t\tMLX5_SET(general_obj_in_cmd_hdr, din, obj_id, *obj_id);\n\t\tMLX5_SET(general_obj_in_cmd_hdr, din, obj_type,\n\t\t\t MLX5_GET(general_obj_in_cmd_hdr, in, obj_type));\n\t\tbreak;\n\n\tcase MLX5_CMD_OP_CREATE_UMEM:\n\t\tMLX5_SET(destroy_umem_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DESTROY_UMEM);\n\t\tMLX5_SET(destroy_umem_in, din, umem_id, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_MKEY:\n\t\tMLX5_SET(destroy_mkey_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DESTROY_MKEY);\n\t\tMLX5_SET(destroy_mkey_in, din, mkey_index, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_CQ:\n\t\tMLX5_SET(destroy_cq_in, din, opcode, MLX5_CMD_OP_DESTROY_CQ);\n\t\tMLX5_SET(destroy_cq_in, din, cqn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ALLOC_PD:\n\t\tMLX5_SET(dealloc_pd_in, din, opcode, MLX5_CMD_OP_DEALLOC_PD);\n\t\tMLX5_SET(dealloc_pd_in, din, pd, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ALLOC_TRANSPORT_DOMAIN:\n\t\tMLX5_SET(dealloc_transport_domain_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DEALLOC_TRANSPORT_DOMAIN);\n\t\tMLX5_SET(dealloc_transport_domain_in, din, transport_domain,\n\t\t\t *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_RMP:\n\t\tMLX5_SET(destroy_rmp_in, din, opcode, MLX5_CMD_OP_DESTROY_RMP);\n\t\tMLX5_SET(destroy_rmp_in, din, rmpn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_SQ:\n\t\tMLX5_SET(destroy_sq_in, din, opcode, MLX5_CMD_OP_DESTROY_SQ);\n\t\tMLX5_SET(destroy_sq_in, din, sqn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_RQ:\n\t\tMLX5_SET(destroy_rq_in, din, opcode, MLX5_CMD_OP_DESTROY_RQ);\n\t\tMLX5_SET(destroy_rq_in, din, rqn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_RQT:\n\t\tMLX5_SET(destroy_rqt_in, din, opcode, MLX5_CMD_OP_DESTROY_RQT);\n\t\tMLX5_SET(destroy_rqt_in, din, rqtn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_TIR:\n\t\tMLX5_SET(destroy_tir_in, din, opcode, MLX5_CMD_OP_DESTROY_TIR);\n\t\tMLX5_SET(destroy_tir_in, din, tirn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_TIS:\n\t\tMLX5_SET(destroy_tis_in, din, opcode, MLX5_CMD_OP_DESTROY_TIS);\n\t\tMLX5_SET(destroy_tis_in, din, tisn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ALLOC_Q_COUNTER:\n\t\tMLX5_SET(dealloc_q_counter_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DEALLOC_Q_COUNTER);\n\t\tMLX5_SET(dealloc_q_counter_in, din, counter_set_id, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_FLOW_TABLE:\n\t\t*dinlen = MLX5_ST_SZ_BYTES(destroy_flow_table_in);\n\t\tMLX5_SET(destroy_flow_table_in, din, other_vport,\n\t\t\t MLX5_GET(create_flow_table_in,  in, other_vport));\n\t\tMLX5_SET(destroy_flow_table_in, din, vport_number,\n\t\t\t MLX5_GET(create_flow_table_in,  in, vport_number));\n\t\tMLX5_SET(destroy_flow_table_in, din, table_type,\n\t\t\t MLX5_GET(create_flow_table_in,  in, table_type));\n\t\tMLX5_SET(destroy_flow_table_in, din, table_id, *obj_id);\n\t\tMLX5_SET(destroy_flow_table_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DESTROY_FLOW_TABLE);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_FLOW_GROUP:\n\t\t*dinlen = MLX5_ST_SZ_BYTES(destroy_flow_group_in);\n\t\tMLX5_SET(destroy_flow_group_in, din, other_vport,\n\t\t\t MLX5_GET(create_flow_group_in, in, other_vport));\n\t\tMLX5_SET(destroy_flow_group_in, din, vport_number,\n\t\t\t MLX5_GET(create_flow_group_in, in, vport_number));\n\t\tMLX5_SET(destroy_flow_group_in, din, table_type,\n\t\t\t MLX5_GET(create_flow_group_in, in, table_type));\n\t\tMLX5_SET(destroy_flow_group_in, din, table_id,\n\t\t\t MLX5_GET(create_flow_group_in, in, table_id));\n\t\tMLX5_SET(destroy_flow_group_in, din, group_id, *obj_id);\n\t\tMLX5_SET(destroy_flow_group_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DESTROY_FLOW_GROUP);\n\t\tbreak;\n\tcase MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY:\n\t\t*dinlen = MLX5_ST_SZ_BYTES(delete_fte_in);\n\t\tMLX5_SET(delete_fte_in, din, other_vport,\n\t\t\t MLX5_GET(set_fte_in,  in, other_vport));\n\t\tMLX5_SET(delete_fte_in, din, vport_number,\n\t\t\t MLX5_GET(set_fte_in, in, vport_number));\n\t\tMLX5_SET(delete_fte_in, din, table_type,\n\t\t\t MLX5_GET(set_fte_in, in, table_type));\n\t\tMLX5_SET(delete_fte_in, din, table_id,\n\t\t\t MLX5_GET(set_fte_in, in, table_id));\n\t\tMLX5_SET(delete_fte_in, din, flow_index, *obj_id);\n\t\tMLX5_SET(delete_fte_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DELETE_FLOW_TABLE_ENTRY);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ALLOC_FLOW_COUNTER:\n\t\tMLX5_SET(dealloc_flow_counter_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DEALLOC_FLOW_COUNTER);\n\t\tMLX5_SET(dealloc_flow_counter_in, din, flow_counter_id,\n\t\t\t *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ALLOC_PACKET_REFORMAT_CONTEXT:\n\t\tMLX5_SET(dealloc_packet_reformat_context_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DEALLOC_PACKET_REFORMAT_CONTEXT);\n\t\tMLX5_SET(dealloc_packet_reformat_context_in, din,\n\t\t\t packet_reformat_id, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ALLOC_MODIFY_HEADER_CONTEXT:\n\t\tMLX5_SET(dealloc_modify_header_context_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DEALLOC_MODIFY_HEADER_CONTEXT);\n\t\tMLX5_SET(dealloc_modify_header_context_in, din,\n\t\t\t modify_header_id, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT:\n\t\t*dinlen = MLX5_ST_SZ_BYTES(destroy_scheduling_element_in);\n\t\tMLX5_SET(destroy_scheduling_element_in, din,\n\t\t\t scheduling_hierarchy,\n\t\t\t MLX5_GET(create_scheduling_element_in, in,\n\t\t\t\t  scheduling_hierarchy));\n\t\tMLX5_SET(destroy_scheduling_element_in, din,\n\t\t\t scheduling_element_id, *obj_id);\n\t\tMLX5_SET(destroy_scheduling_element_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DESTROY_SCHEDULING_ELEMENT);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT:\n\t\t*dinlen = MLX5_ST_SZ_BYTES(delete_vxlan_udp_dport_in);\n\t\tMLX5_SET(delete_vxlan_udp_dport_in, din, vxlan_udp_port, *obj_id);\n\t\tMLX5_SET(delete_vxlan_udp_dport_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DELETE_VXLAN_UDP_DPORT);\n\t\tbreak;\n\tcase MLX5_CMD_OP_SET_L2_TABLE_ENTRY:\n\t\t*dinlen = MLX5_ST_SZ_BYTES(delete_l2_table_entry_in);\n\t\tMLX5_SET(delete_l2_table_entry_in, din, table_index, *obj_id);\n\t\tMLX5_SET(delete_l2_table_entry_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DELETE_L2_TABLE_ENTRY);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_QP:\n\t\tMLX5_SET(destroy_qp_in, din, opcode, MLX5_CMD_OP_DESTROY_QP);\n\t\tMLX5_SET(destroy_qp_in, din, qpn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_SRQ:\n\t\tMLX5_SET(destroy_srq_in, din, opcode, MLX5_CMD_OP_DESTROY_SRQ);\n\t\tMLX5_SET(destroy_srq_in, din, srqn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_XRC_SRQ:\n\t\tMLX5_SET(destroy_xrc_srq_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DESTROY_XRC_SRQ);\n\t\tMLX5_SET(destroy_xrc_srq_in, din, xrc_srqn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_DCT:\n\t\tMLX5_SET(destroy_dct_in, din, opcode, MLX5_CMD_OP_DESTROY_DCT);\n\t\tMLX5_SET(destroy_dct_in, din, dctn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_XRQ:\n\t\tMLX5_SET(destroy_xrq_in, din, opcode, MLX5_CMD_OP_DESTROY_XRQ);\n\t\tMLX5_SET(destroy_xrq_in, din, xrqn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ATTACH_TO_MCG:\n\t\t*dinlen = MLX5_ST_SZ_BYTES(detach_from_mcg_in);\n\t\tMLX5_SET(detach_from_mcg_in, din, qpn,\n\t\t\t MLX5_GET(attach_to_mcg_in, in, qpn));\n\t\tmemcpy(MLX5_ADDR_OF(detach_from_mcg_in, din, multicast_gid),\n\t\t       MLX5_ADDR_OF(attach_to_mcg_in, in, multicast_gid),\n\t\t       MLX5_FLD_SZ_BYTES(attach_to_mcg_in, multicast_gid));\n\t\tMLX5_SET(detach_from_mcg_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DETACH_FROM_MCG);\n\t\tMLX5_SET(detach_from_mcg_in, din, qpn, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_ALLOC_XRCD:\n\t\tMLX5_SET(dealloc_xrcd_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DEALLOC_XRCD);\n\t\tMLX5_SET(dealloc_xrcd_in, din, xrcd, *obj_id);\n\t\tbreak;\n\tcase MLX5_CMD_OP_CREATE_PSV:\n\t\tMLX5_SET(destroy_psv_in, din, opcode,\n\t\t\t MLX5_CMD_OP_DESTROY_PSV);\n\t\tMLX5_SET(destroy_psv_in, din, psvn, *obj_id);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tWARN_ON(true);\n\t\tbreak;\n\t}\n}\n\nstatic int devx_handle_mkey_indirect(struct devx_obj *obj,\n\t\t\t\t     struct mlx5_ib_dev *dev,\n\t\t\t\t     void *in, void *out)\n{\n\tstruct mlx5_ib_mkey *mkey = &obj->mkey;\n\tvoid *mkc;\n\tu8 key;\n\n\tmkc = MLX5_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);\n\tkey = MLX5_GET(mkc, mkc, mkey_7_0);\n\tmkey->key = mlx5_idx_to_mkey(\n\t\t\tMLX5_GET(create_mkey_out, out, mkey_index)) | key;\n\tmkey->type = MLX5_MKEY_INDIRECT_DEVX;\n\tmkey->ndescs = MLX5_GET(mkc, mkc, translations_octword_size);\n\tinit_waitqueue_head(&mkey->wait);\n\n\treturn mlx5r_store_odp_mkey(dev, mkey);\n}\n\nstatic int devx_handle_mkey_create(struct mlx5_ib_dev *dev,\n\t\t\t\t   struct devx_obj *obj,\n\t\t\t\t   void *in, int in_len)\n{\n\tint min_len = MLX5_BYTE_OFF(create_mkey_in, memory_key_mkey_entry) +\n\t\t\tMLX5_FLD_SZ_BYTES(create_mkey_in,\n\t\t\tmemory_key_mkey_entry);\n\tvoid *mkc;\n\tu8 access_mode;\n\n\tif (in_len < min_len)\n\t\treturn -EINVAL;\n\n\tmkc = MLX5_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);\n\n\taccess_mode = MLX5_GET(mkc, mkc, access_mode_1_0);\n\taccess_mode |= MLX5_GET(mkc, mkc, access_mode_4_2) << 2;\n\n\tif (access_mode == MLX5_MKC_ACCESS_MODE_KLMS ||\n\t\taccess_mode == MLX5_MKC_ACCESS_MODE_KSM) {\n\t\tif (IS_ENABLED(CONFIG_INFINIBAND_ON_DEMAND_PAGING))\n\t\t\tobj->flags |= DEVX_OBJ_FLAGS_INDIRECT_MKEY;\n\t\treturn 0;\n\t}\n\n\tMLX5_SET(create_mkey_in, in, mkey_umem_valid, 1);\n\treturn 0;\n}\n\nstatic void devx_cleanup_subscription(struct mlx5_ib_dev *dev,\n\t\t\t\t      struct devx_event_subscription *sub)\n{\n\tstruct devx_event *event;\n\tstruct devx_obj_event *xa_val_level2;\n\n\tif (sub->is_cleaned)\n\t\treturn;\n\n\tsub->is_cleaned = 1;\n\tlist_del_rcu(&sub->xa_list);\n\n\tif (list_empty(&sub->obj_list))\n\t\treturn;\n\n\tlist_del_rcu(&sub->obj_list);\n\t \n\tevent = xa_load(&dev->devx_event_table.event_xa,\n\t\t\tsub->xa_key_level1);\n\tWARN_ON(!event);\n\n\txa_val_level2 = xa_load(&event->object_ids, sub->xa_key_level2);\n\tif (list_empty(&xa_val_level2->obj_sub_list)) {\n\t\txa_erase(&event->object_ids,\n\t\t\t sub->xa_key_level2);\n\t\tkfree_rcu(xa_val_level2, rcu);\n\t}\n}\n\nstatic int devx_obj_cleanup(struct ib_uobject *uobject,\n\t\t\t    enum rdma_remove_reason why,\n\t\t\t    struct uverbs_attr_bundle *attrs)\n{\n\tu32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)];\n\tstruct mlx5_devx_event_table *devx_event_table;\n\tstruct devx_obj *obj = uobject->object;\n\tstruct devx_event_subscription *sub_entry, *tmp;\n\tstruct mlx5_ib_dev *dev;\n\tint ret;\n\n\tdev = mlx5_udata_to_mdev(&attrs->driver_udata);\n\tif (obj->flags & DEVX_OBJ_FLAGS_INDIRECT_MKEY &&\n\t    xa_erase(&obj->ib_dev->odp_mkeys,\n\t\t     mlx5_base_mkey(obj->mkey.key)))\n\t\t \n\t\tmlx5r_deref_wait_odp_mkey(&obj->mkey);\n\n\tif (obj->flags & DEVX_OBJ_FLAGS_DCT)\n\t\tret = mlx5_core_destroy_dct(obj->ib_dev, &obj->core_dct);\n\telse if (obj->flags & DEVX_OBJ_FLAGS_CQ)\n\t\tret = mlx5_core_destroy_cq(obj->ib_dev->mdev, &obj->core_cq);\n\telse\n\t\tret = mlx5_cmd_exec(obj->ib_dev->mdev, obj->dinbox,\n\t\t\t\t    obj->dinlen, out, sizeof(out));\n\tif (ret)\n\t\treturn ret;\n\n\tdevx_event_table = &dev->devx_event_table;\n\n\tmutex_lock(&devx_event_table->event_xa_lock);\n\tlist_for_each_entry_safe(sub_entry, tmp, &obj->event_sub, obj_list)\n\t\tdevx_cleanup_subscription(dev, sub_entry);\n\tmutex_unlock(&devx_event_table->event_xa_lock);\n\n\tkfree(obj);\n\treturn ret;\n}\n\nstatic void devx_cq_comp(struct mlx5_core_cq *mcq, struct mlx5_eqe *eqe)\n{\n\tstruct devx_obj *obj = container_of(mcq, struct devx_obj, core_cq);\n\tstruct mlx5_devx_event_table *table;\n\tstruct devx_event *event;\n\tstruct devx_obj_event *obj_event;\n\tu32 obj_id = mcq->cqn;\n\n\ttable = &obj->ib_dev->devx_event_table;\n\trcu_read_lock();\n\tevent = xa_load(&table->event_xa, MLX5_EVENT_TYPE_COMP);\n\tif (!event)\n\t\tgoto out;\n\n\tobj_event = xa_load(&event->object_ids, obj_id);\n\tif (!obj_event)\n\t\tgoto out;\n\n\tdispatch_event_fd(&obj_event->obj_sub_list, eqe);\nout:\n\trcu_read_unlock();\n}\n\nstatic bool is_apu_cq(struct mlx5_ib_dev *dev, const void *in)\n{\n\tif (!MLX5_CAP_GEN(dev->mdev, apu) ||\n\t    !MLX5_GET(cqc, MLX5_ADDR_OF(create_cq_in, in, cq_context), apu_cq))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_OBJ_CREATE)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tvoid *cmd_in = uverbs_attr_get_alloced_ptr(attrs, MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_IN);\n\tint cmd_out_len =  uverbs_attr_get_len(attrs,\n\t\t\t\t\tMLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_OUT);\n\tint cmd_in_len = uverbs_attr_get_len(attrs,\n\t\t\t\t\tMLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_IN);\n\tvoid *cmd_out;\n\tstruct ib_uobject *uobj = uverbs_attr_get_uobject(\n\t\tattrs, MLX5_IB_ATTR_DEVX_OBJ_CREATE_HANDLE);\n\tstruct mlx5_ib_ucontext *c = rdma_udata_to_drv_context(\n\t\t&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);\n\tstruct mlx5_ib_dev *dev = to_mdev(c->ibucontext.device);\n\tu32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)];\n\tstruct devx_obj *obj;\n\tu16 obj_type = 0;\n\tint err, err2 = 0;\n\tint uid;\n\tu32 obj_id;\n\tu16 opcode;\n\n\tif (MLX5_GET(general_obj_in_cmd_hdr, cmd_in, vhca_tunnel_id))\n\t\treturn -EINVAL;\n\n\tuid = devx_get_uid(c, cmd_in);\n\tif (uid < 0)\n\t\treturn uid;\n\n\tif (!devx_is_obj_create_cmd(cmd_in, &opcode))\n\t\treturn -EINVAL;\n\n\tcmd_out = uverbs_zalloc(attrs, cmd_out_len);\n\tif (IS_ERR(cmd_out))\n\t\treturn PTR_ERR(cmd_out);\n\n\tobj = kzalloc(sizeof(struct devx_obj), GFP_KERNEL);\n\tif (!obj)\n\t\treturn -ENOMEM;\n\n\tMLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);\n\tif (opcode == MLX5_CMD_OP_CREATE_MKEY) {\n\t\terr = devx_handle_mkey_create(dev, obj, cmd_in, cmd_in_len);\n\t\tif (err)\n\t\t\tgoto obj_free;\n\t} else {\n\t\tdevx_set_umem_valid(cmd_in);\n\t}\n\n\tif (opcode == MLX5_CMD_OP_CREATE_DCT) {\n\t\tobj->flags |= DEVX_OBJ_FLAGS_DCT;\n\t\terr = mlx5_core_create_dct(dev, &obj->core_dct, cmd_in,\n\t\t\t\t\t   cmd_in_len, cmd_out, cmd_out_len);\n\t} else if (opcode == MLX5_CMD_OP_CREATE_CQ &&\n\t\t   !is_apu_cq(dev, cmd_in)) {\n\t\tobj->flags |= DEVX_OBJ_FLAGS_CQ;\n\t\tobj->core_cq.comp = devx_cq_comp;\n\t\terr = mlx5_create_cq(dev->mdev, &obj->core_cq,\n\t\t\t\t     cmd_in, cmd_in_len, cmd_out,\n\t\t\t\t     cmd_out_len);\n\t} else {\n\t\terr = mlx5_cmd_do(dev->mdev, cmd_in, cmd_in_len,\n\t\t\t\t  cmd_out, cmd_out_len);\n\t}\n\n\tif (err == -EREMOTEIO)\n\t\terr2 = uverbs_copy_to(attrs,\n\t\t\t\t      MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_OUT,\n\t\t\t\t      cmd_out, cmd_out_len);\n\tif (err)\n\t\tgoto obj_free;\n\n\tif (opcode == MLX5_CMD_OP_ALLOC_FLOW_COUNTER) {\n\t\tu32 bulk = MLX5_GET(alloc_flow_counter_in,\n\t\t\t\t    cmd_in,\n\t\t\t\t    flow_counter_bulk_log_size);\n\n\t\tif (bulk)\n\t\t\tbulk = 1 << bulk;\n\t\telse\n\t\t\tbulk = 128UL * MLX5_GET(alloc_flow_counter_in,\n\t\t\t\t\t\tcmd_in,\n\t\t\t\t\t\tflow_counter_bulk);\n\t\tobj->flow_counter_bulk_size = bulk;\n\t}\n\n\tuobj->object = obj;\n\tINIT_LIST_HEAD(&obj->event_sub);\n\tobj->ib_dev = dev;\n\tdevx_obj_build_destroy_cmd(cmd_in, cmd_out, obj->dinbox, &obj->dinlen,\n\t\t\t\t   &obj_id);\n\tWARN_ON(obj->dinlen > MLX5_MAX_DESTROY_INBOX_SIZE_DW * sizeof(u32));\n\n\terr = uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_OUT, cmd_out, cmd_out_len);\n\tif (err)\n\t\tgoto obj_destroy;\n\n\tif (opcode == MLX5_CMD_OP_CREATE_GENERAL_OBJECT)\n\t\tobj_type = MLX5_GET(general_obj_in_cmd_hdr, cmd_in, obj_type);\n\tobj->obj_id = get_enc_obj_id(opcode | obj_type << 16, obj_id);\n\n\tif (obj->flags & DEVX_OBJ_FLAGS_INDIRECT_MKEY) {\n\t\terr = devx_handle_mkey_indirect(obj, dev, cmd_in, cmd_out);\n\t\tif (err)\n\t\t\tgoto obj_destroy;\n\t}\n\treturn 0;\n\nobj_destroy:\n\tif (obj->flags & DEVX_OBJ_FLAGS_DCT)\n\t\tmlx5_core_destroy_dct(obj->ib_dev, &obj->core_dct);\n\telse if (obj->flags & DEVX_OBJ_FLAGS_CQ)\n\t\tmlx5_core_destroy_cq(obj->ib_dev->mdev, &obj->core_cq);\n\telse\n\t\tmlx5_cmd_exec(obj->ib_dev->mdev, obj->dinbox, obj->dinlen, out,\n\t\t\t      sizeof(out));\nobj_free:\n\tkfree(obj);\n\treturn err2 ?: err;\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_OBJ_MODIFY)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tvoid *cmd_in = uverbs_attr_get_alloced_ptr(attrs, MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_IN);\n\tint cmd_out_len = uverbs_attr_get_len(attrs,\n\t\t\t\t\tMLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_OUT);\n\tstruct ib_uobject *uobj = uverbs_attr_get_uobject(attrs,\n\t\t\t\t\t\t\t  MLX5_IB_ATTR_DEVX_OBJ_MODIFY_HANDLE);\n\tstruct mlx5_ib_ucontext *c = rdma_udata_to_drv_context(\n\t\t&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);\n\tstruct mlx5_ib_dev *mdev = to_mdev(c->ibucontext.device);\n\tvoid *cmd_out;\n\tint err, err2;\n\tint uid;\n\n\tif (MLX5_GET(general_obj_in_cmd_hdr, cmd_in, vhca_tunnel_id))\n\t\treturn -EINVAL;\n\n\tuid = devx_get_uid(c, cmd_in);\n\tif (uid < 0)\n\t\treturn uid;\n\n\tif (!devx_is_obj_modify_cmd(cmd_in))\n\t\treturn -EINVAL;\n\n\tif (!devx_is_valid_obj_id(attrs, uobj, cmd_in))\n\t\treturn -EINVAL;\n\n\tcmd_out = uverbs_zalloc(attrs, cmd_out_len);\n\tif (IS_ERR(cmd_out))\n\t\treturn PTR_ERR(cmd_out);\n\n\tMLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);\n\tdevx_set_umem_valid(cmd_in);\n\n\terr = mlx5_cmd_do(mdev->mdev, cmd_in,\n\t\t\t  uverbs_attr_get_len(attrs, MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_IN),\n\t\t\t  cmd_out, cmd_out_len);\n\tif (err && err != -EREMOTEIO)\n\t\treturn err;\n\n\terr2 = uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_OUT,\n\t\t\t      cmd_out, cmd_out_len);\n\n\treturn err2 ?: err;\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_OBJ_QUERY)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tvoid *cmd_in = uverbs_attr_get_alloced_ptr(attrs, MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_IN);\n\tint cmd_out_len = uverbs_attr_get_len(attrs,\n\t\t\t\t\t      MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_OUT);\n\tstruct ib_uobject *uobj = uverbs_attr_get_uobject(attrs,\n\t\t\t\t\t\t\t  MLX5_IB_ATTR_DEVX_OBJ_QUERY_HANDLE);\n\tstruct mlx5_ib_ucontext *c = rdma_udata_to_drv_context(\n\t\t&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);\n\tvoid *cmd_out;\n\tint err, err2;\n\tint uid;\n\tstruct mlx5_ib_dev *mdev = to_mdev(c->ibucontext.device);\n\n\tif (MLX5_GET(general_obj_in_cmd_hdr, cmd_in, vhca_tunnel_id))\n\t\treturn -EINVAL;\n\n\tuid = devx_get_uid(c, cmd_in);\n\tif (uid < 0)\n\t\treturn uid;\n\n\tif (!devx_is_obj_query_cmd(cmd_in))\n\t\treturn -EINVAL;\n\n\tif (!devx_is_valid_obj_id(attrs, uobj, cmd_in))\n\t\treturn -EINVAL;\n\n\tcmd_out = uverbs_zalloc(attrs, cmd_out_len);\n\tif (IS_ERR(cmd_out))\n\t\treturn PTR_ERR(cmd_out);\n\n\tMLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);\n\terr = mlx5_cmd_do(mdev->mdev, cmd_in,\n\t\t\t  uverbs_attr_get_len(attrs, MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_IN),\n\t\t\t  cmd_out, cmd_out_len);\n\tif (err && err != -EREMOTEIO)\n\t\treturn err;\n\n\terr2 = uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_OUT,\n\t\t\t      cmd_out, cmd_out_len);\n\n\treturn err2 ?: err;\n}\n\nstruct devx_async_event_queue {\n\tspinlock_t\t\tlock;\n\twait_queue_head_t\tpoll_wait;\n\tstruct list_head\tevent_list;\n\tatomic_t\t\tbytes_in_use;\n\tu8\t\t\tis_destroyed:1;\n};\n\nstruct devx_async_cmd_event_file {\n\tstruct ib_uobject\t\tuobj;\n\tstruct devx_async_event_queue\tev_queue;\n\tstruct mlx5_async_ctx\t\tasync_ctx;\n};\n\nstatic void devx_init_event_queue(struct devx_async_event_queue *ev_queue)\n{\n\tspin_lock_init(&ev_queue->lock);\n\tINIT_LIST_HEAD(&ev_queue->event_list);\n\tinit_waitqueue_head(&ev_queue->poll_wait);\n\tatomic_set(&ev_queue->bytes_in_use, 0);\n\tev_queue->is_destroyed = 0;\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_ASYNC_CMD_FD_ALLOC)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tstruct devx_async_cmd_event_file *ev_file;\n\n\tstruct ib_uobject *uobj = uverbs_attr_get_uobject(\n\t\tattrs, MLX5_IB_ATTR_DEVX_ASYNC_CMD_FD_ALLOC_HANDLE);\n\tstruct mlx5_ib_dev *mdev = mlx5_udata_to_mdev(&attrs->driver_udata);\n\n\tev_file = container_of(uobj, struct devx_async_cmd_event_file,\n\t\t\t       uobj);\n\tdevx_init_event_queue(&ev_file->ev_queue);\n\tmlx5_cmd_init_async_ctx(mdev->mdev, &ev_file->async_ctx);\n\treturn 0;\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_ASYNC_EVENT_FD_ALLOC)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tstruct ib_uobject *uobj = uverbs_attr_get_uobject(\n\t\tattrs, MLX5_IB_ATTR_DEVX_ASYNC_EVENT_FD_ALLOC_HANDLE);\n\tstruct devx_async_event_file *ev_file;\n\tstruct mlx5_ib_ucontext *c = rdma_udata_to_drv_context(\n\t\t&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);\n\tstruct mlx5_ib_dev *dev = to_mdev(c->ibucontext.device);\n\tu32 flags;\n\tint err;\n\n\terr = uverbs_get_flags32(&flags, attrs,\n\t\tMLX5_IB_ATTR_DEVX_ASYNC_EVENT_FD_ALLOC_FLAGS,\n\t\tMLX5_IB_UAPI_DEVX_CR_EV_CH_FLAGS_OMIT_DATA);\n\n\tif (err)\n\t\treturn err;\n\n\tev_file = container_of(uobj, struct devx_async_event_file,\n\t\t\t       uobj);\n\tspin_lock_init(&ev_file->lock);\n\tINIT_LIST_HEAD(&ev_file->event_list);\n\tinit_waitqueue_head(&ev_file->poll_wait);\n\tif (flags & MLX5_IB_UAPI_DEVX_CR_EV_CH_FLAGS_OMIT_DATA)\n\t\tev_file->omit_data = 1;\n\tINIT_LIST_HEAD(&ev_file->subscribed_events_list);\n\tev_file->dev = dev;\n\tget_device(&dev->ib_dev.dev);\n\treturn 0;\n}\n\nstatic void devx_query_callback(int status, struct mlx5_async_work *context)\n{\n\tstruct devx_async_data *async_data =\n\t\tcontainer_of(context, struct devx_async_data, cb_work);\n\tstruct devx_async_cmd_event_file *ev_file = async_data->ev_file;\n\tstruct devx_async_event_queue *ev_queue = &ev_file->ev_queue;\n\tunsigned long flags;\n\n\t \n\tspin_lock_irqsave(&ev_queue->lock, flags);\n\tlist_add_tail(&async_data->list, &ev_queue->event_list);\n\tspin_unlock_irqrestore(&ev_queue->lock, flags);\n\n\twake_up_interruptible(&ev_queue->poll_wait);\n}\n\n#define MAX_ASYNC_BYTES_IN_USE (1024 * 1024)  \n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_OBJ_ASYNC_QUERY)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tvoid *cmd_in = uverbs_attr_get_alloced_ptr(attrs,\n\t\t\t\tMLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_CMD_IN);\n\tstruct ib_uobject *uobj = uverbs_attr_get_uobject(\n\t\t\t\tattrs,\n\t\t\t\tMLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_HANDLE);\n\tu16 cmd_out_len;\n\tstruct mlx5_ib_ucontext *c = rdma_udata_to_drv_context(\n\t\t&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);\n\tstruct ib_uobject *fd_uobj;\n\tint err;\n\tint uid;\n\tstruct mlx5_ib_dev *mdev = to_mdev(c->ibucontext.device);\n\tstruct devx_async_cmd_event_file *ev_file;\n\tstruct devx_async_data *async_data;\n\n\tif (MLX5_GET(general_obj_in_cmd_hdr, cmd_in, vhca_tunnel_id))\n\t\treturn -EINVAL;\n\n\tuid = devx_get_uid(c, cmd_in);\n\tif (uid < 0)\n\t\treturn uid;\n\n\tif (!devx_is_obj_query_cmd(cmd_in))\n\t\treturn -EINVAL;\n\n\terr = uverbs_get_const(&cmd_out_len, attrs,\n\t\t\t       MLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_OUT_LEN);\n\tif (err)\n\t\treturn err;\n\n\tif (!devx_is_valid_obj_id(attrs, uobj, cmd_in))\n\t\treturn -EINVAL;\n\n\tfd_uobj = uverbs_attr_get_uobject(attrs,\n\t\t\t\tMLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_FD);\n\tif (IS_ERR(fd_uobj))\n\t\treturn PTR_ERR(fd_uobj);\n\n\tev_file = container_of(fd_uobj, struct devx_async_cmd_event_file,\n\t\t\t       uobj);\n\n\tif (atomic_add_return(cmd_out_len, &ev_file->ev_queue.bytes_in_use) >\n\t\t\tMAX_ASYNC_BYTES_IN_USE) {\n\t\tatomic_sub(cmd_out_len, &ev_file->ev_queue.bytes_in_use);\n\t\treturn -EAGAIN;\n\t}\n\n\tasync_data = kvzalloc(struct_size(async_data, hdr.out_data,\n\t\t\t\t\t  cmd_out_len), GFP_KERNEL);\n\tif (!async_data) {\n\t\terr = -ENOMEM;\n\t\tgoto sub_bytes;\n\t}\n\n\terr = uverbs_copy_from(&async_data->hdr.wr_id, attrs,\n\t\t\t       MLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_WR_ID);\n\tif (err)\n\t\tgoto free_async;\n\n\tasync_data->cmd_out_len = cmd_out_len;\n\tasync_data->mdev = mdev;\n\tasync_data->ev_file = ev_file;\n\n\tMLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);\n\terr = mlx5_cmd_exec_cb(&ev_file->async_ctx, cmd_in,\n\t\t    uverbs_attr_get_len(attrs,\n\t\t\t\tMLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_CMD_IN),\n\t\t    async_data->hdr.out_data,\n\t\t    async_data->cmd_out_len,\n\t\t    devx_query_callback, &async_data->cb_work);\n\n\tif (err)\n\t\tgoto free_async;\n\n\treturn 0;\n\nfree_async:\n\tkvfree(async_data);\nsub_bytes:\n\tatomic_sub(cmd_out_len, &ev_file->ev_queue.bytes_in_use);\n\treturn err;\n}\n\nstatic void\nsubscribe_event_xa_dealloc(struct mlx5_devx_event_table *devx_event_table,\n\t\t\t   u32 key_level1,\n\t\t\t   bool is_level2,\n\t\t\t   u32 key_level2)\n{\n\tstruct devx_event *event;\n\tstruct devx_obj_event *xa_val_level2;\n\n\t \n\tif (!is_level2)\n\t\treturn;\n\n\tevent = xa_load(&devx_event_table->event_xa, key_level1);\n\tWARN_ON(!event);\n\n\txa_val_level2 = xa_load(&event->object_ids,\n\t\t\t\tkey_level2);\n\tif (list_empty(&xa_val_level2->obj_sub_list)) {\n\t\txa_erase(&event->object_ids,\n\t\t\t key_level2);\n\t\tkfree_rcu(xa_val_level2, rcu);\n\t}\n}\n\nstatic int\nsubscribe_event_xa_alloc(struct mlx5_devx_event_table *devx_event_table,\n\t\t\t u32 key_level1,\n\t\t\t bool is_level2,\n\t\t\t u32 key_level2)\n{\n\tstruct devx_obj_event *obj_event;\n\tstruct devx_event *event;\n\tint err;\n\n\tevent = xa_load(&devx_event_table->event_xa, key_level1);\n\tif (!event) {\n\t\tevent = kzalloc(sizeof(*event), GFP_KERNEL);\n\t\tif (!event)\n\t\t\treturn -ENOMEM;\n\n\t\tINIT_LIST_HEAD(&event->unaffiliated_list);\n\t\txa_init(&event->object_ids);\n\n\t\terr = xa_insert(&devx_event_table->event_xa,\n\t\t\t\tkey_level1,\n\t\t\t\tevent,\n\t\t\t\tGFP_KERNEL);\n\t\tif (err) {\n\t\t\tkfree(event);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tif (!is_level2)\n\t\treturn 0;\n\n\tobj_event = xa_load(&event->object_ids, key_level2);\n\tif (!obj_event) {\n\t\tobj_event = kzalloc(sizeof(*obj_event), GFP_KERNEL);\n\t\tif (!obj_event)\n\t\t\t \n\t\t\treturn -ENOMEM;\n\n\t\terr = xa_insert(&event->object_ids,\n\t\t\t\tkey_level2,\n\t\t\t\tobj_event,\n\t\t\t\tGFP_KERNEL);\n\t\tif (err) {\n\t\t\tkfree(obj_event);\n\t\t\treturn err;\n\t\t}\n\t\tINIT_LIST_HEAD(&obj_event->obj_sub_list);\n\t}\n\n\treturn 0;\n}\n\nstatic bool is_valid_events_legacy(int num_events, u16 *event_type_num_list,\n\t\t\t\t   struct devx_obj *obj)\n{\n\tint i;\n\n\tfor (i = 0; i < num_events; i++) {\n\t\tif (obj) {\n\t\t\tif (!is_legacy_obj_event_num(event_type_num_list[i]))\n\t\t\t\treturn false;\n\t\t} else if (!is_legacy_unaffiliated_event_num(\n\t\t\t\tevent_type_num_list[i])) {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}\n\n#define MAX_SUPP_EVENT_NUM 255\nstatic bool is_valid_events(struct mlx5_core_dev *dev,\n\t\t\t    int num_events, u16 *event_type_num_list,\n\t\t\t    struct devx_obj *obj)\n{\n\t__be64 *aff_events;\n\t__be64 *unaff_events;\n\tint mask_entry;\n\tint mask_bit;\n\tint i;\n\n\tif (MLX5_CAP_GEN(dev, event_cap)) {\n\t\taff_events = MLX5_CAP_DEV_EVENT(dev,\n\t\t\t\t\t\tuser_affiliated_events);\n\t\tunaff_events = MLX5_CAP_DEV_EVENT(dev,\n\t\t\t\t\t\t  user_unaffiliated_events);\n\t} else {\n\t\treturn is_valid_events_legacy(num_events, event_type_num_list,\n\t\t\t\t\t      obj);\n\t}\n\n\tfor (i = 0; i < num_events; i++) {\n\t\tif (event_type_num_list[i] > MAX_SUPP_EVENT_NUM)\n\t\t\treturn false;\n\n\t\tmask_entry = event_type_num_list[i] / 64;\n\t\tmask_bit = event_type_num_list[i] % 64;\n\n\t\tif (obj) {\n\t\t\t \n\t\t\tif (event_type_num_list[i] == 0)\n\t\t\t\tcontinue;\n\n\t\t\tif (!(be64_to_cpu(aff_events[mask_entry]) &\n\t\t\t\t\t(1ull << mask_bit)))\n\t\t\t\treturn false;\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!(be64_to_cpu(unaff_events[mask_entry]) &\n\t\t\t\t(1ull << mask_bit)))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n#define MAX_NUM_EVENTS 16\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_SUBSCRIBE_EVENT)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tstruct ib_uobject *devx_uobj = uverbs_attr_get_uobject(\n\t\t\t\tattrs,\n\t\t\t\tMLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_OBJ_HANDLE);\n\tstruct mlx5_ib_ucontext *c = rdma_udata_to_drv_context(\n\t\t&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);\n\tstruct mlx5_ib_dev *dev = to_mdev(c->ibucontext.device);\n\tstruct ib_uobject *fd_uobj;\n\tstruct devx_obj *obj = NULL;\n\tstruct devx_async_event_file *ev_file;\n\tstruct mlx5_devx_event_table *devx_event_table = &dev->devx_event_table;\n\tu16 *event_type_num_list;\n\tstruct devx_event_subscription *event_sub, *tmp_sub;\n\tstruct list_head sub_list;\n\tint redirect_fd;\n\tbool use_eventfd = false;\n\tint num_events;\n\tu16 obj_type = 0;\n\tu64 cookie = 0;\n\tu32 obj_id = 0;\n\tint err;\n\tint i;\n\n\tif (!c->devx_uid)\n\t\treturn -EINVAL;\n\n\tif (!IS_ERR(devx_uobj)) {\n\t\tobj = (struct devx_obj *)devx_uobj->object;\n\t\tif (obj)\n\t\t\tobj_id = get_dec_obj_id(obj->obj_id);\n\t}\n\n\tfd_uobj = uverbs_attr_get_uobject(attrs,\n\t\t\t\tMLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_FD_HANDLE);\n\tif (IS_ERR(fd_uobj))\n\t\treturn PTR_ERR(fd_uobj);\n\n\tev_file = container_of(fd_uobj, struct devx_async_event_file,\n\t\t\t       uobj);\n\n\tif (uverbs_attr_is_valid(attrs,\n\t\t\t\t MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_FD_NUM)) {\n\t\terr = uverbs_copy_from(&redirect_fd, attrs,\n\t\t\t       MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_FD_NUM);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tuse_eventfd = true;\n\t}\n\n\tif (uverbs_attr_is_valid(attrs,\n\t\t\t\t MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_COOKIE)) {\n\t\tif (use_eventfd)\n\t\t\treturn -EINVAL;\n\n\t\terr = uverbs_copy_from(&cookie, attrs,\n\t\t\t\tMLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_COOKIE);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tnum_events = uverbs_attr_ptr_get_array_size(\n\t\tattrs, MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_TYPE_NUM_LIST,\n\t\tsizeof(u16));\n\n\tif (num_events < 0)\n\t\treturn num_events;\n\n\tif (num_events > MAX_NUM_EVENTS)\n\t\treturn -EINVAL;\n\n\tevent_type_num_list = uverbs_attr_get_alloced_ptr(attrs,\n\t\t\tMLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_TYPE_NUM_LIST);\n\n\tif (!is_valid_events(dev->mdev, num_events, event_type_num_list, obj))\n\t\treturn -EINVAL;\n\n\tINIT_LIST_HEAD(&sub_list);\n\n\t \n\tmutex_lock(&devx_event_table->event_xa_lock);\n\tfor (i = 0; i < num_events; i++) {\n\t\tu32 key_level1;\n\n\t\tif (obj)\n\t\t\tobj_type = get_dec_obj_type(obj,\n\t\t\t\t\t\t    event_type_num_list[i]);\n\t\tkey_level1 = event_type_num_list[i] | obj_type << 16;\n\n\t\terr = subscribe_event_xa_alloc(devx_event_table,\n\t\t\t\t\t       key_level1,\n\t\t\t\t\t       obj,\n\t\t\t\t\t       obj_id);\n\t\tif (err)\n\t\t\tgoto err;\n\n\t\tevent_sub = kzalloc(sizeof(*event_sub), GFP_KERNEL);\n\t\tif (!event_sub) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\tlist_add_tail(&event_sub->event_list, &sub_list);\n\t\tuverbs_uobject_get(&ev_file->uobj);\n\t\tif (use_eventfd) {\n\t\t\tevent_sub->eventfd =\n\t\t\t\teventfd_ctx_fdget(redirect_fd);\n\n\t\t\tif (IS_ERR(event_sub->eventfd)) {\n\t\t\t\terr = PTR_ERR(event_sub->eventfd);\n\t\t\t\tevent_sub->eventfd = NULL;\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t\tevent_sub->cookie = cookie;\n\t\tevent_sub->ev_file = ev_file;\n\t\t \n\t\tevent_sub->xa_key_level1 = key_level1;\n\t\tevent_sub->xa_key_level2 = obj_id;\n\t\tINIT_LIST_HEAD(&event_sub->obj_list);\n\t}\n\n\t \n\tlist_for_each_entry_safe(event_sub, tmp_sub, &sub_list, event_list) {\n\t\tstruct devx_event *event;\n\t\tstruct devx_obj_event *obj_event;\n\n\t\tlist_del_init(&event_sub->event_list);\n\n\t\tspin_lock_irq(&ev_file->lock);\n\t\tlist_add_tail_rcu(&event_sub->file_list,\n\t\t\t\t  &ev_file->subscribed_events_list);\n\t\tspin_unlock_irq(&ev_file->lock);\n\n\t\tevent = xa_load(&devx_event_table->event_xa,\n\t\t\t\tevent_sub->xa_key_level1);\n\t\tWARN_ON(!event);\n\n\t\tif (!obj) {\n\t\t\tlist_add_tail_rcu(&event_sub->xa_list,\n\t\t\t\t\t  &event->unaffiliated_list);\n\t\t\tcontinue;\n\t\t}\n\n\t\tobj_event = xa_load(&event->object_ids, obj_id);\n\t\tWARN_ON(!obj_event);\n\t\tlist_add_tail_rcu(&event_sub->xa_list,\n\t\t\t\t  &obj_event->obj_sub_list);\n\t\tlist_add_tail_rcu(&event_sub->obj_list,\n\t\t\t\t  &obj->event_sub);\n\t}\n\n\tmutex_unlock(&devx_event_table->event_xa_lock);\n\treturn 0;\n\nerr:\n\tlist_for_each_entry_safe(event_sub, tmp_sub, &sub_list, event_list) {\n\t\tlist_del(&event_sub->event_list);\n\n\t\tsubscribe_event_xa_dealloc(devx_event_table,\n\t\t\t\t\t   event_sub->xa_key_level1,\n\t\t\t\t\t   obj,\n\t\t\t\t\t   obj_id);\n\n\t\tif (event_sub->eventfd)\n\t\t\teventfd_ctx_put(event_sub->eventfd);\n\t\tuverbs_uobject_put(&event_sub->ev_file->uobj);\n\t\tkfree(event_sub);\n\t}\n\n\tmutex_unlock(&devx_event_table->event_xa_lock);\n\treturn err;\n}\n\nstatic int devx_umem_get(struct mlx5_ib_dev *dev, struct ib_ucontext *ucontext,\n\t\t\t struct uverbs_attr_bundle *attrs,\n\t\t\t struct devx_umem *obj, u32 access_flags)\n{\n\tu64 addr;\n\tsize_t size;\n\tint err;\n\n\tif (uverbs_copy_from(&addr, attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_ADDR) ||\n\t    uverbs_copy_from(&size, attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_LEN))\n\t\treturn -EFAULT;\n\n\terr = ib_check_mr_access(&dev->ib_dev, access_flags);\n\tif (err)\n\t\treturn err;\n\n\tif (uverbs_attr_is_valid(attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_DMABUF_FD)) {\n\t\tstruct ib_umem_dmabuf *umem_dmabuf;\n\t\tint dmabuf_fd;\n\n\t\terr = uverbs_get_raw_fd(&dmabuf_fd, attrs,\n\t\t\t\t\tMLX5_IB_ATTR_DEVX_UMEM_REG_DMABUF_FD);\n\t\tif (err)\n\t\t\treturn -EFAULT;\n\n\t\tumem_dmabuf = ib_umem_dmabuf_get_pinned(\n\t\t\t&dev->ib_dev, addr, size, dmabuf_fd, access_flags);\n\t\tif (IS_ERR(umem_dmabuf))\n\t\t\treturn PTR_ERR(umem_dmabuf);\n\t\tobj->umem = &umem_dmabuf->umem;\n\t} else {\n\t\tobj->umem = ib_umem_get(&dev->ib_dev, addr, size, access_flags);\n\t\tif (IS_ERR(obj->umem))\n\t\t\treturn PTR_ERR(obj->umem);\n\t}\n\treturn 0;\n}\n\nstatic unsigned int devx_umem_find_best_pgsize(struct ib_umem *umem,\n\t\t\t\t\t       unsigned long pgsz_bitmap)\n{\n\tunsigned long page_size;\n\n\t \n\tpgsz_bitmap &= GENMASK_ULL(max_t(u64, order_base_2(umem->length),\n\t\t\t\t\t PAGE_SHIFT),\n\t\t\t\t   MLX5_ADAPTER_PAGE_SHIFT);\n\tif (!pgsz_bitmap)\n\t\treturn 0;\n\n\tpage_size = ib_umem_find_best_pgoff(umem, pgsz_bitmap, U64_MAX);\n\tif (!page_size)\n\t\treturn 0;\n\n\t \n\twhile ((ib_umem_dma_offset(umem, page_size) != 0 ||\n\t\t(umem->length % page_size) != 0) &&\n\t\tpage_size > PAGE_SIZE)\n\t\tpage_size /= 2;\n\n\treturn page_size;\n}\n\nstatic int devx_umem_reg_cmd_alloc(struct mlx5_ib_dev *dev,\n\t\t\t\t   struct uverbs_attr_bundle *attrs,\n\t\t\t\t   struct devx_umem *obj,\n\t\t\t\t   struct devx_umem_reg_cmd *cmd,\n\t\t\t\t   int access)\n{\n\tunsigned long pgsz_bitmap;\n\tunsigned int page_size;\n\t__be64 *mtt;\n\tvoid *umem;\n\tint ret;\n\n\t \n\tret = uverbs_get_const_default(&pgsz_bitmap, attrs,\n\t\t\tMLX5_IB_ATTR_DEVX_UMEM_REG_PGSZ_BITMAP,\n\t\t\tGENMASK_ULL(63,\n\t\t\t\t    min(PAGE_SHIFT, MLX5_ADAPTER_PAGE_SHIFT)));\n\tif (ret)\n\t\treturn ret;\n\n\tpage_size = devx_umem_find_best_pgsize(obj->umem, pgsz_bitmap);\n\tif (!page_size)\n\t\treturn -EINVAL;\n\n\tcmd->inlen = MLX5_ST_SZ_BYTES(create_umem_in) +\n\t\t     (MLX5_ST_SZ_BYTES(mtt) *\n\t\t      ib_umem_num_dma_blocks(obj->umem, page_size));\n\tcmd->in = uverbs_zalloc(attrs, cmd->inlen);\n\tif (IS_ERR(cmd->in))\n\t\treturn PTR_ERR(cmd->in);\n\n\tumem = MLX5_ADDR_OF(create_umem_in, cmd->in, umem);\n\tmtt = (__be64 *)MLX5_ADDR_OF(umem, umem, mtt);\n\n\tMLX5_SET(create_umem_in, cmd->in, opcode, MLX5_CMD_OP_CREATE_UMEM);\n\tMLX5_SET64(umem, umem, num_of_mtt,\n\t\t   ib_umem_num_dma_blocks(obj->umem, page_size));\n\tMLX5_SET(umem, umem, log_page_size,\n\t\t order_base_2(page_size) - MLX5_ADAPTER_PAGE_SHIFT);\n\tMLX5_SET(umem, umem, page_offset,\n\t\t ib_umem_dma_offset(obj->umem, page_size));\n\n\tif (mlx5_umem_needs_ats(dev, obj->umem, access))\n\t\tMLX5_SET(umem, umem, ats, 1);\n\n\tmlx5_ib_populate_pas(obj->umem, page_size, mtt,\n\t\t\t     (obj->umem->writable ? MLX5_IB_MTT_WRITE : 0) |\n\t\t\t\t     MLX5_IB_MTT_READ);\n\treturn 0;\n}\n\nstatic int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_UMEM_REG)(\n\tstruct uverbs_attr_bundle *attrs)\n{\n\tstruct devx_umem_reg_cmd cmd;\n\tstruct devx_umem *obj;\n\tstruct ib_uobject *uobj = uverbs_attr_get_uobject(\n\t\tattrs, MLX5_IB_ATTR_DEVX_UMEM_REG_HANDLE);\n\tu32 obj_id;\n\tstruct mlx5_ib_ucontext *c = rdma_udata_to_drv_context(\n\t\t&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);\n\tstruct mlx5_ib_dev *dev = to_mdev(c->ibucontext.device);\n\tint access_flags;\n\tint err;\n\n\tif (!c->devx_uid)\n\t\treturn -EINVAL;\n\n\terr = uverbs_get_flags32(&access_flags, attrs,\n\t\t\t\t MLX5_IB_ATTR_DEVX_UMEM_REG_ACCESS,\n\t\t\t\t IB_ACCESS_LOCAL_WRITE |\n\t\t\t\t IB_ACCESS_REMOTE_WRITE |\n\t\t\t\t IB_ACCESS_REMOTE_READ |\n\t\t\t\t IB_ACCESS_RELAXED_ORDERING);\n\tif (err)\n\t\treturn err;\n\n\tobj = kzalloc(sizeof(struct devx_umem), GFP_KERNEL);\n\tif (!obj)\n\t\treturn -ENOMEM;\n\n\terr = devx_umem_get(dev, &c->ibucontext, attrs, obj, access_flags);\n\tif (err)\n\t\tgoto err_obj_free;\n\n\terr = devx_umem_reg_cmd_alloc(dev, attrs, obj, &cmd, access_flags);\n\tif (err)\n\t\tgoto err_umem_release;\n\n\tMLX5_SET(create_umem_in, cmd.in, uid, c->devx_uid);\n\terr = mlx5_cmd_exec(dev->mdev, cmd.in, cmd.inlen, cmd.out,\n\t\t\t    sizeof(cmd.out));\n\tif (err)\n\t\tgoto err_umem_release;\n\n\tobj->mdev = dev->mdev;\n\tuobj->object = obj;\n\tdevx_obj_build_destroy_cmd(cmd.in, cmd.out, obj->dinbox, &obj->dinlen, &obj_id);\n\tuverbs_finalize_uobj_create(attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_HANDLE);\n\n\terr = uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_OUT_ID, &obj_id,\n\t\t\t     sizeof(obj_id));\n\treturn err;\n\nerr_umem_release:\n\tib_umem_release(obj->umem);\nerr_obj_free:\n\tkfree(obj);\n\treturn err;\n}\n\nstatic int devx_umem_cleanup(struct ib_uobject *uobject,\n\t\t\t     enum rdma_remove_reason why,\n\t\t\t     struct uverbs_attr_bundle *attrs)\n{\n\tstruct devx_umem *obj = uobject->object;\n\tu32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)];\n\tint err;\n\n\terr = mlx5_cmd_exec(obj->mdev, obj->dinbox, obj->dinlen, out, sizeof(out));\n\tif (err)\n\t\treturn err;\n\n\tib_umem_release(obj->umem);\n\tkfree(obj);\n\treturn 0;\n}\n\nstatic bool is_unaffiliated_event(struct mlx5_core_dev *dev,\n\t\t\t\t  unsigned long event_type)\n{\n\t__be64 *unaff_events;\n\tint mask_entry;\n\tint mask_bit;\n\n\tif (!MLX5_CAP_GEN(dev, event_cap))\n\t\treturn is_legacy_unaffiliated_event_num(event_type);\n\n\tunaff_events = MLX5_CAP_DEV_EVENT(dev,\n\t\t\t\t\t  user_unaffiliated_events);\n\tWARN_ON(event_type > MAX_SUPP_EVENT_NUM);\n\n\tmask_entry = event_type / 64;\n\tmask_bit = event_type % 64;\n\n\tif (!(be64_to_cpu(unaff_events[mask_entry]) & (1ull << mask_bit)))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic u32 devx_get_obj_id_from_event(unsigned long event_type, void *data)\n{\n\tstruct mlx5_eqe *eqe = data;\n\tu32 obj_id = 0;\n\n\tswitch (event_type) {\n\tcase MLX5_EVENT_TYPE_SRQ_CATAS_ERROR:\n\tcase MLX5_EVENT_TYPE_SRQ_RQ_LIMIT:\n\tcase MLX5_EVENT_TYPE_PATH_MIG:\n\tcase MLX5_EVENT_TYPE_COMM_EST:\n\tcase MLX5_EVENT_TYPE_SQ_DRAINED:\n\tcase MLX5_EVENT_TYPE_SRQ_LAST_WQE:\n\tcase MLX5_EVENT_TYPE_WQ_CATAS_ERROR:\n\tcase MLX5_EVENT_TYPE_PATH_MIG_FAILED:\n\tcase MLX5_EVENT_TYPE_WQ_INVAL_REQ_ERROR:\n\tcase MLX5_EVENT_TYPE_WQ_ACCESS_ERROR:\n\t\tobj_id = be32_to_cpu(eqe->data.qp_srq.qp_srq_n) & 0xffffff;\n\t\tbreak;\n\tcase MLX5_EVENT_TYPE_XRQ_ERROR:\n\t\tobj_id = be32_to_cpu(eqe->data.xrq_err.type_xrqn) & 0xffffff;\n\t\tbreak;\n\tcase MLX5_EVENT_TYPE_DCT_DRAINED:\n\tcase MLX5_EVENT_TYPE_DCT_KEY_VIOLATION:\n\t\tobj_id = be32_to_cpu(eqe->data.dct.dctn) & 0xffffff;\n\t\tbreak;\n\tcase MLX5_EVENT_TYPE_CQ_ERROR:\n\t\tobj_id = be32_to_cpu(eqe->data.cq_err.cqn) & 0xffffff;\n\t\tbreak;\n\tdefault:\n\t\tobj_id = MLX5_GET(affiliated_event_header, &eqe->data, obj_id);\n\t\tbreak;\n\t}\n\n\treturn obj_id;\n}\n\nstatic int deliver_event(struct devx_event_subscription *event_sub,\n\t\t\t const void *data)\n{\n\tstruct devx_async_event_file *ev_file;\n\tstruct devx_async_event_data *event_data;\n\tunsigned long flags;\n\n\tev_file = event_sub->ev_file;\n\n\tif (ev_file->omit_data) {\n\t\tspin_lock_irqsave(&ev_file->lock, flags);\n\t\tif (!list_empty(&event_sub->event_list) ||\n\t\t    ev_file->is_destroyed) {\n\t\t\tspin_unlock_irqrestore(&ev_file->lock, flags);\n\t\t\treturn 0;\n\t\t}\n\n\t\tlist_add_tail(&event_sub->event_list, &ev_file->event_list);\n\t\tspin_unlock_irqrestore(&ev_file->lock, flags);\n\t\twake_up_interruptible(&ev_file->poll_wait);\n\t\treturn 0;\n\t}\n\n\tevent_data = kzalloc(sizeof(*event_data) + sizeof(struct mlx5_eqe),\n\t\t\t     GFP_ATOMIC);\n\tif (!event_data) {\n\t\tspin_lock_irqsave(&ev_file->lock, flags);\n\t\tev_file->is_overflow_err = 1;\n\t\tspin_unlock_irqrestore(&ev_file->lock, flags);\n\t\treturn -ENOMEM;\n\t}\n\n\tevent_data->hdr.cookie = event_sub->cookie;\n\tmemcpy(event_data->hdr.out_data, data, sizeof(struct mlx5_eqe));\n\n\tspin_lock_irqsave(&ev_file->lock, flags);\n\tif (!ev_file->is_destroyed)\n\t\tlist_add_tail(&event_data->list, &ev_file->event_list);\n\telse\n\t\tkfree(event_data);\n\tspin_unlock_irqrestore(&ev_file->lock, flags);\n\twake_up_interruptible(&ev_file->poll_wait);\n\n\treturn 0;\n}\n\nstatic void dispatch_event_fd(struct list_head *fd_list,\n\t\t\t      const void *data)\n{\n\tstruct devx_event_subscription *item;\n\n\tlist_for_each_entry_rcu(item, fd_list, xa_list) {\n\t\tif (item->eventfd)\n\t\t\teventfd_signal(item->eventfd, 1);\n\t\telse\n\t\t\tdeliver_event(item, data);\n\t}\n}\n\nstatic int devx_event_notifier(struct notifier_block *nb,\n\t\t\t       unsigned long event_type, void *data)\n{\n\tstruct mlx5_devx_event_table *table;\n\tstruct mlx5_ib_dev *dev;\n\tstruct devx_event *event;\n\tstruct devx_obj_event *obj_event;\n\tu16 obj_type = 0;\n\tbool is_unaffiliated;\n\tu32 obj_id;\n\n\t \n\tif (event_type == MLX5_EVENT_TYPE_CMD ||\n\t    event_type == MLX5_EVENT_TYPE_PAGE_REQUEST)\n\t\treturn NOTIFY_OK;\n\n\ttable = container_of(nb, struct mlx5_devx_event_table, devx_nb.nb);\n\tdev = container_of(table, struct mlx5_ib_dev, devx_event_table);\n\tis_unaffiliated = is_unaffiliated_event(dev->mdev, event_type);\n\n\tif (!is_unaffiliated)\n\t\tobj_type = get_event_obj_type(event_type, data);\n\n\trcu_read_lock();\n\tevent = xa_load(&table->event_xa, event_type | (obj_type << 16));\n\tif (!event) {\n\t\trcu_read_unlock();\n\t\treturn NOTIFY_DONE;\n\t}\n\n\tif (is_unaffiliated) {\n\t\tdispatch_event_fd(&event->unaffiliated_list, data);\n\t\trcu_read_unlock();\n\t\treturn NOTIFY_OK;\n\t}\n\n\tobj_id = devx_get_obj_id_from_event(event_type, data);\n\tobj_event = xa_load(&event->object_ids, obj_id);\n\tif (!obj_event) {\n\t\trcu_read_unlock();\n\t\treturn NOTIFY_DONE;\n\t}\n\n\tdispatch_event_fd(&obj_event->obj_sub_list, data);\n\n\trcu_read_unlock();\n\treturn NOTIFY_OK;\n}\n\nint mlx5_ib_devx_init(struct mlx5_ib_dev *dev)\n{\n\tstruct mlx5_devx_event_table *table = &dev->devx_event_table;\n\tint uid;\n\n\tuid = mlx5_ib_devx_create(dev, false);\n\tif (uid > 0) {\n\t\tdev->devx_whitelist_uid = uid;\n\t\txa_init(&table->event_xa);\n\t\tmutex_init(&table->event_xa_lock);\n\t\tMLX5_NB_INIT(&table->devx_nb, devx_event_notifier, NOTIFY_ANY);\n\t\tmlx5_eq_notifier_register(dev->mdev, &table->devx_nb);\n\t}\n\n\treturn 0;\n}\n\nvoid mlx5_ib_devx_cleanup(struct mlx5_ib_dev *dev)\n{\n\tstruct mlx5_devx_event_table *table = &dev->devx_event_table;\n\tstruct devx_event_subscription *sub, *tmp;\n\tstruct devx_event *event;\n\tvoid *entry;\n\tunsigned long id;\n\n\tif (dev->devx_whitelist_uid) {\n\t\tmlx5_eq_notifier_unregister(dev->mdev, &table->devx_nb);\n\t\tmutex_lock(&dev->devx_event_table.event_xa_lock);\n\t\txa_for_each(&table->event_xa, id, entry) {\n\t\t\tevent = entry;\n\t\t\tlist_for_each_entry_safe(\n\t\t\t\tsub, tmp, &event->unaffiliated_list, xa_list)\n\t\t\t\tdevx_cleanup_subscription(dev, sub);\n\t\t\tkfree(entry);\n\t\t}\n\t\tmutex_unlock(&dev->devx_event_table.event_xa_lock);\n\t\txa_destroy(&table->event_xa);\n\n\t\tmlx5_ib_devx_destroy(dev, dev->devx_whitelist_uid);\n\t}\n}\n\nstatic ssize_t devx_async_cmd_event_read(struct file *filp, char __user *buf,\n\t\t\t\t\t size_t count, loff_t *pos)\n{\n\tstruct devx_async_cmd_event_file *comp_ev_file = filp->private_data;\n\tstruct devx_async_event_queue *ev_queue = &comp_ev_file->ev_queue;\n\tstruct devx_async_data *event;\n\tint ret = 0;\n\tsize_t eventsz;\n\n\tspin_lock_irq(&ev_queue->lock);\n\n\twhile (list_empty(&ev_queue->event_list)) {\n\t\tspin_unlock_irq(&ev_queue->lock);\n\n\t\tif (filp->f_flags & O_NONBLOCK)\n\t\t\treturn -EAGAIN;\n\n\t\tif (wait_event_interruptible(\n\t\t\t    ev_queue->poll_wait,\n\t\t\t    (!list_empty(&ev_queue->event_list) ||\n\t\t\t     ev_queue->is_destroyed))) {\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\n\t\tspin_lock_irq(&ev_queue->lock);\n\t\tif (ev_queue->is_destroyed) {\n\t\t\tspin_unlock_irq(&ev_queue->lock);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\tevent = list_entry(ev_queue->event_list.next,\n\t\t\t   struct devx_async_data, list);\n\teventsz = event->cmd_out_len +\n\t\t\tsizeof(struct mlx5_ib_uapi_devx_async_cmd_hdr);\n\n\tif (eventsz > count) {\n\t\tspin_unlock_irq(&ev_queue->lock);\n\t\treturn -ENOSPC;\n\t}\n\n\tlist_del(ev_queue->event_list.next);\n\tspin_unlock_irq(&ev_queue->lock);\n\n\tif (copy_to_user(buf, &event->hdr, eventsz))\n\t\tret = -EFAULT;\n\telse\n\t\tret = eventsz;\n\n\tatomic_sub(event->cmd_out_len, &ev_queue->bytes_in_use);\n\tkvfree(event);\n\treturn ret;\n}\n\nstatic __poll_t devx_async_cmd_event_poll(struct file *filp,\n\t\t\t\t\t      struct poll_table_struct *wait)\n{\n\tstruct devx_async_cmd_event_file *comp_ev_file = filp->private_data;\n\tstruct devx_async_event_queue *ev_queue = &comp_ev_file->ev_queue;\n\t__poll_t pollflags = 0;\n\n\tpoll_wait(filp, &ev_queue->poll_wait, wait);\n\n\tspin_lock_irq(&ev_queue->lock);\n\tif (ev_queue->is_destroyed)\n\t\tpollflags = EPOLLIN | EPOLLRDNORM | EPOLLRDHUP;\n\telse if (!list_empty(&ev_queue->event_list))\n\t\tpollflags = EPOLLIN | EPOLLRDNORM;\n\tspin_unlock_irq(&ev_queue->lock);\n\n\treturn pollflags;\n}\n\nstatic const struct file_operations devx_async_cmd_event_fops = {\n\t.owner\t = THIS_MODULE,\n\t.read\t = devx_async_cmd_event_read,\n\t.poll    = devx_async_cmd_event_poll,\n\t.release = uverbs_uobject_fd_release,\n\t.llseek\t = no_llseek,\n};\n\nstatic ssize_t devx_async_event_read(struct file *filp, char __user *buf,\n\t\t\t\t     size_t count, loff_t *pos)\n{\n\tstruct devx_async_event_file *ev_file = filp->private_data;\n\tstruct devx_event_subscription *event_sub;\n\tstruct devx_async_event_data *event;\n\tint ret = 0;\n\tsize_t eventsz;\n\tbool omit_data;\n\tvoid *event_data;\n\n\tomit_data = ev_file->omit_data;\n\n\tspin_lock_irq(&ev_file->lock);\n\n\tif (ev_file->is_overflow_err) {\n\t\tev_file->is_overflow_err = 0;\n\t\tspin_unlock_irq(&ev_file->lock);\n\t\treturn -EOVERFLOW;\n\t}\n\n\n\twhile (list_empty(&ev_file->event_list)) {\n\t\tspin_unlock_irq(&ev_file->lock);\n\n\t\tif (filp->f_flags & O_NONBLOCK)\n\t\t\treturn -EAGAIN;\n\n\t\tif (wait_event_interruptible(ev_file->poll_wait,\n\t\t\t    (!list_empty(&ev_file->event_list) ||\n\t\t\t     ev_file->is_destroyed))) {\n\t\t\treturn -ERESTARTSYS;\n\t\t}\n\n\t\tspin_lock_irq(&ev_file->lock);\n\t\tif (ev_file->is_destroyed) {\n\t\t\tspin_unlock_irq(&ev_file->lock);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\tif (omit_data) {\n\t\tevent_sub = list_first_entry(&ev_file->event_list,\n\t\t\t\t\tstruct devx_event_subscription,\n\t\t\t\t\tevent_list);\n\t\teventsz = sizeof(event_sub->cookie);\n\t\tevent_data = &event_sub->cookie;\n\t} else {\n\t\tevent = list_first_entry(&ev_file->event_list,\n\t\t\t\t      struct devx_async_event_data, list);\n\t\teventsz = sizeof(struct mlx5_eqe) +\n\t\t\tsizeof(struct mlx5_ib_uapi_devx_async_event_hdr);\n\t\tevent_data = &event->hdr;\n\t}\n\n\tif (eventsz > count) {\n\t\tspin_unlock_irq(&ev_file->lock);\n\t\treturn -EINVAL;\n\t}\n\n\tif (omit_data)\n\t\tlist_del_init(&event_sub->event_list);\n\telse\n\t\tlist_del(&event->list);\n\n\tspin_unlock_irq(&ev_file->lock);\n\n\tif (copy_to_user(buf, event_data, eventsz))\n\t\t \n\t\tret = -EFAULT;\n\telse\n\t\tret = eventsz;\n\n\tif (!omit_data)\n\t\tkfree(event);\n\treturn ret;\n}\n\nstatic __poll_t devx_async_event_poll(struct file *filp,\n\t\t\t\t      struct poll_table_struct *wait)\n{\n\tstruct devx_async_event_file *ev_file = filp->private_data;\n\t__poll_t pollflags = 0;\n\n\tpoll_wait(filp, &ev_file->poll_wait, wait);\n\n\tspin_lock_irq(&ev_file->lock);\n\tif (ev_file->is_destroyed)\n\t\tpollflags = EPOLLIN | EPOLLRDNORM | EPOLLRDHUP;\n\telse if (!list_empty(&ev_file->event_list))\n\t\tpollflags = EPOLLIN | EPOLLRDNORM;\n\tspin_unlock_irq(&ev_file->lock);\n\n\treturn pollflags;\n}\n\nstatic void devx_free_subscription(struct rcu_head *rcu)\n{\n\tstruct devx_event_subscription *event_sub =\n\t\tcontainer_of(rcu, struct devx_event_subscription, rcu);\n\n\tif (event_sub->eventfd)\n\t\teventfd_ctx_put(event_sub->eventfd);\n\tuverbs_uobject_put(&event_sub->ev_file->uobj);\n\tkfree(event_sub);\n}\n\nstatic const struct file_operations devx_async_event_fops = {\n\t.owner\t = THIS_MODULE,\n\t.read\t = devx_async_event_read,\n\t.poll    = devx_async_event_poll,\n\t.release = uverbs_uobject_fd_release,\n\t.llseek\t = no_llseek,\n};\n\nstatic void devx_async_cmd_event_destroy_uobj(struct ib_uobject *uobj,\n\t\t\t\t\t      enum rdma_remove_reason why)\n{\n\tstruct devx_async_cmd_event_file *comp_ev_file =\n\t\tcontainer_of(uobj, struct devx_async_cmd_event_file,\n\t\t\t     uobj);\n\tstruct devx_async_event_queue *ev_queue = &comp_ev_file->ev_queue;\n\tstruct devx_async_data *entry, *tmp;\n\n\tspin_lock_irq(&ev_queue->lock);\n\tev_queue->is_destroyed = 1;\n\tspin_unlock_irq(&ev_queue->lock);\n\twake_up_interruptible(&ev_queue->poll_wait);\n\n\tmlx5_cmd_cleanup_async_ctx(&comp_ev_file->async_ctx);\n\n\tspin_lock_irq(&comp_ev_file->ev_queue.lock);\n\tlist_for_each_entry_safe(entry, tmp,\n\t\t\t\t &comp_ev_file->ev_queue.event_list, list) {\n\t\tlist_del(&entry->list);\n\t\tkvfree(entry);\n\t}\n\tspin_unlock_irq(&comp_ev_file->ev_queue.lock);\n};\n\nstatic void devx_async_event_destroy_uobj(struct ib_uobject *uobj,\n\t\t\t\t\t  enum rdma_remove_reason why)\n{\n\tstruct devx_async_event_file *ev_file =\n\t\tcontainer_of(uobj, struct devx_async_event_file,\n\t\t\t     uobj);\n\tstruct devx_event_subscription *event_sub, *event_sub_tmp;\n\tstruct mlx5_ib_dev *dev = ev_file->dev;\n\n\tspin_lock_irq(&ev_file->lock);\n\tev_file->is_destroyed = 1;\n\n\t \n\tif (ev_file->omit_data) {\n\t\tstruct devx_event_subscription *event_sub, *tmp;\n\n\t\tlist_for_each_entry_safe(event_sub, tmp, &ev_file->event_list,\n\t\t\t\t\t event_list)\n\t\t\tlist_del_init(&event_sub->event_list);\n\n\t} else {\n\t\tstruct devx_async_event_data *entry, *tmp;\n\n\t\tlist_for_each_entry_safe(entry, tmp, &ev_file->event_list,\n\t\t\t\t\t list) {\n\t\t\tlist_del(&entry->list);\n\t\t\tkfree(entry);\n\t\t}\n\t}\n\n\tspin_unlock_irq(&ev_file->lock);\n\twake_up_interruptible(&ev_file->poll_wait);\n\n\tmutex_lock(&dev->devx_event_table.event_xa_lock);\n\t \n\tlist_for_each_entry_safe(event_sub, event_sub_tmp,\n\t\t\t\t &ev_file->subscribed_events_list, file_list) {\n\t\tdevx_cleanup_subscription(dev, event_sub);\n\t\tlist_del_rcu(&event_sub->file_list);\n\t\t \n\t\tcall_rcu(&event_sub->rcu, devx_free_subscription);\n\t}\n\tmutex_unlock(&dev->devx_event_table.event_xa_lock);\n\n\tput_device(&dev->ib_dev.dev);\n};\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_UMEM_REG,\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_UMEM_REG_HANDLE,\n\t\t\tMLX5_IB_OBJECT_DEVX_UMEM,\n\t\t\tUVERBS_ACCESS_NEW,\n\t\t\tUA_MANDATORY),\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_UMEM_REG_ADDR,\n\t\t\t   UVERBS_ATTR_TYPE(u64),\n\t\t\t   UA_MANDATORY),\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_UMEM_REG_LEN,\n\t\t\t   UVERBS_ATTR_TYPE(u64),\n\t\t\t   UA_MANDATORY),\n\tUVERBS_ATTR_RAW_FD(MLX5_IB_ATTR_DEVX_UMEM_REG_DMABUF_FD,\n\t\t\t   UA_OPTIONAL),\n\tUVERBS_ATTR_FLAGS_IN(MLX5_IB_ATTR_DEVX_UMEM_REG_ACCESS,\n\t\t\t     enum ib_access_flags),\n\tUVERBS_ATTR_CONST_IN(MLX5_IB_ATTR_DEVX_UMEM_REG_PGSZ_BITMAP,\n\t\t\t     u64),\n\tUVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_DEVX_UMEM_REG_OUT_ID,\n\t\t\t    UVERBS_ATTR_TYPE(u32),\n\t\t\t    UA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD_DESTROY(\n\tMLX5_IB_METHOD_DEVX_UMEM_DEREG,\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_UMEM_DEREG_HANDLE,\n\t\t\tMLX5_IB_OBJECT_DEVX_UMEM,\n\t\t\tUVERBS_ACCESS_DESTROY,\n\t\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_QUERY_EQN,\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_QUERY_EQN_USER_VEC,\n\t\t\t   UVERBS_ATTR_TYPE(u32),\n\t\t\t   UA_MANDATORY),\n\tUVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_DEVX_QUERY_EQN_DEV_EQN,\n\t\t\t    UVERBS_ATTR_TYPE(u32),\n\t\t\t    UA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_QUERY_UAR,\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_QUERY_UAR_USER_IDX,\n\t\t\t   UVERBS_ATTR_TYPE(u32),\n\t\t\t   UA_MANDATORY),\n\tUVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_DEVX_QUERY_UAR_DEV_IDX,\n\t\t\t    UVERBS_ATTR_TYPE(u32),\n\t\t\t    UA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_OTHER,\n\tUVERBS_ATTR_PTR_IN(\n\t\tMLX5_IB_ATTR_DEVX_OTHER_CMD_IN,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),\n\t\tUA_MANDATORY,\n\t\tUA_ALLOC_AND_COPY),\n\tUVERBS_ATTR_PTR_OUT(\n\t\tMLX5_IB_ATTR_DEVX_OTHER_CMD_OUT,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),\n\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_OBJ_CREATE,\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_CREATE_HANDLE,\n\t\t\tMLX5_IB_OBJECT_DEVX_OBJ,\n\t\t\tUVERBS_ACCESS_NEW,\n\t\t\tUA_MANDATORY),\n\tUVERBS_ATTR_PTR_IN(\n\t\tMLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_IN,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),\n\t\tUA_MANDATORY,\n\t\tUA_ALLOC_AND_COPY),\n\tUVERBS_ATTR_PTR_OUT(\n\t\tMLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_OUT,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),\n\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD_DESTROY(\n\tMLX5_IB_METHOD_DEVX_OBJ_DESTROY,\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_DESTROY_HANDLE,\n\t\t\tMLX5_IB_OBJECT_DEVX_OBJ,\n\t\t\tUVERBS_ACCESS_DESTROY,\n\t\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_OBJ_MODIFY,\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_MODIFY_HANDLE,\n\t\t\tUVERBS_IDR_ANY_OBJECT,\n\t\t\tUVERBS_ACCESS_WRITE,\n\t\t\tUA_MANDATORY),\n\tUVERBS_ATTR_PTR_IN(\n\t\tMLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_IN,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),\n\t\tUA_MANDATORY,\n\t\tUA_ALLOC_AND_COPY),\n\tUVERBS_ATTR_PTR_OUT(\n\t\tMLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_OUT,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),\n\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_OBJ_QUERY,\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_QUERY_HANDLE,\n\t\t\tUVERBS_IDR_ANY_OBJECT,\n\t\t\tUVERBS_ACCESS_READ,\n\t\t\tUA_MANDATORY),\n\tUVERBS_ATTR_PTR_IN(\n\t\tMLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_IN,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),\n\t\tUA_MANDATORY,\n\t\tUA_ALLOC_AND_COPY),\n\tUVERBS_ATTR_PTR_OUT(\n\t\tMLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_OUT,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),\n\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_OBJ_ASYNC_QUERY,\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_QUERY_HANDLE,\n\t\t\tUVERBS_IDR_ANY_OBJECT,\n\t\t\tUVERBS_ACCESS_READ,\n\t\t\tUA_MANDATORY),\n\tUVERBS_ATTR_PTR_IN(\n\t\tMLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_IN,\n\t\tUVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),\n\t\tUA_MANDATORY,\n\t\tUA_ALLOC_AND_COPY),\n\tUVERBS_ATTR_CONST_IN(MLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_OUT_LEN,\n\t\tu16, UA_MANDATORY),\n\tUVERBS_ATTR_FD(MLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_FD,\n\t\tMLX5_IB_OBJECT_DEVX_ASYNC_CMD_FD,\n\t\tUVERBS_ACCESS_READ,\n\t\tUA_MANDATORY),\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_OBJ_QUERY_ASYNC_WR_ID,\n\t\tUVERBS_ATTR_TYPE(u64),\n\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_SUBSCRIBE_EVENT,\n\tUVERBS_ATTR_FD(MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_FD_HANDLE,\n\t\tMLX5_IB_OBJECT_DEVX_ASYNC_EVENT_FD,\n\t\tUVERBS_ACCESS_READ,\n\t\tUA_MANDATORY),\n\tUVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_OBJ_HANDLE,\n\t\tMLX5_IB_OBJECT_DEVX_OBJ,\n\t\tUVERBS_ACCESS_READ,\n\t\tUA_OPTIONAL),\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_TYPE_NUM_LIST,\n\t\tUVERBS_ATTR_MIN_SIZE(sizeof(u16)),\n\t\tUA_MANDATORY,\n\t\tUA_ALLOC_AND_COPY),\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_COOKIE,\n\t\tUVERBS_ATTR_TYPE(u64),\n\t\tUA_OPTIONAL),\n\tUVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_SUBSCRIBE_EVENT_FD_NUM,\n\t\tUVERBS_ATTR_TYPE(u32),\n\t\tUA_OPTIONAL));\n\nDECLARE_UVERBS_GLOBAL_METHODS(MLX5_IB_OBJECT_DEVX,\n\t\t\t      &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OTHER),\n\t\t\t      &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_QUERY_UAR),\n\t\t\t      &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_QUERY_EQN),\n\t\t\t      &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_SUBSCRIBE_EVENT));\n\nDECLARE_UVERBS_NAMED_OBJECT(MLX5_IB_OBJECT_DEVX_OBJ,\n\t\t\t    UVERBS_TYPE_ALLOC_IDR(devx_obj_cleanup),\n\t\t\t    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_CREATE),\n\t\t\t    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_DESTROY),\n\t\t\t    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_MODIFY),\n\t\t\t    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_QUERY),\n\t\t\t    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_ASYNC_QUERY));\n\nDECLARE_UVERBS_NAMED_OBJECT(MLX5_IB_OBJECT_DEVX_UMEM,\n\t\t\t    UVERBS_TYPE_ALLOC_IDR(devx_umem_cleanup),\n\t\t\t    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_UMEM_REG),\n\t\t\t    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_UMEM_DEREG));\n\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_ASYNC_CMD_FD_ALLOC,\n\tUVERBS_ATTR_FD(MLX5_IB_ATTR_DEVX_ASYNC_CMD_FD_ALLOC_HANDLE,\n\t\t\tMLX5_IB_OBJECT_DEVX_ASYNC_CMD_FD,\n\t\t\tUVERBS_ACCESS_NEW,\n\t\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_OBJECT(\n\tMLX5_IB_OBJECT_DEVX_ASYNC_CMD_FD,\n\tUVERBS_TYPE_ALLOC_FD(sizeof(struct devx_async_cmd_event_file),\n\t\t\t     devx_async_cmd_event_destroy_uobj,\n\t\t\t     &devx_async_cmd_event_fops, \"[devx_async_cmd]\",\n\t\t\t     O_RDONLY),\n\t&UVERBS_METHOD(MLX5_IB_METHOD_DEVX_ASYNC_CMD_FD_ALLOC));\n\nDECLARE_UVERBS_NAMED_METHOD(\n\tMLX5_IB_METHOD_DEVX_ASYNC_EVENT_FD_ALLOC,\n\tUVERBS_ATTR_FD(MLX5_IB_ATTR_DEVX_ASYNC_EVENT_FD_ALLOC_HANDLE,\n\t\t\tMLX5_IB_OBJECT_DEVX_ASYNC_EVENT_FD,\n\t\t\tUVERBS_ACCESS_NEW,\n\t\t\tUA_MANDATORY),\n\tUVERBS_ATTR_FLAGS_IN(MLX5_IB_ATTR_DEVX_ASYNC_EVENT_FD_ALLOC_FLAGS,\n\t\t\tenum mlx5_ib_uapi_devx_create_event_channel_flags,\n\t\t\tUA_MANDATORY));\n\nDECLARE_UVERBS_NAMED_OBJECT(\n\tMLX5_IB_OBJECT_DEVX_ASYNC_EVENT_FD,\n\tUVERBS_TYPE_ALLOC_FD(sizeof(struct devx_async_event_file),\n\t\t\t     devx_async_event_destroy_uobj,\n\t\t\t     &devx_async_event_fops, \"[devx_async_event]\",\n\t\t\t     O_RDONLY),\n\t&UVERBS_METHOD(MLX5_IB_METHOD_DEVX_ASYNC_EVENT_FD_ALLOC));\n\nstatic bool devx_is_supported(struct ib_device *device)\n{\n\tstruct mlx5_ib_dev *dev = to_mdev(device);\n\n\treturn MLX5_CAP_GEN(dev->mdev, log_max_uctx);\n}\n\nconst struct uapi_definition mlx5_ib_devx_defs[] = {\n\tUAPI_DEF_CHAIN_OBJ_TREE_NAMED(\n\t\tMLX5_IB_OBJECT_DEVX,\n\t\tUAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),\n\tUAPI_DEF_CHAIN_OBJ_TREE_NAMED(\n\t\tMLX5_IB_OBJECT_DEVX_OBJ,\n\t\tUAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),\n\tUAPI_DEF_CHAIN_OBJ_TREE_NAMED(\n\t\tMLX5_IB_OBJECT_DEVX_UMEM,\n\t\tUAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),\n\tUAPI_DEF_CHAIN_OBJ_TREE_NAMED(\n\t\tMLX5_IB_OBJECT_DEVX_ASYNC_CMD_FD,\n\t\tUAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),\n\tUAPI_DEF_CHAIN_OBJ_TREE_NAMED(\n\t\tMLX5_IB_OBJECT_DEVX_ASYNC_EVENT_FD,\n\t\tUAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),\n\t{},\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}