{
  "module_name": "rtrs.c",
  "hash_id": "73558c9a1745b6463891ddeda85b0f7a0979b5dd3076c43715733899c4ef970f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/ulp/rtrs/rtrs.c",
  "human_readable_source": "\n \n#undef pr_fmt\n#define pr_fmt(fmt) KBUILD_MODNAME \" L\" __stringify(__LINE__) \": \" fmt\n\n#include <linux/module.h>\n#include <linux/inet.h>\n\n#include \"rtrs-pri.h\"\n#include \"rtrs-log.h\"\n\nMODULE_DESCRIPTION(\"RDMA Transport Core\");\nMODULE_LICENSE(\"GPL\");\n\nstruct rtrs_iu *rtrs_iu_alloc(u32 iu_num, size_t size, gfp_t gfp_mask,\n\t\t\t      struct ib_device *dma_dev,\n\t\t\t      enum dma_data_direction dir,\n\t\t\t      void (*done)(struct ib_cq *cq, struct ib_wc *wc))\n{\n\tstruct rtrs_iu *ius, *iu;\n\tint i;\n\n\tius = kcalloc(iu_num, sizeof(*ius), gfp_mask);\n\tif (!ius)\n\t\treturn NULL;\n\tfor (i = 0; i < iu_num; i++) {\n\t\tiu = &ius[i];\n\t\tiu->direction = dir;\n\t\tiu->buf = kzalloc(size, gfp_mask);\n\t\tif (!iu->buf)\n\t\t\tgoto err;\n\n\t\tiu->dma_addr = ib_dma_map_single(dma_dev, iu->buf, size, dir);\n\t\tif (ib_dma_mapping_error(dma_dev, iu->dma_addr)) {\n\t\t\tkfree(iu->buf);\n\t\t\tgoto err;\n\t\t}\n\n\t\tiu->cqe.done  = done;\n\t\tiu->size      = size;\n\t}\n\treturn ius;\nerr:\n\trtrs_iu_free(ius, dma_dev, i);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(rtrs_iu_alloc);\n\nvoid rtrs_iu_free(struct rtrs_iu *ius, struct ib_device *ibdev, u32 queue_num)\n{\n\tstruct rtrs_iu *iu;\n\tint i;\n\n\tif (!ius)\n\t\treturn;\n\n\tfor (i = 0; i < queue_num; i++) {\n\t\tiu = &ius[i];\n\t\tib_dma_unmap_single(ibdev, iu->dma_addr, iu->size, iu->direction);\n\t\tkfree(iu->buf);\n\t}\n\tkfree(ius);\n}\nEXPORT_SYMBOL_GPL(rtrs_iu_free);\n\nint rtrs_iu_post_recv(struct rtrs_con *con, struct rtrs_iu *iu)\n{\n\tstruct rtrs_path *path = con->path;\n\tstruct ib_recv_wr wr;\n\tstruct ib_sge list;\n\n\tlist.addr   = iu->dma_addr;\n\tlist.length = iu->size;\n\tlist.lkey   = path->dev->ib_pd->local_dma_lkey;\n\n\tif (list.length == 0) {\n\t\trtrs_wrn(con->path,\n\t\t\t  \"Posting receive work request failed, sg list is empty\\n\");\n\t\treturn -EINVAL;\n\t}\n\twr = (struct ib_recv_wr) {\n\t\t.wr_cqe  = &iu->cqe,\n\t\t.sg_list = &list,\n\t\t.num_sge = 1,\n\t};\n\n\treturn ib_post_recv(con->qp, &wr, NULL);\n}\nEXPORT_SYMBOL_GPL(rtrs_iu_post_recv);\n\nint rtrs_post_recv_empty(struct rtrs_con *con, struct ib_cqe *cqe)\n{\n\tstruct ib_recv_wr wr;\n\n\twr = (struct ib_recv_wr) {\n\t\t.wr_cqe  = cqe,\n\t};\n\n\treturn ib_post_recv(con->qp, &wr, NULL);\n}\nEXPORT_SYMBOL_GPL(rtrs_post_recv_empty);\n\nstatic int rtrs_post_send(struct ib_qp *qp, struct ib_send_wr *head,\n\t\t\t  struct ib_send_wr *wr, struct ib_send_wr *tail)\n{\n\tif (head) {\n\t\tstruct ib_send_wr *next = head;\n\n\t\twhile (next->next)\n\t\t\tnext = next->next;\n\t\tnext->next = wr;\n\t} else {\n\t\thead = wr;\n\t}\n\n\tif (tail)\n\t\twr->next = tail;\n\n\treturn ib_post_send(qp, head, NULL);\n}\n\nint rtrs_iu_post_send(struct rtrs_con *con, struct rtrs_iu *iu, size_t size,\n\t\t       struct ib_send_wr *head)\n{\n\tstruct rtrs_path *path = con->path;\n\tstruct ib_send_wr wr;\n\tstruct ib_sge list;\n\n\tif (WARN_ON(size == 0))\n\t\treturn -EINVAL;\n\n\tlist.addr   = iu->dma_addr;\n\tlist.length = size;\n\tlist.lkey   = path->dev->ib_pd->local_dma_lkey;\n\n\twr = (struct ib_send_wr) {\n\t\t.wr_cqe     = &iu->cqe,\n\t\t.sg_list    = &list,\n\t\t.num_sge    = 1,\n\t\t.opcode     = IB_WR_SEND,\n\t\t.send_flags = IB_SEND_SIGNALED,\n\t};\n\n\treturn rtrs_post_send(con->qp, head, &wr, NULL);\n}\nEXPORT_SYMBOL_GPL(rtrs_iu_post_send);\n\nint rtrs_iu_post_rdma_write_imm(struct rtrs_con *con, struct rtrs_iu *iu,\n\t\t\t\tstruct ib_sge *sge, unsigned int num_sge,\n\t\t\t\tu32 rkey, u64 rdma_addr, u32 imm_data,\n\t\t\t\tenum ib_send_flags flags,\n\t\t\t\tstruct ib_send_wr *head,\n\t\t\t\tstruct ib_send_wr *tail)\n{\n\tstruct ib_rdma_wr wr;\n\tint i;\n\n\twr = (struct ib_rdma_wr) {\n\t\t.wr.wr_cqe\t  = &iu->cqe,\n\t\t.wr.sg_list\t  = sge,\n\t\t.wr.num_sge\t  = num_sge,\n\t\t.rkey\t\t  = rkey,\n\t\t.remote_addr\t  = rdma_addr,\n\t\t.wr.opcode\t  = IB_WR_RDMA_WRITE_WITH_IMM,\n\t\t.wr.ex.imm_data = cpu_to_be32(imm_data),\n\t\t.wr.send_flags  = flags,\n\t};\n\n\t \n\tfor (i = 0; i < num_sge; i++)\n\t\tif (WARN_ONCE(sge[i].length == 0, \"sg %d is zero length\\n\", i))\n\t\t\treturn -EINVAL;\n\n\treturn rtrs_post_send(con->qp, head, &wr.wr, tail);\n}\nEXPORT_SYMBOL_GPL(rtrs_iu_post_rdma_write_imm);\n\nstatic int rtrs_post_rdma_write_imm_empty(struct rtrs_con *con,\n\t\t\t\t\t  struct ib_cqe *cqe,\n\t\t\t\t\t  u32 imm_data,\n\t\t\t\t\t  struct ib_send_wr *head)\n{\n\tstruct ib_rdma_wr wr;\n\tstruct rtrs_path *path = con->path;\n\tenum ib_send_flags sflags;\n\n\tatomic_dec_if_positive(&con->sq_wr_avail);\n\tsflags = (atomic_inc_return(&con->wr_cnt) % path->signal_interval) ?\n\t\t0 : IB_SEND_SIGNALED;\n\n\twr = (struct ib_rdma_wr) {\n\t\t.wr.wr_cqe\t= cqe,\n\t\t.wr.send_flags\t= sflags,\n\t\t.wr.opcode\t= IB_WR_RDMA_WRITE_WITH_IMM,\n\t\t.wr.ex.imm_data\t= cpu_to_be32(imm_data),\n\t};\n\n\treturn rtrs_post_send(con->qp, head, &wr.wr, NULL);\n}\n\nstatic void qp_event_handler(struct ib_event *ev, void *ctx)\n{\n\tstruct rtrs_con *con = ctx;\n\n\tswitch (ev->event) {\n\tcase IB_EVENT_COMM_EST:\n\t\trtrs_info(con->path, \"QP event %s (%d) received\\n\",\n\t\t\t   ib_event_msg(ev->event), ev->event);\n\t\trdma_notify(con->cm_id, IB_EVENT_COMM_EST);\n\t\tbreak;\n\tdefault:\n\t\trtrs_info(con->path, \"Unhandled QP event %s (%d) received\\n\",\n\t\t\t   ib_event_msg(ev->event), ev->event);\n\t\tbreak;\n\t}\n}\n\nstatic bool is_pollqueue(struct rtrs_con *con)\n{\n\treturn con->cid >= con->path->irq_con_num;\n}\n\nstatic int create_cq(struct rtrs_con *con, int cq_vector, int nr_cqe,\n\t\t     enum ib_poll_context poll_ctx)\n{\n\tstruct rdma_cm_id *cm_id = con->cm_id;\n\tstruct ib_cq *cq;\n\n\tif (is_pollqueue(con))\n\t\tcq = ib_alloc_cq(cm_id->device, con, nr_cqe, cq_vector,\n\t\t\t\t poll_ctx);\n\telse\n\t\tcq = ib_cq_pool_get(cm_id->device, nr_cqe, cq_vector, poll_ctx);\n\n\tif (IS_ERR(cq)) {\n\t\trtrs_err(con->path, \"Creating completion queue failed, errno: %ld\\n\",\n\t\t\t  PTR_ERR(cq));\n\t\treturn PTR_ERR(cq);\n\t}\n\tcon->cq = cq;\n\tcon->nr_cqe = nr_cqe;\n\n\treturn 0;\n}\n\nstatic int create_qp(struct rtrs_con *con, struct ib_pd *pd,\n\t\t     u32 max_send_wr, u32 max_recv_wr, u32 max_sge)\n{\n\tstruct ib_qp_init_attr init_attr = {NULL};\n\tstruct rdma_cm_id *cm_id = con->cm_id;\n\tint ret;\n\n\tinit_attr.cap.max_send_wr = max_send_wr;\n\tinit_attr.cap.max_recv_wr = max_recv_wr;\n\tinit_attr.cap.max_recv_sge = 1;\n\tinit_attr.event_handler = qp_event_handler;\n\tinit_attr.qp_context = con;\n\tinit_attr.cap.max_send_sge = max_sge;\n\n\tinit_attr.qp_type = IB_QPT_RC;\n\tinit_attr.send_cq = con->cq;\n\tinit_attr.recv_cq = con->cq;\n\tinit_attr.sq_sig_type = IB_SIGNAL_REQ_WR;\n\n\tret = rdma_create_qp(cm_id, pd, &init_attr);\n\tif (ret) {\n\t\trtrs_err(con->path, \"Creating QP failed, err: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\tcon->qp = cm_id->qp;\n\n\treturn ret;\n}\n\nstatic void destroy_cq(struct rtrs_con *con)\n{\n\tif (con->cq) {\n\t\tif (is_pollqueue(con))\n\t\t\tib_free_cq(con->cq);\n\t\telse\n\t\t\tib_cq_pool_put(con->cq, con->nr_cqe);\n\t}\n\tcon->cq = NULL;\n}\n\nint rtrs_cq_qp_create(struct rtrs_path *path, struct rtrs_con *con,\n\t\t       u32 max_send_sge, int cq_vector, int nr_cqe,\n\t\t       u32 max_send_wr, u32 max_recv_wr,\n\t\t       enum ib_poll_context poll_ctx)\n{\n\tint err;\n\n\terr = create_cq(con, cq_vector, nr_cqe, poll_ctx);\n\tif (err)\n\t\treturn err;\n\n\terr = create_qp(con, path->dev->ib_pd, max_send_wr, max_recv_wr,\n\t\t\tmax_send_sge);\n\tif (err) {\n\t\tdestroy_cq(con);\n\t\treturn err;\n\t}\n\tcon->path = path;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(rtrs_cq_qp_create);\n\nvoid rtrs_cq_qp_destroy(struct rtrs_con *con)\n{\n\tif (con->qp) {\n\t\trdma_destroy_qp(con->cm_id);\n\t\tcon->qp = NULL;\n\t}\n\tdestroy_cq(con);\n}\nEXPORT_SYMBOL_GPL(rtrs_cq_qp_destroy);\n\nstatic void schedule_hb(struct rtrs_path *path)\n{\n\tqueue_delayed_work(path->hb_wq, &path->hb_dwork,\n\t\t\t   msecs_to_jiffies(path->hb_interval_ms));\n}\n\nvoid rtrs_send_hb_ack(struct rtrs_path *path)\n{\n\tstruct rtrs_con *usr_con = path->con[0];\n\tu32 imm;\n\tint err;\n\n\timm = rtrs_to_imm(RTRS_HB_ACK_IMM, 0);\n\terr = rtrs_post_rdma_write_imm_empty(usr_con, path->hb_cqe, imm,\n\t\t\t\t\t     NULL);\n\tif (err) {\n\t\trtrs_err(path, \"send HB ACK failed, errno: %d\\n\", err);\n\t\tpath->hb_err_handler(usr_con);\n\t\treturn;\n\t}\n}\nEXPORT_SYMBOL_GPL(rtrs_send_hb_ack);\n\nstatic void hb_work(struct work_struct *work)\n{\n\tstruct rtrs_con *usr_con;\n\tstruct rtrs_path *path;\n\tu32 imm;\n\tint err;\n\n\tpath = container_of(to_delayed_work(work), typeof(*path), hb_dwork);\n\tusr_con = path->con[0];\n\n\tif (path->hb_missed_cnt > path->hb_missed_max) {\n\t\trtrs_err(path, \"HB missed max reached.\\n\");\n\t\tpath->hb_err_handler(usr_con);\n\t\treturn;\n\t}\n\tif (path->hb_missed_cnt++) {\n\t\t \n\t\tschedule_hb(path);\n\t\treturn;\n\t}\n\n\tpath->hb_last_sent = ktime_get();\n\n\timm = rtrs_to_imm(RTRS_HB_MSG_IMM, 0);\n\terr = rtrs_post_rdma_write_imm_empty(usr_con, path->hb_cqe, imm,\n\t\t\t\t\t     NULL);\n\tif (err) {\n\t\trtrs_err(path, \"HB send failed, errno: %d\\n\", err);\n\t\tpath->hb_err_handler(usr_con);\n\t\treturn;\n\t}\n\n\tschedule_hb(path);\n}\n\nvoid rtrs_init_hb(struct rtrs_path *path, struct ib_cqe *cqe,\n\t\t  unsigned int interval_ms, unsigned int missed_max,\n\t\t  void (*err_handler)(struct rtrs_con *con),\n\t\t  struct workqueue_struct *wq)\n{\n\tpath->hb_cqe = cqe;\n\tpath->hb_interval_ms = interval_ms;\n\tpath->hb_err_handler = err_handler;\n\tpath->hb_wq = wq;\n\tpath->hb_missed_max = missed_max;\n\tpath->hb_missed_cnt = 0;\n\tINIT_DELAYED_WORK(&path->hb_dwork, hb_work);\n}\nEXPORT_SYMBOL_GPL(rtrs_init_hb);\n\nvoid rtrs_start_hb(struct rtrs_path *path)\n{\n\tschedule_hb(path);\n}\nEXPORT_SYMBOL_GPL(rtrs_start_hb);\n\nvoid rtrs_stop_hb(struct rtrs_path *path)\n{\n\tcancel_delayed_work_sync(&path->hb_dwork);\n\tpath->hb_missed_cnt = 0;\n}\nEXPORT_SYMBOL_GPL(rtrs_stop_hb);\n\nstatic int rtrs_str_gid_to_sockaddr(const char *addr, size_t len,\n\t\t\t\t     short port, struct sockaddr_storage *dst)\n{\n\tstruct sockaddr_ib *dst_ib = (struct sockaddr_ib *)dst;\n\tint ret;\n\n\t \n\tret = in6_pton(addr, len, dst_ib->sib_addr.sib_raw, '\\0', NULL);\n\tif (ret == 0)\n\t\treturn -EINVAL;\n\n\tdst_ib->sib_family = AF_IB;\n\t \n\tdst_ib->sib_sid = cpu_to_be64(RDMA_IB_IP_PS_IB | port);\n\tdst_ib->sib_sid_mask = cpu_to_be64(0xffffffffffffffffULL);\n\tdst_ib->sib_pkey = cpu_to_be16(0xffff);\n\n\treturn 0;\n}\n\n \nstatic int rtrs_str_to_sockaddr(const char *addr, size_t len,\n\t\t\t\tu16 port, struct sockaddr_storage *dst)\n{\n\tif (strncmp(addr, \"gid:\", 4) == 0) {\n\t\treturn rtrs_str_gid_to_sockaddr(addr + 4, len - 4, port, dst);\n\t} else if (strncmp(addr, \"ip:\", 3) == 0) {\n\t\tchar port_str[8];\n\t\tchar *cpy;\n\t\tint err;\n\n\t\tsnprintf(port_str, sizeof(port_str), \"%u\", port);\n\t\tcpy = kstrndup(addr + 3, len - 3, GFP_KERNEL);\n\t\terr = cpy ? inet_pton_with_scope(&init_net, AF_UNSPEC,\n\t\t\t\t\t\t cpy, port_str, dst) : -ENOMEM;\n\t\tkfree(cpy);\n\n\t\treturn err;\n\t}\n\treturn -EPROTONOSUPPORT;\n}\n\n \nint sockaddr_to_str(const struct sockaddr *addr, char *buf, size_t len)\n{\n\tswitch (addr->sa_family) {\n\tcase AF_IB:\n\t\treturn scnprintf(buf, len, \"gid:%pI6\",\n\t\t\t&((struct sockaddr_ib *)addr)->sib_addr.sib_raw);\n\tcase AF_INET:\n\t\treturn scnprintf(buf, len, \"ip:%pI4\",\n\t\t\t&((struct sockaddr_in *)addr)->sin_addr);\n\tcase AF_INET6:\n\t\treturn scnprintf(buf, len, \"ip:%pI6c\",\n\t\t\t  &((struct sockaddr_in6 *)addr)->sin6_addr);\n\t}\n\treturn scnprintf(buf, len, \"<invalid address family>\");\n}\nEXPORT_SYMBOL(sockaddr_to_str);\n\n \nint rtrs_addr_to_str(const struct rtrs_addr *addr, char *buf, size_t len)\n{\n\tint cnt;\n\n\tcnt = sockaddr_to_str((struct sockaddr *)addr->src,\n\t\t\t      buf, len);\n\tcnt += scnprintf(buf + cnt, len - cnt, \"@\");\n\tsockaddr_to_str((struct sockaddr *)addr->dst,\n\t\t\tbuf + cnt, len - cnt);\n\treturn cnt;\n}\nEXPORT_SYMBOL(rtrs_addr_to_str);\n\n \nint rtrs_addr_to_sockaddr(const char *str, size_t len, u16 port,\n\t\t\t  struct rtrs_addr *addr)\n{\n\tconst char *d;\n\n\td = strchr(str, ',');\n\tif (!d)\n\t\td = strchr(str, '@');\n\tif (d) {\n\t\tif (rtrs_str_to_sockaddr(str, d - str, 0, addr->src))\n\t\t\treturn -EINVAL;\n\t\td += 1;\n\t\tlen -= d - str;\n\t\tstr  = d;\n\n\t} else {\n\t\taddr->src = NULL;\n\t}\n\treturn rtrs_str_to_sockaddr(str, len, port, addr->dst);\n}\nEXPORT_SYMBOL(rtrs_addr_to_sockaddr);\n\nvoid rtrs_rdma_dev_pd_init(enum ib_pd_flags pd_flags,\n\t\t\t    struct rtrs_rdma_dev_pd *pool)\n{\n\tINIT_LIST_HEAD(&pool->list);\n\tmutex_init(&pool->mutex);\n\tpool->pd_flags = pd_flags;\n}\nEXPORT_SYMBOL(rtrs_rdma_dev_pd_init);\n\nvoid rtrs_rdma_dev_pd_deinit(struct rtrs_rdma_dev_pd *pool)\n{\n\tmutex_destroy(&pool->mutex);\n\tWARN_ON(!list_empty(&pool->list));\n}\nEXPORT_SYMBOL(rtrs_rdma_dev_pd_deinit);\n\nstatic void dev_free(struct kref *ref)\n{\n\tstruct rtrs_rdma_dev_pd *pool;\n\tstruct rtrs_ib_dev *dev;\n\n\tdev = container_of(ref, typeof(*dev), ref);\n\tpool = dev->pool;\n\n\tmutex_lock(&pool->mutex);\n\tlist_del(&dev->entry);\n\tmutex_unlock(&pool->mutex);\n\n\tib_dealloc_pd(dev->ib_pd);\n\tkfree(dev);\n}\n\nint rtrs_ib_dev_put(struct rtrs_ib_dev *dev)\n{\n\treturn kref_put(&dev->ref, dev_free);\n}\nEXPORT_SYMBOL(rtrs_ib_dev_put);\n\nstatic int rtrs_ib_dev_get(struct rtrs_ib_dev *dev)\n{\n\treturn kref_get_unless_zero(&dev->ref);\n}\n\nstruct rtrs_ib_dev *\nrtrs_ib_dev_find_or_add(struct ib_device *ib_dev,\n\t\t\t struct rtrs_rdma_dev_pd *pool)\n{\n\tstruct rtrs_ib_dev *dev;\n\n\tmutex_lock(&pool->mutex);\n\tlist_for_each_entry(dev, &pool->list, entry) {\n\t\tif (dev->ib_dev->node_guid == ib_dev->node_guid &&\n\t\t    rtrs_ib_dev_get(dev))\n\t\t\tgoto out_unlock;\n\t}\n\tmutex_unlock(&pool->mutex);\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\tgoto out_err;\n\n\tkref_init(&dev->ref);\n\tdev->pool = pool;\n\tdev->ib_dev = ib_dev;\n\tdev->ib_pd = ib_alloc_pd(ib_dev, pool->pd_flags);\n\tif (IS_ERR(dev->ib_pd))\n\t\tgoto out_free_dev;\n\n\tif (pool->ops && pool->ops->init && pool->ops->init(dev))\n\t\tgoto out_free_pd;\n\n\tmutex_lock(&pool->mutex);\n\tlist_add(&dev->entry, &pool->list);\nout_unlock:\n\tmutex_unlock(&pool->mutex);\n\treturn dev;\n\nout_free_pd:\n\tib_dealloc_pd(dev->ib_pd);\nout_free_dev:\n\tkfree(dev);\nout_err:\n\treturn NULL;\n}\nEXPORT_SYMBOL(rtrs_ib_dev_find_or_add);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}