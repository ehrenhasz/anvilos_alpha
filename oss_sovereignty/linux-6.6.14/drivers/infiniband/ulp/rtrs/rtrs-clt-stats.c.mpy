{
  "module_name": "rtrs-clt-stats.c",
  "hash_id": "99d5b5dcaad7530741b52f467d92d7406360f5b8223d0cd59030c286f6081cb5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/ulp/rtrs/rtrs-clt-stats.c",
  "human_readable_source": "\n \n#undef pr_fmt\n#define pr_fmt(fmt) KBUILD_MODNAME \" L\" __stringify(__LINE__) \": \" fmt\n\n#include \"rtrs-clt.h\"\n\nvoid rtrs_clt_update_wc_stats(struct rtrs_clt_con *con)\n{\n\tstruct rtrs_clt_path *clt_path = to_clt_path(con->c.path);\n\tstruct rtrs_clt_stats *stats = clt_path->stats;\n\tstruct rtrs_clt_stats_pcpu *s;\n\tint cpu;\n\n\tcpu = raw_smp_processor_id();\n\ts = get_cpu_ptr(stats->pcpu_stats);\n\tif (con->cpu != cpu) {\n\t\ts->cpu_migr.to++;\n\n\t\t \n\t\ts = per_cpu_ptr(stats->pcpu_stats, con->cpu);\n\t\tatomic_inc(&s->cpu_migr.from);\n\t}\n\tput_cpu_ptr(stats->pcpu_stats);\n}\n\nvoid rtrs_clt_inc_failover_cnt(struct rtrs_clt_stats *stats)\n{\n\tthis_cpu_inc(stats->pcpu_stats->rdma.failover_cnt);\n}\n\nint rtrs_clt_stats_migration_from_cnt_to_str(struct rtrs_clt_stats *stats, char *buf)\n{\n\tstruct rtrs_clt_stats_pcpu *s;\n\n\tsize_t used;\n\tint cpu;\n\n\tused = 0;\n\tfor_each_possible_cpu(cpu) {\n\t\ts = per_cpu_ptr(stats->pcpu_stats, cpu);\n\t\tused += sysfs_emit_at(buf, used, \"%d \",\n\t\t\t\t  atomic_read(&s->cpu_migr.from));\n\t}\n\n\tused += sysfs_emit_at(buf, used, \"\\n\");\n\n\treturn used;\n}\n\nint rtrs_clt_stats_migration_to_cnt_to_str(struct rtrs_clt_stats *stats, char *buf)\n{\n\tstruct rtrs_clt_stats_pcpu *s;\n\n\tsize_t used;\n\tint cpu;\n\n\tused = 0;\n\tfor_each_possible_cpu(cpu) {\n\t\ts = per_cpu_ptr(stats->pcpu_stats, cpu);\n\t\tused += sysfs_emit_at(buf, used, \"%d \", s->cpu_migr.to);\n\t}\n\n\tused += sysfs_emit_at(buf, used, \"\\n\");\n\n\treturn used;\n}\n\nint rtrs_clt_stats_reconnects_to_str(struct rtrs_clt_stats *stats, char *buf)\n{\n\treturn sysfs_emit(buf, \"%d %d\\n\", stats->reconnects.successful_cnt,\n\t\t\t  stats->reconnects.fail_cnt);\n}\n\nssize_t rtrs_clt_stats_rdma_to_str(struct rtrs_clt_stats *stats, char *page)\n{\n\tstruct rtrs_clt_stats_rdma sum;\n\tstruct rtrs_clt_stats_rdma *r;\n\tint cpu;\n\n\tmemset(&sum, 0, sizeof(sum));\n\n\tfor_each_possible_cpu(cpu) {\n\t\tr = &per_cpu_ptr(stats->pcpu_stats, cpu)->rdma;\n\n\t\tsum.dir[READ].cnt\t  += r->dir[READ].cnt;\n\t\tsum.dir[READ].size_total  += r->dir[READ].size_total;\n\t\tsum.dir[WRITE].cnt\t  += r->dir[WRITE].cnt;\n\t\tsum.dir[WRITE].size_total += r->dir[WRITE].size_total;\n\t\tsum.failover_cnt\t  += r->failover_cnt;\n\t}\n\n\treturn sysfs_emit(page, \"%llu %llu %llu %llu %u %llu\\n\",\n\t\t\t sum.dir[READ].cnt, sum.dir[READ].size_total,\n\t\t\t sum.dir[WRITE].cnt, sum.dir[WRITE].size_total,\n\t\t\t atomic_read(&stats->inflight), sum.failover_cnt);\n}\n\nssize_t rtrs_clt_reset_all_help(struct rtrs_clt_stats *s, char *page)\n{\n\treturn sysfs_emit(page, \"echo 1 to reset all statistics\\n\");\n}\n\nint rtrs_clt_reset_rdma_stats(struct rtrs_clt_stats *stats, bool enable)\n{\n\tstruct rtrs_clt_stats_pcpu *s;\n\tint cpu;\n\n\tif (!enable)\n\t\treturn -EINVAL;\n\n\tfor_each_possible_cpu(cpu) {\n\t\ts = per_cpu_ptr(stats->pcpu_stats, cpu);\n\t\tmemset(&s->rdma, 0, sizeof(s->rdma));\n\t}\n\n\treturn 0;\n}\n\nint rtrs_clt_reset_cpu_migr_stats(struct rtrs_clt_stats *stats, bool enable)\n{\n\tstruct rtrs_clt_stats_pcpu *s;\n\tint cpu;\n\n\tif (!enable)\n\t\treturn -EINVAL;\n\n\tfor_each_possible_cpu(cpu) {\n\t\ts = per_cpu_ptr(stats->pcpu_stats, cpu);\n\t\tmemset(&s->cpu_migr, 0, sizeof(s->cpu_migr));\n\t}\n\n\treturn 0;\n}\n\nint rtrs_clt_reset_reconnects_stat(struct rtrs_clt_stats *stats, bool enable)\n{\n\tif (!enable)\n\t\treturn -EINVAL;\n\n\tmemset(&stats->reconnects, 0, sizeof(stats->reconnects));\n\n\treturn 0;\n}\n\nint rtrs_clt_reset_all_stats(struct rtrs_clt_stats *s, bool enable)\n{\n\tif (enable) {\n\t\trtrs_clt_reset_rdma_stats(s, enable);\n\t\trtrs_clt_reset_cpu_migr_stats(s, enable);\n\t\trtrs_clt_reset_reconnects_stat(s, enable);\n\t\tatomic_set(&s->inflight, 0);\n\t\treturn 0;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic inline void rtrs_clt_update_rdma_stats(struct rtrs_clt_stats *stats,\n\t\t\t\t\t       size_t size, int d)\n{\n\tthis_cpu_inc(stats->pcpu_stats->rdma.dir[d].cnt);\n\tthis_cpu_add(stats->pcpu_stats->rdma.dir[d].size_total, size);\n}\n\nvoid rtrs_clt_update_all_stats(struct rtrs_clt_io_req *req, int dir)\n{\n\tstruct rtrs_clt_con *con = req->con;\n\tstruct rtrs_clt_path *clt_path = to_clt_path(con->c.path);\n\tstruct rtrs_clt_stats *stats = clt_path->stats;\n\tunsigned int len;\n\n\tlen = req->usr_len + req->data_len;\n\trtrs_clt_update_rdma_stats(stats, len, dir);\n\tif (req->mp_policy == MP_POLICY_MIN_INFLIGHT)\n\t\tatomic_inc(&stats->inflight);\n}\n\nint rtrs_clt_init_stats(struct rtrs_clt_stats *stats)\n{\n\tstats->pcpu_stats = alloc_percpu(typeof(*stats->pcpu_stats));\n\tif (!stats->pcpu_stats)\n\t\treturn -ENOMEM;\n\n\t \n\tstats->reconnects.successful_cnt = -1;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}