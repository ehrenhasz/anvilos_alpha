{
  "module_name": "sa_query.c",
  "hash_id": "63a468b574d3186f36b4efb6ca0176a0a8b0d30c1ebca3e5abad24a01ae80e22",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/core/sa_query.c",
  "human_readable_source": " \n\n#include <linux/init.h>\n#include <linux/err.h>\n#include <linux/random.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/dma-mapping.h>\n#include <linux/kref.h>\n#include <linux/xarray.h>\n#include <linux/workqueue.h>\n#include <uapi/linux/if_ether.h>\n#include <rdma/ib_pack.h>\n#include <rdma/ib_cache.h>\n#include <rdma/rdma_netlink.h>\n#include <net/netlink.h>\n#include <uapi/rdma/ib_user_sa.h>\n#include <rdma/ib_marshall.h>\n#include <rdma/ib_addr.h>\n#include <rdma/opa_addr.h>\n#include <rdma/rdma_cm.h>\n#include \"sa.h\"\n#include \"core_priv.h\"\n\n#define IB_SA_LOCAL_SVC_TIMEOUT_MIN\t\t100\n#define IB_SA_LOCAL_SVC_TIMEOUT_DEFAULT\t\t2000\n#define IB_SA_LOCAL_SVC_TIMEOUT_MAX\t\t200000\n#define IB_SA_CPI_MAX_RETRY_CNT\t\t\t3\n#define IB_SA_CPI_RETRY_WAIT\t\t\t1000  \nstatic int sa_local_svc_timeout_ms = IB_SA_LOCAL_SVC_TIMEOUT_DEFAULT;\n\nstruct ib_sa_sm_ah {\n\tstruct ib_ah        *ah;\n\tstruct kref          ref;\n\tu16\t\t     pkey_index;\n\tu8\t\t     src_path_mask;\n};\n\nenum rdma_class_port_info_type {\n\tRDMA_CLASS_PORT_INFO_IB,\n\tRDMA_CLASS_PORT_INFO_OPA\n};\n\nstruct rdma_class_port_info {\n\tenum rdma_class_port_info_type type;\n\tunion {\n\t\tstruct ib_class_port_info ib;\n\t\tstruct opa_class_port_info opa;\n\t};\n};\n\nstruct ib_sa_classport_cache {\n\tbool valid;\n\tint retry_cnt;\n\tstruct rdma_class_port_info data;\n};\n\nstruct ib_sa_port {\n\tstruct ib_mad_agent *agent;\n\tstruct ib_sa_sm_ah  *sm_ah;\n\tstruct work_struct   update_task;\n\tstruct ib_sa_classport_cache classport_info;\n\tstruct delayed_work ib_cpi_work;\n\tspinlock_t                   classport_lock;  \n\tspinlock_t           ah_lock;\n\tu32\t\t     port_num;\n};\n\nstruct ib_sa_device {\n\tint                     start_port, end_port;\n\tstruct ib_event_handler event_handler;\n\tstruct ib_sa_port port[];\n};\n\nstruct ib_sa_query {\n\tvoid (*callback)(struct ib_sa_query *sa_query, int status,\n\t\t\t struct ib_sa_mad *mad);\n\tvoid (*release)(struct ib_sa_query *);\n\tstruct ib_sa_client    *client;\n\tstruct ib_sa_port      *port;\n\tstruct ib_mad_send_buf *mad_buf;\n\tstruct ib_sa_sm_ah     *sm_ah;\n\tint\t\t\tid;\n\tu32\t\t\tflags;\n\tstruct list_head\tlist;  \n\tu32\t\t\tseq;  \n\tunsigned long\t\ttimeout;  \n\tu8\t\t\tpath_use;  \n};\n\n#define IB_SA_ENABLE_LOCAL_SERVICE\t0x00000001\n#define IB_SA_CANCEL\t\t\t0x00000002\n#define IB_SA_QUERY_OPA\t\t\t0x00000004\n\nstruct ib_sa_path_query {\n\tvoid (*callback)(int status, struct sa_path_rec *rec,\n\t\t\t unsigned int num_paths, void *context);\n\tvoid *context;\n\tstruct ib_sa_query sa_query;\n\tstruct sa_path_rec *conv_pr;\n};\n\nstruct ib_sa_guidinfo_query {\n\tvoid (*callback)(int, struct ib_sa_guidinfo_rec *, void *);\n\tvoid *context;\n\tstruct ib_sa_query sa_query;\n};\n\nstruct ib_sa_classport_info_query {\n\tvoid (*callback)(void *);\n\tvoid *context;\n\tstruct ib_sa_query sa_query;\n};\n\nstruct ib_sa_mcmember_query {\n\tvoid (*callback)(int, struct ib_sa_mcmember_rec *, void *);\n\tvoid *context;\n\tstruct ib_sa_query sa_query;\n};\n\nstatic LIST_HEAD(ib_nl_request_list);\nstatic DEFINE_SPINLOCK(ib_nl_request_lock);\nstatic atomic_t ib_nl_sa_request_seq;\nstatic struct workqueue_struct *ib_nl_wq;\nstatic struct delayed_work ib_nl_timed_work;\nstatic const struct nla_policy ib_nl_policy[LS_NLA_TYPE_MAX] = {\n\t[LS_NLA_TYPE_PATH_RECORD]\t= {.type = NLA_BINARY,\n\t\t.len = sizeof(struct ib_path_rec_data)},\n\t[LS_NLA_TYPE_TIMEOUT]\t\t= {.type = NLA_U32},\n\t[LS_NLA_TYPE_SERVICE_ID]\t= {.type = NLA_U64},\n\t[LS_NLA_TYPE_DGID]\t\t= {.type = NLA_BINARY,\n\t\t.len = sizeof(struct rdma_nla_ls_gid)},\n\t[LS_NLA_TYPE_SGID]\t\t= {.type = NLA_BINARY,\n\t\t.len = sizeof(struct rdma_nla_ls_gid)},\n\t[LS_NLA_TYPE_TCLASS]\t\t= {.type = NLA_U8},\n\t[LS_NLA_TYPE_PKEY]\t\t= {.type = NLA_U16},\n\t[LS_NLA_TYPE_QOS_CLASS]\t\t= {.type = NLA_U16},\n};\n\n\nstatic int ib_sa_add_one(struct ib_device *device);\nstatic void ib_sa_remove_one(struct ib_device *device, void *client_data);\n\nstatic struct ib_client sa_client = {\n\t.name   = \"sa\",\n\t.add    = ib_sa_add_one,\n\t.remove = ib_sa_remove_one\n};\n\nstatic DEFINE_XARRAY_FLAGS(queries, XA_FLAGS_ALLOC | XA_FLAGS_LOCK_IRQ);\n\nstatic DEFINE_SPINLOCK(tid_lock);\nstatic u32 tid;\n\n#define PATH_REC_FIELD(field) \\\n\t.struct_offset_bytes = offsetof(struct sa_path_rec, field),\t\\\n\t.struct_size_bytes   = sizeof_field(struct sa_path_rec, field),\t\\\n\t.field_name          = \"sa_path_rec:\" #field\n\nstatic const struct ib_field path_rec_table[] = {\n\t{ PATH_REC_FIELD(service_id),\n\t  .offset_words = 0,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 64 },\n\t{ PATH_REC_FIELD(dgid),\n\t  .offset_words = 2,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ PATH_REC_FIELD(sgid),\n\t  .offset_words = 6,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ PATH_REC_FIELD(ib.dlid),\n\t  .offset_words = 10,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 16 },\n\t{ PATH_REC_FIELD(ib.slid),\n\t  .offset_words = 10,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\t{ PATH_REC_FIELD(ib.raw_traffic),\n\t  .offset_words = 11,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 1 },\n\t{ RESERVED,\n\t  .offset_words = 11,\n\t  .offset_bits  = 1,\n\t  .size_bits    = 3 },\n\t{ PATH_REC_FIELD(flow_label),\n\t  .offset_words = 11,\n\t  .offset_bits  = 4,\n\t  .size_bits    = 20 },\n\t{ PATH_REC_FIELD(hop_limit),\n\t  .offset_words = 11,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 8 },\n\t{ PATH_REC_FIELD(traffic_class),\n\t  .offset_words = 12,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 8 },\n\t{ PATH_REC_FIELD(reversible),\n\t  .offset_words = 12,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 1 },\n\t{ PATH_REC_FIELD(numb_path),\n\t  .offset_words = 12,\n\t  .offset_bits  = 9,\n\t  .size_bits    = 7 },\n\t{ PATH_REC_FIELD(pkey),\n\t  .offset_words = 12,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\t{ PATH_REC_FIELD(qos_class),\n\t  .offset_words = 13,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 12 },\n\t{ PATH_REC_FIELD(sl),\n\t  .offset_words = 13,\n\t  .offset_bits  = 12,\n\t  .size_bits    = 4 },\n\t{ PATH_REC_FIELD(mtu_selector),\n\t  .offset_words = 13,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 2 },\n\t{ PATH_REC_FIELD(mtu),\n\t  .offset_words = 13,\n\t  .offset_bits  = 18,\n\t  .size_bits    = 6 },\n\t{ PATH_REC_FIELD(rate_selector),\n\t  .offset_words = 13,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 2 },\n\t{ PATH_REC_FIELD(rate),\n\t  .offset_words = 13,\n\t  .offset_bits  = 26,\n\t  .size_bits    = 6 },\n\t{ PATH_REC_FIELD(packet_life_time_selector),\n\t  .offset_words = 14,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 2 },\n\t{ PATH_REC_FIELD(packet_life_time),\n\t  .offset_words = 14,\n\t  .offset_bits  = 2,\n\t  .size_bits    = 6 },\n\t{ PATH_REC_FIELD(preference),\n\t  .offset_words = 14,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 8 },\n\t{ RESERVED,\n\t  .offset_words = 14,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 48 },\n};\n\n#define OPA_PATH_REC_FIELD(field) \\\n\t.struct_offset_bytes = \\\n\t\toffsetof(struct sa_path_rec, field), \\\n\t.struct_size_bytes   = \\\n\t\tsizeof_field(struct sa_path_rec, field),\t\\\n\t.field_name          = \"sa_path_rec:\" #field\n\nstatic const struct ib_field opa_path_rec_table[] = {\n\t{ OPA_PATH_REC_FIELD(service_id),\n\t  .offset_words = 0,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 64 },\n\t{ OPA_PATH_REC_FIELD(dgid),\n\t  .offset_words = 2,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ OPA_PATH_REC_FIELD(sgid),\n\t  .offset_words = 6,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ OPA_PATH_REC_FIELD(opa.dlid),\n\t  .offset_words = 10,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_PATH_REC_FIELD(opa.slid),\n\t  .offset_words = 11,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_PATH_REC_FIELD(opa.raw_traffic),\n\t  .offset_words = 12,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 1 },\n\t{ RESERVED,\n\t  .offset_words = 12,\n\t  .offset_bits  = 1,\n\t  .size_bits    = 3 },\n\t{ OPA_PATH_REC_FIELD(flow_label),\n\t  .offset_words = 12,\n\t  .offset_bits  = 4,\n\t  .size_bits    = 20 },\n\t{ OPA_PATH_REC_FIELD(hop_limit),\n\t  .offset_words = 12,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 8 },\n\t{ OPA_PATH_REC_FIELD(traffic_class),\n\t  .offset_words = 13,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 8 },\n\t{ OPA_PATH_REC_FIELD(reversible),\n\t  .offset_words = 13,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 1 },\n\t{ OPA_PATH_REC_FIELD(numb_path),\n\t  .offset_words = 13,\n\t  .offset_bits  = 9,\n\t  .size_bits    = 7 },\n\t{ OPA_PATH_REC_FIELD(pkey),\n\t  .offset_words = 13,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\t{ OPA_PATH_REC_FIELD(opa.l2_8B),\n\t  .offset_words = 14,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 1 },\n\t{ OPA_PATH_REC_FIELD(opa.l2_10B),\n\t  .offset_words = 14,\n\t  .offset_bits  = 1,\n\t  .size_bits    = 1 },\n\t{ OPA_PATH_REC_FIELD(opa.l2_9B),\n\t  .offset_words = 14,\n\t  .offset_bits  = 2,\n\t  .size_bits    = 1 },\n\t{ OPA_PATH_REC_FIELD(opa.l2_16B),\n\t  .offset_words = 14,\n\t  .offset_bits  = 3,\n\t  .size_bits    = 1 },\n\t{ RESERVED,\n\t  .offset_words = 14,\n\t  .offset_bits  = 4,\n\t  .size_bits    = 2 },\n\t{ OPA_PATH_REC_FIELD(opa.qos_type),\n\t  .offset_words = 14,\n\t  .offset_bits  = 6,\n\t  .size_bits    = 2 },\n\t{ OPA_PATH_REC_FIELD(opa.qos_priority),\n\t  .offset_words = 14,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 8 },\n\t{ RESERVED,\n\t  .offset_words = 14,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 3 },\n\t{ OPA_PATH_REC_FIELD(sl),\n\t  .offset_words = 14,\n\t  .offset_bits  = 19,\n\t  .size_bits    = 5 },\n\t{ RESERVED,\n\t  .offset_words = 14,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 8 },\n\t{ OPA_PATH_REC_FIELD(mtu_selector),\n\t  .offset_words = 15,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 2 },\n\t{ OPA_PATH_REC_FIELD(mtu),\n\t  .offset_words = 15,\n\t  .offset_bits  = 2,\n\t  .size_bits    = 6 },\n\t{ OPA_PATH_REC_FIELD(rate_selector),\n\t  .offset_words = 15,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 2 },\n\t{ OPA_PATH_REC_FIELD(rate),\n\t  .offset_words = 15,\n\t  .offset_bits  = 10,\n\t  .size_bits    = 6 },\n\t{ OPA_PATH_REC_FIELD(packet_life_time_selector),\n\t  .offset_words = 15,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 2 },\n\t{ OPA_PATH_REC_FIELD(packet_life_time),\n\t  .offset_words = 15,\n\t  .offset_bits  = 18,\n\t  .size_bits    = 6 },\n\t{ OPA_PATH_REC_FIELD(preference),\n\t  .offset_words = 15,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 8 },\n};\n\n#define MCMEMBER_REC_FIELD(field) \\\n\t.struct_offset_bytes = offsetof(struct ib_sa_mcmember_rec, field),\t\\\n\t.struct_size_bytes   = sizeof_field(struct ib_sa_mcmember_rec, field),\t\\\n\t.field_name          = \"sa_mcmember_rec:\" #field\n\nstatic const struct ib_field mcmember_rec_table[] = {\n\t{ MCMEMBER_REC_FIELD(mgid),\n\t  .offset_words = 0,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ MCMEMBER_REC_FIELD(port_gid),\n\t  .offset_words = 4,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ MCMEMBER_REC_FIELD(qkey),\n\t  .offset_words = 8,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ MCMEMBER_REC_FIELD(mlid),\n\t  .offset_words = 9,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 16 },\n\t{ MCMEMBER_REC_FIELD(mtu_selector),\n\t  .offset_words = 9,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 2 },\n\t{ MCMEMBER_REC_FIELD(mtu),\n\t  .offset_words = 9,\n\t  .offset_bits  = 18,\n\t  .size_bits    = 6 },\n\t{ MCMEMBER_REC_FIELD(traffic_class),\n\t  .offset_words = 9,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 8 },\n\t{ MCMEMBER_REC_FIELD(pkey),\n\t  .offset_words = 10,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 16 },\n\t{ MCMEMBER_REC_FIELD(rate_selector),\n\t  .offset_words = 10,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 2 },\n\t{ MCMEMBER_REC_FIELD(rate),\n\t  .offset_words = 10,\n\t  .offset_bits  = 18,\n\t  .size_bits    = 6 },\n\t{ MCMEMBER_REC_FIELD(packet_life_time_selector),\n\t  .offset_words = 10,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 2 },\n\t{ MCMEMBER_REC_FIELD(packet_life_time),\n\t  .offset_words = 10,\n\t  .offset_bits  = 26,\n\t  .size_bits    = 6 },\n\t{ MCMEMBER_REC_FIELD(sl),\n\t  .offset_words = 11,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 4 },\n\t{ MCMEMBER_REC_FIELD(flow_label),\n\t  .offset_words = 11,\n\t  .offset_bits  = 4,\n\t  .size_bits    = 20 },\n\t{ MCMEMBER_REC_FIELD(hop_limit),\n\t  .offset_words = 11,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 8 },\n\t{ MCMEMBER_REC_FIELD(scope),\n\t  .offset_words = 12,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 4 },\n\t{ MCMEMBER_REC_FIELD(join_state),\n\t  .offset_words = 12,\n\t  .offset_bits  = 4,\n\t  .size_bits    = 4 },\n\t{ MCMEMBER_REC_FIELD(proxy_join),\n\t  .offset_words = 12,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 1 },\n\t{ RESERVED,\n\t  .offset_words = 12,\n\t  .offset_bits  = 9,\n\t  .size_bits    = 23 },\n};\n\n#define CLASSPORTINFO_REC_FIELD(field) \\\n\t.struct_offset_bytes = offsetof(struct ib_class_port_info, field),\t\\\n\t.struct_size_bytes   = sizeof_field(struct ib_class_port_info, field),\t\\\n\t.field_name          = \"ib_class_port_info:\" #field\n\nstatic const struct ib_field ib_classport_info_rec_table[] = {\n\t{ CLASSPORTINFO_REC_FIELD(base_version),\n\t  .offset_words = 0,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 8 },\n\t{ CLASSPORTINFO_REC_FIELD(class_version),\n\t  .offset_words = 0,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 8 },\n\t{ CLASSPORTINFO_REC_FIELD(capability_mask),\n\t  .offset_words = 0,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\t{ CLASSPORTINFO_REC_FIELD(cap_mask2_resp_time),\n\t  .offset_words = 1,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ CLASSPORTINFO_REC_FIELD(redirect_gid),\n\t  .offset_words = 2,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ CLASSPORTINFO_REC_FIELD(redirect_tcslfl),\n\t  .offset_words = 6,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ CLASSPORTINFO_REC_FIELD(redirect_lid),\n\t  .offset_words = 7,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 16 },\n\t{ CLASSPORTINFO_REC_FIELD(redirect_pkey),\n\t  .offset_words = 7,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\n\t{ CLASSPORTINFO_REC_FIELD(redirect_qp),\n\t  .offset_words = 8,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ CLASSPORTINFO_REC_FIELD(redirect_qkey),\n\t  .offset_words = 9,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\n\t{ CLASSPORTINFO_REC_FIELD(trap_gid),\n\t  .offset_words = 10,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ CLASSPORTINFO_REC_FIELD(trap_tcslfl),\n\t  .offset_words = 14,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\n\t{ CLASSPORTINFO_REC_FIELD(trap_lid),\n\t  .offset_words = 15,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 16 },\n\t{ CLASSPORTINFO_REC_FIELD(trap_pkey),\n\t  .offset_words = 15,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\n\t{ CLASSPORTINFO_REC_FIELD(trap_hlqp),\n\t  .offset_words = 16,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ CLASSPORTINFO_REC_FIELD(trap_qkey),\n\t  .offset_words = 17,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n};\n\n#define OPA_CLASSPORTINFO_REC_FIELD(field) \\\n\t.struct_offset_bytes =\\\n\t\toffsetof(struct opa_class_port_info, field),\t\\\n\t.struct_size_bytes   = \\\n\t\tsizeof_field(struct opa_class_port_info, field),\t\\\n\t.field_name          = \"opa_class_port_info:\" #field\n\nstatic const struct ib_field opa_classport_info_rec_table[] = {\n\t{ OPA_CLASSPORTINFO_REC_FIELD(base_version),\n\t  .offset_words = 0,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 8 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(class_version),\n\t  .offset_words = 0,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 8 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(cap_mask),\n\t  .offset_words = 0,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(cap_mask2_resp_time),\n\t  .offset_words = 1,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(redirect_gid),\n\t  .offset_words = 2,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(redirect_tc_fl),\n\t  .offset_words = 6,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(redirect_lid),\n\t  .offset_words = 7,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(redirect_sl_qp),\n\t  .offset_words = 8,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(redirect_qkey),\n\t  .offset_words = 9,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(trap_gid),\n\t  .offset_words = 10,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 128 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(trap_tc_fl),\n\t  .offset_words = 14,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(trap_lid),\n\t  .offset_words = 15,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(trap_hl_qp),\n\t  .offset_words = 16,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(trap_qkey),\n\t  .offset_words = 17,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(trap_pkey),\n\t  .offset_words = 18,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 16 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(redirect_pkey),\n\t  .offset_words = 18,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 16 },\n\t{ OPA_CLASSPORTINFO_REC_FIELD(trap_sl_rsvd),\n\t  .offset_words = 19,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 8 },\n\t{ RESERVED,\n\t  .offset_words = 19,\n\t  .offset_bits  = 8,\n\t  .size_bits    = 24 },\n};\n\n#define GUIDINFO_REC_FIELD(field) \\\n\t.struct_offset_bytes = offsetof(struct ib_sa_guidinfo_rec, field),\t\\\n\t.struct_size_bytes   = sizeof_field(struct ib_sa_guidinfo_rec, field),\t\\\n\t.field_name          = \"sa_guidinfo_rec:\" #field\n\nstatic const struct ib_field guidinfo_rec_table[] = {\n\t{ GUIDINFO_REC_FIELD(lid),\n\t  .offset_words = 0,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 16 },\n\t{ GUIDINFO_REC_FIELD(block_num),\n\t  .offset_words = 0,\n\t  .offset_bits  = 16,\n\t  .size_bits    = 8 },\n\t{ GUIDINFO_REC_FIELD(res1),\n\t  .offset_words = 0,\n\t  .offset_bits  = 24,\n\t  .size_bits    = 8 },\n\t{ GUIDINFO_REC_FIELD(res2),\n\t  .offset_words = 1,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 32 },\n\t{ GUIDINFO_REC_FIELD(guid_info_list),\n\t  .offset_words = 2,\n\t  .offset_bits  = 0,\n\t  .size_bits    = 512 },\n};\n\n#define RDMA_PRIMARY_PATH_MAX_REC_NUM 3\n\nstatic inline void ib_sa_disable_local_svc(struct ib_sa_query *query)\n{\n\tquery->flags &= ~IB_SA_ENABLE_LOCAL_SERVICE;\n}\n\nstatic inline int ib_sa_query_cancelled(struct ib_sa_query *query)\n{\n\treturn (query->flags & IB_SA_CANCEL);\n}\n\nstatic void ib_nl_set_path_rec_attrs(struct sk_buff *skb,\n\t\t\t\t     struct ib_sa_query *query)\n{\n\tstruct sa_path_rec *sa_rec = query->mad_buf->context[1];\n\tstruct ib_sa_mad *mad = query->mad_buf->mad;\n\tib_sa_comp_mask comp_mask = mad->sa_hdr.comp_mask;\n\tu16 val16;\n\tu64 val64;\n\tstruct rdma_ls_resolve_header *header;\n\n\tquery->mad_buf->context[1] = NULL;\n\n\t \n\theader = skb_put(skb, NLMSG_ALIGN(sizeof(*header)));\n\tstrscpy_pad(header->device_name,\n\t\t    dev_name(&query->port->agent->device->dev),\n\t\t    LS_DEVICE_NAME_MAX);\n\theader->port_num = query->port->port_num;\n\n\tif ((comp_mask & IB_SA_PATH_REC_REVERSIBLE) &&\n\t    sa_rec->reversible != 0)\n\t\tquery->path_use = LS_RESOLVE_PATH_USE_ALL;\n\telse\n\t\tquery->path_use = LS_RESOLVE_PATH_USE_UNIDIRECTIONAL;\n\theader->path_use = query->path_use;\n\n\t \n\tif (comp_mask & IB_SA_PATH_REC_SERVICE_ID) {\n\t\tval64 = be64_to_cpu(sa_rec->service_id);\n\t\tnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_SERVICE_ID,\n\t\t\tsizeof(val64), &val64);\n\t}\n\tif (comp_mask & IB_SA_PATH_REC_DGID)\n\t\tnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_DGID,\n\t\t\tsizeof(sa_rec->dgid), &sa_rec->dgid);\n\tif (comp_mask & IB_SA_PATH_REC_SGID)\n\t\tnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_SGID,\n\t\t\tsizeof(sa_rec->sgid), &sa_rec->sgid);\n\tif (comp_mask & IB_SA_PATH_REC_TRAFFIC_CLASS)\n\t\tnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_TCLASS,\n\t\t\tsizeof(sa_rec->traffic_class), &sa_rec->traffic_class);\n\n\tif (comp_mask & IB_SA_PATH_REC_PKEY) {\n\t\tval16 = be16_to_cpu(sa_rec->pkey);\n\t\tnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_PKEY,\n\t\t\tsizeof(val16), &val16);\n\t}\n\tif (comp_mask & IB_SA_PATH_REC_QOS_CLASS) {\n\t\tval16 = be16_to_cpu(sa_rec->qos_class);\n\t\tnla_put(skb, RDMA_NLA_F_MANDATORY | LS_NLA_TYPE_QOS_CLASS,\n\t\t\tsizeof(val16), &val16);\n\t}\n}\n\nstatic int ib_nl_get_path_rec_attrs_len(ib_sa_comp_mask comp_mask)\n{\n\tint len = 0;\n\n\tif (comp_mask & IB_SA_PATH_REC_SERVICE_ID)\n\t\tlen += nla_total_size(sizeof(u64));\n\tif (comp_mask & IB_SA_PATH_REC_DGID)\n\t\tlen += nla_total_size(sizeof(struct rdma_nla_ls_gid));\n\tif (comp_mask & IB_SA_PATH_REC_SGID)\n\t\tlen += nla_total_size(sizeof(struct rdma_nla_ls_gid));\n\tif (comp_mask & IB_SA_PATH_REC_TRAFFIC_CLASS)\n\t\tlen += nla_total_size(sizeof(u8));\n\tif (comp_mask & IB_SA_PATH_REC_PKEY)\n\t\tlen += nla_total_size(sizeof(u16));\n\tif (comp_mask & IB_SA_PATH_REC_QOS_CLASS)\n\t\tlen += nla_total_size(sizeof(u16));\n\n\t \n\tif (WARN_ON(len == 0))\n\t\treturn len;\n\n\t \n\tlen += NLMSG_ALIGN(sizeof(struct rdma_ls_resolve_header));\n\n\treturn len;\n}\n\nstatic int ib_nl_make_request(struct ib_sa_query *query, gfp_t gfp_mask)\n{\n\tstruct sk_buff *skb = NULL;\n\tstruct nlmsghdr *nlh;\n\tvoid *data;\n\tstruct ib_sa_mad *mad;\n\tint len;\n\tunsigned long flags;\n\tunsigned long delay;\n\tgfp_t gfp_flag;\n\tint ret;\n\n\tINIT_LIST_HEAD(&query->list);\n\tquery->seq = (u32)atomic_inc_return(&ib_nl_sa_request_seq);\n\n\tmad = query->mad_buf->mad;\n\tlen = ib_nl_get_path_rec_attrs_len(mad->sa_hdr.comp_mask);\n\tif (len <= 0)\n\t\treturn -EMSGSIZE;\n\n\tskb = nlmsg_new(len, gfp_mask);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\t \n\tdata = ibnl_put_msg(skb, &nlh, query->seq, 0, RDMA_NL_LS,\n\t\t\t    RDMA_NL_LS_OP_RESOLVE, NLM_F_REQUEST);\n\tif (!data) {\n\t\tnlmsg_free(skb);\n\t\treturn -EMSGSIZE;\n\t}\n\n\t \n\tib_nl_set_path_rec_attrs(skb, query);\n\n\t \n\tnlmsg_end(skb, nlh);\n\n\tgfp_flag = ((gfp_mask & GFP_ATOMIC) == GFP_ATOMIC) ? GFP_ATOMIC :\n\t\tGFP_NOWAIT;\n\n\tspin_lock_irqsave(&ib_nl_request_lock, flags);\n\tret = rdma_nl_multicast(&init_net, skb, RDMA_NL_GROUP_LS, gfp_flag);\n\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tdelay = msecs_to_jiffies(sa_local_svc_timeout_ms);\n\tquery->timeout = delay + jiffies;\n\tlist_add_tail(&query->list, &ib_nl_request_list);\n\t \n\tif (ib_nl_request_list.next == &query->list)\n\t\tqueue_delayed_work(ib_nl_wq, &ib_nl_timed_work, delay);\n\nout:\n\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n\n\treturn ret;\n}\n\nstatic int ib_nl_cancel_request(struct ib_sa_query *query)\n{\n\tunsigned long flags;\n\tstruct ib_sa_query *wait_query;\n\tint found = 0;\n\n\tspin_lock_irqsave(&ib_nl_request_lock, flags);\n\tlist_for_each_entry(wait_query, &ib_nl_request_list, list) {\n\t\t \n\t\tif (query == wait_query) {\n\t\t\tquery->flags |= IB_SA_CANCEL;\n\t\t\tquery->timeout = jiffies;\n\t\t\tlist_move(&query->list, &ib_nl_request_list);\n\t\t\tfound = 1;\n\t\t\tmod_delayed_work(ib_nl_wq, &ib_nl_timed_work, 1);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n\n\treturn found;\n}\n\nstatic void send_handler(struct ib_mad_agent *agent,\n\t\t\t struct ib_mad_send_wc *mad_send_wc);\n\nstatic void ib_nl_process_good_resolve_rsp(struct ib_sa_query *query,\n\t\t\t\t\t   const struct nlmsghdr *nlh)\n{\n\tstruct sa_path_rec recs[RDMA_PRIMARY_PATH_MAX_REC_NUM];\n\tstruct ib_sa_path_query *path_query;\n\tstruct ib_path_rec_data *rec_data;\n\tstruct ib_mad_send_wc mad_send_wc;\n\tconst struct nlattr *head, *curr;\n\tstruct ib_sa_mad *mad = NULL;\n\tint len, rem, status = -EIO;\n\tunsigned int num_prs = 0;\n\tu32 mask = 0;\n\n\tif (!query->callback)\n\t\tgoto out;\n\n\tpath_query = container_of(query, struct ib_sa_path_query, sa_query);\n\tmad = query->mad_buf->mad;\n\n\thead = (const struct nlattr *) nlmsg_data(nlh);\n\tlen = nlmsg_len(nlh);\n\tswitch (query->path_use) {\n\tcase LS_RESOLVE_PATH_USE_UNIDIRECTIONAL:\n\t\tmask = IB_PATH_PRIMARY | IB_PATH_OUTBOUND;\n\t\tbreak;\n\n\tcase LS_RESOLVE_PATH_USE_ALL:\n\t\tmask = IB_PATH_PRIMARY;\n\t\tbreak;\n\n\tcase LS_RESOLVE_PATH_USE_GMP:\n\tdefault:\n\t\tmask = IB_PATH_PRIMARY | IB_PATH_GMP |\n\t\t\tIB_PATH_BIDIRECTIONAL;\n\t\tbreak;\n\t}\n\n\tnla_for_each_attr(curr, head, len, rem) {\n\t\tif (curr->nla_type != LS_NLA_TYPE_PATH_RECORD)\n\t\t\tcontinue;\n\n\t\trec_data = nla_data(curr);\n\t\tif ((rec_data->flags & mask) != mask)\n\t\t\tcontinue;\n\n\t\tif ((query->flags & IB_SA_QUERY_OPA) ||\n\t\t    path_query->conv_pr) {\n\t\t\tmad->mad_hdr.method |= IB_MGMT_METHOD_RESP;\n\t\t\tmemcpy(mad->data, rec_data->path_rec,\n\t\t\t       sizeof(rec_data->path_rec));\n\t\t\tquery->callback(query, 0, mad);\n\t\t\tgoto out;\n\t\t}\n\n\t\tstatus = 0;\n\t\tib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table),\n\t\t\t  rec_data->path_rec, &recs[num_prs]);\n\t\trecs[num_prs].flags = rec_data->flags;\n\t\trecs[num_prs].rec_type = SA_PATH_REC_TYPE_IB;\n\t\tsa_path_set_dmac_zero(&recs[num_prs]);\n\n\t\tnum_prs++;\n\t\tif (num_prs >= RDMA_PRIMARY_PATH_MAX_REC_NUM)\n\t\t\tbreak;\n\t}\n\n\tif (!status) {\n\t\tmad->mad_hdr.method |= IB_MGMT_METHOD_RESP;\n\t\tpath_query->callback(status, recs, num_prs,\n\t\t\t\t     path_query->context);\n\t} else\n\t\tquery->callback(query, status, mad);\n\nout:\n\tmad_send_wc.send_buf = query->mad_buf;\n\tmad_send_wc.status = IB_WC_SUCCESS;\n\tsend_handler(query->mad_buf->mad_agent, &mad_send_wc);\n}\n\nstatic void ib_nl_request_timeout(struct work_struct *work)\n{\n\tunsigned long flags;\n\tstruct ib_sa_query *query;\n\tunsigned long delay;\n\tstruct ib_mad_send_wc mad_send_wc;\n\tint ret;\n\n\tspin_lock_irqsave(&ib_nl_request_lock, flags);\n\twhile (!list_empty(&ib_nl_request_list)) {\n\t\tquery = list_entry(ib_nl_request_list.next,\n\t\t\t\t   struct ib_sa_query, list);\n\n\t\tif (time_after(query->timeout, jiffies)) {\n\t\t\tdelay = query->timeout - jiffies;\n\t\t\tif ((long)delay <= 0)\n\t\t\t\tdelay = 1;\n\t\t\tqueue_delayed_work(ib_nl_wq, &ib_nl_timed_work, delay);\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_del(&query->list);\n\t\tib_sa_disable_local_svc(query);\n\t\t \n\t\tif (ib_sa_query_cancelled(query))\n\t\t\tret = -1;\n\t\telse\n\t\t\tret = ib_post_send_mad(query->mad_buf, NULL);\n\t\tif (ret) {\n\t\t\tmad_send_wc.send_buf = query->mad_buf;\n\t\t\tmad_send_wc.status = IB_WC_WR_FLUSH_ERR;\n\t\t\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n\t\t\tsend_handler(query->port->agent, &mad_send_wc);\n\t\t\tspin_lock_irqsave(&ib_nl_request_lock, flags);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n}\n\nint ib_nl_handle_set_timeout(struct sk_buff *skb,\n\t\t\t     struct nlmsghdr *nlh,\n\t\t\t     struct netlink_ext_ack *extack)\n{\n\tint timeout, delta, abs_delta;\n\tconst struct nlattr *attr;\n\tunsigned long flags;\n\tstruct ib_sa_query *query;\n\tlong delay = 0;\n\tstruct nlattr *tb[LS_NLA_TYPE_MAX];\n\tint ret;\n\n\tif (!(nlh->nlmsg_flags & NLM_F_REQUEST) ||\n\t    !(NETLINK_CB(skb).sk))\n\t\treturn -EPERM;\n\n\tret = nla_parse_deprecated(tb, LS_NLA_TYPE_MAX - 1, nlmsg_data(nlh),\n\t\t\t\t   nlmsg_len(nlh), ib_nl_policy, NULL);\n\tattr = (const struct nlattr *)tb[LS_NLA_TYPE_TIMEOUT];\n\tif (ret || !attr)\n\t\tgoto settimeout_out;\n\n\ttimeout = *(int *) nla_data(attr);\n\tif (timeout < IB_SA_LOCAL_SVC_TIMEOUT_MIN)\n\t\ttimeout = IB_SA_LOCAL_SVC_TIMEOUT_MIN;\n\tif (timeout > IB_SA_LOCAL_SVC_TIMEOUT_MAX)\n\t\ttimeout = IB_SA_LOCAL_SVC_TIMEOUT_MAX;\n\n\tdelta = timeout - sa_local_svc_timeout_ms;\n\tif (delta < 0)\n\t\tabs_delta = -delta;\n\telse\n\t\tabs_delta = delta;\n\n\tif (delta != 0) {\n\t\tspin_lock_irqsave(&ib_nl_request_lock, flags);\n\t\tsa_local_svc_timeout_ms = timeout;\n\t\tlist_for_each_entry(query, &ib_nl_request_list, list) {\n\t\t\tif (delta < 0 && abs_delta > query->timeout)\n\t\t\t\tquery->timeout = 0;\n\t\t\telse\n\t\t\t\tquery->timeout += delta;\n\n\t\t\t \n\t\t\tif (!delay) {\n\t\t\t\tdelay = query->timeout - jiffies;\n\t\t\t\tif (delay <= 0)\n\t\t\t\t\tdelay = 1;\n\t\t\t}\n\t\t}\n\t\tif (delay)\n\t\t\tmod_delayed_work(ib_nl_wq, &ib_nl_timed_work,\n\t\t\t\t\t (unsigned long)delay);\n\t\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n\t}\n\nsettimeout_out:\n\treturn 0;\n}\n\nstatic inline int ib_nl_is_good_resolve_resp(const struct nlmsghdr *nlh)\n{\n\tstruct nlattr *tb[LS_NLA_TYPE_MAX];\n\tint ret;\n\n\tif (nlh->nlmsg_flags & RDMA_NL_LS_F_ERR)\n\t\treturn 0;\n\n\tret = nla_parse_deprecated(tb, LS_NLA_TYPE_MAX - 1, nlmsg_data(nlh),\n\t\t\t\t   nlmsg_len(nlh), ib_nl_policy, NULL);\n\tif (ret)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nint ib_nl_handle_resolve_resp(struct sk_buff *skb,\n\t\t\t      struct nlmsghdr *nlh,\n\t\t\t      struct netlink_ext_ack *extack)\n{\n\tunsigned long flags;\n\tstruct ib_sa_query *query = NULL, *iter;\n\tstruct ib_mad_send_buf *send_buf;\n\tstruct ib_mad_send_wc mad_send_wc;\n\tint ret;\n\n\tif ((nlh->nlmsg_flags & NLM_F_REQUEST) ||\n\t    !(NETLINK_CB(skb).sk))\n\t\treturn -EPERM;\n\n\tspin_lock_irqsave(&ib_nl_request_lock, flags);\n\tlist_for_each_entry(iter, &ib_nl_request_list, list) {\n\t\t \n\t\tif (nlh->nlmsg_seq == iter->seq) {\n\t\t\tif (!ib_sa_query_cancelled(iter)) {\n\t\t\t\tlist_del(&iter->list);\n\t\t\t\tquery = iter;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!query) {\n\t\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n\t\tgoto resp_out;\n\t}\n\n\tsend_buf = query->mad_buf;\n\n\tif (!ib_nl_is_good_resolve_resp(nlh)) {\n\t\t \n\t\tib_sa_disable_local_svc(query);\n\t\tret = ib_post_send_mad(query->mad_buf, NULL);\n\t\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n\t\tif (ret) {\n\t\t\tmad_send_wc.send_buf = send_buf;\n\t\t\tmad_send_wc.status = IB_WC_GENERAL_ERR;\n\t\t\tsend_handler(query->port->agent, &mad_send_wc);\n\t\t}\n\t} else {\n\t\tspin_unlock_irqrestore(&ib_nl_request_lock, flags);\n\t\tib_nl_process_good_resolve_rsp(query, nlh);\n\t}\n\nresp_out:\n\treturn 0;\n}\n\nstatic void free_sm_ah(struct kref *kref)\n{\n\tstruct ib_sa_sm_ah *sm_ah = container_of(kref, struct ib_sa_sm_ah, ref);\n\n\trdma_destroy_ah(sm_ah->ah, 0);\n\tkfree(sm_ah);\n}\n\nvoid ib_sa_register_client(struct ib_sa_client *client)\n{\n\tatomic_set(&client->users, 1);\n\tinit_completion(&client->comp);\n}\nEXPORT_SYMBOL(ib_sa_register_client);\n\nvoid ib_sa_unregister_client(struct ib_sa_client *client)\n{\n\tib_sa_client_put(client);\n\twait_for_completion(&client->comp);\n}\nEXPORT_SYMBOL(ib_sa_unregister_client);\n\n \nvoid ib_sa_cancel_query(int id, struct ib_sa_query *query)\n{\n\tunsigned long flags;\n\tstruct ib_mad_send_buf *mad_buf;\n\n\txa_lock_irqsave(&queries, flags);\n\tif (xa_load(&queries, id) != query) {\n\t\txa_unlock_irqrestore(&queries, flags);\n\t\treturn;\n\t}\n\tmad_buf = query->mad_buf;\n\txa_unlock_irqrestore(&queries, flags);\n\n\t \n\tif (!ib_nl_cancel_request(query))\n\t\tib_cancel_mad(mad_buf);\n}\nEXPORT_SYMBOL(ib_sa_cancel_query);\n\nstatic u8 get_src_path_mask(struct ib_device *device, u32 port_num)\n{\n\tstruct ib_sa_device *sa_dev;\n\tstruct ib_sa_port   *port;\n\tunsigned long flags;\n\tu8 src_path_mask;\n\n\tsa_dev = ib_get_client_data(device, &sa_client);\n\tif (!sa_dev)\n\t\treturn 0x7f;\n\n\tport  = &sa_dev->port[port_num - sa_dev->start_port];\n\tspin_lock_irqsave(&port->ah_lock, flags);\n\tsrc_path_mask = port->sm_ah ? port->sm_ah->src_path_mask : 0x7f;\n\tspin_unlock_irqrestore(&port->ah_lock, flags);\n\n\treturn src_path_mask;\n}\n\nstatic int init_ah_attr_grh_fields(struct ib_device *device, u32 port_num,\n\t\t\t\t   struct sa_path_rec *rec,\n\t\t\t\t   struct rdma_ah_attr *ah_attr,\n\t\t\t\t   const struct ib_gid_attr *gid_attr)\n{\n\tenum ib_gid_type type = sa_conv_pathrec_to_gid_type(rec);\n\n\tif (!gid_attr) {\n\t\tgid_attr = rdma_find_gid_by_port(device, &rec->sgid, type,\n\t\t\t\t\t\t port_num, NULL);\n\t\tif (IS_ERR(gid_attr))\n\t\t\treturn PTR_ERR(gid_attr);\n\t} else\n\t\trdma_hold_gid_attr(gid_attr);\n\n\trdma_move_grh_sgid_attr(ah_attr, &rec->dgid,\n\t\t\t\tbe32_to_cpu(rec->flow_label),\n\t\t\t\trec->hop_limit,\trec->traffic_class,\n\t\t\t\tgid_attr);\n\treturn 0;\n}\n\n \nint ib_init_ah_attr_from_path(struct ib_device *device, u32 port_num,\n\t\t\t      struct sa_path_rec *rec,\n\t\t\t      struct rdma_ah_attr *ah_attr,\n\t\t\t      const struct ib_gid_attr *gid_attr)\n{\n\tint ret = 0;\n\n\tmemset(ah_attr, 0, sizeof(*ah_attr));\n\tah_attr->type = rdma_ah_find_type(device, port_num);\n\trdma_ah_set_sl(ah_attr, rec->sl);\n\trdma_ah_set_port_num(ah_attr, port_num);\n\trdma_ah_set_static_rate(ah_attr, rec->rate);\n\n\tif (sa_path_is_roce(rec)) {\n\t\tret = roce_resolve_route_from_path(rec, gid_attr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tmemcpy(ah_attr->roce.dmac, sa_path_get_dmac(rec), ETH_ALEN);\n\t} else {\n\t\trdma_ah_set_dlid(ah_attr, be32_to_cpu(sa_path_get_dlid(rec)));\n\t\tif (sa_path_is_opa(rec) &&\n\t\t    rdma_ah_get_dlid(ah_attr) == be16_to_cpu(IB_LID_PERMISSIVE))\n\t\t\trdma_ah_set_make_grd(ah_attr, true);\n\n\t\trdma_ah_set_path_bits(ah_attr,\n\t\t\t\t      be32_to_cpu(sa_path_get_slid(rec)) &\n\t\t\t\t      get_src_path_mask(device, port_num));\n\t}\n\n\tif (rec->hop_limit > 0 || sa_path_is_roce(rec))\n\t\tret = init_ah_attr_grh_fields(device, port_num,\n\t\t\t\t\t      rec, ah_attr, gid_attr);\n\treturn ret;\n}\nEXPORT_SYMBOL(ib_init_ah_attr_from_path);\n\nstatic int alloc_mad(struct ib_sa_query *query, gfp_t gfp_mask)\n{\n\tstruct rdma_ah_attr ah_attr;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&query->port->ah_lock, flags);\n\tif (!query->port->sm_ah) {\n\t\tspin_unlock_irqrestore(&query->port->ah_lock, flags);\n\t\treturn -EAGAIN;\n\t}\n\tkref_get(&query->port->sm_ah->ref);\n\tquery->sm_ah = query->port->sm_ah;\n\tspin_unlock_irqrestore(&query->port->ah_lock, flags);\n\n\t \n\tif ((rdma_query_ah(query->sm_ah->ah, &ah_attr) < 0) ||\n\t    !rdma_is_valid_unicast_lid(&ah_attr)) {\n\t\tkref_put(&query->sm_ah->ref, free_sm_ah);\n\t\treturn -EAGAIN;\n\t}\n\tquery->mad_buf = ib_create_send_mad(query->port->agent, 1,\n\t\t\t\t\t    query->sm_ah->pkey_index,\n\t\t\t\t\t    0, IB_MGMT_SA_HDR, IB_MGMT_SA_DATA,\n\t\t\t\t\t    gfp_mask,\n\t\t\t\t\t    ((query->flags & IB_SA_QUERY_OPA) ?\n\t\t\t\t\t     OPA_MGMT_BASE_VERSION :\n\t\t\t\t\t     IB_MGMT_BASE_VERSION));\n\tif (IS_ERR(query->mad_buf)) {\n\t\tkref_put(&query->sm_ah->ref, free_sm_ah);\n\t\treturn -ENOMEM;\n\t}\n\n\tquery->mad_buf->ah = query->sm_ah->ah;\n\n\treturn 0;\n}\n\nstatic void free_mad(struct ib_sa_query *query)\n{\n\tib_free_send_mad(query->mad_buf);\n\tkref_put(&query->sm_ah->ref, free_sm_ah);\n}\n\nstatic void init_mad(struct ib_sa_query *query, struct ib_mad_agent *agent)\n{\n\tstruct ib_sa_mad *mad = query->mad_buf->mad;\n\tunsigned long flags;\n\n\tmemset(mad, 0, sizeof *mad);\n\n\tif (query->flags & IB_SA_QUERY_OPA) {\n\t\tmad->mad_hdr.base_version  = OPA_MGMT_BASE_VERSION;\n\t\tmad->mad_hdr.class_version = OPA_SA_CLASS_VERSION;\n\t} else {\n\t\tmad->mad_hdr.base_version  = IB_MGMT_BASE_VERSION;\n\t\tmad->mad_hdr.class_version = IB_SA_CLASS_VERSION;\n\t}\n\tmad->mad_hdr.mgmt_class    = IB_MGMT_CLASS_SUBN_ADM;\n\tspin_lock_irqsave(&tid_lock, flags);\n\tmad->mad_hdr.tid           =\n\t\tcpu_to_be64(((u64) agent->hi_tid) << 32 | tid++);\n\tspin_unlock_irqrestore(&tid_lock, flags);\n}\n\nstatic int send_mad(struct ib_sa_query *query, unsigned long timeout_ms,\n\t\t    gfp_t gfp_mask)\n{\n\tunsigned long flags;\n\tint ret, id;\n\tconst int nmbr_sa_query_retries = 10;\n\n\txa_lock_irqsave(&queries, flags);\n\tret = __xa_alloc(&queries, &id, query, xa_limit_32b, gfp_mask);\n\txa_unlock_irqrestore(&queries, flags);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tquery->mad_buf->timeout_ms  = timeout_ms / nmbr_sa_query_retries;\n\tquery->mad_buf->retries = nmbr_sa_query_retries;\n\tif (!query->mad_buf->timeout_ms) {\n\t\t \n\t\tquery->mad_buf->timeout_ms = 1;\n\t\tquery->mad_buf->retries = timeout_ms;\n\t}\n\tquery->mad_buf->context[0] = query;\n\tquery->id = id;\n\n\tif ((query->flags & IB_SA_ENABLE_LOCAL_SERVICE) &&\n\t    (!(query->flags & IB_SA_QUERY_OPA))) {\n\t\tif (rdma_nl_chk_listeners(RDMA_NL_GROUP_LS)) {\n\t\t\tif (!ib_nl_make_request(query, gfp_mask))\n\t\t\t\treturn id;\n\t\t}\n\t\tib_sa_disable_local_svc(query);\n\t}\n\n\tret = ib_post_send_mad(query->mad_buf, NULL);\n\tif (ret) {\n\t\txa_lock_irqsave(&queries, flags);\n\t\t__xa_erase(&queries, id);\n\t\txa_unlock_irqrestore(&queries, flags);\n\t}\n\n\t \n\treturn ret ? ret : id;\n}\n\nvoid ib_sa_unpack_path(void *attribute, struct sa_path_rec *rec)\n{\n\tib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table), attribute, rec);\n}\nEXPORT_SYMBOL(ib_sa_unpack_path);\n\nvoid ib_sa_pack_path(struct sa_path_rec *rec, void *attribute)\n{\n\tib_pack(path_rec_table, ARRAY_SIZE(path_rec_table), rec, attribute);\n}\nEXPORT_SYMBOL(ib_sa_pack_path);\n\nstatic bool ib_sa_opa_pathrecord_support(struct ib_sa_client *client,\n\t\t\t\t\t struct ib_sa_device *sa_dev,\n\t\t\t\t\t u32 port_num)\n{\n\tstruct ib_sa_port *port;\n\tunsigned long flags;\n\tbool ret = false;\n\n\tport = &sa_dev->port[port_num - sa_dev->start_port];\n\tspin_lock_irqsave(&port->classport_lock, flags);\n\tif (!port->classport_info.valid)\n\t\tgoto ret;\n\n\tif (port->classport_info.data.type == RDMA_CLASS_PORT_INFO_OPA)\n\t\tret = opa_get_cpi_capmask2(&port->classport_info.data.opa) &\n\t\t\tOPA_CLASS_PORT_INFO_PR_SUPPORT;\nret:\n\tspin_unlock_irqrestore(&port->classport_lock, flags);\n\treturn ret;\n}\n\nenum opa_pr_supported {\n\tPR_NOT_SUPPORTED,\n\tPR_OPA_SUPPORTED,\n\tPR_IB_SUPPORTED\n};\n\n \nstatic int opa_pr_query_possible(struct ib_sa_client *client,\n\t\t\t\t struct ib_sa_device *sa_dev,\n\t\t\t\t struct ib_device *device, u32 port_num)\n{\n\tstruct ib_port_attr port_attr;\n\n\tif (ib_query_port(device, port_num, &port_attr))\n\t\treturn PR_NOT_SUPPORTED;\n\n\tif (ib_sa_opa_pathrecord_support(client, sa_dev, port_num))\n\t\treturn PR_OPA_SUPPORTED;\n\n\tif (port_attr.lid >= be16_to_cpu(IB_MULTICAST_LID_BASE))\n\t\treturn PR_NOT_SUPPORTED;\n\telse\n\t\treturn PR_IB_SUPPORTED;\n}\n\nstatic void ib_sa_path_rec_callback(struct ib_sa_query *sa_query,\n\t\t\t\t    int status, struct ib_sa_mad *mad)\n{\n\tstruct ib_sa_path_query *query =\n\t\tcontainer_of(sa_query, struct ib_sa_path_query, sa_query);\n\tstruct sa_path_rec rec = {};\n\n\tif (!mad) {\n\t\tquery->callback(status, NULL, 0, query->context);\n\t\treturn;\n\t}\n\n\tif (sa_query->flags & IB_SA_QUERY_OPA) {\n\t\tib_unpack(opa_path_rec_table, ARRAY_SIZE(opa_path_rec_table),\n\t\t\t  mad->data, &rec);\n\t\trec.rec_type = SA_PATH_REC_TYPE_OPA;\n\t\tquery->callback(status, &rec, 1, query->context);\n\t\treturn;\n\t}\n\n\tib_unpack(path_rec_table, ARRAY_SIZE(path_rec_table),\n\t\t  mad->data, &rec);\n\trec.rec_type = SA_PATH_REC_TYPE_IB;\n\tsa_path_set_dmac_zero(&rec);\n\n\tif (query->conv_pr) {\n\t\tstruct sa_path_rec opa;\n\n\t\tmemset(&opa, 0, sizeof(struct sa_path_rec));\n\t\tsa_convert_path_ib_to_opa(&opa, &rec);\n\t\tquery->callback(status, &opa, 1, query->context);\n\t} else {\n\t\tquery->callback(status, &rec, 1, query->context);\n\t}\n}\n\nstatic void ib_sa_path_rec_release(struct ib_sa_query *sa_query)\n{\n\tstruct ib_sa_path_query *query =\n\t\tcontainer_of(sa_query, struct ib_sa_path_query, sa_query);\n\n\tkfree(query->conv_pr);\n\tkfree(query);\n}\n\n \nint ib_sa_path_rec_get(struct ib_sa_client *client,\n\t\t       struct ib_device *device, u32 port_num,\n\t\t       struct sa_path_rec *rec,\n\t\t       ib_sa_comp_mask comp_mask,\n\t\t       unsigned long timeout_ms, gfp_t gfp_mask,\n\t\t       void (*callback)(int status,\n\t\t\t\t\tstruct sa_path_rec *resp,\n\t\t\t\t\tunsigned int num_paths, void *context),\n\t\t       void *context,\n\t\t       struct ib_sa_query **sa_query)\n{\n\tstruct ib_sa_path_query *query;\n\tstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\n\tstruct ib_sa_port   *port;\n\tstruct ib_mad_agent *agent;\n\tstruct ib_sa_mad *mad;\n\tenum opa_pr_supported status;\n\tint ret;\n\n\tif (!sa_dev)\n\t\treturn -ENODEV;\n\n\tif ((rec->rec_type != SA_PATH_REC_TYPE_IB) &&\n\t    (rec->rec_type != SA_PATH_REC_TYPE_OPA))\n\t\treturn -EINVAL;\n\n\tport  = &sa_dev->port[port_num - sa_dev->start_port];\n\tagent = port->agent;\n\n\tquery = kzalloc(sizeof(*query), gfp_mask);\n\tif (!query)\n\t\treturn -ENOMEM;\n\n\tquery->sa_query.port     = port;\n\tif (rec->rec_type == SA_PATH_REC_TYPE_OPA) {\n\t\tstatus = opa_pr_query_possible(client, sa_dev, device, port_num);\n\t\tif (status == PR_NOT_SUPPORTED) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err1;\n\t\t} else if (status == PR_OPA_SUPPORTED) {\n\t\t\tquery->sa_query.flags |= IB_SA_QUERY_OPA;\n\t\t} else {\n\t\t\tquery->conv_pr =\n\t\t\t\tkmalloc(sizeof(*query->conv_pr), gfp_mask);\n\t\t\tif (!query->conv_pr) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto err1;\n\t\t\t}\n\t\t}\n\t}\n\n\tret = alloc_mad(&query->sa_query, gfp_mask);\n\tif (ret)\n\t\tgoto err2;\n\n\tib_sa_client_get(client);\n\tquery->sa_query.client = client;\n\tquery->callback        = callback;\n\tquery->context         = context;\n\n\tmad = query->sa_query.mad_buf->mad;\n\tinit_mad(&query->sa_query, agent);\n\n\tquery->sa_query.callback = callback ? ib_sa_path_rec_callback : NULL;\n\tquery->sa_query.release  = ib_sa_path_rec_release;\n\tmad->mad_hdr.method\t = IB_MGMT_METHOD_GET;\n\tmad->mad_hdr.attr_id\t = cpu_to_be16(IB_SA_ATTR_PATH_REC);\n\tmad->sa_hdr.comp_mask\t = comp_mask;\n\n\tif (query->sa_query.flags & IB_SA_QUERY_OPA) {\n\t\tib_pack(opa_path_rec_table, ARRAY_SIZE(opa_path_rec_table),\n\t\t\trec, mad->data);\n\t} else if (query->conv_pr) {\n\t\tsa_convert_path_opa_to_ib(query->conv_pr, rec);\n\t\tib_pack(path_rec_table, ARRAY_SIZE(path_rec_table),\n\t\t\tquery->conv_pr, mad->data);\n\t} else {\n\t\tib_pack(path_rec_table, ARRAY_SIZE(path_rec_table),\n\t\t\trec, mad->data);\n\t}\n\n\t*sa_query = &query->sa_query;\n\n\tquery->sa_query.flags |= IB_SA_ENABLE_LOCAL_SERVICE;\n\tquery->sa_query.mad_buf->context[1] = (query->conv_pr) ?\n\t\t\t\t\t\tquery->conv_pr : rec;\n\n\tret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\n\tif (ret < 0)\n\t\tgoto err3;\n\n\treturn ret;\n\nerr3:\n\t*sa_query = NULL;\n\tib_sa_client_put(query->sa_query.client);\n\tfree_mad(&query->sa_query);\nerr2:\n\tkfree(query->conv_pr);\nerr1:\n\tkfree(query);\n\treturn ret;\n}\nEXPORT_SYMBOL(ib_sa_path_rec_get);\n\nstatic void ib_sa_mcmember_rec_callback(struct ib_sa_query *sa_query,\n\t\t\t\t\tint status, struct ib_sa_mad *mad)\n{\n\tstruct ib_sa_mcmember_query *query =\n\t\tcontainer_of(sa_query, struct ib_sa_mcmember_query, sa_query);\n\n\tif (mad) {\n\t\tstruct ib_sa_mcmember_rec rec;\n\n\t\tib_unpack(mcmember_rec_table, ARRAY_SIZE(mcmember_rec_table),\n\t\t\t  mad->data, &rec);\n\t\tquery->callback(status, &rec, query->context);\n\t} else\n\t\tquery->callback(status, NULL, query->context);\n}\n\nstatic void ib_sa_mcmember_rec_release(struct ib_sa_query *sa_query)\n{\n\tkfree(container_of(sa_query, struct ib_sa_mcmember_query, sa_query));\n}\n\nint ib_sa_mcmember_rec_query(struct ib_sa_client *client,\n\t\t\t     struct ib_device *device, u32 port_num,\n\t\t\t     u8 method,\n\t\t\t     struct ib_sa_mcmember_rec *rec,\n\t\t\t     ib_sa_comp_mask comp_mask,\n\t\t\t     unsigned long timeout_ms, gfp_t gfp_mask,\n\t\t\t     void (*callback)(int status,\n\t\t\t\t\t      struct ib_sa_mcmember_rec *resp,\n\t\t\t\t\t      void *context),\n\t\t\t     void *context,\n\t\t\t     struct ib_sa_query **sa_query)\n{\n\tstruct ib_sa_mcmember_query *query;\n\tstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\n\tstruct ib_sa_port   *port;\n\tstruct ib_mad_agent *agent;\n\tstruct ib_sa_mad *mad;\n\tint ret;\n\n\tif (!sa_dev)\n\t\treturn -ENODEV;\n\n\tport  = &sa_dev->port[port_num - sa_dev->start_port];\n\tagent = port->agent;\n\n\tquery = kzalloc(sizeof(*query), gfp_mask);\n\tif (!query)\n\t\treturn -ENOMEM;\n\n\tquery->sa_query.port     = port;\n\tret = alloc_mad(&query->sa_query, gfp_mask);\n\tif (ret)\n\t\tgoto err1;\n\n\tib_sa_client_get(client);\n\tquery->sa_query.client = client;\n\tquery->callback        = callback;\n\tquery->context         = context;\n\n\tmad = query->sa_query.mad_buf->mad;\n\tinit_mad(&query->sa_query, agent);\n\n\tquery->sa_query.callback = callback ? ib_sa_mcmember_rec_callback : NULL;\n\tquery->sa_query.release  = ib_sa_mcmember_rec_release;\n\tmad->mad_hdr.method\t = method;\n\tmad->mad_hdr.attr_id\t = cpu_to_be16(IB_SA_ATTR_MC_MEMBER_REC);\n\tmad->sa_hdr.comp_mask\t = comp_mask;\n\n\tib_pack(mcmember_rec_table, ARRAY_SIZE(mcmember_rec_table),\n\t\trec, mad->data);\n\n\t*sa_query = &query->sa_query;\n\n\tret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\n\tif (ret < 0)\n\t\tgoto err2;\n\n\treturn ret;\n\nerr2:\n\t*sa_query = NULL;\n\tib_sa_client_put(query->sa_query.client);\n\tfree_mad(&query->sa_query);\n\nerr1:\n\tkfree(query);\n\treturn ret;\n}\n\n \nstatic void ib_sa_guidinfo_rec_callback(struct ib_sa_query *sa_query,\n\t\t\t\t\tint status, struct ib_sa_mad *mad)\n{\n\tstruct ib_sa_guidinfo_query *query =\n\t\tcontainer_of(sa_query, struct ib_sa_guidinfo_query, sa_query);\n\n\tif (mad) {\n\t\tstruct ib_sa_guidinfo_rec rec;\n\n\t\tib_unpack(guidinfo_rec_table, ARRAY_SIZE(guidinfo_rec_table),\n\t\t\t  mad->data, &rec);\n\t\tquery->callback(status, &rec, query->context);\n\t} else\n\t\tquery->callback(status, NULL, query->context);\n}\n\nstatic void ib_sa_guidinfo_rec_release(struct ib_sa_query *sa_query)\n{\n\tkfree(container_of(sa_query, struct ib_sa_guidinfo_query, sa_query));\n}\n\nint ib_sa_guid_info_rec_query(struct ib_sa_client *client,\n\t\t\t      struct ib_device *device, u32 port_num,\n\t\t\t      struct ib_sa_guidinfo_rec *rec,\n\t\t\t      ib_sa_comp_mask comp_mask, u8 method,\n\t\t\t      unsigned long timeout_ms, gfp_t gfp_mask,\n\t\t\t      void (*callback)(int status,\n\t\t\t\t\t       struct ib_sa_guidinfo_rec *resp,\n\t\t\t\t\t       void *context),\n\t\t\t      void *context,\n\t\t\t      struct ib_sa_query **sa_query)\n{\n\tstruct ib_sa_guidinfo_query *query;\n\tstruct ib_sa_device *sa_dev = ib_get_client_data(device, &sa_client);\n\tstruct ib_sa_port *port;\n\tstruct ib_mad_agent *agent;\n\tstruct ib_sa_mad *mad;\n\tint ret;\n\n\tif (!sa_dev)\n\t\treturn -ENODEV;\n\n\tif (method != IB_MGMT_METHOD_GET &&\n\t    method != IB_MGMT_METHOD_SET &&\n\t    method != IB_SA_METHOD_DELETE) {\n\t\treturn -EINVAL;\n\t}\n\n\tport  = &sa_dev->port[port_num - sa_dev->start_port];\n\tagent = port->agent;\n\n\tquery = kzalloc(sizeof(*query), gfp_mask);\n\tif (!query)\n\t\treturn -ENOMEM;\n\n\tquery->sa_query.port = port;\n\tret = alloc_mad(&query->sa_query, gfp_mask);\n\tif (ret)\n\t\tgoto err1;\n\n\tib_sa_client_get(client);\n\tquery->sa_query.client = client;\n\tquery->callback        = callback;\n\tquery->context         = context;\n\n\tmad = query->sa_query.mad_buf->mad;\n\tinit_mad(&query->sa_query, agent);\n\n\tquery->sa_query.callback = callback ? ib_sa_guidinfo_rec_callback : NULL;\n\tquery->sa_query.release  = ib_sa_guidinfo_rec_release;\n\n\tmad->mad_hdr.method\t = method;\n\tmad->mad_hdr.attr_id\t = cpu_to_be16(IB_SA_ATTR_GUID_INFO_REC);\n\tmad->sa_hdr.comp_mask\t = comp_mask;\n\n\tib_pack(guidinfo_rec_table, ARRAY_SIZE(guidinfo_rec_table), rec,\n\t\tmad->data);\n\n\t*sa_query = &query->sa_query;\n\n\tret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\n\tif (ret < 0)\n\t\tgoto err2;\n\n\treturn ret;\n\nerr2:\n\t*sa_query = NULL;\n\tib_sa_client_put(query->sa_query.client);\n\tfree_mad(&query->sa_query);\n\nerr1:\n\tkfree(query);\n\treturn ret;\n}\nEXPORT_SYMBOL(ib_sa_guid_info_rec_query);\n\nstruct ib_classport_info_context {\n\tstruct completion\tdone;\n\tstruct ib_sa_query\t*sa_query;\n};\n\nstatic void ib_classportinfo_cb(void *context)\n{\n\tstruct ib_classport_info_context *cb_ctx = context;\n\n\tcomplete(&cb_ctx->done);\n}\n\nstatic void ib_sa_classport_info_rec_callback(struct ib_sa_query *sa_query,\n\t\t\t\t\t      int status, struct ib_sa_mad *mad)\n{\n\tunsigned long flags;\n\tstruct ib_sa_classport_info_query *query =\n\t\tcontainer_of(sa_query, struct ib_sa_classport_info_query, sa_query);\n\tstruct ib_sa_classport_cache *info = &sa_query->port->classport_info;\n\n\tif (mad) {\n\t\tif (sa_query->flags & IB_SA_QUERY_OPA) {\n\t\t\tstruct opa_class_port_info rec;\n\n\t\t\tib_unpack(opa_classport_info_rec_table,\n\t\t\t\t  ARRAY_SIZE(opa_classport_info_rec_table),\n\t\t\t\t  mad->data, &rec);\n\n\t\t\tspin_lock_irqsave(&sa_query->port->classport_lock,\n\t\t\t\t\t  flags);\n\t\t\tif (!status && !info->valid) {\n\t\t\t\tmemcpy(&info->data.opa, &rec,\n\t\t\t\t       sizeof(info->data.opa));\n\n\t\t\t\tinfo->valid = true;\n\t\t\t\tinfo->data.type = RDMA_CLASS_PORT_INFO_OPA;\n\t\t\t}\n\t\t\tspin_unlock_irqrestore(&sa_query->port->classport_lock,\n\t\t\t\t\t       flags);\n\n\t\t} else {\n\t\t\tstruct ib_class_port_info rec;\n\n\t\t\tib_unpack(ib_classport_info_rec_table,\n\t\t\t\t  ARRAY_SIZE(ib_classport_info_rec_table),\n\t\t\t\t  mad->data, &rec);\n\n\t\t\tspin_lock_irqsave(&sa_query->port->classport_lock,\n\t\t\t\t\t  flags);\n\t\t\tif (!status && !info->valid) {\n\t\t\t\tmemcpy(&info->data.ib, &rec,\n\t\t\t\t       sizeof(info->data.ib));\n\n\t\t\t\tinfo->valid = true;\n\t\t\t\tinfo->data.type = RDMA_CLASS_PORT_INFO_IB;\n\t\t\t}\n\t\t\tspin_unlock_irqrestore(&sa_query->port->classport_lock,\n\t\t\t\t\t       flags);\n\t\t}\n\t}\n\tquery->callback(query->context);\n}\n\nstatic void ib_sa_classport_info_rec_release(struct ib_sa_query *sa_query)\n{\n\tkfree(container_of(sa_query, struct ib_sa_classport_info_query,\n\t\t\t   sa_query));\n}\n\nstatic int ib_sa_classport_info_rec_query(struct ib_sa_port *port,\n\t\t\t\t\t  unsigned long timeout_ms,\n\t\t\t\t\t  void (*callback)(void *context),\n\t\t\t\t\t  void *context,\n\t\t\t\t\t  struct ib_sa_query **sa_query)\n{\n\tstruct ib_mad_agent *agent;\n\tstruct ib_sa_classport_info_query *query;\n\tstruct ib_sa_mad *mad;\n\tgfp_t gfp_mask = GFP_KERNEL;\n\tint ret;\n\n\tagent = port->agent;\n\n\tquery = kzalloc(sizeof(*query), gfp_mask);\n\tif (!query)\n\t\treturn -ENOMEM;\n\n\tquery->sa_query.port = port;\n\tquery->sa_query.flags |= rdma_cap_opa_ah(port->agent->device,\n\t\t\t\t\t\t port->port_num) ?\n\t\t\t\t IB_SA_QUERY_OPA : 0;\n\tret = alloc_mad(&query->sa_query, gfp_mask);\n\tif (ret)\n\t\tgoto err_free;\n\n\tquery->callback = callback;\n\tquery->context = context;\n\n\tmad = query->sa_query.mad_buf->mad;\n\tinit_mad(&query->sa_query, agent);\n\n\tquery->sa_query.callback = ib_sa_classport_info_rec_callback;\n\tquery->sa_query.release  = ib_sa_classport_info_rec_release;\n\tmad->mad_hdr.method\t = IB_MGMT_METHOD_GET;\n\tmad->mad_hdr.attr_id\t = cpu_to_be16(IB_SA_ATTR_CLASS_PORTINFO);\n\tmad->sa_hdr.comp_mask\t = 0;\n\t*sa_query = &query->sa_query;\n\n\tret = send_mad(&query->sa_query, timeout_ms, gfp_mask);\n\tif (ret < 0)\n\t\tgoto err_free_mad;\n\n\treturn ret;\n\nerr_free_mad:\n\t*sa_query = NULL;\n\tfree_mad(&query->sa_query);\n\nerr_free:\n\tkfree(query);\n\treturn ret;\n}\n\nstatic void update_ib_cpi(struct work_struct *work)\n{\n\tstruct ib_sa_port *port =\n\t\tcontainer_of(work, struct ib_sa_port, ib_cpi_work.work);\n\tstruct ib_classport_info_context *cb_context;\n\tunsigned long flags;\n\tint ret;\n\n\t \n\tspin_lock_irqsave(&port->classport_lock, flags);\n\tif (port->classport_info.valid) {\n\t\tspin_unlock_irqrestore(&port->classport_lock, flags);\n\t\treturn;\n\t}\n\tspin_unlock_irqrestore(&port->classport_lock, flags);\n\n\tcb_context = kmalloc(sizeof(*cb_context), GFP_KERNEL);\n\tif (!cb_context)\n\t\tgoto err_nomem;\n\n\tinit_completion(&cb_context->done);\n\n\tret = ib_sa_classport_info_rec_query(port, 3000,\n\t\t\t\t\t     ib_classportinfo_cb, cb_context,\n\t\t\t\t\t     &cb_context->sa_query);\n\tif (ret < 0)\n\t\tgoto free_cb_err;\n\twait_for_completion(&cb_context->done);\nfree_cb_err:\n\tkfree(cb_context);\n\tspin_lock_irqsave(&port->classport_lock, flags);\n\n\t \n\tif (!port->classport_info.valid) {\n\t\tport->classport_info.retry_cnt++;\n\t\tif (port->classport_info.retry_cnt <=\n\t\t    IB_SA_CPI_MAX_RETRY_CNT) {\n\t\t\tunsigned long delay =\n\t\t\t\tmsecs_to_jiffies(IB_SA_CPI_RETRY_WAIT);\n\n\t\t\tqueue_delayed_work(ib_wq, &port->ib_cpi_work, delay);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&port->classport_lock, flags);\n\nerr_nomem:\n\treturn;\n}\n\nstatic void send_handler(struct ib_mad_agent *agent,\n\t\t\t struct ib_mad_send_wc *mad_send_wc)\n{\n\tstruct ib_sa_query *query = mad_send_wc->send_buf->context[0];\n\tunsigned long flags;\n\n\tif (query->callback)\n\t\tswitch (mad_send_wc->status) {\n\t\tcase IB_WC_SUCCESS:\n\t\t\t \n\t\t\tbreak;\n\t\tcase IB_WC_RESP_TIMEOUT_ERR:\n\t\t\tquery->callback(query, -ETIMEDOUT, NULL);\n\t\t\tbreak;\n\t\tcase IB_WC_WR_FLUSH_ERR:\n\t\t\tquery->callback(query, -EINTR, NULL);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tquery->callback(query, -EIO, NULL);\n\t\t\tbreak;\n\t\t}\n\n\txa_lock_irqsave(&queries, flags);\n\t__xa_erase(&queries, query->id);\n\txa_unlock_irqrestore(&queries, flags);\n\n\tfree_mad(query);\n\tif (query->client)\n\t\tib_sa_client_put(query->client);\n\tquery->release(query);\n}\n\nstatic void recv_handler(struct ib_mad_agent *mad_agent,\n\t\t\t struct ib_mad_send_buf *send_buf,\n\t\t\t struct ib_mad_recv_wc *mad_recv_wc)\n{\n\tstruct ib_sa_query *query;\n\n\tif (!send_buf)\n\t\treturn;\n\n\tquery = send_buf->context[0];\n\tif (query->callback) {\n\t\tif (mad_recv_wc->wc->status == IB_WC_SUCCESS)\n\t\t\tquery->callback(query,\n\t\t\t\t\tmad_recv_wc->recv_buf.mad->mad_hdr.status ?\n\t\t\t\t\t-EINVAL : 0,\n\t\t\t\t\t(struct ib_sa_mad *) mad_recv_wc->recv_buf.mad);\n\t\telse\n\t\t\tquery->callback(query, -EIO, NULL);\n\t}\n\n\tib_free_recv_mad(mad_recv_wc);\n}\n\nstatic void update_sm_ah(struct work_struct *work)\n{\n\tstruct ib_sa_port *port =\n\t\tcontainer_of(work, struct ib_sa_port, update_task);\n\tstruct ib_sa_sm_ah *new_ah;\n\tstruct ib_port_attr port_attr;\n\tstruct rdma_ah_attr   ah_attr;\n\tbool grh_required;\n\n\tif (ib_query_port(port->agent->device, port->port_num, &port_attr)) {\n\t\tpr_warn(\"Couldn't query port\\n\");\n\t\treturn;\n\t}\n\n\tnew_ah = kmalloc(sizeof(*new_ah), GFP_KERNEL);\n\tif (!new_ah)\n\t\treturn;\n\n\tkref_init(&new_ah->ref);\n\tnew_ah->src_path_mask = (1 << port_attr.lmc) - 1;\n\n\tnew_ah->pkey_index = 0;\n\tif (ib_find_pkey(port->agent->device, port->port_num,\n\t\t\t IB_DEFAULT_PKEY_FULL, &new_ah->pkey_index))\n\t\tpr_err(\"Couldn't find index for default PKey\\n\");\n\n\tmemset(&ah_attr, 0, sizeof(ah_attr));\n\tah_attr.type = rdma_ah_find_type(port->agent->device,\n\t\t\t\t\t port->port_num);\n\trdma_ah_set_dlid(&ah_attr, port_attr.sm_lid);\n\trdma_ah_set_sl(&ah_attr, port_attr.sm_sl);\n\trdma_ah_set_port_num(&ah_attr, port->port_num);\n\n\tgrh_required = rdma_is_grh_required(port->agent->device,\n\t\t\t\t\t    port->port_num);\n\n\t \n\tif (ah_attr.type == RDMA_AH_ATTR_TYPE_OPA &&\n\t    (grh_required ||\n\t     port_attr.sm_lid == be16_to_cpu(IB_LID_PERMISSIVE)))\n\t\trdma_ah_set_make_grd(&ah_attr, true);\n\n\tif (ah_attr.type == RDMA_AH_ATTR_TYPE_IB && grh_required) {\n\t\trdma_ah_set_ah_flags(&ah_attr, IB_AH_GRH);\n\t\trdma_ah_set_subnet_prefix(&ah_attr,\n\t\t\t\t\t  cpu_to_be64(port_attr.subnet_prefix));\n\t\trdma_ah_set_interface_id(&ah_attr,\n\t\t\t\t\t cpu_to_be64(IB_SA_WELL_KNOWN_GUID));\n\t}\n\n\tnew_ah->ah = rdma_create_ah(port->agent->qp->pd, &ah_attr,\n\t\t\t\t    RDMA_CREATE_AH_SLEEPABLE);\n\tif (IS_ERR(new_ah->ah)) {\n\t\tpr_warn(\"Couldn't create new SM AH\\n\");\n\t\tkfree(new_ah);\n\t\treturn;\n\t}\n\n\tspin_lock_irq(&port->ah_lock);\n\tif (port->sm_ah)\n\t\tkref_put(&port->sm_ah->ref, free_sm_ah);\n\tport->sm_ah = new_ah;\n\tspin_unlock_irq(&port->ah_lock);\n}\n\nstatic void ib_sa_event(struct ib_event_handler *handler,\n\t\t\tstruct ib_event *event)\n{\n\tif (event->event == IB_EVENT_PORT_ERR    ||\n\t    event->event == IB_EVENT_PORT_ACTIVE ||\n\t    event->event == IB_EVENT_LID_CHANGE  ||\n\t    event->event == IB_EVENT_PKEY_CHANGE ||\n\t    event->event == IB_EVENT_SM_CHANGE   ||\n\t    event->event == IB_EVENT_CLIENT_REREGISTER) {\n\t\tunsigned long flags;\n\t\tstruct ib_sa_device *sa_dev =\n\t\t\tcontainer_of(handler, typeof(*sa_dev), event_handler);\n\t\tu32 port_num = event->element.port_num - sa_dev->start_port;\n\t\tstruct ib_sa_port *port = &sa_dev->port[port_num];\n\n\t\tif (!rdma_cap_ib_sa(handler->device, port->port_num))\n\t\t\treturn;\n\n\t\tspin_lock_irqsave(&port->ah_lock, flags);\n\t\tif (port->sm_ah)\n\t\t\tkref_put(&port->sm_ah->ref, free_sm_ah);\n\t\tport->sm_ah = NULL;\n\t\tspin_unlock_irqrestore(&port->ah_lock, flags);\n\n\t\tif (event->event == IB_EVENT_SM_CHANGE ||\n\t\t    event->event == IB_EVENT_CLIENT_REREGISTER ||\n\t\t    event->event == IB_EVENT_LID_CHANGE ||\n\t\t    event->event == IB_EVENT_PORT_ACTIVE) {\n\t\t\tunsigned long delay =\n\t\t\t\tmsecs_to_jiffies(IB_SA_CPI_RETRY_WAIT);\n\n\t\t\tspin_lock_irqsave(&port->classport_lock, flags);\n\t\t\tport->classport_info.valid = false;\n\t\t\tport->classport_info.retry_cnt = 0;\n\t\t\tspin_unlock_irqrestore(&port->classport_lock, flags);\n\t\t\tqueue_delayed_work(ib_wq,\n\t\t\t\t\t   &port->ib_cpi_work, delay);\n\t\t}\n\t\tqueue_work(ib_wq, &sa_dev->port[port_num].update_task);\n\t}\n}\n\nstatic int ib_sa_add_one(struct ib_device *device)\n{\n\tstruct ib_sa_device *sa_dev;\n\tint s, e, i;\n\tint count = 0;\n\tint ret;\n\n\ts = rdma_start_port(device);\n\te = rdma_end_port(device);\n\n\tsa_dev = kzalloc(struct_size(sa_dev, port,\n\t\t\t\t     size_add(size_sub(e, s), 1)),\n\t\t\t GFP_KERNEL);\n\tif (!sa_dev)\n\t\treturn -ENOMEM;\n\n\tsa_dev->start_port = s;\n\tsa_dev->end_port   = e;\n\n\tfor (i = 0; i <= e - s; ++i) {\n\t\tspin_lock_init(&sa_dev->port[i].ah_lock);\n\t\tif (!rdma_cap_ib_sa(device, i + 1))\n\t\t\tcontinue;\n\n\t\tsa_dev->port[i].sm_ah    = NULL;\n\t\tsa_dev->port[i].port_num = i + s;\n\n\t\tspin_lock_init(&sa_dev->port[i].classport_lock);\n\t\tsa_dev->port[i].classport_info.valid = false;\n\n\t\tsa_dev->port[i].agent =\n\t\t\tib_register_mad_agent(device, i + s, IB_QPT_GSI,\n\t\t\t\t\t      NULL, 0, send_handler,\n\t\t\t\t\t      recv_handler, sa_dev, 0);\n\t\tif (IS_ERR(sa_dev->port[i].agent)) {\n\t\t\tret = PTR_ERR(sa_dev->port[i].agent);\n\t\t\tgoto err;\n\t\t}\n\n\t\tINIT_WORK(&sa_dev->port[i].update_task, update_sm_ah);\n\t\tINIT_DELAYED_WORK(&sa_dev->port[i].ib_cpi_work,\n\t\t\t\t  update_ib_cpi);\n\n\t\tcount++;\n\t}\n\n\tif (!count) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto free;\n\t}\n\n\tib_set_client_data(device, &sa_client, sa_dev);\n\n\t \n\n\tINIT_IB_EVENT_HANDLER(&sa_dev->event_handler, device, ib_sa_event);\n\tib_register_event_handler(&sa_dev->event_handler);\n\n\tfor (i = 0; i <= e - s; ++i) {\n\t\tif (rdma_cap_ib_sa(device, i + 1))\n\t\t\tupdate_sm_ah(&sa_dev->port[i].update_task);\n\t}\n\n\treturn 0;\n\nerr:\n\twhile (--i >= 0) {\n\t\tif (rdma_cap_ib_sa(device, i + 1))\n\t\t\tib_unregister_mad_agent(sa_dev->port[i].agent);\n\t}\nfree:\n\tkfree(sa_dev);\n\treturn ret;\n}\n\nstatic void ib_sa_remove_one(struct ib_device *device, void *client_data)\n{\n\tstruct ib_sa_device *sa_dev = client_data;\n\tint i;\n\n\tib_unregister_event_handler(&sa_dev->event_handler);\n\tflush_workqueue(ib_wq);\n\n\tfor (i = 0; i <= sa_dev->end_port - sa_dev->start_port; ++i) {\n\t\tif (rdma_cap_ib_sa(device, i + 1)) {\n\t\t\tcancel_delayed_work_sync(&sa_dev->port[i].ib_cpi_work);\n\t\t\tib_unregister_mad_agent(sa_dev->port[i].agent);\n\t\t\tif (sa_dev->port[i].sm_ah)\n\t\t\t\tkref_put(&sa_dev->port[i].sm_ah->ref, free_sm_ah);\n\t\t}\n\n\t}\n\n\tkfree(sa_dev);\n}\n\nint ib_sa_init(void)\n{\n\tint ret;\n\n\tget_random_bytes(&tid, sizeof tid);\n\n\tatomic_set(&ib_nl_sa_request_seq, 0);\n\n\tret = ib_register_client(&sa_client);\n\tif (ret) {\n\t\tpr_err(\"Couldn't register ib_sa client\\n\");\n\t\tgoto err1;\n\t}\n\n\tret = mcast_init();\n\tif (ret) {\n\t\tpr_err(\"Couldn't initialize multicast handling\\n\");\n\t\tgoto err2;\n\t}\n\n\tib_nl_wq = alloc_ordered_workqueue(\"ib_nl_sa_wq\", WQ_MEM_RECLAIM);\n\tif (!ib_nl_wq) {\n\t\tret = -ENOMEM;\n\t\tgoto err3;\n\t}\n\n\tINIT_DELAYED_WORK(&ib_nl_timed_work, ib_nl_request_timeout);\n\n\treturn 0;\n\nerr3:\n\tmcast_cleanup();\nerr2:\n\tib_unregister_client(&sa_client);\nerr1:\n\treturn ret;\n}\n\nvoid ib_sa_cleanup(void)\n{\n\tcancel_delayed_work(&ib_nl_timed_work);\n\tdestroy_workqueue(ib_nl_wq);\n\tmcast_cleanup();\n\tib_unregister_client(&sa_client);\n\tWARN_ON(!xa_empty(&queries));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}