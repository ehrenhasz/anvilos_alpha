{
  "module_name": "security.c",
  "hash_id": "c6cc652691fcaae3a4162f63dde6fb7382d72c530d491c57d51923ed73d234c1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/core/security.c",
  "human_readable_source": " \n\n#include <linux/security.h>\n#include <linux/completion.h>\n#include <linux/list.h>\n\n#include <rdma/ib_verbs.h>\n#include <rdma/ib_cache.h>\n#include \"core_priv.h\"\n#include \"mad_priv.h\"\n\nstatic LIST_HEAD(mad_agent_list);\n \nstatic DEFINE_SPINLOCK(mad_agent_list_lock);\n\nstatic struct pkey_index_qp_list *get_pkey_idx_qp_list(struct ib_port_pkey *pp)\n{\n\tstruct pkey_index_qp_list *pkey = NULL;\n\tstruct pkey_index_qp_list *tmp_pkey;\n\tstruct ib_device *dev = pp->sec->dev;\n\n\tspin_lock(&dev->port_data[pp->port_num].pkey_list_lock);\n\tlist_for_each_entry (tmp_pkey, &dev->port_data[pp->port_num].pkey_list,\n\t\t\t     pkey_index_list) {\n\t\tif (tmp_pkey->pkey_index == pp->pkey_index) {\n\t\t\tpkey = tmp_pkey;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&dev->port_data[pp->port_num].pkey_list_lock);\n\treturn pkey;\n}\n\nstatic int get_pkey_and_subnet_prefix(struct ib_port_pkey *pp,\n\t\t\t\t      u16 *pkey,\n\t\t\t\t      u64 *subnet_prefix)\n{\n\tstruct ib_device *dev = pp->sec->dev;\n\tint ret;\n\n\tret = ib_get_cached_pkey(dev, pp->port_num, pp->pkey_index, pkey);\n\tif (ret)\n\t\treturn ret;\n\n\tib_get_cached_subnet_prefix(dev, pp->port_num, subnet_prefix);\n\n\treturn ret;\n}\n\nstatic int enforce_qp_pkey_security(u16 pkey,\n\t\t\t\t    u64 subnet_prefix,\n\t\t\t\t    struct ib_qp_security *qp_sec)\n{\n\tstruct ib_qp_security *shared_qp_sec;\n\tint ret;\n\n\tret = security_ib_pkey_access(qp_sec->security, subnet_prefix, pkey);\n\tif (ret)\n\t\treturn ret;\n\n\tlist_for_each_entry(shared_qp_sec,\n\t\t\t    &qp_sec->shared_qp_list,\n\t\t\t    shared_qp_list) {\n\t\tret = security_ib_pkey_access(shared_qp_sec->security,\n\t\t\t\t\t      subnet_prefix,\n\t\t\t\t\t      pkey);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\n \nstatic int check_qp_port_pkey_settings(struct ib_ports_pkeys *pps,\n\t\t\t\t       struct ib_qp_security *sec)\n{\n\tu64 subnet_prefix;\n\tu16 pkey;\n\tint ret = 0;\n\n\tif (!pps)\n\t\treturn 0;\n\n\tif (pps->main.state != IB_PORT_PKEY_NOT_VALID) {\n\t\tret = get_pkey_and_subnet_prefix(&pps->main,\n\t\t\t\t\t\t &pkey,\n\t\t\t\t\t\t &subnet_prefix);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = enforce_qp_pkey_security(pkey,\n\t\t\t\t\t       subnet_prefix,\n\t\t\t\t\t       sec);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (pps->alt.state != IB_PORT_PKEY_NOT_VALID) {\n\t\tret = get_pkey_and_subnet_prefix(&pps->alt,\n\t\t\t\t\t\t &pkey,\n\t\t\t\t\t\t &subnet_prefix);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = enforce_qp_pkey_security(pkey,\n\t\t\t\t\t       subnet_prefix,\n\t\t\t\t\t       sec);\n\t}\n\n\treturn ret;\n}\n\n \nstatic void qp_to_error(struct ib_qp_security *sec)\n{\n\tstruct ib_qp_security *shared_qp_sec;\n\tstruct ib_qp_attr attr = {\n\t\t.qp_state = IB_QPS_ERR\n\t};\n\tstruct ib_event event = {\n\t\t.event = IB_EVENT_QP_FATAL\n\t};\n\n\t \n\tif (sec->destroying)\n\t\treturn;\n\n\tib_modify_qp(sec->qp,\n\t\t     &attr,\n\t\t     IB_QP_STATE);\n\n\tif (sec->qp->event_handler && sec->qp->qp_context) {\n\t\tevent.element.qp = sec->qp;\n\t\tsec->qp->event_handler(&event,\n\t\t\t\t       sec->qp->qp_context);\n\t}\n\n\tlist_for_each_entry(shared_qp_sec,\n\t\t\t    &sec->shared_qp_list,\n\t\t\t    shared_qp_list) {\n\t\tstruct ib_qp *qp = shared_qp_sec->qp;\n\n\t\tif (qp->event_handler && qp->qp_context) {\n\t\t\tevent.element.qp = qp;\n\t\t\tevent.device = qp->device;\n\t\t\tqp->event_handler(&event,\n\t\t\t\t\t  qp->qp_context);\n\t\t}\n\t}\n}\n\nstatic inline void check_pkey_qps(struct pkey_index_qp_list *pkey,\n\t\t\t\t  struct ib_device *device,\n\t\t\t\t  u32 port_num,\n\t\t\t\t  u64 subnet_prefix)\n{\n\tstruct ib_port_pkey *pp, *tmp_pp;\n\tbool comp;\n\tLIST_HEAD(to_error_list);\n\tu16 pkey_val;\n\n\tif (!ib_get_cached_pkey(device,\n\t\t\t\tport_num,\n\t\t\t\tpkey->pkey_index,\n\t\t\t\t&pkey_val)) {\n\t\tspin_lock(&pkey->qp_list_lock);\n\t\tlist_for_each_entry(pp, &pkey->qp_list, qp_list) {\n\t\t\tif (atomic_read(&pp->sec->error_list_count))\n\t\t\t\tcontinue;\n\n\t\t\tif (enforce_qp_pkey_security(pkey_val,\n\t\t\t\t\t\t     subnet_prefix,\n\t\t\t\t\t\t     pp->sec)) {\n\t\t\t\tatomic_inc(&pp->sec->error_list_count);\n\t\t\t\tlist_add(&pp->to_error_list,\n\t\t\t\t\t &to_error_list);\n\t\t\t}\n\t\t}\n\t\tspin_unlock(&pkey->qp_list_lock);\n\t}\n\n\tlist_for_each_entry_safe(pp,\n\t\t\t\t tmp_pp,\n\t\t\t\t &to_error_list,\n\t\t\t\t to_error_list) {\n\t\tmutex_lock(&pp->sec->mutex);\n\t\tqp_to_error(pp->sec);\n\t\tlist_del(&pp->to_error_list);\n\t\tatomic_dec(&pp->sec->error_list_count);\n\t\tcomp = pp->sec->destroying;\n\t\tmutex_unlock(&pp->sec->mutex);\n\n\t\tif (comp)\n\t\t\tcomplete(&pp->sec->error_complete);\n\t}\n}\n\n \nstatic int port_pkey_list_insert(struct ib_port_pkey *pp)\n{\n\tstruct pkey_index_qp_list *tmp_pkey;\n\tstruct pkey_index_qp_list *pkey;\n\tstruct ib_device *dev;\n\tu32 port_num = pp->port_num;\n\tint ret = 0;\n\n\tif (pp->state != IB_PORT_PKEY_VALID)\n\t\treturn 0;\n\n\tdev = pp->sec->dev;\n\n\tpkey = get_pkey_idx_qp_list(pp);\n\n\tif (!pkey) {\n\t\tbool found = false;\n\n\t\tpkey = kzalloc(sizeof(*pkey), GFP_KERNEL);\n\t\tif (!pkey)\n\t\t\treturn -ENOMEM;\n\n\t\tspin_lock(&dev->port_data[port_num].pkey_list_lock);\n\t\t \n\t\tlist_for_each_entry(tmp_pkey,\n\t\t\t\t    &dev->port_data[port_num].pkey_list,\n\t\t\t\t    pkey_index_list) {\n\t\t\tif (tmp_pkey->pkey_index == pp->pkey_index) {\n\t\t\t\tkfree(pkey);\n\t\t\t\tpkey = tmp_pkey;\n\t\t\t\tfound = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!found) {\n\t\t\tpkey->pkey_index = pp->pkey_index;\n\t\t\tspin_lock_init(&pkey->qp_list_lock);\n\t\t\tINIT_LIST_HEAD(&pkey->qp_list);\n\t\t\tlist_add(&pkey->pkey_index_list,\n\t\t\t\t &dev->port_data[port_num].pkey_list);\n\t\t}\n\t\tspin_unlock(&dev->port_data[port_num].pkey_list_lock);\n\t}\n\n\tspin_lock(&pkey->qp_list_lock);\n\tlist_add(&pp->qp_list, &pkey->qp_list);\n\tspin_unlock(&pkey->qp_list_lock);\n\n\tpp->state = IB_PORT_PKEY_LISTED;\n\n\treturn ret;\n}\n\n \nstatic void port_pkey_list_remove(struct ib_port_pkey *pp)\n{\n\tstruct pkey_index_qp_list *pkey;\n\n\tif (pp->state != IB_PORT_PKEY_LISTED)\n\t\treturn;\n\n\tpkey = get_pkey_idx_qp_list(pp);\n\n\tspin_lock(&pkey->qp_list_lock);\n\tlist_del(&pp->qp_list);\n\tspin_unlock(&pkey->qp_list_lock);\n\n\t \n\tpp->state = IB_PORT_PKEY_VALID;\n}\n\nstatic void destroy_qp_security(struct ib_qp_security *sec)\n{\n\tsecurity_ib_free_security(sec->security);\n\tkfree(sec->ports_pkeys);\n\tkfree(sec);\n}\n\n \nstatic struct ib_ports_pkeys *get_new_pps(const struct ib_qp *qp,\n\t\t\t\t\t  const struct ib_qp_attr *qp_attr,\n\t\t\t\t\t  int qp_attr_mask)\n{\n\tstruct ib_ports_pkeys *new_pps;\n\tstruct ib_ports_pkeys *qp_pps = qp->qp_sec->ports_pkeys;\n\n\tnew_pps = kzalloc(sizeof(*new_pps), GFP_KERNEL);\n\tif (!new_pps)\n\t\treturn NULL;\n\n\tif (qp_attr_mask & IB_QP_PORT)\n\t\tnew_pps->main.port_num = qp_attr->port_num;\n\telse if (qp_pps)\n\t\tnew_pps->main.port_num = qp_pps->main.port_num;\n\n\tif (qp_attr_mask & IB_QP_PKEY_INDEX)\n\t\tnew_pps->main.pkey_index = qp_attr->pkey_index;\n\telse if (qp_pps)\n\t\tnew_pps->main.pkey_index = qp_pps->main.pkey_index;\n\n\tif (((qp_attr_mask & IB_QP_PKEY_INDEX) &&\n\t     (qp_attr_mask & IB_QP_PORT)) ||\n\t    (qp_pps && qp_pps->main.state != IB_PORT_PKEY_NOT_VALID))\n\t\tnew_pps->main.state = IB_PORT_PKEY_VALID;\n\n\tif (qp_attr_mask & IB_QP_ALT_PATH) {\n\t\tnew_pps->alt.port_num = qp_attr->alt_port_num;\n\t\tnew_pps->alt.pkey_index = qp_attr->alt_pkey_index;\n\t\tnew_pps->alt.state = IB_PORT_PKEY_VALID;\n\t} else if (qp_pps) {\n\t\tnew_pps->alt.port_num = qp_pps->alt.port_num;\n\t\tnew_pps->alt.pkey_index = qp_pps->alt.pkey_index;\n\t\tif (qp_pps->alt.state != IB_PORT_PKEY_NOT_VALID)\n\t\t\tnew_pps->alt.state = IB_PORT_PKEY_VALID;\n\t}\n\n\tnew_pps->main.sec = qp->qp_sec;\n\tnew_pps->alt.sec = qp->qp_sec;\n\treturn new_pps;\n}\n\nint ib_open_shared_qp_security(struct ib_qp *qp, struct ib_device *dev)\n{\n\tstruct ib_qp *real_qp = qp->real_qp;\n\tint ret;\n\n\tret = ib_create_qp_security(qp, dev);\n\n\tif (ret)\n\t\treturn ret;\n\n\tif (!qp->qp_sec)\n\t\treturn 0;\n\n\tmutex_lock(&real_qp->qp_sec->mutex);\n\tret = check_qp_port_pkey_settings(real_qp->qp_sec->ports_pkeys,\n\t\t\t\t\t  qp->qp_sec);\n\n\tif (ret)\n\t\tgoto ret;\n\n\tif (qp != real_qp)\n\t\tlist_add(&qp->qp_sec->shared_qp_list,\n\t\t\t &real_qp->qp_sec->shared_qp_list);\nret:\n\tmutex_unlock(&real_qp->qp_sec->mutex);\n\tif (ret)\n\t\tdestroy_qp_security(qp->qp_sec);\n\n\treturn ret;\n}\n\nvoid ib_close_shared_qp_security(struct ib_qp_security *sec)\n{\n\tstruct ib_qp *real_qp = sec->qp->real_qp;\n\n\tmutex_lock(&real_qp->qp_sec->mutex);\n\tlist_del(&sec->shared_qp_list);\n\tmutex_unlock(&real_qp->qp_sec->mutex);\n\n\tdestroy_qp_security(sec);\n}\n\nint ib_create_qp_security(struct ib_qp *qp, struct ib_device *dev)\n{\n\tunsigned int i;\n\tbool is_ib = false;\n\tint ret;\n\n\trdma_for_each_port (dev, i) {\n\t\tis_ib = rdma_protocol_ib(dev, i);\n\t\tif (is_ib)\n\t\t\tbreak;\n\t}\n\n\t \n\tif (!is_ib)\n\t\treturn 0;\n\n\tqp->qp_sec = kzalloc(sizeof(*qp->qp_sec), GFP_KERNEL);\n\tif (!qp->qp_sec)\n\t\treturn -ENOMEM;\n\n\tqp->qp_sec->qp = qp;\n\tqp->qp_sec->dev = dev;\n\tmutex_init(&qp->qp_sec->mutex);\n\tINIT_LIST_HEAD(&qp->qp_sec->shared_qp_list);\n\tatomic_set(&qp->qp_sec->error_list_count, 0);\n\tinit_completion(&qp->qp_sec->error_complete);\n\tret = security_ib_alloc_security(&qp->qp_sec->security);\n\tif (ret) {\n\t\tkfree(qp->qp_sec);\n\t\tqp->qp_sec = NULL;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL(ib_create_qp_security);\n\nvoid ib_destroy_qp_security_begin(struct ib_qp_security *sec)\n{\n\t \n\tif (!sec)\n\t\treturn;\n\n\tmutex_lock(&sec->mutex);\n\n\t \n\tif (sec->ports_pkeys) {\n\t\tport_pkey_list_remove(&sec->ports_pkeys->main);\n\t\tport_pkey_list_remove(&sec->ports_pkeys->alt);\n\t}\n\n\t \n\tsec->destroying = true;\n\n\t \n\tsec->error_comps_pending = atomic_read(&sec->error_list_count);\n\n\tmutex_unlock(&sec->mutex);\n}\n\nvoid ib_destroy_qp_security_abort(struct ib_qp_security *sec)\n{\n\tint ret;\n\tint i;\n\n\t \n\tif (!sec)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < sec->error_comps_pending; i++)\n\t\twait_for_completion(&sec->error_complete);\n\n\tmutex_lock(&sec->mutex);\n\tsec->destroying = false;\n\n\t \n\tif (sec->ports_pkeys) {\n\t\tport_pkey_list_insert(&sec->ports_pkeys->main);\n\t\tport_pkey_list_insert(&sec->ports_pkeys->alt);\n\t}\n\n\tret = check_qp_port_pkey_settings(sec->ports_pkeys, sec);\n\tif (ret)\n\t\tqp_to_error(sec);\n\n\tmutex_unlock(&sec->mutex);\n}\n\nvoid ib_destroy_qp_security_end(struct ib_qp_security *sec)\n{\n\tint i;\n\n\t \n\tif (!sec)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < sec->error_comps_pending; i++)\n\t\twait_for_completion(&sec->error_complete);\n\n\tdestroy_qp_security(sec);\n}\n\nvoid ib_security_cache_change(struct ib_device *device,\n\t\t\t      u32 port_num,\n\t\t\t      u64 subnet_prefix)\n{\n\tstruct pkey_index_qp_list *pkey;\n\n\tlist_for_each_entry (pkey, &device->port_data[port_num].pkey_list,\n\t\t\t     pkey_index_list) {\n\t\tcheck_pkey_qps(pkey,\n\t\t\t       device,\n\t\t\t       port_num,\n\t\t\t       subnet_prefix);\n\t}\n}\n\nvoid ib_security_release_port_pkey_list(struct ib_device *device)\n{\n\tstruct pkey_index_qp_list *pkey, *tmp_pkey;\n\tunsigned int i;\n\n\trdma_for_each_port (device, i) {\n\t\tlist_for_each_entry_safe(pkey,\n\t\t\t\t\t tmp_pkey,\n\t\t\t\t\t &device->port_data[i].pkey_list,\n\t\t\t\t\t pkey_index_list) {\n\t\t\tlist_del(&pkey->pkey_index_list);\n\t\t\tkfree(pkey);\n\t\t}\n\t}\n}\n\nint ib_security_modify_qp(struct ib_qp *qp,\n\t\t\t  struct ib_qp_attr *qp_attr,\n\t\t\t  int qp_attr_mask,\n\t\t\t  struct ib_udata *udata)\n{\n\tint ret = 0;\n\tstruct ib_ports_pkeys *tmp_pps;\n\tstruct ib_ports_pkeys *new_pps = NULL;\n\tstruct ib_qp *real_qp = qp->real_qp;\n\tbool special_qp = (real_qp->qp_type == IB_QPT_SMI ||\n\t\t\t   real_qp->qp_type == IB_QPT_GSI ||\n\t\t\t   real_qp->qp_type >= IB_QPT_RESERVED1);\n\tbool pps_change = ((qp_attr_mask & (IB_QP_PKEY_INDEX | IB_QP_PORT)) ||\n\t\t\t   (qp_attr_mask & IB_QP_ALT_PATH));\n\n\tWARN_ONCE((qp_attr_mask & IB_QP_PORT &&\n\t\t   rdma_protocol_ib(real_qp->device, qp_attr->port_num) &&\n\t\t   !real_qp->qp_sec),\n\t\t   \"%s: QP security is not initialized for IB QP: %u\\n\",\n\t\t   __func__, real_qp->qp_num);\n\n\t \n\n\tif (pps_change && !special_qp && real_qp->qp_sec) {\n\t\tmutex_lock(&real_qp->qp_sec->mutex);\n\t\tnew_pps = get_new_pps(real_qp,\n\t\t\t\t      qp_attr,\n\t\t\t\t      qp_attr_mask);\n\t\tif (!new_pps) {\n\t\t\tmutex_unlock(&real_qp->qp_sec->mutex);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\t \n\t\tret = port_pkey_list_insert(&new_pps->main);\n\n\t\tif (!ret)\n\t\t\tret = port_pkey_list_insert(&new_pps->alt);\n\n\t\tif (!ret)\n\t\t\tret = check_qp_port_pkey_settings(new_pps,\n\t\t\t\t\t\t\t  real_qp->qp_sec);\n\t}\n\n\tif (!ret)\n\t\tret = real_qp->device->ops.modify_qp(real_qp,\n\t\t\t\t\t\t     qp_attr,\n\t\t\t\t\t\t     qp_attr_mask,\n\t\t\t\t\t\t     udata);\n\n\tif (new_pps) {\n\t\t \n\t\tif (ret) {\n\t\t\ttmp_pps = new_pps;\n\t\t} else {\n\t\t\ttmp_pps = real_qp->qp_sec->ports_pkeys;\n\t\t\treal_qp->qp_sec->ports_pkeys = new_pps;\n\t\t}\n\n\t\tif (tmp_pps) {\n\t\t\tport_pkey_list_remove(&tmp_pps->main);\n\t\t\tport_pkey_list_remove(&tmp_pps->alt);\n\t\t}\n\t\tkfree(tmp_pps);\n\t\tmutex_unlock(&real_qp->qp_sec->mutex);\n\t}\n\treturn ret;\n}\n\nstatic int ib_security_pkey_access(struct ib_device *dev,\n\t\t\t\t   u32 port_num,\n\t\t\t\t   u16 pkey_index,\n\t\t\t\t   void *sec)\n{\n\tu64 subnet_prefix;\n\tu16 pkey;\n\tint ret;\n\n\tif (!rdma_protocol_ib(dev, port_num))\n\t\treturn 0;\n\n\tret = ib_get_cached_pkey(dev, port_num, pkey_index, &pkey);\n\tif (ret)\n\t\treturn ret;\n\n\tib_get_cached_subnet_prefix(dev, port_num, &subnet_prefix);\n\n\treturn security_ib_pkey_access(sec, subnet_prefix, pkey);\n}\n\nvoid ib_mad_agent_security_change(void)\n{\n\tstruct ib_mad_agent *ag;\n\n\tspin_lock(&mad_agent_list_lock);\n\tlist_for_each_entry(ag,\n\t\t\t    &mad_agent_list,\n\t\t\t    mad_agent_sec_list)\n\t\tWRITE_ONCE(ag->smp_allowed,\n\t\t\t   !security_ib_endport_manage_subnet(ag->security,\n\t\t\t\tdev_name(&ag->device->dev), ag->port_num));\n\tspin_unlock(&mad_agent_list_lock);\n}\n\nint ib_mad_agent_security_setup(struct ib_mad_agent *agent,\n\t\t\t\tenum ib_qp_type qp_type)\n{\n\tint ret;\n\n\tif (!rdma_protocol_ib(agent->device, agent->port_num))\n\t\treturn 0;\n\n\tINIT_LIST_HEAD(&agent->mad_agent_sec_list);\n\n\tret = security_ib_alloc_security(&agent->security);\n\tif (ret)\n\t\treturn ret;\n\n\tif (qp_type != IB_QPT_SMI)\n\t\treturn 0;\n\n\tspin_lock(&mad_agent_list_lock);\n\tret = security_ib_endport_manage_subnet(agent->security,\n\t\t\t\t\t\tdev_name(&agent->device->dev),\n\t\t\t\t\t\tagent->port_num);\n\tif (ret)\n\t\tgoto free_security;\n\n\tWRITE_ONCE(agent->smp_allowed, true);\n\tlist_add(&agent->mad_agent_sec_list, &mad_agent_list);\n\tspin_unlock(&mad_agent_list_lock);\n\treturn 0;\n\nfree_security:\n\tspin_unlock(&mad_agent_list_lock);\n\tsecurity_ib_free_security(agent->security);\n\treturn ret;\n}\n\nvoid ib_mad_agent_security_cleanup(struct ib_mad_agent *agent)\n{\n\tif (!rdma_protocol_ib(agent->device, agent->port_num))\n\t\treturn;\n\n\tif (agent->qp->qp_type == IB_QPT_SMI) {\n\t\tspin_lock(&mad_agent_list_lock);\n\t\tlist_del(&agent->mad_agent_sec_list);\n\t\tspin_unlock(&mad_agent_list_lock);\n\t}\n\n\tsecurity_ib_free_security(agent->security);\n}\n\nint ib_mad_enforce_security(struct ib_mad_agent_private *map, u16 pkey_index)\n{\n\tif (!rdma_protocol_ib(map->agent.device, map->agent.port_num))\n\t\treturn 0;\n\n\tif (map->agent.qp->qp_type == IB_QPT_SMI) {\n\t\tif (!READ_ONCE(map->agent.smp_allowed))\n\t\t\treturn -EACCES;\n\t\treturn 0;\n\t}\n\n\treturn ib_security_pkey_access(map->agent.device,\n\t\t\t\t       map->agent.port_num,\n\t\t\t\t       pkey_index,\n\t\t\t\t       map->agent.security);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}