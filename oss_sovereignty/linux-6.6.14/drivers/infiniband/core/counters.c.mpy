{
  "module_name": "counters.c",
  "hash_id": "08dcffa7734d31216bdda8b96252a9b3f8254d010a926438461605cf383afc2d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/core/counters.c",
  "human_readable_source": "\n \n#include <rdma/ib_verbs.h>\n#include <rdma/rdma_counter.h>\n\n#include \"core_priv.h\"\n#include \"restrack.h\"\n\n#define ALL_AUTO_MODE_MASKS (RDMA_COUNTER_MASK_QP_TYPE | RDMA_COUNTER_MASK_PID)\n\nstatic int __counter_set_mode(struct rdma_port_counter *port_counter,\n\t\t\t      enum rdma_nl_counter_mode new_mode,\n\t\t\t      enum rdma_nl_counter_mask new_mask)\n{\n\tif (new_mode == RDMA_COUNTER_MODE_AUTO) {\n\t\tif (new_mask & (~ALL_AUTO_MODE_MASKS))\n\t\t\treturn -EINVAL;\n\t\tif (port_counter->num_counters)\n\t\t\treturn -EBUSY;\n\t}\n\n\tport_counter->mode.mode = new_mode;\n\tport_counter->mode.mask = new_mask;\n\treturn 0;\n}\n\n \nint rdma_counter_set_auto_mode(struct ib_device *dev, u32 port,\n\t\t\t       enum rdma_nl_counter_mask mask,\n\t\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct rdma_port_counter *port_counter;\n\tenum rdma_nl_counter_mode mode;\n\tint ret;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\tif (!port_counter->hstats)\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&port_counter->lock);\n\tif (mask)\n\t\tmode = RDMA_COUNTER_MODE_AUTO;\n\telse\n\t\tmode = (port_counter->num_counters) ? RDMA_COUNTER_MODE_MANUAL :\n\t\t\t\t\t\t      RDMA_COUNTER_MODE_NONE;\n\n\tif (port_counter->mode.mode == mode &&\n\t    port_counter->mode.mask == mask) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tret = __counter_set_mode(port_counter, mode, mask);\n\nout:\n\tmutex_unlock(&port_counter->lock);\n\tif (ret == -EBUSY)\n\t\tNL_SET_ERR_MSG(\n\t\t\textack,\n\t\t\t\"Modifying auto mode is not allowed when there is a bound QP\");\n\treturn ret;\n}\n\nstatic void auto_mode_init_counter(struct rdma_counter *counter,\n\t\t\t\t   const struct ib_qp *qp,\n\t\t\t\t   enum rdma_nl_counter_mask new_mask)\n{\n\tstruct auto_mode_param *param = &counter->mode.param;\n\n\tcounter->mode.mode = RDMA_COUNTER_MODE_AUTO;\n\tcounter->mode.mask = new_mask;\n\n\tif (new_mask & RDMA_COUNTER_MASK_QP_TYPE)\n\t\tparam->qp_type = qp->qp_type;\n}\n\nstatic int __rdma_counter_bind_qp(struct rdma_counter *counter,\n\t\t\t\t  struct ib_qp *qp)\n{\n\tint ret;\n\n\tif (qp->counter)\n\t\treturn -EINVAL;\n\n\tif (!qp->device->ops.counter_bind_qp)\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&counter->lock);\n\tret = qp->device->ops.counter_bind_qp(counter, qp);\n\tmutex_unlock(&counter->lock);\n\n\treturn ret;\n}\n\nint rdma_counter_modify(struct ib_device *dev, u32 port,\n\t\t\tunsigned int index, bool enable)\n{\n\tstruct rdma_hw_stats *stats;\n\tint ret = 0;\n\n\tif (!dev->ops.modify_hw_stat)\n\t\treturn -EOPNOTSUPP;\n\n\tstats = ib_get_hw_stats_port(dev, port);\n\tif (!stats || index >= stats->num_counters ||\n\t    !(stats->descs[index].flags & IB_STAT_FLAG_OPTIONAL))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&stats->lock);\n\n\tif (enable != test_bit(index, stats->is_disabled))\n\t\tgoto out;\n\n\tret = dev->ops.modify_hw_stat(dev, port, index, enable);\n\tif (ret)\n\t\tgoto out;\n\n\tif (enable)\n\t\tclear_bit(index, stats->is_disabled);\n\telse\n\t\tset_bit(index, stats->is_disabled);\nout:\n\tmutex_unlock(&stats->lock);\n\treturn ret;\n}\n\nstatic struct rdma_counter *alloc_and_bind(struct ib_device *dev, u32 port,\n\t\t\t\t\t   struct ib_qp *qp,\n\t\t\t\t\t   enum rdma_nl_counter_mode mode)\n{\n\tstruct rdma_port_counter *port_counter;\n\tstruct rdma_counter *counter;\n\tint ret;\n\n\tif (!dev->ops.counter_dealloc || !dev->ops.counter_alloc_stats)\n\t\treturn NULL;\n\n\tcounter = kzalloc(sizeof(*counter), GFP_KERNEL);\n\tif (!counter)\n\t\treturn NULL;\n\n\tcounter->device    = dev;\n\tcounter->port      = port;\n\n\trdma_restrack_new(&counter->res, RDMA_RESTRACK_COUNTER);\n\tcounter->stats = dev->ops.counter_alloc_stats(counter);\n\tif (!counter->stats)\n\t\tgoto err_stats;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\tmutex_lock(&port_counter->lock);\n\tswitch (mode) {\n\tcase RDMA_COUNTER_MODE_MANUAL:\n\t\tret = __counter_set_mode(port_counter, RDMA_COUNTER_MODE_MANUAL,\n\t\t\t\t\t 0);\n\t\tif (ret) {\n\t\t\tmutex_unlock(&port_counter->lock);\n\t\t\tgoto err_mode;\n\t\t}\n\t\tbreak;\n\tcase RDMA_COUNTER_MODE_AUTO:\n\t\tauto_mode_init_counter(counter, qp, port_counter->mode.mask);\n\t\tbreak;\n\tdefault:\n\t\tret = -EOPNOTSUPP;\n\t\tmutex_unlock(&port_counter->lock);\n\t\tgoto err_mode;\n\t}\n\n\tport_counter->num_counters++;\n\tmutex_unlock(&port_counter->lock);\n\n\tcounter->mode.mode = mode;\n\tkref_init(&counter->kref);\n\tmutex_init(&counter->lock);\n\n\tret = __rdma_counter_bind_qp(counter, qp);\n\tif (ret)\n\t\tgoto err_mode;\n\n\trdma_restrack_parent_name(&counter->res, &qp->res);\n\trdma_restrack_add(&counter->res);\n\treturn counter;\n\nerr_mode:\n\trdma_free_hw_stats_struct(counter->stats);\nerr_stats:\n\trdma_restrack_put(&counter->res);\n\tkfree(counter);\n\treturn NULL;\n}\n\nstatic void rdma_counter_free(struct rdma_counter *counter)\n{\n\tstruct rdma_port_counter *port_counter;\n\n\tport_counter = &counter->device->port_data[counter->port].port_counter;\n\tmutex_lock(&port_counter->lock);\n\tport_counter->num_counters--;\n\tif (!port_counter->num_counters &&\n\t    (port_counter->mode.mode == RDMA_COUNTER_MODE_MANUAL))\n\t\t__counter_set_mode(port_counter, RDMA_COUNTER_MODE_NONE, 0);\n\n\tmutex_unlock(&port_counter->lock);\n\n\trdma_restrack_del(&counter->res);\n\trdma_free_hw_stats_struct(counter->stats);\n\tkfree(counter);\n}\n\nstatic bool auto_mode_match(struct ib_qp *qp, struct rdma_counter *counter,\n\t\t\t    enum rdma_nl_counter_mask auto_mask)\n{\n\tstruct auto_mode_param *param = &counter->mode.param;\n\tbool match = true;\n\n\tif (auto_mask & RDMA_COUNTER_MASK_QP_TYPE)\n\t\tmatch &= (param->qp_type == qp->qp_type);\n\n\tif (auto_mask & RDMA_COUNTER_MASK_PID)\n\t\tmatch &= (task_pid_nr(counter->res.task) ==\n\t\t\t  task_pid_nr(qp->res.task));\n\n\treturn match;\n}\n\nstatic int __rdma_counter_unbind_qp(struct ib_qp *qp)\n{\n\tstruct rdma_counter *counter = qp->counter;\n\tint ret;\n\n\tif (!qp->device->ops.counter_unbind_qp)\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&counter->lock);\n\tret = qp->device->ops.counter_unbind_qp(qp);\n\tmutex_unlock(&counter->lock);\n\n\treturn ret;\n}\n\nstatic void counter_history_stat_update(struct rdma_counter *counter)\n{\n\tstruct ib_device *dev = counter->device;\n\tstruct rdma_port_counter *port_counter;\n\tint i;\n\n\tport_counter = &dev->port_data[counter->port].port_counter;\n\tif (!port_counter->hstats)\n\t\treturn;\n\n\trdma_counter_query_stats(counter);\n\n\tfor (i = 0; i < counter->stats->num_counters; i++)\n\t\tport_counter->hstats->value[i] += counter->stats->value[i];\n}\n\n \nstatic struct rdma_counter *rdma_get_counter_auto_mode(struct ib_qp *qp,\n\t\t\t\t\t\t       u32 port)\n{\n\tstruct rdma_port_counter *port_counter;\n\tstruct rdma_counter *counter = NULL;\n\tstruct ib_device *dev = qp->device;\n\tstruct rdma_restrack_entry *res;\n\tstruct rdma_restrack_root *rt;\n\tunsigned long id = 0;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\trt = &dev->res[RDMA_RESTRACK_COUNTER];\n\txa_lock(&rt->xa);\n\txa_for_each(&rt->xa, id, res) {\n\t\tcounter = container_of(res, struct rdma_counter, res);\n\t\tif ((counter->device != qp->device) || (counter->port != port))\n\t\t\tgoto next;\n\n\t\tif (auto_mode_match(qp, counter, port_counter->mode.mask))\n\t\t\tbreak;\nnext:\n\t\tcounter = NULL;\n\t}\n\n\tif (counter && !kref_get_unless_zero(&counter->kref))\n\t\tcounter = NULL;\n\n\txa_unlock(&rt->xa);\n\treturn counter;\n}\n\nstatic void counter_release(struct kref *kref)\n{\n\tstruct rdma_counter *counter;\n\n\tcounter = container_of(kref, struct rdma_counter, kref);\n\tcounter_history_stat_update(counter);\n\tcounter->device->ops.counter_dealloc(counter);\n\trdma_counter_free(counter);\n}\n\n \nint rdma_counter_bind_qp_auto(struct ib_qp *qp, u32 port)\n{\n\tstruct rdma_port_counter *port_counter;\n\tstruct ib_device *dev = qp->device;\n\tstruct rdma_counter *counter;\n\tint ret;\n\n\tif (!rdma_restrack_is_tracked(&qp->res) || rdma_is_kernel_res(&qp->res))\n\t\treturn 0;\n\n\tif (!rdma_is_port_valid(dev, port))\n\t\treturn -EINVAL;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\tif (port_counter->mode.mode != RDMA_COUNTER_MODE_AUTO)\n\t\treturn 0;\n\n\tcounter = rdma_get_counter_auto_mode(qp, port);\n\tif (counter) {\n\t\tret = __rdma_counter_bind_qp(counter, qp);\n\t\tif (ret) {\n\t\t\tkref_put(&counter->kref, counter_release);\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\tcounter = alloc_and_bind(dev, port, qp, RDMA_COUNTER_MODE_AUTO);\n\t\tif (!counter)\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\n \nint rdma_counter_unbind_qp(struct ib_qp *qp, bool force)\n{\n\tstruct rdma_counter *counter = qp->counter;\n\tint ret;\n\n\tif (!counter)\n\t\treturn -EINVAL;\n\n\tret = __rdma_counter_unbind_qp(qp);\n\tif (ret && !force)\n\t\treturn ret;\n\n\tkref_put(&counter->kref, counter_release);\n\treturn 0;\n}\n\nint rdma_counter_query_stats(struct rdma_counter *counter)\n{\n\tstruct ib_device *dev = counter->device;\n\tint ret;\n\n\tif (!dev->ops.counter_update_stats)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&counter->lock);\n\tret = dev->ops.counter_update_stats(counter);\n\tmutex_unlock(&counter->lock);\n\n\treturn ret;\n}\n\nstatic u64 get_running_counters_hwstat_sum(struct ib_device *dev,\n\t\t\t\t\t   u32 port, u32 index)\n{\n\tstruct rdma_restrack_entry *res;\n\tstruct rdma_restrack_root *rt;\n\tstruct rdma_counter *counter;\n\tunsigned long id = 0;\n\tu64 sum = 0;\n\n\trt = &dev->res[RDMA_RESTRACK_COUNTER];\n\txa_lock(&rt->xa);\n\txa_for_each(&rt->xa, id, res) {\n\t\tif (!rdma_restrack_get(res))\n\t\t\tcontinue;\n\n\t\txa_unlock(&rt->xa);\n\n\t\tcounter = container_of(res, struct rdma_counter, res);\n\t\tif ((counter->device != dev) || (counter->port != port) ||\n\t\t    rdma_counter_query_stats(counter))\n\t\t\tgoto next;\n\n\t\tsum += counter->stats->value[index];\n\nnext:\n\t\txa_lock(&rt->xa);\n\t\trdma_restrack_put(res);\n\t}\n\n\txa_unlock(&rt->xa);\n\treturn sum;\n}\n\n \nu64 rdma_counter_get_hwstat_value(struct ib_device *dev, u32 port, u32 index)\n{\n\tstruct rdma_port_counter *port_counter;\n\tu64 sum;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\tif (!port_counter->hstats)\n\t\treturn 0;\n\n\tsum = get_running_counters_hwstat_sum(dev, port, index);\n\tsum += port_counter->hstats->value[index];\n\n\treturn sum;\n}\n\nstatic struct ib_qp *rdma_counter_get_qp(struct ib_device *dev, u32 qp_num)\n{\n\tstruct rdma_restrack_entry *res = NULL;\n\tstruct ib_qp *qp = NULL;\n\n\tres = rdma_restrack_get_byid(dev, RDMA_RESTRACK_QP, qp_num);\n\tif (IS_ERR(res))\n\t\treturn NULL;\n\n\tqp = container_of(res, struct ib_qp, res);\n\tif (qp->qp_type == IB_QPT_RAW_PACKET && !capable(CAP_NET_RAW))\n\t\tgoto err;\n\n\treturn qp;\n\nerr:\n\trdma_restrack_put(res);\n\treturn NULL;\n}\n\nstatic struct rdma_counter *rdma_get_counter_by_id(struct ib_device *dev,\n\t\t\t\t\t\t   u32 counter_id)\n{\n\tstruct rdma_restrack_entry *res;\n\tstruct rdma_counter *counter;\n\n\tres = rdma_restrack_get_byid(dev, RDMA_RESTRACK_COUNTER, counter_id);\n\tif (IS_ERR(res))\n\t\treturn NULL;\n\n\tcounter = container_of(res, struct rdma_counter, res);\n\tkref_get(&counter->kref);\n\trdma_restrack_put(res);\n\n\treturn counter;\n}\n\n \nint rdma_counter_bind_qpn(struct ib_device *dev, u32 port,\n\t\t\t  u32 qp_num, u32 counter_id)\n{\n\tstruct rdma_port_counter *port_counter;\n\tstruct rdma_counter *counter;\n\tstruct ib_qp *qp;\n\tint ret;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\tif (port_counter->mode.mode == RDMA_COUNTER_MODE_AUTO)\n\t\treturn -EINVAL;\n\n\tqp = rdma_counter_get_qp(dev, qp_num);\n\tif (!qp)\n\t\treturn -ENOENT;\n\n\tcounter = rdma_get_counter_by_id(dev, counter_id);\n\tif (!counter) {\n\t\tret = -ENOENT;\n\t\tgoto err;\n\t}\n\n\tif (rdma_is_kernel_res(&counter->res) != rdma_is_kernel_res(&qp->res)) {\n\t\tret = -EINVAL;\n\t\tgoto err_task;\n\t}\n\n\tif ((counter->device != qp->device) || (counter->port != qp->port)) {\n\t\tret = -EINVAL;\n\t\tgoto err_task;\n\t}\n\n\tret = __rdma_counter_bind_qp(counter, qp);\n\tif (ret)\n\t\tgoto err_task;\n\n\trdma_restrack_put(&qp->res);\n\treturn 0;\n\nerr_task:\n\tkref_put(&counter->kref, counter_release);\nerr:\n\trdma_restrack_put(&qp->res);\n\treturn ret;\n}\n\n \nint rdma_counter_bind_qpn_alloc(struct ib_device *dev, u32 port,\n\t\t\t\tu32 qp_num, u32 *counter_id)\n{\n\tstruct rdma_port_counter *port_counter;\n\tstruct rdma_counter *counter;\n\tstruct ib_qp *qp;\n\tint ret;\n\n\tif (!rdma_is_port_valid(dev, port))\n\t\treturn -EINVAL;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\tif (!port_counter->hstats)\n\t\treturn -EOPNOTSUPP;\n\n\tif (port_counter->mode.mode == RDMA_COUNTER_MODE_AUTO)\n\t\treturn -EINVAL;\n\n\tqp = rdma_counter_get_qp(dev, qp_num);\n\tif (!qp)\n\t\treturn -ENOENT;\n\n\tif (rdma_is_port_valid(dev, qp->port) && (qp->port != port)) {\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tcounter = alloc_and_bind(dev, port, qp, RDMA_COUNTER_MODE_MANUAL);\n\tif (!counter) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tif (counter_id)\n\t\t*counter_id = counter->id;\n\n\trdma_restrack_put(&qp->res);\n\treturn 0;\n\nerr:\n\trdma_restrack_put(&qp->res);\n\treturn ret;\n}\n\n \nint rdma_counter_unbind_qpn(struct ib_device *dev, u32 port,\n\t\t\t    u32 qp_num, u32 counter_id)\n{\n\tstruct rdma_port_counter *port_counter;\n\tstruct ib_qp *qp;\n\tint ret;\n\n\tif (!rdma_is_port_valid(dev, port))\n\t\treturn -EINVAL;\n\n\tqp = rdma_counter_get_qp(dev, qp_num);\n\tif (!qp)\n\t\treturn -ENOENT;\n\n\tif (rdma_is_port_valid(dev, qp->port) && (qp->port != port)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tport_counter = &dev->port_data[port].port_counter;\n\tif (!qp->counter || qp->counter->id != counter_id ||\n\t    port_counter->mode.mode != RDMA_COUNTER_MODE_MANUAL) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tret = rdma_counter_unbind_qp(qp, false);\n\nout:\n\trdma_restrack_put(&qp->res);\n\treturn ret;\n}\n\nint rdma_counter_get_mode(struct ib_device *dev, u32 port,\n\t\t\t  enum rdma_nl_counter_mode *mode,\n\t\t\t  enum rdma_nl_counter_mask *mask)\n{\n\tstruct rdma_port_counter *port_counter;\n\n\tport_counter = &dev->port_data[port].port_counter;\n\t*mode = port_counter->mode.mode;\n\t*mask = port_counter->mode.mask;\n\n\treturn 0;\n}\n\nvoid rdma_counter_init(struct ib_device *dev)\n{\n\tstruct rdma_port_counter *port_counter;\n\tu32 port, i;\n\n\tif (!dev->port_data)\n\t\treturn;\n\n\trdma_for_each_port(dev, port) {\n\t\tport_counter = &dev->port_data[port].port_counter;\n\t\tport_counter->mode.mode = RDMA_COUNTER_MODE_NONE;\n\t\tmutex_init(&port_counter->lock);\n\n\t\tif (!dev->ops.alloc_hw_port_stats)\n\t\t\tcontinue;\n\n\t\tport_counter->hstats = dev->ops.alloc_hw_port_stats(dev, port);\n\t\tif (!port_counter->hstats)\n\t\t\tgoto fail;\n\t}\n\n\treturn;\n\nfail:\n\tfor (i = port; i >= rdma_start_port(dev); i--) {\n\t\tport_counter = &dev->port_data[port].port_counter;\n\t\trdma_free_hw_stats_struct(port_counter->hstats);\n\t\tport_counter->hstats = NULL;\n\t\tmutex_destroy(&port_counter->lock);\n\t}\n}\n\nvoid rdma_counter_release(struct ib_device *dev)\n{\n\tstruct rdma_port_counter *port_counter;\n\tu32 port;\n\n\trdma_for_each_port(dev, port) {\n\t\tport_counter = &dev->port_data[port].port_counter;\n\t\trdma_free_hw_stats_struct(port_counter->hstats);\n\t\tmutex_destroy(&port_counter->lock);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}