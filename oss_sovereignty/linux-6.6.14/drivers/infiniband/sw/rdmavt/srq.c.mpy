{
  "module_name": "srq.c",
  "hash_id": "d7c4077e2be6a10ace5d56b84c00d0e289d697d4db03abf7edb963da33c3b6c4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/sw/rdmavt/srq.c",
  "human_readable_source": "\n \n\n#include <linux/err.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <rdma/uverbs_ioctl.h>\n\n#include \"srq.h\"\n#include \"vt.h\"\n#include \"qp.h\"\n \nvoid rvt_driver_srq_init(struct rvt_dev_info *rdi)\n{\n\tspin_lock_init(&rdi->n_srqs_lock);\n\trdi->n_srqs_allocated = 0;\n}\n\n \nint rvt_create_srq(struct ib_srq *ibsrq, struct ib_srq_init_attr *srq_init_attr,\n\t\t   struct ib_udata *udata)\n{\n\tstruct rvt_dev_info *dev = ib_to_rvt(ibsrq->device);\n\tstruct rvt_srq *srq = ibsrq_to_rvtsrq(ibsrq);\n\tu32 sz;\n\tint ret;\n\n\tif (srq_init_attr->srq_type != IB_SRQT_BASIC)\n\t\treturn -EOPNOTSUPP;\n\n\tif (srq_init_attr->attr.max_sge == 0 ||\n\t    srq_init_attr->attr.max_sge > dev->dparms.props.max_srq_sge ||\n\t    srq_init_attr->attr.max_wr == 0 ||\n\t    srq_init_attr->attr.max_wr > dev->dparms.props.max_srq_wr)\n\t\treturn -EINVAL;\n\n\t \n\tsrq->rq.size = srq_init_attr->attr.max_wr + 1;\n\tsrq->rq.max_sge = srq_init_attr->attr.max_sge;\n\tsz = sizeof(struct ib_sge) * srq->rq.max_sge +\n\t\tsizeof(struct rvt_rwqe);\n\tif (rvt_alloc_rq(&srq->rq, srq->rq.size * sz,\n\t\t\t dev->dparms.node, udata)) {\n\t\tret = -ENOMEM;\n\t\tgoto bail_srq;\n\t}\n\n\t \n\tif (udata && udata->outlen >= sizeof(__u64)) {\n\t\tu32 s = sizeof(struct rvt_rwq) + srq->rq.size * sz;\n\n\t\tsrq->ip = rvt_create_mmap_info(dev, s, udata, srq->rq.wq);\n\t\tif (IS_ERR(srq->ip)) {\n\t\t\tret = PTR_ERR(srq->ip);\n\t\t\tgoto bail_wq;\n\t\t}\n\n\t\tret = ib_copy_to_udata(udata, &srq->ip->offset,\n\t\t\t\t       sizeof(srq->ip->offset));\n\t\tif (ret)\n\t\t\tgoto bail_ip;\n\t}\n\n\t \n\tspin_lock_init(&srq->rq.lock);\n\tsrq->limit = srq_init_attr->attr.srq_limit;\n\n\tspin_lock(&dev->n_srqs_lock);\n\tif (dev->n_srqs_allocated == dev->dparms.props.max_srq) {\n\t\tspin_unlock(&dev->n_srqs_lock);\n\t\tret = -ENOMEM;\n\t\tgoto bail_ip;\n\t}\n\n\tdev->n_srqs_allocated++;\n\tspin_unlock(&dev->n_srqs_lock);\n\n\tif (srq->ip) {\n\t\tspin_lock_irq(&dev->pending_lock);\n\t\tlist_add(&srq->ip->pending_mmaps, &dev->pending_mmaps);\n\t\tspin_unlock_irq(&dev->pending_lock);\n\t}\n\n\treturn 0;\n\nbail_ip:\n\tkfree(srq->ip);\nbail_wq:\n\trvt_free_rq(&srq->rq);\nbail_srq:\n\treturn ret;\n}\n\n \nint rvt_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,\n\t\t   enum ib_srq_attr_mask attr_mask,\n\t\t   struct ib_udata *udata)\n{\n\tstruct rvt_srq *srq = ibsrq_to_rvtsrq(ibsrq);\n\tstruct rvt_dev_info *dev = ib_to_rvt(ibsrq->device);\n\tstruct rvt_rq tmp_rq = {};\n\tint ret = 0;\n\n\tif (attr_mask & IB_SRQ_MAX_WR) {\n\t\tstruct rvt_krwq *okwq = NULL;\n\t\tstruct rvt_rwq *owq = NULL;\n\t\tstruct rvt_rwqe *p;\n\t\tu32 sz, size, n, head, tail;\n\n\t\t \n\t\tif ((attr->max_wr > dev->dparms.props.max_srq_wr) ||\n\t\t    ((attr_mask & IB_SRQ_LIMIT) ?\n\t\t     attr->srq_limit : srq->limit) > attr->max_wr)\n\t\t\treturn -EINVAL;\n\t\tsz = sizeof(struct rvt_rwqe) +\n\t\t\tsrq->rq.max_sge * sizeof(struct ib_sge);\n\t\tsize = attr->max_wr + 1;\n\t\tif (rvt_alloc_rq(&tmp_rq, size * sz, dev->dparms.node,\n\t\t\t\t udata))\n\t\t\treturn -ENOMEM;\n\t\t \n\t\tif (udata && udata->inlen >= sizeof(__u64)) {\n\t\t\t__u64 offset_addr;\n\t\t\t__u64 offset = 0;\n\n\t\t\tret = ib_copy_from_udata(&offset_addr, udata,\n\t\t\t\t\t\t sizeof(offset_addr));\n\t\t\tif (ret)\n\t\t\t\tgoto bail_free;\n\t\t\tudata->outbuf = (void __user *)\n\t\t\t\t\t(unsigned long)offset_addr;\n\t\t\tret = ib_copy_to_udata(udata, &offset,\n\t\t\t\t\t       sizeof(offset));\n\t\t\tif (ret)\n\t\t\t\tgoto bail_free;\n\t\t}\n\n\t\tspin_lock_irq(&srq->rq.kwq->c_lock);\n\t\t \n\t\tif (udata) {\n\t\t\towq = srq->rq.wq;\n\t\t\thead = RDMA_READ_UAPI_ATOMIC(owq->head);\n\t\t\ttail = RDMA_READ_UAPI_ATOMIC(owq->tail);\n\t\t} else {\n\t\t\tokwq = srq->rq.kwq;\n\t\t\thead = okwq->head;\n\t\t\ttail = okwq->tail;\n\t\t}\n\t\tif (head >= srq->rq.size || tail >= srq->rq.size) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto bail_unlock;\n\t\t}\n\t\tn = head;\n\t\tif (n < tail)\n\t\t\tn += srq->rq.size - tail;\n\t\telse\n\t\t\tn -= tail;\n\t\tif (size <= n) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto bail_unlock;\n\t\t}\n\t\tn = 0;\n\t\tp = tmp_rq.kwq->curr_wq;\n\t\twhile (tail != head) {\n\t\t\tstruct rvt_rwqe *wqe;\n\t\t\tint i;\n\n\t\t\twqe = rvt_get_rwqe_ptr(&srq->rq, tail);\n\t\t\tp->wr_id = wqe->wr_id;\n\t\t\tp->num_sge = wqe->num_sge;\n\t\t\tfor (i = 0; i < wqe->num_sge; i++)\n\t\t\t\tp->sg_list[i] = wqe->sg_list[i];\n\t\t\tn++;\n\t\t\tp = (struct rvt_rwqe *)((char *)p + sz);\n\t\t\tif (++tail >= srq->rq.size)\n\t\t\t\ttail = 0;\n\t\t}\n\t\tsrq->rq.kwq = tmp_rq.kwq;\n\t\tif (udata) {\n\t\t\tsrq->rq.wq = tmp_rq.wq;\n\t\t\tRDMA_WRITE_UAPI_ATOMIC(tmp_rq.wq->head, n);\n\t\t\tRDMA_WRITE_UAPI_ATOMIC(tmp_rq.wq->tail, 0);\n\t\t} else {\n\t\t\ttmp_rq.kwq->head = n;\n\t\t\ttmp_rq.kwq->tail = 0;\n\t\t}\n\t\tsrq->rq.size = size;\n\t\tif (attr_mask & IB_SRQ_LIMIT)\n\t\t\tsrq->limit = attr->srq_limit;\n\t\tspin_unlock_irq(&srq->rq.kwq->c_lock);\n\n\t\tvfree(owq);\n\t\tkvfree(okwq);\n\n\t\tif (srq->ip) {\n\t\t\tstruct rvt_mmap_info *ip = srq->ip;\n\t\t\tstruct rvt_dev_info *dev = ib_to_rvt(srq->ibsrq.device);\n\t\t\tu32 s = sizeof(struct rvt_rwq) + size * sz;\n\n\t\t\trvt_update_mmap_info(dev, ip, s, tmp_rq.wq);\n\n\t\t\t \n\t\t\tif (udata && udata->inlen >= sizeof(__u64)) {\n\t\t\t\tret = ib_copy_to_udata(udata, &ip->offset,\n\t\t\t\t\t\t       sizeof(ip->offset));\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\t \n\t\t\tspin_lock_irq(&dev->pending_lock);\n\t\t\tif (list_empty(&ip->pending_mmaps))\n\t\t\t\tlist_add(&ip->pending_mmaps,\n\t\t\t\t\t &dev->pending_mmaps);\n\t\t\tspin_unlock_irq(&dev->pending_lock);\n\t\t}\n\t} else if (attr_mask & IB_SRQ_LIMIT) {\n\t\tspin_lock_irq(&srq->rq.kwq->c_lock);\n\t\tif (attr->srq_limit >= srq->rq.size)\n\t\t\tret = -EINVAL;\n\t\telse\n\t\t\tsrq->limit = attr->srq_limit;\n\t\tspin_unlock_irq(&srq->rq.kwq->c_lock);\n\t}\n\treturn ret;\n\nbail_unlock:\n\tspin_unlock_irq(&srq->rq.kwq->c_lock);\nbail_free:\n\trvt_free_rq(&tmp_rq);\n\treturn ret;\n}\n\n \nint rvt_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr)\n{\n\tstruct rvt_srq *srq = ibsrq_to_rvtsrq(ibsrq);\n\n\tattr->max_wr = srq->rq.size - 1;\n\tattr->max_sge = srq->rq.max_sge;\n\tattr->srq_limit = srq->limit;\n\treturn 0;\n}\n\n \nint rvt_destroy_srq(struct ib_srq *ibsrq, struct ib_udata *udata)\n{\n\tstruct rvt_srq *srq = ibsrq_to_rvtsrq(ibsrq);\n\tstruct rvt_dev_info *dev = ib_to_rvt(ibsrq->device);\n\n\tspin_lock(&dev->n_srqs_lock);\n\tdev->n_srqs_allocated--;\n\tspin_unlock(&dev->n_srqs_lock);\n\tif (srq->ip)\n\t\tkref_put(&srq->ip->ref, rvt_release_mmap_info);\n\tkvfree(srq->rq.kwq);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}