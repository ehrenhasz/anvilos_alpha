{
  "module_name": "siw_qp.c",
  "hash_id": "24ef0c34f46d9638f6371023177d091d4ea25759a0b00121e0ebde6217fea0ec",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/sw/siw/siw_qp.c",
  "human_readable_source": "\n\n \n \n\n#include <linux/errno.h>\n#include <linux/types.h>\n#include <linux/net.h>\n#include <linux/scatterlist.h>\n#include <linux/llist.h>\n#include <asm/barrier.h>\n#include <net/tcp.h>\n#include <trace/events/sock.h>\n\n#include \"siw.h\"\n#include \"siw_verbs.h\"\n#include \"siw_mem.h\"\n\nstatic char siw_qp_state_to_string[SIW_QP_STATE_COUNT][sizeof \"TERMINATE\"] = {\n\t[SIW_QP_STATE_IDLE] = \"IDLE\",\n\t[SIW_QP_STATE_RTR] = \"RTR\",\n\t[SIW_QP_STATE_RTS] = \"RTS\",\n\t[SIW_QP_STATE_CLOSING] = \"CLOSING\",\n\t[SIW_QP_STATE_TERMINATE] = \"TERMINATE\",\n\t[SIW_QP_STATE_ERROR] = \"ERROR\"\n};\n\n \nstruct iwarp_msg_info iwarp_pktinfo[RDMAP_TERMINATE + 1] = {\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_rdma_write),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_rdma_write) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_TAGGED | DDP_FLAG_LAST |\n\t\t\t\t cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_RDMA_WRITE),\n\t  .rx_data = siw_proc_write },\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_rdma_rreq),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_rdma_rreq) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_LAST | cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_RDMA_READ_REQ),\n\t  .rx_data = siw_proc_rreq },\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_rdma_rresp),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_rdma_rresp) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_TAGGED | DDP_FLAG_LAST |\n\t\t\t\t cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_RDMA_READ_RESP),\n\t  .rx_data = siw_proc_rresp },\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_send),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_send) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_LAST | cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_SEND),\n\t  .rx_data = siw_proc_send },\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_send_inv),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_send_inv) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_LAST | cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_SEND_INVAL),\n\t  .rx_data = siw_proc_send },\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_send),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_send) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_LAST | cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_SEND_SE),\n\t  .rx_data = siw_proc_send },\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_send_inv),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_send_inv) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_LAST | cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_SEND_SE_INVAL),\n\t  .rx_data = siw_proc_send },\n\t{  \n\t  .hdr_len = sizeof(struct iwarp_terminate),\n\t  .ctrl.mpa_len = htons(sizeof(struct iwarp_terminate) - 2),\n\t  .ctrl.ddp_rdmap_ctrl = DDP_FLAG_LAST | cpu_to_be16(DDP_VERSION << 8) |\n\t\t\t\t cpu_to_be16(RDMAP_VERSION << 6) |\n\t\t\t\t cpu_to_be16(RDMAP_TERMINATE),\n\t  .rx_data = siw_proc_terminate }\n};\n\nvoid siw_qp_llp_data_ready(struct sock *sk)\n{\n\tstruct siw_qp *qp;\n\n\ttrace_sk_data_ready(sk);\n\n\tread_lock(&sk->sk_callback_lock);\n\n\tif (unlikely(!sk->sk_user_data || !sk_to_qp(sk)))\n\t\tgoto done;\n\n\tqp = sk_to_qp(sk);\n\n\tif (likely(!qp->rx_stream.rx_suspend &&\n\t\t   down_read_trylock(&qp->state_lock))) {\n\t\tread_descriptor_t rd_desc = { .arg.data = qp, .count = 1 };\n\n\t\tif (likely(qp->attrs.state == SIW_QP_STATE_RTS))\n\t\t\t \n\t\t\ttcp_read_sock(sk, &rd_desc, siw_tcp_rx_data);\n\n\t\tup_read(&qp->state_lock);\n\t} else {\n\t\tsiw_dbg_qp(qp, \"unable to process RX, suspend: %d\\n\",\n\t\t\t   qp->rx_stream.rx_suspend);\n\t}\ndone:\n\tread_unlock(&sk->sk_callback_lock);\n}\n\nvoid siw_qp_llp_close(struct siw_qp *qp)\n{\n\tsiw_dbg_qp(qp, \"enter llp close, state = %s\\n\",\n\t\t   siw_qp_state_to_string[qp->attrs.state]);\n\n\tdown_write(&qp->state_lock);\n\n\tqp->rx_stream.rx_suspend = 1;\n\tqp->tx_ctx.tx_suspend = 1;\n\tqp->attrs.sk = NULL;\n\n\tswitch (qp->attrs.state) {\n\tcase SIW_QP_STATE_RTS:\n\tcase SIW_QP_STATE_RTR:\n\tcase SIW_QP_STATE_IDLE:\n\tcase SIW_QP_STATE_TERMINATE:\n\t\tqp->attrs.state = SIW_QP_STATE_ERROR;\n\t\tbreak;\n\t \n\tcase SIW_QP_STATE_CLOSING:\n\t\tif (tx_wqe(qp)->wr_status == SIW_WR_IDLE)\n\t\t\tqp->attrs.state = SIW_QP_STATE_ERROR;\n\t\telse\n\t\t\tqp->attrs.state = SIW_QP_STATE_IDLE;\n\t\tbreak;\n\n\tdefault:\n\t\tsiw_dbg_qp(qp, \"llp close: no state transition needed: %s\\n\",\n\t\t\t   siw_qp_state_to_string[qp->attrs.state]);\n\t\tbreak;\n\t}\n\tsiw_sq_flush(qp);\n\tsiw_rq_flush(qp);\n\n\t \n\tif (qp->cep) {\n\t\tsiw_cep_put(qp->cep);\n\t\tqp->cep = NULL;\n\t}\n\n\tup_write(&qp->state_lock);\n\n\tsiw_dbg_qp(qp, \"llp close exit: state %s\\n\",\n\t\t   siw_qp_state_to_string[qp->attrs.state]);\n}\n\n \nvoid siw_qp_llp_write_space(struct sock *sk)\n{\n\tstruct siw_cep *cep;\n\n\tread_lock(&sk->sk_callback_lock);\n\n\tcep  = sk_to_cep(sk);\n\tif (cep) {\n\t\tcep->sk_write_space(sk);\n\n\t\tif (!test_bit(SOCK_NOSPACE, &sk->sk_socket->flags))\n\t\t\t(void)siw_sq_start(cep->qp);\n\t}\n\n\tread_unlock(&sk->sk_callback_lock);\n}\n\nstatic int siw_qp_readq_init(struct siw_qp *qp, int irq_size, int orq_size)\n{\n\tif (irq_size) {\n\t\tirq_size = roundup_pow_of_two(irq_size);\n\t\tqp->irq = vcalloc(irq_size, sizeof(struct siw_sqe));\n\t\tif (!qp->irq) {\n\t\t\tqp->attrs.irq_size = 0;\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\tif (orq_size) {\n\t\torq_size = roundup_pow_of_two(orq_size);\n\t\tqp->orq = vcalloc(orq_size, sizeof(struct siw_sqe));\n\t\tif (!qp->orq) {\n\t\t\tqp->attrs.orq_size = 0;\n\t\t\tqp->attrs.irq_size = 0;\n\t\t\tvfree(qp->irq);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\tqp->attrs.irq_size = irq_size;\n\tqp->attrs.orq_size = orq_size;\n\tsiw_dbg_qp(qp, \"ORD %d, IRD %d\\n\", orq_size, irq_size);\n\treturn 0;\n}\n\nstatic int siw_qp_enable_crc(struct siw_qp *qp)\n{\n\tstruct siw_rx_stream *c_rx = &qp->rx_stream;\n\tstruct siw_iwarp_tx *c_tx = &qp->tx_ctx;\n\tint size;\n\n\tif (siw_crypto_shash == NULL)\n\t\treturn -ENOENT;\n\n\tsize = crypto_shash_descsize(siw_crypto_shash) +\n\t\tsizeof(struct shash_desc);\n\n\tc_tx->mpa_crc_hd = kzalloc(size, GFP_KERNEL);\n\tc_rx->mpa_crc_hd = kzalloc(size, GFP_KERNEL);\n\tif (!c_tx->mpa_crc_hd || !c_rx->mpa_crc_hd) {\n\t\tkfree(c_tx->mpa_crc_hd);\n\t\tkfree(c_rx->mpa_crc_hd);\n\t\tc_tx->mpa_crc_hd = NULL;\n\t\tc_rx->mpa_crc_hd = NULL;\n\t\treturn -ENOMEM;\n\t}\n\tc_tx->mpa_crc_hd->tfm = siw_crypto_shash;\n\tc_rx->mpa_crc_hd->tfm = siw_crypto_shash;\n\n\treturn 0;\n}\n\n \nint siw_qp_mpa_rts(struct siw_qp *qp, enum mpa_v2_ctrl ctrl)\n{\n\tstruct siw_wqe *wqe = tx_wqe(qp);\n\tunsigned long flags;\n\tint rv = 0;\n\n\tspin_lock_irqsave(&qp->sq_lock, flags);\n\n\tif (unlikely(wqe->wr_status != SIW_WR_IDLE)) {\n\t\tspin_unlock_irqrestore(&qp->sq_lock, flags);\n\t\treturn -EIO;\n\t}\n\tmemset(wqe->mem, 0, sizeof(*wqe->mem) * SIW_MAX_SGE);\n\n\twqe->wr_status = SIW_WR_QUEUED;\n\twqe->sqe.flags = 0;\n\twqe->sqe.num_sge = 1;\n\twqe->sqe.sge[0].length = 0;\n\twqe->sqe.sge[0].laddr = 0;\n\twqe->sqe.sge[0].lkey = 0;\n\t \n\twqe->sqe.rkey = 1;\n\twqe->sqe.raddr = 0;\n\twqe->processed = 0;\n\n\tif (ctrl & MPA_V2_RDMA_WRITE_RTR)\n\t\twqe->sqe.opcode = SIW_OP_WRITE;\n\telse if (ctrl & MPA_V2_RDMA_READ_RTR) {\n\t\tstruct siw_sqe *rreq = NULL;\n\n\t\twqe->sqe.opcode = SIW_OP_READ;\n\n\t\tspin_lock(&qp->orq_lock);\n\n\t\tif (qp->attrs.orq_size)\n\t\t\trreq = orq_get_free(qp);\n\t\tif (rreq) {\n\t\t\tsiw_read_to_orq(rreq, &wqe->sqe);\n\t\t\tqp->orq_put++;\n\t\t} else\n\t\t\trv = -EIO;\n\n\t\tspin_unlock(&qp->orq_lock);\n\t} else\n\t\trv = -EINVAL;\n\n\tif (rv)\n\t\twqe->wr_status = SIW_WR_IDLE;\n\n\tspin_unlock_irqrestore(&qp->sq_lock, flags);\n\n\tif (!rv)\n\t\trv = siw_sq_start(qp);\n\n\treturn rv;\n}\n\n \nenum ddp_ecode siw_tagged_error(enum siw_access_state state)\n{\n\tswitch (state) {\n\tcase E_STAG_INVALID:\n\t\treturn DDP_ECODE_T_INVALID_STAG;\n\tcase E_BASE_BOUNDS:\n\t\treturn DDP_ECODE_T_BASE_BOUNDS;\n\tcase E_PD_MISMATCH:\n\t\treturn DDP_ECODE_T_STAG_NOT_ASSOC;\n\tcase E_ACCESS_PERM:\n\t\t \n\t\treturn DDP_ECODE_T_INVALID_STAG;\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn DDP_ECODE_T_INVALID_STAG;\n\t}\n}\n\n \nenum rdmap_ecode siw_rdmap_error(enum siw_access_state state)\n{\n\tswitch (state) {\n\tcase E_STAG_INVALID:\n\t\treturn RDMAP_ECODE_INVALID_STAG;\n\tcase E_BASE_BOUNDS:\n\t\treturn RDMAP_ECODE_BASE_BOUNDS;\n\tcase E_PD_MISMATCH:\n\t\treturn RDMAP_ECODE_STAG_NOT_ASSOC;\n\tcase E_ACCESS_PERM:\n\t\treturn RDMAP_ECODE_ACCESS_RIGHTS;\n\tdefault:\n\t\treturn RDMAP_ECODE_UNSPECIFIED;\n\t}\n}\n\nvoid siw_init_terminate(struct siw_qp *qp, enum term_elayer layer, u8 etype,\n\t\t\tu8 ecode, int in_tx)\n{\n\tif (!qp->term_info.valid) {\n\t\tmemset(&qp->term_info, 0, sizeof(qp->term_info));\n\t\tqp->term_info.layer = layer;\n\t\tqp->term_info.etype = etype;\n\t\tqp->term_info.ecode = ecode;\n\t\tqp->term_info.in_tx = in_tx;\n\t\tqp->term_info.valid = 1;\n\t}\n\tsiw_dbg_qp(qp, \"init TERM: layer %d, type %d, code %d, in tx %s\\n\",\n\t\t   layer, etype, ecode, in_tx ? \"yes\" : \"no\");\n}\n\n \nvoid siw_send_terminate(struct siw_qp *qp)\n{\n\tstruct kvec iov[3];\n\tstruct msghdr msg = { .msg_flags = MSG_DONTWAIT | MSG_EOR };\n\tstruct iwarp_terminate *term = NULL;\n\tunion iwarp_hdr *err_hdr = NULL;\n\tstruct socket *s = qp->attrs.sk;\n\tstruct siw_rx_stream *srx = &qp->rx_stream;\n\tunion iwarp_hdr *rx_hdr = &srx->hdr;\n\tu32 crc = 0;\n\tint num_frags, len_terminate, rv;\n\n\tif (!qp->term_info.valid)\n\t\treturn;\n\n\tqp->term_info.valid = 0;\n\n\tif (tx_wqe(qp)->wr_status == SIW_WR_INPROGRESS) {\n\t\tsiw_dbg_qp(qp, \"cannot send TERMINATE: op %d in progress\\n\",\n\t\t\t   tx_type(tx_wqe(qp)));\n\t\treturn;\n\t}\n\tif (!s && qp->cep)\n\t\t \n\t\ts = qp->cep->sock;\n\n\tif (!s) {\n\t\tsiw_dbg_qp(qp, \"cannot send TERMINATE: not connected\\n\");\n\t\treturn;\n\t}\n\n\tterm = kzalloc(sizeof(*term), GFP_KERNEL);\n\tif (!term)\n\t\treturn;\n\n\tterm->ddp_qn = cpu_to_be32(RDMAP_UNTAGGED_QN_TERMINATE);\n\tterm->ddp_mo = 0;\n\tterm->ddp_msn = cpu_to_be32(1);\n\n\tiov[0].iov_base = term;\n\tiov[0].iov_len = sizeof(*term);\n\n\tif ((qp->term_info.layer == TERM_ERROR_LAYER_DDP) ||\n\t    ((qp->term_info.layer == TERM_ERROR_LAYER_RDMAP) &&\n\t     (qp->term_info.etype != RDMAP_ETYPE_CATASTROPHIC))) {\n\t\terr_hdr = kzalloc(sizeof(*err_hdr), GFP_KERNEL);\n\t\tif (!err_hdr) {\n\t\t\tkfree(term);\n\t\t\treturn;\n\t\t}\n\t}\n\tmemcpy(&term->ctrl, &iwarp_pktinfo[RDMAP_TERMINATE].ctrl,\n\t       sizeof(struct iwarp_ctrl));\n\n\t__rdmap_term_set_layer(term, qp->term_info.layer);\n\t__rdmap_term_set_etype(term, qp->term_info.etype);\n\t__rdmap_term_set_ecode(term, qp->term_info.ecode);\n\n\tswitch (qp->term_info.layer) {\n\tcase TERM_ERROR_LAYER_RDMAP:\n\t\tif (qp->term_info.etype == RDMAP_ETYPE_CATASTROPHIC)\n\t\t\t \n\t\t\tbreak;\n\n\t\tif (qp->term_info.etype == RDMAP_ETYPE_REMOTE_PROTECTION) {\n\t\t\t \n\t\t\tterm->flag_m = 1;\n\t\t\tterm->flag_d = 1;\n\t\t\tterm->flag_r = 1;\n\n\t\t\tif (qp->term_info.in_tx) {\n\t\t\t\tstruct iwarp_rdma_rreq *rreq;\n\t\t\t\tstruct siw_wqe *wqe = tx_wqe(qp);\n\n\t\t\t\t \n\t\t\t\trreq = (struct iwarp_rdma_rreq *)err_hdr;\n\n\t\t\t\tmemcpy(&rreq->ctrl,\n\t\t\t\t       &iwarp_pktinfo[RDMAP_RDMA_READ_REQ].ctrl,\n\t\t\t\t       sizeof(struct iwarp_ctrl));\n\n\t\t\t\trreq->rsvd = 0;\n\t\t\t\trreq->ddp_qn =\n\t\t\t\t\thtonl(RDMAP_UNTAGGED_QN_RDMA_READ);\n\n\t\t\t\t \n\t\t\t\trreq->ddp_msn = htonl(wqe->sqe.sge[0].length);\n\n\t\t\t\trreq->ddp_mo = htonl(wqe->processed);\n\t\t\t\trreq->sink_stag = htonl(wqe->sqe.rkey);\n\t\t\t\trreq->sink_to = cpu_to_be64(wqe->sqe.raddr);\n\t\t\t\trreq->read_size = htonl(wqe->sqe.sge[0].length);\n\t\t\t\trreq->source_stag = htonl(wqe->sqe.sge[0].lkey);\n\t\t\t\trreq->source_to =\n\t\t\t\t\tcpu_to_be64(wqe->sqe.sge[0].laddr);\n\n\t\t\t\tiov[1].iov_base = rreq;\n\t\t\t\tiov[1].iov_len = sizeof(*rreq);\n\n\t\t\t\trx_hdr = (union iwarp_hdr *)rreq;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tiov[1].iov_base = rx_hdr;\n\n\t\t\t\tif (__rdmap_get_opcode(&rx_hdr->ctrl) ==\n\t\t\t\t    RDMAP_RDMA_READ_REQ)\n\t\t\t\t\tiov[1].iov_len =\n\t\t\t\t\t\tsizeof(struct iwarp_rdma_rreq);\n\t\t\t\telse  \n\t\t\t\t\tiov[1].iov_len =\n\t\t\t\t\t\tsizeof(struct iwarp_send);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tif ((qp->term_info.ecode == RDMAP_ECODE_VERSION) ||\n\t\t\t    (qp->term_info.ecode == RDMAP_ECODE_OPCODE))\n\t\t\t\tbreak;\n\n\t\t\tiov[1].iov_base = rx_hdr;\n\n\t\t\t \n\t\t\tif (rx_hdr->ctrl.ddp_rdmap_ctrl & DDP_FLAG_TAGGED)\n\t\t\t\tiov[1].iov_len =\n\t\t\t\t\tsizeof(struct iwarp_rdma_write);\n\t\t\telse\n\t\t\t\tiov[1].iov_len = sizeof(struct iwarp_send);\n\n\t\t\tterm->flag_m = 1;\n\t\t\tterm->flag_d = 1;\n\t\t}\n\t\tterm->ctrl.mpa_len = cpu_to_be16(iov[1].iov_len);\n\t\tbreak;\n\n\tcase TERM_ERROR_LAYER_DDP:\n\t\t \n\n\t\t \n\t\tif (((qp->term_info.etype == DDP_ETYPE_TAGGED_BUF) &&\n\t\t     (qp->term_info.ecode == DDP_ECODE_T_VERSION)) ||\n\t\t    ((qp->term_info.etype == DDP_ETYPE_UNTAGGED_BUF) &&\n\t\t     (qp->term_info.ecode == DDP_ECODE_UT_VERSION)))\n\t\t\tbreak;\n\n\t\tiov[1].iov_base = rx_hdr;\n\n\t\tif (rx_hdr->ctrl.ddp_rdmap_ctrl & DDP_FLAG_TAGGED)\n\t\t\tiov[1].iov_len = sizeof(struct iwarp_ctrl_tagged);\n\t\telse\n\t\t\tiov[1].iov_len = sizeof(struct iwarp_ctrl_untagged);\n\n\t\tterm->flag_m = 1;\n\t\tterm->flag_d = 1;\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\tif (term->flag_m || term->flag_d || term->flag_r) {\n\t\tiov[2].iov_base = &crc;\n\t\tiov[2].iov_len = sizeof(crc);\n\t\tlen_terminate = sizeof(*term) + iov[1].iov_len + MPA_CRC_SIZE;\n\t\tnum_frags = 3;\n\t} else {\n\t\tiov[1].iov_base = &crc;\n\t\tiov[1].iov_len = sizeof(crc);\n\t\tlen_terminate = sizeof(*term) + MPA_CRC_SIZE;\n\t\tnum_frags = 2;\n\t}\n\n\t \n\tif (term->flag_m) {\n\t\tu32 real_ddp_len = be16_to_cpu(rx_hdr->ctrl.mpa_len);\n\t\tenum rdma_opcode op = __rdmap_get_opcode(&rx_hdr->ctrl);\n\n\t\treal_ddp_len -= iwarp_pktinfo[op].hdr_len - MPA_HDR_SIZE;\n\t\trx_hdr->ctrl.mpa_len = cpu_to_be16(real_ddp_len);\n\t}\n\n\tterm->ctrl.mpa_len =\n\t\tcpu_to_be16(len_terminate - (MPA_HDR_SIZE + MPA_CRC_SIZE));\n\tif (qp->tx_ctx.mpa_crc_hd) {\n\t\tcrypto_shash_init(qp->tx_ctx.mpa_crc_hd);\n\t\tif (crypto_shash_update(qp->tx_ctx.mpa_crc_hd,\n\t\t\t\t\t(u8 *)iov[0].iov_base,\n\t\t\t\t\tiov[0].iov_len))\n\t\t\tgoto out;\n\n\t\tif (num_frags == 3) {\n\t\t\tif (crypto_shash_update(qp->tx_ctx.mpa_crc_hd,\n\t\t\t\t\t\t(u8 *)iov[1].iov_base,\n\t\t\t\t\t\tiov[1].iov_len))\n\t\t\t\tgoto out;\n\t\t}\n\t\tcrypto_shash_final(qp->tx_ctx.mpa_crc_hd, (u8 *)&crc);\n\t}\n\n\trv = kernel_sendmsg(s, &msg, iov, num_frags, len_terminate);\n\tsiw_dbg_qp(qp, \"sent TERM: %s, layer %d, type %d, code %d (%d bytes)\\n\",\n\t\t   rv == len_terminate ? \"success\" : \"failure\",\n\t\t   __rdmap_term_layer(term), __rdmap_term_etype(term),\n\t\t   __rdmap_term_ecode(term), rv);\nout:\n\tkfree(term);\n\tkfree(err_hdr);\n}\n\n \nstatic void siw_qp_modify_nonstate(struct siw_qp *qp,\n\t\t\t\t   struct siw_qp_attrs *attrs,\n\t\t\t\t   enum siw_qp_attr_mask mask)\n{\n\tif (mask & SIW_QP_ATTR_ACCESS_FLAGS) {\n\t\tif (attrs->flags & SIW_RDMA_BIND_ENABLED)\n\t\t\tqp->attrs.flags |= SIW_RDMA_BIND_ENABLED;\n\t\telse\n\t\t\tqp->attrs.flags &= ~SIW_RDMA_BIND_ENABLED;\n\n\t\tif (attrs->flags & SIW_RDMA_WRITE_ENABLED)\n\t\t\tqp->attrs.flags |= SIW_RDMA_WRITE_ENABLED;\n\t\telse\n\t\t\tqp->attrs.flags &= ~SIW_RDMA_WRITE_ENABLED;\n\n\t\tif (attrs->flags & SIW_RDMA_READ_ENABLED)\n\t\t\tqp->attrs.flags |= SIW_RDMA_READ_ENABLED;\n\t\telse\n\t\t\tqp->attrs.flags &= ~SIW_RDMA_READ_ENABLED;\n\t}\n}\n\nstatic int siw_qp_nextstate_from_idle(struct siw_qp *qp,\n\t\t\t\t      struct siw_qp_attrs *attrs,\n\t\t\t\t      enum siw_qp_attr_mask mask)\n{\n\tint rv = 0;\n\n\tswitch (attrs->state) {\n\tcase SIW_QP_STATE_RTS:\n\t\tif (attrs->flags & SIW_MPA_CRC) {\n\t\t\trv = siw_qp_enable_crc(qp);\n\t\t\tif (rv)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (!(mask & SIW_QP_ATTR_LLP_HANDLE)) {\n\t\t\tsiw_dbg_qp(qp, \"no socket\\n\");\n\t\t\trv = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (!(mask & SIW_QP_ATTR_MPA)) {\n\t\t\tsiw_dbg_qp(qp, \"no MPA\\n\");\n\t\t\trv = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tqp->tx_ctx.ddp_msn[RDMAP_UNTAGGED_QN_SEND] = 0;\n\t\tqp->tx_ctx.ddp_msn[RDMAP_UNTAGGED_QN_RDMA_READ] = 0;\n\t\tqp->tx_ctx.ddp_msn[RDMAP_UNTAGGED_QN_TERMINATE] = 0;\n\n\t\t \n\t\tqp->rx_stream.ddp_msn[RDMAP_UNTAGGED_QN_SEND] = 1;\n\t\tqp->rx_stream.ddp_msn[RDMAP_UNTAGGED_QN_RDMA_READ] = 1;\n\t\tqp->rx_stream.ddp_msn[RDMAP_UNTAGGED_QN_TERMINATE] = 1;\n\n\t\t \n\t\trv = siw_qp_readq_init(qp, attrs->irq_size,\n\t\t\t\t       attrs->orq_size);\n\t\tif (rv)\n\t\t\tbreak;\n\n\t\tqp->attrs.sk = attrs->sk;\n\t\tqp->attrs.state = SIW_QP_STATE_RTS;\n\n\t\tsiw_dbg_qp(qp, \"enter RTS: crc=%s, ord=%u, ird=%u\\n\",\n\t\t\t   attrs->flags & SIW_MPA_CRC ? \"y\" : \"n\",\n\t\t\t   qp->attrs.orq_size, qp->attrs.irq_size);\n\t\tbreak;\n\n\tcase SIW_QP_STATE_ERROR:\n\t\tsiw_rq_flush(qp);\n\t\tqp->attrs.state = SIW_QP_STATE_ERROR;\n\t\tif (qp->cep) {\n\t\t\tsiw_cep_put(qp->cep);\n\t\t\tqp->cep = NULL;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\treturn rv;\n}\n\nstatic int siw_qp_nextstate_from_rts(struct siw_qp *qp,\n\t\t\t\t     struct siw_qp_attrs *attrs)\n{\n\tint drop_conn = 0;\n\n\tswitch (attrs->state) {\n\tcase SIW_QP_STATE_CLOSING:\n\t\t \n\t\tif (tx_wqe(qp)->wr_status == SIW_WR_IDLE) {\n\t\t\tqp->attrs.state = SIW_QP_STATE_CLOSING;\n\t\t} else {\n\t\t\tqp->attrs.state = SIW_QP_STATE_ERROR;\n\t\t\tsiw_sq_flush(qp);\n\t\t}\n\t\tsiw_rq_flush(qp);\n\n\t\tdrop_conn = 1;\n\t\tbreak;\n\n\tcase SIW_QP_STATE_TERMINATE:\n\t\tqp->attrs.state = SIW_QP_STATE_TERMINATE;\n\n\t\tsiw_init_terminate(qp, TERM_ERROR_LAYER_RDMAP,\n\t\t\t\t   RDMAP_ETYPE_CATASTROPHIC,\n\t\t\t\t   RDMAP_ECODE_UNSPECIFIED, 1);\n\t\tdrop_conn = 1;\n\t\tbreak;\n\n\tcase SIW_QP_STATE_ERROR:\n\t\t \n\t\tsiw_sq_flush(qp);\n\t\tsiw_rq_flush(qp);\n\t\tqp->attrs.state = SIW_QP_STATE_ERROR;\n\t\tdrop_conn = 1;\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\treturn drop_conn;\n}\n\nstatic void siw_qp_nextstate_from_term(struct siw_qp *qp,\n\t\t\t\t       struct siw_qp_attrs *attrs)\n{\n\tswitch (attrs->state) {\n\tcase SIW_QP_STATE_ERROR:\n\t\tsiw_rq_flush(qp);\n\t\tqp->attrs.state = SIW_QP_STATE_ERROR;\n\n\t\tif (tx_wqe(qp)->wr_status != SIW_WR_IDLE)\n\t\t\tsiw_sq_flush(qp);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic int siw_qp_nextstate_from_close(struct siw_qp *qp,\n\t\t\t\t       struct siw_qp_attrs *attrs)\n{\n\tint rv = 0;\n\n\tswitch (attrs->state) {\n\tcase SIW_QP_STATE_IDLE:\n\t\tWARN_ON(tx_wqe(qp)->wr_status != SIW_WR_IDLE);\n\t\tqp->attrs.state = SIW_QP_STATE_IDLE;\n\t\tbreak;\n\n\tcase SIW_QP_STATE_CLOSING:\n\t\t \n\t\tbreak;\n\n\tcase SIW_QP_STATE_ERROR:\n\t\t \n\t\tqp->attrs.state = SIW_QP_STATE_ERROR;\n\n\t\tif (tx_wqe(qp)->wr_status != SIW_WR_IDLE)\n\t\t\tsiw_sq_flush(qp);\n\n\t\tsiw_rq_flush(qp);\n\t\tbreak;\n\n\tdefault:\n\t\tsiw_dbg_qp(qp, \"state transition undefined: %s => %s\\n\",\n\t\t\t   siw_qp_state_to_string[qp->attrs.state],\n\t\t\t   siw_qp_state_to_string[attrs->state]);\n\n\t\trv = -ECONNABORTED;\n\t}\n\treturn rv;\n}\n\n \nint siw_qp_modify(struct siw_qp *qp, struct siw_qp_attrs *attrs,\n\t\t  enum siw_qp_attr_mask mask)\n{\n\tint drop_conn = 0, rv = 0;\n\n\tif (!mask)\n\t\treturn 0;\n\n\tsiw_dbg_qp(qp, \"state: %s => %s\\n\",\n\t\t   siw_qp_state_to_string[qp->attrs.state],\n\t\t   siw_qp_state_to_string[attrs->state]);\n\n\tif (mask != SIW_QP_ATTR_STATE)\n\t\tsiw_qp_modify_nonstate(qp, attrs, mask);\n\n\tif (!(mask & SIW_QP_ATTR_STATE))\n\t\treturn 0;\n\n\tswitch (qp->attrs.state) {\n\tcase SIW_QP_STATE_IDLE:\n\tcase SIW_QP_STATE_RTR:\n\t\trv = siw_qp_nextstate_from_idle(qp, attrs, mask);\n\t\tbreak;\n\n\tcase SIW_QP_STATE_RTS:\n\t\tdrop_conn = siw_qp_nextstate_from_rts(qp, attrs);\n\t\tbreak;\n\n\tcase SIW_QP_STATE_TERMINATE:\n\t\tsiw_qp_nextstate_from_term(qp, attrs);\n\t\tbreak;\n\n\tcase SIW_QP_STATE_CLOSING:\n\t\tsiw_qp_nextstate_from_close(qp, attrs);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\tif (drop_conn)\n\t\tsiw_qp_cm_drop(qp, 0);\n\n\treturn rv;\n}\n\nvoid siw_read_to_orq(struct siw_sqe *rreq, struct siw_sqe *sqe)\n{\n\trreq->id = sqe->id;\n\trreq->opcode = sqe->opcode;\n\trreq->sge[0].laddr = sqe->sge[0].laddr;\n\trreq->sge[0].length = sqe->sge[0].length;\n\trreq->sge[0].lkey = sqe->sge[0].lkey;\n\trreq->sge[1].lkey = sqe->sge[1].lkey;\n\trreq->flags = sqe->flags | SIW_WQE_VALID;\n\trreq->num_sge = 1;\n}\n\nstatic int siw_activate_tx_from_sq(struct siw_qp *qp)\n{\n\tstruct siw_sqe *sqe;\n\tstruct siw_wqe *wqe = tx_wqe(qp);\n\tint rv = 1;\n\n\tsqe = sq_get_next(qp);\n\tif (!sqe)\n\t\treturn 0;\n\n\tmemset(wqe->mem, 0, sizeof(*wqe->mem) * SIW_MAX_SGE);\n\twqe->wr_status = SIW_WR_QUEUED;\n\n\t \n\tmemcpy(&wqe->sqe, sqe, sizeof(*sqe));\n\n\tif (wqe->sqe.opcode >= SIW_NUM_OPCODES) {\n\t\trv = -EINVAL;\n\t\tgoto out;\n\t}\n\tif (wqe->sqe.flags & SIW_WQE_INLINE) {\n\t\tif (wqe->sqe.opcode != SIW_OP_SEND &&\n\t\t    wqe->sqe.opcode != SIW_OP_WRITE) {\n\t\t\trv = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tif (wqe->sqe.sge[0].length > SIW_MAX_INLINE) {\n\t\t\trv = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\twqe->sqe.sge[0].laddr = (uintptr_t)&wqe->sqe.sge[1];\n\t\twqe->sqe.sge[0].lkey = 0;\n\t\twqe->sqe.num_sge = 1;\n\t}\n\tif (wqe->sqe.flags & SIW_WQE_READ_FENCE) {\n\t\t \n\t\tif (unlikely(wqe->sqe.opcode == SIW_OP_READ ||\n\t\t\t     wqe->sqe.opcode ==\n\t\t\t\t     SIW_OP_READ_LOCAL_INV)) {\n\t\t\tsiw_dbg_qp(qp, \"cannot fence read\\n\");\n\t\t\trv = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\tspin_lock(&qp->orq_lock);\n\n\t\tif (qp->attrs.orq_size && !siw_orq_empty(qp)) {\n\t\t\tqp->tx_ctx.orq_fence = 1;\n\t\t\trv = 0;\n\t\t}\n\t\tspin_unlock(&qp->orq_lock);\n\n\t} else if (wqe->sqe.opcode == SIW_OP_READ ||\n\t\t   wqe->sqe.opcode == SIW_OP_READ_LOCAL_INV) {\n\t\tstruct siw_sqe *rreq;\n\n\t\tif (unlikely(!qp->attrs.orq_size)) {\n\t\t\t \n\t\t\trv = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t\twqe->sqe.num_sge = 1;\n\n\t\tspin_lock(&qp->orq_lock);\n\n\t\trreq = orq_get_free(qp);\n\t\tif (rreq) {\n\t\t\t \n\t\t\tsiw_read_to_orq(rreq, &wqe->sqe);\n\t\t\tqp->orq_put++;\n\t\t} else {\n\t\t\tqp->tx_ctx.orq_fence = 1;\n\t\t\trv = 0;\n\t\t}\n\t\tspin_unlock(&qp->orq_lock);\n\t}\n\n\t \n\tsmp_store_mb(sqe->flags, 0);\n\tqp->sq_get++;\nout:\n\tif (unlikely(rv < 0)) {\n\t\tsiw_dbg_qp(qp, \"error %d\\n\", rv);\n\t\twqe->wr_status = SIW_WR_IDLE;\n\t}\n\treturn rv;\n}\n\n \nint siw_activate_tx(struct siw_qp *qp)\n{\n\tstruct siw_sqe *irqe;\n\tstruct siw_wqe *wqe = tx_wqe(qp);\n\n\tif (!qp->attrs.irq_size)\n\t\treturn siw_activate_tx_from_sq(qp);\n\n\tirqe = &qp->irq[qp->irq_get % qp->attrs.irq_size];\n\n\tif (!(irqe->flags & SIW_WQE_VALID))\n\t\treturn siw_activate_tx_from_sq(qp);\n\n\t \n\tif (sq_get_next(qp) && ++qp->irq_burst >= SIW_IRQ_MAXBURST_SQ_ACTIVE) {\n\t\tqp->irq_burst = 0;\n\t\treturn siw_activate_tx_from_sq(qp);\n\t}\n\tmemset(wqe->mem, 0, sizeof(*wqe->mem) * SIW_MAX_SGE);\n\twqe->wr_status = SIW_WR_QUEUED;\n\n\t \n\twqe->sqe.opcode = SIW_OP_READ_RESPONSE;\n\twqe->sqe.flags = 0;\n\tif (irqe->num_sge) {\n\t\twqe->sqe.num_sge = 1;\n\t\twqe->sqe.sge[0].length = irqe->sge[0].length;\n\t\twqe->sqe.sge[0].laddr = irqe->sge[0].laddr;\n\t\twqe->sqe.sge[0].lkey = irqe->sge[0].lkey;\n\t} else {\n\t\twqe->sqe.num_sge = 0;\n\t}\n\n\t \n\twqe->sqe.sge[1].length = irqe->sge[1].length;\n\n\twqe->sqe.rkey = irqe->rkey;\n\twqe->sqe.raddr = irqe->raddr;\n\n\twqe->processed = 0;\n\tqp->irq_get++;\n\n\t \n\tsmp_store_mb(irqe->flags, 0);\n\n\treturn 1;\n}\n\n \nstatic bool siw_cq_notify_now(struct siw_cq *cq, u32 flags)\n{\n\tu32 cq_notify;\n\n\tif (!cq->base_cq.comp_handler)\n\t\treturn false;\n\n\t \n\tcq_notify = READ_ONCE(cq->notify->flags);\n\n\tif ((cq_notify & SIW_NOTIFY_NEXT_COMPLETION) ||\n\t    ((cq_notify & SIW_NOTIFY_SOLICITED) &&\n\t     (flags & SIW_WQE_SOLICITED))) {\n\t\t \n\t\tWRITE_ONCE(cq->notify->flags, SIW_NOTIFY_NOT);\n\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nint siw_sqe_complete(struct siw_qp *qp, struct siw_sqe *sqe, u32 bytes,\n\t\t     enum siw_wc_status status)\n{\n\tstruct siw_cq *cq = qp->scq;\n\tint rv = 0;\n\n\tif (cq) {\n\t\tu32 sqe_flags = sqe->flags;\n\t\tstruct siw_cqe *cqe;\n\t\tu32 idx;\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&cq->lock, flags);\n\n\t\tidx = cq->cq_put % cq->num_cqe;\n\t\tcqe = &cq->queue[idx];\n\n\t\tif (!READ_ONCE(cqe->flags)) {\n\t\t\tbool notify;\n\n\t\t\tcqe->id = sqe->id;\n\t\t\tcqe->opcode = sqe->opcode;\n\t\t\tcqe->status = status;\n\t\t\tcqe->imm_data = 0;\n\t\t\tcqe->bytes = bytes;\n\n\t\t\tif (rdma_is_kernel_res(&cq->base_cq.res))\n\t\t\t\tcqe->base_qp = &qp->base_qp;\n\t\t\telse\n\t\t\t\tcqe->qp_id = qp_id(qp);\n\n\t\t\t \n\t\t\tWRITE_ONCE(cqe->flags, SIW_WQE_VALID);\n\t\t\t \n\t\t\tsmp_store_mb(sqe->flags, 0);\n\n\t\t\tcq->cq_put++;\n\t\t\tnotify = siw_cq_notify_now(cq, sqe_flags);\n\n\t\t\tspin_unlock_irqrestore(&cq->lock, flags);\n\n\t\t\tif (notify) {\n\t\t\t\tsiw_dbg_cq(cq, \"Call completion handler\\n\");\n\t\t\t\tcq->base_cq.comp_handler(&cq->base_cq,\n\t\t\t\t\t\tcq->base_cq.cq_context);\n\t\t\t}\n\t\t} else {\n\t\t\tspin_unlock_irqrestore(&cq->lock, flags);\n\t\t\trv = -ENOMEM;\n\t\t\tsiw_cq_event(cq, IB_EVENT_CQ_ERR);\n\t\t}\n\t} else {\n\t\t \n\t\tsmp_store_mb(sqe->flags, 0);\n\t}\n\treturn rv;\n}\n\nint siw_rqe_complete(struct siw_qp *qp, struct siw_rqe *rqe, u32 bytes,\n\t\t     u32 inval_stag, enum siw_wc_status status)\n{\n\tstruct siw_cq *cq = qp->rcq;\n\tint rv = 0;\n\n\tif (cq) {\n\t\tstruct siw_cqe *cqe;\n\t\tu32 idx;\n\t\tunsigned long flags;\n\n\t\tspin_lock_irqsave(&cq->lock, flags);\n\n\t\tidx = cq->cq_put % cq->num_cqe;\n\t\tcqe = &cq->queue[idx];\n\n\t\tif (!READ_ONCE(cqe->flags)) {\n\t\t\tbool notify;\n\t\t\tu8 cqe_flags = SIW_WQE_VALID;\n\n\t\t\tcqe->id = rqe->id;\n\t\t\tcqe->opcode = SIW_OP_RECEIVE;\n\t\t\tcqe->status = status;\n\t\t\tcqe->imm_data = 0;\n\t\t\tcqe->bytes = bytes;\n\n\t\t\tif (rdma_is_kernel_res(&cq->base_cq.res)) {\n\t\t\t\tcqe->base_qp = &qp->base_qp;\n\t\t\t\tif (inval_stag) {\n\t\t\t\t\tcqe_flags |= SIW_WQE_REM_INVAL;\n\t\t\t\t\tcqe->inval_stag = inval_stag;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tcqe->qp_id = qp_id(qp);\n\t\t\t}\n\t\t\t \n\t\t\tWRITE_ONCE(cqe->flags, cqe_flags);\n\t\t\t \n\t\t\tsmp_store_mb(rqe->flags, 0);\n\n\t\t\tcq->cq_put++;\n\t\t\tnotify = siw_cq_notify_now(cq, SIW_WQE_SIGNALLED);\n\n\t\t\tspin_unlock_irqrestore(&cq->lock, flags);\n\n\t\t\tif (notify) {\n\t\t\t\tsiw_dbg_cq(cq, \"Call completion handler\\n\");\n\t\t\t\tcq->base_cq.comp_handler(&cq->base_cq,\n\t\t\t\t\t\tcq->base_cq.cq_context);\n\t\t\t}\n\t\t} else {\n\t\t\tspin_unlock_irqrestore(&cq->lock, flags);\n\t\t\trv = -ENOMEM;\n\t\t\tsiw_cq_event(cq, IB_EVENT_CQ_ERR);\n\t\t}\n\t} else {\n\t\t \n\t\tsmp_store_mb(rqe->flags, 0);\n\t}\n\treturn rv;\n}\n\n \nvoid siw_sq_flush(struct siw_qp *qp)\n{\n\tstruct siw_sqe *sqe;\n\tstruct siw_wqe *wqe = tx_wqe(qp);\n\tint async_event = 0;\n\n\t \n\twhile (qp->attrs.orq_size) {\n\t\tsqe = &qp->orq[qp->orq_get % qp->attrs.orq_size];\n\t\tif (!READ_ONCE(sqe->flags))\n\t\t\tbreak;\n\n\t\tif (siw_sqe_complete(qp, sqe, 0, SIW_WC_WR_FLUSH_ERR) != 0)\n\t\t\tbreak;\n\n\t\tWRITE_ONCE(sqe->flags, 0);\n\t\tqp->orq_get++;\n\t}\n\t \n\tif (wqe->wr_status != SIW_WR_IDLE) {\n\t\tsiw_dbg_qp(qp, \"flush current SQE, type %d, status %d\\n\",\n\t\t\t   tx_type(wqe), wqe->wr_status);\n\n\t\tsiw_wqe_put_mem(wqe, tx_type(wqe));\n\n\t\tif (tx_type(wqe) != SIW_OP_READ_RESPONSE &&\n\t\t    ((tx_type(wqe) != SIW_OP_READ &&\n\t\t      tx_type(wqe) != SIW_OP_READ_LOCAL_INV) ||\n\t\t     wqe->wr_status == SIW_WR_QUEUED))\n\t\t\t \n\t\t\tsiw_sqe_complete(qp, &wqe->sqe, wqe->bytes,\n\t\t\t\t\t SIW_WC_WR_FLUSH_ERR);\n\n\t\twqe->wr_status = SIW_WR_IDLE;\n\t}\n\t \n\twhile (qp->attrs.sq_size) {\n\t\tsqe = &qp->sendq[qp->sq_get % qp->attrs.sq_size];\n\t\tif (!READ_ONCE(sqe->flags))\n\t\t\tbreak;\n\n\t\tasync_event = 1;\n\t\tif (siw_sqe_complete(qp, sqe, 0, SIW_WC_WR_FLUSH_ERR) != 0)\n\t\t\t \n\t\t\tbreak;\n\n\t\tWRITE_ONCE(sqe->flags, 0);\n\t\tqp->sq_get++;\n\t}\n\tif (async_event)\n\t\tsiw_qp_event(qp, IB_EVENT_SQ_DRAINED);\n}\n\n \nvoid siw_rq_flush(struct siw_qp *qp)\n{\n\tstruct siw_wqe *wqe = &qp->rx_untagged.wqe_active;\n\n\t \n\tif (wqe->wr_status != SIW_WR_IDLE) {\n\t\tsiw_dbg_qp(qp, \"flush current rqe, type %d, status %d\\n\",\n\t\t\t   rx_type(wqe), wqe->wr_status);\n\n\t\tsiw_wqe_put_mem(wqe, rx_type(wqe));\n\n\t\tif (rx_type(wqe) == SIW_OP_RECEIVE) {\n\t\t\tsiw_rqe_complete(qp, &wqe->rqe, wqe->bytes,\n\t\t\t\t\t 0, SIW_WC_WR_FLUSH_ERR);\n\t\t} else if (rx_type(wqe) != SIW_OP_READ &&\n\t\t\t   rx_type(wqe) != SIW_OP_READ_RESPONSE &&\n\t\t\t   rx_type(wqe) != SIW_OP_WRITE) {\n\t\t\tsiw_sqe_complete(qp, &wqe->sqe, 0, SIW_WC_WR_FLUSH_ERR);\n\t\t}\n\t\twqe->wr_status = SIW_WR_IDLE;\n\t}\n\twqe = &qp->rx_tagged.wqe_active;\n\n\tif (wqe->wr_status != SIW_WR_IDLE) {\n\t\tsiw_wqe_put_mem(wqe, rx_type(wqe));\n\t\twqe->wr_status = SIW_WR_IDLE;\n\t}\n\t \n\twhile (qp->attrs.rq_size) {\n\t\tstruct siw_rqe *rqe =\n\t\t\t&qp->recvq[qp->rq_get % qp->attrs.rq_size];\n\n\t\tif (!READ_ONCE(rqe->flags))\n\t\t\tbreak;\n\n\t\tif (siw_rqe_complete(qp, rqe, 0, 0, SIW_WC_WR_FLUSH_ERR) != 0)\n\t\t\tbreak;\n\n\t\tWRITE_ONCE(rqe->flags, 0);\n\t\tqp->rq_get++;\n\t}\n}\n\nint siw_qp_add(struct siw_device *sdev, struct siw_qp *qp)\n{\n\tint rv = xa_alloc(&sdev->qp_xa, &qp->base_qp.qp_num, qp, xa_limit_32b,\n\t\t\t  GFP_KERNEL);\n\n\tif (!rv) {\n\t\tkref_init(&qp->ref);\n\t\tqp->sdev = sdev;\n\t\tsiw_dbg_qp(qp, \"new QP\\n\");\n\t}\n\treturn rv;\n}\n\nvoid siw_free_qp(struct kref *ref)\n{\n\tstruct siw_qp *found, *qp = container_of(ref, struct siw_qp, ref);\n\tstruct siw_device *sdev = qp->sdev;\n\tunsigned long flags;\n\n\tif (qp->cep)\n\t\tsiw_cep_put(qp->cep);\n\n\tfound = xa_erase(&sdev->qp_xa, qp_id(qp));\n\tWARN_ON(found != qp);\n\tspin_lock_irqsave(&sdev->lock, flags);\n\tlist_del(&qp->devq);\n\tspin_unlock_irqrestore(&sdev->lock, flags);\n\n\tvfree(qp->sendq);\n\tvfree(qp->recvq);\n\tvfree(qp->irq);\n\tvfree(qp->orq);\n\n\tsiw_put_tx_cpu(qp->tx_cpu);\n\tcomplete(&qp->qp_free);\n\tatomic_dec(&sdev->num_qp);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}