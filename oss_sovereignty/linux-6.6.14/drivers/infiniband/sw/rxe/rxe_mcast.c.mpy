{
  "module_name": "rxe_mcast.c",
  "hash_id": "cbc88f89284097020fd42cbf45ba0378e5060aeefe6e67c54dabebd95818ab61",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/sw/rxe/rxe_mcast.c",
  "human_readable_source": "\n \n\n \n\n#include \"rxe.h\"\n\n \nstatic int rxe_mcast_add(struct rxe_dev *rxe, union ib_gid *mgid)\n{\n\tunsigned char ll_addr[ETH_ALEN];\n\n\tipv6_eth_mc_map((struct in6_addr *)mgid->raw, ll_addr);\n\n\treturn dev_mc_add(rxe->ndev, ll_addr);\n}\n\n \nstatic int rxe_mcast_del(struct rxe_dev *rxe, union ib_gid *mgid)\n{\n\tunsigned char ll_addr[ETH_ALEN];\n\n\tipv6_eth_mc_map((struct in6_addr *)mgid->raw, ll_addr);\n\n\treturn dev_mc_del(rxe->ndev, ll_addr);\n}\n\n \nstatic void __rxe_insert_mcg(struct rxe_mcg *mcg)\n{\n\tstruct rb_root *tree = &mcg->rxe->mcg_tree;\n\tstruct rb_node **link = &tree->rb_node;\n\tstruct rb_node *node = NULL;\n\tstruct rxe_mcg *tmp;\n\tint cmp;\n\n\twhile (*link) {\n\t\tnode = *link;\n\t\ttmp = rb_entry(node, struct rxe_mcg, node);\n\n\t\tcmp = memcmp(&tmp->mgid, &mcg->mgid, sizeof(mcg->mgid));\n\t\tif (cmp > 0)\n\t\t\tlink = &(*link)->rb_left;\n\t\telse\n\t\t\tlink = &(*link)->rb_right;\n\t}\n\n\trb_link_node(&mcg->node, node, link);\n\trb_insert_color(&mcg->node, tree);\n}\n\n \nstatic void __rxe_remove_mcg(struct rxe_mcg *mcg)\n{\n\trb_erase(&mcg->node, &mcg->rxe->mcg_tree);\n}\n\n \nstatic struct rxe_mcg *__rxe_lookup_mcg(struct rxe_dev *rxe,\n\t\t\t\t\tunion ib_gid *mgid)\n{\n\tstruct rb_root *tree = &rxe->mcg_tree;\n\tstruct rxe_mcg *mcg;\n\tstruct rb_node *node;\n\tint cmp;\n\n\tnode = tree->rb_node;\n\n\twhile (node) {\n\t\tmcg = rb_entry(node, struct rxe_mcg, node);\n\n\t\tcmp = memcmp(&mcg->mgid, mgid, sizeof(*mgid));\n\n\t\tif (cmp > 0)\n\t\t\tnode = node->rb_left;\n\t\telse if (cmp < 0)\n\t\t\tnode = node->rb_right;\n\t\telse\n\t\t\tbreak;\n\t}\n\n\tif (node) {\n\t\tkref_get(&mcg->ref_cnt);\n\t\treturn mcg;\n\t}\n\n\treturn NULL;\n}\n\n \nstruct rxe_mcg *rxe_lookup_mcg(struct rxe_dev *rxe, union ib_gid *mgid)\n{\n\tstruct rxe_mcg *mcg;\n\n\tspin_lock_bh(&rxe->mcg_lock);\n\tmcg = __rxe_lookup_mcg(rxe, mgid);\n\tspin_unlock_bh(&rxe->mcg_lock);\n\n\treturn mcg;\n}\n\n \nstatic void __rxe_init_mcg(struct rxe_dev *rxe, union ib_gid *mgid,\n\t\t\t   struct rxe_mcg *mcg)\n{\n\tkref_init(&mcg->ref_cnt);\n\tmemcpy(&mcg->mgid, mgid, sizeof(mcg->mgid));\n\tINIT_LIST_HEAD(&mcg->qp_list);\n\tmcg->rxe = rxe;\n\n\t \n\tkref_get(&mcg->ref_cnt);\n\t__rxe_insert_mcg(mcg);\n}\n\n \nstatic struct rxe_mcg *rxe_get_mcg(struct rxe_dev *rxe, union ib_gid *mgid)\n{\n\tstruct rxe_mcg *mcg, *tmp;\n\tint err;\n\n\tif (rxe->attr.max_mcast_grp == 0)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t \n\tmcg = rxe_lookup_mcg(rxe, mgid);\n\tif (mcg)\n\t\treturn mcg;\n\n\t \n\tif (atomic_inc_return(&rxe->mcg_num) > rxe->attr.max_mcast_grp) {\n\t\terr = -ENOMEM;\n\t\tgoto err_dec;\n\t}\n\n\t \n\tmcg = kzalloc(sizeof(*mcg), GFP_KERNEL);\n\tif (!mcg) {\n\t\terr = -ENOMEM;\n\t\tgoto err_dec;\n\t}\n\n\tspin_lock_bh(&rxe->mcg_lock);\n\t \n\ttmp = __rxe_lookup_mcg(rxe, mgid);\n\tif (tmp) {\n\t\tspin_unlock_bh(&rxe->mcg_lock);\n\t\tatomic_dec(&rxe->mcg_num);\n\t\tkfree(mcg);\n\t\treturn tmp;\n\t}\n\n\t__rxe_init_mcg(rxe, mgid, mcg);\n\tspin_unlock_bh(&rxe->mcg_lock);\n\n\t \n\terr = rxe_mcast_add(rxe, mgid);\n\tif (!err)\n\t\treturn mcg;\n\n\tkfree(mcg);\nerr_dec:\n\tatomic_dec(&rxe->mcg_num);\n\treturn ERR_PTR(err);\n}\n\n \nvoid rxe_cleanup_mcg(struct kref *kref)\n{\n\tstruct rxe_mcg *mcg = container_of(kref, typeof(*mcg), ref_cnt);\n\n\tkfree(mcg);\n}\n\n \nstatic void __rxe_destroy_mcg(struct rxe_mcg *mcg)\n{\n\tstruct rxe_dev *rxe = mcg->rxe;\n\n\t \n\t__rxe_remove_mcg(mcg);\n\tkref_put(&mcg->ref_cnt, rxe_cleanup_mcg);\n\n\tatomic_dec(&rxe->mcg_num);\n}\n\n \nstatic void rxe_destroy_mcg(struct rxe_mcg *mcg)\n{\n\t \n\trxe_mcast_del(mcg->rxe, &mcg->mgid);\n\n\tspin_lock_bh(&mcg->rxe->mcg_lock);\n\t__rxe_destroy_mcg(mcg);\n\tspin_unlock_bh(&mcg->rxe->mcg_lock);\n}\n\n \nstatic int __rxe_init_mca(struct rxe_qp *qp, struct rxe_mcg *mcg,\n\t\t\t  struct rxe_mca *mca)\n{\n\tstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\n\tint n;\n\n\tn = atomic_inc_return(&rxe->mcg_attach);\n\tif (n > rxe->attr.max_total_mcast_qp_attach) {\n\t\tatomic_dec(&rxe->mcg_attach);\n\t\treturn -ENOMEM;\n\t}\n\n\tn = atomic_inc_return(&mcg->qp_num);\n\tif (n > rxe->attr.max_mcast_qp_attach) {\n\t\tatomic_dec(&mcg->qp_num);\n\t\tatomic_dec(&rxe->mcg_attach);\n\t\treturn -ENOMEM;\n\t}\n\n\tatomic_inc(&qp->mcg_num);\n\n\trxe_get(qp);\n\tmca->qp = qp;\n\n\tlist_add_tail(&mca->qp_list, &mcg->qp_list);\n\n\treturn 0;\n}\n\n \nstatic int rxe_attach_mcg(struct rxe_mcg *mcg, struct rxe_qp *qp)\n{\n\tstruct rxe_dev *rxe = mcg->rxe;\n\tstruct rxe_mca *mca, *tmp;\n\tint err;\n\n\t \n\tspin_lock_bh(&rxe->mcg_lock);\n\tlist_for_each_entry(mca, &mcg->qp_list, qp_list) {\n\t\tif (mca->qp == qp) {\n\t\t\tspin_unlock_bh(&rxe->mcg_lock);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tspin_unlock_bh(&rxe->mcg_lock);\n\n\t \n\tmca = kzalloc(sizeof(*mca), GFP_KERNEL);\n\tif (!mca)\n\t\treturn -ENOMEM;\n\n\tspin_lock_bh(&rxe->mcg_lock);\n\t \n\tlist_for_each_entry(tmp, &mcg->qp_list, qp_list) {\n\t\tif (tmp->qp == qp) {\n\t\t\tkfree(mca);\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\terr = __rxe_init_mca(qp, mcg, mca);\n\tif (err)\n\t\tkfree(mca);\nout:\n\tspin_unlock_bh(&rxe->mcg_lock);\n\treturn err;\n}\n\n \nstatic void __rxe_cleanup_mca(struct rxe_mca *mca, struct rxe_mcg *mcg)\n{\n\tlist_del(&mca->qp_list);\n\n\tatomic_dec(&mcg->qp_num);\n\tatomic_dec(&mcg->rxe->mcg_attach);\n\tatomic_dec(&mca->qp->mcg_num);\n\trxe_put(mca->qp);\n\n\tkfree(mca);\n}\n\n \nstatic int rxe_detach_mcg(struct rxe_mcg *mcg, struct rxe_qp *qp)\n{\n\tstruct rxe_dev *rxe = mcg->rxe;\n\tstruct rxe_mca *mca, *tmp;\n\n\tspin_lock_bh(&rxe->mcg_lock);\n\tlist_for_each_entry_safe(mca, tmp, &mcg->qp_list, qp_list) {\n\t\tif (mca->qp == qp) {\n\t\t\t__rxe_cleanup_mca(mca, mcg);\n\n\t\t\t \n\t\t\tif (atomic_read(&mcg->qp_num) <= 0)\n\t\t\t\t__rxe_destroy_mcg(mcg);\n\n\t\t\tspin_unlock_bh(&rxe->mcg_lock);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\tspin_unlock_bh(&rxe->mcg_lock);\n\treturn -EINVAL;\n}\n\n \nint rxe_attach_mcast(struct ib_qp *ibqp, union ib_gid *mgid, u16 mlid)\n{\n\tint err;\n\tstruct rxe_dev *rxe = to_rdev(ibqp->device);\n\tstruct rxe_qp *qp = to_rqp(ibqp);\n\tstruct rxe_mcg *mcg;\n\n\t \n\tmcg = rxe_get_mcg(rxe, mgid);\n\tif (IS_ERR(mcg))\n\t\treturn PTR_ERR(mcg);\n\n\terr = rxe_attach_mcg(mcg, qp);\n\n\t \n\tif (atomic_read(&mcg->qp_num) == 0)\n\t\trxe_destroy_mcg(mcg);\n\n\tkref_put(&mcg->ref_cnt, rxe_cleanup_mcg);\n\n\treturn err;\n}\n\n \nint rxe_detach_mcast(struct ib_qp *ibqp, union ib_gid *mgid, u16 mlid)\n{\n\tstruct rxe_dev *rxe = to_rdev(ibqp->device);\n\tstruct rxe_qp *qp = to_rqp(ibqp);\n\tstruct rxe_mcg *mcg;\n\tint err;\n\n\tmcg = rxe_lookup_mcg(rxe, mgid);\n\tif (!mcg)\n\t\treturn -EINVAL;\n\n\terr = rxe_detach_mcg(mcg, qp);\n\tkref_put(&mcg->ref_cnt, rxe_cleanup_mcg);\n\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}