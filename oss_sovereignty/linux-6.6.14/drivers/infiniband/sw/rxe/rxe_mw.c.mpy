{
  "module_name": "rxe_mw.c",
  "hash_id": "48574dd7eb64aefd30bce49cc4a53b40470a0fa216a235f98383248ffc8af62e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/sw/rxe/rxe_mw.c",
  "human_readable_source": "\n \n\n \n\n#include \"rxe.h\"\n\nint rxe_alloc_mw(struct ib_mw *ibmw, struct ib_udata *udata)\n{\n\tstruct rxe_mw *mw = to_rmw(ibmw);\n\tstruct rxe_pd *pd = to_rpd(ibmw->pd);\n\tstruct rxe_dev *rxe = to_rdev(ibmw->device);\n\tint ret;\n\n\trxe_get(pd);\n\n\tret = rxe_add_to_pool(&rxe->mw_pool, mw);\n\tif (ret) {\n\t\trxe_put(pd);\n\t\treturn ret;\n\t}\n\n\tmw->rkey = ibmw->rkey = (mw->elem.index << 8) | rxe_get_next_key(-1);\n\tmw->state = (mw->ibmw.type == IB_MW_TYPE_2) ?\n\t\t\tRXE_MW_STATE_FREE : RXE_MW_STATE_VALID;\n\tspin_lock_init(&mw->lock);\n\n\trxe_finalize(mw);\n\n\treturn 0;\n}\n\nint rxe_dealloc_mw(struct ib_mw *ibmw)\n{\n\tstruct rxe_mw *mw = to_rmw(ibmw);\n\n\trxe_cleanup(mw);\n\n\treturn 0;\n}\n\nstatic int rxe_check_bind_mw(struct rxe_qp *qp, struct rxe_send_wqe *wqe,\n\t\t\t struct rxe_mw *mw, struct rxe_mr *mr, int access)\n{\n\tif (mw->ibmw.type == IB_MW_TYPE_1) {\n\t\tif (unlikely(mw->state != RXE_MW_STATE_VALID)) {\n\t\t\trxe_dbg_mw(mw,\n\t\t\t\t\"attempt to bind a type 1 MW not in the valid state\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (unlikely((access & IB_ZERO_BASED))) {\n\t\t\trxe_dbg_mw(mw, \"attempt to bind a zero based type 1 MW\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (mw->ibmw.type == IB_MW_TYPE_2) {\n\t\t \n\t\tif (unlikely(mw->state != RXE_MW_STATE_FREE)) {\n\t\t\trxe_dbg_mw(mw,\n\t\t\t\t\"attempt to bind a type 2 MW not in the free state\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (unlikely(qp->pd != to_rpd(mw->ibmw.pd))) {\n\t\t\trxe_dbg_mw(mw,\n\t\t\t\t\"attempt to bind type 2 MW with qp with different PD\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (unlikely(!mr || wqe->wr.wr.mw.length == 0)) {\n\t\t\trxe_dbg_mw(mw,\n\t\t\t\t\"attempt to invalidate type 2 MW by binding with NULL or zero length MR\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t \n\tif (!mr)\n\t\treturn 0;\n\n\tif (unlikely(mr->access & IB_ZERO_BASED)) {\n\t\trxe_dbg_mw(mw, \"attempt to bind MW to zero based MR\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (unlikely(!(mr->access & IB_ACCESS_MW_BIND))) {\n\t\trxe_dbg_mw(mw,\n\t\t\t\"attempt to bind an MW to an MR without bind access\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (unlikely((access &\n\t\t      (IB_ACCESS_REMOTE_WRITE | IB_ACCESS_REMOTE_ATOMIC)) &&\n\t\t     !(mr->access & IB_ACCESS_LOCAL_WRITE))) {\n\t\trxe_dbg_mw(mw,\n\t\t\t\"attempt to bind an Writable MW to an MR without local write access\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (access & IB_ZERO_BASED) {\n\t\tif (unlikely(wqe->wr.wr.mw.length > mr->ibmr.length)) {\n\t\t\trxe_dbg_mw(mw,\n\t\t\t\t\"attempt to bind a ZB MW outside of the MR\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tif (unlikely((wqe->wr.wr.mw.addr < mr->ibmr.iova) ||\n\t\t\t     ((wqe->wr.wr.mw.addr + wqe->wr.wr.mw.length) >\n\t\t\t      (mr->ibmr.iova + mr->ibmr.length)))) {\n\t\t\trxe_dbg_mw(mw,\n\t\t\t\t\"attempt to bind a VA MW outside of the MR\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void rxe_do_bind_mw(struct rxe_qp *qp, struct rxe_send_wqe *wqe,\n\t\t      struct rxe_mw *mw, struct rxe_mr *mr, int access)\n{\n\tu32 key = wqe->wr.wr.mw.rkey & 0xff;\n\n\tmw->rkey = (mw->rkey & ~0xff) | key;\n\tmw->access = access;\n\tmw->state = RXE_MW_STATE_VALID;\n\tmw->addr = wqe->wr.wr.mw.addr;\n\tmw->length = wqe->wr.wr.mw.length;\n\n\tif (mw->mr) {\n\t\trxe_put(mw->mr);\n\t\tatomic_dec(&mw->mr->num_mw);\n\t\tmw->mr = NULL;\n\t}\n\n\tif (mw->length) {\n\t\tmw->mr = mr;\n\t\tatomic_inc(&mr->num_mw);\n\t\trxe_get(mr);\n\t}\n\n\tif (mw->ibmw.type == IB_MW_TYPE_2) {\n\t\trxe_get(qp);\n\t\tmw->qp = qp;\n\t}\n}\n\nint rxe_bind_mw(struct rxe_qp *qp, struct rxe_send_wqe *wqe)\n{\n\tint ret;\n\tstruct rxe_mw *mw;\n\tstruct rxe_mr *mr;\n\tstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\n\tu32 mw_rkey = wqe->wr.wr.mw.mw_rkey;\n\tu32 mr_lkey = wqe->wr.wr.mw.mr_lkey;\n\tint access = wqe->wr.wr.mw.access;\n\n\tmw = rxe_pool_get_index(&rxe->mw_pool, mw_rkey >> 8);\n\tif (unlikely(!mw)) {\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tif (unlikely(mw->rkey != mw_rkey)) {\n\t\tret = -EINVAL;\n\t\tgoto err_drop_mw;\n\t}\n\n\tif (likely(wqe->wr.wr.mw.length)) {\n\t\tmr = rxe_pool_get_index(&rxe->mr_pool, mr_lkey >> 8);\n\t\tif (unlikely(!mr)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_drop_mw;\n\t\t}\n\n\t\tif (unlikely(mr->lkey != mr_lkey)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_drop_mr;\n\t\t}\n\t} else {\n\t\tmr = NULL;\n\t}\n\n\tif (access & ~RXE_ACCESS_SUPPORTED_MW) {\n\t\trxe_err_mw(mw, \"access %#x not supported\", access);\n\t\tret = -EOPNOTSUPP;\n\t\tgoto err_drop_mr;\n\t}\n\n\tspin_lock_bh(&mw->lock);\n\n\tret = rxe_check_bind_mw(qp, wqe, mw, mr, access);\n\tif (ret)\n\t\tgoto err_unlock;\n\n\trxe_do_bind_mw(qp, wqe, mw, mr, access);\nerr_unlock:\n\tspin_unlock_bh(&mw->lock);\nerr_drop_mr:\n\tif (mr)\n\t\trxe_put(mr);\nerr_drop_mw:\n\trxe_put(mw);\nerr:\n\treturn ret;\n}\n\nstatic int rxe_check_invalidate_mw(struct rxe_qp *qp, struct rxe_mw *mw)\n{\n\tif (unlikely(mw->state == RXE_MW_STATE_INVALID))\n\t\treturn -EINVAL;\n\n\t \n\tif (unlikely(mw->ibmw.type == IB_MW_TYPE_1))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic void rxe_do_invalidate_mw(struct rxe_mw *mw)\n{\n\tstruct rxe_qp *qp;\n\tstruct rxe_mr *mr;\n\n\t \n\tqp = mw->qp;\n\tmw->qp = NULL;\n\trxe_put(qp);\n\n\t \n\tmr = mw->mr;\n\tmw->mr = NULL;\n\tatomic_dec(&mr->num_mw);\n\trxe_put(mr);\n\n\tmw->access = 0;\n\tmw->addr = 0;\n\tmw->length = 0;\n\tmw->state = RXE_MW_STATE_FREE;\n}\n\nint rxe_invalidate_mw(struct rxe_qp *qp, u32 rkey)\n{\n\tstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\n\tstruct rxe_mw *mw;\n\tint ret;\n\n\tmw = rxe_pool_get_index(&rxe->mw_pool, rkey >> 8);\n\tif (!mw) {\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tif (rkey != mw->rkey) {\n\t\tret = -EINVAL;\n\t\tgoto err_drop_ref;\n\t}\n\n\tspin_lock_bh(&mw->lock);\n\n\tret = rxe_check_invalidate_mw(qp, mw);\n\tif (ret)\n\t\tgoto err_unlock;\n\n\trxe_do_invalidate_mw(mw);\nerr_unlock:\n\tspin_unlock_bh(&mw->lock);\nerr_drop_ref:\n\trxe_put(mw);\nerr:\n\treturn ret;\n}\n\nstruct rxe_mw *rxe_lookup_mw(struct rxe_qp *qp, int access, u32 rkey)\n{\n\tstruct rxe_dev *rxe = to_rdev(qp->ibqp.device);\n\tstruct rxe_pd *pd = to_rpd(qp->ibqp.pd);\n\tstruct rxe_mw *mw;\n\tint index = rkey >> 8;\n\n\tmw = rxe_pool_get_index(&rxe->mw_pool, index);\n\tif (!mw)\n\t\treturn NULL;\n\n\tif (unlikely((mw->rkey != rkey) || rxe_mw_pd(mw) != pd ||\n\t\t     (mw->ibmw.type == IB_MW_TYPE_2 && mw->qp != qp) ||\n\t\t     (mw->length == 0) || ((access & mw->access) != access) ||\n\t\t     mw->state != RXE_MW_STATE_VALID)) {\n\t\trxe_put(mw);\n\t\treturn NULL;\n\t}\n\n\treturn mw;\n}\n\nvoid rxe_mw_cleanup(struct rxe_pool_elem *elem)\n{\n\tstruct rxe_mw *mw = container_of(elem, typeof(*mw), elem);\n\tstruct rxe_pd *pd = to_rpd(mw->ibmw.pd);\n\n\trxe_put(pd);\n\n\tif (mw->mr) {\n\t\tstruct rxe_mr *mr = mw->mr;\n\n\t\tmw->mr = NULL;\n\t\tatomic_dec(&mr->num_mw);\n\t\trxe_put(mr);\n\t}\n\n\tif (mw->qp) {\n\t\tstruct rxe_qp *qp = mw->qp;\n\n\t\tmw->qp = NULL;\n\t\trxe_put(qp);\n\t}\n\n\tmw->access = 0;\n\tmw->addr = 0;\n\tmw->length = 0;\n\tmw->state = RXE_MW_STATE_INVALID;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}