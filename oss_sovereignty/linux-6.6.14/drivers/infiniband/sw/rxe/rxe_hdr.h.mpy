{
  "module_name": "rxe_hdr.h",
  "hash_id": "fd03c6873374093b69298671a12db68cbac9524818087d97331c7d7fc4c6d981",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/sw/rxe/rxe_hdr.h",
  "human_readable_source": " \n \n\n#ifndef RXE_HDR_H\n#define RXE_HDR_H\n\n \nstruct rxe_pkt_info {\n\tstruct rxe_dev\t\t*rxe;\t\t \n\tstruct rxe_qp\t\t*qp;\t\t \n\tstruct rxe_send_wqe\t*wqe;\t\t \n\tu8\t\t\t*hdr;\t\t \n\tu32\t\t\tmask;\t\t \n\tu32\t\t\tpsn;\t\t \n\tu16\t\t\tpkey_index;\t \n\tu16\t\t\tpaylen;\t\t \n\tu8\t\t\tport_num;\t \n\tu8\t\t\topcode;\t\t \n};\n\n \nstatic inline struct rxe_pkt_info *SKB_TO_PKT(struct sk_buff *skb)\n{\n\tBUILD_BUG_ON(sizeof(struct rxe_pkt_info) > sizeof(skb->cb));\n\treturn (void *)skb->cb;\n}\n\nstatic inline struct sk_buff *PKT_TO_SKB(struct rxe_pkt_info *pkt)\n{\n\treturn container_of((void *)pkt, struct sk_buff, cb);\n}\n\n \n\n#define RXE_ICRC_SIZE\t\t(4)\n#define RXE_MAX_HDR_LENGTH\t(80)\n\n \nstruct rxe_bth {\n\tu8\t\t\topcode;\n\tu8\t\t\tflags;\n\t__be16\t\t\tpkey;\n\t__be32\t\t\tqpn;\n\t__be32\t\t\tapsn;\n};\n\n#define BTH_TVER\t\t(0)\n#define BTH_DEF_PKEY\t\t(0xffff)\n\n#define BTH_SE_MASK\t\t(0x80)\n#define BTH_MIG_MASK\t\t(0x40)\n#define BTH_PAD_MASK\t\t(0x30)\n#define BTH_TVER_MASK\t\t(0x0f)\n#define BTH_FECN_MASK\t\t(0x80000000)\n#define BTH_BECN_MASK\t\t(0x40000000)\n#define BTH_RESV6A_MASK\t\t(0x3f000000)\n#define BTH_QPN_MASK\t\t(0x00ffffff)\n#define BTH_ACK_MASK\t\t(0x80000000)\n#define BTH_RESV7_MASK\t\t(0x7f000000)\n#define BTH_PSN_MASK\t\t(0x00ffffff)\n\nstatic inline u8 __bth_opcode(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn bth->opcode;\n}\n\nstatic inline void __bth_set_opcode(void *arg, u8 opcode)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tbth->opcode = opcode;\n}\n\nstatic inline u8 __bth_se(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn 0 != (BTH_SE_MASK & bth->flags);\n}\n\nstatic inline void __bth_set_se(void *arg, int se)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tif (se)\n\t\tbth->flags |= BTH_SE_MASK;\n\telse\n\t\tbth->flags &= ~BTH_SE_MASK;\n}\n\nstatic inline u8 __bth_mig(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn 0 != (BTH_MIG_MASK & bth->flags);\n}\n\nstatic inline void __bth_set_mig(void *arg, u8 mig)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tif (mig)\n\t\tbth->flags |= BTH_MIG_MASK;\n\telse\n\t\tbth->flags &= ~BTH_MIG_MASK;\n}\n\nstatic inline u8 __bth_pad(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn (BTH_PAD_MASK & bth->flags) >> 4;\n}\n\nstatic inline void __bth_set_pad(void *arg, u8 pad)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tbth->flags = (BTH_PAD_MASK & (pad << 4)) |\n\t\t\t(~BTH_PAD_MASK & bth->flags);\n}\n\nstatic inline u8 __bth_tver(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn BTH_TVER_MASK & bth->flags;\n}\n\nstatic inline void __bth_set_tver(void *arg, u8 tver)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tbth->flags = (BTH_TVER_MASK & tver) |\n\t\t\t(~BTH_TVER_MASK & bth->flags);\n}\n\nstatic inline u16 __bth_pkey(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn be16_to_cpu(bth->pkey);\n}\n\nstatic inline void __bth_set_pkey(void *arg, u16 pkey)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tbth->pkey = cpu_to_be16(pkey);\n}\n\nstatic inline u32 __bth_qpn(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn BTH_QPN_MASK & be32_to_cpu(bth->qpn);\n}\n\nstatic inline void __bth_set_qpn(void *arg, u32 qpn)\n{\n\tstruct rxe_bth *bth = arg;\n\tu32 resvqpn = be32_to_cpu(bth->qpn);\n\n\tbth->qpn = cpu_to_be32((BTH_QPN_MASK & qpn) |\n\t\t\t       (~BTH_QPN_MASK & resvqpn));\n}\n\nstatic inline int __bth_fecn(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn 0 != (cpu_to_be32(BTH_FECN_MASK) & bth->qpn);\n}\n\nstatic inline void __bth_set_fecn(void *arg, int fecn)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tif (fecn)\n\t\tbth->qpn |= cpu_to_be32(BTH_FECN_MASK);\n\telse\n\t\tbth->qpn &= ~cpu_to_be32(BTH_FECN_MASK);\n}\n\nstatic inline int __bth_becn(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn 0 != (cpu_to_be32(BTH_BECN_MASK) & bth->qpn);\n}\n\nstatic inline void __bth_set_becn(void *arg, int becn)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tif (becn)\n\t\tbth->qpn |= cpu_to_be32(BTH_BECN_MASK);\n\telse\n\t\tbth->qpn &= ~cpu_to_be32(BTH_BECN_MASK);\n}\n\nstatic inline u8 __bth_resv6a(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn (BTH_RESV6A_MASK & be32_to_cpu(bth->qpn)) >> 24;\n}\n\nstatic inline void __bth_set_resv6a(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tbth->qpn = cpu_to_be32(~BTH_RESV6A_MASK);\n}\n\nstatic inline int __bth_ack(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn 0 != (cpu_to_be32(BTH_ACK_MASK) & bth->apsn);\n}\n\nstatic inline void __bth_set_ack(void *arg, int ack)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tif (ack)\n\t\tbth->apsn |= cpu_to_be32(BTH_ACK_MASK);\n\telse\n\t\tbth->apsn &= ~cpu_to_be32(BTH_ACK_MASK);\n}\n\nstatic inline void __bth_set_resv7(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\tbth->apsn &= ~cpu_to_be32(BTH_RESV7_MASK);\n}\n\nstatic inline u32 __bth_psn(void *arg)\n{\n\tstruct rxe_bth *bth = arg;\n\n\treturn BTH_PSN_MASK & be32_to_cpu(bth->apsn);\n}\n\nstatic inline void __bth_set_psn(void *arg, u32 psn)\n{\n\tstruct rxe_bth *bth = arg;\n\tu32 apsn = be32_to_cpu(bth->apsn);\n\n\tbth->apsn = cpu_to_be32((BTH_PSN_MASK & psn) |\n\t\t\t(~BTH_PSN_MASK & apsn));\n}\n\nstatic inline u8 bth_opcode(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_opcode(pkt->hdr);\n}\n\nstatic inline void bth_set_opcode(struct rxe_pkt_info *pkt, u8 opcode)\n{\n\t__bth_set_opcode(pkt->hdr, opcode);\n}\n\nstatic inline u8 bth_se(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_se(pkt->hdr);\n}\n\nstatic inline void bth_set_se(struct rxe_pkt_info *pkt, int se)\n{\n\t__bth_set_se(pkt->hdr, se);\n}\n\nstatic inline u8 bth_mig(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_mig(pkt->hdr);\n}\n\nstatic inline void bth_set_mig(struct rxe_pkt_info *pkt, u8 mig)\n{\n\t__bth_set_mig(pkt->hdr, mig);\n}\n\nstatic inline u8 bth_pad(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_pad(pkt->hdr);\n}\n\nstatic inline void bth_set_pad(struct rxe_pkt_info *pkt, u8 pad)\n{\n\t__bth_set_pad(pkt->hdr, pad);\n}\n\nstatic inline u8 bth_tver(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_tver(pkt->hdr);\n}\n\nstatic inline void bth_set_tver(struct rxe_pkt_info *pkt, u8 tver)\n{\n\t__bth_set_tver(pkt->hdr, tver);\n}\n\nstatic inline u16 bth_pkey(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_pkey(pkt->hdr);\n}\n\nstatic inline void bth_set_pkey(struct rxe_pkt_info *pkt, u16 pkey)\n{\n\t__bth_set_pkey(pkt->hdr, pkey);\n}\n\nstatic inline u32 bth_qpn(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_qpn(pkt->hdr);\n}\n\nstatic inline void bth_set_qpn(struct rxe_pkt_info *pkt, u32 qpn)\n{\n\t__bth_set_qpn(pkt->hdr, qpn);\n}\n\nstatic inline int bth_fecn(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_fecn(pkt->hdr);\n}\n\nstatic inline void bth_set_fecn(struct rxe_pkt_info *pkt, int fecn)\n{\n\t__bth_set_fecn(pkt->hdr, fecn);\n}\n\nstatic inline int bth_becn(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_becn(pkt->hdr);\n}\n\nstatic inline void bth_set_becn(struct rxe_pkt_info *pkt, int becn)\n{\n\t__bth_set_becn(pkt->hdr, becn);\n}\n\nstatic inline u8 bth_resv6a(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_resv6a(pkt->hdr);\n}\n\nstatic inline void bth_set_resv6a(struct rxe_pkt_info *pkt)\n{\n\t__bth_set_resv6a(pkt->hdr);\n}\n\nstatic inline int bth_ack(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_ack(pkt->hdr);\n}\n\nstatic inline void bth_set_ack(struct rxe_pkt_info *pkt, int ack)\n{\n\t__bth_set_ack(pkt->hdr, ack);\n}\n\nstatic inline void bth_set_resv7(struct rxe_pkt_info *pkt)\n{\n\t__bth_set_resv7(pkt->hdr);\n}\n\nstatic inline u32 bth_psn(struct rxe_pkt_info *pkt)\n{\n\treturn __bth_psn(pkt->hdr);\n}\n\nstatic inline void bth_set_psn(struct rxe_pkt_info *pkt, u32 psn)\n{\n\t__bth_set_psn(pkt->hdr, psn);\n}\n\nstatic inline void bth_init(struct rxe_pkt_info *pkt, u8 opcode, int se,\n\t\t\t    int mig, int pad, u16 pkey, u32 qpn, int ack_req,\n\t\t\t    u32 psn)\n{\n\tstruct rxe_bth *bth = (struct rxe_bth *)(pkt->hdr);\n\n\tbth->opcode = opcode;\n\tbth->flags = (pad << 4) & BTH_PAD_MASK;\n\tif (se)\n\t\tbth->flags |= BTH_SE_MASK;\n\tif (mig)\n\t\tbth->flags |= BTH_MIG_MASK;\n\tbth->pkey = cpu_to_be16(pkey);\n\tbth->qpn = cpu_to_be32(qpn & BTH_QPN_MASK);\n\tpsn &= BTH_PSN_MASK;\n\tif (ack_req)\n\t\tpsn |= BTH_ACK_MASK;\n\tbth->apsn = cpu_to_be32(psn);\n}\n\n \nstruct rxe_rdeth {\n\t__be32\t\t\teen;\n};\n\n#define RDETH_EEN_MASK\t\t(0x00ffffff)\n\nstatic inline u8 __rdeth_een(void *arg)\n{\n\tstruct rxe_rdeth *rdeth = arg;\n\n\treturn RDETH_EEN_MASK & be32_to_cpu(rdeth->een);\n}\n\nstatic inline void __rdeth_set_een(void *arg, u32 een)\n{\n\tstruct rxe_rdeth *rdeth = arg;\n\n\trdeth->een = cpu_to_be32(RDETH_EEN_MASK & een);\n}\n\nstatic inline u8 rdeth_een(struct rxe_pkt_info *pkt)\n{\n\treturn __rdeth_een(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RDETH]);\n}\n\nstatic inline void rdeth_set_een(struct rxe_pkt_info *pkt, u32 een)\n{\n\t__rdeth_set_een(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RDETH], een);\n}\n\n \nstruct rxe_deth {\n\t__be32\t\t\tqkey;\n\t__be32\t\t\tsqp;\n};\n\n#define GSI_QKEY\t\t(0x80010000)\n#define DETH_SQP_MASK\t\t(0x00ffffff)\n\nstatic inline u32 __deth_qkey(void *arg)\n{\n\tstruct rxe_deth *deth = arg;\n\n\treturn be32_to_cpu(deth->qkey);\n}\n\nstatic inline void __deth_set_qkey(void *arg, u32 qkey)\n{\n\tstruct rxe_deth *deth = arg;\n\n\tdeth->qkey = cpu_to_be32(qkey);\n}\n\nstatic inline u32 __deth_sqp(void *arg)\n{\n\tstruct rxe_deth *deth = arg;\n\n\treturn DETH_SQP_MASK & be32_to_cpu(deth->sqp);\n}\n\nstatic inline void __deth_set_sqp(void *arg, u32 sqp)\n{\n\tstruct rxe_deth *deth = arg;\n\n\tdeth->sqp = cpu_to_be32(DETH_SQP_MASK & sqp);\n}\n\nstatic inline u32 deth_qkey(struct rxe_pkt_info *pkt)\n{\n\treturn __deth_qkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_DETH]);\n}\n\nstatic inline void deth_set_qkey(struct rxe_pkt_info *pkt, u32 qkey)\n{\n\t__deth_set_qkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_DETH], qkey);\n}\n\nstatic inline u32 deth_sqp(struct rxe_pkt_info *pkt)\n{\n\treturn __deth_sqp(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_DETH]);\n}\n\nstatic inline void deth_set_sqp(struct rxe_pkt_info *pkt, u32 sqp)\n{\n\t__deth_set_sqp(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_DETH], sqp);\n}\n\n \nstruct rxe_reth {\n\t__be64\t\t\tva;\n\t__be32\t\t\trkey;\n\t__be32\t\t\tlen;\n};\n\nstatic inline u64 __reth_va(void *arg)\n{\n\tstruct rxe_reth *reth = arg;\n\n\treturn be64_to_cpu(reth->va);\n}\n\nstatic inline void __reth_set_va(void *arg, u64 va)\n{\n\tstruct rxe_reth *reth = arg;\n\n\treth->va = cpu_to_be64(va);\n}\n\nstatic inline u32 __reth_rkey(void *arg)\n{\n\tstruct rxe_reth *reth = arg;\n\n\treturn be32_to_cpu(reth->rkey);\n}\n\nstatic inline void __reth_set_rkey(void *arg, u32 rkey)\n{\n\tstruct rxe_reth *reth = arg;\n\n\treth->rkey = cpu_to_be32(rkey);\n}\n\nstatic inline u32 __reth_len(void *arg)\n{\n\tstruct rxe_reth *reth = arg;\n\n\treturn be32_to_cpu(reth->len);\n}\n\nstatic inline void __reth_set_len(void *arg, u32 len)\n{\n\tstruct rxe_reth *reth = arg;\n\n\treth->len = cpu_to_be32(len);\n}\n\nstatic inline u64 reth_va(struct rxe_pkt_info *pkt)\n{\n\treturn __reth_va(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RETH]);\n}\n\nstatic inline void reth_set_va(struct rxe_pkt_info *pkt, u64 va)\n{\n\t__reth_set_va(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RETH], va);\n}\n\nstatic inline u32 reth_rkey(struct rxe_pkt_info *pkt)\n{\n\treturn __reth_rkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RETH]);\n}\n\nstatic inline void reth_set_rkey(struct rxe_pkt_info *pkt, u32 rkey)\n{\n\t__reth_set_rkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RETH], rkey);\n}\n\nstatic inline u32 reth_len(struct rxe_pkt_info *pkt)\n{\n\treturn __reth_len(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RETH]);\n}\n\nstatic inline void reth_set_len(struct rxe_pkt_info *pkt, u32 len)\n{\n\t__reth_set_len(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_RETH], len);\n}\n\n \n\nstruct rxe_feth {\n\t__be32 bits;\n};\n\n#define FETH_PLT_MASK\t\t(0x0000000f)  \n#define FETH_SEL_MASK\t\t(0x00000030)  \n#define FETH_SEL_SHIFT\t\t(4U)\n\nstatic inline u32 __feth_plt(void *arg)\n{\n\tstruct rxe_feth *feth = arg;\n\n\treturn be32_to_cpu(feth->bits) & FETH_PLT_MASK;\n}\n\nstatic inline u32 __feth_sel(void *arg)\n{\n\tstruct rxe_feth *feth = arg;\n\n\treturn (be32_to_cpu(feth->bits) & FETH_SEL_MASK) >> FETH_SEL_SHIFT;\n}\n\nstatic inline u32 feth_plt(struct rxe_pkt_info *pkt)\n{\n\treturn __feth_plt(pkt->hdr + rxe_opcode[pkt->opcode].offset[RXE_FETH]);\n}\n\nstatic inline u32 feth_sel(struct rxe_pkt_info *pkt)\n{\n\treturn __feth_sel(pkt->hdr + rxe_opcode[pkt->opcode].offset[RXE_FETH]);\n}\n\nstatic inline void feth_init(struct rxe_pkt_info *pkt, u8 type, u8 level)\n{\n\tstruct rxe_feth *feth = (struct rxe_feth *)\n\t\t    (pkt->hdr + rxe_opcode[pkt->opcode].offset[RXE_FETH]);\n\tu32 bits = ((level << FETH_SEL_SHIFT) & FETH_SEL_MASK) |\n\t\t   (type & FETH_PLT_MASK);\n\n\tfeth->bits = cpu_to_be32(bits);\n}\n\n \nstruct rxe_atmeth {\n\t__be64\t\t\tva;\n\t__be32\t\t\trkey;\n\t__be64\t\t\tswap_add;\n\t__be64\t\t\tcomp;\n} __packed;\n\nstatic inline u64 __atmeth_va(void *arg)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\treturn be64_to_cpu(atmeth->va);\n}\n\nstatic inline void __atmeth_set_va(void *arg, u64 va)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\tatmeth->va = cpu_to_be64(va);\n}\n\nstatic inline u32 __atmeth_rkey(void *arg)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\treturn be32_to_cpu(atmeth->rkey);\n}\n\nstatic inline void __atmeth_set_rkey(void *arg, u32 rkey)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\tatmeth->rkey = cpu_to_be32(rkey);\n}\n\nstatic inline u64 __atmeth_swap_add(void *arg)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\treturn be64_to_cpu(atmeth->swap_add);\n}\n\nstatic inline void __atmeth_set_swap_add(void *arg, u64 swap_add)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\tatmeth->swap_add = cpu_to_be64(swap_add);\n}\n\nstatic inline u64 __atmeth_comp(void *arg)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\treturn be64_to_cpu(atmeth->comp);\n}\n\nstatic inline void __atmeth_set_comp(void *arg, u64 comp)\n{\n\tstruct rxe_atmeth *atmeth = arg;\n\n\tatmeth->comp = cpu_to_be64(comp);\n}\n\nstatic inline u64 atmeth_va(struct rxe_pkt_info *pkt)\n{\n\treturn __atmeth_va(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH]);\n}\n\nstatic inline void atmeth_set_va(struct rxe_pkt_info *pkt, u64 va)\n{\n\t__atmeth_set_va(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH], va);\n}\n\nstatic inline u32 atmeth_rkey(struct rxe_pkt_info *pkt)\n{\n\treturn __atmeth_rkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH]);\n}\n\nstatic inline void atmeth_set_rkey(struct rxe_pkt_info *pkt, u32 rkey)\n{\n\t__atmeth_set_rkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH], rkey);\n}\n\nstatic inline u64 atmeth_swap_add(struct rxe_pkt_info *pkt)\n{\n\treturn __atmeth_swap_add(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH]);\n}\n\nstatic inline void atmeth_set_swap_add(struct rxe_pkt_info *pkt, u64 swap_add)\n{\n\t__atmeth_set_swap_add(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH], swap_add);\n}\n\nstatic inline u64 atmeth_comp(struct rxe_pkt_info *pkt)\n{\n\treturn __atmeth_comp(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH]);\n}\n\nstatic inline void atmeth_set_comp(struct rxe_pkt_info *pkt, u64 comp)\n{\n\t__atmeth_set_comp(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMETH], comp);\n}\n\n \nstruct rxe_aeth {\n\t__be32\t\t\tsmsn;\n};\n\n#define AETH_SYN_MASK\t\t(0xff000000)\n#define AETH_MSN_MASK\t\t(0x00ffffff)\n\nenum aeth_syndrome {\n\tAETH_TYPE_MASK\t\t= 0xe0,\n\tAETH_ACK\t\t= 0x00,\n\tAETH_RNR_NAK\t\t= 0x20,\n\tAETH_RSVD\t\t= 0x40,\n\tAETH_NAK\t\t= 0x60,\n\tAETH_ACK_UNLIMITED\t= 0x1f,\n\tAETH_NAK_PSN_SEQ_ERROR\t= 0x60,\n\tAETH_NAK_INVALID_REQ\t= 0x61,\n\tAETH_NAK_REM_ACC_ERR\t= 0x62,\n\tAETH_NAK_REM_OP_ERR\t= 0x63,\n};\n\nstatic inline u8 __aeth_syn(void *arg)\n{\n\tstruct rxe_aeth *aeth = arg;\n\n\treturn (AETH_SYN_MASK & be32_to_cpu(aeth->smsn)) >> 24;\n}\n\nstatic inline void __aeth_set_syn(void *arg, u8 syn)\n{\n\tstruct rxe_aeth *aeth = arg;\n\tu32 smsn = be32_to_cpu(aeth->smsn);\n\n\taeth->smsn = cpu_to_be32((AETH_SYN_MASK & (syn << 24)) |\n\t\t\t (~AETH_SYN_MASK & smsn));\n}\n\nstatic inline u32 __aeth_msn(void *arg)\n{\n\tstruct rxe_aeth *aeth = arg;\n\n\treturn AETH_MSN_MASK & be32_to_cpu(aeth->smsn);\n}\n\nstatic inline void __aeth_set_msn(void *arg, u32 msn)\n{\n\tstruct rxe_aeth *aeth = arg;\n\tu32 smsn = be32_to_cpu(aeth->smsn);\n\n\taeth->smsn = cpu_to_be32((AETH_MSN_MASK & msn) |\n\t\t\t (~AETH_MSN_MASK & smsn));\n}\n\nstatic inline u8 aeth_syn(struct rxe_pkt_info *pkt)\n{\n\treturn __aeth_syn(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_AETH]);\n}\n\nstatic inline void aeth_set_syn(struct rxe_pkt_info *pkt, u8 syn)\n{\n\t__aeth_set_syn(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_AETH], syn);\n}\n\nstatic inline u32 aeth_msn(struct rxe_pkt_info *pkt)\n{\n\treturn __aeth_msn(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_AETH]);\n}\n\nstatic inline void aeth_set_msn(struct rxe_pkt_info *pkt, u32 msn)\n{\n\t__aeth_set_msn(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_AETH], msn);\n}\n\n \nstruct rxe_atmack {\n\t__be64\t\t\torig;\n};\n\nstatic inline u64 __atmack_orig(void *arg)\n{\n\tstruct rxe_atmack *atmack = arg;\n\n\treturn be64_to_cpu(atmack->orig);\n}\n\nstatic inline void __atmack_set_orig(void *arg, u64 orig)\n{\n\tstruct rxe_atmack *atmack = arg;\n\n\tatmack->orig = cpu_to_be64(orig);\n}\n\nstatic inline u64 atmack_orig(struct rxe_pkt_info *pkt)\n{\n\treturn __atmack_orig(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMACK]);\n}\n\nstatic inline void atmack_set_orig(struct rxe_pkt_info *pkt, u64 orig)\n{\n\t__atmack_set_orig(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_ATMACK], orig);\n}\n\n \nstruct rxe_immdt {\n\t__be32\t\t\timm;\n};\n\nstatic inline __be32 __immdt_imm(void *arg)\n{\n\tstruct rxe_immdt *immdt = arg;\n\n\treturn immdt->imm;\n}\n\nstatic inline void __immdt_set_imm(void *arg, __be32 imm)\n{\n\tstruct rxe_immdt *immdt = arg;\n\n\timmdt->imm = imm;\n}\n\nstatic inline __be32 immdt_imm(struct rxe_pkt_info *pkt)\n{\n\treturn __immdt_imm(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_IMMDT]);\n}\n\nstatic inline void immdt_set_imm(struct rxe_pkt_info *pkt, __be32 imm)\n{\n\t__immdt_set_imm(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_IMMDT], imm);\n}\n\n \nstruct rxe_ieth {\n\t__be32\t\t\trkey;\n};\n\nstatic inline u32 __ieth_rkey(void *arg)\n{\n\tstruct rxe_ieth *ieth = arg;\n\n\treturn be32_to_cpu(ieth->rkey);\n}\n\nstatic inline void __ieth_set_rkey(void *arg, u32 rkey)\n{\n\tstruct rxe_ieth *ieth = arg;\n\n\tieth->rkey = cpu_to_be32(rkey);\n}\n\nstatic inline u32 ieth_rkey(struct rxe_pkt_info *pkt)\n{\n\treturn __ieth_rkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_IETH]);\n}\n\nstatic inline void ieth_set_rkey(struct rxe_pkt_info *pkt, u32 rkey)\n{\n\t__ieth_set_rkey(pkt->hdr +\n\t\trxe_opcode[pkt->opcode].offset[RXE_IETH], rkey);\n}\n\nenum rxe_hdr_length {\n\tRXE_BTH_BYTES\t\t= sizeof(struct rxe_bth),\n\tRXE_DETH_BYTES\t\t= sizeof(struct rxe_deth),\n\tRXE_IMMDT_BYTES\t\t= sizeof(struct rxe_immdt),\n\tRXE_RETH_BYTES\t\t= sizeof(struct rxe_reth),\n\tRXE_AETH_BYTES\t\t= sizeof(struct rxe_aeth),\n\tRXE_ATMACK_BYTES\t= sizeof(struct rxe_atmack),\n\tRXE_ATMETH_BYTES\t= sizeof(struct rxe_atmeth),\n\tRXE_IETH_BYTES\t\t= sizeof(struct rxe_ieth),\n\tRXE_RDETH_BYTES\t\t= sizeof(struct rxe_rdeth),\n\tRXE_FETH_BYTES\t\t= sizeof(struct rxe_feth),\n};\n\nstatic inline size_t header_size(struct rxe_pkt_info *pkt)\n{\n\treturn rxe_opcode[pkt->opcode].length;\n}\n\nstatic inline void *payload_addr(struct rxe_pkt_info *pkt)\n{\n\treturn pkt->hdr + rxe_opcode[pkt->opcode].offset[RXE_PAYLOAD];\n}\n\nstatic inline size_t payload_size(struct rxe_pkt_info *pkt)\n{\n\treturn pkt->paylen - rxe_opcode[pkt->opcode].offset[RXE_PAYLOAD]\n\t\t- bth_pad(pkt) - RXE_ICRC_SIZE;\n}\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}