{
  "module_name": "rxe_cq.c",
  "hash_id": "1e4e699bda3a1017c282962d5b04cf6c9c2942514eae44be27839d3e0f8a49c4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/sw/rxe/rxe_cq.c",
  "human_readable_source": "\n \n#include <linux/vmalloc.h>\n#include \"rxe.h\"\n#include \"rxe_loc.h\"\n#include \"rxe_queue.h\"\n\nint rxe_cq_chk_attr(struct rxe_dev *rxe, struct rxe_cq *cq,\n\t\t    int cqe, int comp_vector)\n{\n\tint count;\n\n\tif (cqe <= 0) {\n\t\trxe_dbg_dev(rxe, \"cqe(%d) <= 0\\n\", cqe);\n\t\tgoto err1;\n\t}\n\n\tif (cqe > rxe->attr.max_cqe) {\n\t\trxe_dbg_dev(rxe, \"cqe(%d) > max_cqe(%d)\\n\",\n\t\t\t\tcqe, rxe->attr.max_cqe);\n\t\tgoto err1;\n\t}\n\n\tif (cq) {\n\t\tcount = queue_count(cq->queue, QUEUE_TYPE_TO_CLIENT);\n\t\tif (cqe < count) {\n\t\t\trxe_dbg_cq(cq, \"cqe(%d) < current # elements in queue (%d)\",\n\t\t\t\t\tcqe, count);\n\t\t\tgoto err1;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr1:\n\treturn -EINVAL;\n}\n\nint rxe_cq_from_init(struct rxe_dev *rxe, struct rxe_cq *cq, int cqe,\n\t\t     int comp_vector, struct ib_udata *udata,\n\t\t     struct rxe_create_cq_resp __user *uresp)\n{\n\tint err;\n\tenum queue_type type;\n\n\ttype = QUEUE_TYPE_TO_CLIENT;\n\tcq->queue = rxe_queue_init(rxe, &cqe,\n\t\t\tsizeof(struct rxe_cqe), type);\n\tif (!cq->queue) {\n\t\trxe_dbg_dev(rxe, \"unable to create cq\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\terr = do_mmap_info(rxe, uresp ? &uresp->mi : NULL, udata,\n\t\t\t   cq->queue->buf, cq->queue->buf_size, &cq->queue->ip);\n\tif (err) {\n\t\tvfree(cq->queue->buf);\n\t\tkfree(cq->queue);\n\t\treturn err;\n\t}\n\n\tcq->is_user = uresp;\n\n\tspin_lock_init(&cq->cq_lock);\n\tcq->ibcq.cqe = cqe;\n\treturn 0;\n}\n\nint rxe_cq_resize_queue(struct rxe_cq *cq, int cqe,\n\t\t\tstruct rxe_resize_cq_resp __user *uresp,\n\t\t\tstruct ib_udata *udata)\n{\n\tint err;\n\n\terr = rxe_queue_resize(cq->queue, (unsigned int *)&cqe,\n\t\t\t       sizeof(struct rxe_cqe), udata,\n\t\t\t       uresp ? &uresp->mi : NULL, NULL, &cq->cq_lock);\n\tif (!err)\n\t\tcq->ibcq.cqe = cqe;\n\n\treturn err;\n}\n\n \nint rxe_cq_post(struct rxe_cq *cq, struct rxe_cqe *cqe, int solicited)\n{\n\tstruct ib_event ev;\n\tint full;\n\tvoid *addr;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cq->cq_lock, flags);\n\n\tfull = queue_full(cq->queue, QUEUE_TYPE_TO_CLIENT);\n\tif (unlikely(full)) {\n\t\trxe_err_cq(cq, \"queue full\");\n\t\tspin_unlock_irqrestore(&cq->cq_lock, flags);\n\t\tif (cq->ibcq.event_handler) {\n\t\t\tev.device = cq->ibcq.device;\n\t\t\tev.element.cq = &cq->ibcq;\n\t\t\tev.event = IB_EVENT_CQ_ERR;\n\t\t\tcq->ibcq.event_handler(&ev, cq->ibcq.cq_context);\n\t\t}\n\n\t\treturn -EBUSY;\n\t}\n\n\taddr = queue_producer_addr(cq->queue, QUEUE_TYPE_TO_CLIENT);\n\tmemcpy(addr, cqe, sizeof(*cqe));\n\n\tqueue_advance_producer(cq->queue, QUEUE_TYPE_TO_CLIENT);\n\n\tif ((cq->notify & IB_CQ_NEXT_COMP) ||\n\t    (cq->notify & IB_CQ_SOLICITED && solicited)) {\n\t\tcq->notify = 0;\n\t\tcq->ibcq.comp_handler(&cq->ibcq, cq->ibcq.cq_context);\n\t}\n\n\tspin_unlock_irqrestore(&cq->cq_lock, flags);\n\n\treturn 0;\n}\n\nvoid rxe_cq_cleanup(struct rxe_pool_elem *elem)\n{\n\tstruct rxe_cq *cq = container_of(elem, typeof(*cq), elem);\n\n\tif (cq->queue)\n\t\trxe_queue_cleanup(cq->queue);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}