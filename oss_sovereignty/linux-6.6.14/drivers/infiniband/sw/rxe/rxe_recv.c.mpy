{
  "module_name": "rxe_recv.c",
  "hash_id": "7fbb668a2901fa8d1f496f342e242cb30dfe5f32dc5bbd340c8c95714c14dee1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/infiniband/sw/rxe/rxe_recv.c",
  "human_readable_source": "\n \n\n#include <linux/skbuff.h>\n\n#include \"rxe.h\"\n#include \"rxe_loc.h\"\n\n \nstatic int check_type_state(struct rxe_dev *rxe, struct rxe_pkt_info *pkt,\n\t\t\t    struct rxe_qp *qp)\n{\n\tunsigned int pkt_type;\n\tunsigned long flags;\n\n\tif (unlikely(!qp->valid))\n\t\treturn -EINVAL;\n\n\tpkt_type = pkt->opcode & 0xe0;\n\n\tswitch (qp_type(qp)) {\n\tcase IB_QPT_RC:\n\t\tif (unlikely(pkt_type != IB_OPCODE_RC))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase IB_QPT_UC:\n\t\tif (unlikely(pkt_type != IB_OPCODE_UC))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase IB_QPT_UD:\n\tcase IB_QPT_GSI:\n\t\tif (unlikely(pkt_type != IB_OPCODE_UD))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tspin_lock_irqsave(&qp->state_lock, flags);\n\tif (pkt->mask & RXE_REQ_MASK) {\n\t\tif (unlikely(qp_state(qp) < IB_QPS_RTR)) {\n\t\t\tspin_unlock_irqrestore(&qp->state_lock, flags);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tif (unlikely(qp_state(qp) < IB_QPS_RTS)) {\n\t\t\tspin_unlock_irqrestore(&qp->state_lock, flags);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&qp->state_lock, flags);\n\n\treturn 0;\n}\n\nstatic void set_bad_pkey_cntr(struct rxe_port *port)\n{\n\tspin_lock_bh(&port->port_lock);\n\tport->attr.bad_pkey_cntr = min((u32)0xffff,\n\t\t\t\t       port->attr.bad_pkey_cntr + 1);\n\tspin_unlock_bh(&port->port_lock);\n}\n\nstatic void set_qkey_viol_cntr(struct rxe_port *port)\n{\n\tspin_lock_bh(&port->port_lock);\n\tport->attr.qkey_viol_cntr = min((u32)0xffff,\n\t\t\t\t\tport->attr.qkey_viol_cntr + 1);\n\tspin_unlock_bh(&port->port_lock);\n}\n\nstatic int check_keys(struct rxe_dev *rxe, struct rxe_pkt_info *pkt,\n\t\t      u32 qpn, struct rxe_qp *qp)\n{\n\tstruct rxe_port *port = &rxe->port;\n\tu16 pkey = bth_pkey(pkt);\n\n\tpkt->pkey_index = 0;\n\n\tif (!pkey_match(pkey, IB_DEFAULT_PKEY_FULL)) {\n\t\tset_bad_pkey_cntr(port);\n\t\treturn -EINVAL;\n\t}\n\n\tif (qp_type(qp) == IB_QPT_UD || qp_type(qp) == IB_QPT_GSI) {\n\t\tu32 qkey = (qpn == 1) ? GSI_QKEY : qp->attr.qkey;\n\n\t\tif (unlikely(deth_qkey(pkt) != qkey)) {\n\t\t\tset_qkey_viol_cntr(port);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int check_addr(struct rxe_dev *rxe, struct rxe_pkt_info *pkt,\n\t\t      struct rxe_qp *qp)\n{\n\tstruct sk_buff *skb = PKT_TO_SKB(pkt);\n\n\tif (qp_type(qp) != IB_QPT_RC && qp_type(qp) != IB_QPT_UC)\n\t\treturn 0;\n\n\tif (unlikely(pkt->port_num != qp->attr.port_num))\n\t\treturn -EINVAL;\n\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\tstruct in_addr *saddr =\n\t\t\t&qp->pri_av.sgid_addr._sockaddr_in.sin_addr;\n\t\tstruct in_addr *daddr =\n\t\t\t&qp->pri_av.dgid_addr._sockaddr_in.sin_addr;\n\n\t\tif ((ip_hdr(skb)->daddr != saddr->s_addr) ||\n\t\t    (ip_hdr(skb)->saddr != daddr->s_addr))\n\t\t\treturn -EINVAL;\n\n\t} else if (skb->protocol == htons(ETH_P_IPV6)) {\n\t\tstruct in6_addr *saddr =\n\t\t\t&qp->pri_av.sgid_addr._sockaddr_in6.sin6_addr;\n\t\tstruct in6_addr *daddr =\n\t\t\t&qp->pri_av.dgid_addr._sockaddr_in6.sin6_addr;\n\n\t\tif (memcmp(&ipv6_hdr(skb)->daddr, saddr, sizeof(*saddr)) ||\n\t\t    memcmp(&ipv6_hdr(skb)->saddr, daddr, sizeof(*daddr)))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int hdr_check(struct rxe_pkt_info *pkt)\n{\n\tstruct rxe_dev *rxe = pkt->rxe;\n\tstruct rxe_port *port = &rxe->port;\n\tstruct rxe_qp *qp = NULL;\n\tu32 qpn = bth_qpn(pkt);\n\tint index;\n\tint err;\n\n\tif (unlikely(bth_tver(pkt) != BTH_TVER))\n\t\tgoto err1;\n\n\tif (unlikely(qpn == 0))\n\t\tgoto err1;\n\n\tif (qpn != IB_MULTICAST_QPN) {\n\t\tindex = (qpn == 1) ? port->qp_gsi_index : qpn;\n\n\t\tqp = rxe_pool_get_index(&rxe->qp_pool, index);\n\t\tif (unlikely(!qp))\n\t\t\tgoto err1;\n\n\t\terr = check_type_state(rxe, pkt, qp);\n\t\tif (unlikely(err))\n\t\t\tgoto err2;\n\n\t\terr = check_addr(rxe, pkt, qp);\n\t\tif (unlikely(err))\n\t\t\tgoto err2;\n\n\t\terr = check_keys(rxe, pkt, qpn, qp);\n\t\tif (unlikely(err))\n\t\t\tgoto err2;\n\t} else {\n\t\tif (unlikely((pkt->mask & RXE_GRH_MASK) == 0))\n\t\t\tgoto err1;\n\t}\n\n\tpkt->qp = qp;\n\treturn 0;\n\nerr2:\n\trxe_put(qp);\nerr1:\n\treturn -EINVAL;\n}\n\nstatic inline void rxe_rcv_pkt(struct rxe_pkt_info *pkt, struct sk_buff *skb)\n{\n\tif (pkt->mask & RXE_REQ_MASK)\n\t\trxe_resp_queue_pkt(pkt->qp, skb);\n\telse\n\t\trxe_comp_queue_pkt(pkt->qp, skb);\n}\n\nstatic void rxe_rcv_mcast_pkt(struct rxe_dev *rxe, struct sk_buff *skb)\n{\n\tstruct rxe_pkt_info *pkt = SKB_TO_PKT(skb);\n\tstruct rxe_mcg *mcg;\n\tstruct rxe_mca *mca;\n\tstruct rxe_qp *qp;\n\tunion ib_gid dgid;\n\tint err;\n\n\tif (skb->protocol == htons(ETH_P_IP))\n\t\tipv6_addr_set_v4mapped(ip_hdr(skb)->daddr,\n\t\t\t\t       (struct in6_addr *)&dgid);\n\telse if (skb->protocol == htons(ETH_P_IPV6))\n\t\tmemcpy(&dgid, &ipv6_hdr(skb)->daddr, sizeof(dgid));\n\n\t \n\tmcg = rxe_lookup_mcg(rxe, &dgid);\n\tif (!mcg)\n\t\tgoto drop;\t \n\n\tspin_lock_bh(&rxe->mcg_lock);\n\n\t \n\tlist_for_each_entry(mca, &mcg->qp_list, qp_list) {\n\t\tqp = mca->qp;\n\n\t\t \n\t\terr = check_type_state(rxe, pkt, qp);\n\t\tif (err)\n\t\t\tcontinue;\n\n\t\terr = check_keys(rxe, pkt, bth_qpn(pkt), qp);\n\t\tif (err)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (mca->qp_list.next != &mcg->qp_list) {\n\t\t\tstruct sk_buff *cskb;\n\t\t\tstruct rxe_pkt_info *cpkt;\n\n\t\t\tcskb = skb_clone(skb, GFP_ATOMIC);\n\t\t\tif (unlikely(!cskb))\n\t\t\t\tcontinue;\n\n\t\t\tif (WARN_ON(!ib_device_try_get(&rxe->ib_dev))) {\n\t\t\t\tkfree_skb(cskb);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tcpkt = SKB_TO_PKT(cskb);\n\t\t\tcpkt->qp = qp;\n\t\t\trxe_get(qp);\n\t\t\trxe_rcv_pkt(cpkt, cskb);\n\t\t} else {\n\t\t\tpkt->qp = qp;\n\t\t\trxe_get(qp);\n\t\t\trxe_rcv_pkt(pkt, skb);\n\t\t\tskb = NULL;\t \n\t\t}\n\t}\n\n\tspin_unlock_bh(&rxe->mcg_lock);\n\n\tkref_put(&mcg->ref_cnt, rxe_cleanup_mcg);\n\n\tif (likely(!skb))\n\t\treturn;\n\n\t \n\ndrop:\n\tkfree_skb(skb);\n\tib_device_put(&rxe->ib_dev);\n}\n\n \nstatic int rxe_chk_dgid(struct rxe_dev *rxe, struct sk_buff *skb)\n{\n\tstruct rxe_pkt_info *pkt = SKB_TO_PKT(skb);\n\tconst struct ib_gid_attr *gid_attr;\n\tunion ib_gid dgid;\n\tunion ib_gid *pdgid;\n\n\tif (pkt->mask & RXE_LOOPBACK_MASK)\n\t\treturn 0;\n\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\tipv6_addr_set_v4mapped(ip_hdr(skb)->daddr,\n\t\t\t\t       (struct in6_addr *)&dgid);\n\t\tpdgid = &dgid;\n\t} else {\n\t\tpdgid = (union ib_gid *)&ipv6_hdr(skb)->daddr;\n\t}\n\n\tif (rdma_is_multicast_addr((struct in6_addr *)pdgid))\n\t\treturn 0;\n\n\tgid_attr = rdma_find_gid_by_port(&rxe->ib_dev, pdgid,\n\t\t\t\t\t IB_GID_TYPE_ROCE_UDP_ENCAP,\n\t\t\t\t\t 1, skb->dev);\n\tif (IS_ERR(gid_attr))\n\t\treturn PTR_ERR(gid_attr);\n\n\trdma_put_gid_attr(gid_attr);\n\treturn 0;\n}\n\n \nvoid rxe_rcv(struct sk_buff *skb)\n{\n\tint err;\n\tstruct rxe_pkt_info *pkt = SKB_TO_PKT(skb);\n\tstruct rxe_dev *rxe = pkt->rxe;\n\n\tif (unlikely(skb->len < RXE_BTH_BYTES))\n\t\tgoto drop;\n\n\tif (rxe_chk_dgid(rxe, skb) < 0)\n\t\tgoto drop;\n\n\tpkt->opcode = bth_opcode(pkt);\n\tpkt->psn = bth_psn(pkt);\n\tpkt->qp = NULL;\n\tpkt->mask |= rxe_opcode[pkt->opcode].mask;\n\n\tif (unlikely(skb->len < header_size(pkt)))\n\t\tgoto drop;\n\n\terr = hdr_check(pkt);\n\tif (unlikely(err))\n\t\tgoto drop;\n\n\terr = rxe_icrc_check(skb, pkt);\n\tif (unlikely(err))\n\t\tgoto drop;\n\n\trxe_counter_inc(rxe, RXE_CNT_RCVD_PKTS);\n\n\tif (unlikely(bth_qpn(pkt) == IB_MULTICAST_QPN))\n\t\trxe_rcv_mcast_pkt(rxe, skb);\n\telse\n\t\trxe_rcv_pkt(pkt, skb);\n\n\treturn;\n\ndrop:\n\tif (pkt->qp)\n\t\trxe_put(pkt->qp);\n\n\tkfree_skb(skb);\n\tib_device_put(&rxe->ib_dev);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}