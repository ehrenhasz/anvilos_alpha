{
  "module_name": "region.c",
  "hash_id": "44a8fcf7819411bec6579c673bcfae4090ce1f39cd42fa3b034dbda270f26536",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cxl/core/region.c",
  "human_readable_source": "\n \n#include <linux/memregion.h>\n#include <linux/genalloc.h>\n#include <linux/device.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/uuid.h>\n#include <linux/sort.h>\n#include <linux/idr.h>\n#include <cxlmem.h>\n#include <cxl.h>\n#include \"core.h\"\n\n \n\nstatic struct cxl_region *to_cxl_region(struct device *dev);\n\nstatic ssize_t uuid_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tssize_t rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\tif (cxlr->mode != CXL_DECODER_PMEM)\n\t\trc = sysfs_emit(buf, \"\\n\");\n\telse\n\t\trc = sysfs_emit(buf, \"%pUb\\n\", &p->uuid);\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\n\nstatic int is_dup(struct device *match, void *data)\n{\n\tstruct cxl_region_params *p;\n\tstruct cxl_region *cxlr;\n\tuuid_t *uuid = data;\n\n\tif (!is_cxl_region(match))\n\t\treturn 0;\n\n\tlockdep_assert_held(&cxl_region_rwsem);\n\tcxlr = to_cxl_region(match);\n\tp = &cxlr->params;\n\n\tif (uuid_equal(&p->uuid, uuid)) {\n\t\tdev_dbg(match, \"already has uuid: %pUb\\n\", uuid);\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\nstatic ssize_t uuid_store(struct device *dev, struct device_attribute *attr,\n\t\t\t  const char *buf, size_t len)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tuuid_t temp;\n\tssize_t rc;\n\n\tif (len != UUID_STRING_LEN + 1)\n\t\treturn -EINVAL;\n\n\trc = uuid_parse(buf, &temp);\n\tif (rc)\n\t\treturn rc;\n\n\tif (uuid_is_null(&temp))\n\t\treturn -EINVAL;\n\n\trc = down_write_killable(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\n\tif (uuid_equal(&p->uuid, &temp))\n\t\tgoto out;\n\n\trc = -EBUSY;\n\tif (p->state >= CXL_CONFIG_ACTIVE)\n\t\tgoto out;\n\n\trc = bus_for_each_dev(&cxl_bus_type, NULL, &temp, is_dup);\n\tif (rc < 0)\n\t\tgoto out;\n\n\tuuid_copy(&p->uuid, &temp);\nout:\n\tup_write(&cxl_region_rwsem);\n\n\tif (rc)\n\t\treturn rc;\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(uuid);\n\nstatic struct cxl_region_ref *cxl_rr_load(struct cxl_port *port,\n\t\t\t\t\t  struct cxl_region *cxlr)\n{\n\treturn xa_load(&port->regions, (unsigned long)cxlr);\n}\n\nstatic int cxl_region_invalidate_memregion(struct cxl_region *cxlr)\n{\n\tif (!cpu_cache_has_invalidate_memregion()) {\n\t\tif (IS_ENABLED(CONFIG_CXL_REGION_INVALIDATION_TEST)) {\n\t\t\tdev_warn_once(\n\t\t\t\t&cxlr->dev,\n\t\t\t\t\"Bypassing cpu_cache_invalidate_memregion() for testing!\\n\");\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tdev_err(&cxlr->dev,\n\t\t\t\t\"Failed to synchronize CPU cache state\\n\");\n\t\t\treturn -ENXIO;\n\t\t}\n\t}\n\n\tcpu_cache_invalidate_memregion(IORES_DESC_CXL);\n\treturn 0;\n}\n\nstatic int cxl_region_decode_reset(struct cxl_region *cxlr, int count)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint i, rc = 0;\n\n\t \n\trc = cxl_region_invalidate_memregion(cxlr);\n\tif (rc)\n\t\treturn rc;\n\n\tfor (i = count - 1; i >= 0; i--) {\n\t\tstruct cxl_endpoint_decoder *cxled = p->targets[i];\n\t\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\t\tstruct cxl_port *iter = cxled_to_port(cxled);\n\t\tstruct cxl_dev_state *cxlds = cxlmd->cxlds;\n\t\tstruct cxl_ep *ep;\n\n\t\tif (cxlds->rcd)\n\t\t\tgoto endpoint_reset;\n\n\t\twhile (!is_cxl_root(to_cxl_port(iter->dev.parent)))\n\t\t\titer = to_cxl_port(iter->dev.parent);\n\n\t\tfor (ep = cxl_ep_load(iter, cxlmd); iter;\n\t\t     iter = ep->next, ep = cxl_ep_load(iter, cxlmd)) {\n\t\t\tstruct cxl_region_ref *cxl_rr;\n\t\t\tstruct cxl_decoder *cxld;\n\n\t\t\tcxl_rr = cxl_rr_load(iter, cxlr);\n\t\t\tcxld = cxl_rr->decoder;\n\t\t\tif (cxld->reset)\n\t\t\t\trc = cxld->reset(cxld);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t\tset_bit(CXL_REGION_F_NEEDS_RESET, &cxlr->flags);\n\t\t}\n\nendpoint_reset:\n\t\trc = cxled->cxld.reset(&cxled->cxld);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tset_bit(CXL_REGION_F_NEEDS_RESET, &cxlr->flags);\n\t}\n\n\t \n\tclear_bit(CXL_REGION_F_NEEDS_RESET, &cxlr->flags);\n\n\treturn 0;\n}\n\nstatic int commit_decoder(struct cxl_decoder *cxld)\n{\n\tstruct cxl_switch_decoder *cxlsd = NULL;\n\n\tif (cxld->commit)\n\t\treturn cxld->commit(cxld);\n\n\tif (is_switch_decoder(&cxld->dev))\n\t\tcxlsd = to_cxl_switch_decoder(&cxld->dev);\n\n\tif (dev_WARN_ONCE(&cxld->dev, !cxlsd || cxlsd->nr_targets > 1,\n\t\t\t  \"->commit() is required\\n\"))\n\t\treturn -ENXIO;\n\treturn 0;\n}\n\nstatic int cxl_region_decode_commit(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint i, rc = 0;\n\n\tfor (i = 0; i < p->nr_targets; i++) {\n\t\tstruct cxl_endpoint_decoder *cxled = p->targets[i];\n\t\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\t\tstruct cxl_region_ref *cxl_rr;\n\t\tstruct cxl_decoder *cxld;\n\t\tstruct cxl_port *iter;\n\t\tstruct cxl_ep *ep;\n\n\t\t \n\t\tfor (iter = cxled_to_port(cxled); !is_cxl_root(iter);\n\t\t     iter = to_cxl_port(iter->dev.parent)) {\n\t\t\tcxl_rr = cxl_rr_load(iter, cxlr);\n\t\t\tcxld = cxl_rr->decoder;\n\t\t\trc = commit_decoder(cxld);\n\t\t\tif (rc)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (rc) {\n\t\t\t \n\t\t\tfor (ep = cxl_ep_load(iter, cxlmd); ep && iter;\n\t\t\t     iter = ep->next, ep = cxl_ep_load(iter, cxlmd)) {\n\t\t\t\tcxl_rr = cxl_rr_load(iter, cxlr);\n\t\t\t\tcxld = cxl_rr->decoder;\n\t\t\t\tif (cxld->reset)\n\t\t\t\t\tcxld->reset(cxld);\n\t\t\t}\n\n\t\t\tcxled->cxld.reset(&cxled->cxld);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\t \n\tcxl_region_decode_reset(cxlr, i);\n\treturn rc;\n}\n\nstatic ssize_t commit_store(struct device *dev, struct device_attribute *attr,\n\t\t\t    const char *buf, size_t len)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tbool commit;\n\tssize_t rc;\n\n\trc = kstrtobool(buf, &commit);\n\tif (rc)\n\t\treturn rc;\n\n\trc = down_write_killable(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (commit && p->state >= CXL_CONFIG_COMMIT)\n\t\tgoto out;\n\tif (!commit && p->state < CXL_CONFIG_COMMIT)\n\t\tgoto out;\n\n\t \n\tif (commit && p->state < CXL_CONFIG_ACTIVE) {\n\t\trc = -ENXIO;\n\t\tgoto out;\n\t}\n\n\t \n\trc = cxl_region_invalidate_memregion(cxlr);\n\tif (rc)\n\t\tgoto out;\n\n\tif (commit) {\n\t\trc = cxl_region_decode_commit(cxlr);\n\t\tif (rc == 0)\n\t\t\tp->state = CXL_CONFIG_COMMIT;\n\t} else {\n\t\tp->state = CXL_CONFIG_RESET_PENDING;\n\t\tup_write(&cxl_region_rwsem);\n\t\tdevice_release_driver(&cxlr->dev);\n\t\tdown_write(&cxl_region_rwsem);\n\n\t\t \n\t\tif (p->state == CXL_CONFIG_RESET_PENDING) {\n\t\t\trc = cxl_region_decode_reset(cxlr, p->interleave_ways);\n\t\t\t \n\t\t\tif (rc)\n\t\t\t\tp->state = CXL_CONFIG_COMMIT;\n\t\t\telse\n\t\t\t\tp->state = CXL_CONFIG_ACTIVE;\n\t\t}\n\t}\n\nout:\n\tup_write(&cxl_region_rwsem);\n\n\tif (rc)\n\t\treturn rc;\n\treturn len;\n}\n\nstatic ssize_t commit_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tssize_t rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\trc = sysfs_emit(buf, \"%d\\n\", p->state >= CXL_CONFIG_COMMIT);\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RW(commit);\n\nstatic umode_t cxl_region_visible(struct kobject *kobj, struct attribute *a,\n\t\t\t\t  int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\n\t \n\tif (a == &dev_attr_uuid.attr && cxlr->mode != CXL_DECODER_PMEM)\n\t\treturn 0444;\n\treturn a->mode;\n}\n\nstatic ssize_t interleave_ways_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tssize_t rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\trc = sysfs_emit(buf, \"%d\\n\", p->interleave_ways);\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\n\nstatic const struct attribute_group *get_cxl_region_target_group(void);\n\nstatic ssize_t interleave_ways_store(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t len)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev->parent);\n\tstruct cxl_decoder *cxld = &cxlrd->cxlsd.cxld;\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tunsigned int val, save;\n\tint rc;\n\tu8 iw;\n\n\trc = kstrtouint(buf, 0, &val);\n\tif (rc)\n\t\treturn rc;\n\n\trc = ways_to_eiw(val, &iw);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (!is_power_of_2(val / cxld->interleave_ways) ||\n\t    (val % cxld->interleave_ways)) {\n\t\tdev_dbg(&cxlr->dev, \"invalid interleave: %d\\n\", val);\n\t\treturn -EINVAL;\n\t}\n\n\trc = down_write_killable(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\tif (p->state >= CXL_CONFIG_INTERLEAVE_ACTIVE) {\n\t\trc = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tsave = p->interleave_ways;\n\tp->interleave_ways = val;\n\trc = sysfs_update_group(&cxlr->dev.kobj, get_cxl_region_target_group());\n\tif (rc)\n\t\tp->interleave_ways = save;\nout:\n\tup_write(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(interleave_ways);\n\nstatic ssize_t interleave_granularity_show(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tssize_t rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\trc = sysfs_emit(buf, \"%d\\n\", p->interleave_granularity);\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\n\nstatic ssize_t interleave_granularity_store(struct device *dev,\n\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t    const char *buf, size_t len)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev->parent);\n\tstruct cxl_decoder *cxld = &cxlrd->cxlsd.cxld;\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint rc, val;\n\tu16 ig;\n\n\trc = kstrtoint(buf, 0, &val);\n\tif (rc)\n\t\treturn rc;\n\n\trc = granularity_to_eig(val, &ig);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (cxld->interleave_ways > 1 && val != cxld->interleave_granularity)\n\t\treturn -EINVAL;\n\n\trc = down_write_killable(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\tif (p->state >= CXL_CONFIG_INTERLEAVE_ACTIVE) {\n\t\trc = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tp->interleave_granularity = val;\nout:\n\tup_write(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(interleave_granularity);\n\nstatic ssize_t resource_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tu64 resource = -1ULL;\n\tssize_t rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\tif (p->res)\n\t\tresource = p->res->start;\n\trc = sysfs_emit(buf, \"%#llx\\n\", resource);\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RO(resource);\n\nstatic ssize_t mode_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", cxl_decoder_mode_name(cxlr->mode));\n}\nstatic DEVICE_ATTR_RO(mode);\n\nstatic int alloc_hpa(struct cxl_region *cxlr, resource_size_t size)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr->dev.parent);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct resource *res;\n\tu32 remainder = 0;\n\n\tlockdep_assert_held_write(&cxl_region_rwsem);\n\n\t \n\tif (p->res && resource_size(p->res) == size)\n\t\treturn 0;\n\n\t \n\tif (p->res)\n\t\treturn -EBUSY;\n\n\tif (p->state >= CXL_CONFIG_INTERLEAVE_ACTIVE)\n\t\treturn -EBUSY;\n\n\t \n\tif (!p->interleave_ways || !p->interleave_granularity ||\n\t    (cxlr->mode == CXL_DECODER_PMEM && uuid_is_null(&p->uuid)))\n\t\treturn -ENXIO;\n\n\tdiv_u64_rem(size, SZ_256M * p->interleave_ways, &remainder);\n\tif (remainder)\n\t\treturn -EINVAL;\n\n\tres = alloc_free_mem_region(cxlrd->res, size, SZ_256M,\n\t\t\t\t    dev_name(&cxlr->dev));\n\tif (IS_ERR(res)) {\n\t\tdev_dbg(&cxlr->dev, \"failed to allocate HPA: %ld\\n\",\n\t\t\tPTR_ERR(res));\n\t\treturn PTR_ERR(res);\n\t}\n\n\tp->res = res;\n\tp->state = CXL_CONFIG_INTERLEAVE_ACTIVE;\n\n\treturn 0;\n}\n\nstatic void cxl_region_iomem_release(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\n\tif (device_is_registered(&cxlr->dev))\n\t\tlockdep_assert_held_write(&cxl_region_rwsem);\n\tif (p->res) {\n\t\t \n\t\tif (p->res->parent)\n\t\t\tremove_resource(p->res);\n\t\tkfree(p->res);\n\t\tp->res = NULL;\n\t}\n}\n\nstatic int free_hpa(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\n\tlockdep_assert_held_write(&cxl_region_rwsem);\n\n\tif (!p->res)\n\t\treturn 0;\n\n\tif (p->state >= CXL_CONFIG_ACTIVE)\n\t\treturn -EBUSY;\n\n\tcxl_region_iomem_release(cxlr);\n\tp->state = CXL_CONFIG_IDLE;\n\treturn 0;\n}\n\nstatic ssize_t size_store(struct device *dev, struct device_attribute *attr,\n\t\t\t  const char *buf, size_t len)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tu64 val;\n\tint rc;\n\n\trc = kstrtou64(buf, 0, &val);\n\tif (rc)\n\t\treturn rc;\n\n\trc = down_write_killable(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\n\tif (val)\n\t\trc = alloc_hpa(cxlr, val);\n\telse\n\t\trc = free_hpa(cxlr);\n\tup_write(&cxl_region_rwsem);\n\n\tif (rc)\n\t\treturn rc;\n\n\treturn len;\n}\n\nstatic ssize_t size_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tu64 size = 0;\n\tssize_t rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\tif (p->res)\n\t\tsize = resource_size(p->res);\n\trc = sysfs_emit(buf, \"%#llx\\n\", size);\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\nstatic DEVICE_ATTR_RW(size);\n\nstatic struct attribute *cxl_region_attrs[] = {\n\t&dev_attr_uuid.attr,\n\t&dev_attr_commit.attr,\n\t&dev_attr_interleave_ways.attr,\n\t&dev_attr_interleave_granularity.attr,\n\t&dev_attr_resource.attr,\n\t&dev_attr_size.attr,\n\t&dev_attr_mode.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group cxl_region_group = {\n\t.attrs = cxl_region_attrs,\n\t.is_visible = cxl_region_visible,\n};\n\nstatic size_t show_targetN(struct cxl_region *cxlr, char *buf, int pos)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_endpoint_decoder *cxled;\n\tint rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\n\tif (pos >= p->interleave_ways) {\n\t\tdev_dbg(&cxlr->dev, \"position %d out of range %d\\n\", pos,\n\t\t\tp->interleave_ways);\n\t\trc = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tcxled = p->targets[pos];\n\tif (!cxled)\n\t\trc = sysfs_emit(buf, \"\\n\");\n\telse\n\t\trc = sysfs_emit(buf, \"%s\\n\", dev_name(&cxled->cxld.dev));\nout:\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\n\nstatic int match_free_decoder(struct device *dev, void *data)\n{\n\tstruct cxl_decoder *cxld;\n\tint *id = data;\n\n\tif (!is_switch_decoder(dev))\n\t\treturn 0;\n\n\tcxld = to_cxl_decoder(dev);\n\n\t \n\tif (cxld->id != *id)\n\t\treturn 0;\n\n\tif (!cxld->region)\n\t\treturn 1;\n\n\t(*id)++;\n\n\treturn 0;\n}\n\nstatic int match_auto_decoder(struct device *dev, void *data)\n{\n\tstruct cxl_region_params *p = data;\n\tstruct cxl_decoder *cxld;\n\tstruct range *r;\n\n\tif (!is_switch_decoder(dev))\n\t\treturn 0;\n\n\tcxld = to_cxl_decoder(dev);\n\tr = &cxld->hpa_range;\n\n\tif (p->res && p->res->start == r->start && p->res->end == r->end)\n\t\treturn 1;\n\n\treturn 0;\n}\n\nstatic struct cxl_decoder *cxl_region_find_decoder(struct cxl_port *port,\n\t\t\t\t\t\t   struct cxl_region *cxlr)\n{\n\tstruct device *dev;\n\tint id = 0;\n\n\tif (test_bit(CXL_REGION_F_AUTO, &cxlr->flags))\n\t\tdev = device_find_child(&port->dev, &cxlr->params,\n\t\t\t\t\tmatch_auto_decoder);\n\telse\n\t\tdev = device_find_child(&port->dev, &id, match_free_decoder);\n\tif (!dev)\n\t\treturn NULL;\n\t \n\tput_device(dev);\n\treturn to_cxl_decoder(dev);\n}\n\nstatic struct cxl_region_ref *alloc_region_ref(struct cxl_port *port,\n\t\t\t\t\t       struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_region_ref *cxl_rr, *iter;\n\tunsigned long index;\n\tint rc;\n\n\txa_for_each(&port->regions, index, iter) {\n\t\tstruct cxl_region_params *ip = &iter->region->params;\n\n\t\tif (!ip->res)\n\t\t\tcontinue;\n\n\t\tif (ip->res->start > p->res->start) {\n\t\t\tdev_dbg(&cxlr->dev,\n\t\t\t\t\"%s: HPA order violation %s:%pr vs %pr\\n\",\n\t\t\t\tdev_name(&port->dev),\n\t\t\t\tdev_name(&iter->region->dev), ip->res, p->res);\n\t\t\treturn ERR_PTR(-EBUSY);\n\t\t}\n\t}\n\n\tcxl_rr = kzalloc(sizeof(*cxl_rr), GFP_KERNEL);\n\tif (!cxl_rr)\n\t\treturn ERR_PTR(-ENOMEM);\n\tcxl_rr->port = port;\n\tcxl_rr->region = cxlr;\n\tcxl_rr->nr_targets = 1;\n\txa_init(&cxl_rr->endpoints);\n\n\trc = xa_insert(&port->regions, (unsigned long)cxlr, cxl_rr, GFP_KERNEL);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev,\n\t\t\t\"%s: failed to track region reference: %d\\n\",\n\t\t\tdev_name(&port->dev), rc);\n\t\tkfree(cxl_rr);\n\t\treturn ERR_PTR(rc);\n\t}\n\n\treturn cxl_rr;\n}\n\nstatic void cxl_rr_free_decoder(struct cxl_region_ref *cxl_rr)\n{\n\tstruct cxl_region *cxlr = cxl_rr->region;\n\tstruct cxl_decoder *cxld = cxl_rr->decoder;\n\n\tif (!cxld)\n\t\treturn;\n\n\tdev_WARN_ONCE(&cxlr->dev, cxld->region != cxlr, \"region mismatch\\n\");\n\tif (cxld->region == cxlr) {\n\t\tcxld->region = NULL;\n\t\tput_device(&cxlr->dev);\n\t}\n}\n\nstatic void free_region_ref(struct cxl_region_ref *cxl_rr)\n{\n\tstruct cxl_port *port = cxl_rr->port;\n\tstruct cxl_region *cxlr = cxl_rr->region;\n\n\tcxl_rr_free_decoder(cxl_rr);\n\txa_erase(&port->regions, (unsigned long)cxlr);\n\txa_destroy(&cxl_rr->endpoints);\n\tkfree(cxl_rr);\n}\n\nstatic int cxl_rr_ep_add(struct cxl_region_ref *cxl_rr,\n\t\t\t struct cxl_endpoint_decoder *cxled)\n{\n\tint rc;\n\tstruct cxl_port *port = cxl_rr->port;\n\tstruct cxl_region *cxlr = cxl_rr->region;\n\tstruct cxl_decoder *cxld = cxl_rr->decoder;\n\tstruct cxl_ep *ep = cxl_ep_load(port, cxled_to_memdev(cxled));\n\n\tif (ep) {\n\t\trc = xa_insert(&cxl_rr->endpoints, (unsigned long)cxled, ep,\n\t\t\t       GFP_KERNEL);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\tcxl_rr->nr_eps++;\n\n\tif (!cxld->region) {\n\t\tcxld->region = cxlr;\n\t\tget_device(&cxlr->dev);\n\t}\n\n\treturn 0;\n}\n\nstatic int cxl_rr_alloc_decoder(struct cxl_port *port, struct cxl_region *cxlr,\n\t\t\t\tstruct cxl_endpoint_decoder *cxled,\n\t\t\t\tstruct cxl_region_ref *cxl_rr)\n{\n\tstruct cxl_decoder *cxld;\n\n\tif (port == cxled_to_port(cxled))\n\t\tcxld = &cxled->cxld;\n\telse\n\t\tcxld = cxl_region_find_decoder(port, cxlr);\n\tif (!cxld) {\n\t\tdev_dbg(&cxlr->dev, \"%s: no decoder available\\n\",\n\t\t\tdev_name(&port->dev));\n\t\treturn -EBUSY;\n\t}\n\n\tif (cxld->region) {\n\t\tdev_dbg(&cxlr->dev, \"%s: %s already attached to %s\\n\",\n\t\t\tdev_name(&port->dev), dev_name(&cxld->dev),\n\t\t\tdev_name(&cxld->region->dev));\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tdev_WARN_ONCE(&cxlr->dev,\n\t\t      port == cxled_to_port(cxled) &&\n\t\t\t      cxld->target_type != cxlr->type,\n\t\t      \"%s:%s mismatch decoder type %d -> %d\\n\",\n\t\t      dev_name(&cxled_to_memdev(cxled)->dev),\n\t\t      dev_name(&cxld->dev), cxld->target_type, cxlr->type);\n\tcxld->target_type = cxlr->type;\n\tcxl_rr->decoder = cxld;\n\treturn 0;\n}\n\n \nstatic int cxl_port_attach_region(struct cxl_port *port,\n\t\t\t\t  struct cxl_region *cxlr,\n\t\t\t\t  struct cxl_endpoint_decoder *cxled, int pos)\n{\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct cxl_ep *ep = cxl_ep_load(port, cxlmd);\n\tstruct cxl_region_ref *cxl_rr;\n\tbool nr_targets_inc = false;\n\tstruct cxl_decoder *cxld;\n\tunsigned long index;\n\tint rc = -EBUSY;\n\n\tlockdep_assert_held_write(&cxl_region_rwsem);\n\n\tcxl_rr = cxl_rr_load(port, cxlr);\n\tif (cxl_rr) {\n\t\tstruct cxl_ep *ep_iter;\n\t\tint found = 0;\n\n\t\t \n\t\txa_for_each(&cxl_rr->endpoints, index, ep_iter) {\n\t\t\tif (ep_iter == ep)\n\t\t\t\tcontinue;\n\t\t\tif (ep_iter->next == ep->next) {\n\t\t\t\tfound++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (!found || !ep->next) {\n\t\t\tcxl_rr->nr_targets++;\n\t\t\tnr_targets_inc = true;\n\t\t}\n\t} else {\n\t\tcxl_rr = alloc_region_ref(port, cxlr);\n\t\tif (IS_ERR(cxl_rr)) {\n\t\t\tdev_dbg(&cxlr->dev,\n\t\t\t\t\"%s: failed to allocate region reference\\n\",\n\t\t\t\tdev_name(&port->dev));\n\t\t\treturn PTR_ERR(cxl_rr);\n\t\t}\n\t\tnr_targets_inc = true;\n\n\t\trc = cxl_rr_alloc_decoder(port, cxlr, cxled, cxl_rr);\n\t\tif (rc)\n\t\t\tgoto out_erase;\n\t}\n\tcxld = cxl_rr->decoder;\n\n\trc = cxl_rr_ep_add(cxl_rr, cxled);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev,\n\t\t\t\"%s: failed to track endpoint %s:%s reference\\n\",\n\t\t\tdev_name(&port->dev), dev_name(&cxlmd->dev),\n\t\t\tdev_name(&cxld->dev));\n\t\tgoto out_erase;\n\t}\n\n\tdev_dbg(&cxlr->dev,\n\t\t\"%s:%s %s add: %s:%s @ %d next: %s nr_eps: %d nr_targets: %d\\n\",\n\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\tdev_name(&cxld->dev), dev_name(&cxlmd->dev),\n\t\tdev_name(&cxled->cxld.dev), pos,\n\t\tep ? ep->next ? dev_name(ep->next->uport_dev) :\n\t\t\t\t      dev_name(&cxlmd->dev) :\n\t\t\t   \"none\",\n\t\tcxl_rr->nr_eps, cxl_rr->nr_targets);\n\n\treturn 0;\nout_erase:\n\tif (nr_targets_inc)\n\t\tcxl_rr->nr_targets--;\n\tif (cxl_rr->nr_eps == 0)\n\t\tfree_region_ref(cxl_rr);\n\treturn rc;\n}\n\nstatic void cxl_port_detach_region(struct cxl_port *port,\n\t\t\t\t   struct cxl_region *cxlr,\n\t\t\t\t   struct cxl_endpoint_decoder *cxled)\n{\n\tstruct cxl_region_ref *cxl_rr;\n\tstruct cxl_ep *ep = NULL;\n\n\tlockdep_assert_held_write(&cxl_region_rwsem);\n\n\tcxl_rr = cxl_rr_load(port, cxlr);\n\tif (!cxl_rr)\n\t\treturn;\n\n\t \n\tif (cxl_rr->decoder == &cxled->cxld)\n\t\tcxl_rr->nr_eps--;\n\telse\n\t\tep = xa_erase(&cxl_rr->endpoints, (unsigned long)cxled);\n\tif (ep) {\n\t\tstruct cxl_ep *ep_iter;\n\t\tunsigned long index;\n\t\tint found = 0;\n\n\t\tcxl_rr->nr_eps--;\n\t\txa_for_each(&cxl_rr->endpoints, index, ep_iter) {\n\t\t\tif (ep_iter->next == ep->next) {\n\t\t\t\tfound++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!found)\n\t\t\tcxl_rr->nr_targets--;\n\t}\n\n\tif (cxl_rr->nr_eps == 0)\n\t\tfree_region_ref(cxl_rr);\n}\n\nstatic int check_last_peer(struct cxl_endpoint_decoder *cxled,\n\t\t\t   struct cxl_ep *ep, struct cxl_region_ref *cxl_rr,\n\t\t\t   int distance)\n{\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct cxl_region *cxlr = cxl_rr->region;\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_endpoint_decoder *cxled_peer;\n\tstruct cxl_port *port = cxl_rr->port;\n\tstruct cxl_memdev *cxlmd_peer;\n\tstruct cxl_ep *ep_peer;\n\tint pos = cxled->pos;\n\n\t \n\tif (pos < distance) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s: cannot host %s:%s at %d\\n\",\n\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev), pos);\n\t\treturn -ENXIO;\n\t}\n\tcxled_peer = p->targets[pos - distance];\n\tcxlmd_peer = cxled_to_memdev(cxled_peer);\n\tep_peer = cxl_ep_load(port, cxlmd_peer);\n\tif (ep->dport != ep_peer->dport) {\n\t\tdev_dbg(&cxlr->dev,\n\t\t\t\"%s:%s: %s:%s pos %d mismatched peer %s:%s\\n\",\n\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev), pos,\n\t\t\tdev_name(&cxlmd_peer->dev),\n\t\t\tdev_name(&cxled_peer->cxld.dev));\n\t\treturn -ENXIO;\n\t}\n\n\treturn 0;\n}\n\nstatic int cxl_port_setup_targets(struct cxl_port *port,\n\t\t\t\t  struct cxl_region *cxlr,\n\t\t\t\t  struct cxl_endpoint_decoder *cxled)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr->dev.parent);\n\tint parent_iw, parent_ig, ig, iw, rc, inc = 0, pos = cxled->pos;\n\tstruct cxl_port *parent_port = to_cxl_port(port->dev.parent);\n\tstruct cxl_region_ref *cxl_rr = cxl_rr_load(port, cxlr);\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct cxl_ep *ep = cxl_ep_load(port, cxlmd);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_decoder *cxld = cxl_rr->decoder;\n\tstruct cxl_switch_decoder *cxlsd;\n\tu16 eig, peig;\n\tu8 eiw, peiw;\n\n\t \n\tif (!is_power_of_2(cxl_rr->nr_targets)) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s: invalid target count %d\\n\",\n\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\tcxl_rr->nr_targets);\n\t\treturn -EINVAL;\n\t}\n\n\tcxlsd = to_cxl_switch_decoder(&cxld->dev);\n\tif (cxl_rr->nr_targets_set) {\n\t\tint i, distance;\n\n\t\t \n\t\tif (cxl_rr->nr_targets == 1)\n\t\t\tdistance = 0;\n\t\telse\n\t\t\tdistance = p->nr_targets / cxl_rr->nr_targets;\n\t\tfor (i = 0; i < cxl_rr->nr_targets_set; i++)\n\t\t\tif (ep->dport == cxlsd->target[i]) {\n\t\t\t\trc = check_last_peer(cxled, ep, cxl_rr,\n\t\t\t\t\t\t     distance);\n\t\t\t\tif (rc)\n\t\t\t\t\treturn rc;\n\t\t\t\tgoto out_target_set;\n\t\t\t}\n\t\tgoto add_target;\n\t}\n\n\tif (is_cxl_root(parent_port)) {\n\t\t \n\t\tparent_ig = p->interleave_granularity;\n\t\tparent_iw = cxlrd->cxlsd.cxld.interleave_ways;\n\t\t \n\t\tif (!is_power_of_2(parent_iw))\n\t\t\tparent_iw /= 3;\n\t} else {\n\t\tstruct cxl_region_ref *parent_rr;\n\t\tstruct cxl_decoder *parent_cxld;\n\n\t\tparent_rr = cxl_rr_load(parent_port, cxlr);\n\t\tparent_cxld = parent_rr->decoder;\n\t\tparent_ig = parent_cxld->interleave_granularity;\n\t\tparent_iw = parent_cxld->interleave_ways;\n\t}\n\n\trc = granularity_to_eig(parent_ig, &peig);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s: invalid parent granularity: %d\\n\",\n\t\t\tdev_name(parent_port->uport_dev),\n\t\t\tdev_name(&parent_port->dev), parent_ig);\n\t\treturn rc;\n\t}\n\n\trc = ways_to_eiw(parent_iw, &peiw);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s: invalid parent interleave: %d\\n\",\n\t\t\tdev_name(parent_port->uport_dev),\n\t\t\tdev_name(&parent_port->dev), parent_iw);\n\t\treturn rc;\n\t}\n\n\tiw = cxl_rr->nr_targets;\n\trc = ways_to_eiw(iw, &eiw);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s: invalid port interleave: %d\\n\",\n\t\t\tdev_name(port->uport_dev), dev_name(&port->dev), iw);\n\t\treturn rc;\n\t}\n\n\t \n\trc = granularity_to_eig(parent_ig * parent_iw, &eig);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev,\n\t\t\t\"%s: invalid granularity calculation (%d * %d)\\n\",\n\t\t\tdev_name(&parent_port->dev), parent_ig, parent_iw);\n\t\treturn rc;\n\t}\n\n\trc = eig_to_granularity(eig, &ig);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s: invalid interleave: %d\\n\",\n\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\t256 << eig);\n\t\treturn rc;\n\t}\n\n\tif (iw > 8 || iw > cxlsd->nr_targets) {\n\t\tdev_dbg(&cxlr->dev,\n\t\t\t\"%s:%s:%s: ways: %d overflows targets: %d\\n\",\n\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\tdev_name(&cxld->dev), iw, cxlsd->nr_targets);\n\t\treturn -ENXIO;\n\t}\n\n\tif (test_bit(CXL_REGION_F_AUTO, &cxlr->flags)) {\n\t\tif (cxld->interleave_ways != iw ||\n\t\t    cxld->interleave_granularity != ig ||\n\t\t    cxld->hpa_range.start != p->res->start ||\n\t\t    cxld->hpa_range.end != p->res->end ||\n\t\t    ((cxld->flags & CXL_DECODER_F_ENABLE) == 0)) {\n\t\t\tdev_err(&cxlr->dev,\n\t\t\t\t\"%s:%s %s expected iw: %d ig: %d %pr\\n\",\n\t\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\t\t__func__, iw, ig, p->res);\n\t\t\tdev_err(&cxlr->dev,\n\t\t\t\t\"%s:%s %s got iw: %d ig: %d state: %s %#llx:%#llx\\n\",\n\t\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\t\t__func__, cxld->interleave_ways,\n\t\t\t\tcxld->interleave_granularity,\n\t\t\t\t(cxld->flags & CXL_DECODER_F_ENABLE) ?\n\t\t\t\t\t\"enabled\" :\n\t\t\t\t\t\"disabled\",\n\t\t\t\tcxld->hpa_range.start, cxld->hpa_range.end);\n\t\t\treturn -ENXIO;\n\t\t}\n\t} else {\n\t\tcxld->interleave_ways = iw;\n\t\tcxld->interleave_granularity = ig;\n\t\tcxld->hpa_range = (struct range) {\n\t\t\t.start = p->res->start,\n\t\t\t.end = p->res->end,\n\t\t};\n\t}\n\tdev_dbg(&cxlr->dev, \"%s:%s iw: %d ig: %d\\n\", dev_name(port->uport_dev),\n\t\tdev_name(&port->dev), iw, ig);\nadd_target:\n\tif (cxl_rr->nr_targets_set == cxl_rr->nr_targets) {\n\t\tdev_dbg(&cxlr->dev,\n\t\t\t\"%s:%s: targets full trying to add %s:%s at %d\\n\",\n\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev), pos);\n\t\treturn -ENXIO;\n\t}\n\tif (test_bit(CXL_REGION_F_AUTO, &cxlr->flags)) {\n\t\tif (cxlsd->target[cxl_rr->nr_targets_set] != ep->dport) {\n\t\t\tdev_dbg(&cxlr->dev, \"%s:%s: %s expected %s at %d\\n\",\n\t\t\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\t\t\tdev_name(&cxlsd->cxld.dev),\n\t\t\t\tdev_name(ep->dport->dport_dev),\n\t\t\t\tcxl_rr->nr_targets_set);\n\t\t\treturn -ENXIO;\n\t\t}\n\t} else\n\t\tcxlsd->target[cxl_rr->nr_targets_set] = ep->dport;\n\tinc = 1;\nout_target_set:\n\tcxl_rr->nr_targets_set += inc;\n\tdev_dbg(&cxlr->dev, \"%s:%s target[%d] = %s for %s:%s @ %d\\n\",\n\t\tdev_name(port->uport_dev), dev_name(&port->dev),\n\t\tcxl_rr->nr_targets_set - 1, dev_name(ep->dport->dport_dev),\n\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev), pos);\n\n\treturn 0;\n}\n\nstatic void cxl_port_reset_targets(struct cxl_port *port,\n\t\t\t\t   struct cxl_region *cxlr)\n{\n\tstruct cxl_region_ref *cxl_rr = cxl_rr_load(port, cxlr);\n\tstruct cxl_decoder *cxld;\n\n\t \n\tif (!cxl_rr)\n\t\treturn;\n\tcxl_rr->nr_targets_set = 0;\n\n\tcxld = cxl_rr->decoder;\n\tcxld->hpa_range = (struct range) {\n\t\t.start = 0,\n\t\t.end = -1,\n\t};\n}\n\nstatic void cxl_region_teardown_targets(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_endpoint_decoder *cxled;\n\tstruct cxl_dev_state *cxlds;\n\tstruct cxl_memdev *cxlmd;\n\tstruct cxl_port *iter;\n\tstruct cxl_ep *ep;\n\tint i;\n\n\t \n\tif (test_bit(CXL_REGION_F_AUTO, &cxlr->flags))\n\t\treturn;\n\n\tfor (i = 0; i < p->nr_targets; i++) {\n\t\tcxled = p->targets[i];\n\t\tcxlmd = cxled_to_memdev(cxled);\n\t\tcxlds = cxlmd->cxlds;\n\n\t\tif (cxlds->rcd)\n\t\t\tcontinue;\n\n\t\titer = cxled_to_port(cxled);\n\t\twhile (!is_cxl_root(to_cxl_port(iter->dev.parent)))\n\t\t\titer = to_cxl_port(iter->dev.parent);\n\n\t\tfor (ep = cxl_ep_load(iter, cxlmd); iter;\n\t\t     iter = ep->next, ep = cxl_ep_load(iter, cxlmd))\n\t\t\tcxl_port_reset_targets(iter, cxlr);\n\t}\n}\n\nstatic int cxl_region_setup_targets(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_endpoint_decoder *cxled;\n\tstruct cxl_dev_state *cxlds;\n\tint i, rc, rch = 0, vh = 0;\n\tstruct cxl_memdev *cxlmd;\n\tstruct cxl_port *iter;\n\tstruct cxl_ep *ep;\n\n\tfor (i = 0; i < p->nr_targets; i++) {\n\t\tcxled = p->targets[i];\n\t\tcxlmd = cxled_to_memdev(cxled);\n\t\tcxlds = cxlmd->cxlds;\n\n\t\t \n\t\tif (!cxlds->rcd) {\n\t\t\tvh++;\n\t\t} else {\n\t\t\trch++;\n\t\t\tcontinue;\n\t\t}\n\n\t\titer = cxled_to_port(cxled);\n\t\twhile (!is_cxl_root(to_cxl_port(iter->dev.parent)))\n\t\t\titer = to_cxl_port(iter->dev.parent);\n\n\t\t \n\t\tfor (ep = cxl_ep_load(iter, cxlmd); iter;\n\t\t     iter = ep->next, ep = cxl_ep_load(iter, cxlmd)) {\n\t\t\trc = cxl_port_setup_targets(iter, cxlr, cxled);\n\t\t\tif (rc) {\n\t\t\t\tcxl_region_teardown_targets(cxlr);\n\t\t\t\treturn rc;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (rch && vh) {\n\t\tdev_err(&cxlr->dev, \"mismatched CXL topologies detected\\n\");\n\t\tcxl_region_teardown_targets(cxlr);\n\t\treturn -ENXIO;\n\t}\n\n\treturn 0;\n}\n\nstatic int cxl_region_validate_position(struct cxl_region *cxlr,\n\t\t\t\t\tstruct cxl_endpoint_decoder *cxled,\n\t\t\t\t\tint pos)\n{\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint i;\n\n\tif (pos < 0 || pos >= p->interleave_ways) {\n\t\tdev_dbg(&cxlr->dev, \"position %d out of range %d\\n\", pos,\n\t\t\tp->interleave_ways);\n\t\treturn -ENXIO;\n\t}\n\n\tif (p->targets[pos] == cxled)\n\t\treturn 0;\n\n\tif (p->targets[pos]) {\n\t\tstruct cxl_endpoint_decoder *cxled_target = p->targets[pos];\n\t\tstruct cxl_memdev *cxlmd_target = cxled_to_memdev(cxled_target);\n\n\t\tdev_dbg(&cxlr->dev, \"position %d already assigned to %s:%s\\n\",\n\t\t\tpos, dev_name(&cxlmd_target->dev),\n\t\t\tdev_name(&cxled_target->cxld.dev));\n\t\treturn -EBUSY;\n\t}\n\n\tfor (i = 0; i < p->interleave_ways; i++) {\n\t\tstruct cxl_endpoint_decoder *cxled_target;\n\t\tstruct cxl_memdev *cxlmd_target;\n\n\t\tcxled_target = p->targets[i];\n\t\tif (!cxled_target)\n\t\t\tcontinue;\n\n\t\tcxlmd_target = cxled_to_memdev(cxled_target);\n\t\tif (cxlmd_target == cxlmd) {\n\t\t\tdev_dbg(&cxlr->dev,\n\t\t\t\t\"%s already specified at position %d via: %s\\n\",\n\t\t\t\tdev_name(&cxlmd->dev), pos,\n\t\t\t\tdev_name(&cxled_target->cxld.dev));\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int cxl_region_attach_position(struct cxl_region *cxlr,\n\t\t\t\t      struct cxl_root_decoder *cxlrd,\n\t\t\t\t      struct cxl_endpoint_decoder *cxled,\n\t\t\t\t      const struct cxl_dport *dport, int pos)\n{\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct cxl_port *iter;\n\tint rc;\n\n\tif (cxlrd->calc_hb(cxlrd, pos) != dport) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s invalid target position for %s\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\tdev_name(&cxlrd->cxlsd.cxld.dev));\n\t\treturn -ENXIO;\n\t}\n\n\tfor (iter = cxled_to_port(cxled); !is_cxl_root(iter);\n\t     iter = to_cxl_port(iter->dev.parent)) {\n\t\trc = cxl_port_attach_region(iter, cxlr, cxled, pos);\n\t\tif (rc)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tfor (iter = cxled_to_port(cxled); !is_cxl_root(iter);\n\t     iter = to_cxl_port(iter->dev.parent))\n\t\tcxl_port_detach_region(iter, cxlr, cxled);\n\treturn rc;\n}\n\nstatic int cxl_region_attach_auto(struct cxl_region *cxlr,\n\t\t\t\t  struct cxl_endpoint_decoder *cxled, int pos)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\n\tif (cxled->state != CXL_DECODER_STATE_AUTO) {\n\t\tdev_err(&cxlr->dev,\n\t\t\t\"%s: unable to add decoder to autodetected region\\n\",\n\t\t\tdev_name(&cxled->cxld.dev));\n\t\treturn -EINVAL;\n\t}\n\n\tif (pos >= 0) {\n\t\tdev_dbg(&cxlr->dev, \"%s: expected auto position, not %d\\n\",\n\t\t\tdev_name(&cxled->cxld.dev), pos);\n\t\treturn -EINVAL;\n\t}\n\n\tif (p->nr_targets >= p->interleave_ways) {\n\t\tdev_err(&cxlr->dev, \"%s: no more target slots available\\n\",\n\t\t\tdev_name(&cxled->cxld.dev));\n\t\treturn -ENXIO;\n\t}\n\n\t \n\tpos = p->nr_targets;\n\tp->targets[pos] = cxled;\n\tcxled->pos = pos;\n\tp->nr_targets++;\n\n\treturn 0;\n}\n\nstatic int cmp_interleave_pos(const void *a, const void *b)\n{\n\tstruct cxl_endpoint_decoder *cxled_a = *(typeof(cxled_a) *)a;\n\tstruct cxl_endpoint_decoder *cxled_b = *(typeof(cxled_b) *)b;\n\n\treturn cxled_a->pos - cxled_b->pos;\n}\n\nstatic struct cxl_port *next_port(struct cxl_port *port)\n{\n\tif (!port->parent_dport)\n\t\treturn NULL;\n\treturn port->parent_dport->port;\n}\n\nstatic int match_switch_decoder_by_range(struct device *dev, void *data)\n{\n\tstruct cxl_switch_decoder *cxlsd;\n\tstruct range *r1, *r2 = data;\n\n\tif (!is_switch_decoder(dev))\n\t\treturn 0;\n\n\tcxlsd = to_cxl_switch_decoder(dev);\n\tr1 = &cxlsd->cxld.hpa_range;\n\n\tif (is_root_decoder(dev))\n\t\treturn range_contains(r1, r2);\n\treturn (r1->start == r2->start && r1->end == r2->end);\n}\n\nstatic int find_pos_and_ways(struct cxl_port *port, struct range *range,\n\t\t\t     int *pos, int *ways)\n{\n\tstruct cxl_switch_decoder *cxlsd;\n\tstruct cxl_port *parent;\n\tstruct device *dev;\n\tint rc = -ENXIO;\n\n\tparent = next_port(port);\n\tif (!parent)\n\t\treturn rc;\n\n\tdev = device_find_child(&parent->dev, range,\n\t\t\t\tmatch_switch_decoder_by_range);\n\tif (!dev) {\n\t\tdev_err(port->uport_dev,\n\t\t\t\"failed to find decoder mapping %#llx-%#llx\\n\",\n\t\t\trange->start, range->end);\n\t\treturn rc;\n\t}\n\tcxlsd = to_cxl_switch_decoder(dev);\n\t*ways = cxlsd->cxld.interleave_ways;\n\n\tfor (int i = 0; i < *ways; i++) {\n\t\tif (cxlsd->target[i] == port->parent_dport) {\n\t\t\t*pos = i;\n\t\t\trc = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\tput_device(dev);\n\n\treturn rc;\n}\n\n \nstatic int cxl_calc_interleave_pos(struct cxl_endpoint_decoder *cxled)\n{\n\tstruct cxl_port *iter, *port = cxled_to_port(cxled);\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct range *range = &cxled->cxld.hpa_range;\n\tint parent_ways = 0, parent_pos = 0, pos = 0;\n\tint rc;\n\n\t \n\n\t \n\tfor (iter = port; iter; iter = next_port(iter)) {\n\t\tif (is_cxl_root(iter))\n\t\t\tbreak;\n\n\t\trc = find_pos_and_ways(iter, range, &parent_pos, &parent_ways);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tpos = pos * parent_ways + parent_pos;\n\t}\n\n\tdev_dbg(&cxlmd->dev,\n\t\t\"decoder:%s parent:%s port:%s range:%#llx-%#llx pos:%d\\n\",\n\t\tdev_name(&cxled->cxld.dev), dev_name(cxlmd->dev.parent),\n\t\tdev_name(&port->dev), range->start, range->end, pos);\n\n\treturn pos;\n}\n\nstatic int cxl_region_sort_targets(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint i, rc = 0;\n\n\tfor (i = 0; i < p->nr_targets; i++) {\n\t\tstruct cxl_endpoint_decoder *cxled = p->targets[i];\n\n\t\tcxled->pos = cxl_calc_interleave_pos(cxled);\n\t\t \n\t\tif (cxled->pos < 0)\n\t\t\trc = -ENXIO;\n\t}\n\t \n\tsort(p->targets, p->nr_targets, sizeof(p->targets[0]),\n\t     cmp_interleave_pos, NULL);\n\n\tdev_dbg(&cxlr->dev, \"region sort %s\\n\", rc ? \"failed\" : \"successful\");\n\treturn rc;\n}\n\nstatic int cxl_region_attach(struct cxl_region *cxlr,\n\t\t\t     struct cxl_endpoint_decoder *cxled, int pos)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(cxlr->dev.parent);\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_port *ep_port, *root_port;\n\tstruct cxl_dport *dport;\n\tint rc = -ENXIO;\n\n\tif (cxled->mode != cxlr->mode) {\n\t\tdev_dbg(&cxlr->dev, \"%s region mode: %d mismatch: %d\\n\",\n\t\t\tdev_name(&cxled->cxld.dev), cxlr->mode, cxled->mode);\n\t\treturn -EINVAL;\n\t}\n\n\tif (cxled->mode == CXL_DECODER_DEAD) {\n\t\tdev_dbg(&cxlr->dev, \"%s dead\\n\", dev_name(&cxled->cxld.dev));\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tif (p->state > CXL_CONFIG_INTERLEAVE_ACTIVE) {\n\t\tdev_dbg(&cxlr->dev, \"region already active\\n\");\n\t\treturn -EBUSY;\n\t} else if (p->state < CXL_CONFIG_INTERLEAVE_ACTIVE) {\n\t\tdev_dbg(&cxlr->dev, \"interleave config missing\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\tif (p->nr_targets >= p->interleave_ways) {\n\t\tdev_dbg(&cxlr->dev, \"region already has %d endpoints\\n\",\n\t\t\tp->nr_targets);\n\t\treturn -EINVAL;\n\t}\n\n\tep_port = cxled_to_port(cxled);\n\troot_port = cxlrd_to_port(cxlrd);\n\tdport = cxl_find_dport_by_dev(root_port, ep_port->host_bridge);\n\tif (!dport) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s invalid target for %s\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\tdev_name(cxlr->dev.parent));\n\t\treturn -ENXIO;\n\t}\n\n\tif (cxled->cxld.target_type != cxlr->type) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s type mismatch: %d vs %d\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\tcxled->cxld.target_type, cxlr->type);\n\t\treturn -ENXIO;\n\t}\n\n\tif (!cxled->dpa_res) {\n\t\tdev_dbg(&cxlr->dev, \"%s:%s: missing DPA allocation.\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev));\n\t\treturn -ENXIO;\n\t}\n\n\tif (resource_size(cxled->dpa_res) * p->interleave_ways !=\n\t    resource_size(p->res)) {\n\t\tdev_dbg(&cxlr->dev,\n\t\t\t\"%s:%s: decoder-size-%#llx * ways-%d != region-size-%#llx\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\t(u64)resource_size(cxled->dpa_res), p->interleave_ways,\n\t\t\t(u64)resource_size(p->res));\n\t\treturn -EINVAL;\n\t}\n\n\tif (test_bit(CXL_REGION_F_AUTO, &cxlr->flags)) {\n\t\tint i;\n\n\t\trc = cxl_region_attach_auto(cxlr, cxled, pos);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\tif (p->nr_targets < p->interleave_ways)\n\t\t\treturn 0;\n\n\t\t \n\t\trc = cxl_region_sort_targets(cxlr);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tfor (i = 0; i < p->nr_targets; i++) {\n\t\t\tcxled = p->targets[i];\n\t\t\tep_port = cxled_to_port(cxled);\n\t\t\tdport = cxl_find_dport_by_dev(root_port,\n\t\t\t\t\t\t      ep_port->host_bridge);\n\t\t\trc = cxl_region_attach_position(cxlr, cxlrd, cxled,\n\t\t\t\t\t\t\tdport, i);\n\t\t\tif (rc)\n\t\t\t\treturn rc;\n\t\t}\n\n\t\trc = cxl_region_setup_targets(cxlr);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\t \n\t\tp->state = CXL_CONFIG_COMMIT;\n\n\t\treturn 0;\n\t}\n\n\trc = cxl_region_validate_position(cxlr, cxled, pos);\n\tif (rc)\n\t\treturn rc;\n\n\trc = cxl_region_attach_position(cxlr, cxlrd, cxled, dport, pos);\n\tif (rc)\n\t\treturn rc;\n\n\tp->targets[pos] = cxled;\n\tcxled->pos = pos;\n\tp->nr_targets++;\n\n\tif (p->nr_targets == p->interleave_ways) {\n\t\trc = cxl_region_setup_targets(cxlr);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tp->state = CXL_CONFIG_ACTIVE;\n\t}\n\n\tcxled->cxld.interleave_ways = p->interleave_ways;\n\tcxled->cxld.interleave_granularity = p->interleave_granularity;\n\tcxled->cxld.hpa_range = (struct range) {\n\t\t.start = p->res->start,\n\t\t.end = p->res->end,\n\t};\n\n\tif (p->nr_targets != p->interleave_ways)\n\t\treturn 0;\n\n\t \n\tfor (int i = 0; i < p->nr_targets; i++) {\n\t\tstruct cxl_endpoint_decoder *cxled = p->targets[i];\n\t\tint test_pos;\n\n\t\ttest_pos = cxl_calc_interleave_pos(cxled);\n\t\tdev_dbg(&cxled->cxld.dev,\n\t\t\t\"Test cxl_calc_interleave_pos(): %s test_pos:%d cxled->pos:%d\\n\",\n\t\t\t(test_pos == cxled->pos) ? \"success\" : \"fail\",\n\t\t\ttest_pos, cxled->pos);\n\t}\n\n\treturn 0;\n}\n\nstatic int cxl_region_detach(struct cxl_endpoint_decoder *cxled)\n{\n\tstruct cxl_port *iter, *ep_port = cxled_to_port(cxled);\n\tstruct cxl_region *cxlr = cxled->cxld.region;\n\tstruct cxl_region_params *p;\n\tint rc = 0;\n\n\tlockdep_assert_held_write(&cxl_region_rwsem);\n\n\tif (!cxlr)\n\t\treturn 0;\n\n\tp = &cxlr->params;\n\tget_device(&cxlr->dev);\n\n\tif (p->state > CXL_CONFIG_ACTIVE) {\n\t\t \n\t\trc = cxl_region_decode_reset(cxlr, p->interleave_ways);\n\t\tif (rc)\n\t\t\tgoto out;\n\t\tp->state = CXL_CONFIG_ACTIVE;\n\t}\n\n\tfor (iter = ep_port; !is_cxl_root(iter);\n\t     iter = to_cxl_port(iter->dev.parent))\n\t\tcxl_port_detach_region(iter, cxlr, cxled);\n\n\tif (cxled->pos < 0 || cxled->pos >= p->interleave_ways ||\n\t    p->targets[cxled->pos] != cxled) {\n\t\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\n\t\tdev_WARN_ONCE(&cxlr->dev, 1, \"expected %s:%s at position %d\\n\",\n\t\t\t      dev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\t      cxled->pos);\n\t\tgoto out;\n\t}\n\n\tif (p->state == CXL_CONFIG_ACTIVE) {\n\t\tp->state = CXL_CONFIG_INTERLEAVE_ACTIVE;\n\t\tcxl_region_teardown_targets(cxlr);\n\t}\n\tp->targets[cxled->pos] = NULL;\n\tp->nr_targets--;\n\tcxled->cxld.hpa_range = (struct range) {\n\t\t.start = 0,\n\t\t.end = -1,\n\t};\n\n\t \n\tup_write(&cxl_region_rwsem);\n\tdevice_release_driver(&cxlr->dev);\n\tdown_write(&cxl_region_rwsem);\nout:\n\tput_device(&cxlr->dev);\n\treturn rc;\n}\n\nvoid cxl_decoder_kill_region(struct cxl_endpoint_decoder *cxled)\n{\n\tdown_write(&cxl_region_rwsem);\n\tcxled->mode = CXL_DECODER_DEAD;\n\tcxl_region_detach(cxled);\n\tup_write(&cxl_region_rwsem);\n}\n\nstatic int attach_target(struct cxl_region *cxlr,\n\t\t\t struct cxl_endpoint_decoder *cxled, int pos,\n\t\t\t unsigned int state)\n{\n\tint rc = 0;\n\n\tif (state == TASK_INTERRUPTIBLE)\n\t\trc = down_write_killable(&cxl_region_rwsem);\n\telse\n\t\tdown_write(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\n\tdown_read(&cxl_dpa_rwsem);\n\trc = cxl_region_attach(cxlr, cxled, pos);\n\tup_read(&cxl_dpa_rwsem);\n\tup_write(&cxl_region_rwsem);\n\treturn rc;\n}\n\nstatic int detach_target(struct cxl_region *cxlr, int pos)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint rc;\n\n\trc = down_write_killable(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\n\tif (pos >= p->interleave_ways) {\n\t\tdev_dbg(&cxlr->dev, \"position %d out of range %d\\n\", pos,\n\t\t\tp->interleave_ways);\n\t\trc = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (!p->targets[pos]) {\n\t\trc = 0;\n\t\tgoto out;\n\t}\n\n\trc = cxl_region_detach(p->targets[pos]);\nout:\n\tup_write(&cxl_region_rwsem);\n\treturn rc;\n}\n\nstatic size_t store_targetN(struct cxl_region *cxlr, const char *buf, int pos,\n\t\t\t    size_t len)\n{\n\tint rc;\n\n\tif (sysfs_streq(buf, \"\\n\"))\n\t\trc = detach_target(cxlr, pos);\n\telse {\n\t\tstruct device *dev;\n\n\t\tdev = bus_find_device_by_name(&cxl_bus_type, NULL, buf);\n\t\tif (!dev)\n\t\t\treturn -ENODEV;\n\n\t\tif (!is_endpoint_decoder(dev)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\trc = attach_target(cxlr, to_cxl_endpoint_decoder(dev), pos,\n\t\t\t\t   TASK_INTERRUPTIBLE);\nout:\n\t\tput_device(dev);\n\t}\n\n\tif (rc < 0)\n\t\treturn rc;\n\treturn len;\n}\n\n#define TARGET_ATTR_RW(n)                                              \\\nstatic ssize_t target##n##_show(                                       \\\n\tstruct device *dev, struct device_attribute *attr, char *buf)  \\\n{                                                                      \\\n\treturn show_targetN(to_cxl_region(dev), buf, (n));             \\\n}                                                                      \\\nstatic ssize_t target##n##_store(struct device *dev,                   \\\n\t\t\t\t struct device_attribute *attr,        \\\n\t\t\t\t const char *buf, size_t len)          \\\n{                                                                      \\\n\treturn store_targetN(to_cxl_region(dev), buf, (n), len);       \\\n}                                                                      \\\nstatic DEVICE_ATTR_RW(target##n)\n\nTARGET_ATTR_RW(0);\nTARGET_ATTR_RW(1);\nTARGET_ATTR_RW(2);\nTARGET_ATTR_RW(3);\nTARGET_ATTR_RW(4);\nTARGET_ATTR_RW(5);\nTARGET_ATTR_RW(6);\nTARGET_ATTR_RW(7);\nTARGET_ATTR_RW(8);\nTARGET_ATTR_RW(9);\nTARGET_ATTR_RW(10);\nTARGET_ATTR_RW(11);\nTARGET_ATTR_RW(12);\nTARGET_ATTR_RW(13);\nTARGET_ATTR_RW(14);\nTARGET_ATTR_RW(15);\n\nstatic struct attribute *target_attrs[] = {\n\t&dev_attr_target0.attr,\n\t&dev_attr_target1.attr,\n\t&dev_attr_target2.attr,\n\t&dev_attr_target3.attr,\n\t&dev_attr_target4.attr,\n\t&dev_attr_target5.attr,\n\t&dev_attr_target6.attr,\n\t&dev_attr_target7.attr,\n\t&dev_attr_target8.attr,\n\t&dev_attr_target9.attr,\n\t&dev_attr_target10.attr,\n\t&dev_attr_target11.attr,\n\t&dev_attr_target12.attr,\n\t&dev_attr_target13.attr,\n\t&dev_attr_target14.attr,\n\t&dev_attr_target15.attr,\n\tNULL,\n};\n\nstatic umode_t cxl_region_target_visible(struct kobject *kobj,\n\t\t\t\t\t struct attribute *a, int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\n\tif (n < p->interleave_ways)\n\t\treturn a->mode;\n\treturn 0;\n}\n\nstatic const struct attribute_group cxl_region_target_group = {\n\t.attrs = target_attrs,\n\t.is_visible = cxl_region_target_visible,\n};\n\nstatic const struct attribute_group *get_cxl_region_target_group(void)\n{\n\treturn &cxl_region_target_group;\n}\n\nstatic const struct attribute_group *region_groups[] = {\n\t&cxl_base_attribute_group,\n\t&cxl_region_group,\n\t&cxl_region_target_group,\n\tNULL,\n};\n\nstatic void cxl_region_release(struct device *dev)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev->parent);\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tint id = atomic_read(&cxlrd->region_id);\n\n\t \n\tif (cxlr->id < id)\n\t\tif (atomic_try_cmpxchg(&cxlrd->region_id, &id, cxlr->id)) {\n\t\t\tmemregion_free(id);\n\t\t\tgoto out;\n\t\t}\n\n\tmemregion_free(cxlr->id);\nout:\n\tput_device(dev->parent);\n\tkfree(cxlr);\n}\n\nconst struct device_type cxl_region_type = {\n\t.name = \"cxl_region\",\n\t.release = cxl_region_release,\n\t.groups = region_groups\n};\n\nbool is_cxl_region(struct device *dev)\n{\n\treturn dev->type == &cxl_region_type;\n}\nEXPORT_SYMBOL_NS_GPL(is_cxl_region, CXL);\n\nstatic struct cxl_region *to_cxl_region(struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev, dev->type != &cxl_region_type,\n\t\t\t  \"not a cxl_region device\\n\"))\n\t\treturn NULL;\n\n\treturn container_of(dev, struct cxl_region, dev);\n}\n\nstatic void unregister_region(void *dev)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint i;\n\n\tdevice_del(dev);\n\n\t \n\tfor (i = 0; i < p->interleave_ways; i++)\n\t\tdetach_target(cxlr, i);\n\n\tcxl_region_iomem_release(cxlr);\n\tput_device(dev);\n}\n\nstatic struct lock_class_key cxl_region_key;\n\nstatic struct cxl_region *cxl_region_alloc(struct cxl_root_decoder *cxlrd, int id)\n{\n\tstruct cxl_region *cxlr;\n\tstruct device *dev;\n\n\tcxlr = kzalloc(sizeof(*cxlr), GFP_KERNEL);\n\tif (!cxlr) {\n\t\tmemregion_free(id);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tdev = &cxlr->dev;\n\tdevice_initialize(dev);\n\tlockdep_set_class(&dev->mutex, &cxl_region_key);\n\tdev->parent = &cxlrd->cxlsd.cxld.dev;\n\t \n\tget_device(dev->parent);\n\tdevice_set_pm_not_required(dev);\n\tdev->bus = &cxl_bus_type;\n\tdev->type = &cxl_region_type;\n\tcxlr->id = id;\n\n\treturn cxlr;\n}\n\n \nstatic struct cxl_region *devm_cxl_add_region(struct cxl_root_decoder *cxlrd,\n\t\t\t\t\t      int id,\n\t\t\t\t\t      enum cxl_decoder_mode mode,\n\t\t\t\t\t      enum cxl_decoder_type type)\n{\n\tstruct cxl_port *port = to_cxl_port(cxlrd->cxlsd.cxld.dev.parent);\n\tstruct cxl_region *cxlr;\n\tstruct device *dev;\n\tint rc;\n\n\tswitch (mode) {\n\tcase CXL_DECODER_RAM:\n\tcase CXL_DECODER_PMEM:\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&cxlrd->cxlsd.cxld.dev, \"unsupported mode %d\\n\", mode);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tcxlr = cxl_region_alloc(cxlrd, id);\n\tif (IS_ERR(cxlr))\n\t\treturn cxlr;\n\tcxlr->mode = mode;\n\tcxlr->type = type;\n\n\tdev = &cxlr->dev;\n\trc = dev_set_name(dev, \"region%d\", id);\n\tif (rc)\n\t\tgoto err;\n\n\trc = device_add(dev);\n\tif (rc)\n\t\tgoto err;\n\n\trc = devm_add_action_or_reset(port->uport_dev, unregister_region, cxlr);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\tdev_dbg(port->uport_dev, \"%s: created %s\\n\",\n\t\tdev_name(&cxlrd->cxlsd.cxld.dev), dev_name(dev));\n\treturn cxlr;\n\nerr:\n\tput_device(dev);\n\treturn ERR_PTR(rc);\n}\n\nstatic ssize_t __create_region_show(struct cxl_root_decoder *cxlrd, char *buf)\n{\n\treturn sysfs_emit(buf, \"region%u\\n\", atomic_read(&cxlrd->region_id));\n}\n\nstatic ssize_t create_pmem_region_show(struct device *dev,\n\t\t\t\t       struct device_attribute *attr, char *buf)\n{\n\treturn __create_region_show(to_cxl_root_decoder(dev), buf);\n}\n\nstatic ssize_t create_ram_region_show(struct device *dev,\n\t\t\t\t      struct device_attribute *attr, char *buf)\n{\n\treturn __create_region_show(to_cxl_root_decoder(dev), buf);\n}\n\nstatic struct cxl_region *__create_region(struct cxl_root_decoder *cxlrd,\n\t\t\t\t\t  enum cxl_decoder_mode mode, int id)\n{\n\tint rc;\n\n\trc = memregion_alloc(GFP_KERNEL);\n\tif (rc < 0)\n\t\treturn ERR_PTR(rc);\n\n\tif (atomic_cmpxchg(&cxlrd->region_id, id, rc) != id) {\n\t\tmemregion_free(rc);\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\n\treturn devm_cxl_add_region(cxlrd, id, mode, CXL_DECODER_HOSTONLYMEM);\n}\n\nstatic ssize_t create_pmem_region_store(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tconst char *buf, size_t len)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev);\n\tstruct cxl_region *cxlr;\n\tint rc, id;\n\n\trc = sscanf(buf, \"region%d\\n\", &id);\n\tif (rc != 1)\n\t\treturn -EINVAL;\n\n\tcxlr = __create_region(cxlrd, CXL_DECODER_PMEM, id);\n\tif (IS_ERR(cxlr))\n\t\treturn PTR_ERR(cxlr);\n\n\treturn len;\n}\nDEVICE_ATTR_RW(create_pmem_region);\n\nstatic ssize_t create_ram_region_store(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       const char *buf, size_t len)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev);\n\tstruct cxl_region *cxlr;\n\tint rc, id;\n\n\trc = sscanf(buf, \"region%d\\n\", &id);\n\tif (rc != 1)\n\t\treturn -EINVAL;\n\n\tcxlr = __create_region(cxlrd, CXL_DECODER_RAM, id);\n\tif (IS_ERR(cxlr))\n\t\treturn PTR_ERR(cxlr);\n\n\treturn len;\n}\nDEVICE_ATTR_RW(create_ram_region);\n\nstatic ssize_t region_show(struct device *dev, struct device_attribute *attr,\n\t\t\t   char *buf)\n{\n\tstruct cxl_decoder *cxld = to_cxl_decoder(dev);\n\tssize_t rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc)\n\t\treturn rc;\n\n\tif (cxld->region)\n\t\trc = sysfs_emit(buf, \"%s\\n\", dev_name(&cxld->region->dev));\n\telse\n\t\trc = sysfs_emit(buf, \"\\n\");\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\nDEVICE_ATTR_RO(region);\n\nstatic struct cxl_region *\ncxl_find_region_by_name(struct cxl_root_decoder *cxlrd, const char *name)\n{\n\tstruct cxl_decoder *cxld = &cxlrd->cxlsd.cxld;\n\tstruct device *region_dev;\n\n\tregion_dev = device_find_child_by_name(&cxld->dev, name);\n\tif (!region_dev)\n\t\treturn ERR_PTR(-ENODEV);\n\n\treturn to_cxl_region(region_dev);\n}\n\nstatic ssize_t delete_region_store(struct device *dev,\n\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t   const char *buf, size_t len)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev);\n\tstruct cxl_port *port = to_cxl_port(dev->parent);\n\tstruct cxl_region *cxlr;\n\n\tcxlr = cxl_find_region_by_name(cxlrd, buf);\n\tif (IS_ERR(cxlr))\n\t\treturn PTR_ERR(cxlr);\n\n\tdevm_release_action(port->uport_dev, unregister_region, cxlr);\n\tput_device(&cxlr->dev);\n\n\treturn len;\n}\nDEVICE_ATTR_WO(delete_region);\n\nstatic void cxl_pmem_region_release(struct device *dev)\n{\n\tstruct cxl_pmem_region *cxlr_pmem = to_cxl_pmem_region(dev);\n\tint i;\n\n\tfor (i = 0; i < cxlr_pmem->nr_mappings; i++) {\n\t\tstruct cxl_memdev *cxlmd = cxlr_pmem->mapping[i].cxlmd;\n\n\t\tput_device(&cxlmd->dev);\n\t}\n\n\tkfree(cxlr_pmem);\n}\n\nstatic const struct attribute_group *cxl_pmem_region_attribute_groups[] = {\n\t&cxl_base_attribute_group,\n\tNULL,\n};\n\nconst struct device_type cxl_pmem_region_type = {\n\t.name = \"cxl_pmem_region\",\n\t.release = cxl_pmem_region_release,\n\t.groups = cxl_pmem_region_attribute_groups,\n};\n\nbool is_cxl_pmem_region(struct device *dev)\n{\n\treturn dev->type == &cxl_pmem_region_type;\n}\nEXPORT_SYMBOL_NS_GPL(is_cxl_pmem_region, CXL);\n\nstruct cxl_pmem_region *to_cxl_pmem_region(struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev, !is_cxl_pmem_region(dev),\n\t\t\t  \"not a cxl_pmem_region device\\n\"))\n\t\treturn NULL;\n\treturn container_of(dev, struct cxl_pmem_region, dev);\n}\nEXPORT_SYMBOL_NS_GPL(to_cxl_pmem_region, CXL);\n\nstruct cxl_poison_context {\n\tstruct cxl_port *port;\n\tenum cxl_decoder_mode mode;\n\tu64 offset;\n};\n\nstatic int cxl_get_poison_unmapped(struct cxl_memdev *cxlmd,\n\t\t\t\t   struct cxl_poison_context *ctx)\n{\n\tstruct cxl_dev_state *cxlds = cxlmd->cxlds;\n\tu64 offset, length;\n\tint rc = 0;\n\n\t \n\n\tif (ctx->mode == CXL_DECODER_RAM) {\n\t\toffset = ctx->offset;\n\t\tlength = resource_size(&cxlds->ram_res) - offset;\n\t\trc = cxl_mem_get_poison(cxlmd, offset, length, NULL);\n\t\tif (rc == -EFAULT)\n\t\t\trc = 0;\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\tif (ctx->mode == CXL_DECODER_PMEM) {\n\t\toffset = ctx->offset;\n\t\tlength = resource_size(&cxlds->dpa_res) - offset;\n\t\tif (!length)\n\t\t\treturn 0;\n\t} else if (resource_size(&cxlds->pmem_res)) {\n\t\toffset = cxlds->pmem_res.start;\n\t\tlength = resource_size(&cxlds->pmem_res);\n\t} else {\n\t\treturn 0;\n\t}\n\n\treturn cxl_mem_get_poison(cxlmd, offset, length, NULL);\n}\n\nstatic int poison_by_decoder(struct device *dev, void *arg)\n{\n\tstruct cxl_poison_context *ctx = arg;\n\tstruct cxl_endpoint_decoder *cxled;\n\tstruct cxl_memdev *cxlmd;\n\tu64 offset, length;\n\tint rc = 0;\n\n\tif (!is_endpoint_decoder(dev))\n\t\treturn rc;\n\n\tcxled = to_cxl_endpoint_decoder(dev);\n\tif (!cxled->dpa_res || !resource_size(cxled->dpa_res))\n\t\treturn rc;\n\n\t \n\tif (cxled->mode == CXL_DECODER_MIXED) {\n\t\tdev_dbg(dev, \"poison list read unsupported in mixed mode\\n\");\n\t\treturn rc;\n\t}\n\n\tcxlmd = cxled_to_memdev(cxled);\n\tif (cxled->skip) {\n\t\toffset = cxled->dpa_res->start - cxled->skip;\n\t\tlength = cxled->skip;\n\t\trc = cxl_mem_get_poison(cxlmd, offset, length, NULL);\n\t\tif (rc == -EFAULT && cxled->mode == CXL_DECODER_RAM)\n\t\t\trc = 0;\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\toffset = cxled->dpa_res->start;\n\tlength = cxled->dpa_res->end - offset + 1;\n\trc = cxl_mem_get_poison(cxlmd, offset, length, cxled->cxld.region);\n\tif (rc == -EFAULT && cxled->mode == CXL_DECODER_RAM)\n\t\trc = 0;\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (cxled->cxld.id == ctx->port->commit_end) {\n\t\tctx->offset = cxled->dpa_res->end + 1;\n\t\tctx->mode = cxled->mode;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nint cxl_get_poison_by_endpoint(struct cxl_port *port)\n{\n\tstruct cxl_poison_context ctx;\n\tint rc = 0;\n\n\tctx = (struct cxl_poison_context) {\n\t\t.port = port\n\t};\n\n\trc = device_for_each_child(&port->dev, &ctx, poison_by_decoder);\n\tif (rc == 1)\n\t\trc = cxl_get_poison_unmapped(to_cxl_memdev(port->uport_dev),\n\t\t\t\t\t     &ctx);\n\n\treturn rc;\n}\n\nstatic struct lock_class_key cxl_pmem_region_key;\n\nstatic struct cxl_pmem_region *cxl_pmem_region_alloc(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_nvdimm_bridge *cxl_nvb;\n\tstruct cxl_pmem_region *cxlr_pmem;\n\tstruct device *dev;\n\tint i;\n\n\tdown_read(&cxl_region_rwsem);\n\tif (p->state != CXL_CONFIG_COMMIT) {\n\t\tcxlr_pmem = ERR_PTR(-ENXIO);\n\t\tgoto out;\n\t}\n\n\tcxlr_pmem = kzalloc(struct_size(cxlr_pmem, mapping, p->nr_targets),\n\t\t\t    GFP_KERNEL);\n\tif (!cxlr_pmem) {\n\t\tcxlr_pmem = ERR_PTR(-ENOMEM);\n\t\tgoto out;\n\t}\n\n\tcxlr_pmem->hpa_range.start = p->res->start;\n\tcxlr_pmem->hpa_range.end = p->res->end;\n\n\t \n\tcxlr_pmem->nr_mappings = p->nr_targets;\n\tfor (i = 0; i < p->nr_targets; i++) {\n\t\tstruct cxl_endpoint_decoder *cxled = p->targets[i];\n\t\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\t\tstruct cxl_pmem_region_mapping *m = &cxlr_pmem->mapping[i];\n\n\t\t \n\t\tif (i == 0) {\n\t\t\tcxl_nvb = cxl_find_nvdimm_bridge(cxlmd);\n\t\t\tif (!cxl_nvb) {\n\t\t\t\tcxlr_pmem = ERR_PTR(-ENODEV);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tcxlr->cxl_nvb = cxl_nvb;\n\t\t}\n\t\tm->cxlmd = cxlmd;\n\t\tget_device(&cxlmd->dev);\n\t\tm->start = cxled->dpa_res->start;\n\t\tm->size = resource_size(cxled->dpa_res);\n\t\tm->position = i;\n\t}\n\n\tdev = &cxlr_pmem->dev;\n\tcxlr_pmem->cxlr = cxlr;\n\tcxlr->cxlr_pmem = cxlr_pmem;\n\tdevice_initialize(dev);\n\tlockdep_set_class(&dev->mutex, &cxl_pmem_region_key);\n\tdevice_set_pm_not_required(dev);\n\tdev->parent = &cxlr->dev;\n\tdev->bus = &cxl_bus_type;\n\tdev->type = &cxl_pmem_region_type;\nout:\n\tup_read(&cxl_region_rwsem);\n\n\treturn cxlr_pmem;\n}\n\nstatic void cxl_dax_region_release(struct device *dev)\n{\n\tstruct cxl_dax_region *cxlr_dax = to_cxl_dax_region(dev);\n\n\tkfree(cxlr_dax);\n}\n\nstatic const struct attribute_group *cxl_dax_region_attribute_groups[] = {\n\t&cxl_base_attribute_group,\n\tNULL,\n};\n\nconst struct device_type cxl_dax_region_type = {\n\t.name = \"cxl_dax_region\",\n\t.release = cxl_dax_region_release,\n\t.groups = cxl_dax_region_attribute_groups,\n};\n\nstatic bool is_cxl_dax_region(struct device *dev)\n{\n\treturn dev->type == &cxl_dax_region_type;\n}\n\nstruct cxl_dax_region *to_cxl_dax_region(struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev, !is_cxl_dax_region(dev),\n\t\t\t  \"not a cxl_dax_region device\\n\"))\n\t\treturn NULL;\n\treturn container_of(dev, struct cxl_dax_region, dev);\n}\nEXPORT_SYMBOL_NS_GPL(to_cxl_dax_region, CXL);\n\nstatic struct lock_class_key cxl_dax_region_key;\n\nstatic struct cxl_dax_region *cxl_dax_region_alloc(struct cxl_region *cxlr)\n{\n\tstruct cxl_region_params *p = &cxlr->params;\n\tstruct cxl_dax_region *cxlr_dax;\n\tstruct device *dev;\n\n\tdown_read(&cxl_region_rwsem);\n\tif (p->state != CXL_CONFIG_COMMIT) {\n\t\tcxlr_dax = ERR_PTR(-ENXIO);\n\t\tgoto out;\n\t}\n\n\tcxlr_dax = kzalloc(sizeof(*cxlr_dax), GFP_KERNEL);\n\tif (!cxlr_dax) {\n\t\tcxlr_dax = ERR_PTR(-ENOMEM);\n\t\tgoto out;\n\t}\n\n\tcxlr_dax->hpa_range.start = p->res->start;\n\tcxlr_dax->hpa_range.end = p->res->end;\n\n\tdev = &cxlr_dax->dev;\n\tcxlr_dax->cxlr = cxlr;\n\tdevice_initialize(dev);\n\tlockdep_set_class(&dev->mutex, &cxl_dax_region_key);\n\tdevice_set_pm_not_required(dev);\n\tdev->parent = &cxlr->dev;\n\tdev->bus = &cxl_bus_type;\n\tdev->type = &cxl_dax_region_type;\nout:\n\tup_read(&cxl_region_rwsem);\n\n\treturn cxlr_dax;\n}\n\nstatic void cxlr_pmem_unregister(void *_cxlr_pmem)\n{\n\tstruct cxl_pmem_region *cxlr_pmem = _cxlr_pmem;\n\tstruct cxl_region *cxlr = cxlr_pmem->cxlr;\n\tstruct cxl_nvdimm_bridge *cxl_nvb = cxlr->cxl_nvb;\n\n\t \n\tdevice_lock_assert(&cxl_nvb->dev);\n\tcxlr->cxlr_pmem = NULL;\n\tcxlr_pmem->cxlr = NULL;\n\tdevice_unregister(&cxlr_pmem->dev);\n}\n\nstatic void cxlr_release_nvdimm(void *_cxlr)\n{\n\tstruct cxl_region *cxlr = _cxlr;\n\tstruct cxl_nvdimm_bridge *cxl_nvb = cxlr->cxl_nvb;\n\n\tdevice_lock(&cxl_nvb->dev);\n\tif (cxlr->cxlr_pmem)\n\t\tdevm_release_action(&cxl_nvb->dev, cxlr_pmem_unregister,\n\t\t\t\t    cxlr->cxlr_pmem);\n\tdevice_unlock(&cxl_nvb->dev);\n\tcxlr->cxl_nvb = NULL;\n\tput_device(&cxl_nvb->dev);\n}\n\n \nstatic int devm_cxl_add_pmem_region(struct cxl_region *cxlr)\n{\n\tstruct cxl_pmem_region *cxlr_pmem;\n\tstruct cxl_nvdimm_bridge *cxl_nvb;\n\tstruct device *dev;\n\tint rc;\n\n\tcxlr_pmem = cxl_pmem_region_alloc(cxlr);\n\tif (IS_ERR(cxlr_pmem))\n\t\treturn PTR_ERR(cxlr_pmem);\n\tcxl_nvb = cxlr->cxl_nvb;\n\n\tdev = &cxlr_pmem->dev;\n\trc = dev_set_name(dev, \"pmem_region%d\", cxlr->id);\n\tif (rc)\n\t\tgoto err;\n\n\trc = device_add(dev);\n\tif (rc)\n\t\tgoto err;\n\n\tdev_dbg(&cxlr->dev, \"%s: register %s\\n\", dev_name(dev->parent),\n\t\tdev_name(dev));\n\n\tdevice_lock(&cxl_nvb->dev);\n\tif (cxl_nvb->dev.driver)\n\t\trc = devm_add_action_or_reset(&cxl_nvb->dev,\n\t\t\t\t\t      cxlr_pmem_unregister, cxlr_pmem);\n\telse\n\t\trc = -ENXIO;\n\tdevice_unlock(&cxl_nvb->dev);\n\n\tif (rc)\n\t\tgoto err_bridge;\n\n\t \n\treturn devm_add_action_or_reset(&cxlr->dev, cxlr_release_nvdimm, cxlr);\n\nerr:\n\tput_device(dev);\nerr_bridge:\n\tput_device(&cxl_nvb->dev);\n\tcxlr->cxl_nvb = NULL;\n\treturn rc;\n}\n\nstatic void cxlr_dax_unregister(void *_cxlr_dax)\n{\n\tstruct cxl_dax_region *cxlr_dax = _cxlr_dax;\n\n\tdevice_unregister(&cxlr_dax->dev);\n}\n\nstatic int devm_cxl_add_dax_region(struct cxl_region *cxlr)\n{\n\tstruct cxl_dax_region *cxlr_dax;\n\tstruct device *dev;\n\tint rc;\n\n\tcxlr_dax = cxl_dax_region_alloc(cxlr);\n\tif (IS_ERR(cxlr_dax))\n\t\treturn PTR_ERR(cxlr_dax);\n\n\tdev = &cxlr_dax->dev;\n\trc = dev_set_name(dev, \"dax_region%d\", cxlr->id);\n\tif (rc)\n\t\tgoto err;\n\n\trc = device_add(dev);\n\tif (rc)\n\t\tgoto err;\n\n\tdev_dbg(&cxlr->dev, \"%s: register %s\\n\", dev_name(dev->parent),\n\t\tdev_name(dev));\n\n\treturn devm_add_action_or_reset(&cxlr->dev, cxlr_dax_unregister,\n\t\t\t\t\tcxlr_dax);\nerr:\n\tput_device(dev);\n\treturn rc;\n}\n\nstatic int match_root_decoder_by_range(struct device *dev, void *data)\n{\n\tstruct range *r1, *r2 = data;\n\tstruct cxl_root_decoder *cxlrd;\n\n\tif (!is_root_decoder(dev))\n\t\treturn 0;\n\n\tcxlrd = to_cxl_root_decoder(dev);\n\tr1 = &cxlrd->cxlsd.cxld.hpa_range;\n\treturn range_contains(r1, r2);\n}\n\nstatic int match_region_by_range(struct device *dev, void *data)\n{\n\tstruct cxl_region_params *p;\n\tstruct cxl_region *cxlr;\n\tstruct range *r = data;\n\tint rc = 0;\n\n\tif (!is_cxl_region(dev))\n\t\treturn 0;\n\n\tcxlr = to_cxl_region(dev);\n\tp = &cxlr->params;\n\n\tdown_read(&cxl_region_rwsem);\n\tif (p->res && p->res->start == r->start && p->res->end == r->end)\n\t\trc = 1;\n\tup_read(&cxl_region_rwsem);\n\n\treturn rc;\n}\n\n \nstatic struct cxl_region *construct_region(struct cxl_root_decoder *cxlrd,\n\t\t\t\t\t   struct cxl_endpoint_decoder *cxled)\n{\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct cxl_port *port = cxlrd_to_port(cxlrd);\n\tstruct range *hpa = &cxled->cxld.hpa_range;\n\tstruct cxl_region_params *p;\n\tstruct cxl_region *cxlr;\n\tstruct resource *res;\n\tint rc;\n\n\tdo {\n\t\tcxlr = __create_region(cxlrd, cxled->mode,\n\t\t\t\t       atomic_read(&cxlrd->region_id));\n\t} while (IS_ERR(cxlr) && PTR_ERR(cxlr) == -EBUSY);\n\n\tif (IS_ERR(cxlr)) {\n\t\tdev_err(cxlmd->dev.parent,\n\t\t\t\"%s:%s: %s failed assign region: %ld\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\t__func__, PTR_ERR(cxlr));\n\t\treturn cxlr;\n\t}\n\n\tdown_write(&cxl_region_rwsem);\n\tp = &cxlr->params;\n\tif (p->state >= CXL_CONFIG_INTERLEAVE_ACTIVE) {\n\t\tdev_err(cxlmd->dev.parent,\n\t\t\t\"%s:%s: %s autodiscovery interrupted\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\t__func__);\n\t\trc = -EBUSY;\n\t\tgoto err;\n\t}\n\n\tset_bit(CXL_REGION_F_AUTO, &cxlr->flags);\n\n\tres = kmalloc(sizeof(*res), GFP_KERNEL);\n\tif (!res) {\n\t\trc = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t*res = DEFINE_RES_MEM_NAMED(hpa->start, range_len(hpa),\n\t\t\t\t    dev_name(&cxlr->dev));\n\trc = insert_resource(cxlrd->res, res);\n\tif (rc) {\n\t\t \n\t\tdev_warn(cxlmd->dev.parent,\n\t\t\t \"%s:%s: %s %s cannot insert resource\\n\",\n\t\t\t dev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev),\n\t\t\t __func__, dev_name(&cxlr->dev));\n\t}\n\n\tp->res = res;\n\tp->interleave_ways = cxled->cxld.interleave_ways;\n\tp->interleave_granularity = cxled->cxld.interleave_granularity;\n\tp->state = CXL_CONFIG_INTERLEAVE_ACTIVE;\n\n\trc = sysfs_update_group(&cxlr->dev.kobj, get_cxl_region_target_group());\n\tif (rc)\n\t\tgoto err;\n\n\tdev_dbg(cxlmd->dev.parent, \"%s:%s: %s %s res: %pr iw: %d ig: %d\\n\",\n\t\tdev_name(&cxlmd->dev), dev_name(&cxled->cxld.dev), __func__,\n\t\tdev_name(&cxlr->dev), p->res, p->interleave_ways,\n\t\tp->interleave_granularity);\n\n\t \n\tget_device(&cxlr->dev);\n\tup_write(&cxl_region_rwsem);\n\n\treturn cxlr;\n\nerr:\n\tup_write(&cxl_region_rwsem);\n\tdevm_release_action(port->uport_dev, unregister_region, cxlr);\n\treturn ERR_PTR(rc);\n}\n\nint cxl_add_to_region(struct cxl_port *root, struct cxl_endpoint_decoder *cxled)\n{\n\tstruct cxl_memdev *cxlmd = cxled_to_memdev(cxled);\n\tstruct range *hpa = &cxled->cxld.hpa_range;\n\tstruct cxl_decoder *cxld = &cxled->cxld;\n\tstruct device *cxlrd_dev, *region_dev;\n\tstruct cxl_root_decoder *cxlrd;\n\tstruct cxl_region_params *p;\n\tstruct cxl_region *cxlr;\n\tbool attach = false;\n\tint rc;\n\n\tcxlrd_dev = device_find_child(&root->dev, &cxld->hpa_range,\n\t\t\t\t      match_root_decoder_by_range);\n\tif (!cxlrd_dev) {\n\t\tdev_err(cxlmd->dev.parent,\n\t\t\t\"%s:%s no CXL window for range %#llx:%#llx\\n\",\n\t\t\tdev_name(&cxlmd->dev), dev_name(&cxld->dev),\n\t\t\tcxld->hpa_range.start, cxld->hpa_range.end);\n\t\treturn -ENXIO;\n\t}\n\n\tcxlrd = to_cxl_root_decoder(cxlrd_dev);\n\n\t \n\tmutex_lock(&cxlrd->range_lock);\n\tregion_dev = device_find_child(&cxlrd->cxlsd.cxld.dev, hpa,\n\t\t\t\t       match_region_by_range);\n\tif (!region_dev) {\n\t\tcxlr = construct_region(cxlrd, cxled);\n\t\tregion_dev = &cxlr->dev;\n\t} else\n\t\tcxlr = to_cxl_region(region_dev);\n\tmutex_unlock(&cxlrd->range_lock);\n\n\trc = PTR_ERR_OR_ZERO(cxlr);\n\tif (rc)\n\t\tgoto out;\n\n\tattach_target(cxlr, cxled, -1, TASK_UNINTERRUPTIBLE);\n\n\tdown_read(&cxl_region_rwsem);\n\tp = &cxlr->params;\n\tattach = p->state == CXL_CONFIG_COMMIT;\n\tup_read(&cxl_region_rwsem);\n\n\tif (attach) {\n\t\t \n\t\tif (device_attach(&cxlr->dev) < 0)\n\t\t\tdev_err(&cxlr->dev, \"failed to enable, range: %pr\\n\",\n\t\t\t\tp->res);\n\t}\n\n\tput_device(region_dev);\nout:\n\tput_device(cxlrd_dev);\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_add_to_region, CXL);\n\nstatic int is_system_ram(struct resource *res, void *arg)\n{\n\tstruct cxl_region *cxlr = arg;\n\tstruct cxl_region_params *p = &cxlr->params;\n\n\tdev_dbg(&cxlr->dev, \"%pr has System RAM: %pr\\n\", p->res, res);\n\treturn 1;\n}\n\nstatic int cxl_region_probe(struct device *dev)\n{\n\tstruct cxl_region *cxlr = to_cxl_region(dev);\n\tstruct cxl_region_params *p = &cxlr->params;\n\tint rc;\n\n\trc = down_read_interruptible(&cxl_region_rwsem);\n\tif (rc) {\n\t\tdev_dbg(&cxlr->dev, \"probe interrupted\\n\");\n\t\treturn rc;\n\t}\n\n\tif (p->state < CXL_CONFIG_COMMIT) {\n\t\tdev_dbg(&cxlr->dev, \"config state: %d\\n\", p->state);\n\t\trc = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (test_bit(CXL_REGION_F_NEEDS_RESET, &cxlr->flags)) {\n\t\tdev_err(&cxlr->dev,\n\t\t\t\"failed to activate, re-commit region and retry\\n\");\n\t\trc = -ENXIO;\n\t\tgoto out;\n\t}\n\n\t \nout:\n\tup_read(&cxl_region_rwsem);\n\n\tif (rc)\n\t\treturn rc;\n\n\tswitch (cxlr->mode) {\n\tcase CXL_DECODER_PMEM:\n\t\treturn devm_cxl_add_pmem_region(cxlr);\n\tcase CXL_DECODER_RAM:\n\t\t \n\t\tif (walk_iomem_res_desc(IORES_DESC_NONE,\n\t\t\t\t\tIORESOURCE_SYSTEM_RAM | IORESOURCE_BUSY,\n\t\t\t\t\tp->res->start, p->res->end, cxlr,\n\t\t\t\t\tis_system_ram) > 0)\n\t\t\treturn 0;\n\t\treturn devm_cxl_add_dax_region(cxlr);\n\tdefault:\n\t\tdev_dbg(&cxlr->dev, \"unsupported region mode: %d\\n\",\n\t\t\tcxlr->mode);\n\t\treturn -ENXIO;\n\t}\n}\n\nstatic struct cxl_driver cxl_region_driver = {\n\t.name = \"cxl_region\",\n\t.probe = cxl_region_probe,\n\t.id = CXL_DEVICE_REGION,\n};\n\nint cxl_region_init(void)\n{\n\treturn cxl_driver_register(&cxl_region_driver);\n}\n\nvoid cxl_region_exit(void)\n{\n\tcxl_driver_unregister(&cxl_region_driver);\n}\n\nMODULE_IMPORT_NS(CXL);\nMODULE_IMPORT_NS(DEVMEM);\nMODULE_ALIAS_CXL(CXL_DEVICE_REGION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}