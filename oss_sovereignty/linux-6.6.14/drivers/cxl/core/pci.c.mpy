{
  "module_name": "pci.c",
  "hash_id": "f1132b5840046beac1fd25f6bf56720128db641d14837bae638be159eadf8017",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cxl/core/pci.c",
  "human_readable_source": "\n \n#include <linux/io-64-nonatomic-lo-hi.h>\n#include <linux/device.h>\n#include <linux/delay.h>\n#include <linux/pci.h>\n#include <linux/pci-doe.h>\n#include <cxlpci.h>\n#include <cxlmem.h>\n#include <cxl.h>\n#include \"core.h\"\n#include \"trace.h\"\n\n \n\nstatic unsigned short media_ready_timeout = 60;\nmodule_param(media_ready_timeout, ushort, 0644);\nMODULE_PARM_DESC(media_ready_timeout, \"seconds to wait for media ready\");\n\nstruct cxl_walk_context {\n\tstruct pci_bus *bus;\n\tstruct cxl_port *port;\n\tint type;\n\tint error;\n\tint count;\n};\n\nstatic int match_add_dports(struct pci_dev *pdev, void *data)\n{\n\tstruct cxl_walk_context *ctx = data;\n\tstruct cxl_port *port = ctx->port;\n\tint type = pci_pcie_type(pdev);\n\tstruct cxl_register_map map;\n\tstruct cxl_dport *dport;\n\tu32 lnkcap, port_num;\n\tint rc;\n\n\tif (pdev->bus != ctx->bus)\n\t\treturn 0;\n\tif (!pci_is_pcie(pdev))\n\t\treturn 0;\n\tif (type != ctx->type)\n\t\treturn 0;\n\tif (pci_read_config_dword(pdev, pci_pcie_cap(pdev) + PCI_EXP_LNKCAP,\n\t\t\t\t  &lnkcap))\n\t\treturn 0;\n\n\trc = cxl_find_regblock(pdev, CXL_REGLOC_RBI_COMPONENT, &map);\n\tif (rc)\n\t\tdev_dbg(&port->dev, \"failed to find component registers\\n\");\n\n\tport_num = FIELD_GET(PCI_EXP_LNKCAP_PN, lnkcap);\n\tdport = devm_cxl_add_dport(port, &pdev->dev, port_num, map.resource);\n\tif (IS_ERR(dport)) {\n\t\tctx->error = PTR_ERR(dport);\n\t\treturn PTR_ERR(dport);\n\t}\n\tctx->count++;\n\n\treturn 0;\n}\n\n \nint devm_cxl_port_enumerate_dports(struct cxl_port *port)\n{\n\tstruct pci_bus *bus = cxl_port_to_pci_bus(port);\n\tstruct cxl_walk_context ctx;\n\tint type;\n\n\tif (!bus)\n\t\treturn -ENXIO;\n\n\tif (pci_is_root_bus(bus))\n\t\ttype = PCI_EXP_TYPE_ROOT_PORT;\n\telse\n\t\ttype = PCI_EXP_TYPE_DOWNSTREAM;\n\n\tctx = (struct cxl_walk_context) {\n\t\t.port = port,\n\t\t.bus = bus,\n\t\t.type = type,\n\t};\n\tpci_walk_bus(bus, match_add_dports, &ctx);\n\n\tif (ctx.count == 0)\n\t\treturn -ENODEV;\n\tif (ctx.error)\n\t\treturn ctx.error;\n\treturn ctx.count;\n}\nEXPORT_SYMBOL_NS_GPL(devm_cxl_port_enumerate_dports, CXL);\n\nstatic int cxl_dvsec_mem_range_valid(struct cxl_dev_state *cxlds, int id)\n{\n\tstruct pci_dev *pdev = to_pci_dev(cxlds->dev);\n\tint d = cxlds->cxl_dvsec;\n\tbool valid = false;\n\tint rc, i;\n\tu32 temp;\n\n\tif (id > CXL_DVSEC_RANGE_MAX)\n\t\treturn -EINVAL;\n\n\t \n\ti = 1;\n\tdo {\n\t\trc = pci_read_config_dword(pdev,\n\t\t\t\t\t   d + CXL_DVSEC_RANGE_SIZE_LOW(id),\n\t\t\t\t\t   &temp);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tvalid = FIELD_GET(CXL_DVSEC_MEM_INFO_VALID, temp);\n\t\tif (valid)\n\t\t\tbreak;\n\t\tmsleep(1000);\n\t} while (i--);\n\n\tif (!valid) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Timeout awaiting memory range %d valid after 1s.\\n\",\n\t\t\tid);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\nstatic int cxl_dvsec_mem_range_active(struct cxl_dev_state *cxlds, int id)\n{\n\tstruct pci_dev *pdev = to_pci_dev(cxlds->dev);\n\tint d = cxlds->cxl_dvsec;\n\tbool active = false;\n\tint rc, i;\n\tu32 temp;\n\n\tif (id > CXL_DVSEC_RANGE_MAX)\n\t\treturn -EINVAL;\n\n\t \n\tfor (i = media_ready_timeout; i; i--) {\n\t\trc = pci_read_config_dword(\n\t\t\tpdev, d + CXL_DVSEC_RANGE_SIZE_LOW(id), &temp);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tactive = FIELD_GET(CXL_DVSEC_MEM_ACTIVE, temp);\n\t\tif (active)\n\t\t\tbreak;\n\t\tmsleep(1000);\n\t}\n\n\tif (!active) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"timeout awaiting memory active after %d seconds\\n\",\n\t\t\tmedia_ready_timeout);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\n \nint cxl_await_media_ready(struct cxl_dev_state *cxlds)\n{\n\tstruct pci_dev *pdev = to_pci_dev(cxlds->dev);\n\tint d = cxlds->cxl_dvsec;\n\tint rc, i, hdm_count;\n\tu64 md_status;\n\tu16 cap;\n\n\trc = pci_read_config_word(pdev,\n\t\t\t\t  d + CXL_DVSEC_CAP_OFFSET, &cap);\n\tif (rc)\n\t\treturn rc;\n\n\thdm_count = FIELD_GET(CXL_DVSEC_HDM_COUNT_MASK, cap);\n\tfor (i = 0; i < hdm_count; i++) {\n\t\trc = cxl_dvsec_mem_range_valid(cxlds, i);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tfor (i = 0; i < hdm_count; i++) {\n\t\trc = cxl_dvsec_mem_range_active(cxlds, i);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tmd_status = readq(cxlds->regs.memdev + CXLMDEV_STATUS_OFFSET);\n\tif (!CXLMDEV_READY(md_status))\n\t\treturn -EIO;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_await_media_ready, CXL);\n\nstatic int wait_for_valid(struct pci_dev *pdev, int d)\n{\n\tu32 val;\n\tint rc;\n\n\t \n\trc = pci_read_config_dword(pdev, d + CXL_DVSEC_RANGE_SIZE_LOW(0), &val);\n\tif (rc)\n\t\treturn rc;\n\n\tif (val & CXL_DVSEC_MEM_INFO_VALID)\n\t\treturn 0;\n\n\tmsleep(1500);\n\n\trc = pci_read_config_dword(pdev, d + CXL_DVSEC_RANGE_SIZE_LOW(0), &val);\n\tif (rc)\n\t\treturn rc;\n\n\tif (val & CXL_DVSEC_MEM_INFO_VALID)\n\t\treturn 0;\n\n\treturn -ETIMEDOUT;\n}\n\nstatic int cxl_set_mem_enable(struct cxl_dev_state *cxlds, u16 val)\n{\n\tstruct pci_dev *pdev = to_pci_dev(cxlds->dev);\n\tint d = cxlds->cxl_dvsec;\n\tu16 ctrl;\n\tint rc;\n\n\trc = pci_read_config_word(pdev, d + CXL_DVSEC_CTRL_OFFSET, &ctrl);\n\tif (rc < 0)\n\t\treturn rc;\n\n\tif ((ctrl & CXL_DVSEC_MEM_ENABLE) == val)\n\t\treturn 1;\n\tctrl &= ~CXL_DVSEC_MEM_ENABLE;\n\tctrl |= val;\n\n\trc = pci_write_config_word(pdev, d + CXL_DVSEC_CTRL_OFFSET, ctrl);\n\tif (rc < 0)\n\t\treturn rc;\n\n\treturn 0;\n}\n\nstatic void clear_mem_enable(void *cxlds)\n{\n\tcxl_set_mem_enable(cxlds, 0);\n}\n\nstatic int devm_cxl_enable_mem(struct device *host, struct cxl_dev_state *cxlds)\n{\n\tint rc;\n\n\trc = cxl_set_mem_enable(cxlds, CXL_DVSEC_MEM_ENABLE);\n\tif (rc < 0)\n\t\treturn rc;\n\tif (rc > 0)\n\t\treturn 0;\n\treturn devm_add_action_or_reset(host, clear_mem_enable, cxlds);\n}\n\n \nstatic int dvsec_range_allowed(struct device *dev, void *arg)\n{\n\tstruct range *dev_range = arg;\n\tstruct cxl_decoder *cxld;\n\n\tif (!is_root_decoder(dev))\n\t\treturn 0;\n\n\tcxld = to_cxl_decoder(dev);\n\n\tif (!(cxld->flags & CXL_DECODER_F_RAM))\n\t\treturn 0;\n\n\treturn range_contains(&cxld->hpa_range, dev_range);\n}\n\nstatic void disable_hdm(void *_cxlhdm)\n{\n\tu32 global_ctrl;\n\tstruct cxl_hdm *cxlhdm = _cxlhdm;\n\tvoid __iomem *hdm = cxlhdm->regs.hdm_decoder;\n\n\tglobal_ctrl = readl(hdm + CXL_HDM_DECODER_CTRL_OFFSET);\n\twritel(global_ctrl & ~CXL_HDM_DECODER_ENABLE,\n\t       hdm + CXL_HDM_DECODER_CTRL_OFFSET);\n}\n\nstatic int devm_cxl_enable_hdm(struct device *host, struct cxl_hdm *cxlhdm)\n{\n\tvoid __iomem *hdm = cxlhdm->regs.hdm_decoder;\n\tu32 global_ctrl;\n\n\tglobal_ctrl = readl(hdm + CXL_HDM_DECODER_CTRL_OFFSET);\n\twritel(global_ctrl | CXL_HDM_DECODER_ENABLE,\n\t       hdm + CXL_HDM_DECODER_CTRL_OFFSET);\n\n\treturn devm_add_action_or_reset(host, disable_hdm, cxlhdm);\n}\n\nint cxl_dvsec_rr_decode(struct device *dev, int d,\n\t\t\tstruct cxl_endpoint_dvsec_info *info)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev);\n\tint hdm_count, rc, i, ranges = 0;\n\tu16 cap, ctrl;\n\n\tif (!d) {\n\t\tdev_dbg(dev, \"No DVSEC Capability\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\trc = pci_read_config_word(pdev, d + CXL_DVSEC_CAP_OFFSET, &cap);\n\tif (rc)\n\t\treturn rc;\n\n\trc = pci_read_config_word(pdev, d + CXL_DVSEC_CTRL_OFFSET, &ctrl);\n\tif (rc)\n\t\treturn rc;\n\n\tif (!(cap & CXL_DVSEC_MEM_CAPABLE)) {\n\t\tdev_dbg(dev, \"Not MEM Capable\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\t \n\thdm_count = FIELD_GET(CXL_DVSEC_HDM_COUNT_MASK, cap);\n\tif (!hdm_count || hdm_count > 2)\n\t\treturn -EINVAL;\n\n\trc = wait_for_valid(pdev, d);\n\tif (rc) {\n\t\tdev_dbg(dev, \"Failure awaiting MEM_INFO_VALID (%d)\\n\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\tinfo->mem_enabled = FIELD_GET(CXL_DVSEC_MEM_ENABLE, ctrl);\n\tif (!info->mem_enabled)\n\t\treturn 0;\n\n\tfor (i = 0; i < hdm_count; i++) {\n\t\tu64 base, size;\n\t\tu32 temp;\n\n\t\trc = pci_read_config_dword(\n\t\t\tpdev, d + CXL_DVSEC_RANGE_SIZE_HIGH(i), &temp);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tsize = (u64)temp << 32;\n\n\t\trc = pci_read_config_dword(\n\t\t\tpdev, d + CXL_DVSEC_RANGE_SIZE_LOW(i), &temp);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tsize |= temp & CXL_DVSEC_MEM_SIZE_LOW_MASK;\n\t\tif (!size) {\n\t\t\tinfo->dvsec_range[i] = (struct range) {\n\t\t\t\t.start = 0,\n\t\t\t\t.end = CXL_RESOURCE_NONE,\n\t\t\t};\n\t\t\tcontinue;\n\t\t}\n\n\t\trc = pci_read_config_dword(\n\t\t\tpdev, d + CXL_DVSEC_RANGE_BASE_HIGH(i), &temp);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tbase = (u64)temp << 32;\n\n\t\trc = pci_read_config_dword(\n\t\t\tpdev, d + CXL_DVSEC_RANGE_BASE_LOW(i), &temp);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tbase |= temp & CXL_DVSEC_MEM_BASE_LOW_MASK;\n\n\t\tinfo->dvsec_range[i] = (struct range) {\n\t\t\t.start = base,\n\t\t\t.end = base + size - 1\n\t\t};\n\n\t\tranges++;\n\t}\n\n\tinfo->ranges = ranges;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_dvsec_rr_decode, CXL);\n\n \nint cxl_hdm_decode_init(struct cxl_dev_state *cxlds, struct cxl_hdm *cxlhdm,\n\t\t\tstruct cxl_endpoint_dvsec_info *info)\n{\n\tvoid __iomem *hdm = cxlhdm->regs.hdm_decoder;\n\tstruct cxl_port *port = cxlhdm->port;\n\tstruct device *dev = cxlds->dev;\n\tstruct cxl_port *root;\n\tint i, rc, allowed;\n\tu32 global_ctrl = 0;\n\n\tif (hdm)\n\t\tglobal_ctrl = readl(hdm + CXL_HDM_DECODER_CTRL_OFFSET);\n\n\t \n\tif (global_ctrl & CXL_HDM_DECODER_ENABLE || (!hdm && info->mem_enabled))\n\t\treturn devm_cxl_enable_mem(&port->dev, cxlds);\n\telse if (!hdm)\n\t\treturn -ENODEV;\n\n\troot = to_cxl_port(port->dev.parent);\n\twhile (!is_cxl_root(root) && is_cxl_port(root->dev.parent))\n\t\troot = to_cxl_port(root->dev.parent);\n\tif (!is_cxl_root(root)) {\n\t\tdev_err(dev, \"Failed to acquire root port for HDM enable\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tfor (i = 0, allowed = 0; info->mem_enabled && i < info->ranges; i++) {\n\t\tstruct device *cxld_dev;\n\n\t\tcxld_dev = device_find_child(&root->dev, &info->dvsec_range[i],\n\t\t\t\t\t     dvsec_range_allowed);\n\t\tif (!cxld_dev) {\n\t\t\tdev_dbg(dev, \"DVSEC Range%d denied by platform\\n\", i);\n\t\t\tcontinue;\n\t\t}\n\t\tdev_dbg(dev, \"DVSEC Range%d allowed by platform\\n\", i);\n\t\tput_device(cxld_dev);\n\t\tallowed++;\n\t}\n\n\tif (!allowed) {\n\t\tcxl_set_mem_enable(cxlds, 0);\n\t\tinfo->mem_enabled = 0;\n\t}\n\n\t \n\tif (info->mem_enabled)\n\t\treturn 0;\n\n\trc = devm_cxl_enable_hdm(&port->dev, cxlhdm);\n\tif (rc)\n\t\treturn rc;\n\n\treturn devm_cxl_enable_mem(&port->dev, cxlds);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_hdm_decode_init, CXL);\n\n#define CXL_DOE_TABLE_ACCESS_REQ_CODE\t\t0x000000ff\n#define   CXL_DOE_TABLE_ACCESS_REQ_CODE_READ\t0\n#define CXL_DOE_TABLE_ACCESS_TABLE_TYPE\t\t0x0000ff00\n#define   CXL_DOE_TABLE_ACCESS_TABLE_TYPE_CDATA\t0\n#define CXL_DOE_TABLE_ACCESS_ENTRY_HANDLE\t0xffff0000\n#define CXL_DOE_TABLE_ACCESS_LAST_ENTRY\t\t0xffff\n#define CXL_DOE_PROTOCOL_TABLE_ACCESS 2\n\n#define CDAT_DOE_REQ(entry_handle) cpu_to_le32\t\t\t\t\\\n\t(FIELD_PREP(CXL_DOE_TABLE_ACCESS_REQ_CODE,\t\t\t\\\n\t\t    CXL_DOE_TABLE_ACCESS_REQ_CODE_READ) |\t\t\\\n\t FIELD_PREP(CXL_DOE_TABLE_ACCESS_TABLE_TYPE,\t\t\t\\\n\t\t    CXL_DOE_TABLE_ACCESS_TABLE_TYPE_CDATA) |\t\t\\\n\t FIELD_PREP(CXL_DOE_TABLE_ACCESS_ENTRY_HANDLE, (entry_handle)))\n\nstatic int cxl_cdat_get_length(struct device *dev,\n\t\t\t       struct pci_doe_mb *cdat_doe,\n\t\t\t       size_t *length)\n{\n\t__le32 request = CDAT_DOE_REQ(0);\n\t__le32 response[2];\n\tint rc;\n\n\trc = pci_doe(cdat_doe, PCI_DVSEC_VENDOR_ID_CXL,\n\t\t     CXL_DOE_PROTOCOL_TABLE_ACCESS,\n\t\t     &request, sizeof(request),\n\t\t     &response, sizeof(response));\n\tif (rc < 0) {\n\t\tdev_err(dev, \"DOE failed: %d\", rc);\n\t\treturn rc;\n\t}\n\tif (rc < sizeof(response))\n\t\treturn -EIO;\n\n\t*length = le32_to_cpu(response[1]);\n\tdev_dbg(dev, \"CDAT length %zu\\n\", *length);\n\n\treturn 0;\n}\n\nstatic int cxl_cdat_read_table(struct device *dev,\n\t\t\t       struct pci_doe_mb *cdat_doe,\n\t\t\t       void *cdat_table, size_t *cdat_length)\n{\n\tsize_t length = *cdat_length + sizeof(__le32);\n\t__le32 *data = cdat_table;\n\tint entry_handle = 0;\n\t__le32 saved_dw = 0;\n\n\tdo {\n\t\t__le32 request = CDAT_DOE_REQ(entry_handle);\n\t\tstruct cdat_entry_header *entry;\n\t\tsize_t entry_dw;\n\t\tint rc;\n\n\t\trc = pci_doe(cdat_doe, PCI_DVSEC_VENDOR_ID_CXL,\n\t\t\t     CXL_DOE_PROTOCOL_TABLE_ACCESS,\n\t\t\t     &request, sizeof(request),\n\t\t\t     data, length);\n\t\tif (rc < 0) {\n\t\t\tdev_err(dev, \"DOE failed: %d\", rc);\n\t\t\treturn rc;\n\t\t}\n\n\t\t \n\t\tentry = (struct cdat_entry_header *)(data + 1);\n\t\tif ((entry_handle == 0 &&\n\t\t     rc != sizeof(__le32) + sizeof(struct cdat_header)) ||\n\t\t    (entry_handle > 0 &&\n\t\t     (rc < sizeof(__le32) + sizeof(*entry) ||\n\t\t      rc != sizeof(__le32) + le16_to_cpu(entry->length))))\n\t\t\treturn -EIO;\n\n\t\t \n\t\tentry_handle = FIELD_GET(CXL_DOE_TABLE_ACCESS_ENTRY_HANDLE,\n\t\t\t\t\t le32_to_cpu(data[0]));\n\t\tentry_dw = rc / sizeof(__le32);\n\t\t \n\t\tentry_dw -= 1;\n\t\t \n\t\t*data = saved_dw;\n\t\tlength -= entry_dw * sizeof(__le32);\n\t\tdata += entry_dw;\n\t\tsaved_dw = *data;\n\t} while (entry_handle != CXL_DOE_TABLE_ACCESS_LAST_ENTRY);\n\n\t \n\t*cdat_length -= length - sizeof(__le32);\n\n\treturn 0;\n}\n\n \nvoid read_cdat_data(struct cxl_port *port)\n{\n\tstruct cxl_memdev *cxlmd = to_cxl_memdev(port->uport_dev);\n\tstruct device *host = cxlmd->dev.parent;\n\tstruct device *dev = &port->dev;\n\tstruct pci_doe_mb *cdat_doe;\n\tsize_t cdat_length;\n\tvoid *cdat_table;\n\tint rc;\n\n\tif (!dev_is_pci(host))\n\t\treturn;\n\tcdat_doe = pci_find_doe_mailbox(to_pci_dev(host),\n\t\t\t\t\tPCI_DVSEC_VENDOR_ID_CXL,\n\t\t\t\t\tCXL_DOE_PROTOCOL_TABLE_ACCESS);\n\tif (!cdat_doe) {\n\t\tdev_dbg(dev, \"No CDAT mailbox\\n\");\n\t\treturn;\n\t}\n\n\tport->cdat_available = true;\n\n\tif (cxl_cdat_get_length(dev, cdat_doe, &cdat_length)) {\n\t\tdev_dbg(dev, \"No CDAT length\\n\");\n\t\treturn;\n\t}\n\n\tcdat_table = devm_kzalloc(dev, cdat_length + sizeof(__le32),\n\t\t\t\t  GFP_KERNEL);\n\tif (!cdat_table)\n\t\treturn;\n\n\trc = cxl_cdat_read_table(dev, cdat_doe, cdat_table, &cdat_length);\n\tif (rc) {\n\t\t \n\t\tdevm_kfree(dev, cdat_table);\n\t\tdev_err(dev, \"CDAT data read error\\n\");\n\t\treturn;\n\t}\n\n\tport->cdat.table = cdat_table + sizeof(__le32);\n\tport->cdat.length = cdat_length;\n}\nEXPORT_SYMBOL_NS_GPL(read_cdat_data, CXL);\n\nvoid cxl_cor_error_detected(struct pci_dev *pdev)\n{\n\tstruct cxl_dev_state *cxlds = pci_get_drvdata(pdev);\n\tvoid __iomem *addr;\n\tu32 status;\n\n\tif (!cxlds->regs.ras)\n\t\treturn;\n\n\taddr = cxlds->regs.ras + CXL_RAS_CORRECTABLE_STATUS_OFFSET;\n\tstatus = readl(addr);\n\tif (status & CXL_RAS_CORRECTABLE_STATUS_MASK) {\n\t\twritel(status & CXL_RAS_CORRECTABLE_STATUS_MASK, addr);\n\t\ttrace_cxl_aer_correctable_error(cxlds->cxlmd, status);\n\t}\n}\nEXPORT_SYMBOL_NS_GPL(cxl_cor_error_detected, CXL);\n\n \nstatic void header_log_copy(struct cxl_dev_state *cxlds, u32 *log)\n{\n\tvoid __iomem *addr;\n\tu32 *log_addr;\n\tint i, log_u32_size = CXL_HEADERLOG_SIZE / sizeof(u32);\n\n\taddr = cxlds->regs.ras + CXL_RAS_HEADER_LOG_OFFSET;\n\tlog_addr = log;\n\n\tfor (i = 0; i < log_u32_size; i++) {\n\t\t*log_addr = readl(addr);\n\t\tlog_addr++;\n\t\taddr += sizeof(u32);\n\t}\n}\n\n \nstatic bool cxl_report_and_clear(struct cxl_dev_state *cxlds)\n{\n\tu32 hl[CXL_HEADERLOG_SIZE_U32];\n\tvoid __iomem *addr;\n\tu32 status;\n\tu32 fe;\n\n\tif (!cxlds->regs.ras)\n\t\treturn false;\n\n\taddr = cxlds->regs.ras + CXL_RAS_UNCORRECTABLE_STATUS_OFFSET;\n\tstatus = readl(addr);\n\tif (!(status & CXL_RAS_UNCORRECTABLE_STATUS_MASK))\n\t\treturn false;\n\n\t \n\tif (hweight32(status) > 1) {\n\t\tvoid __iomem *rcc_addr =\n\t\t\tcxlds->regs.ras + CXL_RAS_CAP_CONTROL_OFFSET;\n\n\t\tfe = BIT(FIELD_GET(CXL_RAS_CAP_CONTROL_FE_MASK,\n\t\t\t\t   readl(rcc_addr)));\n\t} else {\n\t\tfe = status;\n\t}\n\n\theader_log_copy(cxlds, hl);\n\ttrace_cxl_aer_uncorrectable_error(cxlds->cxlmd, status, fe, hl);\n\twritel(status & CXL_RAS_UNCORRECTABLE_STATUS_MASK, addr);\n\n\treturn true;\n}\n\npci_ers_result_t cxl_error_detected(struct pci_dev *pdev,\n\t\t\t\t    pci_channel_state_t state)\n{\n\tstruct cxl_dev_state *cxlds = pci_get_drvdata(pdev);\n\tstruct cxl_memdev *cxlmd = cxlds->cxlmd;\n\tstruct device *dev = &cxlmd->dev;\n\tbool ue;\n\n\t \n\tue = cxl_report_and_clear(cxlds);\n\n\tswitch (state) {\n\tcase pci_channel_io_normal:\n\t\tif (ue) {\n\t\t\tdevice_release_driver(dev);\n\t\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\t\t}\n\t\treturn PCI_ERS_RESULT_CAN_RECOVER;\n\tcase pci_channel_io_frozen:\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"%s: frozen state error detected, disable CXL.mem\\n\",\n\t\t\t dev_name(dev));\n\t\tdevice_release_driver(dev);\n\t\treturn PCI_ERS_RESULT_NEED_RESET;\n\tcase pci_channel_io_perm_failure:\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"failure state error detected, request disconnect\\n\");\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\t}\n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_error_detected, CXL);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}