{
  "module_name": "port.c",
  "hash_id": "882c2ba8d34fde20eaa53b9e3db2e261e8e9fff3aa77f07f8f4a357e5b45f878",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cxl/core/port.c",
  "human_readable_source": "\n \n#include <linux/platform_device.h>\n#include <linux/memregion.h>\n#include <linux/workqueue.h>\n#include <linux/debugfs.h>\n#include <linux/device.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/idr.h>\n#include <cxlmem.h>\n#include <cxlpci.h>\n#include <cxl.h>\n#include \"core.h\"\n\n \n\n \nDECLARE_RWSEM(cxl_region_rwsem);\n\nstatic DEFINE_IDA(cxl_port_ida);\nstatic DEFINE_XARRAY(cxl_root_buses);\n\nint cxl_num_decoders_committed(struct cxl_port *port)\n{\n\tlockdep_assert_held(&cxl_region_rwsem);\n\n\treturn port->commit_end + 1;\n}\n\nstatic ssize_t devtype_show(struct device *dev, struct device_attribute *attr,\n\t\t\t    char *buf)\n{\n\treturn sysfs_emit(buf, \"%s\\n\", dev->type->name);\n}\nstatic DEVICE_ATTR_RO(devtype);\n\nstatic int cxl_device_id(const struct device *dev)\n{\n\tif (dev->type == &cxl_nvdimm_bridge_type)\n\t\treturn CXL_DEVICE_NVDIMM_BRIDGE;\n\tif (dev->type == &cxl_nvdimm_type)\n\t\treturn CXL_DEVICE_NVDIMM;\n\tif (dev->type == CXL_PMEM_REGION_TYPE())\n\t\treturn CXL_DEVICE_PMEM_REGION;\n\tif (dev->type == CXL_DAX_REGION_TYPE())\n\t\treturn CXL_DEVICE_DAX_REGION;\n\tif (is_cxl_port(dev)) {\n\t\tif (is_cxl_root(to_cxl_port(dev)))\n\t\t\treturn CXL_DEVICE_ROOT;\n\t\treturn CXL_DEVICE_PORT;\n\t}\n\tif (is_cxl_memdev(dev))\n\t\treturn CXL_DEVICE_MEMORY_EXPANDER;\n\tif (dev->type == CXL_REGION_TYPE())\n\t\treturn CXL_DEVICE_REGION;\n\tif (dev->type == &cxl_pmu_type)\n\t\treturn CXL_DEVICE_PMU;\n\treturn 0;\n}\n\nstatic ssize_t modalias_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\treturn sysfs_emit(buf, CXL_MODALIAS_FMT \"\\n\", cxl_device_id(dev));\n}\nstatic DEVICE_ATTR_RO(modalias);\n\nstatic struct attribute *cxl_base_attributes[] = {\n\t&dev_attr_devtype.attr,\n\t&dev_attr_modalias.attr,\n\tNULL,\n};\n\nstruct attribute_group cxl_base_attribute_group = {\n\t.attrs = cxl_base_attributes,\n};\n\nstatic ssize_t start_show(struct device *dev, struct device_attribute *attr,\n\t\t\t  char *buf)\n{\n\tstruct cxl_decoder *cxld = to_cxl_decoder(dev);\n\n\treturn sysfs_emit(buf, \"%#llx\\n\", cxld->hpa_range.start);\n}\nstatic DEVICE_ATTR_ADMIN_RO(start);\n\nstatic ssize_t size_show(struct device *dev, struct device_attribute *attr,\n\t\t\tchar *buf)\n{\n\tstruct cxl_decoder *cxld = to_cxl_decoder(dev);\n\n\treturn sysfs_emit(buf, \"%#llx\\n\", range_len(&cxld->hpa_range));\n}\nstatic DEVICE_ATTR_RO(size);\n\n#define CXL_DECODER_FLAG_ATTR(name, flag)                            \\\nstatic ssize_t name##_show(struct device *dev,                       \\\n\t\t\t   struct device_attribute *attr, char *buf) \\\n{                                                                    \\\n\tstruct cxl_decoder *cxld = to_cxl_decoder(dev);              \\\n                                                                     \\\n\treturn sysfs_emit(buf, \"%s\\n\",                               \\\n\t\t\t  (cxld->flags & (flag)) ? \"1\" : \"0\");       \\\n}                                                                    \\\nstatic DEVICE_ATTR_RO(name)\n\nCXL_DECODER_FLAG_ATTR(cap_pmem, CXL_DECODER_F_PMEM);\nCXL_DECODER_FLAG_ATTR(cap_ram, CXL_DECODER_F_RAM);\nCXL_DECODER_FLAG_ATTR(cap_type2, CXL_DECODER_F_TYPE2);\nCXL_DECODER_FLAG_ATTR(cap_type3, CXL_DECODER_F_TYPE3);\nCXL_DECODER_FLAG_ATTR(locked, CXL_DECODER_F_LOCK);\n\nstatic ssize_t target_type_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct cxl_decoder *cxld = to_cxl_decoder(dev);\n\n\tswitch (cxld->target_type) {\n\tcase CXL_DECODER_DEVMEM:\n\t\treturn sysfs_emit(buf, \"accelerator\\n\");\n\tcase CXL_DECODER_HOSTONLYMEM:\n\t\treturn sysfs_emit(buf, \"expander\\n\");\n\t}\n\treturn -ENXIO;\n}\nstatic DEVICE_ATTR_RO(target_type);\n\nstatic ssize_t emit_target_list(struct cxl_switch_decoder *cxlsd, char *buf)\n{\n\tstruct cxl_decoder *cxld = &cxlsd->cxld;\n\tssize_t offset = 0;\n\tint i, rc = 0;\n\n\tfor (i = 0; i < cxld->interleave_ways; i++) {\n\t\tstruct cxl_dport *dport = cxlsd->target[i];\n\t\tstruct cxl_dport *next = NULL;\n\n\t\tif (!dport)\n\t\t\tbreak;\n\n\t\tif (i + 1 < cxld->interleave_ways)\n\t\t\tnext = cxlsd->target[i + 1];\n\t\trc = sysfs_emit_at(buf, offset, \"%d%s\", dport->port_id,\n\t\t\t\t   next ? \",\" : \"\");\n\t\tif (rc < 0)\n\t\t\treturn rc;\n\t\toffset += rc;\n\t}\n\n\treturn offset;\n}\n\nstatic ssize_t target_list_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct cxl_switch_decoder *cxlsd = to_cxl_switch_decoder(dev);\n\tssize_t offset;\n\tint rc;\n\n\tguard(rwsem_read)(&cxl_region_rwsem);\n\trc = emit_target_list(cxlsd, buf);\n\tif (rc < 0)\n\t\treturn rc;\n\toffset = rc;\n\n\trc = sysfs_emit_at(buf, offset, \"\\n\");\n\tif (rc < 0)\n\t\treturn rc;\n\n\treturn offset + rc;\n}\nstatic DEVICE_ATTR_RO(target_list);\n\nstatic ssize_t mode_show(struct device *dev, struct device_attribute *attr,\n\t\t\t char *buf)\n{\n\tstruct cxl_endpoint_decoder *cxled = to_cxl_endpoint_decoder(dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\", cxl_decoder_mode_name(cxled->mode));\n}\n\nstatic ssize_t mode_store(struct device *dev, struct device_attribute *attr,\n\t\t\t  const char *buf, size_t len)\n{\n\tstruct cxl_endpoint_decoder *cxled = to_cxl_endpoint_decoder(dev);\n\tenum cxl_decoder_mode mode;\n\tssize_t rc;\n\n\tif (sysfs_streq(buf, \"pmem\"))\n\t\tmode = CXL_DECODER_PMEM;\n\telse if (sysfs_streq(buf, \"ram\"))\n\t\tmode = CXL_DECODER_RAM;\n\telse\n\t\treturn -EINVAL;\n\n\trc = cxl_dpa_set_mode(cxled, mode);\n\tif (rc)\n\t\treturn rc;\n\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(mode);\n\nstatic ssize_t dpa_resource_show(struct device *dev, struct device_attribute *attr,\n\t\t\t    char *buf)\n{\n\tstruct cxl_endpoint_decoder *cxled = to_cxl_endpoint_decoder(dev);\n\n\tguard(rwsem_read)(&cxl_dpa_rwsem);\n\treturn sysfs_emit(buf, \"%#llx\\n\", (u64)cxl_dpa_resource_start(cxled));\n}\nstatic DEVICE_ATTR_RO(dpa_resource);\n\nstatic ssize_t dpa_size_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct cxl_endpoint_decoder *cxled = to_cxl_endpoint_decoder(dev);\n\tresource_size_t size = cxl_dpa_size(cxled);\n\n\treturn sysfs_emit(buf, \"%pa\\n\", &size);\n}\n\nstatic ssize_t dpa_size_store(struct device *dev, struct device_attribute *attr,\n\t\t\t      const char *buf, size_t len)\n{\n\tstruct cxl_endpoint_decoder *cxled = to_cxl_endpoint_decoder(dev);\n\tunsigned long long size;\n\tssize_t rc;\n\n\trc = kstrtoull(buf, 0, &size);\n\tif (rc)\n\t\treturn rc;\n\n\tif (!IS_ALIGNED(size, SZ_256M))\n\t\treturn -EINVAL;\n\n\trc = cxl_dpa_free(cxled);\n\tif (rc)\n\t\treturn rc;\n\n\tif (size == 0)\n\t\treturn len;\n\n\trc = cxl_dpa_alloc(cxled, size);\n\tif (rc)\n\t\treturn rc;\n\n\treturn len;\n}\nstatic DEVICE_ATTR_RW(dpa_size);\n\nstatic ssize_t interleave_granularity_show(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tstruct cxl_decoder *cxld = to_cxl_decoder(dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", cxld->interleave_granularity);\n}\n\nstatic DEVICE_ATTR_RO(interleave_granularity);\n\nstatic ssize_t interleave_ways_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct cxl_decoder *cxld = to_cxl_decoder(dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", cxld->interleave_ways);\n}\n\nstatic DEVICE_ATTR_RO(interleave_ways);\n\nstatic struct attribute *cxl_decoder_base_attrs[] = {\n\t&dev_attr_start.attr,\n\t&dev_attr_size.attr,\n\t&dev_attr_locked.attr,\n\t&dev_attr_interleave_granularity.attr,\n\t&dev_attr_interleave_ways.attr,\n\tNULL,\n};\n\nstatic struct attribute_group cxl_decoder_base_attribute_group = {\n\t.attrs = cxl_decoder_base_attrs,\n};\n\nstatic struct attribute *cxl_decoder_root_attrs[] = {\n\t&dev_attr_cap_pmem.attr,\n\t&dev_attr_cap_ram.attr,\n\t&dev_attr_cap_type2.attr,\n\t&dev_attr_cap_type3.attr,\n\t&dev_attr_target_list.attr,\n\tSET_CXL_REGION_ATTR(create_pmem_region)\n\tSET_CXL_REGION_ATTR(create_ram_region)\n\tSET_CXL_REGION_ATTR(delete_region)\n\tNULL,\n};\n\nstatic bool can_create_pmem(struct cxl_root_decoder *cxlrd)\n{\n\tunsigned long flags = CXL_DECODER_F_TYPE3 | CXL_DECODER_F_PMEM;\n\n\treturn (cxlrd->cxlsd.cxld.flags & flags) == flags;\n}\n\nstatic bool can_create_ram(struct cxl_root_decoder *cxlrd)\n{\n\tunsigned long flags = CXL_DECODER_F_TYPE3 | CXL_DECODER_F_RAM;\n\n\treturn (cxlrd->cxlsd.cxld.flags & flags) == flags;\n}\n\nstatic umode_t cxl_root_decoder_visible(struct kobject *kobj, struct attribute *a, int n)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev);\n\n\tif (a == CXL_REGION_ATTR(create_pmem_region) && !can_create_pmem(cxlrd))\n\t\treturn 0;\n\n\tif (a == CXL_REGION_ATTR(create_ram_region) && !can_create_ram(cxlrd))\n\t\treturn 0;\n\n\tif (a == CXL_REGION_ATTR(delete_region) &&\n\t    !(can_create_pmem(cxlrd) || can_create_ram(cxlrd)))\n\t\treturn 0;\n\n\treturn a->mode;\n}\n\nstatic struct attribute_group cxl_decoder_root_attribute_group = {\n\t.attrs = cxl_decoder_root_attrs,\n\t.is_visible = cxl_root_decoder_visible,\n};\n\nstatic const struct attribute_group *cxl_decoder_root_attribute_groups[] = {\n\t&cxl_decoder_root_attribute_group,\n\t&cxl_decoder_base_attribute_group,\n\t&cxl_base_attribute_group,\n\tNULL,\n};\n\nstatic struct attribute *cxl_decoder_switch_attrs[] = {\n\t&dev_attr_target_type.attr,\n\t&dev_attr_target_list.attr,\n\tSET_CXL_REGION_ATTR(region)\n\tNULL,\n};\n\nstatic struct attribute_group cxl_decoder_switch_attribute_group = {\n\t.attrs = cxl_decoder_switch_attrs,\n};\n\nstatic const struct attribute_group *cxl_decoder_switch_attribute_groups[] = {\n\t&cxl_decoder_switch_attribute_group,\n\t&cxl_decoder_base_attribute_group,\n\t&cxl_base_attribute_group,\n\tNULL,\n};\n\nstatic struct attribute *cxl_decoder_endpoint_attrs[] = {\n\t&dev_attr_target_type.attr,\n\t&dev_attr_mode.attr,\n\t&dev_attr_dpa_size.attr,\n\t&dev_attr_dpa_resource.attr,\n\tSET_CXL_REGION_ATTR(region)\n\tNULL,\n};\n\nstatic struct attribute_group cxl_decoder_endpoint_attribute_group = {\n\t.attrs = cxl_decoder_endpoint_attrs,\n};\n\nstatic const struct attribute_group *cxl_decoder_endpoint_attribute_groups[] = {\n\t&cxl_decoder_base_attribute_group,\n\t&cxl_decoder_endpoint_attribute_group,\n\t&cxl_base_attribute_group,\n\tNULL,\n};\n\nstatic void __cxl_decoder_release(struct cxl_decoder *cxld)\n{\n\tstruct cxl_port *port = to_cxl_port(cxld->dev.parent);\n\n\tida_free(&port->decoder_ida, cxld->id);\n\tput_device(&port->dev);\n}\n\nstatic void cxl_endpoint_decoder_release(struct device *dev)\n{\n\tstruct cxl_endpoint_decoder *cxled = to_cxl_endpoint_decoder(dev);\n\n\t__cxl_decoder_release(&cxled->cxld);\n\tkfree(cxled);\n}\n\nstatic void cxl_switch_decoder_release(struct device *dev)\n{\n\tstruct cxl_switch_decoder *cxlsd = to_cxl_switch_decoder(dev);\n\n\t__cxl_decoder_release(&cxlsd->cxld);\n\tkfree(cxlsd);\n}\n\nstruct cxl_root_decoder *to_cxl_root_decoder(struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev, !is_root_decoder(dev),\n\t\t\t  \"not a cxl_root_decoder device\\n\"))\n\t\treturn NULL;\n\treturn container_of(dev, struct cxl_root_decoder, cxlsd.cxld.dev);\n}\nEXPORT_SYMBOL_NS_GPL(to_cxl_root_decoder, CXL);\n\nstatic void cxl_root_decoder_release(struct device *dev)\n{\n\tstruct cxl_root_decoder *cxlrd = to_cxl_root_decoder(dev);\n\n\tif (atomic_read(&cxlrd->region_id) >= 0)\n\t\tmemregion_free(atomic_read(&cxlrd->region_id));\n\t__cxl_decoder_release(&cxlrd->cxlsd.cxld);\n\tkfree(cxlrd);\n}\n\nstatic const struct device_type cxl_decoder_endpoint_type = {\n\t.name = \"cxl_decoder_endpoint\",\n\t.release = cxl_endpoint_decoder_release,\n\t.groups = cxl_decoder_endpoint_attribute_groups,\n};\n\nstatic const struct device_type cxl_decoder_switch_type = {\n\t.name = \"cxl_decoder_switch\",\n\t.release = cxl_switch_decoder_release,\n\t.groups = cxl_decoder_switch_attribute_groups,\n};\n\nstatic const struct device_type cxl_decoder_root_type = {\n\t.name = \"cxl_decoder_root\",\n\t.release = cxl_root_decoder_release,\n\t.groups = cxl_decoder_root_attribute_groups,\n};\n\nbool is_endpoint_decoder(struct device *dev)\n{\n\treturn dev->type == &cxl_decoder_endpoint_type;\n}\nEXPORT_SYMBOL_NS_GPL(is_endpoint_decoder, CXL);\n\nbool is_root_decoder(struct device *dev)\n{\n\treturn dev->type == &cxl_decoder_root_type;\n}\nEXPORT_SYMBOL_NS_GPL(is_root_decoder, CXL);\n\nbool is_switch_decoder(struct device *dev)\n{\n\treturn is_root_decoder(dev) || dev->type == &cxl_decoder_switch_type;\n}\nEXPORT_SYMBOL_NS_GPL(is_switch_decoder, CXL);\n\nstruct cxl_decoder *to_cxl_decoder(struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev,\n\t\t\t  !is_switch_decoder(dev) && !is_endpoint_decoder(dev),\n\t\t\t  \"not a cxl_decoder device\\n\"))\n\t\treturn NULL;\n\treturn container_of(dev, struct cxl_decoder, dev);\n}\nEXPORT_SYMBOL_NS_GPL(to_cxl_decoder, CXL);\n\nstruct cxl_endpoint_decoder *to_cxl_endpoint_decoder(struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev, !is_endpoint_decoder(dev),\n\t\t\t  \"not a cxl_endpoint_decoder device\\n\"))\n\t\treturn NULL;\n\treturn container_of(dev, struct cxl_endpoint_decoder, cxld.dev);\n}\nEXPORT_SYMBOL_NS_GPL(to_cxl_endpoint_decoder, CXL);\n\nstruct cxl_switch_decoder *to_cxl_switch_decoder(struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev, !is_switch_decoder(dev),\n\t\t\t  \"not a cxl_switch_decoder device\\n\"))\n\t\treturn NULL;\n\treturn container_of(dev, struct cxl_switch_decoder, cxld.dev);\n}\nEXPORT_SYMBOL_NS_GPL(to_cxl_switch_decoder, CXL);\n\nstatic void cxl_ep_release(struct cxl_ep *ep)\n{\n\tput_device(ep->ep);\n\tkfree(ep);\n}\n\nstatic void cxl_ep_remove(struct cxl_port *port, struct cxl_ep *ep)\n{\n\tif (!ep)\n\t\treturn;\n\txa_erase(&port->endpoints, (unsigned long) ep->ep);\n\tcxl_ep_release(ep);\n}\n\nstatic void cxl_port_release(struct device *dev)\n{\n\tstruct cxl_port *port = to_cxl_port(dev);\n\tunsigned long index;\n\tstruct cxl_ep *ep;\n\n\txa_for_each(&port->endpoints, index, ep)\n\t\tcxl_ep_remove(port, ep);\n\txa_destroy(&port->endpoints);\n\txa_destroy(&port->dports);\n\txa_destroy(&port->regions);\n\tida_free(&cxl_port_ida, port->id);\n\tkfree(port);\n}\n\nstatic const struct attribute_group *cxl_port_attribute_groups[] = {\n\t&cxl_base_attribute_group,\n\tNULL,\n};\n\nstatic const struct device_type cxl_port_type = {\n\t.name = \"cxl_port\",\n\t.release = cxl_port_release,\n\t.groups = cxl_port_attribute_groups,\n};\n\nbool is_cxl_port(const struct device *dev)\n{\n\treturn dev->type == &cxl_port_type;\n}\nEXPORT_SYMBOL_NS_GPL(is_cxl_port, CXL);\n\nstruct cxl_port *to_cxl_port(const struct device *dev)\n{\n\tif (dev_WARN_ONCE(dev, dev->type != &cxl_port_type,\n\t\t\t  \"not a cxl_port device\\n\"))\n\t\treturn NULL;\n\treturn container_of(dev, struct cxl_port, dev);\n}\nEXPORT_SYMBOL_NS_GPL(to_cxl_port, CXL);\n\nstatic void unregister_port(void *_port)\n{\n\tstruct cxl_port *port = _port;\n\tstruct cxl_port *parent;\n\tstruct device *lock_dev;\n\n\tif (is_cxl_root(port))\n\t\tparent = NULL;\n\telse\n\t\tparent = to_cxl_port(port->dev.parent);\n\n\t \n\tif (!parent)\n\t\tlock_dev = port->uport_dev;\n\telse if (is_cxl_root(parent))\n\t\tlock_dev = parent->uport_dev;\n\telse\n\t\tlock_dev = &parent->dev;\n\n\tdevice_lock_assert(lock_dev);\n\tport->dead = true;\n\tdevice_unregister(&port->dev);\n}\n\nstatic void cxl_unlink_uport(void *_port)\n{\n\tstruct cxl_port *port = _port;\n\n\tsysfs_remove_link(&port->dev.kobj, \"uport\");\n}\n\nstatic int devm_cxl_link_uport(struct device *host, struct cxl_port *port)\n{\n\tint rc;\n\n\trc = sysfs_create_link(&port->dev.kobj, &port->uport_dev->kobj,\n\t\t\t       \"uport\");\n\tif (rc)\n\t\treturn rc;\n\treturn devm_add_action_or_reset(host, cxl_unlink_uport, port);\n}\n\nstatic void cxl_unlink_parent_dport(void *_port)\n{\n\tstruct cxl_port *port = _port;\n\n\tsysfs_remove_link(&port->dev.kobj, \"parent_dport\");\n}\n\nstatic int devm_cxl_link_parent_dport(struct device *host,\n\t\t\t\t      struct cxl_port *port,\n\t\t\t\t      struct cxl_dport *parent_dport)\n{\n\tint rc;\n\n\tif (!parent_dport)\n\t\treturn 0;\n\n\trc = sysfs_create_link(&port->dev.kobj, &parent_dport->dport_dev->kobj,\n\t\t\t       \"parent_dport\");\n\tif (rc)\n\t\treturn rc;\n\treturn devm_add_action_or_reset(host, cxl_unlink_parent_dport, port);\n}\n\nstatic struct lock_class_key cxl_port_key;\n\nstatic struct cxl_port *cxl_port_alloc(struct device *uport_dev,\n\t\t\t\t       resource_size_t component_reg_phys,\n\t\t\t\t       struct cxl_dport *parent_dport)\n{\n\tstruct cxl_port *port;\n\tstruct device *dev;\n\tint rc;\n\n\tport = kzalloc(sizeof(*port), GFP_KERNEL);\n\tif (!port)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trc = ida_alloc(&cxl_port_ida, GFP_KERNEL);\n\tif (rc < 0)\n\t\tgoto err;\n\tport->id = rc;\n\tport->uport_dev = uport_dev;\n\n\t \n\tdev = &port->dev;\n\tif (parent_dport) {\n\t\tstruct cxl_port *parent_port = parent_dport->port;\n\t\tstruct cxl_port *iter;\n\n\t\tdev->parent = &parent_port->dev;\n\t\tport->depth = parent_port->depth + 1;\n\t\tport->parent_dport = parent_dport;\n\n\t\t \n\t\titer = port;\n\t\twhile (!iter->host_bridge &&\n\t\t       !is_cxl_root(to_cxl_port(iter->dev.parent)))\n\t\t\titer = to_cxl_port(iter->dev.parent);\n\t\tif (iter->host_bridge)\n\t\t\tport->host_bridge = iter->host_bridge;\n\t\telse if (parent_dport->rch)\n\t\t\tport->host_bridge = parent_dport->dport_dev;\n\t\telse\n\t\t\tport->host_bridge = iter->uport_dev;\n\t\tdev_dbg(uport_dev, \"host-bridge: %s\\n\",\n\t\t\tdev_name(port->host_bridge));\n\t} else\n\t\tdev->parent = uport_dev;\n\n\tport->component_reg_phys = component_reg_phys;\n\tida_init(&port->decoder_ida);\n\tport->hdm_end = -1;\n\tport->commit_end = -1;\n\txa_init(&port->dports);\n\txa_init(&port->endpoints);\n\txa_init(&port->regions);\n\n\tdevice_initialize(dev);\n\tlockdep_set_class_and_subclass(&dev->mutex, &cxl_port_key, port->depth);\n\tdevice_set_pm_not_required(dev);\n\tdev->bus = &cxl_bus_type;\n\tdev->type = &cxl_port_type;\n\n\treturn port;\n\nerr:\n\tkfree(port);\n\treturn ERR_PTR(rc);\n}\n\nstatic int cxl_setup_comp_regs(struct device *host, struct cxl_register_map *map,\n\t\t\t       resource_size_t component_reg_phys)\n{\n\tif (component_reg_phys == CXL_RESOURCE_NONE)\n\t\treturn 0;\n\n\t*map = (struct cxl_register_map) {\n\t\t.host = host,\n\t\t.reg_type = CXL_REGLOC_RBI_COMPONENT,\n\t\t.resource = component_reg_phys,\n\t\t.max_size = CXL_COMPONENT_REG_BLOCK_SIZE,\n\t};\n\n\treturn cxl_setup_regs(map);\n}\n\nstatic int cxl_port_setup_regs(struct cxl_port *port,\n\t\t\tresource_size_t component_reg_phys)\n{\n\tif (dev_is_platform(port->uport_dev))\n\t\treturn 0;\n\treturn cxl_setup_comp_regs(&port->dev, &port->comp_map,\n\t\t\t\t   component_reg_phys);\n}\n\nstatic int cxl_dport_setup_regs(struct device *host, struct cxl_dport *dport,\n\t\t\t\tresource_size_t component_reg_phys)\n{\n\tint rc;\n\n\tif (dev_is_platform(dport->dport_dev))\n\t\treturn 0;\n\n\t \n\trc = cxl_setup_comp_regs(dport->dport_dev, &dport->comp_map,\n\t\t\t\t component_reg_phys);\n\tdport->comp_map.host = host;\n\treturn rc;\n}\n\nstatic struct cxl_port *__devm_cxl_add_port(struct device *host,\n\t\t\t\t\t    struct device *uport_dev,\n\t\t\t\t\t    resource_size_t component_reg_phys,\n\t\t\t\t\t    struct cxl_dport *parent_dport)\n{\n\tstruct cxl_port *port;\n\tstruct device *dev;\n\tint rc;\n\n\tport = cxl_port_alloc(uport_dev, component_reg_phys, parent_dport);\n\tif (IS_ERR(port))\n\t\treturn port;\n\n\tdev = &port->dev;\n\tif (is_cxl_memdev(uport_dev))\n\t\trc = dev_set_name(dev, \"endpoint%d\", port->id);\n\telse if (parent_dport)\n\t\trc = dev_set_name(dev, \"port%d\", port->id);\n\telse\n\t\trc = dev_set_name(dev, \"root%d\", port->id);\n\tif (rc)\n\t\tgoto err;\n\n\trc = cxl_port_setup_regs(port, component_reg_phys);\n\tif (rc)\n\t\tgoto err;\n\n\trc = device_add(dev);\n\tif (rc)\n\t\tgoto err;\n\n\trc = devm_add_action_or_reset(host, unregister_port, port);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\trc = devm_cxl_link_uport(host, port);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\trc = devm_cxl_link_parent_dport(host, port, parent_dport);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\treturn port;\n\nerr:\n\tput_device(dev);\n\treturn ERR_PTR(rc);\n}\n\n \nstruct cxl_port *devm_cxl_add_port(struct device *host,\n\t\t\t\t   struct device *uport_dev,\n\t\t\t\t   resource_size_t component_reg_phys,\n\t\t\t\t   struct cxl_dport *parent_dport)\n{\n\tstruct cxl_port *port, *parent_port;\n\n\tport = __devm_cxl_add_port(host, uport_dev, component_reg_phys,\n\t\t\t\t   parent_dport);\n\n\tparent_port = parent_dport ? parent_dport->port : NULL;\n\tif (IS_ERR(port)) {\n\t\tdev_dbg(uport_dev, \"Failed to add%s%s%s: %ld\\n\",\n\t\t\tparent_port ? \" port to \" : \"\",\n\t\t\tparent_port ? dev_name(&parent_port->dev) : \"\",\n\t\t\tparent_port ? \"\" : \" root port\",\n\t\t\tPTR_ERR(port));\n\t} else {\n\t\tdev_dbg(uport_dev, \"%s added%s%s%s\\n\",\n\t\t\tdev_name(&port->dev),\n\t\t\tparent_port ? \" to \" : \"\",\n\t\t\tparent_port ? dev_name(&parent_port->dev) : \"\",\n\t\t\tparent_port ? \"\" : \" (root port)\");\n\t}\n\n\treturn port;\n}\nEXPORT_SYMBOL_NS_GPL(devm_cxl_add_port, CXL);\n\nstruct pci_bus *cxl_port_to_pci_bus(struct cxl_port *port)\n{\n\t \n\tif (is_cxl_root(port))\n\t\treturn NULL;\n\n\tif (dev_is_pci(port->uport_dev)) {\n\t\tstruct pci_dev *pdev = to_pci_dev(port->uport_dev);\n\n\t\treturn pdev->subordinate;\n\t}\n\n\treturn xa_load(&cxl_root_buses, (unsigned long)port->uport_dev);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_port_to_pci_bus, CXL);\n\nstatic void unregister_pci_bus(void *uport_dev)\n{\n\txa_erase(&cxl_root_buses, (unsigned long)uport_dev);\n}\n\nint devm_cxl_register_pci_bus(struct device *host, struct device *uport_dev,\n\t\t\t      struct pci_bus *bus)\n{\n\tint rc;\n\n\tif (dev_is_pci(uport_dev))\n\t\treturn -EINVAL;\n\n\trc = xa_insert(&cxl_root_buses, (unsigned long)uport_dev, bus,\n\t\t       GFP_KERNEL);\n\tif (rc)\n\t\treturn rc;\n\treturn devm_add_action_or_reset(host, unregister_pci_bus, uport_dev);\n}\nEXPORT_SYMBOL_NS_GPL(devm_cxl_register_pci_bus, CXL);\n\nstatic bool dev_is_cxl_root_child(struct device *dev)\n{\n\tstruct cxl_port *port, *parent;\n\n\tif (!is_cxl_port(dev))\n\t\treturn false;\n\n\tport = to_cxl_port(dev);\n\tif (is_cxl_root(port))\n\t\treturn false;\n\n\tparent = to_cxl_port(port->dev.parent);\n\tif (is_cxl_root(parent))\n\t\treturn true;\n\n\treturn false;\n}\n\nstruct cxl_port *find_cxl_root(struct cxl_port *port)\n{\n\tstruct cxl_port *iter = port;\n\n\twhile (iter && !is_cxl_root(iter))\n\t\titer = to_cxl_port(iter->dev.parent);\n\n\tif (!iter)\n\t\treturn NULL;\n\tget_device(&iter->dev);\n\treturn iter;\n}\nEXPORT_SYMBOL_NS_GPL(find_cxl_root, CXL);\n\nstatic struct cxl_dport *find_dport(struct cxl_port *port, int id)\n{\n\tstruct cxl_dport *dport;\n\tunsigned long index;\n\n\tdevice_lock_assert(&port->dev);\n\txa_for_each(&port->dports, index, dport)\n\t\tif (dport->port_id == id)\n\t\t\treturn dport;\n\treturn NULL;\n}\n\nstatic int add_dport(struct cxl_port *port, struct cxl_dport *dport)\n{\n\tstruct cxl_dport *dup;\n\tint rc;\n\n\tdevice_lock_assert(&port->dev);\n\tdup = find_dport(port, dport->port_id);\n\tif (dup) {\n\t\tdev_err(&port->dev,\n\t\t\t\"unable to add dport%d-%s non-unique port id (%s)\\n\",\n\t\t\tdport->port_id, dev_name(dport->dport_dev),\n\t\t\tdev_name(dup->dport_dev));\n\t\treturn -EBUSY;\n\t}\n\n\trc = xa_insert(&port->dports, (unsigned long)dport->dport_dev, dport,\n\t\t       GFP_KERNEL);\n\tif (rc)\n\t\treturn rc;\n\n\tport->nr_dports++;\n\treturn 0;\n}\n\n \nstatic void cond_cxl_root_lock(struct cxl_port *port)\n{\n\tif (is_cxl_root(port))\n\t\tdevice_lock(&port->dev);\n}\n\nstatic void cond_cxl_root_unlock(struct cxl_port *port)\n{\n\tif (is_cxl_root(port))\n\t\tdevice_unlock(&port->dev);\n}\n\nstatic void cxl_dport_remove(void *data)\n{\n\tstruct cxl_dport *dport = data;\n\tstruct cxl_port *port = dport->port;\n\n\txa_erase(&port->dports, (unsigned long) dport->dport_dev);\n\tput_device(dport->dport_dev);\n}\n\nstatic void cxl_dport_unlink(void *data)\n{\n\tstruct cxl_dport *dport = data;\n\tstruct cxl_port *port = dport->port;\n\tchar link_name[CXL_TARGET_STRLEN];\n\n\tsprintf(link_name, \"dport%d\", dport->port_id);\n\tsysfs_remove_link(&port->dev.kobj, link_name);\n}\n\nstatic struct cxl_dport *\n__devm_cxl_add_dport(struct cxl_port *port, struct device *dport_dev,\n\t\t     int port_id, resource_size_t component_reg_phys,\n\t\t     resource_size_t rcrb)\n{\n\tchar link_name[CXL_TARGET_STRLEN];\n\tstruct cxl_dport *dport;\n\tstruct device *host;\n\tint rc;\n\n\tif (is_cxl_root(port))\n\t\thost = port->uport_dev;\n\telse\n\t\thost = &port->dev;\n\n\tif (!host->driver) {\n\t\tdev_WARN_ONCE(&port->dev, 1, \"dport:%s bad devm context\\n\",\n\t\t\t      dev_name(dport_dev));\n\t\treturn ERR_PTR(-ENXIO);\n\t}\n\n\tif (snprintf(link_name, CXL_TARGET_STRLEN, \"dport%d\", port_id) >=\n\t    CXL_TARGET_STRLEN)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tdport = devm_kzalloc(host, sizeof(*dport), GFP_KERNEL);\n\tif (!dport)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdport->dport_dev = dport_dev;\n\tdport->port_id = port_id;\n\tdport->port = port;\n\n\tif (rcrb == CXL_RESOURCE_NONE) {\n\t\trc = cxl_dport_setup_regs(&port->dev, dport,\n\t\t\t\t\t  component_reg_phys);\n\t\tif (rc)\n\t\t\treturn ERR_PTR(rc);\n\t} else {\n\t\tdport->rcrb.base = rcrb;\n\t\tcomponent_reg_phys = __rcrb_to_component(dport_dev, &dport->rcrb,\n\t\t\t\t\t\t\t CXL_RCRB_DOWNSTREAM);\n\t\tif (component_reg_phys == CXL_RESOURCE_NONE) {\n\t\t\tdev_warn(dport_dev, \"Invalid Component Registers in RCRB\");\n\t\t\treturn ERR_PTR(-ENXIO);\n\t\t}\n\n\t\t \n\t\trc = cxl_dport_setup_regs(NULL, dport, component_reg_phys);\n\t\tif (rc)\n\t\t\treturn ERR_PTR(rc);\n\n\t\tdport->rch = true;\n\t}\n\n\tif (component_reg_phys != CXL_RESOURCE_NONE)\n\t\tdev_dbg(dport_dev, \"Component Registers found for dport: %pa\\n\",\n\t\t\t&component_reg_phys);\n\n\tcond_cxl_root_lock(port);\n\trc = add_dport(port, dport);\n\tcond_cxl_root_unlock(port);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\tget_device(dport_dev);\n\trc = devm_add_action_or_reset(host, cxl_dport_remove, dport);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\trc = sysfs_create_link(&port->dev.kobj, &dport_dev->kobj, link_name);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\trc = devm_add_action_or_reset(host, cxl_dport_unlink, dport);\n\tif (rc)\n\t\treturn ERR_PTR(rc);\n\n\treturn dport;\n}\n\n \nstruct cxl_dport *devm_cxl_add_dport(struct cxl_port *port,\n\t\t\t\t     struct device *dport_dev, int port_id,\n\t\t\t\t     resource_size_t component_reg_phys)\n{\n\tstruct cxl_dport *dport;\n\n\tdport = __devm_cxl_add_dport(port, dport_dev, port_id,\n\t\t\t\t     component_reg_phys, CXL_RESOURCE_NONE);\n\tif (IS_ERR(dport)) {\n\t\tdev_dbg(dport_dev, \"failed to add dport to %s: %ld\\n\",\n\t\t\tdev_name(&port->dev), PTR_ERR(dport));\n\t} else {\n\t\tdev_dbg(dport_dev, \"dport added to %s\\n\",\n\t\t\tdev_name(&port->dev));\n\t}\n\n\treturn dport;\n}\nEXPORT_SYMBOL_NS_GPL(devm_cxl_add_dport, CXL);\n\n \nstruct cxl_dport *devm_cxl_add_rch_dport(struct cxl_port *port,\n\t\t\t\t\t struct device *dport_dev, int port_id,\n\t\t\t\t\t resource_size_t rcrb)\n{\n\tstruct cxl_dport *dport;\n\n\tif (rcrb == CXL_RESOURCE_NONE) {\n\t\tdev_dbg(&port->dev, \"failed to add RCH dport, missing RCRB\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tdport = __devm_cxl_add_dport(port, dport_dev, port_id,\n\t\t\t\t     CXL_RESOURCE_NONE, rcrb);\n\tif (IS_ERR(dport)) {\n\t\tdev_dbg(dport_dev, \"failed to add RCH dport to %s: %ld\\n\",\n\t\t\tdev_name(&port->dev), PTR_ERR(dport));\n\t} else {\n\t\tdev_dbg(dport_dev, \"RCH dport added to %s\\n\",\n\t\t\tdev_name(&port->dev));\n\t}\n\n\treturn dport;\n}\nEXPORT_SYMBOL_NS_GPL(devm_cxl_add_rch_dport, CXL);\n\nstatic int add_ep(struct cxl_ep *new)\n{\n\tstruct cxl_port *port = new->dport->port;\n\tint rc;\n\n\tdevice_lock(&port->dev);\n\tif (port->dead) {\n\t\tdevice_unlock(&port->dev);\n\t\treturn -ENXIO;\n\t}\n\trc = xa_insert(&port->endpoints, (unsigned long)new->ep, new,\n\t\t       GFP_KERNEL);\n\tdevice_unlock(&port->dev);\n\n\treturn rc;\n}\n\n \nstatic int cxl_add_ep(struct cxl_dport *dport, struct device *ep_dev)\n{\n\tstruct cxl_ep *ep;\n\tint rc;\n\n\tep = kzalloc(sizeof(*ep), GFP_KERNEL);\n\tif (!ep)\n\t\treturn -ENOMEM;\n\n\tep->ep = get_device(ep_dev);\n\tep->dport = dport;\n\n\trc = add_ep(ep);\n\tif (rc)\n\t\tcxl_ep_release(ep);\n\treturn rc;\n}\n\nstruct cxl_find_port_ctx {\n\tconst struct device *dport_dev;\n\tconst struct cxl_port *parent_port;\n\tstruct cxl_dport **dport;\n};\n\nstatic int match_port_by_dport(struct device *dev, const void *data)\n{\n\tconst struct cxl_find_port_ctx *ctx = data;\n\tstruct cxl_dport *dport;\n\tstruct cxl_port *port;\n\n\tif (!is_cxl_port(dev))\n\t\treturn 0;\n\tif (ctx->parent_port && dev->parent != &ctx->parent_port->dev)\n\t\treturn 0;\n\n\tport = to_cxl_port(dev);\n\tdport = cxl_find_dport_by_dev(port, ctx->dport_dev);\n\tif (ctx->dport)\n\t\t*ctx->dport = dport;\n\treturn dport != NULL;\n}\n\nstatic struct cxl_port *__find_cxl_port(struct cxl_find_port_ctx *ctx)\n{\n\tstruct device *dev;\n\n\tif (!ctx->dport_dev)\n\t\treturn NULL;\n\n\tdev = bus_find_device(&cxl_bus_type, NULL, ctx, match_port_by_dport);\n\tif (dev)\n\t\treturn to_cxl_port(dev);\n\treturn NULL;\n}\n\nstatic struct cxl_port *find_cxl_port(struct device *dport_dev,\n\t\t\t\t      struct cxl_dport **dport)\n{\n\tstruct cxl_find_port_ctx ctx = {\n\t\t.dport_dev = dport_dev,\n\t\t.dport = dport,\n\t};\n\tstruct cxl_port *port;\n\n\tport = __find_cxl_port(&ctx);\n\treturn port;\n}\n\nstatic struct cxl_port *find_cxl_port_at(struct cxl_port *parent_port,\n\t\t\t\t\t struct device *dport_dev,\n\t\t\t\t\t struct cxl_dport **dport)\n{\n\tstruct cxl_find_port_ctx ctx = {\n\t\t.dport_dev = dport_dev,\n\t\t.parent_port = parent_port,\n\t\t.dport = dport,\n\t};\n\tstruct cxl_port *port;\n\n\tport = __find_cxl_port(&ctx);\n\treturn port;\n}\n\n \nstatic struct device *grandparent(struct device *dev)\n{\n\tif (dev && dev->parent)\n\t\treturn dev->parent->parent;\n\treturn NULL;\n}\n\nstatic struct device *endpoint_host(struct cxl_port *endpoint)\n{\n\tstruct cxl_port *port = to_cxl_port(endpoint->dev.parent);\n\n\tif (is_cxl_root(port))\n\t\treturn port->uport_dev;\n\treturn &port->dev;\n}\n\nstatic void delete_endpoint(void *data)\n{\n\tstruct cxl_memdev *cxlmd = data;\n\tstruct cxl_port *endpoint = cxlmd->endpoint;\n\tstruct device *host = endpoint_host(endpoint);\n\n\tdevice_lock(host);\n\tif (host->driver && !endpoint->dead) {\n\t\tdevm_release_action(host, cxl_unlink_parent_dport, endpoint);\n\t\tdevm_release_action(host, cxl_unlink_uport, endpoint);\n\t\tdevm_release_action(host, unregister_port, endpoint);\n\t}\n\tcxlmd->endpoint = NULL;\n\tdevice_unlock(host);\n\tput_device(&endpoint->dev);\n\tput_device(host);\n}\n\nint cxl_endpoint_autoremove(struct cxl_memdev *cxlmd, struct cxl_port *endpoint)\n{\n\tstruct device *host = endpoint_host(endpoint);\n\tstruct device *dev = &cxlmd->dev;\n\n\tget_device(host);\n\tget_device(&endpoint->dev);\n\tcxlmd->endpoint = endpoint;\n\tcxlmd->depth = endpoint->depth;\n\treturn devm_add_action_or_reset(dev, delete_endpoint, cxlmd);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_endpoint_autoremove, CXL);\n\n \nstatic void delete_switch_port(struct cxl_port *port)\n{\n\tdevm_release_action(port->dev.parent, cxl_unlink_parent_dport, port);\n\tdevm_release_action(port->dev.parent, cxl_unlink_uport, port);\n\tdevm_release_action(port->dev.parent, unregister_port, port);\n}\n\nstatic void reap_dports(struct cxl_port *port)\n{\n\tstruct cxl_dport *dport;\n\tunsigned long index;\n\n\tdevice_lock_assert(&port->dev);\n\n\txa_for_each(&port->dports, index, dport) {\n\t\tdevm_release_action(&port->dev, cxl_dport_unlink, dport);\n\t\tdevm_release_action(&port->dev, cxl_dport_remove, dport);\n\t\tdevm_kfree(&port->dev, dport);\n\t}\n}\n\nstruct detach_ctx {\n\tstruct cxl_memdev *cxlmd;\n\tint depth;\n};\n\nstatic int port_has_memdev(struct device *dev, const void *data)\n{\n\tconst struct detach_ctx *ctx = data;\n\tstruct cxl_port *port;\n\n\tif (!is_cxl_port(dev))\n\t\treturn 0;\n\n\tport = to_cxl_port(dev);\n\tif (port->depth != ctx->depth)\n\t\treturn 0;\n\n\treturn !!cxl_ep_load(port, ctx->cxlmd);\n}\n\nstatic void cxl_detach_ep(void *data)\n{\n\tstruct cxl_memdev *cxlmd = data;\n\n\tfor (int i = cxlmd->depth - 1; i >= 1; i--) {\n\t\tstruct cxl_port *port, *parent_port;\n\t\tstruct detach_ctx ctx = {\n\t\t\t.cxlmd = cxlmd,\n\t\t\t.depth = i,\n\t\t};\n\t\tstruct device *dev;\n\t\tstruct cxl_ep *ep;\n\t\tbool died = false;\n\n\t\tdev = bus_find_device(&cxl_bus_type, NULL, &ctx,\n\t\t\t\t      port_has_memdev);\n\t\tif (!dev)\n\t\t\tcontinue;\n\t\tport = to_cxl_port(dev);\n\n\t\tparent_port = to_cxl_port(port->dev.parent);\n\t\tdevice_lock(&parent_port->dev);\n\t\tdevice_lock(&port->dev);\n\t\tep = cxl_ep_load(port, cxlmd);\n\t\tdev_dbg(&cxlmd->dev, \"disconnect %s from %s\\n\",\n\t\t\tep ? dev_name(ep->ep) : \"\", dev_name(&port->dev));\n\t\tcxl_ep_remove(port, ep);\n\t\tif (ep && !port->dead && xa_empty(&port->endpoints) &&\n\t\t    !is_cxl_root(parent_port) && parent_port->dev.driver) {\n\t\t\t \n\t\t\tdied = true;\n\t\t\tport->dead = true;\n\t\t\treap_dports(port);\n\t\t}\n\t\tdevice_unlock(&port->dev);\n\n\t\tif (died) {\n\t\t\tdev_dbg(&cxlmd->dev, \"delete %s\\n\",\n\t\t\t\tdev_name(&port->dev));\n\t\t\tdelete_switch_port(port);\n\t\t}\n\t\tput_device(&port->dev);\n\t\tdevice_unlock(&parent_port->dev);\n\t}\n}\n\nstatic resource_size_t find_component_registers(struct device *dev)\n{\n\tstruct cxl_register_map map;\n\tstruct pci_dev *pdev;\n\n\t \n\tif (!dev_is_pci(dev))\n\t\treturn CXL_RESOURCE_NONE;\n\n\tpdev = to_pci_dev(dev);\n\n\tcxl_find_regblock(pdev, CXL_REGLOC_RBI_COMPONENT, &map);\n\treturn map.resource;\n}\n\nstatic int add_port_attach_ep(struct cxl_memdev *cxlmd,\n\t\t\t      struct device *uport_dev,\n\t\t\t      struct device *dport_dev)\n{\n\tstruct device *dparent = grandparent(dport_dev);\n\tstruct cxl_port *port, *parent_port = NULL;\n\tstruct cxl_dport *dport, *parent_dport;\n\tresource_size_t component_reg_phys;\n\tint rc;\n\n\tif (!dparent) {\n\t\t \n\t\tdev_dbg(&cxlmd->dev, \"%s is a root dport\\n\",\n\t\t\tdev_name(dport_dev));\n\t\treturn -ENXIO;\n\t}\n\n\tparent_port = find_cxl_port(dparent, &parent_dport);\n\tif (!parent_port) {\n\t\t \n\t\treturn -EAGAIN;\n\t}\n\n\tdevice_lock(&parent_port->dev);\n\tif (!parent_port->dev.driver) {\n\t\tdev_warn(&cxlmd->dev,\n\t\t\t \"port %s:%s disabled, failed to enumerate CXL.mem\\n\",\n\t\t\t dev_name(&parent_port->dev), dev_name(uport_dev));\n\t\tport = ERR_PTR(-ENXIO);\n\t\tgoto out;\n\t}\n\n\tport = find_cxl_port_at(parent_port, dport_dev, &dport);\n\tif (!port) {\n\t\tcomponent_reg_phys = find_component_registers(uport_dev);\n\t\tport = devm_cxl_add_port(&parent_port->dev, uport_dev,\n\t\t\t\t\t component_reg_phys, parent_dport);\n\t\t \n\t\tif (!IS_ERR(port))\n\t\t\tport = find_cxl_port_at(parent_port, dport_dev, &dport);\n\t}\nout:\n\tdevice_unlock(&parent_port->dev);\n\n\tif (IS_ERR(port))\n\t\trc = PTR_ERR(port);\n\telse {\n\t\tdev_dbg(&cxlmd->dev, \"add to new port %s:%s\\n\",\n\t\t\tdev_name(&port->dev), dev_name(port->uport_dev));\n\t\trc = cxl_add_ep(dport, &cxlmd->dev);\n\t\tif (rc == -EBUSY) {\n\t\t\t \n\t\t\trc = -ENXIO;\n\t\t}\n\t\tput_device(&port->dev);\n\t}\n\n\tput_device(&parent_port->dev);\n\treturn rc;\n}\n\nint devm_cxl_enumerate_ports(struct cxl_memdev *cxlmd)\n{\n\tstruct device *dev = &cxlmd->dev;\n\tstruct device *iter;\n\tint rc;\n\n\t \n\tif (cxlmd->cxlds->rcd)\n\t\treturn 0;\n\n\trc = devm_add_action_or_reset(&cxlmd->dev, cxl_detach_ep, cxlmd);\n\tif (rc)\n\t\treturn rc;\n\n\t \nretry:\n\tfor (iter = dev; iter; iter = grandparent(iter)) {\n\t\tstruct device *dport_dev = grandparent(iter);\n\t\tstruct device *uport_dev;\n\t\tstruct cxl_dport *dport;\n\t\tstruct cxl_port *port;\n\n\t\tif (!dport_dev)\n\t\t\treturn 0;\n\n\t\tuport_dev = dport_dev->parent;\n\t\tif (!uport_dev) {\n\t\t\tdev_warn(dev, \"at %s no parent for dport: %s\\n\",\n\t\t\t\t dev_name(iter), dev_name(dport_dev));\n\t\t\treturn -ENXIO;\n\t\t}\n\n\t\tdev_dbg(dev, \"scan: iter: %s dport_dev: %s parent: %s\\n\",\n\t\t\tdev_name(iter), dev_name(dport_dev),\n\t\t\tdev_name(uport_dev));\n\t\tport = find_cxl_port(dport_dev, &dport);\n\t\tif (port) {\n\t\t\tdev_dbg(&cxlmd->dev,\n\t\t\t\t\"found already registered port %s:%s\\n\",\n\t\t\t\tdev_name(&port->dev),\n\t\t\t\tdev_name(port->uport_dev));\n\t\t\trc = cxl_add_ep(dport, &cxlmd->dev);\n\n\t\t\t \n\t\t\tif (rc && rc != -EBUSY) {\n\t\t\t\tput_device(&port->dev);\n\t\t\t\treturn rc;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (!dev_is_cxl_root_child(&port->dev)) {\n\t\t\t\tput_device(&port->dev);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tput_device(&port->dev);\n\t\t\treturn 0;\n\t\t}\n\n\t\trc = add_port_attach_ep(cxlmd, uport_dev, dport_dev);\n\t\t \n\t\tif (rc == -EAGAIN)\n\t\t\tcontinue;\n\t\t \n\t\tif (rc)\n\t\t\treturn rc;\n\t\t \n\t\tgoto retry;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(devm_cxl_enumerate_ports, CXL);\n\nstruct cxl_port *cxl_pci_find_port(struct pci_dev *pdev,\n\t\t\t\t   struct cxl_dport **dport)\n{\n\treturn find_cxl_port(pdev->dev.parent, dport);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_pci_find_port, CXL);\n\nstruct cxl_port *cxl_mem_find_port(struct cxl_memdev *cxlmd,\n\t\t\t\t   struct cxl_dport **dport)\n{\n\treturn find_cxl_port(grandparent(&cxlmd->dev), dport);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_mem_find_port, CXL);\n\nstatic int decoder_populate_targets(struct cxl_switch_decoder *cxlsd,\n\t\t\t\t    struct cxl_port *port, int *target_map)\n{\n\tint i;\n\n\tif (!target_map)\n\t\treturn 0;\n\n\tdevice_lock_assert(&port->dev);\n\n\tif (xa_empty(&port->dports))\n\t\treturn -EINVAL;\n\n\tguard(rwsem_write)(&cxl_region_rwsem);\n\tfor (i = 0; i < cxlsd->cxld.interleave_ways; i++) {\n\t\tstruct cxl_dport *dport = find_dport(port, target_map[i]);\n\n\t\tif (!dport)\n\t\t\treturn -ENXIO;\n\t\tcxlsd->target[i] = dport;\n\t}\n\n\treturn 0;\n}\n\nstruct cxl_dport *cxl_hb_modulo(struct cxl_root_decoder *cxlrd, int pos)\n{\n\tstruct cxl_switch_decoder *cxlsd = &cxlrd->cxlsd;\n\tstruct cxl_decoder *cxld = &cxlsd->cxld;\n\tint iw;\n\n\tiw = cxld->interleave_ways;\n\tif (dev_WARN_ONCE(&cxld->dev, iw != cxlsd->nr_targets,\n\t\t\t  \"misconfigured root decoder\\n\"))\n\t\treturn NULL;\n\n\treturn cxlrd->cxlsd.target[pos % iw];\n}\nEXPORT_SYMBOL_NS_GPL(cxl_hb_modulo, CXL);\n\nstatic struct lock_class_key cxl_decoder_key;\n\n \nstatic int cxl_decoder_init(struct cxl_port *port, struct cxl_decoder *cxld)\n{\n\tstruct device *dev;\n\tint rc;\n\n\trc = ida_alloc(&port->decoder_ida, GFP_KERNEL);\n\tif (rc < 0)\n\t\treturn rc;\n\n\t \n\tget_device(&port->dev);\n\tcxld->id = rc;\n\n\tdev = &cxld->dev;\n\tdevice_initialize(dev);\n\tlockdep_set_class(&dev->mutex, &cxl_decoder_key);\n\tdevice_set_pm_not_required(dev);\n\tdev->parent = &port->dev;\n\tdev->bus = &cxl_bus_type;\n\n\t \n\tcxld->interleave_ways = 1;\n\tcxld->interleave_granularity = PAGE_SIZE;\n\tcxld->target_type = CXL_DECODER_HOSTONLYMEM;\n\tcxld->hpa_range = (struct range) {\n\t\t.start = 0,\n\t\t.end = -1,\n\t};\n\n\treturn 0;\n}\n\nstatic int cxl_switch_decoder_init(struct cxl_port *port,\n\t\t\t\t   struct cxl_switch_decoder *cxlsd,\n\t\t\t\t   int nr_targets)\n{\n\tif (nr_targets > CXL_DECODER_MAX_INTERLEAVE)\n\t\treturn -EINVAL;\n\n\tcxlsd->nr_targets = nr_targets;\n\treturn cxl_decoder_init(port, &cxlsd->cxld);\n}\n\n \nstruct cxl_root_decoder *cxl_root_decoder_alloc(struct cxl_port *port,\n\t\t\t\t\t\tunsigned int nr_targets,\n\t\t\t\t\t\tcxl_calc_hb_fn calc_hb)\n{\n\tstruct cxl_root_decoder *cxlrd;\n\tstruct cxl_switch_decoder *cxlsd;\n\tstruct cxl_decoder *cxld;\n\tint rc;\n\n\tif (!is_cxl_root(port))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcxlrd = kzalloc(struct_size(cxlrd, cxlsd.target, nr_targets),\n\t\t\tGFP_KERNEL);\n\tif (!cxlrd)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tcxlsd = &cxlrd->cxlsd;\n\trc = cxl_switch_decoder_init(port, cxlsd, nr_targets);\n\tif (rc) {\n\t\tkfree(cxlrd);\n\t\treturn ERR_PTR(rc);\n\t}\n\n\tcxlrd->calc_hb = calc_hb;\n\tmutex_init(&cxlrd->range_lock);\n\n\tcxld = &cxlsd->cxld;\n\tcxld->dev.type = &cxl_decoder_root_type;\n\t \n\tatomic_set(&cxlrd->region_id, -1);\n\trc = memregion_alloc(GFP_KERNEL);\n\tif (rc < 0) {\n\t\tput_device(&cxld->dev);\n\t\treturn ERR_PTR(rc);\n\t}\n\n\tatomic_set(&cxlrd->region_id, rc);\n\treturn cxlrd;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_root_decoder_alloc, CXL);\n\n \nstruct cxl_switch_decoder *cxl_switch_decoder_alloc(struct cxl_port *port,\n\t\t\t\t\t\t    unsigned int nr_targets)\n{\n\tstruct cxl_switch_decoder *cxlsd;\n\tstruct cxl_decoder *cxld;\n\tint rc;\n\n\tif (is_cxl_root(port) || is_cxl_endpoint(port))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcxlsd = kzalloc(struct_size(cxlsd, target, nr_targets), GFP_KERNEL);\n\tif (!cxlsd)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\trc = cxl_switch_decoder_init(port, cxlsd, nr_targets);\n\tif (rc) {\n\t\tkfree(cxlsd);\n\t\treturn ERR_PTR(rc);\n\t}\n\n\tcxld = &cxlsd->cxld;\n\tcxld->dev.type = &cxl_decoder_switch_type;\n\treturn cxlsd;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_switch_decoder_alloc, CXL);\n\n \nstruct cxl_endpoint_decoder *cxl_endpoint_decoder_alloc(struct cxl_port *port)\n{\n\tstruct cxl_endpoint_decoder *cxled;\n\tstruct cxl_decoder *cxld;\n\tint rc;\n\n\tif (!is_cxl_endpoint(port))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcxled = kzalloc(sizeof(*cxled), GFP_KERNEL);\n\tif (!cxled)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tcxled->pos = -1;\n\tcxld = &cxled->cxld;\n\trc = cxl_decoder_init(port, cxld);\n\tif (rc)\t {\n\t\tkfree(cxled);\n\t\treturn ERR_PTR(rc);\n\t}\n\n\tcxld->dev.type = &cxl_decoder_endpoint_type;\n\treturn cxled;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_endpoint_decoder_alloc, CXL);\n\n \nint cxl_decoder_add_locked(struct cxl_decoder *cxld, int *target_map)\n{\n\tstruct cxl_port *port;\n\tstruct device *dev;\n\tint rc;\n\n\tif (WARN_ON_ONCE(!cxld))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON_ONCE(IS_ERR(cxld)))\n\t\treturn PTR_ERR(cxld);\n\n\tif (cxld->interleave_ways < 1)\n\t\treturn -EINVAL;\n\n\tdev = &cxld->dev;\n\n\tport = to_cxl_port(cxld->dev.parent);\n\tif (!is_endpoint_decoder(dev)) {\n\t\tstruct cxl_switch_decoder *cxlsd = to_cxl_switch_decoder(dev);\n\n\t\trc = decoder_populate_targets(cxlsd, port, target_map);\n\t\tif (rc && (cxld->flags & CXL_DECODER_F_ENABLE)) {\n\t\t\tdev_err(&port->dev,\n\t\t\t\t\"Failed to populate active decoder targets\\n\");\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\trc = dev_set_name(dev, \"decoder%d.%d\", port->id, cxld->id);\n\tif (rc)\n\t\treturn rc;\n\n\treturn device_add(dev);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_decoder_add_locked, CXL);\n\n \nint cxl_decoder_add(struct cxl_decoder *cxld, int *target_map)\n{\n\tstruct cxl_port *port;\n\tint rc;\n\n\tif (WARN_ON_ONCE(!cxld))\n\t\treturn -EINVAL;\n\n\tif (WARN_ON_ONCE(IS_ERR(cxld)))\n\t\treturn PTR_ERR(cxld);\n\n\tport = to_cxl_port(cxld->dev.parent);\n\n\tdevice_lock(&port->dev);\n\trc = cxl_decoder_add_locked(cxld, target_map);\n\tdevice_unlock(&port->dev);\n\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_decoder_add, CXL);\n\nstatic void cxld_unregister(void *dev)\n{\n\tstruct cxl_endpoint_decoder *cxled;\n\n\tif (is_endpoint_decoder(dev)) {\n\t\tcxled = to_cxl_endpoint_decoder(dev);\n\t\tcxl_decoder_kill_region(cxled);\n\t}\n\n\tdevice_unregister(dev);\n}\n\nint cxl_decoder_autoremove(struct device *host, struct cxl_decoder *cxld)\n{\n\treturn devm_add_action_or_reset(host, cxld_unregister, &cxld->dev);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_decoder_autoremove, CXL);\n\n \nint __cxl_driver_register(struct cxl_driver *cxl_drv, struct module *owner,\n\t\t\t  const char *modname)\n{\n\tif (!cxl_drv->probe) {\n\t\tpr_debug(\"%s ->probe() must be specified\\n\", modname);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!cxl_drv->name) {\n\t\tpr_debug(\"%s ->name must be specified\\n\", modname);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!cxl_drv->id) {\n\t\tpr_debug(\"%s ->id must be specified\\n\", modname);\n\t\treturn -EINVAL;\n\t}\n\n\tcxl_drv->drv.bus = &cxl_bus_type;\n\tcxl_drv->drv.owner = owner;\n\tcxl_drv->drv.mod_name = modname;\n\tcxl_drv->drv.name = cxl_drv->name;\n\n\treturn driver_register(&cxl_drv->drv);\n}\nEXPORT_SYMBOL_NS_GPL(__cxl_driver_register, CXL);\n\nvoid cxl_driver_unregister(struct cxl_driver *cxl_drv)\n{\n\tdriver_unregister(&cxl_drv->drv);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_driver_unregister, CXL);\n\nstatic int cxl_bus_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\treturn add_uevent_var(env, \"MODALIAS=\" CXL_MODALIAS_FMT,\n\t\t\t      cxl_device_id(dev));\n}\n\nstatic int cxl_bus_match(struct device *dev, struct device_driver *drv)\n{\n\treturn cxl_device_id(dev) == to_cxl_drv(drv)->id;\n}\n\nstatic int cxl_bus_probe(struct device *dev)\n{\n\tint rc;\n\n\trc = to_cxl_drv(dev->driver)->probe(dev);\n\tdev_dbg(dev, \"probe: %d\\n\", rc);\n\treturn rc;\n}\n\nstatic void cxl_bus_remove(struct device *dev)\n{\n\tstruct cxl_driver *cxl_drv = to_cxl_drv(dev->driver);\n\n\tif (cxl_drv->remove)\n\t\tcxl_drv->remove(dev);\n}\n\nstatic struct workqueue_struct *cxl_bus_wq;\n\nstatic void cxl_bus_rescan_queue(struct work_struct *w)\n{\n\tint rc = bus_rescan_devices(&cxl_bus_type);\n\n\tpr_debug(\"CXL bus rescan result: %d\\n\", rc);\n}\n\nvoid cxl_bus_rescan(void)\n{\n\tstatic DECLARE_WORK(rescan_work, cxl_bus_rescan_queue);\n\n\tqueue_work(cxl_bus_wq, &rescan_work);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_bus_rescan, CXL);\n\nvoid cxl_bus_drain(void)\n{\n\tdrain_workqueue(cxl_bus_wq);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_bus_drain, CXL);\n\nbool schedule_cxl_memdev_detach(struct cxl_memdev *cxlmd)\n{\n\treturn queue_work(cxl_bus_wq, &cxlmd->detach_work);\n}\nEXPORT_SYMBOL_NS_GPL(schedule_cxl_memdev_detach, CXL);\n\n \nstatic ssize_t flush_store(const struct bus_type *bus, const char *buf, size_t count)\n{\n\tif (sysfs_streq(buf, \"1\")) {\n\t\tflush_workqueue(cxl_bus_wq);\n\t\treturn count;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic BUS_ATTR_WO(flush);\n\nstatic struct attribute *cxl_bus_attributes[] = {\n\t&bus_attr_flush.attr,\n\tNULL,\n};\n\nstatic struct attribute_group cxl_bus_attribute_group = {\n\t.attrs = cxl_bus_attributes,\n};\n\nstatic const struct attribute_group *cxl_bus_attribute_groups[] = {\n\t&cxl_bus_attribute_group,\n\tNULL,\n};\n\nstruct bus_type cxl_bus_type = {\n\t.name = \"cxl\",\n\t.uevent = cxl_bus_uevent,\n\t.match = cxl_bus_match,\n\t.probe = cxl_bus_probe,\n\t.remove = cxl_bus_remove,\n\t.bus_groups = cxl_bus_attribute_groups,\n};\nEXPORT_SYMBOL_NS_GPL(cxl_bus_type, CXL);\n\nstatic struct dentry *cxl_debugfs;\n\nstruct dentry *cxl_debugfs_create_dir(const char *dir)\n{\n\treturn debugfs_create_dir(dir, cxl_debugfs);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_debugfs_create_dir, CXL);\n\nstatic __init int cxl_core_init(void)\n{\n\tint rc;\n\n\tcxl_debugfs = debugfs_create_dir(\"cxl\", NULL);\n\n\tcxl_mbox_init();\n\n\trc = cxl_memdev_init();\n\tif (rc)\n\t\treturn rc;\n\n\tcxl_bus_wq = alloc_ordered_workqueue(\"cxl_port\", 0);\n\tif (!cxl_bus_wq) {\n\t\trc = -ENOMEM;\n\t\tgoto err_wq;\n\t}\n\n\trc = bus_register(&cxl_bus_type);\n\tif (rc)\n\t\tgoto err_bus;\n\n\trc = cxl_region_init();\n\tif (rc)\n\t\tgoto err_region;\n\n\treturn 0;\n\nerr_region:\n\tbus_unregister(&cxl_bus_type);\nerr_bus:\n\tdestroy_workqueue(cxl_bus_wq);\nerr_wq:\n\tcxl_memdev_exit();\n\treturn rc;\n}\n\nstatic void cxl_core_exit(void)\n{\n\tcxl_region_exit();\n\tbus_unregister(&cxl_bus_type);\n\tdestroy_workqueue(cxl_bus_wq);\n\tcxl_memdev_exit();\n\tdebugfs_remove_recursive(cxl_debugfs);\n}\n\nsubsys_initcall(cxl_core_init);\nmodule_exit(cxl_core_exit);\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}