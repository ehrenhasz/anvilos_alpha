{
  "module_name": "mbox.c",
  "hash_id": "04d4f0be0feabb3e3ab2cc064bc554eaad5de439d193bc63a489a8d134541eac",
  "original_prompt": "Ingested from linux-6.6.14/drivers/cxl/core/mbox.c",
  "human_readable_source": "\n \n#include <linux/security.h>\n#include <linux/debugfs.h>\n#include <linux/ktime.h>\n#include <linux/mutex.h>\n#include <asm/unaligned.h>\n#include <cxlpci.h>\n#include <cxlmem.h>\n#include <cxl.h>\n\n#include \"core.h\"\n#include \"trace.h\"\n\nstatic bool cxl_raw_allow_all;\n\n \n\n#define cxl_for_each_cmd(cmd)                                                  \\\n\tfor ((cmd) = &cxl_mem_commands[0];                                     \\\n\t     ((cmd) - cxl_mem_commands) < ARRAY_SIZE(cxl_mem_commands); (cmd)++)\n\n#define CXL_CMD(_id, sin, sout, _flags)                                        \\\n\t[CXL_MEM_COMMAND_ID_##_id] = {                                         \\\n\t.info =\t{                                                              \\\n\t\t\t.id = CXL_MEM_COMMAND_ID_##_id,                        \\\n\t\t\t.size_in = sin,                                        \\\n\t\t\t.size_out = sout,                                      \\\n\t\t},                                                             \\\n\t.opcode = CXL_MBOX_OP_##_id,                                           \\\n\t.flags = _flags,                                                       \\\n\t}\n\n#define CXL_VARIABLE_PAYLOAD\t~0U\n \nstatic struct cxl_mem_command cxl_mem_commands[CXL_MEM_COMMAND_ID_MAX] = {\n\tCXL_CMD(IDENTIFY, 0, 0x43, CXL_CMD_FLAG_FORCE_ENABLE),\n#ifdef CONFIG_CXL_MEM_RAW_COMMANDS\n\tCXL_CMD(RAW, CXL_VARIABLE_PAYLOAD, CXL_VARIABLE_PAYLOAD, 0),\n#endif\n\tCXL_CMD(GET_SUPPORTED_LOGS, 0, CXL_VARIABLE_PAYLOAD, CXL_CMD_FLAG_FORCE_ENABLE),\n\tCXL_CMD(GET_FW_INFO, 0, 0x50, 0),\n\tCXL_CMD(GET_PARTITION_INFO, 0, 0x20, 0),\n\tCXL_CMD(GET_LSA, 0x8, CXL_VARIABLE_PAYLOAD, 0),\n\tCXL_CMD(GET_HEALTH_INFO, 0, 0x12, 0),\n\tCXL_CMD(GET_LOG, 0x18, CXL_VARIABLE_PAYLOAD, CXL_CMD_FLAG_FORCE_ENABLE),\n\tCXL_CMD(SET_PARTITION_INFO, 0x0a, 0, 0),\n\tCXL_CMD(SET_LSA, CXL_VARIABLE_PAYLOAD, 0, 0),\n\tCXL_CMD(GET_ALERT_CONFIG, 0, 0x10, 0),\n\tCXL_CMD(SET_ALERT_CONFIG, 0xc, 0, 0),\n\tCXL_CMD(GET_SHUTDOWN_STATE, 0, 0x1, 0),\n\tCXL_CMD(SET_SHUTDOWN_STATE, 0x1, 0, 0),\n\tCXL_CMD(GET_SCAN_MEDIA_CAPS, 0x10, 0x4, 0),\n};\n\n \nstatic u16 cxl_disabled_raw_commands[] = {\n\tCXL_MBOX_OP_ACTIVATE_FW,\n\tCXL_MBOX_OP_SET_PARTITION_INFO,\n\tCXL_MBOX_OP_SET_LSA,\n\tCXL_MBOX_OP_SET_SHUTDOWN_STATE,\n\tCXL_MBOX_OP_SCAN_MEDIA,\n\tCXL_MBOX_OP_GET_SCAN_MEDIA,\n\tCXL_MBOX_OP_GET_POISON,\n\tCXL_MBOX_OP_INJECT_POISON,\n\tCXL_MBOX_OP_CLEAR_POISON,\n};\n\n \nstatic u8 security_command_sets[] = {\n\t0x44,  \n\t0x45,  \n\t0x46,  \n};\n\nstatic bool cxl_is_security_command(u16 opcode)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(security_command_sets); i++)\n\t\tif (security_command_sets[i] == (opcode >> 8))\n\t\t\treturn true;\n\treturn false;\n}\n\nstatic void cxl_set_security_cmd_enabled(struct cxl_security_state *security,\n\t\t\t\t\t u16 opcode)\n{\n\tswitch (opcode) {\n\tcase CXL_MBOX_OP_SANITIZE:\n\t\tset_bit(CXL_SEC_ENABLED_SANITIZE, security->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_SECURE_ERASE:\n\t\tset_bit(CXL_SEC_ENABLED_SECURE_ERASE,\n\t\t\tsecurity->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_GET_SECURITY_STATE:\n\t\tset_bit(CXL_SEC_ENABLED_GET_SECURITY_STATE,\n\t\t\tsecurity->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_SET_PASSPHRASE:\n\t\tset_bit(CXL_SEC_ENABLED_SET_PASSPHRASE,\n\t\t\tsecurity->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_DISABLE_PASSPHRASE:\n\t\tset_bit(CXL_SEC_ENABLED_DISABLE_PASSPHRASE,\n\t\t\tsecurity->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_UNLOCK:\n\t\tset_bit(CXL_SEC_ENABLED_UNLOCK, security->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_FREEZE_SECURITY:\n\t\tset_bit(CXL_SEC_ENABLED_FREEZE_SECURITY,\n\t\t\tsecurity->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_PASSPHRASE_SECURE_ERASE:\n\t\tset_bit(CXL_SEC_ENABLED_PASSPHRASE_SECURE_ERASE,\n\t\t\tsecurity->enabled_cmds);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic bool cxl_is_poison_command(u16 opcode)\n{\n#define CXL_MBOX_OP_POISON_CMDS 0x43\n\n\tif ((opcode >> 8) == CXL_MBOX_OP_POISON_CMDS)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void cxl_set_poison_cmd_enabled(struct cxl_poison_state *poison,\n\t\t\t\t       u16 opcode)\n{\n\tswitch (opcode) {\n\tcase CXL_MBOX_OP_GET_POISON:\n\t\tset_bit(CXL_POISON_ENABLED_LIST, poison->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_INJECT_POISON:\n\t\tset_bit(CXL_POISON_ENABLED_INJECT, poison->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_CLEAR_POISON:\n\t\tset_bit(CXL_POISON_ENABLED_CLEAR, poison->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_GET_SCAN_MEDIA_CAPS:\n\t\tset_bit(CXL_POISON_ENABLED_SCAN_CAPS, poison->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_SCAN_MEDIA:\n\t\tset_bit(CXL_POISON_ENABLED_SCAN_MEDIA, poison->enabled_cmds);\n\t\tbreak;\n\tcase CXL_MBOX_OP_GET_SCAN_MEDIA:\n\t\tset_bit(CXL_POISON_ENABLED_SCAN_RESULTS, poison->enabled_cmds);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic struct cxl_mem_command *cxl_mem_find_command(u16 opcode)\n{\n\tstruct cxl_mem_command *c;\n\n\tcxl_for_each_cmd(c)\n\t\tif (c->opcode == opcode)\n\t\t\treturn c;\n\n\treturn NULL;\n}\n\nstatic const char *cxl_mem_opcode_to_name(u16 opcode)\n{\n\tstruct cxl_mem_command *c;\n\n\tc = cxl_mem_find_command(opcode);\n\tif (!c)\n\t\treturn NULL;\n\n\treturn cxl_command_names[c->info.id].name;\n}\n\n \nint cxl_internal_send_cmd(struct cxl_memdev_state *mds,\n\t\t\t  struct cxl_mbox_cmd *mbox_cmd)\n{\n\tsize_t out_size, min_out;\n\tint rc;\n\n\tif (mbox_cmd->size_in > mds->payload_size ||\n\t    mbox_cmd->size_out > mds->payload_size)\n\t\treturn -E2BIG;\n\n\tout_size = mbox_cmd->size_out;\n\tmin_out = mbox_cmd->min_out;\n\trc = mds->mbox_send(mds, mbox_cmd);\n\t \n\tif (WARN_ONCE(rc == -EIO, \"Bad return code: -EIO\"))\n\t\treturn -ENXIO;\n\tif (rc)\n\t\treturn rc;\n\n\tif (mbox_cmd->return_code != CXL_MBOX_CMD_RC_SUCCESS &&\n\t    mbox_cmd->return_code != CXL_MBOX_CMD_RC_BACKGROUND)\n\t\treturn cxl_mbox_cmd_rc2errno(mbox_cmd);\n\n\tif (!out_size)\n\t\treturn 0;\n\n\t \n\tif (min_out == 0)\n\t\tmin_out = out_size;\n\n\tif (mbox_cmd->size_out < min_out)\n\t\treturn -EIO;\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_internal_send_cmd, CXL);\n\nstatic bool cxl_mem_raw_command_allowed(u16 opcode)\n{\n\tint i;\n\n\tif (!IS_ENABLED(CONFIG_CXL_MEM_RAW_COMMANDS))\n\t\treturn false;\n\n\tif (security_locked_down(LOCKDOWN_PCI_ACCESS))\n\t\treturn false;\n\n\tif (cxl_raw_allow_all)\n\t\treturn true;\n\n\tif (cxl_is_security_command(opcode))\n\t\treturn false;\n\n\tfor (i = 0; i < ARRAY_SIZE(cxl_disabled_raw_commands); i++)\n\t\tif (cxl_disabled_raw_commands[i] == opcode)\n\t\t\treturn false;\n\n\treturn true;\n}\n\n \nstatic bool cxl_payload_from_user_allowed(u16 opcode, void *payload_in)\n{\n\tswitch (opcode) {\n\tcase CXL_MBOX_OP_SET_PARTITION_INFO: {\n\t\tstruct cxl_mbox_set_partition_info *pi = payload_in;\n\n\t\tif (pi->flags & CXL_SET_PARTITION_IMMEDIATE_FLAG)\n\t\t\treturn false;\n\t\tbreak;\n\t}\n\tdefault:\n\t\tbreak;\n\t}\n\treturn true;\n}\n\nstatic int cxl_mbox_cmd_ctor(struct cxl_mbox_cmd *mbox,\n\t\t\t     struct cxl_memdev_state *mds, u16 opcode,\n\t\t\t     size_t in_size, size_t out_size, u64 in_payload)\n{\n\t*mbox = (struct cxl_mbox_cmd) {\n\t\t.opcode = opcode,\n\t\t.size_in = in_size,\n\t};\n\n\tif (in_size) {\n\t\tmbox->payload_in = vmemdup_user(u64_to_user_ptr(in_payload),\n\t\t\t\t\t\tin_size);\n\t\tif (IS_ERR(mbox->payload_in))\n\t\t\treturn PTR_ERR(mbox->payload_in);\n\n\t\tif (!cxl_payload_from_user_allowed(opcode, mbox->payload_in)) {\n\t\t\tdev_dbg(mds->cxlds.dev, \"%s: input payload not allowed\\n\",\n\t\t\t\tcxl_mem_opcode_to_name(opcode));\n\t\t\tkvfree(mbox->payload_in);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\t \n\tif (out_size == CXL_VARIABLE_PAYLOAD)\n\t\tmbox->size_out = mds->payload_size;\n\telse\n\t\tmbox->size_out = out_size;\n\n\tif (mbox->size_out) {\n\t\tmbox->payload_out = kvzalloc(mbox->size_out, GFP_KERNEL);\n\t\tif (!mbox->payload_out) {\n\t\t\tkvfree(mbox->payload_in);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void cxl_mbox_cmd_dtor(struct cxl_mbox_cmd *mbox)\n{\n\tkvfree(mbox->payload_in);\n\tkvfree(mbox->payload_out);\n}\n\nstatic int cxl_to_mem_cmd_raw(struct cxl_mem_command *mem_cmd,\n\t\t\t      const struct cxl_send_command *send_cmd,\n\t\t\t      struct cxl_memdev_state *mds)\n{\n\tif (send_cmd->raw.rsvd)\n\t\treturn -EINVAL;\n\n\t \n\tif (send_cmd->out.size > mds->payload_size)\n\t\treturn -EINVAL;\n\n\tif (!cxl_mem_raw_command_allowed(send_cmd->raw.opcode))\n\t\treturn -EPERM;\n\n\tdev_WARN_ONCE(mds->cxlds.dev, true, \"raw command path used\\n\");\n\n\t*mem_cmd = (struct cxl_mem_command) {\n\t\t.info = {\n\t\t\t.id = CXL_MEM_COMMAND_ID_RAW,\n\t\t\t.size_in = send_cmd->in.size,\n\t\t\t.size_out = send_cmd->out.size,\n\t\t},\n\t\t.opcode = send_cmd->raw.opcode\n\t};\n\n\treturn 0;\n}\n\nstatic int cxl_to_mem_cmd(struct cxl_mem_command *mem_cmd,\n\t\t\t  const struct cxl_send_command *send_cmd,\n\t\t\t  struct cxl_memdev_state *mds)\n{\n\tstruct cxl_mem_command *c = &cxl_mem_commands[send_cmd->id];\n\tconst struct cxl_command_info *info = &c->info;\n\n\tif (send_cmd->flags & ~CXL_MEM_COMMAND_FLAG_MASK)\n\t\treturn -EINVAL;\n\n\tif (send_cmd->rsvd)\n\t\treturn -EINVAL;\n\n\tif (send_cmd->in.rsvd || send_cmd->out.rsvd)\n\t\treturn -EINVAL;\n\n\t \n\tif (!test_bit(info->id, mds->enabled_cmds))\n\t\treturn -ENOTTY;\n\n\t \n\tif (test_bit(info->id, mds->exclusive_cmds))\n\t\treturn -EBUSY;\n\n\t \n\tif ((info->size_in != CXL_VARIABLE_PAYLOAD) &&\n\t    (info->size_in != send_cmd->in.size))\n\t\treturn -ENOMEM;\n\n\t \n\tif ((info->size_out != CXL_VARIABLE_PAYLOAD) &&\n\t    (send_cmd->out.size < info->size_out))\n\t\treturn -ENOMEM;\n\n\t*mem_cmd = (struct cxl_mem_command) {\n\t\t.info = {\n\t\t\t.id = info->id,\n\t\t\t.flags = info->flags,\n\t\t\t.size_in = send_cmd->in.size,\n\t\t\t.size_out = send_cmd->out.size,\n\t\t},\n\t\t.opcode = c->opcode\n\t};\n\n\treturn 0;\n}\n\n \nstatic int cxl_validate_cmd_from_user(struct cxl_mbox_cmd *mbox_cmd,\n\t\t\t\t      struct cxl_memdev_state *mds,\n\t\t\t\t      const struct cxl_send_command *send_cmd)\n{\n\tstruct cxl_mem_command mem_cmd;\n\tint rc;\n\n\tif (send_cmd->id == 0 || send_cmd->id >= CXL_MEM_COMMAND_ID_MAX)\n\t\treturn -ENOTTY;\n\n\t \n\tif (send_cmd->in.size > mds->payload_size)\n\t\treturn -EINVAL;\n\n\t \n\tif (send_cmd->id == CXL_MEM_COMMAND_ID_RAW)\n\t\trc = cxl_to_mem_cmd_raw(&mem_cmd, send_cmd, mds);\n\telse\n\t\trc = cxl_to_mem_cmd(&mem_cmd, send_cmd, mds);\n\n\tif (rc)\n\t\treturn rc;\n\n\t \n\treturn cxl_mbox_cmd_ctor(mbox_cmd, mds, mem_cmd.opcode,\n\t\t\t\t mem_cmd.info.size_in, mem_cmd.info.size_out,\n\t\t\t\t send_cmd->in.payload);\n}\n\nint cxl_query_cmd(struct cxl_memdev *cxlmd,\n\t\t  struct cxl_mem_query_commands __user *q)\n{\n\tstruct cxl_memdev_state *mds = to_cxl_memdev_state(cxlmd->cxlds);\n\tstruct device *dev = &cxlmd->dev;\n\tstruct cxl_mem_command *cmd;\n\tu32 n_commands;\n\tint j = 0;\n\n\tdev_dbg(dev, \"Query IOCTL\\n\");\n\n\tif (get_user(n_commands, &q->n_commands))\n\t\treturn -EFAULT;\n\n\t \n\tif (n_commands == 0)\n\t\treturn put_user(ARRAY_SIZE(cxl_mem_commands), &q->n_commands);\n\n\t \n\tcxl_for_each_cmd(cmd) {\n\t\tstruct cxl_command_info info = cmd->info;\n\n\t\tif (test_bit(info.id, mds->enabled_cmds))\n\t\t\tinfo.flags |= CXL_MEM_COMMAND_FLAG_ENABLED;\n\t\tif (test_bit(info.id, mds->exclusive_cmds))\n\t\t\tinfo.flags |= CXL_MEM_COMMAND_FLAG_EXCLUSIVE;\n\n\t\tif (copy_to_user(&q->commands[j++], &info, sizeof(info)))\n\t\t\treturn -EFAULT;\n\n\t\tif (j == n_commands)\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int handle_mailbox_cmd_from_user(struct cxl_memdev_state *mds,\n\t\t\t\t\tstruct cxl_mbox_cmd *mbox_cmd,\n\t\t\t\t\tu64 out_payload, s32 *size_out,\n\t\t\t\t\tu32 *retval)\n{\n\tstruct device *dev = mds->cxlds.dev;\n\tint rc;\n\n\tdev_dbg(dev,\n\t\t\"Submitting %s command for user\\n\"\n\t\t\"\\topcode: %x\\n\"\n\t\t\"\\tsize: %zx\\n\",\n\t\tcxl_mem_opcode_to_name(mbox_cmd->opcode),\n\t\tmbox_cmd->opcode, mbox_cmd->size_in);\n\n\trc = mds->mbox_send(mds, mbox_cmd);\n\tif (rc)\n\t\tgoto out;\n\n\t \n\tif (mbox_cmd->size_out) {\n\t\tdev_WARN_ONCE(dev, mbox_cmd->size_out > *size_out,\n\t\t\t      \"Invalid return size\\n\");\n\t\tif (copy_to_user(u64_to_user_ptr(out_payload),\n\t\t\t\t mbox_cmd->payload_out, mbox_cmd->size_out)) {\n\t\t\trc = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t*size_out = mbox_cmd->size_out;\n\t*retval = mbox_cmd->return_code;\n\nout:\n\tcxl_mbox_cmd_dtor(mbox_cmd);\n\treturn rc;\n}\n\nint cxl_send_cmd(struct cxl_memdev *cxlmd, struct cxl_send_command __user *s)\n{\n\tstruct cxl_memdev_state *mds = to_cxl_memdev_state(cxlmd->cxlds);\n\tstruct device *dev = &cxlmd->dev;\n\tstruct cxl_send_command send;\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tint rc;\n\n\tdev_dbg(dev, \"Send IOCTL\\n\");\n\n\tif (copy_from_user(&send, s, sizeof(send)))\n\t\treturn -EFAULT;\n\n\trc = cxl_validate_cmd_from_user(&mbox_cmd, mds, &send);\n\tif (rc)\n\t\treturn rc;\n\n\trc = handle_mailbox_cmd_from_user(mds, &mbox_cmd, send.out.payload,\n\t\t\t\t\t  &send.out.size, &send.retval);\n\tif (rc)\n\t\treturn rc;\n\n\tif (copy_to_user(s, &send, sizeof(send)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int cxl_xfer_log(struct cxl_memdev_state *mds, uuid_t *uuid,\n\t\t\tu32 *size, u8 *out)\n{\n\tu32 remaining = *size;\n\tu32 offset = 0;\n\n\twhile (remaining) {\n\t\tu32 xfer_size = min_t(u32, remaining, mds->payload_size);\n\t\tstruct cxl_mbox_cmd mbox_cmd;\n\t\tstruct cxl_mbox_get_log log;\n\t\tint rc;\n\n\t\tlog = (struct cxl_mbox_get_log) {\n\t\t\t.uuid = *uuid,\n\t\t\t.offset = cpu_to_le32(offset),\n\t\t\t.length = cpu_to_le32(xfer_size),\n\t\t};\n\n\t\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t\t.opcode = CXL_MBOX_OP_GET_LOG,\n\t\t\t.size_in = sizeof(log),\n\t\t\t.payload_in = &log,\n\t\t\t.size_out = xfer_size,\n\t\t\t.payload_out = out,\n\t\t};\n\n\t\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\n\t\t \n\t\tif (rc == -EIO && mbox_cmd.size_out < xfer_size) {\n\t\t\toffset += mbox_cmd.size_out;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rc < 0)\n\t\t\treturn rc;\n\n\t\tout += xfer_size;\n\t\tremaining -= xfer_size;\n\t\toffset += xfer_size;\n\t}\n\n\t*size = offset;\n\n\treturn 0;\n}\n\n \nstatic void cxl_walk_cel(struct cxl_memdev_state *mds, size_t size, u8 *cel)\n{\n\tstruct cxl_cel_entry *cel_entry;\n\tconst int cel_entries = size / sizeof(*cel_entry);\n\tstruct device *dev = mds->cxlds.dev;\n\tint i;\n\n\tcel_entry = (struct cxl_cel_entry *) cel;\n\n\tfor (i = 0; i < cel_entries; i++) {\n\t\tu16 opcode = le16_to_cpu(cel_entry[i].opcode);\n\t\tstruct cxl_mem_command *cmd = cxl_mem_find_command(opcode);\n\t\tint enabled = 0;\n\n\t\tif (cmd) {\n\t\t\tset_bit(cmd->info.id, mds->enabled_cmds);\n\t\t\tenabled++;\n\t\t}\n\n\t\tif (cxl_is_poison_command(opcode)) {\n\t\t\tcxl_set_poison_cmd_enabled(&mds->poison, opcode);\n\t\t\tenabled++;\n\t\t}\n\n\t\tif (cxl_is_security_command(opcode)) {\n\t\t\tcxl_set_security_cmd_enabled(&mds->security, opcode);\n\t\t\tenabled++;\n\t\t}\n\n\t\tdev_dbg(dev, \"Opcode 0x%04x %s\\n\", opcode,\n\t\t\tenabled ? \"enabled\" : \"unsupported by driver\");\n\t}\n}\n\nstatic struct cxl_mbox_get_supported_logs *cxl_get_gsl(struct cxl_memdev_state *mds)\n{\n\tstruct cxl_mbox_get_supported_logs *ret;\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tint rc;\n\n\tret = kvmalloc(mds->payload_size, GFP_KERNEL);\n\tif (!ret)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t.opcode = CXL_MBOX_OP_GET_SUPPORTED_LOGS,\n\t\t.size_out = mds->payload_size,\n\t\t.payload_out = ret,\n\t\t \n\t\t.min_out = 2,\n\t};\n\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\tif (rc < 0) {\n\t\tkvfree(ret);\n\t\treturn ERR_PTR(rc);\n\t}\n\n\n\treturn ret;\n}\n\nenum {\n\tCEL_UUID,\n\tVENDOR_DEBUG_UUID,\n};\n\n \nstatic const uuid_t log_uuid[] = {\n\t[CEL_UUID] = DEFINE_CXL_CEL_UUID,\n\t[VENDOR_DEBUG_UUID] = DEFINE_CXL_VENDOR_DEBUG_UUID,\n};\n\n \nint cxl_enumerate_cmds(struct cxl_memdev_state *mds)\n{\n\tstruct cxl_mbox_get_supported_logs *gsl;\n\tstruct device *dev = mds->cxlds.dev;\n\tstruct cxl_mem_command *cmd;\n\tint i, rc;\n\n\tgsl = cxl_get_gsl(mds);\n\tif (IS_ERR(gsl))\n\t\treturn PTR_ERR(gsl);\n\n\trc = -ENOENT;\n\tfor (i = 0; i < le16_to_cpu(gsl->entries); i++) {\n\t\tu32 size = le32_to_cpu(gsl->entry[i].size);\n\t\tuuid_t uuid = gsl->entry[i].uuid;\n\t\tu8 *log;\n\n\t\tdev_dbg(dev, \"Found LOG type %pU of size %d\", &uuid, size);\n\n\t\tif (!uuid_equal(&uuid, &log_uuid[CEL_UUID]))\n\t\t\tcontinue;\n\n\t\tlog = kvmalloc(size, GFP_KERNEL);\n\t\tif (!log) {\n\t\t\trc = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\n\t\trc = cxl_xfer_log(mds, &uuid, &size, log);\n\t\tif (rc) {\n\t\t\tkvfree(log);\n\t\t\tgoto out;\n\t\t}\n\n\t\tcxl_walk_cel(mds, size, log);\n\t\tkvfree(log);\n\n\t\t \n\t\tcxl_for_each_cmd(cmd)\n\t\t\tif (cmd->flags & CXL_CMD_FLAG_FORCE_ENABLE)\n\t\t\t\tset_bit(cmd->info.id, mds->enabled_cmds);\n\n\t\t \n\t\trc = 0;\n\t}\nout:\n\tkvfree(gsl);\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_enumerate_cmds, CXL);\n\n \nstatic const uuid_t gen_media_event_uuid =\n\tUUID_INIT(0xfbcd0a77, 0xc260, 0x417f,\n\t\t  0x85, 0xa9, 0x08, 0x8b, 0x16, 0x21, 0xeb, 0xa6);\n\n \nstatic const uuid_t dram_event_uuid =\n\tUUID_INIT(0x601dcbb3, 0x9c06, 0x4eab,\n\t\t  0xb8, 0xaf, 0x4e, 0x9b, 0xfb, 0x5c, 0x96, 0x24);\n\n \nstatic const uuid_t mem_mod_event_uuid =\n\tUUID_INIT(0xfe927475, 0xdd59, 0x4339,\n\t\t  0xa5, 0x86, 0x79, 0xba, 0xb1, 0x13, 0xb7, 0x74);\n\nstatic void cxl_event_trace_record(const struct cxl_memdev *cxlmd,\n\t\t\t\t   enum cxl_event_log_type type,\n\t\t\t\t   struct cxl_event_record_raw *record)\n{\n\tuuid_t *id = &record->hdr.id;\n\n\tif (uuid_equal(id, &gen_media_event_uuid)) {\n\t\tstruct cxl_event_gen_media *rec =\n\t\t\t\t(struct cxl_event_gen_media *)record;\n\n\t\ttrace_cxl_general_media(cxlmd, type, rec);\n\t} else if (uuid_equal(id, &dram_event_uuid)) {\n\t\tstruct cxl_event_dram *rec = (struct cxl_event_dram *)record;\n\n\t\ttrace_cxl_dram(cxlmd, type, rec);\n\t} else if (uuid_equal(id, &mem_mod_event_uuid)) {\n\t\tstruct cxl_event_mem_module *rec =\n\t\t\t\t(struct cxl_event_mem_module *)record;\n\n\t\ttrace_cxl_memory_module(cxlmd, type, rec);\n\t} else {\n\t\t \n\t\ttrace_cxl_generic_event(cxlmd, type, record);\n\t}\n}\n\nstatic int cxl_clear_event_record(struct cxl_memdev_state *mds,\n\t\t\t\t  enum cxl_event_log_type log,\n\t\t\t\t  struct cxl_get_event_payload *get_pl)\n{\n\tstruct cxl_mbox_clear_event_payload *payload;\n\tu16 total = le16_to_cpu(get_pl->record_count);\n\tu8 max_handles = CXL_CLEAR_EVENT_MAX_HANDLES;\n\tsize_t pl_size = struct_size(payload, handles, max_handles);\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tu16 cnt;\n\tint rc = 0;\n\tint i;\n\n\t \n\tif (pl_size > mds->payload_size) {\n\t\tmax_handles = (mds->payload_size - sizeof(*payload)) /\n\t\t\t      sizeof(__le16);\n\t\tpl_size = struct_size(payload, handles, max_handles);\n\t}\n\n\tpayload = kvzalloc(pl_size, GFP_KERNEL);\n\tif (!payload)\n\t\treturn -ENOMEM;\n\n\t*payload = (struct cxl_mbox_clear_event_payload) {\n\t\t.event_log = log,\n\t};\n\n\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t.opcode = CXL_MBOX_OP_CLEAR_EVENT_RECORD,\n\t\t.payload_in = payload,\n\t\t.size_in = pl_size,\n\t};\n\n\t \n\ti = 0;\n\tfor (cnt = 0; cnt < total; cnt++) {\n\t\tpayload->handles[i++] = get_pl->records[cnt].hdr.handle;\n\t\tdev_dbg(mds->cxlds.dev, \"Event log '%d': Clearing %u\\n\", log,\n\t\t\tle16_to_cpu(payload->handles[i]));\n\n\t\tif (i == max_handles) {\n\t\t\tpayload->nr_recs = i;\n\t\t\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\t\t\tif (rc)\n\t\t\t\tgoto free_pl;\n\t\t\ti = 0;\n\t\t}\n\t}\n\n\t \n\tif (i) {\n\t\tpayload->nr_recs = i;\n\t\tmbox_cmd.size_in = struct_size(payload, handles, i);\n\t\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\t\tif (rc)\n\t\t\tgoto free_pl;\n\t}\n\nfree_pl:\n\tkvfree(payload);\n\treturn rc;\n}\n\nstatic void cxl_mem_get_records_log(struct cxl_memdev_state *mds,\n\t\t\t\t    enum cxl_event_log_type type)\n{\n\tstruct cxl_memdev *cxlmd = mds->cxlds.cxlmd;\n\tstruct device *dev = mds->cxlds.dev;\n\tstruct cxl_get_event_payload *payload;\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tu8 log_type = type;\n\tu16 nr_rec;\n\n\tmutex_lock(&mds->event.log_lock);\n\tpayload = mds->event.buf;\n\n\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t.opcode = CXL_MBOX_OP_GET_EVENT_RECORD,\n\t\t.payload_in = &log_type,\n\t\t.size_in = sizeof(log_type),\n\t\t.payload_out = payload,\n\t\t.size_out = mds->payload_size,\n\t\t.min_out = struct_size(payload, records, 0),\n\t};\n\n\tdo {\n\t\tint rc, i;\n\n\t\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\t\tif (rc) {\n\t\t\tdev_err_ratelimited(dev,\n\t\t\t\t\"Event log '%d': Failed to query event records : %d\",\n\t\t\t\ttype, rc);\n\t\t\tbreak;\n\t\t}\n\n\t\tnr_rec = le16_to_cpu(payload->record_count);\n\t\tif (!nr_rec)\n\t\t\tbreak;\n\n\t\tfor (i = 0; i < nr_rec; i++)\n\t\t\tcxl_event_trace_record(cxlmd, type,\n\t\t\t\t\t       &payload->records[i]);\n\n\t\tif (payload->flags & CXL_GET_EVENT_FLAG_OVERFLOW)\n\t\t\ttrace_cxl_overflow(cxlmd, type, payload);\n\n\t\trc = cxl_clear_event_record(mds, type, payload);\n\t\tif (rc) {\n\t\t\tdev_err_ratelimited(dev,\n\t\t\t\t\"Event log '%d': Failed to clear events : %d\",\n\t\t\t\ttype, rc);\n\t\t\tbreak;\n\t\t}\n\t} while (nr_rec);\n\n\tmutex_unlock(&mds->event.log_lock);\n}\n\n \nvoid cxl_mem_get_event_records(struct cxl_memdev_state *mds, u32 status)\n{\n\tdev_dbg(mds->cxlds.dev, \"Reading event logs: %x\\n\", status);\n\n\tif (status & CXLDEV_EVENT_STATUS_FATAL)\n\t\tcxl_mem_get_records_log(mds, CXL_EVENT_TYPE_FATAL);\n\tif (status & CXLDEV_EVENT_STATUS_FAIL)\n\t\tcxl_mem_get_records_log(mds, CXL_EVENT_TYPE_FAIL);\n\tif (status & CXLDEV_EVENT_STATUS_WARN)\n\t\tcxl_mem_get_records_log(mds, CXL_EVENT_TYPE_WARN);\n\tif (status & CXLDEV_EVENT_STATUS_INFO)\n\t\tcxl_mem_get_records_log(mds, CXL_EVENT_TYPE_INFO);\n}\nEXPORT_SYMBOL_NS_GPL(cxl_mem_get_event_records, CXL);\n\n \nstatic int cxl_mem_get_partition_info(struct cxl_memdev_state *mds)\n{\n\tstruct cxl_mbox_get_partition_info pi;\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tint rc;\n\n\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t.opcode = CXL_MBOX_OP_GET_PARTITION_INFO,\n\t\t.size_out = sizeof(pi),\n\t\t.payload_out = &pi,\n\t};\n\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\tif (rc)\n\t\treturn rc;\n\n\tmds->active_volatile_bytes =\n\t\tle64_to_cpu(pi.active_volatile_cap) * CXL_CAPACITY_MULTIPLIER;\n\tmds->active_persistent_bytes =\n\t\tle64_to_cpu(pi.active_persistent_cap) * CXL_CAPACITY_MULTIPLIER;\n\tmds->next_volatile_bytes =\n\t\tle64_to_cpu(pi.next_volatile_cap) * CXL_CAPACITY_MULTIPLIER;\n\tmds->next_persistent_bytes =\n\t\tle64_to_cpu(pi.next_volatile_cap) * CXL_CAPACITY_MULTIPLIER;\n\n\treturn 0;\n}\n\n \nint cxl_dev_state_identify(struct cxl_memdev_state *mds)\n{\n\t \n\tstruct cxl_mbox_identify id;\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tu32 val;\n\tint rc;\n\n\tif (!mds->cxlds.media_ready)\n\t\treturn 0;\n\n\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t.opcode = CXL_MBOX_OP_IDENTIFY,\n\t\t.size_out = sizeof(id),\n\t\t.payload_out = &id,\n\t};\n\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\tif (rc < 0)\n\t\treturn rc;\n\n\tmds->total_bytes =\n\t\tle64_to_cpu(id.total_capacity) * CXL_CAPACITY_MULTIPLIER;\n\tmds->volatile_only_bytes =\n\t\tle64_to_cpu(id.volatile_capacity) * CXL_CAPACITY_MULTIPLIER;\n\tmds->persistent_only_bytes =\n\t\tle64_to_cpu(id.persistent_capacity) * CXL_CAPACITY_MULTIPLIER;\n\tmds->partition_align_bytes =\n\t\tle64_to_cpu(id.partition_align) * CXL_CAPACITY_MULTIPLIER;\n\n\tmds->lsa_size = le32_to_cpu(id.lsa_size);\n\tmemcpy(mds->firmware_version, id.fw_revision,\n\t       sizeof(id.fw_revision));\n\n\tif (test_bit(CXL_POISON_ENABLED_LIST, mds->poison.enabled_cmds)) {\n\t\tval = get_unaligned_le24(id.poison_list_max_mer);\n\t\tmds->poison.max_errors = min_t(u32, val, CXL_POISON_LIST_MAX);\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_dev_state_identify, CXL);\n\nstatic int __cxl_mem_sanitize(struct cxl_memdev_state *mds, u16 cmd)\n{\n\tint rc;\n\tu32 sec_out = 0;\n\tstruct cxl_get_security_output {\n\t\t__le32 flags;\n\t} out;\n\tstruct cxl_mbox_cmd sec_cmd = {\n\t\t.opcode = CXL_MBOX_OP_GET_SECURITY_STATE,\n\t\t.payload_out = &out,\n\t\t.size_out = sizeof(out),\n\t};\n\tstruct cxl_mbox_cmd mbox_cmd = { .opcode = cmd };\n\tstruct cxl_dev_state *cxlds = &mds->cxlds;\n\n\tif (cmd != CXL_MBOX_OP_SANITIZE && cmd != CXL_MBOX_OP_SECURE_ERASE)\n\t\treturn -EINVAL;\n\n\trc = cxl_internal_send_cmd(mds, &sec_cmd);\n\tif (rc < 0) {\n\t\tdev_err(cxlds->dev, \"Failed to get security state : %d\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\tsec_out = le32_to_cpu(out.flags);\n\tif (sec_out & CXL_PMEM_SEC_STATE_USER_PASS_SET)\n\t\treturn -EINVAL;\n\n\tif (cmd == CXL_MBOX_OP_SECURE_ERASE &&\n\t    sec_out & CXL_PMEM_SEC_STATE_LOCKED)\n\t\treturn -EINVAL;\n\n\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\tif (rc < 0) {\n\t\tdev_err(cxlds->dev, \"Failed to sanitize device : %d\", rc);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\n\n \nint cxl_mem_sanitize(struct cxl_memdev *cxlmd, u16 cmd)\n{\n\tstruct cxl_memdev_state *mds = to_cxl_memdev_state(cxlmd->cxlds);\n\tstruct cxl_port  *endpoint;\n\tint rc;\n\n\t \n\tdevice_lock(&cxlmd->dev);\n\tendpoint = cxlmd->endpoint;\n\tdown_read(&cxl_region_rwsem);\n\t \n\tif (endpoint && cxl_num_decoders_committed(endpoint) == 0)\n\t\trc = __cxl_mem_sanitize(mds, cmd);\n\telse\n\t\trc = -EBUSY;\n\tup_read(&cxl_region_rwsem);\n\tdevice_unlock(&cxlmd->dev);\n\n\treturn rc;\n}\n\nstatic int add_dpa_res(struct device *dev, struct resource *parent,\n\t\t       struct resource *res, resource_size_t start,\n\t\t       resource_size_t size, const char *type)\n{\n\tint rc;\n\n\tres->name = type;\n\tres->start = start;\n\tres->end = start + size - 1;\n\tres->flags = IORESOURCE_MEM;\n\tif (resource_size(res) == 0) {\n\t\tdev_dbg(dev, \"DPA(%s): no capacity\\n\", res->name);\n\t\treturn 0;\n\t}\n\trc = request_resource(parent, res);\n\tif (rc) {\n\t\tdev_err(dev, \"DPA(%s): failed to track %pr (%d)\\n\", res->name,\n\t\t\tres, rc);\n\t\treturn rc;\n\t}\n\n\tdev_dbg(dev, \"DPA(%s): %pr\\n\", res->name, res);\n\n\treturn 0;\n}\n\nint cxl_mem_create_range_info(struct cxl_memdev_state *mds)\n{\n\tstruct cxl_dev_state *cxlds = &mds->cxlds;\n\tstruct device *dev = cxlds->dev;\n\tint rc;\n\n\tif (!cxlds->media_ready) {\n\t\tcxlds->dpa_res = DEFINE_RES_MEM(0, 0);\n\t\tcxlds->ram_res = DEFINE_RES_MEM(0, 0);\n\t\tcxlds->pmem_res = DEFINE_RES_MEM(0, 0);\n\t\treturn 0;\n\t}\n\n\tcxlds->dpa_res =\n\t\t(struct resource)DEFINE_RES_MEM(0, mds->total_bytes);\n\n\tif (mds->partition_align_bytes == 0) {\n\t\trc = add_dpa_res(dev, &cxlds->dpa_res, &cxlds->ram_res, 0,\n\t\t\t\t mds->volatile_only_bytes, \"ram\");\n\t\tif (rc)\n\t\t\treturn rc;\n\t\treturn add_dpa_res(dev, &cxlds->dpa_res, &cxlds->pmem_res,\n\t\t\t\t   mds->volatile_only_bytes,\n\t\t\t\t   mds->persistent_only_bytes, \"pmem\");\n\t}\n\n\trc = cxl_mem_get_partition_info(mds);\n\tif (rc) {\n\t\tdev_err(dev, \"Failed to query partition information\\n\");\n\t\treturn rc;\n\t}\n\n\trc = add_dpa_res(dev, &cxlds->dpa_res, &cxlds->ram_res, 0,\n\t\t\t mds->active_volatile_bytes, \"ram\");\n\tif (rc)\n\t\treturn rc;\n\treturn add_dpa_res(dev, &cxlds->dpa_res, &cxlds->pmem_res,\n\t\t\t   mds->active_volatile_bytes,\n\t\t\t   mds->active_persistent_bytes, \"pmem\");\n}\nEXPORT_SYMBOL_NS_GPL(cxl_mem_create_range_info, CXL);\n\nint cxl_set_timestamp(struct cxl_memdev_state *mds)\n{\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tstruct cxl_mbox_set_timestamp_in pi;\n\tint rc;\n\n\tpi.timestamp = cpu_to_le64(ktime_get_real_ns());\n\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t.opcode = CXL_MBOX_OP_SET_TIMESTAMP,\n\t\t.size_in = sizeof(pi),\n\t\t.payload_in = &pi,\n\t};\n\n\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\t \n\tif (rc && (mbox_cmd.return_code != CXL_MBOX_CMD_RC_UNSUPPORTED))\n\t\treturn rc;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_set_timestamp, CXL);\n\nint cxl_mem_get_poison(struct cxl_memdev *cxlmd, u64 offset, u64 len,\n\t\t       struct cxl_region *cxlr)\n{\n\tstruct cxl_memdev_state *mds = to_cxl_memdev_state(cxlmd->cxlds);\n\tstruct cxl_mbox_poison_out *po;\n\tstruct cxl_mbox_poison_in pi;\n\tstruct cxl_mbox_cmd mbox_cmd;\n\tint nr_records = 0;\n\tint rc;\n\n\trc = mutex_lock_interruptible(&mds->poison.lock);\n\tif (rc)\n\t\treturn rc;\n\n\tpo = mds->poison.list_out;\n\tpi.offset = cpu_to_le64(offset);\n\tpi.length = cpu_to_le64(len / CXL_POISON_LEN_MULT);\n\n\tmbox_cmd = (struct cxl_mbox_cmd) {\n\t\t.opcode = CXL_MBOX_OP_GET_POISON,\n\t\t.size_in = sizeof(pi),\n\t\t.payload_in = &pi,\n\t\t.size_out = mds->payload_size,\n\t\t.payload_out = po,\n\t\t.min_out = struct_size(po, record, 0),\n\t};\n\n\tdo {\n\t\trc = cxl_internal_send_cmd(mds, &mbox_cmd);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tfor (int i = 0; i < le16_to_cpu(po->count); i++)\n\t\t\ttrace_cxl_poison(cxlmd, cxlr, &po->record[i],\n\t\t\t\t\t po->flags, po->overflow_ts,\n\t\t\t\t\t CXL_POISON_TRACE_LIST);\n\n\t\t \n\t\tnr_records = nr_records + le16_to_cpu(po->count);\n\t\tif (nr_records >= mds->poison.max_errors) {\n\t\t\tdev_dbg(&cxlmd->dev, \"Max Error Records reached: %d\\n\",\n\t\t\t\tnr_records);\n\t\t\tbreak;\n\t\t}\n\t} while (po->flags & CXL_POISON_FLAG_MORE);\n\n\tmutex_unlock(&mds->poison.lock);\n\treturn rc;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_mem_get_poison, CXL);\n\nstatic void free_poison_buf(void *buf)\n{\n\tkvfree(buf);\n}\n\n \nstatic int cxl_poison_alloc_buf(struct cxl_memdev_state *mds)\n{\n\tmds->poison.list_out = kvmalloc(mds->payload_size, GFP_KERNEL);\n\tif (!mds->poison.list_out)\n\t\treturn -ENOMEM;\n\n\treturn devm_add_action_or_reset(mds->cxlds.dev, free_poison_buf,\n\t\t\t\t\tmds->poison.list_out);\n}\n\nint cxl_poison_state_init(struct cxl_memdev_state *mds)\n{\n\tint rc;\n\n\tif (!test_bit(CXL_POISON_ENABLED_LIST, mds->poison.enabled_cmds))\n\t\treturn 0;\n\n\trc = cxl_poison_alloc_buf(mds);\n\tif (rc) {\n\t\tclear_bit(CXL_POISON_ENABLED_LIST, mds->poison.enabled_cmds);\n\t\treturn rc;\n\t}\n\n\tmutex_init(&mds->poison.lock);\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_poison_state_init, CXL);\n\nstruct cxl_memdev_state *cxl_memdev_state_create(struct device *dev)\n{\n\tstruct cxl_memdev_state *mds;\n\n\tmds = devm_kzalloc(dev, sizeof(*mds), GFP_KERNEL);\n\tif (!mds) {\n\t\tdev_err(dev, \"No memory available\\n\");\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tmutex_init(&mds->mbox_mutex);\n\tmutex_init(&mds->event.log_lock);\n\tmds->cxlds.dev = dev;\n\tmds->cxlds.type = CXL_DEVTYPE_CLASSMEM;\n\n\treturn mds;\n}\nEXPORT_SYMBOL_NS_GPL(cxl_memdev_state_create, CXL);\n\nvoid __init cxl_mbox_init(void)\n{\n\tstruct dentry *mbox_debugfs;\n\n\tmbox_debugfs = cxl_debugfs_create_dir(\"mbox\");\n\tdebugfs_create_bool(\"raw_allow_all\", 0600, mbox_debugfs,\n\t\t\t    &cxl_raw_allow_all);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}