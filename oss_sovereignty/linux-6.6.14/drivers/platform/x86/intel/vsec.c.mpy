{
  "module_name": "vsec.c",
  "hash_id": "2191b0e182672af103058c1a1caf65909d88b0e2e26598f4d1151a6db5347751",
  "original_prompt": "Ingested from linux-6.6.14/drivers/platform/x86/intel/vsec.c",
  "human_readable_source": "\n \n\n#include <linux/auxiliary_bus.h>\n#include <linux/bits.h>\n#include <linux/delay.h>\n#include <linux/kernel.h>\n#include <linux/idr.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/types.h>\n\n#include \"vsec.h\"\n\n \n#define INTEL_DVSEC_ENTRIES\t\t0xA\n#define INTEL_DVSEC_SIZE\t\t0xB\n#define INTEL_DVSEC_TABLE\t\t0xC\n#define INTEL_DVSEC_TABLE_BAR(x)\t((x) & GENMASK(2, 0))\n#define INTEL_DVSEC_TABLE_OFFSET(x)\t((x) & GENMASK(31, 3))\n#define TABLE_OFFSET_SHIFT\t\t3\n#define PMT_XA_START\t\t\t0\n#define PMT_XA_MAX\t\t\tINT_MAX\n#define PMT_XA_LIMIT\t\t\tXA_LIMIT(PMT_XA_START, PMT_XA_MAX)\n\nstatic DEFINE_IDA(intel_vsec_ida);\nstatic DEFINE_IDA(intel_vsec_sdsi_ida);\nstatic DEFINE_XARRAY_ALLOC(auxdev_array);\n\n \nstruct intel_vsec_header {\n\tu8\trev;\n\tu16\tlength;\n\tu16\tid;\n\tu8\tnum_entries;\n\tu8\tentry_size;\n\tu8\ttbir;\n\tu32\toffset;\n};\n\nenum intel_vsec_id {\n\tVSEC_ID_TELEMETRY\t= 2,\n\tVSEC_ID_WATCHER\t\t= 3,\n\tVSEC_ID_CRASHLOG\t= 4,\n\tVSEC_ID_SDSI\t\t= 65,\n\tVSEC_ID_TPMI\t\t= 66,\n};\n\nstatic const char *intel_vsec_name(enum intel_vsec_id id)\n{\n\tswitch (id) {\n\tcase VSEC_ID_TELEMETRY:\n\t\treturn \"telemetry\";\n\n\tcase VSEC_ID_WATCHER:\n\t\treturn \"watcher\";\n\n\tcase VSEC_ID_CRASHLOG:\n\t\treturn \"crashlog\";\n\n\tcase VSEC_ID_SDSI:\n\t\treturn \"sdsi\";\n\n\tcase VSEC_ID_TPMI:\n\t\treturn \"tpmi\";\n\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic bool intel_vsec_supported(u16 id, unsigned long caps)\n{\n\tswitch (id) {\n\tcase VSEC_ID_TELEMETRY:\n\t\treturn !!(caps & VSEC_CAP_TELEMETRY);\n\tcase VSEC_ID_WATCHER:\n\t\treturn !!(caps & VSEC_CAP_WATCHER);\n\tcase VSEC_ID_CRASHLOG:\n\t\treturn !!(caps & VSEC_CAP_CRASHLOG);\n\tcase VSEC_ID_SDSI:\n\t\treturn !!(caps & VSEC_CAP_SDSI);\n\tcase VSEC_ID_TPMI:\n\t\treturn !!(caps & VSEC_CAP_TPMI);\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic void intel_vsec_remove_aux(void *data)\n{\n\tauxiliary_device_delete(data);\n\tauxiliary_device_uninit(data);\n}\n\nstatic DEFINE_MUTEX(vsec_ida_lock);\n\nstatic void intel_vsec_dev_release(struct device *dev)\n{\n\tstruct intel_vsec_device *intel_vsec_dev = dev_to_ivdev(dev);\n\n\txa_erase(&auxdev_array, intel_vsec_dev->id);\n\n\tmutex_lock(&vsec_ida_lock);\n\tida_free(intel_vsec_dev->ida, intel_vsec_dev->auxdev.id);\n\tmutex_unlock(&vsec_ida_lock);\n\n\tkfree(intel_vsec_dev->resource);\n\tkfree(intel_vsec_dev);\n}\n\nint intel_vsec_add_aux(struct pci_dev *pdev, struct device *parent,\n\t\t       struct intel_vsec_device *intel_vsec_dev,\n\t\t       const char *name)\n{\n\tstruct auxiliary_device *auxdev = &intel_vsec_dev->auxdev;\n\tint ret, id;\n\n\tret = xa_alloc(&auxdev_array, &intel_vsec_dev->id, intel_vsec_dev,\n\t\t       PMT_XA_LIMIT, GFP_KERNEL);\n\tif (ret < 0) {\n\t\tkfree(intel_vsec_dev->resource);\n\t\tkfree(intel_vsec_dev);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&vsec_ida_lock);\n\tid = ida_alloc(intel_vsec_dev->ida, GFP_KERNEL);\n\tmutex_unlock(&vsec_ida_lock);\n\tif (id < 0) {\n\t\txa_erase(&auxdev_array, intel_vsec_dev->id);\n\t\tkfree(intel_vsec_dev->resource);\n\t\tkfree(intel_vsec_dev);\n\t\treturn id;\n\t}\n\n\tif (!parent)\n\t\tparent = &pdev->dev;\n\n\tauxdev->id = id;\n\tauxdev->name = name;\n\tauxdev->dev.parent = parent;\n\tauxdev->dev.release = intel_vsec_dev_release;\n\n\tret = auxiliary_device_init(auxdev);\n\tif (ret < 0) {\n\t\tintel_vsec_dev_release(&auxdev->dev);\n\t\treturn ret;\n\t}\n\n\tret = auxiliary_device_add(auxdev);\n\tif (ret < 0) {\n\t\tauxiliary_device_uninit(auxdev);\n\t\treturn ret;\n\t}\n\n\tret = devm_add_action_or_reset(parent, intel_vsec_remove_aux,\n\t\t\t\t       auxdev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_NS_GPL(intel_vsec_add_aux, INTEL_VSEC);\n\nstatic int intel_vsec_add_dev(struct pci_dev *pdev, struct intel_vsec_header *header,\n\t\t\t      struct intel_vsec_platform_info *info)\n{\n\tstruct intel_vsec_device *intel_vsec_dev;\n\tstruct resource *res, *tmp;\n\tunsigned long quirks = info->quirks;\n\tint i;\n\n\tif (!intel_vsec_supported(header->id, info->caps))\n\t\treturn -EINVAL;\n\n\tif (!header->num_entries) {\n\t\tdev_dbg(&pdev->dev, \"Invalid 0 entry count for header id %d\\n\", header->id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!header->entry_size) {\n\t\tdev_dbg(&pdev->dev, \"Invalid 0 entry size for header id %d\\n\", header->id);\n\t\treturn -EINVAL;\n\t}\n\n\tintel_vsec_dev = kzalloc(sizeof(*intel_vsec_dev), GFP_KERNEL);\n\tif (!intel_vsec_dev)\n\t\treturn -ENOMEM;\n\n\tres = kcalloc(header->num_entries, sizeof(*res), GFP_KERNEL);\n\tif (!res) {\n\t\tkfree(intel_vsec_dev);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (quirks & VSEC_QUIRK_TABLE_SHIFT)\n\t\theader->offset >>= TABLE_OFFSET_SHIFT;\n\n\t \n\tfor (i = 0, tmp = res; i < header->num_entries; i++, tmp++) {\n\t\ttmp->start = pdev->resource[header->tbir].start +\n\t\t\t     header->offset + i * (header->entry_size * sizeof(u32));\n\t\ttmp->end = tmp->start + (header->entry_size * sizeof(u32)) - 1;\n\t\ttmp->flags = IORESOURCE_MEM;\n\t}\n\n\tintel_vsec_dev->pcidev = pdev;\n\tintel_vsec_dev->resource = res;\n\tintel_vsec_dev->num_resources = header->num_entries;\n\tintel_vsec_dev->info = info;\n\n\tif (header->id == VSEC_ID_SDSI)\n\t\tintel_vsec_dev->ida = &intel_vsec_sdsi_ida;\n\telse\n\t\tintel_vsec_dev->ida = &intel_vsec_ida;\n\n\treturn intel_vsec_add_aux(pdev, NULL, intel_vsec_dev,\n\t\t\t\t  intel_vsec_name(header->id));\n}\n\nstatic bool intel_vsec_walk_header(struct pci_dev *pdev,\n\t\t\t\t   struct intel_vsec_platform_info *info)\n{\n\tstruct intel_vsec_header **header = info->headers;\n\tbool have_devices = false;\n\tint ret;\n\n\tfor ( ; *header; header++) {\n\t\tret = intel_vsec_add_dev(pdev, *header, info);\n\t\tif (ret)\n\t\t\tdev_info(&pdev->dev, \"Could not add device for VSEC id %d\\n\",\n\t\t\t\t (*header)->id);\n\t\telse\n\t\t\thave_devices = true;\n\t}\n\n\treturn have_devices;\n}\n\nstatic bool intel_vsec_walk_dvsec(struct pci_dev *pdev,\n\t\t\t\t  struct intel_vsec_platform_info *info)\n{\n\tbool have_devices = false;\n\tint pos = 0;\n\n\tdo {\n\t\tstruct intel_vsec_header header;\n\t\tu32 table, hdr;\n\t\tu16 vid;\n\t\tint ret;\n\n\t\tpos = pci_find_next_ext_capability(pdev, pos, PCI_EXT_CAP_ID_DVSEC);\n\t\tif (!pos)\n\t\t\tbreak;\n\n\t\tpci_read_config_dword(pdev, pos + PCI_DVSEC_HEADER1, &hdr);\n\t\tvid = PCI_DVSEC_HEADER1_VID(hdr);\n\t\tif (vid != PCI_VENDOR_ID_INTEL)\n\t\t\tcontinue;\n\n\t\t \n\t\theader.rev = PCI_DVSEC_HEADER1_REV(hdr);\n\t\tif (header.rev != 1) {\n\t\t\tdev_info(&pdev->dev, \"Unsupported DVSEC revision %d\\n\", header.rev);\n\t\t\tcontinue;\n\t\t}\n\n\t\theader.length = PCI_DVSEC_HEADER1_LEN(hdr);\n\n\t\tpci_read_config_byte(pdev, pos + INTEL_DVSEC_ENTRIES, &header.num_entries);\n\t\tpci_read_config_byte(pdev, pos + INTEL_DVSEC_SIZE, &header.entry_size);\n\t\tpci_read_config_dword(pdev, pos + INTEL_DVSEC_TABLE, &table);\n\n\t\theader.tbir = INTEL_DVSEC_TABLE_BAR(table);\n\t\theader.offset = INTEL_DVSEC_TABLE_OFFSET(table);\n\n\t\tpci_read_config_dword(pdev, pos + PCI_DVSEC_HEADER2, &hdr);\n\t\theader.id = PCI_DVSEC_HEADER2_ID(hdr);\n\n\t\tret = intel_vsec_add_dev(pdev, &header, info);\n\t\tif (ret)\n\t\t\tcontinue;\n\n\t\thave_devices = true;\n\t} while (true);\n\n\treturn have_devices;\n}\n\nstatic bool intel_vsec_walk_vsec(struct pci_dev *pdev,\n\t\t\t\t struct intel_vsec_platform_info *info)\n{\n\tbool have_devices = false;\n\tint pos = 0;\n\n\tdo {\n\t\tstruct intel_vsec_header header;\n\t\tu32 table, hdr;\n\t\tint ret;\n\n\t\tpos = pci_find_next_ext_capability(pdev, pos, PCI_EXT_CAP_ID_VNDR);\n\t\tif (!pos)\n\t\t\tbreak;\n\n\t\tpci_read_config_dword(pdev, pos + PCI_VNDR_HEADER, &hdr);\n\n\t\t \n\t\theader.rev = PCI_VNDR_HEADER_REV(hdr);\n\t\tif (header.rev != 1) {\n\t\t\tdev_info(&pdev->dev, \"Unsupported VSEC revision %d\\n\", header.rev);\n\t\t\tcontinue;\n\t\t}\n\n\t\theader.id = PCI_VNDR_HEADER_ID(hdr);\n\t\theader.length = PCI_VNDR_HEADER_LEN(hdr);\n\n\t\t \n\t\tpci_read_config_byte(pdev, pos + INTEL_DVSEC_ENTRIES, &header.num_entries);\n\t\tpci_read_config_byte(pdev, pos + INTEL_DVSEC_SIZE, &header.entry_size);\n\t\tpci_read_config_dword(pdev, pos + INTEL_DVSEC_TABLE, &table);\n\n\t\theader.tbir = INTEL_DVSEC_TABLE_BAR(table);\n\t\theader.offset = INTEL_DVSEC_TABLE_OFFSET(table);\n\n\t\tret = intel_vsec_add_dev(pdev, &header, info);\n\t\tif (ret)\n\t\t\tcontinue;\n\n\t\thave_devices = true;\n\t} while (true);\n\n\treturn have_devices;\n}\n\nstatic int intel_vsec_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tstruct intel_vsec_platform_info *info;\n\tbool have_devices = false;\n\tint ret;\n\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ret;\n\n\tpci_save_state(pdev);\n\tinfo = (struct intel_vsec_platform_info *)id->driver_data;\n\tif (!info)\n\t\treturn -EINVAL;\n\n\tif (intel_vsec_walk_dvsec(pdev, info))\n\t\thave_devices = true;\n\n\tif (intel_vsec_walk_vsec(pdev, info))\n\t\thave_devices = true;\n\n\tif (info && (info->quirks & VSEC_QUIRK_NO_DVSEC) &&\n\t    intel_vsec_walk_header(pdev, info))\n\t\thave_devices = true;\n\n\tif (!have_devices)\n\t\treturn -ENODEV;\n\n\treturn 0;\n}\n\n \nstatic struct intel_vsec_header dg1_header = {\n\t.length = 0x10,\n\t.id = 2,\n\t.num_entries = 1,\n\t.entry_size = 3,\n\t.tbir = 0,\n\t.offset = 0x466000,\n};\n\nstatic struct intel_vsec_header *dg1_headers[] = {\n\t&dg1_header,\n\tNULL\n};\n\nstatic const struct intel_vsec_platform_info dg1_info = {\n\t.caps = VSEC_CAP_TELEMETRY,\n\t.headers = dg1_headers,\n\t.quirks = VSEC_QUIRK_NO_DVSEC | VSEC_QUIRK_EARLY_HW,\n};\n\n \nstatic const struct intel_vsec_platform_info mtl_info = {\n\t.caps = VSEC_CAP_TELEMETRY,\n};\n\n \nstatic const struct intel_vsec_platform_info oobmsm_info = {\n\t.caps = VSEC_CAP_TELEMETRY | VSEC_CAP_SDSI | VSEC_CAP_TPMI,\n};\n\n \nstatic const struct intel_vsec_platform_info tgl_info = {\n\t.caps = VSEC_CAP_TELEMETRY,\n\t.quirks = VSEC_QUIRK_TABLE_SHIFT | VSEC_QUIRK_EARLY_HW,\n};\n\n#define PCI_DEVICE_ID_INTEL_VSEC_ADL\t\t0x467d\n#define PCI_DEVICE_ID_INTEL_VSEC_DG1\t\t0x490e\n#define PCI_DEVICE_ID_INTEL_VSEC_MTL_M\t\t0x7d0d\n#define PCI_DEVICE_ID_INTEL_VSEC_MTL_S\t\t0xad0d\n#define PCI_DEVICE_ID_INTEL_VSEC_OOBMSM\t\t0x09a7\n#define PCI_DEVICE_ID_INTEL_VSEC_RPL\t\t0xa77d\n#define PCI_DEVICE_ID_INTEL_VSEC_TGL\t\t0x9a0d\nstatic const struct pci_device_id intel_vsec_pci_ids[] = {\n\t{ PCI_DEVICE_DATA(INTEL, VSEC_ADL, &tgl_info) },\n\t{ PCI_DEVICE_DATA(INTEL, VSEC_DG1, &dg1_info) },\n\t{ PCI_DEVICE_DATA(INTEL, VSEC_MTL_M, &mtl_info) },\n\t{ PCI_DEVICE_DATA(INTEL, VSEC_MTL_S, &mtl_info) },\n\t{ PCI_DEVICE_DATA(INTEL, VSEC_OOBMSM, &oobmsm_info) },\n\t{ PCI_DEVICE_DATA(INTEL, VSEC_RPL, &tgl_info) },\n\t{ PCI_DEVICE_DATA(INTEL, VSEC_TGL, &tgl_info) },\n\t{ }\n};\nMODULE_DEVICE_TABLE(pci, intel_vsec_pci_ids);\n\nstatic pci_ers_result_t intel_vsec_pci_error_detected(struct pci_dev *pdev,\n\t\t\t\t\t\t      pci_channel_state_t state)\n{\n\tpci_ers_result_t status = PCI_ERS_RESULT_NEED_RESET;\n\n\tdev_info(&pdev->dev, \"PCI error detected, state %d\", state);\n\n\tif (state == pci_channel_io_perm_failure)\n\t\tstatus = PCI_ERS_RESULT_DISCONNECT;\n\telse\n\t\tpci_disable_device(pdev);\n\n\treturn status;\n}\n\nstatic pci_ers_result_t intel_vsec_pci_slot_reset(struct pci_dev *pdev)\n{\n\tstruct intel_vsec_device *intel_vsec_dev;\n\tpci_ers_result_t status = PCI_ERS_RESULT_DISCONNECT;\n\tconst struct pci_device_id *pci_dev_id;\n\tunsigned long index;\n\n\tdev_info(&pdev->dev, \"Resetting PCI slot\\n\");\n\n\tmsleep(2000);\n\tif (pci_enable_device(pdev)) {\n\t\tdev_info(&pdev->dev,\n\t\t\t \"Failed to re-enable PCI device after reset.\\n\");\n\t\tgoto out;\n\t}\n\n\tstatus = PCI_ERS_RESULT_RECOVERED;\n\n\txa_for_each(&auxdev_array, index, intel_vsec_dev) {\n\t\t \n\t\tif (pdev != intel_vsec_dev->pcidev)\n\t\t\tcontinue;\n\t\tdevm_release_action(&pdev->dev, intel_vsec_remove_aux,\n\t\t\t\t    &intel_vsec_dev->auxdev);\n\t}\n\tpci_disable_device(pdev);\n\tpci_restore_state(pdev);\n\tpci_dev_id = pci_match_id(intel_vsec_pci_ids, pdev);\n\tintel_vsec_pci_probe(pdev, pci_dev_id);\n\nout:\n\treturn status;\n}\n\nstatic void intel_vsec_pci_resume(struct pci_dev *pdev)\n{\n\tdev_info(&pdev->dev, \"Done resuming PCI device\\n\");\n}\n\nstatic const struct pci_error_handlers intel_vsec_pci_err_handlers = {\n\t.error_detected = intel_vsec_pci_error_detected,\n\t.slot_reset = intel_vsec_pci_slot_reset,\n\t.resume = intel_vsec_pci_resume,\n};\n\nstatic struct pci_driver intel_vsec_pci_driver = {\n\t.name = \"intel_vsec\",\n\t.id_table = intel_vsec_pci_ids,\n\t.probe = intel_vsec_pci_probe,\n\t.err_handler = &intel_vsec_pci_err_handlers,\n};\nmodule_pci_driver(intel_vsec_pci_driver);\n\nMODULE_AUTHOR(\"David E. Box <david.e.box@linux.intel.com>\");\nMODULE_DESCRIPTION(\"Intel Extended Capabilities auxiliary bus driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}