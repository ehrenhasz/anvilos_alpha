{
  "module_name": "fc.c",
  "hash_id": "41ac4ed6107b8c2b589869c2052ec522f5551e594662cafb08767dcb18c55b10",
  "original_prompt": "Ingested from linux-6.6.14/drivers/nvme/host/fc.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/module.h>\n#include <linux/parser.h>\n#include <uapi/scsi/fc/fc_fs.h>\n#include <uapi/scsi/fc/fc_els.h>\n#include <linux/delay.h>\n#include <linux/overflow.h>\n#include <linux/blk-cgroup.h>\n#include \"nvme.h\"\n#include \"fabrics.h\"\n#include <linux/nvme-fc-driver.h>\n#include <linux/nvme-fc.h>\n#include \"fc.h\"\n#include <scsi/scsi_transport_fc.h>\n#include <linux/blk-mq-pci.h>\n\n \n\n\nenum nvme_fc_queue_flags {\n\tNVME_FC_Q_CONNECTED = 0,\n\tNVME_FC_Q_LIVE,\n};\n\n#define NVME_FC_DEFAULT_DEV_LOSS_TMO\t60\t \n#define NVME_FC_DEFAULT_RECONNECT_TMO\t2\t \n\nstruct nvme_fc_queue {\n\tstruct nvme_fc_ctrl\t*ctrl;\n\tstruct device\t\t*dev;\n\tstruct blk_mq_hw_ctx\t*hctx;\n\tvoid\t\t\t*lldd_handle;\n\tsize_t\t\t\tcmnd_capsule_len;\n\tu32\t\t\tqnum;\n\tu32\t\t\trqcnt;\n\tu32\t\t\tseqno;\n\n\tu64\t\t\tconnection_id;\n\tatomic_t\t\tcsn;\n\n\tunsigned long\t\tflags;\n} __aligned(sizeof(u64));\t \n\nenum nvme_fcop_flags {\n\tFCOP_FLAGS_TERMIO\t= (1 << 0),\n\tFCOP_FLAGS_AEN\t\t= (1 << 1),\n};\n\nstruct nvmefc_ls_req_op {\n\tstruct nvmefc_ls_req\tls_req;\n\n\tstruct nvme_fc_rport\t*rport;\n\tstruct nvme_fc_queue\t*queue;\n\tstruct request\t\t*rq;\n\tu32\t\t\tflags;\n\n\tint\t\t\tls_error;\n\tstruct completion\tls_done;\n\tstruct list_head\tlsreq_list;\t \n\tbool\t\t\treq_queued;\n};\n\nstruct nvmefc_ls_rcv_op {\n\tstruct nvme_fc_rport\t\t*rport;\n\tstruct nvmefc_ls_rsp\t\t*lsrsp;\n\tunion nvmefc_ls_requests\t*rqstbuf;\n\tunion nvmefc_ls_responses\t*rspbuf;\n\tu16\t\t\t\trqstdatalen;\n\tbool\t\t\t\thandled;\n\tdma_addr_t\t\t\trspdma;\n\tstruct list_head\t\tlsrcv_list;\t \n} __aligned(sizeof(u64));\t \n\nenum nvme_fcpop_state {\n\tFCPOP_STATE_UNINIT\t= 0,\n\tFCPOP_STATE_IDLE\t= 1,\n\tFCPOP_STATE_ACTIVE\t= 2,\n\tFCPOP_STATE_ABORTED\t= 3,\n\tFCPOP_STATE_COMPLETE\t= 4,\n};\n\nstruct nvme_fc_fcp_op {\n\tstruct nvme_request\tnreq;\t\t \n\tstruct nvmefc_fcp_req\tfcp_req;\n\n\tstruct nvme_fc_ctrl\t*ctrl;\n\tstruct nvme_fc_queue\t*queue;\n\tstruct request\t\t*rq;\n\n\tatomic_t\t\tstate;\n\tu32\t\t\tflags;\n\tu32\t\t\trqno;\n\tu32\t\t\tnents;\n\n\tstruct nvme_fc_cmd_iu\tcmd_iu;\n\tstruct nvme_fc_ersp_iu\trsp_iu;\n};\n\nstruct nvme_fcp_op_w_sgl {\n\tstruct nvme_fc_fcp_op\top;\n\tstruct scatterlist\tsgl[NVME_INLINE_SG_CNT];\n\tuint8_t\t\t\tpriv[];\n};\n\nstruct nvme_fc_lport {\n\tstruct nvme_fc_local_port\tlocalport;\n\n\tstruct ida\t\t\tendp_cnt;\n\tstruct list_head\t\tport_list;\t \n\tstruct list_head\t\tendp_list;\n\tstruct device\t\t\t*dev;\t \n\tstruct nvme_fc_port_template\t*ops;\n\tstruct kref\t\t\tref;\n\tatomic_t                        act_rport_cnt;\n} __aligned(sizeof(u64));\t \n\nstruct nvme_fc_rport {\n\tstruct nvme_fc_remote_port\tremoteport;\n\n\tstruct list_head\t\tendp_list;  \n\tstruct list_head\t\tctrl_list;\n\tstruct list_head\t\tls_req_list;\n\tstruct list_head\t\tls_rcv_list;\n\tstruct list_head\t\tdisc_list;\n\tstruct device\t\t\t*dev;\t \n\tstruct nvme_fc_lport\t\t*lport;\n\tspinlock_t\t\t\tlock;\n\tstruct kref\t\t\tref;\n\tatomic_t                        act_ctrl_cnt;\n\tunsigned long\t\t\tdev_loss_end;\n\tstruct work_struct\t\tlsrcv_work;\n} __aligned(sizeof(u64));\t \n\n \n#define ASSOC_ACTIVE\t\t0\n#define ASSOC_FAILED\t\t1\n#define FCCTRL_TERMIO\t\t2\n\nstruct nvme_fc_ctrl {\n\tspinlock_t\t\tlock;\n\tstruct nvme_fc_queue\t*queues;\n\tstruct device\t\t*dev;\n\tstruct nvme_fc_lport\t*lport;\n\tstruct nvme_fc_rport\t*rport;\n\tu32\t\t\tcnum;\n\n\tbool\t\t\tioq_live;\n\tu64\t\t\tassociation_id;\n\tstruct nvmefc_ls_rcv_op\t*rcv_disconn;\n\n\tstruct list_head\tctrl_list;\t \n\n\tstruct blk_mq_tag_set\tadmin_tag_set;\n\tstruct blk_mq_tag_set\ttag_set;\n\n\tstruct work_struct\tioerr_work;\n\tstruct delayed_work\tconnect_work;\n\n\tstruct kref\t\tref;\n\tunsigned long\t\tflags;\n\tu32\t\t\tiocnt;\n\twait_queue_head_t\tioabort_wait;\n\n\tstruct nvme_fc_fcp_op\taen_ops[NVME_NR_AEN_COMMANDS];\n\n\tstruct nvme_ctrl\tctrl;\n};\n\nstatic inline struct nvme_fc_ctrl *\nto_fc_ctrl(struct nvme_ctrl *ctrl)\n{\n\treturn container_of(ctrl, struct nvme_fc_ctrl, ctrl);\n}\n\nstatic inline struct nvme_fc_lport *\nlocalport_to_lport(struct nvme_fc_local_port *portptr)\n{\n\treturn container_of(portptr, struct nvme_fc_lport, localport);\n}\n\nstatic inline struct nvme_fc_rport *\nremoteport_to_rport(struct nvme_fc_remote_port *portptr)\n{\n\treturn container_of(portptr, struct nvme_fc_rport, remoteport);\n}\n\nstatic inline struct nvmefc_ls_req_op *\nls_req_to_lsop(struct nvmefc_ls_req *lsreq)\n{\n\treturn container_of(lsreq, struct nvmefc_ls_req_op, ls_req);\n}\n\nstatic inline struct nvme_fc_fcp_op *\nfcp_req_to_fcp_op(struct nvmefc_fcp_req *fcpreq)\n{\n\treturn container_of(fcpreq, struct nvme_fc_fcp_op, fcp_req);\n}\n\n\n\n \n\n\nstatic DEFINE_SPINLOCK(nvme_fc_lock);\n\nstatic LIST_HEAD(nvme_fc_lport_list);\nstatic DEFINE_IDA(nvme_fc_local_port_cnt);\nstatic DEFINE_IDA(nvme_fc_ctrl_cnt);\n\nstatic struct workqueue_struct *nvme_fc_wq;\n\nstatic bool nvme_fc_waiting_to_unload;\nstatic DECLARE_COMPLETION(nvme_fc_unload_proceed);\n\n \nstatic struct device *fc_udev_device;\n\nstatic void nvme_fc_complete_rq(struct request *rq);\n\n \n\nstatic void __nvme_fc_delete_hw_queue(struct nvme_fc_ctrl *,\n\t\t\tstruct nvme_fc_queue *, unsigned int);\n\nstatic void nvme_fc_handle_ls_rqst_work(struct work_struct *work);\n\n\nstatic void\nnvme_fc_free_lport(struct kref *ref)\n{\n\tstruct nvme_fc_lport *lport =\n\t\tcontainer_of(ref, struct nvme_fc_lport, ref);\n\tunsigned long flags;\n\n\tWARN_ON(lport->localport.port_state != FC_OBJSTATE_DELETED);\n\tWARN_ON(!list_empty(&lport->endp_list));\n\n\t \n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\tlist_del(&lport->port_list);\n\tif (nvme_fc_waiting_to_unload && list_empty(&nvme_fc_lport_list))\n\t\tcomplete(&nvme_fc_unload_proceed);\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\tida_free(&nvme_fc_local_port_cnt, lport->localport.port_num);\n\tida_destroy(&lport->endp_cnt);\n\n\tput_device(lport->dev);\n\n\tkfree(lport);\n}\n\nstatic void\nnvme_fc_lport_put(struct nvme_fc_lport *lport)\n{\n\tkref_put(&lport->ref, nvme_fc_free_lport);\n}\n\nstatic int\nnvme_fc_lport_get(struct nvme_fc_lport *lport)\n{\n\treturn kref_get_unless_zero(&lport->ref);\n}\n\n\nstatic struct nvme_fc_lport *\nnvme_fc_attach_to_unreg_lport(struct nvme_fc_port_info *pinfo,\n\t\t\tstruct nvme_fc_port_template *ops,\n\t\t\tstruct device *dev)\n{\n\tstruct nvme_fc_lport *lport;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\n\tlist_for_each_entry(lport, &nvme_fc_lport_list, port_list) {\n\t\tif (lport->localport.node_name != pinfo->node_name ||\n\t\t    lport->localport.port_name != pinfo->port_name)\n\t\t\tcontinue;\n\n\t\tif (lport->dev != dev) {\n\t\t\tlport = ERR_PTR(-EXDEV);\n\t\t\tgoto out_done;\n\t\t}\n\n\t\tif (lport->localport.port_state != FC_OBJSTATE_DELETED) {\n\t\t\tlport = ERR_PTR(-EEXIST);\n\t\t\tgoto out_done;\n\t\t}\n\n\t\tif (!nvme_fc_lport_get(lport)) {\n\t\t\t \n\t\t\tlport = NULL;\n\t\t\tgoto out_done;\n\t\t}\n\n\t\t \n\n\t\tlport->ops = ops;\n\t\tlport->localport.port_role = pinfo->port_role;\n\t\tlport->localport.port_id = pinfo->port_id;\n\t\tlport->localport.port_state = FC_OBJSTATE_ONLINE;\n\n\t\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\t\treturn lport;\n\t}\n\n\tlport = NULL;\n\nout_done:\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\treturn lport;\n}\n\n \nint\nnvme_fc_register_localport(struct nvme_fc_port_info *pinfo,\n\t\t\tstruct nvme_fc_port_template *template,\n\t\t\tstruct device *dev,\n\t\t\tstruct nvme_fc_local_port **portptr)\n{\n\tstruct nvme_fc_lport *newrec;\n\tunsigned long flags;\n\tint ret, idx;\n\n\tif (!template->localport_delete || !template->remoteport_delete ||\n\t    !template->ls_req || !template->fcp_io ||\n\t    !template->ls_abort || !template->fcp_abort ||\n\t    !template->max_hw_queues || !template->max_sgl_segments ||\n\t    !template->max_dif_sgl_segments || !template->dma_boundary) {\n\t\tret = -EINVAL;\n\t\tgoto out_reghost_failed;\n\t}\n\n\t \n\tnewrec = nvme_fc_attach_to_unreg_lport(pinfo, template, dev);\n\n\t \n\tif (IS_ERR(newrec)) {\n\t\tret = PTR_ERR(newrec);\n\t\tgoto out_reghost_failed;\n\n\t \n\t} else if (newrec) {\n\t\t*portptr = &newrec->localport;\n\t\treturn 0;\n\t}\n\n\t \n\n\tnewrec = kmalloc((sizeof(*newrec) + template->local_priv_sz),\n\t\t\t GFP_KERNEL);\n\tif (!newrec) {\n\t\tret = -ENOMEM;\n\t\tgoto out_reghost_failed;\n\t}\n\n\tidx = ida_alloc(&nvme_fc_local_port_cnt, GFP_KERNEL);\n\tif (idx < 0) {\n\t\tret = -ENOSPC;\n\t\tgoto out_fail_kfree;\n\t}\n\n\tif (!get_device(dev) && dev) {\n\t\tret = -ENODEV;\n\t\tgoto out_ida_put;\n\t}\n\n\tINIT_LIST_HEAD(&newrec->port_list);\n\tINIT_LIST_HEAD(&newrec->endp_list);\n\tkref_init(&newrec->ref);\n\tatomic_set(&newrec->act_rport_cnt, 0);\n\tnewrec->ops = template;\n\tnewrec->dev = dev;\n\tida_init(&newrec->endp_cnt);\n\tif (template->local_priv_sz)\n\t\tnewrec->localport.private = &newrec[1];\n\telse\n\t\tnewrec->localport.private = NULL;\n\tnewrec->localport.node_name = pinfo->node_name;\n\tnewrec->localport.port_name = pinfo->port_name;\n\tnewrec->localport.port_role = pinfo->port_role;\n\tnewrec->localport.port_id = pinfo->port_id;\n\tnewrec->localport.port_state = FC_OBJSTATE_ONLINE;\n\tnewrec->localport.port_num = idx;\n\n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\tlist_add_tail(&newrec->port_list, &nvme_fc_lport_list);\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\tif (dev)\n\t\tdma_set_seg_boundary(dev, template->dma_boundary);\n\n\t*portptr = &newrec->localport;\n\treturn 0;\n\nout_ida_put:\n\tida_free(&nvme_fc_local_port_cnt, idx);\nout_fail_kfree:\n\tkfree(newrec);\nout_reghost_failed:\n\t*portptr = NULL;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(nvme_fc_register_localport);\n\n \nint\nnvme_fc_unregister_localport(struct nvme_fc_local_port *portptr)\n{\n\tstruct nvme_fc_lport *lport = localport_to_lport(portptr);\n\tunsigned long flags;\n\n\tif (!portptr)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\n\tif (portptr->port_state != FC_OBJSTATE_ONLINE) {\n\t\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\t\treturn -EINVAL;\n\t}\n\tportptr->port_state = FC_OBJSTATE_DELETED;\n\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\tif (atomic_read(&lport->act_rport_cnt) == 0)\n\t\tlport->ops->localport_delete(&lport->localport);\n\n\tnvme_fc_lport_put(lport);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nvme_fc_unregister_localport);\n\n \n#define FCNVME_TRADDR_LENGTH\t\t64\n\nstatic void\nnvme_fc_signal_discovery_scan(struct nvme_fc_lport *lport,\n\t\tstruct nvme_fc_rport *rport)\n{\n\tchar hostaddr[FCNVME_TRADDR_LENGTH];\t \n\tchar tgtaddr[FCNVME_TRADDR_LENGTH];\t \n\tchar *envp[4] = { \"FC_EVENT=nvmediscovery\", hostaddr, tgtaddr, NULL };\n\n\tif (!(rport->remoteport.port_role & FC_PORT_ROLE_NVME_DISCOVERY))\n\t\treturn;\n\n\tsnprintf(hostaddr, sizeof(hostaddr),\n\t\t\"NVMEFC_HOST_TRADDR=nn-0x%016llx:pn-0x%016llx\",\n\t\tlport->localport.node_name, lport->localport.port_name);\n\tsnprintf(tgtaddr, sizeof(tgtaddr),\n\t\t\"NVMEFC_TRADDR=nn-0x%016llx:pn-0x%016llx\",\n\t\trport->remoteport.node_name, rport->remoteport.port_name);\n\tkobject_uevent_env(&fc_udev_device->kobj, KOBJ_CHANGE, envp);\n}\n\nstatic void\nnvme_fc_free_rport(struct kref *ref)\n{\n\tstruct nvme_fc_rport *rport =\n\t\tcontainer_of(ref, struct nvme_fc_rport, ref);\n\tstruct nvme_fc_lport *lport =\n\t\t\tlocalport_to_lport(rport->remoteport.localport);\n\tunsigned long flags;\n\n\tWARN_ON(rport->remoteport.port_state != FC_OBJSTATE_DELETED);\n\tWARN_ON(!list_empty(&rport->ctrl_list));\n\n\t \n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\tlist_del(&rport->endp_list);\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\tWARN_ON(!list_empty(&rport->disc_list));\n\tida_free(&lport->endp_cnt, rport->remoteport.port_num);\n\n\tkfree(rport);\n\n\tnvme_fc_lport_put(lport);\n}\n\nstatic void\nnvme_fc_rport_put(struct nvme_fc_rport *rport)\n{\n\tkref_put(&rport->ref, nvme_fc_free_rport);\n}\n\nstatic int\nnvme_fc_rport_get(struct nvme_fc_rport *rport)\n{\n\treturn kref_get_unless_zero(&rport->ref);\n}\n\nstatic void\nnvme_fc_resume_controller(struct nvme_fc_ctrl *ctrl)\n{\n\tswitch (nvme_ctrl_state(&ctrl->ctrl)) {\n\tcase NVME_CTRL_NEW:\n\tcase NVME_CTRL_CONNECTING:\n\t\t \n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: connectivity re-established. \"\n\t\t\t\"Attempting reconnect\\n\", ctrl->cnum);\n\n\t\tqueue_delayed_work(nvme_wq, &ctrl->connect_work, 0);\n\t\tbreak;\n\n\tcase NVME_CTRL_RESETTING:\n\t\t \n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n}\n\nstatic struct nvme_fc_rport *\nnvme_fc_attach_to_suspended_rport(struct nvme_fc_lport *lport,\n\t\t\t\tstruct nvme_fc_port_info *pinfo)\n{\n\tstruct nvme_fc_rport *rport;\n\tstruct nvme_fc_ctrl *ctrl;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\n\tlist_for_each_entry(rport, &lport->endp_list, endp_list) {\n\t\tif (rport->remoteport.node_name != pinfo->node_name ||\n\t\t    rport->remoteport.port_name != pinfo->port_name)\n\t\t\tcontinue;\n\n\t\tif (!nvme_fc_rport_get(rport)) {\n\t\t\trport = ERR_PTR(-ENOLCK);\n\t\t\tgoto out_done;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\t\tspin_lock_irqsave(&rport->lock, flags);\n\n\t\t \n\t\tif (rport->remoteport.port_state != FC_OBJSTATE_DELETED) {\n\t\t\t \n\t\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\t\tnvme_fc_rport_put(rport);\n\t\t\treturn ERR_PTR(-ESTALE);\n\t\t}\n\n\t\trport->remoteport.port_role = pinfo->port_role;\n\t\trport->remoteport.port_id = pinfo->port_id;\n\t\trport->remoteport.port_state = FC_OBJSTATE_ONLINE;\n\t\trport->dev_loss_end = 0;\n\n\t\t \n\t\tlist_for_each_entry(ctrl, &rport->ctrl_list, ctrl_list)\n\t\t\tnvme_fc_resume_controller(ctrl);\n\n\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\t\treturn rport;\n\t}\n\n\trport = NULL;\n\nout_done:\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\treturn rport;\n}\n\nstatic inline void\n__nvme_fc_set_dev_loss_tmo(struct nvme_fc_rport *rport,\n\t\t\tstruct nvme_fc_port_info *pinfo)\n{\n\tif (pinfo->dev_loss_tmo)\n\t\trport->remoteport.dev_loss_tmo = pinfo->dev_loss_tmo;\n\telse\n\t\trport->remoteport.dev_loss_tmo = NVME_FC_DEFAULT_DEV_LOSS_TMO;\n}\n\n \nint\nnvme_fc_register_remoteport(struct nvme_fc_local_port *localport,\n\t\t\t\tstruct nvme_fc_port_info *pinfo,\n\t\t\t\tstruct nvme_fc_remote_port **portptr)\n{\n\tstruct nvme_fc_lport *lport = localport_to_lport(localport);\n\tstruct nvme_fc_rport *newrec;\n\tunsigned long flags;\n\tint ret, idx;\n\n\tif (!nvme_fc_lport_get(lport)) {\n\t\tret = -ESHUTDOWN;\n\t\tgoto out_reghost_failed;\n\t}\n\n\t \n\tnewrec = nvme_fc_attach_to_suspended_rport(lport, pinfo);\n\n\t \n\tif (IS_ERR(newrec)) {\n\t\tret = PTR_ERR(newrec);\n\t\tgoto out_lport_put;\n\n\t \n\t} else if (newrec) {\n\t\tnvme_fc_lport_put(lport);\n\t\t__nvme_fc_set_dev_loss_tmo(newrec, pinfo);\n\t\tnvme_fc_signal_discovery_scan(lport, newrec);\n\t\t*portptr = &newrec->remoteport;\n\t\treturn 0;\n\t}\n\n\t \n\n\tnewrec = kmalloc((sizeof(*newrec) + lport->ops->remote_priv_sz),\n\t\t\t GFP_KERNEL);\n\tif (!newrec) {\n\t\tret = -ENOMEM;\n\t\tgoto out_lport_put;\n\t}\n\n\tidx = ida_alloc(&lport->endp_cnt, GFP_KERNEL);\n\tif (idx < 0) {\n\t\tret = -ENOSPC;\n\t\tgoto out_kfree_rport;\n\t}\n\n\tINIT_LIST_HEAD(&newrec->endp_list);\n\tINIT_LIST_HEAD(&newrec->ctrl_list);\n\tINIT_LIST_HEAD(&newrec->ls_req_list);\n\tINIT_LIST_HEAD(&newrec->disc_list);\n\tkref_init(&newrec->ref);\n\tatomic_set(&newrec->act_ctrl_cnt, 0);\n\tspin_lock_init(&newrec->lock);\n\tnewrec->remoteport.localport = &lport->localport;\n\tINIT_LIST_HEAD(&newrec->ls_rcv_list);\n\tnewrec->dev = lport->dev;\n\tnewrec->lport = lport;\n\tif (lport->ops->remote_priv_sz)\n\t\tnewrec->remoteport.private = &newrec[1];\n\telse\n\t\tnewrec->remoteport.private = NULL;\n\tnewrec->remoteport.port_role = pinfo->port_role;\n\tnewrec->remoteport.node_name = pinfo->node_name;\n\tnewrec->remoteport.port_name = pinfo->port_name;\n\tnewrec->remoteport.port_id = pinfo->port_id;\n\tnewrec->remoteport.port_state = FC_OBJSTATE_ONLINE;\n\tnewrec->remoteport.port_num = idx;\n\t__nvme_fc_set_dev_loss_tmo(newrec, pinfo);\n\tINIT_WORK(&newrec->lsrcv_work, nvme_fc_handle_ls_rqst_work);\n\n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\tlist_add_tail(&newrec->endp_list, &lport->endp_list);\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\tnvme_fc_signal_discovery_scan(lport, newrec);\n\n\t*portptr = &newrec->remoteport;\n\treturn 0;\n\nout_kfree_rport:\n\tkfree(newrec);\nout_lport_put:\n\tnvme_fc_lport_put(lport);\nout_reghost_failed:\n\t*portptr = NULL;\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(nvme_fc_register_remoteport);\n\nstatic int\nnvme_fc_abort_lsops(struct nvme_fc_rport *rport)\n{\n\tstruct nvmefc_ls_req_op *lsop;\n\tunsigned long flags;\n\nrestart:\n\tspin_lock_irqsave(&rport->lock, flags);\n\n\tlist_for_each_entry(lsop, &rport->ls_req_list, lsreq_list) {\n\t\tif (!(lsop->flags & FCOP_FLAGS_TERMIO)) {\n\t\t\tlsop->flags |= FCOP_FLAGS_TERMIO;\n\t\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\t\trport->lport->ops->ls_abort(&rport->lport->localport,\n\t\t\t\t\t\t&rport->remoteport,\n\t\t\t\t\t\t&lsop->ls_req);\n\t\t\tgoto restart;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\treturn 0;\n}\n\nstatic void\nnvme_fc_ctrl_connectivity_loss(struct nvme_fc_ctrl *ctrl)\n{\n\tdev_info(ctrl->ctrl.device,\n\t\t\"NVME-FC{%d}: controller connectivity lost. Awaiting \"\n\t\t\"Reconnect\", ctrl->cnum);\n\n\tswitch (nvme_ctrl_state(&ctrl->ctrl)) {\n\tcase NVME_CTRL_NEW:\n\tcase NVME_CTRL_LIVE:\n\t\t \n\t\tif (nvme_reset_ctrl(&ctrl->ctrl)) {\n\t\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\t\"NVME-FC{%d}: Couldn't schedule reset.\\n\",\n\t\t\t\tctrl->cnum);\n\t\t\tnvme_delete_ctrl(&ctrl->ctrl);\n\t\t}\n\t\tbreak;\n\n\tcase NVME_CTRL_CONNECTING:\n\t\t \n\t\tbreak;\n\n\tcase NVME_CTRL_RESETTING:\n\t\t \n\t\tbreak;\n\n\tcase NVME_CTRL_DELETING:\n\tcase NVME_CTRL_DELETING_NOIO:\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n}\n\n \nint\nnvme_fc_unregister_remoteport(struct nvme_fc_remote_port *portptr)\n{\n\tstruct nvme_fc_rport *rport = remoteport_to_rport(portptr);\n\tstruct nvme_fc_ctrl *ctrl;\n\tunsigned long flags;\n\n\tif (!portptr)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\n\tif (portptr->port_state != FC_OBJSTATE_ONLINE) {\n\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\tportptr->port_state = FC_OBJSTATE_DELETED;\n\n\trport->dev_loss_end = jiffies + (portptr->dev_loss_tmo * HZ);\n\n\tlist_for_each_entry(ctrl, &rport->ctrl_list, ctrl_list) {\n\t\t \n\t\tif (!portptr->dev_loss_tmo) {\n\t\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\t\"NVME-FC{%d}: controller connectivity lost.\\n\",\n\t\t\t\tctrl->cnum);\n\t\t\tnvme_delete_ctrl(&ctrl->ctrl);\n\t\t} else\n\t\t\tnvme_fc_ctrl_connectivity_loss(ctrl);\n\t}\n\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\tnvme_fc_abort_lsops(rport);\n\n\tif (atomic_read(&rport->act_ctrl_cnt) == 0)\n\t\trport->lport->ops->remoteport_delete(portptr);\n\n\t \n\tnvme_fc_rport_put(rport);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nvme_fc_unregister_remoteport);\n\n \nvoid\nnvme_fc_rescan_remoteport(struct nvme_fc_remote_port *remoteport)\n{\n\tstruct nvme_fc_rport *rport = remoteport_to_rport(remoteport);\n\n\tnvme_fc_signal_discovery_scan(rport->lport, rport);\n}\nEXPORT_SYMBOL_GPL(nvme_fc_rescan_remoteport);\n\nint\nnvme_fc_set_remoteport_devloss(struct nvme_fc_remote_port *portptr,\n\t\t\tu32 dev_loss_tmo)\n{\n\tstruct nvme_fc_rport *rport = remoteport_to_rport(portptr);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\n\tif (portptr->port_state != FC_OBJSTATE_ONLINE) {\n\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\trport->remoteport.dev_loss_tmo = dev_loss_tmo;\n\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(nvme_fc_set_remoteport_devloss);\n\n\n \n\n \n\nstatic inline dma_addr_t\nfc_dma_map_single(struct device *dev, void *ptr, size_t size,\n\t\tenum dma_data_direction dir)\n{\n\treturn dev ? dma_map_single(dev, ptr, size, dir) : (dma_addr_t)0L;\n}\n\nstatic inline int\nfc_dma_mapping_error(struct device *dev, dma_addr_t dma_addr)\n{\n\treturn dev ? dma_mapping_error(dev, dma_addr) : 0;\n}\n\nstatic inline void\nfc_dma_unmap_single(struct device *dev, dma_addr_t addr, size_t size,\n\tenum dma_data_direction dir)\n{\n\tif (dev)\n\t\tdma_unmap_single(dev, addr, size, dir);\n}\n\nstatic inline void\nfc_dma_sync_single_for_cpu(struct device *dev, dma_addr_t addr, size_t size,\n\t\tenum dma_data_direction dir)\n{\n\tif (dev)\n\t\tdma_sync_single_for_cpu(dev, addr, size, dir);\n}\n\nstatic inline void\nfc_dma_sync_single_for_device(struct device *dev, dma_addr_t addr, size_t size,\n\t\tenum dma_data_direction dir)\n{\n\tif (dev)\n\t\tdma_sync_single_for_device(dev, addr, size, dir);\n}\n\n \nstatic int\nfc_map_sg(struct scatterlist *sg, int nents)\n{\n\tstruct scatterlist *s;\n\tint i;\n\n\tWARN_ON(nents == 0 || sg[0].length == 0);\n\n\tfor_each_sg(sg, s, nents, i) {\n\t\ts->dma_address = 0L;\n#ifdef CONFIG_NEED_SG_DMA_LENGTH\n\t\ts->dma_length = s->length;\n#endif\n\t}\n\treturn nents;\n}\n\nstatic inline int\nfc_dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,\n\t\tenum dma_data_direction dir)\n{\n\treturn dev ? dma_map_sg(dev, sg, nents, dir) : fc_map_sg(sg, nents);\n}\n\nstatic inline void\nfc_dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nents,\n\t\tenum dma_data_direction dir)\n{\n\tif (dev)\n\t\tdma_unmap_sg(dev, sg, nents, dir);\n}\n\n \n\nstatic void nvme_fc_ctrl_put(struct nvme_fc_ctrl *);\nstatic int nvme_fc_ctrl_get(struct nvme_fc_ctrl *);\n\nstatic void nvme_fc_error_recovery(struct nvme_fc_ctrl *ctrl, char *errmsg);\n\nstatic void\n__nvme_fc_finish_ls_req(struct nvmefc_ls_req_op *lsop)\n{\n\tstruct nvme_fc_rport *rport = lsop->rport;\n\tstruct nvmefc_ls_req *lsreq = &lsop->ls_req;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\n\tif (!lsop->req_queued) {\n\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\treturn;\n\t}\n\n\tlist_del(&lsop->lsreq_list);\n\n\tlsop->req_queued = false;\n\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\tfc_dma_unmap_single(rport->dev, lsreq->rqstdma,\n\t\t\t\t  (lsreq->rqstlen + lsreq->rsplen),\n\t\t\t\t  DMA_BIDIRECTIONAL);\n\n\tnvme_fc_rport_put(rport);\n}\n\nstatic int\n__nvme_fc_send_ls_req(struct nvme_fc_rport *rport,\n\t\tstruct nvmefc_ls_req_op *lsop,\n\t\tvoid (*done)(struct nvmefc_ls_req *req, int status))\n{\n\tstruct nvmefc_ls_req *lsreq = &lsop->ls_req;\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (rport->remoteport.port_state != FC_OBJSTATE_ONLINE)\n\t\treturn -ECONNREFUSED;\n\n\tif (!nvme_fc_rport_get(rport))\n\t\treturn -ESHUTDOWN;\n\n\tlsreq->done = done;\n\tlsop->rport = rport;\n\tlsop->req_queued = false;\n\tINIT_LIST_HEAD(&lsop->lsreq_list);\n\tinit_completion(&lsop->ls_done);\n\n\tlsreq->rqstdma = fc_dma_map_single(rport->dev, lsreq->rqstaddr,\n\t\t\t\t  lsreq->rqstlen + lsreq->rsplen,\n\t\t\t\t  DMA_BIDIRECTIONAL);\n\tif (fc_dma_mapping_error(rport->dev, lsreq->rqstdma)) {\n\t\tret = -EFAULT;\n\t\tgoto out_putrport;\n\t}\n\tlsreq->rspdma = lsreq->rqstdma + lsreq->rqstlen;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\n\tlist_add_tail(&lsop->lsreq_list, &rport->ls_req_list);\n\n\tlsop->req_queued = true;\n\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\tret = rport->lport->ops->ls_req(&rport->lport->localport,\n\t\t\t\t\t&rport->remoteport, lsreq);\n\tif (ret)\n\t\tgoto out_unlink;\n\n\treturn 0;\n\nout_unlink:\n\tlsop->ls_error = ret;\n\tspin_lock_irqsave(&rport->lock, flags);\n\tlsop->req_queued = false;\n\tlist_del(&lsop->lsreq_list);\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\tfc_dma_unmap_single(rport->dev, lsreq->rqstdma,\n\t\t\t\t  (lsreq->rqstlen + lsreq->rsplen),\n\t\t\t\t  DMA_BIDIRECTIONAL);\nout_putrport:\n\tnvme_fc_rport_put(rport);\n\n\treturn ret;\n}\n\nstatic void\nnvme_fc_send_ls_req_done(struct nvmefc_ls_req *lsreq, int status)\n{\n\tstruct nvmefc_ls_req_op *lsop = ls_req_to_lsop(lsreq);\n\n\tlsop->ls_error = status;\n\tcomplete(&lsop->ls_done);\n}\n\nstatic int\nnvme_fc_send_ls_req(struct nvme_fc_rport *rport, struct nvmefc_ls_req_op *lsop)\n{\n\tstruct nvmefc_ls_req *lsreq = &lsop->ls_req;\n\tstruct fcnvme_ls_rjt *rjt = lsreq->rspaddr;\n\tint ret;\n\n\tret = __nvme_fc_send_ls_req(rport, lsop, nvme_fc_send_ls_req_done);\n\n\tif (!ret) {\n\t\t \n\t\twait_for_completion(&lsop->ls_done);\n\n\t\t__nvme_fc_finish_ls_req(lsop);\n\n\t\tret = lsop->ls_error;\n\t}\n\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (rjt->w0.ls_cmd == FCNVME_LS_RJT)\n\t\treturn -ENXIO;\n\n\treturn 0;\n}\n\nstatic int\nnvme_fc_send_ls_req_async(struct nvme_fc_rport *rport,\n\t\tstruct nvmefc_ls_req_op *lsop,\n\t\tvoid (*done)(struct nvmefc_ls_req *req, int status))\n{\n\t \n\n\treturn __nvme_fc_send_ls_req(rport, lsop, done);\n}\n\nstatic int\nnvme_fc_connect_admin_queue(struct nvme_fc_ctrl *ctrl,\n\tstruct nvme_fc_queue *queue, u16 qsize, u16 ersp_ratio)\n{\n\tstruct nvmefc_ls_req_op *lsop;\n\tstruct nvmefc_ls_req *lsreq;\n\tstruct fcnvme_ls_cr_assoc_rqst *assoc_rqst;\n\tstruct fcnvme_ls_cr_assoc_acc *assoc_acc;\n\tunsigned long flags;\n\tint ret, fcret = 0;\n\n\tlsop = kzalloc((sizeof(*lsop) +\n\t\t\t sizeof(*assoc_rqst) + sizeof(*assoc_acc) +\n\t\t\t ctrl->lport->ops->lsrqst_priv_sz), GFP_KERNEL);\n\tif (!lsop) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: send Create Association failed: ENOMEM\\n\",\n\t\t\tctrl->cnum);\n\t\tret = -ENOMEM;\n\t\tgoto out_no_memory;\n\t}\n\n\tassoc_rqst = (struct fcnvme_ls_cr_assoc_rqst *)&lsop[1];\n\tassoc_acc = (struct fcnvme_ls_cr_assoc_acc *)&assoc_rqst[1];\n\tlsreq = &lsop->ls_req;\n\tif (ctrl->lport->ops->lsrqst_priv_sz)\n\t\tlsreq->private = &assoc_acc[1];\n\telse\n\t\tlsreq->private = NULL;\n\n\tassoc_rqst->w0.ls_cmd = FCNVME_LS_CREATE_ASSOCIATION;\n\tassoc_rqst->desc_list_len =\n\t\t\tcpu_to_be32(sizeof(struct fcnvme_lsdesc_cr_assoc_cmd));\n\n\tassoc_rqst->assoc_cmd.desc_tag =\n\t\t\tcpu_to_be32(FCNVME_LSDESC_CREATE_ASSOC_CMD);\n\tassoc_rqst->assoc_cmd.desc_len =\n\t\t\tfcnvme_lsdesc_len(\n\t\t\t\tsizeof(struct fcnvme_lsdesc_cr_assoc_cmd));\n\n\tassoc_rqst->assoc_cmd.ersp_ratio = cpu_to_be16(ersp_ratio);\n\tassoc_rqst->assoc_cmd.sqsize = cpu_to_be16(qsize - 1);\n\t \n\tassoc_rqst->assoc_cmd.cntlid = cpu_to_be16(0xffff);\n\tuuid_copy(&assoc_rqst->assoc_cmd.hostid, &ctrl->ctrl.opts->host->id);\n\tstrncpy(assoc_rqst->assoc_cmd.hostnqn, ctrl->ctrl.opts->host->nqn,\n\t\tmin(FCNVME_ASSOC_HOSTNQN_LEN, NVMF_NQN_SIZE));\n\tstrncpy(assoc_rqst->assoc_cmd.subnqn, ctrl->ctrl.opts->subsysnqn,\n\t\tmin(FCNVME_ASSOC_SUBNQN_LEN, NVMF_NQN_SIZE));\n\n\tlsop->queue = queue;\n\tlsreq->rqstaddr = assoc_rqst;\n\tlsreq->rqstlen = sizeof(*assoc_rqst);\n\tlsreq->rspaddr = assoc_acc;\n\tlsreq->rsplen = sizeof(*assoc_acc);\n\tlsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;\n\n\tret = nvme_fc_send_ls_req(ctrl->rport, lsop);\n\tif (ret)\n\t\tgoto out_free_buffer;\n\n\t \n\n\t \n\tif (assoc_acc->hdr.w0.ls_cmd != FCNVME_LS_ACC)\n\t\tfcret = VERR_LSACC;\n\telse if (assoc_acc->hdr.desc_list_len !=\n\t\t\tfcnvme_lsdesc_len(\n\t\t\t\tsizeof(struct fcnvme_ls_cr_assoc_acc)))\n\t\tfcret = VERR_CR_ASSOC_ACC_LEN;\n\telse if (assoc_acc->hdr.rqst.desc_tag !=\n\t\t\tcpu_to_be32(FCNVME_LSDESC_RQST))\n\t\tfcret = VERR_LSDESC_RQST;\n\telse if (assoc_acc->hdr.rqst.desc_len !=\n\t\t\tfcnvme_lsdesc_len(sizeof(struct fcnvme_lsdesc_rqst)))\n\t\tfcret = VERR_LSDESC_RQST_LEN;\n\telse if (assoc_acc->hdr.rqst.w0.ls_cmd != FCNVME_LS_CREATE_ASSOCIATION)\n\t\tfcret = VERR_CR_ASSOC;\n\telse if (assoc_acc->associd.desc_tag !=\n\t\t\tcpu_to_be32(FCNVME_LSDESC_ASSOC_ID))\n\t\tfcret = VERR_ASSOC_ID;\n\telse if (assoc_acc->associd.desc_len !=\n\t\t\tfcnvme_lsdesc_len(\n\t\t\t\tsizeof(struct fcnvme_lsdesc_assoc_id)))\n\t\tfcret = VERR_ASSOC_ID_LEN;\n\telse if (assoc_acc->connectid.desc_tag !=\n\t\t\tcpu_to_be32(FCNVME_LSDESC_CONN_ID))\n\t\tfcret = VERR_CONN_ID;\n\telse if (assoc_acc->connectid.desc_len !=\n\t\t\tfcnvme_lsdesc_len(sizeof(struct fcnvme_lsdesc_conn_id)))\n\t\tfcret = VERR_CONN_ID_LEN;\n\n\tif (fcret) {\n\t\tret = -EBADF;\n\t\tdev_err(ctrl->dev,\n\t\t\t\"q %d Create Association LS failed: %s\\n\",\n\t\t\tqueue->qnum, validation_errors[fcret]);\n\t} else {\n\t\tspin_lock_irqsave(&ctrl->lock, flags);\n\t\tctrl->association_id =\n\t\t\tbe64_to_cpu(assoc_acc->associd.association_id);\n\t\tqueue->connection_id =\n\t\t\tbe64_to_cpu(assoc_acc->connectid.connection_id);\n\t\tset_bit(NVME_FC_Q_CONNECTED, &queue->flags);\n\t\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\t}\n\nout_free_buffer:\n\tkfree(lsop);\nout_no_memory:\n\tif (ret)\n\t\tdev_err(ctrl->dev,\n\t\t\t\"queue %d connect admin queue failed (%d).\\n\",\n\t\t\tqueue->qnum, ret);\n\treturn ret;\n}\n\nstatic int\nnvme_fc_connect_queue(struct nvme_fc_ctrl *ctrl, struct nvme_fc_queue *queue,\n\t\t\tu16 qsize, u16 ersp_ratio)\n{\n\tstruct nvmefc_ls_req_op *lsop;\n\tstruct nvmefc_ls_req *lsreq;\n\tstruct fcnvme_ls_cr_conn_rqst *conn_rqst;\n\tstruct fcnvme_ls_cr_conn_acc *conn_acc;\n\tint ret, fcret = 0;\n\n\tlsop = kzalloc((sizeof(*lsop) +\n\t\t\t sizeof(*conn_rqst) + sizeof(*conn_acc) +\n\t\t\t ctrl->lport->ops->lsrqst_priv_sz), GFP_KERNEL);\n\tif (!lsop) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: send Create Connection failed: ENOMEM\\n\",\n\t\t\tctrl->cnum);\n\t\tret = -ENOMEM;\n\t\tgoto out_no_memory;\n\t}\n\n\tconn_rqst = (struct fcnvme_ls_cr_conn_rqst *)&lsop[1];\n\tconn_acc = (struct fcnvme_ls_cr_conn_acc *)&conn_rqst[1];\n\tlsreq = &lsop->ls_req;\n\tif (ctrl->lport->ops->lsrqst_priv_sz)\n\t\tlsreq->private = (void *)&conn_acc[1];\n\telse\n\t\tlsreq->private = NULL;\n\n\tconn_rqst->w0.ls_cmd = FCNVME_LS_CREATE_CONNECTION;\n\tconn_rqst->desc_list_len = cpu_to_be32(\n\t\t\t\tsizeof(struct fcnvme_lsdesc_assoc_id) +\n\t\t\t\tsizeof(struct fcnvme_lsdesc_cr_conn_cmd));\n\n\tconn_rqst->associd.desc_tag = cpu_to_be32(FCNVME_LSDESC_ASSOC_ID);\n\tconn_rqst->associd.desc_len =\n\t\t\tfcnvme_lsdesc_len(\n\t\t\t\tsizeof(struct fcnvme_lsdesc_assoc_id));\n\tconn_rqst->associd.association_id = cpu_to_be64(ctrl->association_id);\n\tconn_rqst->connect_cmd.desc_tag =\n\t\t\tcpu_to_be32(FCNVME_LSDESC_CREATE_CONN_CMD);\n\tconn_rqst->connect_cmd.desc_len =\n\t\t\tfcnvme_lsdesc_len(\n\t\t\t\tsizeof(struct fcnvme_lsdesc_cr_conn_cmd));\n\tconn_rqst->connect_cmd.ersp_ratio = cpu_to_be16(ersp_ratio);\n\tconn_rqst->connect_cmd.qid  = cpu_to_be16(queue->qnum);\n\tconn_rqst->connect_cmd.sqsize = cpu_to_be16(qsize - 1);\n\n\tlsop->queue = queue;\n\tlsreq->rqstaddr = conn_rqst;\n\tlsreq->rqstlen = sizeof(*conn_rqst);\n\tlsreq->rspaddr = conn_acc;\n\tlsreq->rsplen = sizeof(*conn_acc);\n\tlsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;\n\n\tret = nvme_fc_send_ls_req(ctrl->rport, lsop);\n\tif (ret)\n\t\tgoto out_free_buffer;\n\n\t \n\n\t \n\tif (conn_acc->hdr.w0.ls_cmd != FCNVME_LS_ACC)\n\t\tfcret = VERR_LSACC;\n\telse if (conn_acc->hdr.desc_list_len !=\n\t\t\tfcnvme_lsdesc_len(sizeof(struct fcnvme_ls_cr_conn_acc)))\n\t\tfcret = VERR_CR_CONN_ACC_LEN;\n\telse if (conn_acc->hdr.rqst.desc_tag != cpu_to_be32(FCNVME_LSDESC_RQST))\n\t\tfcret = VERR_LSDESC_RQST;\n\telse if (conn_acc->hdr.rqst.desc_len !=\n\t\t\tfcnvme_lsdesc_len(sizeof(struct fcnvme_lsdesc_rqst)))\n\t\tfcret = VERR_LSDESC_RQST_LEN;\n\telse if (conn_acc->hdr.rqst.w0.ls_cmd != FCNVME_LS_CREATE_CONNECTION)\n\t\tfcret = VERR_CR_CONN;\n\telse if (conn_acc->connectid.desc_tag !=\n\t\t\tcpu_to_be32(FCNVME_LSDESC_CONN_ID))\n\t\tfcret = VERR_CONN_ID;\n\telse if (conn_acc->connectid.desc_len !=\n\t\t\tfcnvme_lsdesc_len(sizeof(struct fcnvme_lsdesc_conn_id)))\n\t\tfcret = VERR_CONN_ID_LEN;\n\n\tif (fcret) {\n\t\tret = -EBADF;\n\t\tdev_err(ctrl->dev,\n\t\t\t\"q %d Create I/O Connection LS failed: %s\\n\",\n\t\t\tqueue->qnum, validation_errors[fcret]);\n\t} else {\n\t\tqueue->connection_id =\n\t\t\tbe64_to_cpu(conn_acc->connectid.connection_id);\n\t\tset_bit(NVME_FC_Q_CONNECTED, &queue->flags);\n\t}\n\nout_free_buffer:\n\tkfree(lsop);\nout_no_memory:\n\tif (ret)\n\t\tdev_err(ctrl->dev,\n\t\t\t\"queue %d connect I/O queue failed (%d).\\n\",\n\t\t\tqueue->qnum, ret);\n\treturn ret;\n}\n\nstatic void\nnvme_fc_disconnect_assoc_done(struct nvmefc_ls_req *lsreq, int status)\n{\n\tstruct nvmefc_ls_req_op *lsop = ls_req_to_lsop(lsreq);\n\n\t__nvme_fc_finish_ls_req(lsop);\n\n\t \n\n\tkfree(lsop);\n}\n\n \nstatic void\nnvme_fc_xmt_disconnect_assoc(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct fcnvme_ls_disconnect_assoc_rqst *discon_rqst;\n\tstruct fcnvme_ls_disconnect_assoc_acc *discon_acc;\n\tstruct nvmefc_ls_req_op *lsop;\n\tstruct nvmefc_ls_req *lsreq;\n\tint ret;\n\n\tlsop = kzalloc((sizeof(*lsop) +\n\t\t\tsizeof(*discon_rqst) + sizeof(*discon_acc) +\n\t\t\tctrl->lport->ops->lsrqst_priv_sz), GFP_KERNEL);\n\tif (!lsop) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: send Disconnect Association \"\n\t\t\t\"failed: ENOMEM\\n\",\n\t\t\tctrl->cnum);\n\t\treturn;\n\t}\n\n\tdiscon_rqst = (struct fcnvme_ls_disconnect_assoc_rqst *)&lsop[1];\n\tdiscon_acc = (struct fcnvme_ls_disconnect_assoc_acc *)&discon_rqst[1];\n\tlsreq = &lsop->ls_req;\n\tif (ctrl->lport->ops->lsrqst_priv_sz)\n\t\tlsreq->private = (void *)&discon_acc[1];\n\telse\n\t\tlsreq->private = NULL;\n\n\tnvmefc_fmt_lsreq_discon_assoc(lsreq, discon_rqst, discon_acc,\n\t\t\t\tctrl->association_id);\n\n\tret = nvme_fc_send_ls_req_async(ctrl->rport, lsop,\n\t\t\t\tnvme_fc_disconnect_assoc_done);\n\tif (ret)\n\t\tkfree(lsop);\n}\n\nstatic void\nnvme_fc_xmt_ls_rsp_done(struct nvmefc_ls_rsp *lsrsp)\n{\n\tstruct nvmefc_ls_rcv_op *lsop = lsrsp->nvme_fc_private;\n\tstruct nvme_fc_rport *rport = lsop->rport;\n\tstruct nvme_fc_lport *lport = rport->lport;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\tlist_del(&lsop->lsrcv_list);\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\tfc_dma_sync_single_for_cpu(lport->dev, lsop->rspdma,\n\t\t\t\tsizeof(*lsop->rspbuf), DMA_TO_DEVICE);\n\tfc_dma_unmap_single(lport->dev, lsop->rspdma,\n\t\t\tsizeof(*lsop->rspbuf), DMA_TO_DEVICE);\n\n\tkfree(lsop->rspbuf);\n\tkfree(lsop->rqstbuf);\n\tkfree(lsop);\n\n\tnvme_fc_rport_put(rport);\n}\n\nstatic void\nnvme_fc_xmt_ls_rsp(struct nvmefc_ls_rcv_op *lsop)\n{\n\tstruct nvme_fc_rport *rport = lsop->rport;\n\tstruct nvme_fc_lport *lport = rport->lport;\n\tstruct fcnvme_ls_rqst_w0 *w0 = &lsop->rqstbuf->w0;\n\tint ret;\n\n\tfc_dma_sync_single_for_device(lport->dev, lsop->rspdma,\n\t\t\t\t  sizeof(*lsop->rspbuf), DMA_TO_DEVICE);\n\n\tret = lport->ops->xmt_ls_rsp(&lport->localport, &rport->remoteport,\n\t\t\t\t     lsop->lsrsp);\n\tif (ret) {\n\t\tdev_warn(lport->dev,\n\t\t\t\"LLDD rejected LS RSP xmt: LS %d status %d\\n\",\n\t\t\tw0->ls_cmd, ret);\n\t\tnvme_fc_xmt_ls_rsp_done(lsop->lsrsp);\n\t\treturn;\n\t}\n}\n\nstatic struct nvme_fc_ctrl *\nnvme_fc_match_disconn_ls(struct nvme_fc_rport *rport,\n\t\t      struct nvmefc_ls_rcv_op *lsop)\n{\n\tstruct fcnvme_ls_disconnect_assoc_rqst *rqst =\n\t\t\t\t\t&lsop->rqstbuf->rq_dis_assoc;\n\tstruct nvme_fc_ctrl *ctrl, *ret = NULL;\n\tstruct nvmefc_ls_rcv_op *oldls = NULL;\n\tu64 association_id = be64_to_cpu(rqst->associd.association_id);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\n\tlist_for_each_entry(ctrl, &rport->ctrl_list, ctrl_list) {\n\t\tif (!nvme_fc_ctrl_get(ctrl))\n\t\t\tcontinue;\n\t\tspin_lock(&ctrl->lock);\n\t\tif (association_id == ctrl->association_id) {\n\t\t\toldls = ctrl->rcv_disconn;\n\t\t\tctrl->rcv_disconn = lsop;\n\t\t\tret = ctrl;\n\t\t}\n\t\tspin_unlock(&ctrl->lock);\n\t\tif (ret)\n\t\t\t \n\t\t\tbreak;\n\t\tnvme_fc_ctrl_put(ctrl);\n\t}\n\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\t \n\tif (oldls) {\n\t\tdev_info(rport->lport->dev,\n\t\t\t\"NVME-FC{%d}: Multiple Disconnect Association \"\n\t\t\t\"LS's received\\n\", ctrl->cnum);\n\t\t \n\t\toldls->lsrsp->rsplen = nvme_fc_format_rjt(oldls->rspbuf,\n\t\t\t\t\t\tsizeof(*oldls->rspbuf),\n\t\t\t\t\t\trqst->w0.ls_cmd,\n\t\t\t\t\t\tFCNVME_RJT_RC_UNAB,\n\t\t\t\t\t\tFCNVME_RJT_EXP_NONE, 0);\n\t\tnvme_fc_xmt_ls_rsp(oldls);\n\t}\n\n\treturn ret;\n}\n\n \nstatic bool\nnvme_fc_ls_disconnect_assoc(struct nvmefc_ls_rcv_op *lsop)\n{\n\tstruct nvme_fc_rport *rport = lsop->rport;\n\tstruct fcnvme_ls_disconnect_assoc_rqst *rqst =\n\t\t\t\t\t&lsop->rqstbuf->rq_dis_assoc;\n\tstruct fcnvme_ls_disconnect_assoc_acc *acc =\n\t\t\t\t\t&lsop->rspbuf->rsp_dis_assoc;\n\tstruct nvme_fc_ctrl *ctrl = NULL;\n\tint ret = 0;\n\n\tmemset(acc, 0, sizeof(*acc));\n\n\tret = nvmefc_vldt_lsreq_discon_assoc(lsop->rqstdatalen, rqst);\n\tif (!ret) {\n\t\t \n\t\tctrl = nvme_fc_match_disconn_ls(rport, lsop);\n\t\tif (!ctrl)\n\t\t\tret = VERR_NO_ASSOC;\n\t}\n\n\tif (ret) {\n\t\tdev_info(rport->lport->dev,\n\t\t\t\"Disconnect LS failed: %s\\n\",\n\t\t\tvalidation_errors[ret]);\n\t\tlsop->lsrsp->rsplen = nvme_fc_format_rjt(acc,\n\t\t\t\t\tsizeof(*acc), rqst->w0.ls_cmd,\n\t\t\t\t\t(ret == VERR_NO_ASSOC) ?\n\t\t\t\t\t\tFCNVME_RJT_RC_INV_ASSOC :\n\t\t\t\t\t\tFCNVME_RJT_RC_LOGIC,\n\t\t\t\t\tFCNVME_RJT_EXP_NONE, 0);\n\t\treturn true;\n\t}\n\n\t \n\n\tlsop->lsrsp->rsplen = sizeof(*acc);\n\n\tnvme_fc_format_rsp_hdr(acc, FCNVME_LS_ACC,\n\t\t\tfcnvme_lsdesc_len(\n\t\t\t\tsizeof(struct fcnvme_ls_disconnect_assoc_acc)),\n\t\t\tFCNVME_LS_DISCONNECT_ASSOC);\n\n\t \n\n\t \n\tnvme_fc_error_recovery(ctrl, \"Disconnect Association LS received\");\n\n\t \n\tnvme_fc_ctrl_put(ctrl);\n\n\treturn false;\n}\n\n \nstatic bool\nnvme_fc_handle_ls_rqst(struct nvmefc_ls_rcv_op *lsop)\n{\n\tstruct fcnvme_ls_rqst_w0 *w0 = &lsop->rqstbuf->w0;\n\tbool ret = true;\n\n\tlsop->lsrsp->nvme_fc_private = lsop;\n\tlsop->lsrsp->rspbuf = lsop->rspbuf;\n\tlsop->lsrsp->rspdma = lsop->rspdma;\n\tlsop->lsrsp->done = nvme_fc_xmt_ls_rsp_done;\n\t \n\tlsop->lsrsp->rsplen = 0;\n\n\t \n\tswitch (w0->ls_cmd) {\n\tcase FCNVME_LS_DISCONNECT_ASSOC:\n\t\tret = nvme_fc_ls_disconnect_assoc(lsop);\n\t\tbreak;\n\tcase FCNVME_LS_DISCONNECT_CONN:\n\t\tlsop->lsrsp->rsplen = nvme_fc_format_rjt(lsop->rspbuf,\n\t\t\t\tsizeof(*lsop->rspbuf), w0->ls_cmd,\n\t\t\t\tFCNVME_RJT_RC_UNSUP, FCNVME_RJT_EXP_NONE, 0);\n\t\tbreak;\n\tcase FCNVME_LS_CREATE_ASSOCIATION:\n\tcase FCNVME_LS_CREATE_CONNECTION:\n\t\tlsop->lsrsp->rsplen = nvme_fc_format_rjt(lsop->rspbuf,\n\t\t\t\tsizeof(*lsop->rspbuf), w0->ls_cmd,\n\t\t\t\tFCNVME_RJT_RC_LOGIC, FCNVME_RJT_EXP_NONE, 0);\n\t\tbreak;\n\tdefault:\n\t\tlsop->lsrsp->rsplen = nvme_fc_format_rjt(lsop->rspbuf,\n\t\t\t\tsizeof(*lsop->rspbuf), w0->ls_cmd,\n\t\t\t\tFCNVME_RJT_RC_INVAL, FCNVME_RJT_EXP_NONE, 0);\n\t\tbreak;\n\t}\n\n\treturn(ret);\n}\n\nstatic void\nnvme_fc_handle_ls_rqst_work(struct work_struct *work)\n{\n\tstruct nvme_fc_rport *rport =\n\t\tcontainer_of(work, struct nvme_fc_rport, lsrcv_work);\n\tstruct fcnvme_ls_rqst_w0 *w0;\n\tstruct nvmefc_ls_rcv_op *lsop;\n\tunsigned long flags;\n\tbool sendrsp;\n\nrestart:\n\tsendrsp = true;\n\tspin_lock_irqsave(&rport->lock, flags);\n\tlist_for_each_entry(lsop, &rport->ls_rcv_list, lsrcv_list) {\n\t\tif (lsop->handled)\n\t\t\tcontinue;\n\n\t\tlsop->handled = true;\n\t\tif (rport->remoteport.port_state == FC_OBJSTATE_ONLINE) {\n\t\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\t\tsendrsp = nvme_fc_handle_ls_rqst(lsop);\n\t\t} else {\n\t\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\t\tw0 = &lsop->rqstbuf->w0;\n\t\t\tlsop->lsrsp->rsplen = nvme_fc_format_rjt(\n\t\t\t\t\t\tlsop->rspbuf,\n\t\t\t\t\t\tsizeof(*lsop->rspbuf),\n\t\t\t\t\t\tw0->ls_cmd,\n\t\t\t\t\t\tFCNVME_RJT_RC_UNAB,\n\t\t\t\t\t\tFCNVME_RJT_EXP_NONE, 0);\n\t\t}\n\t\tif (sendrsp)\n\t\t\tnvme_fc_xmt_ls_rsp(lsop);\n\t\tgoto restart;\n\t}\n\tspin_unlock_irqrestore(&rport->lock, flags);\n}\n\nstatic\nvoid nvme_fc_rcv_ls_req_err_msg(struct nvme_fc_lport *lport,\n\t\t\t\tstruct fcnvme_ls_rqst_w0 *w0)\n{\n\tdev_info(lport->dev, \"RCV %s LS failed: No memory\\n\",\n\t\t(w0->ls_cmd <= NVME_FC_LAST_LS_CMD_VALUE) ?\n\t\t\tnvmefc_ls_names[w0->ls_cmd] : \"\");\n}\n\n \nint\nnvme_fc_rcv_ls_req(struct nvme_fc_remote_port *portptr,\n\t\t\tstruct nvmefc_ls_rsp *lsrsp,\n\t\t\tvoid *lsreqbuf, u32 lsreqbuf_len)\n{\n\tstruct nvme_fc_rport *rport = remoteport_to_rport(portptr);\n\tstruct nvme_fc_lport *lport = rport->lport;\n\tstruct fcnvme_ls_rqst_w0 *w0 = (struct fcnvme_ls_rqst_w0 *)lsreqbuf;\n\tstruct nvmefc_ls_rcv_op *lsop;\n\tunsigned long flags;\n\tint ret;\n\n\tnvme_fc_rport_get(rport);\n\n\t \n\tif (!lport->ops->xmt_ls_rsp) {\n\t\tdev_info(lport->dev,\n\t\t\t\"RCV %s LS failed: no LLDD xmt_ls_rsp\\n\",\n\t\t\t(w0->ls_cmd <= NVME_FC_LAST_LS_CMD_VALUE) ?\n\t\t\t\tnvmefc_ls_names[w0->ls_cmd] : \"\");\n\t\tret = -EINVAL;\n\t\tgoto out_put;\n\t}\n\n\tif (lsreqbuf_len > sizeof(union nvmefc_ls_requests)) {\n\t\tdev_info(lport->dev,\n\t\t\t\"RCV %s LS failed: payload too large\\n\",\n\t\t\t(w0->ls_cmd <= NVME_FC_LAST_LS_CMD_VALUE) ?\n\t\t\t\tnvmefc_ls_names[w0->ls_cmd] : \"\");\n\t\tret = -E2BIG;\n\t\tgoto out_put;\n\t}\n\n\tlsop = kzalloc(sizeof(*lsop), GFP_KERNEL);\n\tif (!lsop) {\n\t\tnvme_fc_rcv_ls_req_err_msg(lport, w0);\n\t\tret = -ENOMEM;\n\t\tgoto out_put;\n\t}\n\n\tlsop->rqstbuf = kzalloc(sizeof(*lsop->rqstbuf), GFP_KERNEL);\n\tlsop->rspbuf = kzalloc(sizeof(*lsop->rspbuf), GFP_KERNEL);\n\tif (!lsop->rqstbuf || !lsop->rspbuf) {\n\t\tnvme_fc_rcv_ls_req_err_msg(lport, w0);\n\t\tret = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\tlsop->rspdma = fc_dma_map_single(lport->dev, lsop->rspbuf,\n\t\t\t\t\tsizeof(*lsop->rspbuf),\n\t\t\t\t\tDMA_TO_DEVICE);\n\tif (fc_dma_mapping_error(lport->dev, lsop->rspdma)) {\n\t\tdev_info(lport->dev,\n\t\t\t\"RCV %s LS failed: DMA mapping failure\\n\",\n\t\t\t(w0->ls_cmd <= NVME_FC_LAST_LS_CMD_VALUE) ?\n\t\t\t\tnvmefc_ls_names[w0->ls_cmd] : \"\");\n\t\tret = -EFAULT;\n\t\tgoto out_free;\n\t}\n\n\tlsop->rport = rport;\n\tlsop->lsrsp = lsrsp;\n\n\tmemcpy(lsop->rqstbuf, lsreqbuf, lsreqbuf_len);\n\tlsop->rqstdatalen = lsreqbuf_len;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\tif (rport->remoteport.port_state != FC_OBJSTATE_ONLINE) {\n\t\tspin_unlock_irqrestore(&rport->lock, flags);\n\t\tret = -ENOTCONN;\n\t\tgoto out_unmap;\n\t}\n\tlist_add_tail(&lsop->lsrcv_list, &rport->ls_rcv_list);\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\tschedule_work(&rport->lsrcv_work);\n\n\treturn 0;\n\nout_unmap:\n\tfc_dma_unmap_single(lport->dev, lsop->rspdma,\n\t\t\tsizeof(*lsop->rspbuf), DMA_TO_DEVICE);\nout_free:\n\tkfree(lsop->rspbuf);\n\tkfree(lsop->rqstbuf);\n\tkfree(lsop);\nout_put:\n\tnvme_fc_rport_put(rport);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(nvme_fc_rcv_ls_req);\n\n\n \n\nstatic void\n__nvme_fc_exit_request(struct nvme_fc_ctrl *ctrl,\n\t\tstruct nvme_fc_fcp_op *op)\n{\n\tfc_dma_unmap_single(ctrl->lport->dev, op->fcp_req.rspdma,\n\t\t\t\tsizeof(op->rsp_iu), DMA_FROM_DEVICE);\n\tfc_dma_unmap_single(ctrl->lport->dev, op->fcp_req.cmddma,\n\t\t\t\tsizeof(op->cmd_iu), DMA_TO_DEVICE);\n\n\tatomic_set(&op->state, FCPOP_STATE_UNINIT);\n}\n\nstatic void\nnvme_fc_exit_request(struct blk_mq_tag_set *set, struct request *rq,\n\t\tunsigned int hctx_idx)\n{\n\tstruct nvme_fc_fcp_op *op = blk_mq_rq_to_pdu(rq);\n\n\treturn __nvme_fc_exit_request(to_fc_ctrl(set->driver_data), op);\n}\n\nstatic int\n__nvme_fc_abort_op(struct nvme_fc_ctrl *ctrl, struct nvme_fc_fcp_op *op)\n{\n\tunsigned long flags;\n\tint opstate;\n\n\tspin_lock_irqsave(&ctrl->lock, flags);\n\topstate = atomic_xchg(&op->state, FCPOP_STATE_ABORTED);\n\tif (opstate != FCPOP_STATE_ACTIVE)\n\t\tatomic_set(&op->state, opstate);\n\telse if (test_bit(FCCTRL_TERMIO, &ctrl->flags)) {\n\t\top->flags |= FCOP_FLAGS_TERMIO;\n\t\tctrl->iocnt++;\n\t}\n\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\n\tif (opstate != FCPOP_STATE_ACTIVE)\n\t\treturn -ECANCELED;\n\n\tctrl->lport->ops->fcp_abort(&ctrl->lport->localport,\n\t\t\t\t\t&ctrl->rport->remoteport,\n\t\t\t\t\top->queue->lldd_handle,\n\t\t\t\t\t&op->fcp_req);\n\n\treturn 0;\n}\n\nstatic void\nnvme_fc_abort_aen_ops(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvme_fc_fcp_op *aen_op = ctrl->aen_ops;\n\tint i;\n\n\t \n\tif (!(aen_op->flags & FCOP_FLAGS_AEN))\n\t\treturn;\n\n\tfor (i = 0; i < NVME_NR_AEN_COMMANDS; i++, aen_op++)\n\t\t__nvme_fc_abort_op(ctrl, aen_op);\n}\n\nstatic inline void\n__nvme_fc_fcpop_chk_teardowns(struct nvme_fc_ctrl *ctrl,\n\t\tstruct nvme_fc_fcp_op *op, int opstate)\n{\n\tunsigned long flags;\n\n\tif (opstate == FCPOP_STATE_ABORTED) {\n\t\tspin_lock_irqsave(&ctrl->lock, flags);\n\t\tif (test_bit(FCCTRL_TERMIO, &ctrl->flags) &&\n\t\t    op->flags & FCOP_FLAGS_TERMIO) {\n\t\t\tif (!--ctrl->iocnt)\n\t\t\t\twake_up(&ctrl->ioabort_wait);\n\t\t}\n\t\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\t}\n}\n\nstatic void\nnvme_fc_ctrl_ioerr_work(struct work_struct *work)\n{\n\tstruct nvme_fc_ctrl *ctrl =\n\t\t\tcontainer_of(work, struct nvme_fc_ctrl, ioerr_work);\n\n\tnvme_fc_error_recovery(ctrl, \"transport detected io error\");\n}\n\n \nchar *nvme_fc_io_getuuid(struct nvmefc_fcp_req *req)\n{\n\tstruct nvme_fc_fcp_op *op = fcp_req_to_fcp_op(req);\n\tstruct request *rq = op->rq;\n\n\tif (!IS_ENABLED(CONFIG_BLK_CGROUP_FC_APPID) || !rq || !rq->bio)\n\t\treturn NULL;\n\treturn blkcg_get_fc_appid(rq->bio);\n}\nEXPORT_SYMBOL_GPL(nvme_fc_io_getuuid);\n\nstatic void\nnvme_fc_fcpio_done(struct nvmefc_fcp_req *req)\n{\n\tstruct nvme_fc_fcp_op *op = fcp_req_to_fcp_op(req);\n\tstruct request *rq = op->rq;\n\tstruct nvmefc_fcp_req *freq = &op->fcp_req;\n\tstruct nvme_fc_ctrl *ctrl = op->ctrl;\n\tstruct nvme_fc_queue *queue = op->queue;\n\tstruct nvme_completion *cqe = &op->rsp_iu.cqe;\n\tstruct nvme_command *sqe = &op->cmd_iu.sqe;\n\t__le16 status = cpu_to_le16(NVME_SC_SUCCESS << 1);\n\tunion nvme_result result;\n\tbool terminate_assoc = true;\n\tint opstate;\n\n\t \n\n\topstate = atomic_xchg(&op->state, FCPOP_STATE_COMPLETE);\n\n\tfc_dma_sync_single_for_cpu(ctrl->lport->dev, op->fcp_req.rspdma,\n\t\t\t\tsizeof(op->rsp_iu), DMA_FROM_DEVICE);\n\n\tif (opstate == FCPOP_STATE_ABORTED)\n\t\tstatus = cpu_to_le16(NVME_SC_HOST_ABORTED_CMD << 1);\n\telse if (freq->status) {\n\t\tstatus = cpu_to_le16(NVME_SC_HOST_PATH_ERROR << 1);\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: io failed due to lldd error %d\\n\",\n\t\t\tctrl->cnum, freq->status);\n\t}\n\n\t \n\tif (status)\n\t\tgoto done;\n\n\t \n\n\tswitch (freq->rcv_rsplen) {\n\n\tcase 0:\n\tcase NVME_FC_SIZEOF_ZEROS_RSP:\n\t\t \n\t\tif (freq->transferred_length !=\n\t\t    be32_to_cpu(op->cmd_iu.data_len)) {\n\t\t\tstatus = cpu_to_le16(NVME_SC_HOST_PATH_ERROR << 1);\n\t\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\t\"NVME-FC{%d}: io failed due to bad transfer \"\n\t\t\t\t\"length: %d vs expected %d\\n\",\n\t\t\t\tctrl->cnum, freq->transferred_length,\n\t\t\t\tbe32_to_cpu(op->cmd_iu.data_len));\n\t\t\tgoto done;\n\t\t}\n\t\tresult.u64 = 0;\n\t\tbreak;\n\n\tcase sizeof(struct nvme_fc_ersp_iu):\n\t\t \n\t\tif (unlikely(be16_to_cpu(op->rsp_iu.iu_len) !=\n\t\t\t\t\t(freq->rcv_rsplen / 4) ||\n\t\t\t     be32_to_cpu(op->rsp_iu.xfrd_len) !=\n\t\t\t\t\tfreq->transferred_length ||\n\t\t\t     op->rsp_iu.ersp_result ||\n\t\t\t     sqe->common.command_id != cqe->command_id)) {\n\t\t\tstatus = cpu_to_le16(NVME_SC_HOST_PATH_ERROR << 1);\n\t\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\t\"NVME-FC{%d}: io failed due to bad NVMe_ERSP: \"\n\t\t\t\t\"iu len %d, xfr len %d vs %d, status code \"\n\t\t\t\t\"%d, cmdid %d vs %d\\n\",\n\t\t\t\tctrl->cnum, be16_to_cpu(op->rsp_iu.iu_len),\n\t\t\t\tbe32_to_cpu(op->rsp_iu.xfrd_len),\n\t\t\t\tfreq->transferred_length,\n\t\t\t\top->rsp_iu.ersp_result,\n\t\t\t\tsqe->common.command_id,\n\t\t\t\tcqe->command_id);\n\t\t\tgoto done;\n\t\t}\n\t\tresult = cqe->result;\n\t\tstatus = cqe->status;\n\t\tbreak;\n\n\tdefault:\n\t\tstatus = cpu_to_le16(NVME_SC_HOST_PATH_ERROR << 1);\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: io failed due to odd NVMe_xRSP iu \"\n\t\t\t\"len %d\\n\",\n\t\t\tctrl->cnum, freq->rcv_rsplen);\n\t\tgoto done;\n\t}\n\n\tterminate_assoc = false;\n\ndone:\n\tif (op->flags & FCOP_FLAGS_AEN) {\n\t\tnvme_complete_async_event(&queue->ctrl->ctrl, status, &result);\n\t\t__nvme_fc_fcpop_chk_teardowns(ctrl, op, opstate);\n\t\tatomic_set(&op->state, FCPOP_STATE_IDLE);\n\t\top->flags = FCOP_FLAGS_AEN;\t \n\t\tnvme_fc_ctrl_put(ctrl);\n\t\tgoto check_error;\n\t}\n\n\t__nvme_fc_fcpop_chk_teardowns(ctrl, op, opstate);\n\tif (!nvme_try_complete_req(rq, status, result))\n\t\tnvme_fc_complete_rq(rq);\n\ncheck_error:\n\tif (terminate_assoc && ctrl->ctrl.state != NVME_CTRL_RESETTING)\n\t\tqueue_work(nvme_reset_wq, &ctrl->ioerr_work);\n}\n\nstatic int\n__nvme_fc_init_request(struct nvme_fc_ctrl *ctrl,\n\t\tstruct nvme_fc_queue *queue, struct nvme_fc_fcp_op *op,\n\t\tstruct request *rq, u32 rqno)\n{\n\tstruct nvme_fcp_op_w_sgl *op_w_sgl =\n\t\tcontainer_of(op, typeof(*op_w_sgl), op);\n\tstruct nvme_fc_cmd_iu *cmdiu = &op->cmd_iu;\n\tint ret = 0;\n\n\tmemset(op, 0, sizeof(*op));\n\top->fcp_req.cmdaddr = &op->cmd_iu;\n\top->fcp_req.cmdlen = sizeof(op->cmd_iu);\n\top->fcp_req.rspaddr = &op->rsp_iu;\n\top->fcp_req.rsplen = sizeof(op->rsp_iu);\n\top->fcp_req.done = nvme_fc_fcpio_done;\n\top->ctrl = ctrl;\n\top->queue = queue;\n\top->rq = rq;\n\top->rqno = rqno;\n\n\tcmdiu->format_id = NVME_CMD_FORMAT_ID;\n\tcmdiu->fc_id = NVME_CMD_FC_ID;\n\tcmdiu->iu_len = cpu_to_be16(sizeof(*cmdiu) / sizeof(u32));\n\tif (queue->qnum)\n\t\tcmdiu->rsv_cat = fccmnd_set_cat_css(0,\n\t\t\t\t\t(NVME_CC_CSS_NVM >> NVME_CC_CSS_SHIFT));\n\telse\n\t\tcmdiu->rsv_cat = fccmnd_set_cat_admin(0);\n\n\top->fcp_req.cmddma = fc_dma_map_single(ctrl->lport->dev,\n\t\t\t\t&op->cmd_iu, sizeof(op->cmd_iu), DMA_TO_DEVICE);\n\tif (fc_dma_mapping_error(ctrl->lport->dev, op->fcp_req.cmddma)) {\n\t\tdev_err(ctrl->dev,\n\t\t\t\"FCP Op failed - cmdiu dma mapping failed.\\n\");\n\t\tret = -EFAULT;\n\t\tgoto out_on_error;\n\t}\n\n\top->fcp_req.rspdma = fc_dma_map_single(ctrl->lport->dev,\n\t\t\t\t&op->rsp_iu, sizeof(op->rsp_iu),\n\t\t\t\tDMA_FROM_DEVICE);\n\tif (fc_dma_mapping_error(ctrl->lport->dev, op->fcp_req.rspdma)) {\n\t\tdev_err(ctrl->dev,\n\t\t\t\"FCP Op failed - rspiu dma mapping failed.\\n\");\n\t\tret = -EFAULT;\n\t}\n\n\tatomic_set(&op->state, FCPOP_STATE_IDLE);\nout_on_error:\n\treturn ret;\n}\n\nstatic int\nnvme_fc_init_request(struct blk_mq_tag_set *set, struct request *rq,\n\t\tunsigned int hctx_idx, unsigned int numa_node)\n{\n\tstruct nvme_fc_ctrl *ctrl = to_fc_ctrl(set->driver_data);\n\tstruct nvme_fcp_op_w_sgl *op = blk_mq_rq_to_pdu(rq);\n\tint queue_idx = (set == &ctrl->tag_set) ? hctx_idx + 1 : 0;\n\tstruct nvme_fc_queue *queue = &ctrl->queues[queue_idx];\n\tint res;\n\n\tres = __nvme_fc_init_request(ctrl, queue, &op->op, rq, queue->rqcnt++);\n\tif (res)\n\t\treturn res;\n\top->op.fcp_req.first_sgl = op->sgl;\n\top->op.fcp_req.private = &op->priv[0];\n\tnvme_req(rq)->ctrl = &ctrl->ctrl;\n\tnvme_req(rq)->cmd = &op->op.cmd_iu.sqe;\n\treturn res;\n}\n\nstatic int\nnvme_fc_init_aen_ops(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvme_fc_fcp_op *aen_op;\n\tstruct nvme_fc_cmd_iu *cmdiu;\n\tstruct nvme_command *sqe;\n\tvoid *private = NULL;\n\tint i, ret;\n\n\taen_op = ctrl->aen_ops;\n\tfor (i = 0; i < NVME_NR_AEN_COMMANDS; i++, aen_op++) {\n\t\tif (ctrl->lport->ops->fcprqst_priv_sz) {\n\t\t\tprivate = kzalloc(ctrl->lport->ops->fcprqst_priv_sz,\n\t\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!private)\n\t\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tcmdiu = &aen_op->cmd_iu;\n\t\tsqe = &cmdiu->sqe;\n\t\tret = __nvme_fc_init_request(ctrl, &ctrl->queues[0],\n\t\t\t\taen_op, (struct request *)NULL,\n\t\t\t\t(NVME_AQ_BLK_MQ_DEPTH + i));\n\t\tif (ret) {\n\t\t\tkfree(private);\n\t\t\treturn ret;\n\t\t}\n\n\t\taen_op->flags = FCOP_FLAGS_AEN;\n\t\taen_op->fcp_req.private = private;\n\n\t\tmemset(sqe, 0, sizeof(*sqe));\n\t\tsqe->common.opcode = nvme_admin_async_event;\n\t\t \n\t\tsqe->common.command_id = NVME_AQ_BLK_MQ_DEPTH + i;\n\t}\n\treturn 0;\n}\n\nstatic void\nnvme_fc_term_aen_ops(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvme_fc_fcp_op *aen_op;\n\tint i;\n\n\tcancel_work_sync(&ctrl->ctrl.async_event_work);\n\taen_op = ctrl->aen_ops;\n\tfor (i = 0; i < NVME_NR_AEN_COMMANDS; i++, aen_op++) {\n\t\t__nvme_fc_exit_request(ctrl, aen_op);\n\n\t\tkfree(aen_op->fcp_req.private);\n\t\taen_op->fcp_req.private = NULL;\n\t}\n}\n\nstatic inline int\n__nvme_fc_init_hctx(struct blk_mq_hw_ctx *hctx, void *data, unsigned int qidx)\n{\n\tstruct nvme_fc_ctrl *ctrl = to_fc_ctrl(data);\n\tstruct nvme_fc_queue *queue = &ctrl->queues[qidx];\n\n\thctx->driver_data = queue;\n\tqueue->hctx = hctx;\n\treturn 0;\n}\n\nstatic int\nnvme_fc_init_hctx(struct blk_mq_hw_ctx *hctx, void *data, unsigned int hctx_idx)\n{\n\treturn __nvme_fc_init_hctx(hctx, data, hctx_idx + 1);\n}\n\nstatic int\nnvme_fc_init_admin_hctx(struct blk_mq_hw_ctx *hctx, void *data,\n\t\tunsigned int hctx_idx)\n{\n\treturn __nvme_fc_init_hctx(hctx, data, hctx_idx);\n}\n\nstatic void\nnvme_fc_init_queue(struct nvme_fc_ctrl *ctrl, int idx)\n{\n\tstruct nvme_fc_queue *queue;\n\n\tqueue = &ctrl->queues[idx];\n\tmemset(queue, 0, sizeof(*queue));\n\tqueue->ctrl = ctrl;\n\tqueue->qnum = idx;\n\tatomic_set(&queue->csn, 0);\n\tqueue->dev = ctrl->dev;\n\n\tif (idx > 0)\n\t\tqueue->cmnd_capsule_len = ctrl->ctrl.ioccsz * 16;\n\telse\n\t\tqueue->cmnd_capsule_len = sizeof(struct nvme_command);\n\n\t \n}\n\n \nstatic void\nnvme_fc_free_queue(struct nvme_fc_queue *queue)\n{\n\tif (!test_and_clear_bit(NVME_FC_Q_CONNECTED, &queue->flags))\n\t\treturn;\n\n\tclear_bit(NVME_FC_Q_LIVE, &queue->flags);\n\t \n\n\tqueue->connection_id = 0;\n\tatomic_set(&queue->csn, 0);\n}\n\nstatic void\n__nvme_fc_delete_hw_queue(struct nvme_fc_ctrl *ctrl,\n\tstruct nvme_fc_queue *queue, unsigned int qidx)\n{\n\tif (ctrl->lport->ops->delete_queue)\n\t\tctrl->lport->ops->delete_queue(&ctrl->lport->localport, qidx,\n\t\t\t\tqueue->lldd_handle);\n\tqueue->lldd_handle = NULL;\n}\n\nstatic void\nnvme_fc_free_io_queues(struct nvme_fc_ctrl *ctrl)\n{\n\tint i;\n\n\tfor (i = 1; i < ctrl->ctrl.queue_count; i++)\n\t\tnvme_fc_free_queue(&ctrl->queues[i]);\n}\n\nstatic int\n__nvme_fc_create_hw_queue(struct nvme_fc_ctrl *ctrl,\n\tstruct nvme_fc_queue *queue, unsigned int qidx, u16 qsize)\n{\n\tint ret = 0;\n\n\tqueue->lldd_handle = NULL;\n\tif (ctrl->lport->ops->create_queue)\n\t\tret = ctrl->lport->ops->create_queue(&ctrl->lport->localport,\n\t\t\t\tqidx, qsize, &queue->lldd_handle);\n\n\treturn ret;\n}\n\nstatic void\nnvme_fc_delete_hw_io_queues(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvme_fc_queue *queue = &ctrl->queues[ctrl->ctrl.queue_count - 1];\n\tint i;\n\n\tfor (i = ctrl->ctrl.queue_count - 1; i >= 1; i--, queue--)\n\t\t__nvme_fc_delete_hw_queue(ctrl, queue, i);\n}\n\nstatic int\nnvme_fc_create_hw_io_queues(struct nvme_fc_ctrl *ctrl, u16 qsize)\n{\n\tstruct nvme_fc_queue *queue = &ctrl->queues[1];\n\tint i, ret;\n\n\tfor (i = 1; i < ctrl->ctrl.queue_count; i++, queue++) {\n\t\tret = __nvme_fc_create_hw_queue(ctrl, queue, i, qsize);\n\t\tif (ret)\n\t\t\tgoto delete_queues;\n\t}\n\n\treturn 0;\n\ndelete_queues:\n\tfor (; i > 0; i--)\n\t\t__nvme_fc_delete_hw_queue(ctrl, &ctrl->queues[i], i);\n\treturn ret;\n}\n\nstatic int\nnvme_fc_connect_io_queues(struct nvme_fc_ctrl *ctrl, u16 qsize)\n{\n\tint i, ret = 0;\n\n\tfor (i = 1; i < ctrl->ctrl.queue_count; i++) {\n\t\tret = nvme_fc_connect_queue(ctrl, &ctrl->queues[i], qsize,\n\t\t\t\t\t(qsize / 5));\n\t\tif (ret)\n\t\t\tbreak;\n\t\tret = nvmf_connect_io_queue(&ctrl->ctrl, i);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tset_bit(NVME_FC_Q_LIVE, &ctrl->queues[i].flags);\n\t}\n\n\treturn ret;\n}\n\nstatic void\nnvme_fc_init_io_queues(struct nvme_fc_ctrl *ctrl)\n{\n\tint i;\n\n\tfor (i = 1; i < ctrl->ctrl.queue_count; i++)\n\t\tnvme_fc_init_queue(ctrl, i);\n}\n\nstatic void\nnvme_fc_ctrl_free(struct kref *ref)\n{\n\tstruct nvme_fc_ctrl *ctrl =\n\t\tcontainer_of(ref, struct nvme_fc_ctrl, ref);\n\tunsigned long flags;\n\n\tif (ctrl->ctrl.tagset)\n\t\tnvme_remove_io_tag_set(&ctrl->ctrl);\n\n\t \n\tspin_lock_irqsave(&ctrl->rport->lock, flags);\n\tlist_del(&ctrl->ctrl_list);\n\tspin_unlock_irqrestore(&ctrl->rport->lock, flags);\n\n\tnvme_unquiesce_admin_queue(&ctrl->ctrl);\n\tnvme_remove_admin_tag_set(&ctrl->ctrl);\n\n\tkfree(ctrl->queues);\n\n\tput_device(ctrl->dev);\n\tnvme_fc_rport_put(ctrl->rport);\n\n\tida_free(&nvme_fc_ctrl_cnt, ctrl->cnum);\n\tif (ctrl->ctrl.opts)\n\t\tnvmf_free_options(ctrl->ctrl.opts);\n\tkfree(ctrl);\n}\n\nstatic void\nnvme_fc_ctrl_put(struct nvme_fc_ctrl *ctrl)\n{\n\tkref_put(&ctrl->ref, nvme_fc_ctrl_free);\n}\n\nstatic int\nnvme_fc_ctrl_get(struct nvme_fc_ctrl *ctrl)\n{\n\treturn kref_get_unless_zero(&ctrl->ref);\n}\n\n \nstatic void\nnvme_fc_nvme_ctrl_freed(struct nvme_ctrl *nctrl)\n{\n\tstruct nvme_fc_ctrl *ctrl = to_fc_ctrl(nctrl);\n\n\tWARN_ON(nctrl != &ctrl->ctrl);\n\n\tnvme_fc_ctrl_put(ctrl);\n}\n\n \nstatic bool nvme_fc_terminate_exchange(struct request *req, void *data)\n{\n\tstruct nvme_ctrl *nctrl = data;\n\tstruct nvme_fc_ctrl *ctrl = to_fc_ctrl(nctrl);\n\tstruct nvme_fc_fcp_op *op = blk_mq_rq_to_pdu(req);\n\n\top->nreq.flags |= NVME_REQ_CANCELLED;\n\t__nvme_fc_abort_op(ctrl, op);\n\treturn true;\n}\n\n \nstatic void\n__nvme_fc_abort_outstanding_ios(struct nvme_fc_ctrl *ctrl, bool start_queues)\n{\n\tint q;\n\n\t \n\tif (ctrl->ctrl.queue_count > 1) {\n\t\tfor (q = 1; q < ctrl->ctrl.queue_count; q++)\n\t\t\tclear_bit(NVME_FC_Q_LIVE, &ctrl->queues[q].flags);\n\t}\n\tclear_bit(NVME_FC_Q_LIVE, &ctrl->queues[0].flags);\n\n\t \n\tif (ctrl->ctrl.queue_count > 1) {\n\t\tnvme_quiesce_io_queues(&ctrl->ctrl);\n\t\tnvme_sync_io_queues(&ctrl->ctrl);\n\t\tblk_mq_tagset_busy_iter(&ctrl->tag_set,\n\t\t\t\tnvme_fc_terminate_exchange, &ctrl->ctrl);\n\t\tblk_mq_tagset_wait_completed_request(&ctrl->tag_set);\n\t\tif (start_queues)\n\t\t\tnvme_unquiesce_io_queues(&ctrl->ctrl);\n\t}\n\n\t \n\n\t \n\tnvme_quiesce_admin_queue(&ctrl->ctrl);\n\tblk_sync_queue(ctrl->ctrl.admin_q);\n\tblk_mq_tagset_busy_iter(&ctrl->admin_tag_set,\n\t\t\t\tnvme_fc_terminate_exchange, &ctrl->ctrl);\n\tblk_mq_tagset_wait_completed_request(&ctrl->admin_tag_set);\n\tif (start_queues)\n\t\tnvme_unquiesce_admin_queue(&ctrl->ctrl);\n}\n\nstatic void\nnvme_fc_error_recovery(struct nvme_fc_ctrl *ctrl, char *errmsg)\n{\n\t \n\tif (ctrl->ctrl.state == NVME_CTRL_CONNECTING) {\n\t\t__nvme_fc_abort_outstanding_ios(ctrl, true);\n\t\tset_bit(ASSOC_FAILED, &ctrl->flags);\n\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: transport error during (re)connect\\n\",\n\t\t\tctrl->cnum);\n\t\treturn;\n\t}\n\n\t \n\tif (ctrl->ctrl.state != NVME_CTRL_LIVE)\n\t\treturn;\n\n\tdev_warn(ctrl->ctrl.device,\n\t\t\"NVME-FC{%d}: transport association event: %s\\n\",\n\t\tctrl->cnum, errmsg);\n\tdev_warn(ctrl->ctrl.device,\n\t\t\"NVME-FC{%d}: resetting controller\\n\", ctrl->cnum);\n\n\tnvme_reset_ctrl(&ctrl->ctrl);\n}\n\nstatic enum blk_eh_timer_return nvme_fc_timeout(struct request *rq)\n{\n\tstruct nvme_fc_fcp_op *op = blk_mq_rq_to_pdu(rq);\n\tstruct nvme_fc_ctrl *ctrl = op->ctrl;\n\tstruct nvme_fc_cmd_iu *cmdiu = &op->cmd_iu;\n\tstruct nvme_command *sqe = &cmdiu->sqe;\n\n\t \n\tdev_info(ctrl->ctrl.device,\n\t\t\"NVME-FC{%d.%d}: io timeout: opcode %d fctype %d w10/11: \"\n\t\t\"x%08x/x%08x\\n\",\n\t\tctrl->cnum, op->queue->qnum, sqe->common.opcode,\n\t\tsqe->connect.fctype, sqe->common.cdw10, sqe->common.cdw11);\n\tif (__nvme_fc_abort_op(ctrl, op))\n\t\tnvme_fc_error_recovery(ctrl, \"io timeout abort failed\");\n\n\t \n\treturn BLK_EH_RESET_TIMER;\n}\n\nstatic int\nnvme_fc_map_data(struct nvme_fc_ctrl *ctrl, struct request *rq,\n\t\tstruct nvme_fc_fcp_op *op)\n{\n\tstruct nvmefc_fcp_req *freq = &op->fcp_req;\n\tint ret;\n\n\tfreq->sg_cnt = 0;\n\n\tif (!blk_rq_nr_phys_segments(rq))\n\t\treturn 0;\n\n\tfreq->sg_table.sgl = freq->first_sgl;\n\tret = sg_alloc_table_chained(&freq->sg_table,\n\t\t\tblk_rq_nr_phys_segments(rq), freq->sg_table.sgl,\n\t\t\tNVME_INLINE_SG_CNT);\n\tif (ret)\n\t\treturn -ENOMEM;\n\n\top->nents = blk_rq_map_sg(rq->q, rq, freq->sg_table.sgl);\n\tWARN_ON(op->nents > blk_rq_nr_phys_segments(rq));\n\tfreq->sg_cnt = fc_dma_map_sg(ctrl->lport->dev, freq->sg_table.sgl,\n\t\t\t\top->nents, rq_dma_dir(rq));\n\tif (unlikely(freq->sg_cnt <= 0)) {\n\t\tsg_free_table_chained(&freq->sg_table, NVME_INLINE_SG_CNT);\n\t\tfreq->sg_cnt = 0;\n\t\treturn -EFAULT;\n\t}\n\n\t \n\treturn 0;\n}\n\nstatic void\nnvme_fc_unmap_data(struct nvme_fc_ctrl *ctrl, struct request *rq,\n\t\tstruct nvme_fc_fcp_op *op)\n{\n\tstruct nvmefc_fcp_req *freq = &op->fcp_req;\n\n\tif (!freq->sg_cnt)\n\t\treturn;\n\n\tfc_dma_unmap_sg(ctrl->lport->dev, freq->sg_table.sgl, op->nents,\n\t\t\trq_dma_dir(rq));\n\n\tsg_free_table_chained(&freq->sg_table, NVME_INLINE_SG_CNT);\n\n\tfreq->sg_cnt = 0;\n}\n\n \nstatic blk_status_t\nnvme_fc_start_fcp_op(struct nvme_fc_ctrl *ctrl, struct nvme_fc_queue *queue,\n\tstruct nvme_fc_fcp_op *op, u32 data_len,\n\tenum nvmefc_fcp_datadir\tio_dir)\n{\n\tstruct nvme_fc_cmd_iu *cmdiu = &op->cmd_iu;\n\tstruct nvme_command *sqe = &cmdiu->sqe;\n\tint ret, opstate;\n\n\t \n\tif (ctrl->rport->remoteport.port_state != FC_OBJSTATE_ONLINE)\n\t\treturn BLK_STS_RESOURCE;\n\n\tif (!nvme_fc_ctrl_get(ctrl))\n\t\treturn BLK_STS_IOERR;\n\n\t \n\tcmdiu->connection_id = cpu_to_be64(queue->connection_id);\n\tcmdiu->data_len = cpu_to_be32(data_len);\n\tswitch (io_dir) {\n\tcase NVMEFC_FCP_WRITE:\n\t\tcmdiu->flags = FCNVME_CMD_FLAGS_WRITE;\n\t\tbreak;\n\tcase NVMEFC_FCP_READ:\n\t\tcmdiu->flags = FCNVME_CMD_FLAGS_READ;\n\t\tbreak;\n\tcase NVMEFC_FCP_NODATA:\n\t\tcmdiu->flags = 0;\n\t\tbreak;\n\t}\n\top->fcp_req.payload_length = data_len;\n\top->fcp_req.io_dir = io_dir;\n\top->fcp_req.transferred_length = 0;\n\top->fcp_req.rcv_rsplen = 0;\n\top->fcp_req.status = NVME_SC_SUCCESS;\n\top->fcp_req.sqid = cpu_to_le16(queue->qnum);\n\n\t \n\tWARN_ON_ONCE(sqe->common.metadata);\n\tsqe->common.flags |= NVME_CMD_SGL_METABUF;\n\n\t \n\tsqe->rw.dptr.sgl.type = (NVME_TRANSPORT_SGL_DATA_DESC << 4) |\n\t\t\t\t\tNVME_SGL_FMT_TRANSPORT_A;\n\tsqe->rw.dptr.sgl.length = cpu_to_le32(data_len);\n\tsqe->rw.dptr.sgl.addr = 0;\n\n\tif (!(op->flags & FCOP_FLAGS_AEN)) {\n\t\tret = nvme_fc_map_data(ctrl, op->rq, op);\n\t\tif (ret < 0) {\n\t\t\tnvme_cleanup_cmd(op->rq);\n\t\t\tnvme_fc_ctrl_put(ctrl);\n\t\t\tif (ret == -ENOMEM || ret == -EAGAIN)\n\t\t\t\treturn BLK_STS_RESOURCE;\n\t\t\treturn BLK_STS_IOERR;\n\t\t}\n\t}\n\n\tfc_dma_sync_single_for_device(ctrl->lport->dev, op->fcp_req.cmddma,\n\t\t\t\t  sizeof(op->cmd_iu), DMA_TO_DEVICE);\n\n\tatomic_set(&op->state, FCPOP_STATE_ACTIVE);\n\n\tif (!(op->flags & FCOP_FLAGS_AEN))\n\t\tnvme_start_request(op->rq);\n\n\tcmdiu->csn = cpu_to_be32(atomic_inc_return(&queue->csn));\n\tret = ctrl->lport->ops->fcp_io(&ctrl->lport->localport,\n\t\t\t\t\t&ctrl->rport->remoteport,\n\t\t\t\t\tqueue->lldd_handle, &op->fcp_req);\n\n\tif (ret) {\n\t\t \n\t\topstate = atomic_xchg(&op->state, FCPOP_STATE_COMPLETE);\n\t\t__nvme_fc_fcpop_chk_teardowns(ctrl, op, opstate);\n\n\t\tif (!(op->flags & FCOP_FLAGS_AEN)) {\n\t\t\tnvme_fc_unmap_data(ctrl, op->rq, op);\n\t\t\tnvme_cleanup_cmd(op->rq);\n\t\t}\n\n\t\tnvme_fc_ctrl_put(ctrl);\n\n\t\tif (ctrl->rport->remoteport.port_state == FC_OBJSTATE_ONLINE &&\n\t\t\t\tret != -EBUSY)\n\t\t\treturn BLK_STS_IOERR;\n\n\t\treturn BLK_STS_RESOURCE;\n\t}\n\n\treturn BLK_STS_OK;\n}\n\nstatic blk_status_t\nnvme_fc_queue_rq(struct blk_mq_hw_ctx *hctx,\n\t\t\tconst struct blk_mq_queue_data *bd)\n{\n\tstruct nvme_ns *ns = hctx->queue->queuedata;\n\tstruct nvme_fc_queue *queue = hctx->driver_data;\n\tstruct nvme_fc_ctrl *ctrl = queue->ctrl;\n\tstruct request *rq = bd->rq;\n\tstruct nvme_fc_fcp_op *op = blk_mq_rq_to_pdu(rq);\n\tenum nvmefc_fcp_datadir\tio_dir;\n\tbool queue_ready = test_bit(NVME_FC_Q_LIVE, &queue->flags);\n\tu32 data_len;\n\tblk_status_t ret;\n\n\tif (ctrl->rport->remoteport.port_state != FC_OBJSTATE_ONLINE ||\n\t    !nvme_check_ready(&queue->ctrl->ctrl, rq, queue_ready))\n\t\treturn nvme_fail_nonready_command(&queue->ctrl->ctrl, rq);\n\n\tret = nvme_setup_cmd(ns, rq);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (blk_rq_nr_phys_segments(rq)) {\n\t\tdata_len = blk_rq_payload_bytes(rq);\n\t\tio_dir = ((rq_data_dir(rq) == WRITE) ?\n\t\t\t\t\tNVMEFC_FCP_WRITE : NVMEFC_FCP_READ);\n\t} else {\n\t\tdata_len = 0;\n\t\tio_dir = NVMEFC_FCP_NODATA;\n\t}\n\n\n\treturn nvme_fc_start_fcp_op(ctrl, queue, op, data_len, io_dir);\n}\n\nstatic void\nnvme_fc_submit_async_event(struct nvme_ctrl *arg)\n{\n\tstruct nvme_fc_ctrl *ctrl = to_fc_ctrl(arg);\n\tstruct nvme_fc_fcp_op *aen_op;\n\tblk_status_t ret;\n\n\tif (test_bit(FCCTRL_TERMIO, &ctrl->flags))\n\t\treturn;\n\n\taen_op = &ctrl->aen_ops[0];\n\n\tret = nvme_fc_start_fcp_op(ctrl, aen_op->queue, aen_op, 0,\n\t\t\t\t\tNVMEFC_FCP_NODATA);\n\tif (ret)\n\t\tdev_err(ctrl->ctrl.device,\n\t\t\t\"failed async event work\\n\");\n}\n\nstatic void\nnvme_fc_complete_rq(struct request *rq)\n{\n\tstruct nvme_fc_fcp_op *op = blk_mq_rq_to_pdu(rq);\n\tstruct nvme_fc_ctrl *ctrl = op->ctrl;\n\n\tatomic_set(&op->state, FCPOP_STATE_IDLE);\n\top->flags &= ~FCOP_FLAGS_TERMIO;\n\n\tnvme_fc_unmap_data(ctrl, rq, op);\n\tnvme_complete_rq(rq);\n\tnvme_fc_ctrl_put(ctrl);\n}\n\nstatic void nvme_fc_map_queues(struct blk_mq_tag_set *set)\n{\n\tstruct nvme_fc_ctrl *ctrl = to_fc_ctrl(set->driver_data);\n\tint i;\n\n\tfor (i = 0; i < set->nr_maps; i++) {\n\t\tstruct blk_mq_queue_map *map = &set->map[i];\n\n\t\tif (!map->nr_queues) {\n\t\t\tWARN_ON(i == HCTX_TYPE_DEFAULT);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (ctrl->lport->ops->map_queues)\n\t\t\tctrl->lport->ops->map_queues(&ctrl->lport->localport,\n\t\t\t\t\t\t     map);\n\t\telse\n\t\t\tblk_mq_map_queues(map);\n\t}\n}\n\nstatic const struct blk_mq_ops nvme_fc_mq_ops = {\n\t.queue_rq\t= nvme_fc_queue_rq,\n\t.complete\t= nvme_fc_complete_rq,\n\t.init_request\t= nvme_fc_init_request,\n\t.exit_request\t= nvme_fc_exit_request,\n\t.init_hctx\t= nvme_fc_init_hctx,\n\t.timeout\t= nvme_fc_timeout,\n\t.map_queues\t= nvme_fc_map_queues,\n};\n\nstatic int\nnvme_fc_create_io_queues(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvmf_ctrl_options *opts = ctrl->ctrl.opts;\n\tunsigned int nr_io_queues;\n\tint ret;\n\n\tnr_io_queues = min(min(opts->nr_io_queues, num_online_cpus()),\n\t\t\t\tctrl->lport->ops->max_hw_queues);\n\tret = nvme_set_queue_count(&ctrl->ctrl, &nr_io_queues);\n\tif (ret) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"set_queue_count failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tctrl->ctrl.queue_count = nr_io_queues + 1;\n\tif (!nr_io_queues)\n\t\treturn 0;\n\n\tnvme_fc_init_io_queues(ctrl);\n\n\tret = nvme_alloc_io_tag_set(&ctrl->ctrl, &ctrl->tag_set,\n\t\t\t&nvme_fc_mq_ops, 1,\n\t\t\tstruct_size_t(struct nvme_fcp_op_w_sgl, priv,\n\t\t\t\t      ctrl->lport->ops->fcprqst_priv_sz));\n\tif (ret)\n\t\treturn ret;\n\n\tret = nvme_fc_create_hw_io_queues(ctrl, ctrl->ctrl.sqsize + 1);\n\tif (ret)\n\t\tgoto out_cleanup_tagset;\n\n\tret = nvme_fc_connect_io_queues(ctrl, ctrl->ctrl.sqsize + 1);\n\tif (ret)\n\t\tgoto out_delete_hw_queues;\n\n\tctrl->ioq_live = true;\n\n\treturn 0;\n\nout_delete_hw_queues:\n\tnvme_fc_delete_hw_io_queues(ctrl);\nout_cleanup_tagset:\n\tnvme_remove_io_tag_set(&ctrl->ctrl);\n\tnvme_fc_free_io_queues(ctrl);\n\n\t \n\tctrl->ctrl.tagset = NULL;\n\n\treturn ret;\n}\n\nstatic int\nnvme_fc_recreate_io_queues(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvmf_ctrl_options *opts = ctrl->ctrl.opts;\n\tu32 prior_ioq_cnt = ctrl->ctrl.queue_count - 1;\n\tunsigned int nr_io_queues;\n\tint ret;\n\n\tnr_io_queues = min(min(opts->nr_io_queues, num_online_cpus()),\n\t\t\t\tctrl->lport->ops->max_hw_queues);\n\tret = nvme_set_queue_count(&ctrl->ctrl, &nr_io_queues);\n\tif (ret) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"set_queue_count failed: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!nr_io_queues && prior_ioq_cnt) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"Fail Reconnect: At least 1 io queue \"\n\t\t\t\"required (was %d)\\n\", prior_ioq_cnt);\n\t\treturn -ENOSPC;\n\t}\n\n\tctrl->ctrl.queue_count = nr_io_queues + 1;\n\t \n\tif (ctrl->ctrl.queue_count == 1)\n\t\treturn 0;\n\n\tif (prior_ioq_cnt != nr_io_queues) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"reconnect: revising io queue count from %d to %d\\n\",\n\t\t\tprior_ioq_cnt, nr_io_queues);\n\t\tblk_mq_update_nr_hw_queues(&ctrl->tag_set, nr_io_queues);\n\t}\n\n\tret = nvme_fc_create_hw_io_queues(ctrl, ctrl->ctrl.sqsize + 1);\n\tif (ret)\n\t\tgoto out_free_io_queues;\n\n\tret = nvme_fc_connect_io_queues(ctrl, ctrl->ctrl.sqsize + 1);\n\tif (ret)\n\t\tgoto out_delete_hw_queues;\n\n\treturn 0;\n\nout_delete_hw_queues:\n\tnvme_fc_delete_hw_io_queues(ctrl);\nout_free_io_queues:\n\tnvme_fc_free_io_queues(ctrl);\n\treturn ret;\n}\n\nstatic void\nnvme_fc_rport_active_on_lport(struct nvme_fc_rport *rport)\n{\n\tstruct nvme_fc_lport *lport = rport->lport;\n\n\tatomic_inc(&lport->act_rport_cnt);\n}\n\nstatic void\nnvme_fc_rport_inactive_on_lport(struct nvme_fc_rport *rport)\n{\n\tstruct nvme_fc_lport *lport = rport->lport;\n\tu32 cnt;\n\n\tcnt = atomic_dec_return(&lport->act_rport_cnt);\n\tif (cnt == 0 && lport->localport.port_state == FC_OBJSTATE_DELETED)\n\t\tlport->ops->localport_delete(&lport->localport);\n}\n\nstatic int\nnvme_fc_ctlr_active_on_rport(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvme_fc_rport *rport = ctrl->rport;\n\tu32 cnt;\n\n\tif (test_and_set_bit(ASSOC_ACTIVE, &ctrl->flags))\n\t\treturn 1;\n\n\tcnt = atomic_inc_return(&rport->act_ctrl_cnt);\n\tif (cnt == 1)\n\t\tnvme_fc_rport_active_on_lport(rport);\n\n\treturn 0;\n}\n\nstatic int\nnvme_fc_ctlr_inactive_on_rport(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvme_fc_rport *rport = ctrl->rport;\n\tstruct nvme_fc_lport *lport = rport->lport;\n\tu32 cnt;\n\n\t \n\n\tcnt = atomic_dec_return(&rport->act_ctrl_cnt);\n\tif (cnt == 0) {\n\t\tif (rport->remoteport.port_state == FC_OBJSTATE_DELETED)\n\t\t\tlport->ops->remoteport_delete(&rport->remoteport);\n\t\tnvme_fc_rport_inactive_on_lport(rport);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nnvme_fc_create_association(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvmf_ctrl_options *opts = ctrl->ctrl.opts;\n\tstruct nvmefc_ls_rcv_op *disls = NULL;\n\tunsigned long flags;\n\tint ret;\n\tbool changed;\n\n\t++ctrl->ctrl.nr_reconnects;\n\n\tif (ctrl->rport->remoteport.port_state != FC_OBJSTATE_ONLINE)\n\t\treturn -ENODEV;\n\n\tif (nvme_fc_ctlr_active_on_rport(ctrl))\n\t\treturn -ENOTUNIQ;\n\n\tdev_info(ctrl->ctrl.device,\n\t\t\"NVME-FC{%d}: create association : host wwpn 0x%016llx \"\n\t\t\" rport wwpn 0x%016llx: NQN \\\"%s\\\"\\n\",\n\t\tctrl->cnum, ctrl->lport->localport.port_name,\n\t\tctrl->rport->remoteport.port_name, ctrl->ctrl.opts->subsysnqn);\n\n\tclear_bit(ASSOC_FAILED, &ctrl->flags);\n\n\t \n\n\tret = __nvme_fc_create_hw_queue(ctrl, &ctrl->queues[0], 0,\n\t\t\t\tNVME_AQ_DEPTH);\n\tif (ret)\n\t\tgoto out_free_queue;\n\n\tret = nvme_fc_connect_admin_queue(ctrl, &ctrl->queues[0],\n\t\t\t\tNVME_AQ_DEPTH, (NVME_AQ_DEPTH / 4));\n\tif (ret)\n\t\tgoto out_delete_hw_queue;\n\n\tret = nvmf_connect_admin_queue(&ctrl->ctrl);\n\tif (ret)\n\t\tgoto out_disconnect_admin_queue;\n\n\tset_bit(NVME_FC_Q_LIVE, &ctrl->queues[0].flags);\n\n\t \n\n\tret = nvme_enable_ctrl(&ctrl->ctrl);\n\tif (!ret && test_bit(ASSOC_FAILED, &ctrl->flags))\n\t\tret = -EIO;\n\tif (ret)\n\t\tgoto out_disconnect_admin_queue;\n\n\tctrl->ctrl.max_segments = ctrl->lport->ops->max_sgl_segments;\n\tctrl->ctrl.max_hw_sectors = ctrl->ctrl.max_segments <<\n\t\t\t\t\t\t(ilog2(SZ_4K) - 9);\n\n\tnvme_unquiesce_admin_queue(&ctrl->ctrl);\n\n\tret = nvme_init_ctrl_finish(&ctrl->ctrl, false);\n\tif (!ret && test_bit(ASSOC_FAILED, &ctrl->flags))\n\t\tret = -EIO;\n\tif (ret)\n\t\tgoto out_disconnect_admin_queue;\n\n\t \n\n\t \n\tif (ctrl->ctrl.icdoff) {\n\t\tdev_err(ctrl->ctrl.device, \"icdoff %d is not supported!\\n\",\n\t\t\t\tctrl->ctrl.icdoff);\n\t\tret = NVME_SC_INVALID_FIELD | NVME_SC_DNR;\n\t\tgoto out_disconnect_admin_queue;\n\t}\n\n\t \n\tif (!nvme_ctrl_sgl_supported(&ctrl->ctrl)) {\n\t\tdev_err(ctrl->ctrl.device,\n\t\t\t\"Mandatory sgls are not supported!\\n\");\n\t\tret = NVME_SC_INVALID_FIELD | NVME_SC_DNR;\n\t\tgoto out_disconnect_admin_queue;\n\t}\n\n\tif (opts->queue_size > ctrl->ctrl.maxcmd) {\n\t\t \n\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\"queue_size %zu > ctrl maxcmd %u, reducing \"\n\t\t\t\"to maxcmd\\n\",\n\t\t\topts->queue_size, ctrl->ctrl.maxcmd);\n\t\topts->queue_size = ctrl->ctrl.maxcmd;\n\t\tctrl->ctrl.sqsize = opts->queue_size - 1;\n\t}\n\n\tret = nvme_fc_init_aen_ops(ctrl);\n\tif (ret)\n\t\tgoto out_term_aen_ops;\n\n\t \n\n\tif (ctrl->ctrl.queue_count > 1) {\n\t\tif (!ctrl->ioq_live)\n\t\t\tret = nvme_fc_create_io_queues(ctrl);\n\t\telse\n\t\t\tret = nvme_fc_recreate_io_queues(ctrl);\n\t}\n\tif (!ret && test_bit(ASSOC_FAILED, &ctrl->flags))\n\t\tret = -EIO;\n\tif (ret)\n\t\tgoto out_term_aen_ops;\n\n\tchanged = nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_LIVE);\n\n\tctrl->ctrl.nr_reconnects = 0;\n\n\tif (changed)\n\t\tnvme_start_ctrl(&ctrl->ctrl);\n\n\treturn 0;\t \n\nout_term_aen_ops:\n\tnvme_fc_term_aen_ops(ctrl);\nout_disconnect_admin_queue:\n\tdev_warn(ctrl->ctrl.device,\n\t\t\"NVME-FC{%d}: create_assoc failed, assoc_id %llx ret %d\\n\",\n\t\tctrl->cnum, ctrl->association_id, ret);\n\t \n\tnvme_fc_xmt_disconnect_assoc(ctrl);\n\tspin_lock_irqsave(&ctrl->lock, flags);\n\tctrl->association_id = 0;\n\tdisls = ctrl->rcv_disconn;\n\tctrl->rcv_disconn = NULL;\n\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\tif (disls)\n\t\tnvme_fc_xmt_ls_rsp(disls);\nout_delete_hw_queue:\n\t__nvme_fc_delete_hw_queue(ctrl, &ctrl->queues[0], 0);\nout_free_queue:\n\tnvme_fc_free_queue(&ctrl->queues[0]);\n\tclear_bit(ASSOC_ACTIVE, &ctrl->flags);\n\tnvme_fc_ctlr_inactive_on_rport(ctrl);\n\n\treturn ret;\n}\n\n\n \nstatic void\nnvme_fc_delete_association(struct nvme_fc_ctrl *ctrl)\n{\n\tstruct nvmefc_ls_rcv_op *disls = NULL;\n\tunsigned long flags;\n\n\tif (!test_and_clear_bit(ASSOC_ACTIVE, &ctrl->flags))\n\t\treturn;\n\n\tspin_lock_irqsave(&ctrl->lock, flags);\n\tset_bit(FCCTRL_TERMIO, &ctrl->flags);\n\tctrl->iocnt = 0;\n\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\n\t__nvme_fc_abort_outstanding_ios(ctrl, false);\n\n\t \n\tnvme_fc_abort_aen_ops(ctrl);\n\n\t \n\tspin_lock_irq(&ctrl->lock);\n\twait_event_lock_irq(ctrl->ioabort_wait, ctrl->iocnt == 0, ctrl->lock);\n\tclear_bit(FCCTRL_TERMIO, &ctrl->flags);\n\tspin_unlock_irq(&ctrl->lock);\n\n\tnvme_fc_term_aen_ops(ctrl);\n\n\t \n\tif (ctrl->association_id)\n\t\tnvme_fc_xmt_disconnect_assoc(ctrl);\n\n\tspin_lock_irqsave(&ctrl->lock, flags);\n\tctrl->association_id = 0;\n\tdisls = ctrl->rcv_disconn;\n\tctrl->rcv_disconn = NULL;\n\tspin_unlock_irqrestore(&ctrl->lock, flags);\n\tif (disls)\n\t\t \n\t\tnvme_fc_xmt_ls_rsp(disls);\n\n\tif (ctrl->ctrl.tagset) {\n\t\tnvme_fc_delete_hw_io_queues(ctrl);\n\t\tnvme_fc_free_io_queues(ctrl);\n\t}\n\n\t__nvme_fc_delete_hw_queue(ctrl, &ctrl->queues[0], 0);\n\tnvme_fc_free_queue(&ctrl->queues[0]);\n\n\t \n\tnvme_unquiesce_admin_queue(&ctrl->ctrl);\n\n\t \n\tnvme_unquiesce_io_queues(&ctrl->ctrl);\n\n\tnvme_fc_ctlr_inactive_on_rport(ctrl);\n}\n\nstatic void\nnvme_fc_delete_ctrl(struct nvme_ctrl *nctrl)\n{\n\tstruct nvme_fc_ctrl *ctrl = to_fc_ctrl(nctrl);\n\n\tcancel_work_sync(&ctrl->ioerr_work);\n\tcancel_delayed_work_sync(&ctrl->connect_work);\n\t \n\tnvme_fc_delete_association(ctrl);\n}\n\nstatic void\nnvme_fc_reconnect_or_delete(struct nvme_fc_ctrl *ctrl, int status)\n{\n\tstruct nvme_fc_rport *rport = ctrl->rport;\n\tstruct nvme_fc_remote_port *portptr = &rport->remoteport;\n\tunsigned long recon_delay = ctrl->ctrl.opts->reconnect_delay * HZ;\n\tbool recon = true;\n\n\tif (nvme_ctrl_state(&ctrl->ctrl) != NVME_CTRL_CONNECTING)\n\t\treturn;\n\n\tif (portptr->port_state == FC_OBJSTATE_ONLINE) {\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: reset: Reconnect attempt failed (%d)\\n\",\n\t\t\tctrl->cnum, status);\n\t\tif (status > 0 && (status & NVME_SC_DNR))\n\t\t\trecon = false;\n\t} else if (time_after_eq(jiffies, rport->dev_loss_end))\n\t\trecon = false;\n\n\tif (recon && nvmf_should_reconnect(&ctrl->ctrl)) {\n\t\tif (portptr->port_state == FC_OBJSTATE_ONLINE)\n\t\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\t\"NVME-FC{%d}: Reconnect attempt in %ld \"\n\t\t\t\t\"seconds\\n\",\n\t\t\t\tctrl->cnum, recon_delay / HZ);\n\t\telse if (time_after(jiffies + recon_delay, rport->dev_loss_end))\n\t\t\trecon_delay = rport->dev_loss_end - jiffies;\n\n\t\tqueue_delayed_work(nvme_wq, &ctrl->connect_work, recon_delay);\n\t} else {\n\t\tif (portptr->port_state == FC_OBJSTATE_ONLINE) {\n\t\t\tif (status > 0 && (status & NVME_SC_DNR))\n\t\t\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\t\t \"NVME-FC{%d}: reconnect failure\\n\",\n\t\t\t\t\t ctrl->cnum);\n\t\t\telse\n\t\t\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\t\t \"NVME-FC{%d}: Max reconnect attempts \"\n\t\t\t\t\t \"(%d) reached.\\n\",\n\t\t\t\t\t ctrl->cnum, ctrl->ctrl.nr_reconnects);\n\t\t} else\n\t\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\t\"NVME-FC{%d}: dev_loss_tmo (%d) expired \"\n\t\t\t\t\"while waiting for remoteport connectivity.\\n\",\n\t\t\t\tctrl->cnum, min_t(int, portptr->dev_loss_tmo,\n\t\t\t\t\t(ctrl->ctrl.opts->max_reconnects *\n\t\t\t\t\t ctrl->ctrl.opts->reconnect_delay)));\n\t\tWARN_ON(nvme_delete_ctrl(&ctrl->ctrl));\n\t}\n}\n\nstatic void\nnvme_fc_reset_ctrl_work(struct work_struct *work)\n{\n\tstruct nvme_fc_ctrl *ctrl =\n\t\tcontainer_of(work, struct nvme_fc_ctrl, ctrl.reset_work);\n\n\tnvme_stop_ctrl(&ctrl->ctrl);\n\n\t \n\tnvme_fc_delete_association(ctrl);\n\n\tif (!nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_CONNECTING))\n\t\tdev_err(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: error_recovery: Couldn't change state \"\n\t\t\t\"to CONNECTING\\n\", ctrl->cnum);\n\n\tif (ctrl->rport->remoteport.port_state == FC_OBJSTATE_ONLINE) {\n\t\tif (!queue_delayed_work(nvme_wq, &ctrl->connect_work, 0)) {\n\t\t\tdev_err(ctrl->ctrl.device,\n\t\t\t\t\"NVME-FC{%d}: failed to schedule connect \"\n\t\t\t\t\"after reset\\n\", ctrl->cnum);\n\t\t} else {\n\t\t\tflush_delayed_work(&ctrl->connect_work);\n\t\t}\n\t} else {\n\t\tnvme_fc_reconnect_or_delete(ctrl, -ENOTCONN);\n\t}\n}\n\n\nstatic const struct nvme_ctrl_ops nvme_fc_ctrl_ops = {\n\t.name\t\t\t= \"fc\",\n\t.module\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= NVME_F_FABRICS,\n\t.reg_read32\t\t= nvmf_reg_read32,\n\t.reg_read64\t\t= nvmf_reg_read64,\n\t.reg_write32\t\t= nvmf_reg_write32,\n\t.free_ctrl\t\t= nvme_fc_nvme_ctrl_freed,\n\t.submit_async_event\t= nvme_fc_submit_async_event,\n\t.delete_ctrl\t\t= nvme_fc_delete_ctrl,\n\t.get_address\t\t= nvmf_get_address,\n};\n\nstatic void\nnvme_fc_connect_ctrl_work(struct work_struct *work)\n{\n\tint ret;\n\n\tstruct nvme_fc_ctrl *ctrl =\n\t\t\tcontainer_of(to_delayed_work(work),\n\t\t\t\tstruct nvme_fc_ctrl, connect_work);\n\n\tret = nvme_fc_create_association(ctrl);\n\tif (ret)\n\t\tnvme_fc_reconnect_or_delete(ctrl, ret);\n\telse\n\t\tdev_info(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: controller connect complete\\n\",\n\t\t\tctrl->cnum);\n}\n\n\nstatic const struct blk_mq_ops nvme_fc_admin_mq_ops = {\n\t.queue_rq\t= nvme_fc_queue_rq,\n\t.complete\t= nvme_fc_complete_rq,\n\t.init_request\t= nvme_fc_init_request,\n\t.exit_request\t= nvme_fc_exit_request,\n\t.init_hctx\t= nvme_fc_init_admin_hctx,\n\t.timeout\t= nvme_fc_timeout,\n};\n\n\n \nstatic bool\nnvme_fc_existing_controller(struct nvme_fc_rport *rport,\n\t\tstruct nvmf_ctrl_options *opts)\n{\n\tstruct nvme_fc_ctrl *ctrl;\n\tunsigned long flags;\n\tbool found = false;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\tlist_for_each_entry(ctrl, &rport->ctrl_list, ctrl_list) {\n\t\tfound = nvmf_ctlr_matches_baseopts(&ctrl->ctrl, opts);\n\t\tif (found)\n\t\t\tbreak;\n\t}\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\treturn found;\n}\n\nstatic struct nvme_ctrl *\nnvme_fc_init_ctrl(struct device *dev, struct nvmf_ctrl_options *opts,\n\tstruct nvme_fc_lport *lport, struct nvme_fc_rport *rport)\n{\n\tstruct nvme_fc_ctrl *ctrl;\n\tunsigned long flags;\n\tint ret, idx, ctrl_loss_tmo;\n\n\tif (!(rport->remoteport.port_role &\n\t    (FC_PORT_ROLE_NVME_DISCOVERY | FC_PORT_ROLE_NVME_TARGET))) {\n\t\tret = -EBADR;\n\t\tgoto out_fail;\n\t}\n\n\tif (!opts->duplicate_connect &&\n\t    nvme_fc_existing_controller(rport, opts)) {\n\t\tret = -EALREADY;\n\t\tgoto out_fail;\n\t}\n\n\tctrl = kzalloc(sizeof(*ctrl), GFP_KERNEL);\n\tif (!ctrl) {\n\t\tret = -ENOMEM;\n\t\tgoto out_fail;\n\t}\n\n\tidx = ida_alloc(&nvme_fc_ctrl_cnt, GFP_KERNEL);\n\tif (idx < 0) {\n\t\tret = -ENOSPC;\n\t\tgoto out_free_ctrl;\n\t}\n\n\t \n\tif (opts->max_reconnects != -1 &&\n\t    opts->reconnect_delay == NVMF_DEF_RECONNECT_DELAY &&\n\t    opts->reconnect_delay > NVME_FC_DEFAULT_RECONNECT_TMO) {\n\t\tctrl_loss_tmo = opts->max_reconnects * opts->reconnect_delay;\n\t\topts->reconnect_delay = NVME_FC_DEFAULT_RECONNECT_TMO;\n\t\topts->max_reconnects = DIV_ROUND_UP(ctrl_loss_tmo,\n\t\t\t\t\t\topts->reconnect_delay);\n\t}\n\n\tctrl->ctrl.opts = opts;\n\tctrl->ctrl.nr_reconnects = 0;\n\tif (lport->dev)\n\t\tctrl->ctrl.numa_node = dev_to_node(lport->dev);\n\telse\n\t\tctrl->ctrl.numa_node = NUMA_NO_NODE;\n\tINIT_LIST_HEAD(&ctrl->ctrl_list);\n\tctrl->lport = lport;\n\tctrl->rport = rport;\n\tctrl->dev = lport->dev;\n\tctrl->cnum = idx;\n\tctrl->ioq_live = false;\n\tinit_waitqueue_head(&ctrl->ioabort_wait);\n\n\tget_device(ctrl->dev);\n\tkref_init(&ctrl->ref);\n\n\tINIT_WORK(&ctrl->ctrl.reset_work, nvme_fc_reset_ctrl_work);\n\tINIT_DELAYED_WORK(&ctrl->connect_work, nvme_fc_connect_ctrl_work);\n\tINIT_WORK(&ctrl->ioerr_work, nvme_fc_ctrl_ioerr_work);\n\tspin_lock_init(&ctrl->lock);\n\n\t \n\tctrl->ctrl.queue_count = min_t(unsigned int,\n\t\t\t\topts->nr_io_queues,\n\t\t\t\tlport->ops->max_hw_queues);\n\tctrl->ctrl.queue_count++;\t \n\n\tctrl->ctrl.sqsize = opts->queue_size - 1;\n\tctrl->ctrl.kato = opts->kato;\n\tctrl->ctrl.cntlid = 0xffff;\n\n\tret = -ENOMEM;\n\tctrl->queues = kcalloc(ctrl->ctrl.queue_count,\n\t\t\t\tsizeof(struct nvme_fc_queue), GFP_KERNEL);\n\tif (!ctrl->queues)\n\t\tgoto out_free_ida;\n\n\tnvme_fc_init_queue(ctrl, 0);\n\n\t \n\n\tret = nvme_init_ctrl(&ctrl->ctrl, dev, &nvme_fc_ctrl_ops, 0);\n\tif (ret)\n\t\tgoto out_free_queues;\n\n\t \n\n\tret = nvme_alloc_admin_tag_set(&ctrl->ctrl, &ctrl->admin_tag_set,\n\t\t\t&nvme_fc_admin_mq_ops,\n\t\t\tstruct_size_t(struct nvme_fcp_op_w_sgl, priv,\n\t\t\t\t      ctrl->lport->ops->fcprqst_priv_sz));\n\tif (ret)\n\t\tgoto fail_ctrl;\n\n\tspin_lock_irqsave(&rport->lock, flags);\n\tlist_add_tail(&ctrl->ctrl_list, &rport->ctrl_list);\n\tspin_unlock_irqrestore(&rport->lock, flags);\n\n\tif (!nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_RESETTING) ||\n\t    !nvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_CONNECTING)) {\n\t\tdev_err(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: failed to init ctrl state\\n\", ctrl->cnum);\n\t\tgoto fail_ctrl;\n\t}\n\n\tif (!queue_delayed_work(nvme_wq, &ctrl->connect_work, 0)) {\n\t\tdev_err(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: failed to schedule initial connect\\n\",\n\t\t\tctrl->cnum);\n\t\tgoto fail_ctrl;\n\t}\n\n\tflush_delayed_work(&ctrl->connect_work);\n\n\tdev_info(ctrl->ctrl.device,\n\t\t\"NVME-FC{%d}: new ctrl: NQN \\\"%s\\\"\\n\",\n\t\tctrl->cnum, nvmf_ctrl_subsysnqn(&ctrl->ctrl));\n\n\treturn &ctrl->ctrl;\n\nfail_ctrl:\n\tnvme_change_ctrl_state(&ctrl->ctrl, NVME_CTRL_DELETING);\n\tcancel_work_sync(&ctrl->ioerr_work);\n\tcancel_work_sync(&ctrl->ctrl.reset_work);\n\tcancel_delayed_work_sync(&ctrl->connect_work);\n\n\tctrl->ctrl.opts = NULL;\n\n\t \n\tnvme_uninit_ctrl(&ctrl->ctrl);\n\n\t \n\tnvme_put_ctrl(&ctrl->ctrl);\n\n\t \n\tnvme_fc_rport_get(rport);\n\n\treturn ERR_PTR(-EIO);\n\nout_free_queues:\n\tkfree(ctrl->queues);\nout_free_ida:\n\tput_device(ctrl->dev);\n\tida_free(&nvme_fc_ctrl_cnt, ctrl->cnum);\nout_free_ctrl:\n\tkfree(ctrl);\nout_fail:\n\t \n\treturn ERR_PTR(ret);\n}\n\n\nstruct nvmet_fc_traddr {\n\tu64\tnn;\n\tu64\tpn;\n};\n\nstatic int\n__nvme_fc_parse_u64(substring_t *sstr, u64 *val)\n{\n\tu64 token64;\n\n\tif (match_u64(sstr, &token64))\n\t\treturn -EINVAL;\n\t*val = token64;\n\n\treturn 0;\n}\n\n \nstatic int\nnvme_fc_parse_traddr(struct nvmet_fc_traddr *traddr, char *buf, size_t blen)\n{\n\tchar name[2 + NVME_FC_TRADDR_HEXNAMELEN + 1];\n\tsubstring_t wwn = { name, &name[sizeof(name)-1] };\n\tint nnoffset, pnoffset;\n\n\t \n\tif (strnlen(buf, blen) == NVME_FC_TRADDR_MAXLENGTH &&\n\t\t\t!strncmp(buf, \"nn-0x\", NVME_FC_TRADDR_OXNNLEN) &&\n\t\t\t!strncmp(&buf[NVME_FC_TRADDR_MAX_PN_OFFSET],\n\t\t\t\t\"pn-0x\", NVME_FC_TRADDR_OXNNLEN)) {\n\t\tnnoffset = NVME_FC_TRADDR_OXNNLEN;\n\t\tpnoffset = NVME_FC_TRADDR_MAX_PN_OFFSET +\n\t\t\t\t\t\tNVME_FC_TRADDR_OXNNLEN;\n\t} else if ((strnlen(buf, blen) == NVME_FC_TRADDR_MINLENGTH &&\n\t\t\t!strncmp(buf, \"nn-\", NVME_FC_TRADDR_NNLEN) &&\n\t\t\t!strncmp(&buf[NVME_FC_TRADDR_MIN_PN_OFFSET],\n\t\t\t\t\"pn-\", NVME_FC_TRADDR_NNLEN))) {\n\t\tnnoffset = NVME_FC_TRADDR_NNLEN;\n\t\tpnoffset = NVME_FC_TRADDR_MIN_PN_OFFSET + NVME_FC_TRADDR_NNLEN;\n\t} else\n\t\tgoto out_einval;\n\n\tname[0] = '0';\n\tname[1] = 'x';\n\tname[2 + NVME_FC_TRADDR_HEXNAMELEN] = 0;\n\n\tmemcpy(&name[2], &buf[nnoffset], NVME_FC_TRADDR_HEXNAMELEN);\n\tif (__nvme_fc_parse_u64(&wwn, &traddr->nn))\n\t\tgoto out_einval;\n\n\tmemcpy(&name[2], &buf[pnoffset], NVME_FC_TRADDR_HEXNAMELEN);\n\tif (__nvme_fc_parse_u64(&wwn, &traddr->pn))\n\t\tgoto out_einval;\n\n\treturn 0;\n\nout_einval:\n\tpr_warn(\"%s: bad traddr string\\n\", __func__);\n\treturn -EINVAL;\n}\n\nstatic struct nvme_ctrl *\nnvme_fc_create_ctrl(struct device *dev, struct nvmf_ctrl_options *opts)\n{\n\tstruct nvme_fc_lport *lport;\n\tstruct nvme_fc_rport *rport;\n\tstruct nvme_ctrl *ctrl;\n\tstruct nvmet_fc_traddr laddr = { 0L, 0L };\n\tstruct nvmet_fc_traddr raddr = { 0L, 0L };\n\tunsigned long flags;\n\tint ret;\n\n\tret = nvme_fc_parse_traddr(&raddr, opts->traddr, NVMF_TRADDR_SIZE);\n\tif (ret || !raddr.nn || !raddr.pn)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tret = nvme_fc_parse_traddr(&laddr, opts->host_traddr, NVMF_TRADDR_SIZE);\n\tif (ret || !laddr.nn || !laddr.pn)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t \n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\tlist_for_each_entry(lport, &nvme_fc_lport_list, port_list) {\n\t\tif (lport->localport.node_name != laddr.nn ||\n\t\t    lport->localport.port_name != laddr.pn ||\n\t\t    lport->localport.port_state != FC_OBJSTATE_ONLINE)\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry(rport, &lport->endp_list, endp_list) {\n\t\t\tif (rport->remoteport.node_name != raddr.nn ||\n\t\t\t    rport->remoteport.port_name != raddr.pn ||\n\t\t\t    rport->remoteport.port_state != FC_OBJSTATE_ONLINE)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (!nvme_fc_rport_get(rport))\n\t\t\t\tbreak;\n\n\t\t\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\t\t\tctrl = nvme_fc_init_ctrl(dev, opts, lport, rport);\n\t\t\tif (IS_ERR(ctrl))\n\t\t\t\tnvme_fc_rport_put(rport);\n\t\t\treturn ctrl;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\tpr_warn(\"%s: %s - %s combination not found\\n\",\n\t\t__func__, opts->traddr, opts->host_traddr);\n\treturn ERR_PTR(-ENOENT);\n}\n\n\nstatic struct nvmf_transport_ops nvme_fc_transport = {\n\t.name\t\t= \"fc\",\n\t.module\t\t= THIS_MODULE,\n\t.required_opts\t= NVMF_OPT_TRADDR | NVMF_OPT_HOST_TRADDR,\n\t.allowed_opts\t= NVMF_OPT_RECONNECT_DELAY | NVMF_OPT_CTRL_LOSS_TMO,\n\t.create_ctrl\t= nvme_fc_create_ctrl,\n};\n\n \n#define DISCOVERY_MAX_FAIL\t20\n\nstatic ssize_t nvme_fc_nvme_discovery_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tunsigned long flags;\n\tLIST_HEAD(local_disc_list);\n\tstruct nvme_fc_lport *lport;\n\tstruct nvme_fc_rport *rport;\n\tint failcnt = 0;\n\n\tspin_lock_irqsave(&nvme_fc_lock, flags);\nrestart:\n\tlist_for_each_entry(lport, &nvme_fc_lport_list, port_list) {\n\t\tlist_for_each_entry(rport, &lport->endp_list, endp_list) {\n\t\t\tif (!nvme_fc_lport_get(lport))\n\t\t\t\tcontinue;\n\t\t\tif (!nvme_fc_rport_get(rport)) {\n\t\t\t\t \n\t\t\t\tnvme_fc_lport_put(lport);\n\n\t\t\t\tif (failcnt++ < DISCOVERY_MAX_FAIL)\n\t\t\t\t\tgoto restart;\n\n\t\t\t\tpr_err(\"nvme_discovery: too many reference \"\n\t\t\t\t       \"failures\\n\");\n\t\t\t\tgoto process_local_list;\n\t\t\t}\n\t\t\tif (list_empty(&rport->disc_list))\n\t\t\t\tlist_add_tail(&rport->disc_list,\n\t\t\t\t\t      &local_disc_list);\n\t\t}\n\t}\n\nprocess_local_list:\n\twhile (!list_empty(&local_disc_list)) {\n\t\trport = list_first_entry(&local_disc_list,\n\t\t\t\t\t struct nvme_fc_rport, disc_list);\n\t\tlist_del_init(&rport->disc_list);\n\t\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\t\tlport = rport->lport;\n\t\t \n\t\tnvme_fc_signal_discovery_scan(lport, rport);\n\t\tnvme_fc_rport_put(rport);\n\t\tnvme_fc_lport_put(lport);\n\n\t\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\t}\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\n\treturn count;\n}\n\nstatic DEVICE_ATTR(nvme_discovery, 0200, NULL, nvme_fc_nvme_discovery_store);\n\n#ifdef CONFIG_BLK_CGROUP_FC_APPID\n \nstatic int fc_parse_cgrpid(const char *buf, u64 *id)\n{\n\tchar cgrp_id[16+1];\n\tint cgrpid_len, j;\n\n\tmemset(cgrp_id, 0x0, sizeof(cgrp_id));\n\tfor (cgrpid_len = 0, j = 0; cgrpid_len < 17; cgrpid_len++) {\n\t\tif (buf[cgrpid_len] != ':')\n\t\t\tcgrp_id[cgrpid_len] = buf[cgrpid_len];\n\t\telse {\n\t\t\tj = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!j)\n\t\treturn -EINVAL;\n\tif (kstrtou64(cgrp_id, 16, id) < 0)\n\t\treturn -EINVAL;\n\treturn cgrpid_len;\n}\n\n \nstatic ssize_t fc_appid_store(struct device *dev,\n\t\tstruct device_attribute *attr, const char *buf, size_t count)\n{\n\tsize_t orig_count = count;\n\tu64 cgrp_id;\n\tint appid_len = 0;\n\tint cgrpid_len = 0;\n\tchar app_id[FC_APPID_LEN];\n\tint ret = 0;\n\n\tif (buf[count-1] == '\\n')\n\t\tcount--;\n\n\tif ((count > (16+1+FC_APPID_LEN)) || (!strchr(buf, ':')))\n\t\treturn -EINVAL;\n\n\tcgrpid_len = fc_parse_cgrpid(buf, &cgrp_id);\n\tif (cgrpid_len < 0)\n\t\treturn -EINVAL;\n\tappid_len = count - cgrpid_len - 1;\n\tif (appid_len > FC_APPID_LEN)\n\t\treturn -EINVAL;\n\n\tmemset(app_id, 0x0, sizeof(app_id));\n\tmemcpy(app_id, &buf[cgrpid_len+1], appid_len);\n\tret = blkcg_set_fc_appid(app_id, cgrp_id, sizeof(app_id));\n\tif (ret < 0)\n\t\treturn ret;\n\treturn orig_count;\n}\nstatic DEVICE_ATTR(appid_store, 0200, NULL, fc_appid_store);\n#endif  \n\nstatic struct attribute *nvme_fc_attrs[] = {\n\t&dev_attr_nvme_discovery.attr,\n#ifdef CONFIG_BLK_CGROUP_FC_APPID\n\t&dev_attr_appid_store.attr,\n#endif\n\tNULL\n};\n\nstatic const struct attribute_group nvme_fc_attr_group = {\n\t.attrs = nvme_fc_attrs,\n};\n\nstatic const struct attribute_group *nvme_fc_attr_groups[] = {\n\t&nvme_fc_attr_group,\n\tNULL\n};\n\nstatic struct class fc_class = {\n\t.name = \"fc\",\n\t.dev_groups = nvme_fc_attr_groups,\n};\n\nstatic int __init nvme_fc_init_module(void)\n{\n\tint ret;\n\n\tnvme_fc_wq = alloc_workqueue(\"nvme_fc_wq\", WQ_MEM_RECLAIM, 0);\n\tif (!nvme_fc_wq)\n\t\treturn -ENOMEM;\n\n\t \n\tret = class_register(&fc_class);\n\tif (ret) {\n\t\tpr_err(\"couldn't register class fc\\n\");\n\t\tgoto out_destroy_wq;\n\t}\n\n\t \n\tfc_udev_device = device_create(&fc_class, NULL, MKDEV(0, 0), NULL,\n\t\t\t\t\"fc_udev_device\");\n\tif (IS_ERR(fc_udev_device)) {\n\t\tpr_err(\"couldn't create fc_udev device!\\n\");\n\t\tret = PTR_ERR(fc_udev_device);\n\t\tgoto out_destroy_class;\n\t}\n\n\tret = nvmf_register_transport(&nvme_fc_transport);\n\tif (ret)\n\t\tgoto out_destroy_device;\n\n\treturn 0;\n\nout_destroy_device:\n\tdevice_destroy(&fc_class, MKDEV(0, 0));\nout_destroy_class:\n\tclass_unregister(&fc_class);\nout_destroy_wq:\n\tdestroy_workqueue(nvme_fc_wq);\n\n\treturn ret;\n}\n\nstatic void\nnvme_fc_delete_controllers(struct nvme_fc_rport *rport)\n{\n\tstruct nvme_fc_ctrl *ctrl;\n\n\tspin_lock(&rport->lock);\n\tlist_for_each_entry(ctrl, &rport->ctrl_list, ctrl_list) {\n\t\tdev_warn(ctrl->ctrl.device,\n\t\t\t\"NVME-FC{%d}: transport unloading: deleting ctrl\\n\",\n\t\t\tctrl->cnum);\n\t\tnvme_delete_ctrl(&ctrl->ctrl);\n\t}\n\tspin_unlock(&rport->lock);\n}\n\nstatic void\nnvme_fc_cleanup_for_unload(void)\n{\n\tstruct nvme_fc_lport *lport;\n\tstruct nvme_fc_rport *rport;\n\n\tlist_for_each_entry(lport, &nvme_fc_lport_list, port_list) {\n\t\tlist_for_each_entry(rport, &lport->endp_list, endp_list) {\n\t\t\tnvme_fc_delete_controllers(rport);\n\t\t}\n\t}\n}\n\nstatic void __exit nvme_fc_exit_module(void)\n{\n\tunsigned long flags;\n\tbool need_cleanup = false;\n\n\tspin_lock_irqsave(&nvme_fc_lock, flags);\n\tnvme_fc_waiting_to_unload = true;\n\tif (!list_empty(&nvme_fc_lport_list)) {\n\t\tneed_cleanup = true;\n\t\tnvme_fc_cleanup_for_unload();\n\t}\n\tspin_unlock_irqrestore(&nvme_fc_lock, flags);\n\tif (need_cleanup) {\n\t\tpr_info(\"%s: waiting for ctlr deletes\\n\", __func__);\n\t\twait_for_completion(&nvme_fc_unload_proceed);\n\t\tpr_info(\"%s: ctrl deletes complete\\n\", __func__);\n\t}\n\n\tnvmf_unregister_transport(&nvme_fc_transport);\n\n\tida_destroy(&nvme_fc_local_port_cnt);\n\tida_destroy(&nvme_fc_ctrl_cnt);\n\n\tdevice_destroy(&fc_class, MKDEV(0, 0));\n\tclass_unregister(&fc_class);\n\tdestroy_workqueue(nvme_fc_wq);\n}\n\nmodule_init(nvme_fc_init_module);\nmodule_exit(nvme_fc_exit_module);\n\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}