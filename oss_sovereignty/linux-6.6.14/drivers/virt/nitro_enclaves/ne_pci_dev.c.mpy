{
  "module_name": "ne_pci_dev.c",
  "hash_id": "b662332f245d3de17c7b5656292c7f0c1cbac524bf454b466cb3062e78a93f9f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/virt/nitro_enclaves/ne_pci_dev.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/delay.h>\n#include <linux/device.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/nitro_enclaves.h>\n#include <linux/pci.h>\n#include <linux/types.h>\n#include <linux/wait.h>\n\n#include \"ne_misc_dev.h\"\n#include \"ne_pci_dev.h\"\n\n \n#define NE_DEFAULT_TIMEOUT_MSECS\t(120000)  \n\nstatic const struct pci_device_id ne_pci_ids[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_AMAZON, PCI_DEVICE_ID_NE) },\n\t{ 0, }\n};\n\nMODULE_DEVICE_TABLE(pci, ne_pci_ids);\n\n \nstatic void ne_submit_request(struct pci_dev *pdev, enum ne_pci_dev_cmd_type cmd_type,\n\t\t\t      void *cmd_request, size_t cmd_request_size)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\n\tmemcpy_toio(ne_pci_dev->iomem_base + NE_SEND_DATA, cmd_request, cmd_request_size);\n\n\tiowrite32(cmd_type, ne_pci_dev->iomem_base + NE_COMMAND);\n}\n\n \nstatic void ne_retrieve_reply(struct pci_dev *pdev, struct ne_pci_dev_cmd_reply *cmd_reply,\n\t\t\t      size_t cmd_reply_size)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\n\tmemcpy_fromio(cmd_reply, ne_pci_dev->iomem_base + NE_RECV_DATA, cmd_reply_size);\n}\n\n \nstatic int ne_wait_for_reply(struct pci_dev *pdev)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\tint rc = -EINVAL;\n\n\t \n\trc = wait_event_timeout(ne_pci_dev->cmd_reply_wait_q,\n\t\t\t\tatomic_read(&ne_pci_dev->cmd_reply_avail) != 0,\n\t\t\t\tmsecs_to_jiffies(NE_DEFAULT_TIMEOUT_MSECS));\n\tif (!rc)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nint ne_do_request(struct pci_dev *pdev, enum ne_pci_dev_cmd_type cmd_type,\n\t\t  void *cmd_request, size_t cmd_request_size,\n\t\t  struct ne_pci_dev_cmd_reply *cmd_reply, size_t cmd_reply_size)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\tint rc = -EINVAL;\n\n\tif (cmd_type <= INVALID_CMD || cmd_type >= MAX_CMD) {\n\t\tdev_err_ratelimited(&pdev->dev, \"Invalid cmd type=%u\\n\", cmd_type);\n\n\t\treturn -EINVAL;\n\t}\n\n\tif (!cmd_request) {\n\t\tdev_err_ratelimited(&pdev->dev, \"Null cmd request for cmd type=%u\\n\",\n\t\t\t\t    cmd_type);\n\n\t\treturn -EINVAL;\n\t}\n\n\tif (cmd_request_size > NE_SEND_DATA_SIZE) {\n\t\tdev_err_ratelimited(&pdev->dev, \"Invalid req size=%zu for cmd type=%u\\n\",\n\t\t\t\t    cmd_request_size, cmd_type);\n\n\t\treturn -EINVAL;\n\t}\n\n\tif (!cmd_reply) {\n\t\tdev_err_ratelimited(&pdev->dev, \"Null cmd reply for cmd type=%u\\n\",\n\t\t\t\t    cmd_type);\n\n\t\treturn -EINVAL;\n\t}\n\n\tif (cmd_reply_size > NE_RECV_DATA_SIZE) {\n\t\tdev_err_ratelimited(&pdev->dev, \"Invalid reply size=%zu for cmd type=%u\\n\",\n\t\t\t\t    cmd_reply_size, cmd_type);\n\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tmutex_lock(&ne_pci_dev->pci_dev_mutex);\n\n\tatomic_set(&ne_pci_dev->cmd_reply_avail, 0);\n\n\tne_submit_request(pdev, cmd_type, cmd_request, cmd_request_size);\n\n\trc = ne_wait_for_reply(pdev);\n\tif (rc < 0) {\n\t\tdev_err_ratelimited(&pdev->dev, \"Error in wait for reply for cmd type=%u [rc=%d]\\n\",\n\t\t\t\t    cmd_type, rc);\n\n\t\tgoto unlock_mutex;\n\t}\n\n\tne_retrieve_reply(pdev, cmd_reply, cmd_reply_size);\n\n\tatomic_set(&ne_pci_dev->cmd_reply_avail, 0);\n\n\tif (cmd_reply->rc < 0) {\n\t\trc = cmd_reply->rc;\n\n\t\tdev_err_ratelimited(&pdev->dev, \"Error in cmd process logic, cmd type=%u [rc=%d]\\n\",\n\t\t\t\t    cmd_type, rc);\n\n\t\tgoto unlock_mutex;\n\t}\n\n\trc = 0;\n\nunlock_mutex:\n\tmutex_unlock(&ne_pci_dev->pci_dev_mutex);\n\n\treturn rc;\n}\n\n \nstatic irqreturn_t ne_reply_handler(int irq, void *args)\n{\n\tstruct ne_pci_dev *ne_pci_dev = (struct ne_pci_dev *)args;\n\n\tatomic_set(&ne_pci_dev->cmd_reply_avail, 1);\n\n\t \n\twake_up(&ne_pci_dev->cmd_reply_wait_q);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic void ne_event_work_handler(struct work_struct *work)\n{\n\tstruct ne_pci_dev_cmd_reply cmd_reply = {};\n\tstruct ne_enclave *ne_enclave = NULL;\n\tstruct ne_pci_dev *ne_pci_dev =\n\t\tcontainer_of(work, struct ne_pci_dev, notify_work);\n\tstruct pci_dev *pdev = ne_pci_dev->pdev;\n\tint rc = -EINVAL;\n\tstruct slot_info_req slot_info_req = {};\n\n\tmutex_lock(&ne_pci_dev->enclaves_list_mutex);\n\n\t \n\tlist_for_each_entry(ne_enclave, &ne_pci_dev->enclaves_list, enclave_list_entry) {\n\t\tmutex_lock(&ne_enclave->enclave_info_mutex);\n\n\t\t \n\t\tif (ne_enclave->state != NE_STATE_RUNNING)\n\t\t\tgoto unlock;\n\n\t\tslot_info_req.slot_uid = ne_enclave->slot_uid;\n\n\t\trc = ne_do_request(pdev, SLOT_INFO,\n\t\t\t\t   &slot_info_req, sizeof(slot_info_req),\n\t\t\t\t   &cmd_reply, sizeof(cmd_reply));\n\t\tif (rc < 0)\n\t\t\tdev_err(&pdev->dev, \"Error in slot info [rc=%d]\\n\", rc);\n\n\t\t \n\t\tif (ne_enclave->state != cmd_reply.state) {\n\t\t\tne_enclave->state = cmd_reply.state;\n\n\t\t\tne_enclave->has_event = true;\n\n\t\t\twake_up_interruptible(&ne_enclave->eventq);\n\t\t}\n\nunlock:\n\t\t mutex_unlock(&ne_enclave->enclave_info_mutex);\n\t}\n\n\tmutex_unlock(&ne_pci_dev->enclaves_list_mutex);\n}\n\n \nstatic irqreturn_t ne_event_handler(int irq, void *args)\n{\n\tstruct ne_pci_dev *ne_pci_dev = (struct ne_pci_dev *)args;\n\n\tqueue_work(ne_pci_dev->event_wq, &ne_pci_dev->notify_work);\n\n\treturn IRQ_HANDLED;\n}\n\n \nstatic int ne_setup_msix(struct pci_dev *pdev)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\tint nr_vecs = 0;\n\tint rc = -EINVAL;\n\n\tnr_vecs = pci_msix_vec_count(pdev);\n\tif (nr_vecs < 0) {\n\t\trc = nr_vecs;\n\n\t\tdev_err(&pdev->dev, \"Error in getting vec count [rc=%d]\\n\", rc);\n\n\t\treturn rc;\n\t}\n\n\trc = pci_alloc_irq_vectors(pdev, nr_vecs, nr_vecs, PCI_IRQ_MSIX);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in alloc MSI-X vecs [rc=%d]\\n\", rc);\n\n\t\treturn rc;\n\t}\n\n\t \n\trc = request_irq(pci_irq_vector(pdev, NE_VEC_REPLY), ne_reply_handler,\n\t\t\t 0, \"enclave_cmd\", ne_pci_dev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in request irq reply [rc=%d]\\n\", rc);\n\n\t\tgoto free_irq_vectors;\n\t}\n\n\tne_pci_dev->event_wq = create_singlethread_workqueue(\"ne_pci_dev_wq\");\n\tif (!ne_pci_dev->event_wq) {\n\t\trc = -ENOMEM;\n\n\t\tdev_err(&pdev->dev, \"Cannot get wq for dev events [rc=%d]\\n\", rc);\n\n\t\tgoto free_reply_irq_vec;\n\t}\n\n\tINIT_WORK(&ne_pci_dev->notify_work, ne_event_work_handler);\n\n\t \n\trc = request_irq(pci_irq_vector(pdev, NE_VEC_EVENT), ne_event_handler,\n\t\t\t 0, \"enclave_evt\", ne_pci_dev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in request irq event [rc=%d]\\n\", rc);\n\n\t\tgoto destroy_wq;\n\t}\n\n\treturn 0;\n\ndestroy_wq:\n\tdestroy_workqueue(ne_pci_dev->event_wq);\nfree_reply_irq_vec:\n\tfree_irq(pci_irq_vector(pdev, NE_VEC_REPLY), ne_pci_dev);\nfree_irq_vectors:\n\tpci_free_irq_vectors(pdev);\n\n\treturn rc;\n}\n\n \nstatic void ne_teardown_msix(struct pci_dev *pdev)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\n\tfree_irq(pci_irq_vector(pdev, NE_VEC_EVENT), ne_pci_dev);\n\n\tflush_work(&ne_pci_dev->notify_work);\n\tdestroy_workqueue(ne_pci_dev->event_wq);\n\n\tfree_irq(pci_irq_vector(pdev, NE_VEC_REPLY), ne_pci_dev);\n\n\tpci_free_irq_vectors(pdev);\n}\n\n \nstatic int ne_pci_dev_enable(struct pci_dev *pdev)\n{\n\tu8 dev_enable_reply = 0;\n\tu16 dev_version_reply = 0;\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\n\tiowrite16(NE_VERSION_MAX, ne_pci_dev->iomem_base + NE_VERSION);\n\n\tdev_version_reply = ioread16(ne_pci_dev->iomem_base + NE_VERSION);\n\tif (dev_version_reply != NE_VERSION_MAX) {\n\t\tdev_err(&pdev->dev, \"Error in pci dev version cmd\\n\");\n\n\t\treturn -EIO;\n\t}\n\n\tiowrite8(NE_ENABLE_ON, ne_pci_dev->iomem_base + NE_ENABLE);\n\n\tdev_enable_reply = ioread8(ne_pci_dev->iomem_base + NE_ENABLE);\n\tif (dev_enable_reply != NE_ENABLE_ON) {\n\t\tdev_err(&pdev->dev, \"Error in pci dev enable cmd\\n\");\n\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void ne_pci_dev_disable(struct pci_dev *pdev)\n{\n\tu8 dev_disable_reply = 0;\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\tconst unsigned int sleep_time = 10;  \n\tunsigned int sleep_time_count = 0;\n\n\tiowrite8(NE_ENABLE_OFF, ne_pci_dev->iomem_base + NE_ENABLE);\n\n\t \n\twhile (sleep_time_count < NE_DEFAULT_TIMEOUT_MSECS) {\n\t\tdev_disable_reply = ioread8(ne_pci_dev->iomem_base + NE_ENABLE);\n\t\tif (dev_disable_reply == NE_ENABLE_OFF)\n\t\t\treturn;\n\n\t\tmsleep_interruptible(sleep_time);\n\t\tsleep_time_count += sleep_time;\n\t}\n\n\tdev_disable_reply = ioread8(ne_pci_dev->iomem_base + NE_ENABLE);\n\tif (dev_disable_reply != NE_ENABLE_OFF)\n\t\tdev_err(&pdev->dev, \"Error in pci dev disable cmd\\n\");\n}\n\n \nstatic int ne_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tstruct ne_pci_dev *ne_pci_dev = NULL;\n\tint rc = -EINVAL;\n\n\tne_pci_dev = kzalloc(sizeof(*ne_pci_dev), GFP_KERNEL);\n\tif (!ne_pci_dev)\n\t\treturn -ENOMEM;\n\n\trc = pci_enable_device(pdev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in pci dev enable [rc=%d]\\n\", rc);\n\n\t\tgoto free_ne_pci_dev;\n\t}\n\n\tpci_set_master(pdev);\n\n\trc = pci_request_regions_exclusive(pdev, \"nitro_enclaves\");\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in pci request regions [rc=%d]\\n\", rc);\n\n\t\tgoto disable_pci_dev;\n\t}\n\n\tne_pci_dev->iomem_base = pci_iomap(pdev, PCI_BAR_NE, 0);\n\tif (!ne_pci_dev->iomem_base) {\n\t\trc = -ENOMEM;\n\n\t\tdev_err(&pdev->dev, \"Error in pci iomap [rc=%d]\\n\", rc);\n\n\t\tgoto release_pci_regions;\n\t}\n\n\tpci_set_drvdata(pdev, ne_pci_dev);\n\n\trc = ne_setup_msix(pdev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in pci dev msix setup [rc=%d]\\n\", rc);\n\n\t\tgoto iounmap_pci_bar;\n\t}\n\n\tne_pci_dev_disable(pdev);\n\n\trc = ne_pci_dev_enable(pdev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in ne_pci_dev enable [rc=%d]\\n\", rc);\n\n\t\tgoto teardown_msix;\n\t}\n\n\tatomic_set(&ne_pci_dev->cmd_reply_avail, 0);\n\tinit_waitqueue_head(&ne_pci_dev->cmd_reply_wait_q);\n\tINIT_LIST_HEAD(&ne_pci_dev->enclaves_list);\n\tmutex_init(&ne_pci_dev->enclaves_list_mutex);\n\tmutex_init(&ne_pci_dev->pci_dev_mutex);\n\tne_pci_dev->pdev = pdev;\n\n\tne_devs.ne_pci_dev = ne_pci_dev;\n\n\trc = misc_register(ne_devs.ne_misc_dev);\n\tif (rc < 0) {\n\t\tdev_err(&pdev->dev, \"Error in misc dev register [rc=%d]\\n\", rc);\n\n\t\tgoto disable_ne_pci_dev;\n\t}\n\n\treturn 0;\n\ndisable_ne_pci_dev:\n\tne_devs.ne_pci_dev = NULL;\n\tne_pci_dev_disable(pdev);\nteardown_msix:\n\tne_teardown_msix(pdev);\niounmap_pci_bar:\n\tpci_set_drvdata(pdev, NULL);\n\tpci_iounmap(pdev, ne_pci_dev->iomem_base);\nrelease_pci_regions:\n\tpci_release_regions(pdev);\ndisable_pci_dev:\n\tpci_disable_device(pdev);\nfree_ne_pci_dev:\n\tkfree(ne_pci_dev);\n\n\treturn rc;\n}\n\n \nstatic void ne_pci_remove(struct pci_dev *pdev)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\n\tmisc_deregister(ne_devs.ne_misc_dev);\n\n\tne_devs.ne_pci_dev = NULL;\n\n\tne_pci_dev_disable(pdev);\n\n\tne_teardown_msix(pdev);\n\n\tpci_set_drvdata(pdev, NULL);\n\n\tpci_iounmap(pdev, ne_pci_dev->iomem_base);\n\n\tpci_release_regions(pdev);\n\n\tpci_disable_device(pdev);\n\n\tkfree(ne_pci_dev);\n}\n\n \nstatic void ne_pci_shutdown(struct pci_dev *pdev)\n{\n\tstruct ne_pci_dev *ne_pci_dev = pci_get_drvdata(pdev);\n\n\tif (!ne_pci_dev)\n\t\treturn;\n\n\tmisc_deregister(ne_devs.ne_misc_dev);\n\n\tne_devs.ne_pci_dev = NULL;\n\n\tne_pci_dev_disable(pdev);\n\n\tne_teardown_msix(pdev);\n\n\tpci_set_drvdata(pdev, NULL);\n\n\tpci_iounmap(pdev, ne_pci_dev->iomem_base);\n\n\tpci_release_regions(pdev);\n\n\tpci_disable_device(pdev);\n\n\tkfree(ne_pci_dev);\n}\n\n \n \nstruct pci_driver ne_pci_driver = {\n\t.name\t\t= \"nitro_enclaves\",\n\t.id_table\t= ne_pci_ids,\n\t.probe\t\t= ne_pci_probe,\n\t.remove\t\t= ne_pci_remove,\n\t.shutdown\t= ne_pci_shutdown,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}