{
  "module_name": "ioreq.c",
  "hash_id": "b2a1f0d186f3a974afcd555b5cb1671ef4813aad729ea54656b5503d77a779d8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/virt/acrn/ioreq.c",
  "human_readable_source": "\n \n\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/kthread.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n\n#include <asm/acrn.h>\n\n#include \"acrn_drv.h\"\n\nstatic void ioreq_pause(void);\nstatic void ioreq_resume(void);\n\nstatic void ioreq_dispatcher(struct work_struct *work);\nstatic struct workqueue_struct *ioreq_wq;\nstatic DECLARE_WORK(ioreq_work, ioreq_dispatcher);\n\nstatic inline bool has_pending_request(struct acrn_ioreq_client *client)\n{\n\treturn !bitmap_empty(client->ioreqs_map, ACRN_IO_REQUEST_MAX);\n}\n\nstatic inline bool is_destroying(struct acrn_ioreq_client *client)\n{\n\treturn test_bit(ACRN_IOREQ_CLIENT_DESTROYING, &client->flags);\n}\n\nstatic int ioreq_complete_request(struct acrn_vm *vm, u16 vcpu,\n\t\t\t\t  struct acrn_io_request *acrn_req)\n{\n\tbool polling_mode;\n\tint ret = 0;\n\n\tpolling_mode = acrn_req->completion_polling;\n\t \n\tsmp_store_release(&acrn_req->processed, ACRN_IOREQ_STATE_COMPLETE);\n\n\t \n\tif (!polling_mode) {\n\t\tret = hcall_notify_req_finish(vm->vmid, vcpu);\n\t\tif (ret < 0)\n\t\t\tdev_err(acrn_dev.this_device,\n\t\t\t\t\"Notify I/O request finished failed!\\n\");\n\t}\n\n\treturn ret;\n}\n\nstatic int acrn_ioreq_complete_request(struct acrn_ioreq_client *client,\n\t\t\t\t       u16 vcpu,\n\t\t\t\t       struct acrn_io_request *acrn_req)\n{\n\tint ret;\n\n\tif (vcpu >= client->vm->vcpu_num)\n\t\treturn -EINVAL;\n\n\tclear_bit(vcpu, client->ioreqs_map);\n\tif (!acrn_req) {\n\t\tacrn_req = (struct acrn_io_request *)client->vm->ioreq_buf;\n\t\tacrn_req += vcpu;\n\t}\n\n\tret = ioreq_complete_request(client->vm, vcpu, acrn_req);\n\n\treturn ret;\n}\n\nint acrn_ioreq_request_default_complete(struct acrn_vm *vm, u16 vcpu)\n{\n\tint ret = 0;\n\n\tspin_lock_bh(&vm->ioreq_clients_lock);\n\tif (vm->default_client)\n\t\tret = acrn_ioreq_complete_request(vm->default_client,\n\t\t\t\t\t\t  vcpu, NULL);\n\tspin_unlock_bh(&vm->ioreq_clients_lock);\n\n\treturn ret;\n}\n\n \nint acrn_ioreq_range_add(struct acrn_ioreq_client *client,\n\t\t\t u32 type, u64 start, u64 end)\n{\n\tstruct acrn_ioreq_range *range;\n\n\tif (end < start) {\n\t\tdev_err(acrn_dev.this_device,\n\t\t\t\"Invalid IO range [0x%llx,0x%llx]\\n\", start, end);\n\t\treturn -EINVAL;\n\t}\n\n\trange = kzalloc(sizeof(*range), GFP_KERNEL);\n\tif (!range)\n\t\treturn -ENOMEM;\n\n\trange->type = type;\n\trange->start = start;\n\trange->end = end;\n\n\twrite_lock_bh(&client->range_lock);\n\tlist_add(&range->list, &client->range_list);\n\twrite_unlock_bh(&client->range_lock);\n\n\treturn 0;\n}\n\n \nvoid acrn_ioreq_range_del(struct acrn_ioreq_client *client,\n\t\t\t  u32 type, u64 start, u64 end)\n{\n\tstruct acrn_ioreq_range *range;\n\n\twrite_lock_bh(&client->range_lock);\n\tlist_for_each_entry(range, &client->range_list, list) {\n\t\tif (type == range->type &&\n\t\t    start == range->start &&\n\t\t    end == range->end) {\n\t\t\tlist_del(&range->list);\n\t\t\tkfree(range);\n\t\t\tbreak;\n\t\t}\n\t}\n\twrite_unlock_bh(&client->range_lock);\n}\n\n \nstatic int ioreq_task(void *data)\n{\n\tstruct acrn_ioreq_client *client = data;\n\tstruct acrn_io_request *req;\n\tunsigned long *ioreqs_map;\n\tint vcpu, ret;\n\n\t \n\tioreqs_map = client->ioreqs_map;\n\twhile (!kthread_should_stop()) {\n\t\tacrn_ioreq_client_wait(client);\n\t\twhile (has_pending_request(client)) {\n\t\t\tvcpu = find_first_bit(ioreqs_map, client->vm->vcpu_num);\n\t\t\treq = client->vm->ioreq_buf->req_slot + vcpu;\n\t\t\tret = client->handler(client, req);\n\t\t\tif (ret < 0) {\n\t\t\t\tdev_err(acrn_dev.this_device,\n\t\t\t\t\t\"IO handle failure: %d\\n\", ret);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tacrn_ioreq_complete_request(client, vcpu, req);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nvoid acrn_ioreq_request_clear(struct acrn_vm *vm)\n{\n\tstruct acrn_ioreq_client *client;\n\tbool has_pending = false;\n\tunsigned long vcpu;\n\tint retry = 10;\n\n\t \n\tset_bit(ACRN_VM_FLAG_CLEARING_IOREQ, &vm->flags);\n\n\t \n\tdo {\n\t\tspin_lock_bh(&vm->ioreq_clients_lock);\n\t\tlist_for_each_entry(client, &vm->ioreq_clients, list) {\n\t\t\thas_pending = has_pending_request(client);\n\t\t\tif (has_pending)\n\t\t\t\tbreak;\n\t\t}\n\t\tspin_unlock_bh(&vm->ioreq_clients_lock);\n\n\t\tif (has_pending)\n\t\t\tschedule_timeout_interruptible(HZ / 100);\n\t} while (has_pending && --retry > 0);\n\tif (retry == 0)\n\t\tdev_warn(acrn_dev.this_device,\n\t\t\t \"%s cannot flush pending request!\\n\", client->name);\n\n\t \n\tspin_lock_bh(&vm->ioreq_clients_lock);\n\tclient = vm->default_client;\n\tif (client) {\n\t\tfor_each_set_bit(vcpu, client->ioreqs_map, ACRN_IO_REQUEST_MAX)\n\t\t\tacrn_ioreq_complete_request(client, vcpu, NULL);\n\t}\n\tspin_unlock_bh(&vm->ioreq_clients_lock);\n\n\t \n\tclear_bit(ACRN_VM_FLAG_CLEARING_IOREQ, &vm->flags);\n}\n\nint acrn_ioreq_client_wait(struct acrn_ioreq_client *client)\n{\n\tif (client->is_default) {\n\t\t \n\t\twait_event_interruptible(client->wq,\n\t\t\t\t\t has_pending_request(client) ||\n\t\t\t\t\t is_destroying(client));\n\t\tif (is_destroying(client))\n\t\t\treturn -ENODEV;\n\t} else {\n\t\twait_event_interruptible(client->wq,\n\t\t\t\t\t has_pending_request(client) ||\n\t\t\t\t\t kthread_should_stop());\n\t}\n\n\treturn 0;\n}\n\nstatic bool is_cfg_addr(struct acrn_io_request *req)\n{\n\treturn ((req->type == ACRN_IOREQ_TYPE_PORTIO) &&\n\t\t(req->reqs.pio_request.address == 0xcf8));\n}\n\nstatic bool is_cfg_data(struct acrn_io_request *req)\n{\n\treturn ((req->type == ACRN_IOREQ_TYPE_PORTIO) &&\n\t\t((req->reqs.pio_request.address >= 0xcfc) &&\n\t\t (req->reqs.pio_request.address < (0xcfc + 4))));\n}\n\n \n#define PCI_LOWREG_MASK  0xFC\n \n#define PCI_HIGHREG_MASK 0xF00\n \n#define PCI_FUNCMAX\t7\n \n#define PCI_SLOTMAX\t31\n \n#define PCI_BUSMAX\t255\n#define CONF1_ENABLE\t0x80000000UL\n \nstatic bool handle_cf8cfc(struct acrn_vm *vm,\n\t\t\t  struct acrn_io_request *req, u16 vcpu)\n{\n\tint offset, pci_cfg_addr, pci_reg;\n\tbool is_handled = false;\n\n\tif (is_cfg_addr(req)) {\n\t\tWARN_ON(req->reqs.pio_request.size != 4);\n\t\tif (req->reqs.pio_request.direction == ACRN_IOREQ_DIR_WRITE)\n\t\t\tvm->pci_conf_addr = req->reqs.pio_request.value;\n\t\telse\n\t\t\treq->reqs.pio_request.value = vm->pci_conf_addr;\n\t\tis_handled = true;\n\t} else if (is_cfg_data(req)) {\n\t\tif (!(vm->pci_conf_addr & CONF1_ENABLE)) {\n\t\t\tif (req->reqs.pio_request.direction ==\n\t\t\t\t\tACRN_IOREQ_DIR_READ)\n\t\t\t\treq->reqs.pio_request.value = 0xffffffff;\n\t\t\tis_handled = true;\n\t\t} else {\n\t\t\toffset = req->reqs.pio_request.address - 0xcfc;\n\n\t\t\treq->type = ACRN_IOREQ_TYPE_PCICFG;\n\t\t\tpci_cfg_addr = vm->pci_conf_addr;\n\t\t\treq->reqs.pci_request.bus =\n\t\t\t\t\t(pci_cfg_addr >> 16) & PCI_BUSMAX;\n\t\t\treq->reqs.pci_request.dev =\n\t\t\t\t\t(pci_cfg_addr >> 11) & PCI_SLOTMAX;\n\t\t\treq->reqs.pci_request.func =\n\t\t\t\t\t(pci_cfg_addr >> 8) & PCI_FUNCMAX;\n\t\t\tpci_reg = (pci_cfg_addr & PCI_LOWREG_MASK) +\n\t\t\t\t   ((pci_cfg_addr >> 16) & PCI_HIGHREG_MASK);\n\t\t\treq->reqs.pci_request.reg = pci_reg + offset;\n\t\t}\n\t}\n\n\tif (is_handled)\n\t\tioreq_complete_request(vm, vcpu, req);\n\n\treturn is_handled;\n}\n\nstatic bool acrn_in_range(struct acrn_ioreq_range *range,\n\t\t     struct acrn_io_request *req)\n{\n\tbool ret = false;\n\n\tif (range->type == req->type) {\n\t\tswitch (req->type) {\n\t\tcase ACRN_IOREQ_TYPE_MMIO:\n\t\t\tif (req->reqs.mmio_request.address >= range->start &&\n\t\t\t    (req->reqs.mmio_request.address +\n\t\t\t     req->reqs.mmio_request.size - 1) <= range->end)\n\t\t\t\tret = true;\n\t\t\tbreak;\n\t\tcase ACRN_IOREQ_TYPE_PORTIO:\n\t\t\tif (req->reqs.pio_request.address >= range->start &&\n\t\t\t    (req->reqs.pio_request.address +\n\t\t\t     req->reqs.pio_request.size - 1) <= range->end)\n\t\t\t\tret = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic struct acrn_ioreq_client *find_ioreq_client(struct acrn_vm *vm,\n\t\t\t\t\t\t   struct acrn_io_request *req)\n{\n\tstruct acrn_ioreq_client *client, *found = NULL;\n\tstruct acrn_ioreq_range *range;\n\n\tlockdep_assert_held(&vm->ioreq_clients_lock);\n\n\tlist_for_each_entry(client, &vm->ioreq_clients, list) {\n\t\tread_lock_bh(&client->range_lock);\n\t\tlist_for_each_entry(range, &client->range_list, list) {\n\t\t\tif (acrn_in_range(range, req)) {\n\t\t\t\tfound = client;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tread_unlock_bh(&client->range_lock);\n\t\tif (found)\n\t\t\tbreak;\n\t}\n\treturn found ? found : vm->default_client;\n}\n\n \nstruct acrn_ioreq_client *acrn_ioreq_client_create(struct acrn_vm *vm,\n\t\t\t\t\t\t   ioreq_handler_t handler,\n\t\t\t\t\t\t   void *priv, bool is_default,\n\t\t\t\t\t\t   const char *name)\n{\n\tstruct acrn_ioreq_client *client;\n\n\tif (!handler && !is_default) {\n\t\tdev_dbg(acrn_dev.this_device,\n\t\t\t\"Cannot create non-default client w/o handler!\\n\");\n\t\treturn NULL;\n\t}\n\tclient = kzalloc(sizeof(*client), GFP_KERNEL);\n\tif (!client)\n\t\treturn NULL;\n\n\tclient->handler = handler;\n\tclient->vm = vm;\n\tclient->priv = priv;\n\tclient->is_default = is_default;\n\tif (name)\n\t\tstrncpy(client->name, name, sizeof(client->name) - 1);\n\trwlock_init(&client->range_lock);\n\tINIT_LIST_HEAD(&client->range_list);\n\tinit_waitqueue_head(&client->wq);\n\n\tif (client->handler) {\n\t\tclient->thread = kthread_run(ioreq_task, client, \"VM%u-%s\",\n\t\t\t\t\t     client->vm->vmid, client->name);\n\t\tif (IS_ERR(client->thread)) {\n\t\t\tkfree(client);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tspin_lock_bh(&vm->ioreq_clients_lock);\n\tif (is_default)\n\t\tvm->default_client = client;\n\telse\n\t\tlist_add(&client->list, &vm->ioreq_clients);\n\tspin_unlock_bh(&vm->ioreq_clients_lock);\n\n\tdev_dbg(acrn_dev.this_device, \"Created ioreq client %s.\\n\", name);\n\treturn client;\n}\n\n \nvoid acrn_ioreq_client_destroy(struct acrn_ioreq_client *client)\n{\n\tstruct acrn_ioreq_range *range, *next;\n\tstruct acrn_vm *vm = client->vm;\n\n\tdev_dbg(acrn_dev.this_device,\n\t\t\"Destroy ioreq client %s.\\n\", client->name);\n\tioreq_pause();\n\tset_bit(ACRN_IOREQ_CLIENT_DESTROYING, &client->flags);\n\tif (client->is_default)\n\t\twake_up_interruptible(&client->wq);\n\telse\n\t\tkthread_stop(client->thread);\n\n\tspin_lock_bh(&vm->ioreq_clients_lock);\n\tif (client->is_default)\n\t\tvm->default_client = NULL;\n\telse\n\t\tlist_del(&client->list);\n\tspin_unlock_bh(&vm->ioreq_clients_lock);\n\n\twrite_lock_bh(&client->range_lock);\n\tlist_for_each_entry_safe(range, next, &client->range_list, list) {\n\t\tlist_del(&range->list);\n\t\tkfree(range);\n\t}\n\twrite_unlock_bh(&client->range_lock);\n\tkfree(client);\n\n\tioreq_resume();\n}\n\nstatic int acrn_ioreq_dispatch(struct acrn_vm *vm)\n{\n\tstruct acrn_ioreq_client *client;\n\tstruct acrn_io_request *req;\n\tint i;\n\n\tfor (i = 0; i < vm->vcpu_num; i++) {\n\t\treq = vm->ioreq_buf->req_slot + i;\n\n\t\t \n\t\tif (smp_load_acquire(&req->processed) ==\n\t\t\t\t     ACRN_IOREQ_STATE_PENDING) {\n\t\t\t \n\t\t\tif (test_bit(ACRN_VM_FLAG_CLEARING_IOREQ, &vm->flags)) {\n\t\t\t\tioreq_complete_request(vm, i, req);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (handle_cf8cfc(vm, req, i))\n\t\t\t\tcontinue;\n\n\t\t\tspin_lock_bh(&vm->ioreq_clients_lock);\n\t\t\tclient = find_ioreq_client(vm, req);\n\t\t\tif (!client) {\n\t\t\t\tdev_err(acrn_dev.this_device,\n\t\t\t\t\t\"Failed to find ioreq client!\\n\");\n\t\t\t\tspin_unlock_bh(&vm->ioreq_clients_lock);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (!client->is_default)\n\t\t\t\treq->kernel_handled = 1;\n\t\t\telse\n\t\t\t\treq->kernel_handled = 0;\n\t\t\t \n\t\t\tsmp_store_release(&req->processed,\n\t\t\t\t\t  ACRN_IOREQ_STATE_PROCESSING);\n\t\t\tset_bit(i, client->ioreqs_map);\n\t\t\twake_up_interruptible(&client->wq);\n\t\t\tspin_unlock_bh(&vm->ioreq_clients_lock);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void ioreq_dispatcher(struct work_struct *work)\n{\n\tstruct acrn_vm *vm;\n\n\tread_lock(&acrn_vm_list_lock);\n\tlist_for_each_entry(vm, &acrn_vm_list, list) {\n\t\tif (!vm->ioreq_buf)\n\t\t\tbreak;\n\t\tacrn_ioreq_dispatch(vm);\n\t}\n\tread_unlock(&acrn_vm_list_lock);\n}\n\nstatic void ioreq_intr_handler(void)\n{\n\tqueue_work(ioreq_wq, &ioreq_work);\n}\n\nstatic void ioreq_pause(void)\n{\n\t \n\tacrn_remove_intr_handler();\n\tdrain_workqueue(ioreq_wq);\n}\n\nstatic void ioreq_resume(void)\n{\n\t \n\tacrn_setup_intr_handler(ioreq_intr_handler);\n\tqueue_work(ioreq_wq, &ioreq_work);\n}\n\nint acrn_ioreq_intr_setup(void)\n{\n\tacrn_setup_intr_handler(ioreq_intr_handler);\n\tioreq_wq = alloc_ordered_workqueue(\"ioreq_wq\",\n\t\t\t\t\t   WQ_HIGHPRI | WQ_MEM_RECLAIM);\n\tif (!ioreq_wq) {\n\t\tdev_err(acrn_dev.this_device, \"Failed to alloc workqueue!\\n\");\n\t\tacrn_remove_intr_handler();\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nvoid acrn_ioreq_intr_remove(void)\n{\n\tif (ioreq_wq)\n\t\tdestroy_workqueue(ioreq_wq);\n\tacrn_remove_intr_handler();\n}\n\nint acrn_ioreq_init(struct acrn_vm *vm, u64 buf_vma)\n{\n\tstruct acrn_ioreq_buffer *set_buffer;\n\tstruct page *page;\n\tint ret;\n\n\tif (vm->ioreq_buf)\n\t\treturn -EEXIST;\n\n\tset_buffer = kzalloc(sizeof(*set_buffer), GFP_KERNEL);\n\tif (!set_buffer)\n\t\treturn -ENOMEM;\n\n\tret = pin_user_pages_fast(buf_vma, 1,\n\t\t\t\t  FOLL_WRITE | FOLL_LONGTERM, &page);\n\tif (unlikely(ret != 1) || !page) {\n\t\tdev_err(acrn_dev.this_device, \"Failed to pin ioreq page!\\n\");\n\t\tret = -EFAULT;\n\t\tgoto free_buf;\n\t}\n\n\tvm->ioreq_buf = page_address(page);\n\tvm->ioreq_page = page;\n\tset_buffer->ioreq_buf = page_to_phys(page);\n\tret = hcall_set_ioreq_buffer(vm->vmid, virt_to_phys(set_buffer));\n\tif (ret < 0) {\n\t\tdev_err(acrn_dev.this_device, \"Failed to init ioreq buffer!\\n\");\n\t\tunpin_user_page(page);\n\t\tvm->ioreq_buf = NULL;\n\t\tgoto free_buf;\n\t}\n\n\tdev_dbg(acrn_dev.this_device,\n\t\t\"Init ioreq buffer %pK!\\n\", vm->ioreq_buf);\n\tret = 0;\nfree_buf:\n\tkfree(set_buffer);\n\treturn ret;\n}\n\nvoid acrn_ioreq_deinit(struct acrn_vm *vm)\n{\n\tstruct acrn_ioreq_client *client, *next;\n\n\tdev_dbg(acrn_dev.this_device,\n\t\t\"Deinit ioreq buffer %pK!\\n\", vm->ioreq_buf);\n\t \n\tlist_for_each_entry_safe(client, next, &vm->ioreq_clients, list)\n\t\tacrn_ioreq_client_destroy(client);\n\tif (vm->default_client)\n\t\tacrn_ioreq_client_destroy(vm->default_client);\n\n\tif (vm->ioreq_buf && vm->ioreq_page) {\n\t\tunpin_user_page(vm->ioreq_page);\n\t\tvm->ioreq_buf = NULL;\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}