{
  "module_name": "binder_alloc.h",
  "hash_id": "c7510cf29e883132a2e1565c7afd3f50abc3c50e36482d756ea7cd871edc1142",
  "original_prompt": "Ingested from linux-6.6.14/drivers/android/binder_alloc.h",
  "human_readable_source": " \n \n\n#ifndef _LINUX_BINDER_ALLOC_H\n#define _LINUX_BINDER_ALLOC_H\n\n#include <linux/rbtree.h>\n#include <linux/list.h>\n#include <linux/mm.h>\n#include <linux/rtmutex.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/list_lru.h>\n#include <uapi/linux/android/binder.h>\n\nextern struct list_lru binder_alloc_lru;\nstruct binder_transaction;\n\n \nstruct binder_buffer {\n\tstruct list_head entry;  \n\tstruct rb_node rb_node;  \n\t\t\t\t \n\tunsigned free:1;\n\tunsigned clear_on_free:1;\n\tunsigned allow_user_free:1;\n\tunsigned async_transaction:1;\n\tunsigned oneway_spam_suspect:1;\n\tunsigned debug_id:27;\n\n\tstruct binder_transaction *transaction;\n\n\tstruct binder_node *target_node;\n\tsize_t data_size;\n\tsize_t offsets_size;\n\tsize_t extra_buffers_size;\n\tvoid __user *user_data;\n\tint    pid;\n};\n\n \nstruct binder_lru_page {\n\tstruct list_head lru;\n\tstruct page *page_ptr;\n\tstruct binder_alloc *alloc;\n};\n\n \nstruct binder_alloc {\n\tstruct mutex mutex;\n\tstruct vm_area_struct *vma;\n\tstruct mm_struct *mm;\n\tvoid __user *buffer;\n\tstruct list_head buffers;\n\tstruct rb_root free_buffers;\n\tstruct rb_root allocated_buffers;\n\tsize_t free_async_space;\n\tstruct binder_lru_page *pages;\n\tsize_t buffer_size;\n\tint pid;\n\tsize_t pages_high;\n\tbool oneway_spam_detected;\n};\n\n#ifdef CONFIG_ANDROID_BINDER_IPC_SELFTEST\nvoid binder_selftest_alloc(struct binder_alloc *alloc);\n#else\nstatic inline void binder_selftest_alloc(struct binder_alloc *alloc) {}\n#endif\nenum lru_status binder_alloc_free_page(struct list_head *item,\n\t\t\t\t       struct list_lru_one *lru,\n\t\t\t\t       spinlock_t *lock, void *cb_arg);\nextern struct binder_buffer *binder_alloc_new_buf(struct binder_alloc *alloc,\n\t\t\t\t\t\t  size_t data_size,\n\t\t\t\t\t\t  size_t offsets_size,\n\t\t\t\t\t\t  size_t extra_buffers_size,\n\t\t\t\t\t\t  int is_async,\n\t\t\t\t\t\t  int pid);\nextern void binder_alloc_init(struct binder_alloc *alloc);\nextern int binder_alloc_shrinker_init(void);\nextern void binder_alloc_shrinker_exit(void);\nextern void binder_alloc_vma_close(struct binder_alloc *alloc);\nextern struct binder_buffer *\nbinder_alloc_prepare_to_free(struct binder_alloc *alloc,\n\t\t\t     uintptr_t user_ptr);\nextern void binder_alloc_free_buf(struct binder_alloc *alloc,\n\t\t\t\t  struct binder_buffer *buffer);\nextern int binder_alloc_mmap_handler(struct binder_alloc *alloc,\n\t\t\t\t     struct vm_area_struct *vma);\nextern void binder_alloc_deferred_release(struct binder_alloc *alloc);\nextern int binder_alloc_get_allocated_count(struct binder_alloc *alloc);\nextern void binder_alloc_print_allocated(struct seq_file *m,\n\t\t\t\t\t struct binder_alloc *alloc);\nvoid binder_alloc_print_pages(struct seq_file *m,\n\t\t\t      struct binder_alloc *alloc);\n\n \nstatic inline size_t\nbinder_alloc_get_free_async_space(struct binder_alloc *alloc)\n{\n\tsize_t free_async_space;\n\n\tmutex_lock(&alloc->mutex);\n\tfree_async_space = alloc->free_async_space;\n\tmutex_unlock(&alloc->mutex);\n\treturn free_async_space;\n}\n\nunsigned long\nbinder_alloc_copy_user_to_buffer(struct binder_alloc *alloc,\n\t\t\t\t struct binder_buffer *buffer,\n\t\t\t\t binder_size_t buffer_offset,\n\t\t\t\t const void __user *from,\n\t\t\t\t size_t bytes);\n\nint binder_alloc_copy_to_buffer(struct binder_alloc *alloc,\n\t\t\t\tstruct binder_buffer *buffer,\n\t\t\t\tbinder_size_t buffer_offset,\n\t\t\t\tvoid *src,\n\t\t\t\tsize_t bytes);\n\nint binder_alloc_copy_from_buffer(struct binder_alloc *alloc,\n\t\t\t\t  void *dest,\n\t\t\t\t  struct binder_buffer *buffer,\n\t\t\t\t  binder_size_t buffer_offset,\n\t\t\t\t  size_t bytes);\n\n#endif  \n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}