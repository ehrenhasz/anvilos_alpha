{
  "module_name": "binder.c",
  "hash_id": "6d41d9bd49121de172784d520414c1e58f12b8697e0275944c791b78df9b033e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/android/binder.c",
  "human_readable_source": "\n \n\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/freezer.h>\n#include <linux/fs.h>\n#include <linux/list.h>\n#include <linux/miscdevice.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/nsproxy.h>\n#include <linux/poll.h>\n#include <linux/debugfs.h>\n#include <linux/rbtree.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/mm.h>\n#include <linux/seq_file.h>\n#include <linux/string.h>\n#include <linux/uaccess.h>\n#include <linux/pid_namespace.h>\n#include <linux/security.h>\n#include <linux/spinlock.h>\n#include <linux/ratelimit.h>\n#include <linux/syscalls.h>\n#include <linux/task_work.h>\n#include <linux/sizes.h>\n#include <linux/ktime.h>\n\n#include <uapi/linux/android/binder.h>\n\n#include <linux/cacheflush.h>\n\n#include \"binder_internal.h\"\n#include \"binder_trace.h\"\n\nstatic HLIST_HEAD(binder_deferred_list);\nstatic DEFINE_MUTEX(binder_deferred_lock);\n\nstatic HLIST_HEAD(binder_devices);\nstatic HLIST_HEAD(binder_procs);\nstatic DEFINE_MUTEX(binder_procs_lock);\n\nstatic HLIST_HEAD(binder_dead_nodes);\nstatic DEFINE_SPINLOCK(binder_dead_nodes_lock);\n\nstatic struct dentry *binder_debugfs_dir_entry_root;\nstatic struct dentry *binder_debugfs_dir_entry_proc;\nstatic atomic_t binder_last_id;\n\nstatic int proc_show(struct seq_file *m, void *unused);\nDEFINE_SHOW_ATTRIBUTE(proc);\n\n#define FORBIDDEN_MMAP_FLAGS                (VM_WRITE)\n\nenum {\n\tBINDER_DEBUG_USER_ERROR             = 1U << 0,\n\tBINDER_DEBUG_FAILED_TRANSACTION     = 1U << 1,\n\tBINDER_DEBUG_DEAD_TRANSACTION       = 1U << 2,\n\tBINDER_DEBUG_OPEN_CLOSE             = 1U << 3,\n\tBINDER_DEBUG_DEAD_BINDER            = 1U << 4,\n\tBINDER_DEBUG_DEATH_NOTIFICATION     = 1U << 5,\n\tBINDER_DEBUG_READ_WRITE             = 1U << 6,\n\tBINDER_DEBUG_USER_REFS              = 1U << 7,\n\tBINDER_DEBUG_THREADS                = 1U << 8,\n\tBINDER_DEBUG_TRANSACTION            = 1U << 9,\n\tBINDER_DEBUG_TRANSACTION_COMPLETE   = 1U << 10,\n\tBINDER_DEBUG_FREE_BUFFER            = 1U << 11,\n\tBINDER_DEBUG_INTERNAL_REFS          = 1U << 12,\n\tBINDER_DEBUG_PRIORITY_CAP           = 1U << 13,\n\tBINDER_DEBUG_SPINLOCKS              = 1U << 14,\n};\nstatic uint32_t binder_debug_mask = BINDER_DEBUG_USER_ERROR |\n\tBINDER_DEBUG_FAILED_TRANSACTION | BINDER_DEBUG_DEAD_TRANSACTION;\nmodule_param_named(debug_mask, binder_debug_mask, uint, 0644);\n\nchar *binder_devices_param = CONFIG_ANDROID_BINDER_DEVICES;\nmodule_param_named(devices, binder_devices_param, charp, 0444);\n\nstatic DECLARE_WAIT_QUEUE_HEAD(binder_user_error_wait);\nstatic int binder_stop_on_user_error;\n\nstatic int binder_set_stop_on_user_error(const char *val,\n\t\t\t\t\t const struct kernel_param *kp)\n{\n\tint ret;\n\n\tret = param_set_int(val, kp);\n\tif (binder_stop_on_user_error < 2)\n\t\twake_up(&binder_user_error_wait);\n\treturn ret;\n}\nmodule_param_call(stop_on_user_error, binder_set_stop_on_user_error,\n\tparam_get_int, &binder_stop_on_user_error, 0644);\n\nstatic __printf(2, 3) void binder_debug(int mask, const char *format, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (binder_debug_mask & mask) {\n\t\tva_start(args, format);\n\t\tvaf.va = &args;\n\t\tvaf.fmt = format;\n\t\tpr_info_ratelimited(\"%pV\", &vaf);\n\t\tva_end(args);\n\t}\n}\n\n#define binder_txn_error(x...) \\\n\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION, x)\n\nstatic __printf(1, 2) void binder_user_error(const char *format, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (binder_debug_mask & BINDER_DEBUG_USER_ERROR) {\n\t\tva_start(args, format);\n\t\tvaf.va = &args;\n\t\tvaf.fmt = format;\n\t\tpr_info_ratelimited(\"%pV\", &vaf);\n\t\tva_end(args);\n\t}\n\n\tif (binder_stop_on_user_error)\n\t\tbinder_stop_on_user_error = 2;\n}\n\n#define binder_set_extended_error(ee, _id, _command, _param) \\\n\tdo { \\\n\t\t(ee)->id = _id; \\\n\t\t(ee)->command = _command; \\\n\t\t(ee)->param = _param; \\\n\t} while (0)\n\n#define to_flat_binder_object(hdr) \\\n\tcontainer_of(hdr, struct flat_binder_object, hdr)\n\n#define to_binder_fd_object(hdr) container_of(hdr, struct binder_fd_object, hdr)\n\n#define to_binder_buffer_object(hdr) \\\n\tcontainer_of(hdr, struct binder_buffer_object, hdr)\n\n#define to_binder_fd_array_object(hdr) \\\n\tcontainer_of(hdr, struct binder_fd_array_object, hdr)\n\nstatic struct binder_stats binder_stats;\n\nstatic inline void binder_stats_deleted(enum binder_stat_types type)\n{\n\tatomic_inc(&binder_stats.obj_deleted[type]);\n}\n\nstatic inline void binder_stats_created(enum binder_stat_types type)\n{\n\tatomic_inc(&binder_stats.obj_created[type]);\n}\n\nstruct binder_transaction_log_entry {\n\tint debug_id;\n\tint debug_id_done;\n\tint call_type;\n\tint from_proc;\n\tint from_thread;\n\tint target_handle;\n\tint to_proc;\n\tint to_thread;\n\tint to_node;\n\tint data_size;\n\tint offsets_size;\n\tint return_error_line;\n\tuint32_t return_error;\n\tuint32_t return_error_param;\n\tchar context_name[BINDERFS_MAX_NAME + 1];\n};\n\nstruct binder_transaction_log {\n\tatomic_t cur;\n\tbool full;\n\tstruct binder_transaction_log_entry entry[32];\n};\n\nstatic struct binder_transaction_log binder_transaction_log;\nstatic struct binder_transaction_log binder_transaction_log_failed;\n\nstatic struct binder_transaction_log_entry *binder_transaction_log_add(\n\tstruct binder_transaction_log *log)\n{\n\tstruct binder_transaction_log_entry *e;\n\tunsigned int cur = atomic_inc_return(&log->cur);\n\n\tif (cur >= ARRAY_SIZE(log->entry))\n\t\tlog->full = true;\n\te = &log->entry[cur % ARRAY_SIZE(log->entry)];\n\tWRITE_ONCE(e->debug_id_done, 0);\n\t \n\tsmp_wmb();\n\tmemset(e, 0, sizeof(*e));\n\treturn e;\n}\n\nenum binder_deferred_state {\n\tBINDER_DEFERRED_FLUSH        = 0x01,\n\tBINDER_DEFERRED_RELEASE      = 0x02,\n};\n\nenum {\n\tBINDER_LOOPER_STATE_REGISTERED  = 0x01,\n\tBINDER_LOOPER_STATE_ENTERED     = 0x02,\n\tBINDER_LOOPER_STATE_EXITED      = 0x04,\n\tBINDER_LOOPER_STATE_INVALID     = 0x08,\n\tBINDER_LOOPER_STATE_WAITING     = 0x10,\n\tBINDER_LOOPER_STATE_POLL        = 0x20,\n};\n\n \n#define binder_proc_lock(proc) _binder_proc_lock(proc, __LINE__)\nstatic void\n_binder_proc_lock(struct binder_proc *proc, int line)\n\t__acquires(&proc->outer_lock)\n{\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tspin_lock(&proc->outer_lock);\n}\n\n \n#define binder_proc_unlock(proc) _binder_proc_unlock(proc, __LINE__)\nstatic void\n_binder_proc_unlock(struct binder_proc *proc, int line)\n\t__releases(&proc->outer_lock)\n{\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tspin_unlock(&proc->outer_lock);\n}\n\n \n#define binder_inner_proc_lock(proc) _binder_inner_proc_lock(proc, __LINE__)\nstatic void\n_binder_inner_proc_lock(struct binder_proc *proc, int line)\n\t__acquires(&proc->inner_lock)\n{\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tspin_lock(&proc->inner_lock);\n}\n\n \n#define binder_inner_proc_unlock(proc) _binder_inner_proc_unlock(proc, __LINE__)\nstatic void\n_binder_inner_proc_unlock(struct binder_proc *proc, int line)\n\t__releases(&proc->inner_lock)\n{\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tspin_unlock(&proc->inner_lock);\n}\n\n \n#define binder_node_lock(node) _binder_node_lock(node, __LINE__)\nstatic void\n_binder_node_lock(struct binder_node *node, int line)\n\t__acquires(&node->lock)\n{\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tspin_lock(&node->lock);\n}\n\n \n#define binder_node_unlock(node) _binder_node_unlock(node, __LINE__)\nstatic void\n_binder_node_unlock(struct binder_node *node, int line)\n\t__releases(&node->lock)\n{\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tspin_unlock(&node->lock);\n}\n\n \n#define binder_node_inner_lock(node) _binder_node_inner_lock(node, __LINE__)\nstatic void\n_binder_node_inner_lock(struct binder_node *node, int line)\n\t__acquires(&node->lock) __acquires(&node->proc->inner_lock)\n{\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tspin_lock(&node->lock);\n\tif (node->proc)\n\t\tbinder_inner_proc_lock(node->proc);\n\telse\n\t\t \n\t\t__acquire(&node->proc->inner_lock);\n}\n\n \n#define binder_node_inner_unlock(node) _binder_node_inner_unlock(node, __LINE__)\nstatic void\n_binder_node_inner_unlock(struct binder_node *node, int line)\n\t__releases(&node->lock) __releases(&node->proc->inner_lock)\n{\n\tstruct binder_proc *proc = node->proc;\n\n\tbinder_debug(BINDER_DEBUG_SPINLOCKS,\n\t\t     \"%s: line=%d\\n\", __func__, line);\n\tif (proc)\n\t\tbinder_inner_proc_unlock(proc);\n\telse\n\t\t \n\t\t__release(&node->proc->inner_lock);\n\tspin_unlock(&node->lock);\n}\n\nstatic bool binder_worklist_empty_ilocked(struct list_head *list)\n{\n\treturn list_empty(list);\n}\n\n \nstatic bool binder_worklist_empty(struct binder_proc *proc,\n\t\t\t\t  struct list_head *list)\n{\n\tbool ret;\n\n\tbinder_inner_proc_lock(proc);\n\tret = binder_worklist_empty_ilocked(list);\n\tbinder_inner_proc_unlock(proc);\n\treturn ret;\n}\n\n \nstatic void\nbinder_enqueue_work_ilocked(struct binder_work *work,\n\t\t\t   struct list_head *target_list)\n{\n\tBUG_ON(target_list == NULL);\n\tBUG_ON(work->entry.next && !list_empty(&work->entry));\n\tlist_add_tail(&work->entry, target_list);\n}\n\n \nstatic void\nbinder_enqueue_deferred_thread_work_ilocked(struct binder_thread *thread,\n\t\t\t\t\t    struct binder_work *work)\n{\n\tWARN_ON(!list_empty(&thread->waiting_thread_node));\n\tbinder_enqueue_work_ilocked(work, &thread->todo);\n}\n\n \nstatic void\nbinder_enqueue_thread_work_ilocked(struct binder_thread *thread,\n\t\t\t\t   struct binder_work *work)\n{\n\tWARN_ON(!list_empty(&thread->waiting_thread_node));\n\tbinder_enqueue_work_ilocked(work, &thread->todo);\n\tthread->process_todo = true;\n}\n\n \nstatic void\nbinder_enqueue_thread_work(struct binder_thread *thread,\n\t\t\t   struct binder_work *work)\n{\n\tbinder_inner_proc_lock(thread->proc);\n\tbinder_enqueue_thread_work_ilocked(thread, work);\n\tbinder_inner_proc_unlock(thread->proc);\n}\n\nstatic void\nbinder_dequeue_work_ilocked(struct binder_work *work)\n{\n\tlist_del_init(&work->entry);\n}\n\n \nstatic void\nbinder_dequeue_work(struct binder_proc *proc, struct binder_work *work)\n{\n\tbinder_inner_proc_lock(proc);\n\tbinder_dequeue_work_ilocked(work);\n\tbinder_inner_proc_unlock(proc);\n}\n\nstatic struct binder_work *binder_dequeue_work_head_ilocked(\n\t\t\t\t\tstruct list_head *list)\n{\n\tstruct binder_work *w;\n\n\tw = list_first_entry_or_null(list, struct binder_work, entry);\n\tif (w)\n\t\tlist_del_init(&w->entry);\n\treturn w;\n}\n\nstatic void\nbinder_defer_work(struct binder_proc *proc, enum binder_deferred_state defer);\nstatic void binder_free_thread(struct binder_thread *thread);\nstatic void binder_free_proc(struct binder_proc *proc);\nstatic void binder_inc_node_tmpref_ilocked(struct binder_node *node);\n\nstatic bool binder_has_work_ilocked(struct binder_thread *thread,\n\t\t\t\t    bool do_proc_work)\n{\n\treturn thread->process_todo ||\n\t\tthread->looper_need_return ||\n\t\t(do_proc_work &&\n\t\t !binder_worklist_empty_ilocked(&thread->proc->todo));\n}\n\nstatic bool binder_has_work(struct binder_thread *thread, bool do_proc_work)\n{\n\tbool has_work;\n\n\tbinder_inner_proc_lock(thread->proc);\n\thas_work = binder_has_work_ilocked(thread, do_proc_work);\n\tbinder_inner_proc_unlock(thread->proc);\n\n\treturn has_work;\n}\n\nstatic bool binder_available_for_proc_work_ilocked(struct binder_thread *thread)\n{\n\treturn !thread->transaction_stack &&\n\t\tbinder_worklist_empty_ilocked(&thread->todo) &&\n\t\t(thread->looper & (BINDER_LOOPER_STATE_ENTERED |\n\t\t\t\t   BINDER_LOOPER_STATE_REGISTERED));\n}\n\nstatic void binder_wakeup_poll_threads_ilocked(struct binder_proc *proc,\n\t\t\t\t\t       bool sync)\n{\n\tstruct rb_node *n;\n\tstruct binder_thread *thread;\n\n\tfor (n = rb_first(&proc->threads); n != NULL; n = rb_next(n)) {\n\t\tthread = rb_entry(n, struct binder_thread, rb_node);\n\t\tif (thread->looper & BINDER_LOOPER_STATE_POLL &&\n\t\t    binder_available_for_proc_work_ilocked(thread)) {\n\t\t\tif (sync)\n\t\t\t\twake_up_interruptible_sync(&thread->wait);\n\t\t\telse\n\t\t\t\twake_up_interruptible(&thread->wait);\n\t\t}\n\t}\n}\n\n \nstatic struct binder_thread *\nbinder_select_thread_ilocked(struct binder_proc *proc)\n{\n\tstruct binder_thread *thread;\n\n\tassert_spin_locked(&proc->inner_lock);\n\tthread = list_first_entry_or_null(&proc->waiting_threads,\n\t\t\t\t\t  struct binder_thread,\n\t\t\t\t\t  waiting_thread_node);\n\n\tif (thread)\n\t\tlist_del_init(&thread->waiting_thread_node);\n\n\treturn thread;\n}\n\n \nstatic void binder_wakeup_thread_ilocked(struct binder_proc *proc,\n\t\t\t\t\t struct binder_thread *thread,\n\t\t\t\t\t bool sync)\n{\n\tassert_spin_locked(&proc->inner_lock);\n\n\tif (thread) {\n\t\tif (sync)\n\t\t\twake_up_interruptible_sync(&thread->wait);\n\t\telse\n\t\t\twake_up_interruptible(&thread->wait);\n\t\treturn;\n\t}\n\n\t \n\tbinder_wakeup_poll_threads_ilocked(proc, sync);\n}\n\nstatic void binder_wakeup_proc_ilocked(struct binder_proc *proc)\n{\n\tstruct binder_thread *thread = binder_select_thread_ilocked(proc);\n\n\tbinder_wakeup_thread_ilocked(proc, thread,  false);\n}\n\nstatic void binder_set_nice(long nice)\n{\n\tlong min_nice;\n\n\tif (can_nice(current, nice)) {\n\t\tset_user_nice(current, nice);\n\t\treturn;\n\t}\n\tmin_nice = rlimit_to_nice(rlimit(RLIMIT_NICE));\n\tbinder_debug(BINDER_DEBUG_PRIORITY_CAP,\n\t\t     \"%d: nice value %ld not allowed use %ld instead\\n\",\n\t\t      current->pid, nice, min_nice);\n\tset_user_nice(current, min_nice);\n\tif (min_nice <= MAX_NICE)\n\t\treturn;\n\tbinder_user_error(\"%d RLIMIT_NICE not set\\n\", current->pid);\n}\n\nstatic struct binder_node *binder_get_node_ilocked(struct binder_proc *proc,\n\t\t\t\t\t\t   binder_uintptr_t ptr)\n{\n\tstruct rb_node *n = proc->nodes.rb_node;\n\tstruct binder_node *node;\n\n\tassert_spin_locked(&proc->inner_lock);\n\n\twhile (n) {\n\t\tnode = rb_entry(n, struct binder_node, rb_node);\n\n\t\tif (ptr < node->ptr)\n\t\t\tn = n->rb_left;\n\t\telse if (ptr > node->ptr)\n\t\t\tn = n->rb_right;\n\t\telse {\n\t\t\t \n\t\t\tbinder_inc_node_tmpref_ilocked(node);\n\t\t\treturn node;\n\t\t}\n\t}\n\treturn NULL;\n}\n\nstatic struct binder_node *binder_get_node(struct binder_proc *proc,\n\t\t\t\t\t   binder_uintptr_t ptr)\n{\n\tstruct binder_node *node;\n\n\tbinder_inner_proc_lock(proc);\n\tnode = binder_get_node_ilocked(proc, ptr);\n\tbinder_inner_proc_unlock(proc);\n\treturn node;\n}\n\nstatic struct binder_node *binder_init_node_ilocked(\n\t\t\t\t\t\tstruct binder_proc *proc,\n\t\t\t\t\t\tstruct binder_node *new_node,\n\t\t\t\t\t\tstruct flat_binder_object *fp)\n{\n\tstruct rb_node **p = &proc->nodes.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct binder_node *node;\n\tbinder_uintptr_t ptr = fp ? fp->binder : 0;\n\tbinder_uintptr_t cookie = fp ? fp->cookie : 0;\n\t__u32 flags = fp ? fp->flags : 0;\n\n\tassert_spin_locked(&proc->inner_lock);\n\n\twhile (*p) {\n\n\t\tparent = *p;\n\t\tnode = rb_entry(parent, struct binder_node, rb_node);\n\n\t\tif (ptr < node->ptr)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (ptr > node->ptr)\n\t\t\tp = &(*p)->rb_right;\n\t\telse {\n\t\t\t \n\t\t\tbinder_inc_node_tmpref_ilocked(node);\n\t\t\treturn node;\n\t\t}\n\t}\n\tnode = new_node;\n\tbinder_stats_created(BINDER_STAT_NODE);\n\tnode->tmp_refs++;\n\trb_link_node(&node->rb_node, parent, p);\n\trb_insert_color(&node->rb_node, &proc->nodes);\n\tnode->debug_id = atomic_inc_return(&binder_last_id);\n\tnode->proc = proc;\n\tnode->ptr = ptr;\n\tnode->cookie = cookie;\n\tnode->work.type = BINDER_WORK_NODE;\n\tnode->min_priority = flags & FLAT_BINDER_FLAG_PRIORITY_MASK;\n\tnode->accept_fds = !!(flags & FLAT_BINDER_FLAG_ACCEPTS_FDS);\n\tnode->txn_security_ctx = !!(flags & FLAT_BINDER_FLAG_TXN_SECURITY_CTX);\n\tspin_lock_init(&node->lock);\n\tINIT_LIST_HEAD(&node->work.entry);\n\tINIT_LIST_HEAD(&node->async_todo);\n\tbinder_debug(BINDER_DEBUG_INTERNAL_REFS,\n\t\t     \"%d:%d node %d u%016llx c%016llx created\\n\",\n\t\t     proc->pid, current->pid, node->debug_id,\n\t\t     (u64)node->ptr, (u64)node->cookie);\n\n\treturn node;\n}\n\nstatic struct binder_node *binder_new_node(struct binder_proc *proc,\n\t\t\t\t\t   struct flat_binder_object *fp)\n{\n\tstruct binder_node *node;\n\tstruct binder_node *new_node = kzalloc(sizeof(*node), GFP_KERNEL);\n\n\tif (!new_node)\n\t\treturn NULL;\n\tbinder_inner_proc_lock(proc);\n\tnode = binder_init_node_ilocked(proc, new_node, fp);\n\tbinder_inner_proc_unlock(proc);\n\tif (node != new_node)\n\t\t \n\t\tkfree(new_node);\n\n\treturn node;\n}\n\nstatic void binder_free_node(struct binder_node *node)\n{\n\tkfree(node);\n\tbinder_stats_deleted(BINDER_STAT_NODE);\n}\n\nstatic int binder_inc_node_nilocked(struct binder_node *node, int strong,\n\t\t\t\t    int internal,\n\t\t\t\t    struct list_head *target_list)\n{\n\tstruct binder_proc *proc = node->proc;\n\n\tassert_spin_locked(&node->lock);\n\tif (proc)\n\t\tassert_spin_locked(&proc->inner_lock);\n\tif (strong) {\n\t\tif (internal) {\n\t\t\tif (target_list == NULL &&\n\t\t\t    node->internal_strong_refs == 0 &&\n\t\t\t    !(node->proc &&\n\t\t\t      node == node->proc->context->binder_context_mgr_node &&\n\t\t\t      node->has_strong_ref)) {\n\t\t\t\tpr_err(\"invalid inc strong node for %d\\n\",\n\t\t\t\t\tnode->debug_id);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnode->internal_strong_refs++;\n\t\t} else\n\t\t\tnode->local_strong_refs++;\n\t\tif (!node->has_strong_ref && target_list) {\n\t\t\tstruct binder_thread *thread = container_of(target_list,\n\t\t\t\t\t\t    struct binder_thread, todo);\n\t\t\tbinder_dequeue_work_ilocked(&node->work);\n\t\t\tBUG_ON(&thread->todo != target_list);\n\t\t\tbinder_enqueue_deferred_thread_work_ilocked(thread,\n\t\t\t\t\t\t\t\t   &node->work);\n\t\t}\n\t} else {\n\t\tif (!internal)\n\t\t\tnode->local_weak_refs++;\n\t\tif (!node->has_weak_ref && list_empty(&node->work.entry)) {\n\t\t\tif (target_list == NULL) {\n\t\t\t\tpr_err(\"invalid inc weak node for %d\\n\",\n\t\t\t\t\tnode->debug_id);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t \n\t\t\tbinder_enqueue_work_ilocked(&node->work, target_list);\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int binder_inc_node(struct binder_node *node, int strong, int internal,\n\t\t\t   struct list_head *target_list)\n{\n\tint ret;\n\n\tbinder_node_inner_lock(node);\n\tret = binder_inc_node_nilocked(node, strong, internal, target_list);\n\tbinder_node_inner_unlock(node);\n\n\treturn ret;\n}\n\nstatic bool binder_dec_node_nilocked(struct binder_node *node,\n\t\t\t\t     int strong, int internal)\n{\n\tstruct binder_proc *proc = node->proc;\n\n\tassert_spin_locked(&node->lock);\n\tif (proc)\n\t\tassert_spin_locked(&proc->inner_lock);\n\tif (strong) {\n\t\tif (internal)\n\t\t\tnode->internal_strong_refs--;\n\t\telse\n\t\t\tnode->local_strong_refs--;\n\t\tif (node->local_strong_refs || node->internal_strong_refs)\n\t\t\treturn false;\n\t} else {\n\t\tif (!internal)\n\t\t\tnode->local_weak_refs--;\n\t\tif (node->local_weak_refs || node->tmp_refs ||\n\t\t\t\t!hlist_empty(&node->refs))\n\t\t\treturn false;\n\t}\n\n\tif (proc && (node->has_strong_ref || node->has_weak_ref)) {\n\t\tif (list_empty(&node->work.entry)) {\n\t\t\tbinder_enqueue_work_ilocked(&node->work, &proc->todo);\n\t\t\tbinder_wakeup_proc_ilocked(proc);\n\t\t}\n\t} else {\n\t\tif (hlist_empty(&node->refs) && !node->local_strong_refs &&\n\t\t    !node->local_weak_refs && !node->tmp_refs) {\n\t\t\tif (proc) {\n\t\t\t\tbinder_dequeue_work_ilocked(&node->work);\n\t\t\t\trb_erase(&node->rb_node, &proc->nodes);\n\t\t\t\tbinder_debug(BINDER_DEBUG_INTERNAL_REFS,\n\t\t\t\t\t     \"refless node %d deleted\\n\",\n\t\t\t\t\t     node->debug_id);\n\t\t\t} else {\n\t\t\t\tBUG_ON(!list_empty(&node->work.entry));\n\t\t\t\tspin_lock(&binder_dead_nodes_lock);\n\t\t\t\t \n\t\t\t\tif (node->tmp_refs) {\n\t\t\t\t\tspin_unlock(&binder_dead_nodes_lock);\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\thlist_del(&node->dead_node);\n\t\t\t\tspin_unlock(&binder_dead_nodes_lock);\n\t\t\t\tbinder_debug(BINDER_DEBUG_INTERNAL_REFS,\n\t\t\t\t\t     \"dead node %d deleted\\n\",\n\t\t\t\t\t     node->debug_id);\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic void binder_dec_node(struct binder_node *node, int strong, int internal)\n{\n\tbool free_node;\n\n\tbinder_node_inner_lock(node);\n\tfree_node = binder_dec_node_nilocked(node, strong, internal);\n\tbinder_node_inner_unlock(node);\n\tif (free_node)\n\t\tbinder_free_node(node);\n}\n\nstatic void binder_inc_node_tmpref_ilocked(struct binder_node *node)\n{\n\t \n\tnode->tmp_refs++;\n}\n\n \nstatic void binder_inc_node_tmpref(struct binder_node *node)\n{\n\tbinder_node_lock(node);\n\tif (node->proc)\n\t\tbinder_inner_proc_lock(node->proc);\n\telse\n\t\tspin_lock(&binder_dead_nodes_lock);\n\tbinder_inc_node_tmpref_ilocked(node);\n\tif (node->proc)\n\t\tbinder_inner_proc_unlock(node->proc);\n\telse\n\t\tspin_unlock(&binder_dead_nodes_lock);\n\tbinder_node_unlock(node);\n}\n\n \nstatic void binder_dec_node_tmpref(struct binder_node *node)\n{\n\tbool free_node;\n\n\tbinder_node_inner_lock(node);\n\tif (!node->proc)\n\t\tspin_lock(&binder_dead_nodes_lock);\n\telse\n\t\t__acquire(&binder_dead_nodes_lock);\n\tnode->tmp_refs--;\n\tBUG_ON(node->tmp_refs < 0);\n\tif (!node->proc)\n\t\tspin_unlock(&binder_dead_nodes_lock);\n\telse\n\t\t__release(&binder_dead_nodes_lock);\n\t \n\tfree_node = binder_dec_node_nilocked(node, 0, 1);\n\tbinder_node_inner_unlock(node);\n\tif (free_node)\n\t\tbinder_free_node(node);\n}\n\nstatic void binder_put_node(struct binder_node *node)\n{\n\tbinder_dec_node_tmpref(node);\n}\n\nstatic struct binder_ref *binder_get_ref_olocked(struct binder_proc *proc,\n\t\t\t\t\t\t u32 desc, bool need_strong_ref)\n{\n\tstruct rb_node *n = proc->refs_by_desc.rb_node;\n\tstruct binder_ref *ref;\n\n\twhile (n) {\n\t\tref = rb_entry(n, struct binder_ref, rb_node_desc);\n\n\t\tif (desc < ref->data.desc) {\n\t\t\tn = n->rb_left;\n\t\t} else if (desc > ref->data.desc) {\n\t\t\tn = n->rb_right;\n\t\t} else if (need_strong_ref && !ref->data.strong) {\n\t\t\tbinder_user_error(\"tried to use weak ref as strong ref\\n\");\n\t\t\treturn NULL;\n\t\t} else {\n\t\t\treturn ref;\n\t\t}\n\t}\n\treturn NULL;\n}\n\n \nstatic struct binder_ref *binder_get_ref_for_node_olocked(\n\t\t\t\t\tstruct binder_proc *proc,\n\t\t\t\t\tstruct binder_node *node,\n\t\t\t\t\tstruct binder_ref *new_ref)\n{\n\tstruct binder_context *context = proc->context;\n\tstruct rb_node **p = &proc->refs_by_node.rb_node;\n\tstruct rb_node *parent = NULL;\n\tstruct binder_ref *ref;\n\tstruct rb_node *n;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tref = rb_entry(parent, struct binder_ref, rb_node_node);\n\n\t\tif (node < ref->node)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (node > ref->node)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\treturn ref;\n\t}\n\tif (!new_ref)\n\t\treturn NULL;\n\n\tbinder_stats_created(BINDER_STAT_REF);\n\tnew_ref->data.debug_id = atomic_inc_return(&binder_last_id);\n\tnew_ref->proc = proc;\n\tnew_ref->node = node;\n\trb_link_node(&new_ref->rb_node_node, parent, p);\n\trb_insert_color(&new_ref->rb_node_node, &proc->refs_by_node);\n\n\tnew_ref->data.desc = (node == context->binder_context_mgr_node) ? 0 : 1;\n\tfor (n = rb_first(&proc->refs_by_desc); n != NULL; n = rb_next(n)) {\n\t\tref = rb_entry(n, struct binder_ref, rb_node_desc);\n\t\tif (ref->data.desc > new_ref->data.desc)\n\t\t\tbreak;\n\t\tnew_ref->data.desc = ref->data.desc + 1;\n\t}\n\n\tp = &proc->refs_by_desc.rb_node;\n\twhile (*p) {\n\t\tparent = *p;\n\t\tref = rb_entry(parent, struct binder_ref, rb_node_desc);\n\n\t\tif (new_ref->data.desc < ref->data.desc)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (new_ref->data.desc > ref->data.desc)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\tBUG();\n\t}\n\trb_link_node(&new_ref->rb_node_desc, parent, p);\n\trb_insert_color(&new_ref->rb_node_desc, &proc->refs_by_desc);\n\n\tbinder_node_lock(node);\n\thlist_add_head(&new_ref->node_entry, &node->refs);\n\n\tbinder_debug(BINDER_DEBUG_INTERNAL_REFS,\n\t\t     \"%d new ref %d desc %d for node %d\\n\",\n\t\t      proc->pid, new_ref->data.debug_id, new_ref->data.desc,\n\t\t      node->debug_id);\n\tbinder_node_unlock(node);\n\treturn new_ref;\n}\n\nstatic void binder_cleanup_ref_olocked(struct binder_ref *ref)\n{\n\tbool delete_node = false;\n\n\tbinder_debug(BINDER_DEBUG_INTERNAL_REFS,\n\t\t     \"%d delete ref %d desc %d for node %d\\n\",\n\t\t      ref->proc->pid, ref->data.debug_id, ref->data.desc,\n\t\t      ref->node->debug_id);\n\n\trb_erase(&ref->rb_node_desc, &ref->proc->refs_by_desc);\n\trb_erase(&ref->rb_node_node, &ref->proc->refs_by_node);\n\n\tbinder_node_inner_lock(ref->node);\n\tif (ref->data.strong)\n\t\tbinder_dec_node_nilocked(ref->node, 1, 1);\n\n\thlist_del(&ref->node_entry);\n\tdelete_node = binder_dec_node_nilocked(ref->node, 0, 1);\n\tbinder_node_inner_unlock(ref->node);\n\t \n\tif (!delete_node) {\n\t\t \n\t\tref->node = NULL;\n\t}\n\n\tif (ref->death) {\n\t\tbinder_debug(BINDER_DEBUG_DEAD_BINDER,\n\t\t\t     \"%d delete ref %d desc %d has death notification\\n\",\n\t\t\t      ref->proc->pid, ref->data.debug_id,\n\t\t\t      ref->data.desc);\n\t\tbinder_dequeue_work(ref->proc, &ref->death->work);\n\t\tbinder_stats_deleted(BINDER_STAT_DEATH);\n\t}\n\tbinder_stats_deleted(BINDER_STAT_REF);\n}\n\n \nstatic int binder_inc_ref_olocked(struct binder_ref *ref, int strong,\n\t\t\t\t  struct list_head *target_list)\n{\n\tint ret;\n\n\tif (strong) {\n\t\tif (ref->data.strong == 0) {\n\t\t\tret = binder_inc_node(ref->node, 1, 1, target_list);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t\tref->data.strong++;\n\t} else {\n\t\tif (ref->data.weak == 0) {\n\t\t\tret = binder_inc_node(ref->node, 0, 1, target_list);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t\tref->data.weak++;\n\t}\n\treturn 0;\n}\n\n \nstatic bool binder_dec_ref_olocked(struct binder_ref *ref, int strong)\n{\n\tif (strong) {\n\t\tif (ref->data.strong == 0) {\n\t\t\tbinder_user_error(\"%d invalid dec strong, ref %d desc %d s %d w %d\\n\",\n\t\t\t\t\t  ref->proc->pid, ref->data.debug_id,\n\t\t\t\t\t  ref->data.desc, ref->data.strong,\n\t\t\t\t\t  ref->data.weak);\n\t\t\treturn false;\n\t\t}\n\t\tref->data.strong--;\n\t\tif (ref->data.strong == 0)\n\t\t\tbinder_dec_node(ref->node, strong, 1);\n\t} else {\n\t\tif (ref->data.weak == 0) {\n\t\t\tbinder_user_error(\"%d invalid dec weak, ref %d desc %d s %d w %d\\n\",\n\t\t\t\t\t  ref->proc->pid, ref->data.debug_id,\n\t\t\t\t\t  ref->data.desc, ref->data.strong,\n\t\t\t\t\t  ref->data.weak);\n\t\t\treturn false;\n\t\t}\n\t\tref->data.weak--;\n\t}\n\tif (ref->data.strong == 0 && ref->data.weak == 0) {\n\t\tbinder_cleanup_ref_olocked(ref);\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nstatic struct binder_node *binder_get_node_from_ref(\n\t\tstruct binder_proc *proc,\n\t\tu32 desc, bool need_strong_ref,\n\t\tstruct binder_ref_data *rdata)\n{\n\tstruct binder_node *node;\n\tstruct binder_ref *ref;\n\n\tbinder_proc_lock(proc);\n\tref = binder_get_ref_olocked(proc, desc, need_strong_ref);\n\tif (!ref)\n\t\tgoto err_no_ref;\n\tnode = ref->node;\n\t \n\tbinder_inc_node_tmpref(node);\n\tif (rdata)\n\t\t*rdata = ref->data;\n\tbinder_proc_unlock(proc);\n\n\treturn node;\n\nerr_no_ref:\n\tbinder_proc_unlock(proc);\n\treturn NULL;\n}\n\n \nstatic void binder_free_ref(struct binder_ref *ref)\n{\n\tif (ref->node)\n\t\tbinder_free_node(ref->node);\n\tkfree(ref->death);\n\tkfree(ref);\n}\n\n \nstatic int binder_update_ref_for_handle(struct binder_proc *proc,\n\t\tuint32_t desc, bool increment, bool strong,\n\t\tstruct binder_ref_data *rdata)\n{\n\tint ret = 0;\n\tstruct binder_ref *ref;\n\tbool delete_ref = false;\n\n\tbinder_proc_lock(proc);\n\tref = binder_get_ref_olocked(proc, desc, strong);\n\tif (!ref) {\n\t\tret = -EINVAL;\n\t\tgoto err_no_ref;\n\t}\n\tif (increment)\n\t\tret = binder_inc_ref_olocked(ref, strong, NULL);\n\telse\n\t\tdelete_ref = binder_dec_ref_olocked(ref, strong);\n\n\tif (rdata)\n\t\t*rdata = ref->data;\n\tbinder_proc_unlock(proc);\n\n\tif (delete_ref)\n\t\tbinder_free_ref(ref);\n\treturn ret;\n\nerr_no_ref:\n\tbinder_proc_unlock(proc);\n\treturn ret;\n}\n\n \nstatic int binder_dec_ref_for_handle(struct binder_proc *proc,\n\t\tuint32_t desc, bool strong, struct binder_ref_data *rdata)\n{\n\treturn binder_update_ref_for_handle(proc, desc, false, strong, rdata);\n}\n\n\n \nstatic int binder_inc_ref_for_node(struct binder_proc *proc,\n\t\t\tstruct binder_node *node,\n\t\t\tbool strong,\n\t\t\tstruct list_head *target_list,\n\t\t\tstruct binder_ref_data *rdata)\n{\n\tstruct binder_ref *ref;\n\tstruct binder_ref *new_ref = NULL;\n\tint ret = 0;\n\n\tbinder_proc_lock(proc);\n\tref = binder_get_ref_for_node_olocked(proc, node, NULL);\n\tif (!ref) {\n\t\tbinder_proc_unlock(proc);\n\t\tnew_ref = kzalloc(sizeof(*ref), GFP_KERNEL);\n\t\tif (!new_ref)\n\t\t\treturn -ENOMEM;\n\t\tbinder_proc_lock(proc);\n\t\tref = binder_get_ref_for_node_olocked(proc, node, new_ref);\n\t}\n\tret = binder_inc_ref_olocked(ref, strong, target_list);\n\t*rdata = ref->data;\n\tif (ret && ref == new_ref) {\n\t\t \n\t\tbinder_cleanup_ref_olocked(new_ref);\n\t\tref = NULL;\n\t}\n\n\tbinder_proc_unlock(proc);\n\tif (new_ref && ref != new_ref)\n\t\t \n\t\tkfree(new_ref);\n\treturn ret;\n}\n\nstatic void binder_pop_transaction_ilocked(struct binder_thread *target_thread,\n\t\t\t\t\t   struct binder_transaction *t)\n{\n\tBUG_ON(!target_thread);\n\tassert_spin_locked(&target_thread->proc->inner_lock);\n\tBUG_ON(target_thread->transaction_stack != t);\n\tBUG_ON(target_thread->transaction_stack->from != target_thread);\n\ttarget_thread->transaction_stack =\n\t\ttarget_thread->transaction_stack->from_parent;\n\tt->from = NULL;\n}\n\n \nstatic void binder_thread_dec_tmpref(struct binder_thread *thread)\n{\n\t \n\tbinder_inner_proc_lock(thread->proc);\n\tatomic_dec(&thread->tmp_ref);\n\tif (thread->is_dead && !atomic_read(&thread->tmp_ref)) {\n\t\tbinder_inner_proc_unlock(thread->proc);\n\t\tbinder_free_thread(thread);\n\t\treturn;\n\t}\n\tbinder_inner_proc_unlock(thread->proc);\n}\n\n \nstatic void binder_proc_dec_tmpref(struct binder_proc *proc)\n{\n\tbinder_inner_proc_lock(proc);\n\tproc->tmp_ref--;\n\tif (proc->is_dead && RB_EMPTY_ROOT(&proc->threads) &&\n\t\t\t!proc->tmp_ref) {\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_free_proc(proc);\n\t\treturn;\n\t}\n\tbinder_inner_proc_unlock(proc);\n}\n\n \nstatic struct binder_thread *binder_get_txn_from(\n\t\tstruct binder_transaction *t)\n{\n\tstruct binder_thread *from;\n\n\tspin_lock(&t->lock);\n\tfrom = t->from;\n\tif (from)\n\t\tatomic_inc(&from->tmp_ref);\n\tspin_unlock(&t->lock);\n\treturn from;\n}\n\n \nstatic struct binder_thread *binder_get_txn_from_and_acq_inner(\n\t\tstruct binder_transaction *t)\n\t__acquires(&t->from->proc->inner_lock)\n{\n\tstruct binder_thread *from;\n\n\tfrom = binder_get_txn_from(t);\n\tif (!from) {\n\t\t__acquire(&from->proc->inner_lock);\n\t\treturn NULL;\n\t}\n\tbinder_inner_proc_lock(from->proc);\n\tif (t->from) {\n\t\tBUG_ON(from != t->from);\n\t\treturn from;\n\t}\n\tbinder_inner_proc_unlock(from->proc);\n\t__acquire(&from->proc->inner_lock);\n\tbinder_thread_dec_tmpref(from);\n\treturn NULL;\n}\n\n \nstatic void binder_free_txn_fixups(struct binder_transaction *t)\n{\n\tstruct binder_txn_fd_fixup *fixup, *tmp;\n\n\tlist_for_each_entry_safe(fixup, tmp, &t->fd_fixups, fixup_entry) {\n\t\tfput(fixup->file);\n\t\tif (fixup->target_fd >= 0)\n\t\t\tput_unused_fd(fixup->target_fd);\n\t\tlist_del(&fixup->fixup_entry);\n\t\tkfree(fixup);\n\t}\n}\n\nstatic void binder_txn_latency_free(struct binder_transaction *t)\n{\n\tint from_proc, from_thread, to_proc, to_thread;\n\n\tspin_lock(&t->lock);\n\tfrom_proc = t->from ? t->from->proc->pid : 0;\n\tfrom_thread = t->from ? t->from->pid : 0;\n\tto_proc = t->to_proc ? t->to_proc->pid : 0;\n\tto_thread = t->to_thread ? t->to_thread->pid : 0;\n\tspin_unlock(&t->lock);\n\n\ttrace_binder_txn_latency_free(t, from_proc, from_thread, to_proc, to_thread);\n}\n\nstatic void binder_free_transaction(struct binder_transaction *t)\n{\n\tstruct binder_proc *target_proc = t->to_proc;\n\n\tif (target_proc) {\n\t\tbinder_inner_proc_lock(target_proc);\n\t\ttarget_proc->outstanding_txns--;\n\t\tif (target_proc->outstanding_txns < 0)\n\t\t\tpr_warn(\"%s: Unexpected outstanding_txns %d\\n\",\n\t\t\t\t__func__, target_proc->outstanding_txns);\n\t\tif (!target_proc->outstanding_txns && target_proc->is_frozen)\n\t\t\twake_up_interruptible_all(&target_proc->freeze_wait);\n\t\tif (t->buffer)\n\t\t\tt->buffer->transaction = NULL;\n\t\tbinder_inner_proc_unlock(target_proc);\n\t}\n\tif (trace_binder_txn_latency_free_enabled())\n\t\tbinder_txn_latency_free(t);\n\t \n\tbinder_free_txn_fixups(t);\n\tkfree(t);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\n}\n\nstatic void binder_send_failed_reply(struct binder_transaction *t,\n\t\t\t\t     uint32_t error_code)\n{\n\tstruct binder_thread *target_thread;\n\tstruct binder_transaction *next;\n\n\tBUG_ON(t->flags & TF_ONE_WAY);\n\twhile (1) {\n\t\ttarget_thread = binder_get_txn_from_and_acq_inner(t);\n\t\tif (target_thread) {\n\t\t\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t\t\t     \"send failed reply for transaction %d to %d:%d\\n\",\n\t\t\t\t      t->debug_id,\n\t\t\t\t      target_thread->proc->pid,\n\t\t\t\t      target_thread->pid);\n\n\t\t\tbinder_pop_transaction_ilocked(target_thread, t);\n\t\t\tif (target_thread->reply_error.cmd == BR_OK) {\n\t\t\t\ttarget_thread->reply_error.cmd = error_code;\n\t\t\t\tbinder_enqueue_thread_work_ilocked(\n\t\t\t\t\ttarget_thread,\n\t\t\t\t\t&target_thread->reply_error.work);\n\t\t\t\twake_up_interruptible(&target_thread->wait);\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tpr_warn(\"Unexpected reply error: %u\\n\",\n\t\t\t\t\ttarget_thread->reply_error.cmd);\n\t\t\t}\n\t\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t\t\tbinder_thread_dec_tmpref(target_thread);\n\t\t\tbinder_free_transaction(t);\n\t\t\treturn;\n\t\t}\n\t\t__release(&target_thread->proc->inner_lock);\n\t\tnext = t->from_parent;\n\n\t\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t\t     \"send failed reply for transaction %d, target dead\\n\",\n\t\t\t     t->debug_id);\n\n\t\tbinder_free_transaction(t);\n\t\tif (next == NULL) {\n\t\t\tbinder_debug(BINDER_DEBUG_DEAD_BINDER,\n\t\t\t\t     \"reply failed, no target thread at root\\n\");\n\t\t\treturn;\n\t\t}\n\t\tt = next;\n\t\tbinder_debug(BINDER_DEBUG_DEAD_BINDER,\n\t\t\t     \"reply failed, no target thread -- retry %d\\n\",\n\t\t\t      t->debug_id);\n\t}\n}\n\n \nstatic void binder_cleanup_transaction(struct binder_transaction *t,\n\t\t\t\t       const char *reason,\n\t\t\t\t       uint32_t error_code)\n{\n\tif (t->buffer->target_node && !(t->flags & TF_ONE_WAY)) {\n\t\tbinder_send_failed_reply(t, error_code);\n\t} else {\n\t\tbinder_debug(BINDER_DEBUG_DEAD_TRANSACTION,\n\t\t\t\"undelivered transaction %d, %s\\n\",\n\t\t\tt->debug_id, reason);\n\t\tbinder_free_transaction(t);\n\t}\n}\n\n \nstatic size_t binder_get_object(struct binder_proc *proc,\n\t\t\t\tconst void __user *u,\n\t\t\t\tstruct binder_buffer *buffer,\n\t\t\t\tunsigned long offset,\n\t\t\t\tstruct binder_object *object)\n{\n\tsize_t read_size;\n\tstruct binder_object_header *hdr;\n\tsize_t object_size = 0;\n\n\tread_size = min_t(size_t, sizeof(*object), buffer->data_size - offset);\n\tif (offset > buffer->data_size || read_size < sizeof(*hdr))\n\t\treturn 0;\n\tif (u) {\n\t\tif (copy_from_user(object, u + offset, read_size))\n\t\t\treturn 0;\n\t} else {\n\t\tif (binder_alloc_copy_from_buffer(&proc->alloc, object, buffer,\n\t\t\t\t\t\t  offset, read_size))\n\t\t\treturn 0;\n\t}\n\n\t \n\thdr = &object->hdr;\n\tswitch (hdr->type) {\n\tcase BINDER_TYPE_BINDER:\n\tcase BINDER_TYPE_WEAK_BINDER:\n\tcase BINDER_TYPE_HANDLE:\n\tcase BINDER_TYPE_WEAK_HANDLE:\n\t\tobject_size = sizeof(struct flat_binder_object);\n\t\tbreak;\n\tcase BINDER_TYPE_FD:\n\t\tobject_size = sizeof(struct binder_fd_object);\n\t\tbreak;\n\tcase BINDER_TYPE_PTR:\n\t\tobject_size = sizeof(struct binder_buffer_object);\n\t\tbreak;\n\tcase BINDER_TYPE_FDA:\n\t\tobject_size = sizeof(struct binder_fd_array_object);\n\t\tbreak;\n\tdefault:\n\t\treturn 0;\n\t}\n\tif (offset <= buffer->data_size - object_size &&\n\t    buffer->data_size >= object_size)\n\t\treturn object_size;\n\telse\n\t\treturn 0;\n}\n\n \nstatic struct binder_buffer_object *binder_validate_ptr(\n\t\t\t\t\t\tstruct binder_proc *proc,\n\t\t\t\t\t\tstruct binder_buffer *b,\n\t\t\t\t\t\tstruct binder_object *object,\n\t\t\t\t\t\tbinder_size_t index,\n\t\t\t\t\t\tbinder_size_t start_offset,\n\t\t\t\t\t\tbinder_size_t *object_offsetp,\n\t\t\t\t\t\tbinder_size_t num_valid)\n{\n\tsize_t object_size;\n\tbinder_size_t object_offset;\n\tunsigned long buffer_offset;\n\n\tif (index >= num_valid)\n\t\treturn NULL;\n\n\tbuffer_offset = start_offset + sizeof(binder_size_t) * index;\n\tif (binder_alloc_copy_from_buffer(&proc->alloc, &object_offset,\n\t\t\t\t\t  b, buffer_offset,\n\t\t\t\t\t  sizeof(object_offset)))\n\t\treturn NULL;\n\tobject_size = binder_get_object(proc, NULL, b, object_offset, object);\n\tif (!object_size || object->hdr.type != BINDER_TYPE_PTR)\n\t\treturn NULL;\n\tif (object_offsetp)\n\t\t*object_offsetp = object_offset;\n\n\treturn &object->bbo;\n}\n\n \nstatic bool binder_validate_fixup(struct binder_proc *proc,\n\t\t\t\t  struct binder_buffer *b,\n\t\t\t\t  binder_size_t objects_start_offset,\n\t\t\t\t  binder_size_t buffer_obj_offset,\n\t\t\t\t  binder_size_t fixup_offset,\n\t\t\t\t  binder_size_t last_obj_offset,\n\t\t\t\t  binder_size_t last_min_offset)\n{\n\tif (!last_obj_offset) {\n\t\t \n\t\treturn false;\n\t}\n\n\twhile (last_obj_offset != buffer_obj_offset) {\n\t\tunsigned long buffer_offset;\n\t\tstruct binder_object last_object;\n\t\tstruct binder_buffer_object *last_bbo;\n\t\tsize_t object_size = binder_get_object(proc, NULL, b,\n\t\t\t\t\t\t       last_obj_offset,\n\t\t\t\t\t\t       &last_object);\n\t\tif (object_size != sizeof(*last_bbo))\n\t\t\treturn false;\n\n\t\tlast_bbo = &last_object.bbo;\n\t\t \n\t\tif ((last_bbo->flags & BINDER_BUFFER_FLAG_HAS_PARENT) == 0)\n\t\t\treturn false;\n\t\tlast_min_offset = last_bbo->parent_offset + sizeof(uintptr_t);\n\t\tbuffer_offset = objects_start_offset +\n\t\t\tsizeof(binder_size_t) * last_bbo->parent;\n\t\tif (binder_alloc_copy_from_buffer(&proc->alloc,\n\t\t\t\t\t\t  &last_obj_offset,\n\t\t\t\t\t\t  b, buffer_offset,\n\t\t\t\t\t\t  sizeof(last_obj_offset)))\n\t\t\treturn false;\n\t}\n\treturn (fixup_offset >= last_min_offset);\n}\n\n \nstruct binder_task_work_cb {\n\tstruct callback_head twork;\n\tstruct file *file;\n};\n\n \nstatic void binder_do_fd_close(struct callback_head *twork)\n{\n\tstruct binder_task_work_cb *twcb = container_of(twork,\n\t\t\tstruct binder_task_work_cb, twork);\n\n\tfput(twcb->file);\n\tkfree(twcb);\n}\n\n \nstatic void binder_deferred_fd_close(int fd)\n{\n\tstruct binder_task_work_cb *twcb;\n\n\ttwcb = kzalloc(sizeof(*twcb), GFP_KERNEL);\n\tif (!twcb)\n\t\treturn;\n\tinit_task_work(&twcb->twork, binder_do_fd_close);\n\ttwcb->file = close_fd_get_file(fd);\n\tif (twcb->file) {\n\t\t \n\t\tget_file(twcb->file);\n\t\tfilp_close(twcb->file, current->files);\n\t\ttask_work_add(current, &twcb->twork, TWA_RESUME);\n\t} else {\n\t\tkfree(twcb);\n\t}\n}\n\nstatic void binder_transaction_buffer_release(struct binder_proc *proc,\n\t\t\t\t\t      struct binder_thread *thread,\n\t\t\t\t\t      struct binder_buffer *buffer,\n\t\t\t\t\t      binder_size_t off_end_offset,\n\t\t\t\t\t      bool is_failure)\n{\n\tint debug_id = buffer->debug_id;\n\tbinder_size_t off_start_offset, buffer_offset;\n\n\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t     \"%d buffer release %d, size %zd-%zd, failed at %llx\\n\",\n\t\t     proc->pid, buffer->debug_id,\n\t\t     buffer->data_size, buffer->offsets_size,\n\t\t     (unsigned long long)off_end_offset);\n\n\tif (buffer->target_node)\n\t\tbinder_dec_node(buffer->target_node, 1, 0);\n\n\toff_start_offset = ALIGN(buffer->data_size, sizeof(void *));\n\n\tfor (buffer_offset = off_start_offset; buffer_offset < off_end_offset;\n\t     buffer_offset += sizeof(binder_size_t)) {\n\t\tstruct binder_object_header *hdr;\n\t\tsize_t object_size = 0;\n\t\tstruct binder_object object;\n\t\tbinder_size_t object_offset;\n\n\t\tif (!binder_alloc_copy_from_buffer(&proc->alloc, &object_offset,\n\t\t\t\t\t\t   buffer, buffer_offset,\n\t\t\t\t\t\t   sizeof(object_offset)))\n\t\t\tobject_size = binder_get_object(proc, NULL, buffer,\n\t\t\t\t\t\t\tobject_offset, &object);\n\t\tif (object_size == 0) {\n\t\t\tpr_err(\"transaction release %d bad object at offset %lld, size %zd\\n\",\n\t\t\t       debug_id, (u64)object_offset, buffer->data_size);\n\t\t\tcontinue;\n\t\t}\n\t\thdr = &object.hdr;\n\t\tswitch (hdr->type) {\n\t\tcase BINDER_TYPE_BINDER:\n\t\tcase BINDER_TYPE_WEAK_BINDER: {\n\t\t\tstruct flat_binder_object *fp;\n\t\t\tstruct binder_node *node;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tnode = binder_get_node(proc, fp->binder);\n\t\t\tif (node == NULL) {\n\t\t\t\tpr_err(\"transaction release %d bad node %016llx\\n\",\n\t\t\t\t       debug_id, (u64)fp->binder);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t\t     \"        node %d u%016llx\\n\",\n\t\t\t\t     node->debug_id, (u64)node->ptr);\n\t\t\tbinder_dec_node(node, hdr->type == BINDER_TYPE_BINDER,\n\t\t\t\t\t0);\n\t\t\tbinder_put_node(node);\n\t\t} break;\n\t\tcase BINDER_TYPE_HANDLE:\n\t\tcase BINDER_TYPE_WEAK_HANDLE: {\n\t\t\tstruct flat_binder_object *fp;\n\t\t\tstruct binder_ref_data rdata;\n\t\t\tint ret;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_dec_ref_for_handle(proc, fp->handle,\n\t\t\t\thdr->type == BINDER_TYPE_HANDLE, &rdata);\n\n\t\t\tif (ret) {\n\t\t\t\tpr_err(\"transaction release %d bad handle %d, ret = %d\\n\",\n\t\t\t\t debug_id, fp->handle, ret);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t\t     \"        ref %d desc %d\\n\",\n\t\t\t\t     rdata.debug_id, rdata.desc);\n\t\t} break;\n\n\t\tcase BINDER_TYPE_FD: {\n\t\t\t \n\t\t} break;\n\t\tcase BINDER_TYPE_PTR:\n\t\t\t \n\t\t\tbreak;\n\t\tcase BINDER_TYPE_FDA: {\n\t\t\tstruct binder_fd_array_object *fda;\n\t\t\tstruct binder_buffer_object *parent;\n\t\t\tstruct binder_object ptr_object;\n\t\t\tbinder_size_t fda_offset;\n\t\t\tsize_t fd_index;\n\t\t\tbinder_size_t fd_buf_size;\n\t\t\tbinder_size_t num_valid;\n\n\t\t\tif (is_failure) {\n\t\t\t\t \n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnum_valid = (buffer_offset - off_start_offset) /\n\t\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tfda = to_binder_fd_array_object(hdr);\n\t\t\tparent = binder_validate_ptr(proc, buffer, &ptr_object,\n\t\t\t\t\t\t     fda->parent,\n\t\t\t\t\t\t     off_start_offset,\n\t\t\t\t\t\t     NULL,\n\t\t\t\t\t\t     num_valid);\n\t\t\tif (!parent) {\n\t\t\t\tpr_err(\"transaction release %d bad parent offset\\n\",\n\t\t\t\t       debug_id);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfd_buf_size = sizeof(u32) * fda->num_fds;\n\t\t\tif (fda->num_fds >= SIZE_MAX / sizeof(u32)) {\n\t\t\t\tpr_err(\"transaction release %d invalid number of fds (%lld)\\n\",\n\t\t\t\t       debug_id, (u64)fda->num_fds);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (fd_buf_size > parent->length ||\n\t\t\t    fda->parent_offset > parent->length - fd_buf_size) {\n\t\t\t\t \n\t\t\t\tpr_err(\"transaction release %d not enough space for %lld fds in buffer\\n\",\n\t\t\t\t       debug_id, (u64)fda->num_fds);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t \n\t\t\tfda_offset =\n\t\t\t    (parent->buffer - (uintptr_t)buffer->user_data) +\n\t\t\t    fda->parent_offset;\n\t\t\tfor (fd_index = 0; fd_index < fda->num_fds;\n\t\t\t     fd_index++) {\n\t\t\t\tu32 fd;\n\t\t\t\tint err;\n\t\t\t\tbinder_size_t offset = fda_offset +\n\t\t\t\t\tfd_index * sizeof(fd);\n\n\t\t\t\terr = binder_alloc_copy_from_buffer(\n\t\t\t\t\t\t&proc->alloc, &fd, buffer,\n\t\t\t\t\t\toffset, sizeof(fd));\n\t\t\t\tWARN_ON(err);\n\t\t\t\tif (!err) {\n\t\t\t\t\tbinder_deferred_fd_close(fd);\n\t\t\t\t\t \n\t\t\t\t\tif (thread)\n\t\t\t\t\t\tthread->looper_need_return = true;\n\t\t\t\t}\n\t\t\t}\n\t\t} break;\n\t\tdefault:\n\t\t\tpr_err(\"transaction release %d bad object type %x\\n\",\n\t\t\t\tdebug_id, hdr->type);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nstatic inline void binder_release_entire_buffer(struct binder_proc *proc,\n\t\t\t\t\t\tstruct binder_thread *thread,\n\t\t\t\t\t\tstruct binder_buffer *buffer,\n\t\t\t\t\t\tbool is_failure)\n{\n\tbinder_size_t off_end_offset;\n\n\toff_end_offset = ALIGN(buffer->data_size, sizeof(void *));\n\toff_end_offset += buffer->offsets_size;\n\n\tbinder_transaction_buffer_release(proc, thread, buffer,\n\t\t\t\t\t  off_end_offset, is_failure);\n}\n\nstatic int binder_translate_binder(struct flat_binder_object *fp,\n\t\t\t\t   struct binder_transaction *t,\n\t\t\t\t   struct binder_thread *thread)\n{\n\tstruct binder_node *node;\n\tstruct binder_proc *proc = thread->proc;\n\tstruct binder_proc *target_proc = t->to_proc;\n\tstruct binder_ref_data rdata;\n\tint ret = 0;\n\n\tnode = binder_get_node(proc, fp->binder);\n\tif (!node) {\n\t\tnode = binder_new_node(proc, fp);\n\t\tif (!node)\n\t\t\treturn -ENOMEM;\n\t}\n\tif (fp->cookie != node->cookie) {\n\t\tbinder_user_error(\"%d:%d sending u%016llx node %d, cookie mismatch %016llx != %016llx\\n\",\n\t\t\t\t  proc->pid, thread->pid, (u64)fp->binder,\n\t\t\t\t  node->debug_id, (u64)fp->cookie,\n\t\t\t\t  (u64)node->cookie);\n\t\tret = -EINVAL;\n\t\tgoto done;\n\t}\n\tif (security_binder_transfer_binder(proc->cred, target_proc->cred)) {\n\t\tret = -EPERM;\n\t\tgoto done;\n\t}\n\n\tret = binder_inc_ref_for_node(target_proc, node,\n\t\t\tfp->hdr.type == BINDER_TYPE_BINDER,\n\t\t\t&thread->todo, &rdata);\n\tif (ret)\n\t\tgoto done;\n\n\tif (fp->hdr.type == BINDER_TYPE_BINDER)\n\t\tfp->hdr.type = BINDER_TYPE_HANDLE;\n\telse\n\t\tfp->hdr.type = BINDER_TYPE_WEAK_HANDLE;\n\tfp->binder = 0;\n\tfp->handle = rdata.desc;\n\tfp->cookie = 0;\n\n\ttrace_binder_transaction_node_to_ref(t, node, &rdata);\n\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t     \"        node %d u%016llx -> ref %d desc %d\\n\",\n\t\t     node->debug_id, (u64)node->ptr,\n\t\t     rdata.debug_id, rdata.desc);\ndone:\n\tbinder_put_node(node);\n\treturn ret;\n}\n\nstatic int binder_translate_handle(struct flat_binder_object *fp,\n\t\t\t\t   struct binder_transaction *t,\n\t\t\t\t   struct binder_thread *thread)\n{\n\tstruct binder_proc *proc = thread->proc;\n\tstruct binder_proc *target_proc = t->to_proc;\n\tstruct binder_node *node;\n\tstruct binder_ref_data src_rdata;\n\tint ret = 0;\n\n\tnode = binder_get_node_from_ref(proc, fp->handle,\n\t\t\tfp->hdr.type == BINDER_TYPE_HANDLE, &src_rdata);\n\tif (!node) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid handle, %d\\n\",\n\t\t\t\t  proc->pid, thread->pid, fp->handle);\n\t\treturn -EINVAL;\n\t}\n\tif (security_binder_transfer_binder(proc->cred, target_proc->cred)) {\n\t\tret = -EPERM;\n\t\tgoto done;\n\t}\n\n\tbinder_node_lock(node);\n\tif (node->proc == target_proc) {\n\t\tif (fp->hdr.type == BINDER_TYPE_HANDLE)\n\t\t\tfp->hdr.type = BINDER_TYPE_BINDER;\n\t\telse\n\t\t\tfp->hdr.type = BINDER_TYPE_WEAK_BINDER;\n\t\tfp->binder = node->ptr;\n\t\tfp->cookie = node->cookie;\n\t\tif (node->proc)\n\t\t\tbinder_inner_proc_lock(node->proc);\n\t\telse\n\t\t\t__acquire(&node->proc->inner_lock);\n\t\tbinder_inc_node_nilocked(node,\n\t\t\t\t\t fp->hdr.type == BINDER_TYPE_BINDER,\n\t\t\t\t\t 0, NULL);\n\t\tif (node->proc)\n\t\t\tbinder_inner_proc_unlock(node->proc);\n\t\telse\n\t\t\t__release(&node->proc->inner_lock);\n\t\ttrace_binder_transaction_ref_to_node(t, node, &src_rdata);\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"        ref %d desc %d -> node %d u%016llx\\n\",\n\t\t\t     src_rdata.debug_id, src_rdata.desc, node->debug_id,\n\t\t\t     (u64)node->ptr);\n\t\tbinder_node_unlock(node);\n\t} else {\n\t\tstruct binder_ref_data dest_rdata;\n\n\t\tbinder_node_unlock(node);\n\t\tret = binder_inc_ref_for_node(target_proc, node,\n\t\t\t\tfp->hdr.type == BINDER_TYPE_HANDLE,\n\t\t\t\tNULL, &dest_rdata);\n\t\tif (ret)\n\t\t\tgoto done;\n\n\t\tfp->binder = 0;\n\t\tfp->handle = dest_rdata.desc;\n\t\tfp->cookie = 0;\n\t\ttrace_binder_transaction_ref_to_ref(t, node, &src_rdata,\n\t\t\t\t\t\t    &dest_rdata);\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"        ref %d desc %d -> ref %d desc %d (node %d)\\n\",\n\t\t\t     src_rdata.debug_id, src_rdata.desc,\n\t\t\t     dest_rdata.debug_id, dest_rdata.desc,\n\t\t\t     node->debug_id);\n\t}\ndone:\n\tbinder_put_node(node);\n\treturn ret;\n}\n\nstatic int binder_translate_fd(u32 fd, binder_size_t fd_offset,\n\t\t\t       struct binder_transaction *t,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       struct binder_transaction *in_reply_to)\n{\n\tstruct binder_proc *proc = thread->proc;\n\tstruct binder_proc *target_proc = t->to_proc;\n\tstruct binder_txn_fd_fixup *fixup;\n\tstruct file *file;\n\tint ret = 0;\n\tbool target_allows_fd;\n\n\tif (in_reply_to)\n\t\ttarget_allows_fd = !!(in_reply_to->flags & TF_ACCEPT_FDS);\n\telse\n\t\ttarget_allows_fd = t->buffer->target_node->accept_fds;\n\tif (!target_allows_fd) {\n\t\tbinder_user_error(\"%d:%d got %s with fd, %d, but target does not allow fds\\n\",\n\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t  in_reply_to ? \"reply\" : \"transaction\",\n\t\t\t\t  fd);\n\t\tret = -EPERM;\n\t\tgoto err_fd_not_accepted;\n\t}\n\n\tfile = fget(fd);\n\tif (!file) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid fd, %d\\n\",\n\t\t\t\t  proc->pid, thread->pid, fd);\n\t\tret = -EBADF;\n\t\tgoto err_fget;\n\t}\n\tret = security_binder_transfer_file(proc->cred, target_proc->cred, file);\n\tif (ret < 0) {\n\t\tret = -EPERM;\n\t\tgoto err_security;\n\t}\n\n\t \n\tfixup = kzalloc(sizeof(*fixup), GFP_KERNEL);\n\tif (!fixup) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc;\n\t}\n\tfixup->file = file;\n\tfixup->offset = fd_offset;\n\tfixup->target_fd = -1;\n\ttrace_binder_transaction_fd_send(t, fd, fixup->offset);\n\tlist_add_tail(&fixup->fixup_entry, &t->fd_fixups);\n\n\treturn ret;\n\nerr_alloc:\nerr_security:\n\tfput(file);\nerr_fget:\nerr_fd_not_accepted:\n\treturn ret;\n}\n\n \nstruct binder_ptr_fixup {\n\tbinder_size_t offset;\n\tsize_t skip_size;\n\tbinder_uintptr_t fixup_data;\n\tstruct list_head node;\n};\n\n \nstruct binder_sg_copy {\n\tbinder_size_t offset;\n\tconst void __user *sender_uaddr;\n\tsize_t length;\n\tstruct list_head node;\n};\n\n \nstatic int binder_do_deferred_txn_copies(struct binder_alloc *alloc,\n\t\t\t\t\t struct binder_buffer *buffer,\n\t\t\t\t\t struct list_head *sgc_head,\n\t\t\t\t\t struct list_head *pf_head)\n{\n\tint ret = 0;\n\tstruct binder_sg_copy *sgc, *tmpsgc;\n\tstruct binder_ptr_fixup *tmppf;\n\tstruct binder_ptr_fixup *pf =\n\t\tlist_first_entry_or_null(pf_head, struct binder_ptr_fixup,\n\t\t\t\t\t node);\n\n\tlist_for_each_entry_safe(sgc, tmpsgc, sgc_head, node) {\n\t\tsize_t bytes_copied = 0;\n\n\t\twhile (bytes_copied < sgc->length) {\n\t\t\tsize_t copy_size;\n\t\t\tsize_t bytes_left = sgc->length - bytes_copied;\n\t\t\tsize_t offset = sgc->offset + bytes_copied;\n\n\t\t\t \n\t\t\tcopy_size = pf ? min(bytes_left, (size_t)pf->offset - offset)\n\t\t\t\t       : bytes_left;\n\t\t\tif (!ret && copy_size)\n\t\t\t\tret = binder_alloc_copy_user_to_buffer(\n\t\t\t\t\t\talloc, buffer,\n\t\t\t\t\t\toffset,\n\t\t\t\t\t\tsgc->sender_uaddr + bytes_copied,\n\t\t\t\t\t\tcopy_size);\n\t\t\tbytes_copied += copy_size;\n\t\t\tif (copy_size != bytes_left) {\n\t\t\t\tBUG_ON(!pf);\n\t\t\t\t \n\t\t\t\tif (pf->skip_size) {\n\t\t\t\t\t \n\t\t\t\t\tbytes_copied += pf->skip_size;\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tif (!ret)\n\t\t\t\t\t\tret = binder_alloc_copy_to_buffer(\n\t\t\t\t\t\t\talloc, buffer,\n\t\t\t\t\t\t\tpf->offset,\n\t\t\t\t\t\t\t&pf->fixup_data,\n\t\t\t\t\t\t\tsizeof(pf->fixup_data));\n\t\t\t\t\tbytes_copied += sizeof(pf->fixup_data);\n\t\t\t\t}\n\t\t\t\tlist_del(&pf->node);\n\t\t\t\tkfree(pf);\n\t\t\t\tpf = list_first_entry_or_null(pf_head,\n\t\t\t\t\t\tstruct binder_ptr_fixup, node);\n\t\t\t}\n\t\t}\n\t\tlist_del(&sgc->node);\n\t\tkfree(sgc);\n\t}\n\tlist_for_each_entry_safe(pf, tmppf, pf_head, node) {\n\t\tBUG_ON(pf->skip_size == 0);\n\t\tlist_del(&pf->node);\n\t\tkfree(pf);\n\t}\n\tBUG_ON(!list_empty(sgc_head));\n\n\treturn ret > 0 ? -EINVAL : ret;\n}\n\n \nstatic void binder_cleanup_deferred_txn_lists(struct list_head *sgc_head,\n\t\t\t\t\t      struct list_head *pf_head)\n{\n\tstruct binder_sg_copy *sgc, *tmpsgc;\n\tstruct binder_ptr_fixup *pf, *tmppf;\n\n\tlist_for_each_entry_safe(sgc, tmpsgc, sgc_head, node) {\n\t\tlist_del(&sgc->node);\n\t\tkfree(sgc);\n\t}\n\tlist_for_each_entry_safe(pf, tmppf, pf_head, node) {\n\t\tlist_del(&pf->node);\n\t\tkfree(pf);\n\t}\n}\n\n \nstatic int binder_defer_copy(struct list_head *sgc_head, binder_size_t offset,\n\t\t\t     const void __user *sender_uaddr, size_t length)\n{\n\tstruct binder_sg_copy *bc = kzalloc(sizeof(*bc), GFP_KERNEL);\n\n\tif (!bc)\n\t\treturn -ENOMEM;\n\n\tbc->offset = offset;\n\tbc->sender_uaddr = sender_uaddr;\n\tbc->length = length;\n\tINIT_LIST_HEAD(&bc->node);\n\n\t \n\tlist_add_tail(&bc->node, sgc_head);\n\n\treturn 0;\n}\n\n \nstatic int binder_add_fixup(struct list_head *pf_head, binder_size_t offset,\n\t\t\t    binder_uintptr_t fixup, size_t skip_size)\n{\n\tstruct binder_ptr_fixup *pf = kzalloc(sizeof(*pf), GFP_KERNEL);\n\tstruct binder_ptr_fixup *tmppf;\n\n\tif (!pf)\n\t\treturn -ENOMEM;\n\n\tpf->offset = offset;\n\tpf->fixup_data = fixup;\n\tpf->skip_size = skip_size;\n\tINIT_LIST_HEAD(&pf->node);\n\n\t \n\tlist_for_each_entry_reverse(tmppf, pf_head, node) {\n\t\tif (tmppf->offset < pf->offset) {\n\t\t\tlist_add(&pf->node, &tmppf->node);\n\t\t\treturn 0;\n\t\t}\n\t}\n\t \n\tlist_add(&pf->node, pf_head);\n\treturn 0;\n}\n\nstatic int binder_translate_fd_array(struct list_head *pf_head,\n\t\t\t\t     struct binder_fd_array_object *fda,\n\t\t\t\t     const void __user *sender_ubuffer,\n\t\t\t\t     struct binder_buffer_object *parent,\n\t\t\t\t     struct binder_buffer_object *sender_uparent,\n\t\t\t\t     struct binder_transaction *t,\n\t\t\t\t     struct binder_thread *thread,\n\t\t\t\t     struct binder_transaction *in_reply_to)\n{\n\tbinder_size_t fdi, fd_buf_size;\n\tbinder_size_t fda_offset;\n\tconst void __user *sender_ufda_base;\n\tstruct binder_proc *proc = thread->proc;\n\tint ret;\n\n\tif (fda->num_fds == 0)\n\t\treturn 0;\n\n\tfd_buf_size = sizeof(u32) * fda->num_fds;\n\tif (fda->num_fds >= SIZE_MAX / sizeof(u32)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid number of fds (%lld)\\n\",\n\t\t\t\t  proc->pid, thread->pid, (u64)fda->num_fds);\n\t\treturn -EINVAL;\n\t}\n\tif (fd_buf_size > parent->length ||\n\t    fda->parent_offset > parent->length - fd_buf_size) {\n\t\t \n\t\tbinder_user_error(\"%d:%d not enough space to store %lld fds in buffer\\n\",\n\t\t\t\t  proc->pid, thread->pid, (u64)fda->num_fds);\n\t\treturn -EINVAL;\n\t}\n\t \n\tfda_offset = (parent->buffer - (uintptr_t)t->buffer->user_data) +\n\t\tfda->parent_offset;\n\tsender_ufda_base = (void __user *)(uintptr_t)sender_uparent->buffer +\n\t\t\t\tfda->parent_offset;\n\n\tif (!IS_ALIGNED((unsigned long)fda_offset, sizeof(u32)) ||\n\t    !IS_ALIGNED((unsigned long)sender_ufda_base, sizeof(u32))) {\n\t\tbinder_user_error(\"%d:%d parent offset not aligned correctly.\\n\",\n\t\t\t\t  proc->pid, thread->pid);\n\t\treturn -EINVAL;\n\t}\n\tret = binder_add_fixup(pf_head, fda_offset, 0, fda->num_fds * sizeof(u32));\n\tif (ret)\n\t\treturn ret;\n\n\tfor (fdi = 0; fdi < fda->num_fds; fdi++) {\n\t\tu32 fd;\n\t\tbinder_size_t offset = fda_offset + fdi * sizeof(fd);\n\t\tbinder_size_t sender_uoffset = fdi * sizeof(fd);\n\n\t\tret = copy_from_user(&fd, sender_ufda_base + sender_uoffset, sizeof(fd));\n\t\tif (!ret)\n\t\t\tret = binder_translate_fd(fd, offset, t, thread,\n\t\t\t\t\t\t  in_reply_to);\n\t\tif (ret)\n\t\t\treturn ret > 0 ? -EINVAL : ret;\n\t}\n\treturn 0;\n}\n\nstatic int binder_fixup_parent(struct list_head *pf_head,\n\t\t\t       struct binder_transaction *t,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       struct binder_buffer_object *bp,\n\t\t\t       binder_size_t off_start_offset,\n\t\t\t       binder_size_t num_valid,\n\t\t\t       binder_size_t last_fixup_obj_off,\n\t\t\t       binder_size_t last_fixup_min_off)\n{\n\tstruct binder_buffer_object *parent;\n\tstruct binder_buffer *b = t->buffer;\n\tstruct binder_proc *proc = thread->proc;\n\tstruct binder_proc *target_proc = t->to_proc;\n\tstruct binder_object object;\n\tbinder_size_t buffer_offset;\n\tbinder_size_t parent_offset;\n\n\tif (!(bp->flags & BINDER_BUFFER_FLAG_HAS_PARENT))\n\t\treturn 0;\n\n\tparent = binder_validate_ptr(target_proc, b, &object, bp->parent,\n\t\t\t\t     off_start_offset, &parent_offset,\n\t\t\t\t     num_valid);\n\tif (!parent) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid parent offset or type\\n\",\n\t\t\t\t  proc->pid, thread->pid);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!binder_validate_fixup(target_proc, b, off_start_offset,\n\t\t\t\t   parent_offset, bp->parent_offset,\n\t\t\t\t   last_fixup_obj_off,\n\t\t\t\t   last_fixup_min_off)) {\n\t\tbinder_user_error(\"%d:%d got transaction with out-of-order buffer fixup\\n\",\n\t\t\t\t  proc->pid, thread->pid);\n\t\treturn -EINVAL;\n\t}\n\n\tif (parent->length < sizeof(binder_uintptr_t) ||\n\t    bp->parent_offset > parent->length - sizeof(binder_uintptr_t)) {\n\t\t \n\t\tbinder_user_error(\"%d:%d got transaction with invalid parent offset\\n\",\n\t\t\t\t  proc->pid, thread->pid);\n\t\treturn -EINVAL;\n\t}\n\tbuffer_offset = bp->parent_offset +\n\t\t\t(uintptr_t)parent->buffer - (uintptr_t)b->user_data;\n\treturn binder_add_fixup(pf_head, buffer_offset, bp->buffer, 0);\n}\n\n \nstatic bool binder_can_update_transaction(struct binder_transaction *t1,\n\t\t\t\t\t  struct binder_transaction *t2)\n{\n\tif ((t1->flags & t2->flags & (TF_ONE_WAY | TF_UPDATE_TXN)) !=\n\t    (TF_ONE_WAY | TF_UPDATE_TXN) || !t1->to_proc || !t2->to_proc)\n\t\treturn false;\n\tif (t1->to_proc->tsk == t2->to_proc->tsk && t1->code == t2->code &&\n\t    t1->flags == t2->flags && t1->buffer->pid == t2->buffer->pid &&\n\t    t1->buffer->target_node->ptr == t2->buffer->target_node->ptr &&\n\t    t1->buffer->target_node->cookie == t2->buffer->target_node->cookie)\n\t\treturn true;\n\treturn false;\n}\n\n \nstatic struct binder_transaction *\nbinder_find_outdated_transaction_ilocked(struct binder_transaction *t,\n\t\t\t\t\t struct list_head *target_list)\n{\n\tstruct binder_work *w;\n\n\tlist_for_each_entry(w, target_list, entry) {\n\t\tstruct binder_transaction *t_queued;\n\n\t\tif (w->type != BINDER_WORK_TRANSACTION)\n\t\t\tcontinue;\n\t\tt_queued = container_of(w, struct binder_transaction, work);\n\t\tif (binder_can_update_transaction(t_queued, t))\n\t\t\treturn t_queued;\n\t}\n\treturn NULL;\n}\n\n \nstatic int binder_proc_transaction(struct binder_transaction *t,\n\t\t\t\t    struct binder_proc *proc,\n\t\t\t\t    struct binder_thread *thread)\n{\n\tstruct binder_node *node = t->buffer->target_node;\n\tbool oneway = !!(t->flags & TF_ONE_WAY);\n\tbool pending_async = false;\n\tstruct binder_transaction *t_outdated = NULL;\n\tbool frozen = false;\n\n\tBUG_ON(!node);\n\tbinder_node_lock(node);\n\tif (oneway) {\n\t\tBUG_ON(thread);\n\t\tif (node->has_async_transaction)\n\t\t\tpending_async = true;\n\t\telse\n\t\t\tnode->has_async_transaction = true;\n\t}\n\n\tbinder_inner_proc_lock(proc);\n\tif (proc->is_frozen) {\n\t\tfrozen = true;\n\t\tproc->sync_recv |= !oneway;\n\t\tproc->async_recv |= oneway;\n\t}\n\n\tif ((frozen && !oneway) || proc->is_dead ||\n\t\t\t(thread && thread->is_dead)) {\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_node_unlock(node);\n\t\treturn frozen ? BR_FROZEN_REPLY : BR_DEAD_REPLY;\n\t}\n\n\tif (!thread && !pending_async)\n\t\tthread = binder_select_thread_ilocked(proc);\n\n\tif (thread) {\n\t\tbinder_enqueue_thread_work_ilocked(thread, &t->work);\n\t} else if (!pending_async) {\n\t\tbinder_enqueue_work_ilocked(&t->work, &proc->todo);\n\t} else {\n\t\tif ((t->flags & TF_UPDATE_TXN) && frozen) {\n\t\t\tt_outdated = binder_find_outdated_transaction_ilocked(t,\n\t\t\t\t\t\t\t\t\t      &node->async_todo);\n\t\t\tif (t_outdated) {\n\t\t\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t\t\t     \"txn %d supersedes %d\\n\",\n\t\t\t\t\t     t->debug_id, t_outdated->debug_id);\n\t\t\t\tlist_del_init(&t_outdated->work.entry);\n\t\t\t\tproc->outstanding_txns--;\n\t\t\t}\n\t\t}\n\t\tbinder_enqueue_work_ilocked(&t->work, &node->async_todo);\n\t}\n\n\tif (!pending_async)\n\t\tbinder_wakeup_thread_ilocked(proc, thread, !oneway  );\n\n\tproc->outstanding_txns++;\n\tbinder_inner_proc_unlock(proc);\n\tbinder_node_unlock(node);\n\n\t \n\tif (t_outdated) {\n\t\tstruct binder_buffer *buffer = t_outdated->buffer;\n\n\t\tt_outdated->buffer = NULL;\n\t\tbuffer->transaction = NULL;\n\t\ttrace_binder_transaction_update_buffer_release(buffer);\n\t\tbinder_release_entire_buffer(proc, NULL, buffer, false);\n\t\tbinder_alloc_free_buf(&proc->alloc, buffer);\n\t\tkfree(t_outdated);\n\t\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\n\t}\n\n\tif (oneway && frozen)\n\t\treturn BR_TRANSACTION_PENDING_FROZEN;\n\n\treturn 0;\n}\n\n \nstatic struct binder_node *binder_get_node_refs_for_txn(\n\t\tstruct binder_node *node,\n\t\tstruct binder_proc **procp,\n\t\tuint32_t *error)\n{\n\tstruct binder_node *target_node = NULL;\n\n\tbinder_node_inner_lock(node);\n\tif (node->proc) {\n\t\ttarget_node = node;\n\t\tbinder_inc_node_nilocked(node, 1, 0, NULL);\n\t\tbinder_inc_node_tmpref_ilocked(node);\n\t\tnode->proc->tmp_ref++;\n\t\t*procp = node->proc;\n\t} else\n\t\t*error = BR_DEAD_REPLY;\n\tbinder_node_inner_unlock(node);\n\n\treturn target_node;\n}\n\nstatic void binder_set_txn_from_error(struct binder_transaction *t, int id,\n\t\t\t\t      uint32_t command, int32_t param)\n{\n\tstruct binder_thread *from = binder_get_txn_from_and_acq_inner(t);\n\n\tif (!from) {\n\t\t \n\t\t__release(&from->proc->inner_lock);\n\t\treturn;\n\t}\n\n\t \n\tif (from->ee.command == BR_OK)\n\t\tbinder_set_extended_error(&from->ee, id, command, param);\n\tbinder_inner_proc_unlock(from->proc);\n\tbinder_thread_dec_tmpref(from);\n}\n\nstatic void binder_transaction(struct binder_proc *proc,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       struct binder_transaction_data *tr, int reply,\n\t\t\t       binder_size_t extra_buffers_size)\n{\n\tint ret;\n\tstruct binder_transaction *t;\n\tstruct binder_work *w;\n\tstruct binder_work *tcomplete;\n\tbinder_size_t buffer_offset = 0;\n\tbinder_size_t off_start_offset, off_end_offset;\n\tbinder_size_t off_min;\n\tbinder_size_t sg_buf_offset, sg_buf_end_offset;\n\tbinder_size_t user_offset = 0;\n\tstruct binder_proc *target_proc = NULL;\n\tstruct binder_thread *target_thread = NULL;\n\tstruct binder_node *target_node = NULL;\n\tstruct binder_transaction *in_reply_to = NULL;\n\tstruct binder_transaction_log_entry *e;\n\tuint32_t return_error = 0;\n\tuint32_t return_error_param = 0;\n\tuint32_t return_error_line = 0;\n\tbinder_size_t last_fixup_obj_off = 0;\n\tbinder_size_t last_fixup_min_off = 0;\n\tstruct binder_context *context = proc->context;\n\tint t_debug_id = atomic_inc_return(&binder_last_id);\n\tktime_t t_start_time = ktime_get();\n\tchar *secctx = NULL;\n\tu32 secctx_sz = 0;\n\tstruct list_head sgc_head;\n\tstruct list_head pf_head;\n\tconst void __user *user_buffer = (const void __user *)\n\t\t\t\t(uintptr_t)tr->data.ptr.buffer;\n\tINIT_LIST_HEAD(&sgc_head);\n\tINIT_LIST_HEAD(&pf_head);\n\n\te = binder_transaction_log_add(&binder_transaction_log);\n\te->debug_id = t_debug_id;\n\te->call_type = reply ? 2 : !!(tr->flags & TF_ONE_WAY);\n\te->from_proc = proc->pid;\n\te->from_thread = thread->pid;\n\te->target_handle = tr->target.handle;\n\te->data_size = tr->data_size;\n\te->offsets_size = tr->offsets_size;\n\tstrscpy(e->context_name, proc->context->name, BINDERFS_MAX_NAME);\n\n\tbinder_inner_proc_lock(proc);\n\tbinder_set_extended_error(&thread->ee, t_debug_id, BR_OK, 0);\n\tbinder_inner_proc_unlock(proc);\n\n\tif (reply) {\n\t\tbinder_inner_proc_lock(proc);\n\t\tin_reply_to = thread->transaction_stack;\n\t\tif (in_reply_to == NULL) {\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with no transaction stack\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_empty_call_stack;\n\t\t}\n\t\tif (in_reply_to->to_thread != thread) {\n\t\t\tspin_lock(&in_reply_to->lock);\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\tproc->pid, thread->pid, in_reply_to->debug_id,\n\t\t\t\tin_reply_to->to_proc ?\n\t\t\t\tin_reply_to->to_proc->pid : 0,\n\t\t\t\tin_reply_to->to_thread ?\n\t\t\t\tin_reply_to->to_thread->pid : 0);\n\t\t\tspin_unlock(&in_reply_to->lock);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\tgoto err_bad_call_stack;\n\t\t}\n\t\tthread->transaction_stack = in_reply_to->to_parent;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_set_nice(in_reply_to->saved_priority);\n\t\ttarget_thread = binder_get_txn_from_and_acq_inner(in_reply_to);\n\t\tif (target_thread == NULL) {\n\t\t\t \n\t\t\t__release(&target_thread->proc->inner_lock);\n\t\t\tbinder_txn_error(\"%d:%d reply target not found\\n\",\n\t\t\t\tthread->pid, proc->pid);\n\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\tif (target_thread->transaction_stack != in_reply_to) {\n\t\t\tbinder_user_error(\"%d:%d got reply transaction with bad target transaction stack %d, expected %d\\n\",\n\t\t\t\tproc->pid, thread->pid,\n\t\t\t\ttarget_thread->transaction_stack ?\n\t\t\t\ttarget_thread->transaction_stack->debug_id : 0,\n\t\t\t\tin_reply_to->debug_id);\n\t\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tin_reply_to = NULL;\n\t\t\ttarget_thread = NULL;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\ttarget_proc = target_thread->proc;\n\t\ttarget_proc->tmp_ref++;\n\t\tbinder_inner_proc_unlock(target_thread->proc);\n\t} else {\n\t\tif (tr->target.handle) {\n\t\t\tstruct binder_ref *ref;\n\n\t\t\t \n\t\t\tbinder_proc_lock(proc);\n\t\t\tref = binder_get_ref_olocked(proc, tr->target.handle,\n\t\t\t\t\t\t     true);\n\t\t\tif (ref) {\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\tref->node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\t} else {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to invalid handle, %u\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid, tr->target.handle);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t}\n\t\t\tbinder_proc_unlock(proc);\n\t\t} else {\n\t\t\tmutex_lock(&context->context_mgr_node_lock);\n\t\t\ttarget_node = context->binder_context_mgr_node;\n\t\t\tif (target_node)\n\t\t\t\ttarget_node = binder_get_node_refs_for_txn(\n\t\t\t\t\t\ttarget_node, &target_proc,\n\t\t\t\t\t\t&return_error);\n\t\t\telse\n\t\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\t\tif (target_node && target_proc->pid == proc->pid) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction to context manager from process owning it\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_invalid_target_handle;\n\t\t\t}\n\t\t}\n\t\tif (!target_node) {\n\t\t\tbinder_txn_error(\"%d:%d cannot find target node\\n\",\n\t\t\t\tthread->pid, proc->pid);\n\t\t\t \n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_dead_binder;\n\t\t}\n\t\te->to_node = target_node->debug_id;\n\t\tif (WARN_ON(proc == target_proc)) {\n\t\t\tbinder_txn_error(\"%d:%d self transactions not allowed\\n\",\n\t\t\t\tthread->pid, proc->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_invalid_target_handle;\n\t\t}\n\t\tif (security_binder_transaction(proc->cred,\n\t\t\t\t\t\ttarget_proc->cred) < 0) {\n\t\t\tbinder_txn_error(\"%d:%d transaction credentials failed\\n\",\n\t\t\t\tthread->pid, proc->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPERM;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_invalid_target_handle;\n\t\t}\n\t\tbinder_inner_proc_lock(proc);\n\n\t\tw = list_first_entry_or_null(&thread->todo,\n\t\t\t\t\t     struct binder_work, entry);\n\t\tif (!(tr->flags & TF_ONE_WAY) && w &&\n\t\t    w->type == BINDER_WORK_TRANSACTION) {\n\t\t\t \n\t\t\tbinder_user_error(\"%d:%d new transaction not allowed when there is a transaction on thread todo\\n\",\n\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EPROTO;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_todo_list;\n\t\t}\n\n\t\tif (!(tr->flags & TF_ONE_WAY) && thread->transaction_stack) {\n\t\t\tstruct binder_transaction *tmp;\n\n\t\t\ttmp = thread->transaction_stack;\n\t\t\tif (tmp->to_thread != thread) {\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tbinder_user_error(\"%d:%d got new transaction with bad transaction stack, transaction %d has target %d:%d\\n\",\n\t\t\t\t\tproc->pid, thread->pid, tmp->debug_id,\n\t\t\t\t\ttmp->to_proc ? tmp->to_proc->pid : 0,\n\t\t\t\t\ttmp->to_thread ?\n\t\t\t\t\ttmp->to_thread->pid : 0);\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EPROTO;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_call_stack;\n\t\t\t}\n\t\t\twhile (tmp) {\n\t\t\t\tstruct binder_thread *from;\n\n\t\t\t\tspin_lock(&tmp->lock);\n\t\t\t\tfrom = tmp->from;\n\t\t\t\tif (from && from->proc == target_proc) {\n\t\t\t\t\tatomic_inc(&from->tmp_ref);\n\t\t\t\t\ttarget_thread = from;\n\t\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tspin_unlock(&tmp->lock);\n\t\t\t\ttmp = tmp->from_parent;\n\t\t\t}\n\t\t}\n\t\tbinder_inner_proc_unlock(proc);\n\t}\n\tif (target_thread)\n\t\te->to_thread = target_thread->pid;\n\te->to_proc = target_proc->pid;\n\n\t \n\tt = kzalloc(sizeof(*t), GFP_KERNEL);\n\tif (t == NULL) {\n\t\tbinder_txn_error(\"%d:%d cannot allocate transaction\\n\",\n\t\t\tthread->pid, proc->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_t_failed;\n\t}\n\tINIT_LIST_HEAD(&t->fd_fixups);\n\tbinder_stats_created(BINDER_STAT_TRANSACTION);\n\tspin_lock_init(&t->lock);\n\n\ttcomplete = kzalloc(sizeof(*tcomplete), GFP_KERNEL);\n\tif (tcomplete == NULL) {\n\t\tbinder_txn_error(\"%d:%d cannot allocate work for transaction\\n\",\n\t\t\tthread->pid, proc->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -ENOMEM;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_alloc_tcomplete_failed;\n\t}\n\tbinder_stats_created(BINDER_STAT_TRANSACTION_COMPLETE);\n\n\tt->debug_id = t_debug_id;\n\tt->start_time = t_start_time;\n\n\tif (reply)\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_REPLY %d -> %d:%d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_thread->pid,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\telse\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d BC_TRANSACTION %d -> %d - node %d, data %016llx-%016llx size %lld-%lld-%lld\\n\",\n\t\t\t     proc->pid, thread->pid, t->debug_id,\n\t\t\t     target_proc->pid, target_node->debug_id,\n\t\t\t     (u64)tr->data.ptr.buffer,\n\t\t\t     (u64)tr->data.ptr.offsets,\n\t\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t\t     (u64)extra_buffers_size);\n\n\tif (!reply && !(tr->flags & TF_ONE_WAY))\n\t\tt->from = thread;\n\telse\n\t\tt->from = NULL;\n\tt->from_pid = proc->pid;\n\tt->from_tid = thread->pid;\n\tt->sender_euid = task_euid(proc->tsk);\n\tt->to_proc = target_proc;\n\tt->to_thread = target_thread;\n\tt->code = tr->code;\n\tt->flags = tr->flags;\n\tt->priority = task_nice(current);\n\n\tif (target_node && target_node->txn_security_ctx) {\n\t\tu32 secid;\n\t\tsize_t added_size;\n\n\t\tsecurity_cred_getsecid(proc->cred, &secid);\n\t\tret = security_secid_to_secctx(secid, &secctx, &secctx_sz);\n\t\tif (ret) {\n\t\t\tbinder_txn_error(\"%d:%d failed to get security context\\n\",\n\t\t\t\tthread->pid, proc->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = ret;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_get_secctx_failed;\n\t\t}\n\t\tadded_size = ALIGN(secctx_sz, sizeof(u64));\n\t\textra_buffers_size += added_size;\n\t\tif (extra_buffers_size < added_size) {\n\t\t\tbinder_txn_error(\"%d:%d integer overflow of extra_buffers_size\\n\",\n\t\t\t\tthread->pid, proc->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_extra_size;\n\t\t}\n\t}\n\n\ttrace_binder_transaction(reply, t, target_node);\n\n\tt->buffer = binder_alloc_new_buf(&target_proc->alloc, tr->data_size,\n\t\ttr->offsets_size, extra_buffers_size,\n\t\t!reply && (t->flags & TF_ONE_WAY), current->tgid);\n\tif (IS_ERR(t->buffer)) {\n\t\tchar *s;\n\n\t\tret = PTR_ERR(t->buffer);\n\t\ts = (ret == -ESRCH) ? \": vma cleared, target dead or dying\"\n\t\t\t: (ret == -ENOSPC) ? \": no space left\"\n\t\t\t: (ret == -ENOMEM) ? \": memory allocation failed\"\n\t\t\t: \"\";\n\t\tbinder_txn_error(\"cannot allocate buffer%s\", s);\n\n\t\treturn_error_param = PTR_ERR(t->buffer);\n\t\treturn_error = return_error_param == -ESRCH ?\n\t\t\tBR_DEAD_REPLY : BR_FAILED_REPLY;\n\t\treturn_error_line = __LINE__;\n\t\tt->buffer = NULL;\n\t\tgoto err_binder_alloc_buf_failed;\n\t}\n\tif (secctx) {\n\t\tint err;\n\t\tsize_t buf_offset = ALIGN(tr->data_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(tr->offsets_size, sizeof(void *)) +\n\t\t\t\t    ALIGN(extra_buffers_size, sizeof(void *)) -\n\t\t\t\t    ALIGN(secctx_sz, sizeof(u64));\n\n\t\tt->security_ctx = (uintptr_t)t->buffer->user_data + buf_offset;\n\t\terr = binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t  t->buffer, buf_offset,\n\t\t\t\t\t\t  secctx, secctx_sz);\n\t\tif (err) {\n\t\t\tt->security_ctx = 0;\n\t\t\tWARN_ON(1);\n\t\t}\n\t\tsecurity_release_secctx(secctx, secctx_sz);\n\t\tsecctx = NULL;\n\t}\n\tt->buffer->debug_id = t->debug_id;\n\tt->buffer->transaction = t;\n\tt->buffer->target_node = target_node;\n\tt->buffer->clear_on_free = !!(t->flags & TF_CLEAR_BUF);\n\ttrace_binder_transaction_alloc_buf(t->buffer);\n\n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer,\n\t\t\t\tALIGN(tr->data_size, sizeof(void *)),\n\t\t\t\t(const void __user *)\n\t\t\t\t\t(uintptr_t)tr->data.ptr.offsets,\n\t\t\t\ttr->offsets_size)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (!IS_ALIGNED(tr->offsets_size, sizeof(binder_size_t))) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets size, %lld\\n\",\n\t\t\t\tproc->pid, thread->pid, (u64)tr->offsets_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\tif (!IS_ALIGNED(extra_buffers_size, sizeof(u64))) {\n\t\tbinder_user_error(\"%d:%d got transaction with unaligned buffers size, %lld\\n\",\n\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t  (u64)extra_buffers_size);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EINVAL;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_bad_offset;\n\t}\n\toff_start_offset = ALIGN(tr->data_size, sizeof(void *));\n\tbuffer_offset = off_start_offset;\n\toff_end_offset = off_start_offset + tr->offsets_size;\n\tsg_buf_offset = ALIGN(off_end_offset, sizeof(void *));\n\tsg_buf_end_offset = sg_buf_offset + extra_buffers_size -\n\t\tALIGN(secctx_sz, sizeof(u64));\n\toff_min = 0;\n\tfor (buffer_offset = off_start_offset; buffer_offset < off_end_offset;\n\t     buffer_offset += sizeof(binder_size_t)) {\n\t\tstruct binder_object_header *hdr;\n\t\tsize_t object_size;\n\t\tstruct binder_object object;\n\t\tbinder_size_t object_offset;\n\t\tbinder_size_t copy_size;\n\n\t\tif (binder_alloc_copy_from_buffer(&target_proc->alloc,\n\t\t\t\t\t\t  &object_offset,\n\t\t\t\t\t\t  t->buffer,\n\t\t\t\t\t\t  buffer_offset,\n\t\t\t\t\t\t  sizeof(object_offset))) {\n\t\t\tbinder_txn_error(\"%d:%d copy offset from buffer failed\\n\",\n\t\t\t\tthread->pid, proc->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\n\t\t \n\t\tcopy_size = object_offset - user_offset;\n\t\tif (copy_size && (user_offset > object_offset ||\n\t\t\t\tbinder_alloc_copy_user_to_buffer(\n\t\t\t\t\t&target_proc->alloc,\n\t\t\t\t\tt->buffer, user_offset,\n\t\t\t\t\tuser_buffer + user_offset,\n\t\t\t\t\tcopy_size))) {\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid data ptr\\n\",\n\t\t\t\t\tproc->pid, thread->pid);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EFAULT;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_copy_data_failed;\n\t\t}\n\t\tobject_size = binder_get_object(target_proc, user_buffer,\n\t\t\t\tt->buffer, object_offset, &object);\n\t\tif (object_size == 0 || object_offset < off_min) {\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid offset (%lld, min %lld max %lld) or object.\\n\",\n\t\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t\t  (u64)object_offset,\n\t\t\t\t\t  (u64)off_min,\n\t\t\t\t\t  (u64)t->buffer->data_size);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_offset;\n\t\t}\n\t\t \n\t\tuser_offset = object_offset + object_size;\n\n\t\thdr = &object.hdr;\n\t\toff_min = object_offset + object_size;\n\t\tswitch (hdr->type) {\n\t\tcase BINDER_TYPE_BINDER:\n\t\tcase BINDER_TYPE_WEAK_BINDER: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_binder(fp, t, thread);\n\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\tbinder_txn_error(\"%d:%d translate binder failed\\n\",\n\t\t\t\t\tthread->pid, proc->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\t\tcase BINDER_TYPE_HANDLE:\n\t\tcase BINDER_TYPE_WEAK_HANDLE: {\n\t\t\tstruct flat_binder_object *fp;\n\n\t\t\tfp = to_flat_binder_object(hdr);\n\t\t\tret = binder_translate_handle(fp, t, thread);\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\tbinder_txn_error(\"%d:%d translate handle failed\\n\",\n\t\t\t\t\tthread->pid, proc->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\n\t\tcase BINDER_TYPE_FD: {\n\t\t\tstruct binder_fd_object *fp = to_binder_fd_object(hdr);\n\t\t\tbinder_size_t fd_offset = object_offset +\n\t\t\t\t(uintptr_t)&fp->fd - (uintptr_t)fp;\n\t\t\tint ret = binder_translate_fd(fp->fd, fd_offset, t,\n\t\t\t\t\t\t      thread, in_reply_to);\n\n\t\t\tfp->pad_binder = 0;\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tfp, sizeof(*fp))) {\n\t\t\t\tbinder_txn_error(\"%d:%d translate fd failed\\n\",\n\t\t\t\t\tthread->pid, proc->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t} break;\n\t\tcase BINDER_TYPE_FDA: {\n\t\t\tstruct binder_object ptr_object;\n\t\t\tbinder_size_t parent_offset;\n\t\t\tstruct binder_object user_object;\n\t\t\tsize_t user_parent_size;\n\t\t\tstruct binder_fd_array_object *fda =\n\t\t\t\tto_binder_fd_array_object(hdr);\n\t\t\tsize_t num_valid = (buffer_offset - off_start_offset) /\n\t\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tstruct binder_buffer_object *parent =\n\t\t\t\tbinder_validate_ptr(target_proc, t->buffer,\n\t\t\t\t\t\t    &ptr_object, fda->parent,\n\t\t\t\t\t\t    off_start_offset,\n\t\t\t\t\t\t    &parent_offset,\n\t\t\t\t\t\t    num_valid);\n\t\t\tif (!parent) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with invalid parent offset or type\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tif (!binder_validate_fixup(target_proc, t->buffer,\n\t\t\t\t\t\t   off_start_offset,\n\t\t\t\t\t\t   parent_offset,\n\t\t\t\t\t\t   fda->parent_offset,\n\t\t\t\t\t\t   last_fixup_obj_off,\n\t\t\t\t\t\t   last_fixup_min_off)) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with out-of-order buffer fixup\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\t \n\t\t\tuser_parent_size =\n\t\t\t\tbinder_get_object(proc, user_buffer, t->buffer,\n\t\t\t\t\t\t  parent_offset, &user_object);\n\t\t\tif (user_parent_size != sizeof(user_object.bbo)) {\n\t\t\t\tbinder_user_error(\"%d:%d invalid ptr object size: %zd vs %zd\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid,\n\t\t\t\t\t\t  user_parent_size,\n\t\t\t\t\t\t  sizeof(user_object.bbo));\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_parent;\n\t\t\t}\n\t\t\tret = binder_translate_fd_array(&pf_head, fda,\n\t\t\t\t\t\t\tuser_buffer, parent,\n\t\t\t\t\t\t\t&user_object.bbo, t,\n\t\t\t\t\t\t\tthread, in_reply_to);\n\t\t\tif (!ret)\n\t\t\t\tret = binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\t\t  t->buffer,\n\t\t\t\t\t\t\t\t  object_offset,\n\t\t\t\t\t\t\t\t  fda, sizeof(*fda));\n\t\t\tif (ret) {\n\t\t\t\tbinder_txn_error(\"%d:%d translate fd array failed\\n\",\n\t\t\t\t\tthread->pid, proc->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret > 0 ? -EINVAL : ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = parent_offset;\n\t\t\tlast_fixup_min_off =\n\t\t\t\tfda->parent_offset + sizeof(u32) * fda->num_fds;\n\t\t} break;\n\t\tcase BINDER_TYPE_PTR: {\n\t\t\tstruct binder_buffer_object *bp =\n\t\t\t\tto_binder_buffer_object(hdr);\n\t\t\tsize_t buf_left = sg_buf_end_offset - sg_buf_offset;\n\t\t\tsize_t num_valid;\n\n\t\t\tif (bp->length > buf_left) {\n\t\t\t\tbinder_user_error(\"%d:%d got transaction with too large buffer\\n\",\n\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = -EINVAL;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_bad_offset;\n\t\t\t}\n\t\t\tret = binder_defer_copy(&sgc_head, sg_buf_offset,\n\t\t\t\t(const void __user *)(uintptr_t)bp->buffer,\n\t\t\t\tbp->length);\n\t\t\tif (ret) {\n\t\t\t\tbinder_txn_error(\"%d:%d deferred copy failed\\n\",\n\t\t\t\t\tthread->pid, proc->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\t \n\t\t\tbp->buffer = (uintptr_t)\n\t\t\t\tt->buffer->user_data + sg_buf_offset;\n\t\t\tsg_buf_offset += ALIGN(bp->length, sizeof(u64));\n\n\t\t\tnum_valid = (buffer_offset - off_start_offset) /\n\t\t\t\t\tsizeof(binder_size_t);\n\t\t\tret = binder_fixup_parent(&pf_head, t,\n\t\t\t\t\t\t  thread, bp,\n\t\t\t\t\t\t  off_start_offset,\n\t\t\t\t\t\t  num_valid,\n\t\t\t\t\t\t  last_fixup_obj_off,\n\t\t\t\t\t\t  last_fixup_min_off);\n\t\t\tif (ret < 0 ||\n\t\t\t    binder_alloc_copy_to_buffer(&target_proc->alloc,\n\t\t\t\t\t\t\tt->buffer,\n\t\t\t\t\t\t\tobject_offset,\n\t\t\t\t\t\t\tbp, sizeof(*bp))) {\n\t\t\t\tbinder_txn_error(\"%d:%d failed to fixup parent\\n\",\n\t\t\t\t\tthread->pid, proc->pid);\n\t\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\t\treturn_error_param = ret;\n\t\t\t\treturn_error_line = __LINE__;\n\t\t\t\tgoto err_translate_failed;\n\t\t\t}\n\t\t\tlast_fixup_obj_off = object_offset;\n\t\t\tlast_fixup_min_off = 0;\n\t\t} break;\n\t\tdefault:\n\t\t\tbinder_user_error(\"%d:%d got transaction with invalid object type, %x\\n\",\n\t\t\t\tproc->pid, thread->pid, hdr->type);\n\t\t\treturn_error = BR_FAILED_REPLY;\n\t\t\treturn_error_param = -EINVAL;\n\t\t\treturn_error_line = __LINE__;\n\t\t\tgoto err_bad_object_type;\n\t\t}\n\t}\n\t \n\tif (binder_alloc_copy_user_to_buffer(\n\t\t\t\t&target_proc->alloc,\n\t\t\t\tt->buffer, user_offset,\n\t\t\t\tuser_buffer + user_offset,\n\t\t\t\ttr->data_size - user_offset)) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid data ptr\\n\",\n\t\t\t\tproc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = -EFAULT;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\n\tret = binder_do_deferred_txn_copies(&target_proc->alloc, t->buffer,\n\t\t\t\t\t    &sgc_head, &pf_head);\n\tif (ret) {\n\t\tbinder_user_error(\"%d:%d got transaction with invalid offsets ptr\\n\",\n\t\t\t\t  proc->pid, thread->pid);\n\t\treturn_error = BR_FAILED_REPLY;\n\t\treturn_error_param = ret;\n\t\treturn_error_line = __LINE__;\n\t\tgoto err_copy_data_failed;\n\t}\n\tif (t->buffer->oneway_spam_suspect)\n\t\ttcomplete->type = BINDER_WORK_TRANSACTION_ONEWAY_SPAM_SUSPECT;\n\telse\n\t\ttcomplete->type = BINDER_WORK_TRANSACTION_COMPLETE;\n\tt->work.type = BINDER_WORK_TRANSACTION;\n\n\tif (reply) {\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tbinder_inner_proc_lock(target_proc);\n\t\tif (target_thread->is_dead) {\n\t\t\treturn_error = BR_DEAD_REPLY;\n\t\t\tbinder_inner_proc_unlock(target_proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_pop_transaction_ilocked(target_thread, in_reply_to);\n\t\tbinder_enqueue_thread_work_ilocked(target_thread, &t->work);\n\t\ttarget_proc->outstanding_txns++;\n\t\tbinder_inner_proc_unlock(target_proc);\n\t\twake_up_interruptible_sync(&target_thread->wait);\n\t\tbinder_free_transaction(in_reply_to);\n\t} else if (!(t->flags & TF_ONE_WAY)) {\n\t\tBUG_ON(t->buffer->async_transaction != 0);\n\t\tbinder_inner_proc_lock(proc);\n\t\t \n\t\tbinder_enqueue_deferred_thread_work_ilocked(thread, tcomplete);\n\t\tt->need_reply = 1;\n\t\tt->from_parent = thread->transaction_stack;\n\t\tthread->transaction_stack = t;\n\t\tbinder_inner_proc_unlock(proc);\n\t\treturn_error = binder_proc_transaction(t,\n\t\t\t\ttarget_proc, target_thread);\n\t\tif (return_error) {\n\t\t\tbinder_inner_proc_lock(proc);\n\t\t\tbinder_pop_transaction_ilocked(thread, t);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tgoto err_dead_proc_or_thread;\n\t\t}\n\t} else {\n\t\tBUG_ON(target_node == NULL);\n\t\tBUG_ON(t->buffer->async_transaction != 1);\n\t\treturn_error = binder_proc_transaction(t, target_proc, NULL);\n\t\t \n\t\tif (return_error == BR_TRANSACTION_PENDING_FROZEN)\n\t\t\ttcomplete->type = BINDER_WORK_TRANSACTION_PENDING;\n\t\tbinder_enqueue_thread_work(thread, tcomplete);\n\t\tif (return_error &&\n\t\t    return_error != BR_TRANSACTION_PENDING_FROZEN)\n\t\t\tgoto err_dead_proc_or_thread;\n\t}\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tbinder_proc_dec_tmpref(target_proc);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\t \n\tsmp_wmb();\n\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\treturn;\n\nerr_dead_proc_or_thread:\n\tbinder_txn_error(\"%d:%d dead process or thread\\n\",\n\t\tthread->pid, proc->pid);\n\treturn_error_line = __LINE__;\n\tbinder_dequeue_work(proc, tcomplete);\nerr_translate_failed:\nerr_bad_object_type:\nerr_bad_offset:\nerr_bad_parent:\nerr_copy_data_failed:\n\tbinder_cleanup_deferred_txn_lists(&sgc_head, &pf_head);\n\tbinder_free_txn_fixups(t);\n\ttrace_binder_transaction_failed_buffer_release(t->buffer);\n\tbinder_transaction_buffer_release(target_proc, NULL, t->buffer,\n\t\t\t\t\t  buffer_offset, true);\n\tif (target_node)\n\t\tbinder_dec_node_tmpref(target_node);\n\ttarget_node = NULL;\n\tt->buffer->transaction = NULL;\n\tbinder_alloc_free_buf(&target_proc->alloc, t->buffer);\nerr_binder_alloc_buf_failed:\nerr_bad_extra_size:\n\tif (secctx)\n\t\tsecurity_release_secctx(secctx, secctx_sz);\nerr_get_secctx_failed:\n\tkfree(tcomplete);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);\nerr_alloc_tcomplete_failed:\n\tif (trace_binder_txn_latency_free_enabled())\n\t\tbinder_txn_latency_free(t);\n\tkfree(t);\n\tbinder_stats_deleted(BINDER_STAT_TRANSACTION);\nerr_alloc_t_failed:\nerr_bad_todo_list:\nerr_bad_call_stack:\nerr_empty_call_stack:\nerr_dead_binder:\nerr_invalid_target_handle:\n\tif (target_node) {\n\t\tbinder_dec_node(target_node, 1, 0);\n\t\tbinder_dec_node_tmpref(target_node);\n\t}\n\n\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t     \"%d:%d transaction %s to %d:%d failed %d/%d/%d, size %lld-%lld line %d\\n\",\n\t\t     proc->pid, thread->pid, reply ? \"reply\" :\n\t\t     (tr->flags & TF_ONE_WAY ? \"async\" : \"call\"),\n\t\t     target_proc ? target_proc->pid : 0,\n\t\t     target_thread ? target_thread->pid : 0,\n\t\t     t_debug_id, return_error, return_error_param,\n\t\t     (u64)tr->data_size, (u64)tr->offsets_size,\n\t\t     return_error_line);\n\n\tif (target_thread)\n\t\tbinder_thread_dec_tmpref(target_thread);\n\tif (target_proc)\n\t\tbinder_proc_dec_tmpref(target_proc);\n\n\t{\n\t\tstruct binder_transaction_log_entry *fe;\n\n\t\te->return_error = return_error;\n\t\te->return_error_param = return_error_param;\n\t\te->return_error_line = return_error_line;\n\t\tfe = binder_transaction_log_add(&binder_transaction_log_failed);\n\t\t*fe = *e;\n\t\t \n\t\tsmp_wmb();\n\t\tWRITE_ONCE(e->debug_id_done, t_debug_id);\n\t\tWRITE_ONCE(fe->debug_id_done, t_debug_id);\n\t}\n\n\tBUG_ON(thread->return_error.cmd != BR_OK);\n\tif (in_reply_to) {\n\t\tbinder_set_txn_from_error(in_reply_to, t_debug_id,\n\t\t\t\treturn_error, return_error_param);\n\t\tthread->return_error.cmd = BR_TRANSACTION_COMPLETE;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t\tbinder_send_failed_reply(in_reply_to, return_error);\n\t} else {\n\t\tbinder_inner_proc_lock(proc);\n\t\tbinder_set_extended_error(&thread->ee, t_debug_id,\n\t\t\t\treturn_error, return_error_param);\n\t\tbinder_inner_proc_unlock(proc);\n\t\tthread->return_error.cmd = return_error;\n\t\tbinder_enqueue_thread_work(thread, &thread->return_error.work);\n\t}\n}\n\n \nstatic void\nbinder_free_buf(struct binder_proc *proc,\n\t\tstruct binder_thread *thread,\n\t\tstruct binder_buffer *buffer, bool is_failure)\n{\n\tbinder_inner_proc_lock(proc);\n\tif (buffer->transaction) {\n\t\tbuffer->transaction->buffer = NULL;\n\t\tbuffer->transaction = NULL;\n\t}\n\tbinder_inner_proc_unlock(proc);\n\tif (buffer->async_transaction && buffer->target_node) {\n\t\tstruct binder_node *buf_node;\n\t\tstruct binder_work *w;\n\n\t\tbuf_node = buffer->target_node;\n\t\tbinder_node_inner_lock(buf_node);\n\t\tBUG_ON(!buf_node->has_async_transaction);\n\t\tBUG_ON(buf_node->proc != proc);\n\t\tw = binder_dequeue_work_head_ilocked(\n\t\t\t\t&buf_node->async_todo);\n\t\tif (!w) {\n\t\t\tbuf_node->has_async_transaction = false;\n\t\t} else {\n\t\t\tbinder_enqueue_work_ilocked(\n\t\t\t\t\tw, &proc->todo);\n\t\t\tbinder_wakeup_proc_ilocked(proc);\n\t\t}\n\t\tbinder_node_inner_unlock(buf_node);\n\t}\n\ttrace_binder_transaction_buffer_release(buffer);\n\tbinder_release_entire_buffer(proc, thread, buffer, is_failure);\n\tbinder_alloc_free_buf(&proc->alloc, buffer);\n}\n\nstatic int binder_thread_write(struct binder_proc *proc,\n\t\t\tstruct binder_thread *thread,\n\t\t\tbinder_uintptr_t binder_buffer, size_t size,\n\t\t\tbinder_size_t *consumed)\n{\n\tuint32_t cmd;\n\tstruct binder_context *context = proc->context;\n\tvoid __user *buffer = (void __user *)(uintptr_t)binder_buffer;\n\tvoid __user *ptr = buffer + *consumed;\n\tvoid __user *end = buffer + size;\n\n\twhile (ptr < end && thread->return_error.cmd == BR_OK) {\n\t\tint ret;\n\n\t\tif (get_user(cmd, (uint32_t __user *)ptr))\n\t\t\treturn -EFAULT;\n\t\tptr += sizeof(uint32_t);\n\t\ttrace_binder_command(cmd);\n\t\tif (_IOC_NR(cmd) < ARRAY_SIZE(binder_stats.bc)) {\n\t\t\tatomic_inc(&binder_stats.bc[_IOC_NR(cmd)]);\n\t\t\tatomic_inc(&proc->stats.bc[_IOC_NR(cmd)]);\n\t\t\tatomic_inc(&thread->stats.bc[_IOC_NR(cmd)]);\n\t\t}\n\t\tswitch (cmd) {\n\t\tcase BC_INCREFS:\n\t\tcase BC_ACQUIRE:\n\t\tcase BC_RELEASE:\n\t\tcase BC_DECREFS: {\n\t\t\tuint32_t target;\n\t\t\tconst char *debug_string;\n\t\t\tbool strong = cmd == BC_ACQUIRE || cmd == BC_RELEASE;\n\t\t\tbool increment = cmd == BC_INCREFS || cmd == BC_ACQUIRE;\n\t\t\tstruct binder_ref_data rdata;\n\n\t\t\tif (get_user(target, (uint32_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\n\t\t\tptr += sizeof(uint32_t);\n\t\t\tret = -1;\n\t\t\tif (increment && !target) {\n\t\t\t\tstruct binder_node *ctx_mgr_node;\n\n\t\t\t\tmutex_lock(&context->context_mgr_node_lock);\n\t\t\t\tctx_mgr_node = context->binder_context_mgr_node;\n\t\t\t\tif (ctx_mgr_node) {\n\t\t\t\t\tif (ctx_mgr_node->proc == proc) {\n\t\t\t\t\t\tbinder_user_error(\"%d:%d context manager tried to acquire desc 0\\n\",\n\t\t\t\t\t\t\t\t  proc->pid, thread->pid);\n\t\t\t\t\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\t\t\t\t\treturn -EINVAL;\n\t\t\t\t\t}\n\t\t\t\t\tret = binder_inc_ref_for_node(\n\t\t\t\t\t\t\tproc, ctx_mgr_node,\n\t\t\t\t\t\t\tstrong, NULL, &rdata);\n\t\t\t\t}\n\t\t\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\t\t}\n\t\t\tif (ret)\n\t\t\t\tret = binder_update_ref_for_handle(\n\t\t\t\t\t\tproc, target, increment, strong,\n\t\t\t\t\t\t&rdata);\n\t\t\tif (!ret && rdata.desc != target) {\n\t\t\t\tbinder_user_error(\"%d:%d tried to acquire reference to desc %d, got %d instead\\n\",\n\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\ttarget, rdata.desc);\n\t\t\t}\n\t\t\tswitch (cmd) {\n\t\t\tcase BC_INCREFS:\n\t\t\t\tdebug_string = \"IncRefs\";\n\t\t\t\tbreak;\n\t\t\tcase BC_ACQUIRE:\n\t\t\t\tdebug_string = \"Acquire\";\n\t\t\t\tbreak;\n\t\t\tcase BC_RELEASE:\n\t\t\t\tdebug_string = \"Release\";\n\t\t\t\tbreak;\n\t\t\tcase BC_DECREFS:\n\t\t\tdefault:\n\t\t\t\tdebug_string = \"DecRefs\";\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ret) {\n\t\t\t\tbinder_user_error(\"%d:%d %s %d refcount change on invalid ref %d ret %d\\n\",\n\t\t\t\t\tproc->pid, thread->pid, debug_string,\n\t\t\t\t\tstrong, target, ret);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbinder_debug(BINDER_DEBUG_USER_REFS,\n\t\t\t\t     \"%d:%d %s ref %d desc %d s %d w %d\\n\",\n\t\t\t\t     proc->pid, thread->pid, debug_string,\n\t\t\t\t     rdata.debug_id, rdata.desc, rdata.strong,\n\t\t\t\t     rdata.weak);\n\t\t\tbreak;\n\t\t}\n\t\tcase BC_INCREFS_DONE:\n\t\tcase BC_ACQUIRE_DONE: {\n\t\t\tbinder_uintptr_t node_ptr;\n\t\t\tbinder_uintptr_t cookie;\n\t\t\tstruct binder_node *node;\n\t\t\tbool free_node;\n\n\t\t\tif (get_user(node_ptr, (binder_uintptr_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(binder_uintptr_t);\n\t\t\tif (get_user(cookie, (binder_uintptr_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(binder_uintptr_t);\n\t\t\tnode = binder_get_node(proc, node_ptr);\n\t\t\tif (node == NULL) {\n\t\t\t\tbinder_user_error(\"%d:%d %s u%016llx no match\\n\",\n\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\tcmd == BC_INCREFS_DONE ?\n\t\t\t\t\t\"BC_INCREFS_DONE\" :\n\t\t\t\t\t\"BC_ACQUIRE_DONE\",\n\t\t\t\t\t(u64)node_ptr);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (cookie != node->cookie) {\n\t\t\t\tbinder_user_error(\"%d:%d %s u%016llx node %d cookie mismatch %016llx != %016llx\\n\",\n\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\tcmd == BC_INCREFS_DONE ?\n\t\t\t\t\t\"BC_INCREFS_DONE\" : \"BC_ACQUIRE_DONE\",\n\t\t\t\t\t(u64)node_ptr, node->debug_id,\n\t\t\t\t\t(u64)cookie, (u64)node->cookie);\n\t\t\t\tbinder_put_node(node);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbinder_node_inner_lock(node);\n\t\t\tif (cmd == BC_ACQUIRE_DONE) {\n\t\t\t\tif (node->pending_strong_ref == 0) {\n\t\t\t\t\tbinder_user_error(\"%d:%d BC_ACQUIRE_DONE node %d has no pending acquire request\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\t\tnode->debug_id);\n\t\t\t\t\tbinder_node_inner_unlock(node);\n\t\t\t\t\tbinder_put_node(node);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnode->pending_strong_ref = 0;\n\t\t\t} else {\n\t\t\t\tif (node->pending_weak_ref == 0) {\n\t\t\t\t\tbinder_user_error(\"%d:%d BC_INCREFS_DONE node %d has no pending increfs request\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\t\tnode->debug_id);\n\t\t\t\t\tbinder_node_inner_unlock(node);\n\t\t\t\t\tbinder_put_node(node);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tnode->pending_weak_ref = 0;\n\t\t\t}\n\t\t\tfree_node = binder_dec_node_nilocked(node,\n\t\t\t\t\tcmd == BC_ACQUIRE_DONE, 0);\n\t\t\tWARN_ON(free_node);\n\t\t\tbinder_debug(BINDER_DEBUG_USER_REFS,\n\t\t\t\t     \"%d:%d %s node %d ls %d lw %d tr %d\\n\",\n\t\t\t\t     proc->pid, thread->pid,\n\t\t\t\t     cmd == BC_INCREFS_DONE ? \"BC_INCREFS_DONE\" : \"BC_ACQUIRE_DONE\",\n\t\t\t\t     node->debug_id, node->local_strong_refs,\n\t\t\t\t     node->local_weak_refs, node->tmp_refs);\n\t\t\tbinder_node_inner_unlock(node);\n\t\t\tbinder_put_node(node);\n\t\t\tbreak;\n\t\t}\n\t\tcase BC_ATTEMPT_ACQUIRE:\n\t\t\tpr_err(\"BC_ATTEMPT_ACQUIRE not supported\\n\");\n\t\t\treturn -EINVAL;\n\t\tcase BC_ACQUIRE_RESULT:\n\t\t\tpr_err(\"BC_ACQUIRE_RESULT not supported\\n\");\n\t\t\treturn -EINVAL;\n\n\t\tcase BC_FREE_BUFFER: {\n\t\t\tbinder_uintptr_t data_ptr;\n\t\t\tstruct binder_buffer *buffer;\n\n\t\t\tif (get_user(data_ptr, (binder_uintptr_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(binder_uintptr_t);\n\n\t\t\tbuffer = binder_alloc_prepare_to_free(&proc->alloc,\n\t\t\t\t\t\t\t      data_ptr);\n\t\t\tif (IS_ERR_OR_NULL(buffer)) {\n\t\t\t\tif (PTR_ERR(buffer) == -EPERM) {\n\t\t\t\t\tbinder_user_error(\n\t\t\t\t\t\t\"%d:%d BC_FREE_BUFFER u%016llx matched unreturned or currently freeing buffer\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\t\t(u64)data_ptr);\n\t\t\t\t} else {\n\t\t\t\t\tbinder_user_error(\n\t\t\t\t\t\t\"%d:%d BC_FREE_BUFFER u%016llx no match\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\t\t(u64)data_ptr);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbinder_debug(BINDER_DEBUG_FREE_BUFFER,\n\t\t\t\t     \"%d:%d BC_FREE_BUFFER u%016llx found buffer %d for %s transaction\\n\",\n\t\t\t\t     proc->pid, thread->pid, (u64)data_ptr,\n\t\t\t\t     buffer->debug_id,\n\t\t\t\t     buffer->transaction ? \"active\" : \"finished\");\n\t\t\tbinder_free_buf(proc, thread, buffer, false);\n\t\t\tbreak;\n\t\t}\n\n\t\tcase BC_TRANSACTION_SG:\n\t\tcase BC_REPLY_SG: {\n\t\t\tstruct binder_transaction_data_sg tr;\n\n\t\t\tif (copy_from_user(&tr, ptr, sizeof(tr)))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(tr);\n\t\t\tbinder_transaction(proc, thread, &tr.transaction_data,\n\t\t\t\t\t   cmd == BC_REPLY_SG, tr.buffers_size);\n\t\t\tbreak;\n\t\t}\n\t\tcase BC_TRANSACTION:\n\t\tcase BC_REPLY: {\n\t\t\tstruct binder_transaction_data tr;\n\n\t\t\tif (copy_from_user(&tr, ptr, sizeof(tr)))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(tr);\n\t\t\tbinder_transaction(proc, thread, &tr,\n\t\t\t\t\t   cmd == BC_REPLY, 0);\n\t\t\tbreak;\n\t\t}\n\n\t\tcase BC_REGISTER_LOOPER:\n\t\t\tbinder_debug(BINDER_DEBUG_THREADS,\n\t\t\t\t     \"%d:%d BC_REGISTER_LOOPER\\n\",\n\t\t\t\t     proc->pid, thread->pid);\n\t\t\tbinder_inner_proc_lock(proc);\n\t\t\tif (thread->looper & BINDER_LOOPER_STATE_ENTERED) {\n\t\t\t\tthread->looper |= BINDER_LOOPER_STATE_INVALID;\n\t\t\t\tbinder_user_error(\"%d:%d ERROR: BC_REGISTER_LOOPER called after BC_ENTER_LOOPER\\n\",\n\t\t\t\t\tproc->pid, thread->pid);\n\t\t\t} else if (proc->requested_threads == 0) {\n\t\t\t\tthread->looper |= BINDER_LOOPER_STATE_INVALID;\n\t\t\t\tbinder_user_error(\"%d:%d ERROR: BC_REGISTER_LOOPER called without request\\n\",\n\t\t\t\t\tproc->pid, thread->pid);\n\t\t\t} else {\n\t\t\t\tproc->requested_threads--;\n\t\t\t\tproc->requested_threads_started++;\n\t\t\t}\n\t\t\tthread->looper |= BINDER_LOOPER_STATE_REGISTERED;\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tbreak;\n\t\tcase BC_ENTER_LOOPER:\n\t\t\tbinder_debug(BINDER_DEBUG_THREADS,\n\t\t\t\t     \"%d:%d BC_ENTER_LOOPER\\n\",\n\t\t\t\t     proc->pid, thread->pid);\n\t\t\tif (thread->looper & BINDER_LOOPER_STATE_REGISTERED) {\n\t\t\t\tthread->looper |= BINDER_LOOPER_STATE_INVALID;\n\t\t\t\tbinder_user_error(\"%d:%d ERROR: BC_ENTER_LOOPER called after BC_REGISTER_LOOPER\\n\",\n\t\t\t\t\tproc->pid, thread->pid);\n\t\t\t}\n\t\t\tthread->looper |= BINDER_LOOPER_STATE_ENTERED;\n\t\t\tbreak;\n\t\tcase BC_EXIT_LOOPER:\n\t\t\tbinder_debug(BINDER_DEBUG_THREADS,\n\t\t\t\t     \"%d:%d BC_EXIT_LOOPER\\n\",\n\t\t\t\t     proc->pid, thread->pid);\n\t\t\tthread->looper |= BINDER_LOOPER_STATE_EXITED;\n\t\t\tbreak;\n\n\t\tcase BC_REQUEST_DEATH_NOTIFICATION:\n\t\tcase BC_CLEAR_DEATH_NOTIFICATION: {\n\t\t\tuint32_t target;\n\t\t\tbinder_uintptr_t cookie;\n\t\t\tstruct binder_ref *ref;\n\t\t\tstruct binder_ref_death *death = NULL;\n\n\t\t\tif (get_user(target, (uint32_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(uint32_t);\n\t\t\tif (get_user(cookie, (binder_uintptr_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(binder_uintptr_t);\n\t\t\tif (cmd == BC_REQUEST_DEATH_NOTIFICATION) {\n\t\t\t\t \n\t\t\t\tdeath = kzalloc(sizeof(*death), GFP_KERNEL);\n\t\t\t\tif (death == NULL) {\n\t\t\t\t\tWARN_ON(thread->return_error.cmd !=\n\t\t\t\t\t\tBR_OK);\n\t\t\t\t\tthread->return_error.cmd = BR_ERROR;\n\t\t\t\t\tbinder_enqueue_thread_work(\n\t\t\t\t\t\tthread,\n\t\t\t\t\t\t&thread->return_error.work);\n\t\t\t\t\tbinder_debug(\n\t\t\t\t\t\tBINDER_DEBUG_FAILED_TRANSACTION,\n\t\t\t\t\t\t\"%d:%d BC_REQUEST_DEATH_NOTIFICATION failed\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbinder_proc_lock(proc);\n\t\t\tref = binder_get_ref_olocked(proc, target, false);\n\t\t\tif (ref == NULL) {\n\t\t\t\tbinder_user_error(\"%d:%d %s invalid ref %d\\n\",\n\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\tcmd == BC_REQUEST_DEATH_NOTIFICATION ?\n\t\t\t\t\t\"BC_REQUEST_DEATH_NOTIFICATION\" :\n\t\t\t\t\t\"BC_CLEAR_DEATH_NOTIFICATION\",\n\t\t\t\t\ttarget);\n\t\t\t\tbinder_proc_unlock(proc);\n\t\t\t\tkfree(death);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbinder_debug(BINDER_DEBUG_DEATH_NOTIFICATION,\n\t\t\t\t     \"%d:%d %s %016llx ref %d desc %d s %d w %d for node %d\\n\",\n\t\t\t\t     proc->pid, thread->pid,\n\t\t\t\t     cmd == BC_REQUEST_DEATH_NOTIFICATION ?\n\t\t\t\t     \"BC_REQUEST_DEATH_NOTIFICATION\" :\n\t\t\t\t     \"BC_CLEAR_DEATH_NOTIFICATION\",\n\t\t\t\t     (u64)cookie, ref->data.debug_id,\n\t\t\t\t     ref->data.desc, ref->data.strong,\n\t\t\t\t     ref->data.weak, ref->node->debug_id);\n\n\t\t\tbinder_node_lock(ref->node);\n\t\t\tif (cmd == BC_REQUEST_DEATH_NOTIFICATION) {\n\t\t\t\tif (ref->death) {\n\t\t\t\t\tbinder_user_error(\"%d:%d BC_REQUEST_DEATH_NOTIFICATION death notification already set\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid);\n\t\t\t\t\tbinder_node_unlock(ref->node);\n\t\t\t\t\tbinder_proc_unlock(proc);\n\t\t\t\t\tkfree(death);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbinder_stats_created(BINDER_STAT_DEATH);\n\t\t\t\tINIT_LIST_HEAD(&death->work.entry);\n\t\t\t\tdeath->cookie = cookie;\n\t\t\t\tref->death = death;\n\t\t\t\tif (ref->node->proc == NULL) {\n\t\t\t\t\tref->death->work.type = BINDER_WORK_DEAD_BINDER;\n\n\t\t\t\t\tbinder_inner_proc_lock(proc);\n\t\t\t\t\tbinder_enqueue_work_ilocked(\n\t\t\t\t\t\t&ref->death->work, &proc->todo);\n\t\t\t\t\tbinder_wakeup_proc_ilocked(proc);\n\t\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (ref->death == NULL) {\n\t\t\t\t\tbinder_user_error(\"%d:%d BC_CLEAR_DEATH_NOTIFICATION death notification not active\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid);\n\t\t\t\t\tbinder_node_unlock(ref->node);\n\t\t\t\t\tbinder_proc_unlock(proc);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tdeath = ref->death;\n\t\t\t\tif (death->cookie != cookie) {\n\t\t\t\t\tbinder_user_error(\"%d:%d BC_CLEAR_DEATH_NOTIFICATION death notification cookie mismatch %016llx != %016llx\\n\",\n\t\t\t\t\t\tproc->pid, thread->pid,\n\t\t\t\t\t\t(u64)death->cookie,\n\t\t\t\t\t\t(u64)cookie);\n\t\t\t\t\tbinder_node_unlock(ref->node);\n\t\t\t\t\tbinder_proc_unlock(proc);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tref->death = NULL;\n\t\t\t\tbinder_inner_proc_lock(proc);\n\t\t\t\tif (list_empty(&death->work.entry)) {\n\t\t\t\t\tdeath->work.type = BINDER_WORK_CLEAR_DEATH_NOTIFICATION;\n\t\t\t\t\tif (thread->looper &\n\t\t\t\t\t    (BINDER_LOOPER_STATE_REGISTERED |\n\t\t\t\t\t     BINDER_LOOPER_STATE_ENTERED))\n\t\t\t\t\t\tbinder_enqueue_thread_work_ilocked(\n\t\t\t\t\t\t\t\tthread,\n\t\t\t\t\t\t\t\t&death->work);\n\t\t\t\t\telse {\n\t\t\t\t\t\tbinder_enqueue_work_ilocked(\n\t\t\t\t\t\t\t\t&death->work,\n\t\t\t\t\t\t\t\t&proc->todo);\n\t\t\t\t\t\tbinder_wakeup_proc_ilocked(\n\t\t\t\t\t\t\t\tproc);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tBUG_ON(death->work.type != BINDER_WORK_DEAD_BINDER);\n\t\t\t\t\tdeath->work.type = BINDER_WORK_DEAD_BINDER_AND_CLEAR;\n\t\t\t\t}\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t}\n\t\t\tbinder_node_unlock(ref->node);\n\t\t\tbinder_proc_unlock(proc);\n\t\t} break;\n\t\tcase BC_DEAD_BINDER_DONE: {\n\t\t\tstruct binder_work *w;\n\t\t\tbinder_uintptr_t cookie;\n\t\t\tstruct binder_ref_death *death = NULL;\n\n\t\t\tif (get_user(cookie, (binder_uintptr_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\n\t\t\tptr += sizeof(cookie);\n\t\t\tbinder_inner_proc_lock(proc);\n\t\t\tlist_for_each_entry(w, &proc->delivered_death,\n\t\t\t\t\t    entry) {\n\t\t\t\tstruct binder_ref_death *tmp_death =\n\t\t\t\t\tcontainer_of(w,\n\t\t\t\t\t\t     struct binder_ref_death,\n\t\t\t\t\t\t     work);\n\n\t\t\t\tif (tmp_death->cookie == cookie) {\n\t\t\t\t\tdeath = tmp_death;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbinder_debug(BINDER_DEBUG_DEAD_BINDER,\n\t\t\t\t     \"%d:%d BC_DEAD_BINDER_DONE %016llx found %pK\\n\",\n\t\t\t\t     proc->pid, thread->pid, (u64)cookie,\n\t\t\t\t     death);\n\t\t\tif (death == NULL) {\n\t\t\t\tbinder_user_error(\"%d:%d BC_DEAD_BINDER_DONE %016llx not found\\n\",\n\t\t\t\t\tproc->pid, thread->pid, (u64)cookie);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbinder_dequeue_work_ilocked(&death->work);\n\t\t\tif (death->work.type == BINDER_WORK_DEAD_BINDER_AND_CLEAR) {\n\t\t\t\tdeath->work.type = BINDER_WORK_CLEAR_DEATH_NOTIFICATION;\n\t\t\t\tif (thread->looper &\n\t\t\t\t\t(BINDER_LOOPER_STATE_REGISTERED |\n\t\t\t\t\t BINDER_LOOPER_STATE_ENTERED))\n\t\t\t\t\tbinder_enqueue_thread_work_ilocked(\n\t\t\t\t\t\tthread, &death->work);\n\t\t\t\telse {\n\t\t\t\t\tbinder_enqueue_work_ilocked(\n\t\t\t\t\t\t\t&death->work,\n\t\t\t\t\t\t\t&proc->todo);\n\t\t\t\t\tbinder_wakeup_proc_ilocked(proc);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t} break;\n\n\t\tdefault:\n\t\t\tpr_err(\"%d:%d unknown command %u\\n\",\n\t\t\t       proc->pid, thread->pid, cmd);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*consumed = ptr - buffer;\n\t}\n\treturn 0;\n}\n\nstatic void binder_stat_br(struct binder_proc *proc,\n\t\t\t   struct binder_thread *thread, uint32_t cmd)\n{\n\ttrace_binder_return(cmd);\n\tif (_IOC_NR(cmd) < ARRAY_SIZE(binder_stats.br)) {\n\t\tatomic_inc(&binder_stats.br[_IOC_NR(cmd)]);\n\t\tatomic_inc(&proc->stats.br[_IOC_NR(cmd)]);\n\t\tatomic_inc(&thread->stats.br[_IOC_NR(cmd)]);\n\t}\n}\n\nstatic int binder_put_node_cmd(struct binder_proc *proc,\n\t\t\t       struct binder_thread *thread,\n\t\t\t       void __user **ptrp,\n\t\t\t       binder_uintptr_t node_ptr,\n\t\t\t       binder_uintptr_t node_cookie,\n\t\t\t       int node_debug_id,\n\t\t\t       uint32_t cmd, const char *cmd_name)\n{\n\tvoid __user *ptr = *ptrp;\n\n\tif (put_user(cmd, (uint32_t __user *)ptr))\n\t\treturn -EFAULT;\n\tptr += sizeof(uint32_t);\n\n\tif (put_user(node_ptr, (binder_uintptr_t __user *)ptr))\n\t\treturn -EFAULT;\n\tptr += sizeof(binder_uintptr_t);\n\n\tif (put_user(node_cookie, (binder_uintptr_t __user *)ptr))\n\t\treturn -EFAULT;\n\tptr += sizeof(binder_uintptr_t);\n\n\tbinder_stat_br(proc, thread, cmd);\n\tbinder_debug(BINDER_DEBUG_USER_REFS, \"%d:%d %s %d u%016llx c%016llx\\n\",\n\t\t     proc->pid, thread->pid, cmd_name, node_debug_id,\n\t\t     (u64)node_ptr, (u64)node_cookie);\n\n\t*ptrp = ptr;\n\treturn 0;\n}\n\nstatic int binder_wait_for_work(struct binder_thread *thread,\n\t\t\t\tbool do_proc_work)\n{\n\tDEFINE_WAIT(wait);\n\tstruct binder_proc *proc = thread->proc;\n\tint ret = 0;\n\n\tbinder_inner_proc_lock(proc);\n\tfor (;;) {\n\t\tprepare_to_wait(&thread->wait, &wait, TASK_INTERRUPTIBLE|TASK_FREEZABLE);\n\t\tif (binder_has_work_ilocked(thread, do_proc_work))\n\t\t\tbreak;\n\t\tif (do_proc_work)\n\t\t\tlist_add(&thread->waiting_thread_node,\n\t\t\t\t &proc->waiting_threads);\n\t\tbinder_inner_proc_unlock(proc);\n\t\tschedule();\n\t\tbinder_inner_proc_lock(proc);\n\t\tlist_del_init(&thread->waiting_thread_node);\n\t\tif (signal_pending(current)) {\n\t\t\tret = -EINTR;\n\t\t\tbreak;\n\t\t}\n\t}\n\tfinish_wait(&thread->wait, &wait);\n\tbinder_inner_proc_unlock(proc);\n\n\treturn ret;\n}\n\n \nstatic int binder_apply_fd_fixups(struct binder_proc *proc,\n\t\t\t\t  struct binder_transaction *t)\n{\n\tstruct binder_txn_fd_fixup *fixup, *tmp;\n\tint ret = 0;\n\n\tlist_for_each_entry(fixup, &t->fd_fixups, fixup_entry) {\n\t\tint fd = get_unused_fd_flags(O_CLOEXEC);\n\n\t\tif (fd < 0) {\n\t\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t\t     \"failed fd fixup txn %d fd %d\\n\",\n\t\t\t\t     t->debug_id, fd);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"fd fixup txn %d fd %d\\n\",\n\t\t\t     t->debug_id, fd);\n\t\ttrace_binder_transaction_fd_recv(t, fd, fixup->offset);\n\t\tfixup->target_fd = fd;\n\t\tif (binder_alloc_copy_to_buffer(&proc->alloc, t->buffer,\n\t\t\t\t\t\tfixup->offset, &fd,\n\t\t\t\t\t\tsizeof(u32))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t}\n\tlist_for_each_entry_safe(fixup, tmp, &t->fd_fixups, fixup_entry) {\n\t\tfd_install(fixup->target_fd, fixup->file);\n\t\tlist_del(&fixup->fixup_entry);\n\t\tkfree(fixup);\n\t}\n\n\treturn ret;\n\nerr:\n\tbinder_free_txn_fixups(t);\n\treturn ret;\n}\n\nstatic int binder_thread_read(struct binder_proc *proc,\n\t\t\t      struct binder_thread *thread,\n\t\t\t      binder_uintptr_t binder_buffer, size_t size,\n\t\t\t      binder_size_t *consumed, int non_block)\n{\n\tvoid __user *buffer = (void __user *)(uintptr_t)binder_buffer;\n\tvoid __user *ptr = buffer + *consumed;\n\tvoid __user *end = buffer + size;\n\n\tint ret = 0;\n\tint wait_for_proc_work;\n\n\tif (*consumed == 0) {\n\t\tif (put_user(BR_NOOP, (uint32_t __user *)ptr))\n\t\t\treturn -EFAULT;\n\t\tptr += sizeof(uint32_t);\n\t}\n\nretry:\n\tbinder_inner_proc_lock(proc);\n\twait_for_proc_work = binder_available_for_proc_work_ilocked(thread);\n\tbinder_inner_proc_unlock(proc);\n\n\tthread->looper |= BINDER_LOOPER_STATE_WAITING;\n\n\ttrace_binder_wait_for_work(wait_for_proc_work,\n\t\t\t\t   !!thread->transaction_stack,\n\t\t\t\t   !binder_worklist_empty(proc, &thread->todo));\n\tif (wait_for_proc_work) {\n\t\tif (!(thread->looper & (BINDER_LOOPER_STATE_REGISTERED |\n\t\t\t\t\tBINDER_LOOPER_STATE_ENTERED))) {\n\t\t\tbinder_user_error(\"%d:%d ERROR: Thread waiting for process work before calling BC_REGISTER_LOOPER or BC_ENTER_LOOPER (state %x)\\n\",\n\t\t\t\tproc->pid, thread->pid, thread->looper);\n\t\t\twait_event_interruptible(binder_user_error_wait,\n\t\t\t\t\t\t binder_stop_on_user_error < 2);\n\t\t}\n\t\tbinder_set_nice(proc->default_priority);\n\t}\n\n\tif (non_block) {\n\t\tif (!binder_has_work(thread, wait_for_proc_work))\n\t\t\tret = -EAGAIN;\n\t} else {\n\t\tret = binder_wait_for_work(thread, wait_for_proc_work);\n\t}\n\n\tthread->looper &= ~BINDER_LOOPER_STATE_WAITING;\n\n\tif (ret)\n\t\treturn ret;\n\n\twhile (1) {\n\t\tuint32_t cmd;\n\t\tstruct binder_transaction_data_secctx tr;\n\t\tstruct binder_transaction_data *trd = &tr.transaction_data;\n\t\tstruct binder_work *w = NULL;\n\t\tstruct list_head *list = NULL;\n\t\tstruct binder_transaction *t = NULL;\n\t\tstruct binder_thread *t_from;\n\t\tsize_t trsize = sizeof(*trd);\n\n\t\tbinder_inner_proc_lock(proc);\n\t\tif (!binder_worklist_empty_ilocked(&thread->todo))\n\t\t\tlist = &thread->todo;\n\t\telse if (!binder_worklist_empty_ilocked(&proc->todo) &&\n\t\t\t   wait_for_proc_work)\n\t\t\tlist = &proc->todo;\n\t\telse {\n\t\t\tbinder_inner_proc_unlock(proc);\n\n\t\t\t \n\t\t\tif (ptr - buffer == 4 && !thread->looper_need_return)\n\t\t\t\tgoto retry;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (end - ptr < sizeof(tr) + 4) {\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tbreak;\n\t\t}\n\t\tw = binder_dequeue_work_head_ilocked(list);\n\t\tif (binder_worklist_empty_ilocked(&thread->todo))\n\t\t\tthread->process_todo = false;\n\n\t\tswitch (w->type) {\n\t\tcase BINDER_WORK_TRANSACTION: {\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tt = container_of(w, struct binder_transaction, work);\n\t\t} break;\n\t\tcase BINDER_WORK_RETURN_ERROR: {\n\t\t\tstruct binder_error *e = container_of(\n\t\t\t\t\tw, struct binder_error, work);\n\n\t\t\tWARN_ON(e->cmd == BR_OK);\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tif (put_user(e->cmd, (uint32_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tcmd = e->cmd;\n\t\t\te->cmd = BR_OK;\n\t\t\tptr += sizeof(uint32_t);\n\n\t\t\tbinder_stat_br(proc, thread, cmd);\n\t\t} break;\n\t\tcase BINDER_WORK_TRANSACTION_COMPLETE:\n\t\tcase BINDER_WORK_TRANSACTION_PENDING:\n\t\tcase BINDER_WORK_TRANSACTION_ONEWAY_SPAM_SUSPECT: {\n\t\t\tif (proc->oneway_spam_detection_enabled &&\n\t\t\t\t   w->type == BINDER_WORK_TRANSACTION_ONEWAY_SPAM_SUSPECT)\n\t\t\t\tcmd = BR_ONEWAY_SPAM_SUSPECT;\n\t\t\telse if (w->type == BINDER_WORK_TRANSACTION_PENDING)\n\t\t\t\tcmd = BR_TRANSACTION_PENDING_FROZEN;\n\t\t\telse\n\t\t\t\tcmd = BR_TRANSACTION_COMPLETE;\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tkfree(w);\n\t\t\tbinder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);\n\t\t\tif (put_user(cmd, (uint32_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(uint32_t);\n\n\t\t\tbinder_stat_br(proc, thread, cmd);\n\t\t\tbinder_debug(BINDER_DEBUG_TRANSACTION_COMPLETE,\n\t\t\t\t     \"%d:%d BR_TRANSACTION_COMPLETE\\n\",\n\t\t\t\t     proc->pid, thread->pid);\n\t\t} break;\n\t\tcase BINDER_WORK_NODE: {\n\t\t\tstruct binder_node *node = container_of(w, struct binder_node, work);\n\t\t\tint strong, weak;\n\t\t\tbinder_uintptr_t node_ptr = node->ptr;\n\t\t\tbinder_uintptr_t node_cookie = node->cookie;\n\t\t\tint node_debug_id = node->debug_id;\n\t\t\tint has_weak_ref;\n\t\t\tint has_strong_ref;\n\t\t\tvoid __user *orig_ptr = ptr;\n\n\t\t\tBUG_ON(proc != node->proc);\n\t\t\tstrong = node->internal_strong_refs ||\n\t\t\t\t\tnode->local_strong_refs;\n\t\t\tweak = !hlist_empty(&node->refs) ||\n\t\t\t\t\tnode->local_weak_refs ||\n\t\t\t\t\tnode->tmp_refs || strong;\n\t\t\thas_strong_ref = node->has_strong_ref;\n\t\t\thas_weak_ref = node->has_weak_ref;\n\n\t\t\tif (weak && !has_weak_ref) {\n\t\t\t\tnode->has_weak_ref = 1;\n\t\t\t\tnode->pending_weak_ref = 1;\n\t\t\t\tnode->local_weak_refs++;\n\t\t\t}\n\t\t\tif (strong && !has_strong_ref) {\n\t\t\t\tnode->has_strong_ref = 1;\n\t\t\t\tnode->pending_strong_ref = 1;\n\t\t\t\tnode->local_strong_refs++;\n\t\t\t}\n\t\t\tif (!strong && has_strong_ref)\n\t\t\t\tnode->has_strong_ref = 0;\n\t\t\tif (!weak && has_weak_ref)\n\t\t\t\tnode->has_weak_ref = 0;\n\t\t\tif (!weak && !strong) {\n\t\t\t\tbinder_debug(BINDER_DEBUG_INTERNAL_REFS,\n\t\t\t\t\t     \"%d:%d node %d u%016llx c%016llx deleted\\n\",\n\t\t\t\t\t     proc->pid, thread->pid,\n\t\t\t\t\t     node_debug_id,\n\t\t\t\t\t     (u64)node_ptr,\n\t\t\t\t\t     (u64)node_cookie);\n\t\t\t\trb_erase(&node->rb_node, &proc->nodes);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\tbinder_node_lock(node);\n\t\t\t\t \n\t\t\t\tbinder_node_unlock(node);\n\t\t\t\tbinder_free_node(node);\n\t\t\t} else\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\n\t\t\tif (weak && !has_weak_ref)\n\t\t\t\tret = binder_put_node_cmd(\n\t\t\t\t\t\tproc, thread, &ptr, node_ptr,\n\t\t\t\t\t\tnode_cookie, node_debug_id,\n\t\t\t\t\t\tBR_INCREFS, \"BR_INCREFS\");\n\t\t\tif (!ret && strong && !has_strong_ref)\n\t\t\t\tret = binder_put_node_cmd(\n\t\t\t\t\t\tproc, thread, &ptr, node_ptr,\n\t\t\t\t\t\tnode_cookie, node_debug_id,\n\t\t\t\t\t\tBR_ACQUIRE, \"BR_ACQUIRE\");\n\t\t\tif (!ret && !strong && has_strong_ref)\n\t\t\t\tret = binder_put_node_cmd(\n\t\t\t\t\t\tproc, thread, &ptr, node_ptr,\n\t\t\t\t\t\tnode_cookie, node_debug_id,\n\t\t\t\t\t\tBR_RELEASE, \"BR_RELEASE\");\n\t\t\tif (!ret && !weak && has_weak_ref)\n\t\t\t\tret = binder_put_node_cmd(\n\t\t\t\t\t\tproc, thread, &ptr, node_ptr,\n\t\t\t\t\t\tnode_cookie, node_debug_id,\n\t\t\t\t\t\tBR_DECREFS, \"BR_DECREFS\");\n\t\t\tif (orig_ptr == ptr)\n\t\t\t\tbinder_debug(BINDER_DEBUG_INTERNAL_REFS,\n\t\t\t\t\t     \"%d:%d node %d u%016llx c%016llx state unchanged\\n\",\n\t\t\t\t\t     proc->pid, thread->pid,\n\t\t\t\t\t     node_debug_id,\n\t\t\t\t\t     (u64)node_ptr,\n\t\t\t\t\t     (u64)node_cookie);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t} break;\n\t\tcase BINDER_WORK_DEAD_BINDER:\n\t\tcase BINDER_WORK_DEAD_BINDER_AND_CLEAR:\n\t\tcase BINDER_WORK_CLEAR_DEATH_NOTIFICATION: {\n\t\t\tstruct binder_ref_death *death;\n\t\t\tuint32_t cmd;\n\t\t\tbinder_uintptr_t cookie;\n\n\t\t\tdeath = container_of(w, struct binder_ref_death, work);\n\t\t\tif (w->type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION)\n\t\t\t\tcmd = BR_CLEAR_DEATH_NOTIFICATION_DONE;\n\t\t\telse\n\t\t\t\tcmd = BR_DEAD_BINDER;\n\t\t\tcookie = death->cookie;\n\n\t\t\tbinder_debug(BINDER_DEBUG_DEATH_NOTIFICATION,\n\t\t\t\t     \"%d:%d %s %016llx\\n\",\n\t\t\t\t      proc->pid, thread->pid,\n\t\t\t\t      cmd == BR_DEAD_BINDER ?\n\t\t\t\t      \"BR_DEAD_BINDER\" :\n\t\t\t\t      \"BR_CLEAR_DEATH_NOTIFICATION_DONE\",\n\t\t\t\t      (u64)cookie);\n\t\t\tif (w->type == BINDER_WORK_CLEAR_DEATH_NOTIFICATION) {\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t\tkfree(death);\n\t\t\t\tbinder_stats_deleted(BINDER_STAT_DEATH);\n\t\t\t} else {\n\t\t\t\tbinder_enqueue_work_ilocked(\n\t\t\t\t\t\tw, &proc->delivered_death);\n\t\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\t}\n\t\t\tif (put_user(cmd, (uint32_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(uint32_t);\n\t\t\tif (put_user(cookie,\n\t\t\t\t     (binder_uintptr_t __user *)ptr))\n\t\t\t\treturn -EFAULT;\n\t\t\tptr += sizeof(binder_uintptr_t);\n\t\t\tbinder_stat_br(proc, thread, cmd);\n\t\t\tif (cmd == BR_DEAD_BINDER)\n\t\t\t\tgoto done;  \n\t\t} break;\n\t\tdefault:\n\t\t\tbinder_inner_proc_unlock(proc);\n\t\t\tpr_err(\"%d:%d: bad work type %d\\n\",\n\t\t\t       proc->pid, thread->pid, w->type);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!t)\n\t\t\tcontinue;\n\n\t\tBUG_ON(t->buffer == NULL);\n\t\tif (t->buffer->target_node) {\n\t\t\tstruct binder_node *target_node = t->buffer->target_node;\n\n\t\t\ttrd->target.ptr = target_node->ptr;\n\t\t\ttrd->cookie =  target_node->cookie;\n\t\t\tt->saved_priority = task_nice(current);\n\t\t\tif (t->priority < target_node->min_priority &&\n\t\t\t    !(t->flags & TF_ONE_WAY))\n\t\t\t\tbinder_set_nice(t->priority);\n\t\t\telse if (!(t->flags & TF_ONE_WAY) ||\n\t\t\t\t t->saved_priority > target_node->min_priority)\n\t\t\t\tbinder_set_nice(target_node->min_priority);\n\t\t\tcmd = BR_TRANSACTION;\n\t\t} else {\n\t\t\ttrd->target.ptr = 0;\n\t\t\ttrd->cookie = 0;\n\t\t\tcmd = BR_REPLY;\n\t\t}\n\t\ttrd->code = t->code;\n\t\ttrd->flags = t->flags;\n\t\ttrd->sender_euid = from_kuid(current_user_ns(), t->sender_euid);\n\n\t\tt_from = binder_get_txn_from(t);\n\t\tif (t_from) {\n\t\t\tstruct task_struct *sender = t_from->proc->tsk;\n\n\t\t\ttrd->sender_pid =\n\t\t\t\ttask_tgid_nr_ns(sender,\n\t\t\t\t\t\ttask_active_pid_ns(current));\n\t\t} else {\n\t\t\ttrd->sender_pid = 0;\n\t\t}\n\n\t\tret = binder_apply_fd_fixups(proc, t);\n\t\tif (ret) {\n\t\t\tstruct binder_buffer *buffer = t->buffer;\n\t\t\tbool oneway = !!(t->flags & TF_ONE_WAY);\n\t\t\tint tid = t->debug_id;\n\n\t\t\tif (t_from)\n\t\t\t\tbinder_thread_dec_tmpref(t_from);\n\t\t\tbuffer->transaction = NULL;\n\t\t\tbinder_cleanup_transaction(t, \"fd fixups failed\",\n\t\t\t\t\t\t   BR_FAILED_REPLY);\n\t\t\tbinder_free_buf(proc, thread, buffer, true);\n\t\t\tbinder_debug(BINDER_DEBUG_FAILED_TRANSACTION,\n\t\t\t\t     \"%d:%d %stransaction %d fd fixups failed %d/%d, line %d\\n\",\n\t\t\t\t     proc->pid, thread->pid,\n\t\t\t\t     oneway ? \"async \" :\n\t\t\t\t\t(cmd == BR_REPLY ? \"reply \" : \"\"),\n\t\t\t\t     tid, BR_FAILED_REPLY, ret, __LINE__);\n\t\t\tif (cmd == BR_REPLY) {\n\t\t\t\tcmd = BR_FAILED_REPLY;\n\t\t\t\tif (put_user(cmd, (uint32_t __user *)ptr))\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tptr += sizeof(uint32_t);\n\t\t\t\tbinder_stat_br(proc, thread, cmd);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\ttrd->data_size = t->buffer->data_size;\n\t\ttrd->offsets_size = t->buffer->offsets_size;\n\t\ttrd->data.ptr.buffer = (uintptr_t)t->buffer->user_data;\n\t\ttrd->data.ptr.offsets = trd->data.ptr.buffer +\n\t\t\t\t\tALIGN(t->buffer->data_size,\n\t\t\t\t\t    sizeof(void *));\n\n\t\ttr.secctx = t->security_ctx;\n\t\tif (t->security_ctx) {\n\t\t\tcmd = BR_TRANSACTION_SEC_CTX;\n\t\t\ttrsize = sizeof(tr);\n\t\t}\n\t\tif (put_user(cmd, (uint32_t __user *)ptr)) {\n\t\t\tif (t_from)\n\t\t\t\tbinder_thread_dec_tmpref(t_from);\n\n\t\t\tbinder_cleanup_transaction(t, \"put_user failed\",\n\t\t\t\t\t\t   BR_FAILED_REPLY);\n\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tptr += sizeof(uint32_t);\n\t\tif (copy_to_user(ptr, &tr, trsize)) {\n\t\t\tif (t_from)\n\t\t\t\tbinder_thread_dec_tmpref(t_from);\n\n\t\t\tbinder_cleanup_transaction(t, \"copy_to_user failed\",\n\t\t\t\t\t\t   BR_FAILED_REPLY);\n\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tptr += trsize;\n\n\t\ttrace_binder_transaction_received(t);\n\t\tbinder_stat_br(proc, thread, cmd);\n\t\tbinder_debug(BINDER_DEBUG_TRANSACTION,\n\t\t\t     \"%d:%d %s %d %d:%d, cmd %u size %zd-%zd ptr %016llx-%016llx\\n\",\n\t\t\t     proc->pid, thread->pid,\n\t\t\t     (cmd == BR_TRANSACTION) ? \"BR_TRANSACTION\" :\n\t\t\t\t(cmd == BR_TRANSACTION_SEC_CTX) ?\n\t\t\t\t     \"BR_TRANSACTION_SEC_CTX\" : \"BR_REPLY\",\n\t\t\t     t->debug_id, t_from ? t_from->proc->pid : 0,\n\t\t\t     t_from ? t_from->pid : 0, cmd,\n\t\t\t     t->buffer->data_size, t->buffer->offsets_size,\n\t\t\t     (u64)trd->data.ptr.buffer,\n\t\t\t     (u64)trd->data.ptr.offsets);\n\n\t\tif (t_from)\n\t\t\tbinder_thread_dec_tmpref(t_from);\n\t\tt->buffer->allow_user_free = 1;\n\t\tif (cmd != BR_REPLY && !(t->flags & TF_ONE_WAY)) {\n\t\t\tbinder_inner_proc_lock(thread->proc);\n\t\t\tt->to_parent = thread->transaction_stack;\n\t\t\tt->to_thread = thread;\n\t\t\tthread->transaction_stack = t;\n\t\t\tbinder_inner_proc_unlock(thread->proc);\n\t\t} else {\n\t\t\tbinder_free_transaction(t);\n\t\t}\n\t\tbreak;\n\t}\n\ndone:\n\n\t*consumed = ptr - buffer;\n\tbinder_inner_proc_lock(proc);\n\tif (proc->requested_threads == 0 &&\n\t    list_empty(&thread->proc->waiting_threads) &&\n\t    proc->requested_threads_started < proc->max_threads &&\n\t    (thread->looper & (BINDER_LOOPER_STATE_REGISTERED |\n\t     BINDER_LOOPER_STATE_ENTERED))  \n\t      ) {\n\t\tproc->requested_threads++;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_debug(BINDER_DEBUG_THREADS,\n\t\t\t     \"%d:%d BR_SPAWN_LOOPER\\n\",\n\t\t\t     proc->pid, thread->pid);\n\t\tif (put_user(BR_SPAWN_LOOPER, (uint32_t __user *)buffer))\n\t\t\treturn -EFAULT;\n\t\tbinder_stat_br(proc, thread, BR_SPAWN_LOOPER);\n\t} else\n\t\tbinder_inner_proc_unlock(proc);\n\treturn 0;\n}\n\nstatic void binder_release_work(struct binder_proc *proc,\n\t\t\t\tstruct list_head *list)\n{\n\tstruct binder_work *w;\n\tenum binder_work_type wtype;\n\n\twhile (1) {\n\t\tbinder_inner_proc_lock(proc);\n\t\tw = binder_dequeue_work_head_ilocked(list);\n\t\twtype = w ? w->type : 0;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (!w)\n\t\t\treturn;\n\n\t\tswitch (wtype) {\n\t\tcase BINDER_WORK_TRANSACTION: {\n\t\t\tstruct binder_transaction *t;\n\n\t\t\tt = container_of(w, struct binder_transaction, work);\n\n\t\t\tbinder_cleanup_transaction(t, \"process died.\",\n\t\t\t\t\t\t   BR_DEAD_REPLY);\n\t\t} break;\n\t\tcase BINDER_WORK_RETURN_ERROR: {\n\t\t\tstruct binder_error *e = container_of(\n\t\t\t\t\tw, struct binder_error, work);\n\n\t\t\tbinder_debug(BINDER_DEBUG_DEAD_TRANSACTION,\n\t\t\t\t\"undelivered TRANSACTION_ERROR: %u\\n\",\n\t\t\t\te->cmd);\n\t\t} break;\n\t\tcase BINDER_WORK_TRANSACTION_PENDING:\n\t\tcase BINDER_WORK_TRANSACTION_ONEWAY_SPAM_SUSPECT:\n\t\tcase BINDER_WORK_TRANSACTION_COMPLETE: {\n\t\t\tbinder_debug(BINDER_DEBUG_DEAD_TRANSACTION,\n\t\t\t\t\"undelivered TRANSACTION_COMPLETE\\n\");\n\t\t\tkfree(w);\n\t\t\tbinder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);\n\t\t} break;\n\t\tcase BINDER_WORK_DEAD_BINDER_AND_CLEAR:\n\t\tcase BINDER_WORK_CLEAR_DEATH_NOTIFICATION: {\n\t\t\tstruct binder_ref_death *death;\n\n\t\t\tdeath = container_of(w, struct binder_ref_death, work);\n\t\t\tbinder_debug(BINDER_DEBUG_DEAD_TRANSACTION,\n\t\t\t\t\"undelivered death notification, %016llx\\n\",\n\t\t\t\t(u64)death->cookie);\n\t\t\tkfree(death);\n\t\t\tbinder_stats_deleted(BINDER_STAT_DEATH);\n\t\t} break;\n\t\tcase BINDER_WORK_NODE:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"unexpected work type, %d, not freed\\n\",\n\t\t\t       wtype);\n\t\t\tbreak;\n\t\t}\n\t}\n\n}\n\nstatic struct binder_thread *binder_get_thread_ilocked(\n\t\tstruct binder_proc *proc, struct binder_thread *new_thread)\n{\n\tstruct binder_thread *thread = NULL;\n\tstruct rb_node *parent = NULL;\n\tstruct rb_node **p = &proc->threads.rb_node;\n\n\twhile (*p) {\n\t\tparent = *p;\n\t\tthread = rb_entry(parent, struct binder_thread, rb_node);\n\n\t\tif (current->pid < thread->pid)\n\t\t\tp = &(*p)->rb_left;\n\t\telse if (current->pid > thread->pid)\n\t\t\tp = &(*p)->rb_right;\n\t\telse\n\t\t\treturn thread;\n\t}\n\tif (!new_thread)\n\t\treturn NULL;\n\tthread = new_thread;\n\tbinder_stats_created(BINDER_STAT_THREAD);\n\tthread->proc = proc;\n\tthread->pid = current->pid;\n\tatomic_set(&thread->tmp_ref, 0);\n\tinit_waitqueue_head(&thread->wait);\n\tINIT_LIST_HEAD(&thread->todo);\n\trb_link_node(&thread->rb_node, parent, p);\n\trb_insert_color(&thread->rb_node, &proc->threads);\n\tthread->looper_need_return = true;\n\tthread->return_error.work.type = BINDER_WORK_RETURN_ERROR;\n\tthread->return_error.cmd = BR_OK;\n\tthread->reply_error.work.type = BINDER_WORK_RETURN_ERROR;\n\tthread->reply_error.cmd = BR_OK;\n\tthread->ee.command = BR_OK;\n\tINIT_LIST_HEAD(&new_thread->waiting_thread_node);\n\treturn thread;\n}\n\nstatic struct binder_thread *binder_get_thread(struct binder_proc *proc)\n{\n\tstruct binder_thread *thread;\n\tstruct binder_thread *new_thread;\n\n\tbinder_inner_proc_lock(proc);\n\tthread = binder_get_thread_ilocked(proc, NULL);\n\tbinder_inner_proc_unlock(proc);\n\tif (!thread) {\n\t\tnew_thread = kzalloc(sizeof(*thread), GFP_KERNEL);\n\t\tif (new_thread == NULL)\n\t\t\treturn NULL;\n\t\tbinder_inner_proc_lock(proc);\n\t\tthread = binder_get_thread_ilocked(proc, new_thread);\n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (thread != new_thread)\n\t\t\tkfree(new_thread);\n\t}\n\treturn thread;\n}\n\nstatic void binder_free_proc(struct binder_proc *proc)\n{\n\tstruct binder_device *device;\n\n\tBUG_ON(!list_empty(&proc->todo));\n\tBUG_ON(!list_empty(&proc->delivered_death));\n\tif (proc->outstanding_txns)\n\t\tpr_warn(\"%s: Unexpected outstanding_txns %d\\n\",\n\t\t\t__func__, proc->outstanding_txns);\n\tdevice = container_of(proc->context, struct binder_device, context);\n\tif (refcount_dec_and_test(&device->ref)) {\n\t\tkfree(proc->context->name);\n\t\tkfree(device);\n\t}\n\tbinder_alloc_deferred_release(&proc->alloc);\n\tput_task_struct(proc->tsk);\n\tput_cred(proc->cred);\n\tbinder_stats_deleted(BINDER_STAT_PROC);\n\tkfree(proc);\n}\n\nstatic void binder_free_thread(struct binder_thread *thread)\n{\n\tBUG_ON(!list_empty(&thread->todo));\n\tbinder_stats_deleted(BINDER_STAT_THREAD);\n\tbinder_proc_dec_tmpref(thread->proc);\n\tkfree(thread);\n}\n\nstatic int binder_thread_release(struct binder_proc *proc,\n\t\t\t\t struct binder_thread *thread)\n{\n\tstruct binder_transaction *t;\n\tstruct binder_transaction *send_reply = NULL;\n\tint active_transactions = 0;\n\tstruct binder_transaction *last_t = NULL;\n\n\tbinder_inner_proc_lock(thread->proc);\n\t \n\tproc->tmp_ref++;\n\t \n\tatomic_inc(&thread->tmp_ref);\n\trb_erase(&thread->rb_node, &proc->threads);\n\tt = thread->transaction_stack;\n\tif (t) {\n\t\tspin_lock(&t->lock);\n\t\tif (t->to_thread == thread)\n\t\t\tsend_reply = t;\n\t} else {\n\t\t__acquire(&t->lock);\n\t}\n\tthread->is_dead = true;\n\n\twhile (t) {\n\t\tlast_t = t;\n\t\tactive_transactions++;\n\t\tbinder_debug(BINDER_DEBUG_DEAD_TRANSACTION,\n\t\t\t     \"release %d:%d transaction %d %s, still active\\n\",\n\t\t\t      proc->pid, thread->pid,\n\t\t\t     t->debug_id,\n\t\t\t     (t->to_thread == thread) ? \"in\" : \"out\");\n\n\t\tif (t->to_thread == thread) {\n\t\t\tthread->proc->outstanding_txns--;\n\t\t\tt->to_proc = NULL;\n\t\t\tt->to_thread = NULL;\n\t\t\tif (t->buffer) {\n\t\t\t\tt->buffer->transaction = NULL;\n\t\t\t\tt->buffer = NULL;\n\t\t\t}\n\t\t\tt = t->to_parent;\n\t\t} else if (t->from == thread) {\n\t\t\tt->from = NULL;\n\t\t\tt = t->from_parent;\n\t\t} else\n\t\t\tBUG();\n\t\tspin_unlock(&last_t->lock);\n\t\tif (t)\n\t\t\tspin_lock(&t->lock);\n\t\telse\n\t\t\t__acquire(&t->lock);\n\t}\n\t \n\t__release(&t->lock);\n\n\t \n\tif (thread->looper & BINDER_LOOPER_STATE_POLL)\n\t\twake_up_pollfree(&thread->wait);\n\n\tbinder_inner_proc_unlock(thread->proc);\n\n\t \n\tif (thread->looper & BINDER_LOOPER_STATE_POLL)\n\t\tsynchronize_rcu();\n\n\tif (send_reply)\n\t\tbinder_send_failed_reply(send_reply, BR_DEAD_REPLY);\n\tbinder_release_work(proc, &thread->todo);\n\tbinder_thread_dec_tmpref(thread);\n\treturn active_transactions;\n}\n\nstatic __poll_t binder_poll(struct file *filp,\n\t\t\t\tstruct poll_table_struct *wait)\n{\n\tstruct binder_proc *proc = filp->private_data;\n\tstruct binder_thread *thread = NULL;\n\tbool wait_for_proc_work;\n\n\tthread = binder_get_thread(proc);\n\tif (!thread)\n\t\treturn EPOLLERR;\n\n\tbinder_inner_proc_lock(thread->proc);\n\tthread->looper |= BINDER_LOOPER_STATE_POLL;\n\twait_for_proc_work = binder_available_for_proc_work_ilocked(thread);\n\n\tbinder_inner_proc_unlock(thread->proc);\n\n\tpoll_wait(filp, &thread->wait, wait);\n\n\tif (binder_has_work(thread, wait_for_proc_work))\n\t\treturn EPOLLIN;\n\n\treturn 0;\n}\n\nstatic int binder_ioctl_write_read(struct file *filp, unsigned long arg,\n\t\t\t\tstruct binder_thread *thread)\n{\n\tint ret = 0;\n\tstruct binder_proc *proc = filp->private_data;\n\tvoid __user *ubuf = (void __user *)arg;\n\tstruct binder_write_read bwr;\n\n\tif (copy_from_user(&bwr, ubuf, sizeof(bwr))) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\tbinder_debug(BINDER_DEBUG_READ_WRITE,\n\t\t     \"%d:%d write %lld at %016llx, read %lld at %016llx\\n\",\n\t\t     proc->pid, thread->pid,\n\t\t     (u64)bwr.write_size, (u64)bwr.write_buffer,\n\t\t     (u64)bwr.read_size, (u64)bwr.read_buffer);\n\n\tif (bwr.write_size > 0) {\n\t\tret = binder_thread_write(proc, thread,\n\t\t\t\t\t  bwr.write_buffer,\n\t\t\t\t\t  bwr.write_size,\n\t\t\t\t\t  &bwr.write_consumed);\n\t\ttrace_binder_write_done(ret);\n\t\tif (ret < 0) {\n\t\t\tbwr.read_consumed = 0;\n\t\t\tif (copy_to_user(ubuf, &bwr, sizeof(bwr)))\n\t\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif (bwr.read_size > 0) {\n\t\tret = binder_thread_read(proc, thread, bwr.read_buffer,\n\t\t\t\t\t bwr.read_size,\n\t\t\t\t\t &bwr.read_consumed,\n\t\t\t\t\t filp->f_flags & O_NONBLOCK);\n\t\ttrace_binder_read_done(ret);\n\t\tbinder_inner_proc_lock(proc);\n\t\tif (!binder_worklist_empty_ilocked(&proc->todo))\n\t\t\tbinder_wakeup_proc_ilocked(proc);\n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (ret < 0) {\n\t\t\tif (copy_to_user(ubuf, &bwr, sizeof(bwr)))\n\t\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\tbinder_debug(BINDER_DEBUG_READ_WRITE,\n\t\t     \"%d:%d wrote %lld of %lld, read return %lld of %lld\\n\",\n\t\t     proc->pid, thread->pid,\n\t\t     (u64)bwr.write_consumed, (u64)bwr.write_size,\n\t\t     (u64)bwr.read_consumed, (u64)bwr.read_size);\n\tif (copy_to_user(ubuf, &bwr, sizeof(bwr))) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\nout:\n\treturn ret;\n}\n\nstatic int binder_ioctl_set_ctx_mgr(struct file *filp,\n\t\t\t\t    struct flat_binder_object *fbo)\n{\n\tint ret = 0;\n\tstruct binder_proc *proc = filp->private_data;\n\tstruct binder_context *context = proc->context;\n\tstruct binder_node *new_node;\n\tkuid_t curr_euid = current_euid();\n\n\tmutex_lock(&context->context_mgr_node_lock);\n\tif (context->binder_context_mgr_node) {\n\t\tpr_err(\"BINDER_SET_CONTEXT_MGR already set\\n\");\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\tret = security_binder_set_context_mgr(proc->cred);\n\tif (ret < 0)\n\t\tgoto out;\n\tif (uid_valid(context->binder_context_mgr_uid)) {\n\t\tif (!uid_eq(context->binder_context_mgr_uid, curr_euid)) {\n\t\t\tpr_err(\"BINDER_SET_CONTEXT_MGR bad uid %d != %d\\n\",\n\t\t\t       from_kuid(&init_user_ns, curr_euid),\n\t\t\t       from_kuid(&init_user_ns,\n\t\t\t\t\t context->binder_context_mgr_uid));\n\t\t\tret = -EPERM;\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tcontext->binder_context_mgr_uid = curr_euid;\n\t}\n\tnew_node = binder_new_node(proc, fbo);\n\tif (!new_node) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tbinder_node_lock(new_node);\n\tnew_node->local_weak_refs++;\n\tnew_node->local_strong_refs++;\n\tnew_node->has_strong_ref = 1;\n\tnew_node->has_weak_ref = 1;\n\tcontext->binder_context_mgr_node = new_node;\n\tbinder_node_unlock(new_node);\n\tbinder_put_node(new_node);\nout:\n\tmutex_unlock(&context->context_mgr_node_lock);\n\treturn ret;\n}\n\nstatic int binder_ioctl_get_node_info_for_ref(struct binder_proc *proc,\n\t\tstruct binder_node_info_for_ref *info)\n{\n\tstruct binder_node *node;\n\tstruct binder_context *context = proc->context;\n\t__u32 handle = info->handle;\n\n\tif (info->strong_count || info->weak_count || info->reserved1 ||\n\t    info->reserved2 || info->reserved3) {\n\t\tbinder_user_error(\"%d BINDER_GET_NODE_INFO_FOR_REF: only handle may be non-zero.\",\n\t\t\t\t  proc->pid);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tmutex_lock(&context->context_mgr_node_lock);\n\tif (!context->binder_context_mgr_node ||\n\t\tcontext->binder_context_mgr_node->proc != proc) {\n\t\tmutex_unlock(&context->context_mgr_node_lock);\n\t\treturn -EPERM;\n\t}\n\tmutex_unlock(&context->context_mgr_node_lock);\n\n\tnode = binder_get_node_from_ref(proc, handle, true, NULL);\n\tif (!node)\n\t\treturn -EINVAL;\n\n\tinfo->strong_count = node->local_strong_refs +\n\t\tnode->internal_strong_refs;\n\tinfo->weak_count = node->local_weak_refs;\n\n\tbinder_put_node(node);\n\n\treturn 0;\n}\n\nstatic int binder_ioctl_get_node_debug_info(struct binder_proc *proc,\n\t\t\t\tstruct binder_node_debug_info *info)\n{\n\tstruct rb_node *n;\n\tbinder_uintptr_t ptr = info->ptr;\n\n\tmemset(info, 0, sizeof(*info));\n\n\tbinder_inner_proc_lock(proc);\n\tfor (n = rb_first(&proc->nodes); n != NULL; n = rb_next(n)) {\n\t\tstruct binder_node *node = rb_entry(n, struct binder_node,\n\t\t\t\t\t\t    rb_node);\n\t\tif (node->ptr > ptr) {\n\t\t\tinfo->ptr = node->ptr;\n\t\t\tinfo->cookie = node->cookie;\n\t\t\tinfo->has_strong_ref = node->has_strong_ref;\n\t\t\tinfo->has_weak_ref = node->has_weak_ref;\n\t\t\tbreak;\n\t\t}\n\t}\n\tbinder_inner_proc_unlock(proc);\n\n\treturn 0;\n}\n\nstatic bool binder_txns_pending_ilocked(struct binder_proc *proc)\n{\n\tstruct rb_node *n;\n\tstruct binder_thread *thread;\n\n\tif (proc->outstanding_txns > 0)\n\t\treturn true;\n\n\tfor (n = rb_first(&proc->threads); n; n = rb_next(n)) {\n\t\tthread = rb_entry(n, struct binder_thread, rb_node);\n\t\tif (thread->transaction_stack)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic int binder_ioctl_freeze(struct binder_freeze_info *info,\n\t\t\t       struct binder_proc *target_proc)\n{\n\tint ret = 0;\n\n\tif (!info->enable) {\n\t\tbinder_inner_proc_lock(target_proc);\n\t\ttarget_proc->sync_recv = false;\n\t\ttarget_proc->async_recv = false;\n\t\ttarget_proc->is_frozen = false;\n\t\tbinder_inner_proc_unlock(target_proc);\n\t\treturn 0;\n\t}\n\n\t \n\tbinder_inner_proc_lock(target_proc);\n\ttarget_proc->sync_recv = false;\n\ttarget_proc->async_recv = false;\n\ttarget_proc->is_frozen = true;\n\tbinder_inner_proc_unlock(target_proc);\n\n\tif (info->timeout_ms > 0)\n\t\tret = wait_event_interruptible_timeout(\n\t\t\ttarget_proc->freeze_wait,\n\t\t\t(!target_proc->outstanding_txns),\n\t\t\tmsecs_to_jiffies(info->timeout_ms));\n\n\t \n\tif (ret >= 0) {\n\t\tbinder_inner_proc_lock(target_proc);\n\t\tif (binder_txns_pending_ilocked(target_proc))\n\t\t\tret = -EAGAIN;\n\t\tbinder_inner_proc_unlock(target_proc);\n\t}\n\n\tif (ret < 0) {\n\t\tbinder_inner_proc_lock(target_proc);\n\t\ttarget_proc->is_frozen = false;\n\t\tbinder_inner_proc_unlock(target_proc);\n\t}\n\n\treturn ret;\n}\n\nstatic int binder_ioctl_get_freezer_info(\n\t\t\t\tstruct binder_frozen_status_info *info)\n{\n\tstruct binder_proc *target_proc;\n\tbool found = false;\n\t__u32 txns_pending;\n\n\tinfo->sync_recv = 0;\n\tinfo->async_recv = 0;\n\n\tmutex_lock(&binder_procs_lock);\n\thlist_for_each_entry(target_proc, &binder_procs, proc_node) {\n\t\tif (target_proc->pid == info->pid) {\n\t\t\tfound = true;\n\t\t\tbinder_inner_proc_lock(target_proc);\n\t\t\ttxns_pending = binder_txns_pending_ilocked(target_proc);\n\t\t\tinfo->sync_recv |= target_proc->sync_recv |\n\t\t\t\t\t(txns_pending << 1);\n\t\t\tinfo->async_recv |= target_proc->async_recv;\n\t\t\tbinder_inner_proc_unlock(target_proc);\n\t\t}\n\t}\n\tmutex_unlock(&binder_procs_lock);\n\n\tif (!found)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int binder_ioctl_get_extended_error(struct binder_thread *thread,\n\t\t\t\t\t   void __user *ubuf)\n{\n\tstruct binder_extended_error ee;\n\n\tbinder_inner_proc_lock(thread->proc);\n\tee = thread->ee;\n\tbinder_set_extended_error(&thread->ee, 0, BR_OK, 0);\n\tbinder_inner_proc_unlock(thread->proc);\n\n\tif (copy_to_user(ubuf, &ee, sizeof(ee)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)\n{\n\tint ret;\n\tstruct binder_proc *proc = filp->private_data;\n\tstruct binder_thread *thread;\n\tvoid __user *ubuf = (void __user *)arg;\n\n\t \n\n\tbinder_selftest_alloc(&proc->alloc);\n\n\ttrace_binder_ioctl(cmd, arg);\n\n\tret = wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error < 2);\n\tif (ret)\n\t\tgoto err_unlocked;\n\n\tthread = binder_get_thread(proc);\n\tif (thread == NULL) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tswitch (cmd) {\n\tcase BINDER_WRITE_READ:\n\t\tret = binder_ioctl_write_read(filp, arg, thread);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbreak;\n\tcase BINDER_SET_MAX_THREADS: {\n\t\tint max_threads;\n\n\t\tif (copy_from_user(&max_threads, ubuf,\n\t\t\t\t   sizeof(max_threads))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tbinder_inner_proc_lock(proc);\n\t\tproc->max_threads = max_threads;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbreak;\n\t}\n\tcase BINDER_SET_CONTEXT_MGR_EXT: {\n\t\tstruct flat_binder_object fbo;\n\n\t\tif (copy_from_user(&fbo, ubuf, sizeof(fbo))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tret = binder_ioctl_set_ctx_mgr(filp, &fbo);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbreak;\n\t}\n\tcase BINDER_SET_CONTEXT_MGR:\n\t\tret = binder_ioctl_set_ctx_mgr(filp, NULL);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbreak;\n\tcase BINDER_THREAD_EXIT:\n\t\tbinder_debug(BINDER_DEBUG_THREADS, \"%d:%d exit\\n\",\n\t\t\t     proc->pid, thread->pid);\n\t\tbinder_thread_release(proc, thread);\n\t\tthread = NULL;\n\t\tbreak;\n\tcase BINDER_VERSION: {\n\t\tstruct binder_version __user *ver = ubuf;\n\n\t\tif (put_user(BINDER_CURRENT_PROTOCOL_VERSION,\n\t\t\t     &ver->protocol_version)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tbreak;\n\t}\n\tcase BINDER_GET_NODE_INFO_FOR_REF: {\n\t\tstruct binder_node_info_for_ref info;\n\n\t\tif (copy_from_user(&info, ubuf, sizeof(info))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = binder_ioctl_get_node_info_for_ref(proc, &info);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\n\t\tif (copy_to_user(ubuf, &info, sizeof(info))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase BINDER_GET_NODE_DEBUG_INFO: {\n\t\tstruct binder_node_debug_info info;\n\n\t\tif (copy_from_user(&info, ubuf, sizeof(info))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = binder_ioctl_get_node_debug_info(proc, &info);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\n\t\tif (copy_to_user(ubuf, &info, sizeof(info))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\t\tbreak;\n\t}\n\tcase BINDER_FREEZE: {\n\t\tstruct binder_freeze_info info;\n\t\tstruct binder_proc **target_procs = NULL, *target_proc;\n\t\tint target_procs_count = 0, i = 0;\n\n\t\tret = 0;\n\n\t\tif (copy_from_user(&info, ubuf, sizeof(info))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\n\t\tmutex_lock(&binder_procs_lock);\n\t\thlist_for_each_entry(target_proc, &binder_procs, proc_node) {\n\t\t\tif (target_proc->pid == info.pid)\n\t\t\t\ttarget_procs_count++;\n\t\t}\n\n\t\tif (target_procs_count == 0) {\n\t\t\tmutex_unlock(&binder_procs_lock);\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\n\t\ttarget_procs = kcalloc(target_procs_count,\n\t\t\t\t       sizeof(struct binder_proc *),\n\t\t\t\t       GFP_KERNEL);\n\n\t\tif (!target_procs) {\n\t\t\tmutex_unlock(&binder_procs_lock);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\thlist_for_each_entry(target_proc, &binder_procs, proc_node) {\n\t\t\tif (target_proc->pid != info.pid)\n\t\t\t\tcontinue;\n\n\t\t\tbinder_inner_proc_lock(target_proc);\n\t\t\ttarget_proc->tmp_ref++;\n\t\t\tbinder_inner_proc_unlock(target_proc);\n\n\t\t\ttarget_procs[i++] = target_proc;\n\t\t}\n\t\tmutex_unlock(&binder_procs_lock);\n\n\t\tfor (i = 0; i < target_procs_count; i++) {\n\t\t\tif (ret >= 0)\n\t\t\t\tret = binder_ioctl_freeze(&info,\n\t\t\t\t\t\t\t  target_procs[i]);\n\n\t\t\tbinder_proc_dec_tmpref(target_procs[i]);\n\t\t}\n\n\t\tkfree(target_procs);\n\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\t\tbreak;\n\t}\n\tcase BINDER_GET_FROZEN_INFO: {\n\t\tstruct binder_frozen_status_info info;\n\n\t\tif (copy_from_user(&info, ubuf, sizeof(info))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\n\t\tret = binder_ioctl_get_freezer_info(&info);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\n\t\tif (copy_to_user(ubuf, &info, sizeof(info))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\t\tbreak;\n\t}\n\tcase BINDER_ENABLE_ONEWAY_SPAM_DETECTION: {\n\t\tuint32_t enable;\n\n\t\tif (copy_from_user(&enable, ubuf, sizeof(enable))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\t\tbinder_inner_proc_lock(proc);\n\t\tproc->oneway_spam_detection_enabled = (bool)enable;\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbreak;\n\t}\n\tcase BINDER_GET_EXTENDED_ERROR:\n\t\tret = binder_ioctl_get_extended_error(thread, ubuf);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\tret = 0;\nerr:\n\tif (thread)\n\t\tthread->looper_need_return = false;\n\twait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error < 2);\n\tif (ret && ret != -EINTR)\n\t\tpr_info(\"%d:%d ioctl %x %lx returned %d\\n\", proc->pid, current->pid, cmd, arg, ret);\nerr_unlocked:\n\ttrace_binder_ioctl_done(ret);\n\treturn ret;\n}\n\nstatic void binder_vma_open(struct vm_area_struct *vma)\n{\n\tstruct binder_proc *proc = vma->vm_private_data;\n\n\tbinder_debug(BINDER_DEBUG_OPEN_CLOSE,\n\t\t     \"%d open vm area %lx-%lx (%ld K) vma %lx pagep %lx\\n\",\n\t\t     proc->pid, vma->vm_start, vma->vm_end,\n\t\t     (vma->vm_end - vma->vm_start) / SZ_1K, vma->vm_flags,\n\t\t     (unsigned long)pgprot_val(vma->vm_page_prot));\n}\n\nstatic void binder_vma_close(struct vm_area_struct *vma)\n{\n\tstruct binder_proc *proc = vma->vm_private_data;\n\n\tbinder_debug(BINDER_DEBUG_OPEN_CLOSE,\n\t\t     \"%d close vm area %lx-%lx (%ld K) vma %lx pagep %lx\\n\",\n\t\t     proc->pid, vma->vm_start, vma->vm_end,\n\t\t     (vma->vm_end - vma->vm_start) / SZ_1K, vma->vm_flags,\n\t\t     (unsigned long)pgprot_val(vma->vm_page_prot));\n\tbinder_alloc_vma_close(&proc->alloc);\n}\n\nstatic vm_fault_t binder_vm_fault(struct vm_fault *vmf)\n{\n\treturn VM_FAULT_SIGBUS;\n}\n\nstatic const struct vm_operations_struct binder_vm_ops = {\n\t.open = binder_vma_open,\n\t.close = binder_vma_close,\n\t.fault = binder_vm_fault,\n};\n\nstatic int binder_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\tstruct binder_proc *proc = filp->private_data;\n\n\tif (proc->tsk != current->group_leader)\n\t\treturn -EINVAL;\n\n\tbinder_debug(BINDER_DEBUG_OPEN_CLOSE,\n\t\t     \"%s: %d %lx-%lx (%ld K) vma %lx pagep %lx\\n\",\n\t\t     __func__, proc->pid, vma->vm_start, vma->vm_end,\n\t\t     (vma->vm_end - vma->vm_start) / SZ_1K, vma->vm_flags,\n\t\t     (unsigned long)pgprot_val(vma->vm_page_prot));\n\n\tif (vma->vm_flags & FORBIDDEN_MMAP_FLAGS) {\n\t\tpr_err(\"%s: %d %lx-%lx %s failed %d\\n\", __func__,\n\t\t       proc->pid, vma->vm_start, vma->vm_end, \"bad vm_flags\", -EPERM);\n\t\treturn -EPERM;\n\t}\n\tvm_flags_mod(vma, VM_DONTCOPY | VM_MIXEDMAP, VM_MAYWRITE);\n\n\tvma->vm_ops = &binder_vm_ops;\n\tvma->vm_private_data = proc;\n\n\treturn binder_alloc_mmap_handler(&proc->alloc, vma);\n}\n\nstatic int binder_open(struct inode *nodp, struct file *filp)\n{\n\tstruct binder_proc *proc, *itr;\n\tstruct binder_device *binder_dev;\n\tstruct binderfs_info *info;\n\tstruct dentry *binder_binderfs_dir_entry_proc = NULL;\n\tbool existing_pid = false;\n\n\tbinder_debug(BINDER_DEBUG_OPEN_CLOSE, \"%s: %d:%d\\n\", __func__,\n\t\t     current->group_leader->pid, current->pid);\n\n\tproc = kzalloc(sizeof(*proc), GFP_KERNEL);\n\tif (proc == NULL)\n\t\treturn -ENOMEM;\n\tspin_lock_init(&proc->inner_lock);\n\tspin_lock_init(&proc->outer_lock);\n\tget_task_struct(current->group_leader);\n\tproc->tsk = current->group_leader;\n\tproc->cred = get_cred(filp->f_cred);\n\tINIT_LIST_HEAD(&proc->todo);\n\tinit_waitqueue_head(&proc->freeze_wait);\n\tproc->default_priority = task_nice(current);\n\t \n\tif (is_binderfs_device(nodp)) {\n\t\tbinder_dev = nodp->i_private;\n\t\tinfo = nodp->i_sb->s_fs_info;\n\t\tbinder_binderfs_dir_entry_proc = info->proc_log_dir;\n\t} else {\n\t\tbinder_dev = container_of(filp->private_data,\n\t\t\t\t\t  struct binder_device, miscdev);\n\t}\n\trefcount_inc(&binder_dev->ref);\n\tproc->context = &binder_dev->context;\n\tbinder_alloc_init(&proc->alloc);\n\n\tbinder_stats_created(BINDER_STAT_PROC);\n\tproc->pid = current->group_leader->pid;\n\tINIT_LIST_HEAD(&proc->delivered_death);\n\tINIT_LIST_HEAD(&proc->waiting_threads);\n\tfilp->private_data = proc;\n\n\tmutex_lock(&binder_procs_lock);\n\thlist_for_each_entry(itr, &binder_procs, proc_node) {\n\t\tif (itr->pid == proc->pid) {\n\t\t\texisting_pid = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\thlist_add_head(&proc->proc_node, &binder_procs);\n\tmutex_unlock(&binder_procs_lock);\n\n\tif (binder_debugfs_dir_entry_proc && !existing_pid) {\n\t\tchar strbuf[11];\n\n\t\tsnprintf(strbuf, sizeof(strbuf), \"%u\", proc->pid);\n\t\t \n\t\tproc->debugfs_entry = debugfs_create_file(strbuf, 0444,\n\t\t\tbinder_debugfs_dir_entry_proc,\n\t\t\t(void *)(unsigned long)proc->pid,\n\t\t\t&proc_fops);\n\t}\n\n\tif (binder_binderfs_dir_entry_proc && !existing_pid) {\n\t\tchar strbuf[11];\n\t\tstruct dentry *binderfs_entry;\n\n\t\tsnprintf(strbuf, sizeof(strbuf), \"%u\", proc->pid);\n\t\t \n\t\tbinderfs_entry = binderfs_create_file(binder_binderfs_dir_entry_proc,\n\t\t\tstrbuf, &proc_fops, (void *)(unsigned long)proc->pid);\n\t\tif (!IS_ERR(binderfs_entry)) {\n\t\t\tproc->binderfs_entry = binderfs_entry;\n\t\t} else {\n\t\t\tint error;\n\n\t\t\terror = PTR_ERR(binderfs_entry);\n\t\t\tpr_warn(\"Unable to create file %s in binderfs (error %d)\\n\",\n\t\t\t\tstrbuf, error);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int binder_flush(struct file *filp, fl_owner_t id)\n{\n\tstruct binder_proc *proc = filp->private_data;\n\n\tbinder_defer_work(proc, BINDER_DEFERRED_FLUSH);\n\n\treturn 0;\n}\n\nstatic void binder_deferred_flush(struct binder_proc *proc)\n{\n\tstruct rb_node *n;\n\tint wake_count = 0;\n\n\tbinder_inner_proc_lock(proc);\n\tfor (n = rb_first(&proc->threads); n != NULL; n = rb_next(n)) {\n\t\tstruct binder_thread *thread = rb_entry(n, struct binder_thread, rb_node);\n\n\t\tthread->looper_need_return = true;\n\t\tif (thread->looper & BINDER_LOOPER_STATE_WAITING) {\n\t\t\twake_up_interruptible(&thread->wait);\n\t\t\twake_count++;\n\t\t}\n\t}\n\tbinder_inner_proc_unlock(proc);\n\n\tbinder_debug(BINDER_DEBUG_OPEN_CLOSE,\n\t\t     \"binder_flush: %d woke %d threads\\n\", proc->pid,\n\t\t     wake_count);\n}\n\nstatic int binder_release(struct inode *nodp, struct file *filp)\n{\n\tstruct binder_proc *proc = filp->private_data;\n\n\tdebugfs_remove(proc->debugfs_entry);\n\n\tif (proc->binderfs_entry) {\n\t\tbinderfs_remove_file(proc->binderfs_entry);\n\t\tproc->binderfs_entry = NULL;\n\t}\n\n\tbinder_defer_work(proc, BINDER_DEFERRED_RELEASE);\n\n\treturn 0;\n}\n\nstatic int binder_node_release(struct binder_node *node, int refs)\n{\n\tstruct binder_ref *ref;\n\tint death = 0;\n\tstruct binder_proc *proc = node->proc;\n\n\tbinder_release_work(proc, &node->async_todo);\n\n\tbinder_node_lock(node);\n\tbinder_inner_proc_lock(proc);\n\tbinder_dequeue_work_ilocked(&node->work);\n\t \n\tBUG_ON(!node->tmp_refs);\n\tif (hlist_empty(&node->refs) && node->tmp_refs == 1) {\n\t\tbinder_inner_proc_unlock(proc);\n\t\tbinder_node_unlock(node);\n\t\tbinder_free_node(node);\n\n\t\treturn refs;\n\t}\n\n\tnode->proc = NULL;\n\tnode->local_strong_refs = 0;\n\tnode->local_weak_refs = 0;\n\tbinder_inner_proc_unlock(proc);\n\n\tspin_lock(&binder_dead_nodes_lock);\n\thlist_add_head(&node->dead_node, &binder_dead_nodes);\n\tspin_unlock(&binder_dead_nodes_lock);\n\n\thlist_for_each_entry(ref, &node->refs, node_entry) {\n\t\trefs++;\n\t\t \n\t\tbinder_inner_proc_lock(ref->proc);\n\t\tif (!ref->death) {\n\t\t\tbinder_inner_proc_unlock(ref->proc);\n\t\t\tcontinue;\n\t\t}\n\n\t\tdeath++;\n\n\t\tBUG_ON(!list_empty(&ref->death->work.entry));\n\t\tref->death->work.type = BINDER_WORK_DEAD_BINDER;\n\t\tbinder_enqueue_work_ilocked(&ref->death->work,\n\t\t\t\t\t    &ref->proc->todo);\n\t\tbinder_wakeup_proc_ilocked(ref->proc);\n\t\tbinder_inner_proc_unlock(ref->proc);\n\t}\n\n\tbinder_debug(BINDER_DEBUG_DEAD_BINDER,\n\t\t     \"node %d now dead, refs %d, death %d\\n\",\n\t\t     node->debug_id, refs, death);\n\tbinder_node_unlock(node);\n\tbinder_put_node(node);\n\n\treturn refs;\n}\n\nstatic void binder_deferred_release(struct binder_proc *proc)\n{\n\tstruct binder_context *context = proc->context;\n\tstruct rb_node *n;\n\tint threads, nodes, incoming_refs, outgoing_refs, active_transactions;\n\n\tmutex_lock(&binder_procs_lock);\n\thlist_del(&proc->proc_node);\n\tmutex_unlock(&binder_procs_lock);\n\n\tmutex_lock(&context->context_mgr_node_lock);\n\tif (context->binder_context_mgr_node &&\n\t    context->binder_context_mgr_node->proc == proc) {\n\t\tbinder_debug(BINDER_DEBUG_DEAD_BINDER,\n\t\t\t     \"%s: %d context_mgr_node gone\\n\",\n\t\t\t     __func__, proc->pid);\n\t\tcontext->binder_context_mgr_node = NULL;\n\t}\n\tmutex_unlock(&context->context_mgr_node_lock);\n\tbinder_inner_proc_lock(proc);\n\t \n\tproc->tmp_ref++;\n\n\tproc->is_dead = true;\n\tproc->is_frozen = false;\n\tproc->sync_recv = false;\n\tproc->async_recv = false;\n\tthreads = 0;\n\tactive_transactions = 0;\n\twhile ((n = rb_first(&proc->threads))) {\n\t\tstruct binder_thread *thread;\n\n\t\tthread = rb_entry(n, struct binder_thread, rb_node);\n\t\tbinder_inner_proc_unlock(proc);\n\t\tthreads++;\n\t\tactive_transactions += binder_thread_release(proc, thread);\n\t\tbinder_inner_proc_lock(proc);\n\t}\n\n\tnodes = 0;\n\tincoming_refs = 0;\n\twhile ((n = rb_first(&proc->nodes))) {\n\t\tstruct binder_node *node;\n\n\t\tnode = rb_entry(n, struct binder_node, rb_node);\n\t\tnodes++;\n\t\t \n\t\tbinder_inc_node_tmpref_ilocked(node);\n\t\trb_erase(&node->rb_node, &proc->nodes);\n\t\tbinder_inner_proc_unlock(proc);\n\t\tincoming_refs = binder_node_release(node, incoming_refs);\n\t\tbinder_inner_proc_lock(proc);\n\t}\n\tbinder_inner_proc_unlock(proc);\n\n\toutgoing_refs = 0;\n\tbinder_proc_lock(proc);\n\twhile ((n = rb_first(&proc->refs_by_desc))) {\n\t\tstruct binder_ref *ref;\n\n\t\tref = rb_entry(n, struct binder_ref, rb_node_desc);\n\t\toutgoing_refs++;\n\t\tbinder_cleanup_ref_olocked(ref);\n\t\tbinder_proc_unlock(proc);\n\t\tbinder_free_ref(ref);\n\t\tbinder_proc_lock(proc);\n\t}\n\tbinder_proc_unlock(proc);\n\n\tbinder_release_work(proc, &proc->todo);\n\tbinder_release_work(proc, &proc->delivered_death);\n\n\tbinder_debug(BINDER_DEBUG_OPEN_CLOSE,\n\t\t     \"%s: %d threads %d, nodes %d (ref %d), refs %d, active transactions %d\\n\",\n\t\t     __func__, proc->pid, threads, nodes, incoming_refs,\n\t\t     outgoing_refs, active_transactions);\n\n\tbinder_proc_dec_tmpref(proc);\n}\n\nstatic void binder_deferred_func(struct work_struct *work)\n{\n\tstruct binder_proc *proc;\n\n\tint defer;\n\n\tdo {\n\t\tmutex_lock(&binder_deferred_lock);\n\t\tif (!hlist_empty(&binder_deferred_list)) {\n\t\t\tproc = hlist_entry(binder_deferred_list.first,\n\t\t\t\t\tstruct binder_proc, deferred_work_node);\n\t\t\thlist_del_init(&proc->deferred_work_node);\n\t\t\tdefer = proc->deferred_work;\n\t\t\tproc->deferred_work = 0;\n\t\t} else {\n\t\t\tproc = NULL;\n\t\t\tdefer = 0;\n\t\t}\n\t\tmutex_unlock(&binder_deferred_lock);\n\n\t\tif (defer & BINDER_DEFERRED_FLUSH)\n\t\t\tbinder_deferred_flush(proc);\n\n\t\tif (defer & BINDER_DEFERRED_RELEASE)\n\t\t\tbinder_deferred_release(proc);  \n\t} while (proc);\n}\nstatic DECLARE_WORK(binder_deferred_work, binder_deferred_func);\n\nstatic void\nbinder_defer_work(struct binder_proc *proc, enum binder_deferred_state defer)\n{\n\tmutex_lock(&binder_deferred_lock);\n\tproc->deferred_work |= defer;\n\tif (hlist_unhashed(&proc->deferred_work_node)) {\n\t\thlist_add_head(&proc->deferred_work_node,\n\t\t\t\t&binder_deferred_list);\n\t\tschedule_work(&binder_deferred_work);\n\t}\n\tmutex_unlock(&binder_deferred_lock);\n}\n\nstatic void print_binder_transaction_ilocked(struct seq_file *m,\n\t\t\t\t\t     struct binder_proc *proc,\n\t\t\t\t\t     const char *prefix,\n\t\t\t\t\t     struct binder_transaction *t)\n{\n\tstruct binder_proc *to_proc;\n\tstruct binder_buffer *buffer = t->buffer;\n\tktime_t current_time = ktime_get();\n\n\tspin_lock(&t->lock);\n\tto_proc = t->to_proc;\n\tseq_printf(m,\n\t\t   \"%s %d: %pK from %d:%d to %d:%d code %x flags %x pri %ld r%d elapsed %lldms\",\n\t\t   prefix, t->debug_id, t,\n\t\t   t->from_pid,\n\t\t   t->from_tid,\n\t\t   to_proc ? to_proc->pid : 0,\n\t\t   t->to_thread ? t->to_thread->pid : 0,\n\t\t   t->code, t->flags, t->priority, t->need_reply,\n\t\t   ktime_ms_delta(current_time, t->start_time));\n\tspin_unlock(&t->lock);\n\n\tif (proc != to_proc) {\n\t\t \n\t\tseq_puts(m, \"\\n\");\n\t\treturn;\n\t}\n\n\tif (buffer == NULL) {\n\t\tseq_puts(m, \" buffer free\\n\");\n\t\treturn;\n\t}\n\tif (buffer->target_node)\n\t\tseq_printf(m, \" node %d\", buffer->target_node->debug_id);\n\tseq_printf(m, \" size %zd:%zd data %pK\\n\",\n\t\t   buffer->data_size, buffer->offsets_size,\n\t\t   buffer->user_data);\n}\n\nstatic void print_binder_work_ilocked(struct seq_file *m,\n\t\t\t\t     struct binder_proc *proc,\n\t\t\t\t     const char *prefix,\n\t\t\t\t     const char *transaction_prefix,\n\t\t\t\t     struct binder_work *w)\n{\n\tstruct binder_node *node;\n\tstruct binder_transaction *t;\n\n\tswitch (w->type) {\n\tcase BINDER_WORK_TRANSACTION:\n\t\tt = container_of(w, struct binder_transaction, work);\n\t\tprint_binder_transaction_ilocked(\n\t\t\t\tm, proc, transaction_prefix, t);\n\t\tbreak;\n\tcase BINDER_WORK_RETURN_ERROR: {\n\t\tstruct binder_error *e = container_of(\n\t\t\t\tw, struct binder_error, work);\n\n\t\tseq_printf(m, \"%stransaction error: %u\\n\",\n\t\t\t   prefix, e->cmd);\n\t} break;\n\tcase BINDER_WORK_TRANSACTION_COMPLETE:\n\t\tseq_printf(m, \"%stransaction complete\\n\", prefix);\n\t\tbreak;\n\tcase BINDER_WORK_NODE:\n\t\tnode = container_of(w, struct binder_node, work);\n\t\tseq_printf(m, \"%snode work %d: u%016llx c%016llx\\n\",\n\t\t\t   prefix, node->debug_id,\n\t\t\t   (u64)node->ptr, (u64)node->cookie);\n\t\tbreak;\n\tcase BINDER_WORK_DEAD_BINDER:\n\t\tseq_printf(m, \"%shas dead binder\\n\", prefix);\n\t\tbreak;\n\tcase BINDER_WORK_DEAD_BINDER_AND_CLEAR:\n\t\tseq_printf(m, \"%shas cleared dead binder\\n\", prefix);\n\t\tbreak;\n\tcase BINDER_WORK_CLEAR_DEATH_NOTIFICATION:\n\t\tseq_printf(m, \"%shas cleared death notification\\n\", prefix);\n\t\tbreak;\n\tdefault:\n\t\tseq_printf(m, \"%sunknown work: type %d\\n\", prefix, w->type);\n\t\tbreak;\n\t}\n}\n\nstatic void print_binder_thread_ilocked(struct seq_file *m,\n\t\t\t\t\tstruct binder_thread *thread,\n\t\t\t\t\tint print_always)\n{\n\tstruct binder_transaction *t;\n\tstruct binder_work *w;\n\tsize_t start_pos = m->count;\n\tsize_t header_pos;\n\n\tseq_printf(m, \"  thread %d: l %02x need_return %d tr %d\\n\",\n\t\t\tthread->pid, thread->looper,\n\t\t\tthread->looper_need_return,\n\t\t\tatomic_read(&thread->tmp_ref));\n\theader_pos = m->count;\n\tt = thread->transaction_stack;\n\twhile (t) {\n\t\tif (t->from == thread) {\n\t\t\tprint_binder_transaction_ilocked(m, thread->proc,\n\t\t\t\t\t\"    outgoing transaction\", t);\n\t\t\tt = t->from_parent;\n\t\t} else if (t->to_thread == thread) {\n\t\t\tprint_binder_transaction_ilocked(m, thread->proc,\n\t\t\t\t\t\t \"    incoming transaction\", t);\n\t\t\tt = t->to_parent;\n\t\t} else {\n\t\t\tprint_binder_transaction_ilocked(m, thread->proc,\n\t\t\t\t\t\"    bad transaction\", t);\n\t\t\tt = NULL;\n\t\t}\n\t}\n\tlist_for_each_entry(w, &thread->todo, entry) {\n\t\tprint_binder_work_ilocked(m, thread->proc, \"    \",\n\t\t\t\t\t  \"    pending transaction\", w);\n\t}\n\tif (!print_always && m->count == header_pos)\n\t\tm->count = start_pos;\n}\n\nstatic void print_binder_node_nilocked(struct seq_file *m,\n\t\t\t\t       struct binder_node *node)\n{\n\tstruct binder_ref *ref;\n\tstruct binder_work *w;\n\tint count;\n\n\tcount = 0;\n\thlist_for_each_entry(ref, &node->refs, node_entry)\n\t\tcount++;\n\n\tseq_printf(m, \"  node %d: u%016llx c%016llx hs %d hw %d ls %d lw %d is %d iw %d tr %d\",\n\t\t   node->debug_id, (u64)node->ptr, (u64)node->cookie,\n\t\t   node->has_strong_ref, node->has_weak_ref,\n\t\t   node->local_strong_refs, node->local_weak_refs,\n\t\t   node->internal_strong_refs, count, node->tmp_refs);\n\tif (count) {\n\t\tseq_puts(m, \" proc\");\n\t\thlist_for_each_entry(ref, &node->refs, node_entry)\n\t\t\tseq_printf(m, \" %d\", ref->proc->pid);\n\t}\n\tseq_puts(m, \"\\n\");\n\tif (node->proc) {\n\t\tlist_for_each_entry(w, &node->async_todo, entry)\n\t\t\tprint_binder_work_ilocked(m, node->proc, \"    \",\n\t\t\t\t\t  \"    pending async transaction\", w);\n\t}\n}\n\nstatic void print_binder_ref_olocked(struct seq_file *m,\n\t\t\t\t     struct binder_ref *ref)\n{\n\tbinder_node_lock(ref->node);\n\tseq_printf(m, \"  ref %d: desc %d %snode %d s %d w %d d %pK\\n\",\n\t\t   ref->data.debug_id, ref->data.desc,\n\t\t   ref->node->proc ? \"\" : \"dead \",\n\t\t   ref->node->debug_id, ref->data.strong,\n\t\t   ref->data.weak, ref->death);\n\tbinder_node_unlock(ref->node);\n}\n\nstatic void print_binder_proc(struct seq_file *m,\n\t\t\t      struct binder_proc *proc, int print_all)\n{\n\tstruct binder_work *w;\n\tstruct rb_node *n;\n\tsize_t start_pos = m->count;\n\tsize_t header_pos;\n\tstruct binder_node *last_node = NULL;\n\n\tseq_printf(m, \"proc %d\\n\", proc->pid);\n\tseq_printf(m, \"context %s\\n\", proc->context->name);\n\theader_pos = m->count;\n\n\tbinder_inner_proc_lock(proc);\n\tfor (n = rb_first(&proc->threads); n != NULL; n = rb_next(n))\n\t\tprint_binder_thread_ilocked(m, rb_entry(n, struct binder_thread,\n\t\t\t\t\t\trb_node), print_all);\n\n\tfor (n = rb_first(&proc->nodes); n != NULL; n = rb_next(n)) {\n\t\tstruct binder_node *node = rb_entry(n, struct binder_node,\n\t\t\t\t\t\t    rb_node);\n\t\tif (!print_all && !node->has_async_transaction)\n\t\t\tcontinue;\n\n\t\t \n\t\tbinder_inc_node_tmpref_ilocked(node);\n\t\t \n\t\tbinder_inner_proc_unlock(proc);\n\t\tif (last_node)\n\t\t\tbinder_put_node(last_node);\n\t\tbinder_node_inner_lock(node);\n\t\tprint_binder_node_nilocked(m, node);\n\t\tbinder_node_inner_unlock(node);\n\t\tlast_node = node;\n\t\tbinder_inner_proc_lock(proc);\n\t}\n\tbinder_inner_proc_unlock(proc);\n\tif (last_node)\n\t\tbinder_put_node(last_node);\n\n\tif (print_all) {\n\t\tbinder_proc_lock(proc);\n\t\tfor (n = rb_first(&proc->refs_by_desc);\n\t\t     n != NULL;\n\t\t     n = rb_next(n))\n\t\t\tprint_binder_ref_olocked(m, rb_entry(n,\n\t\t\t\t\t\t\t    struct binder_ref,\n\t\t\t\t\t\t\t    rb_node_desc));\n\t\tbinder_proc_unlock(proc);\n\t}\n\tbinder_alloc_print_allocated(m, &proc->alloc);\n\tbinder_inner_proc_lock(proc);\n\tlist_for_each_entry(w, &proc->todo, entry)\n\t\tprint_binder_work_ilocked(m, proc, \"  \",\n\t\t\t\t\t  \"  pending transaction\", w);\n\tlist_for_each_entry(w, &proc->delivered_death, entry) {\n\t\tseq_puts(m, \"  has delivered dead binder\\n\");\n\t\tbreak;\n\t}\n\tbinder_inner_proc_unlock(proc);\n\tif (!print_all && m->count == header_pos)\n\t\tm->count = start_pos;\n}\n\nstatic const char * const binder_return_strings[] = {\n\t\"BR_ERROR\",\n\t\"BR_OK\",\n\t\"BR_TRANSACTION\",\n\t\"BR_REPLY\",\n\t\"BR_ACQUIRE_RESULT\",\n\t\"BR_DEAD_REPLY\",\n\t\"BR_TRANSACTION_COMPLETE\",\n\t\"BR_INCREFS\",\n\t\"BR_ACQUIRE\",\n\t\"BR_RELEASE\",\n\t\"BR_DECREFS\",\n\t\"BR_ATTEMPT_ACQUIRE\",\n\t\"BR_NOOP\",\n\t\"BR_SPAWN_LOOPER\",\n\t\"BR_FINISHED\",\n\t\"BR_DEAD_BINDER\",\n\t\"BR_CLEAR_DEATH_NOTIFICATION_DONE\",\n\t\"BR_FAILED_REPLY\",\n\t\"BR_FROZEN_REPLY\",\n\t\"BR_ONEWAY_SPAM_SUSPECT\",\n\t\"BR_TRANSACTION_PENDING_FROZEN\"\n};\n\nstatic const char * const binder_command_strings[] = {\n\t\"BC_TRANSACTION\",\n\t\"BC_REPLY\",\n\t\"BC_ACQUIRE_RESULT\",\n\t\"BC_FREE_BUFFER\",\n\t\"BC_INCREFS\",\n\t\"BC_ACQUIRE\",\n\t\"BC_RELEASE\",\n\t\"BC_DECREFS\",\n\t\"BC_INCREFS_DONE\",\n\t\"BC_ACQUIRE_DONE\",\n\t\"BC_ATTEMPT_ACQUIRE\",\n\t\"BC_REGISTER_LOOPER\",\n\t\"BC_ENTER_LOOPER\",\n\t\"BC_EXIT_LOOPER\",\n\t\"BC_REQUEST_DEATH_NOTIFICATION\",\n\t\"BC_CLEAR_DEATH_NOTIFICATION\",\n\t\"BC_DEAD_BINDER_DONE\",\n\t\"BC_TRANSACTION_SG\",\n\t\"BC_REPLY_SG\",\n};\n\nstatic const char * const binder_objstat_strings[] = {\n\t\"proc\",\n\t\"thread\",\n\t\"node\",\n\t\"ref\",\n\t\"death\",\n\t\"transaction\",\n\t\"transaction_complete\"\n};\n\nstatic void print_binder_stats(struct seq_file *m, const char *prefix,\n\t\t\t       struct binder_stats *stats)\n{\n\tint i;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(stats->bc) !=\n\t\t     ARRAY_SIZE(binder_command_strings));\n\tfor (i = 0; i < ARRAY_SIZE(stats->bc); i++) {\n\t\tint temp = atomic_read(&stats->bc[i]);\n\n\t\tif (temp)\n\t\t\tseq_printf(m, \"%s%s: %d\\n\", prefix,\n\t\t\t\t   binder_command_strings[i], temp);\n\t}\n\n\tBUILD_BUG_ON(ARRAY_SIZE(stats->br) !=\n\t\t     ARRAY_SIZE(binder_return_strings));\n\tfor (i = 0; i < ARRAY_SIZE(stats->br); i++) {\n\t\tint temp = atomic_read(&stats->br[i]);\n\n\t\tif (temp)\n\t\t\tseq_printf(m, \"%s%s: %d\\n\", prefix,\n\t\t\t\t   binder_return_strings[i], temp);\n\t}\n\n\tBUILD_BUG_ON(ARRAY_SIZE(stats->obj_created) !=\n\t\t     ARRAY_SIZE(binder_objstat_strings));\n\tBUILD_BUG_ON(ARRAY_SIZE(stats->obj_created) !=\n\t\t     ARRAY_SIZE(stats->obj_deleted));\n\tfor (i = 0; i < ARRAY_SIZE(stats->obj_created); i++) {\n\t\tint created = atomic_read(&stats->obj_created[i]);\n\t\tint deleted = atomic_read(&stats->obj_deleted[i]);\n\n\t\tif (created || deleted)\n\t\t\tseq_printf(m, \"%s%s: active %d total %d\\n\",\n\t\t\t\tprefix,\n\t\t\t\tbinder_objstat_strings[i],\n\t\t\t\tcreated - deleted,\n\t\t\t\tcreated);\n\t}\n}\n\nstatic void print_binder_proc_stats(struct seq_file *m,\n\t\t\t\t    struct binder_proc *proc)\n{\n\tstruct binder_work *w;\n\tstruct binder_thread *thread;\n\tstruct rb_node *n;\n\tint count, strong, weak, ready_threads;\n\tsize_t free_async_space =\n\t\tbinder_alloc_get_free_async_space(&proc->alloc);\n\n\tseq_printf(m, \"proc %d\\n\", proc->pid);\n\tseq_printf(m, \"context %s\\n\", proc->context->name);\n\tcount = 0;\n\tready_threads = 0;\n\tbinder_inner_proc_lock(proc);\n\tfor (n = rb_first(&proc->threads); n != NULL; n = rb_next(n))\n\t\tcount++;\n\n\tlist_for_each_entry(thread, &proc->waiting_threads, waiting_thread_node)\n\t\tready_threads++;\n\n\tseq_printf(m, \"  threads: %d\\n\", count);\n\tseq_printf(m, \"  requested threads: %d+%d/%d\\n\"\n\t\t\t\"  ready threads %d\\n\"\n\t\t\t\"  free async space %zd\\n\", proc->requested_threads,\n\t\t\tproc->requested_threads_started, proc->max_threads,\n\t\t\tready_threads,\n\t\t\tfree_async_space);\n\tcount = 0;\n\tfor (n = rb_first(&proc->nodes); n != NULL; n = rb_next(n))\n\t\tcount++;\n\tbinder_inner_proc_unlock(proc);\n\tseq_printf(m, \"  nodes: %d\\n\", count);\n\tcount = 0;\n\tstrong = 0;\n\tweak = 0;\n\tbinder_proc_lock(proc);\n\tfor (n = rb_first(&proc->refs_by_desc); n != NULL; n = rb_next(n)) {\n\t\tstruct binder_ref *ref = rb_entry(n, struct binder_ref,\n\t\t\t\t\t\t  rb_node_desc);\n\t\tcount++;\n\t\tstrong += ref->data.strong;\n\t\tweak += ref->data.weak;\n\t}\n\tbinder_proc_unlock(proc);\n\tseq_printf(m, \"  refs: %d s %d w %d\\n\", count, strong, weak);\n\n\tcount = binder_alloc_get_allocated_count(&proc->alloc);\n\tseq_printf(m, \"  buffers: %d\\n\", count);\n\n\tbinder_alloc_print_pages(m, &proc->alloc);\n\n\tcount = 0;\n\tbinder_inner_proc_lock(proc);\n\tlist_for_each_entry(w, &proc->todo, entry) {\n\t\tif (w->type == BINDER_WORK_TRANSACTION)\n\t\t\tcount++;\n\t}\n\tbinder_inner_proc_unlock(proc);\n\tseq_printf(m, \"  pending transactions: %d\\n\", count);\n\n\tprint_binder_stats(m, \"  \", &proc->stats);\n}\n\nstatic int state_show(struct seq_file *m, void *unused)\n{\n\tstruct binder_proc *proc;\n\tstruct binder_node *node;\n\tstruct binder_node *last_node = NULL;\n\n\tseq_puts(m, \"binder state:\\n\");\n\n\tspin_lock(&binder_dead_nodes_lock);\n\tif (!hlist_empty(&binder_dead_nodes))\n\t\tseq_puts(m, \"dead nodes:\\n\");\n\thlist_for_each_entry(node, &binder_dead_nodes, dead_node) {\n\t\t \n\t\tnode->tmp_refs++;\n\t\tspin_unlock(&binder_dead_nodes_lock);\n\t\tif (last_node)\n\t\t\tbinder_put_node(last_node);\n\t\tbinder_node_lock(node);\n\t\tprint_binder_node_nilocked(m, node);\n\t\tbinder_node_unlock(node);\n\t\tlast_node = node;\n\t\tspin_lock(&binder_dead_nodes_lock);\n\t}\n\tspin_unlock(&binder_dead_nodes_lock);\n\tif (last_node)\n\t\tbinder_put_node(last_node);\n\n\tmutex_lock(&binder_procs_lock);\n\thlist_for_each_entry(proc, &binder_procs, proc_node)\n\t\tprint_binder_proc(m, proc, 1);\n\tmutex_unlock(&binder_procs_lock);\n\n\treturn 0;\n}\n\nstatic int stats_show(struct seq_file *m, void *unused)\n{\n\tstruct binder_proc *proc;\n\n\tseq_puts(m, \"binder stats:\\n\");\n\n\tprint_binder_stats(m, \"\", &binder_stats);\n\n\tmutex_lock(&binder_procs_lock);\n\thlist_for_each_entry(proc, &binder_procs, proc_node)\n\t\tprint_binder_proc_stats(m, proc);\n\tmutex_unlock(&binder_procs_lock);\n\n\treturn 0;\n}\n\nstatic int transactions_show(struct seq_file *m, void *unused)\n{\n\tstruct binder_proc *proc;\n\n\tseq_puts(m, \"binder transactions:\\n\");\n\tmutex_lock(&binder_procs_lock);\n\thlist_for_each_entry(proc, &binder_procs, proc_node)\n\t\tprint_binder_proc(m, proc, 0);\n\tmutex_unlock(&binder_procs_lock);\n\n\treturn 0;\n}\n\nstatic int proc_show(struct seq_file *m, void *unused)\n{\n\tstruct binder_proc *itr;\n\tint pid = (unsigned long)m->private;\n\n\tmutex_lock(&binder_procs_lock);\n\thlist_for_each_entry(itr, &binder_procs, proc_node) {\n\t\tif (itr->pid == pid) {\n\t\t\tseq_puts(m, \"binder proc state:\\n\");\n\t\t\tprint_binder_proc(m, itr, 1);\n\t\t}\n\t}\n\tmutex_unlock(&binder_procs_lock);\n\n\treturn 0;\n}\n\nstatic void print_binder_transaction_log_entry(struct seq_file *m,\n\t\t\t\t\tstruct binder_transaction_log_entry *e)\n{\n\tint debug_id = READ_ONCE(e->debug_id_done);\n\t \n\tsmp_rmb();\n\tseq_printf(m,\n\t\t   \"%d: %s from %d:%d to %d:%d context %s node %d handle %d size %d:%d ret %d/%d l=%d\",\n\t\t   e->debug_id, (e->call_type == 2) ? \"reply\" :\n\t\t   ((e->call_type == 1) ? \"async\" : \"call \"), e->from_proc,\n\t\t   e->from_thread, e->to_proc, e->to_thread, e->context_name,\n\t\t   e->to_node, e->target_handle, e->data_size, e->offsets_size,\n\t\t   e->return_error, e->return_error_param,\n\t\t   e->return_error_line);\n\t \n\tsmp_rmb();\n\tseq_printf(m, debug_id && debug_id == READ_ONCE(e->debug_id_done) ?\n\t\t\t\"\\n\" : \" (incomplete)\\n\");\n}\n\nstatic int transaction_log_show(struct seq_file *m, void *unused)\n{\n\tstruct binder_transaction_log *log = m->private;\n\tunsigned int log_cur = atomic_read(&log->cur);\n\tunsigned int count;\n\tunsigned int cur;\n\tint i;\n\n\tcount = log_cur + 1;\n\tcur = count < ARRAY_SIZE(log->entry) && !log->full ?\n\t\t0 : count % ARRAY_SIZE(log->entry);\n\tif (count > ARRAY_SIZE(log->entry) || log->full)\n\t\tcount = ARRAY_SIZE(log->entry);\n\tfor (i = 0; i < count; i++) {\n\t\tunsigned int index = cur++ % ARRAY_SIZE(log->entry);\n\n\t\tprint_binder_transaction_log_entry(m, &log->entry[index]);\n\t}\n\treturn 0;\n}\n\nconst struct file_operations binder_fops = {\n\t.owner = THIS_MODULE,\n\t.poll = binder_poll,\n\t.unlocked_ioctl = binder_ioctl,\n\t.compat_ioctl = compat_ptr_ioctl,\n\t.mmap = binder_mmap,\n\t.open = binder_open,\n\t.flush = binder_flush,\n\t.release = binder_release,\n};\n\nDEFINE_SHOW_ATTRIBUTE(state);\nDEFINE_SHOW_ATTRIBUTE(stats);\nDEFINE_SHOW_ATTRIBUTE(transactions);\nDEFINE_SHOW_ATTRIBUTE(transaction_log);\n\nconst struct binder_debugfs_entry binder_debugfs_entries[] = {\n\t{\n\t\t.name = \"state\",\n\t\t.mode = 0444,\n\t\t.fops = &state_fops,\n\t\t.data = NULL,\n\t},\n\t{\n\t\t.name = \"stats\",\n\t\t.mode = 0444,\n\t\t.fops = &stats_fops,\n\t\t.data = NULL,\n\t},\n\t{\n\t\t.name = \"transactions\",\n\t\t.mode = 0444,\n\t\t.fops = &transactions_fops,\n\t\t.data = NULL,\n\t},\n\t{\n\t\t.name = \"transaction_log\",\n\t\t.mode = 0444,\n\t\t.fops = &transaction_log_fops,\n\t\t.data = &binder_transaction_log,\n\t},\n\t{\n\t\t.name = \"failed_transaction_log\",\n\t\t.mode = 0444,\n\t\t.fops = &transaction_log_fops,\n\t\t.data = &binder_transaction_log_failed,\n\t},\n\t{}  \n};\n\nstatic int __init init_binder_device(const char *name)\n{\n\tint ret;\n\tstruct binder_device *binder_device;\n\n\tbinder_device = kzalloc(sizeof(*binder_device), GFP_KERNEL);\n\tif (!binder_device)\n\t\treturn -ENOMEM;\n\n\tbinder_device->miscdev.fops = &binder_fops;\n\tbinder_device->miscdev.minor = MISC_DYNAMIC_MINOR;\n\tbinder_device->miscdev.name = name;\n\n\trefcount_set(&binder_device->ref, 1);\n\tbinder_device->context.binder_context_mgr_uid = INVALID_UID;\n\tbinder_device->context.name = name;\n\tmutex_init(&binder_device->context.context_mgr_node_lock);\n\n\tret = misc_register(&binder_device->miscdev);\n\tif (ret < 0) {\n\t\tkfree(binder_device);\n\t\treturn ret;\n\t}\n\n\thlist_add_head(&binder_device->hlist, &binder_devices);\n\n\treturn ret;\n}\n\nstatic int __init binder_init(void)\n{\n\tint ret;\n\tchar *device_name, *device_tmp;\n\tstruct binder_device *device;\n\tstruct hlist_node *tmp;\n\tchar *device_names = NULL;\n\tconst struct binder_debugfs_entry *db_entry;\n\n\tret = binder_alloc_shrinker_init();\n\tif (ret)\n\t\treturn ret;\n\n\tatomic_set(&binder_transaction_log.cur, ~0U);\n\tatomic_set(&binder_transaction_log_failed.cur, ~0U);\n\n\tbinder_debugfs_dir_entry_root = debugfs_create_dir(\"binder\", NULL);\n\n\tbinder_for_each_debugfs_entry(db_entry)\n\t\tdebugfs_create_file(db_entry->name,\n\t\t\t\t\tdb_entry->mode,\n\t\t\t\t\tbinder_debugfs_dir_entry_root,\n\t\t\t\t\tdb_entry->data,\n\t\t\t\t\tdb_entry->fops);\n\n\tbinder_debugfs_dir_entry_proc = debugfs_create_dir(\"proc\",\n\t\t\t\t\t\tbinder_debugfs_dir_entry_root);\n\n\tif (!IS_ENABLED(CONFIG_ANDROID_BINDERFS) &&\n\t    strcmp(binder_devices_param, \"\") != 0) {\n\t\t \n\t\tdevice_names = kstrdup(binder_devices_param, GFP_KERNEL);\n\t\tif (!device_names) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_alloc_device_names_failed;\n\t\t}\n\n\t\tdevice_tmp = device_names;\n\t\twhile ((device_name = strsep(&device_tmp, \",\"))) {\n\t\t\tret = init_binder_device(device_name);\n\t\t\tif (ret)\n\t\t\t\tgoto err_init_binder_device_failed;\n\t\t}\n\t}\n\n\tret = init_binderfs();\n\tif (ret)\n\t\tgoto err_init_binder_device_failed;\n\n\treturn ret;\n\nerr_init_binder_device_failed:\n\thlist_for_each_entry_safe(device, tmp, &binder_devices, hlist) {\n\t\tmisc_deregister(&device->miscdev);\n\t\thlist_del(&device->hlist);\n\t\tkfree(device);\n\t}\n\n\tkfree(device_names);\n\nerr_alloc_device_names_failed:\n\tdebugfs_remove_recursive(binder_debugfs_dir_entry_root);\n\tbinder_alloc_shrinker_exit();\n\n\treturn ret;\n}\n\ndevice_initcall(binder_init);\n\n#define CREATE_TRACE_POINTS\n#include \"binder_trace.h\"\n\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}