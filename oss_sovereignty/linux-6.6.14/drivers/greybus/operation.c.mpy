{
  "module_name": "operation.c",
  "hash_id": "6cadebdcf48ba1454010a5a6a26bad912f288244c79a3d87c06db06afd250123",
  "original_prompt": "Ingested from linux-6.6.14/drivers/greybus/operation.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/wait.h>\n#include <linux/workqueue.h>\n#include <linux/greybus.h>\n\n#include \"greybus_trace.h\"\n\nstatic struct kmem_cache *gb_operation_cache;\nstatic struct kmem_cache *gb_message_cache;\n\n \nstatic struct workqueue_struct *gb_operation_completion_wq;\n\n \nstatic DECLARE_WAIT_QUEUE_HEAD(gb_operation_cancellation_queue);\n\n \nstatic DEFINE_SPINLOCK(gb_operations_lock);\n\nstatic int gb_operation_response_send(struct gb_operation *operation,\n\t\t\t\t      int errno);\n\n \nstatic int gb_operation_get_active(struct gb_operation *operation)\n{\n\tstruct gb_connection *connection = operation->connection;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&connection->lock, flags);\n\tswitch (connection->state) {\n\tcase GB_CONNECTION_STATE_ENABLED:\n\t\tbreak;\n\tcase GB_CONNECTION_STATE_ENABLED_TX:\n\t\tif (gb_operation_is_incoming(operation))\n\t\t\tgoto err_unlock;\n\t\tbreak;\n\tcase GB_CONNECTION_STATE_DISCONNECTING:\n\t\tif (!gb_operation_is_core(operation))\n\t\t\tgoto err_unlock;\n\t\tbreak;\n\tdefault:\n\t\tgoto err_unlock;\n\t}\n\n\tif (operation->active++ == 0)\n\t\tlist_add_tail(&operation->links, &connection->operations);\n\n\ttrace_gb_operation_get_active(operation);\n\n\tspin_unlock_irqrestore(&connection->lock, flags);\n\n\treturn 0;\n\nerr_unlock:\n\tspin_unlock_irqrestore(&connection->lock, flags);\n\n\treturn -ENOTCONN;\n}\n\n \nstatic void gb_operation_put_active(struct gb_operation *operation)\n{\n\tstruct gb_connection *connection = operation->connection;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&connection->lock, flags);\n\n\ttrace_gb_operation_put_active(operation);\n\n\tif (--operation->active == 0) {\n\t\tlist_del(&operation->links);\n\t\tif (atomic_read(&operation->waiters))\n\t\t\twake_up(&gb_operation_cancellation_queue);\n\t}\n\tspin_unlock_irqrestore(&connection->lock, flags);\n}\n\nstatic bool gb_operation_is_active(struct gb_operation *operation)\n{\n\tstruct gb_connection *connection = operation->connection;\n\tunsigned long flags;\n\tbool ret;\n\n\tspin_lock_irqsave(&connection->lock, flags);\n\tret = operation->active;\n\tspin_unlock_irqrestore(&connection->lock, flags);\n\n\treturn ret;\n}\n\n \nstatic bool gb_operation_result_set(struct gb_operation *operation, int result)\n{\n\tunsigned long flags;\n\tint prev;\n\n\tif (result == -EINPROGRESS) {\n\t\t \n\t\tspin_lock_irqsave(&gb_operations_lock, flags);\n\t\tprev = operation->errno;\n\t\tif (prev == -EBADR)\n\t\t\toperation->errno = result;\n\t\telse\n\t\t\toperation->errno = -EILSEQ;\n\t\tspin_unlock_irqrestore(&gb_operations_lock, flags);\n\t\tWARN_ON(prev != -EBADR);\n\n\t\treturn true;\n\t}\n\n\t \n\tif (WARN_ON(result == -EBADR))\n\t\tresult = -EILSEQ;  \n\n\tspin_lock_irqsave(&gb_operations_lock, flags);\n\tprev = operation->errno;\n\tif (prev == -EINPROGRESS)\n\t\toperation->errno = result;\t \n\tspin_unlock_irqrestore(&gb_operations_lock, flags);\n\n\treturn prev == -EINPROGRESS;\n}\n\nint gb_operation_result(struct gb_operation *operation)\n{\n\tint result = operation->errno;\n\n\tWARN_ON(result == -EBADR);\n\tWARN_ON(result == -EINPROGRESS);\n\n\treturn result;\n}\nEXPORT_SYMBOL_GPL(gb_operation_result);\n\n \nstatic struct gb_operation *\ngb_operation_find_outgoing(struct gb_connection *connection, u16 operation_id)\n{\n\tstruct gb_operation *operation;\n\tunsigned long flags;\n\tbool found = false;\n\n\tspin_lock_irqsave(&connection->lock, flags);\n\tlist_for_each_entry(operation, &connection->operations, links)\n\t\tif (operation->id == operation_id &&\n\t\t    !gb_operation_is_incoming(operation)) {\n\t\t\tgb_operation_get(operation);\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\tspin_unlock_irqrestore(&connection->lock, flags);\n\n\treturn found ? operation : NULL;\n}\n\nstatic int gb_message_send(struct gb_message *message, gfp_t gfp)\n{\n\tstruct gb_connection *connection = message->operation->connection;\n\n\ttrace_gb_message_send(message);\n\treturn connection->hd->driver->message_send(connection->hd,\n\t\t\t\t\tconnection->hd_cport_id,\n\t\t\t\t\tmessage,\n\t\t\t\t\tgfp);\n}\n\n \nstatic void gb_message_cancel(struct gb_message *message)\n{\n\tstruct gb_host_device *hd = message->operation->connection->hd;\n\n\thd->driver->message_cancel(message);\n}\n\nstatic void gb_operation_request_handle(struct gb_operation *operation)\n{\n\tstruct gb_connection *connection = operation->connection;\n\tint status;\n\tint ret;\n\n\tif (connection->handler) {\n\t\tstatus = connection->handler(operation);\n\t} else {\n\t\tdev_err(&connection->hd->dev,\n\t\t\t\"%s: unexpected incoming request of type 0x%02x\\n\",\n\t\t\tconnection->name, operation->type);\n\n\t\tstatus = -EPROTONOSUPPORT;\n\t}\n\n\tret = gb_operation_response_send(operation, status);\n\tif (ret) {\n\t\tdev_err(&connection->hd->dev,\n\t\t\t\"%s: failed to send response %d for type 0x%02x: %d\\n\",\n\t\t\tconnection->name, status, operation->type, ret);\n\t\treturn;\n\t}\n}\n\n \nstatic void gb_operation_work(struct work_struct *work)\n{\n\tstruct gb_operation *operation;\n\tint ret;\n\n\toperation = container_of(work, struct gb_operation, work);\n\n\tif (gb_operation_is_incoming(operation)) {\n\t\tgb_operation_request_handle(operation);\n\t} else {\n\t\tret = del_timer_sync(&operation->timer);\n\t\tif (!ret) {\n\t\t\t \n\t\t\tif (gb_operation_result(operation) == -ETIMEDOUT)\n\t\t\t\tgb_message_cancel(operation->request);\n\t\t}\n\n\t\toperation->callback(operation);\n\t}\n\n\tgb_operation_put_active(operation);\n\tgb_operation_put(operation);\n}\n\nstatic void gb_operation_timeout(struct timer_list *t)\n{\n\tstruct gb_operation *operation = from_timer(operation, t, timer);\n\n\tif (gb_operation_result_set(operation, -ETIMEDOUT)) {\n\t\t \n\t\tqueue_work(gb_operation_completion_wq, &operation->work);\n\t}\n}\n\nstatic void gb_operation_message_init(struct gb_host_device *hd,\n\t\t\t\t      struct gb_message *message,\n\t\t\t\t      u16 operation_id,\n\t\t\t\t      size_t payload_size, u8 type)\n{\n\tstruct gb_operation_msg_hdr *header;\n\n\theader = message->buffer;\n\n\tmessage->header = header;\n\tmessage->payload = payload_size ? header + 1 : NULL;\n\tmessage->payload_size = payload_size;\n\n\t \n\tif (type != GB_REQUEST_TYPE_INVALID) {\n\t\tu16 message_size = (u16)(sizeof(*header) + payload_size);\n\n\t\t \n\t\theader->size = cpu_to_le16(message_size);\n\t\theader->operation_id = 0;\n\t\theader->type = type;\n\t\theader->result = 0;\n\t}\n}\n\n \nstatic struct gb_message *\ngb_operation_message_alloc(struct gb_host_device *hd, u8 type,\n\t\t\t   size_t payload_size, gfp_t gfp_flags)\n{\n\tstruct gb_message *message;\n\tstruct gb_operation_msg_hdr *header;\n\tsize_t message_size = payload_size + sizeof(*header);\n\n\tif (message_size > hd->buffer_size_max) {\n\t\tdev_warn(&hd->dev, \"requested message size too big (%zu > %zu)\\n\",\n\t\t\t message_size, hd->buffer_size_max);\n\t\treturn NULL;\n\t}\n\n\t \n\tmessage = kmem_cache_zalloc(gb_message_cache, gfp_flags);\n\tif (!message)\n\t\treturn NULL;\n\n\tmessage->buffer = kzalloc(message_size, gfp_flags);\n\tif (!message->buffer)\n\t\tgoto err_free_message;\n\n\t \n\tgb_operation_message_init(hd, message, 0, payload_size, type);\n\n\treturn message;\n\nerr_free_message:\n\tkmem_cache_free(gb_message_cache, message);\n\n\treturn NULL;\n}\n\nstatic void gb_operation_message_free(struct gb_message *message)\n{\n\tkfree(message->buffer);\n\tkmem_cache_free(gb_message_cache, message);\n}\n\n \nstatic int gb_operation_status_map(u8 status)\n{\n\tswitch (status) {\n\tcase GB_OP_SUCCESS:\n\t\treturn 0;\n\tcase GB_OP_INTERRUPTED:\n\t\treturn -EINTR;\n\tcase GB_OP_TIMEOUT:\n\t\treturn -ETIMEDOUT;\n\tcase GB_OP_NO_MEMORY:\n\t\treturn -ENOMEM;\n\tcase GB_OP_PROTOCOL_BAD:\n\t\treturn -EPROTONOSUPPORT;\n\tcase GB_OP_OVERFLOW:\n\t\treturn -EMSGSIZE;\n\tcase GB_OP_INVALID:\n\t\treturn -EINVAL;\n\tcase GB_OP_RETRY:\n\t\treturn -EAGAIN;\n\tcase GB_OP_NONEXISTENT:\n\t\treturn -ENODEV;\n\tcase GB_OP_MALFUNCTION:\n\t\treturn -EILSEQ;\n\tcase GB_OP_UNKNOWN_ERROR:\n\tdefault:\n\t\treturn -EIO;\n\t}\n}\n\n \nstatic u8 gb_operation_errno_map(int errno)\n{\n\tswitch (errno) {\n\tcase 0:\n\t\treturn GB_OP_SUCCESS;\n\tcase -EINTR:\n\t\treturn GB_OP_INTERRUPTED;\n\tcase -ETIMEDOUT:\n\t\treturn GB_OP_TIMEOUT;\n\tcase -ENOMEM:\n\t\treturn GB_OP_NO_MEMORY;\n\tcase -EPROTONOSUPPORT:\n\t\treturn GB_OP_PROTOCOL_BAD;\n\tcase -EMSGSIZE:\n\t\treturn GB_OP_OVERFLOW;\t \n\tcase -EINVAL:\n\t\treturn GB_OP_INVALID;\n\tcase -EAGAIN:\n\t\treturn GB_OP_RETRY;\n\tcase -EILSEQ:\n\t\treturn GB_OP_MALFUNCTION;\n\tcase -ENODEV:\n\t\treturn GB_OP_NONEXISTENT;\n\tcase -EIO:\n\tdefault:\n\t\treturn GB_OP_UNKNOWN_ERROR;\n\t}\n}\n\nbool gb_operation_response_alloc(struct gb_operation *operation,\n\t\t\t\t size_t response_size, gfp_t gfp)\n{\n\tstruct gb_host_device *hd = operation->connection->hd;\n\tstruct gb_operation_msg_hdr *request_header;\n\tstruct gb_message *response;\n\tu8 type;\n\n\ttype = operation->type | GB_MESSAGE_TYPE_RESPONSE;\n\tresponse = gb_operation_message_alloc(hd, type, response_size, gfp);\n\tif (!response)\n\t\treturn false;\n\tresponse->operation = operation;\n\n\t \n\trequest_header = operation->request->header;\n\tresponse->header->operation_id = request_header->operation_id;\n\toperation->response = response;\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(gb_operation_response_alloc);\n\n \nstatic struct gb_operation *\ngb_operation_create_common(struct gb_connection *connection, u8 type,\n\t\t\t   size_t request_size, size_t response_size,\n\t\t\t   unsigned long op_flags, gfp_t gfp_flags)\n{\n\tstruct gb_host_device *hd = connection->hd;\n\tstruct gb_operation *operation;\n\n\toperation = kmem_cache_zalloc(gb_operation_cache, gfp_flags);\n\tif (!operation)\n\t\treturn NULL;\n\toperation->connection = connection;\n\n\toperation->request = gb_operation_message_alloc(hd, type, request_size,\n\t\t\t\t\t\t\tgfp_flags);\n\tif (!operation->request)\n\t\tgoto err_cache;\n\toperation->request->operation = operation;\n\n\t \n\tif (!(op_flags & GB_OPERATION_FLAG_INCOMING)) {\n\t\tif (!gb_operation_response_alloc(operation, response_size,\n\t\t\t\t\t\t gfp_flags)) {\n\t\t\tgoto err_request;\n\t\t}\n\n\t\ttimer_setup(&operation->timer, gb_operation_timeout, 0);\n\t}\n\n\toperation->flags = op_flags;\n\toperation->type = type;\n\toperation->errno = -EBADR;   \n\n\tINIT_WORK(&operation->work, gb_operation_work);\n\tinit_completion(&operation->completion);\n\tkref_init(&operation->kref);\n\tatomic_set(&operation->waiters, 0);\n\n\treturn operation;\n\nerr_request:\n\tgb_operation_message_free(operation->request);\nerr_cache:\n\tkmem_cache_free(gb_operation_cache, operation);\n\n\treturn NULL;\n}\n\n \nstruct gb_operation *\ngb_operation_create_flags(struct gb_connection *connection,\n\t\t\t  u8 type, size_t request_size,\n\t\t\t  size_t response_size, unsigned long flags,\n\t\t\t  gfp_t gfp)\n{\n\tstruct gb_operation *operation;\n\n\tif (WARN_ON_ONCE(type == GB_REQUEST_TYPE_INVALID))\n\t\treturn NULL;\n\tif (WARN_ON_ONCE(type & GB_MESSAGE_TYPE_RESPONSE))\n\t\ttype &= ~GB_MESSAGE_TYPE_RESPONSE;\n\n\tif (WARN_ON_ONCE(flags & ~GB_OPERATION_FLAG_USER_MASK))\n\t\tflags &= GB_OPERATION_FLAG_USER_MASK;\n\n\toperation = gb_operation_create_common(connection, type,\n\t\t\t\t\t       request_size, response_size,\n\t\t\t\t\t       flags, gfp);\n\tif (operation)\n\t\ttrace_gb_operation_create(operation);\n\n\treturn operation;\n}\nEXPORT_SYMBOL_GPL(gb_operation_create_flags);\n\nstruct gb_operation *\ngb_operation_create_core(struct gb_connection *connection,\n\t\t\t u8 type, size_t request_size,\n\t\t\t size_t response_size, unsigned long flags,\n\t\t\t gfp_t gfp)\n{\n\tstruct gb_operation *operation;\n\n\tflags |= GB_OPERATION_FLAG_CORE;\n\n\toperation = gb_operation_create_common(connection, type,\n\t\t\t\t\t       request_size, response_size,\n\t\t\t\t\t       flags, gfp);\n\tif (operation)\n\t\ttrace_gb_operation_create_core(operation);\n\n\treturn operation;\n}\n\n \n\nsize_t gb_operation_get_payload_size_max(struct gb_connection *connection)\n{\n\tstruct gb_host_device *hd = connection->hd;\n\n\treturn hd->buffer_size_max - sizeof(struct gb_operation_msg_hdr);\n}\nEXPORT_SYMBOL_GPL(gb_operation_get_payload_size_max);\n\nstatic struct gb_operation *\ngb_operation_create_incoming(struct gb_connection *connection, u16 id,\n\t\t\t     u8 type, void *data, size_t size)\n{\n\tstruct gb_operation *operation;\n\tsize_t request_size;\n\tunsigned long flags = GB_OPERATION_FLAG_INCOMING;\n\n\t \n\trequest_size = size - sizeof(struct gb_operation_msg_hdr);\n\n\tif (!id)\n\t\tflags |= GB_OPERATION_FLAG_UNIDIRECTIONAL;\n\n\toperation = gb_operation_create_common(connection, type,\n\t\t\t\t\t       request_size,\n\t\t\t\t\t       GB_REQUEST_TYPE_INVALID,\n\t\t\t\t\t       flags, GFP_ATOMIC);\n\tif (!operation)\n\t\treturn NULL;\n\n\toperation->id = id;\n\tmemcpy(operation->request->header, data, size);\n\ttrace_gb_operation_create_incoming(operation);\n\n\treturn operation;\n}\n\n \nvoid gb_operation_get(struct gb_operation *operation)\n{\n\tkref_get(&operation->kref);\n}\nEXPORT_SYMBOL_GPL(gb_operation_get);\n\n \nstatic void _gb_operation_destroy(struct kref *kref)\n{\n\tstruct gb_operation *operation;\n\n\toperation = container_of(kref, struct gb_operation, kref);\n\n\ttrace_gb_operation_destroy(operation);\n\n\tif (operation->response)\n\t\tgb_operation_message_free(operation->response);\n\tgb_operation_message_free(operation->request);\n\n\tkmem_cache_free(gb_operation_cache, operation);\n}\n\n \nvoid gb_operation_put(struct gb_operation *operation)\n{\n\tif (WARN_ON(!operation))\n\t\treturn;\n\n\tkref_put(&operation->kref, _gb_operation_destroy);\n}\nEXPORT_SYMBOL_GPL(gb_operation_put);\n\n \nstatic void gb_operation_sync_callback(struct gb_operation *operation)\n{\n\tcomplete(&operation->completion);\n}\n\n \nint gb_operation_request_send(struct gb_operation *operation,\n\t\t\t      gb_operation_callback callback,\n\t\t\t      unsigned int timeout,\n\t\t\t      gfp_t gfp)\n{\n\tstruct gb_connection *connection = operation->connection;\n\tstruct gb_operation_msg_hdr *header;\n\tunsigned int cycle;\n\tint ret;\n\n\tif (gb_connection_is_offloaded(connection))\n\t\treturn -EBUSY;\n\n\tif (!callback)\n\t\treturn -EINVAL;\n\n\t \n\toperation->callback = callback;\n\n\t \n\tif (gb_operation_is_unidirectional(operation)) {\n\t\toperation->id = 0;\n\t} else {\n\t\tcycle = (unsigned int)atomic_inc_return(&connection->op_cycle);\n\t\toperation->id = (u16)(cycle % U16_MAX + 1);\n\t}\n\n\theader = operation->request->header;\n\theader->operation_id = cpu_to_le16(operation->id);\n\n\tgb_operation_result_set(operation, -EINPROGRESS);\n\n\t \n\tgb_operation_get(operation);\n\tret = gb_operation_get_active(operation);\n\tif (ret)\n\t\tgoto err_put;\n\n\tret = gb_message_send(operation->request, gfp);\n\tif (ret)\n\t\tgoto err_put_active;\n\n\tif (timeout) {\n\t\toperation->timer.expires = jiffies + msecs_to_jiffies(timeout);\n\t\tadd_timer(&operation->timer);\n\t}\n\n\treturn 0;\n\nerr_put_active:\n\tgb_operation_put_active(operation);\nerr_put:\n\tgb_operation_put(operation);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(gb_operation_request_send);\n\n \nint gb_operation_request_send_sync_timeout(struct gb_operation *operation,\n\t\t\t\t\t   unsigned int timeout)\n{\n\tint ret;\n\n\tret = gb_operation_request_send(operation, gb_operation_sync_callback,\n\t\t\t\t\ttimeout, GFP_KERNEL);\n\tif (ret)\n\t\treturn ret;\n\n\tret = wait_for_completion_interruptible(&operation->completion);\n\tif (ret < 0) {\n\t\t \n\t\tgb_operation_cancel(operation, -ECANCELED);\n\t}\n\n\treturn gb_operation_result(operation);\n}\nEXPORT_SYMBOL_GPL(gb_operation_request_send_sync_timeout);\n\n \nstatic int gb_operation_response_send(struct gb_operation *operation,\n\t\t\t\t      int errno)\n{\n\tstruct gb_connection *connection = operation->connection;\n\tint ret;\n\n\tif (!operation->response &&\n\t    !gb_operation_is_unidirectional(operation)) {\n\t\tif (!gb_operation_response_alloc(operation, 0, GFP_KERNEL))\n\t\t\treturn -ENOMEM;\n\t}\n\n\t \n\tif (!gb_operation_result_set(operation, errno)) {\n\t\tdev_err(&connection->hd->dev, \"request result already set\\n\");\n\t\treturn -EIO;\t \n\t}\n\n\t \n\tif (gb_operation_is_unidirectional(operation))\n\t\treturn 0;\n\n\t \n\tgb_operation_get(operation);\n\tret = gb_operation_get_active(operation);\n\tif (ret)\n\t\tgoto err_put;\n\n\t \n\toperation->response->header->result = gb_operation_errno_map(errno);\n\n\tret = gb_message_send(operation->response, GFP_KERNEL);\n\tif (ret)\n\t\tgoto err_put_active;\n\n\treturn 0;\n\nerr_put_active:\n\tgb_operation_put_active(operation);\nerr_put:\n\tgb_operation_put(operation);\n\n\treturn ret;\n}\n\n \nvoid greybus_message_sent(struct gb_host_device *hd,\n\t\t\t  struct gb_message *message, int status)\n{\n\tstruct gb_operation *operation = message->operation;\n\tstruct gb_connection *connection = operation->connection;\n\n\t \n\tif (message == operation->response) {\n\t\tif (status) {\n\t\t\tdev_err(&connection->hd->dev,\n\t\t\t\t\"%s: error sending response 0x%02x: %d\\n\",\n\t\t\t\tconnection->name, operation->type, status);\n\t\t}\n\n\t\tgb_operation_put_active(operation);\n\t\tgb_operation_put(operation);\n\t} else if (status || gb_operation_is_unidirectional(operation)) {\n\t\tif (gb_operation_result_set(operation, status)) {\n\t\t\tqueue_work(gb_operation_completion_wq,\n\t\t\t\t   &operation->work);\n\t\t}\n\t}\n}\nEXPORT_SYMBOL_GPL(greybus_message_sent);\n\n \nstatic void gb_connection_recv_request(struct gb_connection *connection,\n\t\t\t\tconst struct gb_operation_msg_hdr *header,\n\t\t\t\tvoid *data, size_t size)\n{\n\tstruct gb_operation *operation;\n\tu16 operation_id;\n\tu8 type;\n\tint ret;\n\n\toperation_id = le16_to_cpu(header->operation_id);\n\ttype = header->type;\n\n\toperation = gb_operation_create_incoming(connection, operation_id,\n\t\t\t\t\t\t type, data, size);\n\tif (!operation) {\n\t\tdev_err(&connection->hd->dev,\n\t\t\t\"%s: can't create incoming operation\\n\",\n\t\t\tconnection->name);\n\t\treturn;\n\t}\n\n\tret = gb_operation_get_active(operation);\n\tif (ret) {\n\t\tgb_operation_put(operation);\n\t\treturn;\n\t}\n\ttrace_gb_message_recv_request(operation->request);\n\n\t \n\tif (gb_operation_result_set(operation, -EINPROGRESS))\n\t\tqueue_work(connection->wq, &operation->work);\n}\n\n \nstatic void gb_connection_recv_response(struct gb_connection *connection,\n\t\t\t\tconst struct gb_operation_msg_hdr *header,\n\t\t\t\tvoid *data, size_t size)\n{\n\tstruct gb_operation *operation;\n\tstruct gb_message *message;\n\tsize_t message_size;\n\tu16 operation_id;\n\tint errno;\n\n\toperation_id = le16_to_cpu(header->operation_id);\n\n\tif (!operation_id) {\n\t\tdev_err_ratelimited(&connection->hd->dev,\n\t\t\t\t    \"%s: invalid response id 0 received\\n\",\n\t\t\t\t    connection->name);\n\t\treturn;\n\t}\n\n\toperation = gb_operation_find_outgoing(connection, operation_id);\n\tif (!operation) {\n\t\tdev_err_ratelimited(&connection->hd->dev,\n\t\t\t\t    \"%s: unexpected response id 0x%04x received\\n\",\n\t\t\t\t    connection->name, operation_id);\n\t\treturn;\n\t}\n\n\terrno = gb_operation_status_map(header->result);\n\tmessage = operation->response;\n\tmessage_size = sizeof(*header) + message->payload_size;\n\tif (!errno && size > message_size) {\n\t\tdev_err_ratelimited(&connection->hd->dev,\n\t\t\t\t    \"%s: malformed response 0x%02x received (%zu > %zu)\\n\",\n\t\t\t\t    connection->name, header->type,\n\t\t\t\t    size, message_size);\n\t\terrno = -EMSGSIZE;\n\t} else if (!errno && size < message_size) {\n\t\tif (gb_operation_short_response_allowed(operation)) {\n\t\t\tmessage->payload_size = size - sizeof(*header);\n\t\t} else {\n\t\t\tdev_err_ratelimited(&connection->hd->dev,\n\t\t\t\t\t    \"%s: short response 0x%02x received (%zu < %zu)\\n\",\n\t\t\t\t\t    connection->name, header->type,\n\t\t\t\t\t    size, message_size);\n\t\t\terrno = -EMSGSIZE;\n\t\t}\n\t}\n\n\t \n\tif (errno)\n\t\tsize = sizeof(*header);\n\n\t \n\tif (gb_operation_result_set(operation, errno)) {\n\t\tmemcpy(message->buffer, data, size);\n\n\t\ttrace_gb_message_recv_response(message);\n\n\t\tqueue_work(gb_operation_completion_wq, &operation->work);\n\t}\n\n\tgb_operation_put(operation);\n}\n\n \nvoid gb_connection_recv(struct gb_connection *connection,\n\t\t\tvoid *data, size_t size)\n{\n\tstruct gb_operation_msg_hdr header;\n\tstruct device *dev = &connection->hd->dev;\n\tsize_t msg_size;\n\n\tif (connection->state == GB_CONNECTION_STATE_DISABLED ||\n\t    gb_connection_is_offloaded(connection)) {\n\t\tdev_warn_ratelimited(dev, \"%s: dropping %zu received bytes\\n\",\n\t\t\t\t     connection->name, size);\n\t\treturn;\n\t}\n\n\tif (size < sizeof(header)) {\n\t\tdev_err_ratelimited(dev, \"%s: short message received\\n\",\n\t\t\t\t    connection->name);\n\t\treturn;\n\t}\n\n\t \n\tmemcpy(&header, data, sizeof(header));\n\tmsg_size = le16_to_cpu(header.size);\n\tif (size < msg_size) {\n\t\tdev_err_ratelimited(dev,\n\t\t\t\t    \"%s: incomplete message 0x%04x of type 0x%02x received (%zu < %zu)\\n\",\n\t\t\t\t    connection->name,\n\t\t\t\t    le16_to_cpu(header.operation_id),\n\t\t\t\t    header.type, size, msg_size);\n\t\treturn;\t\t \n\t}\n\n\tif (header.type & GB_MESSAGE_TYPE_RESPONSE) {\n\t\tgb_connection_recv_response(connection,\t&header, data,\n\t\t\t\t\t    msg_size);\n\t} else {\n\t\tgb_connection_recv_request(connection, &header, data,\n\t\t\t\t\t   msg_size);\n\t}\n}\n\n \nvoid gb_operation_cancel(struct gb_operation *operation, int errno)\n{\n\tif (WARN_ON(gb_operation_is_incoming(operation)))\n\t\treturn;\n\n\tif (gb_operation_result_set(operation, errno)) {\n\t\tgb_message_cancel(operation->request);\n\t\tqueue_work(gb_operation_completion_wq, &operation->work);\n\t}\n\ttrace_gb_message_cancel_outgoing(operation->request);\n\n\tatomic_inc(&operation->waiters);\n\twait_event(gb_operation_cancellation_queue,\n\t\t   !gb_operation_is_active(operation));\n\tatomic_dec(&operation->waiters);\n}\nEXPORT_SYMBOL_GPL(gb_operation_cancel);\n\n \nvoid gb_operation_cancel_incoming(struct gb_operation *operation, int errno)\n{\n\tif (WARN_ON(!gb_operation_is_incoming(operation)))\n\t\treturn;\n\n\tif (!gb_operation_is_unidirectional(operation)) {\n\t\t \n\t\tflush_work(&operation->work);\n\t\tif (!gb_operation_result_set(operation, errno))\n\t\t\tgb_message_cancel(operation->response);\n\t}\n\ttrace_gb_message_cancel_incoming(operation->response);\n\n\tatomic_inc(&operation->waiters);\n\twait_event(gb_operation_cancellation_queue,\n\t\t   !gb_operation_is_active(operation));\n\tatomic_dec(&operation->waiters);\n}\n\n \nint gb_operation_sync_timeout(struct gb_connection *connection, int type,\n\t\t\t      void *request, int request_size,\n\t\t\t      void *response, int response_size,\n\t\t\t      unsigned int timeout)\n{\n\tstruct gb_operation *operation;\n\tint ret;\n\n\tif ((response_size && !response) ||\n\t    (request_size && !request))\n\t\treturn -EINVAL;\n\n\toperation = gb_operation_create(connection, type,\n\t\t\t\t\trequest_size, response_size,\n\t\t\t\t\tGFP_KERNEL);\n\tif (!operation)\n\t\treturn -ENOMEM;\n\n\tif (request_size)\n\t\tmemcpy(operation->request->payload, request, request_size);\n\n\tret = gb_operation_request_send_sync_timeout(operation, timeout);\n\tif (ret) {\n\t\tdev_err(&connection->hd->dev,\n\t\t\t\"%s: synchronous operation id 0x%04x of type 0x%02x failed: %d\\n\",\n\t\t\tconnection->name, operation->id, type, ret);\n\t} else {\n\t\tif (response_size) {\n\t\t\tmemcpy(response, operation->response->payload,\n\t\t\t       response_size);\n\t\t}\n\t}\n\n\tgb_operation_put(operation);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(gb_operation_sync_timeout);\n\n \nint gb_operation_unidirectional_timeout(struct gb_connection *connection,\n\t\t\t\t\tint type, void *request,\n\t\t\t\t\tint request_size,\n\t\t\t\t\tunsigned int timeout)\n{\n\tstruct gb_operation *operation;\n\tint ret;\n\n\tif (request_size && !request)\n\t\treturn -EINVAL;\n\n\toperation = gb_operation_create_flags(connection, type,\n\t\t\t\t\t      request_size, 0,\n\t\t\t\t\t      GB_OPERATION_FLAG_UNIDIRECTIONAL,\n\t\t\t\t\t      GFP_KERNEL);\n\tif (!operation)\n\t\treturn -ENOMEM;\n\n\tif (request_size)\n\t\tmemcpy(operation->request->payload, request, request_size);\n\n\tret = gb_operation_request_send_sync_timeout(operation, timeout);\n\tif (ret) {\n\t\tdev_err(&connection->hd->dev,\n\t\t\t\"%s: unidirectional operation of type 0x%02x failed: %d\\n\",\n\t\t\tconnection->name, type, ret);\n\t}\n\n\tgb_operation_put(operation);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(gb_operation_unidirectional_timeout);\n\nint __init gb_operation_init(void)\n{\n\tgb_message_cache = kmem_cache_create(\"gb_message_cache\",\n\t\t\t\t\t     sizeof(struct gb_message), 0, 0,\n\t\t\t\t\t     NULL);\n\tif (!gb_message_cache)\n\t\treturn -ENOMEM;\n\n\tgb_operation_cache = kmem_cache_create(\"gb_operation_cache\",\n\t\t\t\t\t       sizeof(struct gb_operation), 0,\n\t\t\t\t\t       0, NULL);\n\tif (!gb_operation_cache)\n\t\tgoto err_destroy_message_cache;\n\n\tgb_operation_completion_wq = alloc_workqueue(\"greybus_completion\",\n\t\t\t\t\t\t     0, 0);\n\tif (!gb_operation_completion_wq)\n\t\tgoto err_destroy_operation_cache;\n\n\treturn 0;\n\nerr_destroy_operation_cache:\n\tkmem_cache_destroy(gb_operation_cache);\n\tgb_operation_cache = NULL;\nerr_destroy_message_cache:\n\tkmem_cache_destroy(gb_message_cache);\n\tgb_message_cache = NULL;\n\n\treturn -ENOMEM;\n}\n\nvoid gb_operation_exit(void)\n{\n\tdestroy_workqueue(gb_operation_completion_wq);\n\tgb_operation_completion_wq = NULL;\n\tkmem_cache_destroy(gb_operation_cache);\n\tgb_operation_cache = NULL;\n\tkmem_cache_destroy(gb_message_cache);\n\tgb_message_cache = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}