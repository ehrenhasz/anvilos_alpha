{
  "module_name": "pm.c",
  "hash_id": "fc9d9a2e6224933cae0a41f81eeae9626af2f4e91af82e8436d88562358dba9a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/bus/mhi/host/pm.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/device.h>\n#include <linux/dma-direction.h>\n#include <linux/dma-mapping.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/mhi.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/wait.h>\n#include \"internal.h\"\n\n \nstatic const struct mhi_pm_transitions dev_state_transitions[] = {\n\t \n\t{\n\t\tMHI_PM_DISABLE,\n\t\tMHI_PM_POR\n\t},\n\t{\n\t\tMHI_PM_POR,\n\t\tMHI_PM_POR | MHI_PM_DISABLE | MHI_PM_M0 |\n\t\tMHI_PM_SYS_ERR_DETECT | MHI_PM_SHUTDOWN_PROCESS |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT | MHI_PM_FW_DL_ERR\n\t},\n\t{\n\t\tMHI_PM_M0,\n\t\tMHI_PM_M0 | MHI_PM_M2 | MHI_PM_M3_ENTER |\n\t\tMHI_PM_SYS_ERR_DETECT | MHI_PM_SHUTDOWN_PROCESS |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT | MHI_PM_FW_DL_ERR\n\t},\n\t{\n\t\tMHI_PM_M2,\n\t\tMHI_PM_M0 | MHI_PM_SYS_ERR_DETECT | MHI_PM_SHUTDOWN_PROCESS |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t{\n\t\tMHI_PM_M3_ENTER,\n\t\tMHI_PM_M3 | MHI_PM_SYS_ERR_DETECT | MHI_PM_SHUTDOWN_PROCESS |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t{\n\t\tMHI_PM_M3,\n\t\tMHI_PM_M3_EXIT | MHI_PM_SYS_ERR_DETECT |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t{\n\t\tMHI_PM_M3_EXIT,\n\t\tMHI_PM_M0 | MHI_PM_SYS_ERR_DETECT | MHI_PM_SHUTDOWN_PROCESS |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t{\n\t\tMHI_PM_FW_DL_ERR,\n\t\tMHI_PM_FW_DL_ERR | MHI_PM_SYS_ERR_DETECT |\n\t\tMHI_PM_SHUTDOWN_PROCESS | MHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t \n\t{\n\t\tMHI_PM_SYS_ERR_DETECT,\n\t\tMHI_PM_SYS_ERR_PROCESS | MHI_PM_SHUTDOWN_PROCESS |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t{\n\t\tMHI_PM_SYS_ERR_PROCESS,\n\t\tMHI_PM_POR | MHI_PM_SHUTDOWN_PROCESS |\n\t\tMHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t \n\t{\n\t\tMHI_PM_SHUTDOWN_PROCESS,\n\t\tMHI_PM_DISABLE | MHI_PM_LD_ERR_FATAL_DETECT\n\t},\n\t \n\t{\n\t\tMHI_PM_LD_ERR_FATAL_DETECT,\n\t\tMHI_PM_LD_ERR_FATAL_DETECT | MHI_PM_DISABLE\n\t},\n};\n\nenum mhi_pm_state __must_check mhi_tryset_pm_state(struct mhi_controller *mhi_cntrl,\n\t\t\t\t\t\t   enum mhi_pm_state state)\n{\n\tunsigned long cur_state = mhi_cntrl->pm_state;\n\tint index = find_last_bit(&cur_state, 32);\n\n\tif (unlikely(index >= ARRAY_SIZE(dev_state_transitions)))\n\t\treturn cur_state;\n\n\tif (unlikely(dev_state_transitions[index].from_state != cur_state))\n\t\treturn cur_state;\n\n\tif (unlikely(!(dev_state_transitions[index].to_states & state)))\n\t\treturn cur_state;\n\n\tmhi_cntrl->pm_state = state;\n\treturn mhi_cntrl->pm_state;\n}\n\nvoid mhi_set_mhi_state(struct mhi_controller *mhi_cntrl, enum mhi_state state)\n{\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tint ret;\n\n\tif (state == MHI_STATE_RESET) {\n\t\tret = mhi_write_reg_field(mhi_cntrl, mhi_cntrl->regs, MHICTRL,\n\t\t\t\t\t  MHICTRL_RESET_MASK, 1);\n\t} else {\n\t\tret = mhi_write_reg_field(mhi_cntrl, mhi_cntrl->regs, MHICTRL,\n\t\t\t\t\t  MHICTRL_MHISTATE_MASK, state);\n\t}\n\n\tif (ret)\n\t\tdev_err(dev, \"Failed to set MHI state to: %s\\n\",\n\t\t\tmhi_state_str(state));\n}\n\n \nstatic void mhi_toggle_dev_wake_nop(struct mhi_controller *mhi_cntrl)\n{\n}\n\nstatic void mhi_toggle_dev_wake(struct mhi_controller *mhi_cntrl)\n{\n\tmhi_cntrl->wake_get(mhi_cntrl, false);\n\tmhi_cntrl->wake_put(mhi_cntrl, true);\n}\n\n \nint mhi_ready_state_transition(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_event *mhi_event;\n\tenum mhi_pm_state cur_state;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tu32 interval_us = 25000;  \n\tint ret, i;\n\n\t \n\tif (MHI_PM_IN_FATAL_STATE(mhi_cntrl->pm_state)) {\n\t\tdev_err(dev, \"Device link is not accessible\\n\");\n\t\treturn -EIO;\n\t}\n\n\t \n\tret = mhi_poll_reg_field(mhi_cntrl, mhi_cntrl->regs, MHICTRL,\n\t\t\t\t MHICTRL_RESET_MASK, 0, interval_us);\n\tif (ret) {\n\t\tdev_err(dev, \"Device failed to clear MHI Reset\\n\");\n\t\treturn ret;\n\t}\n\n\tret = mhi_poll_reg_field(mhi_cntrl, mhi_cntrl->regs, MHISTATUS,\n\t\t\t\t MHISTATUS_READY_MASK, 1, interval_us);\n\tif (ret) {\n\t\tdev_err(dev, \"Device failed to enter MHI Ready\\n\");\n\t\treturn ret;\n\t}\n\n\tdev_dbg(dev, \"Device in READY State\\n\");\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tcur_state = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_POR);\n\tmhi_cntrl->dev_state = MHI_STATE_READY;\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\n\tif (cur_state != MHI_PM_POR) {\n\t\tdev_err(dev, \"Error moving to state %s from %s\\n\",\n\t\t\tto_mhi_pm_state_str(MHI_PM_POR),\n\t\t\tto_mhi_pm_state_str(cur_state));\n\t\treturn -EIO;\n\t}\n\n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\tif (!MHI_REG_ACCESS_VALID(mhi_cntrl->pm_state)) {\n\t\tdev_err(dev, \"Device registers not accessible\\n\");\n\t\tgoto error_mmio;\n\t}\n\n\t \n\tret = mhi_init_mmio(mhi_cntrl);\n\tif (ret) {\n\t\tdev_err(dev, \"Error configuring MMIO registers\\n\");\n\t\tgoto error_mmio;\n\t}\n\n\t \n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tstruct mhi_ring *ring = &mhi_event->ring;\n\n\t\t \n\t\tif (mhi_event->offload_ev || mhi_event->hw_ring)\n\t\t\tcontinue;\n\n\t\tring->wp = ring->base + ring->len - ring->el_size;\n\t\t*ring->ctxt_wp = cpu_to_le64(ring->iommu_base + ring->len - ring->el_size);\n\t\t \n\t\tsmp_wmb();\n\n\t\t \n\t\tspin_lock_irq(&mhi_event->lock);\n\t\tmhi_ring_er_db(mhi_event);\n\t\tspin_unlock_irq(&mhi_event->lock);\n\t}\n\n\t \n\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_M0);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\n\treturn 0;\n\nerror_mmio:\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\n\treturn -EIO;\n}\n\nint mhi_pm_m0_transition(struct mhi_controller *mhi_cntrl)\n{\n\tenum mhi_pm_state cur_state;\n\tstruct mhi_chan *mhi_chan;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tint i;\n\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tmhi_cntrl->dev_state = MHI_STATE_M0;\n\tcur_state = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_M0);\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\tif (unlikely(cur_state != MHI_PM_M0)) {\n\t\tdev_err(dev, \"Unable to transition to M0 state\\n\");\n\t\treturn -EIO;\n\t}\n\tmhi_cntrl->M0++;\n\n\t \n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\tmhi_cntrl->wake_get(mhi_cntrl, true);\n\n\t \n\tif (MHI_IN_MISSION_MODE(mhi_cntrl->ee)) {\n\t\tstruct mhi_event *mhi_event = mhi_cntrl->mhi_event;\n\t\tstruct mhi_cmd *mhi_cmd =\n\t\t\t&mhi_cntrl->mhi_cmd[PRIMARY_CMD_RING];\n\n\t\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\t\tif (mhi_event->offload_ev)\n\t\t\t\tcontinue;\n\n\t\t\tspin_lock_irq(&mhi_event->lock);\n\t\t\tmhi_ring_er_db(mhi_event);\n\t\t\tspin_unlock_irq(&mhi_event->lock);\n\t\t}\n\n\t\t \n\t\tspin_lock_irq(&mhi_cmd->lock);\n\t\tif (mhi_cmd->ring.rp != mhi_cmd->ring.wp)\n\t\t\tmhi_ring_cmd_db(mhi_cntrl, mhi_cmd);\n\t\tspin_unlock_irq(&mhi_cmd->lock);\n\t}\n\n\t \n\tmhi_chan = mhi_cntrl->mhi_chan;\n\tfor (i = 0; i < mhi_cntrl->max_chan; i++, mhi_chan++) {\n\t\tstruct mhi_ring *tre_ring = &mhi_chan->tre_ring;\n\n\t\tif (mhi_chan->db_cfg.reset_req) {\n\t\t\twrite_lock_irq(&mhi_chan->lock);\n\t\t\tmhi_chan->db_cfg.db_mode = true;\n\t\t\twrite_unlock_irq(&mhi_chan->lock);\n\t\t}\n\n\t\tread_lock_irq(&mhi_chan->lock);\n\n\t\t \n\t\tif (tre_ring->base && tre_ring->wp  != tre_ring->rp &&\n\t\t    mhi_chan->ch_state == MHI_CH_STATE_ENABLED)\n\t\t\tmhi_ring_chan_db(mhi_cntrl, mhi_chan);\n\t\tread_unlock_irq(&mhi_chan->lock);\n\t}\n\n\tmhi_cntrl->wake_put(mhi_cntrl, false);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\twake_up_all(&mhi_cntrl->state_event);\n\n\treturn 0;\n}\n\n \nvoid mhi_pm_m1_transition(struct mhi_controller *mhi_cntrl)\n{\n\tenum mhi_pm_state state;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tstate = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_M2);\n\tif (state == MHI_PM_M2) {\n\t\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_M2);\n\t\tmhi_cntrl->dev_state = MHI_STATE_M2;\n\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\n\t\tmhi_cntrl->M2++;\n\t\twake_up_all(&mhi_cntrl->state_event);\n\n\t\t \n\t\tif (unlikely(atomic_read(&mhi_cntrl->pending_pkts) ||\n\t\t\t     atomic_read(&mhi_cntrl->dev_wake))) {\n\t\t\tdev_dbg(dev,\n\t\t\t\t\"Exiting M2, pending_pkts: %d dev_wake: %d\\n\",\n\t\t\t\tatomic_read(&mhi_cntrl->pending_pkts),\n\t\t\t\tatomic_read(&mhi_cntrl->dev_wake));\n\t\t\tread_lock_bh(&mhi_cntrl->pm_lock);\n\t\t\tmhi_cntrl->wake_get(mhi_cntrl, true);\n\t\t\tmhi_cntrl->wake_put(mhi_cntrl, true);\n\t\t\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\t\t} else {\n\t\t\tmhi_cntrl->status_cb(mhi_cntrl, MHI_CB_IDLE);\n\t\t}\n\t} else {\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t}\n}\n\n \nint mhi_pm_m3_transition(struct mhi_controller *mhi_cntrl)\n{\n\tenum mhi_pm_state state;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tmhi_cntrl->dev_state = MHI_STATE_M3;\n\tstate = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_M3);\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\tif (state != MHI_PM_M3) {\n\t\tdev_err(dev, \"Unable to transition to M3 state\\n\");\n\t\treturn -EIO;\n\t}\n\n\tmhi_cntrl->M3++;\n\twake_up_all(&mhi_cntrl->state_event);\n\n\treturn 0;\n}\n\n \nstatic int mhi_pm_mission_mode_transition(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_event *mhi_event;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tenum mhi_ee_type ee = MHI_EE_MAX, current_ee = mhi_cntrl->ee;\n\tint i, ret;\n\n\tdev_dbg(dev, \"Processing Mission Mode transition\\n\");\n\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tif (MHI_REG_ACCESS_VALID(mhi_cntrl->pm_state))\n\t\tee = mhi_get_exec_env(mhi_cntrl);\n\n\tif (!MHI_IN_MISSION_MODE(ee)) {\n\t\tmhi_cntrl->pm_state = MHI_PM_LD_ERR_FATAL_DETECT;\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\twake_up_all(&mhi_cntrl->state_event);\n\t\treturn -EIO;\n\t}\n\tmhi_cntrl->ee = ee;\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\n\twake_up_all(&mhi_cntrl->state_event);\n\n\tdevice_for_each_child(&mhi_cntrl->mhi_dev->dev, &current_ee,\n\t\t\t      mhi_destroy_device);\n\tmhi_cntrl->status_cb(mhi_cntrl, MHI_CB_EE_MISSION_MODE);\n\n\t \n\tret = __mhi_device_get_sync(mhi_cntrl);\n\tif (ret)\n\t\treturn ret;\n\n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\n\tif (MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state)) {\n\t\tret = -EIO;\n\t\tgoto error_mission_mode;\n\t}\n\n\t \n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tstruct mhi_ring *ring = &mhi_event->ring;\n\n\t\tif (mhi_event->offload_ev || !mhi_event->hw_ring)\n\t\t\tcontinue;\n\n\t\tring->wp = ring->base + ring->len - ring->el_size;\n\t\t*ring->ctxt_wp = cpu_to_le64(ring->iommu_base + ring->len - ring->el_size);\n\t\t \n\t\tsmp_wmb();\n\n\t\tspin_lock_irq(&mhi_event->lock);\n\t\tif (MHI_DB_ACCESS_VALID(mhi_cntrl))\n\t\t\tmhi_ring_er_db(mhi_event);\n\t\tspin_unlock_irq(&mhi_event->lock);\n\t}\n\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\n\t \n\tmhi_create_devices(mhi_cntrl);\n\n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\nerror_mission_mode:\n\tmhi_cntrl->wake_put(mhi_cntrl, false);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\n\treturn ret;\n}\n\n \nstatic void mhi_pm_disable_transition(struct mhi_controller *mhi_cntrl)\n{\n\tenum mhi_pm_state cur_state;\n\tstruct mhi_event *mhi_event;\n\tstruct mhi_cmd_ctxt *cmd_ctxt;\n\tstruct mhi_cmd *mhi_cmd;\n\tstruct mhi_event_ctxt *er_ctxt;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tint ret, i;\n\n\tdev_dbg(dev, \"Processing disable transition with PM state: %s\\n\",\n\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state));\n\n\tmutex_lock(&mhi_cntrl->pm_mutex);\n\n\t \n\tif (!MHI_PM_IN_FATAL_STATE(mhi_cntrl->pm_state)) {\n\t\t \n\t\tif (mhi_cntrl->rddm_image && mhi_get_exec_env(mhi_cntrl) == MHI_EE_RDDM)\n\t\t\tgoto skip_mhi_reset;\n\n\t\tdev_dbg(dev, \"Triggering MHI Reset in device\\n\");\n\t\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_RESET);\n\n\t\t \n\t\tret = mhi_poll_reg_field(mhi_cntrl, mhi_cntrl->regs, MHICTRL,\n\t\t\t\t MHICTRL_RESET_MASK, 0, 25000);\n\t\tif (ret)\n\t\t\tdev_err(dev, \"Device failed to clear MHI Reset\\n\");\n\n\t\t \n\t\tmhi_write_reg(mhi_cntrl, mhi_cntrl->bhi, BHI_INTVEC, 0);\n\n\t\tif (!MHI_IN_PBL(mhi_get_exec_env(mhi_cntrl))) {\n\t\t\t \n\t\t\tret = mhi_poll_reg_field(mhi_cntrl, mhi_cntrl->regs,\n\t\t\t\t\t\t MHISTATUS,\n\t\t\t\t\t\t MHISTATUS_READY_MASK, 1, 25000);\n\t\t\tif (ret)\n\t\t\t\tdev_err(dev, \"Device failed to enter READY state\\n\");\n\t\t}\n\t}\n\nskip_mhi_reset:\n\tdev_dbg(dev,\n\t\t \"Waiting for all pending event ring processing to complete\\n\");\n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\t\tdisable_irq(mhi_cntrl->irq[mhi_event->irq]);\n\t\ttasklet_kill(&mhi_event->task);\n\t}\n\n\t \n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\tdev_dbg(dev, \"Waiting for all pending threads to complete\\n\");\n\twake_up_all(&mhi_cntrl->state_event);\n\n\tdev_dbg(dev, \"Reset all active channels and remove MHI devices\\n\");\n\tdevice_for_each_child(&mhi_cntrl->mhi_dev->dev, NULL, mhi_destroy_device);\n\n\tmutex_lock(&mhi_cntrl->pm_mutex);\n\n\tWARN_ON(atomic_read(&mhi_cntrl->dev_wake));\n\tWARN_ON(atomic_read(&mhi_cntrl->pending_pkts));\n\n\t \n\tdev_dbg(dev, \"Resetting EV CTXT and CMD CTXT\\n\");\n\tmhi_cmd = mhi_cntrl->mhi_cmd;\n\tcmd_ctxt = mhi_cntrl->mhi_ctxt->cmd_ctxt;\n\tfor (i = 0; i < NR_OF_CMD_RINGS; i++, mhi_cmd++, cmd_ctxt++) {\n\t\tstruct mhi_ring *ring = &mhi_cmd->ring;\n\n\t\tring->rp = ring->base;\n\t\tring->wp = ring->base;\n\t\tcmd_ctxt->rp = cmd_ctxt->rbase;\n\t\tcmd_ctxt->wp = cmd_ctxt->rbase;\n\t}\n\n\tmhi_event = mhi_cntrl->mhi_event;\n\ter_ctxt = mhi_cntrl->mhi_ctxt->er_ctxt;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, er_ctxt++,\n\t\t     mhi_event++) {\n\t\tstruct mhi_ring *ring = &mhi_event->ring;\n\n\t\t \n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tring->rp = ring->base;\n\t\tring->wp = ring->base;\n\t\ter_ctxt->rp = er_ctxt->rbase;\n\t\ter_ctxt->wp = er_ctxt->rbase;\n\t}\n\n\t \n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tcur_state = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_DISABLE);\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\tif (unlikely(cur_state != MHI_PM_DISABLE))\n\t\tdev_err(dev, \"Error moving from PM state: %s to: %s\\n\",\n\t\t\tto_mhi_pm_state_str(cur_state),\n\t\t\tto_mhi_pm_state_str(MHI_PM_DISABLE));\n\n\tdev_dbg(dev, \"Exiting with PM state: %s, MHI state: %s\\n\",\n\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state),\n\t\tmhi_state_str(mhi_cntrl->dev_state));\n\n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n}\n\n \nstatic void mhi_pm_sys_error_transition(struct mhi_controller *mhi_cntrl)\n{\n\tenum mhi_pm_state cur_state, prev_state;\n\tenum dev_st_transition next_state;\n\tstruct mhi_event *mhi_event;\n\tstruct mhi_cmd_ctxt *cmd_ctxt;\n\tstruct mhi_cmd *mhi_cmd;\n\tstruct mhi_event_ctxt *er_ctxt;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tint ret, i;\n\n\tdev_dbg(dev, \"Transitioning from PM state: %s to: %s\\n\",\n\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state),\n\t\tto_mhi_pm_state_str(MHI_PM_SYS_ERR_PROCESS));\n\n\t \n\tmhi_cntrl->status_cb(mhi_cntrl, MHI_CB_SYS_ERROR);\n\n\tmutex_lock(&mhi_cntrl->pm_mutex);\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tprev_state = mhi_cntrl->pm_state;\n\tcur_state = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_SYS_ERR_PROCESS);\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\n\tif (cur_state != MHI_PM_SYS_ERR_PROCESS) {\n\t\tdev_err(dev, \"Failed to transition from PM state: %s to: %s\\n\",\n\t\t\tto_mhi_pm_state_str(cur_state),\n\t\t\tto_mhi_pm_state_str(MHI_PM_SYS_ERR_PROCESS));\n\t\tgoto exit_sys_error_transition;\n\t}\n\n\tmhi_cntrl->ee = MHI_EE_DISABLE_TRANSITION;\n\tmhi_cntrl->dev_state = MHI_STATE_RESET;\n\n\t \n\twake_up_all(&mhi_cntrl->state_event);\n\n\t \n\tif (MHI_REG_ACCESS_VALID(prev_state)) {\n\t\tu32 in_reset = -1;\n\t\tunsigned long timeout = msecs_to_jiffies(mhi_cntrl->timeout_ms);\n\n\t\tdev_dbg(dev, \"Triggering MHI Reset in device\\n\");\n\t\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_RESET);\n\n\t\t \n\t\tret = wait_event_timeout(mhi_cntrl->state_event,\n\t\t\t\t\t mhi_read_reg_field(mhi_cntrl,\n\t\t\t\t\t\t\t    mhi_cntrl->regs,\n\t\t\t\t\t\t\t    MHICTRL,\n\t\t\t\t\t\t\t    MHICTRL_RESET_MASK,\n\t\t\t\t\t\t\t    &in_reset) ||\n\t\t\t\t\t!in_reset, timeout);\n\t\tif (!ret || in_reset) {\n\t\t\tdev_err(dev, \"Device failed to exit MHI Reset state\\n\");\n\t\t\tgoto exit_sys_error_transition;\n\t\t}\n\n\t\t \n\t\tmhi_write_reg(mhi_cntrl, mhi_cntrl->bhi, BHI_INTVEC, 0);\n\t}\n\n\tdev_dbg(dev,\n\t\t\"Waiting for all pending event ring processing to complete\\n\");\n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\t\ttasklet_kill(&mhi_event->task);\n\t}\n\n\t \n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\tdev_dbg(dev, \"Waiting for all pending threads to complete\\n\");\n\twake_up_all(&mhi_cntrl->state_event);\n\n\tdev_dbg(dev, \"Reset all active channels and remove MHI devices\\n\");\n\tdevice_for_each_child(&mhi_cntrl->mhi_dev->dev, NULL, mhi_destroy_device);\n\n\tmutex_lock(&mhi_cntrl->pm_mutex);\n\n\tWARN_ON(atomic_read(&mhi_cntrl->dev_wake));\n\tWARN_ON(atomic_read(&mhi_cntrl->pending_pkts));\n\n\t \n\tdev_dbg(dev, \"Resetting EV CTXT and CMD CTXT\\n\");\n\tmhi_cmd = mhi_cntrl->mhi_cmd;\n\tcmd_ctxt = mhi_cntrl->mhi_ctxt->cmd_ctxt;\n\tfor (i = 0; i < NR_OF_CMD_RINGS; i++, mhi_cmd++, cmd_ctxt++) {\n\t\tstruct mhi_ring *ring = &mhi_cmd->ring;\n\n\t\tring->rp = ring->base;\n\t\tring->wp = ring->base;\n\t\tcmd_ctxt->rp = cmd_ctxt->rbase;\n\t\tcmd_ctxt->wp = cmd_ctxt->rbase;\n\t}\n\n\tmhi_event = mhi_cntrl->mhi_event;\n\ter_ctxt = mhi_cntrl->mhi_ctxt->er_ctxt;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, er_ctxt++,\n\t     mhi_event++) {\n\t\tstruct mhi_ring *ring = &mhi_event->ring;\n\n\t\t \n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tring->rp = ring->base;\n\t\tring->wp = ring->base;\n\t\ter_ctxt->rp = er_ctxt->rbase;\n\t\ter_ctxt->wp = er_ctxt->rbase;\n\t}\n\n\t \n\tif (MHI_IN_PBL(mhi_get_exec_env(mhi_cntrl))) {\n\t\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\t\tcur_state = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_POR);\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\tif (cur_state != MHI_PM_POR) {\n\t\t\tdev_err(dev, \"Error moving to state %s from %s\\n\",\n\t\t\t\tto_mhi_pm_state_str(MHI_PM_POR),\n\t\t\t\tto_mhi_pm_state_str(cur_state));\n\t\t\tgoto exit_sys_error_transition;\n\t\t}\n\t\tnext_state = DEV_ST_TRANSITION_PBL;\n\t} else {\n\t\tnext_state = DEV_ST_TRANSITION_READY;\n\t}\n\n\tmhi_queue_state_transition(mhi_cntrl, next_state);\n\nexit_sys_error_transition:\n\tdev_dbg(dev, \"Exiting with PM state: %s, MHI state: %s\\n\",\n\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state),\n\t\tmhi_state_str(mhi_cntrl->dev_state));\n\n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n}\n\n \nint mhi_queue_state_transition(struct mhi_controller *mhi_cntrl,\n\t\t\t       enum dev_st_transition state)\n{\n\tstruct state_transition *item = kmalloc(sizeof(*item), GFP_ATOMIC);\n\tunsigned long flags;\n\n\tif (!item)\n\t\treturn -ENOMEM;\n\n\titem->state = state;\n\tspin_lock_irqsave(&mhi_cntrl->transition_lock, flags);\n\tlist_add_tail(&item->node, &mhi_cntrl->transition_list);\n\tspin_unlock_irqrestore(&mhi_cntrl->transition_lock, flags);\n\n\tqueue_work(mhi_cntrl->hiprio_wq, &mhi_cntrl->st_worker);\n\n\treturn 0;\n}\n\n \nvoid mhi_pm_sys_err_handler(struct mhi_controller *mhi_cntrl)\n{\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\n\t \n\tif (mhi_cntrl->rddm_image) {\n\t\tdev_dbg(dev, \"Controller supports RDDM, skip SYS_ERROR\\n\");\n\t\treturn;\n\t}\n\n\tmhi_queue_state_transition(mhi_cntrl, DEV_ST_TRANSITION_SYS_ERR);\n}\n\n \nvoid mhi_pm_st_worker(struct work_struct *work)\n{\n\tstruct state_transition *itr, *tmp;\n\tLIST_HEAD(head);\n\tstruct mhi_controller *mhi_cntrl = container_of(work,\n\t\t\t\t\t\t\tstruct mhi_controller,\n\t\t\t\t\t\t\tst_worker);\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\n\tspin_lock_irq(&mhi_cntrl->transition_lock);\n\tlist_splice_tail_init(&mhi_cntrl->transition_list, &head);\n\tspin_unlock_irq(&mhi_cntrl->transition_lock);\n\n\tlist_for_each_entry_safe(itr, tmp, &head, node) {\n\t\tlist_del(&itr->node);\n\t\tdev_dbg(dev, \"Handling state transition: %s\\n\",\n\t\t\tTO_DEV_STATE_TRANS_STR(itr->state));\n\n\t\tswitch (itr->state) {\n\t\tcase DEV_ST_TRANSITION_PBL:\n\t\t\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\t\t\tif (MHI_REG_ACCESS_VALID(mhi_cntrl->pm_state))\n\t\t\t\tmhi_cntrl->ee = mhi_get_exec_env(mhi_cntrl);\n\t\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\t\tmhi_fw_load_handler(mhi_cntrl);\n\t\t\tbreak;\n\t\tcase DEV_ST_TRANSITION_SBL:\n\t\t\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\t\t\tmhi_cntrl->ee = MHI_EE_SBL;\n\t\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\t\t \n\t\t\tmhi_create_devices(mhi_cntrl);\n\t\t\tif (mhi_cntrl->fbc_download)\n\t\t\t\tmhi_download_amss_image(mhi_cntrl);\n\t\t\tbreak;\n\t\tcase DEV_ST_TRANSITION_MISSION_MODE:\n\t\t\tmhi_pm_mission_mode_transition(mhi_cntrl);\n\t\t\tbreak;\n\t\tcase DEV_ST_TRANSITION_FP:\n\t\t\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\t\t\tmhi_cntrl->ee = MHI_EE_FP;\n\t\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\t\tmhi_create_devices(mhi_cntrl);\n\t\t\tbreak;\n\t\tcase DEV_ST_TRANSITION_READY:\n\t\t\tmhi_ready_state_transition(mhi_cntrl);\n\t\t\tbreak;\n\t\tcase DEV_ST_TRANSITION_SYS_ERR:\n\t\t\tmhi_pm_sys_error_transition(mhi_cntrl);\n\t\t\tbreak;\n\t\tcase DEV_ST_TRANSITION_DISABLE:\n\t\t\tmhi_pm_disable_transition(mhi_cntrl);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tkfree(itr);\n\t}\n}\n\nint mhi_pm_suspend(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_chan *itr, *tmp;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tenum mhi_pm_state new_state;\n\tint ret;\n\n\tif (mhi_cntrl->pm_state == MHI_PM_DISABLE)\n\t\treturn -EINVAL;\n\n\tif (MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state))\n\t\treturn -EIO;\n\n\t \n\tif (atomic_read(&mhi_cntrl->dev_wake) ||\n\t    atomic_read(&mhi_cntrl->pending_pkts))\n\t\treturn -EBUSY;\n\n\t \n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\tmhi_cntrl->wake_get(mhi_cntrl, false);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\n\tret = wait_event_timeout(mhi_cntrl->state_event,\n\t\t\t\t mhi_cntrl->dev_state == MHI_STATE_M0 ||\n\t\t\t\t mhi_cntrl->dev_state == MHI_STATE_M1 ||\n\t\t\t\t MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state),\n\t\t\t\t msecs_to_jiffies(mhi_cntrl->timeout_ms));\n\n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\tmhi_cntrl->wake_put(mhi_cntrl, false);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\n\tif (!ret || MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state)) {\n\t\tdev_err(dev,\n\t\t\t\"Could not enter M0/M1 state\");\n\t\treturn -EIO;\n\t}\n\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\n\tif (atomic_read(&mhi_cntrl->dev_wake) ||\n\t    atomic_read(&mhi_cntrl->pending_pkts)) {\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\treturn -EBUSY;\n\t}\n\n\tdev_dbg(dev, \"Allowing M3 transition\\n\");\n\tnew_state = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_M3_ENTER);\n\tif (new_state != MHI_PM_M3_ENTER) {\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\tdev_err(dev,\n\t\t\t\"Error setting to PM state: %s from: %s\\n\",\n\t\t\tto_mhi_pm_state_str(MHI_PM_M3_ENTER),\n\t\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state));\n\t\treturn -EIO;\n\t}\n\n\t \n\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_M3);\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\tdev_dbg(dev, \"Waiting for M3 completion\\n\");\n\n\tret = wait_event_timeout(mhi_cntrl->state_event,\n\t\t\t\t mhi_cntrl->dev_state == MHI_STATE_M3 ||\n\t\t\t\t MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state),\n\t\t\t\t msecs_to_jiffies(mhi_cntrl->timeout_ms));\n\n\tif (!ret || MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state)) {\n\t\tdev_err(dev,\n\t\t\t\"Did not enter M3 state, MHI state: %s, PM state: %s\\n\",\n\t\t\tmhi_state_str(mhi_cntrl->dev_state),\n\t\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state));\n\t\treturn -EIO;\n\t}\n\n\t \n\tlist_for_each_entry_safe(itr, tmp, &mhi_cntrl->lpm_chans, node) {\n\t\tmutex_lock(&itr->mutex);\n\t\tif (itr->mhi_dev)\n\t\t\tmhi_notify(itr->mhi_dev, MHI_CB_LPM_ENTER);\n\t\tmutex_unlock(&itr->mutex);\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mhi_pm_suspend);\n\nstatic int __mhi_pm_resume(struct mhi_controller *mhi_cntrl, bool force)\n{\n\tstruct mhi_chan *itr, *tmp;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tenum mhi_pm_state cur_state;\n\tint ret;\n\n\tdev_dbg(dev, \"Entered with PM state: %s, MHI state: %s\\n\",\n\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state),\n\t\tmhi_state_str(mhi_cntrl->dev_state));\n\n\tif (mhi_cntrl->pm_state == MHI_PM_DISABLE)\n\t\treturn 0;\n\n\tif (MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state))\n\t\treturn -EIO;\n\n\tif (mhi_get_mhi_state(mhi_cntrl) != MHI_STATE_M3) {\n\t\tdev_warn(dev, \"Resuming from non M3 state (%s)\\n\",\n\t\t\t mhi_state_str(mhi_get_mhi_state(mhi_cntrl)));\n\t\tif (!force)\n\t\t\treturn -EINVAL;\n\t}\n\n\t \n\tlist_for_each_entry_safe(itr, tmp, &mhi_cntrl->lpm_chans, node) {\n\t\tmutex_lock(&itr->mutex);\n\t\tif (itr->mhi_dev)\n\t\t\tmhi_notify(itr->mhi_dev, MHI_CB_LPM_EXIT);\n\t\tmutex_unlock(&itr->mutex);\n\t}\n\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tcur_state = mhi_tryset_pm_state(mhi_cntrl, MHI_PM_M3_EXIT);\n\tif (cur_state != MHI_PM_M3_EXIT) {\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\tdev_info(dev,\n\t\t\t \"Error setting to PM state: %s from: %s\\n\",\n\t\t\t to_mhi_pm_state_str(MHI_PM_M3_EXIT),\n\t\t\t to_mhi_pm_state_str(mhi_cntrl->pm_state));\n\t\treturn -EIO;\n\t}\n\n\t \n\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_M0);\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\n\tret = wait_event_timeout(mhi_cntrl->state_event,\n\t\t\t\t mhi_cntrl->dev_state == MHI_STATE_M0 ||\n\t\t\t\t mhi_cntrl->dev_state == MHI_STATE_M2 ||\n\t\t\t\t MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state),\n\t\t\t\t msecs_to_jiffies(mhi_cntrl->timeout_ms));\n\n\tif (!ret || MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state)) {\n\t\tdev_err(dev,\n\t\t\t\"Did not enter M0 state, MHI state: %s, PM state: %s\\n\",\n\t\t\tmhi_state_str(mhi_cntrl->dev_state),\n\t\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state));\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nint mhi_pm_resume(struct mhi_controller *mhi_cntrl)\n{\n\treturn __mhi_pm_resume(mhi_cntrl, false);\n}\nEXPORT_SYMBOL_GPL(mhi_pm_resume);\n\nint mhi_pm_resume_force(struct mhi_controller *mhi_cntrl)\n{\n\treturn __mhi_pm_resume(mhi_cntrl, true);\n}\nEXPORT_SYMBOL_GPL(mhi_pm_resume_force);\n\nint __mhi_device_get_sync(struct mhi_controller *mhi_cntrl)\n{\n\tint ret;\n\n\t \n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\tif (MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state)) {\n\t\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\t\treturn -EIO;\n\t}\n\tmhi_cntrl->wake_get(mhi_cntrl, true);\n\tif (MHI_PM_IN_SUSPEND_STATE(mhi_cntrl->pm_state))\n\t\tmhi_trigger_resume(mhi_cntrl);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\n\tret = wait_event_timeout(mhi_cntrl->state_event,\n\t\t\t\t mhi_cntrl->pm_state == MHI_PM_M0 ||\n\t\t\t\t MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state),\n\t\t\t\t msecs_to_jiffies(mhi_cntrl->timeout_ms));\n\n\tif (!ret || MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state)) {\n\t\tread_lock_bh(&mhi_cntrl->pm_lock);\n\t\tmhi_cntrl->wake_put(mhi_cntrl, false);\n\t\tread_unlock_bh(&mhi_cntrl->pm_lock);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic void mhi_assert_dev_wake(struct mhi_controller *mhi_cntrl, bool force)\n{\n\tunsigned long flags;\n\n\t \n\tif (unlikely(force)) {\n\t\tspin_lock_irqsave(&mhi_cntrl->wlock, flags);\n\t\tatomic_inc(&mhi_cntrl->dev_wake);\n\t\tif (MHI_WAKE_DB_FORCE_SET_VALID(mhi_cntrl->pm_state) &&\n\t\t    !mhi_cntrl->wake_set) {\n\t\t\tmhi_write_db(mhi_cntrl, mhi_cntrl->wake_db, 1);\n\t\t\tmhi_cntrl->wake_set = true;\n\t\t}\n\t\tspin_unlock_irqrestore(&mhi_cntrl->wlock, flags);\n\t} else {\n\t\t \n\t\tif (likely(atomic_add_unless(&mhi_cntrl->dev_wake, 1, 0)))\n\t\t\treturn;\n\n\t\tspin_lock_irqsave(&mhi_cntrl->wlock, flags);\n\t\tif ((atomic_inc_return(&mhi_cntrl->dev_wake) == 1) &&\n\t\t    MHI_WAKE_DB_SET_VALID(mhi_cntrl->pm_state) &&\n\t\t    !mhi_cntrl->wake_set) {\n\t\t\tmhi_write_db(mhi_cntrl, mhi_cntrl->wake_db, 1);\n\t\t\tmhi_cntrl->wake_set = true;\n\t\t}\n\t\tspin_unlock_irqrestore(&mhi_cntrl->wlock, flags);\n\t}\n}\n\n \nstatic void mhi_deassert_dev_wake(struct mhi_controller *mhi_cntrl,\n\t\t\t\t  bool override)\n{\n\tunsigned long flags;\n\n\t \n\tif (likely(atomic_add_unless(&mhi_cntrl->dev_wake, -1, 1)))\n\t\treturn;\n\n\tspin_lock_irqsave(&mhi_cntrl->wlock, flags);\n\tif ((atomic_dec_return(&mhi_cntrl->dev_wake) == 0) &&\n\t    MHI_WAKE_DB_CLEAR_VALID(mhi_cntrl->pm_state) && !override &&\n\t    mhi_cntrl->wake_set) {\n\t\tmhi_write_db(mhi_cntrl, mhi_cntrl->wake_db, 0);\n\t\tmhi_cntrl->wake_set = false;\n\t}\n\tspin_unlock_irqrestore(&mhi_cntrl->wlock, flags);\n}\n\nint mhi_async_power_up(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_event *mhi_event = mhi_cntrl->mhi_event;\n\tenum mhi_state state;\n\tenum mhi_ee_type current_ee;\n\tenum dev_st_transition next_state;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tu32 interval_us = 25000;  \n\tint ret, i;\n\n\tdev_info(dev, \"Requested to power ON\\n\");\n\n\t \n\tif (!mhi_cntrl->wake_get || !mhi_cntrl->wake_put ||\n\t    !mhi_cntrl->wake_toggle) {\n\t\tmhi_cntrl->wake_get = mhi_assert_dev_wake;\n\t\tmhi_cntrl->wake_put = mhi_deassert_dev_wake;\n\t\tmhi_cntrl->wake_toggle = (mhi_cntrl->db_access & MHI_PM_M2) ?\n\t\t\tmhi_toggle_dev_wake_nop : mhi_toggle_dev_wake;\n\t}\n\n\tmutex_lock(&mhi_cntrl->pm_mutex);\n\tmhi_cntrl->pm_state = MHI_PM_DISABLE;\n\n\t \n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tmhi_write_reg(mhi_cntrl, mhi_cntrl->bhi, BHI_INTVEC, 0);\n\tmhi_cntrl->pm_state = MHI_PM_POR;\n\tmhi_cntrl->ee = MHI_EE_MAX;\n\tcurrent_ee = mhi_get_exec_env(mhi_cntrl);\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\n\t \n\tif (!MHI_POWER_UP_CAPABLE(current_ee)) {\n\t\tdev_err(dev, \"%s is not a valid EE for power on\\n\",\n\t\t\tTO_MHI_EXEC_STR(current_ee));\n\t\tret = -EIO;\n\t\tgoto error_exit;\n\t}\n\n\tstate = mhi_get_mhi_state(mhi_cntrl);\n\tdev_dbg(dev, \"Attempting power on with EE: %s, state: %s\\n\",\n\t\tTO_MHI_EXEC_STR(current_ee), mhi_state_str(state));\n\n\tif (state == MHI_STATE_SYS_ERR) {\n\t\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_RESET);\n\t\tret = mhi_poll_reg_field(mhi_cntrl, mhi_cntrl->regs, MHICTRL,\n\t\t\t\t MHICTRL_RESET_MASK, 0, interval_us);\n\t\tif (ret) {\n\t\t\tdev_info(dev, \"Failed to reset MHI due to syserr state\\n\");\n\t\t\tgoto error_exit;\n\t\t}\n\n\t\t \n\t\tmhi_write_reg(mhi_cntrl, mhi_cntrl->bhi, BHI_INTVEC, 0);\n\t}\n\n\t \n\tenable_irq(mhi_cntrl->irq[0]);\n\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tenable_irq(mhi_cntrl->irq[mhi_event->irq]);\n\t}\n\n\t \n\tnext_state = MHI_IN_PBL(current_ee) ?\n\t\tDEV_ST_TRANSITION_PBL : DEV_ST_TRANSITION_READY;\n\n\tmhi_queue_state_transition(mhi_cntrl, next_state);\n\n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\n\tdev_info(dev, \"Power on setup success\\n\");\n\n\treturn 0;\n\nerror_exit:\n\tmhi_cntrl->pm_state = MHI_PM_DISABLE;\n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mhi_async_power_up);\n\nvoid mhi_power_down(struct mhi_controller *mhi_cntrl, bool graceful)\n{\n\tenum mhi_pm_state cur_state, transition_state;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\n\tmutex_lock(&mhi_cntrl->pm_mutex);\n\twrite_lock_irq(&mhi_cntrl->pm_lock);\n\tcur_state = mhi_cntrl->pm_state;\n\tif (cur_state == MHI_PM_DISABLE) {\n\t\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\t\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\t\treturn;  \n\t}\n\n\t \n\ttransition_state = (graceful) ? MHI_PM_SHUTDOWN_PROCESS :\n\t\t\t   MHI_PM_LD_ERR_FATAL_DETECT;\n\n\tcur_state = mhi_tryset_pm_state(mhi_cntrl, transition_state);\n\tif (cur_state != transition_state) {\n\t\tdev_err(dev, \"Failed to move to state: %s from: %s\\n\",\n\t\t\tto_mhi_pm_state_str(transition_state),\n\t\t\tto_mhi_pm_state_str(mhi_cntrl->pm_state));\n\t\t \n\t\tmhi_cntrl->pm_state = MHI_PM_LD_ERR_FATAL_DETECT;\n\t}\n\n\t \n\tmhi_cntrl->ee = MHI_EE_DISABLE_TRANSITION;\n\tmhi_cntrl->dev_state = MHI_STATE_RESET;\n\n\twake_up_all(&mhi_cntrl->state_event);\n\n\twrite_unlock_irq(&mhi_cntrl->pm_lock);\n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\n\tmhi_queue_state_transition(mhi_cntrl, DEV_ST_TRANSITION_DISABLE);\n\n\t \n\tflush_work(&mhi_cntrl->st_worker);\n\n\tdisable_irq(mhi_cntrl->irq[0]);\n}\nEXPORT_SYMBOL_GPL(mhi_power_down);\n\nint mhi_sync_power_up(struct mhi_controller *mhi_cntrl)\n{\n\tint ret = mhi_async_power_up(mhi_cntrl);\n\n\tif (ret)\n\t\treturn ret;\n\n\twait_event_timeout(mhi_cntrl->state_event,\n\t\t\t   MHI_IN_MISSION_MODE(mhi_cntrl->ee) ||\n\t\t\t   MHI_PM_IN_ERROR_STATE(mhi_cntrl->pm_state),\n\t\t\t   msecs_to_jiffies(mhi_cntrl->timeout_ms));\n\n\tret = (MHI_IN_MISSION_MODE(mhi_cntrl->ee)) ? 0 : -ETIMEDOUT;\n\tif (ret)\n\t\tmhi_power_down(mhi_cntrl, false);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(mhi_sync_power_up);\n\nint mhi_force_rddm_mode(struct mhi_controller *mhi_cntrl)\n{\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tint ret;\n\n\t \n\tif (mhi_cntrl->ee == MHI_EE_RDDM)\n\t\treturn 0;\n\n\tdev_dbg(dev, \"Triggering SYS_ERR to force RDDM state\\n\");\n\tmhi_set_mhi_state(mhi_cntrl, MHI_STATE_SYS_ERR);\n\n\t \n\tret = wait_event_timeout(mhi_cntrl->state_event,\n\t\t\t\t mhi_cntrl->ee == MHI_EE_RDDM,\n\t\t\t\t msecs_to_jiffies(mhi_cntrl->timeout_ms));\n\tret = ret ? 0 : -EIO;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mhi_force_rddm_mode);\n\nvoid mhi_device_get(struct mhi_device *mhi_dev)\n{\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\n\tmhi_dev->dev_wake++;\n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\tif (MHI_PM_IN_SUSPEND_STATE(mhi_cntrl->pm_state))\n\t\tmhi_trigger_resume(mhi_cntrl);\n\n\tmhi_cntrl->wake_get(mhi_cntrl, true);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n}\nEXPORT_SYMBOL_GPL(mhi_device_get);\n\nint mhi_device_get_sync(struct mhi_device *mhi_dev)\n{\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\tint ret;\n\n\tret = __mhi_device_get_sync(mhi_cntrl);\n\tif (!ret)\n\t\tmhi_dev->dev_wake++;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mhi_device_get_sync);\n\nvoid mhi_device_put(struct mhi_device *mhi_dev)\n{\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\n\tmhi_dev->dev_wake--;\n\tread_lock_bh(&mhi_cntrl->pm_lock);\n\tif (MHI_PM_IN_SUSPEND_STATE(mhi_cntrl->pm_state))\n\t\tmhi_trigger_resume(mhi_cntrl);\n\n\tmhi_cntrl->wake_put(mhi_cntrl, false);\n\tread_unlock_bh(&mhi_cntrl->pm_lock);\n}\nEXPORT_SYMBOL_GPL(mhi_device_put);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}