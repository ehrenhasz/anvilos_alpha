{
  "module_name": "init.c",
  "hash_id": "f25cd20488196b6b6fb2939bf4f5bd600e714c657aa4cca4354189fb5fc83312",
  "original_prompt": "Ingested from linux-6.6.14/drivers/bus/mhi/host/init.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/debugfs.h>\n#include <linux/device.h>\n#include <linux/dma-direction.h>\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/interrupt.h>\n#include <linux/list.h>\n#include <linux/mhi.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/wait.h>\n#include \"internal.h\"\n\nstatic DEFINE_IDA(mhi_controller_ida);\n\nconst char * const mhi_ee_str[MHI_EE_MAX] = {\n\t[MHI_EE_PBL] = \"PRIMARY BOOTLOADER\",\n\t[MHI_EE_SBL] = \"SECONDARY BOOTLOADER\",\n\t[MHI_EE_AMSS] = \"MISSION MODE\",\n\t[MHI_EE_RDDM] = \"RAMDUMP DOWNLOAD MODE\",\n\t[MHI_EE_WFW] = \"WLAN FIRMWARE\",\n\t[MHI_EE_PTHRU] = \"PASS THROUGH\",\n\t[MHI_EE_EDL] = \"EMERGENCY DOWNLOAD\",\n\t[MHI_EE_FP] = \"FLASH PROGRAMMER\",\n\t[MHI_EE_DISABLE_TRANSITION] = \"DISABLE\",\n\t[MHI_EE_NOT_SUPPORTED] = \"NOT SUPPORTED\",\n};\n\nconst char * const dev_state_tran_str[DEV_ST_TRANSITION_MAX] = {\n\t[DEV_ST_TRANSITION_PBL] = \"PBL\",\n\t[DEV_ST_TRANSITION_READY] = \"READY\",\n\t[DEV_ST_TRANSITION_SBL] = \"SBL\",\n\t[DEV_ST_TRANSITION_MISSION_MODE] = \"MISSION MODE\",\n\t[DEV_ST_TRANSITION_FP] = \"FLASH PROGRAMMER\",\n\t[DEV_ST_TRANSITION_SYS_ERR] = \"SYS ERROR\",\n\t[DEV_ST_TRANSITION_DISABLE] = \"DISABLE\",\n};\n\nconst char * const mhi_ch_state_type_str[MHI_CH_STATE_TYPE_MAX] = {\n\t[MHI_CH_STATE_TYPE_RESET] = \"RESET\",\n\t[MHI_CH_STATE_TYPE_STOP] = \"STOP\",\n\t[MHI_CH_STATE_TYPE_START] = \"START\",\n};\n\nstatic const char * const mhi_pm_state_str[] = {\n\t[MHI_PM_STATE_DISABLE] = \"DISABLE\",\n\t[MHI_PM_STATE_POR] = \"POWER ON RESET\",\n\t[MHI_PM_STATE_M0] = \"M0\",\n\t[MHI_PM_STATE_M2] = \"M2\",\n\t[MHI_PM_STATE_M3_ENTER] = \"M?->M3\",\n\t[MHI_PM_STATE_M3] = \"M3\",\n\t[MHI_PM_STATE_M3_EXIT] = \"M3->M0\",\n\t[MHI_PM_STATE_FW_DL_ERR] = \"Firmware Download Error\",\n\t[MHI_PM_STATE_SYS_ERR_DETECT] = \"SYS ERROR Detect\",\n\t[MHI_PM_STATE_SYS_ERR_PROCESS] = \"SYS ERROR Process\",\n\t[MHI_PM_STATE_SHUTDOWN_PROCESS] = \"SHUTDOWN Process\",\n\t[MHI_PM_STATE_LD_ERR_FATAL_DETECT] = \"Linkdown or Error Fatal Detect\",\n};\n\nconst char *to_mhi_pm_state_str(u32 state)\n{\n\tint index;\n\n\tif (state)\n\t\tindex = __fls(state);\n\n\tif (!state || index >= ARRAY_SIZE(mhi_pm_state_str))\n\t\treturn \"Invalid State\";\n\n\treturn mhi_pm_state_str[index];\n}\n\nstatic ssize_t serial_number_show(struct device *dev,\n\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t  char *buf)\n{\n\tstruct mhi_device *mhi_dev = to_mhi_device(dev);\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\n\treturn sysfs_emit(buf, \"Serial Number: %u\\n\",\n\t\t\tmhi_cntrl->serial_number);\n}\nstatic DEVICE_ATTR_RO(serial_number);\n\nstatic ssize_t oem_pk_hash_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr,\n\t\t\t\tchar *buf)\n{\n\tstruct mhi_device *mhi_dev = to_mhi_device(dev);\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\tint i, cnt = 0;\n\n\tfor (i = 0; i < ARRAY_SIZE(mhi_cntrl->oem_pk_hash); i++)\n\t\tcnt += sysfs_emit_at(buf, cnt, \"OEMPKHASH[%d]: 0x%x\\n\",\n\t\t\t\ti, mhi_cntrl->oem_pk_hash[i]);\n\n\treturn cnt;\n}\nstatic DEVICE_ATTR_RO(oem_pk_hash);\n\nstatic ssize_t soc_reset_store(struct device *dev,\n\t\t\t       struct device_attribute *attr,\n\t\t\t       const char *buf,\n\t\t\t       size_t count)\n{\n\tstruct mhi_device *mhi_dev = to_mhi_device(dev);\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\n\tmhi_soc_reset(mhi_cntrl);\n\treturn count;\n}\nstatic DEVICE_ATTR_WO(soc_reset);\n\nstatic struct attribute *mhi_dev_attrs[] = {\n\t&dev_attr_serial_number.attr,\n\t&dev_attr_oem_pk_hash.attr,\n\t&dev_attr_soc_reset.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(mhi_dev);\n\n \nstatic int mhi_alloc_aligned_ring(struct mhi_controller *mhi_cntrl,\n\t\t\t\t  struct mhi_ring *ring,\n\t\t\t\t  u64 len)\n{\n\tring->alloc_size = len + (len - 1);\n\tring->pre_aligned = dma_alloc_coherent(mhi_cntrl->cntrl_dev, ring->alloc_size,\n\t\t\t\t\t       &ring->dma_handle, GFP_KERNEL);\n\tif (!ring->pre_aligned)\n\t\treturn -ENOMEM;\n\n\tring->iommu_base = (ring->dma_handle + (len - 1)) & ~(len - 1);\n\tring->base = ring->pre_aligned + (ring->iommu_base - ring->dma_handle);\n\n\treturn 0;\n}\n\nvoid mhi_deinit_free_irq(struct mhi_controller *mhi_cntrl)\n{\n\tint i;\n\tstruct mhi_event *mhi_event = mhi_cntrl->mhi_event;\n\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tfree_irq(mhi_cntrl->irq[mhi_event->irq], mhi_event);\n\t}\n\n\tfree_irq(mhi_cntrl->irq[0], mhi_cntrl);\n}\n\nint mhi_init_irq_setup(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_event *mhi_event = mhi_cntrl->mhi_event;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tunsigned long irq_flags = IRQF_SHARED | IRQF_NO_SUSPEND;\n\tint i, ret;\n\n\t \n\tif (mhi_cntrl->irq_flags)\n\t\tirq_flags = mhi_cntrl->irq_flags;\n\n\t \n\tret = request_threaded_irq(mhi_cntrl->irq[0], mhi_intvec_handler,\n\t\t\t\t   mhi_intvec_threaded_handler,\n\t\t\t\t   irq_flags,\n\t\t\t\t   \"bhi\", mhi_cntrl);\n\tif (ret)\n\t\treturn ret;\n\t \n\tdisable_irq(mhi_cntrl->irq[0]);\n\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tif (mhi_event->irq >= mhi_cntrl->nr_irqs) {\n\t\t\tdev_err(dev, \"irq %d not available for event ring\\n\",\n\t\t\t\tmhi_event->irq);\n\t\t\tret = -EINVAL;\n\t\t\tgoto error_request;\n\t\t}\n\n\t\tret = request_irq(mhi_cntrl->irq[mhi_event->irq],\n\t\t\t\t  mhi_irq_handler,\n\t\t\t\t  irq_flags,\n\t\t\t\t  \"mhi\", mhi_event);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Error requesting irq:%d for ev:%d\\n\",\n\t\t\t\tmhi_cntrl->irq[mhi_event->irq], i);\n\t\t\tgoto error_request;\n\t\t}\n\n\t\tdisable_irq(mhi_cntrl->irq[mhi_event->irq]);\n\t}\n\n\treturn 0;\n\nerror_request:\n\tfor (--i, --mhi_event; i >= 0; i--, mhi_event--) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tfree_irq(mhi_cntrl->irq[mhi_event->irq], mhi_event);\n\t}\n\tfree_irq(mhi_cntrl->irq[0], mhi_cntrl);\n\n\treturn ret;\n}\n\nvoid mhi_deinit_dev_ctxt(struct mhi_controller *mhi_cntrl)\n{\n\tint i;\n\tstruct mhi_ctxt *mhi_ctxt = mhi_cntrl->mhi_ctxt;\n\tstruct mhi_cmd *mhi_cmd;\n\tstruct mhi_event *mhi_event;\n\tstruct mhi_ring *ring;\n\n\tmhi_cmd = mhi_cntrl->mhi_cmd;\n\tfor (i = 0; i < NR_OF_CMD_RINGS; i++, mhi_cmd++) {\n\t\tring = &mhi_cmd->ring;\n\t\tdma_free_coherent(mhi_cntrl->cntrl_dev, ring->alloc_size,\n\t\t\t\t  ring->pre_aligned, ring->dma_handle);\n\t\tring->base = NULL;\n\t\tring->iommu_base = 0;\n\t}\n\n\tdma_free_coherent(mhi_cntrl->cntrl_dev,\n\t\t\t  sizeof(*mhi_ctxt->cmd_ctxt) * NR_OF_CMD_RINGS,\n\t\t\t  mhi_ctxt->cmd_ctxt, mhi_ctxt->cmd_ctxt_addr);\n\n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tring = &mhi_event->ring;\n\t\tdma_free_coherent(mhi_cntrl->cntrl_dev, ring->alloc_size,\n\t\t\t\t  ring->pre_aligned, ring->dma_handle);\n\t\tring->base = NULL;\n\t\tring->iommu_base = 0;\n\t}\n\n\tdma_free_coherent(mhi_cntrl->cntrl_dev, sizeof(*mhi_ctxt->er_ctxt) *\n\t\t\t  mhi_cntrl->total_ev_rings, mhi_ctxt->er_ctxt,\n\t\t\t  mhi_ctxt->er_ctxt_addr);\n\n\tdma_free_coherent(mhi_cntrl->cntrl_dev, sizeof(*mhi_ctxt->chan_ctxt) *\n\t\t\t  mhi_cntrl->max_chan, mhi_ctxt->chan_ctxt,\n\t\t\t  mhi_ctxt->chan_ctxt_addr);\n\n\tkfree(mhi_ctxt);\n\tmhi_cntrl->mhi_ctxt = NULL;\n}\n\nint mhi_init_dev_ctxt(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_ctxt *mhi_ctxt;\n\tstruct mhi_chan_ctxt *chan_ctxt;\n\tstruct mhi_event_ctxt *er_ctxt;\n\tstruct mhi_cmd_ctxt *cmd_ctxt;\n\tstruct mhi_chan *mhi_chan;\n\tstruct mhi_event *mhi_event;\n\tstruct mhi_cmd *mhi_cmd;\n\tu32 tmp;\n\tint ret = -ENOMEM, i;\n\n\tatomic_set(&mhi_cntrl->dev_wake, 0);\n\tatomic_set(&mhi_cntrl->pending_pkts, 0);\n\n\tmhi_ctxt = kzalloc(sizeof(*mhi_ctxt), GFP_KERNEL);\n\tif (!mhi_ctxt)\n\t\treturn -ENOMEM;\n\n\t \n\tmhi_ctxt->chan_ctxt = dma_alloc_coherent(mhi_cntrl->cntrl_dev,\n\t\t\t\t\t\t sizeof(*mhi_ctxt->chan_ctxt) *\n\t\t\t\t\t\t mhi_cntrl->max_chan,\n\t\t\t\t\t\t &mhi_ctxt->chan_ctxt_addr,\n\t\t\t\t\t\t GFP_KERNEL);\n\tif (!mhi_ctxt->chan_ctxt)\n\t\tgoto error_alloc_chan_ctxt;\n\n\tmhi_chan = mhi_cntrl->mhi_chan;\n\tchan_ctxt = mhi_ctxt->chan_ctxt;\n\tfor (i = 0; i < mhi_cntrl->max_chan; i++, chan_ctxt++, mhi_chan++) {\n\t\t \n\t\tif (mhi_chan->offload_ch)\n\t\t\tcontinue;\n\n\t\ttmp = le32_to_cpu(chan_ctxt->chcfg);\n\t\ttmp &= ~CHAN_CTX_CHSTATE_MASK;\n\t\ttmp |= FIELD_PREP(CHAN_CTX_CHSTATE_MASK, MHI_CH_STATE_DISABLED);\n\t\ttmp &= ~CHAN_CTX_BRSTMODE_MASK;\n\t\ttmp |= FIELD_PREP(CHAN_CTX_BRSTMODE_MASK, mhi_chan->db_cfg.brstmode);\n\t\ttmp &= ~CHAN_CTX_POLLCFG_MASK;\n\t\ttmp |= FIELD_PREP(CHAN_CTX_POLLCFG_MASK, mhi_chan->db_cfg.pollcfg);\n\t\tchan_ctxt->chcfg = cpu_to_le32(tmp);\n\n\t\tchan_ctxt->chtype = cpu_to_le32(mhi_chan->type);\n\t\tchan_ctxt->erindex = cpu_to_le32(mhi_chan->er_index);\n\n\t\tmhi_chan->ch_state = MHI_CH_STATE_DISABLED;\n\t\tmhi_chan->tre_ring.db_addr = (void __iomem *)&chan_ctxt->wp;\n\t}\n\n\t \n\tmhi_ctxt->er_ctxt = dma_alloc_coherent(mhi_cntrl->cntrl_dev,\n\t\t\t\t\t       sizeof(*mhi_ctxt->er_ctxt) *\n\t\t\t\t\t       mhi_cntrl->total_ev_rings,\n\t\t\t\t\t       &mhi_ctxt->er_ctxt_addr,\n\t\t\t\t\t       GFP_KERNEL);\n\tif (!mhi_ctxt->er_ctxt)\n\t\tgoto error_alloc_er_ctxt;\n\n\ter_ctxt = mhi_ctxt->er_ctxt;\n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, er_ctxt++,\n\t\t     mhi_event++) {\n\t\tstruct mhi_ring *ring = &mhi_event->ring;\n\n\t\t \n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\ttmp = le32_to_cpu(er_ctxt->intmod);\n\t\ttmp &= ~EV_CTX_INTMODC_MASK;\n\t\ttmp &= ~EV_CTX_INTMODT_MASK;\n\t\ttmp |= FIELD_PREP(EV_CTX_INTMODT_MASK, mhi_event->intmod);\n\t\ter_ctxt->intmod = cpu_to_le32(tmp);\n\n\t\ter_ctxt->ertype = cpu_to_le32(MHI_ER_TYPE_VALID);\n\t\ter_ctxt->msivec = cpu_to_le32(mhi_event->irq);\n\t\tmhi_event->db_cfg.db_mode = true;\n\n\t\tring->el_size = sizeof(struct mhi_ring_element);\n\t\tring->len = ring->el_size * ring->elements;\n\t\tret = mhi_alloc_aligned_ring(mhi_cntrl, ring, ring->len);\n\t\tif (ret)\n\t\t\tgoto error_alloc_er;\n\n\t\t \n\t\tring->rp = ring->wp = ring->base;\n\t\ter_ctxt->rbase = cpu_to_le64(ring->iommu_base);\n\t\ter_ctxt->rp = er_ctxt->wp = er_ctxt->rbase;\n\t\ter_ctxt->rlen = cpu_to_le64(ring->len);\n\t\tring->ctxt_wp = &er_ctxt->wp;\n\t}\n\n\t \n\tret = -ENOMEM;\n\tmhi_ctxt->cmd_ctxt = dma_alloc_coherent(mhi_cntrl->cntrl_dev,\n\t\t\t\t\t\tsizeof(*mhi_ctxt->cmd_ctxt) *\n\t\t\t\t\t\tNR_OF_CMD_RINGS,\n\t\t\t\t\t\t&mhi_ctxt->cmd_ctxt_addr,\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (!mhi_ctxt->cmd_ctxt)\n\t\tgoto error_alloc_er;\n\n\tmhi_cmd = mhi_cntrl->mhi_cmd;\n\tcmd_ctxt = mhi_ctxt->cmd_ctxt;\n\tfor (i = 0; i < NR_OF_CMD_RINGS; i++, mhi_cmd++, cmd_ctxt++) {\n\t\tstruct mhi_ring *ring = &mhi_cmd->ring;\n\n\t\tring->el_size = sizeof(struct mhi_ring_element);\n\t\tring->elements = CMD_EL_PER_RING;\n\t\tring->len = ring->el_size * ring->elements;\n\t\tret = mhi_alloc_aligned_ring(mhi_cntrl, ring, ring->len);\n\t\tif (ret)\n\t\t\tgoto error_alloc_cmd;\n\n\t\tring->rp = ring->wp = ring->base;\n\t\tcmd_ctxt->rbase = cpu_to_le64(ring->iommu_base);\n\t\tcmd_ctxt->rp = cmd_ctxt->wp = cmd_ctxt->rbase;\n\t\tcmd_ctxt->rlen = cpu_to_le64(ring->len);\n\t\tring->ctxt_wp = &cmd_ctxt->wp;\n\t}\n\n\tmhi_cntrl->mhi_ctxt = mhi_ctxt;\n\n\treturn 0;\n\nerror_alloc_cmd:\n\tfor (--i, --mhi_cmd; i >= 0; i--, mhi_cmd--) {\n\t\tstruct mhi_ring *ring = &mhi_cmd->ring;\n\n\t\tdma_free_coherent(mhi_cntrl->cntrl_dev, ring->alloc_size,\n\t\t\t\t  ring->pre_aligned, ring->dma_handle);\n\t}\n\tdma_free_coherent(mhi_cntrl->cntrl_dev,\n\t\t\t  sizeof(*mhi_ctxt->cmd_ctxt) * NR_OF_CMD_RINGS,\n\t\t\t  mhi_ctxt->cmd_ctxt, mhi_ctxt->cmd_ctxt_addr);\n\ti = mhi_cntrl->total_ev_rings;\n\tmhi_event = mhi_cntrl->mhi_event + i;\n\nerror_alloc_er:\n\tfor (--i, --mhi_event; i >= 0; i--, mhi_event--) {\n\t\tstruct mhi_ring *ring = &mhi_event->ring;\n\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tdma_free_coherent(mhi_cntrl->cntrl_dev, ring->alloc_size,\n\t\t\t\t  ring->pre_aligned, ring->dma_handle);\n\t}\n\tdma_free_coherent(mhi_cntrl->cntrl_dev, sizeof(*mhi_ctxt->er_ctxt) *\n\t\t\t  mhi_cntrl->total_ev_rings, mhi_ctxt->er_ctxt,\n\t\t\t  mhi_ctxt->er_ctxt_addr);\n\nerror_alloc_er_ctxt:\n\tdma_free_coherent(mhi_cntrl->cntrl_dev, sizeof(*mhi_ctxt->chan_ctxt) *\n\t\t\t  mhi_cntrl->max_chan, mhi_ctxt->chan_ctxt,\n\t\t\t  mhi_ctxt->chan_ctxt_addr);\n\nerror_alloc_chan_ctxt:\n\tkfree(mhi_ctxt);\n\n\treturn ret;\n}\n\nint mhi_init_mmio(struct mhi_controller *mhi_cntrl)\n{\n\tu32 val;\n\tint i, ret;\n\tstruct mhi_chan *mhi_chan;\n\tstruct mhi_event *mhi_event;\n\tvoid __iomem *base = mhi_cntrl->regs;\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tstruct {\n\t\tu32 offset;\n\t\tu32 val;\n\t} reg_info[] = {\n\t\t{\n\t\t\tCCABAP_HIGHER,\n\t\t\tupper_32_bits(mhi_cntrl->mhi_ctxt->chan_ctxt_addr),\n\t\t},\n\t\t{\n\t\t\tCCABAP_LOWER,\n\t\t\tlower_32_bits(mhi_cntrl->mhi_ctxt->chan_ctxt_addr),\n\t\t},\n\t\t{\n\t\t\tECABAP_HIGHER,\n\t\t\tupper_32_bits(mhi_cntrl->mhi_ctxt->er_ctxt_addr),\n\t\t},\n\t\t{\n\t\t\tECABAP_LOWER,\n\t\t\tlower_32_bits(mhi_cntrl->mhi_ctxt->er_ctxt_addr),\n\t\t},\n\t\t{\n\t\t\tCRCBAP_HIGHER,\n\t\t\tupper_32_bits(mhi_cntrl->mhi_ctxt->cmd_ctxt_addr),\n\t\t},\n\t\t{\n\t\t\tCRCBAP_LOWER,\n\t\t\tlower_32_bits(mhi_cntrl->mhi_ctxt->cmd_ctxt_addr),\n\t\t},\n\t\t{\n\t\t\tMHICTRLBASE_HIGHER,\n\t\t\tupper_32_bits(mhi_cntrl->iova_start),\n\t\t},\n\t\t{\n\t\t\tMHICTRLBASE_LOWER,\n\t\t\tlower_32_bits(mhi_cntrl->iova_start),\n\t\t},\n\t\t{\n\t\t\tMHIDATABASE_HIGHER,\n\t\t\tupper_32_bits(mhi_cntrl->iova_start),\n\t\t},\n\t\t{\n\t\t\tMHIDATABASE_LOWER,\n\t\t\tlower_32_bits(mhi_cntrl->iova_start),\n\t\t},\n\t\t{\n\t\t\tMHICTRLLIMIT_HIGHER,\n\t\t\tupper_32_bits(mhi_cntrl->iova_stop),\n\t\t},\n\t\t{\n\t\t\tMHICTRLLIMIT_LOWER,\n\t\t\tlower_32_bits(mhi_cntrl->iova_stop),\n\t\t},\n\t\t{\n\t\t\tMHIDATALIMIT_HIGHER,\n\t\t\tupper_32_bits(mhi_cntrl->iova_stop),\n\t\t},\n\t\t{\n\t\t\tMHIDATALIMIT_LOWER,\n\t\t\tlower_32_bits(mhi_cntrl->iova_stop),\n\t\t},\n\t\t{0, 0}\n\t};\n\n\tdev_dbg(dev, \"Initializing MHI registers\\n\");\n\n\t \n\tret = mhi_read_reg(mhi_cntrl, base, CHDBOFF, &val);\n\tif (ret) {\n\t\tdev_err(dev, \"Unable to read CHDBOFF register\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (val >= mhi_cntrl->reg_len - (8 * MHI_DEV_WAKE_DB)) {\n\t\tdev_err(dev, \"CHDB offset: 0x%x is out of range: 0x%zx\\n\",\n\t\t\tval, mhi_cntrl->reg_len - (8 * MHI_DEV_WAKE_DB));\n\t\treturn -ERANGE;\n\t}\n\n\t \n\tmhi_cntrl->wake_db = base + val + (8 * MHI_DEV_WAKE_DB);\n\tmhi_cntrl->wake_set = false;\n\n\t \n\tmhi_chan = mhi_cntrl->mhi_chan;\n\tfor (i = 0; i < mhi_cntrl->max_chan; i++, val += 8, mhi_chan++)\n\t\tmhi_chan->tre_ring.db_addr = base + val;\n\n\t \n\tret = mhi_read_reg(mhi_cntrl, base, ERDBOFF, &val);\n\tif (ret) {\n\t\tdev_err(dev, \"Unable to read ERDBOFF register\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (val >= mhi_cntrl->reg_len - (8 * mhi_cntrl->total_ev_rings)) {\n\t\tdev_err(dev, \"ERDB offset: 0x%x is out of range: 0x%zx\\n\",\n\t\t\tval, mhi_cntrl->reg_len - (8 * mhi_cntrl->total_ev_rings));\n\t\treturn -ERANGE;\n\t}\n\n\t \n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, val += 8, mhi_event++) {\n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tmhi_event->ring.db_addr = base + val;\n\t}\n\n\t \n\tmhi_cntrl->mhi_cmd[PRIMARY_CMD_RING].ring.db_addr = base + CRDB_LOWER;\n\n\t \n\tfor (i = 0; reg_info[i].offset; i++)\n\t\tmhi_write_reg(mhi_cntrl, base, reg_info[i].offset,\n\t\t\t      reg_info[i].val);\n\n\tret = mhi_write_reg_field(mhi_cntrl, base, MHICFG, MHICFG_NER_MASK,\n\t\t\t\t  mhi_cntrl->total_ev_rings);\n\tif (ret) {\n\t\tdev_err(dev, \"Unable to write MHICFG register\\n\");\n\t\treturn ret;\n\t}\n\n\tret = mhi_write_reg_field(mhi_cntrl, base, MHICFG, MHICFG_NHWER_MASK,\n\t\t\t\t  mhi_cntrl->hw_ev_rings);\n\tif (ret) {\n\t\tdev_err(dev, \"Unable to write MHICFG register\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nvoid mhi_deinit_chan_ctxt(struct mhi_controller *mhi_cntrl,\n\t\t\t  struct mhi_chan *mhi_chan)\n{\n\tstruct mhi_ring *buf_ring;\n\tstruct mhi_ring *tre_ring;\n\tstruct mhi_chan_ctxt *chan_ctxt;\n\tu32 tmp;\n\n\tbuf_ring = &mhi_chan->buf_ring;\n\ttre_ring = &mhi_chan->tre_ring;\n\tchan_ctxt = &mhi_cntrl->mhi_ctxt->chan_ctxt[mhi_chan->chan];\n\n\tif (!chan_ctxt->rbase)  \n\t\treturn;\n\n\tdma_free_coherent(mhi_cntrl->cntrl_dev, tre_ring->alloc_size,\n\t\t\t  tre_ring->pre_aligned, tre_ring->dma_handle);\n\tvfree(buf_ring->base);\n\n\tbuf_ring->base = tre_ring->base = NULL;\n\ttre_ring->ctxt_wp = NULL;\n\tchan_ctxt->rbase = 0;\n\tchan_ctxt->rlen = 0;\n\tchan_ctxt->rp = 0;\n\tchan_ctxt->wp = 0;\n\n\ttmp = le32_to_cpu(chan_ctxt->chcfg);\n\ttmp &= ~CHAN_CTX_CHSTATE_MASK;\n\ttmp |= FIELD_PREP(CHAN_CTX_CHSTATE_MASK, MHI_CH_STATE_DISABLED);\n\tchan_ctxt->chcfg = cpu_to_le32(tmp);\n\n\t \n\tsmp_wmb();\n}\n\nint mhi_init_chan_ctxt(struct mhi_controller *mhi_cntrl,\n\t\t       struct mhi_chan *mhi_chan)\n{\n\tstruct mhi_ring *buf_ring;\n\tstruct mhi_ring *tre_ring;\n\tstruct mhi_chan_ctxt *chan_ctxt;\n\tu32 tmp;\n\tint ret;\n\n\tbuf_ring = &mhi_chan->buf_ring;\n\ttre_ring = &mhi_chan->tre_ring;\n\ttre_ring->el_size = sizeof(struct mhi_ring_element);\n\ttre_ring->len = tre_ring->el_size * tre_ring->elements;\n\tchan_ctxt = &mhi_cntrl->mhi_ctxt->chan_ctxt[mhi_chan->chan];\n\tret = mhi_alloc_aligned_ring(mhi_cntrl, tre_ring, tre_ring->len);\n\tif (ret)\n\t\treturn -ENOMEM;\n\n\tbuf_ring->el_size = sizeof(struct mhi_buf_info);\n\tbuf_ring->len = buf_ring->el_size * buf_ring->elements;\n\tbuf_ring->base = vzalloc(buf_ring->len);\n\n\tif (!buf_ring->base) {\n\t\tdma_free_coherent(mhi_cntrl->cntrl_dev, tre_ring->alloc_size,\n\t\t\t\t  tre_ring->pre_aligned, tre_ring->dma_handle);\n\t\treturn -ENOMEM;\n\t}\n\n\ttmp = le32_to_cpu(chan_ctxt->chcfg);\n\ttmp &= ~CHAN_CTX_CHSTATE_MASK;\n\ttmp |= FIELD_PREP(CHAN_CTX_CHSTATE_MASK, MHI_CH_STATE_ENABLED);\n\tchan_ctxt->chcfg = cpu_to_le32(tmp);\n\n\tchan_ctxt->rbase = cpu_to_le64(tre_ring->iommu_base);\n\tchan_ctxt->rp = chan_ctxt->wp = chan_ctxt->rbase;\n\tchan_ctxt->rlen = cpu_to_le64(tre_ring->len);\n\ttre_ring->ctxt_wp = &chan_ctxt->wp;\n\n\ttre_ring->rp = tre_ring->wp = tre_ring->base;\n\tbuf_ring->rp = buf_ring->wp = buf_ring->base;\n\tmhi_chan->db_cfg.db_mode = 1;\n\n\t \n\tsmp_wmb();\n\n\treturn 0;\n}\n\nstatic int parse_ev_cfg(struct mhi_controller *mhi_cntrl,\n\t\t\tconst struct mhi_controller_config *config)\n{\n\tstruct mhi_event *mhi_event;\n\tconst struct mhi_event_config *event_cfg;\n\tstruct device *dev = mhi_cntrl->cntrl_dev;\n\tint i, num;\n\n\tnum = config->num_events;\n\tmhi_cntrl->total_ev_rings = num;\n\tmhi_cntrl->mhi_event = kcalloc(num, sizeof(*mhi_cntrl->mhi_event),\n\t\t\t\t       GFP_KERNEL);\n\tif (!mhi_cntrl->mhi_event)\n\t\treturn -ENOMEM;\n\n\t \n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < num; i++) {\n\t\tevent_cfg = &config->event_cfg[i];\n\n\t\tmhi_event->er_index = i;\n\t\tmhi_event->ring.elements = event_cfg->num_elements;\n\t\tmhi_event->intmod = event_cfg->irq_moderation_ms;\n\t\tmhi_event->irq = event_cfg->irq;\n\n\t\tif (event_cfg->channel != U32_MAX) {\n\t\t\t \n\t\t\tmhi_event->chan = event_cfg->channel;\n\t\t\tif (mhi_event->chan >= mhi_cntrl->max_chan) {\n\t\t\t\tdev_err(dev,\n\t\t\t\t\t\"Event Ring channel not available\\n\");\n\t\t\t\tgoto error_ev_cfg;\n\t\t\t}\n\n\t\t\tmhi_event->mhi_chan =\n\t\t\t\t&mhi_cntrl->mhi_chan[mhi_event->chan];\n\t\t}\n\n\t\t \n\t\tmhi_event->priority = 1;\n\n\t\tmhi_event->db_cfg.brstmode = event_cfg->mode;\n\t\tif (MHI_INVALID_BRSTMODE(mhi_event->db_cfg.brstmode))\n\t\t\tgoto error_ev_cfg;\n\n\t\tif (mhi_event->db_cfg.brstmode == MHI_DB_BRST_ENABLE)\n\t\t\tmhi_event->db_cfg.process_db = mhi_db_brstmode;\n\t\telse\n\t\t\tmhi_event->db_cfg.process_db = mhi_db_brstmode_disable;\n\n\t\tmhi_event->data_type = event_cfg->data_type;\n\n\t\tswitch (mhi_event->data_type) {\n\t\tcase MHI_ER_DATA:\n\t\t\tmhi_event->process_event = mhi_process_data_event_ring;\n\t\t\tbreak;\n\t\tcase MHI_ER_CTRL:\n\t\t\tmhi_event->process_event = mhi_process_ctrl_ev_ring;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(dev, \"Event Ring type not supported\\n\");\n\t\t\tgoto error_ev_cfg;\n\t\t}\n\n\t\tmhi_event->hw_ring = event_cfg->hardware_event;\n\t\tif (mhi_event->hw_ring)\n\t\t\tmhi_cntrl->hw_ev_rings++;\n\t\telse\n\t\t\tmhi_cntrl->sw_ev_rings++;\n\n\t\tmhi_event->cl_manage = event_cfg->client_managed;\n\t\tmhi_event->offload_ev = event_cfg->offload_channel;\n\t\tmhi_event++;\n\t}\n\n\treturn 0;\n\nerror_ev_cfg:\n\n\tkfree(mhi_cntrl->mhi_event);\n\treturn -EINVAL;\n}\n\nstatic int parse_ch_cfg(struct mhi_controller *mhi_cntrl,\n\t\t\tconst struct mhi_controller_config *config)\n{\n\tconst struct mhi_channel_config *ch_cfg;\n\tstruct device *dev = mhi_cntrl->cntrl_dev;\n\tint i;\n\tu32 chan;\n\n\tmhi_cntrl->max_chan = config->max_channels;\n\n\t \n\tmhi_cntrl->mhi_chan = vcalloc(mhi_cntrl->max_chan,\n\t\t\t\t      sizeof(*mhi_cntrl->mhi_chan));\n\tif (!mhi_cntrl->mhi_chan)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&mhi_cntrl->lpm_chans);\n\n\t \n\tfor (i = 0; i < config->num_channels; i++) {\n\t\tstruct mhi_chan *mhi_chan;\n\n\t\tch_cfg = &config->ch_cfg[i];\n\n\t\tchan = ch_cfg->num;\n\t\tif (chan >= mhi_cntrl->max_chan) {\n\t\t\tdev_err(dev, \"Channel %d not available\\n\", chan);\n\t\t\tgoto error_chan_cfg;\n\t\t}\n\n\t\tmhi_chan = &mhi_cntrl->mhi_chan[chan];\n\t\tmhi_chan->name = ch_cfg->name;\n\t\tmhi_chan->chan = chan;\n\n\t\tmhi_chan->tre_ring.elements = ch_cfg->num_elements;\n\t\tif (!mhi_chan->tre_ring.elements)\n\t\t\tgoto error_chan_cfg;\n\n\t\t \n\t\tmhi_chan->buf_ring.elements = ch_cfg->local_elements;\n\t\tif (!mhi_chan->buf_ring.elements)\n\t\t\tmhi_chan->buf_ring.elements = mhi_chan->tre_ring.elements;\n\t\tmhi_chan->er_index = ch_cfg->event_ring;\n\t\tmhi_chan->dir = ch_cfg->dir;\n\n\t\t \n\t\tmhi_chan->type = ch_cfg->type;\n\t\tif (!mhi_chan->type)\n\t\t\tmhi_chan->type = (enum mhi_ch_type)mhi_chan->dir;\n\n\t\tmhi_chan->ee_mask = ch_cfg->ee_mask;\n\t\tmhi_chan->db_cfg.pollcfg = ch_cfg->pollcfg;\n\t\tmhi_chan->lpm_notify = ch_cfg->lpm_notify;\n\t\tmhi_chan->offload_ch = ch_cfg->offload_channel;\n\t\tmhi_chan->db_cfg.reset_req = ch_cfg->doorbell_mode_switch;\n\t\tmhi_chan->pre_alloc = ch_cfg->auto_queue;\n\t\tmhi_chan->wake_capable = ch_cfg->wake_capable;\n\n\t\t \n\t\tif (mhi_chan->pre_alloc && mhi_chan->dir != DMA_FROM_DEVICE) {\n\t\t\tdev_err(dev, \"Invalid channel configuration\\n\");\n\t\t\tgoto error_chan_cfg;\n\t\t}\n\n\t\t \n\t\tif ((mhi_chan->dir == DMA_BIDIRECTIONAL ||\n\t\t     mhi_chan->dir == DMA_NONE) && !mhi_chan->offload_ch) {\n\t\t\tdev_err(dev, \"Invalid channel configuration\\n\");\n\t\t\tgoto error_chan_cfg;\n\t\t}\n\n\t\tif (!mhi_chan->offload_ch) {\n\t\t\tmhi_chan->db_cfg.brstmode = ch_cfg->doorbell;\n\t\t\tif (MHI_INVALID_BRSTMODE(mhi_chan->db_cfg.brstmode)) {\n\t\t\t\tdev_err(dev, \"Invalid Door bell mode\\n\");\n\t\t\t\tgoto error_chan_cfg;\n\t\t\t}\n\t\t}\n\n\t\tif (mhi_chan->db_cfg.brstmode == MHI_DB_BRST_ENABLE)\n\t\t\tmhi_chan->db_cfg.process_db = mhi_db_brstmode;\n\t\telse\n\t\t\tmhi_chan->db_cfg.process_db = mhi_db_brstmode_disable;\n\n\t\tmhi_chan->configured = true;\n\n\t\tif (mhi_chan->lpm_notify)\n\t\t\tlist_add_tail(&mhi_chan->node, &mhi_cntrl->lpm_chans);\n\t}\n\n\treturn 0;\n\nerror_chan_cfg:\n\tvfree(mhi_cntrl->mhi_chan);\n\n\treturn -EINVAL;\n}\n\nstatic int parse_config(struct mhi_controller *mhi_cntrl,\n\t\t\tconst struct mhi_controller_config *config)\n{\n\tint ret;\n\n\t \n\tret = parse_ch_cfg(mhi_cntrl, config);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = parse_ev_cfg(mhi_cntrl, config);\n\tif (ret)\n\t\tgoto error_ev_cfg;\n\n\tmhi_cntrl->timeout_ms = config->timeout_ms;\n\tif (!mhi_cntrl->timeout_ms)\n\t\tmhi_cntrl->timeout_ms = MHI_TIMEOUT_MS;\n\n\tmhi_cntrl->bounce_buf = config->use_bounce_buf;\n\tmhi_cntrl->buffer_len = config->buf_len;\n\tif (!mhi_cntrl->buffer_len)\n\t\tmhi_cntrl->buffer_len = MHI_MAX_MTU;\n\n\t \n\tmhi_cntrl->db_access = MHI_PM_M0 | MHI_PM_M2;\n\tif (config->m2_no_db)\n\t\tmhi_cntrl->db_access &= ~MHI_PM_M2;\n\n\treturn 0;\n\nerror_ev_cfg:\n\tvfree(mhi_cntrl->mhi_chan);\n\n\treturn ret;\n}\n\nint mhi_register_controller(struct mhi_controller *mhi_cntrl,\n\t\t\t    const struct mhi_controller_config *config)\n{\n\tstruct mhi_event *mhi_event;\n\tstruct mhi_chan *mhi_chan;\n\tstruct mhi_cmd *mhi_cmd;\n\tstruct mhi_device *mhi_dev;\n\tu32 soc_info;\n\tint ret, i;\n\n\tif (!mhi_cntrl || !mhi_cntrl->cntrl_dev || !mhi_cntrl->regs ||\n\t    !mhi_cntrl->runtime_get || !mhi_cntrl->runtime_put ||\n\t    !mhi_cntrl->status_cb || !mhi_cntrl->read_reg ||\n\t    !mhi_cntrl->write_reg || !mhi_cntrl->nr_irqs ||\n\t    !mhi_cntrl->irq || !mhi_cntrl->reg_len)\n\t\treturn -EINVAL;\n\n\tret = parse_config(mhi_cntrl, config);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tmhi_cntrl->mhi_cmd = kcalloc(NR_OF_CMD_RINGS,\n\t\t\t\t     sizeof(*mhi_cntrl->mhi_cmd), GFP_KERNEL);\n\tif (!mhi_cntrl->mhi_cmd) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_event;\n\t}\n\n\tINIT_LIST_HEAD(&mhi_cntrl->transition_list);\n\tmutex_init(&mhi_cntrl->pm_mutex);\n\trwlock_init(&mhi_cntrl->pm_lock);\n\tspin_lock_init(&mhi_cntrl->transition_lock);\n\tspin_lock_init(&mhi_cntrl->wlock);\n\tINIT_WORK(&mhi_cntrl->st_worker, mhi_pm_st_worker);\n\tinit_waitqueue_head(&mhi_cntrl->state_event);\n\n\tmhi_cntrl->hiprio_wq = alloc_ordered_workqueue(\"mhi_hiprio_wq\", WQ_HIGHPRI);\n\tif (!mhi_cntrl->hiprio_wq) {\n\t\tdev_err(mhi_cntrl->cntrl_dev, \"Failed to allocate workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_free_cmd;\n\t}\n\n\tmhi_cmd = mhi_cntrl->mhi_cmd;\n\tfor (i = 0; i < NR_OF_CMD_RINGS; i++, mhi_cmd++)\n\t\tspin_lock_init(&mhi_cmd->lock);\n\n\tmhi_event = mhi_cntrl->mhi_event;\n\tfor (i = 0; i < mhi_cntrl->total_ev_rings; i++, mhi_event++) {\n\t\t \n\t\tif (mhi_event->offload_ev)\n\t\t\tcontinue;\n\n\t\tmhi_event->mhi_cntrl = mhi_cntrl;\n\t\tspin_lock_init(&mhi_event->lock);\n\t\tif (mhi_event->data_type == MHI_ER_CTRL)\n\t\t\ttasklet_init(&mhi_event->task, mhi_ctrl_ev_task,\n\t\t\t\t     (ulong)mhi_event);\n\t\telse\n\t\t\ttasklet_init(&mhi_event->task, mhi_ev_task,\n\t\t\t\t     (ulong)mhi_event);\n\t}\n\n\tmhi_chan = mhi_cntrl->mhi_chan;\n\tfor (i = 0; i < mhi_cntrl->max_chan; i++, mhi_chan++) {\n\t\tmutex_init(&mhi_chan->mutex);\n\t\tinit_completion(&mhi_chan->completion);\n\t\trwlock_init(&mhi_chan->lock);\n\n\t\t \n\t\tmhi_event = &mhi_cntrl->mhi_event[mhi_chan->er_index];\n\t\tmhi_chan->intmod = mhi_event->intmod;\n\t}\n\n\tif (mhi_cntrl->bounce_buf) {\n\t\tmhi_cntrl->map_single = mhi_map_single_use_bb;\n\t\tmhi_cntrl->unmap_single = mhi_unmap_single_use_bb;\n\t} else {\n\t\tmhi_cntrl->map_single = mhi_map_single_no_bb;\n\t\tmhi_cntrl->unmap_single = mhi_unmap_single_no_bb;\n\t}\n\n\t \n\tret = mhi_read_reg(mhi_cntrl, mhi_cntrl->regs,\n\t\t\t   SOC_HW_VERSION_OFFS, &soc_info);\n\tif (ret)\n\t\tgoto err_destroy_wq;\n\n\tmhi_cntrl->family_number = FIELD_GET(SOC_HW_VERSION_FAM_NUM_BMSK, soc_info);\n\tmhi_cntrl->device_number = FIELD_GET(SOC_HW_VERSION_DEV_NUM_BMSK, soc_info);\n\tmhi_cntrl->major_version = FIELD_GET(SOC_HW_VERSION_MAJOR_VER_BMSK, soc_info);\n\tmhi_cntrl->minor_version = FIELD_GET(SOC_HW_VERSION_MINOR_VER_BMSK, soc_info);\n\n\tmhi_cntrl->index = ida_alloc(&mhi_controller_ida, GFP_KERNEL);\n\tif (mhi_cntrl->index < 0) {\n\t\tret = mhi_cntrl->index;\n\t\tgoto err_destroy_wq;\n\t}\n\n\tret = mhi_init_irq_setup(mhi_cntrl);\n\tif (ret)\n\t\tgoto err_ida_free;\n\n\t \n\tmhi_dev = mhi_alloc_device(mhi_cntrl);\n\tif (IS_ERR(mhi_dev)) {\n\t\tdev_err(mhi_cntrl->cntrl_dev, \"Failed to allocate MHI device\\n\");\n\t\tret = PTR_ERR(mhi_dev);\n\t\tgoto error_setup_irq;\n\t}\n\n\tmhi_dev->dev_type = MHI_DEVICE_CONTROLLER;\n\tmhi_dev->mhi_cntrl = mhi_cntrl;\n\tdev_set_name(&mhi_dev->dev, \"mhi%d\", mhi_cntrl->index);\n\tmhi_dev->name = dev_name(&mhi_dev->dev);\n\n\t \n\tdevice_init_wakeup(&mhi_dev->dev, true);\n\n\tret = device_add(&mhi_dev->dev);\n\tif (ret)\n\t\tgoto err_release_dev;\n\n\tmhi_cntrl->mhi_dev = mhi_dev;\n\n\tmhi_create_debugfs(mhi_cntrl);\n\n\treturn 0;\n\nerr_release_dev:\n\tput_device(&mhi_dev->dev);\nerror_setup_irq:\n\tmhi_deinit_free_irq(mhi_cntrl);\nerr_ida_free:\n\tida_free(&mhi_controller_ida, mhi_cntrl->index);\nerr_destroy_wq:\n\tdestroy_workqueue(mhi_cntrl->hiprio_wq);\nerr_free_cmd:\n\tkfree(mhi_cntrl->mhi_cmd);\nerr_free_event:\n\tkfree(mhi_cntrl->mhi_event);\n\tvfree(mhi_cntrl->mhi_chan);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mhi_register_controller);\n\nvoid mhi_unregister_controller(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_device *mhi_dev = mhi_cntrl->mhi_dev;\n\tstruct mhi_chan *mhi_chan = mhi_cntrl->mhi_chan;\n\tunsigned int i;\n\n\tmhi_deinit_free_irq(mhi_cntrl);\n\tmhi_destroy_debugfs(mhi_cntrl);\n\n\tdestroy_workqueue(mhi_cntrl->hiprio_wq);\n\tkfree(mhi_cntrl->mhi_cmd);\n\tkfree(mhi_cntrl->mhi_event);\n\n\t \n\tfor (i = 0; i < mhi_cntrl->max_chan; i++, mhi_chan++) {\n\t\tif (!mhi_chan->mhi_dev)\n\t\t\tcontinue;\n\n\t\tput_device(&mhi_chan->mhi_dev->dev);\n\t}\n\tvfree(mhi_cntrl->mhi_chan);\n\n\tdevice_del(&mhi_dev->dev);\n\tput_device(&mhi_dev->dev);\n\n\tida_free(&mhi_controller_ida, mhi_cntrl->index);\n}\nEXPORT_SYMBOL_GPL(mhi_unregister_controller);\n\nstruct mhi_controller *mhi_alloc_controller(void)\n{\n\tstruct mhi_controller *mhi_cntrl;\n\n\tmhi_cntrl = kzalloc(sizeof(*mhi_cntrl), GFP_KERNEL);\n\n\treturn mhi_cntrl;\n}\nEXPORT_SYMBOL_GPL(mhi_alloc_controller);\n\nvoid mhi_free_controller(struct mhi_controller *mhi_cntrl)\n{\n\tkfree(mhi_cntrl);\n}\nEXPORT_SYMBOL_GPL(mhi_free_controller);\n\nint mhi_prepare_for_power_up(struct mhi_controller *mhi_cntrl)\n{\n\tstruct device *dev = &mhi_cntrl->mhi_dev->dev;\n\tu32 bhi_off, bhie_off;\n\tint ret;\n\n\tmutex_lock(&mhi_cntrl->pm_mutex);\n\n\tret = mhi_init_dev_ctxt(mhi_cntrl);\n\tif (ret)\n\t\tgoto error_dev_ctxt;\n\n\tret = mhi_read_reg(mhi_cntrl, mhi_cntrl->regs, BHIOFF, &bhi_off);\n\tif (ret) {\n\t\tdev_err(dev, \"Error getting BHI offset\\n\");\n\t\tgoto error_reg_offset;\n\t}\n\n\tif (bhi_off >= mhi_cntrl->reg_len) {\n\t\tdev_err(dev, \"BHI offset: 0x%x is out of range: 0x%zx\\n\",\n\t\t\tbhi_off, mhi_cntrl->reg_len);\n\t\tret = -ERANGE;\n\t\tgoto error_reg_offset;\n\t}\n\tmhi_cntrl->bhi = mhi_cntrl->regs + bhi_off;\n\n\tif (mhi_cntrl->fbc_download || mhi_cntrl->rddm_size) {\n\t\tret = mhi_read_reg(mhi_cntrl, mhi_cntrl->regs, BHIEOFF,\n\t\t\t\t   &bhie_off);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Error getting BHIE offset\\n\");\n\t\t\tgoto error_reg_offset;\n\t\t}\n\n\t\tif (bhie_off >= mhi_cntrl->reg_len) {\n\t\t\tdev_err(dev,\n\t\t\t\t\"BHIe offset: 0x%x is out of range: 0x%zx\\n\",\n\t\t\t\tbhie_off, mhi_cntrl->reg_len);\n\t\t\tret = -ERANGE;\n\t\t\tgoto error_reg_offset;\n\t\t}\n\t\tmhi_cntrl->bhie = mhi_cntrl->regs + bhie_off;\n\t}\n\n\tif (mhi_cntrl->rddm_size) {\n\t\t \n\t\tmemset_io(mhi_cntrl->bhie + BHIE_RXVECADDR_LOW_OFFS,\n\t\t\t  0, BHIE_RXVECSTATUS_OFFS - BHIE_RXVECADDR_LOW_OFFS +\n\t\t\t  4);\n\t\t \n\t\tmhi_alloc_bhie_table(mhi_cntrl, &mhi_cntrl->rddm_image,\n\t\t\t\t     mhi_cntrl->rddm_size);\n\t\tif (mhi_cntrl->rddm_image) {\n\t\t\tret = mhi_rddm_prepare(mhi_cntrl,\n\t\t\t\t\t       mhi_cntrl->rddm_image);\n\t\t\tif (ret) {\n\t\t\t\tmhi_free_bhie_table(mhi_cntrl,\n\t\t\t\t\t\t    mhi_cntrl->rddm_image);\n\t\t\t\tgoto error_reg_offset;\n\t\t\t}\n\t\t}\n\t}\n\n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\n\treturn 0;\n\nerror_reg_offset:\n\tmhi_deinit_dev_ctxt(mhi_cntrl);\n\nerror_dev_ctxt:\n\tmutex_unlock(&mhi_cntrl->pm_mutex);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mhi_prepare_for_power_up);\n\nvoid mhi_unprepare_after_power_down(struct mhi_controller *mhi_cntrl)\n{\n\tif (mhi_cntrl->fbc_image) {\n\t\tmhi_free_bhie_table(mhi_cntrl, mhi_cntrl->fbc_image);\n\t\tmhi_cntrl->fbc_image = NULL;\n\t}\n\n\tif (mhi_cntrl->rddm_image) {\n\t\tmhi_free_bhie_table(mhi_cntrl, mhi_cntrl->rddm_image);\n\t\tmhi_cntrl->rddm_image = NULL;\n\t}\n\n\tmhi_cntrl->bhi = NULL;\n\tmhi_cntrl->bhie = NULL;\n\n\tmhi_deinit_dev_ctxt(mhi_cntrl);\n}\nEXPORT_SYMBOL_GPL(mhi_unprepare_after_power_down);\n\nstatic void mhi_release_device(struct device *dev)\n{\n\tstruct mhi_device *mhi_dev = to_mhi_device(dev);\n\n\t \n\tif (mhi_dev->ul_chan)\n\t\tmhi_dev->ul_chan->mhi_dev = NULL;\n\n\tif (mhi_dev->dl_chan)\n\t\tmhi_dev->dl_chan->mhi_dev = NULL;\n\n\tkfree(mhi_dev);\n}\n\nstruct mhi_device *mhi_alloc_device(struct mhi_controller *mhi_cntrl)\n{\n\tstruct mhi_device *mhi_dev;\n\tstruct device *dev;\n\n\tmhi_dev = kzalloc(sizeof(*mhi_dev), GFP_KERNEL);\n\tif (!mhi_dev)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdev = &mhi_dev->dev;\n\tdevice_initialize(dev);\n\tdev->bus = &mhi_bus_type;\n\tdev->release = mhi_release_device;\n\n\tif (mhi_cntrl->mhi_dev) {\n\t\t \n\t\tdev->parent = &mhi_cntrl->mhi_dev->dev;\n\t} else {\n\t\t \n\t\tdev->parent = mhi_cntrl->cntrl_dev;\n\t}\n\n\tmhi_dev->mhi_cntrl = mhi_cntrl;\n\tmhi_dev->dev_wake = 0;\n\n\treturn mhi_dev;\n}\n\nstatic int mhi_driver_probe(struct device *dev)\n{\n\tstruct mhi_device *mhi_dev = to_mhi_device(dev);\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\tstruct device_driver *drv = dev->driver;\n\tstruct mhi_driver *mhi_drv = to_mhi_driver(drv);\n\tstruct mhi_event *mhi_event;\n\tstruct mhi_chan *ul_chan = mhi_dev->ul_chan;\n\tstruct mhi_chan *dl_chan = mhi_dev->dl_chan;\n\tint ret;\n\n\t \n\tret = mhi_device_get_sync(mhi_dev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = -EINVAL;\n\n\tif (ul_chan) {\n\t\t \n\t\tif (ul_chan->lpm_notify && !mhi_drv->status_cb)\n\t\t\tgoto exit_probe;\n\n\t\t \n\t\tif (!ul_chan->offload_ch && !mhi_drv->ul_xfer_cb)\n\t\t\tgoto exit_probe;\n\n\t\tul_chan->xfer_cb = mhi_drv->ul_xfer_cb;\n\t}\n\n\tret = -EINVAL;\n\tif (dl_chan) {\n\t\t \n\t\tif (dl_chan->lpm_notify && !mhi_drv->status_cb)\n\t\t\tgoto exit_probe;\n\n\t\t \n\t\tif (!dl_chan->offload_ch && !mhi_drv->dl_xfer_cb)\n\t\t\tgoto exit_probe;\n\n\t\tmhi_event = &mhi_cntrl->mhi_event[dl_chan->er_index];\n\n\t\t \n\t\tif (mhi_event->cl_manage && !mhi_drv->status_cb)\n\t\t\tgoto exit_probe;\n\n\t\tdl_chan->xfer_cb = mhi_drv->dl_xfer_cb;\n\t}\n\n\t \n\tret = mhi_drv->probe(mhi_dev, mhi_dev->id);\n\tif (ret)\n\t\tgoto exit_probe;\n\n\tmhi_device_put(mhi_dev);\n\n\treturn ret;\n\nexit_probe:\n\tmhi_unprepare_from_transfer(mhi_dev);\n\n\tmhi_device_put(mhi_dev);\n\n\treturn ret;\n}\n\nstatic int mhi_driver_remove(struct device *dev)\n{\n\tstruct mhi_device *mhi_dev = to_mhi_device(dev);\n\tstruct mhi_driver *mhi_drv = to_mhi_driver(dev->driver);\n\tstruct mhi_controller *mhi_cntrl = mhi_dev->mhi_cntrl;\n\tstruct mhi_chan *mhi_chan;\n\tenum mhi_ch_state ch_state[] = {\n\t\tMHI_CH_STATE_DISABLED,\n\t\tMHI_CH_STATE_DISABLED\n\t};\n\tint dir;\n\n\t \n\tif (mhi_dev->dev_type == MHI_DEVICE_CONTROLLER)\n\t\treturn 0;\n\n\t \n\tfor (dir = 0; dir < 2; dir++) {\n\t\tmhi_chan = dir ? mhi_dev->ul_chan : mhi_dev->dl_chan;\n\n\t\tif (!mhi_chan)\n\t\t\tcontinue;\n\n\t\t \n\t\twrite_lock_irq(&mhi_chan->lock);\n\t\tmhi_chan->ccs = MHI_EV_CC_INVALID;\n\t\tcomplete_all(&mhi_chan->completion);\n\t\twrite_unlock_irq(&mhi_chan->lock);\n\n\t\t \n\t\tmutex_lock(&mhi_chan->mutex);\n\t\twrite_lock_irq(&mhi_chan->lock);\n\t\tch_state[dir] = mhi_chan->ch_state;\n\t\tmhi_chan->ch_state = MHI_CH_STATE_SUSPENDED;\n\t\twrite_unlock_irq(&mhi_chan->lock);\n\n\t\t \n\t\tif (!mhi_chan->offload_ch)\n\t\t\tmhi_reset_chan(mhi_cntrl, mhi_chan);\n\n\t\tmutex_unlock(&mhi_chan->mutex);\n\t}\n\n\tmhi_drv->remove(mhi_dev);\n\n\t \n\tfor (dir = 0; dir < 2; dir++) {\n\t\tmhi_chan = dir ? mhi_dev->ul_chan : mhi_dev->dl_chan;\n\n\t\tif (!mhi_chan)\n\t\t\tcontinue;\n\n\t\tmutex_lock(&mhi_chan->mutex);\n\n\t\tif ((ch_state[dir] == MHI_CH_STATE_ENABLED ||\n\t\t     ch_state[dir] == MHI_CH_STATE_STOP) &&\n\t\t    !mhi_chan->offload_ch)\n\t\t\tmhi_deinit_chan_ctxt(mhi_cntrl, mhi_chan);\n\n\t\tmhi_chan->ch_state = MHI_CH_STATE_DISABLED;\n\n\t\tmutex_unlock(&mhi_chan->mutex);\n\t}\n\n\twhile (mhi_dev->dev_wake)\n\t\tmhi_device_put(mhi_dev);\n\n\treturn 0;\n}\n\nint __mhi_driver_register(struct mhi_driver *mhi_drv, struct module *owner)\n{\n\tstruct device_driver *driver = &mhi_drv->driver;\n\n\tif (!mhi_drv->probe || !mhi_drv->remove)\n\t\treturn -EINVAL;\n\n\tdriver->bus = &mhi_bus_type;\n\tdriver->owner = owner;\n\tdriver->probe = mhi_driver_probe;\n\tdriver->remove = mhi_driver_remove;\n\n\treturn driver_register(driver);\n}\nEXPORT_SYMBOL_GPL(__mhi_driver_register);\n\nvoid mhi_driver_unregister(struct mhi_driver *mhi_drv)\n{\n\tdriver_unregister(&mhi_drv->driver);\n}\nEXPORT_SYMBOL_GPL(mhi_driver_unregister);\n\nstatic int mhi_uevent(const struct device *dev, struct kobj_uevent_env *env)\n{\n\tconst struct mhi_device *mhi_dev = to_mhi_device(dev);\n\n\treturn add_uevent_var(env, \"MODALIAS=\" MHI_DEVICE_MODALIAS_FMT,\n\t\t\t\t\tmhi_dev->name);\n}\n\nstatic int mhi_match(struct device *dev, struct device_driver *drv)\n{\n\tstruct mhi_device *mhi_dev = to_mhi_device(dev);\n\tstruct mhi_driver *mhi_drv = to_mhi_driver(drv);\n\tconst struct mhi_device_id *id;\n\n\t \n\tif (mhi_dev->dev_type == MHI_DEVICE_CONTROLLER)\n\t\treturn 0;\n\n\tfor (id = mhi_drv->id_table; id->chan[0]; id++)\n\t\tif (!strcmp(mhi_dev->name, id->chan)) {\n\t\t\tmhi_dev->id = id;\n\t\t\treturn 1;\n\t\t}\n\n\treturn 0;\n};\n\nstruct bus_type mhi_bus_type = {\n\t.name = \"mhi\",\n\t.dev_name = \"mhi\",\n\t.match = mhi_match,\n\t.uevent = mhi_uevent,\n\t.dev_groups = mhi_dev_groups,\n};\n\nstatic int __init mhi_init(void)\n{\n\tmhi_debugfs_init();\n\treturn bus_register(&mhi_bus_type);\n}\n\nstatic void __exit mhi_exit(void)\n{\n\tmhi_debugfs_exit();\n\tbus_unregister(&mhi_bus_type);\n}\n\npostcore_initcall(mhi_init);\nmodule_exit(mhi_exit);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"Modem Host Interface\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}