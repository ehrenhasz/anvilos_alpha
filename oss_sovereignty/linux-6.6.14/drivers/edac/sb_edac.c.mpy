{
  "module_name": "sb_edac.c",
  "hash_id": "6eefe1130ca817e5a44ba9bd4b9d38dd85b749d7c08e658f44579d21db0cf144",
  "original_prompt": "Ingested from linux-6.6.14/drivers/edac/sb_edac.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/pci.h>\n#include <linux/pci_ids.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/edac.h>\n#include <linux/mmzone.h>\n#include <linux/smp.h>\n#include <linux/bitmap.h>\n#include <linux/math64.h>\n#include <linux/mod_devicetable.h>\n#include <asm/cpu_device_id.h>\n#include <asm/intel-family.h>\n#include <asm/processor.h>\n#include <asm/mce.h>\n\n#include \"edac_module.h\"\n\n \nstatic LIST_HEAD(sbridge_edac_list);\n\n \n#define SBRIDGE_REVISION    \" Ver: 1.1.2 \"\n#define EDAC_MOD_STR\t    \"sb_edac\"\n\n \n#define sbridge_printk(level, fmt, arg...)\t\t\t\\\n\tedac_printk(level, \"sbridge\", fmt, ##arg)\n\n#define sbridge_mc_printk(mci, level, fmt, arg...)\t\t\\\n\tedac_mc_chipset_printk(mci, level, \"sbridge\", fmt, ##arg)\n\n \n#define GET_BITFIELD(v, lo, hi)\t\\\n\t(((v) & GENMASK_ULL(hi, lo)) >> (lo))\n\n \nstatic const u32 sbridge_dram_rule[] = {\n\t0x80, 0x88, 0x90, 0x98, 0xa0,\n\t0xa8, 0xb0, 0xb8, 0xc0, 0xc8,\n};\n\nstatic const u32 ibridge_dram_rule[] = {\n\t0x60, 0x68, 0x70, 0x78, 0x80,\n\t0x88, 0x90, 0x98, 0xa0,\t0xa8,\n\t0xb0, 0xb8, 0xc0, 0xc8, 0xd0,\n\t0xd8, 0xe0, 0xe8, 0xf0, 0xf8,\n};\n\nstatic const u32 knl_dram_rule[] = {\n\t0x60, 0x68, 0x70, 0x78, 0x80,  \n\t0x88, 0x90, 0x98, 0xa0, 0xa8,  \n\t0xb0, 0xb8, 0xc0, 0xc8, 0xd0,  \n\t0xd8, 0xe0, 0xe8, 0xf0, 0xf8,  \n\t0x100, 0x108, 0x110, 0x118,    \n};\n\n#define DRAM_RULE_ENABLE(reg)\tGET_BITFIELD(reg, 0,  0)\n#define A7MODE(reg)\t\tGET_BITFIELD(reg, 26, 26)\n\nstatic char *show_dram_attr(u32 attr)\n{\n\tswitch (attr) {\n\t\tcase 0:\n\t\t\treturn \"DRAM\";\n\t\tcase 1:\n\t\t\treturn \"MMCFG\";\n\t\tcase 2:\n\t\t\treturn \"NXM\";\n\t\tdefault:\n\t\t\treturn \"unknown\";\n\t}\n}\n\nstatic const u32 sbridge_interleave_list[] = {\n\t0x84, 0x8c, 0x94, 0x9c, 0xa4,\n\t0xac, 0xb4, 0xbc, 0xc4, 0xcc,\n};\n\nstatic const u32 ibridge_interleave_list[] = {\n\t0x64, 0x6c, 0x74, 0x7c, 0x84,\n\t0x8c, 0x94, 0x9c, 0xa4, 0xac,\n\t0xb4, 0xbc, 0xc4, 0xcc, 0xd4,\n\t0xdc, 0xe4, 0xec, 0xf4, 0xfc,\n};\n\nstatic const u32 knl_interleave_list[] = {\n\t0x64, 0x6c, 0x74, 0x7c, 0x84,  \n\t0x8c, 0x94, 0x9c, 0xa4, 0xac,  \n\t0xb4, 0xbc, 0xc4, 0xcc, 0xd4,  \n\t0xdc, 0xe4, 0xec, 0xf4, 0xfc,  \n\t0x104, 0x10c, 0x114, 0x11c,    \n};\n#define MAX_INTERLEAVE\t\t\t\t\t\t\t\\\n\t(max_t(unsigned int, ARRAY_SIZE(sbridge_interleave_list),\t\\\n\t       max_t(unsigned int, ARRAY_SIZE(ibridge_interleave_list),\t\\\n\t\t     ARRAY_SIZE(knl_interleave_list))))\n\nstruct interleave_pkg {\n\tunsigned char start;\n\tunsigned char end;\n};\n\nstatic const struct interleave_pkg sbridge_interleave_pkg[] = {\n\t{ 0, 2 },\n\t{ 3, 5 },\n\t{ 8, 10 },\n\t{ 11, 13 },\n\t{ 16, 18 },\n\t{ 19, 21 },\n\t{ 24, 26 },\n\t{ 27, 29 },\n};\n\nstatic const struct interleave_pkg ibridge_interleave_pkg[] = {\n\t{ 0, 3 },\n\t{ 4, 7 },\n\t{ 8, 11 },\n\t{ 12, 15 },\n\t{ 16, 19 },\n\t{ 20, 23 },\n\t{ 24, 27 },\n\t{ 28, 31 },\n};\n\nstatic inline int sad_pkg(const struct interleave_pkg *table, u32 reg,\n\t\t\t  int interleave)\n{\n\treturn GET_BITFIELD(reg, table[interleave].start,\n\t\t\t    table[interleave].end);\n}\n\n \n\n#define TOLM\t\t0x80\n#define TOHM\t\t0x84\n#define HASWELL_TOLM\t0xd0\n#define HASWELL_TOHM_0\t0xd4\n#define HASWELL_TOHM_1\t0xd8\n#define KNL_TOLM\t0xd0\n#define KNL_TOHM_0\t0xd4\n#define KNL_TOHM_1\t0xd8\n\n#define GET_TOLM(reg)\t\t((GET_BITFIELD(reg, 0,  3) << 28) | 0x3ffffff)\n#define GET_TOHM(reg)\t\t((GET_BITFIELD(reg, 0, 20) << 25) | 0x3ffffff)\n\n \n\n#define SAD_TARGET\t0xf0\n\n#define SOURCE_ID(reg)\t\tGET_BITFIELD(reg, 9, 11)\n\n#define SOURCE_ID_KNL(reg)\tGET_BITFIELD(reg, 12, 14)\n\n#define SAD_CONTROL\t0xf4\n\n \n\nstatic const u32 tad_dram_rule[] = {\n\t0x40, 0x44, 0x48, 0x4c,\n\t0x50, 0x54, 0x58, 0x5c,\n\t0x60, 0x64, 0x68, 0x6c,\n};\n#define MAX_TAD\tARRAY_SIZE(tad_dram_rule)\n\n#define TAD_LIMIT(reg)\t\t((GET_BITFIELD(reg, 12, 31) << 26) | 0x3ffffff)\n#define TAD_SOCK(reg)\t\tGET_BITFIELD(reg, 10, 11)\n#define TAD_CH(reg)\t\tGET_BITFIELD(reg,  8,  9)\n#define TAD_TGT3(reg)\t\tGET_BITFIELD(reg,  6,  7)\n#define TAD_TGT2(reg)\t\tGET_BITFIELD(reg,  4,  5)\n#define TAD_TGT1(reg)\t\tGET_BITFIELD(reg,  2,  3)\n#define TAD_TGT0(reg)\t\tGET_BITFIELD(reg,  0,  1)\n\n \n\n#define MCMTR\t\t\t0x7c\n#define KNL_MCMTR\t\t0x624\n\n#define IS_ECC_ENABLED(mcmtr)\t\tGET_BITFIELD(mcmtr, 2, 2)\n#define IS_LOCKSTEP_ENABLED(mcmtr)\tGET_BITFIELD(mcmtr, 1, 1)\n#define IS_CLOSE_PG(mcmtr)\t\tGET_BITFIELD(mcmtr, 0, 0)\n\n \n\n#define RASENABLES\t\t0xac\n#define IS_MIRROR_ENABLED(reg)\t\tGET_BITFIELD(reg, 0, 0)\n\n \n\nstatic const int mtr_regs[] = {\n\t0x80, 0x84, 0x88,\n};\n\nstatic const int knl_mtr_reg = 0xb60;\n\n#define RANK_DISABLE(mtr)\t\tGET_BITFIELD(mtr, 16, 19)\n#define IS_DIMM_PRESENT(mtr)\t\tGET_BITFIELD(mtr, 14, 14)\n#define RANK_CNT_BITS(mtr)\t\tGET_BITFIELD(mtr, 12, 13)\n#define RANK_WIDTH_BITS(mtr)\t\tGET_BITFIELD(mtr, 2, 4)\n#define COL_WIDTH_BITS(mtr)\t\tGET_BITFIELD(mtr, 0, 1)\n\nstatic const u32 tad_ch_nilv_offset[] = {\n\t0x90, 0x94, 0x98, 0x9c,\n\t0xa0, 0xa4, 0xa8, 0xac,\n\t0xb0, 0xb4, 0xb8, 0xbc,\n};\n#define CHN_IDX_OFFSET(reg)\t\tGET_BITFIELD(reg, 28, 29)\n#define TAD_OFFSET(reg)\t\t\t(GET_BITFIELD(reg,  6, 25) << 26)\n\nstatic const u32 rir_way_limit[] = {\n\t0x108, 0x10c, 0x110, 0x114, 0x118,\n};\n#define MAX_RIR_RANGES ARRAY_SIZE(rir_way_limit)\n\n#define IS_RIR_VALID(reg)\tGET_BITFIELD(reg, 31, 31)\n#define RIR_WAY(reg)\t\tGET_BITFIELD(reg, 28, 29)\n\n#define MAX_RIR_WAY\t8\n\nstatic const u32 rir_offset[MAX_RIR_RANGES][MAX_RIR_WAY] = {\n\t{ 0x120, 0x124, 0x128, 0x12c, 0x130, 0x134, 0x138, 0x13c },\n\t{ 0x140, 0x144, 0x148, 0x14c, 0x150, 0x154, 0x158, 0x15c },\n\t{ 0x160, 0x164, 0x168, 0x16c, 0x170, 0x174, 0x178, 0x17c },\n\t{ 0x180, 0x184, 0x188, 0x18c, 0x190, 0x194, 0x198, 0x19c },\n\t{ 0x1a0, 0x1a4, 0x1a8, 0x1ac, 0x1b0, 0x1b4, 0x1b8, 0x1bc },\n};\n\n#define RIR_RNK_TGT(type, reg) (((type) == BROADWELL) ? \\\n\tGET_BITFIELD(reg, 20, 23) : GET_BITFIELD(reg, 16, 19))\n\n#define RIR_OFFSET(type, reg) (((type) == HASWELL || (type) == BROADWELL) ? \\\n\tGET_BITFIELD(reg,  2, 15) : GET_BITFIELD(reg,  2, 14))\n\n \n\n \n\n#define RANK_ODD_OV(reg)\t\tGET_BITFIELD(reg, 31, 31)\n#define RANK_ODD_ERR_CNT(reg)\t\tGET_BITFIELD(reg, 16, 30)\n#define RANK_EVEN_OV(reg)\t\tGET_BITFIELD(reg, 15, 15)\n#define RANK_EVEN_ERR_CNT(reg)\t\tGET_BITFIELD(reg,  0, 14)\n\n#if 0  \nstatic const u32 correrrcnt[] = {\n\t0x104, 0x108, 0x10c, 0x110,\n};\n\nstatic const u32 correrrthrsld[] = {\n\t0x11c, 0x120, 0x124, 0x128,\n};\n#endif\n\n#define RANK_ODD_ERR_THRSLD(reg)\tGET_BITFIELD(reg, 16, 30)\n#define RANK_EVEN_ERR_THRSLD(reg)\tGET_BITFIELD(reg,  0, 14)\n\n\n \n\n#define SB_RANK_CFG_A\t\t0x0328\n\n#define IB_RANK_CFG_A\t\t0x0320\n\n \n\n#define NUM_CHANNELS\t\t6\t \n#define MAX_DIMMS\t\t3\t \n#define KNL_MAX_CHAS\t\t38\t \n#define KNL_MAX_CHANNELS\t6\t \n#define KNL_MAX_EDCS\t\t8\t \n#define CHANNEL_UNSPECIFIED\t0xf\t \n\nenum type {\n\tSANDY_BRIDGE,\n\tIVY_BRIDGE,\n\tHASWELL,\n\tBROADWELL,\n\tKNIGHTS_LANDING,\n};\n\nenum domain {\n\tIMC0 = 0,\n\tIMC1,\n\tSOCK,\n};\n\nenum mirroring_mode {\n\tNON_MIRRORING,\n\tADDR_RANGE_MIRRORING,\n\tFULL_MIRRORING,\n};\n\nstruct sbridge_pvt;\nstruct sbridge_info {\n\tenum type\ttype;\n\tu32\t\tmcmtr;\n\tu32\t\trankcfgr;\n\tu64\t\t(*get_tolm)(struct sbridge_pvt *pvt);\n\tu64\t\t(*get_tohm)(struct sbridge_pvt *pvt);\n\tu64\t\t(*rir_limit)(u32 reg);\n\tu64\t\t(*sad_limit)(u32 reg);\n\tu32\t\t(*interleave_mode)(u32 reg);\n\tu32\t\t(*dram_attr)(u32 reg);\n\tconst u32\t*dram_rule;\n\tconst u32\t*interleave_list;\n\tconst struct interleave_pkg *interleave_pkg;\n\tu8\t\tmax_sad;\n\tu8\t\t(*get_node_id)(struct sbridge_pvt *pvt);\n\tu8\t\t(*get_ha)(u8 bank);\n\tenum mem_type\t(*get_memory_type)(struct sbridge_pvt *pvt);\n\tenum dev_type\t(*get_width)(struct sbridge_pvt *pvt, u32 mtr);\n\tstruct pci_dev\t*pci_vtd;\n};\n\nstruct sbridge_channel {\n\tu32\t\tranks;\n\tu32\t\tdimms;\n\tstruct dimm {\n\t\tu32 rowbits;\n\t\tu32 colbits;\n\t\tu32 bank_xor_enable;\n\t\tu32 amap_fine;\n\t} dimm[MAX_DIMMS];\n};\n\nstruct pci_id_descr {\n\tint\t\t\tdev_id;\n\tint\t\t\toptional;\n\tenum domain\t\tdom;\n};\n\nstruct pci_id_table {\n\tconst struct pci_id_descr\t*descr;\n\tint\t\t\t\tn_devs_per_imc;\n\tint\t\t\t\tn_devs_per_sock;\n\tint\t\t\t\tn_imcs_per_sock;\n\tenum type\t\t\ttype;\n};\n\nstruct sbridge_dev {\n\tstruct list_head\tlist;\n\tint\t\t\tseg;\n\tu8\t\t\tbus, mc;\n\tu8\t\t\tnode_id, source_id;\n\tstruct pci_dev\t\t**pdev;\n\tenum domain\t\tdom;\n\tint\t\t\tn_devs;\n\tint\t\t\ti_devs;\n\tstruct mem_ctl_info\t*mci;\n};\n\nstruct knl_pvt {\n\tstruct pci_dev          *pci_cha[KNL_MAX_CHAS];\n\tstruct pci_dev          *pci_channel[KNL_MAX_CHANNELS];\n\tstruct pci_dev          *pci_mc0;\n\tstruct pci_dev          *pci_mc1;\n\tstruct pci_dev          *pci_mc0_misc;\n\tstruct pci_dev          *pci_mc1_misc;\n\tstruct pci_dev          *pci_mc_info;  \n};\n\nstruct sbridge_pvt {\n\t \n\tstruct pci_dev\t\t*pci_ddrio;\n\tstruct pci_dev\t\t*pci_sad0, *pci_sad1;\n\tstruct pci_dev\t\t*pci_br0, *pci_br1;\n\t \n\tstruct pci_dev\t\t*pci_ha, *pci_ta, *pci_ras;\n\tstruct pci_dev\t\t*pci_tad[NUM_CHANNELS];\n\n\tstruct sbridge_dev\t*sbridge_dev;\n\n\tstruct sbridge_info\tinfo;\n\tstruct sbridge_channel\tchannel[NUM_CHANNELS];\n\n\t \n\tbool\t\t\tis_cur_addr_mirrored, is_lockstep, is_close_pg;\n\tbool\t\t\tis_chan_hash;\n\tenum mirroring_mode\tmirror_mode;\n\n\t \n\tu64\t\t\ttolm, tohm;\n\tstruct knl_pvt knl;\n};\n\n#define PCI_DESCR(device_id, opt, domain)\t\\\n\t.dev_id = (device_id),\t\t\\\n\t.optional = opt,\t\\\n\t.dom = domain\n\nstatic const struct pci_id_descr pci_dev_descr_sbridge[] = {\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_HA0,   0, IMC0) },\n\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TA,    0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_RAS,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD0,  0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD1,  0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD2,  0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD3,  0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_DDRIO, 1, SOCK) },\n\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_SAD0,      0, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_SAD1,      0, SOCK) },\n\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_SBRIDGE_BR,        0, SOCK) },\n};\n\n#define PCI_ID_TABLE_ENTRY(A, N, M, T) {\t\\\n\t.descr = A,\t\t\t\\\n\t.n_devs_per_imc = N,\t\\\n\t.n_devs_per_sock = ARRAY_SIZE(A),\t\\\n\t.n_imcs_per_sock = M,\t\\\n\t.type = T\t\t\t\\\n}\n\nstatic const struct pci_id_table pci_dev_descr_sbridge_table[] = {\n\tPCI_ID_TABLE_ENTRY(pci_dev_descr_sbridge, ARRAY_SIZE(pci_dev_descr_sbridge), 1, SANDY_BRIDGE),\n\t{0,}\t\t\t \n};\n\n \n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_1HA_DDRIO0\t0x0eb8\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_2HA_DDRIO0\t0x0ebc\n\n \n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0\t\t0x0ea0\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TA\t\t0x0ea8\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_RAS\t\t0x0e71\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD0\t0x0eaa\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD1\t0x0eab\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD2\t0x0eac\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD3\t0x0ead\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_SAD\t\t\t0x0ec8\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_BR0\t\t\t0x0ec9\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_BR1\t\t\t0x0eca\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1\t\t0x0e60\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TA\t\t0x0e68\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_RAS\t\t0x0e79\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD0\t0x0e6a\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD1\t0x0e6b\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD2\t0x0e6c\n#define PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD3\t0x0e6d\n\nstatic const struct pci_id_descr pci_dev_descr_ibridge[] = {\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0,        0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1,        1, IMC1) },\n\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TA,     0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_RAS,    0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD0,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD1,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD2,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD3,   0, IMC0) },\n\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TA,     1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_RAS,    1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD0,   1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD1,   1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD2,   1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD3,   1, IMC1) },\n\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_1HA_DDRIO0, 1, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_2HA_DDRIO0, 1, SOCK) },\n\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_SAD,            0, SOCK) },\n\n\t\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_BR0,            1, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_IBRIDGE_BR1,            0, SOCK) },\n\n};\n\nstatic const struct pci_id_table pci_dev_descr_ibridge_table[] = {\n\tPCI_ID_TABLE_ENTRY(pci_dev_descr_ibridge, 12, 2, IVY_BRIDGE),\n\t{0,}\t\t\t \n};\n\n \n \n#define HASWELL_DDRCRCLKCONTROLS 0xa10  \n#define HASWELL_HASYSDEFEATURE2 0x84\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_VTD_MISC 0x2f28\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0\t0x2fa0\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1\t0x2f60\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TA\t0x2fa8\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TM\t0x2f71\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TA\t0x2f68\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TM\t0x2f79\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_CBO_SAD0 0x2ffc\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_CBO_SAD1 0x2ffd\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD0 0x2faa\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD1 0x2fab\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD2 0x2fac\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD3 0x2fad\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD0 0x2f6a\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD1 0x2f6b\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD2 0x2f6c\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD3 0x2f6d\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO0 0x2fbd\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO1 0x2fbf\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO2 0x2fb9\n#define PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO3 0x2fbb\nstatic const struct pci_id_descr pci_dev_descr_haswell[] = {\n\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0,      0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1,      1, IMC1) },\n\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TA,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TM,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD0, 0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD1, 0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD2, 1, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD3, 1, IMC0) },\n\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TA,   1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TM,   1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD0, 1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD1, 1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD2, 1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD3, 1, IMC1) },\n\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_CBO_SAD0, 0, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_CBO_SAD1, 0, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO0,   1, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO1,   1, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO2,   1, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO3,   1, SOCK) },\n};\n\nstatic const struct pci_id_table pci_dev_descr_haswell_table[] = {\n\tPCI_ID_TABLE_ENTRY(pci_dev_descr_haswell, 13, 2, HASWELL),\n\t{0,}\t\t\t \n};\n\n \n \n#define knl_channel_remap(mc, chan) ((mc) ? (chan) : (chan) + 3)\n\n \n#define PCI_DEVICE_ID_INTEL_KNL_IMC_MC       0x7840\n \n#define PCI_DEVICE_ID_INTEL_KNL_IMC_CHAN     0x7843\n \n#define PCI_DEVICE_ID_INTEL_KNL_IMC_TA       0x7844\n \n#define PCI_DEVICE_ID_INTEL_KNL_IMC_SAD0     0x782a\n \n#define PCI_DEVICE_ID_INTEL_KNL_IMC_SAD1     0x782b\n \n#define PCI_DEVICE_ID_INTEL_KNL_IMC_CHA      0x782c\n \n#define PCI_DEVICE_ID_INTEL_KNL_IMC_TOLHM    0x7810\n\n \n\nstatic const struct pci_id_descr pci_dev_descr_knl[] = {\n\t[0 ... 1]   = { PCI_DESCR(PCI_DEVICE_ID_INTEL_KNL_IMC_MC,    0, IMC0)},\n\t[2 ... 7]   = { PCI_DESCR(PCI_DEVICE_ID_INTEL_KNL_IMC_CHAN,  0, IMC0) },\n\t[8]\t    = { PCI_DESCR(PCI_DEVICE_ID_INTEL_KNL_IMC_TA,    0, IMC0) },\n\t[9]\t    = { PCI_DESCR(PCI_DEVICE_ID_INTEL_KNL_IMC_TOLHM, 0, IMC0) },\n\t[10]\t    = { PCI_DESCR(PCI_DEVICE_ID_INTEL_KNL_IMC_SAD0,  0, SOCK) },\n\t[11]\t    = { PCI_DESCR(PCI_DEVICE_ID_INTEL_KNL_IMC_SAD1,  0, SOCK) },\n\t[12 ... 49] = { PCI_DESCR(PCI_DEVICE_ID_INTEL_KNL_IMC_CHA,   0, SOCK) },\n};\n\nstatic const struct pci_id_table pci_dev_descr_knl_table[] = {\n\tPCI_ID_TABLE_ENTRY(pci_dev_descr_knl, ARRAY_SIZE(pci_dev_descr_knl), 1, KNIGHTS_LANDING),\n\t{0,}\n};\n\n \n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_VTD_MISC 0x6f28\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0\t0x6fa0\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1\t0x6f60\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TA\t0x6fa8\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TM\t0x6f71\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TA\t0x6f68\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TM\t0x6f79\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_CBO_SAD0 0x6ffc\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_CBO_SAD1 0x6ffd\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD0 0x6faa\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD1 0x6fab\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD2 0x6fac\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD3 0x6fad\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD0 0x6f6a\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD1 0x6f6b\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD2 0x6f6c\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD3 0x6f6d\n#define PCI_DEVICE_ID_INTEL_BROADWELL_IMC_DDRIO0 0x6faf\n\nstatic const struct pci_id_descr pci_dev_descr_broadwell[] = {\n\t \n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0,      0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1,      1, IMC1) },\n\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TA,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TM,   0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD0, 0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD1, 0, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD2, 1, IMC0) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD3, 1, IMC0) },\n\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TA,   1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TM,   1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD0, 1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD1, 1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD2, 1, IMC1) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD3, 1, IMC1) },\n\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_CBO_SAD0, 0, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_CBO_SAD1, 0, SOCK) },\n\t{ PCI_DESCR(PCI_DEVICE_ID_INTEL_BROADWELL_IMC_DDRIO0,   1, SOCK) },\n};\n\nstatic const struct pci_id_table pci_dev_descr_broadwell_table[] = {\n\tPCI_ID_TABLE_ENTRY(pci_dev_descr_broadwell, 10, 2, BROADWELL),\n\t{0,}\t\t\t \n};\n\n\n \n\nstatic inline int numrank(enum type type, u32 mtr)\n{\n\tint ranks = (1 << RANK_CNT_BITS(mtr));\n\tint max = 4;\n\n\tif (type == HASWELL || type == BROADWELL || type == KNIGHTS_LANDING)\n\t\tmax = 8;\n\n\tif (ranks > max) {\n\t\tedac_dbg(0, \"Invalid number of ranks: %d (max = %i) raw value = %x (%04x)\\n\",\n\t\t\t ranks, max, (unsigned int)RANK_CNT_BITS(mtr), mtr);\n\t\treturn -EINVAL;\n\t}\n\n\treturn ranks;\n}\n\nstatic inline int numrow(u32 mtr)\n{\n\tint rows = (RANK_WIDTH_BITS(mtr) + 12);\n\n\tif (rows < 13 || rows > 18) {\n\t\tedac_dbg(0, \"Invalid number of rows: %d (should be between 14 and 17) raw value = %x (%04x)\\n\",\n\t\t\t rows, (unsigned int)RANK_WIDTH_BITS(mtr), mtr);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 1 << rows;\n}\n\nstatic inline int numcol(u32 mtr)\n{\n\tint cols = (COL_WIDTH_BITS(mtr) + 10);\n\n\tif (cols > 12) {\n\t\tedac_dbg(0, \"Invalid number of cols: %d (max = 4) raw value = %x (%04x)\\n\",\n\t\t\t cols, (unsigned int)COL_WIDTH_BITS(mtr), mtr);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 1 << cols;\n}\n\nstatic struct sbridge_dev *get_sbridge_dev(int seg, u8 bus, enum domain dom,\n\t\t\t\t\t   int multi_bus,\n\t\t\t\t\t   struct sbridge_dev *prev)\n{\n\tstruct sbridge_dev *sbridge_dev;\n\n\t \n\tif (multi_bus) {\n\t\treturn list_first_entry_or_null(&sbridge_edac_list,\n\t\t\t\tstruct sbridge_dev, list);\n\t}\n\n\tsbridge_dev = list_entry(prev ? prev->list.next\n\t\t\t\t      : sbridge_edac_list.next, struct sbridge_dev, list);\n\n\tlist_for_each_entry_from(sbridge_dev, &sbridge_edac_list, list) {\n\t\tif ((sbridge_dev->seg == seg) && (sbridge_dev->bus == bus) &&\n\t\t\t\t(dom == SOCK || dom == sbridge_dev->dom))\n\t\t\treturn sbridge_dev;\n\t}\n\n\treturn NULL;\n}\n\nstatic struct sbridge_dev *alloc_sbridge_dev(int seg, u8 bus, enum domain dom,\n\t\t\t\t\t     const struct pci_id_table *table)\n{\n\tstruct sbridge_dev *sbridge_dev;\n\n\tsbridge_dev = kzalloc(sizeof(*sbridge_dev), GFP_KERNEL);\n\tif (!sbridge_dev)\n\t\treturn NULL;\n\n\tsbridge_dev->pdev = kcalloc(table->n_devs_per_imc,\n\t\t\t\t    sizeof(*sbridge_dev->pdev),\n\t\t\t\t    GFP_KERNEL);\n\tif (!sbridge_dev->pdev) {\n\t\tkfree(sbridge_dev);\n\t\treturn NULL;\n\t}\n\n\tsbridge_dev->seg = seg;\n\tsbridge_dev->bus = bus;\n\tsbridge_dev->dom = dom;\n\tsbridge_dev->n_devs = table->n_devs_per_imc;\n\tlist_add_tail(&sbridge_dev->list, &sbridge_edac_list);\n\n\treturn sbridge_dev;\n}\n\nstatic void free_sbridge_dev(struct sbridge_dev *sbridge_dev)\n{\n\tlist_del(&sbridge_dev->list);\n\tkfree(sbridge_dev->pdev);\n\tkfree(sbridge_dev);\n}\n\nstatic u64 sbridge_get_tolm(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\t \n\tpci_read_config_dword(pvt->pci_sad1, TOLM, &reg);\n\treturn GET_TOLM(reg);\n}\n\nstatic u64 sbridge_get_tohm(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->pci_sad1, TOHM, &reg);\n\treturn GET_TOHM(reg);\n}\n\nstatic u64 ibridge_get_tolm(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->pci_br1, TOLM, &reg);\n\n\treturn GET_TOLM(reg);\n}\n\nstatic u64 ibridge_get_tohm(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->pci_br1, TOHM, &reg);\n\n\treturn GET_TOHM(reg);\n}\n\nstatic u64 rir_limit(u32 reg)\n{\n\treturn ((u64)GET_BITFIELD(reg,  1, 10) << 29) | 0x1fffffff;\n}\n\nstatic u64 sad_limit(u32 reg)\n{\n\treturn (GET_BITFIELD(reg, 6, 25) << 26) | 0x3ffffff;\n}\n\nstatic u32 interleave_mode(u32 reg)\n{\n\treturn GET_BITFIELD(reg, 1, 1);\n}\n\nstatic u32 dram_attr(u32 reg)\n{\n\treturn GET_BITFIELD(reg, 2, 3);\n}\n\nstatic u64 knl_sad_limit(u32 reg)\n{\n\treturn (GET_BITFIELD(reg, 7, 26) << 26) | 0x3ffffff;\n}\n\nstatic u32 knl_interleave_mode(u32 reg)\n{\n\treturn GET_BITFIELD(reg, 1, 2);\n}\n\nstatic const char * const knl_intlv_mode[] = {\n\t\"[8:6]\", \"[10:8]\", \"[14:12]\", \"[32:30]\"\n};\n\nstatic const char *get_intlv_mode_str(u32 reg, enum type t)\n{\n\tif (t == KNIGHTS_LANDING)\n\t\treturn knl_intlv_mode[knl_interleave_mode(reg)];\n\telse\n\t\treturn interleave_mode(reg) ? \"[8:6]\" : \"[8:6]XOR[18:16]\";\n}\n\nstatic u32 dram_attr_knl(u32 reg)\n{\n\treturn GET_BITFIELD(reg, 3, 4);\n}\n\n\nstatic enum mem_type get_memory_type(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\tenum mem_type mtype;\n\n\tif (pvt->pci_ddrio) {\n\t\tpci_read_config_dword(pvt->pci_ddrio, pvt->info.rankcfgr,\n\t\t\t\t      &reg);\n\t\tif (GET_BITFIELD(reg, 11, 11))\n\t\t\t \n\t\t\tmtype = MEM_RDDR3;\n\t\telse\n\t\t\tmtype = MEM_DDR3;\n\t} else\n\t\tmtype = MEM_UNKNOWN;\n\n\treturn mtype;\n}\n\nstatic enum mem_type haswell_get_memory_type(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\tbool registered = false;\n\tenum mem_type mtype = MEM_UNKNOWN;\n\n\tif (!pvt->pci_ddrio)\n\t\tgoto out;\n\n\tpci_read_config_dword(pvt->pci_ddrio,\n\t\t\t      HASWELL_DDRCRCLKCONTROLS, &reg);\n\t \n\tif (GET_BITFIELD(reg, 16, 16))\n\t\tregistered = true;\n\n\tpci_read_config_dword(pvt->pci_ta, MCMTR, &reg);\n\tif (GET_BITFIELD(reg, 14, 14)) {\n\t\tif (registered)\n\t\t\tmtype = MEM_RDDR4;\n\t\telse\n\t\t\tmtype = MEM_DDR4;\n\t} else {\n\t\tif (registered)\n\t\t\tmtype = MEM_RDDR3;\n\t\telse\n\t\t\tmtype = MEM_DDR3;\n\t}\n\nout:\n\treturn mtype;\n}\n\nstatic enum dev_type knl_get_width(struct sbridge_pvt *pvt, u32 mtr)\n{\n\t \n\treturn DEV_X16;\n}\n\nstatic enum dev_type sbridge_get_width(struct sbridge_pvt *pvt, u32 mtr)\n{\n\t \n\treturn DEV_UNKNOWN;\n}\n\nstatic enum dev_type __ibridge_get_width(u32 mtr)\n{\n\tenum dev_type type = DEV_UNKNOWN;\n\n\tswitch (mtr) {\n\tcase 2:\n\t\ttype = DEV_X16;\n\t\tbreak;\n\tcase 1:\n\t\ttype = DEV_X8;\n\t\tbreak;\n\tcase 0:\n\t\ttype = DEV_X4;\n\t\tbreak;\n\t}\n\n\treturn type;\n}\n\nstatic enum dev_type ibridge_get_width(struct sbridge_pvt *pvt, u32 mtr)\n{\n\t \n\treturn __ibridge_get_width(GET_BITFIELD(mtr, 7, 8));\n}\n\nstatic enum dev_type broadwell_get_width(struct sbridge_pvt *pvt, u32 mtr)\n{\n\t \n\treturn __ibridge_get_width(GET_BITFIELD(mtr, 8, 9));\n}\n\nstatic enum mem_type knl_get_memory_type(struct sbridge_pvt *pvt)\n{\n\t \n\treturn MEM_RDDR4;\n}\n\nstatic u8 get_node_id(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\tpci_read_config_dword(pvt->pci_br0, SAD_CONTROL, &reg);\n\treturn GET_BITFIELD(reg, 0, 2);\n}\n\nstatic u8 haswell_get_node_id(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->pci_sad1, SAD_CONTROL, &reg);\n\treturn GET_BITFIELD(reg, 0, 3);\n}\n\nstatic u8 knl_get_node_id(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->pci_sad1, SAD_CONTROL, &reg);\n\treturn GET_BITFIELD(reg, 0, 2);\n}\n\n \nstatic u8 sbridge_get_ha(u8 bank)\n{\n\treturn 0;\n}\n\n \nstatic u8 ibridge_get_ha(u8 bank)\n{\n\tswitch (bank) {\n\tcase 7 ... 8:\n\t\treturn bank - 7;\n\tcase 9 ... 16:\n\t\treturn (bank - 9) / 4;\n\tdefault:\n\t\treturn 0xff;\n\t}\n}\n\n \nstatic u8 knl_get_ha(u8 bank)\n{\n\treturn 0xff;\n}\n\nstatic u64 haswell_get_tolm(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->info.pci_vtd, HASWELL_TOLM, &reg);\n\treturn (GET_BITFIELD(reg, 26, 31) << 26) | 0x3ffffff;\n}\n\nstatic u64 haswell_get_tohm(struct sbridge_pvt *pvt)\n{\n\tu64 rc;\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->info.pci_vtd, HASWELL_TOHM_0, &reg);\n\trc = GET_BITFIELD(reg, 26, 31);\n\tpci_read_config_dword(pvt->info.pci_vtd, HASWELL_TOHM_1, &reg);\n\trc = ((reg << 6) | rc) << 26;\n\n\treturn rc | 0x3ffffff;\n}\n\nstatic u64 knl_get_tolm(struct sbridge_pvt *pvt)\n{\n\tu32 reg;\n\n\tpci_read_config_dword(pvt->knl.pci_mc_info, KNL_TOLM, &reg);\n\treturn (GET_BITFIELD(reg, 26, 31) << 26) | 0x3ffffff;\n}\n\nstatic u64 knl_get_tohm(struct sbridge_pvt *pvt)\n{\n\tu64 rc;\n\tu32 reg_lo, reg_hi;\n\n\tpci_read_config_dword(pvt->knl.pci_mc_info, KNL_TOHM_0, &reg_lo);\n\tpci_read_config_dword(pvt->knl.pci_mc_info, KNL_TOHM_1, &reg_hi);\n\trc = ((u64)reg_hi << 32) | reg_lo;\n\treturn rc | 0x3ffffff;\n}\n\n\nstatic u64 haswell_rir_limit(u32 reg)\n{\n\treturn (((u64)GET_BITFIELD(reg,  1, 11) + 1) << 29) - 1;\n}\n\nstatic inline u8 sad_pkg_socket(u8 pkg)\n{\n\t \n\treturn ((pkg >> 3) << 2) | (pkg & 0x3);\n}\n\nstatic inline u8 sad_pkg_ha(u8 pkg)\n{\n\treturn (pkg >> 2) & 0x1;\n}\n\nstatic int haswell_chan_hash(int idx, u64 addr)\n{\n\tint i;\n\n\t \n\tfor (i = 12; i < 28; i += 2)\n\t\tidx ^= (addr >> i) & 3;\n\n\treturn idx;\n}\n\n \nstatic const u32 knl_tad_dram_limit_lo[] = {\n\t0x400, 0x500, 0x600, 0x700,\n\t0x800, 0x900, 0xa00, 0xb00,\n};\n\n \nstatic const u32 knl_tad_dram_offset_lo[] = {\n\t0x404, 0x504, 0x604, 0x704,\n\t0x804, 0x904, 0xa04, 0xb04,\n};\n\n \nstatic const u32 knl_tad_dram_hi[] = {\n\t0x408, 0x508, 0x608, 0x708,\n\t0x808, 0x908, 0xa08, 0xb08,\n};\n\n \nstatic const u32 knl_tad_ways[] = {\n\t8, 6, 4, 3, 2, 1,\n};\n\n \nstatic int knl_get_tad(const struct sbridge_pvt *pvt,\n\t\tconst int entry,\n\t\tconst int mc,\n\t\tu64 *offset,\n\t\tu64 *limit,\n\t\tint *ways)\n{\n\tu32 reg_limit_lo, reg_offset_lo, reg_hi;\n\tstruct pci_dev *pci_mc;\n\tint way_id;\n\n\tswitch (mc) {\n\tcase 0:\n\t\tpci_mc = pvt->knl.pci_mc0;\n\t\tbreak;\n\tcase 1:\n\t\tpci_mc = pvt->knl.pci_mc1;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -EINVAL;\n\t}\n\n\tpci_read_config_dword(pci_mc,\n\t\t\tknl_tad_dram_limit_lo[entry], &reg_limit_lo);\n\tpci_read_config_dword(pci_mc,\n\t\t\tknl_tad_dram_offset_lo[entry], &reg_offset_lo);\n\tpci_read_config_dword(pci_mc,\n\t\t\tknl_tad_dram_hi[entry], &reg_hi);\n\n\t \n\tif (!GET_BITFIELD(reg_limit_lo, 0, 0))\n\t\treturn -ENODEV;\n\n\tway_id = GET_BITFIELD(reg_limit_lo, 3, 5);\n\n\tif (way_id < ARRAY_SIZE(knl_tad_ways)) {\n\t\t*ways = knl_tad_ways[way_id];\n\t} else {\n\t\t*ways = 0;\n\t\tsbridge_printk(KERN_ERR,\n\t\t\t\t\"Unexpected value %d in mc_tad_limit_lo wayness field\\n\",\n\t\t\t\tway_id);\n\t\treturn -ENODEV;\n\t}\n\n\t \n\t*offset = ((u64) GET_BITFIELD(reg_offset_lo, 6, 31) << 6) |\n\t\t\t\t((u64) GET_BITFIELD(reg_hi, 0,  15) << 32);\n\t*limit = ((u64) GET_BITFIELD(reg_limit_lo,  6, 31) << 6) | 63 |\n\t\t\t\t((u64) GET_BITFIELD(reg_hi, 16, 31) << 32);\n\n\treturn 0;\n}\n\n \nstatic int knl_channel_mc(int channel)\n{\n\tWARN_ON(channel < 0 || channel >= 6);\n\n\treturn channel < 3 ? 1 : 0;\n}\n\n \nstatic u32 knl_get_edc_route(int entry, u32 reg)\n{\n\tWARN_ON(entry >= KNL_MAX_EDCS);\n\treturn GET_BITFIELD(reg, entry*3, (entry*3)+2);\n}\n\n \n\nstatic u32 knl_get_mc_route(int entry, u32 reg)\n{\n\tint mc, chan;\n\n\tWARN_ON(entry >= KNL_MAX_CHANNELS);\n\n\tmc = GET_BITFIELD(reg, entry*3, (entry*3)+2);\n\tchan = GET_BITFIELD(reg, (entry*2) + 18, (entry*2) + 18 + 1);\n\n\treturn knl_channel_remap(mc, chan);\n}\n\n \nstatic void knl_show_edc_route(u32 reg, char *s)\n{\n\tint i;\n\n\tfor (i = 0; i < KNL_MAX_EDCS; i++) {\n\t\ts[i*2] = knl_get_edc_route(i, reg) + '0';\n\t\ts[i*2+1] = '-';\n\t}\n\n\ts[KNL_MAX_EDCS*2 - 1] = '\\0';\n}\n\n \nstatic void knl_show_mc_route(u32 reg, char *s)\n{\n\tint i;\n\n\tfor (i = 0; i < KNL_MAX_CHANNELS; i++) {\n\t\ts[i*2] = knl_get_mc_route(i, reg) + '0';\n\t\ts[i*2+1] = '-';\n\t}\n\n\ts[KNL_MAX_CHANNELS*2 - 1] = '\\0';\n}\n\n#define KNL_EDC_ROUTE 0xb8\n#define KNL_MC_ROUTE 0xb4\n\n \n#define KNL_EDRAM(reg) GET_BITFIELD(reg, 29, 29)\n\n \n#define KNL_CACHEABLE(reg) GET_BITFIELD(reg, 28, 28)\n\n \n#define KNL_EDRAM_ONLY(reg) GET_BITFIELD(reg, 29, 29)\n\n \n#define KNL_CACHEABLE(reg) GET_BITFIELD(reg, 28, 28)\n\n \n#define KNL_MOD3(reg) GET_BITFIELD(reg, 27, 27)\n\n \nstatic int knl_get_dimm_capacity(struct sbridge_pvt *pvt, u64 *mc_sizes)\n{\n\tu64 sad_base, sad_limit = 0;\n\tu64 tad_base, tad_size, tad_limit, tad_deadspace, tad_livespace;\n\tint sad_rule = 0;\n\tint tad_rule = 0;\n\tint intrlv_ways, tad_ways;\n\tu32 first_pkg, pkg;\n\tint i;\n\tu64 sad_actual_size[2];  \n\tu32 dram_rule, interleave_reg;\n\tu32 mc_route_reg[KNL_MAX_CHAS];\n\tu32 edc_route_reg[KNL_MAX_CHAS];\n\tint edram_only;\n\tchar edc_route_string[KNL_MAX_EDCS*2];\n\tchar mc_route_string[KNL_MAX_CHANNELS*2];\n\tint cur_reg_start;\n\tint mc;\n\tint channel;\n\tint participants[KNL_MAX_CHANNELS];\n\n\tfor (i = 0; i < KNL_MAX_CHANNELS; i++)\n\t\tmc_sizes[i] = 0;\n\n\t \n\tcur_reg_start = 0;\n\tfor (i = 0; i < KNL_MAX_CHAS; i++) {\n\t\tpci_read_config_dword(pvt->knl.pci_cha[i],\n\t\t\t\tKNL_EDC_ROUTE, &edc_route_reg[i]);\n\n\t\tif (i > 0 && edc_route_reg[i] != edc_route_reg[i-1]) {\n\t\t\tknl_show_edc_route(edc_route_reg[i-1],\n\t\t\t\t\tedc_route_string);\n\t\t\tif (cur_reg_start == i-1)\n\t\t\t\tedac_dbg(0, \"edc route table for CHA %d: %s\\n\",\n\t\t\t\t\tcur_reg_start, edc_route_string);\n\t\t\telse\n\t\t\t\tedac_dbg(0, \"edc route table for CHA %d-%d: %s\\n\",\n\t\t\t\t\tcur_reg_start, i-1, edc_route_string);\n\t\t\tcur_reg_start = i;\n\t\t}\n\t}\n\tknl_show_edc_route(edc_route_reg[i-1], edc_route_string);\n\tif (cur_reg_start == i-1)\n\t\tedac_dbg(0, \"edc route table for CHA %d: %s\\n\",\n\t\t\tcur_reg_start, edc_route_string);\n\telse\n\t\tedac_dbg(0, \"edc route table for CHA %d-%d: %s\\n\",\n\t\t\tcur_reg_start, i-1, edc_route_string);\n\n\t \n\tcur_reg_start = 0;\n\tfor (i = 0; i < KNL_MAX_CHAS; i++) {\n\t\tpci_read_config_dword(pvt->knl.pci_cha[i],\n\t\t\tKNL_MC_ROUTE, &mc_route_reg[i]);\n\n\t\tif (i > 0 && mc_route_reg[i] != mc_route_reg[i-1]) {\n\t\t\tknl_show_mc_route(mc_route_reg[i-1], mc_route_string);\n\t\t\tif (cur_reg_start == i-1)\n\t\t\t\tedac_dbg(0, \"mc route table for CHA %d: %s\\n\",\n\t\t\t\t\tcur_reg_start, mc_route_string);\n\t\t\telse\n\t\t\t\tedac_dbg(0, \"mc route table for CHA %d-%d: %s\\n\",\n\t\t\t\t\tcur_reg_start, i-1, mc_route_string);\n\t\t\tcur_reg_start = i;\n\t\t}\n\t}\n\tknl_show_mc_route(mc_route_reg[i-1], mc_route_string);\n\tif (cur_reg_start == i-1)\n\t\tedac_dbg(0, \"mc route table for CHA %d: %s\\n\",\n\t\t\tcur_reg_start, mc_route_string);\n\telse\n\t\tedac_dbg(0, \"mc route table for CHA %d-%d: %s\\n\",\n\t\t\tcur_reg_start, i-1, mc_route_string);\n\n\t \n\tfor (sad_rule = 0; sad_rule < pvt->info.max_sad; sad_rule++) {\n\t\t \n\t\tsad_base = sad_limit;\n\n\t\tpci_read_config_dword(pvt->pci_sad0,\n\t\t\tpvt->info.dram_rule[sad_rule], &dram_rule);\n\n\t\tif (!DRAM_RULE_ENABLE(dram_rule))\n\t\t\tbreak;\n\n\t\tedram_only = KNL_EDRAM_ONLY(dram_rule);\n\n\t\tsad_limit = pvt->info.sad_limit(dram_rule)+1;\n\n\t\tpci_read_config_dword(pvt->pci_sad0,\n\t\t\tpvt->info.interleave_list[sad_rule], &interleave_reg);\n\n\t\t \n\t\tfirst_pkg = sad_pkg(pvt->info.interleave_pkg,\n\t\t\t\t\t\tinterleave_reg, 0);\n\t\tfor (intrlv_ways = 1; intrlv_ways < 8; intrlv_ways++) {\n\t\t\tpkg = sad_pkg(pvt->info.interleave_pkg,\n\t\t\t\t\t\tinterleave_reg, intrlv_ways);\n\n\t\t\tif ((pkg & 0x8) == 0) {\n\t\t\t\t \n\t\t\t\tedac_dbg(0, \"Unexpected interleave target %d\\n\",\n\t\t\t\t\tpkg);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (pkg == first_pkg)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (KNL_MOD3(dram_rule))\n\t\t\tintrlv_ways *= 3;\n\n\t\tedac_dbg(3, \"dram rule %d (base 0x%llx, limit 0x%llx), %d way interleave%s\\n\",\n\t\t\tsad_rule,\n\t\t\tsad_base,\n\t\t\tsad_limit,\n\t\t\tintrlv_ways,\n\t\t\tedram_only ? \", EDRAM\" : \"\");\n\n\t\t \n\t\tfor (mc = 0; mc < 2; mc++) {\n\t\t\tsad_actual_size[mc] = 0;\n\t\t\ttad_livespace = 0;\n\t\t\tfor (tad_rule = 0;\n\t\t\t\t\ttad_rule < ARRAY_SIZE(\n\t\t\t\t\t\tknl_tad_dram_limit_lo);\n\t\t\t\t\ttad_rule++) {\n\t\t\t\tif (knl_get_tad(pvt,\n\t\t\t\t\t\ttad_rule,\n\t\t\t\t\t\tmc,\n\t\t\t\t\t\t&tad_deadspace,\n\t\t\t\t\t\t&tad_limit,\n\t\t\t\t\t\t&tad_ways))\n\t\t\t\t\tbreak;\n\n\t\t\t\ttad_size = (tad_limit+1) -\n\t\t\t\t\t(tad_livespace + tad_deadspace);\n\t\t\t\ttad_livespace += tad_size;\n\t\t\t\ttad_base = (tad_limit+1) - tad_size;\n\n\t\t\t\tif (tad_base < sad_base) {\n\t\t\t\t\tif (tad_limit > sad_base)\n\t\t\t\t\t\tedac_dbg(0, \"TAD region overlaps lower SAD boundary -- TAD tables may be configured incorrectly.\\n\");\n\t\t\t\t} else if (tad_base < sad_limit) {\n\t\t\t\t\tif (tad_limit+1 > sad_limit) {\n\t\t\t\t\t\tedac_dbg(0, \"TAD region overlaps upper SAD boundary -- TAD tables may be configured incorrectly.\\n\");\n\t\t\t\t\t} else {\n\t\t\t\t\t\t \n\t\t\t\t\t\tedac_dbg(3, \"TAD region %d 0x%llx - 0x%llx (%lld bytes) table%d\\n\",\n\t\t\t\t\t\t\ttad_rule, tad_base,\n\t\t\t\t\t\t\ttad_limit, tad_size,\n\t\t\t\t\t\t\tmc);\n\t\t\t\t\t\tsad_actual_size[mc] += tad_size;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (mc = 0; mc < 2; mc++) {\n\t\t\tedac_dbg(3, \" total TAD DRAM footprint in table%d : 0x%llx (%lld bytes)\\n\",\n\t\t\t\tmc, sad_actual_size[mc], sad_actual_size[mc]);\n\t\t}\n\n\t\t \n\t\tif (edram_only)\n\t\t\tcontinue;\n\n\t\t \n\t\tfor (channel = 0; channel < KNL_MAX_CHANNELS; channel++)\n\t\t\tparticipants[channel] = 0;\n\n\t\t \n\t\tfor (channel = 0; channel < KNL_MAX_CHANNELS; channel++) {\n\t\t\tint target;\n\t\t\tint cha;\n\n\t\t\tfor (target = 0; target < KNL_MAX_CHANNELS; target++) {\n\t\t\t\tfor (cha = 0; cha < KNL_MAX_CHAS; cha++) {\n\t\t\t\t\tif (knl_get_mc_route(target,\n\t\t\t\t\t\tmc_route_reg[cha]) == channel\n\t\t\t\t\t\t&& !participants[channel]) {\n\t\t\t\t\t\tparticipants[channel] = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (channel = 0; channel < KNL_MAX_CHANNELS; channel++) {\n\t\t\tmc = knl_channel_mc(channel);\n\t\t\tif (participants[channel]) {\n\t\t\t\tedac_dbg(4, \"mc channel %d contributes %lld bytes via sad entry %d\\n\",\n\t\t\t\t\tchannel,\n\t\t\t\t\tsad_actual_size[mc]/intrlv_ways,\n\t\t\t\t\tsad_rule);\n\t\t\t\tmc_sizes[channel] +=\n\t\t\t\t\tsad_actual_size[mc]/intrlv_ways;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void get_source_id(struct mem_ctl_info *mci)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tu32 reg;\n\n\tif (pvt->info.type == HASWELL || pvt->info.type == BROADWELL ||\n\t    pvt->info.type == KNIGHTS_LANDING)\n\t\tpci_read_config_dword(pvt->pci_sad1, SAD_TARGET, &reg);\n\telse\n\t\tpci_read_config_dword(pvt->pci_br0, SAD_TARGET, &reg);\n\n\tif (pvt->info.type == KNIGHTS_LANDING)\n\t\tpvt->sbridge_dev->source_id = SOURCE_ID_KNL(reg);\n\telse\n\t\tpvt->sbridge_dev->source_id = SOURCE_ID(reg);\n}\n\nstatic int __populate_dimms(struct mem_ctl_info *mci,\n\t\t\t    u64 knl_mc_sizes[KNL_MAX_CHANNELS],\n\t\t\t    enum edac_type mode)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tint channels = pvt->info.type == KNIGHTS_LANDING ? KNL_MAX_CHANNELS\n\t\t\t\t\t\t\t : NUM_CHANNELS;\n\tunsigned int i, j, banks, ranks, rows, cols, npages;\n\tstruct dimm_info *dimm;\n\tenum mem_type mtype;\n\tu64 size;\n\n\tmtype = pvt->info.get_memory_type(pvt);\n\tif (mtype == MEM_RDDR3 || mtype == MEM_RDDR4)\n\t\tedac_dbg(0, \"Memory is registered\\n\");\n\telse if (mtype == MEM_UNKNOWN)\n\t\tedac_dbg(0, \"Cannot determine memory type\\n\");\n\telse\n\t\tedac_dbg(0, \"Memory is unregistered\\n\");\n\n\tif (mtype == MEM_DDR4 || mtype == MEM_RDDR4)\n\t\tbanks = 16;\n\telse\n\t\tbanks = 8;\n\n\tfor (i = 0; i < channels; i++) {\n\t\tu32 mtr, amap = 0;\n\n\t\tint max_dimms_per_channel;\n\n\t\tif (pvt->info.type == KNIGHTS_LANDING) {\n\t\t\tmax_dimms_per_channel = 1;\n\t\t\tif (!pvt->knl.pci_channel[i])\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tmax_dimms_per_channel = ARRAY_SIZE(mtr_regs);\n\t\t\tif (!pvt->pci_tad[i])\n\t\t\t\tcontinue;\n\t\t\tpci_read_config_dword(pvt->pci_tad[i], 0x8c, &amap);\n\t\t}\n\n\t\tfor (j = 0; j < max_dimms_per_channel; j++) {\n\t\t\tdimm = edac_get_dimm(mci, i, j, 0);\n\t\t\tif (pvt->info.type == KNIGHTS_LANDING) {\n\t\t\t\tpci_read_config_dword(pvt->knl.pci_channel[i],\n\t\t\t\t\tknl_mtr_reg, &mtr);\n\t\t\t} else {\n\t\t\t\tpci_read_config_dword(pvt->pci_tad[i],\n\t\t\t\t\tmtr_regs[j], &mtr);\n\t\t\t}\n\t\t\tedac_dbg(4, \"Channel #%d  MTR%d = %x\\n\", i, j, mtr);\n\n\t\t\tif (IS_DIMM_PRESENT(mtr)) {\n\t\t\t\tif (!IS_ECC_ENABLED(pvt->info.mcmtr)) {\n\t\t\t\t\tsbridge_printk(KERN_ERR, \"CPU SrcID #%d, Ha #%d, Channel #%d has DIMMs, but ECC is disabled\\n\",\n\t\t\t\t\t\t       pvt->sbridge_dev->source_id,\n\t\t\t\t\t\t       pvt->sbridge_dev->dom, i);\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\t}\n\t\t\t\tpvt->channel[i].dimms++;\n\n\t\t\t\tranks = numrank(pvt->info.type, mtr);\n\n\t\t\t\tif (pvt->info.type == KNIGHTS_LANDING) {\n\t\t\t\t\t \n\t\t\t\t\tcols = 1 << 10;\n\t\t\t\t\trows = knl_mc_sizes[i] /\n\t\t\t\t\t\t((u64) cols * ranks * banks * 8);\n\t\t\t\t} else {\n\t\t\t\t\trows = numrow(mtr);\n\t\t\t\t\tcols = numcol(mtr);\n\t\t\t\t}\n\n\t\t\t\tsize = ((u64)rows * cols * banks * ranks) >> (20 - 3);\n\t\t\t\tnpages = MiB_TO_PAGES(size);\n\n\t\t\t\tedac_dbg(0, \"mc#%d: ha %d channel %d, dimm %d, %lld MiB (%d pages) bank: %d, rank: %d, row: %#x, col: %#x\\n\",\n\t\t\t\t\t pvt->sbridge_dev->mc, pvt->sbridge_dev->dom, i, j,\n\t\t\t\t\t size, npages,\n\t\t\t\t\t banks, ranks, rows, cols);\n\n\t\t\t\tdimm->nr_pages = npages;\n\t\t\t\tdimm->grain = 32;\n\t\t\t\tdimm->dtype = pvt->info.get_width(pvt, mtr);\n\t\t\t\tdimm->mtype = mtype;\n\t\t\t\tdimm->edac_mode = mode;\n\t\t\t\tpvt->channel[i].dimm[j].rowbits = order_base_2(rows);\n\t\t\t\tpvt->channel[i].dimm[j].colbits = order_base_2(cols);\n\t\t\t\tpvt->channel[i].dimm[j].bank_xor_enable =\n\t\t\t\t\t\tGET_BITFIELD(pvt->info.mcmtr, 9, 9);\n\t\t\t\tpvt->channel[i].dimm[j].amap_fine = GET_BITFIELD(amap, 0, 0);\n\t\t\t\tsnprintf(dimm->label, sizeof(dimm->label),\n\t\t\t\t\t\t \"CPU_SrcID#%u_Ha#%u_Chan#%u_DIMM#%u\",\n\t\t\t\t\t\t pvt->sbridge_dev->source_id, pvt->sbridge_dev->dom, i, j);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int get_dimm_config(struct mem_ctl_info *mci)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tu64 knl_mc_sizes[KNL_MAX_CHANNELS];\n\tenum edac_type mode;\n\tu32 reg;\n\n\tpvt->sbridge_dev->node_id = pvt->info.get_node_id(pvt);\n\tedac_dbg(0, \"mc#%d: Node ID: %d, source ID: %d\\n\",\n\t\t pvt->sbridge_dev->mc,\n\t\t pvt->sbridge_dev->node_id,\n\t\t pvt->sbridge_dev->source_id);\n\n\t \n\tif (pvt->info.type == KNIGHTS_LANDING) {\n\t\tmode = EDAC_S4ECD4ED;\n\t\tpvt->mirror_mode = NON_MIRRORING;\n\t\tpvt->is_cur_addr_mirrored = false;\n\n\t\tif (knl_get_dimm_capacity(pvt, knl_mc_sizes) != 0)\n\t\t\treturn -1;\n\t\tif (pci_read_config_dword(pvt->pci_ta, KNL_MCMTR, &pvt->info.mcmtr)) {\n\t\t\tedac_dbg(0, \"Failed to read KNL_MCMTR register\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t} else {\n\t\tif (pvt->info.type == HASWELL || pvt->info.type == BROADWELL) {\n\t\t\tif (pci_read_config_dword(pvt->pci_ha, HASWELL_HASYSDEFEATURE2, &reg)) {\n\t\t\t\tedac_dbg(0, \"Failed to read HASWELL_HASYSDEFEATURE2 register\\n\");\n\t\t\t\treturn -ENODEV;\n\t\t\t}\n\t\t\tpvt->is_chan_hash = GET_BITFIELD(reg, 21, 21);\n\t\t\tif (GET_BITFIELD(reg, 28, 28)) {\n\t\t\t\tpvt->mirror_mode = ADDR_RANGE_MIRRORING;\n\t\t\t\tedac_dbg(0, \"Address range partial memory mirroring is enabled\\n\");\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t}\n\t\tif (pci_read_config_dword(pvt->pci_ras, RASENABLES, &reg)) {\n\t\t\tedac_dbg(0, \"Failed to read RASENABLES register\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tif (IS_MIRROR_ENABLED(reg)) {\n\t\t\tpvt->mirror_mode = FULL_MIRRORING;\n\t\t\tedac_dbg(0, \"Full memory mirroring is enabled\\n\");\n\t\t} else {\n\t\t\tpvt->mirror_mode = NON_MIRRORING;\n\t\t\tedac_dbg(0, \"Memory mirroring is disabled\\n\");\n\t\t}\n\nnext:\n\t\tif (pci_read_config_dword(pvt->pci_ta, MCMTR, &pvt->info.mcmtr)) {\n\t\t\tedac_dbg(0, \"Failed to read MCMTR register\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t\tif (IS_LOCKSTEP_ENABLED(pvt->info.mcmtr)) {\n\t\t\tedac_dbg(0, \"Lockstep is enabled\\n\");\n\t\t\tmode = EDAC_S8ECD8ED;\n\t\t\tpvt->is_lockstep = true;\n\t\t} else {\n\t\t\tedac_dbg(0, \"Lockstep is disabled\\n\");\n\t\t\tmode = EDAC_S4ECD4ED;\n\t\t\tpvt->is_lockstep = false;\n\t\t}\n\t\tif (IS_CLOSE_PG(pvt->info.mcmtr)) {\n\t\t\tedac_dbg(0, \"address map is on closed page mode\\n\");\n\t\t\tpvt->is_close_pg = true;\n\t\t} else {\n\t\t\tedac_dbg(0, \"address map is on open page mode\\n\");\n\t\t\tpvt->is_close_pg = false;\n\t\t}\n\t}\n\n\treturn __populate_dimms(mci, knl_mc_sizes, mode);\n}\n\nstatic void get_memory_layout(const struct mem_ctl_info *mci)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tint i, j, k, n_sads, n_tads, sad_interl;\n\tu32 reg;\n\tu64 limit, prv = 0;\n\tu64 tmp_mb;\n\tu32 gb, mb;\n\tu32 rir_way;\n\n\t \n\n\tpvt->tolm = pvt->info.get_tolm(pvt);\n\ttmp_mb = (1 + pvt->tolm) >> 20;\n\n\tgb = div_u64_rem(tmp_mb, 1024, &mb);\n\tedac_dbg(0, \"TOLM: %u.%03u GB (0x%016Lx)\\n\",\n\t\tgb, (mb*1000)/1024, (u64)pvt->tolm);\n\n\t \n\tpvt->tohm = pvt->info.get_tohm(pvt);\n\ttmp_mb = (1 + pvt->tohm) >> 20;\n\n\tgb = div_u64_rem(tmp_mb, 1024, &mb);\n\tedac_dbg(0, \"TOHM: %u.%03u GB (0x%016Lx)\\n\",\n\t\tgb, (mb*1000)/1024, (u64)pvt->tohm);\n\n\t \n\tprv = 0;\n\tfor (n_sads = 0; n_sads < pvt->info.max_sad; n_sads++) {\n\t\t \n\t\tpci_read_config_dword(pvt->pci_sad0, pvt->info.dram_rule[n_sads],\n\t\t\t\t      &reg);\n\t\tlimit = pvt->info.sad_limit(reg);\n\n\t\tif (!DRAM_RULE_ENABLE(reg))\n\t\t\tcontinue;\n\n\t\tif (limit <= prv)\n\t\t\tbreak;\n\n\t\ttmp_mb = (limit + 1) >> 20;\n\t\tgb = div_u64_rem(tmp_mb, 1024, &mb);\n\t\tedac_dbg(0, \"SAD#%d %s up to %u.%03u GB (0x%016Lx) Interleave: %s reg=0x%08x\\n\",\n\t\t\t n_sads,\n\t\t\t show_dram_attr(pvt->info.dram_attr(reg)),\n\t\t\t gb, (mb*1000)/1024,\n\t\t\t ((u64)tmp_mb) << 20L,\n\t\t\t get_intlv_mode_str(reg, pvt->info.type),\n\t\t\t reg);\n\t\tprv = limit;\n\n\t\tpci_read_config_dword(pvt->pci_sad0, pvt->info.interleave_list[n_sads],\n\t\t\t\t      &reg);\n\t\tsad_interl = sad_pkg(pvt->info.interleave_pkg, reg, 0);\n\t\tfor (j = 0; j < 8; j++) {\n\t\t\tu32 pkg = sad_pkg(pvt->info.interleave_pkg, reg, j);\n\t\t\tif (j > 0 && sad_interl == pkg)\n\t\t\t\tbreak;\n\n\t\t\tedac_dbg(0, \"SAD#%d, interleave #%d: %d\\n\",\n\t\t\t\t n_sads, j, pkg);\n\t\t}\n\t}\n\n\tif (pvt->info.type == KNIGHTS_LANDING)\n\t\treturn;\n\n\t \n\tprv = 0;\n\tfor (n_tads = 0; n_tads < MAX_TAD; n_tads++) {\n\t\tpci_read_config_dword(pvt->pci_ha, tad_dram_rule[n_tads], &reg);\n\t\tlimit = TAD_LIMIT(reg);\n\t\tif (limit <= prv)\n\t\t\tbreak;\n\t\ttmp_mb = (limit + 1) >> 20;\n\n\t\tgb = div_u64_rem(tmp_mb, 1024, &mb);\n\t\tedac_dbg(0, \"TAD#%d: up to %u.%03u GB (0x%016Lx), socket interleave %d, memory interleave %d, TGT: %d, %d, %d, %d, reg=0x%08x\\n\",\n\t\t\t n_tads, gb, (mb*1000)/1024,\n\t\t\t ((u64)tmp_mb) << 20L,\n\t\t\t (u32)(1 << TAD_SOCK(reg)),\n\t\t\t (u32)TAD_CH(reg) + 1,\n\t\t\t (u32)TAD_TGT0(reg),\n\t\t\t (u32)TAD_TGT1(reg),\n\t\t\t (u32)TAD_TGT2(reg),\n\t\t\t (u32)TAD_TGT3(reg),\n\t\t\t reg);\n\t\tprv = limit;\n\t}\n\n\t \n\tfor (i = 0; i < NUM_CHANNELS; i++) {\n\t\tif (!pvt->channel[i].dimms)\n\t\t\tcontinue;\n\t\tfor (j = 0; j < n_tads; j++) {\n\t\t\tpci_read_config_dword(pvt->pci_tad[i],\n\t\t\t\t\t      tad_ch_nilv_offset[j],\n\t\t\t\t\t      &reg);\n\t\t\ttmp_mb = TAD_OFFSET(reg) >> 20;\n\t\t\tgb = div_u64_rem(tmp_mb, 1024, &mb);\n\t\t\tedac_dbg(0, \"TAD CH#%d, offset #%d: %u.%03u GB (0x%016Lx), reg=0x%08x\\n\",\n\t\t\t\t i, j,\n\t\t\t\t gb, (mb*1000)/1024,\n\t\t\t\t ((u64)tmp_mb) << 20L,\n\t\t\t\t reg);\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < NUM_CHANNELS; i++) {\n\t\tif (!pvt->channel[i].dimms)\n\t\t\tcontinue;\n\t\tfor (j = 0; j < MAX_RIR_RANGES; j++) {\n\t\t\tpci_read_config_dword(pvt->pci_tad[i],\n\t\t\t\t\t      rir_way_limit[j],\n\t\t\t\t\t      &reg);\n\n\t\t\tif (!IS_RIR_VALID(reg))\n\t\t\t\tcontinue;\n\n\t\t\ttmp_mb = pvt->info.rir_limit(reg) >> 20;\n\t\t\trir_way = 1 << RIR_WAY(reg);\n\t\t\tgb = div_u64_rem(tmp_mb, 1024, &mb);\n\t\t\tedac_dbg(0, \"CH#%d RIR#%d, limit: %u.%03u GB (0x%016Lx), way: %d, reg=0x%08x\\n\",\n\t\t\t\t i, j,\n\t\t\t\t gb, (mb*1000)/1024,\n\t\t\t\t ((u64)tmp_mb) << 20L,\n\t\t\t\t rir_way,\n\t\t\t\t reg);\n\n\t\t\tfor (k = 0; k < rir_way; k++) {\n\t\t\t\tpci_read_config_dword(pvt->pci_tad[i],\n\t\t\t\t\t\t      rir_offset[j][k],\n\t\t\t\t\t\t      &reg);\n\t\t\t\ttmp_mb = RIR_OFFSET(pvt->info.type, reg) << 6;\n\n\t\t\t\tgb = div_u64_rem(tmp_mb, 1024, &mb);\n\t\t\t\tedac_dbg(0, \"CH#%d RIR#%d INTL#%d, offset %u.%03u GB (0x%016Lx), tgt: %d, reg=0x%08x\\n\",\n\t\t\t\t\t i, j, k,\n\t\t\t\t\t gb, (mb*1000)/1024,\n\t\t\t\t\t ((u64)tmp_mb) << 20L,\n\t\t\t\t\t (u32)RIR_RNK_TGT(pvt->info.type, reg),\n\t\t\t\t\t reg);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic struct mem_ctl_info *get_mci_for_node_id(u8 node_id, u8 ha)\n{\n\tstruct sbridge_dev *sbridge_dev;\n\n\tlist_for_each_entry(sbridge_dev, &sbridge_edac_list, list) {\n\t\tif (sbridge_dev->node_id == node_id && sbridge_dev->dom == ha)\n\t\t\treturn sbridge_dev->mci;\n\t}\n\treturn NULL;\n}\n\nstatic u8 sb_close_row[] = {\n\t15, 16, 17, 18, 20, 21, 22, 28, 10, 11, 12, 13, 29, 30, 31, 32, 33\n};\n\nstatic u8 sb_close_column[] = {\n\t3, 4, 5, 14, 19, 23, 24, 25, 26, 27\n};\n\nstatic u8 sb_open_row[] = {\n\t14, 15, 16, 20, 28, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33\n};\n\nstatic u8 sb_open_column[] = {\n\t3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n};\n\nstatic u8 sb_open_fine_column[] = {\n\t3, 4, 5, 7, 8, 9, 10, 11, 12, 13\n};\n\nstatic int sb_bits(u64 addr, int nbits, u8 *bits)\n{\n\tint i, res = 0;\n\n\tfor (i = 0; i < nbits; i++)\n\t\tres |= ((addr >> bits[i]) & 1) << i;\n\treturn res;\n}\n\nstatic int sb_bank_bits(u64 addr, int b0, int b1, int do_xor, int x0, int x1)\n{\n\tint ret = GET_BITFIELD(addr, b0, b0) | (GET_BITFIELD(addr, b1, b1) << 1);\n\n\tif (do_xor)\n\t\tret ^= GET_BITFIELD(addr, x0, x0) | (GET_BITFIELD(addr, x1, x1) << 1);\n\n\treturn ret;\n}\n\nstatic bool sb_decode_ddr4(struct mem_ctl_info *mci, int ch, u8 rank,\n\t\t\t   u64 rank_addr, char *msg)\n{\n\tint dimmno = 0;\n\tint row, col, bank_address, bank_group;\n\tstruct sbridge_pvt *pvt;\n\tu32 bg0 = 0, rowbits = 0, colbits = 0;\n\tu32 amap_fine = 0, bank_xor_enable = 0;\n\n\tdimmno = (rank < 12) ? rank / 4 : 2;\n\tpvt = mci->pvt_info;\n\tamap_fine =  pvt->channel[ch].dimm[dimmno].amap_fine;\n\tbg0 = amap_fine ? 6 : 13;\n\trowbits = pvt->channel[ch].dimm[dimmno].rowbits;\n\tcolbits = pvt->channel[ch].dimm[dimmno].colbits;\n\tbank_xor_enable = pvt->channel[ch].dimm[dimmno].bank_xor_enable;\n\n\tif (pvt->is_lockstep) {\n\t\tpr_warn_once(\"LockStep row/column decode is not supported yet!\\n\");\n\t\tmsg[0] = '\\0';\n\t\treturn false;\n\t}\n\n\tif (pvt->is_close_pg) {\n\t\trow = sb_bits(rank_addr, rowbits, sb_close_row);\n\t\tcol = sb_bits(rank_addr, colbits, sb_close_column);\n\t\tcol |= 0x400;  \n\t\tbank_address = sb_bank_bits(rank_addr, 8, 9, bank_xor_enable, 22, 28);\n\t\tbank_group = sb_bank_bits(rank_addr, 6, 7, bank_xor_enable, 20, 21);\n\t} else {\n\t\trow = sb_bits(rank_addr, rowbits, sb_open_row);\n\t\tif (amap_fine)\n\t\t\tcol = sb_bits(rank_addr, colbits, sb_open_fine_column);\n\t\telse\n\t\t\tcol = sb_bits(rank_addr, colbits, sb_open_column);\n\t\tbank_address = sb_bank_bits(rank_addr, 18, 19, bank_xor_enable, 22, 23);\n\t\tbank_group = sb_bank_bits(rank_addr, bg0, 17, bank_xor_enable, 20, 21);\n\t}\n\n\trow &= (1u << rowbits) - 1;\n\n\tsprintf(msg, \"row:0x%x col:0x%x bank_addr:%d bank_group:%d\",\n\t\trow, col, bank_address, bank_group);\n\treturn true;\n}\n\nstatic bool sb_decode_ddr3(struct mem_ctl_info *mci, int ch, u8 rank,\n\t\t\t   u64 rank_addr, char *msg)\n{\n\tpr_warn_once(\"DDR3 row/column decode not support yet!\\n\");\n\tmsg[0] = '\\0';\n\treturn false;\n}\n\nstatic int get_memory_error_data(struct mem_ctl_info *mci,\n\t\t\t\t u64 addr,\n\t\t\t\t u8 *socket, u8 *ha,\n\t\t\t\t long *channel_mask,\n\t\t\t\t u8 *rank,\n\t\t\t\t char **area_type, char *msg)\n{\n\tstruct mem_ctl_info\t*new_mci;\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tstruct pci_dev\t\t*pci_ha;\n\tint\t\t\tn_rir, n_sads, n_tads, sad_way, sck_xch;\n\tint\t\t\tsad_interl, idx, base_ch;\n\tint\t\t\tinterleave_mode, shiftup = 0;\n\tunsigned int\t\tsad_interleave[MAX_INTERLEAVE];\n\tu32\t\t\treg, dram_rule;\n\tu8\t\t\tch_way, sck_way, pkg, sad_ha = 0, rankid = 0;\n\tu32\t\t\ttad_offset;\n\tu32\t\t\trir_way;\n\tu32\t\t\tmb, gb;\n\tu64\t\t\tch_addr, offset, limit = 0, prv = 0;\n\tu64\t\t\trank_addr;\n\tenum mem_type\t\tmtype;\n\n\t \n\tif ((addr > (u64) pvt->tolm) && (addr < (1LL << 32))) {\n\t\tsprintf(msg, \"Error at TOLM area, on addr 0x%08Lx\", addr);\n\t\treturn -EINVAL;\n\t}\n\tif (addr >= (u64)pvt->tohm) {\n\t\tsprintf(msg, \"Error at MMIOH area, on addr 0x%016Lx\", addr);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tfor (n_sads = 0; n_sads < pvt->info.max_sad; n_sads++) {\n\t\tpci_read_config_dword(pvt->pci_sad0, pvt->info.dram_rule[n_sads],\n\t\t\t\t      &reg);\n\n\t\tif (!DRAM_RULE_ENABLE(reg))\n\t\t\tcontinue;\n\n\t\tlimit = pvt->info.sad_limit(reg);\n\t\tif (limit <= prv) {\n\t\t\tsprintf(msg, \"Can't discover the memory socket\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif  (addr <= limit)\n\t\t\tbreak;\n\t\tprv = limit;\n\t}\n\tif (n_sads == pvt->info.max_sad) {\n\t\tsprintf(msg, \"Can't discover the memory socket\");\n\t\treturn -EINVAL;\n\t}\n\tdram_rule = reg;\n\t*area_type = show_dram_attr(pvt->info.dram_attr(dram_rule));\n\tinterleave_mode = pvt->info.interleave_mode(dram_rule);\n\n\tpci_read_config_dword(pvt->pci_sad0, pvt->info.interleave_list[n_sads],\n\t\t\t      &reg);\n\n\tif (pvt->info.type == SANDY_BRIDGE) {\n\t\tsad_interl = sad_pkg(pvt->info.interleave_pkg, reg, 0);\n\t\tfor (sad_way = 0; sad_way < 8; sad_way++) {\n\t\t\tu32 pkg = sad_pkg(pvt->info.interleave_pkg, reg, sad_way);\n\t\t\tif (sad_way > 0 && sad_interl == pkg)\n\t\t\t\tbreak;\n\t\t\tsad_interleave[sad_way] = pkg;\n\t\t\tedac_dbg(0, \"SAD interleave #%d: %d\\n\",\n\t\t\t\t sad_way, sad_interleave[sad_way]);\n\t\t}\n\t\tedac_dbg(0, \"mc#%d: Error detected on SAD#%d: address 0x%016Lx < 0x%016Lx, Interleave [%d:6]%s\\n\",\n\t\t\t pvt->sbridge_dev->mc,\n\t\t\t n_sads,\n\t\t\t addr,\n\t\t\t limit,\n\t\t\t sad_way + 7,\n\t\t\t !interleave_mode ? \"\" : \"XOR[18:16]\");\n\t\tif (interleave_mode)\n\t\t\tidx = ((addr >> 6) ^ (addr >> 16)) & 7;\n\t\telse\n\t\t\tidx = (addr >> 6) & 7;\n\t\tswitch (sad_way) {\n\t\tcase 1:\n\t\t\tidx = 0;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tidx = idx & 1;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tidx = idx & 3;\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tsprintf(msg, \"Can't discover socket interleave\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t*socket = sad_interleave[idx];\n\t\tedac_dbg(0, \"SAD interleave index: %d (wayness %d) = CPU socket %d\\n\",\n\t\t\t idx, sad_way, *socket);\n\t} else if (pvt->info.type == HASWELL || pvt->info.type == BROADWELL) {\n\t\tint bits, a7mode = A7MODE(dram_rule);\n\n\t\tif (a7mode) {\n\t\t\t \n\t\t\tbits = GET_BITFIELD(addr, 7, 8) << 1;\n\t\t\tbits |= GET_BITFIELD(addr, 9, 9);\n\t\t} else\n\t\t\tbits = GET_BITFIELD(addr, 6, 8);\n\n\t\tif (interleave_mode == 0) {\n\t\t\t \n\t\t\tidx = GET_BITFIELD(addr, 16, 18);\n\t\t\tidx ^= bits;\n\t\t} else\n\t\t\tidx = bits;\n\n\t\tpkg = sad_pkg(pvt->info.interleave_pkg, reg, idx);\n\t\t*socket = sad_pkg_socket(pkg);\n\t\tsad_ha = sad_pkg_ha(pkg);\n\n\t\tif (a7mode) {\n\t\t\t \n\t\t\tpci_read_config_dword(pvt->pci_ha, HASWELL_HASYSDEFEATURE2, &reg);\n\t\t\tshiftup = GET_BITFIELD(reg, 22, 22);\n\t\t}\n\n\t\tedac_dbg(0, \"SAD interleave package: %d = CPU socket %d, HA %i, shiftup: %i\\n\",\n\t\t\t idx, *socket, sad_ha, shiftup);\n\t} else {\n\t\t \n\t\tidx = (addr >> 6) & 7;\n\t\tpkg = sad_pkg(pvt->info.interleave_pkg, reg, idx);\n\t\t*socket = sad_pkg_socket(pkg);\n\t\tsad_ha = sad_pkg_ha(pkg);\n\t\tedac_dbg(0, \"SAD interleave package: %d = CPU socket %d, HA %d\\n\",\n\t\t\t idx, *socket, sad_ha);\n\t}\n\n\t*ha = sad_ha;\n\n\t \n\tnew_mci = get_mci_for_node_id(*socket, sad_ha);\n\tif (!new_mci) {\n\t\tsprintf(msg, \"Struct for socket #%u wasn't initialized\",\n\t\t\t*socket);\n\t\treturn -EINVAL;\n\t}\n\tmci = new_mci;\n\tpvt = mci->pvt_info;\n\n\t \n\tprv = 0;\n\tpci_ha = pvt->pci_ha;\n\tfor (n_tads = 0; n_tads < MAX_TAD; n_tads++) {\n\t\tpci_read_config_dword(pci_ha, tad_dram_rule[n_tads], &reg);\n\t\tlimit = TAD_LIMIT(reg);\n\t\tif (limit <= prv) {\n\t\t\tsprintf(msg, \"Can't discover the memory channel\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif  (addr <= limit)\n\t\t\tbreak;\n\t\tprv = limit;\n\t}\n\tif (n_tads == MAX_TAD) {\n\t\tsprintf(msg, \"Can't discover the memory channel\");\n\t\treturn -EINVAL;\n\t}\n\n\tch_way = TAD_CH(reg) + 1;\n\tsck_way = TAD_SOCK(reg);\n\n\tif (ch_way == 3)\n\t\tidx = addr >> 6;\n\telse {\n\t\tidx = (addr >> (6 + sck_way + shiftup)) & 0x3;\n\t\tif (pvt->is_chan_hash)\n\t\t\tidx = haswell_chan_hash(idx, addr);\n\t}\n\tidx = idx % ch_way;\n\n\t \n\tswitch (idx) {\n\tcase 0:\n\t\tbase_ch = TAD_TGT0(reg);\n\t\tbreak;\n\tcase 1:\n\t\tbase_ch = TAD_TGT1(reg);\n\t\tbreak;\n\tcase 2:\n\t\tbase_ch = TAD_TGT2(reg);\n\t\tbreak;\n\tcase 3:\n\t\tbase_ch = TAD_TGT3(reg);\n\t\tbreak;\n\tdefault:\n\t\tsprintf(msg, \"Can't discover the TAD target\");\n\t\treturn -EINVAL;\n\t}\n\t*channel_mask = 1 << base_ch;\n\n\tpci_read_config_dword(pvt->pci_tad[base_ch], tad_ch_nilv_offset[n_tads], &tad_offset);\n\n\tif (pvt->mirror_mode == FULL_MIRRORING ||\n\t    (pvt->mirror_mode == ADDR_RANGE_MIRRORING && n_tads == 0)) {\n\t\t*channel_mask |= 1 << ((base_ch + 2) % 4);\n\t\tswitch(ch_way) {\n\t\tcase 2:\n\t\tcase 4:\n\t\t\tsck_xch = (1 << sck_way) * (ch_way >> 1);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tsprintf(msg, \"Invalid mirror set. Can't decode addr\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tpvt->is_cur_addr_mirrored = true;\n\t} else {\n\t\tsck_xch = (1 << sck_way) * ch_way;\n\t\tpvt->is_cur_addr_mirrored = false;\n\t}\n\n\tif (pvt->is_lockstep)\n\t\t*channel_mask |= 1 << ((base_ch + 1) % 4);\n\n\toffset = TAD_OFFSET(tad_offset);\n\n\tedac_dbg(0, \"TAD#%d: address 0x%016Lx < 0x%016Lx, socket interleave %d, channel interleave %d (offset 0x%08Lx), index %d, base ch: %d, ch mask: 0x%02lx\\n\",\n\t\t n_tads,\n\t\t addr,\n\t\t limit,\n\t\t sck_way,\n\t\t ch_way,\n\t\t offset,\n\t\t idx,\n\t\t base_ch,\n\t\t *channel_mask);\n\n\t \n\t \n\n\tif (offset > addr) {\n\t\tsprintf(msg, \"Can't calculate ch addr: TAD offset 0x%08Lx is too high for addr 0x%08Lx!\",\n\t\t\toffset, addr);\n\t\treturn -EINVAL;\n\t}\n\n\tch_addr = addr - offset;\n\tch_addr >>= (6 + shiftup);\n\tch_addr /= sck_xch;\n\tch_addr <<= (6 + shiftup);\n\tch_addr |= addr & ((1 << (6 + shiftup)) - 1);\n\n\t \n\tfor (n_rir = 0; n_rir < MAX_RIR_RANGES; n_rir++) {\n\t\tpci_read_config_dword(pvt->pci_tad[base_ch], rir_way_limit[n_rir], &reg);\n\n\t\tif (!IS_RIR_VALID(reg))\n\t\t\tcontinue;\n\n\t\tlimit = pvt->info.rir_limit(reg);\n\t\tgb = div_u64_rem(limit >> 20, 1024, &mb);\n\t\tedac_dbg(0, \"RIR#%d, limit: %u.%03u GB (0x%016Lx), way: %d\\n\",\n\t\t\t n_rir,\n\t\t\t gb, (mb*1000)/1024,\n\t\t\t limit,\n\t\t\t 1 << RIR_WAY(reg));\n\t\tif  (ch_addr <= limit)\n\t\t\tbreak;\n\t}\n\tif (n_rir == MAX_RIR_RANGES) {\n\t\tsprintf(msg, \"Can't discover the memory rank for ch addr 0x%08Lx\",\n\t\t\tch_addr);\n\t\treturn -EINVAL;\n\t}\n\trir_way = RIR_WAY(reg);\n\n\tif (pvt->is_close_pg)\n\t\tidx = (ch_addr >> 6);\n\telse\n\t\tidx = (ch_addr >> 13);\t \n\tidx %= 1 << rir_way;\n\n\tpci_read_config_dword(pvt->pci_tad[base_ch], rir_offset[n_rir][idx], &reg);\n\t*rank = RIR_RNK_TGT(pvt->info.type, reg);\n\n\tif (pvt->info.type == BROADWELL) {\n\t\tif (pvt->is_close_pg)\n\t\t\tshiftup = 6;\n\t\telse\n\t\t\tshiftup = 13;\n\n\t\trank_addr = ch_addr >> shiftup;\n\t\trank_addr /= (1 << rir_way);\n\t\trank_addr <<= shiftup;\n\t\trank_addr |= ch_addr & GENMASK_ULL(shiftup - 1, 0);\n\t\trank_addr -= RIR_OFFSET(pvt->info.type, reg);\n\n\t\tmtype = pvt->info.get_memory_type(pvt);\n\t\trankid = *rank;\n\t\tif (mtype == MEM_DDR4 || mtype == MEM_RDDR4)\n\t\t\tsb_decode_ddr4(mci, base_ch, rankid, rank_addr, msg);\n\t\telse\n\t\t\tsb_decode_ddr3(mci, base_ch, rankid, rank_addr, msg);\n\t} else {\n\t\tmsg[0] = '\\0';\n\t}\n\n\tedac_dbg(0, \"RIR#%d: channel address 0x%08Lx < 0x%08Lx, RIR interleave %d, index %d\\n\",\n\t\t n_rir,\n\t\t ch_addr,\n\t\t limit,\n\t\t rir_way,\n\t\t idx);\n\n\treturn 0;\n}\n\nstatic int get_memory_error_data_from_mce(struct mem_ctl_info *mci,\n\t\t\t\t\t  const struct mce *m, u8 *socket,\n\t\t\t\t\t  u8 *ha, long *channel_mask,\n\t\t\t\t\t  char *msg)\n{\n\tu32 reg, channel = GET_BITFIELD(m->status, 0, 3);\n\tstruct mem_ctl_info *new_mci;\n\tstruct sbridge_pvt *pvt;\n\tstruct pci_dev *pci_ha;\n\tbool tad0;\n\n\tif (channel >= NUM_CHANNELS) {\n\t\tsprintf(msg, \"Invalid channel 0x%x\", channel);\n\t\treturn -EINVAL;\n\t}\n\n\tpvt = mci->pvt_info;\n\tif (!pvt->info.get_ha) {\n\t\tsprintf(msg, \"No get_ha()\");\n\t\treturn -EINVAL;\n\t}\n\t*ha = pvt->info.get_ha(m->bank);\n\tif (*ha != 0 && *ha != 1) {\n\t\tsprintf(msg, \"Impossible bank %d\", m->bank);\n\t\treturn -EINVAL;\n\t}\n\n\t*socket = m->socketid;\n\tnew_mci = get_mci_for_node_id(*socket, *ha);\n\tif (!new_mci) {\n\t\tstrcpy(msg, \"mci socket got corrupted!\");\n\t\treturn -EINVAL;\n\t}\n\n\tpvt = new_mci->pvt_info;\n\tpci_ha = pvt->pci_ha;\n\tpci_read_config_dword(pci_ha, tad_dram_rule[0], &reg);\n\ttad0 = m->addr <= TAD_LIMIT(reg);\n\n\t*channel_mask = 1 << channel;\n\tif (pvt->mirror_mode == FULL_MIRRORING ||\n\t    (pvt->mirror_mode == ADDR_RANGE_MIRRORING && tad0)) {\n\t\t*channel_mask |= 1 << ((channel + 2) % 4);\n\t\tpvt->is_cur_addr_mirrored = true;\n\t} else {\n\t\tpvt->is_cur_addr_mirrored = false;\n\t}\n\n\tif (pvt->is_lockstep)\n\t\t*channel_mask |= 1 << ((channel + 1) % 4);\n\n\treturn 0;\n}\n\n \n\n \nstatic void sbridge_put_devices(struct sbridge_dev *sbridge_dev)\n{\n\tint i;\n\n\tedac_dbg(0, \"\\n\");\n\tfor (i = 0; i < sbridge_dev->n_devs; i++) {\n\t\tstruct pci_dev *pdev = sbridge_dev->pdev[i];\n\t\tif (!pdev)\n\t\t\tcontinue;\n\t\tedac_dbg(0, \"Removing dev %02x:%02x.%d\\n\",\n\t\t\t pdev->bus->number,\n\t\t\t PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn));\n\t\tpci_dev_put(pdev);\n\t}\n}\n\nstatic void sbridge_put_all_devices(void)\n{\n\tstruct sbridge_dev *sbridge_dev, *tmp;\n\n\tlist_for_each_entry_safe(sbridge_dev, tmp, &sbridge_edac_list, list) {\n\t\tsbridge_put_devices(sbridge_dev);\n\t\tfree_sbridge_dev(sbridge_dev);\n\t}\n}\n\nstatic int sbridge_get_onedevice(struct pci_dev **prev,\n\t\t\t\t u8 *num_mc,\n\t\t\t\t const struct pci_id_table *table,\n\t\t\t\t const unsigned devno,\n\t\t\t\t const int multi_bus)\n{\n\tstruct sbridge_dev *sbridge_dev = NULL;\n\tconst struct pci_id_descr *dev_descr = &table->descr[devno];\n\tstruct pci_dev *pdev = NULL;\n\tint seg = 0;\n\tu8 bus = 0;\n\tint i = 0;\n\n\tsbridge_printk(KERN_DEBUG,\n\t\t\"Seeking for: PCI ID %04x:%04x\\n\",\n\t\tPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\n\n\tpdev = pci_get_device(PCI_VENDOR_ID_INTEL,\n\t\t\t      dev_descr->dev_id, *prev);\n\n\tif (!pdev) {\n\t\tif (*prev) {\n\t\t\t*prev = pdev;\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (dev_descr->optional)\n\t\t\treturn 0;\n\n\t\t \n\t\tif (devno == 0)\n\t\t\treturn -ENODEV;\n\n\t\tsbridge_printk(KERN_INFO,\n\t\t\t\"Device not found: %04x:%04x\\n\",\n\t\t\tPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\n\n\t\t \n\t\treturn -ENODEV;\n\t}\n\tseg = pci_domain_nr(pdev->bus);\n\tbus = pdev->bus->number;\n\nnext_imc:\n\tsbridge_dev = get_sbridge_dev(seg, bus, dev_descr->dom,\n\t\t\t\t      multi_bus, sbridge_dev);\n\tif (!sbridge_dev) {\n\t\t \n\t\tif (dev_descr->dom == IMC1 && devno != 1) {\n\t\t\tedac_dbg(0, \"Skip IMC1: %04x:%04x (since HA1 was absent)\\n\",\n\t\t\t\t PCI_VENDOR_ID_INTEL, dev_descr->dev_id);\n\t\t\tpci_dev_put(pdev);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (dev_descr->dom == SOCK)\n\t\t\tgoto out_imc;\n\n\t\tsbridge_dev = alloc_sbridge_dev(seg, bus, dev_descr->dom, table);\n\t\tif (!sbridge_dev) {\n\t\t\tpci_dev_put(pdev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\t(*num_mc)++;\n\t}\n\n\tif (sbridge_dev->pdev[sbridge_dev->i_devs]) {\n\t\tsbridge_printk(KERN_ERR,\n\t\t\t\"Duplicated device for %04x:%04x\\n\",\n\t\t\tPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\n\t\tpci_dev_put(pdev);\n\t\treturn -ENODEV;\n\t}\n\n\tsbridge_dev->pdev[sbridge_dev->i_devs++] = pdev;\n\n\t \n\tif (++i > 1)\n\t\tpci_dev_get(pdev);\n\n\tif (dev_descr->dom == SOCK && i < table->n_imcs_per_sock)\n\t\tgoto next_imc;\n\nout_imc:\n\t \n\tif (unlikely(pci_enable_device(pdev) < 0)) {\n\t\tsbridge_printk(KERN_ERR,\n\t\t\t\"Couldn't enable %04x:%04x\\n\",\n\t\t\tPCI_VENDOR_ID_INTEL, dev_descr->dev_id);\n\t\treturn -ENODEV;\n\t}\n\n\tedac_dbg(0, \"Detected %04x:%04x\\n\",\n\t\t PCI_VENDOR_ID_INTEL, dev_descr->dev_id);\n\n\t \n\tpci_dev_get(pdev);\n\n\t*prev = pdev;\n\n\treturn 0;\n}\n\n \nstatic int sbridge_get_all_devices(u8 *num_mc,\n\t\t\t\t\tconst struct pci_id_table *table)\n{\n\tint i, rc;\n\tstruct pci_dev *pdev = NULL;\n\tint allow_dups = 0;\n\tint multi_bus = 0;\n\n\tif (table->type == KNIGHTS_LANDING)\n\t\tallow_dups = multi_bus = 1;\n\twhile (table && table->descr) {\n\t\tfor (i = 0; i < table->n_devs_per_sock; i++) {\n\t\t\tif (!allow_dups || i == 0 ||\n\t\t\t\t\ttable->descr[i].dev_id !=\n\t\t\t\t\t\ttable->descr[i-1].dev_id) {\n\t\t\t\tpdev = NULL;\n\t\t\t}\n\t\t\tdo {\n\t\t\t\trc = sbridge_get_onedevice(&pdev, num_mc,\n\t\t\t\t\t\t\t   table, i, multi_bus);\n\t\t\t\tif (rc < 0) {\n\t\t\t\t\tif (i == 0) {\n\t\t\t\t\t\ti = table->n_devs_per_sock;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tsbridge_put_all_devices();\n\t\t\t\t\treturn -ENODEV;\n\t\t\t\t}\n\t\t\t} while (pdev && !allow_dups);\n\t\t}\n\t\ttable++;\n\t}\n\n\treturn 0;\n}\n\n \n#define TAD_DEV_TO_CHAN(dev) (((dev) & 0xf) - 0xa)\n\nstatic int sbridge_mci_bind_devs(struct mem_ctl_info *mci,\n\t\t\t\t struct sbridge_dev *sbridge_dev)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tstruct pci_dev *pdev;\n\tu8 saw_chan_mask = 0;\n\tint i;\n\n\tfor (i = 0; i < sbridge_dev->n_devs; i++) {\n\t\tpdev = sbridge_dev->pdev[i];\n\t\tif (!pdev)\n\t\t\tcontinue;\n\n\t\tswitch (pdev->device) {\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_SAD0:\n\t\t\tpvt->pci_sad0 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_SAD1:\n\t\t\tpvt->pci_sad1 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_BR:\n\t\t\tpvt->pci_br0 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_HA0:\n\t\t\tpvt->pci_ha = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TA:\n\t\t\tpvt->pci_ta = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_RAS:\n\t\t\tpvt->pci_ras = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD0:\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD1:\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD2:\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_TAD3:\n\t\t{\n\t\t\tint id = TAD_DEV_TO_CHAN(pdev->device);\n\t\t\tpvt->pci_tad[id] = pdev;\n\t\t\tsaw_chan_mask |= 1 << id;\n\t\t}\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_SBRIDGE_IMC_DDRIO:\n\t\t\tpvt->pci_ddrio = pdev;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto error;\n\t\t}\n\n\t\tedac_dbg(0, \"Associated PCI %02x:%02x, bus %d with dev = %p\\n\",\n\t\t\t pdev->vendor, pdev->device,\n\t\t\t sbridge_dev->bus,\n\t\t\t pdev);\n\t}\n\n\t \n\tif (!pvt->pci_sad0 || !pvt->pci_sad1 || !pvt->pci_ha ||\n\t    !pvt->pci_ras || !pvt->pci_ta)\n\t\tgoto enodev;\n\n\tif (saw_chan_mask != 0x0f)\n\t\tgoto enodev;\n\treturn 0;\n\nenodev:\n\tsbridge_printk(KERN_ERR, \"Some needed devices are missing\\n\");\n\treturn -ENODEV;\n\nerror:\n\tsbridge_printk(KERN_ERR, \"Unexpected device %02x:%02x\\n\",\n\t\t       PCI_VENDOR_ID_INTEL, pdev->device);\n\treturn -EINVAL;\n}\n\nstatic int ibridge_mci_bind_devs(struct mem_ctl_info *mci,\n\t\t\t\t struct sbridge_dev *sbridge_dev)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tstruct pci_dev *pdev;\n\tu8 saw_chan_mask = 0;\n\tint i;\n\n\tfor (i = 0; i < sbridge_dev->n_devs; i++) {\n\t\tpdev = sbridge_dev->pdev[i];\n\t\tif (!pdev)\n\t\t\tcontinue;\n\n\t\tswitch (pdev->device) {\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1:\n\t\t\tpvt->pci_ha = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TA:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TA:\n\t\t\tpvt->pci_ta = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_RAS:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_RAS:\n\t\t\tpvt->pci_ras = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD0:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD1:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD2:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA0_TAD3:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD0:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD1:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD2:\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_HA1_TAD3:\n\t\t{\n\t\t\tint id = TAD_DEV_TO_CHAN(pdev->device);\n\t\t\tpvt->pci_tad[id] = pdev;\n\t\t\tsaw_chan_mask |= 1 << id;\n\t\t}\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_2HA_DDRIO0:\n\t\t\tpvt->pci_ddrio = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_IMC_1HA_DDRIO0:\n\t\t\tpvt->pci_ddrio = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_SAD:\n\t\t\tpvt->pci_sad0 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_BR0:\n\t\t\tpvt->pci_br0 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_IBRIDGE_BR1:\n\t\t\tpvt->pci_br1 = pdev;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto error;\n\t\t}\n\n\t\tedac_dbg(0, \"Associated PCI %02x.%02d.%d with dev = %p\\n\",\n\t\t\t sbridge_dev->bus,\n\t\t\t PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn),\n\t\t\t pdev);\n\t}\n\n\t \n\tif (!pvt->pci_sad0 || !pvt->pci_ha || !pvt->pci_br0 ||\n\t    !pvt->pci_br1 || !pvt->pci_ras || !pvt->pci_ta)\n\t\tgoto enodev;\n\n\tif (saw_chan_mask != 0x0f &&  \n\t    saw_chan_mask != 0x03)    \n\t\tgoto enodev;\n\treturn 0;\n\nenodev:\n\tsbridge_printk(KERN_ERR, \"Some needed devices are missing\\n\");\n\treturn -ENODEV;\n\nerror:\n\tsbridge_printk(KERN_ERR,\n\t\t       \"Unexpected device %02x:%02x\\n\", PCI_VENDOR_ID_INTEL,\n\t\t\tpdev->device);\n\treturn -EINVAL;\n}\n\nstatic int haswell_mci_bind_devs(struct mem_ctl_info *mci,\n\t\t\t\t struct sbridge_dev *sbridge_dev)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tstruct pci_dev *pdev;\n\tu8 saw_chan_mask = 0;\n\tint i;\n\n\t \n\tif (pvt->info.pci_vtd == NULL)\n\t\t \n\t\tpvt->info.pci_vtd = pci_get_device(PCI_VENDOR_ID_INTEL,\n\t\t\t\t\t\t   PCI_DEVICE_ID_INTEL_HASWELL_IMC_VTD_MISC,\n\t\t\t\t\t\t   NULL);\n\n\tfor (i = 0; i < sbridge_dev->n_devs; i++) {\n\t\tpdev = sbridge_dev->pdev[i];\n\t\tif (!pdev)\n\t\t\tcontinue;\n\n\t\tswitch (pdev->device) {\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_CBO_SAD0:\n\t\t\tpvt->pci_sad0 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_CBO_SAD1:\n\t\t\tpvt->pci_sad1 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1:\n\t\t\tpvt->pci_ha = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TA:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TA:\n\t\t\tpvt->pci_ta = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TM:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TM:\n\t\t\tpvt->pci_ras = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD0:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD1:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD2:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA0_TAD3:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD0:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD1:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD2:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_HA1_TAD3:\n\t\t{\n\t\t\tint id = TAD_DEV_TO_CHAN(pdev->device);\n\t\t\tpvt->pci_tad[id] = pdev;\n\t\t\tsaw_chan_mask |= 1 << id;\n\t\t}\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO0:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO1:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO2:\n\t\tcase PCI_DEVICE_ID_INTEL_HASWELL_IMC_DDRIO3:\n\t\t\tif (!pvt->pci_ddrio)\n\t\t\t\tpvt->pci_ddrio = pdev;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tedac_dbg(0, \"Associated PCI %02x.%02d.%d with dev = %p\\n\",\n\t\t\t sbridge_dev->bus,\n\t\t\t PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn),\n\t\t\t pdev);\n\t}\n\n\t \n\tif (!pvt->pci_sad0 || !pvt->pci_ha || !pvt->pci_sad1 ||\n\t    !pvt->pci_ras  || !pvt->pci_ta || !pvt->info.pci_vtd)\n\t\tgoto enodev;\n\n\tif (saw_chan_mask != 0x0f &&  \n\t    saw_chan_mask != 0x03)    \n\t\tgoto enodev;\n\treturn 0;\n\nenodev:\n\tsbridge_printk(KERN_ERR, \"Some needed devices are missing\\n\");\n\treturn -ENODEV;\n}\n\nstatic int broadwell_mci_bind_devs(struct mem_ctl_info *mci,\n\t\t\t\t struct sbridge_dev *sbridge_dev)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tstruct pci_dev *pdev;\n\tu8 saw_chan_mask = 0;\n\tint i;\n\n\t \n\tif (pvt->info.pci_vtd == NULL)\n\t\t \n\t\tpvt->info.pci_vtd = pci_get_device(PCI_VENDOR_ID_INTEL,\n\t\t\t\t\t\t   PCI_DEVICE_ID_INTEL_BROADWELL_IMC_VTD_MISC,\n\t\t\t\t\t\t   NULL);\n\n\tfor (i = 0; i < sbridge_dev->n_devs; i++) {\n\t\tpdev = sbridge_dev->pdev[i];\n\t\tif (!pdev)\n\t\t\tcontinue;\n\n\t\tswitch (pdev->device) {\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_CBO_SAD0:\n\t\t\tpvt->pci_sad0 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_CBO_SAD1:\n\t\t\tpvt->pci_sad1 = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1:\n\t\t\tpvt->pci_ha = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TA:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TA:\n\t\t\tpvt->pci_ta = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TM:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TM:\n\t\t\tpvt->pci_ras = pdev;\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD0:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD1:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD2:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA0_TAD3:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD0:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD1:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD2:\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_HA1_TAD3:\n\t\t{\n\t\t\tint id = TAD_DEV_TO_CHAN(pdev->device);\n\t\t\tpvt->pci_tad[id] = pdev;\n\t\t\tsaw_chan_mask |= 1 << id;\n\t\t}\n\t\t\tbreak;\n\t\tcase PCI_DEVICE_ID_INTEL_BROADWELL_IMC_DDRIO0:\n\t\t\tpvt->pci_ddrio = pdev;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tedac_dbg(0, \"Associated PCI %02x.%02d.%d with dev = %p\\n\",\n\t\t\t sbridge_dev->bus,\n\t\t\t PCI_SLOT(pdev->devfn), PCI_FUNC(pdev->devfn),\n\t\t\t pdev);\n\t}\n\n\t \n\tif (!pvt->pci_sad0 || !pvt->pci_ha || !pvt->pci_sad1 ||\n\t    !pvt->pci_ras  || !pvt->pci_ta || !pvt->info.pci_vtd)\n\t\tgoto enodev;\n\n\tif (saw_chan_mask != 0x0f &&  \n\t    saw_chan_mask != 0x03)    \n\t\tgoto enodev;\n\treturn 0;\n\nenodev:\n\tsbridge_printk(KERN_ERR, \"Some needed devices are missing\\n\");\n\treturn -ENODEV;\n}\n\nstatic int knl_mci_bind_devs(struct mem_ctl_info *mci,\n\t\t\tstruct sbridge_dev *sbridge_dev)\n{\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tstruct pci_dev *pdev;\n\tint dev, func;\n\n\tint i;\n\tint devidx;\n\n\tfor (i = 0; i < sbridge_dev->n_devs; i++) {\n\t\tpdev = sbridge_dev->pdev[i];\n\t\tif (!pdev)\n\t\t\tcontinue;\n\n\t\t \n\t\tdev = (pdev->devfn >> 3) & 0x1f;\n\t\tfunc = pdev->devfn & 0x7;\n\n\t\tswitch (pdev->device) {\n\t\tcase PCI_DEVICE_ID_INTEL_KNL_IMC_MC:\n\t\t\tif (dev == 8)\n\t\t\t\tpvt->knl.pci_mc0 = pdev;\n\t\t\telse if (dev == 9)\n\t\t\t\tpvt->knl.pci_mc1 = pdev;\n\t\t\telse {\n\t\t\t\tsbridge_printk(KERN_ERR,\n\t\t\t\t\t\"Memory controller in unexpected place! (dev %d, fn %d)\\n\",\n\t\t\t\t\tdev, func);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PCI_DEVICE_ID_INTEL_KNL_IMC_SAD0:\n\t\t\tpvt->pci_sad0 = pdev;\n\t\t\tbreak;\n\n\t\tcase PCI_DEVICE_ID_INTEL_KNL_IMC_SAD1:\n\t\t\tpvt->pci_sad1 = pdev;\n\t\t\tbreak;\n\n\t\tcase PCI_DEVICE_ID_INTEL_KNL_IMC_CHA:\n\t\t\t \n\t\t\tdevidx = ((dev-14)*8)+func;\n\n\t\t\tif (devidx < 0 || devidx >= KNL_MAX_CHAS) {\n\t\t\t\tsbridge_printk(KERN_ERR,\n\t\t\t\t\t\"Caching and Home Agent in unexpected place! (dev %d, fn %d)\\n\",\n\t\t\t\t\tdev, func);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tWARN_ON(pvt->knl.pci_cha[devidx] != NULL);\n\n\t\t\tpvt->knl.pci_cha[devidx] = pdev;\n\t\t\tbreak;\n\n\t\tcase PCI_DEVICE_ID_INTEL_KNL_IMC_CHAN:\n\t\t\tdevidx = -1;\n\n\t\t\t \n\n\t\t\tif (dev == 9)\n\t\t\t\tdevidx = func-2;\n\t\t\telse if (dev == 8)\n\t\t\t\tdevidx = 3 + (func-2);\n\n\t\t\tif (devidx < 0 || devidx >= KNL_MAX_CHANNELS) {\n\t\t\t\tsbridge_printk(KERN_ERR,\n\t\t\t\t\t\"DRAM Channel Registers in unexpected place! (dev %d, fn %d)\\n\",\n\t\t\t\t\tdev, func);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tWARN_ON(pvt->knl.pci_channel[devidx] != NULL);\n\t\t\tpvt->knl.pci_channel[devidx] = pdev;\n\t\t\tbreak;\n\n\t\tcase PCI_DEVICE_ID_INTEL_KNL_IMC_TOLHM:\n\t\t\tpvt->knl.pci_mc_info = pdev;\n\t\t\tbreak;\n\n\t\tcase PCI_DEVICE_ID_INTEL_KNL_IMC_TA:\n\t\t\tpvt->pci_ta = pdev;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tsbridge_printk(KERN_ERR, \"Unexpected device %d\\n\",\n\t\t\t\tpdev->device);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!pvt->knl.pci_mc0  || !pvt->knl.pci_mc1 ||\n\t    !pvt->pci_sad0     || !pvt->pci_sad1    ||\n\t    !pvt->pci_ta) {\n\t\tgoto enodev;\n\t}\n\n\tfor (i = 0; i < KNL_MAX_CHANNELS; i++) {\n\t\tif (!pvt->knl.pci_channel[i]) {\n\t\t\tsbridge_printk(KERN_ERR, \"Missing channel %d\\n\", i);\n\t\t\tgoto enodev;\n\t\t}\n\t}\n\n\tfor (i = 0; i < KNL_MAX_CHAS; i++) {\n\t\tif (!pvt->knl.pci_cha[i]) {\n\t\t\tsbridge_printk(KERN_ERR, \"Missing CHA %d\\n\", i);\n\t\t\tgoto enodev;\n\t\t}\n\t}\n\n\treturn 0;\n\nenodev:\n\tsbridge_printk(KERN_ERR, \"Some needed devices are missing\\n\");\n\treturn -ENODEV;\n}\n\n \n\n \nstatic void sbridge_mce_output_error(struct mem_ctl_info *mci,\n\t\t\t\t    const struct mce *m)\n{\n\tstruct mem_ctl_info *new_mci;\n\tstruct sbridge_pvt *pvt = mci->pvt_info;\n\tenum hw_event_mc_err_type tp_event;\n\tchar *optype, msg[256], msg_full[512];\n\tbool ripv = GET_BITFIELD(m->mcgstatus, 0, 0);\n\tbool overflow = GET_BITFIELD(m->status, 62, 62);\n\tbool uncorrected_error = GET_BITFIELD(m->status, 61, 61);\n\tbool recoverable;\n\tu32 core_err_cnt = GET_BITFIELD(m->status, 38, 52);\n\tu32 mscod = GET_BITFIELD(m->status, 16, 31);\n\tu32 errcode = GET_BITFIELD(m->status, 0, 15);\n\tu32 channel = GET_BITFIELD(m->status, 0, 3);\n\tu32 optypenum = GET_BITFIELD(m->status, 4, 6);\n\t \n\tu32 lsb = GET_BITFIELD(m->misc, 0, 5);\n\tlong channel_mask, first_channel;\n\tu8  rank = 0xff, socket, ha;\n\tint rc, dimm;\n\tchar *area_type = \"DRAM\";\n\n\tif (pvt->info.type != SANDY_BRIDGE)\n\t\trecoverable = true;\n\telse\n\t\trecoverable = GET_BITFIELD(m->status, 56, 56);\n\n\tif (uncorrected_error) {\n\t\tcore_err_cnt = 1;\n\t\tif (ripv) {\n\t\t\ttp_event = HW_EVENT_ERR_UNCORRECTED;\n\t\t} else {\n\t\t\ttp_event = HW_EVENT_ERR_FATAL;\n\t\t}\n\t} else {\n\t\ttp_event = HW_EVENT_ERR_CORRECTED;\n\t}\n\n\t \n\tswitch (optypenum) {\n\tcase 0:\n\t\toptype = \"generic undef request error\";\n\t\tbreak;\n\tcase 1:\n\t\toptype = \"memory read error\";\n\t\tbreak;\n\tcase 2:\n\t\toptype = \"memory write error\";\n\t\tbreak;\n\tcase 3:\n\t\toptype = \"addr/cmd error\";\n\t\tbreak;\n\tcase 4:\n\t\toptype = \"memory scrubbing error\";\n\t\tbreak;\n\tdefault:\n\t\toptype = \"reserved\";\n\t\tbreak;\n\t}\n\n\tif (pvt->info.type == KNIGHTS_LANDING) {\n\t\tif (channel == 14) {\n\t\t\tedac_dbg(0, \"%s%s err_code:%04x:%04x EDRAM bank %d\\n\",\n\t\t\t\toverflow ? \" OVERFLOW\" : \"\",\n\t\t\t\t(uncorrected_error && recoverable)\n\t\t\t\t? \" recoverable\" : \"\",\n\t\t\t\tmscod, errcode,\n\t\t\t\tm->bank);\n\t\t} else {\n\t\t\tchar A = *(\"A\");\n\n\t\t\t \n\t\t\tchannel = knl_channel_remap(m->bank == 16, channel);\n\t\t\tchannel_mask = 1 << channel;\n\n\t\t\tsnprintf(msg, sizeof(msg),\n\t\t\t\t\"%s%s err_code:%04x:%04x channel:%d (DIMM_%c)\",\n\t\t\t\toverflow ? \" OVERFLOW\" : \"\",\n\t\t\t\t(uncorrected_error && recoverable)\n\t\t\t\t? \" recoverable\" : \" \",\n\t\t\t\tmscod, errcode, channel, A + channel);\n\t\t\tedac_mc_handle_error(tp_event, mci, core_err_cnt,\n\t\t\t\tm->addr >> PAGE_SHIFT, m->addr & ~PAGE_MASK, 0,\n\t\t\t\tchannel, 0, -1,\n\t\t\t\toptype, msg);\n\t\t}\n\t\treturn;\n\t} else if (lsb < 12) {\n\t\trc = get_memory_error_data(mci, m->addr, &socket, &ha,\n\t\t\t\t\t   &channel_mask, &rank,\n\t\t\t\t\t   &area_type, msg);\n\t} else {\n\t\trc = get_memory_error_data_from_mce(mci, m, &socket, &ha,\n\t\t\t\t\t\t    &channel_mask, msg);\n\t}\n\n\tif (rc < 0)\n\t\tgoto err_parsing;\n\tnew_mci = get_mci_for_node_id(socket, ha);\n\tif (!new_mci) {\n\t\tstrcpy(msg, \"Error: socket got corrupted!\");\n\t\tgoto err_parsing;\n\t}\n\tmci = new_mci;\n\tpvt = mci->pvt_info;\n\n\tfirst_channel = find_first_bit(&channel_mask, NUM_CHANNELS);\n\n\tif (rank == 0xff)\n\t\tdimm = -1;\n\telse if (rank < 4)\n\t\tdimm = 0;\n\telse if (rank < 8)\n\t\tdimm = 1;\n\telse\n\t\tdimm = 2;\n\n\t \n\tif (!pvt->is_lockstep && !pvt->is_cur_addr_mirrored && !pvt->is_close_pg)\n\t\tchannel = first_channel;\n\tsnprintf(msg_full, sizeof(msg_full),\n\t\t \"%s%s area:%s err_code:%04x:%04x socket:%d ha:%d channel_mask:%ld rank:%d %s\",\n\t\t overflow ? \" OVERFLOW\" : \"\",\n\t\t (uncorrected_error && recoverable) ? \" recoverable\" : \"\",\n\t\t area_type,\n\t\t mscod, errcode,\n\t\t socket, ha,\n\t\t channel_mask,\n\t\t rank, msg);\n\n\tedac_dbg(0, \"%s\\n\", msg_full);\n\n\t \n\n\tif (channel == CHANNEL_UNSPECIFIED)\n\t\tchannel = -1;\n\n\t \n\tedac_mc_handle_error(tp_event, mci, core_err_cnt,\n\t\t\t     m->addr >> PAGE_SHIFT, m->addr & ~PAGE_MASK, 0,\n\t\t\t     channel, dimm, -1,\n\t\t\t     optype, msg_full);\n\treturn;\nerr_parsing:\n\tedac_mc_handle_error(tp_event, mci, core_err_cnt, 0, 0, 0,\n\t\t\t     -1, -1, -1,\n\t\t\t     msg, \"\");\n\n}\n\n \nstatic int sbridge_mce_check_error(struct notifier_block *nb, unsigned long val,\n\t\t\t\t   void *data)\n{\n\tstruct mce *mce = (struct mce *)data;\n\tstruct mem_ctl_info *mci;\n\tchar *type;\n\n\tif (mce->kflags & MCE_HANDLED_CEC)\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif ((mce->status & 0xefff) >> 7 != 1)\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif (!GET_BITFIELD(mce->status, 58, 58))\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif (!GET_BITFIELD(mce->status, 59, 59))\n\t\treturn NOTIFY_DONE;\n\n\t \n\tif (GET_BITFIELD(mce->misc, 6, 8) != 2)\n\t\treturn NOTIFY_DONE;\n\n\tmci = get_mci_for_node_id(mce->socketid, IMC0);\n\tif (!mci)\n\t\treturn NOTIFY_DONE;\n\n\tif (mce->mcgstatus & MCG_STATUS_MCIP)\n\t\ttype = \"Exception\";\n\telse\n\t\ttype = \"Event\";\n\n\tsbridge_mc_printk(mci, KERN_DEBUG, \"HANDLING MCE MEMORY ERROR\\n\");\n\n\tsbridge_mc_printk(mci, KERN_DEBUG, \"CPU %d: Machine Check %s: %Lx \"\n\t\t\t  \"Bank %d: %016Lx\\n\", mce->extcpu, type,\n\t\t\t  mce->mcgstatus, mce->bank, mce->status);\n\tsbridge_mc_printk(mci, KERN_DEBUG, \"TSC %llx \", mce->tsc);\n\tsbridge_mc_printk(mci, KERN_DEBUG, \"ADDR %llx \", mce->addr);\n\tsbridge_mc_printk(mci, KERN_DEBUG, \"MISC %llx \", mce->misc);\n\n\tsbridge_mc_printk(mci, KERN_DEBUG, \"PROCESSOR %u:%x TIME %llu SOCKET \"\n\t\t\t  \"%u APIC %x\\n\", mce->cpuvendor, mce->cpuid,\n\t\t\t  mce->time, mce->socketid, mce->apicid);\n\n\tsbridge_mce_output_error(mci, mce);\n\n\t \n\tmce->kflags |= MCE_HANDLED_EDAC;\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block sbridge_mce_dec = {\n\t.notifier_call\t= sbridge_mce_check_error,\n\t.priority\t= MCE_PRIO_EDAC,\n};\n\n \n\nstatic void sbridge_unregister_mci(struct sbridge_dev *sbridge_dev)\n{\n\tstruct mem_ctl_info *mci = sbridge_dev->mci;\n\n\tif (unlikely(!mci || !mci->pvt_info)) {\n\t\tedac_dbg(0, \"MC: dev = %p\\n\", &sbridge_dev->pdev[0]->dev);\n\n\t\tsbridge_printk(KERN_ERR, \"Couldn't find mci handler\\n\");\n\t\treturn;\n\t}\n\n\tedac_dbg(0, \"MC: mci = %p, dev = %p\\n\",\n\t\t mci, &sbridge_dev->pdev[0]->dev);\n\n\t \n\tedac_mc_del_mc(mci->pdev);\n\n\tedac_dbg(1, \"%s: free mci struct\\n\", mci->ctl_name);\n\tkfree(mci->ctl_name);\n\tedac_mc_free(mci);\n\tsbridge_dev->mci = NULL;\n}\n\nstatic int sbridge_register_mci(struct sbridge_dev *sbridge_dev, enum type type)\n{\n\tstruct mem_ctl_info *mci;\n\tstruct edac_mc_layer layers[2];\n\tstruct sbridge_pvt *pvt;\n\tstruct pci_dev *pdev = sbridge_dev->pdev[0];\n\tint rc;\n\n\t \n\tlayers[0].type = EDAC_MC_LAYER_CHANNEL;\n\tlayers[0].size = type == KNIGHTS_LANDING ?\n\t\tKNL_MAX_CHANNELS : NUM_CHANNELS;\n\tlayers[0].is_virt_csrow = false;\n\tlayers[1].type = EDAC_MC_LAYER_SLOT;\n\tlayers[1].size = type == KNIGHTS_LANDING ? 1 : MAX_DIMMS;\n\tlayers[1].is_virt_csrow = true;\n\tmci = edac_mc_alloc(sbridge_dev->mc, ARRAY_SIZE(layers), layers,\n\t\t\t    sizeof(*pvt));\n\n\tif (unlikely(!mci))\n\t\treturn -ENOMEM;\n\n\tedac_dbg(0, \"MC: mci = %p, dev = %p\\n\",\n\t\t mci, &pdev->dev);\n\n\tpvt = mci->pvt_info;\n\tmemset(pvt, 0, sizeof(*pvt));\n\n\t \n\tpvt->sbridge_dev = sbridge_dev;\n\tsbridge_dev->mci = mci;\n\n\tmci->mtype_cap = type == KNIGHTS_LANDING ?\n\t\tMEM_FLAG_DDR4 : MEM_FLAG_DDR3;\n\tmci->edac_ctl_cap = EDAC_FLAG_NONE;\n\tmci->edac_cap = EDAC_FLAG_NONE;\n\tmci->mod_name = EDAC_MOD_STR;\n\tmci->dev_name = pci_name(pdev);\n\tmci->ctl_page_to_phys = NULL;\n\n\tpvt->info.type = type;\n\tswitch (type) {\n\tcase IVY_BRIDGE:\n\t\tpvt->info.rankcfgr = IB_RANK_CFG_A;\n\t\tpvt->info.get_tolm = ibridge_get_tolm;\n\t\tpvt->info.get_tohm = ibridge_get_tohm;\n\t\tpvt->info.dram_rule = ibridge_dram_rule;\n\t\tpvt->info.get_memory_type = get_memory_type;\n\t\tpvt->info.get_node_id = get_node_id;\n\t\tpvt->info.get_ha = ibridge_get_ha;\n\t\tpvt->info.rir_limit = rir_limit;\n\t\tpvt->info.sad_limit = sad_limit;\n\t\tpvt->info.interleave_mode = interleave_mode;\n\t\tpvt->info.dram_attr = dram_attr;\n\t\tpvt->info.max_sad = ARRAY_SIZE(ibridge_dram_rule);\n\t\tpvt->info.interleave_list = ibridge_interleave_list;\n\t\tpvt->info.interleave_pkg = ibridge_interleave_pkg;\n\t\tpvt->info.get_width = ibridge_get_width;\n\n\t\t \n\t\trc = ibridge_mci_bind_devs(mci, sbridge_dev);\n\t\tif (unlikely(rc < 0))\n\t\t\tgoto fail0;\n\t\tget_source_id(mci);\n\t\tmci->ctl_name = kasprintf(GFP_KERNEL, \"Ivy Bridge SrcID#%d_Ha#%d\",\n\t\t\tpvt->sbridge_dev->source_id, pvt->sbridge_dev->dom);\n\t\tbreak;\n\tcase SANDY_BRIDGE:\n\t\tpvt->info.rankcfgr = SB_RANK_CFG_A;\n\t\tpvt->info.get_tolm = sbridge_get_tolm;\n\t\tpvt->info.get_tohm = sbridge_get_tohm;\n\t\tpvt->info.dram_rule = sbridge_dram_rule;\n\t\tpvt->info.get_memory_type = get_memory_type;\n\t\tpvt->info.get_node_id = get_node_id;\n\t\tpvt->info.get_ha = sbridge_get_ha;\n\t\tpvt->info.rir_limit = rir_limit;\n\t\tpvt->info.sad_limit = sad_limit;\n\t\tpvt->info.interleave_mode = interleave_mode;\n\t\tpvt->info.dram_attr = dram_attr;\n\t\tpvt->info.max_sad = ARRAY_SIZE(sbridge_dram_rule);\n\t\tpvt->info.interleave_list = sbridge_interleave_list;\n\t\tpvt->info.interleave_pkg = sbridge_interleave_pkg;\n\t\tpvt->info.get_width = sbridge_get_width;\n\n\t\t \n\t\trc = sbridge_mci_bind_devs(mci, sbridge_dev);\n\t\tif (unlikely(rc < 0))\n\t\t\tgoto fail0;\n\t\tget_source_id(mci);\n\t\tmci->ctl_name = kasprintf(GFP_KERNEL, \"Sandy Bridge SrcID#%d_Ha#%d\",\n\t\t\tpvt->sbridge_dev->source_id, pvt->sbridge_dev->dom);\n\t\tbreak;\n\tcase HASWELL:\n\t\t \n\t\tpvt->info.get_tolm = haswell_get_tolm;\n\t\tpvt->info.get_tohm = haswell_get_tohm;\n\t\tpvt->info.dram_rule = ibridge_dram_rule;\n\t\tpvt->info.get_memory_type = haswell_get_memory_type;\n\t\tpvt->info.get_node_id = haswell_get_node_id;\n\t\tpvt->info.get_ha = ibridge_get_ha;\n\t\tpvt->info.rir_limit = haswell_rir_limit;\n\t\tpvt->info.sad_limit = sad_limit;\n\t\tpvt->info.interleave_mode = interleave_mode;\n\t\tpvt->info.dram_attr = dram_attr;\n\t\tpvt->info.max_sad = ARRAY_SIZE(ibridge_dram_rule);\n\t\tpvt->info.interleave_list = ibridge_interleave_list;\n\t\tpvt->info.interleave_pkg = ibridge_interleave_pkg;\n\t\tpvt->info.get_width = ibridge_get_width;\n\n\t\t \n\t\trc = haswell_mci_bind_devs(mci, sbridge_dev);\n\t\tif (unlikely(rc < 0))\n\t\t\tgoto fail0;\n\t\tget_source_id(mci);\n\t\tmci->ctl_name = kasprintf(GFP_KERNEL, \"Haswell SrcID#%d_Ha#%d\",\n\t\t\tpvt->sbridge_dev->source_id, pvt->sbridge_dev->dom);\n\t\tbreak;\n\tcase BROADWELL:\n\t\t \n\t\tpvt->info.get_tolm = haswell_get_tolm;\n\t\tpvt->info.get_tohm = haswell_get_tohm;\n\t\tpvt->info.dram_rule = ibridge_dram_rule;\n\t\tpvt->info.get_memory_type = haswell_get_memory_type;\n\t\tpvt->info.get_node_id = haswell_get_node_id;\n\t\tpvt->info.get_ha = ibridge_get_ha;\n\t\tpvt->info.rir_limit = haswell_rir_limit;\n\t\tpvt->info.sad_limit = sad_limit;\n\t\tpvt->info.interleave_mode = interleave_mode;\n\t\tpvt->info.dram_attr = dram_attr;\n\t\tpvt->info.max_sad = ARRAY_SIZE(ibridge_dram_rule);\n\t\tpvt->info.interleave_list = ibridge_interleave_list;\n\t\tpvt->info.interleave_pkg = ibridge_interleave_pkg;\n\t\tpvt->info.get_width = broadwell_get_width;\n\n\t\t \n\t\trc = broadwell_mci_bind_devs(mci, sbridge_dev);\n\t\tif (unlikely(rc < 0))\n\t\t\tgoto fail0;\n\t\tget_source_id(mci);\n\t\tmci->ctl_name = kasprintf(GFP_KERNEL, \"Broadwell SrcID#%d_Ha#%d\",\n\t\t\tpvt->sbridge_dev->source_id, pvt->sbridge_dev->dom);\n\t\tbreak;\n\tcase KNIGHTS_LANDING:\n\t\t \n\t\tpvt->info.get_tolm = knl_get_tolm;\n\t\tpvt->info.get_tohm = knl_get_tohm;\n\t\tpvt->info.dram_rule = knl_dram_rule;\n\t\tpvt->info.get_memory_type = knl_get_memory_type;\n\t\tpvt->info.get_node_id = knl_get_node_id;\n\t\tpvt->info.get_ha = knl_get_ha;\n\t\tpvt->info.rir_limit = NULL;\n\t\tpvt->info.sad_limit = knl_sad_limit;\n\t\tpvt->info.interleave_mode = knl_interleave_mode;\n\t\tpvt->info.dram_attr = dram_attr_knl;\n\t\tpvt->info.max_sad = ARRAY_SIZE(knl_dram_rule);\n\t\tpvt->info.interleave_list = knl_interleave_list;\n\t\tpvt->info.interleave_pkg = ibridge_interleave_pkg;\n\t\tpvt->info.get_width = knl_get_width;\n\n\t\trc = knl_mci_bind_devs(mci, sbridge_dev);\n\t\tif (unlikely(rc < 0))\n\t\t\tgoto fail0;\n\t\tget_source_id(mci);\n\t\tmci->ctl_name = kasprintf(GFP_KERNEL, \"Knights Landing SrcID#%d_Ha#%d\",\n\t\t\tpvt->sbridge_dev->source_id, pvt->sbridge_dev->dom);\n\t\tbreak;\n\t}\n\n\tif (!mci->ctl_name) {\n\t\trc = -ENOMEM;\n\t\tgoto fail0;\n\t}\n\n\t \n\trc = get_dimm_config(mci);\n\tif (rc < 0) {\n\t\tedac_dbg(0, \"MC: failed to get_dimm_config()\\n\");\n\t\tgoto fail;\n\t}\n\tget_memory_layout(mci);\n\n\t \n\tmci->pdev = &pdev->dev;\n\n\t \n\tif (unlikely(edac_mc_add_mc(mci))) {\n\t\tedac_dbg(0, \"MC: failed edac_mc_add_mc()\\n\");\n\t\trc = -EINVAL;\n\t\tgoto fail;\n\t}\n\n\treturn 0;\n\nfail:\n\tkfree(mci->ctl_name);\nfail0:\n\tedac_mc_free(mci);\n\tsbridge_dev->mci = NULL;\n\treturn rc;\n}\n\nstatic const struct x86_cpu_id sbridge_cpuids[] = {\n\tX86_MATCH_INTEL_FAM6_MODEL(SANDYBRIDGE_X, &pci_dev_descr_sbridge_table),\n\tX86_MATCH_INTEL_FAM6_MODEL(IVYBRIDGE_X,\t  &pci_dev_descr_ibridge_table),\n\tX86_MATCH_INTEL_FAM6_MODEL(HASWELL_X,\t  &pci_dev_descr_haswell_table),\n\tX86_MATCH_INTEL_FAM6_MODEL(BROADWELL_X,\t  &pci_dev_descr_broadwell_table),\n\tX86_MATCH_INTEL_FAM6_MODEL(BROADWELL_D,\t  &pci_dev_descr_broadwell_table),\n\tX86_MATCH_INTEL_FAM6_MODEL(XEON_PHI_KNL,  &pci_dev_descr_knl_table),\n\tX86_MATCH_INTEL_FAM6_MODEL(XEON_PHI_KNM,  &pci_dev_descr_knl_table),\n\t{ }\n};\nMODULE_DEVICE_TABLE(x86cpu, sbridge_cpuids);\n\n \n\nstatic int sbridge_probe(const struct x86_cpu_id *id)\n{\n\tint rc;\n\tu8 mc, num_mc = 0;\n\tstruct sbridge_dev *sbridge_dev;\n\tstruct pci_id_table *ptable = (struct pci_id_table *)id->driver_data;\n\n\t \n\trc = sbridge_get_all_devices(&num_mc, ptable);\n\n\tif (unlikely(rc < 0)) {\n\t\tedac_dbg(0, \"couldn't get all devices\\n\");\n\t\tgoto fail0;\n\t}\n\n\tmc = 0;\n\n\tlist_for_each_entry(sbridge_dev, &sbridge_edac_list, list) {\n\t\tedac_dbg(0, \"Registering MC#%d (%d of %d)\\n\",\n\t\t\t mc, mc + 1, num_mc);\n\n\t\tsbridge_dev->mc = mc++;\n\t\trc = sbridge_register_mci(sbridge_dev, ptable->type);\n\t\tif (unlikely(rc < 0))\n\t\t\tgoto fail1;\n\t}\n\n\tsbridge_printk(KERN_INFO, \"%s\\n\", SBRIDGE_REVISION);\n\n\treturn 0;\n\nfail1:\n\tlist_for_each_entry(sbridge_dev, &sbridge_edac_list, list)\n\t\tsbridge_unregister_mci(sbridge_dev);\n\n\tsbridge_put_all_devices();\nfail0:\n\treturn rc;\n}\n\n \nstatic void sbridge_remove(void)\n{\n\tstruct sbridge_dev *sbridge_dev;\n\n\tedac_dbg(0, \"\\n\");\n\n\tlist_for_each_entry(sbridge_dev, &sbridge_edac_list, list)\n\t\tsbridge_unregister_mci(sbridge_dev);\n\n\t \n\tsbridge_put_all_devices();\n}\n\n \nstatic int __init sbridge_init(void)\n{\n\tconst struct x86_cpu_id *id;\n\tconst char *owner;\n\tint rc;\n\n\tedac_dbg(2, \"\\n\");\n\n\tif (ghes_get_devices())\n\t\treturn -EBUSY;\n\n\towner = edac_get_owner();\n\tif (owner && strncmp(owner, EDAC_MOD_STR, sizeof(EDAC_MOD_STR)))\n\t\treturn -EBUSY;\n\n\tif (cpu_feature_enabled(X86_FEATURE_HYPERVISOR))\n\t\treturn -ENODEV;\n\n\tid = x86_match_cpu(sbridge_cpuids);\n\tif (!id)\n\t\treturn -ENODEV;\n\n\t \n\topstate_init();\n\n\trc = sbridge_probe(id);\n\n\tif (rc >= 0) {\n\t\tmce_register_decode_chain(&sbridge_mce_dec);\n\t\treturn 0;\n\t}\n\n\tsbridge_printk(KERN_ERR, \"Failed to register device with error %d.\\n\",\n\t\t      rc);\n\n\treturn rc;\n}\n\n \nstatic void __exit sbridge_exit(void)\n{\n\tedac_dbg(2, \"\\n\");\n\tsbridge_remove();\n\tmce_unregister_decode_chain(&sbridge_mce_dec);\n}\n\nmodule_init(sbridge_init);\nmodule_exit(sbridge_exit);\n\nmodule_param(edac_op_state, int, 0444);\nMODULE_PARM_DESC(edac_op_state, \"EDAC Error Reporting state: 0=Poll,1=NMI\");\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Mauro Carvalho Chehab\");\nMODULE_AUTHOR(\"Red Hat Inc. (https:\nMODULE_DESCRIPTION(\"MC Driver for Intel Sandy Bridge and Ivy Bridge memory controllers - \"\n\t\t   SBRIDGE_REVISION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}