{
  "module_name": "dma-fence-array.c",
  "hash_id": "fc75d2beabd43fb8b6036e9c94e7c49eae901c8ad8a6d4cb41397e12657061dd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dma-buf/dma-fence-array.c",
  "human_readable_source": "\n \n\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/dma-fence-array.h>\n\n#define PENDING_ERROR 1\n\nstatic const char *dma_fence_array_get_driver_name(struct dma_fence *fence)\n{\n\treturn \"dma_fence_array\";\n}\n\nstatic const char *dma_fence_array_get_timeline_name(struct dma_fence *fence)\n{\n\treturn \"unbound\";\n}\n\nstatic void dma_fence_array_set_pending_error(struct dma_fence_array *array,\n\t\t\t\t\t      int error)\n{\n\t \n\tif (error)\n\t\tcmpxchg(&array->base.error, PENDING_ERROR, error);\n}\n\nstatic void dma_fence_array_clear_pending_error(struct dma_fence_array *array)\n{\n\t \n\tcmpxchg(&array->base.error, PENDING_ERROR, 0);\n}\n\nstatic void irq_dma_fence_array_work(struct irq_work *wrk)\n{\n\tstruct dma_fence_array *array = container_of(wrk, typeof(*array), work);\n\n\tdma_fence_array_clear_pending_error(array);\n\n\tdma_fence_signal(&array->base);\n\tdma_fence_put(&array->base);\n}\n\nstatic void dma_fence_array_cb_func(struct dma_fence *f,\n\t\t\t\t    struct dma_fence_cb *cb)\n{\n\tstruct dma_fence_array_cb *array_cb =\n\t\tcontainer_of(cb, struct dma_fence_array_cb, cb);\n\tstruct dma_fence_array *array = array_cb->array;\n\n\tdma_fence_array_set_pending_error(array, f->error);\n\n\tif (atomic_dec_and_test(&array->num_pending))\n\t\tirq_work_queue(&array->work);\n\telse\n\t\tdma_fence_put(&array->base);\n}\n\nstatic bool dma_fence_array_enable_signaling(struct dma_fence *fence)\n{\n\tstruct dma_fence_array *array = to_dma_fence_array(fence);\n\tstruct dma_fence_array_cb *cb = (void *)(&array[1]);\n\tunsigned i;\n\n\tfor (i = 0; i < array->num_fences; ++i) {\n\t\tcb[i].array = array;\n\t\t \n\t\tdma_fence_get(&array->base);\n\t\tif (dma_fence_add_callback(array->fences[i], &cb[i].cb,\n\t\t\t\t\t   dma_fence_array_cb_func)) {\n\t\t\tint error = array->fences[i]->error;\n\n\t\t\tdma_fence_array_set_pending_error(array, error);\n\t\t\tdma_fence_put(&array->base);\n\t\t\tif (atomic_dec_and_test(&array->num_pending)) {\n\t\t\t\tdma_fence_array_clear_pending_error(array);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn true;\n}\n\nstatic bool dma_fence_array_signaled(struct dma_fence *fence)\n{\n\tstruct dma_fence_array *array = to_dma_fence_array(fence);\n\n\tif (atomic_read(&array->num_pending) > 0)\n\t\treturn false;\n\n\tdma_fence_array_clear_pending_error(array);\n\treturn true;\n}\n\nstatic void dma_fence_array_release(struct dma_fence *fence)\n{\n\tstruct dma_fence_array *array = to_dma_fence_array(fence);\n\tunsigned i;\n\n\tfor (i = 0; i < array->num_fences; ++i)\n\t\tdma_fence_put(array->fences[i]);\n\n\tkfree(array->fences);\n\tdma_fence_free(fence);\n}\n\nstatic void dma_fence_array_set_deadline(struct dma_fence *fence,\n\t\t\t\t\t ktime_t deadline)\n{\n\tstruct dma_fence_array *array = to_dma_fence_array(fence);\n\tunsigned i;\n\n\tfor (i = 0; i < array->num_fences; ++i)\n\t\tdma_fence_set_deadline(array->fences[i], deadline);\n}\n\nconst struct dma_fence_ops dma_fence_array_ops = {\n\t.get_driver_name = dma_fence_array_get_driver_name,\n\t.get_timeline_name = dma_fence_array_get_timeline_name,\n\t.enable_signaling = dma_fence_array_enable_signaling,\n\t.signaled = dma_fence_array_signaled,\n\t.release = dma_fence_array_release,\n\t.set_deadline = dma_fence_array_set_deadline,\n};\nEXPORT_SYMBOL(dma_fence_array_ops);\n\n \nstruct dma_fence_array *dma_fence_array_create(int num_fences,\n\t\t\t\t\t       struct dma_fence **fences,\n\t\t\t\t\t       u64 context, unsigned seqno,\n\t\t\t\t\t       bool signal_on_any)\n{\n\tstruct dma_fence_array *array;\n\tsize_t size = sizeof(*array);\n\n\tWARN_ON(!num_fences || !fences);\n\n\t \n\tsize += num_fences * sizeof(struct dma_fence_array_cb);\n\tarray = kzalloc(size, GFP_KERNEL);\n\tif (!array)\n\t\treturn NULL;\n\n\tspin_lock_init(&array->lock);\n\tdma_fence_init(&array->base, &dma_fence_array_ops, &array->lock,\n\t\t       context, seqno);\n\tinit_irq_work(&array->work, irq_dma_fence_array_work);\n\n\tarray->num_fences = num_fences;\n\tatomic_set(&array->num_pending, signal_on_any ? 1 : num_fences);\n\tarray->fences = fences;\n\n\tarray->base.error = PENDING_ERROR;\n\n\t \n\twhile (num_fences--)\n\t\tWARN_ON(dma_fence_is_container(fences[num_fences]));\n\n\treturn array;\n}\nEXPORT_SYMBOL(dma_fence_array_create);\n\n \nbool dma_fence_match_context(struct dma_fence *fence, u64 context)\n{\n\tstruct dma_fence_array *array = to_dma_fence_array(fence);\n\tunsigned i;\n\n\tif (!dma_fence_is_array(fence))\n\t\treturn fence->context == context;\n\n\tfor (i = 0; i < array->num_fences; i++) {\n\t\tif (array->fences[i]->context != context)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\nEXPORT_SYMBOL(dma_fence_match_context);\n\nstruct dma_fence *dma_fence_array_first(struct dma_fence *head)\n{\n\tstruct dma_fence_array *array;\n\n\tif (!head)\n\t\treturn NULL;\n\n\tarray = to_dma_fence_array(head);\n\tif (!array)\n\t\treturn head;\n\n\tif (!array->num_fences)\n\t\treturn NULL;\n\n\treturn array->fences[0];\n}\nEXPORT_SYMBOL(dma_fence_array_first);\n\nstruct dma_fence *dma_fence_array_next(struct dma_fence *head,\n\t\t\t\t       unsigned int index)\n{\n\tstruct dma_fence_array *array = to_dma_fence_array(head);\n\n\tif (!array || index >= array->num_fences)\n\t\treturn NULL;\n\n\treturn array->fences[index];\n}\nEXPORT_SYMBOL(dma_fence_array_next);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}