{
  "module_name": "core.c",
  "hash_id": "7e12dba4fd10e8ca02540bfd8c5263bce98de79313f68b27ec37c397a3b97bfc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/most/core.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/fs.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/list.h>\n#include <linux/poll.h>\n#include <linux/wait.h>\n#include <linux/kobject.h>\n#include <linux/mutex.h>\n#include <linux/completion.h>\n#include <linux/sysfs.h>\n#include <linux/kthread.h>\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/most.h>\n\n#define MAX_CHANNELS\t64\n#define STRING_SIZE\t80\n\nstatic struct ida mdev_id;\nstatic int dummy_num_buffers;\nstatic struct list_head comp_list;\n\nstruct pipe {\n\tstruct most_component *comp;\n\tint refs;\n\tint num_buffers;\n};\n\nstruct most_channel {\n\tstruct device dev;\n\tstruct completion cleanup;\n\tatomic_t mbo_ref;\n\tatomic_t mbo_nq_level;\n\tu16 channel_id;\n\tchar name[STRING_SIZE];\n\tbool is_poisoned;\n\tstruct mutex start_mutex;  \n\tstruct mutex nq_mutex;  \n\tint is_starving;\n\tstruct most_interface *iface;\n\tstruct most_channel_config cfg;\n\tbool keep_mbo;\n\tbool enqueue_halt;\n\tstruct list_head fifo;\n\tspinlock_t fifo_lock;  \n\tstruct list_head halt_fifo;\n\tstruct list_head list;\n\tstruct pipe pipe0;\n\tstruct pipe pipe1;\n\tstruct list_head trash_fifo;\n\tstruct task_struct *hdm_enqueue_task;\n\twait_queue_head_t hdm_fifo_wq;\n\n};\n\n#define to_channel(d) container_of(d, struct most_channel, dev)\n\nstruct interface_private {\n\tint dev_id;\n\tchar name[STRING_SIZE];\n\tstruct most_channel *channel[MAX_CHANNELS];\n\tstruct list_head channel_list;\n};\n\nstatic const struct {\n\tint most_ch_data_type;\n\tconst char *name;\n} ch_data_type[] = {\n\t{ MOST_CH_CONTROL, \"control\" },\n\t{ MOST_CH_ASYNC, \"async\" },\n\t{ MOST_CH_SYNC, \"sync\" },\n\t{ MOST_CH_ISOC, \"isoc\"},\n\t{ MOST_CH_ISOC, \"isoc_avp\"},\n};\n\n \n#define list_pop_mbo(ptr)\t\t\t\t\t\t\\\n({\t\t\t\t\t\t\t\t\t\\\n\tstruct mbo *_mbo = list_first_entry(ptr, struct mbo, list);\t\\\n\tlist_del(&_mbo->list);\t\t\t\t\t\t\\\n\t_mbo;\t\t\t\t\t\t\t\t\\\n})\n\n \nstatic void most_free_mbo_coherent(struct mbo *mbo)\n{\n\tstruct most_channel *c = mbo->context;\n\tu16 const coherent_buf_size = c->cfg.buffer_size + c->cfg.extra_len;\n\n\tif (c->iface->dma_free)\n\t\tc->iface->dma_free(mbo, coherent_buf_size);\n\telse\n\t\tkfree(mbo->virt_address);\n\tkfree(mbo);\n\tif (atomic_sub_and_test(1, &c->mbo_ref))\n\t\tcomplete(&c->cleanup);\n}\n\n \nstatic void flush_channel_fifos(struct most_channel *c)\n{\n\tunsigned long flags, hf_flags;\n\tstruct mbo *mbo, *tmp;\n\n\tif (list_empty(&c->fifo) && list_empty(&c->halt_fifo))\n\t\treturn;\n\n\tspin_lock_irqsave(&c->fifo_lock, flags);\n\tlist_for_each_entry_safe(mbo, tmp, &c->fifo, list) {\n\t\tlist_del(&mbo->list);\n\t\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\t\tmost_free_mbo_coherent(mbo);\n\t\tspin_lock_irqsave(&c->fifo_lock, flags);\n\t}\n\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\n\tspin_lock_irqsave(&c->fifo_lock, hf_flags);\n\tlist_for_each_entry_safe(mbo, tmp, &c->halt_fifo, list) {\n\t\tlist_del(&mbo->list);\n\t\tspin_unlock_irqrestore(&c->fifo_lock, hf_flags);\n\t\tmost_free_mbo_coherent(mbo);\n\t\tspin_lock_irqsave(&c->fifo_lock, hf_flags);\n\t}\n\tspin_unlock_irqrestore(&c->fifo_lock, hf_flags);\n\n\tif (unlikely((!list_empty(&c->fifo) || !list_empty(&c->halt_fifo))))\n\t\tdev_warn(&c->dev, \"Channel or trash fifo not empty\\n\");\n}\n\n \nstatic int flush_trash_fifo(struct most_channel *c)\n{\n\tstruct mbo *mbo, *tmp;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&c->fifo_lock, flags);\n\tlist_for_each_entry_safe(mbo, tmp, &c->trash_fifo, list) {\n\t\tlist_del(&mbo->list);\n\t\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\t\tmost_free_mbo_coherent(mbo);\n\t\tspin_lock_irqsave(&c->fifo_lock, flags);\n\t}\n\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\treturn 0;\n}\n\nstatic ssize_t available_directions_show(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\tunsigned int i = c->channel_id;\n\n\tstrcpy(buf, \"\");\n\tif (c->iface->channel_vector[i].direction & MOST_CH_RX)\n\t\tstrcat(buf, \"rx \");\n\tif (c->iface->channel_vector[i].direction & MOST_CH_TX)\n\t\tstrcat(buf, \"tx \");\n\tstrcat(buf, \"\\n\");\n\treturn strlen(buf);\n}\n\nstatic ssize_t available_datatypes_show(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\tunsigned int i = c->channel_id;\n\n\tstrcpy(buf, \"\");\n\tif (c->iface->channel_vector[i].data_type & MOST_CH_CONTROL)\n\t\tstrcat(buf, \"control \");\n\tif (c->iface->channel_vector[i].data_type & MOST_CH_ASYNC)\n\t\tstrcat(buf, \"async \");\n\tif (c->iface->channel_vector[i].data_type & MOST_CH_SYNC)\n\t\tstrcat(buf, \"sync \");\n\tif (c->iface->channel_vector[i].data_type & MOST_CH_ISOC)\n\t\tstrcat(buf, \"isoc \");\n\tstrcat(buf, \"\\n\");\n\treturn strlen(buf);\n}\n\nstatic ssize_t number_of_packet_buffers_show(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\tunsigned int i = c->channel_id;\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\",\n\t\t\tc->iface->channel_vector[i].num_buffers_packet);\n}\n\nstatic ssize_t number_of_stream_buffers_show(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\tunsigned int i = c->channel_id;\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\",\n\t\t\tc->iface->channel_vector[i].num_buffers_streaming);\n}\n\nstatic ssize_t size_of_packet_buffer_show(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\tunsigned int i = c->channel_id;\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\",\n\t\t\tc->iface->channel_vector[i].buffer_size_packet);\n}\n\nstatic ssize_t size_of_stream_buffer_show(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\tunsigned int i = c->channel_id;\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\",\n\t\t\tc->iface->channel_vector[i].buffer_size_streaming);\n}\n\nstatic ssize_t channel_starving_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", c->is_starving);\n}\n\nstatic ssize_t set_number_of_buffers_show(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", c->cfg.num_buffers);\n}\n\nstatic ssize_t set_buffer_size_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", c->cfg.buffer_size);\n}\n\nstatic ssize_t set_direction_show(struct device *dev,\n\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t  char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\tif (c->cfg.direction & MOST_CH_TX)\n\t\treturn snprintf(buf, PAGE_SIZE, \"tx\\n\");\n\telse if (c->cfg.direction & MOST_CH_RX)\n\t\treturn snprintf(buf, PAGE_SIZE, \"rx\\n\");\n\treturn snprintf(buf, PAGE_SIZE, \"unconfigured\\n\");\n}\n\nstatic ssize_t set_datatype_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr,\n\t\t\t\t char *buf)\n{\n\tint i;\n\tstruct most_channel *c = to_channel(dev);\n\n\tfor (i = 0; i < ARRAY_SIZE(ch_data_type); i++) {\n\t\tif (c->cfg.data_type & ch_data_type[i].most_ch_data_type)\n\t\t\treturn snprintf(buf, PAGE_SIZE, \"%s\",\n\t\t\t\t\tch_data_type[i].name);\n\t}\n\treturn snprintf(buf, PAGE_SIZE, \"unconfigured\\n\");\n}\n\nstatic ssize_t set_subbuffer_size_show(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", c->cfg.subbuffer_size);\n}\n\nstatic ssize_t set_packets_per_xact_show(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", c->cfg.packets_per_xact);\n}\n\nstatic ssize_t set_dbr_size_show(struct device *dev,\n\t\t\t\t struct device_attribute *attr, char *buf)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%d\\n\", c->cfg.dbr_size);\n}\n\n#define to_dev_attr(a) container_of(a, struct device_attribute, attr)\nstatic umode_t channel_attr_is_visible(struct kobject *kobj,\n\t\t\t\t       struct attribute *attr, int index)\n{\n\tstruct device_attribute *dev_attr = to_dev_attr(attr);\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct most_channel *c = to_channel(dev);\n\n\tif (!strcmp(dev_attr->attr.name, \"set_dbr_size\") &&\n\t    (c->iface->interface != ITYPE_MEDIALB_DIM2))\n\t\treturn 0;\n\tif (!strcmp(dev_attr->attr.name, \"set_packets_per_xact\") &&\n\t    (c->iface->interface != ITYPE_USB))\n\t\treturn 0;\n\n\treturn attr->mode;\n}\n\n#define DEV_ATTR(_name)  (&dev_attr_##_name.attr)\n\nstatic DEVICE_ATTR_RO(available_directions);\nstatic DEVICE_ATTR_RO(available_datatypes);\nstatic DEVICE_ATTR_RO(number_of_packet_buffers);\nstatic DEVICE_ATTR_RO(number_of_stream_buffers);\nstatic DEVICE_ATTR_RO(size_of_stream_buffer);\nstatic DEVICE_ATTR_RO(size_of_packet_buffer);\nstatic DEVICE_ATTR_RO(channel_starving);\nstatic DEVICE_ATTR_RO(set_buffer_size);\nstatic DEVICE_ATTR_RO(set_number_of_buffers);\nstatic DEVICE_ATTR_RO(set_direction);\nstatic DEVICE_ATTR_RO(set_datatype);\nstatic DEVICE_ATTR_RO(set_subbuffer_size);\nstatic DEVICE_ATTR_RO(set_packets_per_xact);\nstatic DEVICE_ATTR_RO(set_dbr_size);\n\nstatic struct attribute *channel_attrs[] = {\n\tDEV_ATTR(available_directions),\n\tDEV_ATTR(available_datatypes),\n\tDEV_ATTR(number_of_packet_buffers),\n\tDEV_ATTR(number_of_stream_buffers),\n\tDEV_ATTR(size_of_stream_buffer),\n\tDEV_ATTR(size_of_packet_buffer),\n\tDEV_ATTR(channel_starving),\n\tDEV_ATTR(set_buffer_size),\n\tDEV_ATTR(set_number_of_buffers),\n\tDEV_ATTR(set_direction),\n\tDEV_ATTR(set_datatype),\n\tDEV_ATTR(set_subbuffer_size),\n\tDEV_ATTR(set_packets_per_xact),\n\tDEV_ATTR(set_dbr_size),\n\tNULL,\n};\n\nstatic const struct attribute_group channel_attr_group = {\n\t.attrs = channel_attrs,\n\t.is_visible = channel_attr_is_visible,\n};\n\nstatic const struct attribute_group *channel_attr_groups[] = {\n\t&channel_attr_group,\n\tNULL,\n};\n\nstatic ssize_t description_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr,\n\t\t\t\tchar *buf)\n{\n\tstruct most_interface *iface = dev_get_drvdata(dev);\n\n\treturn snprintf(buf, PAGE_SIZE, \"%s\\n\", iface->description);\n}\n\nstatic ssize_t interface_show(struct device *dev,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct most_interface *iface = dev_get_drvdata(dev);\n\n\tswitch (iface->interface) {\n\tcase ITYPE_LOOPBACK:\n\t\treturn snprintf(buf, PAGE_SIZE, \"loopback\\n\");\n\tcase ITYPE_I2C:\n\t\treturn snprintf(buf, PAGE_SIZE, \"i2c\\n\");\n\tcase ITYPE_I2S:\n\t\treturn snprintf(buf, PAGE_SIZE, \"i2s\\n\");\n\tcase ITYPE_TSI:\n\t\treturn snprintf(buf, PAGE_SIZE, \"tsi\\n\");\n\tcase ITYPE_HBI:\n\t\treturn snprintf(buf, PAGE_SIZE, \"hbi\\n\");\n\tcase ITYPE_MEDIALB_DIM:\n\t\treturn snprintf(buf, PAGE_SIZE, \"mlb_dim\\n\");\n\tcase ITYPE_MEDIALB_DIM2:\n\t\treturn snprintf(buf, PAGE_SIZE, \"mlb_dim2\\n\");\n\tcase ITYPE_USB:\n\t\treturn snprintf(buf, PAGE_SIZE, \"usb\\n\");\n\tcase ITYPE_PCIE:\n\t\treturn snprintf(buf, PAGE_SIZE, \"pcie\\n\");\n\t}\n\treturn snprintf(buf, PAGE_SIZE, \"unknown\\n\");\n}\n\nstatic DEVICE_ATTR_RO(description);\nstatic DEVICE_ATTR_RO(interface);\n\nstatic struct attribute *interface_attrs[] = {\n\tDEV_ATTR(description),\n\tDEV_ATTR(interface),\n\tNULL,\n};\n\nstatic const struct attribute_group interface_attr_group = {\n\t.attrs = interface_attrs,\n};\n\nstatic const struct attribute_group *interface_attr_groups[] = {\n\t&interface_attr_group,\n\tNULL,\n};\n\nstatic struct most_component *match_component(char *name)\n{\n\tstruct most_component *comp;\n\n\tlist_for_each_entry(comp, &comp_list, list) {\n\t\tif (!strcmp(comp->name, name))\n\t\t\treturn comp;\n\t}\n\treturn NULL;\n}\n\nstruct show_links_data {\n\tint offs;\n\tchar *buf;\n};\n\nstatic int print_links(struct device *dev, void *data)\n{\n\tstruct show_links_data *d = data;\n\tint offs = d->offs;\n\tchar *buf = d->buf;\n\tstruct most_channel *c;\n\tstruct most_interface *iface = dev_get_drvdata(dev);\n\n\tlist_for_each_entry(c, &iface->p->channel_list, list) {\n\t\tif (c->pipe0.comp) {\n\t\t\toffs += scnprintf(buf + offs,\n\t\t\t\t\t PAGE_SIZE - offs,\n\t\t\t\t\t \"%s:%s:%s\\n\",\n\t\t\t\t\t c->pipe0.comp->name,\n\t\t\t\t\t dev_name(iface->dev),\n\t\t\t\t\t dev_name(&c->dev));\n\t\t}\n\t\tif (c->pipe1.comp) {\n\t\t\toffs += scnprintf(buf + offs,\n\t\t\t\t\t PAGE_SIZE - offs,\n\t\t\t\t\t \"%s:%s:%s\\n\",\n\t\t\t\t\t c->pipe1.comp->name,\n\t\t\t\t\t dev_name(iface->dev),\n\t\t\t\t\t dev_name(&c->dev));\n\t\t}\n\t}\n\td->offs = offs;\n\treturn 0;\n}\n\nstatic int most_match(struct device *dev, struct device_driver *drv)\n{\n\tif (!strcmp(dev_name(dev), \"most\"))\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\n\nstatic struct bus_type mostbus = {\n\t.name = \"most\",\n\t.match = most_match,\n};\n\nstatic ssize_t links_show(struct device_driver *drv, char *buf)\n{\n\tstruct show_links_data d = { .buf = buf };\n\n\tbus_for_each_dev(&mostbus, NULL, &d, print_links);\n\treturn d.offs;\n}\n\nstatic ssize_t components_show(struct device_driver *drv, char *buf)\n{\n\tstruct most_component *comp;\n\tint offs = 0;\n\n\tlist_for_each_entry(comp, &comp_list, list) {\n\t\toffs += scnprintf(buf + offs, PAGE_SIZE - offs, \"%s\\n\",\n\t\t\t\t comp->name);\n\t}\n\treturn offs;\n}\n\n \nstatic struct most_channel *get_channel(char *mdev, char *mdev_ch)\n{\n\tstruct device *dev = NULL;\n\tstruct most_interface *iface;\n\tstruct most_channel *c, *tmp;\n\n\tdev = bus_find_device_by_name(&mostbus, NULL, mdev);\n\tif (!dev)\n\t\treturn NULL;\n\tput_device(dev);\n\tiface = dev_get_drvdata(dev);\n\tlist_for_each_entry_safe(c, tmp, &iface->p->channel_list, list) {\n\t\tif (!strcmp(dev_name(&c->dev), mdev_ch))\n\t\t\treturn c;\n\t}\n\treturn NULL;\n}\n\nstatic\ninline int link_channel_to_component(struct most_channel *c,\n\t\t\t\t     struct most_component *comp,\n\t\t\t\t     char *name,\n\t\t\t\t     char *comp_param)\n{\n\tint ret;\n\tstruct most_component **comp_ptr;\n\n\tif (!c->pipe0.comp)\n\t\tcomp_ptr = &c->pipe0.comp;\n\telse if (!c->pipe1.comp)\n\t\tcomp_ptr = &c->pipe1.comp;\n\telse\n\t\treturn -ENOSPC;\n\n\t*comp_ptr = comp;\n\tret = comp->probe_channel(c->iface, c->channel_id, &c->cfg, name,\n\t\t\t\t  comp_param);\n\tif (ret) {\n\t\t*comp_ptr = NULL;\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nint most_set_cfg_buffer_size(char *mdev, char *mdev_ch, u16 val)\n{\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\n\tif (!c)\n\t\treturn -ENODEV;\n\tc->cfg.buffer_size = val;\n\treturn 0;\n}\n\nint most_set_cfg_subbuffer_size(char *mdev, char *mdev_ch, u16 val)\n{\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\n\tif (!c)\n\t\treturn -ENODEV;\n\tc->cfg.subbuffer_size = val;\n\treturn 0;\n}\n\nint most_set_cfg_dbr_size(char *mdev, char *mdev_ch, u16 val)\n{\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\n\tif (!c)\n\t\treturn -ENODEV;\n\tc->cfg.dbr_size = val;\n\treturn 0;\n}\n\nint most_set_cfg_num_buffers(char *mdev, char *mdev_ch, u16 val)\n{\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\n\tif (!c)\n\t\treturn -ENODEV;\n\tc->cfg.num_buffers = val;\n\treturn 0;\n}\n\nint most_set_cfg_datatype(char *mdev, char *mdev_ch, char *buf)\n{\n\tint i;\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\n\tif (!c)\n\t\treturn -ENODEV;\n\tfor (i = 0; i < ARRAY_SIZE(ch_data_type); i++) {\n\t\tif (!strcmp(buf, ch_data_type[i].name)) {\n\t\t\tc->cfg.data_type = ch_data_type[i].most_ch_data_type;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == ARRAY_SIZE(ch_data_type))\n\t\tdev_warn(&c->dev, \"Invalid attribute settings\\n\");\n\treturn 0;\n}\n\nint most_set_cfg_direction(char *mdev, char *mdev_ch, char *buf)\n{\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\n\tif (!c)\n\t\treturn -ENODEV;\n\tif (!strcmp(buf, \"dir_rx\")) {\n\t\tc->cfg.direction = MOST_CH_RX;\n\t} else if (!strcmp(buf, \"rx\")) {\n\t\tc->cfg.direction = MOST_CH_RX;\n\t} else if (!strcmp(buf, \"dir_tx\")) {\n\t\tc->cfg.direction = MOST_CH_TX;\n\t} else if (!strcmp(buf, \"tx\")) {\n\t\tc->cfg.direction = MOST_CH_TX;\n\t} else {\n\t\tdev_err(&c->dev, \"Invalid direction\\n\");\n\t\treturn -ENODATA;\n\t}\n\treturn 0;\n}\n\nint most_set_cfg_packets_xact(char *mdev, char *mdev_ch, u16 val)\n{\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\n\tif (!c)\n\t\treturn -ENODEV;\n\tc->cfg.packets_per_xact = val;\n\treturn 0;\n}\n\nint most_cfg_complete(char *comp_name)\n{\n\tstruct most_component *comp;\n\n\tcomp = match_component(comp_name);\n\tif (!comp)\n\t\treturn -ENODEV;\n\n\treturn comp->cfg_complete();\n}\n\nint most_add_link(char *mdev, char *mdev_ch, char *comp_name, char *link_name,\n\t\t  char *comp_param)\n{\n\tstruct most_channel *c = get_channel(mdev, mdev_ch);\n\tstruct most_component *comp = match_component(comp_name);\n\n\tif (!c || !comp)\n\t\treturn -ENODEV;\n\n\treturn link_channel_to_component(c, comp, link_name, comp_param);\n}\n\nint most_remove_link(char *mdev, char *mdev_ch, char *comp_name)\n{\n\tstruct most_channel *c;\n\tstruct most_component *comp;\n\n\tcomp = match_component(comp_name);\n\tif (!comp)\n\t\treturn -ENODEV;\n\tc = get_channel(mdev, mdev_ch);\n\tif (!c)\n\t\treturn -ENODEV;\n\n\tif (comp->disconnect_channel(c->iface, c->channel_id))\n\t\treturn -EIO;\n\tif (c->pipe0.comp == comp)\n\t\tc->pipe0.comp = NULL;\n\tif (c->pipe1.comp == comp)\n\t\tc->pipe1.comp = NULL;\n\treturn 0;\n}\n\n#define DRV_ATTR(_name)  (&driver_attr_##_name.attr)\n\nstatic DRIVER_ATTR_RO(links);\nstatic DRIVER_ATTR_RO(components);\n\nstatic struct attribute *mc_attrs[] = {\n\tDRV_ATTR(links),\n\tDRV_ATTR(components),\n\tNULL,\n};\n\nstatic const struct attribute_group mc_attr_group = {\n\t.attrs = mc_attrs,\n};\n\nstatic const struct attribute_group *mc_attr_groups[] = {\n\t&mc_attr_group,\n\tNULL,\n};\n\nstatic struct device_driver mostbus_driver = {\n\t.name = \"most_core\",\n\t.bus = &mostbus,\n\t.groups = mc_attr_groups,\n};\n\nstatic inline void trash_mbo(struct mbo *mbo)\n{\n\tunsigned long flags;\n\tstruct most_channel *c = mbo->context;\n\n\tspin_lock_irqsave(&c->fifo_lock, flags);\n\tlist_add(&mbo->list, &c->trash_fifo);\n\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n}\n\nstatic bool hdm_mbo_ready(struct most_channel *c)\n{\n\tbool empty;\n\n\tif (c->enqueue_halt)\n\t\treturn false;\n\n\tspin_lock_irq(&c->fifo_lock);\n\tempty = list_empty(&c->halt_fifo);\n\tspin_unlock_irq(&c->fifo_lock);\n\n\treturn !empty;\n}\n\nstatic void nq_hdm_mbo(struct mbo *mbo)\n{\n\tunsigned long flags;\n\tstruct most_channel *c = mbo->context;\n\n\tspin_lock_irqsave(&c->fifo_lock, flags);\n\tlist_add_tail(&mbo->list, &c->halt_fifo);\n\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\twake_up_interruptible(&c->hdm_fifo_wq);\n}\n\nstatic int hdm_enqueue_thread(void *data)\n{\n\tstruct most_channel *c = data;\n\tstruct mbo *mbo;\n\tint ret;\n\ttypeof(c->iface->enqueue) enqueue = c->iface->enqueue;\n\n\twhile (likely(!kthread_should_stop())) {\n\t\twait_event_interruptible(c->hdm_fifo_wq,\n\t\t\t\t\t hdm_mbo_ready(c) ||\n\t\t\t\t\t kthread_should_stop());\n\n\t\tmutex_lock(&c->nq_mutex);\n\t\tspin_lock_irq(&c->fifo_lock);\n\t\tif (unlikely(c->enqueue_halt || list_empty(&c->halt_fifo))) {\n\t\t\tspin_unlock_irq(&c->fifo_lock);\n\t\t\tmutex_unlock(&c->nq_mutex);\n\t\t\tcontinue;\n\t\t}\n\n\t\tmbo = list_pop_mbo(&c->halt_fifo);\n\t\tspin_unlock_irq(&c->fifo_lock);\n\n\t\tif (c->cfg.direction == MOST_CH_RX)\n\t\t\tmbo->buffer_length = c->cfg.buffer_size;\n\n\t\tret = enqueue(mbo->ifp, mbo->hdm_channel_id, mbo);\n\t\tmutex_unlock(&c->nq_mutex);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdev_err(&c->dev, \"Buffer enqueue failed\\n\");\n\t\t\tnq_hdm_mbo(mbo);\n\t\t\tc->hdm_enqueue_task = NULL;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int run_enqueue_thread(struct most_channel *c, int channel_id)\n{\n\tstruct task_struct *task =\n\t\tkthread_run(hdm_enqueue_thread, c, \"hdm_fifo_%d\",\n\t\t\t    channel_id);\n\n\tif (IS_ERR(task))\n\t\treturn PTR_ERR(task);\n\n\tc->hdm_enqueue_task = task;\n\treturn 0;\n}\n\n \nstatic void arm_mbo(struct mbo *mbo)\n{\n\tunsigned long flags;\n\tstruct most_channel *c;\n\n\tc = mbo->context;\n\n\tif (c->is_poisoned) {\n\t\ttrash_mbo(mbo);\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&c->fifo_lock, flags);\n\t++*mbo->num_buffers_ptr;\n\tlist_add_tail(&mbo->list, &c->fifo);\n\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\n\tif (c->pipe0.refs && c->pipe0.comp->tx_completion)\n\t\tc->pipe0.comp->tx_completion(c->iface, c->channel_id);\n\n\tif (c->pipe1.refs && c->pipe1.comp->tx_completion)\n\t\tc->pipe1.comp->tx_completion(c->iface, c->channel_id);\n}\n\n \nstatic int arm_mbo_chain(struct most_channel *c, int dir,\n\t\t\t void (*compl)(struct mbo *))\n{\n\tunsigned int i;\n\tstruct mbo *mbo;\n\tunsigned long flags;\n\tu32 coherent_buf_size = c->cfg.buffer_size + c->cfg.extra_len;\n\n\tatomic_set(&c->mbo_nq_level, 0);\n\n\tfor (i = 0; i < c->cfg.num_buffers; i++) {\n\t\tmbo = kzalloc(sizeof(*mbo), GFP_KERNEL);\n\t\tif (!mbo)\n\t\t\tgoto flush_fifos;\n\n\t\tmbo->context = c;\n\t\tmbo->ifp = c->iface;\n\t\tmbo->hdm_channel_id = c->channel_id;\n\t\tif (c->iface->dma_alloc) {\n\t\t\tmbo->virt_address =\n\t\t\t\tc->iface->dma_alloc(mbo, coherent_buf_size);\n\t\t} else {\n\t\t\tmbo->virt_address =\n\t\t\t\tkzalloc(coherent_buf_size, GFP_KERNEL);\n\t\t}\n\t\tif (!mbo->virt_address)\n\t\t\tgoto release_mbo;\n\n\t\tmbo->complete = compl;\n\t\tmbo->num_buffers_ptr = &dummy_num_buffers;\n\t\tif (dir == MOST_CH_RX) {\n\t\t\tnq_hdm_mbo(mbo);\n\t\t\tatomic_inc(&c->mbo_nq_level);\n\t\t} else {\n\t\t\tspin_lock_irqsave(&c->fifo_lock, flags);\n\t\t\tlist_add_tail(&mbo->list, &c->fifo);\n\t\t\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\t\t}\n\t}\n\treturn c->cfg.num_buffers;\n\nrelease_mbo:\n\tkfree(mbo);\n\nflush_fifos:\n\tflush_channel_fifos(c);\n\treturn 0;\n}\n\n \nvoid most_submit_mbo(struct mbo *mbo)\n{\n\tif (WARN_ONCE(!mbo || !mbo->context,\n\t\t      \"Bad buffer or missing channel reference\\n\"))\n\t\treturn;\n\n\tnq_hdm_mbo(mbo);\n}\nEXPORT_SYMBOL_GPL(most_submit_mbo);\n\n \nstatic void most_write_completion(struct mbo *mbo)\n{\n\tstruct most_channel *c;\n\n\tc = mbo->context;\n\tif (unlikely(c->is_poisoned || (mbo->status == MBO_E_CLOSE)))\n\t\ttrash_mbo(mbo);\n\telse\n\t\tarm_mbo(mbo);\n}\n\nint channel_has_mbo(struct most_interface *iface, int id,\n\t\t    struct most_component *comp)\n{\n\tstruct most_channel *c = iface->p->channel[id];\n\tunsigned long flags;\n\tint empty;\n\n\tif (unlikely(!c))\n\t\treturn -EINVAL;\n\n\tif (c->pipe0.refs && c->pipe1.refs &&\n\t    ((comp == c->pipe0.comp && c->pipe0.num_buffers <= 0) ||\n\t     (comp == c->pipe1.comp && c->pipe1.num_buffers <= 0)))\n\t\treturn 0;\n\n\tspin_lock_irqsave(&c->fifo_lock, flags);\n\tempty = list_empty(&c->fifo);\n\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\treturn !empty;\n}\nEXPORT_SYMBOL_GPL(channel_has_mbo);\n\n \nstruct mbo *most_get_mbo(struct most_interface *iface, int id,\n\t\t\t struct most_component *comp)\n{\n\tstruct mbo *mbo;\n\tstruct most_channel *c;\n\tunsigned long flags;\n\tint *num_buffers_ptr;\n\n\tc = iface->p->channel[id];\n\tif (unlikely(!c))\n\t\treturn NULL;\n\n\tif (c->pipe0.refs && c->pipe1.refs &&\n\t    ((comp == c->pipe0.comp && c->pipe0.num_buffers <= 0) ||\n\t     (comp == c->pipe1.comp && c->pipe1.num_buffers <= 0)))\n\t\treturn NULL;\n\n\tif (comp == c->pipe0.comp)\n\t\tnum_buffers_ptr = &c->pipe0.num_buffers;\n\telse if (comp == c->pipe1.comp)\n\t\tnum_buffers_ptr = &c->pipe1.num_buffers;\n\telse\n\t\tnum_buffers_ptr = &dummy_num_buffers;\n\n\tspin_lock_irqsave(&c->fifo_lock, flags);\n\tif (list_empty(&c->fifo)) {\n\t\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\t\treturn NULL;\n\t}\n\tmbo = list_pop_mbo(&c->fifo);\n\t--*num_buffers_ptr;\n\tspin_unlock_irqrestore(&c->fifo_lock, flags);\n\n\tmbo->num_buffers_ptr = num_buffers_ptr;\n\tmbo->buffer_length = c->cfg.buffer_size;\n\treturn mbo;\n}\nEXPORT_SYMBOL_GPL(most_get_mbo);\n\n \nvoid most_put_mbo(struct mbo *mbo)\n{\n\tstruct most_channel *c = mbo->context;\n\n\tif (c->cfg.direction == MOST_CH_TX) {\n\t\tarm_mbo(mbo);\n\t\treturn;\n\t}\n\tnq_hdm_mbo(mbo);\n\tatomic_inc(&c->mbo_nq_level);\n}\nEXPORT_SYMBOL_GPL(most_put_mbo);\n\n \nstatic void most_read_completion(struct mbo *mbo)\n{\n\tstruct most_channel *c = mbo->context;\n\n\tif (unlikely(c->is_poisoned || (mbo->status == MBO_E_CLOSE))) {\n\t\ttrash_mbo(mbo);\n\t\treturn;\n\t}\n\n\tif (mbo->status == MBO_E_INVAL) {\n\t\tnq_hdm_mbo(mbo);\n\t\tatomic_inc(&c->mbo_nq_level);\n\t\treturn;\n\t}\n\n\tif (atomic_sub_and_test(1, &c->mbo_nq_level))\n\t\tc->is_starving = 1;\n\n\tif (c->pipe0.refs && c->pipe0.comp->rx_completion &&\n\t    c->pipe0.comp->rx_completion(mbo) == 0)\n\t\treturn;\n\n\tif (c->pipe1.refs && c->pipe1.comp->rx_completion &&\n\t    c->pipe1.comp->rx_completion(mbo) == 0)\n\t\treturn;\n\n\tmost_put_mbo(mbo);\n}\n\n \nint most_start_channel(struct most_interface *iface, int id,\n\t\t       struct most_component *comp)\n{\n\tint num_buffer;\n\tint ret;\n\tstruct most_channel *c = iface->p->channel[id];\n\n\tif (unlikely(!c))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&c->start_mutex);\n\tif (c->pipe0.refs + c->pipe1.refs > 0)\n\t\tgoto out;  \n\n\tif (!try_module_get(iface->mod)) {\n\t\tdev_err(&c->dev, \"Failed to acquire HDM lock\\n\");\n\t\tmutex_unlock(&c->start_mutex);\n\t\treturn -ENOLCK;\n\t}\n\n\tc->cfg.extra_len = 0;\n\tif (c->iface->configure(c->iface, c->channel_id, &c->cfg)) {\n\t\tdev_err(&c->dev, \"Channel configuration failed. Go check settings...\\n\");\n\t\tret = -EINVAL;\n\t\tgoto err_put_module;\n\t}\n\n\tinit_waitqueue_head(&c->hdm_fifo_wq);\n\n\tif (c->cfg.direction == MOST_CH_RX)\n\t\tnum_buffer = arm_mbo_chain(c, c->cfg.direction,\n\t\t\t\t\t   most_read_completion);\n\telse\n\t\tnum_buffer = arm_mbo_chain(c, c->cfg.direction,\n\t\t\t\t\t   most_write_completion);\n\tif (unlikely(!num_buffer)) {\n\t\tret = -ENOMEM;\n\t\tgoto err_put_module;\n\t}\n\n\tret = run_enqueue_thread(c, id);\n\tif (ret)\n\t\tgoto err_put_module;\n\n\tc->is_starving = 0;\n\tc->pipe0.num_buffers = c->cfg.num_buffers / 2;\n\tc->pipe1.num_buffers = c->cfg.num_buffers - c->pipe0.num_buffers;\n\tatomic_set(&c->mbo_ref, num_buffer);\n\nout:\n\tif (comp == c->pipe0.comp)\n\t\tc->pipe0.refs++;\n\tif (comp == c->pipe1.comp)\n\t\tc->pipe1.refs++;\n\tmutex_unlock(&c->start_mutex);\n\treturn 0;\n\nerr_put_module:\n\tmodule_put(iface->mod);\n\tmutex_unlock(&c->start_mutex);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(most_start_channel);\n\n \nint most_stop_channel(struct most_interface *iface, int id,\n\t\t      struct most_component *comp)\n{\n\tstruct most_channel *c;\n\n\tif (unlikely((!iface) || (id >= iface->num_channels) || (id < 0))) {\n\t\tpr_err(\"Bad interface or index out of range\\n\");\n\t\treturn -EINVAL;\n\t}\n\tc = iface->p->channel[id];\n\tif (unlikely(!c))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&c->start_mutex);\n\tif (c->pipe0.refs + c->pipe1.refs >= 2)\n\t\tgoto out;\n\n\tif (c->hdm_enqueue_task)\n\t\tkthread_stop(c->hdm_enqueue_task);\n\tc->hdm_enqueue_task = NULL;\n\n\tif (iface->mod)\n\t\tmodule_put(iface->mod);\n\n\tc->is_poisoned = true;\n\tif (c->iface->poison_channel(c->iface, c->channel_id)) {\n\t\tdev_err(&c->dev, \"Failed to stop channel %d of interface %s\\n\", c->channel_id,\n\t\t\tc->iface->description);\n\t\tmutex_unlock(&c->start_mutex);\n\t\treturn -EAGAIN;\n\t}\n\tflush_trash_fifo(c);\n\tflush_channel_fifos(c);\n\n#ifdef CMPL_INTERRUPTIBLE\n\tif (wait_for_completion_interruptible(&c->cleanup)) {\n\t\tdev_err(&c->dev, \"Interrupted while cleaning up channel %d\\n\", c->channel_id);\n\t\tmutex_unlock(&c->start_mutex);\n\t\treturn -EINTR;\n\t}\n#else\n\twait_for_completion(&c->cleanup);\n#endif\n\tc->is_poisoned = false;\n\nout:\n\tif (comp == c->pipe0.comp)\n\t\tc->pipe0.refs--;\n\tif (comp == c->pipe1.comp)\n\t\tc->pipe1.refs--;\n\tmutex_unlock(&c->start_mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(most_stop_channel);\n\n \nint most_register_component(struct most_component *comp)\n{\n\tif (!comp) {\n\t\tpr_err(\"Bad component\\n\");\n\t\treturn -EINVAL;\n\t}\n\tlist_add_tail(&comp->list, &comp_list);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(most_register_component);\n\nstatic int disconnect_channels(struct device *dev, void *data)\n{\n\tstruct most_interface *iface;\n\tstruct most_channel *c, *tmp;\n\tstruct most_component *comp = data;\n\n\tiface = dev_get_drvdata(dev);\n\tlist_for_each_entry_safe(c, tmp, &iface->p->channel_list, list) {\n\t\tif (c->pipe0.comp == comp || c->pipe1.comp == comp)\n\t\t\tcomp->disconnect_channel(c->iface, c->channel_id);\n\t\tif (c->pipe0.comp == comp)\n\t\t\tc->pipe0.comp = NULL;\n\t\tif (c->pipe1.comp == comp)\n\t\t\tc->pipe1.comp = NULL;\n\t}\n\treturn 0;\n}\n\n \nint most_deregister_component(struct most_component *comp)\n{\n\tif (!comp) {\n\t\tpr_err(\"Bad component\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tbus_for_each_dev(&mostbus, NULL, comp, disconnect_channels);\n\tlist_del(&comp->list);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(most_deregister_component);\n\nstatic void release_channel(struct device *dev)\n{\n\tstruct most_channel *c = to_channel(dev);\n\n\tkfree(c);\n}\n\n \nint most_register_interface(struct most_interface *iface)\n{\n\tunsigned int i;\n\tint id;\n\tstruct most_channel *c;\n\n\tif (!iface || !iface->enqueue || !iface->configure ||\n\t    !iface->poison_channel || (iface->num_channels > MAX_CHANNELS))\n\t\treturn -EINVAL;\n\n\tid = ida_simple_get(&mdev_id, 0, 0, GFP_KERNEL);\n\tif (id < 0) {\n\t\tdev_err(iface->dev, \"Failed to allocate device ID\\n\");\n\t\treturn id;\n\t}\n\n\tiface->p = kzalloc(sizeof(*iface->p), GFP_KERNEL);\n\tif (!iface->p) {\n\t\tida_simple_remove(&mdev_id, id);\n\t\treturn -ENOMEM;\n\t}\n\n\tINIT_LIST_HEAD(&iface->p->channel_list);\n\tiface->p->dev_id = id;\n\tstrscpy(iface->p->name, iface->description, sizeof(iface->p->name));\n\tiface->dev->bus = &mostbus;\n\tiface->dev->groups = interface_attr_groups;\n\tdev_set_drvdata(iface->dev, iface);\n\tif (device_register(iface->dev)) {\n\t\tdev_err(iface->dev, \"Failed to register interface device\\n\");\n\t\tkfree(iface->p);\n\t\tput_device(iface->dev);\n\t\tida_simple_remove(&mdev_id, id);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < iface->num_channels; i++) {\n\t\tconst char *name_suffix = iface->channel_vector[i].name_suffix;\n\n\t\tc = kzalloc(sizeof(*c), GFP_KERNEL);\n\t\tif (!c)\n\t\t\tgoto err_free_resources;\n\t\tif (!name_suffix)\n\t\t\tsnprintf(c->name, STRING_SIZE, \"ch%d\", i);\n\t\telse\n\t\t\tsnprintf(c->name, STRING_SIZE, \"%s\", name_suffix);\n\t\tc->dev.init_name = c->name;\n\t\tc->dev.parent = iface->dev;\n\t\tc->dev.groups = channel_attr_groups;\n\t\tc->dev.release = release_channel;\n\t\tiface->p->channel[i] = c;\n\t\tc->is_starving = 0;\n\t\tc->iface = iface;\n\t\tc->channel_id = i;\n\t\tc->keep_mbo = false;\n\t\tc->enqueue_halt = false;\n\t\tc->is_poisoned = false;\n\t\tc->cfg.direction = 0;\n\t\tc->cfg.data_type = 0;\n\t\tc->cfg.num_buffers = 0;\n\t\tc->cfg.buffer_size = 0;\n\t\tc->cfg.subbuffer_size = 0;\n\t\tc->cfg.packets_per_xact = 0;\n\t\tspin_lock_init(&c->fifo_lock);\n\t\tINIT_LIST_HEAD(&c->fifo);\n\t\tINIT_LIST_HEAD(&c->trash_fifo);\n\t\tINIT_LIST_HEAD(&c->halt_fifo);\n\t\tinit_completion(&c->cleanup);\n\t\tatomic_set(&c->mbo_ref, 0);\n\t\tmutex_init(&c->start_mutex);\n\t\tmutex_init(&c->nq_mutex);\n\t\tlist_add_tail(&c->list, &iface->p->channel_list);\n\t\tif (device_register(&c->dev)) {\n\t\t\tdev_err(&c->dev, \"Failed to register channel device\\n\");\n\t\t\tgoto err_free_most_channel;\n\t\t}\n\t}\n\tmost_interface_register_notify(iface->description);\n\treturn 0;\n\nerr_free_most_channel:\n\tput_device(&c->dev);\n\nerr_free_resources:\n\twhile (i > 0) {\n\t\tc = iface->p->channel[--i];\n\t\tdevice_unregister(&c->dev);\n\t}\n\tkfree(iface->p);\n\tdevice_unregister(iface->dev);\n\tida_simple_remove(&mdev_id, id);\n\treturn -ENOMEM;\n}\nEXPORT_SYMBOL_GPL(most_register_interface);\n\n \nvoid most_deregister_interface(struct most_interface *iface)\n{\n\tint i;\n\tstruct most_channel *c;\n\n\tfor (i = 0; i < iface->num_channels; i++) {\n\t\tc = iface->p->channel[i];\n\t\tif (c->pipe0.comp)\n\t\t\tc->pipe0.comp->disconnect_channel(c->iface,\n\t\t\t\t\t\t\tc->channel_id);\n\t\tif (c->pipe1.comp)\n\t\t\tc->pipe1.comp->disconnect_channel(c->iface,\n\t\t\t\t\t\t\tc->channel_id);\n\t\tc->pipe0.comp = NULL;\n\t\tc->pipe1.comp = NULL;\n\t\tlist_del(&c->list);\n\t\tdevice_unregister(&c->dev);\n\t}\n\n\tida_simple_remove(&mdev_id, iface->p->dev_id);\n\tkfree(iface->p);\n\tdevice_unregister(iface->dev);\n}\nEXPORT_SYMBOL_GPL(most_deregister_interface);\n\n \nvoid most_stop_enqueue(struct most_interface *iface, int id)\n{\n\tstruct most_channel *c = iface->p->channel[id];\n\n\tif (!c)\n\t\treturn;\n\n\tmutex_lock(&c->nq_mutex);\n\tc->enqueue_halt = true;\n\tmutex_unlock(&c->nq_mutex);\n}\nEXPORT_SYMBOL_GPL(most_stop_enqueue);\n\n \nvoid most_resume_enqueue(struct most_interface *iface, int id)\n{\n\tstruct most_channel *c = iface->p->channel[id];\n\n\tif (!c)\n\t\treturn;\n\n\tmutex_lock(&c->nq_mutex);\n\tc->enqueue_halt = false;\n\tmutex_unlock(&c->nq_mutex);\n\n\twake_up_interruptible(&c->hdm_fifo_wq);\n}\nEXPORT_SYMBOL_GPL(most_resume_enqueue);\n\nstatic int __init most_init(void)\n{\n\tint err;\n\n\tINIT_LIST_HEAD(&comp_list);\n\tida_init(&mdev_id);\n\n\terr = bus_register(&mostbus);\n\tif (err) {\n\t\tpr_err(\"Failed to register most bus\\n\");\n\t\treturn err;\n\t}\n\terr = driver_register(&mostbus_driver);\n\tif (err) {\n\t\tpr_err(\"Failed to register core driver\\n\");\n\t\tgoto err_unregister_bus;\n\t}\n\tconfigfs_init();\n\treturn 0;\n\nerr_unregister_bus:\n\tbus_unregister(&mostbus);\n\treturn err;\n}\n\nstatic void __exit most_exit(void)\n{\n\tdriver_unregister(&mostbus_driver);\n\tbus_unregister(&mostbus);\n\tida_destroy(&mdev_id);\n}\n\nsubsys_initcall(most_init);\nmodule_exit(most_exit);\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Christian Gromm <christian.gromm@microchip.com>\");\nMODULE_DESCRIPTION(\"Core module of stacked MOST Linux driver\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}