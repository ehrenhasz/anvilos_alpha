{
  "module_name": "arm_arch_timer.c",
  "hash_id": "c2123307dbdcc391bce4c8f8563cc610a45598ad3c1a1afd0134bbb6b606feb2",
  "original_prompt": "Ingested from linux-6.6.14/drivers/clocksource/arm_arch_timer.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \t\"arch_timer: \" fmt\n\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/device.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/cpu_pm.h>\n#include <linux/clockchips.h>\n#include <linux/clocksource.h>\n#include <linux/clocksource_ids.h>\n#include <linux/interrupt.h>\n#include <linux/kstrtox.h>\n#include <linux/of_irq.h>\n#include <linux/of_address.h>\n#include <linux/io.h>\n#include <linux/slab.h>\n#include <linux/sched/clock.h>\n#include <linux/sched_clock.h>\n#include <linux/acpi.h>\n#include <linux/arm-smccc.h>\n#include <linux/ptp_kvm.h>\n\n#include <asm/arch_timer.h>\n#include <asm/virt.h>\n\n#include <clocksource/arm_arch_timer.h>\n\n#define CNTTIDR\t\t0x08\n#define CNTTIDR_VIRT(n)\t(BIT(1) << ((n) * 4))\n\n#define CNTACR(n)\t(0x40 + ((n) * 4))\n#define CNTACR_RPCT\tBIT(0)\n#define CNTACR_RVCT\tBIT(1)\n#define CNTACR_RFRQ\tBIT(2)\n#define CNTACR_RVOFF\tBIT(3)\n#define CNTACR_RWVT\tBIT(4)\n#define CNTACR_RWPT\tBIT(5)\n\n#define CNTPCT_LO\t0x00\n#define CNTVCT_LO\t0x08\n#define CNTFRQ\t\t0x10\n#define CNTP_CVAL_LO\t0x20\n#define CNTP_CTL\t0x2c\n#define CNTV_CVAL_LO\t0x30\n#define CNTV_CTL\t0x3c\n\n \n#define MIN_ROLLOVER_SECS\t(40ULL * 365 * 24 * 3600)\n\nstatic unsigned arch_timers_present __initdata;\n\nstruct arch_timer {\n\tvoid __iomem *base;\n\tstruct clock_event_device evt;\n};\n\nstatic struct arch_timer *arch_timer_mem __ro_after_init;\n\n#define to_arch_timer(e) container_of(e, struct arch_timer, evt)\n\nstatic u32 arch_timer_rate __ro_after_init;\nstatic int arch_timer_ppi[ARCH_TIMER_MAX_TIMER_PPI] __ro_after_init;\n\nstatic const char *arch_timer_ppi_names[ARCH_TIMER_MAX_TIMER_PPI] = {\n\t[ARCH_TIMER_PHYS_SECURE_PPI]\t= \"sec-phys\",\n\t[ARCH_TIMER_PHYS_NONSECURE_PPI]\t= \"phys\",\n\t[ARCH_TIMER_VIRT_PPI]\t\t= \"virt\",\n\t[ARCH_TIMER_HYP_PPI]\t\t= \"hyp-phys\",\n\t[ARCH_TIMER_HYP_VIRT_PPI]\t= \"hyp-virt\",\n};\n\nstatic struct clock_event_device __percpu *arch_timer_evt;\n\nstatic enum arch_timer_ppi_nr arch_timer_uses_ppi __ro_after_init = ARCH_TIMER_VIRT_PPI;\nstatic bool arch_timer_c3stop __ro_after_init;\nstatic bool arch_timer_mem_use_virtual __ro_after_init;\nstatic bool arch_counter_suspend_stop __ro_after_init;\n#ifdef CONFIG_GENERIC_GETTIMEOFDAY\nstatic enum vdso_clock_mode vdso_default = VDSO_CLOCKMODE_ARCHTIMER;\n#else\nstatic enum vdso_clock_mode vdso_default = VDSO_CLOCKMODE_NONE;\n#endif  \n\nstatic cpumask_t evtstrm_available = CPU_MASK_NONE;\nstatic bool evtstrm_enable __ro_after_init = IS_ENABLED(CONFIG_ARM_ARCH_TIMER_EVTSTREAM);\n\nstatic int __init early_evtstrm_cfg(char *buf)\n{\n\treturn kstrtobool(buf, &evtstrm_enable);\n}\nearly_param(\"clocksource.arm_arch_timer.evtstrm\", early_evtstrm_cfg);\n\n \nstatic int arch_counter_get_width(void)\n{\n\tu64 min_cycles = MIN_ROLLOVER_SECS * arch_timer_rate;\n\n\t \n\treturn clamp_val(ilog2(min_cycles - 1) + 1, 56, 64);\n}\n\n \n\nstatic __always_inline\nvoid arch_timer_reg_write(int access, enum arch_timer_reg reg, u64 val,\n\t\t\t  struct clock_event_device *clk)\n{\n\tif (access == ARCH_TIMER_MEM_PHYS_ACCESS) {\n\t\tstruct arch_timer *timer = to_arch_timer(clk);\n\t\tswitch (reg) {\n\t\tcase ARCH_TIMER_REG_CTRL:\n\t\t\twritel_relaxed((u32)val, timer->base + CNTP_CTL);\n\t\t\tbreak;\n\t\tcase ARCH_TIMER_REG_CVAL:\n\t\t\t \n\t\t\twriteq_relaxed(val, timer->base + CNTP_CVAL_LO);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUILD_BUG();\n\t\t}\n\t} else if (access == ARCH_TIMER_MEM_VIRT_ACCESS) {\n\t\tstruct arch_timer *timer = to_arch_timer(clk);\n\t\tswitch (reg) {\n\t\tcase ARCH_TIMER_REG_CTRL:\n\t\t\twritel_relaxed((u32)val, timer->base + CNTV_CTL);\n\t\t\tbreak;\n\t\tcase ARCH_TIMER_REG_CVAL:\n\t\t\t \n\t\t\twriteq_relaxed(val, timer->base + CNTV_CVAL_LO);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUILD_BUG();\n\t\t}\n\t} else {\n\t\tarch_timer_reg_write_cp15(access, reg, val);\n\t}\n}\n\nstatic __always_inline\nu32 arch_timer_reg_read(int access, enum arch_timer_reg reg,\n\t\t\tstruct clock_event_device *clk)\n{\n\tu32 val;\n\n\tif (access == ARCH_TIMER_MEM_PHYS_ACCESS) {\n\t\tstruct arch_timer *timer = to_arch_timer(clk);\n\t\tswitch (reg) {\n\t\tcase ARCH_TIMER_REG_CTRL:\n\t\t\tval = readl_relaxed(timer->base + CNTP_CTL);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUILD_BUG();\n\t\t}\n\t} else if (access == ARCH_TIMER_MEM_VIRT_ACCESS) {\n\t\tstruct arch_timer *timer = to_arch_timer(clk);\n\t\tswitch (reg) {\n\t\tcase ARCH_TIMER_REG_CTRL:\n\t\t\tval = readl_relaxed(timer->base + CNTV_CTL);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUILD_BUG();\n\t\t}\n\t} else {\n\t\tval = arch_timer_reg_read_cp15(access, reg);\n\t}\n\n\treturn val;\n}\n\nstatic noinstr u64 raw_counter_get_cntpct_stable(void)\n{\n\treturn __arch_counter_get_cntpct_stable();\n}\n\nstatic notrace u64 arch_counter_get_cntpct_stable(void)\n{\n\tu64 val;\n\tpreempt_disable_notrace();\n\tval = __arch_counter_get_cntpct_stable();\n\tpreempt_enable_notrace();\n\treturn val;\n}\n\nstatic noinstr u64 arch_counter_get_cntpct(void)\n{\n\treturn __arch_counter_get_cntpct();\n}\n\nstatic noinstr u64 raw_counter_get_cntvct_stable(void)\n{\n\treturn __arch_counter_get_cntvct_stable();\n}\n\nstatic notrace u64 arch_counter_get_cntvct_stable(void)\n{\n\tu64 val;\n\tpreempt_disable_notrace();\n\tval = __arch_counter_get_cntvct_stable();\n\tpreempt_enable_notrace();\n\treturn val;\n}\n\nstatic noinstr u64 arch_counter_get_cntvct(void)\n{\n\treturn __arch_counter_get_cntvct();\n}\n\n \nu64 (*arch_timer_read_counter)(void) __ro_after_init = arch_counter_get_cntvct;\nEXPORT_SYMBOL_GPL(arch_timer_read_counter);\n\nstatic u64 arch_counter_read(struct clocksource *cs)\n{\n\treturn arch_timer_read_counter();\n}\n\nstatic u64 arch_counter_read_cc(const struct cyclecounter *cc)\n{\n\treturn arch_timer_read_counter();\n}\n\nstatic struct clocksource clocksource_counter = {\n\t.name\t= \"arch_sys_counter\",\n\t.id\t= CSID_ARM_ARCH_COUNTER,\n\t.rating\t= 400,\n\t.read\t= arch_counter_read,\n\t.flags\t= CLOCK_SOURCE_IS_CONTINUOUS,\n};\n\nstatic struct cyclecounter cyclecounter __ro_after_init = {\n\t.read\t= arch_counter_read_cc,\n};\n\nstruct ate_acpi_oem_info {\n\tchar oem_id[ACPI_OEM_ID_SIZE + 1];\n\tchar oem_table_id[ACPI_OEM_TABLE_ID_SIZE + 1];\n\tu32 oem_revision;\n};\n\n#ifdef CONFIG_FSL_ERRATUM_A008585\n \n#define __fsl_a008585_read_reg(reg) ({\t\t\t\\\n\tu64 _old, _new;\t\t\t\t\t\\\n\tint _retries = 200;\t\t\t\t\\\n\t\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\\\n\t\t_old = read_sysreg(reg);\t\t\\\n\t\t_new = read_sysreg(reg);\t\t\\\n\t\t_retries--;\t\t\t\t\\\n\t} while (unlikely(_old != _new) && _retries);\t\\\n\t\t\t\t\t\t\t\\\n\tWARN_ON_ONCE(!_retries);\t\t\t\\\n\t_new;\t\t\t\t\t\t\\\n})\n\nstatic u64 notrace fsl_a008585_read_cntpct_el0(void)\n{\n\treturn __fsl_a008585_read_reg(cntpct_el0);\n}\n\nstatic u64 notrace fsl_a008585_read_cntvct_el0(void)\n{\n\treturn __fsl_a008585_read_reg(cntvct_el0);\n}\n#endif\n\n#ifdef CONFIG_HISILICON_ERRATUM_161010101\n \n#define __hisi_161010101_read_reg(reg) ({\t\t\t\t\\\n\tu64 _old, _new;\t\t\t\t\t\t\\\n\tint _retries = 50;\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\t_old = read_sysreg(reg);\t\t\t\\\n\t\t_new = read_sysreg(reg);\t\t\t\\\n\t\t_retries--;\t\t\t\t\t\\\n\t} while (unlikely((_new - _old) >> 5) && _retries);\t\\\n\t\t\t\t\t\t\t\t\\\n\tWARN_ON_ONCE(!_retries);\t\t\t\t\\\n\t_new;\t\t\t\t\t\t\t\\\n})\n\nstatic u64 notrace hisi_161010101_read_cntpct_el0(void)\n{\n\treturn __hisi_161010101_read_reg(cntpct_el0);\n}\n\nstatic u64 notrace hisi_161010101_read_cntvct_el0(void)\n{\n\treturn __hisi_161010101_read_reg(cntvct_el0);\n}\n\nstatic struct ate_acpi_oem_info hisi_161010101_oem_info[] = {\n\t \n\t{\n\t\t.oem_id\t\t= \"HISI  \",\n\t\t.oem_table_id\t= \"HIP05   \",\n\t\t.oem_revision\t= 0,\n\t},\n\t{\n\t\t.oem_id\t\t= \"HISI  \",\n\t\t.oem_table_id\t= \"HIP06   \",\n\t\t.oem_revision\t= 0,\n\t},\n\t{\n\t\t.oem_id\t\t= \"HISI  \",\n\t\t.oem_table_id\t= \"HIP07   \",\n\t\t.oem_revision\t= 0,\n\t},\n\t{   },\n};\n#endif\n\n#ifdef CONFIG_ARM64_ERRATUM_858921\nstatic u64 notrace arm64_858921_read_cntpct_el0(void)\n{\n\tu64 old, new;\n\n\told = read_sysreg(cntpct_el0);\n\tnew = read_sysreg(cntpct_el0);\n\treturn (((old ^ new) >> 32) & 1) ? old : new;\n}\n\nstatic u64 notrace arm64_858921_read_cntvct_el0(void)\n{\n\tu64 old, new;\n\n\told = read_sysreg(cntvct_el0);\n\tnew = read_sysreg(cntvct_el0);\n\treturn (((old ^ new) >> 32) & 1) ? old : new;\n}\n#endif\n\n#ifdef CONFIG_SUN50I_ERRATUM_UNKNOWN1\n \n#define __sun50i_a64_read_reg(reg) ({\t\t\t\t\t\\\n\tu64 _val;\t\t\t\t\t\t\t\\\n\tint _retries = 150;\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\t_val = read_sysreg(reg);\t\t\t\t\\\n\t\t_retries--;\t\t\t\t\t\t\\\n\t} while (((_val + 1) & GENMASK(8, 0)) <= 1 && _retries);\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tWARN_ON_ONCE(!_retries);\t\t\t\t\t\\\n\t_val;\t\t\t\t\t\t\t\t\\\n})\n\nstatic u64 notrace sun50i_a64_read_cntpct_el0(void)\n{\n\treturn __sun50i_a64_read_reg(cntpct_el0);\n}\n\nstatic u64 notrace sun50i_a64_read_cntvct_el0(void)\n{\n\treturn __sun50i_a64_read_reg(cntvct_el0);\n}\n#endif\n\n#ifdef CONFIG_ARM_ARCH_TIMER_OOL_WORKAROUND\nDEFINE_PER_CPU(const struct arch_timer_erratum_workaround *, timer_unstable_counter_workaround);\nEXPORT_SYMBOL_GPL(timer_unstable_counter_workaround);\n\nstatic atomic_t timer_unstable_counter_workaround_in_use = ATOMIC_INIT(0);\n\n \nstatic __always_inline\nvoid erratum_set_next_event_generic(const int access, unsigned long evt,\n\t\t\t\t    struct clock_event_device *clk)\n{\n\tunsigned long ctrl;\n\tu64 cval;\n\n\tctrl = arch_timer_reg_read(access, ARCH_TIMER_REG_CTRL, clk);\n\tctrl |= ARCH_TIMER_CTRL_ENABLE;\n\tctrl &= ~ARCH_TIMER_CTRL_IT_MASK;\n\n\tif (access == ARCH_TIMER_PHYS_ACCESS) {\n\t\tcval = evt + arch_counter_get_cntpct_stable();\n\t\twrite_sysreg(cval, cntp_cval_el0);\n\t} else {\n\t\tcval = evt + arch_counter_get_cntvct_stable();\n\t\twrite_sysreg(cval, cntv_cval_el0);\n\t}\n\n\tarch_timer_reg_write(access, ARCH_TIMER_REG_CTRL, ctrl, clk);\n}\n\nstatic __maybe_unused int erratum_set_next_event_virt(unsigned long evt,\n\t\t\t\t\t    struct clock_event_device *clk)\n{\n\terratum_set_next_event_generic(ARCH_TIMER_VIRT_ACCESS, evt, clk);\n\treturn 0;\n}\n\nstatic __maybe_unused int erratum_set_next_event_phys(unsigned long evt,\n\t\t\t\t\t    struct clock_event_device *clk)\n{\n\terratum_set_next_event_generic(ARCH_TIMER_PHYS_ACCESS, evt, clk);\n\treturn 0;\n}\n\nstatic const struct arch_timer_erratum_workaround ool_workarounds[] = {\n#ifdef CONFIG_FSL_ERRATUM_A008585\n\t{\n\t\t.match_type = ate_match_dt,\n\t\t.id = \"fsl,erratum-a008585\",\n\t\t.desc = \"Freescale erratum a005858\",\n\t\t.read_cntpct_el0 = fsl_a008585_read_cntpct_el0,\n\t\t.read_cntvct_el0 = fsl_a008585_read_cntvct_el0,\n\t\t.set_next_event_phys = erratum_set_next_event_phys,\n\t\t.set_next_event_virt = erratum_set_next_event_virt,\n\t},\n#endif\n#ifdef CONFIG_HISILICON_ERRATUM_161010101\n\t{\n\t\t.match_type = ate_match_dt,\n\t\t.id = \"hisilicon,erratum-161010101\",\n\t\t.desc = \"HiSilicon erratum 161010101\",\n\t\t.read_cntpct_el0 = hisi_161010101_read_cntpct_el0,\n\t\t.read_cntvct_el0 = hisi_161010101_read_cntvct_el0,\n\t\t.set_next_event_phys = erratum_set_next_event_phys,\n\t\t.set_next_event_virt = erratum_set_next_event_virt,\n\t},\n\t{\n\t\t.match_type = ate_match_acpi_oem_info,\n\t\t.id = hisi_161010101_oem_info,\n\t\t.desc = \"HiSilicon erratum 161010101\",\n\t\t.read_cntpct_el0 = hisi_161010101_read_cntpct_el0,\n\t\t.read_cntvct_el0 = hisi_161010101_read_cntvct_el0,\n\t\t.set_next_event_phys = erratum_set_next_event_phys,\n\t\t.set_next_event_virt = erratum_set_next_event_virt,\n\t},\n#endif\n#ifdef CONFIG_ARM64_ERRATUM_858921\n\t{\n\t\t.match_type = ate_match_local_cap_id,\n\t\t.id = (void *)ARM64_WORKAROUND_858921,\n\t\t.desc = \"ARM erratum 858921\",\n\t\t.read_cntpct_el0 = arm64_858921_read_cntpct_el0,\n\t\t.read_cntvct_el0 = arm64_858921_read_cntvct_el0,\n\t\t.set_next_event_phys = erratum_set_next_event_phys,\n\t\t.set_next_event_virt = erratum_set_next_event_virt,\n\t},\n#endif\n#ifdef CONFIG_SUN50I_ERRATUM_UNKNOWN1\n\t{\n\t\t.match_type = ate_match_dt,\n\t\t.id = \"allwinner,erratum-unknown1\",\n\t\t.desc = \"Allwinner erratum UNKNOWN1\",\n\t\t.read_cntpct_el0 = sun50i_a64_read_cntpct_el0,\n\t\t.read_cntvct_el0 = sun50i_a64_read_cntvct_el0,\n\t\t.set_next_event_phys = erratum_set_next_event_phys,\n\t\t.set_next_event_virt = erratum_set_next_event_virt,\n\t},\n#endif\n#ifdef CONFIG_ARM64_ERRATUM_1418040\n\t{\n\t\t.match_type = ate_match_local_cap_id,\n\t\t.id = (void *)ARM64_WORKAROUND_1418040,\n\t\t.desc = \"ARM erratum 1418040\",\n\t\t.disable_compat_vdso = true,\n\t},\n#endif\n};\n\ntypedef bool (*ate_match_fn_t)(const struct arch_timer_erratum_workaround *,\n\t\t\t       const void *);\n\nstatic\nbool arch_timer_check_dt_erratum(const struct arch_timer_erratum_workaround *wa,\n\t\t\t\t const void *arg)\n{\n\tconst struct device_node *np = arg;\n\n\treturn of_property_read_bool(np, wa->id);\n}\n\nstatic\nbool arch_timer_check_local_cap_erratum(const struct arch_timer_erratum_workaround *wa,\n\t\t\t\t\tconst void *arg)\n{\n\treturn this_cpu_has_cap((uintptr_t)wa->id);\n}\n\n\nstatic\nbool arch_timer_check_acpi_oem_erratum(const struct arch_timer_erratum_workaround *wa,\n\t\t\t\t       const void *arg)\n{\n\tstatic const struct ate_acpi_oem_info empty_oem_info = {};\n\tconst struct ate_acpi_oem_info *info = wa->id;\n\tconst struct acpi_table_header *table = arg;\n\n\t \n\twhile (memcmp(info, &empty_oem_info, sizeof(*info))) {\n\t\tif (!memcmp(info->oem_id, table->oem_id, ACPI_OEM_ID_SIZE) &&\n\t\t    !memcmp(info->oem_table_id, table->oem_table_id, ACPI_OEM_TABLE_ID_SIZE) &&\n\t\t    info->oem_revision == table->oem_revision)\n\t\t\treturn true;\n\n\t\tinfo++;\n\t}\n\n\treturn false;\n}\n\nstatic const struct arch_timer_erratum_workaround *\narch_timer_iterate_errata(enum arch_timer_erratum_match_type type,\n\t\t\t  ate_match_fn_t match_fn,\n\t\t\t  void *arg)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(ool_workarounds); i++) {\n\t\tif (ool_workarounds[i].match_type != type)\n\t\t\tcontinue;\n\n\t\tif (match_fn(&ool_workarounds[i], arg))\n\t\t\treturn &ool_workarounds[i];\n\t}\n\n\treturn NULL;\n}\n\nstatic\nvoid arch_timer_enable_workaround(const struct arch_timer_erratum_workaround *wa,\n\t\t\t\t  bool local)\n{\n\tint i;\n\n\tif (local) {\n\t\t__this_cpu_write(timer_unstable_counter_workaround, wa);\n\t} else {\n\t\tfor_each_possible_cpu(i)\n\t\t\tper_cpu(timer_unstable_counter_workaround, i) = wa;\n\t}\n\n\tif (wa->read_cntvct_el0 || wa->read_cntpct_el0)\n\t\tatomic_set(&timer_unstable_counter_workaround_in_use, 1);\n\n\t \n\tif (wa->read_cntvct_el0) {\n\t\tclocksource_counter.vdso_clock_mode = VDSO_CLOCKMODE_NONE;\n\t\tvdso_default = VDSO_CLOCKMODE_NONE;\n\t} else if (wa->disable_compat_vdso && vdso_default != VDSO_CLOCKMODE_NONE) {\n\t\tvdso_default = VDSO_CLOCKMODE_ARCHTIMER_NOCOMPAT;\n\t\tclocksource_counter.vdso_clock_mode = vdso_default;\n\t}\n}\n\nstatic void arch_timer_check_ool_workaround(enum arch_timer_erratum_match_type type,\n\t\t\t\t\t    void *arg)\n{\n\tconst struct arch_timer_erratum_workaround *wa, *__wa;\n\tate_match_fn_t match_fn = NULL;\n\tbool local = false;\n\n\tswitch (type) {\n\tcase ate_match_dt:\n\t\tmatch_fn = arch_timer_check_dt_erratum;\n\t\tbreak;\n\tcase ate_match_local_cap_id:\n\t\tmatch_fn = arch_timer_check_local_cap_erratum;\n\t\tlocal = true;\n\t\tbreak;\n\tcase ate_match_acpi_oem_info:\n\t\tmatch_fn = arch_timer_check_acpi_oem_erratum;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\twa = arch_timer_iterate_errata(type, match_fn, arg);\n\tif (!wa)\n\t\treturn;\n\n\t__wa = __this_cpu_read(timer_unstable_counter_workaround);\n\tif (__wa && wa != __wa)\n\t\tpr_warn(\"Can't enable workaround for %s (clashes with %s\\n)\",\n\t\t\twa->desc, __wa->desc);\n\n\tif (__wa)\n\t\treturn;\n\n\tarch_timer_enable_workaround(wa, local);\n\tpr_info(\"Enabling %s workaround for %s\\n\",\n\t\tlocal ? \"local\" : \"global\", wa->desc);\n}\n\nstatic bool arch_timer_this_cpu_has_cntvct_wa(void)\n{\n\treturn has_erratum_handler(read_cntvct_el0);\n}\n\nstatic bool arch_timer_counter_has_wa(void)\n{\n\treturn atomic_read(&timer_unstable_counter_workaround_in_use);\n}\n#else\n#define arch_timer_check_ool_workaround(t,a)\t\tdo { } while(0)\n#define arch_timer_this_cpu_has_cntvct_wa()\t\t({false;})\n#define arch_timer_counter_has_wa()\t\t\t({false;})\n#endif  \n\nstatic __always_inline irqreturn_t timer_handler(const int access,\n\t\t\t\t\tstruct clock_event_device *evt)\n{\n\tunsigned long ctrl;\n\n\tctrl = arch_timer_reg_read(access, ARCH_TIMER_REG_CTRL, evt);\n\tif (ctrl & ARCH_TIMER_CTRL_IT_STAT) {\n\t\tctrl |= ARCH_TIMER_CTRL_IT_MASK;\n\t\tarch_timer_reg_write(access, ARCH_TIMER_REG_CTRL, ctrl, evt);\n\t\tevt->event_handler(evt);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\treturn IRQ_NONE;\n}\n\nstatic irqreturn_t arch_timer_handler_virt(int irq, void *dev_id)\n{\n\tstruct clock_event_device *evt = dev_id;\n\n\treturn timer_handler(ARCH_TIMER_VIRT_ACCESS, evt);\n}\n\nstatic irqreturn_t arch_timer_handler_phys(int irq, void *dev_id)\n{\n\tstruct clock_event_device *evt = dev_id;\n\n\treturn timer_handler(ARCH_TIMER_PHYS_ACCESS, evt);\n}\n\nstatic irqreturn_t arch_timer_handler_phys_mem(int irq, void *dev_id)\n{\n\tstruct clock_event_device *evt = dev_id;\n\n\treturn timer_handler(ARCH_TIMER_MEM_PHYS_ACCESS, evt);\n}\n\nstatic irqreturn_t arch_timer_handler_virt_mem(int irq, void *dev_id)\n{\n\tstruct clock_event_device *evt = dev_id;\n\n\treturn timer_handler(ARCH_TIMER_MEM_VIRT_ACCESS, evt);\n}\n\nstatic __always_inline int arch_timer_shutdown(const int access,\n\t\t\t\t\t       struct clock_event_device *clk)\n{\n\tunsigned long ctrl;\n\n\tctrl = arch_timer_reg_read(access, ARCH_TIMER_REG_CTRL, clk);\n\tctrl &= ~ARCH_TIMER_CTRL_ENABLE;\n\tarch_timer_reg_write(access, ARCH_TIMER_REG_CTRL, ctrl, clk);\n\n\treturn 0;\n}\n\nstatic int arch_timer_shutdown_virt(struct clock_event_device *clk)\n{\n\treturn arch_timer_shutdown(ARCH_TIMER_VIRT_ACCESS, clk);\n}\n\nstatic int arch_timer_shutdown_phys(struct clock_event_device *clk)\n{\n\treturn arch_timer_shutdown(ARCH_TIMER_PHYS_ACCESS, clk);\n}\n\nstatic int arch_timer_shutdown_virt_mem(struct clock_event_device *clk)\n{\n\treturn arch_timer_shutdown(ARCH_TIMER_MEM_VIRT_ACCESS, clk);\n}\n\nstatic int arch_timer_shutdown_phys_mem(struct clock_event_device *clk)\n{\n\treturn arch_timer_shutdown(ARCH_TIMER_MEM_PHYS_ACCESS, clk);\n}\n\nstatic __always_inline void set_next_event(const int access, unsigned long evt,\n\t\t\t\t\t   struct clock_event_device *clk)\n{\n\tunsigned long ctrl;\n\tu64 cnt;\n\n\tctrl = arch_timer_reg_read(access, ARCH_TIMER_REG_CTRL, clk);\n\tctrl |= ARCH_TIMER_CTRL_ENABLE;\n\tctrl &= ~ARCH_TIMER_CTRL_IT_MASK;\n\n\tif (access == ARCH_TIMER_PHYS_ACCESS)\n\t\tcnt = __arch_counter_get_cntpct();\n\telse\n\t\tcnt = __arch_counter_get_cntvct();\n\n\tarch_timer_reg_write(access, ARCH_TIMER_REG_CVAL, evt + cnt, clk);\n\tarch_timer_reg_write(access, ARCH_TIMER_REG_CTRL, ctrl, clk);\n}\n\nstatic int arch_timer_set_next_event_virt(unsigned long evt,\n\t\t\t\t\t  struct clock_event_device *clk)\n{\n\tset_next_event(ARCH_TIMER_VIRT_ACCESS, evt, clk);\n\treturn 0;\n}\n\nstatic int arch_timer_set_next_event_phys(unsigned long evt,\n\t\t\t\t\t  struct clock_event_device *clk)\n{\n\tset_next_event(ARCH_TIMER_PHYS_ACCESS, evt, clk);\n\treturn 0;\n}\n\nstatic noinstr u64 arch_counter_get_cnt_mem(struct arch_timer *t, int offset_lo)\n{\n\tu32 cnt_lo, cnt_hi, tmp_hi;\n\n\tdo {\n\t\tcnt_hi = __le32_to_cpu((__le32 __force)__raw_readl(t->base + offset_lo + 4));\n\t\tcnt_lo = __le32_to_cpu((__le32 __force)__raw_readl(t->base + offset_lo));\n\t\ttmp_hi = __le32_to_cpu((__le32 __force)__raw_readl(t->base + offset_lo + 4));\n\t} while (cnt_hi != tmp_hi);\n\n\treturn ((u64) cnt_hi << 32) | cnt_lo;\n}\n\nstatic __always_inline void set_next_event_mem(const int access, unsigned long evt,\n\t\t\t\t\t   struct clock_event_device *clk)\n{\n\tstruct arch_timer *timer = to_arch_timer(clk);\n\tunsigned long ctrl;\n\tu64 cnt;\n\n\tctrl = arch_timer_reg_read(access, ARCH_TIMER_REG_CTRL, clk);\n\n\t \n\tif (ctrl & ARCH_TIMER_CTRL_ENABLE) {\n\t\tctrl &= ~ARCH_TIMER_CTRL_ENABLE;\n\t\tarch_timer_reg_write(access, ARCH_TIMER_REG_CTRL, ctrl, clk);\n\t}\n\n\tctrl |= ARCH_TIMER_CTRL_ENABLE;\n\tctrl &= ~ARCH_TIMER_CTRL_IT_MASK;\n\n\tif (access ==  ARCH_TIMER_MEM_VIRT_ACCESS)\n\t\tcnt = arch_counter_get_cnt_mem(timer, CNTVCT_LO);\n\telse\n\t\tcnt = arch_counter_get_cnt_mem(timer, CNTPCT_LO);\n\n\tarch_timer_reg_write(access, ARCH_TIMER_REG_CVAL, evt + cnt, clk);\n\tarch_timer_reg_write(access, ARCH_TIMER_REG_CTRL, ctrl, clk);\n}\n\nstatic int arch_timer_set_next_event_virt_mem(unsigned long evt,\n\t\t\t\t\t      struct clock_event_device *clk)\n{\n\tset_next_event_mem(ARCH_TIMER_MEM_VIRT_ACCESS, evt, clk);\n\treturn 0;\n}\n\nstatic int arch_timer_set_next_event_phys_mem(unsigned long evt,\n\t\t\t\t\t      struct clock_event_device *clk)\n{\n\tset_next_event_mem(ARCH_TIMER_MEM_PHYS_ACCESS, evt, clk);\n\treturn 0;\n}\n\nstatic u64 __arch_timer_check_delta(void)\n{\n#ifdef CONFIG_ARM64\n\tconst struct midr_range broken_cval_midrs[] = {\n\t\t \n\t\tMIDR_REV_RANGE(MIDR_CPU_MODEL(ARM_CPU_IMP_APM,\n\t\t\t\t\t      APM_CPU_PART_XGENE),\n\t\t\t       APM_CPU_VAR_POTENZA, 0x0, 0xf),\n\t\t{},\n\t};\n\n\tif (is_midr_in_range_list(read_cpuid_id(), broken_cval_midrs)) {\n\t\tpr_warn_once(\"Broken CNTx_CVAL_EL1, using 31 bit TVAL instead.\\n\");\n\t\treturn CLOCKSOURCE_MASK(31);\n\t}\n#endif\n\treturn CLOCKSOURCE_MASK(arch_counter_get_width());\n}\n\nstatic void __arch_timer_setup(unsigned type,\n\t\t\t       struct clock_event_device *clk)\n{\n\tu64 max_delta;\n\n\tclk->features = CLOCK_EVT_FEAT_ONESHOT;\n\n\tif (type == ARCH_TIMER_TYPE_CP15) {\n\t\ttypeof(clk->set_next_event) sne;\n\n\t\tarch_timer_check_ool_workaround(ate_match_local_cap_id, NULL);\n\n\t\tif (arch_timer_c3stop)\n\t\t\tclk->features |= CLOCK_EVT_FEAT_C3STOP;\n\t\tclk->name = \"arch_sys_timer\";\n\t\tclk->rating = 450;\n\t\tclk->cpumask = cpumask_of(smp_processor_id());\n\t\tclk->irq = arch_timer_ppi[arch_timer_uses_ppi];\n\t\tswitch (arch_timer_uses_ppi) {\n\t\tcase ARCH_TIMER_VIRT_PPI:\n\t\t\tclk->set_state_shutdown = arch_timer_shutdown_virt;\n\t\t\tclk->set_state_oneshot_stopped = arch_timer_shutdown_virt;\n\t\t\tsne = erratum_handler(set_next_event_virt);\n\t\t\tbreak;\n\t\tcase ARCH_TIMER_PHYS_SECURE_PPI:\n\t\tcase ARCH_TIMER_PHYS_NONSECURE_PPI:\n\t\tcase ARCH_TIMER_HYP_PPI:\n\t\t\tclk->set_state_shutdown = arch_timer_shutdown_phys;\n\t\t\tclk->set_state_oneshot_stopped = arch_timer_shutdown_phys;\n\t\t\tsne = erratum_handler(set_next_event_phys);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\n\t\tclk->set_next_event = sne;\n\t\tmax_delta = __arch_timer_check_delta();\n\t} else {\n\t\tclk->features |= CLOCK_EVT_FEAT_DYNIRQ;\n\t\tclk->name = \"arch_mem_timer\";\n\t\tclk->rating = 400;\n\t\tclk->cpumask = cpu_possible_mask;\n\t\tif (arch_timer_mem_use_virtual) {\n\t\t\tclk->set_state_shutdown = arch_timer_shutdown_virt_mem;\n\t\t\tclk->set_state_oneshot_stopped = arch_timer_shutdown_virt_mem;\n\t\t\tclk->set_next_event =\n\t\t\t\tarch_timer_set_next_event_virt_mem;\n\t\t} else {\n\t\t\tclk->set_state_shutdown = arch_timer_shutdown_phys_mem;\n\t\t\tclk->set_state_oneshot_stopped = arch_timer_shutdown_phys_mem;\n\t\t\tclk->set_next_event =\n\t\t\t\tarch_timer_set_next_event_phys_mem;\n\t\t}\n\n\t\tmax_delta = CLOCKSOURCE_MASK(56);\n\t}\n\n\tclk->set_state_shutdown(clk);\n\n\tclockevents_config_and_register(clk, arch_timer_rate, 0xf, max_delta);\n}\n\nstatic void arch_timer_evtstrm_enable(unsigned int divider)\n{\n\tu32 cntkctl = arch_timer_get_cntkctl();\n\n#ifdef CONFIG_ARM64\n\t \n\tif (cpus_have_const_cap(ARM64_HAS_ECV) && divider > 15) {\n\t\tcntkctl |= ARCH_TIMER_EVT_INTERVAL_SCALE;\n\t\tdivider -= 8;\n\t}\n#endif\n\n\tdivider = min(divider, 15U);\n\tcntkctl &= ~ARCH_TIMER_EVT_TRIGGER_MASK;\n\t \n\tcntkctl |= (divider << ARCH_TIMER_EVT_TRIGGER_SHIFT)\n\t\t\t| ARCH_TIMER_VIRT_EVT_EN;\n\tarch_timer_set_cntkctl(cntkctl);\n\tarch_timer_set_evtstrm_feature();\n\tcpumask_set_cpu(smp_processor_id(), &evtstrm_available);\n}\n\nstatic void arch_timer_configure_evtstream(void)\n{\n\tint evt_stream_div, lsb;\n\n\t \n\tevt_stream_div = arch_timer_rate / ARCH_TIMER_EVT_STREAM_FREQ / 2;\n\n\t \n\tlsb = fls(evt_stream_div) - 1;\n\tif (lsb > 0 && (evt_stream_div & BIT(lsb - 1)))\n\t\tlsb++;\n\n\t \n\tarch_timer_evtstrm_enable(max(0, lsb));\n}\n\nstatic void arch_counter_set_user_access(void)\n{\n\tu32 cntkctl = arch_timer_get_cntkctl();\n\n\t \n\t \n\tcntkctl &= ~(ARCH_TIMER_USR_PT_ACCESS_EN\n\t\t\t| ARCH_TIMER_USR_VT_ACCESS_EN\n\t\t        | ARCH_TIMER_USR_VCT_ACCESS_EN\n\t\t\t| ARCH_TIMER_VIRT_EVT_EN\n\t\t\t| ARCH_TIMER_USR_PCT_ACCESS_EN);\n\n\t \n\tif (arch_timer_this_cpu_has_cntvct_wa())\n\t\tpr_info(\"CPU%d: Trapping CNTVCT access\\n\", smp_processor_id());\n\telse\n\t\tcntkctl |= ARCH_TIMER_USR_VCT_ACCESS_EN;\n\n\tarch_timer_set_cntkctl(cntkctl);\n}\n\nstatic bool arch_timer_has_nonsecure_ppi(void)\n{\n\treturn (arch_timer_uses_ppi == ARCH_TIMER_PHYS_SECURE_PPI &&\n\t\tarch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI]);\n}\n\nstatic u32 check_ppi_trigger(int irq)\n{\n\tu32 flags = irq_get_trigger_type(irq);\n\n\tif (flags != IRQF_TRIGGER_HIGH && flags != IRQF_TRIGGER_LOW) {\n\t\tpr_warn(\"WARNING: Invalid trigger for IRQ%d, assuming level low\\n\", irq);\n\t\tpr_warn(\"WARNING: Please fix your firmware\\n\");\n\t\tflags = IRQF_TRIGGER_LOW;\n\t}\n\n\treturn flags;\n}\n\nstatic int arch_timer_starting_cpu(unsigned int cpu)\n{\n\tstruct clock_event_device *clk = this_cpu_ptr(arch_timer_evt);\n\tu32 flags;\n\n\t__arch_timer_setup(ARCH_TIMER_TYPE_CP15, clk);\n\n\tflags = check_ppi_trigger(arch_timer_ppi[arch_timer_uses_ppi]);\n\tenable_percpu_irq(arch_timer_ppi[arch_timer_uses_ppi], flags);\n\n\tif (arch_timer_has_nonsecure_ppi()) {\n\t\tflags = check_ppi_trigger(arch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI]);\n\t\tenable_percpu_irq(arch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI],\n\t\t\t\t  flags);\n\t}\n\n\tarch_counter_set_user_access();\n\tif (evtstrm_enable)\n\t\tarch_timer_configure_evtstream();\n\n\treturn 0;\n}\n\nstatic int validate_timer_rate(void)\n{\n\tif (!arch_timer_rate)\n\t\treturn -EINVAL;\n\n\t \n\tWARN_ON(arch_timer_rate < 1000000);\n\n\treturn 0;\n}\n\n \nstatic void __init arch_timer_of_configure_rate(u32 rate, struct device_node *np)\n{\n\t \n\tif (arch_timer_rate)\n\t\treturn;\n\n\tif (of_property_read_u32(np, \"clock-frequency\", &arch_timer_rate))\n\t\tarch_timer_rate = rate;\n\n\t \n\tif (validate_timer_rate())\n\t\tpr_warn(\"frequency not available\\n\");\n}\n\nstatic void __init arch_timer_banner(unsigned type)\n{\n\tpr_info(\"%s%s%s timer(s) running at %lu.%02luMHz (%s%s%s).\\n\",\n\t\ttype & ARCH_TIMER_TYPE_CP15 ? \"cp15\" : \"\",\n\t\ttype == (ARCH_TIMER_TYPE_CP15 | ARCH_TIMER_TYPE_MEM) ?\n\t\t\t\" and \" : \"\",\n\t\ttype & ARCH_TIMER_TYPE_MEM ? \"mmio\" : \"\",\n\t\t(unsigned long)arch_timer_rate / 1000000,\n\t\t(unsigned long)(arch_timer_rate / 10000) % 100,\n\t\ttype & ARCH_TIMER_TYPE_CP15 ?\n\t\t\t(arch_timer_uses_ppi == ARCH_TIMER_VIRT_PPI) ? \"virt\" : \"phys\" :\n\t\t\t\"\",\n\t\ttype == (ARCH_TIMER_TYPE_CP15 | ARCH_TIMER_TYPE_MEM) ? \"/\" : \"\",\n\t\ttype & ARCH_TIMER_TYPE_MEM ?\n\t\t\tarch_timer_mem_use_virtual ? \"virt\" : \"phys\" :\n\t\t\t\"\");\n}\n\nu32 arch_timer_get_rate(void)\n{\n\treturn arch_timer_rate;\n}\n\nbool arch_timer_evtstrm_available(void)\n{\n\t \n\treturn cpumask_test_cpu(raw_smp_processor_id(), &evtstrm_available);\n}\n\nstatic noinstr u64 arch_counter_get_cntvct_mem(void)\n{\n\treturn arch_counter_get_cnt_mem(arch_timer_mem, CNTVCT_LO);\n}\n\nstatic struct arch_timer_kvm_info arch_timer_kvm_info;\n\nstruct arch_timer_kvm_info *arch_timer_get_kvm_info(void)\n{\n\treturn &arch_timer_kvm_info;\n}\n\nstatic void __init arch_counter_register(unsigned type)\n{\n\tu64 (*scr)(void);\n\tu64 start_count;\n\tint width;\n\n\t \n\tif (type & ARCH_TIMER_TYPE_CP15) {\n\t\tu64 (*rd)(void);\n\n\t\tif ((IS_ENABLED(CONFIG_ARM64) && !is_hyp_mode_available()) ||\n\t\t    arch_timer_uses_ppi == ARCH_TIMER_VIRT_PPI) {\n\t\t\tif (arch_timer_counter_has_wa()) {\n\t\t\t\trd = arch_counter_get_cntvct_stable;\n\t\t\t\tscr = raw_counter_get_cntvct_stable;\n\t\t\t} else {\n\t\t\t\trd = arch_counter_get_cntvct;\n\t\t\t\tscr = arch_counter_get_cntvct;\n\t\t\t}\n\t\t} else {\n\t\t\tif (arch_timer_counter_has_wa()) {\n\t\t\t\trd = arch_counter_get_cntpct_stable;\n\t\t\t\tscr = raw_counter_get_cntpct_stable;\n\t\t\t} else {\n\t\t\t\trd = arch_counter_get_cntpct;\n\t\t\t\tscr = arch_counter_get_cntpct;\n\t\t\t}\n\t\t}\n\n\t\tarch_timer_read_counter = rd;\n\t\tclocksource_counter.vdso_clock_mode = vdso_default;\n\t} else {\n\t\tarch_timer_read_counter = arch_counter_get_cntvct_mem;\n\t\tscr = arch_counter_get_cntvct_mem;\n\t}\n\n\twidth = arch_counter_get_width();\n\tclocksource_counter.mask = CLOCKSOURCE_MASK(width);\n\tcyclecounter.mask = CLOCKSOURCE_MASK(width);\n\n\tif (!arch_counter_suspend_stop)\n\t\tclocksource_counter.flags |= CLOCK_SOURCE_SUSPEND_NONSTOP;\n\tstart_count = arch_timer_read_counter();\n\tclocksource_register_hz(&clocksource_counter, arch_timer_rate);\n\tcyclecounter.mult = clocksource_counter.mult;\n\tcyclecounter.shift = clocksource_counter.shift;\n\ttimecounter_init(&arch_timer_kvm_info.timecounter,\n\t\t\t &cyclecounter, start_count);\n\n\tsched_clock_register(scr, width, arch_timer_rate);\n}\n\nstatic void arch_timer_stop(struct clock_event_device *clk)\n{\n\tpr_debug(\"disable IRQ%d cpu #%d\\n\", clk->irq, smp_processor_id());\n\n\tdisable_percpu_irq(arch_timer_ppi[arch_timer_uses_ppi]);\n\tif (arch_timer_has_nonsecure_ppi())\n\t\tdisable_percpu_irq(arch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI]);\n\n\tclk->set_state_shutdown(clk);\n}\n\nstatic int arch_timer_dying_cpu(unsigned int cpu)\n{\n\tstruct clock_event_device *clk = this_cpu_ptr(arch_timer_evt);\n\n\tcpumask_clear_cpu(smp_processor_id(), &evtstrm_available);\n\n\tarch_timer_stop(clk);\n\treturn 0;\n}\n\n#ifdef CONFIG_CPU_PM\nstatic DEFINE_PER_CPU(unsigned long, saved_cntkctl);\nstatic int arch_timer_cpu_pm_notify(struct notifier_block *self,\n\t\t\t\t    unsigned long action, void *hcpu)\n{\n\tif (action == CPU_PM_ENTER) {\n\t\t__this_cpu_write(saved_cntkctl, arch_timer_get_cntkctl());\n\n\t\tcpumask_clear_cpu(smp_processor_id(), &evtstrm_available);\n\t} else if (action == CPU_PM_ENTER_FAILED || action == CPU_PM_EXIT) {\n\t\tarch_timer_set_cntkctl(__this_cpu_read(saved_cntkctl));\n\n\t\tif (arch_timer_have_evtstrm_feature())\n\t\t\tcpumask_set_cpu(smp_processor_id(), &evtstrm_available);\n\t}\n\treturn NOTIFY_OK;\n}\n\nstatic struct notifier_block arch_timer_cpu_pm_notifier = {\n\t.notifier_call = arch_timer_cpu_pm_notify,\n};\n\nstatic int __init arch_timer_cpu_pm_init(void)\n{\n\treturn cpu_pm_register_notifier(&arch_timer_cpu_pm_notifier);\n}\n\nstatic void __init arch_timer_cpu_pm_deinit(void)\n{\n\tWARN_ON(cpu_pm_unregister_notifier(&arch_timer_cpu_pm_notifier));\n}\n\n#else\nstatic int __init arch_timer_cpu_pm_init(void)\n{\n\treturn 0;\n}\n\nstatic void __init arch_timer_cpu_pm_deinit(void)\n{\n}\n#endif\n\nstatic int __init arch_timer_register(void)\n{\n\tint err;\n\tint ppi;\n\n\tarch_timer_evt = alloc_percpu(struct clock_event_device);\n\tif (!arch_timer_evt) {\n\t\terr = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tppi = arch_timer_ppi[arch_timer_uses_ppi];\n\tswitch (arch_timer_uses_ppi) {\n\tcase ARCH_TIMER_VIRT_PPI:\n\t\terr = request_percpu_irq(ppi, arch_timer_handler_virt,\n\t\t\t\t\t \"arch_timer\", arch_timer_evt);\n\t\tbreak;\n\tcase ARCH_TIMER_PHYS_SECURE_PPI:\n\tcase ARCH_TIMER_PHYS_NONSECURE_PPI:\n\t\terr = request_percpu_irq(ppi, arch_timer_handler_phys,\n\t\t\t\t\t \"arch_timer\", arch_timer_evt);\n\t\tif (!err && arch_timer_has_nonsecure_ppi()) {\n\t\t\tppi = arch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI];\n\t\t\terr = request_percpu_irq(ppi, arch_timer_handler_phys,\n\t\t\t\t\t\t \"arch_timer\", arch_timer_evt);\n\t\t\tif (err)\n\t\t\t\tfree_percpu_irq(arch_timer_ppi[ARCH_TIMER_PHYS_SECURE_PPI],\n\t\t\t\t\t\tarch_timer_evt);\n\t\t}\n\t\tbreak;\n\tcase ARCH_TIMER_HYP_PPI:\n\t\terr = request_percpu_irq(ppi, arch_timer_handler_phys,\n\t\t\t\t\t \"arch_timer\", arch_timer_evt);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tif (err) {\n\t\tpr_err(\"can't register interrupt %d (%d)\\n\", ppi, err);\n\t\tgoto out_free;\n\t}\n\n\terr = arch_timer_cpu_pm_init();\n\tif (err)\n\t\tgoto out_unreg_notify;\n\n\t \n\terr = cpuhp_setup_state(CPUHP_AP_ARM_ARCH_TIMER_STARTING,\n\t\t\t\t\"clockevents/arm/arch_timer:starting\",\n\t\t\t\tarch_timer_starting_cpu, arch_timer_dying_cpu);\n\tif (err)\n\t\tgoto out_unreg_cpupm;\n\treturn 0;\n\nout_unreg_cpupm:\n\tarch_timer_cpu_pm_deinit();\n\nout_unreg_notify:\n\tfree_percpu_irq(arch_timer_ppi[arch_timer_uses_ppi], arch_timer_evt);\n\tif (arch_timer_has_nonsecure_ppi())\n\t\tfree_percpu_irq(arch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI],\n\t\t\t\tarch_timer_evt);\n\nout_free:\n\tfree_percpu(arch_timer_evt);\nout:\n\treturn err;\n}\n\nstatic int __init arch_timer_mem_register(void __iomem *base, unsigned int irq)\n{\n\tint ret;\n\tirq_handler_t func;\n\n\tarch_timer_mem = kzalloc(sizeof(*arch_timer_mem), GFP_KERNEL);\n\tif (!arch_timer_mem)\n\t\treturn -ENOMEM;\n\n\tarch_timer_mem->base = base;\n\tarch_timer_mem->evt.irq = irq;\n\t__arch_timer_setup(ARCH_TIMER_TYPE_MEM, &arch_timer_mem->evt);\n\n\tif (arch_timer_mem_use_virtual)\n\t\tfunc = arch_timer_handler_virt_mem;\n\telse\n\t\tfunc = arch_timer_handler_phys_mem;\n\n\tret = request_irq(irq, func, IRQF_TIMER, \"arch_mem_timer\", &arch_timer_mem->evt);\n\tif (ret) {\n\t\tpr_err(\"Failed to request mem timer irq\\n\");\n\t\tkfree(arch_timer_mem);\n\t\tarch_timer_mem = NULL;\n\t}\n\n\treturn ret;\n}\n\nstatic const struct of_device_id arch_timer_of_match[] __initconst = {\n\t{ .compatible   = \"arm,armv7-timer\",    },\n\t{ .compatible   = \"arm,armv8-timer\",    },\n\t{},\n};\n\nstatic const struct of_device_id arch_timer_mem_of_match[] __initconst = {\n\t{ .compatible   = \"arm,armv7-timer-mem\", },\n\t{},\n};\n\nstatic bool __init arch_timer_needs_of_probing(void)\n{\n\tstruct device_node *dn;\n\tbool needs_probing = false;\n\tunsigned int mask = ARCH_TIMER_TYPE_CP15 | ARCH_TIMER_TYPE_MEM;\n\n\t \n\tif ((arch_timers_present & mask) == mask)\n\t\treturn false;\n\n\t \n\tif (arch_timers_present & ARCH_TIMER_TYPE_CP15)\n\t\tdn = of_find_matching_node(NULL, arch_timer_mem_of_match);\n\telse\n\t\tdn = of_find_matching_node(NULL, arch_timer_of_match);\n\n\tif (dn && of_device_is_available(dn))\n\t\tneeds_probing = true;\n\n\tof_node_put(dn);\n\n\treturn needs_probing;\n}\n\nstatic int __init arch_timer_common_init(void)\n{\n\tarch_timer_banner(arch_timers_present);\n\tarch_counter_register(arch_timers_present);\n\treturn arch_timer_arch_init();\n}\n\n \nstatic enum arch_timer_ppi_nr __init arch_timer_select_ppi(void)\n{\n\tif (is_kernel_in_hyp_mode())\n\t\treturn ARCH_TIMER_HYP_PPI;\n\n\tif (!is_hyp_mode_available() && arch_timer_ppi[ARCH_TIMER_VIRT_PPI])\n\t\treturn ARCH_TIMER_VIRT_PPI;\n\n\tif (IS_ENABLED(CONFIG_ARM64))\n\t\treturn ARCH_TIMER_PHYS_NONSECURE_PPI;\n\n\treturn ARCH_TIMER_PHYS_SECURE_PPI;\n}\n\nstatic void __init arch_timer_populate_kvm_info(void)\n{\n\tarch_timer_kvm_info.virtual_irq = arch_timer_ppi[ARCH_TIMER_VIRT_PPI];\n\tif (is_kernel_in_hyp_mode())\n\t\tarch_timer_kvm_info.physical_irq = arch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI];\n}\n\nstatic int __init arch_timer_of_init(struct device_node *np)\n{\n\tint i, irq, ret;\n\tu32 rate;\n\tbool has_names;\n\n\tif (arch_timers_present & ARCH_TIMER_TYPE_CP15) {\n\t\tpr_warn(\"multiple nodes in dt, skipping\\n\");\n\t\treturn 0;\n\t}\n\n\tarch_timers_present |= ARCH_TIMER_TYPE_CP15;\n\n\thas_names = of_property_read_bool(np, \"interrupt-names\");\n\n\tfor (i = ARCH_TIMER_PHYS_SECURE_PPI; i < ARCH_TIMER_MAX_TIMER_PPI; i++) {\n\t\tif (has_names)\n\t\t\tirq = of_irq_get_byname(np, arch_timer_ppi_names[i]);\n\t\telse\n\t\t\tirq = of_irq_get(np, i);\n\t\tif (irq > 0)\n\t\t\tarch_timer_ppi[i] = irq;\n\t}\n\n\tarch_timer_populate_kvm_info();\n\n\trate = arch_timer_get_cntfrq();\n\tarch_timer_of_configure_rate(rate, np);\n\n\tarch_timer_c3stop = !of_property_read_bool(np, \"always-on\");\n\n\t \n\tarch_timer_check_ool_workaround(ate_match_dt, np);\n\n\t \n\tif (IS_ENABLED(CONFIG_ARM) &&\n\t    of_property_read_bool(np, \"arm,cpu-registers-not-fw-configured\"))\n\t\tarch_timer_uses_ppi = ARCH_TIMER_PHYS_SECURE_PPI;\n\telse\n\t\tarch_timer_uses_ppi = arch_timer_select_ppi();\n\n\tif (!arch_timer_ppi[arch_timer_uses_ppi]) {\n\t\tpr_err(\"No interrupt available, giving up\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tarch_counter_suspend_stop = of_property_read_bool(np,\n\t\t\t\t\t\t\t \"arm,no-tick-in-suspend\");\n\n\tret = arch_timer_register();\n\tif (ret)\n\t\treturn ret;\n\n\tif (arch_timer_needs_of_probing())\n\t\treturn 0;\n\n\treturn arch_timer_common_init();\n}\nTIMER_OF_DECLARE(armv7_arch_timer, \"arm,armv7-timer\", arch_timer_of_init);\nTIMER_OF_DECLARE(armv8_arch_timer, \"arm,armv8-timer\", arch_timer_of_init);\n\nstatic u32 __init\narch_timer_mem_frame_get_cntfrq(struct arch_timer_mem_frame *frame)\n{\n\tvoid __iomem *base;\n\tu32 rate;\n\n\tbase = ioremap(frame->cntbase, frame->size);\n\tif (!base) {\n\t\tpr_err(\"Unable to map frame @ %pa\\n\", &frame->cntbase);\n\t\treturn 0;\n\t}\n\n\trate = readl_relaxed(base + CNTFRQ);\n\n\tiounmap(base);\n\n\treturn rate;\n}\n\nstatic struct arch_timer_mem_frame * __init\narch_timer_mem_find_best_frame(struct arch_timer_mem *timer_mem)\n{\n\tstruct arch_timer_mem_frame *frame, *best_frame = NULL;\n\tvoid __iomem *cntctlbase;\n\tu32 cnttidr;\n\tint i;\n\n\tcntctlbase = ioremap(timer_mem->cntctlbase, timer_mem->size);\n\tif (!cntctlbase) {\n\t\tpr_err(\"Can't map CNTCTLBase @ %pa\\n\",\n\t\t\t&timer_mem->cntctlbase);\n\t\treturn NULL;\n\t}\n\n\tcnttidr = readl_relaxed(cntctlbase + CNTTIDR);\n\n\t \n\tfor (i = 0; i < ARCH_TIMER_MEM_MAX_FRAMES; i++) {\n\t\tu32 cntacr = CNTACR_RFRQ | CNTACR_RWPT | CNTACR_RPCT |\n\t\t\t     CNTACR_RWVT | CNTACR_RVOFF | CNTACR_RVCT;\n\n\t\tframe = &timer_mem->frame[i];\n\t\tif (!frame->valid)\n\t\t\tcontinue;\n\n\t\t \n\t\twritel_relaxed(cntacr, cntctlbase + CNTACR(i));\n\t\tcntacr = readl_relaxed(cntctlbase + CNTACR(i));\n\n\t\tif ((cnttidr & CNTTIDR_VIRT(i)) &&\n\t\t    !(~cntacr & (CNTACR_RWVT | CNTACR_RVCT))) {\n\t\t\tbest_frame = frame;\n\t\t\tarch_timer_mem_use_virtual = true;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (~cntacr & (CNTACR_RWPT | CNTACR_RPCT))\n\t\t\tcontinue;\n\n\t\tbest_frame = frame;\n\t}\n\n\tiounmap(cntctlbase);\n\n\treturn best_frame;\n}\n\nstatic int __init\narch_timer_mem_frame_register(struct arch_timer_mem_frame *frame)\n{\n\tvoid __iomem *base;\n\tint ret, irq = 0;\n\n\tif (arch_timer_mem_use_virtual)\n\t\tirq = frame->virt_irq;\n\telse\n\t\tirq = frame->phys_irq;\n\n\tif (!irq) {\n\t\tpr_err(\"Frame missing %s irq.\\n\",\n\t\t       arch_timer_mem_use_virtual ? \"virt\" : \"phys\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!request_mem_region(frame->cntbase, frame->size,\n\t\t\t\t\"arch_mem_timer\"))\n\t\treturn -EBUSY;\n\n\tbase = ioremap(frame->cntbase, frame->size);\n\tif (!base) {\n\t\tpr_err(\"Can't map frame's registers\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\tret = arch_timer_mem_register(base, irq);\n\tif (ret) {\n\t\tiounmap(base);\n\t\treturn ret;\n\t}\n\n\tarch_timers_present |= ARCH_TIMER_TYPE_MEM;\n\n\treturn 0;\n}\n\nstatic int __init arch_timer_mem_of_init(struct device_node *np)\n{\n\tstruct arch_timer_mem *timer_mem;\n\tstruct arch_timer_mem_frame *frame;\n\tstruct device_node *frame_node;\n\tstruct resource res;\n\tint ret = -EINVAL;\n\tu32 rate;\n\n\ttimer_mem = kzalloc(sizeof(*timer_mem), GFP_KERNEL);\n\tif (!timer_mem)\n\t\treturn -ENOMEM;\n\n\tif (of_address_to_resource(np, 0, &res))\n\t\tgoto out;\n\ttimer_mem->cntctlbase = res.start;\n\ttimer_mem->size = resource_size(&res);\n\n\tfor_each_available_child_of_node(np, frame_node) {\n\t\tu32 n;\n\t\tstruct arch_timer_mem_frame *frame;\n\n\t\tif (of_property_read_u32(frame_node, \"frame-number\", &n)) {\n\t\t\tpr_err(FW_BUG \"Missing frame-number.\\n\");\n\t\t\tof_node_put(frame_node);\n\t\t\tgoto out;\n\t\t}\n\t\tif (n >= ARCH_TIMER_MEM_MAX_FRAMES) {\n\t\t\tpr_err(FW_BUG \"Wrong frame-number, only 0-%u are permitted.\\n\",\n\t\t\t       ARCH_TIMER_MEM_MAX_FRAMES - 1);\n\t\t\tof_node_put(frame_node);\n\t\t\tgoto out;\n\t\t}\n\t\tframe = &timer_mem->frame[n];\n\n\t\tif (frame->valid) {\n\t\t\tpr_err(FW_BUG \"Duplicated frame-number.\\n\");\n\t\t\tof_node_put(frame_node);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (of_address_to_resource(frame_node, 0, &res)) {\n\t\t\tof_node_put(frame_node);\n\t\t\tgoto out;\n\t\t}\n\t\tframe->cntbase = res.start;\n\t\tframe->size = resource_size(&res);\n\n\t\tframe->virt_irq = irq_of_parse_and_map(frame_node,\n\t\t\t\t\t\t       ARCH_TIMER_VIRT_SPI);\n\t\tframe->phys_irq = irq_of_parse_and_map(frame_node,\n\t\t\t\t\t\t       ARCH_TIMER_PHYS_SPI);\n\n\t\tframe->valid = true;\n\t}\n\n\tframe = arch_timer_mem_find_best_frame(timer_mem);\n\tif (!frame) {\n\t\tpr_err(\"Unable to find a suitable frame in timer @ %pa\\n\",\n\t\t\t&timer_mem->cntctlbase);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\trate = arch_timer_mem_frame_get_cntfrq(frame);\n\tarch_timer_of_configure_rate(rate, np);\n\n\tret = arch_timer_mem_frame_register(frame);\n\tif (!ret && !arch_timer_needs_of_probing())\n\t\tret = arch_timer_common_init();\nout:\n\tkfree(timer_mem);\n\treturn ret;\n}\nTIMER_OF_DECLARE(armv7_arch_timer_mem, \"arm,armv7-timer-mem\",\n\t\t       arch_timer_mem_of_init);\n\n#ifdef CONFIG_ACPI_GTDT\nstatic int __init\narch_timer_mem_verify_cntfrq(struct arch_timer_mem *timer_mem)\n{\n\tstruct arch_timer_mem_frame *frame;\n\tu32 rate;\n\tint i;\n\n\tfor (i = 0; i < ARCH_TIMER_MEM_MAX_FRAMES; i++) {\n\t\tframe = &timer_mem->frame[i];\n\n\t\tif (!frame->valid)\n\t\t\tcontinue;\n\n\t\trate = arch_timer_mem_frame_get_cntfrq(frame);\n\t\tif (rate == arch_timer_rate)\n\t\t\tcontinue;\n\n\t\tpr_err(FW_BUG \"CNTFRQ mismatch: frame @ %pa: (0x%08lx), CPU: (0x%08lx)\\n\",\n\t\t\t&frame->cntbase,\n\t\t\t(unsigned long)rate, (unsigned long)arch_timer_rate);\n\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int __init arch_timer_mem_acpi_init(int platform_timer_count)\n{\n\tstruct arch_timer_mem *timers, *timer;\n\tstruct arch_timer_mem_frame *frame, *best_frame = NULL;\n\tint timer_count, i, ret = 0;\n\n\ttimers = kcalloc(platform_timer_count, sizeof(*timers),\n\t\t\t    GFP_KERNEL);\n\tif (!timers)\n\t\treturn -ENOMEM;\n\n\tret = acpi_arch_timer_mem_init(timers, &timer_count);\n\tif (ret || !timer_count)\n\t\tgoto out;\n\n\t \n\tfor (i = 0; i < timer_count; i++) {\n\t\ttimer = &timers[i];\n\n\t\tframe = arch_timer_mem_find_best_frame(timer);\n\t\tif (!best_frame)\n\t\t\tbest_frame = frame;\n\n\t\tret = arch_timer_mem_verify_cntfrq(timer);\n\t\tif (ret) {\n\t\t\tpr_err(\"Disabling MMIO timers due to CNTFRQ mismatch\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!best_frame)  \n\t\t\t \n\t\t\tpr_err(\"Unable to find a suitable frame in timer @ %pa\\n\",\n\t\t\t\t&timer->cntctlbase);\n\t}\n\n\tif (best_frame)\n\t\tret = arch_timer_mem_frame_register(best_frame);\nout:\n\tkfree(timers);\n\treturn ret;\n}\n\n \nstatic int __init arch_timer_acpi_init(struct acpi_table_header *table)\n{\n\tint ret, platform_timer_count;\n\n\tif (arch_timers_present & ARCH_TIMER_TYPE_CP15) {\n\t\tpr_warn(\"already initialized, skipping\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tarch_timers_present |= ARCH_TIMER_TYPE_CP15;\n\n\tret = acpi_gtdt_init(table, &platform_timer_count);\n\tif (ret)\n\t\treturn ret;\n\n\tarch_timer_ppi[ARCH_TIMER_PHYS_NONSECURE_PPI] =\n\t\tacpi_gtdt_map_ppi(ARCH_TIMER_PHYS_NONSECURE_PPI);\n\n\tarch_timer_ppi[ARCH_TIMER_VIRT_PPI] =\n\t\tacpi_gtdt_map_ppi(ARCH_TIMER_VIRT_PPI);\n\n\tarch_timer_ppi[ARCH_TIMER_HYP_PPI] =\n\t\tacpi_gtdt_map_ppi(ARCH_TIMER_HYP_PPI);\n\n\tarch_timer_populate_kvm_info();\n\n\t \n\tarch_timer_rate = arch_timer_get_cntfrq();\n\tret = validate_timer_rate();\n\tif (ret) {\n\t\tpr_err(FW_BUG \"frequency not available.\\n\");\n\t\treturn ret;\n\t}\n\n\tarch_timer_uses_ppi = arch_timer_select_ppi();\n\tif (!arch_timer_ppi[arch_timer_uses_ppi]) {\n\t\tpr_err(\"No interrupt available, giving up\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tarch_timer_c3stop = acpi_gtdt_c3stop(arch_timer_uses_ppi);\n\n\t \n\tarch_timer_check_ool_workaround(ate_match_acpi_oem_info, table);\n\n\tret = arch_timer_register();\n\tif (ret)\n\t\treturn ret;\n\n\tif (platform_timer_count &&\n\t    arch_timer_mem_acpi_init(platform_timer_count))\n\t\tpr_err(\"Failed to initialize memory-mapped timer.\\n\");\n\n\treturn arch_timer_common_init();\n}\nTIMER_ACPI_DECLARE(arch_timer, ACPI_SIG_GTDT, arch_timer_acpi_init);\n#endif\n\nint kvm_arch_ptp_get_crosststamp(u64 *cycle, struct timespec64 *ts,\n\t\t\t\t struct clocksource **cs)\n{\n\tstruct arm_smccc_res hvc_res;\n\tu32 ptp_counter;\n\tktime_t ktime;\n\n\tif (!IS_ENABLED(CONFIG_HAVE_ARM_SMCCC_DISCOVERY))\n\t\treturn -EOPNOTSUPP;\n\n\tif (arch_timer_uses_ppi == ARCH_TIMER_VIRT_PPI)\n\t\tptp_counter = KVM_PTP_VIRT_COUNTER;\n\telse\n\t\tptp_counter = KVM_PTP_PHYS_COUNTER;\n\n\tarm_smccc_1_1_invoke(ARM_SMCCC_VENDOR_HYP_KVM_PTP_FUNC_ID,\n\t\t\t     ptp_counter, &hvc_res);\n\n\tif ((int)(hvc_res.a0) < 0)\n\t\treturn -EOPNOTSUPP;\n\n\tktime = (u64)hvc_res.a0 << 32 | hvc_res.a1;\n\t*ts = ktime_to_timespec64(ktime);\n\tif (cycle)\n\t\t*cycle = (u64)hvc_res.a2 << 32 | hvc_res.a3;\n\tif (cs)\n\t\t*cs = &clocksource_counter;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(kvm_arch_ptp_get_crosststamp);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}