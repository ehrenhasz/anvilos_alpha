{
  "module_name": "device.c",
  "hash_id": "c657711d11d7243887d1485409591e1a8a72f3b905625148e360e2d0a4737af5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/dax/device.c",
  "human_readable_source": "\n \n#include <linux/memremap.h>\n#include <linux/pagemap.h>\n#include <linux/module.h>\n#include <linux/device.h>\n#include <linux/pfn_t.h>\n#include <linux/cdev.h>\n#include <linux/slab.h>\n#include <linux/dax.h>\n#include <linux/fs.h>\n#include <linux/mm.h>\n#include <linux/mman.h>\n#include \"dax-private.h\"\n#include \"bus.h\"\n\nstatic int check_vma(struct dev_dax *dev_dax, struct vm_area_struct *vma,\n\t\tconst char *func)\n{\n\tstruct device *dev = &dev_dax->dev;\n\tunsigned long mask;\n\n\tif (!dax_alive(dev_dax->dax_dev))\n\t\treturn -ENXIO;\n\n\t \n\tif ((vma->vm_flags & VM_MAYSHARE) != VM_MAYSHARE) {\n\t\tdev_info_ratelimited(dev,\n\t\t\t\t\"%s: %s: fail, attempted private mapping\\n\",\n\t\t\t\tcurrent->comm, func);\n\t\treturn -EINVAL;\n\t}\n\n\tmask = dev_dax->align - 1;\n\tif (vma->vm_start & mask || vma->vm_end & mask) {\n\t\tdev_info_ratelimited(dev,\n\t\t\t\t\"%s: %s: fail, unaligned vma (%#lx - %#lx, %#lx)\\n\",\n\t\t\t\tcurrent->comm, func, vma->vm_start, vma->vm_end,\n\t\t\t\tmask);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!vma_is_dax(vma)) {\n\t\tdev_info_ratelimited(dev,\n\t\t\t\t\"%s: %s: fail, vma is not DAX capable\\n\",\n\t\t\t\tcurrent->comm, func);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \n__weak phys_addr_t dax_pgoff_to_phys(struct dev_dax *dev_dax, pgoff_t pgoff,\n\t\tunsigned long size)\n{\n\tint i;\n\n\tfor (i = 0; i < dev_dax->nr_range; i++) {\n\t\tstruct dev_dax_range *dax_range = &dev_dax->ranges[i];\n\t\tstruct range *range = &dax_range->range;\n\t\tunsigned long long pgoff_end;\n\t\tphys_addr_t phys;\n\n\t\tpgoff_end = dax_range->pgoff + PHYS_PFN(range_len(range)) - 1;\n\t\tif (pgoff < dax_range->pgoff || pgoff > pgoff_end)\n\t\t\tcontinue;\n\t\tphys = PFN_PHYS(pgoff - dax_range->pgoff) + range->start;\n\t\tif (phys + size - 1 <= range->end)\n\t\t\treturn phys;\n\t\tbreak;\n\t}\n\treturn -1;\n}\n\nstatic void dax_set_mapping(struct vm_fault *vmf, pfn_t pfn,\n\t\t\t      unsigned long fault_size)\n{\n\tunsigned long i, nr_pages = fault_size / PAGE_SIZE;\n\tstruct file *filp = vmf->vma->vm_file;\n\tstruct dev_dax *dev_dax = filp->private_data;\n\tpgoff_t pgoff;\n\n\t \n\tif (dev_dax->pgmap->vmemmap_shift)\n\t\tnr_pages = 1;\n\n\tpgoff = linear_page_index(vmf->vma,\n\t\t\tALIGN(vmf->address, fault_size));\n\n\tfor (i = 0; i < nr_pages; i++) {\n\t\tstruct page *page = pfn_to_page(pfn_t_to_pfn(pfn) + i);\n\n\t\tpage = compound_head(page);\n\t\tif (page->mapping)\n\t\t\tcontinue;\n\n\t\tpage->mapping = filp->f_mapping;\n\t\tpage->index = pgoff + i;\n\t}\n}\n\nstatic vm_fault_t __dev_dax_pte_fault(struct dev_dax *dev_dax,\n\t\t\t\tstruct vm_fault *vmf)\n{\n\tstruct device *dev = &dev_dax->dev;\n\tphys_addr_t phys;\n\tpfn_t pfn;\n\tunsigned int fault_size = PAGE_SIZE;\n\n\tif (check_vma(dev_dax, vmf->vma, __func__))\n\t\treturn VM_FAULT_SIGBUS;\n\n\tif (dev_dax->align > PAGE_SIZE) {\n\t\tdev_dbg(dev, \"alignment (%#x) > fault size (%#x)\\n\",\n\t\t\tdev_dax->align, fault_size);\n\t\treturn VM_FAULT_SIGBUS;\n\t}\n\n\tif (fault_size != dev_dax->align)\n\t\treturn VM_FAULT_SIGBUS;\n\n\tphys = dax_pgoff_to_phys(dev_dax, vmf->pgoff, PAGE_SIZE);\n\tif (phys == -1) {\n\t\tdev_dbg(dev, \"pgoff_to_phys(%#lx) failed\\n\", vmf->pgoff);\n\t\treturn VM_FAULT_SIGBUS;\n\t}\n\n\tpfn = phys_to_pfn_t(phys, PFN_DEV|PFN_MAP);\n\n\tdax_set_mapping(vmf, pfn, fault_size);\n\n\treturn vmf_insert_mixed(vmf->vma, vmf->address, pfn);\n}\n\nstatic vm_fault_t __dev_dax_pmd_fault(struct dev_dax *dev_dax,\n\t\t\t\tstruct vm_fault *vmf)\n{\n\tunsigned long pmd_addr = vmf->address & PMD_MASK;\n\tstruct device *dev = &dev_dax->dev;\n\tphys_addr_t phys;\n\tpgoff_t pgoff;\n\tpfn_t pfn;\n\tunsigned int fault_size = PMD_SIZE;\n\n\tif (check_vma(dev_dax, vmf->vma, __func__))\n\t\treturn VM_FAULT_SIGBUS;\n\n\tif (dev_dax->align > PMD_SIZE) {\n\t\tdev_dbg(dev, \"alignment (%#x) > fault size (%#x)\\n\",\n\t\t\tdev_dax->align, fault_size);\n\t\treturn VM_FAULT_SIGBUS;\n\t}\n\n\tif (fault_size < dev_dax->align)\n\t\treturn VM_FAULT_SIGBUS;\n\telse if (fault_size > dev_dax->align)\n\t\treturn VM_FAULT_FALLBACK;\n\n\t \n\tif (pmd_addr < vmf->vma->vm_start ||\n\t\t\t(pmd_addr + PMD_SIZE) > vmf->vma->vm_end)\n\t\treturn VM_FAULT_SIGBUS;\n\n\tpgoff = linear_page_index(vmf->vma, pmd_addr);\n\tphys = dax_pgoff_to_phys(dev_dax, pgoff, PMD_SIZE);\n\tif (phys == -1) {\n\t\tdev_dbg(dev, \"pgoff_to_phys(%#lx) failed\\n\", pgoff);\n\t\treturn VM_FAULT_SIGBUS;\n\t}\n\n\tpfn = phys_to_pfn_t(phys, PFN_DEV|PFN_MAP);\n\n\tdax_set_mapping(vmf, pfn, fault_size);\n\n\treturn vmf_insert_pfn_pmd(vmf, pfn, vmf->flags & FAULT_FLAG_WRITE);\n}\n\n#ifdef CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE_PUD\nstatic vm_fault_t __dev_dax_pud_fault(struct dev_dax *dev_dax,\n\t\t\t\tstruct vm_fault *vmf)\n{\n\tunsigned long pud_addr = vmf->address & PUD_MASK;\n\tstruct device *dev = &dev_dax->dev;\n\tphys_addr_t phys;\n\tpgoff_t pgoff;\n\tpfn_t pfn;\n\tunsigned int fault_size = PUD_SIZE;\n\n\n\tif (check_vma(dev_dax, vmf->vma, __func__))\n\t\treturn VM_FAULT_SIGBUS;\n\n\tif (dev_dax->align > PUD_SIZE) {\n\t\tdev_dbg(dev, \"alignment (%#x) > fault size (%#x)\\n\",\n\t\t\tdev_dax->align, fault_size);\n\t\treturn VM_FAULT_SIGBUS;\n\t}\n\n\tif (fault_size < dev_dax->align)\n\t\treturn VM_FAULT_SIGBUS;\n\telse if (fault_size > dev_dax->align)\n\t\treturn VM_FAULT_FALLBACK;\n\n\t \n\tif (pud_addr < vmf->vma->vm_start ||\n\t\t\t(pud_addr + PUD_SIZE) > vmf->vma->vm_end)\n\t\treturn VM_FAULT_SIGBUS;\n\n\tpgoff = linear_page_index(vmf->vma, pud_addr);\n\tphys = dax_pgoff_to_phys(dev_dax, pgoff, PUD_SIZE);\n\tif (phys == -1) {\n\t\tdev_dbg(dev, \"pgoff_to_phys(%#lx) failed\\n\", pgoff);\n\t\treturn VM_FAULT_SIGBUS;\n\t}\n\n\tpfn = phys_to_pfn_t(phys, PFN_DEV|PFN_MAP);\n\n\tdax_set_mapping(vmf, pfn, fault_size);\n\n\treturn vmf_insert_pfn_pud(vmf, pfn, vmf->flags & FAULT_FLAG_WRITE);\n}\n#else\nstatic vm_fault_t __dev_dax_pud_fault(struct dev_dax *dev_dax,\n\t\t\t\tstruct vm_fault *vmf)\n{\n\treturn VM_FAULT_FALLBACK;\n}\n#endif  \n\nstatic vm_fault_t dev_dax_huge_fault(struct vm_fault *vmf, unsigned int order)\n{\n\tstruct file *filp = vmf->vma->vm_file;\n\tvm_fault_t rc = VM_FAULT_SIGBUS;\n\tint id;\n\tstruct dev_dax *dev_dax = filp->private_data;\n\n\tdev_dbg(&dev_dax->dev, \"%s: %s (%#lx - %#lx) order:%d\\n\", current->comm,\n\t\t\t(vmf->flags & FAULT_FLAG_WRITE) ? \"write\" : \"read\",\n\t\t\tvmf->vma->vm_start, vmf->vma->vm_end, order);\n\n\tid = dax_read_lock();\n\tif (order == 0)\n\t\trc = __dev_dax_pte_fault(dev_dax, vmf);\n\telse if (order == PMD_ORDER)\n\t\trc = __dev_dax_pmd_fault(dev_dax, vmf);\n\telse if (order == PUD_ORDER)\n\t\trc = __dev_dax_pud_fault(dev_dax, vmf);\n\telse\n\t\trc = VM_FAULT_SIGBUS;\n\n\tdax_read_unlock(id);\n\n\treturn rc;\n}\n\nstatic vm_fault_t dev_dax_fault(struct vm_fault *vmf)\n{\n\treturn dev_dax_huge_fault(vmf, 0);\n}\n\nstatic int dev_dax_may_split(struct vm_area_struct *vma, unsigned long addr)\n{\n\tstruct file *filp = vma->vm_file;\n\tstruct dev_dax *dev_dax = filp->private_data;\n\n\tif (!IS_ALIGNED(addr, dev_dax->align))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic unsigned long dev_dax_pagesize(struct vm_area_struct *vma)\n{\n\tstruct file *filp = vma->vm_file;\n\tstruct dev_dax *dev_dax = filp->private_data;\n\n\treturn dev_dax->align;\n}\n\nstatic const struct vm_operations_struct dax_vm_ops = {\n\t.fault = dev_dax_fault,\n\t.huge_fault = dev_dax_huge_fault,\n\t.may_split = dev_dax_may_split,\n\t.pagesize = dev_dax_pagesize,\n};\n\nstatic int dax_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\tstruct dev_dax *dev_dax = filp->private_data;\n\tint rc, id;\n\n\tdev_dbg(&dev_dax->dev, \"trace\\n\");\n\n\t \n\tid = dax_read_lock();\n\trc = check_vma(dev_dax, vma, __func__);\n\tdax_read_unlock(id);\n\tif (rc)\n\t\treturn rc;\n\n\tvma->vm_ops = &dax_vm_ops;\n\tvm_flags_set(vma, VM_HUGEPAGE);\n\treturn 0;\n}\n\n \nstatic unsigned long dax_get_unmapped_area(struct file *filp,\n\t\tunsigned long addr, unsigned long len, unsigned long pgoff,\n\t\tunsigned long flags)\n{\n\tunsigned long off, off_end, off_align, len_align, addr_align, align;\n\tstruct dev_dax *dev_dax = filp ? filp->private_data : NULL;\n\n\tif (!dev_dax || addr)\n\t\tgoto out;\n\n\talign = dev_dax->align;\n\toff = pgoff << PAGE_SHIFT;\n\toff_end = off + len;\n\toff_align = round_up(off, align);\n\n\tif ((off_end <= off_align) || ((off_end - off_align) < align))\n\t\tgoto out;\n\n\tlen_align = len + align;\n\tif ((off + len_align) < off)\n\t\tgoto out;\n\n\taddr_align = current->mm->get_unmapped_area(filp, addr, len_align,\n\t\t\tpgoff, flags);\n\tif (!IS_ERR_VALUE(addr_align)) {\n\t\taddr_align += (off - addr_align) & (align - 1);\n\t\treturn addr_align;\n\t}\n out:\n\treturn current->mm->get_unmapped_area(filp, addr, len, pgoff, flags);\n}\n\nstatic const struct address_space_operations dev_dax_aops = {\n\t.dirty_folio\t= noop_dirty_folio,\n};\n\nstatic int dax_open(struct inode *inode, struct file *filp)\n{\n\tstruct dax_device *dax_dev = inode_dax(inode);\n\tstruct inode *__dax_inode = dax_inode(dax_dev);\n\tstruct dev_dax *dev_dax = dax_get_private(dax_dev);\n\n\tdev_dbg(&dev_dax->dev, \"trace\\n\");\n\tinode->i_mapping = __dax_inode->i_mapping;\n\tinode->i_mapping->host = __dax_inode;\n\tinode->i_mapping->a_ops = &dev_dax_aops;\n\tfilp->f_mapping = inode->i_mapping;\n\tfilp->f_wb_err = filemap_sample_wb_err(filp->f_mapping);\n\tfilp->f_sb_err = file_sample_sb_err(filp);\n\tfilp->private_data = dev_dax;\n\tinode->i_flags = S_DAX;\n\n\treturn 0;\n}\n\nstatic int dax_release(struct inode *inode, struct file *filp)\n{\n\tstruct dev_dax *dev_dax = filp->private_data;\n\n\tdev_dbg(&dev_dax->dev, \"trace\\n\");\n\treturn 0;\n}\n\nstatic const struct file_operations dax_fops = {\n\t.llseek = noop_llseek,\n\t.owner = THIS_MODULE,\n\t.open = dax_open,\n\t.release = dax_release,\n\t.get_unmapped_area = dax_get_unmapped_area,\n\t.mmap = dax_mmap,\n\t.mmap_supported_flags = MAP_SYNC,\n};\n\nstatic void dev_dax_cdev_del(void *cdev)\n{\n\tcdev_del(cdev);\n}\n\nstatic void dev_dax_kill(void *dev_dax)\n{\n\tkill_dev_dax(dev_dax);\n}\n\nstatic int dev_dax_probe(struct dev_dax *dev_dax)\n{\n\tstruct dax_device *dax_dev = dev_dax->dax_dev;\n\tstruct device *dev = &dev_dax->dev;\n\tstruct dev_pagemap *pgmap;\n\tstruct inode *inode;\n\tstruct cdev *cdev;\n\tvoid *addr;\n\tint rc, i;\n\n\tif (static_dev_dax(dev_dax))  {\n\t\tif (dev_dax->nr_range > 1) {\n\t\t\tdev_warn(dev,\n\t\t\t\t\"static pgmap / multi-range device conflict\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tpgmap = dev_dax->pgmap;\n\t} else {\n\t\tif (dev_dax->pgmap) {\n\t\t\tdev_warn(dev,\n\t\t\t\t \"dynamic-dax with pre-populated page map\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tpgmap = devm_kzalloc(dev,\n                       struct_size(pgmap, ranges, dev_dax->nr_range - 1),\n                       GFP_KERNEL);\n\t\tif (!pgmap)\n\t\t\treturn -ENOMEM;\n\n\t\tpgmap->nr_range = dev_dax->nr_range;\n\t\tdev_dax->pgmap = pgmap;\n\n\t\tfor (i = 0; i < dev_dax->nr_range; i++) {\n\t\t\tstruct range *range = &dev_dax->ranges[i].range;\n\t\t\tpgmap->ranges[i] = *range;\n\t\t}\n\t}\n\n\tfor (i = 0; i < dev_dax->nr_range; i++) {\n\t\tstruct range *range = &dev_dax->ranges[i].range;\n\n\t\tif (!devm_request_mem_region(dev, range->start,\n\t\t\t\t\trange_len(range), dev_name(dev))) {\n\t\t\tdev_warn(dev, \"mapping%d: %#llx-%#llx could not reserve range\\n\",\n\t\t\t\t\ti, range->start, range->end);\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\tpgmap->type = MEMORY_DEVICE_GENERIC;\n\tif (dev_dax->align > PAGE_SIZE)\n\t\tpgmap->vmemmap_shift =\n\t\t\torder_base_2(dev_dax->align >> PAGE_SHIFT);\n\taddr = devm_memremap_pages(dev, pgmap);\n\tif (IS_ERR(addr))\n\t\treturn PTR_ERR(addr);\n\n\tinode = dax_inode(dax_dev);\n\tcdev = inode->i_cdev;\n\tcdev_init(cdev, &dax_fops);\n\tcdev->owner = dev->driver->owner;\n\tcdev_set_parent(cdev, &dev->kobj);\n\trc = cdev_add(cdev, dev->devt, 1);\n\tif (rc)\n\t\treturn rc;\n\n\trc = devm_add_action_or_reset(dev, dev_dax_cdev_del, cdev);\n\tif (rc)\n\t\treturn rc;\n\n\trun_dax(dax_dev);\n\treturn devm_add_action_or_reset(dev, dev_dax_kill, dev_dax);\n}\n\nstatic struct dax_device_driver device_dax_driver = {\n\t.probe = dev_dax_probe,\n\t.type = DAXDRV_DEVICE_TYPE,\n};\n\nstatic int __init dax_init(void)\n{\n\treturn dax_driver_register(&device_dax_driver);\n}\n\nstatic void __exit dax_exit(void)\n{\n\tdax_driver_unregister(&device_dax_driver);\n}\n\nMODULE_AUTHOR(\"Intel Corporation\");\nMODULE_LICENSE(\"GPL v2\");\nmodule_init(dax_init);\nmodule_exit(dax_exit);\nMODULE_ALIAS_DAX_DEVICE(0);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}