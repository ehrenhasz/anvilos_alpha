{
  "module_name": "tty_ldsem.c",
  "hash_id": "2de40e27947bf23e7f0d423f409e1102b6b4e75851cbe833b8e2d0dac4ea9799",
  "original_prompt": "Ingested from linux-6.6.14/drivers/tty/tty_ldsem.c",
  "human_readable_source": "\n \n\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/atomic.h>\n#include <linux/tty.h>\n#include <linux/sched.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n\n\n#if BITS_PER_LONG == 64\n# define LDSEM_ACTIVE_MASK\t0xffffffffL\n#else\n# define LDSEM_ACTIVE_MASK\t0x0000ffffL\n#endif\n\n#define LDSEM_UNLOCKED\t\t0L\n#define LDSEM_ACTIVE_BIAS\t1L\n#define LDSEM_WAIT_BIAS\t\t(-LDSEM_ACTIVE_MASK-1)\n#define LDSEM_READ_BIAS\t\tLDSEM_ACTIVE_BIAS\n#define LDSEM_WRITE_BIAS\t(LDSEM_WAIT_BIAS + LDSEM_ACTIVE_BIAS)\n\nstruct ldsem_waiter {\n\tstruct list_head list;\n\tstruct task_struct *task;\n};\n\n \nvoid __init_ldsem(struct ld_semaphore *sem, const char *name,\n\t\t  struct lock_class_key *key)\n{\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t \n\tdebug_check_no_locks_freed((void *)sem, sizeof(*sem));\n\tlockdep_init_map(&sem->dep_map, name, key, 0);\n#endif\n\tatomic_long_set(&sem->count, LDSEM_UNLOCKED);\n\tsem->wait_readers = 0;\n\traw_spin_lock_init(&sem->wait_lock);\n\tINIT_LIST_HEAD(&sem->read_wait);\n\tINIT_LIST_HEAD(&sem->write_wait);\n}\n\nstatic void __ldsem_wake_readers(struct ld_semaphore *sem)\n{\n\tstruct ldsem_waiter *waiter, *next;\n\tstruct task_struct *tsk;\n\tlong adjust, count;\n\n\t \n\tadjust = sem->wait_readers * (LDSEM_ACTIVE_BIAS - LDSEM_WAIT_BIAS);\n\tcount = atomic_long_add_return(adjust, &sem->count);\n\tdo {\n\t\tif (count > 0)\n\t\t\tbreak;\n\t\tif (atomic_long_try_cmpxchg(&sem->count, &count, count - adjust))\n\t\t\treturn;\n\t} while (1);\n\n\tlist_for_each_entry_safe(waiter, next, &sem->read_wait, list) {\n\t\ttsk = waiter->task;\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\twake_up_process(tsk);\n\t\tput_task_struct(tsk);\n\t}\n\tINIT_LIST_HEAD(&sem->read_wait);\n\tsem->wait_readers = 0;\n}\n\nstatic inline int writer_trylock(struct ld_semaphore *sem)\n{\n\t \n\tlong count = atomic_long_add_return(LDSEM_ACTIVE_BIAS, &sem->count);\n\tdo {\n\t\tif ((count & LDSEM_ACTIVE_MASK) == LDSEM_ACTIVE_BIAS)\n\t\t\treturn 1;\n\t\tif (atomic_long_try_cmpxchg(&sem->count, &count, count - LDSEM_ACTIVE_BIAS))\n\t\t\treturn 0;\n\t} while (1);\n}\n\nstatic void __ldsem_wake_writer(struct ld_semaphore *sem)\n{\n\tstruct ldsem_waiter *waiter;\n\n\twaiter = list_entry(sem->write_wait.next, struct ldsem_waiter, list);\n\twake_up_process(waiter->task);\n}\n\n \nstatic void __ldsem_wake(struct ld_semaphore *sem)\n{\n\tif (!list_empty(&sem->write_wait))\n\t\t__ldsem_wake_writer(sem);\n\telse if (!list_empty(&sem->read_wait))\n\t\t__ldsem_wake_readers(sem);\n}\n\nstatic void ldsem_wake(struct ld_semaphore *sem)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\t__ldsem_wake(sem);\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n}\n\n \nstatic struct ld_semaphore __sched *\ndown_read_failed(struct ld_semaphore *sem, long count, long timeout)\n{\n\tstruct ldsem_waiter waiter;\n\tlong adjust = -LDSEM_ACTIVE_BIAS + LDSEM_WAIT_BIAS;\n\n\t \n\traw_spin_lock_irq(&sem->wait_lock);\n\n\t \n\tdo {\n\t\tif (atomic_long_try_cmpxchg(&sem->count, &count, count + adjust)) {\n\t\t\tcount += adjust;\n\t\t\tbreak;\n\t\t}\n\t\tif (count > 0) {\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\treturn sem;\n\t\t}\n\t} while (1);\n\n\tlist_add_tail(&waiter.list, &sem->read_wait);\n\tsem->wait_readers++;\n\n\twaiter.task = current;\n\tget_task_struct(current);\n\n\t \n\tif ((count & LDSEM_ACTIVE_MASK) == 0)\n\t\t__ldsem_wake(sem);\n\n\traw_spin_unlock_irq(&sem->wait_lock);\n\n\t \n\tfor (;;) {\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\n\t\tif (!smp_load_acquire(&waiter.task))\n\t\t\tbreak;\n\t\tif (!timeout)\n\t\t\tbreak;\n\t\ttimeout = schedule_timeout(timeout);\n\t}\n\n\t__set_current_state(TASK_RUNNING);\n\n\tif (!timeout) {\n\t\t \n\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\tif (waiter.task) {\n\t\t\tatomic_long_add_return(-LDSEM_WAIT_BIAS, &sem->count);\n\t\t\tsem->wait_readers--;\n\t\t\tlist_del(&waiter.list);\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\tput_task_struct(waiter.task);\n\t\t\treturn NULL;\n\t\t}\n\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t}\n\n\treturn sem;\n}\n\n \nstatic struct ld_semaphore __sched *\ndown_write_failed(struct ld_semaphore *sem, long count, long timeout)\n{\n\tstruct ldsem_waiter waiter;\n\tlong adjust = -LDSEM_ACTIVE_BIAS;\n\tint locked = 0;\n\n\t \n\traw_spin_lock_irq(&sem->wait_lock);\n\n\t \n\tdo {\n\t\tif (atomic_long_try_cmpxchg(&sem->count, &count, count + adjust))\n\t\t\tbreak;\n\t\tif ((count & LDSEM_ACTIVE_MASK) == LDSEM_ACTIVE_BIAS) {\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\treturn sem;\n\t\t}\n\t} while (1);\n\n\tlist_add_tail(&waiter.list, &sem->write_wait);\n\n\twaiter.task = current;\n\n\tset_current_state(TASK_UNINTERRUPTIBLE);\n\tfor (;;) {\n\t\tif (!timeout)\n\t\t\tbreak;\n\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\ttimeout = schedule_timeout(timeout);\n\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\tlocked = writer_trylock(sem);\n\t\tif (locked)\n\t\t\tbreak;\n\t}\n\n\tif (!locked)\n\t\tatomic_long_add_return(-LDSEM_WAIT_BIAS, &sem->count);\n\tlist_del(&waiter.list);\n\n\t \n\tif (!locked && list_empty(&sem->write_wait))\n\t\t__ldsem_wake_readers(sem);\n\n\traw_spin_unlock_irq(&sem->wait_lock);\n\n\t__set_current_state(TASK_RUNNING);\n\n\t \n\tif (!locked)\n\t\treturn NULL;\n\treturn sem;\n}\n\n\n\nstatic int __ldsem_down_read_nested(struct ld_semaphore *sem,\n\t\t\t\t\t   int subclass, long timeout)\n{\n\tlong count;\n\n\trwsem_acquire_read(&sem->dep_map, subclass, 0, _RET_IP_);\n\n\tcount = atomic_long_add_return(LDSEM_READ_BIAS, &sem->count);\n\tif (count <= 0) {\n\t\tlock_contended(&sem->dep_map, _RET_IP_);\n\t\tif (!down_read_failed(sem, count, timeout)) {\n\t\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tlock_acquired(&sem->dep_map, _RET_IP_);\n\treturn 1;\n}\n\nstatic int __ldsem_down_write_nested(struct ld_semaphore *sem,\n\t\t\t\t\t    int subclass, long timeout)\n{\n\tlong count;\n\n\trwsem_acquire(&sem->dep_map, subclass, 0, _RET_IP_);\n\n\tcount = atomic_long_add_return(LDSEM_WRITE_BIAS, &sem->count);\n\tif ((count & LDSEM_ACTIVE_MASK) != LDSEM_ACTIVE_BIAS) {\n\t\tlock_contended(&sem->dep_map, _RET_IP_);\n\t\tif (!down_write_failed(sem, count, timeout)) {\n\t\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tlock_acquired(&sem->dep_map, _RET_IP_);\n\treturn 1;\n}\n\n\n \nint __sched ldsem_down_read(struct ld_semaphore *sem, long timeout)\n{\n\tmight_sleep();\n\treturn __ldsem_down_read_nested(sem, 0, timeout);\n}\n\n \nint ldsem_down_read_trylock(struct ld_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\n\twhile (count >= 0) {\n\t\tif (atomic_long_try_cmpxchg(&sem->count, &count, count + LDSEM_READ_BIAS)) {\n\t\t\trwsem_acquire_read(&sem->dep_map, 0, 1, _RET_IP_);\n\t\t\tlock_acquired(&sem->dep_map, _RET_IP_);\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nint __sched ldsem_down_write(struct ld_semaphore *sem, long timeout)\n{\n\tmight_sleep();\n\treturn __ldsem_down_write_nested(sem, 0, timeout);\n}\n\n \nint ldsem_down_write_trylock(struct ld_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\n\twhile ((count & LDSEM_ACTIVE_MASK) == 0) {\n\t\tif (atomic_long_try_cmpxchg(&sem->count, &count, count + LDSEM_WRITE_BIAS)) {\n\t\t\trwsem_acquire(&sem->dep_map, 0, 1, _RET_IP_);\n\t\t\tlock_acquired(&sem->dep_map, _RET_IP_);\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nvoid ldsem_up_read(struct ld_semaphore *sem)\n{\n\tlong count;\n\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\tcount = atomic_long_add_return(-LDSEM_READ_BIAS, &sem->count);\n\tif (count < 0 && (count & LDSEM_ACTIVE_MASK) == 0)\n\t\tldsem_wake(sem);\n}\n\n \nvoid ldsem_up_write(struct ld_semaphore *sem)\n{\n\tlong count;\n\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\tcount = atomic_long_add_return(-LDSEM_WRITE_BIAS, &sem->count);\n\tif (count < 0)\n\t\tldsem_wake(sem);\n}\n\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\nint ldsem_down_read_nested(struct ld_semaphore *sem, int subclass, long timeout)\n{\n\tmight_sleep();\n\treturn __ldsem_down_read_nested(sem, subclass, timeout);\n}\n\nint ldsem_down_write_nested(struct ld_semaphore *sem, int subclass,\n\t\t\t    long timeout)\n{\n\tmight_sleep();\n\treturn __ldsem_down_write_nested(sem, subclass, timeout);\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}