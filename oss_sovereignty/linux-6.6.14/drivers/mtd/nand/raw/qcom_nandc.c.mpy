{
  "module_name": "qcom_nandc.c",
  "hash_id": "59e45d2279008d931a6714311121821d241f54707463b6bebb22495e7a9084b0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/mtd/nand/raw/qcom_nandc.c",
  "human_readable_source": "\n \n#include <linux/bitops.h>\n#include <linux/clk.h>\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/dma-mapping.h>\n#include <linux/dma/qcom_adm.h>\n#include <linux/dma/qcom_bam_dma.h>\n#include <linux/module.h>\n#include <linux/mtd/partitions.h>\n#include <linux/mtd/rawnand.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n\n \n#define\tNAND_FLASH_CMD\t\t\t0x00\n#define\tNAND_ADDR0\t\t\t0x04\n#define\tNAND_ADDR1\t\t\t0x08\n#define\tNAND_FLASH_CHIP_SELECT\t\t0x0c\n#define\tNAND_EXEC_CMD\t\t\t0x10\n#define\tNAND_FLASH_STATUS\t\t0x14\n#define\tNAND_BUFFER_STATUS\t\t0x18\n#define\tNAND_DEV0_CFG0\t\t\t0x20\n#define\tNAND_DEV0_CFG1\t\t\t0x24\n#define\tNAND_DEV0_ECC_CFG\t\t0x28\n#define\tNAND_AUTO_STATUS_EN\t\t0x2c\n#define\tNAND_DEV1_CFG0\t\t\t0x30\n#define\tNAND_DEV1_CFG1\t\t\t0x34\n#define\tNAND_READ_ID\t\t\t0x40\n#define\tNAND_READ_STATUS\t\t0x44\n#define\tNAND_DEV_CMD0\t\t\t0xa0\n#define\tNAND_DEV_CMD1\t\t\t0xa4\n#define\tNAND_DEV_CMD2\t\t\t0xa8\n#define\tNAND_DEV_CMD_VLD\t\t0xac\n#define\tSFLASHC_BURST_CFG\t\t0xe0\n#define\tNAND_ERASED_CW_DETECT_CFG\t0xe8\n#define\tNAND_ERASED_CW_DETECT_STATUS\t0xec\n#define\tNAND_EBI2_ECC_BUF_CFG\t\t0xf0\n#define\tFLASH_BUF_ACC\t\t\t0x100\n\n#define\tNAND_CTRL\t\t\t0xf00\n#define\tNAND_VERSION\t\t\t0xf08\n#define\tNAND_READ_LOCATION_0\t\t0xf20\n#define\tNAND_READ_LOCATION_1\t\t0xf24\n#define\tNAND_READ_LOCATION_2\t\t0xf28\n#define\tNAND_READ_LOCATION_3\t\t0xf2c\n#define\tNAND_READ_LOCATION_LAST_CW_0\t0xf40\n#define\tNAND_READ_LOCATION_LAST_CW_1\t0xf44\n#define\tNAND_READ_LOCATION_LAST_CW_2\t0xf48\n#define\tNAND_READ_LOCATION_LAST_CW_3\t0xf4c\n\n \n#define\tNAND_DEV_CMD1_RESTORE\t\t0xdead\n#define\tNAND_DEV_CMD_VLD_RESTORE\t0xbeef\n\n \n#define\tPAGE_ACC\t\t\tBIT(4)\n#define\tLAST_PAGE\t\t\tBIT(5)\n\n \n#define\tNAND_DEV_SEL\t\t\t0\n#define\tDM_EN\t\t\t\tBIT(2)\n\n \n#define\tFS_OP_ERR\t\t\tBIT(4)\n#define\tFS_READY_BSY_N\t\t\tBIT(5)\n#define\tFS_MPU_ERR\t\t\tBIT(8)\n#define\tFS_DEVICE_STS_ERR\t\tBIT(16)\n#define\tFS_DEVICE_WP\t\t\tBIT(23)\n\n \n#define\tBS_UNCORRECTABLE_BIT\t\tBIT(8)\n#define\tBS_CORRECTABLE_ERR_MSK\t\t0x1f\n\n \n#define\tDISABLE_STATUS_AFTER_WRITE\t4\n#define\tCW_PER_PAGE\t\t\t6\n#define\tUD_SIZE_BYTES\t\t\t9\n#define\tUD_SIZE_BYTES_MASK\t\tGENMASK(18, 9)\n#define\tECC_PARITY_SIZE_BYTES_RS\t19\n#define\tSPARE_SIZE_BYTES\t\t23\n#define\tSPARE_SIZE_BYTES_MASK\t\tGENMASK(26, 23)\n#define\tNUM_ADDR_CYCLES\t\t\t27\n#define\tSTATUS_BFR_READ\t\t\t30\n#define\tSET_RD_MODE_AFTER_STATUS\t31\n\n \n#define\tDEV0_CFG1_ECC_DISABLE\t\t0\n#define\tWIDE_FLASH\t\t\t1\n#define\tNAND_RECOVERY_CYCLES\t\t2\n#define\tCS_ACTIVE_BSY\t\t\t5\n#define\tBAD_BLOCK_BYTE_NUM\t\t6\n#define\tBAD_BLOCK_IN_SPARE_AREA\t\t16\n#define\tWR_RD_BSY_GAP\t\t\t17\n#define\tENABLE_BCH_ECC\t\t\t27\n\n \n#define\tECC_CFG_ECC_DISABLE\t\t0\n#define\tECC_SW_RESET\t\t\t1\n#define\tECC_MODE\t\t\t4\n#define\tECC_PARITY_SIZE_BYTES_BCH\t8\n#define\tECC_NUM_DATA_BYTES\t\t16\n#define\tECC_NUM_DATA_BYTES_MASK\t\tGENMASK(25, 16)\n#define\tECC_FORCE_CLK_OPEN\t\t30\n\n \n#define\tREAD_ADDR\t\t\t0\n\n \n#define\tREAD_START_VLD\t\t\tBIT(0)\n#define\tREAD_STOP_VLD\t\t\tBIT(1)\n#define\tWRITE_START_VLD\t\t\tBIT(2)\n#define\tERASE_START_VLD\t\t\tBIT(3)\n#define\tSEQ_READ_START_VLD\t\tBIT(4)\n\n \n#define\tNUM_STEPS\t\t\t0\n\n \n#define\tERASED_CW_ECC_MASK\t\t1\n#define\tAUTO_DETECT_RES\t\t\t0\n#define\tMASK_ECC\t\t\tBIT(ERASED_CW_ECC_MASK)\n#define\tRESET_ERASED_DET\t\tBIT(AUTO_DETECT_RES)\n#define\tACTIVE_ERASED_DET\t\t(0 << AUTO_DETECT_RES)\n#define\tCLR_ERASED_PAGE_DET\t\t(RESET_ERASED_DET | MASK_ECC)\n#define\tSET_ERASED_PAGE_DET\t\t(ACTIVE_ERASED_DET | MASK_ECC)\n\n \n#define\tPAGE_ALL_ERASED\t\t\tBIT(7)\n#define\tCODEWORD_ALL_ERASED\t\tBIT(6)\n#define\tPAGE_ERASED\t\t\tBIT(5)\n#define\tCODEWORD_ERASED\t\t\tBIT(4)\n#define\tERASED_PAGE\t\t\t(PAGE_ALL_ERASED | PAGE_ERASED)\n#define\tERASED_CW\t\t\t(CODEWORD_ALL_ERASED | CODEWORD_ERASED)\n\n \n#define READ_LOCATION_OFFSET\t\t0\n#define READ_LOCATION_SIZE\t\t16\n#define READ_LOCATION_LAST\t\t31\n\n \n#define\tNAND_VERSION_MAJOR_MASK\t\t0xf0000000\n#define\tNAND_VERSION_MAJOR_SHIFT\t28\n#define\tNAND_VERSION_MINOR_MASK\t\t0x0fff0000\n#define\tNAND_VERSION_MINOR_SHIFT\t16\n\n \n#define\tOP_PAGE_READ\t\t\t0x2\n#define\tOP_PAGE_READ_WITH_ECC\t\t0x3\n#define\tOP_PAGE_READ_WITH_ECC_SPARE\t0x4\n#define\tOP_PAGE_READ_ONFI_READ\t\t0x5\n#define\tOP_PROGRAM_PAGE\t\t\t0x6\n#define\tOP_PAGE_PROGRAM_WITH_ECC\t0x7\n#define\tOP_PROGRAM_PAGE_SPARE\t\t0x9\n#define\tOP_BLOCK_ERASE\t\t\t0xa\n#define\tOP_CHECK_STATUS\t\t\t0xc\n#define\tOP_FETCH_ID\t\t\t0xb\n#define\tOP_RESET_DEVICE\t\t\t0xd\n\n \n#define NAND_DEV_CMD_VLD_VAL\t\t(READ_START_VLD | WRITE_START_VLD | \\\n\t\t\t\t\t ERASE_START_VLD | SEQ_READ_START_VLD)\n\n \n#define\tBAM_MODE_EN\t\t\tBIT(0)\n\n \n#define\tNANDC_STEP_SIZE\t\t\t512\n\n \n#define\tMAX_NUM_STEPS\t\t\t(SZ_8K / NANDC_STEP_SIZE)\n\n \n#define\tMAX_REG_RD\t\t\t(3 * MAX_NUM_STEPS)\n\n \n#define\tECC_NONE\tBIT(0)\n#define\tECC_RS_4BIT\tBIT(1)\n#define\tECC_BCH_4BIT\tBIT(2)\n#define\tECC_BCH_8BIT\tBIT(3)\n\n#define nandc_set_read_loc_first(chip, reg, cw_offset, read_size, is_last_read_loc)\t\\\nnandc_set_reg(chip, reg,\t\t\t\\\n\t      ((cw_offset) << READ_LOCATION_OFFSET) |\t\t\\\n\t      ((read_size) << READ_LOCATION_SIZE) |\t\t\t\\\n\t      ((is_last_read_loc) << READ_LOCATION_LAST))\n\n#define nandc_set_read_loc_last(chip, reg, cw_offset, read_size, is_last_read_loc)\t\\\nnandc_set_reg(chip, reg,\t\t\t\\\n\t      ((cw_offset) << READ_LOCATION_OFFSET) |\t\t\\\n\t      ((read_size) << READ_LOCATION_SIZE) |\t\t\t\\\n\t      ((is_last_read_loc) << READ_LOCATION_LAST))\n \n#define dev_cmd_reg_addr(nandc, reg) ((nandc)->props->dev_cmd_reg_start + (reg))\n\n \n#define nandc_reg_phys(chip, offset) ((chip)->base_phys + (offset))\n\n \n#define reg_buf_dma_addr(chip, vaddr) \\\n\t((chip)->reg_read_dma + \\\n\t((u8 *)(vaddr) - (u8 *)(chip)->reg_read_buf))\n\n#define QPIC_PER_CW_CMD_ELEMENTS\t32\n#define QPIC_PER_CW_CMD_SGL\t\t32\n#define QPIC_PER_CW_DATA_SGL\t\t8\n\n#define QPIC_NAND_COMPLETION_TIMEOUT\tmsecs_to_jiffies(2000)\n\n \n \n#define NAND_BAM_NO_EOT\t\t\tBIT(0)\n \n#define NAND_BAM_NWD\t\t\tBIT(1)\n \n#define NAND_BAM_NEXT_SGL\t\tBIT(2)\n \n#define NAND_ERASED_CW_SET\t\tBIT(4)\n\n#define MAX_ADDRESS_CYCLE\t\t5\n\n \nstruct bam_transaction {\n\tstruct bam_cmd_element *bam_ce;\n\tstruct scatterlist *cmd_sgl;\n\tstruct scatterlist *data_sgl;\n\tstruct dma_async_tx_descriptor *last_data_desc;\n\tstruct dma_async_tx_descriptor *last_cmd_desc;\n\tstruct completion txn_done;\n\tu32 bam_ce_pos;\n\tu32 bam_ce_start;\n\tu32 cmd_sgl_pos;\n\tu32 cmd_sgl_start;\n\tu32 tx_sgl_pos;\n\tu32 tx_sgl_start;\n\tu32 rx_sgl_pos;\n\tu32 rx_sgl_start;\n\tbool wait_second_completion;\n};\n\n \nstruct desc_info {\n\tstruct dma_async_tx_descriptor *dma_desc;\n\tstruct list_head node;\n\n\tunion {\n\t\tstruct scatterlist adm_sgl;\n\t\tstruct {\n\t\t\tstruct scatterlist *bam_sgl;\n\t\t\tint sgl_cnt;\n\t\t};\n\t};\n\tenum dma_data_direction dir;\n};\n\n \nstruct nandc_regs {\n\t__le32 cmd;\n\t__le32 addr0;\n\t__le32 addr1;\n\t__le32 chip_sel;\n\t__le32 exec;\n\n\t__le32 cfg0;\n\t__le32 cfg1;\n\t__le32 ecc_bch_cfg;\n\n\t__le32 clrflashstatus;\n\t__le32 clrreadstatus;\n\n\t__le32 cmd1;\n\t__le32 vld;\n\n\t__le32 orig_cmd1;\n\t__le32 orig_vld;\n\n\t__le32 ecc_buf_cfg;\n\t__le32 read_location0;\n\t__le32 read_location1;\n\t__le32 read_location2;\n\t__le32 read_location3;\n\t__le32 read_location_last0;\n\t__le32 read_location_last1;\n\t__le32 read_location_last2;\n\t__le32 read_location_last3;\n\n\t__le32 erased_cw_detect_cfg_clr;\n\t__le32 erased_cw_detect_cfg_set;\n};\n\n \nstruct qcom_nand_controller {\n\tstruct device *dev;\n\n\tvoid __iomem *base;\n\n\tstruct clk *core_clk;\n\tstruct clk *aon_clk;\n\n\tstruct nandc_regs *regs;\n\tstruct bam_transaction *bam_txn;\n\n\tconst struct qcom_nandc_props *props;\n\n\tstruct nand_controller controller;\n\tstruct list_head host_list;\n\n\tunion {\n\t\t \n\t\tstruct {\n\t\t\tstruct dma_chan *tx_chan;\n\t\t\tstruct dma_chan *rx_chan;\n\t\t\tstruct dma_chan *cmd_chan;\n\t\t};\n\n\t\t \n\t\tstruct {\n\t\t\tstruct dma_chan *chan;\n\t\t\tunsigned int cmd_crci;\n\t\t\tunsigned int data_crci;\n\t\t};\n\t};\n\n\tstruct list_head desc_list;\n\n\tu8\t\t*data_buffer;\n\t__le32\t\t*reg_read_buf;\n\n\tphys_addr_t base_phys;\n\tdma_addr_t base_dma;\n\tdma_addr_t reg_read_dma;\n\n\tint\t\tbuf_size;\n\tint\t\tbuf_count;\n\tint\t\tbuf_start;\n\tunsigned int\tmax_cwperpage;\n\n\tint reg_read_pos;\n\n\tu32 cmd1, vld;\n\tbool exec_opwrite;\n};\n\n \nstruct qcom_nand_boot_partition {\n\tu32 page_offset;\n\tu32 page_size;\n};\n\n \nstruct qcom_op {\n\tconst struct nand_op_instr *data_instr;\n\tunsigned int data_instr_idx;\n\tunsigned int rdy_timeout_ms;\n\tunsigned int rdy_delay_ns;\n\tu32 addr1_reg;\n\tu32 addr2_reg;\n\tu32 cmd_reg;\n\tu8 flag;\n};\n\n \nstruct qcom_nand_host {\n\tstruct qcom_nand_boot_partition *boot_partitions;\n\n\tstruct nand_chip chip;\n\tstruct list_head node;\n\n\tint nr_boot_partitions;\n\n\tint cs;\n\tint cw_size;\n\tint cw_data;\n\tint ecc_bytes_hw;\n\tint spare_bytes;\n\tint bbm_size;\n\n\tint last_command;\n\n\tu32 cfg0, cfg1;\n\tu32 cfg0_raw, cfg1_raw;\n\tu32 ecc_buf_cfg;\n\tu32 ecc_bch_cfg;\n\tu32 clrflashstatus;\n\tu32 clrreadstatus;\n\n\tu8 status;\n\tbool codeword_fixup;\n\tbool use_ecc;\n\tbool bch_enabled;\n};\n\n \nstruct qcom_nandc_props {\n\tu32 ecc_modes;\n\tu32 dev_cmd_reg_start;\n\tbool is_bam;\n\tbool is_qpic;\n\tbool qpic_v2;\n\tbool use_codeword_fixup;\n};\n\n \nstatic void free_bam_transaction(struct qcom_nand_controller *nandc)\n{\n\tstruct bam_transaction *bam_txn = nandc->bam_txn;\n\n\tdevm_kfree(nandc->dev, bam_txn);\n}\n\n \nstatic struct bam_transaction *\nalloc_bam_transaction(struct qcom_nand_controller *nandc)\n{\n\tstruct bam_transaction *bam_txn;\n\tsize_t bam_txn_size;\n\tunsigned int num_cw = nandc->max_cwperpage;\n\tvoid *bam_txn_buf;\n\n\tbam_txn_size =\n\t\tsizeof(*bam_txn) + num_cw *\n\t\t((sizeof(*bam_txn->bam_ce) * QPIC_PER_CW_CMD_ELEMENTS) +\n\t\t(sizeof(*bam_txn->cmd_sgl) * QPIC_PER_CW_CMD_SGL) +\n\t\t(sizeof(*bam_txn->data_sgl) * QPIC_PER_CW_DATA_SGL));\n\n\tbam_txn_buf = devm_kzalloc(nandc->dev, bam_txn_size, GFP_KERNEL);\n\tif (!bam_txn_buf)\n\t\treturn NULL;\n\n\tbam_txn = bam_txn_buf;\n\tbam_txn_buf += sizeof(*bam_txn);\n\n\tbam_txn->bam_ce = bam_txn_buf;\n\tbam_txn_buf +=\n\t\tsizeof(*bam_txn->bam_ce) * QPIC_PER_CW_CMD_ELEMENTS * num_cw;\n\n\tbam_txn->cmd_sgl = bam_txn_buf;\n\tbam_txn_buf +=\n\t\tsizeof(*bam_txn->cmd_sgl) * QPIC_PER_CW_CMD_SGL * num_cw;\n\n\tbam_txn->data_sgl = bam_txn_buf;\n\n\tinit_completion(&bam_txn->txn_done);\n\n\treturn bam_txn;\n}\n\n \nstatic void clear_bam_transaction(struct qcom_nand_controller *nandc)\n{\n\tstruct bam_transaction *bam_txn = nandc->bam_txn;\n\n\tif (!nandc->props->is_bam)\n\t\treturn;\n\n\tbam_txn->bam_ce_pos = 0;\n\tbam_txn->bam_ce_start = 0;\n\tbam_txn->cmd_sgl_pos = 0;\n\tbam_txn->cmd_sgl_start = 0;\n\tbam_txn->tx_sgl_pos = 0;\n\tbam_txn->tx_sgl_start = 0;\n\tbam_txn->rx_sgl_pos = 0;\n\tbam_txn->rx_sgl_start = 0;\n\tbam_txn->last_data_desc = NULL;\n\tbam_txn->wait_second_completion = false;\n\n\tsg_init_table(bam_txn->cmd_sgl, nandc->max_cwperpage *\n\t\t      QPIC_PER_CW_CMD_SGL);\n\tsg_init_table(bam_txn->data_sgl, nandc->max_cwperpage *\n\t\t      QPIC_PER_CW_DATA_SGL);\n\n\treinit_completion(&bam_txn->txn_done);\n}\n\n \nstatic void qpic_bam_dma_done(void *data)\n{\n\tstruct bam_transaction *bam_txn = data;\n\n\t \n\tif (bam_txn->wait_second_completion)\n\t\tbam_txn->wait_second_completion = false;\n\telse\n\t\tcomplete(&bam_txn->txn_done);\n}\n\nstatic inline struct qcom_nand_host *to_qcom_nand_host(struct nand_chip *chip)\n{\n\treturn container_of(chip, struct qcom_nand_host, chip);\n}\n\nstatic inline struct qcom_nand_controller *\nget_qcom_nand_controller(struct nand_chip *chip)\n{\n\treturn container_of(chip->controller, struct qcom_nand_controller,\n\t\t\t    controller);\n}\n\nstatic inline u32 nandc_read(struct qcom_nand_controller *nandc, int offset)\n{\n\treturn ioread32(nandc->base + offset);\n}\n\nstatic inline void nandc_write(struct qcom_nand_controller *nandc, int offset,\n\t\t\t       u32 val)\n{\n\tiowrite32(val, nandc->base + offset);\n}\n\nstatic inline void nandc_read_buffer_sync(struct qcom_nand_controller *nandc,\n\t\t\t\t\t  bool is_cpu)\n{\n\tif (!nandc->props->is_bam)\n\t\treturn;\n\n\tif (is_cpu)\n\t\tdma_sync_single_for_cpu(nandc->dev, nandc->reg_read_dma,\n\t\t\t\t\tMAX_REG_RD *\n\t\t\t\t\tsizeof(*nandc->reg_read_buf),\n\t\t\t\t\tDMA_FROM_DEVICE);\n\telse\n\t\tdma_sync_single_for_device(nandc->dev, nandc->reg_read_dma,\n\t\t\t\t\t   MAX_REG_RD *\n\t\t\t\t\t   sizeof(*nandc->reg_read_buf),\n\t\t\t\t\t   DMA_FROM_DEVICE);\n}\n\nstatic __le32 *offset_to_nandc_reg(struct nandc_regs *regs, int offset)\n{\n\tswitch (offset) {\n\tcase NAND_FLASH_CMD:\n\t\treturn &regs->cmd;\n\tcase NAND_ADDR0:\n\t\treturn &regs->addr0;\n\tcase NAND_ADDR1:\n\t\treturn &regs->addr1;\n\tcase NAND_FLASH_CHIP_SELECT:\n\t\treturn &regs->chip_sel;\n\tcase NAND_EXEC_CMD:\n\t\treturn &regs->exec;\n\tcase NAND_FLASH_STATUS:\n\t\treturn &regs->clrflashstatus;\n\tcase NAND_DEV0_CFG0:\n\t\treturn &regs->cfg0;\n\tcase NAND_DEV0_CFG1:\n\t\treturn &regs->cfg1;\n\tcase NAND_DEV0_ECC_CFG:\n\t\treturn &regs->ecc_bch_cfg;\n\tcase NAND_READ_STATUS:\n\t\treturn &regs->clrreadstatus;\n\tcase NAND_DEV_CMD1:\n\t\treturn &regs->cmd1;\n\tcase NAND_DEV_CMD1_RESTORE:\n\t\treturn &regs->orig_cmd1;\n\tcase NAND_DEV_CMD_VLD:\n\t\treturn &regs->vld;\n\tcase NAND_DEV_CMD_VLD_RESTORE:\n\t\treturn &regs->orig_vld;\n\tcase NAND_EBI2_ECC_BUF_CFG:\n\t\treturn &regs->ecc_buf_cfg;\n\tcase NAND_READ_LOCATION_0:\n\t\treturn &regs->read_location0;\n\tcase NAND_READ_LOCATION_1:\n\t\treturn &regs->read_location1;\n\tcase NAND_READ_LOCATION_2:\n\t\treturn &regs->read_location2;\n\tcase NAND_READ_LOCATION_3:\n\t\treturn &regs->read_location3;\n\tcase NAND_READ_LOCATION_LAST_CW_0:\n\t\treturn &regs->read_location_last0;\n\tcase NAND_READ_LOCATION_LAST_CW_1:\n\t\treturn &regs->read_location_last1;\n\tcase NAND_READ_LOCATION_LAST_CW_2:\n\t\treturn &regs->read_location_last2;\n\tcase NAND_READ_LOCATION_LAST_CW_3:\n\t\treturn &regs->read_location_last3;\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic void nandc_set_reg(struct nand_chip *chip, int offset,\n\t\t\t  u32 val)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nandc_regs *regs = nandc->regs;\n\t__le32 *reg;\n\n\treg = offset_to_nandc_reg(regs, offset);\n\n\tif (reg)\n\t\t*reg = cpu_to_le32(val);\n}\n\n \nstatic bool qcom_nandc_is_last_cw(struct nand_ecc_ctrl *ecc, int cw)\n{\n\treturn cw == (ecc->steps - 1);\n}\n\n \nstatic void nandc_set_read_loc(struct nand_chip *chip, int cw, int reg,\n\t\t\t       int cw_offset, int read_size, int is_last_read_loc)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tint reg_base = NAND_READ_LOCATION_0;\n\n\tif (nandc->props->qpic_v2 && qcom_nandc_is_last_cw(ecc, cw))\n\t\treg_base = NAND_READ_LOCATION_LAST_CW_0;\n\n\treg_base += reg * 4;\n\n\tif (nandc->props->qpic_v2 && qcom_nandc_is_last_cw(ecc, cw))\n\t\treturn nandc_set_read_loc_last(chip, reg_base, cw_offset,\n\t\t\t\tread_size, is_last_read_loc);\n\telse\n\t\treturn nandc_set_read_loc_first(chip, reg_base, cw_offset,\n\t\t\t\tread_size, is_last_read_loc);\n}\n\n \nstatic void set_address(struct qcom_nand_host *host, u16 column, int page)\n{\n\tstruct nand_chip *chip = &host->chip;\n\n\tif (chip->options & NAND_BUSWIDTH_16)\n\t\tcolumn >>= 1;\n\n\tnandc_set_reg(chip, NAND_ADDR0, page << 16 | column);\n\tnandc_set_reg(chip, NAND_ADDR1, page >> 16 & 0xff);\n}\n\n \nstatic void update_rw_regs(struct qcom_nand_host *host, int num_cw, bool read, int cw)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tu32 cmd, cfg0, cfg1, ecc_bch_cfg;\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\n\tif (read) {\n\t\tif (host->use_ecc)\n\t\t\tcmd = OP_PAGE_READ_WITH_ECC | PAGE_ACC | LAST_PAGE;\n\t\telse\n\t\t\tcmd = OP_PAGE_READ | PAGE_ACC | LAST_PAGE;\n\t} else {\n\t\tcmd = OP_PROGRAM_PAGE | PAGE_ACC | LAST_PAGE;\n\t}\n\n\tif (host->use_ecc) {\n\t\tcfg0 = (host->cfg0 & ~(7U << CW_PER_PAGE)) |\n\t\t\t\t(num_cw - 1) << CW_PER_PAGE;\n\n\t\tcfg1 = host->cfg1;\n\t\tecc_bch_cfg = host->ecc_bch_cfg;\n\t} else {\n\t\tcfg0 = (host->cfg0_raw & ~(7U << CW_PER_PAGE)) |\n\t\t\t\t(num_cw - 1) << CW_PER_PAGE;\n\n\t\tcfg1 = host->cfg1_raw;\n\t\tecc_bch_cfg = 1 << ECC_CFG_ECC_DISABLE;\n\t}\n\n\tnandc_set_reg(chip, NAND_FLASH_CMD, cmd);\n\tnandc_set_reg(chip, NAND_DEV0_CFG0, cfg0);\n\tnandc_set_reg(chip, NAND_DEV0_CFG1, cfg1);\n\tnandc_set_reg(chip, NAND_DEV0_ECC_CFG, ecc_bch_cfg);\n\tif (!nandc->props->qpic_v2)\n\t\tnandc_set_reg(chip, NAND_EBI2_ECC_BUF_CFG, host->ecc_buf_cfg);\n\tnandc_set_reg(chip, NAND_FLASH_STATUS, host->clrflashstatus);\n\tnandc_set_reg(chip, NAND_READ_STATUS, host->clrreadstatus);\n\tnandc_set_reg(chip, NAND_EXEC_CMD, 1);\n\n\tif (read)\n\t\tnandc_set_read_loc(chip, cw, 0, 0, host->use_ecc ?\n\t\t\t\t   host->cw_data : host->cw_size, 1);\n}\n\n \nstatic int prepare_bam_async_desc(struct qcom_nand_controller *nandc,\n\t\t\t\t  struct dma_chan *chan,\n\t\t\t\t  unsigned long flags)\n{\n\tstruct desc_info *desc;\n\tstruct scatterlist *sgl;\n\tunsigned int sgl_cnt;\n\tint ret;\n\tstruct bam_transaction *bam_txn = nandc->bam_txn;\n\tenum dma_transfer_direction dir_eng;\n\tstruct dma_async_tx_descriptor *dma_desc;\n\n\tdesc = kzalloc(sizeof(*desc), GFP_KERNEL);\n\tif (!desc)\n\t\treturn -ENOMEM;\n\n\tif (chan == nandc->cmd_chan) {\n\t\tsgl = &bam_txn->cmd_sgl[bam_txn->cmd_sgl_start];\n\t\tsgl_cnt = bam_txn->cmd_sgl_pos - bam_txn->cmd_sgl_start;\n\t\tbam_txn->cmd_sgl_start = bam_txn->cmd_sgl_pos;\n\t\tdir_eng = DMA_MEM_TO_DEV;\n\t\tdesc->dir = DMA_TO_DEVICE;\n\t} else if (chan == nandc->tx_chan) {\n\t\tsgl = &bam_txn->data_sgl[bam_txn->tx_sgl_start];\n\t\tsgl_cnt = bam_txn->tx_sgl_pos - bam_txn->tx_sgl_start;\n\t\tbam_txn->tx_sgl_start = bam_txn->tx_sgl_pos;\n\t\tdir_eng = DMA_MEM_TO_DEV;\n\t\tdesc->dir = DMA_TO_DEVICE;\n\t} else {\n\t\tsgl = &bam_txn->data_sgl[bam_txn->rx_sgl_start];\n\t\tsgl_cnt = bam_txn->rx_sgl_pos - bam_txn->rx_sgl_start;\n\t\tbam_txn->rx_sgl_start = bam_txn->rx_sgl_pos;\n\t\tdir_eng = DMA_DEV_TO_MEM;\n\t\tdesc->dir = DMA_FROM_DEVICE;\n\t}\n\n\tsg_mark_end(sgl + sgl_cnt - 1);\n\tret = dma_map_sg(nandc->dev, sgl, sgl_cnt, desc->dir);\n\tif (ret == 0) {\n\t\tdev_err(nandc->dev, \"failure in mapping desc\\n\");\n\t\tkfree(desc);\n\t\treturn -ENOMEM;\n\t}\n\n\tdesc->sgl_cnt = sgl_cnt;\n\tdesc->bam_sgl = sgl;\n\n\tdma_desc = dmaengine_prep_slave_sg(chan, sgl, sgl_cnt, dir_eng,\n\t\t\t\t\t   flags);\n\n\tif (!dma_desc) {\n\t\tdev_err(nandc->dev, \"failure in prep desc\\n\");\n\t\tdma_unmap_sg(nandc->dev, sgl, sgl_cnt, desc->dir);\n\t\tkfree(desc);\n\t\treturn -EINVAL;\n\t}\n\n\tdesc->dma_desc = dma_desc;\n\n\t \n\tif (chan == nandc->cmd_chan)\n\t\tbam_txn->last_cmd_desc = dma_desc;\n\telse\n\t\tbam_txn->last_data_desc = dma_desc;\n\n\tlist_add_tail(&desc->node, &nandc->desc_list);\n\n\treturn 0;\n}\n\n \nstatic int prep_bam_dma_desc_cmd(struct qcom_nand_controller *nandc, bool read,\n\t\t\t\t int reg_off, const void *vaddr,\n\t\t\t\t int size, unsigned int flags)\n{\n\tint bam_ce_size;\n\tint i, ret;\n\tstruct bam_cmd_element *bam_ce_buffer;\n\tstruct bam_transaction *bam_txn = nandc->bam_txn;\n\n\tbam_ce_buffer = &bam_txn->bam_ce[bam_txn->bam_ce_pos];\n\n\t \n\tfor (i = 0; i < size; i++) {\n\t\tif (read)\n\t\t\tbam_prep_ce(&bam_ce_buffer[i],\n\t\t\t\t    nandc_reg_phys(nandc, reg_off + 4 * i),\n\t\t\t\t    BAM_READ_COMMAND,\n\t\t\t\t    reg_buf_dma_addr(nandc,\n\t\t\t\t\t\t     (__le32 *)vaddr + i));\n\t\telse\n\t\t\tbam_prep_ce_le32(&bam_ce_buffer[i],\n\t\t\t\t\t nandc_reg_phys(nandc, reg_off + 4 * i),\n\t\t\t\t\t BAM_WRITE_COMMAND,\n\t\t\t\t\t *((__le32 *)vaddr + i));\n\t}\n\n\tbam_txn->bam_ce_pos += size;\n\n\t \n\tif (flags & NAND_BAM_NEXT_SGL) {\n\t\tbam_ce_buffer = &bam_txn->bam_ce[bam_txn->bam_ce_start];\n\t\tbam_ce_size = (bam_txn->bam_ce_pos -\n\t\t\t\tbam_txn->bam_ce_start) *\n\t\t\t\tsizeof(struct bam_cmd_element);\n\t\tsg_set_buf(&bam_txn->cmd_sgl[bam_txn->cmd_sgl_pos],\n\t\t\t   bam_ce_buffer, bam_ce_size);\n\t\tbam_txn->cmd_sgl_pos++;\n\t\tbam_txn->bam_ce_start = bam_txn->bam_ce_pos;\n\n\t\tif (flags & NAND_BAM_NWD) {\n\t\t\tret = prepare_bam_async_desc(nandc, nandc->cmd_chan,\n\t\t\t\t\t\t     DMA_PREP_FENCE |\n\t\t\t\t\t\t     DMA_PREP_CMD);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic int prep_bam_dma_desc_data(struct qcom_nand_controller *nandc, bool read,\n\t\t\t\t  const void *vaddr,\n\t\t\t\t  int size, unsigned int flags)\n{\n\tint ret;\n\tstruct bam_transaction *bam_txn = nandc->bam_txn;\n\n\tif (read) {\n\t\tsg_set_buf(&bam_txn->data_sgl[bam_txn->rx_sgl_pos],\n\t\t\t   vaddr, size);\n\t\tbam_txn->rx_sgl_pos++;\n\t} else {\n\t\tsg_set_buf(&bam_txn->data_sgl[bam_txn->tx_sgl_pos],\n\t\t\t   vaddr, size);\n\t\tbam_txn->tx_sgl_pos++;\n\n\t\t \n\t\tif (!(flags & NAND_BAM_NO_EOT)) {\n\t\t\tret = prepare_bam_async_desc(nandc, nandc->tx_chan,\n\t\t\t\t\t\t     DMA_PREP_INTERRUPT);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int prep_adm_dma_desc(struct qcom_nand_controller *nandc, bool read,\n\t\t\t     int reg_off, const void *vaddr, int size,\n\t\t\t     bool flow_control)\n{\n\tstruct desc_info *desc;\n\tstruct dma_async_tx_descriptor *dma_desc;\n\tstruct scatterlist *sgl;\n\tstruct dma_slave_config slave_conf;\n\tstruct qcom_adm_peripheral_config periph_conf = {};\n\tenum dma_transfer_direction dir_eng;\n\tint ret;\n\n\tdesc = kzalloc(sizeof(*desc), GFP_KERNEL);\n\tif (!desc)\n\t\treturn -ENOMEM;\n\n\tsgl = &desc->adm_sgl;\n\n\tsg_init_one(sgl, vaddr, size);\n\n\tif (read) {\n\t\tdir_eng = DMA_DEV_TO_MEM;\n\t\tdesc->dir = DMA_FROM_DEVICE;\n\t} else {\n\t\tdir_eng = DMA_MEM_TO_DEV;\n\t\tdesc->dir = DMA_TO_DEVICE;\n\t}\n\n\tret = dma_map_sg(nandc->dev, sgl, 1, desc->dir);\n\tif (ret == 0) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tmemset(&slave_conf, 0x00, sizeof(slave_conf));\n\n\tslave_conf.device_fc = flow_control;\n\tif (read) {\n\t\tslave_conf.src_maxburst = 16;\n\t\tslave_conf.src_addr = nandc->base_dma + reg_off;\n\t\tif (nandc->data_crci) {\n\t\t\tperiph_conf.crci = nandc->data_crci;\n\t\t\tslave_conf.peripheral_config = &periph_conf;\n\t\t\tslave_conf.peripheral_size = sizeof(periph_conf);\n\t\t}\n\t} else {\n\t\tslave_conf.dst_maxburst = 16;\n\t\tslave_conf.dst_addr = nandc->base_dma + reg_off;\n\t\tif (nandc->cmd_crci) {\n\t\t\tperiph_conf.crci = nandc->cmd_crci;\n\t\t\tslave_conf.peripheral_config = &periph_conf;\n\t\t\tslave_conf.peripheral_size = sizeof(periph_conf);\n\t\t}\n\t}\n\n\tret = dmaengine_slave_config(nandc->chan, &slave_conf);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failed to configure dma channel\\n\");\n\t\tgoto err;\n\t}\n\n\tdma_desc = dmaengine_prep_slave_sg(nandc->chan, sgl, 1, dir_eng, 0);\n\tif (!dma_desc) {\n\t\tdev_err(nandc->dev, \"failed to prepare desc\\n\");\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tdesc->dma_desc = dma_desc;\n\n\tlist_add_tail(&desc->node, &nandc->desc_list);\n\n\treturn 0;\nerr:\n\tkfree(desc);\n\n\treturn ret;\n}\n\n \nstatic int read_reg_dma(struct qcom_nand_controller *nandc, int first,\n\t\t\tint num_regs, unsigned int flags)\n{\n\tbool flow_control = false;\n\tvoid *vaddr;\n\n\tvaddr = nandc->reg_read_buf + nandc->reg_read_pos;\n\tnandc->reg_read_pos += num_regs;\n\n\tif (first == NAND_DEV_CMD_VLD || first == NAND_DEV_CMD1)\n\t\tfirst = dev_cmd_reg_addr(nandc, first);\n\n\tif (nandc->props->is_bam)\n\t\treturn prep_bam_dma_desc_cmd(nandc, true, first, vaddr,\n\t\t\t\t\t     num_regs, flags);\n\n\tif (first == NAND_READ_ID || first == NAND_FLASH_STATUS)\n\t\tflow_control = true;\n\n\treturn prep_adm_dma_desc(nandc, true, first, vaddr,\n\t\t\t\t num_regs * sizeof(u32), flow_control);\n}\n\n \nstatic int write_reg_dma(struct qcom_nand_controller *nandc, int first,\n\t\t\t int num_regs, unsigned int flags)\n{\n\tbool flow_control = false;\n\tstruct nandc_regs *regs = nandc->regs;\n\tvoid *vaddr;\n\n\tvaddr = offset_to_nandc_reg(regs, first);\n\n\tif (first == NAND_ERASED_CW_DETECT_CFG) {\n\t\tif (flags & NAND_ERASED_CW_SET)\n\t\t\tvaddr = &regs->erased_cw_detect_cfg_set;\n\t\telse\n\t\t\tvaddr = &regs->erased_cw_detect_cfg_clr;\n\t}\n\n\tif (first == NAND_EXEC_CMD)\n\t\tflags |= NAND_BAM_NWD;\n\n\tif (first == NAND_DEV_CMD1_RESTORE || first == NAND_DEV_CMD1)\n\t\tfirst = dev_cmd_reg_addr(nandc, NAND_DEV_CMD1);\n\n\tif (first == NAND_DEV_CMD_VLD_RESTORE || first == NAND_DEV_CMD_VLD)\n\t\tfirst = dev_cmd_reg_addr(nandc, NAND_DEV_CMD_VLD);\n\n\tif (nandc->props->is_bam)\n\t\treturn prep_bam_dma_desc_cmd(nandc, false, first, vaddr,\n\t\t\t\t\t     num_regs, flags);\n\n\tif (first == NAND_FLASH_CMD)\n\t\tflow_control = true;\n\n\treturn prep_adm_dma_desc(nandc, false, first, vaddr,\n\t\t\t\t num_regs * sizeof(u32), flow_control);\n}\n\n \nstatic int read_data_dma(struct qcom_nand_controller *nandc, int reg_off,\n\t\t\t const u8 *vaddr, int size, unsigned int flags)\n{\n\tif (nandc->props->is_bam)\n\t\treturn prep_bam_dma_desc_data(nandc, true, vaddr, size, flags);\n\n\treturn prep_adm_dma_desc(nandc, true, reg_off, vaddr, size, false);\n}\n\n \nstatic int write_data_dma(struct qcom_nand_controller *nandc, int reg_off,\n\t\t\t  const u8 *vaddr, int size, unsigned int flags)\n{\n\tif (nandc->props->is_bam)\n\t\treturn prep_bam_dma_desc_data(nandc, false, vaddr, size, flags);\n\n\treturn prep_adm_dma_desc(nandc, false, reg_off, vaddr, size, false);\n}\n\n \nstatic void config_nand_page_read(struct nand_chip *chip)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\n\twrite_reg_dma(nandc, NAND_ADDR0, 2, 0);\n\twrite_reg_dma(nandc, NAND_DEV0_CFG0, 3, 0);\n\tif (!nandc->props->qpic_v2)\n\t\twrite_reg_dma(nandc, NAND_EBI2_ECC_BUF_CFG, 1, 0);\n\twrite_reg_dma(nandc, NAND_ERASED_CW_DETECT_CFG, 1, 0);\n\twrite_reg_dma(nandc, NAND_ERASED_CW_DETECT_CFG, 1,\n\t\t      NAND_ERASED_CW_SET | NAND_BAM_NEXT_SGL);\n}\n\n \nstatic void\nconfig_nand_cw_read(struct nand_chip *chip, bool use_ecc, int cw)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\n\tint reg = NAND_READ_LOCATION_0;\n\n\tif (nandc->props->qpic_v2 && qcom_nandc_is_last_cw(ecc, cw))\n\t\treg = NAND_READ_LOCATION_LAST_CW_0;\n\n\tif (nandc->props->is_bam)\n\t\twrite_reg_dma(nandc, reg, 4, NAND_BAM_NEXT_SGL);\n\n\twrite_reg_dma(nandc, NAND_FLASH_CMD, 1, NAND_BAM_NEXT_SGL);\n\twrite_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);\n\n\tif (use_ecc) {\n\t\tread_reg_dma(nandc, NAND_FLASH_STATUS, 2, 0);\n\t\tread_reg_dma(nandc, NAND_ERASED_CW_DETECT_STATUS, 1,\n\t\t\t     NAND_BAM_NEXT_SGL);\n\t} else {\n\t\tread_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);\n\t}\n}\n\n \nstatic void\nconfig_nand_single_cw_page_read(struct nand_chip *chip,\n\t\t\t\tbool use_ecc, int cw)\n{\n\tconfig_nand_page_read(chip);\n\tconfig_nand_cw_read(chip, use_ecc, cw);\n}\n\n \nstatic void config_nand_page_write(struct nand_chip *chip)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\n\twrite_reg_dma(nandc, NAND_ADDR0, 2, 0);\n\twrite_reg_dma(nandc, NAND_DEV0_CFG0, 3, 0);\n\tif (!nandc->props->qpic_v2)\n\t\twrite_reg_dma(nandc, NAND_EBI2_ECC_BUF_CFG, 1,\n\t\t\t      NAND_BAM_NEXT_SGL);\n}\n\n \nstatic void config_nand_cw_write(struct nand_chip *chip)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\n\twrite_reg_dma(nandc, NAND_FLASH_CMD, 1, NAND_BAM_NEXT_SGL);\n\twrite_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);\n\n\tread_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);\n\n\twrite_reg_dma(nandc, NAND_FLASH_STATUS, 1, 0);\n\twrite_reg_dma(nandc, NAND_READ_STATUS, 1, NAND_BAM_NEXT_SGL);\n}\n\n \nstatic int submit_descs(struct qcom_nand_controller *nandc)\n{\n\tstruct desc_info *desc, *n;\n\tdma_cookie_t cookie = 0;\n\tstruct bam_transaction *bam_txn = nandc->bam_txn;\n\tint ret = 0;\n\n\tif (nandc->props->is_bam) {\n\t\tif (bam_txn->rx_sgl_pos > bam_txn->rx_sgl_start) {\n\t\t\tret = prepare_bam_async_desc(nandc, nandc->rx_chan, 0);\n\t\t\tif (ret)\n\t\t\t\tgoto err_unmap_free_desc;\n\t\t}\n\n\t\tif (bam_txn->tx_sgl_pos > bam_txn->tx_sgl_start) {\n\t\t\tret = prepare_bam_async_desc(nandc, nandc->tx_chan,\n\t\t\t\t\t\t   DMA_PREP_INTERRUPT);\n\t\t\tif (ret)\n\t\t\t\tgoto err_unmap_free_desc;\n\t\t}\n\n\t\tif (bam_txn->cmd_sgl_pos > bam_txn->cmd_sgl_start) {\n\t\t\tret = prepare_bam_async_desc(nandc, nandc->cmd_chan,\n\t\t\t\t\t\t   DMA_PREP_CMD);\n\t\t\tif (ret)\n\t\t\t\tgoto err_unmap_free_desc;\n\t\t}\n\t}\n\n\tlist_for_each_entry(desc, &nandc->desc_list, node)\n\t\tcookie = dmaengine_submit(desc->dma_desc);\n\n\tif (nandc->props->is_bam) {\n\t\tbam_txn->last_cmd_desc->callback = qpic_bam_dma_done;\n\t\tbam_txn->last_cmd_desc->callback_param = bam_txn;\n\t\tif (bam_txn->last_data_desc) {\n\t\t\tbam_txn->last_data_desc->callback = qpic_bam_dma_done;\n\t\t\tbam_txn->last_data_desc->callback_param = bam_txn;\n\t\t\tbam_txn->wait_second_completion = true;\n\t\t}\n\n\t\tdma_async_issue_pending(nandc->tx_chan);\n\t\tdma_async_issue_pending(nandc->rx_chan);\n\t\tdma_async_issue_pending(nandc->cmd_chan);\n\n\t\tif (!wait_for_completion_timeout(&bam_txn->txn_done,\n\t\t\t\t\t\t QPIC_NAND_COMPLETION_TIMEOUT))\n\t\t\tret = -ETIMEDOUT;\n\t} else {\n\t\tif (dma_sync_wait(nandc->chan, cookie) != DMA_COMPLETE)\n\t\t\tret = -ETIMEDOUT;\n\t}\n\nerr_unmap_free_desc:\n\t \n\tlist_for_each_entry_safe(desc, n, &nandc->desc_list, node) {\n\t\tlist_del(&desc->node);\n\n\t\tif (nandc->props->is_bam)\n\t\t\tdma_unmap_sg(nandc->dev, desc->bam_sgl,\n\t\t\t\t     desc->sgl_cnt, desc->dir);\n\t\telse\n\t\t\tdma_unmap_sg(nandc->dev, &desc->adm_sgl, 1,\n\t\t\t\t     desc->dir);\n\n\t\tkfree(desc);\n\t}\n\n\treturn ret;\n}\n\n \nstatic void clear_read_regs(struct qcom_nand_controller *nandc)\n{\n\tnandc->reg_read_pos = 0;\n\tnandc_read_buffer_sync(nandc, false);\n}\n\n \nstatic bool erased_chunk_check_and_fixup(u8 *data_buf, int data_len)\n{\n\tu8 empty1, empty2;\n\n\t \n\n\tempty1 = data_buf[3];\n\tempty2 = data_buf[175];\n\n\t \n\tif ((empty1 == 0x54 && empty2 == 0xff) ||\n\t    (empty1 == 0xff && empty2 == 0x54)) {\n\t\tdata_buf[3] = 0xff;\n\t\tdata_buf[175] = 0xff;\n\t}\n\n\t \n\tif (memchr_inv(data_buf, 0xff, data_len)) {\n\t\tdata_buf[3] = empty1;\n\t\tdata_buf[175] = empty2;\n\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstruct read_stats {\n\t__le32 flash;\n\t__le32 buffer;\n\t__le32 erased_cw;\n};\n\n \nstatic int check_flash_errors(struct qcom_nand_host *host, int cw_cnt)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tint i;\n\n\tnandc_read_buffer_sync(nandc, true);\n\n\tfor (i = 0; i < cw_cnt; i++) {\n\t\tu32 flash = le32_to_cpu(nandc->reg_read_buf[i]);\n\n\t\tif (flash & (FS_OP_ERR | FS_MPU_ERR))\n\t\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int\nqcom_nandc_read_cw_raw(struct mtd_info *mtd, struct nand_chip *chip,\n\t\t       u8 *data_buf, u8 *oob_buf, int page, int cw)\n{\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tint data_size1, data_size2, oob_size1, oob_size2;\n\tint ret, reg_off = FLASH_BUF_ACC, read_loc = 0;\n\tint raw_cw = cw;\n\n\tnand_read_page_op(chip, page, 0, NULL, 0);\n\tnandc->buf_count = 0;\n\tnandc->buf_start = 0;\n\tclear_read_regs(nandc);\n\thost->use_ecc = false;\n\n\tif (nandc->props->qpic_v2)\n\t\traw_cw = ecc->steps - 1;\n\n\tclear_bam_transaction(nandc);\n\tset_address(host, host->cw_size * cw, page);\n\tupdate_rw_regs(host, 1, true, raw_cw);\n\tconfig_nand_page_read(chip);\n\n\tdata_size1 = mtd->writesize - host->cw_size * (ecc->steps - 1);\n\toob_size1 = host->bbm_size;\n\n\tif (qcom_nandc_is_last_cw(ecc, cw) && !host->codeword_fixup) {\n\t\tdata_size2 = ecc->size - data_size1 -\n\t\t\t     ((ecc->steps - 1) * 4);\n\t\toob_size2 = (ecc->steps * 4) + host->ecc_bytes_hw +\n\t\t\t    host->spare_bytes;\n\t} else {\n\t\tdata_size2 = host->cw_data - data_size1;\n\t\toob_size2 = host->ecc_bytes_hw + host->spare_bytes;\n\t}\n\n\tif (nandc->props->is_bam) {\n\t\tnandc_set_read_loc(chip, cw, 0, read_loc, data_size1, 0);\n\t\tread_loc += data_size1;\n\n\t\tnandc_set_read_loc(chip, cw, 1, read_loc, oob_size1, 0);\n\t\tread_loc += oob_size1;\n\n\t\tnandc_set_read_loc(chip, cw, 2, read_loc, data_size2, 0);\n\t\tread_loc += data_size2;\n\n\t\tnandc_set_read_loc(chip, cw, 3, read_loc, oob_size2, 1);\n\t}\n\n\tconfig_nand_cw_read(chip, false, raw_cw);\n\n\tread_data_dma(nandc, reg_off, data_buf, data_size1, 0);\n\treg_off += data_size1;\n\n\tread_data_dma(nandc, reg_off, oob_buf, oob_size1, 0);\n\treg_off += oob_size1;\n\n\tread_data_dma(nandc, reg_off, data_buf + data_size1, data_size2, 0);\n\treg_off += data_size2;\n\n\tread_data_dma(nandc, reg_off, oob_buf + oob_size1, oob_size2, 0);\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure to read raw cw %d\\n\", cw);\n\t\treturn ret;\n\t}\n\n\treturn check_flash_errors(host, 1);\n}\n\n \nstatic int\ncheck_for_erased_page(struct qcom_nand_host *host, u8 *data_buf,\n\t\t      u8 *oob_buf, unsigned long uncorrectable_cws,\n\t\t      int page, unsigned int max_bitflips)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tu8 *cw_data_buf, *cw_oob_buf;\n\tint cw, data_size, oob_size, ret;\n\n\tif (!data_buf)\n\t\tdata_buf = nand_get_data_buf(chip);\n\n\tif (!oob_buf) {\n\t\tnand_get_data_buf(chip);\n\t\toob_buf = chip->oob_poi;\n\t}\n\n\tfor_each_set_bit(cw, &uncorrectable_cws, ecc->steps) {\n\t\tif (qcom_nandc_is_last_cw(ecc, cw) && !host->codeword_fixup) {\n\t\t\tdata_size = ecc->size - ((ecc->steps - 1) * 4);\n\t\t\toob_size = (ecc->steps * 4) + host->ecc_bytes_hw;\n\t\t} else {\n\t\t\tdata_size = host->cw_data;\n\t\t\toob_size = host->ecc_bytes_hw;\n\t\t}\n\n\t\t \n\t\tcw_data_buf = data_buf + (cw * host->cw_data);\n\t\tcw_oob_buf = oob_buf + (cw * ecc->bytes);\n\n\t\tret = qcom_nandc_read_cw_raw(mtd, chip, cw_data_buf,\n\t\t\t\t\t     cw_oob_buf, page, cw);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\tret = nand_check_erased_ecc_chunk(cw_data_buf, data_size,\n\t\t\t\t\t\t  cw_oob_buf + host->bbm_size,\n\t\t\t\t\t\t  oob_size, NULL,\n\t\t\t\t\t\t  0, ecc->strength);\n\t\tif (ret < 0) {\n\t\t\tmtd->ecc_stats.failed++;\n\t\t} else {\n\t\t\tmtd->ecc_stats.corrected += ret;\n\t\t\tmax_bitflips = max_t(unsigned int, max_bitflips, ret);\n\t\t}\n\t}\n\n\treturn max_bitflips;\n}\n\n \nstatic int parse_read_errors(struct qcom_nand_host *host, u8 *data_buf,\n\t\t\t     u8 *oob_buf, int page)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tunsigned int max_bitflips = 0, uncorrectable_cws = 0;\n\tstruct read_stats *buf;\n\tbool flash_op_err = false, erased;\n\tint i;\n\tu8 *data_buf_start = data_buf, *oob_buf_start = oob_buf;\n\n\tbuf = (struct read_stats *)nandc->reg_read_buf;\n\tnandc_read_buffer_sync(nandc, true);\n\n\tfor (i = 0; i < ecc->steps; i++, buf++) {\n\t\tu32 flash, buffer, erased_cw;\n\t\tint data_len, oob_len;\n\n\t\tif (qcom_nandc_is_last_cw(ecc, i)) {\n\t\t\tdata_len = ecc->size - ((ecc->steps - 1) << 2);\n\t\t\toob_len = ecc->steps << 2;\n\t\t} else {\n\t\t\tdata_len = host->cw_data;\n\t\t\toob_len = 0;\n\t\t}\n\n\t\tflash = le32_to_cpu(buf->flash);\n\t\tbuffer = le32_to_cpu(buf->buffer);\n\t\terased_cw = le32_to_cpu(buf->erased_cw);\n\n\t\t \n\t\tif ((flash & FS_OP_ERR) && (buffer & BS_UNCORRECTABLE_BIT)) {\n\t\t\t \n\t\t\tif (host->bch_enabled) {\n\t\t\t\terased = (erased_cw & ERASED_CW) == ERASED_CW;\n\t\t\t \n\t\t\t} else if (data_buf) {\n\t\t\t\terased = erased_chunk_check_and_fixup(data_buf,\n\t\t\t\t\t\t\t\t      data_len);\n\t\t\t} else {\n\t\t\t\terased = false;\n\t\t\t}\n\n\t\t\tif (!erased)\n\t\t\t\tuncorrectable_cws |= BIT(i);\n\t\t \n\t\t} else if (flash & (FS_OP_ERR | FS_MPU_ERR)) {\n\t\t\tflash_op_err = true;\n\t\t \n\t\t} else {\n\t\t\tunsigned int stat;\n\n\t\t\tstat = buffer & BS_CORRECTABLE_ERR_MSK;\n\t\t\tmtd->ecc_stats.corrected += stat;\n\t\t\tmax_bitflips = max(max_bitflips, stat);\n\t\t}\n\n\t\tif (data_buf)\n\t\t\tdata_buf += data_len;\n\t\tif (oob_buf)\n\t\t\toob_buf += oob_len + ecc->bytes;\n\t}\n\n\tif (flash_op_err)\n\t\treturn -EIO;\n\n\tif (!uncorrectable_cws)\n\t\treturn max_bitflips;\n\n\treturn check_for_erased_page(host, data_buf_start, oob_buf_start,\n\t\t\t\t     uncorrectable_cws, page,\n\t\t\t\t     max_bitflips);\n}\n\n \nstatic int read_page_ecc(struct qcom_nand_host *host, u8 *data_buf,\n\t\t\t u8 *oob_buf, int page)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tu8 *data_buf_start = data_buf, *oob_buf_start = oob_buf;\n\tint i, ret;\n\n\tconfig_nand_page_read(chip);\n\n\t \n\tfor (i = 0; i < ecc->steps; i++) {\n\t\tint data_size, oob_size;\n\n\t\tif (qcom_nandc_is_last_cw(ecc, i) && !host->codeword_fixup) {\n\t\t\tdata_size = ecc->size - ((ecc->steps - 1) << 2);\n\t\t\toob_size = (ecc->steps << 2) + host->ecc_bytes_hw +\n\t\t\t\t   host->spare_bytes;\n\t\t} else {\n\t\t\tdata_size = host->cw_data;\n\t\t\toob_size = host->ecc_bytes_hw + host->spare_bytes;\n\t\t}\n\n\t\tif (nandc->props->is_bam) {\n\t\t\tif (data_buf && oob_buf) {\n\t\t\t\tnandc_set_read_loc(chip, i, 0, 0, data_size, 0);\n\t\t\t\tnandc_set_read_loc(chip, i, 1, data_size,\n\t\t\t\t\t\t   oob_size, 1);\n\t\t\t} else if (data_buf) {\n\t\t\t\tnandc_set_read_loc(chip, i, 0, 0, data_size, 1);\n\t\t\t} else {\n\t\t\t\tnandc_set_read_loc(chip, i, 0, data_size,\n\t\t\t\t\t\t   oob_size, 1);\n\t\t\t}\n\t\t}\n\n\t\tconfig_nand_cw_read(chip, true, i);\n\n\t\tif (data_buf)\n\t\t\tread_data_dma(nandc, FLASH_BUF_ACC, data_buf,\n\t\t\t\t      data_size, 0);\n\n\t\t \n\t\tif (oob_buf) {\n\t\t\tint j;\n\n\t\t\tfor (j = 0; j < host->bbm_size; j++)\n\t\t\t\t*oob_buf++ = 0xff;\n\n\t\t\tread_data_dma(nandc, FLASH_BUF_ACC + data_size,\n\t\t\t\t      oob_buf, oob_size, 0);\n\t\t}\n\n\t\tif (data_buf)\n\t\t\tdata_buf += data_size;\n\t\tif (oob_buf)\n\t\t\toob_buf += oob_size;\n\t}\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure to read page/oob\\n\");\n\t\treturn ret;\n\t}\n\n\treturn parse_read_errors(host, data_buf_start, oob_buf_start, page);\n}\n\n \nstatic int copy_last_cw(struct qcom_nand_host *host, int page)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tint size;\n\tint ret;\n\n\tclear_read_regs(nandc);\n\n\tsize = host->use_ecc ? host->cw_data : host->cw_size;\n\n\t \n\tmemset(nandc->data_buffer, 0xff, size);\n\n\tset_address(host, host->cw_size * (ecc->steps - 1), page);\n\tupdate_rw_regs(host, 1, true, ecc->steps - 1);\n\n\tconfig_nand_single_cw_page_read(chip, host->use_ecc, ecc->steps - 1);\n\n\tread_data_dma(nandc, FLASH_BUF_ACC, nandc->data_buffer, size, 0);\n\n\tret = submit_descs(nandc);\n\tif (ret)\n\t\tdev_err(nandc->dev, \"failed to copy last codeword\\n\");\n\n\treturn ret;\n}\n\nstatic bool qcom_nandc_is_boot_partition(struct qcom_nand_host *host, int page)\n{\n\tstruct qcom_nand_boot_partition *boot_partition;\n\tu32 start, end;\n\tint i;\n\n\t \n\n\t \n\tboot_partition = &host->boot_partitions[host->nr_boot_partitions - 1];\n\tstart = boot_partition->page_offset;\n\tend = start + boot_partition->page_size;\n\n\t \n\tif (page > end)\n\t\treturn false;\n\n\t \n\tif (page < end && page >= start)\n\t\treturn true;\n\n\t \n\tfor (i = host->nr_boot_partitions - 2; i >= 0; i--) {\n\t\tboot_partition = &host->boot_partitions[i];\n\t\tstart = boot_partition->page_offset;\n\t\tend = start + boot_partition->page_size;\n\n\t\tif (page < end && page >= start)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void qcom_nandc_codeword_fixup(struct qcom_nand_host *host, int page)\n{\n\tbool codeword_fixup = qcom_nandc_is_boot_partition(host, page);\n\n\t \n\tif (codeword_fixup == host->codeword_fixup)\n\t\treturn;\n\n\thost->codeword_fixup = codeword_fixup;\n\n\thost->cw_data = codeword_fixup ? 512 : 516;\n\thost->spare_bytes = host->cw_size - host->ecc_bytes_hw -\n\t\t\t    host->bbm_size - host->cw_data;\n\n\thost->cfg0 &= ~(SPARE_SIZE_BYTES_MASK | UD_SIZE_BYTES_MASK);\n\thost->cfg0 |= host->spare_bytes << SPARE_SIZE_BYTES |\n\t\t      host->cw_data << UD_SIZE_BYTES;\n\n\thost->ecc_bch_cfg &= ~ECC_NUM_DATA_BYTES_MASK;\n\thost->ecc_bch_cfg |= host->cw_data << ECC_NUM_DATA_BYTES;\n\thost->ecc_buf_cfg = (host->cw_data - 1) << NUM_STEPS;\n}\n\n \nstatic int qcom_nandc_read_page(struct nand_chip *chip, u8 *buf,\n\t\t\t\tint oob_required, int page)\n{\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tu8 *data_buf, *oob_buf = NULL;\n\n\tif (host->nr_boot_partitions)\n\t\tqcom_nandc_codeword_fixup(host, page);\n\n\tnand_read_page_op(chip, page, 0, NULL, 0);\n\tnandc->buf_count = 0;\n\tnandc->buf_start = 0;\n\thost->use_ecc = true;\n\tclear_read_regs(nandc);\n\tset_address(host, 0, page);\n\tupdate_rw_regs(host, ecc->steps, true, 0);\n\n\tdata_buf = buf;\n\toob_buf = oob_required ? chip->oob_poi : NULL;\n\n\tclear_bam_transaction(nandc);\n\n\treturn read_page_ecc(host, data_buf, oob_buf, page);\n}\n\n \nstatic int qcom_nandc_read_page_raw(struct nand_chip *chip, u8 *buf,\n\t\t\t\t    int oob_required, int page)\n{\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tint cw, ret;\n\tu8 *data_buf = buf, *oob_buf = chip->oob_poi;\n\n\tif (host->nr_boot_partitions)\n\t\tqcom_nandc_codeword_fixup(host, page);\n\n\tfor (cw = 0; cw < ecc->steps; cw++) {\n\t\tret = qcom_nandc_read_cw_raw(mtd, chip, data_buf, oob_buf,\n\t\t\t\t\t     page, cw);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tdata_buf += host->cw_data;\n\t\toob_buf += ecc->bytes;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int qcom_nandc_read_oob(struct nand_chip *chip, int page)\n{\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\n\tif (host->nr_boot_partitions)\n\t\tqcom_nandc_codeword_fixup(host, page);\n\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\thost->use_ecc = true;\n\tset_address(host, 0, page);\n\tupdate_rw_regs(host, ecc->steps, true, 0);\n\n\treturn read_page_ecc(host, NULL, chip->oob_poi, page);\n}\n\n \nstatic int qcom_nandc_write_page(struct nand_chip *chip, const u8 *buf,\n\t\t\t\t int oob_required, int page)\n{\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tu8 *data_buf, *oob_buf;\n\tint i, ret;\n\n\tif (host->nr_boot_partitions)\n\t\tqcom_nandc_codeword_fixup(host, page);\n\n\tnand_prog_page_begin_op(chip, page, 0, NULL, 0);\n\n\tset_address(host, 0, page);\n\tnandc->buf_count = 0;\n\tnandc->buf_start = 0;\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\tdata_buf = (u8 *)buf;\n\toob_buf = chip->oob_poi;\n\n\thost->use_ecc = true;\n\tupdate_rw_regs(host, ecc->steps, false, 0);\n\tconfig_nand_page_write(chip);\n\n\tfor (i = 0; i < ecc->steps; i++) {\n\t\tint data_size, oob_size;\n\n\t\tif (qcom_nandc_is_last_cw(ecc, i) && !host->codeword_fixup) {\n\t\t\tdata_size = ecc->size - ((ecc->steps - 1) << 2);\n\t\t\toob_size = (ecc->steps << 2) + host->ecc_bytes_hw +\n\t\t\t\t   host->spare_bytes;\n\t\t} else {\n\t\t\tdata_size = host->cw_data;\n\t\t\toob_size = ecc->bytes;\n\t\t}\n\n\t\twrite_data_dma(nandc, FLASH_BUF_ACC, data_buf, data_size,\n\t\t\t       i == (ecc->steps - 1) ? NAND_BAM_NO_EOT : 0);\n\n\t\t \n\t\tif (qcom_nandc_is_last_cw(ecc, i)) {\n\t\t\toob_buf += host->bbm_size;\n\n\t\t\twrite_data_dma(nandc, FLASH_BUF_ACC + data_size,\n\t\t\t\t       oob_buf, oob_size, 0);\n\t\t}\n\n\t\tconfig_nand_cw_write(chip);\n\n\t\tdata_buf += data_size;\n\t\toob_buf += oob_size;\n\t}\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure to write page\\n\");\n\t\treturn ret;\n\t}\n\n\treturn nand_prog_page_end_op(chip);\n}\n\n \nstatic int qcom_nandc_write_page_raw(struct nand_chip *chip,\n\t\t\t\t     const u8 *buf, int oob_required,\n\t\t\t\t     int page)\n{\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tu8 *data_buf, *oob_buf;\n\tint i, ret;\n\n\tif (host->nr_boot_partitions)\n\t\tqcom_nandc_codeword_fixup(host, page);\n\n\tnand_prog_page_begin_op(chip, page, 0, NULL, 0);\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\tdata_buf = (u8 *)buf;\n\toob_buf = chip->oob_poi;\n\n\thost->use_ecc = false;\n\tupdate_rw_regs(host, ecc->steps, false, 0);\n\tconfig_nand_page_write(chip);\n\n\tfor (i = 0; i < ecc->steps; i++) {\n\t\tint data_size1, data_size2, oob_size1, oob_size2;\n\t\tint reg_off = FLASH_BUF_ACC;\n\n\t\tdata_size1 = mtd->writesize - host->cw_size * (ecc->steps - 1);\n\t\toob_size1 = host->bbm_size;\n\n\t\tif (qcom_nandc_is_last_cw(ecc, i) && !host->codeword_fixup) {\n\t\t\tdata_size2 = ecc->size - data_size1 -\n\t\t\t\t     ((ecc->steps - 1) << 2);\n\t\t\toob_size2 = (ecc->steps << 2) + host->ecc_bytes_hw +\n\t\t\t\t    host->spare_bytes;\n\t\t} else {\n\t\t\tdata_size2 = host->cw_data - data_size1;\n\t\t\toob_size2 = host->ecc_bytes_hw + host->spare_bytes;\n\t\t}\n\n\t\twrite_data_dma(nandc, reg_off, data_buf, data_size1,\n\t\t\t       NAND_BAM_NO_EOT);\n\t\treg_off += data_size1;\n\t\tdata_buf += data_size1;\n\n\t\twrite_data_dma(nandc, reg_off, oob_buf, oob_size1,\n\t\t\t       NAND_BAM_NO_EOT);\n\t\treg_off += oob_size1;\n\t\toob_buf += oob_size1;\n\n\t\twrite_data_dma(nandc, reg_off, data_buf, data_size2,\n\t\t\t       NAND_BAM_NO_EOT);\n\t\treg_off += data_size2;\n\t\tdata_buf += data_size2;\n\n\t\twrite_data_dma(nandc, reg_off, oob_buf, oob_size2, 0);\n\t\toob_buf += oob_size2;\n\n\t\tconfig_nand_cw_write(chip);\n\t}\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure to write raw page\\n\");\n\t\treturn ret;\n\t}\n\n\treturn nand_prog_page_end_op(chip);\n}\n\n \nstatic int qcom_nandc_write_oob(struct nand_chip *chip, int page)\n{\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tu8 *oob = chip->oob_poi;\n\tint data_size, oob_size;\n\tint ret;\n\n\tif (host->nr_boot_partitions)\n\t\tqcom_nandc_codeword_fixup(host, page);\n\n\thost->use_ecc = true;\n\tclear_bam_transaction(nandc);\n\n\t \n\tdata_size = ecc->size - ((ecc->steps - 1) << 2);\n\toob_size = mtd->oobavail;\n\n\tmemset(nandc->data_buffer, 0xff, host->cw_data);\n\t \n\tmtd_ooblayout_get_databytes(mtd, nandc->data_buffer + data_size, oob,\n\t\t\t\t    0, mtd->oobavail);\n\n\tset_address(host, host->cw_size * (ecc->steps - 1), page);\n\tupdate_rw_regs(host, 1, false, 0);\n\n\tconfig_nand_page_write(chip);\n\twrite_data_dma(nandc, FLASH_BUF_ACC,\n\t\t       nandc->data_buffer, data_size + oob_size, 0);\n\tconfig_nand_cw_write(chip);\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure to write oob\\n\");\n\t\treturn ret;\n\t}\n\n\treturn nand_prog_page_end_op(chip);\n}\n\nstatic int qcom_nandc_block_bad(struct nand_chip *chip, loff_t ofs)\n{\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tint page, ret, bbpos, bad = 0;\n\n\tpage = (int)(ofs >> chip->page_shift) & chip->pagemask;\n\n\t \n\thost->use_ecc = false;\n\n\tclear_bam_transaction(nandc);\n\tret = copy_last_cw(host, page);\n\tif (ret)\n\t\tgoto err;\n\n\tif (check_flash_errors(host, 1)) {\n\t\tdev_warn(nandc->dev, \"error when trying to read BBM\\n\");\n\t\tgoto err;\n\t}\n\n\tbbpos = mtd->writesize - host->cw_size * (ecc->steps - 1);\n\n\tbad = nandc->data_buffer[bbpos] != 0xff;\n\n\tif (chip->options & NAND_BUSWIDTH_16)\n\t\tbad = bad || (nandc->data_buffer[bbpos + 1] != 0xff);\nerr:\n\treturn bad;\n}\n\nstatic int qcom_nandc_block_markbad(struct nand_chip *chip, loff_t ofs)\n{\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tint page, ret;\n\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\t \n\tmemset(nandc->data_buffer, 0x00, host->cw_size);\n\n\tpage = (int)(ofs >> chip->page_shift) & chip->pagemask;\n\n\t \n\thost->use_ecc = false;\n\tset_address(host, host->cw_size * (ecc->steps - 1), page);\n\tupdate_rw_regs(host, 1, false, ecc->steps - 1);\n\n\tconfig_nand_page_write(chip);\n\twrite_data_dma(nandc, FLASH_BUF_ACC,\n\t\t       nandc->data_buffer, host->cw_size, 0);\n\tconfig_nand_cw_write(chip);\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure to update BBM\\n\");\n\t\treturn ret;\n\t}\n\n\treturn nand_prog_page_end_op(chip);\n}\n\n \nstatic int qcom_nand_ooblayout_ecc(struct mtd_info *mtd, int section,\n\t\t\t\t   struct mtd_oob_region *oobregion)\n{\n\tstruct nand_chip *chip = mtd_to_nand(mtd);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\n\tif (section > 1)\n\t\treturn -ERANGE;\n\n\tif (!section) {\n\t\toobregion->length = (ecc->bytes * (ecc->steps - 1)) +\n\t\t\t\t    host->bbm_size;\n\t\toobregion->offset = 0;\n\t} else {\n\t\toobregion->length = host->ecc_bytes_hw + host->spare_bytes;\n\t\toobregion->offset = mtd->oobsize - oobregion->length;\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_nand_ooblayout_free(struct mtd_info *mtd, int section,\n\t\t\t\t    struct mtd_oob_region *oobregion)\n{\n\tstruct nand_chip *chip = mtd_to_nand(mtd);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\n\tif (section)\n\t\treturn -ERANGE;\n\n\toobregion->length = ecc->steps * 4;\n\toobregion->offset = ((ecc->steps - 1) * ecc->bytes) + host->bbm_size;\n\n\treturn 0;\n}\n\nstatic const struct mtd_ooblayout_ops qcom_nand_ooblayout_ops = {\n\t.ecc = qcom_nand_ooblayout_ecc,\n\t.free = qcom_nand_ooblayout_free,\n};\n\nstatic int\nqcom_nandc_calc_ecc_bytes(int step_size, int strength)\n{\n\treturn strength == 4 ? 12 : 16;\n}\n\nNAND_ECC_CAPS_SINGLE(qcom_nandc_ecc_caps, qcom_nandc_calc_ecc_bytes,\n\t\t     NANDC_STEP_SIZE, 4, 8);\n\nstatic int qcom_nand_attach_chip(struct nand_chip *chip)\n{\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tint cwperpage, bad_block_byte, ret;\n\tbool wide_bus;\n\tint ecc_mode = 1;\n\n\t \n\tecc->size = NANDC_STEP_SIZE;\n\twide_bus = chip->options & NAND_BUSWIDTH_16 ? true : false;\n\tcwperpage = mtd->writesize / NANDC_STEP_SIZE;\n\n\t \n\tret = nand_ecc_choose_conf(chip, &qcom_nandc_ecc_caps,\n\t\t\t\t   mtd->oobsize - (cwperpage * 4));\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"No valid ECC settings possible\\n\");\n\t\treturn ret;\n\t}\n\n\tif (ecc->strength >= 8) {\n\t\t \n\t\thost->bch_enabled = true;\n\t\tecc_mode = 1;\n\n\t\tif (wide_bus) {\n\t\t\thost->ecc_bytes_hw = 14;\n\t\t\thost->spare_bytes = 0;\n\t\t\thost->bbm_size = 2;\n\t\t} else {\n\t\t\thost->ecc_bytes_hw = 13;\n\t\t\thost->spare_bytes = 2;\n\t\t\thost->bbm_size = 1;\n\t\t}\n\t} else {\n\t\t \n\t\tif (nandc->props->ecc_modes & ECC_BCH_4BIT) {\n\t\t\t \n\t\t\thost->bch_enabled = true;\n\t\t\tecc_mode = 0;\n\n\t\t\tif (wide_bus) {\n\t\t\t\thost->ecc_bytes_hw = 8;\n\t\t\t\thost->spare_bytes = 2;\n\t\t\t\thost->bbm_size = 2;\n\t\t\t} else {\n\t\t\t\thost->ecc_bytes_hw = 7;\n\t\t\t\thost->spare_bytes = 4;\n\t\t\t\thost->bbm_size = 1;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\thost->ecc_bytes_hw = 10;\n\n\t\t\tif (wide_bus) {\n\t\t\t\thost->spare_bytes = 0;\n\t\t\t\thost->bbm_size = 2;\n\t\t\t} else {\n\t\t\t\thost->spare_bytes = 1;\n\t\t\t\thost->bbm_size = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tecc->bytes = host->ecc_bytes_hw + host->spare_bytes + host->bbm_size;\n\n\tecc->read_page\t\t= qcom_nandc_read_page;\n\tecc->read_page_raw\t= qcom_nandc_read_page_raw;\n\tecc->read_oob\t\t= qcom_nandc_read_oob;\n\tecc->write_page\t\t= qcom_nandc_write_page;\n\tecc->write_page_raw\t= qcom_nandc_write_page_raw;\n\tecc->write_oob\t\t= qcom_nandc_write_oob;\n\n\tecc->engine_type = NAND_ECC_ENGINE_TYPE_ON_HOST;\n\n\tmtd_set_ooblayout(mtd, &qcom_nand_ooblayout_ops);\n\t \n\tif (nandc->props->is_bam)\n\t\tfree_bam_transaction(nandc);\n\n\tnandc->max_cwperpage = max_t(unsigned int, nandc->max_cwperpage,\n\t\t\t\t     cwperpage);\n\n\t \n\tif (nandc->props->is_bam) {\n\t\tnandc->bam_txn = alloc_bam_transaction(nandc);\n\t\tif (!nandc->bam_txn) {\n\t\t\tdev_err(nandc->dev,\n\t\t\t\t\"failed to allocate bam transaction\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\t \n\thost->cw_data = 516;\n\n\t \n\thost->cw_size = host->cw_data + ecc->bytes;\n\tbad_block_byte = mtd->writesize - host->cw_size * (cwperpage - 1) + 1;\n\n\thost->cfg0 = (cwperpage - 1) << CW_PER_PAGE\n\t\t\t\t| host->cw_data << UD_SIZE_BYTES\n\t\t\t\t| 0 << DISABLE_STATUS_AFTER_WRITE\n\t\t\t\t| 5 << NUM_ADDR_CYCLES\n\t\t\t\t| host->ecc_bytes_hw << ECC_PARITY_SIZE_BYTES_RS\n\t\t\t\t| 0 << STATUS_BFR_READ\n\t\t\t\t| 1 << SET_RD_MODE_AFTER_STATUS\n\t\t\t\t| host->spare_bytes << SPARE_SIZE_BYTES;\n\n\thost->cfg1 = 7 << NAND_RECOVERY_CYCLES\n\t\t\t\t| 0 <<  CS_ACTIVE_BSY\n\t\t\t\t| bad_block_byte << BAD_BLOCK_BYTE_NUM\n\t\t\t\t| 0 << BAD_BLOCK_IN_SPARE_AREA\n\t\t\t\t| 2 << WR_RD_BSY_GAP\n\t\t\t\t| wide_bus << WIDE_FLASH\n\t\t\t\t| host->bch_enabled << ENABLE_BCH_ECC;\n\n\thost->cfg0_raw = (cwperpage - 1) << CW_PER_PAGE\n\t\t\t\t| host->cw_size << UD_SIZE_BYTES\n\t\t\t\t| 5 << NUM_ADDR_CYCLES\n\t\t\t\t| 0 << SPARE_SIZE_BYTES;\n\n\thost->cfg1_raw = 7 << NAND_RECOVERY_CYCLES\n\t\t\t\t| 0 << CS_ACTIVE_BSY\n\t\t\t\t| 17 << BAD_BLOCK_BYTE_NUM\n\t\t\t\t| 1 << BAD_BLOCK_IN_SPARE_AREA\n\t\t\t\t| 2 << WR_RD_BSY_GAP\n\t\t\t\t| wide_bus << WIDE_FLASH\n\t\t\t\t| 1 << DEV0_CFG1_ECC_DISABLE;\n\n\thost->ecc_bch_cfg = !host->bch_enabled << ECC_CFG_ECC_DISABLE\n\t\t\t\t| 0 << ECC_SW_RESET\n\t\t\t\t| host->cw_data << ECC_NUM_DATA_BYTES\n\t\t\t\t| 1 << ECC_FORCE_CLK_OPEN\n\t\t\t\t| ecc_mode << ECC_MODE\n\t\t\t\t| host->ecc_bytes_hw << ECC_PARITY_SIZE_BYTES_BCH;\n\n\tif (!nandc->props->qpic_v2)\n\t\thost->ecc_buf_cfg = 0x203 << NUM_STEPS;\n\n\thost->clrflashstatus = FS_READY_BSY_N;\n\thost->clrreadstatus = 0xc0;\n\tnandc->regs->erased_cw_detect_cfg_clr =\n\t\tcpu_to_le32(CLR_ERASED_PAGE_DET);\n\tnandc->regs->erased_cw_detect_cfg_set =\n\t\tcpu_to_le32(SET_ERASED_PAGE_DET);\n\n\tdev_dbg(nandc->dev,\n\t\t\"cfg0 %x cfg1 %x ecc_buf_cfg %x ecc_bch cfg %x cw_size %d cw_data %d strength %d parity_bytes %d steps %d\\n\",\n\t\thost->cfg0, host->cfg1, host->ecc_buf_cfg, host->ecc_bch_cfg,\n\t\thost->cw_size, host->cw_data, ecc->strength, ecc->bytes,\n\t\tcwperpage);\n\n\treturn 0;\n}\n\nstatic int qcom_op_cmd_mapping(struct nand_chip *chip, u8 opcode,\n\t\t\t       struct qcom_op *q_op)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tint cmd;\n\n\tswitch (opcode) {\n\tcase NAND_CMD_RESET:\n\t\tcmd = OP_RESET_DEVICE;\n\t\tbreak;\n\tcase NAND_CMD_READID:\n\t\tcmd = OP_FETCH_ID;\n\t\tbreak;\n\tcase NAND_CMD_PARAM:\n\t\tif (nandc->props->qpic_v2)\n\t\t\tcmd = OP_PAGE_READ_ONFI_READ;\n\t\telse\n\t\t\tcmd = OP_PAGE_READ;\n\t\tbreak;\n\tcase NAND_CMD_ERASE1:\n\tcase NAND_CMD_ERASE2:\n\t\tcmd = OP_BLOCK_ERASE;\n\t\tbreak;\n\tcase NAND_CMD_STATUS:\n\t\tcmd = OP_CHECK_STATUS;\n\t\tbreak;\n\tcase NAND_CMD_PAGEPROG:\n\t\tcmd = OP_PROGRAM_PAGE;\n\t\tq_op->flag = OP_PROGRAM_PAGE;\n\t\tnandc->exec_opwrite = true;\n\t\tbreak;\n\tcase NAND_CMD_READ0:\n\tcase NAND_CMD_READSTART:\n\t\tif (host->use_ecc)\n\t\t\tcmd = OP_PAGE_READ_WITH_ECC;\n\t\telse\n\t\t\tcmd = OP_PAGE_READ;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(nandc->dev, \"Opcode not supported: %u\\n\", opcode);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn cmd;\n}\n\n \nstatic int qcom_parse_instructions(struct nand_chip *chip,\n\t\t\t\t    const struct nand_subop *subop,\n\t\t\t\t    struct qcom_op *q_op)\n{\n\tconst struct nand_op_instr *instr = NULL;\n\tunsigned int op_id;\n\tint i, ret;\n\n\tfor (op_id = 0; op_id < subop->ninstrs; op_id++) {\n\t\tunsigned int offset, naddrs;\n\t\tconst u8 *addrs;\n\n\t\tinstr = &subop->instrs[op_id];\n\n\t\tswitch (instr->type) {\n\t\tcase NAND_OP_CMD_INSTR:\n\t\t\tret = qcom_op_cmd_mapping(chip, instr->ctx.cmd.opcode, q_op);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tq_op->cmd_reg = ret;\n\t\t\tq_op->rdy_delay_ns = instr->delay_ns;\n\t\t\tbreak;\n\n\t\tcase NAND_OP_ADDR_INSTR:\n\t\t\toffset = nand_subop_get_addr_start_off(subop, op_id);\n\t\t\tnaddrs = nand_subop_get_num_addr_cyc(subop, op_id);\n\t\t\taddrs = &instr->ctx.addr.addrs[offset];\n\n\t\t\tfor (i = 0; i < min_t(unsigned int, 4, naddrs); i++)\n\t\t\t\tq_op->addr1_reg |= addrs[i] << (i * 8);\n\n\t\t\tif (naddrs > 4)\n\t\t\t\tq_op->addr2_reg |= addrs[4];\n\n\t\t\tq_op->rdy_delay_ns = instr->delay_ns;\n\t\t\tbreak;\n\n\t\tcase NAND_OP_DATA_IN_INSTR:\n\t\t\tq_op->data_instr = instr;\n\t\t\tq_op->data_instr_idx = op_id;\n\t\t\tq_op->rdy_delay_ns = instr->delay_ns;\n\t\t\tfallthrough;\n\t\tcase NAND_OP_DATA_OUT_INSTR:\n\t\t\tq_op->rdy_delay_ns = instr->delay_ns;\n\t\t\tbreak;\n\n\t\tcase NAND_OP_WAITRDY_INSTR:\n\t\t\tq_op->rdy_timeout_ms = instr->ctx.waitrdy.timeout_ms;\n\t\t\tq_op->rdy_delay_ns = instr->delay_ns;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void qcom_delay_ns(unsigned int ns)\n{\n\tif (!ns)\n\t\treturn;\n\n\tif (ns < 10000)\n\t\tndelay(ns);\n\telse\n\t\tudelay(DIV_ROUND_UP(ns, 1000));\n}\n\nstatic int qcom_wait_rdy_poll(struct nand_chip *chip, unsigned int time_ms)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tunsigned long start = jiffies + msecs_to_jiffies(time_ms);\n\tu32 flash;\n\n\tnandc_read_buffer_sync(nandc, true);\n\n\tdo {\n\t\tflash = le32_to_cpu(nandc->reg_read_buf[0]);\n\t\tif (flash & FS_READY_BSY_N)\n\t\t\treturn 0;\n\t\tcpu_relax();\n\t} while (time_after(start, jiffies));\n\n\tdev_err(nandc->dev, \"Timeout waiting for device to be ready:0x%08x\\n\", flash);\n\n\treturn -ETIMEDOUT;\n}\n\nstatic int qcom_read_status_exec(struct nand_chip *chip,\n\t\t\t\t const struct nand_subop *subop)\n{\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct nand_ecc_ctrl *ecc = &chip->ecc;\n\tstruct qcom_op q_op = {};\n\tconst struct nand_op_instr *instr = NULL;\n\tunsigned int op_id = 0;\n\tunsigned int len = 0;\n\tint ret, num_cw, i;\n\tu32 flash_status;\n\n\thost->status = NAND_STATUS_READY | NAND_STATUS_WP;\n\n\tret = qcom_parse_instructions(chip, subop, &q_op);\n\tif (ret)\n\t\treturn ret;\n\n\tnum_cw = nandc->exec_opwrite ? ecc->steps : 1;\n\tnandc->exec_opwrite = false;\n\n\tnandc->buf_count = 0;\n\tnandc->buf_start = 0;\n\thost->use_ecc = false;\n\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\tnandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);\n\tnandc_set_reg(chip, NAND_EXEC_CMD, 1);\n\n\twrite_reg_dma(nandc, NAND_FLASH_CMD, 1, NAND_BAM_NEXT_SGL);\n\twrite_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);\n\tread_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure in submitting status descriptor\\n\");\n\t\tgoto err_out;\n\t}\n\n\tnandc_read_buffer_sync(nandc, true);\n\n\tfor (i = 0; i < num_cw; i++) {\n\t\tflash_status = le32_to_cpu(nandc->reg_read_buf[i]);\n\n\t\tif (flash_status & FS_MPU_ERR)\n\t\t\thost->status &= ~NAND_STATUS_WP;\n\n\t\tif (flash_status & FS_OP_ERR ||\n\t\t    (i == (num_cw - 1) && (flash_status & FS_DEVICE_STS_ERR)))\n\t\t\thost->status |= NAND_STATUS_FAIL;\n\t}\n\n\tflash_status = host->status;\n\tinstr = q_op.data_instr;\n\top_id = q_op.data_instr_idx;\n\tlen = nand_subop_get_data_len(subop, op_id);\n\tmemcpy(instr->ctx.data.buf.in, &flash_status, len);\n\nerr_out:\n\treturn ret;\n}\n\nstatic int qcom_read_id_type_exec(struct nand_chip *chip, const struct nand_subop *subop)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_op q_op = {};\n\tconst struct nand_op_instr *instr = NULL;\n\tunsigned int op_id = 0;\n\tunsigned int len = 0;\n\tint ret;\n\n\tret = qcom_parse_instructions(chip, subop, &q_op);\n\tif (ret)\n\t\treturn ret;\n\n\tnandc->buf_count = 0;\n\tnandc->buf_start = 0;\n\thost->use_ecc = false;\n\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\tnandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);\n\tnandc_set_reg(chip, NAND_ADDR0, q_op.addr1_reg);\n\tnandc_set_reg(chip, NAND_ADDR1, q_op.addr2_reg);\n\tnandc_set_reg(chip, NAND_FLASH_CHIP_SELECT,\n\t\t      nandc->props->is_bam ? 0 : DM_EN);\n\n\tnandc_set_reg(chip, NAND_EXEC_CMD, 1);\n\n\twrite_reg_dma(nandc, NAND_FLASH_CMD, 4, NAND_BAM_NEXT_SGL);\n\twrite_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);\n\n\tread_reg_dma(nandc, NAND_READ_ID, 1, NAND_BAM_NEXT_SGL);\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure in submitting read id descriptor\\n\");\n\t\tgoto err_out;\n\t}\n\n\tinstr = q_op.data_instr;\n\top_id = q_op.data_instr_idx;\n\tlen = nand_subop_get_data_len(subop, op_id);\n\n\tnandc_read_buffer_sync(nandc, true);\n\tmemcpy(instr->ctx.data.buf.in, nandc->reg_read_buf, len);\n\nerr_out:\n\treturn ret;\n}\n\nstatic int qcom_misc_cmd_type_exec(struct nand_chip *chip, const struct nand_subop *subop)\n{\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_op q_op = {};\n\tint ret;\n\tint instrs = 1;\n\n\tret = qcom_parse_instructions(chip, subop, &q_op);\n\tif (ret)\n\t\treturn ret;\n\n\tif (q_op.flag == OP_PROGRAM_PAGE) {\n\t\tgoto wait_rdy;\n\t} else if (q_op.cmd_reg == OP_BLOCK_ERASE) {\n\t\tq_op.cmd_reg |= PAGE_ACC | LAST_PAGE;\n\t\tnandc_set_reg(chip, NAND_ADDR0, q_op.addr1_reg);\n\t\tnandc_set_reg(chip, NAND_ADDR1, q_op.addr2_reg);\n\t\tnandc_set_reg(chip, NAND_DEV0_CFG0,\n\t\t\t      host->cfg0_raw & ~(7 << CW_PER_PAGE));\n\t\tnandc_set_reg(chip, NAND_DEV0_CFG1, host->cfg1_raw);\n\t\tinstrs = 3;\n\t} else {\n\t\treturn 0;\n\t}\n\n\tnandc->buf_count = 0;\n\tnandc->buf_start = 0;\n\thost->use_ecc = false;\n\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\tnandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);\n\tnandc_set_reg(chip, NAND_EXEC_CMD, 1);\n\n\twrite_reg_dma(nandc, NAND_FLASH_CMD, instrs, NAND_BAM_NEXT_SGL);\n\t(q_op.cmd_reg == OP_BLOCK_ERASE) ? write_reg_dma(nandc, NAND_DEV0_CFG0,\n\t2, NAND_BAM_NEXT_SGL) : read_reg_dma(nandc,\n\tNAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);\n\n\twrite_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);\n\tread_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure in submitting misc descriptor\\n\");\n\t\tgoto err_out;\n\t}\n\nwait_rdy:\n\tqcom_delay_ns(q_op.rdy_delay_ns);\n\tret = qcom_wait_rdy_poll(chip, q_op.rdy_timeout_ms);\n\nerr_out:\n\treturn ret;\n}\n\nstatic int qcom_param_page_type_exec(struct nand_chip *chip,  const struct nand_subop *subop)\n{\n\tstruct qcom_nand_host *host = to_qcom_nand_host(chip);\n\tstruct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);\n\tstruct qcom_op q_op = {};\n\tconst struct nand_op_instr *instr = NULL;\n\tunsigned int op_id = 0;\n\tunsigned int len = 0;\n\tint ret;\n\n\tret = qcom_parse_instructions(chip, subop, &q_op);\n\tif (ret)\n\t\treturn ret;\n\n\tq_op.cmd_reg |= PAGE_ACC | LAST_PAGE;\n\n\tnandc->buf_count = 0;\n\tnandc->buf_start = 0;\n\thost->use_ecc = false;\n\tclear_read_regs(nandc);\n\tclear_bam_transaction(nandc);\n\n\tnandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);\n\n\tnandc_set_reg(chip, NAND_ADDR0, 0);\n\tnandc_set_reg(chip, NAND_ADDR1, 0);\n\tnandc_set_reg(chip, NAND_DEV0_CFG0, 0 << CW_PER_PAGE\n\t\t\t\t\t| 512 << UD_SIZE_BYTES\n\t\t\t\t\t| 5 << NUM_ADDR_CYCLES\n\t\t\t\t\t| 0 << SPARE_SIZE_BYTES);\n\tnandc_set_reg(chip, NAND_DEV0_CFG1, 7 << NAND_RECOVERY_CYCLES\n\t\t\t\t\t| 0 << CS_ACTIVE_BSY\n\t\t\t\t\t| 17 << BAD_BLOCK_BYTE_NUM\n\t\t\t\t\t| 1 << BAD_BLOCK_IN_SPARE_AREA\n\t\t\t\t\t| 2 << WR_RD_BSY_GAP\n\t\t\t\t\t| 0 << WIDE_FLASH\n\t\t\t\t\t| 1 << DEV0_CFG1_ECC_DISABLE);\n\tif (!nandc->props->qpic_v2)\n\t\tnandc_set_reg(chip, NAND_EBI2_ECC_BUF_CFG, 1 << ECC_CFG_ECC_DISABLE);\n\n\t \n\tif (!nandc->props->qpic_v2) {\n\t\tnandc_set_reg(chip, NAND_DEV_CMD_VLD,\n\t\t\t      (nandc->vld & ~READ_START_VLD));\n\t\tnandc_set_reg(chip, NAND_DEV_CMD1,\n\t\t\t      (nandc->cmd1 & ~(0xFF << READ_ADDR))\n\t\t\t      | NAND_CMD_PARAM << READ_ADDR);\n\t}\n\n\tnandc_set_reg(chip, NAND_EXEC_CMD, 1);\n\n\tif (!nandc->props->qpic_v2) {\n\t\tnandc_set_reg(chip, NAND_DEV_CMD1_RESTORE, nandc->cmd1);\n\t\tnandc_set_reg(chip, NAND_DEV_CMD_VLD_RESTORE, nandc->vld);\n\t}\n\n\tinstr = q_op.data_instr;\n\top_id = q_op.data_instr_idx;\n\tlen = nand_subop_get_data_len(subop, op_id);\n\n\tnandc_set_read_loc(chip, 0, 0, 0, len, 1);\n\n\tif (!nandc->props->qpic_v2) {\n\t\twrite_reg_dma(nandc, NAND_DEV_CMD_VLD, 1, 0);\n\t\twrite_reg_dma(nandc, NAND_DEV_CMD1, 1, NAND_BAM_NEXT_SGL);\n\t}\n\n\tnandc->buf_count = len;\n\tmemset(nandc->data_buffer, 0xff, nandc->buf_count);\n\n\tconfig_nand_single_cw_page_read(chip, false, 0);\n\n\tread_data_dma(nandc, FLASH_BUF_ACC, nandc->data_buffer,\n\t\t      nandc->buf_count, 0);\n\n\t \n\tif (!nandc->props->qpic_v2) {\n\t\twrite_reg_dma(nandc, NAND_DEV_CMD1_RESTORE, 1, 0);\n\t\twrite_reg_dma(nandc, NAND_DEV_CMD_VLD_RESTORE, 1, NAND_BAM_NEXT_SGL);\n\t}\n\n\tret = submit_descs(nandc);\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failure in submitting param page descriptor\\n\");\n\t\tgoto err_out;\n\t}\n\n\tret = qcom_wait_rdy_poll(chip, q_op.rdy_timeout_ms);\n\tif (ret)\n\t\tgoto err_out;\n\n\tmemcpy(instr->ctx.data.buf.in, nandc->data_buffer, len);\n\nerr_out:\n\treturn ret;\n}\n\nstatic const struct nand_op_parser qcom_op_parser = NAND_OP_PARSER(\n\t\tNAND_OP_PARSER_PATTERN(\n\t\t\tqcom_read_id_type_exec,\n\t\t\tNAND_OP_PARSER_PAT_CMD_ELEM(false),\n\t\t\tNAND_OP_PARSER_PAT_ADDR_ELEM(false, MAX_ADDRESS_CYCLE),\n\t\t\tNAND_OP_PARSER_PAT_DATA_IN_ELEM(false, 8)),\n\t\tNAND_OP_PARSER_PATTERN(\n\t\t\tqcom_read_status_exec,\n\t\t\tNAND_OP_PARSER_PAT_CMD_ELEM(false),\n\t\t\tNAND_OP_PARSER_PAT_DATA_IN_ELEM(false, 1)),\n\t\tNAND_OP_PARSER_PATTERN(\n\t\t\tqcom_param_page_type_exec,\n\t\t\tNAND_OP_PARSER_PAT_CMD_ELEM(false),\n\t\t\tNAND_OP_PARSER_PAT_ADDR_ELEM(false, MAX_ADDRESS_CYCLE),\n\t\t\tNAND_OP_PARSER_PAT_WAITRDY_ELEM(true),\n\t\t\tNAND_OP_PARSER_PAT_DATA_IN_ELEM(false, 512)),\n\t\tNAND_OP_PARSER_PATTERN(\n\t\t\tqcom_misc_cmd_type_exec,\n\t\t\tNAND_OP_PARSER_PAT_CMD_ELEM(false),\n\t\t\tNAND_OP_PARSER_PAT_ADDR_ELEM(true, MAX_ADDRESS_CYCLE),\n\t\t\tNAND_OP_PARSER_PAT_CMD_ELEM(true),\n\t\t\tNAND_OP_PARSER_PAT_WAITRDY_ELEM(false)),\n\t\t);\n\nstatic int qcom_check_op(struct nand_chip *chip,\n\t\t\t const struct nand_operation *op)\n{\n\tconst struct nand_op_instr *instr;\n\tint op_id;\n\n\tfor (op_id = 0; op_id < op->ninstrs; op_id++) {\n\t\tinstr = &op->instrs[op_id];\n\n\t\tswitch (instr->type) {\n\t\tcase NAND_OP_CMD_INSTR:\n\t\t\tif (instr->ctx.cmd.opcode != NAND_CMD_RESET  &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_READID &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_PARAM  &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_ERASE1 &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_ERASE2 &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_STATUS &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_PAGEPROG &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_READ0 &&\n\t\t\t    instr->ctx.cmd.opcode != NAND_CMD_READSTART)\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_nand_exec_op(struct nand_chip *chip,\n\t\t\t     const struct nand_operation *op, bool check_only)\n{\n\tif (check_only)\n\t\treturn qcom_check_op(chip, op);\n\n\treturn nand_op_parser_exec_op(chip, &qcom_op_parser, op, check_only);\n}\n\nstatic const struct nand_controller_ops qcom_nandc_ops = {\n\t.attach_chip = qcom_nand_attach_chip,\n\t.exec_op = qcom_nand_exec_op,\n};\n\nstatic void qcom_nandc_unalloc(struct qcom_nand_controller *nandc)\n{\n\tif (nandc->props->is_bam) {\n\t\tif (!dma_mapping_error(nandc->dev, nandc->reg_read_dma))\n\t\t\tdma_unmap_single(nandc->dev, nandc->reg_read_dma,\n\t\t\t\t\t MAX_REG_RD *\n\t\t\t\t\t sizeof(*nandc->reg_read_buf),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\n\t\tif (nandc->tx_chan)\n\t\t\tdma_release_channel(nandc->tx_chan);\n\n\t\tif (nandc->rx_chan)\n\t\t\tdma_release_channel(nandc->rx_chan);\n\n\t\tif (nandc->cmd_chan)\n\t\t\tdma_release_channel(nandc->cmd_chan);\n\t} else {\n\t\tif (nandc->chan)\n\t\t\tdma_release_channel(nandc->chan);\n\t}\n}\n\nstatic int qcom_nandc_alloc(struct qcom_nand_controller *nandc)\n{\n\tint ret;\n\n\tret = dma_set_coherent_mask(nandc->dev, DMA_BIT_MASK(32));\n\tif (ret) {\n\t\tdev_err(nandc->dev, \"failed to set DMA mask\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tnandc->buf_size = 532;\n\n\tnandc->data_buffer = devm_kzalloc(nandc->dev, nandc->buf_size, GFP_KERNEL);\n\tif (!nandc->data_buffer)\n\t\treturn -ENOMEM;\n\n\tnandc->regs = devm_kzalloc(nandc->dev, sizeof(*nandc->regs), GFP_KERNEL);\n\tif (!nandc->regs)\n\t\treturn -ENOMEM;\n\n\tnandc->reg_read_buf = devm_kcalloc(nandc->dev, MAX_REG_RD,\n\t\t\t\t\t   sizeof(*nandc->reg_read_buf),\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!nandc->reg_read_buf)\n\t\treturn -ENOMEM;\n\n\tif (nandc->props->is_bam) {\n\t\tnandc->reg_read_dma =\n\t\t\tdma_map_single(nandc->dev, nandc->reg_read_buf,\n\t\t\t\t       MAX_REG_RD *\n\t\t\t\t       sizeof(*nandc->reg_read_buf),\n\t\t\t\t       DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(nandc->dev, nandc->reg_read_dma)) {\n\t\t\tdev_err(nandc->dev, \"failed to DMA MAP reg buffer\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tnandc->tx_chan = dma_request_chan(nandc->dev, \"tx\");\n\t\tif (IS_ERR(nandc->tx_chan)) {\n\t\t\tret = PTR_ERR(nandc->tx_chan);\n\t\t\tnandc->tx_chan = NULL;\n\t\t\tdev_err_probe(nandc->dev, ret,\n\t\t\t\t      \"tx DMA channel request failed\\n\");\n\t\t\tgoto unalloc;\n\t\t}\n\n\t\tnandc->rx_chan = dma_request_chan(nandc->dev, \"rx\");\n\t\tif (IS_ERR(nandc->rx_chan)) {\n\t\t\tret = PTR_ERR(nandc->rx_chan);\n\t\t\tnandc->rx_chan = NULL;\n\t\t\tdev_err_probe(nandc->dev, ret,\n\t\t\t\t      \"rx DMA channel request failed\\n\");\n\t\t\tgoto unalloc;\n\t\t}\n\n\t\tnandc->cmd_chan = dma_request_chan(nandc->dev, \"cmd\");\n\t\tif (IS_ERR(nandc->cmd_chan)) {\n\t\t\tret = PTR_ERR(nandc->cmd_chan);\n\t\t\tnandc->cmd_chan = NULL;\n\t\t\tdev_err_probe(nandc->dev, ret,\n\t\t\t\t      \"cmd DMA channel request failed\\n\");\n\t\t\tgoto unalloc;\n\t\t}\n\n\t\t \n\t\tnandc->max_cwperpage = 1;\n\t\tnandc->bam_txn = alloc_bam_transaction(nandc);\n\t\tif (!nandc->bam_txn) {\n\t\t\tdev_err(nandc->dev,\n\t\t\t\t\"failed to allocate bam transaction\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto unalloc;\n\t\t}\n\t} else {\n\t\tnandc->chan = dma_request_chan(nandc->dev, \"rxtx\");\n\t\tif (IS_ERR(nandc->chan)) {\n\t\t\tret = PTR_ERR(nandc->chan);\n\t\t\tnandc->chan = NULL;\n\t\t\tdev_err_probe(nandc->dev, ret,\n\t\t\t\t      \"rxtx DMA channel request failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tINIT_LIST_HEAD(&nandc->desc_list);\n\tINIT_LIST_HEAD(&nandc->host_list);\n\n\tnand_controller_init(&nandc->controller);\n\tnandc->controller.ops = &qcom_nandc_ops;\n\n\treturn 0;\nunalloc:\n\tqcom_nandc_unalloc(nandc);\n\treturn ret;\n}\n\n \nstatic int qcom_nandc_setup(struct qcom_nand_controller *nandc)\n{\n\tu32 nand_ctrl;\n\n\t \n\tif (!nandc->props->is_qpic)\n\t\tnandc_write(nandc, SFLASHC_BURST_CFG, 0);\n\n\tif (!nandc->props->qpic_v2)\n\t\tnandc_write(nandc, dev_cmd_reg_addr(nandc, NAND_DEV_CMD_VLD),\n\t\t\t    NAND_DEV_CMD_VLD_VAL);\n\n\t \n\tif (nandc->props->is_bam) {\n\t\tnand_ctrl = nandc_read(nandc, NAND_CTRL);\n\n\t\t \n\t\tif (!(nand_ctrl & BAM_MODE_EN))\n\t\t\tnandc_write(nandc, NAND_CTRL, nand_ctrl | BAM_MODE_EN);\n\t} else {\n\t\tnandc_write(nandc, NAND_FLASH_CHIP_SELECT, DM_EN);\n\t}\n\n\t \n\tif (!nandc->props->qpic_v2) {\n\t\tnandc->cmd1 = nandc_read(nandc, dev_cmd_reg_addr(nandc, NAND_DEV_CMD1));\n\t\tnandc->vld = NAND_DEV_CMD_VLD_VAL;\n\t}\n\n\treturn 0;\n}\n\nstatic const char * const probes[] = { \"cmdlinepart\", \"ofpart\", \"qcomsmem\", NULL };\n\nstatic int qcom_nand_host_parse_boot_partitions(struct qcom_nand_controller *nandc,\n\t\t\t\t\t\tstruct qcom_nand_host *host,\n\t\t\t\t\t\tstruct device_node *dn)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct qcom_nand_boot_partition *boot_partition;\n\tstruct device *dev = nandc->dev;\n\tint partitions_count, i, j, ret;\n\n\tif (!of_property_present(dn, \"qcom,boot-partitions\"))\n\t\treturn 0;\n\n\tpartitions_count = of_property_count_u32_elems(dn, \"qcom,boot-partitions\");\n\tif (partitions_count <= 0) {\n\t\tdev_err(dev, \"Error parsing boot partition\\n\");\n\t\treturn partitions_count ? partitions_count : -EINVAL;\n\t}\n\n\thost->nr_boot_partitions = partitions_count / 2;\n\thost->boot_partitions = devm_kcalloc(dev, host->nr_boot_partitions,\n\t\t\t\t\t     sizeof(*host->boot_partitions), GFP_KERNEL);\n\tif (!host->boot_partitions) {\n\t\thost->nr_boot_partitions = 0;\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0, j = 0; i < host->nr_boot_partitions; i++, j += 2) {\n\t\tboot_partition = &host->boot_partitions[i];\n\n\t\tret = of_property_read_u32_index(dn, \"qcom,boot-partitions\", j,\n\t\t\t\t\t\t &boot_partition->page_offset);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Error parsing boot partition offset at index %d\\n\", i);\n\t\t\thost->nr_boot_partitions = 0;\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (boot_partition->page_offset % mtd->writesize) {\n\t\t\tdev_err(dev, \"Boot partition offset not multiple of writesize at index %i\\n\",\n\t\t\t\ti);\n\t\t\thost->nr_boot_partitions = 0;\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t \n\t\tboot_partition->page_offset /= mtd->writesize;\n\n\t\tret = of_property_read_u32_index(dn, \"qcom,boot-partitions\", j + 1,\n\t\t\t\t\t\t &boot_partition->page_size);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Error parsing boot partition size at index %d\\n\", i);\n\t\t\thost->nr_boot_partitions = 0;\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (boot_partition->page_size % mtd->writesize) {\n\t\t\tdev_err(dev, \"Boot partition size not multiple of writesize at index %i\\n\",\n\t\t\t\ti);\n\t\t\thost->nr_boot_partitions = 0;\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t \n\t\tboot_partition->page_size /= mtd->writesize;\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_nand_host_init_and_register(struct qcom_nand_controller *nandc,\n\t\t\t\t\t    struct qcom_nand_host *host,\n\t\t\t\t\t    struct device_node *dn)\n{\n\tstruct nand_chip *chip = &host->chip;\n\tstruct mtd_info *mtd = nand_to_mtd(chip);\n\tstruct device *dev = nandc->dev;\n\tint ret;\n\n\tret = of_property_read_u32(dn, \"reg\", &host->cs);\n\tif (ret) {\n\t\tdev_err(dev, \"can't get chip-select\\n\");\n\t\treturn -ENXIO;\n\t}\n\n\tnand_set_flash_node(chip, dn);\n\tmtd->name = devm_kasprintf(dev, GFP_KERNEL, \"qcom_nand.%d\", host->cs);\n\tif (!mtd->name)\n\t\treturn -ENOMEM;\n\n\tmtd->owner = THIS_MODULE;\n\tmtd->dev.parent = dev;\n\n\t \n\tchip->legacy.block_bad\t\t= qcom_nandc_block_bad;\n\tchip->legacy.block_markbad\t= qcom_nandc_block_markbad;\n\n\tchip->controller = &nandc->controller;\n\tchip->options |= NAND_NO_SUBPAGE_WRITE | NAND_USES_DMA |\n\t\t\t NAND_SKIP_BBTSCAN;\n\n\t \n\thost->status = NAND_STATUS_READY | NAND_STATUS_WP;\n\n\tret = nand_scan(chip, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tret = mtd_device_parse_register(mtd, probes, NULL, NULL, 0);\n\tif (ret)\n\t\tgoto err;\n\n\tif (nandc->props->use_codeword_fixup) {\n\t\tret = qcom_nand_host_parse_boot_partitions(nandc, host, dn);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tnand_cleanup(chip);\n\treturn ret;\n}\n\nstatic int qcom_probe_nand_devices(struct qcom_nand_controller *nandc)\n{\n\tstruct device *dev = nandc->dev;\n\tstruct device_node *dn = dev->of_node, *child;\n\tstruct qcom_nand_host *host;\n\tint ret = -ENODEV;\n\n\tfor_each_available_child_of_node(dn, child) {\n\t\thost = devm_kzalloc(dev, sizeof(*host), GFP_KERNEL);\n\t\tif (!host) {\n\t\t\tof_node_put(child);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tret = qcom_nand_host_init_and_register(nandc, host, child);\n\t\tif (ret) {\n\t\t\tdevm_kfree(dev, host);\n\t\t\tcontinue;\n\t\t}\n\n\t\tlist_add_tail(&host->node, &nandc->host_list);\n\t}\n\n\treturn ret;\n}\n\n \nstatic int qcom_nandc_parse_dt(struct platform_device *pdev)\n{\n\tstruct qcom_nand_controller *nandc = platform_get_drvdata(pdev);\n\tstruct device_node *np = nandc->dev->of_node;\n\tint ret;\n\n\tif (!nandc->props->is_bam) {\n\t\tret = of_property_read_u32(np, \"qcom,cmd-crci\",\n\t\t\t\t\t   &nandc->cmd_crci);\n\t\tif (ret) {\n\t\t\tdev_err(nandc->dev, \"command CRCI unspecified\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = of_property_read_u32(np, \"qcom,data-crci\",\n\t\t\t\t\t   &nandc->data_crci);\n\t\tif (ret) {\n\t\t\tdev_err(nandc->dev, \"data CRCI unspecified\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int qcom_nandc_probe(struct platform_device *pdev)\n{\n\tstruct qcom_nand_controller *nandc;\n\tconst void *dev_data;\n\tstruct device *dev = &pdev->dev;\n\tstruct resource *res;\n\tint ret;\n\n\tnandc = devm_kzalloc(&pdev->dev, sizeof(*nandc), GFP_KERNEL);\n\tif (!nandc)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, nandc);\n\tnandc->dev = dev;\n\n\tdev_data = of_device_get_match_data(dev);\n\tif (!dev_data) {\n\t\tdev_err(&pdev->dev, \"failed to get device data\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tnandc->props = dev_data;\n\n\tnandc->core_clk = devm_clk_get(dev, \"core\");\n\tif (IS_ERR(nandc->core_clk))\n\t\treturn PTR_ERR(nandc->core_clk);\n\n\tnandc->aon_clk = devm_clk_get(dev, \"aon\");\n\tif (IS_ERR(nandc->aon_clk))\n\t\treturn PTR_ERR(nandc->aon_clk);\n\n\tret = qcom_nandc_parse_dt(pdev);\n\tif (ret)\n\t\treturn ret;\n\n\tnandc->base = devm_platform_get_and_ioremap_resource(pdev, 0, &res);\n\tif (IS_ERR(nandc->base))\n\t\treturn PTR_ERR(nandc->base);\n\n\tnandc->base_phys = res->start;\n\tnandc->base_dma = dma_map_resource(dev, res->start,\n\t\t\t\t\t   resource_size(res),\n\t\t\t\t\t   DMA_BIDIRECTIONAL, 0);\n\tif (dma_mapping_error(dev, nandc->base_dma))\n\t\treturn -ENXIO;\n\n\tret = clk_prepare_enable(nandc->core_clk);\n\tif (ret)\n\t\tgoto err_core_clk;\n\n\tret = clk_prepare_enable(nandc->aon_clk);\n\tif (ret)\n\t\tgoto err_aon_clk;\n\n\tret = qcom_nandc_alloc(nandc);\n\tif (ret)\n\t\tgoto err_nandc_alloc;\n\n\tret = qcom_nandc_setup(nandc);\n\tif (ret)\n\t\tgoto err_setup;\n\n\tret = qcom_probe_nand_devices(nandc);\n\tif (ret)\n\t\tgoto err_setup;\n\n\treturn 0;\n\nerr_setup:\n\tqcom_nandc_unalloc(nandc);\nerr_nandc_alloc:\n\tclk_disable_unprepare(nandc->aon_clk);\nerr_aon_clk:\n\tclk_disable_unprepare(nandc->core_clk);\nerr_core_clk:\n\tdma_unmap_resource(dev, nandc->base_dma, resource_size(res),\n\t\t\t   DMA_BIDIRECTIONAL, 0);\n\treturn ret;\n}\n\nstatic void qcom_nandc_remove(struct platform_device *pdev)\n{\n\tstruct qcom_nand_controller *nandc = platform_get_drvdata(pdev);\n\tstruct resource *res = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tstruct qcom_nand_host *host;\n\tstruct nand_chip *chip;\n\tint ret;\n\n\tlist_for_each_entry(host, &nandc->host_list, node) {\n\t\tchip = &host->chip;\n\t\tret = mtd_device_unregister(nand_to_mtd(chip));\n\t\tWARN_ON(ret);\n\t\tnand_cleanup(chip);\n\t}\n\n\tqcom_nandc_unalloc(nandc);\n\n\tclk_disable_unprepare(nandc->aon_clk);\n\tclk_disable_unprepare(nandc->core_clk);\n\n\tdma_unmap_resource(&pdev->dev, nandc->base_dma, resource_size(res),\n\t\t\t   DMA_BIDIRECTIONAL, 0);\n}\n\nstatic const struct qcom_nandc_props ipq806x_nandc_props = {\n\t.ecc_modes = (ECC_RS_4BIT | ECC_BCH_8BIT),\n\t.is_bam = false,\n\t.use_codeword_fixup = true,\n\t.dev_cmd_reg_start = 0x0,\n};\n\nstatic const struct qcom_nandc_props ipq4019_nandc_props = {\n\t.ecc_modes = (ECC_BCH_4BIT | ECC_BCH_8BIT),\n\t.is_bam = true,\n\t.is_qpic = true,\n\t.dev_cmd_reg_start = 0x0,\n};\n\nstatic const struct qcom_nandc_props ipq8074_nandc_props = {\n\t.ecc_modes = (ECC_BCH_4BIT | ECC_BCH_8BIT),\n\t.is_bam = true,\n\t.is_qpic = true,\n\t.dev_cmd_reg_start = 0x7000,\n};\n\nstatic const struct qcom_nandc_props sdx55_nandc_props = {\n\t.ecc_modes = (ECC_BCH_4BIT | ECC_BCH_8BIT),\n\t.is_bam = true,\n\t.is_qpic = true,\n\t.qpic_v2 = true,\n\t.dev_cmd_reg_start = 0x7000,\n};\n\n \nstatic const struct of_device_id qcom_nandc_of_match[] = {\n\t{\n\t\t.compatible = \"qcom,ipq806x-nand\",\n\t\t.data = &ipq806x_nandc_props,\n\t},\n\t{\n\t\t.compatible = \"qcom,ipq4019-nand\",\n\t\t.data = &ipq4019_nandc_props,\n\t},\n\t{\n\t\t.compatible = \"qcom,ipq6018-nand\",\n\t\t.data = &ipq8074_nandc_props,\n\t},\n\t{\n\t\t.compatible = \"qcom,ipq8074-nand\",\n\t\t.data = &ipq8074_nandc_props,\n\t},\n\t{\n\t\t.compatible = \"qcom,sdx55-nand\",\n\t\t.data = &sdx55_nandc_props,\n\t},\n\t{}\n};\nMODULE_DEVICE_TABLE(of, qcom_nandc_of_match);\n\nstatic struct platform_driver qcom_nandc_driver = {\n\t.driver = {\n\t\t.name = \"qcom-nandc\",\n\t\t.of_match_table = qcom_nandc_of_match,\n\t},\n\t.probe   = qcom_nandc_probe,\n\t.remove_new = qcom_nandc_remove,\n};\nmodule_platform_driver(qcom_nandc_driver);\n\nMODULE_AUTHOR(\"Archit Taneja <architt@codeaurora.org>\");\nMODULE_DESCRIPTION(\"Qualcomm NAND Controller driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}