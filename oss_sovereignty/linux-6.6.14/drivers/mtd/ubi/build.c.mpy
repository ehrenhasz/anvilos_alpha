{
  "module_name": "build.c",
  "hash_id": "a72abc5356d53efd01ea1774304713772d2a40e0ad21275a0c1f35f77424687a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/mtd/ubi/build.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/stringify.h>\n#include <linux/namei.h>\n#include <linux/stat.h>\n#include <linux/miscdevice.h>\n#include <linux/mtd/partitions.h>\n#include <linux/log2.h>\n#include <linux/kthread.h>\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/major.h>\n#include \"ubi.h\"\n\n \n#define MTD_PARAM_LEN_MAX 64\n\n \n#define MTD_PARAM_MAX_COUNT 5\n\n \n#define MAX_MTD_UBI_BEB_LIMIT 768\n\n#ifdef CONFIG_MTD_UBI_MODULE\n#define ubi_is_module() 1\n#else\n#define ubi_is_module() 0\n#endif\n\n \nstruct mtd_dev_param {\n\tchar name[MTD_PARAM_LEN_MAX];\n\tint ubi_num;\n\tint vid_hdr_offs;\n\tint max_beb_per1024;\n\tint enable_fm;\n};\n\n \nstatic int mtd_devs;\n\n \nstatic struct mtd_dev_param mtd_dev_param[UBI_MAX_DEVICES];\n#ifdef CONFIG_MTD_UBI_FASTMAP\n \nstatic bool fm_autoconvert;\nstatic bool fm_debug;\n#endif\n\n \nstruct kmem_cache *ubi_wl_entry_slab;\n\n \nstatic struct miscdevice ubi_ctrl_cdev = {\n\t.minor = MISC_DYNAMIC_MINOR,\n\t.name = \"ubi_ctrl\",\n\t.fops = &ubi_ctrl_cdev_operations,\n};\n\n \nstatic struct ubi_device *ubi_devices[UBI_MAX_DEVICES];\n\n \nDEFINE_MUTEX(ubi_devices_mutex);\n\n \nstatic DEFINE_SPINLOCK(ubi_devices_lock);\n\n \n \nstatic ssize_t version_show(const struct class *class, const struct class_attribute *attr,\n\t\t\t    char *buf)\n{\n\treturn sprintf(buf, \"%d\\n\", UBI_VERSION);\n}\nstatic CLASS_ATTR_RO(version);\n\nstatic struct attribute *ubi_class_attrs[] = {\n\t&class_attr_version.attr,\n\tNULL,\n};\nATTRIBUTE_GROUPS(ubi_class);\n\n \nstruct class ubi_class = {\n\t.name\t\t= UBI_NAME_STR,\n\t.class_groups\t= ubi_class_groups,\n};\n\nstatic ssize_t dev_attribute_show(struct device *dev,\n\t\t\t\t  struct device_attribute *attr, char *buf);\n\n \nstatic struct device_attribute dev_eraseblock_size =\n\t__ATTR(eraseblock_size, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_avail_eraseblocks =\n\t__ATTR(avail_eraseblocks, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_total_eraseblocks =\n\t__ATTR(total_eraseblocks, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_volumes_count =\n\t__ATTR(volumes_count, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_max_ec =\n\t__ATTR(max_ec, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_reserved_for_bad =\n\t__ATTR(reserved_for_bad, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_bad_peb_count =\n\t__ATTR(bad_peb_count, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_max_vol_count =\n\t__ATTR(max_vol_count, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_min_io_size =\n\t__ATTR(min_io_size, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_bgt_enabled =\n\t__ATTR(bgt_enabled, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_mtd_num =\n\t__ATTR(mtd_num, S_IRUGO, dev_attribute_show, NULL);\nstatic struct device_attribute dev_ro_mode =\n\t__ATTR(ro_mode, S_IRUGO, dev_attribute_show, NULL);\n\n \nint ubi_volume_notify(struct ubi_device *ubi, struct ubi_volume *vol, int ntype)\n{\n\tint ret;\n\tstruct ubi_notification nt;\n\n\tubi_do_get_device_info(ubi, &nt.di);\n\tubi_do_get_volume_info(ubi, vol, &nt.vi);\n\n\tswitch (ntype) {\n\tcase UBI_VOLUME_ADDED:\n\tcase UBI_VOLUME_REMOVED:\n\tcase UBI_VOLUME_RESIZED:\n\tcase UBI_VOLUME_RENAMED:\n\t\tret = ubi_update_fastmap(ubi);\n\t\tif (ret)\n\t\t\tubi_msg(ubi, \"Unable to write a new fastmap: %i\", ret);\n\t}\n\n\treturn blocking_notifier_call_chain(&ubi_notifiers, ntype, &nt);\n}\n\n \nint ubi_notify_all(struct ubi_device *ubi, int ntype, struct notifier_block *nb)\n{\n\tstruct ubi_notification nt;\n\tint i, count = 0;\n\n\tubi_do_get_device_info(ubi, &nt.di);\n\n\tmutex_lock(&ubi->device_mutex);\n\tfor (i = 0; i < ubi->vtbl_slots; i++) {\n\t\t \n\t\tif (!ubi->volumes[i])\n\t\t\tcontinue;\n\n\t\tubi_do_get_volume_info(ubi, ubi->volumes[i], &nt.vi);\n\t\tif (nb)\n\t\t\tnb->notifier_call(nb, ntype, &nt);\n\t\telse\n\t\t\tblocking_notifier_call_chain(&ubi_notifiers, ntype,\n\t\t\t\t\t\t     &nt);\n\t\tcount += 1;\n\t}\n\tmutex_unlock(&ubi->device_mutex);\n\n\treturn count;\n}\n\n \nint ubi_enumerate_volumes(struct notifier_block *nb)\n{\n\tint i, count = 0;\n\n\t \n\tfor (i = 0; i < UBI_MAX_DEVICES; i++) {\n\t\tstruct ubi_device *ubi = ubi_devices[i];\n\n\t\tif (!ubi)\n\t\t\tcontinue;\n\t\tcount += ubi_notify_all(ubi, UBI_VOLUME_ADDED, nb);\n\t}\n\n\treturn count;\n}\n\n \nstruct ubi_device *ubi_get_device(int ubi_num)\n{\n\tstruct ubi_device *ubi;\n\n\tspin_lock(&ubi_devices_lock);\n\tubi = ubi_devices[ubi_num];\n\tif (ubi) {\n\t\tubi_assert(ubi->ref_count >= 0);\n\t\tubi->ref_count += 1;\n\t\tget_device(&ubi->dev);\n\t}\n\tspin_unlock(&ubi_devices_lock);\n\n\treturn ubi;\n}\n\n \nvoid ubi_put_device(struct ubi_device *ubi)\n{\n\tspin_lock(&ubi_devices_lock);\n\tubi->ref_count -= 1;\n\tput_device(&ubi->dev);\n\tspin_unlock(&ubi_devices_lock);\n}\n\n \nstruct ubi_device *ubi_get_by_major(int major)\n{\n\tint i;\n\tstruct ubi_device *ubi;\n\n\tspin_lock(&ubi_devices_lock);\n\tfor (i = 0; i < UBI_MAX_DEVICES; i++) {\n\t\tubi = ubi_devices[i];\n\t\tif (ubi && MAJOR(ubi->cdev.dev) == major) {\n\t\t\tubi_assert(ubi->ref_count >= 0);\n\t\t\tubi->ref_count += 1;\n\t\t\tget_device(&ubi->dev);\n\t\t\tspin_unlock(&ubi_devices_lock);\n\t\t\treturn ubi;\n\t\t}\n\t}\n\tspin_unlock(&ubi_devices_lock);\n\n\treturn NULL;\n}\n\n \nint ubi_major2num(int major)\n{\n\tint i, ubi_num = -ENODEV;\n\n\tspin_lock(&ubi_devices_lock);\n\tfor (i = 0; i < UBI_MAX_DEVICES; i++) {\n\t\tstruct ubi_device *ubi = ubi_devices[i];\n\n\t\tif (ubi && MAJOR(ubi->cdev.dev) == major) {\n\t\t\tubi_num = ubi->ubi_num;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&ubi_devices_lock);\n\n\treturn ubi_num;\n}\n\n \nstatic ssize_t dev_attribute_show(struct device *dev,\n\t\t\t\t  struct device_attribute *attr, char *buf)\n{\n\tssize_t ret;\n\tstruct ubi_device *ubi;\n\n\t \n\tubi = container_of(dev, struct ubi_device, dev);\n\n\tif (attr == &dev_eraseblock_size)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->leb_size);\n\telse if (attr == &dev_avail_eraseblocks)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->avail_pebs);\n\telse if (attr == &dev_total_eraseblocks)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->good_peb_count);\n\telse if (attr == &dev_volumes_count)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->vol_count - UBI_INT_VOL_COUNT);\n\telse if (attr == &dev_max_ec)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->max_ec);\n\telse if (attr == &dev_reserved_for_bad)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->beb_rsvd_pebs);\n\telse if (attr == &dev_bad_peb_count)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->bad_peb_count);\n\telse if (attr == &dev_max_vol_count)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->vtbl_slots);\n\telse if (attr == &dev_min_io_size)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->min_io_size);\n\telse if (attr == &dev_bgt_enabled)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->thread_enabled);\n\telse if (attr == &dev_mtd_num)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->mtd->index);\n\telse if (attr == &dev_ro_mode)\n\t\tret = sprintf(buf, \"%d\\n\", ubi->ro_mode);\n\telse\n\t\tret = -EINVAL;\n\n\treturn ret;\n}\n\nstatic struct attribute *ubi_dev_attrs[] = {\n\t&dev_eraseblock_size.attr,\n\t&dev_avail_eraseblocks.attr,\n\t&dev_total_eraseblocks.attr,\n\t&dev_volumes_count.attr,\n\t&dev_max_ec.attr,\n\t&dev_reserved_for_bad.attr,\n\t&dev_bad_peb_count.attr,\n\t&dev_max_vol_count.attr,\n\t&dev_min_io_size.attr,\n\t&dev_bgt_enabled.attr,\n\t&dev_mtd_num.attr,\n\t&dev_ro_mode.attr,\n\tNULL\n};\nATTRIBUTE_GROUPS(ubi_dev);\n\nstatic void dev_release(struct device *dev)\n{\n\tstruct ubi_device *ubi = container_of(dev, struct ubi_device, dev);\n\n\tkfree(ubi);\n}\n\n \nstatic void kill_volumes(struct ubi_device *ubi)\n{\n\tint i;\n\n\tfor (i = 0; i < ubi->vtbl_slots; i++)\n\t\tif (ubi->volumes[i])\n\t\t\tubi_free_volume(ubi, ubi->volumes[i]);\n}\n\n \nstatic int uif_init(struct ubi_device *ubi)\n{\n\tint i, err;\n\tdev_t dev;\n\n\tsprintf(ubi->ubi_name, UBI_NAME_STR \"%d\", ubi->ubi_num);\n\n\t \n\terr = alloc_chrdev_region(&dev, 0, ubi->vtbl_slots + 1, ubi->ubi_name);\n\tif (err) {\n\t\tubi_err(ubi, \"cannot register UBI character devices\");\n\t\treturn err;\n\t}\n\n\tubi->dev.devt = dev;\n\n\tubi_assert(MINOR(dev) == 0);\n\tcdev_init(&ubi->cdev, &ubi_cdev_operations);\n\tdbg_gen(\"%s major is %u\", ubi->ubi_name, MAJOR(dev));\n\tubi->cdev.owner = THIS_MODULE;\n\n\tdev_set_name(&ubi->dev, UBI_NAME_STR \"%d\", ubi->ubi_num);\n\terr = cdev_device_add(&ubi->cdev, &ubi->dev);\n\tif (err)\n\t\tgoto out_unreg;\n\n\tfor (i = 0; i < ubi->vtbl_slots; i++)\n\t\tif (ubi->volumes[i]) {\n\t\t\terr = ubi_add_volume(ubi, ubi->volumes[i]);\n\t\t\tif (err) {\n\t\t\t\tubi_err(ubi, \"cannot add volume %d\", i);\n\t\t\t\tubi->volumes[i] = NULL;\n\t\t\t\tgoto out_volumes;\n\t\t\t}\n\t\t}\n\n\treturn 0;\n\nout_volumes:\n\tkill_volumes(ubi);\n\tcdev_device_del(&ubi->cdev, &ubi->dev);\nout_unreg:\n\tunregister_chrdev_region(ubi->cdev.dev, ubi->vtbl_slots + 1);\n\tubi_err(ubi, \"cannot initialize UBI %s, error %d\",\n\t\tubi->ubi_name, err);\n\treturn err;\n}\n\n \nstatic void uif_close(struct ubi_device *ubi)\n{\n\tkill_volumes(ubi);\n\tcdev_device_del(&ubi->cdev, &ubi->dev);\n\tunregister_chrdev_region(ubi->cdev.dev, ubi->vtbl_slots + 1);\n}\n\n \nstatic void ubi_free_volumes_from(struct ubi_device *ubi, int from)\n{\n\tint i;\n\n\tfor (i = from; i < ubi->vtbl_slots + UBI_INT_VOL_COUNT; i++) {\n\t\tif (!ubi->volumes[i])\n\t\t\tcontinue;\n\t\tubi_eba_replace_table(ubi->volumes[i], NULL);\n\t\tubi_fastmap_destroy_checkmap(ubi->volumes[i]);\n\t\tkfree(ubi->volumes[i]);\n\t\tubi->volumes[i] = NULL;\n\t}\n}\n\n \nvoid ubi_free_all_volumes(struct ubi_device *ubi)\n{\n\tubi_free_volumes_from(ubi, 0);\n}\n\n \nvoid ubi_free_internal_volumes(struct ubi_device *ubi)\n{\n\tubi_free_volumes_from(ubi, ubi->vtbl_slots);\n}\n\nstatic int get_bad_peb_limit(const struct ubi_device *ubi, int max_beb_per1024)\n{\n\tint limit, device_pebs;\n\tuint64_t device_size;\n\n\tif (!max_beb_per1024) {\n\t\t \n\t\tlimit = mtd_max_bad_blocks(ubi->mtd, 0, ubi->mtd->size);\n\t\tif (limit < 0)\n\t\t\treturn 0;\n\t\treturn limit;\n\t}\n\n\t \n\tdevice_size = mtd_get_device_size(ubi->mtd);\n\tdevice_pebs = mtd_div_by_eb(device_size, ubi->mtd);\n\tlimit = mult_frac(device_pebs, max_beb_per1024, 1024);\n\n\t \n\tif (mult_frac(limit, 1024, max_beb_per1024) < device_pebs)\n\t\tlimit += 1;\n\n\treturn limit;\n}\n\n \nstatic int io_init(struct ubi_device *ubi, int max_beb_per1024)\n{\n\tdbg_gen(\"sizeof(struct ubi_ainf_peb) %zu\", sizeof(struct ubi_ainf_peb));\n\tdbg_gen(\"sizeof(struct ubi_wl_entry) %zu\", sizeof(struct ubi_wl_entry));\n\n\tif (ubi->mtd->numeraseregions != 0) {\n\t\t \n\t\tubi_err(ubi, \"multiple regions, not implemented\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (ubi->vid_hdr_offset < 0)\n\t\treturn -EINVAL;\n\n\t \n\n\tubi->peb_size   = ubi->mtd->erasesize;\n\tubi->peb_count  = mtd_div_by_eb(ubi->mtd->size, ubi->mtd);\n\tubi->flash_size = ubi->mtd->size;\n\n\tif (mtd_can_have_bb(ubi->mtd)) {\n\t\tubi->bad_allowed = 1;\n\t\tubi->bad_peb_limit = get_bad_peb_limit(ubi, max_beb_per1024);\n\t}\n\n\tif (ubi->mtd->type == MTD_NORFLASH)\n\t\tubi->nor_flash = 1;\n\n\tubi->min_io_size = ubi->mtd->writesize;\n\tubi->hdrs_min_io_size = ubi->mtd->writesize >> ubi->mtd->subpage_sft;\n\n\t \n\tif (!is_power_of_2(ubi->min_io_size)) {\n\t\tubi_err(ubi, \"min. I/O unit (%d) is not power of 2\",\n\t\t\tubi->min_io_size);\n\t\treturn -EINVAL;\n\t}\n\n\tubi_assert(ubi->hdrs_min_io_size > 0);\n\tubi_assert(ubi->hdrs_min_io_size <= ubi->min_io_size);\n\tubi_assert(ubi->min_io_size % ubi->hdrs_min_io_size == 0);\n\n\tubi->max_write_size = ubi->mtd->writebufsize;\n\t \n\tif (ubi->max_write_size < ubi->min_io_size ||\n\t    ubi->max_write_size % ubi->min_io_size ||\n\t    !is_power_of_2(ubi->max_write_size)) {\n\t\tubi_err(ubi, \"bad write buffer size %d for %d min. I/O unit\",\n\t\t\tubi->max_write_size, ubi->min_io_size);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tubi->ec_hdr_alsize = ALIGN(UBI_EC_HDR_SIZE, ubi->hdrs_min_io_size);\n\tubi->vid_hdr_alsize = ALIGN(UBI_VID_HDR_SIZE, ubi->hdrs_min_io_size);\n\n\tdbg_gen(\"min_io_size      %d\", ubi->min_io_size);\n\tdbg_gen(\"max_write_size   %d\", ubi->max_write_size);\n\tdbg_gen(\"hdrs_min_io_size %d\", ubi->hdrs_min_io_size);\n\tdbg_gen(\"ec_hdr_alsize    %d\", ubi->ec_hdr_alsize);\n\tdbg_gen(\"vid_hdr_alsize   %d\", ubi->vid_hdr_alsize);\n\n\tif (ubi->vid_hdr_offset == 0)\n\t\t \n\t\tubi->vid_hdr_offset = ubi->vid_hdr_aloffset =\n\t\t\t\t      ubi->ec_hdr_alsize;\n\telse {\n\t\tubi->vid_hdr_aloffset = ubi->vid_hdr_offset &\n\t\t\t\t\t\t~(ubi->hdrs_min_io_size - 1);\n\t\tubi->vid_hdr_shift = ubi->vid_hdr_offset -\n\t\t\t\t\t\tubi->vid_hdr_aloffset;\n\t}\n\n\t \n\tif ((ubi->vid_hdr_shift + UBI_VID_HDR_SIZE) > ubi->vid_hdr_alsize) {\n\t\tubi_err(ubi, \"Invalid VID header offset %d, VID header shift(%d)\"\n\t\t\t\" + VID header size(%zu) > VID header aligned size(%d).\",\n\t\t\tubi->vid_hdr_offset, ubi->vid_hdr_shift,\n\t\t\tUBI_VID_HDR_SIZE, ubi->vid_hdr_alsize);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tubi->leb_start = ubi->vid_hdr_offset + UBI_VID_HDR_SIZE;\n\tubi->leb_start = ALIGN(ubi->leb_start, ubi->min_io_size);\n\n\tdbg_gen(\"vid_hdr_offset   %d\", ubi->vid_hdr_offset);\n\tdbg_gen(\"vid_hdr_aloffset %d\", ubi->vid_hdr_aloffset);\n\tdbg_gen(\"vid_hdr_shift    %d\", ubi->vid_hdr_shift);\n\tdbg_gen(\"leb_start        %d\", ubi->leb_start);\n\n\t \n\tif (ubi->vid_hdr_shift % 4) {\n\t\tubi_err(ubi, \"unaligned VID header shift %d\",\n\t\t\tubi->vid_hdr_shift);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (ubi->vid_hdr_offset < UBI_EC_HDR_SIZE ||\n\t    ubi->leb_start < ubi->vid_hdr_offset + UBI_VID_HDR_SIZE ||\n\t    ubi->leb_start > ubi->peb_size - UBI_VID_HDR_SIZE ||\n\t    ubi->leb_start & (ubi->min_io_size - 1)) {\n\t\tubi_err(ubi, \"bad VID header (%d) or data offsets (%d)\",\n\t\t\tubi->vid_hdr_offset, ubi->leb_start);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tubi->max_erroneous = ubi->peb_count / 10;\n\tif (ubi->max_erroneous < 16)\n\t\tubi->max_erroneous = 16;\n\tdbg_gen(\"max_erroneous    %d\", ubi->max_erroneous);\n\n\t \n\tif (ubi->vid_hdr_offset + UBI_VID_HDR_SIZE <= ubi->hdrs_min_io_size) {\n\t\tubi_warn(ubi, \"EC and VID headers are in the same minimal I/O unit, switch to read-only mode\");\n\t\tubi->ro_mode = 1;\n\t}\n\n\tubi->leb_size = ubi->peb_size - ubi->leb_start;\n\n\tif (!(ubi->mtd->flags & MTD_WRITEABLE)) {\n\t\tubi_msg(ubi, \"MTD device %d is write-protected, attach in read-only mode\",\n\t\t\tubi->mtd->index);\n\t\tubi->ro_mode = 1;\n\t}\n\n\t \n\n\treturn 0;\n}\n\n \nstatic int autoresize(struct ubi_device *ubi, int vol_id)\n{\n\tstruct ubi_volume_desc desc;\n\tstruct ubi_volume *vol = ubi->volumes[vol_id];\n\tint err, old_reserved_pebs = vol->reserved_pebs;\n\n\tif (ubi->ro_mode) {\n\t\tubi_warn(ubi, \"skip auto-resize because of R/O mode\");\n\t\treturn 0;\n\t}\n\n\t \n\tubi->vtbl[vol_id].flags &= ~UBI_VTBL_AUTORESIZE_FLG;\n\n\tif (ubi->avail_pebs == 0) {\n\t\tstruct ubi_vtbl_record vtbl_rec;\n\n\t\t \n\t\tvtbl_rec = ubi->vtbl[vol_id];\n\t\terr = ubi_change_vtbl_record(ubi, vol_id, &vtbl_rec);\n\t\tif (err)\n\t\t\tubi_err(ubi, \"cannot clean auto-resize flag for volume %d\",\n\t\t\t\tvol_id);\n\t} else {\n\t\tdesc.vol = vol;\n\t\terr = ubi_resize_volume(&desc,\n\t\t\t\t\told_reserved_pebs + ubi->avail_pebs);\n\t\tif (err)\n\t\t\tubi_err(ubi, \"cannot auto-resize volume %d\",\n\t\t\t\tvol_id);\n\t}\n\n\tif (err)\n\t\treturn err;\n\n\tubi_msg(ubi, \"volume %d (\\\"%s\\\") re-sized from %d to %d LEBs\",\n\t\tvol_id, vol->name, old_reserved_pebs, vol->reserved_pebs);\n\treturn 0;\n}\n\n \nint ubi_attach_mtd_dev(struct mtd_info *mtd, int ubi_num,\n\t\t       int vid_hdr_offset, int max_beb_per1024, bool disable_fm)\n{\n\tstruct ubi_device *ubi;\n\tint i, err;\n\n\tif (max_beb_per1024 < 0 || max_beb_per1024 > MAX_MTD_UBI_BEB_LIMIT)\n\t\treturn -EINVAL;\n\n\tif (!max_beb_per1024)\n\t\tmax_beb_per1024 = CONFIG_MTD_UBI_BEB_LIMIT;\n\n\t \n\tfor (i = 0; i < UBI_MAX_DEVICES; i++) {\n\t\tubi = ubi_devices[i];\n\t\tif (ubi && mtd->index == ubi->mtd->index) {\n\t\t\tpr_err(\"ubi: mtd%d is already attached to ubi%d\\n\",\n\t\t\t\tmtd->index, i);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\t \n\tif (mtd->type == MTD_UBIVOLUME) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - it is already emulated on top of UBI\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (mtd->type == MTD_MLCNANDFLASH &&\n\t    !(mtd->flags & MTD_SLC_ON_MLC_EMULATION)) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - MLC NAND is not supported\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!mtd->erasesize) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - zero erasesize flash is not supported\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ubi_num == UBI_DEV_NUM_AUTO) {\n\t\t \n\t\tfor (ubi_num = 0; ubi_num < UBI_MAX_DEVICES; ubi_num++)\n\t\t\tif (!ubi_devices[ubi_num])\n\t\t\t\tbreak;\n\t\tif (ubi_num == UBI_MAX_DEVICES) {\n\t\t\tpr_err(\"ubi: only %d UBI devices may be created\\n\",\n\t\t\t\tUBI_MAX_DEVICES);\n\t\t\treturn -ENFILE;\n\t\t}\n\t} else {\n\t\tif (ubi_num >= UBI_MAX_DEVICES)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (ubi_devices[ubi_num]) {\n\t\t\tpr_err(\"ubi: ubi%i already exists\\n\", ubi_num);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tubi = kzalloc(sizeof(struct ubi_device), GFP_KERNEL);\n\tif (!ubi)\n\t\treturn -ENOMEM;\n\n\tdevice_initialize(&ubi->dev);\n\tubi->dev.release = dev_release;\n\tubi->dev.class = &ubi_class;\n\tubi->dev.groups = ubi_dev_groups;\n\tubi->dev.parent = &mtd->dev;\n\n\tubi->mtd = mtd;\n\tubi->ubi_num = ubi_num;\n\tubi->vid_hdr_offset = vid_hdr_offset;\n\tubi->autoresize_vol_id = -1;\n\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\tubi->fm_pool.used = ubi->fm_pool.size = 0;\n\tubi->fm_wl_pool.used = ubi->fm_wl_pool.size = 0;\n\n\t \n\tubi->fm_pool.max_size = min(((int)mtd_div_by_eb(ubi->mtd->size,\n\t\tubi->mtd) / 100) * 5, UBI_FM_MAX_POOL_SIZE);\n\tubi->fm_pool.max_size = max(ubi->fm_pool.max_size,\n\t\tUBI_FM_MIN_POOL_SIZE);\n\n\tubi->fm_wl_pool.max_size = ubi->fm_pool.max_size / 2;\n\tubi->fm_disabled = (!fm_autoconvert || disable_fm) ? 1 : 0;\n\tif (fm_debug)\n\t\tubi_enable_dbg_chk_fastmap(ubi);\n\n\tif (!ubi->fm_disabled && (int)mtd_div_by_eb(ubi->mtd->size, ubi->mtd)\n\t    <= UBI_FM_MAX_START) {\n\t\tubi_err(ubi, \"More than %i PEBs are needed for fastmap, sorry.\",\n\t\t\tUBI_FM_MAX_START);\n\t\tubi->fm_disabled = 1;\n\t}\n\n\tubi_msg(ubi, \"default fastmap pool size: %d\", ubi->fm_pool.max_size);\n\tubi_msg(ubi, \"default fastmap WL pool size: %d\",\n\t\tubi->fm_wl_pool.max_size);\n#else\n\tubi->fm_disabled = 1;\n#endif\n\tmutex_init(&ubi->buf_mutex);\n\tmutex_init(&ubi->ckvol_mutex);\n\tmutex_init(&ubi->device_mutex);\n\tspin_lock_init(&ubi->volumes_lock);\n\tinit_rwsem(&ubi->fm_protect);\n\tinit_rwsem(&ubi->fm_eba_sem);\n\n\tubi_msg(ubi, \"attaching mtd%d\", mtd->index);\n\n\terr = io_init(ubi, max_beb_per1024);\n\tif (err)\n\t\tgoto out_free;\n\n\terr = -ENOMEM;\n\tubi->peb_buf = vmalloc(ubi->peb_size);\n\tif (!ubi->peb_buf)\n\t\tgoto out_free;\n\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\tubi->fm_size = ubi_calc_fm_size(ubi);\n\tubi->fm_buf = vzalloc(ubi->fm_size);\n\tif (!ubi->fm_buf)\n\t\tgoto out_free;\n#endif\n\terr = ubi_attach(ubi, disable_fm ? 1 : 0);\n\tif (err) {\n\t\tubi_err(ubi, \"failed to attach mtd%d, error %d\",\n\t\t\tmtd->index, err);\n\t\tgoto out_free;\n\t}\n\n\tif (ubi->autoresize_vol_id != -1) {\n\t\terr = autoresize(ubi, ubi->autoresize_vol_id);\n\t\tif (err)\n\t\t\tgoto out_detach;\n\t}\n\n\terr = uif_init(ubi);\n\tif (err)\n\t\tgoto out_detach;\n\n\terr = ubi_debugfs_init_dev(ubi);\n\tif (err)\n\t\tgoto out_uif;\n\n\tubi->bgt_thread = kthread_create(ubi_thread, ubi, \"%s\", ubi->bgt_name);\n\tif (IS_ERR(ubi->bgt_thread)) {\n\t\terr = PTR_ERR(ubi->bgt_thread);\n\t\tubi_err(ubi, \"cannot spawn \\\"%s\\\", error %d\",\n\t\t\tubi->bgt_name, err);\n\t\tgoto out_debugfs;\n\t}\n\n\tubi_msg(ubi, \"attached mtd%d (name \\\"%s\\\", size %llu MiB)\",\n\t\tmtd->index, mtd->name, ubi->flash_size >> 20);\n\tubi_msg(ubi, \"PEB size: %d bytes (%d KiB), LEB size: %d bytes\",\n\t\tubi->peb_size, ubi->peb_size >> 10, ubi->leb_size);\n\tubi_msg(ubi, \"min./max. I/O unit sizes: %d/%d, sub-page size %d\",\n\t\tubi->min_io_size, ubi->max_write_size, ubi->hdrs_min_io_size);\n\tubi_msg(ubi, \"VID header offset: %d (aligned %d), data offset: %d\",\n\t\tubi->vid_hdr_offset, ubi->vid_hdr_aloffset, ubi->leb_start);\n\tubi_msg(ubi, \"good PEBs: %d, bad PEBs: %d, corrupted PEBs: %d\",\n\t\tubi->good_peb_count, ubi->bad_peb_count, ubi->corr_peb_count);\n\tubi_msg(ubi, \"user volume: %d, internal volumes: %d, max. volumes count: %d\",\n\t\tubi->vol_count - UBI_INT_VOL_COUNT, UBI_INT_VOL_COUNT,\n\t\tubi->vtbl_slots);\n\tubi_msg(ubi, \"max/mean erase counter: %d/%d, WL threshold: %d, image sequence number: %u\",\n\t\tubi->max_ec, ubi->mean_ec, CONFIG_MTD_UBI_WL_THRESHOLD,\n\t\tubi->image_seq);\n\tubi_msg(ubi, \"available PEBs: %d, total reserved PEBs: %d, PEBs reserved for bad PEB handling: %d\",\n\t\tubi->avail_pebs, ubi->rsvd_pebs, ubi->beb_rsvd_pebs);\n\n\t \n\tspin_lock(&ubi->wl_lock);\n\tubi->thread_enabled = 1;\n\twake_up_process(ubi->bgt_thread);\n\tspin_unlock(&ubi->wl_lock);\n\n\tubi_devices[ubi_num] = ubi;\n\tubi_notify_all(ubi, UBI_VOLUME_ADDED, NULL);\n\treturn ubi_num;\n\nout_debugfs:\n\tubi_debugfs_exit_dev(ubi);\nout_uif:\n\tuif_close(ubi);\nout_detach:\n\tubi_wl_close(ubi);\n\tubi_free_all_volumes(ubi);\n\tvfree(ubi->vtbl);\nout_free:\n\tvfree(ubi->peb_buf);\n\tvfree(ubi->fm_buf);\n\tput_device(&ubi->dev);\n\treturn err;\n}\n\n \nint ubi_detach_mtd_dev(int ubi_num, int anyway)\n{\n\tstruct ubi_device *ubi;\n\n\tif (ubi_num < 0 || ubi_num >= UBI_MAX_DEVICES)\n\t\treturn -EINVAL;\n\n\tubi = ubi_get_device(ubi_num);\n\tif (!ubi)\n\t\treturn -EINVAL;\n\n\tspin_lock(&ubi_devices_lock);\n\tput_device(&ubi->dev);\n\tubi->ref_count -= 1;\n\tif (ubi->ref_count) {\n\t\tif (!anyway) {\n\t\t\tspin_unlock(&ubi_devices_lock);\n\t\t\treturn -EBUSY;\n\t\t}\n\t\t \n\t\tubi_err(ubi, \"%s reference count %d, destroy anyway\",\n\t\t\tubi->ubi_name, ubi->ref_count);\n\t}\n\tubi_devices[ubi_num] = NULL;\n\tspin_unlock(&ubi_devices_lock);\n\n\tubi_assert(ubi_num == ubi->ubi_num);\n\tubi_notify_all(ubi, UBI_VOLUME_REMOVED, NULL);\n\tubi_msg(ubi, \"detaching mtd%d\", ubi->mtd->index);\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\t \n\tif (!ubi_dbg_chk_fastmap(ubi))\n\t\tubi_update_fastmap(ubi);\n#endif\n\t \n\tif (ubi->bgt_thread)\n\t\tkthread_stop(ubi->bgt_thread);\n\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\tcancel_work_sync(&ubi->fm_work);\n#endif\n\tubi_debugfs_exit_dev(ubi);\n\tuif_close(ubi);\n\n\tubi_wl_close(ubi);\n\tubi_free_internal_volumes(ubi);\n\tvfree(ubi->vtbl);\n\tvfree(ubi->peb_buf);\n\tvfree(ubi->fm_buf);\n\tubi_msg(ubi, \"mtd%d is detached\", ubi->mtd->index);\n\tput_mtd_device(ubi->mtd);\n\tput_device(&ubi->dev);\n\treturn 0;\n}\n\n \nstatic struct mtd_info * __init open_mtd_by_chdev(const char *mtd_dev)\n{\n\tint err, minor;\n\tstruct path path;\n\tstruct kstat stat;\n\n\t \n\terr = kern_path(mtd_dev, LOOKUP_FOLLOW, &path);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\terr = vfs_getattr(&path, &stat, STATX_TYPE, AT_STATX_SYNC_AS_STAT);\n\tpath_put(&path);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\t \n\tif (MAJOR(stat.rdev) != MTD_CHAR_MAJOR || !S_ISCHR(stat.mode))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tminor = MINOR(stat.rdev);\n\n\tif (minor & 1)\n\t\t \n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn get_mtd_device(NULL, minor / 2);\n}\n\n \nstatic struct mtd_info * __init open_mtd_device(const char *mtd_dev)\n{\n\tstruct mtd_info *mtd;\n\tint mtd_num;\n\tchar *endp;\n\n\tmtd_num = simple_strtoul(mtd_dev, &endp, 0);\n\tif (*endp != '\\0' || mtd_dev == endp) {\n\t\t \n\t\tmtd = get_mtd_device_nm(mtd_dev);\n\t\tif (PTR_ERR(mtd) == -ENODEV)\n\t\t\t \n\t\t\tmtd = open_mtd_by_chdev(mtd_dev);\n\t} else\n\t\tmtd = get_mtd_device(NULL, mtd_num);\n\n\treturn mtd;\n}\n\nstatic int __init ubi_init(void)\n{\n\tint err, i, k;\n\n\t \n\tBUILD_BUG_ON(sizeof(struct ubi_ec_hdr) != 64);\n\tBUILD_BUG_ON(sizeof(struct ubi_vid_hdr) != 64);\n\n\tif (mtd_devs > UBI_MAX_DEVICES) {\n\t\tpr_err(\"UBI error: too many MTD devices, maximum is %d\\n\",\n\t\t       UBI_MAX_DEVICES);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\terr = class_register(&ubi_class);\n\tif (err < 0)\n\t\treturn err;\n\n\terr = misc_register(&ubi_ctrl_cdev);\n\tif (err) {\n\t\tpr_err(\"UBI error: cannot register device\\n\");\n\t\tgoto out;\n\t}\n\n\tubi_wl_entry_slab = kmem_cache_create(\"ubi_wl_entry_slab\",\n\t\t\t\t\t      sizeof(struct ubi_wl_entry),\n\t\t\t\t\t      0, 0, NULL);\n\tif (!ubi_wl_entry_slab) {\n\t\terr = -ENOMEM;\n\t\tgoto out_dev_unreg;\n\t}\n\n\terr = ubi_debugfs_init();\n\tif (err)\n\t\tgoto out_slab;\n\n\n\t \n\tfor (i = 0; i < mtd_devs; i++) {\n\t\tstruct mtd_dev_param *p = &mtd_dev_param[i];\n\t\tstruct mtd_info *mtd;\n\n\t\tcond_resched();\n\n\t\tmtd = open_mtd_device(p->name);\n\t\tif (IS_ERR(mtd)) {\n\t\t\terr = PTR_ERR(mtd);\n\t\t\tpr_err(\"UBI error: cannot open mtd %s, error %d\\n\",\n\t\t\t       p->name, err);\n\t\t\t \n\t\t\tif (ubi_is_module())\n\t\t\t\tgoto out_detach;\n\t\t\tcontinue;\n\t\t}\n\n\t\tmutex_lock(&ubi_devices_mutex);\n\t\terr = ubi_attach_mtd_dev(mtd, p->ubi_num,\n\t\t\t\t\t p->vid_hdr_offs, p->max_beb_per1024,\n\t\t\t\t\t p->enable_fm == 0);\n\t\tmutex_unlock(&ubi_devices_mutex);\n\t\tif (err < 0) {\n\t\t\tpr_err(\"UBI error: cannot attach mtd%d\\n\",\n\t\t\t       mtd->index);\n\t\t\tput_mtd_device(mtd);\n\n\t\t\t \n\t\t\tif (ubi_is_module())\n\t\t\t\tgoto out_detach;\n\t\t}\n\t}\n\n\terr = ubiblock_init();\n\tif (err) {\n\t\tpr_err(\"UBI error: block: cannot initialize, error %d\\n\", err);\n\n\t\t \n\t\tif (ubi_is_module())\n\t\t\tgoto out_detach;\n\t}\n\n\treturn 0;\n\nout_detach:\n\tfor (k = 0; k < i; k++)\n\t\tif (ubi_devices[k]) {\n\t\t\tmutex_lock(&ubi_devices_mutex);\n\t\t\tubi_detach_mtd_dev(ubi_devices[k]->ubi_num, 1);\n\t\t\tmutex_unlock(&ubi_devices_mutex);\n\t\t}\n\tubi_debugfs_exit();\nout_slab:\n\tkmem_cache_destroy(ubi_wl_entry_slab);\nout_dev_unreg:\n\tmisc_deregister(&ubi_ctrl_cdev);\nout:\n\tclass_unregister(&ubi_class);\n\tpr_err(\"UBI error: cannot initialize UBI, error %d\\n\", err);\n\treturn err;\n}\nlate_initcall(ubi_init);\n\nstatic void __exit ubi_exit(void)\n{\n\tint i;\n\n\tubiblock_exit();\n\n\tfor (i = 0; i < UBI_MAX_DEVICES; i++)\n\t\tif (ubi_devices[i]) {\n\t\t\tmutex_lock(&ubi_devices_mutex);\n\t\t\tubi_detach_mtd_dev(ubi_devices[i]->ubi_num, 1);\n\t\t\tmutex_unlock(&ubi_devices_mutex);\n\t\t}\n\tubi_debugfs_exit();\n\tkmem_cache_destroy(ubi_wl_entry_slab);\n\tmisc_deregister(&ubi_ctrl_cdev);\n\tclass_unregister(&ubi_class);\n}\nmodule_exit(ubi_exit);\n\n \nstatic int bytes_str_to_int(const char *str)\n{\n\tchar *endp;\n\tunsigned long result;\n\n\tresult = simple_strtoul(str, &endp, 0);\n\tif (str == endp || result >= INT_MAX) {\n\t\tpr_err(\"UBI error: incorrect bytes count: \\\"%s\\\"\\n\", str);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (*endp) {\n\tcase 'G':\n\t\tresult *= 1024;\n\t\tfallthrough;\n\tcase 'M':\n\t\tresult *= 1024;\n\t\tfallthrough;\n\tcase 'K':\n\t\tresult *= 1024;\n\t\tbreak;\n\tcase '\\0':\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"UBI error: incorrect bytes count: \\\"%s\\\"\\n\", str);\n\t\treturn -EINVAL;\n\t}\n\n\treturn result;\n}\n\n \nstatic int ubi_mtd_param_parse(const char *val, const struct kernel_param *kp)\n{\n\tint i, len;\n\tstruct mtd_dev_param *p;\n\tchar buf[MTD_PARAM_LEN_MAX];\n\tchar *pbuf = &buf[0];\n\tchar *tokens[MTD_PARAM_MAX_COUNT], *token;\n\n\tif (!val)\n\t\treturn -EINVAL;\n\n\tif (mtd_devs == UBI_MAX_DEVICES) {\n\t\tpr_err(\"UBI error: too many parameters, max. is %d\\n\",\n\t\t       UBI_MAX_DEVICES);\n\t\treturn -EINVAL;\n\t}\n\n\tlen = strnlen(val, MTD_PARAM_LEN_MAX);\n\tif (len == MTD_PARAM_LEN_MAX) {\n\t\tpr_err(\"UBI error: parameter \\\"%s\\\" is too long, max. is %d\\n\",\n\t\t       val, MTD_PARAM_LEN_MAX);\n\t\treturn -EINVAL;\n\t}\n\n\tif (len == 0) {\n\t\tpr_warn(\"UBI warning: empty 'mtd=' parameter - ignored\\n\");\n\t\treturn 0;\n\t}\n\n\tstrcpy(buf, val);\n\n\t \n\tif (buf[len - 1] == '\\n')\n\t\tbuf[len - 1] = '\\0';\n\n\tfor (i = 0; i < MTD_PARAM_MAX_COUNT; i++)\n\t\ttokens[i] = strsep(&pbuf, \",\");\n\n\tif (pbuf) {\n\t\tpr_err(\"UBI error: too many arguments at \\\"%s\\\"\\n\", val);\n\t\treturn -EINVAL;\n\t}\n\n\tp = &mtd_dev_param[mtd_devs];\n\tstrcpy(&p->name[0], tokens[0]);\n\n\ttoken = tokens[1];\n\tif (token) {\n\t\tp->vid_hdr_offs = bytes_str_to_int(token);\n\n\t\tif (p->vid_hdr_offs < 0)\n\t\t\treturn p->vid_hdr_offs;\n\t}\n\n\ttoken = tokens[2];\n\tif (token) {\n\t\tint err = kstrtoint(token, 10, &p->max_beb_per1024);\n\n\t\tif (err) {\n\t\t\tpr_err(\"UBI error: bad value for max_beb_per1024 parameter: %s\\n\",\n\t\t\t       token);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\ttoken = tokens[3];\n\tif (token) {\n\t\tint err = kstrtoint(token, 10, &p->ubi_num);\n\n\t\tif (err) {\n\t\t\tpr_err(\"UBI error: bad value for ubi_num parameter: %s\\n\",\n\t\t\t       token);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else\n\t\tp->ubi_num = UBI_DEV_NUM_AUTO;\n\n\ttoken = tokens[4];\n\tif (token) {\n\t\tint err = kstrtoint(token, 10, &p->enable_fm);\n\n\t\tif (err) {\n\t\t\tpr_err(\"UBI error: bad value for enable_fm parameter: %s\\n\",\n\t\t\t\ttoken);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else\n\t\tp->enable_fm = 0;\n\n\tmtd_devs += 1;\n\treturn 0;\n}\n\nmodule_param_call(mtd, ubi_mtd_param_parse, NULL, NULL, 0400);\nMODULE_PARM_DESC(mtd, \"MTD devices to attach. Parameter format: mtd=<name|num|path>[,<vid_hdr_offs>[,max_beb_per1024[,ubi_num]]].\\n\"\n\t\t      \"Multiple \\\"mtd\\\" parameters may be specified.\\n\"\n\t\t      \"MTD devices may be specified by their number, name, or path to the MTD character device node.\\n\"\n\t\t      \"Optional \\\"vid_hdr_offs\\\" parameter specifies UBI VID header position to be used by UBI. (default value if 0)\\n\"\n\t\t      \"Optional \\\"max_beb_per1024\\\" parameter specifies the maximum expected bad eraseblock per 1024 eraseblocks. (default value (\"\n\t\t      __stringify(CONFIG_MTD_UBI_BEB_LIMIT) \") if 0)\\n\"\n\t\t      \"Optional \\\"ubi_num\\\" parameter specifies UBI device number which have to be assigned to the newly created UBI device (assigned automatically by default)\\n\"\n\t\t      \"Optional \\\"enable_fm\\\" parameter determines whether to enable fastmap during attach. If the value is non-zero, fastmap is enabled. Default value is 0.\\n\"\n\t\t      \"\\n\"\n\t\t      \"Example 1: mtd=/dev/mtd0 - attach MTD device /dev/mtd0.\\n\"\n\t\t      \"Example 2: mtd=content,1984 mtd=4 - attach MTD device with name \\\"content\\\" using VID header offset 1984, and MTD device number 4 with default VID header offset.\\n\"\n\t\t      \"Example 3: mtd=/dev/mtd1,0,25 - attach MTD device /dev/mtd1 using default VID header offset and reserve 25*nand_size_in_blocks/1024 erase blocks for bad block handling.\\n\"\n\t\t      \"Example 4: mtd=/dev/mtd1,0,0,5 - attach MTD device /dev/mtd1 to UBI 5 and using default values for the other fields.\\n\"\n\t\t      \"example 5: mtd=1,0,0,5 mtd=2,0,0,6,1 - attach MTD device /dev/mtd1 to UBI 5 and disable fastmap; attach MTD device /dev/mtd2 to UBI 6 and enable fastmap.(only works when fastmap is enabled and fm_autoconvert=Y).\\n\"\n\t\t      \"\\t(e.g. if the NAND *chipset* has 4096 PEB, 100 will be reserved for this UBI device).\");\n#ifdef CONFIG_MTD_UBI_FASTMAP\nmodule_param(fm_autoconvert, bool, 0644);\nMODULE_PARM_DESC(fm_autoconvert, \"Set this parameter to enable fastmap automatically on images without a fastmap.\");\nmodule_param(fm_debug, bool, 0);\nMODULE_PARM_DESC(fm_debug, \"Set this parameter to enable fastmap debugging by default. Warning, this will make fastmap slow!\");\n#endif\nMODULE_VERSION(__stringify(UBI_VERSION));\nMODULE_DESCRIPTION(\"UBI - Unsorted Block Images\");\nMODULE_AUTHOR(\"Artem Bityutskiy\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}