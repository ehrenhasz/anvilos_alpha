{
  "module_name": "mtd_blkdevs.c",
  "hash_id": "185160c2be3e47fd6003c285b0bb1abf6bd4bb56f5c618635b43c7dcf45ec675",
  "original_prompt": "Ingested from linux-6.6.14/drivers/mtd/mtd_blkdevs.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <linux/list.h>\n#include <linux/fs.h>\n#include <linux/mtd/blktrans.h>\n#include <linux/mtd/mtd.h>\n#include <linux/blkdev.h>\n#include <linux/blk-mq.h>\n#include <linux/blkpg.h>\n#include <linux/spinlock.h>\n#include <linux/hdreg.h>\n#include <linux/mutex.h>\n#include <linux/uaccess.h>\n\n#include \"mtdcore.h\"\n\nstatic LIST_HEAD(blktrans_majors);\n\nstatic void blktrans_dev_release(struct kref *kref)\n{\n\tstruct mtd_blktrans_dev *dev =\n\t\tcontainer_of(kref, struct mtd_blktrans_dev, ref);\n\n\tput_disk(dev->disk);\n\tblk_mq_free_tag_set(dev->tag_set);\n\tkfree(dev->tag_set);\n\tlist_del(&dev->list);\n\tkfree(dev);\n}\n\nstatic void blktrans_dev_put(struct mtd_blktrans_dev *dev)\n{\n\tkref_put(&dev->ref, blktrans_dev_release);\n}\n\n\nstatic blk_status_t do_blktrans_request(struct mtd_blktrans_ops *tr,\n\t\t\t       struct mtd_blktrans_dev *dev,\n\t\t\t       struct request *req)\n{\n\tstruct req_iterator iter;\n\tstruct bio_vec bvec;\n\tunsigned long block, nsect;\n\tchar *buf;\n\n\tblock = blk_rq_pos(req) << 9 >> tr->blkshift;\n\tnsect = blk_rq_cur_bytes(req) >> tr->blkshift;\n\n\tswitch (req_op(req)) {\n\tcase REQ_OP_FLUSH:\n\t\tif (tr->flush(dev))\n\t\t\treturn BLK_STS_IOERR;\n\t\treturn BLK_STS_OK;\n\tcase REQ_OP_DISCARD:\n\t\tif (tr->discard(dev, block, nsect))\n\t\t\treturn BLK_STS_IOERR;\n\t\treturn BLK_STS_OK;\n\tcase REQ_OP_READ:\n\t\tbuf = kmap(bio_page(req->bio)) + bio_offset(req->bio);\n\t\tfor (; nsect > 0; nsect--, block++, buf += tr->blksize) {\n\t\t\tif (tr->readsect(dev, block, buf)) {\n\t\t\t\tkunmap(bio_page(req->bio));\n\t\t\t\treturn BLK_STS_IOERR;\n\t\t\t}\n\t\t}\n\t\tkunmap(bio_page(req->bio));\n\n\t\trq_for_each_segment(bvec, req, iter)\n\t\t\tflush_dcache_page(bvec.bv_page);\n\t\treturn BLK_STS_OK;\n\tcase REQ_OP_WRITE:\n\t\tif (!tr->writesect)\n\t\t\treturn BLK_STS_IOERR;\n\n\t\trq_for_each_segment(bvec, req, iter)\n\t\t\tflush_dcache_page(bvec.bv_page);\n\n\t\tbuf = kmap(bio_page(req->bio)) + bio_offset(req->bio);\n\t\tfor (; nsect > 0; nsect--, block++, buf += tr->blksize) {\n\t\t\tif (tr->writesect(dev, block, buf)) {\n\t\t\t\tkunmap(bio_page(req->bio));\n\t\t\t\treturn BLK_STS_IOERR;\n\t\t\t}\n\t\t}\n\t\tkunmap(bio_page(req->bio));\n\t\treturn BLK_STS_OK;\n\tdefault:\n\t\treturn BLK_STS_IOERR;\n\t}\n}\n\nint mtd_blktrans_cease_background(struct mtd_blktrans_dev *dev)\n{\n\treturn dev->bg_stop;\n}\nEXPORT_SYMBOL_GPL(mtd_blktrans_cease_background);\n\nstatic struct request *mtd_next_request(struct mtd_blktrans_dev *dev)\n{\n\tstruct request *rq;\n\n\trq = list_first_entry_or_null(&dev->rq_list, struct request, queuelist);\n\tif (rq) {\n\t\tlist_del_init(&rq->queuelist);\n\t\tblk_mq_start_request(rq);\n\t\treturn rq;\n\t}\n\n\treturn NULL;\n}\n\nstatic void mtd_blktrans_work(struct mtd_blktrans_dev *dev)\n\t__releases(&dev->queue_lock)\n\t__acquires(&dev->queue_lock)\n{\n\tstruct mtd_blktrans_ops *tr = dev->tr;\n\tstruct request *req = NULL;\n\tint background_done = 0;\n\n\twhile (1) {\n\t\tblk_status_t res;\n\n\t\tdev->bg_stop = false;\n\t\tif (!req && !(req = mtd_next_request(dev))) {\n\t\t\tif (tr->background && !background_done) {\n\t\t\t\tspin_unlock_irq(&dev->queue_lock);\n\t\t\t\tmutex_lock(&dev->lock);\n\t\t\t\ttr->background(dev);\n\t\t\t\tmutex_unlock(&dev->lock);\n\t\t\t\tspin_lock_irq(&dev->queue_lock);\n\t\t\t\t \n\t\t\t\tbackground_done = !dev->bg_stop;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock_irq(&dev->queue_lock);\n\n\t\tmutex_lock(&dev->lock);\n\t\tres = do_blktrans_request(dev->tr, dev, req);\n\t\tmutex_unlock(&dev->lock);\n\n\t\tif (!blk_update_request(req, res, blk_rq_cur_bytes(req))) {\n\t\t\t__blk_mq_end_request(req, res);\n\t\t\treq = NULL;\n\t\t}\n\n\t\tbackground_done = 0;\n\t\tcond_resched();\n\t\tspin_lock_irq(&dev->queue_lock);\n\t}\n}\n\nstatic blk_status_t mtd_queue_rq(struct blk_mq_hw_ctx *hctx,\n\t\t\t\t const struct blk_mq_queue_data *bd)\n{\n\tstruct mtd_blktrans_dev *dev;\n\n\tdev = hctx->queue->queuedata;\n\tif (!dev) {\n\t\tblk_mq_start_request(bd->rq);\n\t\treturn BLK_STS_IOERR;\n\t}\n\n\tspin_lock_irq(&dev->queue_lock);\n\tlist_add_tail(&bd->rq->queuelist, &dev->rq_list);\n\tmtd_blktrans_work(dev);\n\tspin_unlock_irq(&dev->queue_lock);\n\n\treturn BLK_STS_OK;\n}\n\nstatic int blktrans_open(struct gendisk *disk, blk_mode_t mode)\n{\n\tstruct mtd_blktrans_dev *dev = disk->private_data;\n\tint ret = 0;\n\n\tkref_get(&dev->ref);\n\n\tmutex_lock(&dev->lock);\n\n\tif (dev->open)\n\t\tgoto unlock;\n\n\t__module_get(dev->tr->owner);\n\n\tif (!dev->mtd)\n\t\tgoto unlock;\n\n\tif (dev->tr->open) {\n\t\tret = dev->tr->open(dev);\n\t\tif (ret)\n\t\t\tgoto error_put;\n\t}\n\n\tret = __get_mtd_device(dev->mtd);\n\tif (ret)\n\t\tgoto error_release;\n\tdev->writable = mode & BLK_OPEN_WRITE;\n\nunlock:\n\tdev->open++;\n\tmutex_unlock(&dev->lock);\n\treturn ret;\n\nerror_release:\n\tif (dev->tr->release)\n\t\tdev->tr->release(dev);\nerror_put:\n\tmodule_put(dev->tr->owner);\n\tmutex_unlock(&dev->lock);\n\tblktrans_dev_put(dev);\n\treturn ret;\n}\n\nstatic void blktrans_release(struct gendisk *disk)\n{\n\tstruct mtd_blktrans_dev *dev = disk->private_data;\n\n\tmutex_lock(&dev->lock);\n\n\tif (--dev->open)\n\t\tgoto unlock;\n\n\tmodule_put(dev->tr->owner);\n\n\tif (dev->mtd) {\n\t\tif (dev->tr->release)\n\t\t\tdev->tr->release(dev);\n\t\t__put_mtd_device(dev->mtd);\n\t}\nunlock:\n\tmutex_unlock(&dev->lock);\n\tblktrans_dev_put(dev);\n}\n\nstatic int blktrans_getgeo(struct block_device *bdev, struct hd_geometry *geo)\n{\n\tstruct mtd_blktrans_dev *dev = bdev->bd_disk->private_data;\n\tint ret = -ENXIO;\n\n\tmutex_lock(&dev->lock);\n\n\tif (!dev->mtd)\n\t\tgoto unlock;\n\n\tret = dev->tr->getgeo ? dev->tr->getgeo(dev, geo) : -ENOTTY;\nunlock:\n\tmutex_unlock(&dev->lock);\n\treturn ret;\n}\n\nstatic const struct block_device_operations mtd_block_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.open\t\t= blktrans_open,\n\t.release\t= blktrans_release,\n\t.getgeo\t\t= blktrans_getgeo,\n};\n\nstatic const struct blk_mq_ops mtd_mq_ops = {\n\t.queue_rq\t= mtd_queue_rq,\n};\n\nint add_mtd_blktrans_dev(struct mtd_blktrans_dev *new)\n{\n\tstruct mtd_blktrans_ops *tr = new->tr;\n\tstruct mtd_blktrans_dev *d;\n\tint last_devnum = -1;\n\tstruct gendisk *gd;\n\tint ret;\n\n\tlockdep_assert_held(&mtd_table_mutex);\n\n\tlist_for_each_entry(d, &tr->devs, list) {\n\t\tif (new->devnum == -1) {\n\t\t\t \n\t\t\tif (d->devnum != last_devnum+1) {\n\t\t\t\t \n\t\t\t\tnew->devnum = last_devnum+1;\n\t\t\t\tlist_add_tail(&new->list, &d->list);\n\t\t\t\tgoto added;\n\t\t\t}\n\t\t} else if (d->devnum == new->devnum) {\n\t\t\t \n\t\t\treturn -EBUSY;\n\t\t} else if (d->devnum > new->devnum) {\n\t\t\t \n\t\t\tlist_add_tail(&new->list, &d->list);\n\t\t\tgoto added;\n\t\t}\n\t\tlast_devnum = d->devnum;\n\t}\n\n\tret = -EBUSY;\n\tif (new->devnum == -1)\n\t\tnew->devnum = last_devnum+1;\n\n\t \n\tif (new->devnum > (MINORMASK >> tr->part_bits) ||\n\t    (tr->part_bits && new->devnum >= 27 * 26))\n\t\treturn ret;\n\n\tlist_add_tail(&new->list, &tr->devs);\n added:\n\n\tmutex_init(&new->lock);\n\tkref_init(&new->ref);\n\tif (!tr->writesect)\n\t\tnew->readonly = 1;\n\n\tret = -ENOMEM;\n\tnew->tag_set = kzalloc(sizeof(*new->tag_set), GFP_KERNEL);\n\tif (!new->tag_set)\n\t\tgoto out_list_del;\n\n\tret = blk_mq_alloc_sq_tag_set(new->tag_set, &mtd_mq_ops, 2,\n\t\t\tBLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_BLOCKING);\n\tif (ret)\n\t\tgoto out_kfree_tag_set;\n\n\t \n\tgd = blk_mq_alloc_disk(new->tag_set, new);\n\tif (IS_ERR(gd)) {\n\t\tret = PTR_ERR(gd);\n\t\tgoto out_free_tag_set;\n\t}\n\n\tnew->disk = gd;\n\tnew->rq = new->disk->queue;\n\tgd->private_data = new;\n\tgd->major = tr->major;\n\tgd->first_minor = (new->devnum) << tr->part_bits;\n\tgd->minors = 1 << tr->part_bits;\n\tgd->fops = &mtd_block_ops;\n\n\tif (tr->part_bits) {\n\t\tif (new->devnum < 26)\n\t\t\tsnprintf(gd->disk_name, sizeof(gd->disk_name),\n\t\t\t\t \"%s%c\", tr->name, 'a' + new->devnum);\n\t\telse\n\t\t\tsnprintf(gd->disk_name, sizeof(gd->disk_name),\n\t\t\t\t \"%s%c%c\", tr->name,\n\t\t\t\t 'a' - 1 + new->devnum / 26,\n\t\t\t\t 'a' + new->devnum % 26);\n\t} else {\n\t\tsnprintf(gd->disk_name, sizeof(gd->disk_name),\n\t\t\t \"%s%d\", tr->name, new->devnum);\n\t\tgd->flags |= GENHD_FL_NO_PART;\n\t}\n\n\tset_capacity(gd, ((u64)new->size * tr->blksize) >> 9);\n\n\t \n\tspin_lock_init(&new->queue_lock);\n\tINIT_LIST_HEAD(&new->rq_list);\n\n\tif (tr->flush)\n\t\tblk_queue_write_cache(new->rq, true, false);\n\n\tblk_queue_logical_block_size(new->rq, tr->blksize);\n\n\tblk_queue_flag_set(QUEUE_FLAG_NONROT, new->rq);\n\tblk_queue_flag_clear(QUEUE_FLAG_ADD_RANDOM, new->rq);\n\n\tif (tr->discard) {\n\t\tblk_queue_max_discard_sectors(new->rq, UINT_MAX);\n\t\tnew->rq->limits.discard_granularity = tr->blksize;\n\t}\n\n\tgd->queue = new->rq;\n\n\tif (new->readonly)\n\t\tset_disk_ro(gd, 1);\n\n\tret = device_add_disk(&new->mtd->dev, gd, NULL);\n\tif (ret)\n\t\tgoto out_cleanup_disk;\n\n\tif (new->disk_attributes) {\n\t\tret = sysfs_create_group(&disk_to_dev(gd)->kobj,\n\t\t\t\t\tnew->disk_attributes);\n\t\tWARN_ON(ret);\n\t}\n\treturn 0;\n\nout_cleanup_disk:\n\tput_disk(new->disk);\nout_free_tag_set:\n\tblk_mq_free_tag_set(new->tag_set);\nout_kfree_tag_set:\n\tkfree(new->tag_set);\nout_list_del:\n\tlist_del(&new->list);\n\treturn ret;\n}\n\nint del_mtd_blktrans_dev(struct mtd_blktrans_dev *old)\n{\n\tunsigned long flags;\n\n\tlockdep_assert_held(&mtd_table_mutex);\n\n\tif (old->disk_attributes)\n\t\tsysfs_remove_group(&disk_to_dev(old->disk)->kobj,\n\t\t\t\t\t\told->disk_attributes);\n\n\t \n\tdel_gendisk(old->disk);\n\n\t \n\tspin_lock_irqsave(&old->queue_lock, flags);\n\told->rq->queuedata = NULL;\n\tspin_unlock_irqrestore(&old->queue_lock, flags);\n\n\t \n\tblk_mq_freeze_queue(old->rq);\n\tblk_mq_quiesce_queue(old->rq);\n\tblk_mq_unquiesce_queue(old->rq);\n\tblk_mq_unfreeze_queue(old->rq);\n\n\t \n\tmutex_lock(&old->lock);\n\tif (old->open) {\n\t\tif (old->tr->release)\n\t\t\told->tr->release(old);\n\t\t__put_mtd_device(old->mtd);\n\t}\n\n\told->mtd = NULL;\n\n\tmutex_unlock(&old->lock);\n\tblktrans_dev_put(old);\n\treturn 0;\n}\n\nstatic void blktrans_notify_remove(struct mtd_info *mtd)\n{\n\tstruct mtd_blktrans_ops *tr;\n\tstruct mtd_blktrans_dev *dev, *next;\n\n\tlist_for_each_entry(tr, &blktrans_majors, list)\n\t\tlist_for_each_entry_safe(dev, next, &tr->devs, list)\n\t\t\tif (dev->mtd == mtd)\n\t\t\t\ttr->remove_dev(dev);\n}\n\nstatic void blktrans_notify_add(struct mtd_info *mtd)\n{\n\tstruct mtd_blktrans_ops *tr;\n\n\tif (mtd->type == MTD_ABSENT || mtd->type == MTD_UBIVOLUME)\n\t\treturn;\n\n\tlist_for_each_entry(tr, &blktrans_majors, list)\n\t\ttr->add_mtd(tr, mtd);\n}\n\nstatic struct mtd_notifier blktrans_notifier = {\n\t.add = blktrans_notify_add,\n\t.remove = blktrans_notify_remove,\n};\n\nint register_mtd_blktrans(struct mtd_blktrans_ops *tr)\n{\n\tstruct mtd_info *mtd;\n\tint ret;\n\n\t \n\tif (!blktrans_notifier.list.next)\n\t\tregister_mtd_user(&blktrans_notifier);\n\n\tret = register_blkdev(tr->major, tr->name);\n\tif (ret < 0) {\n\t\tprintk(KERN_WARNING \"Unable to register %s block device on major %d: %d\\n\",\n\t\t       tr->name, tr->major, ret);\n\t\treturn ret;\n\t}\n\n\tif (ret)\n\t\ttr->major = ret;\n\n\ttr->blkshift = ffs(tr->blksize) - 1;\n\n\tINIT_LIST_HEAD(&tr->devs);\n\n\tmutex_lock(&mtd_table_mutex);\n\tlist_add(&tr->list, &blktrans_majors);\n\tmtd_for_each_device(mtd)\n\t\tif (mtd->type != MTD_ABSENT && mtd->type != MTD_UBIVOLUME)\n\t\t\ttr->add_mtd(tr, mtd);\n\tmutex_unlock(&mtd_table_mutex);\n\treturn 0;\n}\n\nint deregister_mtd_blktrans(struct mtd_blktrans_ops *tr)\n{\n\tstruct mtd_blktrans_dev *dev, *next;\n\n\tmutex_lock(&mtd_table_mutex);\n\n\t \n\tlist_del(&tr->list);\n\n\tlist_for_each_entry_safe(dev, next, &tr->devs, list)\n\t\ttr->remove_dev(dev);\n\n\tmutex_unlock(&mtd_table_mutex);\n\tunregister_blkdev(tr->major, tr->name);\n\n\tBUG_ON(!list_empty(&tr->devs));\n\treturn 0;\n}\n\nstatic void __exit mtd_blktrans_exit(void)\n{\n\t \n\tif (blktrans_notifier.list.next)\n\t\tunregister_mtd_user(&blktrans_notifier);\n}\n\nmodule_exit(mtd_blktrans_exit);\n\nEXPORT_SYMBOL_GPL(register_mtd_blktrans);\nEXPORT_SYMBOL_GPL(deregister_mtd_blktrans);\nEXPORT_SYMBOL_GPL(add_mtd_blktrans_dev);\nEXPORT_SYMBOL_GPL(del_mtd_blktrans_dev);\n\nMODULE_AUTHOR(\"David Woodhouse <dwmw2@infradead.org>\");\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"Common interface to block layer for MTD 'translation layers'\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}