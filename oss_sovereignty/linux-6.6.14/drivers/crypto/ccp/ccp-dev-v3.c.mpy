{
  "module_name": "ccp-dev-v3.c",
  "hash_id": "98d013820b5e3e5be1885e93b760140db7aa7e39e571a308742b3cb84fbadf96",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/ccp/ccp-dev-v3.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/kthread.h>\n#include <linux/interrupt.h>\n#include <linux/ccp.h>\n\n#include \"ccp-dev.h\"\n\nstatic u32 ccp_alloc_ksb(struct ccp_cmd_queue *cmd_q, unsigned int count)\n{\n\tint start;\n\tstruct ccp_device *ccp = cmd_q->ccp;\n\n\tfor (;;) {\n\t\tmutex_lock(&ccp->sb_mutex);\n\n\t\tstart = (u32)bitmap_find_next_zero_area(ccp->sb,\n\t\t\t\t\t\t\tccp->sb_count,\n\t\t\t\t\t\t\tccp->sb_start,\n\t\t\t\t\t\t\tcount, 0);\n\t\tif (start <= ccp->sb_count) {\n\t\t\tbitmap_set(ccp->sb, start, count);\n\n\t\t\tmutex_unlock(&ccp->sb_mutex);\n\t\t\tbreak;\n\t\t}\n\n\t\tccp->sb_avail = 0;\n\n\t\tmutex_unlock(&ccp->sb_mutex);\n\n\t\t \n\t\tif (wait_event_interruptible(ccp->sb_queue, ccp->sb_avail))\n\t\t\treturn 0;\n\t}\n\n\treturn KSB_START + start;\n}\n\nstatic void ccp_free_ksb(struct ccp_cmd_queue *cmd_q, unsigned int start,\n\t\t\t unsigned int count)\n{\n\tstruct ccp_device *ccp = cmd_q->ccp;\n\n\tif (!start)\n\t\treturn;\n\n\tmutex_lock(&ccp->sb_mutex);\n\n\tbitmap_clear(ccp->sb, start - KSB_START, count);\n\n\tccp->sb_avail = 1;\n\n\tmutex_unlock(&ccp->sb_mutex);\n\n\twake_up_interruptible_all(&ccp->sb_queue);\n}\n\nstatic unsigned int ccp_get_free_slots(struct ccp_cmd_queue *cmd_q)\n{\n\treturn CMD_Q_DEPTH(ioread32(cmd_q->reg_status));\n}\n\nstatic int ccp_do_cmd(struct ccp_op *op, u32 *cr, unsigned int cr_count)\n{\n\tstruct ccp_cmd_queue *cmd_q = op->cmd_q;\n\tstruct ccp_device *ccp = cmd_q->ccp;\n\tvoid __iomem *cr_addr;\n\tu32 cr0, cmd;\n\tunsigned int i;\n\tint ret = 0;\n\n\t \n\tcmd_q->free_slots--;\n\n\tcr0 = (cmd_q->id << REQ0_CMD_Q_SHIFT)\n\t      | (op->jobid << REQ0_JOBID_SHIFT)\n\t      | REQ0_WAIT_FOR_WRITE;\n\n\tif (op->soc)\n\t\tcr0 |= REQ0_STOP_ON_COMPLETE\n\t\t       | REQ0_INT_ON_COMPLETE;\n\n\tif (op->ioc || !cmd_q->free_slots)\n\t\tcr0 |= REQ0_INT_ON_COMPLETE;\n\n\t \n\tcr_addr = ccp->io_regs + CMD_REQ0 + CMD_REQ_INCR;\n\n\tmutex_lock(&ccp->req_mutex);\n\n\t \n\tfor (i = 0; i < cr_count; i++, cr_addr += CMD_REQ_INCR)\n\t\tiowrite32(*(cr + i), cr_addr);\n\n\t \n\twmb();\n\tiowrite32(cr0, ccp->io_regs + CMD_REQ0);\n\n\tmutex_unlock(&ccp->req_mutex);\n\n\tif (cr0 & REQ0_INT_ON_COMPLETE) {\n\t\t \n\t\tret = wait_event_interruptible(cmd_q->int_queue,\n\t\t\t\t\t       cmd_q->int_rcvd);\n\t\tif (ret || cmd_q->cmd_error) {\n\t\t\t \n\t\t\tcmd = (cmd_q->id << DEL_Q_ID_SHIFT)\n\t\t\t      | op->jobid;\n\t\t\tif (cmd_q->cmd_error)\n\t\t\t\tccp_log_error(cmd_q->ccp,\n\t\t\t\t\t      cmd_q->cmd_error);\n\n\t\t\tiowrite32(cmd, ccp->io_regs + DEL_CMD_Q_JOB);\n\n\t\t\tif (!ret)\n\t\t\t\tret = -EIO;\n\t\t} else if (op->soc) {\n\t\t\t \n\t\t\tcmd = DEL_Q_ACTIVE\n\t\t\t      | (cmd_q->id << DEL_Q_ID_SHIFT)\n\t\t\t      | op->jobid;\n\n\t\t\tiowrite32(cmd, ccp->io_regs + DEL_CMD_Q_JOB);\n\t\t}\n\n\t\tcmd_q->free_slots = CMD_Q_DEPTH(cmd_q->q_status);\n\n\t\tcmd_q->int_rcvd = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic int ccp_perform_aes(struct ccp_op *op)\n{\n\tu32 cr[6];\n\n\t \n\tcr[0] = (CCP_ENGINE_AES << REQ1_ENGINE_SHIFT)\n\t\t| (op->u.aes.type << REQ1_AES_TYPE_SHIFT)\n\t\t| (op->u.aes.mode << REQ1_AES_MODE_SHIFT)\n\t\t| (op->u.aes.action << REQ1_AES_ACTION_SHIFT)\n\t\t| (op->sb_key << REQ1_KEY_KSB_SHIFT);\n\tcr[1] = op->src.u.dma.length - 1;\n\tcr[2] = ccp_addr_lo(&op->src.u.dma);\n\tcr[3] = (op->sb_ctx << REQ4_KSB_SHIFT)\n\t\t| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->src.u.dma);\n\tcr[4] = ccp_addr_lo(&op->dst.u.dma);\n\tcr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->dst.u.dma);\n\n\tif (op->u.aes.mode == CCP_AES_MODE_CFB)\n\t\tcr[0] |= ((0x7f) << REQ1_AES_CFB_SIZE_SHIFT);\n\n\tif (op->eom)\n\t\tcr[0] |= REQ1_EOM;\n\n\tif (op->init)\n\t\tcr[0] |= REQ1_INIT;\n\n\treturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\n}\n\nstatic int ccp_perform_xts_aes(struct ccp_op *op)\n{\n\tu32 cr[6];\n\n\t \n\tcr[0] = (CCP_ENGINE_XTS_AES_128 << REQ1_ENGINE_SHIFT)\n\t\t| (op->u.xts.action << REQ1_AES_ACTION_SHIFT)\n\t\t| (op->u.xts.unit_size << REQ1_XTS_AES_SIZE_SHIFT)\n\t\t| (op->sb_key << REQ1_KEY_KSB_SHIFT);\n\tcr[1] = op->src.u.dma.length - 1;\n\tcr[2] = ccp_addr_lo(&op->src.u.dma);\n\tcr[3] = (op->sb_ctx << REQ4_KSB_SHIFT)\n\t\t| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->src.u.dma);\n\tcr[4] = ccp_addr_lo(&op->dst.u.dma);\n\tcr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->dst.u.dma);\n\n\tif (op->eom)\n\t\tcr[0] |= REQ1_EOM;\n\n\tif (op->init)\n\t\tcr[0] |= REQ1_INIT;\n\n\treturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\n}\n\nstatic int ccp_perform_sha(struct ccp_op *op)\n{\n\tu32 cr[6];\n\n\t \n\tcr[0] = (CCP_ENGINE_SHA << REQ1_ENGINE_SHIFT)\n\t\t| (op->u.sha.type << REQ1_SHA_TYPE_SHIFT)\n\t\t| REQ1_INIT;\n\tcr[1] = op->src.u.dma.length - 1;\n\tcr[2] = ccp_addr_lo(&op->src.u.dma);\n\tcr[3] = (op->sb_ctx << REQ4_KSB_SHIFT)\n\t\t| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->src.u.dma);\n\n\tif (op->eom) {\n\t\tcr[0] |= REQ1_EOM;\n\t\tcr[4] = lower_32_bits(op->u.sha.msg_bits);\n\t\tcr[5] = upper_32_bits(op->u.sha.msg_bits);\n\t} else {\n\t\tcr[4] = 0;\n\t\tcr[5] = 0;\n\t}\n\n\treturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\n}\n\nstatic int ccp_perform_rsa(struct ccp_op *op)\n{\n\tu32 cr[6];\n\n\t \n\tcr[0] = (CCP_ENGINE_RSA << REQ1_ENGINE_SHIFT)\n\t\t| (op->u.rsa.mod_size << REQ1_RSA_MOD_SIZE_SHIFT)\n\t\t| (op->sb_key << REQ1_KEY_KSB_SHIFT)\n\t\t| REQ1_EOM;\n\tcr[1] = op->u.rsa.input_len - 1;\n\tcr[2] = ccp_addr_lo(&op->src.u.dma);\n\tcr[3] = (op->sb_ctx << REQ4_KSB_SHIFT)\n\t\t| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->src.u.dma);\n\tcr[4] = ccp_addr_lo(&op->dst.u.dma);\n\tcr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->dst.u.dma);\n\n\treturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\n}\n\nstatic int ccp_perform_passthru(struct ccp_op *op)\n{\n\tu32 cr[6];\n\n\t \n\tcr[0] = (CCP_ENGINE_PASSTHRU << REQ1_ENGINE_SHIFT)\n\t\t| (op->u.passthru.bit_mod << REQ1_PT_BW_SHIFT)\n\t\t| (op->u.passthru.byte_swap << REQ1_PT_BS_SHIFT);\n\n\tif (op->src.type == CCP_MEMTYPE_SYSTEM)\n\t\tcr[1] = op->src.u.dma.length - 1;\n\telse\n\t\tcr[1] = op->dst.u.dma.length - 1;\n\n\tif (op->src.type == CCP_MEMTYPE_SYSTEM) {\n\t\tcr[2] = ccp_addr_lo(&op->src.u.dma);\n\t\tcr[3] = (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\n\t\t\t| ccp_addr_hi(&op->src.u.dma);\n\n\t\tif (op->u.passthru.bit_mod != CCP_PASSTHRU_BITWISE_NOOP)\n\t\t\tcr[3] |= (op->sb_key << REQ4_KSB_SHIFT);\n\t} else {\n\t\tcr[2] = op->src.u.sb * CCP_SB_BYTES;\n\t\tcr[3] = (CCP_MEMTYPE_SB << REQ4_MEMTYPE_SHIFT);\n\t}\n\n\tif (op->dst.type == CCP_MEMTYPE_SYSTEM) {\n\t\tcr[4] = ccp_addr_lo(&op->dst.u.dma);\n\t\tcr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\n\t\t\t| ccp_addr_hi(&op->dst.u.dma);\n\t} else {\n\t\tcr[4] = op->dst.u.sb * CCP_SB_BYTES;\n\t\tcr[5] = (CCP_MEMTYPE_SB << REQ6_MEMTYPE_SHIFT);\n\t}\n\n\tif (op->eom)\n\t\tcr[0] |= REQ1_EOM;\n\n\treturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\n}\n\nstatic int ccp_perform_ecc(struct ccp_op *op)\n{\n\tu32 cr[6];\n\n\t \n\tcr[0] = REQ1_ECC_AFFINE_CONVERT\n\t\t| (CCP_ENGINE_ECC << REQ1_ENGINE_SHIFT)\n\t\t| (op->u.ecc.function << REQ1_ECC_FUNCTION_SHIFT)\n\t\t| REQ1_EOM;\n\tcr[1] = op->src.u.dma.length - 1;\n\tcr[2] = ccp_addr_lo(&op->src.u.dma);\n\tcr[3] = (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->src.u.dma);\n\tcr[4] = ccp_addr_lo(&op->dst.u.dma);\n\tcr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\n\t\t| ccp_addr_hi(&op->dst.u.dma);\n\n\treturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\n}\n\nstatic void ccp_disable_queue_interrupts(struct ccp_device *ccp)\n{\n\tiowrite32(0x00, ccp->io_regs + IRQ_MASK_REG);\n}\n\nstatic void ccp_enable_queue_interrupts(struct ccp_device *ccp)\n{\n\tiowrite32(ccp->qim, ccp->io_regs + IRQ_MASK_REG);\n}\n\nstatic void ccp_irq_bh(unsigned long data)\n{\n\tstruct ccp_device *ccp = (struct ccp_device *)data;\n\tstruct ccp_cmd_queue *cmd_q;\n\tu32 q_int, status;\n\tunsigned int i;\n\n\tstatus = ioread32(ccp->io_regs + IRQ_STATUS_REG);\n\n\tfor (i = 0; i < ccp->cmd_q_count; i++) {\n\t\tcmd_q = &ccp->cmd_q[i];\n\n\t\tq_int = status & (cmd_q->int_ok | cmd_q->int_err);\n\t\tif (q_int) {\n\t\t\tcmd_q->int_status = status;\n\t\t\tcmd_q->q_status = ioread32(cmd_q->reg_status);\n\t\t\tcmd_q->q_int_status = ioread32(cmd_q->reg_int_status);\n\n\t\t\t \n\t\t\tif ((q_int & cmd_q->int_err) && !cmd_q->cmd_error)\n\t\t\t\tcmd_q->cmd_error = CMD_Q_ERROR(cmd_q->q_status);\n\n\t\t\tcmd_q->int_rcvd = 1;\n\n\t\t\t \n\t\t\tiowrite32(q_int, ccp->io_regs + IRQ_STATUS_REG);\n\t\t\twake_up_interruptible(&cmd_q->int_queue);\n\t\t}\n\t}\n\tccp_enable_queue_interrupts(ccp);\n}\n\nstatic irqreturn_t ccp_irq_handler(int irq, void *data)\n{\n\tstruct ccp_device *ccp = (struct ccp_device *)data;\n\n\tccp_disable_queue_interrupts(ccp);\n\tif (ccp->use_tasklet)\n\t\ttasklet_schedule(&ccp->irq_tasklet);\n\telse\n\t\tccp_irq_bh((unsigned long)ccp);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int ccp_init(struct ccp_device *ccp)\n{\n\tstruct device *dev = ccp->dev;\n\tstruct ccp_cmd_queue *cmd_q;\n\tstruct dma_pool *dma_pool;\n\tchar dma_pool_name[MAX_DMAPOOL_NAME_LEN];\n\tunsigned int qmr, i;\n\tint ret;\n\n\t \n\tccp->qim = 0;\n\tqmr = ioread32(ccp->io_regs + Q_MASK_REG);\n\tfor (i = 0; (i < MAX_HW_QUEUES) && (ccp->cmd_q_count < ccp->max_q_count); i++) {\n\t\tif (!(qmr & (1 << i)))\n\t\t\tcontinue;\n\n\t\t \n\t\tsnprintf(dma_pool_name, sizeof(dma_pool_name), \"%s_q%d\",\n\t\t\t ccp->name, i);\n\t\tdma_pool = dma_pool_create(dma_pool_name, dev,\n\t\t\t\t\t   CCP_DMAPOOL_MAX_SIZE,\n\t\t\t\t\t   CCP_DMAPOOL_ALIGN, 0);\n\t\tif (!dma_pool) {\n\t\t\tdev_err(dev, \"unable to allocate dma pool\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto e_pool;\n\t\t}\n\n\t\tcmd_q = &ccp->cmd_q[ccp->cmd_q_count];\n\t\tccp->cmd_q_count++;\n\n\t\tcmd_q->ccp = ccp;\n\t\tcmd_q->id = i;\n\t\tcmd_q->dma_pool = dma_pool;\n\n\t\t \n\t\tcmd_q->sb_key = KSB_START + ccp->sb_start++;\n\t\tcmd_q->sb_ctx = KSB_START + ccp->sb_start++;\n\t\tccp->sb_count -= 2;\n\n\t\t \n\t\tcmd_q->reg_status = ccp->io_regs + CMD_Q_STATUS_BASE +\n\t\t\t\t    (CMD_Q_STATUS_INCR * i);\n\t\tcmd_q->reg_int_status = ccp->io_regs + CMD_Q_INT_STATUS_BASE +\n\t\t\t\t\t(CMD_Q_STATUS_INCR * i);\n\t\tcmd_q->int_ok = 1 << (i * 2);\n\t\tcmd_q->int_err = 1 << ((i * 2) + 1);\n\n\t\tcmd_q->free_slots = ccp_get_free_slots(cmd_q);\n\n\t\tinit_waitqueue_head(&cmd_q->int_queue);\n\n\t\t \n\t\tccp->qim |= cmd_q->int_ok | cmd_q->int_err;\n\n#ifdef CONFIG_ARM64\n\t\t \n\t\tiowrite32(ccp->axcache, ccp->io_regs + CMD_Q_CACHE_BASE +\n\t\t\t  (CMD_Q_CACHE_INC * i));\n#endif\n\n\t\tdev_dbg(dev, \"queue #%u available\\n\", i);\n\t}\n\tif (ccp->cmd_q_count == 0) {\n\t\tdev_notice(dev, \"no command queues available\\n\");\n\t\tret = -EIO;\n\t\tgoto e_pool;\n\t}\n\tdev_notice(dev, \"%u command queues available\\n\", ccp->cmd_q_count);\n\n\t \n\tccp_disable_queue_interrupts(ccp);\n\tfor (i = 0; i < ccp->cmd_q_count; i++) {\n\t\tcmd_q = &ccp->cmd_q[i];\n\n\t\tioread32(cmd_q->reg_int_status);\n\t\tioread32(cmd_q->reg_status);\n\t}\n\tiowrite32(ccp->qim, ccp->io_regs + IRQ_STATUS_REG);\n\n\t \n\tret = sp_request_ccp_irq(ccp->sp, ccp_irq_handler, ccp->name, ccp);\n\tif (ret) {\n\t\tdev_err(dev, \"unable to allocate an IRQ\\n\");\n\t\tgoto e_pool;\n\t}\n\n\t \n\tif (ccp->use_tasklet)\n\t\ttasklet_init(&ccp->irq_tasklet, ccp_irq_bh,\n\t\t\t     (unsigned long)ccp);\n\n\tdev_dbg(dev, \"Starting threads...\\n\");\n\t \n\tfor (i = 0; i < ccp->cmd_q_count; i++) {\n\t\tstruct task_struct *kthread;\n\n\t\tcmd_q = &ccp->cmd_q[i];\n\n\t\tkthread = kthread_run(ccp_cmd_queue_thread, cmd_q,\n\t\t\t\t      \"%s-q%u\", ccp->name, cmd_q->id);\n\t\tif (IS_ERR(kthread)) {\n\t\t\tdev_err(dev, \"error creating queue thread (%ld)\\n\",\n\t\t\t\tPTR_ERR(kthread));\n\t\t\tret = PTR_ERR(kthread);\n\t\t\tgoto e_kthread;\n\t\t}\n\n\t\tcmd_q->kthread = kthread;\n\t}\n\n\tdev_dbg(dev, \"Enabling interrupts...\\n\");\n\t \n\tccp_enable_queue_interrupts(ccp);\n\n\tdev_dbg(dev, \"Registering device...\\n\");\n\tccp_add_device(ccp);\n\n\tret = ccp_register_rng(ccp);\n\tif (ret)\n\t\tgoto e_kthread;\n\n\t \n\tret = ccp_dmaengine_register(ccp);\n\tif (ret)\n\t\tgoto e_hwrng;\n\n\treturn 0;\n\ne_hwrng:\n\tccp_unregister_rng(ccp);\n\ne_kthread:\n\tfor (i = 0; i < ccp->cmd_q_count; i++)\n\t\tif (ccp->cmd_q[i].kthread)\n\t\t\tkthread_stop(ccp->cmd_q[i].kthread);\n\n\tsp_free_ccp_irq(ccp->sp, ccp);\n\ne_pool:\n\tfor (i = 0; i < ccp->cmd_q_count; i++)\n\t\tdma_pool_destroy(ccp->cmd_q[i].dma_pool);\n\n\treturn ret;\n}\n\nstatic void ccp_destroy(struct ccp_device *ccp)\n{\n\tstruct ccp_cmd_queue *cmd_q;\n\tstruct ccp_cmd *cmd;\n\tunsigned int i;\n\n\t \n\tccp_dmaengine_unregister(ccp);\n\n\t \n\tccp_unregister_rng(ccp);\n\n\t \n\tccp_del_device(ccp);\n\n\t \n\tccp_disable_queue_interrupts(ccp);\n\tfor (i = 0; i < ccp->cmd_q_count; i++) {\n\t\tcmd_q = &ccp->cmd_q[i];\n\n\t\tioread32(cmd_q->reg_int_status);\n\t\tioread32(cmd_q->reg_status);\n\t}\n\tiowrite32(ccp->qim, ccp->io_regs + IRQ_STATUS_REG);\n\n\t \n\tfor (i = 0; i < ccp->cmd_q_count; i++)\n\t\tif (ccp->cmd_q[i].kthread)\n\t\t\tkthread_stop(ccp->cmd_q[i].kthread);\n\n\tsp_free_ccp_irq(ccp->sp, ccp);\n\n\tfor (i = 0; i < ccp->cmd_q_count; i++)\n\t\tdma_pool_destroy(ccp->cmd_q[i].dma_pool);\n\n\t \n\twhile (!list_empty(&ccp->cmd)) {\n\t\t \n\t\tcmd = list_first_entry(&ccp->cmd, struct ccp_cmd, entry);\n\t\tlist_del(&cmd->entry);\n\t\tcmd->callback(cmd->data, -ENODEV);\n\t}\n\twhile (!list_empty(&ccp->backlog)) {\n\t\t \n\t\tcmd = list_first_entry(&ccp->backlog, struct ccp_cmd, entry);\n\t\tlist_del(&cmd->entry);\n\t\tcmd->callback(cmd->data, -ENODEV);\n\t}\n}\n\nstatic const struct ccp_actions ccp3_actions = {\n\t.aes = ccp_perform_aes,\n\t.xts_aes = ccp_perform_xts_aes,\n\t.des3 = NULL,\n\t.sha = ccp_perform_sha,\n\t.rsa = ccp_perform_rsa,\n\t.passthru = ccp_perform_passthru,\n\t.ecc = ccp_perform_ecc,\n\t.sballoc = ccp_alloc_ksb,\n\t.sbfree = ccp_free_ksb,\n\t.init = ccp_init,\n\t.destroy = ccp_destroy,\n\t.get_free_slots = ccp_get_free_slots,\n\t.irqhandler = ccp_irq_handler,\n};\n\nconst struct ccp_vdata ccpv3_platform = {\n\t.version = CCP_VERSION(3, 0),\n\t.setup = NULL,\n\t.perform = &ccp3_actions,\n\t.offset = 0,\n\t.rsamax = CCP_RSA_MAX_WIDTH,\n};\n\nconst struct ccp_vdata ccpv3 = {\n\t.version = CCP_VERSION(3, 0),\n\t.setup = NULL,\n\t.perform = &ccp3_actions,\n\t.offset = 0x20000,\n\t.rsamax = CCP_RSA_MAX_WIDTH,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}