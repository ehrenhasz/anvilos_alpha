{
  "module_name": "ccp-crypto-aes-xts.c",
  "hash_id": "f02b40e7cf0590aad63efdb04f01fc13ebfd2c7200f8e9a3154f792d84eb57bd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/ccp/ccp-crypto-aes-xts.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/delay.h>\n#include <linux/scatterlist.h>\n#include <crypto/aes.h>\n#include <crypto/xts.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n\n#include \"ccp-crypto.h\"\n\nstruct ccp_aes_xts_def {\n\tconst char *name;\n\tconst char *drv_name;\n};\n\nstatic const struct ccp_aes_xts_def aes_xts_algs[] = {\n\t{\n\t\t.name\t\t= \"xts(aes)\",\n\t\t.drv_name\t= \"xts-aes-ccp\",\n\t},\n};\n\nstruct ccp_unit_size_map {\n\tunsigned int size;\n\tu32 value;\n};\n\nstatic struct ccp_unit_size_map xts_unit_sizes[] = {\n\t{\n\t\t.size   = 16,\n\t\t.value\t= CCP_XTS_AES_UNIT_SIZE_16,\n\t},\n\t{\n\t\t.size   = 512,\n\t\t.value\t= CCP_XTS_AES_UNIT_SIZE_512,\n\t},\n\t{\n\t\t.size   = 1024,\n\t\t.value\t= CCP_XTS_AES_UNIT_SIZE_1024,\n\t},\n\t{\n\t\t.size   = 2048,\n\t\t.value\t= CCP_XTS_AES_UNIT_SIZE_2048,\n\t},\n\t{\n\t\t.size   = 4096,\n\t\t.value\t= CCP_XTS_AES_UNIT_SIZE_4096,\n\t},\n};\n\nstatic int ccp_aes_xts_complete(struct crypto_async_request *async_req, int ret)\n{\n\tstruct skcipher_request *req = skcipher_request_cast(async_req);\n\tstruct ccp_aes_req_ctx *rctx = skcipher_request_ctx_dma(req);\n\n\tif (ret)\n\t\treturn ret;\n\n\tmemcpy(req->iv, rctx->iv, AES_BLOCK_SIZE);\n\n\treturn 0;\n}\n\nstatic int ccp_aes_xts_setkey(struct crypto_skcipher *tfm, const u8 *key,\n\t\t\t      unsigned int key_len)\n{\n\tstruct ccp_ctx *ctx = crypto_skcipher_ctx_dma(tfm);\n\tunsigned int ccpversion = ccp_version();\n\tint ret;\n\n\tret = xts_verify_key(tfm, key, key_len);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tswitch (key_len) {\n\tcase AES_KEYSIZE_128 * 2:\n\t\tmemcpy(ctx->u.aes.key, key, key_len);\n\t\tbreak;\n\tcase AES_KEYSIZE_256 * 2:\n\t\tif (ccpversion > CCP_VERSION(3, 0))\n\t\t\tmemcpy(ctx->u.aes.key, key, key_len);\n\t\tbreak;\n\t}\n\tctx->u.aes.key_len = key_len / 2;\n\tsg_init_one(&ctx->u.aes.key_sg, ctx->u.aes.key, key_len);\n\n\treturn crypto_skcipher_setkey(ctx->u.aes.tfm_skcipher, key, key_len);\n}\n\nstatic int ccp_aes_xts_crypt(struct skcipher_request *req,\n\t\t\t     unsigned int encrypt)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct ccp_ctx *ctx = crypto_skcipher_ctx_dma(tfm);\n\tstruct ccp_aes_req_ctx *rctx = skcipher_request_ctx_dma(req);\n\tunsigned int ccpversion = ccp_version();\n\tunsigned int fallback = 0;\n\tunsigned int unit;\n\tu32 unit_size;\n\tint ret;\n\n\tif (!ctx->u.aes.key_len)\n\t\treturn -EINVAL;\n\n\tif (!req->iv)\n\t\treturn -EINVAL;\n\n\t \n\tunit_size = CCP_XTS_AES_UNIT_SIZE__LAST;\n\tfor (unit = 0; unit < ARRAY_SIZE(xts_unit_sizes); unit++) {\n\t\tif (req->cryptlen == xts_unit_sizes[unit].size) {\n\t\t\tunit_size = unit;\n\t\t\tbreak;\n\t\t}\n\t}\n\t \n\tif (unit_size == CCP_XTS_AES_UNIT_SIZE__LAST)\n\t\tfallback = 1;\n\tif ((ccpversion < CCP_VERSION(5, 0)) &&\n\t    (ctx->u.aes.key_len != AES_KEYSIZE_128))\n\t\tfallback = 1;\n\tif ((ctx->u.aes.key_len != AES_KEYSIZE_128) &&\n\t    (ctx->u.aes.key_len != AES_KEYSIZE_256))\n\t\tfallback = 1;\n\tif (fallback) {\n\t\t \n\t\tskcipher_request_set_tfm(&rctx->fallback_req,\n\t\t\t\t\t ctx->u.aes.tfm_skcipher);\n\t\tskcipher_request_set_callback(&rctx->fallback_req,\n\t\t\t\t\t      req->base.flags,\n\t\t\t\t\t      req->base.complete,\n\t\t\t\t\t      req->base.data);\n\t\tskcipher_request_set_crypt(&rctx->fallback_req, req->src,\n\t\t\t\t\t   req->dst, req->cryptlen, req->iv);\n\t\tret = encrypt ? crypto_skcipher_encrypt(&rctx->fallback_req) :\n\t\t\t\tcrypto_skcipher_decrypt(&rctx->fallback_req);\n\t\treturn ret;\n\t}\n\n\tmemcpy(rctx->iv, req->iv, AES_BLOCK_SIZE);\n\tsg_init_one(&rctx->iv_sg, rctx->iv, AES_BLOCK_SIZE);\n\n\tmemset(&rctx->cmd, 0, sizeof(rctx->cmd));\n\tINIT_LIST_HEAD(&rctx->cmd.entry);\n\trctx->cmd.engine = CCP_ENGINE_XTS_AES_128;\n\trctx->cmd.u.xts.type = CCP_AES_TYPE_128;\n\trctx->cmd.u.xts.action = (encrypt) ? CCP_AES_ACTION_ENCRYPT\n\t\t\t\t\t   : CCP_AES_ACTION_DECRYPT;\n\trctx->cmd.u.xts.unit_size = unit_size;\n\trctx->cmd.u.xts.key = &ctx->u.aes.key_sg;\n\trctx->cmd.u.xts.key_len = ctx->u.aes.key_len;\n\trctx->cmd.u.xts.iv = &rctx->iv_sg;\n\trctx->cmd.u.xts.iv_len = AES_BLOCK_SIZE;\n\trctx->cmd.u.xts.src = req->src;\n\trctx->cmd.u.xts.src_len = req->cryptlen;\n\trctx->cmd.u.xts.dst = req->dst;\n\n\tret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);\n\n\treturn ret;\n}\n\nstatic int ccp_aes_xts_encrypt(struct skcipher_request *req)\n{\n\treturn ccp_aes_xts_crypt(req, 1);\n}\n\nstatic int ccp_aes_xts_decrypt(struct skcipher_request *req)\n{\n\treturn ccp_aes_xts_crypt(req, 0);\n}\n\nstatic int ccp_aes_xts_init_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct ccp_ctx *ctx = crypto_skcipher_ctx_dma(tfm);\n\tstruct crypto_skcipher *fallback_tfm;\n\n\tctx->complete = ccp_aes_xts_complete;\n\tctx->u.aes.key_len = 0;\n\n\tfallback_tfm = crypto_alloc_skcipher(\"xts(aes)\", 0,\n\t\t\t\t\t     CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(fallback_tfm)) {\n\t\tpr_warn(\"could not load fallback driver xts(aes)\\n\");\n\t\treturn PTR_ERR(fallback_tfm);\n\t}\n\tctx->u.aes.tfm_skcipher = fallback_tfm;\n\n\tcrypto_skcipher_set_reqsize_dma(tfm,\n\t\t\t\t\tsizeof(struct ccp_aes_req_ctx) +\n\t\t\t\t\tcrypto_skcipher_reqsize(fallback_tfm));\n\n\treturn 0;\n}\n\nstatic void ccp_aes_xts_exit_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct ccp_ctx *ctx = crypto_skcipher_ctx_dma(tfm);\n\n\tcrypto_free_skcipher(ctx->u.aes.tfm_skcipher);\n}\n\nstatic int ccp_register_aes_xts_alg(struct list_head *head,\n\t\t\t\t    const struct ccp_aes_xts_def *def)\n{\n\tstruct ccp_crypto_skcipher_alg *ccp_alg;\n\tstruct skcipher_alg *alg;\n\tint ret;\n\n\tccp_alg = kzalloc(sizeof(*ccp_alg), GFP_KERNEL);\n\tif (!ccp_alg)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&ccp_alg->entry);\n\n\talg = &ccp_alg->alg;\n\n\tsnprintf(alg->base.cra_name, CRYPTO_MAX_ALG_NAME, \"%s\", def->name);\n\tsnprintf(alg->base.cra_driver_name, CRYPTO_MAX_ALG_NAME, \"%s\",\n\t\t def->drv_name);\n\talg->base.cra_flags\t= CRYPTO_ALG_ASYNC |\n\t\t\t\t  CRYPTO_ALG_ALLOCATES_MEMORY |\n\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t  CRYPTO_ALG_NEED_FALLBACK;\n\talg->base.cra_blocksize\t= AES_BLOCK_SIZE;\n\talg->base.cra_ctxsize\t= sizeof(struct ccp_ctx) +\n\t\t\t\t  crypto_dma_padding();\n\talg->base.cra_priority\t= CCP_CRA_PRIORITY;\n\talg->base.cra_module\t= THIS_MODULE;\n\n\talg->setkey\t\t= ccp_aes_xts_setkey;\n\talg->encrypt\t\t= ccp_aes_xts_encrypt;\n\talg->decrypt\t\t= ccp_aes_xts_decrypt;\n\talg->min_keysize\t= AES_MIN_KEY_SIZE * 2;\n\talg->max_keysize\t= AES_MAX_KEY_SIZE * 2;\n\talg->ivsize\t\t= AES_BLOCK_SIZE;\n\talg->init\t\t= ccp_aes_xts_init_tfm;\n\talg->exit\t\t= ccp_aes_xts_exit_tfm;\n\n\tret = crypto_register_skcipher(alg);\n\tif (ret) {\n\t\tpr_err(\"%s skcipher algorithm registration error (%d)\\n\",\n\t\t       alg->base.cra_name, ret);\n\t\tkfree(ccp_alg);\n\t\treturn ret;\n\t}\n\n\tlist_add(&ccp_alg->entry, head);\n\n\treturn 0;\n}\n\nint ccp_register_aes_xts_algs(struct list_head *head)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < ARRAY_SIZE(aes_xts_algs); i++) {\n\t\tret = ccp_register_aes_xts_alg(head, &aes_xts_algs[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}