{
  "module_name": "ccp-crypto-sha.c",
  "hash_id": "b0e8089adda6a7a67738ae89a91683660ee7a3f223997e08dcf0349fb68070d7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/ccp/ccp-crypto-sha.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/delay.h>\n#include <linux/scatterlist.h>\n#include <linux/crypto.h>\n#include <crypto/algapi.h>\n#include <crypto/hash.h>\n#include <crypto/hmac.h>\n#include <crypto/internal/hash.h>\n#include <crypto/sha1.h>\n#include <crypto/sha2.h>\n#include <crypto/scatterwalk.h>\n#include <linux/string.h>\n\n#include \"ccp-crypto.h\"\n\nstatic int ccp_sha_complete(struct crypto_async_request *async_req, int ret)\n{\n\tstruct ahash_request *req = ahash_request_cast(async_req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ccp_sha_req_ctx *rctx = ahash_request_ctx_dma(req);\n\tunsigned int digest_size = crypto_ahash_digestsize(tfm);\n\n\tif (ret)\n\t\tgoto e_free;\n\n\tif (rctx->hash_rem) {\n\t\t \n\t\tunsigned int offset = rctx->nbytes - rctx->hash_rem;\n\n\t\tscatterwalk_map_and_copy(rctx->buf, rctx->src,\n\t\t\t\t\t offset, rctx->hash_rem, 0);\n\t\trctx->buf_count = rctx->hash_rem;\n\t} else {\n\t\trctx->buf_count = 0;\n\t}\n\n\t \n\tif (req->result && rctx->final)\n\t\tmemcpy(req->result, rctx->ctx, digest_size);\n\ne_free:\n\tsg_free_table(&rctx->data_sg);\n\n\treturn ret;\n}\n\nstatic int ccp_do_sha_update(struct ahash_request *req, unsigned int nbytes,\n\t\t\t     unsigned int final)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ccp_ctx *ctx = crypto_ahash_ctx_dma(tfm);\n\tstruct ccp_sha_req_ctx *rctx = ahash_request_ctx_dma(req);\n\tstruct scatterlist *sg;\n\tunsigned int block_size =\n\t\tcrypto_tfm_alg_blocksize(crypto_ahash_tfm(tfm));\n\tunsigned int sg_count;\n\tgfp_t gfp;\n\tu64 len;\n\tint ret;\n\n\tlen = (u64)rctx->buf_count + (u64)nbytes;\n\n\tif (!final && (len <= block_size)) {\n\t\tscatterwalk_map_and_copy(rctx->buf + rctx->buf_count, req->src,\n\t\t\t\t\t 0, nbytes, 0);\n\t\trctx->buf_count += nbytes;\n\n\t\treturn 0;\n\t}\n\n\trctx->src = req->src;\n\trctx->nbytes = nbytes;\n\n\trctx->final = final;\n\trctx->hash_rem = final ? 0 : len & (block_size - 1);\n\trctx->hash_cnt = len - rctx->hash_rem;\n\tif (!final && !rctx->hash_rem) {\n\t\t \n\t\trctx->hash_cnt -= block_size;\n\t\trctx->hash_rem = block_size;\n\t}\n\n\t \n\tsg_init_one(&rctx->ctx_sg, rctx->ctx, sizeof(rctx->ctx));\n\n\tsg = NULL;\n\tif (rctx->buf_count && nbytes) {\n\t\t \n\t\tgfp = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?\n\t\t\tGFP_KERNEL : GFP_ATOMIC;\n\t\tsg_count = sg_nents(req->src) + 1;\n\t\tret = sg_alloc_table(&rctx->data_sg, sg_count, gfp);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tsg_init_one(&rctx->buf_sg, rctx->buf, rctx->buf_count);\n\t\tsg = ccp_crypto_sg_table_add(&rctx->data_sg, &rctx->buf_sg);\n\t\tif (!sg) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_free;\n\t\t}\n\t\tsg = ccp_crypto_sg_table_add(&rctx->data_sg, req->src);\n\t\tif (!sg) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto e_free;\n\t\t}\n\t\tsg_mark_end(sg);\n\n\t\tsg = rctx->data_sg.sgl;\n\t} else if (rctx->buf_count) {\n\t\tsg_init_one(&rctx->buf_sg, rctx->buf, rctx->buf_count);\n\n\t\tsg = &rctx->buf_sg;\n\t} else if (nbytes) {\n\t\tsg = req->src;\n\t}\n\n\trctx->msg_bits += (rctx->hash_cnt << 3);\t \n\n\tmemset(&rctx->cmd, 0, sizeof(rctx->cmd));\n\tINIT_LIST_HEAD(&rctx->cmd.entry);\n\trctx->cmd.engine = CCP_ENGINE_SHA;\n\trctx->cmd.u.sha.type = rctx->type;\n\trctx->cmd.u.sha.ctx = &rctx->ctx_sg;\n\n\tswitch (rctx->type) {\n\tcase CCP_SHA_TYPE_1:\n\t\trctx->cmd.u.sha.ctx_len = SHA1_DIGEST_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_224:\n\t\trctx->cmd.u.sha.ctx_len = SHA224_DIGEST_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_256:\n\t\trctx->cmd.u.sha.ctx_len = SHA256_DIGEST_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_384:\n\t\trctx->cmd.u.sha.ctx_len = SHA384_DIGEST_SIZE;\n\t\tbreak;\n\tcase CCP_SHA_TYPE_512:\n\t\trctx->cmd.u.sha.ctx_len = SHA512_DIGEST_SIZE;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\n\trctx->cmd.u.sha.src = sg;\n\trctx->cmd.u.sha.src_len = rctx->hash_cnt;\n\trctx->cmd.u.sha.opad = ctx->u.sha.key_len ?\n\t\t&ctx->u.sha.opad_sg : NULL;\n\trctx->cmd.u.sha.opad_len = ctx->u.sha.key_len ?\n\t\tctx->u.sha.opad_count : 0;\n\trctx->cmd.u.sha.first = rctx->first;\n\trctx->cmd.u.sha.final = rctx->final;\n\trctx->cmd.u.sha.msg_bits = rctx->msg_bits;\n\n\trctx->first = 0;\n\n\tret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);\n\n\treturn ret;\n\ne_free:\n\tsg_free_table(&rctx->data_sg);\n\n\treturn ret;\n}\n\nstatic int ccp_sha_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct ccp_ctx *ctx = crypto_ahash_ctx_dma(tfm);\n\tstruct ccp_sha_req_ctx *rctx = ahash_request_ctx_dma(req);\n\tstruct ccp_crypto_ahash_alg *alg =\n\t\tccp_crypto_ahash_alg(crypto_ahash_tfm(tfm));\n\tunsigned int block_size =\n\t\tcrypto_tfm_alg_blocksize(crypto_ahash_tfm(tfm));\n\n\tmemset(rctx, 0, sizeof(*rctx));\n\n\trctx->type = alg->type;\n\trctx->first = 1;\n\n\tif (ctx->u.sha.key_len) {\n\t\t \n\t\tmemcpy(rctx->buf, ctx->u.sha.ipad, block_size);\n\t\trctx->buf_count = block_size;\n\t}\n\n\treturn 0;\n}\n\nstatic int ccp_sha_update(struct ahash_request *req)\n{\n\treturn ccp_do_sha_update(req, req->nbytes, 0);\n}\n\nstatic int ccp_sha_final(struct ahash_request *req)\n{\n\treturn ccp_do_sha_update(req, 0, 1);\n}\n\nstatic int ccp_sha_finup(struct ahash_request *req)\n{\n\treturn ccp_do_sha_update(req, req->nbytes, 1);\n}\n\nstatic int ccp_sha_digest(struct ahash_request *req)\n{\n\tint ret;\n\n\tret = ccp_sha_init(req);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ccp_sha_finup(req);\n}\n\nstatic int ccp_sha_export(struct ahash_request *req, void *out)\n{\n\tstruct ccp_sha_req_ctx *rctx = ahash_request_ctx_dma(req);\n\tstruct ccp_sha_exp_ctx state;\n\n\t \n\tmemset(&state, 0, sizeof(state));\n\n\tstate.type = rctx->type;\n\tstate.msg_bits = rctx->msg_bits;\n\tstate.first = rctx->first;\n\tmemcpy(state.ctx, rctx->ctx, sizeof(state.ctx));\n\tstate.buf_count = rctx->buf_count;\n\tmemcpy(state.buf, rctx->buf, sizeof(state.buf));\n\n\t \n\tmemcpy(out, &state, sizeof(state));\n\n\treturn 0;\n}\n\nstatic int ccp_sha_import(struct ahash_request *req, const void *in)\n{\n\tstruct ccp_sha_req_ctx *rctx = ahash_request_ctx_dma(req);\n\tstruct ccp_sha_exp_ctx state;\n\n\t \n\tmemcpy(&state, in, sizeof(state));\n\n\tmemset(rctx, 0, sizeof(*rctx));\n\trctx->type = state.type;\n\trctx->msg_bits = state.msg_bits;\n\trctx->first = state.first;\n\tmemcpy(rctx->ctx, state.ctx, sizeof(rctx->ctx));\n\trctx->buf_count = state.buf_count;\n\tmemcpy(rctx->buf, state.buf, sizeof(rctx->buf));\n\n\treturn 0;\n}\n\nstatic int ccp_sha_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t  unsigned int key_len)\n{\n\tstruct ccp_ctx *ctx = crypto_ahash_ctx_dma(tfm);\n\tstruct crypto_shash *shash = ctx->u.sha.hmac_tfm;\n\tunsigned int block_size = crypto_shash_blocksize(shash);\n\tunsigned int digest_size = crypto_shash_digestsize(shash);\n\tint i, ret;\n\n\t \n\tctx->u.sha.key_len = 0;\n\n\t \n\tmemset(ctx->u.sha.key, 0, sizeof(ctx->u.sha.key));\n\n\tif (key_len > block_size) {\n\t\t \n\t\tret = crypto_shash_tfm_digest(shash, key, key_len,\n\t\t\t\t\t      ctx->u.sha.key);\n\t\tif (ret)\n\t\t\treturn -EINVAL;\n\n\t\tkey_len = digest_size;\n\t} else {\n\t\tmemcpy(ctx->u.sha.key, key, key_len);\n\t}\n\n\tfor (i = 0; i < block_size; i++) {\n\t\tctx->u.sha.ipad[i] = ctx->u.sha.key[i] ^ HMAC_IPAD_VALUE;\n\t\tctx->u.sha.opad[i] = ctx->u.sha.key[i] ^ HMAC_OPAD_VALUE;\n\t}\n\n\tsg_init_one(&ctx->u.sha.opad_sg, ctx->u.sha.opad, block_size);\n\tctx->u.sha.opad_count = block_size;\n\n\tctx->u.sha.key_len = key_len;\n\n\treturn 0;\n}\n\nstatic int ccp_sha_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct crypto_ahash *ahash = __crypto_ahash_cast(tfm);\n\tstruct ccp_ctx *ctx = crypto_ahash_ctx_dma(ahash);\n\n\tctx->complete = ccp_sha_complete;\n\tctx->u.sha.key_len = 0;\n\n\tcrypto_ahash_set_reqsize_dma(ahash, sizeof(struct ccp_sha_req_ctx));\n\n\treturn 0;\n}\n\nstatic void ccp_sha_cra_exit(struct crypto_tfm *tfm)\n{\n}\n\nstatic int ccp_hmac_sha_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct ccp_ctx *ctx = crypto_tfm_ctx_dma(tfm);\n\tstruct ccp_crypto_ahash_alg *alg = ccp_crypto_ahash_alg(tfm);\n\tstruct crypto_shash *hmac_tfm;\n\n\thmac_tfm = crypto_alloc_shash(alg->child_alg, 0, 0);\n\tif (IS_ERR(hmac_tfm)) {\n\t\tpr_warn(\"could not load driver %s need for HMAC support\\n\",\n\t\t\talg->child_alg);\n\t\treturn PTR_ERR(hmac_tfm);\n\t}\n\n\tctx->u.sha.hmac_tfm = hmac_tfm;\n\n\treturn ccp_sha_cra_init(tfm);\n}\n\nstatic void ccp_hmac_sha_cra_exit(struct crypto_tfm *tfm)\n{\n\tstruct ccp_ctx *ctx = crypto_tfm_ctx_dma(tfm);\n\n\tif (ctx->u.sha.hmac_tfm)\n\t\tcrypto_free_shash(ctx->u.sha.hmac_tfm);\n\n\tccp_sha_cra_exit(tfm);\n}\n\nstruct ccp_sha_def {\n\tunsigned int version;\n\tconst char *name;\n\tconst char *drv_name;\n\tenum ccp_sha_type type;\n\tu32 digest_size;\n\tu32 block_size;\n};\n\nstatic struct ccp_sha_def sha_algs[] = {\n\t{\n\t\t.version\t= CCP_VERSION(3, 0),\n\t\t.name\t\t= \"sha1\",\n\t\t.drv_name\t= \"sha1-ccp\",\n\t\t.type\t\t= CCP_SHA_TYPE_1,\n\t\t.digest_size\t= SHA1_DIGEST_SIZE,\n\t\t.block_size\t= SHA1_BLOCK_SIZE,\n\t},\n\t{\n\t\t.version\t= CCP_VERSION(3, 0),\n\t\t.name\t\t= \"sha224\",\n\t\t.drv_name\t= \"sha224-ccp\",\n\t\t.type\t\t= CCP_SHA_TYPE_224,\n\t\t.digest_size\t= SHA224_DIGEST_SIZE,\n\t\t.block_size\t= SHA224_BLOCK_SIZE,\n\t},\n\t{\n\t\t.version\t= CCP_VERSION(3, 0),\n\t\t.name\t\t= \"sha256\",\n\t\t.drv_name\t= \"sha256-ccp\",\n\t\t.type\t\t= CCP_SHA_TYPE_256,\n\t\t.digest_size\t= SHA256_DIGEST_SIZE,\n\t\t.block_size\t= SHA256_BLOCK_SIZE,\n\t},\n\t{\n\t\t.version\t= CCP_VERSION(5, 0),\n\t\t.name\t\t= \"sha384\",\n\t\t.drv_name\t= \"sha384-ccp\",\n\t\t.type\t\t= CCP_SHA_TYPE_384,\n\t\t.digest_size\t= SHA384_DIGEST_SIZE,\n\t\t.block_size\t= SHA384_BLOCK_SIZE,\n\t},\n\t{\n\t\t.version\t= CCP_VERSION(5, 0),\n\t\t.name\t\t= \"sha512\",\n\t\t.drv_name\t= \"sha512-ccp\",\n\t\t.type\t\t= CCP_SHA_TYPE_512,\n\t\t.digest_size\t= SHA512_DIGEST_SIZE,\n\t\t.block_size\t= SHA512_BLOCK_SIZE,\n\t},\n};\n\nstatic int ccp_register_hmac_alg(struct list_head *head,\n\t\t\t\t const struct ccp_sha_def *def,\n\t\t\t\t const struct ccp_crypto_ahash_alg *base_alg)\n{\n\tstruct ccp_crypto_ahash_alg *ccp_alg;\n\tstruct ahash_alg *alg;\n\tstruct hash_alg_common *halg;\n\tstruct crypto_alg *base;\n\tint ret;\n\n\tccp_alg = kzalloc(sizeof(*ccp_alg), GFP_KERNEL);\n\tif (!ccp_alg)\n\t\treturn -ENOMEM;\n\n\t \n\t*ccp_alg = *base_alg;\n\tINIT_LIST_HEAD(&ccp_alg->entry);\n\n\tstrscpy(ccp_alg->child_alg, def->name, CRYPTO_MAX_ALG_NAME);\n\n\talg = &ccp_alg->alg;\n\talg->setkey = ccp_sha_setkey;\n\n\thalg = &alg->halg;\n\n\tbase = &halg->base;\n\tsnprintf(base->cra_name, CRYPTO_MAX_ALG_NAME, \"hmac(%s)\", def->name);\n\tsnprintf(base->cra_driver_name, CRYPTO_MAX_ALG_NAME, \"hmac-%s\",\n\t\t def->drv_name);\n\tbase->cra_init = ccp_hmac_sha_cra_init;\n\tbase->cra_exit = ccp_hmac_sha_cra_exit;\n\n\tret = crypto_register_ahash(alg);\n\tif (ret) {\n\t\tpr_err(\"%s ahash algorithm registration error (%d)\\n\",\n\t\t       base->cra_name, ret);\n\t\tkfree(ccp_alg);\n\t\treturn ret;\n\t}\n\n\tlist_add(&ccp_alg->entry, head);\n\n\treturn ret;\n}\n\nstatic int ccp_register_sha_alg(struct list_head *head,\n\t\t\t\tconst struct ccp_sha_def *def)\n{\n\tstruct ccp_crypto_ahash_alg *ccp_alg;\n\tstruct ahash_alg *alg;\n\tstruct hash_alg_common *halg;\n\tstruct crypto_alg *base;\n\tint ret;\n\n\tccp_alg = kzalloc(sizeof(*ccp_alg), GFP_KERNEL);\n\tif (!ccp_alg)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&ccp_alg->entry);\n\n\tccp_alg->type = def->type;\n\n\talg = &ccp_alg->alg;\n\talg->init = ccp_sha_init;\n\talg->update = ccp_sha_update;\n\talg->final = ccp_sha_final;\n\talg->finup = ccp_sha_finup;\n\talg->digest = ccp_sha_digest;\n\talg->export = ccp_sha_export;\n\talg->import = ccp_sha_import;\n\n\thalg = &alg->halg;\n\thalg->digestsize = def->digest_size;\n\thalg->statesize = sizeof(struct ccp_sha_exp_ctx);\n\n\tbase = &halg->base;\n\tsnprintf(base->cra_name, CRYPTO_MAX_ALG_NAME, \"%s\", def->name);\n\tsnprintf(base->cra_driver_name, CRYPTO_MAX_ALG_NAME, \"%s\",\n\t\t def->drv_name);\n\tbase->cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t  CRYPTO_ALG_ALLOCATES_MEMORY |\n\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t  CRYPTO_ALG_NEED_FALLBACK;\n\tbase->cra_blocksize = def->block_size;\n\tbase->cra_ctxsize = sizeof(struct ccp_ctx) + crypto_dma_padding();\n\tbase->cra_priority = CCP_CRA_PRIORITY;\n\tbase->cra_init = ccp_sha_cra_init;\n\tbase->cra_exit = ccp_sha_cra_exit;\n\tbase->cra_module = THIS_MODULE;\n\n\tret = crypto_register_ahash(alg);\n\tif (ret) {\n\t\tpr_err(\"%s ahash algorithm registration error (%d)\\n\",\n\t\t       base->cra_name, ret);\n\t\tkfree(ccp_alg);\n\t\treturn ret;\n\t}\n\n\tlist_add(&ccp_alg->entry, head);\n\n\tret = ccp_register_hmac_alg(head, def, ccp_alg);\n\n\treturn ret;\n}\n\nint ccp_register_sha_algs(struct list_head *head)\n{\n\tint i, ret;\n\tunsigned int ccpversion = ccp_version();\n\n\tfor (i = 0; i < ARRAY_SIZE(sha_algs); i++) {\n\t\tif (sha_algs[i].version > ccpversion)\n\t\t\tcontinue;\n\t\tret = ccp_register_sha_alg(head, &sha_algs[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}