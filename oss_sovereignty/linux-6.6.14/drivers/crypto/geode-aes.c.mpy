{
  "module_name": "geode-aes.c",
  "hash_id": "3c56573b9951ec03b85340695d86dbb972dde657f1b193927707a9f7e5220470",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/geode-aes.c",
  "human_readable_source": "\n  \n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/pci.h>\n#include <linux/pci_ids.h>\n#include <linux/crypto.h>\n#include <linux/spinlock.h>\n#include <crypto/algapi.h>\n#include <crypto/aes.h>\n#include <crypto/internal/cipher.h>\n#include <crypto/internal/skcipher.h>\n\n#include <linux/io.h>\n#include <linux/delay.h>\n\n#include \"geode-aes.h\"\n\n \n\nstatic void __iomem *_iobase;\nstatic DEFINE_SPINLOCK(lock);\n\n \nstatic inline void\n_writefield(u32 offset, const void *value)\n{\n\tint i;\n\n\tfor (i = 0; i < 4; i++)\n\t\tiowrite32(((const u32 *) value)[i], _iobase + offset + (i * 4));\n}\n\n \nstatic inline void\n_readfield(u32 offset, void *value)\n{\n\tint i;\n\n\tfor (i = 0; i < 4; i++)\n\t\t((u32 *) value)[i] = ioread32(_iobase + offset + (i * 4));\n}\n\nstatic int\ndo_crypt(const void *src, void *dst, u32 len, u32 flags)\n{\n\tu32 status;\n\tu32 counter = AES_OP_TIMEOUT;\n\n\tiowrite32(virt_to_phys((void *)src), _iobase + AES_SOURCEA_REG);\n\tiowrite32(virt_to_phys(dst), _iobase + AES_DSTA_REG);\n\tiowrite32(len,  _iobase + AES_LENA_REG);\n\n\t \n\tiowrite32(AES_CTRL_START | flags, _iobase + AES_CTRLA_REG);\n\n\tdo {\n\t\tstatus = ioread32(_iobase + AES_INTR_REG);\n\t\tcpu_relax();\n\t} while (!(status & AES_INTRA_PENDING) && --counter);\n\n\t \n\tiowrite32((status & 0xFF) | AES_INTRA_PENDING, _iobase + AES_INTR_REG);\n\treturn counter ? 0 : 1;\n}\n\nstatic void\ngeode_aes_crypt(const struct geode_aes_tfm_ctx *tctx, const void *src,\n\t\tvoid *dst, u32 len, u8 *iv, int mode, int dir)\n{\n\tu32 flags = 0;\n\tunsigned long iflags;\n\tint ret;\n\n\t \n\n\tflags |= (AES_CTRL_DCA | AES_CTRL_SCA);\n\n\tif (dir == AES_DIR_ENCRYPT)\n\t\tflags |= AES_CTRL_ENCRYPT;\n\n\t \n\n\tspin_lock_irqsave(&lock, iflags);\n\n\tif (mode == AES_MODE_CBC) {\n\t\tflags |= AES_CTRL_CBC;\n\t\t_writefield(AES_WRITEIV0_REG, iv);\n\t}\n\n\tflags |= AES_CTRL_WRKEY;\n\t_writefield(AES_WRITEKEY0_REG, tctx->key);\n\n\tret = do_crypt(src, dst, len, flags);\n\tBUG_ON(ret);\n\n\tif (mode == AES_MODE_CBC)\n\t\t_readfield(AES_WRITEIV0_REG, iv);\n\n\tspin_unlock_irqrestore(&lock, iflags);\n}\n\n \n\nstatic int geode_setkey_cip(struct crypto_tfm *tfm, const u8 *key,\n\t\tunsigned int len)\n{\n\tstruct geode_aes_tfm_ctx *tctx = crypto_tfm_ctx(tfm);\n\n\ttctx->keylen = len;\n\n\tif (len == AES_KEYSIZE_128) {\n\t\tmemcpy(tctx->key, key, len);\n\t\treturn 0;\n\t}\n\n\tif (len != AES_KEYSIZE_192 && len != AES_KEYSIZE_256)\n\t\t \n\t\treturn -EINVAL;\n\n\t \n\ttctx->fallback.cip->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\ttctx->fallback.cip->base.crt_flags |=\n\t\t(tfm->crt_flags & CRYPTO_TFM_REQ_MASK);\n\n\treturn crypto_cipher_setkey(tctx->fallback.cip, key, len);\n}\n\nstatic int geode_setkey_skcipher(struct crypto_skcipher *tfm, const u8 *key,\n\t\t\t\t unsigned int len)\n{\n\tstruct geode_aes_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\n\ttctx->keylen = len;\n\n\tif (len == AES_KEYSIZE_128) {\n\t\tmemcpy(tctx->key, key, len);\n\t\treturn 0;\n\t}\n\n\tif (len != AES_KEYSIZE_192 && len != AES_KEYSIZE_256)\n\t\t \n\t\treturn -EINVAL;\n\n\t \n\tcrypto_skcipher_clear_flags(tctx->fallback.skcipher,\n\t\t\t\t    CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(tctx->fallback.skcipher,\n\t\t\t\t  crypto_skcipher_get_flags(tfm) &\n\t\t\t\t  CRYPTO_TFM_REQ_MASK);\n\treturn crypto_skcipher_setkey(tctx->fallback.skcipher, key, len);\n}\n\nstatic void\ngeode_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct geode_aes_tfm_ctx *tctx = crypto_tfm_ctx(tfm);\n\n\tif (unlikely(tctx->keylen != AES_KEYSIZE_128)) {\n\t\tcrypto_cipher_encrypt_one(tctx->fallback.cip, out, in);\n\t\treturn;\n\t}\n\n\tgeode_aes_crypt(tctx, in, out, AES_BLOCK_SIZE, NULL,\n\t\t\tAES_MODE_ECB, AES_DIR_ENCRYPT);\n}\n\n\nstatic void\ngeode_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)\n{\n\tconst struct geode_aes_tfm_ctx *tctx = crypto_tfm_ctx(tfm);\n\n\tif (unlikely(tctx->keylen != AES_KEYSIZE_128)) {\n\t\tcrypto_cipher_decrypt_one(tctx->fallback.cip, out, in);\n\t\treturn;\n\t}\n\n\tgeode_aes_crypt(tctx, in, out, AES_BLOCK_SIZE, NULL,\n\t\t\tAES_MODE_ECB, AES_DIR_DECRYPT);\n}\n\nstatic int fallback_init_cip(struct crypto_tfm *tfm)\n{\n\tconst char *name = crypto_tfm_alg_name(tfm);\n\tstruct geode_aes_tfm_ctx *tctx = crypto_tfm_ctx(tfm);\n\n\ttctx->fallback.cip = crypto_alloc_cipher(name, 0,\n\t\t\t\t\t\t CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(tctx->fallback.cip)) {\n\t\tprintk(KERN_ERR \"Error allocating fallback algo %s\\n\", name);\n\t\treturn PTR_ERR(tctx->fallback.cip);\n\t}\n\n\treturn 0;\n}\n\nstatic void fallback_exit_cip(struct crypto_tfm *tfm)\n{\n\tstruct geode_aes_tfm_ctx *tctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_cipher(tctx->fallback.cip);\n}\n\nstatic struct crypto_alg geode_alg = {\n\t.cra_name\t\t\t=\t\"aes\",\n\t.cra_driver_name\t=\t\"geode-aes\",\n\t.cra_priority\t\t=\t300,\n\t.cra_alignmask\t\t=\t15,\n\t.cra_flags\t\t\t=\tCRYPTO_ALG_TYPE_CIPHER |\n\t\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t.cra_init\t\t\t=\tfallback_init_cip,\n\t.cra_exit\t\t\t=\tfallback_exit_cip,\n\t.cra_blocksize\t\t=\tAES_BLOCK_SIZE,\n\t.cra_ctxsize\t\t=\tsizeof(struct geode_aes_tfm_ctx),\n\t.cra_module\t\t\t=\tTHIS_MODULE,\n\t.cra_u\t\t\t\t=\t{\n\t\t.cipher\t=\t{\n\t\t\t.cia_min_keysize\t=\tAES_MIN_KEY_SIZE,\n\t\t\t.cia_max_keysize\t=\tAES_MAX_KEY_SIZE,\n\t\t\t.cia_setkey\t\t\t=\tgeode_setkey_cip,\n\t\t\t.cia_encrypt\t\t=\tgeode_encrypt,\n\t\t\t.cia_decrypt\t\t=\tgeode_decrypt\n\t\t}\n\t}\n};\n\nstatic int geode_init_skcipher(struct crypto_skcipher *tfm)\n{\n\tconst char *name = crypto_tfm_alg_name(&tfm->base);\n\tstruct geode_aes_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\n\ttctx->fallback.skcipher =\n\t\tcrypto_alloc_skcipher(name, 0, CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t      CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(tctx->fallback.skcipher)) {\n\t\tprintk(KERN_ERR \"Error allocating fallback algo %s\\n\", name);\n\t\treturn PTR_ERR(tctx->fallback.skcipher);\n\t}\n\n\tcrypto_skcipher_set_reqsize(tfm, sizeof(struct skcipher_request) +\n\t\t\t\t    crypto_skcipher_reqsize(tctx->fallback.skcipher));\n\treturn 0;\n}\n\nstatic void geode_exit_skcipher(struct crypto_skcipher *tfm)\n{\n\tstruct geode_aes_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\n\tcrypto_free_skcipher(tctx->fallback.skcipher);\n}\n\nstatic int geode_skcipher_crypt(struct skcipher_request *req, int mode, int dir)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tconst struct geode_aes_tfm_ctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct skcipher_walk walk;\n\tunsigned int nbytes;\n\tint err;\n\n\tif (unlikely(tctx->keylen != AES_KEYSIZE_128)) {\n\t\tstruct skcipher_request *subreq = skcipher_request_ctx(req);\n\n\t\t*subreq = *req;\n\t\tskcipher_request_set_tfm(subreq, tctx->fallback.skcipher);\n\t\tif (dir == AES_DIR_DECRYPT)\n\t\t\treturn crypto_skcipher_decrypt(subreq);\n\t\telse\n\t\t\treturn crypto_skcipher_encrypt(subreq);\n\t}\n\n\terr = skcipher_walk_virt(&walk, req, false);\n\n\twhile ((nbytes = walk.nbytes) != 0) {\n\t\tgeode_aes_crypt(tctx, walk.src.virt.addr, walk.dst.virt.addr,\n\t\t\t\tround_down(nbytes, AES_BLOCK_SIZE),\n\t\t\t\twalk.iv, mode, dir);\n\t\terr = skcipher_walk_done(&walk, nbytes % AES_BLOCK_SIZE);\n\t}\n\n\treturn err;\n}\n\nstatic int geode_cbc_encrypt(struct skcipher_request *req)\n{\n\treturn geode_skcipher_crypt(req, AES_MODE_CBC, AES_DIR_ENCRYPT);\n}\n\nstatic int geode_cbc_decrypt(struct skcipher_request *req)\n{\n\treturn geode_skcipher_crypt(req, AES_MODE_CBC, AES_DIR_DECRYPT);\n}\n\nstatic int geode_ecb_encrypt(struct skcipher_request *req)\n{\n\treturn geode_skcipher_crypt(req, AES_MODE_ECB, AES_DIR_ENCRYPT);\n}\n\nstatic int geode_ecb_decrypt(struct skcipher_request *req)\n{\n\treturn geode_skcipher_crypt(req, AES_MODE_ECB, AES_DIR_DECRYPT);\n}\n\nstatic struct skcipher_alg geode_skcipher_algs[] = {\n\t{\n\t\t.base.cra_name\t\t= \"cbc(aes)\",\n\t\t.base.cra_driver_name\t= \"cbc-aes-geode\",\n\t\t.base.cra_priority\t= 400,\n\t\t.base.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t  CRYPTO_ALG_NEED_FALLBACK,\n\t\t.base.cra_blocksize\t= AES_BLOCK_SIZE,\n\t\t.base.cra_ctxsize\t= sizeof(struct geode_aes_tfm_ctx),\n\t\t.base.cra_alignmask\t= 15,\n\t\t.base.cra_module\t= THIS_MODULE,\n\t\t.init\t\t\t= geode_init_skcipher,\n\t\t.exit\t\t\t= geode_exit_skcipher,\n\t\t.setkey\t\t\t= geode_setkey_skcipher,\n\t\t.encrypt\t\t= geode_cbc_encrypt,\n\t\t.decrypt\t\t= geode_cbc_decrypt,\n\t\t.min_keysize\t\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t\t= AES_MAX_KEY_SIZE,\n\t\t.ivsize\t\t\t= AES_BLOCK_SIZE,\n\t}, {\n\t\t.base.cra_name\t\t= \"ecb(aes)\",\n\t\t.base.cra_driver_name\t= \"ecb-aes-geode\",\n\t\t.base.cra_priority\t= 400,\n\t\t.base.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t  CRYPTO_ALG_NEED_FALLBACK,\n\t\t.base.cra_blocksize\t= AES_BLOCK_SIZE,\n\t\t.base.cra_ctxsize\t= sizeof(struct geode_aes_tfm_ctx),\n\t\t.base.cra_alignmask\t= 15,\n\t\t.base.cra_module\t= THIS_MODULE,\n\t\t.init\t\t\t= geode_init_skcipher,\n\t\t.exit\t\t\t= geode_exit_skcipher,\n\t\t.setkey\t\t\t= geode_setkey_skcipher,\n\t\t.encrypt\t\t= geode_ecb_encrypt,\n\t\t.decrypt\t\t= geode_ecb_decrypt,\n\t\t.min_keysize\t\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t\t= AES_MAX_KEY_SIZE,\n\t},\n};\n\nstatic void geode_aes_remove(struct pci_dev *dev)\n{\n\tcrypto_unregister_alg(&geode_alg);\n\tcrypto_unregister_skciphers(geode_skcipher_algs,\n\t\t\t\t    ARRAY_SIZE(geode_skcipher_algs));\n\n\tpci_iounmap(dev, _iobase);\n\t_iobase = NULL;\n\n\tpci_release_regions(dev);\n\tpci_disable_device(dev);\n}\n\n\nstatic int geode_aes_probe(struct pci_dev *dev, const struct pci_device_id *id)\n{\n\tint ret;\n\n\tret = pci_enable_device(dev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = pci_request_regions(dev, \"geode-aes\");\n\tif (ret)\n\t\tgoto eenable;\n\n\t_iobase = pci_iomap(dev, 0, 0);\n\n\tif (_iobase == NULL) {\n\t\tret = -ENOMEM;\n\t\tgoto erequest;\n\t}\n\n\t \n\tiowrite32(AES_INTR_PENDING | AES_INTR_MASK, _iobase + AES_INTR_REG);\n\n\tret = crypto_register_alg(&geode_alg);\n\tif (ret)\n\t\tgoto eiomap;\n\n\tret = crypto_register_skciphers(geode_skcipher_algs,\n\t\t\t\t\tARRAY_SIZE(geode_skcipher_algs));\n\tif (ret)\n\t\tgoto ealg;\n\n\tdev_notice(&dev->dev, \"GEODE AES engine enabled.\\n\");\n\treturn 0;\n\n ealg:\n\tcrypto_unregister_alg(&geode_alg);\n\n eiomap:\n\tpci_iounmap(dev, _iobase);\n\n erequest:\n\tpci_release_regions(dev);\n\n eenable:\n\tpci_disable_device(dev);\n\n\tdev_err(&dev->dev, \"GEODE AES initialization failed.\\n\");\n\treturn ret;\n}\n\nstatic struct pci_device_id geode_aes_tbl[] = {\n\t{ PCI_VDEVICE(AMD, PCI_DEVICE_ID_AMD_LX_AES), },\n\t{ 0, }\n};\n\nMODULE_DEVICE_TABLE(pci, geode_aes_tbl);\n\nstatic struct pci_driver geode_aes_driver = {\n\t.name = \"Geode LX AES\",\n\t.id_table = geode_aes_tbl,\n\t.probe = geode_aes_probe,\n\t.remove = geode_aes_remove,\n};\n\nmodule_pci_driver(geode_aes_driver);\n\nMODULE_AUTHOR(\"Advanced Micro Devices, Inc.\");\nMODULE_DESCRIPTION(\"Geode LX Hardware AES driver\");\nMODULE_LICENSE(\"GPL\");\nMODULE_IMPORT_NS(CRYPTO_INTERNAL);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}