{
  "module_name": "cipher.c",
  "hash_id": "6c9f536b474248f2ea2c43b1ddd698c217b2f005a88f18c0a4b103f9354bbf09",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/bcm/cipher.c",
  "human_readable_source": "\n \n\n#include <linux/err.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/platform_device.h>\n#include <linux/scatterlist.h>\n#include <linux/crypto.h>\n#include <linux/kthread.h>\n#include <linux/rtnetlink.h>\n#include <linux/sched.h>\n#include <linux/of.h>\n#include <linux/io.h>\n#include <linux/bitops.h>\n\n#include <crypto/algapi.h>\n#include <crypto/aead.h>\n#include <crypto/internal/aead.h>\n#include <crypto/aes.h>\n#include <crypto/internal/des.h>\n#include <crypto/hmac.h>\n#include <crypto/md5.h>\n#include <crypto/authenc.h>\n#include <crypto/skcipher.h>\n#include <crypto/hash.h>\n#include <crypto/sha1.h>\n#include <crypto/sha2.h>\n#include <crypto/sha3.h>\n\n#include \"util.h\"\n#include \"cipher.h\"\n#include \"spu.h\"\n#include \"spum.h\"\n#include \"spu2.h\"\n\n \n\nstruct bcm_device_private iproc_priv;\n\n \n\nint flow_debug_logging;\nmodule_param(flow_debug_logging, int, 0644);\nMODULE_PARM_DESC(flow_debug_logging, \"Enable Flow Debug Logging\");\n\nint packet_debug_logging;\nmodule_param(packet_debug_logging, int, 0644);\nMODULE_PARM_DESC(packet_debug_logging, \"Enable Packet Debug Logging\");\n\nint debug_logging_sleep;\nmodule_param(debug_logging_sleep, int, 0644);\nMODULE_PARM_DESC(debug_logging_sleep, \"Packet Debug Logging Sleep\");\n\n \nstatic int cipher_pri = 150;\nmodule_param(cipher_pri, int, 0644);\nMODULE_PARM_DESC(cipher_pri, \"Priority for cipher algos\");\n\nstatic int hash_pri = 100;\nmodule_param(hash_pri, int, 0644);\nMODULE_PARM_DESC(hash_pri, \"Priority for hash algos\");\n\nstatic int aead_pri = 150;\nmodule_param(aead_pri, int, 0644);\nMODULE_PARM_DESC(aead_pri, \"Priority for AEAD algos\");\n\n \nstatic char BCMHEADER[] = { 0x60, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x28 };\n \n#define BCM_HDR_LEN  iproc_priv.bcm_hdr_len\n\n \n#define MBOX_SLEEP_MIN  800\n#define MBOX_SLEEP_MAX 1000\n\n \nstatic u8 select_channel(void)\n{\n\tu8 chan_idx = atomic_inc_return(&iproc_priv.next_chan);\n\n\treturn chan_idx % iproc_priv.spu.num_chan;\n}\n\n \nstatic int\nspu_skcipher_rx_sg_create(struct brcm_message *mssg,\n\t\t\t    struct iproc_reqctx_s *rctx,\n\t\t\t    u8 rx_frag_num,\n\t\t\t    unsigned int chunksize, u32 stat_pad_len)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct scatterlist *sg;\t \n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tu32 datalen;\t\t \n\n\tmssg->spu.dst = kcalloc(rx_frag_num, sizeof(struct scatterlist),\n\t\t\t\trctx->gfp);\n\tif (!mssg->spu.dst)\n\t\treturn -ENOMEM;\n\n\tsg = mssg->spu.dst;\n\tsg_init_table(sg, rx_frag_num);\n\t \n\tsg_set_buf(sg++, rctx->msg_buf.spu_resp_hdr, ctx->spu_resp_hdr_len);\n\n\t \n\tif ((ctx->cipher.mode == CIPHER_MODE_XTS) &&\n\t    spu->spu_xts_tweak_in_payload())\n\t\tsg_set_buf(sg++, rctx->msg_buf.c.supdt_tweak,\n\t\t\t   SPU_XTS_TWEAK_SIZE);\n\n\t \n\tdatalen = spu_msg_sg_add(&sg, &rctx->dst_sg, &rctx->dst_skip,\n\t\t\t\t rctx->dst_nents, chunksize);\n\tif (datalen < chunksize) {\n\t\tpr_err(\"%s(): failed to copy dst sg to mbox msg. chunksize %u, datalen %u\",\n\t\t       __func__, chunksize, datalen);\n\t\treturn -EFAULT;\n\t}\n\n\tif (stat_pad_len)\n\t\tsg_set_buf(sg++, rctx->msg_buf.rx_stat_pad, stat_pad_len);\n\n\tmemset(rctx->msg_buf.rx_stat, 0, SPU_RX_STATUS_LEN);\n\tsg_set_buf(sg, rctx->msg_buf.rx_stat, spu->spu_rx_status_len());\n\n\treturn 0;\n}\n\n \nstatic int\nspu_skcipher_tx_sg_create(struct brcm_message *mssg,\n\t\t\t    struct iproc_reqctx_s *rctx,\n\t\t\t    u8 tx_frag_num, unsigned int chunksize, u32 pad_len)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct scatterlist *sg;\t \n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tu32 datalen;\t\t \n\tu32 stat_len;\n\n\tmssg->spu.src = kcalloc(tx_frag_num, sizeof(struct scatterlist),\n\t\t\t\trctx->gfp);\n\tif (unlikely(!mssg->spu.src))\n\t\treturn -ENOMEM;\n\n\tsg = mssg->spu.src;\n\tsg_init_table(sg, tx_frag_num);\n\n\tsg_set_buf(sg++, rctx->msg_buf.bcm_spu_req_hdr,\n\t\t   BCM_HDR_LEN + ctx->spu_req_hdr_len);\n\n\t \n\tif ((ctx->cipher.mode == CIPHER_MODE_XTS) &&\n\t    spu->spu_xts_tweak_in_payload())\n\t\tsg_set_buf(sg++, rctx->msg_buf.iv_ctr, SPU_XTS_TWEAK_SIZE);\n\n\t \n\tdatalen = spu_msg_sg_add(&sg, &rctx->src_sg, &rctx->src_skip,\n\t\t\t\t rctx->src_nents, chunksize);\n\tif (unlikely(datalen < chunksize)) {\n\t\tpr_err(\"%s(): failed to copy src sg to mbox msg\",\n\t\t       __func__);\n\t\treturn -EFAULT;\n\t}\n\n\tif (pad_len)\n\t\tsg_set_buf(sg++, rctx->msg_buf.spu_req_pad, pad_len);\n\n\tstat_len = spu->spu_tx_status_len();\n\tif (stat_len) {\n\t\tmemset(rctx->msg_buf.tx_stat, 0, stat_len);\n\t\tsg_set_buf(sg, rctx->msg_buf.tx_stat, stat_len);\n\t}\n\treturn 0;\n}\n\nstatic int mailbox_send_message(struct brcm_message *mssg, u32 flags,\n\t\t\t\tu8 chan_idx)\n{\n\tint err;\n\tint retry_cnt = 0;\n\tstruct device *dev = &(iproc_priv.pdev->dev);\n\n\terr = mbox_send_message(iproc_priv.mbox[chan_idx], mssg);\n\tif (flags & CRYPTO_TFM_REQ_MAY_SLEEP) {\n\t\twhile ((err == -ENOBUFS) && (retry_cnt < SPU_MB_RETRY_MAX)) {\n\t\t\t \n\t\t\tretry_cnt++;\n\t\t\tusleep_range(MBOX_SLEEP_MIN, MBOX_SLEEP_MAX);\n\t\t\terr = mbox_send_message(iproc_priv.mbox[chan_idx],\n\t\t\t\t\t\tmssg);\n\t\t\tatomic_inc(&iproc_priv.mb_no_spc);\n\t\t}\n\t}\n\tif (err < 0) {\n\t\tatomic_inc(&iproc_priv.mb_send_fail);\n\t\treturn err;\n\t}\n\n\t \n\terr = mssg->error;\n\tif (unlikely(err < 0)) {\n\t\tdev_err(dev, \"message error %d\", err);\n\t\t \n\t}\n\n\t \n\tmbox_client_txdone(iproc_priv.mbox[chan_idx], err);\n\treturn err;\n}\n\n \nstatic int handle_skcipher_req(struct iproc_reqctx_s *rctx)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct crypto_async_request *areq = rctx->parent;\n\tstruct skcipher_request *req =\n\t    container_of(areq, struct skcipher_request, base);\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tstruct spu_cipher_parms cipher_parms;\n\tint err;\n\tunsigned int chunksize;\t \n\tint remaining;\t \n\tint chunk_start;\t \n\n\t \n\tu8 local_iv_ctr[MAX_IV_SIZE];\n\tu32 stat_pad_len;\t \n\tu32 pad_len;\t\t \n\tstruct brcm_message *mssg;\t \n\n\t \n\tu8 rx_frag_num = 2;\t \n\tu8 tx_frag_num = 1;\t \n\n\tflow_log(\"%s\\n\", __func__);\n\n\tcipher_parms.alg = ctx->cipher.alg;\n\tcipher_parms.mode = ctx->cipher.mode;\n\tcipher_parms.type = ctx->cipher_type;\n\tcipher_parms.key_len = ctx->enckeylen;\n\tcipher_parms.key_buf = ctx->enckey;\n\tcipher_parms.iv_buf = local_iv_ctr;\n\tcipher_parms.iv_len = rctx->iv_ctr_len;\n\n\tmssg = &rctx->mb_mssg;\n\tchunk_start = rctx->src_sent;\n\tremaining = rctx->total_todo - chunk_start;\n\n\t \n\tif ((ctx->max_payload != SPU_MAX_PAYLOAD_INF) &&\n\t    (remaining > ctx->max_payload))\n\t\tchunksize = ctx->max_payload;\n\telse\n\t\tchunksize = remaining;\n\n\trctx->src_sent += chunksize;\n\trctx->total_sent = rctx->src_sent;\n\n\t \n\trctx->src_nents = spu_sg_count(rctx->src_sg, rctx->src_skip, chunksize);\n\trctx->dst_nents = spu_sg_count(rctx->dst_sg, rctx->dst_skip, chunksize);\n\n\tif ((ctx->cipher.mode == CIPHER_MODE_CBC) &&\n\t    rctx->is_encrypt && chunk_start)\n\t\t \n\t\tsg_copy_part_to_buf(req->dst, rctx->msg_buf.iv_ctr,\n\t\t\t\t    rctx->iv_ctr_len,\n\t\t\t\t    chunk_start - rctx->iv_ctr_len);\n\n\tif (rctx->iv_ctr_len) {\n\t\t \n\t\t__builtin_memcpy(local_iv_ctr, rctx->msg_buf.iv_ctr,\n\t\t\t\t rctx->iv_ctr_len);\n\n\t\t \n\t\tif ((ctx->cipher.mode == CIPHER_MODE_CBC) &&\n\t\t    !rctx->is_encrypt) {\n\t\t\t \n\t\t\tsg_copy_part_to_buf(req->src, rctx->msg_buf.iv_ctr,\n\t\t\t\t\t    rctx->iv_ctr_len,\n\t\t\t\t\t    rctx->src_sent - rctx->iv_ctr_len);\n\t\t} else if (ctx->cipher.mode == CIPHER_MODE_CTR) {\n\t\t\t \n\t\t\tadd_to_ctr(rctx->msg_buf.iv_ctr, chunksize >> 4);\n\t\t}\n\t}\n\n\tif (ctx->max_payload == SPU_MAX_PAYLOAD_INF)\n\t\tflow_log(\"max_payload infinite\\n\");\n\telse\n\t\tflow_log(\"max_payload %u\\n\", ctx->max_payload);\n\n\tflow_log(\"sent:%u start:%u remains:%u size:%u\\n\",\n\t\t rctx->src_sent, chunk_start, remaining, chunksize);\n\n\t \n\tmemcpy(rctx->msg_buf.bcm_spu_req_hdr, ctx->bcm_spu_req_hdr,\n\t       sizeof(rctx->msg_buf.bcm_spu_req_hdr));\n\n\tspu->spu_cipher_req_finish(rctx->msg_buf.bcm_spu_req_hdr + BCM_HDR_LEN,\n\t\t\t\t   ctx->spu_req_hdr_len, !(rctx->is_encrypt),\n\t\t\t\t   &cipher_parms, chunksize);\n\n\tatomic64_add(chunksize, &iproc_priv.bytes_out);\n\n\tstat_pad_len = spu->spu_wordalign_padlen(chunksize);\n\tif (stat_pad_len)\n\t\trx_frag_num++;\n\tpad_len = stat_pad_len;\n\tif (pad_len) {\n\t\ttx_frag_num++;\n\t\tspu->spu_request_pad(rctx->msg_buf.spu_req_pad, 0,\n\t\t\t\t     0, ctx->auth.alg, ctx->auth.mode,\n\t\t\t\t     rctx->total_sent, stat_pad_len);\n\t}\n\n\tspu->spu_dump_msg_hdr(rctx->msg_buf.bcm_spu_req_hdr + BCM_HDR_LEN,\n\t\t\t      ctx->spu_req_hdr_len);\n\tpacket_log(\"payload:\\n\");\n\tdump_sg(rctx->src_sg, rctx->src_skip, chunksize);\n\tpacket_dump(\"   pad: \", rctx->msg_buf.spu_req_pad, pad_len);\n\n\t \n\tmemset(mssg, 0, sizeof(*mssg));\n\tmssg->type = BRCM_MESSAGE_SPU;\n\tmssg->ctx = rctx;\t \n\n\t \n\trx_frag_num += rctx->dst_nents;\n\n\tif ((ctx->cipher.mode == CIPHER_MODE_XTS) &&\n\t    spu->spu_xts_tweak_in_payload())\n\t\trx_frag_num++;\t \n\n\terr = spu_skcipher_rx_sg_create(mssg, rctx, rx_frag_num, chunksize,\n\t\t\t\t\t  stat_pad_len);\n\tif (err)\n\t\treturn err;\n\n\t \n\ttx_frag_num += rctx->src_nents;\n\tif (spu->spu_tx_status_len())\n\t\ttx_frag_num++;\n\n\tif ((ctx->cipher.mode == CIPHER_MODE_XTS) &&\n\t    spu->spu_xts_tweak_in_payload())\n\t\ttx_frag_num++;\t \n\n\terr = spu_skcipher_tx_sg_create(mssg, rctx, tx_frag_num, chunksize,\n\t\t\t\t\t  pad_len);\n\tif (err)\n\t\treturn err;\n\n\terr = mailbox_send_message(mssg, req->base.flags, rctx->chan_idx);\n\tif (unlikely(err < 0))\n\t\treturn err;\n\n\treturn -EINPROGRESS;\n}\n\n \nstatic void handle_skcipher_resp(struct iproc_reqctx_s *rctx)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct crypto_async_request *areq = rctx->parent;\n\tstruct skcipher_request *req = skcipher_request_cast(areq);\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tu32 payload_len;\n\n\t \n\tpayload_len = spu->spu_payload_length(rctx->msg_buf.spu_resp_hdr);\n\n\t \n\tif ((ctx->cipher.mode == CIPHER_MODE_XTS) &&\n\t    spu->spu_xts_tweak_in_payload() &&\n\t    (payload_len >= SPU_XTS_TWEAK_SIZE))\n\t\tpayload_len -= SPU_XTS_TWEAK_SIZE;\n\n\tatomic64_add(payload_len, &iproc_priv.bytes_in);\n\n\tflow_log(\"%s() offset: %u, bd_len: %u BD:\\n\",\n\t\t __func__, rctx->total_received, payload_len);\n\n\tdump_sg(req->dst, rctx->total_received, payload_len);\n\n\trctx->total_received += payload_len;\n\tif (rctx->total_received == rctx->total_todo) {\n\t\tatomic_inc(&iproc_priv.op_counts[SPU_OP_CIPHER]);\n\t\tatomic_inc(\n\t\t   &iproc_priv.cipher_cnt[ctx->cipher.alg][ctx->cipher.mode]);\n\t}\n}\n\n \nstatic int\nspu_ahash_rx_sg_create(struct brcm_message *mssg,\n\t\t       struct iproc_reqctx_s *rctx,\n\t\t       u8 rx_frag_num, unsigned int digestsize,\n\t\t       u32 stat_pad_len)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct scatterlist *sg;\t \n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\n\tmssg->spu.dst = kcalloc(rx_frag_num, sizeof(struct scatterlist),\n\t\t\t\trctx->gfp);\n\tif (!mssg->spu.dst)\n\t\treturn -ENOMEM;\n\n\tsg = mssg->spu.dst;\n\tsg_init_table(sg, rx_frag_num);\n\t \n\tsg_set_buf(sg++, rctx->msg_buf.spu_resp_hdr, ctx->spu_resp_hdr_len);\n\n\t \n\tsg_set_buf(sg++, rctx->msg_buf.digest, digestsize);\n\n\tif (stat_pad_len)\n\t\tsg_set_buf(sg++, rctx->msg_buf.rx_stat_pad, stat_pad_len);\n\n\tmemset(rctx->msg_buf.rx_stat, 0, SPU_RX_STATUS_LEN);\n\tsg_set_buf(sg, rctx->msg_buf.rx_stat, spu->spu_rx_status_len());\n\treturn 0;\n}\n\n \nstatic int\nspu_ahash_tx_sg_create(struct brcm_message *mssg,\n\t\t       struct iproc_reqctx_s *rctx,\n\t\t       u8 tx_frag_num,\n\t\t       u32 spu_hdr_len,\n\t\t       unsigned int hash_carry_len,\n\t\t       unsigned int new_data_len, u32 pad_len)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct scatterlist *sg;\t \n\tu32 datalen;\t\t \n\tu32 stat_len;\n\n\tmssg->spu.src = kcalloc(tx_frag_num, sizeof(struct scatterlist),\n\t\t\t\trctx->gfp);\n\tif (!mssg->spu.src)\n\t\treturn -ENOMEM;\n\n\tsg = mssg->spu.src;\n\tsg_init_table(sg, tx_frag_num);\n\n\tsg_set_buf(sg++, rctx->msg_buf.bcm_spu_req_hdr,\n\t\t   BCM_HDR_LEN + spu_hdr_len);\n\n\tif (hash_carry_len)\n\t\tsg_set_buf(sg++, rctx->hash_carry, hash_carry_len);\n\n\tif (new_data_len) {\n\t\t \n\t\tdatalen = spu_msg_sg_add(&sg, &rctx->src_sg, &rctx->src_skip,\n\t\t\t\t\t rctx->src_nents, new_data_len);\n\t\tif (datalen < new_data_len) {\n\t\t\tpr_err(\"%s(): failed to copy src sg to mbox msg\",\n\t\t\t       __func__);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\tif (pad_len)\n\t\tsg_set_buf(sg++, rctx->msg_buf.spu_req_pad, pad_len);\n\n\tstat_len = spu->spu_tx_status_len();\n\tif (stat_len) {\n\t\tmemset(rctx->msg_buf.tx_stat, 0, stat_len);\n\t\tsg_set_buf(sg, rctx->msg_buf.tx_stat, stat_len);\n\t}\n\n\treturn 0;\n}\n\n \nstatic int handle_ahash_req(struct iproc_reqctx_s *rctx)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct crypto_async_request *areq = rctx->parent;\n\tstruct ahash_request *req = ahash_request_cast(areq);\n\tstruct crypto_ahash *ahash = crypto_ahash_reqtfm(req);\n\tstruct crypto_tfm *tfm = crypto_ahash_tfm(ahash);\n\tunsigned int blocksize = crypto_tfm_alg_blocksize(tfm);\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\n\t \n\tunsigned int nbytes_to_hash = 0;\n\tint err;\n\tunsigned int chunksize = 0;\t \n\t \n\tunsigned int new_data_len;\n\n\tunsigned int __maybe_unused chunk_start = 0;\n\tu32 db_size;\t  \n\tint pad_len = 0;  \n\tu32 data_pad_len = 0;\t \n\tu32 stat_pad_len = 0;\t \n\tstruct brcm_message *mssg;\t \n\tstruct spu_request_opts req_opts;\n\tstruct spu_cipher_parms cipher_parms;\n\tstruct spu_hash_parms hash_parms;\n\tstruct spu_aead_parms aead_parms;\n\tunsigned int local_nbuf;\n\tu32 spu_hdr_len;\n\tunsigned int digestsize;\n\tu16 rem = 0;\n\n\t \n\tu8 rx_frag_num = 3;\n\tu8 tx_frag_num = 1;\n\n\tflow_log(\"total_todo %u, total_sent %u\\n\",\n\t\t rctx->total_todo, rctx->total_sent);\n\n\tmemset(&req_opts, 0, sizeof(req_opts));\n\tmemset(&cipher_parms, 0, sizeof(cipher_parms));\n\tmemset(&hash_parms, 0, sizeof(hash_parms));\n\tmemset(&aead_parms, 0, sizeof(aead_parms));\n\n\treq_opts.bd_suppress = true;\n\thash_parms.alg = ctx->auth.alg;\n\thash_parms.mode = ctx->auth.mode;\n\thash_parms.type = HASH_TYPE_NONE;\n\thash_parms.key_buf = (u8 *)ctx->authkey;\n\thash_parms.key_len = ctx->authkeylen;\n\n\t \n\tcipher_parms.type = ctx->cipher_type;\n\n\tmssg = &rctx->mb_mssg;\n\tchunk_start = rctx->src_sent;\n\n\t \n\tnbytes_to_hash = rctx->total_todo - rctx->total_sent;\n\tchunksize = nbytes_to_hash;\n\tif ((ctx->max_payload != SPU_MAX_PAYLOAD_INF) &&\n\t    (chunksize > ctx->max_payload))\n\t\tchunksize = ctx->max_payload;\n\n\t \n\tif (!rctx->is_final) {\n\t\tu8 *dest = rctx->hash_carry + rctx->hash_carry_len;\n\t\tu16 new_len;   \n\n\t\trem = chunksize % blocksize;    \n\t\tif (rem) {\n\t\t\t \n\t\t\tchunksize -= rem;\n\t\t\tif (chunksize == 0) {\n\t\t\t\t \n\t\t\t\tnew_len = rem - rctx->hash_carry_len;\n\t\t\t\tsg_copy_part_to_buf(req->src, dest, new_len,\n\t\t\t\t\t\t    rctx->src_sent);\n\t\t\t\trctx->hash_carry_len = rem;\n\t\t\t\tflow_log(\"Exiting with hash carry len: %u\\n\",\n\t\t\t\t\t rctx->hash_carry_len);\n\t\t\t\tpacket_dump(\"  buf: \",\n\t\t\t\t\t    rctx->hash_carry,\n\t\t\t\t\t    rctx->hash_carry_len);\n\t\t\t\treturn -EAGAIN;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tlocal_nbuf = rctx->hash_carry_len;\n\trctx->hash_carry_len = 0;\n\tif (local_nbuf)\n\t\ttx_frag_num++;\n\tnew_data_len = chunksize - local_nbuf;\n\n\t \n\trctx->src_nents = spu_sg_count(rctx->src_sg, rctx->src_skip,\n\t\t\t\t       new_data_len);\n\n\t \n\tif (hash_parms.alg == HASH_ALG_AES)\n\t\thash_parms.type = (enum hash_type)cipher_parms.type;\n\telse\n\t\thash_parms.type = spu->spu_hash_type(rctx->total_sent);\n\n\tdigestsize = spu->spu_digest_size(ctx->digestsize, ctx->auth.alg,\n\t\t\t\t\t  hash_parms.type);\n\thash_parms.digestsize =\tdigestsize;\n\n\t \n\trctx->total_sent += chunksize;\n\t \n\trctx->src_sent += new_data_len;\n\n\tif ((rctx->total_sent == rctx->total_todo) && rctx->is_final)\n\t\thash_parms.pad_len = spu->spu_hash_pad_len(hash_parms.alg,\n\t\t\t\t\t\t\t   hash_parms.mode,\n\t\t\t\t\t\t\t   chunksize,\n\t\t\t\t\t\t\t   blocksize);\n\n\t \n\tif ((hash_parms.type == HASH_TYPE_UPDT) &&\n\t    (hash_parms.alg != HASH_ALG_AES)) {\n\t\thash_parms.key_buf = rctx->incr_hash;\n\t\thash_parms.key_len = digestsize;\n\t}\n\n\tatomic64_add(chunksize, &iproc_priv.bytes_out);\n\n\tflow_log(\"%s() final: %u nbuf: %u \",\n\t\t __func__, rctx->is_final, local_nbuf);\n\n\tif (ctx->max_payload == SPU_MAX_PAYLOAD_INF)\n\t\tflow_log(\"max_payload infinite\\n\");\n\telse\n\t\tflow_log(\"max_payload %u\\n\", ctx->max_payload);\n\n\tflow_log(\"chunk_start: %u chunk_size: %u\\n\", chunk_start, chunksize);\n\n\t \n\tmemcpy(rctx->msg_buf.bcm_spu_req_hdr, BCMHEADER, BCM_HDR_LEN);\n\n\thash_parms.prebuf_len = local_nbuf;\n\tspu_hdr_len = spu->spu_create_request(rctx->msg_buf.bcm_spu_req_hdr +\n\t\t\t\t\t      BCM_HDR_LEN,\n\t\t\t\t\t      &req_opts, &cipher_parms,\n\t\t\t\t\t      &hash_parms, &aead_parms,\n\t\t\t\t\t      new_data_len);\n\n\tif (spu_hdr_len == 0) {\n\t\tpr_err(\"Failed to create SPU request header\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\t \n\tdata_pad_len = spu->spu_gcm_ccm_pad_len(ctx->cipher.mode, chunksize);\n\tdb_size = spu_real_db_size(0, 0, local_nbuf, new_data_len,\n\t\t\t\t   0, 0, hash_parms.pad_len);\n\tif (spu->spu_tx_status_len())\n\t\tstat_pad_len = spu->spu_wordalign_padlen(db_size);\n\tif (stat_pad_len)\n\t\trx_frag_num++;\n\tpad_len = hash_parms.pad_len + data_pad_len + stat_pad_len;\n\tif (pad_len) {\n\t\ttx_frag_num++;\n\t\tspu->spu_request_pad(rctx->msg_buf.spu_req_pad, data_pad_len,\n\t\t\t\t     hash_parms.pad_len, ctx->auth.alg,\n\t\t\t\t     ctx->auth.mode, rctx->total_sent,\n\t\t\t\t     stat_pad_len);\n\t}\n\n\tspu->spu_dump_msg_hdr(rctx->msg_buf.bcm_spu_req_hdr + BCM_HDR_LEN,\n\t\t\t      spu_hdr_len);\n\tpacket_dump(\"    prebuf: \", rctx->hash_carry, local_nbuf);\n\tflow_log(\"Data:\\n\");\n\tdump_sg(rctx->src_sg, rctx->src_skip, new_data_len);\n\tpacket_dump(\"   pad: \", rctx->msg_buf.spu_req_pad, pad_len);\n\n\t \n\tmemset(mssg, 0, sizeof(*mssg));\n\tmssg->type = BRCM_MESSAGE_SPU;\n\tmssg->ctx = rctx;\t \n\n\t \n\terr = spu_ahash_rx_sg_create(mssg, rctx, rx_frag_num, digestsize,\n\t\t\t\t     stat_pad_len);\n\tif (err)\n\t\treturn err;\n\n\t \n\ttx_frag_num += rctx->src_nents;\n\tif (spu->spu_tx_status_len())\n\t\ttx_frag_num++;\n\terr = spu_ahash_tx_sg_create(mssg, rctx, tx_frag_num, spu_hdr_len,\n\t\t\t\t     local_nbuf, new_data_len, pad_len);\n\tif (err)\n\t\treturn err;\n\n\terr = mailbox_send_message(mssg, req->base.flags, rctx->chan_idx);\n\tif (unlikely(err < 0))\n\t\treturn err;\n\n\treturn -EINPROGRESS;\n}\n\n \nstatic int spu_hmac_outer_hash(struct ahash_request *req,\n\t\t\t       struct iproc_ctx_s *ctx)\n{\n\tstruct crypto_ahash *ahash = crypto_ahash_reqtfm(req);\n\tunsigned int blocksize =\n\t\tcrypto_tfm_alg_blocksize(crypto_ahash_tfm(ahash));\n\tint rc;\n\n\tswitch (ctx->auth.alg) {\n\tcase HASH_ALG_MD5:\n\t\trc = do_shash(\"md5\", req->result, ctx->opad, blocksize,\n\t\t\t      req->result, ctx->digestsize, NULL, 0);\n\t\tbreak;\n\tcase HASH_ALG_SHA1:\n\t\trc = do_shash(\"sha1\", req->result, ctx->opad, blocksize,\n\t\t\t      req->result, ctx->digestsize, NULL, 0);\n\t\tbreak;\n\tcase HASH_ALG_SHA224:\n\t\trc = do_shash(\"sha224\", req->result, ctx->opad, blocksize,\n\t\t\t      req->result, ctx->digestsize, NULL, 0);\n\t\tbreak;\n\tcase HASH_ALG_SHA256:\n\t\trc = do_shash(\"sha256\", req->result, ctx->opad, blocksize,\n\t\t\t      req->result, ctx->digestsize, NULL, 0);\n\t\tbreak;\n\tcase HASH_ALG_SHA384:\n\t\trc = do_shash(\"sha384\", req->result, ctx->opad, blocksize,\n\t\t\t      req->result, ctx->digestsize, NULL, 0);\n\t\tbreak;\n\tcase HASH_ALG_SHA512:\n\t\trc = do_shash(\"sha512\", req->result, ctx->opad, blocksize,\n\t\t\t      req->result, ctx->digestsize, NULL, 0);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s() Error : unknown hmac type\\n\", __func__);\n\t\trc = -EINVAL;\n\t}\n\treturn rc;\n}\n\n \nstatic int ahash_req_done(struct iproc_reqctx_s *rctx)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct crypto_async_request *areq = rctx->parent;\n\tstruct ahash_request *req = ahash_request_cast(areq);\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tint err;\n\n\tmemcpy(req->result, rctx->msg_buf.digest, ctx->digestsize);\n\n\tif (spu->spu_type == SPU_TYPE_SPUM) {\n\t\t \n\t\tif (ctx->auth.alg == HASH_ALG_MD5) {\n\t\t\t__swab32s((u32 *)req->result);\n\t\t\t__swab32s(((u32 *)req->result) + 1);\n\t\t\t__swab32s(((u32 *)req->result) + 2);\n\t\t\t__swab32s(((u32 *)req->result) + 3);\n\t\t\t__swab32s(((u32 *)req->result) + 4);\n\t\t}\n\t}\n\n\tflow_dump(\"  digest \", req->result, ctx->digestsize);\n\n\t \n\tif (rctx->is_sw_hmac) {\n\t\terr = spu_hmac_outer_hash(req, ctx);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t\tflow_dump(\"  hmac: \", req->result, ctx->digestsize);\n\t}\n\n\tif (rctx->is_sw_hmac || ctx->auth.mode == HASH_MODE_HMAC) {\n\t\tatomic_inc(&iproc_priv.op_counts[SPU_OP_HMAC]);\n\t\tatomic_inc(&iproc_priv.hmac_cnt[ctx->auth.alg]);\n\t} else {\n\t\tatomic_inc(&iproc_priv.op_counts[SPU_OP_HASH]);\n\t\tatomic_inc(&iproc_priv.hash_cnt[ctx->auth.alg]);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void handle_ahash_resp(struct iproc_reqctx_s *rctx)\n{\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tstruct crypto_async_request *areq = rctx->parent;\n\tstruct ahash_request *req = ahash_request_cast(areq);\n\tstruct crypto_ahash *ahash = crypto_ahash_reqtfm(req);\n\tunsigned int blocksize =\n\t\tcrypto_tfm_alg_blocksize(crypto_ahash_tfm(ahash));\n\t \n\tmemcpy(rctx->incr_hash, rctx->msg_buf.digest, MAX_DIGEST_SIZE);\n\n\tflow_log(\"%s() blocksize:%u digestsize:%u\\n\",\n\t\t __func__, blocksize, ctx->digestsize);\n\n\tatomic64_add(ctx->digestsize, &iproc_priv.bytes_in);\n\n\tif (rctx->is_final && (rctx->total_sent == rctx->total_todo))\n\t\tahash_req_done(rctx);\n}\n\n \nstatic int spu_aead_rx_sg_create(struct brcm_message *mssg,\n\t\t\t\t struct aead_request *req,\n\t\t\t\t struct iproc_reqctx_s *rctx,\n\t\t\t\t u8 rx_frag_num,\n\t\t\t\t unsigned int assoc_len,\n\t\t\t\t u32 ret_iv_len, unsigned int resp_len,\n\t\t\t\t unsigned int digestsize, u32 stat_pad_len)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct scatterlist *sg;\t \n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tu32 datalen;\t\t \n\tu32 assoc_buf_len;\n\tu8 data_padlen = 0;\n\n\tif (ctx->is_rfc4543) {\n\t\t \n\t\tdata_padlen = spu->spu_gcm_ccm_pad_len(ctx->cipher.mode,\n\t\t\t\t\t\t\t  assoc_len + resp_len);\n\t\tassoc_buf_len = assoc_len;\n\t} else {\n\t\tdata_padlen = spu->spu_gcm_ccm_pad_len(ctx->cipher.mode,\n\t\t\t\t\t\t\t  resp_len);\n\t\tassoc_buf_len = spu->spu_assoc_resp_len(ctx->cipher.mode,\n\t\t\t\t\t\tassoc_len, ret_iv_len,\n\t\t\t\t\t\trctx->is_encrypt);\n\t}\n\n\tif (ctx->cipher.mode == CIPHER_MODE_CCM)\n\t\t \n\t\tdata_padlen += spu->spu_wordalign_padlen(assoc_buf_len +\n\t\t\t\t\t\t\t resp_len +\n\t\t\t\t\t\t\t data_padlen);\n\n\tif (data_padlen)\n\t\t \n\t\trx_frag_num++;\n\n\tmssg->spu.dst = kcalloc(rx_frag_num, sizeof(struct scatterlist),\n\t\t\t\trctx->gfp);\n\tif (!mssg->spu.dst)\n\t\treturn -ENOMEM;\n\n\tsg = mssg->spu.dst;\n\tsg_init_table(sg, rx_frag_num);\n\n\t \n\tsg_set_buf(sg++, rctx->msg_buf.spu_resp_hdr, ctx->spu_resp_hdr_len);\n\n\tif (assoc_buf_len) {\n\t\t \n\t\tmemset(rctx->msg_buf.a.resp_aad, 0, assoc_buf_len);\n\t\tsg_set_buf(sg++, rctx->msg_buf.a.resp_aad, assoc_buf_len);\n\t}\n\n\tif (resp_len) {\n\t\t \n\t\tdatalen = spu_msg_sg_add(&sg, &rctx->dst_sg, &rctx->dst_skip,\n\t\t\t\t\t rctx->dst_nents, resp_len);\n\t\tif (datalen < (resp_len)) {\n\t\t\tpr_err(\"%s(): failed to copy dst sg to mbox msg. expected len %u, datalen %u\",\n\t\t\t       __func__, resp_len, datalen);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\t \n\tif (data_padlen) {\n\t\tmemset(rctx->msg_buf.a.gcmpad, 0, data_padlen);\n\t\tsg_set_buf(sg++, rctx->msg_buf.a.gcmpad, data_padlen);\n\t}\n\n\t \n\tsg_set_buf(sg++, rctx->msg_buf.digest, digestsize);\n\n\tflow_log(\"stat_pad_len %u\\n\", stat_pad_len);\n\tif (stat_pad_len) {\n\t\tmemset(rctx->msg_buf.rx_stat_pad, 0, stat_pad_len);\n\t\tsg_set_buf(sg++, rctx->msg_buf.rx_stat_pad, stat_pad_len);\n\t}\n\n\tmemset(rctx->msg_buf.rx_stat, 0, SPU_RX_STATUS_LEN);\n\tsg_set_buf(sg, rctx->msg_buf.rx_stat, spu->spu_rx_status_len());\n\n\treturn 0;\n}\n\n \nstatic int spu_aead_tx_sg_create(struct brcm_message *mssg,\n\t\t\t\t struct iproc_reqctx_s *rctx,\n\t\t\t\t u8 tx_frag_num,\n\t\t\t\t u32 spu_hdr_len,\n\t\t\t\t struct scatterlist *assoc,\n\t\t\t\t unsigned int assoc_len,\n\t\t\t\t int assoc_nents,\n\t\t\t\t unsigned int aead_iv_len,\n\t\t\t\t unsigned int chunksize,\n\t\t\t\t u32 aad_pad_len, u32 pad_len, bool incl_icv)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct scatterlist *sg;\t \n\tstruct scatterlist *assoc_sg = assoc;\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tu32 datalen;\t\t \n\tu32 written;\t\t \n\tu32 assoc_offset = 0;\n\tu32 stat_len;\n\n\tmssg->spu.src = kcalloc(tx_frag_num, sizeof(struct scatterlist),\n\t\t\t\trctx->gfp);\n\tif (!mssg->spu.src)\n\t\treturn -ENOMEM;\n\n\tsg = mssg->spu.src;\n\tsg_init_table(sg, tx_frag_num);\n\n\tsg_set_buf(sg++, rctx->msg_buf.bcm_spu_req_hdr,\n\t\t   BCM_HDR_LEN + spu_hdr_len);\n\n\tif (assoc_len) {\n\t\t \n\t\twritten = spu_msg_sg_add(&sg, &assoc_sg, &assoc_offset,\n\t\t\t\t\t assoc_nents, assoc_len);\n\t\tif (written < assoc_len) {\n\t\t\tpr_err(\"%s(): failed to copy assoc sg to mbox msg\",\n\t\t\t       __func__);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\tif (aead_iv_len)\n\t\tsg_set_buf(sg++, rctx->msg_buf.iv_ctr, aead_iv_len);\n\n\tif (aad_pad_len) {\n\t\tmemset(rctx->msg_buf.a.req_aad_pad, 0, aad_pad_len);\n\t\tsg_set_buf(sg++, rctx->msg_buf.a.req_aad_pad, aad_pad_len);\n\t}\n\n\tdatalen = chunksize;\n\tif ((chunksize > ctx->digestsize) && incl_icv)\n\t\tdatalen -= ctx->digestsize;\n\tif (datalen) {\n\t\t \n\t\twritten = spu_msg_sg_add(&sg, &rctx->src_sg, &rctx->src_skip,\n\t\t\t\t\t rctx->src_nents, datalen);\n\t\tif (written < datalen) {\n\t\t\tpr_err(\"%s(): failed to copy src sg to mbox msg\",\n\t\t\t       __func__);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\tif (pad_len) {\n\t\tmemset(rctx->msg_buf.spu_req_pad, 0, pad_len);\n\t\tsg_set_buf(sg++, rctx->msg_buf.spu_req_pad, pad_len);\n\t}\n\n\tif (incl_icv)\n\t\tsg_set_buf(sg++, rctx->msg_buf.digest, ctx->digestsize);\n\n\tstat_len = spu->spu_tx_status_len();\n\tif (stat_len) {\n\t\tmemset(rctx->msg_buf.tx_stat, 0, stat_len);\n\t\tsg_set_buf(sg, rctx->msg_buf.tx_stat, stat_len);\n\t}\n\treturn 0;\n}\n\n \nstatic int handle_aead_req(struct iproc_reqctx_s *rctx)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct crypto_async_request *areq = rctx->parent;\n\tstruct aead_request *req = container_of(areq,\n\t\t\t\t\t\tstruct aead_request, base);\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tint err;\n\tunsigned int chunksize;\n\tunsigned int resp_len;\n\tu32 spu_hdr_len;\n\tu32 db_size;\n\tu32 stat_pad_len;\n\tu32 pad_len;\n\tstruct brcm_message *mssg;\t \n\tstruct spu_request_opts req_opts;\n\tstruct spu_cipher_parms cipher_parms;\n\tstruct spu_hash_parms hash_parms;\n\tstruct spu_aead_parms aead_parms;\n\tint assoc_nents = 0;\n\tbool incl_icv = false;\n\tunsigned int digestsize = ctx->digestsize;\n\n\t \n\tu8 rx_frag_num = 2;\t \n\tu8 tx_frag_num = 1;\n\n\t \n\tchunksize = rctx->total_todo;\n\n\tflow_log(\"%s: chunksize %u\\n\", __func__, chunksize);\n\n\tmemset(&req_opts, 0, sizeof(req_opts));\n\tmemset(&hash_parms, 0, sizeof(hash_parms));\n\tmemset(&aead_parms, 0, sizeof(aead_parms));\n\n\treq_opts.is_inbound = !(rctx->is_encrypt);\n\treq_opts.auth_first = ctx->auth_first;\n\treq_opts.is_aead = true;\n\treq_opts.is_esp = ctx->is_esp;\n\n\tcipher_parms.alg = ctx->cipher.alg;\n\tcipher_parms.mode = ctx->cipher.mode;\n\tcipher_parms.type = ctx->cipher_type;\n\tcipher_parms.key_buf = ctx->enckey;\n\tcipher_parms.key_len = ctx->enckeylen;\n\tcipher_parms.iv_buf = rctx->msg_buf.iv_ctr;\n\tcipher_parms.iv_len = rctx->iv_ctr_len;\n\n\thash_parms.alg = ctx->auth.alg;\n\thash_parms.mode = ctx->auth.mode;\n\thash_parms.type = HASH_TYPE_NONE;\n\thash_parms.key_buf = (u8 *)ctx->authkey;\n\thash_parms.key_len = ctx->authkeylen;\n\thash_parms.digestsize = digestsize;\n\n\tif ((ctx->auth.alg == HASH_ALG_SHA224) &&\n\t    (ctx->authkeylen < SHA224_DIGEST_SIZE))\n\t\thash_parms.key_len = SHA224_DIGEST_SIZE;\n\n\taead_parms.assoc_size = req->assoclen;\n\tif (ctx->is_esp && !ctx->is_rfc4543) {\n\t\t \n\t\taead_parms.assoc_size -= GCM_RFC4106_IV_SIZE;\n\n\t\tif (rctx->is_encrypt) {\n\t\t\taead_parms.return_iv = true;\n\t\t\taead_parms.ret_iv_len = GCM_RFC4106_IV_SIZE;\n\t\t\taead_parms.ret_iv_off = GCM_ESP_SALT_SIZE;\n\t\t}\n\t} else {\n\t\taead_parms.ret_iv_len = 0;\n\t}\n\n\t \n\trctx->src_nents = spu_sg_count(rctx->src_sg, rctx->src_skip, chunksize);\n\trctx->dst_nents = spu_sg_count(rctx->dst_sg, rctx->dst_skip, chunksize);\n\tif (aead_parms.assoc_size)\n\t\tassoc_nents = spu_sg_count(rctx->assoc, 0,\n\t\t\t\t\t   aead_parms.assoc_size);\n\n\tmssg = &rctx->mb_mssg;\n\n\trctx->total_sent = chunksize;\n\trctx->src_sent = chunksize;\n\tif (spu->spu_assoc_resp_len(ctx->cipher.mode,\n\t\t\t\t    aead_parms.assoc_size,\n\t\t\t\t    aead_parms.ret_iv_len,\n\t\t\t\t    rctx->is_encrypt))\n\t\trx_frag_num++;\n\n\taead_parms.iv_len = spu->spu_aead_ivlen(ctx->cipher.mode,\n\t\t\t\t\t\trctx->iv_ctr_len);\n\n\tif (ctx->auth.alg == HASH_ALG_AES)\n\t\thash_parms.type = (enum hash_type)ctx->cipher_type;\n\n\t \n\taead_parms.aad_pad_len = spu->spu_gcm_ccm_pad_len(ctx->cipher.mode,\n\t\t\t\t\t\t aead_parms.assoc_size);\n\n\t \n\taead_parms.data_pad_len = spu->spu_gcm_ccm_pad_len(ctx->cipher.mode,\n\t\t\t\t\t\t\t   chunksize);\n\n\tif (ctx->cipher.mode == CIPHER_MODE_CCM) {\n\t\t \n\t\taead_parms.aad_pad_len = spu->spu_gcm_ccm_pad_len(\n\t\t\t\t\t ctx->cipher.mode,\n\t\t\t\t\t aead_parms.assoc_size + 2);\n\n\t\t \n\t\tif (!rctx->is_encrypt)\n\t\t\taead_parms.data_pad_len =\n\t\t\t\tspu->spu_gcm_ccm_pad_len(ctx->cipher.mode,\n\t\t\t\t\t\t\tchunksize - digestsize);\n\n\t\t \n\t\tspu->spu_ccm_update_iv(digestsize, &cipher_parms, req->assoclen,\n\t\t\t\t       chunksize, rctx->is_encrypt,\n\t\t\t\t       ctx->is_esp);\n\t}\n\n\tif (ctx->is_rfc4543) {\n\t\t \n\t\taead_parms.aad_pad_len = 0;\n\t\tif (!rctx->is_encrypt)\n\t\t\taead_parms.data_pad_len = spu->spu_gcm_ccm_pad_len(\n\t\t\t\t\tctx->cipher.mode,\n\t\t\t\t\taead_parms.assoc_size + chunksize -\n\t\t\t\t\tdigestsize);\n\t\telse\n\t\t\taead_parms.data_pad_len = spu->spu_gcm_ccm_pad_len(\n\t\t\t\t\tctx->cipher.mode,\n\t\t\t\t\taead_parms.assoc_size + chunksize);\n\n\t\treq_opts.is_rfc4543 = true;\n\t}\n\n\tif (spu_req_incl_icv(ctx->cipher.mode, rctx->is_encrypt)) {\n\t\tincl_icv = true;\n\t\ttx_frag_num++;\n\t\t \n\t\tsg_copy_part_to_buf(req->src, rctx->msg_buf.digest, digestsize,\n\t\t\t\t    req->assoclen + rctx->total_sent -\n\t\t\t\t    digestsize);\n\t}\n\n\tatomic64_add(chunksize, &iproc_priv.bytes_out);\n\n\tflow_log(\"%s()-sent chunksize:%u\\n\", __func__, chunksize);\n\n\t \n\tmemcpy(rctx->msg_buf.bcm_spu_req_hdr, BCMHEADER, BCM_HDR_LEN);\n\n\tspu_hdr_len = spu->spu_create_request(rctx->msg_buf.bcm_spu_req_hdr +\n\t\t\t\t\t      BCM_HDR_LEN, &req_opts,\n\t\t\t\t\t      &cipher_parms, &hash_parms,\n\t\t\t\t\t      &aead_parms, chunksize);\n\n\t \n\tdb_size = spu_real_db_size(aead_parms.assoc_size, aead_parms.iv_len, 0,\n\t\t\t\t   chunksize, aead_parms.aad_pad_len,\n\t\t\t\t   aead_parms.data_pad_len, 0);\n\n\tstat_pad_len = spu->spu_wordalign_padlen(db_size);\n\n\tif (stat_pad_len)\n\t\trx_frag_num++;\n\tpad_len = aead_parms.data_pad_len + stat_pad_len;\n\tif (pad_len) {\n\t\ttx_frag_num++;\n\t\tspu->spu_request_pad(rctx->msg_buf.spu_req_pad,\n\t\t\t\t     aead_parms.data_pad_len, 0,\n\t\t\t\t     ctx->auth.alg, ctx->auth.mode,\n\t\t\t\t     rctx->total_sent, stat_pad_len);\n\t}\n\n\tspu->spu_dump_msg_hdr(rctx->msg_buf.bcm_spu_req_hdr + BCM_HDR_LEN,\n\t\t\t      spu_hdr_len);\n\tdump_sg(rctx->assoc, 0, aead_parms.assoc_size);\n\tpacket_dump(\"    aead iv: \", rctx->msg_buf.iv_ctr, aead_parms.iv_len);\n\tpacket_log(\"BD:\\n\");\n\tdump_sg(rctx->src_sg, rctx->src_skip, chunksize);\n\tpacket_dump(\"   pad: \", rctx->msg_buf.spu_req_pad, pad_len);\n\n\t \n\tmemset(mssg, 0, sizeof(*mssg));\n\tmssg->type = BRCM_MESSAGE_SPU;\n\tmssg->ctx = rctx;\t \n\n\t \n\trx_frag_num += rctx->dst_nents;\n\tresp_len = chunksize;\n\n\t \n\trx_frag_num++;\n\n\tif (((ctx->cipher.mode == CIPHER_MODE_GCM) ||\n\t     (ctx->cipher.mode == CIPHER_MODE_CCM)) && !rctx->is_encrypt) {\n\t\t \n\t\tresp_len -= ctx->digestsize;\n\t\tif (resp_len == 0)\n\t\t\t \n\t\t\trx_frag_num -= rctx->dst_nents;\n\t}\n\n\terr = spu_aead_rx_sg_create(mssg, req, rctx, rx_frag_num,\n\t\t\t\t    aead_parms.assoc_size,\n\t\t\t\t    aead_parms.ret_iv_len, resp_len, digestsize,\n\t\t\t\t    stat_pad_len);\n\tif (err)\n\t\treturn err;\n\n\t \n\ttx_frag_num += rctx->src_nents;\n\ttx_frag_num += assoc_nents;\n\tif (aead_parms.aad_pad_len)\n\t\ttx_frag_num++;\n\tif (aead_parms.iv_len)\n\t\ttx_frag_num++;\n\tif (spu->spu_tx_status_len())\n\t\ttx_frag_num++;\n\terr = spu_aead_tx_sg_create(mssg, rctx, tx_frag_num, spu_hdr_len,\n\t\t\t\t    rctx->assoc, aead_parms.assoc_size,\n\t\t\t\t    assoc_nents, aead_parms.iv_len, chunksize,\n\t\t\t\t    aead_parms.aad_pad_len, pad_len, incl_icv);\n\tif (err)\n\t\treturn err;\n\n\terr = mailbox_send_message(mssg, req->base.flags, rctx->chan_idx);\n\tif (unlikely(err < 0))\n\t\treturn err;\n\n\treturn -EINPROGRESS;\n}\n\n \nstatic void handle_aead_resp(struct iproc_reqctx_s *rctx)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct crypto_async_request *areq = rctx->parent;\n\tstruct aead_request *req = container_of(areq,\n\t\t\t\t\t\tstruct aead_request, base);\n\tstruct iproc_ctx_s *ctx = rctx->ctx;\n\tu32 payload_len;\n\tunsigned int icv_offset;\n\tu32 result_len;\n\n\t \n\tpayload_len = spu->spu_payload_length(rctx->msg_buf.spu_resp_hdr);\n\tflow_log(\"payload_len %u\\n\", payload_len);\n\n\t \n\tatomic64_add(payload_len, &iproc_priv.bytes_in);\n\n\tif (req->assoclen)\n\t\tpacket_dump(\"  assoc_data \", rctx->msg_buf.a.resp_aad,\n\t\t\t    req->assoclen);\n\n\t \n\tresult_len = req->cryptlen;\n\tif (rctx->is_encrypt) {\n\t\ticv_offset = req->assoclen + rctx->total_sent;\n\t\tpacket_dump(\"  ICV: \", rctx->msg_buf.digest, ctx->digestsize);\n\t\tflow_log(\"copying ICV to dst sg at offset %u\\n\", icv_offset);\n\t\tsg_copy_part_from_buf(req->dst, rctx->msg_buf.digest,\n\t\t\t\t      ctx->digestsize, icv_offset);\n\t\tresult_len += ctx->digestsize;\n\t}\n\n\tpacket_log(\"response data:  \");\n\tdump_sg(req->dst, req->assoclen, result_len);\n\n\tatomic_inc(&iproc_priv.op_counts[SPU_OP_AEAD]);\n\tif (ctx->cipher.alg == CIPHER_ALG_AES) {\n\t\tif (ctx->cipher.mode == CIPHER_MODE_CCM)\n\t\t\tatomic_inc(&iproc_priv.aead_cnt[AES_CCM]);\n\t\telse if (ctx->cipher.mode == CIPHER_MODE_GCM)\n\t\t\tatomic_inc(&iproc_priv.aead_cnt[AES_GCM]);\n\t\telse\n\t\t\tatomic_inc(&iproc_priv.aead_cnt[AUTHENC]);\n\t} else {\n\t\tatomic_inc(&iproc_priv.aead_cnt[AUTHENC]);\n\t}\n}\n\n \nstatic void spu_chunk_cleanup(struct iproc_reqctx_s *rctx)\n{\n\t \n\tstruct brcm_message *mssg = &rctx->mb_mssg;\n\n\tkfree(mssg->spu.src);\n\tkfree(mssg->spu.dst);\n\tmemset(mssg, 0, sizeof(struct brcm_message));\n}\n\n \nstatic void finish_req(struct iproc_reqctx_s *rctx, int err)\n{\n\tstruct crypto_async_request *areq = rctx->parent;\n\n\tflow_log(\"%s() err:%d\\n\\n\", __func__, err);\n\n\t \n\tspu_chunk_cleanup(rctx);\n\n\tif (areq)\n\t\tcrypto_request_complete(areq, err);\n}\n\n \nstatic void spu_rx_callback(struct mbox_client *cl, void *msg)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct brcm_message *mssg = msg;\n\tstruct iproc_reqctx_s *rctx;\n\tint err;\n\n\trctx = mssg->ctx;\n\tif (unlikely(!rctx)) {\n\t\t \n\t\tpr_err(\"%s(): no request context\", __func__);\n\t\terr = -EFAULT;\n\t\tgoto cb_finish;\n\t}\n\n\t \n\terr = spu->spu_status_process(rctx->msg_buf.rx_stat);\n\tif (err != 0) {\n\t\tif (err == SPU_INVALID_ICV)\n\t\t\tatomic_inc(&iproc_priv.bad_icv);\n\t\terr = -EBADMSG;\n\t\tgoto cb_finish;\n\t}\n\n\t \n\tswitch (rctx->ctx->alg->type) {\n\tcase CRYPTO_ALG_TYPE_SKCIPHER:\n\t\thandle_skcipher_resp(rctx);\n\t\tbreak;\n\tcase CRYPTO_ALG_TYPE_AHASH:\n\t\thandle_ahash_resp(rctx);\n\t\tbreak;\n\tcase CRYPTO_ALG_TYPE_AEAD:\n\t\thandle_aead_resp(rctx);\n\t\tbreak;\n\tdefault:\n\t\terr = -EINVAL;\n\t\tgoto cb_finish;\n\t}\n\n\t \n\tif (rctx->total_sent < rctx->total_todo) {\n\t\t \n\t\tspu_chunk_cleanup(rctx);\n\n\t\tswitch (rctx->ctx->alg->type) {\n\t\tcase CRYPTO_ALG_TYPE_SKCIPHER:\n\t\t\terr = handle_skcipher_req(rctx);\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AHASH:\n\t\t\terr = handle_ahash_req(rctx);\n\t\t\tif (err == -EAGAIN)\n\t\t\t\t \n\t\t\t\terr = 0;\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AEAD:\n\t\t\terr = handle_aead_req(rctx);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terr = -EINVAL;\n\t\t}\n\n\t\tif (err == -EINPROGRESS)\n\t\t\t \n\t\t\treturn;\n\t}\n\ncb_finish:\n\tfinish_req(rctx, err);\n}\n\n \n\n \nstatic int skcipher_enqueue(struct skcipher_request *req, bool encrypt)\n{\n\tstruct iproc_reqctx_s *rctx = skcipher_request_ctx(req);\n\tstruct iproc_ctx_s *ctx =\n\t    crypto_skcipher_ctx(crypto_skcipher_reqtfm(req));\n\tint err;\n\n\tflow_log(\"%s() enc:%u\\n\", __func__, encrypt);\n\n\trctx->gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |\n\t\t       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;\n\trctx->parent = &req->base;\n\trctx->is_encrypt = encrypt;\n\trctx->bd_suppress = false;\n\trctx->total_todo = req->cryptlen;\n\trctx->src_sent = 0;\n\trctx->total_sent = 0;\n\trctx->total_received = 0;\n\trctx->ctx = ctx;\n\n\t \n\trctx->src_sg = req->src;\n\trctx->src_nents = 0;\n\trctx->src_skip = 0;\n\trctx->dst_sg = req->dst;\n\trctx->dst_nents = 0;\n\trctx->dst_skip = 0;\n\n\tif (ctx->cipher.mode == CIPHER_MODE_CBC ||\n\t    ctx->cipher.mode == CIPHER_MODE_CTR ||\n\t    ctx->cipher.mode == CIPHER_MODE_OFB ||\n\t    ctx->cipher.mode == CIPHER_MODE_XTS ||\n\t    ctx->cipher.mode == CIPHER_MODE_GCM ||\n\t    ctx->cipher.mode == CIPHER_MODE_CCM) {\n\t\trctx->iv_ctr_len =\n\t\t    crypto_skcipher_ivsize(crypto_skcipher_reqtfm(req));\n\t\tmemcpy(rctx->msg_buf.iv_ctr, req->iv, rctx->iv_ctr_len);\n\t} else {\n\t\trctx->iv_ctr_len = 0;\n\t}\n\n\t \n\trctx->chan_idx = select_channel();\n\terr = handle_skcipher_req(rctx);\n\tif (err != -EINPROGRESS)\n\t\t \n\t\tspu_chunk_cleanup(rctx);\n\n\treturn err;\n}\n\nstatic int des_setkey(struct crypto_skcipher *cipher, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_skcipher_ctx(cipher);\n\tint err;\n\n\terr = verify_skcipher_des_key(cipher, key);\n\tif (err)\n\t\treturn err;\n\n\tctx->cipher_type = CIPHER_TYPE_DES;\n\treturn 0;\n}\n\nstatic int threedes_setkey(struct crypto_skcipher *cipher, const u8 *key,\n\t\t\t   unsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_skcipher_ctx(cipher);\n\tint err;\n\n\terr = verify_skcipher_des3_key(cipher, key);\n\tif (err)\n\t\treturn err;\n\n\tctx->cipher_type = CIPHER_TYPE_3DES;\n\treturn 0;\n}\n\nstatic int aes_setkey(struct crypto_skcipher *cipher, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_skcipher_ctx(cipher);\n\n\tif (ctx->cipher.mode == CIPHER_MODE_XTS)\n\t\t \n\t\tkeylen = keylen / 2;\n\n\tswitch (keylen) {\n\tcase AES_KEYSIZE_128:\n\t\tctx->cipher_type = CIPHER_TYPE_AES128;\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\tctx->cipher_type = CIPHER_TYPE_AES192;\n\t\tbreak;\n\tcase AES_KEYSIZE_256:\n\t\tctx->cipher_type = CIPHER_TYPE_AES256;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tWARN_ON((ctx->max_payload != SPU_MAX_PAYLOAD_INF) &&\n\t\t((ctx->max_payload % AES_BLOCK_SIZE) != 0));\n\treturn 0;\n}\n\nstatic int skcipher_setkey(struct crypto_skcipher *cipher, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct iproc_ctx_s *ctx = crypto_skcipher_ctx(cipher);\n\tstruct spu_cipher_parms cipher_parms;\n\tu32 alloc_len = 0;\n\tint err;\n\n\tflow_log(\"skcipher_setkey() keylen: %d\\n\", keylen);\n\tflow_dump(\"  key: \", key, keylen);\n\n\tswitch (ctx->cipher.alg) {\n\tcase CIPHER_ALG_DES:\n\t\terr = des_setkey(cipher, key, keylen);\n\t\tbreak;\n\tcase CIPHER_ALG_3DES:\n\t\terr = threedes_setkey(cipher, key, keylen);\n\t\tbreak;\n\tcase CIPHER_ALG_AES:\n\t\terr = aes_setkey(cipher, key, keylen);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s() Error: unknown cipher alg\\n\", __func__);\n\t\terr = -EINVAL;\n\t}\n\tif (err)\n\t\treturn err;\n\n\tmemcpy(ctx->enckey, key, keylen);\n\tctx->enckeylen = keylen;\n\n\t \n\tif ((ctx->cipher.alg == CIPHER_ALG_AES) &&\n\t    (ctx->cipher.mode == CIPHER_MODE_XTS)) {\n\t\tunsigned int xts_keylen = keylen / 2;\n\n\t\tmemcpy(ctx->enckey, key + xts_keylen, xts_keylen);\n\t\tmemcpy(ctx->enckey + xts_keylen, key, xts_keylen);\n\t}\n\n\tif (spu->spu_type == SPU_TYPE_SPUM)\n\t\talloc_len = BCM_HDR_LEN + SPU_HEADER_ALLOC_LEN;\n\telse if (spu->spu_type == SPU_TYPE_SPU2)\n\t\talloc_len = BCM_HDR_LEN + SPU2_HEADER_ALLOC_LEN;\n\tmemset(ctx->bcm_spu_req_hdr, 0, alloc_len);\n\tcipher_parms.iv_buf = NULL;\n\tcipher_parms.iv_len = crypto_skcipher_ivsize(cipher);\n\tflow_log(\"%s: iv_len %u\\n\", __func__, cipher_parms.iv_len);\n\n\tcipher_parms.alg = ctx->cipher.alg;\n\tcipher_parms.mode = ctx->cipher.mode;\n\tcipher_parms.type = ctx->cipher_type;\n\tcipher_parms.key_buf = ctx->enckey;\n\tcipher_parms.key_len = ctx->enckeylen;\n\n\t \n\tmemcpy(ctx->bcm_spu_req_hdr, BCMHEADER, BCM_HDR_LEN);\n\tctx->spu_req_hdr_len =\n\t    spu->spu_cipher_req_init(ctx->bcm_spu_req_hdr + BCM_HDR_LEN,\n\t\t\t\t     &cipher_parms);\n\n\tctx->spu_resp_hdr_len = spu->spu_response_hdr_len(ctx->authkeylen,\n\t\t\t\t\t\t\t  ctx->enckeylen,\n\t\t\t\t\t\t\t  false);\n\n\tatomic_inc(&iproc_priv.setkey_cnt[SPU_OP_CIPHER]);\n\n\treturn 0;\n}\n\nstatic int skcipher_encrypt(struct skcipher_request *req)\n{\n\tflow_log(\"skcipher_encrypt() nbytes:%u\\n\", req->cryptlen);\n\n\treturn skcipher_enqueue(req, true);\n}\n\nstatic int skcipher_decrypt(struct skcipher_request *req)\n{\n\tflow_log(\"skcipher_decrypt() nbytes:%u\\n\", req->cryptlen);\n\treturn skcipher_enqueue(req, false);\n}\n\nstatic int ahash_enqueue(struct ahash_request *req)\n{\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\tint err;\n\tconst char *alg_name;\n\n\tflow_log(\"ahash_enqueue() nbytes:%u\\n\", req->nbytes);\n\n\trctx->gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |\n\t\t       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;\n\trctx->parent = &req->base;\n\trctx->ctx = ctx;\n\trctx->bd_suppress = true;\n\tmemset(&rctx->mb_mssg, 0, sizeof(struct brcm_message));\n\n\t \n\trctx->src_sg = req->src;\n\trctx->src_skip = 0;\n\trctx->src_nents = 0;\n\trctx->dst_sg = NULL;\n\trctx->dst_skip = 0;\n\trctx->dst_nents = 0;\n\n\t \n\tif ((rctx->is_final == 1) && (rctx->total_todo == 0) &&\n\t    (iproc_priv.spu.spu_type == SPU_TYPE_SPU2)) {\n\t\talg_name = crypto_ahash_alg_name(tfm);\n\t\tflow_log(\"Doing %sfinal %s zero-len hash request in software\\n\",\n\t\t\t rctx->is_final ? \"\" : \"non-\", alg_name);\n\t\terr = do_shash((unsigned char *)alg_name, req->result,\n\t\t\t       NULL, 0, NULL, 0, ctx->authkey,\n\t\t\t       ctx->authkeylen);\n\t\tif (err < 0)\n\t\t\tflow_log(\"Hash request failed with error %d\\n\", err);\n\t\treturn err;\n\t}\n\t \n\trctx->chan_idx = select_channel();\n\n\terr = handle_ahash_req(rctx);\n\tif (err != -EINPROGRESS)\n\t\t \n\t\tspu_chunk_cleanup(rctx);\n\n\tif (err == -EAGAIN)\n\t\t \n\t\terr = 0;\n\n\treturn err;\n}\n\nstatic int __ahash_init(struct ahash_request *req)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\n\tflow_log(\"%s()\\n\", __func__);\n\n\t \n\trctx->hash_carry_len = 0;\n\trctx->is_final = 0;\n\n\trctx->total_todo = 0;\n\trctx->src_sent = 0;\n\trctx->total_sent = 0;\n\trctx->total_received = 0;\n\n\tctx->digestsize = crypto_ahash_digestsize(tfm);\n\t \n\tWARN_ON(ctx->digestsize > MAX_DIGEST_SIZE);\n\n\trctx->is_sw_hmac = false;\n\n\tctx->spu_resp_hdr_len = spu->spu_response_hdr_len(ctx->authkeylen, 0,\n\t\t\t\t\t\t\t  true);\n\n\treturn 0;\n}\n\n \nstatic bool spu_no_incr_hash(struct iproc_ctx_s *ctx)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\n\tif (spu->spu_type == SPU_TYPE_SPU2)\n\t\treturn true;\n\n\tif ((ctx->auth.alg == HASH_ALG_AES) &&\n\t    (ctx->auth.mode == HASH_MODE_XCBC))\n\t\treturn true;\n\n\t \n\treturn false;\n}\n\nstatic int ahash_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\tconst char *alg_name;\n\tstruct crypto_shash *hash;\n\tint ret;\n\tgfp_t gfp;\n\n\tif (spu_no_incr_hash(ctx)) {\n\t\t \n\t\talg_name = crypto_ahash_alg_name(tfm);\n\t\thash = crypto_alloc_shash(alg_name, 0, 0);\n\t\tif (IS_ERR(hash)) {\n\t\t\tret = PTR_ERR(hash);\n\t\t\tgoto err;\n\t\t}\n\n\t\tgfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |\n\t\t       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;\n\t\tctx->shash = kmalloc(sizeof(*ctx->shash) +\n\t\t\t\t     crypto_shash_descsize(hash), gfp);\n\t\tif (!ctx->shash) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_hash;\n\t\t}\n\t\tctx->shash->tfm = hash;\n\n\t\t \n\t\tif (ctx->authkeylen > 0) {\n\t\t\tret = crypto_shash_setkey(hash, ctx->authkey,\n\t\t\t\t\t\t  ctx->authkeylen);\n\t\t\tif (ret)\n\t\t\t\tgoto err_shash;\n\t\t}\n\n\t\t \n\t\tret = crypto_shash_init(ctx->shash);\n\t\tif (ret)\n\t\t\tgoto err_shash;\n\t} else {\n\t\t \n\t\tret = __ahash_init(req);\n\t}\n\n\treturn ret;\n\nerr_shash:\n\tkfree(ctx->shash);\nerr_hash:\n\tcrypto_free_shash(hash);\nerr:\n\treturn ret;\n}\n\nstatic int __ahash_update(struct ahash_request *req)\n{\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\n\tflow_log(\"ahash_update() nbytes:%u\\n\", req->nbytes);\n\n\tif (!req->nbytes)\n\t\treturn 0;\n\trctx->total_todo += req->nbytes;\n\trctx->src_sent = 0;\n\n\treturn ahash_enqueue(req);\n}\n\nstatic int ahash_update(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\tu8 *tmpbuf;\n\tint ret;\n\tint nents;\n\tgfp_t gfp;\n\n\tif (spu_no_incr_hash(ctx)) {\n\t\t \n\t\tif (req->src)\n\t\t\tnents = sg_nents(req->src);\n\t\telse\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tgfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |\n\t\t       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;\n\t\ttmpbuf = kmalloc(req->nbytes, gfp);\n\t\tif (!tmpbuf)\n\t\t\treturn -ENOMEM;\n\n\t\tif (sg_copy_to_buffer(req->src, nents, tmpbuf, req->nbytes) !=\n\t\t\t\treq->nbytes) {\n\t\t\tkfree(tmpbuf);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tret = crypto_shash_update(ctx->shash, tmpbuf, req->nbytes);\n\t\tkfree(tmpbuf);\n\t} else {\n\t\t \n\t\tret = __ahash_update(req);\n\t}\n\n\treturn ret;\n}\n\nstatic int __ahash_final(struct ahash_request *req)\n{\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\n\tflow_log(\"ahash_final() nbytes:%u\\n\", req->nbytes);\n\n\trctx->is_final = 1;\n\n\treturn ahash_enqueue(req);\n}\n\nstatic int ahash_final(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\tint ret;\n\n\tif (spu_no_incr_hash(ctx)) {\n\t\t \n\t\tret = crypto_shash_final(ctx->shash, req->result);\n\n\t\t \n\t\tcrypto_free_shash(ctx->shash->tfm);\n\t\tkfree(ctx->shash);\n\n\t} else {\n\t\t \n\t\tret = __ahash_final(req);\n\t}\n\n\treturn ret;\n}\n\nstatic int __ahash_finup(struct ahash_request *req)\n{\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\n\tflow_log(\"ahash_finup() nbytes:%u\\n\", req->nbytes);\n\n\trctx->total_todo += req->nbytes;\n\trctx->src_sent = 0;\n\trctx->is_final = 1;\n\n\treturn ahash_enqueue(req);\n}\n\nstatic int ahash_finup(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\tu8 *tmpbuf;\n\tint ret;\n\tint nents;\n\tgfp_t gfp;\n\n\tif (spu_no_incr_hash(ctx)) {\n\t\t \n\t\tif (req->src) {\n\t\t\tnents = sg_nents(req->src);\n\t\t} else {\n\t\t\tret = -EINVAL;\n\t\t\tgoto ahash_finup_exit;\n\t\t}\n\n\t\t \n\t\tgfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |\n\t\t       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;\n\t\ttmpbuf = kmalloc(req->nbytes, gfp);\n\t\tif (!tmpbuf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto ahash_finup_exit;\n\t\t}\n\n\t\tif (sg_copy_to_buffer(req->src, nents, tmpbuf, req->nbytes) !=\n\t\t\t\treq->nbytes) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto ahash_finup_free;\n\t\t}\n\n\t\t \n\t\tret = crypto_shash_finup(ctx->shash, tmpbuf, req->nbytes,\n\t\t\t\t\t req->result);\n\t} else {\n\t\t \n\t\treturn __ahash_finup(req);\n\t}\nahash_finup_free:\n\tkfree(tmpbuf);\n\nahash_finup_exit:\n\t \n\tcrypto_free_shash(ctx->shash->tfm);\n\tkfree(ctx->shash);\n\treturn ret;\n}\n\nstatic int ahash_digest(struct ahash_request *req)\n{\n\tint err;\n\n\tflow_log(\"ahash_digest() nbytes:%u\\n\", req->nbytes);\n\n\t \n\terr = __ahash_init(req);\n\tif (!err)\n\t\terr = __ahash_finup(req);\n\n\treturn err;\n}\n\nstatic int ahash_setkey(struct crypto_ahash *ahash, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(ahash);\n\n\tflow_log(\"%s() ahash:%p key:%p keylen:%u\\n\",\n\t\t __func__, ahash, key, keylen);\n\tflow_dump(\"  key: \", key, keylen);\n\n\tif (ctx->auth.alg == HASH_ALG_AES) {\n\t\tswitch (keylen) {\n\t\tcase AES_KEYSIZE_128:\n\t\t\tctx->cipher_type = CIPHER_TYPE_AES128;\n\t\t\tbreak;\n\t\tcase AES_KEYSIZE_192:\n\t\t\tctx->cipher_type = CIPHER_TYPE_AES192;\n\t\t\tbreak;\n\t\tcase AES_KEYSIZE_256:\n\t\t\tctx->cipher_type = CIPHER_TYPE_AES256;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"%s() Error: Invalid key length\\n\", __func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tpr_err(\"%s() Error: unknown hash alg\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\tmemcpy(ctx->authkey, key, keylen);\n\tctx->authkeylen = keylen;\n\n\treturn 0;\n}\n\nstatic int ahash_export(struct ahash_request *req, void *out)\n{\n\tconst struct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\tstruct spu_hash_export_s *spu_exp = (struct spu_hash_export_s *)out;\n\n\tspu_exp->total_todo = rctx->total_todo;\n\tspu_exp->total_sent = rctx->total_sent;\n\tspu_exp->is_sw_hmac = rctx->is_sw_hmac;\n\tmemcpy(spu_exp->hash_carry, rctx->hash_carry, sizeof(rctx->hash_carry));\n\tspu_exp->hash_carry_len = rctx->hash_carry_len;\n\tmemcpy(spu_exp->incr_hash, rctx->incr_hash, sizeof(rctx->incr_hash));\n\n\treturn 0;\n}\n\nstatic int ahash_import(struct ahash_request *req, const void *in)\n{\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\tstruct spu_hash_export_s *spu_exp = (struct spu_hash_export_s *)in;\n\n\trctx->total_todo = spu_exp->total_todo;\n\trctx->total_sent = spu_exp->total_sent;\n\trctx->is_sw_hmac = spu_exp->is_sw_hmac;\n\tmemcpy(rctx->hash_carry, spu_exp->hash_carry, sizeof(rctx->hash_carry));\n\trctx->hash_carry_len = spu_exp->hash_carry_len;\n\tmemcpy(rctx->incr_hash, spu_exp->incr_hash, sizeof(rctx->incr_hash));\n\n\treturn 0;\n}\n\nstatic int ahash_hmac_setkey(struct crypto_ahash *ahash, const u8 *key,\n\t\t\t     unsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(ahash);\n\tunsigned int blocksize =\n\t\tcrypto_tfm_alg_blocksize(crypto_ahash_tfm(ahash));\n\tunsigned int digestsize = crypto_ahash_digestsize(ahash);\n\tunsigned int index;\n\tint rc;\n\n\tflow_log(\"%s() ahash:%p key:%p keylen:%u blksz:%u digestsz:%u\\n\",\n\t\t __func__, ahash, key, keylen, blocksize, digestsize);\n\tflow_dump(\"  key: \", key, keylen);\n\n\tif (keylen > blocksize) {\n\t\tswitch (ctx->auth.alg) {\n\t\tcase HASH_ALG_MD5:\n\t\t\trc = do_shash(\"md5\", ctx->authkey, key, keylen, NULL,\n\t\t\t\t      0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA1:\n\t\t\trc = do_shash(\"sha1\", ctx->authkey, key, keylen, NULL,\n\t\t\t\t      0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA224:\n\t\t\trc = do_shash(\"sha224\", ctx->authkey, key, keylen, NULL,\n\t\t\t\t      0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA256:\n\t\t\trc = do_shash(\"sha256\", ctx->authkey, key, keylen, NULL,\n\t\t\t\t      0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA384:\n\t\t\trc = do_shash(\"sha384\", ctx->authkey, key, keylen, NULL,\n\t\t\t\t      0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA512:\n\t\t\trc = do_shash(\"sha512\", ctx->authkey, key, keylen, NULL,\n\t\t\t\t      0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA3_224:\n\t\t\trc = do_shash(\"sha3-224\", ctx->authkey, key, keylen,\n\t\t\t\t      NULL, 0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA3_256:\n\t\t\trc = do_shash(\"sha3-256\", ctx->authkey, key, keylen,\n\t\t\t\t      NULL, 0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA3_384:\n\t\t\trc = do_shash(\"sha3-384\", ctx->authkey, key, keylen,\n\t\t\t\t      NULL, 0, NULL, 0);\n\t\t\tbreak;\n\t\tcase HASH_ALG_SHA3_512:\n\t\t\trc = do_shash(\"sha3-512\", ctx->authkey, key, keylen,\n\t\t\t\t      NULL, 0, NULL, 0);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpr_err(\"%s() Error: unknown hash alg\\n\", __func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (rc < 0) {\n\t\t\tpr_err(\"%s() Error %d computing shash for %s\\n\",\n\t\t\t       __func__, rc, hash_alg_name[ctx->auth.alg]);\n\t\t\treturn rc;\n\t\t}\n\t\tctx->authkeylen = digestsize;\n\n\t\tflow_log(\"  keylen > digestsize... hashed\\n\");\n\t\tflow_dump(\"  newkey: \", ctx->authkey, ctx->authkeylen);\n\t} else {\n\t\tmemcpy(ctx->authkey, key, keylen);\n\t\tctx->authkeylen = keylen;\n\t}\n\n\t \n\tif (iproc_priv.spu.spu_type == SPU_TYPE_SPUM) {\n\t\tmemcpy(ctx->ipad, ctx->authkey, ctx->authkeylen);\n\t\tmemset(ctx->ipad + ctx->authkeylen, 0,\n\t\t       blocksize - ctx->authkeylen);\n\t\tctx->authkeylen = 0;\n\t\tunsafe_memcpy(ctx->opad, ctx->ipad, blocksize,\n\t\t\t      \"fortified memcpy causes -Wrestrict warning\");\n\n\t\tfor (index = 0; index < blocksize; index++) {\n\t\t\tctx->ipad[index] ^= HMAC_IPAD_VALUE;\n\t\t\tctx->opad[index] ^= HMAC_OPAD_VALUE;\n\t\t}\n\n\t\tflow_dump(\"  ipad: \", ctx->ipad, blocksize);\n\t\tflow_dump(\"  opad: \", ctx->opad, blocksize);\n\t}\n\tctx->digestsize = digestsize;\n\tatomic_inc(&iproc_priv.setkey_cnt[SPU_OP_HMAC]);\n\n\treturn 0;\n}\n\nstatic int ahash_hmac_init(struct ahash_request *req)\n{\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\tunsigned int blocksize =\n\t\t\tcrypto_tfm_alg_blocksize(crypto_ahash_tfm(tfm));\n\n\tflow_log(\"ahash_hmac_init()\\n\");\n\n\t \n\tahash_init(req);\n\n\tif (!spu_no_incr_hash(ctx)) {\n\t\t \n\t\trctx->is_sw_hmac = true;\n\t\tctx->auth.mode = HASH_MODE_HASH;\n\t\t \n\t\tmemcpy(rctx->hash_carry, ctx->ipad, blocksize);\n\t\trctx->hash_carry_len = blocksize;\n\t\trctx->total_todo += blocksize;\n\t}\n\n\treturn 0;\n}\n\nstatic int ahash_hmac_update(struct ahash_request *req)\n{\n\tflow_log(\"ahash_hmac_update() nbytes:%u\\n\", req->nbytes);\n\n\tif (!req->nbytes)\n\t\treturn 0;\n\n\treturn ahash_update(req);\n}\n\nstatic int ahash_hmac_final(struct ahash_request *req)\n{\n\tflow_log(\"ahash_hmac_final() nbytes:%u\\n\", req->nbytes);\n\n\treturn ahash_final(req);\n}\n\nstatic int ahash_hmac_finup(struct ahash_request *req)\n{\n\tflow_log(\"ahash_hmac_finupl() nbytes:%u\\n\", req->nbytes);\n\n\treturn ahash_finup(req);\n}\n\nstatic int ahash_hmac_digest(struct ahash_request *req)\n{\n\tstruct iproc_reqctx_s *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_ahash_ctx(tfm);\n\tunsigned int blocksize =\n\t\t\tcrypto_tfm_alg_blocksize(crypto_ahash_tfm(tfm));\n\n\tflow_log(\"ahash_hmac_digest() nbytes:%u\\n\", req->nbytes);\n\n\t \n\t__ahash_init(req);\n\n\tif (iproc_priv.spu.spu_type == SPU_TYPE_SPU2) {\n\t\t \n\t\trctx->is_sw_hmac = false;\n\t\tctx->auth.mode = HASH_MODE_HMAC;\n\t} else {\n\t\trctx->is_sw_hmac = true;\n\t\tctx->auth.mode = HASH_MODE_HASH;\n\t\t \n\t\tmemcpy(rctx->hash_carry, ctx->ipad, blocksize);\n\t\trctx->hash_carry_len = blocksize;\n\t\trctx->total_todo += blocksize;\n\t}\n\n\treturn __ahash_finup(req);\n}\n\n \n\nstatic int aead_need_fallback(struct aead_request *req)\n{\n\tstruct iproc_reqctx_s *rctx = aead_request_ctx(req);\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(aead);\n\tu32 payload_len;\n\n\t \n\tif (((ctx->cipher.mode == CIPHER_MODE_GCM) ||\n\t     (ctx->cipher.mode == CIPHER_MODE_CCM)) &&\n\t    (req->assoclen == 0)) {\n\t\tif ((rctx->is_encrypt && (req->cryptlen == 0)) ||\n\t\t    (!rctx->is_encrypt && (req->cryptlen == ctx->digestsize))) {\n\t\t\tflow_log(\"AES GCM/CCM needs fallback for 0 len req\\n\");\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\t \n\tif ((ctx->cipher.mode == CIPHER_MODE_CCM) &&\n\t    (spu->spu_type == SPU_TYPE_SPUM) &&\n\t    (ctx->digestsize != 8) && (ctx->digestsize != 12) &&\n\t    (ctx->digestsize != 16)) {\n\t\tflow_log(\"%s() AES CCM needs fallback for digest size %d\\n\",\n\t\t\t __func__, ctx->digestsize);\n\t\treturn 1;\n\t}\n\n\t \n\tif ((ctx->cipher.mode == CIPHER_MODE_CCM) &&\n\t    (spu->spu_subtype == SPU_SUBTYPE_SPUM_NSP) &&\n\t    (req->assoclen == 0)) {\n\t\tflow_log(\"%s() AES_CCM needs fallback for 0 len AAD on NSP\\n\",\n\t\t\t __func__);\n\t\treturn 1;\n\t}\n\n\t \n\tif (ctx->cipher.mode == CIPHER_MODE_GCM &&\n\t    ctx->cipher.alg == CIPHER_ALG_AES &&\n\t    rctx->iv_ctr_len == GCM_RFC4106_IV_SIZE &&\n\t    req->assoclen != 16 && req->assoclen != 20) {\n\t\tflow_log(\"RFC4106/RFC4543 needs fallback for assoclen\"\n\t\t\t \" other than 16 or 20 bytes\\n\");\n\t\treturn 1;\n\t}\n\n\tpayload_len = req->cryptlen;\n\tif (spu->spu_type == SPU_TYPE_SPUM)\n\t\tpayload_len += req->assoclen;\n\n\tflow_log(\"%s() payload len: %u\\n\", __func__, payload_len);\n\n\tif (ctx->max_payload == SPU_MAX_PAYLOAD_INF)\n\t\treturn 0;\n\telse\n\t\treturn payload_len > ctx->max_payload;\n}\n\nstatic int aead_do_fallback(struct aead_request *req, bool is_encrypt)\n{\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct crypto_tfm *tfm = crypto_aead_tfm(aead);\n\tstruct iproc_reqctx_s *rctx = aead_request_ctx(req);\n\tstruct iproc_ctx_s *ctx = crypto_tfm_ctx(tfm);\n\tstruct aead_request *subreq;\n\n\tflow_log(\"%s() enc:%u\\n\", __func__, is_encrypt);\n\n\tif (!ctx->fallback_cipher)\n\t\treturn -EINVAL;\n\n\tsubreq = &rctx->req;\n\taead_request_set_tfm(subreq, ctx->fallback_cipher);\n\taead_request_set_callback(subreq, aead_request_flags(req),\n\t\t\t\t  req->base.complete, req->base.data);\n\taead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,\n\t\t\t       req->iv);\n\taead_request_set_ad(subreq, req->assoclen);\n\n\treturn is_encrypt ? crypto_aead_encrypt(req) :\n\t\t\t    crypto_aead_decrypt(req);\n}\n\nstatic int aead_enqueue(struct aead_request *req, bool is_encrypt)\n{\n\tstruct iproc_reqctx_s *rctx = aead_request_ctx(req);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(aead);\n\tint err;\n\n\tflow_log(\"%s() enc:%u\\n\", __func__, is_encrypt);\n\n\tif (req->assoclen > MAX_ASSOC_SIZE) {\n\t\tpr_err\n\t\t    (\"%s() Error: associated data too long. (%u > %u bytes)\\n\",\n\t\t     __func__, req->assoclen, MAX_ASSOC_SIZE);\n\t\treturn -EINVAL;\n\t}\n\n\trctx->gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |\n\t\t       CRYPTO_TFM_REQ_MAY_SLEEP)) ? GFP_KERNEL : GFP_ATOMIC;\n\trctx->parent = &req->base;\n\trctx->is_encrypt = is_encrypt;\n\trctx->bd_suppress = false;\n\trctx->total_todo = req->cryptlen;\n\trctx->src_sent = 0;\n\trctx->total_sent = 0;\n\trctx->total_received = 0;\n\trctx->is_sw_hmac = false;\n\trctx->ctx = ctx;\n\tmemset(&rctx->mb_mssg, 0, sizeof(struct brcm_message));\n\n\t \n\trctx->assoc = req->src;\n\n\t \n\tif (spu_sg_at_offset(req->src, req->assoclen, &rctx->src_sg,\n\t\t\t     &rctx->src_skip) < 0) {\n\t\tpr_err(\"%s() Error: Unable to find start of src data\\n\",\n\t\t       __func__);\n\t\treturn -EINVAL;\n\t}\n\n\trctx->src_nents = 0;\n\trctx->dst_nents = 0;\n\tif (req->dst == req->src) {\n\t\trctx->dst_sg = rctx->src_sg;\n\t\trctx->dst_skip = rctx->src_skip;\n\t} else {\n\t\t \n\t\tif (spu_sg_at_offset(req->dst, req->assoclen, &rctx->dst_sg,\n\t\t\t\t     &rctx->dst_skip) < 0) {\n\t\t\tpr_err(\"%s() Error: Unable to find start of dst data\\n\",\n\t\t\t       __func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (ctx->cipher.mode == CIPHER_MODE_CBC ||\n\t    ctx->cipher.mode == CIPHER_MODE_CTR ||\n\t    ctx->cipher.mode == CIPHER_MODE_OFB ||\n\t    ctx->cipher.mode == CIPHER_MODE_XTS ||\n\t    ctx->cipher.mode == CIPHER_MODE_GCM) {\n\t\trctx->iv_ctr_len =\n\t\t\tctx->salt_len +\n\t\t\tcrypto_aead_ivsize(crypto_aead_reqtfm(req));\n\t} else if (ctx->cipher.mode == CIPHER_MODE_CCM) {\n\t\trctx->iv_ctr_len = CCM_AES_IV_SIZE;\n\t} else {\n\t\trctx->iv_ctr_len = 0;\n\t}\n\n\trctx->hash_carry_len = 0;\n\n\tflow_log(\"  src sg: %p\\n\", req->src);\n\tflow_log(\"  rctx->src_sg: %p, src_skip %u\\n\",\n\t\t rctx->src_sg, rctx->src_skip);\n\tflow_log(\"  assoc:  %p, assoclen %u\\n\", rctx->assoc, req->assoclen);\n\tflow_log(\"  dst sg: %p\\n\", req->dst);\n\tflow_log(\"  rctx->dst_sg: %p, dst_skip %u\\n\",\n\t\t rctx->dst_sg, rctx->dst_skip);\n\tflow_log(\"  iv_ctr_len:%u\\n\", rctx->iv_ctr_len);\n\tflow_dump(\"  iv: \", req->iv, rctx->iv_ctr_len);\n\tflow_log(\"  authkeylen:%u\\n\", ctx->authkeylen);\n\tflow_log(\"  is_esp: %s\\n\", ctx->is_esp ? \"yes\" : \"no\");\n\n\tif (ctx->max_payload == SPU_MAX_PAYLOAD_INF)\n\t\tflow_log(\"  max_payload infinite\");\n\telse\n\t\tflow_log(\"  max_payload: %u\\n\", ctx->max_payload);\n\n\tif (unlikely(aead_need_fallback(req)))\n\t\treturn aead_do_fallback(req, is_encrypt);\n\n\t \n\tif (rctx->iv_ctr_len) {\n\t\tif (ctx->salt_len)\n\t\t\tmemcpy(rctx->msg_buf.iv_ctr + ctx->salt_offset,\n\t\t\t       ctx->salt, ctx->salt_len);\n\t\tmemcpy(rctx->msg_buf.iv_ctr + ctx->salt_offset + ctx->salt_len,\n\t\t       req->iv,\n\t\t       rctx->iv_ctr_len - ctx->salt_len - ctx->salt_offset);\n\t}\n\n\trctx->chan_idx = select_channel();\n\terr = handle_aead_req(rctx);\n\tif (err != -EINPROGRESS)\n\t\t \n\t\tspu_chunk_cleanup(rctx);\n\n\treturn err;\n}\n\nstatic int aead_authenc_setkey(struct crypto_aead *cipher,\n\t\t\t       const u8 *key, unsigned int keylen)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(cipher);\n\tstruct crypto_tfm *tfm = crypto_aead_tfm(cipher);\n\tstruct crypto_authenc_keys keys;\n\tint ret;\n\n\tflow_log(\"%s() aead:%p key:%p keylen:%u\\n\", __func__, cipher, key,\n\t\t keylen);\n\tflow_dump(\"  key: \", key, keylen);\n\n\tret = crypto_authenc_extractkeys(&keys, key, keylen);\n\tif (ret)\n\t\tgoto badkey;\n\n\tif (keys.enckeylen > MAX_KEY_SIZE ||\n\t    keys.authkeylen > MAX_KEY_SIZE)\n\t\tgoto badkey;\n\n\tctx->enckeylen = keys.enckeylen;\n\tctx->authkeylen = keys.authkeylen;\n\n\tmemcpy(ctx->enckey, keys.enckey, keys.enckeylen);\n\t \n\tmemset(ctx->authkey, 0, sizeof(ctx->authkey));\n\tmemcpy(ctx->authkey, keys.authkey, keys.authkeylen);\n\n\tswitch (ctx->alg->cipher_info.alg) {\n\tcase CIPHER_ALG_DES:\n\t\tif (verify_aead_des_key(cipher, keys.enckey, keys.enckeylen))\n\t\t\treturn -EINVAL;\n\n\t\tctx->cipher_type = CIPHER_TYPE_DES;\n\t\tbreak;\n\tcase CIPHER_ALG_3DES:\n\t\tif (verify_aead_des3_key(cipher, keys.enckey, keys.enckeylen))\n\t\t\treturn -EINVAL;\n\n\t\tctx->cipher_type = CIPHER_TYPE_3DES;\n\t\tbreak;\n\tcase CIPHER_ALG_AES:\n\t\tswitch (ctx->enckeylen) {\n\t\tcase AES_KEYSIZE_128:\n\t\t\tctx->cipher_type = CIPHER_TYPE_AES128;\n\t\t\tbreak;\n\t\tcase AES_KEYSIZE_192:\n\t\t\tctx->cipher_type = CIPHER_TYPE_AES192;\n\t\t\tbreak;\n\t\tcase AES_KEYSIZE_256:\n\t\t\tctx->cipher_type = CIPHER_TYPE_AES256;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto badkey;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s() Error: Unknown cipher alg\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tflow_log(\"  enckeylen:%u authkeylen:%u\\n\", ctx->enckeylen,\n\t\t ctx->authkeylen);\n\tflow_dump(\"  enc: \", ctx->enckey, ctx->enckeylen);\n\tflow_dump(\"  auth: \", ctx->authkey, ctx->authkeylen);\n\n\t \n\tif (ctx->fallback_cipher) {\n\t\tflow_log(\"  running fallback setkey()\\n\");\n\n\t\tctx->fallback_cipher->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\t\tctx->fallback_cipher->base.crt_flags |=\n\t\t    tfm->crt_flags & CRYPTO_TFM_REQ_MASK;\n\t\tret = crypto_aead_setkey(ctx->fallback_cipher, key, keylen);\n\t\tif (ret)\n\t\t\tflow_log(\"  fallback setkey() returned:%d\\n\", ret);\n\t}\n\n\tctx->spu_resp_hdr_len = spu->spu_response_hdr_len(ctx->authkeylen,\n\t\t\t\t\t\t\t  ctx->enckeylen,\n\t\t\t\t\t\t\t  false);\n\n\tatomic_inc(&iproc_priv.setkey_cnt[SPU_OP_AEAD]);\n\n\treturn ret;\n\nbadkey:\n\tctx->enckeylen = 0;\n\tctx->authkeylen = 0;\n\tctx->digestsize = 0;\n\n\treturn -EINVAL;\n}\n\nstatic int aead_gcm_ccm_setkey(struct crypto_aead *cipher,\n\t\t\t       const u8 *key, unsigned int keylen)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(cipher);\n\tstruct crypto_tfm *tfm = crypto_aead_tfm(cipher);\n\n\tint ret = 0;\n\n\tflow_log(\"%s() keylen:%u\\n\", __func__, keylen);\n\tflow_dump(\"  key: \", key, keylen);\n\n\tif (!ctx->is_esp)\n\t\tctx->digestsize = keylen;\n\n\tctx->enckeylen = keylen;\n\tctx->authkeylen = 0;\n\n\tswitch (ctx->enckeylen) {\n\tcase AES_KEYSIZE_128:\n\t\tctx->cipher_type = CIPHER_TYPE_AES128;\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\tctx->cipher_type = CIPHER_TYPE_AES192;\n\t\tbreak;\n\tcase AES_KEYSIZE_256:\n\t\tctx->cipher_type = CIPHER_TYPE_AES256;\n\t\tbreak;\n\tdefault:\n\t\tgoto badkey;\n\t}\n\n\tmemcpy(ctx->enckey, key, ctx->enckeylen);\n\n\tflow_log(\"  enckeylen:%u authkeylen:%u\\n\", ctx->enckeylen,\n\t\t ctx->authkeylen);\n\tflow_dump(\"  enc: \", ctx->enckey, ctx->enckeylen);\n\tflow_dump(\"  auth: \", ctx->authkey, ctx->authkeylen);\n\n\t \n\tif (ctx->fallback_cipher) {\n\t\tflow_log(\"  running fallback setkey()\\n\");\n\n\t\tctx->fallback_cipher->base.crt_flags &= ~CRYPTO_TFM_REQ_MASK;\n\t\tctx->fallback_cipher->base.crt_flags |=\n\t\t    tfm->crt_flags & CRYPTO_TFM_REQ_MASK;\n\t\tret = crypto_aead_setkey(ctx->fallback_cipher, key,\n\t\t\t\t\t keylen + ctx->salt_len);\n\t\tif (ret)\n\t\t\tflow_log(\"  fallback setkey() returned:%d\\n\", ret);\n\t}\n\n\tctx->spu_resp_hdr_len = spu->spu_response_hdr_len(ctx->authkeylen,\n\t\t\t\t\t\t\t  ctx->enckeylen,\n\t\t\t\t\t\t\t  false);\n\n\tatomic_inc(&iproc_priv.setkey_cnt[SPU_OP_AEAD]);\n\n\tflow_log(\"  enckeylen:%u authkeylen:%u\\n\", ctx->enckeylen,\n\t\t ctx->authkeylen);\n\n\treturn ret;\n\nbadkey:\n\tctx->enckeylen = 0;\n\tctx->authkeylen = 0;\n\tctx->digestsize = 0;\n\n\treturn -EINVAL;\n}\n\n \nstatic int aead_gcm_esp_setkey(struct crypto_aead *cipher,\n\t\t\t       const u8 *key, unsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(cipher);\n\n\tflow_log(\"%s\\n\", __func__);\n\n\tif (keylen < GCM_ESP_SALT_SIZE)\n\t\treturn -EINVAL;\n\n\tctx->salt_len = GCM_ESP_SALT_SIZE;\n\tctx->salt_offset = GCM_ESP_SALT_OFFSET;\n\tmemcpy(ctx->salt, key + keylen - GCM_ESP_SALT_SIZE, GCM_ESP_SALT_SIZE);\n\tkeylen -= GCM_ESP_SALT_SIZE;\n\tctx->digestsize = GCM_ESP_DIGESTSIZE;\n\tctx->is_esp = true;\n\tflow_dump(\"salt: \", ctx->salt, GCM_ESP_SALT_SIZE);\n\n\treturn aead_gcm_ccm_setkey(cipher, key, keylen);\n}\n\n \nstatic int rfc4543_gcm_esp_setkey(struct crypto_aead *cipher,\n\t\t\t\t  const u8 *key, unsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(cipher);\n\n\tflow_log(\"%s\\n\", __func__);\n\n\tif (keylen < GCM_ESP_SALT_SIZE)\n\t\treturn -EINVAL;\n\n\tctx->salt_len = GCM_ESP_SALT_SIZE;\n\tctx->salt_offset = GCM_ESP_SALT_OFFSET;\n\tmemcpy(ctx->salt, key + keylen - GCM_ESP_SALT_SIZE, GCM_ESP_SALT_SIZE);\n\tkeylen -= GCM_ESP_SALT_SIZE;\n\tctx->digestsize = GCM_ESP_DIGESTSIZE;\n\tctx->is_esp = true;\n\tctx->is_rfc4543 = true;\n\tflow_dump(\"salt: \", ctx->salt, GCM_ESP_SALT_SIZE);\n\n\treturn aead_gcm_ccm_setkey(cipher, key, keylen);\n}\n\n \nstatic int aead_ccm_esp_setkey(struct crypto_aead *cipher,\n\t\t\t       const u8 *key, unsigned int keylen)\n{\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(cipher);\n\n\tflow_log(\"%s\\n\", __func__);\n\n\tif (keylen < CCM_ESP_SALT_SIZE)\n\t\treturn -EINVAL;\n\n\tctx->salt_len = CCM_ESP_SALT_SIZE;\n\tctx->salt_offset = CCM_ESP_SALT_OFFSET;\n\tmemcpy(ctx->salt, key + keylen - CCM_ESP_SALT_SIZE, CCM_ESP_SALT_SIZE);\n\tkeylen -= CCM_ESP_SALT_SIZE;\n\tctx->is_esp = true;\n\tflow_dump(\"salt: \", ctx->salt, CCM_ESP_SALT_SIZE);\n\n\treturn aead_gcm_ccm_setkey(cipher, key, keylen);\n}\n\nstatic int aead_setauthsize(struct crypto_aead *cipher, unsigned int authsize)\n{\n\tstruct iproc_ctx_s *ctx = crypto_aead_ctx(cipher);\n\tint ret = 0;\n\n\tflow_log(\"%s() authkeylen:%u authsize:%u\\n\",\n\t\t __func__, ctx->authkeylen, authsize);\n\n\tctx->digestsize = authsize;\n\n\t \n\tif (ctx->fallback_cipher) {\n\t\tflow_log(\"  running fallback setauth()\\n\");\n\n\t\tret = crypto_aead_setauthsize(ctx->fallback_cipher, authsize);\n\t\tif (ret)\n\t\t\tflow_log(\"  fallback setauth() returned:%d\\n\", ret);\n\t}\n\n\treturn ret;\n}\n\nstatic int aead_encrypt(struct aead_request *req)\n{\n\tflow_log(\"%s() cryptlen:%u %08x\\n\", __func__, req->cryptlen,\n\t\t req->cryptlen);\n\tdump_sg(req->src, 0, req->cryptlen + req->assoclen);\n\tflow_log(\"  assoc_len:%u\\n\", req->assoclen);\n\n\treturn aead_enqueue(req, true);\n}\n\nstatic int aead_decrypt(struct aead_request *req)\n{\n\tflow_log(\"%s() cryptlen:%u\\n\", __func__, req->cryptlen);\n\tdump_sg(req->src, 0, req->cryptlen + req->assoclen);\n\tflow_log(\"  assoc_len:%u\\n\", req->assoclen);\n\n\treturn aead_enqueue(req, false);\n}\n\n \n\nstatic struct iproc_alg_s driver_algs[] = {\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"gcm(aes)\",\n\t\t\t.cra_driver_name = \"gcm-aes-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK\n\t\t },\n\t\t .setkey = aead_gcm_ccm_setkey,\n\t\t .ivsize = GCM_AES_IV_SIZE,\n\t\t.maxauthsize = AES_BLOCK_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_GCM,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_AES,\n\t\t       .mode = HASH_MODE_GCM,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"ccm(aes)\",\n\t\t\t.cra_driver_name = \"ccm-aes-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK\n\t\t },\n\t\t .setkey = aead_gcm_ccm_setkey,\n\t\t .ivsize = CCM_AES_IV_SIZE,\n\t\t.maxauthsize = AES_BLOCK_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_CCM,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_AES,\n\t\t       .mode = HASH_MODE_CCM,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"rfc4106(gcm(aes))\",\n\t\t\t.cra_driver_name = \"gcm-aes-esp-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK\n\t\t },\n\t\t .setkey = aead_gcm_esp_setkey,\n\t\t .ivsize = GCM_RFC4106_IV_SIZE,\n\t\t .maxauthsize = AES_BLOCK_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_GCM,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_AES,\n\t\t       .mode = HASH_MODE_GCM,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"rfc4309(ccm(aes))\",\n\t\t\t.cra_driver_name = \"ccm-aes-esp-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK\n\t\t },\n\t\t .setkey = aead_ccm_esp_setkey,\n\t\t .ivsize = CCM_AES_IV_SIZE,\n\t\t .maxauthsize = AES_BLOCK_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_CCM,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_AES,\n\t\t       .mode = HASH_MODE_CCM,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"rfc4543(gcm(aes))\",\n\t\t\t.cra_driver_name = \"gmac-aes-esp-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK\n\t\t },\n\t\t .setkey = rfc4543_gcm_esp_setkey,\n\t\t .ivsize = GCM_RFC4106_IV_SIZE,\n\t\t .maxauthsize = AES_BLOCK_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_GCM,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_AES,\n\t\t       .mode = HASH_MODE_GCM,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(md5),cbc(aes))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-md5-cbc-aes-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t.maxauthsize = MD5_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_MD5,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha1),cbc(aes))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha1-cbc-aes-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = AES_BLOCK_SIZE,\n\t\t .maxauthsize = SHA1_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA1,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha256),cbc(aes))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha256-cbc-aes-iproc\",\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = AES_BLOCK_SIZE,\n\t\t .maxauthsize = SHA256_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA256,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(md5),cbc(des))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-md5-cbc-des-iproc\",\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES_BLOCK_SIZE,\n\t\t .maxauthsize = MD5_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_MD5,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha1),cbc(des))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha1-cbc-des-iproc\",\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES_BLOCK_SIZE,\n\t\t .maxauthsize = SHA1_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA1,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha224),cbc(des))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha224-cbc-des-iproc\",\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES_BLOCK_SIZE,\n\t\t .maxauthsize = SHA224_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA224,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha256),cbc(des))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha256-cbc-des-iproc\",\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES_BLOCK_SIZE,\n\t\t .maxauthsize = SHA256_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA256,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha384),cbc(des))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha384-cbc-des-iproc\",\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES_BLOCK_SIZE,\n\t\t .maxauthsize = SHA384_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA384,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha512),cbc(des))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha512-cbc-des-iproc\",\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES_BLOCK_SIZE,\n\t\t .maxauthsize = SHA512_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA512,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(md5),cbc(des3_ede))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-md5-cbc-des3-iproc\",\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t .maxauthsize = MD5_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_MD5,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha1),cbc(des3_ede))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha1-cbc-des3-iproc\",\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t .maxauthsize = SHA1_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA1,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha224),cbc(des3_ede))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha224-cbc-des3-iproc\",\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t .maxauthsize = SHA224_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA224,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha256),cbc(des3_ede))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha256-cbc-des3-iproc\",\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t .maxauthsize = SHA256_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA256,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha384),cbc(des3_ede))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha384-cbc-des3-iproc\",\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t .maxauthsize = SHA384_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA384,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AEAD,\n\t .alg.aead = {\n\t\t .base = {\n\t\t\t.cra_name = \"authenc(hmac(sha512),cbc(des3_ede))\",\n\t\t\t.cra_driver_name = \"authenc-hmac-sha512-cbc-des3-iproc\",\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_flags = CRYPTO_ALG_NEED_FALLBACK |\n\t\t\t\t     CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY\n\t\t },\n\t\t .setkey = aead_authenc_setkey,\n\t\t .ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t .maxauthsize = SHA512_DIGEST_SIZE,\n\t },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA512,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t .auth_first = 0,\n\t },\n\n \n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"ofb(des)\",\n\t\t\t.base.cra_driver_name = \"ofb-des-iproc\",\n\t\t\t.base.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t.ivsize = DES_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_OFB,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"cbc(des)\",\n\t\t\t.base.cra_driver_name = \"cbc-des-iproc\",\n\t\t\t.base.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t.ivsize = DES_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"ecb(des)\",\n\t\t\t.base.cra_driver_name = \"ecb-des-iproc\",\n\t\t\t.base.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.min_keysize = DES_KEY_SIZE,\n\t\t\t.max_keysize = DES_KEY_SIZE,\n\t\t\t.ivsize = 0,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_DES,\n\t\t\t .mode = CIPHER_MODE_ECB,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"ofb(des3_ede)\",\n\t\t\t.base.cra_driver_name = \"ofb-des3-iproc\",\n\t\t\t.base.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t.ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_OFB,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"cbc(des3_ede)\",\n\t\t\t.base.cra_driver_name = \"cbc-des3-iproc\",\n\t\t\t.base.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t.ivsize = DES3_EDE_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"ecb(des3_ede)\",\n\t\t\t.base.cra_driver_name = \"ecb-des3-iproc\",\n\t\t\t.base.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t\t.ivsize = 0,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_3DES,\n\t\t\t .mode = CIPHER_MODE_ECB,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"ofb(aes)\",\n\t\t\t.base.cra_driver_name = \"ofb-aes-iproc\",\n\t\t\t.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_OFB,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"cbc(aes)\",\n\t\t\t.base.cra_driver_name = \"cbc-aes-iproc\",\n\t\t\t.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_CBC,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"ecb(aes)\",\n\t\t\t.base.cra_driver_name = \"ecb-aes-iproc\",\n\t\t\t.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t.ivsize = 0,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_ECB,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"ctr(aes)\",\n\t\t\t.base.cra_driver_name = \"ctr-aes-iproc\",\n\t\t\t.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_CTR,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n{\n\t .type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t .alg.skcipher = {\n\t\t\t.base.cra_name = \"xts(aes)\",\n\t\t\t.base.cra_driver_name = \"xts-aes-iproc\",\n\t\t\t.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.min_keysize = 2 * AES_MIN_KEY_SIZE,\n\t\t\t.max_keysize = 2 * AES_MAX_KEY_SIZE,\n\t\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t\t},\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_AES,\n\t\t\t .mode = CIPHER_MODE_XTS,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_NONE,\n\t\t       .mode = HASH_MODE_NONE,\n\t\t       },\n\t },\n\n \n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = MD5_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"md5\",\n\t\t\t\t    .cra_driver_name = \"md5-iproc\",\n\t\t\t\t    .cra_blocksize = MD5_BLOCK_WORDS * 4,\n\t\t\t\t    .cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_MD5,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = MD5_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(md5)\",\n\t\t\t\t    .cra_driver_name = \"hmac-md5-iproc\",\n\t\t\t\t    .cra_blocksize = MD5_BLOCK_WORDS * 4,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_MD5,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{.type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA1_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha1\",\n\t\t\t\t    .cra_driver_name = \"sha1-iproc\",\n\t\t\t\t    .cra_blocksize = SHA1_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA1,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{.type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA1_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha1)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha1-iproc\",\n\t\t\t\t    .cra_blocksize = SHA1_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA1,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{.type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t\t.halg.digestsize = SHA224_DIGEST_SIZE,\n\t\t\t.halg.base = {\n\t\t\t\t    .cra_name = \"sha224\",\n\t\t\t\t    .cra_driver_name = \"sha224-iproc\",\n\t\t\t\t    .cra_blocksize = SHA224_BLOCK_SIZE,\n\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA224,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{.type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA224_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha224)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha224-iproc\",\n\t\t\t\t    .cra_blocksize = SHA224_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA224,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{.type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha256\",\n\t\t\t\t    .cra_driver_name = \"sha256-iproc\",\n\t\t\t\t    .cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA256,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{.type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha256)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha256-iproc\",\n\t\t\t\t    .cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA256,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{\n\t.type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA384_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha384\",\n\t\t\t\t    .cra_driver_name = \"sha384-iproc\",\n\t\t\t\t    .cra_blocksize = SHA384_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA384,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA384_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha384)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha384-iproc\",\n\t\t\t\t    .cra_blocksize = SHA384_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA384,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA512_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha512\",\n\t\t\t\t    .cra_driver_name = \"sha512-iproc\",\n\t\t\t\t    .cra_blocksize = SHA512_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA512,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA512_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha512)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha512-iproc\",\n\t\t\t\t    .cra_blocksize = SHA512_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA512,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_224_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha3-224\",\n\t\t\t\t    .cra_driver_name = \"sha3-224-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_224_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_224,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_224_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha3-224)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha3-224-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_224_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_224,\n\t\t       .mode = HASH_MODE_HMAC\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_256_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha3-256\",\n\t\t\t\t    .cra_driver_name = \"sha3-256-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_256_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_256,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_256_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha3-256)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha3-256-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_256_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_256,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_384_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha3-384\",\n\t\t\t\t    .cra_driver_name = \"sha3-384-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_224_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_384,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_384_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha3-384)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha3-384-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_384_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_384,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_512_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"sha3-512\",\n\t\t\t\t    .cra_driver_name = \"sha3-512-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_512_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_512,\n\t\t       .mode = HASH_MODE_HASH,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = SHA3_512_DIGEST_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"hmac(sha3-512)\",\n\t\t\t\t    .cra_driver_name = \"hmac-sha3-512-iproc\",\n\t\t\t\t    .cra_blocksize = SHA3_512_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_SHA3_512,\n\t\t       .mode = HASH_MODE_HMAC,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = AES_BLOCK_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"xcbc(aes)\",\n\t\t\t\t    .cra_driver_name = \"xcbc-aes-iproc\",\n\t\t\t\t    .cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_AES,\n\t\t       .mode = HASH_MODE_XCBC,\n\t\t       },\n\t },\n\t{\n\t .type = CRYPTO_ALG_TYPE_AHASH,\n\t .alg.hash = {\n\t\t      .halg.digestsize = AES_BLOCK_SIZE,\n\t\t      .halg.base = {\n\t\t\t\t    .cra_name = \"cmac(aes)\",\n\t\t\t\t    .cra_driver_name = \"cmac-aes-iproc\",\n\t\t\t\t    .cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t\t}\n\t\t      },\n\t .cipher_info = {\n\t\t\t .alg = CIPHER_ALG_NONE,\n\t\t\t .mode = CIPHER_MODE_NONE,\n\t\t\t },\n\t .auth_info = {\n\t\t       .alg = HASH_ALG_AES,\n\t\t       .mode = HASH_MODE_CMAC,\n\t\t       },\n\t },\n};\n\nstatic int generic_cra_init(struct crypto_tfm *tfm,\n\t\t\t    struct iproc_alg_s *cipher_alg)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct iproc_ctx_s *ctx = crypto_tfm_ctx(tfm);\n\tunsigned int blocksize = crypto_tfm_alg_blocksize(tfm);\n\n\tflow_log(\"%s()\\n\", __func__);\n\n\tctx->alg = cipher_alg;\n\tctx->cipher = cipher_alg->cipher_info;\n\tctx->auth = cipher_alg->auth_info;\n\tctx->auth_first = cipher_alg->auth_first;\n\tctx->max_payload = spu->spu_ctx_max_payload(ctx->cipher.alg,\n\t\t\t\t\t\t    ctx->cipher.mode,\n\t\t\t\t\t\t    blocksize);\n\tctx->fallback_cipher = NULL;\n\n\tctx->enckeylen = 0;\n\tctx->authkeylen = 0;\n\n\tatomic_inc(&iproc_priv.stream_count);\n\tatomic_inc(&iproc_priv.session_count);\n\n\treturn 0;\n}\n\nstatic int skcipher_init_tfm(struct crypto_skcipher *skcipher)\n{\n\tstruct crypto_tfm *tfm = crypto_skcipher_tfm(skcipher);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(skcipher);\n\tstruct iproc_alg_s *cipher_alg;\n\n\tflow_log(\"%s()\\n\", __func__);\n\n\tcrypto_skcipher_set_reqsize(skcipher, sizeof(struct iproc_reqctx_s));\n\n\tcipher_alg = container_of(alg, struct iproc_alg_s, alg.skcipher);\n\treturn generic_cra_init(tfm, cipher_alg);\n}\n\nstatic int ahash_cra_init(struct crypto_tfm *tfm)\n{\n\tint err;\n\tstruct crypto_alg *alg = tfm->__crt_alg;\n\tstruct iproc_alg_s *cipher_alg;\n\n\tcipher_alg = container_of(__crypto_ahash_alg(alg), struct iproc_alg_s,\n\t\t\t\t  alg.hash);\n\n\terr = generic_cra_init(tfm, cipher_alg);\n\tflow_log(\"%s()\\n\", __func__);\n\n\t \n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct iproc_reqctx_s));\n\n\treturn err;\n}\n\nstatic int aead_cra_init(struct crypto_aead *aead)\n{\n\tunsigned int reqsize = sizeof(struct iproc_reqctx_s);\n\tstruct crypto_tfm *tfm = crypto_aead_tfm(aead);\n\tstruct iproc_ctx_s *ctx = crypto_tfm_ctx(tfm);\n\tstruct crypto_alg *alg = tfm->__crt_alg;\n\tstruct aead_alg *aalg = container_of(alg, struct aead_alg, base);\n\tstruct iproc_alg_s *cipher_alg = container_of(aalg, struct iproc_alg_s,\n\t\t\t\t\t\t      alg.aead);\n\n\tint err = generic_cra_init(tfm, cipher_alg);\n\n\tflow_log(\"%s()\\n\", __func__);\n\n\tctx->is_esp = false;\n\tctx->salt_len = 0;\n\tctx->salt_offset = 0;\n\n\t \n\tget_random_bytes(ctx->iv, MAX_IV_SIZE);\n\tflow_dump(\"  iv: \", ctx->iv, MAX_IV_SIZE);\n\n\tif (err)\n\t\tgoto out;\n\n\tif (!(alg->cra_flags & CRYPTO_ALG_NEED_FALLBACK))\n\t\tgoto reqsize;\n\n\tflow_log(\"%s() creating fallback cipher\\n\", __func__);\n\n\tctx->fallback_cipher = crypto_alloc_aead(alg->cra_name, 0,\n\t\t\t\t\t\t CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(ctx->fallback_cipher)) {\n\t\tpr_err(\"%s() Error: failed to allocate fallback for %s\\n\",\n\t\t       __func__, alg->cra_name);\n\t\treturn PTR_ERR(ctx->fallback_cipher);\n\t}\n\n\treqsize += crypto_aead_reqsize(ctx->fallback_cipher);\n\nreqsize:\n\tcrypto_aead_set_reqsize(aead, reqsize);\n\nout:\n\treturn err;\n}\n\nstatic void generic_cra_exit(struct crypto_tfm *tfm)\n{\n\tatomic_dec(&iproc_priv.session_count);\n}\n\nstatic void skcipher_exit_tfm(struct crypto_skcipher *tfm)\n{\n\tgeneric_cra_exit(crypto_skcipher_tfm(tfm));\n}\n\nstatic void aead_cra_exit(struct crypto_aead *aead)\n{\n\tstruct crypto_tfm *tfm = crypto_aead_tfm(aead);\n\tstruct iproc_ctx_s *ctx = crypto_tfm_ctx(tfm);\n\n\tgeneric_cra_exit(tfm);\n\n\tif (ctx->fallback_cipher) {\n\t\tcrypto_free_aead(ctx->fallback_cipher);\n\t\tctx->fallback_cipher = NULL;\n\t}\n}\n\n \nstatic void spu_functions_register(struct device *dev,\n\t\t\t\t   enum spu_spu_type spu_type,\n\t\t\t\t   enum spu_spu_subtype spu_subtype)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\n\tif (spu_type == SPU_TYPE_SPUM) {\n\t\tdev_dbg(dev, \"Registering SPUM functions\");\n\t\tspu->spu_dump_msg_hdr = spum_dump_msg_hdr;\n\t\tspu->spu_payload_length = spum_payload_length;\n\t\tspu->spu_response_hdr_len = spum_response_hdr_len;\n\t\tspu->spu_hash_pad_len = spum_hash_pad_len;\n\t\tspu->spu_gcm_ccm_pad_len = spum_gcm_ccm_pad_len;\n\t\tspu->spu_assoc_resp_len = spum_assoc_resp_len;\n\t\tspu->spu_aead_ivlen = spum_aead_ivlen;\n\t\tspu->spu_hash_type = spum_hash_type;\n\t\tspu->spu_digest_size = spum_digest_size;\n\t\tspu->spu_create_request = spum_create_request;\n\t\tspu->spu_cipher_req_init = spum_cipher_req_init;\n\t\tspu->spu_cipher_req_finish = spum_cipher_req_finish;\n\t\tspu->spu_request_pad = spum_request_pad;\n\t\tspu->spu_tx_status_len = spum_tx_status_len;\n\t\tspu->spu_rx_status_len = spum_rx_status_len;\n\t\tspu->spu_status_process = spum_status_process;\n\t\tspu->spu_xts_tweak_in_payload = spum_xts_tweak_in_payload;\n\t\tspu->spu_ccm_update_iv = spum_ccm_update_iv;\n\t\tspu->spu_wordalign_padlen = spum_wordalign_padlen;\n\t\tif (spu_subtype == SPU_SUBTYPE_SPUM_NS2)\n\t\t\tspu->spu_ctx_max_payload = spum_ns2_ctx_max_payload;\n\t\telse\n\t\t\tspu->spu_ctx_max_payload = spum_nsp_ctx_max_payload;\n\t} else {\n\t\tdev_dbg(dev, \"Registering SPU2 functions\");\n\t\tspu->spu_dump_msg_hdr = spu2_dump_msg_hdr;\n\t\tspu->spu_ctx_max_payload = spu2_ctx_max_payload;\n\t\tspu->spu_payload_length = spu2_payload_length;\n\t\tspu->spu_response_hdr_len = spu2_response_hdr_len;\n\t\tspu->spu_hash_pad_len = spu2_hash_pad_len;\n\t\tspu->spu_gcm_ccm_pad_len = spu2_gcm_ccm_pad_len;\n\t\tspu->spu_assoc_resp_len = spu2_assoc_resp_len;\n\t\tspu->spu_aead_ivlen = spu2_aead_ivlen;\n\t\tspu->spu_hash_type = spu2_hash_type;\n\t\tspu->spu_digest_size = spu2_digest_size;\n\t\tspu->spu_create_request = spu2_create_request;\n\t\tspu->spu_cipher_req_init = spu2_cipher_req_init;\n\t\tspu->spu_cipher_req_finish = spu2_cipher_req_finish;\n\t\tspu->spu_request_pad = spu2_request_pad;\n\t\tspu->spu_tx_status_len = spu2_tx_status_len;\n\t\tspu->spu_rx_status_len = spu2_rx_status_len;\n\t\tspu->spu_status_process = spu2_status_process;\n\t\tspu->spu_xts_tweak_in_payload = spu2_xts_tweak_in_payload;\n\t\tspu->spu_ccm_update_iv = spu2_ccm_update_iv;\n\t\tspu->spu_wordalign_padlen = spu2_wordalign_padlen;\n\t}\n}\n\n \nstatic int spu_mb_init(struct device *dev)\n{\n\tstruct mbox_client *mcl = &iproc_priv.mcl;\n\tint err, i;\n\n\tiproc_priv.mbox = devm_kcalloc(dev, iproc_priv.spu.num_chan,\n\t\t\t\t  sizeof(struct mbox_chan *), GFP_KERNEL);\n\tif (!iproc_priv.mbox)\n\t\treturn -ENOMEM;\n\n\tmcl->dev = dev;\n\tmcl->tx_block = false;\n\tmcl->tx_tout = 0;\n\tmcl->knows_txdone = true;\n\tmcl->rx_callback = spu_rx_callback;\n\tmcl->tx_done = NULL;\n\n\tfor (i = 0; i < iproc_priv.spu.num_chan; i++) {\n\t\tiproc_priv.mbox[i] = mbox_request_channel(mcl, i);\n\t\tif (IS_ERR(iproc_priv.mbox[i])) {\n\t\t\terr = PTR_ERR(iproc_priv.mbox[i]);\n\t\t\tdev_err(dev,\n\t\t\t\t\"Mbox channel %d request failed with err %d\",\n\t\t\t\ti, err);\n\t\t\tiproc_priv.mbox[i] = NULL;\n\t\t\tgoto free_channels;\n\t\t}\n\t}\n\n\treturn 0;\nfree_channels:\n\tfor (i = 0; i < iproc_priv.spu.num_chan; i++) {\n\t\tif (iproc_priv.mbox[i])\n\t\t\tmbox_free_channel(iproc_priv.mbox[i]);\n\t}\n\n\treturn err;\n}\n\nstatic void spu_mb_release(struct platform_device *pdev)\n{\n\tint i;\n\n\tfor (i = 0; i < iproc_priv.spu.num_chan; i++)\n\t\tmbox_free_channel(iproc_priv.mbox[i]);\n}\n\nstatic void spu_counters_init(void)\n{\n\tint i;\n\tint j;\n\n\tatomic_set(&iproc_priv.session_count, 0);\n\tatomic_set(&iproc_priv.stream_count, 0);\n\tatomic_set(&iproc_priv.next_chan, (int)iproc_priv.spu.num_chan);\n\tatomic64_set(&iproc_priv.bytes_in, 0);\n\tatomic64_set(&iproc_priv.bytes_out, 0);\n\tfor (i = 0; i < SPU_OP_NUM; i++) {\n\t\tatomic_set(&iproc_priv.op_counts[i], 0);\n\t\tatomic_set(&iproc_priv.setkey_cnt[i], 0);\n\t}\n\tfor (i = 0; i < CIPHER_ALG_LAST; i++)\n\t\tfor (j = 0; j < CIPHER_MODE_LAST; j++)\n\t\t\tatomic_set(&iproc_priv.cipher_cnt[i][j], 0);\n\n\tfor (i = 0; i < HASH_ALG_LAST; i++) {\n\t\tatomic_set(&iproc_priv.hash_cnt[i], 0);\n\t\tatomic_set(&iproc_priv.hmac_cnt[i], 0);\n\t}\n\tfor (i = 0; i < AEAD_TYPE_LAST; i++)\n\t\tatomic_set(&iproc_priv.aead_cnt[i], 0);\n\n\tatomic_set(&iproc_priv.mb_no_spc, 0);\n\tatomic_set(&iproc_priv.mb_send_fail, 0);\n\tatomic_set(&iproc_priv.bad_icv, 0);\n}\n\nstatic int spu_register_skcipher(struct iproc_alg_s *driver_alg)\n{\n\tstruct skcipher_alg *crypto = &driver_alg->alg.skcipher;\n\tint err;\n\n\tcrypto->base.cra_module = THIS_MODULE;\n\tcrypto->base.cra_priority = cipher_pri;\n\tcrypto->base.cra_alignmask = 0;\n\tcrypto->base.cra_ctxsize = sizeof(struct iproc_ctx_s);\n\tcrypto->base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t CRYPTO_ALG_ALLOCATES_MEMORY |\n\t\t\t\t CRYPTO_ALG_KERN_DRIVER_ONLY;\n\n\tcrypto->init = skcipher_init_tfm;\n\tcrypto->exit = skcipher_exit_tfm;\n\tcrypto->setkey = skcipher_setkey;\n\tcrypto->encrypt = skcipher_encrypt;\n\tcrypto->decrypt = skcipher_decrypt;\n\n\terr = crypto_register_skcipher(crypto);\n\t \n\tif (err == 0)\n\t\tdriver_alg->registered = true;\n\tpr_debug(\"  registered skcipher %s\\n\", crypto->base.cra_driver_name);\n\treturn err;\n}\n\nstatic int spu_register_ahash(struct iproc_alg_s *driver_alg)\n{\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct ahash_alg *hash = &driver_alg->alg.hash;\n\tint err;\n\n\t \n\tif ((driver_alg->auth_info.alg == HASH_ALG_AES) &&\n\t    (driver_alg->auth_info.mode != HASH_MODE_XCBC) &&\n\t    (spu->spu_type == SPU_TYPE_SPUM))\n\t\treturn 0;\n\n\t \n\tif ((driver_alg->auth_info.alg >= HASH_ALG_SHA3_224) &&\n\t    (spu->spu_subtype != SPU_SUBTYPE_SPU2_V2))\n\t\treturn 0;\n\n\thash->halg.base.cra_module = THIS_MODULE;\n\thash->halg.base.cra_priority = hash_pri;\n\thash->halg.base.cra_alignmask = 0;\n\thash->halg.base.cra_ctxsize = sizeof(struct iproc_ctx_s);\n\thash->halg.base.cra_init = ahash_cra_init;\n\thash->halg.base.cra_exit = generic_cra_exit;\n\thash->halg.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t    CRYPTO_ALG_ALLOCATES_MEMORY;\n\thash->halg.statesize = sizeof(struct spu_hash_export_s);\n\n\tif (driver_alg->auth_info.mode != HASH_MODE_HMAC) {\n\t\thash->init = ahash_init;\n\t\thash->update = ahash_update;\n\t\thash->final = ahash_final;\n\t\thash->finup = ahash_finup;\n\t\thash->digest = ahash_digest;\n\t\tif ((driver_alg->auth_info.alg == HASH_ALG_AES) &&\n\t\t    ((driver_alg->auth_info.mode == HASH_MODE_XCBC) ||\n\t\t    (driver_alg->auth_info.mode == HASH_MODE_CMAC))) {\n\t\t\thash->setkey = ahash_setkey;\n\t\t}\n\t} else {\n\t\thash->setkey = ahash_hmac_setkey;\n\t\thash->init = ahash_hmac_init;\n\t\thash->update = ahash_hmac_update;\n\t\thash->final = ahash_hmac_final;\n\t\thash->finup = ahash_hmac_finup;\n\t\thash->digest = ahash_hmac_digest;\n\t}\n\thash->export = ahash_export;\n\thash->import = ahash_import;\n\n\terr = crypto_register_ahash(hash);\n\t \n\tif (err == 0)\n\t\tdriver_alg->registered = true;\n\tpr_debug(\"  registered ahash %s\\n\",\n\t\t hash->halg.base.cra_driver_name);\n\treturn err;\n}\n\nstatic int spu_register_aead(struct iproc_alg_s *driver_alg)\n{\n\tstruct aead_alg *aead = &driver_alg->alg.aead;\n\tint err;\n\n\taead->base.cra_module = THIS_MODULE;\n\taead->base.cra_priority = aead_pri;\n\taead->base.cra_alignmask = 0;\n\taead->base.cra_ctxsize = sizeof(struct iproc_ctx_s);\n\n\taead->base.cra_flags |= CRYPTO_ALG_ASYNC | CRYPTO_ALG_ALLOCATES_MEMORY;\n\t \n\taead->setauthsize = aead_setauthsize;\n\taead->encrypt = aead_encrypt;\n\taead->decrypt = aead_decrypt;\n\taead->init = aead_cra_init;\n\taead->exit = aead_cra_exit;\n\n\terr = crypto_register_aead(aead);\n\t \n\tif (err == 0)\n\t\tdriver_alg->registered = true;\n\tpr_debug(\"  registered aead %s\\n\", aead->base.cra_driver_name);\n\treturn err;\n}\n\n \nstatic int spu_algs_register(struct device *dev)\n{\n\tint i, j;\n\tint err;\n\n\tfor (i = 0; i < ARRAY_SIZE(driver_algs); i++) {\n\t\tswitch (driver_algs[i].type) {\n\t\tcase CRYPTO_ALG_TYPE_SKCIPHER:\n\t\t\terr = spu_register_skcipher(&driver_algs[i]);\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AHASH:\n\t\t\terr = spu_register_ahash(&driver_algs[i]);\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AEAD:\n\t\t\terr = spu_register_aead(&driver_algs[i]);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(dev,\n\t\t\t\t\"iproc-crypto: unknown alg type: %d\",\n\t\t\t\tdriver_algs[i].type);\n\t\t\terr = -EINVAL;\n\t\t}\n\n\t\tif (err) {\n\t\t\tdev_err(dev, \"alg registration failed with error %d\\n\",\n\t\t\t\terr);\n\t\t\tgoto err_algs;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_algs:\n\tfor (j = 0; j < i; j++) {\n\t\t \n\t\tif (!driver_algs[j].registered)\n\t\t\tcontinue;\n\t\tswitch (driver_algs[j].type) {\n\t\tcase CRYPTO_ALG_TYPE_SKCIPHER:\n\t\t\tcrypto_unregister_skcipher(&driver_algs[j].alg.skcipher);\n\t\t\tdriver_algs[j].registered = false;\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AHASH:\n\t\t\tcrypto_unregister_ahash(&driver_algs[j].alg.hash);\n\t\t\tdriver_algs[j].registered = false;\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AEAD:\n\t\t\tcrypto_unregister_aead(&driver_algs[j].alg.aead);\n\t\t\tdriver_algs[j].registered = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn err;\n}\n\n \n\nstatic struct spu_type_subtype spum_ns2_types = {\n\tSPU_TYPE_SPUM, SPU_SUBTYPE_SPUM_NS2\n};\n\nstatic struct spu_type_subtype spum_nsp_types = {\n\tSPU_TYPE_SPUM, SPU_SUBTYPE_SPUM_NSP\n};\n\nstatic struct spu_type_subtype spu2_types = {\n\tSPU_TYPE_SPU2, SPU_SUBTYPE_SPU2_V1\n};\n\nstatic struct spu_type_subtype spu2_v2_types = {\n\tSPU_TYPE_SPU2, SPU_SUBTYPE_SPU2_V2\n};\n\nstatic const struct of_device_id bcm_spu_dt_ids[] = {\n\t{\n\t\t.compatible = \"brcm,spum-crypto\",\n\t\t.data = &spum_ns2_types,\n\t},\n\t{\n\t\t.compatible = \"brcm,spum-nsp-crypto\",\n\t\t.data = &spum_nsp_types,\n\t},\n\t{\n\t\t.compatible = \"brcm,spu2-crypto\",\n\t\t.data = &spu2_types,\n\t},\n\t{\n\t\t.compatible = \"brcm,spu2-v2-crypto\",\n\t\t.data = &spu2_v2_types,\n\t},\n\t{   }\n};\n\nMODULE_DEVICE_TABLE(of, bcm_spu_dt_ids);\n\nstatic int spu_dt_read(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tstruct resource *spu_ctrl_regs;\n\tconst struct spu_type_subtype *matched_spu_type;\n\tstruct device_node *dn = pdev->dev.of_node;\n\tint err, i;\n\n\t \n\tspu->num_chan = of_count_phandle_with_args(dn, \"mboxes\", \"#mbox-cells\");\n\n\tmatched_spu_type = of_device_get_match_data(dev);\n\tif (!matched_spu_type) {\n\t\tdev_err(dev, \"Failed to match device\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tspu->spu_type = matched_spu_type->type;\n\tspu->spu_subtype = matched_spu_type->subtype;\n\n\tfor (i = 0; (i < MAX_SPUS) && ((spu_ctrl_regs =\n\t\tplatform_get_resource(pdev, IORESOURCE_MEM, i)) != NULL); i++) {\n\n\t\tspu->reg_vbase[i] = devm_ioremap_resource(dev, spu_ctrl_regs);\n\t\tif (IS_ERR(spu->reg_vbase[i])) {\n\t\t\terr = PTR_ERR(spu->reg_vbase[i]);\n\t\t\tdev_err(dev, \"Failed to map registers: %d\\n\",\n\t\t\t\terr);\n\t\t\tspu->reg_vbase[i] = NULL;\n\t\t\treturn err;\n\t\t}\n\t}\n\tspu->num_spu = i;\n\tdev_dbg(dev, \"Device has %d SPUs\", spu->num_spu);\n\n\treturn 0;\n}\n\nstatic int bcm_spu_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct spu_hw *spu = &iproc_priv.spu;\n\tint err;\n\n\tiproc_priv.pdev  = pdev;\n\tplatform_set_drvdata(iproc_priv.pdev,\n\t\t\t     &iproc_priv);\n\n\terr = spu_dt_read(pdev);\n\tif (err < 0)\n\t\tgoto failure;\n\n\terr = spu_mb_init(dev);\n\tif (err < 0)\n\t\tgoto failure;\n\n\tif (spu->spu_type == SPU_TYPE_SPUM)\n\t\tiproc_priv.bcm_hdr_len = 8;\n\telse if (spu->spu_type == SPU_TYPE_SPU2)\n\t\tiproc_priv.bcm_hdr_len = 0;\n\n\tspu_functions_register(dev, spu->spu_type, spu->spu_subtype);\n\n\tspu_counters_init();\n\n\tspu_setup_debugfs();\n\n\terr = spu_algs_register(dev);\n\tif (err < 0)\n\t\tgoto fail_reg;\n\n\treturn 0;\n\nfail_reg:\n\tspu_free_debugfs();\nfailure:\n\tspu_mb_release(pdev);\n\tdev_err(dev, \"%s failed with error %d.\\n\", __func__, err);\n\n\treturn err;\n}\n\nstatic int bcm_spu_remove(struct platform_device *pdev)\n{\n\tint i;\n\tstruct device *dev = &pdev->dev;\n\tchar *cdn;\n\n\tfor (i = 0; i < ARRAY_SIZE(driver_algs); i++) {\n\t\t \n\t\tif (!driver_algs[i].registered)\n\t\t\tcontinue;\n\n\t\tswitch (driver_algs[i].type) {\n\t\tcase CRYPTO_ALG_TYPE_SKCIPHER:\n\t\t\tcrypto_unregister_skcipher(&driver_algs[i].alg.skcipher);\n\t\t\tdev_dbg(dev, \"  unregistered cipher %s\\n\",\n\t\t\t\tdriver_algs[i].alg.skcipher.base.cra_driver_name);\n\t\t\tdriver_algs[i].registered = false;\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AHASH:\n\t\t\tcrypto_unregister_ahash(&driver_algs[i].alg.hash);\n\t\t\tcdn = driver_algs[i].alg.hash.halg.base.cra_driver_name;\n\t\t\tdev_dbg(dev, \"  unregistered hash %s\\n\", cdn);\n\t\t\tdriver_algs[i].registered = false;\n\t\t\tbreak;\n\t\tcase CRYPTO_ALG_TYPE_AEAD:\n\t\t\tcrypto_unregister_aead(&driver_algs[i].alg.aead);\n\t\t\tdev_dbg(dev, \"  unregistered aead %s\\n\",\n\t\t\t\tdriver_algs[i].alg.aead.base.cra_driver_name);\n\t\t\tdriver_algs[i].registered = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\tspu_free_debugfs();\n\tspu_mb_release(pdev);\n\treturn 0;\n}\n\n \n\nstatic struct platform_driver bcm_spu_pdriver = {\n\t.driver = {\n\t\t   .name = \"brcm-spu-crypto\",\n\t\t   .of_match_table = of_match_ptr(bcm_spu_dt_ids),\n\t\t   },\n\t.probe = bcm_spu_probe,\n\t.remove = bcm_spu_remove,\n};\nmodule_platform_driver(bcm_spu_pdriver);\n\nMODULE_AUTHOR(\"Rob Rice <rob.rice@broadcom.com>\");\nMODULE_DESCRIPTION(\"Broadcom symmetric crypto offload driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}