{
  "module_name": "omap-sham.c",
  "hash_id": "0e8e356eea6b5d750bc5f1fc008950882261ddd47b796f270f2ae9ceb5997956",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/omap-sham.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) \"%s: \" fmt, __func__\n\n#include <crypto/engine.h>\n#include <crypto/hmac.h>\n#include <crypto/internal/hash.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/sha1.h>\n#include <crypto/sha2.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmaengine.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/irq.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n\n#define MD5_DIGEST_SIZE\t\t\t16\n\n#define SHA_REG_IDIGEST(dd, x)\t\t((dd)->pdata->idigest_ofs + ((x)*0x04))\n#define SHA_REG_DIN(dd, x)\t\t((dd)->pdata->din_ofs + ((x) * 0x04))\n#define SHA_REG_DIGCNT(dd)\t\t((dd)->pdata->digcnt_ofs)\n\n#define SHA_REG_ODIGEST(dd, x)\t\t((dd)->pdata->odigest_ofs + (x * 0x04))\n\n#define SHA_REG_CTRL\t\t\t0x18\n#define SHA_REG_CTRL_LENGTH\t\t(0xFFFFFFFF << 5)\n#define SHA_REG_CTRL_CLOSE_HASH\t\t(1 << 4)\n#define SHA_REG_CTRL_ALGO_CONST\t\t(1 << 3)\n#define SHA_REG_CTRL_ALGO\t\t(1 << 2)\n#define SHA_REG_CTRL_INPUT_READY\t(1 << 1)\n#define SHA_REG_CTRL_OUTPUT_READY\t(1 << 0)\n\n#define SHA_REG_REV(dd)\t\t\t((dd)->pdata->rev_ofs)\n\n#define SHA_REG_MASK(dd)\t\t((dd)->pdata->mask_ofs)\n#define SHA_REG_MASK_DMA_EN\t\t(1 << 3)\n#define SHA_REG_MASK_IT_EN\t\t(1 << 2)\n#define SHA_REG_MASK_SOFTRESET\t\t(1 << 1)\n#define SHA_REG_AUTOIDLE\t\t(1 << 0)\n\n#define SHA_REG_SYSSTATUS(dd)\t\t((dd)->pdata->sysstatus_ofs)\n#define SHA_REG_SYSSTATUS_RESETDONE\t(1 << 0)\n\n#define SHA_REG_MODE(dd)\t\t((dd)->pdata->mode_ofs)\n#define SHA_REG_MODE_HMAC_OUTER_HASH\t(1 << 7)\n#define SHA_REG_MODE_HMAC_KEY_PROC\t(1 << 5)\n#define SHA_REG_MODE_CLOSE_HASH\t\t(1 << 4)\n#define SHA_REG_MODE_ALGO_CONSTANT\t(1 << 3)\n\n#define SHA_REG_MODE_ALGO_MASK\t\t(7 << 0)\n#define SHA_REG_MODE_ALGO_MD5_128\t(0 << 1)\n#define SHA_REG_MODE_ALGO_SHA1_160\t(1 << 1)\n#define SHA_REG_MODE_ALGO_SHA2_224\t(2 << 1)\n#define SHA_REG_MODE_ALGO_SHA2_256\t(3 << 1)\n#define SHA_REG_MODE_ALGO_SHA2_384\t(1 << 0)\n#define SHA_REG_MODE_ALGO_SHA2_512\t(3 << 0)\n\n#define SHA_REG_LENGTH(dd)\t\t((dd)->pdata->length_ofs)\n\n#define SHA_REG_IRQSTATUS\t\t0x118\n#define SHA_REG_IRQSTATUS_CTX_RDY\t(1 << 3)\n#define SHA_REG_IRQSTATUS_PARTHASH_RDY (1 << 2)\n#define SHA_REG_IRQSTATUS_INPUT_RDY\t(1 << 1)\n#define SHA_REG_IRQSTATUS_OUTPUT_RDY\t(1 << 0)\n\n#define SHA_REG_IRQENA\t\t\t0x11C\n#define SHA_REG_IRQENA_CTX_RDY\t\t(1 << 3)\n#define SHA_REG_IRQENA_PARTHASH_RDY\t(1 << 2)\n#define SHA_REG_IRQENA_INPUT_RDY\t(1 << 1)\n#define SHA_REG_IRQENA_OUTPUT_RDY\t(1 << 0)\n\n#define DEFAULT_TIMEOUT_INTERVAL\tHZ\n\n#define DEFAULT_AUTOSUSPEND_DELAY\t1000\n\n \n#define FLAGS_FINAL\t\t1\n#define FLAGS_DMA_ACTIVE\t2\n#define FLAGS_OUTPUT_READY\t3\n#define FLAGS_CPU\t\t5\n#define FLAGS_DMA_READY\t\t6\n#define FLAGS_AUTO_XOR\t\t7\n#define FLAGS_BE32_SHA1\t\t8\n#define FLAGS_SGS_COPIED\t9\n#define FLAGS_SGS_ALLOCED\t10\n#define FLAGS_HUGE\t\t11\n\n \n#define FLAGS_FINUP\t\t16\n\n#define FLAGS_MODE_SHIFT\t18\n#define FLAGS_MODE_MASK\t\t(SHA_REG_MODE_ALGO_MASK\t<< FLAGS_MODE_SHIFT)\n#define FLAGS_MODE_MD5\t\t(SHA_REG_MODE_ALGO_MD5_128 << FLAGS_MODE_SHIFT)\n#define FLAGS_MODE_SHA1\t\t(SHA_REG_MODE_ALGO_SHA1_160 << FLAGS_MODE_SHIFT)\n#define FLAGS_MODE_SHA224\t(SHA_REG_MODE_ALGO_SHA2_224 << FLAGS_MODE_SHIFT)\n#define FLAGS_MODE_SHA256\t(SHA_REG_MODE_ALGO_SHA2_256 << FLAGS_MODE_SHIFT)\n#define FLAGS_MODE_SHA384\t(SHA_REG_MODE_ALGO_SHA2_384 << FLAGS_MODE_SHIFT)\n#define FLAGS_MODE_SHA512\t(SHA_REG_MODE_ALGO_SHA2_512 << FLAGS_MODE_SHIFT)\n\n#define FLAGS_HMAC\t\t21\n#define FLAGS_ERROR\t\t22\n\n#define OP_UPDATE\t\t1\n#define OP_FINAL\t\t2\n\n#define OMAP_ALIGN_MASK\t\t(sizeof(u32)-1)\n#define OMAP_ALIGNED\t\t__attribute__((aligned(sizeof(u32))))\n\n#define BUFLEN\t\t\tSHA512_BLOCK_SIZE\n#define OMAP_SHA_DMA_THRESHOLD\t256\n\n#define OMAP_SHA_MAX_DMA_LEN\t(1024 * 2048)\n\nstruct omap_sham_dev;\n\nstruct omap_sham_reqctx {\n\tstruct omap_sham_dev\t*dd;\n\tunsigned long\t\tflags;\n\tu8\t\t\top;\n\n\tu8\t\t\tdigest[SHA512_DIGEST_SIZE] OMAP_ALIGNED;\n\tsize_t\t\t\tdigcnt;\n\tsize_t\t\t\tbufcnt;\n\tsize_t\t\t\tbuflen;\n\n\t \n\tstruct scatterlist\t*sg;\n\tstruct scatterlist\tsgl[2];\n\tint\t\t\toffset;\t \n\tint\t\t\tsg_len;\n\tunsigned int\t\ttotal;\t \n\n\tu8\t\t\tbuffer[] OMAP_ALIGNED;\n};\n\nstruct omap_sham_hmac_ctx {\n\tstruct crypto_shash\t*shash;\n\tu8\t\t\tipad[SHA512_BLOCK_SIZE] OMAP_ALIGNED;\n\tu8\t\t\topad[SHA512_BLOCK_SIZE] OMAP_ALIGNED;\n};\n\nstruct omap_sham_ctx {\n\tunsigned long\t\tflags;\n\n\t \n\tstruct crypto_shash\t*fallback;\n\n\tstruct omap_sham_hmac_ctx base[];\n};\n\n#define OMAP_SHAM_QUEUE_LENGTH\t10\n\nstruct omap_sham_algs_info {\n\tstruct ahash_engine_alg\t*algs_list;\n\tunsigned int\t\tsize;\n\tunsigned int\t\tregistered;\n};\n\nstruct omap_sham_pdata {\n\tstruct omap_sham_algs_info\t*algs_info;\n\tunsigned int\talgs_info_size;\n\tunsigned long\tflags;\n\tint\t\tdigest_size;\n\n\tvoid\t\t(*copy_hash)(struct ahash_request *req, int out);\n\tvoid\t\t(*write_ctrl)(struct omap_sham_dev *dd, size_t length,\n\t\t\t\t      int final, int dma);\n\tvoid\t\t(*trigger)(struct omap_sham_dev *dd, size_t length);\n\tint\t\t(*poll_irq)(struct omap_sham_dev *dd);\n\tirqreturn_t\t(*intr_hdlr)(int irq, void *dev_id);\n\n\tu32\t\todigest_ofs;\n\tu32\t\tidigest_ofs;\n\tu32\t\tdin_ofs;\n\tu32\t\tdigcnt_ofs;\n\tu32\t\trev_ofs;\n\tu32\t\tmask_ofs;\n\tu32\t\tsysstatus_ofs;\n\tu32\t\tmode_ofs;\n\tu32\t\tlength_ofs;\n\n\tu32\t\tmajor_mask;\n\tu32\t\tmajor_shift;\n\tu32\t\tminor_mask;\n\tu32\t\tminor_shift;\n};\n\nstruct omap_sham_dev {\n\tstruct list_head\tlist;\n\tunsigned long\t\tphys_base;\n\tstruct device\t\t*dev;\n\tvoid __iomem\t\t*io_base;\n\tint\t\t\tirq;\n\tint\t\t\terr;\n\tstruct dma_chan\t\t*dma_lch;\n\tstruct tasklet_struct\tdone_task;\n\tu8\t\t\tpolling_mode;\n\tu8\t\t\txmit_buf[BUFLEN] OMAP_ALIGNED;\n\n\tunsigned long\t\tflags;\n\tint\t\t\tfallback_sz;\n\tstruct crypto_queue\tqueue;\n\tstruct ahash_request\t*req;\n\tstruct crypto_engine\t*engine;\n\n\tconst struct omap_sham_pdata\t*pdata;\n};\n\nstruct omap_sham_drv {\n\tstruct list_head\tdev_list;\n\tspinlock_t\t\tlock;\n\tunsigned long\t\tflags;\n};\n\nstatic struct omap_sham_drv sham = {\n\t.dev_list = LIST_HEAD_INIT(sham.dev_list),\n\t.lock = __SPIN_LOCK_UNLOCKED(sham.lock),\n};\n\nstatic int omap_sham_enqueue(struct ahash_request *req, unsigned int op);\nstatic void omap_sham_finish_req(struct ahash_request *req, int err);\n\nstatic inline u32 omap_sham_read(struct omap_sham_dev *dd, u32 offset)\n{\n\treturn __raw_readl(dd->io_base + offset);\n}\n\nstatic inline void omap_sham_write(struct omap_sham_dev *dd,\n\t\t\t\t\tu32 offset, u32 value)\n{\n\t__raw_writel(value, dd->io_base + offset);\n}\n\nstatic inline void omap_sham_write_mask(struct omap_sham_dev *dd, u32 address,\n\t\t\t\t\tu32 value, u32 mask)\n{\n\tu32 val;\n\n\tval = omap_sham_read(dd, address);\n\tval &= ~mask;\n\tval |= value;\n\tomap_sham_write(dd, address, val);\n}\n\nstatic inline int omap_sham_wait(struct omap_sham_dev *dd, u32 offset, u32 bit)\n{\n\tunsigned long timeout = jiffies + DEFAULT_TIMEOUT_INTERVAL;\n\n\twhile (!(omap_sham_read(dd, offset) & bit)) {\n\t\tif (time_is_before_jiffies(timeout))\n\t\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\nstatic void omap_sham_copy_hash_omap2(struct ahash_request *req, int out)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd = ctx->dd;\n\tu32 *hash = (u32 *)ctx->digest;\n\tint i;\n\n\tfor (i = 0; i < dd->pdata->digest_size / sizeof(u32); i++) {\n\t\tif (out)\n\t\t\thash[i] = omap_sham_read(dd, SHA_REG_IDIGEST(dd, i));\n\t\telse\n\t\t\tomap_sham_write(dd, SHA_REG_IDIGEST(dd, i), hash[i]);\n\t}\n}\n\nstatic void omap_sham_copy_hash_omap4(struct ahash_request *req, int out)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd = ctx->dd;\n\tint i;\n\n\tif (ctx->flags & BIT(FLAGS_HMAC)) {\n\t\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(dd->req);\n\t\tstruct omap_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\t\tstruct omap_sham_hmac_ctx *bctx = tctx->base;\n\t\tu32 *opad = (u32 *)bctx->opad;\n\n\t\tfor (i = 0; i < dd->pdata->digest_size / sizeof(u32); i++) {\n\t\t\tif (out)\n\t\t\t\topad[i] = omap_sham_read(dd,\n\t\t\t\t\t\tSHA_REG_ODIGEST(dd, i));\n\t\t\telse\n\t\t\t\tomap_sham_write(dd, SHA_REG_ODIGEST(dd, i),\n\t\t\t\t\t\topad[i]);\n\t\t}\n\t}\n\n\tomap_sham_copy_hash_omap2(req, out);\n}\n\nstatic void omap_sham_copy_ready_hash(struct ahash_request *req)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tu32 *in = (u32 *)ctx->digest;\n\tu32 *hash = (u32 *)req->result;\n\tint i, d, big_endian = 0;\n\n\tif (!hash)\n\t\treturn;\n\n\tswitch (ctx->flags & FLAGS_MODE_MASK) {\n\tcase FLAGS_MODE_MD5:\n\t\td = MD5_DIGEST_SIZE / sizeof(u32);\n\t\tbreak;\n\tcase FLAGS_MODE_SHA1:\n\t\t \n\t\tif (test_bit(FLAGS_BE32_SHA1, &ctx->dd->flags))\n\t\t\tbig_endian = 1;\n\t\td = SHA1_DIGEST_SIZE / sizeof(u32);\n\t\tbreak;\n\tcase FLAGS_MODE_SHA224:\n\t\td = SHA224_DIGEST_SIZE / sizeof(u32);\n\t\tbreak;\n\tcase FLAGS_MODE_SHA256:\n\t\td = SHA256_DIGEST_SIZE / sizeof(u32);\n\t\tbreak;\n\tcase FLAGS_MODE_SHA384:\n\t\td = SHA384_DIGEST_SIZE / sizeof(u32);\n\t\tbreak;\n\tcase FLAGS_MODE_SHA512:\n\t\td = SHA512_DIGEST_SIZE / sizeof(u32);\n\t\tbreak;\n\tdefault:\n\t\td = 0;\n\t}\n\n\tif (big_endian)\n\t\tfor (i = 0; i < d; i++)\n\t\t\thash[i] = be32_to_cpup((__be32 *)in + i);\n\telse\n\t\tfor (i = 0; i < d; i++)\n\t\t\thash[i] = le32_to_cpup((__le32 *)in + i);\n}\n\nstatic void omap_sham_write_ctrl_omap2(struct omap_sham_dev *dd, size_t length,\n\t\t\t\t int final, int dma)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(dd->req);\n\tu32 val = length << 5, mask;\n\n\tif (likely(ctx->digcnt))\n\t\tomap_sham_write(dd, SHA_REG_DIGCNT(dd), ctx->digcnt);\n\n\tomap_sham_write_mask(dd, SHA_REG_MASK(dd),\n\t\tSHA_REG_MASK_IT_EN | (dma ? SHA_REG_MASK_DMA_EN : 0),\n\t\tSHA_REG_MASK_IT_EN | SHA_REG_MASK_DMA_EN);\n\t \n\tif ((ctx->flags & FLAGS_MODE_MASK) == FLAGS_MODE_SHA1)\n\t\tval |= SHA_REG_CTRL_ALGO;\n\tif (!ctx->digcnt)\n\t\tval |= SHA_REG_CTRL_ALGO_CONST;\n\tif (final)\n\t\tval |= SHA_REG_CTRL_CLOSE_HASH;\n\n\tmask = SHA_REG_CTRL_ALGO_CONST | SHA_REG_CTRL_CLOSE_HASH |\n\t\t\tSHA_REG_CTRL_ALGO | SHA_REG_CTRL_LENGTH;\n\n\tomap_sham_write_mask(dd, SHA_REG_CTRL, val, mask);\n}\n\nstatic void omap_sham_trigger_omap2(struct omap_sham_dev *dd, size_t length)\n{\n}\n\nstatic int omap_sham_poll_irq_omap2(struct omap_sham_dev *dd)\n{\n\treturn omap_sham_wait(dd, SHA_REG_CTRL, SHA_REG_CTRL_INPUT_READY);\n}\n\nstatic int get_block_size(struct omap_sham_reqctx *ctx)\n{\n\tint d;\n\n\tswitch (ctx->flags & FLAGS_MODE_MASK) {\n\tcase FLAGS_MODE_MD5:\n\tcase FLAGS_MODE_SHA1:\n\t\td = SHA1_BLOCK_SIZE;\n\t\tbreak;\n\tcase FLAGS_MODE_SHA224:\n\tcase FLAGS_MODE_SHA256:\n\t\td = SHA256_BLOCK_SIZE;\n\t\tbreak;\n\tcase FLAGS_MODE_SHA384:\n\tcase FLAGS_MODE_SHA512:\n\t\td = SHA512_BLOCK_SIZE;\n\t\tbreak;\n\tdefault:\n\t\td = 0;\n\t}\n\n\treturn d;\n}\n\nstatic void omap_sham_write_n(struct omap_sham_dev *dd, u32 offset,\n\t\t\t\t    u32 *value, int count)\n{\n\tfor (; count--; value++, offset += 4)\n\t\tomap_sham_write(dd, offset, *value);\n}\n\nstatic void omap_sham_write_ctrl_omap4(struct omap_sham_dev *dd, size_t length,\n\t\t\t\t int final, int dma)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(dd->req);\n\tu32 val, mask;\n\n\tif (likely(ctx->digcnt))\n\t\tomap_sham_write(dd, SHA_REG_DIGCNT(dd), ctx->digcnt);\n\n\t \n\tval = (ctx->flags & FLAGS_MODE_MASK) >> (FLAGS_MODE_SHIFT);\n\tif (!ctx->digcnt) {\n\t\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(dd->req);\n\t\tstruct omap_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\t\tstruct omap_sham_hmac_ctx *bctx = tctx->base;\n\t\tint bs, nr_dr;\n\n\t\tval |= SHA_REG_MODE_ALGO_CONSTANT;\n\n\t\tif (ctx->flags & BIT(FLAGS_HMAC)) {\n\t\t\tbs = get_block_size(ctx);\n\t\t\tnr_dr = bs / (2 * sizeof(u32));\n\t\t\tval |= SHA_REG_MODE_HMAC_KEY_PROC;\n\t\t\tomap_sham_write_n(dd, SHA_REG_ODIGEST(dd, 0),\n\t\t\t\t\t  (u32 *)bctx->ipad, nr_dr);\n\t\t\tomap_sham_write_n(dd, SHA_REG_IDIGEST(dd, 0),\n\t\t\t\t\t  (u32 *)bctx->ipad + nr_dr, nr_dr);\n\t\t\tctx->digcnt += bs;\n\t\t}\n\t}\n\n\tif (final) {\n\t\tval |= SHA_REG_MODE_CLOSE_HASH;\n\n\t\tif (ctx->flags & BIT(FLAGS_HMAC))\n\t\t\tval |= SHA_REG_MODE_HMAC_OUTER_HASH;\n\t}\n\n\tmask = SHA_REG_MODE_ALGO_CONSTANT | SHA_REG_MODE_CLOSE_HASH |\n\t       SHA_REG_MODE_ALGO_MASK | SHA_REG_MODE_HMAC_OUTER_HASH |\n\t       SHA_REG_MODE_HMAC_KEY_PROC;\n\n\tdev_dbg(dd->dev, \"ctrl: %08x, flags: %08lx\\n\", val, ctx->flags);\n\tomap_sham_write_mask(dd, SHA_REG_MODE(dd), val, mask);\n\tomap_sham_write(dd, SHA_REG_IRQENA, SHA_REG_IRQENA_OUTPUT_RDY);\n\tomap_sham_write_mask(dd, SHA_REG_MASK(dd),\n\t\t\t     SHA_REG_MASK_IT_EN |\n\t\t\t\t     (dma ? SHA_REG_MASK_DMA_EN : 0),\n\t\t\t     SHA_REG_MASK_IT_EN | SHA_REG_MASK_DMA_EN);\n}\n\nstatic void omap_sham_trigger_omap4(struct omap_sham_dev *dd, size_t length)\n{\n\tomap_sham_write(dd, SHA_REG_LENGTH(dd), length);\n}\n\nstatic int omap_sham_poll_irq_omap4(struct omap_sham_dev *dd)\n{\n\treturn omap_sham_wait(dd, SHA_REG_IRQSTATUS,\n\t\t\t      SHA_REG_IRQSTATUS_INPUT_RDY);\n}\n\nstatic int omap_sham_xmit_cpu(struct omap_sham_dev *dd, size_t length,\n\t\t\t      int final)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(dd->req);\n\tint count, len32, bs32, offset = 0;\n\tconst u32 *buffer;\n\tint mlen;\n\tstruct sg_mapping_iter mi;\n\n\tdev_dbg(dd->dev, \"xmit_cpu: digcnt: %zd, length: %zd, final: %d\\n\",\n\t\t\t\t\t\tctx->digcnt, length, final);\n\n\tdd->pdata->write_ctrl(dd, length, final, 0);\n\tdd->pdata->trigger(dd, length);\n\n\t \n\tctx->digcnt += length;\n\tctx->total -= length;\n\n\tif (final)\n\t\tset_bit(FLAGS_FINAL, &dd->flags);  \n\n\tset_bit(FLAGS_CPU, &dd->flags);\n\n\tlen32 = DIV_ROUND_UP(length, sizeof(u32));\n\tbs32 = get_block_size(ctx) / sizeof(u32);\n\n\tsg_miter_start(&mi, ctx->sg, ctx->sg_len,\n\t\t       SG_MITER_FROM_SG | SG_MITER_ATOMIC);\n\n\tmlen = 0;\n\n\twhile (len32) {\n\t\tif (dd->pdata->poll_irq(dd))\n\t\t\treturn -ETIMEDOUT;\n\n\t\tfor (count = 0; count < min(len32, bs32); count++, offset++) {\n\t\t\tif (!mlen) {\n\t\t\t\tsg_miter_next(&mi);\n\t\t\t\tmlen = mi.length;\n\t\t\t\tif (!mlen) {\n\t\t\t\t\tpr_err(\"sg miter failure.\\n\");\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\t}\n\t\t\t\toffset = 0;\n\t\t\t\tbuffer = mi.addr;\n\t\t\t}\n\t\t\tomap_sham_write(dd, SHA_REG_DIN(dd, count),\n\t\t\t\t\tbuffer[offset]);\n\t\t\tmlen -= 4;\n\t\t}\n\t\tlen32 -= min(len32, bs32);\n\t}\n\n\tsg_miter_stop(&mi);\n\n\treturn -EINPROGRESS;\n}\n\nstatic void omap_sham_dma_callback(void *param)\n{\n\tstruct omap_sham_dev *dd = param;\n\n\tset_bit(FLAGS_DMA_READY, &dd->flags);\n\ttasklet_schedule(&dd->done_task);\n}\n\nstatic int omap_sham_xmit_dma(struct omap_sham_dev *dd, size_t length,\n\t\t\t      int final)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(dd->req);\n\tstruct dma_async_tx_descriptor *tx;\n\tstruct dma_slave_config cfg;\n\tint ret;\n\n\tdev_dbg(dd->dev, \"xmit_dma: digcnt: %zd, length: %zd, final: %d\\n\",\n\t\t\t\t\t\tctx->digcnt, length, final);\n\n\tif (!dma_map_sg(dd->dev, ctx->sg, ctx->sg_len, DMA_TO_DEVICE)) {\n\t\tdev_err(dd->dev, \"dma_map_sg error\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&cfg, 0, sizeof(cfg));\n\n\tcfg.dst_addr = dd->phys_base + SHA_REG_DIN(dd, 0);\n\tcfg.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\tcfg.dst_maxburst = get_block_size(ctx) / DMA_SLAVE_BUSWIDTH_4_BYTES;\n\n\tret = dmaengine_slave_config(dd->dma_lch, &cfg);\n\tif (ret) {\n\t\tpr_err(\"omap-sham: can't configure dmaengine slave: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\ttx = dmaengine_prep_slave_sg(dd->dma_lch, ctx->sg, ctx->sg_len,\n\t\t\t\t     DMA_MEM_TO_DEV,\n\t\t\t\t     DMA_PREP_INTERRUPT | DMA_CTRL_ACK);\n\n\tif (!tx) {\n\t\tdev_err(dd->dev, \"prep_slave_sg failed\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ttx->callback = omap_sham_dma_callback;\n\ttx->callback_param = dd;\n\n\tdd->pdata->write_ctrl(dd, length, final, 1);\n\n\tctx->digcnt += length;\n\tctx->total -= length;\n\n\tif (final)\n\t\tset_bit(FLAGS_FINAL, &dd->flags);  \n\n\tset_bit(FLAGS_DMA_ACTIVE, &dd->flags);\n\n\tdmaengine_submit(tx);\n\tdma_async_issue_pending(dd->dma_lch);\n\n\tdd->pdata->trigger(dd, length);\n\n\treturn -EINPROGRESS;\n}\n\nstatic int omap_sham_copy_sg_lists(struct omap_sham_reqctx *ctx,\n\t\t\t\t   struct scatterlist *sg, int bs, int new_len)\n{\n\tint n = sg_nents(sg);\n\tstruct scatterlist *tmp;\n\tint offset = ctx->offset;\n\n\tctx->total = new_len;\n\n\tif (ctx->bufcnt)\n\t\tn++;\n\n\tctx->sg = kmalloc_array(n, sizeof(*sg), GFP_KERNEL);\n\tif (!ctx->sg)\n\t\treturn -ENOMEM;\n\n\tsg_init_table(ctx->sg, n);\n\n\ttmp = ctx->sg;\n\n\tctx->sg_len = 0;\n\n\tif (ctx->bufcnt) {\n\t\tsg_set_buf(tmp, ctx->dd->xmit_buf, ctx->bufcnt);\n\t\ttmp = sg_next(tmp);\n\t\tctx->sg_len++;\n\t\tnew_len -= ctx->bufcnt;\n\t}\n\n\twhile (sg && new_len) {\n\t\tint len = sg->length - offset;\n\n\t\tif (len <= 0) {\n\t\t\toffset -= sg->length;\n\t\t\tsg = sg_next(sg);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (new_len < len)\n\t\t\tlen = new_len;\n\n\t\tif (len > 0) {\n\t\t\tnew_len -= len;\n\t\t\tsg_set_page(tmp, sg_page(sg), len, sg->offset + offset);\n\t\t\toffset = 0;\n\t\t\tctx->offset = 0;\n\t\t\tctx->sg_len++;\n\t\t\tif (new_len <= 0)\n\t\t\t\tbreak;\n\t\t\ttmp = sg_next(tmp);\n\t\t}\n\n\t\tsg = sg_next(sg);\n\t}\n\n\tif (tmp)\n\t\tsg_mark_end(tmp);\n\n\tset_bit(FLAGS_SGS_ALLOCED, &ctx->dd->flags);\n\n\tctx->offset += new_len - ctx->bufcnt;\n\tctx->bufcnt = 0;\n\n\treturn 0;\n}\n\nstatic int omap_sham_copy_sgs(struct omap_sham_reqctx *ctx,\n\t\t\t      struct scatterlist *sg, int bs,\n\t\t\t      unsigned int new_len)\n{\n\tint pages;\n\tvoid *buf;\n\n\tpages = get_order(new_len);\n\n\tbuf = (void *)__get_free_pages(GFP_ATOMIC, pages);\n\tif (!buf) {\n\t\tpr_err(\"Couldn't allocate pages for unaligned cases.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (ctx->bufcnt)\n\t\tmemcpy(buf, ctx->dd->xmit_buf, ctx->bufcnt);\n\n\tscatterwalk_map_and_copy(buf + ctx->bufcnt, sg, ctx->offset,\n\t\t\t\t min(new_len, ctx->total) - ctx->bufcnt, 0);\n\tsg_init_table(ctx->sgl, 1);\n\tsg_set_buf(ctx->sgl, buf, new_len);\n\tctx->sg = ctx->sgl;\n\tset_bit(FLAGS_SGS_COPIED, &ctx->dd->flags);\n\tctx->sg_len = 1;\n\tctx->offset += new_len - ctx->bufcnt;\n\tctx->bufcnt = 0;\n\tctx->total = new_len;\n\n\treturn 0;\n}\n\nstatic int omap_sham_align_sgs(struct scatterlist *sg,\n\t\t\t       int nbytes, int bs, bool final,\n\t\t\t       struct omap_sham_reqctx *rctx)\n{\n\tint n = 0;\n\tbool aligned = true;\n\tbool list_ok = true;\n\tstruct scatterlist *sg_tmp = sg;\n\tint new_len;\n\tint offset = rctx->offset;\n\tint bufcnt = rctx->bufcnt;\n\n\tif (!sg || !sg->length || !nbytes) {\n\t\tif (bufcnt) {\n\t\t\tbufcnt = DIV_ROUND_UP(bufcnt, bs) * bs;\n\t\t\tsg_init_table(rctx->sgl, 1);\n\t\t\tsg_set_buf(rctx->sgl, rctx->dd->xmit_buf, bufcnt);\n\t\t\trctx->sg = rctx->sgl;\n\t\t\trctx->sg_len = 1;\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tnew_len = nbytes;\n\n\tif (offset)\n\t\tlist_ok = false;\n\n\tif (final)\n\t\tnew_len = DIV_ROUND_UP(new_len, bs) * bs;\n\telse\n\t\tnew_len = (new_len - 1) / bs * bs;\n\n\tif (!new_len)\n\t\treturn 0;\n\n\tif (nbytes != new_len)\n\t\tlist_ok = false;\n\n\twhile (nbytes > 0 && sg_tmp) {\n\t\tn++;\n\n\t\tif (bufcnt) {\n\t\t\tif (!IS_ALIGNED(bufcnt, bs)) {\n\t\t\t\taligned = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tnbytes -= bufcnt;\n\t\t\tbufcnt = 0;\n\t\t\tif (!nbytes)\n\t\t\t\tlist_ok = false;\n\n\t\t\tcontinue;\n\t\t}\n\n#ifdef CONFIG_ZONE_DMA\n\t\tif (page_zonenum(sg_page(sg_tmp)) != ZONE_DMA) {\n\t\t\taligned = false;\n\t\t\tbreak;\n\t\t}\n#endif\n\n\t\tif (offset < sg_tmp->length) {\n\t\t\tif (!IS_ALIGNED(offset + sg_tmp->offset, 4)) {\n\t\t\t\taligned = false;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (!IS_ALIGNED(sg_tmp->length - offset, bs)) {\n\t\t\t\taligned = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (offset) {\n\t\t\toffset -= sg_tmp->length;\n\t\t\tif (offset < 0) {\n\t\t\t\tnbytes += offset;\n\t\t\t\toffset = 0;\n\t\t\t}\n\t\t} else {\n\t\t\tnbytes -= sg_tmp->length;\n\t\t}\n\n\t\tsg_tmp = sg_next(sg_tmp);\n\n\t\tif (nbytes < 0) {\n\t\t\tlist_ok = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (new_len > OMAP_SHA_MAX_DMA_LEN) {\n\t\tnew_len = OMAP_SHA_MAX_DMA_LEN;\n\t\taligned = false;\n\t}\n\n\tif (!aligned)\n\t\treturn omap_sham_copy_sgs(rctx, sg, bs, new_len);\n\telse if (!list_ok)\n\t\treturn omap_sham_copy_sg_lists(rctx, sg, bs, new_len);\n\n\trctx->total = new_len;\n\trctx->offset += new_len;\n\trctx->sg_len = n;\n\tif (rctx->bufcnt) {\n\t\tsg_init_table(rctx->sgl, 2);\n\t\tsg_set_buf(rctx->sgl, rctx->dd->xmit_buf, rctx->bufcnt);\n\t\tsg_chain(rctx->sgl, 2, sg);\n\t\trctx->sg = rctx->sgl;\n\t} else {\n\t\trctx->sg = sg;\n\t}\n\n\treturn 0;\n}\n\nstatic int omap_sham_prepare_request(struct crypto_engine *engine, void *areq)\n{\n\tstruct ahash_request *req = container_of(areq, struct ahash_request,\n\t\t\t\t\t\t base);\n\tstruct omap_sham_reqctx *rctx = ahash_request_ctx(req);\n\tint bs;\n\tint ret;\n\tunsigned int nbytes;\n\tbool final = rctx->flags & BIT(FLAGS_FINUP);\n\tbool update = rctx->op == OP_UPDATE;\n\tint hash_later;\n\n\tbs = get_block_size(rctx);\n\n\tnbytes = rctx->bufcnt;\n\n\tif (update)\n\t\tnbytes += req->nbytes - rctx->offset;\n\n\tdev_dbg(rctx->dd->dev,\n\t\t\"%s: nbytes=%d, bs=%d, total=%d, offset=%d, bufcnt=%zd\\n\",\n\t\t__func__, nbytes, bs, rctx->total, rctx->offset,\n\t\trctx->bufcnt);\n\n\tif (!nbytes)\n\t\treturn 0;\n\n\trctx->total = nbytes;\n\n\tif (update && req->nbytes && (!IS_ALIGNED(rctx->bufcnt, bs))) {\n\t\tint len = bs - rctx->bufcnt % bs;\n\n\t\tif (len > req->nbytes)\n\t\t\tlen = req->nbytes;\n\t\tscatterwalk_map_and_copy(rctx->buffer + rctx->bufcnt, req->src,\n\t\t\t\t\t 0, len, 0);\n\t\trctx->bufcnt += len;\n\t\trctx->offset = len;\n\t}\n\n\tif (rctx->bufcnt)\n\t\tmemcpy(rctx->dd->xmit_buf, rctx->buffer, rctx->bufcnt);\n\n\tret = omap_sham_align_sgs(req->src, nbytes, bs, final, rctx);\n\tif (ret)\n\t\treturn ret;\n\n\thash_later = nbytes - rctx->total;\n\tif (hash_later < 0)\n\t\thash_later = 0;\n\n\tif (hash_later && hash_later <= rctx->buflen) {\n\t\tscatterwalk_map_and_copy(rctx->buffer,\n\t\t\t\t\t req->src,\n\t\t\t\t\t req->nbytes - hash_later,\n\t\t\t\t\t hash_later, 0);\n\n\t\trctx->bufcnt = hash_later;\n\t} else {\n\t\trctx->bufcnt = 0;\n\t}\n\n\tif (hash_later > rctx->buflen)\n\t\tset_bit(FLAGS_HUGE, &rctx->dd->flags);\n\n\trctx->total = min(nbytes, rctx->total);\n\n\treturn 0;\n}\n\nstatic int omap_sham_update_dma_stop(struct omap_sham_dev *dd)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(dd->req);\n\n\tdma_unmap_sg(dd->dev, ctx->sg, ctx->sg_len, DMA_TO_DEVICE);\n\n\tclear_bit(FLAGS_DMA_ACTIVE, &dd->flags);\n\n\treturn 0;\n}\n\nstatic struct omap_sham_dev *omap_sham_find_dev(struct omap_sham_reqctx *ctx)\n{\n\tstruct omap_sham_dev *dd;\n\n\tif (ctx->dd)\n\t\treturn ctx->dd;\n\n\tspin_lock_bh(&sham.lock);\n\tdd = list_first_entry(&sham.dev_list, struct omap_sham_dev, list);\n\tlist_move_tail(&dd->list, &sham.dev_list);\n\tctx->dd = dd;\n\tspin_unlock_bh(&sham.lock);\n\n\treturn dd;\n}\n\nstatic int omap_sham_init(struct ahash_request *req)\n{\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct omap_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd;\n\tint bs = 0;\n\n\tctx->dd = NULL;\n\n\tdd = omap_sham_find_dev(ctx);\n\tif (!dd)\n\t\treturn -ENODEV;\n\n\tctx->flags = 0;\n\n\tdev_dbg(dd->dev, \"init: digest size: %d\\n\",\n\t\tcrypto_ahash_digestsize(tfm));\n\n\tswitch (crypto_ahash_digestsize(tfm)) {\n\tcase MD5_DIGEST_SIZE:\n\t\tctx->flags |= FLAGS_MODE_MD5;\n\t\tbs = SHA1_BLOCK_SIZE;\n\t\tbreak;\n\tcase SHA1_DIGEST_SIZE:\n\t\tctx->flags |= FLAGS_MODE_SHA1;\n\t\tbs = SHA1_BLOCK_SIZE;\n\t\tbreak;\n\tcase SHA224_DIGEST_SIZE:\n\t\tctx->flags |= FLAGS_MODE_SHA224;\n\t\tbs = SHA224_BLOCK_SIZE;\n\t\tbreak;\n\tcase SHA256_DIGEST_SIZE:\n\t\tctx->flags |= FLAGS_MODE_SHA256;\n\t\tbs = SHA256_BLOCK_SIZE;\n\t\tbreak;\n\tcase SHA384_DIGEST_SIZE:\n\t\tctx->flags |= FLAGS_MODE_SHA384;\n\t\tbs = SHA384_BLOCK_SIZE;\n\t\tbreak;\n\tcase SHA512_DIGEST_SIZE:\n\t\tctx->flags |= FLAGS_MODE_SHA512;\n\t\tbs = SHA512_BLOCK_SIZE;\n\t\tbreak;\n\t}\n\n\tctx->bufcnt = 0;\n\tctx->digcnt = 0;\n\tctx->total = 0;\n\tctx->offset = 0;\n\tctx->buflen = BUFLEN;\n\n\tif (tctx->flags & BIT(FLAGS_HMAC)) {\n\t\tif (!test_bit(FLAGS_AUTO_XOR, &dd->flags)) {\n\t\t\tstruct omap_sham_hmac_ctx *bctx = tctx->base;\n\n\t\t\tmemcpy(ctx->buffer, bctx->ipad, bs);\n\t\t\tctx->bufcnt = bs;\n\t\t}\n\n\t\tctx->flags |= BIT(FLAGS_HMAC);\n\t}\n\n\treturn 0;\n\n}\n\nstatic int omap_sham_update_req(struct omap_sham_dev *dd)\n{\n\tstruct ahash_request *req = dd->req;\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tint err;\n\tbool final = (ctx->flags & BIT(FLAGS_FINUP)) &&\n\t\t!(dd->flags & BIT(FLAGS_HUGE));\n\n\tdev_dbg(dd->dev, \"update_req: total: %u, digcnt: %zd, final: %d\",\n\t\tctx->total, ctx->digcnt, final);\n\n\tif (ctx->total < get_block_size(ctx) ||\n\t    ctx->total < dd->fallback_sz)\n\t\tctx->flags |= BIT(FLAGS_CPU);\n\n\tif (ctx->flags & BIT(FLAGS_CPU))\n\t\terr = omap_sham_xmit_cpu(dd, ctx->total, final);\n\telse\n\t\terr = omap_sham_xmit_dma(dd, ctx->total, final);\n\n\t \n\tdev_dbg(dd->dev, \"update: err: %d, digcnt: %zd\\n\", err, ctx->digcnt);\n\n\treturn err;\n}\n\nstatic int omap_sham_final_req(struct omap_sham_dev *dd)\n{\n\tstruct ahash_request *req = dd->req;\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tint err = 0, use_dma = 1;\n\n\tif (dd->flags & BIT(FLAGS_HUGE))\n\t\treturn 0;\n\n\tif ((ctx->total <= get_block_size(ctx)) || dd->polling_mode)\n\t\t \n\t\tuse_dma = 0;\n\n\tif (use_dma)\n\t\terr = omap_sham_xmit_dma(dd, ctx->total, 1);\n\telse\n\t\terr = omap_sham_xmit_cpu(dd, ctx->total, 1);\n\n\tctx->bufcnt = 0;\n\n\tdev_dbg(dd->dev, \"final_req: err: %d\\n\", err);\n\n\treturn err;\n}\n\nstatic int omap_sham_hash_one_req(struct crypto_engine *engine, void *areq)\n{\n\tstruct ahash_request *req = container_of(areq, struct ahash_request,\n\t\t\t\t\t\t base);\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd = ctx->dd;\n\tint err;\n\tbool final = (ctx->flags & BIT(FLAGS_FINUP)) &&\n\t\t\t!(dd->flags & BIT(FLAGS_HUGE));\n\n\tdev_dbg(dd->dev, \"hash-one: op: %u, total: %u, digcnt: %zd, final: %d\",\n\t\tctx->op, ctx->total, ctx->digcnt, final);\n\n\terr = omap_sham_prepare_request(engine, areq);\n\tif (err)\n\t\treturn err;\n\n\terr = pm_runtime_resume_and_get(dd->dev);\n\tif (err < 0) {\n\t\tdev_err(dd->dev, \"failed to get sync: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\tdd->err = 0;\n\tdd->req = req;\n\n\tif (ctx->digcnt)\n\t\tdd->pdata->copy_hash(req, 0);\n\n\tif (ctx->op == OP_UPDATE)\n\t\terr = omap_sham_update_req(dd);\n\telse if (ctx->op == OP_FINAL)\n\t\terr = omap_sham_final_req(dd);\n\n\tif (err != -EINPROGRESS)\n\t\tomap_sham_finish_req(req, err);\n\n\treturn 0;\n}\n\nstatic int omap_sham_finish_hmac(struct ahash_request *req)\n{\n\tstruct omap_sham_ctx *tctx = crypto_tfm_ctx(req->base.tfm);\n\tstruct omap_sham_hmac_ctx *bctx = tctx->base;\n\tint bs = crypto_shash_blocksize(bctx->shash);\n\tint ds = crypto_shash_digestsize(bctx->shash);\n\tSHASH_DESC_ON_STACK(shash, bctx->shash);\n\n\tshash->tfm = bctx->shash;\n\n\treturn crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, bctx->opad, bs) ?:\n\t       crypto_shash_finup(shash, req->result, ds, req->result);\n}\n\nstatic int omap_sham_finish(struct ahash_request *req)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd = ctx->dd;\n\tint err = 0;\n\n\tif (ctx->digcnt) {\n\t\tomap_sham_copy_ready_hash(req);\n\t\tif ((ctx->flags & BIT(FLAGS_HMAC)) &&\n\t\t\t\t!test_bit(FLAGS_AUTO_XOR, &dd->flags))\n\t\t\terr = omap_sham_finish_hmac(req);\n\t}\n\n\tdev_dbg(dd->dev, \"digcnt: %zd, bufcnt: %zd\\n\", ctx->digcnt, ctx->bufcnt);\n\n\treturn err;\n}\n\nstatic void omap_sham_finish_req(struct ahash_request *req, int err)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd = ctx->dd;\n\n\tif (test_bit(FLAGS_SGS_COPIED, &dd->flags))\n\t\tfree_pages((unsigned long)sg_virt(ctx->sg),\n\t\t\t   get_order(ctx->sg->length));\n\n\tif (test_bit(FLAGS_SGS_ALLOCED, &dd->flags))\n\t\tkfree(ctx->sg);\n\n\tctx->sg = NULL;\n\n\tdd->flags &= ~(BIT(FLAGS_SGS_ALLOCED) | BIT(FLAGS_SGS_COPIED) |\n\t\t       BIT(FLAGS_CPU) | BIT(FLAGS_DMA_READY) |\n\t\t       BIT(FLAGS_OUTPUT_READY));\n\n\tif (!err)\n\t\tdd->pdata->copy_hash(req, 1);\n\n\tif (dd->flags & BIT(FLAGS_HUGE)) {\n\t\t \n\t\tomap_sham_enqueue(req, ctx->op);\n\t\treturn;\n\t}\n\n\tif (!err) {\n\t\tif (test_bit(FLAGS_FINAL, &dd->flags))\n\t\t\terr = omap_sham_finish(req);\n\t} else {\n\t\tctx->flags |= BIT(FLAGS_ERROR);\n\t}\n\n\t \n\tdd->flags &= ~(BIT(FLAGS_FINAL) | BIT(FLAGS_CPU) |\n\t\t\tBIT(FLAGS_DMA_READY) | BIT(FLAGS_OUTPUT_READY));\n\n\tpm_runtime_mark_last_busy(dd->dev);\n\tpm_runtime_put_autosuspend(dd->dev);\n\n\tctx->offset = 0;\n\n\tcrypto_finalize_hash_request(dd->engine, req, err);\n}\n\nstatic int omap_sham_handle_queue(struct omap_sham_dev *dd,\n\t\t\t\t  struct ahash_request *req)\n{\n\treturn crypto_transfer_hash_request_to_engine(dd->engine, req);\n}\n\nstatic int omap_sham_enqueue(struct ahash_request *req, unsigned int op)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd = ctx->dd;\n\n\tctx->op = op;\n\n\treturn omap_sham_handle_queue(dd, req);\n}\n\nstatic int omap_sham_update(struct ahash_request *req)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tstruct omap_sham_dev *dd = omap_sham_find_dev(ctx);\n\n\tif (!req->nbytes)\n\t\treturn 0;\n\n\tif (ctx->bufcnt + req->nbytes <= ctx->buflen) {\n\t\tscatterwalk_map_and_copy(ctx->buffer + ctx->bufcnt, req->src,\n\t\t\t\t\t 0, req->nbytes, 0);\n\t\tctx->bufcnt += req->nbytes;\n\t\treturn 0;\n\t}\n\n\tif (dd->polling_mode)\n\t\tctx->flags |= BIT(FLAGS_CPU);\n\n\treturn omap_sham_enqueue(req, OP_UPDATE);\n}\n\nstatic int omap_sham_final_shash(struct ahash_request *req)\n{\n\tstruct omap_sham_ctx *tctx = crypto_tfm_ctx(req->base.tfm);\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tint offset = 0;\n\n\t \n\tif (test_bit(FLAGS_HMAC, &ctx->flags) &&\n\t    !test_bit(FLAGS_AUTO_XOR, &ctx->dd->flags))\n\t\toffset = get_block_size(ctx);\n\n\treturn crypto_shash_tfm_digest(tctx->fallback, ctx->buffer + offset,\n\t\t\t\t       ctx->bufcnt - offset, req->result);\n}\n\nstatic int omap_sham_final(struct ahash_request *req)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\n\tctx->flags |= BIT(FLAGS_FINUP);\n\n\tif (ctx->flags & BIT(FLAGS_ERROR))\n\t\treturn 0;  \n\n\t \n\tif (!ctx->digcnt && ctx->bufcnt < ctx->dd->fallback_sz)\n\t\treturn omap_sham_final_shash(req);\n\telse if (ctx->bufcnt)\n\t\treturn omap_sham_enqueue(req, OP_FINAL);\n\n\t \n\treturn omap_sham_finish(req);\n}\n\nstatic int omap_sham_finup(struct ahash_request *req)\n{\n\tstruct omap_sham_reqctx *ctx = ahash_request_ctx(req);\n\tint err1, err2;\n\n\tctx->flags |= BIT(FLAGS_FINUP);\n\n\terr1 = omap_sham_update(req);\n\tif (err1 == -EINPROGRESS || err1 == -EBUSY)\n\t\treturn err1;\n\t \n\terr2 = omap_sham_final(req);\n\n\treturn err1 ?: err2;\n}\n\nstatic int omap_sham_digest(struct ahash_request *req)\n{\n\treturn omap_sham_init(req) ?: omap_sham_finup(req);\n}\n\nstatic int omap_sham_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t      unsigned int keylen)\n{\n\tstruct omap_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct omap_sham_hmac_ctx *bctx = tctx->base;\n\tint bs = crypto_shash_blocksize(bctx->shash);\n\tint ds = crypto_shash_digestsize(bctx->shash);\n\tint err, i;\n\n\terr = crypto_shash_setkey(tctx->fallback, key, keylen);\n\tif (err)\n\t\treturn err;\n\n\tif (keylen > bs) {\n\t\terr = crypto_shash_tfm_digest(bctx->shash, key, keylen,\n\t\t\t\t\t      bctx->ipad);\n\t\tif (err)\n\t\t\treturn err;\n\t\tkeylen = ds;\n\t} else {\n\t\tmemcpy(bctx->ipad, key, keylen);\n\t}\n\n\tmemset(bctx->ipad + keylen, 0, bs - keylen);\n\n\tif (!test_bit(FLAGS_AUTO_XOR, &sham.flags)) {\n\t\tmemcpy(bctx->opad, bctx->ipad, bs);\n\n\t\tfor (i = 0; i < bs; i++) {\n\t\t\tbctx->ipad[i] ^= HMAC_IPAD_VALUE;\n\t\t\tbctx->opad[i] ^= HMAC_OPAD_VALUE;\n\t\t}\n\t}\n\n\treturn err;\n}\n\nstatic int omap_sham_cra_init_alg(struct crypto_tfm *tfm, const char *alg_base)\n{\n\tstruct omap_sham_ctx *tctx = crypto_tfm_ctx(tfm);\n\tconst char *alg_name = crypto_tfm_alg_name(tfm);\n\n\t \n\ttctx->fallback = crypto_alloc_shash(alg_name, 0,\n\t\t\t\t\t    CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(tctx->fallback)) {\n\t\tpr_err(\"omap-sham: fallback driver '%s' \"\n\t\t\t\t\"could not be loaded.\\n\", alg_name);\n\t\treturn PTR_ERR(tctx->fallback);\n\t}\n\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct omap_sham_reqctx) + BUFLEN);\n\n\tif (alg_base) {\n\t\tstruct omap_sham_hmac_ctx *bctx = tctx->base;\n\t\ttctx->flags |= BIT(FLAGS_HMAC);\n\t\tbctx->shash = crypto_alloc_shash(alg_base, 0,\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK);\n\t\tif (IS_ERR(bctx->shash)) {\n\t\t\tpr_err(\"omap-sham: base driver '%s' \"\n\t\t\t\t\t\"could not be loaded.\\n\", alg_base);\n\t\t\tcrypto_free_shash(tctx->fallback);\n\t\t\treturn PTR_ERR(bctx->shash);\n\t\t}\n\n\t}\n\n\treturn 0;\n}\n\nstatic int omap_sham_cra_init(struct crypto_tfm *tfm)\n{\n\treturn omap_sham_cra_init_alg(tfm, NULL);\n}\n\nstatic int omap_sham_cra_sha1_init(struct crypto_tfm *tfm)\n{\n\treturn omap_sham_cra_init_alg(tfm, \"sha1\");\n}\n\nstatic int omap_sham_cra_sha224_init(struct crypto_tfm *tfm)\n{\n\treturn omap_sham_cra_init_alg(tfm, \"sha224\");\n}\n\nstatic int omap_sham_cra_sha256_init(struct crypto_tfm *tfm)\n{\n\treturn omap_sham_cra_init_alg(tfm, \"sha256\");\n}\n\nstatic int omap_sham_cra_md5_init(struct crypto_tfm *tfm)\n{\n\treturn omap_sham_cra_init_alg(tfm, \"md5\");\n}\n\nstatic int omap_sham_cra_sha384_init(struct crypto_tfm *tfm)\n{\n\treturn omap_sham_cra_init_alg(tfm, \"sha384\");\n}\n\nstatic int omap_sham_cra_sha512_init(struct crypto_tfm *tfm)\n{\n\treturn omap_sham_cra_init_alg(tfm, \"sha512\");\n}\n\nstatic void omap_sham_cra_exit(struct crypto_tfm *tfm)\n{\n\tstruct omap_sham_ctx *tctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_free_shash(tctx->fallback);\n\ttctx->fallback = NULL;\n\n\tif (tctx->flags & BIT(FLAGS_HMAC)) {\n\t\tstruct omap_sham_hmac_ctx *bctx = tctx->base;\n\t\tcrypto_free_shash(bctx->shash);\n\t}\n}\n\nstatic int omap_sham_export(struct ahash_request *req, void *out)\n{\n\tstruct omap_sham_reqctx *rctx = ahash_request_ctx(req);\n\n\tmemcpy(out, rctx, sizeof(*rctx) + rctx->bufcnt);\n\n\treturn 0;\n}\n\nstatic int omap_sham_import(struct ahash_request *req, const void *in)\n{\n\tstruct omap_sham_reqctx *rctx = ahash_request_ctx(req);\n\tconst struct omap_sham_reqctx *ctx_in = in;\n\n\tmemcpy(rctx, in, sizeof(*rctx) + ctx_in->bufcnt);\n\n\treturn 0;\n}\n\nstatic struct ahash_engine_alg algs_sha1_md5[] = {\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.halg.digestsize\t= SHA1_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"sha1\",\n\t\t.cra_driver_name\t= \"omap-sha1\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.halg.digestsize\t= MD5_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"md5\",\n\t\t.cra_driver_name\t= \"omap-md5\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.setkey\t\t= omap_sham_setkey,\n\t.base.halg.digestsize\t= SHA1_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"hmac(sha1)\",\n\t\t.cra_driver_name\t= \"omap-hmac-sha1\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx) +\n\t\t\t\t\tsizeof(struct omap_sham_hmac_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_sha1_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.setkey\t\t= omap_sham_setkey,\n\t.base.halg.digestsize\t= MD5_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"hmac(md5)\",\n\t\t.cra_driver_name\t= \"omap-hmac-md5\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx) +\n\t\t\t\t\tsizeof(struct omap_sham_hmac_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_md5_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n}\n};\n\n \nstatic struct ahash_engine_alg algs_sha224_sha256[] = {\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.halg.digestsize\t= SHA224_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"sha224\",\n\t\t.cra_driver_name\t= \"omap-sha224\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA224_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.halg.digestsize\t= SHA256_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"sha256\",\n\t\t.cra_driver_name\t= \"omap-sha256\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA256_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.setkey\t\t= omap_sham_setkey,\n\t.base.halg.digestsize\t= SHA224_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"hmac(sha224)\",\n\t\t.cra_driver_name\t= \"omap-hmac-sha224\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA224_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx) +\n\t\t\t\t\tsizeof(struct omap_sham_hmac_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_sha224_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.setkey\t\t= omap_sham_setkey,\n\t.base.halg.digestsize\t= SHA256_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"hmac(sha256)\",\n\t\t.cra_driver_name\t= \"omap-hmac-sha256\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA256_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx) +\n\t\t\t\t\tsizeof(struct omap_sham_hmac_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_sha256_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n};\n\nstatic struct ahash_engine_alg algs_sha384_sha512[] = {\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.halg.digestsize\t= SHA384_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"sha384\",\n\t\t.cra_driver_name\t= \"omap-sha384\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA384_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.halg.digestsize\t= SHA512_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"sha512\",\n\t\t.cra_driver_name\t= \"omap-sha512\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA512_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.setkey\t\t= omap_sham_setkey,\n\t.base.halg.digestsize\t= SHA384_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"hmac(sha384)\",\n\t\t.cra_driver_name\t= \"omap-hmac-sha384\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA384_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx) +\n\t\t\t\t\tsizeof(struct omap_sham_hmac_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_sha384_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n{\n\t.base.init\t\t= omap_sham_init,\n\t.base.update\t\t= omap_sham_update,\n\t.base.final\t\t= omap_sham_final,\n\t.base.finup\t\t= omap_sham_finup,\n\t.base.digest\t\t= omap_sham_digest,\n\t.base.setkey\t\t= omap_sham_setkey,\n\t.base.halg.digestsize\t= SHA512_DIGEST_SIZE,\n\t.base.halg.base\t= {\n\t\t.cra_name\t\t= \"hmac(sha512)\",\n\t\t.cra_driver_name\t= \"omap-hmac-sha512\",\n\t\t.cra_priority\t\t= 400,\n\t\t.cra_flags\t\t= CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t\tCRYPTO_ALG_ASYNC |\n\t\t\t\t\t\tCRYPTO_ALG_NEED_FALLBACK,\n\t\t.cra_blocksize\t\t= SHA512_BLOCK_SIZE,\n\t\t.cra_ctxsize\t\t= sizeof(struct omap_sham_ctx) +\n\t\t\t\t\tsizeof(struct omap_sham_hmac_ctx),\n\t\t.cra_alignmask\t\t= OMAP_ALIGN_MASK,\n\t\t.cra_module\t\t= THIS_MODULE,\n\t\t.cra_init\t\t= omap_sham_cra_sha512_init,\n\t\t.cra_exit\t\t= omap_sham_cra_exit,\n\t},\n\t.op.do_one_request = omap_sham_hash_one_req,\n},\n};\n\nstatic void omap_sham_done_task(unsigned long data)\n{\n\tstruct omap_sham_dev *dd = (struct omap_sham_dev *)data;\n\tint err = 0;\n\n\tdev_dbg(dd->dev, \"%s: flags=%lx\\n\", __func__, dd->flags);\n\n\tif (test_bit(FLAGS_CPU, &dd->flags)) {\n\t\tif (test_and_clear_bit(FLAGS_OUTPUT_READY, &dd->flags))\n\t\t\tgoto finish;\n\t} else if (test_bit(FLAGS_DMA_READY, &dd->flags)) {\n\t\tif (test_bit(FLAGS_DMA_ACTIVE, &dd->flags)) {\n\t\t\tomap_sham_update_dma_stop(dd);\n\t\t\tif (dd->err) {\n\t\t\t\terr = dd->err;\n\t\t\t\tgoto finish;\n\t\t\t}\n\t\t}\n\t\tif (test_and_clear_bit(FLAGS_OUTPUT_READY, &dd->flags)) {\n\t\t\t \n\t\t\tclear_bit(FLAGS_DMA_READY, &dd->flags);\n\t\t\tgoto finish;\n\t\t}\n\t}\n\n\treturn;\n\nfinish:\n\tdev_dbg(dd->dev, \"update done: err: %d\\n\", err);\n\t \n\tomap_sham_finish_req(dd->req, err);\n}\n\nstatic irqreturn_t omap_sham_irq_common(struct omap_sham_dev *dd)\n{\n\tset_bit(FLAGS_OUTPUT_READY, &dd->flags);\n\ttasklet_schedule(&dd->done_task);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t omap_sham_irq_omap2(int irq, void *dev_id)\n{\n\tstruct omap_sham_dev *dd = dev_id;\n\n\tif (unlikely(test_bit(FLAGS_FINAL, &dd->flags)))\n\t\t \n\t\tomap_sham_write_mask(dd, SHA_REG_CTRL, 0, SHA_REG_CTRL_LENGTH);\n\n\tomap_sham_write_mask(dd, SHA_REG_CTRL, SHA_REG_CTRL_OUTPUT_READY,\n\t\t\t\t SHA_REG_CTRL_OUTPUT_READY);\n\tomap_sham_read(dd, SHA_REG_CTRL);\n\n\treturn omap_sham_irq_common(dd);\n}\n\nstatic irqreturn_t omap_sham_irq_omap4(int irq, void *dev_id)\n{\n\tstruct omap_sham_dev *dd = dev_id;\n\n\tomap_sham_write_mask(dd, SHA_REG_MASK(dd), 0, SHA_REG_MASK_IT_EN);\n\n\treturn omap_sham_irq_common(dd);\n}\n\nstatic struct omap_sham_algs_info omap_sham_algs_info_omap2[] = {\n\t{\n\t\t.algs_list\t= algs_sha1_md5,\n\t\t.size\t\t= ARRAY_SIZE(algs_sha1_md5),\n\t},\n};\n\nstatic const struct omap_sham_pdata omap_sham_pdata_omap2 = {\n\t.algs_info\t= omap_sham_algs_info_omap2,\n\t.algs_info_size\t= ARRAY_SIZE(omap_sham_algs_info_omap2),\n\t.flags\t\t= BIT(FLAGS_BE32_SHA1),\n\t.digest_size\t= SHA1_DIGEST_SIZE,\n\t.copy_hash\t= omap_sham_copy_hash_omap2,\n\t.write_ctrl\t= omap_sham_write_ctrl_omap2,\n\t.trigger\t= omap_sham_trigger_omap2,\n\t.poll_irq\t= omap_sham_poll_irq_omap2,\n\t.intr_hdlr\t= omap_sham_irq_omap2,\n\t.idigest_ofs\t= 0x00,\n\t.din_ofs\t= 0x1c,\n\t.digcnt_ofs\t= 0x14,\n\t.rev_ofs\t= 0x5c,\n\t.mask_ofs\t= 0x60,\n\t.sysstatus_ofs\t= 0x64,\n\t.major_mask\t= 0xf0,\n\t.major_shift\t= 4,\n\t.minor_mask\t= 0x0f,\n\t.minor_shift\t= 0,\n};\n\n#ifdef CONFIG_OF\nstatic struct omap_sham_algs_info omap_sham_algs_info_omap4[] = {\n\t{\n\t\t.algs_list\t= algs_sha1_md5,\n\t\t.size\t\t= ARRAY_SIZE(algs_sha1_md5),\n\t},\n\t{\n\t\t.algs_list\t= algs_sha224_sha256,\n\t\t.size\t\t= ARRAY_SIZE(algs_sha224_sha256),\n\t},\n};\n\nstatic const struct omap_sham_pdata omap_sham_pdata_omap4 = {\n\t.algs_info\t= omap_sham_algs_info_omap4,\n\t.algs_info_size\t= ARRAY_SIZE(omap_sham_algs_info_omap4),\n\t.flags\t\t= BIT(FLAGS_AUTO_XOR),\n\t.digest_size\t= SHA256_DIGEST_SIZE,\n\t.copy_hash\t= omap_sham_copy_hash_omap4,\n\t.write_ctrl\t= omap_sham_write_ctrl_omap4,\n\t.trigger\t= omap_sham_trigger_omap4,\n\t.poll_irq\t= omap_sham_poll_irq_omap4,\n\t.intr_hdlr\t= omap_sham_irq_omap4,\n\t.idigest_ofs\t= 0x020,\n\t.odigest_ofs\t= 0x0,\n\t.din_ofs\t= 0x080,\n\t.digcnt_ofs\t= 0x040,\n\t.rev_ofs\t= 0x100,\n\t.mask_ofs\t= 0x110,\n\t.sysstatus_ofs\t= 0x114,\n\t.mode_ofs\t= 0x44,\n\t.length_ofs\t= 0x48,\n\t.major_mask\t= 0x0700,\n\t.major_shift\t= 8,\n\t.minor_mask\t= 0x003f,\n\t.minor_shift\t= 0,\n};\n\nstatic struct omap_sham_algs_info omap_sham_algs_info_omap5[] = {\n\t{\n\t\t.algs_list\t= algs_sha1_md5,\n\t\t.size\t\t= ARRAY_SIZE(algs_sha1_md5),\n\t},\n\t{\n\t\t.algs_list\t= algs_sha224_sha256,\n\t\t.size\t\t= ARRAY_SIZE(algs_sha224_sha256),\n\t},\n\t{\n\t\t.algs_list\t= algs_sha384_sha512,\n\t\t.size\t\t= ARRAY_SIZE(algs_sha384_sha512),\n\t},\n};\n\nstatic const struct omap_sham_pdata omap_sham_pdata_omap5 = {\n\t.algs_info\t= omap_sham_algs_info_omap5,\n\t.algs_info_size\t= ARRAY_SIZE(omap_sham_algs_info_omap5),\n\t.flags\t\t= BIT(FLAGS_AUTO_XOR),\n\t.digest_size\t= SHA512_DIGEST_SIZE,\n\t.copy_hash\t= omap_sham_copy_hash_omap4,\n\t.write_ctrl\t= omap_sham_write_ctrl_omap4,\n\t.trigger\t= omap_sham_trigger_omap4,\n\t.poll_irq\t= omap_sham_poll_irq_omap4,\n\t.intr_hdlr\t= omap_sham_irq_omap4,\n\t.idigest_ofs\t= 0x240,\n\t.odigest_ofs\t= 0x200,\n\t.din_ofs\t= 0x080,\n\t.digcnt_ofs\t= 0x280,\n\t.rev_ofs\t= 0x100,\n\t.mask_ofs\t= 0x110,\n\t.sysstatus_ofs\t= 0x114,\n\t.mode_ofs\t= 0x284,\n\t.length_ofs\t= 0x288,\n\t.major_mask\t= 0x0700,\n\t.major_shift\t= 8,\n\t.minor_mask\t= 0x003f,\n\t.minor_shift\t= 0,\n};\n\nstatic const struct of_device_id omap_sham_of_match[] = {\n\t{\n\t\t.compatible\t= \"ti,omap2-sham\",\n\t\t.data\t\t= &omap_sham_pdata_omap2,\n\t},\n\t{\n\t\t.compatible\t= \"ti,omap3-sham\",\n\t\t.data\t\t= &omap_sham_pdata_omap2,\n\t},\n\t{\n\t\t.compatible\t= \"ti,omap4-sham\",\n\t\t.data\t\t= &omap_sham_pdata_omap4,\n\t},\n\t{\n\t\t.compatible\t= \"ti,omap5-sham\",\n\t\t.data\t\t= &omap_sham_pdata_omap5,\n\t},\n\t{},\n};\nMODULE_DEVICE_TABLE(of, omap_sham_of_match);\n\nstatic int omap_sham_get_res_of(struct omap_sham_dev *dd,\n\t\tstruct device *dev, struct resource *res)\n{\n\tstruct device_node *node = dev->of_node;\n\tint err = 0;\n\n\tdd->pdata = of_device_get_match_data(dev);\n\tif (!dd->pdata) {\n\t\tdev_err(dev, \"no compatible OF match\\n\");\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\terr = of_address_to_resource(node, 0, res);\n\tif (err < 0) {\n\t\tdev_err(dev, \"can't translate OF node address\\n\");\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tdd->irq = irq_of_parse_and_map(node, 0);\n\tif (!dd->irq) {\n\t\tdev_err(dev, \"can't translate OF irq value\\n\");\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\nerr:\n\treturn err;\n}\n#else\nstatic const struct of_device_id omap_sham_of_match[] = {\n\t{},\n};\n\nstatic int omap_sham_get_res_of(struct omap_sham_dev *dd,\n\t\tstruct device *dev, struct resource *res)\n{\n\treturn -EINVAL;\n}\n#endif\n\nstatic int omap_sham_get_res_pdev(struct omap_sham_dev *dd,\n\t\tstruct platform_device *pdev, struct resource *res)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct resource *r;\n\tint err = 0;\n\n\t \n\tr = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!r) {\n\t\tdev_err(dev, \"no MEM resource info\\n\");\n\t\terr = -ENODEV;\n\t\tgoto err;\n\t}\n\tmemcpy(res, r, sizeof(*res));\n\n\t \n\tdd->irq = platform_get_irq(pdev, 0);\n\tif (dd->irq < 0) {\n\t\terr = dd->irq;\n\t\tgoto err;\n\t}\n\n\t \n\tdd->pdata = &omap_sham_pdata_omap2;\n\nerr:\n\treturn err;\n}\n\nstatic ssize_t fallback_show(struct device *dev, struct device_attribute *attr,\n\t\t\t     char *buf)\n{\n\tstruct omap_sham_dev *dd = dev_get_drvdata(dev);\n\n\treturn sprintf(buf, \"%d\\n\", dd->fallback_sz);\n}\n\nstatic ssize_t fallback_store(struct device *dev, struct device_attribute *attr,\n\t\t\t      const char *buf, size_t size)\n{\n\tstruct omap_sham_dev *dd = dev_get_drvdata(dev);\n\tssize_t status;\n\tlong value;\n\n\tstatus = kstrtol(buf, 0, &value);\n\tif (status)\n\t\treturn status;\n\n\t \n\tif (value < 9) {\n\t\tdev_err(dev, \"minimum fallback size 9\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdd->fallback_sz = value;\n\n\treturn size;\n}\n\nstatic ssize_t queue_len_show(struct device *dev, struct device_attribute *attr,\n\t\t\t      char *buf)\n{\n\tstruct omap_sham_dev *dd = dev_get_drvdata(dev);\n\n\treturn sprintf(buf, \"%d\\n\", dd->queue.max_qlen);\n}\n\nstatic ssize_t queue_len_store(struct device *dev,\n\t\t\t       struct device_attribute *attr, const char *buf,\n\t\t\t       size_t size)\n{\n\tstruct omap_sham_dev *dd = dev_get_drvdata(dev);\n\tssize_t status;\n\tlong value;\n\n\tstatus = kstrtol(buf, 0, &value);\n\tif (status)\n\t\treturn status;\n\n\tif (value < 1)\n\t\treturn -EINVAL;\n\n\t \n\tdd->queue.max_qlen = value;\n\n\treturn size;\n}\n\nstatic DEVICE_ATTR_RW(queue_len);\nstatic DEVICE_ATTR_RW(fallback);\n\nstatic struct attribute *omap_sham_attrs[] = {\n\t&dev_attr_queue_len.attr,\n\t&dev_attr_fallback.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group omap_sham_attr_group = {\n\t.attrs = omap_sham_attrs,\n};\n\nstatic int omap_sham_probe(struct platform_device *pdev)\n{\n\tstruct omap_sham_dev *dd;\n\tstruct device *dev = &pdev->dev;\n\tstruct resource res;\n\tdma_cap_mask_t mask;\n\tint err, i, j;\n\tu32 rev;\n\n\tdd = devm_kzalloc(dev, sizeof(struct omap_sham_dev), GFP_KERNEL);\n\tif (dd == NULL) {\n\t\tdev_err(dev, \"unable to alloc data struct.\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto data_err;\n\t}\n\tdd->dev = dev;\n\tplatform_set_drvdata(pdev, dd);\n\n\tINIT_LIST_HEAD(&dd->list);\n\ttasklet_init(&dd->done_task, omap_sham_done_task, (unsigned long)dd);\n\tcrypto_init_queue(&dd->queue, OMAP_SHAM_QUEUE_LENGTH);\n\n\terr = (dev->of_node) ? omap_sham_get_res_of(dd, dev, &res) :\n\t\t\t       omap_sham_get_res_pdev(dd, pdev, &res);\n\tif (err)\n\t\tgoto data_err;\n\n\tdd->io_base = devm_ioremap_resource(dev, &res);\n\tif (IS_ERR(dd->io_base)) {\n\t\terr = PTR_ERR(dd->io_base);\n\t\tgoto data_err;\n\t}\n\tdd->phys_base = res.start;\n\n\terr = devm_request_irq(dev, dd->irq, dd->pdata->intr_hdlr,\n\t\t\t       IRQF_TRIGGER_NONE, dev_name(dev), dd);\n\tif (err) {\n\t\tdev_err(dev, \"unable to request irq %d, err = %d\\n\",\n\t\t\tdd->irq, err);\n\t\tgoto data_err;\n\t}\n\n\tdma_cap_zero(mask);\n\tdma_cap_set(DMA_SLAVE, mask);\n\n\tdd->dma_lch = dma_request_chan(dev, \"rx\");\n\tif (IS_ERR(dd->dma_lch)) {\n\t\terr = PTR_ERR(dd->dma_lch);\n\t\tif (err == -EPROBE_DEFER)\n\t\t\tgoto data_err;\n\n\t\tdd->polling_mode = 1;\n\t\tdev_dbg(dev, \"using polling mode instead of dma\\n\");\n\t}\n\n\tdd->flags |= dd->pdata->flags;\n\tsham.flags |= dd->pdata->flags;\n\n\tpm_runtime_use_autosuspend(dev);\n\tpm_runtime_set_autosuspend_delay(dev, DEFAULT_AUTOSUSPEND_DELAY);\n\n\tdd->fallback_sz = OMAP_SHA_DMA_THRESHOLD;\n\n\tpm_runtime_enable(dev);\n\n\terr = pm_runtime_resume_and_get(dev);\n\tif (err < 0) {\n\t\tdev_err(dev, \"failed to get sync: %d\\n\", err);\n\t\tgoto err_pm;\n\t}\n\n\trev = omap_sham_read(dd, SHA_REG_REV(dd));\n\tpm_runtime_put_sync(&pdev->dev);\n\n\tdev_info(dev, \"hw accel on OMAP rev %u.%u\\n\",\n\t\t(rev & dd->pdata->major_mask) >> dd->pdata->major_shift,\n\t\t(rev & dd->pdata->minor_mask) >> dd->pdata->minor_shift);\n\n\tspin_lock_bh(&sham.lock);\n\tlist_add_tail(&dd->list, &sham.dev_list);\n\tspin_unlock_bh(&sham.lock);\n\n\tdd->engine = crypto_engine_alloc_init(dev, 1);\n\tif (!dd->engine) {\n\t\terr = -ENOMEM;\n\t\tgoto err_engine;\n\t}\n\n\terr = crypto_engine_start(dd->engine);\n\tif (err)\n\t\tgoto err_engine_start;\n\n\tfor (i = 0; i < dd->pdata->algs_info_size; i++) {\n\t\tif (dd->pdata->algs_info[i].registered)\n\t\t\tbreak;\n\n\t\tfor (j = 0; j < dd->pdata->algs_info[i].size; j++) {\n\t\t\tstruct ahash_engine_alg *ealg;\n\t\t\tstruct ahash_alg *alg;\n\n\t\t\tealg = &dd->pdata->algs_info[i].algs_list[j];\n\t\t\talg = &ealg->base;\n\t\t\talg->export = omap_sham_export;\n\t\t\talg->import = omap_sham_import;\n\t\t\talg->halg.statesize = sizeof(struct omap_sham_reqctx) +\n\t\t\t\t\t      BUFLEN;\n\t\t\terr = crypto_engine_register_ahash(ealg);\n\t\t\tif (err)\n\t\t\t\tgoto err_algs;\n\n\t\t\tdd->pdata->algs_info[i].registered++;\n\t\t}\n\t}\n\n\terr = sysfs_create_group(&dev->kobj, &omap_sham_attr_group);\n\tif (err) {\n\t\tdev_err(dev, \"could not create sysfs device attrs\\n\");\n\t\tgoto err_algs;\n\t}\n\n\treturn 0;\n\nerr_algs:\n\tfor (i = dd->pdata->algs_info_size - 1; i >= 0; i--)\n\t\tfor (j = dd->pdata->algs_info[i].registered - 1; j >= 0; j--)\n\t\t\tcrypto_engine_unregister_ahash(\n\t\t\t\t\t&dd->pdata->algs_info[i].algs_list[j]);\nerr_engine_start:\n\tcrypto_engine_exit(dd->engine);\nerr_engine:\n\tspin_lock_bh(&sham.lock);\n\tlist_del(&dd->list);\n\tspin_unlock_bh(&sham.lock);\nerr_pm:\n\tpm_runtime_dont_use_autosuspend(dev);\n\tpm_runtime_disable(dev);\n\tif (!dd->polling_mode)\n\t\tdma_release_channel(dd->dma_lch);\ndata_err:\n\tdev_err(dev, \"initialization failed.\\n\");\n\n\treturn err;\n}\n\nstatic int omap_sham_remove(struct platform_device *pdev)\n{\n\tstruct omap_sham_dev *dd;\n\tint i, j;\n\n\tdd = platform_get_drvdata(pdev);\n\n\tspin_lock_bh(&sham.lock);\n\tlist_del(&dd->list);\n\tspin_unlock_bh(&sham.lock);\n\tfor (i = dd->pdata->algs_info_size - 1; i >= 0; i--)\n\t\tfor (j = dd->pdata->algs_info[i].registered - 1; j >= 0; j--) {\n\t\t\tcrypto_engine_unregister_ahash(\n\t\t\t\t\t&dd->pdata->algs_info[i].algs_list[j]);\n\t\t\tdd->pdata->algs_info[i].registered--;\n\t\t}\n\ttasklet_kill(&dd->done_task);\n\tpm_runtime_dont_use_autosuspend(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\n\tif (!dd->polling_mode)\n\t\tdma_release_channel(dd->dma_lch);\n\n\tsysfs_remove_group(&dd->dev->kobj, &omap_sham_attr_group);\n\n\treturn 0;\n}\n\nstatic struct platform_driver omap_sham_driver = {\n\t.probe\t= omap_sham_probe,\n\t.remove\t= omap_sham_remove,\n\t.driver\t= {\n\t\t.name\t= \"omap-sham\",\n\t\t.of_match_table\t= omap_sham_of_match,\n\t},\n};\n\nmodule_platform_driver(omap_sham_driver);\n\nMODULE_DESCRIPTION(\"OMAP SHA1/MD5 hw acceleration support.\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Dmitry Kasatkin\");\nMODULE_ALIAS(\"platform:omap-sham\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}