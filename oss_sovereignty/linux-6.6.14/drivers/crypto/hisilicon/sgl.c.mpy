{
  "module_name": "sgl.c",
  "hash_id": "589ddf926d4789bea89e028ef222572a452b8f8366edc856bc4f4e739b8a77fd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/hisilicon/sgl.c",
  "human_readable_source": "\n \n#include <linux/align.h>\n#include <linux/dma-mapping.h>\n#include <linux/hisi_acc_qm.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n\n#define HISI_ACC_SGL_SGE_NR_MIN\t\t1\n#define HISI_ACC_SGL_NR_MAX\t\t256\n#define HISI_ACC_SGL_ALIGN_SIZE\t\t64\n#define HISI_ACC_MEM_BLOCK_NR\t\t5\n\nstruct acc_hw_sge {\n\tdma_addr_t buf;\n\tvoid *page_ctrl;\n\t__le32 len;\n\t__le32 pad;\n\t__le32 pad0;\n\t__le32 pad1;\n};\n\n \nstruct hisi_acc_hw_sgl {\n\tdma_addr_t next_dma;\n\t__le16 entry_sum_in_chain;\n\t__le16 entry_sum_in_sgl;\n\t__le16 entry_length_in_sgl;\n\t__le16 pad0;\n\t__le64 pad1[5];\n\tstruct hisi_acc_hw_sgl *next;\n\tstruct acc_hw_sge sge_entries[];\n} __aligned(1);\n\nstruct hisi_acc_sgl_pool {\n\tstruct mem_block {\n\t\tstruct hisi_acc_hw_sgl *sgl;\n\t\tdma_addr_t sgl_dma;\n\t\tsize_t size;\n\t} mem_block[HISI_ACC_MEM_BLOCK_NR];\n\tu32 sgl_num_per_block;\n\tu32 block_num;\n\tu32 count;\n\tu32 sge_nr;\n\tsize_t sgl_size;\n};\n\n \nstruct hisi_acc_sgl_pool *hisi_acc_create_sgl_pool(struct device *dev,\n\t\t\t\t\t\t   u32 count, u32 sge_nr)\n{\n\tu32 sgl_size, block_size, sgl_num_per_block, block_num, remain_sgl;\n\tstruct hisi_acc_sgl_pool *pool;\n\tstruct mem_block *block;\n\tu32 i, j;\n\n\tif (!dev || !count || !sge_nr || sge_nr > HISI_ACC_SGL_SGE_NR_MAX)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tsgl_size = ALIGN(sizeof(struct acc_hw_sge) * sge_nr +\n\t\t\t sizeof(struct hisi_acc_hw_sgl),\n\t\t\t HISI_ACC_SGL_ALIGN_SIZE);\n\n\t \n\tblock_size = 1 << (PAGE_SHIFT + MAX_ORDER < 32 ?\n\t\t\t   PAGE_SHIFT + MAX_ORDER : 31);\n\tsgl_num_per_block = block_size / sgl_size;\n\tblock_num = count / sgl_num_per_block;\n\tremain_sgl = count % sgl_num_per_block;\n\n\tif ((!remain_sgl && block_num > HISI_ACC_MEM_BLOCK_NR) ||\n\t    (remain_sgl > 0 && block_num > HISI_ACC_MEM_BLOCK_NR - 1))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tpool = kzalloc(sizeof(*pool), GFP_KERNEL);\n\tif (!pool)\n\t\treturn ERR_PTR(-ENOMEM);\n\tblock = pool->mem_block;\n\n\tfor (i = 0; i < block_num; i++) {\n\t\tblock[i].sgl = dma_alloc_coherent(dev, block_size,\n\t\t\t\t\t\t  &block[i].sgl_dma,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!block[i].sgl) {\n\t\t\tdev_err(dev, \"Fail to allocate hw SG buffer!\\n\");\n\t\t\tgoto err_free_mem;\n\t\t}\n\n\t\tblock[i].size = block_size;\n\t}\n\n\tif (remain_sgl > 0) {\n\t\tblock[i].sgl = dma_alloc_coherent(dev, remain_sgl * sgl_size,\n\t\t\t\t\t\t  &block[i].sgl_dma,\n\t\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!block[i].sgl) {\n\t\t\tdev_err(dev, \"Fail to allocate remained hw SG buffer!\\n\");\n\t\t\tgoto err_free_mem;\n\t\t}\n\n\t\tblock[i].size = remain_sgl * sgl_size;\n\t}\n\n\tpool->sgl_num_per_block = sgl_num_per_block;\n\tpool->block_num = remain_sgl ? block_num + 1 : block_num;\n\tpool->count = count;\n\tpool->sgl_size = sgl_size;\n\tpool->sge_nr = sge_nr;\n\n\treturn pool;\n\nerr_free_mem:\n\tfor (j = 0; j < i; j++) {\n\t\tdma_free_coherent(dev, block_size, block[j].sgl,\n\t\t\t\t  block[j].sgl_dma);\n\t}\n\tkfree_sensitive(pool);\n\treturn ERR_PTR(-ENOMEM);\n}\nEXPORT_SYMBOL_GPL(hisi_acc_create_sgl_pool);\n\n \nvoid hisi_acc_free_sgl_pool(struct device *dev, struct hisi_acc_sgl_pool *pool)\n{\n\tstruct mem_block *block;\n\tint i;\n\n\tif (!dev || !pool)\n\t\treturn;\n\n\tblock = pool->mem_block;\n\n\tfor (i = 0; i < pool->block_num; i++)\n\t\tdma_free_coherent(dev, block[i].size, block[i].sgl,\n\t\t\t\t  block[i].sgl_dma);\n\n\tkfree(pool);\n}\nEXPORT_SYMBOL_GPL(hisi_acc_free_sgl_pool);\n\nstatic struct hisi_acc_hw_sgl *acc_get_sgl(struct hisi_acc_sgl_pool *pool,\n\t\t\t\t\t   u32 index, dma_addr_t *hw_sgl_dma)\n{\n\tstruct mem_block *block;\n\tu32 block_index, offset;\n\n\tif (!pool || !hw_sgl_dma || index >= pool->count)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tblock = pool->mem_block;\n\tblock_index = index / pool->sgl_num_per_block;\n\toffset = index % pool->sgl_num_per_block;\n\n\t*hw_sgl_dma = block[block_index].sgl_dma + pool->sgl_size * offset;\n\treturn (void *)block[block_index].sgl + pool->sgl_size * offset;\n}\n\nstatic void sg_map_to_hw_sg(struct scatterlist *sgl,\n\t\t\t    struct acc_hw_sge *hw_sge)\n{\n\thw_sge->buf = sg_dma_address(sgl);\n\thw_sge->len = cpu_to_le32(sg_dma_len(sgl));\n\thw_sge->page_ctrl = sg_virt(sgl);\n}\n\nstatic void inc_hw_sgl_sge(struct hisi_acc_hw_sgl *hw_sgl)\n{\n\tu16 var = le16_to_cpu(hw_sgl->entry_sum_in_sgl);\n\n\tvar++;\n\thw_sgl->entry_sum_in_sgl = cpu_to_le16(var);\n}\n\nstatic void update_hw_sgl_sum_sge(struct hisi_acc_hw_sgl *hw_sgl, u16 sum)\n{\n\thw_sgl->entry_sum_in_chain = cpu_to_le16(sum);\n}\n\nstatic void clear_hw_sgl_sge(struct hisi_acc_hw_sgl *hw_sgl)\n{\n\tstruct acc_hw_sge *hw_sge = hw_sgl->sge_entries;\n\tint i;\n\n\tfor (i = 0; i < le16_to_cpu(hw_sgl->entry_sum_in_sgl); i++) {\n\t\thw_sge[i].page_ctrl = NULL;\n\t\thw_sge[i].buf = 0;\n\t\thw_sge[i].len = 0;\n\t}\n}\n\n \nstruct hisi_acc_hw_sgl *\nhisi_acc_sg_buf_map_to_hw_sgl(struct device *dev,\n\t\t\t      struct scatterlist *sgl,\n\t\t\t      struct hisi_acc_sgl_pool *pool,\n\t\t\t      u32 index, dma_addr_t *hw_sgl_dma)\n{\n\tstruct hisi_acc_hw_sgl *curr_hw_sgl;\n\tdma_addr_t curr_sgl_dma = 0;\n\tstruct acc_hw_sge *curr_hw_sge;\n\tstruct scatterlist *sg;\n\tint i, sg_n, sg_n_mapped;\n\n\tif (!dev || !sgl || !pool || !hw_sgl_dma)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tsg_n = sg_nents(sgl);\n\n\tsg_n_mapped = dma_map_sg(dev, sgl, sg_n, DMA_BIDIRECTIONAL);\n\tif (!sg_n_mapped) {\n\t\tdev_err(dev, \"DMA mapping for SG error!\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (sg_n_mapped > pool->sge_nr) {\n\t\tdev_err(dev, \"the number of entries in input scatterlist is bigger than SGL pool setting.\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tcurr_hw_sgl = acc_get_sgl(pool, index, &curr_sgl_dma);\n\tif (IS_ERR(curr_hw_sgl)) {\n\t\tdev_err(dev, \"Get SGL error!\\n\");\n\t\tdma_unmap_sg(dev, sgl, sg_n, DMA_BIDIRECTIONAL);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tcurr_hw_sgl->entry_length_in_sgl = cpu_to_le16(pool->sge_nr);\n\tcurr_hw_sge = curr_hw_sgl->sge_entries;\n\n\tfor_each_sg(sgl, sg, sg_n_mapped, i) {\n\t\tsg_map_to_hw_sg(sg, curr_hw_sge);\n\t\tinc_hw_sgl_sge(curr_hw_sgl);\n\t\tcurr_hw_sge++;\n\t}\n\n\tupdate_hw_sgl_sum_sge(curr_hw_sgl, pool->sge_nr);\n\t*hw_sgl_dma = curr_sgl_dma;\n\n\treturn curr_hw_sgl;\n}\nEXPORT_SYMBOL_GPL(hisi_acc_sg_buf_map_to_hw_sgl);\n\n \nvoid hisi_acc_sg_buf_unmap(struct device *dev, struct scatterlist *sgl,\n\t\t\t   struct hisi_acc_hw_sgl *hw_sgl)\n{\n\tif (!dev || !sgl || !hw_sgl)\n\t\treturn;\n\n\tdma_unmap_sg(dev, sgl, sg_nents(sgl), DMA_BIDIRECTIONAL);\n\tclear_hw_sgl_sge(hw_sgl);\n\thw_sgl->entry_sum_in_chain = 0;\n\thw_sgl->entry_sum_in_sgl = 0;\n\thw_sgl->entry_length_in_sgl = 0;\n}\nEXPORT_SYMBOL_GPL(hisi_acc_sg_buf_unmap);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}