{
  "module_name": "sec_algs.c",
  "hash_id": "9326ef752274a9c909580584daee0281630a09a083aeb6232b68c13bc7a3a56e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/hisilicon/sec/sec_algs.c",
  "human_readable_source": "\n \n#include <linux/crypto.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n\n#include <crypto/aes.h>\n#include <crypto/algapi.h>\n#include <crypto/internal/des.h>\n#include <crypto/skcipher.h>\n#include <crypto/xts.h>\n#include <crypto/internal/skcipher.h>\n\n#include \"sec_drv.h\"\n\n#define SEC_MAX_CIPHER_KEY\t\t64\n#define SEC_REQ_LIMIT SZ_32M\n\nstruct sec_c_alg_cfg {\n\tunsigned c_alg\t\t: 3;\n\tunsigned c_mode\t\t: 3;\n\tunsigned key_len\t: 2;\n\tunsigned c_width\t: 2;\n};\n\nstatic const struct sec_c_alg_cfg sec_c_alg_cfgs[] =  {\n\t[SEC_C_DES_ECB_64] = {\n\t\t.c_alg = SEC_C_ALG_DES,\n\t\t.c_mode = SEC_C_MODE_ECB,\n\t\t.key_len = SEC_KEY_LEN_DES,\n\t},\n\t[SEC_C_DES_CBC_64] = {\n\t\t.c_alg = SEC_C_ALG_DES,\n\t\t.c_mode = SEC_C_MODE_CBC,\n\t\t.key_len = SEC_KEY_LEN_DES,\n\t},\n\t[SEC_C_3DES_ECB_192_3KEY] = {\n\t\t.c_alg = SEC_C_ALG_3DES,\n\t\t.c_mode = SEC_C_MODE_ECB,\n\t\t.key_len = SEC_KEY_LEN_3DES_3_KEY,\n\t},\n\t[SEC_C_3DES_ECB_192_2KEY] = {\n\t\t.c_alg = SEC_C_ALG_3DES,\n\t\t.c_mode = SEC_C_MODE_ECB,\n\t\t.key_len = SEC_KEY_LEN_3DES_2_KEY,\n\t},\n\t[SEC_C_3DES_CBC_192_3KEY] = {\n\t\t.c_alg = SEC_C_ALG_3DES,\n\t\t.c_mode = SEC_C_MODE_CBC,\n\t\t.key_len = SEC_KEY_LEN_3DES_3_KEY,\n\t},\n\t[SEC_C_3DES_CBC_192_2KEY] = {\n\t\t.c_alg = SEC_C_ALG_3DES,\n\t\t.c_mode = SEC_C_MODE_CBC,\n\t\t.key_len = SEC_KEY_LEN_3DES_2_KEY,\n\t},\n\t[SEC_C_AES_ECB_128] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_ECB,\n\t\t.key_len = SEC_KEY_LEN_AES_128,\n\t},\n\t[SEC_C_AES_ECB_192] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_ECB,\n\t\t.key_len = SEC_KEY_LEN_AES_192,\n\t},\n\t[SEC_C_AES_ECB_256] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_ECB,\n\t\t.key_len = SEC_KEY_LEN_AES_256,\n\t},\n\t[SEC_C_AES_CBC_128] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_CBC,\n\t\t.key_len = SEC_KEY_LEN_AES_128,\n\t},\n\t[SEC_C_AES_CBC_192] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_CBC,\n\t\t.key_len = SEC_KEY_LEN_AES_192,\n\t},\n\t[SEC_C_AES_CBC_256] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_CBC,\n\t\t.key_len = SEC_KEY_LEN_AES_256,\n\t},\n\t[SEC_C_AES_CTR_128] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_CTR,\n\t\t.key_len = SEC_KEY_LEN_AES_128,\n\t},\n\t[SEC_C_AES_CTR_192] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_CTR,\n\t\t.key_len = SEC_KEY_LEN_AES_192,\n\t},\n\t[SEC_C_AES_CTR_256] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_CTR,\n\t\t.key_len = SEC_KEY_LEN_AES_256,\n\t},\n\t[SEC_C_AES_XTS_128] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_XTS,\n\t\t.key_len = SEC_KEY_LEN_AES_128,\n\t},\n\t[SEC_C_AES_XTS_256] = {\n\t\t.c_alg = SEC_C_ALG_AES,\n\t\t.c_mode = SEC_C_MODE_XTS,\n\t\t.key_len = SEC_KEY_LEN_AES_256,\n\t},\n\t[SEC_C_NULL] = {\n\t},\n};\n\n \nstatic DEFINE_MUTEX(algs_lock);\nstatic unsigned int active_devs;\n\nstatic void sec_alg_skcipher_init_template(struct sec_alg_tfm_ctx *ctx,\n\t\t\t\t\t   struct sec_bd_info *req,\n\t\t\t\t\t   enum sec_cipher_alg alg)\n{\n\tconst struct sec_c_alg_cfg *cfg = &sec_c_alg_cfgs[alg];\n\n\tmemset(req, 0, sizeof(*req));\n\treq->w0 |= cfg->c_mode << SEC_BD_W0_C_MODE_S;\n\treq->w1 |= cfg->c_alg << SEC_BD_W1_C_ALG_S;\n\treq->w3 |= cfg->key_len << SEC_BD_W3_C_KEY_LEN_S;\n\treq->w0 |= cfg->c_width << SEC_BD_W0_C_WIDTH_S;\n\n\treq->cipher_key_addr_lo = lower_32_bits(ctx->pkey);\n\treq->cipher_key_addr_hi = upper_32_bits(ctx->pkey);\n}\n\nstatic void sec_alg_skcipher_init_context(struct crypto_skcipher *atfm,\n\t\t\t\t\t  const u8 *key,\n\t\t\t\t\t  unsigned int keylen,\n\t\t\t\t\t  enum sec_cipher_alg alg)\n{\n\tstruct crypto_tfm *tfm = crypto_skcipher_tfm(atfm);\n\tstruct sec_alg_tfm_ctx *ctx = crypto_tfm_ctx(tfm);\n\n\tctx->cipher_alg = alg;\n\tmemcpy(ctx->key, key, keylen);\n\tsec_alg_skcipher_init_template(ctx, &ctx->req_template,\n\t\t\t\t       ctx->cipher_alg);\n}\n\nstatic void sec_free_hw_sgl(struct sec_hw_sgl *hw_sgl,\n\t\t\t    dma_addr_t psec_sgl, struct sec_dev_info *info)\n{\n\tstruct sec_hw_sgl *sgl_current, *sgl_next;\n\tdma_addr_t sgl_next_dma;\n\n\tsgl_current = hw_sgl;\n\twhile (sgl_current) {\n\t\tsgl_next = sgl_current->next;\n\t\tsgl_next_dma = sgl_current->next_sgl;\n\n\t\tdma_pool_free(info->hw_sgl_pool, sgl_current, psec_sgl);\n\n\t\tsgl_current = sgl_next;\n\t\tpsec_sgl = sgl_next_dma;\n\t}\n}\n\nstatic int sec_alloc_and_fill_hw_sgl(struct sec_hw_sgl **sec_sgl,\n\t\t\t\t     dma_addr_t *psec_sgl,\n\t\t\t\t     struct scatterlist *sgl,\n\t\t\t\t     int count,\n\t\t\t\t     struct sec_dev_info *info,\n\t\t\t\t     gfp_t gfp)\n{\n\tstruct sec_hw_sgl *sgl_current = NULL;\n\tstruct sec_hw_sgl *sgl_next;\n\tdma_addr_t sgl_next_dma;\n\tstruct scatterlist *sg;\n\tint ret, sge_index, i;\n\n\tif (!count)\n\t\treturn -EINVAL;\n\n\tfor_each_sg(sgl, sg, count, i) {\n\t\tsge_index = i % SEC_MAX_SGE_NUM;\n\t\tif (sge_index == 0) {\n\t\t\tsgl_next = dma_pool_zalloc(info->hw_sgl_pool,\n\t\t\t\t\t\t   gfp, &sgl_next_dma);\n\t\t\tif (!sgl_next) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto err_free_hw_sgls;\n\t\t\t}\n\n\t\t\tif (!sgl_current) {  \n\t\t\t\t*psec_sgl = sgl_next_dma;\n\t\t\t\t*sec_sgl = sgl_next;\n\t\t\t} else {  \n\t\t\t\tsgl_current->entry_sum_in_sgl = SEC_MAX_SGE_NUM;\n\t\t\t\tsgl_current->next_sgl = sgl_next_dma;\n\t\t\t\tsgl_current->next = sgl_next;\n\t\t\t}\n\t\t\tsgl_current = sgl_next;\n\t\t}\n\t\tsgl_current->sge_entries[sge_index].buf = sg_dma_address(sg);\n\t\tsgl_current->sge_entries[sge_index].len = sg_dma_len(sg);\n\t\tsgl_current->data_bytes_in_sgl += sg_dma_len(sg);\n\t}\n\tsgl_current->entry_sum_in_sgl = count % SEC_MAX_SGE_NUM;\n\tsgl_current->next_sgl = 0;\n\t(*sec_sgl)->entry_sum_in_chain = count;\n\n\treturn 0;\n\nerr_free_hw_sgls:\n\tsec_free_hw_sgl(*sec_sgl, *psec_sgl, info);\n\t*psec_sgl = 0;\n\n\treturn ret;\n}\n\nstatic int sec_alg_skcipher_setkey(struct crypto_skcipher *tfm,\n\t\t\t\t   const u8 *key, unsigned int keylen,\n\t\t\t\t   enum sec_cipher_alg alg)\n{\n\tstruct sec_alg_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tstruct device *dev = ctx->queue->dev_info->dev;\n\n\tmutex_lock(&ctx->lock);\n\tif (ctx->key) {\n\t\t \n\t\tmemset(ctx->key, 0, SEC_MAX_CIPHER_KEY);\n\t} else {\n\t\t \n\t\tctx->key = dma_alloc_coherent(dev, SEC_MAX_CIPHER_KEY,\n\t\t\t\t\t      &ctx->pkey, GFP_KERNEL);\n\t\tif (!ctx->key) {\n\t\t\tmutex_unlock(&ctx->lock);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\tmutex_unlock(&ctx->lock);\n\tsec_alg_skcipher_init_context(tfm, key, keylen, alg);\n\n\treturn 0;\n}\n\nstatic int sec_alg_skcipher_setkey_aes_ecb(struct crypto_skcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\tenum sec_cipher_alg alg;\n\n\tswitch (keylen) {\n\tcase AES_KEYSIZE_128:\n\t\talg = SEC_C_AES_ECB_128;\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\talg = SEC_C_AES_ECB_192;\n\t\tbreak;\n\tcase AES_KEYSIZE_256:\n\t\talg = SEC_C_AES_ECB_256;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn sec_alg_skcipher_setkey(tfm, key, keylen, alg);\n}\n\nstatic int sec_alg_skcipher_setkey_aes_cbc(struct crypto_skcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\tenum sec_cipher_alg alg;\n\n\tswitch (keylen) {\n\tcase AES_KEYSIZE_128:\n\t\talg = SEC_C_AES_CBC_128;\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\talg = SEC_C_AES_CBC_192;\n\t\tbreak;\n\tcase AES_KEYSIZE_256:\n\t\talg = SEC_C_AES_CBC_256;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn sec_alg_skcipher_setkey(tfm, key, keylen, alg);\n}\n\nstatic int sec_alg_skcipher_setkey_aes_ctr(struct crypto_skcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\tenum sec_cipher_alg alg;\n\n\tswitch (keylen) {\n\tcase AES_KEYSIZE_128:\n\t\talg = SEC_C_AES_CTR_128;\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\talg = SEC_C_AES_CTR_192;\n\t\tbreak;\n\tcase AES_KEYSIZE_256:\n\t\talg = SEC_C_AES_CTR_256;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn sec_alg_skcipher_setkey(tfm, key, keylen, alg);\n}\n\nstatic int sec_alg_skcipher_setkey_aes_xts(struct crypto_skcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\tenum sec_cipher_alg alg;\n\tint ret;\n\n\tret = xts_verify_key(tfm, key, keylen);\n\tif (ret)\n\t\treturn ret;\n\n\tswitch (keylen) {\n\tcase AES_KEYSIZE_128 * 2:\n\t\talg = SEC_C_AES_XTS_128;\n\t\tbreak;\n\tcase AES_KEYSIZE_256 * 2:\n\t\talg = SEC_C_AES_XTS_256;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn sec_alg_skcipher_setkey(tfm, key, keylen, alg);\n}\n\nstatic int sec_alg_skcipher_setkey_des_ecb(struct crypto_skcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\treturn verify_skcipher_des_key(tfm, key) ?:\n\t       sec_alg_skcipher_setkey(tfm, key, keylen, SEC_C_DES_ECB_64);\n}\n\nstatic int sec_alg_skcipher_setkey_des_cbc(struct crypto_skcipher *tfm,\n\t\t\t\t\t   const u8 *key, unsigned int keylen)\n{\n\treturn verify_skcipher_des_key(tfm, key) ?:\n\t       sec_alg_skcipher_setkey(tfm, key, keylen, SEC_C_DES_CBC_64);\n}\n\nstatic int sec_alg_skcipher_setkey_3des_ecb(struct crypto_skcipher *tfm,\n\t\t\t\t\t    const u8 *key, unsigned int keylen)\n{\n\treturn verify_skcipher_des3_key(tfm, key) ?:\n\t       sec_alg_skcipher_setkey(tfm, key, keylen,\n\t\t\t\t       SEC_C_3DES_ECB_192_3KEY);\n}\n\nstatic int sec_alg_skcipher_setkey_3des_cbc(struct crypto_skcipher *tfm,\n\t\t\t\t\t    const u8 *key, unsigned int keylen)\n{\n\treturn verify_skcipher_des3_key(tfm, key) ?:\n\t       sec_alg_skcipher_setkey(tfm, key, keylen,\n\t\t\t\t       SEC_C_3DES_CBC_192_3KEY);\n}\n\nstatic void sec_alg_free_el(struct sec_request_el *el,\n\t\t\t    struct sec_dev_info *info)\n{\n\tsec_free_hw_sgl(el->out, el->dma_out, info);\n\tsec_free_hw_sgl(el->in, el->dma_in, info);\n\tkfree(el->sgl_in);\n\tkfree(el->sgl_out);\n\tkfree(el);\n}\n\n \nstatic int sec_send_request(struct sec_request *sec_req, struct sec_queue *queue)\n{\n\tstruct sec_request_el *el, *temp;\n\tint ret = 0;\n\n\tmutex_lock(&sec_req->lock);\n\tlist_for_each_entry_safe(el, temp, &sec_req->elements, head) {\n\t\t \n\t\tif (!queue->havesoftqueue ||\n\t\t    (kfifo_is_empty(&queue->softqueue) &&\n\t\t     sec_queue_empty(queue))) {\n\t\t\tret = sec_queue_send(queue, &el->req, sec_req);\n\t\t\tif (ret == -EAGAIN) {\n\t\t\t\t \n\t\t\t\t \n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto err_unlock;\n\t\t\t}\n\t\t} else {\n\t\t\tkfifo_put(&queue->softqueue, el);\n\t\t}\n\t}\nerr_unlock:\n\tmutex_unlock(&sec_req->lock);\n\n\treturn ret;\n}\n\nstatic void sec_skcipher_alg_callback(struct sec_bd_info *sec_resp,\n\t\t\t\t      struct crypto_async_request *req_base)\n{\n\tstruct skcipher_request *skreq = container_of(req_base,\n\t\t\t\t\t\t      struct skcipher_request,\n\t\t\t\t\t\t      base);\n\tstruct sec_request *sec_req = skcipher_request_ctx(skreq);\n\tstruct sec_request *backlog_req;\n\tstruct sec_request_el *sec_req_el, *nextrequest;\n\tstruct sec_alg_tfm_ctx *ctx = sec_req->tfm_ctx;\n\tstruct crypto_skcipher *atfm = crypto_skcipher_reqtfm(skreq);\n\tstruct device *dev = ctx->queue->dev_info->dev;\n\tint icv_or_skey_en, ret;\n\tbool done;\n\n\tsec_req_el = list_first_entry(&sec_req->elements, struct sec_request_el,\n\t\t\t\t      head);\n\ticv_or_skey_en = (sec_resp->w0 & SEC_BD_W0_ICV_OR_SKEY_EN_M) >>\n\t\tSEC_BD_W0_ICV_OR_SKEY_EN_S;\n\tif (sec_resp->w1 & SEC_BD_W1_BD_INVALID || icv_or_skey_en == 3) {\n\t\tdev_err(dev, \"Got an invalid answer %lu %d\\n\",\n\t\t\tsec_resp->w1 & SEC_BD_W1_BD_INVALID,\n\t\t\ticv_or_skey_en);\n\t\tsec_req->err = -EINVAL;\n\t\t \n\t}\n\n\tspin_lock_bh(&ctx->queue->queuelock);\n\t \n\tswitch (ctx->cipher_alg) {\n\tcase SEC_C_AES_CBC_128:\n\tcase SEC_C_AES_CBC_192:\n\tcase SEC_C_AES_CBC_256:\n\t\tif (sec_req_el->req.w0 & SEC_BD_W0_DE)\n\t\t\tsg_pcopy_to_buffer(sec_req_el->sgl_out,\n\t\t\t\t\t   sg_nents(sec_req_el->sgl_out),\n\t\t\t\t\t   skreq->iv,\n\t\t\t\t\t   crypto_skcipher_ivsize(atfm),\n\t\t\t\t\t   sec_req_el->el_length -\n\t\t\t\t\t   crypto_skcipher_ivsize(atfm));\n\t\telse\n\t\t\tsg_pcopy_to_buffer(sec_req_el->sgl_in,\n\t\t\t\t\t   sg_nents(sec_req_el->sgl_in),\n\t\t\t\t\t   skreq->iv,\n\t\t\t\t\t   crypto_skcipher_ivsize(atfm),\n\t\t\t\t\t   sec_req_el->el_length -\n\t\t\t\t\t   crypto_skcipher_ivsize(atfm));\n\t\t \n\t\tbreak;\n\tcase SEC_C_AES_CTR_128:\n\tcase SEC_C_AES_CTR_192:\n\tcase SEC_C_AES_CTR_256:\n\t\tcrypto_inc(skreq->iv, 16);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\n\tif (ctx->queue->havesoftqueue &&\n\t    !kfifo_is_empty(&ctx->queue->softqueue) &&\n\t    sec_queue_empty(ctx->queue)) {\n\t\tret = kfifo_get(&ctx->queue->softqueue, &nextrequest);\n\t\tif (ret <= 0)\n\t\t\tdev_err(dev,\n\t\t\t\t\"Error getting next element from kfifo %d\\n\",\n\t\t\t\tret);\n\t\telse\n\t\t\t \n\t\t\tsec_queue_send(ctx->queue, &nextrequest->req,\n\t\t\t\t       nextrequest->sec_req);\n\t} else if (!list_empty(&ctx->backlog)) {\n\t\t \n\t\tbacklog_req = list_first_entry(&ctx->backlog,\n\t\t\t\t\t       typeof(*backlog_req),\n\t\t\t\t\t       backlog_head);\n\t\tif (sec_queue_can_enqueue(ctx->queue,\n\t\t    backlog_req->num_elements) ||\n\t\t    (ctx->queue->havesoftqueue &&\n\t\t     kfifo_avail(&ctx->queue->softqueue) >\n\t\t     backlog_req->num_elements)) {\n\t\t\tsec_send_request(backlog_req, ctx->queue);\n\t\t\tcrypto_request_complete(backlog_req->req_base,\n\t\t\t\t\t\t-EINPROGRESS);\n\t\t\tlist_del(&backlog_req->backlog_head);\n\t\t}\n\t}\n\tspin_unlock_bh(&ctx->queue->queuelock);\n\n\tmutex_lock(&sec_req->lock);\n\tlist_del(&sec_req_el->head);\n\tmutex_unlock(&sec_req->lock);\n\tsec_alg_free_el(sec_req_el, ctx->queue->dev_info);\n\n\t \n\tmutex_lock(&sec_req->lock);\n\tdone = list_empty(&sec_req->elements);\n\tmutex_unlock(&sec_req->lock);\n\tif (done) {\n\t\tif (crypto_skcipher_ivsize(atfm)) {\n\t\t\tdma_unmap_single(dev, sec_req->dma_iv,\n\t\t\t\t\t crypto_skcipher_ivsize(atfm),\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\t}\n\t\tdma_unmap_sg(dev, skreq->src, sec_req->len_in,\n\t\t\t     DMA_BIDIRECTIONAL);\n\t\tif (skreq->src != skreq->dst)\n\t\t\tdma_unmap_sg(dev, skreq->dst, sec_req->len_out,\n\t\t\t\t     DMA_BIDIRECTIONAL);\n\t\tskcipher_request_complete(skreq, sec_req->err);\n\t}\n}\n\nvoid sec_alg_callback(struct sec_bd_info *resp, void *shadow)\n{\n\tstruct sec_request *sec_req = shadow;\n\n\tsec_req->cb(resp, sec_req->req_base);\n}\n\nstatic int sec_alg_alloc_and_calc_split_sizes(int length, size_t **split_sizes,\n\t\t\t\t\t      int *steps, gfp_t gfp)\n{\n\tsize_t *sizes;\n\tint i;\n\n\t \n\t*steps = roundup(length, SEC_REQ_LIMIT) / SEC_REQ_LIMIT;\n\tsizes = kcalloc(*steps, sizeof(*sizes), gfp);\n\tif (!sizes)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < *steps - 1; i++)\n\t\tsizes[i] = SEC_REQ_LIMIT;\n\tsizes[*steps - 1] = length - SEC_REQ_LIMIT * (*steps - 1);\n\t*split_sizes = sizes;\n\n\treturn 0;\n}\n\nstatic int sec_map_and_split_sg(struct scatterlist *sgl, size_t *split_sizes,\n\t\t\t\tint steps, struct scatterlist ***splits,\n\t\t\t\tint **splits_nents,\n\t\t\t\tint sgl_len_in,\n\t\t\t\tstruct device *dev, gfp_t gfp)\n{\n\tint ret, count;\n\n\tcount = dma_map_sg(dev, sgl, sgl_len_in, DMA_BIDIRECTIONAL);\n\tif (!count)\n\t\treturn -EINVAL;\n\n\t*splits = kcalloc(steps, sizeof(struct scatterlist *), gfp);\n\tif (!*splits) {\n\t\tret = -ENOMEM;\n\t\tgoto err_unmap_sg;\n\t}\n\t*splits_nents = kcalloc(steps, sizeof(int), gfp);\n\tif (!*splits_nents) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_splits;\n\t}\n\n\t \n\tret = sg_split(sgl, count, 0, steps, split_sizes,\n\t\t       *splits, *splits_nents, gfp);\n\tif (ret) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_splits_nents;\n\t}\n\n\treturn 0;\n\nerr_free_splits_nents:\n\tkfree(*splits_nents);\nerr_free_splits:\n\tkfree(*splits);\nerr_unmap_sg:\n\tdma_unmap_sg(dev, sgl, sgl_len_in, DMA_BIDIRECTIONAL);\n\n\treturn ret;\n}\n\n \nstatic void sec_unmap_sg_on_err(struct scatterlist *sgl, int steps,\n\t\t\t\tstruct scatterlist **splits, int *splits_nents,\n\t\t\t\tint sgl_len_in, struct device *dev)\n{\n\tint i;\n\n\tfor (i = 0; i < steps; i++)\n\t\tkfree(splits[i]);\n\tkfree(splits_nents);\n\tkfree(splits);\n\n\tdma_unmap_sg(dev, sgl, sgl_len_in, DMA_BIDIRECTIONAL);\n}\n\nstatic struct sec_request_el\n*sec_alg_alloc_and_fill_el(struct sec_bd_info *template, int encrypt,\n\t\t\t   int el_size, bool different_dest,\n\t\t\t   struct scatterlist *sgl_in, int n_ents_in,\n\t\t\t   struct scatterlist *sgl_out, int n_ents_out,\n\t\t\t   struct sec_dev_info *info, gfp_t gfp)\n{\n\tstruct sec_request_el *el;\n\tstruct sec_bd_info *req;\n\tint ret;\n\n\tel = kzalloc(sizeof(*el), gfp);\n\tif (!el)\n\t\treturn ERR_PTR(-ENOMEM);\n\tel->el_length = el_size;\n\treq = &el->req;\n\tmemcpy(req, template, sizeof(*req));\n\n\treq->w0 &= ~SEC_BD_W0_CIPHER_M;\n\tif (encrypt)\n\t\treq->w0 |= SEC_CIPHER_ENCRYPT << SEC_BD_W0_CIPHER_S;\n\telse\n\t\treq->w0 |= SEC_CIPHER_DECRYPT << SEC_BD_W0_CIPHER_S;\n\n\treq->w0 &= ~SEC_BD_W0_C_GRAN_SIZE_19_16_M;\n\treq->w0 |= ((el_size >> 16) << SEC_BD_W0_C_GRAN_SIZE_19_16_S) &\n\t\tSEC_BD_W0_C_GRAN_SIZE_19_16_M;\n\n\treq->w0 &= ~SEC_BD_W0_C_GRAN_SIZE_21_20_M;\n\treq->w0 |= ((el_size >> 20) << SEC_BD_W0_C_GRAN_SIZE_21_20_S) &\n\t\tSEC_BD_W0_C_GRAN_SIZE_21_20_M;\n\n\t \n\treq->w2 = ((1 << SEC_BD_W2_GRAN_NUM_S) & SEC_BD_W2_GRAN_NUM_M) |\n\t\t((el_size << SEC_BD_W2_C_GRAN_SIZE_15_0_S) &\n\t\t SEC_BD_W2_C_GRAN_SIZE_15_0_M);\n\n\treq->w3 &= ~SEC_BD_W3_CIPHER_LEN_OFFSET_M;\n\treq->w1 |= SEC_BD_W1_ADDR_TYPE;\n\n\tel->sgl_in = sgl_in;\n\n\tret = sec_alloc_and_fill_hw_sgl(&el->in, &el->dma_in, el->sgl_in,\n\t\t\t\t\tn_ents_in, info, gfp);\n\tif (ret)\n\t\tgoto err_free_el;\n\n\treq->data_addr_lo = lower_32_bits(el->dma_in);\n\treq->data_addr_hi = upper_32_bits(el->dma_in);\n\n\tif (different_dest) {\n\t\tel->sgl_out = sgl_out;\n\t\tret = sec_alloc_and_fill_hw_sgl(&el->out, &el->dma_out,\n\t\t\t\t\t\tel->sgl_out,\n\t\t\t\t\t\tn_ents_out, info, gfp);\n\t\tif (ret)\n\t\t\tgoto err_free_hw_sgl_in;\n\n\t\treq->w0 |= SEC_BD_W0_DE;\n\t\treq->cipher_destin_addr_lo = lower_32_bits(el->dma_out);\n\t\treq->cipher_destin_addr_hi = upper_32_bits(el->dma_out);\n\n\t} else {\n\t\treq->w0 &= ~SEC_BD_W0_DE;\n\t\treq->cipher_destin_addr_lo = lower_32_bits(el->dma_in);\n\t\treq->cipher_destin_addr_hi = upper_32_bits(el->dma_in);\n\t}\n\n\treturn el;\n\nerr_free_hw_sgl_in:\n\tsec_free_hw_sgl(el->in, el->dma_in, info);\nerr_free_el:\n\tkfree(el);\n\n\treturn ERR_PTR(ret);\n}\n\nstatic int sec_alg_skcipher_crypto(struct skcipher_request *skreq,\n\t\t\t\t   bool encrypt)\n{\n\tstruct crypto_skcipher *atfm = crypto_skcipher_reqtfm(skreq);\n\tstruct crypto_tfm *tfm = crypto_skcipher_tfm(atfm);\n\tstruct sec_alg_tfm_ctx *ctx = crypto_tfm_ctx(tfm);\n\tstruct sec_queue *queue = ctx->queue;\n\tstruct sec_request *sec_req = skcipher_request_ctx(skreq);\n\tstruct sec_dev_info *info = queue->dev_info;\n\tint i, ret, steps;\n\tsize_t *split_sizes;\n\tstruct scatterlist **splits_in;\n\tstruct scatterlist **splits_out = NULL;\n\tint *splits_in_nents;\n\tint *splits_out_nents = NULL;\n\tstruct sec_request_el *el, *temp;\n\tbool split = skreq->src != skreq->dst;\n\tgfp_t gfp = skreq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL : GFP_ATOMIC;\n\n\tmutex_init(&sec_req->lock);\n\tsec_req->req_base = &skreq->base;\n\tsec_req->err = 0;\n\t \n\tsec_req->len_in = sg_nents(skreq->src);\n\n\tret = sec_alg_alloc_and_calc_split_sizes(skreq->cryptlen, &split_sizes,\n\t\t\t\t\t\t &steps, gfp);\n\tif (ret)\n\t\treturn ret;\n\tsec_req->num_elements = steps;\n\tret = sec_map_and_split_sg(skreq->src, split_sizes, steps, &splits_in,\n\t\t\t\t   &splits_in_nents, sec_req->len_in,\n\t\t\t\t   info->dev, gfp);\n\tif (ret)\n\t\tgoto err_free_split_sizes;\n\n\tif (split) {\n\t\tsec_req->len_out = sg_nents(skreq->dst);\n\t\tret = sec_map_and_split_sg(skreq->dst, split_sizes, steps,\n\t\t\t\t\t   &splits_out, &splits_out_nents,\n\t\t\t\t\t   sec_req->len_out, info->dev, gfp);\n\t\tif (ret)\n\t\t\tgoto err_unmap_in_sg;\n\t}\n\t \n\tsec_req->tfm_ctx = ctx;\n\tsec_req->cb = sec_skcipher_alg_callback;\n\tINIT_LIST_HEAD(&sec_req->elements);\n\n\t \n\tif (crypto_skcipher_ivsize(atfm)) {\n\t\tsec_req->dma_iv = dma_map_single(info->dev, skreq->iv,\n\t\t\t\t\t\t crypto_skcipher_ivsize(atfm),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(info->dev, sec_req->dma_iv)) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_unmap_out_sg;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < steps; i++) {\n\t\tel = sec_alg_alloc_and_fill_el(&ctx->req_template,\n\t\t\t\t\t       encrypt ? 1 : 0,\n\t\t\t\t\t       split_sizes[i],\n\t\t\t\t\t       skreq->src != skreq->dst,\n\t\t\t\t\t       splits_in[i], splits_in_nents[i],\n\t\t\t\t\t       split ? splits_out[i] : NULL,\n\t\t\t\t\t       split ? splits_out_nents[i] : 0,\n\t\t\t\t\t       info, gfp);\n\t\tif (IS_ERR(el)) {\n\t\t\tret = PTR_ERR(el);\n\t\t\tgoto err_free_elements;\n\t\t}\n\t\tel->req.cipher_iv_addr_lo = lower_32_bits(sec_req->dma_iv);\n\t\tel->req.cipher_iv_addr_hi = upper_32_bits(sec_req->dma_iv);\n\t\tel->sec_req = sec_req;\n\t\tlist_add_tail(&el->head, &sec_req->elements);\n\t}\n\n\t \n\n\t \n\tspin_lock_bh(&queue->queuelock);\n\n\t \n\tif ((!sec_queue_can_enqueue(queue, steps) &&\n\t     (!queue->havesoftqueue ||\n\t      kfifo_avail(&queue->softqueue) > steps)) ||\n\t    !list_empty(&ctx->backlog)) {\n\t\tret = -EBUSY;\n\t\tif ((skreq->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)) {\n\t\t\tlist_add_tail(&sec_req->backlog_head, &ctx->backlog);\n\t\t\tspin_unlock_bh(&queue->queuelock);\n\t\t\tgoto out;\n\t\t}\n\n\t\tspin_unlock_bh(&queue->queuelock);\n\t\tgoto err_free_elements;\n\t}\n\tret = sec_send_request(sec_req, queue);\n\tspin_unlock_bh(&queue->queuelock);\n\tif (ret)\n\t\tgoto err_free_elements;\n\n\tret = -EINPROGRESS;\nout:\n\t \n\tkfree(splits_in_nents);\n\tkfree(splits_in);\n\tkfree(splits_out_nents);\n\tkfree(splits_out);\n\tkfree(split_sizes);\n\treturn ret;\n\nerr_free_elements:\n\tlist_for_each_entry_safe(el, temp, &sec_req->elements, head) {\n\t\tlist_del(&el->head);\n\t\tsec_alg_free_el(el, info);\n\t}\n\tif (crypto_skcipher_ivsize(atfm))\n\t\tdma_unmap_single(info->dev, sec_req->dma_iv,\n\t\t\t\t crypto_skcipher_ivsize(atfm),\n\t\t\t\t DMA_BIDIRECTIONAL);\nerr_unmap_out_sg:\n\tif (split)\n\t\tsec_unmap_sg_on_err(skreq->dst, steps, splits_out,\n\t\t\t\t    splits_out_nents, sec_req->len_out,\n\t\t\t\t    info->dev);\nerr_unmap_in_sg:\n\tsec_unmap_sg_on_err(skreq->src, steps, splits_in, splits_in_nents,\n\t\t\t    sec_req->len_in, info->dev);\nerr_free_split_sizes:\n\tkfree(split_sizes);\n\n\treturn ret;\n}\n\nstatic int sec_alg_skcipher_encrypt(struct skcipher_request *req)\n{\n\treturn sec_alg_skcipher_crypto(req, true);\n}\n\nstatic int sec_alg_skcipher_decrypt(struct skcipher_request *req)\n{\n\treturn sec_alg_skcipher_crypto(req, false);\n}\n\nstatic int sec_alg_skcipher_init(struct crypto_skcipher *tfm)\n{\n\tstruct sec_alg_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\n\tmutex_init(&ctx->lock);\n\tINIT_LIST_HEAD(&ctx->backlog);\n\tcrypto_skcipher_set_reqsize(tfm, sizeof(struct sec_request));\n\n\tctx->queue = sec_queue_alloc_start_safe();\n\tif (IS_ERR(ctx->queue))\n\t\treturn PTR_ERR(ctx->queue);\n\n\tspin_lock_init(&ctx->queue->queuelock);\n\tctx->queue->havesoftqueue = false;\n\n\treturn 0;\n}\n\nstatic void sec_alg_skcipher_exit(struct crypto_skcipher *tfm)\n{\n\tstruct sec_alg_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tstruct device *dev = ctx->queue->dev_info->dev;\n\n\tif (ctx->key) {\n\t\tmemzero_explicit(ctx->key, SEC_MAX_CIPHER_KEY);\n\t\tdma_free_coherent(dev, SEC_MAX_CIPHER_KEY, ctx->key,\n\t\t\t\t  ctx->pkey);\n\t}\n\tsec_queue_stop_release(ctx->queue);\n}\n\nstatic int sec_alg_skcipher_init_with_queue(struct crypto_skcipher *tfm)\n{\n\tstruct sec_alg_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tint ret;\n\n\tret = sec_alg_skcipher_init(tfm);\n\tif (ret)\n\t\treturn ret;\n\n\tINIT_KFIFO(ctx->queue->softqueue);\n\tret = kfifo_alloc(&ctx->queue->softqueue, 512, GFP_KERNEL);\n\tif (ret) {\n\t\tsec_alg_skcipher_exit(tfm);\n\t\treturn ret;\n\t}\n\tctx->queue->havesoftqueue = true;\n\n\treturn 0;\n}\n\nstatic void sec_alg_skcipher_exit_with_queue(struct crypto_skcipher *tfm)\n{\n\tstruct sec_alg_tfm_ctx *ctx = crypto_skcipher_ctx(tfm);\n\n\tkfifo_free(&ctx->queue->softqueue);\n\tsec_alg_skcipher_exit(tfm);\n}\n\nstatic struct skcipher_alg sec_algs[] = {\n\t{\n\t\t.base = {\n\t\t\t.cra_name = \"ecb(aes)\",\n\t\t\t.cra_driver_name = \"hisi_sec_aes_ecb\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init,\n\t\t.exit = sec_alg_skcipher_exit,\n\t\t.setkey = sec_alg_skcipher_setkey_aes_ecb,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t.ivsize = 0,\n\t}, {\n\t\t.base = {\n\t\t\t.cra_name = \"cbc(aes)\",\n\t\t\t.cra_driver_name = \"hisi_sec_aes_cbc\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init_with_queue,\n\t\t.exit = sec_alg_skcipher_exit_with_queue,\n\t\t.setkey = sec_alg_skcipher_setkey_aes_cbc,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t.ivsize = AES_BLOCK_SIZE,\n\t}, {\n\t\t.base = {\n\t\t\t.cra_name = \"ctr(aes)\",\n\t\t\t.cra_driver_name = \"hisi_sec_aes_ctr\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init_with_queue,\n\t\t.exit = sec_alg_skcipher_exit_with_queue,\n\t\t.setkey = sec_alg_skcipher_setkey_aes_ctr,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t.ivsize = AES_BLOCK_SIZE,\n\t}, {\n\t\t.base = {\n\t\t\t.cra_name = \"xts(aes)\",\n\t\t\t.cra_driver_name = \"hisi_sec_aes_xts\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init,\n\t\t.exit = sec_alg_skcipher_exit,\n\t\t.setkey = sec_alg_skcipher_setkey_aes_xts,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = 2 * AES_MIN_KEY_SIZE,\n\t\t.max_keysize = 2 * AES_MAX_KEY_SIZE,\n\t\t.ivsize = AES_BLOCK_SIZE,\n\t}, {\n\t \n\t\t.base = {\n\t\t\t.cra_name = \"ecb(des)\",\n\t\t\t.cra_driver_name = \"hisi_sec_des_ecb\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init,\n\t\t.exit = sec_alg_skcipher_exit,\n\t\t.setkey = sec_alg_skcipher_setkey_des_ecb,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = DES_KEY_SIZE,\n\t\t.max_keysize = DES_KEY_SIZE,\n\t\t.ivsize = 0,\n\t}, {\n\t\t.base = {\n\t\t\t.cra_name = \"cbc(des)\",\n\t\t\t.cra_driver_name = \"hisi_sec_des_cbc\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = DES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init_with_queue,\n\t\t.exit = sec_alg_skcipher_exit_with_queue,\n\t\t.setkey = sec_alg_skcipher_setkey_des_cbc,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = DES_KEY_SIZE,\n\t\t.max_keysize = DES_KEY_SIZE,\n\t\t.ivsize = DES_BLOCK_SIZE,\n\t}, {\n\t\t.base = {\n\t\t\t.cra_name = \"cbc(des3_ede)\",\n\t\t\t.cra_driver_name = \"hisi_sec_3des_cbc\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init_with_queue,\n\t\t.exit = sec_alg_skcipher_exit_with_queue,\n\t\t.setkey = sec_alg_skcipher_setkey_3des_cbc,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t.ivsize = DES3_EDE_BLOCK_SIZE,\n\t}, {\n\t\t.base = {\n\t\t\t.cra_name = \"ecb(des3_ede)\",\n\t\t\t.cra_driver_name = \"hisi_sec_3des_ecb\",\n\t\t\t.cra_priority = 4001,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = DES3_EDE_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct sec_alg_tfm_ctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.init = sec_alg_skcipher_init,\n\t\t.exit = sec_alg_skcipher_exit,\n\t\t.setkey = sec_alg_skcipher_setkey_3des_ecb,\n\t\t.decrypt = sec_alg_skcipher_decrypt,\n\t\t.encrypt = sec_alg_skcipher_encrypt,\n\t\t.min_keysize = DES3_EDE_KEY_SIZE,\n\t\t.max_keysize = DES3_EDE_KEY_SIZE,\n\t\t.ivsize = 0,\n\t}\n};\n\nint sec_algs_register(void)\n{\n\tint ret = 0;\n\n\tmutex_lock(&algs_lock);\n\tif (++active_devs != 1)\n\t\tgoto unlock;\n\n\tret = crypto_register_skciphers(sec_algs, ARRAY_SIZE(sec_algs));\n\tif (ret)\n\t\t--active_devs;\nunlock:\n\tmutex_unlock(&algs_lock);\n\n\treturn ret;\n}\n\nvoid sec_algs_unregister(void)\n{\n\tmutex_lock(&algs_lock);\n\tif (--active_devs != 0)\n\t\tgoto unlock;\n\tcrypto_unregister_skciphers(sec_algs, ARRAY_SIZE(sec_algs));\n\nunlock:\n\tmutex_unlock(&algs_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}