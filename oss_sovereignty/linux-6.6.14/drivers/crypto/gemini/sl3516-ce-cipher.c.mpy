{
  "module_name": "sl3516-ce-cipher.c",
  "hash_id": "12d7a9663c13ca9fbb2ee933c0db784daa90f2f793a1d00b7ac695356daa545d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/gemini/sl3516-ce-cipher.c",
  "human_readable_source": "\n \n\n#include <crypto/engine.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n#include <linux/dma-mapping.h>\n#include <linux/delay.h>\n#include <linux/err.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/pm_runtime.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include \"sl3516-ce.h\"\n\n \nstatic bool sl3516_ce_need_fallback(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sl3516_ce_dev *ce = op->ce;\n\tstruct scatterlist *in_sg;\n\tstruct scatterlist *out_sg;\n\tstruct scatterlist *sg;\n\n\tif (areq->cryptlen == 0 || areq->cryptlen % 16) {\n\t\tce->fallback_mod16++;\n\t\treturn true;\n\t}\n\n\t \n\tif (sg_nents(areq->src) > MAXDESC / 2) {\n\t\tce->fallback_sg_count_tx++;\n\t\treturn true;\n\t}\n\t \n\tif (sg_nents(areq->dst) > MAXDESC) {\n\t\tce->fallback_sg_count_rx++;\n\t\treturn true;\n\t}\n\n\tsg = areq->src;\n\twhile (sg) {\n\t\tif ((sg->length % 16) != 0) {\n\t\t\tce->fallback_mod16++;\n\t\t\treturn true;\n\t\t}\n\t\tif ((sg_dma_len(sg) % 16) != 0) {\n\t\t\tce->fallback_mod16++;\n\t\t\treturn true;\n\t\t}\n\t\tif (!IS_ALIGNED(sg->offset, 16)) {\n\t\t\tce->fallback_align16++;\n\t\t\treturn true;\n\t\t}\n\t\tsg = sg_next(sg);\n\t}\n\tsg = areq->dst;\n\twhile (sg) {\n\t\tif ((sg->length % 16) != 0) {\n\t\t\tce->fallback_mod16++;\n\t\t\treturn true;\n\t\t}\n\t\tif ((sg_dma_len(sg) % 16) != 0) {\n\t\t\tce->fallback_mod16++;\n\t\t\treturn true;\n\t\t}\n\t\tif (!IS_ALIGNED(sg->offset, 16)) {\n\t\t\tce->fallback_align16++;\n\t\t\treturn true;\n\t\t}\n\t\tsg = sg_next(sg);\n\t}\n\n\t \n\tin_sg = areq->src;\n\tout_sg = areq->dst;\n\twhile (in_sg && out_sg) {\n\t\tif (in_sg->length != out_sg->length) {\n\t\t\tce->fallback_not_same_len++;\n\t\t\treturn true;\n\t\t}\n\t\tin_sg = sg_next(in_sg);\n\t\tout_sg = sg_next(out_sg);\n\t}\n\tif (in_sg || out_sg)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int sl3516_ce_cipher_fallback(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sl3516_ce_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(tfm);\n\tstruct sl3516_ce_alg_template *algt;\n\tint err;\n\n\talgt = container_of(alg, struct sl3516_ce_alg_template, alg.skcipher.base);\n\talgt->stat_fb++;\n\n\tskcipher_request_set_tfm(&rctx->fallback_req, op->fallback_tfm);\n\tskcipher_request_set_callback(&rctx->fallback_req, areq->base.flags,\n\t\t\t\t      areq->base.complete, areq->base.data);\n\tskcipher_request_set_crypt(&rctx->fallback_req, areq->src, areq->dst,\n\t\t\t\t   areq->cryptlen, areq->iv);\n\tif (rctx->op_dir == CE_DECRYPTION)\n\t\terr = crypto_skcipher_decrypt(&rctx->fallback_req);\n\telse\n\t\terr = crypto_skcipher_encrypt(&rctx->fallback_req);\n\treturn err;\n}\n\nstatic int sl3516_ce_cipher(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sl3516_ce_dev *ce = op->ce;\n\tstruct sl3516_ce_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(tfm);\n\tstruct sl3516_ce_alg_template *algt;\n\tstruct scatterlist *sg;\n\tunsigned int todo, len;\n\tstruct pkt_control_ecb *ecb;\n\tint nr_sgs = 0;\n\tint nr_sgd = 0;\n\tint err = 0;\n\tint i;\n\n\talgt = container_of(alg, struct sl3516_ce_alg_template, alg.skcipher.base);\n\n\tdev_dbg(ce->dev, \"%s %s %u %x IV(%p %u) key=%u\\n\", __func__,\n\t\tcrypto_tfm_alg_name(areq->base.tfm),\n\t\tareq->cryptlen,\n\t\trctx->op_dir, areq->iv, crypto_skcipher_ivsize(tfm),\n\t\top->keylen);\n\n\talgt->stat_req++;\n\n\tif (areq->src == areq->dst) {\n\t\tnr_sgs = dma_map_sg(ce->dev, areq->src, sg_nents(areq->src),\n\t\t\t\t    DMA_BIDIRECTIONAL);\n\t\tif (nr_sgs <= 0 || nr_sgs > MAXDESC / 2) {\n\t\t\tdev_err(ce->dev, \"Invalid sg number %d\\n\", nr_sgs);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend;\n\t\t}\n\t\tnr_sgd = nr_sgs;\n\t} else {\n\t\tnr_sgs = dma_map_sg(ce->dev, areq->src, sg_nents(areq->src),\n\t\t\t\t    DMA_TO_DEVICE);\n\t\tif (nr_sgs <= 0 || nr_sgs > MAXDESC / 2) {\n\t\t\tdev_err(ce->dev, \"Invalid sg number %d\\n\", nr_sgs);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend;\n\t\t}\n\t\tnr_sgd = dma_map_sg(ce->dev, areq->dst, sg_nents(areq->dst),\n\t\t\t\t    DMA_FROM_DEVICE);\n\t\tif (nr_sgd <= 0 || nr_sgd > MAXDESC) {\n\t\t\tdev_err(ce->dev, \"Invalid sg number %d\\n\", nr_sgd);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend_sgs;\n\t\t}\n\t}\n\n\tlen = areq->cryptlen;\n\ti = 0;\n\tsg = areq->src;\n\twhile (i < nr_sgs && sg && len) {\n\t\tif (sg_dma_len(sg) == 0)\n\t\t\tgoto sgs_next;\n\t\trctx->t_src[i].addr = sg_dma_address(sg);\n\t\ttodo = min(len, sg_dma_len(sg));\n\t\trctx->t_src[i].len = todo;\n\t\tdev_dbg(ce->dev, \"%s total=%u SGS(%d %u off=%d) todo=%u\\n\", __func__,\n\t\t\tareq->cryptlen, i, rctx->t_src[i].len, sg->offset, todo);\n\t\tlen -= todo;\n\t\ti++;\nsgs_next:\n\t\tsg = sg_next(sg);\n\t}\n\tif (len > 0) {\n\t\tdev_err(ce->dev, \"remaining len %d/%u nr_sgs=%d\\n\", len, areq->cryptlen, nr_sgs);\n\t\terr = -EINVAL;\n\t\tgoto theend_sgs;\n\t}\n\n\tlen = areq->cryptlen;\n\ti = 0;\n\tsg = areq->dst;\n\twhile (i < nr_sgd && sg && len) {\n\t\tif (sg_dma_len(sg) == 0)\n\t\t\tgoto sgd_next;\n\t\trctx->t_dst[i].addr = sg_dma_address(sg);\n\t\ttodo = min(len, sg_dma_len(sg));\n\t\trctx->t_dst[i].len = todo;\n\t\tdev_dbg(ce->dev, \"%s total=%u SGD(%d %u off=%d) todo=%u\\n\", __func__,\n\t\t\tareq->cryptlen, i, rctx->t_dst[i].len, sg->offset, todo);\n\t\tlen -= todo;\n\t\ti++;\n\nsgd_next:\n\t\tsg = sg_next(sg);\n\t}\n\tif (len > 0) {\n\t\tdev_err(ce->dev, \"remaining len %d\\n\", len);\n\t\terr = -EINVAL;\n\t\tgoto theend_sgs;\n\t}\n\n\tswitch (algt->mode) {\n\tcase ECB_AES:\n\t\trctx->pctrllen = sizeof(struct pkt_control_ecb);\n\t\tecb = (struct pkt_control_ecb *)ce->pctrl;\n\n\t\trctx->tqflag = TQ0_TYPE_CTRL;\n\t\trctx->tqflag |= TQ1_CIPHER;\n\t\tecb->control.op_mode = rctx->op_dir;\n\t\tecb->control.cipher_algorithm = ECB_AES;\n\t\tecb->cipher.header_len = 0;\n\t\tecb->cipher.algorithm_len = areq->cryptlen;\n\t\tcpu_to_be32_array((__be32 *)ecb->key, (u32 *)op->key, op->keylen / 4);\n\t\trctx->h = &ecb->cipher;\n\n\t\trctx->tqflag |= TQ4_KEY0;\n\t\trctx->tqflag |= TQ5_KEY4;\n\t\trctx->tqflag |= TQ6_KEY6;\n\t\tecb->control.aesnk = op->keylen / 4;\n\t\tbreak;\n\t}\n\n\trctx->nr_sgs = nr_sgs;\n\trctx->nr_sgd = nr_sgd;\n\terr = sl3516_ce_run_task(ce, rctx, crypto_tfm_alg_name(areq->base.tfm));\n\ntheend_sgs:\n\tif (areq->src == areq->dst) {\n\t\tdma_unmap_sg(ce->dev, areq->src, sg_nents(areq->src),\n\t\t\t     DMA_BIDIRECTIONAL);\n\t} else {\n\t\tdma_unmap_sg(ce->dev, areq->src, sg_nents(areq->src),\n\t\t\t     DMA_TO_DEVICE);\n\t\tdma_unmap_sg(ce->dev, areq->dst, sg_nents(areq->dst),\n\t\t\t     DMA_FROM_DEVICE);\n\t}\n\ntheend:\n\n\treturn err;\n}\n\nint sl3516_ce_handle_cipher_request(struct crypto_engine *engine, void *areq)\n{\n\tint err;\n\tstruct skcipher_request *breq = container_of(areq, struct skcipher_request, base);\n\n\terr = sl3516_ce_cipher(breq);\n\tlocal_bh_disable();\n\tcrypto_finalize_skcipher_request(engine, breq, err);\n\tlocal_bh_enable();\n\n\treturn 0;\n}\n\nint sl3516_ce_skdecrypt(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sl3516_ce_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct crypto_engine *engine;\n\n\tmemset(rctx, 0, sizeof(struct sl3516_ce_cipher_req_ctx));\n\trctx->op_dir = CE_DECRYPTION;\n\n\tif (sl3516_ce_need_fallback(areq))\n\t\treturn sl3516_ce_cipher_fallback(areq);\n\n\tengine = op->ce->engine;\n\n\treturn crypto_transfer_skcipher_request_to_engine(engine, areq);\n}\n\nint sl3516_ce_skencrypt(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sl3516_ce_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct crypto_engine *engine;\n\n\tmemset(rctx, 0, sizeof(struct sl3516_ce_cipher_req_ctx));\n\trctx->op_dir = CE_ENCRYPTION;\n\n\tif (sl3516_ce_need_fallback(areq))\n\t\treturn sl3516_ce_cipher_fallback(areq);\n\n\tengine = op->ce->engine;\n\n\treturn crypto_transfer_skcipher_request_to_engine(engine, areq);\n}\n\nint sl3516_ce_cipher_init(struct crypto_tfm *tfm)\n{\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_tfm_ctx(tfm);\n\tstruct sl3516_ce_alg_template *algt;\n\tconst char *name = crypto_tfm_alg_name(tfm);\n\tstruct crypto_skcipher *sktfm = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(sktfm);\n\tint err;\n\n\tmemset(op, 0, sizeof(struct sl3516_ce_cipher_tfm_ctx));\n\n\talgt = container_of(alg, struct sl3516_ce_alg_template, alg.skcipher.base);\n\top->ce = algt->ce;\n\n\top->fallback_tfm = crypto_alloc_skcipher(name, 0, CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(op->fallback_tfm)) {\n\t\tdev_err(op->ce->dev, \"ERROR: Cannot allocate fallback for %s %ld\\n\",\n\t\t\tname, PTR_ERR(op->fallback_tfm));\n\t\treturn PTR_ERR(op->fallback_tfm);\n\t}\n\n\tsktfm->reqsize = sizeof(struct sl3516_ce_cipher_req_ctx) +\n\t\t\t crypto_skcipher_reqsize(op->fallback_tfm);\n\n\tdev_info(op->ce->dev, \"Fallback for %s is %s\\n\",\n\t\t crypto_tfm_alg_driver_name(&sktfm->base),\n\t\t crypto_tfm_alg_driver_name(crypto_skcipher_tfm(op->fallback_tfm)));\n\n\terr = pm_runtime_get_sync(op->ce->dev);\n\tif (err < 0)\n\t\tgoto error_pm;\n\n\treturn 0;\nerror_pm:\n\tpm_runtime_put_noidle(op->ce->dev);\n\tcrypto_free_skcipher(op->fallback_tfm);\n\treturn err;\n}\n\nvoid sl3516_ce_cipher_exit(struct crypto_tfm *tfm)\n{\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_tfm_ctx(tfm);\n\n\tkfree_sensitive(op->key);\n\tcrypto_free_skcipher(op->fallback_tfm);\n\tpm_runtime_put_sync_suspend(op->ce->dev);\n}\n\nint sl3516_ce_aes_setkey(struct crypto_skcipher *tfm, const u8 *key,\n\t\t\t unsigned int keylen)\n{\n\tstruct sl3516_ce_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sl3516_ce_dev *ce = op->ce;\n\n\tswitch (keylen) {\n\tcase 128 / 8:\n\t\tbreak;\n\tcase 192 / 8:\n\t\tbreak;\n\tcase 256 / 8:\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(ce->dev, \"ERROR: Invalid keylen %u\\n\", keylen);\n\t\treturn -EINVAL;\n\t}\n\tkfree_sensitive(op->key);\n\top->keylen = keylen;\n\top->key = kmemdup(key, keylen, GFP_KERNEL | GFP_DMA);\n\tif (!op->key)\n\t\treturn -ENOMEM;\n\n\tcrypto_skcipher_clear_flags(op->fallback_tfm, CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(op->fallback_tfm, tfm->base.crt_flags & CRYPTO_TFM_REQ_MASK);\n\n\treturn crypto_skcipher_setkey(op->fallback_tfm, key, keylen);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}