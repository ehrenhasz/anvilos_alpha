{
  "module_name": "artpec6_crypto.c",
  "hash_id": "6cb765809ba1c793ac59e50d30e7b3357ef995ffc9ed2e6fef3a8778f639834c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/axis/artpec6_crypto.c",
  "human_readable_source": "\n \n#define pr_fmt(fmt)     KBUILD_MODNAME \": \" fmt\n\n#include <linux/bitfield.h>\n#include <linux/crypto.h>\n#include <linux/debugfs.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/fault-inject.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n\n#include <crypto/aes.h>\n#include <crypto/gcm.h>\n#include <crypto/internal/aead.h>\n#include <crypto/internal/hash.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/sha1.h>\n#include <crypto/sha2.h>\n#include <crypto/xts.h>\n\n \n#define ARTPEC_CACHE_LINE_MAX\t32\n\n#define PDMA_OUT_CFG\t\t0x0000\n#define PDMA_OUT_BUF_CFG\t0x0004\n#define PDMA_OUT_CMD\t\t0x0008\n#define PDMA_OUT_DESCRQ_PUSH\t0x0010\n#define PDMA_OUT_DESCRQ_STAT\t0x0014\n\n#define A6_PDMA_IN_CFG\t\t0x0028\n#define A6_PDMA_IN_BUF_CFG\t0x002c\n#define A6_PDMA_IN_CMD\t\t0x0030\n#define A6_PDMA_IN_STATQ_PUSH\t0x0038\n#define A6_PDMA_IN_DESCRQ_PUSH\t0x0044\n#define A6_PDMA_IN_DESCRQ_STAT\t0x0048\n#define A6_PDMA_INTR_MASK\t0x0068\n#define A6_PDMA_ACK_INTR\t0x006c\n#define A6_PDMA_MASKED_INTR\t0x0074\n\n#define A7_PDMA_IN_CFG\t\t0x002c\n#define A7_PDMA_IN_BUF_CFG\t0x0030\n#define A7_PDMA_IN_CMD\t\t0x0034\n#define A7_PDMA_IN_STATQ_PUSH\t0x003c\n#define A7_PDMA_IN_DESCRQ_PUSH\t0x0048\n#define A7_PDMA_IN_DESCRQ_STAT\t0x004C\n#define A7_PDMA_INTR_MASK\t0x006c\n#define A7_PDMA_ACK_INTR\t0x0070\n#define A7_PDMA_MASKED_INTR\t0x0078\n\n#define PDMA_OUT_CFG_EN\t\t\t\tBIT(0)\n\n#define PDMA_OUT_BUF_CFG_DATA_BUF_SIZE\t\tGENMASK(4, 0)\n#define PDMA_OUT_BUF_CFG_DESCR_BUF_SIZE\t\tGENMASK(9, 5)\n\n#define PDMA_OUT_CMD_START\t\t\tBIT(0)\n#define A6_PDMA_OUT_CMD_STOP\t\t\tBIT(3)\n#define A7_PDMA_OUT_CMD_STOP\t\t\tBIT(2)\n\n#define PDMA_OUT_DESCRQ_PUSH_LEN\t\tGENMASK(5, 0)\n#define PDMA_OUT_DESCRQ_PUSH_ADDR\t\tGENMASK(31, 6)\n\n#define PDMA_OUT_DESCRQ_STAT_LEVEL\t\tGENMASK(3, 0)\n#define PDMA_OUT_DESCRQ_STAT_SIZE\t\tGENMASK(7, 4)\n\n#define PDMA_IN_CFG_EN\t\t\t\tBIT(0)\n\n#define PDMA_IN_BUF_CFG_DATA_BUF_SIZE\t\tGENMASK(4, 0)\n#define PDMA_IN_BUF_CFG_DESCR_BUF_SIZE\t\tGENMASK(9, 5)\n#define PDMA_IN_BUF_CFG_STAT_BUF_SIZE\t\tGENMASK(14, 10)\n\n#define PDMA_IN_CMD_START\t\t\tBIT(0)\n#define A6_PDMA_IN_CMD_FLUSH_STAT\t\tBIT(2)\n#define A6_PDMA_IN_CMD_STOP\t\t\tBIT(3)\n#define A7_PDMA_IN_CMD_FLUSH_STAT\t\tBIT(1)\n#define A7_PDMA_IN_CMD_STOP\t\t\tBIT(2)\n\n#define PDMA_IN_STATQ_PUSH_LEN\t\t\tGENMASK(5, 0)\n#define PDMA_IN_STATQ_PUSH_ADDR\t\t\tGENMASK(31, 6)\n\n#define PDMA_IN_DESCRQ_PUSH_LEN\t\t\tGENMASK(5, 0)\n#define PDMA_IN_DESCRQ_PUSH_ADDR\t\tGENMASK(31, 6)\n\n#define PDMA_IN_DESCRQ_STAT_LEVEL\t\tGENMASK(3, 0)\n#define PDMA_IN_DESCRQ_STAT_SIZE\t\tGENMASK(7, 4)\n\n#define A6_PDMA_INTR_MASK_IN_DATA\t\tBIT(2)\n#define A6_PDMA_INTR_MASK_IN_EOP\t\tBIT(3)\n#define A6_PDMA_INTR_MASK_IN_EOP_FLUSH\t\tBIT(4)\n\n#define A7_PDMA_INTR_MASK_IN_DATA\t\tBIT(3)\n#define A7_PDMA_INTR_MASK_IN_EOP\t\tBIT(4)\n#define A7_PDMA_INTR_MASK_IN_EOP_FLUSH\t\tBIT(5)\n\n#define A6_CRY_MD_OPER\t\tGENMASK(19, 16)\n\n#define A6_CRY_MD_HASH_SEL_CTX\tGENMASK(21, 20)\n#define A6_CRY_MD_HASH_HMAC_FIN\tBIT(23)\n\n#define A6_CRY_MD_CIPHER_LEN\tGENMASK(21, 20)\n#define A6_CRY_MD_CIPHER_DECR\tBIT(22)\n#define A6_CRY_MD_CIPHER_TWEAK\tBIT(23)\n#define A6_CRY_MD_CIPHER_DSEQ\tBIT(24)\n\n#define A7_CRY_MD_OPER\t\tGENMASK(11, 8)\n\n#define A7_CRY_MD_HASH_SEL_CTX\tGENMASK(13, 12)\n#define A7_CRY_MD_HASH_HMAC_FIN\tBIT(15)\n\n#define A7_CRY_MD_CIPHER_LEN\tGENMASK(13, 12)\n#define A7_CRY_MD_CIPHER_DECR\tBIT(14)\n#define A7_CRY_MD_CIPHER_TWEAK\tBIT(15)\n#define A7_CRY_MD_CIPHER_DSEQ\tBIT(16)\n\n \n#define regk_crypto_aes_cbc     0x00000002\n#define regk_crypto_aes_ctr     0x00000003\n#define regk_crypto_aes_ecb     0x00000001\n#define regk_crypto_aes_gcm     0x00000004\n#define regk_crypto_aes_xts     0x00000005\n#define regk_crypto_cache       0x00000002\n#define a6_regk_crypto_dlkey    0x0000000a\n#define a7_regk_crypto_dlkey    0x0000000e\n#define regk_crypto_ext         0x00000001\n#define regk_crypto_hmac_sha1   0x00000007\n#define regk_crypto_hmac_sha256 0x00000009\n#define regk_crypto_init        0x00000000\n#define regk_crypto_key_128     0x00000000\n#define regk_crypto_key_192     0x00000001\n#define regk_crypto_key_256     0x00000002\n#define regk_crypto_null        0x00000000\n#define regk_crypto_sha1        0x00000006\n#define regk_crypto_sha256      0x00000008\n\n \nstruct pdma_descr_ctrl  {\n\tunsigned char short_descr : 1;\n\tunsigned char pad1        : 1;\n\tunsigned char eop         : 1;\n\tunsigned char intr        : 1;\n\tunsigned char short_len   : 3;\n\tunsigned char pad2        : 1;\n} __packed;\n\nstruct pdma_data_descr {\n\tunsigned int len : 24;\n\tunsigned int buf : 32;\n} __packed;\n\nstruct pdma_short_descr {\n\tunsigned char data[7];\n} __packed;\n\nstruct pdma_descr {\n\tstruct pdma_descr_ctrl ctrl;\n\tunion {\n\t\tstruct pdma_data_descr   data;\n\t\tstruct pdma_short_descr  shrt;\n\t};\n};\n\nstruct pdma_stat_descr {\n\tunsigned char pad1        : 1;\n\tunsigned char pad2        : 1;\n\tunsigned char eop         : 1;\n\tunsigned char pad3        : 5;\n\tunsigned int  len         : 24;\n};\n\n \n#define PDMA_DESCR_COUNT\t64\n\n#define MODULE_NAME   \"Artpec-6 CA\"\n\n \n#define ARTPEC6_CRYPTO_HASH_SHA1\t1\n#define ARTPEC6_CRYPTO_HASH_SHA256\t2\n\n \n#define ARTPEC6_CRYPTO_CIPHER_AES_ECB\t1\n#define ARTPEC6_CRYPTO_CIPHER_AES_CBC\t2\n#define ARTPEC6_CRYPTO_CIPHER_AES_CTR\t3\n#define ARTPEC6_CRYPTO_CIPHER_AES_XTS\t5\n\n \n\nstruct artpec6_crypto_bounce_buffer {\n\tstruct list_head list;\n\tsize_t length;\n\tstruct scatterlist *sg;\n\tsize_t offset;\n\t \n\tvoid *buf;\n};\n\nstruct artpec6_crypto_dma_map {\n\tdma_addr_t dma_addr;\n\tsize_t size;\n\tenum dma_data_direction dir;\n};\n\nstruct artpec6_crypto_dma_descriptors {\n\tstruct pdma_descr out[PDMA_DESCR_COUNT] __aligned(64);\n\tstruct pdma_descr in[PDMA_DESCR_COUNT] __aligned(64);\n\tu32 stat[PDMA_DESCR_COUNT] __aligned(64);\n\tstruct list_head bounce_buffers;\n\t \n\tstruct artpec6_crypto_dma_map maps[PDMA_DESCR_COUNT * 2 + 2];\n\tdma_addr_t out_dma_addr;\n\tdma_addr_t in_dma_addr;\n\tdma_addr_t stat_dma_addr;\n\tsize_t out_cnt;\n\tsize_t in_cnt;\n\tsize_t map_count;\n};\n\nenum artpec6_crypto_variant {\n\tARTPEC6_CRYPTO,\n\tARTPEC7_CRYPTO,\n};\n\nstruct artpec6_crypto {\n\tvoid __iomem *base;\n\tspinlock_t queue_lock;\n\tstruct list_head queue;  \n\tstruct list_head pending;  \n\tstruct tasklet_struct task;\n\tstruct kmem_cache *dma_cache;\n\tint pending_count;\n\tstruct timer_list timer;\n\tenum artpec6_crypto_variant variant;\n\tvoid *pad_buffer;  \n\tvoid *zero_buffer;\n};\n\nenum artpec6_crypto_hash_flags {\n\tHASH_FLAG_INIT_CTX = 2,\n\tHASH_FLAG_UPDATE = 4,\n\tHASH_FLAG_FINALIZE = 8,\n\tHASH_FLAG_HMAC = 16,\n\tHASH_FLAG_UPDATE_KEY = 32,\n};\n\nstruct artpec6_crypto_req_common {\n\tstruct list_head list;\n\tstruct list_head complete_in_progress;\n\tstruct artpec6_crypto_dma_descriptors *dma;\n\tstruct crypto_async_request *req;\n\tvoid (*complete)(struct crypto_async_request *req);\n\tgfp_t gfp_flags;\n};\n\nstruct artpec6_hash_request_context {\n\tchar partial_buffer[SHA256_BLOCK_SIZE];\n\tchar partial_buffer_out[SHA256_BLOCK_SIZE];\n\tchar key_buffer[SHA256_BLOCK_SIZE];\n\tchar pad_buffer[SHA256_BLOCK_SIZE + 32];\n\tunsigned char digeststate[SHA256_DIGEST_SIZE];\n\tsize_t partial_bytes;\n\tu64 digcnt;\n\tu32 key_md;\n\tu32 hash_md;\n\tenum artpec6_crypto_hash_flags hash_flags;\n\tstruct artpec6_crypto_req_common common;\n};\n\nstruct artpec6_hash_export_state {\n\tchar partial_buffer[SHA256_BLOCK_SIZE];\n\tunsigned char digeststate[SHA256_DIGEST_SIZE];\n\tsize_t partial_bytes;\n\tu64 digcnt;\n\tint oper;\n\tunsigned int hash_flags;\n};\n\nstruct artpec6_hashalg_context {\n\tchar hmac_key[SHA256_BLOCK_SIZE];\n\tsize_t hmac_key_length;\n\tstruct crypto_shash *child_hash;\n};\n\nstruct artpec6_crypto_request_context {\n\tu32 cipher_md;\n\tbool decrypt;\n\tstruct artpec6_crypto_req_common common;\n};\n\nstruct artpec6_cryptotfm_context {\n\tunsigned char aes_key[2*AES_MAX_KEY_SIZE];\n\tsize_t key_length;\n\tu32 key_md;\n\tint crypto_type;\n\tstruct crypto_sync_skcipher *fallback;\n};\n\nstruct artpec6_crypto_aead_hw_ctx {\n\t__be64\taad_length_bits;\n\t__be64  text_length_bits;\n\t__u8\tJ0[AES_BLOCK_SIZE];\n};\n\nstruct artpec6_crypto_aead_req_ctx {\n\tstruct artpec6_crypto_aead_hw_ctx hw_ctx;\n\tu32 cipher_md;\n\tbool decrypt;\n\tstruct artpec6_crypto_req_common common;\n\t__u8 decryption_tag[AES_BLOCK_SIZE] ____cacheline_aligned;\n};\n\n \nstatic struct device *artpec6_crypto_dev;\n\n#ifdef CONFIG_FAULT_INJECTION\nstatic DECLARE_FAULT_ATTR(artpec6_crypto_fail_status_read);\nstatic DECLARE_FAULT_ATTR(artpec6_crypto_fail_dma_array_full);\n#endif\n\nenum {\n\tARTPEC6_CRYPTO_PREPARE_HASH_NO_START,\n\tARTPEC6_CRYPTO_PREPARE_HASH_START,\n};\n\nstatic int artpec6_crypto_prepare_aead(struct aead_request *areq);\nstatic int artpec6_crypto_prepare_crypto(struct skcipher_request *areq);\nstatic int artpec6_crypto_prepare_hash(struct ahash_request *areq);\n\nstatic void\nartpec6_crypto_complete_crypto(struct crypto_async_request *req);\nstatic void\nartpec6_crypto_complete_cbc_encrypt(struct crypto_async_request *req);\nstatic void\nartpec6_crypto_complete_cbc_decrypt(struct crypto_async_request *req);\nstatic void\nartpec6_crypto_complete_aead(struct crypto_async_request *req);\nstatic void\nartpec6_crypto_complete_hash(struct crypto_async_request *req);\n\nstatic int\nartpec6_crypto_common_destroy(struct artpec6_crypto_req_common *common);\n\nstatic void\nartpec6_crypto_start_dma(struct artpec6_crypto_req_common *common);\n\nstruct artpec6_crypto_walk {\n\tstruct scatterlist *sg;\n\tsize_t offset;\n};\n\nstatic void artpec6_crypto_walk_init(struct artpec6_crypto_walk *awalk,\n\t\t\t\t     struct scatterlist *sg)\n{\n\tawalk->sg = sg;\n\tawalk->offset = 0;\n}\n\nstatic size_t artpec6_crypto_walk_advance(struct artpec6_crypto_walk *awalk,\n\t\t\t\t\t  size_t nbytes)\n{\n\twhile (nbytes && awalk->sg) {\n\t\tsize_t piece;\n\n\t\tWARN_ON(awalk->offset > awalk->sg->length);\n\n\t\tpiece = min(nbytes, (size_t)awalk->sg->length - awalk->offset);\n\t\tnbytes -= piece;\n\t\tawalk->offset += piece;\n\t\tif (awalk->offset == awalk->sg->length) {\n\t\t\tawalk->sg = sg_next(awalk->sg);\n\t\t\tawalk->offset = 0;\n\t\t}\n\n\t}\n\n\treturn nbytes;\n}\n\nstatic size_t\nartpec6_crypto_walk_chunklen(const struct artpec6_crypto_walk *awalk)\n{\n\tWARN_ON(awalk->sg->length == awalk->offset);\n\n\treturn awalk->sg->length - awalk->offset;\n}\n\nstatic dma_addr_t\nartpec6_crypto_walk_chunk_phys(const struct artpec6_crypto_walk *awalk)\n{\n\treturn sg_phys(awalk->sg) + awalk->offset;\n}\n\nstatic void\nartpec6_crypto_copy_bounce_buffers(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct artpec6_crypto_bounce_buffer *b;\n\tstruct artpec6_crypto_bounce_buffer *next;\n\n\tlist_for_each_entry_safe(b, next, &dma->bounce_buffers, list) {\n\t\tpr_debug(\"bounce entry %p: %zu bytes @ %zu from %p\\n\",\n\t\t\t b, b->length, b->offset, b->buf);\n\t\tsg_pcopy_from_buffer(b->sg,\n\t\t\t\t   1,\n\t\t\t\t   b->buf,\n\t\t\t\t   b->length,\n\t\t\t\t   b->offset);\n\n\t\tlist_del(&b->list);\n\t\tkfree(b);\n\t}\n}\n\nstatic inline bool artpec6_crypto_busy(void)\n{\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tint fifo_count = ac->pending_count;\n\n\treturn fifo_count > 6;\n}\n\nstatic int artpec6_crypto_submit(struct artpec6_crypto_req_common *req)\n{\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tint ret = -EBUSY;\n\n\tspin_lock_bh(&ac->queue_lock);\n\n\tif (!artpec6_crypto_busy()) {\n\t\tlist_add_tail(&req->list, &ac->pending);\n\t\tartpec6_crypto_start_dma(req);\n\t\tret = -EINPROGRESS;\n\t} else if (req->req->flags & CRYPTO_TFM_REQ_MAY_BACKLOG) {\n\t\tlist_add_tail(&req->list, &ac->queue);\n\t} else {\n\t\tartpec6_crypto_common_destroy(req);\n\t}\n\n\tspin_unlock_bh(&ac->queue_lock);\n\n\treturn ret;\n}\n\nstatic void artpec6_crypto_start_dma(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tvoid __iomem *base = ac->base;\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tu32 ind, statd, outd;\n\n\t \n\twmb();\n\n\tind = FIELD_PREP(PDMA_IN_DESCRQ_PUSH_LEN, dma->in_cnt - 1) |\n\t      FIELD_PREP(PDMA_IN_DESCRQ_PUSH_ADDR, dma->in_dma_addr >> 6);\n\n\tstatd = FIELD_PREP(PDMA_IN_STATQ_PUSH_LEN, dma->in_cnt - 1) |\n\t\tFIELD_PREP(PDMA_IN_STATQ_PUSH_ADDR, dma->stat_dma_addr >> 6);\n\n\toutd = FIELD_PREP(PDMA_OUT_DESCRQ_PUSH_LEN, dma->out_cnt - 1) |\n\t       FIELD_PREP(PDMA_OUT_DESCRQ_PUSH_ADDR, dma->out_dma_addr >> 6);\n\n\tif (variant == ARTPEC6_CRYPTO) {\n\t\twritel_relaxed(ind, base + A6_PDMA_IN_DESCRQ_PUSH);\n\t\twritel_relaxed(statd, base + A6_PDMA_IN_STATQ_PUSH);\n\t\twritel_relaxed(PDMA_IN_CMD_START, base + A6_PDMA_IN_CMD);\n\t} else {\n\t\twritel_relaxed(ind, base + A7_PDMA_IN_DESCRQ_PUSH);\n\t\twritel_relaxed(statd, base + A7_PDMA_IN_STATQ_PUSH);\n\t\twritel_relaxed(PDMA_IN_CMD_START, base + A7_PDMA_IN_CMD);\n\t}\n\n\twritel_relaxed(outd, base + PDMA_OUT_DESCRQ_PUSH);\n\twritel_relaxed(PDMA_OUT_CMD_START, base + PDMA_OUT_CMD);\n\n\tac->pending_count++;\n}\n\nstatic void\nartpec6_crypto_init_dma_operation(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\n\tdma->out_cnt = 0;\n\tdma->in_cnt = 0;\n\tdma->map_count = 0;\n\tINIT_LIST_HEAD(&dma->bounce_buffers);\n}\n\nstatic bool fault_inject_dma_descr(void)\n{\n#ifdef CONFIG_FAULT_INJECTION\n\treturn should_fail(&artpec6_crypto_fail_dma_array_full, 1);\n#else\n\treturn false;\n#endif\n}\n\n \nstatic int\nartpec6_crypto_setup_out_descr_phys(struct artpec6_crypto_req_common *common,\n\t\t\t\t    dma_addr_t addr, size_t len, bool eop)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct pdma_descr *d;\n\n\tif (dma->out_cnt >= PDMA_DESCR_COUNT ||\n\t    fault_inject_dma_descr()) {\n\t\tpr_err(\"No free OUT DMA descriptors available!\\n\");\n\t\treturn -ENOSPC;\n\t}\n\n\td = &dma->out[dma->out_cnt++];\n\tmemset(d, 0, sizeof(*d));\n\n\td->ctrl.short_descr = 0;\n\td->ctrl.eop = eop;\n\td->data.len = len;\n\td->data.buf = addr;\n\treturn 0;\n}\n\n \nstatic int\nartpec6_crypto_setup_out_descr_short(struct artpec6_crypto_req_common *common,\n\t\t\t\t     void *dst, unsigned int len, bool eop)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct pdma_descr *d;\n\n\tif (dma->out_cnt >= PDMA_DESCR_COUNT ||\n\t    fault_inject_dma_descr()) {\n\t\tpr_err(\"No free OUT DMA descriptors available!\\n\");\n\t\treturn -ENOSPC;\n\t} else if (len > 7 || len < 1) {\n\t\treturn -EINVAL;\n\t}\n\td = &dma->out[dma->out_cnt++];\n\tmemset(d, 0, sizeof(*d));\n\n\td->ctrl.short_descr = 1;\n\td->ctrl.short_len = len;\n\td->ctrl.eop = eop;\n\tmemcpy(d->shrt.data, dst, len);\n\treturn 0;\n}\n\nstatic int artpec6_crypto_dma_map_page(struct artpec6_crypto_req_common *common,\n\t\t\t\t      struct page *page, size_t offset,\n\t\t\t\t      size_t size,\n\t\t\t\t      enum dma_data_direction dir,\n\t\t\t\t      dma_addr_t *dma_addr_out)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct device *dev = artpec6_crypto_dev;\n\tstruct artpec6_crypto_dma_map *map;\n\tdma_addr_t dma_addr;\n\n\t*dma_addr_out = 0;\n\n\tif (dma->map_count >= ARRAY_SIZE(dma->maps))\n\t\treturn -ENOMEM;\n\n\tdma_addr = dma_map_page(dev, page, offset, size, dir);\n\tif (dma_mapping_error(dev, dma_addr))\n\t\treturn -ENOMEM;\n\n\tmap = &dma->maps[dma->map_count++];\n\tmap->size = size;\n\tmap->dma_addr = dma_addr;\n\tmap->dir = dir;\n\n\t*dma_addr_out = dma_addr;\n\n\treturn 0;\n}\n\nstatic int\nartpec6_crypto_dma_map_single(struct artpec6_crypto_req_common *common,\n\t\t\t      void *ptr, size_t size,\n\t\t\t      enum dma_data_direction dir,\n\t\t\t      dma_addr_t *dma_addr_out)\n{\n\tstruct page *page = virt_to_page(ptr);\n\tsize_t offset = (uintptr_t)ptr & ~PAGE_MASK;\n\n\treturn artpec6_crypto_dma_map_page(common, page, offset, size, dir,\n\t\t\t\t\t  dma_addr_out);\n}\n\nstatic int\nartpec6_crypto_dma_map_descs(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tint ret;\n\n\tret = artpec6_crypto_dma_map_single(common, dma->in,\n\t\t\t\tsizeof(dma->in[0]) * dma->in_cnt,\n\t\t\t\tDMA_TO_DEVICE, &dma->in_dma_addr);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_dma_map_single(common, dma->out,\n\t\t\t\tsizeof(dma->out[0]) * dma->out_cnt,\n\t\t\t\tDMA_TO_DEVICE, &dma->out_dma_addr);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tdma->stat[dma->in_cnt - 1] = 0;\n\n\t \n\treturn artpec6_crypto_dma_map_single(common,\n\t\t\t\tdma->stat,\n\t\t\t\tsizeof(dma->stat[0]) * dma->in_cnt,\n\t\t\t\tDMA_BIDIRECTIONAL,\n\t\t\t\t&dma->stat_dma_addr);\n}\n\nstatic void\nartpec6_crypto_dma_unmap_all(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct device *dev = artpec6_crypto_dev;\n\tint i;\n\n\tfor (i = 0; i < dma->map_count; i++) {\n\t\tstruct artpec6_crypto_dma_map *map = &dma->maps[i];\n\n\t\tdma_unmap_page(dev, map->dma_addr, map->size, map->dir);\n\t}\n\n\tdma->map_count = 0;\n}\n\n \nstatic int\nartpec6_crypto_setup_out_descr(struct artpec6_crypto_req_common *common,\n\t\t\t       void *dst, unsigned int len, bool eop,\n\t\t\t       bool use_short)\n{\n\tif (use_short && len < 7) {\n\t\treturn artpec6_crypto_setup_out_descr_short(common, dst, len,\n\t\t\t\t\t\t\t    eop);\n\t} else {\n\t\tint ret;\n\t\tdma_addr_t dma_addr;\n\n\t\tret = artpec6_crypto_dma_map_single(common, dst, len,\n\t\t\t\t\t\t   DMA_TO_DEVICE,\n\t\t\t\t\t\t   &dma_addr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\treturn artpec6_crypto_setup_out_descr_phys(common, dma_addr,\n\t\t\t\t\t\t\t   len, eop);\n\t}\n}\n\n \nstatic int\nartpec6_crypto_setup_in_descr_phys(struct artpec6_crypto_req_common *common,\n\t\t\t       dma_addr_t addr, unsigned int len, bool intr)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct pdma_descr *d;\n\n\tif (dma->in_cnt >= PDMA_DESCR_COUNT ||\n\t    fault_inject_dma_descr()) {\n\t\tpr_err(\"No free IN DMA descriptors available!\\n\");\n\t\treturn -ENOSPC;\n\t}\n\td = &dma->in[dma->in_cnt++];\n\tmemset(d, 0, sizeof(*d));\n\n\td->ctrl.intr = intr;\n\td->data.len = len;\n\td->data.buf = addr;\n\treturn 0;\n}\n\n \nstatic int\nartpec6_crypto_setup_in_descr(struct artpec6_crypto_req_common *common,\n\t\t\t  void *buffer, unsigned int len, bool last)\n{\n\tdma_addr_t dma_addr;\n\tint ret;\n\n\tret = artpec6_crypto_dma_map_single(common, buffer, len,\n\t\t\t\t\t   DMA_FROM_DEVICE, &dma_addr);\n\tif (ret)\n\t\treturn ret;\n\n\treturn artpec6_crypto_setup_in_descr_phys(common, dma_addr, len, last);\n}\n\nstatic struct artpec6_crypto_bounce_buffer *\nartpec6_crypto_alloc_bounce(gfp_t flags)\n{\n\tvoid *base;\n\tsize_t alloc_size = sizeof(struct artpec6_crypto_bounce_buffer) +\n\t\t\t    2 * ARTPEC_CACHE_LINE_MAX;\n\tstruct artpec6_crypto_bounce_buffer *bbuf = kzalloc(alloc_size, flags);\n\n\tif (!bbuf)\n\t\treturn NULL;\n\n\tbase = bbuf + 1;\n\tbbuf->buf = PTR_ALIGN(base, ARTPEC_CACHE_LINE_MAX);\n\treturn bbuf;\n}\n\nstatic int setup_bounce_buffer_in(struct artpec6_crypto_req_common *common,\n\t\t\t\t  struct artpec6_crypto_walk *walk, size_t size)\n{\n\tstruct artpec6_crypto_bounce_buffer *bbuf;\n\tint ret;\n\n\tbbuf = artpec6_crypto_alloc_bounce(common->gfp_flags);\n\tif (!bbuf)\n\t\treturn -ENOMEM;\n\n\tbbuf->length = size;\n\tbbuf->sg = walk->sg;\n\tbbuf->offset = walk->offset;\n\n\tret =  artpec6_crypto_setup_in_descr(common, bbuf->buf, size, false);\n\tif (ret) {\n\t\tkfree(bbuf);\n\t\treturn ret;\n\t}\n\n\tpr_debug(\"BOUNCE %zu offset %zu\\n\", size, walk->offset);\n\tlist_add_tail(&bbuf->list, &common->dma->bounce_buffers);\n\treturn 0;\n}\n\nstatic int\nartpec6_crypto_setup_sg_descrs_in(struct artpec6_crypto_req_common *common,\n\t\t\t\t  struct artpec6_crypto_walk *walk,\n\t\t\t\t  size_t count)\n{\n\tsize_t chunk;\n\tint ret;\n\tdma_addr_t addr;\n\n\twhile (walk->sg && count) {\n\t\tchunk = min(count, artpec6_crypto_walk_chunklen(walk));\n\t\taddr = artpec6_crypto_walk_chunk_phys(walk);\n\n\t\t \n\t\tif (!IS_ALIGNED(addr, ARTPEC_CACHE_LINE_MAX)) {\n\t\t\tchunk = min_t(dma_addr_t, chunk,\n\t\t\t\t      ALIGN(addr, ARTPEC_CACHE_LINE_MAX) -\n\t\t\t\t      addr);\n\n\t\t\tpr_debug(\"CHUNK-b %pad:%zu\\n\", &addr, chunk);\n\t\t\tret = setup_bounce_buffer_in(common, walk, chunk);\n\t\t} else if (chunk < ARTPEC_CACHE_LINE_MAX) {\n\t\t\tpr_debug(\"CHUNK-b %pad:%zu\\n\", &addr, chunk);\n\t\t\tret = setup_bounce_buffer_in(common, walk, chunk);\n\t\t} else {\n\t\t\tdma_addr_t dma_addr;\n\n\t\t\tchunk = chunk & ~(ARTPEC_CACHE_LINE_MAX-1);\n\n\t\t\tpr_debug(\"CHUNK %pad:%zu\\n\", &addr, chunk);\n\n\t\t\tret = artpec6_crypto_dma_map_page(common,\n\t\t\t\t\t\t\t sg_page(walk->sg),\n\t\t\t\t\t\t\t walk->sg->offset +\n\t\t\t\t\t\t\t walk->offset,\n\t\t\t\t\t\t\t chunk,\n\t\t\t\t\t\t\t DMA_FROM_DEVICE,\n\t\t\t\t\t\t\t &dma_addr);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tret = artpec6_crypto_setup_in_descr_phys(common,\n\t\t\t\t\t\t\t\t dma_addr,\n\t\t\t\t\t\t\t\t chunk, false);\n\t\t}\n\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tcount = count - chunk;\n\t\tartpec6_crypto_walk_advance(walk, chunk);\n\t}\n\n\tif (count)\n\t\tpr_err(\"EOL unexpected %zu bytes left\\n\", count);\n\n\treturn count ? -EINVAL : 0;\n}\n\nstatic int\nartpec6_crypto_setup_sg_descrs_out(struct artpec6_crypto_req_common *common,\n\t\t\t\t   struct artpec6_crypto_walk *walk,\n\t\t\t\t   size_t count)\n{\n\tsize_t chunk;\n\tint ret;\n\tdma_addr_t addr;\n\n\twhile (walk->sg && count) {\n\t\tchunk = min(count, artpec6_crypto_walk_chunklen(walk));\n\t\taddr = artpec6_crypto_walk_chunk_phys(walk);\n\n\t\tpr_debug(\"OUT-CHUNK %pad:%zu\\n\", &addr, chunk);\n\n\t\tif (addr & 3) {\n\t\t\tchar buf[3];\n\n\t\t\tchunk = min_t(size_t, chunk, (4-(addr&3)));\n\n\t\t\tsg_pcopy_to_buffer(walk->sg, 1, buf, chunk,\n\t\t\t\t\t   walk->offset);\n\n\t\t\tret = artpec6_crypto_setup_out_descr_short(common, buf,\n\t\t\t\t\t\t\t\t   chunk,\n\t\t\t\t\t\t\t\t   false);\n\t\t} else {\n\t\t\tdma_addr_t dma_addr;\n\n\t\t\tret = artpec6_crypto_dma_map_page(common,\n\t\t\t\t\t\t\t sg_page(walk->sg),\n\t\t\t\t\t\t\t walk->sg->offset +\n\t\t\t\t\t\t\t walk->offset,\n\t\t\t\t\t\t\t chunk,\n\t\t\t\t\t\t\t DMA_TO_DEVICE,\n\t\t\t\t\t\t\t &dma_addr);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tret = artpec6_crypto_setup_out_descr_phys(common,\n\t\t\t\t\t\t\t\t dma_addr,\n\t\t\t\t\t\t\t\t chunk, false);\n\t\t}\n\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tcount = count - chunk;\n\t\tartpec6_crypto_walk_advance(walk, chunk);\n\t}\n\n\tif (count)\n\t\tpr_err(\"EOL unexpected %zu bytes left\\n\", count);\n\n\treturn count ? -EINVAL : 0;\n}\n\n\n \nstatic int\nartpec6_crypto_terminate_out_descrs(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct pdma_descr *d;\n\n\tif (!dma->out_cnt || dma->out_cnt > PDMA_DESCR_COUNT) {\n\t\tpr_err(\"%s: OUT descriptor list is %s\\n\",\n\t\t\tMODULE_NAME, dma->out_cnt ? \"empty\" : \"full\");\n\t\treturn -EINVAL;\n\n\t}\n\n\td = &dma->out[dma->out_cnt-1];\n\td->ctrl.eop = 1;\n\n\treturn 0;\n}\n\n \nstatic int\nartpec6_crypto_terminate_in_descrs(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto_dma_descriptors *dma = common->dma;\n\tstruct pdma_descr *d;\n\n\tif (!dma->in_cnt || dma->in_cnt > PDMA_DESCR_COUNT) {\n\t\tpr_err(\"%s: IN descriptor list is %s\\n\",\n\t\t\tMODULE_NAME, dma->in_cnt ? \"empty\" : \"full\");\n\t\treturn -EINVAL;\n\t}\n\n\td = &dma->in[dma->in_cnt-1];\n\td->ctrl.intr = 1;\n\treturn 0;\n}\n\n \nstatic size_t\ncreate_hash_pad(int oper, unsigned char *dst, u64 dgstlen, u64 bitcount)\n{\n\tunsigned int mod, target, diff, pad_bytes, size_bytes;\n\t__be64 bits = __cpu_to_be64(bitcount);\n\n\tswitch (oper) {\n\tcase regk_crypto_sha1:\n\tcase regk_crypto_sha256:\n\tcase regk_crypto_hmac_sha1:\n\tcase regk_crypto_hmac_sha256:\n\t\ttarget = 448 / 8;\n\t\tmod = 512 / 8;\n\t\tsize_bytes = 8;\n\t\tbreak;\n\tdefault:\n\t\ttarget = 896 / 8;\n\t\tmod = 1024 / 8;\n\t\tsize_bytes = 16;\n\t\tbreak;\n\t}\n\n\ttarget -= 1;\n\tdiff = dgstlen & (mod - 1);\n\tpad_bytes = diff > target ? target + mod - diff : target - diff;\n\n\tmemset(dst + 1, 0, pad_bytes);\n\tdst[0] = 0x80;\n\n\tif (size_bytes == 16) {\n\t\tmemset(dst + 1 + pad_bytes, 0, 8);\n\t\tmemcpy(dst + 1 + pad_bytes + 8, &bits, 8);\n\t} else {\n\t\tmemcpy(dst + 1 + pad_bytes, &bits, 8);\n\t}\n\n\treturn pad_bytes + size_bytes + 1;\n}\n\nstatic int artpec6_crypto_common_init(struct artpec6_crypto_req_common *common,\n\t\tstruct crypto_async_request *parent,\n\t\tvoid (*complete)(struct crypto_async_request *req),\n\t\tstruct scatterlist *dstsg, unsigned int nbytes)\n{\n\tgfp_t flags;\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\n\tflags = (parent->flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?\n\t\t GFP_KERNEL : GFP_ATOMIC;\n\n\tcommon->gfp_flags = flags;\n\tcommon->dma = kmem_cache_alloc(ac->dma_cache, flags);\n\tif (!common->dma)\n\t\treturn -ENOMEM;\n\n\tcommon->req = parent;\n\tcommon->complete = complete;\n\treturn 0;\n}\n\nstatic void\nartpec6_crypto_bounce_destroy(struct artpec6_crypto_dma_descriptors *dma)\n{\n\tstruct artpec6_crypto_bounce_buffer *b;\n\tstruct artpec6_crypto_bounce_buffer *next;\n\n\tlist_for_each_entry_safe(b, next, &dma->bounce_buffers, list) {\n\t\tkfree(b);\n\t}\n}\n\nstatic int\nartpec6_crypto_common_destroy(struct artpec6_crypto_req_common *common)\n{\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\n\tartpec6_crypto_dma_unmap_all(common);\n\tartpec6_crypto_bounce_destroy(common->dma);\n\tkmem_cache_free(ac->dma_cache, common->dma);\n\tcommon->dma = NULL;\n\treturn 0;\n}\n\n \nstatic int artpec6_crypto_encrypt(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *cipher = crypto_skcipher_reqtfm(req);\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(cipher);\n\tstruct artpec6_crypto_request_context *req_ctx = NULL;\n\tvoid (*complete)(struct crypto_async_request *req);\n\tint ret;\n\n\treq_ctx = skcipher_request_ctx(req);\n\n\tswitch (ctx->crypto_type) {\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_CBC:\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_ECB:\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_XTS:\n\t\treq_ctx->decrypt = 0;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tswitch (ctx->crypto_type) {\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_CBC:\n\t\tcomplete = artpec6_crypto_complete_cbc_encrypt;\n\t\tbreak;\n\tdefault:\n\t\tcomplete = artpec6_crypto_complete_crypto;\n\t\tbreak;\n\t}\n\n\tret = artpec6_crypto_common_init(&req_ctx->common,\n\t\t\t\t  &req->base,\n\t\t\t\t  complete,\n\t\t\t\t  req->dst, req->cryptlen);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_prepare_crypto(req);\n\tif (ret) {\n\t\tartpec6_crypto_common_destroy(&req_ctx->common);\n\t\treturn ret;\n\t}\n\n\treturn artpec6_crypto_submit(&req_ctx->common);\n}\n\nstatic int artpec6_crypto_decrypt(struct skcipher_request *req)\n{\n\tint ret;\n\tstruct crypto_skcipher *cipher = crypto_skcipher_reqtfm(req);\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(cipher);\n\tstruct artpec6_crypto_request_context *req_ctx = NULL;\n\tvoid (*complete)(struct crypto_async_request *req);\n\n\treq_ctx = skcipher_request_ctx(req);\n\n\tswitch (ctx->crypto_type) {\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_CBC:\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_ECB:\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_XTS:\n\t\treq_ctx->decrypt = 1;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\n\tswitch (ctx->crypto_type) {\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_CBC:\n\t\tcomplete = artpec6_crypto_complete_cbc_decrypt;\n\t\tbreak;\n\tdefault:\n\t\tcomplete = artpec6_crypto_complete_crypto;\n\t\tbreak;\n\t}\n\n\tret = artpec6_crypto_common_init(&req_ctx->common, &req->base,\n\t\t\t\t  complete,\n\t\t\t\t  req->dst, req->cryptlen);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_prepare_crypto(req);\n\tif (ret) {\n\t\tartpec6_crypto_common_destroy(&req_ctx->common);\n\t\treturn ret;\n\t}\n\n\treturn artpec6_crypto_submit(&req_ctx->common);\n}\n\nstatic int\nartpec6_crypto_ctr_crypt(struct skcipher_request *req, bool encrypt)\n{\n\tstruct crypto_skcipher *cipher = crypto_skcipher_reqtfm(req);\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(cipher);\n\tsize_t iv_len = crypto_skcipher_ivsize(cipher);\n\tunsigned int counter = be32_to_cpup((__be32 *)\n\t\t\t\t\t    (req->iv + iv_len - 4));\n\tunsigned int nblks = ALIGN(req->cryptlen, AES_BLOCK_SIZE) /\n\t\t\t     AES_BLOCK_SIZE;\n\n\t \n\tif (counter + nblks < counter) {\n\t\tint ret;\n\n\t\tpr_debug(\"counter %x will overflow (nblks %u), falling back\\n\",\n\t\t\t counter, counter + nblks);\n\n\t\tret = crypto_sync_skcipher_setkey(ctx->fallback, ctx->aes_key,\n\t\t\t\t\t\t  ctx->key_length);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t{\n\t\t\tSYNC_SKCIPHER_REQUEST_ON_STACK(subreq, ctx->fallback);\n\n\t\t\tskcipher_request_set_sync_tfm(subreq, ctx->fallback);\n\t\t\tskcipher_request_set_callback(subreq, req->base.flags,\n\t\t\t\t\t\t      NULL, NULL);\n\t\t\tskcipher_request_set_crypt(subreq, req->src, req->dst,\n\t\t\t\t\t\t   req->cryptlen, req->iv);\n\t\t\tret = encrypt ? crypto_skcipher_encrypt(subreq)\n\t\t\t\t      : crypto_skcipher_decrypt(subreq);\n\t\t\tskcipher_request_zero(subreq);\n\t\t}\n\t\treturn ret;\n\t}\n\n\treturn encrypt ? artpec6_crypto_encrypt(req)\n\t\t       : artpec6_crypto_decrypt(req);\n}\n\nstatic int artpec6_crypto_ctr_encrypt(struct skcipher_request *req)\n{\n\treturn artpec6_crypto_ctr_crypt(req, true);\n}\n\nstatic int artpec6_crypto_ctr_decrypt(struct skcipher_request *req)\n{\n\treturn artpec6_crypto_ctr_crypt(req, false);\n}\n\n \nstatic int artpec6_crypto_aead_init(struct crypto_aead *tfm)\n{\n\tstruct artpec6_cryptotfm_context *tfm_ctx = crypto_aead_ctx(tfm);\n\n\tmemset(tfm_ctx, 0, sizeof(*tfm_ctx));\n\n\tcrypto_aead_set_reqsize(tfm,\n\t\t\t\tsizeof(struct artpec6_crypto_aead_req_ctx));\n\n\treturn 0;\n}\n\nstatic int artpec6_crypto_aead_set_key(struct crypto_aead *tfm, const u8 *key,\n\t\t\t       unsigned int len)\n{\n\tstruct artpec6_cryptotfm_context *ctx = crypto_tfm_ctx(&tfm->base);\n\n\tif (len != 16 && len != 24 && len != 32)\n\t\treturn -EINVAL;\n\n\tctx->key_length = len;\n\n\tmemcpy(ctx->aes_key, key, len);\n\treturn 0;\n}\n\nstatic int artpec6_crypto_aead_encrypt(struct aead_request *req)\n{\n\tint ret;\n\tstruct artpec6_crypto_aead_req_ctx *req_ctx = aead_request_ctx(req);\n\n\treq_ctx->decrypt = false;\n\tret = artpec6_crypto_common_init(&req_ctx->common, &req->base,\n\t\t\t\t  artpec6_crypto_complete_aead,\n\t\t\t\t  NULL, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_prepare_aead(req);\n\tif (ret) {\n\t\tartpec6_crypto_common_destroy(&req_ctx->common);\n\t\treturn ret;\n\t}\n\n\treturn artpec6_crypto_submit(&req_ctx->common);\n}\n\nstatic int artpec6_crypto_aead_decrypt(struct aead_request *req)\n{\n\tint ret;\n\tstruct artpec6_crypto_aead_req_ctx *req_ctx = aead_request_ctx(req);\n\n\treq_ctx->decrypt = true;\n\tif (req->cryptlen < AES_BLOCK_SIZE)\n\t\treturn -EINVAL;\n\n\tret = artpec6_crypto_common_init(&req_ctx->common,\n\t\t\t\t  &req->base,\n\t\t\t\t  artpec6_crypto_complete_aead,\n\t\t\t\t  NULL, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_prepare_aead(req);\n\tif (ret) {\n\t\tartpec6_crypto_common_destroy(&req_ctx->common);\n\t\treturn ret;\n\t}\n\n\treturn artpec6_crypto_submit(&req_ctx->common);\n}\n\nstatic int artpec6_crypto_prepare_hash(struct ahash_request *areq)\n{\n\tstruct artpec6_hashalg_context *ctx = crypto_tfm_ctx(areq->base.tfm);\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(areq);\n\tsize_t digestsize = crypto_ahash_digestsize(crypto_ahash_reqtfm(areq));\n\tsize_t contextsize = digestsize;\n\tsize_t blocksize = crypto_tfm_alg_blocksize(\n\t\tcrypto_ahash_tfm(crypto_ahash_reqtfm(areq)));\n\tstruct artpec6_crypto_req_common *common = &req_ctx->common;\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tu32 sel_ctx;\n\tbool ext_ctx = false;\n\tbool run_hw = false;\n\tint error = 0;\n\n\tartpec6_crypto_init_dma_operation(common);\n\n\t \n\tif (req_ctx->hash_flags & HASH_FLAG_HMAC) {\n\t\tif (variant == ARTPEC6_CRYPTO) {\n\t\t\treq_ctx->key_md = FIELD_PREP(A6_CRY_MD_OPER,\n\t\t\t\t\t\t     a6_regk_crypto_dlkey);\n\t\t} else {\n\t\t\treq_ctx->key_md = FIELD_PREP(A7_CRY_MD_OPER,\n\t\t\t\t\t\t     a7_regk_crypto_dlkey);\n\t\t}\n\n\t\t \n\t\tmemcpy(req_ctx->key_buffer, ctx->hmac_key,\n\t\t       ctx->hmac_key_length);\n\t\tmemset(req_ctx->key_buffer + ctx->hmac_key_length, 0,\n\t\t       blocksize - ctx->hmac_key_length);\n\n\t\terror = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t(void *)&req_ctx->key_md,\n\t\t\t\t\tsizeof(req_ctx->key_md), false, false);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\terror = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\treq_ctx->key_buffer, blocksize,\n\t\t\t\t\ttrue, false);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\tif (!(req_ctx->hash_flags & HASH_FLAG_INIT_CTX)) {\n\t\t \n\t\tsel_ctx = regk_crypto_ext;\n\t\text_ctx = true;\n\t} else {\n\t\tsel_ctx = regk_crypto_init;\n\t}\n\n\tif (variant == ARTPEC6_CRYPTO) {\n\t\treq_ctx->hash_md &= ~A6_CRY_MD_HASH_SEL_CTX;\n\t\treq_ctx->hash_md |= FIELD_PREP(A6_CRY_MD_HASH_SEL_CTX, sel_ctx);\n\n\t\t \n\t\tif (req_ctx->hash_flags & HASH_FLAG_FINALIZE)\n\t\t\treq_ctx->hash_md |= A6_CRY_MD_HASH_HMAC_FIN;\n\t} else {\n\t\treq_ctx->hash_md &= ~A7_CRY_MD_HASH_SEL_CTX;\n\t\treq_ctx->hash_md |= FIELD_PREP(A7_CRY_MD_HASH_SEL_CTX, sel_ctx);\n\n\t\t \n\t\tif (req_ctx->hash_flags & HASH_FLAG_FINALIZE)\n\t\t\treq_ctx->hash_md |= A7_CRY_MD_HASH_HMAC_FIN;\n\t}\n\n\t \n\terror = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t(void *)&req_ctx->hash_md,\n\t\t\t\tsizeof(req_ctx->hash_md), false, false);\n\tif (error)\n\t\treturn error;\n\n\terror = artpec6_crypto_setup_in_descr(common, ac->pad_buffer, 4, false);\n\tif (error)\n\t\treturn error;\n\n\tif (ext_ctx) {\n\t\terror = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\treq_ctx->digeststate,\n\t\t\t\t\tcontextsize, false, false);\n\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\tif (req_ctx->hash_flags & HASH_FLAG_UPDATE) {\n\t\tsize_t done_bytes = 0;\n\t\tsize_t total_bytes = areq->nbytes + req_ctx->partial_bytes;\n\t\tsize_t ready_bytes = round_down(total_bytes, blocksize);\n\t\tstruct artpec6_crypto_walk walk;\n\n\t\trun_hw = ready_bytes > 0;\n\t\tif (req_ctx->partial_bytes && ready_bytes) {\n\t\t\t \n\t\t\tmemcpy(req_ctx->partial_buffer_out,\n\t\t\t\treq_ctx->partial_buffer,\n\t\t\t\treq_ctx->partial_bytes);\n\n\t\t\terror = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t\treq_ctx->partial_buffer_out,\n\t\t\t\t\t\treq_ctx->partial_bytes,\n\t\t\t\t\t\tfalse, true);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\n\t\t\t \n\t\t\tdone_bytes += req_ctx->partial_bytes;\n\t\t\treq_ctx->partial_bytes = 0;\n\t\t}\n\n\t\tartpec6_crypto_walk_init(&walk, areq->src);\n\n\t\terror = artpec6_crypto_setup_sg_descrs_out(common, &walk,\n\t\t\t\t\t\t\t   ready_bytes -\n\t\t\t\t\t\t\t   done_bytes);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\tif (walk.sg) {\n\t\t\tsize_t sg_skip = ready_bytes - done_bytes;\n\t\t\tsize_t sg_rem = areq->nbytes - sg_skip;\n\n\t\t\tsg_pcopy_to_buffer(areq->src, sg_nents(areq->src),\n\t\t\t\t\t   req_ctx->partial_buffer +\n\t\t\t\t\t   req_ctx->partial_bytes,\n\t\t\t\t\t   sg_rem, sg_skip);\n\n\t\t\treq_ctx->partial_bytes += sg_rem;\n\t\t}\n\n\t\treq_ctx->digcnt += ready_bytes;\n\t\treq_ctx->hash_flags &= ~(HASH_FLAG_UPDATE);\n\t}\n\n\t \n\tif (req_ctx->hash_flags & HASH_FLAG_FINALIZE) {\n\t\tsize_t hash_pad_len;\n\t\tu64 digest_bits;\n\t\tu32 oper;\n\n\t\tif (variant == ARTPEC6_CRYPTO)\n\t\t\toper = FIELD_GET(A6_CRY_MD_OPER, req_ctx->hash_md);\n\t\telse\n\t\t\toper = FIELD_GET(A7_CRY_MD_OPER, req_ctx->hash_md);\n\n\t\t \n\t\tif (req_ctx->partial_bytes) {\n\t\t\tmemcpy(req_ctx->partial_buffer_out,\n\t\t\t       req_ctx->partial_buffer,\n\t\t\t       req_ctx->partial_bytes);\n\t\t\terror = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t\treq_ctx->partial_buffer_out,\n\t\t\t\t\t\treq_ctx->partial_bytes,\n\t\t\t\t\t\tfalse, true);\n\t\t\tif (error)\n\t\t\t\treturn error;\n\n\t\t\treq_ctx->digcnt += req_ctx->partial_bytes;\n\t\t\treq_ctx->partial_bytes = 0;\n\t\t}\n\n\t\tif (req_ctx->hash_flags & HASH_FLAG_HMAC)\n\t\t\tdigest_bits = 8 * (req_ctx->digcnt + blocksize);\n\t\telse\n\t\t\tdigest_bits = 8 * req_ctx->digcnt;\n\n\t\t \n\t\thash_pad_len = create_hash_pad(oper, req_ctx->pad_buffer,\n\t\t\t\t\t       req_ctx->digcnt, digest_bits);\n\t\terror = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t\t      req_ctx->pad_buffer,\n\t\t\t\t\t\t      hash_pad_len, false,\n\t\t\t\t\t\t      true);\n\t\treq_ctx->digcnt = 0;\n\n\t\tif (error)\n\t\t\treturn error;\n\n\t\t \n\t\terror = artpec6_crypto_setup_in_descr(common, areq->result,\n\t\t\t\t\t\t      digestsize,\n\t\t\t\t\t\t      true);\n\t\tif (error)\n\t\t\treturn error;\n\n\t} else {  \n\t\tif (!run_hw)\n\t\t\treturn ARTPEC6_CRYPTO_PREPARE_HASH_NO_START;\n\n\t\t \n\t\terror = artpec6_crypto_setup_in_descr(common,\n\t\t\t\t\t\t      req_ctx->digeststate,\n\t\t\t\t\t\t      contextsize, false);\n\t\tif (error)\n\t\t\treturn error;\n\t\t \n\t}\n\n\treq_ctx->hash_flags &= ~(HASH_FLAG_INIT_CTX | HASH_FLAG_UPDATE |\n\t\t\t\t HASH_FLAG_FINALIZE);\n\n\terror = artpec6_crypto_terminate_in_descrs(common);\n\tif (error)\n\t\treturn error;\n\n\terror = artpec6_crypto_terminate_out_descrs(common);\n\tif (error)\n\t\treturn error;\n\n\terror = artpec6_crypto_dma_map_descs(common);\n\tif (error)\n\t\treturn error;\n\n\treturn ARTPEC6_CRYPTO_PREPARE_HASH_START;\n}\n\n\nstatic int artpec6_crypto_aes_ecb_init(struct crypto_skcipher *tfm)\n{\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(tfm);\n\n\ttfm->reqsize = sizeof(struct artpec6_crypto_request_context);\n\tctx->crypto_type = ARTPEC6_CRYPTO_CIPHER_AES_ECB;\n\n\treturn 0;\n}\n\nstatic int artpec6_crypto_aes_ctr_init(struct crypto_skcipher *tfm)\n{\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(tfm);\n\n\tctx->fallback =\n\t\tcrypto_alloc_sync_skcipher(crypto_tfm_alg_name(&tfm->base),\n\t\t\t\t\t   0, CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(ctx->fallback))\n\t\treturn PTR_ERR(ctx->fallback);\n\n\ttfm->reqsize = sizeof(struct artpec6_crypto_request_context);\n\tctx->crypto_type = ARTPEC6_CRYPTO_CIPHER_AES_CTR;\n\n\treturn 0;\n}\n\nstatic int artpec6_crypto_aes_cbc_init(struct crypto_skcipher *tfm)\n{\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(tfm);\n\n\ttfm->reqsize = sizeof(struct artpec6_crypto_request_context);\n\tctx->crypto_type = ARTPEC6_CRYPTO_CIPHER_AES_CBC;\n\n\treturn 0;\n}\n\nstatic int artpec6_crypto_aes_xts_init(struct crypto_skcipher *tfm)\n{\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(tfm);\n\n\ttfm->reqsize = sizeof(struct artpec6_crypto_request_context);\n\tctx->crypto_type = ARTPEC6_CRYPTO_CIPHER_AES_XTS;\n\n\treturn 0;\n}\n\nstatic void artpec6_crypto_aes_exit(struct crypto_skcipher *tfm)\n{\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(tfm);\n\n\tmemset(ctx, 0, sizeof(*ctx));\n}\n\nstatic void artpec6_crypto_aes_ctr_exit(struct crypto_skcipher *tfm)\n{\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(tfm);\n\n\tcrypto_free_sync_skcipher(ctx->fallback);\n\tartpec6_crypto_aes_exit(tfm);\n}\n\nstatic int\nartpec6_crypto_cipher_set_key(struct crypto_skcipher *cipher, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct artpec6_cryptotfm_context *ctx =\n\t\tcrypto_skcipher_ctx(cipher);\n\n\tswitch (keylen) {\n\tcase 16:\n\tcase 24:\n\tcase 32:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->aes_key, key, keylen);\n\tctx->key_length = keylen;\n\treturn 0;\n}\n\nstatic int\nartpec6_crypto_xts_set_key(struct crypto_skcipher *cipher, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct artpec6_cryptotfm_context *ctx =\n\t\tcrypto_skcipher_ctx(cipher);\n\tint ret;\n\n\tret = xts_verify_key(cipher, key, keylen);\n\tif (ret)\n\t\treturn ret;\n\n\tswitch (keylen) {\n\tcase 32:\n\tcase 48:\n\tcase 64:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(ctx->aes_key, key, keylen);\n\tctx->key_length = keylen;\n\treturn 0;\n}\n\n \nstatic int artpec6_crypto_prepare_crypto(struct skcipher_request *areq)\n{\n\tint ret;\n\tstruct artpec6_crypto_walk walk;\n\tstruct crypto_skcipher *cipher = crypto_skcipher_reqtfm(areq);\n\tstruct artpec6_cryptotfm_context *ctx = crypto_skcipher_ctx(cipher);\n\tstruct artpec6_crypto_request_context *req_ctx = NULL;\n\tsize_t iv_len = crypto_skcipher_ivsize(cipher);\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tstruct artpec6_crypto_req_common *common;\n\tbool cipher_decr = false;\n\tsize_t cipher_klen;\n\tu32 cipher_len = 0;  \n\tu32 oper;\n\n\treq_ctx = skcipher_request_ctx(areq);\n\tcommon = &req_ctx->common;\n\n\tartpec6_crypto_init_dma_operation(common);\n\n\tif (variant == ARTPEC6_CRYPTO)\n\t\tctx->key_md = FIELD_PREP(A6_CRY_MD_OPER, a6_regk_crypto_dlkey);\n\telse\n\t\tctx->key_md = FIELD_PREP(A7_CRY_MD_OPER, a7_regk_crypto_dlkey);\n\n\tret = artpec6_crypto_setup_out_descr(common, (void *)&ctx->key_md,\n\t\t\t\t\t     sizeof(ctx->key_md), false, false);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_setup_out_descr(common, ctx->aes_key,\n\t\t\t\t\t      ctx->key_length, true, false);\n\tif (ret)\n\t\treturn ret;\n\n\treq_ctx->cipher_md = 0;\n\n\tif (ctx->crypto_type == ARTPEC6_CRYPTO_CIPHER_AES_XTS)\n\t\tcipher_klen = ctx->key_length/2;\n\telse\n\t\tcipher_klen =  ctx->key_length;\n\n\t \n\tswitch (cipher_klen) {\n\tcase 16:\n\t\tcipher_len = regk_crypto_key_128;\n\t\tbreak;\n\tcase 24:\n\t\tcipher_len = regk_crypto_key_192;\n\t\tbreak;\n\tcase 32:\n\t\tcipher_len = regk_crypto_key_256;\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s: Invalid key length %zu!\\n\",\n\t\t\tMODULE_NAME, ctx->key_length);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (ctx->crypto_type) {\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_ECB:\n\t\toper = regk_crypto_aes_ecb;\n\t\tcipher_decr = req_ctx->decrypt;\n\t\tbreak;\n\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_CBC:\n\t\toper = regk_crypto_aes_cbc;\n\t\tcipher_decr = req_ctx->decrypt;\n\t\tbreak;\n\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_CTR:\n\t\toper = regk_crypto_aes_ctr;\n\t\tcipher_decr = false;\n\t\tbreak;\n\n\tcase ARTPEC6_CRYPTO_CIPHER_AES_XTS:\n\t\toper = regk_crypto_aes_xts;\n\t\tcipher_decr = req_ctx->decrypt;\n\n\t\tif (variant == ARTPEC6_CRYPTO)\n\t\t\treq_ctx->cipher_md |= A6_CRY_MD_CIPHER_DSEQ;\n\t\telse\n\t\t\treq_ctx->cipher_md |= A7_CRY_MD_CIPHER_DSEQ;\n\t\tbreak;\n\n\tdefault:\n\t\tpr_err(\"%s: Invalid cipher mode %d!\\n\",\n\t\t\tMODULE_NAME, ctx->crypto_type);\n\t\treturn -EINVAL;\n\t}\n\n\tif (variant == ARTPEC6_CRYPTO) {\n\t\treq_ctx->cipher_md |= FIELD_PREP(A6_CRY_MD_OPER, oper);\n\t\treq_ctx->cipher_md |= FIELD_PREP(A6_CRY_MD_CIPHER_LEN,\n\t\t\t\t\t\t cipher_len);\n\t\tif (cipher_decr)\n\t\t\treq_ctx->cipher_md |= A6_CRY_MD_CIPHER_DECR;\n\t} else {\n\t\treq_ctx->cipher_md |= FIELD_PREP(A7_CRY_MD_OPER, oper);\n\t\treq_ctx->cipher_md |= FIELD_PREP(A7_CRY_MD_CIPHER_LEN,\n\t\t\t\t\t\t cipher_len);\n\t\tif (cipher_decr)\n\t\t\treq_ctx->cipher_md |= A7_CRY_MD_CIPHER_DECR;\n\t}\n\n\tret = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t    &req_ctx->cipher_md,\n\t\t\t\t\t    sizeof(req_ctx->cipher_md),\n\t\t\t\t\t    false, false);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_setup_in_descr(common, ac->pad_buffer, 4, false);\n\tif (ret)\n\t\treturn ret;\n\n\tif (iv_len) {\n\t\tret = artpec6_crypto_setup_out_descr(common, areq->iv, iv_len,\n\t\t\t\t\t\t     false, false);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\t \n\tartpec6_crypto_walk_init(&walk, areq->src);\n\tret = artpec6_crypto_setup_sg_descrs_out(common, &walk, areq->cryptlen);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tartpec6_crypto_walk_init(&walk, areq->dst);\n\tret = artpec6_crypto_setup_sg_descrs_in(common, &walk, areq->cryptlen);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (ctx->crypto_type == ARTPEC6_CRYPTO_CIPHER_AES_CTR ||\n\t    ctx->crypto_type == ARTPEC6_CRYPTO_CIPHER_AES_XTS) {\n\t\tsize_t pad = ALIGN(areq->cryptlen, AES_BLOCK_SIZE) -\n\t\t\t     areq->cryptlen;\n\n\t\tif (pad) {\n\t\t\tret = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t\t\t     ac->pad_buffer,\n\t\t\t\t\t\t\t     pad, false, false);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tret = artpec6_crypto_setup_in_descr(common,\n\t\t\t\t\t\t\t    ac->pad_buffer, pad,\n\t\t\t\t\t\t\t    false);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = artpec6_crypto_terminate_out_descrs(common);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_terminate_in_descrs(common);\n\tif (ret)\n\t\treturn ret;\n\n\treturn artpec6_crypto_dma_map_descs(common);\n}\n\nstatic int artpec6_crypto_prepare_aead(struct aead_request *areq)\n{\n\tsize_t count;\n\tint ret;\n\tsize_t input_length;\n\tstruct artpec6_cryptotfm_context *ctx = crypto_tfm_ctx(areq->base.tfm);\n\tstruct artpec6_crypto_aead_req_ctx *req_ctx = aead_request_ctx(areq);\n\tstruct crypto_aead *cipher = crypto_aead_reqtfm(areq);\n\tstruct artpec6_crypto_req_common *common = &req_ctx->common;\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tu32 md_cipher_len;\n\n\tartpec6_crypto_init_dma_operation(common);\n\n\t \n\tif (variant == ARTPEC6_CRYPTO) {\n\t\tctx->key_md = FIELD_PREP(A6_CRY_MD_OPER,\n\t\t\t\t\t a6_regk_crypto_dlkey);\n\t} else {\n\t\tctx->key_md = FIELD_PREP(A7_CRY_MD_OPER,\n\t\t\t\t\t a7_regk_crypto_dlkey);\n\t}\n\tret = artpec6_crypto_setup_out_descr(common, (void *)&ctx->key_md,\n\t\t\t\t\t     sizeof(ctx->key_md), false, false);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_setup_out_descr(common, ctx->aes_key,\n\t\t\t\t\t     ctx->key_length, true, false);\n\tif (ret)\n\t\treturn ret;\n\n\treq_ctx->cipher_md = 0;\n\n\tswitch (ctx->key_length) {\n\tcase 16:\n\t\tmd_cipher_len = regk_crypto_key_128;\n\t\tbreak;\n\tcase 24:\n\t\tmd_cipher_len = regk_crypto_key_192;\n\t\tbreak;\n\tcase 32:\n\t\tmd_cipher_len = regk_crypto_key_256;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (variant == ARTPEC6_CRYPTO) {\n\t\treq_ctx->cipher_md |= FIELD_PREP(A6_CRY_MD_OPER,\n\t\t\t\t\t\t regk_crypto_aes_gcm);\n\t\treq_ctx->cipher_md |= FIELD_PREP(A6_CRY_MD_CIPHER_LEN,\n\t\t\t\t\t\t md_cipher_len);\n\t\tif (req_ctx->decrypt)\n\t\t\treq_ctx->cipher_md |= A6_CRY_MD_CIPHER_DECR;\n\t} else {\n\t\treq_ctx->cipher_md |= FIELD_PREP(A7_CRY_MD_OPER,\n\t\t\t\t\t\t regk_crypto_aes_gcm);\n\t\treq_ctx->cipher_md |= FIELD_PREP(A7_CRY_MD_CIPHER_LEN,\n\t\t\t\t\t\t md_cipher_len);\n\t\tif (req_ctx->decrypt)\n\t\t\treq_ctx->cipher_md |= A7_CRY_MD_CIPHER_DECR;\n\t}\n\n\tret = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t    (void *) &req_ctx->cipher_md,\n\t\t\t\t\t    sizeof(req_ctx->cipher_md), false,\n\t\t\t\t\t    false);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_setup_in_descr(common, ac->pad_buffer, 4, false);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tinput_length = areq->cryptlen;\n\tif (req_ctx->decrypt)\n\t\tinput_length -= crypto_aead_authsize(cipher);\n\n\t \n\treq_ctx->hw_ctx.aad_length_bits =\n\t\t__cpu_to_be64(8*areq->assoclen);\n\n\treq_ctx->hw_ctx.text_length_bits =\n\t\t__cpu_to_be64(8*input_length);\n\n\tmemcpy(req_ctx->hw_ctx.J0, areq->iv, crypto_aead_ivsize(cipher));\n\t\n\tmemcpy(req_ctx->hw_ctx.J0 + GCM_AES_IV_SIZE, \"\\x00\\x00\\x00\\x01\", 4);\n\n\tret = artpec6_crypto_setup_out_descr(common, &req_ctx->hw_ctx,\n\t\tsizeof(struct artpec6_crypto_aead_hw_ctx), false, false);\n\tif (ret)\n\t\treturn ret;\n\n\t{\n\t\tstruct artpec6_crypto_walk walk;\n\n\t\tartpec6_crypto_walk_init(&walk, areq->src);\n\n\t\t \n\t\tcount = areq->assoclen;\n\t\tret = artpec6_crypto_setup_sg_descrs_out(common, &walk, count);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!IS_ALIGNED(areq->assoclen, 16)) {\n\t\t\tsize_t assoc_pad = 16 - (areq->assoclen % 16);\n\t\t\t \n\t\t\tret = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t\t\t     ac->zero_buffer,\n\t\t\t\t\t\t\t     assoc_pad, false,\n\t\t\t\t\t\t\t     false);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tcount = input_length;\n\t\tret = artpec6_crypto_setup_sg_descrs_out(common, &walk, count);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!IS_ALIGNED(input_length, 16)) {\n\t\t\tsize_t crypto_pad = 16 - (input_length % 16);\n\t\t\t \n\t\t\tret = artpec6_crypto_setup_out_descr(common,\n\t\t\t\t\t\t\t     ac->zero_buffer,\n\t\t\t\t\t\t\t     crypto_pad,\n\t\t\t\t\t\t\t     false,\n\t\t\t\t\t\t\t     false);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\t{\n\t\tstruct artpec6_crypto_walk walk;\n\t\tsize_t output_len = areq->cryptlen;\n\n\t\tif (req_ctx->decrypt)\n\t\t\toutput_len -= crypto_aead_authsize(cipher);\n\n\t\tartpec6_crypto_walk_init(&walk, areq->dst);\n\n\t\t \n\t\tcount = artpec6_crypto_walk_advance(&walk, areq->assoclen);\n\t\tif (count)\n\t\t\treturn -EINVAL;\n\n\t\tcount = output_len;\n\t\tret = artpec6_crypto_setup_sg_descrs_in(common, &walk, count);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\tif (!IS_ALIGNED(output_len, 16)) {\n\t\t\tsize_t crypto_pad = 16 - (output_len % 16);\n\n\t\t\tret = artpec6_crypto_setup_in_descr(common,\n\t\t\t\t\t\t\t    ac->pad_buffer,\n\t\t\t\t\t\t\t    crypto_pad, false);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\t \n\n\t\tif (req_ctx->decrypt) {\n\t\t\tret = artpec6_crypto_setup_in_descr(common,\n\t\t\t\treq_ctx->decryption_tag, AES_BLOCK_SIZE, false);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t} else {\n\t\t\t \n\t\t\tsize_t authsize = crypto_aead_authsize(cipher);\n\n\t\t\tret = artpec6_crypto_setup_sg_descrs_in(common, &walk,\n\t\t\t\t\t\t\t\tauthsize);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tif (authsize < AES_BLOCK_SIZE) {\n\t\t\t\tcount = AES_BLOCK_SIZE - authsize;\n\t\t\t\tret = artpec6_crypto_setup_in_descr(common,\n\t\t\t\t\tac->pad_buffer,\n\t\t\t\t\tcount, false);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tret = artpec6_crypto_terminate_in_descrs(common);\n\tif (ret)\n\t\treturn ret;\n\n\tret = artpec6_crypto_terminate_out_descrs(common);\n\tif (ret)\n\t\treturn ret;\n\n\treturn artpec6_crypto_dma_map_descs(common);\n}\n\nstatic void artpec6_crypto_process_queue(struct artpec6_crypto *ac,\n\t    struct list_head *completions)\n{\n\tstruct artpec6_crypto_req_common *req;\n\n\twhile (!list_empty(&ac->queue) && !artpec6_crypto_busy()) {\n\t\treq = list_first_entry(&ac->queue,\n\t\t\t\t       struct artpec6_crypto_req_common,\n\t\t\t\t       list);\n\t\tlist_move_tail(&req->list, &ac->pending);\n\t\tartpec6_crypto_start_dma(req);\n\n\t\tlist_add_tail(&req->complete_in_progress, completions);\n\t}\n\n\t \n\tif (ac->pending_count)\n\t\tmod_timer(&ac->timer, jiffies + msecs_to_jiffies(100));\n\telse\n\t\tdel_timer(&ac->timer);\n}\n\nstatic void artpec6_crypto_timeout(struct timer_list *t)\n{\n\tstruct artpec6_crypto *ac = from_timer(ac, t, timer);\n\n\tdev_info_ratelimited(artpec6_crypto_dev, \"timeout\\n\");\n\n\ttasklet_schedule(&ac->task);\n}\n\nstatic void artpec6_crypto_task(unsigned long data)\n{\n\tstruct artpec6_crypto *ac = (struct artpec6_crypto *)data;\n\tstruct artpec6_crypto_req_common *req;\n\tstruct artpec6_crypto_req_common *n;\n\tstruct list_head complete_done;\n\tstruct list_head complete_in_progress;\n\n\tINIT_LIST_HEAD(&complete_done);\n\tINIT_LIST_HEAD(&complete_in_progress);\n\n\tif (list_empty(&ac->pending)) {\n\t\tpr_debug(\"Spurious IRQ\\n\");\n\t\treturn;\n\t}\n\n\tspin_lock(&ac->queue_lock);\n\n\tlist_for_each_entry_safe(req, n, &ac->pending, list) {\n\t\tstruct artpec6_crypto_dma_descriptors *dma = req->dma;\n\t\tu32 stat;\n\t\tdma_addr_t stataddr;\n\n\t\tstataddr = dma->stat_dma_addr + 4 * (req->dma->in_cnt - 1);\n\t\tdma_sync_single_for_cpu(artpec6_crypto_dev,\n\t\t\t\t\tstataddr,\n\t\t\t\t\t4,\n\t\t\t\t\tDMA_BIDIRECTIONAL);\n\n\t\tstat = req->dma->stat[req->dma->in_cnt-1];\n\n\t\t \n\t\tpr_debug(\"Request %p status is %X\\n\", req, stat);\n\t\tif (!stat)\n\t\t\tbreak;\n\n\t\t \n#ifdef CONFIG_FAULT_INJECTION\n\t\tif (should_fail(&artpec6_crypto_fail_status_read, 1))\n\t\t\tcontinue;\n#endif\n\n\t\tpr_debug(\"Completing request %p\\n\", req);\n\n\t\tlist_move_tail(&req->list, &complete_done);\n\n\t\tac->pending_count--;\n\t}\n\n\tartpec6_crypto_process_queue(ac, &complete_in_progress);\n\n\tspin_unlock(&ac->queue_lock);\n\n\t \n\tlist_for_each_entry_safe(req, n, &complete_done, list) {\n\t\tartpec6_crypto_dma_unmap_all(req);\n\t\tartpec6_crypto_copy_bounce_buffers(req);\n\t\tartpec6_crypto_common_destroy(req);\n\n\t\treq->complete(req->req);\n\t}\n\n\tlist_for_each_entry_safe(req, n, &complete_in_progress,\n\t\t\t\t complete_in_progress) {\n\t\tcrypto_request_complete(req->req, -EINPROGRESS);\n\t}\n}\n\nstatic void artpec6_crypto_complete_crypto(struct crypto_async_request *req)\n{\n\tcrypto_request_complete(req, 0);\n}\n\nstatic void\nartpec6_crypto_complete_cbc_decrypt(struct crypto_async_request *req)\n{\n\tstruct skcipher_request *cipher_req = container_of(req,\n\t\tstruct skcipher_request, base);\n\n\tscatterwalk_map_and_copy(cipher_req->iv, cipher_req->src,\n\t\t\t\t cipher_req->cryptlen - AES_BLOCK_SIZE,\n\t\t\t\t AES_BLOCK_SIZE, 0);\n\tskcipher_request_complete(cipher_req, 0);\n}\n\nstatic void\nartpec6_crypto_complete_cbc_encrypt(struct crypto_async_request *req)\n{\n\tstruct skcipher_request *cipher_req = container_of(req,\n\t\tstruct skcipher_request, base);\n\n\tscatterwalk_map_and_copy(cipher_req->iv, cipher_req->dst,\n\t\t\t\t cipher_req->cryptlen - AES_BLOCK_SIZE,\n\t\t\t\t AES_BLOCK_SIZE, 0);\n\tskcipher_request_complete(cipher_req, 0);\n}\n\nstatic void artpec6_crypto_complete_aead(struct crypto_async_request *req)\n{\n\tint result = 0;\n\n\t \n\tstruct aead_request *areq = container_of(req,\n\t\tstruct aead_request, base);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(areq);\n\tstruct artpec6_crypto_aead_req_ctx *req_ctx = aead_request_ctx(areq);\n\n\tif (req_ctx->decrypt) {\n\t\tu8 input_tag[AES_BLOCK_SIZE];\n\t\tunsigned int authsize = crypto_aead_authsize(aead);\n\n\t\tsg_pcopy_to_buffer(areq->src,\n\t\t\t\t   sg_nents(areq->src),\n\t\t\t\t   input_tag,\n\t\t\t\t   authsize,\n\t\t\t\t   areq->assoclen + areq->cryptlen -\n\t\t\t\t   authsize);\n\n\t\tif (crypto_memneq(req_ctx->decryption_tag,\n\t\t\t\t  input_tag,\n\t\t\t\t  authsize)) {\n\t\t\tpr_debug(\"***EBADMSG:\\n\");\n\t\t\tprint_hex_dump_debug(\"ref:\", DUMP_PREFIX_ADDRESS, 32, 1,\n\t\t\t\t\t     input_tag, authsize, true);\n\t\t\tprint_hex_dump_debug(\"out:\", DUMP_PREFIX_ADDRESS, 32, 1,\n\t\t\t\t\t     req_ctx->decryption_tag,\n\t\t\t\t\t     authsize, true);\n\n\t\t\tresult = -EBADMSG;\n\t\t}\n\t}\n\n\taead_request_complete(areq, result);\n}\n\nstatic void artpec6_crypto_complete_hash(struct crypto_async_request *req)\n{\n\tcrypto_request_complete(req, 0);\n}\n\n\n \nstatic int\nartpec6_crypto_hash_set_key(struct crypto_ahash *tfm,\n\t\t    const u8 *key, unsigned int keylen)\n{\n\tstruct artpec6_hashalg_context *tfm_ctx = crypto_tfm_ctx(&tfm->base);\n\tsize_t blocksize;\n\tint ret;\n\n\tif (!keylen) {\n\t\tpr_err(\"Invalid length (%d) of HMAC key\\n\",\n\t\t\tkeylen);\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(tfm_ctx->hmac_key, 0, sizeof(tfm_ctx->hmac_key));\n\n\tblocksize = crypto_tfm_alg_blocksize(crypto_ahash_tfm(tfm));\n\n\tif (keylen > blocksize) {\n\t\ttfm_ctx->hmac_key_length = blocksize;\n\n\t\tret = crypto_shash_tfm_digest(tfm_ctx->child_hash, key, keylen,\n\t\t\t\t\t      tfm_ctx->hmac_key);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tmemcpy(tfm_ctx->hmac_key, key, keylen);\n\t\ttfm_ctx->hmac_key_length = keylen;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nartpec6_crypto_init_hash(struct ahash_request *req, u8 type, int hmac)\n{\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(req);\n\tu32 oper;\n\n\tmemset(req_ctx, 0, sizeof(*req_ctx));\n\n\treq_ctx->hash_flags = HASH_FLAG_INIT_CTX;\n\tif (hmac)\n\t\treq_ctx->hash_flags |= (HASH_FLAG_HMAC | HASH_FLAG_UPDATE_KEY);\n\n\tswitch (type) {\n\tcase ARTPEC6_CRYPTO_HASH_SHA1:\n\t\toper = hmac ? regk_crypto_hmac_sha1 : regk_crypto_sha1;\n\t\tbreak;\n\tcase ARTPEC6_CRYPTO_HASH_SHA256:\n\t\toper = hmac ? regk_crypto_hmac_sha256 : regk_crypto_sha256;\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"%s: Unsupported hash type 0x%x\\n\", MODULE_NAME, type);\n\t\treturn -EINVAL;\n\t}\n\n\tif (variant == ARTPEC6_CRYPTO)\n\t\treq_ctx->hash_md = FIELD_PREP(A6_CRY_MD_OPER, oper);\n\telse\n\t\treq_ctx->hash_md = FIELD_PREP(A7_CRY_MD_OPER, oper);\n\n\treturn 0;\n}\n\nstatic int artpec6_crypto_prepare_submit_hash(struct ahash_request *req)\n{\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(req);\n\tint ret;\n\n\tif (!req_ctx->common.dma) {\n\t\tret = artpec6_crypto_common_init(&req_ctx->common,\n\t\t\t\t\t  &req->base,\n\t\t\t\t\t  artpec6_crypto_complete_hash,\n\t\t\t\t\t  NULL, 0);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = artpec6_crypto_prepare_hash(req);\n\tswitch (ret) {\n\tcase ARTPEC6_CRYPTO_PREPARE_HASH_START:\n\t\tret = artpec6_crypto_submit(&req_ctx->common);\n\t\tbreak;\n\n\tcase ARTPEC6_CRYPTO_PREPARE_HASH_NO_START:\n\t\tret = 0;\n\t\tfallthrough;\n\n\tdefault:\n\t\tartpec6_crypto_common_destroy(&req_ctx->common);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int artpec6_crypto_hash_final(struct ahash_request *req)\n{\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(req);\n\n\treq_ctx->hash_flags |= HASH_FLAG_FINALIZE;\n\n\treturn artpec6_crypto_prepare_submit_hash(req);\n}\n\nstatic int artpec6_crypto_hash_update(struct ahash_request *req)\n{\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(req);\n\n\treq_ctx->hash_flags |= HASH_FLAG_UPDATE;\n\n\treturn artpec6_crypto_prepare_submit_hash(req);\n}\n\nstatic int artpec6_crypto_sha1_init(struct ahash_request *req)\n{\n\treturn artpec6_crypto_init_hash(req, ARTPEC6_CRYPTO_HASH_SHA1, 0);\n}\n\nstatic int artpec6_crypto_sha1_digest(struct ahash_request *req)\n{\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(req);\n\n\tartpec6_crypto_init_hash(req, ARTPEC6_CRYPTO_HASH_SHA1, 0);\n\n\treq_ctx->hash_flags |= HASH_FLAG_UPDATE | HASH_FLAG_FINALIZE;\n\n\treturn artpec6_crypto_prepare_submit_hash(req);\n}\n\nstatic int artpec6_crypto_sha256_init(struct ahash_request *req)\n{\n\treturn artpec6_crypto_init_hash(req, ARTPEC6_CRYPTO_HASH_SHA256, 0);\n}\n\nstatic int artpec6_crypto_sha256_digest(struct ahash_request *req)\n{\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(req);\n\n\tartpec6_crypto_init_hash(req, ARTPEC6_CRYPTO_HASH_SHA256, 0);\n\treq_ctx->hash_flags |= HASH_FLAG_UPDATE | HASH_FLAG_FINALIZE;\n\n\treturn artpec6_crypto_prepare_submit_hash(req);\n}\n\nstatic int artpec6_crypto_hmac_sha256_init(struct ahash_request *req)\n{\n\treturn artpec6_crypto_init_hash(req, ARTPEC6_CRYPTO_HASH_SHA256, 1);\n}\n\nstatic int artpec6_crypto_hmac_sha256_digest(struct ahash_request *req)\n{\n\tstruct artpec6_hash_request_context *req_ctx = ahash_request_ctx(req);\n\n\tartpec6_crypto_init_hash(req, ARTPEC6_CRYPTO_HASH_SHA256, 1);\n\treq_ctx->hash_flags |= HASH_FLAG_UPDATE | HASH_FLAG_FINALIZE;\n\n\treturn artpec6_crypto_prepare_submit_hash(req);\n}\n\nstatic int artpec6_crypto_ahash_init_common(struct crypto_tfm *tfm,\n\t\t\t\t    const char *base_hash_name)\n{\n\tstruct artpec6_hashalg_context *tfm_ctx = crypto_tfm_ctx(tfm);\n\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct artpec6_hash_request_context));\n\tmemset(tfm_ctx, 0, sizeof(*tfm_ctx));\n\n\tif (base_hash_name) {\n\t\tstruct crypto_shash *child;\n\n\t\tchild = crypto_alloc_shash(base_hash_name, 0,\n\t\t\t\t\t   CRYPTO_ALG_NEED_FALLBACK);\n\n\t\tif (IS_ERR(child))\n\t\t\treturn PTR_ERR(child);\n\n\t\ttfm_ctx->child_hash = child;\n\t}\n\n\treturn 0;\n}\n\nstatic int artpec6_crypto_ahash_init(struct crypto_tfm *tfm)\n{\n\treturn artpec6_crypto_ahash_init_common(tfm, NULL);\n}\n\nstatic int artpec6_crypto_ahash_init_hmac_sha256(struct crypto_tfm *tfm)\n{\n\treturn artpec6_crypto_ahash_init_common(tfm, \"sha256\");\n}\n\nstatic void artpec6_crypto_ahash_exit(struct crypto_tfm *tfm)\n{\n\tstruct artpec6_hashalg_context *tfm_ctx = crypto_tfm_ctx(tfm);\n\n\tif (tfm_ctx->child_hash)\n\t\tcrypto_free_shash(tfm_ctx->child_hash);\n\n\tmemset(tfm_ctx->hmac_key, 0, sizeof(tfm_ctx->hmac_key));\n\ttfm_ctx->hmac_key_length = 0;\n}\n\nstatic int artpec6_crypto_hash_export(struct ahash_request *req, void *out)\n{\n\tconst struct artpec6_hash_request_context *ctx = ahash_request_ctx(req);\n\tstruct artpec6_hash_export_state *state = out;\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tenum artpec6_crypto_variant variant = ac->variant;\n\n\tBUILD_BUG_ON(sizeof(state->partial_buffer) !=\n\t\t     sizeof(ctx->partial_buffer));\n\tBUILD_BUG_ON(sizeof(state->digeststate) != sizeof(ctx->digeststate));\n\n\tstate->digcnt = ctx->digcnt;\n\tstate->partial_bytes = ctx->partial_bytes;\n\tstate->hash_flags = ctx->hash_flags;\n\n\tif (variant == ARTPEC6_CRYPTO)\n\t\tstate->oper = FIELD_GET(A6_CRY_MD_OPER, ctx->hash_md);\n\telse\n\t\tstate->oper = FIELD_GET(A7_CRY_MD_OPER, ctx->hash_md);\n\n\tmemcpy(state->partial_buffer, ctx->partial_buffer,\n\t       sizeof(state->partial_buffer));\n\tmemcpy(state->digeststate, ctx->digeststate,\n\t       sizeof(state->digeststate));\n\n\treturn 0;\n}\n\nstatic int artpec6_crypto_hash_import(struct ahash_request *req, const void *in)\n{\n\tstruct artpec6_hash_request_context *ctx = ahash_request_ctx(req);\n\tconst struct artpec6_hash_export_state *state = in;\n\tstruct artpec6_crypto *ac = dev_get_drvdata(artpec6_crypto_dev);\n\tenum artpec6_crypto_variant variant = ac->variant;\n\n\tmemset(ctx, 0, sizeof(*ctx));\n\n\tctx->digcnt = state->digcnt;\n\tctx->partial_bytes = state->partial_bytes;\n\tctx->hash_flags = state->hash_flags;\n\n\tif (variant == ARTPEC6_CRYPTO)\n\t\tctx->hash_md = FIELD_PREP(A6_CRY_MD_OPER, state->oper);\n\telse\n\t\tctx->hash_md = FIELD_PREP(A7_CRY_MD_OPER, state->oper);\n\n\tmemcpy(ctx->partial_buffer, state->partial_buffer,\n\t       sizeof(state->partial_buffer));\n\tmemcpy(ctx->digeststate, state->digeststate,\n\t       sizeof(state->digeststate));\n\n\treturn 0;\n}\n\nstatic int init_crypto_hw(struct artpec6_crypto *ac)\n{\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tvoid __iomem *base = ac->base;\n\tu32 out_descr_buf_size;\n\tu32 out_data_buf_size;\n\tu32 in_data_buf_size;\n\tu32 in_descr_buf_size;\n\tu32 in_stat_buf_size;\n\tu32 in, out;\n\n\t \n\tout_data_buf_size = 16;   \n\tout_descr_buf_size = 15;  \n\tin_data_buf_size = 8;     \n\tin_descr_buf_size = 4;    \n\tin_stat_buf_size = 4;    \n\n\tBUILD_BUG_ON_MSG((out_data_buf_size\n\t\t\t\t+ out_descr_buf_size) * 64 > 1984,\n\t\t\t  \"Invalid OUT configuration\");\n\n\tBUILD_BUG_ON_MSG((in_data_buf_size\n\t\t\t\t+ in_descr_buf_size\n\t\t\t\t+ in_stat_buf_size) * 64 > 1024,\n\t\t\t  \"Invalid IN configuration\");\n\n\tin = FIELD_PREP(PDMA_IN_BUF_CFG_DATA_BUF_SIZE, in_data_buf_size) |\n\t     FIELD_PREP(PDMA_IN_BUF_CFG_DESCR_BUF_SIZE, in_descr_buf_size) |\n\t     FIELD_PREP(PDMA_IN_BUF_CFG_STAT_BUF_SIZE, in_stat_buf_size);\n\n\tout = FIELD_PREP(PDMA_OUT_BUF_CFG_DATA_BUF_SIZE, out_data_buf_size) |\n\t      FIELD_PREP(PDMA_OUT_BUF_CFG_DESCR_BUF_SIZE, out_descr_buf_size);\n\n\twritel_relaxed(out, base + PDMA_OUT_BUF_CFG);\n\twritel_relaxed(PDMA_OUT_CFG_EN, base + PDMA_OUT_CFG);\n\n\tif (variant == ARTPEC6_CRYPTO) {\n\t\twritel_relaxed(in, base + A6_PDMA_IN_BUF_CFG);\n\t\twritel_relaxed(PDMA_IN_CFG_EN, base + A6_PDMA_IN_CFG);\n\t\twritel_relaxed(A6_PDMA_INTR_MASK_IN_DATA |\n\t\t\t       A6_PDMA_INTR_MASK_IN_EOP_FLUSH,\n\t\t\t       base + A6_PDMA_INTR_MASK);\n\t} else {\n\t\twritel_relaxed(in, base + A7_PDMA_IN_BUF_CFG);\n\t\twritel_relaxed(PDMA_IN_CFG_EN, base + A7_PDMA_IN_CFG);\n\t\twritel_relaxed(A7_PDMA_INTR_MASK_IN_DATA |\n\t\t\t       A7_PDMA_INTR_MASK_IN_EOP_FLUSH,\n\t\t\t       base + A7_PDMA_INTR_MASK);\n\t}\n\n\treturn 0;\n}\n\nstatic void artpec6_crypto_disable_hw(struct artpec6_crypto *ac)\n{\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tvoid __iomem *base = ac->base;\n\n\tif (variant == ARTPEC6_CRYPTO) {\n\t\twritel_relaxed(A6_PDMA_IN_CMD_STOP, base + A6_PDMA_IN_CMD);\n\t\twritel_relaxed(0, base + A6_PDMA_IN_CFG);\n\t\twritel_relaxed(A6_PDMA_OUT_CMD_STOP, base + PDMA_OUT_CMD);\n\t} else {\n\t\twritel_relaxed(A7_PDMA_IN_CMD_STOP, base + A7_PDMA_IN_CMD);\n\t\twritel_relaxed(0, base + A7_PDMA_IN_CFG);\n\t\twritel_relaxed(A7_PDMA_OUT_CMD_STOP, base + PDMA_OUT_CMD);\n\t}\n\n\twritel_relaxed(0, base + PDMA_OUT_CFG);\n\n}\n\nstatic irqreturn_t artpec6_crypto_irq(int irq, void *dev_id)\n{\n\tstruct artpec6_crypto *ac = dev_id;\n\tenum artpec6_crypto_variant variant = ac->variant;\n\tvoid __iomem *base = ac->base;\n\tu32 mask_in_data, mask_in_eop_flush;\n\tu32 in_cmd_flush_stat, in_cmd_reg;\n\tu32 ack_intr_reg;\n\tu32 ack = 0;\n\tu32 intr;\n\n\tif (variant == ARTPEC6_CRYPTO) {\n\t\tintr = readl_relaxed(base + A6_PDMA_MASKED_INTR);\n\t\tmask_in_data = A6_PDMA_INTR_MASK_IN_DATA;\n\t\tmask_in_eop_flush = A6_PDMA_INTR_MASK_IN_EOP_FLUSH;\n\t\tin_cmd_flush_stat = A6_PDMA_IN_CMD_FLUSH_STAT;\n\t\tin_cmd_reg = A6_PDMA_IN_CMD;\n\t\tack_intr_reg = A6_PDMA_ACK_INTR;\n\t} else {\n\t\tintr = readl_relaxed(base + A7_PDMA_MASKED_INTR);\n\t\tmask_in_data = A7_PDMA_INTR_MASK_IN_DATA;\n\t\tmask_in_eop_flush = A7_PDMA_INTR_MASK_IN_EOP_FLUSH;\n\t\tin_cmd_flush_stat = A7_PDMA_IN_CMD_FLUSH_STAT;\n\t\tin_cmd_reg = A7_PDMA_IN_CMD;\n\t\tack_intr_reg = A7_PDMA_ACK_INTR;\n\t}\n\n\t \n\tif (intr & mask_in_data)\n\t\tack |= mask_in_data;\n\n\tif (intr & mask_in_eop_flush)\n\t\tack |= mask_in_eop_flush;\n\telse\n\t\twritel_relaxed(in_cmd_flush_stat, base + in_cmd_reg);\n\n\twritel_relaxed(ack, base + ack_intr_reg);\n\n\tif (intr & mask_in_eop_flush)\n\t\ttasklet_schedule(&ac->task);\n\n\treturn IRQ_HANDLED;\n}\n\n \n\n \nstatic struct ahash_alg hash_algos[] = {\n\t \n\t{\n\t\t.init = artpec6_crypto_sha1_init,\n\t\t.update = artpec6_crypto_hash_update,\n\t\t.final = artpec6_crypto_hash_final,\n\t\t.digest = artpec6_crypto_sha1_digest,\n\t\t.import = artpec6_crypto_hash_import,\n\t\t.export = artpec6_crypto_hash_export,\n\t\t.halg.digestsize = SHA1_DIGEST_SIZE,\n\t\t.halg.statesize = sizeof(struct artpec6_hash_export_state),\n\t\t.halg.base = {\n\t\t\t.cra_name = \"sha1\",\n\t\t\t.cra_driver_name = \"artpec-sha1\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = SHA1_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_hashalg_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_init = artpec6_crypto_ahash_init,\n\t\t\t.cra_exit = artpec6_crypto_ahash_exit,\n\t\t}\n\t},\n\t \n\t{\n\t\t.init = artpec6_crypto_sha256_init,\n\t\t.update = artpec6_crypto_hash_update,\n\t\t.final = artpec6_crypto_hash_final,\n\t\t.digest = artpec6_crypto_sha256_digest,\n\t\t.import = artpec6_crypto_hash_import,\n\t\t.export = artpec6_crypto_hash_export,\n\t\t.halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t.halg.statesize = sizeof(struct artpec6_hash_export_state),\n\t\t.halg.base = {\n\t\t\t.cra_name = \"sha256\",\n\t\t\t.cra_driver_name = \"artpec-sha256\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_hashalg_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_init = artpec6_crypto_ahash_init,\n\t\t\t.cra_exit = artpec6_crypto_ahash_exit,\n\t\t}\n\t},\n\t \n\t{\n\t\t.init = artpec6_crypto_hmac_sha256_init,\n\t\t.update = artpec6_crypto_hash_update,\n\t\t.final = artpec6_crypto_hash_final,\n\t\t.digest = artpec6_crypto_hmac_sha256_digest,\n\t\t.import = artpec6_crypto_hash_import,\n\t\t.export = artpec6_crypto_hash_export,\n\t\t.setkey = artpec6_crypto_hash_set_key,\n\t\t.halg.digestsize = SHA256_DIGEST_SIZE,\n\t\t.halg.statesize = sizeof(struct artpec6_hash_export_state),\n\t\t.halg.base = {\n\t\t\t.cra_name = \"hmac(sha256)\",\n\t\t\t.cra_driver_name = \"artpec-hmac-sha256\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = SHA256_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_hashalg_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t\t.cra_init = artpec6_crypto_ahash_init_hmac_sha256,\n\t\t\t.cra_exit = artpec6_crypto_ahash_exit,\n\t\t}\n\t},\n};\n\n \nstatic struct skcipher_alg crypto_algos[] = {\n\t \n\t{\n\t\t.base = {\n\t\t\t.cra_name = \"ecb(aes)\",\n\t\t\t.cra_driver_name = \"artpec6-ecb-aes\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_cryptotfm_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t.setkey = artpec6_crypto_cipher_set_key,\n\t\t.encrypt = artpec6_crypto_encrypt,\n\t\t.decrypt = artpec6_crypto_decrypt,\n\t\t.init = artpec6_crypto_aes_ecb_init,\n\t\t.exit = artpec6_crypto_aes_exit,\n\t},\n\t \n\t{\n\t\t.base = {\n\t\t\t.cra_name = \"ctr(aes)\",\n\t\t\t.cra_driver_name = \"artpec6-ctr-aes\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY |\n\t\t\t\t     CRYPTO_ALG_NEED_FALLBACK,\n\t\t\t.cra_blocksize = 1,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_cryptotfm_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t.setkey = artpec6_crypto_cipher_set_key,\n\t\t.encrypt = artpec6_crypto_ctr_encrypt,\n\t\t.decrypt = artpec6_crypto_ctr_decrypt,\n\t\t.init = artpec6_crypto_aes_ctr_init,\n\t\t.exit = artpec6_crypto_aes_ctr_exit,\n\t},\n\t \n\t{\n\t\t.base = {\n\t\t\t.cra_name = \"cbc(aes)\",\n\t\t\t.cra_driver_name = \"artpec6-cbc-aes\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = AES_BLOCK_SIZE,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_cryptotfm_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.min_keysize = AES_MIN_KEY_SIZE,\n\t\t.max_keysize = AES_MAX_KEY_SIZE,\n\t\t.ivsize = AES_BLOCK_SIZE,\n\t\t.setkey = artpec6_crypto_cipher_set_key,\n\t\t.encrypt = artpec6_crypto_encrypt,\n\t\t.decrypt = artpec6_crypto_decrypt,\n\t\t.init = artpec6_crypto_aes_cbc_init,\n\t\t.exit = artpec6_crypto_aes_exit\n\t},\n\t \n\t{\n\t\t.base = {\n\t\t\t.cra_name = \"xts(aes)\",\n\t\t\t.cra_driver_name = \"artpec6-xts-aes\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY,\n\t\t\t.cra_blocksize = 1,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_cryptotfm_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.min_keysize = 2*AES_MIN_KEY_SIZE,\n\t\t.max_keysize = 2*AES_MAX_KEY_SIZE,\n\t\t.ivsize = 16,\n\t\t.setkey = artpec6_crypto_xts_set_key,\n\t\t.encrypt = artpec6_crypto_encrypt,\n\t\t.decrypt = artpec6_crypto_decrypt,\n\t\t.init = artpec6_crypto_aes_xts_init,\n\t\t.exit = artpec6_crypto_aes_exit,\n\t},\n};\n\nstatic struct aead_alg aead_algos[] = {\n\t{\n\t\t.init   = artpec6_crypto_aead_init,\n\t\t.setkey = artpec6_crypto_aead_set_key,\n\t\t.encrypt = artpec6_crypto_aead_encrypt,\n\t\t.decrypt = artpec6_crypto_aead_decrypt,\n\t\t.ivsize = GCM_AES_IV_SIZE,\n\t\t.maxauthsize = AES_BLOCK_SIZE,\n\n\t\t.base = {\n\t\t\t.cra_name = \"gcm(aes)\",\n\t\t\t.cra_driver_name = \"artpec-gcm-aes\",\n\t\t\t.cra_priority = 300,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_ALLOCATES_MEMORY |\n\t\t\t\t     CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t.cra_blocksize = 1,\n\t\t\t.cra_ctxsize = sizeof(struct artpec6_cryptotfm_context),\n\t\t\t.cra_alignmask = 3,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t}\n};\n\n#ifdef CONFIG_DEBUG_FS\n\nstruct dbgfs_u32 {\n\tchar *name;\n\tmode_t mode;\n\tu32 *flag;\n\tchar *desc;\n};\n\nstatic struct dentry *dbgfs_root;\n\nstatic void artpec6_crypto_init_debugfs(void)\n{\n\tdbgfs_root = debugfs_create_dir(\"artpec6_crypto\", NULL);\n\n#ifdef CONFIG_FAULT_INJECTION\n\tfault_create_debugfs_attr(\"fail_status_read\", dbgfs_root,\n\t\t\t\t  &artpec6_crypto_fail_status_read);\n\n\tfault_create_debugfs_attr(\"fail_dma_array_full\", dbgfs_root,\n\t\t\t\t  &artpec6_crypto_fail_dma_array_full);\n#endif\n}\n\nstatic void artpec6_crypto_free_debugfs(void)\n{\n\tdebugfs_remove_recursive(dbgfs_root);\n\tdbgfs_root = NULL;\n}\n#endif\n\nstatic const struct of_device_id artpec6_crypto_of_match[] = {\n\t{ .compatible = \"axis,artpec6-crypto\", .data = (void *)ARTPEC6_CRYPTO },\n\t{ .compatible = \"axis,artpec7-crypto\", .data = (void *)ARTPEC7_CRYPTO },\n\t{}\n};\nMODULE_DEVICE_TABLE(of, artpec6_crypto_of_match);\n\nstatic int artpec6_crypto_probe(struct platform_device *pdev)\n{\n\tconst struct of_device_id *match;\n\tenum artpec6_crypto_variant variant;\n\tstruct artpec6_crypto *ac;\n\tstruct device *dev = &pdev->dev;\n\tvoid __iomem *base;\n\tint irq;\n\tint err;\n\n\tif (artpec6_crypto_dev)\n\t\treturn -ENODEV;\n\n\tmatch = of_match_node(artpec6_crypto_of_match, dev->of_node);\n\tif (!match)\n\t\treturn -EINVAL;\n\n\tvariant = (enum artpec6_crypto_variant)match->data;\n\n\tbase = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(base))\n\t\treturn PTR_ERR(base);\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn -ENODEV;\n\n\tac = devm_kzalloc(&pdev->dev, sizeof(struct artpec6_crypto),\n\t\t\t  GFP_KERNEL);\n\tif (!ac)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, ac);\n\tac->variant = variant;\n\n\tspin_lock_init(&ac->queue_lock);\n\tINIT_LIST_HEAD(&ac->queue);\n\tINIT_LIST_HEAD(&ac->pending);\n\ttimer_setup(&ac->timer, artpec6_crypto_timeout, 0);\n\n\tac->base = base;\n\n\tac->dma_cache = kmem_cache_create(\"artpec6_crypto_dma\",\n\t\tsizeof(struct artpec6_crypto_dma_descriptors),\n\t\t64,\n\t\t0,\n\t\tNULL);\n\tif (!ac->dma_cache)\n\t\treturn -ENOMEM;\n\n#ifdef CONFIG_DEBUG_FS\n\tartpec6_crypto_init_debugfs();\n#endif\n\n\ttasklet_init(&ac->task, artpec6_crypto_task,\n\t\t     (unsigned long)ac);\n\n\tac->pad_buffer = devm_kzalloc(&pdev->dev, 2 * ARTPEC_CACHE_LINE_MAX,\n\t\t\t\t      GFP_KERNEL);\n\tif (!ac->pad_buffer)\n\t\treturn -ENOMEM;\n\tac->pad_buffer = PTR_ALIGN(ac->pad_buffer, ARTPEC_CACHE_LINE_MAX);\n\n\tac->zero_buffer = devm_kzalloc(&pdev->dev, 2 * ARTPEC_CACHE_LINE_MAX,\n\t\t\t\t      GFP_KERNEL);\n\tif (!ac->zero_buffer)\n\t\treturn -ENOMEM;\n\tac->zero_buffer = PTR_ALIGN(ac->zero_buffer, ARTPEC_CACHE_LINE_MAX);\n\n\terr = init_crypto_hw(ac);\n\tif (err)\n\t\tgoto free_cache;\n\n\terr = devm_request_irq(&pdev->dev, irq, artpec6_crypto_irq, 0,\n\t\t\t       \"artpec6-crypto\", ac);\n\tif (err)\n\t\tgoto disable_hw;\n\n\tartpec6_crypto_dev = &pdev->dev;\n\n\terr = crypto_register_ahashes(hash_algos, ARRAY_SIZE(hash_algos));\n\tif (err) {\n\t\tdev_err(dev, \"Failed to register ahashes\\n\");\n\t\tgoto disable_hw;\n\t}\n\n\terr = crypto_register_skciphers(crypto_algos, ARRAY_SIZE(crypto_algos));\n\tif (err) {\n\t\tdev_err(dev, \"Failed to register ciphers\\n\");\n\t\tgoto unregister_ahashes;\n\t}\n\n\terr = crypto_register_aeads(aead_algos, ARRAY_SIZE(aead_algos));\n\tif (err) {\n\t\tdev_err(dev, \"Failed to register aeads\\n\");\n\t\tgoto unregister_algs;\n\t}\n\n\treturn 0;\n\nunregister_algs:\n\tcrypto_unregister_skciphers(crypto_algos, ARRAY_SIZE(crypto_algos));\nunregister_ahashes:\n\tcrypto_unregister_ahashes(hash_algos, ARRAY_SIZE(hash_algos));\ndisable_hw:\n\tartpec6_crypto_disable_hw(ac);\nfree_cache:\n\tkmem_cache_destroy(ac->dma_cache);\n\treturn err;\n}\n\nstatic int artpec6_crypto_remove(struct platform_device *pdev)\n{\n\tstruct artpec6_crypto *ac = platform_get_drvdata(pdev);\n\tint irq = platform_get_irq(pdev, 0);\n\n\tcrypto_unregister_ahashes(hash_algos, ARRAY_SIZE(hash_algos));\n\tcrypto_unregister_skciphers(crypto_algos, ARRAY_SIZE(crypto_algos));\n\tcrypto_unregister_aeads(aead_algos, ARRAY_SIZE(aead_algos));\n\n\ttasklet_disable(&ac->task);\n\tdevm_free_irq(&pdev->dev, irq, ac);\n\ttasklet_kill(&ac->task);\n\tdel_timer_sync(&ac->timer);\n\n\tartpec6_crypto_disable_hw(ac);\n\n\tkmem_cache_destroy(ac->dma_cache);\n#ifdef CONFIG_DEBUG_FS\n\tartpec6_crypto_free_debugfs();\n#endif\n\treturn 0;\n}\n\nstatic struct platform_driver artpec6_crypto_driver = {\n\t.probe   = artpec6_crypto_probe,\n\t.remove  = artpec6_crypto_remove,\n\t.driver  = {\n\t\t.name  = \"artpec6-crypto\",\n\t\t.of_match_table = artpec6_crypto_of_match,\n\t},\n};\n\nmodule_platform_driver(artpec6_crypto_driver);\n\nMODULE_AUTHOR(\"Axis Communications AB\");\nMODULE_DESCRIPTION(\"ARTPEC-6 Crypto driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}