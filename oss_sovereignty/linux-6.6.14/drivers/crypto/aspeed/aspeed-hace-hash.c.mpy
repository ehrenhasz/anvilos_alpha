{
  "module_name": "aspeed-hace-hash.c",
  "hash_id": "23d5fe7a6373a27bed808283586d6ef1175451c7e594afd1c43670ae33197842",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/aspeed/aspeed-hace-hash.c",
  "human_readable_source": "\n \n\n#include \"aspeed-hace.h\"\n#include <crypto/engine.h>\n#include <crypto/hmac.h>\n#include <crypto/internal/hash.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/sha1.h>\n#include <crypto/sha2.h>\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n\n#ifdef CONFIG_CRYPTO_DEV_ASPEED_DEBUG\n#define AHASH_DBG(h, fmt, ...)\t\\\n\tdev_info((h)->dev, \"%s() \" fmt, __func__, ##__VA_ARGS__)\n#else\n#define AHASH_DBG(h, fmt, ...)\t\\\n\tdev_dbg((h)->dev, \"%s() \" fmt, __func__, ##__VA_ARGS__)\n#endif\n\n \nstatic const __be32 sha1_iv[8] = {\n\tcpu_to_be32(SHA1_H0), cpu_to_be32(SHA1_H1),\n\tcpu_to_be32(SHA1_H2), cpu_to_be32(SHA1_H3),\n\tcpu_to_be32(SHA1_H4), 0, 0, 0\n};\n\nstatic const __be32 sha224_iv[8] = {\n\tcpu_to_be32(SHA224_H0), cpu_to_be32(SHA224_H1),\n\tcpu_to_be32(SHA224_H2), cpu_to_be32(SHA224_H3),\n\tcpu_to_be32(SHA224_H4), cpu_to_be32(SHA224_H5),\n\tcpu_to_be32(SHA224_H6), cpu_to_be32(SHA224_H7),\n};\n\nstatic const __be32 sha256_iv[8] = {\n\tcpu_to_be32(SHA256_H0), cpu_to_be32(SHA256_H1),\n\tcpu_to_be32(SHA256_H2), cpu_to_be32(SHA256_H3),\n\tcpu_to_be32(SHA256_H4), cpu_to_be32(SHA256_H5),\n\tcpu_to_be32(SHA256_H6), cpu_to_be32(SHA256_H7),\n};\n\nstatic const __be64 sha384_iv[8] = {\n\tcpu_to_be64(SHA384_H0), cpu_to_be64(SHA384_H1),\n\tcpu_to_be64(SHA384_H2), cpu_to_be64(SHA384_H3),\n\tcpu_to_be64(SHA384_H4), cpu_to_be64(SHA384_H5),\n\tcpu_to_be64(SHA384_H6), cpu_to_be64(SHA384_H7)\n};\n\nstatic const __be64 sha512_iv[8] = {\n\tcpu_to_be64(SHA512_H0), cpu_to_be64(SHA512_H1),\n\tcpu_to_be64(SHA512_H2), cpu_to_be64(SHA512_H3),\n\tcpu_to_be64(SHA512_H4), cpu_to_be64(SHA512_H5),\n\tcpu_to_be64(SHA512_H6), cpu_to_be64(SHA512_H7)\n};\n\n \nstatic void aspeed_ahash_fill_padding(struct aspeed_hace_dev *hace_dev,\n\t\t\t\t      struct aspeed_sham_reqctx *rctx)\n{\n\tunsigned int index, padlen;\n\t__be64 bits[2];\n\n\tAHASH_DBG(hace_dev, \"rctx flags:0x%x\\n\", (u32)rctx->flags);\n\n\tswitch (rctx->flags & SHA_FLAGS_MASK) {\n\tcase SHA_FLAGS_SHA1:\n\tcase SHA_FLAGS_SHA224:\n\tcase SHA_FLAGS_SHA256:\n\t\tbits[0] = cpu_to_be64(rctx->digcnt[0] << 3);\n\t\tindex = rctx->bufcnt & 0x3f;\n\t\tpadlen = (index < 56) ? (56 - index) : ((64 + 56) - index);\n\t\t*(rctx->buffer + rctx->bufcnt) = 0x80;\n\t\tmemset(rctx->buffer + rctx->bufcnt + 1, 0, padlen - 1);\n\t\tmemcpy(rctx->buffer + rctx->bufcnt + padlen, bits, 8);\n\t\trctx->bufcnt += padlen + 8;\n\t\tbreak;\n\tdefault:\n\t\tbits[1] = cpu_to_be64(rctx->digcnt[0] << 3);\n\t\tbits[0] = cpu_to_be64(rctx->digcnt[1] << 3 |\n\t\t\t\t      rctx->digcnt[0] >> 61);\n\t\tindex = rctx->bufcnt & 0x7f;\n\t\tpadlen = (index < 112) ? (112 - index) : ((128 + 112) - index);\n\t\t*(rctx->buffer + rctx->bufcnt) = 0x80;\n\t\tmemset(rctx->buffer + rctx->bufcnt + 1, 0, padlen - 1);\n\t\tmemcpy(rctx->buffer + rctx->bufcnt + padlen, bits, 16);\n\t\trctx->bufcnt += padlen + 16;\n\t\tbreak;\n\t}\n}\n\n \nstatic int aspeed_ahash_dma_prepare(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tint length, remain;\n\n\tlength = rctx->total + rctx->bufcnt;\n\tremain = length % rctx->block_size;\n\n\tAHASH_DBG(hace_dev, \"length:0x%x, remain:0x%x\\n\", length, remain);\n\n\tif (rctx->bufcnt)\n\t\tmemcpy(hash_engine->ahash_src_addr, rctx->buffer, rctx->bufcnt);\n\n\tif (rctx->total + rctx->bufcnt < ASPEED_CRYPTO_SRC_DMA_BUF_LEN) {\n\t\tscatterwalk_map_and_copy(hash_engine->ahash_src_addr +\n\t\t\t\t\t rctx->bufcnt, rctx->src_sg,\n\t\t\t\t\t rctx->offset, rctx->total - remain, 0);\n\t\trctx->offset += rctx->total - remain;\n\n\t} else {\n\t\tdev_warn(hace_dev->dev, \"Hash data length is too large\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tscatterwalk_map_and_copy(rctx->buffer, rctx->src_sg,\n\t\t\t\t rctx->offset, remain, 0);\n\n\trctx->bufcnt = remain;\n\trctx->digest_dma_addr = dma_map_single(hace_dev->dev, rctx->digest,\n\t\t\t\t\t       SHA512_DIGEST_SIZE,\n\t\t\t\t\t       DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(hace_dev->dev, rctx->digest_dma_addr)) {\n\t\tdev_warn(hace_dev->dev, \"dma_map() rctx digest error\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\thash_engine->src_length = length - remain;\n\thash_engine->src_dma = hash_engine->ahash_src_dma_addr;\n\thash_engine->digest_dma = rctx->digest_dma_addr;\n\n\treturn 0;\n}\n\n \nstatic int aspeed_ahash_dma_prepare_sg(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tstruct aspeed_sg_list *src_list;\n\tstruct scatterlist *s;\n\tint length, remain, sg_len, i;\n\tint rc = 0;\n\n\tremain = (rctx->total + rctx->bufcnt) % rctx->block_size;\n\tlength = rctx->total + rctx->bufcnt - remain;\n\n\tAHASH_DBG(hace_dev, \"%s:0x%x, %s:%zu, %s:0x%x, %s:0x%x\\n\",\n\t\t  \"rctx total\", rctx->total, \"bufcnt\", rctx->bufcnt,\n\t\t  \"length\", length, \"remain\", remain);\n\n\tsg_len = dma_map_sg(hace_dev->dev, rctx->src_sg, rctx->src_nents,\n\t\t\t    DMA_TO_DEVICE);\n\tif (!sg_len) {\n\t\tdev_warn(hace_dev->dev, \"dma_map_sg() src error\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto end;\n\t}\n\n\tsrc_list = (struct aspeed_sg_list *)hash_engine->ahash_src_addr;\n\trctx->digest_dma_addr = dma_map_single(hace_dev->dev, rctx->digest,\n\t\t\t\t\t       SHA512_DIGEST_SIZE,\n\t\t\t\t\t       DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(hace_dev->dev, rctx->digest_dma_addr)) {\n\t\tdev_warn(hace_dev->dev, \"dma_map() rctx digest error\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto free_src_sg;\n\t}\n\n\tif (rctx->bufcnt != 0) {\n\t\tu32 phy_addr;\n\t\tu32 len;\n\n\t\trctx->buffer_dma_addr = dma_map_single(hace_dev->dev,\n\t\t\t\t\t\t       rctx->buffer,\n\t\t\t\t\t\t       rctx->block_size * 2,\n\t\t\t\t\t\t       DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(hace_dev->dev, rctx->buffer_dma_addr)) {\n\t\t\tdev_warn(hace_dev->dev, \"dma_map() rctx buffer error\\n\");\n\t\t\trc = -ENOMEM;\n\t\t\tgoto free_rctx_digest;\n\t\t}\n\n\t\tphy_addr = rctx->buffer_dma_addr;\n\t\tlen = rctx->bufcnt;\n\t\tlength -= len;\n\n\t\t \n\t\tif (length == 0)\n\t\t\tlen |= HASH_SG_LAST_LIST;\n\n\t\tsrc_list[0].phy_addr = cpu_to_le32(phy_addr);\n\t\tsrc_list[0].len = cpu_to_le32(len);\n\t\tsrc_list++;\n\t}\n\n\tif (length != 0) {\n\t\tfor_each_sg(rctx->src_sg, s, sg_len, i) {\n\t\t\tu32 phy_addr = sg_dma_address(s);\n\t\t\tu32 len = sg_dma_len(s);\n\n\t\t\tif (length > len)\n\t\t\t\tlength -= len;\n\t\t\telse {\n\t\t\t\t \n\t\t\t\tlen = length;\n\t\t\t\tlen |= HASH_SG_LAST_LIST;\n\t\t\t\tlength = 0;\n\t\t\t}\n\n\t\t\tsrc_list[i].phy_addr = cpu_to_le32(phy_addr);\n\t\t\tsrc_list[i].len = cpu_to_le32(len);\n\t\t}\n\t}\n\n\tif (length != 0) {\n\t\trc = -EINVAL;\n\t\tgoto free_rctx_buffer;\n\t}\n\n\trctx->offset = rctx->total - remain;\n\thash_engine->src_length = rctx->total + rctx->bufcnt - remain;\n\thash_engine->src_dma = hash_engine->ahash_src_dma_addr;\n\thash_engine->digest_dma = rctx->digest_dma_addr;\n\n\treturn 0;\n\nfree_rctx_buffer:\n\tif (rctx->bufcnt != 0)\n\t\tdma_unmap_single(hace_dev->dev, rctx->buffer_dma_addr,\n\t\t\t\t rctx->block_size * 2, DMA_TO_DEVICE);\nfree_rctx_digest:\n\tdma_unmap_single(hace_dev->dev, rctx->digest_dma_addr,\n\t\t\t SHA512_DIGEST_SIZE, DMA_BIDIRECTIONAL);\nfree_src_sg:\n\tdma_unmap_sg(hace_dev->dev, rctx->src_sg, rctx->src_nents,\n\t\t     DMA_TO_DEVICE);\nend:\n\treturn rc;\n}\n\nstatic int aspeed_ahash_complete(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\thash_engine->flags &= ~CRYPTO_FLAGS_BUSY;\n\n\tcrypto_finalize_hash_request(hace_dev->crypt_engine_hash, req, 0);\n\n\treturn 0;\n}\n\n \nstatic int aspeed_ahash_transfer(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\tdma_unmap_single(hace_dev->dev, rctx->digest_dma_addr,\n\t\t\t SHA512_DIGEST_SIZE, DMA_BIDIRECTIONAL);\n\n\tdma_unmap_single(hace_dev->dev, rctx->buffer_dma_addr,\n\t\t\t rctx->block_size * 2, DMA_TO_DEVICE);\n\n\tmemcpy(req->result, rctx->digest, rctx->digsize);\n\n\treturn aspeed_ahash_complete(hace_dev);\n}\n\n \nstatic int aspeed_hace_ahash_trigger(struct aspeed_hace_dev *hace_dev,\n\t\t\t\t     aspeed_hace_fn_t resume)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\n\tAHASH_DBG(hace_dev, \"src_dma:%pad, digest_dma:%pad, length:%zu\\n\",\n\t\t  &hash_engine->src_dma, &hash_engine->digest_dma,\n\t\t  hash_engine->src_length);\n\n\trctx->cmd |= HASH_CMD_INT_ENABLE;\n\thash_engine->resume = resume;\n\n\tast_hace_write(hace_dev, hash_engine->src_dma, ASPEED_HACE_HASH_SRC);\n\tast_hace_write(hace_dev, hash_engine->digest_dma,\n\t\t       ASPEED_HACE_HASH_DIGEST_BUFF);\n\tast_hace_write(hace_dev, hash_engine->digest_dma,\n\t\t       ASPEED_HACE_HASH_KEY_BUFF);\n\tast_hace_write(hace_dev, hash_engine->src_length,\n\t\t       ASPEED_HACE_HASH_DATA_LEN);\n\n\t \n\tmb();\n\n\tast_hace_write(hace_dev, rctx->cmd, ASPEED_HACE_HASH_CMD);\n\n\treturn -EINPROGRESS;\n}\n\n \nstatic int aspeed_ahash_hmac_resume(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_sha_hmac_ctx *bctx = tctx->base;\n\tint rc = 0;\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\tdma_unmap_single(hace_dev->dev, rctx->digest_dma_addr,\n\t\t\t SHA512_DIGEST_SIZE, DMA_BIDIRECTIONAL);\n\n\tdma_unmap_single(hace_dev->dev, rctx->buffer_dma_addr,\n\t\t\t rctx->block_size * 2, DMA_TO_DEVICE);\n\n\t \n\tmemcpy(rctx->buffer, bctx->opad, rctx->block_size);\n\tmemcpy(rctx->buffer + rctx->block_size, rctx->digest, rctx->digsize);\n\n\trctx->bufcnt = rctx->block_size + rctx->digsize;\n\trctx->digcnt[0] = rctx->block_size + rctx->digsize;\n\n\taspeed_ahash_fill_padding(hace_dev, rctx);\n\tmemcpy(rctx->digest, rctx->sha_iv, rctx->ivsize);\n\n\trctx->digest_dma_addr = dma_map_single(hace_dev->dev, rctx->digest,\n\t\t\t\t\t       SHA512_DIGEST_SIZE,\n\t\t\t\t\t       DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(hace_dev->dev, rctx->digest_dma_addr)) {\n\t\tdev_warn(hace_dev->dev, \"dma_map() rctx digest error\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto end;\n\t}\n\n\trctx->buffer_dma_addr = dma_map_single(hace_dev->dev, rctx->buffer,\n\t\t\t\t\t       rctx->block_size * 2,\n\t\t\t\t\t       DMA_TO_DEVICE);\n\tif (dma_mapping_error(hace_dev->dev, rctx->buffer_dma_addr)) {\n\t\tdev_warn(hace_dev->dev, \"dma_map() rctx buffer error\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto free_rctx_digest;\n\t}\n\n\thash_engine->src_dma = rctx->buffer_dma_addr;\n\thash_engine->src_length = rctx->bufcnt;\n\thash_engine->digest_dma = rctx->digest_dma_addr;\n\n\treturn aspeed_hace_ahash_trigger(hace_dev, aspeed_ahash_transfer);\n\nfree_rctx_digest:\n\tdma_unmap_single(hace_dev->dev, rctx->digest_dma_addr,\n\t\t\t SHA512_DIGEST_SIZE, DMA_BIDIRECTIONAL);\nend:\n\treturn rc;\n}\n\nstatic int aspeed_ahash_req_final(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tint rc = 0;\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\taspeed_ahash_fill_padding(hace_dev, rctx);\n\n\trctx->digest_dma_addr = dma_map_single(hace_dev->dev,\n\t\t\t\t\t       rctx->digest,\n\t\t\t\t\t       SHA512_DIGEST_SIZE,\n\t\t\t\t\t       DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(hace_dev->dev, rctx->digest_dma_addr)) {\n\t\tdev_warn(hace_dev->dev, \"dma_map() rctx digest error\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto end;\n\t}\n\n\trctx->buffer_dma_addr = dma_map_single(hace_dev->dev,\n\t\t\t\t\t       rctx->buffer,\n\t\t\t\t\t       rctx->block_size * 2,\n\t\t\t\t\t       DMA_TO_DEVICE);\n\tif (dma_mapping_error(hace_dev->dev, rctx->buffer_dma_addr)) {\n\t\tdev_warn(hace_dev->dev, \"dma_map() rctx buffer error\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto free_rctx_digest;\n\t}\n\n\thash_engine->src_dma = rctx->buffer_dma_addr;\n\thash_engine->src_length = rctx->bufcnt;\n\thash_engine->digest_dma = rctx->digest_dma_addr;\n\n\tif (rctx->flags & SHA_FLAGS_HMAC)\n\t\treturn aspeed_hace_ahash_trigger(hace_dev,\n\t\t\t\t\t\t aspeed_ahash_hmac_resume);\n\n\treturn aspeed_hace_ahash_trigger(hace_dev, aspeed_ahash_transfer);\n\nfree_rctx_digest:\n\tdma_unmap_single(hace_dev->dev, rctx->digest_dma_addr,\n\t\t\t SHA512_DIGEST_SIZE, DMA_BIDIRECTIONAL);\nend:\n\treturn rc;\n}\n\nstatic int aspeed_ahash_update_resume_sg(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\tdma_unmap_sg(hace_dev->dev, rctx->src_sg, rctx->src_nents,\n\t\t     DMA_TO_DEVICE);\n\n\tif (rctx->bufcnt != 0)\n\t\tdma_unmap_single(hace_dev->dev, rctx->buffer_dma_addr,\n\t\t\t\t rctx->block_size * 2,\n\t\t\t\t DMA_TO_DEVICE);\n\n\tdma_unmap_single(hace_dev->dev, rctx->digest_dma_addr,\n\t\t\t SHA512_DIGEST_SIZE, DMA_BIDIRECTIONAL);\n\n\tscatterwalk_map_and_copy(rctx->buffer, rctx->src_sg, rctx->offset,\n\t\t\t\t rctx->total - rctx->offset, 0);\n\n\trctx->bufcnt = rctx->total - rctx->offset;\n\trctx->cmd &= ~HASH_CMD_HASH_SRC_SG_CTRL;\n\n\tif (rctx->flags & SHA_FLAGS_FINUP)\n\t\treturn aspeed_ahash_req_final(hace_dev);\n\n\treturn aspeed_ahash_complete(hace_dev);\n}\n\nstatic int aspeed_ahash_update_resume(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\tdma_unmap_single(hace_dev->dev, rctx->digest_dma_addr,\n\t\t\t SHA512_DIGEST_SIZE, DMA_BIDIRECTIONAL);\n\n\tif (rctx->flags & SHA_FLAGS_FINUP)\n\t\treturn aspeed_ahash_req_final(hace_dev);\n\n\treturn aspeed_ahash_complete(hace_dev);\n}\n\nstatic int aspeed_ahash_req_update(struct aspeed_hace_dev *hace_dev)\n{\n\tstruct aspeed_engine_hash *hash_engine = &hace_dev->hash_engine;\n\tstruct ahash_request *req = hash_engine->req;\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\taspeed_hace_fn_t resume;\n\tint ret;\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\tif (hace_dev->version == AST2600_VERSION) {\n\t\trctx->cmd |= HASH_CMD_HASH_SRC_SG_CTRL;\n\t\tresume = aspeed_ahash_update_resume_sg;\n\n\t} else {\n\t\tresume = aspeed_ahash_update_resume;\n\t}\n\n\tret = hash_engine->dma_prepare(hace_dev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn aspeed_hace_ahash_trigger(hace_dev, resume);\n}\n\nstatic int aspeed_hace_hash_handle_queue(struct aspeed_hace_dev *hace_dev,\n\t\t\t\t  struct ahash_request *req)\n{\n\treturn crypto_transfer_hash_request_to_engine(\n\t\t\thace_dev->crypt_engine_hash, req);\n}\n\nstatic int aspeed_ahash_do_request(struct crypto_engine *engine, void *areq)\n{\n\tstruct ahash_request *req = ahash_request_cast(areq);\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\tstruct aspeed_engine_hash *hash_engine;\n\tint ret = 0;\n\n\thash_engine = &hace_dev->hash_engine;\n\thash_engine->flags |= CRYPTO_FLAGS_BUSY;\n\n\tif (rctx->op == SHA_OP_UPDATE)\n\t\tret = aspeed_ahash_req_update(hace_dev);\n\telse if (rctx->op == SHA_OP_FINAL)\n\t\tret = aspeed_ahash_req_final(hace_dev);\n\n\tif (ret != -EINPROGRESS)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void aspeed_ahash_prepare_request(struct crypto_engine *engine,\n\t\t\t\t\t void *areq)\n{\n\tstruct ahash_request *req = ahash_request_cast(areq);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\tstruct aspeed_engine_hash *hash_engine;\n\n\thash_engine = &hace_dev->hash_engine;\n\thash_engine->req = req;\n\n\tif (hace_dev->version == AST2600_VERSION)\n\t\thash_engine->dma_prepare = aspeed_ahash_dma_prepare_sg;\n\telse\n\t\thash_engine->dma_prepare = aspeed_ahash_dma_prepare;\n}\n\nstatic int aspeed_ahash_do_one(struct crypto_engine *engine, void *areq)\n{\n\taspeed_ahash_prepare_request(engine, areq);\n\treturn aspeed_ahash_do_request(engine, areq);\n}\n\nstatic int aspeed_sham_update(struct ahash_request *req)\n{\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\n\tAHASH_DBG(hace_dev, \"req->nbytes: %d\\n\", req->nbytes);\n\n\trctx->total = req->nbytes;\n\trctx->src_sg = req->src;\n\trctx->offset = 0;\n\trctx->src_nents = sg_nents(req->src);\n\trctx->op = SHA_OP_UPDATE;\n\n\trctx->digcnt[0] += rctx->total;\n\tif (rctx->digcnt[0] < rctx->total)\n\t\trctx->digcnt[1]++;\n\n\tif (rctx->bufcnt + rctx->total < rctx->block_size) {\n\t\tscatterwalk_map_and_copy(rctx->buffer + rctx->bufcnt,\n\t\t\t\t\t rctx->src_sg, rctx->offset,\n\t\t\t\t\t rctx->total, 0);\n\t\trctx->bufcnt += rctx->total;\n\n\t\treturn 0;\n\t}\n\n\treturn aspeed_hace_hash_handle_queue(hace_dev, req);\n}\n\nstatic int aspeed_sham_shash_digest(struct crypto_shash *tfm, u32 flags,\n\t\t\t\t    const u8 *data, unsigned int len, u8 *out)\n{\n\tSHASH_DESC_ON_STACK(shash, tfm);\n\n\tshash->tfm = tfm;\n\n\treturn crypto_shash_digest(shash, data, len, out);\n}\n\nstatic int aspeed_sham_final(struct ahash_request *req)\n{\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\n\tAHASH_DBG(hace_dev, \"req->nbytes:%d, rctx->total:%d\\n\",\n\t\t  req->nbytes, rctx->total);\n\trctx->op = SHA_OP_FINAL;\n\n\treturn aspeed_hace_hash_handle_queue(hace_dev, req);\n}\n\nstatic int aspeed_sham_finup(struct ahash_request *req)\n{\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\tint rc1, rc2;\n\n\tAHASH_DBG(hace_dev, \"req->nbytes: %d\\n\", req->nbytes);\n\n\trctx->flags |= SHA_FLAGS_FINUP;\n\n\trc1 = aspeed_sham_update(req);\n\tif (rc1 == -EINPROGRESS || rc1 == -EBUSY)\n\t\treturn rc1;\n\n\t \n\trc2 = aspeed_sham_final(req);\n\n\treturn rc1 ? : rc2;\n}\n\nstatic int aspeed_sham_init(struct ahash_request *req)\n{\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\tstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\tstruct aspeed_sha_hmac_ctx *bctx = tctx->base;\n\n\tAHASH_DBG(hace_dev, \"%s: digest size:%d\\n\",\n\t\t  crypto_tfm_alg_name(&tfm->base),\n\t\t  crypto_ahash_digestsize(tfm));\n\n\trctx->cmd = HASH_CMD_ACC_MODE;\n\trctx->flags = 0;\n\n\tswitch (crypto_ahash_digestsize(tfm)) {\n\tcase SHA1_DIGEST_SIZE:\n\t\trctx->cmd |= HASH_CMD_SHA1 | HASH_CMD_SHA_SWAP;\n\t\trctx->flags |= SHA_FLAGS_SHA1;\n\t\trctx->digsize = SHA1_DIGEST_SIZE;\n\t\trctx->block_size = SHA1_BLOCK_SIZE;\n\t\trctx->sha_iv = sha1_iv;\n\t\trctx->ivsize = 32;\n\t\tmemcpy(rctx->digest, sha1_iv, rctx->ivsize);\n\t\tbreak;\n\tcase SHA224_DIGEST_SIZE:\n\t\trctx->cmd |= HASH_CMD_SHA224 | HASH_CMD_SHA_SWAP;\n\t\trctx->flags |= SHA_FLAGS_SHA224;\n\t\trctx->digsize = SHA224_DIGEST_SIZE;\n\t\trctx->block_size = SHA224_BLOCK_SIZE;\n\t\trctx->sha_iv = sha224_iv;\n\t\trctx->ivsize = 32;\n\t\tmemcpy(rctx->digest, sha224_iv, rctx->ivsize);\n\t\tbreak;\n\tcase SHA256_DIGEST_SIZE:\n\t\trctx->cmd |= HASH_CMD_SHA256 | HASH_CMD_SHA_SWAP;\n\t\trctx->flags |= SHA_FLAGS_SHA256;\n\t\trctx->digsize = SHA256_DIGEST_SIZE;\n\t\trctx->block_size = SHA256_BLOCK_SIZE;\n\t\trctx->sha_iv = sha256_iv;\n\t\trctx->ivsize = 32;\n\t\tmemcpy(rctx->digest, sha256_iv, rctx->ivsize);\n\t\tbreak;\n\tcase SHA384_DIGEST_SIZE:\n\t\trctx->cmd |= HASH_CMD_SHA512_SER | HASH_CMD_SHA384 |\n\t\t\t     HASH_CMD_SHA_SWAP;\n\t\trctx->flags |= SHA_FLAGS_SHA384;\n\t\trctx->digsize = SHA384_DIGEST_SIZE;\n\t\trctx->block_size = SHA384_BLOCK_SIZE;\n\t\trctx->sha_iv = (const __be32 *)sha384_iv;\n\t\trctx->ivsize = 64;\n\t\tmemcpy(rctx->digest, sha384_iv, rctx->ivsize);\n\t\tbreak;\n\tcase SHA512_DIGEST_SIZE:\n\t\trctx->cmd |= HASH_CMD_SHA512_SER | HASH_CMD_SHA512 |\n\t\t\t     HASH_CMD_SHA_SWAP;\n\t\trctx->flags |= SHA_FLAGS_SHA512;\n\t\trctx->digsize = SHA512_DIGEST_SIZE;\n\t\trctx->block_size = SHA512_BLOCK_SIZE;\n\t\trctx->sha_iv = (const __be32 *)sha512_iv;\n\t\trctx->ivsize = 64;\n\t\tmemcpy(rctx->digest, sha512_iv, rctx->ivsize);\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(tctx->hace_dev->dev, \"digest size %d not support\\n\",\n\t\t\t crypto_ahash_digestsize(tfm));\n\t\treturn -EINVAL;\n\t}\n\n\trctx->bufcnt = 0;\n\trctx->total = 0;\n\trctx->digcnt[0] = 0;\n\trctx->digcnt[1] = 0;\n\n\t \n\tif (tctx->flags & SHA_FLAGS_HMAC) {\n\t\trctx->digcnt[0] = rctx->block_size;\n\t\trctx->bufcnt = rctx->block_size;\n\t\tmemcpy(rctx->buffer, bctx->ipad, rctx->block_size);\n\t\trctx->flags |= SHA_FLAGS_HMAC;\n\t}\n\n\treturn 0;\n}\n\nstatic int aspeed_sham_digest(struct ahash_request *req)\n{\n\treturn aspeed_sham_init(req) ? : aspeed_sham_finup(req);\n}\n\nstatic int aspeed_sham_setkey(struct crypto_ahash *tfm, const u8 *key,\n\t\t\t      unsigned int keylen)\n{\n\tstruct aspeed_sham_ctx *tctx = crypto_ahash_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\tstruct aspeed_sha_hmac_ctx *bctx = tctx->base;\n\tint ds = crypto_shash_digestsize(bctx->shash);\n\tint bs = crypto_shash_blocksize(bctx->shash);\n\tint err = 0;\n\tint i;\n\n\tAHASH_DBG(hace_dev, \"%s: keylen:%d\\n\", crypto_tfm_alg_name(&tfm->base),\n\t\t  keylen);\n\n\tif (keylen > bs) {\n\t\terr = aspeed_sham_shash_digest(bctx->shash,\n\t\t\t\t\t       crypto_shash_get_flags(bctx->shash),\n\t\t\t\t\t       key, keylen, bctx->ipad);\n\t\tif (err)\n\t\t\treturn err;\n\t\tkeylen = ds;\n\n\t} else {\n\t\tmemcpy(bctx->ipad, key, keylen);\n\t}\n\n\tmemset(bctx->ipad + keylen, 0, bs - keylen);\n\tmemcpy(bctx->opad, bctx->ipad, bs);\n\n\tfor (i = 0; i < bs; i++) {\n\t\tbctx->ipad[i] ^= HMAC_IPAD_VALUE;\n\t\tbctx->opad[i] ^= HMAC_OPAD_VALUE;\n\t}\n\n\treturn err;\n}\n\nstatic int aspeed_sham_cra_init(struct crypto_tfm *tfm)\n{\n\tstruct ahash_alg *alg = __crypto_ahash_alg(tfm->__crt_alg);\n\tstruct aspeed_sham_ctx *tctx = crypto_tfm_ctx(tfm);\n\tstruct aspeed_hace_alg *ast_alg;\n\n\tast_alg = container_of(alg, struct aspeed_hace_alg, alg.ahash.base);\n\ttctx->hace_dev = ast_alg->hace_dev;\n\ttctx->flags = 0;\n\n\tcrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\n\t\t\t\t sizeof(struct aspeed_sham_reqctx));\n\n\tif (ast_alg->alg_base) {\n\t\t \n\t\tstruct aspeed_sha_hmac_ctx *bctx = tctx->base;\n\n\t\ttctx->flags |= SHA_FLAGS_HMAC;\n\t\tbctx->shash = crypto_alloc_shash(ast_alg->alg_base, 0,\n\t\t\t\t\t\t CRYPTO_ALG_NEED_FALLBACK);\n\t\tif (IS_ERR(bctx->shash)) {\n\t\t\tdev_warn(ast_alg->hace_dev->dev,\n\t\t\t\t \"base driver '%s' could not be loaded.\\n\",\n\t\t\t\t ast_alg->alg_base);\n\t\t\treturn PTR_ERR(bctx->shash);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void aspeed_sham_cra_exit(struct crypto_tfm *tfm)\n{\n\tstruct aspeed_sham_ctx *tctx = crypto_tfm_ctx(tfm);\n\tstruct aspeed_hace_dev *hace_dev = tctx->hace_dev;\n\n\tAHASH_DBG(hace_dev, \"%s\\n\", crypto_tfm_alg_name(tfm));\n\n\tif (tctx->flags & SHA_FLAGS_HMAC) {\n\t\tstruct aspeed_sha_hmac_ctx *bctx = tctx->base;\n\n\t\tcrypto_free_shash(bctx->shash);\n\t}\n}\n\nstatic int aspeed_sham_export(struct ahash_request *req, void *out)\n{\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\n\tmemcpy(out, rctx, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic int aspeed_sham_import(struct ahash_request *req, const void *in)\n{\n\tstruct aspeed_sham_reqctx *rctx = ahash_request_ctx(req);\n\n\tmemcpy(rctx, in, sizeof(*rctx));\n\n\treturn 0;\n}\n\nstatic struct aspeed_hace_alg aspeed_ahash_algs[] = {\n\t{\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA1_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"sha1\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-sha1\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA256_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"sha256\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-sha256\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA256_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA224_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"sha224\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-sha224\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA224_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg_base = \"sha1\",\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.setkey\t= aspeed_sham_setkey,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA1_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"hmac(sha1)\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-hmac-sha1\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA1_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx) +\n\t\t\t\t\t\t\t\tsizeof(struct aspeed_sha_hmac_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg_base = \"sha224\",\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.setkey\t= aspeed_sham_setkey,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA224_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"hmac(sha224)\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-hmac-sha224\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA224_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx) +\n\t\t\t\t\t\t\t\tsizeof(struct aspeed_sha_hmac_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg_base = \"sha256\",\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.setkey\t= aspeed_sham_setkey,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA256_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"hmac(sha256)\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-hmac-sha256\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA256_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx) +\n\t\t\t\t\t\t\t\tsizeof(struct aspeed_sha_hmac_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n};\n\nstatic struct aspeed_hace_alg aspeed_ahash_algs_g6[] = {\n\t{\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA384_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"sha384\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-sha384\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA384_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA512_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"sha512\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-sha512\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA512_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg_base = \"sha384\",\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.setkey\t= aspeed_sham_setkey,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA384_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"hmac(sha384)\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-hmac-sha384\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA384_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx) +\n\t\t\t\t\t\t\t\tsizeof(struct aspeed_sha_hmac_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n\t{\n\t\t.alg_base = \"sha512\",\n\t\t.alg.ahash.base = {\n\t\t\t.init\t= aspeed_sham_init,\n\t\t\t.update\t= aspeed_sham_update,\n\t\t\t.final\t= aspeed_sham_final,\n\t\t\t.finup\t= aspeed_sham_finup,\n\t\t\t.digest\t= aspeed_sham_digest,\n\t\t\t.setkey\t= aspeed_sham_setkey,\n\t\t\t.export\t= aspeed_sham_export,\n\t\t\t.import\t= aspeed_sham_import,\n\t\t\t.halg = {\n\t\t\t\t.digestsize = SHA512_DIGEST_SIZE,\n\t\t\t\t.statesize = sizeof(struct aspeed_sham_reqctx),\n\t\t\t\t.base = {\n\t\t\t\t\t.cra_name\t\t= \"hmac(sha512)\",\n\t\t\t\t\t.cra_driver_name\t= \"aspeed-hmac-sha512\",\n\t\t\t\t\t.cra_priority\t\t= 300,\n\t\t\t\t\t.cra_flags\t\t= CRYPTO_ALG_TYPE_AHASH |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_ASYNC |\n\t\t\t\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t\t\t.cra_blocksize\t\t= SHA512_BLOCK_SIZE,\n\t\t\t\t\t.cra_ctxsize\t\t= sizeof(struct aspeed_sham_ctx) +\n\t\t\t\t\t\t\t\tsizeof(struct aspeed_sha_hmac_ctx),\n\t\t\t\t\t.cra_alignmask\t\t= 0,\n\t\t\t\t\t.cra_module\t\t= THIS_MODULE,\n\t\t\t\t\t.cra_init\t\t= aspeed_sham_cra_init,\n\t\t\t\t\t.cra_exit\t\t= aspeed_sham_cra_exit,\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\t.alg.ahash.op = {\n\t\t\t.do_one_request = aspeed_ahash_do_one,\n\t\t},\n\t},\n};\n\nvoid aspeed_unregister_hace_hash_algs(struct aspeed_hace_dev *hace_dev)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(aspeed_ahash_algs); i++)\n\t\tcrypto_engine_unregister_ahash(&aspeed_ahash_algs[i].alg.ahash);\n\n\tif (hace_dev->version != AST2600_VERSION)\n\t\treturn;\n\n\tfor (i = 0; i < ARRAY_SIZE(aspeed_ahash_algs_g6); i++)\n\t\tcrypto_engine_unregister_ahash(&aspeed_ahash_algs_g6[i].alg.ahash);\n}\n\nvoid aspeed_register_hace_hash_algs(struct aspeed_hace_dev *hace_dev)\n{\n\tint rc, i;\n\n\tAHASH_DBG(hace_dev, \"\\n\");\n\n\tfor (i = 0; i < ARRAY_SIZE(aspeed_ahash_algs); i++) {\n\t\taspeed_ahash_algs[i].hace_dev = hace_dev;\n\t\trc = crypto_engine_register_ahash(&aspeed_ahash_algs[i].alg.ahash);\n\t\tif (rc) {\n\t\t\tAHASH_DBG(hace_dev, \"Failed to register %s\\n\",\n\t\t\t\t  aspeed_ahash_algs[i].alg.ahash.base.halg.base.cra_name);\n\t\t}\n\t}\n\n\tif (hace_dev->version != AST2600_VERSION)\n\t\treturn;\n\n\tfor (i = 0; i < ARRAY_SIZE(aspeed_ahash_algs_g6); i++) {\n\t\taspeed_ahash_algs_g6[i].hace_dev = hace_dev;\n\t\trc = crypto_engine_register_ahash(&aspeed_ahash_algs_g6[i].alg.ahash);\n\t\tif (rc) {\n\t\t\tAHASH_DBG(hace_dev, \"Failed to register %s\\n\",\n\t\t\t\t  aspeed_ahash_algs_g6[i].alg.ahash.base.halg.base.cra_name);\n\t\t}\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}