{
  "module_name": "adf_vf_isr.c",
  "hash_id": "7115577e2b2c57e11b204f7d42f6ad8da93595bb7d9aee6e591a6f2c736410d7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/intel/qat/qat_common/adf_vf_isr.c",
  "human_readable_source": "\n \n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/types.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/workqueue.h>\n#include \"adf_accel_devices.h\"\n#include \"adf_common_drv.h\"\n#include \"adf_cfg.h\"\n#include \"adf_cfg_strings.h\"\n#include \"adf_cfg_common.h\"\n#include \"adf_transport_access_macros.h\"\n#include \"adf_transport_internal.h\"\n\n#define ADF_VINTSOU_OFFSET\t0x204\n#define ADF_VINTMSK_OFFSET\t0x208\n#define ADF_VINTSOU_BUN\t\tBIT(0)\n#define ADF_VINTSOU_PF2VF\tBIT(1)\n\nstatic struct workqueue_struct *adf_vf_stop_wq;\n\nstruct adf_vf_stop_data {\n\tstruct adf_accel_dev *accel_dev;\n\tstruct work_struct work;\n};\n\nvoid adf_enable_pf2vf_interrupts(struct adf_accel_dev *accel_dev)\n{\n\tvoid __iomem *pmisc_addr = adf_get_pmisc_base(accel_dev);\n\n\tADF_CSR_WR(pmisc_addr, ADF_VINTMSK_OFFSET, 0x0);\n}\n\nvoid adf_disable_pf2vf_interrupts(struct adf_accel_dev *accel_dev)\n{\n\tvoid __iomem *pmisc_addr = adf_get_pmisc_base(accel_dev);\n\n\tADF_CSR_WR(pmisc_addr, ADF_VINTMSK_OFFSET, 0x2);\n}\nEXPORT_SYMBOL_GPL(adf_disable_pf2vf_interrupts);\n\nstatic int adf_enable_msi(struct adf_accel_dev *accel_dev)\n{\n\tstruct adf_accel_pci *pci_dev_info = &accel_dev->accel_pci_dev;\n\tint stat = pci_alloc_irq_vectors(pci_dev_info->pci_dev, 1, 1,\n\t\t\t\t\t PCI_IRQ_MSI);\n\tif (unlikely(stat < 0)) {\n\t\tdev_err(&GET_DEV(accel_dev),\n\t\t\t\"Failed to enable MSI interrupt: %d\\n\", stat);\n\t\treturn stat;\n\t}\n\n\treturn 0;\n}\n\nstatic void adf_disable_msi(struct adf_accel_dev *accel_dev)\n{\n\tstruct pci_dev *pdev = accel_to_pci_dev(accel_dev);\n\n\tpci_free_irq_vectors(pdev);\n}\n\nstatic void adf_dev_stop_async(struct work_struct *work)\n{\n\tstruct adf_vf_stop_data *stop_data =\n\t\tcontainer_of(work, struct adf_vf_stop_data, work);\n\tstruct adf_accel_dev *accel_dev = stop_data->accel_dev;\n\n\tadf_dev_restarting_notify(accel_dev);\n\tadf_dev_down(accel_dev, false);\n\n\t \n\tadf_enable_pf2vf_interrupts(accel_dev);\n\tkfree(stop_data);\n}\n\nint adf_pf2vf_handle_pf_restarting(struct adf_accel_dev *accel_dev)\n{\n\tstruct adf_vf_stop_data *stop_data;\n\n\tclear_bit(ADF_STATUS_PF_RUNNING, &accel_dev->status);\n\tstop_data = kzalloc(sizeof(*stop_data), GFP_ATOMIC);\n\tif (!stop_data) {\n\t\tdev_err(&GET_DEV(accel_dev),\n\t\t\t\"Couldn't schedule stop for vf_%d\\n\",\n\t\t\taccel_dev->accel_id);\n\t\treturn -ENOMEM;\n\t}\n\tstop_data->accel_dev = accel_dev;\n\tINIT_WORK(&stop_data->work, adf_dev_stop_async);\n\tqueue_work(adf_vf_stop_wq, &stop_data->work);\n\n\treturn 0;\n}\n\nstatic void adf_pf2vf_bh_handler(void *data)\n{\n\tstruct adf_accel_dev *accel_dev = data;\n\tbool ret;\n\n\tret = adf_recv_and_handle_pf2vf_msg(accel_dev);\n\tif (ret)\n\t\t \n\t\tadf_enable_pf2vf_interrupts(accel_dev);\n\n\treturn;\n\n}\n\nstatic int adf_setup_pf2vf_bh(struct adf_accel_dev *accel_dev)\n{\n\ttasklet_init(&accel_dev->vf.pf2vf_bh_tasklet,\n\t\t     (void *)adf_pf2vf_bh_handler, (unsigned long)accel_dev);\n\n\tmutex_init(&accel_dev->vf.vf2pf_lock);\n\treturn 0;\n}\n\nstatic void adf_cleanup_pf2vf_bh(struct adf_accel_dev *accel_dev)\n{\n\ttasklet_disable(&accel_dev->vf.pf2vf_bh_tasklet);\n\ttasklet_kill(&accel_dev->vf.pf2vf_bh_tasklet);\n\tmutex_destroy(&accel_dev->vf.vf2pf_lock);\n}\n\nstatic irqreturn_t adf_isr(int irq, void *privdata)\n{\n\tstruct adf_accel_dev *accel_dev = privdata;\n\tstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\n\tstruct adf_hw_csr_ops *csr_ops = &hw_data->csr_ops;\n\tstruct adf_bar *pmisc =\n\t\t\t&GET_BARS(accel_dev)[hw_data->get_misc_bar_id(hw_data)];\n\tvoid __iomem *pmisc_bar_addr = pmisc->virt_addr;\n\tbool handled = false;\n\tu32 v_int, v_mask;\n\n\t \n\tv_int = ADF_CSR_RD(pmisc_bar_addr, ADF_VINTSOU_OFFSET);\n\n\t \n\tv_mask = ADF_CSR_RD(pmisc_bar_addr, ADF_VINTMSK_OFFSET);\n\n\t \n\tv_int &= ~v_mask;\n\n\t \n\tif (v_int & ADF_VINTSOU_PF2VF) {\n\t\t \n\t\tadf_disable_pf2vf_interrupts(accel_dev);\n\n\t\t \n\t\ttasklet_hi_schedule(&accel_dev->vf.pf2vf_bh_tasklet);\n\t\thandled = true;\n\t}\n\n\t \n\tif (v_int & ADF_VINTSOU_BUN) {\n\t\tstruct adf_etr_data *etr_data = accel_dev->transport;\n\t\tstruct adf_etr_bank_data *bank = &etr_data->banks[0];\n\n\t\t \n\t\tcsr_ops->write_csr_int_flag_and_col(bank->csr_addr,\n\t\t\t\t\t\t    bank->bank_number, 0);\n\t\ttasklet_hi_schedule(&bank->resp_handler);\n\t\thandled = true;\n\t}\n\n\treturn handled ? IRQ_HANDLED : IRQ_NONE;\n}\n\nstatic int adf_request_msi_irq(struct adf_accel_dev *accel_dev)\n{\n\tstruct pci_dev *pdev = accel_to_pci_dev(accel_dev);\n\tunsigned int cpu;\n\tint ret;\n\n\tsnprintf(accel_dev->vf.irq_name, ADF_MAX_MSIX_VECTOR_NAME,\n\t\t \"qat_%02x:%02d.%02d\", pdev->bus->number, PCI_SLOT(pdev->devfn),\n\t\t PCI_FUNC(pdev->devfn));\n\tret = request_irq(pdev->irq, adf_isr, 0, accel_dev->vf.irq_name,\n\t\t\t  (void *)accel_dev);\n\tif (ret) {\n\t\tdev_err(&GET_DEV(accel_dev), \"failed to enable irq for %s\\n\",\n\t\t\taccel_dev->vf.irq_name);\n\t\treturn ret;\n\t}\n\tcpu = accel_dev->accel_id % num_online_cpus();\n\tirq_set_affinity_hint(pdev->irq, get_cpu_mask(cpu));\n\taccel_dev->vf.irq_enabled = true;\n\n\treturn ret;\n}\n\nstatic int adf_setup_bh(struct adf_accel_dev *accel_dev)\n{\n\tstruct adf_etr_data *priv_data = accel_dev->transport;\n\n\ttasklet_init(&priv_data->banks[0].resp_handler, adf_response_handler,\n\t\t     (unsigned long)priv_data->banks);\n\treturn 0;\n}\n\nstatic void adf_cleanup_bh(struct adf_accel_dev *accel_dev)\n{\n\tstruct adf_etr_data *priv_data = accel_dev->transport;\n\n\ttasklet_disable(&priv_data->banks[0].resp_handler);\n\ttasklet_kill(&priv_data->banks[0].resp_handler);\n}\n\n \nvoid adf_vf_isr_resource_free(struct adf_accel_dev *accel_dev)\n{\n\tstruct pci_dev *pdev = accel_to_pci_dev(accel_dev);\n\n\tif (accel_dev->vf.irq_enabled) {\n\t\tirq_set_affinity_hint(pdev->irq, NULL);\n\t\tfree_irq(pdev->irq, accel_dev);\n\t}\n\tadf_cleanup_bh(accel_dev);\n\tadf_cleanup_pf2vf_bh(accel_dev);\n\tadf_disable_msi(accel_dev);\n}\nEXPORT_SYMBOL_GPL(adf_vf_isr_resource_free);\n\n \nint adf_vf_isr_resource_alloc(struct adf_accel_dev *accel_dev)\n{\n\tif (adf_enable_msi(accel_dev))\n\t\tgoto err_out;\n\n\tif (adf_setup_pf2vf_bh(accel_dev))\n\t\tgoto err_disable_msi;\n\n\tif (adf_setup_bh(accel_dev))\n\t\tgoto err_cleanup_pf2vf_bh;\n\n\tif (adf_request_msi_irq(accel_dev))\n\t\tgoto err_cleanup_bh;\n\n\treturn 0;\n\nerr_cleanup_bh:\n\tadf_cleanup_bh(accel_dev);\n\nerr_cleanup_pf2vf_bh:\n\tadf_cleanup_pf2vf_bh(accel_dev);\n\nerr_disable_msi:\n\tadf_disable_msi(accel_dev);\n\nerr_out:\n\treturn -EFAULT;\n}\nEXPORT_SYMBOL_GPL(adf_vf_isr_resource_alloc);\n\n \nvoid adf_flush_vf_wq(struct adf_accel_dev *accel_dev)\n{\n\tadf_disable_pf2vf_interrupts(accel_dev);\n\n\tflush_workqueue(adf_vf_stop_wq);\n}\nEXPORT_SYMBOL_GPL(adf_flush_vf_wq);\n\n \nint __init adf_init_vf_wq(void)\n{\n\tadf_vf_stop_wq = alloc_workqueue(\"adf_vf_stop_wq\", WQ_MEM_RECLAIM, 0);\n\n\treturn !adf_vf_stop_wq ? -EFAULT : 0;\n}\n\nvoid adf_exit_vf_wq(void)\n{\n\tif (adf_vf_stop_wq)\n\t\tdestroy_workqueue(adf_vf_stop_wq);\n\n\tadf_vf_stop_wq = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}