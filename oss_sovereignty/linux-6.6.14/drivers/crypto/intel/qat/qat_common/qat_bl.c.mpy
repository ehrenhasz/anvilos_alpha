{
  "module_name": "qat_bl.c",
  "hash_id": "1a94b0c1a5f1b7a88dadb4c407603f31f0461c16581f21832a0354f19426d5d8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/intel/qat/qat_common/qat_bl.c",
  "human_readable_source": "\n \n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/pci.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include \"adf_accel_devices.h\"\n#include \"qat_bl.h\"\n#include \"qat_crypto.h\"\n\nvoid qat_bl_free_bufl(struct adf_accel_dev *accel_dev,\n\t\t      struct qat_request_buffs *buf)\n{\n\tstruct device *dev = &GET_DEV(accel_dev);\n\tstruct qat_alg_buf_list *bl = buf->bl;\n\tstruct qat_alg_buf_list *blout = buf->blout;\n\tdma_addr_t blp = buf->blp;\n\tdma_addr_t blpout = buf->bloutp;\n\tsize_t sz = buf->sz;\n\tsize_t sz_out = buf->sz_out;\n\tint bl_dma_dir;\n\tint i;\n\n\tbl_dma_dir = blp != blpout ? DMA_TO_DEVICE : DMA_BIDIRECTIONAL;\n\n\tfor (i = 0; i < bl->num_bufs; i++)\n\t\tdma_unmap_single(dev, bl->buffers[i].addr,\n\t\t\t\t bl->buffers[i].len, bl_dma_dir);\n\n\tdma_unmap_single(dev, blp, sz, DMA_TO_DEVICE);\n\n\tif (!buf->sgl_src_valid)\n\t\tkfree(bl);\n\n\tif (blp != blpout) {\n\t\tfor (i = 0; i < blout->num_mapped_bufs; i++) {\n\t\t\tdma_unmap_single(dev, blout->buffers[i].addr,\n\t\t\t\t\t blout->buffers[i].len,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t}\n\t\tdma_unmap_single(dev, blpout, sz_out, DMA_TO_DEVICE);\n\n\t\tif (!buf->sgl_dst_valid)\n\t\t\tkfree(blout);\n\t}\n}\n\nstatic int __qat_bl_sgl_to_bufl(struct adf_accel_dev *accel_dev,\n\t\t\t\tstruct scatterlist *sgl,\n\t\t\t\tstruct scatterlist *sglout,\n\t\t\t\tstruct qat_request_buffs *buf,\n\t\t\t\tdma_addr_t extra_dst_buff,\n\t\t\t\tsize_t sz_extra_dst_buff,\n\t\t\t\tunsigned int sskip,\n\t\t\t\tunsigned int dskip,\n\t\t\t\tgfp_t flags)\n{\n\tstruct device *dev = &GET_DEV(accel_dev);\n\tint i, sg_nctr = 0;\n\tint n = sg_nents(sgl);\n\tstruct qat_alg_buf_list *bufl;\n\tstruct qat_alg_buf_list *buflout = NULL;\n\tdma_addr_t blp = DMA_MAPPING_ERROR;\n\tdma_addr_t bloutp = DMA_MAPPING_ERROR;\n\tstruct scatterlist *sg;\n\tsize_t sz_out, sz = struct_size(bufl, buffers, n);\n\tint node = dev_to_node(&GET_DEV(accel_dev));\n\tunsigned int left;\n\tint bufl_dma_dir;\n\n\tif (unlikely(!n))\n\t\treturn -EINVAL;\n\n\tbuf->sgl_src_valid = false;\n\tbuf->sgl_dst_valid = false;\n\n\tif (n > QAT_MAX_BUFF_DESC) {\n\t\tbufl = kzalloc_node(sz, flags, node);\n\t\tif (unlikely(!bufl))\n\t\t\treturn -ENOMEM;\n\t} else {\n\t\tbufl = &buf->sgl_src.sgl_hdr;\n\t\tmemset(bufl, 0, sizeof(struct qat_alg_buf_list));\n\t\tbuf->sgl_src_valid = true;\n\t}\n\n\tbufl_dma_dir = sgl != sglout ? DMA_TO_DEVICE : DMA_BIDIRECTIONAL;\n\n\tfor (i = 0; i < n; i++)\n\t\tbufl->buffers[i].addr = DMA_MAPPING_ERROR;\n\n\tleft = sskip;\n\n\tfor_each_sg(sgl, sg, n, i) {\n\t\tint y = sg_nctr;\n\n\t\tif (!sg->length)\n\t\t\tcontinue;\n\n\t\tif (left >= sg->length) {\n\t\t\tleft -= sg->length;\n\t\t\tcontinue;\n\t\t}\n\t\tbufl->buffers[y].addr = dma_map_single(dev, sg_virt(sg) + left,\n\t\t\t\t\t\t       sg->length - left,\n\t\t\t\t\t\t       bufl_dma_dir);\n\t\tbufl->buffers[y].len = sg->length;\n\t\tif (unlikely(dma_mapping_error(dev, bufl->buffers[y].addr)))\n\t\t\tgoto err_in;\n\t\tsg_nctr++;\n\t\tif (left) {\n\t\t\tbufl->buffers[y].len -= left;\n\t\t\tleft = 0;\n\t\t}\n\t}\n\tbufl->num_bufs = sg_nctr;\n\tblp = dma_map_single(dev, bufl, sz, DMA_TO_DEVICE);\n\tif (unlikely(dma_mapping_error(dev, blp)))\n\t\tgoto err_in;\n\tbuf->bl = bufl;\n\tbuf->blp = blp;\n\tbuf->sz = sz;\n\t \n\tif (sgl != sglout) {\n\t\tstruct qat_alg_buf *buffers;\n\t\tint extra_buff = extra_dst_buff ? 1 : 0;\n\t\tint n_sglout = sg_nents(sglout);\n\n\t\tn = n_sglout + extra_buff;\n\t\tsz_out = struct_size(buflout, buffers, n);\n\t\tleft = dskip;\n\n\t\tsg_nctr = 0;\n\n\t\tif (n > QAT_MAX_BUFF_DESC) {\n\t\t\tbuflout = kzalloc_node(sz_out, flags, node);\n\t\t\tif (unlikely(!buflout))\n\t\t\t\tgoto err_in;\n\t\t} else {\n\t\t\tbuflout = &buf->sgl_dst.sgl_hdr;\n\t\t\tmemset(buflout, 0, sizeof(struct qat_alg_buf_list));\n\t\t\tbuf->sgl_dst_valid = true;\n\t\t}\n\n\t\tbuffers = buflout->buffers;\n\t\tfor (i = 0; i < n; i++)\n\t\t\tbuffers[i].addr = DMA_MAPPING_ERROR;\n\n\t\tfor_each_sg(sglout, sg, n_sglout, i) {\n\t\t\tint y = sg_nctr;\n\n\t\t\tif (!sg->length)\n\t\t\t\tcontinue;\n\n\t\t\tif (left >= sg->length) {\n\t\t\t\tleft -= sg->length;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbuffers[y].addr = dma_map_single(dev, sg_virt(sg) + left,\n\t\t\t\t\t\t\t sg->length - left,\n\t\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tif (unlikely(dma_mapping_error(dev, buffers[y].addr)))\n\t\t\t\tgoto err_out;\n\t\t\tbuffers[y].len = sg->length;\n\t\t\tsg_nctr++;\n\t\t\tif (left) {\n\t\t\t\tbuffers[y].len -= left;\n\t\t\t\tleft = 0;\n\t\t\t}\n\t\t}\n\t\tif (extra_buff) {\n\t\t\tbuffers[sg_nctr].addr = extra_dst_buff;\n\t\t\tbuffers[sg_nctr].len = sz_extra_dst_buff;\n\t\t}\n\n\t\tbuflout->num_bufs = sg_nctr;\n\t\tbuflout->num_bufs += extra_buff;\n\t\tbuflout->num_mapped_bufs = sg_nctr;\n\t\tbloutp = dma_map_single(dev, buflout, sz_out, DMA_TO_DEVICE);\n\t\tif (unlikely(dma_mapping_error(dev, bloutp)))\n\t\t\tgoto err_out;\n\t\tbuf->blout = buflout;\n\t\tbuf->bloutp = bloutp;\n\t\tbuf->sz_out = sz_out;\n\t} else {\n\t\t \n\t\tbuf->bloutp = buf->blp;\n\t\tbuf->sz_out = 0;\n\t}\n\treturn 0;\n\nerr_out:\n\tif (!dma_mapping_error(dev, bloutp))\n\t\tdma_unmap_single(dev, bloutp, sz_out, DMA_TO_DEVICE);\n\n\tn = sg_nents(sglout);\n\tfor (i = 0; i < n; i++) {\n\t\tif (buflout->buffers[i].addr == extra_dst_buff)\n\t\t\tbreak;\n\t\tif (!dma_mapping_error(dev, buflout->buffers[i].addr))\n\t\t\tdma_unmap_single(dev, buflout->buffers[i].addr,\n\t\t\t\t\t buflout->buffers[i].len,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t}\n\n\tif (!buf->sgl_dst_valid)\n\t\tkfree(buflout);\n\nerr_in:\n\tif (!dma_mapping_error(dev, blp))\n\t\tdma_unmap_single(dev, blp, sz, DMA_TO_DEVICE);\n\n\tn = sg_nents(sgl);\n\tfor (i = 0; i < n; i++)\n\t\tif (!dma_mapping_error(dev, bufl->buffers[i].addr))\n\t\t\tdma_unmap_single(dev, bufl->buffers[i].addr,\n\t\t\t\t\t bufl->buffers[i].len,\n\t\t\t\t\t bufl_dma_dir);\n\n\tif (!buf->sgl_src_valid)\n\t\tkfree(bufl);\n\n\tdev_err(dev, \"Failed to map buf for dma\\n\");\n\treturn -ENOMEM;\n}\n\nint qat_bl_sgl_to_bufl(struct adf_accel_dev *accel_dev,\n\t\t       struct scatterlist *sgl,\n\t\t       struct scatterlist *sglout,\n\t\t       struct qat_request_buffs *buf,\n\t\t       struct qat_sgl_to_bufl_params *params,\n\t\t       gfp_t flags)\n{\n\tdma_addr_t extra_dst_buff = 0;\n\tsize_t sz_extra_dst_buff = 0;\n\tunsigned int sskip = 0;\n\tunsigned int dskip = 0;\n\n\tif (params) {\n\t\textra_dst_buff = params->extra_dst_buff;\n\t\tsz_extra_dst_buff = params->sz_extra_dst_buff;\n\t\tsskip = params->sskip;\n\t\tdskip = params->dskip;\n\t}\n\n\treturn __qat_bl_sgl_to_bufl(accel_dev, sgl, sglout, buf,\n\t\t\t\t    extra_dst_buff, sz_extra_dst_buff,\n\t\t\t\t    sskip, dskip, flags);\n}\n\nstatic void qat_bl_sgl_unmap(struct adf_accel_dev *accel_dev,\n\t\t\t     struct qat_alg_buf_list *bl)\n{\n\tstruct device *dev = &GET_DEV(accel_dev);\n\tint n = bl->num_bufs;\n\tint i;\n\n\tfor (i = 0; i < n; i++)\n\t\tif (!dma_mapping_error(dev, bl->buffers[i].addr))\n\t\t\tdma_unmap_single(dev, bl->buffers[i].addr,\n\t\t\t\t\t bl->buffers[i].len, DMA_FROM_DEVICE);\n}\n\nstatic int qat_bl_sgl_map(struct adf_accel_dev *accel_dev,\n\t\t\t  struct scatterlist *sgl,\n\t\t\t  struct qat_alg_buf_list **bl)\n{\n\tstruct device *dev = &GET_DEV(accel_dev);\n\tstruct qat_alg_buf_list *bufl;\n\tint node = dev_to_node(dev);\n\tstruct scatterlist *sg;\n\tint n, i, sg_nctr;\n\tsize_t sz;\n\n\tn = sg_nents(sgl);\n\tsz = struct_size(bufl, buffers, n);\n\tbufl = kzalloc_node(sz, GFP_KERNEL, node);\n\tif (unlikely(!bufl))\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < n; i++)\n\t\tbufl->buffers[i].addr = DMA_MAPPING_ERROR;\n\n\tsg_nctr = 0;\n\tfor_each_sg(sgl, sg, n, i) {\n\t\tint y = sg_nctr;\n\n\t\tif (!sg->length)\n\t\t\tcontinue;\n\n\t\tbufl->buffers[y].addr = dma_map_single(dev, sg_virt(sg),\n\t\t\t\t\t\t       sg->length,\n\t\t\t\t\t\t       DMA_FROM_DEVICE);\n\t\tbufl->buffers[y].len = sg->length;\n\t\tif (unlikely(dma_mapping_error(dev, bufl->buffers[y].addr)))\n\t\t\tgoto err_map;\n\t\tsg_nctr++;\n\t}\n\tbufl->num_bufs = sg_nctr;\n\tbufl->num_mapped_bufs = sg_nctr;\n\n\t*bl = bufl;\n\n\treturn 0;\n\nerr_map:\n\tfor (i = 0; i < n; i++)\n\t\tif (!dma_mapping_error(dev, bufl->buffers[i].addr))\n\t\t\tdma_unmap_single(dev, bufl->buffers[i].addr,\n\t\t\t\t\t bufl->buffers[i].len,\n\t\t\t\t\t DMA_FROM_DEVICE);\n\tkfree(bufl);\n\t*bl = NULL;\n\n\treturn -ENOMEM;\n}\n\nstatic void qat_bl_sgl_free_unmap(struct adf_accel_dev *accel_dev,\n\t\t\t\t  struct scatterlist *sgl,\n\t\t\t\t  struct qat_alg_buf_list *bl,\n\t\t\t\t  bool free_bl)\n{\n\tif (bl) {\n\t\tqat_bl_sgl_unmap(accel_dev, bl);\n\n\t\tif (free_bl)\n\t\t\tkfree(bl);\n\t}\n\tif (sgl)\n\t\tsgl_free(sgl);\n}\n\nstatic int qat_bl_sgl_alloc_map(struct adf_accel_dev *accel_dev,\n\t\t\t\tstruct scatterlist **sgl,\n\t\t\t\tstruct qat_alg_buf_list **bl,\n\t\t\t\tunsigned int dlen,\n\t\t\t\tgfp_t gfp)\n{\n\tstruct scatterlist *dst;\n\tint ret;\n\n\tdst = sgl_alloc(dlen, gfp, NULL);\n\tif (!dst) {\n\t\tdev_err(&GET_DEV(accel_dev), \"sg_alloc failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tret = qat_bl_sgl_map(accel_dev, dst, bl);\n\tif (ret)\n\t\tgoto err;\n\n\t*sgl = dst;\n\n\treturn 0;\n\nerr:\n\tsgl_free(dst);\n\t*sgl = NULL;\n\treturn ret;\n}\n\nint qat_bl_realloc_map_new_dst(struct adf_accel_dev *accel_dev,\n\t\t\t       struct scatterlist **sg,\n\t\t\t       unsigned int dlen,\n\t\t\t       struct qat_request_buffs *qat_bufs,\n\t\t\t       gfp_t gfp)\n{\n\tstruct device *dev = &GET_DEV(accel_dev);\n\tdma_addr_t new_blp = DMA_MAPPING_ERROR;\n\tstruct qat_alg_buf_list *new_bl;\n\tstruct scatterlist *new_sg;\n\tsize_t new_bl_size;\n\tint ret;\n\n\tret = qat_bl_sgl_alloc_map(accel_dev, &new_sg, &new_bl, dlen, gfp);\n\tif (ret)\n\t\treturn ret;\n\n\tnew_bl_size = struct_size(new_bl, buffers, new_bl->num_bufs);\n\n\t \n\tnew_blp = dma_map_single(dev, new_bl, new_bl_size, DMA_TO_DEVICE);\n\tif (unlikely(dma_mapping_error(dev, new_blp)))\n\t\tgoto err;\n\n\t \n\tdma_unmap_single(dev, qat_bufs->bloutp, qat_bufs->sz_out, DMA_TO_DEVICE);\n\n\t \n\tqat_bl_sgl_free_unmap(accel_dev, *sg, qat_bufs->blout,\n\t\t\t      !qat_bufs->sgl_dst_valid);\n\n\tqat_bufs->sgl_dst_valid = false;\n\tqat_bufs->blout = new_bl;\n\tqat_bufs->bloutp = new_blp;\n\tqat_bufs->sz_out = new_bl_size;\n\n\t*sg = new_sg;\n\n\treturn 0;\nerr:\n\tqat_bl_sgl_free_unmap(accel_dev, new_sg, new_bl, true);\n\n\tif (!dma_mapping_error(dev, new_blp))\n\t\tdma_unmap_single(dev, new_blp, new_bl_size, DMA_TO_DEVICE);\n\n\treturn -ENOMEM;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}