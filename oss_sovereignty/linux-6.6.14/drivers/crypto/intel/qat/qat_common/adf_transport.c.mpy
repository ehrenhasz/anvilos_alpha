{
  "module_name": "adf_transport.c",
  "hash_id": "d9ca53726ae1af1b38a97372ae1622f7d4b60873c79deec546d56e3a9859887c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/intel/qat/qat_common/adf_transport.c",
  "human_readable_source": "\n \n#include <linux/delay.h>\n#include <linux/nospec.h>\n#include \"adf_accel_devices.h\"\n#include \"adf_transport_internal.h\"\n#include \"adf_transport_access_macros.h\"\n#include \"adf_cfg.h\"\n#include \"adf_common_drv.h\"\n\n#define ADF_MAX_RING_THRESHOLD\t\t80\n#define ADF_PERCENT(tot, percent)\t(((tot) * (percent)) / 100)\n\nstatic inline u32 adf_modulo(u32 data, u32 shift)\n{\n\tu32 div = data >> shift;\n\tu32 mult = div << shift;\n\n\treturn data - mult;\n}\n\nstatic inline int adf_check_ring_alignment(u64 addr, u64 size)\n{\n\tif (((size - 1) & addr) != 0)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int adf_verify_ring_size(u32 msg_size, u32 msg_num)\n{\n\tint i = ADF_MIN_RING_SIZE;\n\n\tfor (; i <= ADF_MAX_RING_SIZE; i++)\n\t\tif ((msg_size * msg_num) == ADF_SIZE_TO_RING_SIZE_IN_BYTES(i))\n\t\t\treturn i;\n\n\treturn ADF_DEFAULT_RING_SIZE;\n}\n\nstatic int adf_reserve_ring(struct adf_etr_bank_data *bank, u32 ring)\n{\n\tspin_lock(&bank->lock);\n\tif (bank->ring_mask & (1 << ring)) {\n\t\tspin_unlock(&bank->lock);\n\t\treturn -EFAULT;\n\t}\n\tbank->ring_mask |= (1 << ring);\n\tspin_unlock(&bank->lock);\n\treturn 0;\n}\n\nstatic void adf_unreserve_ring(struct adf_etr_bank_data *bank, u32 ring)\n{\n\tspin_lock(&bank->lock);\n\tbank->ring_mask &= ~(1 << ring);\n\tspin_unlock(&bank->lock);\n}\n\nstatic void adf_enable_ring_irq(struct adf_etr_bank_data *bank, u32 ring)\n{\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(bank->accel_dev);\n\n\tspin_lock_bh(&bank->lock);\n\tbank->irq_mask |= (1 << ring);\n\tspin_unlock_bh(&bank->lock);\n\tcsr_ops->write_csr_int_col_en(bank->csr_addr, bank->bank_number,\n\t\t\t\t      bank->irq_mask);\n\tcsr_ops->write_csr_int_col_ctl(bank->csr_addr, bank->bank_number,\n\t\t\t\t       bank->irq_coalesc_timer);\n}\n\nstatic void adf_disable_ring_irq(struct adf_etr_bank_data *bank, u32 ring)\n{\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(bank->accel_dev);\n\n\tspin_lock_bh(&bank->lock);\n\tbank->irq_mask &= ~(1 << ring);\n\tspin_unlock_bh(&bank->lock);\n\tcsr_ops->write_csr_int_col_en(bank->csr_addr, bank->bank_number,\n\t\t\t\t      bank->irq_mask);\n}\n\nbool adf_ring_nearly_full(struct adf_etr_ring_data *ring)\n{\n\treturn atomic_read(ring->inflights) > ring->threshold;\n}\n\nint adf_send_message(struct adf_etr_ring_data *ring, u32 *msg)\n{\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(ring->bank->accel_dev);\n\n\tif (atomic_add_return(1, ring->inflights) >\n\t    ADF_MAX_INFLIGHTS(ring->ring_size, ring->msg_size)) {\n\t\tatomic_dec(ring->inflights);\n\t\treturn -EAGAIN;\n\t}\n\tspin_lock_bh(&ring->lock);\n\tmemcpy((void *)((uintptr_t)ring->base_addr + ring->tail), msg,\n\t       ADF_MSG_SIZE_TO_BYTES(ring->msg_size));\n\n\tring->tail = adf_modulo(ring->tail +\n\t\t\t\tADF_MSG_SIZE_TO_BYTES(ring->msg_size),\n\t\t\t\tADF_RING_SIZE_MODULO(ring->ring_size));\n\tcsr_ops->write_csr_ring_tail(ring->bank->csr_addr,\n\t\t\t\t     ring->bank->bank_number, ring->ring_number,\n\t\t\t\t     ring->tail);\n\tspin_unlock_bh(&ring->lock);\n\n\treturn 0;\n}\n\nstatic int adf_handle_response(struct adf_etr_ring_data *ring)\n{\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(ring->bank->accel_dev);\n\tu32 msg_counter = 0;\n\tu32 *msg = (u32 *)((uintptr_t)ring->base_addr + ring->head);\n\n\twhile (*msg != ADF_RING_EMPTY_SIG) {\n\t\tring->callback((u32 *)msg);\n\t\tatomic_dec(ring->inflights);\n\t\t*msg = ADF_RING_EMPTY_SIG;\n\t\tring->head = adf_modulo(ring->head +\n\t\t\t\t\tADF_MSG_SIZE_TO_BYTES(ring->msg_size),\n\t\t\t\t\tADF_RING_SIZE_MODULO(ring->ring_size));\n\t\tmsg_counter++;\n\t\tmsg = (u32 *)((uintptr_t)ring->base_addr + ring->head);\n\t}\n\tif (msg_counter > 0) {\n\t\tcsr_ops->write_csr_ring_head(ring->bank->csr_addr,\n\t\t\t\t\t     ring->bank->bank_number,\n\t\t\t\t\t     ring->ring_number, ring->head);\n\t}\n\treturn 0;\n}\n\nstatic void adf_configure_tx_ring(struct adf_etr_ring_data *ring)\n{\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(ring->bank->accel_dev);\n\tu32 ring_config = BUILD_RING_CONFIG(ring->ring_size);\n\n\tcsr_ops->write_csr_ring_config(ring->bank->csr_addr,\n\t\t\t\t       ring->bank->bank_number,\n\t\t\t\t       ring->ring_number, ring_config);\n\n}\n\nstatic void adf_configure_rx_ring(struct adf_etr_ring_data *ring)\n{\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(ring->bank->accel_dev);\n\tu32 ring_config =\n\t\t\tBUILD_RESP_RING_CONFIG(ring->ring_size,\n\t\t\t\t\t       ADF_RING_NEAR_WATERMARK_512,\n\t\t\t\t\t       ADF_RING_NEAR_WATERMARK_0);\n\n\tcsr_ops->write_csr_ring_config(ring->bank->csr_addr,\n\t\t\t\t       ring->bank->bank_number,\n\t\t\t\t       ring->ring_number, ring_config);\n}\n\nstatic int adf_init_ring(struct adf_etr_ring_data *ring)\n{\n\tstruct adf_etr_bank_data *bank = ring->bank;\n\tstruct adf_accel_dev *accel_dev = bank->accel_dev;\n\tstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(accel_dev);\n\tu64 ring_base;\n\tu32 ring_size_bytes =\n\t\t\tADF_SIZE_TO_RING_SIZE_IN_BYTES(ring->ring_size);\n\n\tring_size_bytes = ADF_RING_SIZE_BYTES_MIN(ring_size_bytes);\n\tring->base_addr = dma_alloc_coherent(&GET_DEV(accel_dev),\n\t\t\t\t\t     ring_size_bytes, &ring->dma_addr,\n\t\t\t\t\t     GFP_KERNEL);\n\tif (!ring->base_addr)\n\t\treturn -ENOMEM;\n\n\tmemset(ring->base_addr, 0x7F, ring_size_bytes);\n\t \n\tif (adf_check_ring_alignment(ring->dma_addr, ring_size_bytes)) {\n\t\tdev_err(&GET_DEV(accel_dev), \"Ring address not aligned\\n\");\n\t\tdma_free_coherent(&GET_DEV(accel_dev), ring_size_bytes,\n\t\t\t\t  ring->base_addr, ring->dma_addr);\n\t\tring->base_addr = NULL;\n\t\treturn -EFAULT;\n\t}\n\n\tif (hw_data->tx_rings_mask & (1 << ring->ring_number))\n\t\tadf_configure_tx_ring(ring);\n\n\telse\n\t\tadf_configure_rx_ring(ring);\n\n\tring_base = csr_ops->build_csr_ring_base_addr(ring->dma_addr,\n\t\t\t\t\t\t      ring->ring_size);\n\n\tcsr_ops->write_csr_ring_base(ring->bank->csr_addr,\n\t\t\t\t     ring->bank->bank_number, ring->ring_number,\n\t\t\t\t     ring_base);\n\tspin_lock_init(&ring->lock);\n\treturn 0;\n}\n\nstatic void adf_cleanup_ring(struct adf_etr_ring_data *ring)\n{\n\tu32 ring_size_bytes =\n\t\t\tADF_SIZE_TO_RING_SIZE_IN_BYTES(ring->ring_size);\n\tring_size_bytes = ADF_RING_SIZE_BYTES_MIN(ring_size_bytes);\n\n\tif (ring->base_addr) {\n\t\tmemset(ring->base_addr, 0x7F, ring_size_bytes);\n\t\tdma_free_coherent(&GET_DEV(ring->bank->accel_dev),\n\t\t\t\t  ring_size_bytes, ring->base_addr,\n\t\t\t\t  ring->dma_addr);\n\t}\n}\n\nint adf_create_ring(struct adf_accel_dev *accel_dev, const char *section,\n\t\t    u32 bank_num, u32 num_msgs,\n\t\t    u32 msg_size, const char *ring_name,\n\t\t    adf_callback_fn callback, int poll_mode,\n\t\t    struct adf_etr_ring_data **ring_ptr)\n{\n\tstruct adf_etr_data *transport_data = accel_dev->transport;\n\tu8 num_rings_per_bank = GET_NUM_RINGS_PER_BANK(accel_dev);\n\tstruct adf_etr_bank_data *bank;\n\tstruct adf_etr_ring_data *ring;\n\tchar val[ADF_CFG_MAX_VAL_LEN_IN_BYTES];\n\tint max_inflights;\n\tu32 ring_num;\n\tint ret;\n\n\tif (bank_num >= GET_MAX_BANKS(accel_dev)) {\n\t\tdev_err(&GET_DEV(accel_dev), \"Invalid bank number\\n\");\n\t\treturn -EFAULT;\n\t}\n\tif (msg_size > ADF_MSG_SIZE_TO_BYTES(ADF_MAX_MSG_SIZE)) {\n\t\tdev_err(&GET_DEV(accel_dev), \"Invalid msg size\\n\");\n\t\treturn -EFAULT;\n\t}\n\tif (ADF_MAX_INFLIGHTS(adf_verify_ring_size(msg_size, num_msgs),\n\t\t\t      ADF_BYTES_TO_MSG_SIZE(msg_size)) < 2) {\n\t\tdev_err(&GET_DEV(accel_dev),\n\t\t\t\"Invalid ring size for given msg size\\n\");\n\t\treturn -EFAULT;\n\t}\n\tif (adf_cfg_get_param_value(accel_dev, section, ring_name, val)) {\n\t\tdev_err(&GET_DEV(accel_dev), \"Section %s, no such entry : %s\\n\",\n\t\t\tsection, ring_name);\n\t\treturn -EFAULT;\n\t}\n\tif (kstrtouint(val, 10, &ring_num)) {\n\t\tdev_err(&GET_DEV(accel_dev), \"Can't get ring number\\n\");\n\t\treturn -EFAULT;\n\t}\n\tif (ring_num >= num_rings_per_bank) {\n\t\tdev_err(&GET_DEV(accel_dev), \"Invalid ring number\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tring_num = array_index_nospec(ring_num, num_rings_per_bank);\n\tbank = &transport_data->banks[bank_num];\n\tif (adf_reserve_ring(bank, ring_num)) {\n\t\tdev_err(&GET_DEV(accel_dev), \"Ring %d, %s already exists.\\n\",\n\t\t\tring_num, ring_name);\n\t\treturn -EFAULT;\n\t}\n\tring = &bank->rings[ring_num];\n\tring->ring_number = ring_num;\n\tring->bank = bank;\n\tring->callback = callback;\n\tring->msg_size = ADF_BYTES_TO_MSG_SIZE(msg_size);\n\tring->ring_size = adf_verify_ring_size(msg_size, num_msgs);\n\tring->head = 0;\n\tring->tail = 0;\n\tmax_inflights = ADF_MAX_INFLIGHTS(ring->ring_size, ring->msg_size);\n\tring->threshold = ADF_PERCENT(max_inflights, ADF_MAX_RING_THRESHOLD);\n\tatomic_set(ring->inflights, 0);\n\tret = adf_init_ring(ring);\n\tif (ret)\n\t\tgoto err;\n\n\t \n\tadf_update_ring_arb(ring);\n\n\tif (adf_ring_debugfs_add(ring, ring_name)) {\n\t\tdev_err(&GET_DEV(accel_dev),\n\t\t\t\"Couldn't add ring debugfs entry\\n\");\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\t \n\tif (callback && (!poll_mode))\n\t\tadf_enable_ring_irq(bank, ring->ring_number);\n\t*ring_ptr = ring;\n\treturn 0;\nerr:\n\tadf_cleanup_ring(ring);\n\tadf_unreserve_ring(bank, ring_num);\n\tadf_update_ring_arb(ring);\n\treturn ret;\n}\n\nvoid adf_remove_ring(struct adf_etr_ring_data *ring)\n{\n\tstruct adf_etr_bank_data *bank = ring->bank;\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(bank->accel_dev);\n\n\t \n\tadf_disable_ring_irq(bank, ring->ring_number);\n\n\t \n\n\tcsr_ops->write_csr_ring_config(bank->csr_addr, bank->bank_number,\n\t\t\t\t       ring->ring_number, 0);\n\tcsr_ops->write_csr_ring_base(bank->csr_addr, bank->bank_number,\n\t\t\t\t     ring->ring_number, 0);\n\tadf_ring_debugfs_rm(ring);\n\tadf_unreserve_ring(bank, ring->ring_number);\n\t \n\tadf_update_ring_arb(ring);\n\tadf_cleanup_ring(ring);\n}\n\nstatic void adf_ring_response_handler(struct adf_etr_bank_data *bank)\n{\n\tstruct adf_accel_dev *accel_dev = bank->accel_dev;\n\tu8 num_rings_per_bank = GET_NUM_RINGS_PER_BANK(accel_dev);\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(accel_dev);\n\tunsigned long empty_rings;\n\tint i;\n\n\tempty_rings = csr_ops->read_csr_e_stat(bank->csr_addr,\n\t\t\t\t\t       bank->bank_number);\n\tempty_rings = ~empty_rings & bank->irq_mask;\n\n\tfor_each_set_bit(i, &empty_rings, num_rings_per_bank)\n\t\tadf_handle_response(&bank->rings[i]);\n}\n\nvoid adf_response_handler(uintptr_t bank_addr)\n{\n\tstruct adf_etr_bank_data *bank = (void *)bank_addr;\n\tstruct adf_hw_csr_ops *csr_ops = GET_CSR_OPS(bank->accel_dev);\n\n\t \n\tadf_ring_response_handler(bank);\n\n\tcsr_ops->write_csr_int_flag_and_col(bank->csr_addr, bank->bank_number,\n\t\t\t\t\t    bank->irq_mask);\n}\n\nstatic inline int adf_get_cfg_int(struct adf_accel_dev *accel_dev,\n\t\t\t\t  const char *section, const char *format,\n\t\t\t\t  u32 key, u32 *value)\n{\n\tchar key_buf[ADF_CFG_MAX_KEY_LEN_IN_BYTES];\n\tchar val_buf[ADF_CFG_MAX_VAL_LEN_IN_BYTES];\n\n\tsnprintf(key_buf, ADF_CFG_MAX_KEY_LEN_IN_BYTES, format, key);\n\n\tif (adf_cfg_get_param_value(accel_dev, section, key_buf, val_buf))\n\t\treturn -EFAULT;\n\n\tif (kstrtouint(val_buf, 10, value))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic void adf_get_coalesc_timer(struct adf_etr_bank_data *bank,\n\t\t\t\t  const char *section,\n\t\t\t\t  u32 bank_num_in_accel)\n{\n\tif (adf_get_cfg_int(bank->accel_dev, section,\n\t\t\t    ADF_ETRMGR_COALESCE_TIMER_FORMAT,\n\t\t\t    bank_num_in_accel, &bank->irq_coalesc_timer))\n\t\tbank->irq_coalesc_timer = ADF_COALESCING_DEF_TIME;\n\n\tif (ADF_COALESCING_MAX_TIME < bank->irq_coalesc_timer ||\n\t    ADF_COALESCING_MIN_TIME > bank->irq_coalesc_timer)\n\t\tbank->irq_coalesc_timer = ADF_COALESCING_DEF_TIME;\n}\n\nstatic int adf_init_bank(struct adf_accel_dev *accel_dev,\n\t\t\t struct adf_etr_bank_data *bank,\n\t\t\t u32 bank_num, void __iomem *csr_addr)\n{\n\tstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\n\tu8 num_rings_per_bank = hw_data->num_rings_per_bank;\n\tstruct adf_hw_csr_ops *csr_ops = &hw_data->csr_ops;\n\tu32 irq_mask = BIT(num_rings_per_bank) - 1;\n\tstruct adf_etr_ring_data *ring;\n\tstruct adf_etr_ring_data *tx_ring;\n\tu32 i, coalesc_enabled = 0;\n\tunsigned long ring_mask;\n\tint size;\n\n\tmemset(bank, 0, sizeof(*bank));\n\tbank->bank_number = bank_num;\n\tbank->csr_addr = csr_addr;\n\tbank->accel_dev = accel_dev;\n\tspin_lock_init(&bank->lock);\n\n\t \n\tsize = num_rings_per_bank * sizeof(struct adf_etr_ring_data);\n\tbank->rings = kzalloc_node(size, GFP_KERNEL,\n\t\t\t\t   dev_to_node(&GET_DEV(accel_dev)));\n\tif (!bank->rings)\n\t\treturn -ENOMEM;\n\n\t \n\tif ((adf_get_cfg_int(accel_dev, \"Accelerator0\",\n\t\t\t     ADF_ETRMGR_COALESCING_ENABLED_FORMAT, bank_num,\n\t\t\t     &coalesc_enabled) == 0) && coalesc_enabled)\n\t\tadf_get_coalesc_timer(bank, \"Accelerator0\", bank_num);\n\telse\n\t\tbank->irq_coalesc_timer = ADF_COALESCING_MIN_TIME;\n\n\tfor (i = 0; i < num_rings_per_bank; i++) {\n\t\tcsr_ops->write_csr_ring_config(csr_addr, bank_num, i, 0);\n\t\tcsr_ops->write_csr_ring_base(csr_addr, bank_num, i, 0);\n\n\t\tring = &bank->rings[i];\n\t\tif (hw_data->tx_rings_mask & (1 << i)) {\n\t\t\tring->inflights =\n\t\t\t\tkzalloc_node(sizeof(atomic_t),\n\t\t\t\t\t     GFP_KERNEL,\n\t\t\t\t\t     dev_to_node(&GET_DEV(accel_dev)));\n\t\t\tif (!ring->inflights)\n\t\t\t\tgoto err;\n\t\t} else {\n\t\t\tif (i < hw_data->tx_rx_gap) {\n\t\t\t\tdev_err(&GET_DEV(accel_dev),\n\t\t\t\t\t\"Invalid tx rings mask config\\n\");\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\ttx_ring = &bank->rings[i - hw_data->tx_rx_gap];\n\t\t\tring->inflights = tx_ring->inflights;\n\t\t}\n\t}\n\tif (adf_bank_debugfs_add(bank)) {\n\t\tdev_err(&GET_DEV(accel_dev),\n\t\t\t\"Failed to add bank debugfs entry\\n\");\n\t\tgoto err;\n\t}\n\n\tcsr_ops->write_csr_int_flag(csr_addr, bank_num, irq_mask);\n\tcsr_ops->write_csr_int_srcsel(csr_addr, bank_num);\n\n\treturn 0;\nerr:\n\tring_mask = hw_data->tx_rings_mask;\n\tfor_each_set_bit(i, &ring_mask, num_rings_per_bank) {\n\t\tring = &bank->rings[i];\n\t\tkfree(ring->inflights);\n\t\tring->inflights = NULL;\n\t}\n\tkfree(bank->rings);\n\treturn -ENOMEM;\n}\n\n \nint adf_init_etr_data(struct adf_accel_dev *accel_dev)\n{\n\tstruct adf_etr_data *etr_data;\n\tstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\n\tvoid __iomem *csr_addr;\n\tu32 size;\n\tu32 num_banks = 0;\n\tint i, ret;\n\n\tetr_data = kzalloc_node(sizeof(*etr_data), GFP_KERNEL,\n\t\t\t\tdev_to_node(&GET_DEV(accel_dev)));\n\tif (!etr_data)\n\t\treturn -ENOMEM;\n\n\tnum_banks = GET_MAX_BANKS(accel_dev);\n\tsize = num_banks * sizeof(struct adf_etr_bank_data);\n\tetr_data->banks = kzalloc_node(size, GFP_KERNEL,\n\t\t\t\t       dev_to_node(&GET_DEV(accel_dev)));\n\tif (!etr_data->banks) {\n\t\tret = -ENOMEM;\n\t\tgoto err_bank;\n\t}\n\n\taccel_dev->transport = etr_data;\n\ti = hw_data->get_etr_bar_id(hw_data);\n\tcsr_addr = accel_dev->accel_pci_dev.pci_bars[i].virt_addr;\n\n\t \n\tetr_data->debug = debugfs_create_dir(\"transport\",\n\t\t\t\t\t     accel_dev->debugfs_dir);\n\n\tfor (i = 0; i < num_banks; i++) {\n\t\tret = adf_init_bank(accel_dev, &etr_data->banks[i], i,\n\t\t\t\t    csr_addr);\n\t\tif (ret)\n\t\t\tgoto err_bank_all;\n\t}\n\n\treturn 0;\n\nerr_bank_all:\n\tdebugfs_remove(etr_data->debug);\n\tkfree(etr_data->banks);\nerr_bank:\n\tkfree(etr_data);\n\taccel_dev->transport = NULL;\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(adf_init_etr_data);\n\nstatic void cleanup_bank(struct adf_etr_bank_data *bank)\n{\n\tstruct adf_accel_dev *accel_dev = bank->accel_dev;\n\tstruct adf_hw_device_data *hw_data = accel_dev->hw_device;\n\tu8 num_rings_per_bank = hw_data->num_rings_per_bank;\n\tu32 i;\n\n\tfor (i = 0; i < num_rings_per_bank; i++) {\n\t\tstruct adf_etr_ring_data *ring = &bank->rings[i];\n\n\t\tif (bank->ring_mask & (1 << i))\n\t\t\tadf_cleanup_ring(ring);\n\n\t\tif (hw_data->tx_rings_mask & (1 << i))\n\t\t\tkfree(ring->inflights);\n\t}\n\tkfree(bank->rings);\n\tadf_bank_debugfs_rm(bank);\n\tmemset(bank, 0, sizeof(*bank));\n}\n\nstatic void adf_cleanup_etr_handles(struct adf_accel_dev *accel_dev)\n{\n\tstruct adf_etr_data *etr_data = accel_dev->transport;\n\tu32 i, num_banks = GET_MAX_BANKS(accel_dev);\n\n\tfor (i = 0; i < num_banks; i++)\n\t\tcleanup_bank(&etr_data->banks[i]);\n}\n\n \nvoid adf_cleanup_etr_data(struct adf_accel_dev *accel_dev)\n{\n\tstruct adf_etr_data *etr_data = accel_dev->transport;\n\n\tif (etr_data) {\n\t\tadf_cleanup_etr_handles(accel_dev);\n\t\tdebugfs_remove(etr_data->debug);\n\t\tkfree(etr_data->banks->rings);\n\t\tkfree(etr_data->banks);\n\t\tkfree(etr_data);\n\t\taccel_dev->transport = NULL;\n\t}\n}\nEXPORT_SYMBOL_GPL(adf_cleanup_etr_data);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}