{
  "module_name": "ocs-hcu.c",
  "hash_id": "c261bba0519f0ff91c966732fa878313fbdc3fea3a79f572a4f3cc68bf85b3aa",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/intel/keembay/ocs-hcu.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/device.h>\n#include <linux/iopoll.h>\n#include <linux/irq.h>\n#include <linux/module.h>\n\n#include <crypto/sha2.h>\n\n#include \"ocs-hcu.h\"\n\n \n#define OCS_HCU_MODE\t\t\t0x00\n#define OCS_HCU_CHAIN\t\t\t0x04\n#define OCS_HCU_OPERATION\t\t0x08\n#define OCS_HCU_KEY_0\t\t\t0x0C\n#define OCS_HCU_ISR\t\t\t0x50\n#define OCS_HCU_IER\t\t\t0x54\n#define OCS_HCU_STATUS\t\t\t0x58\n#define OCS_HCU_MSG_LEN_LO\t\t0x60\n#define OCS_HCU_MSG_LEN_HI\t\t0x64\n#define OCS_HCU_KEY_BYTE_ORDER_CFG\t0x80\n#define OCS_HCU_DMA_SRC_ADDR\t\t0x400\n#define OCS_HCU_DMA_SRC_SIZE\t\t0x408\n#define OCS_HCU_DMA_DST_SIZE\t\t0x40C\n#define OCS_HCU_DMA_DMA_MODE\t\t0x410\n#define OCS_HCU_DMA_NEXT_SRC_DESCR\t0x418\n#define OCS_HCU_DMA_MSI_ISR\t\t0x480\n#define OCS_HCU_DMA_MSI_IER\t\t0x484\n#define OCS_HCU_DMA_MSI_MASK\t\t0x488\n\n \n#define HCU_MODE_ALGO_SHIFT\t\t16\n#define HCU_MODE_HMAC_SHIFT\t\t22\n\n#define HCU_STATUS_BUSY\t\t\tBIT(0)\n\n#define HCU_BYTE_ORDER_SWAP\t\tBIT(0)\n\n#define HCU_IRQ_HASH_DONE\t\tBIT(2)\n#define HCU_IRQ_HASH_ERR_MASK\t\t(BIT(3) | BIT(1) | BIT(0))\n\n#define HCU_DMA_IRQ_SRC_DONE\t\tBIT(0)\n#define HCU_DMA_IRQ_SAI_ERR\t\tBIT(2)\n#define HCU_DMA_IRQ_BAD_COMP_ERR\tBIT(3)\n#define HCU_DMA_IRQ_INBUF_RD_ERR\tBIT(4)\n#define HCU_DMA_IRQ_INBUF_WD_ERR\tBIT(5)\n#define HCU_DMA_IRQ_OUTBUF_WR_ERR\tBIT(6)\n#define HCU_DMA_IRQ_OUTBUF_RD_ERR\tBIT(7)\n#define HCU_DMA_IRQ_CRD_ERR\t\tBIT(8)\n#define HCU_DMA_IRQ_ERR_MASK\t\t(HCU_DMA_IRQ_SAI_ERR | \\\n\t\t\t\t\t HCU_DMA_IRQ_BAD_COMP_ERR | \\\n\t\t\t\t\t HCU_DMA_IRQ_INBUF_RD_ERR | \\\n\t\t\t\t\t HCU_DMA_IRQ_INBUF_WD_ERR | \\\n\t\t\t\t\t HCU_DMA_IRQ_OUTBUF_WR_ERR | \\\n\t\t\t\t\t HCU_DMA_IRQ_OUTBUF_RD_ERR | \\\n\t\t\t\t\t HCU_DMA_IRQ_CRD_ERR)\n\n#define HCU_DMA_SNOOP_MASK\t\t(0x7 << 28)\n#define HCU_DMA_SRC_LL_EN\t\tBIT(25)\n#define HCU_DMA_EN\t\t\tBIT(31)\n\n#define OCS_HCU_ENDIANNESS_VALUE\t0x2A\n\n#define HCU_DMA_MSI_UNMASK\t\tBIT(0)\n#define HCU_DMA_MSI_DISABLE\t\t0\n#define HCU_IRQ_DISABLE\t\t\t0\n\n#define OCS_HCU_START\t\t\tBIT(0)\n#define OCS_HCU_TERMINATE\t\tBIT(1)\n\n#define OCS_LL_DMA_FLAG_TERMINATE\tBIT(31)\n\n#define OCS_HCU_HW_KEY_LEN_U32\t\t(OCS_HCU_HW_KEY_LEN / sizeof(u32))\n\n#define HCU_DATA_WRITE_ENDIANNESS_OFFSET\t26\n\n#define OCS_HCU_NUM_CHAINS_SHA256_224_SM3\t(SHA256_DIGEST_SIZE / sizeof(u32))\n#define OCS_HCU_NUM_CHAINS_SHA384_512\t\t(SHA512_DIGEST_SIZE / sizeof(u32))\n\n \n#define OCS_HCU_WAIT_BUSY_RETRY_DELAY_US\t200\n \n#define OCS_HCU_WAIT_BUSY_TIMEOUT_US\t\t1000000\n\n \nstruct ocs_hcu_dma_entry {\n\tu32 src_addr;\n\tu32 src_len;\n\tu32 nxt_desc;\n\tu32 ll_flags;\n};\n\n \nstruct ocs_hcu_dma_list {\n\tstruct ocs_hcu_dma_entry\t*head;\n\tstruct ocs_hcu_dma_entry\t*tail;\n\tdma_addr_t\t\t\tdma_addr;\n\tsize_t\t\t\t\tmax_nents;\n};\n\nstatic inline u32 ocs_hcu_num_chains(enum ocs_hcu_algo algo)\n{\n\tswitch (algo) {\n\tcase OCS_HCU_ALGO_SHA224:\n\tcase OCS_HCU_ALGO_SHA256:\n\tcase OCS_HCU_ALGO_SM3:\n\t\treturn OCS_HCU_NUM_CHAINS_SHA256_224_SM3;\n\tcase OCS_HCU_ALGO_SHA384:\n\tcase OCS_HCU_ALGO_SHA512:\n\t\treturn OCS_HCU_NUM_CHAINS_SHA384_512;\n\tdefault:\n\t\treturn 0;\n\t};\n}\n\nstatic inline u32 ocs_hcu_digest_size(enum ocs_hcu_algo algo)\n{\n\tswitch (algo) {\n\tcase OCS_HCU_ALGO_SHA224:\n\t\treturn SHA224_DIGEST_SIZE;\n\tcase OCS_HCU_ALGO_SHA256:\n\tcase OCS_HCU_ALGO_SM3:\n\t\t \n\t\treturn SHA256_DIGEST_SIZE;\n\tcase OCS_HCU_ALGO_SHA384:\n\t\treturn SHA384_DIGEST_SIZE;\n\tcase OCS_HCU_ALGO_SHA512:\n\t\treturn SHA512_DIGEST_SIZE;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\n \nstatic int ocs_hcu_wait_busy(struct ocs_hcu_dev *hcu_dev)\n{\n\tlong val;\n\n\treturn readl_poll_timeout(hcu_dev->io_base + OCS_HCU_STATUS, val,\n\t\t\t\t  !(val & HCU_STATUS_BUSY),\n\t\t\t\t  OCS_HCU_WAIT_BUSY_RETRY_DELAY_US,\n\t\t\t\t  OCS_HCU_WAIT_BUSY_TIMEOUT_US);\n}\n\nstatic void ocs_hcu_done_irq_en(struct ocs_hcu_dev *hcu_dev)\n{\n\t \n\twritel(0xFFFFFFFF, hcu_dev->io_base + OCS_HCU_ISR);\n\thcu_dev->irq_err = false;\n\t \n\twritel(HCU_IRQ_HASH_DONE | HCU_IRQ_HASH_ERR_MASK,\n\t       hcu_dev->io_base + OCS_HCU_IER);\n}\n\nstatic void ocs_hcu_dma_irq_en(struct ocs_hcu_dev *hcu_dev)\n{\n\t \n\twritel(0xFFFFFFFF, hcu_dev->io_base + OCS_HCU_DMA_MSI_ISR);\n\thcu_dev->irq_err = false;\n\t \n\twritel(HCU_DMA_IRQ_ERR_MASK | HCU_DMA_IRQ_SRC_DONE,\n\t       hcu_dev->io_base + OCS_HCU_DMA_MSI_IER);\n\t \n\twritel(HCU_DMA_MSI_UNMASK, hcu_dev->io_base + OCS_HCU_DMA_MSI_MASK);\n}\n\nstatic void ocs_hcu_irq_dis(struct ocs_hcu_dev *hcu_dev)\n{\n\twritel(HCU_IRQ_DISABLE, hcu_dev->io_base + OCS_HCU_IER);\n\twritel(HCU_DMA_MSI_DISABLE, hcu_dev->io_base + OCS_HCU_DMA_MSI_IER);\n}\n\nstatic int ocs_hcu_wait_and_disable_irq(struct ocs_hcu_dev *hcu_dev)\n{\n\tint rc;\n\n\trc = wait_for_completion_interruptible(&hcu_dev->irq_done);\n\tif (rc)\n\t\tgoto exit;\n\n\tif (hcu_dev->irq_err) {\n\t\t \n\t\thcu_dev->irq_err = false;\n\t\trc = -EIO;\n\t\tgoto exit;\n\t}\n\nexit:\n\tocs_hcu_irq_dis(hcu_dev);\n\n\treturn rc;\n}\n\n \nstatic int ocs_hcu_get_intermediate_data(struct ocs_hcu_dev *hcu_dev,\n\t\t\t\t\t struct ocs_hcu_idata *data,\n\t\t\t\t\t enum ocs_hcu_algo algo)\n{\n\tconst int n = ocs_hcu_num_chains(algo);\n\tu32 *chain;\n\tint rc;\n\tint i;\n\n\t \n\tif (!data)\n\t\treturn -EINVAL;\n\n\tchain = (u32 *)data->digest;\n\n\t \n\trc = ocs_hcu_wait_busy(hcu_dev);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tfor (i = 0; i < n; i++)\n\t\tchain[i] = readl(hcu_dev->io_base + OCS_HCU_CHAIN);\n\n\tdata->msg_len_lo = readl(hcu_dev->io_base + OCS_HCU_MSG_LEN_LO);\n\tdata->msg_len_hi = readl(hcu_dev->io_base + OCS_HCU_MSG_LEN_HI);\n\n\treturn 0;\n}\n\n \nstatic void ocs_hcu_set_intermediate_data(struct ocs_hcu_dev *hcu_dev,\n\t\t\t\t\t  const struct ocs_hcu_idata *data,\n\t\t\t\t\t  enum ocs_hcu_algo algo)\n{\n\tconst int n = ocs_hcu_num_chains(algo);\n\tu32 *chain = (u32 *)data->digest;\n\tint i;\n\n\t \n\tfor (i = 0; i < n; i++)\n\t\twritel(chain[i], hcu_dev->io_base + OCS_HCU_CHAIN);\n\n\twritel(data->msg_len_lo, hcu_dev->io_base + OCS_HCU_MSG_LEN_LO);\n\twritel(data->msg_len_hi, hcu_dev->io_base + OCS_HCU_MSG_LEN_HI);\n}\n\nstatic int ocs_hcu_get_digest(struct ocs_hcu_dev *hcu_dev,\n\t\t\t      enum ocs_hcu_algo algo, u8 *dgst, size_t dgst_len)\n{\n\tu32 *chain;\n\tint rc;\n\tint i;\n\n\tif (!dgst)\n\t\treturn -EINVAL;\n\n\t \n\tif (dgst_len != ocs_hcu_digest_size(algo))\n\t\treturn -EINVAL;\n\n\t \n\trc = ocs_hcu_wait_busy(hcu_dev);\n\tif (rc)\n\t\treturn rc;\n\n\tchain = (u32 *)dgst;\n\tfor (i = 0; i < dgst_len / sizeof(u32); i++)\n\t\tchain[i] = readl(hcu_dev->io_base + OCS_HCU_CHAIN);\n\n\treturn 0;\n}\n\n \nstatic int ocs_hcu_hw_cfg(struct ocs_hcu_dev *hcu_dev, enum ocs_hcu_algo algo,\n\t\t\t  bool use_hmac)\n{\n\tu32 cfg;\n\tint rc;\n\n\tif (algo != OCS_HCU_ALGO_SHA256 && algo != OCS_HCU_ALGO_SHA224 &&\n\t    algo != OCS_HCU_ALGO_SHA384 && algo != OCS_HCU_ALGO_SHA512 &&\n\t    algo != OCS_HCU_ALGO_SM3)\n\t\treturn -EINVAL;\n\n\trc = ocs_hcu_wait_busy(hcu_dev);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tocs_hcu_irq_dis(hcu_dev);\n\n\t \n\tcfg = OCS_HCU_ENDIANNESS_VALUE << HCU_DATA_WRITE_ENDIANNESS_OFFSET;\n\tcfg |= algo << HCU_MODE_ALGO_SHIFT;\n\tif (use_hmac)\n\t\tcfg |= BIT(HCU_MODE_HMAC_SHIFT);\n\n\twritel(cfg, hcu_dev->io_base + OCS_HCU_MODE);\n\n\treturn 0;\n}\n\n \nstatic void ocs_hcu_clear_key(struct ocs_hcu_dev *hcu_dev)\n{\n\tint reg_off;\n\n\t \n\tfor (reg_off = 0; reg_off < OCS_HCU_HW_KEY_LEN; reg_off += sizeof(u32))\n\t\twritel(0, hcu_dev->io_base + OCS_HCU_KEY_0 + reg_off);\n}\n\n \nstatic int ocs_hcu_write_key(struct ocs_hcu_dev *hcu_dev, const u8 *key, size_t len)\n{\n\tu32 key_u32[OCS_HCU_HW_KEY_LEN_U32];\n\tint i;\n\n\tif (len > OCS_HCU_HW_KEY_LEN)\n\t\treturn -EINVAL;\n\n\t \n\tmemcpy(key_u32, key, len);\n\n\t \n\tmemzero_explicit((u8 *)key_u32 + len, OCS_HCU_HW_KEY_LEN - len);\n\n\t \n\twritel(HCU_BYTE_ORDER_SWAP,\n\t       hcu_dev->io_base + OCS_HCU_KEY_BYTE_ORDER_CFG);\n\t \n\tfor (i = 0; i < OCS_HCU_HW_KEY_LEN_U32; i++)\n\t\twritel(key_u32[OCS_HCU_HW_KEY_LEN_U32 - 1 - i],\n\t\t       hcu_dev->io_base + OCS_HCU_KEY_0 + (sizeof(u32) * i));\n\n\tmemzero_explicit(key_u32, OCS_HCU_HW_KEY_LEN);\n\n\treturn 0;\n}\n\n \nstatic int ocs_hcu_ll_dma_start(struct ocs_hcu_dev *hcu_dev,\n\t\t\t\tconst struct ocs_hcu_dma_list *dma_list,\n\t\t\t\tbool finalize)\n{\n\tu32 cfg = HCU_DMA_SNOOP_MASK | HCU_DMA_SRC_LL_EN | HCU_DMA_EN;\n\tint rc;\n\n\tif (!dma_list)\n\t\treturn -EINVAL;\n\n\t \n\tif (finalize)\n\t\tocs_hcu_done_irq_en(hcu_dev);\n\telse\n\t\tocs_hcu_dma_irq_en(hcu_dev);\n\n\treinit_completion(&hcu_dev->irq_done);\n\twritel(dma_list->dma_addr, hcu_dev->io_base + OCS_HCU_DMA_NEXT_SRC_DESCR);\n\twritel(0, hcu_dev->io_base + OCS_HCU_DMA_SRC_SIZE);\n\twritel(0, hcu_dev->io_base + OCS_HCU_DMA_DST_SIZE);\n\n\twritel(OCS_HCU_START, hcu_dev->io_base + OCS_HCU_OPERATION);\n\n\twritel(cfg, hcu_dev->io_base + OCS_HCU_DMA_DMA_MODE);\n\n\tif (finalize)\n\t\twritel(OCS_HCU_TERMINATE, hcu_dev->io_base + OCS_HCU_OPERATION);\n\n\trc = ocs_hcu_wait_and_disable_irq(hcu_dev);\n\tif (rc)\n\t\treturn rc;\n\n\treturn 0;\n}\n\nstruct ocs_hcu_dma_list *ocs_hcu_dma_list_alloc(struct ocs_hcu_dev *hcu_dev,\n\t\t\t\t\t\tint max_nents)\n{\n\tstruct ocs_hcu_dma_list *dma_list;\n\n\tdma_list = kmalloc(sizeof(*dma_list), GFP_KERNEL);\n\tif (!dma_list)\n\t\treturn NULL;\n\n\t \n\tdma_list->head = dma_alloc_coherent(hcu_dev->dev,\n\t\t\t\t\t    sizeof(*dma_list->head) * max_nents,\n\t\t\t\t\t    &dma_list->dma_addr, GFP_KERNEL);\n\tif (!dma_list->head) {\n\t\tkfree(dma_list);\n\t\treturn NULL;\n\t}\n\tdma_list->max_nents = max_nents;\n\tdma_list->tail = NULL;\n\n\treturn dma_list;\n}\n\nvoid ocs_hcu_dma_list_free(struct ocs_hcu_dev *hcu_dev,\n\t\t\t   struct ocs_hcu_dma_list *dma_list)\n{\n\tif (!dma_list)\n\t\treturn;\n\n\tdma_free_coherent(hcu_dev->dev,\n\t\t\t  sizeof(*dma_list->head) * dma_list->max_nents,\n\t\t\t  dma_list->head, dma_list->dma_addr);\n\n\tkfree(dma_list);\n}\n\n \nint ocs_hcu_dma_list_add_tail(struct ocs_hcu_dev *hcu_dev,\n\t\t\t      struct ocs_hcu_dma_list *dma_list,\n\t\t\t      dma_addr_t addr, u32 len)\n{\n\tstruct device *dev = hcu_dev->dev;\n\tstruct ocs_hcu_dma_entry *old_tail;\n\tstruct ocs_hcu_dma_entry *new_tail;\n\n\tif (!len)\n\t\treturn 0;\n\n\tif (!dma_list)\n\t\treturn -EINVAL;\n\n\tif (addr & ~OCS_HCU_DMA_BIT_MASK) {\n\t\tdev_err(dev,\n\t\t\t\"Unexpected error: Invalid DMA address for OCS HCU\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\told_tail = dma_list->tail;\n\tnew_tail = old_tail ? old_tail + 1 : dma_list->head;\n\n\t \n\tif (new_tail - dma_list->head >= dma_list->max_nents)\n\t\treturn -ENOMEM;\n\n\t \n\tif (old_tail) {\n\t\told_tail->ll_flags &= ~OCS_LL_DMA_FLAG_TERMINATE;\n\t\t \n\t\told_tail->nxt_desc = dma_list->dma_addr +\n\t\t\t\t     sizeof(*dma_list->tail) * (new_tail -\n\t\t\t\t\t\t\t\tdma_list->head);\n\t}\n\n\tnew_tail->src_addr = (u32)addr;\n\tnew_tail->src_len = (u32)len;\n\tnew_tail->ll_flags = OCS_LL_DMA_FLAG_TERMINATE;\n\tnew_tail->nxt_desc = 0;\n\n\t \n\tdma_list->tail = new_tail;\n\n\treturn 0;\n}\n\n \nint ocs_hcu_hash_init(struct ocs_hcu_hash_ctx *ctx, enum ocs_hcu_algo algo)\n{\n\tif (!ctx)\n\t\treturn -EINVAL;\n\n\tctx->algo = algo;\n\tctx->idata.msg_len_lo = 0;\n\tctx->idata.msg_len_hi = 0;\n\t \n\n\treturn 0;\n}\n\n \nint ocs_hcu_hash_update(struct ocs_hcu_dev *hcu_dev,\n\t\t\tstruct ocs_hcu_hash_ctx *ctx,\n\t\t\tconst struct ocs_hcu_dma_list *dma_list)\n{\n\tint rc;\n\n\tif (!hcu_dev || !ctx)\n\t\treturn -EINVAL;\n\n\t \n\trc = ocs_hcu_hw_cfg(hcu_dev, ctx->algo, false);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (ctx->idata.msg_len_lo || ctx->idata.msg_len_hi)\n\t\tocs_hcu_set_intermediate_data(hcu_dev, &ctx->idata, ctx->algo);\n\n\t \n\trc = ocs_hcu_ll_dma_start(hcu_dev, dma_list, false);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\treturn ocs_hcu_get_intermediate_data(hcu_dev, &ctx->idata, ctx->algo);\n}\n\n \nint ocs_hcu_hash_finup(struct ocs_hcu_dev *hcu_dev,\n\t\t       const struct ocs_hcu_hash_ctx *ctx,\n\t\t       const struct ocs_hcu_dma_list *dma_list,\n\t\t       u8 *dgst, size_t dgst_len)\n{\n\tint rc;\n\n\tif (!hcu_dev || !ctx)\n\t\treturn -EINVAL;\n\n\t \n\trc = ocs_hcu_hw_cfg(hcu_dev, ctx->algo, false);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (ctx->idata.msg_len_lo || ctx->idata.msg_len_hi)\n\t\tocs_hcu_set_intermediate_data(hcu_dev, &ctx->idata, ctx->algo);\n\n\t \n\trc = ocs_hcu_ll_dma_start(hcu_dev, dma_list, true);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\treturn ocs_hcu_get_digest(hcu_dev, ctx->algo, dgst, dgst_len);\n}\n\n \nint ocs_hcu_hash_final(struct ocs_hcu_dev *hcu_dev,\n\t\t       const struct ocs_hcu_hash_ctx *ctx, u8 *dgst,\n\t\t       size_t dgst_len)\n{\n\tint rc;\n\n\tif (!hcu_dev || !ctx)\n\t\treturn -EINVAL;\n\n\t \n\trc = ocs_hcu_hw_cfg(hcu_dev, ctx->algo, false);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (ctx->idata.msg_len_lo || ctx->idata.msg_len_hi)\n\t\tocs_hcu_set_intermediate_data(hcu_dev, &ctx->idata, ctx->algo);\n\n\t \n\tocs_hcu_done_irq_en(hcu_dev);\n\treinit_completion(&hcu_dev->irq_done);\n\twritel(OCS_HCU_TERMINATE, hcu_dev->io_base + OCS_HCU_OPERATION);\n\n\trc = ocs_hcu_wait_and_disable_irq(hcu_dev);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\treturn ocs_hcu_get_digest(hcu_dev, ctx->algo, dgst, dgst_len);\n}\n\n \nint ocs_hcu_digest(struct ocs_hcu_dev *hcu_dev, enum ocs_hcu_algo algo,\n\t\t   void *data, size_t data_len, u8 *dgst, size_t dgst_len)\n{\n\tstruct device *dev = hcu_dev->dev;\n\tdma_addr_t dma_handle;\n\tu32 reg;\n\tint rc;\n\n\t \n\trc = ocs_hcu_hw_cfg(hcu_dev, algo, false);\n\tif (rc)\n\t\treturn rc;\n\n\tdma_handle = dma_map_single(dev, data, data_len, DMA_TO_DEVICE);\n\tif (dma_mapping_error(dev, dma_handle))\n\t\treturn -EIO;\n\n\treg = HCU_DMA_SNOOP_MASK | HCU_DMA_EN;\n\n\tocs_hcu_done_irq_en(hcu_dev);\n\n\treinit_completion(&hcu_dev->irq_done);\n\n\twritel(dma_handle, hcu_dev->io_base + OCS_HCU_DMA_SRC_ADDR);\n\twritel(data_len, hcu_dev->io_base + OCS_HCU_DMA_SRC_SIZE);\n\twritel(OCS_HCU_START, hcu_dev->io_base + OCS_HCU_OPERATION);\n\twritel(reg, hcu_dev->io_base + OCS_HCU_DMA_DMA_MODE);\n\n\twritel(OCS_HCU_TERMINATE, hcu_dev->io_base + OCS_HCU_OPERATION);\n\n\trc = ocs_hcu_wait_and_disable_irq(hcu_dev);\n\tif (rc)\n\t\treturn rc;\n\n\tdma_unmap_single(dev, dma_handle, data_len, DMA_TO_DEVICE);\n\n\treturn ocs_hcu_get_digest(hcu_dev, algo, dgst, dgst_len);\n}\n\n \nint ocs_hcu_hmac(struct ocs_hcu_dev *hcu_dev, enum ocs_hcu_algo algo,\n\t\t const u8 *key, size_t key_len,\n\t\t const struct ocs_hcu_dma_list *dma_list,\n\t\t u8 *dgst, size_t dgst_len)\n{\n\tint rc;\n\n\t \n\tif (!key || key_len == 0)\n\t\treturn -EINVAL;\n\n\t \n\trc = ocs_hcu_hw_cfg(hcu_dev, algo, true);\n\tif (rc)\n\t\treturn rc;\n\n\trc = ocs_hcu_write_key(hcu_dev, key, key_len);\n\tif (rc)\n\t\treturn rc;\n\n\trc = ocs_hcu_ll_dma_start(hcu_dev, dma_list, true);\n\n\t \n\tocs_hcu_clear_key(hcu_dev);\n\n\tif (rc)\n\t\treturn rc;\n\n\treturn ocs_hcu_get_digest(hcu_dev, algo, dgst, dgst_len);\n}\n\nirqreturn_t ocs_hcu_irq_handler(int irq, void *dev_id)\n{\n\tstruct ocs_hcu_dev *hcu_dev = dev_id;\n\tu32 hcu_irq;\n\tu32 dma_irq;\n\n\t \n\thcu_irq = readl(hcu_dev->io_base + OCS_HCU_ISR);\n\twritel(hcu_irq, hcu_dev->io_base + OCS_HCU_ISR);\n\n\t \n\tdma_irq = readl(hcu_dev->io_base + OCS_HCU_DMA_MSI_ISR);\n\twritel(dma_irq, hcu_dev->io_base + OCS_HCU_DMA_MSI_ISR);\n\n\t \n\tif (hcu_irq & HCU_IRQ_HASH_ERR_MASK || dma_irq & HCU_DMA_IRQ_ERR_MASK) {\n\t\thcu_dev->irq_err = true;\n\t\tgoto complete;\n\t}\n\n\t \n\tif (hcu_irq & HCU_IRQ_HASH_DONE || dma_irq & HCU_DMA_IRQ_SRC_DONE)\n\t\tgoto complete;\n\n\treturn IRQ_NONE;\n\ncomplete:\n\tcomplete(&hcu_dev->irq_done);\n\n\treturn IRQ_HANDLED;\n}\n\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}