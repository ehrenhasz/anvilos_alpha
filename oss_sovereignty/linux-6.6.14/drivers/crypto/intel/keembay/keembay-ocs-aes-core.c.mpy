{
  "module_name": "keembay-ocs-aes-core.c",
  "hash_id": "8ce0803d6f78a8ef476910c08a80a925fe36713963b6ef4449897b102db3f471",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/intel/keembay/keembay-ocs-aes-core.c",
  "human_readable_source": "\n \n\n#include <crypto/aes.h>\n#include <crypto/engine.h>\n#include <crypto/gcm.h>\n#include <crypto/internal/aead.h>\n#include <crypto/internal/skcipher.h>\n#include <crypto/scatterwalk.h>\n#include <linux/clk.h>\n#include <linux/completion.h>\n#include <linux/dma-mapping.h>\n#include <linux/err.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/of.h>\n#include <linux/platform_device.h>\n#include <linux/string.h>\n\n#include \"ocs-aes.h\"\n\n#define KMB_OCS_PRIORITY\t350\n#define DRV_NAME\t\t\"keembay-ocs-aes\"\n\n#define OCS_AES_MIN_KEY_SIZE\t16\n#define OCS_AES_MAX_KEY_SIZE\t32\n#define OCS_AES_KEYSIZE_128\t16\n#define OCS_AES_KEYSIZE_192\t24\n#define OCS_AES_KEYSIZE_256\t32\n#define OCS_SM4_KEY_SIZE\t16\n\n \nstruct ocs_aes_tctx {\n\tstruct ocs_aes_dev *aes_dev;\n\tu8 key[OCS_AES_KEYSIZE_256];\n\tunsigned int key_len;\n\tenum ocs_cipher cipher;\n\tunion {\n\t\tstruct crypto_sync_skcipher *sk;\n\t\tstruct crypto_aead *aead;\n\t} sw_cipher;\n\tbool use_fallback;\n};\n\n \nstruct ocs_aes_rctx {\n\t \n\tenum ocs_instruction\tinstruction;\n\tenum ocs_mode\t\tmode;\n\tint\t\t\tsrc_nents;\n\tint\t\t\tdst_nents;\n\tint\t\t\tsrc_dma_count;\n\tint\t\t\tdst_dma_count;\n\tbool\t\t\tin_place;\n\tstruct ocs_dll_desc\tsrc_dll;\n\tstruct ocs_dll_desc\tdst_dll;\n\n\t \n\tu8\t\t\tlast_ct_blk[AES_BLOCK_SIZE];\n\n\t \n\tint\t\t\tcts_swap;\n\n\t \n\tstruct ocs_dll_desc\taad_src_dll;\n\tstruct ocs_dll_desc\taad_dst_dll;\n\tu8\t\t\tin_tag[AES_BLOCK_SIZE];\n\n\t \n\tu8\t\t\tout_tag[AES_BLOCK_SIZE];\n};\n\n \nstruct ocs_aes_drv {\n\tstruct list_head dev_list;\n\tspinlock_t lock;\t \n};\n\nstatic struct ocs_aes_drv ocs_aes = {\n\t.dev_list = LIST_HEAD_INIT(ocs_aes.dev_list),\n\t.lock = __SPIN_LOCK_UNLOCKED(ocs_aes.lock),\n};\n\nstatic struct ocs_aes_dev *kmb_ocs_aes_find_dev(struct ocs_aes_tctx *tctx)\n{\n\tstruct ocs_aes_dev *aes_dev;\n\n\tspin_lock(&ocs_aes.lock);\n\n\tif (tctx->aes_dev) {\n\t\taes_dev = tctx->aes_dev;\n\t\tgoto exit;\n\t}\n\n\t \n\taes_dev = list_first_entry(&ocs_aes.dev_list, struct ocs_aes_dev, list);\n\ttctx->aes_dev = aes_dev;\n\nexit:\n\tspin_unlock(&ocs_aes.lock);\n\n\treturn aes_dev;\n}\n\n \nstatic int check_key(const u8 *in_key, size_t key_len, enum ocs_cipher cipher)\n{\n\tif (!in_key)\n\t\treturn -EINVAL;\n\n\t \n\tif (cipher == OCS_AES && (key_len == OCS_AES_KEYSIZE_128 ||\n\t\t\t\t  key_len == OCS_AES_KEYSIZE_256))\n\t\treturn 0;\n\n\t \n\tif (cipher == OCS_SM4 && key_len == OCS_AES_KEYSIZE_128)\n\t\treturn 0;\n\n\t \n\treturn -EINVAL;\n}\n\n \nstatic int save_key(struct ocs_aes_tctx *tctx, const u8 *in_key, size_t key_len,\n\t\t    enum ocs_cipher cipher)\n{\n\tint ret;\n\n\tret = check_key(in_key, key_len, cipher);\n\tif (ret)\n\t\treturn ret;\n\n\tmemcpy(tctx->key, in_key, key_len);\n\ttctx->key_len = key_len;\n\ttctx->cipher = cipher;\n\n\treturn 0;\n}\n\n \nstatic int kmb_ocs_sk_set_key(struct crypto_skcipher *tfm, const u8 *in_key,\n\t\t\t      size_t key_len, enum ocs_cipher cipher)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\n\t \n\ttctx->use_fallback = (cipher == OCS_AES &&\n\t\t\t      key_len == OCS_AES_KEYSIZE_192);\n\n\tif (!tctx->use_fallback)\n\t\treturn save_key(tctx, in_key, key_len, cipher);\n\n\tcrypto_sync_skcipher_clear_flags(tctx->sw_cipher.sk,\n\t\t\t\t\t CRYPTO_TFM_REQ_MASK);\n\tcrypto_sync_skcipher_set_flags(tctx->sw_cipher.sk,\n\t\t\t\t       tfm->base.crt_flags &\n\t\t\t\t       CRYPTO_TFM_REQ_MASK);\n\n\treturn crypto_sync_skcipher_setkey(tctx->sw_cipher.sk, in_key, key_len);\n}\n\n \nstatic int kmb_ocs_aead_set_key(struct crypto_aead *tfm, const u8 *in_key,\n\t\t\t\tsize_t key_len, enum ocs_cipher cipher)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(tfm);\n\n\t \n\ttctx->use_fallback = (cipher == OCS_AES &&\n\t\t\t      key_len == OCS_AES_KEYSIZE_192);\n\n\tif (!tctx->use_fallback)\n\t\treturn save_key(tctx, in_key, key_len, cipher);\n\n\tcrypto_aead_clear_flags(tctx->sw_cipher.aead, CRYPTO_TFM_REQ_MASK);\n\tcrypto_aead_set_flags(tctx->sw_cipher.aead,\n\t\t\t      crypto_aead_get_flags(tfm) & CRYPTO_TFM_REQ_MASK);\n\n\treturn crypto_aead_setkey(tctx->sw_cipher.aead, in_key, key_len);\n}\n\n \nstatic void sg_swap_blocks(struct scatterlist *sgl, unsigned int nents,\n\t\t\t   off_t blk1_offset, off_t blk2_offset)\n{\n\tu8 tmp_buf1[AES_BLOCK_SIZE], tmp_buf2[AES_BLOCK_SIZE];\n\n\t \n\tsg_pcopy_to_buffer(sgl, nents, tmp_buf1, AES_BLOCK_SIZE, blk1_offset);\n\tsg_pcopy_to_buffer(sgl, nents, tmp_buf2, AES_BLOCK_SIZE, blk2_offset);\n\tsg_pcopy_from_buffer(sgl, nents, tmp_buf1, AES_BLOCK_SIZE, blk2_offset);\n\tsg_pcopy_from_buffer(sgl, nents, tmp_buf2, AES_BLOCK_SIZE, blk1_offset);\n}\n\n \nstatic void ocs_aes_init_rctx(struct ocs_aes_rctx *rctx)\n{\n\t \n\tmemset(rctx, 0, sizeof(*rctx));\n\n\t \n\trctx->src_dll.dma_addr = DMA_MAPPING_ERROR;\n\trctx->dst_dll.dma_addr = DMA_MAPPING_ERROR;\n\trctx->aad_src_dll.dma_addr = DMA_MAPPING_ERROR;\n\trctx->aad_dst_dll.dma_addr = DMA_MAPPING_ERROR;\n}\n\nstatic int kmb_ocs_sk_validate_input(struct skcipher_request *req,\n\t\t\t\t     enum ocs_mode mode)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tint iv_size = crypto_skcipher_ivsize(tfm);\n\n\tswitch (mode) {\n\tcase OCS_MODE_ECB:\n\t\t \n\t\tif (req->cryptlen % AES_BLOCK_SIZE != 0)\n\t\t\treturn -EINVAL;\n\n\t\treturn 0;\n\n\tcase OCS_MODE_CBC:\n\t\t \n\t\tif (req->cryptlen % AES_BLOCK_SIZE != 0)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (!req->iv || iv_size != AES_BLOCK_SIZE)\n\t\t\treturn -EINVAL;\n\t\t \n\t\treturn 0;\n\n\tcase OCS_MODE_CTR:\n\t\t \n\t\tif (!req->iv || iv_size != AES_BLOCK_SIZE)\n\t\t\treturn -EINVAL;\n\t\treturn 0;\n\n\tcase OCS_MODE_CTS:\n\t\t \n\t\tif (req->cryptlen < AES_BLOCK_SIZE)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (!req->iv || iv_size != AES_BLOCK_SIZE)\n\t\t\treturn -EINVAL;\n\n\t\treturn 0;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n \nstatic int kmb_ocs_sk_common(struct skcipher_request *req,\n\t\t\t     enum ocs_cipher cipher,\n\t\t\t     enum ocs_instruction instruction,\n\t\t\t     enum ocs_mode mode)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct ocs_aes_rctx *rctx = skcipher_request_ctx(req);\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct ocs_aes_dev *aes_dev;\n\tint rc;\n\n\tif (tctx->use_fallback) {\n\t\tSYNC_SKCIPHER_REQUEST_ON_STACK(subreq, tctx->sw_cipher.sk);\n\n\t\tskcipher_request_set_sync_tfm(subreq, tctx->sw_cipher.sk);\n\t\tskcipher_request_set_callback(subreq, req->base.flags, NULL,\n\t\t\t\t\t      NULL);\n\t\tskcipher_request_set_crypt(subreq, req->src, req->dst,\n\t\t\t\t\t   req->cryptlen, req->iv);\n\n\t\tif (instruction == OCS_ENCRYPT)\n\t\t\trc = crypto_skcipher_encrypt(subreq);\n\t\telse\n\t\t\trc = crypto_skcipher_decrypt(subreq);\n\n\t\tskcipher_request_zero(subreq);\n\n\t\treturn rc;\n\t}\n\n\t \n\tif (!req->cryptlen && mode != OCS_MODE_CTS)\n\t\treturn 0;\n\n\trc = kmb_ocs_sk_validate_input(req, mode);\n\tif (rc)\n\t\treturn rc;\n\n\taes_dev = kmb_ocs_aes_find_dev(tctx);\n\tif (!aes_dev)\n\t\treturn -ENODEV;\n\n\tif (cipher != tctx->cipher)\n\t\treturn -EINVAL;\n\n\tocs_aes_init_rctx(rctx);\n\trctx->instruction = instruction;\n\trctx->mode = mode;\n\n\treturn crypto_transfer_skcipher_request_to_engine(aes_dev->engine, req);\n}\n\nstatic void cleanup_ocs_dma_linked_list(struct device *dev,\n\t\t\t\t\tstruct ocs_dll_desc *dll)\n{\n\tif (dll->vaddr)\n\t\tdma_free_coherent(dev, dll->size, dll->vaddr, dll->dma_addr);\n\tdll->vaddr = NULL;\n\tdll->size = 0;\n\tdll->dma_addr = DMA_MAPPING_ERROR;\n}\n\nstatic void kmb_ocs_sk_dma_cleanup(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct ocs_aes_rctx *rctx = skcipher_request_ctx(req);\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct device *dev = tctx->aes_dev->dev;\n\n\tif (rctx->src_dma_count) {\n\t\tdma_unmap_sg(dev, req->src, rctx->src_nents, DMA_TO_DEVICE);\n\t\trctx->src_dma_count = 0;\n\t}\n\n\tif (rctx->dst_dma_count) {\n\t\tdma_unmap_sg(dev, req->dst, rctx->dst_nents, rctx->in_place ?\n\t\t\t\t\t\t\t     DMA_BIDIRECTIONAL :\n\t\t\t\t\t\t\t     DMA_FROM_DEVICE);\n\t\trctx->dst_dma_count = 0;\n\t}\n\n\t \n\tcleanup_ocs_dma_linked_list(dev, &rctx->src_dll);\n\tcleanup_ocs_dma_linked_list(dev, &rctx->dst_dll);\n}\n\nstatic int kmb_ocs_sk_prepare_inplace(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct ocs_aes_rctx *rctx = skcipher_request_ctx(req);\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\tint iv_size = crypto_skcipher_ivsize(tfm);\n\tint rc;\n\n\t \n\tif (rctx->mode == OCS_MODE_CBC && rctx->instruction == OCS_DECRYPT)\n\t\tscatterwalk_map_and_copy(rctx->last_ct_blk, req->src,\n\t\t\t\t\t req->cryptlen - iv_size, iv_size, 0);\n\n\t \n\tif (rctx->cts_swap && rctx->instruction == OCS_DECRYPT)\n\t\tsg_swap_blocks(req->dst, rctx->dst_nents,\n\t\t\t       req->cryptlen - AES_BLOCK_SIZE,\n\t\t\t       req->cryptlen - (2 * AES_BLOCK_SIZE));\n\n\t \n\trctx->dst_dma_count = dma_map_sg(tctx->aes_dev->dev, req->dst,\n\t\t\t\t\t rctx->dst_nents, DMA_BIDIRECTIONAL);\n\tif (rctx->dst_dma_count == 0) {\n\t\tdev_err(tctx->aes_dev->dev, \"Failed to map destination sg\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,\n\t\t\t\t\t    rctx->dst_dma_count, &rctx->dst_dll,\n\t\t\t\t\t    req->cryptlen, 0);\n\tif (rc)\n\t\treturn rc;\n\t \n\trctx->src_dll.dma_addr = rctx->dst_dll.dma_addr;\n\n\treturn 0;\n}\n\nstatic int kmb_ocs_sk_prepare_notinplace(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct ocs_aes_rctx *rctx = skcipher_request_ctx(req);\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\tint rc;\n\n\trctx->src_nents =  sg_nents_for_len(req->src, req->cryptlen);\n\tif (rctx->src_nents < 0)\n\t\treturn -EBADMSG;\n\n\t \n\trctx->src_dma_count = dma_map_sg(tctx->aes_dev->dev, req->src,\n\t\t\t\t\t rctx->src_nents, DMA_TO_DEVICE);\n\tif (rctx->src_dma_count == 0) {\n\t\tdev_err(tctx->aes_dev->dev, \"Failed to map source sg\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->src,\n\t\t\t\t\t    rctx->src_dma_count, &rctx->src_dll,\n\t\t\t\t\t    req->cryptlen, 0);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trctx->dst_dma_count = dma_map_sg(tctx->aes_dev->dev, req->dst,\n\t\t\t\t\t rctx->dst_nents, DMA_FROM_DEVICE);\n\tif (rctx->dst_dma_count == 0) {\n\t\tdev_err(tctx->aes_dev->dev, \"Failed to map destination sg\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,\n\t\t\t\t\t    rctx->dst_dma_count, &rctx->dst_dll,\n\t\t\t\t\t    req->cryptlen, 0);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tif (!(rctx->cts_swap && rctx->instruction == OCS_DECRYPT))\n\t\treturn 0;\n\n\t \n\trc = ocs_aes_bypass_op(tctx->aes_dev, rctx->dst_dll.dma_addr,\n\t\t\t       rctx->src_dll.dma_addr, req->cryptlen);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\tkmb_ocs_sk_dma_cleanup(req);\n\trctx->in_place = true;\n\n\treturn kmb_ocs_sk_prepare_inplace(req);\n}\n\nstatic int kmb_ocs_sk_run(struct skcipher_request *req)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct ocs_aes_rctx *rctx = skcipher_request_ctx(req);\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct ocs_aes_dev *aes_dev = tctx->aes_dev;\n\tint iv_size = crypto_skcipher_ivsize(tfm);\n\tint rc;\n\n\trctx->dst_nents = sg_nents_for_len(req->dst, req->cryptlen);\n\tif (rctx->dst_nents < 0)\n\t\treturn -EBADMSG;\n\n\t \n\trctx->cts_swap = (rctx->mode == OCS_MODE_CTS &&\n\t\t\t  req->cryptlen > AES_BLOCK_SIZE &&\n\t\t\t  req->cryptlen % AES_BLOCK_SIZE == 0);\n\n\trctx->in_place = (req->src == req->dst);\n\n\tif (rctx->in_place)\n\t\trc = kmb_ocs_sk_prepare_inplace(req);\n\telse\n\t\trc = kmb_ocs_sk_prepare_notinplace(req);\n\n\tif (rc)\n\t\tgoto error;\n\n\trc = ocs_aes_op(aes_dev, rctx->mode, tctx->cipher, rctx->instruction,\n\t\t\trctx->dst_dll.dma_addr, rctx->src_dll.dma_addr,\n\t\t\treq->cryptlen, req->iv, iv_size);\n\tif (rc)\n\t\tgoto error;\n\n\t \n\tkmb_ocs_sk_dma_cleanup(req);\n\n\t \n\tif (rctx->cts_swap && rctx->instruction == OCS_ENCRYPT) {\n\t\tsg_swap_blocks(req->dst, rctx->dst_nents,\n\t\t\t       req->cryptlen - AES_BLOCK_SIZE,\n\t\t\t       req->cryptlen - (2 * AES_BLOCK_SIZE));\n\t\treturn 0;\n\t}\n\n\t \n\tif (rctx->mode == OCS_MODE_CBC) {\n\t\t \n\t\tif (rctx->instruction == OCS_ENCRYPT) {\n\t\t\tscatterwalk_map_and_copy(req->iv, req->dst,\n\t\t\t\t\t\t req->cryptlen - iv_size,\n\t\t\t\t\t\t iv_size, 0);\n\t\t\treturn 0;\n\t\t}\n\t\t \n\t\tif (rctx->in_place)\n\t\t\tmemcpy(req->iv, rctx->last_ct_blk, iv_size);\n\t\telse\n\t\t\tscatterwalk_map_and_copy(req->iv, req->src,\n\t\t\t\t\t\t req->cryptlen - iv_size,\n\t\t\t\t\t\t iv_size, 0);\n\t\treturn 0;\n\t}\n\t \n\n\treturn 0;\n\nerror:\n\tkmb_ocs_sk_dma_cleanup(req);\n\n\treturn rc;\n}\n\nstatic int kmb_ocs_aead_validate_input(struct aead_request *req,\n\t\t\t\t       enum ocs_instruction instruction,\n\t\t\t\t       enum ocs_mode mode)\n{\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tint tag_size = crypto_aead_authsize(tfm);\n\tint iv_size = crypto_aead_ivsize(tfm);\n\n\t \n\tif (instruction == OCS_DECRYPT && req->cryptlen < tag_size)\n\t\treturn -EINVAL;\n\n\t \n\tif (!req->iv)\n\t\treturn -EINVAL;\n\n\tswitch (mode) {\n\tcase OCS_MODE_GCM:\n\t\tif (iv_size != GCM_AES_IV_SIZE)\n\t\t\treturn -EINVAL;\n\n\t\treturn 0;\n\n\tcase OCS_MODE_CCM:\n\t\t \n\t\tif (iv_size != AES_BLOCK_SIZE)\n\t\t\treturn -EINVAL;\n\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\n \nstatic int kmb_ocs_aead_common(struct aead_request *req,\n\t\t\t       enum ocs_cipher cipher,\n\t\t\t       enum ocs_instruction instruction,\n\t\t\t       enum ocs_mode mode)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(crypto_aead_reqtfm(req));\n\tstruct ocs_aes_rctx *rctx = aead_request_ctx(req);\n\tstruct ocs_aes_dev *dd;\n\tint rc;\n\n\tif (tctx->use_fallback) {\n\t\tstruct aead_request *subreq = aead_request_ctx(req);\n\n\t\taead_request_set_tfm(subreq, tctx->sw_cipher.aead);\n\t\taead_request_set_callback(subreq, req->base.flags,\n\t\t\t\t\t  req->base.complete, req->base.data);\n\t\taead_request_set_crypt(subreq, req->src, req->dst,\n\t\t\t\t       req->cryptlen, req->iv);\n\t\taead_request_set_ad(subreq, req->assoclen);\n\t\trc = crypto_aead_setauthsize(tctx->sw_cipher.aead,\n\t\t\t\t\t     crypto_aead_authsize(crypto_aead_reqtfm(req)));\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\treturn (instruction == OCS_ENCRYPT) ?\n\t\t       crypto_aead_encrypt(subreq) :\n\t\t       crypto_aead_decrypt(subreq);\n\t}\n\n\trc = kmb_ocs_aead_validate_input(req, instruction, mode);\n\tif (rc)\n\t\treturn rc;\n\n\tdd = kmb_ocs_aes_find_dev(tctx);\n\tif (!dd)\n\t\treturn -ENODEV;\n\n\tif (cipher != tctx->cipher)\n\t\treturn -EINVAL;\n\n\tocs_aes_init_rctx(rctx);\n\trctx->instruction = instruction;\n\trctx->mode = mode;\n\n\treturn crypto_transfer_aead_request_to_engine(dd->engine, req);\n}\n\nstatic void kmb_ocs_aead_dma_cleanup(struct aead_request *req)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(crypto_aead_reqtfm(req));\n\tstruct ocs_aes_rctx *rctx = aead_request_ctx(req);\n\tstruct device *dev = tctx->aes_dev->dev;\n\n\tif (rctx->src_dma_count) {\n\t\tdma_unmap_sg(dev, req->src, rctx->src_nents, DMA_TO_DEVICE);\n\t\trctx->src_dma_count = 0;\n\t}\n\n\tif (rctx->dst_dma_count) {\n\t\tdma_unmap_sg(dev, req->dst, rctx->dst_nents, rctx->in_place ?\n\t\t\t\t\t\t\t     DMA_BIDIRECTIONAL :\n\t\t\t\t\t\t\t     DMA_FROM_DEVICE);\n\t\trctx->dst_dma_count = 0;\n\t}\n\t \n\tcleanup_ocs_dma_linked_list(dev, &rctx->src_dll);\n\tcleanup_ocs_dma_linked_list(dev, &rctx->dst_dll);\n\tcleanup_ocs_dma_linked_list(dev, &rctx->aad_src_dll);\n\tcleanup_ocs_dma_linked_list(dev, &rctx->aad_dst_dll);\n}\n\n \nstatic int kmb_ocs_aead_dma_prepare(struct aead_request *req, u32 *src_dll_size)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(crypto_aead_reqtfm(req));\n\tconst int tag_size = crypto_aead_authsize(crypto_aead_reqtfm(req));\n\tstruct ocs_aes_rctx *rctx = aead_request_ctx(req);\n\tu32 in_size;\t \n\tu32 out_size;\t \n\tu32 dst_size;\t \n\tint rc;\n\n\t \n\trctx->src_nents = sg_nents_for_len(req->src,\n\t\t\t\t\t   req->assoclen + req->cryptlen);\n\tif (rctx->src_nents < 0)\n\t\treturn -EBADMSG;\n\n\tif (rctx->instruction == OCS_DECRYPT) {\n\t\t \n\n\t\t \n\t\tin_size = req->cryptlen - tag_size;\n\n\t\t \n\t\tout_size = in_size;\n\n\t\t \n\t\tdst_size = req->assoclen + out_size;\n\n\t\t \n\t\tsg_pcopy_to_buffer(req->src, rctx->src_nents, rctx->in_tag,\n\t\t\t\t   tag_size, req->assoclen + in_size);\n\n\t} else {  \n\t\t \n\t\t \n\t\tin_size = req->cryptlen;\n\n\t\t \n\t\tout_size = (rctx->mode == OCS_MODE_CCM) ? in_size + tag_size :\n\t\t\t\t\t\t\t  in_size;\n\t\t \n\t\tdst_size = req->assoclen + in_size + tag_size;\n\t}\n\t*src_dll_size = in_size;\n\n\t \n\trctx->dst_nents = sg_nents_for_len(req->dst, dst_size);\n\tif (rctx->dst_nents < 0)\n\t\treturn -EBADMSG;\n\n\trctx->in_place = (req->src == req->dst) ? 1 : 0;\n\n\t \n\trctx->dst_dma_count = dma_map_sg(tctx->aes_dev->dev, req->dst,\n\t\t\t\t\t rctx->dst_nents,\n\t\t\t\t\t rctx->in_place ? DMA_BIDIRECTIONAL :\n\t\t\t\t\t\t\t  DMA_FROM_DEVICE);\n\tif (rctx->dst_dma_count == 0 && rctx->dst_nents != 0) {\n\t\tdev_err(tctx->aes_dev->dev, \"Failed to map destination sg\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,\n\t\t\t\t\t    rctx->dst_dma_count,\n\t\t\t\t\t    &rctx->aad_dst_dll, req->assoclen,\n\t\t\t\t\t    0);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,\n\t\t\t\t\t    rctx->dst_dma_count, &rctx->dst_dll,\n\t\t\t\t\t    out_size, req->assoclen);\n\tif (rc)\n\t\treturn rc;\n\n\tif (rctx->in_place) {\n\t\t \n\t\tif (!(rctx->mode == OCS_MODE_CCM &&\n\t\t      rctx->instruction == OCS_ENCRYPT)) {\n\t\t\t \n\t\t\trctx->src_dll.dma_addr = rctx->dst_dll.dma_addr;\n\t\t\trctx->aad_src_dll.dma_addr = rctx->aad_dst_dll.dma_addr;\n\n\t\t\treturn 0;\n\t\t}\n\t\t \n\t\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,\n\t\t\t\t\t\t    rctx->dst_dma_count,\n\t\t\t\t\t\t    &rctx->aad_src_dll,\n\t\t\t\t\t\t    req->assoclen, 0);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,\n\t\t\t\t\t\t    rctx->dst_dma_count,\n\t\t\t\t\t\t    &rctx->src_dll, in_size,\n\t\t\t\t\t\t    req->assoclen);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\treturn 0;\n\t}\n\t \n\n\t \n\trctx->src_dma_count = dma_map_sg(tctx->aes_dev->dev, req->src,\n\t\t\t\t\t rctx->src_nents, DMA_TO_DEVICE);\n\tif (rctx->src_dma_count == 0 && rctx->src_nents != 0) {\n\t\tdev_err(tctx->aes_dev->dev, \"Failed to map source sg\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->src,\n\t\t\t\t\t    rctx->src_dma_count,\n\t\t\t\t\t    &rctx->aad_src_dll,\n\t\t\t\t\t    req->assoclen, 0);\n\tif (rc)\n\t\treturn rc;\n\n\t \n\trc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->src,\n\t\t\t\t\t    rctx->src_dma_count,\n\t\t\t\t\t    &rctx->src_dll, in_size,\n\t\t\t\t\t    req->assoclen);\n\tif (rc)\n\t\treturn rc;\n\n\tif (req->assoclen == 0)\n\t\treturn 0;\n\n\t \n\trc = ocs_aes_bypass_op(tctx->aes_dev, rctx->aad_dst_dll.dma_addr,\n\t\t\t       rctx->aad_src_dll.dma_addr, req->cryptlen);\n\tif (rc)\n\t\tdev_err(tctx->aes_dev->dev,\n\t\t\t\"Failed to copy source AAD to destination AAD\\n\");\n\n\treturn rc;\n}\n\nstatic int kmb_ocs_aead_run(struct aead_request *req)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(crypto_aead_reqtfm(req));\n\tconst int tag_size = crypto_aead_authsize(crypto_aead_reqtfm(req));\n\tstruct ocs_aes_rctx *rctx = aead_request_ctx(req);\n\tu32 in_size;\t \n\tint rc;\n\n\trc = kmb_ocs_aead_dma_prepare(req, &in_size);\n\tif (rc)\n\t\tgoto exit;\n\n\t \n\tif (rctx->mode == OCS_MODE_CCM) {\n\t\trc = ocs_aes_ccm_op(tctx->aes_dev, tctx->cipher,\n\t\t\t\t    rctx->instruction, rctx->dst_dll.dma_addr,\n\t\t\t\t    rctx->src_dll.dma_addr, in_size,\n\t\t\t\t    req->iv,\n\t\t\t\t    rctx->aad_src_dll.dma_addr, req->assoclen,\n\t\t\t\t    rctx->in_tag, tag_size);\n\t\tgoto exit;\n\t}\n\t \n\trc = ocs_aes_gcm_op(tctx->aes_dev, tctx->cipher,\n\t\t\t    rctx->instruction,\n\t\t\t    rctx->dst_dll.dma_addr,\n\t\t\t    rctx->src_dll.dma_addr, in_size,\n\t\t\t    req->iv,\n\t\t\t    rctx->aad_src_dll.dma_addr, req->assoclen,\n\t\t\t    rctx->out_tag, tag_size);\n\tif (rc)\n\t\tgoto exit;\n\n\t \n\tif (rctx->instruction == OCS_DECRYPT) {\n\t\trc = memcmp(rctx->in_tag, rctx->out_tag, tag_size) ?\n\t\t     -EBADMSG : 0;\n\t\tgoto exit;\n\t}\n\n\t \n\n\t \n\tkmb_ocs_aead_dma_cleanup(req);\n\n\t \n\tsg_pcopy_from_buffer(req->dst, rctx->dst_nents, rctx->out_tag,\n\t\t\t     tag_size, req->assoclen + req->cryptlen);\n\n\t \n\treturn 0;\n\nexit:\n\tkmb_ocs_aead_dma_cleanup(req);\n\n\treturn rc;\n}\n\nstatic int kmb_ocs_aes_sk_do_one_request(struct crypto_engine *engine,\n\t\t\t\t\t void *areq)\n{\n\tstruct skcipher_request *req =\n\t\t\tcontainer_of(areq, struct skcipher_request, base);\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\tint err;\n\n\tif (!tctx->aes_dev) {\n\t\terr = -ENODEV;\n\t\tgoto exit;\n\t}\n\n\terr = ocs_aes_set_key(tctx->aes_dev, tctx->key_len, tctx->key,\n\t\t\t      tctx->cipher);\n\tif (err)\n\t\tgoto exit;\n\n\terr = kmb_ocs_sk_run(req);\n\nexit:\n\tcrypto_finalize_skcipher_request(engine, req, err);\n\n\treturn 0;\n}\n\nstatic int kmb_ocs_aes_aead_do_one_request(struct crypto_engine *engine,\n\t\t\t\t\t   void *areq)\n{\n\tstruct aead_request *req = container_of(areq,\n\t\t\t\t\t\tstruct aead_request, base);\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(crypto_aead_reqtfm(req));\n\tint err;\n\n\tif (!tctx->aes_dev)\n\t\treturn -ENODEV;\n\n\terr = ocs_aes_set_key(tctx->aes_dev, tctx->key_len, tctx->key,\n\t\t\t      tctx->cipher);\n\tif (err)\n\t\tgoto exit;\n\n\terr = kmb_ocs_aead_run(req);\n\nexit:\n\tcrypto_finalize_aead_request(tctx->aes_dev->engine, req, err);\n\n\treturn 0;\n}\n\nstatic int kmb_ocs_aes_set_key(struct crypto_skcipher *tfm, const u8 *in_key,\n\t\t\t       unsigned int key_len)\n{\n\treturn kmb_ocs_sk_set_key(tfm, in_key, key_len, OCS_AES);\n}\n\nstatic int kmb_ocs_aes_aead_set_key(struct crypto_aead *tfm, const u8 *in_key,\n\t\t\t\t    unsigned int key_len)\n{\n\treturn kmb_ocs_aead_set_key(tfm, in_key, key_len, OCS_AES);\n}\n\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB\nstatic int kmb_ocs_aes_ecb_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_ENCRYPT, OCS_MODE_ECB);\n}\n\nstatic int kmb_ocs_aes_ecb_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_DECRYPT, OCS_MODE_ECB);\n}\n#endif  \n\nstatic int kmb_ocs_aes_cbc_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_ENCRYPT, OCS_MODE_CBC);\n}\n\nstatic int kmb_ocs_aes_cbc_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_DECRYPT, OCS_MODE_CBC);\n}\n\nstatic int kmb_ocs_aes_ctr_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_ENCRYPT, OCS_MODE_CTR);\n}\n\nstatic int kmb_ocs_aes_ctr_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_DECRYPT, OCS_MODE_CTR);\n}\n\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS\nstatic int kmb_ocs_aes_cts_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_ENCRYPT, OCS_MODE_CTS);\n}\n\nstatic int kmb_ocs_aes_cts_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_AES, OCS_DECRYPT, OCS_MODE_CTS);\n}\n#endif  \n\nstatic int kmb_ocs_aes_gcm_encrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_AES, OCS_ENCRYPT, OCS_MODE_GCM);\n}\n\nstatic int kmb_ocs_aes_gcm_decrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_AES, OCS_DECRYPT, OCS_MODE_GCM);\n}\n\nstatic int kmb_ocs_aes_ccm_encrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_AES, OCS_ENCRYPT, OCS_MODE_CCM);\n}\n\nstatic int kmb_ocs_aes_ccm_decrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_AES, OCS_DECRYPT, OCS_MODE_CCM);\n}\n\nstatic int kmb_ocs_sm4_set_key(struct crypto_skcipher *tfm, const u8 *in_key,\n\t\t\t       unsigned int key_len)\n{\n\treturn kmb_ocs_sk_set_key(tfm, in_key, key_len, OCS_SM4);\n}\n\nstatic int kmb_ocs_sm4_aead_set_key(struct crypto_aead *tfm, const u8 *in_key,\n\t\t\t\t    unsigned int key_len)\n{\n\treturn kmb_ocs_aead_set_key(tfm, in_key, key_len, OCS_SM4);\n}\n\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB\nstatic int kmb_ocs_sm4_ecb_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_ENCRYPT, OCS_MODE_ECB);\n}\n\nstatic int kmb_ocs_sm4_ecb_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_DECRYPT, OCS_MODE_ECB);\n}\n#endif  \n\nstatic int kmb_ocs_sm4_cbc_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_ENCRYPT, OCS_MODE_CBC);\n}\n\nstatic int kmb_ocs_sm4_cbc_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_DECRYPT, OCS_MODE_CBC);\n}\n\nstatic int kmb_ocs_sm4_ctr_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_ENCRYPT, OCS_MODE_CTR);\n}\n\nstatic int kmb_ocs_sm4_ctr_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_DECRYPT, OCS_MODE_CTR);\n}\n\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS\nstatic int kmb_ocs_sm4_cts_encrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_ENCRYPT, OCS_MODE_CTS);\n}\n\nstatic int kmb_ocs_sm4_cts_decrypt(struct skcipher_request *req)\n{\n\treturn kmb_ocs_sk_common(req, OCS_SM4, OCS_DECRYPT, OCS_MODE_CTS);\n}\n#endif  \n\nstatic int kmb_ocs_sm4_gcm_encrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_SM4, OCS_ENCRYPT, OCS_MODE_GCM);\n}\n\nstatic int kmb_ocs_sm4_gcm_decrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_SM4, OCS_DECRYPT, OCS_MODE_GCM);\n}\n\nstatic int kmb_ocs_sm4_ccm_encrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_SM4, OCS_ENCRYPT, OCS_MODE_CCM);\n}\n\nstatic int kmb_ocs_sm4_ccm_decrypt(struct aead_request *req)\n{\n\treturn kmb_ocs_aead_common(req, OCS_SM4, OCS_DECRYPT, OCS_MODE_CCM);\n}\n\nstatic int ocs_aes_init_tfm(struct crypto_skcipher *tfm)\n{\n\tconst char *alg_name = crypto_tfm_alg_name(&tfm->base);\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\tstruct crypto_sync_skcipher *blk;\n\n\t \n\tblk = crypto_alloc_sync_skcipher(alg_name, 0, CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(blk))\n\t\treturn PTR_ERR(blk);\n\n\ttctx->sw_cipher.sk = blk;\n\n\tcrypto_skcipher_set_reqsize(tfm, sizeof(struct ocs_aes_rctx));\n\n\treturn 0;\n}\n\nstatic int ocs_sm4_init_tfm(struct crypto_skcipher *tfm)\n{\n\tcrypto_skcipher_set_reqsize(tfm, sizeof(struct ocs_aes_rctx));\n\n\treturn 0;\n}\n\nstatic inline void clear_key(struct ocs_aes_tctx *tctx)\n{\n\tmemzero_explicit(tctx->key, OCS_AES_KEYSIZE_256);\n\n\t \n\tif (tctx->aes_dev)\n\t\tocs_aes_set_key(tctx->aes_dev, OCS_AES_KEYSIZE_256,\n\t\t\t\ttctx->key, OCS_AES);\n}\n\nstatic void ocs_exit_tfm(struct crypto_skcipher *tfm)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_skcipher_ctx(tfm);\n\n\tclear_key(tctx);\n\n\tif (tctx->sw_cipher.sk) {\n\t\tcrypto_free_sync_skcipher(tctx->sw_cipher.sk);\n\t\ttctx->sw_cipher.sk = NULL;\n\t}\n}\n\nstatic int ocs_aes_aead_cra_init(struct crypto_aead *tfm)\n{\n\tconst char *alg_name = crypto_tfm_alg_name(&tfm->base);\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(tfm);\n\tstruct crypto_aead *blk;\n\n\t \n\tblk = crypto_alloc_aead(alg_name, 0, CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(blk))\n\t\treturn PTR_ERR(blk);\n\n\ttctx->sw_cipher.aead = blk;\n\n\tcrypto_aead_set_reqsize(tfm,\n\t\t\t\tmax(sizeof(struct ocs_aes_rctx),\n\t\t\t\t    (sizeof(struct aead_request) +\n\t\t\t\t     crypto_aead_reqsize(tctx->sw_cipher.aead))));\n\n\treturn 0;\n}\n\nstatic int kmb_ocs_aead_ccm_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t\tunsigned int authsize)\n{\n\tswitch (authsize) {\n\tcase 4:\n\tcase 6:\n\tcase 8:\n\tcase 10:\n\tcase 12:\n\tcase 14:\n\tcase 16:\n\t\treturn 0;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic int kmb_ocs_aead_gcm_setauthsize(struct crypto_aead *tfm,\n\t\t\t\t\tunsigned int authsize)\n{\n\treturn crypto_gcm_check_authsize(authsize);\n}\n\nstatic int ocs_sm4_aead_cra_init(struct crypto_aead *tfm)\n{\n\tcrypto_aead_set_reqsize(tfm, sizeof(struct ocs_aes_rctx));\n\n\treturn 0;\n}\n\nstatic void ocs_aead_cra_exit(struct crypto_aead *tfm)\n{\n\tstruct ocs_aes_tctx *tctx = crypto_aead_ctx(tfm);\n\n\tclear_key(tctx);\n\n\tif (tctx->sw_cipher.aead) {\n\t\tcrypto_free_aead(tctx->sw_cipher.aead);\n\t\ttctx->sw_cipher.aead = NULL;\n\t}\n}\n\nstatic struct skcipher_engine_alg algs[] = {\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB\n\t{\n\t\t.base.base.cra_name = \"ecb(aes)\",\n\t\t.base.base.cra_driver_name = \"ecb-aes-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t       CRYPTO_ALG_NEED_FALLBACK,\n\t\t.base.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_AES_MIN_KEY_SIZE,\n\t\t.base.max_keysize = OCS_AES_MAX_KEY_SIZE,\n\t\t.base.setkey = kmb_ocs_aes_set_key,\n\t\t.base.encrypt = kmb_ocs_aes_ecb_encrypt,\n\t\t.base.decrypt = kmb_ocs_aes_ecb_decrypt,\n\t\t.base.init = ocs_aes_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t},\n#endif  \n\t{\n\t\t.base.base.cra_name = \"cbc(aes)\",\n\t\t.base.base.cra_driver_name = \"cbc-aes-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t       CRYPTO_ALG_NEED_FALLBACK,\n\t\t.base.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_AES_MIN_KEY_SIZE,\n\t\t.base.max_keysize = OCS_AES_MAX_KEY_SIZE,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.setkey = kmb_ocs_aes_set_key,\n\t\t.base.encrypt = kmb_ocs_aes_cbc_encrypt,\n\t\t.base.decrypt = kmb_ocs_aes_cbc_decrypt,\n\t\t.base.init = ocs_aes_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t},\n\t{\n\t\t.base.base.cra_name = \"ctr(aes)\",\n\t\t.base.base.cra_driver_name = \"ctr-aes-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t       CRYPTO_ALG_NEED_FALLBACK,\n\t\t.base.base.cra_blocksize = 1,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_AES_MIN_KEY_SIZE,\n\t\t.base.max_keysize = OCS_AES_MAX_KEY_SIZE,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.setkey = kmb_ocs_aes_set_key,\n\t\t.base.encrypt = kmb_ocs_aes_ctr_encrypt,\n\t\t.base.decrypt = kmb_ocs_aes_ctr_decrypt,\n\t\t.base.init = ocs_aes_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t},\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS\n\t{\n\t\t.base.base.cra_name = \"cts(cbc(aes))\",\n\t\t.base.base.cra_driver_name = \"cts-aes-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t       CRYPTO_ALG_NEED_FALLBACK,\n\t\t.base.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_AES_MIN_KEY_SIZE,\n\t\t.base.max_keysize = OCS_AES_MAX_KEY_SIZE,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.setkey = kmb_ocs_aes_set_key,\n\t\t.base.encrypt = kmb_ocs_aes_cts_encrypt,\n\t\t.base.decrypt = kmb_ocs_aes_cts_decrypt,\n\t\t.base.init = ocs_aes_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t},\n#endif  \n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB\n\t{\n\t\t.base.base.cra_name = \"ecb(sm4)\",\n\t\t.base.base.cra_driver_name = \"ecb-sm4-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t.base.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.max_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.setkey = kmb_ocs_sm4_set_key,\n\t\t.base.encrypt = kmb_ocs_sm4_ecb_encrypt,\n\t\t.base.decrypt = kmb_ocs_sm4_ecb_decrypt,\n\t\t.base.init = ocs_sm4_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t},\n#endif  \n\t{\n\t\t.base.base.cra_name = \"cbc(sm4)\",\n\t\t.base.base.cra_driver_name = \"cbc-sm4-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t.base.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.max_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.setkey = kmb_ocs_sm4_set_key,\n\t\t.base.encrypt = kmb_ocs_sm4_cbc_encrypt,\n\t\t.base.decrypt = kmb_ocs_sm4_cbc_decrypt,\n\t\t.base.init = ocs_sm4_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t},\n\t{\n\t\t.base.base.cra_name = \"ctr(sm4)\",\n\t\t.base.base.cra_driver_name = \"ctr-sm4-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t.base.base.cra_blocksize = 1,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.max_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.setkey = kmb_ocs_sm4_set_key,\n\t\t.base.encrypt = kmb_ocs_sm4_ctr_encrypt,\n\t\t.base.decrypt = kmb_ocs_sm4_ctr_decrypt,\n\t\t.base.init = ocs_sm4_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t},\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS\n\t{\n\t\t.base.base.cra_name = \"cts(cbc(sm4))\",\n\t\t.base.base.cra_driver_name = \"cts-sm4-keembay-ocs\",\n\t\t.base.base.cra_priority = KMB_OCS_PRIORITY,\n\t\t.base.base.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t       CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t.base.base.cra_blocksize = AES_BLOCK_SIZE,\n\t\t.base.base.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t.base.base.cra_module = THIS_MODULE,\n\t\t.base.base.cra_alignmask = 0,\n\n\t\t.base.min_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.max_keysize = OCS_SM4_KEY_SIZE,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.setkey = kmb_ocs_sm4_set_key,\n\t\t.base.encrypt = kmb_ocs_sm4_cts_encrypt,\n\t\t.base.decrypt = kmb_ocs_sm4_cts_decrypt,\n\t\t.base.init = ocs_sm4_init_tfm,\n\t\t.base.exit = ocs_exit_tfm,\n\t\t.op.do_one_request = kmb_ocs_aes_sk_do_one_request,\n\t}\n#endif  \n};\n\nstatic struct aead_engine_alg algs_aead[] = {\n\t{\n\t\t.base.base = {\n\t\t\t.cra_name = \"gcm(aes)\",\n\t\t\t.cra_driver_name = \"gcm-aes-keembay-ocs\",\n\t\t\t.cra_priority = KMB_OCS_PRIORITY,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t     CRYPTO_ALG_NEED_FALLBACK,\n\t\t\t.cra_blocksize = 1,\n\t\t\t.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.base.init = ocs_aes_aead_cra_init,\n\t\t.base.exit = ocs_aead_cra_exit,\n\t\t.base.ivsize = GCM_AES_IV_SIZE,\n\t\t.base.maxauthsize = AES_BLOCK_SIZE,\n\t\t.base.setauthsize = kmb_ocs_aead_gcm_setauthsize,\n\t\t.base.setkey = kmb_ocs_aes_aead_set_key,\n\t\t.base.encrypt = kmb_ocs_aes_gcm_encrypt,\n\t\t.base.decrypt = kmb_ocs_aes_gcm_decrypt,\n\t\t.op.do_one_request = kmb_ocs_aes_aead_do_one_request,\n\t},\n\t{\n\t\t.base.base = {\n\t\t\t.cra_name = \"ccm(aes)\",\n\t\t\t.cra_driver_name = \"ccm-aes-keembay-ocs\",\n\t\t\t.cra_priority = KMB_OCS_PRIORITY,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t     CRYPTO_ALG_NEED_FALLBACK,\n\t\t\t.cra_blocksize = 1,\n\t\t\t.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.base.init = ocs_aes_aead_cra_init,\n\t\t.base.exit = ocs_aead_cra_exit,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.maxauthsize = AES_BLOCK_SIZE,\n\t\t.base.setauthsize = kmb_ocs_aead_ccm_setauthsize,\n\t\t.base.setkey = kmb_ocs_aes_aead_set_key,\n\t\t.base.encrypt = kmb_ocs_aes_ccm_encrypt,\n\t\t.base.decrypt = kmb_ocs_aes_ccm_decrypt,\n\t\t.op.do_one_request = kmb_ocs_aes_aead_do_one_request,\n\t},\n\t{\n\t\t.base.base = {\n\t\t\t.cra_name = \"gcm(sm4)\",\n\t\t\t.cra_driver_name = \"gcm-sm4-keembay-ocs\",\n\t\t\t.cra_priority = KMB_OCS_PRIORITY,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t.cra_blocksize = 1,\n\t\t\t.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.base.init = ocs_sm4_aead_cra_init,\n\t\t.base.exit = ocs_aead_cra_exit,\n\t\t.base.ivsize = GCM_AES_IV_SIZE,\n\t\t.base.maxauthsize = AES_BLOCK_SIZE,\n\t\t.base.setauthsize = kmb_ocs_aead_gcm_setauthsize,\n\t\t.base.setkey = kmb_ocs_sm4_aead_set_key,\n\t\t.base.encrypt = kmb_ocs_sm4_gcm_encrypt,\n\t\t.base.decrypt = kmb_ocs_sm4_gcm_decrypt,\n\t\t.op.do_one_request = kmb_ocs_aes_aead_do_one_request,\n\t},\n\t{\n\t\t.base.base = {\n\t\t\t.cra_name = \"ccm(sm4)\",\n\t\t\t.cra_driver_name = \"ccm-sm4-keembay-ocs\",\n\t\t\t.cra_priority = KMB_OCS_PRIORITY,\n\t\t\t.cra_flags = CRYPTO_ALG_ASYNC |\n\t\t\t\t     CRYPTO_ALG_KERN_DRIVER_ONLY,\n\t\t\t.cra_blocksize = 1,\n\t\t\t.cra_ctxsize = sizeof(struct ocs_aes_tctx),\n\t\t\t.cra_alignmask = 0,\n\t\t\t.cra_module = THIS_MODULE,\n\t\t},\n\t\t.base.init = ocs_sm4_aead_cra_init,\n\t\t.base.exit = ocs_aead_cra_exit,\n\t\t.base.ivsize = AES_BLOCK_SIZE,\n\t\t.base.maxauthsize = AES_BLOCK_SIZE,\n\t\t.base.setauthsize = kmb_ocs_aead_ccm_setauthsize,\n\t\t.base.setkey = kmb_ocs_sm4_aead_set_key,\n\t\t.base.encrypt = kmb_ocs_sm4_ccm_encrypt,\n\t\t.base.decrypt = kmb_ocs_sm4_ccm_decrypt,\n\t\t.op.do_one_request = kmb_ocs_aes_aead_do_one_request,\n\t}\n};\n\nstatic void unregister_aes_algs(struct ocs_aes_dev *aes_dev)\n{\n\tcrypto_engine_unregister_aeads(algs_aead, ARRAY_SIZE(algs_aead));\n\tcrypto_engine_unregister_skciphers(algs, ARRAY_SIZE(algs));\n}\n\nstatic int register_aes_algs(struct ocs_aes_dev *aes_dev)\n{\n\tint ret;\n\n\t \n\tret = crypto_engine_register_aeads(algs_aead, ARRAY_SIZE(algs_aead));\n\tif (ret)\n\t\treturn ret;\n\n\tret = crypto_engine_register_skciphers(algs, ARRAY_SIZE(algs));\n\tif (ret)\n\t\tcrypto_engine_unregister_aeads(algs_aead, ARRAY_SIZE(algs));\n\n\treturn ret;\n}\n\n \nstatic const struct of_device_id kmb_ocs_aes_of_match[] = {\n\t{\n\t\t.compatible = \"intel,keembay-ocs-aes\",\n\t},\n\t{}\n};\n\nstatic int kmb_ocs_aes_remove(struct platform_device *pdev)\n{\n\tstruct ocs_aes_dev *aes_dev;\n\n\taes_dev = platform_get_drvdata(pdev);\n\n\tunregister_aes_algs(aes_dev);\n\n\tspin_lock(&ocs_aes.lock);\n\tlist_del(&aes_dev->list);\n\tspin_unlock(&ocs_aes.lock);\n\n\tcrypto_engine_exit(aes_dev->engine);\n\n\treturn 0;\n}\n\nstatic int kmb_ocs_aes_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct ocs_aes_dev *aes_dev;\n\tint rc;\n\n\taes_dev = devm_kzalloc(dev, sizeof(*aes_dev), GFP_KERNEL);\n\tif (!aes_dev)\n\t\treturn -ENOMEM;\n\n\taes_dev->dev = dev;\n\n\tplatform_set_drvdata(pdev, aes_dev);\n\n\trc = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));\n\tif (rc) {\n\t\tdev_err(dev, \"Failed to set 32 bit dma mask %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\taes_dev->base_reg = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(aes_dev->base_reg))\n\t\treturn PTR_ERR(aes_dev->base_reg);\n\n\t \n\taes_dev->irq = platform_get_irq(pdev, 0);\n\tif (aes_dev->irq < 0)\n\t\treturn aes_dev->irq;\n\n\trc = devm_request_threaded_irq(dev, aes_dev->irq, ocs_aes_irq_handler,\n\t\t\t\t       NULL, 0, \"keembay-ocs-aes\", aes_dev);\n\tif (rc < 0) {\n\t\tdev_err(dev, \"Could not request IRQ\\n\");\n\t\treturn rc;\n\t}\n\n\tINIT_LIST_HEAD(&aes_dev->list);\n\tspin_lock(&ocs_aes.lock);\n\tlist_add_tail(&aes_dev->list, &ocs_aes.dev_list);\n\tspin_unlock(&ocs_aes.lock);\n\n\tinit_completion(&aes_dev->irq_completion);\n\n\t \n\taes_dev->engine = crypto_engine_alloc_init(dev, true);\n\tif (!aes_dev->engine) {\n\t\trc = -ENOMEM;\n\t\tgoto list_del;\n\t}\n\n\trc = crypto_engine_start(aes_dev->engine);\n\tif (rc) {\n\t\tdev_err(dev, \"Could not start crypto engine\\n\");\n\t\tgoto cleanup;\n\t}\n\n\trc = register_aes_algs(aes_dev);\n\tif (rc) {\n\t\tdev_err(dev,\n\t\t\t\"Could not register OCS algorithms with Crypto API\\n\");\n\t\tgoto cleanup;\n\t}\n\n\treturn 0;\n\ncleanup:\n\tcrypto_engine_exit(aes_dev->engine);\nlist_del:\n\tspin_lock(&ocs_aes.lock);\n\tlist_del(&aes_dev->list);\n\tspin_unlock(&ocs_aes.lock);\n\n\treturn rc;\n}\n\n \nstatic struct platform_driver kmb_ocs_aes_driver = {\n\t.probe = kmb_ocs_aes_probe,\n\t.remove = kmb_ocs_aes_remove,\n\t.driver = {\n\t\t\t.name = DRV_NAME,\n\t\t\t.of_match_table = kmb_ocs_aes_of_match,\n\t\t},\n};\n\nmodule_platform_driver(kmb_ocs_aes_driver);\n\nMODULE_DESCRIPTION(\"Intel Keem Bay Offload and Crypto Subsystem (OCS) AES/SM4 Driver\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_ALIAS_CRYPTO(\"cbc-aes-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"ctr-aes-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"gcm-aes-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"ccm-aes-keembay-ocs\");\n\nMODULE_ALIAS_CRYPTO(\"cbc-sm4-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"ctr-sm4-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"gcm-sm4-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"ccm-sm4-keembay-ocs\");\n\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_ECB\nMODULE_ALIAS_CRYPTO(\"ecb-aes-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"ecb-sm4-keembay-ocs\");\n#endif  \n\n#ifdef CONFIG_CRYPTO_DEV_KEEMBAY_OCS_AES_SM4_CTS\nMODULE_ALIAS_CRYPTO(\"cts-aes-keembay-ocs\");\nMODULE_ALIAS_CRYPTO(\"cts-sm4-keembay-ocs\");\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}