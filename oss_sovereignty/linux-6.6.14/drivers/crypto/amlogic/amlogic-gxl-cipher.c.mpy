{
  "module_name": "amlogic-gxl-cipher.c",
  "hash_id": "898f6103a82c46ae4bfa8dbc8f087f36f8a61c89c1c0d5bcb6ee88705aca2248",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/amlogic/amlogic-gxl-cipher.c",
  "human_readable_source": "\n \n\n#include <linux/crypto.h>\n#include <linux/delay.h>\n#include <linux/io.h>\n#include <crypto/scatterwalk.h>\n#include <linux/scatterlist.h>\n#include <linux/dma-mapping.h>\n#include <crypto/internal/skcipher.h>\n#include \"amlogic-gxl.h\"\n\nstatic int get_engine_number(struct meson_dev *mc)\n{\n\treturn atomic_inc_return(&mc->flow) % MAXFLOW;\n}\n\nstatic bool meson_cipher_need_fallback(struct skcipher_request *areq)\n{\n\tstruct scatterlist *src_sg = areq->src;\n\tstruct scatterlist *dst_sg = areq->dst;\n\n\tif (areq->cryptlen == 0)\n\t\treturn true;\n\n\tif (sg_nents(src_sg) != sg_nents(dst_sg))\n\t\treturn true;\n\n\t \n\tif (sg_nents(src_sg) > MAXDESC - 3 || sg_nents(dst_sg) > MAXDESC - 3)\n\t\treturn true;\n\n\twhile (src_sg && dst_sg) {\n\t\tif ((src_sg->length % 16) != 0)\n\t\t\treturn true;\n\t\tif ((dst_sg->length % 16) != 0)\n\t\t\treturn true;\n\t\tif (src_sg->length != dst_sg->length)\n\t\t\treturn true;\n\t\tif (!IS_ALIGNED(src_sg->offset, sizeof(u32)))\n\t\t\treturn true;\n\t\tif (!IS_ALIGNED(dst_sg->offset, sizeof(u32)))\n\t\t\treturn true;\n\t\tsrc_sg = sg_next(src_sg);\n\t\tdst_sg = sg_next(dst_sg);\n\t}\n\n\treturn false;\n}\n\nstatic int meson_cipher_do_fallback(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct meson_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct meson_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tint err;\n#ifdef CONFIG_CRYPTO_DEV_AMLOGIC_GXL_DEBUG\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(tfm);\n\tstruct meson_alg_template *algt;\n\n\talgt = container_of(alg, struct meson_alg_template, alg.skcipher.base);\n\talgt->stat_fb++;\n#endif\n\tskcipher_request_set_tfm(&rctx->fallback_req, op->fallback_tfm);\n\tskcipher_request_set_callback(&rctx->fallback_req, areq->base.flags,\n\t\t\t\t      areq->base.complete, areq->base.data);\n\tskcipher_request_set_crypt(&rctx->fallback_req, areq->src, areq->dst,\n\t\t\t\t   areq->cryptlen, areq->iv);\n\n\tif (rctx->op_dir == MESON_DECRYPT)\n\t\terr = crypto_skcipher_decrypt(&rctx->fallback_req);\n\telse\n\t\terr = crypto_skcipher_encrypt(&rctx->fallback_req);\n\treturn err;\n}\n\nstatic int meson_cipher(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct meson_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct meson_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct meson_dev *mc = op->mc;\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(tfm);\n\tstruct meson_alg_template *algt;\n\tint flow = rctx->flow;\n\tunsigned int todo, eat, len;\n\tstruct scatterlist *src_sg = areq->src;\n\tstruct scatterlist *dst_sg = areq->dst;\n\tstruct meson_desc *desc;\n\tint nr_sgs, nr_sgd;\n\tint i, err = 0;\n\tunsigned int keyivlen, ivsize, offset, tloffset;\n\tdma_addr_t phykeyiv;\n\tvoid *backup_iv = NULL, *bkeyiv;\n\tu32 v;\n\n\talgt = container_of(alg, struct meson_alg_template, alg.skcipher.base);\n\n\tdev_dbg(mc->dev, \"%s %s %u %x IV(%u) key=%u flow=%d\\n\", __func__,\n\t\tcrypto_tfm_alg_name(areq->base.tfm),\n\t\tareq->cryptlen,\n\t\trctx->op_dir, crypto_skcipher_ivsize(tfm),\n\t\top->keylen, flow);\n\n#ifdef CONFIG_CRYPTO_DEV_AMLOGIC_GXL_DEBUG\n\talgt->stat_req++;\n\tmc->chanlist[flow].stat_req++;\n#endif\n\n\t \n\tbkeyiv = kzalloc(48, GFP_KERNEL | GFP_DMA);\n\tif (!bkeyiv)\n\t\treturn -ENOMEM;\n\n\tmemcpy(bkeyiv, op->key, op->keylen);\n\tkeyivlen = op->keylen;\n\n\tivsize = crypto_skcipher_ivsize(tfm);\n\tif (areq->iv && ivsize > 0) {\n\t\tif (ivsize > areq->cryptlen) {\n\t\t\tdev_err(mc->dev, \"invalid ivsize=%d vs len=%d\\n\", ivsize, areq->cryptlen);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend;\n\t\t}\n\t\tmemcpy(bkeyiv + 32, areq->iv, ivsize);\n\t\tkeyivlen = 48;\n\t\tif (rctx->op_dir == MESON_DECRYPT) {\n\t\t\tbackup_iv = kzalloc(ivsize, GFP_KERNEL);\n\t\t\tif (!backup_iv) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto theend;\n\t\t\t}\n\t\t\toffset = areq->cryptlen - ivsize;\n\t\t\tscatterwalk_map_and_copy(backup_iv, areq->src, offset,\n\t\t\t\t\t\t ivsize, 0);\n\t\t}\n\t}\n\tif (keyivlen == 24)\n\t\tkeyivlen = 32;\n\n\tphykeyiv = dma_map_single(mc->dev, bkeyiv, keyivlen,\n\t\t\t\t  DMA_TO_DEVICE);\n\terr = dma_mapping_error(mc->dev, phykeyiv);\n\tif (err) {\n\t\tdev_err(mc->dev, \"Cannot DMA MAP KEY IV\\n\");\n\t\tgoto theend;\n\t}\n\n\ttloffset = 0;\n\teat = 0;\n\ti = 0;\n\twhile (keyivlen > eat) {\n\t\tdesc = &mc->chanlist[flow].tl[tloffset];\n\t\tmemset(desc, 0, sizeof(struct meson_desc));\n\t\ttodo = min(keyivlen - eat, 16u);\n\t\tdesc->t_src = cpu_to_le32(phykeyiv + i * 16);\n\t\tdesc->t_dst = cpu_to_le32(i * 16);\n\t\tv = (MODE_KEY << 20) | DESC_OWN | 16;\n\t\tdesc->t_status = cpu_to_le32(v);\n\n\t\teat += todo;\n\t\ti++;\n\t\ttloffset++;\n\t}\n\n\tif (areq->src == areq->dst) {\n\t\tnr_sgs = dma_map_sg(mc->dev, areq->src, sg_nents(areq->src),\n\t\t\t\t    DMA_BIDIRECTIONAL);\n\t\tif (!nr_sgs) {\n\t\t\tdev_err(mc->dev, \"Invalid SG count %d\\n\", nr_sgs);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend;\n\t\t}\n\t\tnr_sgd = nr_sgs;\n\t} else {\n\t\tnr_sgs = dma_map_sg(mc->dev, areq->src, sg_nents(areq->src),\n\t\t\t\t    DMA_TO_DEVICE);\n\t\tif (!nr_sgs || nr_sgs > MAXDESC - 3) {\n\t\t\tdev_err(mc->dev, \"Invalid SG count %d\\n\", nr_sgs);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend;\n\t\t}\n\t\tnr_sgd = dma_map_sg(mc->dev, areq->dst, sg_nents(areq->dst),\n\t\t\t\t    DMA_FROM_DEVICE);\n\t\tif (!nr_sgd || nr_sgd > MAXDESC - 3) {\n\t\t\tdev_err(mc->dev, \"Invalid SG count %d\\n\", nr_sgd);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend;\n\t\t}\n\t}\n\n\tsrc_sg = areq->src;\n\tdst_sg = areq->dst;\n\tlen = areq->cryptlen;\n\twhile (src_sg) {\n\t\tdesc = &mc->chanlist[flow].tl[tloffset];\n\t\tmemset(desc, 0, sizeof(struct meson_desc));\n\n\t\tdesc->t_src = cpu_to_le32(sg_dma_address(src_sg));\n\t\tdesc->t_dst = cpu_to_le32(sg_dma_address(dst_sg));\n\t\ttodo = min(len, sg_dma_len(src_sg));\n\t\tv = (op->keymode << 20) | DESC_OWN | todo | (algt->blockmode << 26);\n\t\tif (rctx->op_dir)\n\t\t\tv |= DESC_ENCRYPTION;\n\t\tlen -= todo;\n\n\t\tif (!sg_next(src_sg))\n\t\t\tv |= DESC_LAST;\n\t\tdesc->t_status = cpu_to_le32(v);\n\t\ttloffset++;\n\t\tsrc_sg = sg_next(src_sg);\n\t\tdst_sg = sg_next(dst_sg);\n\t}\n\n\treinit_completion(&mc->chanlist[flow].complete);\n\tmc->chanlist[flow].status = 0;\n\twritel(mc->chanlist[flow].t_phy | 2, mc->base + (flow << 2));\n\twait_for_completion_interruptible_timeout(&mc->chanlist[flow].complete,\n\t\t\t\t\t\t  msecs_to_jiffies(500));\n\tif (mc->chanlist[flow].status == 0) {\n\t\tdev_err(mc->dev, \"DMA timeout for flow %d\\n\", flow);\n\t\terr = -EINVAL;\n\t}\n\n\tdma_unmap_single(mc->dev, phykeyiv, keyivlen, DMA_TO_DEVICE);\n\n\tif (areq->src == areq->dst) {\n\t\tdma_unmap_sg(mc->dev, areq->src, sg_nents(areq->src), DMA_BIDIRECTIONAL);\n\t} else {\n\t\tdma_unmap_sg(mc->dev, areq->src, sg_nents(areq->src), DMA_TO_DEVICE);\n\t\tdma_unmap_sg(mc->dev, areq->dst, sg_nents(areq->dst), DMA_FROM_DEVICE);\n\t}\n\n\tif (areq->iv && ivsize > 0) {\n\t\tif (rctx->op_dir == MESON_DECRYPT) {\n\t\t\tmemcpy(areq->iv, backup_iv, ivsize);\n\t\t} else {\n\t\t\tscatterwalk_map_and_copy(areq->iv, areq->dst,\n\t\t\t\t\t\t areq->cryptlen - ivsize,\n\t\t\t\t\t\t ivsize, 0);\n\t\t}\n\t}\ntheend:\n\tkfree_sensitive(bkeyiv);\n\tkfree_sensitive(backup_iv);\n\n\treturn err;\n}\n\nint meson_handle_cipher_request(struct crypto_engine *engine, void *areq)\n{\n\tint err;\n\tstruct skcipher_request *breq = container_of(areq, struct skcipher_request, base);\n\n\terr = meson_cipher(breq);\n\tlocal_bh_disable();\n\tcrypto_finalize_skcipher_request(engine, breq, err);\n\tlocal_bh_enable();\n\n\treturn 0;\n}\n\nint meson_skdecrypt(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct meson_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct meson_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct crypto_engine *engine;\n\tint e;\n\n\trctx->op_dir = MESON_DECRYPT;\n\tif (meson_cipher_need_fallback(areq))\n\t\treturn meson_cipher_do_fallback(areq);\n\te = get_engine_number(op->mc);\n\tengine = op->mc->chanlist[e].engine;\n\trctx->flow = e;\n\n\treturn crypto_transfer_skcipher_request_to_engine(engine, areq);\n}\n\nint meson_skencrypt(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct meson_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct meson_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct crypto_engine *engine;\n\tint e;\n\n\trctx->op_dir = MESON_ENCRYPT;\n\tif (meson_cipher_need_fallback(areq))\n\t\treturn meson_cipher_do_fallback(areq);\n\te = get_engine_number(op->mc);\n\tengine = op->mc->chanlist[e].engine;\n\trctx->flow = e;\n\n\treturn crypto_transfer_skcipher_request_to_engine(engine, areq);\n}\n\nint meson_cipher_init(struct crypto_tfm *tfm)\n{\n\tstruct meson_cipher_tfm_ctx *op = crypto_tfm_ctx(tfm);\n\tstruct meson_alg_template *algt;\n\tconst char *name = crypto_tfm_alg_name(tfm);\n\tstruct crypto_skcipher *sktfm = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(sktfm);\n\n\tmemset(op, 0, sizeof(struct meson_cipher_tfm_ctx));\n\n\talgt = container_of(alg, struct meson_alg_template, alg.skcipher.base);\n\top->mc = algt->mc;\n\n\top->fallback_tfm = crypto_alloc_skcipher(name, 0, CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(op->fallback_tfm)) {\n\t\tdev_err(op->mc->dev, \"ERROR: Cannot allocate fallback for %s %ld\\n\",\n\t\t\tname, PTR_ERR(op->fallback_tfm));\n\t\treturn PTR_ERR(op->fallback_tfm);\n\t}\n\n\tsktfm->reqsize = sizeof(struct meson_cipher_req_ctx) +\n\t\t\t crypto_skcipher_reqsize(op->fallback_tfm);\n\n\treturn 0;\n}\n\nvoid meson_cipher_exit(struct crypto_tfm *tfm)\n{\n\tstruct meson_cipher_tfm_ctx *op = crypto_tfm_ctx(tfm);\n\n\tkfree_sensitive(op->key);\n\tcrypto_free_skcipher(op->fallback_tfm);\n}\n\nint meson_aes_setkey(struct crypto_skcipher *tfm, const u8 *key,\n\t\t     unsigned int keylen)\n{\n\tstruct meson_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct meson_dev *mc = op->mc;\n\n\tswitch (keylen) {\n\tcase 128 / 8:\n\t\top->keymode = MODE_AES_128;\n\t\tbreak;\n\tcase 192 / 8:\n\t\top->keymode = MODE_AES_192;\n\t\tbreak;\n\tcase 256 / 8:\n\t\top->keymode = MODE_AES_256;\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(mc->dev, \"ERROR: Invalid keylen %u\\n\", keylen);\n\t\treturn -EINVAL;\n\t}\n\tkfree_sensitive(op->key);\n\top->keylen = keylen;\n\top->key = kmemdup(key, keylen, GFP_KERNEL | GFP_DMA);\n\tif (!op->key)\n\t\treturn -ENOMEM;\n\n\treturn crypto_skcipher_setkey(op->fallback_tfm, key, keylen);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}