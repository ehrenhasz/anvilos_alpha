{
  "module_name": "nx.c",
  "hash_id": "4cb9cbf3019c6f9afc78a79d7da0bf847d590b7783263e313ea2fc29803a8716",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/nx/nx.c",
  "human_readable_source": "\n \n\n#include <crypto/internal/aead.h>\n#include <crypto/internal/hash.h>\n#include <crypto/aes.h>\n#include <crypto/sha2.h>\n#include <crypto/algapi.h>\n#include <crypto/scatterwalk.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/types.h>\n#include <linux/mm.h>\n#include <linux/scatterlist.h>\n#include <linux/device.h>\n#include <linux/of.h>\n#include <asm/hvcall.h>\n#include <asm/vio.h>\n\n#include \"nx_csbcpb.h\"\n#include \"nx.h\"\n\n\n \nint nx_hcall_sync(struct nx_crypto_ctx *nx_ctx,\n\t\t  struct vio_pfo_op    *op,\n\t\t  u32                   may_sleep)\n{\n\tint rc, retries = 10;\n\tstruct vio_dev *viodev = nx_driver.viodev;\n\n\tatomic_inc(&(nx_ctx->stats->sync_ops));\n\n\tdo {\n\t\trc = vio_h_cop_sync(viodev, op);\n\t} while (rc == -EBUSY && !may_sleep && retries--);\n\n\tif (rc) {\n\t\tdev_dbg(&viodev->dev, \"vio_h_cop_sync failed: rc: %d \"\n\t\t\t\"hcall rc: %ld\\n\", rc, op->hcall_err);\n\t\tatomic_inc(&(nx_ctx->stats->errors));\n\t\tatomic_set(&(nx_ctx->stats->last_error), op->hcall_err);\n\t\tatomic_set(&(nx_ctx->stats->last_error_pid), current->pid);\n\t}\n\n\treturn rc;\n}\n\n \nstruct nx_sg *nx_build_sg_list(struct nx_sg *sg_head,\n\t\t\t       u8           *start_addr,\n\t\t\t       unsigned int *len,\n\t\t\t       u32           sgmax)\n{\n\tunsigned int sg_len = 0;\n\tstruct nx_sg *sg;\n\tu64 sg_addr = (u64)start_addr;\n\tu64 end_addr;\n\n\t \n\tif (is_vmalloc_addr(start_addr))\n\t\tsg_addr = page_to_phys(vmalloc_to_page(start_addr))\n\t\t\t  + offset_in_page(sg_addr);\n\telse\n\t\tsg_addr = __pa(sg_addr);\n\n\tend_addr = sg_addr + *len;\n\n\t \n\tfor (sg = sg_head; sg_len < *len; sg++) {\n\t\tu64 next_page;\n\n\t\tsg->addr = sg_addr;\n\t\tsg_addr = min_t(u64, NX_PAGE_NUM(sg_addr + NX_PAGE_SIZE),\n\t\t\t\tend_addr);\n\n\t\tnext_page = (sg->addr & PAGE_MASK) + PAGE_SIZE;\n\t\tsg->len = min_t(u64, sg_addr, next_page) - sg->addr;\n\t\tsg_len += sg->len;\n\n\t\tif (sg_addr >= next_page &&\n\t\t\t\tis_vmalloc_addr(start_addr + sg_len)) {\n\t\t\tsg_addr = page_to_phys(vmalloc_to_page(\n\t\t\t\t\t\tstart_addr + sg_len));\n\t\t\tend_addr = sg_addr + *len - sg_len;\n\t\t}\n\n\t\tif ((sg - sg_head) == sgmax) {\n\t\t\tpr_err(\"nx: scatter/gather list overflow, pid: %d\\n\",\n\t\t\t       current->pid);\n\t\t\tsg++;\n\t\t\tbreak;\n\t\t}\n\t}\n\t*len = sg_len;\n\n\t \n\treturn sg;\n}\n\n \nstruct nx_sg *nx_walk_and_build(struct nx_sg       *nx_dst,\n\t\t\t\tunsigned int        sglen,\n\t\t\t\tstruct scatterlist *sg_src,\n\t\t\t\tunsigned int        start,\n\t\t\t\tunsigned int       *src_len)\n{\n\tstruct scatter_walk walk;\n\tstruct nx_sg *nx_sg = nx_dst;\n\tunsigned int n, offset = 0, len = *src_len;\n\tchar *dst;\n\n\t \n\tfor (;;) {\n\t\tscatterwalk_start(&walk, sg_src);\n\n\t\tif (start < offset + sg_src->length)\n\t\t\tbreak;\n\n\t\toffset += sg_src->length;\n\t\tsg_src = sg_next(sg_src);\n\t}\n\n\t \n\tscatterwalk_advance(&walk, start - offset);\n\n\twhile (len && (nx_sg - nx_dst) < sglen) {\n\t\tn = scatterwalk_clamp(&walk, len);\n\t\tif (!n) {\n\t\t\t \n\t\t\tscatterwalk_start(&walk, sg_next(walk.sg));\n\t\t\tn = scatterwalk_clamp(&walk, len);\n\t\t}\n\t\tdst = scatterwalk_map(&walk);\n\n\t\tnx_sg = nx_build_sg_list(nx_sg, dst, &n, sglen - (nx_sg - nx_dst));\n\t\tlen -= n;\n\n\t\tscatterwalk_unmap(dst);\n\t\tscatterwalk_advance(&walk, n);\n\t\tscatterwalk_done(&walk, SCATTERWALK_FROM_SG, len);\n\t}\n\t \n\t*src_len -= len;\n\n\t \n\treturn nx_sg;\n}\n\n \nstatic long int trim_sg_list(struct nx_sg *sg,\n\t\t\t     struct nx_sg *end,\n\t\t\t     unsigned int delta,\n\t\t\t     unsigned int *nbytes)\n{\n\tlong int oplen;\n\tlong int data_back;\n\tunsigned int is_delta = delta;\n\n\twhile (delta && end > sg) {\n\t\tstruct nx_sg *last = end - 1;\n\n\t\tif (last->len > delta) {\n\t\t\tlast->len -= delta;\n\t\t\tdelta = 0;\n\t\t} else {\n\t\t\tend--;\n\t\t\tdelta -= last->len;\n\t\t}\n\t}\n\n\t \n\toplen = (sg - end) * sizeof(struct nx_sg);\n\tif (is_delta) {\n\t\tdata_back = (abs(oplen) / AES_BLOCK_SIZE) *  sg->len;\n\t\tdata_back = *nbytes - (data_back & ~(AES_BLOCK_SIZE - 1));\n\t\t*nbytes -= data_back;\n\t}\n\n\treturn oplen;\n}\n\n \nint nx_build_sg_lists(struct nx_crypto_ctx  *nx_ctx,\n\t\t      const u8              *iv,\n\t\t      struct scatterlist    *dst,\n\t\t      struct scatterlist    *src,\n\t\t      unsigned int          *nbytes,\n\t\t      unsigned int           offset,\n\t\t      u8                    *oiv)\n{\n\tunsigned int delta = 0;\n\tunsigned int total = *nbytes;\n\tstruct nx_sg *nx_insg = nx_ctx->in_sg;\n\tstruct nx_sg *nx_outsg = nx_ctx->out_sg;\n\tunsigned int max_sg_len;\n\n\tmax_sg_len = min_t(u64, nx_ctx->ap->sglen,\n\t\t\tnx_driver.of.max_sg_len/sizeof(struct nx_sg));\n\tmax_sg_len = min_t(u64, max_sg_len,\n\t\t\tnx_ctx->ap->databytelen/NX_PAGE_SIZE);\n\n\tif (oiv)\n\t\tmemcpy(oiv, iv, AES_BLOCK_SIZE);\n\n\t*nbytes = min_t(u64, *nbytes, nx_ctx->ap->databytelen);\n\n\tnx_outsg = nx_walk_and_build(nx_outsg, max_sg_len, dst,\n\t\t\t\t\toffset, nbytes);\n\tnx_insg = nx_walk_and_build(nx_insg, max_sg_len, src,\n\t\t\t\t\toffset, nbytes);\n\n\tif (*nbytes < total)\n\t\tdelta = *nbytes - (*nbytes & ~(AES_BLOCK_SIZE - 1));\n\n\t \n\tnx_ctx->op.inlen = trim_sg_list(nx_ctx->in_sg, nx_insg, delta, nbytes);\n\tnx_ctx->op.outlen = trim_sg_list(nx_ctx->out_sg, nx_outsg, delta, nbytes);\n\n\treturn 0;\n}\n\n \nvoid nx_ctx_init(struct nx_crypto_ctx *nx_ctx, unsigned int function)\n{\n\tspin_lock_init(&nx_ctx->lock);\n\tmemset(nx_ctx->kmem, 0, nx_ctx->kmem_len);\n\tnx_ctx->csbcpb->csb.valid |= NX_CSB_VALID_BIT;\n\n\tnx_ctx->op.flags = function;\n\tnx_ctx->op.csbcpb = __pa(nx_ctx->csbcpb);\n\tnx_ctx->op.in = __pa(nx_ctx->in_sg);\n\tnx_ctx->op.out = __pa(nx_ctx->out_sg);\n\n\tif (nx_ctx->csbcpb_aead) {\n\t\tnx_ctx->csbcpb_aead->csb.valid |= NX_CSB_VALID_BIT;\n\n\t\tnx_ctx->op_aead.flags = function;\n\t\tnx_ctx->op_aead.csbcpb = __pa(nx_ctx->csbcpb_aead);\n\t\tnx_ctx->op_aead.in = __pa(nx_ctx->in_sg);\n\t\tnx_ctx->op_aead.out = __pa(nx_ctx->out_sg);\n\t}\n}\n\nstatic void nx_of_update_status(struct device   *dev,\n\t\t\t       struct property *p,\n\t\t\t       struct nx_of    *props)\n{\n\tif (!strncmp(p->value, \"okay\", p->length)) {\n\t\tprops->status = NX_WAITING;\n\t\tprops->flags |= NX_OF_FLAG_STATUS_SET;\n\t} else {\n\t\tdev_info(dev, \"%s: status '%s' is not 'okay'\\n\", __func__,\n\t\t\t (char *)p->value);\n\t}\n}\n\nstatic void nx_of_update_sglen(struct device   *dev,\n\t\t\t       struct property *p,\n\t\t\t       struct nx_of    *props)\n{\n\tif (p->length != sizeof(props->max_sg_len)) {\n\t\tdev_err(dev, \"%s: unexpected format for \"\n\t\t\t\"ibm,max-sg-len property\\n\", __func__);\n\t\tdev_dbg(dev, \"%s: ibm,max-sg-len is %d bytes \"\n\t\t\t\"long, expected %zd bytes\\n\", __func__,\n\t\t\tp->length, sizeof(props->max_sg_len));\n\t\treturn;\n\t}\n\n\tprops->max_sg_len = *(u32 *)p->value;\n\tprops->flags |= NX_OF_FLAG_MAXSGLEN_SET;\n}\n\nstatic void nx_of_update_msc(struct device   *dev,\n\t\t\t     struct property *p,\n\t\t\t     struct nx_of    *props)\n{\n\tstruct msc_triplet *trip;\n\tstruct max_sync_cop *msc;\n\tunsigned int bytes_so_far, i, lenp;\n\n\tmsc = (struct max_sync_cop *)p->value;\n\tlenp = p->length;\n\n\t \n\tbytes_so_far = 0;\n\n\twhile ((bytes_so_far + sizeof(struct max_sync_cop)) <= lenp) {\n\t\tbytes_so_far += sizeof(struct max_sync_cop);\n\n\t\ttrip = msc->trip;\n\n\t\tfor (i = 0;\n\t\t     ((bytes_so_far + sizeof(struct msc_triplet)) <= lenp) &&\n\t\t     i < msc->triplets;\n\t\t     i++) {\n\t\t\tif (msc->fc >= NX_MAX_FC || msc->mode >= NX_MAX_MODE) {\n\t\t\t\tdev_err(dev, \"unknown function code/mode \"\n\t\t\t\t\t\"combo: %d/%d (ignored)\\n\", msc->fc,\n\t\t\t\t\tmsc->mode);\n\t\t\t\tgoto next_loop;\n\t\t\t}\n\n\t\t\tif (!trip->sglen || trip->databytelen < NX_PAGE_SIZE) {\n\t\t\t\tdev_warn(dev, \"bogus sglen/databytelen: \"\n\t\t\t\t\t \"%u/%u (ignored)\\n\", trip->sglen,\n\t\t\t\t\t trip->databytelen);\n\t\t\t\tgoto next_loop;\n\t\t\t}\n\n\t\t\tswitch (trip->keybitlen) {\n\t\t\tcase 128:\n\t\t\tcase 160:\n\t\t\t\tprops->ap[msc->fc][msc->mode][0].databytelen =\n\t\t\t\t\ttrip->databytelen;\n\t\t\t\tprops->ap[msc->fc][msc->mode][0].sglen =\n\t\t\t\t\ttrip->sglen;\n\t\t\t\tbreak;\n\t\t\tcase 192:\n\t\t\t\tprops->ap[msc->fc][msc->mode][1].databytelen =\n\t\t\t\t\ttrip->databytelen;\n\t\t\t\tprops->ap[msc->fc][msc->mode][1].sglen =\n\t\t\t\t\ttrip->sglen;\n\t\t\t\tbreak;\n\t\t\tcase 256:\n\t\t\t\tif (msc->fc == NX_FC_AES) {\n\t\t\t\t\tprops->ap[msc->fc][msc->mode][2].\n\t\t\t\t\t\tdatabytelen = trip->databytelen;\n\t\t\t\t\tprops->ap[msc->fc][msc->mode][2].sglen =\n\t\t\t\t\t\ttrip->sglen;\n\t\t\t\t} else if (msc->fc == NX_FC_AES_HMAC ||\n\t\t\t\t\t   msc->fc == NX_FC_SHA) {\n\t\t\t\t\tprops->ap[msc->fc][msc->mode][1].\n\t\t\t\t\t\tdatabytelen = trip->databytelen;\n\t\t\t\t\tprops->ap[msc->fc][msc->mode][1].sglen =\n\t\t\t\t\t\ttrip->sglen;\n\t\t\t\t} else {\n\t\t\t\t\tdev_warn(dev, \"unknown function \"\n\t\t\t\t\t\t\"code/key bit len combo\"\n\t\t\t\t\t\t\": (%u/256)\\n\", msc->fc);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 512:\n\t\t\t\tprops->ap[msc->fc][msc->mode][2].databytelen =\n\t\t\t\t\ttrip->databytelen;\n\t\t\t\tprops->ap[msc->fc][msc->mode][2].sglen =\n\t\t\t\t\ttrip->sglen;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tdev_warn(dev, \"unknown function code/key bit \"\n\t\t\t\t\t \"len combo: (%u/%u)\\n\", msc->fc,\n\t\t\t\t\t trip->keybitlen);\n\t\t\t\tbreak;\n\t\t\t}\nnext_loop:\n\t\t\tbytes_so_far += sizeof(struct msc_triplet);\n\t\t\ttrip++;\n\t\t}\n\n\t\tmsc = (struct max_sync_cop *)trip;\n\t}\n\n\tprops->flags |= NX_OF_FLAG_MAXSYNCCOP_SET;\n}\n\n \nstatic void nx_of_init(struct device *dev, struct nx_of *props)\n{\n\tstruct device_node *base_node = dev->of_node;\n\tstruct property *p;\n\n\tp = of_find_property(base_node, \"status\", NULL);\n\tif (!p)\n\t\tdev_info(dev, \"%s: property 'status' not found\\n\", __func__);\n\telse\n\t\tnx_of_update_status(dev, p, props);\n\n\tp = of_find_property(base_node, \"ibm,max-sg-len\", NULL);\n\tif (!p)\n\t\tdev_info(dev, \"%s: property 'ibm,max-sg-len' not found\\n\",\n\t\t\t __func__);\n\telse\n\t\tnx_of_update_sglen(dev, p, props);\n\n\tp = of_find_property(base_node, \"ibm,max-sync-cop\", NULL);\n\tif (!p)\n\t\tdev_info(dev, \"%s: property 'ibm,max-sync-cop' not found\\n\",\n\t\t\t __func__);\n\telse\n\t\tnx_of_update_msc(dev, p, props);\n}\n\nstatic bool nx_check_prop(struct device *dev, u32 fc, u32 mode, int slot)\n{\n\tstruct alg_props *props = &nx_driver.of.ap[fc][mode][slot];\n\n\tif (!props->sglen || props->databytelen < NX_PAGE_SIZE) {\n\t\tif (dev)\n\t\t\tdev_warn(dev, \"bogus sglen/databytelen for %u/%u/%u: \"\n\t\t\t\t \"%u/%u (ignored)\\n\", fc, mode, slot,\n\t\t\t\t props->sglen, props->databytelen);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool nx_check_props(struct device *dev, u32 fc, u32 mode)\n{\n\tint i;\n\n\tfor (i = 0; i < 3; i++)\n\t\tif (!nx_check_prop(dev, fc, mode, i))\n\t\t\treturn false;\n\n\treturn true;\n}\n\nstatic int nx_register_skcipher(struct skcipher_alg *alg, u32 fc, u32 mode)\n{\n\treturn nx_check_props(&nx_driver.viodev->dev, fc, mode) ?\n\t       crypto_register_skcipher(alg) : 0;\n}\n\nstatic int nx_register_aead(struct aead_alg *alg, u32 fc, u32 mode)\n{\n\treturn nx_check_props(&nx_driver.viodev->dev, fc, mode) ?\n\t       crypto_register_aead(alg) : 0;\n}\n\nstatic int nx_register_shash(struct shash_alg *alg, u32 fc, u32 mode, int slot)\n{\n\treturn (slot >= 0 ? nx_check_prop(&nx_driver.viodev->dev,\n\t\t\t\t\t  fc, mode, slot) :\n\t\t\t    nx_check_props(&nx_driver.viodev->dev, fc, mode)) ?\n\t       crypto_register_shash(alg) : 0;\n}\n\nstatic void nx_unregister_skcipher(struct skcipher_alg *alg, u32 fc, u32 mode)\n{\n\tif (nx_check_props(NULL, fc, mode))\n\t\tcrypto_unregister_skcipher(alg);\n}\n\nstatic void nx_unregister_aead(struct aead_alg *alg, u32 fc, u32 mode)\n{\n\tif (nx_check_props(NULL, fc, mode))\n\t\tcrypto_unregister_aead(alg);\n}\n\nstatic void nx_unregister_shash(struct shash_alg *alg, u32 fc, u32 mode,\n\t\t\t\tint slot)\n{\n\tif (slot >= 0 ? nx_check_prop(NULL, fc, mode, slot) :\n\t\t\tnx_check_props(NULL, fc, mode))\n\t\tcrypto_unregister_shash(alg);\n}\n\n \nstatic int nx_register_algs(void)\n{\n\tint rc = -1;\n\n\tif (nx_driver.of.flags != NX_OF_FLAG_MASK_READY)\n\t\tgoto out;\n\n\tmemset(&nx_driver.stats, 0, sizeof(struct nx_stats));\n\n\tNX_DEBUGFS_INIT(&nx_driver);\n\n\tnx_driver.of.status = NX_OKAY;\n\n\trc = nx_register_skcipher(&nx_ecb_aes_alg, NX_FC_AES, NX_MODE_AES_ECB);\n\tif (rc)\n\t\tgoto out;\n\n\trc = nx_register_skcipher(&nx_cbc_aes_alg, NX_FC_AES, NX_MODE_AES_CBC);\n\tif (rc)\n\t\tgoto out_unreg_ecb;\n\n\trc = nx_register_skcipher(&nx_ctr3686_aes_alg, NX_FC_AES,\n\t\t\t\t  NX_MODE_AES_CTR);\n\tif (rc)\n\t\tgoto out_unreg_cbc;\n\n\trc = nx_register_aead(&nx_gcm_aes_alg, NX_FC_AES, NX_MODE_AES_GCM);\n\tif (rc)\n\t\tgoto out_unreg_ctr3686;\n\n\trc = nx_register_aead(&nx_gcm4106_aes_alg, NX_FC_AES, NX_MODE_AES_GCM);\n\tif (rc)\n\t\tgoto out_unreg_gcm;\n\n\trc = nx_register_aead(&nx_ccm_aes_alg, NX_FC_AES, NX_MODE_AES_CCM);\n\tif (rc)\n\t\tgoto out_unreg_gcm4106;\n\n\trc = nx_register_aead(&nx_ccm4309_aes_alg, NX_FC_AES, NX_MODE_AES_CCM);\n\tif (rc)\n\t\tgoto out_unreg_ccm;\n\n\trc = nx_register_shash(&nx_shash_sha256_alg, NX_FC_SHA, NX_MODE_SHA,\n\t\t\t       NX_PROPS_SHA256);\n\tif (rc)\n\t\tgoto out_unreg_ccm4309;\n\n\trc = nx_register_shash(&nx_shash_sha512_alg, NX_FC_SHA, NX_MODE_SHA,\n\t\t\t       NX_PROPS_SHA512);\n\tif (rc)\n\t\tgoto out_unreg_s256;\n\n\trc = nx_register_shash(&nx_shash_aes_xcbc_alg,\n\t\t\t       NX_FC_AES, NX_MODE_AES_XCBC_MAC, -1);\n\tif (rc)\n\t\tgoto out_unreg_s512;\n\n\tgoto out;\n\nout_unreg_s512:\n\tnx_unregister_shash(&nx_shash_sha512_alg, NX_FC_SHA, NX_MODE_SHA,\n\t\t\t    NX_PROPS_SHA512);\nout_unreg_s256:\n\tnx_unregister_shash(&nx_shash_sha256_alg, NX_FC_SHA, NX_MODE_SHA,\n\t\t\t    NX_PROPS_SHA256);\nout_unreg_ccm4309:\n\tnx_unregister_aead(&nx_ccm4309_aes_alg, NX_FC_AES, NX_MODE_AES_CCM);\nout_unreg_ccm:\n\tnx_unregister_aead(&nx_ccm_aes_alg, NX_FC_AES, NX_MODE_AES_CCM);\nout_unreg_gcm4106:\n\tnx_unregister_aead(&nx_gcm4106_aes_alg, NX_FC_AES, NX_MODE_AES_GCM);\nout_unreg_gcm:\n\tnx_unregister_aead(&nx_gcm_aes_alg, NX_FC_AES, NX_MODE_AES_GCM);\nout_unreg_ctr3686:\n\tnx_unregister_skcipher(&nx_ctr3686_aes_alg, NX_FC_AES, NX_MODE_AES_CTR);\nout_unreg_cbc:\n\tnx_unregister_skcipher(&nx_cbc_aes_alg, NX_FC_AES, NX_MODE_AES_CBC);\nout_unreg_ecb:\n\tnx_unregister_skcipher(&nx_ecb_aes_alg, NX_FC_AES, NX_MODE_AES_ECB);\nout:\n\treturn rc;\n}\n\n \nstatic int nx_crypto_ctx_init(struct nx_crypto_ctx *nx_ctx, u32 fc, u32 mode)\n{\n\tif (nx_driver.of.status != NX_OKAY) {\n\t\tpr_err(\"Attempt to initialize NX crypto context while device \"\n\t\t       \"is not available!\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tif (mode == NX_MODE_AES_GCM || mode == NX_MODE_AES_CCM)\n\t\tnx_ctx->kmem_len = (5 * NX_PAGE_SIZE) +\n\t\t\t\t   sizeof(struct nx_csbcpb);\n\telse\n\t\tnx_ctx->kmem_len = (4 * NX_PAGE_SIZE) +\n\t\t\t\t   sizeof(struct nx_csbcpb);\n\n\tnx_ctx->kmem = kmalloc(nx_ctx->kmem_len, GFP_KERNEL);\n\tif (!nx_ctx->kmem)\n\t\treturn -ENOMEM;\n\n\t \n\tnx_ctx->csbcpb = (struct nx_csbcpb *)(round_up((u64)nx_ctx->kmem,\n\t\t\t\t\t\t       (u64)NX_PAGE_SIZE));\n\tnx_ctx->in_sg = (struct nx_sg *)((u8 *)nx_ctx->csbcpb + NX_PAGE_SIZE);\n\tnx_ctx->out_sg = (struct nx_sg *)((u8 *)nx_ctx->in_sg + NX_PAGE_SIZE);\n\n\tif (mode == NX_MODE_AES_GCM || mode == NX_MODE_AES_CCM)\n\t\tnx_ctx->csbcpb_aead =\n\t\t\t(struct nx_csbcpb *)((u8 *)nx_ctx->out_sg +\n\t\t\t\t\t     NX_PAGE_SIZE);\n\n\t \n\tnx_ctx->stats = &nx_driver.stats;\n\tmemcpy(nx_ctx->props, nx_driver.of.ap[fc][mode],\n\t       sizeof(struct alg_props) * 3);\n\n\treturn 0;\n}\n\n \nint nx_crypto_ctx_aes_ccm_init(struct crypto_aead *tfm)\n{\n\tcrypto_aead_set_reqsize(tfm, sizeof(struct nx_ccm_rctx));\n\treturn nx_crypto_ctx_init(crypto_aead_ctx(tfm), NX_FC_AES,\n\t\t\t\t  NX_MODE_AES_CCM);\n}\n\nint nx_crypto_ctx_aes_gcm_init(struct crypto_aead *tfm)\n{\n\tcrypto_aead_set_reqsize(tfm, sizeof(struct nx_gcm_rctx));\n\treturn nx_crypto_ctx_init(crypto_aead_ctx(tfm), NX_FC_AES,\n\t\t\t\t  NX_MODE_AES_GCM);\n}\n\nint nx_crypto_ctx_aes_ctr_init(struct crypto_skcipher *tfm)\n{\n\treturn nx_crypto_ctx_init(crypto_skcipher_ctx(tfm), NX_FC_AES,\n\t\t\t\t  NX_MODE_AES_CTR);\n}\n\nint nx_crypto_ctx_aes_cbc_init(struct crypto_skcipher *tfm)\n{\n\treturn nx_crypto_ctx_init(crypto_skcipher_ctx(tfm), NX_FC_AES,\n\t\t\t\t  NX_MODE_AES_CBC);\n}\n\nint nx_crypto_ctx_aes_ecb_init(struct crypto_skcipher *tfm)\n{\n\treturn nx_crypto_ctx_init(crypto_skcipher_ctx(tfm), NX_FC_AES,\n\t\t\t\t  NX_MODE_AES_ECB);\n}\n\nint nx_crypto_ctx_sha_init(struct crypto_tfm *tfm)\n{\n\treturn nx_crypto_ctx_init(crypto_tfm_ctx(tfm), NX_FC_SHA, NX_MODE_SHA);\n}\n\nint nx_crypto_ctx_aes_xcbc_init(struct crypto_tfm *tfm)\n{\n\treturn nx_crypto_ctx_init(crypto_tfm_ctx(tfm), NX_FC_AES,\n\t\t\t\t  NX_MODE_AES_XCBC_MAC);\n}\n\n \nvoid nx_crypto_ctx_exit(struct crypto_tfm *tfm)\n{\n\tstruct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(tfm);\n\n\tkfree_sensitive(nx_ctx->kmem);\n\tnx_ctx->csbcpb = NULL;\n\tnx_ctx->csbcpb_aead = NULL;\n\tnx_ctx->in_sg = NULL;\n\tnx_ctx->out_sg = NULL;\n}\n\nvoid nx_crypto_ctx_skcipher_exit(struct crypto_skcipher *tfm)\n{\n\tnx_crypto_ctx_exit(crypto_skcipher_ctx(tfm));\n}\n\nvoid nx_crypto_ctx_aead_exit(struct crypto_aead *tfm)\n{\n\tstruct nx_crypto_ctx *nx_ctx = crypto_aead_ctx(tfm);\n\n\tkfree_sensitive(nx_ctx->kmem);\n}\n\nstatic int nx_probe(struct vio_dev *viodev, const struct vio_device_id *id)\n{\n\tdev_dbg(&viodev->dev, \"driver probed: %s resource id: 0x%x\\n\",\n\t\tviodev->name, viodev->resource_id);\n\n\tif (nx_driver.viodev) {\n\t\tdev_err(&viodev->dev, \"%s: Attempt to register more than one \"\n\t\t\t\"instance of the hardware\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tnx_driver.viodev = viodev;\n\n\tnx_of_init(&viodev->dev, &nx_driver.of);\n\n\treturn nx_register_algs();\n}\n\nstatic void nx_remove(struct vio_dev *viodev)\n{\n\tdev_dbg(&viodev->dev, \"entering nx_remove for UA 0x%x\\n\",\n\t\tviodev->unit_address);\n\n\tif (nx_driver.of.status == NX_OKAY) {\n\t\tNX_DEBUGFS_FINI(&nx_driver);\n\n\t\tnx_unregister_shash(&nx_shash_aes_xcbc_alg,\n\t\t\t\t    NX_FC_AES, NX_MODE_AES_XCBC_MAC, -1);\n\t\tnx_unregister_shash(&nx_shash_sha512_alg,\n\t\t\t\t    NX_FC_SHA, NX_MODE_SHA, NX_PROPS_SHA256);\n\t\tnx_unregister_shash(&nx_shash_sha256_alg,\n\t\t\t\t    NX_FC_SHA, NX_MODE_SHA, NX_PROPS_SHA512);\n\t\tnx_unregister_aead(&nx_ccm4309_aes_alg,\n\t\t\t\t   NX_FC_AES, NX_MODE_AES_CCM);\n\t\tnx_unregister_aead(&nx_ccm_aes_alg, NX_FC_AES, NX_MODE_AES_CCM);\n\t\tnx_unregister_aead(&nx_gcm4106_aes_alg,\n\t\t\t\t   NX_FC_AES, NX_MODE_AES_GCM);\n\t\tnx_unregister_aead(&nx_gcm_aes_alg,\n\t\t\t\t   NX_FC_AES, NX_MODE_AES_GCM);\n\t\tnx_unregister_skcipher(&nx_ctr3686_aes_alg,\n\t\t\t\t       NX_FC_AES, NX_MODE_AES_CTR);\n\t\tnx_unregister_skcipher(&nx_cbc_aes_alg, NX_FC_AES,\n\t\t\t\t       NX_MODE_AES_CBC);\n\t\tnx_unregister_skcipher(&nx_ecb_aes_alg, NX_FC_AES,\n\t\t\t\t       NX_MODE_AES_ECB);\n\t}\n}\n\n\n \nstatic int __init nx_init(void)\n{\n\treturn vio_register_driver(&nx_driver.viodriver);\n}\n\nstatic void __exit nx_fini(void)\n{\n\tvio_unregister_driver(&nx_driver.viodriver);\n}\n\nstatic const struct vio_device_id nx_crypto_driver_ids[] = {\n\t{ \"ibm,sym-encryption-v1\", \"ibm,sym-encryption\" },\n\t{ \"\", \"\" }\n};\nMODULE_DEVICE_TABLE(vio, nx_crypto_driver_ids);\n\n \nstruct nx_crypto_driver nx_driver = {\n\t.viodriver = {\n\t\t.id_table = nx_crypto_driver_ids,\n\t\t.probe = nx_probe,\n\t\t.remove = nx_remove,\n\t\t.name  = NX_NAME,\n\t},\n};\n\nmodule_init(nx_init);\nmodule_exit(nx_fini);\n\nMODULE_AUTHOR(\"Kent Yoder <yoder1@us.ibm.com>\");\nMODULE_DESCRIPTION(NX_STRING);\nMODULE_LICENSE(\"GPL\");\nMODULE_VERSION(NX_VERSION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}