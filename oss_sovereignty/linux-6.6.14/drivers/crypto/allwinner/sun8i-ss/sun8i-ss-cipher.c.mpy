{
  "module_name": "sun8i-ss-cipher.c",
  "hash_id": "612e60de0931eb45a82746e320cfd06a1eeb0c2cee5af1ab6aebebd7902562f9",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c",
  "human_readable_source": "\n \n\n#include <linux/bottom_half.h>\n#include <linux/crypto.h>\n#include <linux/dma-mapping.h>\n#include <linux/io.h>\n#include <linux/pm_runtime.h>\n#include <crypto/scatterwalk.h>\n#include <crypto/internal/skcipher.h>\n#include \"sun8i-ss.h\"\n\nstatic bool sun8i_ss_need_fallback(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(tfm);\n\tstruct sun8i_ss_alg_template *algt = container_of(alg, struct sun8i_ss_alg_template, alg.skcipher.base);\n\tstruct scatterlist *in_sg = areq->src;\n\tstruct scatterlist *out_sg = areq->dst;\n\tstruct scatterlist *sg;\n\tunsigned int todo, len;\n\n\tif (areq->cryptlen == 0 || areq->cryptlen % 16) {\n\t\talgt->stat_fb_len++;\n\t\treturn true;\n\t}\n\n\tif (sg_nents_for_len(areq->src, areq->cryptlen) > 8 ||\n\t\tsg_nents_for_len(areq->dst, areq->cryptlen) > 8) {\n\t\talgt->stat_fb_sgnum++;\n\t\treturn true;\n\t}\n\n\tlen = areq->cryptlen;\n\tsg = areq->src;\n\twhile (sg) {\n\t\ttodo = min(len, sg->length);\n\t\tif ((todo % 16) != 0) {\n\t\t\talgt->stat_fb_sglen++;\n\t\t\treturn true;\n\t\t}\n\t\tif (!IS_ALIGNED(sg->offset, 16)) {\n\t\t\talgt->stat_fb_align++;\n\t\t\treturn true;\n\t\t}\n\t\tlen -= todo;\n\t\tsg = sg_next(sg);\n\t}\n\tlen = areq->cryptlen;\n\tsg = areq->dst;\n\twhile (sg) {\n\t\ttodo = min(len, sg->length);\n\t\tif ((todo % 16) != 0) {\n\t\t\talgt->stat_fb_sglen++;\n\t\t\treturn true;\n\t\t}\n\t\tif (!IS_ALIGNED(sg->offset, 16)) {\n\t\t\talgt->stat_fb_align++;\n\t\t\treturn true;\n\t\t}\n\t\tlen -= todo;\n\t\tsg = sg_next(sg);\n\t}\n\n\t \n\tin_sg = areq->src;\n\tout_sg = areq->dst;\n\twhile (in_sg && out_sg) {\n\t\tif (in_sg->length != out_sg->length)\n\t\t\treturn true;\n\t\tin_sg = sg_next(in_sg);\n\t\tout_sg = sg_next(out_sg);\n\t}\n\tif (in_sg || out_sg)\n\t\treturn true;\n\treturn false;\n}\n\nstatic int sun8i_ss_cipher_fallback(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sun8i_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tint err;\n\n\tif (IS_ENABLED(CONFIG_CRYPTO_DEV_SUN8I_SS_DEBUG)) {\n\t\tstruct skcipher_alg *alg = crypto_skcipher_alg(tfm);\n\t\tstruct sun8i_ss_alg_template *algt __maybe_unused;\n\n\t\talgt = container_of(alg, struct sun8i_ss_alg_template,\n\t\t\t\t    alg.skcipher.base);\n\n#ifdef CONFIG_CRYPTO_DEV_SUN8I_SS_DEBUG\n\t\talgt->stat_fb++;\n#endif\n\t}\n\n\tskcipher_request_set_tfm(&rctx->fallback_req, op->fallback_tfm);\n\tskcipher_request_set_callback(&rctx->fallback_req, areq->base.flags,\n\t\t\t\t      areq->base.complete, areq->base.data);\n\tskcipher_request_set_crypt(&rctx->fallback_req, areq->src, areq->dst,\n\t\t\t\t   areq->cryptlen, areq->iv);\n\tif (rctx->op_dir & SS_DECRYPTION)\n\t\terr = crypto_skcipher_decrypt(&rctx->fallback_req);\n\telse\n\t\terr = crypto_skcipher_encrypt(&rctx->fallback_req);\n\treturn err;\n}\n\nstatic int sun8i_ss_setup_ivs(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sun8i_ss_dev *ss = op->ss;\n\tstruct sun8i_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct scatterlist *sg = areq->src;\n\tunsigned int todo, offset;\n\tunsigned int len = areq->cryptlen;\n\tunsigned int ivsize = crypto_skcipher_ivsize(tfm);\n\tstruct sun8i_ss_flow *sf = &ss->flows[rctx->flow];\n\tint i = 0;\n\tdma_addr_t a;\n\tint err;\n\n\trctx->ivlen = ivsize;\n\tif (rctx->op_dir & SS_DECRYPTION) {\n\t\toffset = areq->cryptlen - ivsize;\n\t\tscatterwalk_map_and_copy(sf->biv, areq->src, offset,\n\t\t\t\t\t ivsize, 0);\n\t}\n\n\t \n\twhile (sg && len) {\n\t\tif (sg_dma_len(sg) == 0) {\n\t\t\tsg = sg_next(sg);\n\t\t\tcontinue;\n\t\t}\n\t\tif (i == 0)\n\t\t\tmemcpy(sf->iv[0], areq->iv, ivsize);\n\t\ta = dma_map_single(ss->dev, sf->iv[i], ivsize, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(ss->dev, a)) {\n\t\t\tmemzero_explicit(sf->iv[i], ivsize);\n\t\t\tdev_err(ss->dev, \"Cannot DMA MAP IV\\n\");\n\t\t\terr = -EFAULT;\n\t\t\tgoto dma_iv_error;\n\t\t}\n\t\trctx->p_iv[i] = a;\n\t\t \n\t\tif (rctx->op_dir == SS_ENCRYPTION)\n\t\t\treturn 0;\n\t\ttodo = min(len, sg_dma_len(sg));\n\t\tlen -= todo;\n\t\ti++;\n\t\tif (i < MAX_SG) {\n\t\t\toffset = sg->length - ivsize;\n\t\t\tscatterwalk_map_and_copy(sf->iv[i], sg, offset, ivsize, 0);\n\t\t}\n\t\trctx->niv = i;\n\t\tsg = sg_next(sg);\n\t}\n\n\treturn 0;\ndma_iv_error:\n\ti--;\n\twhile (i >= 0) {\n\t\tdma_unmap_single(ss->dev, rctx->p_iv[i], ivsize, DMA_TO_DEVICE);\n\t\tmemzero_explicit(sf->iv[i], ivsize);\n\t\ti--;\n\t}\n\treturn err;\n}\n\nstatic int sun8i_ss_cipher(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sun8i_ss_dev *ss = op->ss;\n\tstruct sun8i_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(tfm);\n\tstruct sun8i_ss_alg_template *algt;\n\tstruct sun8i_ss_flow *sf = &ss->flows[rctx->flow];\n\tstruct scatterlist *sg;\n\tunsigned int todo, len, offset, ivsize;\n\tint nr_sgs = 0;\n\tint nr_sgd = 0;\n\tint err = 0;\n\tint nsgs = sg_nents_for_len(areq->src, areq->cryptlen);\n\tint nsgd = sg_nents_for_len(areq->dst, areq->cryptlen);\n\tint i;\n\n\talgt = container_of(alg, struct sun8i_ss_alg_template, alg.skcipher.base);\n\n\tdev_dbg(ss->dev, \"%s %s %u %x IV(%p %u) key=%u\\n\", __func__,\n\t\tcrypto_tfm_alg_name(areq->base.tfm),\n\t\tareq->cryptlen,\n\t\trctx->op_dir, areq->iv, crypto_skcipher_ivsize(tfm),\n\t\top->keylen);\n\n#ifdef CONFIG_CRYPTO_DEV_SUN8I_SS_DEBUG\n\talgt->stat_req++;\n#endif\n\n\trctx->op_mode = ss->variant->op_mode[algt->ss_blockmode];\n\trctx->method = ss->variant->alg_cipher[algt->ss_algo_id];\n\trctx->keylen = op->keylen;\n\n\trctx->p_key = dma_map_single(ss->dev, op->key, op->keylen, DMA_TO_DEVICE);\n\tif (dma_mapping_error(ss->dev, rctx->p_key)) {\n\t\tdev_err(ss->dev, \"Cannot DMA MAP KEY\\n\");\n\t\terr = -EFAULT;\n\t\tgoto theend;\n\t}\n\n\tivsize = crypto_skcipher_ivsize(tfm);\n\tif (areq->iv && crypto_skcipher_ivsize(tfm) > 0) {\n\t\terr = sun8i_ss_setup_ivs(areq);\n\t\tif (err)\n\t\t\tgoto theend_key;\n\t}\n\tif (areq->src == areq->dst) {\n\t\tnr_sgs = dma_map_sg(ss->dev, areq->src, nsgs, DMA_BIDIRECTIONAL);\n\t\tif (nr_sgs <= 0 || nr_sgs > 8) {\n\t\t\tdev_err(ss->dev, \"Invalid sg number %d\\n\", nr_sgs);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend_iv;\n\t\t}\n\t\tnr_sgd = nr_sgs;\n\t} else {\n\t\tnr_sgs = dma_map_sg(ss->dev, areq->src, nsgs, DMA_TO_DEVICE);\n\t\tif (nr_sgs <= 0 || nr_sgs > 8) {\n\t\t\tdev_err(ss->dev, \"Invalid sg number %d\\n\", nr_sgs);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend_iv;\n\t\t}\n\t\tnr_sgd = dma_map_sg(ss->dev, areq->dst, nsgd, DMA_FROM_DEVICE);\n\t\tif (nr_sgd <= 0 || nr_sgd > 8) {\n\t\t\tdev_err(ss->dev, \"Invalid sg number %d\\n\", nr_sgd);\n\t\t\terr = -EINVAL;\n\t\t\tgoto theend_sgs;\n\t\t}\n\t}\n\n\tlen = areq->cryptlen;\n\ti = 0;\n\tsg = areq->src;\n\twhile (i < nr_sgs && sg && len) {\n\t\tif (sg_dma_len(sg) == 0)\n\t\t\tgoto sgs_next;\n\t\trctx->t_src[i].addr = sg_dma_address(sg);\n\t\ttodo = min(len, sg_dma_len(sg));\n\t\trctx->t_src[i].len = todo / 4;\n\t\tdev_dbg(ss->dev, \"%s total=%u SGS(%d %u off=%d) todo=%u\\n\", __func__,\n\t\t\tareq->cryptlen, i, rctx->t_src[i].len, sg->offset, todo);\n\t\tlen -= todo;\n\t\ti++;\nsgs_next:\n\t\tsg = sg_next(sg);\n\t}\n\tif (len > 0) {\n\t\tdev_err(ss->dev, \"remaining len %d\\n\", len);\n\t\terr = -EINVAL;\n\t\tgoto theend_sgs;\n\t}\n\n\tlen = areq->cryptlen;\n\ti = 0;\n\tsg = areq->dst;\n\twhile (i < nr_sgd && sg && len) {\n\t\tif (sg_dma_len(sg) == 0)\n\t\t\tgoto sgd_next;\n\t\trctx->t_dst[i].addr = sg_dma_address(sg);\n\t\ttodo = min(len, sg_dma_len(sg));\n\t\trctx->t_dst[i].len = todo / 4;\n\t\tdev_dbg(ss->dev, \"%s total=%u SGD(%d %u off=%d) todo=%u\\n\", __func__,\n\t\t\tareq->cryptlen, i, rctx->t_dst[i].len, sg->offset, todo);\n\t\tlen -= todo;\n\t\ti++;\nsgd_next:\n\t\tsg = sg_next(sg);\n\t}\n\tif (len > 0) {\n\t\tdev_err(ss->dev, \"remaining len %d\\n\", len);\n\t\terr = -EINVAL;\n\t\tgoto theend_sgs;\n\t}\n\n\terr = sun8i_ss_run_task(ss, rctx, crypto_tfm_alg_name(areq->base.tfm));\n\ntheend_sgs:\n\tif (areq->src == areq->dst) {\n\t\tdma_unmap_sg(ss->dev, areq->src, nsgs, DMA_BIDIRECTIONAL);\n\t} else {\n\t\tdma_unmap_sg(ss->dev, areq->src, nsgs, DMA_TO_DEVICE);\n\t\tdma_unmap_sg(ss->dev, areq->dst, nsgd, DMA_FROM_DEVICE);\n\t}\n\ntheend_iv:\n\tif (areq->iv && ivsize > 0) {\n\t\tfor (i = 0; i < rctx->niv; i++) {\n\t\t\tdma_unmap_single(ss->dev, rctx->p_iv[i], ivsize, DMA_TO_DEVICE);\n\t\t\tmemzero_explicit(sf->iv[i], ivsize);\n\t\t}\n\n\t\toffset = areq->cryptlen - ivsize;\n\t\tif (rctx->op_dir & SS_DECRYPTION) {\n\t\t\tmemcpy(areq->iv, sf->biv, ivsize);\n\t\t\tmemzero_explicit(sf->biv, ivsize);\n\t\t} else {\n\t\t\tscatterwalk_map_and_copy(areq->iv, areq->dst, offset,\n\t\t\t\t\tivsize, 0);\n\t\t}\n\t}\n\ntheend_key:\n\tdma_unmap_single(ss->dev, rctx->p_key, op->keylen, DMA_TO_DEVICE);\n\ntheend:\n\n\treturn err;\n}\n\nint sun8i_ss_handle_cipher_request(struct crypto_engine *engine, void *areq)\n{\n\tint err;\n\tstruct skcipher_request *breq = container_of(areq, struct skcipher_request, base);\n\n\terr = sun8i_ss_cipher(breq);\n\tlocal_bh_disable();\n\tcrypto_finalize_skcipher_request(engine, breq, err);\n\tlocal_bh_enable();\n\n\treturn 0;\n}\n\nint sun8i_ss_skdecrypt(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sun8i_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct crypto_engine *engine;\n\tint e;\n\n\tmemset(rctx, 0, sizeof(struct sun8i_cipher_req_ctx));\n\trctx->op_dir = SS_DECRYPTION;\n\n\tif (sun8i_ss_need_fallback(areq))\n\t\treturn sun8i_ss_cipher_fallback(areq);\n\n\te = sun8i_ss_get_engine_number(op->ss);\n\tengine = op->ss->flows[e].engine;\n\trctx->flow = e;\n\n\treturn crypto_transfer_skcipher_request_to_engine(engine, areq);\n}\n\nint sun8i_ss_skencrypt(struct skcipher_request *areq)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(areq);\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sun8i_cipher_req_ctx *rctx = skcipher_request_ctx(areq);\n\tstruct crypto_engine *engine;\n\tint e;\n\n\tmemset(rctx, 0, sizeof(struct sun8i_cipher_req_ctx));\n\trctx->op_dir = SS_ENCRYPTION;\n\n\tif (sun8i_ss_need_fallback(areq))\n\t\treturn sun8i_ss_cipher_fallback(areq);\n\n\te = sun8i_ss_get_engine_number(op->ss);\n\tengine = op->ss->flows[e].engine;\n\trctx->flow = e;\n\n\treturn crypto_transfer_skcipher_request_to_engine(engine, areq);\n}\n\nint sun8i_ss_cipher_init(struct crypto_tfm *tfm)\n{\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_tfm_ctx(tfm);\n\tstruct sun8i_ss_alg_template *algt;\n\tconst char *name = crypto_tfm_alg_name(tfm);\n\tstruct crypto_skcipher *sktfm = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(sktfm);\n\tint err;\n\n\tmemset(op, 0, sizeof(struct sun8i_cipher_tfm_ctx));\n\n\talgt = container_of(alg, struct sun8i_ss_alg_template, alg.skcipher.base);\n\top->ss = algt->ss;\n\n\top->fallback_tfm = crypto_alloc_skcipher(name, 0, CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(op->fallback_tfm)) {\n\t\tdev_err(op->ss->dev, \"ERROR: Cannot allocate fallback for %s %ld\\n\",\n\t\t\tname, PTR_ERR(op->fallback_tfm));\n\t\treturn PTR_ERR(op->fallback_tfm);\n\t}\n\n\tsktfm->reqsize = sizeof(struct sun8i_cipher_req_ctx) +\n\t\t\t crypto_skcipher_reqsize(op->fallback_tfm);\n\n\n\tmemcpy(algt->fbname,\n\t       crypto_tfm_alg_driver_name(crypto_skcipher_tfm(op->fallback_tfm)),\n\t       CRYPTO_MAX_ALG_NAME);\n\n\terr = pm_runtime_resume_and_get(op->ss->dev);\n\tif (err < 0) {\n\t\tdev_err(op->ss->dev, \"pm error %d\\n\", err);\n\t\tgoto error_pm;\n\t}\n\n\treturn 0;\nerror_pm:\n\tcrypto_free_skcipher(op->fallback_tfm);\n\treturn err;\n}\n\nvoid sun8i_ss_cipher_exit(struct crypto_tfm *tfm)\n{\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_tfm_ctx(tfm);\n\n\tkfree_sensitive(op->key);\n\tcrypto_free_skcipher(op->fallback_tfm);\n\tpm_runtime_put_sync(op->ss->dev);\n}\n\nint sun8i_ss_aes_setkey(struct crypto_skcipher *tfm, const u8 *key,\n\t\t\tunsigned int keylen)\n{\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sun8i_ss_dev *ss = op->ss;\n\n\tswitch (keylen) {\n\tcase 128 / 8:\n\t\tbreak;\n\tcase 192 / 8:\n\t\tbreak;\n\tcase 256 / 8:\n\t\tbreak;\n\tdefault:\n\t\tdev_dbg(ss->dev, \"ERROR: Invalid keylen %u\\n\", keylen);\n\t\treturn -EINVAL;\n\t}\n\tkfree_sensitive(op->key);\n\top->keylen = keylen;\n\top->key = kmemdup(key, keylen, GFP_KERNEL);\n\tif (!op->key)\n\t\treturn -ENOMEM;\n\n\tcrypto_skcipher_clear_flags(op->fallback_tfm, CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(op->fallback_tfm, tfm->base.crt_flags & CRYPTO_TFM_REQ_MASK);\n\n\treturn crypto_skcipher_setkey(op->fallback_tfm, key, keylen);\n}\n\nint sun8i_ss_des3_setkey(struct crypto_skcipher *tfm, const u8 *key,\n\t\t\t unsigned int keylen)\n{\n\tstruct sun8i_cipher_tfm_ctx *op = crypto_skcipher_ctx(tfm);\n\tstruct sun8i_ss_dev *ss = op->ss;\n\n\tif (unlikely(keylen != 3 * DES_KEY_SIZE)) {\n\t\tdev_dbg(ss->dev, \"Invalid keylen %u\\n\", keylen);\n\t\treturn -EINVAL;\n\t}\n\n\tkfree_sensitive(op->key);\n\top->keylen = keylen;\n\top->key = kmemdup(key, keylen, GFP_KERNEL);\n\tif (!op->key)\n\t\treturn -ENOMEM;\n\n\tcrypto_skcipher_clear_flags(op->fallback_tfm, CRYPTO_TFM_REQ_MASK);\n\tcrypto_skcipher_set_flags(op->fallback_tfm, tfm->base.crt_flags & CRYPTO_TFM_REQ_MASK);\n\n\treturn crypto_skcipher_setkey(op->fallback_tfm, key, keylen);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}