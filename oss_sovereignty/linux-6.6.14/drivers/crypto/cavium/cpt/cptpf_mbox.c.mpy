{
  "module_name": "cptpf_mbox.c",
  "hash_id": "74a875d4cb8a34e6b4a243a0b74103d93326a1b994314de58206b907d298884d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/cavium/cpt/cptpf_mbox.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include \"cptpf.h\"\n\nstatic void cpt_send_msg_to_vf(struct cpt_device *cpt, int vf,\n\t\t\t       struct cpt_mbox *mbx)\n{\n\t \n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_VFX_MBOXX(0, vf, 1),\n\t\t\tmbx->data);\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_VFX_MBOXX(0, vf, 0), mbx->msg);\n}\n\n \nstatic void cpt_mbox_send_ack(struct cpt_device *cpt, int vf,\n\t\t\t      struct cpt_mbox *mbx)\n{\n\tmbx->data = 0ull;\n\tmbx->msg = CPT_MBOX_MSG_TYPE_ACK;\n\tcpt_send_msg_to_vf(cpt, vf, mbx);\n}\n\nstatic void cpt_clear_mbox_intr(struct cpt_device *cpt, u32 vf)\n{\n\t \n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_MBOX_INTX(0, 0), (1 << vf));\n}\n\n \nstatic void cpt_cfg_qlen_for_vf(struct cpt_device *cpt, int vf, u32 size)\n{\n\tunion cptx_pf_qx_ctl pf_qx_ctl;\n\n\tpf_qx_ctl.u = cpt_read_csr64(cpt->reg_base, CPTX_PF_QX_CTL(0, vf));\n\tpf_qx_ctl.s.size = size;\n\tpf_qx_ctl.s.cont_err = true;\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_QX_CTL(0, vf), pf_qx_ctl.u);\n}\n\n \nstatic void cpt_cfg_vq_priority(struct cpt_device *cpt, int vf, u32 pri)\n{\n\tunion cptx_pf_qx_ctl pf_qx_ctl;\n\n\tpf_qx_ctl.u = cpt_read_csr64(cpt->reg_base, CPTX_PF_QX_CTL(0, vf));\n\tpf_qx_ctl.s.pri = pri;\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_QX_CTL(0, vf), pf_qx_ctl.u);\n}\n\nstatic int cpt_bind_vq_to_grp(struct cpt_device *cpt, u8 q, u8 grp)\n{\n\tstruct microcode *mcode = cpt->mcode;\n\tunion cptx_pf_qx_ctl pf_qx_ctl;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\tif (q >= CPT_MAX_VF_NUM) {\n\t\tdev_err(dev, \"Queues are more than cores in the group\");\n\t\treturn -EINVAL;\n\t}\n\tif (grp >= CPT_MAX_CORE_GROUPS) {\n\t\tdev_err(dev, \"Request group is more than possible groups\");\n\t\treturn -EINVAL;\n\t}\n\tif (grp >= cpt->next_mc_idx) {\n\t\tdev_err(dev, \"Request group is higher than available functional groups\");\n\t\treturn -EINVAL;\n\t}\n\tpf_qx_ctl.u = cpt_read_csr64(cpt->reg_base, CPTX_PF_QX_CTL(0, q));\n\tpf_qx_ctl.s.grp = mcode[grp].group;\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_QX_CTL(0, q), pf_qx_ctl.u);\n\tdev_dbg(dev, \"VF %d TYPE %s\", q, (mcode[grp].is_ae ? \"AE\" : \"SE\"));\n\n\treturn mcode[grp].is_ae ? AE_TYPES : SE_TYPES;\n}\n\n \nstatic void cpt_handle_mbox_intr(struct cpt_device *cpt, int vf)\n{\n\tstruct cpt_vf_info *vfx = &cpt->vfinfo[vf];\n\tstruct cpt_mbox mbx = {};\n\tint vftype;\n\tstruct device *dev = &cpt->pdev->dev;\n\t \n\tmbx.msg  = cpt_read_csr64(cpt->reg_base, CPTX_PF_VFX_MBOXX(0, vf, 0));\n\tmbx.data = cpt_read_csr64(cpt->reg_base, CPTX_PF_VFX_MBOXX(0, vf, 1));\n\tdev_dbg(dev, \"%s: Mailbox msg 0x%llx from VF%d\", __func__, mbx.msg, vf);\n\tswitch (mbx.msg) {\n\tcase CPT_MSG_VF_UP:\n\t\tvfx->state = VF_STATE_UP;\n\t\ttry_module_get(THIS_MODULE);\n\t\tcpt_mbox_send_ack(cpt, vf, &mbx);\n\t\tbreak;\n\tcase CPT_MSG_READY:\n\t\tmbx.msg  = CPT_MSG_READY;\n\t\tmbx.data = vf;\n\t\tcpt_send_msg_to_vf(cpt, vf, &mbx);\n\t\tbreak;\n\tcase CPT_MSG_VF_DOWN:\n\t\t \n\t\tvfx->state = VF_STATE_DOWN;\n\t\tmodule_put(THIS_MODULE);\n\t\tcpt_mbox_send_ack(cpt, vf, &mbx);\n\t\tbreak;\n\tcase CPT_MSG_QLEN:\n\t\tvfx->qlen = mbx.data;\n\t\tcpt_cfg_qlen_for_vf(cpt, vf, vfx->qlen);\n\t\tcpt_mbox_send_ack(cpt, vf, &mbx);\n\t\tbreak;\n\tcase CPT_MSG_QBIND_GRP:\n\t\tvftype = cpt_bind_vq_to_grp(cpt, vf, (u8)mbx.data);\n\t\tif ((vftype != AE_TYPES) && (vftype != SE_TYPES))\n\t\t\tdev_err(dev, \"Queue %d binding to group %llu failed\",\n\t\t\t\tvf, mbx.data);\n\t\telse {\n\t\t\tdev_dbg(dev, \"Queue %d binding to group %llu successful\",\n\t\t\t\tvf, mbx.data);\n\t\t\tmbx.msg = CPT_MSG_QBIND_GRP;\n\t\t\tmbx.data = vftype;\n\t\t\tcpt_send_msg_to_vf(cpt, vf, &mbx);\n\t\t}\n\t\tbreak;\n\tcase CPT_MSG_VQ_PRIORITY:\n\t\tvfx->priority = mbx.data;\n\t\tcpt_cfg_vq_priority(cpt, vf, vfx->priority);\n\t\tcpt_mbox_send_ack(cpt, vf, &mbx);\n\t\tbreak;\n\tdefault:\n\t\tdev_err(&cpt->pdev->dev, \"Invalid msg from VF%d, msg 0x%llx\\n\",\n\t\t\tvf, mbx.msg);\n\t\tbreak;\n\t}\n}\n\nvoid cpt_mbox_intr_handler (struct cpt_device *cpt, int mbx)\n{\n\tu64 intr;\n\tu8  vf;\n\n\tintr = cpt_read_csr64(cpt->reg_base, CPTX_PF_MBOX_INTX(0, 0));\n\tdev_dbg(&cpt->pdev->dev, \"PF interrupt Mbox%d 0x%llx\\n\", mbx, intr);\n\tfor (vf = 0; vf < CPT_MAX_VF_NUM; vf++) {\n\t\tif (intr & (1ULL << vf)) {\n\t\t\tdev_dbg(&cpt->pdev->dev, \"Intr from VF %d\\n\", vf);\n\t\t\tcpt_handle_mbox_intr(cpt, vf);\n\t\t\tcpt_clear_mbox_intr(cpt, vf);\n\t\t}\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}