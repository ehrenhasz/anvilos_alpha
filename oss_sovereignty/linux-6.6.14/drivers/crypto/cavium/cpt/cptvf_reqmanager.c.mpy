{
  "module_name": "cptvf_reqmanager.c",
  "hash_id": "b441c3881bd27e72c519c03a3c6a96343f3e099d8256c6c490d84880c848df47",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/cavium/cpt/cptvf_reqmanager.c",
  "human_readable_source": "\n \n\n#include \"cptvf.h\"\n#include \"cptvf_algs.h\"\n#include \"request_manager.h\"\n\n \nstatic struct pending_entry *get_free_pending_entry(struct pending_queue *q,\n\t\t\t\t\t\t    int qlen)\n{\n\tstruct pending_entry *ent = NULL;\n\n\tent = &q->head[q->rear];\n\tif (unlikely(ent->busy)) {\n\t\tent = NULL;\n\t\tgoto no_free_entry;\n\t}\n\n\tq->rear++;\n\tif (unlikely(q->rear == qlen))\n\t\tq->rear = 0;\n\nno_free_entry:\n\treturn ent;\n}\n\nstatic inline void pending_queue_inc_front(struct pending_qinfo *pqinfo,\n\t\t\t\t\t   int qno)\n{\n\tstruct pending_queue *queue = &pqinfo->queue[qno];\n\n\tqueue->front++;\n\tif (unlikely(queue->front == pqinfo->qlen))\n\t\tqueue->front = 0;\n}\n\nstatic int setup_sgio_components(struct cpt_vf *cptvf, struct buf_ptr *list,\n\t\t\t\t int buf_count, u8 *buffer)\n{\n\tint ret = 0, i, j;\n\tint components;\n\tstruct sglist_component *sg_ptr = NULL;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\n\tif (unlikely(!list)) {\n\t\tdev_err(&pdev->dev, \"Input List pointer is NULL\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tfor (i = 0; i < buf_count; i++) {\n\t\tif (likely(list[i].vptr)) {\n\t\t\tlist[i].dma_addr = dma_map_single(&pdev->dev,\n\t\t\t\t\t\t\t  list[i].vptr,\n\t\t\t\t\t\t\t  list[i].size,\n\t\t\t\t\t\t\t  DMA_BIDIRECTIONAL);\n\t\t\tif (unlikely(dma_mapping_error(&pdev->dev,\n\t\t\t\t\t\t       list[i].dma_addr))) {\n\t\t\t\tdev_err(&pdev->dev, \"DMA map kernel buffer failed for component: %d\\n\",\n\t\t\t\t\ti);\n\t\t\t\tret = -EIO;\n\t\t\t\tgoto sg_cleanup;\n\t\t\t}\n\t\t}\n\t}\n\n\tcomponents = buf_count / 4;\n\tsg_ptr = (struct sglist_component *)buffer;\n\tfor (i = 0; i < components; i++) {\n\t\tsg_ptr->u.s.len0 = cpu_to_be16(list[i * 4 + 0].size);\n\t\tsg_ptr->u.s.len1 = cpu_to_be16(list[i * 4 + 1].size);\n\t\tsg_ptr->u.s.len2 = cpu_to_be16(list[i * 4 + 2].size);\n\t\tsg_ptr->u.s.len3 = cpu_to_be16(list[i * 4 + 3].size);\n\t\tsg_ptr->ptr0 = cpu_to_be64(list[i * 4 + 0].dma_addr);\n\t\tsg_ptr->ptr1 = cpu_to_be64(list[i * 4 + 1].dma_addr);\n\t\tsg_ptr->ptr2 = cpu_to_be64(list[i * 4 + 2].dma_addr);\n\t\tsg_ptr->ptr3 = cpu_to_be64(list[i * 4 + 3].dma_addr);\n\t\tsg_ptr++;\n\t}\n\n\tcomponents = buf_count % 4;\n\n\tswitch (components) {\n\tcase 3:\n\t\tsg_ptr->u.s.len2 = cpu_to_be16(list[i * 4 + 2].size);\n\t\tsg_ptr->ptr2 = cpu_to_be64(list[i * 4 + 2].dma_addr);\n\t\tfallthrough;\n\tcase 2:\n\t\tsg_ptr->u.s.len1 = cpu_to_be16(list[i * 4 + 1].size);\n\t\tsg_ptr->ptr1 = cpu_to_be64(list[i * 4 + 1].dma_addr);\n\t\tfallthrough;\n\tcase 1:\n\t\tsg_ptr->u.s.len0 = cpu_to_be16(list[i * 4 + 0].size);\n\t\tsg_ptr->ptr0 = cpu_to_be64(list[i * 4 + 0].dma_addr);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn ret;\n\nsg_cleanup:\n\tfor (j = 0; j < i; j++) {\n\t\tif (list[j].dma_addr) {\n\t\t\tdma_unmap_single(&pdev->dev, list[i].dma_addr,\n\t\t\t\t\t list[i].size, DMA_BIDIRECTIONAL);\n\t\t}\n\n\t\tlist[j].dma_addr = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic inline int setup_sgio_list(struct cpt_vf *cptvf,\n\t\t\t\t  struct cpt_info_buffer *info,\n\t\t\t\t  struct cpt_request_info *req)\n{\n\tu16 g_sz_bytes = 0, s_sz_bytes = 0;\n\tint ret = 0;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\n\tif (req->incnt > MAX_SG_IN_CNT || req->outcnt > MAX_SG_OUT_CNT) {\n\t\tdev_err(&pdev->dev, \"Request SG components are higher than supported\\n\");\n\t\tret = -EINVAL;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\t \n\tg_sz_bytes = ((req->incnt + 3) / 4) * sizeof(struct sglist_component);\n\tinfo->gather_components = kzalloc(g_sz_bytes, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);\n\tif (!info->gather_components) {\n\t\tret = -ENOMEM;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\tret = setup_sgio_components(cptvf, req->in,\n\t\t\t\t    req->incnt,\n\t\t\t\t    info->gather_components);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to setup gather list\\n\");\n\t\tret = -EFAULT;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\t \n\ts_sz_bytes = ((req->outcnt + 3) / 4) * sizeof(struct sglist_component);\n\tinfo->scatter_components = kzalloc(s_sz_bytes, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);\n\tif (!info->scatter_components) {\n\t\tret = -ENOMEM;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\tret = setup_sgio_components(cptvf, req->out,\n\t\t\t\t    req->outcnt,\n\t\t\t\t    info->scatter_components);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to setup gather list\\n\");\n\t\tret = -EFAULT;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\t \n\tinfo->dlen = g_sz_bytes + s_sz_bytes + SG_LIST_HDR_SIZE;\n\tinfo->in_buffer = kzalloc(info->dlen, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);\n\tif (!info->in_buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\t((__be16 *)info->in_buffer)[0] = cpu_to_be16(req->outcnt);\n\t((__be16 *)info->in_buffer)[1] = cpu_to_be16(req->incnt);\n\t((__be16 *)info->in_buffer)[2] = 0;\n\t((__be16 *)info->in_buffer)[3] = 0;\n\n\tmemcpy(&info->in_buffer[8], info->gather_components,\n\t       g_sz_bytes);\n\tmemcpy(&info->in_buffer[8 + g_sz_bytes],\n\t       info->scatter_components, s_sz_bytes);\n\n\tinfo->dptr_baddr = dma_map_single(&pdev->dev,\n\t\t\t\t\t  (void *)info->in_buffer,\n\t\t\t\t\t  info->dlen,\n\t\t\t\t\t  DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(&pdev->dev, info->dptr_baddr)) {\n\t\tdev_err(&pdev->dev, \"Mapping DPTR Failed %d\\n\", info->dlen);\n\t\tret = -EIO;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\t \n\tinfo->out_buffer = kzalloc(COMPLETION_CODE_SIZE, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);\n\tif (!info->out_buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto scatter_gather_clean;\n\t}\n\n\t*((u64 *)info->out_buffer) = ~((u64)COMPLETION_CODE_INIT);\n\tinfo->alternate_caddr = (u64 *)info->out_buffer;\n\tinfo->rptr_baddr = dma_map_single(&pdev->dev,\n\t\t\t\t\t  (void *)info->out_buffer,\n\t\t\t\t\t  COMPLETION_CODE_SIZE,\n\t\t\t\t\t  DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(&pdev->dev, info->rptr_baddr)) {\n\t\tdev_err(&pdev->dev, \"Mapping RPTR Failed %d\\n\",\n\t\t\tCOMPLETION_CODE_SIZE);\n\t\tret = -EIO;\n\t\tgoto  scatter_gather_clean;\n\t}\n\n\treturn 0;\n\nscatter_gather_clean:\n\treturn ret;\n}\n\nstatic int send_cpt_command(struct cpt_vf *cptvf, union cpt_inst_s *cmd,\n\t\t     u32 qno)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tstruct command_qinfo *qinfo = NULL;\n\tstruct command_queue *queue;\n\tstruct command_chunk *chunk;\n\tu8 *ent;\n\tint ret = 0;\n\n\tif (unlikely(qno >= cptvf->nr_queues)) {\n\t\tdev_err(&pdev->dev, \"Invalid queue (qno: %d, nr_queues: %d)\\n\",\n\t\t\tqno, cptvf->nr_queues);\n\t\treturn -EINVAL;\n\t}\n\n\tqinfo = &cptvf->cqinfo;\n\tqueue = &qinfo->queue[qno];\n\t \n\tspin_lock(&queue->lock);\n\tent = &queue->qhead->head[queue->idx * qinfo->cmd_size];\n\tmemcpy(ent, (void *)cmd, qinfo->cmd_size);\n\n\tif (++queue->idx >= queue->qhead->size / 64) {\n\t\thlist_for_each_entry(chunk, &queue->chead, nextchunk) {\n\t\t\tif (chunk == queue->qhead) {\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tqueue->qhead = chunk;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tqueue->idx = 0;\n\t}\n\t \n\tsmp_wmb();\n\tcptvf_write_vq_doorbell(cptvf, 1);\n\t \n\tspin_unlock(&queue->lock);\n\n\treturn ret;\n}\n\nstatic void do_request_cleanup(struct cpt_vf *cptvf,\n\t\t\tstruct cpt_info_buffer *info)\n{\n\tint i;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tstruct cpt_request_info *req;\n\n\tif (info->dptr_baddr)\n\t\tdma_unmap_single(&pdev->dev, info->dptr_baddr,\n\t\t\t\t info->dlen, DMA_BIDIRECTIONAL);\n\n\tif (info->rptr_baddr)\n\t\tdma_unmap_single(&pdev->dev, info->rptr_baddr,\n\t\t\t\t COMPLETION_CODE_SIZE, DMA_BIDIRECTIONAL);\n\n\tif (info->comp_baddr)\n\t\tdma_unmap_single(&pdev->dev, info->comp_baddr,\n\t\t\t\t sizeof(union cpt_res_s), DMA_BIDIRECTIONAL);\n\n\tif (info->req) {\n\t\treq = info->req;\n\t\tfor (i = 0; i < req->outcnt; i++) {\n\t\t\tif (req->out[i].dma_addr)\n\t\t\t\tdma_unmap_single(&pdev->dev,\n\t\t\t\t\t\t req->out[i].dma_addr,\n\t\t\t\t\t\t req->out[i].size,\n\t\t\t\t\t\t DMA_BIDIRECTIONAL);\n\t\t}\n\n\t\tfor (i = 0; i < req->incnt; i++) {\n\t\t\tif (req->in[i].dma_addr)\n\t\t\t\tdma_unmap_single(&pdev->dev,\n\t\t\t\t\t\t req->in[i].dma_addr,\n\t\t\t\t\t\t req->in[i].size,\n\t\t\t\t\t\t DMA_BIDIRECTIONAL);\n\t\t}\n\t}\n\n\tkfree_sensitive(info->scatter_components);\n\tkfree_sensitive(info->gather_components);\n\tkfree_sensitive(info->out_buffer);\n\tkfree_sensitive(info->in_buffer);\n\tkfree_sensitive((void *)info->completion_addr);\n\tkfree_sensitive(info);\n}\n\nstatic void do_post_process(struct cpt_vf *cptvf, struct cpt_info_buffer *info)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\n\tif (!info) {\n\t\tdev_err(&pdev->dev, \"incorrect cpt_info_buffer for post processing\\n\");\n\t\treturn;\n\t}\n\n\tdo_request_cleanup(cptvf, info);\n}\n\nstatic inline void process_pending_queue(struct cpt_vf *cptvf,\n\t\t\t\t\t struct pending_qinfo *pqinfo,\n\t\t\t\t\t int qno)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tstruct pending_queue *pqueue = &pqinfo->queue[qno];\n\tstruct pending_entry *pentry = NULL;\n\tstruct cpt_info_buffer *info = NULL;\n\tunion cpt_res_s *status = NULL;\n\tunsigned char ccode;\n\n\twhile (1) {\n\t\tspin_lock_bh(&pqueue->lock);\n\t\tpentry = &pqueue->head[pqueue->front];\n\t\tif (unlikely(!pentry->busy)) {\n\t\t\tspin_unlock_bh(&pqueue->lock);\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo = (struct cpt_info_buffer *)pentry->post_arg;\n\t\tif (unlikely(!info)) {\n\t\t\tdev_err(&pdev->dev, \"Pending Entry post arg NULL\\n\");\n\t\t\tpending_queue_inc_front(pqinfo, qno);\n\t\t\tspin_unlock_bh(&pqueue->lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tstatus = (union cpt_res_s *)pentry->completion_addr;\n\t\tccode = status->s.compcode;\n\t\tif ((status->s.compcode == CPT_COMP_E_FAULT) ||\n\t\t    (status->s.compcode == CPT_COMP_E_SWERR)) {\n\t\t\tdev_err(&pdev->dev, \"Request failed with %s\\n\",\n\t\t\t\t(status->s.compcode == CPT_COMP_E_FAULT) ?\n\t\t\t\t\"DMA Fault\" : \"Software error\");\n\t\t\tpentry->completion_addr = NULL;\n\t\t\tpentry->busy = false;\n\t\t\tatomic64_dec((&pqueue->pending_count));\n\t\t\tpentry->post_arg = NULL;\n\t\t\tpending_queue_inc_front(pqinfo, qno);\n\t\t\tdo_request_cleanup(cptvf, info);\n\t\t\tspin_unlock_bh(&pqueue->lock);\n\t\t\tbreak;\n\t\t} else if (status->s.compcode == COMPLETION_CODE_INIT) {\n\t\t\t \n\t\t\tif (time_after_eq(jiffies,\n\t\t\t\t\t  (info->time_in +\n\t\t\t\t\t  (CPT_COMMAND_TIMEOUT * HZ)))) {\n\t\t\t\tdev_err(&pdev->dev, \"Request timed out\");\n\t\t\t\tpentry->completion_addr = NULL;\n\t\t\t\tpentry->busy = false;\n\t\t\t\tatomic64_dec((&pqueue->pending_count));\n\t\t\t\tpentry->post_arg = NULL;\n\t\t\t\tpending_queue_inc_front(pqinfo, qno);\n\t\t\t\tdo_request_cleanup(cptvf, info);\n\t\t\t\tspin_unlock_bh(&pqueue->lock);\n\t\t\t\tbreak;\n\t\t\t} else if ((*info->alternate_caddr ==\n\t\t\t\t(~COMPLETION_CODE_INIT)) &&\n\t\t\t\t(info->extra_time < TIME_IN_RESET_COUNT)) {\n\t\t\t\tinfo->time_in = jiffies;\n\t\t\t\tinfo->extra_time++;\n\t\t\t\tspin_unlock_bh(&pqueue->lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tpentry->completion_addr = NULL;\n\t\tpentry->busy = false;\n\t\tpentry->post_arg = NULL;\n\t\tatomic64_dec((&pqueue->pending_count));\n\t\tpending_queue_inc_front(pqinfo, qno);\n\t\tspin_unlock_bh(&pqueue->lock);\n\n\t\tdo_post_process(info->cptvf, info);\n\t\t \n\t\tpentry->callback(ccode, pentry->callback_arg);\n\t}\n}\n\nint process_request(struct cpt_vf *cptvf, struct cpt_request_info *req)\n{\n\tint ret = 0, clear = 0, queue = 0;\n\tstruct cpt_info_buffer *info = NULL;\n\tstruct cptvf_request *cpt_req = NULL;\n\tunion ctrl_info *ctrl = NULL;\n\tunion cpt_res_s *result = NULL;\n\tstruct pending_entry *pentry = NULL;\n\tstruct pending_queue *pqueue = NULL;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tu8 group = 0;\n\tstruct cpt_vq_command vq_cmd;\n\tunion cpt_inst_s cptinst;\n\n\tinfo = kzalloc(sizeof(*info), req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);\n\tif (unlikely(!info)) {\n\t\tdev_err(&pdev->dev, \"Unable to allocate memory for info_buffer\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tcpt_req = (struct cptvf_request *)&req->req;\n\tctrl = (union ctrl_info *)&req->ctrl;\n\n\tinfo->cptvf = cptvf;\n\tgroup = ctrl->s.grp;\n\tret = setup_sgio_list(cptvf, info, req);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Setting up SG list failed\");\n\t\tgoto request_cleanup;\n\t}\n\n\tcpt_req->dlen = info->dlen;\n\t \n\tinfo->completion_addr = kzalloc(sizeof(union cpt_res_s), req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);\n\tif (unlikely(!info->completion_addr)) {\n\t\tdev_err(&pdev->dev, \"Unable to allocate memory for completion_addr\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto request_cleanup;\n\t}\n\n\tresult = (union cpt_res_s *)info->completion_addr;\n\tresult->s.compcode = COMPLETION_CODE_INIT;\n\tinfo->comp_baddr = dma_map_single(&pdev->dev,\n\t\t\t\t\t       (void *)info->completion_addr,\n\t\t\t\t\t       sizeof(union cpt_res_s),\n\t\t\t\t\t       DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(&pdev->dev, info->comp_baddr)) {\n\t\tdev_err(&pdev->dev, \"mapping compptr Failed %lu\\n\",\n\t\t\tsizeof(union cpt_res_s));\n\t\tret = -EFAULT;\n\t\tgoto  request_cleanup;\n\t}\n\n\t \n\tvq_cmd.cmd.u64 = 0;\n\tvq_cmd.cmd.s.opcode = cpu_to_be16(cpt_req->opcode.flags);\n\tvq_cmd.cmd.s.param1 = cpu_to_be16(cpt_req->param1);\n\tvq_cmd.cmd.s.param2 = cpu_to_be16(cpt_req->param2);\n\tvq_cmd.cmd.s.dlen   = cpu_to_be16(cpt_req->dlen);\n\n\tvq_cmd.dptr = info->dptr_baddr;\n\tvq_cmd.rptr = info->rptr_baddr;\n\tvq_cmd.cptr.u64 = 0;\n\tvq_cmd.cptr.s.grp = group;\n\t \n\t \n\tqueue = 0;\n\tpqueue = &cptvf->pqinfo.queue[queue];\n\n\tif (atomic64_read(&pqueue->pending_count) > PENDING_THOLD) {\n\t\tdev_err(&pdev->dev, \"pending threshold reached\\n\");\n\t\tprocess_pending_queue(cptvf, &cptvf->pqinfo, queue);\n\t}\n\nget_pending_entry:\n\tspin_lock_bh(&pqueue->lock);\n\tpentry = get_free_pending_entry(pqueue, cptvf->pqinfo.qlen);\n\tif (unlikely(!pentry)) {\n\t\tspin_unlock_bh(&pqueue->lock);\n\t\tif (clear == 0) {\n\t\t\tprocess_pending_queue(cptvf, &cptvf->pqinfo, queue);\n\t\t\tclear = 1;\n\t\t\tgoto get_pending_entry;\n\t\t}\n\t\tdev_err(&pdev->dev, \"Get free entry failed\\n\");\n\t\tdev_err(&pdev->dev, \"queue: %d, rear: %d, front: %d\\n\",\n\t\t\tqueue, pqueue->rear, pqueue->front);\n\t\tret = -EFAULT;\n\t\tgoto request_cleanup;\n\t}\n\n\tpentry->completion_addr = info->completion_addr;\n\tpentry->post_arg = (void *)info;\n\tpentry->callback = req->callback;\n\tpentry->callback_arg = req->callback_arg;\n\tinfo->pentry = pentry;\n\tpentry->busy = true;\n\tatomic64_inc(&pqueue->pending_count);\n\n\t \n\tinfo->pentry = pentry;\n\tinfo->time_in = jiffies;\n\tinfo->req = req;\n\n\t \n\tcptinst.s.doneint = true;\n\tcptinst.s.res_addr = (u64)info->comp_baddr;\n\tcptinst.s.tag = 0;\n\tcptinst.s.grp = 0;\n\tcptinst.s.wq_ptr = 0;\n\tcptinst.s.ei0 = vq_cmd.cmd.u64;\n\tcptinst.s.ei1 = vq_cmd.dptr;\n\tcptinst.s.ei2 = vq_cmd.rptr;\n\tcptinst.s.ei3 = vq_cmd.cptr.u64;\n\n\tret = send_cpt_command(cptvf, &cptinst, queue);\n\tspin_unlock_bh(&pqueue->lock);\n\tif (unlikely(ret)) {\n\t\tdev_err(&pdev->dev, \"Send command failed for AE\\n\");\n\t\tret = -EFAULT;\n\t\tgoto request_cleanup;\n\t}\n\n\treturn 0;\n\nrequest_cleanup:\n\tdev_dbg(&pdev->dev, \"Failed to submit CPT command\\n\");\n\tdo_request_cleanup(cptvf, info);\n\n\treturn ret;\n}\n\nvoid vq_post_process(struct cpt_vf *cptvf, u32 qno)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\n\tif (unlikely(qno > cptvf->nr_queues)) {\n\t\tdev_err(&pdev->dev, \"Request for post processing on invalid pending queue: %u\\n\",\n\t\t\tqno);\n\t\treturn;\n\t}\n\n\tprocess_pending_queue(cptvf, &cptvf->pqinfo, qno);\n}\n\nint cptvf_do_request(void *vfdev, struct cpt_request_info *req)\n{\n\tstruct cpt_vf *cptvf = (struct cpt_vf *)vfdev;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\n\tif (!cpt_device_ready(cptvf)) {\n\t\tdev_err(&pdev->dev, \"CPT Device is not ready\");\n\t\treturn -ENODEV;\n\t}\n\n\tif ((cptvf->vftype == SE_TYPES) && (!req->ctrl.s.se_req)) {\n\t\tdev_err(&pdev->dev, \"CPTVF-%d of SE TYPE got AE request\",\n\t\t\tcptvf->vfid);\n\t\treturn -EINVAL;\n\t} else if ((cptvf->vftype == AE_TYPES) && (req->ctrl.s.se_req)) {\n\t\tdev_err(&pdev->dev, \"CPTVF-%d of AE TYPE got SE request\",\n\t\t\tcptvf->vfid);\n\t\treturn -EINVAL;\n\t}\n\n\treturn process_request(cptvf, req);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}