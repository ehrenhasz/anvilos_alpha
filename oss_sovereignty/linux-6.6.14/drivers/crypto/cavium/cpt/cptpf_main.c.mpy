{
  "module_name": "cptpf_main.c",
  "hash_id": "567bb8477ac09ec5070ffa51473ffdbbe1303edd6a738c364598d949d91367a1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/cavium/cpt/cptpf_main.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/firmware.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/pci.h>\n#include <linux/printk.h>\n\n#include \"cptpf.h\"\n\n#define DRV_NAME\t\"thunder-cpt\"\n#define DRV_VERSION\t\"1.0\"\n\nstatic u32 num_vfs = 4;  \nmodule_param(num_vfs, uint, 0444);\nMODULE_PARM_DESC(num_vfs, \"Number of VFs to enable(1-16)\");\n\n \nstatic void cpt_disable_cores(struct cpt_device *cpt, u64 coremask,\n\t\t\t      u8 type, u8 grp)\n{\n\tu64 pf_exe_ctl;\n\tu32 timeout = 100;\n\tu64 grpmask = 0;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\tif (type == AE_TYPES)\n\t\tcoremask = (coremask << cpt->max_se_cores);\n\n\t \n\tgrpmask = cpt_read_csr64(cpt->reg_base, CPTX_PF_GX_EN(0, grp));\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_GX_EN(0, grp),\n\t\t\t(grpmask & ~coremask));\n\tudelay(CSR_DELAY);\n\tgrp = cpt_read_csr64(cpt->reg_base, CPTX_PF_EXEC_BUSY(0));\n\twhile (grp & coremask) {\n\t\tdev_err(dev, \"Cores still busy %llx\", coremask);\n\t\tgrp = cpt_read_csr64(cpt->reg_base,\n\t\t\t\t     CPTX_PF_EXEC_BUSY(0));\n\t\tif (timeout--)\n\t\t\tbreak;\n\n\t\tudelay(CSR_DELAY);\n\t}\n\n\t \n\tpf_exe_ctl = cpt_read_csr64(cpt->reg_base, CPTX_PF_EXE_CTL(0));\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_EXE_CTL(0),\n\t\t\t(pf_exe_ctl & ~coremask));\n\tudelay(CSR_DELAY);\n}\n\n \nstatic void cpt_enable_cores(struct cpt_device *cpt, u64 coremask,\n\t\t\t     u8 type)\n{\n\tu64 pf_exe_ctl;\n\n\tif (type == AE_TYPES)\n\t\tcoremask = (coremask << cpt->max_se_cores);\n\n\tpf_exe_ctl = cpt_read_csr64(cpt->reg_base, CPTX_PF_EXE_CTL(0));\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_EXE_CTL(0),\n\t\t\t(pf_exe_ctl | coremask));\n\tudelay(CSR_DELAY);\n}\n\nstatic void cpt_configure_group(struct cpt_device *cpt, u8 grp,\n\t\t\t\tu64 coremask, u8 type)\n{\n\tu64 pf_gx_en = 0;\n\n\tif (type == AE_TYPES)\n\t\tcoremask = (coremask << cpt->max_se_cores);\n\n\tpf_gx_en = cpt_read_csr64(cpt->reg_base, CPTX_PF_GX_EN(0, grp));\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_GX_EN(0, grp),\n\t\t\t(pf_gx_en | coremask));\n\tudelay(CSR_DELAY);\n}\n\nstatic void cpt_disable_mbox_interrupts(struct cpt_device *cpt)\n{\n\t \n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_MBOX_ENA_W1CX(0, 0), ~0ull);\n}\n\nstatic void cpt_disable_ecc_interrupts(struct cpt_device *cpt)\n{\n\t \n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_ECC0_ENA_W1C(0), ~0ull);\n}\n\nstatic void cpt_disable_exec_interrupts(struct cpt_device *cpt)\n{\n\t \n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_EXEC_ENA_W1C(0), ~0ull);\n}\n\nstatic void cpt_disable_all_interrupts(struct cpt_device *cpt)\n{\n\tcpt_disable_mbox_interrupts(cpt);\n\tcpt_disable_ecc_interrupts(cpt);\n\tcpt_disable_exec_interrupts(cpt);\n}\n\nstatic void cpt_enable_mbox_interrupts(struct cpt_device *cpt)\n{\n\t \n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_MBOX_ENA_W1SX(0, 0), ~0ull);\n}\n\nstatic int cpt_load_microcode(struct cpt_device *cpt, struct microcode *mcode)\n{\n\tint ret = 0, core = 0, shift = 0;\n\tu32 total_cores = 0;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\tif (!mcode || !mcode->code) {\n\t\tdev_err(dev, \"Either the mcode is null or data is NULL\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (mcode->code_size == 0) {\n\t\tdev_err(dev, \"microcode size is 0\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (mcode->is_ae) {\n\t\tcore = CPT_MAX_SE_CORES;  \n\t\ttotal_cores = CPT_MAX_TOTAL_CORES;  \n\t} else {\n\t\tcore = 0;  \n\t\ttotal_cores = CPT_MAX_SE_CORES;  \n\t}\n\n\t \n\tfor (; core < total_cores ; core++, shift++) {\n\t\tif (mcode->core_mask & (1 << shift)) {\n\t\t\tcpt_write_csr64(cpt->reg_base,\n\t\t\t\t\tCPTX_PF_ENGX_UCODE_BASE(0, core),\n\t\t\t\t\t(u64)mcode->phys_base);\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int do_cpt_init(struct cpt_device *cpt, struct microcode *mcode)\n{\n\tint ret = 0;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\t \n\tcpt->flags &= ~CPT_FLAG_DEVICE_READY;\n\t \n\tcpt_disable_all_interrupts(cpt);\n\t \n\tif (mcode->is_ae) {\n\t\tif (mcode->num_cores > cpt->max_ae_cores) {\n\t\t\tdev_err(dev, \"Requested for more cores than available AE cores\\n\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto cpt_init_fail;\n\t\t}\n\n\t\tif (cpt->next_group >= CPT_MAX_CORE_GROUPS) {\n\t\t\tdev_err(dev, \"Can't load, all eight microcode groups in use\");\n\t\t\treturn -ENFILE;\n\t\t}\n\n\t\tmcode->group = cpt->next_group;\n\t\t \n\t\tmcode->core_mask = GENMASK(mcode->num_cores, 0);\n\t\tcpt_disable_cores(cpt, mcode->core_mask, AE_TYPES,\n\t\t\t\t  mcode->group);\n\t\t \n\t\tret = cpt_load_microcode(cpt, mcode);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Microcode load Failed for %s\\n\",\n\t\t\t\tmcode->version);\n\t\t\tgoto cpt_init_fail;\n\t\t}\n\t\tcpt->next_group++;\n\t\t \n\t\tcpt_configure_group(cpt, mcode->group, mcode->core_mask,\n\t\t\t\t    AE_TYPES);\n\t\t \n\t\tcpt_enable_cores(cpt, mcode->core_mask, AE_TYPES);\n\t} else {\n\t\tif (mcode->num_cores > cpt->max_se_cores) {\n\t\t\tdev_err(dev, \"Requested for more cores than available SE cores\\n\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto cpt_init_fail;\n\t\t}\n\t\tif (cpt->next_group >= CPT_MAX_CORE_GROUPS) {\n\t\t\tdev_err(dev, \"Can't load, all eight microcode groups in use\");\n\t\t\treturn -ENFILE;\n\t\t}\n\n\t\tmcode->group = cpt->next_group;\n\t\t \n\t\tmcode->core_mask = GENMASK(mcode->num_cores, 0);\n\t\tcpt_disable_cores(cpt, mcode->core_mask, SE_TYPES,\n\t\t\t\t  mcode->group);\n\t\t \n\t\tret = cpt_load_microcode(cpt, mcode);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"Microcode load Failed for %s\\n\",\n\t\t\t\tmcode->version);\n\t\t\tgoto cpt_init_fail;\n\t\t}\n\t\tcpt->next_group++;\n\t\t \n\t\tcpt_configure_group(cpt, mcode->group, mcode->core_mask,\n\t\t\t\t    SE_TYPES);\n\t\t \n\t\tcpt_enable_cores(cpt, mcode->core_mask, SE_TYPES);\n\t}\n\n\t \n\tcpt_enable_mbox_interrupts(cpt);\n\tcpt->flags |= CPT_FLAG_DEVICE_READY;\n\n\treturn ret;\n\ncpt_init_fail:\n\t \n\tcpt_enable_mbox_interrupts(cpt);\n\n\treturn ret;\n}\n\nstruct ucode_header {\n\tu8 version[CPT_UCODE_VERSION_SZ];\n\t__be32 code_length;\n\tu32 data_length;\n\tu64 sram_address;\n};\n\nstatic int cpt_ucode_load_fw(struct cpt_device *cpt, const u8 *fw, bool is_ae)\n{\n\tconst struct firmware *fw_entry;\n\tstruct device *dev = &cpt->pdev->dev;\n\tstruct ucode_header *ucode;\n\tunsigned int code_length;\n\tstruct microcode *mcode;\n\tint j, ret = 0;\n\n\tret = request_firmware(&fw_entry, fw, dev);\n\tif (ret)\n\t\treturn ret;\n\n\tucode = (struct ucode_header *)fw_entry->data;\n\tmcode = &cpt->mcode[cpt->next_mc_idx];\n\tmemcpy(mcode->version, (u8 *)fw_entry->data, CPT_UCODE_VERSION_SZ);\n\tcode_length = ntohl(ucode->code_length);\n\tif (code_length == 0 || code_length >= INT_MAX / 2) {\n\t\tret = -EINVAL;\n\t\tgoto fw_release;\n\t}\n\tmcode->code_size = code_length * 2;\n\n\tmcode->is_ae = is_ae;\n\tmcode->core_mask = 0ULL;\n\tmcode->num_cores = is_ae ? 6 : 10;\n\n\t \n\tmcode->code = dma_alloc_coherent(&cpt->pdev->dev, mcode->code_size,\n\t\t\t\t\t &mcode->phys_base, GFP_KERNEL);\n\tif (!mcode->code) {\n\t\tdev_err(dev, \"Unable to allocate space for microcode\");\n\t\tret = -ENOMEM;\n\t\tgoto fw_release;\n\t}\n\n\tmemcpy((void *)mcode->code, (void *)(fw_entry->data + sizeof(*ucode)),\n\t       mcode->code_size);\n\n\t \n\tfor (j = 0; j < (mcode->code_size / 8); j++)\n\t\t((__be64 *)mcode->code)[j] = cpu_to_be64(((u64 *)mcode->code)[j]);\n\t \n\tfor (j = 0; j < (mcode->code_size / 2); j++)\n\t\t((__be16 *)mcode->code)[j] = cpu_to_be16(((u16 *)mcode->code)[j]);\n\n\tdev_dbg(dev, \"mcode->code_size = %u\\n\", mcode->code_size);\n\tdev_dbg(dev, \"mcode->is_ae = %u\\n\", mcode->is_ae);\n\tdev_dbg(dev, \"mcode->num_cores = %u\\n\", mcode->num_cores);\n\tdev_dbg(dev, \"mcode->code = %llx\\n\", (u64)mcode->code);\n\tdev_dbg(dev, \"mcode->phys_base = %llx\\n\", mcode->phys_base);\n\n\tret = do_cpt_init(cpt, mcode);\n\tif (ret) {\n\t\tdev_err(dev, \"do_cpt_init failed with ret: %d\\n\", ret);\n\t\tgoto fw_release;\n\t}\n\n\tdev_info(dev, \"Microcode Loaded %s\\n\", mcode->version);\n\tmcode->is_mc_valid = 1;\n\tcpt->next_mc_idx++;\n\nfw_release:\n\trelease_firmware(fw_entry);\n\n\treturn ret;\n}\n\nstatic int cpt_ucode_load(struct cpt_device *cpt)\n{\n\tint ret = 0;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\tret = cpt_ucode_load_fw(cpt, \"cpt8x-mc-ae.out\", true);\n\tif (ret) {\n\t\tdev_err(dev, \"ae:cpt_ucode_load failed with ret: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\tret = cpt_ucode_load_fw(cpt, \"cpt8x-mc-se.out\", false);\n\tif (ret) {\n\t\tdev_err(dev, \"se:cpt_ucode_load failed with ret: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic irqreturn_t cpt_mbx0_intr_handler(int irq, void *cpt_irq)\n{\n\tstruct cpt_device *cpt = (struct cpt_device *)cpt_irq;\n\n\tcpt_mbox_intr_handler(cpt, 0);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void cpt_reset(struct cpt_device *cpt)\n{\n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_RESET(0), 1);\n}\n\nstatic void cpt_find_max_enabled_cores(struct cpt_device *cpt)\n{\n\tunion cptx_pf_constants pf_cnsts = {0};\n\n\tpf_cnsts.u = cpt_read_csr64(cpt->reg_base, CPTX_PF_CONSTANTS(0));\n\tcpt->max_se_cores = pf_cnsts.s.se;\n\tcpt->max_ae_cores = pf_cnsts.s.ae;\n}\n\nstatic u32 cpt_check_bist_status(struct cpt_device *cpt)\n{\n\tunion cptx_pf_bist_status bist_sts = {0};\n\n\tbist_sts.u = cpt_read_csr64(cpt->reg_base,\n\t\t\t\t    CPTX_PF_BIST_STATUS(0));\n\n\treturn bist_sts.u;\n}\n\nstatic u64 cpt_check_exe_bist_status(struct cpt_device *cpt)\n{\n\tunion cptx_pf_exe_bist_status bist_sts = {0};\n\n\tbist_sts.u = cpt_read_csr64(cpt->reg_base,\n\t\t\t\t    CPTX_PF_EXE_BIST_STATUS(0));\n\n\treturn bist_sts.u;\n}\n\nstatic void cpt_disable_all_cores(struct cpt_device *cpt)\n{\n\tu32 grp, timeout = 100;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\t \n\tfor (grp = 0; grp < CPT_MAX_CORE_GROUPS; grp++) {\n\t\tcpt_write_csr64(cpt->reg_base, CPTX_PF_GX_EN(0, grp), 0);\n\t\tudelay(CSR_DELAY);\n\t}\n\n\tgrp = cpt_read_csr64(cpt->reg_base, CPTX_PF_EXEC_BUSY(0));\n\twhile (grp) {\n\t\tdev_err(dev, \"Cores still busy\");\n\t\tgrp = cpt_read_csr64(cpt->reg_base,\n\t\t\t\t     CPTX_PF_EXEC_BUSY(0));\n\t\tif (timeout--)\n\t\t\tbreak;\n\n\t\tudelay(CSR_DELAY);\n\t}\n\t \n\tcpt_write_csr64(cpt->reg_base, CPTX_PF_EXE_CTL(0), 0);\n}\n\n \nstatic void cpt_unload_microcode(struct cpt_device *cpt)\n{\n\tu32 grp = 0, core;\n\n\t \n\tfor (grp = 0; grp < CPT_MAX_CORE_GROUPS; grp++) {\n\t\tstruct microcode *mcode = &cpt->mcode[grp];\n\n\t\tif (cpt->mcode[grp].code)\n\t\t\tdma_free_coherent(&cpt->pdev->dev, mcode->code_size,\n\t\t\t\t\t  mcode->code, mcode->phys_base);\n\t\tmcode->code = NULL;\n\t}\n\t \n\tfor (core = 0; core < CPT_MAX_TOTAL_CORES; core++)\n\t\tcpt_write_csr64(cpt->reg_base,\n\t\t\t\tCPTX_PF_ENGX_UCODE_BASE(0, core), 0ull);\n}\n\nstatic int cpt_device_init(struct cpt_device *cpt)\n{\n\tu64 bist;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\t \n\tcpt_reset(cpt);\n\tmsleep(100);\n\n\t \n\tbist = (u64)cpt_check_bist_status(cpt);\n\tif (bist) {\n\t\tdev_err(dev, \"RAM BIST failed with code 0x%llx\", bist);\n\t\treturn -ENODEV;\n\t}\n\n\tbist = cpt_check_exe_bist_status(cpt);\n\tif (bist) {\n\t\tdev_err(dev, \"Engine BIST failed with code 0x%llx\", bist);\n\t\treturn -ENODEV;\n\t}\n\n\t \n\t \n\tcpt_find_max_enabled_cores(cpt);\n\t \n\tcpt_disable_all_cores(cpt);\n\t \n\tcpt->next_mc_idx   = 0;\n\tcpt->next_group = 0;\n\t \n\tcpt->flags |= CPT_FLAG_DEVICE_READY;\n\n\treturn 0;\n}\n\nstatic int cpt_register_interrupts(struct cpt_device *cpt)\n{\n\tint ret;\n\tstruct device *dev = &cpt->pdev->dev;\n\n\t \n\tret = pci_alloc_irq_vectors(cpt->pdev, CPT_PF_MSIX_VECTORS,\n\t\t\tCPT_PF_MSIX_VECTORS, PCI_IRQ_MSIX);\n\tif (ret < 0) {\n\t\tdev_err(&cpt->pdev->dev, \"Request for #%d msix vectors failed\\n\",\n\t\t\tCPT_PF_MSIX_VECTORS);\n\t\treturn ret;\n\t}\n\n\t \n\tret = request_irq(pci_irq_vector(cpt->pdev, CPT_PF_INT_VEC_E_MBOXX(0)),\n\t\t\t  cpt_mbx0_intr_handler, 0, \"CPT Mbox0\", cpt);\n\tif (ret)\n\t\tgoto fail;\n\n\t \n\tcpt_enable_mbox_interrupts(cpt);\n\treturn 0;\n\nfail:\n\tdev_err(dev, \"Request irq failed\\n\");\n\tpci_disable_msix(cpt->pdev);\n\treturn ret;\n}\n\nstatic void cpt_unregister_interrupts(struct cpt_device *cpt)\n{\n\tfree_irq(pci_irq_vector(cpt->pdev, CPT_PF_INT_VEC_E_MBOXX(0)), cpt);\n\tpci_disable_msix(cpt->pdev);\n}\n\nstatic int cpt_sriov_init(struct cpt_device *cpt, int num_vfs)\n{\n\tint pos = 0;\n\tint err;\n\tu16 total_vf_cnt;\n\tstruct pci_dev *pdev = cpt->pdev;\n\n\tpos = pci_find_ext_capability(pdev, PCI_EXT_CAP_ID_SRIOV);\n\tif (!pos) {\n\t\tdev_err(&pdev->dev, \"SRIOV capability is not found in PCIe config space\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tcpt->num_vf_en = num_vfs;  \n\tpci_read_config_word(pdev, (pos + PCI_SRIOV_TOTAL_VF), &total_vf_cnt);\n\tif (total_vf_cnt < cpt->num_vf_en)\n\t\tcpt->num_vf_en = total_vf_cnt;\n\n\tif (!total_vf_cnt)\n\t\treturn 0;\n\n\t \n\terr = pci_enable_sriov(pdev, cpt->num_vf_en);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"SRIOV enable failed, num VF is %d\\n\",\n\t\t\tcpt->num_vf_en);\n\t\tcpt->num_vf_en = 0;\n\t\treturn err;\n\t}\n\n\t \n\n\tdev_info(&pdev->dev, \"SRIOV enabled, number of VF available %d\\n\",\n\t\t cpt->num_vf_en);\n\n\tcpt->flags |= CPT_FLAG_SRIOV_ENABLED;\n\n\treturn 0;\n}\n\nstatic int cpt_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct cpt_device *cpt;\n\tint err;\n\n\tif (num_vfs > 16 || num_vfs < 4) {\n\t\tdev_warn(dev, \"Invalid vf count %d, Resetting it to 4(default)\\n\",\n\t\t\t num_vfs);\n\t\tnum_vfs = 4;\n\t}\n\n\tcpt = devm_kzalloc(dev, sizeof(*cpt), GFP_KERNEL);\n\tif (!cpt)\n\t\treturn -ENOMEM;\n\n\tpci_set_drvdata(pdev, cpt);\n\tcpt->pdev = pdev;\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to enable PCI device\\n\");\n\t\tpci_set_drvdata(pdev, NULL);\n\t\treturn err;\n\t}\n\n\terr = pci_request_regions(pdev, DRV_NAME);\n\tif (err) {\n\t\tdev_err(dev, \"PCI request regions failed 0x%x\\n\", err);\n\t\tgoto cpt_err_disable_device;\n\t}\n\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(48));\n\tif (err) {\n\t\tdev_err(dev, \"Unable to get usable 48-bit DMA configuration\\n\");\n\t\tgoto cpt_err_release_regions;\n\t}\n\n\t \n\tcpt->reg_base = pcim_iomap(pdev, 0, 0);\n\tif (!cpt->reg_base) {\n\t\tdev_err(dev, \"Cannot map config register space, aborting\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto cpt_err_release_regions;\n\t}\n\n\t \n\tcpt_device_init(cpt);\n\n\t \n\terr = cpt_register_interrupts(cpt);\n\tif (err)\n\t\tgoto cpt_err_release_regions;\n\n\terr = cpt_ucode_load(cpt);\n\tif (err)\n\t\tgoto cpt_err_unregister_interrupts;\n\n\t \n\terr = cpt_sriov_init(cpt, num_vfs);\n\tif (err)\n\t\tgoto cpt_err_unregister_interrupts;\n\n\treturn 0;\n\ncpt_err_unregister_interrupts:\n\tcpt_unregister_interrupts(cpt);\ncpt_err_release_regions:\n\tpci_release_regions(pdev);\ncpt_err_disable_device:\n\tpci_disable_device(pdev);\n\tpci_set_drvdata(pdev, NULL);\n\treturn err;\n}\n\nstatic void cpt_remove(struct pci_dev *pdev)\n{\n\tstruct cpt_device *cpt = pci_get_drvdata(pdev);\n\n\t \n\tcpt_disable_all_cores(cpt);\n\t \n\tcpt_unload_microcode(cpt);\n\tcpt_unregister_interrupts(cpt);\n\tpci_disable_sriov(pdev);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\tpci_set_drvdata(pdev, NULL);\n}\n\nstatic void cpt_shutdown(struct pci_dev *pdev)\n{\n\tstruct cpt_device *cpt = pci_get_drvdata(pdev);\n\n\tif (!cpt)\n\t\treturn;\n\n\tdev_info(&pdev->dev, \"Shutdown device %x:%x.\\n\",\n\t\t (u32)pdev->vendor, (u32)pdev->device);\n\n\tcpt_unregister_interrupts(cpt);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\tpci_set_drvdata(pdev, NULL);\n}\n\n \nstatic const struct pci_device_id cpt_id_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, CPT_81XX_PCI_PF_DEVICE_ID) },\n\t{ 0, }   \n};\n\nstatic struct pci_driver cpt_pci_driver = {\n\t.name = DRV_NAME,\n\t.id_table = cpt_id_table,\n\t.probe = cpt_probe,\n\t.remove = cpt_remove,\n\t.shutdown = cpt_shutdown,\n};\n\nmodule_pci_driver(cpt_pci_driver);\n\nMODULE_AUTHOR(\"George Cherian <george.cherian@cavium.com>\");\nMODULE_DESCRIPTION(\"Cavium Thunder CPT Physical Function Driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_VERSION(DRV_VERSION);\nMODULE_DEVICE_TABLE(pci, cpt_id_table);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}