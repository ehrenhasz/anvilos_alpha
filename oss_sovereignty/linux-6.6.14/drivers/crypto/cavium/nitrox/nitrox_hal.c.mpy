{
  "module_name": "nitrox_hal.c",
  "hash_id": "5696ff9515de636c3abf89c692f6caa21f90abd9eb70ff3dacd5b4fcecd3f899",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/cavium/nitrox/nitrox_hal.c",
  "human_readable_source": "\n#include <linux/delay.h>\n\n#include \"nitrox_dev.h\"\n#include \"nitrox_csr.h\"\n#include \"nitrox_hal.h\"\n\n#define PLL_REF_CLK 50\n#define MAX_CSR_RETRIES 10\n\n \nstatic void emu_enable_cores(struct nitrox_device *ndev)\n{\n\tunion emu_se_enable emu_se;\n\tunion emu_ae_enable emu_ae;\n\tint i;\n\n\t \n\temu_ae.value = 0;\n\temu_ae.s.enable = 0xfffff;\n\n\t \n\temu_se.value = 0;\n\temu_se.s.enable = 0xffff;\n\n\t \n\tfor (i = 0; i < NR_CLUSTERS; i++) {\n\t\tnitrox_write_csr(ndev, EMU_AE_ENABLEX(i), emu_ae.value);\n\t\tnitrox_write_csr(ndev, EMU_SE_ENABLEX(i), emu_se.value);\n\t}\n}\n\n \nvoid nitrox_config_emu_unit(struct nitrox_device *ndev)\n{\n\tunion emu_wd_int_ena_w1s emu_wd_int;\n\tunion emu_ge_int_ena_w1s emu_ge_int;\n\tu64 offset;\n\tint i;\n\n\t \n\temu_enable_cores(ndev);\n\n\t \n\temu_ge_int.value = 0;\n\temu_ge_int.s.se_ge = 0xffff;\n\temu_ge_int.s.ae_ge = 0xfffff;\n\temu_wd_int.value = 0;\n\temu_wd_int.s.se_wd = 1;\n\n\tfor (i = 0; i < NR_CLUSTERS; i++) {\n\t\toffset = EMU_WD_INT_ENA_W1SX(i);\n\t\tnitrox_write_csr(ndev, offset, emu_wd_int.value);\n\t\toffset = EMU_GE_INT_ENA_W1SX(i);\n\t\tnitrox_write_csr(ndev, offset, emu_ge_int.value);\n\t}\n}\n\nstatic void reset_pkt_input_ring(struct nitrox_device *ndev, int ring)\n{\n\tunion nps_pkt_in_instr_ctl pkt_in_ctl;\n\tunion nps_pkt_in_done_cnts pkt_in_cnts;\n\tint max_retries = MAX_CSR_RETRIES;\n\tu64 offset;\n\n\t \n\toffset = NPS_PKT_IN_INSTR_CTLX(ring);\n\tpkt_in_ctl.value = nitrox_read_csr(ndev, offset);\n\tpkt_in_ctl.s.enb = 0;\n\tnitrox_write_csr(ndev, offset, pkt_in_ctl.value);\n\n\t \n\tusleep_range(100, 150);\n\tdo {\n\t\tpkt_in_ctl.value = nitrox_read_csr(ndev, offset);\n\t\tif (!pkt_in_ctl.s.enb)\n\t\t\tbreak;\n\t\tudelay(50);\n\t} while (max_retries--);\n\n\t \n\toffset = NPS_PKT_IN_DONE_CNTSX(ring);\n\tpkt_in_cnts.value = nitrox_read_csr(ndev, offset);\n\tnitrox_write_csr(ndev, offset, pkt_in_cnts.value);\n\tusleep_range(50, 100);\n}\n\nvoid enable_pkt_input_ring(struct nitrox_device *ndev, int ring)\n{\n\tunion nps_pkt_in_instr_ctl pkt_in_ctl;\n\tint max_retries = MAX_CSR_RETRIES;\n\tu64 offset;\n\n\t \n\toffset = NPS_PKT_IN_INSTR_CTLX(ring);\n\tpkt_in_ctl.value = nitrox_read_csr(ndev, offset);\n\tpkt_in_ctl.s.is64b = 1;\n\tpkt_in_ctl.s.enb = 1;\n\tnitrox_write_csr(ndev, offset, pkt_in_ctl.value);\n\n\t \n\tdo {\n\t\tpkt_in_ctl.value = nitrox_read_csr(ndev, offset);\n\t\tif (pkt_in_ctl.s.enb)\n\t\t\tbreak;\n\t\tudelay(50);\n\t} while (max_retries--);\n}\n\n \nvoid nitrox_config_pkt_input_rings(struct nitrox_device *ndev)\n{\n\tint i;\n\n\tfor (i = 0; i < ndev->nr_queues; i++) {\n\t\tstruct nitrox_cmdq *cmdq = &ndev->pkt_inq[i];\n\t\tunion nps_pkt_in_instr_rsize pkt_in_rsize;\n\t\tunion nps_pkt_in_instr_baoff_dbell pkt_in_dbell;\n\t\tu64 offset;\n\n\t\treset_pkt_input_ring(ndev, i);\n\n\t\t \n\t\toffset = NPS_PKT_IN_INSTR_BADDRX(i);\n\t\tnitrox_write_csr(ndev, offset, cmdq->dma);\n\n\t\t \n\t\toffset = NPS_PKT_IN_INSTR_RSIZEX(i);\n\t\tpkt_in_rsize.value = 0;\n\t\tpkt_in_rsize.s.rsize = ndev->qlen;\n\t\tnitrox_write_csr(ndev, offset, pkt_in_rsize.value);\n\n\t\t \n\t\toffset = NPS_PKT_IN_INT_LEVELSX(i);\n\t\tnitrox_write_csr(ndev, offset, 0xffffffff);\n\n\t\t \n\t\toffset = NPS_PKT_IN_INSTR_BAOFF_DBELLX(i);\n\t\tpkt_in_dbell.value = 0;\n\t\tpkt_in_dbell.s.dbell = 0xffffffff;\n\t\tnitrox_write_csr(ndev, offset, pkt_in_dbell.value);\n\n\t\t \n\t\tenable_pkt_input_ring(ndev, i);\n\t}\n}\n\nstatic void reset_pkt_solicit_port(struct nitrox_device *ndev, int port)\n{\n\tunion nps_pkt_slc_ctl pkt_slc_ctl;\n\tunion nps_pkt_slc_cnts pkt_slc_cnts;\n\tint max_retries = MAX_CSR_RETRIES;\n\tu64 offset;\n\n\t \n\toffset = NPS_PKT_SLC_CTLX(port);\n\tpkt_slc_ctl.value = nitrox_read_csr(ndev, offset);\n\tpkt_slc_ctl.s.enb = 0;\n\tnitrox_write_csr(ndev, offset, pkt_slc_ctl.value);\n\n\t \n\tusleep_range(100, 150);\n\t \n\tdo {\n\t\tpkt_slc_ctl.value = nitrox_read_csr(ndev, offset);\n\t\tif (!pkt_slc_ctl.s.enb)\n\t\t\tbreak;\n\t\tudelay(50);\n\t} while (max_retries--);\n\n\t \n\toffset = NPS_PKT_SLC_CNTSX(port);\n\tpkt_slc_cnts.value = nitrox_read_csr(ndev, offset);\n\tnitrox_write_csr(ndev, offset, pkt_slc_cnts.value);\n\tusleep_range(50, 100);\n}\n\nvoid enable_pkt_solicit_port(struct nitrox_device *ndev, int port)\n{\n\tunion nps_pkt_slc_ctl pkt_slc_ctl;\n\tint max_retries = MAX_CSR_RETRIES;\n\tu64 offset;\n\n\toffset = NPS_PKT_SLC_CTLX(port);\n\tpkt_slc_ctl.value = 0;\n\tpkt_slc_ctl.s.enb = 1;\n\t \n\tpkt_slc_ctl.s.z = 1;\n\t \n\tpkt_slc_ctl.s.rh = 1;\n\tnitrox_write_csr(ndev, offset, pkt_slc_ctl.value);\n\n\t \n\tdo {\n\t\tpkt_slc_ctl.value = nitrox_read_csr(ndev, offset);\n\t\tif (pkt_slc_ctl.s.enb)\n\t\t\tbreak;\n\t\tudelay(50);\n\t} while (max_retries--);\n}\n\nstatic void config_pkt_solicit_port(struct nitrox_device *ndev, int port)\n{\n\tunion nps_pkt_slc_int_levels pkt_slc_int;\n\tu64 offset;\n\n\treset_pkt_solicit_port(ndev, port);\n\n\t \n\toffset = NPS_PKT_SLC_INT_LEVELSX(port);\n\tpkt_slc_int.value = 0;\n\t \n\tpkt_slc_int.s.timet = 0x3fffff;\n\tnitrox_write_csr(ndev, offset, pkt_slc_int.value);\n\n\t \n\tenable_pkt_solicit_port(ndev, port);\n}\n\nvoid nitrox_config_pkt_solicit_ports(struct nitrox_device *ndev)\n{\n\tint i;\n\n\tfor (i = 0; i < ndev->nr_queues; i++)\n\t\tconfig_pkt_solicit_port(ndev, i);\n}\n\n \nstatic void enable_nps_core_interrupts(struct nitrox_device *ndev)\n{\n\tunion nps_core_int_ena_w1s core_int;\n\n\t \n\tcore_int.value = 0;\n\tcore_int.s.host_wr_err = 1;\n\tcore_int.s.host_wr_timeout = 1;\n\tcore_int.s.exec_wr_timeout = 1;\n\tcore_int.s.npco_dma_malform = 1;\n\tcore_int.s.host_nps_wr_err = 1;\n\tnitrox_write_csr(ndev, NPS_CORE_INT_ENA_W1S, core_int.value);\n}\n\nvoid nitrox_config_nps_core_unit(struct nitrox_device *ndev)\n{\n\tunion nps_core_gbl_vfcfg core_gbl_vfcfg;\n\n\t \n\tnitrox_write_csr(ndev, NPS_CORE_CONTROL, 1ULL);\n\n\t \n\tcore_gbl_vfcfg.value = 0;\n\tcore_gbl_vfcfg.s.ilk_disable = 1;\n\tcore_gbl_vfcfg.s.cfg = __NDEV_MODE_PF;\n\tnitrox_write_csr(ndev, NPS_CORE_GBL_VFCFG, core_gbl_vfcfg.value);\n\n\t \n\tenable_nps_core_interrupts(ndev);\n}\n\n \nstatic void enable_nps_pkt_interrupts(struct nitrox_device *ndev)\n{\n\t \n\tnitrox_write_csr(ndev, NPS_PKT_IN_RERR_LO_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, NPS_PKT_IN_RERR_HI_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, NPS_PKT_IN_ERR_TYPE_ENA_W1S, (~0ULL));\n\t \n\tnitrox_write_csr(ndev, NPS_PKT_SLC_RERR_HI_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, NPS_PKT_SLC_RERR_LO_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, NPS_PKT_SLC_ERR_TYPE_ENA_W1S, (~0uLL));\n}\n\nvoid nitrox_config_nps_pkt_unit(struct nitrox_device *ndev)\n{\n\t \n\tnitrox_config_pkt_input_rings(ndev);\n\tnitrox_config_pkt_solicit_ports(ndev);\n\n\t \n\tenable_nps_pkt_interrupts(ndev);\n}\n\nstatic void reset_aqm_ring(struct nitrox_device *ndev, int ring)\n{\n\tunion aqmq_en aqmq_en_reg;\n\tunion aqmq_activity_stat activity_stat;\n\tunion aqmq_cmp_cnt cmp_cnt;\n\tint max_retries = MAX_CSR_RETRIES;\n\tu64 offset;\n\n\t \n\toffset = AQMQ_ENX(ring);\n\taqmq_en_reg.value = 0;\n\taqmq_en_reg.queue_enable = 0;\n\tnitrox_write_csr(ndev, offset, aqmq_en_reg.value);\n\n\t \n\tusleep_range(100, 150);\n\toffset = AQMQ_ACTIVITY_STATX(ring);\n\tdo {\n\t\tactivity_stat.value = nitrox_read_csr(ndev, offset);\n\t\tif (!activity_stat.queue_active)\n\t\t\tbreak;\n\t\tudelay(50);\n\t} while (max_retries--);\n\n\t \n\toffset = AQMQ_CMP_CNTX(ring);\n\tcmp_cnt.value = nitrox_read_csr(ndev, offset);\n\tnitrox_write_csr(ndev, offset, cmp_cnt.value);\n\tusleep_range(50, 100);\n}\n\nvoid enable_aqm_ring(struct nitrox_device *ndev, int ring)\n{\n\tunion aqmq_en aqmq_en_reg;\n\tu64 offset;\n\n\toffset = AQMQ_ENX(ring);\n\taqmq_en_reg.value = 0;\n\taqmq_en_reg.queue_enable = 1;\n\tnitrox_write_csr(ndev, offset, aqmq_en_reg.value);\n\tusleep_range(50, 100);\n}\n\nvoid nitrox_config_aqm_rings(struct nitrox_device *ndev)\n{\n\tint ring;\n\n\tfor (ring = 0; ring < ndev->nr_queues; ring++) {\n\t\tstruct nitrox_cmdq *cmdq = ndev->aqmq[ring];\n\t\tunion aqmq_drbl drbl;\n\t\tunion aqmq_qsz qsize;\n\t\tunion aqmq_cmp_thr cmp_thr;\n\t\tu64 offset;\n\n\t\t \n\t\treset_aqm_ring(ndev, ring);\n\n\t\t \n\t\toffset = AQMQ_DRBLX(ring);\n\t\tdrbl.value = 0;\n\t\tdrbl.dbell_count = 0xFFFFFFFF;\n\t\tnitrox_write_csr(ndev, offset, drbl.value);\n\n\t\t \n\n\t\t \n\t\toffset = AQMQ_NXT_CMDX(ring);\n\t\tnitrox_write_csr(ndev, offset, 0ULL);\n\n\t\t \n\t\toffset = AQMQ_BADRX(ring);\n\t\tnitrox_write_csr(ndev, offset, cmdq->dma);\n\n\t\t \n\t\toffset = AQMQ_QSZX(ring);\n\t\tqsize.value = 0;\n\t\tqsize.host_queue_size = ndev->qlen;\n\t\tnitrox_write_csr(ndev, offset, qsize.value);\n\n\t\t \n\t\toffset = AQMQ_CMP_THRX(ring);\n\t\tcmp_thr.value = 0;\n\t\tcmp_thr.commands_completed_threshold = 1;\n\t\tnitrox_write_csr(ndev, offset, cmp_thr.value);\n\n\t\t \n\t\tenable_aqm_ring(ndev, ring);\n\t}\n}\n\nstatic void enable_aqm_interrupts(struct nitrox_device *ndev)\n{\n\t \n\tnitrox_write_csr(ndev, AQM_DBELL_OVF_LO_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, AQM_DBELL_OVF_HI_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, AQM_DMA_RD_ERR_LO_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, AQM_DMA_RD_ERR_HI_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, AQM_EXEC_NA_LO_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, AQM_EXEC_NA_HI_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, AQM_EXEC_ERR_LO_ENA_W1S, (~0ULL));\n\tnitrox_write_csr(ndev, AQM_EXEC_ERR_HI_ENA_W1S, (~0ULL));\n}\n\nvoid nitrox_config_aqm_unit(struct nitrox_device *ndev)\n{\n\t \n\tnitrox_config_aqm_rings(ndev);\n\n\t \n\tenable_aqm_interrupts(ndev);\n}\n\nvoid nitrox_config_pom_unit(struct nitrox_device *ndev)\n{\n\tunion pom_int_ena_w1s pom_int;\n\tint i;\n\n\t \n\tpom_int.value = 0;\n\tpom_int.s.illegal_dport = 1;\n\tnitrox_write_csr(ndev, POM_INT_ENA_W1S, pom_int.value);\n\n\t \n\tfor (i = 0; i < ndev->hw.se_cores; i++)\n\t\tnitrox_write_csr(ndev, POM_PERF_CTL, BIT_ULL(i));\n}\n\n \nvoid nitrox_config_rand_unit(struct nitrox_device *ndev)\n{\n\tunion efl_rnm_ctl_status efl_rnm_ctl;\n\tu64 offset;\n\n\toffset = EFL_RNM_CTL_STATUS;\n\tefl_rnm_ctl.value = nitrox_read_csr(ndev, offset);\n\tefl_rnm_ctl.s.ent_en = 1;\n\tefl_rnm_ctl.s.rng_en = 1;\n\tnitrox_write_csr(ndev, offset, efl_rnm_ctl.value);\n}\n\nvoid nitrox_config_efl_unit(struct nitrox_device *ndev)\n{\n\tint i;\n\n\tfor (i = 0; i < NR_CLUSTERS; i++) {\n\t\tunion efl_core_int_ena_w1s efl_core_int;\n\t\tu64 offset;\n\n\t\t \n\t\toffset = EFL_CORE_INT_ENA_W1SX(i);\n\t\tefl_core_int.value = 0;\n\t\tefl_core_int.s.len_ovr = 1;\n\t\tefl_core_int.s.d_left = 1;\n\t\tefl_core_int.s.epci_decode_err = 1;\n\t\tnitrox_write_csr(ndev, offset, efl_core_int.value);\n\n\t\toffset = EFL_CORE_VF_ERR_INT0_ENA_W1SX(i);\n\t\tnitrox_write_csr(ndev, offset, (~0ULL));\n\t\toffset = EFL_CORE_VF_ERR_INT1_ENA_W1SX(i);\n\t\tnitrox_write_csr(ndev, offset, (~0ULL));\n\t}\n}\n\nvoid nitrox_config_bmi_unit(struct nitrox_device *ndev)\n{\n\tunion bmi_ctl bmi_ctl;\n\tunion bmi_int_ena_w1s bmi_int_ena;\n\tu64 offset;\n\n\t \n\toffset = BMI_CTL;\n\tbmi_ctl.value = nitrox_read_csr(ndev, offset);\n\tbmi_ctl.s.max_pkt_len = 0xff;\n\tbmi_ctl.s.nps_free_thrsh = 0xff;\n\tbmi_ctl.s.nps_hdrq_thrsh = 0x7a;\n\tnitrox_write_csr(ndev, offset, bmi_ctl.value);\n\n\t \n\toffset = BMI_INT_ENA_W1S;\n\tbmi_int_ena.value = 0;\n\tbmi_int_ena.s.max_len_err_nps = 1;\n\tbmi_int_ena.s.pkt_rcv_err_nps = 1;\n\tbmi_int_ena.s.fpf_undrrn = 1;\n\tnitrox_write_csr(ndev, offset, bmi_int_ena.value);\n}\n\nvoid nitrox_config_bmo_unit(struct nitrox_device *ndev)\n{\n\tunion bmo_ctl2 bmo_ctl2;\n\tu64 offset;\n\n\t \n\toffset = BMO_CTL2;\n\tbmo_ctl2.value = nitrox_read_csr(ndev, offset);\n\tbmo_ctl2.s.nps_slc_buf_thrsh = 0xff;\n\tnitrox_write_csr(ndev, offset, bmo_ctl2.value);\n}\n\nvoid invalidate_lbc(struct nitrox_device *ndev)\n{\n\tunion lbc_inval_ctl lbc_ctl;\n\tunion lbc_inval_status lbc_stat;\n\tint max_retries = MAX_CSR_RETRIES;\n\tu64 offset;\n\n\t \n\toffset = LBC_INVAL_CTL;\n\tlbc_ctl.value = nitrox_read_csr(ndev, offset);\n\tlbc_ctl.s.cam_inval_start = 1;\n\tnitrox_write_csr(ndev, offset, lbc_ctl.value);\n\n\toffset = LBC_INVAL_STATUS;\n\tdo {\n\t\tlbc_stat.value = nitrox_read_csr(ndev, offset);\n\t\tif (lbc_stat.s.done)\n\t\t\tbreak;\n\t\tudelay(50);\n\t} while (max_retries--);\n}\n\nvoid nitrox_config_lbc_unit(struct nitrox_device *ndev)\n{\n\tunion lbc_int_ena_w1s lbc_int_ena;\n\tu64 offset;\n\n\tinvalidate_lbc(ndev);\n\n\t \n\toffset = LBC_INT_ENA_W1S;\n\tlbc_int_ena.value = 0;\n\tlbc_int_ena.s.dma_rd_err = 1;\n\tlbc_int_ena.s.over_fetch_err = 1;\n\tlbc_int_ena.s.cam_inval_abort = 1;\n\tlbc_int_ena.s.cam_hard_err = 1;\n\tnitrox_write_csr(ndev, offset, lbc_int_ena.value);\n\n\toffset = LBC_PLM_VF1_64_INT_ENA_W1S;\n\tnitrox_write_csr(ndev, offset, (~0ULL));\n\toffset = LBC_PLM_VF65_128_INT_ENA_W1S;\n\tnitrox_write_csr(ndev, offset, (~0ULL));\n\n\toffset = LBC_ELM_VF1_64_INT_ENA_W1S;\n\tnitrox_write_csr(ndev, offset, (~0ULL));\n\toffset = LBC_ELM_VF65_128_INT_ENA_W1S;\n\tnitrox_write_csr(ndev, offset, (~0ULL));\n}\n\nvoid config_nps_core_vfcfg_mode(struct nitrox_device *ndev, enum vf_mode mode)\n{\n\tunion nps_core_gbl_vfcfg vfcfg;\n\n\tvfcfg.value = nitrox_read_csr(ndev, NPS_CORE_GBL_VFCFG);\n\tvfcfg.s.cfg = mode & 0x7;\n\n\tnitrox_write_csr(ndev, NPS_CORE_GBL_VFCFG, vfcfg.value);\n}\n\nstatic const char *get_core_option(u8 se_cores, u8 ae_cores)\n{\n\tconst char *option = \"\";\n\n\tif (ae_cores == AE_MAX_CORES) {\n\t\tswitch (se_cores) {\n\t\tcase SE_MAX_CORES:\n\t\t\toption = \"60\";\n\t\t\tbreak;\n\t\tcase 40:\n\t\t\toption = \"60s\";\n\t\t\tbreak;\n\t\t}\n\t} else if (ae_cores == (AE_MAX_CORES / 2)) {\n\t\toption = \"30\";\n\t} else {\n\t\toption = \"60i\";\n\t}\n\n\treturn option;\n}\n\nstatic const char *get_feature_option(u8 zip_cores, int core_freq)\n{\n\tif (zip_cores == 0)\n\t\treturn \"\";\n\telse if (zip_cores < ZIP_MAX_CORES)\n\t\treturn \"-C15\";\n\n\tif (core_freq >= 850)\n\t\treturn \"-C45\";\n\telse if (core_freq >= 750)\n\t\treturn \"-C35\";\n\telse if (core_freq >= 550)\n\t\treturn \"-C25\";\n\n\treturn \"\";\n}\n\nvoid nitrox_get_hwinfo(struct nitrox_device *ndev)\n{\n\tunion emu_fuse_map emu_fuse;\n\tunion rst_boot rst_boot;\n\tunion fus_dat1 fus_dat1;\n\tunsigned char name[IFNAMSIZ * 2] = {};\n\tint i, dead_cores;\n\tu64 offset;\n\n\t \n\toffset = RST_BOOT;\n\trst_boot.value = nitrox_read_csr(ndev, offset);\n\tndev->hw.freq = (rst_boot.pnr_mul + 3) * PLL_REF_CLK;\n\n\tfor (i = 0; i < NR_CLUSTERS; i++) {\n\t\toffset = EMU_FUSE_MAPX(i);\n\t\temu_fuse.value = nitrox_read_csr(ndev, offset);\n\t\tif (emu_fuse.s.valid) {\n\t\t\tdead_cores = hweight32(emu_fuse.s.ae_fuse);\n\t\t\tndev->hw.ae_cores += AE_CORES_PER_CLUSTER - dead_cores;\n\t\t\tdead_cores = hweight16(emu_fuse.s.se_fuse);\n\t\t\tndev->hw.se_cores += SE_CORES_PER_CLUSTER - dead_cores;\n\t\t}\n\t}\n\t \n\toffset = FUS_DAT1;\n\tfus_dat1.value = nitrox_read_csr(ndev, offset);\n\tif (!fus_dat1.nozip) {\n\t\tdead_cores = hweight8(fus_dat1.zip_info);\n\t\tndev->hw.zip_cores = ZIP_MAX_CORES - dead_cores;\n\t}\n\n\t \n\tsnprintf(name, sizeof(name), \"CNN55%s-%3dBG676%s-1.%u\",\n\t\t get_core_option(ndev->hw.se_cores, ndev->hw.ae_cores),\n\t\t ndev->hw.freq,\n\t\t get_feature_option(ndev->hw.zip_cores, ndev->hw.freq),\n\t\t ndev->hw.revision_id);\n\n\t \n\tstrncpy(ndev->hw.partname, name, sizeof(ndev->hw.partname));\n}\n\nvoid enable_pf2vf_mbox_interrupts(struct nitrox_device *ndev)\n{\n\tu64 value = ~0ULL;\n\tu64 reg_addr;\n\n\t \n\treg_addr = NPS_PKT_MBOX_INT_LO_ENA_W1S;\n\tnitrox_write_csr(ndev, reg_addr, value);\n\n\t \n\treg_addr = NPS_PKT_MBOX_INT_HI_ENA_W1S;\n\tnitrox_write_csr(ndev, reg_addr, value);\n}\n\nvoid disable_pf2vf_mbox_interrupts(struct nitrox_device *ndev)\n{\n\tu64 value = ~0ULL;\n\tu64 reg_addr;\n\n\t \n\treg_addr = NPS_PKT_MBOX_INT_LO_ENA_W1C;\n\tnitrox_write_csr(ndev, reg_addr, value);\n\n\t \n\treg_addr = NPS_PKT_MBOX_INT_HI_ENA_W1C;\n\tnitrox_write_csr(ndev, reg_addr, value);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}