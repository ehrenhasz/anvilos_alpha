{
  "module_name": "nitrox_mbx.c",
  "hash_id": "c56c69c806a7382d615eb70ff6abd4582b84a94398bd0ae25cc6d762d13550de",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/cavium/nitrox/nitrox_mbx.c",
  "human_readable_source": "\n#include <linux/bitmap.h>\n#include <linux/workqueue.h>\n\n#include \"nitrox_csr.h\"\n#include \"nitrox_hal.h\"\n#include \"nitrox_dev.h\"\n#include \"nitrox_mbx.h\"\n\n#define RING_TO_VFNO(_x, _y)\t((_x) / (_y))\n\n \nenum mbx_msg_type {\n\tMBX_MSG_TYPE_NOP,\n\tMBX_MSG_TYPE_REQ,\n\tMBX_MSG_TYPE_ACK,\n\tMBX_MSG_TYPE_NACK,\n};\n\n \nenum mbx_msg_opcode {\n\tMSG_OP_VF_MODE = 1,\n\tMSG_OP_VF_UP,\n\tMSG_OP_VF_DOWN,\n\tMSG_OP_CHIPID_VFID,\n\tMSG_OP_MCODE_INFO = 11,\n};\n\nstruct pf2vf_work {\n\tstruct nitrox_vfdev *vfdev;\n\tstruct nitrox_device *ndev;\n\tstruct work_struct pf2vf_resp;\n};\n\nstatic inline u64 pf2vf_read_mbox(struct nitrox_device *ndev, int ring)\n{\n\tu64 reg_addr;\n\n\treg_addr = NPS_PKT_MBOX_VF_PF_PFDATAX(ring);\n\treturn nitrox_read_csr(ndev, reg_addr);\n}\n\nstatic inline void pf2vf_write_mbox(struct nitrox_device *ndev, u64 value,\n\t\t\t\t    int ring)\n{\n\tu64 reg_addr;\n\n\treg_addr = NPS_PKT_MBOX_PF_VF_PFDATAX(ring);\n\tnitrox_write_csr(ndev, reg_addr, value);\n}\n\nstatic void pf2vf_send_response(struct nitrox_device *ndev,\n\t\t\t\tstruct nitrox_vfdev *vfdev)\n{\n\tunion mbox_msg msg;\n\n\tmsg.value = vfdev->msg.value;\n\n\tswitch (vfdev->msg.opcode) {\n\tcase MSG_OP_VF_MODE:\n\t\tmsg.data = ndev->mode;\n\t\tbreak;\n\tcase MSG_OP_VF_UP:\n\t\tvfdev->nr_queues = vfdev->msg.data;\n\t\tatomic_set(&vfdev->state, __NDEV_READY);\n\t\tbreak;\n\tcase MSG_OP_CHIPID_VFID:\n\t\tmsg.id.chipid = ndev->idx;\n\t\tmsg.id.vfid = vfdev->vfno;\n\t\tbreak;\n\tcase MSG_OP_VF_DOWN:\n\t\tvfdev->nr_queues = 0;\n\t\tatomic_set(&vfdev->state, __NDEV_NOT_READY);\n\t\tbreak;\n\tcase MSG_OP_MCODE_INFO:\n\t\tmsg.data = 0;\n\t\tmsg.mcode_info.count = 2;\n\t\tmsg.mcode_info.info = MCODE_TYPE_SE_SSL | (MCODE_TYPE_AE << 5);\n\t\tmsg.mcode_info.next_se_grp = 1;\n\t\tmsg.mcode_info.next_ae_grp = 1;\n\t\tbreak;\n\tdefault:\n\t\tmsg.type = MBX_MSG_TYPE_NOP;\n\t\tbreak;\n\t}\n\n\tif (msg.type == MBX_MSG_TYPE_NOP)\n\t\treturn;\n\n\t \n\tmsg.type = MBX_MSG_TYPE_ACK;\n\tpf2vf_write_mbox(ndev, msg.value, vfdev->ring);\n\n\tvfdev->msg.value = 0;\n\tatomic64_inc(&vfdev->mbx_resp);\n}\n\nstatic void pf2vf_resp_handler(struct work_struct *work)\n{\n\tstruct pf2vf_work *pf2vf_resp = container_of(work, struct pf2vf_work,\n\t\t\t\t\t\t     pf2vf_resp);\n\tstruct nitrox_vfdev *vfdev = pf2vf_resp->vfdev;\n\tstruct nitrox_device *ndev = pf2vf_resp->ndev;\n\n\tswitch (vfdev->msg.type) {\n\tcase MBX_MSG_TYPE_REQ:\n\t\t \n\t\tpf2vf_send_response(ndev, vfdev);\n\t\tbreak;\n\tcase MBX_MSG_TYPE_ACK:\n\tcase MBX_MSG_TYPE_NACK:\n\t\tbreak;\n\t}\n\n\tkfree(pf2vf_resp);\n}\n\nvoid nitrox_pf2vf_mbox_handler(struct nitrox_device *ndev)\n{\n\tDECLARE_BITMAP(csr, BITS_PER_TYPE(u64));\n\tstruct nitrox_vfdev *vfdev;\n\tstruct pf2vf_work *pfwork;\n\tu64 value, reg_addr;\n\tu32 i;\n\tint vfno;\n\n\t \n\treg_addr = NPS_PKT_MBOX_INT_LO;\n\tvalue = nitrox_read_csr(ndev, reg_addr);\n\tbitmap_from_u64(csr, value);\n\tfor_each_set_bit(i, csr, BITS_PER_TYPE(csr)) {\n\t\t \n\t\tvfno = RING_TO_VFNO(i, ndev->iov.max_vf_queues);\n\t\tvfdev = ndev->iov.vfdev + vfno;\n\t\tvfdev->ring = i;\n\t\t \n\t\tvfdev->msg.value = pf2vf_read_mbox(ndev, vfdev->ring);\n\t\tpfwork = kzalloc(sizeof(*pfwork), GFP_ATOMIC);\n\t\tif (!pfwork)\n\t\t\tcontinue;\n\n\t\tpfwork->vfdev = vfdev;\n\t\tpfwork->ndev = ndev;\n\t\tINIT_WORK(&pfwork->pf2vf_resp, pf2vf_resp_handler);\n\t\tqueue_work(ndev->iov.pf2vf_wq, &pfwork->pf2vf_resp);\n\t\t \n\t\tnitrox_write_csr(ndev, reg_addr, BIT_ULL(i));\n\t}\n\n\t \n\treg_addr = NPS_PKT_MBOX_INT_HI;\n\tvalue = nitrox_read_csr(ndev, reg_addr);\n\tbitmap_from_u64(csr, value);\n\tfor_each_set_bit(i, csr, BITS_PER_TYPE(csr)) {\n\t\t \n\t\tvfno = RING_TO_VFNO(i + 64, ndev->iov.max_vf_queues);\n\t\tvfdev = ndev->iov.vfdev + vfno;\n\t\tvfdev->ring = (i + 64);\n\t\t \n\t\tvfdev->msg.value = pf2vf_read_mbox(ndev, vfdev->ring);\n\n\t\tpfwork = kzalloc(sizeof(*pfwork), GFP_ATOMIC);\n\t\tif (!pfwork)\n\t\t\tcontinue;\n\n\t\tpfwork->vfdev = vfdev;\n\t\tpfwork->ndev = ndev;\n\t\tINIT_WORK(&pfwork->pf2vf_resp, pf2vf_resp_handler);\n\t\tqueue_work(ndev->iov.pf2vf_wq, &pfwork->pf2vf_resp);\n\t\t \n\t\tnitrox_write_csr(ndev, reg_addr, BIT_ULL(i));\n\t}\n}\n\nint nitrox_mbox_init(struct nitrox_device *ndev)\n{\n\tstruct nitrox_vfdev *vfdev;\n\tint i;\n\n\tndev->iov.vfdev = kcalloc(ndev->iov.num_vfs,\n\t\t\t\t  sizeof(struct nitrox_vfdev), GFP_KERNEL);\n\tif (!ndev->iov.vfdev)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < ndev->iov.num_vfs; i++) {\n\t\tvfdev = ndev->iov.vfdev + i;\n\t\tvfdev->vfno = i;\n\t}\n\n\t \n\tndev->iov.pf2vf_wq = alloc_workqueue(\"nitrox_pf2vf\", 0, 0);\n\tif (!ndev->iov.pf2vf_wq) {\n\t\tkfree(ndev->iov.vfdev);\n\t\tndev->iov.vfdev = NULL;\n\t\treturn -ENOMEM;\n\t}\n\t \n\tenable_pf2vf_mbox_interrupts(ndev);\n\n\treturn 0;\n}\n\nvoid nitrox_mbox_cleanup(struct nitrox_device *ndev)\n{\n\t \n\tdisable_pf2vf_mbox_interrupts(ndev);\n\t \n\tif (ndev->iov.pf2vf_wq)\n\t\tdestroy_workqueue(ndev->iov.pf2vf_wq);\n\n\tkfree(ndev->iov.vfdev);\n\tndev->iov.pf2vf_wq = NULL;\n\tndev->iov.vfdev = NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}