{
  "module_name": "otx2_cptlf.h",
  "hash_id": "70a952a6d9591560c860db6e66281707cfa3a45874a072bf30bb6135fd265d83",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/marvell/octeontx2/otx2_cptlf.h",
  "human_readable_source": " \n#ifndef __OTX2_CPTLF_H\n#define __OTX2_CPTLF_H\n\n#include <linux/soc/marvell/octeontx2/asm.h>\n#include <mbox.h>\n#include <rvu.h>\n#include \"otx2_cpt_common.h\"\n#include \"otx2_cpt_reqmgr.h\"\n\n \n#define OTX2_CPT_USER_REQUESTED_QLEN_MSGS 8200\n\n \n#define OTX2_CPT_SIZE_DIV40 (OTX2_CPT_USER_REQUESTED_QLEN_MSGS/40)\n\n \n#define OTX2_CPT_INST_QLEN_MSGS\t((OTX2_CPT_SIZE_DIV40 - 1) * 40)\n\n \n#define OTX2_CPT_INST_QLEN_EXTRA_BYTES  (320 * OTX2_CPT_INST_SIZE)\n#define OTX2_CPT_EXTRA_SIZE_DIV40       (320/40)\n\n \n#define OTX2_CPT_INST_QLEN_BYTES                                               \\\n\t\t((OTX2_CPT_SIZE_DIV40 * 40 * OTX2_CPT_INST_SIZE) +             \\\n\t\tOTX2_CPT_INST_QLEN_EXTRA_BYTES)\n\n \n#define OTX2_CPT_INST_GRP_QLEN_BYTES                                           \\\n\t\t((OTX2_CPT_SIZE_DIV40 + OTX2_CPT_EXTRA_SIZE_DIV40) * 16)\n\n \n#define OTX2_CPT_Q_FC_LEN 128\n\n \n#define OTX2_CPT_INST_Q_ALIGNMENT  128\n\n \n#define OTX2_CPT_ALL_ENG_GRPS_MASK 0xFF\n\n \n#define OTX2_CPT_MAX_LFS_NUM    64\n\n \n#define OTX2_CPT_QUEUE_HI_PRIO  0x1\n#define OTX2_CPT_QUEUE_LOW_PRIO 0x0\n\nenum otx2_cptlf_state {\n\tOTX2_CPTLF_IN_RESET,\n\tOTX2_CPTLF_STARTED,\n};\n\nstruct otx2_cpt_inst_queue {\n\tu8 *vaddr;\n\tu8 *real_vaddr;\n\tdma_addr_t dma_addr;\n\tdma_addr_t real_dma_addr;\n\tu32 size;\n};\n\nstruct otx2_cptlfs_info;\nstruct otx2_cptlf_wqe {\n\tstruct tasklet_struct work;\n\tstruct otx2_cptlfs_info *lfs;\n\tu8 lf_num;\n};\n\nstruct otx2_cptlf_info {\n\tstruct otx2_cptlfs_info *lfs;            \n\tvoid __iomem *lmtline;                   \n\tvoid __iomem *ioreg;                     \n\tint msix_offset;                         \n\tcpumask_var_t affinity_mask;             \n\tu8 irq_name[OTX2_CPT_LF_MSIX_VECTORS][32]; \n\tu8 is_irq_reg[OTX2_CPT_LF_MSIX_VECTORS];   \n\tu8 slot;                                 \n\n\tstruct otx2_cpt_inst_queue iqueue; \n\tstruct otx2_cpt_pending_queue pqueue;  \n\tstruct otx2_cptlf_wqe *wqe;        \n};\n\nstruct cpt_hw_ops {\n\tvoid (*send_cmd)(union otx2_cpt_inst_s *cptinst, u32 insts_num,\n\t\t\t struct otx2_cptlf_info *lf);\n\tu8 (*cpt_get_compcode)(union otx2_cpt_res_s *result);\n\tu8 (*cpt_get_uc_compcode)(union otx2_cpt_res_s *result);\n};\n\nstruct otx2_cptlfs_info {\n\t \n\tvoid __iomem *reg_base;\n#define LMTLINE_SIZE  128\n\tvoid __iomem *lmt_base;\n\tstruct pci_dev *pdev;    \n\tstruct otx2_cptlf_info lf[OTX2_CPT_MAX_LFS_NUM];\n\tstruct otx2_mbox *mbox;\n\tstruct cpt_hw_ops *ops;\n\tu8 are_lfs_attached;\t \n\tu8 lfs_num;\t\t \n\tu8 kcrypto_eng_grp_num;\t \n\tu8 kvf_limits;           \n\tatomic_t state;          \n\tint blkaddr;             \n};\n\nstatic inline void otx2_cpt_free_instruction_queues(\n\t\t\t\t\tstruct otx2_cptlfs_info *lfs)\n{\n\tstruct otx2_cpt_inst_queue *iq;\n\tint i;\n\n\tfor (i = 0; i < lfs->lfs_num; i++) {\n\t\tiq = &lfs->lf[i].iqueue;\n\t\tif (iq->real_vaddr)\n\t\t\tdma_free_coherent(&lfs->pdev->dev,\n\t\t\t\t\t  iq->size,\n\t\t\t\t\t  iq->real_vaddr,\n\t\t\t\t\t  iq->real_dma_addr);\n\t\tiq->real_vaddr = NULL;\n\t\tiq->vaddr = NULL;\n\t}\n}\n\nstatic inline int otx2_cpt_alloc_instruction_queues(\n\t\t\t\t\tstruct otx2_cptlfs_info *lfs)\n{\n\tstruct otx2_cpt_inst_queue *iq;\n\tint ret = 0, i;\n\n\tif (!lfs->lfs_num)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < lfs->lfs_num; i++) {\n\t\tiq = &lfs->lf[i].iqueue;\n\t\tiq->size = OTX2_CPT_INST_QLEN_BYTES +\n\t\t\t   OTX2_CPT_Q_FC_LEN +\n\t\t\t   OTX2_CPT_INST_GRP_QLEN_BYTES +\n\t\t\t   OTX2_CPT_INST_Q_ALIGNMENT;\n\t\tiq->real_vaddr = dma_alloc_coherent(&lfs->pdev->dev, iq->size,\n\t\t\t\t\t&iq->real_dma_addr, GFP_KERNEL);\n\t\tif (!iq->real_vaddr) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto error;\n\t\t}\n\t\tiq->vaddr = iq->real_vaddr + OTX2_CPT_INST_GRP_QLEN_BYTES;\n\t\tiq->dma_addr = iq->real_dma_addr + OTX2_CPT_INST_GRP_QLEN_BYTES;\n\n\t\t \n\t\tiq->vaddr = PTR_ALIGN(iq->vaddr, OTX2_CPT_INST_Q_ALIGNMENT);\n\t\tiq->dma_addr = PTR_ALIGN(iq->dma_addr,\n\t\t\t\t\t OTX2_CPT_INST_Q_ALIGNMENT);\n\t}\n\treturn 0;\n\nerror:\n\totx2_cpt_free_instruction_queues(lfs);\n\treturn ret;\n}\n\nstatic inline void otx2_cptlf_set_iqueues_base_addr(\n\t\t\t\t\tstruct otx2_cptlfs_info *lfs)\n{\n\tunion otx2_cptx_lf_q_base lf_q_base;\n\tint slot;\n\n\tfor (slot = 0; slot < lfs->lfs_num; slot++) {\n\t\tlf_q_base.u = lfs->lf[slot].iqueue.dma_addr;\n\t\totx2_cpt_write64(lfs->reg_base, lfs->blkaddr, slot,\n\t\t\t\t OTX2_CPT_LF_Q_BASE, lf_q_base.u);\n\t}\n}\n\nstatic inline void otx2_cptlf_do_set_iqueue_size(struct otx2_cptlf_info *lf)\n{\n\tunion otx2_cptx_lf_q_size lf_q_size = { .u = 0x0 };\n\n\tlf_q_size.s.size_div40 = OTX2_CPT_SIZE_DIV40 +\n\t\t\t\t OTX2_CPT_EXTRA_SIZE_DIV40;\n\totx2_cpt_write64(lf->lfs->reg_base, lf->lfs->blkaddr, lf->slot,\n\t\t\t OTX2_CPT_LF_Q_SIZE, lf_q_size.u);\n}\n\nstatic inline void otx2_cptlf_set_iqueues_size(struct otx2_cptlfs_info *lfs)\n{\n\tint slot;\n\n\tfor (slot = 0; slot < lfs->lfs_num; slot++)\n\t\totx2_cptlf_do_set_iqueue_size(&lfs->lf[slot]);\n}\n\nstatic inline void otx2_cptlf_do_disable_iqueue(struct otx2_cptlf_info *lf)\n{\n\tunion otx2_cptx_lf_ctl lf_ctl = { .u = 0x0 };\n\tunion otx2_cptx_lf_inprog lf_inprog;\n\tu8 blkaddr = lf->lfs->blkaddr;\n\tint timeout = 20;\n\n\t \n\totx2_cpt_write64(lf->lfs->reg_base, blkaddr, lf->slot,\n\t\t\t OTX2_CPT_LF_CTL, lf_ctl.u);\n\n\t \n\tdo {\n\t\tlf_inprog.u = otx2_cpt_read64(lf->lfs->reg_base, blkaddr,\n\t\t\t\t\t      lf->slot, OTX2_CPT_LF_INPROG);\n\t\tif (!lf_inprog.s.inflight)\n\t\t\tbreak;\n\n\t\tusleep_range(10000, 20000);\n\t\tif (timeout-- < 0) {\n\t\t\tdev_err(&lf->lfs->pdev->dev,\n\t\t\t\t\"Error LF %d is still busy.\\n\", lf->slot);\n\t\t\tbreak;\n\t\t}\n\n\t} while (1);\n\n\t \n\tlf_inprog.s.eena = 0x0;\n\totx2_cpt_write64(lf->lfs->reg_base, blkaddr, lf->slot,\n\t\t\t OTX2_CPT_LF_INPROG, lf_inprog.u);\n}\n\nstatic inline void otx2_cptlf_disable_iqueues(struct otx2_cptlfs_info *lfs)\n{\n\tint slot;\n\n\tfor (slot = 0; slot < lfs->lfs_num; slot++)\n\t\totx2_cptlf_do_disable_iqueue(&lfs->lf[slot]);\n}\n\nstatic inline void otx2_cptlf_set_iqueue_enq(struct otx2_cptlf_info *lf,\n\t\t\t\t\t     bool enable)\n{\n\tu8 blkaddr = lf->lfs->blkaddr;\n\tunion otx2_cptx_lf_ctl lf_ctl;\n\n\tlf_ctl.u = otx2_cpt_read64(lf->lfs->reg_base, blkaddr, lf->slot,\n\t\t\t\t   OTX2_CPT_LF_CTL);\n\n\t \n\tlf_ctl.s.ena = enable ? 0x1 : 0x0;\n\totx2_cpt_write64(lf->lfs->reg_base, blkaddr, lf->slot,\n\t\t\t OTX2_CPT_LF_CTL, lf_ctl.u);\n}\n\nstatic inline void otx2_cptlf_enable_iqueue_enq(struct otx2_cptlf_info *lf)\n{\n\totx2_cptlf_set_iqueue_enq(lf, true);\n}\n\nstatic inline void otx2_cptlf_set_iqueue_exec(struct otx2_cptlf_info *lf,\n\t\t\t\t\t      bool enable)\n{\n\tunion otx2_cptx_lf_inprog lf_inprog;\n\tu8 blkaddr = lf->lfs->blkaddr;\n\n\tlf_inprog.u = otx2_cpt_read64(lf->lfs->reg_base, blkaddr, lf->slot,\n\t\t\t\t      OTX2_CPT_LF_INPROG);\n\n\t \n\tlf_inprog.s.eena = enable ? 0x1 : 0x0;\n\totx2_cpt_write64(lf->lfs->reg_base, blkaddr, lf->slot,\n\t\t\t OTX2_CPT_LF_INPROG, lf_inprog.u);\n}\n\nstatic inline void otx2_cptlf_enable_iqueue_exec(struct otx2_cptlf_info *lf)\n{\n\totx2_cptlf_set_iqueue_exec(lf, true);\n}\n\nstatic inline void otx2_cptlf_disable_iqueue_exec(struct otx2_cptlf_info *lf)\n{\n\totx2_cptlf_set_iqueue_exec(lf, false);\n}\n\nstatic inline void otx2_cptlf_enable_iqueues(struct otx2_cptlfs_info *lfs)\n{\n\tint slot;\n\n\tfor (slot = 0; slot < lfs->lfs_num; slot++) {\n\t\totx2_cptlf_enable_iqueue_exec(&lfs->lf[slot]);\n\t\totx2_cptlf_enable_iqueue_enq(&lfs->lf[slot]);\n\t}\n}\n\nstatic inline void otx2_cpt_fill_inst(union otx2_cpt_inst_s *cptinst,\n\t\t\t\t      struct otx2_cpt_iq_command *iq_cmd,\n\t\t\t\t      u64 comp_baddr)\n{\n\tcptinst->u[0] = 0x0;\n\tcptinst->s.doneint = true;\n\tcptinst->s.res_addr = comp_baddr;\n\tcptinst->u[2] = 0x0;\n\tcptinst->u[3] = 0x0;\n\tcptinst->s.ei0 = iq_cmd->cmd.u;\n\tcptinst->s.ei1 = iq_cmd->dptr;\n\tcptinst->s.ei2 = iq_cmd->rptr;\n\tcptinst->s.ei3 = iq_cmd->cptr.u;\n}\n\n \nstatic inline void otx2_cpt_send_cmd(union otx2_cpt_inst_s *cptinst,\n\t\t\t\t     u32 insts_num, struct otx2_cptlf_info *lf)\n{\n\tvoid __iomem *lmtline = lf->lmtline;\n\tlong ret;\n\n\t \n\tdma_wmb();\n\n\tdo {\n\t\t \n\t\tmemcpy_toio(lmtline, cptinst, insts_num * OTX2_CPT_INST_SIZE);\n\n\t\t \n\t\tret = otx2_lmt_flush(lf->ioreg);\n\n\t} while (!ret);\n}\n\nstatic inline bool otx2_cptlf_started(struct otx2_cptlfs_info *lfs)\n{\n\treturn atomic_read(&lfs->state) == OTX2_CPTLF_STARTED;\n}\n\nstatic inline void otx2_cptlf_set_dev_info(struct otx2_cptlfs_info *lfs,\n\t\t\t\t\t   struct pci_dev *pdev,\n\t\t\t\t\t   void __iomem *reg_base,\n\t\t\t\t\t   struct otx2_mbox *mbox,\n\t\t\t\t\t   int blkaddr)\n{\n\tlfs->pdev = pdev;\n\tlfs->reg_base = reg_base;\n\tlfs->mbox = mbox;\n\tlfs->blkaddr = blkaddr;\n}\n\nint otx2_cptlf_init(struct otx2_cptlfs_info *lfs, u8 eng_grp_msk, int pri,\n\t\t    int lfs_num);\nvoid otx2_cptlf_shutdown(struct otx2_cptlfs_info *lfs);\nint otx2_cptlf_register_interrupts(struct otx2_cptlfs_info *lfs);\nvoid otx2_cptlf_unregister_interrupts(struct otx2_cptlfs_info *lfs);\nvoid otx2_cptlf_free_irqs_affinity(struct otx2_cptlfs_info *lfs);\nint otx2_cptlf_set_irqs_affinity(struct otx2_cptlfs_info *lfs);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}