{
  "module_name": "otx2_cptpf_main.c",
  "hash_id": "01c643d56062118913cbd528d9e3372e868004cb6245ac3a29781211fa627303",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/marvell/octeontx2/otx2_cptpf_main.c",
  "human_readable_source": "\n \n\n#include <linux/firmware.h>\n#include \"otx2_cpt_hw_types.h\"\n#include \"otx2_cpt_common.h\"\n#include \"otx2_cpt_devlink.h\"\n#include \"otx2_cptpf_ucode.h\"\n#include \"otx2_cptpf.h\"\n#include \"cn10k_cpt.h\"\n#include \"rvu_reg.h\"\n\n#define OTX2_CPT_DRV_NAME    \"rvu_cptpf\"\n#define OTX2_CPT_DRV_STRING  \"Marvell RVU CPT Physical Function Driver\"\n\n#define CPT_UC_RID_CN9K_B0   1\n\nstatic void cptpf_enable_vfpf_mbox_intr(struct otx2_cptpf_dev *cptpf,\n\t\t\t\t\tint num_vfs)\n{\n\tint ena_bits;\n\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFPF_MBOX_INTX(0), ~0x0ULL);\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFPF_MBOX_INTX(1), ~0x0ULL);\n\n\t \n\tena_bits = ((num_vfs - 1) % 64);\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFPF_MBOX_INT_ENA_W1SX(0),\n\t\t\t GENMASK_ULL(ena_bits, 0));\n\n\tif (num_vfs > 64) {\n\t\t \n\t\tena_bits = num_vfs - 64 - 1;\n\t\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\tRVU_PF_VFPF_MBOX_INT_ENA_W1SX(1),\n\t\t\t\tGENMASK_ULL(ena_bits, 0));\n\t}\n}\n\nstatic void cptpf_disable_vfpf_mbox_intr(struct otx2_cptpf_dev *cptpf,\n\t\t\t\t\t int num_vfs)\n{\n\tint vector;\n\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFPF_MBOX_INT_ENA_W1CX(0), ~0ULL);\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFPF_MBOX_INT_ENA_W1CX(1), ~0ULL);\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFPF_MBOX_INTX(0), ~0ULL);\n\n\tvector = pci_irq_vector(cptpf->pdev, RVU_PF_INT_VEC_VFPF_MBOX0);\n\tfree_irq(vector, cptpf);\n\n\tif (num_vfs > 64) {\n\t\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t RVU_PF_VFPF_MBOX_INTX(1), ~0ULL);\n\t\tvector = pci_irq_vector(cptpf->pdev, RVU_PF_INT_VEC_VFPF_MBOX1);\n\t\tfree_irq(vector, cptpf);\n\t}\n}\n\nstatic void cptpf_enable_vf_flr_me_intrs(struct otx2_cptpf_dev *cptpf,\n\t\t\t\t\t int num_vfs)\n{\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_VFFLR_INTX(0),\n\t\t\t INTR_MASK(num_vfs));\n\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFFLR_INT_ENA_W1SX(0), INTR_MASK(num_vfs));\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_VFME_INTX(0),\n\t\t\t INTR_MASK(num_vfs));\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFME_INT_ENA_W1SX(0), INTR_MASK(num_vfs));\n\n\tif (num_vfs <= 64)\n\t\treturn;\n\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_VFFLR_INTX(1),\n\t\t\t INTR_MASK(num_vfs - 64));\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFFLR_INT_ENA_W1SX(1), INTR_MASK(num_vfs - 64));\n\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_VFME_INTX(1),\n\t\t\t INTR_MASK(num_vfs - 64));\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFME_INT_ENA_W1SX(1), INTR_MASK(num_vfs - 64));\n}\n\nstatic void cptpf_disable_vf_flr_me_intrs(struct otx2_cptpf_dev *cptpf,\n\t\t\t\t       int num_vfs)\n{\n\tint vector;\n\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFFLR_INT_ENA_W1CX(0), INTR_MASK(num_vfs));\n\tvector = pci_irq_vector(cptpf->pdev, RVU_PF_INT_VEC_VFFLR0);\n\tfree_irq(vector, cptpf);\n\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFME_INT_ENA_W1CX(0), INTR_MASK(num_vfs));\n\tvector = pci_irq_vector(cptpf->pdev, RVU_PF_INT_VEC_VFME0);\n\tfree_irq(vector, cptpf);\n\n\tif (num_vfs <= 64)\n\t\treturn;\n\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFFLR_INT_ENA_W1CX(1), INTR_MASK(num_vfs - 64));\n\tvector = pci_irq_vector(cptpf->pdev, RVU_PF_INT_VEC_VFFLR1);\n\tfree_irq(vector, cptpf);\n\n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t RVU_PF_VFME_INT_ENA_W1CX(1), INTR_MASK(num_vfs - 64));\n\tvector = pci_irq_vector(cptpf->pdev, RVU_PF_INT_VEC_VFME1);\n\tfree_irq(vector, cptpf);\n}\n\nstatic void cptpf_flr_wq_handler(struct work_struct *work)\n{\n\tstruct cptpf_flr_work *flr_work;\n\tstruct otx2_cptpf_dev *pf;\n\tstruct mbox_msghdr *req;\n\tstruct otx2_mbox *mbox;\n\tint vf, reg = 0;\n\n\tflr_work = container_of(work, struct cptpf_flr_work, work);\n\tpf = flr_work->pf;\n\tmbox = &pf->afpf_mbox;\n\n\tvf = flr_work - pf->flr_work;\n\n\tmutex_lock(&pf->lock);\n\treq = otx2_mbox_alloc_msg_rsp(mbox, 0, sizeof(*req),\n\t\t\t\t      sizeof(struct msg_rsp));\n\tif (!req) {\n\t\tmutex_unlock(&pf->lock);\n\t\treturn;\n\t}\n\n\treq->sig = OTX2_MBOX_REQ_SIG;\n\treq->id = MBOX_MSG_VF_FLR;\n\treq->pcifunc &= RVU_PFVF_FUNC_MASK;\n\treq->pcifunc |= (vf + 1) & RVU_PFVF_FUNC_MASK;\n\n\totx2_cpt_send_mbox_msg(mbox, pf->pdev);\n\tif (!otx2_cpt_sync_mbox_msg(&pf->afpf_mbox)) {\n\n\t\tif (vf >= 64) {\n\t\t\treg = 1;\n\t\t\tvf = vf - 64;\n\t\t}\n\t\t \n\t\totx2_cpt_write64(pf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t RVU_PF_VFTRPENDX(reg), BIT_ULL(vf));\n\t\totx2_cpt_write64(pf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t RVU_PF_VFFLR_INT_ENA_W1SX(reg), BIT_ULL(vf));\n\t}\n\tmutex_unlock(&pf->lock);\n}\n\nstatic irqreturn_t cptpf_vf_flr_intr(int __always_unused irq, void *arg)\n{\n\tint reg, dev, vf, start_vf, num_reg = 1;\n\tstruct otx2_cptpf_dev *cptpf = arg;\n\tu64 intr;\n\n\tif (cptpf->max_vfs > 64)\n\t\tnum_reg = 2;\n\n\tfor (reg = 0; reg < num_reg; reg++) {\n\t\tintr = otx2_cpt_read64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t       RVU_PF_VFFLR_INTX(reg));\n\t\tif (!intr)\n\t\t\tcontinue;\n\t\tstart_vf = 64 * reg;\n\t\tfor (vf = 0; vf < 64; vf++) {\n\t\t\tif (!(intr & BIT_ULL(vf)))\n\t\t\t\tcontinue;\n\t\t\tdev = vf + start_vf;\n\t\t\tqueue_work(cptpf->flr_wq, &cptpf->flr_work[dev].work);\n\t\t\t \n\t\t\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t\t RVU_PF_VFFLR_INTX(reg), BIT_ULL(vf));\n\t\t\t \n\t\t\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t\t RVU_PF_VFFLR_INT_ENA_W1CX(reg),\n\t\t\t\t\t BIT_ULL(vf));\n\t\t}\n\t}\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t cptpf_vf_me_intr(int __always_unused irq, void *arg)\n{\n\tstruct otx2_cptpf_dev *cptpf = arg;\n\tint reg, vf, num_reg = 1;\n\tu64 intr;\n\n\tif (cptpf->max_vfs > 64)\n\t\tnum_reg = 2;\n\n\tfor (reg = 0; reg < num_reg; reg++) {\n\t\tintr = otx2_cpt_read64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t       RVU_PF_VFME_INTX(reg));\n\t\tif (!intr)\n\t\t\tcontinue;\n\t\tfor (vf = 0; vf < 64; vf++) {\n\t\t\tif (!(intr & BIT_ULL(vf)))\n\t\t\t\tcontinue;\n\t\t\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t\t RVU_PF_VFTRPENDX(reg), BIT_ULL(vf));\n\t\t\t \n\t\t\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t\t\t RVU_PF_VFME_INTX(reg), BIT_ULL(vf));\n\t\t}\n\t}\n\treturn IRQ_HANDLED;\n}\n\nstatic void cptpf_unregister_vfpf_intr(struct otx2_cptpf_dev *cptpf,\n\t\t\t\t       int num_vfs)\n{\n\tcptpf_disable_vfpf_mbox_intr(cptpf, num_vfs);\n\tcptpf_disable_vf_flr_me_intrs(cptpf, num_vfs);\n}\n\nstatic int cptpf_register_vfpf_intr(struct otx2_cptpf_dev *cptpf, int num_vfs)\n{\n\tstruct pci_dev *pdev = cptpf->pdev;\n\tstruct device *dev = &pdev->dev;\n\tint ret, vector;\n\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFPF_MBOX0);\n\t \n\tret = request_irq(vector, otx2_cptpf_vfpf_mbox_intr, 0, \"CPTVFPF Mbox0\",\n\t\t\t  cptpf);\n\tif (ret) {\n\t\tdev_err(dev,\n\t\t\t\"IRQ registration failed for PFVF mbox0 irq\\n\");\n\t\treturn ret;\n\t}\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFFLR0);\n\t \n\tret = request_irq(vector, cptpf_vf_flr_intr, 0, \"CPTPF FLR0\", cptpf);\n\tif (ret) {\n\t\tdev_err(dev,\n\t\t\t\"IRQ registration failed for VFFLR0 irq\\n\");\n\t\tgoto free_mbox0_irq;\n\t}\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFME0);\n\t \n\tret = request_irq(vector, cptpf_vf_me_intr, 0, \"CPTPF ME0\", cptpf);\n\tif (ret) {\n\t\tdev_err(dev,\n\t\t\t\"IRQ registration failed for PFVF mbox0 irq\\n\");\n\t\tgoto free_flr0_irq;\n\t}\n\n\tif (num_vfs > 64) {\n\t\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFPF_MBOX1);\n\t\tret = request_irq(vector, otx2_cptpf_vfpf_mbox_intr, 0,\n\t\t\t\t  \"CPTVFPF Mbox1\", cptpf);\n\t\tif (ret) {\n\t\t\tdev_err(dev,\n\t\t\t\t\"IRQ registration failed for PFVF mbox1 irq\\n\");\n\t\t\tgoto free_me0_irq;\n\t\t}\n\t\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFFLR1);\n\t\t \n\t\tret = request_irq(vector, cptpf_vf_flr_intr, 0, \"CPTPF FLR1\",\n\t\t\t\t  cptpf);\n\t\tif (ret) {\n\t\t\tdev_err(dev,\n\t\t\t\t\"IRQ registration failed for VFFLR1 irq\\n\");\n\t\t\tgoto free_mbox1_irq;\n\t\t}\n\t\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFME1);\n\t\t \n\t\tret = request_irq(vector, cptpf_vf_me_intr, 0, \"CPTPF ME1\",\n\t\t\t\t  cptpf);\n\t\tif (ret) {\n\t\t\tdev_err(dev,\n\t\t\t\t\"IRQ registration failed for VFFLR1 irq\\n\");\n\t\t\tgoto free_flr1_irq;\n\t\t}\n\t}\n\tcptpf_enable_vfpf_mbox_intr(cptpf, num_vfs);\n\tcptpf_enable_vf_flr_me_intrs(cptpf, num_vfs);\n\n\treturn 0;\n\nfree_flr1_irq:\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFFLR1);\n\tfree_irq(vector, cptpf);\nfree_mbox1_irq:\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFPF_MBOX1);\n\tfree_irq(vector, cptpf);\nfree_me0_irq:\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFME0);\n\tfree_irq(vector, cptpf);\nfree_flr0_irq:\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFFLR0);\n\tfree_irq(vector, cptpf);\nfree_mbox0_irq:\n\tvector = pci_irq_vector(pdev, RVU_PF_INT_VEC_VFPF_MBOX0);\n\tfree_irq(vector, cptpf);\n\treturn ret;\n}\n\nstatic void cptpf_flr_wq_destroy(struct otx2_cptpf_dev *pf)\n{\n\tif (!pf->flr_wq)\n\t\treturn;\n\tdestroy_workqueue(pf->flr_wq);\n\tpf->flr_wq = NULL;\n\tkfree(pf->flr_work);\n}\n\nstatic int cptpf_flr_wq_init(struct otx2_cptpf_dev *cptpf, int num_vfs)\n{\n\tint vf;\n\n\tcptpf->flr_wq = alloc_ordered_workqueue(\"cptpf_flr_wq\", 0);\n\tif (!cptpf->flr_wq)\n\t\treturn -ENOMEM;\n\n\tcptpf->flr_work = kcalloc(num_vfs, sizeof(struct cptpf_flr_work),\n\t\t\t\t  GFP_KERNEL);\n\tif (!cptpf->flr_work)\n\t\tgoto destroy_wq;\n\n\tfor (vf = 0; vf < num_vfs; vf++) {\n\t\tcptpf->flr_work[vf].pf = cptpf;\n\t\tINIT_WORK(&cptpf->flr_work[vf].work, cptpf_flr_wq_handler);\n\t}\n\treturn 0;\n\ndestroy_wq:\n\tdestroy_workqueue(cptpf->flr_wq);\n\treturn -ENOMEM;\n}\n\nstatic int cptpf_vfpf_mbox_init(struct otx2_cptpf_dev *cptpf, int num_vfs)\n{\n\tstruct device *dev = &cptpf->pdev->dev;\n\tu64 vfpf_mbox_base;\n\tint err, i;\n\n\tcptpf->vfpf_mbox_wq =\n\t\talloc_ordered_workqueue(\"cpt_vfpf_mailbox\",\n\t\t\t\t\tWQ_HIGHPRI | WQ_MEM_RECLAIM);\n\tif (!cptpf->vfpf_mbox_wq)\n\t\treturn -ENOMEM;\n\n\t \n\tif (test_bit(CN10K_MBOX, &cptpf->cap_flag))\n\t\tvfpf_mbox_base = readq(cptpf->reg_base + RVU_PF_VF_MBOX_ADDR);\n\telse\n\t\tvfpf_mbox_base = readq(cptpf->reg_base + RVU_PF_VF_BAR4_ADDR);\n\n\tif (!vfpf_mbox_base) {\n\t\tdev_err(dev, \"VF-PF mailbox address not configured\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto free_wqe;\n\t}\n\tcptpf->vfpf_mbox_base = devm_ioremap_wc(dev, vfpf_mbox_base,\n\t\t\t\t\t\tMBOX_SIZE * cptpf->max_vfs);\n\tif (!cptpf->vfpf_mbox_base) {\n\t\tdev_err(dev, \"Mapping of VF-PF mailbox address failed\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto free_wqe;\n\t}\n\terr = otx2_mbox_init(&cptpf->vfpf_mbox, cptpf->vfpf_mbox_base,\n\t\t\t     cptpf->pdev, cptpf->reg_base, MBOX_DIR_PFVF,\n\t\t\t     num_vfs);\n\tif (err)\n\t\tgoto free_wqe;\n\n\tfor (i = 0; i < num_vfs; i++) {\n\t\tcptpf->vf[i].vf_id = i;\n\t\tcptpf->vf[i].cptpf = cptpf;\n\t\tcptpf->vf[i].intr_idx = i % 64;\n\t\tINIT_WORK(&cptpf->vf[i].vfpf_mbox_work,\n\t\t\t  otx2_cptpf_vfpf_mbox_handler);\n\t}\n\treturn 0;\n\nfree_wqe:\n\tdestroy_workqueue(cptpf->vfpf_mbox_wq);\n\treturn err;\n}\n\nstatic void cptpf_vfpf_mbox_destroy(struct otx2_cptpf_dev *cptpf)\n{\n\tdestroy_workqueue(cptpf->vfpf_mbox_wq);\n\totx2_mbox_destroy(&cptpf->vfpf_mbox);\n}\n\nstatic void cptpf_disable_afpf_mbox_intr(struct otx2_cptpf_dev *cptpf)\n{\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_INT_ENA_W1C,\n\t\t\t 0x1ULL);\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_INT, 0x1ULL);\n}\n\nstatic int cptpf_register_afpf_mbox_intr(struct otx2_cptpf_dev *cptpf)\n{\n\tstruct pci_dev *pdev = cptpf->pdev;\n\tstruct device *dev = &pdev->dev;\n\tint ret, irq;\n\n\tirq = pci_irq_vector(pdev, RVU_PF_INT_VEC_AFPF_MBOX);\n\t \n\tret = devm_request_irq(dev, irq, otx2_cptpf_afpf_mbox_intr, 0,\n\t\t\t       \"CPTAFPF Mbox\", cptpf);\n\tif (ret) {\n\t\tdev_err(dev,\n\t\t\t\"IRQ registration failed for PFAF mbox irq\\n\");\n\t\treturn ret;\n\t}\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_INT, 0x1ULL);\n\t \n\totx2_cpt_write64(cptpf->reg_base, BLKADDR_RVUM, 0, RVU_PF_INT_ENA_W1S,\n\t\t\t 0x1ULL);\n\n\tret = otx2_cpt_send_ready_msg(&cptpf->afpf_mbox, cptpf->pdev);\n\tif (ret) {\n\t\tdev_warn(dev,\n\t\t\t \"AF not responding to mailbox, deferring probe\\n\");\n\t\tcptpf_disable_afpf_mbox_intr(cptpf);\n\t\treturn -EPROBE_DEFER;\n\t}\n\treturn 0;\n}\n\nstatic int cptpf_afpf_mbox_init(struct otx2_cptpf_dev *cptpf)\n{\n\tstruct pci_dev *pdev = cptpf->pdev;\n\tresource_size_t offset;\n\tint err;\n\n\tcptpf->afpf_mbox_wq =\n\t\talloc_ordered_workqueue(\"cpt_afpf_mailbox\",\n\t\t\t\t\tWQ_HIGHPRI | WQ_MEM_RECLAIM);\n\tif (!cptpf->afpf_mbox_wq)\n\t\treturn -ENOMEM;\n\n\toffset = pci_resource_start(pdev, PCI_MBOX_BAR_NUM);\n\t \n\tcptpf->afpf_mbox_base = devm_ioremap_wc(&pdev->dev, offset, MBOX_SIZE);\n\tif (!cptpf->afpf_mbox_base) {\n\t\tdev_err(&pdev->dev, \"Unable to map BAR4\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto error;\n\t}\n\n\terr = otx2_mbox_init(&cptpf->afpf_mbox, cptpf->afpf_mbox_base,\n\t\t\t     pdev, cptpf->reg_base, MBOX_DIR_PFAF, 1);\n\tif (err)\n\t\tgoto error;\n\n\terr = otx2_mbox_init(&cptpf->afpf_mbox_up, cptpf->afpf_mbox_base,\n\t\t\t     pdev, cptpf->reg_base, MBOX_DIR_PFAF_UP, 1);\n\tif (err)\n\t\tgoto mbox_cleanup;\n\n\tINIT_WORK(&cptpf->afpf_mbox_work, otx2_cptpf_afpf_mbox_handler);\n\tINIT_WORK(&cptpf->afpf_mbox_up_work, otx2_cptpf_afpf_mbox_up_handler);\n\tmutex_init(&cptpf->lock);\n\n\treturn 0;\n\nmbox_cleanup:\n\totx2_mbox_destroy(&cptpf->afpf_mbox);\nerror:\n\tdestroy_workqueue(cptpf->afpf_mbox_wq);\n\treturn err;\n}\n\nstatic void cptpf_afpf_mbox_destroy(struct otx2_cptpf_dev *cptpf)\n{\n\tdestroy_workqueue(cptpf->afpf_mbox_wq);\n\totx2_mbox_destroy(&cptpf->afpf_mbox);\n\totx2_mbox_destroy(&cptpf->afpf_mbox_up);\n}\n\nstatic ssize_t sso_pf_func_ovrd_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct otx2_cptpf_dev *cptpf = dev_get_drvdata(dev);\n\n\treturn sprintf(buf, \"%d\\n\", cptpf->sso_pf_func_ovrd);\n}\n\nstatic ssize_t sso_pf_func_ovrd_store(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      const char *buf, size_t count)\n{\n\tstruct otx2_cptpf_dev *cptpf = dev_get_drvdata(dev);\n\tu8 sso_pf_func_ovrd;\n\n\tif (!(cptpf->pdev->revision == CPT_UC_RID_CN9K_B0))\n\t\treturn count;\n\n\tif (kstrtou8(buf, 0, &sso_pf_func_ovrd))\n\t\treturn -EINVAL;\n\n\tcptpf->sso_pf_func_ovrd = sso_pf_func_ovrd;\n\n\treturn count;\n}\n\nstatic ssize_t kvf_limits_show(struct device *dev,\n\t\t\t       struct device_attribute *attr, char *buf)\n{\n\tstruct otx2_cptpf_dev *cptpf = dev_get_drvdata(dev);\n\n\treturn sprintf(buf, \"%d\\n\", cptpf->kvf_limits);\n}\n\nstatic ssize_t kvf_limits_store(struct device *dev,\n\t\t\t\tstruct device_attribute *attr,\n\t\t\t\tconst char *buf, size_t count)\n{\n\tstruct otx2_cptpf_dev *cptpf = dev_get_drvdata(dev);\n\tint lfs_num;\n\tint ret;\n\n\tret = kstrtoint(buf, 0, &lfs_num);\n\tif (ret)\n\t\treturn ret;\n\tif (lfs_num < 1 || lfs_num > num_online_cpus()) {\n\t\tdev_err(dev, \"lfs count %d must be in range [1 - %d]\\n\",\n\t\t\tlfs_num, num_online_cpus());\n\t\treturn -EINVAL;\n\t}\n\tcptpf->kvf_limits = lfs_num;\n\n\treturn count;\n}\n\nstatic DEVICE_ATTR_RW(kvf_limits);\nstatic DEVICE_ATTR_RW(sso_pf_func_ovrd);\n\nstatic struct attribute *cptpf_attrs[] = {\n\t&dev_attr_kvf_limits.attr,\n\t&dev_attr_sso_pf_func_ovrd.attr,\n\tNULL\n};\n\nstatic const struct attribute_group cptpf_sysfs_group = {\n\t.attrs = cptpf_attrs,\n};\n\nstatic int cpt_is_pf_usable(struct otx2_cptpf_dev *cptpf)\n{\n\tu64 rev;\n\n\trev = otx2_cpt_read64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t      RVU_PF_BLOCK_ADDRX_DISC(BLKADDR_RVUM));\n\trev = (rev >> 12) & 0xFF;\n\t \n\tif (!rev) {\n\t\tdev_warn(&cptpf->pdev->dev,\n\t\t\t \"AF is not initialized, deferring probe\\n\");\n\t\treturn -EPROBE_DEFER;\n\t}\n\treturn 0;\n}\n\nstatic int cptx_device_reset(struct otx2_cptpf_dev *cptpf, int blkaddr)\n{\n\tint timeout = 10, ret;\n\tu64 reg = 0;\n\n\tret = otx2_cpt_write_af_reg(&cptpf->afpf_mbox, cptpf->pdev,\n\t\t\t\t    CPT_AF_BLK_RST, 0x1, blkaddr);\n\tif (ret)\n\t\treturn ret;\n\n\tdo {\n\t\tret = otx2_cpt_read_af_reg(&cptpf->afpf_mbox, cptpf->pdev,\n\t\t\t\t\t   CPT_AF_BLK_RST, &reg, blkaddr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!((reg >> 63) & 0x1))\n\t\t\tbreak;\n\n\t\tusleep_range(10000, 20000);\n\t\tif (timeout-- < 0)\n\t\t\treturn -EBUSY;\n\t} while (1);\n\n\treturn ret;\n}\n\nstatic int cptpf_device_reset(struct otx2_cptpf_dev *cptpf)\n{\n\tint ret = 0;\n\n\tif (cptpf->has_cpt1) {\n\t\tret = cptx_device_reset(cptpf, BLKADDR_CPT1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn cptx_device_reset(cptpf, BLKADDR_CPT0);\n}\n\nstatic void cptpf_check_block_implemented(struct otx2_cptpf_dev *cptpf)\n{\n\tu64 cfg;\n\n\tcfg = otx2_cpt_read64(cptpf->reg_base, BLKADDR_RVUM, 0,\n\t\t\t      RVU_PF_BLOCK_ADDRX_DISC(BLKADDR_CPT1));\n\tif (cfg & BIT_ULL(11))\n\t\tcptpf->has_cpt1 = true;\n}\n\nstatic int cptpf_device_init(struct otx2_cptpf_dev *cptpf)\n{\n\tunion otx2_cptx_af_constants1 af_cnsts1 = {0};\n\tint ret = 0;\n\n\t \n\tcptpf_check_block_implemented(cptpf);\n\t \n\tret = cptpf_device_reset(cptpf);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = otx2_cpt_read_af_reg(&cptpf->afpf_mbox, cptpf->pdev,\n\t\t\t\t   CPT_AF_CONSTANTS1, &af_cnsts1.u,\n\t\t\t\t   BLKADDR_CPT0);\n\tif (ret)\n\t\treturn ret;\n\n\tcptpf->eng_grps.avail.max_se_cnt = af_cnsts1.s.se;\n\tcptpf->eng_grps.avail.max_ie_cnt = af_cnsts1.s.ie;\n\tcptpf->eng_grps.avail.max_ae_cnt = af_cnsts1.s.ae;\n\n\t \n\tret = otx2_cpt_disable_all_cores(cptpf);\n\n\treturn ret;\n}\n\nstatic int cptpf_sriov_disable(struct pci_dev *pdev)\n{\n\tstruct otx2_cptpf_dev *cptpf = pci_get_drvdata(pdev);\n\tint num_vfs = pci_num_vf(pdev);\n\n\tif (!num_vfs)\n\t\treturn 0;\n\n\tpci_disable_sriov(pdev);\n\tcptpf_unregister_vfpf_intr(cptpf, num_vfs);\n\tcptpf_flr_wq_destroy(cptpf);\n\tcptpf_vfpf_mbox_destroy(cptpf);\n\tmodule_put(THIS_MODULE);\n\tcptpf->enabled_vfs = 0;\n\n\treturn 0;\n}\n\nstatic int cptpf_sriov_enable(struct pci_dev *pdev, int num_vfs)\n{\n\tstruct otx2_cptpf_dev *cptpf = pci_get_drvdata(pdev);\n\tint ret;\n\n\t \n\tret = cptpf_vfpf_mbox_init(cptpf, num_vfs);\n\tif (ret)\n\t\treturn ret;\n\n\tret = cptpf_flr_wq_init(cptpf, num_vfs);\n\tif (ret)\n\t\tgoto destroy_mbox;\n\t \n\tret = cptpf_register_vfpf_intr(cptpf, num_vfs);\n\tif (ret)\n\t\tgoto destroy_flr;\n\n\t \n\tret = otx2_cpt_discover_eng_capabilities(cptpf);\n\tif (ret)\n\t\tgoto disable_intr;\n\n\tret = otx2_cpt_create_eng_grps(cptpf, &cptpf->eng_grps);\n\tif (ret)\n\t\tgoto disable_intr;\n\n\tcptpf->enabled_vfs = num_vfs;\n\tret = pci_enable_sriov(pdev, num_vfs);\n\tif (ret)\n\t\tgoto disable_intr;\n\n\tdev_notice(&cptpf->pdev->dev, \"VFs enabled: %d\\n\", num_vfs);\n\n\ttry_module_get(THIS_MODULE);\n\treturn num_vfs;\n\ndisable_intr:\n\tcptpf_unregister_vfpf_intr(cptpf, num_vfs);\n\tcptpf->enabled_vfs = 0;\ndestroy_flr:\n\tcptpf_flr_wq_destroy(cptpf);\ndestroy_mbox:\n\tcptpf_vfpf_mbox_destroy(cptpf);\n\treturn ret;\n}\n\nstatic int otx2_cptpf_sriov_configure(struct pci_dev *pdev, int num_vfs)\n{\n\tif (num_vfs > 0) {\n\t\treturn cptpf_sriov_enable(pdev, num_vfs);\n\t} else {\n\t\treturn cptpf_sriov_disable(pdev);\n\t}\n}\n\nstatic int otx2_cptpf_probe(struct pci_dev *pdev,\n\t\t\t    const struct pci_device_id *ent)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct otx2_cptpf_dev *cptpf;\n\tint err;\n\n\tcptpf = devm_kzalloc(dev, sizeof(*cptpf), GFP_KERNEL);\n\tif (!cptpf)\n\t\treturn -ENOMEM;\n\n\terr = pcim_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to enable PCI device\\n\");\n\t\tgoto clear_drvdata;\n\t}\n\n\terr = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(48));\n\tif (err) {\n\t\tdev_err(dev, \"Unable to get usable DMA configuration\\n\");\n\t\tgoto clear_drvdata;\n\t}\n\t \n\terr = pcim_iomap_regions_request_all(pdev, 1 << PCI_PF_REG_BAR_NUM,\n\t\t\t\t\t     OTX2_CPT_DRV_NAME);\n\tif (err) {\n\t\tdev_err(dev, \"Couldn't get PCI resources 0x%x\\n\", err);\n\t\tgoto clear_drvdata;\n\t}\n\tpci_set_master(pdev);\n\tpci_set_drvdata(pdev, cptpf);\n\tcptpf->pdev = pdev;\n\n\tcptpf->reg_base = pcim_iomap_table(pdev)[PCI_PF_REG_BAR_NUM];\n\n\t \n\terr = cpt_is_pf_usable(cptpf);\n\tif (err)\n\t\tgoto clear_drvdata;\n\n\terr = pci_alloc_irq_vectors(pdev, RVU_PF_INT_VEC_CNT,\n\t\t\t\t    RVU_PF_INT_VEC_CNT, PCI_IRQ_MSIX);\n\tif (err < 0) {\n\t\tdev_err(dev, \"Request for %d msix vectors failed\\n\",\n\t\t\tRVU_PF_INT_VEC_CNT);\n\t\tgoto clear_drvdata;\n\t}\n\totx2_cpt_set_hw_caps(pdev, &cptpf->cap_flag);\n\t \n\terr = cptpf_afpf_mbox_init(cptpf);\n\tif (err)\n\t\tgoto clear_drvdata;\n\t \n\terr = cptpf_register_afpf_mbox_intr(cptpf);\n\tif (err)\n\t\tgoto destroy_afpf_mbox;\n\n\tcptpf->max_vfs = pci_sriov_get_totalvfs(pdev);\n\n\terr = cn10k_cptpf_lmtst_init(cptpf);\n\tif (err)\n\t\tgoto unregister_intr;\n\n\t \n\terr = cptpf_device_init(cptpf);\n\tif (err)\n\t\tgoto unregister_intr;\n\n\t \n\terr = otx2_cpt_init_eng_grps(pdev, &cptpf->eng_grps);\n\tif (err)\n\t\tgoto unregister_intr;\n\n\terr = sysfs_create_group(&dev->kobj, &cptpf_sysfs_group);\n\tif (err)\n\t\tgoto cleanup_eng_grps;\n\n\terr = otx2_cpt_register_dl(cptpf);\n\tif (err)\n\t\tgoto sysfs_grp_del;\n\n\treturn 0;\n\nsysfs_grp_del:\n\tsysfs_remove_group(&dev->kobj, &cptpf_sysfs_group);\ncleanup_eng_grps:\n\totx2_cpt_cleanup_eng_grps(pdev, &cptpf->eng_grps);\nunregister_intr:\n\tcptpf_disable_afpf_mbox_intr(cptpf);\ndestroy_afpf_mbox:\n\tcptpf_afpf_mbox_destroy(cptpf);\nclear_drvdata:\n\tpci_set_drvdata(pdev, NULL);\n\treturn err;\n}\n\nstatic void otx2_cptpf_remove(struct pci_dev *pdev)\n{\n\tstruct otx2_cptpf_dev *cptpf = pci_get_drvdata(pdev);\n\n\tif (!cptpf)\n\t\treturn;\n\n\tcptpf_sriov_disable(pdev);\n\totx2_cpt_unregister_dl(cptpf);\n\t \n\tsysfs_remove_group(&pdev->dev.kobj, &cptpf_sysfs_group);\n\t \n\totx2_cpt_cleanup_eng_grps(pdev, &cptpf->eng_grps);\n\t \n\tcptpf_disable_afpf_mbox_intr(cptpf);\n\t \n\tcptpf_afpf_mbox_destroy(cptpf);\n\tpci_set_drvdata(pdev, NULL);\n}\n\n \nstatic const struct pci_device_id otx2_cpt_id_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, OTX2_CPT_PCI_PF_DEVICE_ID) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_CAVIUM, CN10K_CPT_PCI_PF_DEVICE_ID) },\n\t{ 0, }   \n};\n\nstatic struct pci_driver otx2_cpt_pci_driver = {\n\t.name = OTX2_CPT_DRV_NAME,\n\t.id_table = otx2_cpt_id_table,\n\t.probe = otx2_cptpf_probe,\n\t.remove = otx2_cptpf_remove,\n\t.sriov_configure = otx2_cptpf_sriov_configure\n};\n\nmodule_pci_driver(otx2_cpt_pci_driver);\n\nMODULE_IMPORT_NS(CRYPTO_DEV_OCTEONTX2_CPT);\n\nMODULE_AUTHOR(\"Marvell\");\nMODULE_DESCRIPTION(OTX2_CPT_DRV_STRING);\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DEVICE_TABLE(pci, otx2_cpt_id_table);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}