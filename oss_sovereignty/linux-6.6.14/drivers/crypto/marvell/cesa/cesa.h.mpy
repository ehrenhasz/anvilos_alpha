{
  "module_name": "cesa.h",
  "hash_id": "bbb9472ff23c715dbee9d6c55cd90e3b2c969694880d8fcf860fb7be53b6a92c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/marvell/cesa/cesa.h",
  "human_readable_source": " \n#ifndef __MARVELL_CESA_H__\n#define __MARVELL_CESA_H__\n\n#include <crypto/internal/hash.h>\n#include <crypto/internal/skcipher.h>\n\n#include <linux/dma-direction.h>\n#include <linux/dmapool.h>\n\n#define CESA_ENGINE_OFF(i)\t\t\t(((i) * 0x2000))\n\n#define CESA_TDMA_BYTE_CNT\t\t\t0x800\n#define CESA_TDMA_SRC_ADDR\t\t\t0x810\n#define CESA_TDMA_DST_ADDR\t\t\t0x820\n#define CESA_TDMA_NEXT_ADDR\t\t\t0x830\n\n#define CESA_TDMA_CONTROL\t\t\t0x840\n#define CESA_TDMA_DST_BURST\t\t\tGENMASK(2, 0)\n#define CESA_TDMA_DST_BURST_32B\t\t\t3\n#define CESA_TDMA_DST_BURST_128B\t\t4\n#define CESA_TDMA_OUT_RD_EN\t\t\tBIT(4)\n#define CESA_TDMA_SRC_BURST\t\t\tGENMASK(8, 6)\n#define CESA_TDMA_SRC_BURST_32B\t\t\t(3 << 6)\n#define CESA_TDMA_SRC_BURST_128B\t\t(4 << 6)\n#define CESA_TDMA_CHAIN\t\t\t\tBIT(9)\n#define CESA_TDMA_BYTE_SWAP\t\t\tBIT(11)\n#define CESA_TDMA_NO_BYTE_SWAP\t\t\tBIT(11)\n#define CESA_TDMA_EN\t\t\t\tBIT(12)\n#define CESA_TDMA_FETCH_ND\t\t\tBIT(13)\n#define CESA_TDMA_ACT\t\t\t\tBIT(14)\n\n#define CESA_TDMA_CUR\t\t\t\t0x870\n#define CESA_TDMA_ERROR_CAUSE\t\t\t0x8c8\n#define CESA_TDMA_ERROR_MSK\t\t\t0x8cc\n\n#define CESA_TDMA_WINDOW_BASE(x)\t\t(((x) * 0x8) + 0xa00)\n#define CESA_TDMA_WINDOW_CTRL(x)\t\t(((x) * 0x8) + 0xa04)\n\n#define CESA_IVDIG(x)\t\t\t\t(0xdd00 + ((x) * 4) +\t\\\n\t\t\t\t\t\t (((x) < 5) ? 0 : 0x14))\n\n#define CESA_SA_CMD\t\t\t\t0xde00\n#define CESA_SA_CMD_EN_CESA_SA_ACCL0\t\tBIT(0)\n#define CESA_SA_CMD_EN_CESA_SA_ACCL1\t\tBIT(1)\n#define CESA_SA_CMD_DISABLE_SEC\t\t\tBIT(2)\n\n#define CESA_SA_DESC_P0\t\t\t\t0xde04\n\n#define CESA_SA_DESC_P1\t\t\t\t0xde14\n\n#define CESA_SA_CFG\t\t\t\t0xde08\n#define CESA_SA_CFG_STOP_DIG_ERR\t\tGENMASK(1, 0)\n#define CESA_SA_CFG_DIG_ERR_CONT\t\t0\n#define CESA_SA_CFG_DIG_ERR_SKIP\t\t1\n#define CESA_SA_CFG_DIG_ERR_STOP\t\t3\n#define CESA_SA_CFG_CH0_W_IDMA\t\t\tBIT(7)\n#define CESA_SA_CFG_CH1_W_IDMA\t\t\tBIT(8)\n#define CESA_SA_CFG_ACT_CH0_IDMA\t\tBIT(9)\n#define CESA_SA_CFG_ACT_CH1_IDMA\t\tBIT(10)\n#define CESA_SA_CFG_MULTI_PKT\t\t\tBIT(11)\n#define CESA_SA_CFG_PARA_DIS\t\t\tBIT(13)\n\n#define CESA_SA_ACCEL_STATUS\t\t\t0xde0c\n#define CESA_SA_ST_ACT_0\t\t\tBIT(0)\n#define CESA_SA_ST_ACT_1\t\t\tBIT(1)\n\n \n#define CESA_SA_FPGA_INT_STATUS\t\t\t0xdd68\n#define CESA_SA_INT_STATUS\t\t\t0xde20\n#define CESA_SA_INT_AUTH_DONE\t\t\tBIT(0)\n#define CESA_SA_INT_DES_E_DONE\t\t\tBIT(1)\n#define CESA_SA_INT_AES_E_DONE\t\t\tBIT(2)\n#define CESA_SA_INT_AES_D_DONE\t\t\tBIT(3)\n#define CESA_SA_INT_ENC_DONE\t\t\tBIT(4)\n#define CESA_SA_INT_ACCEL0_DONE\t\t\tBIT(5)\n#define CESA_SA_INT_ACCEL1_DONE\t\t\tBIT(6)\n#define CESA_SA_INT_ACC0_IDMA_DONE\t\tBIT(7)\n#define CESA_SA_INT_ACC1_IDMA_DONE\t\tBIT(8)\n#define CESA_SA_INT_IDMA_DONE\t\t\tBIT(9)\n#define CESA_SA_INT_IDMA_OWN_ERR\t\tBIT(10)\n\n#define CESA_SA_INT_MSK\t\t\t\t0xde24\n\n#define CESA_SA_DESC_CFG_OP_MAC_ONLY\t\t0\n#define CESA_SA_DESC_CFG_OP_CRYPT_ONLY\t\t1\n#define CESA_SA_DESC_CFG_OP_MAC_CRYPT\t\t2\n#define CESA_SA_DESC_CFG_OP_CRYPT_MAC\t\t3\n#define CESA_SA_DESC_CFG_OP_MSK\t\t\tGENMASK(1, 0)\n#define CESA_SA_DESC_CFG_MACM_SHA256\t\t(1 << 4)\n#define CESA_SA_DESC_CFG_MACM_HMAC_SHA256\t(3 << 4)\n#define CESA_SA_DESC_CFG_MACM_MD5\t\t(4 << 4)\n#define CESA_SA_DESC_CFG_MACM_SHA1\t\t(5 << 4)\n#define CESA_SA_DESC_CFG_MACM_HMAC_MD5\t\t(6 << 4)\n#define CESA_SA_DESC_CFG_MACM_HMAC_SHA1\t\t(7 << 4)\n#define CESA_SA_DESC_CFG_MACM_MSK\t\tGENMASK(6, 4)\n#define CESA_SA_DESC_CFG_CRYPTM_DES\t\t(1 << 8)\n#define CESA_SA_DESC_CFG_CRYPTM_3DES\t\t(2 << 8)\n#define CESA_SA_DESC_CFG_CRYPTM_AES\t\t(3 << 8)\n#define CESA_SA_DESC_CFG_CRYPTM_MSK\t\tGENMASK(9, 8)\n#define CESA_SA_DESC_CFG_DIR_ENC\t\t(0 << 12)\n#define CESA_SA_DESC_CFG_DIR_DEC\t\t(1 << 12)\n#define CESA_SA_DESC_CFG_CRYPTCM_ECB\t\t(0 << 16)\n#define CESA_SA_DESC_CFG_CRYPTCM_CBC\t\t(1 << 16)\n#define CESA_SA_DESC_CFG_CRYPTCM_MSK\t\tBIT(16)\n#define CESA_SA_DESC_CFG_3DES_EEE\t\t(0 << 20)\n#define CESA_SA_DESC_CFG_3DES_EDE\t\t(1 << 20)\n#define CESA_SA_DESC_CFG_AES_LEN_128\t\t(0 << 24)\n#define CESA_SA_DESC_CFG_AES_LEN_192\t\t(1 << 24)\n#define CESA_SA_DESC_CFG_AES_LEN_256\t\t(2 << 24)\n#define CESA_SA_DESC_CFG_AES_LEN_MSK\t\tGENMASK(25, 24)\n#define CESA_SA_DESC_CFG_NOT_FRAG\t\t(0 << 30)\n#define CESA_SA_DESC_CFG_FIRST_FRAG\t\t(1 << 30)\n#define CESA_SA_DESC_CFG_LAST_FRAG\t\t(2 << 30)\n#define CESA_SA_DESC_CFG_MID_FRAG\t\t(3 << 30)\n#define CESA_SA_DESC_CFG_FRAG_MSK\t\tGENMASK(31, 30)\n\n \n\n \n\n#define CESA_SA_CFG_SRAM_OFFSET\t\t\t0x00\n#define CESA_SA_DATA_SRAM_OFFSET\t\t0x80\n\n#define CESA_SA_CRYPT_KEY_SRAM_OFFSET\t\t0x20\n#define CESA_SA_CRYPT_IV_SRAM_OFFSET\t\t0x40\n\n#define CESA_SA_MAC_IIV_SRAM_OFFSET\t\t0x20\n#define CESA_SA_MAC_OIV_SRAM_OFFSET\t\t0x40\n#define CESA_SA_MAC_DIG_SRAM_OFFSET\t\t0x60\n\n#define CESA_SA_DESC_CRYPT_DATA(offset)\t\t\t\t\t\\\n\tcpu_to_le32((CESA_SA_DATA_SRAM_OFFSET + (offset)) |\t\t\\\n\t\t    ((CESA_SA_DATA_SRAM_OFFSET + (offset)) << 16))\n\n#define CESA_SA_DESC_CRYPT_IV(offset)\t\t\t\t\t\\\n\tcpu_to_le32((CESA_SA_CRYPT_IV_SRAM_OFFSET + (offset)) |\t\\\n\t\t    ((CESA_SA_CRYPT_IV_SRAM_OFFSET + (offset)) << 16))\n\n#define CESA_SA_DESC_CRYPT_KEY(offset)\t\t\t\t\t\\\n\tcpu_to_le32(CESA_SA_CRYPT_KEY_SRAM_OFFSET + (offset))\n\n#define CESA_SA_DESC_MAC_DATA(offset)\t\t\t\t\t\\\n\tcpu_to_le32(CESA_SA_DATA_SRAM_OFFSET + (offset))\n#define CESA_SA_DESC_MAC_DATA_MSK\t\tcpu_to_le32(GENMASK(15, 0))\n\n#define CESA_SA_DESC_MAC_TOTAL_LEN(total_len)\tcpu_to_le32((total_len) << 16)\n#define CESA_SA_DESC_MAC_TOTAL_LEN_MSK\t\tcpu_to_le32(GENMASK(31, 16))\n\n#define CESA_SA_DESC_MAC_SRC_TOTAL_LEN_MAX\t0xffff\n\n#define CESA_SA_DESC_MAC_DIGEST(offset)\t\t\t\t\t\\\n\tcpu_to_le32(CESA_SA_MAC_DIG_SRAM_OFFSET + (offset))\n#define CESA_SA_DESC_MAC_DIGEST_MSK\t\tcpu_to_le32(GENMASK(15, 0))\n\n#define CESA_SA_DESC_MAC_FRAG_LEN(frag_len)\tcpu_to_le32((frag_len) << 16)\n#define CESA_SA_DESC_MAC_FRAG_LEN_MSK\t\tcpu_to_le32(GENMASK(31, 16))\n\n#define CESA_SA_DESC_MAC_IV(offset)\t\t\t\t\t\\\n\tcpu_to_le32((CESA_SA_MAC_IIV_SRAM_OFFSET + (offset)) |\t\t\\\n\t\t    ((CESA_SA_MAC_OIV_SRAM_OFFSET + (offset)) << 16))\n\n#define CESA_SA_SRAM_SIZE\t\t\t2048\n#define CESA_SA_SRAM_PAYLOAD_SIZE\t\t(cesa_dev->sram_size - \\\n\t\t\t\t\t\t CESA_SA_DATA_SRAM_OFFSET)\n\n#define CESA_SA_DEFAULT_SRAM_SIZE\t\t2048\n#define CESA_SA_MIN_SRAM_SIZE\t\t\t1024\n\n#define CESA_SA_SRAM_MSK\t\t\t(2048 - 1)\n\n#define CESA_MAX_HASH_BLOCK_SIZE\t\t64\n#define CESA_HASH_BLOCK_SIZE_MSK\t\t(CESA_MAX_HASH_BLOCK_SIZE - 1)\n\n \nstruct mv_cesa_sec_accel_desc {\n\t__le32 config;\n\t__le32 enc_p;\n\t__le32 enc_len;\n\t__le32 enc_key_p;\n\t__le32 enc_iv;\n\t__le32 mac_src_p;\n\t__le32 mac_digest;\n\t__le32 mac_iv;\n};\n\n \nstruct mv_cesa_skcipher_op_ctx {\n\t__le32 key[8];\n\tu32 iv[4];\n};\n\n \nstruct mv_cesa_hash_op_ctx {\n\tu32 iv[16];\n\t__le32 hash[8];\n};\n\n \nstruct mv_cesa_op_ctx {\n\tstruct mv_cesa_sec_accel_desc desc;\n\tunion {\n\t\tstruct mv_cesa_skcipher_op_ctx skcipher;\n\t\tstruct mv_cesa_hash_op_ctx hash;\n\t} ctx;\n};\n\n \n#define CESA_TDMA_DST_IN_SRAM\t\t\tBIT(31)\n#define CESA_TDMA_SRC_IN_SRAM\t\t\tBIT(30)\n#define CESA_TDMA_END_OF_REQ\t\t\tBIT(29)\n#define CESA_TDMA_BREAK_CHAIN\t\t\tBIT(28)\n#define CESA_TDMA_SET_STATE\t\t\tBIT(27)\n#define CESA_TDMA_TYPE_MSK\t\t\tGENMASK(26, 0)\n#define CESA_TDMA_DUMMY\t\t\t\t0\n#define CESA_TDMA_DATA\t\t\t\t1\n#define CESA_TDMA_OP\t\t\t\t2\n#define CESA_TDMA_RESULT\t\t\t3\n\n \nstruct mv_cesa_tdma_desc {\n\t__le32 byte_cnt;\n\tunion {\n\t\t__le32 src;\n\t\tu32 src_dma;\n\t};\n\tunion {\n\t\t__le32 dst;\n\t\tu32 dst_dma;\n\t};\n\t__le32 next_dma;\n\n\t \n\tdma_addr_t cur_dma;\n\tstruct mv_cesa_tdma_desc *next;\n\tunion {\n\t\tstruct mv_cesa_op_ctx *op;\n\t\tvoid *data;\n\t};\n\tu32 flags;\n};\n\n \nstruct mv_cesa_sg_dma_iter {\n\tenum dma_data_direction dir;\n\tstruct scatterlist *sg;\n\tunsigned int offset;\n\tunsigned int op_offset;\n};\n\n \nstruct mv_cesa_dma_iter {\n\tunsigned int len;\n\tunsigned int offset;\n\tunsigned int op_len;\n};\n\n \nstruct mv_cesa_tdma_chain {\n\tstruct mv_cesa_tdma_desc *first;\n\tstruct mv_cesa_tdma_desc *last;\n};\n\nstruct mv_cesa_engine;\n\n \nstruct mv_cesa_caps {\n\tint nengines;\n\tbool has_tdma;\n\tstruct skcipher_alg **cipher_algs;\n\tint ncipher_algs;\n\tstruct ahash_alg **ahash_algs;\n\tint nahash_algs;\n};\n\n \nstruct mv_cesa_dev_dma {\n\tstruct dma_pool *tdma_desc_pool;\n\tstruct dma_pool *op_pool;\n\tstruct dma_pool *cache_pool;\n\tstruct dma_pool *padding_pool;\n};\n\n \nstruct mv_cesa_dev {\n\tconst struct mv_cesa_caps *caps;\n\tvoid __iomem *regs;\n\tstruct device *dev;\n\tunsigned int sram_size;\n\tspinlock_t lock;\n\tstruct mv_cesa_engine *engines;\n\tstruct mv_cesa_dev_dma *dma;\n};\n\n \nstruct mv_cesa_engine {\n\tint id;\n\tvoid __iomem *regs;\n\tunion {\n\t\tvoid __iomem *sram;\n\t\tvoid *sram_pool;\n\t};\n\tdma_addr_t sram_dma;\n\tspinlock_t lock;\n\tstruct crypto_async_request *req;\n\tstruct clk *clk;\n\tstruct clk *zclk;\n\tsize_t max_req_len;\n\tu32 int_mask;\n\tstruct gen_pool *pool;\n\tstruct crypto_queue queue;\n\tatomic_t load;\n\tstruct mv_cesa_tdma_chain chain;\n\tstruct list_head complete_queue;\n\tint irq;\n};\n\n \nstruct mv_cesa_req_ops {\n\tint (*process)(struct crypto_async_request *req, u32 status);\n\tvoid (*step)(struct crypto_async_request *req);\n\tvoid (*cleanup)(struct crypto_async_request *req);\n\tvoid (*complete)(struct crypto_async_request *req);\n};\n\n \nstruct mv_cesa_ctx {\n\tconst struct mv_cesa_req_ops *ops;\n};\n\n \nstruct mv_cesa_hash_ctx {\n\tstruct mv_cesa_ctx base;\n};\n\n \nstruct mv_cesa_hmac_ctx {\n\tstruct mv_cesa_ctx base;\n\t__be32 iv[16];\n};\n\n \nenum mv_cesa_req_type {\n\tCESA_STD_REQ,\n\tCESA_DMA_REQ,\n};\n\n \nstruct mv_cesa_req {\n\tstruct mv_cesa_engine *engine;\n\tstruct mv_cesa_tdma_chain chain;\n};\n\n \nstruct mv_cesa_sg_std_iter {\n\tstruct sg_mapping_iter iter;\n\tunsigned int offset;\n};\n\n \nstruct mv_cesa_skcipher_std_req {\n\tstruct mv_cesa_op_ctx op;\n\tunsigned int offset;\n\tunsigned int size;\n\tbool skip_ctx;\n};\n\n \nstruct mv_cesa_skcipher_req {\n\tstruct mv_cesa_req base;\n\tstruct mv_cesa_skcipher_std_req std;\n\tint src_nents;\n\tint dst_nents;\n};\n\n \nstruct mv_cesa_ahash_std_req {\n\tunsigned int offset;\n};\n\n \nstruct mv_cesa_ahash_dma_req {\n\tu8 *padding;\n\tdma_addr_t padding_dma;\n\tu8 *cache;\n\tdma_addr_t cache_dma;\n};\n\n \nstruct mv_cesa_ahash_req {\n\tstruct mv_cesa_req base;\n\tunion {\n\t\tstruct mv_cesa_ahash_dma_req dma;\n\t\tstruct mv_cesa_ahash_std_req std;\n\t} req;\n\tstruct mv_cesa_op_ctx op_tmpl;\n\tu8 cache[CESA_MAX_HASH_BLOCK_SIZE];\n\tunsigned int cache_ptr;\n\tu64 len;\n\tint src_nents;\n\tbool last_req;\n\tbool algo_le;\n\tu32 state[8];\n};\n\n \n\nextern struct mv_cesa_dev *cesa_dev;\n\n\nstatic inline void\nmv_cesa_engine_enqueue_complete_request(struct mv_cesa_engine *engine,\n\t\t\t\t\tstruct crypto_async_request *req)\n{\n\tlist_add_tail(&req->list, &engine->complete_queue);\n}\n\nstatic inline struct crypto_async_request *\nmv_cesa_engine_dequeue_complete_request(struct mv_cesa_engine *engine)\n{\n\tstruct crypto_async_request *req;\n\n\treq = list_first_entry_or_null(&engine->complete_queue,\n\t\t\t\t       struct crypto_async_request,\n\t\t\t\t       list);\n\tif (req)\n\t\tlist_del(&req->list);\n\n\treturn req;\n}\n\n\nstatic inline enum mv_cesa_req_type\nmv_cesa_req_get_type(struct mv_cesa_req *req)\n{\n\treturn req->chain.first ? CESA_DMA_REQ : CESA_STD_REQ;\n}\n\nstatic inline void mv_cesa_update_op_cfg(struct mv_cesa_op_ctx *op,\n\t\t\t\t\t u32 cfg, u32 mask)\n{\n\top->desc.config &= cpu_to_le32(~mask);\n\top->desc.config |= cpu_to_le32(cfg);\n}\n\nstatic inline u32 mv_cesa_get_op_cfg(const struct mv_cesa_op_ctx *op)\n{\n\treturn le32_to_cpu(op->desc.config);\n}\n\nstatic inline void mv_cesa_set_op_cfg(struct mv_cesa_op_ctx *op, u32 cfg)\n{\n\top->desc.config = cpu_to_le32(cfg);\n}\n\nstatic inline void mv_cesa_adjust_op(struct mv_cesa_engine *engine,\n\t\t\t\t     struct mv_cesa_op_ctx *op)\n{\n\tu32 offset = engine->sram_dma & CESA_SA_SRAM_MSK;\n\n\top->desc.enc_p = CESA_SA_DESC_CRYPT_DATA(offset);\n\top->desc.enc_key_p = CESA_SA_DESC_CRYPT_KEY(offset);\n\top->desc.enc_iv = CESA_SA_DESC_CRYPT_IV(offset);\n\top->desc.mac_src_p &= ~CESA_SA_DESC_MAC_DATA_MSK;\n\top->desc.mac_src_p |= CESA_SA_DESC_MAC_DATA(offset);\n\top->desc.mac_digest &= ~CESA_SA_DESC_MAC_DIGEST_MSK;\n\top->desc.mac_digest |= CESA_SA_DESC_MAC_DIGEST(offset);\n\top->desc.mac_iv = CESA_SA_DESC_MAC_IV(offset);\n}\n\nstatic inline void mv_cesa_set_crypt_op_len(struct mv_cesa_op_ctx *op, int len)\n{\n\top->desc.enc_len = cpu_to_le32(len);\n}\n\nstatic inline void mv_cesa_set_mac_op_total_len(struct mv_cesa_op_ctx *op,\n\t\t\t\t\t\tint len)\n{\n\top->desc.mac_src_p &= ~CESA_SA_DESC_MAC_TOTAL_LEN_MSK;\n\top->desc.mac_src_p |= CESA_SA_DESC_MAC_TOTAL_LEN(len);\n}\n\nstatic inline void mv_cesa_set_mac_op_frag_len(struct mv_cesa_op_ctx *op,\n\t\t\t\t\t       int len)\n{\n\top->desc.mac_digest &= ~CESA_SA_DESC_MAC_FRAG_LEN_MSK;\n\top->desc.mac_digest |= CESA_SA_DESC_MAC_FRAG_LEN(len);\n}\n\nstatic inline void mv_cesa_set_int_mask(struct mv_cesa_engine *engine,\n\t\t\t\t\tu32 int_mask)\n{\n\tif (int_mask == engine->int_mask)\n\t\treturn;\n\n\twritel_relaxed(int_mask, engine->regs + CESA_SA_INT_MSK);\n\tengine->int_mask = int_mask;\n}\n\nstatic inline u32 mv_cesa_get_int_mask(struct mv_cesa_engine *engine)\n{\n\treturn engine->int_mask;\n}\n\nstatic inline bool mv_cesa_mac_op_is_first_frag(const struct mv_cesa_op_ctx *op)\n{\n\treturn (mv_cesa_get_op_cfg(op) & CESA_SA_DESC_CFG_FRAG_MSK) ==\n\t\tCESA_SA_DESC_CFG_FIRST_FRAG;\n}\n\nint mv_cesa_queue_req(struct crypto_async_request *req,\n\t\t      struct mv_cesa_req *creq);\n\nstruct crypto_async_request *\nmv_cesa_dequeue_req_locked(struct mv_cesa_engine *engine,\n\t\t\t   struct crypto_async_request **backlog);\n\nstatic inline struct mv_cesa_engine *mv_cesa_select_engine(int weight)\n{\n\tint i;\n\tu32 min_load = U32_MAX;\n\tstruct mv_cesa_engine *selected = NULL;\n\n\tfor (i = 0; i < cesa_dev->caps->nengines; i++) {\n\t\tstruct mv_cesa_engine *engine = cesa_dev->engines + i;\n\t\tu32 load = atomic_read(&engine->load);\n\n\t\tif (load < min_load) {\n\t\t\tmin_load = load;\n\t\t\tselected = engine;\n\t\t}\n\t}\n\n\tatomic_add(weight, &selected->load);\n\n\treturn selected;\n}\n\n \nstatic inline int mv_cesa_req_needs_cleanup(struct crypto_async_request *req,\n\t\t\t\t\t    int ret)\n{\n\t \n\tif (ret == -EINPROGRESS)\n\t\treturn false;\n\n\t \n\tif (ret == -EBUSY)\n\t\treturn false;\n\n\t \n\treturn true;\n}\n\n \n\nstatic inline void mv_cesa_req_dma_iter_init(struct mv_cesa_dma_iter *iter,\n\t\t\t\t\t     unsigned int len)\n{\n\titer->len = len;\n\titer->op_len = min(len, CESA_SA_SRAM_PAYLOAD_SIZE);\n\titer->offset = 0;\n}\n\nstatic inline void mv_cesa_sg_dma_iter_init(struct mv_cesa_sg_dma_iter *iter,\n\t\t\t\t\t    struct scatterlist *sg,\n\t\t\t\t\t    enum dma_data_direction dir)\n{\n\titer->op_offset = 0;\n\titer->offset = 0;\n\titer->sg = sg;\n\titer->dir = dir;\n}\n\nstatic inline unsigned int\nmv_cesa_req_dma_iter_transfer_len(struct mv_cesa_dma_iter *iter,\n\t\t\t\t  struct mv_cesa_sg_dma_iter *sgiter)\n{\n\treturn min(iter->op_len - sgiter->op_offset,\n\t\t   sg_dma_len(sgiter->sg) - sgiter->offset);\n}\n\nbool mv_cesa_req_dma_iter_next_transfer(struct mv_cesa_dma_iter *chain,\n\t\t\t\t\tstruct mv_cesa_sg_dma_iter *sgiter,\n\t\t\t\t\tunsigned int len);\n\nstatic inline bool mv_cesa_req_dma_iter_next_op(struct mv_cesa_dma_iter *iter)\n{\n\titer->offset += iter->op_len;\n\titer->op_len = min(iter->len - iter->offset,\n\t\t\t   CESA_SA_SRAM_PAYLOAD_SIZE);\n\n\treturn iter->op_len;\n}\n\nvoid mv_cesa_dma_step(struct mv_cesa_req *dreq);\n\nstatic inline int mv_cesa_dma_process(struct mv_cesa_req *dreq,\n\t\t\t\t      u32 status)\n{\n\tif (!(status & CESA_SA_INT_ACC0_IDMA_DONE))\n\t\treturn -EINPROGRESS;\n\n\tif (status & CESA_SA_INT_IDMA_OWN_ERR)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nvoid mv_cesa_dma_prepare(struct mv_cesa_req *dreq,\n\t\t\t struct mv_cesa_engine *engine);\nvoid mv_cesa_dma_cleanup(struct mv_cesa_req *dreq);\nvoid mv_cesa_tdma_chain(struct mv_cesa_engine *engine,\n\t\t\tstruct mv_cesa_req *dreq);\nint mv_cesa_tdma_process(struct mv_cesa_engine *engine, u32 status);\n\n\nstatic inline void\nmv_cesa_tdma_desc_iter_init(struct mv_cesa_tdma_chain *chain)\n{\n\tmemset(chain, 0, sizeof(*chain));\n}\n\nint mv_cesa_dma_add_result_op(struct mv_cesa_tdma_chain *chain, dma_addr_t src,\n\t\t\t  u32 size, u32 flags, gfp_t gfp_flags);\n\nstruct mv_cesa_op_ctx *mv_cesa_dma_add_op(struct mv_cesa_tdma_chain *chain,\n\t\t\t\t\tconst struct mv_cesa_op_ctx *op_templ,\n\t\t\t\t\tbool skip_ctx,\n\t\t\t\t\tgfp_t flags);\n\nint mv_cesa_dma_add_data_transfer(struct mv_cesa_tdma_chain *chain,\n\t\t\t\t  dma_addr_t dst, dma_addr_t src, u32 size,\n\t\t\t\t  u32 flags, gfp_t gfp_flags);\n\nint mv_cesa_dma_add_dummy_launch(struct mv_cesa_tdma_chain *chain, gfp_t flags);\nint mv_cesa_dma_add_dummy_end(struct mv_cesa_tdma_chain *chain, gfp_t flags);\n\nint mv_cesa_dma_add_op_transfers(struct mv_cesa_tdma_chain *chain,\n\t\t\t\t struct mv_cesa_dma_iter *dma_iter,\n\t\t\t\t struct mv_cesa_sg_dma_iter *sgiter,\n\t\t\t\t gfp_t gfp_flags);\n\nsize_t mv_cesa_sg_copy(struct mv_cesa_engine *engine,\n\t\t       struct scatterlist *sgl, unsigned int nents,\n\t\t       unsigned int sram_off, size_t buflen, off_t skip,\n\t\t       bool to_sram);\n\nstatic inline size_t mv_cesa_sg_copy_to_sram(struct mv_cesa_engine *engine,\n\t\t\t\t\t     struct scatterlist *sgl,\n\t\t\t\t\t     unsigned int nents,\n\t\t\t\t\t     unsigned int sram_off,\n\t\t\t\t\t     size_t buflen, off_t skip)\n{\n\treturn mv_cesa_sg_copy(engine, sgl, nents, sram_off, buflen, skip,\n\t\t\t       true);\n}\n\nstatic inline size_t mv_cesa_sg_copy_from_sram(struct mv_cesa_engine *engine,\n\t\t\t\t\t       struct scatterlist *sgl,\n\t\t\t\t\t       unsigned int nents,\n\t\t\t\t\t       unsigned int sram_off,\n\t\t\t\t\t       size_t buflen, off_t skip)\n{\n\treturn mv_cesa_sg_copy(engine, sgl, nents, sram_off, buflen, skip,\n\t\t\t       false);\n}\n\n \n\nextern struct ahash_alg mv_md5_alg;\nextern struct ahash_alg mv_sha1_alg;\nextern struct ahash_alg mv_sha256_alg;\nextern struct ahash_alg mv_ahmac_md5_alg;\nextern struct ahash_alg mv_ahmac_sha1_alg;\nextern struct ahash_alg mv_ahmac_sha256_alg;\n\nextern struct skcipher_alg mv_cesa_ecb_des_alg;\nextern struct skcipher_alg mv_cesa_cbc_des_alg;\nextern struct skcipher_alg mv_cesa_ecb_des3_ede_alg;\nextern struct skcipher_alg mv_cesa_cbc_des3_ede_alg;\nextern struct skcipher_alg mv_cesa_ecb_aes_alg;\nextern struct skcipher_alg mv_cesa_cbc_aes_alg;\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}