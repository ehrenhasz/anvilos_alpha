{
  "module_name": "otx_cptvf_main.c",
  "hash_id": "ca0a8d17815e19da2f14ff175966989a643c0e5fdb1a27c85bce352de8ee475e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/marvell/octeontx/otx_cptvf_main.c",
  "human_readable_source": "\n \n\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include \"otx_cptvf.h\"\n#include \"otx_cptvf_algs.h\"\n#include \"otx_cptvf_reqmgr.h\"\n\n#define DRV_NAME\t\"octeontx-cptvf\"\n#define DRV_VERSION\t\"1.0\"\n\nstatic void vq_work_handler(unsigned long data)\n{\n\tstruct otx_cptvf_wqe_info *cwqe_info =\n\t\t\t\t\t(struct otx_cptvf_wqe_info *) data;\n\n\totx_cpt_post_process(&cwqe_info->vq_wqe[0]);\n}\n\nstatic int init_worker_threads(struct otx_cptvf *cptvf)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tstruct otx_cptvf_wqe_info *cwqe_info;\n\tint i;\n\n\tcwqe_info = kzalloc(sizeof(*cwqe_info), GFP_KERNEL);\n\tif (!cwqe_info)\n\t\treturn -ENOMEM;\n\n\tif (cptvf->num_queues) {\n\t\tdev_dbg(&pdev->dev, \"Creating VQ worker threads (%d)\\n\",\n\t\t\tcptvf->num_queues);\n\t}\n\n\tfor (i = 0; i < cptvf->num_queues; i++) {\n\t\ttasklet_init(&cwqe_info->vq_wqe[i].twork, vq_work_handler,\n\t\t\t     (u64)cwqe_info);\n\t\tcwqe_info->vq_wqe[i].cptvf = cptvf;\n\t}\n\tcptvf->wqe_info = cwqe_info;\n\n\treturn 0;\n}\n\nstatic void cleanup_worker_threads(struct otx_cptvf *cptvf)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tstruct otx_cptvf_wqe_info *cwqe_info;\n\tint i;\n\n\tcwqe_info = (struct otx_cptvf_wqe_info *)cptvf->wqe_info;\n\tif (!cwqe_info)\n\t\treturn;\n\n\tif (cptvf->num_queues) {\n\t\tdev_dbg(&pdev->dev, \"Cleaning VQ worker threads (%u)\\n\",\n\t\t\tcptvf->num_queues);\n\t}\n\n\tfor (i = 0; i < cptvf->num_queues; i++)\n\t\ttasklet_kill(&cwqe_info->vq_wqe[i].twork);\n\n\tkfree_sensitive(cwqe_info);\n\tcptvf->wqe_info = NULL;\n}\n\nstatic void free_pending_queues(struct otx_cpt_pending_qinfo *pqinfo)\n{\n\tstruct otx_cpt_pending_queue *queue;\n\tint i;\n\n\tfor_each_pending_queue(pqinfo, queue, i) {\n\t\tif (!queue->head)\n\t\t\tcontinue;\n\n\t\t \n\t\tkfree_sensitive((queue->head));\n\t\tqueue->front = 0;\n\t\tqueue->rear = 0;\n\t\tqueue->qlen = 0;\n\t}\n\tpqinfo->num_queues = 0;\n}\n\nstatic int alloc_pending_queues(struct otx_cpt_pending_qinfo *pqinfo, u32 qlen,\n\t\t\t\tu32 num_queues)\n{\n\tstruct otx_cpt_pending_queue *queue = NULL;\n\tint ret;\n\tu32 i;\n\n\tpqinfo->num_queues = num_queues;\n\n\tfor_each_pending_queue(pqinfo, queue, i) {\n\t\tqueue->head = kcalloc(qlen, sizeof(*queue->head), GFP_KERNEL);\n\t\tif (!queue->head) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto pending_qfail;\n\t\t}\n\n\t\tqueue->pending_count = 0;\n\t\tqueue->front = 0;\n\t\tqueue->rear = 0;\n\t\tqueue->qlen = qlen;\n\n\t\t \n\t\tspin_lock_init(&queue->lock);\n\t}\n\treturn 0;\n\npending_qfail:\n\tfree_pending_queues(pqinfo);\n\n\treturn ret;\n}\n\nstatic int init_pending_queues(struct otx_cptvf *cptvf, u32 qlen,\n\t\t\t       u32 num_queues)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tint ret;\n\n\tif (!num_queues)\n\t\treturn 0;\n\n\tret = alloc_pending_queues(&cptvf->pqinfo, qlen, num_queues);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to setup pending queues (%u)\\n\",\n\t\t\tnum_queues);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic void cleanup_pending_queues(struct otx_cptvf *cptvf)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\n\tif (!cptvf->num_queues)\n\t\treturn;\n\n\tdev_dbg(&pdev->dev, \"Cleaning VQ pending queue (%u)\\n\",\n\t\tcptvf->num_queues);\n\tfree_pending_queues(&cptvf->pqinfo);\n}\n\nstatic void free_command_queues(struct otx_cptvf *cptvf,\n\t\t\t\tstruct otx_cpt_cmd_qinfo *cqinfo)\n{\n\tstruct otx_cpt_cmd_queue *queue = NULL;\n\tstruct otx_cpt_cmd_chunk *chunk = NULL;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tint i;\n\n\t \n\tfor (i = 0; i < cptvf->num_queues; i++) {\n\t\tqueue = &cqinfo->queue[i];\n\n\t\twhile (!list_empty(&cqinfo->queue[i].chead)) {\n\t\t\tchunk = list_first_entry(&cqinfo->queue[i].chead,\n\t\t\t\t\tstruct otx_cpt_cmd_chunk, nextchunk);\n\n\t\t\tdma_free_coherent(&pdev->dev, chunk->size,\n\t\t\t\t\t  chunk->head,\n\t\t\t\t\t  chunk->dma_addr);\n\t\t\tchunk->head = NULL;\n\t\t\tchunk->dma_addr = 0;\n\t\t\tlist_del(&chunk->nextchunk);\n\t\t\tkfree_sensitive(chunk);\n\t\t}\n\t\tqueue->num_chunks = 0;\n\t\tqueue->idx = 0;\n\n\t}\n}\n\nstatic int alloc_command_queues(struct otx_cptvf *cptvf,\n\t\t\t\tstruct otx_cpt_cmd_qinfo *cqinfo,\n\t\t\t\tu32 qlen)\n{\n\tstruct otx_cpt_cmd_chunk *curr, *first, *last;\n\tstruct otx_cpt_cmd_queue *queue = NULL;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tsize_t q_size, c_size, rem_q_size;\n\tu32 qcsize_bytes;\n\tint i;\n\n\n\t \n\tcptvf->qsize = min(qlen, cqinfo->qchunksize) *\n\t\t       OTX_CPT_NEXT_CHUNK_PTR_SIZE + 1;\n\t \n\tq_size = qlen * OTX_CPT_INST_SIZE;\n\n\tqcsize_bytes = cqinfo->qchunksize * OTX_CPT_INST_SIZE;\n\n\t \n\tfor (i = 0; i < cptvf->num_queues; i++) {\n\t\trem_q_size = q_size;\n\t\tfirst = NULL;\n\t\tlast = NULL;\n\n\t\tqueue = &cqinfo->queue[i];\n\t\tINIT_LIST_HEAD(&queue->chead);\n\t\tdo {\n\t\t\tcurr = kzalloc(sizeof(*curr), GFP_KERNEL);\n\t\t\tif (!curr)\n\t\t\t\tgoto cmd_qfail;\n\n\t\t\tc_size = (rem_q_size > qcsize_bytes) ? qcsize_bytes :\n\t\t\t\t\trem_q_size;\n\t\t\tcurr->head = dma_alloc_coherent(&pdev->dev,\n\t\t\t\t\t   c_size + OTX_CPT_NEXT_CHUNK_PTR_SIZE,\n\t\t\t\t\t   &curr->dma_addr, GFP_KERNEL);\n\t\t\tif (!curr->head) {\n\t\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Command Q (%d) chunk (%d) allocation failed\\n\",\n\t\t\t\t\ti, queue->num_chunks);\n\t\t\t\tgoto free_curr;\n\t\t\t}\n\t\t\tcurr->size = c_size;\n\n\t\t\tif (queue->num_chunks == 0) {\n\t\t\t\tfirst = curr;\n\t\t\t\tqueue->base  = first;\n\t\t\t}\n\t\t\tlist_add_tail(&curr->nextchunk,\n\t\t\t\t      &cqinfo->queue[i].chead);\n\n\t\t\tqueue->num_chunks++;\n\t\t\trem_q_size -= c_size;\n\t\t\tif (last)\n\t\t\t\t*((u64 *)(&last->head[last->size])) =\n\t\t\t\t\t(u64)curr->dma_addr;\n\n\t\t\tlast = curr;\n\t\t} while (rem_q_size);\n\n\t\t \n\t\tcurr = first;\n\t\t*((u64 *)(&last->head[last->size])) = (u64)curr->dma_addr;\n\t\tqueue->qhead = curr;\n\t}\n\treturn 0;\nfree_curr:\n\tkfree(curr);\ncmd_qfail:\n\tfree_command_queues(cptvf, cqinfo);\n\treturn -ENOMEM;\n}\n\nstatic int init_command_queues(struct otx_cptvf *cptvf, u32 qlen)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tint ret;\n\n\t \n\tret = alloc_command_queues(cptvf, &cptvf->cqinfo, qlen);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to allocate command queues (%u)\\n\",\n\t\t\tcptvf->num_queues);\n\t\treturn ret;\n\t}\n\treturn ret;\n}\n\nstatic void cleanup_command_queues(struct otx_cptvf *cptvf)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\n\tif (!cptvf->num_queues)\n\t\treturn;\n\n\tdev_dbg(&pdev->dev, \"Cleaning VQ command queue (%u)\\n\",\n\t\tcptvf->num_queues);\n\tfree_command_queues(cptvf, &cptvf->cqinfo);\n}\n\nstatic void cptvf_sw_cleanup(struct otx_cptvf *cptvf)\n{\n\tcleanup_worker_threads(cptvf);\n\tcleanup_pending_queues(cptvf);\n\tcleanup_command_queues(cptvf);\n}\n\nstatic int cptvf_sw_init(struct otx_cptvf *cptvf, u32 qlen, u32 num_queues)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tu32 max_dev_queues = 0;\n\tint ret;\n\n\tmax_dev_queues = OTX_CPT_NUM_QS_PER_VF;\n\t \n\tnum_queues = min_t(u32, num_queues, max_dev_queues);\n\tcptvf->num_queues = num_queues;\n\n\tret = init_command_queues(cptvf, qlen);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to setup command queues (%u)\\n\",\n\t\t\tnum_queues);\n\t\treturn ret;\n\t}\n\n\tret = init_pending_queues(cptvf, qlen, num_queues);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to setup pending queues (%u)\\n\",\n\t\t\tnum_queues);\n\t\tgoto setup_pqfail;\n\t}\n\n\t \n\tret = init_worker_threads(cptvf);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to setup worker threads\\n\");\n\t\tgoto init_work_fail;\n\t}\n\treturn 0;\n\ninit_work_fail:\n\tcleanup_worker_threads(cptvf);\n\tcleanup_pending_queues(cptvf);\n\nsetup_pqfail:\n\tcleanup_command_queues(cptvf);\n\n\treturn ret;\n}\n\nstatic void cptvf_free_irq_affinity(struct otx_cptvf *cptvf, int vec)\n{\n\tirq_set_affinity_hint(pci_irq_vector(cptvf->pdev, vec), NULL);\n\tfree_cpumask_var(cptvf->affinity_mask[vec]);\n}\n\nstatic void cptvf_write_vq_ctl(struct otx_cptvf *cptvf, bool val)\n{\n\tunion otx_cptx_vqx_ctl vqx_ctl;\n\n\tvqx_ctl.u = readq(cptvf->reg_base + OTX_CPT_VQX_CTL(0));\n\tvqx_ctl.s.ena = val;\n\twriteq(vqx_ctl.u, cptvf->reg_base + OTX_CPT_VQX_CTL(0));\n}\n\nvoid otx_cptvf_write_vq_doorbell(struct otx_cptvf *cptvf, u32 val)\n{\n\tunion otx_cptx_vqx_doorbell vqx_dbell;\n\n\tvqx_dbell.u = readq(cptvf->reg_base + OTX_CPT_VQX_DOORBELL(0));\n\tvqx_dbell.s.dbell_cnt = val * 8;  \n\twriteq(vqx_dbell.u, cptvf->reg_base + OTX_CPT_VQX_DOORBELL(0));\n}\n\nstatic void cptvf_write_vq_inprog(struct otx_cptvf *cptvf, u8 val)\n{\n\tunion otx_cptx_vqx_inprog vqx_inprg;\n\n\tvqx_inprg.u = readq(cptvf->reg_base + OTX_CPT_VQX_INPROG(0));\n\tvqx_inprg.s.inflight = val;\n\twriteq(vqx_inprg.u, cptvf->reg_base + OTX_CPT_VQX_INPROG(0));\n}\n\nstatic void cptvf_write_vq_done_numwait(struct otx_cptvf *cptvf, u32 val)\n{\n\tunion otx_cptx_vqx_done_wait vqx_dwait;\n\n\tvqx_dwait.u = readq(cptvf->reg_base + OTX_CPT_VQX_DONE_WAIT(0));\n\tvqx_dwait.s.num_wait = val;\n\twriteq(vqx_dwait.u, cptvf->reg_base + OTX_CPT_VQX_DONE_WAIT(0));\n}\n\nstatic u32 cptvf_read_vq_done_numwait(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_done_wait vqx_dwait;\n\n\tvqx_dwait.u = readq(cptvf->reg_base + OTX_CPT_VQX_DONE_WAIT(0));\n\treturn vqx_dwait.s.num_wait;\n}\n\nstatic void cptvf_write_vq_done_timewait(struct otx_cptvf *cptvf, u16 time)\n{\n\tunion otx_cptx_vqx_done_wait vqx_dwait;\n\n\tvqx_dwait.u = readq(cptvf->reg_base + OTX_CPT_VQX_DONE_WAIT(0));\n\tvqx_dwait.s.time_wait = time;\n\twriteq(vqx_dwait.u, cptvf->reg_base + OTX_CPT_VQX_DONE_WAIT(0));\n}\n\n\nstatic u16 cptvf_read_vq_done_timewait(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_done_wait vqx_dwait;\n\n\tvqx_dwait.u = readq(cptvf->reg_base + OTX_CPT_VQX_DONE_WAIT(0));\n\treturn vqx_dwait.s.time_wait;\n}\n\nstatic void cptvf_enable_swerr_interrupts(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_misc_ena_w1s vqx_misc_ena;\n\n\tvqx_misc_ena.u = readq(cptvf->reg_base + OTX_CPT_VQX_MISC_ENA_W1S(0));\n\t \n\tvqx_misc_ena.s.swerr = 1;\n\twriteq(vqx_misc_ena.u, cptvf->reg_base + OTX_CPT_VQX_MISC_ENA_W1S(0));\n}\n\nstatic void cptvf_enable_mbox_interrupts(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_misc_ena_w1s vqx_misc_ena;\n\n\tvqx_misc_ena.u = readq(cptvf->reg_base + OTX_CPT_VQX_MISC_ENA_W1S(0));\n\t \n\tvqx_misc_ena.s.mbox = 1;\n\twriteq(vqx_misc_ena.u, cptvf->reg_base + OTX_CPT_VQX_MISC_ENA_W1S(0));\n}\n\nstatic void cptvf_enable_done_interrupts(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_done_ena_w1s vqx_done_ena;\n\n\tvqx_done_ena.u = readq(cptvf->reg_base + OTX_CPT_VQX_DONE_ENA_W1S(0));\n\t \n\tvqx_done_ena.s.done = 1;\n\twriteq(vqx_done_ena.u, cptvf->reg_base + OTX_CPT_VQX_DONE_ENA_W1S(0));\n}\n\nstatic void cptvf_clear_dovf_intr(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_misc_int vqx_misc_int;\n\n\tvqx_misc_int.u = readq(cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n\t \n\tvqx_misc_int.s.dovf = 1;\n\twriteq(vqx_misc_int.u, cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n}\n\nstatic void cptvf_clear_irde_intr(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_misc_int vqx_misc_int;\n\n\tvqx_misc_int.u = readq(cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n\t \n\tvqx_misc_int.s.irde = 1;\n\twriteq(vqx_misc_int.u, cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n}\n\nstatic void cptvf_clear_nwrp_intr(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_misc_int vqx_misc_int;\n\n\tvqx_misc_int.u = readq(cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n\t \n\tvqx_misc_int.s.nwrp = 1;\n\twriteq(vqx_misc_int.u, cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n}\n\nstatic void cptvf_clear_mbox_intr(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_misc_int vqx_misc_int;\n\n\tvqx_misc_int.u = readq(cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n\t \n\tvqx_misc_int.s.mbox = 1;\n\twriteq(vqx_misc_int.u, cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n}\n\nstatic void cptvf_clear_swerr_intr(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_misc_int vqx_misc_int;\n\n\tvqx_misc_int.u = readq(cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n\t \n\tvqx_misc_int.s.swerr = 1;\n\twriteq(vqx_misc_int.u, cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n}\n\nstatic u64 cptvf_read_vf_misc_intr_status(struct otx_cptvf *cptvf)\n{\n\treturn readq(cptvf->reg_base + OTX_CPT_VQX_MISC_INT(0));\n}\n\nstatic irqreturn_t cptvf_misc_intr_handler(int __always_unused irq,\n\t\t\t\t\t   void *arg)\n{\n\tstruct otx_cptvf *cptvf = arg;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tu64 intr;\n\n\tintr = cptvf_read_vf_misc_intr_status(cptvf);\n\t \n\tif (likely(intr & OTX_CPT_VF_INTR_MBOX_MASK)) {\n\t\tdev_dbg(&pdev->dev, \"Mailbox interrupt 0x%llx on CPT VF %d\\n\",\n\t\t\tintr, cptvf->vfid);\n\t\totx_cptvf_handle_mbox_intr(cptvf);\n\t\tcptvf_clear_mbox_intr(cptvf);\n\t} else if (unlikely(intr & OTX_CPT_VF_INTR_DOVF_MASK)) {\n\t\tcptvf_clear_dovf_intr(cptvf);\n\t\t \n\t\totx_cptvf_write_vq_doorbell(cptvf, 0);\n\t\tdev_err(&pdev->dev,\n\t\t\"Doorbell overflow error interrupt 0x%llx on CPT VF %d\\n\",\n\t\t\tintr, cptvf->vfid);\n\t} else if (unlikely(intr & OTX_CPT_VF_INTR_IRDE_MASK)) {\n\t\tcptvf_clear_irde_intr(cptvf);\n\t\tdev_err(&pdev->dev,\n\t\t\"Instruction NCB read error interrupt 0x%llx on CPT VF %d\\n\",\n\t\t\tintr, cptvf->vfid);\n\t} else if (unlikely(intr & OTX_CPT_VF_INTR_NWRP_MASK)) {\n\t\tcptvf_clear_nwrp_intr(cptvf);\n\t\tdev_err(&pdev->dev,\n\t\t\"NCB response write error interrupt 0x%llx on CPT VF %d\\n\",\n\t\t\tintr, cptvf->vfid);\n\t} else if (unlikely(intr & OTX_CPT_VF_INTR_SERR_MASK)) {\n\t\tcptvf_clear_swerr_intr(cptvf);\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Software error interrupt 0x%llx on CPT VF %d\\n\",\n\t\t\tintr, cptvf->vfid);\n\t} else {\n\t\tdev_err(&pdev->dev, \"Unhandled interrupt in OTX_CPT VF %d\\n\",\n\t\t\tcptvf->vfid);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic inline struct otx_cptvf_wqe *get_cptvf_vq_wqe(struct otx_cptvf *cptvf,\n\t\t\t\t\t\t     int qno)\n{\n\tstruct otx_cptvf_wqe_info *nwqe_info;\n\n\tif (unlikely(qno >= cptvf->num_queues))\n\t\treturn NULL;\n\tnwqe_info = (struct otx_cptvf_wqe_info *)cptvf->wqe_info;\n\n\treturn &nwqe_info->vq_wqe[qno];\n}\n\nstatic inline u32 cptvf_read_vq_done_count(struct otx_cptvf *cptvf)\n{\n\tunion otx_cptx_vqx_done vqx_done;\n\n\tvqx_done.u = readq(cptvf->reg_base + OTX_CPT_VQX_DONE(0));\n\treturn vqx_done.s.done;\n}\n\nstatic inline void cptvf_write_vq_done_ack(struct otx_cptvf *cptvf,\n\t\t\t\t\t   u32 ackcnt)\n{\n\tunion otx_cptx_vqx_done_ack vqx_dack_cnt;\n\n\tvqx_dack_cnt.u = readq(cptvf->reg_base + OTX_CPT_VQX_DONE_ACK(0));\n\tvqx_dack_cnt.s.done_ack = ackcnt;\n\twriteq(vqx_dack_cnt.u, cptvf->reg_base + OTX_CPT_VQX_DONE_ACK(0));\n}\n\nstatic irqreturn_t cptvf_done_intr_handler(int __always_unused irq,\n\t\t\t\t\t   void *cptvf_dev)\n{\n\tstruct otx_cptvf *cptvf = (struct otx_cptvf *)cptvf_dev;\n\tstruct pci_dev *pdev = cptvf->pdev;\n\t \n\tu32 intr = cptvf_read_vq_done_count(cptvf);\n\n\tif (intr) {\n\t\tstruct otx_cptvf_wqe *wqe;\n\n\t\t \n\t\tcptvf_write_vq_done_ack(cptvf, intr);\n\t\twqe = get_cptvf_vq_wqe(cptvf, 0);\n\t\tif (unlikely(!wqe)) {\n\t\t\tdev_err(&pdev->dev, \"No work to schedule for VF (%d)\\n\",\n\t\t\t\tcptvf->vfid);\n\t\t\treturn IRQ_NONE;\n\t\t}\n\t\ttasklet_hi_schedule(&wqe->twork);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void cptvf_set_irq_affinity(struct otx_cptvf *cptvf, int vec)\n{\n\tstruct pci_dev *pdev = cptvf->pdev;\n\tint cpu;\n\n\tif (!zalloc_cpumask_var(&cptvf->affinity_mask[vec],\n\t\t\t\tGFP_KERNEL)) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Allocation failed for affinity_mask for VF %d\\n\",\n\t\t\tcptvf->vfid);\n\t\treturn;\n\t}\n\n\tcpu = cptvf->vfid % num_online_cpus();\n\tcpumask_set_cpu(cpumask_local_spread(cpu, cptvf->node),\n\t\t\tcptvf->affinity_mask[vec]);\n\tirq_set_affinity_hint(pci_irq_vector(pdev, vec),\n\t\t\t      cptvf->affinity_mask[vec]);\n}\n\nstatic void cptvf_write_vq_saddr(struct otx_cptvf *cptvf, u64 val)\n{\n\tunion otx_cptx_vqx_saddr vqx_saddr;\n\n\tvqx_saddr.u = val;\n\twriteq(vqx_saddr.u, cptvf->reg_base + OTX_CPT_VQX_SADDR(0));\n}\n\nstatic void cptvf_device_init(struct otx_cptvf *cptvf)\n{\n\tu64 base_addr = 0;\n\n\t \n\tcptvf_write_vq_ctl(cptvf, 0);\n\t \n\totx_cptvf_write_vq_doorbell(cptvf, 0);\n\t \n\tcptvf_write_vq_inprog(cptvf, 0);\n\t \n\tbase_addr = (u64)(cptvf->cqinfo.queue[0].qhead->dma_addr);\n\tcptvf_write_vq_saddr(cptvf, base_addr);\n\t \n\tcptvf_write_vq_done_timewait(cptvf, OTX_CPT_TIMER_HOLD);\n\tcptvf_write_vq_done_numwait(cptvf, OTX_CPT_COUNT_HOLD);\n\t \n\tcptvf_write_vq_ctl(cptvf, 1);\n\t \n\tcptvf->flags |= OTX_CPT_FLAG_DEVICE_READY;\n}\n\nstatic ssize_t vf_type_show(struct device *dev,\n\t\t\t    struct device_attribute *attr,\n\t\t\t    char *buf)\n{\n\tstruct otx_cptvf *cptvf = dev_get_drvdata(dev);\n\tchar *msg;\n\n\tswitch (cptvf->vftype) {\n\tcase OTX_CPT_AE_TYPES:\n\t\tmsg = \"AE\";\n\t\tbreak;\n\n\tcase OTX_CPT_SE_TYPES:\n\t\tmsg = \"SE\";\n\t\tbreak;\n\n\tdefault:\n\t\tmsg = \"Invalid\";\n\t}\n\n\treturn sysfs_emit(buf, \"%s\\n\", msg);\n}\n\nstatic ssize_t vf_engine_group_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t    char *buf)\n{\n\tstruct otx_cptvf *cptvf = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", cptvf->vfgrp);\n}\n\nstatic ssize_t vf_engine_group_store(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t count)\n{\n\tstruct otx_cptvf *cptvf = dev_get_drvdata(dev);\n\tint val, ret;\n\n\tret = kstrtoint(buf, 10, &val);\n\tif (ret)\n\t\treturn ret;\n\n\tif (val < 0)\n\t\treturn -EINVAL;\n\n\tif (val >= OTX_CPT_MAX_ENGINE_GROUPS) {\n\t\tdev_err(dev, \"Engine group >= than max available groups %d\\n\",\n\t\t\tOTX_CPT_MAX_ENGINE_GROUPS);\n\t\treturn -EINVAL;\n\t}\n\n\tret = otx_cptvf_send_vf_to_grp_msg(cptvf, val);\n\tif (ret)\n\t\treturn ret;\n\n\treturn count;\n}\n\nstatic ssize_t vf_coalesc_time_wait_show(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct otx_cptvf *cptvf = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\",\n\t\t\t cptvf_read_vq_done_timewait(cptvf));\n}\n\nstatic ssize_t vf_coalesc_num_wait_show(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tstruct otx_cptvf *cptvf = dev_get_drvdata(dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\",\n\t\t\t cptvf_read_vq_done_numwait(cptvf));\n}\n\nstatic ssize_t vf_coalesc_time_wait_store(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  const char *buf, size_t count)\n{\n\tstruct otx_cptvf *cptvf = dev_get_drvdata(dev);\n\tlong val;\n\tint ret;\n\n\tret = kstrtol(buf, 10, &val);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tif (val < OTX_CPT_COALESC_MIN_TIME_WAIT ||\n\t    val > OTX_CPT_COALESC_MAX_TIME_WAIT)\n\t\treturn -EINVAL;\n\n\tcptvf_write_vq_done_timewait(cptvf, val);\n\treturn count;\n}\n\nstatic ssize_t vf_coalesc_num_wait_store(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t const char *buf, size_t count)\n{\n\tstruct otx_cptvf *cptvf = dev_get_drvdata(dev);\n\tlong val;\n\tint ret;\n\n\tret = kstrtol(buf, 10, &val);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tif (val < OTX_CPT_COALESC_MIN_NUM_WAIT ||\n\t    val > OTX_CPT_COALESC_MAX_NUM_WAIT)\n\t\treturn -EINVAL;\n\n\tcptvf_write_vq_done_numwait(cptvf, val);\n\treturn count;\n}\n\nstatic DEVICE_ATTR_RO(vf_type);\nstatic DEVICE_ATTR_RW(vf_engine_group);\nstatic DEVICE_ATTR_RW(vf_coalesc_time_wait);\nstatic DEVICE_ATTR_RW(vf_coalesc_num_wait);\n\nstatic struct attribute *otx_cptvf_attrs[] = {\n\t&dev_attr_vf_type.attr,\n\t&dev_attr_vf_engine_group.attr,\n\t&dev_attr_vf_coalesc_time_wait.attr,\n\t&dev_attr_vf_coalesc_num_wait.attr,\n\tNULL\n};\n\nstatic const struct attribute_group otx_cptvf_sysfs_group = {\n\t.attrs = otx_cptvf_attrs,\n};\n\nstatic int otx_cptvf_probe(struct pci_dev *pdev,\n\t\t\t   const struct pci_device_id *ent)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct otx_cptvf *cptvf;\n\tint err;\n\n\tcptvf = devm_kzalloc(dev, sizeof(*cptvf), GFP_KERNEL);\n\tif (!cptvf)\n\t\treturn -ENOMEM;\n\n\tpci_set_drvdata(pdev, cptvf);\n\tcptvf->pdev = pdev;\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to enable PCI device\\n\");\n\t\tgoto clear_drvdata;\n\t}\n\terr = pci_request_regions(pdev, DRV_NAME);\n\tif (err) {\n\t\tdev_err(dev, \"PCI request regions failed 0x%x\\n\", err);\n\t\tgoto disable_device;\n\t}\n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(48));\n\tif (err) {\n\t\tdev_err(dev, \"Unable to get usable 48-bit DMA configuration\\n\");\n\t\tgoto release_regions;\n\t}\n\n\t \n\tcptvf->reg_base = pci_iomap(pdev, OTX_CPT_VF_PCI_CFG_BAR, 0);\n\tif (!cptvf->reg_base) {\n\t\tdev_err(dev, \"Cannot map config register space, aborting\\n\");\n\t\terr = -ENOMEM;\n\t\tgoto release_regions;\n\t}\n\n\tcptvf->node = dev_to_node(&pdev->dev);\n\terr = pci_alloc_irq_vectors(pdev, OTX_CPT_VF_MSIX_VECTORS,\n\t\t\t\t    OTX_CPT_VF_MSIX_VECTORS, PCI_IRQ_MSIX);\n\tif (err < 0) {\n\t\tdev_err(dev, \"Request for #%d msix vectors failed\\n\",\n\t\t\tOTX_CPT_VF_MSIX_VECTORS);\n\t\tgoto unmap_region;\n\t}\n\n\terr = request_irq(pci_irq_vector(pdev, CPT_VF_INT_VEC_E_MISC),\n\t\t\t  cptvf_misc_intr_handler, 0, \"CPT VF misc intr\",\n\t\t\t  cptvf);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to request misc irq\\n\");\n\t\tgoto free_vectors;\n\t}\n\n\t \n\tcptvf_enable_mbox_interrupts(cptvf);\n\tcptvf_enable_swerr_interrupts(cptvf);\n\n\t \n\terr = otx_cptvf_check_pf_ready(cptvf);\n\tif (err)\n\t\tgoto free_misc_irq;\n\n\t \n\tcptvf->cqinfo.qchunksize = OTX_CPT_CMD_QCHUNK_SIZE;\n\terr = cptvf_sw_init(cptvf, OTX_CPT_CMD_QLEN, OTX_CPT_NUM_QS_PER_VF);\n\tif (err) {\n\t\tdev_err(dev, \"cptvf_sw_init() failed\\n\");\n\t\tgoto free_misc_irq;\n\t}\n\t \n\terr = otx_cptvf_send_vq_size_msg(cptvf);\n\tif (err)\n\t\tgoto sw_cleanup;\n\n\t \n\tcptvf_device_init(cptvf);\n\t \n\terr = otx_cptvf_send_vf_to_grp_msg(cptvf, cptvf->vfgrp);\n\tif (err)\n\t\tgoto sw_cleanup;\n\n\tcptvf->priority = 1;\n\terr = otx_cptvf_send_vf_priority_msg(cptvf);\n\tif (err)\n\t\tgoto sw_cleanup;\n\n\terr = request_irq(pci_irq_vector(pdev, CPT_VF_INT_VEC_E_DONE),\n\t\t\t  cptvf_done_intr_handler, 0, \"CPT VF done intr\",\n\t\t\t  cptvf);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to request done irq\\n\");\n\t\tgoto free_done_irq;\n\t}\n\n\t \n\tcptvf_enable_done_interrupts(cptvf);\n\n\t \n\tcptvf_set_irq_affinity(cptvf, CPT_VF_INT_VEC_E_MISC);\n\tcptvf_set_irq_affinity(cptvf, CPT_VF_INT_VEC_E_DONE);\n\n\terr = otx_cptvf_send_vf_up(cptvf);\n\tif (err)\n\t\tgoto free_irq_affinity;\n\n\t \n\terr = otx_cpt_crypto_init(pdev, THIS_MODULE,\n\t\t    cptvf->vftype == OTX_CPT_SE_TYPES ? OTX_CPT_SE : OTX_CPT_AE,\n\t\t    cptvf->vftype, 1, cptvf->num_vfs);\n\tif (err) {\n\t\tdev_err(dev, \"Failed to register crypto algs\\n\");\n\t\tgoto free_irq_affinity;\n\t}\n\n\terr = sysfs_create_group(&dev->kobj, &otx_cptvf_sysfs_group);\n\tif (err) {\n\t\tdev_err(dev, \"Creating sysfs entries failed\\n\");\n\t\tgoto crypto_exit;\n\t}\n\n\treturn 0;\n\ncrypto_exit:\n\totx_cpt_crypto_exit(pdev, THIS_MODULE, cptvf->vftype);\nfree_irq_affinity:\n\tcptvf_free_irq_affinity(cptvf, CPT_VF_INT_VEC_E_DONE);\n\tcptvf_free_irq_affinity(cptvf, CPT_VF_INT_VEC_E_MISC);\nfree_done_irq:\n\tfree_irq(pci_irq_vector(pdev, CPT_VF_INT_VEC_E_DONE), cptvf);\nsw_cleanup:\n\tcptvf_sw_cleanup(cptvf);\nfree_misc_irq:\n\tfree_irq(pci_irq_vector(pdev, CPT_VF_INT_VEC_E_MISC), cptvf);\nfree_vectors:\n\tpci_free_irq_vectors(cptvf->pdev);\nunmap_region:\n\tpci_iounmap(pdev, cptvf->reg_base);\nrelease_regions:\n\tpci_release_regions(pdev);\ndisable_device:\n\tpci_disable_device(pdev);\nclear_drvdata:\n\tpci_set_drvdata(pdev, NULL);\n\n\treturn err;\n}\n\nstatic void otx_cptvf_remove(struct pci_dev *pdev)\n{\n\tstruct otx_cptvf *cptvf = pci_get_drvdata(pdev);\n\n\tif (!cptvf) {\n\t\tdev_err(&pdev->dev, \"Invalid CPT-VF device\\n\");\n\t\treturn;\n\t}\n\n\t \n\tif (otx_cptvf_send_vf_down(cptvf)) {\n\t\tdev_err(&pdev->dev, \"PF not responding to DOWN msg\\n\");\n\t} else {\n\t\tsysfs_remove_group(&pdev->dev.kobj, &otx_cptvf_sysfs_group);\n\t\totx_cpt_crypto_exit(pdev, THIS_MODULE, cptvf->vftype);\n\t\tcptvf_free_irq_affinity(cptvf, CPT_VF_INT_VEC_E_DONE);\n\t\tcptvf_free_irq_affinity(cptvf, CPT_VF_INT_VEC_E_MISC);\n\t\tfree_irq(pci_irq_vector(pdev, CPT_VF_INT_VEC_E_DONE), cptvf);\n\t\tfree_irq(pci_irq_vector(pdev, CPT_VF_INT_VEC_E_MISC), cptvf);\n\t\tcptvf_sw_cleanup(cptvf);\n\t\tpci_free_irq_vectors(cptvf->pdev);\n\t\tpci_iounmap(pdev, cptvf->reg_base);\n\t\tpci_release_regions(pdev);\n\t\tpci_disable_device(pdev);\n\t\tpci_set_drvdata(pdev, NULL);\n\t}\n}\n\n \nstatic const struct pci_device_id otx_cptvf_id_table[] = {\n\t{PCI_VDEVICE(CAVIUM, OTX_CPT_PCI_VF_DEVICE_ID), 0},\n\t{ 0, }   \n};\n\nstatic struct pci_driver otx_cptvf_pci_driver = {\n\t.name = DRV_NAME,\n\t.id_table = otx_cptvf_id_table,\n\t.probe = otx_cptvf_probe,\n\t.remove = otx_cptvf_remove,\n};\n\nmodule_pci_driver(otx_cptvf_pci_driver);\n\nMODULE_AUTHOR(\"Marvell International Ltd.\");\nMODULE_DESCRIPTION(\"Marvell OcteonTX CPT Virtual Function Driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_VERSION(DRV_VERSION);\nMODULE_DEVICE_TABLE(pci, otx_cptvf_id_table);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}