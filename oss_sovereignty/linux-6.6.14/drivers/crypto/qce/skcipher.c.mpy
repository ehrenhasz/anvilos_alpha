{
  "module_name": "skcipher.c",
  "hash_id": "4014f649931f8161d983934ef7df9bccf0f010d26a2db14f45721669f765c6d0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/qce/skcipher.c",
  "human_readable_source": "\n \n\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/interrupt.h>\n#include <linux/moduleparam.h>\n#include <linux/types.h>\n#include <linux/errno.h>\n#include <crypto/aes.h>\n#include <crypto/internal/des.h>\n#include <crypto/internal/skcipher.h>\n\n#include \"cipher.h\"\n\nstatic unsigned int aes_sw_max_len = CONFIG_CRYPTO_DEV_QCE_SW_MAX_LEN;\nmodule_param(aes_sw_max_len, uint, 0644);\nMODULE_PARM_DESC(aes_sw_max_len,\n\t\t \"Only use hardware for AES requests larger than this \"\n\t\t \"[0=always use hardware; anything <16 breaks AES-GCM; default=\"\n\t\t __stringify(CONFIG_CRYPTO_DEV_QCE_SW_MAX_LEN)\"]\");\n\nstatic LIST_HEAD(skcipher_algs);\n\nstatic void qce_skcipher_done(void *data)\n{\n\tstruct crypto_async_request *async_req = data;\n\tstruct skcipher_request *req = skcipher_request_cast(async_req);\n\tstruct qce_cipher_reqctx *rctx = skcipher_request_ctx(req);\n\tstruct qce_alg_template *tmpl = to_cipher_tmpl(crypto_skcipher_reqtfm(req));\n\tstruct qce_device *qce = tmpl->qce;\n\tstruct qce_result_dump *result_buf = qce->dma.result_buf;\n\tenum dma_data_direction dir_src, dir_dst;\n\tu32 status;\n\tint error;\n\tbool diff_dst;\n\n\tdiff_dst = (req->src != req->dst) ? true : false;\n\tdir_src = diff_dst ? DMA_TO_DEVICE : DMA_BIDIRECTIONAL;\n\tdir_dst = diff_dst ? DMA_FROM_DEVICE : DMA_BIDIRECTIONAL;\n\n\terror = qce_dma_terminate_all(&qce->dma);\n\tif (error)\n\t\tdev_dbg(qce->dev, \"skcipher dma termination error (%d)\\n\",\n\t\t\terror);\n\n\tif (diff_dst)\n\t\tdma_unmap_sg(qce->dev, rctx->src_sg, rctx->src_nents, dir_src);\n\tdma_unmap_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);\n\n\tsg_free_table(&rctx->dst_tbl);\n\n\terror = qce_check_status(qce, &status);\n\tif (error < 0)\n\t\tdev_dbg(qce->dev, \"skcipher operation error (%x)\\n\", status);\n\n\tmemcpy(rctx->iv, result_buf->encr_cntr_iv, rctx->ivsize);\n\tqce->async_req_done(tmpl->qce, error);\n}\n\nstatic int\nqce_skcipher_async_req_handle(struct crypto_async_request *async_req)\n{\n\tstruct skcipher_request *req = skcipher_request_cast(async_req);\n\tstruct qce_cipher_reqctx *rctx = skcipher_request_ctx(req);\n\tstruct crypto_skcipher *skcipher = crypto_skcipher_reqtfm(req);\n\tstruct qce_alg_template *tmpl = to_cipher_tmpl(crypto_skcipher_reqtfm(req));\n\tstruct qce_device *qce = tmpl->qce;\n\tenum dma_data_direction dir_src, dir_dst;\n\tstruct scatterlist *sg;\n\tbool diff_dst;\n\tgfp_t gfp;\n\tint dst_nents, src_nents, ret;\n\n\trctx->iv = req->iv;\n\trctx->ivsize = crypto_skcipher_ivsize(skcipher);\n\trctx->cryptlen = req->cryptlen;\n\n\tdiff_dst = (req->src != req->dst) ? true : false;\n\tdir_src = diff_dst ? DMA_TO_DEVICE : DMA_BIDIRECTIONAL;\n\tdir_dst = diff_dst ? DMA_FROM_DEVICE : DMA_BIDIRECTIONAL;\n\n\trctx->src_nents = sg_nents_for_len(req->src, req->cryptlen);\n\tif (diff_dst)\n\t\trctx->dst_nents = sg_nents_for_len(req->dst, req->cryptlen);\n\telse\n\t\trctx->dst_nents = rctx->src_nents;\n\tif (rctx->src_nents < 0) {\n\t\tdev_err(qce->dev, \"Invalid numbers of src SG.\\n\");\n\t\treturn rctx->src_nents;\n\t}\n\tif (rctx->dst_nents < 0) {\n\t\tdev_err(qce->dev, \"Invalid numbers of dst SG.\\n\");\n\t\treturn -rctx->dst_nents;\n\t}\n\n\trctx->dst_nents += 1;\n\n\tgfp = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?\n\t\t\t\t\t\tGFP_KERNEL : GFP_ATOMIC;\n\n\tret = sg_alloc_table(&rctx->dst_tbl, rctx->dst_nents, gfp);\n\tif (ret)\n\t\treturn ret;\n\n\tsg_init_one(&rctx->result_sg, qce->dma.result_buf, QCE_RESULT_BUF_SZ);\n\n\tsg = qce_sgtable_add(&rctx->dst_tbl, req->dst, req->cryptlen);\n\tif (IS_ERR(sg)) {\n\t\tret = PTR_ERR(sg);\n\t\tgoto error_free;\n\t}\n\n\tsg = qce_sgtable_add(&rctx->dst_tbl, &rctx->result_sg,\n\t\t\t     QCE_RESULT_BUF_SZ);\n\tif (IS_ERR(sg)) {\n\t\tret = PTR_ERR(sg);\n\t\tgoto error_free;\n\t}\n\n\tsg_mark_end(sg);\n\trctx->dst_sg = rctx->dst_tbl.sgl;\n\n\tdst_nents = dma_map_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);\n\tif (!dst_nents) {\n\t\tret = -EIO;\n\t\tgoto error_free;\n\t}\n\n\tif (diff_dst) {\n\t\tsrc_nents = dma_map_sg(qce->dev, req->src, rctx->src_nents, dir_src);\n\t\tif (!src_nents) {\n\t\t\tret = -EIO;\n\t\t\tgoto error_unmap_dst;\n\t\t}\n\t\trctx->src_sg = req->src;\n\t} else {\n\t\trctx->src_sg = rctx->dst_sg;\n\t\tsrc_nents = dst_nents - 1;\n\t}\n\n\tret = qce_dma_prep_sgs(&qce->dma, rctx->src_sg, src_nents,\n\t\t\t       rctx->dst_sg, dst_nents,\n\t\t\t       qce_skcipher_done, async_req);\n\tif (ret)\n\t\tgoto error_unmap_src;\n\n\tqce_dma_issue_pending(&qce->dma);\n\n\tret = qce_start(async_req, tmpl->crypto_alg_type);\n\tif (ret)\n\t\tgoto error_terminate;\n\n\treturn 0;\n\nerror_terminate:\n\tqce_dma_terminate_all(&qce->dma);\nerror_unmap_src:\n\tif (diff_dst)\n\t\tdma_unmap_sg(qce->dev, req->src, rctx->src_nents, dir_src);\nerror_unmap_dst:\n\tdma_unmap_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);\nerror_free:\n\tsg_free_table(&rctx->dst_tbl);\n\treturn ret;\n}\n\nstatic int qce_skcipher_setkey(struct crypto_skcipher *ablk, const u8 *key,\n\t\t\t\t unsigned int keylen)\n{\n\tstruct crypto_tfm *tfm = crypto_skcipher_tfm(ablk);\n\tstruct qce_cipher_ctx *ctx = crypto_tfm_ctx(tfm);\n\tunsigned long flags = to_cipher_tmpl(ablk)->alg_flags;\n\tunsigned int __keylen;\n\tint ret;\n\n\tif (!key || !keylen)\n\t\treturn -EINVAL;\n\n\t \n\tif (IS_XTS(flags)) {\n\t\t__keylen = keylen >> 1;\n\t\tif (!memcmp(key, key + __keylen, __keylen))\n\t\t\treturn -ENOKEY;\n\t} else {\n\t\t__keylen = keylen;\n\t}\n\n\tswitch (__keylen) {\n\tcase AES_KEYSIZE_128:\n\tcase AES_KEYSIZE_256:\n\t\tmemcpy(ctx->enc_key, key, keylen);\n\t\tbreak;\n\tcase AES_KEYSIZE_192:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tret = crypto_skcipher_setkey(ctx->fallback, key, keylen);\n\tif (!ret)\n\t\tctx->enc_keylen = keylen;\n\treturn ret;\n}\n\nstatic int qce_des_setkey(struct crypto_skcipher *ablk, const u8 *key,\n\t\t\t  unsigned int keylen)\n{\n\tstruct qce_cipher_ctx *ctx = crypto_skcipher_ctx(ablk);\n\tint err;\n\n\terr = verify_skcipher_des_key(ablk, key);\n\tif (err)\n\t\treturn err;\n\n\tctx->enc_keylen = keylen;\n\tmemcpy(ctx->enc_key, key, keylen);\n\treturn 0;\n}\n\nstatic int qce_des3_setkey(struct crypto_skcipher *ablk, const u8 *key,\n\t\t\t   unsigned int keylen)\n{\n\tstruct qce_cipher_ctx *ctx = crypto_skcipher_ctx(ablk);\n\tu32 _key[6];\n\tint err;\n\n\terr = verify_skcipher_des3_key(ablk, key);\n\tif (err)\n\t\treturn err;\n\n\t \n\tmemcpy(_key, key, DES3_EDE_KEY_SIZE);\n\tif (!((_key[0] ^ _key[2]) | (_key[1] ^ _key[3])) ||\n\t    !((_key[2] ^ _key[4]) | (_key[3] ^ _key[5])) ||\n\t    !((_key[0] ^ _key[4]) | (_key[1] ^ _key[5])))\n\t\treturn -ENOKEY;\n\n\tctx->enc_keylen = keylen;\n\tmemcpy(ctx->enc_key, key, keylen);\n\treturn 0;\n}\n\nstatic int qce_skcipher_crypt(struct skcipher_request *req, int encrypt)\n{\n\tstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\n\tstruct qce_cipher_ctx *ctx = crypto_skcipher_ctx(tfm);\n\tstruct qce_cipher_reqctx *rctx = skcipher_request_ctx(req);\n\tstruct qce_alg_template *tmpl = to_cipher_tmpl(tfm);\n\tunsigned int blocksize = crypto_skcipher_blocksize(tfm);\n\tint keylen;\n\tint ret;\n\n\trctx->flags = tmpl->alg_flags;\n\trctx->flags |= encrypt ? QCE_ENCRYPT : QCE_DECRYPT;\n\tkeylen = IS_XTS(rctx->flags) ? ctx->enc_keylen >> 1 : ctx->enc_keylen;\n\n\t \n\tif (!req->cryptlen)\n\t\treturn 0;\n\n\t \n\tif (IS_ECB(rctx->flags) || IS_CBC(rctx->flags))\n\t\tif (!IS_ALIGNED(req->cryptlen, blocksize))\n\t\t\treturn -EINVAL;\n\n\t \n\tif (IS_AES(rctx->flags) &&\n\t    ((keylen != AES_KEYSIZE_128 && keylen != AES_KEYSIZE_256) ||\n\t    (IS_XTS(rctx->flags) && ((req->cryptlen <= aes_sw_max_len) ||\n\t    (req->cryptlen > QCE_SECTOR_SIZE &&\n\t    req->cryptlen % QCE_SECTOR_SIZE))))) {\n\t\tskcipher_request_set_tfm(&rctx->fallback_req, ctx->fallback);\n\t\tskcipher_request_set_callback(&rctx->fallback_req,\n\t\t\t\t\t      req->base.flags,\n\t\t\t\t\t      req->base.complete,\n\t\t\t\t\t      req->base.data);\n\t\tskcipher_request_set_crypt(&rctx->fallback_req, req->src,\n\t\t\t\t\t   req->dst, req->cryptlen, req->iv);\n\t\tret = encrypt ? crypto_skcipher_encrypt(&rctx->fallback_req) :\n\t\t\t\tcrypto_skcipher_decrypt(&rctx->fallback_req);\n\t\treturn ret;\n\t}\n\n\treturn tmpl->qce->async_req_enqueue(tmpl->qce, &req->base);\n}\n\nstatic int qce_skcipher_encrypt(struct skcipher_request *req)\n{\n\treturn qce_skcipher_crypt(req, 1);\n}\n\nstatic int qce_skcipher_decrypt(struct skcipher_request *req)\n{\n\treturn qce_skcipher_crypt(req, 0);\n}\n\nstatic int qce_skcipher_init(struct crypto_skcipher *tfm)\n{\n\t \n\tcrypto_skcipher_set_reqsize(tfm, offsetof(struct qce_cipher_reqctx,\n\t\t\t\t\t\t  fallback_req));\n\treturn 0;\n}\n\nstatic int qce_skcipher_init_fallback(struct crypto_skcipher *tfm)\n{\n\tstruct qce_cipher_ctx *ctx = crypto_skcipher_ctx(tfm);\n\n\tctx->fallback = crypto_alloc_skcipher(crypto_tfm_alg_name(&tfm->base),\n\t\t\t\t\t      0, CRYPTO_ALG_NEED_FALLBACK);\n\tif (IS_ERR(ctx->fallback))\n\t\treturn PTR_ERR(ctx->fallback);\n\n\tcrypto_skcipher_set_reqsize(tfm, sizeof(struct qce_cipher_reqctx) +\n\t\t\t\t\t crypto_skcipher_reqsize(ctx->fallback));\n\treturn 0;\n}\n\nstatic void qce_skcipher_exit(struct crypto_skcipher *tfm)\n{\n\tstruct qce_cipher_ctx *ctx = crypto_skcipher_ctx(tfm);\n\n\tcrypto_free_skcipher(ctx->fallback);\n}\n\nstruct qce_skcipher_def {\n\tunsigned long flags;\n\tconst char *name;\n\tconst char *drv_name;\n\tunsigned int blocksize;\n\tunsigned int chunksize;\n\tunsigned int ivsize;\n\tunsigned int min_keysize;\n\tunsigned int max_keysize;\n};\n\nstatic const struct qce_skcipher_def skcipher_def[] = {\n\t{\n\t\t.flags\t\t= QCE_ALG_AES | QCE_MODE_ECB,\n\t\t.name\t\t= \"ecb(aes)\",\n\t\t.drv_name\t= \"ecb-aes-qce\",\n\t\t.blocksize\t= AES_BLOCK_SIZE,\n\t\t.ivsize\t\t= 0,\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t},\n\t{\n\t\t.flags\t\t= QCE_ALG_AES | QCE_MODE_CBC,\n\t\t.name\t\t= \"cbc(aes)\",\n\t\t.drv_name\t= \"cbc-aes-qce\",\n\t\t.blocksize\t= AES_BLOCK_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t},\n\t{\n\t\t.flags\t\t= QCE_ALG_AES | QCE_MODE_CTR,\n\t\t.name\t\t= \"ctr(aes)\",\n\t\t.drv_name\t= \"ctr-aes-qce\",\n\t\t.blocksize\t= 1,\n\t\t.chunksize\t= AES_BLOCK_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE,\n\t},\n\t{\n\t\t.flags\t\t= QCE_ALG_AES | QCE_MODE_XTS,\n\t\t.name\t\t= \"xts(aes)\",\n\t\t.drv_name\t= \"xts-aes-qce\",\n\t\t.blocksize\t= AES_BLOCK_SIZE,\n\t\t.ivsize\t\t= AES_BLOCK_SIZE,\n\t\t.min_keysize\t= AES_MIN_KEY_SIZE * 2,\n\t\t.max_keysize\t= AES_MAX_KEY_SIZE * 2,\n\t},\n\t{\n\t\t.flags\t\t= QCE_ALG_DES | QCE_MODE_ECB,\n\t\t.name\t\t= \"ecb(des)\",\n\t\t.drv_name\t= \"ecb-des-qce\",\n\t\t.blocksize\t= DES_BLOCK_SIZE,\n\t\t.ivsize\t\t= 0,\n\t\t.min_keysize\t= DES_KEY_SIZE,\n\t\t.max_keysize\t= DES_KEY_SIZE,\n\t},\n\t{\n\t\t.flags\t\t= QCE_ALG_DES | QCE_MODE_CBC,\n\t\t.name\t\t= \"cbc(des)\",\n\t\t.drv_name\t= \"cbc-des-qce\",\n\t\t.blocksize\t= DES_BLOCK_SIZE,\n\t\t.ivsize\t\t= DES_BLOCK_SIZE,\n\t\t.min_keysize\t= DES_KEY_SIZE,\n\t\t.max_keysize\t= DES_KEY_SIZE,\n\t},\n\t{\n\t\t.flags\t\t= QCE_ALG_3DES | QCE_MODE_ECB,\n\t\t.name\t\t= \"ecb(des3_ede)\",\n\t\t.drv_name\t= \"ecb-3des-qce\",\n\t\t.blocksize\t= DES3_EDE_BLOCK_SIZE,\n\t\t.ivsize\t\t= 0,\n\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t},\n\t{\n\t\t.flags\t\t= QCE_ALG_3DES | QCE_MODE_CBC,\n\t\t.name\t\t= \"cbc(des3_ede)\",\n\t\t.drv_name\t= \"cbc-3des-qce\",\n\t\t.blocksize\t= DES3_EDE_BLOCK_SIZE,\n\t\t.ivsize\t\t= DES3_EDE_BLOCK_SIZE,\n\t\t.min_keysize\t= DES3_EDE_KEY_SIZE,\n\t\t.max_keysize\t= DES3_EDE_KEY_SIZE,\n\t},\n};\n\nstatic int qce_skcipher_register_one(const struct qce_skcipher_def *def,\n\t\t\t\t       struct qce_device *qce)\n{\n\tstruct qce_alg_template *tmpl;\n\tstruct skcipher_alg *alg;\n\tint ret;\n\n\ttmpl = kzalloc(sizeof(*tmpl), GFP_KERNEL);\n\tif (!tmpl)\n\t\treturn -ENOMEM;\n\n\talg = &tmpl->alg.skcipher;\n\n\tsnprintf(alg->base.cra_name, CRYPTO_MAX_ALG_NAME, \"%s\", def->name);\n\tsnprintf(alg->base.cra_driver_name, CRYPTO_MAX_ALG_NAME, \"%s\",\n\t\t def->drv_name);\n\n\talg->base.cra_blocksize\t\t= def->blocksize;\n\talg->chunksize\t\t\t= def->chunksize;\n\talg->ivsize\t\t\t= def->ivsize;\n\talg->min_keysize\t\t= def->min_keysize;\n\talg->max_keysize\t\t= def->max_keysize;\n\talg->setkey\t\t\t= IS_3DES(def->flags) ? qce_des3_setkey :\n\t\t\t\t\t  IS_DES(def->flags) ? qce_des_setkey :\n\t\t\t\t\t  qce_skcipher_setkey;\n\talg->encrypt\t\t\t= qce_skcipher_encrypt;\n\talg->decrypt\t\t\t= qce_skcipher_decrypt;\n\n\talg->base.cra_priority\t\t= 300;\n\talg->base.cra_flags\t\t= CRYPTO_ALG_ASYNC |\n\t\t\t\t\t  CRYPTO_ALG_ALLOCATES_MEMORY |\n\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY;\n\talg->base.cra_ctxsize\t\t= sizeof(struct qce_cipher_ctx);\n\talg->base.cra_alignmask\t\t= 0;\n\talg->base.cra_module\t\t= THIS_MODULE;\n\n\tif (IS_AES(def->flags)) {\n\t\talg->base.cra_flags    |= CRYPTO_ALG_NEED_FALLBACK;\n\t\talg->init\t\t= qce_skcipher_init_fallback;\n\t\talg->exit\t\t= qce_skcipher_exit;\n\t} else {\n\t\talg->init\t\t= qce_skcipher_init;\n\t}\n\n\tINIT_LIST_HEAD(&tmpl->entry);\n\ttmpl->crypto_alg_type = CRYPTO_ALG_TYPE_SKCIPHER;\n\ttmpl->alg_flags = def->flags;\n\ttmpl->qce = qce;\n\n\tret = crypto_register_skcipher(alg);\n\tif (ret) {\n\t\tdev_err(qce->dev, \"%s registration failed\\n\", alg->base.cra_name);\n\t\tkfree(tmpl);\n\t\treturn ret;\n\t}\n\n\tlist_add_tail(&tmpl->entry, &skcipher_algs);\n\tdev_dbg(qce->dev, \"%s is registered\\n\", alg->base.cra_name);\n\treturn 0;\n}\n\nstatic void qce_skcipher_unregister(struct qce_device *qce)\n{\n\tstruct qce_alg_template *tmpl, *n;\n\n\tlist_for_each_entry_safe(tmpl, n, &skcipher_algs, entry) {\n\t\tcrypto_unregister_skcipher(&tmpl->alg.skcipher);\n\t\tlist_del(&tmpl->entry);\n\t\tkfree(tmpl);\n\t}\n}\n\nstatic int qce_skcipher_register(struct qce_device *qce)\n{\n\tint ret, i;\n\n\tfor (i = 0; i < ARRAY_SIZE(skcipher_def); i++) {\n\t\tret = qce_skcipher_register_one(&skcipher_def[i], qce);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tqce_skcipher_unregister(qce);\n\treturn ret;\n}\n\nconst struct qce_algo_ops skcipher_ops = {\n\t.type = CRYPTO_ALG_TYPE_SKCIPHER,\n\t.register_algs = qce_skcipher_register,\n\t.unregister_algs = qce_skcipher_unregister,\n\t.async_req_handle = qce_skcipher_async_req_handle,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}