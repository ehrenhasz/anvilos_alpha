{
  "module_name": "aead.c",
  "hash_id": "785fe2fc08776cb591936272f0b6b48b9d88d50dd2f54321f2222484f6f04317",
  "original_prompt": "Ingested from linux-6.6.14/drivers/crypto/qce/aead.c",
  "human_readable_source": "\n\n \n#include <linux/dma-mapping.h>\n#include <linux/interrupt.h>\n#include <crypto/gcm.h>\n#include <crypto/authenc.h>\n#include <crypto/internal/aead.h>\n#include <crypto/internal/des.h>\n#include <crypto/sha1.h>\n#include <crypto/sha2.h>\n#include <crypto/scatterwalk.h>\n#include \"aead.h\"\n\n#define CCM_NONCE_ADATA_SHIFT\t\t6\n#define CCM_NONCE_AUTHSIZE_SHIFT\t3\n#define MAX_CCM_ADATA_HEADER_LEN        6\n\nstatic LIST_HEAD(aead_algs);\n\nstatic void qce_aead_done(void *data)\n{\n\tstruct crypto_async_request *async_req = data;\n\tstruct aead_request *req = aead_request_cast(async_req);\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct qce_aead_ctx *ctx = crypto_tfm_ctx(async_req->tfm);\n\tstruct qce_alg_template *tmpl = to_aead_tmpl(crypto_aead_reqtfm(req));\n\tstruct qce_device *qce = tmpl->qce;\n\tstruct qce_result_dump *result_buf = qce->dma.result_buf;\n\tenum dma_data_direction dir_src, dir_dst;\n\tbool diff_dst;\n\tint error;\n\tu32 status;\n\tunsigned int totallen;\n\tunsigned char tag[SHA256_DIGEST_SIZE] = {0};\n\tint ret = 0;\n\n\tdiff_dst = (req->src != req->dst) ? true : false;\n\tdir_src = diff_dst ? DMA_TO_DEVICE : DMA_BIDIRECTIONAL;\n\tdir_dst = diff_dst ? DMA_FROM_DEVICE : DMA_BIDIRECTIONAL;\n\n\terror = qce_dma_terminate_all(&qce->dma);\n\tif (error)\n\t\tdev_dbg(qce->dev, \"aead dma termination error (%d)\\n\",\n\t\t\terror);\n\tif (diff_dst)\n\t\tdma_unmap_sg(qce->dev, rctx->src_sg, rctx->src_nents, dir_src);\n\n\tdma_unmap_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);\n\n\tif (IS_CCM(rctx->flags)) {\n\t\tif (req->assoclen) {\n\t\t\tsg_free_table(&rctx->src_tbl);\n\t\t\tif (diff_dst)\n\t\t\t\tsg_free_table(&rctx->dst_tbl);\n\t\t} else {\n\t\t\tif (!(IS_DECRYPT(rctx->flags) && !diff_dst))\n\t\t\t\tsg_free_table(&rctx->dst_tbl);\n\t\t}\n\t} else {\n\t\tsg_free_table(&rctx->dst_tbl);\n\t}\n\n\terror = qce_check_status(qce, &status);\n\tif (error < 0 && (error != -EBADMSG))\n\t\tdev_err(qce->dev, \"aead operation error (%x)\\n\", status);\n\n\tif (IS_ENCRYPT(rctx->flags)) {\n\t\ttotallen = req->cryptlen + req->assoclen;\n\t\tif (IS_CCM(rctx->flags))\n\t\t\tscatterwalk_map_and_copy(rctx->ccmresult_buf, req->dst,\n\t\t\t\t\t\t totallen, ctx->authsize, 1);\n\t\telse\n\t\t\tscatterwalk_map_and_copy(result_buf->auth_iv, req->dst,\n\t\t\t\t\t\t totallen, ctx->authsize, 1);\n\n\t} else if (!IS_CCM(rctx->flags)) {\n\t\ttotallen = req->cryptlen + req->assoclen - ctx->authsize;\n\t\tscatterwalk_map_and_copy(tag, req->src, totallen, ctx->authsize, 0);\n\t\tret = memcmp(result_buf->auth_iv, tag, ctx->authsize);\n\t\tif (ret) {\n\t\t\tpr_err(\"Bad message error\\n\");\n\t\t\terror = -EBADMSG;\n\t\t}\n\t}\n\n\tqce->async_req_done(qce, error);\n}\n\nstatic struct scatterlist *\nqce_aead_prepare_result_buf(struct sg_table *tbl, struct aead_request *req)\n{\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct qce_alg_template *tmpl = to_aead_tmpl(crypto_aead_reqtfm(req));\n\tstruct qce_device *qce = tmpl->qce;\n\n\tsg_init_one(&rctx->result_sg, qce->dma.result_buf, QCE_RESULT_BUF_SZ);\n\treturn qce_sgtable_add(tbl, &rctx->result_sg, QCE_RESULT_BUF_SZ);\n}\n\nstatic struct scatterlist *\nqce_aead_prepare_ccm_result_buf(struct sg_table *tbl, struct aead_request *req)\n{\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\n\tsg_init_one(&rctx->result_sg, rctx->ccmresult_buf, QCE_BAM_BURST_SIZE);\n\treturn qce_sgtable_add(tbl, &rctx->result_sg, QCE_BAM_BURST_SIZE);\n}\n\nstatic struct scatterlist *\nqce_aead_prepare_dst_buf(struct aead_request *req)\n{\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct qce_alg_template *tmpl = to_aead_tmpl(crypto_aead_reqtfm(req));\n\tstruct qce_device *qce = tmpl->qce;\n\tstruct scatterlist *sg, *msg_sg, __sg[2];\n\tgfp_t gfp;\n\tunsigned int assoclen = req->assoclen;\n\tunsigned int totallen;\n\tint ret;\n\n\ttotallen = rctx->cryptlen + assoclen;\n\trctx->dst_nents = sg_nents_for_len(req->dst, totallen);\n\tif (rctx->dst_nents < 0) {\n\t\tdev_err(qce->dev, \"Invalid numbers of dst SG.\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\tif (IS_CCM(rctx->flags))\n\t\trctx->dst_nents += 2;\n\telse\n\t\trctx->dst_nents += 1;\n\n\tgfp = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?\n\t\t\t\t\t\tGFP_KERNEL : GFP_ATOMIC;\n\tret = sg_alloc_table(&rctx->dst_tbl, rctx->dst_nents, gfp);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tif (IS_CCM(rctx->flags) && assoclen) {\n\t\t \n\t\tmsg_sg = scatterwalk_ffwd(__sg, req->dst, assoclen);\n\n\t\tsg = qce_sgtable_add(&rctx->dst_tbl, &rctx->adata_sg,\n\t\t\t\t     rctx->assoclen);\n\t\tif (IS_ERR(sg)) {\n\t\t\tret = PTR_ERR(sg);\n\t\t\tgoto dst_tbl_free;\n\t\t}\n\t\t \n\t\tsg = qce_sgtable_add(&rctx->dst_tbl, msg_sg, rctx->cryptlen);\n\t\tif (IS_ERR(sg)) {\n\t\t\tret = PTR_ERR(sg);\n\t\t\tgoto dst_tbl_free;\n\t\t}\n\t\ttotallen = rctx->cryptlen + rctx->assoclen;\n\t} else {\n\t\tif (totallen) {\n\t\t\tsg = qce_sgtable_add(&rctx->dst_tbl, req->dst, totallen);\n\t\t\tif (IS_ERR(sg))\n\t\t\t\tgoto dst_tbl_free;\n\t\t}\n\t}\n\tif (IS_CCM(rctx->flags))\n\t\tsg = qce_aead_prepare_ccm_result_buf(&rctx->dst_tbl, req);\n\telse\n\t\tsg = qce_aead_prepare_result_buf(&rctx->dst_tbl, req);\n\n\tif (IS_ERR(sg))\n\t\tgoto dst_tbl_free;\n\n\tsg_mark_end(sg);\n\trctx->dst_sg = rctx->dst_tbl.sgl;\n\trctx->dst_nents = sg_nents_for_len(rctx->dst_sg, totallen) + 1;\n\n\treturn sg;\n\ndst_tbl_free:\n\tsg_free_table(&rctx->dst_tbl);\n\treturn sg;\n}\n\nstatic int\nqce_aead_ccm_prepare_buf_assoclen(struct aead_request *req)\n{\n\tstruct scatterlist *sg, *msg_sg, __sg[2];\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tunsigned int assoclen = rctx->assoclen;\n\tunsigned int adata_header_len, cryptlen, totallen;\n\tgfp_t gfp;\n\tbool diff_dst;\n\tint ret;\n\n\tif (IS_DECRYPT(rctx->flags))\n\t\tcryptlen = rctx->cryptlen + ctx->authsize;\n\telse\n\t\tcryptlen = rctx->cryptlen;\n\ttotallen = cryptlen + req->assoclen;\n\n\t \n\tmsg_sg = scatterwalk_ffwd(__sg, req->src, req->assoclen);\n\n\trctx->adata = kzalloc((ALIGN(assoclen, 16) + MAX_CCM_ADATA_HEADER_LEN) *\n\t\t\t       sizeof(unsigned char), GFP_ATOMIC);\n\tif (!rctx->adata)\n\t\treturn -ENOMEM;\n\n\t \n\tif (assoclen < 0xff00) {\n\t\tadata_header_len = 2;\n\t\t*(__be16 *)rctx->adata = cpu_to_be16(assoclen);\n\t} else {\n\t\tadata_header_len = 6;\n\t\t*(__be16 *)rctx->adata = cpu_to_be16(0xfffe);\n\t\t*(__be32 *)(rctx->adata + 2) = cpu_to_be32(assoclen);\n\t}\n\n\t \n\tif (sg_copy_to_buffer(req->src, sg_nents_for_len(req->src, assoclen),\n\t\t\t      rctx->adata + adata_header_len,\n\t\t\t      assoclen) != assoclen)\n\t\treturn -EINVAL;\n\n\t \n\trctx->assoclen = ALIGN(assoclen + adata_header_len, 16);\n\n\tdiff_dst = (req->src != req->dst) ? true : false;\n\n\tif (diff_dst)\n\t\trctx->src_nents = sg_nents_for_len(req->src, totallen) + 1;\n\telse\n\t\trctx->src_nents = sg_nents_for_len(req->src, totallen) + 2;\n\n\tgfp = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ? GFP_KERNEL : GFP_ATOMIC;\n\tret = sg_alloc_table(&rctx->src_tbl, rctx->src_nents, gfp);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tsg_init_one(&rctx->adata_sg, rctx->adata, rctx->assoclen);\n\tsg = qce_sgtable_add(&rctx->src_tbl, &rctx->adata_sg,\n\t\t\t     rctx->assoclen);\n\tif (IS_ERR(sg)) {\n\t\tret = PTR_ERR(sg);\n\t\tgoto err_free;\n\t}\n\t \n\tsg = qce_sgtable_add(&rctx->src_tbl, msg_sg, cryptlen);\n\tif (IS_ERR(sg)) {\n\t\tret = PTR_ERR(sg);\n\t\tgoto err_free;\n\t}\n\tif (!diff_dst) {\n\t\t \n\t\tif (!IS_DECRYPT(rctx->flags)) {\n\t\t\tsg = qce_aead_prepare_ccm_result_buf(&rctx->src_tbl, req);\n\t\t\tif (IS_ERR(sg)) {\n\t\t\t\tret = PTR_ERR(sg);\n\t\t\t\tgoto err_free;\n\t\t\t}\n\t\t}\n\t}\n\tsg_mark_end(sg);\n\trctx->src_sg = rctx->src_tbl.sgl;\n\ttotallen = cryptlen + rctx->assoclen;\n\trctx->src_nents = sg_nents_for_len(rctx->src_sg, totallen);\n\n\tif (diff_dst) {\n\t\tsg = qce_aead_prepare_dst_buf(req);\n\t\tif (IS_ERR(sg)) {\n\t\t\tret = PTR_ERR(sg);\n\t\t\tgoto err_free;\n\t\t}\n\t} else {\n\t\tif (IS_ENCRYPT(rctx->flags))\n\t\t\trctx->dst_nents = rctx->src_nents + 1;\n\t\telse\n\t\t\trctx->dst_nents = rctx->src_nents;\n\t\trctx->dst_sg = rctx->src_sg;\n\t}\n\n\treturn 0;\nerr_free:\n\tsg_free_table(&rctx->src_tbl);\n\treturn ret;\n}\n\nstatic int qce_aead_prepare_buf(struct aead_request *req)\n{\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct qce_alg_template *tmpl = to_aead_tmpl(crypto_aead_reqtfm(req));\n\tstruct qce_device *qce = tmpl->qce;\n\tstruct scatterlist *sg;\n\tbool diff_dst = (req->src != req->dst) ? true : false;\n\tunsigned int totallen;\n\n\ttotallen = rctx->cryptlen + rctx->assoclen;\n\n\tsg = qce_aead_prepare_dst_buf(req);\n\tif (IS_ERR(sg))\n\t\treturn PTR_ERR(sg);\n\tif (diff_dst) {\n\t\trctx->src_nents = sg_nents_for_len(req->src, totallen);\n\t\tif (rctx->src_nents < 0) {\n\t\t\tdev_err(qce->dev, \"Invalid numbers of src SG.\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\trctx->src_sg = req->src;\n\t} else {\n\t\trctx->src_nents = rctx->dst_nents - 1;\n\t\trctx->src_sg = rctx->dst_sg;\n\t}\n\treturn 0;\n}\n\nstatic int qce_aead_ccm_prepare_buf(struct aead_request *req)\n{\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct scatterlist *sg;\n\tbool diff_dst = (req->src != req->dst) ? true : false;\n\tunsigned int cryptlen;\n\n\tif (rctx->assoclen)\n\t\treturn qce_aead_ccm_prepare_buf_assoclen(req);\n\n\tif (IS_ENCRYPT(rctx->flags))\n\t\treturn qce_aead_prepare_buf(req);\n\n\tcryptlen = rctx->cryptlen + ctx->authsize;\n\tif (diff_dst) {\n\t\trctx->src_nents = sg_nents_for_len(req->src, cryptlen);\n\t\trctx->src_sg = req->src;\n\t\tsg = qce_aead_prepare_dst_buf(req);\n\t\tif (IS_ERR(sg))\n\t\t\treturn PTR_ERR(sg);\n\t} else {\n\t\trctx->src_nents = sg_nents_for_len(req->src, cryptlen);\n\t\trctx->src_sg = req->src;\n\t\trctx->dst_nents = rctx->src_nents;\n\t\trctx->dst_sg = rctx->src_sg;\n\t}\n\n\treturn 0;\n}\n\nstatic int qce_aead_create_ccm_nonce(struct qce_aead_reqctx *rctx, struct qce_aead_ctx *ctx)\n{\n\tunsigned int msglen_size, ivsize;\n\tu8 msg_len[4];\n\tint i;\n\n\tif (!rctx || !rctx->iv)\n\t\treturn -EINVAL;\n\n\tmsglen_size = rctx->iv[0] + 1;\n\n\t \n\tif (msglen_size < 2 || msglen_size > 8)\n\t\treturn -EINVAL;\n\n\tivsize = rctx->ivsize;\n\n\t \n\tif (!IS_CCM_RFC4309(rctx->flags)) {\n\t\tfor (i = 0; i < msglen_size; i++)\n\t\t\trctx->iv[ivsize - i - 1] = 0;\n\t}\n\n\t \n\tif (msglen_size > 4)\n\t\tmsglen_size = 4;\n\n\tmemcpy(&msg_len[0], &rctx->cryptlen, 4);\n\n\tmemcpy(&rctx->ccm_nonce[0], rctx->iv, rctx->ivsize);\n\tif (rctx->assoclen)\n\t\trctx->ccm_nonce[0] |= 1 << CCM_NONCE_ADATA_SHIFT;\n\trctx->ccm_nonce[0] |= ((ctx->authsize - 2) / 2) <<\n\t\t\t\tCCM_NONCE_AUTHSIZE_SHIFT;\n\tfor (i = 0; i < msglen_size; i++)\n\t\trctx->ccm_nonce[QCE_MAX_NONCE - i - 1] = msg_len[i];\n\n\treturn 0;\n}\n\nstatic int\nqce_aead_async_req_handle(struct crypto_async_request *async_req)\n{\n\tstruct aead_request *req = aead_request_cast(async_req);\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct qce_aead_ctx *ctx = crypto_tfm_ctx(async_req->tfm);\n\tstruct qce_alg_template *tmpl = to_aead_tmpl(crypto_aead_reqtfm(req));\n\tstruct qce_device *qce = tmpl->qce;\n\tenum dma_data_direction dir_src, dir_dst;\n\tbool diff_dst;\n\tint dst_nents, src_nents, ret;\n\n\tif (IS_CCM_RFC4309(rctx->flags)) {\n\t\tmemset(rctx->ccm_rfc4309_iv, 0, QCE_MAX_IV_SIZE);\n\t\trctx->ccm_rfc4309_iv[0] = 3;\n\t\tmemcpy(&rctx->ccm_rfc4309_iv[1], ctx->ccm4309_salt, QCE_CCM4309_SALT_SIZE);\n\t\tmemcpy(&rctx->ccm_rfc4309_iv[4], req->iv, 8);\n\t\trctx->iv = rctx->ccm_rfc4309_iv;\n\t\trctx->ivsize = AES_BLOCK_SIZE;\n\t} else {\n\t\trctx->iv = req->iv;\n\t\trctx->ivsize = crypto_aead_ivsize(tfm);\n\t}\n\tif (IS_CCM_RFC4309(rctx->flags))\n\t\trctx->assoclen = req->assoclen - 8;\n\telse\n\t\trctx->assoclen = req->assoclen;\n\n\tdiff_dst = (req->src != req->dst) ? true : false;\n\tdir_src = diff_dst ? DMA_TO_DEVICE : DMA_BIDIRECTIONAL;\n\tdir_dst = diff_dst ? DMA_FROM_DEVICE : DMA_BIDIRECTIONAL;\n\n\tif (IS_CCM(rctx->flags)) {\n\t\tret = qce_aead_create_ccm_nonce(rctx, ctx);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\tif (IS_CCM(rctx->flags))\n\t\tret = qce_aead_ccm_prepare_buf(req);\n\telse\n\t\tret = qce_aead_prepare_buf(req);\n\n\tif (ret)\n\t\treturn ret;\n\tdst_nents = dma_map_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);\n\tif (!dst_nents) {\n\t\tret = -EIO;\n\t\tgoto error_free;\n\t}\n\n\tif (diff_dst) {\n\t\tsrc_nents = dma_map_sg(qce->dev, rctx->src_sg, rctx->src_nents, dir_src);\n\t\tif (src_nents < 0) {\n\t\t\tret = src_nents;\n\t\t\tgoto error_unmap_dst;\n\t\t}\n\t} else {\n\t\tif (IS_CCM(rctx->flags) && IS_DECRYPT(rctx->flags))\n\t\t\tsrc_nents = dst_nents;\n\t\telse\n\t\t\tsrc_nents = dst_nents - 1;\n\t}\n\n\tret = qce_dma_prep_sgs(&qce->dma, rctx->src_sg, src_nents, rctx->dst_sg, dst_nents,\n\t\t\t       qce_aead_done, async_req);\n\tif (ret)\n\t\tgoto error_unmap_src;\n\n\tqce_dma_issue_pending(&qce->dma);\n\n\tret = qce_start(async_req, tmpl->crypto_alg_type);\n\tif (ret)\n\t\tgoto error_terminate;\n\n\treturn 0;\n\nerror_terminate:\n\tqce_dma_terminate_all(&qce->dma);\nerror_unmap_src:\n\tif (diff_dst)\n\t\tdma_unmap_sg(qce->dev, req->src, rctx->src_nents, dir_src);\nerror_unmap_dst:\n\tdma_unmap_sg(qce->dev, rctx->dst_sg, rctx->dst_nents, dir_dst);\nerror_free:\n\tif (IS_CCM(rctx->flags) && rctx->assoclen) {\n\t\tsg_free_table(&rctx->src_tbl);\n\t\tif (diff_dst)\n\t\t\tsg_free_table(&rctx->dst_tbl);\n\t} else {\n\t\tsg_free_table(&rctx->dst_tbl);\n\t}\n\treturn ret;\n}\n\nstatic int qce_aead_crypt(struct aead_request *req, int encrypt)\n{\n\tstruct crypto_aead *tfm = crypto_aead_reqtfm(req);\n\tstruct qce_aead_reqctx *rctx = aead_request_ctx_dma(req);\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct qce_alg_template *tmpl = to_aead_tmpl(tfm);\n\tunsigned int blocksize = crypto_aead_blocksize(tfm);\n\n\trctx->flags  = tmpl->alg_flags;\n\trctx->flags |= encrypt ? QCE_ENCRYPT : QCE_DECRYPT;\n\n\tif (encrypt)\n\t\trctx->cryptlen = req->cryptlen;\n\telse\n\t\trctx->cryptlen = req->cryptlen - ctx->authsize;\n\n\t \n\tif (!rctx->cryptlen) {\n\t\tif (!(IS_CCM(rctx->flags) && IS_DECRYPT(rctx->flags)))\n\t\t\tctx->need_fallback = true;\n\t}\n\n\t \n\tif (ctx->need_fallback) {\n\t\t \n\t\tctx->need_fallback = false;\n\n\t\taead_request_set_tfm(&rctx->fallback_req, ctx->fallback);\n\t\taead_request_set_callback(&rctx->fallback_req, req->base.flags,\n\t\t\t\t\t  req->base.complete, req->base.data);\n\t\taead_request_set_crypt(&rctx->fallback_req, req->src,\n\t\t\t\t       req->dst, req->cryptlen, req->iv);\n\t\taead_request_set_ad(&rctx->fallback_req, req->assoclen);\n\n\t\treturn encrypt ? crypto_aead_encrypt(&rctx->fallback_req) :\n\t\t\t\t crypto_aead_decrypt(&rctx->fallback_req);\n\t}\n\n\t \n\tif (IS_CBC(rctx->flags) && !IS_ALIGNED(rctx->cryptlen, blocksize))\n\t\treturn -EINVAL;\n\n\t \n\tif (IS_CCM_RFC4309(rctx->flags))\n\t\tif (crypto_ipsec_check_assoclen(req->assoclen))\n\t\t\treturn -EINVAL;\n\n\treturn tmpl->qce->async_req_enqueue(tmpl->qce, &req->base);\n}\n\nstatic int qce_aead_encrypt(struct aead_request *req)\n{\n\treturn qce_aead_crypt(req, 1);\n}\n\nstatic int qce_aead_decrypt(struct aead_request *req)\n{\n\treturn qce_aead_crypt(req, 0);\n}\n\nstatic int qce_aead_ccm_setkey(struct crypto_aead *tfm, const u8 *key,\n\t\t\t       unsigned int keylen)\n{\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tunsigned long flags = to_aead_tmpl(tfm)->alg_flags;\n\n\tif (IS_CCM_RFC4309(flags)) {\n\t\tif (keylen < QCE_CCM4309_SALT_SIZE)\n\t\t\treturn -EINVAL;\n\t\tkeylen -= QCE_CCM4309_SALT_SIZE;\n\t\tmemcpy(ctx->ccm4309_salt, key + keylen, QCE_CCM4309_SALT_SIZE);\n\t}\n\n\tif (keylen != AES_KEYSIZE_128 && keylen != AES_KEYSIZE_256 && keylen != AES_KEYSIZE_192)\n\t\treturn -EINVAL;\n\n\tctx->enc_keylen = keylen;\n\tctx->auth_keylen = keylen;\n\n\tmemcpy(ctx->enc_key, key, keylen);\n\tmemcpy(ctx->auth_key, key, keylen);\n\n\tif (keylen == AES_KEYSIZE_192)\n\t\tctx->need_fallback = true;\n\n\treturn IS_CCM_RFC4309(flags) ?\n\t\tcrypto_aead_setkey(ctx->fallback, key, keylen + QCE_CCM4309_SALT_SIZE) :\n\t\tcrypto_aead_setkey(ctx->fallback, key, keylen);\n}\n\nstatic int qce_aead_setkey(struct crypto_aead *tfm, const u8 *key, unsigned int keylen)\n{\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct crypto_authenc_keys authenc_keys;\n\tunsigned long flags = to_aead_tmpl(tfm)->alg_flags;\n\tu32 _key[6];\n\tint err;\n\n\terr = crypto_authenc_extractkeys(&authenc_keys, key, keylen);\n\tif (err)\n\t\treturn err;\n\n\tif (authenc_keys.enckeylen > QCE_MAX_KEY_SIZE ||\n\t    authenc_keys.authkeylen > QCE_MAX_KEY_SIZE)\n\t\treturn -EINVAL;\n\n\tif (IS_DES(flags)) {\n\t\terr = verify_aead_des_key(tfm, authenc_keys.enckey, authenc_keys.enckeylen);\n\t\tif (err)\n\t\t\treturn err;\n\t} else if (IS_3DES(flags)) {\n\t\terr = verify_aead_des3_key(tfm, authenc_keys.enckey, authenc_keys.enckeylen);\n\t\tif (err)\n\t\t\treturn err;\n\t\t \n\t\tmemcpy(_key, authenc_keys.enckey, DES3_EDE_KEY_SIZE);\n\t\tif (!((_key[0] ^ _key[2]) | (_key[1] ^ _key[3])) ||\n\t\t    !((_key[2] ^ _key[4]) | (_key[3] ^ _key[5])) ||\n\t\t    !((_key[0] ^ _key[4]) | (_key[1] ^ _key[5])))\n\t\t\tctx->need_fallback = true;\n\t} else if (IS_AES(flags)) {\n\t\t \n\t\tif (authenc_keys.enckeylen != AES_KEYSIZE_128 &&\n\t\t    authenc_keys.enckeylen != AES_KEYSIZE_192 &&\n\t\t    authenc_keys.enckeylen != AES_KEYSIZE_256)\n\t\t\treturn -EINVAL;\n\t\tif (authenc_keys.enckeylen == AES_KEYSIZE_192)\n\t\t\tctx->need_fallback = true;\n\t}\n\n\tctx->enc_keylen = authenc_keys.enckeylen;\n\tctx->auth_keylen = authenc_keys.authkeylen;\n\n\tmemcpy(ctx->enc_key, authenc_keys.enckey, authenc_keys.enckeylen);\n\n\tmemset(ctx->auth_key, 0, sizeof(ctx->auth_key));\n\tmemcpy(ctx->auth_key, authenc_keys.authkey, authenc_keys.authkeylen);\n\n\treturn crypto_aead_setkey(ctx->fallback, key, keylen);\n}\n\nstatic int qce_aead_setauthsize(struct crypto_aead *tfm, unsigned int authsize)\n{\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tunsigned long flags = to_aead_tmpl(tfm)->alg_flags;\n\n\tif (IS_CCM(flags)) {\n\t\tif (authsize < 4 || authsize > 16 || authsize % 2)\n\t\t\treturn -EINVAL;\n\t\tif (IS_CCM_RFC4309(flags) && (authsize < 8 || authsize % 4))\n\t\t\treturn -EINVAL;\n\t}\n\tctx->authsize = authsize;\n\n\treturn crypto_aead_setauthsize(ctx->fallback, authsize);\n}\n\nstatic int qce_aead_init(struct crypto_aead *tfm)\n{\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\n\tctx->need_fallback = false;\n\tctx->fallback = crypto_alloc_aead(crypto_tfm_alg_name(&tfm->base),\n\t\t\t\t\t  0, CRYPTO_ALG_NEED_FALLBACK);\n\n\tif (IS_ERR(ctx->fallback))\n\t\treturn PTR_ERR(ctx->fallback);\n\n\tcrypto_aead_set_reqsize_dma(tfm, sizeof(struct qce_aead_reqctx) +\n\t\t\t\t\t crypto_aead_reqsize(ctx->fallback));\n\treturn 0;\n}\n\nstatic void qce_aead_exit(struct crypto_aead *tfm)\n{\n\tstruct qce_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\n\tcrypto_free_aead(ctx->fallback);\n}\n\nstruct qce_aead_def {\n\tunsigned long flags;\n\tconst char *name;\n\tconst char *drv_name;\n\tunsigned int blocksize;\n\tunsigned int chunksize;\n\tunsigned int ivsize;\n\tunsigned int maxauthsize;\n};\n\nstatic const struct qce_aead_def aead_def[] = {\n\t{\n\t\t.flags          = QCE_ALG_DES | QCE_MODE_CBC | QCE_HASH_SHA1_HMAC,\n\t\t.name           = \"authenc(hmac(sha1),cbc(des))\",\n\t\t.drv_name       = \"authenc-hmac-sha1-cbc-des-qce\",\n\t\t.blocksize      = DES_BLOCK_SIZE,\n\t\t.ivsize         = DES_BLOCK_SIZE,\n\t\t.maxauthsize\t= SHA1_DIGEST_SIZE,\n\t},\n\t{\n\t\t.flags          = QCE_ALG_3DES | QCE_MODE_CBC | QCE_HASH_SHA1_HMAC,\n\t\t.name           = \"authenc(hmac(sha1),cbc(des3_ede))\",\n\t\t.drv_name       = \"authenc-hmac-sha1-cbc-3des-qce\",\n\t\t.blocksize      = DES3_EDE_BLOCK_SIZE,\n\t\t.ivsize         = DES3_EDE_BLOCK_SIZE,\n\t\t.maxauthsize\t= SHA1_DIGEST_SIZE,\n\t},\n\t{\n\t\t.flags          = QCE_ALG_DES | QCE_MODE_CBC | QCE_HASH_SHA256_HMAC,\n\t\t.name           = \"authenc(hmac(sha256),cbc(des))\",\n\t\t.drv_name       = \"authenc-hmac-sha256-cbc-des-qce\",\n\t\t.blocksize      = DES_BLOCK_SIZE,\n\t\t.ivsize         = DES_BLOCK_SIZE,\n\t\t.maxauthsize\t= SHA256_DIGEST_SIZE,\n\t},\n\t{\n\t\t.flags          = QCE_ALG_3DES | QCE_MODE_CBC | QCE_HASH_SHA256_HMAC,\n\t\t.name           = \"authenc(hmac(sha256),cbc(des3_ede))\",\n\t\t.drv_name       = \"authenc-hmac-sha256-cbc-3des-qce\",\n\t\t.blocksize      = DES3_EDE_BLOCK_SIZE,\n\t\t.ivsize         = DES3_EDE_BLOCK_SIZE,\n\t\t.maxauthsize\t= SHA256_DIGEST_SIZE,\n\t},\n\t{\n\t\t.flags          =  QCE_ALG_AES | QCE_MODE_CBC | QCE_HASH_SHA256_HMAC,\n\t\t.name           = \"authenc(hmac(sha256),cbc(aes))\",\n\t\t.drv_name       = \"authenc-hmac-sha256-cbc-aes-qce\",\n\t\t.blocksize      = AES_BLOCK_SIZE,\n\t\t.ivsize         = AES_BLOCK_SIZE,\n\t\t.maxauthsize\t= SHA256_DIGEST_SIZE,\n\t},\n\t{\n\t\t.flags          =  QCE_ALG_AES | QCE_MODE_CCM,\n\t\t.name           = \"ccm(aes)\",\n\t\t.drv_name       = \"ccm-aes-qce\",\n\t\t.blocksize\t= 1,\n\t\t.ivsize         = AES_BLOCK_SIZE,\n\t\t.maxauthsize\t= AES_BLOCK_SIZE,\n\t},\n\t{\n\t\t.flags          =  QCE_ALG_AES | QCE_MODE_CCM | QCE_MODE_CCM_RFC4309,\n\t\t.name           = \"rfc4309(ccm(aes))\",\n\t\t.drv_name       = \"rfc4309-ccm-aes-qce\",\n\t\t.blocksize\t= 1,\n\t\t.ivsize         = 8,\n\t\t.maxauthsize\t= AES_BLOCK_SIZE,\n\t},\n};\n\nstatic int qce_aead_register_one(const struct qce_aead_def *def, struct qce_device *qce)\n{\n\tstruct qce_alg_template *tmpl;\n\tstruct aead_alg *alg;\n\tint ret;\n\n\ttmpl = kzalloc(sizeof(*tmpl), GFP_KERNEL);\n\tif (!tmpl)\n\t\treturn -ENOMEM;\n\n\talg = &tmpl->alg.aead;\n\n\tsnprintf(alg->base.cra_name, CRYPTO_MAX_ALG_NAME, \"%s\", def->name);\n\tsnprintf(alg->base.cra_driver_name, CRYPTO_MAX_ALG_NAME, \"%s\",\n\t\t def->drv_name);\n\n\talg->base.cra_blocksize\t\t= def->blocksize;\n\talg->chunksize\t\t\t= def->chunksize;\n\talg->ivsize\t\t\t= def->ivsize;\n\talg->maxauthsize\t\t= def->maxauthsize;\n\tif (IS_CCM(def->flags))\n\t\talg->setkey\t\t= qce_aead_ccm_setkey;\n\telse\n\t\talg->setkey\t\t= qce_aead_setkey;\n\talg->setauthsize\t\t= qce_aead_setauthsize;\n\talg->encrypt\t\t\t= qce_aead_encrypt;\n\talg->decrypt\t\t\t= qce_aead_decrypt;\n\talg->init\t\t\t= qce_aead_init;\n\talg->exit\t\t\t= qce_aead_exit;\n\n\talg->base.cra_priority\t\t= 300;\n\talg->base.cra_flags\t\t= CRYPTO_ALG_ASYNC |\n\t\t\t\t\t  CRYPTO_ALG_ALLOCATES_MEMORY |\n\t\t\t\t\t  CRYPTO_ALG_KERN_DRIVER_ONLY |\n\t\t\t\t\t  CRYPTO_ALG_NEED_FALLBACK;\n\talg->base.cra_ctxsize\t\t= sizeof(struct qce_aead_ctx);\n\talg->base.cra_alignmask\t\t= 0;\n\talg->base.cra_module\t\t= THIS_MODULE;\n\n\tINIT_LIST_HEAD(&tmpl->entry);\n\ttmpl->crypto_alg_type = CRYPTO_ALG_TYPE_AEAD;\n\ttmpl->alg_flags = def->flags;\n\ttmpl->qce = qce;\n\n\tret = crypto_register_aead(alg);\n\tif (ret) {\n\t\tdev_err(qce->dev, \"%s registration failed\\n\", alg->base.cra_name);\n\t\tkfree(tmpl);\n\t\treturn ret;\n\t}\n\n\tlist_add_tail(&tmpl->entry, &aead_algs);\n\tdev_dbg(qce->dev, \"%s is registered\\n\", alg->base.cra_name);\n\treturn 0;\n}\n\nstatic void qce_aead_unregister(struct qce_device *qce)\n{\n\tstruct qce_alg_template *tmpl, *n;\n\n\tlist_for_each_entry_safe(tmpl, n, &aead_algs, entry) {\n\t\tcrypto_unregister_aead(&tmpl->alg.aead);\n\t\tlist_del(&tmpl->entry);\n\t\tkfree(tmpl);\n\t}\n}\n\nstatic int qce_aead_register(struct qce_device *qce)\n{\n\tint ret, i;\n\n\tfor (i = 0; i < ARRAY_SIZE(aead_def); i++) {\n\t\tret = qce_aead_register_one(&aead_def[i], qce);\n\t\tif (ret)\n\t\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tqce_aead_unregister(qce);\n\treturn ret;\n}\n\nconst struct qce_algo_ops aead_ops = {\n\t.type = CRYPTO_ALG_TYPE_AEAD,\n\t.register_algs = qce_aead_register,\n\t.unregister_algs = qce_aead_unregister,\n\t.async_req_handle = qce_aead_async_req_handle,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}