{
  "module_name": "bus.c",
  "hash_id": "a7417767868fb13e97724c26c982ec3e908eea92a369428ca6143043a3581f81",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/host1x/bus.c",
  "human_readable_source": "\n \n\n#include <linux/debugfs.h>\n#include <linux/dma-mapping.h>\n#include <linux/host1x.h>\n#include <linux/of.h>\n#include <linux/seq_file.h>\n#include <linux/slab.h>\n#include <linux/of_device.h>\n\n#include \"bus.h\"\n#include \"dev.h\"\n\nstatic DEFINE_MUTEX(clients_lock);\nstatic LIST_HEAD(clients);\n\nstatic DEFINE_MUTEX(drivers_lock);\nstatic LIST_HEAD(drivers);\n\nstatic DEFINE_MUTEX(devices_lock);\nstatic LIST_HEAD(devices);\n\nstruct host1x_subdev {\n\tstruct host1x_client *client;\n\tstruct device_node *np;\n\tstruct list_head list;\n};\n\n \nstatic int host1x_subdev_add(struct host1x_device *device,\n\t\t\t     struct host1x_driver *driver,\n\t\t\t     struct device_node *np)\n{\n\tstruct host1x_subdev *subdev;\n\tstruct device_node *child;\n\tint err;\n\n\tsubdev = kzalloc(sizeof(*subdev), GFP_KERNEL);\n\tif (!subdev)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&subdev->list);\n\tsubdev->np = of_node_get(np);\n\n\tmutex_lock(&device->subdevs_lock);\n\tlist_add_tail(&subdev->list, &device->subdevs);\n\tmutex_unlock(&device->subdevs_lock);\n\n\t \n\tfor_each_child_of_node(np, child) {\n\t\tif (of_match_node(driver->subdevs, child) &&\n\t\t    of_device_is_available(child)) {\n\t\t\terr = host1x_subdev_add(device, driver, child);\n\t\t\tif (err < 0) {\n\t\t\t\t \n\t\t\t\tof_node_put(child);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic void host1x_subdev_del(struct host1x_subdev *subdev)\n{\n\tlist_del(&subdev->list);\n\tof_node_put(subdev->np);\n\tkfree(subdev);\n}\n\n \nstatic int host1x_device_parse_dt(struct host1x_device *device,\n\t\t\t\t  struct host1x_driver *driver)\n{\n\tstruct device_node *np;\n\tint err;\n\n\tfor_each_child_of_node(device->dev.parent->of_node, np) {\n\t\tif (of_match_node(driver->subdevs, np) &&\n\t\t    of_device_is_available(np)) {\n\t\t\terr = host1x_subdev_add(device, driver, np);\n\t\t\tif (err < 0) {\n\t\t\t\tof_node_put(np);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void host1x_subdev_register(struct host1x_device *device,\n\t\t\t\t   struct host1x_subdev *subdev,\n\t\t\t\t   struct host1x_client *client)\n{\n\tint err;\n\n\t \n\tmutex_lock(&device->subdevs_lock);\n\tmutex_lock(&device->clients_lock);\n\tlist_move_tail(&client->list, &device->clients);\n\tlist_move_tail(&subdev->list, &device->active);\n\tclient->host = &device->dev;\n\tsubdev->client = client;\n\tmutex_unlock(&device->clients_lock);\n\tmutex_unlock(&device->subdevs_lock);\n\n\tif (list_empty(&device->subdevs)) {\n\t\terr = device_add(&device->dev);\n\t\tif (err < 0)\n\t\t\tdev_err(&device->dev, \"failed to add: %d\\n\", err);\n\t\telse\n\t\t\tdevice->registered = true;\n\t}\n}\n\nstatic void __host1x_subdev_unregister(struct host1x_device *device,\n\t\t\t\t       struct host1x_subdev *subdev)\n{\n\tstruct host1x_client *client = subdev->client;\n\n\t \n\tif (list_empty(&device->subdevs)) {\n\t\tif (device->registered) {\n\t\t\tdevice->registered = false;\n\t\t\tdevice_del(&device->dev);\n\t\t}\n\t}\n\n\t \n\tmutex_lock(&device->clients_lock);\n\tsubdev->client = NULL;\n\tclient->host = NULL;\n\tlist_move_tail(&subdev->list, &device->subdevs);\n\t \n\tlist_del_init(&client->list);\n\tmutex_unlock(&device->clients_lock);\n}\n\nstatic void host1x_subdev_unregister(struct host1x_device *device,\n\t\t\t\t     struct host1x_subdev *subdev)\n{\n\tmutex_lock(&device->subdevs_lock);\n\t__host1x_subdev_unregister(device, subdev);\n\tmutex_unlock(&device->subdevs_lock);\n}\n\n \nint host1x_device_init(struct host1x_device *device)\n{\n\tstruct host1x_client *client;\n\tint err;\n\n\tmutex_lock(&device->clients_lock);\n\n\tlist_for_each_entry(client, &device->clients, list) {\n\t\tif (client->ops && client->ops->early_init) {\n\t\t\terr = client->ops->early_init(client);\n\t\t\tif (err < 0) {\n\t\t\t\tdev_err(&device->dev, \"failed to early initialize %s: %d\\n\",\n\t\t\t\t\tdev_name(client->dev), err);\n\t\t\t\tgoto teardown_late;\n\t\t\t}\n\t\t}\n\t}\n\n\tlist_for_each_entry(client, &device->clients, list) {\n\t\tif (client->ops && client->ops->init) {\n\t\t\terr = client->ops->init(client);\n\t\t\tif (err < 0) {\n\t\t\t\tdev_err(&device->dev,\n\t\t\t\t\t\"failed to initialize %s: %d\\n\",\n\t\t\t\t\tdev_name(client->dev), err);\n\t\t\t\tgoto teardown;\n\t\t\t}\n\t\t}\n\t}\n\n\tmutex_unlock(&device->clients_lock);\n\n\treturn 0;\n\nteardown:\n\tlist_for_each_entry_continue_reverse(client, &device->clients, list)\n\t\tif (client->ops->exit)\n\t\t\tclient->ops->exit(client);\n\n\t \n\tclient = list_entry(&device->clients, struct host1x_client, list);\n\nteardown_late:\n\tlist_for_each_entry_continue_reverse(client, &device->clients, list)\n\t\tif (client->ops->late_exit)\n\t\t\tclient->ops->late_exit(client);\n\n\tmutex_unlock(&device->clients_lock);\n\treturn err;\n}\nEXPORT_SYMBOL(host1x_device_init);\n\n \nint host1x_device_exit(struct host1x_device *device)\n{\n\tstruct host1x_client *client;\n\tint err;\n\n\tmutex_lock(&device->clients_lock);\n\n\tlist_for_each_entry_reverse(client, &device->clients, list) {\n\t\tif (client->ops && client->ops->exit) {\n\t\t\terr = client->ops->exit(client);\n\t\t\tif (err < 0) {\n\t\t\t\tdev_err(&device->dev,\n\t\t\t\t\t\"failed to cleanup %s: %d\\n\",\n\t\t\t\t\tdev_name(client->dev), err);\n\t\t\t\tmutex_unlock(&device->clients_lock);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\n\tlist_for_each_entry_reverse(client, &device->clients, list) {\n\t\tif (client->ops && client->ops->late_exit) {\n\t\t\terr = client->ops->late_exit(client);\n\t\t\tif (err < 0) {\n\t\t\t\tdev_err(&device->dev, \"failed to late cleanup %s: %d\\n\",\n\t\t\t\t\tdev_name(client->dev), err);\n\t\t\t\tmutex_unlock(&device->clients_lock);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\n\tmutex_unlock(&device->clients_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(host1x_device_exit);\n\nstatic int host1x_add_client(struct host1x *host1x,\n\t\t\t     struct host1x_client *client)\n{\n\tstruct host1x_device *device;\n\tstruct host1x_subdev *subdev;\n\n\tmutex_lock(&host1x->devices_lock);\n\n\tlist_for_each_entry(device, &host1x->devices, list) {\n\t\tlist_for_each_entry(subdev, &device->subdevs, list) {\n\t\t\tif (subdev->np == client->dev->of_node) {\n\t\t\t\thost1x_subdev_register(device, subdev, client);\n\t\t\t\tmutex_unlock(&host1x->devices_lock);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tmutex_unlock(&host1x->devices_lock);\n\treturn -ENODEV;\n}\n\nstatic int host1x_del_client(struct host1x *host1x,\n\t\t\t     struct host1x_client *client)\n{\n\tstruct host1x_device *device, *dt;\n\tstruct host1x_subdev *subdev;\n\n\tmutex_lock(&host1x->devices_lock);\n\n\tlist_for_each_entry_safe(device, dt, &host1x->devices, list) {\n\t\tlist_for_each_entry(subdev, &device->active, list) {\n\t\t\tif (subdev->client == client) {\n\t\t\t\thost1x_subdev_unregister(device, subdev);\n\t\t\t\tmutex_unlock(&host1x->devices_lock);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tmutex_unlock(&host1x->devices_lock);\n\treturn -ENODEV;\n}\n\nstatic int host1x_device_match(struct device *dev, struct device_driver *drv)\n{\n\treturn strcmp(dev_name(dev), drv->name) == 0;\n}\n\n \nstatic int host1x_device_uevent(const struct device *dev,\n\t\t\t\tstruct kobj_uevent_env *env)\n{\n\tof_device_uevent(dev->parent, env);\n\n\treturn 0;\n}\n\nstatic int host1x_dma_configure(struct device *dev)\n{\n\treturn of_dma_configure(dev, dev->of_node, true);\n}\n\nstatic const struct dev_pm_ops host1x_device_pm_ops = {\n\t.suspend = pm_generic_suspend,\n\t.resume = pm_generic_resume,\n\t.freeze = pm_generic_freeze,\n\t.thaw = pm_generic_thaw,\n\t.poweroff = pm_generic_poweroff,\n\t.restore = pm_generic_restore,\n};\n\nstruct bus_type host1x_bus_type = {\n\t.name = \"host1x\",\n\t.match = host1x_device_match,\n\t.uevent = host1x_device_uevent,\n\t.dma_configure = host1x_dma_configure,\n\t.pm = &host1x_device_pm_ops,\n};\n\nstatic void __host1x_device_del(struct host1x_device *device)\n{\n\tstruct host1x_subdev *subdev, *sd;\n\tstruct host1x_client *client, *cl;\n\n\tmutex_lock(&device->subdevs_lock);\n\n\t \n\tlist_for_each_entry_safe(subdev, sd, &device->active, list) {\n\t\t \n\t\tclient = subdev->client;\n\n\t\t__host1x_subdev_unregister(device, subdev);\n\n\t\t \n\t\tmutex_lock(&clients_lock);\n\t\tlist_add_tail(&client->list, &clients);\n\t\tmutex_unlock(&clients_lock);\n\t}\n\n\t \n\tlist_for_each_entry_safe(subdev, sd, &device->subdevs, list)\n\t\thost1x_subdev_del(subdev);\n\n\tmutex_unlock(&device->subdevs_lock);\n\n\t \n\tmutex_lock(&clients_lock);\n\tmutex_lock(&device->clients_lock);\n\n\tlist_for_each_entry_safe(client, cl, &device->clients, list)\n\t\tlist_move_tail(&client->list, &clients);\n\n\tmutex_unlock(&device->clients_lock);\n\tmutex_unlock(&clients_lock);\n\n\t \n\tlist_del_init(&device->list);\n}\n\nstatic void host1x_device_release(struct device *dev)\n{\n\tstruct host1x_device *device = to_host1x_device(dev);\n\n\t__host1x_device_del(device);\n\tkfree(device);\n}\n\nstatic int host1x_device_add(struct host1x *host1x,\n\t\t\t     struct host1x_driver *driver)\n{\n\tstruct host1x_client *client, *tmp;\n\tstruct host1x_subdev *subdev;\n\tstruct host1x_device *device;\n\tint err;\n\n\tdevice = kzalloc(sizeof(*device), GFP_KERNEL);\n\tif (!device)\n\t\treturn -ENOMEM;\n\n\tdevice_initialize(&device->dev);\n\n\tmutex_init(&device->subdevs_lock);\n\tINIT_LIST_HEAD(&device->subdevs);\n\tINIT_LIST_HEAD(&device->active);\n\tmutex_init(&device->clients_lock);\n\tINIT_LIST_HEAD(&device->clients);\n\tINIT_LIST_HEAD(&device->list);\n\tdevice->driver = driver;\n\n\tdevice->dev.coherent_dma_mask = host1x->dev->coherent_dma_mask;\n\tdevice->dev.dma_mask = &device->dev.coherent_dma_mask;\n\tdev_set_name(&device->dev, \"%s\", driver->driver.name);\n\tdevice->dev.release = host1x_device_release;\n\tdevice->dev.bus = &host1x_bus_type;\n\tdevice->dev.parent = host1x->dev;\n\n\tof_dma_configure(&device->dev, host1x->dev->of_node, true);\n\n\tdevice->dev.dma_parms = &device->dma_parms;\n\tdma_set_max_seg_size(&device->dev, UINT_MAX);\n\n\terr = host1x_device_parse_dt(device, driver);\n\tif (err < 0) {\n\t\tkfree(device);\n\t\treturn err;\n\t}\n\n\tlist_add_tail(&device->list, &host1x->devices);\n\n\tmutex_lock(&clients_lock);\n\n\tlist_for_each_entry_safe(client, tmp, &clients, list) {\n\t\tlist_for_each_entry(subdev, &device->subdevs, list) {\n\t\t\tif (subdev->np == client->dev->of_node) {\n\t\t\t\thost1x_subdev_register(device, subdev, client);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tmutex_unlock(&clients_lock);\n\n\treturn 0;\n}\n\n \nstatic void host1x_device_del(struct host1x *host1x,\n\t\t\t      struct host1x_device *device)\n{\n\tif (device->registered) {\n\t\tdevice->registered = false;\n\t\tdevice_del(&device->dev);\n\t}\n\n\tput_device(&device->dev);\n}\n\nstatic void host1x_attach_driver(struct host1x *host1x,\n\t\t\t\t struct host1x_driver *driver)\n{\n\tstruct host1x_device *device;\n\tint err;\n\n\tmutex_lock(&host1x->devices_lock);\n\n\tlist_for_each_entry(device, &host1x->devices, list) {\n\t\tif (device->driver == driver) {\n\t\t\tmutex_unlock(&host1x->devices_lock);\n\t\t\treturn;\n\t\t}\n\t}\n\n\terr = host1x_device_add(host1x, driver);\n\tif (err < 0)\n\t\tdev_err(host1x->dev, \"failed to allocate device: %d\\n\", err);\n\n\tmutex_unlock(&host1x->devices_lock);\n}\n\nstatic void host1x_detach_driver(struct host1x *host1x,\n\t\t\t\t struct host1x_driver *driver)\n{\n\tstruct host1x_device *device, *tmp;\n\n\tmutex_lock(&host1x->devices_lock);\n\n\tlist_for_each_entry_safe(device, tmp, &host1x->devices, list)\n\t\tif (device->driver == driver)\n\t\t\thost1x_device_del(host1x, device);\n\n\tmutex_unlock(&host1x->devices_lock);\n}\n\nstatic int host1x_devices_show(struct seq_file *s, void *data)\n{\n\tstruct host1x *host1x = s->private;\n\tstruct host1x_device *device;\n\n\tmutex_lock(&host1x->devices_lock);\n\n\tlist_for_each_entry(device, &host1x->devices, list) {\n\t\tstruct host1x_subdev *subdev;\n\n\t\tseq_printf(s, \"%s\\n\", dev_name(&device->dev));\n\n\t\tmutex_lock(&device->subdevs_lock);\n\n\t\tlist_for_each_entry(subdev, &device->active, list)\n\t\t\tseq_printf(s, \"  %pOFf: %s\\n\", subdev->np,\n\t\t\t\t   dev_name(subdev->client->dev));\n\n\t\tlist_for_each_entry(subdev, &device->subdevs, list)\n\t\t\tseq_printf(s, \"  %pOFf:\\n\", subdev->np);\n\n\t\tmutex_unlock(&device->subdevs_lock);\n\t}\n\n\tmutex_unlock(&host1x->devices_lock);\n\n\treturn 0;\n}\nDEFINE_SHOW_ATTRIBUTE(host1x_devices);\n\n \nint host1x_register(struct host1x *host1x)\n{\n\tstruct host1x_driver *driver;\n\n\tmutex_lock(&devices_lock);\n\tlist_add_tail(&host1x->list, &devices);\n\tmutex_unlock(&devices_lock);\n\n\tmutex_lock(&drivers_lock);\n\n\tlist_for_each_entry(driver, &drivers, list)\n\t\thost1x_attach_driver(host1x, driver);\n\n\tmutex_unlock(&drivers_lock);\n\n\tdebugfs_create_file(\"devices\", S_IRUGO, host1x->debugfs, host1x,\n\t\t\t    &host1x_devices_fops);\n\n\treturn 0;\n}\n\n \nint host1x_unregister(struct host1x *host1x)\n{\n\tstruct host1x_driver *driver;\n\n\tmutex_lock(&drivers_lock);\n\n\tlist_for_each_entry(driver, &drivers, list)\n\t\thost1x_detach_driver(host1x, driver);\n\n\tmutex_unlock(&drivers_lock);\n\n\tmutex_lock(&devices_lock);\n\tlist_del_init(&host1x->list);\n\tmutex_unlock(&devices_lock);\n\n\treturn 0;\n}\n\nstatic int host1x_device_probe(struct device *dev)\n{\n\tstruct host1x_driver *driver = to_host1x_driver(dev->driver);\n\tstruct host1x_device *device = to_host1x_device(dev);\n\n\tif (driver->probe)\n\t\treturn driver->probe(device);\n\n\treturn 0;\n}\n\nstatic int host1x_device_remove(struct device *dev)\n{\n\tstruct host1x_driver *driver = to_host1x_driver(dev->driver);\n\tstruct host1x_device *device = to_host1x_device(dev);\n\n\tif (driver->remove)\n\t\treturn driver->remove(device);\n\n\treturn 0;\n}\n\nstatic void host1x_device_shutdown(struct device *dev)\n{\n\tstruct host1x_driver *driver = to_host1x_driver(dev->driver);\n\tstruct host1x_device *device = to_host1x_device(dev);\n\n\tif (driver->shutdown)\n\t\tdriver->shutdown(device);\n}\n\n \nint host1x_driver_register_full(struct host1x_driver *driver,\n\t\t\t\tstruct module *owner)\n{\n\tstruct host1x *host1x;\n\n\tINIT_LIST_HEAD(&driver->list);\n\n\tmutex_lock(&drivers_lock);\n\tlist_add_tail(&driver->list, &drivers);\n\tmutex_unlock(&drivers_lock);\n\n\tmutex_lock(&devices_lock);\n\n\tlist_for_each_entry(host1x, &devices, list)\n\t\thost1x_attach_driver(host1x, driver);\n\n\tmutex_unlock(&devices_lock);\n\n\tdriver->driver.bus = &host1x_bus_type;\n\tdriver->driver.owner = owner;\n\tdriver->driver.probe = host1x_device_probe;\n\tdriver->driver.remove = host1x_device_remove;\n\tdriver->driver.shutdown = host1x_device_shutdown;\n\n\treturn driver_register(&driver->driver);\n}\nEXPORT_SYMBOL(host1x_driver_register_full);\n\n \nvoid host1x_driver_unregister(struct host1x_driver *driver)\n{\n\tstruct host1x *host1x;\n\n\tdriver_unregister(&driver->driver);\n\n\tmutex_lock(&devices_lock);\n\n\tlist_for_each_entry(host1x, &devices, list)\n\t\thost1x_detach_driver(host1x, driver);\n\n\tmutex_unlock(&devices_lock);\n\n\tmutex_lock(&drivers_lock);\n\tlist_del_init(&driver->list);\n\tmutex_unlock(&drivers_lock);\n}\nEXPORT_SYMBOL(host1x_driver_unregister);\n\n \nvoid __host1x_client_init(struct host1x_client *client, struct lock_class_key *key)\n{\n\thost1x_bo_cache_init(&client->cache);\n\tINIT_LIST_HEAD(&client->list);\n\t__mutex_init(&client->lock, \"host1x client lock\", key);\n\tclient->usecount = 0;\n}\nEXPORT_SYMBOL(__host1x_client_init);\n\n \nvoid host1x_client_exit(struct host1x_client *client)\n{\n\tmutex_destroy(&client->lock);\n}\nEXPORT_SYMBOL(host1x_client_exit);\n\n \nint __host1x_client_register(struct host1x_client *client)\n{\n\tstruct host1x *host1x;\n\tint err;\n\n\tmutex_lock(&devices_lock);\n\n\tlist_for_each_entry(host1x, &devices, list) {\n\t\terr = host1x_add_client(host1x, client);\n\t\tif (!err) {\n\t\t\tmutex_unlock(&devices_lock);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tmutex_unlock(&devices_lock);\n\n\tmutex_lock(&clients_lock);\n\tlist_add_tail(&client->list, &clients);\n\tmutex_unlock(&clients_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(__host1x_client_register);\n\n \nvoid host1x_client_unregister(struct host1x_client *client)\n{\n\tstruct host1x_client *c;\n\tstruct host1x *host1x;\n\tint err;\n\n\tmutex_lock(&devices_lock);\n\n\tlist_for_each_entry(host1x, &devices, list) {\n\t\terr = host1x_del_client(host1x, client);\n\t\tif (!err) {\n\t\t\tmutex_unlock(&devices_lock);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tmutex_unlock(&devices_lock);\n\tmutex_lock(&clients_lock);\n\n\tlist_for_each_entry(c, &clients, list) {\n\t\tif (c == client) {\n\t\t\tlist_del_init(&c->list);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&clients_lock);\n\n\thost1x_bo_cache_destroy(&client->cache);\n}\nEXPORT_SYMBOL(host1x_client_unregister);\n\nint host1x_client_suspend(struct host1x_client *client)\n{\n\tint err = 0;\n\n\tmutex_lock(&client->lock);\n\n\tif (client->usecount == 1) {\n\t\tif (client->ops && client->ops->suspend) {\n\t\t\terr = client->ops->suspend(client);\n\t\t\tif (err < 0)\n\t\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\tclient->usecount--;\n\tdev_dbg(client->dev, \"use count: %u\\n\", client->usecount);\n\n\tif (client->parent) {\n\t\terr = host1x_client_suspend(client->parent);\n\t\tif (err < 0)\n\t\t\tgoto resume;\n\t}\n\n\tgoto unlock;\n\nresume:\n\tif (client->usecount == 0)\n\t\tif (client->ops && client->ops->resume)\n\t\t\tclient->ops->resume(client);\n\n\tclient->usecount++;\nunlock:\n\tmutex_unlock(&client->lock);\n\treturn err;\n}\nEXPORT_SYMBOL(host1x_client_suspend);\n\nint host1x_client_resume(struct host1x_client *client)\n{\n\tint err = 0;\n\n\tmutex_lock(&client->lock);\n\n\tif (client->parent) {\n\t\terr = host1x_client_resume(client->parent);\n\t\tif (err < 0)\n\t\t\tgoto unlock;\n\t}\n\n\tif (client->usecount == 0) {\n\t\tif (client->ops && client->ops->resume) {\n\t\t\terr = client->ops->resume(client);\n\t\t\tif (err < 0)\n\t\t\t\tgoto suspend;\n\t\t}\n\t}\n\n\tclient->usecount++;\n\tdev_dbg(client->dev, \"use count: %u\\n\", client->usecount);\n\n\tgoto unlock;\n\nsuspend:\n\tif (client->parent)\n\t\thost1x_client_suspend(client->parent);\nunlock:\n\tmutex_unlock(&client->lock);\n\treturn err;\n}\nEXPORT_SYMBOL(host1x_client_resume);\n\nstruct host1x_bo_mapping *host1x_bo_pin(struct device *dev, struct host1x_bo *bo,\n\t\t\t\t\tenum dma_data_direction dir,\n\t\t\t\t\tstruct host1x_bo_cache *cache)\n{\n\tstruct host1x_bo_mapping *mapping;\n\n\tif (cache) {\n\t\tmutex_lock(&cache->lock);\n\n\t\tlist_for_each_entry(mapping, &cache->mappings, entry) {\n\t\t\tif (mapping->bo == bo && mapping->direction == dir) {\n\t\t\t\tkref_get(&mapping->ref);\n\t\t\t\tgoto unlock;\n\t\t\t}\n\t\t}\n\t}\n\n\tmapping = bo->ops->pin(dev, bo, dir);\n\tif (IS_ERR(mapping))\n\t\tgoto unlock;\n\n\tspin_lock(&mapping->bo->lock);\n\tlist_add_tail(&mapping->list, &bo->mappings);\n\tspin_unlock(&mapping->bo->lock);\n\n\tif (cache) {\n\t\tINIT_LIST_HEAD(&mapping->entry);\n\t\tmapping->cache = cache;\n\n\t\tlist_add_tail(&mapping->entry, &cache->mappings);\n\n\t\t \n\t\tkref_get(&mapping->ref);\n\t}\n\nunlock:\n\tif (cache)\n\t\tmutex_unlock(&cache->lock);\n\n\treturn mapping;\n}\nEXPORT_SYMBOL(host1x_bo_pin);\n\nstatic void __host1x_bo_unpin(struct kref *ref)\n{\n\tstruct host1x_bo_mapping *mapping = to_host1x_bo_mapping(ref);\n\n\t \n\tif (mapping->cache)\n\t\tlist_del(&mapping->entry);\n\n\tspin_lock(&mapping->bo->lock);\n\tlist_del(&mapping->list);\n\tspin_unlock(&mapping->bo->lock);\n\n\tmapping->bo->ops->unpin(mapping);\n}\n\nvoid host1x_bo_unpin(struct host1x_bo_mapping *mapping)\n{\n\tstruct host1x_bo_cache *cache = mapping->cache;\n\n\tif (cache)\n\t\tmutex_lock(&cache->lock);\n\n\tkref_put(&mapping->ref, __host1x_bo_unpin);\n\n\tif (cache)\n\t\tmutex_unlock(&cache->lock);\n}\nEXPORT_SYMBOL(host1x_bo_unpin);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}