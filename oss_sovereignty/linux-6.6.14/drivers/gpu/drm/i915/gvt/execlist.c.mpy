{
  "module_name": "execlist.c",
  "hash_id": "6336b0fef1dacc6df844b19c7b909595aa34bd75677a67e87500e78fcf15c59b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gvt/execlist.c",
  "human_readable_source": " \n\n#include \"i915_drv.h\"\n#include \"gvt.h\"\n\n#define _EL_OFFSET_STATUS       0x234\n#define _EL_OFFSET_STATUS_BUF   0x370\n#define _EL_OFFSET_STATUS_PTR   0x3A0\n\n#define execlist_ring_mmio(e, offset) ((e)->mmio_base + (offset))\n\n#define valid_context(ctx) ((ctx)->valid)\n#define same_context(a, b) (((a)->context_id == (b)->context_id) && \\\n\t\t((a)->lrca == (b)->lrca))\n\nstatic int context_switch_events[] = {\n\t[RCS0]  = RCS_AS_CONTEXT_SWITCH,\n\t[BCS0]  = BCS_AS_CONTEXT_SWITCH,\n\t[VCS0]  = VCS_AS_CONTEXT_SWITCH,\n\t[VCS1]  = VCS2_AS_CONTEXT_SWITCH,\n\t[VECS0] = VECS_AS_CONTEXT_SWITCH,\n};\n\nstatic int to_context_switch_event(const struct intel_engine_cs *engine)\n{\n\tif (WARN_ON(engine->id >= ARRAY_SIZE(context_switch_events)))\n\t\treturn -EINVAL;\n\n\treturn context_switch_events[engine->id];\n}\n\nstatic void switch_virtual_execlist_slot(struct intel_vgpu_execlist *execlist)\n{\n\tgvt_dbg_el(\"[before] running slot %d/context %x pending slot %d\\n\",\n\t\t\texeclist->running_slot ?\n\t\t\texeclist->running_slot->index : -1,\n\t\t\texeclist->running_context ?\n\t\t\texeclist->running_context->context_id : 0,\n\t\t\texeclist->pending_slot ?\n\t\t\texeclist->pending_slot->index : -1);\n\n\texeclist->running_slot = execlist->pending_slot;\n\texeclist->pending_slot = NULL;\n\texeclist->running_context = execlist->running_context ?\n\t\t&execlist->running_slot->ctx[0] : NULL;\n\n\tgvt_dbg_el(\"[after] running slot %d/context %x pending slot %d\\n\",\n\t\t\texeclist->running_slot ?\n\t\t\texeclist->running_slot->index : -1,\n\t\t\texeclist->running_context ?\n\t\t\texeclist->running_context->context_id : 0,\n\t\t\texeclist->pending_slot ?\n\t\t\texeclist->pending_slot->index : -1);\n}\n\nstatic void emulate_execlist_status(struct intel_vgpu_execlist *execlist)\n{\n\tstruct intel_vgpu_execlist_slot *running = execlist->running_slot;\n\tstruct intel_vgpu_execlist_slot *pending = execlist->pending_slot;\n\tstruct execlist_ctx_descriptor_format *desc = execlist->running_context;\n\tstruct intel_vgpu *vgpu = execlist->vgpu;\n\tstruct execlist_status_format status;\n\tu32 status_reg =\n\t\texeclist_ring_mmio(execlist->engine, _EL_OFFSET_STATUS);\n\n\tstatus.ldw = vgpu_vreg(vgpu, status_reg);\n\tstatus.udw = vgpu_vreg(vgpu, status_reg + 4);\n\n\tif (running) {\n\t\tstatus.current_execlist_pointer = !!running->index;\n\t\tstatus.execlist_write_pointer = !!!running->index;\n\t\tstatus.execlist_0_active = status.execlist_0_valid =\n\t\t\t!!!(running->index);\n\t\tstatus.execlist_1_active = status.execlist_1_valid =\n\t\t\t!!(running->index);\n\t} else {\n\t\tstatus.context_id = 0;\n\t\tstatus.execlist_0_active = status.execlist_0_valid = 0;\n\t\tstatus.execlist_1_active = status.execlist_1_valid = 0;\n\t}\n\n\tstatus.context_id = desc ? desc->context_id : 0;\n\tstatus.execlist_queue_full = !!(pending);\n\n\tvgpu_vreg(vgpu, status_reg) = status.ldw;\n\tvgpu_vreg(vgpu, status_reg + 4) = status.udw;\n\n\tgvt_dbg_el(\"vgpu%d: status reg offset %x ldw %x udw %x\\n\",\n\t\tvgpu->id, status_reg, status.ldw, status.udw);\n}\n\nstatic void emulate_csb_update(struct intel_vgpu_execlist *execlist,\n\t\t\t       struct execlist_context_status_format *status,\n\t\t\t       bool trigger_interrupt_later)\n{\n\tstruct intel_vgpu *vgpu = execlist->vgpu;\n\tstruct execlist_context_status_pointer_format ctx_status_ptr;\n\tu32 write_pointer;\n\tu32 ctx_status_ptr_reg, ctx_status_buf_reg, offset;\n\tunsigned long hwsp_gpa;\n\n\tctx_status_ptr_reg =\n\t\texeclist_ring_mmio(execlist->engine, _EL_OFFSET_STATUS_PTR);\n\tctx_status_buf_reg =\n\t\texeclist_ring_mmio(execlist->engine, _EL_OFFSET_STATUS_BUF);\n\n\tctx_status_ptr.dw = vgpu_vreg(vgpu, ctx_status_ptr_reg);\n\n\twrite_pointer = ctx_status_ptr.write_ptr;\n\n\tif (write_pointer == 0x7)\n\t\twrite_pointer = 0;\n\telse {\n\t\t++write_pointer;\n\t\twrite_pointer %= 0x6;\n\t}\n\n\toffset = ctx_status_buf_reg + write_pointer * 8;\n\n\tvgpu_vreg(vgpu, offset) = status->ldw;\n\tvgpu_vreg(vgpu, offset + 4) = status->udw;\n\n\tctx_status_ptr.write_ptr = write_pointer;\n\tvgpu_vreg(vgpu, ctx_status_ptr_reg) = ctx_status_ptr.dw;\n\n\t \n\thwsp_gpa = intel_vgpu_gma_to_gpa(vgpu->gtt.ggtt_mm,\n\t\t\t\t\t vgpu->hws_pga[execlist->engine->id]);\n\tif (hwsp_gpa != INTEL_GVT_INVALID_ADDR) {\n\t\tintel_gvt_write_gpa(vgpu,\n\t\t\thwsp_gpa + I915_HWS_CSB_BUF0_INDEX * 4 + write_pointer * 8,\n\t\t\tstatus, 8);\n\t\tintel_gvt_write_gpa(vgpu,\n\t\t\thwsp_gpa + INTEL_HWS_CSB_WRITE_INDEX(execlist->engine->i915) * 4,\n\t\t\t&write_pointer, 4);\n\t}\n\n\tgvt_dbg_el(\"vgpu%d: w pointer %u reg %x csb l %x csb h %x\\n\",\n\t\t   vgpu->id, write_pointer, offset, status->ldw, status->udw);\n\n\tif (trigger_interrupt_later)\n\t\treturn;\n\n\tintel_vgpu_trigger_virtual_event(vgpu,\n\t\t\t\t\t to_context_switch_event(execlist->engine));\n}\n\nstatic int emulate_execlist_ctx_schedule_out(\n\t\tstruct intel_vgpu_execlist *execlist,\n\t\tstruct execlist_ctx_descriptor_format *ctx)\n{\n\tstruct intel_vgpu *vgpu = execlist->vgpu;\n\tstruct intel_vgpu_execlist_slot *running = execlist->running_slot;\n\tstruct intel_vgpu_execlist_slot *pending = execlist->pending_slot;\n\tstruct execlist_ctx_descriptor_format *ctx0 = &running->ctx[0];\n\tstruct execlist_ctx_descriptor_format *ctx1 = &running->ctx[1];\n\tstruct execlist_context_status_format status;\n\n\tmemset(&status, 0, sizeof(status));\n\n\tgvt_dbg_el(\"schedule out context id %x\\n\", ctx->context_id);\n\n\tif (WARN_ON(!same_context(ctx, execlist->running_context))) {\n\t\tgvt_vgpu_err(\"schedule out context is not running context,\"\n\t\t\t\t\"ctx id %x running ctx id %x\\n\",\n\t\t\t\tctx->context_id,\n\t\t\t\texeclist->running_context->context_id);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (valid_context(ctx1) && same_context(ctx0, ctx)) {\n\t\tgvt_dbg_el(\"ctx 1 valid, ctx/ctx 0 is scheduled-out\\n\");\n\n\t\texeclist->running_context = ctx1;\n\n\t\temulate_execlist_status(execlist);\n\n\t\tstatus.context_complete = status.element_switch = 1;\n\t\tstatus.context_id = ctx->context_id;\n\n\t\temulate_csb_update(execlist, &status, false);\n\t\t \n\t} else if ((!valid_context(ctx1) && same_context(ctx0, ctx))\n\t\t\t|| (valid_context(ctx1) && same_context(ctx1, ctx))) {\n\t\tgvt_dbg_el(\"need to switch virtual execlist slot\\n\");\n\n\t\tswitch_virtual_execlist_slot(execlist);\n\n\t\temulate_execlist_status(execlist);\n\n\t\tstatus.context_complete = status.active_to_idle = 1;\n\t\tstatus.context_id = ctx->context_id;\n\n\t\tif (!pending) {\n\t\t\temulate_csb_update(execlist, &status, false);\n\t\t} else {\n\t\t\temulate_csb_update(execlist, &status, true);\n\n\t\t\tmemset(&status, 0, sizeof(status));\n\n\t\t\tstatus.idle_to_active = 1;\n\t\t\tstatus.context_id = 0;\n\n\t\t\temulate_csb_update(execlist, &status, false);\n\t\t}\n\t} else {\n\t\tWARN_ON(1);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic struct intel_vgpu_execlist_slot *get_next_execlist_slot(\n\t\tstruct intel_vgpu_execlist *execlist)\n{\n\tstruct intel_vgpu *vgpu = execlist->vgpu;\n\tu32 status_reg =\n\t\texeclist_ring_mmio(execlist->engine, _EL_OFFSET_STATUS);\n\tstruct execlist_status_format status;\n\n\tstatus.ldw = vgpu_vreg(vgpu, status_reg);\n\tstatus.udw = vgpu_vreg(vgpu, status_reg + 4);\n\n\tif (status.execlist_queue_full) {\n\t\tgvt_vgpu_err(\"virtual execlist slots are full\\n\");\n\t\treturn NULL;\n\t}\n\n\treturn &execlist->slot[status.execlist_write_pointer];\n}\n\nstatic int emulate_execlist_schedule_in(struct intel_vgpu_execlist *execlist,\n\t\tstruct execlist_ctx_descriptor_format ctx[2])\n{\n\tstruct intel_vgpu_execlist_slot *running = execlist->running_slot;\n\tstruct intel_vgpu_execlist_slot *slot =\n\t\tget_next_execlist_slot(execlist);\n\n\tstruct execlist_ctx_descriptor_format *ctx0, *ctx1;\n\tstruct execlist_context_status_format status;\n\tstruct intel_vgpu *vgpu = execlist->vgpu;\n\n\tgvt_dbg_el(\"emulate schedule-in\\n\");\n\n\tif (!slot) {\n\t\tgvt_vgpu_err(\"no available execlist slot\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmemset(&status, 0, sizeof(status));\n\tmemset(slot->ctx, 0, sizeof(slot->ctx));\n\n\tslot->ctx[0] = ctx[0];\n\tslot->ctx[1] = ctx[1];\n\n\tgvt_dbg_el(\"alloc slot index %d ctx 0 %x ctx 1 %x\\n\",\n\t\t\tslot->index, ctx[0].context_id,\n\t\t\tctx[1].context_id);\n\n\t \n\tif (!running) {\n\t\tgvt_dbg_el(\"no current running execlist\\n\");\n\n\t\texeclist->running_slot = slot;\n\t\texeclist->pending_slot = NULL;\n\t\texeclist->running_context = &slot->ctx[0];\n\n\t\tgvt_dbg_el(\"running slot index %d running context %x\\n\",\n\t\t\t\texeclist->running_slot->index,\n\t\t\t\texeclist->running_context->context_id);\n\n\t\temulate_execlist_status(execlist);\n\n\t\tstatus.idle_to_active = 1;\n\t\tstatus.context_id = 0;\n\n\t\temulate_csb_update(execlist, &status, false);\n\t\treturn 0;\n\t}\n\n\tctx0 = &running->ctx[0];\n\tctx1 = &running->ctx[1];\n\n\tgvt_dbg_el(\"current running slot index %d ctx 0 %x ctx 1 %x\\n\",\n\t\trunning->index, ctx0->context_id, ctx1->context_id);\n\n\t \n\tif ((valid_context(ctx1) && same_context(ctx1, &slot->ctx[0]) &&\n\t\t \n\t\t(!same_context(ctx0, execlist->running_context))) ||\n\t\t\t(!valid_context(ctx1) &&\n\t\t\t same_context(ctx0, &slot->ctx[0]))) {  \n\t\tgvt_dbg_el(\"need to switch virtual execlist slot\\n\");\n\n\t\texeclist->pending_slot = slot;\n\t\tswitch_virtual_execlist_slot(execlist);\n\n\t\temulate_execlist_status(execlist);\n\n\t\tstatus.lite_restore = status.preempted = 1;\n\t\tstatus.context_id = ctx[0].context_id;\n\n\t\temulate_csb_update(execlist, &status, false);\n\t} else {\n\t\tgvt_dbg_el(\"emulate as pending slot\\n\");\n\t\t \n\t\texeclist->pending_slot = slot;\n\t\temulate_execlist_status(execlist);\n\t}\n\treturn 0;\n}\n\n#define get_desc_from_elsp_dwords(ed, i) \\\n\t((struct execlist_ctx_descriptor_format *)&((ed)->data[i * 2]))\n\nstatic int prepare_execlist_workload(struct intel_vgpu_workload *workload)\n{\n\tstruct intel_vgpu *vgpu = workload->vgpu;\n\tstruct intel_vgpu_submission *s = &vgpu->submission;\n\tstruct execlist_ctx_descriptor_format ctx[2];\n\tint ret;\n\n\tif (!workload->emulate_schedule_in)\n\t\treturn 0;\n\n\tctx[0] = *get_desc_from_elsp_dwords(&workload->elsp_dwords, 0);\n\tctx[1] = *get_desc_from_elsp_dwords(&workload->elsp_dwords, 1);\n\n\tret = emulate_execlist_schedule_in(&s->execlist[workload->engine->id],\n\t\t\t\t\t   ctx);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"fail to emulate execlist schedule in\\n\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int complete_execlist_workload(struct intel_vgpu_workload *workload)\n{\n\tstruct intel_vgpu *vgpu = workload->vgpu;\n\tstruct intel_vgpu_submission *s = &vgpu->submission;\n\tstruct intel_vgpu_execlist *execlist =\n\t\t&s->execlist[workload->engine->id];\n\tstruct intel_vgpu_workload *next_workload;\n\tstruct list_head *next = workload_q_head(vgpu, workload->engine)->next;\n\tbool lite_restore = false;\n\tint ret = 0;\n\n\tgvt_dbg_el(\"complete workload %p status %d\\n\",\n\t\t   workload, workload->status);\n\n\tif (workload->status || vgpu->resetting_eng & workload->engine->mask)\n\t\tgoto out;\n\n\tif (!list_empty(workload_q_head(vgpu, workload->engine))) {\n\t\tstruct execlist_ctx_descriptor_format *this_desc, *next_desc;\n\n\t\tnext_workload = container_of(next,\n\t\t\t\tstruct intel_vgpu_workload, list);\n\t\tthis_desc = &workload->ctx_desc;\n\t\tnext_desc = &next_workload->ctx_desc;\n\n\t\tlite_restore = same_context(this_desc, next_desc);\n\t}\n\n\tif (lite_restore) {\n\t\tgvt_dbg_el(\"next context == current - no schedule-out\\n\");\n\t\tgoto out;\n\t}\n\n\tret = emulate_execlist_ctx_schedule_out(execlist, &workload->ctx_desc);\nout:\n\treturn ret;\n}\n\nstatic int submit_context(struct intel_vgpu *vgpu,\n\t\t\t  const struct intel_engine_cs *engine,\n\t\t\t  struct execlist_ctx_descriptor_format *desc,\n\t\t\t  bool emulate_schedule_in)\n{\n\tstruct intel_vgpu_submission *s = &vgpu->submission;\n\tstruct intel_vgpu_workload *workload = NULL;\n\n\tworkload = intel_vgpu_create_workload(vgpu, engine, desc);\n\tif (IS_ERR(workload))\n\t\treturn PTR_ERR(workload);\n\n\tworkload->prepare = prepare_execlist_workload;\n\tworkload->complete = complete_execlist_workload;\n\tworkload->emulate_schedule_in = emulate_schedule_in;\n\n\tif (emulate_schedule_in)\n\t\tworkload->elsp_dwords = s->execlist[engine->id].elsp_dwords;\n\n\tgvt_dbg_el(\"workload %p emulate schedule_in %d\\n\", workload,\n\t\t   emulate_schedule_in);\n\n\tintel_vgpu_queue_workload(workload);\n\treturn 0;\n}\n\nint intel_vgpu_submit_execlist(struct intel_vgpu *vgpu,\n\t\t\t       const struct intel_engine_cs *engine)\n{\n\tstruct intel_vgpu_submission *s = &vgpu->submission;\n\tstruct intel_vgpu_execlist *execlist = &s->execlist[engine->id];\n\tstruct execlist_ctx_descriptor_format *desc[2];\n\tint i, ret;\n\n\tdesc[0] = get_desc_from_elsp_dwords(&execlist->elsp_dwords, 0);\n\tdesc[1] = get_desc_from_elsp_dwords(&execlist->elsp_dwords, 1);\n\n\tif (!desc[0]->valid) {\n\t\tgvt_vgpu_err(\"invalid elsp submission, desc0 is invalid\\n\");\n\t\tgoto inv_desc;\n\t}\n\n\tfor (i = 0; i < ARRAY_SIZE(desc); i++) {\n\t\tif (!desc[i]->valid)\n\t\t\tcontinue;\n\t\tif (!desc[i]->privilege_access) {\n\t\t\tgvt_vgpu_err(\"unexpected GGTT elsp submission\\n\");\n\t\t\tgoto inv_desc;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(desc); i++) {\n\t\tif (!desc[i]->valid)\n\t\t\tcontinue;\n\t\tret = submit_context(vgpu, engine, desc[i], i == 0);\n\t\tif (ret) {\n\t\t\tgvt_vgpu_err(\"failed to submit desc %d\\n\", i);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n\ninv_desc:\n\tgvt_vgpu_err(\"descriptors content: desc0 %08x %08x desc1 %08x %08x\\n\",\n\t\t     desc[0]->udw, desc[0]->ldw, desc[1]->udw, desc[1]->ldw);\n\treturn -EINVAL;\n}\n\nstatic void init_vgpu_execlist(struct intel_vgpu *vgpu,\n\t\t\t       const struct intel_engine_cs *engine)\n{\n\tstruct intel_vgpu_submission *s = &vgpu->submission;\n\tstruct intel_vgpu_execlist *execlist = &s->execlist[engine->id];\n\tstruct execlist_context_status_pointer_format ctx_status_ptr;\n\tu32 ctx_status_ptr_reg;\n\n\tmemset(execlist, 0, sizeof(*execlist));\n\n\texeclist->vgpu = vgpu;\n\texeclist->engine = engine;\n\texeclist->slot[0].index = 0;\n\texeclist->slot[1].index = 1;\n\n\tctx_status_ptr_reg = execlist_ring_mmio(engine, _EL_OFFSET_STATUS_PTR);\n\tctx_status_ptr.dw = vgpu_vreg(vgpu, ctx_status_ptr_reg);\n\tctx_status_ptr.read_ptr = 0;\n\tctx_status_ptr.write_ptr = 0x7;\n\tvgpu_vreg(vgpu, ctx_status_ptr_reg) = ctx_status_ptr.dw;\n}\n\nstatic void clean_execlist(struct intel_vgpu *vgpu,\n\t\t\t   intel_engine_mask_t engine_mask)\n{\n\tstruct intel_vgpu_submission *s = &vgpu->submission;\n\tstruct intel_engine_cs *engine;\n\tintel_engine_mask_t tmp;\n\n\tfor_each_engine_masked(engine, vgpu->gvt->gt, engine_mask, tmp) {\n\t\tkfree(s->ring_scan_buffer[engine->id]);\n\t\ts->ring_scan_buffer[engine->id] = NULL;\n\t\ts->ring_scan_buffer_size[engine->id] = 0;\n\t}\n}\n\nstatic void reset_execlist(struct intel_vgpu *vgpu,\n\t\t\t   intel_engine_mask_t engine_mask)\n{\n\tstruct intel_engine_cs *engine;\n\tintel_engine_mask_t tmp;\n\n\tfor_each_engine_masked(engine, vgpu->gvt->gt, engine_mask, tmp)\n\t\tinit_vgpu_execlist(vgpu, engine);\n}\n\nstatic int init_execlist(struct intel_vgpu *vgpu,\n\t\t\t intel_engine_mask_t engine_mask)\n{\n\treset_execlist(vgpu, engine_mask);\n\treturn 0;\n}\n\nconst struct intel_vgpu_submission_ops intel_vgpu_execlist_submission_ops = {\n\t.name = \"execlist\",\n\t.init = init_execlist,\n\t.reset = reset_execlist,\n\t.clean = clean_execlist,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}