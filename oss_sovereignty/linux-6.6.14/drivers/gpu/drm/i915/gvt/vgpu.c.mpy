{
  "module_name": "vgpu.c",
  "hash_id": "f5039748ae3deeada0a7f222e41f38cafc53b5595d2839d52aa79d455ca9ffb6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gvt/vgpu.c",
  "human_readable_source": " \n\n#include \"i915_drv.h\"\n#include \"gvt.h\"\n#include \"i915_pvinfo.h\"\n\nvoid populate_pvinfo_page(struct intel_vgpu *vgpu)\n{\n\tstruct drm_i915_private *i915 = vgpu->gvt->gt->i915;\n\t \n\tvgpu_vreg64_t(vgpu, vgtif_reg(magic)) = VGT_MAGIC;\n\tvgpu_vreg_t(vgpu, vgtif_reg(version_major)) = 1;\n\tvgpu_vreg_t(vgpu, vgtif_reg(version_minor)) = 0;\n\tvgpu_vreg_t(vgpu, vgtif_reg(display_ready)) = 0;\n\tvgpu_vreg_t(vgpu, vgtif_reg(vgt_id)) = vgpu->id;\n\n\tvgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) = VGT_CAPS_FULL_PPGTT;\n\tvgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HWSP_EMULATION;\n\tvgpu_vreg_t(vgpu, vgtif_reg(vgt_caps)) |= VGT_CAPS_HUGE_GTT;\n\n\tvgpu_vreg_t(vgpu, vgtif_reg(avail_rs.mappable_gmadr.base)) =\n\t\tvgpu_aperture_gmadr_base(vgpu);\n\tvgpu_vreg_t(vgpu, vgtif_reg(avail_rs.mappable_gmadr.size)) =\n\t\tvgpu_aperture_sz(vgpu);\n\tvgpu_vreg_t(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.base)) =\n\t\tvgpu_hidden_gmadr_base(vgpu);\n\tvgpu_vreg_t(vgpu, vgtif_reg(avail_rs.nonmappable_gmadr.size)) =\n\t\tvgpu_hidden_sz(vgpu);\n\n\tvgpu_vreg_t(vgpu, vgtif_reg(avail_rs.fence_num)) = vgpu_fence_sz(vgpu);\n\n\tvgpu_vreg_t(vgpu, vgtif_reg(cursor_x_hot)) = UINT_MAX;\n\tvgpu_vreg_t(vgpu, vgtif_reg(cursor_y_hot)) = UINT_MAX;\n\n\tgvt_dbg_core(\"Populate PVINFO PAGE for vGPU %d\\n\", vgpu->id);\n\tgvt_dbg_core(\"aperture base [GMADR] 0x%llx size 0x%llx\\n\",\n\t\tvgpu_aperture_gmadr_base(vgpu), vgpu_aperture_sz(vgpu));\n\tgvt_dbg_core(\"hidden base [GMADR] 0x%llx size=0x%llx\\n\",\n\t\tvgpu_hidden_gmadr_base(vgpu), vgpu_hidden_sz(vgpu));\n\tgvt_dbg_core(\"fence size %d\\n\", vgpu_fence_sz(vgpu));\n\n\tdrm_WARN_ON(&i915->drm, sizeof(struct vgt_if) != VGT_PVINFO_SIZE);\n}\n\n \n#define VGPU_MAX_WEIGHT 16\n#define VGPU_WEIGHT(vgpu_num)\t\\\n\t(VGPU_MAX_WEIGHT / (vgpu_num))\n\nstatic const struct intel_vgpu_config intel_vgpu_configs[] = {\n\t{ MB_TO_BYTES(64), MB_TO_BYTES(384), 4, VGPU_WEIGHT(8), GVT_EDID_1024_768, \"8\" },\n\t{ MB_TO_BYTES(128), MB_TO_BYTES(512), 4, VGPU_WEIGHT(4), GVT_EDID_1920_1200, \"4\" },\n\t{ MB_TO_BYTES(256), MB_TO_BYTES(1024), 4, VGPU_WEIGHT(2), GVT_EDID_1920_1200, \"2\" },\n\t{ MB_TO_BYTES(512), MB_TO_BYTES(2048), 4, VGPU_WEIGHT(1), GVT_EDID_1920_1200, \"1\" },\n};\n\n \nint intel_gvt_init_vgpu_types(struct intel_gvt *gvt)\n{\n\tunsigned int low_avail = gvt_aperture_sz(gvt) - HOST_LOW_GM_SIZE;\n\tunsigned int high_avail = gvt_hidden_sz(gvt) - HOST_HIGH_GM_SIZE;\n\tunsigned int num_types = ARRAY_SIZE(intel_vgpu_configs);\n\tunsigned int i;\n\n\tgvt->types = kcalloc(num_types, sizeof(struct intel_vgpu_type),\n\t\t\t     GFP_KERNEL);\n\tif (!gvt->types)\n\t\treturn -ENOMEM;\n\n\tgvt->mdev_types = kcalloc(num_types, sizeof(*gvt->mdev_types),\n\t\t\t     GFP_KERNEL);\n\tif (!gvt->mdev_types)\n\t\tgoto out_free_types;\n\n\tfor (i = 0; i < num_types; ++i) {\n\t\tconst struct intel_vgpu_config *conf = &intel_vgpu_configs[i];\n\n\t\tif (low_avail / conf->low_mm == 0)\n\t\t\tbreak;\n\t\tif (conf->weight < 1 || conf->weight > VGPU_MAX_WEIGHT)\n\t\t\tgoto out_free_mdev_types;\n\n\t\tsprintf(gvt->types[i].name, \"GVTg_V%u_%s\",\n\t\t\tGRAPHICS_VER(gvt->gt->i915) == 8 ? 4 : 5, conf->name);\n\t\tgvt->types[i].conf = conf;\n\n\t\tgvt_dbg_core(\"type[%d]: %s avail %u low %u high %u fence %u weight %u res %s\\n\",\n\t\t\t     i, gvt->types[i].name,\n\t\t\t     min(low_avail / conf->low_mm,\n\t\t\t\t high_avail / conf->high_mm),\n\t\t\t     conf->low_mm, conf->high_mm, conf->fence,\n\t\t\t     conf->weight, vgpu_edid_str(conf->edid));\n\n\t\tgvt->mdev_types[i] = &gvt->types[i].type;\n\t\tgvt->mdev_types[i]->sysfs_name = gvt->types[i].name;\n\t}\n\n\tgvt->num_types = i;\n\treturn 0;\n\nout_free_mdev_types:\n\tkfree(gvt->mdev_types);\nout_free_types:\n\tkfree(gvt->types);\n\treturn -EINVAL;\n}\n\nvoid intel_gvt_clean_vgpu_types(struct intel_gvt *gvt)\n{\n\tkfree(gvt->mdev_types);\n\tkfree(gvt->types);\n}\n\n \nvoid intel_gvt_activate_vgpu(struct intel_vgpu *vgpu)\n{\n\tset_bit(INTEL_VGPU_STATUS_ACTIVE, vgpu->status);\n}\n\n \nvoid intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)\n{\n\tmutex_lock(&vgpu->vgpu_lock);\n\n\tclear_bit(INTEL_VGPU_STATUS_ACTIVE, vgpu->status);\n\n\tif (atomic_read(&vgpu->submission.running_workload_num)) {\n\t\tmutex_unlock(&vgpu->vgpu_lock);\n\t\tintel_gvt_wait_vgpu_idle(vgpu);\n\t\tmutex_lock(&vgpu->vgpu_lock);\n\t}\n\n\tintel_vgpu_stop_schedule(vgpu);\n\n\tmutex_unlock(&vgpu->vgpu_lock);\n}\n\n \nvoid intel_gvt_release_vgpu(struct intel_vgpu *vgpu)\n{\n\tintel_gvt_deactivate_vgpu(vgpu);\n\n\tmutex_lock(&vgpu->vgpu_lock);\n\tvgpu->d3_entered = false;\n\tintel_vgpu_clean_workloads(vgpu, ALL_ENGINES);\n\tintel_vgpu_dmabuf_cleanup(vgpu);\n\tmutex_unlock(&vgpu->vgpu_lock);\n}\n\n \nvoid intel_gvt_destroy_vgpu(struct intel_vgpu *vgpu)\n{\n\tstruct intel_gvt *gvt = vgpu->gvt;\n\tstruct drm_i915_private *i915 = gvt->gt->i915;\n\n\tdrm_WARN(&i915->drm, test_bit(INTEL_VGPU_STATUS_ACTIVE, vgpu->status),\n\t\t \"vGPU is still active!\\n\");\n\n\t \n\tmutex_lock(&gvt->lock);\n\tidr_remove(&gvt->vgpu_idr, vgpu->id);\n\tmutex_unlock(&gvt->lock);\n\n\tmutex_lock(&vgpu->vgpu_lock);\n\tintel_gvt_debugfs_remove_vgpu(vgpu);\n\tintel_vgpu_clean_sched_policy(vgpu);\n\tintel_vgpu_clean_submission(vgpu);\n\tintel_vgpu_clean_display(vgpu);\n\tintel_vgpu_clean_opregion(vgpu);\n\tintel_vgpu_reset_ggtt(vgpu, true);\n\tintel_vgpu_clean_gtt(vgpu);\n\tintel_vgpu_detach_regions(vgpu);\n\tintel_vgpu_free_resource(vgpu);\n\tintel_vgpu_clean_mmio(vgpu);\n\tintel_vgpu_dmabuf_cleanup(vgpu);\n\tmutex_unlock(&vgpu->vgpu_lock);\n}\n\n#define IDLE_VGPU_IDR 0\n\n \nstruct intel_vgpu *intel_gvt_create_idle_vgpu(struct intel_gvt *gvt)\n{\n\tstruct intel_vgpu *vgpu;\n\tenum intel_engine_id i;\n\tint ret;\n\n\tvgpu = vzalloc(sizeof(*vgpu));\n\tif (!vgpu)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tvgpu->id = IDLE_VGPU_IDR;\n\tvgpu->gvt = gvt;\n\tmutex_init(&vgpu->vgpu_lock);\n\n\tfor (i = 0; i < I915_NUM_ENGINES; i++)\n\t\tINIT_LIST_HEAD(&vgpu->submission.workload_q_head[i]);\n\n\tret = intel_vgpu_init_sched_policy(vgpu);\n\tif (ret)\n\t\tgoto out_free_vgpu;\n\n\tclear_bit(INTEL_VGPU_STATUS_ACTIVE, vgpu->status);\n\treturn vgpu;\n\nout_free_vgpu:\n\tvfree(vgpu);\n\treturn ERR_PTR(ret);\n}\n\n \nvoid intel_gvt_destroy_idle_vgpu(struct intel_vgpu *vgpu)\n{\n\tmutex_lock(&vgpu->vgpu_lock);\n\tintel_vgpu_clean_sched_policy(vgpu);\n\tmutex_unlock(&vgpu->vgpu_lock);\n\n\tvfree(vgpu);\n}\n\nint intel_gvt_create_vgpu(struct intel_vgpu *vgpu,\n\t\tconst struct intel_vgpu_config *conf)\n{\n\tstruct intel_gvt *gvt = vgpu->gvt;\n\tstruct drm_i915_private *dev_priv = gvt->gt->i915;\n\tint ret;\n\n\tgvt_dbg_core(\"low %u MB high %u MB fence %u\\n\",\n\t\t\tBYTES_TO_MB(conf->low_mm), BYTES_TO_MB(conf->high_mm),\n\t\t\tconf->fence);\n\n\tmutex_lock(&gvt->lock);\n\tret = idr_alloc(&gvt->vgpu_idr, vgpu, IDLE_VGPU_IDR + 1, GVT_MAX_VGPU,\n\t\tGFP_KERNEL);\n\tif (ret < 0)\n\t\tgoto out_unlock;\n\n\tvgpu->id = ret;\n\tvgpu->sched_ctl.weight = conf->weight;\n\tmutex_init(&vgpu->vgpu_lock);\n\tmutex_init(&vgpu->dmabuf_lock);\n\tINIT_LIST_HEAD(&vgpu->dmabuf_obj_list_head);\n\tINIT_RADIX_TREE(&vgpu->page_track_tree, GFP_KERNEL);\n\tidr_init_base(&vgpu->object_idr, 1);\n\tintel_vgpu_init_cfg_space(vgpu, 1);\n\tvgpu->d3_entered = false;\n\n\tret = intel_vgpu_init_mmio(vgpu);\n\tif (ret)\n\t\tgoto out_clean_idr;\n\n\tret = intel_vgpu_alloc_resource(vgpu, conf);\n\tif (ret)\n\t\tgoto out_clean_vgpu_mmio;\n\n\tpopulate_pvinfo_page(vgpu);\n\n\tret = intel_vgpu_init_gtt(vgpu);\n\tif (ret)\n\t\tgoto out_clean_vgpu_resource;\n\n\tret = intel_vgpu_init_opregion(vgpu);\n\tif (ret)\n\t\tgoto out_clean_gtt;\n\n\tret = intel_vgpu_init_display(vgpu, conf->edid);\n\tif (ret)\n\t\tgoto out_clean_opregion;\n\n\tret = intel_vgpu_setup_submission(vgpu);\n\tif (ret)\n\t\tgoto out_clean_display;\n\n\tret = intel_vgpu_init_sched_policy(vgpu);\n\tif (ret)\n\t\tgoto out_clean_submission;\n\n\tintel_gvt_debugfs_add_vgpu(vgpu);\n\n\tret = intel_gvt_set_opregion(vgpu);\n\tif (ret)\n\t\tgoto out_clean_sched_policy;\n\n\tif (IS_BROADWELL(dev_priv) || IS_BROXTON(dev_priv))\n\t\tret = intel_gvt_set_edid(vgpu, PORT_B);\n\telse\n\t\tret = intel_gvt_set_edid(vgpu, PORT_D);\n\tif (ret)\n\t\tgoto out_clean_sched_policy;\n\n\tintel_gvt_update_reg_whitelist(vgpu);\n\tmutex_unlock(&gvt->lock);\n\treturn 0;\n\nout_clean_sched_policy:\n\tintel_vgpu_clean_sched_policy(vgpu);\nout_clean_submission:\n\tintel_vgpu_clean_submission(vgpu);\nout_clean_display:\n\tintel_vgpu_clean_display(vgpu);\nout_clean_opregion:\n\tintel_vgpu_clean_opregion(vgpu);\nout_clean_gtt:\n\tintel_vgpu_clean_gtt(vgpu);\nout_clean_vgpu_resource:\n\tintel_vgpu_free_resource(vgpu);\nout_clean_vgpu_mmio:\n\tintel_vgpu_clean_mmio(vgpu);\nout_clean_idr:\n\tidr_remove(&gvt->vgpu_idr, vgpu->id);\nout_unlock:\n\tmutex_unlock(&gvt->lock);\n\treturn ret;\n}\n\n \nvoid intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,\n\t\t\t\t intel_engine_mask_t engine_mask)\n{\n\tstruct intel_gvt *gvt = vgpu->gvt;\n\tstruct intel_gvt_workload_scheduler *scheduler = &gvt->scheduler;\n\tintel_engine_mask_t resetting_eng = dmlr ? ALL_ENGINES : engine_mask;\n\n\tgvt_dbg_core(\"------------------------------------------\\n\");\n\tgvt_dbg_core(\"resseting vgpu%d, dmlr %d, engine_mask %08x\\n\",\n\t\t     vgpu->id, dmlr, engine_mask);\n\n\tvgpu->resetting_eng = resetting_eng;\n\n\tintel_vgpu_stop_schedule(vgpu);\n\t \n\tif (scheduler->current_vgpu == NULL) {\n\t\tmutex_unlock(&vgpu->vgpu_lock);\n\t\tintel_gvt_wait_vgpu_idle(vgpu);\n\t\tmutex_lock(&vgpu->vgpu_lock);\n\t}\n\n\tintel_vgpu_reset_submission(vgpu, resetting_eng);\n\t \n\tif (engine_mask == ALL_ENGINES || dmlr) {\n\t\tintel_vgpu_select_submission_ops(vgpu, ALL_ENGINES, 0);\n\t\tif (engine_mask == ALL_ENGINES)\n\t\t\tintel_vgpu_invalidate_ppgtt(vgpu);\n\t\t \n\t\tif (dmlr) {\n\t\t\tif(!vgpu->d3_entered) {\n\t\t\t\tintel_vgpu_invalidate_ppgtt(vgpu);\n\t\t\t\tintel_vgpu_destroy_all_ppgtt_mm(vgpu);\n\t\t\t}\n\t\t\tintel_vgpu_reset_ggtt(vgpu, true);\n\t\t\tintel_vgpu_reset_resource(vgpu);\n\t\t}\n\n\t\tintel_vgpu_reset_mmio(vgpu, dmlr);\n\t\tpopulate_pvinfo_page(vgpu);\n\n\t\tif (dmlr) {\n\t\t\tintel_vgpu_reset_display(vgpu);\n\t\t\tintel_vgpu_reset_cfg_space(vgpu);\n\t\t\t \n\t\t\tvgpu->failsafe = false;\n\t\t\t \n\t\t\tif(vgpu->d3_entered)\n\t\t\t\tvgpu->d3_entered = false;\n\t\t\telse\n\t\t\t\tvgpu->pv_notified = false;\n\t\t}\n\t}\n\n\tvgpu->resetting_eng = 0;\n\tgvt_dbg_core(\"reset vgpu%d done\\n\", vgpu->id);\n\tgvt_dbg_core(\"------------------------------------------\\n\");\n}\n\n \nvoid intel_gvt_reset_vgpu(struct intel_vgpu *vgpu)\n{\n\tmutex_lock(&vgpu->vgpu_lock);\n\tintel_gvt_reset_vgpu_locked(vgpu, true, 0);\n\tmutex_unlock(&vgpu->vgpu_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}