{
  "module_name": "cmd_parser.c",
  "hash_id": "dd9740a7e2928ea1779aea930c2445090ea2ef09aadfe7b5b565f1feccf709eb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gvt/cmd_parser.c",
  "human_readable_source": " \n\n#include <linux/slab.h>\n\n#include \"i915_drv.h\"\n#include \"i915_reg.h\"\n#include \"gt/intel_engine_regs.h\"\n#include \"gt/intel_gpu_commands.h\"\n#include \"gt/intel_gt_regs.h\"\n#include \"gt/intel_lrc.h\"\n#include \"gt/intel_ring.h\"\n#include \"gt/intel_gt_requests.h\"\n#include \"gt/shmem_utils.h\"\n#include \"gvt.h\"\n#include \"i915_pvinfo.h\"\n#include \"trace.h\"\n\n#include \"display/intel_display.h\"\n#include \"gem/i915_gem_context.h\"\n#include \"gem/i915_gem_pm.h\"\n#include \"gt/intel_context.h\"\n\n#define INVALID_OP    (~0U)\n\n#define OP_LEN_MI           9\n#define OP_LEN_2D           10\n#define OP_LEN_3D_MEDIA     16\n#define OP_LEN_MFX_VC       16\n#define OP_LEN_VEBOX\t    16\n\n#define CMD_TYPE(cmd)\t(((cmd) >> 29) & 7)\n\nstruct sub_op_bits {\n\tint hi;\n\tint low;\n};\nstruct decode_info {\n\tconst char *name;\n\tint op_len;\n\tint nr_sub_op;\n\tconst struct sub_op_bits *sub_op;\n};\n\n#define   MAX_CMD_BUDGET\t\t\t0x7fffffff\n#define   MI_WAIT_FOR_PLANE_C_FLIP_PENDING      (1<<15)\n#define   MI_WAIT_FOR_PLANE_B_FLIP_PENDING      (1<<9)\n#define   MI_WAIT_FOR_PLANE_A_FLIP_PENDING      (1<<1)\n\n#define   MI_WAIT_FOR_SPRITE_C_FLIP_PENDING      (1<<20)\n#define   MI_WAIT_FOR_SPRITE_B_FLIP_PENDING      (1<<10)\n#define   MI_WAIT_FOR_SPRITE_A_FLIP_PENDING      (1<<2)\n\n \n\n \n#define OP_MI_NOOP                          0x0\n#define OP_MI_SET_PREDICATE                 0x1   \n#define OP_MI_USER_INTERRUPT                0x2\n#define OP_MI_WAIT_FOR_EVENT                0x3\n#define OP_MI_FLUSH                         0x4\n#define OP_MI_ARB_CHECK                     0x5\n#define OP_MI_RS_CONTROL                    0x6   \n#define OP_MI_REPORT_HEAD                   0x7\n#define OP_MI_ARB_ON_OFF                    0x8\n#define OP_MI_URB_ATOMIC_ALLOC              0x9   \n#define OP_MI_BATCH_BUFFER_END              0xA\n#define OP_MI_SUSPEND_FLUSH                 0xB\n#define OP_MI_PREDICATE                     0xC   \n#define OP_MI_TOPOLOGY_FILTER               0xD   \n#define OP_MI_SET_APPID                     0xE   \n#define OP_MI_RS_CONTEXT                    0xF   \n#define OP_MI_LOAD_SCAN_LINES_INCL          0x12  \n#define OP_MI_DISPLAY_FLIP                  0x14\n#define OP_MI_SEMAPHORE_MBOX                0x16\n#define OP_MI_SET_CONTEXT                   0x18\n#define OP_MI_MATH                          0x1A\n#define OP_MI_URB_CLEAR                     0x19\n#define OP_MI_SEMAPHORE_SIGNAL\t\t    0x1B   \n#define OP_MI_SEMAPHORE_WAIT\t\t    0x1C   \n\n#define OP_MI_STORE_DATA_IMM                0x20\n#define OP_MI_STORE_DATA_INDEX              0x21\n#define OP_MI_LOAD_REGISTER_IMM             0x22\n#define OP_MI_UPDATE_GTT                    0x23\n#define OP_MI_STORE_REGISTER_MEM            0x24\n#define OP_MI_FLUSH_DW                      0x26\n#define OP_MI_CLFLUSH                       0x27\n#define OP_MI_REPORT_PERF_COUNT             0x28\n#define OP_MI_LOAD_REGISTER_MEM             0x29   \n#define OP_MI_LOAD_REGISTER_REG             0x2A   \n#define OP_MI_RS_STORE_DATA_IMM             0x2B   \n#define OP_MI_LOAD_URB_MEM                  0x2C   \n#define OP_MI_STORE_URM_MEM                 0x2D   \n#define OP_MI_2E\t\t\t    0x2E   \n#define OP_MI_2F\t\t\t    0x2F   \n#define OP_MI_BATCH_BUFFER_START            0x31\n\n \n#define _CMDBIT_BB_START_IN_PPGTT\t(1UL << 8)\n\n#define OP_MI_CONDITIONAL_BATCH_BUFFER_END  0x36\n\n#define BATCH_BUFFER_ADDR_MASK ((1UL << 32) - (1U << 2))\n#define BATCH_BUFFER_ADDR_HIGH_MASK ((1UL << 16) - (1U))\n#define BATCH_BUFFER_ADR_SPACE_BIT(x)\t(((x) >> 8) & 1U)\n#define BATCH_BUFFER_2ND_LEVEL_BIT(x)   ((x) >> 22 & 1U)\n\n \n#define OP_2D(x)    ((2<<7) | x)\n\n#define OP_XY_SETUP_BLT                             OP_2D(0x1)\n#define OP_XY_SETUP_CLIP_BLT                        OP_2D(0x3)\n#define OP_XY_SETUP_MONO_PATTERN_SL_BLT             OP_2D(0x11)\n#define OP_XY_PIXEL_BLT                             OP_2D(0x24)\n#define OP_XY_SCANLINES_BLT                         OP_2D(0x25)\n#define OP_XY_TEXT_BLT                              OP_2D(0x26)\n#define OP_XY_TEXT_IMMEDIATE_BLT                    OP_2D(0x31)\n#define OP_XY_COLOR_BLT                             OP_2D(0x50)\n#define OP_XY_PAT_BLT                               OP_2D(0x51)\n#define OP_XY_MONO_PAT_BLT                          OP_2D(0x52)\n#define OP_XY_SRC_COPY_BLT                          OP_2D(0x53)\n#define OP_XY_MONO_SRC_COPY_BLT                     OP_2D(0x54)\n#define OP_XY_FULL_BLT                              OP_2D(0x55)\n#define OP_XY_FULL_MONO_SRC_BLT                     OP_2D(0x56)\n#define OP_XY_FULL_MONO_PATTERN_BLT                 OP_2D(0x57)\n#define OP_XY_FULL_MONO_PATTERN_MONO_SRC_BLT        OP_2D(0x58)\n#define OP_XY_MONO_PAT_FIXED_BLT                    OP_2D(0x59)\n#define OP_XY_MONO_SRC_COPY_IMMEDIATE_BLT           OP_2D(0x71)\n#define OP_XY_PAT_BLT_IMMEDIATE                     OP_2D(0x72)\n#define OP_XY_SRC_COPY_CHROMA_BLT                   OP_2D(0x73)\n#define OP_XY_FULL_IMMEDIATE_PATTERN_BLT            OP_2D(0x74)\n#define OP_XY_FULL_MONO_SRC_IMMEDIATE_PATTERN_BLT   OP_2D(0x75)\n#define OP_XY_PAT_CHROMA_BLT                        OP_2D(0x76)\n#define OP_XY_PAT_CHROMA_BLT_IMMEDIATE              OP_2D(0x77)\n\n \n#define OP_3D_MEDIA(sub_type, opcode, sub_opcode) \\\n\t((3 << 13) | ((sub_type) << 11) | ((opcode) << 8) | (sub_opcode))\n\n#define OP_STATE_PREFETCH                       OP_3D_MEDIA(0x0, 0x0, 0x03)\n\n#define OP_STATE_BASE_ADDRESS                   OP_3D_MEDIA(0x0, 0x1, 0x01)\n#define OP_STATE_SIP                            OP_3D_MEDIA(0x0, 0x1, 0x02)\n#define OP_3D_MEDIA_0_1_4\t\t\tOP_3D_MEDIA(0x0, 0x1, 0x04)\n#define OP_SWTESS_BASE_ADDRESS\t\t\tOP_3D_MEDIA(0x0, 0x1, 0x03)\n\n#define OP_3DSTATE_VF_STATISTICS_GM45           OP_3D_MEDIA(0x1, 0x0, 0x0B)\n\n#define OP_PIPELINE_SELECT                      OP_3D_MEDIA(0x1, 0x1, 0x04)\n\n#define OP_MEDIA_VFE_STATE                      OP_3D_MEDIA(0x2, 0x0, 0x0)\n#define OP_MEDIA_CURBE_LOAD                     OP_3D_MEDIA(0x2, 0x0, 0x1)\n#define OP_MEDIA_INTERFACE_DESCRIPTOR_LOAD      OP_3D_MEDIA(0x2, 0x0, 0x2)\n#define OP_MEDIA_GATEWAY_STATE                  OP_3D_MEDIA(0x2, 0x0, 0x3)\n#define OP_MEDIA_STATE_FLUSH                    OP_3D_MEDIA(0x2, 0x0, 0x4)\n#define OP_MEDIA_POOL_STATE                     OP_3D_MEDIA(0x2, 0x0, 0x5)\n\n#define OP_MEDIA_OBJECT                         OP_3D_MEDIA(0x2, 0x1, 0x0)\n#define OP_MEDIA_OBJECT_PRT                     OP_3D_MEDIA(0x2, 0x1, 0x2)\n#define OP_MEDIA_OBJECT_WALKER                  OP_3D_MEDIA(0x2, 0x1, 0x3)\n#define OP_GPGPU_WALKER                         OP_3D_MEDIA(0x2, 0x1, 0x5)\n\n#define OP_3DSTATE_CLEAR_PARAMS                 OP_3D_MEDIA(0x3, 0x0, 0x04)  \n#define OP_3DSTATE_DEPTH_BUFFER                 OP_3D_MEDIA(0x3, 0x0, 0x05)  \n#define OP_3DSTATE_STENCIL_BUFFER               OP_3D_MEDIA(0x3, 0x0, 0x06)  \n#define OP_3DSTATE_HIER_DEPTH_BUFFER            OP_3D_MEDIA(0x3, 0x0, 0x07)  \n#define OP_3DSTATE_VERTEX_BUFFERS               OP_3D_MEDIA(0x3, 0x0, 0x08)\n#define OP_3DSTATE_VERTEX_ELEMENTS              OP_3D_MEDIA(0x3, 0x0, 0x09)\n#define OP_3DSTATE_INDEX_BUFFER                 OP_3D_MEDIA(0x3, 0x0, 0x0A)\n#define OP_3DSTATE_VF_STATISTICS                OP_3D_MEDIA(0x3, 0x0, 0x0B)\n#define OP_3DSTATE_VF                           OP_3D_MEDIA(0x3, 0x0, 0x0C)   \n#define OP_3DSTATE_CC_STATE_POINTERS            OP_3D_MEDIA(0x3, 0x0, 0x0E)\n#define OP_3DSTATE_SCISSOR_STATE_POINTERS       OP_3D_MEDIA(0x3, 0x0, 0x0F)\n#define OP_3DSTATE_VS                           OP_3D_MEDIA(0x3, 0x0, 0x10)\n#define OP_3DSTATE_GS                           OP_3D_MEDIA(0x3, 0x0, 0x11)\n#define OP_3DSTATE_CLIP                         OP_3D_MEDIA(0x3, 0x0, 0x12)\n#define OP_3DSTATE_SF                           OP_3D_MEDIA(0x3, 0x0, 0x13)\n#define OP_3DSTATE_WM                           OP_3D_MEDIA(0x3, 0x0, 0x14)\n#define OP_3DSTATE_CONSTANT_VS                  OP_3D_MEDIA(0x3, 0x0, 0x15)\n#define OP_3DSTATE_CONSTANT_GS                  OP_3D_MEDIA(0x3, 0x0, 0x16)\n#define OP_3DSTATE_CONSTANT_PS                  OP_3D_MEDIA(0x3, 0x0, 0x17)\n#define OP_3DSTATE_SAMPLE_MASK                  OP_3D_MEDIA(0x3, 0x0, 0x18)\n#define OP_3DSTATE_CONSTANT_HS                  OP_3D_MEDIA(0x3, 0x0, 0x19)  \n#define OP_3DSTATE_CONSTANT_DS                  OP_3D_MEDIA(0x3, 0x0, 0x1A)  \n#define OP_3DSTATE_HS                           OP_3D_MEDIA(0x3, 0x0, 0x1B)  \n#define OP_3DSTATE_TE                           OP_3D_MEDIA(0x3, 0x0, 0x1C)  \n#define OP_3DSTATE_DS                           OP_3D_MEDIA(0x3, 0x0, 0x1D)  \n#define OP_3DSTATE_STREAMOUT                    OP_3D_MEDIA(0x3, 0x0, 0x1E)  \n#define OP_3DSTATE_SBE                          OP_3D_MEDIA(0x3, 0x0, 0x1F)  \n#define OP_3DSTATE_PS                           OP_3D_MEDIA(0x3, 0x0, 0x20)  \n#define OP_3DSTATE_VIEWPORT_STATE_POINTERS_SF_CLIP OP_3D_MEDIA(0x3, 0x0, 0x21)  \n#define OP_3DSTATE_VIEWPORT_STATE_POINTERS_CC   OP_3D_MEDIA(0x3, 0x0, 0x23)  \n#define OP_3DSTATE_BLEND_STATE_POINTERS         OP_3D_MEDIA(0x3, 0x0, 0x24)  \n#define OP_3DSTATE_DEPTH_STENCIL_STATE_POINTERS OP_3D_MEDIA(0x3, 0x0, 0x25)  \n#define OP_3DSTATE_BINDING_TABLE_POINTERS_VS    OP_3D_MEDIA(0x3, 0x0, 0x26)  \n#define OP_3DSTATE_BINDING_TABLE_POINTERS_HS    OP_3D_MEDIA(0x3, 0x0, 0x27)  \n#define OP_3DSTATE_BINDING_TABLE_POINTERS_DS    OP_3D_MEDIA(0x3, 0x0, 0x28)  \n#define OP_3DSTATE_BINDING_TABLE_POINTERS_GS    OP_3D_MEDIA(0x3, 0x0, 0x29)  \n#define OP_3DSTATE_BINDING_TABLE_POINTERS_PS    OP_3D_MEDIA(0x3, 0x0, 0x2A)  \n#define OP_3DSTATE_SAMPLER_STATE_POINTERS_VS    OP_3D_MEDIA(0x3, 0x0, 0x2B)  \n#define OP_3DSTATE_SAMPLER_STATE_POINTERS_HS    OP_3D_MEDIA(0x3, 0x0, 0x2C)  \n#define OP_3DSTATE_SAMPLER_STATE_POINTERS_DS    OP_3D_MEDIA(0x3, 0x0, 0x2D)  \n#define OP_3DSTATE_SAMPLER_STATE_POINTERS_GS    OP_3D_MEDIA(0x3, 0x0, 0x2E)  \n#define OP_3DSTATE_SAMPLER_STATE_POINTERS_PS    OP_3D_MEDIA(0x3, 0x0, 0x2F)  \n#define OP_3DSTATE_URB_VS                       OP_3D_MEDIA(0x3, 0x0, 0x30)  \n#define OP_3DSTATE_URB_HS                       OP_3D_MEDIA(0x3, 0x0, 0x31)  \n#define OP_3DSTATE_URB_DS                       OP_3D_MEDIA(0x3, 0x0, 0x32)  \n#define OP_3DSTATE_URB_GS                       OP_3D_MEDIA(0x3, 0x0, 0x33)  \n#define OP_3DSTATE_GATHER_CONSTANT_VS           OP_3D_MEDIA(0x3, 0x0, 0x34)  \n#define OP_3DSTATE_GATHER_CONSTANT_GS           OP_3D_MEDIA(0x3, 0x0, 0x35)  \n#define OP_3DSTATE_GATHER_CONSTANT_HS           OP_3D_MEDIA(0x3, 0x0, 0x36)  \n#define OP_3DSTATE_GATHER_CONSTANT_DS           OP_3D_MEDIA(0x3, 0x0, 0x37)  \n#define OP_3DSTATE_GATHER_CONSTANT_PS           OP_3D_MEDIA(0x3, 0x0, 0x38)  \n#define OP_3DSTATE_DX9_CONSTANTF_VS             OP_3D_MEDIA(0x3, 0x0, 0x39)  \n#define OP_3DSTATE_DX9_CONSTANTF_PS             OP_3D_MEDIA(0x3, 0x0, 0x3A)  \n#define OP_3DSTATE_DX9_CONSTANTI_VS             OP_3D_MEDIA(0x3, 0x0, 0x3B)  \n#define OP_3DSTATE_DX9_CONSTANTI_PS             OP_3D_MEDIA(0x3, 0x0, 0x3C)  \n#define OP_3DSTATE_DX9_CONSTANTB_VS             OP_3D_MEDIA(0x3, 0x0, 0x3D)  \n#define OP_3DSTATE_DX9_CONSTANTB_PS             OP_3D_MEDIA(0x3, 0x0, 0x3E)  \n#define OP_3DSTATE_DX9_LOCAL_VALID_VS           OP_3D_MEDIA(0x3, 0x0, 0x3F)  \n#define OP_3DSTATE_DX9_LOCAL_VALID_PS           OP_3D_MEDIA(0x3, 0x0, 0x40)  \n#define OP_3DSTATE_DX9_GENERATE_ACTIVE_VS       OP_3D_MEDIA(0x3, 0x0, 0x41)  \n#define OP_3DSTATE_DX9_GENERATE_ACTIVE_PS       OP_3D_MEDIA(0x3, 0x0, 0x42)  \n#define OP_3DSTATE_BINDING_TABLE_EDIT_VS        OP_3D_MEDIA(0x3, 0x0, 0x43)  \n#define OP_3DSTATE_BINDING_TABLE_EDIT_GS        OP_3D_MEDIA(0x3, 0x0, 0x44)  \n#define OP_3DSTATE_BINDING_TABLE_EDIT_HS        OP_3D_MEDIA(0x3, 0x0, 0x45)  \n#define OP_3DSTATE_BINDING_TABLE_EDIT_DS        OP_3D_MEDIA(0x3, 0x0, 0x46)  \n#define OP_3DSTATE_BINDING_TABLE_EDIT_PS        OP_3D_MEDIA(0x3, 0x0, 0x47)  \n\n#define OP_3DSTATE_VF_INSTANCING \t\tOP_3D_MEDIA(0x3, 0x0, 0x49)  \n#define OP_3DSTATE_VF_SGVS  \t\t\tOP_3D_MEDIA(0x3, 0x0, 0x4A)  \n#define OP_3DSTATE_VF_TOPOLOGY   \t\tOP_3D_MEDIA(0x3, 0x0, 0x4B)  \n#define OP_3DSTATE_WM_CHROMAKEY   \t\tOP_3D_MEDIA(0x3, 0x0, 0x4C)  \n#define OP_3DSTATE_PS_BLEND   \t\t\tOP_3D_MEDIA(0x3, 0x0, 0x4D)  \n#define OP_3DSTATE_WM_DEPTH_STENCIL   \t\tOP_3D_MEDIA(0x3, 0x0, 0x4E)  \n#define OP_3DSTATE_PS_EXTRA   \t\t\tOP_3D_MEDIA(0x3, 0x0, 0x4F)  \n#define OP_3DSTATE_RASTER   \t\t\tOP_3D_MEDIA(0x3, 0x0, 0x50)  \n#define OP_3DSTATE_SBE_SWIZ   \t\t\tOP_3D_MEDIA(0x3, 0x0, 0x51)  \n#define OP_3DSTATE_WM_HZ_OP   \t\t\tOP_3D_MEDIA(0x3, 0x0, 0x52)  \n#define OP_3DSTATE_COMPONENT_PACKING\t\tOP_3D_MEDIA(0x3, 0x0, 0x55)  \n\n#define OP_3DSTATE_DRAWING_RECTANGLE            OP_3D_MEDIA(0x3, 0x1, 0x00)\n#define OP_3DSTATE_SAMPLER_PALETTE_LOAD0        OP_3D_MEDIA(0x3, 0x1, 0x02)\n#define OP_3DSTATE_CHROMA_KEY                   OP_3D_MEDIA(0x3, 0x1, 0x04)\n#define OP_SNB_3DSTATE_DEPTH_BUFFER             OP_3D_MEDIA(0x3, 0x1, 0x05)\n#define OP_3DSTATE_POLY_STIPPLE_OFFSET          OP_3D_MEDIA(0x3, 0x1, 0x06)\n#define OP_3DSTATE_POLY_STIPPLE_PATTERN         OP_3D_MEDIA(0x3, 0x1, 0x07)\n#define OP_3DSTATE_LINE_STIPPLE                 OP_3D_MEDIA(0x3, 0x1, 0x08)\n#define OP_3DSTATE_AA_LINE_PARAMS               OP_3D_MEDIA(0x3, 0x1, 0x0A)\n#define OP_3DSTATE_GS_SVB_INDEX                 OP_3D_MEDIA(0x3, 0x1, 0x0B)\n#define OP_3DSTATE_SAMPLER_PALETTE_LOAD1        OP_3D_MEDIA(0x3, 0x1, 0x0C)\n#define OP_3DSTATE_MULTISAMPLE_BDW\t\tOP_3D_MEDIA(0x3, 0x0, 0x0D)\n#define OP_SNB_3DSTATE_STENCIL_BUFFER           OP_3D_MEDIA(0x3, 0x1, 0x0E)\n#define OP_SNB_3DSTATE_HIER_DEPTH_BUFFER        OP_3D_MEDIA(0x3, 0x1, 0x0F)\n#define OP_SNB_3DSTATE_CLEAR_PARAMS             OP_3D_MEDIA(0x3, 0x1, 0x10)\n#define OP_3DSTATE_MONOFILTER_SIZE              OP_3D_MEDIA(0x3, 0x1, 0x11)\n#define OP_3DSTATE_PUSH_CONSTANT_ALLOC_VS       OP_3D_MEDIA(0x3, 0x1, 0x12)  \n#define OP_3DSTATE_PUSH_CONSTANT_ALLOC_HS       OP_3D_MEDIA(0x3, 0x1, 0x13)  \n#define OP_3DSTATE_PUSH_CONSTANT_ALLOC_DS       OP_3D_MEDIA(0x3, 0x1, 0x14)  \n#define OP_3DSTATE_PUSH_CONSTANT_ALLOC_GS       OP_3D_MEDIA(0x3, 0x1, 0x15)  \n#define OP_3DSTATE_PUSH_CONSTANT_ALLOC_PS       OP_3D_MEDIA(0x3, 0x1, 0x16)  \n#define OP_3DSTATE_SO_DECL_LIST                 OP_3D_MEDIA(0x3, 0x1, 0x17)\n#define OP_3DSTATE_SO_BUFFER                    OP_3D_MEDIA(0x3, 0x1, 0x18)\n#define OP_3DSTATE_BINDING_TABLE_POOL_ALLOC     OP_3D_MEDIA(0x3, 0x1, 0x19)  \n#define OP_3DSTATE_GATHER_POOL_ALLOC            OP_3D_MEDIA(0x3, 0x1, 0x1A)  \n#define OP_3DSTATE_DX9_CONSTANT_BUFFER_POOL_ALLOC OP_3D_MEDIA(0x3, 0x1, 0x1B)  \n#define OP_3DSTATE_SAMPLE_PATTERN               OP_3D_MEDIA(0x3, 0x1, 0x1C)\n#define OP_PIPE_CONTROL                         OP_3D_MEDIA(0x3, 0x2, 0x00)\n#define OP_3DPRIMITIVE                          OP_3D_MEDIA(0x3, 0x3, 0x00)\n\n \n\n \n\n#define OP_MFX(pipeline, op, sub_opa, sub_opb)     \\\n\t(3 << 13 | \\\n\t (pipeline) << 11 | \\\n\t (op) << 8 | \\\n\t (sub_opa) << 5 | \\\n\t (sub_opb))\n\n#define OP_MFX_PIPE_MODE_SELECT                    OP_MFX(2, 0, 0, 0)   \n#define OP_MFX_SURFACE_STATE                       OP_MFX(2, 0, 0, 1)   \n#define OP_MFX_PIPE_BUF_ADDR_STATE                 OP_MFX(2, 0, 0, 2)   \n#define OP_MFX_IND_OBJ_BASE_ADDR_STATE             OP_MFX(2, 0, 0, 3)   \n#define OP_MFX_BSP_BUF_BASE_ADDR_STATE             OP_MFX(2, 0, 0, 4)   \n#define OP_2_0_0_5                                 OP_MFX(2, 0, 0, 5)   \n#define OP_MFX_STATE_POINTER                       OP_MFX(2, 0, 0, 6)   \n#define OP_MFX_QM_STATE                            OP_MFX(2, 0, 0, 7)   \n#define OP_MFX_FQM_STATE                           OP_MFX(2, 0, 0, 8)   \n#define OP_MFX_PAK_INSERT_OBJECT                   OP_MFX(2, 0, 2, 8)   \n#define OP_MFX_STITCH_OBJECT                       OP_MFX(2, 0, 2, 0xA)   \n\n#define OP_MFD_IT_OBJECT                           OP_MFX(2, 0, 1, 9)  \n\n#define OP_MFX_WAIT                                OP_MFX(1, 0, 0, 0)  \n#define OP_MFX_AVC_IMG_STATE                       OP_MFX(2, 1, 0, 0)  \n#define OP_MFX_AVC_QM_STATE                        OP_MFX(2, 1, 0, 1)  \n#define OP_MFX_AVC_DIRECTMODE_STATE                OP_MFX(2, 1, 0, 2)  \n#define OP_MFX_AVC_SLICE_STATE                     OP_MFX(2, 1, 0, 3)  \n#define OP_MFX_AVC_REF_IDX_STATE                   OP_MFX(2, 1, 0, 4)  \n#define OP_MFX_AVC_WEIGHTOFFSET_STATE              OP_MFX(2, 1, 0, 5)  \n#define OP_MFD_AVC_PICID_STATE                     OP_MFX(2, 1, 1, 5)  \n#define OP_MFD_AVC_DPB_STATE\t\t\t   OP_MFX(2, 1, 1, 6)  \n#define OP_MFD_AVC_SLICEADDR                       OP_MFX(2, 1, 1, 7)  \n#define OP_MFD_AVC_BSD_OBJECT                      OP_MFX(2, 1, 1, 8)  \n#define OP_MFC_AVC_PAK_OBJECT                      OP_MFX(2, 1, 2, 9)  \n\n#define OP_MFX_VC1_PRED_PIPE_STATE                 OP_MFX(2, 2, 0, 1)  \n#define OP_MFX_VC1_DIRECTMODE_STATE                OP_MFX(2, 2, 0, 2)  \n#define OP_MFD_VC1_SHORT_PIC_STATE                 OP_MFX(2, 2, 1, 0)  \n#define OP_MFD_VC1_LONG_PIC_STATE                  OP_MFX(2, 2, 1, 1)  \n#define OP_MFD_VC1_BSD_OBJECT                      OP_MFX(2, 2, 1, 8)  \n\n#define OP_MFX_MPEG2_PIC_STATE                     OP_MFX(2, 3, 0, 0)  \n#define OP_MFX_MPEG2_QM_STATE                      OP_MFX(2, 3, 0, 1)  \n#define OP_MFD_MPEG2_BSD_OBJECT                    OP_MFX(2, 3, 1, 8)  \n#define OP_MFC_MPEG2_SLICEGROUP_STATE              OP_MFX(2, 3, 2, 3)  \n#define OP_MFC_MPEG2_PAK_OBJECT                    OP_MFX(2, 3, 2, 9)  \n\n#define OP_MFX_2_6_0_0                             OP_MFX(2, 6, 0, 0)  \n#define OP_MFX_2_6_0_8                             OP_MFX(2, 6, 0, 8)  \n#define OP_MFX_2_6_0_9                             OP_MFX(2, 6, 0, 9)  \n\n#define OP_MFX_JPEG_PIC_STATE                      OP_MFX(2, 7, 0, 0)\n#define OP_MFX_JPEG_HUFF_TABLE_STATE               OP_MFX(2, 7, 0, 2)\n#define OP_MFD_JPEG_BSD_OBJECT                     OP_MFX(2, 7, 1, 8)\n\n#define OP_VEB(pipeline, op, sub_opa, sub_opb) \\\n\t(3 << 13 | \\\n\t (pipeline) << 11 | \\\n\t (op) << 8 | \\\n\t (sub_opa) << 5 | \\\n\t (sub_opb))\n\n#define OP_VEB_SURFACE_STATE                       OP_VEB(2, 4, 0, 0)\n#define OP_VEB_STATE                               OP_VEB(2, 4, 0, 2)\n#define OP_VEB_DNDI_IECP_STATE                     OP_VEB(2, 4, 0, 3)\n\nstruct parser_exec_state;\n\ntypedef int (*parser_cmd_handler)(struct parser_exec_state *s);\n\n#define GVT_CMD_HASH_BITS   7\n\n \n#define ADDR_FIX_1(x1)\t\t\t(1 << (x1))\n#define ADDR_FIX_2(x1, x2)\t\t(ADDR_FIX_1(x1) | ADDR_FIX_1(x2))\n#define ADDR_FIX_3(x1, x2, x3)\t\t(ADDR_FIX_1(x1) | ADDR_FIX_2(x2, x3))\n#define ADDR_FIX_4(x1, x2, x3, x4)\t(ADDR_FIX_1(x1) | ADDR_FIX_3(x2, x3, x4))\n#define ADDR_FIX_5(x1, x2, x3, x4, x5)  (ADDR_FIX_1(x1) | ADDR_FIX_4(x2, x3, x4, x5))\n\n#define DWORD_FIELD(dword, end, start) \\\n\tFIELD_GET(GENMASK(end, start), cmd_val(s, dword))\n\n#define OP_LENGTH_BIAS 2\n#define CMD_LEN(value)  (value + OP_LENGTH_BIAS)\n\nstatic int gvt_check_valid_cmd_length(int len, int valid_len)\n{\n\tif (valid_len != len) {\n\t\tgvt_err(\"len is not valid:  len=%u  valid_len=%u\\n\",\n\t\t\tlen, valid_len);\n\t\treturn -EFAULT;\n\t}\n\treturn 0;\n}\n\nstruct cmd_info {\n\tconst char *name;\n\tu32 opcode;\n\n#define F_LEN_MASK\t3U\n#define F_LEN_CONST  1U\n#define F_LEN_VAR    0U\n \n#define F_LEN_VAR_FIXED    (1<<1)\n\n \n#define F_IP_ADVANCE_CUSTOM (1<<2)\n\tu32 flag;\n\n#define R_RCS\tBIT(RCS0)\n#define R_VCS1  BIT(VCS0)\n#define R_VCS2  BIT(VCS1)\n#define R_VCS\t(R_VCS1 | R_VCS2)\n#define R_BCS\tBIT(BCS0)\n#define R_VECS\tBIT(VECS0)\n#define R_ALL (R_RCS | R_VCS | R_BCS | R_VECS)\n\t \n\tintel_engine_mask_t rings;\n\n\t \n\tu16 devices;\n\n\t \n\tu16 addr_bitmap;\n\n\t \n\tu32 len;\n\n\tparser_cmd_handler handler;\n\n\t \n\tu32 valid_len;\n};\n\nstruct cmd_entry {\n\tstruct hlist_node hlist;\n\tconst struct cmd_info *info;\n};\n\nenum {\n\tRING_BUFFER_INSTRUCTION,\n\tBATCH_BUFFER_INSTRUCTION,\n\tBATCH_BUFFER_2ND_LEVEL,\n\tRING_BUFFER_CTX,\n};\n\nenum {\n\tGTT_BUFFER,\n\tPPGTT_BUFFER\n};\n\nstruct parser_exec_state {\n\tstruct intel_vgpu *vgpu;\n\tconst struct intel_engine_cs *engine;\n\n\tint buf_type;\n\n\t \n\tint buf_addr_type;\n\n\t \n\tunsigned long ring_start;\n\tunsigned long ring_size;\n\tunsigned long ring_head;\n\tunsigned long ring_tail;\n\n\t \n\tunsigned long ip_gma;\n\n\t \n\tvoid *ip_va;\n\tvoid *rb_va;\n\n\tvoid *ret_bb_va;\n\t \n\tunsigned long ret_ip_gma_ring;\n\n\t \n\tunsigned long ret_ip_gma_bb;\n\n\t \n\tint saved_buf_addr_type;\n\tbool is_ctx_wa;\n\tbool is_init_ctx;\n\n\tconst struct cmd_info *info;\n\n\tstruct intel_vgpu_workload *workload;\n};\n\n#define gmadr_dw_number(s)\t\\\n\t(s->vgpu->gvt->device_info.gmadr_bytes_in_cmd >> 2)\n\nstatic unsigned long bypass_scan_mask = 0;\n\n \nstatic const struct sub_op_bits sub_op_mi[] = {\n\t{31, 29},\n\t{28, 23},\n};\n\nstatic const struct decode_info decode_info_mi = {\n\t\"MI\",\n\tOP_LEN_MI,\n\tARRAY_SIZE(sub_op_mi),\n\tsub_op_mi,\n};\n\n \nstatic const struct sub_op_bits sub_op_2d[] = {\n\t{31, 29},\n\t{28, 22},\n};\n\nstatic const struct decode_info decode_info_2d = {\n\t\"2D\",\n\tOP_LEN_2D,\n\tARRAY_SIZE(sub_op_2d),\n\tsub_op_2d,\n};\n\n \nstatic const struct sub_op_bits sub_op_3d_media[] = {\n\t{31, 29},\n\t{28, 27},\n\t{26, 24},\n\t{23, 16},\n};\n\nstatic const struct decode_info decode_info_3d_media = {\n\t\"3D_Media\",\n\tOP_LEN_3D_MEDIA,\n\tARRAY_SIZE(sub_op_3d_media),\n\tsub_op_3d_media,\n};\n\n \nstatic const struct sub_op_bits sub_op_mfx_vc[] = {\n\t{31, 29},\n\t{28, 27},\n\t{26, 24},\n\t{23, 21},\n\t{20, 16},\n};\n\nstatic const struct decode_info decode_info_mfx_vc = {\n\t\"MFX_VC\",\n\tOP_LEN_MFX_VC,\n\tARRAY_SIZE(sub_op_mfx_vc),\n\tsub_op_mfx_vc,\n};\n\n \nstatic const struct sub_op_bits sub_op_vebox[] = {\n\t{31, 29},\n\t{28, 27},\n\t{26, 24},\n\t{23, 21},\n\t{20, 16},\n};\n\nstatic const struct decode_info decode_info_vebox = {\n\t\"VEBOX\",\n\tOP_LEN_VEBOX,\n\tARRAY_SIZE(sub_op_vebox),\n\tsub_op_vebox,\n};\n\nstatic const struct decode_info *ring_decode_info[I915_NUM_ENGINES][8] = {\n\t[RCS0] = {\n\t\t&decode_info_mi,\n\t\tNULL,\n\t\tNULL,\n\t\t&decode_info_3d_media,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t},\n\n\t[VCS0] = {\n\t\t&decode_info_mi,\n\t\tNULL,\n\t\tNULL,\n\t\t&decode_info_mfx_vc,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t},\n\n\t[BCS0] = {\n\t\t&decode_info_mi,\n\t\tNULL,\n\t\t&decode_info_2d,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t},\n\n\t[VECS0] = {\n\t\t&decode_info_mi,\n\t\tNULL,\n\t\tNULL,\n\t\t&decode_info_vebox,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t},\n\n\t[VCS1] = {\n\t\t&decode_info_mi,\n\t\tNULL,\n\t\tNULL,\n\t\t&decode_info_mfx_vc,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t\tNULL,\n\t},\n};\n\nstatic inline u32 get_opcode(u32 cmd, const struct intel_engine_cs *engine)\n{\n\tconst struct decode_info *d_info;\n\n\td_info = ring_decode_info[engine->id][CMD_TYPE(cmd)];\n\tif (d_info == NULL)\n\t\treturn INVALID_OP;\n\n\treturn cmd >> (32 - d_info->op_len);\n}\n\nstatic inline const struct cmd_info *\nfind_cmd_entry(struct intel_gvt *gvt, unsigned int opcode,\n\t       const struct intel_engine_cs *engine)\n{\n\tstruct cmd_entry *e;\n\n\thash_for_each_possible(gvt->cmd_table, e, hlist, opcode) {\n\t\tif (opcode == e->info->opcode &&\n\t\t    e->info->rings & engine->mask)\n\t\t\treturn e->info;\n\t}\n\treturn NULL;\n}\n\nstatic inline const struct cmd_info *\nget_cmd_info(struct intel_gvt *gvt, u32 cmd,\n\t     const struct intel_engine_cs *engine)\n{\n\tu32 opcode;\n\n\topcode = get_opcode(cmd, engine);\n\tif (opcode == INVALID_OP)\n\t\treturn NULL;\n\n\treturn find_cmd_entry(gvt, opcode, engine);\n}\n\nstatic inline u32 sub_op_val(u32 cmd, u32 hi, u32 low)\n{\n\treturn (cmd >> low) & ((1U << (hi - low + 1)) - 1);\n}\n\nstatic inline void print_opcode(u32 cmd, const struct intel_engine_cs *engine)\n{\n\tconst struct decode_info *d_info;\n\tint i;\n\n\td_info = ring_decode_info[engine->id][CMD_TYPE(cmd)];\n\tif (d_info == NULL)\n\t\treturn;\n\n\tgvt_dbg_cmd(\"opcode=0x%x %s sub_ops:\",\n\t\t\tcmd >> (32 - d_info->op_len), d_info->name);\n\n\tfor (i = 0; i < d_info->nr_sub_op; i++)\n\t\tpr_err(\"0x%x \", sub_op_val(cmd, d_info->sub_op[i].hi,\n\t\t\t\t\td_info->sub_op[i].low));\n\n\tpr_err(\"\\n\");\n}\n\nstatic inline u32 *cmd_ptr(struct parser_exec_state *s, int index)\n{\n\treturn s->ip_va + (index << 2);\n}\n\nstatic inline u32 cmd_val(struct parser_exec_state *s, int index)\n{\n\treturn *cmd_ptr(s, index);\n}\n\nstatic inline bool is_init_ctx(struct parser_exec_state *s)\n{\n\treturn (s->buf_type == RING_BUFFER_CTX && s->is_init_ctx);\n}\n\nstatic void parser_exec_state_dump(struct parser_exec_state *s)\n{\n\tint cnt = 0;\n\tint i;\n\n\tgvt_dbg_cmd(\"  vgpu%d RING%s: ring_start(%08lx) ring_end(%08lx)\"\n\t\t    \" ring_head(%08lx) ring_tail(%08lx)\\n\",\n\t\t    s->vgpu->id, s->engine->name,\n\t\t    s->ring_start, s->ring_start + s->ring_size,\n\t\t    s->ring_head, s->ring_tail);\n\n\tgvt_dbg_cmd(\"  %s %s ip_gma(%08lx) \",\n\t\t\ts->buf_type == RING_BUFFER_INSTRUCTION ?\n\t\t\t\"RING_BUFFER\" : ((s->buf_type == RING_BUFFER_CTX) ?\n\t\t\t\t\"CTX_BUFFER\" : \"BATCH_BUFFER\"),\n\t\t\ts->buf_addr_type == GTT_BUFFER ?\n\t\t\t\"GTT\" : \"PPGTT\", s->ip_gma);\n\n\tif (s->ip_va == NULL) {\n\t\tgvt_dbg_cmd(\" ip_va(NULL)\");\n\t\treturn;\n\t}\n\n\tgvt_dbg_cmd(\"  ip_va=%p: %08x %08x %08x %08x\\n\",\n\t\t\ts->ip_va, cmd_val(s, 0), cmd_val(s, 1),\n\t\t\tcmd_val(s, 2), cmd_val(s, 3));\n\n\tprint_opcode(cmd_val(s, 0), s->engine);\n\n\ts->ip_va = (u32 *)((((u64)s->ip_va) >> 12) << 12);\n\n\twhile (cnt < 1024) {\n\t\tgvt_dbg_cmd(\"ip_va=%p: \", s->ip_va);\n\t\tfor (i = 0; i < 8; i++)\n\t\t\tgvt_dbg_cmd(\"%08x \", cmd_val(s, i));\n\t\tgvt_dbg_cmd(\"\\n\");\n\n\t\ts->ip_va += 8 * sizeof(u32);\n\t\tcnt += 8;\n\t}\n}\n\nstatic inline void update_ip_va(struct parser_exec_state *s)\n{\n\tunsigned long len = 0;\n\n\tif (WARN_ON(s->ring_head == s->ring_tail))\n\t\treturn;\n\n\tif (s->buf_type == RING_BUFFER_INSTRUCTION ||\n\t\t\ts->buf_type == RING_BUFFER_CTX) {\n\t\tunsigned long ring_top = s->ring_start + s->ring_size;\n\n\t\tif (s->ring_head > s->ring_tail) {\n\t\t\tif (s->ip_gma >= s->ring_head && s->ip_gma < ring_top)\n\t\t\t\tlen = (s->ip_gma - s->ring_head);\n\t\t\telse if (s->ip_gma >= s->ring_start &&\n\t\t\t\t\ts->ip_gma <= s->ring_tail)\n\t\t\t\tlen = (ring_top - s->ring_head) +\n\t\t\t\t\t(s->ip_gma - s->ring_start);\n\t\t} else\n\t\t\tlen = (s->ip_gma - s->ring_head);\n\n\t\ts->ip_va = s->rb_va + len;\n\t} else { \n\t\ts->ip_va = s->ret_bb_va;\n\t}\n}\n\nstatic inline int ip_gma_set(struct parser_exec_state *s,\n\t\tunsigned long ip_gma)\n{\n\tWARN_ON(!IS_ALIGNED(ip_gma, 4));\n\n\ts->ip_gma = ip_gma;\n\tupdate_ip_va(s);\n\treturn 0;\n}\n\nstatic inline int ip_gma_advance(struct parser_exec_state *s,\n\t\tunsigned int dw_len)\n{\n\ts->ip_gma += (dw_len << 2);\n\n\tif (s->buf_type == RING_BUFFER_INSTRUCTION) {\n\t\tif (s->ip_gma >= s->ring_start + s->ring_size)\n\t\t\ts->ip_gma -= s->ring_size;\n\t\tupdate_ip_va(s);\n\t} else {\n\t\ts->ip_va += (dw_len << 2);\n\t}\n\n\treturn 0;\n}\n\nstatic inline int get_cmd_length(const struct cmd_info *info, u32 cmd)\n{\n\tif ((info->flag & F_LEN_MASK) == F_LEN_CONST)\n\t\treturn info->len;\n\telse\n\t\treturn (cmd & ((1U << info->len) - 1)) + 2;\n\treturn 0;\n}\n\nstatic inline int cmd_length(struct parser_exec_state *s)\n{\n\treturn get_cmd_length(s->info, cmd_val(s, 0));\n}\n\n \n#define patch_value(s, addr, val) do { \\\n\t*addr = val; \\\n} while (0)\n\nstatic inline bool is_mocs_mmio(unsigned int offset)\n{\n\treturn ((offset >= 0xc800) && (offset <= 0xcff8)) ||\n\t\t((offset >= 0xb020) && (offset <= 0xb0a0));\n}\n\nstatic int is_cmd_update_pdps(unsigned int offset,\n\t\t\t      struct parser_exec_state *s)\n{\n\tu32 base = s->workload->engine->mmio_base;\n\treturn i915_mmio_reg_equal(_MMIO(offset), GEN8_RING_PDP_UDW(base, 0));\n}\n\nstatic int cmd_pdp_mmio_update_handler(struct parser_exec_state *s,\n\t\t\t\t       unsigned int offset, unsigned int index)\n{\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tstruct intel_vgpu_mm *shadow_mm = s->workload->shadow_mm;\n\tstruct intel_vgpu_mm *mm;\n\tu64 pdps[GEN8_3LVL_PDPES];\n\n\tif (shadow_mm->ppgtt_mm.root_entry_type ==\n\t    GTT_TYPE_PPGTT_ROOT_L4_ENTRY) {\n\t\tpdps[0] = (u64)cmd_val(s, 2) << 32;\n\t\tpdps[0] |= cmd_val(s, 4);\n\n\t\tmm = intel_vgpu_find_ppgtt_mm(vgpu, pdps);\n\t\tif (!mm) {\n\t\t\tgvt_vgpu_err(\"failed to get the 4-level shadow vm\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tintel_vgpu_mm_get(mm);\n\t\tlist_add_tail(&mm->ppgtt_mm.link,\n\t\t\t      &s->workload->lri_shadow_mm);\n\t\t*cmd_ptr(s, 2) = upper_32_bits(mm->ppgtt_mm.shadow_pdps[0]);\n\t\t*cmd_ptr(s, 4) = lower_32_bits(mm->ppgtt_mm.shadow_pdps[0]);\n\t} else {\n\t\t \n\t\tGEM_BUG_ON(1);\n\t\tgvt_vgpu_err(\"invalid shared shadow vm type\\n\");\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic int cmd_reg_handler(struct parser_exec_state *s,\n\tunsigned int offset, unsigned int index, char *cmd)\n{\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tstruct intel_gvt *gvt = vgpu->gvt;\n\tu32 ctx_sr_ctl;\n\tu32 *vreg, vreg_old;\n\n\tif (offset + 4 > gvt->device_info.mmio_size) {\n\t\tgvt_vgpu_err(\"%s access to (%x) outside of MMIO range\\n\",\n\t\t\t\tcmd, offset);\n\t\treturn -EFAULT;\n\t}\n\n\tif (is_init_ctx(s)) {\n\t\tstruct intel_gvt_mmio_info *mmio_info;\n\n\t\tintel_gvt_mmio_set_cmd_accessible(gvt, offset);\n\t\tmmio_info = intel_gvt_find_mmio_info(gvt, offset);\n\t\tif (mmio_info && mmio_info->write)\n\t\t\tintel_gvt_mmio_set_cmd_write_patch(gvt, offset);\n\t\treturn 0;\n\t}\n\n\tif (!intel_gvt_mmio_is_cmd_accessible(gvt, offset)) {\n\t\tgvt_vgpu_err(\"%s access to non-render register (%x)\\n\",\n\t\t\t\tcmd, offset);\n\t\treturn -EBADRQC;\n\t}\n\n\tif (!strncmp(cmd, \"srm\", 3) ||\n\t\t\t!strncmp(cmd, \"lrm\", 3)) {\n\t\tif (offset == i915_mmio_reg_offset(GEN8_L3SQCREG4) ||\n\t\t    offset == 0x21f0 ||\n\t\t    (IS_BROADWELL(gvt->gt->i915) &&\n\t\t     offset == i915_mmio_reg_offset(INSTPM)))\n\t\t\treturn 0;\n\t\telse {\n\t\t\tgvt_vgpu_err(\"%s access to register (%x)\\n\",\n\t\t\t\t\tcmd, offset);\n\t\t\treturn -EPERM;\n\t\t}\n\t}\n\n\tif (!strncmp(cmd, \"lrr-src\", 7) ||\n\t\t\t!strncmp(cmd, \"lrr-dst\", 7)) {\n\t\tif (IS_BROADWELL(gvt->gt->i915) && offset == 0x215c)\n\t\t\treturn 0;\n\t\telse {\n\t\t\tgvt_vgpu_err(\"not allowed cmd %s reg (%x)\\n\", cmd, offset);\n\t\t\treturn -EPERM;\n\t\t}\n\t}\n\n\tif (!strncmp(cmd, \"pipe_ctrl\", 9)) {\n\t\t \n\t\treturn 0;\n\t}\n\n\tif (strncmp(cmd, \"lri\", 3))\n\t\treturn -EPERM;\n\n\t \n\tvreg = &vgpu_vreg(s->vgpu, offset);\n\n\tif (is_cmd_update_pdps(offset, s) &&\n\t    cmd_pdp_mmio_update_handler(s, offset, index))\n\t\treturn -EINVAL;\n\n\tif (offset == i915_mmio_reg_offset(DERRMR) ||\n\t\toffset == i915_mmio_reg_offset(FORCEWAKE_MT)) {\n\t\t \n\t\tpatch_value(s, cmd_ptr(s, index), VGT_PVINFO_PAGE);\n\t}\n\n\tif (is_mocs_mmio(offset))\n\t\t*vreg = cmd_val(s, index + 1);\n\n\tvreg_old = *vreg;\n\n\tif (intel_gvt_mmio_is_cmd_write_patch(gvt, offset)) {\n\t\tu32 cmdval_new, cmdval;\n\t\tstruct intel_gvt_mmio_info *mmio_info;\n\n\t\tcmdval = cmd_val(s, index + 1);\n\n\t\tmmio_info = intel_gvt_find_mmio_info(gvt, offset);\n\t\tif (!mmio_info) {\n\t\t\tcmdval_new = cmdval;\n\t\t} else {\n\t\t\tu64 ro_mask = mmio_info->ro_mask;\n\t\t\tint ret;\n\n\t\t\tif (likely(!ro_mask))\n\t\t\t\tret = mmio_info->write(s->vgpu, offset,\n\t\t\t\t\t\t&cmdval, 4);\n\t\t\telse {\n\t\t\t\tgvt_vgpu_err(\"try to write RO reg %x\\n\",\n\t\t\t\t\t\toffset);\n\t\t\t\tret = -EBADRQC;\n\t\t\t}\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tcmdval_new = *vreg;\n\t\t}\n\t\tif (cmdval_new != cmdval)\n\t\t\tpatch_value(s, cmd_ptr(s, index+1), cmdval_new);\n\t}\n\n\t \n\t*vreg = vreg_old;\n\n\t \n\tif (GRAPHICS_VER(s->engine->i915) == 9 &&\n\t    intel_gvt_mmio_is_sr_in_ctx(gvt, offset) &&\n\t    !strncmp(cmd, \"lri\", 3)) {\n\t\tintel_gvt_read_gpa(s->vgpu,\n\t\t\ts->workload->ring_context_gpa + 12, &ctx_sr_ctl, 4);\n\t\t \n\t\tif (ctx_sr_ctl & 1) {\n\t\t\tu32 data = cmd_val(s, index + 1);\n\n\t\t\tif (intel_gvt_mmio_has_mode_mask(s->vgpu->gvt, offset))\n\t\t\t\tintel_vgpu_mask_mmio_write(vgpu,\n\t\t\t\t\t\t\toffset, &data, 4);\n\t\t\telse\n\t\t\t\tvgpu_vreg(vgpu, offset) = data;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n#define cmd_reg(s, i) \\\n\t(cmd_val(s, i) & GENMASK(22, 2))\n\n#define cmd_reg_inhibit(s, i) \\\n\t(cmd_val(s, i) & GENMASK(22, 18))\n\n#define cmd_gma(s, i) \\\n\t(cmd_val(s, i) & GENMASK(31, 2))\n\n#define cmd_gma_hi(s, i) \\\n\t(cmd_val(s, i) & GENMASK(15, 0))\n\nstatic int cmd_handler_lri(struct parser_exec_state *s)\n{\n\tint i, ret = 0;\n\tint cmd_len = cmd_length(s);\n\n\tfor (i = 1; i < cmd_len; i += 2) {\n\t\tif (IS_BROADWELL(s->engine->i915) && s->engine->id != RCS0) {\n\t\t\tif (s->engine->id == BCS0 &&\n\t\t\t    cmd_reg(s, i) == i915_mmio_reg_offset(DERRMR))\n\t\t\t\tret |= 0;\n\t\t\telse\n\t\t\t\tret |= cmd_reg_inhibit(s, i) ? -EBADRQC : 0;\n\t\t}\n\t\tif (ret)\n\t\t\tbreak;\n\t\tret |= cmd_reg_handler(s, cmd_reg(s, i), i, \"lri\");\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\nstatic int cmd_handler_lrr(struct parser_exec_state *s)\n{\n\tint i, ret = 0;\n\tint cmd_len = cmd_length(s);\n\n\tfor (i = 1; i < cmd_len; i += 2) {\n\t\tif (IS_BROADWELL(s->engine->i915))\n\t\t\tret |= ((cmd_reg_inhibit(s, i) ||\n\t\t\t\t (cmd_reg_inhibit(s, i + 1)))) ?\n\t\t\t\t-EBADRQC : 0;\n\t\tif (ret)\n\t\t\tbreak;\n\t\tret |= cmd_reg_handler(s, cmd_reg(s, i), i, \"lrr-src\");\n\t\tif (ret)\n\t\t\tbreak;\n\t\tret |= cmd_reg_handler(s, cmd_reg(s, i + 1), i, \"lrr-dst\");\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\treturn ret;\n}\n\nstatic inline int cmd_address_audit(struct parser_exec_state *s,\n\t\tunsigned long guest_gma, int op_size, bool index_mode);\n\nstatic int cmd_handler_lrm(struct parser_exec_state *s)\n{\n\tstruct intel_gvt *gvt = s->vgpu->gvt;\n\tint gmadr_bytes = gvt->device_info.gmadr_bytes_in_cmd;\n\tunsigned long gma;\n\tint i, ret = 0;\n\tint cmd_len = cmd_length(s);\n\n\tfor (i = 1; i < cmd_len;) {\n\t\tif (IS_BROADWELL(s->engine->i915))\n\t\t\tret |= (cmd_reg_inhibit(s, i)) ? -EBADRQC : 0;\n\t\tif (ret)\n\t\t\tbreak;\n\t\tret |= cmd_reg_handler(s, cmd_reg(s, i), i, \"lrm\");\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (cmd_val(s, 0) & (1 << 22)) {\n\t\t\tgma = cmd_gma(s, i + 1);\n\t\t\tif (gmadr_bytes == 8)\n\t\t\t\tgma |= (cmd_gma_hi(s, i + 2)) << 32;\n\t\t\tret |= cmd_address_audit(s, gma, sizeof(u32), false);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t\ti += gmadr_dw_number(s) + 1;\n\t}\n\treturn ret;\n}\n\nstatic int cmd_handler_srm(struct parser_exec_state *s)\n{\n\tint gmadr_bytes = s->vgpu->gvt->device_info.gmadr_bytes_in_cmd;\n\tunsigned long gma;\n\tint i, ret = 0;\n\tint cmd_len = cmd_length(s);\n\n\tfor (i = 1; i < cmd_len;) {\n\t\tret |= cmd_reg_handler(s, cmd_reg(s, i), i, \"srm\");\n\t\tif (ret)\n\t\t\tbreak;\n\t\tif (cmd_val(s, 0) & (1 << 22)) {\n\t\t\tgma = cmd_gma(s, i + 1);\n\t\t\tif (gmadr_bytes == 8)\n\t\t\t\tgma |= (cmd_gma_hi(s, i + 2)) << 32;\n\t\t\tret |= cmd_address_audit(s, gma, sizeof(u32), false);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t\ti += gmadr_dw_number(s) + 1;\n\t}\n\treturn ret;\n}\n\nstruct cmd_interrupt_event {\n\tint pipe_control_notify;\n\tint mi_flush_dw;\n\tint mi_user_interrupt;\n};\n\nstatic const struct cmd_interrupt_event cmd_interrupt_events[] = {\n\t[RCS0] = {\n\t\t.pipe_control_notify = RCS_PIPE_CONTROL,\n\t\t.mi_flush_dw = INTEL_GVT_EVENT_RESERVED,\n\t\t.mi_user_interrupt = RCS_MI_USER_INTERRUPT,\n\t},\n\t[BCS0] = {\n\t\t.pipe_control_notify = INTEL_GVT_EVENT_RESERVED,\n\t\t.mi_flush_dw = BCS_MI_FLUSH_DW,\n\t\t.mi_user_interrupt = BCS_MI_USER_INTERRUPT,\n\t},\n\t[VCS0] = {\n\t\t.pipe_control_notify = INTEL_GVT_EVENT_RESERVED,\n\t\t.mi_flush_dw = VCS_MI_FLUSH_DW,\n\t\t.mi_user_interrupt = VCS_MI_USER_INTERRUPT,\n\t},\n\t[VCS1] = {\n\t\t.pipe_control_notify = INTEL_GVT_EVENT_RESERVED,\n\t\t.mi_flush_dw = VCS2_MI_FLUSH_DW,\n\t\t.mi_user_interrupt = VCS2_MI_USER_INTERRUPT,\n\t},\n\t[VECS0] = {\n\t\t.pipe_control_notify = INTEL_GVT_EVENT_RESERVED,\n\t\t.mi_flush_dw = VECS_MI_FLUSH_DW,\n\t\t.mi_user_interrupt = VECS_MI_USER_INTERRUPT,\n\t},\n};\n\nstatic int cmd_handler_pipe_control(struct parser_exec_state *s)\n{\n\tint gmadr_bytes = s->vgpu->gvt->device_info.gmadr_bytes_in_cmd;\n\tunsigned long gma;\n\tbool index_mode = false;\n\tunsigned int post_sync;\n\tint ret = 0;\n\tu32 hws_pga, val;\n\n\tpost_sync = (cmd_val(s, 1) & PIPE_CONTROL_POST_SYNC_OP_MASK) >> 14;\n\n\t \n\tif (cmd_val(s, 1) & PIPE_CONTROL_MMIO_WRITE)\n\t\tret = cmd_reg_handler(s, cmd_reg(s, 2), 1, \"pipe_ctrl\");\n\t \n\telse if (post_sync) {\n\t\tif (post_sync == 2)\n\t\t\tret = cmd_reg_handler(s, 0x2350, 1, \"pipe_ctrl\");\n\t\telse if (post_sync == 3)\n\t\t\tret = cmd_reg_handler(s, 0x2358, 1, \"pipe_ctrl\");\n\t\telse if (post_sync == 1) {\n\t\t\t \n\t\t\tif ((cmd_val(s, 1) & PIPE_CONTROL_GLOBAL_GTT_IVB)) {\n\t\t\t\tgma = cmd_val(s, 2) & GENMASK(31, 3);\n\t\t\t\tif (gmadr_bytes == 8)\n\t\t\t\t\tgma |= (cmd_gma_hi(s, 3)) << 32;\n\t\t\t\t \n\t\t\t\tif (cmd_val(s, 1) & (1 << 21))\n\t\t\t\t\tindex_mode = true;\n\t\t\t\tret |= cmd_address_audit(s, gma, sizeof(u64),\n\t\t\t\t\t\tindex_mode);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t\tif (index_mode) {\n\t\t\t\t\thws_pga = s->vgpu->hws_pga[s->engine->id];\n\t\t\t\t\tgma = hws_pga + gma;\n\t\t\t\t\tpatch_value(s, cmd_ptr(s, 2), gma);\n\t\t\t\t\tval = cmd_val(s, 1) & (~(1 << 21));\n\t\t\t\t\tpatch_value(s, cmd_ptr(s, 1), val);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ret)\n\t\treturn ret;\n\n\tif (cmd_val(s, 1) & PIPE_CONTROL_NOTIFY)\n\t\tset_bit(cmd_interrupt_events[s->engine->id].pipe_control_notify,\n\t\t\ts->workload->pending_events);\n\treturn 0;\n}\n\nstatic int cmd_handler_mi_user_interrupt(struct parser_exec_state *s)\n{\n\tset_bit(cmd_interrupt_events[s->engine->id].mi_user_interrupt,\n\t\ts->workload->pending_events);\n\tpatch_value(s, cmd_ptr(s, 0), MI_NOOP);\n\treturn 0;\n}\n\nstatic int cmd_advance_default(struct parser_exec_state *s)\n{\n\treturn ip_gma_advance(s, cmd_length(s));\n}\n\nstatic int cmd_handler_mi_batch_buffer_end(struct parser_exec_state *s)\n{\n\tint ret;\n\n\tif (s->buf_type == BATCH_BUFFER_2ND_LEVEL) {\n\t\ts->buf_type = BATCH_BUFFER_INSTRUCTION;\n\t\tret = ip_gma_set(s, s->ret_ip_gma_bb);\n\t\ts->buf_addr_type = s->saved_buf_addr_type;\n\t} else if (s->buf_type == RING_BUFFER_CTX) {\n\t\tret = ip_gma_set(s, s->ring_tail);\n\t} else {\n\t\ts->buf_type = RING_BUFFER_INSTRUCTION;\n\t\ts->buf_addr_type = GTT_BUFFER;\n\t\tif (s->ret_ip_gma_ring >= s->ring_start + s->ring_size)\n\t\t\ts->ret_ip_gma_ring -= s->ring_size;\n\t\tret = ip_gma_set(s, s->ret_ip_gma_ring);\n\t}\n\treturn ret;\n}\n\nstruct mi_display_flip_command_info {\n\tint pipe;\n\tint plane;\n\tint event;\n\ti915_reg_t stride_reg;\n\ti915_reg_t ctrl_reg;\n\ti915_reg_t surf_reg;\n\tu64 stride_val;\n\tu64 tile_val;\n\tu64 surf_val;\n\tbool async_flip;\n};\n\nstruct plane_code_mapping {\n\tint pipe;\n\tint plane;\n\tint event;\n};\n\nstatic int gen8_decode_mi_display_flip(struct parser_exec_state *s,\n\t\tstruct mi_display_flip_command_info *info)\n{\n\tstruct drm_i915_private *dev_priv = s->engine->i915;\n\tstruct plane_code_mapping gen8_plane_code[] = {\n\t\t[0] = {PIPE_A, PLANE_A, PRIMARY_A_FLIP_DONE},\n\t\t[1] = {PIPE_B, PLANE_A, PRIMARY_B_FLIP_DONE},\n\t\t[2] = {PIPE_A, PLANE_B, SPRITE_A_FLIP_DONE},\n\t\t[3] = {PIPE_B, PLANE_B, SPRITE_B_FLIP_DONE},\n\t\t[4] = {PIPE_C, PLANE_A, PRIMARY_C_FLIP_DONE},\n\t\t[5] = {PIPE_C, PLANE_B, SPRITE_C_FLIP_DONE},\n\t};\n\tu32 dword0, dword1, dword2;\n\tu32 v;\n\n\tdword0 = cmd_val(s, 0);\n\tdword1 = cmd_val(s, 1);\n\tdword2 = cmd_val(s, 2);\n\n\tv = (dword0 & GENMASK(21, 19)) >> 19;\n\tif (drm_WARN_ON(&dev_priv->drm, v >= ARRAY_SIZE(gen8_plane_code)))\n\t\treturn -EBADRQC;\n\n\tinfo->pipe = gen8_plane_code[v].pipe;\n\tinfo->plane = gen8_plane_code[v].plane;\n\tinfo->event = gen8_plane_code[v].event;\n\tinfo->stride_val = (dword1 & GENMASK(15, 6)) >> 6;\n\tinfo->tile_val = (dword1 & 0x1);\n\tinfo->surf_val = (dword2 & GENMASK(31, 12)) >> 12;\n\tinfo->async_flip = ((dword2 & GENMASK(1, 0)) == 0x1);\n\n\tif (info->plane == PLANE_A) {\n\t\tinfo->ctrl_reg = DSPCNTR(info->pipe);\n\t\tinfo->stride_reg = DSPSTRIDE(info->pipe);\n\t\tinfo->surf_reg = DSPSURF(info->pipe);\n\t} else if (info->plane == PLANE_B) {\n\t\tinfo->ctrl_reg = SPRCTL(info->pipe);\n\t\tinfo->stride_reg = SPRSTRIDE(info->pipe);\n\t\tinfo->surf_reg = SPRSURF(info->pipe);\n\t} else {\n\t\tdrm_WARN_ON(&dev_priv->drm, 1);\n\t\treturn -EBADRQC;\n\t}\n\treturn 0;\n}\n\nstatic int skl_decode_mi_display_flip(struct parser_exec_state *s,\n\t\tstruct mi_display_flip_command_info *info)\n{\n\tstruct drm_i915_private *dev_priv = s->engine->i915;\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tu32 dword0 = cmd_val(s, 0);\n\tu32 dword1 = cmd_val(s, 1);\n\tu32 dword2 = cmd_val(s, 2);\n\tu32 plane = (dword0 & GENMASK(12, 8)) >> 8;\n\n\tinfo->plane = PRIMARY_PLANE;\n\n\tswitch (plane) {\n\tcase MI_DISPLAY_FLIP_SKL_PLANE_1_A:\n\t\tinfo->pipe = PIPE_A;\n\t\tinfo->event = PRIMARY_A_FLIP_DONE;\n\t\tbreak;\n\tcase MI_DISPLAY_FLIP_SKL_PLANE_1_B:\n\t\tinfo->pipe = PIPE_B;\n\t\tinfo->event = PRIMARY_B_FLIP_DONE;\n\t\tbreak;\n\tcase MI_DISPLAY_FLIP_SKL_PLANE_1_C:\n\t\tinfo->pipe = PIPE_C;\n\t\tinfo->event = PRIMARY_C_FLIP_DONE;\n\t\tbreak;\n\n\tcase MI_DISPLAY_FLIP_SKL_PLANE_2_A:\n\t\tinfo->pipe = PIPE_A;\n\t\tinfo->event = SPRITE_A_FLIP_DONE;\n\t\tinfo->plane = SPRITE_PLANE;\n\t\tbreak;\n\tcase MI_DISPLAY_FLIP_SKL_PLANE_2_B:\n\t\tinfo->pipe = PIPE_B;\n\t\tinfo->event = SPRITE_B_FLIP_DONE;\n\t\tinfo->plane = SPRITE_PLANE;\n\t\tbreak;\n\tcase MI_DISPLAY_FLIP_SKL_PLANE_2_C:\n\t\tinfo->pipe = PIPE_C;\n\t\tinfo->event = SPRITE_C_FLIP_DONE;\n\t\tinfo->plane = SPRITE_PLANE;\n\t\tbreak;\n\n\tdefault:\n\t\tgvt_vgpu_err(\"unknown plane code %d\\n\", plane);\n\t\treturn -EBADRQC;\n\t}\n\n\tinfo->stride_val = (dword1 & GENMASK(15, 6)) >> 6;\n\tinfo->tile_val = (dword1 & GENMASK(2, 0));\n\tinfo->surf_val = (dword2 & GENMASK(31, 12)) >> 12;\n\tinfo->async_flip = ((dword2 & GENMASK(1, 0)) == 0x1);\n\n\tinfo->ctrl_reg = DSPCNTR(info->pipe);\n\tinfo->stride_reg = DSPSTRIDE(info->pipe);\n\tinfo->surf_reg = DSPSURF(info->pipe);\n\n\treturn 0;\n}\n\nstatic int gen8_check_mi_display_flip(struct parser_exec_state *s,\n\t\tstruct mi_display_flip_command_info *info)\n{\n\tu32 stride, tile;\n\n\tif (!info->async_flip)\n\t\treturn 0;\n\n\tif (GRAPHICS_VER(s->engine->i915) >= 9) {\n\t\tstride = vgpu_vreg_t(s->vgpu, info->stride_reg) & GENMASK(9, 0);\n\t\ttile = (vgpu_vreg_t(s->vgpu, info->ctrl_reg) &\n\t\t\t\tGENMASK(12, 10)) >> 10;\n\t} else {\n\t\tstride = (vgpu_vreg_t(s->vgpu, info->stride_reg) &\n\t\t\t\tGENMASK(15, 6)) >> 6;\n\t\ttile = (vgpu_vreg_t(s->vgpu, info->ctrl_reg) & (1 << 10)) >> 10;\n\t}\n\n\tif (stride != info->stride_val)\n\t\tgvt_dbg_cmd(\"cannot change stride during async flip\\n\");\n\n\tif (tile != info->tile_val)\n\t\tgvt_dbg_cmd(\"cannot change tile during async flip\\n\");\n\n\treturn 0;\n}\n\nstatic int gen8_update_plane_mmio_from_mi_display_flip(\n\t\tstruct parser_exec_state *s,\n\t\tstruct mi_display_flip_command_info *info)\n{\n\tstruct drm_i915_private *dev_priv = s->engine->i915;\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\n\tset_mask_bits(&vgpu_vreg_t(vgpu, info->surf_reg), GENMASK(31, 12),\n\t\t      info->surf_val << 12);\n\tif (GRAPHICS_VER(dev_priv) >= 9) {\n\t\tset_mask_bits(&vgpu_vreg_t(vgpu, info->stride_reg), GENMASK(9, 0),\n\t\t\t      info->stride_val);\n\t\tset_mask_bits(&vgpu_vreg_t(vgpu, info->ctrl_reg), GENMASK(12, 10),\n\t\t\t      info->tile_val << 10);\n\t} else {\n\t\tset_mask_bits(&vgpu_vreg_t(vgpu, info->stride_reg), GENMASK(15, 6),\n\t\t\t      info->stride_val << 6);\n\t\tset_mask_bits(&vgpu_vreg_t(vgpu, info->ctrl_reg), GENMASK(10, 10),\n\t\t\t      info->tile_val << 10);\n\t}\n\n\tif (info->plane == PLANE_PRIMARY)\n\t\tvgpu_vreg_t(vgpu, PIPE_FLIPCOUNT_G4X(info->pipe))++;\n\n\tif (info->async_flip)\n\t\tintel_vgpu_trigger_virtual_event(vgpu, info->event);\n\telse\n\t\tset_bit(info->event, vgpu->irq.flip_done_event[info->pipe]);\n\n\treturn 0;\n}\n\nstatic int decode_mi_display_flip(struct parser_exec_state *s,\n\t\tstruct mi_display_flip_command_info *info)\n{\n\tif (IS_BROADWELL(s->engine->i915))\n\t\treturn gen8_decode_mi_display_flip(s, info);\n\tif (GRAPHICS_VER(s->engine->i915) >= 9)\n\t\treturn skl_decode_mi_display_flip(s, info);\n\n\treturn -ENODEV;\n}\n\nstatic int check_mi_display_flip(struct parser_exec_state *s,\n\t\tstruct mi_display_flip_command_info *info)\n{\n\treturn gen8_check_mi_display_flip(s, info);\n}\n\nstatic int update_plane_mmio_from_mi_display_flip(\n\t\tstruct parser_exec_state *s,\n\t\tstruct mi_display_flip_command_info *info)\n{\n\treturn gen8_update_plane_mmio_from_mi_display_flip(s, info);\n}\n\nstatic int cmd_handler_mi_display_flip(struct parser_exec_state *s)\n{\n\tstruct mi_display_flip_command_info info;\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tint ret;\n\tint i;\n\tint len = cmd_length(s);\n\tu32 valid_len = CMD_LEN(1);\n\n\t \n\tif (DWORD_FIELD(2, 1, 0) == 2)\n\t\tvalid_len++;\n\tret = gvt_check_valid_cmd_length(cmd_length(s),\n\t\t\tvalid_len);\n\tif (ret)\n\t\treturn ret;\n\n\tret = decode_mi_display_flip(s, &info);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"fail to decode MI display flip command\\n\");\n\t\treturn ret;\n\t}\n\n\tret = check_mi_display_flip(s, &info);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"invalid MI display flip command\\n\");\n\t\treturn ret;\n\t}\n\n\tret = update_plane_mmio_from_mi_display_flip(s, &info);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"fail to update plane mmio\\n\");\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < len; i++)\n\t\tpatch_value(s, cmd_ptr(s, i), MI_NOOP);\n\treturn 0;\n}\n\nstatic bool is_wait_for_flip_pending(u32 cmd)\n{\n\treturn cmd & (MI_WAIT_FOR_PLANE_A_FLIP_PENDING |\n\t\t\tMI_WAIT_FOR_PLANE_B_FLIP_PENDING |\n\t\t\tMI_WAIT_FOR_PLANE_C_FLIP_PENDING |\n\t\t\tMI_WAIT_FOR_SPRITE_A_FLIP_PENDING |\n\t\t\tMI_WAIT_FOR_SPRITE_B_FLIP_PENDING |\n\t\t\tMI_WAIT_FOR_SPRITE_C_FLIP_PENDING);\n}\n\nstatic int cmd_handler_mi_wait_for_event(struct parser_exec_state *s)\n{\n\tu32 cmd = cmd_val(s, 0);\n\n\tif (!is_wait_for_flip_pending(cmd))\n\t\treturn 0;\n\n\tpatch_value(s, cmd_ptr(s, 0), MI_NOOP);\n\treturn 0;\n}\n\nstatic unsigned long get_gma_bb_from_cmd(struct parser_exec_state *s, int index)\n{\n\tunsigned long addr;\n\tunsigned long gma_high, gma_low;\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tint gmadr_bytes = vgpu->gvt->device_info.gmadr_bytes_in_cmd;\n\n\tif (WARN_ON(gmadr_bytes != 4 && gmadr_bytes != 8)) {\n\t\tgvt_vgpu_err(\"invalid gma bytes %d\\n\", gmadr_bytes);\n\t\treturn INTEL_GVT_INVALID_ADDR;\n\t}\n\n\tgma_low = cmd_val(s, index) & BATCH_BUFFER_ADDR_MASK;\n\tif (gmadr_bytes == 4) {\n\t\taddr = gma_low;\n\t} else {\n\t\tgma_high = cmd_val(s, index + 1) & BATCH_BUFFER_ADDR_HIGH_MASK;\n\t\taddr = (((unsigned long)gma_high) << 32) | gma_low;\n\t}\n\treturn addr;\n}\n\nstatic inline int cmd_address_audit(struct parser_exec_state *s,\n\t\tunsigned long guest_gma, int op_size, bool index_mode)\n{\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tu32 max_surface_size = vgpu->gvt->device_info.max_surface_size;\n\tint i;\n\tint ret;\n\n\tif (op_size > max_surface_size) {\n\t\tgvt_vgpu_err(\"command address audit fail name %s\\n\",\n\t\t\ts->info->name);\n\t\treturn -EFAULT;\n\t}\n\n\tif (index_mode)\t{\n\t\tif (guest_gma >= I915_GTT_PAGE_SIZE) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto err;\n\t\t}\n\t} else if (!intel_gvt_ggtt_validate_range(vgpu, guest_gma, op_size)) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\treturn 0;\n\nerr:\n\tgvt_vgpu_err(\"cmd_parser: Malicious %s detected, addr=0x%lx, len=%d!\\n\",\n\t\t\ts->info->name, guest_gma, op_size);\n\n\tpr_err(\"cmd dump: \");\n\tfor (i = 0; i < cmd_length(s); i++) {\n\t\tif (!(i % 4))\n\t\t\tpr_err(\"\\n%08x \", cmd_val(s, i));\n\t\telse\n\t\t\tpr_err(\"%08x \", cmd_val(s, i));\n\t}\n\tpr_err(\"\\nvgpu%d: aperture 0x%llx - 0x%llx, hidden 0x%llx - 0x%llx\\n\",\n\t\t\tvgpu->id,\n\t\t\tvgpu_aperture_gmadr_base(vgpu),\n\t\t\tvgpu_aperture_gmadr_end(vgpu),\n\t\t\tvgpu_hidden_gmadr_base(vgpu),\n\t\t\tvgpu_hidden_gmadr_end(vgpu));\n\treturn ret;\n}\n\nstatic int cmd_handler_mi_store_data_imm(struct parser_exec_state *s)\n{\n\tint gmadr_bytes = s->vgpu->gvt->device_info.gmadr_bytes_in_cmd;\n\tint op_size = (cmd_length(s) - 3) * sizeof(u32);\n\tint core_id = (cmd_val(s, 2) & (1 << 0)) ? 1 : 0;\n\tunsigned long gma, gma_low, gma_high;\n\tu32 valid_len = CMD_LEN(2);\n\tint ret = 0;\n\n\t \n\tif (!(cmd_val(s, 0) & (1 << 22)))\n\t\treturn 0;\n\n\t \n\tif (DWORD_FIELD(0, 21, 21))\n\t\tvalid_len++;\n\tret = gvt_check_valid_cmd_length(cmd_length(s),\n\t\t\tvalid_len);\n\tif (ret)\n\t\treturn ret;\n\n\tgma = cmd_val(s, 2) & GENMASK(31, 2);\n\n\tif (gmadr_bytes == 8) {\n\t\tgma_low = cmd_val(s, 1) & GENMASK(31, 2);\n\t\tgma_high = cmd_val(s, 2) & GENMASK(15, 0);\n\t\tgma = (gma_high << 32) | gma_low;\n\t\tcore_id = (cmd_val(s, 1) & (1 << 0)) ? 1 : 0;\n\t}\n\tret = cmd_address_audit(s, gma + op_size * core_id, op_size, false);\n\treturn ret;\n}\n\nstatic inline int unexpected_cmd(struct parser_exec_state *s)\n{\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\n\tgvt_vgpu_err(\"Unexpected %s in command buffer!\\n\", s->info->name);\n\n\treturn -EBADRQC;\n}\n\nstatic int cmd_handler_mi_semaphore_wait(struct parser_exec_state *s)\n{\n\treturn unexpected_cmd(s);\n}\n\nstatic int cmd_handler_mi_report_perf_count(struct parser_exec_state *s)\n{\n\treturn unexpected_cmd(s);\n}\n\nstatic int cmd_handler_mi_op_2e(struct parser_exec_state *s)\n{\n\treturn unexpected_cmd(s);\n}\n\nstatic int cmd_handler_mi_op_2f(struct parser_exec_state *s)\n{\n\tint gmadr_bytes = s->vgpu->gvt->device_info.gmadr_bytes_in_cmd;\n\tint op_size = (1 << ((cmd_val(s, 0) & GENMASK(20, 19)) >> 19)) *\n\t\t\tsizeof(u32);\n\tunsigned long gma, gma_high;\n\tu32 valid_len = CMD_LEN(1);\n\tint ret = 0;\n\n\tif (!(cmd_val(s, 0) & (1 << 22)))\n\t\treturn ret;\n\n\t \n\tif (cmd_val(s, 0) & BIT(18))\n\t\tvalid_len = CMD_LEN(9);\n\tret = gvt_check_valid_cmd_length(cmd_length(s),\n\t\t\tvalid_len);\n\tif (ret)\n\t\treturn ret;\n\n\tgma = cmd_val(s, 1) & GENMASK(31, 2);\n\tif (gmadr_bytes == 8) {\n\t\tgma_high = cmd_val(s, 2) & GENMASK(15, 0);\n\t\tgma = (gma_high << 32) | gma;\n\t}\n\tret = cmd_address_audit(s, gma, op_size, false);\n\treturn ret;\n}\n\nstatic int cmd_handler_mi_store_data_index(struct parser_exec_state *s)\n{\n\treturn unexpected_cmd(s);\n}\n\nstatic int cmd_handler_mi_clflush(struct parser_exec_state *s)\n{\n\treturn unexpected_cmd(s);\n}\n\nstatic int cmd_handler_mi_conditional_batch_buffer_end(\n\t\tstruct parser_exec_state *s)\n{\n\treturn unexpected_cmd(s);\n}\n\nstatic int cmd_handler_mi_update_gtt(struct parser_exec_state *s)\n{\n\treturn unexpected_cmd(s);\n}\n\nstatic int cmd_handler_mi_flush_dw(struct parser_exec_state *s)\n{\n\tint gmadr_bytes = s->vgpu->gvt->device_info.gmadr_bytes_in_cmd;\n\tunsigned long gma;\n\tbool index_mode = false;\n\tint ret = 0;\n\tu32 hws_pga, val;\n\tu32 valid_len = CMD_LEN(2);\n\n\tret = gvt_check_valid_cmd_length(cmd_length(s),\n\t\t\tvalid_len);\n\tif (ret) {\n\t\t \n\t\tret = gvt_check_valid_cmd_length(cmd_length(s),\n\t\t\t++valid_len);\n\t\treturn ret;\n\t}\n\n\t \n\tif (((cmd_val(s, 0) >> 14) & 0x3) && (cmd_val(s, 1) & (1 << 2))) {\n\t\tgma = cmd_val(s, 1) & GENMASK(31, 3);\n\t\tif (gmadr_bytes == 8)\n\t\t\tgma |= (cmd_val(s, 2) & GENMASK(15, 0)) << 32;\n\t\t \n\t\tif (cmd_val(s, 0) & (1 << 21))\n\t\t\tindex_mode = true;\n\t\tret = cmd_address_audit(s, gma, sizeof(u64), index_mode);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (index_mode) {\n\t\t\thws_pga = s->vgpu->hws_pga[s->engine->id];\n\t\t\tgma = hws_pga + gma;\n\t\t\tpatch_value(s, cmd_ptr(s, 1), gma);\n\t\t\tval = cmd_val(s, 0) & (~(1 << 21));\n\t\t\tpatch_value(s, cmd_ptr(s, 0), val);\n\t\t}\n\t}\n\t \n\tif ((cmd_val(s, 0) & (1 << 8)))\n\t\tset_bit(cmd_interrupt_events[s->engine->id].mi_flush_dw,\n\t\t\ts->workload->pending_events);\n\treturn ret;\n}\n\nstatic void addr_type_update_snb(struct parser_exec_state *s)\n{\n\tif ((s->buf_type == RING_BUFFER_INSTRUCTION) &&\n\t\t\t(BATCH_BUFFER_ADR_SPACE_BIT(cmd_val(s, 0)) == 1)) {\n\t\ts->buf_addr_type = PPGTT_BUFFER;\n\t}\n}\n\n\nstatic int copy_gma_to_hva(struct intel_vgpu *vgpu, struct intel_vgpu_mm *mm,\n\t\tunsigned long gma, unsigned long end_gma, void *va)\n{\n\tunsigned long copy_len, offset;\n\tunsigned long len = 0;\n\tunsigned long gpa;\n\n\twhile (gma != end_gma) {\n\t\tgpa = intel_vgpu_gma_to_gpa(mm, gma);\n\t\tif (gpa == INTEL_GVT_INVALID_ADDR) {\n\t\t\tgvt_vgpu_err(\"invalid gma address: %lx\\n\", gma);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\toffset = gma & (I915_GTT_PAGE_SIZE - 1);\n\n\t\tcopy_len = (end_gma - gma) >= (I915_GTT_PAGE_SIZE - offset) ?\n\t\t\tI915_GTT_PAGE_SIZE - offset : end_gma - gma;\n\n\t\tintel_gvt_read_gpa(vgpu, gpa, va + len, copy_len);\n\n\t\tlen += copy_len;\n\t\tgma += copy_len;\n\t}\n\treturn len;\n}\n\n\n \nstatic int batch_buffer_needs_scan(struct parser_exec_state *s)\n{\n\t \n\tif (cmd_val(s, 0) & BIT(8) &&\n\t    !(s->vgpu->scan_nonprivbb & s->engine->mask))\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic const char *repr_addr_type(unsigned int type)\n{\n\treturn type == PPGTT_BUFFER ? \"ppgtt\" : \"ggtt\";\n}\n\nstatic int find_bb_size(struct parser_exec_state *s,\n\t\t\tunsigned long *bb_size,\n\t\t\tunsigned long *bb_end_cmd_offset)\n{\n\tunsigned long gma = 0;\n\tconst struct cmd_info *info;\n\tu32 cmd_len = 0;\n\tbool bb_end = false;\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tu32 cmd;\n\tstruct intel_vgpu_mm *mm = (s->buf_addr_type == GTT_BUFFER) ?\n\t\ts->vgpu->gtt.ggtt_mm : s->workload->shadow_mm;\n\n\t*bb_size = 0;\n\t*bb_end_cmd_offset = 0;\n\n\t \n\tgma = get_gma_bb_from_cmd(s, 1);\n\tif (gma == INTEL_GVT_INVALID_ADDR)\n\t\treturn -EFAULT;\n\n\tcmd = cmd_val(s, 0);\n\tinfo = get_cmd_info(s->vgpu->gvt, cmd, s->engine);\n\tif (info == NULL) {\n\t\tgvt_vgpu_err(\"unknown cmd 0x%x, opcode=0x%x, addr_type=%s, ring %s, workload=%p\\n\",\n\t\t\t     cmd, get_opcode(cmd, s->engine),\n\t\t\t     repr_addr_type(s->buf_addr_type),\n\t\t\t     s->engine->name, s->workload);\n\t\treturn -EBADRQC;\n\t}\n\tdo {\n\t\tif (copy_gma_to_hva(s->vgpu, mm,\n\t\t\t\t    gma, gma + 4, &cmd) < 0)\n\t\t\treturn -EFAULT;\n\t\tinfo = get_cmd_info(s->vgpu->gvt, cmd, s->engine);\n\t\tif (info == NULL) {\n\t\t\tgvt_vgpu_err(\"unknown cmd 0x%x, opcode=0x%x, addr_type=%s, ring %s, workload=%p\\n\",\n\t\t\t\t     cmd, get_opcode(cmd, s->engine),\n\t\t\t\t     repr_addr_type(s->buf_addr_type),\n\t\t\t\t     s->engine->name, s->workload);\n\t\t\treturn -EBADRQC;\n\t\t}\n\n\t\tif (info->opcode == OP_MI_BATCH_BUFFER_END) {\n\t\t\tbb_end = true;\n\t\t} else if (info->opcode == OP_MI_BATCH_BUFFER_START) {\n\t\t\tif (BATCH_BUFFER_2ND_LEVEL_BIT(cmd) == 0)\n\t\t\t\t \n\t\t\t\tbb_end = true;\n\t\t}\n\n\t\tif (bb_end)\n\t\t\t*bb_end_cmd_offset = *bb_size;\n\n\t\tcmd_len = get_cmd_length(info, cmd) << 2;\n\t\t*bb_size += cmd_len;\n\t\tgma += cmd_len;\n\t} while (!bb_end);\n\n\treturn 0;\n}\n\nstatic int audit_bb_end(struct parser_exec_state *s, void *va)\n{\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tu32 cmd = *(u32 *)va;\n\tconst struct cmd_info *info;\n\n\tinfo = get_cmd_info(s->vgpu->gvt, cmd, s->engine);\n\tif (info == NULL) {\n\t\tgvt_vgpu_err(\"unknown cmd 0x%x, opcode=0x%x, addr_type=%s, ring %s, workload=%p\\n\",\n\t\t\t     cmd, get_opcode(cmd, s->engine),\n\t\t\t     repr_addr_type(s->buf_addr_type),\n\t\t\t     s->engine->name, s->workload);\n\t\treturn -EBADRQC;\n\t}\n\n\tif ((info->opcode == OP_MI_BATCH_BUFFER_END) ||\n\t    ((info->opcode == OP_MI_BATCH_BUFFER_START) &&\n\t     (BATCH_BUFFER_2ND_LEVEL_BIT(cmd) == 0)))\n\t\treturn 0;\n\n\treturn -EBADRQC;\n}\n\nstatic int perform_bb_shadow(struct parser_exec_state *s)\n{\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tstruct intel_vgpu_shadow_bb *bb;\n\tunsigned long gma = 0;\n\tunsigned long bb_size;\n\tunsigned long bb_end_cmd_offset;\n\tint ret = 0;\n\tstruct intel_vgpu_mm *mm = (s->buf_addr_type == GTT_BUFFER) ?\n\t\ts->vgpu->gtt.ggtt_mm : s->workload->shadow_mm;\n\tunsigned long start_offset = 0;\n\n\t \n\tgma = get_gma_bb_from_cmd(s, 1);\n\tif (gma == INTEL_GVT_INVALID_ADDR)\n\t\treturn -EFAULT;\n\n\tret = find_bb_size(s, &bb_size, &bb_end_cmd_offset);\n\tif (ret)\n\t\treturn ret;\n\n\tbb = kzalloc(sizeof(*bb), GFP_KERNEL);\n\tif (!bb)\n\t\treturn -ENOMEM;\n\n\tbb->ppgtt = (s->buf_addr_type == GTT_BUFFER) ? false : true;\n\n\t \n\tif (bb->ppgtt)\n\t\tstart_offset = gma & ~I915_GTT_PAGE_MASK;\n\n\tbb->obj = i915_gem_object_create_shmem(s->engine->i915,\n\t\t\t\t\t       round_up(bb_size + start_offset,\n\t\t\t\t\t\t\tPAGE_SIZE));\n\tif (IS_ERR(bb->obj)) {\n\t\tret = PTR_ERR(bb->obj);\n\t\tgoto err_free_bb;\n\t}\n\n\tbb->va = i915_gem_object_pin_map(bb->obj, I915_MAP_WB);\n\tif (IS_ERR(bb->va)) {\n\t\tret = PTR_ERR(bb->va);\n\t\tgoto err_free_obj;\n\t}\n\n\tret = copy_gma_to_hva(s->vgpu, mm,\n\t\t\t      gma, gma + bb_size,\n\t\t\t      bb->va + start_offset);\n\tif (ret < 0) {\n\t\tgvt_vgpu_err(\"fail to copy guest ring buffer\\n\");\n\t\tret = -EFAULT;\n\t\tgoto err_unmap;\n\t}\n\n\tret = audit_bb_end(s, bb->va + start_offset + bb_end_cmd_offset);\n\tif (ret)\n\t\tgoto err_unmap;\n\n\ti915_gem_object_unlock(bb->obj);\n\tINIT_LIST_HEAD(&bb->list);\n\tlist_add(&bb->list, &s->workload->shadow_bb);\n\n\tbb->bb_start_cmd_va = s->ip_va;\n\n\tif ((s->buf_type == BATCH_BUFFER_INSTRUCTION) && (!s->is_ctx_wa))\n\t\tbb->bb_offset = s->ip_va - s->rb_va;\n\telse\n\t\tbb->bb_offset = 0;\n\n\t \n\ts->ip_va = bb->va + start_offset;\n\ts->ip_gma = gma;\n\treturn 0;\nerr_unmap:\n\ti915_gem_object_unpin_map(bb->obj);\nerr_free_obj:\n\ti915_gem_object_put(bb->obj);\nerr_free_bb:\n\tkfree(bb);\n\treturn ret;\n}\n\nstatic int cmd_handler_mi_batch_buffer_start(struct parser_exec_state *s)\n{\n\tbool second_level;\n\tint ret = 0;\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\n\tif (s->buf_type == BATCH_BUFFER_2ND_LEVEL) {\n\t\tgvt_vgpu_err(\"Found MI_BATCH_BUFFER_START in 2nd level BB\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tsecond_level = BATCH_BUFFER_2ND_LEVEL_BIT(cmd_val(s, 0)) == 1;\n\tif (second_level && (s->buf_type != BATCH_BUFFER_INSTRUCTION)) {\n\t\tgvt_vgpu_err(\"Jumping to 2nd level BB from RB is not allowed\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\ts->saved_buf_addr_type = s->buf_addr_type;\n\taddr_type_update_snb(s);\n\tif (s->buf_type == RING_BUFFER_INSTRUCTION) {\n\t\ts->ret_ip_gma_ring = s->ip_gma + cmd_length(s) * sizeof(u32);\n\t\ts->buf_type = BATCH_BUFFER_INSTRUCTION;\n\t} else if (second_level) {\n\t\ts->buf_type = BATCH_BUFFER_2ND_LEVEL;\n\t\ts->ret_ip_gma_bb = s->ip_gma + cmd_length(s) * sizeof(u32);\n\t\ts->ret_bb_va = s->ip_va + cmd_length(s) * sizeof(u32);\n\t}\n\n\tif (batch_buffer_needs_scan(s)) {\n\t\tret = perform_bb_shadow(s);\n\t\tif (ret < 0)\n\t\t\tgvt_vgpu_err(\"invalid shadow batch buffer\\n\");\n\t} else {\n\t\t \n\t\tret = cmd_handler_mi_batch_buffer_end(s);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\treturn ret;\n}\n\nstatic int mi_noop_index;\n\nstatic const struct cmd_info cmd_info[] = {\n\t{\"MI_NOOP\", OP_MI_NOOP, F_LEN_CONST, R_ALL, D_ALL, 0, 1, NULL},\n\n\t{\"MI_SET_PREDICATE\", OP_MI_SET_PREDICATE, F_LEN_CONST, R_ALL, D_ALL,\n\t\t0, 1, NULL},\n\n\t{\"MI_USER_INTERRUPT\", OP_MI_USER_INTERRUPT, F_LEN_CONST, R_ALL, D_ALL,\n\t\t0, 1, cmd_handler_mi_user_interrupt},\n\n\t{\"MI_WAIT_FOR_EVENT\", OP_MI_WAIT_FOR_EVENT, F_LEN_CONST, R_RCS | R_BCS,\n\t\tD_ALL, 0, 1, cmd_handler_mi_wait_for_event},\n\n\t{\"MI_FLUSH\", OP_MI_FLUSH, F_LEN_CONST, R_ALL, D_ALL, 0, 1, NULL},\n\n\t{\"MI_ARB_CHECK\", OP_MI_ARB_CHECK, F_LEN_CONST, R_ALL, D_ALL, 0, 1,\n\t\tNULL},\n\n\t{\"MI_RS_CONTROL\", OP_MI_RS_CONTROL, F_LEN_CONST, R_RCS, D_ALL, 0, 1,\n\t\tNULL},\n\n\t{\"MI_REPORT_HEAD\", OP_MI_REPORT_HEAD, F_LEN_CONST, R_ALL, D_ALL, 0, 1,\n\t\tNULL},\n\n\t{\"MI_ARB_ON_OFF\", OP_MI_ARB_ON_OFF, F_LEN_CONST, R_ALL, D_ALL, 0, 1,\n\t\tNULL},\n\n\t{\"MI_URB_ATOMIC_ALLOC\", OP_MI_URB_ATOMIC_ALLOC, F_LEN_CONST, R_RCS,\n\t\tD_ALL, 0, 1, NULL},\n\n\t{\"MI_BATCH_BUFFER_END\", OP_MI_BATCH_BUFFER_END,\n\t\tF_IP_ADVANCE_CUSTOM | F_LEN_CONST, R_ALL, D_ALL, 0, 1,\n\t\tcmd_handler_mi_batch_buffer_end},\n\n\t{\"MI_SUSPEND_FLUSH\", OP_MI_SUSPEND_FLUSH, F_LEN_CONST, R_ALL, D_ALL,\n\t\t0, 1, NULL},\n\n\t{\"MI_PREDICATE\", OP_MI_PREDICATE, F_LEN_CONST, R_RCS, D_ALL, 0, 1,\n\t\tNULL},\n\n\t{\"MI_TOPOLOGY_FILTER\", OP_MI_TOPOLOGY_FILTER, F_LEN_CONST, R_ALL,\n\t\tD_ALL, 0, 1, NULL},\n\n\t{\"MI_SET_APPID\", OP_MI_SET_APPID, F_LEN_CONST, R_ALL, D_ALL, 0, 1,\n\t\tNULL},\n\n\t{\"MI_RS_CONTEXT\", OP_MI_RS_CONTEXT, F_LEN_CONST, R_RCS, D_ALL, 0, 1,\n\t\tNULL},\n\n\t{\"MI_DISPLAY_FLIP\", OP_MI_DISPLAY_FLIP, F_LEN_VAR,\n\t\tR_RCS | R_BCS, D_ALL, 0, 8, cmd_handler_mi_display_flip},\n\n\t{\"MI_SEMAPHORE_MBOX\", OP_MI_SEMAPHORE_MBOX, F_LEN_VAR | F_LEN_VAR_FIXED,\n\t\tR_ALL, D_ALL, 0, 8, NULL, CMD_LEN(1)},\n\n\t{\"MI_MATH\", OP_MI_MATH, F_LEN_VAR, R_ALL, D_ALL, 0, 8, NULL},\n\n\t{\"MI_URB_CLEAR\", OP_MI_URB_CLEAR, F_LEN_VAR | F_LEN_VAR_FIXED, R_RCS,\n\t\tD_ALL, 0, 8, NULL, CMD_LEN(0)},\n\n\t{\"MI_SEMAPHORE_SIGNAL\", OP_MI_SEMAPHORE_SIGNAL,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_BDW_PLUS, 0, 8,\n\t\tNULL, CMD_LEN(0)},\n\n\t{\"MI_SEMAPHORE_WAIT\", OP_MI_SEMAPHORE_WAIT,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_BDW_PLUS, ADDR_FIX_1(2),\n\t\t8, cmd_handler_mi_semaphore_wait, CMD_LEN(2)},\n\n\t{\"MI_STORE_DATA_IMM\", OP_MI_STORE_DATA_IMM, F_LEN_VAR, R_ALL, D_BDW_PLUS,\n\t\tADDR_FIX_1(1), 10, cmd_handler_mi_store_data_imm},\n\n\t{\"MI_STORE_DATA_INDEX\", OP_MI_STORE_DATA_INDEX, F_LEN_VAR, R_ALL, D_ALL,\n\t\t0, 8, cmd_handler_mi_store_data_index},\n\n\t{\"MI_LOAD_REGISTER_IMM\", OP_MI_LOAD_REGISTER_IMM, F_LEN_VAR, R_ALL,\n\t\tD_ALL, 0, 8, cmd_handler_lri},\n\n\t{\"MI_UPDATE_GTT\", OP_MI_UPDATE_GTT, F_LEN_VAR, R_ALL, D_BDW_PLUS, 0, 10,\n\t\tcmd_handler_mi_update_gtt},\n\n\t{\"MI_STORE_REGISTER_MEM\", OP_MI_STORE_REGISTER_MEM,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_ALL, ADDR_FIX_1(2), 8,\n\t\tcmd_handler_srm, CMD_LEN(2)},\n\n\t{\"MI_FLUSH_DW\", OP_MI_FLUSH_DW, F_LEN_VAR, R_ALL, D_ALL, 0, 6,\n\t\tcmd_handler_mi_flush_dw},\n\n\t{\"MI_CLFLUSH\", OP_MI_CLFLUSH, F_LEN_VAR, R_ALL, D_ALL, ADDR_FIX_1(1),\n\t\t10, cmd_handler_mi_clflush},\n\n\t{\"MI_REPORT_PERF_COUNT\", OP_MI_REPORT_PERF_COUNT,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_ALL, ADDR_FIX_1(1), 6,\n\t\tcmd_handler_mi_report_perf_count, CMD_LEN(2)},\n\n\t{\"MI_LOAD_REGISTER_MEM\", OP_MI_LOAD_REGISTER_MEM,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_ALL, ADDR_FIX_1(2), 8,\n\t\tcmd_handler_lrm, CMD_LEN(2)},\n\n\t{\"MI_LOAD_REGISTER_REG\", OP_MI_LOAD_REGISTER_REG,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_ALL, 0, 8,\n\t\tcmd_handler_lrr, CMD_LEN(1)},\n\n\t{\"MI_RS_STORE_DATA_IMM\", OP_MI_RS_STORE_DATA_IMM,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_RCS, D_ALL, 0,\n\t\t8, NULL, CMD_LEN(2)},\n\n\t{\"MI_LOAD_URB_MEM\", OP_MI_LOAD_URB_MEM, F_LEN_VAR | F_LEN_VAR_FIXED,\n\t\tR_RCS, D_ALL, ADDR_FIX_1(2), 8, NULL, CMD_LEN(2)},\n\n\t{\"MI_STORE_URM_MEM\", OP_MI_STORE_URM_MEM, F_LEN_VAR, R_RCS, D_ALL,\n\t\tADDR_FIX_1(2), 8, NULL},\n\n\t{\"MI_OP_2E\", OP_MI_2E, F_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_BDW_PLUS,\n\t\tADDR_FIX_2(1, 2), 8, cmd_handler_mi_op_2e, CMD_LEN(3)},\n\n\t{\"MI_OP_2F\", OP_MI_2F, F_LEN_VAR, R_ALL, D_BDW_PLUS, ADDR_FIX_1(1),\n\t\t8, cmd_handler_mi_op_2f},\n\n\t{\"MI_BATCH_BUFFER_START\", OP_MI_BATCH_BUFFER_START,\n\t\tF_IP_ADVANCE_CUSTOM, R_ALL, D_ALL, 0, 8,\n\t\tcmd_handler_mi_batch_buffer_start},\n\n\t{\"MI_CONDITIONAL_BATCH_BUFFER_END\", OP_MI_CONDITIONAL_BATCH_BUFFER_END,\n\t\tF_LEN_VAR | F_LEN_VAR_FIXED, R_ALL, D_ALL, ADDR_FIX_1(2), 8,\n\t\tcmd_handler_mi_conditional_batch_buffer_end, CMD_LEN(2)},\n\n\t{\"MI_LOAD_SCAN_LINES_INCL\", OP_MI_LOAD_SCAN_LINES_INCL, F_LEN_CONST,\n\t\tR_RCS | R_BCS, D_ALL, 0, 2, NULL},\n\n\t{\"XY_SETUP_BLT\", OP_XY_SETUP_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\tADDR_FIX_2(4, 7), 8, NULL},\n\n\t{\"XY_SETUP_CLIP_BLT\", OP_XY_SETUP_CLIP_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"XY_SETUP_MONO_PATTERN_SL_BLT\", OP_XY_SETUP_MONO_PATTERN_SL_BLT,\n\t\tF_LEN_VAR, R_BCS, D_ALL, ADDR_FIX_1(4), 8, NULL},\n\n\t{\"XY_PIXEL_BLT\", OP_XY_PIXEL_BLT, F_LEN_VAR, R_BCS, D_ALL, 0, 8, NULL},\n\n\t{\"XY_SCANLINES_BLT\", OP_XY_SCANLINES_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"XY_TEXT_BLT\", OP_XY_TEXT_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\tADDR_FIX_1(3), 8, NULL},\n\n\t{\"XY_TEXT_IMMEDIATE_BLT\", OP_XY_TEXT_IMMEDIATE_BLT, F_LEN_VAR, R_BCS,\n\t\tD_ALL, 0, 8, NULL},\n\n\t{\"XY_COLOR_BLT\", OP_XY_COLOR_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\tADDR_FIX_1(4), 8, NULL},\n\n\t{\"XY_PAT_BLT\", OP_XY_PAT_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\tADDR_FIX_2(4, 5), 8, NULL},\n\n\t{\"XY_MONO_PAT_BLT\", OP_XY_MONO_PAT_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\tADDR_FIX_1(4), 8, NULL},\n\n\t{\"XY_SRC_COPY_BLT\", OP_XY_SRC_COPY_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\tADDR_FIX_2(4, 7), 8, NULL},\n\n\t{\"XY_MONO_SRC_COPY_BLT\", OP_XY_MONO_SRC_COPY_BLT, F_LEN_VAR, R_BCS,\n\t\tD_ALL, ADDR_FIX_2(4, 5), 8, NULL},\n\n\t{\"XY_FULL_BLT\", OP_XY_FULL_BLT, F_LEN_VAR, R_BCS, D_ALL, 0, 8, NULL},\n\n\t{\"XY_FULL_MONO_SRC_BLT\", OP_XY_FULL_MONO_SRC_BLT, F_LEN_VAR, R_BCS,\n\t\tD_ALL, ADDR_FIX_3(4, 5, 8), 8, NULL},\n\n\t{\"XY_FULL_MONO_PATTERN_BLT\", OP_XY_FULL_MONO_PATTERN_BLT, F_LEN_VAR,\n\t\tR_BCS, D_ALL, ADDR_FIX_2(4, 7), 8, NULL},\n\n\t{\"XY_FULL_MONO_PATTERN_MONO_SRC_BLT\",\n\t\tOP_XY_FULL_MONO_PATTERN_MONO_SRC_BLT,\n\t\tF_LEN_VAR, R_BCS, D_ALL, ADDR_FIX_2(4, 5), 8, NULL},\n\n\t{\"XY_MONO_PAT_FIXED_BLT\", OP_XY_MONO_PAT_FIXED_BLT, F_LEN_VAR, R_BCS,\n\t\tD_ALL, ADDR_FIX_1(4), 8, NULL},\n\n\t{\"XY_MONO_SRC_COPY_IMMEDIATE_BLT\", OP_XY_MONO_SRC_COPY_IMMEDIATE_BLT,\n\t\tF_LEN_VAR, R_BCS, D_ALL, ADDR_FIX_1(4), 8, NULL},\n\n\t{\"XY_PAT_BLT_IMMEDIATE\", OP_XY_PAT_BLT_IMMEDIATE, F_LEN_VAR, R_BCS,\n\t\tD_ALL, ADDR_FIX_1(4), 8, NULL},\n\n\t{\"XY_SRC_COPY_CHROMA_BLT\", OP_XY_SRC_COPY_CHROMA_BLT, F_LEN_VAR, R_BCS,\n\t\tD_ALL, ADDR_FIX_2(4, 7), 8, NULL},\n\n\t{\"XY_FULL_IMMEDIATE_PATTERN_BLT\", OP_XY_FULL_IMMEDIATE_PATTERN_BLT,\n\t\tF_LEN_VAR, R_BCS, D_ALL, ADDR_FIX_2(4, 7), 8, NULL},\n\n\t{\"XY_FULL_MONO_SRC_IMMEDIATE_PATTERN_BLT\",\n\t\tOP_XY_FULL_MONO_SRC_IMMEDIATE_PATTERN_BLT,\n\t\tF_LEN_VAR, R_BCS, D_ALL, ADDR_FIX_2(4, 5), 8, NULL},\n\n\t{\"XY_PAT_CHROMA_BLT\", OP_XY_PAT_CHROMA_BLT, F_LEN_VAR, R_BCS, D_ALL,\n\t\tADDR_FIX_2(4, 5), 8, NULL},\n\n\t{\"XY_PAT_CHROMA_BLT_IMMEDIATE\", OP_XY_PAT_CHROMA_BLT_IMMEDIATE,\n\t\tF_LEN_VAR, R_BCS, D_ALL, ADDR_FIX_1(4), 8, NULL},\n\n\t{\"3DSTATE_VIEWPORT_STATE_POINTERS_SF_CLIP\",\n\t\tOP_3DSTATE_VIEWPORT_STATE_POINTERS_SF_CLIP,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_VIEWPORT_STATE_POINTERS_CC\",\n\t\tOP_3DSTATE_VIEWPORT_STATE_POINTERS_CC,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_BLEND_STATE_POINTERS\",\n\t\tOP_3DSTATE_BLEND_STATE_POINTERS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DEPTH_STENCIL_STATE_POINTERS\",\n\t\tOP_3DSTATE_DEPTH_STENCIL_STATE_POINTERS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_POINTERS_VS\",\n\t\tOP_3DSTATE_BINDING_TABLE_POINTERS_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_POINTERS_HS\",\n\t\tOP_3DSTATE_BINDING_TABLE_POINTERS_HS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_POINTERS_DS\",\n\t\tOP_3DSTATE_BINDING_TABLE_POINTERS_DS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_POINTERS_GS\",\n\t\tOP_3DSTATE_BINDING_TABLE_POINTERS_GS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_POINTERS_PS\",\n\t\tOP_3DSTATE_BINDING_TABLE_POINTERS_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLER_STATE_POINTERS_VS\",\n\t\tOP_3DSTATE_SAMPLER_STATE_POINTERS_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLER_STATE_POINTERS_HS\",\n\t\tOP_3DSTATE_SAMPLER_STATE_POINTERS_HS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLER_STATE_POINTERS_DS\",\n\t\tOP_3DSTATE_SAMPLER_STATE_POINTERS_DS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLER_STATE_POINTERS_GS\",\n\t\tOP_3DSTATE_SAMPLER_STATE_POINTERS_GS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLER_STATE_POINTERS_PS\",\n\t\tOP_3DSTATE_SAMPLER_STATE_POINTERS_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_URB_VS\", OP_3DSTATE_URB_VS, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"3DSTATE_URB_HS\", OP_3DSTATE_URB_HS, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"3DSTATE_URB_DS\", OP_3DSTATE_URB_DS, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"3DSTATE_URB_GS\", OP_3DSTATE_URB_GS, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"3DSTATE_GATHER_CONSTANT_VS\", OP_3DSTATE_GATHER_CONSTANT_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_GATHER_CONSTANT_GS\", OP_3DSTATE_GATHER_CONSTANT_GS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_GATHER_CONSTANT_HS\", OP_3DSTATE_GATHER_CONSTANT_HS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_GATHER_CONSTANT_DS\", OP_3DSTATE_GATHER_CONSTANT_DS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_GATHER_CONSTANT_PS\", OP_3DSTATE_GATHER_CONSTANT_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_CONSTANTF_VS\", OP_3DSTATE_DX9_CONSTANTF_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 11, NULL},\n\n\t{\"3DSTATE_DX9_CONSTANTF_PS\", OP_3DSTATE_DX9_CONSTANTF_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 11, NULL},\n\n\t{\"3DSTATE_DX9_CONSTANTI_VS\", OP_3DSTATE_DX9_CONSTANTI_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_CONSTANTI_PS\", OP_3DSTATE_DX9_CONSTANTI_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_CONSTANTB_VS\", OP_3DSTATE_DX9_CONSTANTB_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_CONSTANTB_PS\", OP_3DSTATE_DX9_CONSTANTB_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_LOCAL_VALID_VS\", OP_3DSTATE_DX9_LOCAL_VALID_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_LOCAL_VALID_PS\", OP_3DSTATE_DX9_LOCAL_VALID_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_GENERATE_ACTIVE_VS\", OP_3DSTATE_DX9_GENERATE_ACTIVE_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DX9_GENERATE_ACTIVE_PS\", OP_3DSTATE_DX9_GENERATE_ACTIVE_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_EDIT_VS\", OP_3DSTATE_BINDING_TABLE_EDIT_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 9, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_EDIT_GS\", OP_3DSTATE_BINDING_TABLE_EDIT_GS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 9, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_EDIT_HS\", OP_3DSTATE_BINDING_TABLE_EDIT_HS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 9, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_EDIT_DS\", OP_3DSTATE_BINDING_TABLE_EDIT_DS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 9, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_EDIT_PS\", OP_3DSTATE_BINDING_TABLE_EDIT_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 9, NULL},\n\n\t{\"3DSTATE_VF_INSTANCING\", OP_3DSTATE_VF_INSTANCING, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_VF_SGVS\", OP_3DSTATE_VF_SGVS, F_LEN_VAR, R_RCS, D_BDW_PLUS, 0, 8,\n\t\tNULL},\n\n\t{\"3DSTATE_VF_TOPOLOGY\", OP_3DSTATE_VF_TOPOLOGY, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_WM_CHROMAKEY\", OP_3DSTATE_WM_CHROMAKEY, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_PS_BLEND\", OP_3DSTATE_PS_BLEND, F_LEN_VAR, R_RCS, D_BDW_PLUS, 0,\n\t\t8, NULL},\n\n\t{\"3DSTATE_WM_DEPTH_STENCIL\", OP_3DSTATE_WM_DEPTH_STENCIL, F_LEN_VAR,\n\t\tR_RCS, D_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_PS_EXTRA\", OP_3DSTATE_PS_EXTRA, F_LEN_VAR, R_RCS, D_BDW_PLUS, 0,\n\t\t8, NULL},\n\n\t{\"3DSTATE_RASTER\", OP_3DSTATE_RASTER, F_LEN_VAR, R_RCS, D_BDW_PLUS, 0, 8,\n\t\tNULL},\n\n\t{\"3DSTATE_SBE_SWIZ\", OP_3DSTATE_SBE_SWIZ, F_LEN_VAR, R_RCS, D_BDW_PLUS, 0, 8,\n\t\tNULL},\n\n\t{\"3DSTATE_WM_HZ_OP\", OP_3DSTATE_WM_HZ_OP, F_LEN_VAR, R_RCS, D_BDW_PLUS, 0, 8,\n\t\tNULL},\n\n\t{\"3DSTATE_VERTEX_BUFFERS\", OP_3DSTATE_VERTEX_BUFFERS, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_VERTEX_ELEMENTS\", OP_3DSTATE_VERTEX_ELEMENTS, F_LEN_VAR,\n\t\tR_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_INDEX_BUFFER\", OP_3DSTATE_INDEX_BUFFER, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, ADDR_FIX_1(2), 8, NULL},\n\n\t{\"3DSTATE_VF_STATISTICS\", OP_3DSTATE_VF_STATISTICS, F_LEN_CONST,\n\t\tR_RCS, D_ALL, 0, 1, NULL},\n\n\t{\"3DSTATE_VF\", OP_3DSTATE_VF, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_CC_STATE_POINTERS\", OP_3DSTATE_CC_STATE_POINTERS, F_LEN_VAR,\n\t\tR_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SCISSOR_STATE_POINTERS\", OP_3DSTATE_SCISSOR_STATE_POINTERS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_GS\", OP_3DSTATE_GS, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_CLIP\", OP_3DSTATE_CLIP, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_WM\", OP_3DSTATE_WM, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_CONSTANT_GS\", OP_3DSTATE_CONSTANT_GS, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_CONSTANT_PS\", OP_3DSTATE_CONSTANT_PS, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLE_MASK\", OP_3DSTATE_SAMPLE_MASK, F_LEN_VAR, R_RCS,\n\t\tD_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_CONSTANT_HS\", OP_3DSTATE_CONSTANT_HS, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_CONSTANT_DS\", OP_3DSTATE_CONSTANT_DS, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_HS\", OP_3DSTATE_HS, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_TE\", OP_3DSTATE_TE, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DS\", OP_3DSTATE_DS, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_STREAMOUT\", OP_3DSTATE_STREAMOUT, F_LEN_VAR, R_RCS,\n\t\tD_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SBE\", OP_3DSTATE_SBE, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_PS\", OP_3DSTATE_PS, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_DRAWING_RECTANGLE\", OP_3DSTATE_DRAWING_RECTANGLE, F_LEN_VAR,\n\t\tR_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLER_PALETTE_LOAD0\", OP_3DSTATE_SAMPLER_PALETTE_LOAD0,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_CHROMA_KEY\", OP_3DSTATE_CHROMA_KEY, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"3DSTATE_DEPTH_BUFFER\", OP_3DSTATE_DEPTH_BUFFER, F_LEN_VAR, R_RCS,\n\t\tD_ALL, ADDR_FIX_1(2), 8, NULL},\n\n\t{\"3DSTATE_POLY_STIPPLE_OFFSET\", OP_3DSTATE_POLY_STIPPLE_OFFSET,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_POLY_STIPPLE_PATTERN\", OP_3DSTATE_POLY_STIPPLE_PATTERN,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_LINE_STIPPLE\", OP_3DSTATE_LINE_STIPPLE, F_LEN_VAR, R_RCS,\n\t\tD_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_AA_LINE_PARAMS\", OP_3DSTATE_AA_LINE_PARAMS, F_LEN_VAR, R_RCS,\n\t\tD_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_GS_SVB_INDEX\", OP_3DSTATE_GS_SVB_INDEX, F_LEN_VAR, R_RCS,\n\t\tD_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SAMPLER_PALETTE_LOAD1\", OP_3DSTATE_SAMPLER_PALETTE_LOAD1,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_MULTISAMPLE\", OP_3DSTATE_MULTISAMPLE_BDW, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"3DSTATE_STENCIL_BUFFER\", OP_3DSTATE_STENCIL_BUFFER, F_LEN_VAR, R_RCS,\n\t\tD_ALL, ADDR_FIX_1(2), 8, NULL},\n\n\t{\"3DSTATE_HIER_DEPTH_BUFFER\", OP_3DSTATE_HIER_DEPTH_BUFFER, F_LEN_VAR,\n\t\tR_RCS, D_ALL, ADDR_FIX_1(2), 8, NULL},\n\n\t{\"3DSTATE_CLEAR_PARAMS\", OP_3DSTATE_CLEAR_PARAMS, F_LEN_VAR,\n\t\tR_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_PUSH_CONSTANT_ALLOC_VS\", OP_3DSTATE_PUSH_CONSTANT_ALLOC_VS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_PUSH_CONSTANT_ALLOC_HS\", OP_3DSTATE_PUSH_CONSTANT_ALLOC_HS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_PUSH_CONSTANT_ALLOC_DS\", OP_3DSTATE_PUSH_CONSTANT_ALLOC_DS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_PUSH_CONSTANT_ALLOC_GS\", OP_3DSTATE_PUSH_CONSTANT_ALLOC_GS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_PUSH_CONSTANT_ALLOC_PS\", OP_3DSTATE_PUSH_CONSTANT_ALLOC_PS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_MONOFILTER_SIZE\", OP_3DSTATE_MONOFILTER_SIZE, F_LEN_VAR,\n\t\tR_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SO_DECL_LIST\", OP_3DSTATE_SO_DECL_LIST, F_LEN_VAR, R_RCS,\n\t\tD_ALL, 0, 9, NULL},\n\n\t{\"3DSTATE_SO_BUFFER\", OP_3DSTATE_SO_BUFFER, F_LEN_VAR, R_RCS, D_BDW_PLUS,\n\t\tADDR_FIX_2(2, 4), 8, NULL},\n\n\t{\"3DSTATE_BINDING_TABLE_POOL_ALLOC\",\n\t\tOP_3DSTATE_BINDING_TABLE_POOL_ALLOC,\n\t\tF_LEN_VAR, R_RCS, D_BDW_PLUS, ADDR_FIX_1(1), 8, NULL},\n\n\t{\"3DSTATE_GATHER_POOL_ALLOC\", OP_3DSTATE_GATHER_POOL_ALLOC,\n\t\tF_LEN_VAR, R_RCS, D_BDW_PLUS, ADDR_FIX_1(1), 8, NULL},\n\n\t{\"3DSTATE_DX9_CONSTANT_BUFFER_POOL_ALLOC\",\n\t\tOP_3DSTATE_DX9_CONSTANT_BUFFER_POOL_ALLOC,\n\t\tF_LEN_VAR, R_RCS, D_BDW_PLUS, ADDR_FIX_1(1), 8, NULL},\n\n\t{\"3DSTATE_SAMPLE_PATTERN\", OP_3DSTATE_SAMPLE_PATTERN, F_LEN_VAR, R_RCS,\n\t\tD_BDW_PLUS, 0, 8, NULL},\n\n\t{\"PIPE_CONTROL\", OP_PIPE_CONTROL, F_LEN_VAR, R_RCS, D_ALL,\n\t\tADDR_FIX_1(2), 8, cmd_handler_pipe_control},\n\n\t{\"3DPRIMITIVE\", OP_3DPRIMITIVE, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"PIPELINE_SELECT\", OP_PIPELINE_SELECT, F_LEN_CONST, R_RCS, D_ALL, 0,\n\t\t1, NULL},\n\n\t{\"STATE_PREFETCH\", OP_STATE_PREFETCH, F_LEN_VAR, R_RCS, D_ALL,\n\t\tADDR_FIX_1(1), 8, NULL},\n\n\t{\"STATE_SIP\", OP_STATE_SIP, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"STATE_BASE_ADDRESS\", OP_STATE_BASE_ADDRESS, F_LEN_VAR, R_RCS, D_BDW_PLUS,\n\t\tADDR_FIX_5(1, 3, 4, 5, 6), 8, NULL},\n\n\t{\"OP_3D_MEDIA_0_1_4\", OP_3D_MEDIA_0_1_4, F_LEN_VAR, R_RCS, D_ALL,\n\t\tADDR_FIX_1(1), 8, NULL},\n\n\t{\"OP_SWTESS_BASE_ADDRESS\", OP_SWTESS_BASE_ADDRESS,\n\t\tF_LEN_VAR, R_RCS, D_ALL, ADDR_FIX_2(1, 2), 3, NULL},\n\n\t{\"3DSTATE_VS\", OP_3DSTATE_VS, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_SF\", OP_3DSTATE_SF, F_LEN_VAR, R_RCS, D_ALL, 0, 8, NULL},\n\n\t{\"3DSTATE_CONSTANT_VS\", OP_3DSTATE_CONSTANT_VS, F_LEN_VAR, R_RCS, D_BDW_PLUS,\n\t\t0, 8, NULL},\n\n\t{\"3DSTATE_COMPONENT_PACKING\", OP_3DSTATE_COMPONENT_PACKING, F_LEN_VAR, R_RCS,\n\t\tD_SKL_PLUS, 0, 8, NULL},\n\n\t{\"MEDIA_INTERFACE_DESCRIPTOR_LOAD\", OP_MEDIA_INTERFACE_DESCRIPTOR_LOAD,\n\t\tF_LEN_VAR, R_RCS, D_ALL, 0, 16, NULL},\n\n\t{\"MEDIA_GATEWAY_STATE\", OP_MEDIA_GATEWAY_STATE, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 16, NULL},\n\n\t{\"MEDIA_STATE_FLUSH\", OP_MEDIA_STATE_FLUSH, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 16, NULL},\n\n\t{\"MEDIA_POOL_STATE\", OP_MEDIA_POOL_STATE, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 16, NULL},\n\n\t{\"MEDIA_OBJECT\", OP_MEDIA_OBJECT, F_LEN_VAR, R_RCS, D_ALL, 0, 16, NULL},\n\n\t{\"MEDIA_CURBE_LOAD\", OP_MEDIA_CURBE_LOAD, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 16, NULL},\n\n\t{\"MEDIA_OBJECT_PRT\", OP_MEDIA_OBJECT_PRT, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 16, NULL},\n\n\t{\"MEDIA_OBJECT_WALKER\", OP_MEDIA_OBJECT_WALKER, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 16, NULL},\n\n\t{\"GPGPU_WALKER\", OP_GPGPU_WALKER, F_LEN_VAR, R_RCS, D_ALL,\n\t\t0, 8, NULL},\n\n\t{\"MEDIA_VFE_STATE\", OP_MEDIA_VFE_STATE, F_LEN_VAR, R_RCS, D_ALL, 0, 16,\n\t\tNULL},\n\n\t{\"3DSTATE_VF_STATISTICS_GM45\", OP_3DSTATE_VF_STATISTICS_GM45,\n\t\tF_LEN_CONST, R_ALL, D_ALL, 0, 1, NULL},\n\n\t{\"MFX_PIPE_MODE_SELECT\", OP_MFX_PIPE_MODE_SELECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_SURFACE_STATE\", OP_MFX_SURFACE_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_PIPE_BUF_ADDR_STATE\", OP_MFX_PIPE_BUF_ADDR_STATE, F_LEN_VAR,\n\t\tR_VCS, D_BDW_PLUS, 0, 12, NULL},\n\n\t{\"MFX_IND_OBJ_BASE_ADDR_STATE\", OP_MFX_IND_OBJ_BASE_ADDR_STATE,\n\t\tF_LEN_VAR, R_VCS, D_BDW_PLUS, 0, 12, NULL},\n\n\t{\"MFX_BSP_BUF_BASE_ADDR_STATE\", OP_MFX_BSP_BUF_BASE_ADDR_STATE,\n\t\tF_LEN_VAR, R_VCS, D_BDW_PLUS, ADDR_FIX_3(1, 3, 5), 12, NULL},\n\n\t{\"OP_2_0_0_5\", OP_2_0_0_5, F_LEN_VAR, R_VCS, D_BDW_PLUS, 0, 12, NULL},\n\n\t{\"MFX_STATE_POINTER\", OP_MFX_STATE_POINTER, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_QM_STATE\", OP_MFX_QM_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_FQM_STATE\", OP_MFX_FQM_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_PAK_INSERT_OBJECT\", OP_MFX_PAK_INSERT_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_STITCH_OBJECT\", OP_MFX_STITCH_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_IT_OBJECT\", OP_MFD_IT_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_WAIT\", OP_MFX_WAIT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 6, NULL},\n\n\t{\"MFX_AVC_IMG_STATE\", OP_MFX_AVC_IMG_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_AVC_QM_STATE\", OP_MFX_AVC_QM_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_AVC_DIRECTMODE_STATE\", OP_MFX_AVC_DIRECTMODE_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_AVC_SLICE_STATE\", OP_MFX_AVC_SLICE_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_AVC_REF_IDX_STATE\", OP_MFX_AVC_REF_IDX_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_AVC_WEIGHTOFFSET_STATE\", OP_MFX_AVC_WEIGHTOFFSET_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_AVC_PICID_STATE\", OP_MFD_AVC_PICID_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\t{\"MFD_AVC_DPB_STATE\", OP_MFD_AVC_DPB_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_AVC_BSD_OBJECT\", OP_MFD_AVC_BSD_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_AVC_SLICEADDR\", OP_MFD_AVC_SLICEADDR, F_LEN_VAR,\n\t\tR_VCS, D_ALL, ADDR_FIX_1(2), 12, NULL},\n\n\t{\"MFC_AVC_PAK_OBJECT\", OP_MFC_AVC_PAK_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_VC1_PRED_PIPE_STATE\", OP_MFX_VC1_PRED_PIPE_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_VC1_DIRECTMODE_STATE\", OP_MFX_VC1_DIRECTMODE_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_VC1_SHORT_PIC_STATE\", OP_MFD_VC1_SHORT_PIC_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_VC1_LONG_PIC_STATE\", OP_MFD_VC1_LONG_PIC_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_VC1_BSD_OBJECT\", OP_MFD_VC1_BSD_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFC_MPEG2_SLICEGROUP_STATE\", OP_MFC_MPEG2_SLICEGROUP_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFC_MPEG2_PAK_OBJECT\", OP_MFC_MPEG2_PAK_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_MPEG2_PIC_STATE\", OP_MFX_MPEG2_PIC_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_MPEG2_QM_STATE\", OP_MFX_MPEG2_QM_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_MPEG2_BSD_OBJECT\", OP_MFD_MPEG2_BSD_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_2_6_0_0\", OP_MFX_2_6_0_0, F_LEN_VAR, R_VCS, D_ALL,\n\t\t0, 16, NULL},\n\n\t{\"MFX_2_6_0_9\", OP_MFX_2_6_0_9, F_LEN_VAR, R_VCS, D_ALL, 0, 16, NULL},\n\n\t{\"MFX_2_6_0_8\", OP_MFX_2_6_0_8, F_LEN_VAR, R_VCS, D_ALL, 0, 16, NULL},\n\n\t{\"MFX_JPEG_PIC_STATE\", OP_MFX_JPEG_PIC_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFX_JPEG_HUFF_TABLE_STATE\", OP_MFX_JPEG_HUFF_TABLE_STATE, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"MFD_JPEG_BSD_OBJECT\", OP_MFD_JPEG_BSD_OBJECT, F_LEN_VAR,\n\t\tR_VCS, D_ALL, 0, 12, NULL},\n\n\t{\"VEBOX_STATE\", OP_VEB_STATE, F_LEN_VAR, R_VECS, D_ALL, 0, 12, NULL},\n\n\t{\"VEBOX_SURFACE_STATE\", OP_VEB_SURFACE_STATE, F_LEN_VAR, R_VECS, D_ALL,\n\t\t0, 12, NULL},\n\n\t{\"VEB_DI_IECP\", OP_VEB_DNDI_IECP_STATE, F_LEN_VAR, R_VECS, D_BDW_PLUS,\n\t\t0, 12, NULL},\n};\n\nstatic void add_cmd_entry(struct intel_gvt *gvt, struct cmd_entry *e)\n{\n\thash_add(gvt->cmd_table, &e->hlist, e->info->opcode);\n}\n\n \nstatic int cmd_parser_exec(struct parser_exec_state *s)\n{\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\tconst struct cmd_info *info;\n\tu32 cmd;\n\tint ret = 0;\n\n\tcmd = cmd_val(s, 0);\n\n\t \n\tif (cmd == MI_NOOP)\n\t\tinfo = &cmd_info[mi_noop_index];\n\telse\n\t\tinfo = get_cmd_info(s->vgpu->gvt, cmd, s->engine);\n\n\tif (info == NULL) {\n\t\tgvt_vgpu_err(\"unknown cmd 0x%x, opcode=0x%x, addr_type=%s, ring %s, workload=%p\\n\",\n\t\t\t     cmd, get_opcode(cmd, s->engine),\n\t\t\t     repr_addr_type(s->buf_addr_type),\n\t\t\t     s->engine->name, s->workload);\n\t\treturn -EBADRQC;\n\t}\n\n\ts->info = info;\n\n\ttrace_gvt_command(vgpu->id, s->engine->id, s->ip_gma, s->ip_va,\n\t\t\t  cmd_length(s), s->buf_type, s->buf_addr_type,\n\t\t\t  s->workload, info->name);\n\n\tif ((info->flag & F_LEN_MASK) == F_LEN_VAR_FIXED) {\n\t\tret = gvt_check_valid_cmd_length(cmd_length(s),\n\t\t\t\t\t\t info->valid_len);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (info->handler) {\n\t\tret = info->handler(s);\n\t\tif (ret < 0) {\n\t\t\tgvt_vgpu_err(\"%s handler error\\n\", info->name);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (!(info->flag & F_IP_ADVANCE_CUSTOM)) {\n\t\tret = cmd_advance_default(s);\n\t\tif (ret) {\n\t\t\tgvt_vgpu_err(\"%s IP advance error\\n\", info->name);\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic inline bool gma_out_of_range(unsigned long gma,\n\t\tunsigned long gma_head, unsigned int gma_tail)\n{\n\tif (gma_tail >= gma_head)\n\t\treturn (gma < gma_head) || (gma > gma_tail);\n\telse\n\t\treturn (gma > gma_tail) && (gma < gma_head);\n}\n\n \nstatic int command_scan(struct parser_exec_state *s,\n\t\tunsigned long rb_head, unsigned long rb_tail,\n\t\tunsigned long rb_start, unsigned long rb_len)\n{\n\n\tunsigned long gma_head, gma_tail, gma_bottom;\n\tint ret = 0;\n\tstruct intel_vgpu *vgpu = s->vgpu;\n\n\tgma_head = rb_start + rb_head;\n\tgma_tail = rb_start + rb_tail;\n\tgma_bottom = rb_start +  rb_len;\n\n\twhile (s->ip_gma != gma_tail) {\n\t\tif (s->buf_type == RING_BUFFER_INSTRUCTION ||\n\t\t\t\ts->buf_type == RING_BUFFER_CTX) {\n\t\t\tif (!(s->ip_gma >= rb_start) ||\n\t\t\t\t!(s->ip_gma < gma_bottom)) {\n\t\t\t\tgvt_vgpu_err(\"ip_gma %lx out of ring scope.\"\n\t\t\t\t\t\"(base:0x%lx, bottom: 0x%lx)\\n\",\n\t\t\t\t\ts->ip_gma, rb_start,\n\t\t\t\t\tgma_bottom);\n\t\t\t\tparser_exec_state_dump(s);\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\tif (gma_out_of_range(s->ip_gma, gma_head, gma_tail)) {\n\t\t\t\tgvt_vgpu_err(\"ip_gma %lx out of range.\"\n\t\t\t\t\t\"base 0x%lx head 0x%lx tail 0x%lx\\n\",\n\t\t\t\t\ts->ip_gma, rb_start,\n\t\t\t\t\trb_head, rb_tail);\n\t\t\t\tparser_exec_state_dump(s);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tret = cmd_parser_exec(s);\n\t\tif (ret) {\n\t\t\tgvt_vgpu_err(\"cmd parser error\\n\");\n\t\t\tparser_exec_state_dump(s);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int scan_workload(struct intel_vgpu_workload *workload)\n{\n\tunsigned long gma_head, gma_tail;\n\tstruct parser_exec_state s;\n\tint ret = 0;\n\n\t \n\tif (WARN_ON(!IS_ALIGNED(workload->rb_start, I915_GTT_PAGE_SIZE)))\n\t\treturn -EINVAL;\n\n\tgma_head = workload->rb_start + workload->rb_head;\n\tgma_tail = workload->rb_start + workload->rb_tail;\n\n\ts.buf_type = RING_BUFFER_INSTRUCTION;\n\ts.buf_addr_type = GTT_BUFFER;\n\ts.vgpu = workload->vgpu;\n\ts.engine = workload->engine;\n\ts.ring_start = workload->rb_start;\n\ts.ring_size = _RING_CTL_BUF_SIZE(workload->rb_ctl);\n\ts.ring_head = gma_head;\n\ts.ring_tail = gma_tail;\n\ts.rb_va = workload->shadow_ring_buffer_va;\n\ts.workload = workload;\n\ts.is_ctx_wa = false;\n\n\tif (bypass_scan_mask & workload->engine->mask || gma_head == gma_tail)\n\t\treturn 0;\n\n\tret = ip_gma_set(&s, gma_head);\n\tif (ret)\n\t\tgoto out;\n\n\tret = command_scan(&s, workload->rb_head, workload->rb_tail,\n\t\tworkload->rb_start, _RING_CTL_BUF_SIZE(workload->rb_ctl));\n\nout:\n\treturn ret;\n}\n\nstatic int scan_wa_ctx(struct intel_shadow_wa_ctx *wa_ctx)\n{\n\n\tunsigned long gma_head, gma_tail, ring_size, ring_tail;\n\tstruct parser_exec_state s;\n\tint ret = 0;\n\tstruct intel_vgpu_workload *workload = container_of(wa_ctx,\n\t\t\t\tstruct intel_vgpu_workload,\n\t\t\t\twa_ctx);\n\n\t \n\tif (WARN_ON(!IS_ALIGNED(wa_ctx->indirect_ctx.guest_gma,\n\t\t\t\t\tI915_GTT_PAGE_SIZE)))\n\t\treturn -EINVAL;\n\n\tring_tail = wa_ctx->indirect_ctx.size + 3 * sizeof(u32);\n\tring_size = round_up(wa_ctx->indirect_ctx.size + CACHELINE_BYTES,\n\t\t\tPAGE_SIZE);\n\tgma_head = wa_ctx->indirect_ctx.guest_gma;\n\tgma_tail = wa_ctx->indirect_ctx.guest_gma + ring_tail;\n\n\ts.buf_type = RING_BUFFER_INSTRUCTION;\n\ts.buf_addr_type = GTT_BUFFER;\n\ts.vgpu = workload->vgpu;\n\ts.engine = workload->engine;\n\ts.ring_start = wa_ctx->indirect_ctx.guest_gma;\n\ts.ring_size = ring_size;\n\ts.ring_head = gma_head;\n\ts.ring_tail = gma_tail;\n\ts.rb_va = wa_ctx->indirect_ctx.shadow_va;\n\ts.workload = workload;\n\ts.is_ctx_wa = true;\n\n\tret = ip_gma_set(&s, gma_head);\n\tif (ret)\n\t\tgoto out;\n\n\tret = command_scan(&s, 0, ring_tail,\n\t\twa_ctx->indirect_ctx.guest_gma, ring_size);\nout:\n\treturn ret;\n}\n\nstatic int shadow_workload_ring_buffer(struct intel_vgpu_workload *workload)\n{\n\tstruct intel_vgpu *vgpu = workload->vgpu;\n\tstruct intel_vgpu_submission *s = &vgpu->submission;\n\tunsigned long gma_head, gma_tail, gma_top, guest_rb_size;\n\tvoid *shadow_ring_buffer_va;\n\tint ret;\n\n\tguest_rb_size = _RING_CTL_BUF_SIZE(workload->rb_ctl);\n\n\t \n\tworkload->rb_len = (workload->rb_tail + guest_rb_size -\n\t\t\tworkload->rb_head) % guest_rb_size;\n\n\tgma_head = workload->rb_start + workload->rb_head;\n\tgma_tail = workload->rb_start + workload->rb_tail;\n\tgma_top = workload->rb_start + guest_rb_size;\n\n\tif (workload->rb_len > s->ring_scan_buffer_size[workload->engine->id]) {\n\t\tvoid *p;\n\n\t\t \n\t\tp = krealloc(s->ring_scan_buffer[workload->engine->id],\n\t\t\t     workload->rb_len, GFP_KERNEL);\n\t\tif (!p) {\n\t\t\tgvt_vgpu_err(\"fail to re-alloc ring scan buffer\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\ts->ring_scan_buffer[workload->engine->id] = p;\n\t\ts->ring_scan_buffer_size[workload->engine->id] = workload->rb_len;\n\t}\n\n\tshadow_ring_buffer_va = s->ring_scan_buffer[workload->engine->id];\n\n\t \n\tworkload->shadow_ring_buffer_va = shadow_ring_buffer_va;\n\n\t \n\tif (gma_head > gma_tail) {\n\t\tret = copy_gma_to_hva(vgpu, vgpu->gtt.ggtt_mm,\n\t\t\t\t      gma_head, gma_top, shadow_ring_buffer_va);\n\t\tif (ret < 0) {\n\t\t\tgvt_vgpu_err(\"fail to copy guest ring buffer\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tshadow_ring_buffer_va += ret;\n\t\tgma_head = workload->rb_start;\n\t}\n\n\t \n\tret = copy_gma_to_hva(vgpu, vgpu->gtt.ggtt_mm, gma_head, gma_tail,\n\t\t\t\tshadow_ring_buffer_va);\n\tif (ret < 0) {\n\t\tgvt_vgpu_err(\"fail to copy guest ring buffer\\n\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nint intel_gvt_scan_and_shadow_ringbuffer(struct intel_vgpu_workload *workload)\n{\n\tint ret;\n\tstruct intel_vgpu *vgpu = workload->vgpu;\n\n\tret = shadow_workload_ring_buffer(workload);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"fail to shadow workload ring_buffer\\n\");\n\t\treturn ret;\n\t}\n\n\tret = scan_workload(workload);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"scan workload error\\n\");\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int shadow_indirect_ctx(struct intel_shadow_wa_ctx *wa_ctx)\n{\n\tint ctx_size = wa_ctx->indirect_ctx.size;\n\tunsigned long guest_gma = wa_ctx->indirect_ctx.guest_gma;\n\tstruct intel_vgpu_workload *workload = container_of(wa_ctx,\n\t\t\t\t\tstruct intel_vgpu_workload,\n\t\t\t\t\twa_ctx);\n\tstruct intel_vgpu *vgpu = workload->vgpu;\n\tstruct drm_i915_gem_object *obj;\n\tint ret = 0;\n\tvoid *map;\n\n\tobj = i915_gem_object_create_shmem(workload->engine->i915,\n\t\t\t\t\t   roundup(ctx_size + CACHELINE_BYTES,\n\t\t\t\t\t\t   PAGE_SIZE));\n\tif (IS_ERR(obj))\n\t\treturn PTR_ERR(obj);\n\n\t \n\tmap = i915_gem_object_pin_map(obj, I915_MAP_WB);\n\tif (IS_ERR(map)) {\n\t\tgvt_vgpu_err(\"failed to vmap shadow indirect ctx\\n\");\n\t\tret = PTR_ERR(map);\n\t\tgoto put_obj;\n\t}\n\n\ti915_gem_object_lock(obj, NULL);\n\tret = i915_gem_object_set_to_cpu_domain(obj, false);\n\ti915_gem_object_unlock(obj);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"failed to set shadow indirect ctx to CPU\\n\");\n\t\tgoto unmap_src;\n\t}\n\n\tret = copy_gma_to_hva(workload->vgpu,\n\t\t\t\tworkload->vgpu->gtt.ggtt_mm,\n\t\t\t\tguest_gma, guest_gma + ctx_size,\n\t\t\t\tmap);\n\tif (ret < 0) {\n\t\tgvt_vgpu_err(\"fail to copy guest indirect ctx\\n\");\n\t\tgoto unmap_src;\n\t}\n\n\twa_ctx->indirect_ctx.obj = obj;\n\twa_ctx->indirect_ctx.shadow_va = map;\n\treturn 0;\n\nunmap_src:\n\ti915_gem_object_unpin_map(obj);\nput_obj:\n\ti915_gem_object_put(obj);\n\treturn ret;\n}\n\nstatic int combine_wa_ctx(struct intel_shadow_wa_ctx *wa_ctx)\n{\n\tu32 per_ctx_start[CACHELINE_DWORDS] = {0};\n\tunsigned char *bb_start_sva;\n\n\tif (!wa_ctx->per_ctx.valid)\n\t\treturn 0;\n\n\tper_ctx_start[0] = 0x18800001;\n\tper_ctx_start[1] = wa_ctx->per_ctx.guest_gma;\n\n\tbb_start_sva = (unsigned char *)wa_ctx->indirect_ctx.shadow_va +\n\t\t\t\twa_ctx->indirect_ctx.size;\n\n\tmemcpy(bb_start_sva, per_ctx_start, CACHELINE_BYTES);\n\n\treturn 0;\n}\n\nint intel_gvt_scan_and_shadow_wa_ctx(struct intel_shadow_wa_ctx *wa_ctx)\n{\n\tint ret;\n\tstruct intel_vgpu_workload *workload = container_of(wa_ctx,\n\t\t\t\t\tstruct intel_vgpu_workload,\n\t\t\t\t\twa_ctx);\n\tstruct intel_vgpu *vgpu = workload->vgpu;\n\n\tif (wa_ctx->indirect_ctx.size == 0)\n\t\treturn 0;\n\n\tret = shadow_indirect_ctx(wa_ctx);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"fail to shadow indirect ctx\\n\");\n\t\treturn ret;\n\t}\n\n\tcombine_wa_ctx(wa_ctx);\n\n\tret = scan_wa_ctx(wa_ctx);\n\tif (ret) {\n\t\tgvt_vgpu_err(\"scan wa ctx error\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nvoid intel_gvt_update_reg_whitelist(struct intel_vgpu *vgpu)\n{\n\tconst unsigned long start = LRC_STATE_PN * PAGE_SIZE;\n\tstruct intel_gvt *gvt = vgpu->gvt;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\tif (gvt->is_reg_whitelist_updated)\n\t\treturn;\n\n\t \n\tfor_each_engine(engine, gvt->gt, id) {\n\t\tstruct parser_exec_state s;\n\t\tvoid *vaddr;\n\t\tint ret;\n\n\t\tif (!engine->default_state)\n\t\t\tcontinue;\n\n\t\tvaddr = shmem_pin_map(engine->default_state);\n\t\tif (!vaddr) {\n\t\t\tgvt_err(\"failed to map %s->default state\\n\",\n\t\t\t\tengine->name);\n\t\t\treturn;\n\t\t}\n\n\t\ts.buf_type = RING_BUFFER_CTX;\n\t\ts.buf_addr_type = GTT_BUFFER;\n\t\ts.vgpu = vgpu;\n\t\ts.engine = engine;\n\t\ts.ring_start = 0;\n\t\ts.ring_size = engine->context_size - start;\n\t\ts.ring_head = 0;\n\t\ts.ring_tail = s.ring_size;\n\t\ts.rb_va = vaddr + start;\n\t\ts.workload = NULL;\n\t\ts.is_ctx_wa = false;\n\t\ts.is_init_ctx = true;\n\n\t\t \n\t\tret = ip_gma_set(&s, RING_CTX_SIZE);\n\t\tif (ret == 0) {\n\t\t\tret = command_scan(&s, 0, s.ring_size, 0, s.ring_size);\n\t\t\tif (ret)\n\t\t\t\tgvt_err(\"Scan init ctx error\\n\");\n\t\t}\n\n\t\tshmem_unpin_map(engine->default_state, vaddr);\n\t\tif (ret)\n\t\t\treturn;\n\t}\n\n\tgvt->is_reg_whitelist_updated = true;\n}\n\nint intel_gvt_scan_engine_context(struct intel_vgpu_workload *workload)\n{\n\tstruct intel_vgpu *vgpu = workload->vgpu;\n\tunsigned long gma_head, gma_tail, gma_start, ctx_size;\n\tstruct parser_exec_state s;\n\tint ring_id = workload->engine->id;\n\tstruct intel_context *ce = vgpu->submission.shadow[ring_id];\n\tint ret;\n\n\tGEM_BUG_ON(atomic_read(&ce->pin_count) < 0);\n\n\tctx_size = workload->engine->context_size - PAGE_SIZE;\n\n\t \n\tif (is_inhibit_context(ce))\n\t\treturn 0;\n\n\tgma_start = i915_ggtt_offset(ce->state) + LRC_STATE_PN*PAGE_SIZE;\n\tgma_head = 0;\n\tgma_tail = ctx_size;\n\n\ts.buf_type = RING_BUFFER_CTX;\n\ts.buf_addr_type = GTT_BUFFER;\n\ts.vgpu = workload->vgpu;\n\ts.engine = workload->engine;\n\ts.ring_start = gma_start;\n\ts.ring_size = ctx_size;\n\ts.ring_head = gma_start + gma_head;\n\ts.ring_tail = gma_start + gma_tail;\n\ts.rb_va = ce->lrc_reg_state;\n\ts.workload = workload;\n\ts.is_ctx_wa = false;\n\ts.is_init_ctx = false;\n\n\t \n\tret = ip_gma_set(&s, gma_start + gma_head + RING_CTX_SIZE);\n\tif (ret)\n\t\tgoto out;\n\n\tret = command_scan(&s, gma_head, gma_tail,\n\t\tgma_start, ctx_size);\nout:\n\tif (ret)\n\t\tgvt_vgpu_err(\"scan shadow ctx error\\n\");\n\n\treturn ret;\n}\n\nstatic int init_cmd_table(struct intel_gvt *gvt)\n{\n\tunsigned int gen_type = intel_gvt_get_device_type(gvt);\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(cmd_info); i++) {\n\t\tstruct cmd_entry *e;\n\n\t\tif (!(cmd_info[i].devices & gen_type))\n\t\t\tcontinue;\n\n\t\te = kzalloc(sizeof(*e), GFP_KERNEL);\n\t\tif (!e)\n\t\t\treturn -ENOMEM;\n\n\t\te->info = &cmd_info[i];\n\t\tif (cmd_info[i].opcode == OP_MI_NOOP)\n\t\t\tmi_noop_index = i;\n\n\t\tINIT_HLIST_NODE(&e->hlist);\n\t\tadd_cmd_entry(gvt, e);\n\t\tgvt_dbg_cmd(\"add %-30s op %04x flag %x devs %02x rings %02x\\n\",\n\t\t\t    e->info->name, e->info->opcode, e->info->flag,\n\t\t\t    e->info->devices, e->info->rings);\n\t}\n\n\treturn 0;\n}\n\nstatic void clean_cmd_table(struct intel_gvt *gvt)\n{\n\tstruct hlist_node *tmp;\n\tstruct cmd_entry *e;\n\tint i;\n\n\thash_for_each_safe(gvt->cmd_table, i, tmp, e, hlist)\n\t\tkfree(e);\n\n\thash_init(gvt->cmd_table);\n}\n\nvoid intel_gvt_clean_cmd_parser(struct intel_gvt *gvt)\n{\n\tclean_cmd_table(gvt);\n}\n\nint intel_gvt_init_cmd_parser(struct intel_gvt *gvt)\n{\n\tint ret;\n\n\tret = init_cmd_table(gvt);\n\tif (ret) {\n\t\tintel_gvt_clean_cmd_parser(gvt);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}