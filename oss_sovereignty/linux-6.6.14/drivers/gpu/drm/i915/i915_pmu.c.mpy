{
  "module_name": "i915_pmu.c",
  "hash_id": "1a84f2fb1d9e2ce7be3da9007aab50eb5e3d9cf652506cf3ac740628cd6e09b6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/i915_pmu.c",
  "human_readable_source": " \n\n#include <linux/pm_runtime.h>\n\n#include \"gt/intel_engine.h\"\n#include \"gt/intel_engine_pm.h\"\n#include \"gt/intel_engine_regs.h\"\n#include \"gt/intel_engine_user.h\"\n#include \"gt/intel_gt.h\"\n#include \"gt/intel_gt_pm.h\"\n#include \"gt/intel_gt_regs.h\"\n#include \"gt/intel_rc6.h\"\n#include \"gt/intel_rps.h\"\n\n#include \"i915_drv.h\"\n#include \"i915_pmu.h\"\n\n \n#define FREQUENCY 200\n#define PERIOD max_t(u64, 10000, NSEC_PER_SEC / FREQUENCY)\n\n#define ENGINE_SAMPLE_MASK \\\n\t(BIT(I915_SAMPLE_BUSY) | \\\n\t BIT(I915_SAMPLE_WAIT) | \\\n\t BIT(I915_SAMPLE_SEMA))\n\nstatic cpumask_t i915_pmu_cpumask;\nstatic unsigned int i915_pmu_target_cpu = -1;\n\nstatic u8 engine_config_sample(u64 config)\n{\n\treturn config & I915_PMU_SAMPLE_MASK;\n}\n\nstatic u8 engine_event_sample(struct perf_event *event)\n{\n\treturn engine_config_sample(event->attr.config);\n}\n\nstatic u8 engine_event_class(struct perf_event *event)\n{\n\treturn (event->attr.config >> I915_PMU_CLASS_SHIFT) & 0xff;\n}\n\nstatic u8 engine_event_instance(struct perf_event *event)\n{\n\treturn (event->attr.config >> I915_PMU_SAMPLE_BITS) & 0xff;\n}\n\nstatic bool is_engine_config(const u64 config)\n{\n\treturn config < __I915_PMU_OTHER(0);\n}\n\nstatic unsigned int config_gt_id(const u64 config)\n{\n\treturn config >> __I915_PMU_GT_SHIFT;\n}\n\nstatic u64 config_counter(const u64 config)\n{\n\treturn config & ~(~0ULL << __I915_PMU_GT_SHIFT);\n}\n\nstatic unsigned int other_bit(const u64 config)\n{\n\tunsigned int val;\n\n\tswitch (config_counter(config)) {\n\tcase I915_PMU_ACTUAL_FREQUENCY:\n\t\tval =  __I915_PMU_ACTUAL_FREQUENCY_ENABLED;\n\t\tbreak;\n\tcase I915_PMU_REQUESTED_FREQUENCY:\n\t\tval = __I915_PMU_REQUESTED_FREQUENCY_ENABLED;\n\t\tbreak;\n\tcase I915_PMU_RC6_RESIDENCY:\n\t\tval = __I915_PMU_RC6_RESIDENCY_ENABLED;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn -1;\n\t}\n\n\treturn I915_ENGINE_SAMPLE_COUNT +\n\t       config_gt_id(config) * __I915_PMU_TRACKED_EVENT_COUNT +\n\t       val;\n}\n\nstatic unsigned int config_bit(const u64 config)\n{\n\tif (is_engine_config(config))\n\t\treturn engine_config_sample(config);\n\telse\n\t\treturn other_bit(config);\n}\n\nstatic u32 config_mask(const u64 config)\n{\n\tunsigned int bit = config_bit(config);\n\n\tif (__builtin_constant_p(config))\n\t\tBUILD_BUG_ON(bit >\n\t\t\t     BITS_PER_TYPE(typeof_member(struct i915_pmu,\n\t\t\t\t\t\t\t enable)) - 1);\n\telse\n\t\tWARN_ON_ONCE(bit >\n\t\t\t     BITS_PER_TYPE(typeof_member(struct i915_pmu,\n\t\t\t\t\t\t\t enable)) - 1);\n\n\treturn BIT(config_bit(config));\n}\n\nstatic bool is_engine_event(struct perf_event *event)\n{\n\treturn is_engine_config(event->attr.config);\n}\n\nstatic unsigned int event_bit(struct perf_event *event)\n{\n\treturn config_bit(event->attr.config);\n}\n\nstatic u32 frequency_enabled_mask(void)\n{\n\tunsigned int i;\n\tu32 mask = 0;\n\n\tfor (i = 0; i < I915_PMU_MAX_GT; i++)\n\t\tmask |= config_mask(__I915_PMU_ACTUAL_FREQUENCY(i)) |\n\t\t\tconfig_mask(__I915_PMU_REQUESTED_FREQUENCY(i));\n\n\treturn mask;\n}\n\nstatic bool pmu_needs_timer(struct i915_pmu *pmu)\n{\n\tstruct drm_i915_private *i915 = container_of(pmu, typeof(*i915), pmu);\n\tu32 enable;\n\n\t \n\tenable = pmu->enable;\n\n\t \n\tenable &= frequency_enabled_mask() | ENGINE_SAMPLE_MASK;\n\n\t \n\tif (i915->caps.scheduler & I915_SCHEDULER_CAP_ENGINE_BUSY_STATS)\n\t\tenable &= ~BIT(I915_SAMPLE_BUSY);\n\n\t \n\treturn enable;\n}\n\nstatic u64 __get_rc6(struct intel_gt *gt)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tu64 val;\n\n\tval = intel_rc6_residency_ns(&gt->rc6, INTEL_RC6_RES_RC6);\n\n\tif (HAS_RC6p(i915))\n\t\tval += intel_rc6_residency_ns(&gt->rc6, INTEL_RC6_RES_RC6p);\n\n\tif (HAS_RC6pp(i915))\n\t\tval += intel_rc6_residency_ns(&gt->rc6, INTEL_RC6_RES_RC6pp);\n\n\treturn val;\n}\n\nstatic inline s64 ktime_since_raw(const ktime_t kt)\n{\n\treturn ktime_to_ns(ktime_sub(ktime_get_raw(), kt));\n}\n\nstatic u64 read_sample(struct i915_pmu *pmu, unsigned int gt_id, int sample)\n{\n\treturn pmu->sample[gt_id][sample].cur;\n}\n\nstatic void\nstore_sample(struct i915_pmu *pmu, unsigned int gt_id, int sample, u64 val)\n{\n\tpmu->sample[gt_id][sample].cur = val;\n}\n\nstatic void\nadd_sample_mult(struct i915_pmu *pmu, unsigned int gt_id, int sample, u32 val, u32 mul)\n{\n\tpmu->sample[gt_id][sample].cur += mul_u32_u32(val, mul);\n}\n\nstatic u64 get_rc6(struct intel_gt *gt)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tconst unsigned int gt_id = gt->info.id;\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tunsigned long flags;\n\tbool awake = false;\n\tu64 val;\n\n\tif (intel_gt_pm_get_if_awake(gt)) {\n\t\tval = __get_rc6(gt);\n\t\tintel_gt_pm_put_async(gt);\n\t\tawake = true;\n\t}\n\n\tspin_lock_irqsave(&pmu->lock, flags);\n\n\tif (awake) {\n\t\tstore_sample(pmu, gt_id, __I915_SAMPLE_RC6, val);\n\t} else {\n\t\t \n\t\tval = ktime_since_raw(pmu->sleep_last[gt_id]);\n\t\tval += read_sample(pmu, gt_id, __I915_SAMPLE_RC6);\n\t}\n\n\tif (val < read_sample(pmu, gt_id, __I915_SAMPLE_RC6_LAST_REPORTED))\n\t\tval = read_sample(pmu, gt_id, __I915_SAMPLE_RC6_LAST_REPORTED);\n\telse\n\t\tstore_sample(pmu, gt_id, __I915_SAMPLE_RC6_LAST_REPORTED, val);\n\n\tspin_unlock_irqrestore(&pmu->lock, flags);\n\n\treturn val;\n}\n\nstatic void init_rc6(struct i915_pmu *pmu)\n{\n\tstruct drm_i915_private *i915 = container_of(pmu, typeof(*i915), pmu);\n\tstruct intel_gt *gt;\n\tunsigned int i;\n\n\tfor_each_gt(gt, i915, i) {\n\t\tintel_wakeref_t wakeref;\n\n\t\twith_intel_runtime_pm(gt->uncore->rpm, wakeref) {\n\t\t\tu64 val = __get_rc6(gt);\n\n\t\t\tstore_sample(pmu, i, __I915_SAMPLE_RC6, val);\n\t\t\tstore_sample(pmu, i, __I915_SAMPLE_RC6_LAST_REPORTED,\n\t\t\t\t     val);\n\t\t\tpmu->sleep_last[i] = ktime_get_raw();\n\t\t}\n\t}\n}\n\nstatic void park_rc6(struct intel_gt *gt)\n{\n\tstruct i915_pmu *pmu = &gt->i915->pmu;\n\n\tstore_sample(pmu, gt->info.id, __I915_SAMPLE_RC6, __get_rc6(gt));\n\tpmu->sleep_last[gt->info.id] = ktime_get_raw();\n}\n\nstatic void __i915_pmu_maybe_start_timer(struct i915_pmu *pmu)\n{\n\tif (!pmu->timer_enabled && pmu_needs_timer(pmu)) {\n\t\tpmu->timer_enabled = true;\n\t\tpmu->timer_last = ktime_get();\n\t\thrtimer_start_range_ns(&pmu->timer,\n\t\t\t\t       ns_to_ktime(PERIOD), 0,\n\t\t\t\t       HRTIMER_MODE_REL_PINNED);\n\t}\n}\n\nvoid i915_pmu_gt_parked(struct intel_gt *gt)\n{\n\tstruct i915_pmu *pmu = &gt->i915->pmu;\n\n\tif (!pmu->base.event_init)\n\t\treturn;\n\n\tspin_lock_irq(&pmu->lock);\n\n\tpark_rc6(gt);\n\n\t \n\tpmu->unparked &= ~BIT(gt->info.id);\n\tif (pmu->unparked == 0)\n\t\tpmu->timer_enabled = false;\n\n\tspin_unlock_irq(&pmu->lock);\n}\n\nvoid i915_pmu_gt_unparked(struct intel_gt *gt)\n{\n\tstruct i915_pmu *pmu = &gt->i915->pmu;\n\n\tif (!pmu->base.event_init)\n\t\treturn;\n\n\tspin_lock_irq(&pmu->lock);\n\n\t \n\tif (pmu->unparked == 0)\n\t\t__i915_pmu_maybe_start_timer(pmu);\n\n\tpmu->unparked |= BIT(gt->info.id);\n\n\tspin_unlock_irq(&pmu->lock);\n}\n\nstatic void\nadd_sample(struct i915_pmu_sample *sample, u32 val)\n{\n\tsample->cur += val;\n}\n\nstatic bool exclusive_mmio_access(const struct drm_i915_private *i915)\n{\n\t \n\treturn GRAPHICS_VER(i915) == 7;\n}\n\nstatic void engine_sample(struct intel_engine_cs *engine, unsigned int period_ns)\n{\n\tstruct intel_engine_pmu *pmu = &engine->pmu;\n\tbool busy;\n\tu32 val;\n\n\tval = ENGINE_READ_FW(engine, RING_CTL);\n\tif (val == 0)  \n\t\treturn;\n\n\tif (val & RING_WAIT)\n\t\tadd_sample(&pmu->sample[I915_SAMPLE_WAIT], period_ns);\n\tif (val & RING_WAIT_SEMAPHORE)\n\t\tadd_sample(&pmu->sample[I915_SAMPLE_SEMA], period_ns);\n\n\t \n\tif (intel_engine_supports_stats(engine))\n\t\treturn;\n\n\t \n\tbusy = val & (RING_WAIT_SEMAPHORE | RING_WAIT);\n\tif (!busy) {\n\t\tval = ENGINE_READ_FW(engine, RING_MI_MODE);\n\t\tbusy = !(val & MODE_IDLE);\n\t}\n\tif (busy)\n\t\tadd_sample(&pmu->sample[I915_SAMPLE_BUSY], period_ns);\n}\n\nstatic void\nengines_sample(struct intel_gt *gt, unsigned int period_ns)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tunsigned long flags;\n\n\tif ((i915->pmu.enable & ENGINE_SAMPLE_MASK) == 0)\n\t\treturn;\n\n\tif (!intel_gt_pm_is_awake(gt))\n\t\treturn;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tif (!engine->pmu.enable)\n\t\t\tcontinue;\n\n\t\tif (!intel_engine_pm_get_if_awake(engine))\n\t\t\tcontinue;\n\n\t\tif (exclusive_mmio_access(i915)) {\n\t\t\tspin_lock_irqsave(&engine->uncore->lock, flags);\n\t\t\tengine_sample(engine, period_ns);\n\t\t\tspin_unlock_irqrestore(&engine->uncore->lock, flags);\n\t\t} else {\n\t\t\tengine_sample(engine, period_ns);\n\t\t}\n\n\t\tintel_engine_pm_put_async(engine);\n\t}\n}\n\nstatic bool\nfrequency_sampling_enabled(struct i915_pmu *pmu, unsigned int gt)\n{\n\treturn pmu->enable &\n\t       (config_mask(__I915_PMU_ACTUAL_FREQUENCY(gt)) |\n\t\tconfig_mask(__I915_PMU_REQUESTED_FREQUENCY(gt)));\n}\n\nstatic void\nfrequency_sample(struct intel_gt *gt, unsigned int period_ns)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tconst unsigned int gt_id = gt->info.id;\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tstruct intel_rps *rps = &gt->rps;\n\n\tif (!frequency_sampling_enabled(pmu, gt_id))\n\t\treturn;\n\n\t \n\tif (!intel_gt_pm_get_if_awake(gt))\n\t\treturn;\n\n\tif (pmu->enable & config_mask(__I915_PMU_ACTUAL_FREQUENCY(gt_id))) {\n\t\tu32 val;\n\n\t\t \n\t\tval = intel_rps_read_actual_frequency_fw(rps);\n\t\tif (!val)\n\t\t\tval = intel_gpu_freq(rps, rps->cur_freq);\n\n\t\tadd_sample_mult(pmu, gt_id, __I915_SAMPLE_FREQ_ACT,\n\t\t\t\tval, period_ns / 1000);\n\t}\n\n\tif (pmu->enable & config_mask(__I915_PMU_REQUESTED_FREQUENCY(gt_id))) {\n\t\tadd_sample_mult(pmu, gt_id, __I915_SAMPLE_FREQ_REQ,\n\t\t\t\tintel_rps_get_requested_frequency(rps),\n\t\t\t\tperiod_ns / 1000);\n\t}\n\n\tintel_gt_pm_put_async(gt);\n}\n\nstatic enum hrtimer_restart i915_sample(struct hrtimer *hrtimer)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(hrtimer, struct drm_i915_private, pmu.timer);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tunsigned int period_ns;\n\tstruct intel_gt *gt;\n\tunsigned int i;\n\tktime_t now;\n\n\tif (!READ_ONCE(pmu->timer_enabled))\n\t\treturn HRTIMER_NORESTART;\n\n\tnow = ktime_get();\n\tperiod_ns = ktime_to_ns(ktime_sub(now, pmu->timer_last));\n\tpmu->timer_last = now;\n\n\t \n\n\tfor_each_gt(gt, i915, i) {\n\t\tif (!(pmu->unparked & BIT(i)))\n\t\t\tcontinue;\n\n\t\tengines_sample(gt, period_ns);\n\t\tfrequency_sample(gt, period_ns);\n\t}\n\n\thrtimer_forward(hrtimer, now, ns_to_ktime(PERIOD));\n\n\treturn HRTIMER_RESTART;\n}\n\nstatic void i915_pmu_event_destroy(struct perf_event *event)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\n\tdrm_WARN_ON(&i915->drm, event->parent);\n\n\tdrm_dev_put(&i915->drm);\n}\n\nstatic int\nengine_event_status(struct intel_engine_cs *engine,\n\t\t    enum drm_i915_pmu_engine_sample sample)\n{\n\tswitch (sample) {\n\tcase I915_SAMPLE_BUSY:\n\tcase I915_SAMPLE_WAIT:\n\t\tbreak;\n\tcase I915_SAMPLE_SEMA:\n\t\tif (GRAPHICS_VER(engine->i915) < 6)\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nconfig_status(struct drm_i915_private *i915, u64 config)\n{\n\tstruct intel_gt *gt = to_gt(i915);\n\n\tunsigned int gt_id = config_gt_id(config);\n\tunsigned int max_gt_id = HAS_EXTRA_GT_LIST(i915) ? 1 : 0;\n\n\tif (gt_id > max_gt_id)\n\t\treturn -ENOENT;\n\n\tswitch (config_counter(config)) {\n\tcase I915_PMU_ACTUAL_FREQUENCY:\n\t\tif (IS_VALLEYVIEW(i915) || IS_CHERRYVIEW(i915))\n\t\t\t \n\t\t\treturn -ENODEV;\n\t\tfallthrough;\n\tcase I915_PMU_REQUESTED_FREQUENCY:\n\t\tif (GRAPHICS_VER(i915) < 6)\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tcase I915_PMU_INTERRUPTS:\n\t\tif (gt_id)\n\t\t\treturn -ENOENT;\n\t\tbreak;\n\tcase I915_PMU_RC6_RESIDENCY:\n\t\tif (!gt->rc6.supported)\n\t\t\treturn -ENODEV;\n\t\tbreak;\n\tcase I915_PMU_SOFTWARE_GT_AWAKE_TIME:\n\t\tbreak;\n\tdefault:\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}\n\nstatic int engine_event_init(struct perf_event *event)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tstruct intel_engine_cs *engine;\n\n\tengine = intel_engine_lookup_user(i915, engine_event_class(event),\n\t\t\t\t\t  engine_event_instance(event));\n\tif (!engine)\n\t\treturn -ENODEV;\n\n\treturn engine_event_status(engine, engine_event_sample(event));\n}\n\nstatic int i915_pmu_event_init(struct perf_event *event)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tint ret;\n\n\tif (pmu->closed)\n\t\treturn -ENODEV;\n\n\tif (event->attr.type != event->pmu->type)\n\t\treturn -ENOENT;\n\n\t \n\tif (event->attr.sample_period)  \n\t\treturn -EINVAL;\n\n\tif (has_branch_stack(event))\n\t\treturn -EOPNOTSUPP;\n\n\tif (event->cpu < 0)\n\t\treturn -EINVAL;\n\n\t \n\tif (!cpumask_test_cpu(event->cpu, &i915_pmu_cpumask))\n\t\treturn -EINVAL;\n\n\tif (is_engine_event(event))\n\t\tret = engine_event_init(event);\n\telse\n\t\tret = config_status(i915, event->attr.config);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!event->parent) {\n\t\tdrm_dev_get(&i915->drm);\n\t\tevent->destroy = i915_pmu_event_destroy;\n\t}\n\n\treturn 0;\n}\n\nstatic u64 __i915_pmu_event_read(struct perf_event *event)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tu64 val = 0;\n\n\tif (is_engine_event(event)) {\n\t\tu8 sample = engine_event_sample(event);\n\t\tstruct intel_engine_cs *engine;\n\n\t\tengine = intel_engine_lookup_user(i915,\n\t\t\t\t\t\t  engine_event_class(event),\n\t\t\t\t\t\t  engine_event_instance(event));\n\n\t\tif (drm_WARN_ON_ONCE(&i915->drm, !engine)) {\n\t\t\t \n\t\t} else if (sample == I915_SAMPLE_BUSY &&\n\t\t\t   intel_engine_supports_stats(engine)) {\n\t\t\tktime_t unused;\n\n\t\t\tval = ktime_to_ns(intel_engine_get_busy_time(engine,\n\t\t\t\t\t\t\t\t     &unused));\n\t\t} else {\n\t\t\tval = engine->pmu.sample[sample].cur;\n\t\t}\n\t} else {\n\t\tconst unsigned int gt_id = config_gt_id(event->attr.config);\n\t\tconst u64 config = config_counter(event->attr.config);\n\n\t\tswitch (config) {\n\t\tcase I915_PMU_ACTUAL_FREQUENCY:\n\t\t\tval =\n\t\t\t   div_u64(read_sample(pmu, gt_id,\n\t\t\t\t\t       __I915_SAMPLE_FREQ_ACT),\n\t\t\t\t   USEC_PER_SEC  );\n\t\t\tbreak;\n\t\tcase I915_PMU_REQUESTED_FREQUENCY:\n\t\t\tval =\n\t\t\t   div_u64(read_sample(pmu, gt_id,\n\t\t\t\t\t       __I915_SAMPLE_FREQ_REQ),\n\t\t\t\t   USEC_PER_SEC  );\n\t\t\tbreak;\n\t\tcase I915_PMU_INTERRUPTS:\n\t\t\tval = READ_ONCE(pmu->irq_count);\n\t\t\tbreak;\n\t\tcase I915_PMU_RC6_RESIDENCY:\n\t\t\tval = get_rc6(i915->gt[gt_id]);\n\t\t\tbreak;\n\t\tcase I915_PMU_SOFTWARE_GT_AWAKE_TIME:\n\t\t\tval = ktime_to_ns(intel_gt_get_awake_time(to_gt(i915)));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn val;\n}\n\nstatic void i915_pmu_event_read(struct perf_event *event)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tu64 prev, new;\n\n\tif (pmu->closed) {\n\t\tevent->hw.state = PERF_HES_STOPPED;\n\t\treturn;\n\t}\nagain:\n\tprev = local64_read(&hwc->prev_count);\n\tnew = __i915_pmu_event_read(event);\n\n\tif (local64_cmpxchg(&hwc->prev_count, prev, new) != prev)\n\t\tgoto again;\n\n\tlocal64_add(new - prev, &event->count);\n}\n\nstatic void i915_pmu_enable(struct perf_event *event)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tconst unsigned int bit = event_bit(event);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tunsigned long flags;\n\n\tif (bit == -1)\n\t\tgoto update;\n\n\tspin_lock_irqsave(&pmu->lock, flags);\n\n\t \n\tBUILD_BUG_ON(ARRAY_SIZE(pmu->enable_count) != I915_PMU_MASK_BITS);\n\tGEM_BUG_ON(bit >= ARRAY_SIZE(pmu->enable_count));\n\tGEM_BUG_ON(pmu->enable_count[bit] == ~0);\n\n\tpmu->enable |= BIT(bit);\n\tpmu->enable_count[bit]++;\n\n\t \n\t__i915_pmu_maybe_start_timer(pmu);\n\n\t \n\tif (is_engine_event(event)) {\n\t\tu8 sample = engine_event_sample(event);\n\t\tstruct intel_engine_cs *engine;\n\n\t\tengine = intel_engine_lookup_user(i915,\n\t\t\t\t\t\t  engine_event_class(event),\n\t\t\t\t\t\t  engine_event_instance(event));\n\n\t\tBUILD_BUG_ON(ARRAY_SIZE(engine->pmu.enable_count) !=\n\t\t\t     I915_ENGINE_SAMPLE_COUNT);\n\t\tBUILD_BUG_ON(ARRAY_SIZE(engine->pmu.sample) !=\n\t\t\t     I915_ENGINE_SAMPLE_COUNT);\n\t\tGEM_BUG_ON(sample >= ARRAY_SIZE(engine->pmu.enable_count));\n\t\tGEM_BUG_ON(sample >= ARRAY_SIZE(engine->pmu.sample));\n\t\tGEM_BUG_ON(engine->pmu.enable_count[sample] == ~0);\n\n\t\tengine->pmu.enable |= BIT(sample);\n\t\tengine->pmu.enable_count[sample]++;\n\t}\n\n\tspin_unlock_irqrestore(&pmu->lock, flags);\n\nupdate:\n\t \n\tlocal64_set(&event->hw.prev_count, __i915_pmu_event_read(event));\n}\n\nstatic void i915_pmu_disable(struct perf_event *event)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tconst unsigned int bit = event_bit(event);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tunsigned long flags;\n\n\tif (bit == -1)\n\t\treturn;\n\n\tspin_lock_irqsave(&pmu->lock, flags);\n\n\tif (is_engine_event(event)) {\n\t\tu8 sample = engine_event_sample(event);\n\t\tstruct intel_engine_cs *engine;\n\n\t\tengine = intel_engine_lookup_user(i915,\n\t\t\t\t\t\t  engine_event_class(event),\n\t\t\t\t\t\t  engine_event_instance(event));\n\n\t\tGEM_BUG_ON(sample >= ARRAY_SIZE(engine->pmu.enable_count));\n\t\tGEM_BUG_ON(sample >= ARRAY_SIZE(engine->pmu.sample));\n\t\tGEM_BUG_ON(engine->pmu.enable_count[sample] == 0);\n\n\t\t \n\t\tif (--engine->pmu.enable_count[sample] == 0)\n\t\t\tengine->pmu.enable &= ~BIT(sample);\n\t}\n\n\tGEM_BUG_ON(bit >= ARRAY_SIZE(pmu->enable_count));\n\tGEM_BUG_ON(pmu->enable_count[bit] == 0);\n\t \n\tif (--pmu->enable_count[bit] == 0) {\n\t\tpmu->enable &= ~BIT(bit);\n\t\tpmu->timer_enabled &= pmu_needs_timer(pmu);\n\t}\n\n\tspin_unlock_irqrestore(&pmu->lock, flags);\n}\n\nstatic void i915_pmu_event_start(struct perf_event *event, int flags)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\n\tif (pmu->closed)\n\t\treturn;\n\n\ti915_pmu_enable(event);\n\tevent->hw.state = 0;\n}\n\nstatic void i915_pmu_event_stop(struct perf_event *event, int flags)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\n\tif (pmu->closed)\n\t\tgoto out;\n\n\tif (flags & PERF_EF_UPDATE)\n\t\ti915_pmu_event_read(event);\n\ti915_pmu_disable(event);\n\nout:\n\tevent->hw.state = PERF_HES_STOPPED;\n}\n\nstatic int i915_pmu_event_add(struct perf_event *event, int flags)\n{\n\tstruct drm_i915_private *i915 =\n\t\tcontainer_of(event->pmu, typeof(*i915), pmu.base);\n\tstruct i915_pmu *pmu = &i915->pmu;\n\n\tif (pmu->closed)\n\t\treturn -ENODEV;\n\n\tif (flags & PERF_EF_START)\n\t\ti915_pmu_event_start(event, flags);\n\n\treturn 0;\n}\n\nstatic void i915_pmu_event_del(struct perf_event *event, int flags)\n{\n\ti915_pmu_event_stop(event, PERF_EF_UPDATE);\n}\n\nstatic int i915_pmu_event_event_idx(struct perf_event *event)\n{\n\treturn 0;\n}\n\nstruct i915_str_attribute {\n\tstruct device_attribute attr;\n\tconst char *str;\n};\n\nstatic ssize_t i915_pmu_format_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct i915_str_attribute *eattr;\n\n\teattr = container_of(attr, struct i915_str_attribute, attr);\n\treturn sprintf(buf, \"%s\\n\", eattr->str);\n}\n\n#define I915_PMU_FORMAT_ATTR(_name, _config) \\\n\t(&((struct i915_str_attribute[]) { \\\n\t\t{ .attr = __ATTR(_name, 0444, i915_pmu_format_show, NULL), \\\n\t\t  .str = _config, } \\\n\t})[0].attr.attr)\n\nstatic struct attribute *i915_pmu_format_attrs[] = {\n\tI915_PMU_FORMAT_ATTR(i915_eventid, \"config:0-20\"),\n\tNULL,\n};\n\nstatic const struct attribute_group i915_pmu_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = i915_pmu_format_attrs,\n};\n\nstruct i915_ext_attribute {\n\tstruct device_attribute attr;\n\tunsigned long val;\n};\n\nstatic ssize_t i915_pmu_event_show(struct device *dev,\n\t\t\t\t   struct device_attribute *attr, char *buf)\n{\n\tstruct i915_ext_attribute *eattr;\n\n\teattr = container_of(attr, struct i915_ext_attribute, attr);\n\treturn sprintf(buf, \"config=0x%lx\\n\", eattr->val);\n}\n\nstatic ssize_t cpumask_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\treturn cpumap_print_to_pagebuf(true, buf, &i915_pmu_cpumask);\n}\n\nstatic DEVICE_ATTR_RO(cpumask);\n\nstatic struct attribute *i915_cpumask_attrs[] = {\n\t&dev_attr_cpumask.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group i915_pmu_cpumask_attr_group = {\n\t.attrs = i915_cpumask_attrs,\n};\n\n#define __event(__counter, __name, __unit) \\\n{ \\\n\t.counter = (__counter), \\\n\t.name = (__name), \\\n\t.unit = (__unit), \\\n\t.global = false, \\\n}\n\n#define __global_event(__counter, __name, __unit) \\\n{ \\\n\t.counter = (__counter), \\\n\t.name = (__name), \\\n\t.unit = (__unit), \\\n\t.global = true, \\\n}\n\n#define __engine_event(__sample, __name) \\\n{ \\\n\t.sample = (__sample), \\\n\t.name = (__name), \\\n}\n\nstatic struct i915_ext_attribute *\nadd_i915_attr(struct i915_ext_attribute *attr, const char *name, u64 config)\n{\n\tsysfs_attr_init(&attr->attr.attr);\n\tattr->attr.attr.name = name;\n\tattr->attr.attr.mode = 0444;\n\tattr->attr.show = i915_pmu_event_show;\n\tattr->val = config;\n\n\treturn ++attr;\n}\n\nstatic struct perf_pmu_events_attr *\nadd_pmu_attr(struct perf_pmu_events_attr *attr, const char *name,\n\t     const char *str)\n{\n\tsysfs_attr_init(&attr->attr.attr);\n\tattr->attr.attr.name = name;\n\tattr->attr.attr.mode = 0444;\n\tattr->attr.show = perf_event_sysfs_show;\n\tattr->event_str = str;\n\n\treturn ++attr;\n}\n\nstatic struct attribute **\ncreate_event_attributes(struct i915_pmu *pmu)\n{\n\tstruct drm_i915_private *i915 = container_of(pmu, typeof(*i915), pmu);\n\tstatic const struct {\n\t\tunsigned int counter;\n\t\tconst char *name;\n\t\tconst char *unit;\n\t\tbool global;\n\t} events[] = {\n\t\t__event(0, \"actual-frequency\", \"M\"),\n\t\t__event(1, \"requested-frequency\", \"M\"),\n\t\t__global_event(2, \"interrupts\", NULL),\n\t\t__event(3, \"rc6-residency\", \"ns\"),\n\t\t__event(4, \"software-gt-awake-time\", \"ns\"),\n\t};\n\tstatic const struct {\n\t\tenum drm_i915_pmu_engine_sample sample;\n\t\tchar *name;\n\t} engine_events[] = {\n\t\t__engine_event(I915_SAMPLE_BUSY, \"busy\"),\n\t\t__engine_event(I915_SAMPLE_SEMA, \"sema\"),\n\t\t__engine_event(I915_SAMPLE_WAIT, \"wait\"),\n\t};\n\tunsigned int count = 0;\n\tstruct perf_pmu_events_attr *pmu_attr = NULL, *pmu_iter;\n\tstruct i915_ext_attribute *i915_attr = NULL, *i915_iter;\n\tstruct attribute **attr = NULL, **attr_iter;\n\tstruct intel_engine_cs *engine;\n\tstruct intel_gt *gt;\n\tunsigned int i, j;\n\n\t \n\tfor_each_gt(gt, i915, j) {\n\t\tfor (i = 0; i < ARRAY_SIZE(events); i++) {\n\t\t\tu64 config = ___I915_PMU_OTHER(j, events[i].counter);\n\n\t\t\tif (!config_status(i915, config))\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\tfor_each_uabi_engine(engine, i915) {\n\t\tfor (i = 0; i < ARRAY_SIZE(engine_events); i++) {\n\t\t\tif (!engine_event_status(engine,\n\t\t\t\t\t\t engine_events[i].sample))\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\t \n\ti915_attr = kcalloc(count, sizeof(*i915_attr), GFP_KERNEL);\n\tif (!i915_attr)\n\t\tgoto err_alloc;\n\n\tpmu_attr = kcalloc(count, sizeof(*pmu_attr), GFP_KERNEL);\n\tif (!pmu_attr)\n\t\tgoto err_alloc;\n\n\t \n\tattr = kcalloc(count * 2 + 1, sizeof(*attr), GFP_KERNEL);\n\tif (!attr)\n\t\tgoto err_alloc;\n\n\ti915_iter = i915_attr;\n\tpmu_iter = pmu_attr;\n\tattr_iter = attr;\n\n\t \n\tfor_each_gt(gt, i915, j) {\n\t\tfor (i = 0; i < ARRAY_SIZE(events); i++) {\n\t\t\tu64 config = ___I915_PMU_OTHER(j, events[i].counter);\n\t\t\tchar *str;\n\n\t\t\tif (config_status(i915, config))\n\t\t\t\tcontinue;\n\n\t\t\tif (events[i].global || !HAS_EXTRA_GT_LIST(i915))\n\t\t\t\tstr = kstrdup(events[i].name, GFP_KERNEL);\n\t\t\telse\n\t\t\t\tstr = kasprintf(GFP_KERNEL, \"%s-gt%u\",\n\t\t\t\t\t\tevents[i].name, j);\n\t\t\tif (!str)\n\t\t\t\tgoto err;\n\n\t\t\t*attr_iter++ = &i915_iter->attr.attr;\n\t\t\ti915_iter = add_i915_attr(i915_iter, str, config);\n\n\t\t\tif (events[i].unit) {\n\t\t\t\tif (events[i].global || !HAS_EXTRA_GT_LIST(i915))\n\t\t\t\t\tstr = kasprintf(GFP_KERNEL, \"%s.unit\",\n\t\t\t\t\t\t\tevents[i].name);\n\t\t\t\telse\n\t\t\t\t\tstr = kasprintf(GFP_KERNEL, \"%s-gt%u.unit\",\n\t\t\t\t\t\t\tevents[i].name, j);\n\t\t\t\tif (!str)\n\t\t\t\t\tgoto err;\n\n\t\t\t\t*attr_iter++ = &pmu_iter->attr.attr;\n\t\t\t\tpmu_iter = add_pmu_attr(pmu_iter, str,\n\t\t\t\t\t\t\tevents[i].unit);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tfor_each_uabi_engine(engine, i915) {\n\t\tfor (i = 0; i < ARRAY_SIZE(engine_events); i++) {\n\t\t\tchar *str;\n\n\t\t\tif (engine_event_status(engine,\n\t\t\t\t\t\tengine_events[i].sample))\n\t\t\t\tcontinue;\n\n\t\t\tstr = kasprintf(GFP_KERNEL, \"%s-%s\",\n\t\t\t\t\tengine->name, engine_events[i].name);\n\t\t\tif (!str)\n\t\t\t\tgoto err;\n\n\t\t\t*attr_iter++ = &i915_iter->attr.attr;\n\t\t\ti915_iter =\n\t\t\t\tadd_i915_attr(i915_iter, str,\n\t\t\t\t\t      __I915_PMU_ENGINE(engine->uabi_class,\n\t\t\t\t\t\t\t\tengine->uabi_instance,\n\t\t\t\t\t\t\t\tengine_events[i].sample));\n\n\t\t\tstr = kasprintf(GFP_KERNEL, \"%s-%s.unit\",\n\t\t\t\t\tengine->name, engine_events[i].name);\n\t\t\tif (!str)\n\t\t\t\tgoto err;\n\n\t\t\t*attr_iter++ = &pmu_iter->attr.attr;\n\t\t\tpmu_iter = add_pmu_attr(pmu_iter, str, \"ns\");\n\t\t}\n\t}\n\n\tpmu->i915_attr = i915_attr;\n\tpmu->pmu_attr = pmu_attr;\n\n\treturn attr;\n\nerr:;\n\tfor (attr_iter = attr; *attr_iter; attr_iter++)\n\t\tkfree((*attr_iter)->name);\n\nerr_alloc:\n\tkfree(attr);\n\tkfree(i915_attr);\n\tkfree(pmu_attr);\n\n\treturn NULL;\n}\n\nstatic void free_event_attributes(struct i915_pmu *pmu)\n{\n\tstruct attribute **attr_iter = pmu->events_attr_group.attrs;\n\n\tfor (; *attr_iter; attr_iter++)\n\t\tkfree((*attr_iter)->name);\n\n\tkfree(pmu->events_attr_group.attrs);\n\tkfree(pmu->i915_attr);\n\tkfree(pmu->pmu_attr);\n\n\tpmu->events_attr_group.attrs = NULL;\n\tpmu->i915_attr = NULL;\n\tpmu->pmu_attr = NULL;\n}\n\nstatic int i915_pmu_cpu_online(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct i915_pmu *pmu = hlist_entry_safe(node, typeof(*pmu), cpuhp.node);\n\n\tGEM_BUG_ON(!pmu->base.event_init);\n\n\t \n\tif (cpumask_empty(&i915_pmu_cpumask))\n\t\tcpumask_set_cpu(cpu, &i915_pmu_cpumask);\n\n\treturn 0;\n}\n\nstatic int i915_pmu_cpu_offline(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct i915_pmu *pmu = hlist_entry_safe(node, typeof(*pmu), cpuhp.node);\n\tunsigned int target = i915_pmu_target_cpu;\n\n\tGEM_BUG_ON(!pmu->base.event_init);\n\n\t \n\tif (pmu->closed)\n\t\treturn 0;\n\n\tif (cpumask_test_and_clear_cpu(cpu, &i915_pmu_cpumask)) {\n\t\ttarget = cpumask_any_but(topology_sibling_cpumask(cpu), cpu);\n\n\t\t \n\t\tif (target < nr_cpu_ids) {\n\t\t\tcpumask_set_cpu(target, &i915_pmu_cpumask);\n\t\t\ti915_pmu_target_cpu = target;\n\t\t}\n\t}\n\n\tif (target < nr_cpu_ids && target != pmu->cpuhp.cpu) {\n\t\tperf_pmu_migrate_context(&pmu->base, cpu, target);\n\t\tpmu->cpuhp.cpu = target;\n\t}\n\n\treturn 0;\n}\n\nstatic enum cpuhp_state cpuhp_slot = CPUHP_INVALID;\n\nint i915_pmu_init(void)\n{\n\tint ret;\n\n\tret = cpuhp_setup_state_multi(CPUHP_AP_ONLINE_DYN,\n\t\t\t\t      \"perf/x86/intel/i915:online\",\n\t\t\t\t      i915_pmu_cpu_online,\n\t\t\t\t      i915_pmu_cpu_offline);\n\tif (ret < 0)\n\t\tpr_notice(\"Failed to setup cpuhp state for i915 PMU! (%d)\\n\",\n\t\t\t  ret);\n\telse\n\t\tcpuhp_slot = ret;\n\n\treturn 0;\n}\n\nvoid i915_pmu_exit(void)\n{\n\tif (cpuhp_slot != CPUHP_INVALID)\n\t\tcpuhp_remove_multi_state(cpuhp_slot);\n}\n\nstatic int i915_pmu_register_cpuhp_state(struct i915_pmu *pmu)\n{\n\tif (cpuhp_slot == CPUHP_INVALID)\n\t\treturn -EINVAL;\n\n\treturn cpuhp_state_add_instance(cpuhp_slot, &pmu->cpuhp.node);\n}\n\nstatic void i915_pmu_unregister_cpuhp_state(struct i915_pmu *pmu)\n{\n\tcpuhp_state_remove_instance(cpuhp_slot, &pmu->cpuhp.node);\n}\n\nstatic bool is_igp(struct drm_i915_private *i915)\n{\n\tstruct pci_dev *pdev = to_pci_dev(i915->drm.dev);\n\n\t \n\treturn pci_domain_nr(pdev->bus) == 0 &&\n\t       pdev->bus->number == 0 &&\n\t       PCI_SLOT(pdev->devfn) == 2 &&\n\t       PCI_FUNC(pdev->devfn) == 0;\n}\n\nvoid i915_pmu_register(struct drm_i915_private *i915)\n{\n\tstruct i915_pmu *pmu = &i915->pmu;\n\tconst struct attribute_group *attr_groups[] = {\n\t\t&i915_pmu_format_attr_group,\n\t\t&pmu->events_attr_group,\n\t\t&i915_pmu_cpumask_attr_group,\n\t\tNULL\n\t};\n\n\tint ret = -ENOMEM;\n\n\tif (GRAPHICS_VER(i915) <= 2) {\n\t\tdrm_info(&i915->drm, \"PMU not supported for this GPU.\");\n\t\treturn;\n\t}\n\n\tspin_lock_init(&pmu->lock);\n\thrtimer_init(&pmu->timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tpmu->timer.function = i915_sample;\n\tpmu->cpuhp.cpu = -1;\n\tinit_rc6(pmu);\n\n\tif (!is_igp(i915)) {\n\t\tpmu->name = kasprintf(GFP_KERNEL,\n\t\t\t\t      \"i915_%s\",\n\t\t\t\t      dev_name(i915->drm.dev));\n\t\tif (pmu->name) {\n\t\t\t \n\t\t\tstrreplace((char *)pmu->name, ':', '_');\n\t\t}\n\t} else {\n\t\tpmu->name = \"i915\";\n\t}\n\tif (!pmu->name)\n\t\tgoto err;\n\n\tpmu->events_attr_group.name = \"events\";\n\tpmu->events_attr_group.attrs = create_event_attributes(pmu);\n\tif (!pmu->events_attr_group.attrs)\n\t\tgoto err_name;\n\n\tpmu->base.attr_groups = kmemdup(attr_groups, sizeof(attr_groups),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!pmu->base.attr_groups)\n\t\tgoto err_attr;\n\n\tpmu->base.module\t= THIS_MODULE;\n\tpmu->base.task_ctx_nr\t= perf_invalid_context;\n\tpmu->base.event_init\t= i915_pmu_event_init;\n\tpmu->base.add\t\t= i915_pmu_event_add;\n\tpmu->base.del\t\t= i915_pmu_event_del;\n\tpmu->base.start\t\t= i915_pmu_event_start;\n\tpmu->base.stop\t\t= i915_pmu_event_stop;\n\tpmu->base.read\t\t= i915_pmu_event_read;\n\tpmu->base.event_idx\t= i915_pmu_event_event_idx;\n\n\tret = perf_pmu_register(&pmu->base, pmu->name, -1);\n\tif (ret)\n\t\tgoto err_groups;\n\n\tret = i915_pmu_register_cpuhp_state(pmu);\n\tif (ret)\n\t\tgoto err_unreg;\n\n\treturn;\n\nerr_unreg:\n\tperf_pmu_unregister(&pmu->base);\nerr_groups:\n\tkfree(pmu->base.attr_groups);\nerr_attr:\n\tpmu->base.event_init = NULL;\n\tfree_event_attributes(pmu);\nerr_name:\n\tif (!is_igp(i915))\n\t\tkfree(pmu->name);\nerr:\n\tdrm_notice(&i915->drm, \"Failed to register PMU!\\n\");\n}\n\nvoid i915_pmu_unregister(struct drm_i915_private *i915)\n{\n\tstruct i915_pmu *pmu = &i915->pmu;\n\n\tif (!pmu->base.event_init)\n\t\treturn;\n\n\t \n\tpmu->closed = true;\n\tsynchronize_rcu();\n\n\thrtimer_cancel(&pmu->timer);\n\n\ti915_pmu_unregister_cpuhp_state(pmu);\n\n\tperf_pmu_unregister(&pmu->base);\n\tpmu->base.event_init = NULL;\n\tkfree(pmu->base.attr_groups);\n\tif (!is_igp(i915))\n\t\tkfree(pmu->name);\n\tfree_event_attributes(pmu);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}