{
  "module_name": "igt_spinner.c",
  "hash_id": "ad8a39b4b7f3057f626285e69406a66cbb9e10408866fd145309ab84f7234c4e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/selftests/igt_spinner.c",
  "human_readable_source": " \n#include \"gt/intel_gpu_commands.h\"\n#include \"gt/intel_gt.h\"\n\n#include \"gem/i915_gem_internal.h\"\n#include \"gem/selftests/igt_gem_utils.h\"\n\n#include \"igt_spinner.h\"\n\nint igt_spinner_init(struct igt_spinner *spin, struct intel_gt *gt)\n{\n\tint err;\n\n\tmemset(spin, 0, sizeof(*spin));\n\tspin->gt = gt;\n\n\tspin->hws = i915_gem_object_create_internal(gt->i915, PAGE_SIZE);\n\tif (IS_ERR(spin->hws)) {\n\t\terr = PTR_ERR(spin->hws);\n\t\tgoto err;\n\t}\n\ti915_gem_object_set_cache_coherency(spin->hws, I915_CACHE_LLC);\n\n\tspin->obj = i915_gem_object_create_internal(gt->i915, PAGE_SIZE);\n\tif (IS_ERR(spin->obj)) {\n\t\terr = PTR_ERR(spin->obj);\n\t\tgoto err_hws;\n\t}\n\n\treturn 0;\n\nerr_hws:\n\ti915_gem_object_put(spin->hws);\nerr:\n\treturn err;\n}\n\nstatic void *igt_spinner_pin_obj(struct intel_context *ce,\n\t\t\t\t struct i915_gem_ww_ctx *ww,\n\t\t\t\t struct drm_i915_gem_object *obj,\n\t\t\t\t unsigned int mode, struct i915_vma **vma)\n{\n\tvoid *vaddr;\n\tint ret;\n\n\t*vma = i915_vma_instance(obj, ce->vm, NULL);\n\tif (IS_ERR(*vma))\n\t\treturn ERR_CAST(*vma);\n\n\tret = i915_gem_object_lock(obj, ww);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tvaddr = i915_gem_object_pin_map(obj, mode);\n\n\tif (!ww)\n\t\ti915_gem_object_unlock(obj);\n\n\tif (IS_ERR(vaddr))\n\t\treturn vaddr;\n\n\tif (ww)\n\t\tret = i915_vma_pin_ww(*vma, ww, 0, 0, PIN_USER);\n\telse\n\t\tret = i915_vma_pin(*vma, 0, 0, PIN_USER);\n\n\tif (ret) {\n\t\ti915_gem_object_unpin_map(obj);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn vaddr;\n}\n\nint igt_spinner_pin(struct igt_spinner *spin,\n\t\t    struct intel_context *ce,\n\t\t    struct i915_gem_ww_ctx *ww)\n{\n\tvoid *vaddr;\n\n\tif (spin->ce && WARN_ON(spin->ce != ce))\n\t\treturn -ENODEV;\n\tspin->ce = ce;\n\n\tif (!spin->seqno) {\n\t\tvaddr = igt_spinner_pin_obj(ce, ww, spin->hws, I915_MAP_WB, &spin->hws_vma);\n\t\tif (IS_ERR(vaddr))\n\t\t\treturn PTR_ERR(vaddr);\n\n\t\tspin->seqno = memset(vaddr, 0xff, PAGE_SIZE);\n\t}\n\n\tif (!spin->batch) {\n\t\tunsigned int mode;\n\n\t\tmode = intel_gt_coherent_map_type(spin->gt, spin->obj, false);\n\t\tvaddr = igt_spinner_pin_obj(ce, ww, spin->obj, mode, &spin->batch_vma);\n\t\tif (IS_ERR(vaddr))\n\t\t\treturn PTR_ERR(vaddr);\n\n\t\tspin->batch = vaddr;\n\t}\n\n\treturn 0;\n}\n\nstatic unsigned int seqno_offset(u64 fence)\n{\n\treturn offset_in_page(sizeof(u32) * fence);\n}\n\nstatic u64 hws_address(const struct i915_vma *hws,\n\t\t       const struct i915_request *rq)\n{\n\treturn i915_vma_offset(hws) + seqno_offset(rq->fence.context);\n}\n\nstruct i915_request *\nigt_spinner_create_request(struct igt_spinner *spin,\n\t\t\t   struct intel_context *ce,\n\t\t\t   u32 arbitration_command)\n{\n\tstruct intel_engine_cs *engine = ce->engine;\n\tstruct i915_request *rq = NULL;\n\tstruct i915_vma *hws, *vma;\n\tunsigned int flags;\n\tu32 *batch;\n\tint err;\n\n\tGEM_BUG_ON(spin->gt != ce->vm->gt);\n\n\tif (!intel_engine_can_store_dword(ce->engine))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tif (!spin->batch) {\n\t\terr = igt_spinner_pin(spin, ce, NULL);\n\t\tif (err)\n\t\t\treturn ERR_PTR(err);\n\t}\n\n\thws = spin->hws_vma;\n\tvma = spin->batch_vma;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn ERR_CAST(rq);\n\n\terr = igt_vma_move_to_active_unlocked(vma, rq, 0);\n\tif (err)\n\t\tgoto cancel_rq;\n\n\terr = igt_vma_move_to_active_unlocked(hws, rq, 0);\n\tif (err)\n\t\tgoto cancel_rq;\n\n\tbatch = spin->batch;\n\n\tif (GRAPHICS_VER(rq->i915) >= 8) {\n\t\t*batch++ = MI_STORE_DWORD_IMM_GEN4;\n\t\t*batch++ = lower_32_bits(hws_address(hws, rq));\n\t\t*batch++ = upper_32_bits(hws_address(hws, rq));\n\t} else if (GRAPHICS_VER(rq->i915) >= 6) {\n\t\t*batch++ = MI_STORE_DWORD_IMM_GEN4;\n\t\t*batch++ = 0;\n\t\t*batch++ = hws_address(hws, rq);\n\t} else if (GRAPHICS_VER(rq->i915) >= 4) {\n\t\t*batch++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*batch++ = 0;\n\t\t*batch++ = hws_address(hws, rq);\n\t} else {\n\t\t*batch++ = MI_STORE_DWORD_IMM | MI_MEM_VIRTUAL;\n\t\t*batch++ = hws_address(hws, rq);\n\t}\n\t*batch++ = rq->fence.seqno;\n\n\t*batch++ = arbitration_command;\n\n\tif (GRAPHICS_VER(rq->i915) >= 8)\n\t\t*batch++ = MI_BATCH_BUFFER_START | BIT(8) | 1;\n\telse if (IS_HASWELL(rq->i915))\n\t\t*batch++ = MI_BATCH_BUFFER_START | MI_BATCH_PPGTT_HSW;\n\telse if (GRAPHICS_VER(rq->i915) >= 6)\n\t\t*batch++ = MI_BATCH_BUFFER_START;\n\telse\n\t\t*batch++ = MI_BATCH_BUFFER_START | MI_BATCH_GTT;\n\t*batch++ = lower_32_bits(i915_vma_offset(vma));\n\t*batch++ = upper_32_bits(i915_vma_offset(vma));\n\n\t*batch++ = MI_BATCH_BUFFER_END;  \n\n\tintel_gt_chipset_flush(engine->gt);\n\n\tif (engine->emit_init_breadcrumb) {\n\t\terr = engine->emit_init_breadcrumb(rq);\n\t\tif (err)\n\t\t\tgoto cancel_rq;\n\t}\n\n\tflags = 0;\n\tif (GRAPHICS_VER(rq->i915) <= 5)\n\t\tflags |= I915_DISPATCH_SECURE;\n\terr = engine->emit_bb_start(rq, i915_vma_offset(vma), PAGE_SIZE, flags);\n\ncancel_rq:\n\tif (err) {\n\t\ti915_request_set_error_once(rq, err);\n\t\ti915_request_add(rq);\n\t}\n\treturn err ? ERR_PTR(err) : rq;\n}\n\nstatic u32\nhws_seqno(const struct igt_spinner *spin, const struct i915_request *rq)\n{\n\tu32 *seqno = spin->seqno + seqno_offset(rq->fence.context);\n\n\treturn READ_ONCE(*seqno);\n}\n\nvoid igt_spinner_end(struct igt_spinner *spin)\n{\n\tif (!spin->batch)\n\t\treturn;\n\n\t*spin->batch = MI_BATCH_BUFFER_END;\n\tintel_gt_chipset_flush(spin->gt);\n}\n\nvoid igt_spinner_fini(struct igt_spinner *spin)\n{\n\tigt_spinner_end(spin);\n\n\tif (spin->batch) {\n\t\ti915_vma_unpin(spin->batch_vma);\n\t\ti915_gem_object_unpin_map(spin->obj);\n\t}\n\ti915_gem_object_put(spin->obj);\n\n\tif (spin->seqno) {\n\t\ti915_vma_unpin(spin->hws_vma);\n\t\ti915_gem_object_unpin_map(spin->hws);\n\t}\n\ti915_gem_object_put(spin->hws);\n}\n\nbool igt_wait_for_spinner(struct igt_spinner *spin, struct i915_request *rq)\n{\n\tif (i915_request_is_ready(rq))\n\t\tintel_engine_flush_submission(rq->engine);\n\n\treturn !(wait_for_us(i915_seqno_passed(hws_seqno(spin, rq),\n\t\t\t\t\t       rq->fence.seqno),\n\t\t\t     100) &&\n\t\t wait_for(i915_seqno_passed(hws_seqno(spin, rq),\n\t\t\t\t\t    rq->fence.seqno),\n\t\t\t  50));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}