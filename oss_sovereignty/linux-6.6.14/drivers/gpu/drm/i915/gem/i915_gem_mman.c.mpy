{
  "module_name": "i915_gem_mman.c",
  "hash_id": "d5a6fa1a6912eadf639a8525a0167c2d3f40744aaa1077c68bae043e4fe9f136",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gem/i915_gem_mman.c",
  "human_readable_source": " \n\n#include <linux/anon_inodes.h>\n#include <linux/mman.h>\n#include <linux/pfn_t.h>\n#include <linux/sizes.h>\n\n#include <drm/drm_cache.h>\n\n#include \"gt/intel_gt.h\"\n#include \"gt/intel_gt_requests.h\"\n\n#include \"i915_drv.h\"\n#include \"i915_gem_evict.h\"\n#include \"i915_gem_gtt.h\"\n#include \"i915_gem_ioctls.h\"\n#include \"i915_gem_object.h\"\n#include \"i915_gem_mman.h\"\n#include \"i915_mm.h\"\n#include \"i915_trace.h\"\n#include \"i915_user_extensions.h\"\n#include \"i915_gem_ttm.h\"\n#include \"i915_vma.h\"\n\nstatic inline bool\n__vma_matches(struct vm_area_struct *vma, struct file *filp,\n\t      unsigned long addr, unsigned long size)\n{\n\tif (vma->vm_file != filp)\n\t\treturn false;\n\n\treturn vma->vm_start == addr &&\n\t       (vma->vm_end - vma->vm_start) == PAGE_ALIGN(size);\n}\n\n \nint\ni915_gem_mmap_ioctl(struct drm_device *dev, void *data,\n\t\t    struct drm_file *file)\n{\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tstruct drm_i915_gem_mmap *args = data;\n\tstruct drm_i915_gem_object *obj;\n\tunsigned long addr;\n\n\t \n\tif (IS_DGFX(i915) || GRAPHICS_VER_FULL(i915) > IP_VER(12, 0))\n\t\treturn -EOPNOTSUPP;\n\n\tif (args->flags & ~(I915_MMAP_WC))\n\t\treturn -EINVAL;\n\n\tif (args->flags & I915_MMAP_WC && !pat_enabled())\n\t\treturn -ENODEV;\n\n\tobj = i915_gem_object_lookup(file, args->handle);\n\tif (!obj)\n\t\treturn -ENOENT;\n\n\t \n\tif (!obj->base.filp) {\n\t\taddr = -ENXIO;\n\t\tgoto err;\n\t}\n\n\tif (range_overflows(args->offset, args->size, (u64)obj->base.size)) {\n\t\taddr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\taddr = vm_mmap(obj->base.filp, 0, args->size,\n\t\t       PROT_READ | PROT_WRITE, MAP_SHARED,\n\t\t       args->offset);\n\tif (IS_ERR_VALUE(addr))\n\t\tgoto err;\n\n\tif (args->flags & I915_MMAP_WC) {\n\t\tstruct mm_struct *mm = current->mm;\n\t\tstruct vm_area_struct *vma;\n\n\t\tif (mmap_write_lock_killable(mm)) {\n\t\t\taddr = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\t\tvma = find_vma(mm, addr);\n\t\tif (vma && __vma_matches(vma, obj->base.filp, addr, args->size))\n\t\t\tvma->vm_page_prot =\n\t\t\t\tpgprot_writecombine(vm_get_page_prot(vma->vm_flags));\n\t\telse\n\t\t\taddr = -ENOMEM;\n\t\tmmap_write_unlock(mm);\n\t\tif (IS_ERR_VALUE(addr))\n\t\t\tgoto err;\n\t}\n\ti915_gem_object_put(obj);\n\n\targs->addr_ptr = (u64)addr;\n\treturn 0;\n\nerr:\n\ti915_gem_object_put(obj);\n\treturn addr;\n}\n\nstatic unsigned int tile_row_pages(const struct drm_i915_gem_object *obj)\n{\n\treturn i915_gem_object_get_tile_row_size(obj) >> PAGE_SHIFT;\n}\n\n \nint i915_gem_mmap_gtt_version(void)\n{\n\treturn 4;\n}\n\nstatic inline struct i915_gtt_view\ncompute_partial_view(const struct drm_i915_gem_object *obj,\n\t\t     pgoff_t page_offset,\n\t\t     unsigned int chunk)\n{\n\tstruct i915_gtt_view view;\n\n\tif (i915_gem_object_is_tiled(obj))\n\t\tchunk = roundup(chunk, tile_row_pages(obj) ?: 1);\n\n\tview.type = I915_GTT_VIEW_PARTIAL;\n\tview.partial.offset = rounddown(page_offset, chunk);\n\tview.partial.size =\n\t\tmin_t(unsigned int, chunk,\n\t\t      (obj->base.size >> PAGE_SHIFT) - view.partial.offset);\n\n\t \n\tif (chunk >= obj->base.size >> PAGE_SHIFT)\n\t\tview.type = I915_GTT_VIEW_NORMAL;\n\n\treturn view;\n}\n\nstatic vm_fault_t i915_error_to_vmf_fault(int err)\n{\n\tswitch (err) {\n\tdefault:\n\t\tWARN_ONCE(err, \"unhandled error in %s: %i\\n\", __func__, err);\n\t\tfallthrough;\n\tcase -EIO:  \n\tcase -EFAULT:  \n\tcase -ENODEV:  \n\tcase -ENXIO:  \n\t\treturn VM_FAULT_SIGBUS;\n\n\tcase -ENOMEM:  \n\t\treturn VM_FAULT_OOM;\n\n\tcase 0:\n\tcase -EAGAIN:\n\tcase -ENOSPC:  \n\tcase -ENOBUFS:  \n\tcase -ERESTARTSYS:\n\tcase -EINTR:\n\tcase -EBUSY:\n\t\t \n\t\treturn VM_FAULT_NOPAGE;\n\t}\n}\n\nstatic vm_fault_t vm_fault_cpu(struct vm_fault *vmf)\n{\n\tstruct vm_area_struct *area = vmf->vma;\n\tstruct i915_mmap_offset *mmo = area->vm_private_data;\n\tstruct drm_i915_gem_object *obj = mmo->obj;\n\tresource_size_t iomap;\n\tint err;\n\n\t \n\tif (unlikely(i915_gem_object_is_readonly(obj) &&\n\t\t     area->vm_flags & VM_WRITE))\n\t\treturn VM_FAULT_SIGBUS;\n\n\tif (i915_gem_object_lock_interruptible(obj, NULL))\n\t\treturn VM_FAULT_NOPAGE;\n\n\terr = i915_gem_object_pin_pages(obj);\n\tif (err)\n\t\tgoto out;\n\n\tiomap = -1;\n\tif (!i915_gem_object_has_struct_page(obj)) {\n\t\tiomap = obj->mm.region->iomap.base;\n\t\tiomap -= obj->mm.region->region.start;\n\t}\n\n\t \n\terr = remap_io_sg(area,\n\t\t\t  area->vm_start, area->vm_end - area->vm_start,\n\t\t\t  obj->mm.pages->sgl, iomap);\n\n\tif (area->vm_flags & VM_WRITE) {\n\t\tGEM_BUG_ON(!i915_gem_object_has_pinned_pages(obj));\n\t\tobj->mm.dirty = true;\n\t}\n\n\ti915_gem_object_unpin_pages(obj);\n\nout:\n\ti915_gem_object_unlock(obj);\n\treturn i915_error_to_vmf_fault(err);\n}\n\nstatic vm_fault_t vm_fault_gtt(struct vm_fault *vmf)\n{\n#define MIN_CHUNK_PAGES (SZ_1M >> PAGE_SHIFT)\n\tstruct vm_area_struct *area = vmf->vma;\n\tstruct i915_mmap_offset *mmo = area->vm_private_data;\n\tstruct drm_i915_gem_object *obj = mmo->obj;\n\tstruct drm_device *dev = obj->base.dev;\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tstruct intel_runtime_pm *rpm = &i915->runtime_pm;\n\tstruct i915_ggtt *ggtt = to_gt(i915)->ggtt;\n\tbool write = area->vm_flags & VM_WRITE;\n\tstruct i915_gem_ww_ctx ww;\n\tintel_wakeref_t wakeref;\n\tstruct i915_vma *vma;\n\tpgoff_t page_offset;\n\tint srcu;\n\tint ret;\n\n\t \n\tpage_offset = (vmf->address - area->vm_start) >> PAGE_SHIFT;\n\n\ttrace_i915_gem_object_fault(obj, page_offset, true, write);\n\n\twakeref = intel_runtime_pm_get(rpm);\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\tret = i915_gem_object_lock(obj, &ww);\n\tif (ret)\n\t\tgoto err_rpm;\n\n\t \n\tif (i915_gem_object_is_readonly(obj) && write) {\n\t\tret = -EFAULT;\n\t\tgoto err_rpm;\n\t}\n\n\tret = i915_gem_object_pin_pages(obj);\n\tif (ret)\n\t\tgoto err_rpm;\n\n\tret = intel_gt_reset_lock_interruptible(ggtt->vm.gt, &srcu);\n\tif (ret)\n\t\tgoto err_pages;\n\n\t \n\tvma = i915_gem_object_ggtt_pin_ww(obj, &ww, NULL, 0, 0,\n\t\t\t\t\t  PIN_MAPPABLE |\n\t\t\t\t\t  PIN_NONBLOCK   |\n\t\t\t\t\t  PIN_NOEVICT);\n\tif (IS_ERR(vma) && vma != ERR_PTR(-EDEADLK)) {\n\t\t \n\t\tstruct i915_gtt_view view =\n\t\t\tcompute_partial_view(obj, page_offset, MIN_CHUNK_PAGES);\n\t\tunsigned int flags;\n\n\t\tflags = PIN_MAPPABLE | PIN_NOSEARCH;\n\t\tif (view.type == I915_GTT_VIEW_NORMAL)\n\t\t\tflags |= PIN_NONBLOCK;  \n\n\t\t \n\n\t\tvma = i915_gem_object_ggtt_pin_ww(obj, &ww, &view, 0, 0, flags);\n\t\tif (IS_ERR(vma) && vma != ERR_PTR(-EDEADLK)) {\n\t\t\tflags = PIN_MAPPABLE;\n\t\t\tview.type = I915_GTT_VIEW_PARTIAL;\n\t\t\tvma = i915_gem_object_ggtt_pin_ww(obj, &ww, &view, 0, 0, flags);\n\t\t}\n\n\t\t \n\t\tif (vma == ERR_PTR(-ENOSPC)) {\n\t\t\tret = mutex_lock_interruptible(&ggtt->vm.mutex);\n\t\t\tif (!ret) {\n\t\t\t\tret = i915_gem_evict_vm(&ggtt->vm, &ww, NULL);\n\t\t\t\tmutex_unlock(&ggtt->vm.mutex);\n\t\t\t}\n\t\t\tif (ret)\n\t\t\t\tgoto err_reset;\n\t\t\tvma = i915_gem_object_ggtt_pin_ww(obj, &ww, &view, 0, 0, flags);\n\t\t}\n\t}\n\tif (IS_ERR(vma)) {\n\t\tret = PTR_ERR(vma);\n\t\tgoto err_reset;\n\t}\n\n\t \n\t \n\tif (!(i915_gem_object_has_cache_level(obj, I915_CACHE_NONE) ||\n\t      HAS_LLC(i915))) {\n\t\tret = -EFAULT;\n\t\tgoto err_unpin;\n\t}\n\n\tret = i915_vma_pin_fence(vma);\n\tif (ret)\n\t\tgoto err_unpin;\n\n\t \n\tret = remap_io_mapping(area,\n\t\t\t       area->vm_start + (vma->gtt_view.partial.offset << PAGE_SHIFT),\n\t\t\t       (ggtt->gmadr.start + i915_ggtt_offset(vma)) >> PAGE_SHIFT,\n\t\t\t       min_t(u64, vma->size, area->vm_end - area->vm_start),\n\t\t\t       &ggtt->iomap);\n\tif (ret)\n\t\tgoto err_fence;\n\n\tassert_rpm_wakelock_held(rpm);\n\n\t \n\tmutex_lock(&to_gt(i915)->ggtt->vm.mutex);\n\tif (!i915_vma_set_userfault(vma) && !obj->userfault_count++)\n\t\tlist_add(&obj->userfault_link, &to_gt(i915)->ggtt->userfault_list);\n\tmutex_unlock(&to_gt(i915)->ggtt->vm.mutex);\n\n\t \n\tvma->mmo = mmo;\n\n\tif (CONFIG_DRM_I915_USERFAULT_AUTOSUSPEND)\n\t\tintel_wakeref_auto(&i915->runtime_pm.userfault_wakeref,\n\t\t\t\t   msecs_to_jiffies_timeout(CONFIG_DRM_I915_USERFAULT_AUTOSUSPEND));\n\n\tif (write) {\n\t\tGEM_BUG_ON(!i915_gem_object_has_pinned_pages(obj));\n\t\ti915_vma_set_ggtt_write(vma);\n\t\tobj->mm.dirty = true;\n\t}\n\nerr_fence:\n\ti915_vma_unpin_fence(vma);\nerr_unpin:\n\t__i915_vma_unpin(vma);\nerr_reset:\n\tintel_gt_reset_unlock(ggtt->vm.gt, srcu);\nerr_pages:\n\ti915_gem_object_unpin_pages(obj);\nerr_rpm:\n\tif (ret == -EDEADLK) {\n\t\tret = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!ret)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\tintel_runtime_pm_put(rpm, wakeref);\n\treturn i915_error_to_vmf_fault(ret);\n}\n\nstatic int\nvm_access(struct vm_area_struct *area, unsigned long addr,\n\t  void *buf, int len, int write)\n{\n\tstruct i915_mmap_offset *mmo = area->vm_private_data;\n\tstruct drm_i915_gem_object *obj = mmo->obj;\n\tstruct i915_gem_ww_ctx ww;\n\tvoid *vaddr;\n\tint err = 0;\n\n\tif (i915_gem_object_is_readonly(obj) && write)\n\t\treturn -EACCES;\n\n\taddr -= area->vm_start;\n\tif (range_overflows_t(u64, addr, len, obj->base.size))\n\t\treturn -EINVAL;\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\terr = i915_gem_object_lock(obj, &ww);\n\tif (err)\n\t\tgoto out;\n\n\t \n\tvaddr = i915_gem_object_pin_map(obj, I915_MAP_FORCE_WC);\n\tif (IS_ERR(vaddr)) {\n\t\terr = PTR_ERR(vaddr);\n\t\tgoto out;\n\t}\n\n\tif (write) {\n\t\tmemcpy(vaddr + addr, buf, len);\n\t\t__i915_gem_object_flush_map(obj, addr, len);\n\t} else {\n\t\tmemcpy(buf, vaddr + addr, len);\n\t}\n\n\ti915_gem_object_unpin_map(obj);\nout:\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\n\tif (err)\n\t\treturn err;\n\n\treturn len;\n}\n\nvoid __i915_gem_object_release_mmap_gtt(struct drm_i915_gem_object *obj)\n{\n\tstruct i915_vma *vma;\n\n\tGEM_BUG_ON(!obj->userfault_count);\n\n\tfor_each_ggtt_vma(vma, obj)\n\t\ti915_vma_revoke_mmap(vma);\n\n\tGEM_BUG_ON(obj->userfault_count);\n}\n\n \nvoid i915_gem_object_release_mmap_gtt(struct drm_i915_gem_object *obj)\n{\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\tintel_wakeref_t wakeref;\n\n\t \n\twakeref = intel_runtime_pm_get(&i915->runtime_pm);\n\tmutex_lock(&to_gt(i915)->ggtt->vm.mutex);\n\n\tif (!obj->userfault_count)\n\t\tgoto out;\n\n\t__i915_gem_object_release_mmap_gtt(obj);\n\n\t \n\twmb();\n\nout:\n\tmutex_unlock(&to_gt(i915)->ggtt->vm.mutex);\n\tintel_runtime_pm_put(&i915->runtime_pm, wakeref);\n}\n\nvoid i915_gem_object_runtime_pm_release_mmap_offset(struct drm_i915_gem_object *obj)\n{\n\tstruct ttm_buffer_object *bo = i915_gem_to_ttm(obj);\n\tstruct ttm_device *bdev = bo->bdev;\n\n\tdrm_vma_node_unmap(&bo->base.vma_node, bdev->dev_mapping);\n\n\t \n\tGEM_BUG_ON(!obj->userfault_count);\n\tlist_del(&obj->userfault_link);\n\tobj->userfault_count = 0;\n}\n\nvoid i915_gem_object_release_mmap_offset(struct drm_i915_gem_object *obj)\n{\n\tstruct i915_mmap_offset *mmo, *mn;\n\n\tif (obj->ops->unmap_virtual)\n\t\tobj->ops->unmap_virtual(obj);\n\n\tspin_lock(&obj->mmo.lock);\n\trbtree_postorder_for_each_entry_safe(mmo, mn,\n\t\t\t\t\t     &obj->mmo.offsets, offset) {\n\t\t \n\t\tif (mmo->mmap_type == I915_MMAP_TYPE_GTT)\n\t\t\tcontinue;\n\n\t\tspin_unlock(&obj->mmo.lock);\n\t\tdrm_vma_node_unmap(&mmo->vma_node,\n\t\t\t\t   obj->base.dev->anon_inode->i_mapping);\n\t\tspin_lock(&obj->mmo.lock);\n\t}\n\tspin_unlock(&obj->mmo.lock);\n}\n\nstatic struct i915_mmap_offset *\nlookup_mmo(struct drm_i915_gem_object *obj,\n\t   enum i915_mmap_type mmap_type)\n{\n\tstruct rb_node *rb;\n\n\tspin_lock(&obj->mmo.lock);\n\trb = obj->mmo.offsets.rb_node;\n\twhile (rb) {\n\t\tstruct i915_mmap_offset *mmo =\n\t\t\trb_entry(rb, typeof(*mmo), offset);\n\n\t\tif (mmo->mmap_type == mmap_type) {\n\t\t\tspin_unlock(&obj->mmo.lock);\n\t\t\treturn mmo;\n\t\t}\n\n\t\tif (mmo->mmap_type < mmap_type)\n\t\t\trb = rb->rb_right;\n\t\telse\n\t\t\trb = rb->rb_left;\n\t}\n\tspin_unlock(&obj->mmo.lock);\n\n\treturn NULL;\n}\n\nstatic struct i915_mmap_offset *\ninsert_mmo(struct drm_i915_gem_object *obj, struct i915_mmap_offset *mmo)\n{\n\tstruct rb_node *rb, **p;\n\n\tspin_lock(&obj->mmo.lock);\n\trb = NULL;\n\tp = &obj->mmo.offsets.rb_node;\n\twhile (*p) {\n\t\tstruct i915_mmap_offset *pos;\n\n\t\trb = *p;\n\t\tpos = rb_entry(rb, typeof(*pos), offset);\n\n\t\tif (pos->mmap_type == mmo->mmap_type) {\n\t\t\tspin_unlock(&obj->mmo.lock);\n\t\t\tdrm_vma_offset_remove(obj->base.dev->vma_offset_manager,\n\t\t\t\t\t      &mmo->vma_node);\n\t\t\tkfree(mmo);\n\t\t\treturn pos;\n\t\t}\n\n\t\tif (pos->mmap_type < mmo->mmap_type)\n\t\t\tp = &rb->rb_right;\n\t\telse\n\t\t\tp = &rb->rb_left;\n\t}\n\trb_link_node(&mmo->offset, rb, p);\n\trb_insert_color(&mmo->offset, &obj->mmo.offsets);\n\tspin_unlock(&obj->mmo.lock);\n\n\treturn mmo;\n}\n\nstatic struct i915_mmap_offset *\nmmap_offset_attach(struct drm_i915_gem_object *obj,\n\t\t   enum i915_mmap_type mmap_type,\n\t\t   struct drm_file *file)\n{\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\tstruct i915_mmap_offset *mmo;\n\tint err;\n\n\tGEM_BUG_ON(obj->ops->mmap_offset || obj->ops->mmap_ops);\n\n\tmmo = lookup_mmo(obj, mmap_type);\n\tif (mmo)\n\t\tgoto out;\n\n\tmmo = kmalloc(sizeof(*mmo), GFP_KERNEL);\n\tif (!mmo)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmmo->obj = obj;\n\tmmo->mmap_type = mmap_type;\n\tdrm_vma_node_reset(&mmo->vma_node);\n\n\terr = drm_vma_offset_add(obj->base.dev->vma_offset_manager,\n\t\t\t\t &mmo->vma_node, obj->base.size / PAGE_SIZE);\n\tif (likely(!err))\n\t\tgoto insert;\n\n\t \n\terr = intel_gt_retire_requests_timeout(to_gt(i915), MAX_SCHEDULE_TIMEOUT,\n\t\t\t\t\t       NULL);\n\tif (err)\n\t\tgoto err;\n\n\ti915_gem_drain_freed_objects(i915);\n\terr = drm_vma_offset_add(obj->base.dev->vma_offset_manager,\n\t\t\t\t &mmo->vma_node, obj->base.size / PAGE_SIZE);\n\tif (err)\n\t\tgoto err;\n\ninsert:\n\tmmo = insert_mmo(obj, mmo);\n\tGEM_BUG_ON(lookup_mmo(obj, mmap_type) != mmo);\nout:\n\tif (file)\n\t\tdrm_vma_node_allow_once(&mmo->vma_node, file);\n\treturn mmo;\n\nerr:\n\tkfree(mmo);\n\treturn ERR_PTR(err);\n}\n\nstatic int\n__assign_mmap_offset(struct drm_i915_gem_object *obj,\n\t\t     enum i915_mmap_type mmap_type,\n\t\t     u64 *offset, struct drm_file *file)\n{\n\tstruct i915_mmap_offset *mmo;\n\n\tif (i915_gem_object_never_mmap(obj))\n\t\treturn -ENODEV;\n\n\tif (obj->ops->mmap_offset)  {\n\t\tif (mmap_type != I915_MMAP_TYPE_FIXED)\n\t\t\treturn -ENODEV;\n\n\t\t*offset = obj->ops->mmap_offset(obj);\n\t\treturn 0;\n\t}\n\n\tif (mmap_type == I915_MMAP_TYPE_FIXED)\n\t\treturn -ENODEV;\n\n\tif (mmap_type != I915_MMAP_TYPE_GTT &&\n\t    !i915_gem_object_has_struct_page(obj) &&\n\t    !i915_gem_object_has_iomem(obj))\n\t\treturn -ENODEV;\n\n\tmmo = mmap_offset_attach(obj, mmap_type, file);\n\tif (IS_ERR(mmo))\n\t\treturn PTR_ERR(mmo);\n\n\t*offset = drm_vma_node_offset_addr(&mmo->vma_node);\n\treturn 0;\n}\n\nstatic int\n__assign_mmap_offset_handle(struct drm_file *file,\n\t\t\t    u32 handle,\n\t\t\t    enum i915_mmap_type mmap_type,\n\t\t\t    u64 *offset)\n{\n\tstruct drm_i915_gem_object *obj;\n\tint err;\n\n\tobj = i915_gem_object_lookup(file, handle);\n\tif (!obj)\n\t\treturn -ENOENT;\n\n\terr = i915_gem_object_lock_interruptible(obj, NULL);\n\tif (err)\n\t\tgoto out_put;\n\terr = __assign_mmap_offset(obj, mmap_type, offset, file);\n\ti915_gem_object_unlock(obj);\nout_put:\n\ti915_gem_object_put(obj);\n\treturn err;\n}\n\nint\ni915_gem_dumb_mmap_offset(struct drm_file *file,\n\t\t\t  struct drm_device *dev,\n\t\t\t  u32 handle,\n\t\t\t  u64 *offset)\n{\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tenum i915_mmap_type mmap_type;\n\n\tif (HAS_LMEM(to_i915(dev)))\n\t\tmmap_type = I915_MMAP_TYPE_FIXED;\n\telse if (pat_enabled())\n\t\tmmap_type = I915_MMAP_TYPE_WC;\n\telse if (!i915_ggtt_has_aperture(to_gt(i915)->ggtt))\n\t\treturn -ENODEV;\n\telse\n\t\tmmap_type = I915_MMAP_TYPE_GTT;\n\n\treturn __assign_mmap_offset_handle(file, handle, mmap_type, offset);\n}\n\n \nint\ni915_gem_mmap_offset_ioctl(struct drm_device *dev, void *data,\n\t\t\t   struct drm_file *file)\n{\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tstruct drm_i915_gem_mmap_offset *args = data;\n\tenum i915_mmap_type type;\n\tint err;\n\n\t \n\n\terr = i915_user_extensions(u64_to_user_ptr(args->extensions),\n\t\t\t\t   NULL, 0, NULL);\n\tif (err)\n\t\treturn err;\n\n\tswitch (args->flags) {\n\tcase I915_MMAP_OFFSET_GTT:\n\t\tif (!i915_ggtt_has_aperture(to_gt(i915)->ggtt))\n\t\t\treturn -ENODEV;\n\t\ttype = I915_MMAP_TYPE_GTT;\n\t\tbreak;\n\n\tcase I915_MMAP_OFFSET_WC:\n\t\tif (!pat_enabled())\n\t\t\treturn -ENODEV;\n\t\ttype = I915_MMAP_TYPE_WC;\n\t\tbreak;\n\n\tcase I915_MMAP_OFFSET_WB:\n\t\ttype = I915_MMAP_TYPE_WB;\n\t\tbreak;\n\n\tcase I915_MMAP_OFFSET_UC:\n\t\tif (!pat_enabled())\n\t\t\treturn -ENODEV;\n\t\ttype = I915_MMAP_TYPE_UC;\n\t\tbreak;\n\n\tcase I915_MMAP_OFFSET_FIXED:\n\t\ttype = I915_MMAP_TYPE_FIXED;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn __assign_mmap_offset_handle(file, args->handle, type, &args->offset);\n}\n\nstatic void vm_open(struct vm_area_struct *vma)\n{\n\tstruct i915_mmap_offset *mmo = vma->vm_private_data;\n\tstruct drm_i915_gem_object *obj = mmo->obj;\n\n\tGEM_BUG_ON(!obj);\n\ti915_gem_object_get(obj);\n}\n\nstatic void vm_close(struct vm_area_struct *vma)\n{\n\tstruct i915_mmap_offset *mmo = vma->vm_private_data;\n\tstruct drm_i915_gem_object *obj = mmo->obj;\n\n\tGEM_BUG_ON(!obj);\n\ti915_gem_object_put(obj);\n}\n\nstatic const struct vm_operations_struct vm_ops_gtt = {\n\t.fault = vm_fault_gtt,\n\t.access = vm_access,\n\t.open = vm_open,\n\t.close = vm_close,\n};\n\nstatic const struct vm_operations_struct vm_ops_cpu = {\n\t.fault = vm_fault_cpu,\n\t.access = vm_access,\n\t.open = vm_open,\n\t.close = vm_close,\n};\n\nstatic int singleton_release(struct inode *inode, struct file *file)\n{\n\tstruct drm_i915_private *i915 = file->private_data;\n\n\tcmpxchg(&i915->gem.mmap_singleton, file, NULL);\n\tdrm_dev_put(&i915->drm);\n\n\treturn 0;\n}\n\nstatic const struct file_operations singleton_fops = {\n\t.owner = THIS_MODULE,\n\t.release = singleton_release,\n};\n\nstatic struct file *mmap_singleton(struct drm_i915_private *i915)\n{\n\tstruct file *file;\n\n\trcu_read_lock();\n\tfile = READ_ONCE(i915->gem.mmap_singleton);\n\tif (file && !get_file_rcu(file))\n\t\tfile = NULL;\n\trcu_read_unlock();\n\tif (file)\n\t\treturn file;\n\n\tfile = anon_inode_getfile(\"i915.gem\", &singleton_fops, i915, O_RDWR);\n\tif (IS_ERR(file))\n\t\treturn file;\n\n\t \n\tfile->f_mapping = i915->drm.anon_inode->i_mapping;\n\n\tsmp_store_mb(i915->gem.mmap_singleton, file);\n\tdrm_dev_get(&i915->drm);\n\n\treturn file;\n}\n\nstatic int\ni915_gem_object_mmap(struct drm_i915_gem_object *obj,\n\t\t     struct i915_mmap_offset *mmo,\n\t\t     struct vm_area_struct *vma)\n{\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\tstruct drm_device *dev = &i915->drm;\n\tstruct file *anon;\n\n\tif (i915_gem_object_is_readonly(obj)) {\n\t\tif (vma->vm_flags & VM_WRITE) {\n\t\t\ti915_gem_object_put(obj);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tvm_flags_clear(vma, VM_MAYWRITE);\n\t}\n\n\tanon = mmap_singleton(to_i915(dev));\n\tif (IS_ERR(anon)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn PTR_ERR(anon);\n\t}\n\n\tvm_flags_set(vma, VM_PFNMAP | VM_DONTEXPAND | VM_DONTDUMP | VM_IO);\n\n\t \n\tvma_set_file(vma, anon);\n\t \n\tfput(anon);\n\n\tif (obj->ops->mmap_ops) {\n\t\tvma->vm_page_prot = pgprot_decrypted(vm_get_page_prot(vma->vm_flags));\n\t\tvma->vm_ops = obj->ops->mmap_ops;\n\t\tvma->vm_private_data = obj->base.vma_node.driver_private;\n\t\treturn 0;\n\t}\n\n\tvma->vm_private_data = mmo;\n\n\tswitch (mmo->mmap_type) {\n\tcase I915_MMAP_TYPE_WC:\n\t\tvma->vm_page_prot =\n\t\t\tpgprot_writecombine(vm_get_page_prot(vma->vm_flags));\n\t\tvma->vm_ops = &vm_ops_cpu;\n\t\tbreak;\n\n\tcase I915_MMAP_TYPE_FIXED:\n\t\tGEM_WARN_ON(1);\n\t\tfallthrough;\n\tcase I915_MMAP_TYPE_WB:\n\t\tvma->vm_page_prot = vm_get_page_prot(vma->vm_flags);\n\t\tvma->vm_ops = &vm_ops_cpu;\n\t\tbreak;\n\n\tcase I915_MMAP_TYPE_UC:\n\t\tvma->vm_page_prot =\n\t\t\tpgprot_noncached(vm_get_page_prot(vma->vm_flags));\n\t\tvma->vm_ops = &vm_ops_cpu;\n\t\tbreak;\n\n\tcase I915_MMAP_TYPE_GTT:\n\t\tvma->vm_page_prot =\n\t\t\tpgprot_writecombine(vm_get_page_prot(vma->vm_flags));\n\t\tvma->vm_ops = &vm_ops_gtt;\n\t\tbreak;\n\t}\n\tvma->vm_page_prot = pgprot_decrypted(vma->vm_page_prot);\n\n\treturn 0;\n}\n\n \nint i915_gem_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\tstruct drm_vma_offset_node *node;\n\tstruct drm_file *priv = filp->private_data;\n\tstruct drm_device *dev = priv->minor->dev;\n\tstruct drm_i915_gem_object *obj = NULL;\n\tstruct i915_mmap_offset *mmo = NULL;\n\n\tif (drm_dev_is_unplugged(dev))\n\t\treturn -ENODEV;\n\n\trcu_read_lock();\n\tdrm_vma_offset_lock_lookup(dev->vma_offset_manager);\n\tnode = drm_vma_offset_exact_lookup_locked(dev->vma_offset_manager,\n\t\t\t\t\t\t  vma->vm_pgoff,\n\t\t\t\t\t\t  vma_pages(vma));\n\tif (node && drm_vma_node_is_allowed(node, priv)) {\n\t\t \n\t\tif (!node->driver_private) {\n\t\t\tmmo = container_of(node, struct i915_mmap_offset, vma_node);\n\t\t\tobj = i915_gem_object_get_rcu(mmo->obj);\n\n\t\t\tGEM_BUG_ON(obj && obj->ops->mmap_ops);\n\t\t} else {\n\t\t\tobj = i915_gem_object_get_rcu\n\t\t\t\t(container_of(node, struct drm_i915_gem_object,\n\t\t\t\t\t      base.vma_node));\n\n\t\t\tGEM_BUG_ON(obj && !obj->ops->mmap_ops);\n\t\t}\n\t}\n\tdrm_vma_offset_unlock_lookup(dev->vma_offset_manager);\n\trcu_read_unlock();\n\tif (!obj)\n\t\treturn node ? -EACCES : -EINVAL;\n\n\treturn i915_gem_object_mmap(obj, mmo, vma);\n}\n\nint i915_gem_fb_mmap(struct drm_i915_gem_object *obj, struct vm_area_struct *vma)\n{\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\tstruct drm_device *dev = &i915->drm;\n\tstruct i915_mmap_offset *mmo = NULL;\n\tenum i915_mmap_type mmap_type;\n\tstruct i915_ggtt *ggtt = to_gt(i915)->ggtt;\n\n\tif (drm_dev_is_unplugged(dev))\n\t\treturn -ENODEV;\n\n\t \n\tif (obj->ops->mmap_ops) {\n\t\t \n\t\tvma->vm_pgoff += drm_vma_node_start(&obj->base.vma_node);\n\t} else {\n\t\t \n\t\tmmap_type = i915_ggtt_has_aperture(ggtt) ? I915_MMAP_TYPE_GTT : I915_MMAP_TYPE_WC;\n\t\tmmo = mmap_offset_attach(obj, mmap_type, NULL);\n\t\tif (IS_ERR(mmo))\n\t\t\treturn PTR_ERR(mmo);\n\t}\n\n\t \n\tobj = i915_gem_object_get(obj);\n\treturn i915_gem_object_mmap(obj, mmo, vma);\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_SELFTEST)\n#include \"selftests/i915_gem_mman.c\"\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}