{
  "module_name": "i915_gem_stolen.c",
  "hash_id": "81746fff70acb5776c972dc2d760c481bcc25ccad5b972bd333b6d1b1512278a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gem/i915_gem_stolen.c",
  "human_readable_source": " \n\n#include <linux/errno.h>\n#include <linux/mutex.h>\n\n#include <drm/drm_mm.h>\n#include <drm/i915_drm.h>\n\n#include \"gem/i915_gem_lmem.h\"\n#include \"gem/i915_gem_region.h\"\n#include \"gt/intel_gt.h\"\n#include \"gt/intel_gt_mcr.h\"\n#include \"gt/intel_gt_regs.h\"\n#include \"gt/intel_region_lmem.h\"\n#include \"i915_drv.h\"\n#include \"i915_gem_stolen.h\"\n#include \"i915_pci.h\"\n#include \"i915_reg.h\"\n#include \"i915_utils.h\"\n#include \"i915_vgpu.h\"\n#include \"intel_mchbar_regs.h\"\n#include \"intel_pci_config.h\"\n\n \n\nint i915_gem_stolen_insert_node_in_range(struct drm_i915_private *i915,\n\t\t\t\t\t struct drm_mm_node *node, u64 size,\n\t\t\t\t\t unsigned alignment, u64 start, u64 end)\n{\n\tint ret;\n\n\tif (!drm_mm_initialized(&i915->mm.stolen))\n\t\treturn -ENODEV;\n\n\t \n\tif (GRAPHICS_VER(i915) >= 8 && start < 4096)\n\t\tstart = 4096;\n\n\tmutex_lock(&i915->mm.stolen_lock);\n\tret = drm_mm_insert_node_in_range(&i915->mm.stolen, node,\n\t\t\t\t\t  size, alignment, 0,\n\t\t\t\t\t  start, end, DRM_MM_INSERT_BEST);\n\tmutex_unlock(&i915->mm.stolen_lock);\n\n\treturn ret;\n}\n\nint i915_gem_stolen_insert_node(struct drm_i915_private *i915,\n\t\t\t\tstruct drm_mm_node *node, u64 size,\n\t\t\t\tunsigned alignment)\n{\n\treturn i915_gem_stolen_insert_node_in_range(i915, node,\n\t\t\t\t\t\t    size, alignment,\n\t\t\t\t\t\t    I915_GEM_STOLEN_BIAS,\n\t\t\t\t\t\t    U64_MAX);\n}\n\nvoid i915_gem_stolen_remove_node(struct drm_i915_private *i915,\n\t\t\t\t struct drm_mm_node *node)\n{\n\tmutex_lock(&i915->mm.stolen_lock);\n\tdrm_mm_remove_node(node);\n\tmutex_unlock(&i915->mm.stolen_lock);\n}\n\nstatic bool valid_stolen_size(struct drm_i915_private *i915, struct resource *dsm)\n{\n\treturn (dsm->start != 0 || HAS_LMEMBAR_SMEM_STOLEN(i915)) && dsm->end > dsm->start;\n}\n\nstatic int adjust_stolen(struct drm_i915_private *i915,\n\t\t\t struct resource *dsm)\n{\n\tstruct i915_ggtt *ggtt = to_gt(i915)->ggtt;\n\tstruct intel_uncore *uncore = ggtt->vm.gt->uncore;\n\n\tif (!valid_stolen_size(i915, dsm))\n\t\treturn -EINVAL;\n\n\t \n\tif (GRAPHICS_VER(i915) <= 4 &&\n\t    !IS_G33(i915) && !IS_PINEVIEW(i915) && !IS_G4X(i915)) {\n\t\tstruct resource stolen[2] = {*dsm, *dsm};\n\t\tstruct resource ggtt_res;\n\t\tresource_size_t ggtt_start;\n\n\t\tggtt_start = intel_uncore_read(uncore, PGTBL_CTL);\n\t\tif (GRAPHICS_VER(i915) == 4)\n\t\t\tggtt_start = (ggtt_start & PGTBL_ADDRESS_LO_MASK) |\n\t\t\t\t     (ggtt_start & PGTBL_ADDRESS_HI_MASK) << 28;\n\t\telse\n\t\t\tggtt_start &= PGTBL_ADDRESS_LO_MASK;\n\n\t\tggtt_res = DEFINE_RES_MEM(ggtt_start, ggtt_total_entries(ggtt) * 4);\n\n\t\tif (ggtt_res.start >= stolen[0].start && ggtt_res.start < stolen[0].end)\n\t\t\tstolen[0].end = ggtt_res.start;\n\t\tif (ggtt_res.end > stolen[1].start && ggtt_res.end <= stolen[1].end)\n\t\t\tstolen[1].start = ggtt_res.end;\n\n\t\t \n\t\tif (resource_size(&stolen[0]) > resource_size(&stolen[1]))\n\t\t\t*dsm = stolen[0];\n\t\telse\n\t\t\t*dsm = stolen[1];\n\n\t\tif (stolen[0].start != stolen[1].start ||\n\t\t    stolen[0].end != stolen[1].end) {\n\t\t\tdrm_dbg(&i915->drm,\n\t\t\t\t\"GTT within stolen memory at %pR\\n\",\n\t\t\t\t&ggtt_res);\n\t\t\tdrm_dbg(&i915->drm, \"Stolen memory adjusted to %pR\\n\",\n\t\t\t\tdsm);\n\t\t}\n\t}\n\n\tif (!valid_stolen_size(i915, dsm))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int request_smem_stolen(struct drm_i915_private *i915,\n\t\t\t       struct resource *dsm)\n{\n\tstruct resource *r;\n\n\t \n\tif (HAS_LMEM(i915) || HAS_LMEMBAR_SMEM_STOLEN(i915))\n\t\treturn 0;\n\n\t \n\tr = devm_request_mem_region(i915->drm.dev, dsm->start,\n\t\t\t\t    resource_size(dsm),\n\t\t\t\t    \"Graphics Stolen Memory\");\n\tif (r == NULL) {\n\t\t \n\t\tr = devm_request_mem_region(i915->drm.dev, dsm->start + 1,\n\t\t\t\t\t    resource_size(dsm) - 2,\n\t\t\t\t\t    \"Graphics Stolen Memory\");\n\t\t \n\t\tif (!r && GRAPHICS_VER(i915) != 3) {\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"conflict detected with stolen region: %pR\\n\",\n\t\t\t\tdsm);\n\n\t\t\treturn -EBUSY;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void i915_gem_cleanup_stolen(struct drm_i915_private *i915)\n{\n\tif (!drm_mm_initialized(&i915->mm.stolen))\n\t\treturn;\n\n\tdrm_mm_takedown(&i915->mm.stolen);\n}\n\nstatic void g4x_get_stolen_reserved(struct drm_i915_private *i915,\n\t\t\t\t    struct intel_uncore *uncore,\n\t\t\t\t    resource_size_t *base,\n\t\t\t\t    resource_size_t *size)\n{\n\tu32 reg_val = intel_uncore_read(uncore,\n\t\t\t\t\tIS_GM45(i915) ?\n\t\t\t\t\tCTG_STOLEN_RESERVED :\n\t\t\t\t\tELK_STOLEN_RESERVED);\n\tresource_size_t stolen_top = i915->dsm.stolen.end + 1;\n\n\tdrm_dbg(&i915->drm, \"%s_STOLEN_RESERVED = %08x\\n\",\n\t\tIS_GM45(i915) ? \"CTG\" : \"ELK\", reg_val);\n\n\tif ((reg_val & G4X_STOLEN_RESERVED_ENABLE) == 0)\n\t\treturn;\n\n\t \n\tdrm_WARN(&i915->drm, GRAPHICS_VER(i915) == 5,\n\t\t \"ILK stolen reserved found? 0x%08x\\n\",\n\t\t reg_val);\n\n\tif (!(reg_val & G4X_STOLEN_RESERVED_ADDR2_MASK))\n\t\treturn;\n\n\t*base = (reg_val & G4X_STOLEN_RESERVED_ADDR2_MASK) << 16;\n\tdrm_WARN_ON(&i915->drm,\n\t\t    (reg_val & G4X_STOLEN_RESERVED_ADDR1_MASK) < *base);\n\n\t*size = stolen_top - *base;\n}\n\nstatic void gen6_get_stolen_reserved(struct drm_i915_private *i915,\n\t\t\t\t     struct intel_uncore *uncore,\n\t\t\t\t     resource_size_t *base,\n\t\t\t\t     resource_size_t *size)\n{\n\tu32 reg_val = intel_uncore_read(uncore, GEN6_STOLEN_RESERVED);\n\n\tdrm_dbg(&i915->drm, \"GEN6_STOLEN_RESERVED = %08x\\n\", reg_val);\n\n\tif (!(reg_val & GEN6_STOLEN_RESERVED_ENABLE))\n\t\treturn;\n\n\t*base = reg_val & GEN6_STOLEN_RESERVED_ADDR_MASK;\n\n\tswitch (reg_val & GEN6_STOLEN_RESERVED_SIZE_MASK) {\n\tcase GEN6_STOLEN_RESERVED_1M:\n\t\t*size = 1024 * 1024;\n\t\tbreak;\n\tcase GEN6_STOLEN_RESERVED_512K:\n\t\t*size = 512 * 1024;\n\t\tbreak;\n\tcase GEN6_STOLEN_RESERVED_256K:\n\t\t*size = 256 * 1024;\n\t\tbreak;\n\tcase GEN6_STOLEN_RESERVED_128K:\n\t\t*size = 128 * 1024;\n\t\tbreak;\n\tdefault:\n\t\t*size = 1024 * 1024;\n\t\tMISSING_CASE(reg_val & GEN6_STOLEN_RESERVED_SIZE_MASK);\n\t}\n}\n\nstatic void vlv_get_stolen_reserved(struct drm_i915_private *i915,\n\t\t\t\t    struct intel_uncore *uncore,\n\t\t\t\t    resource_size_t *base,\n\t\t\t\t    resource_size_t *size)\n{\n\tu32 reg_val = intel_uncore_read(uncore, GEN6_STOLEN_RESERVED);\n\tresource_size_t stolen_top = i915->dsm.stolen.end + 1;\n\n\tdrm_dbg(&i915->drm, \"GEN6_STOLEN_RESERVED = %08x\\n\", reg_val);\n\n\tif (!(reg_val & GEN6_STOLEN_RESERVED_ENABLE))\n\t\treturn;\n\n\tswitch (reg_val & GEN7_STOLEN_RESERVED_SIZE_MASK) {\n\tdefault:\n\t\tMISSING_CASE(reg_val & GEN7_STOLEN_RESERVED_SIZE_MASK);\n\t\tfallthrough;\n\tcase GEN7_STOLEN_RESERVED_1M:\n\t\t*size = 1024 * 1024;\n\t\tbreak;\n\t}\n\n\t \n\t*base = stolen_top - *size;\n}\n\nstatic void gen7_get_stolen_reserved(struct drm_i915_private *i915,\n\t\t\t\t     struct intel_uncore *uncore,\n\t\t\t\t     resource_size_t *base,\n\t\t\t\t     resource_size_t *size)\n{\n\tu32 reg_val = intel_uncore_read(uncore, GEN6_STOLEN_RESERVED);\n\n\tdrm_dbg(&i915->drm, \"GEN6_STOLEN_RESERVED = %08x\\n\", reg_val);\n\n\tif (!(reg_val & GEN6_STOLEN_RESERVED_ENABLE))\n\t\treturn;\n\n\t*base = reg_val & GEN7_STOLEN_RESERVED_ADDR_MASK;\n\n\tswitch (reg_val & GEN7_STOLEN_RESERVED_SIZE_MASK) {\n\tcase GEN7_STOLEN_RESERVED_1M:\n\t\t*size = 1024 * 1024;\n\t\tbreak;\n\tcase GEN7_STOLEN_RESERVED_256K:\n\t\t*size = 256 * 1024;\n\t\tbreak;\n\tdefault:\n\t\t*size = 1024 * 1024;\n\t\tMISSING_CASE(reg_val & GEN7_STOLEN_RESERVED_SIZE_MASK);\n\t}\n}\n\nstatic void chv_get_stolen_reserved(struct drm_i915_private *i915,\n\t\t\t\t    struct intel_uncore *uncore,\n\t\t\t\t    resource_size_t *base,\n\t\t\t\t    resource_size_t *size)\n{\n\tu32 reg_val = intel_uncore_read(uncore, GEN6_STOLEN_RESERVED);\n\n\tdrm_dbg(&i915->drm, \"GEN6_STOLEN_RESERVED = %08x\\n\", reg_val);\n\n\tif (!(reg_val & GEN6_STOLEN_RESERVED_ENABLE))\n\t\treturn;\n\n\t*base = reg_val & GEN6_STOLEN_RESERVED_ADDR_MASK;\n\n\tswitch (reg_val & GEN8_STOLEN_RESERVED_SIZE_MASK) {\n\tcase GEN8_STOLEN_RESERVED_1M:\n\t\t*size = 1024 * 1024;\n\t\tbreak;\n\tcase GEN8_STOLEN_RESERVED_2M:\n\t\t*size = 2 * 1024 * 1024;\n\t\tbreak;\n\tcase GEN8_STOLEN_RESERVED_4M:\n\t\t*size = 4 * 1024 * 1024;\n\t\tbreak;\n\tcase GEN8_STOLEN_RESERVED_8M:\n\t\t*size = 8 * 1024 * 1024;\n\t\tbreak;\n\tdefault:\n\t\t*size = 8 * 1024 * 1024;\n\t\tMISSING_CASE(reg_val & GEN8_STOLEN_RESERVED_SIZE_MASK);\n\t}\n}\n\nstatic void bdw_get_stolen_reserved(struct drm_i915_private *i915,\n\t\t\t\t    struct intel_uncore *uncore,\n\t\t\t\t    resource_size_t *base,\n\t\t\t\t    resource_size_t *size)\n{\n\tu32 reg_val = intel_uncore_read(uncore, GEN6_STOLEN_RESERVED);\n\tresource_size_t stolen_top = i915->dsm.stolen.end + 1;\n\n\tdrm_dbg(&i915->drm, \"GEN6_STOLEN_RESERVED = %08x\\n\", reg_val);\n\n\tif (!(reg_val & GEN6_STOLEN_RESERVED_ENABLE))\n\t\treturn;\n\n\tif (!(reg_val & GEN6_STOLEN_RESERVED_ADDR_MASK))\n\t\treturn;\n\n\t*base = reg_val & GEN6_STOLEN_RESERVED_ADDR_MASK;\n\t*size = stolen_top - *base;\n}\n\nstatic void icl_get_stolen_reserved(struct drm_i915_private *i915,\n\t\t\t\t    struct intel_uncore *uncore,\n\t\t\t\t    resource_size_t *base,\n\t\t\t\t    resource_size_t *size)\n{\n\tu64 reg_val = intel_uncore_read64(uncore, GEN6_STOLEN_RESERVED);\n\n\tdrm_dbg(&i915->drm, \"GEN6_STOLEN_RESERVED = 0x%016llx\\n\", reg_val);\n\n\tswitch (reg_val & GEN8_STOLEN_RESERVED_SIZE_MASK) {\n\tcase GEN8_STOLEN_RESERVED_1M:\n\t\t*size = 1024 * 1024;\n\t\tbreak;\n\tcase GEN8_STOLEN_RESERVED_2M:\n\t\t*size = 2 * 1024 * 1024;\n\t\tbreak;\n\tcase GEN8_STOLEN_RESERVED_4M:\n\t\t*size = 4 * 1024 * 1024;\n\t\tbreak;\n\tcase GEN8_STOLEN_RESERVED_8M:\n\t\t*size = 8 * 1024 * 1024;\n\t\tbreak;\n\tdefault:\n\t\t*size = 8 * 1024 * 1024;\n\t\tMISSING_CASE(reg_val & GEN8_STOLEN_RESERVED_SIZE_MASK);\n\t}\n\n\tif (HAS_LMEMBAR_SMEM_STOLEN(i915))\n\t\t \n\t\t*base -= *size;\n\telse\n\t\t*base = reg_val & GEN11_STOLEN_RESERVED_ADDR_MASK;\n}\n\n \nstatic int init_reserved_stolen(struct drm_i915_private *i915)\n{\n\tstruct intel_uncore *uncore = &i915->uncore;\n\tresource_size_t reserved_base, stolen_top;\n\tresource_size_t reserved_size;\n\tint ret = 0;\n\n\tstolen_top = i915->dsm.stolen.end + 1;\n\treserved_base = stolen_top;\n\treserved_size = 0;\n\n\tif (GRAPHICS_VER(i915) >= 11) {\n\t\ticl_get_stolen_reserved(i915, uncore,\n\t\t\t\t\t&reserved_base, &reserved_size);\n\t} else if (GRAPHICS_VER(i915) >= 8) {\n\t\tif (IS_LP(i915))\n\t\t\tchv_get_stolen_reserved(i915, uncore,\n\t\t\t\t\t\t&reserved_base, &reserved_size);\n\t\telse\n\t\t\tbdw_get_stolen_reserved(i915, uncore,\n\t\t\t\t\t\t&reserved_base, &reserved_size);\n\t} else if (GRAPHICS_VER(i915) >= 7) {\n\t\tif (IS_VALLEYVIEW(i915))\n\t\t\tvlv_get_stolen_reserved(i915, uncore,\n\t\t\t\t\t\t&reserved_base, &reserved_size);\n\t\telse\n\t\t\tgen7_get_stolen_reserved(i915, uncore,\n\t\t\t\t\t\t &reserved_base, &reserved_size);\n\t} else if (GRAPHICS_VER(i915) >= 6) {\n\t\tgen6_get_stolen_reserved(i915, uncore,\n\t\t\t\t\t &reserved_base, &reserved_size);\n\t} else if (GRAPHICS_VER(i915) >= 5 || IS_G4X(i915)) {\n\t\tg4x_get_stolen_reserved(i915, uncore,\n\t\t\t\t\t&reserved_base, &reserved_size);\n\t}\n\n\t \n\tif (reserved_base == stolen_top)\n\t\tgoto bail_out;\n\n\tif (!reserved_base) {\n\t\tdrm_err(&i915->drm,\n\t\t\t\"inconsistent reservation %pa + %pa; ignoring\\n\",\n\t\t\t&reserved_base, &reserved_size);\n\t\tret = -EINVAL;\n\t\tgoto bail_out;\n\t}\n\n\ti915->dsm.reserved = DEFINE_RES_MEM(reserved_base, reserved_size);\n\n\tif (!resource_contains(&i915->dsm.stolen, &i915->dsm.reserved)) {\n\t\tdrm_err(&i915->drm,\n\t\t\t\"Stolen reserved area %pR outside stolen memory %pR\\n\",\n\t\t\t&i915->dsm.reserved, &i915->dsm.stolen);\n\t\tret = -EINVAL;\n\t\tgoto bail_out;\n\t}\n\n\treturn 0;\n\nbail_out:\n\ti915->dsm.reserved = DEFINE_RES_MEM(reserved_base, 0);\n\n\treturn ret;\n}\n\nstatic int i915_gem_init_stolen(struct intel_memory_region *mem)\n{\n\tstruct drm_i915_private *i915 = mem->i915;\n\n\tmutex_init(&i915->mm.stolen_lock);\n\n\tif (intel_vgpu_active(i915)) {\n\t\tdrm_notice(&i915->drm,\n\t\t\t   \"%s, disabling use of stolen memory\\n\",\n\t\t\t   \"iGVT-g active\");\n\t\treturn -ENOSPC;\n\t}\n\n\tif (i915_vtd_active(i915) && GRAPHICS_VER(i915) < 8) {\n\t\tdrm_notice(&i915->drm,\n\t\t\t   \"%s, disabling use of stolen memory\\n\",\n\t\t\t   \"DMAR active\");\n\t\treturn -ENOSPC;\n\t}\n\n\tif (adjust_stolen(i915, &mem->region))\n\t\treturn -ENOSPC;\n\n\tif (request_smem_stolen(i915, &mem->region))\n\t\treturn -ENOSPC;\n\n\ti915->dsm.stolen = mem->region;\n\n\tif (init_reserved_stolen(i915))\n\t\treturn -ENOSPC;\n\n\t \n\tmem->region.end = i915->dsm.reserved.start - 1;\n\tmem->io_size = min(mem->io_size, resource_size(&mem->region));\n\n\ti915->dsm.usable_size = resource_size(&mem->region);\n\n\tdrm_dbg(&i915->drm,\n\t\t\"Memory reserved for graphics device: %lluK, usable: %lluK\\n\",\n\t\t(u64)resource_size(&i915->dsm.stolen) >> 10,\n\t\t(u64)i915->dsm.usable_size >> 10);\n\n\tif (i915->dsm.usable_size == 0)\n\t\treturn -ENOSPC;\n\n\t \n\tdrm_mm_init(&i915->mm.stolen, 0, i915->dsm.usable_size);\n\n\t \n\tif (IS_METEORLAKE(i915) && INTEL_REVID(i915) == 0x0)\n\t\ti915->dsm.usable_size = 0;\n\n\treturn 0;\n}\n\nstatic void dbg_poison(struct i915_ggtt *ggtt,\n\t\t       dma_addr_t addr, resource_size_t size,\n\t\t       u8 x)\n{\n#if IS_ENABLED(CONFIG_DRM_I915_DEBUG_GEM)\n\tif (!drm_mm_node_allocated(&ggtt->error_capture))\n\t\treturn;\n\n\tif (ggtt->vm.bind_async_flags & I915_VMA_GLOBAL_BIND)\n\t\treturn;  \n\n\tGEM_BUG_ON(!IS_ALIGNED(size, PAGE_SIZE));\n\n\tmutex_lock(&ggtt->error_mutex);\n\twhile (size) {\n\t\tvoid __iomem *s;\n\n\t\tggtt->vm.insert_page(&ggtt->vm, addr,\n\t\t\t\t     ggtt->error_capture.start,\n\t\t\t\t     i915_gem_get_pat_index(ggtt->vm.i915,\n\t\t\t\t\t\t\t    I915_CACHE_NONE),\n\t\t\t\t     0);\n\t\tmb();\n\n\t\ts = io_mapping_map_wc(&ggtt->iomap,\n\t\t\t\t      ggtt->error_capture.start,\n\t\t\t\t      PAGE_SIZE);\n\t\tmemset_io(s, x, PAGE_SIZE);\n\t\tio_mapping_unmap(s);\n\n\t\taddr += PAGE_SIZE;\n\t\tsize -= PAGE_SIZE;\n\t}\n\tmb();\n\tggtt->vm.clear_range(&ggtt->vm, ggtt->error_capture.start, PAGE_SIZE);\n\tmutex_unlock(&ggtt->error_mutex);\n#endif\n}\n\nstatic struct sg_table *\ni915_pages_create_for_stolen(struct drm_device *dev,\n\t\t\t     resource_size_t offset, resource_size_t size)\n{\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tstruct sg_table *st;\n\tstruct scatterlist *sg;\n\n\tGEM_BUG_ON(range_overflows(offset, size, resource_size(&i915->dsm.stolen)));\n\n\t \n\n\tst = kmalloc(sizeof(*st), GFP_KERNEL);\n\tif (st == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (sg_alloc_table(st, 1, GFP_KERNEL)) {\n\t\tkfree(st);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tsg = st->sgl;\n\tsg->offset = 0;\n\tsg->length = size;\n\n\tsg_dma_address(sg) = (dma_addr_t)i915->dsm.stolen.start + offset;\n\tsg_dma_len(sg) = size;\n\n\treturn st;\n}\n\nstatic int i915_gem_object_get_pages_stolen(struct drm_i915_gem_object *obj)\n{\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\tstruct sg_table *pages =\n\t\ti915_pages_create_for_stolen(obj->base.dev,\n\t\t\t\t\t     obj->stolen->start,\n\t\t\t\t\t     obj->stolen->size);\n\tif (IS_ERR(pages))\n\t\treturn PTR_ERR(pages);\n\n\tdbg_poison(to_gt(i915)->ggtt,\n\t\t   sg_dma_address(pages->sgl),\n\t\t   sg_dma_len(pages->sgl),\n\t\t   POISON_INUSE);\n\n\t__i915_gem_object_set_pages(obj, pages);\n\n\treturn 0;\n}\n\nstatic void i915_gem_object_put_pages_stolen(struct drm_i915_gem_object *obj,\n\t\t\t\t\t     struct sg_table *pages)\n{\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\t \n\n\tdbg_poison(to_gt(i915)->ggtt,\n\t\t   sg_dma_address(pages->sgl),\n\t\t   sg_dma_len(pages->sgl),\n\t\t   POISON_FREE);\n\n\tsg_free_table(pages);\n\tkfree(pages);\n}\n\nstatic void\ni915_gem_object_release_stolen(struct drm_i915_gem_object *obj)\n{\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\tstruct drm_mm_node *stolen = fetch_and_zero(&obj->stolen);\n\n\tGEM_BUG_ON(!stolen);\n\ti915_gem_stolen_remove_node(i915, stolen);\n\tkfree(stolen);\n\n\ti915_gem_object_release_memory_region(obj);\n}\n\nstatic const struct drm_i915_gem_object_ops i915_gem_object_stolen_ops = {\n\t.name = \"i915_gem_object_stolen\",\n\t.get_pages = i915_gem_object_get_pages_stolen,\n\t.put_pages = i915_gem_object_put_pages_stolen,\n\t.release = i915_gem_object_release_stolen,\n};\n\nstatic int __i915_gem_object_create_stolen(struct intel_memory_region *mem,\n\t\t\t\t\t   struct drm_i915_gem_object *obj,\n\t\t\t\t\t   struct drm_mm_node *stolen)\n{\n\tstatic struct lock_class_key lock_class;\n\tunsigned int cache_level;\n\tunsigned int flags;\n\tint err;\n\n\t \n\tflags = I915_BO_ALLOC_CONTIGUOUS;\n\n\tdrm_gem_private_object_init(&mem->i915->drm, &obj->base, stolen->size);\n\ti915_gem_object_init(obj, &i915_gem_object_stolen_ops, &lock_class, flags);\n\n\tobj->stolen = stolen;\n\tobj->read_domains = I915_GEM_DOMAIN_CPU | I915_GEM_DOMAIN_GTT;\n\tcache_level = HAS_LLC(mem->i915) ? I915_CACHE_LLC : I915_CACHE_NONE;\n\ti915_gem_object_set_cache_coherency(obj, cache_level);\n\n\tif (WARN_ON(!i915_gem_object_trylock(obj, NULL)))\n\t\treturn -EBUSY;\n\n\ti915_gem_object_init_memory_region(obj, mem);\n\n\terr = i915_gem_object_pin_pages(obj);\n\tif (err)\n\t\ti915_gem_object_release_memory_region(obj);\n\ti915_gem_object_unlock(obj);\n\n\treturn err;\n}\n\nstatic int _i915_gem_object_stolen_init(struct intel_memory_region *mem,\n\t\t\t\t\tstruct drm_i915_gem_object *obj,\n\t\t\t\t\tresource_size_t offset,\n\t\t\t\t\tresource_size_t size,\n\t\t\t\t\tresource_size_t page_size,\n\t\t\t\t\tunsigned int flags)\n{\n\tstruct drm_i915_private *i915 = mem->i915;\n\tstruct drm_mm_node *stolen;\n\tint ret;\n\n\tif (!drm_mm_initialized(&i915->mm.stolen))\n\t\treturn -ENODEV;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\n\t \n\tif (mem->type == INTEL_MEMORY_STOLEN_LOCAL && !mem->io_size &&\n\t    !(flags & I915_BO_ALLOC_GPU_ONLY))\n\t\treturn -ENOSPC;\n\n\tstolen = kzalloc(sizeof(*stolen), GFP_KERNEL);\n\tif (!stolen)\n\t\treturn -ENOMEM;\n\n\tif (offset != I915_BO_INVALID_OFFSET) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"creating preallocated stolen object: stolen_offset=%pa, size=%pa\\n\",\n\t\t\t&offset, &size);\n\n\t\tstolen->start = offset;\n\t\tstolen->size = size;\n\t\tmutex_lock(&i915->mm.stolen_lock);\n\t\tret = drm_mm_reserve_node(&i915->mm.stolen, stolen);\n\t\tmutex_unlock(&i915->mm.stolen_lock);\n\t} else {\n\t\tret = i915_gem_stolen_insert_node(i915, stolen, size,\n\t\t\t\t\t\t  mem->min_page_size);\n\t}\n\tif (ret)\n\t\tgoto err_free;\n\n\tret = __i915_gem_object_create_stolen(mem, obj, stolen);\n\tif (ret)\n\t\tgoto err_remove;\n\n\treturn 0;\n\nerr_remove:\n\ti915_gem_stolen_remove_node(i915, stolen);\nerr_free:\n\tkfree(stolen);\n\treturn ret;\n}\n\nstruct drm_i915_gem_object *\ni915_gem_object_create_stolen(struct drm_i915_private *i915,\n\t\t\t      resource_size_t size)\n{\n\treturn i915_gem_object_create_region(i915->mm.stolen_region, size, 0, 0);\n}\n\nstatic int init_stolen_smem(struct intel_memory_region *mem)\n{\n\tint err;\n\n\t \n\terr = i915_gem_init_stolen(mem);\n\tif (err)\n\t\tdrm_dbg(&mem->i915->drm, \"Skip stolen region: failed to setup\\n\");\n\n\treturn 0;\n}\n\nstatic int release_stolen_smem(struct intel_memory_region *mem)\n{\n\ti915_gem_cleanup_stolen(mem->i915);\n\treturn 0;\n}\n\nstatic const struct intel_memory_region_ops i915_region_stolen_smem_ops = {\n\t.init = init_stolen_smem,\n\t.release = release_stolen_smem,\n\t.init_object = _i915_gem_object_stolen_init,\n};\n\nstatic int init_stolen_lmem(struct intel_memory_region *mem)\n{\n\tstruct drm_i915_private *i915 = mem->i915;\n\tint err;\n\n\tif (GEM_WARN_ON(resource_size(&mem->region) == 0))\n\t\treturn 0;\n\n\terr = i915_gem_init_stolen(mem);\n\tif (err) {\n\t\tdrm_dbg(&mem->i915->drm, \"Skip stolen region: failed to setup\\n\");\n\t\treturn 0;\n\t}\n\n\tif (mem->io_size &&\n\t    !io_mapping_init_wc(&mem->iomap, mem->io_start, mem->io_size))\n\t\tgoto err_cleanup;\n\n\tdrm_dbg(&i915->drm, \"Stolen Local memory IO start: %pa\\n\",\n\t\t&mem->io_start);\n\tdrm_dbg(&i915->drm, \"Stolen Local DSM base: %pa\\n\", &mem->region.start);\n\n\treturn 0;\n\nerr_cleanup:\n\ti915_gem_cleanup_stolen(mem->i915);\n\treturn err;\n}\n\nstatic int release_stolen_lmem(struct intel_memory_region *mem)\n{\n\tif (mem->io_size)\n\t\tio_mapping_fini(&mem->iomap);\n\ti915_gem_cleanup_stolen(mem->i915);\n\treturn 0;\n}\n\nstatic const struct intel_memory_region_ops i915_region_stolen_lmem_ops = {\n\t.init = init_stolen_lmem,\n\t.release = release_stolen_lmem,\n\t.init_object = _i915_gem_object_stolen_init,\n};\n\nstatic int mtl_get_gms_size(struct intel_uncore *uncore)\n{\n\tu16 ggc, gms;\n\n\tggc = intel_uncore_read16(uncore, GGC);\n\n\t \n\tif ((ggc & GGMS_MASK) != GGMS_MASK)\n\t\treturn -EIO;\n\n\t \n\tgms = REG_FIELD_GET(GMS_MASK, ggc);\n\tswitch (gms) {\n\tcase 0x0 ... 0x04:\n\t\treturn gms * 32;\n\tcase 0xf0 ... 0xfe:\n\t\treturn (gms - 0xf0 + 1) * 4;\n\tdefault:\n\t\tMISSING_CASE(gms);\n\t\treturn -EIO;\n\t}\n}\n\nstruct intel_memory_region *\ni915_gem_stolen_lmem_setup(struct drm_i915_private *i915, u16 type,\n\t\t\t   u16 instance)\n{\n\tstruct intel_uncore *uncore = &i915->uncore;\n\tstruct pci_dev *pdev = to_pci_dev(i915->drm.dev);\n\tresource_size_t dsm_size, dsm_base, lmem_size;\n\tstruct intel_memory_region *mem;\n\tresource_size_t io_start, io_size;\n\tresource_size_t min_page_size;\n\tint ret;\n\n\tif (WARN_ON_ONCE(instance))\n\t\treturn ERR_PTR(-ENODEV);\n\n\tif (!i915_pci_resource_valid(pdev, GEN12_LMEM_BAR))\n\t\treturn ERR_PTR(-ENXIO);\n\n\tif (HAS_LMEMBAR_SMEM_STOLEN(i915) || IS_DG1(i915)) {\n\t\tlmem_size = pci_resource_len(pdev, GEN12_LMEM_BAR);\n\t} else {\n\t\tresource_size_t lmem_range;\n\n\t\tlmem_range = intel_gt_mcr_read_any(to_gt(i915), XEHP_TILE0_ADDR_RANGE) & 0xFFFF;\n\t\tlmem_size = lmem_range >> XEHP_TILE_LMEM_RANGE_SHIFT;\n\t\tlmem_size *= SZ_1G;\n\t}\n\n\tif (HAS_LMEMBAR_SMEM_STOLEN(i915)) {\n\t\t \n\t\tret = mtl_get_gms_size(uncore);\n\t\tif (ret < 0) {\n\t\t\tdrm_err(&i915->drm, \"invalid MTL GGC register setting\\n\");\n\t\t\treturn ERR_PTR(ret);\n\t\t}\n\n\t\tdsm_base = SZ_8M;\n\t\tdsm_size = (resource_size_t)(ret * SZ_1M);\n\n\t\tGEM_BUG_ON(pci_resource_len(pdev, GEN12_LMEM_BAR) != SZ_256M);\n\t\tGEM_BUG_ON((dsm_base + dsm_size) > lmem_size);\n\t} else {\n\t\t \n\t\tdsm_base = intel_uncore_read64(uncore, GEN12_DSMBASE) & GEN12_BDSM_MASK;\n\t\tif (WARN_ON(lmem_size < dsm_base))\n\t\t\treturn ERR_PTR(-ENODEV);\n\t\tdsm_size = ALIGN_DOWN(lmem_size - dsm_base, SZ_1M);\n\t}\n\n\tif (pci_resource_len(pdev, GEN12_LMEM_BAR) < lmem_size) {\n\t\tio_start = 0;\n\t\tio_size = 0;\n\t} else {\n\t\tio_start = pci_resource_start(pdev, GEN12_LMEM_BAR) + dsm_base;\n\t\tio_size = dsm_size;\n\t}\n\n\tmin_page_size = HAS_64K_PAGES(i915) ? I915_GTT_PAGE_SIZE_64K :\n\t\t\t\t\t\tI915_GTT_PAGE_SIZE_4K;\n\n\tmem = intel_memory_region_create(i915, dsm_base, dsm_size,\n\t\t\t\t\t min_page_size,\n\t\t\t\t\t io_start, io_size,\n\t\t\t\t\t type, instance,\n\t\t\t\t\t &i915_region_stolen_lmem_ops);\n\tif (IS_ERR(mem))\n\t\treturn mem;\n\n\tintel_memory_region_set_name(mem, \"stolen-local\");\n\n\tmem->private = true;\n\n\treturn mem;\n}\n\nstruct intel_memory_region*\ni915_gem_stolen_smem_setup(struct drm_i915_private *i915, u16 type,\n\t\t\t   u16 instance)\n{\n\tstruct intel_memory_region *mem;\n\n\tmem = intel_memory_region_create(i915,\n\t\t\t\t\t intel_graphics_stolen_res.start,\n\t\t\t\t\t resource_size(&intel_graphics_stolen_res),\n\t\t\t\t\t PAGE_SIZE, 0, 0, type, instance,\n\t\t\t\t\t &i915_region_stolen_smem_ops);\n\tif (IS_ERR(mem))\n\t\treturn mem;\n\n\tintel_memory_region_set_name(mem, \"stolen-system\");\n\n\tmem->private = true;\n\n\treturn mem;\n}\n\nbool i915_gem_object_is_stolen(const struct drm_i915_gem_object *obj)\n{\n\treturn obj->ops == &i915_gem_object_stolen_ops;\n}\n\nbool i915_gem_stolen_initialized(const struct drm_i915_private *i915)\n{\n\treturn drm_mm_initialized(&i915->mm.stolen);\n}\n\nu64 i915_gem_stolen_area_address(const struct drm_i915_private *i915)\n{\n\treturn i915->dsm.stolen.start;\n}\n\nu64 i915_gem_stolen_area_size(const struct drm_i915_private *i915)\n{\n\treturn resource_size(&i915->dsm.stolen);\n}\n\nu64 i915_gem_stolen_node_address(const struct drm_i915_private *i915,\n\t\t\t\t const struct drm_mm_node *node)\n{\n\treturn i915->dsm.stolen.start + i915_gem_stolen_node_offset(node);\n}\n\nbool i915_gem_stolen_node_allocated(const struct drm_mm_node *node)\n{\n\treturn drm_mm_node_allocated(node);\n}\n\nu64 i915_gem_stolen_node_offset(const struct drm_mm_node *node)\n{\n\treturn node->start;\n}\n\nu64 i915_gem_stolen_node_size(const struct drm_mm_node *node)\n{\n\treturn node->size;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}