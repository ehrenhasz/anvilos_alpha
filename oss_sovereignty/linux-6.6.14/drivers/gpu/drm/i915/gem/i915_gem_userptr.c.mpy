{
  "module_name": "i915_gem_userptr.c",
  "hash_id": "0ad61f74bf6dd3439d697498ded9bc7835186fc6cb93dfe28eb9bd537ade7491",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gem/i915_gem_userptr.c",
  "human_readable_source": " \n \n\n#include <linux/mmu_context.h>\n#include <linux/mempolicy.h>\n#include <linux/swap.h>\n#include <linux/sched/mm.h>\n\n#include \"i915_drv.h\"\n#include \"i915_gem_ioctls.h\"\n#include \"i915_gem_object.h\"\n#include \"i915_gem_userptr.h\"\n#include \"i915_scatterlist.h\"\n\n#ifdef CONFIG_MMU_NOTIFIER\n\n \nstatic bool i915_gem_userptr_invalidate(struct mmu_interval_notifier *mni,\n\t\t\t\t\tconst struct mmu_notifier_range *range,\n\t\t\t\t\tunsigned long cur_seq)\n{\n\tstruct drm_i915_gem_object *obj = container_of(mni, struct drm_i915_gem_object, userptr.notifier);\n\tstruct drm_i915_private *i915 = to_i915(obj->base.dev);\n\tlong r;\n\n\tif (!mmu_notifier_range_blockable(range))\n\t\treturn false;\n\n\twrite_lock(&i915->mm.notifier_lock);\n\n\tmmu_interval_set_seq(mni, cur_seq);\n\n\twrite_unlock(&i915->mm.notifier_lock);\n\n\t \n\tif (current->flags & PF_EXITING)\n\t\treturn true;\n\n\t \n\tr = dma_resv_wait_timeout(obj->base.resv, DMA_RESV_USAGE_BOOKKEEP, false,\n\t\t\t\t  MAX_SCHEDULE_TIMEOUT);\n\tif (r <= 0)\n\t\tdrm_err(&i915->drm, \"(%ld) failed to wait for idle\\n\", r);\n\n\treturn true;\n}\n\nstatic const struct mmu_interval_notifier_ops i915_gem_userptr_notifier_ops = {\n\t.invalidate = i915_gem_userptr_invalidate,\n};\n\nstatic int\ni915_gem_userptr_init__mmu_notifier(struct drm_i915_gem_object *obj)\n{\n\treturn mmu_interval_notifier_insert(&obj->userptr.notifier, current->mm,\n\t\t\t\t\t    obj->userptr.ptr, obj->base.size,\n\t\t\t\t\t    &i915_gem_userptr_notifier_ops);\n}\n\nstatic void i915_gem_object_userptr_drop_ref(struct drm_i915_gem_object *obj)\n{\n\tstruct page **pvec = NULL;\n\n\tassert_object_held_shared(obj);\n\n\tif (!--obj->userptr.page_ref) {\n\t\tpvec = obj->userptr.pvec;\n\t\tobj->userptr.pvec = NULL;\n\t}\n\tGEM_BUG_ON(obj->userptr.page_ref < 0);\n\n\tif (pvec) {\n\t\tconst unsigned long num_pages = obj->base.size >> PAGE_SHIFT;\n\n\t\tunpin_user_pages(pvec, num_pages);\n\t\tkvfree(pvec);\n\t}\n}\n\nstatic int i915_gem_userptr_get_pages(struct drm_i915_gem_object *obj)\n{\n\tunsigned int max_segment = i915_sg_segment_size(obj->base.dev->dev);\n\tstruct sg_table *st;\n\tstruct page **pvec;\n\tunsigned int num_pages;  \n\tint ret;\n\n\tif (overflows_type(obj->base.size >> PAGE_SHIFT, num_pages))\n\t\treturn -E2BIG;\n\n\tnum_pages = obj->base.size >> PAGE_SHIFT;\n\tst = kmalloc(sizeof(*st), GFP_KERNEL);\n\tif (!st)\n\t\treturn -ENOMEM;\n\n\tif (!obj->userptr.page_ref) {\n\t\tret = -EAGAIN;\n\t\tgoto err_free;\n\t}\n\n\tobj->userptr.page_ref++;\n\tpvec = obj->userptr.pvec;\n\nalloc_table:\n\tret = sg_alloc_table_from_pages_segment(st, pvec, num_pages, 0,\n\t\t\t\t\t\tnum_pages << PAGE_SHIFT,\n\t\t\t\t\t\tmax_segment, GFP_KERNEL);\n\tif (ret)\n\t\tgoto err;\n\n\tret = i915_gem_gtt_prepare_pages(obj, st);\n\tif (ret) {\n\t\tsg_free_table(st);\n\n\t\tif (max_segment > PAGE_SIZE) {\n\t\t\tmax_segment = PAGE_SIZE;\n\t\t\tgoto alloc_table;\n\t\t}\n\n\t\tgoto err;\n\t}\n\n\tWARN_ON_ONCE(!(obj->cache_coherent & I915_BO_CACHE_COHERENT_FOR_WRITE));\n\tif (i915_gem_object_can_bypass_llc(obj))\n\t\tobj->cache_dirty = true;\n\n\t__i915_gem_object_set_pages(obj, st);\n\n\treturn 0;\n\nerr:\n\ti915_gem_object_userptr_drop_ref(obj);\nerr_free:\n\tkfree(st);\n\treturn ret;\n}\n\nstatic void\ni915_gem_userptr_put_pages(struct drm_i915_gem_object *obj,\n\t\t\t   struct sg_table *pages)\n{\n\tstruct sgt_iter sgt_iter;\n\tstruct page *page;\n\n\tif (!pages)\n\t\treturn;\n\n\t__i915_gem_object_release_shmem(obj, pages, true);\n\ti915_gem_gtt_finish_pages(obj, pages);\n\n\t \n\tif (i915_gem_object_is_readonly(obj))\n\t\tobj->mm.dirty = false;\n\n\tfor_each_sgt_page(page, sgt_iter, pages) {\n\t\tif (obj->mm.dirty && trylock_page(page)) {\n\t\t\t \n\t\t\tset_page_dirty(page);\n\t\t\tunlock_page(page);\n\t\t}\n\n\t\tmark_page_accessed(page);\n\t}\n\tobj->mm.dirty = false;\n\n\tsg_free_table(pages);\n\tkfree(pages);\n\n\ti915_gem_object_userptr_drop_ref(obj);\n}\n\nstatic int i915_gem_object_userptr_unbind(struct drm_i915_gem_object *obj)\n{\n\tstruct sg_table *pages;\n\tint err;\n\n\terr = i915_gem_object_unbind(obj, I915_GEM_OBJECT_UNBIND_ACTIVE);\n\tif (err)\n\t\treturn err;\n\n\tif (GEM_WARN_ON(i915_gem_object_has_pinned_pages(obj)))\n\t\treturn -EBUSY;\n\n\tassert_object_held(obj);\n\n\tpages = __i915_gem_object_unset_pages(obj);\n\tif (!IS_ERR_OR_NULL(pages))\n\t\ti915_gem_userptr_put_pages(obj, pages);\n\n\treturn err;\n}\n\nint i915_gem_object_userptr_submit_init(struct drm_i915_gem_object *obj)\n{\n\tconst unsigned long num_pages = obj->base.size >> PAGE_SHIFT;\n\tstruct page **pvec;\n\tunsigned int gup_flags = 0;\n\tunsigned long notifier_seq;\n\tint pinned, ret;\n\n\tif (obj->userptr.notifier.mm != current->mm)\n\t\treturn -EFAULT;\n\n\tnotifier_seq = mmu_interval_read_begin(&obj->userptr.notifier);\n\n\tret = i915_gem_object_lock_interruptible(obj, NULL);\n\tif (ret)\n\t\treturn ret;\n\n\tif (notifier_seq == obj->userptr.notifier_seq && obj->userptr.pvec) {\n\t\ti915_gem_object_unlock(obj);\n\t\treturn 0;\n\t}\n\n\tret = i915_gem_object_userptr_unbind(obj);\n\ti915_gem_object_unlock(obj);\n\tif (ret)\n\t\treturn ret;\n\n\tpvec = kvmalloc_array(num_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pvec)\n\t\treturn -ENOMEM;\n\n\tif (!i915_gem_object_is_readonly(obj))\n\t\tgup_flags |= FOLL_WRITE;\n\n\tpinned = 0;\n\twhile (pinned < num_pages) {\n\t\tret = pin_user_pages_fast(obj->userptr.ptr + pinned * PAGE_SIZE,\n\t\t\t\t\t  num_pages - pinned, gup_flags,\n\t\t\t\t\t  &pvec[pinned]);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tpinned += ret;\n\t}\n\n\tret = i915_gem_object_lock_interruptible(obj, NULL);\n\tif (ret)\n\t\tgoto out;\n\n\tif (mmu_interval_read_retry(&obj->userptr.notifier,\n\t\t!obj->userptr.page_ref ? notifier_seq :\n\t\tobj->userptr.notifier_seq)) {\n\t\tret = -EAGAIN;\n\t\tgoto out_unlock;\n\t}\n\n\tif (!obj->userptr.page_ref++) {\n\t\tobj->userptr.pvec = pvec;\n\t\tobj->userptr.notifier_seq = notifier_seq;\n\t\tpvec = NULL;\n\t\tret = ____i915_gem_object_get_pages(obj);\n\t}\n\n\tobj->userptr.page_ref--;\n\nout_unlock:\n\ti915_gem_object_unlock(obj);\n\nout:\n\tif (pvec) {\n\t\tunpin_user_pages(pvec, pinned);\n\t\tkvfree(pvec);\n\t}\n\n\treturn ret;\n}\n\nint i915_gem_object_userptr_submit_done(struct drm_i915_gem_object *obj)\n{\n\tif (mmu_interval_read_retry(&obj->userptr.notifier,\n\t\t\t\t    obj->userptr.notifier_seq)) {\n\t\t \n\n\t\treturn -EAGAIN;\n\t}\n\n\treturn 0;\n}\n\nint i915_gem_object_userptr_validate(struct drm_i915_gem_object *obj)\n{\n\tint err;\n\n\terr = i915_gem_object_userptr_submit_init(obj);\n\tif (err)\n\t\treturn err;\n\n\terr = i915_gem_object_lock_interruptible(obj, NULL);\n\tif (!err) {\n\t\t \n\t\terr = i915_gem_object_pin_pages(obj);\n\t\tif (!err)\n\t\t\ti915_gem_object_unpin_pages(obj);\n\n\t\ti915_gem_object_unlock(obj);\n\t}\n\n\treturn err;\n}\n\nstatic void\ni915_gem_userptr_release(struct drm_i915_gem_object *obj)\n{\n\tGEM_WARN_ON(obj->userptr.page_ref);\n\n\tmmu_interval_notifier_remove(&obj->userptr.notifier);\n\tobj->userptr.notifier.mm = NULL;\n}\n\nstatic int\ni915_gem_userptr_dmabuf_export(struct drm_i915_gem_object *obj)\n{\n\tdrm_dbg(obj->base.dev, \"Exporting userptr no longer allowed\\n\");\n\n\treturn -EINVAL;\n}\n\nstatic int\ni915_gem_userptr_pwrite(struct drm_i915_gem_object *obj,\n\t\t\tconst struct drm_i915_gem_pwrite *args)\n{\n\tdrm_dbg(obj->base.dev, \"pwrite to userptr no longer allowed\\n\");\n\n\treturn -EINVAL;\n}\n\nstatic int\ni915_gem_userptr_pread(struct drm_i915_gem_object *obj,\n\t\t       const struct drm_i915_gem_pread *args)\n{\n\tdrm_dbg(obj->base.dev, \"pread from userptr no longer allowed\\n\");\n\n\treturn -EINVAL;\n}\n\nstatic const struct drm_i915_gem_object_ops i915_gem_userptr_ops = {\n\t.name = \"i915_gem_object_userptr\",\n\t.flags = I915_GEM_OBJECT_IS_SHRINKABLE |\n\t\t I915_GEM_OBJECT_NO_MMAP |\n\t\t I915_GEM_OBJECT_IS_PROXY,\n\t.get_pages = i915_gem_userptr_get_pages,\n\t.put_pages = i915_gem_userptr_put_pages,\n\t.dmabuf_export = i915_gem_userptr_dmabuf_export,\n\t.pwrite = i915_gem_userptr_pwrite,\n\t.pread = i915_gem_userptr_pread,\n\t.release = i915_gem_userptr_release,\n};\n\n#endif\n\nstatic int\nprobe_range(struct mm_struct *mm, unsigned long addr, unsigned long len)\n{\n\tVMA_ITERATOR(vmi, mm, addr);\n\tstruct vm_area_struct *vma;\n\tunsigned long end = addr + len;\n\n\tmmap_read_lock(mm);\n\tfor_each_vma_range(vmi, vma, end) {\n\t\t \n\t\tif (vma->vm_start > addr)\n\t\t\tbreak;\n\n\t\tif (vma->vm_flags & (VM_PFNMAP | VM_MIXEDMAP))\n\t\t\tbreak;\n\n\t\taddr = vma->vm_end;\n\t}\n\tmmap_read_unlock(mm);\n\n\tif (vma || addr < end)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\n \nint\ni915_gem_userptr_ioctl(struct drm_device *dev,\n\t\t       void *data,\n\t\t       struct drm_file *file)\n{\n\tstatic struct lock_class_key __maybe_unused lock_class;\n\tstruct drm_i915_private *dev_priv = to_i915(dev);\n\tstruct drm_i915_gem_userptr *args = data;\n\tstruct drm_i915_gem_object __maybe_unused *obj;\n\tint __maybe_unused ret;\n\tu32 __maybe_unused handle;\n\n\tif (!HAS_LLC(dev_priv) && !HAS_SNOOP(dev_priv)) {\n\t\t \n\t\treturn -ENODEV;\n\t}\n\n\tif (args->flags & ~(I915_USERPTR_READ_ONLY |\n\t\t\t    I915_USERPTR_UNSYNCHRONIZED |\n\t\t\t    I915_USERPTR_PROBE))\n\t\treturn -EINVAL;\n\n\tif (i915_gem_object_size_2big(args->user_size))\n\t\treturn -E2BIG;\n\n\tif (!args->user_size)\n\t\treturn -EINVAL;\n\n\tif (offset_in_page(args->user_ptr | args->user_size))\n\t\treturn -EINVAL;\n\n\tif (!access_ok((char __user *)(unsigned long)args->user_ptr, args->user_size))\n\t\treturn -EFAULT;\n\n\tif (args->flags & I915_USERPTR_UNSYNCHRONIZED)\n\t\treturn -ENODEV;\n\n\tif (args->flags & I915_USERPTR_READ_ONLY) {\n\t\t \n\t\tif (!to_gt(dev_priv)->vm->has_read_only)\n\t\t\treturn -ENODEV;\n\t}\n\n\tif (args->flags & I915_USERPTR_PROBE) {\n\t\t \n\t\tret = probe_range(current->mm, args->user_ptr, args->user_size);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n#ifdef CONFIG_MMU_NOTIFIER\n\tobj = i915_gem_object_alloc();\n\tif (obj == NULL)\n\t\treturn -ENOMEM;\n\n\tdrm_gem_private_object_init(dev, &obj->base, args->user_size);\n\ti915_gem_object_init(obj, &i915_gem_userptr_ops, &lock_class,\n\t\t\t     I915_BO_ALLOC_USER);\n\tobj->mem_flags = I915_BO_FLAG_STRUCT_PAGE;\n\tobj->read_domains = I915_GEM_DOMAIN_CPU;\n\tobj->write_domain = I915_GEM_DOMAIN_CPU;\n\ti915_gem_object_set_cache_coherency(obj, I915_CACHE_LLC);\n\n\tobj->userptr.ptr = args->user_ptr;\n\tobj->userptr.notifier_seq = ULONG_MAX;\n\tif (args->flags & I915_USERPTR_READ_ONLY)\n\t\ti915_gem_object_set_readonly(obj);\n\n\t \n\tret = i915_gem_userptr_init__mmu_notifier(obj);\n\tif (ret == 0)\n\t\tret = drm_gem_handle_create(file, &obj->base, &handle);\n\n\t \n\ti915_gem_object_put(obj);\n\tif (ret)\n\t\treturn ret;\n\n\targs->handle = handle;\n\treturn 0;\n#else\n\treturn -ENODEV;\n#endif\n}\n\nint i915_gem_init_userptr(struct drm_i915_private *dev_priv)\n{\n#ifdef CONFIG_MMU_NOTIFIER\n\trwlock_init(&dev_priv->mm.notifier_lock);\n#endif\n\n\treturn 0;\n}\n\nvoid i915_gem_cleanup_userptr(struct drm_i915_private *dev_priv)\n{\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}