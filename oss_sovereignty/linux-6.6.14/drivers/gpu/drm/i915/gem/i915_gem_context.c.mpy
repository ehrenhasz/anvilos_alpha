{
  "module_name": "i915_gem_context.c",
  "hash_id": "b8a40b7d72696d79bc54b3291655be0a626756d7dfee449ba166a30e64e05bed",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gem/i915_gem_context.c",
  "human_readable_source": " \n\n \n\n#include <linux/highmem.h>\n#include <linux/log2.h>\n#include <linux/nospec.h>\n\n#include <drm/drm_cache.h>\n#include <drm/drm_syncobj.h>\n\n#include \"gt/gen6_ppgtt.h\"\n#include \"gt/intel_context.h\"\n#include \"gt/intel_context_param.h\"\n#include \"gt/intel_engine_heartbeat.h\"\n#include \"gt/intel_engine_user.h\"\n#include \"gt/intel_gpu_commands.h\"\n#include \"gt/intel_ring.h\"\n\n#include \"pxp/intel_pxp.h\"\n\n#include \"i915_file_private.h\"\n#include \"i915_gem_context.h\"\n#include \"i915_trace.h\"\n#include \"i915_user_extensions.h\"\n\n#define ALL_L3_SLICES(dev) (1 << NUM_L3_SLICES(dev)) - 1\n\nstatic struct kmem_cache *slab_luts;\n\nstruct i915_lut_handle *i915_lut_handle_alloc(void)\n{\n\treturn kmem_cache_alloc(slab_luts, GFP_KERNEL);\n}\n\nvoid i915_lut_handle_free(struct i915_lut_handle *lut)\n{\n\treturn kmem_cache_free(slab_luts, lut);\n}\n\nstatic void lut_close(struct i915_gem_context *ctx)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\n\tmutex_lock(&ctx->lut_mutex);\n\trcu_read_lock();\n\tradix_tree_for_each_slot(slot, &ctx->handles_vma, &iter, 0) {\n\t\tstruct i915_vma *vma = rcu_dereference_raw(*slot);\n\t\tstruct drm_i915_gem_object *obj = vma->obj;\n\t\tstruct i915_lut_handle *lut;\n\n\t\tif (!kref_get_unless_zero(&obj->base.refcount))\n\t\t\tcontinue;\n\n\t\tspin_lock(&obj->lut_lock);\n\t\tlist_for_each_entry(lut, &obj->lut_list, obj_link) {\n\t\t\tif (lut->ctx != ctx)\n\t\t\t\tcontinue;\n\n\t\t\tif (lut->handle != iter.index)\n\t\t\t\tcontinue;\n\n\t\t\tlist_del(&lut->obj_link);\n\t\t\tbreak;\n\t\t}\n\t\tspin_unlock(&obj->lut_lock);\n\n\t\tif (&lut->obj_link != &obj->lut_list) {\n\t\t\ti915_lut_handle_free(lut);\n\t\t\tradix_tree_iter_delete(&ctx->handles_vma, &iter, slot);\n\t\t\ti915_vma_close(vma);\n\t\t\ti915_gem_object_put(obj);\n\t\t}\n\n\t\ti915_gem_object_put(obj);\n\t}\n\trcu_read_unlock();\n\tmutex_unlock(&ctx->lut_mutex);\n}\n\nstatic struct intel_context *\nlookup_user_engine(struct i915_gem_context *ctx,\n\t\t   unsigned long flags,\n\t\t   const struct i915_engine_class_instance *ci)\n#define LOOKUP_USER_INDEX BIT(0)\n{\n\tint idx;\n\n\tif (!!(flags & LOOKUP_USER_INDEX) != i915_gem_context_user_engines(ctx))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (!i915_gem_context_user_engines(ctx)) {\n\t\tstruct intel_engine_cs *engine;\n\n\t\tengine = intel_engine_lookup_user(ctx->i915,\n\t\t\t\t\t\t  ci->engine_class,\n\t\t\t\t\t\t  ci->engine_instance);\n\t\tif (!engine)\n\t\t\treturn ERR_PTR(-EINVAL);\n\n\t\tidx = engine->legacy_idx;\n\t} else {\n\t\tidx = ci->engine_instance;\n\t}\n\n\treturn i915_gem_context_get_engine(ctx, idx);\n}\n\nstatic int validate_priority(struct drm_i915_private *i915,\n\t\t\t     const struct drm_i915_gem_context_param *args)\n{\n\ts64 priority = args->value;\n\n\tif (args->size)\n\t\treturn -EINVAL;\n\n\tif (!(i915->caps.scheduler & I915_SCHEDULER_CAP_PRIORITY))\n\t\treturn -ENODEV;\n\n\tif (priority > I915_CONTEXT_MAX_USER_PRIORITY ||\n\t    priority < I915_CONTEXT_MIN_USER_PRIORITY)\n\t\treturn -EINVAL;\n\n\tif (priority > I915_CONTEXT_DEFAULT_PRIORITY &&\n\t    !capable(CAP_SYS_NICE))\n\t\treturn -EPERM;\n\n\treturn 0;\n}\n\nstatic void proto_context_close(struct drm_i915_private *i915,\n\t\t\t\tstruct i915_gem_proto_context *pc)\n{\n\tint i;\n\n\tif (pc->pxp_wakeref)\n\t\tintel_runtime_pm_put(&i915->runtime_pm, pc->pxp_wakeref);\n\tif (pc->vm)\n\t\ti915_vm_put(pc->vm);\n\tif (pc->user_engines) {\n\t\tfor (i = 0; i < pc->num_user_engines; i++)\n\t\t\tkfree(pc->user_engines[i].siblings);\n\t\tkfree(pc->user_engines);\n\t}\n\tkfree(pc);\n}\n\nstatic int proto_context_set_persistence(struct drm_i915_private *i915,\n\t\t\t\t\t struct i915_gem_proto_context *pc,\n\t\t\t\t\t bool persist)\n{\n\tif (persist) {\n\t\t \n\t\tif (!i915->params.enable_hangcheck)\n\t\t\treturn -EINVAL;\n\n\t\tpc->user_flags |= BIT(UCONTEXT_PERSISTENCE);\n\t} else {\n\t\t \n\t\tif (!(i915->caps.scheduler & I915_SCHEDULER_CAP_PREEMPTION))\n\t\t\treturn -ENODEV;\n\n\t\t \n\t\tif (!intel_has_reset_engine(to_gt(i915)))\n\t\t\treturn -ENODEV;\n\n\t\tpc->user_flags &= ~BIT(UCONTEXT_PERSISTENCE);\n\t}\n\n\treturn 0;\n}\n\nstatic int proto_context_set_protected(struct drm_i915_private *i915,\n\t\t\t\t       struct i915_gem_proto_context *pc,\n\t\t\t\t       bool protected)\n{\n\tint ret = 0;\n\n\tif (!protected) {\n\t\tpc->uses_protected_content = false;\n\t} else if (!intel_pxp_is_enabled(i915->pxp)) {\n\t\tret = -ENODEV;\n\t} else if ((pc->user_flags & BIT(UCONTEXT_RECOVERABLE)) ||\n\t\t   !(pc->user_flags & BIT(UCONTEXT_BANNABLE))) {\n\t\tret = -EPERM;\n\t} else {\n\t\tpc->uses_protected_content = true;\n\n\t\t \n\t\tpc->pxp_wakeref = intel_runtime_pm_get(&i915->runtime_pm);\n\n\t\tif (!intel_pxp_is_active(i915->pxp))\n\t\t\tret = intel_pxp_start(i915->pxp);\n\t}\n\n\treturn ret;\n}\n\nstatic struct i915_gem_proto_context *\nproto_context_create(struct drm_i915_private *i915, unsigned int flags)\n{\n\tstruct i915_gem_proto_context *pc, *err;\n\n\tpc = kzalloc(sizeof(*pc), GFP_KERNEL);\n\tif (!pc)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpc->num_user_engines = -1;\n\tpc->user_engines = NULL;\n\tpc->user_flags = BIT(UCONTEXT_BANNABLE) |\n\t\t\t BIT(UCONTEXT_RECOVERABLE);\n\tif (i915->params.enable_hangcheck)\n\t\tpc->user_flags |= BIT(UCONTEXT_PERSISTENCE);\n\tpc->sched.priority = I915_PRIORITY_NORMAL;\n\n\tif (flags & I915_CONTEXT_CREATE_FLAGS_SINGLE_TIMELINE) {\n\t\tif (!HAS_EXECLISTS(i915)) {\n\t\t\terr = ERR_PTR(-EINVAL);\n\t\t\tgoto proto_close;\n\t\t}\n\t\tpc->single_timeline = true;\n\t}\n\n\treturn pc;\n\nproto_close:\n\tproto_context_close(i915, pc);\n\treturn err;\n}\n\nstatic int proto_context_register_locked(struct drm_i915_file_private *fpriv,\n\t\t\t\t\t struct i915_gem_proto_context *pc,\n\t\t\t\t\t u32 *id)\n{\n\tint ret;\n\tvoid *old;\n\n\tlockdep_assert_held(&fpriv->proto_context_lock);\n\n\tret = xa_alloc(&fpriv->context_xa, id, NULL, xa_limit_32b, GFP_KERNEL);\n\tif (ret)\n\t\treturn ret;\n\n\told = xa_store(&fpriv->proto_context_xa, *id, pc, GFP_KERNEL);\n\tif (xa_is_err(old)) {\n\t\txa_erase(&fpriv->context_xa, *id);\n\t\treturn xa_err(old);\n\t}\n\tWARN_ON(old);\n\n\treturn 0;\n}\n\nstatic int proto_context_register(struct drm_i915_file_private *fpriv,\n\t\t\t\t  struct i915_gem_proto_context *pc,\n\t\t\t\t  u32 *id)\n{\n\tint ret;\n\n\tmutex_lock(&fpriv->proto_context_lock);\n\tret = proto_context_register_locked(fpriv, pc, id);\n\tmutex_unlock(&fpriv->proto_context_lock);\n\n\treturn ret;\n}\n\nstatic struct i915_address_space *\ni915_gem_vm_lookup(struct drm_i915_file_private *file_priv, u32 id)\n{\n\tstruct i915_address_space *vm;\n\n\txa_lock(&file_priv->vm_xa);\n\tvm = xa_load(&file_priv->vm_xa, id);\n\tif (vm)\n\t\tkref_get(&vm->ref);\n\txa_unlock(&file_priv->vm_xa);\n\n\treturn vm;\n}\n\nstatic int set_proto_ctx_vm(struct drm_i915_file_private *fpriv,\n\t\t\t    struct i915_gem_proto_context *pc,\n\t\t\t    const struct drm_i915_gem_context_param *args)\n{\n\tstruct drm_i915_private *i915 = fpriv->i915;\n\tstruct i915_address_space *vm;\n\n\tif (args->size)\n\t\treturn -EINVAL;\n\n\tif (!HAS_FULL_PPGTT(i915))\n\t\treturn -ENODEV;\n\n\tif (upper_32_bits(args->value))\n\t\treturn -ENOENT;\n\n\tvm = i915_gem_vm_lookup(fpriv, args->value);\n\tif (!vm)\n\t\treturn -ENOENT;\n\n\tif (pc->vm)\n\t\ti915_vm_put(pc->vm);\n\tpc->vm = vm;\n\n\treturn 0;\n}\n\nstruct set_proto_ctx_engines {\n\tstruct drm_i915_private *i915;\n\tunsigned num_engines;\n\tstruct i915_gem_proto_engine *engines;\n};\n\nstatic int\nset_proto_ctx_engines_balance(struct i915_user_extension __user *base,\n\t\t\t      void *data)\n{\n\tstruct i915_context_engines_load_balance __user *ext =\n\t\tcontainer_of_user(base, typeof(*ext), base);\n\tconst struct set_proto_ctx_engines *set = data;\n\tstruct drm_i915_private *i915 = set->i915;\n\tstruct intel_engine_cs **siblings;\n\tu16 num_siblings, idx;\n\tunsigned int n;\n\tint err;\n\n\tif (!HAS_EXECLISTS(i915))\n\t\treturn -ENODEV;\n\n\tif (get_user(idx, &ext->engine_index))\n\t\treturn -EFAULT;\n\n\tif (idx >= set->num_engines) {\n\t\tdrm_dbg(&i915->drm, \"Invalid placement value, %d >= %d\\n\",\n\t\t\tidx, set->num_engines);\n\t\treturn -EINVAL;\n\t}\n\n\tidx = array_index_nospec(idx, set->num_engines);\n\tif (set->engines[idx].type != I915_GEM_ENGINE_TYPE_INVALID) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"Invalid placement[%d], already occupied\\n\", idx);\n\t\treturn -EEXIST;\n\t}\n\n\tif (get_user(num_siblings, &ext->num_siblings))\n\t\treturn -EFAULT;\n\n\terr = check_user_mbz(&ext->flags);\n\tif (err)\n\t\treturn err;\n\n\terr = check_user_mbz(&ext->mbz64);\n\tif (err)\n\t\treturn err;\n\n\tif (num_siblings == 0)\n\t\treturn 0;\n\n\tsiblings = kmalloc_array(num_siblings, sizeof(*siblings), GFP_KERNEL);\n\tif (!siblings)\n\t\treturn -ENOMEM;\n\n\tfor (n = 0; n < num_siblings; n++) {\n\t\tstruct i915_engine_class_instance ci;\n\n\t\tif (copy_from_user(&ci, &ext->engines[n], sizeof(ci))) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto err_siblings;\n\t\t}\n\n\t\tsiblings[n] = intel_engine_lookup_user(i915,\n\t\t\t\t\t\t       ci.engine_class,\n\t\t\t\t\t\t       ci.engine_instance);\n\t\tif (!siblings[n]) {\n\t\t\tdrm_dbg(&i915->drm,\n\t\t\t\t\"Invalid sibling[%d]: { class:%d, inst:%d }\\n\",\n\t\t\t\tn, ci.engine_class, ci.engine_instance);\n\t\t\terr = -EINVAL;\n\t\t\tgoto err_siblings;\n\t\t}\n\t}\n\n\tif (num_siblings == 1) {\n\t\tset->engines[idx].type = I915_GEM_ENGINE_TYPE_PHYSICAL;\n\t\tset->engines[idx].engine = siblings[0];\n\t\tkfree(siblings);\n\t} else {\n\t\tset->engines[idx].type = I915_GEM_ENGINE_TYPE_BALANCED;\n\t\tset->engines[idx].num_siblings = num_siblings;\n\t\tset->engines[idx].siblings = siblings;\n\t}\n\n\treturn 0;\n\nerr_siblings:\n\tkfree(siblings);\n\n\treturn err;\n}\n\nstatic int\nset_proto_ctx_engines_bond(struct i915_user_extension __user *base, void *data)\n{\n\tstruct i915_context_engines_bond __user *ext =\n\t\tcontainer_of_user(base, typeof(*ext), base);\n\tconst struct set_proto_ctx_engines *set = data;\n\tstruct drm_i915_private *i915 = set->i915;\n\tstruct i915_engine_class_instance ci;\n\tstruct intel_engine_cs *master;\n\tu16 idx, num_bonds;\n\tint err, n;\n\n\tif (GRAPHICS_VER(i915) >= 12 && !IS_TIGERLAKE(i915) &&\n\t    !IS_ROCKETLAKE(i915) && !IS_ALDERLAKE_S(i915)) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"Bonding not supported on this platform\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (get_user(idx, &ext->virtual_index))\n\t\treturn -EFAULT;\n\n\tif (idx >= set->num_engines) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"Invalid index for virtual engine: %d >= %d\\n\",\n\t\t\tidx, set->num_engines);\n\t\treturn -EINVAL;\n\t}\n\n\tidx = array_index_nospec(idx, set->num_engines);\n\tif (set->engines[idx].type == I915_GEM_ENGINE_TYPE_INVALID) {\n\t\tdrm_dbg(&i915->drm, \"Invalid engine at %d\\n\", idx);\n\t\treturn -EINVAL;\n\t}\n\n\tif (set->engines[idx].type != I915_GEM_ENGINE_TYPE_PHYSICAL) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"Bonding with virtual engines not allowed\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = check_user_mbz(&ext->flags);\n\tif (err)\n\t\treturn err;\n\n\tfor (n = 0; n < ARRAY_SIZE(ext->mbz64); n++) {\n\t\terr = check_user_mbz(&ext->mbz64[n]);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (copy_from_user(&ci, &ext->master, sizeof(ci)))\n\t\treturn -EFAULT;\n\n\tmaster = intel_engine_lookup_user(i915,\n\t\t\t\t\t  ci.engine_class,\n\t\t\t\t\t  ci.engine_instance);\n\tif (!master) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"Unrecognised master engine: { class:%u, instance:%u }\\n\",\n\t\t\tci.engine_class, ci.engine_instance);\n\t\treturn -EINVAL;\n\t}\n\n\tif (intel_engine_uses_guc(master)) {\n\t\tdrm_dbg(&i915->drm, \"bonding extension not supported with GuC submission\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (get_user(num_bonds, &ext->num_bonds))\n\t\treturn -EFAULT;\n\n\tfor (n = 0; n < num_bonds; n++) {\n\t\tstruct intel_engine_cs *bond;\n\n\t\tif (copy_from_user(&ci, &ext->engines[n], sizeof(ci)))\n\t\t\treturn -EFAULT;\n\n\t\tbond = intel_engine_lookup_user(i915,\n\t\t\t\t\t\tci.engine_class,\n\t\t\t\t\t\tci.engine_instance);\n\t\tif (!bond) {\n\t\t\tdrm_dbg(&i915->drm,\n\t\t\t\t\"Unrecognised engine[%d] for bonding: { class:%d, instance: %d }\\n\",\n\t\t\t\tn, ci.engine_class, ci.engine_instance);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int\nset_proto_ctx_engines_parallel_submit(struct i915_user_extension __user *base,\n\t\t\t\t      void *data)\n{\n\tstruct i915_context_engines_parallel_submit __user *ext =\n\t\tcontainer_of_user(base, typeof(*ext), base);\n\tconst struct set_proto_ctx_engines *set = data;\n\tstruct drm_i915_private *i915 = set->i915;\n\tstruct i915_engine_class_instance prev_engine;\n\tu64 flags;\n\tint err = 0, n, i, j;\n\tu16 slot, width, num_siblings;\n\tstruct intel_engine_cs **siblings = NULL;\n\tintel_engine_mask_t prev_mask;\n\n\tif (get_user(slot, &ext->engine_index))\n\t\treturn -EFAULT;\n\n\tif (get_user(width, &ext->width))\n\t\treturn -EFAULT;\n\n\tif (get_user(num_siblings, &ext->num_siblings))\n\t\treturn -EFAULT;\n\n\tif (!intel_uc_uses_guc_submission(&to_gt(i915)->uc) &&\n\t    num_siblings != 1) {\n\t\tdrm_dbg(&i915->drm, \"Only 1 sibling (%d) supported in non-GuC mode\\n\",\n\t\t\tnum_siblings);\n\t\treturn -EINVAL;\n\t}\n\n\tif (slot >= set->num_engines) {\n\t\tdrm_dbg(&i915->drm, \"Invalid placement value, %d >= %d\\n\",\n\t\t\tslot, set->num_engines);\n\t\treturn -EINVAL;\n\t}\n\n\tif (set->engines[slot].type != I915_GEM_ENGINE_TYPE_INVALID) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"Invalid placement[%d], already occupied\\n\", slot);\n\t\treturn -EINVAL;\n\t}\n\n\tif (get_user(flags, &ext->flags))\n\t\treturn -EFAULT;\n\n\tif (flags) {\n\t\tdrm_dbg(&i915->drm, \"Unknown flags 0x%02llx\", flags);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (n = 0; n < ARRAY_SIZE(ext->mbz64); n++) {\n\t\terr = check_user_mbz(&ext->mbz64[n]);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tif (width < 2) {\n\t\tdrm_dbg(&i915->drm, \"Width (%d) < 2\\n\", width);\n\t\treturn -EINVAL;\n\t}\n\n\tif (num_siblings < 1) {\n\t\tdrm_dbg(&i915->drm, \"Number siblings (%d) < 1\\n\",\n\t\t\tnum_siblings);\n\t\treturn -EINVAL;\n\t}\n\n\tsiblings = kmalloc_array(num_siblings * width,\n\t\t\t\t sizeof(*siblings),\n\t\t\t\t GFP_KERNEL);\n\tif (!siblings)\n\t\treturn -ENOMEM;\n\n\t \n\tfor (i = 0; i < width; ++i) {\n\t\tintel_engine_mask_t current_mask = 0;\n\n\t\tfor (j = 0; j < num_siblings; ++j) {\n\t\t\tstruct i915_engine_class_instance ci;\n\n\t\t\tn = i * num_siblings + j;\n\t\t\tif (copy_from_user(&ci, &ext->engines[n], sizeof(ci))) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\n\t\t\tsiblings[n] =\n\t\t\t\tintel_engine_lookup_user(i915, ci.engine_class,\n\t\t\t\t\t\t\t ci.engine_instance);\n\t\t\tif (!siblings[n]) {\n\t\t\t\tdrm_dbg(&i915->drm,\n\t\t\t\t\t\"Invalid sibling[%d]: { class:%d, inst:%d }\\n\",\n\t\t\t\t\tn, ci.engine_class, ci.engine_instance);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (siblings[n]->class == RENDER_CLASS ||\n\t\t\t    siblings[n]->class == COMPUTE_CLASS) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\n\t\t\tif (n) {\n\t\t\t\tif (prev_engine.engine_class !=\n\t\t\t\t    ci.engine_class) {\n\t\t\t\t\tdrm_dbg(&i915->drm,\n\t\t\t\t\t\t\"Mismatched class %d, %d\\n\",\n\t\t\t\t\t\tprev_engine.engine_class,\n\t\t\t\t\t\tci.engine_class);\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out_err;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tprev_engine = ci;\n\t\t\tcurrent_mask |= siblings[n]->logical_mask;\n\t\t}\n\n\t\tif (i > 0) {\n\t\t\tif (current_mask != prev_mask << 1) {\n\t\t\t\tdrm_dbg(&i915->drm,\n\t\t\t\t\t\"Non contiguous logical mask 0x%x, 0x%x\\n\",\n\t\t\t\t\tprev_mask, current_mask);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\t\tprev_mask = current_mask;\n\t}\n\n\tset->engines[slot].type = I915_GEM_ENGINE_TYPE_PARALLEL;\n\tset->engines[slot].num_siblings = num_siblings;\n\tset->engines[slot].width = width;\n\tset->engines[slot].siblings = siblings;\n\n\treturn 0;\n\nout_err:\n\tkfree(siblings);\n\n\treturn err;\n}\n\nstatic const i915_user_extension_fn set_proto_ctx_engines_extensions[] = {\n\t[I915_CONTEXT_ENGINES_EXT_LOAD_BALANCE] = set_proto_ctx_engines_balance,\n\t[I915_CONTEXT_ENGINES_EXT_BOND] = set_proto_ctx_engines_bond,\n\t[I915_CONTEXT_ENGINES_EXT_PARALLEL_SUBMIT] =\n\t\tset_proto_ctx_engines_parallel_submit,\n};\n\nstatic int set_proto_ctx_engines(struct drm_i915_file_private *fpriv,\n\t\t\t         struct i915_gem_proto_context *pc,\n\t\t\t         const struct drm_i915_gem_context_param *args)\n{\n\tstruct drm_i915_private *i915 = fpriv->i915;\n\tstruct set_proto_ctx_engines set = { .i915 = i915 };\n\tstruct i915_context_param_engines __user *user =\n\t\tu64_to_user_ptr(args->value);\n\tunsigned int n;\n\tu64 extensions;\n\tint err;\n\n\tif (pc->num_user_engines >= 0) {\n\t\tdrm_dbg(&i915->drm, \"Cannot set engines twice\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (args->size < sizeof(*user) ||\n\t    !IS_ALIGNED(args->size - sizeof(*user), sizeof(*user->engines))) {\n\t\tdrm_dbg(&i915->drm, \"Invalid size for engine array: %d\\n\",\n\t\t\targs->size);\n\t\treturn -EINVAL;\n\t}\n\n\tset.num_engines = (args->size - sizeof(*user)) / sizeof(*user->engines);\n\t \n\tif (set.num_engines > I915_EXEC_RING_MASK + 1)\n\t\treturn -EINVAL;\n\n\tset.engines = kmalloc_array(set.num_engines, sizeof(*set.engines), GFP_KERNEL);\n\tif (!set.engines)\n\t\treturn -ENOMEM;\n\n\tfor (n = 0; n < set.num_engines; n++) {\n\t\tstruct i915_engine_class_instance ci;\n\t\tstruct intel_engine_cs *engine;\n\n\t\tif (copy_from_user(&ci, &user->engines[n], sizeof(ci))) {\n\t\t\tkfree(set.engines);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tmemset(&set.engines[n], 0, sizeof(set.engines[n]));\n\n\t\tif (ci.engine_class == (u16)I915_ENGINE_CLASS_INVALID &&\n\t\t    ci.engine_instance == (u16)I915_ENGINE_CLASS_INVALID_NONE)\n\t\t\tcontinue;\n\n\t\tengine = intel_engine_lookup_user(i915,\n\t\t\t\t\t\t  ci.engine_class,\n\t\t\t\t\t\t  ci.engine_instance);\n\t\tif (!engine) {\n\t\t\tdrm_dbg(&i915->drm,\n\t\t\t\t\"Invalid engine[%d]: { class:%d, instance:%d }\\n\",\n\t\t\t\tn, ci.engine_class, ci.engine_instance);\n\t\t\tkfree(set.engines);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tset.engines[n].type = I915_GEM_ENGINE_TYPE_PHYSICAL;\n\t\tset.engines[n].engine = engine;\n\t}\n\n\terr = -EFAULT;\n\tif (!get_user(extensions, &user->extensions))\n\t\terr = i915_user_extensions(u64_to_user_ptr(extensions),\n\t\t\t\t\t   set_proto_ctx_engines_extensions,\n\t\t\t\t\t   ARRAY_SIZE(set_proto_ctx_engines_extensions),\n\t\t\t\t\t   &set);\n\tif (err) {\n\t\tkfree(set.engines);\n\t\treturn err;\n\t}\n\n\tpc->num_user_engines = set.num_engines;\n\tpc->user_engines = set.engines;\n\n\treturn 0;\n}\n\nstatic int set_proto_ctx_sseu(struct drm_i915_file_private *fpriv,\n\t\t\t      struct i915_gem_proto_context *pc,\n\t\t\t      struct drm_i915_gem_context_param *args)\n{\n\tstruct drm_i915_private *i915 = fpriv->i915;\n\tstruct drm_i915_gem_context_param_sseu user_sseu;\n\tstruct intel_sseu *sseu;\n\tint ret;\n\n\tif (args->size < sizeof(user_sseu))\n\t\treturn -EINVAL;\n\n\tif (GRAPHICS_VER(i915) != 11)\n\t\treturn -ENODEV;\n\n\tif (copy_from_user(&user_sseu, u64_to_user_ptr(args->value),\n\t\t\t   sizeof(user_sseu)))\n\t\treturn -EFAULT;\n\n\tif (user_sseu.rsvd)\n\t\treturn -EINVAL;\n\n\tif (user_sseu.flags & ~(I915_CONTEXT_SSEU_FLAG_ENGINE_INDEX))\n\t\treturn -EINVAL;\n\n\tif (!!(user_sseu.flags & I915_CONTEXT_SSEU_FLAG_ENGINE_INDEX) != (pc->num_user_engines >= 0))\n\t\treturn -EINVAL;\n\n\tif (pc->num_user_engines >= 0) {\n\t\tint idx = user_sseu.engine.engine_instance;\n\t\tstruct i915_gem_proto_engine *pe;\n\n\t\tif (idx >= pc->num_user_engines)\n\t\t\treturn -EINVAL;\n\n\t\tidx = array_index_nospec(idx, pc->num_user_engines);\n\t\tpe = &pc->user_engines[idx];\n\n\t\t \n\t\tif (pe->engine->class != RENDER_CLASS)\n\t\t\treturn -EINVAL;\n\n\t\tsseu = &pe->sseu;\n\t} else {\n\t\t \n\t\tif (user_sseu.engine.engine_class != I915_ENGINE_CLASS_RENDER)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (user_sseu.engine.engine_instance != 0)\n\t\t\treturn -EINVAL;\n\n\t\tsseu = &pc->legacy_rcs_sseu;\n\t}\n\n\tret = i915_gem_user_to_context_sseu(to_gt(i915), &user_sseu, sseu);\n\tif (ret)\n\t\treturn ret;\n\n\targs->size = sizeof(user_sseu);\n\n\treturn 0;\n}\n\nstatic int set_proto_ctx_param(struct drm_i915_file_private *fpriv,\n\t\t\t       struct i915_gem_proto_context *pc,\n\t\t\t       struct drm_i915_gem_context_param *args)\n{\n\tint ret = 0;\n\n\tswitch (args->param) {\n\tcase I915_CONTEXT_PARAM_NO_ERROR_CAPTURE:\n\t\tif (args->size)\n\t\t\tret = -EINVAL;\n\t\telse if (args->value)\n\t\t\tpc->user_flags |= BIT(UCONTEXT_NO_ERROR_CAPTURE);\n\t\telse\n\t\t\tpc->user_flags &= ~BIT(UCONTEXT_NO_ERROR_CAPTURE);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_BANNABLE:\n\t\tif (args->size)\n\t\t\tret = -EINVAL;\n\t\telse if (!capable(CAP_SYS_ADMIN) && !args->value)\n\t\t\tret = -EPERM;\n\t\telse if (args->value)\n\t\t\tpc->user_flags |= BIT(UCONTEXT_BANNABLE);\n\t\telse if (pc->uses_protected_content)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tpc->user_flags &= ~BIT(UCONTEXT_BANNABLE);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_RECOVERABLE:\n\t\tif (args->size)\n\t\t\tret = -EINVAL;\n\t\telse if (!args->value)\n\t\t\tpc->user_flags &= ~BIT(UCONTEXT_RECOVERABLE);\n\t\telse if (pc->uses_protected_content)\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tpc->user_flags |= BIT(UCONTEXT_RECOVERABLE);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PRIORITY:\n\t\tret = validate_priority(fpriv->i915, args);\n\t\tif (!ret)\n\t\t\tpc->sched.priority = args->value;\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_SSEU:\n\t\tret = set_proto_ctx_sseu(fpriv, pc, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_VM:\n\t\tret = set_proto_ctx_vm(fpriv, pc, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_ENGINES:\n\t\tret = set_proto_ctx_engines(fpriv, pc, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PERSISTENCE:\n\t\tif (args->size)\n\t\t\tret = -EINVAL;\n\t\telse\n\t\t\tret = proto_context_set_persistence(fpriv->i915, pc,\n\t\t\t\t\t\t\t    args->value);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PROTECTED_CONTENT:\n\t\tret = proto_context_set_protected(fpriv->i915, pc,\n\t\t\t\t\t\t  args->value);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_NO_ZEROMAP:\n\tcase I915_CONTEXT_PARAM_BAN_PERIOD:\n\tcase I915_CONTEXT_PARAM_RINGSIZE:\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int intel_context_set_gem(struct intel_context *ce,\n\t\t\t\t struct i915_gem_context *ctx,\n\t\t\t\t struct intel_sseu sseu)\n{\n\tint ret = 0;\n\n\tGEM_BUG_ON(rcu_access_pointer(ce->gem_context));\n\tRCU_INIT_POINTER(ce->gem_context, ctx);\n\n\tGEM_BUG_ON(intel_context_is_pinned(ce));\n\n\tif (ce->engine->class == COMPUTE_CLASS)\n\t\tce->ring_size = SZ_512K;\n\telse\n\t\tce->ring_size = SZ_16K;\n\n\ti915_vm_put(ce->vm);\n\tce->vm = i915_gem_context_get_eb_vm(ctx);\n\n\tif (ctx->sched.priority >= I915_PRIORITY_NORMAL &&\n\t    intel_engine_has_timeslices(ce->engine) &&\n\t    intel_engine_has_semaphores(ce->engine))\n\t\t__set_bit(CONTEXT_USE_SEMAPHORES, &ce->flags);\n\n\tif (CONFIG_DRM_I915_REQUEST_TIMEOUT &&\n\t    ctx->i915->params.request_timeout_ms) {\n\t\tunsigned int timeout_ms = ctx->i915->params.request_timeout_ms;\n\n\t\tintel_context_set_watchdog_us(ce, (u64)timeout_ms * 1000);\n\t}\n\n\t \n\tif (sseu.slice_mask && !WARN_ON(ce->engine->class != RENDER_CLASS))\n\t\tret = intel_context_reconfigure_sseu(ce, sseu);\n\n\treturn ret;\n}\n\nstatic void __unpin_engines(struct i915_gem_engines *e, unsigned int count)\n{\n\twhile (count--) {\n\t\tstruct intel_context *ce = e->engines[count], *child;\n\n\t\tif (!ce || !test_bit(CONTEXT_PERMA_PIN, &ce->flags))\n\t\t\tcontinue;\n\n\t\tfor_each_child(ce, child)\n\t\t\tintel_context_unpin(child);\n\t\tintel_context_unpin(ce);\n\t}\n}\n\nstatic void unpin_engines(struct i915_gem_engines *e)\n{\n\t__unpin_engines(e, e->num_engines);\n}\n\nstatic void __free_engines(struct i915_gem_engines *e, unsigned int count)\n{\n\twhile (count--) {\n\t\tif (!e->engines[count])\n\t\t\tcontinue;\n\n\t\tintel_context_put(e->engines[count]);\n\t}\n\tkfree(e);\n}\n\nstatic void free_engines(struct i915_gem_engines *e)\n{\n\t__free_engines(e, e->num_engines);\n}\n\nstatic void free_engines_rcu(struct rcu_head *rcu)\n{\n\tstruct i915_gem_engines *engines =\n\t\tcontainer_of(rcu, struct i915_gem_engines, rcu);\n\n\ti915_sw_fence_fini(&engines->fence);\n\tfree_engines(engines);\n}\n\nstatic void accumulate_runtime(struct i915_drm_client *client,\n\t\t\t       struct i915_gem_engines *engines)\n{\n\tstruct i915_gem_engines_iter it;\n\tstruct intel_context *ce;\n\n\tif (!client)\n\t\treturn;\n\n\t \n\tfor_each_gem_engine(ce, engines, it) {\n\t\tunsigned int class = ce->engine->uabi_class;\n\n\t\tGEM_BUG_ON(class >= ARRAY_SIZE(client->past_runtime));\n\t\tatomic64_add(intel_context_get_total_runtime_ns(ce),\n\t\t\t     &client->past_runtime[class]);\n\t}\n}\n\nstatic int\nengines_notify(struct i915_sw_fence *fence, enum i915_sw_fence_notify state)\n{\n\tstruct i915_gem_engines *engines =\n\t\tcontainer_of(fence, typeof(*engines), fence);\n\tstruct i915_gem_context *ctx = engines->ctx;\n\n\tswitch (state) {\n\tcase FENCE_COMPLETE:\n\t\tif (!list_empty(&engines->link)) {\n\t\t\tunsigned long flags;\n\n\t\t\tspin_lock_irqsave(&ctx->stale.lock, flags);\n\t\t\tlist_del(&engines->link);\n\t\t\tspin_unlock_irqrestore(&ctx->stale.lock, flags);\n\t\t}\n\t\taccumulate_runtime(ctx->client, engines);\n\t\ti915_gem_context_put(ctx);\n\n\t\tbreak;\n\n\tcase FENCE_FREE:\n\t\tinit_rcu_head(&engines->rcu);\n\t\tcall_rcu(&engines->rcu, free_engines_rcu);\n\t\tbreak;\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\nstatic struct i915_gem_engines *alloc_engines(unsigned int count)\n{\n\tstruct i915_gem_engines *e;\n\n\te = kzalloc(struct_size(e, engines, count), GFP_KERNEL);\n\tif (!e)\n\t\treturn NULL;\n\n\ti915_sw_fence_init(&e->fence, engines_notify);\n\treturn e;\n}\n\nstatic struct i915_gem_engines *default_engines(struct i915_gem_context *ctx,\n\t\t\t\t\t\tstruct intel_sseu rcs_sseu)\n{\n\tconst unsigned int max = I915_NUM_ENGINES;\n\tstruct intel_engine_cs *engine;\n\tstruct i915_gem_engines *e, *err;\n\n\te = alloc_engines(max);\n\tif (!e)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor_each_uabi_engine(engine, ctx->i915) {\n\t\tstruct intel_context *ce;\n\t\tstruct intel_sseu sseu = {};\n\t\tint ret;\n\n\t\tif (engine->legacy_idx == INVALID_ENGINE)\n\t\t\tcontinue;\n\n\t\tGEM_BUG_ON(engine->legacy_idx >= max);\n\t\tGEM_BUG_ON(e->engines[engine->legacy_idx]);\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = ERR_CAST(ce);\n\t\t\tgoto free_engines;\n\t\t}\n\n\t\te->engines[engine->legacy_idx] = ce;\n\t\te->num_engines = max(e->num_engines, engine->legacy_idx + 1);\n\n\t\tif (engine->class == RENDER_CLASS)\n\t\t\tsseu = rcs_sseu;\n\n\t\tret = intel_context_set_gem(ce, ctx, sseu);\n\t\tif (ret) {\n\t\t\terr = ERR_PTR(ret);\n\t\t\tgoto free_engines;\n\t\t}\n\n\t}\n\n\treturn e;\n\nfree_engines:\n\tfree_engines(e);\n\treturn err;\n}\n\nstatic int perma_pin_contexts(struct intel_context *ce)\n{\n\tstruct intel_context *child;\n\tint i = 0, j = 0, ret;\n\n\tGEM_BUG_ON(!intel_context_is_parent(ce));\n\n\tret = intel_context_pin(ce);\n\tif (unlikely(ret))\n\t\treturn ret;\n\n\tfor_each_child(ce, child) {\n\t\tret = intel_context_pin(child);\n\t\tif (unlikely(ret))\n\t\t\tgoto unwind;\n\t\t++i;\n\t}\n\n\tset_bit(CONTEXT_PERMA_PIN, &ce->flags);\n\n\treturn 0;\n\nunwind:\n\tintel_context_unpin(ce);\n\tfor_each_child(ce, child) {\n\t\tif (j++ < i)\n\t\t\tintel_context_unpin(child);\n\t\telse\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic struct i915_gem_engines *user_engines(struct i915_gem_context *ctx,\n\t\t\t\t\t     unsigned int num_engines,\n\t\t\t\t\t     struct i915_gem_proto_engine *pe)\n{\n\tstruct i915_gem_engines *e, *err;\n\tunsigned int n;\n\n\te = alloc_engines(num_engines);\n\tif (!e)\n\t\treturn ERR_PTR(-ENOMEM);\n\te->num_engines = num_engines;\n\n\tfor (n = 0; n < num_engines; n++) {\n\t\tstruct intel_context *ce, *child;\n\t\tint ret;\n\n\t\tswitch (pe[n].type) {\n\t\tcase I915_GEM_ENGINE_TYPE_PHYSICAL:\n\t\t\tce = intel_context_create(pe[n].engine);\n\t\t\tbreak;\n\n\t\tcase I915_GEM_ENGINE_TYPE_BALANCED:\n\t\t\tce = intel_engine_create_virtual(pe[n].siblings,\n\t\t\t\t\t\t\t pe[n].num_siblings, 0);\n\t\t\tbreak;\n\n\t\tcase I915_GEM_ENGINE_TYPE_PARALLEL:\n\t\t\tce = intel_engine_create_parallel(pe[n].siblings,\n\t\t\t\t\t\t\t  pe[n].num_siblings,\n\t\t\t\t\t\t\t  pe[n].width);\n\t\t\tbreak;\n\n\t\tcase I915_GEM_ENGINE_TYPE_INVALID:\n\t\tdefault:\n\t\t\tGEM_WARN_ON(pe[n].type != I915_GEM_ENGINE_TYPE_INVALID);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = ERR_CAST(ce);\n\t\t\tgoto free_engines;\n\t\t}\n\n\t\te->engines[n] = ce;\n\n\t\tret = intel_context_set_gem(ce, ctx, pe->sseu);\n\t\tif (ret) {\n\t\t\terr = ERR_PTR(ret);\n\t\t\tgoto free_engines;\n\t\t}\n\t\tfor_each_child(ce, child) {\n\t\t\tret = intel_context_set_gem(child, ctx, pe->sseu);\n\t\t\tif (ret) {\n\t\t\t\terr = ERR_PTR(ret);\n\t\t\t\tgoto free_engines;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (pe[n].type == I915_GEM_ENGINE_TYPE_PARALLEL) {\n\t\t\tret = perma_pin_contexts(ce);\n\t\t\tif (ret) {\n\t\t\t\terr = ERR_PTR(ret);\n\t\t\t\tgoto free_engines;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn e;\n\nfree_engines:\n\tfree_engines(e);\n\treturn err;\n}\n\nstatic void i915_gem_context_release_work(struct work_struct *work)\n{\n\tstruct i915_gem_context *ctx = container_of(work, typeof(*ctx),\n\t\t\t\t\t\t    release_work);\n\tstruct i915_address_space *vm;\n\n\ttrace_i915_context_free(ctx);\n\tGEM_BUG_ON(!i915_gem_context_is_closed(ctx));\n\n\tspin_lock(&ctx->i915->gem.contexts.lock);\n\tlist_del(&ctx->link);\n\tspin_unlock(&ctx->i915->gem.contexts.lock);\n\n\tif (ctx->syncobj)\n\t\tdrm_syncobj_put(ctx->syncobj);\n\n\tvm = ctx->vm;\n\tif (vm)\n\t\ti915_vm_put(vm);\n\n\tif (ctx->pxp_wakeref)\n\t\tintel_runtime_pm_put(&ctx->i915->runtime_pm, ctx->pxp_wakeref);\n\n\tif (ctx->client)\n\t\ti915_drm_client_put(ctx->client);\n\n\tmutex_destroy(&ctx->engines_mutex);\n\tmutex_destroy(&ctx->lut_mutex);\n\n\tput_pid(ctx->pid);\n\tmutex_destroy(&ctx->mutex);\n\n\tkfree_rcu(ctx, rcu);\n}\n\nvoid i915_gem_context_release(struct kref *ref)\n{\n\tstruct i915_gem_context *ctx = container_of(ref, typeof(*ctx), ref);\n\n\tqueue_work(ctx->i915->wq, &ctx->release_work);\n}\n\nstatic inline struct i915_gem_engines *\n__context_engines_static(const struct i915_gem_context *ctx)\n{\n\treturn rcu_dereference_protected(ctx->engines, true);\n}\n\nstatic void __reset_context(struct i915_gem_context *ctx,\n\t\t\t    struct intel_engine_cs *engine)\n{\n\tintel_gt_handle_error(engine->gt, engine->mask, 0,\n\t\t\t      \"context closure in %s\", ctx->name);\n}\n\nstatic bool __cancel_engine(struct intel_engine_cs *engine)\n{\n\t \n\treturn intel_engine_pulse(engine) == 0;\n}\n\nstatic struct intel_engine_cs *active_engine(struct intel_context *ce)\n{\n\tstruct intel_engine_cs *engine = NULL;\n\tstruct i915_request *rq;\n\n\tif (intel_context_has_inflight(ce))\n\t\treturn intel_context_inflight(ce);\n\n\tif (!ce->timeline)\n\t\treturn NULL;\n\n\t \n\trcu_read_lock();\n\tlist_for_each_entry_reverse(rq, &ce->timeline->requests, link) {\n\t\tbool found;\n\n\t\t \n\t\tif (!i915_request_get_rcu(rq))\n\t\t\tbreak;\n\n\t\t \n\t\tfound = true;\n\t\tif (likely(rcu_access_pointer(rq->timeline) == ce->timeline))\n\t\t\tfound = i915_request_active_engine(rq, &engine);\n\n\t\ti915_request_put(rq);\n\t\tif (found)\n\t\t\tbreak;\n\t}\n\trcu_read_unlock();\n\n\treturn engine;\n}\n\nstatic void\nkill_engines(struct i915_gem_engines *engines, bool exit, bool persistent)\n{\n\tstruct i915_gem_engines_iter it;\n\tstruct intel_context *ce;\n\n\t \n\tfor_each_gem_engine(ce, engines, it) {\n\t\tstruct intel_engine_cs *engine;\n\n\t\tif ((exit || !persistent) && intel_context_revoke(ce))\n\t\t\tcontinue;  \n\n\t\t \n\t\tengine = active_engine(ce);\n\n\t\t \n\t\tif (engine && !__cancel_engine(engine) && (exit || !persistent))\n\t\t\t \n\t\t\t__reset_context(engines->ctx, engine);\n\t}\n}\n\nstatic void kill_context(struct i915_gem_context *ctx)\n{\n\tstruct i915_gem_engines *pos, *next;\n\n\tspin_lock_irq(&ctx->stale.lock);\n\tGEM_BUG_ON(!i915_gem_context_is_closed(ctx));\n\tlist_for_each_entry_safe(pos, next, &ctx->stale.engines, link) {\n\t\tif (!i915_sw_fence_await(&pos->fence)) {\n\t\t\tlist_del_init(&pos->link);\n\t\t\tcontinue;\n\t\t}\n\n\t\tspin_unlock_irq(&ctx->stale.lock);\n\n\t\tkill_engines(pos, !ctx->i915->params.enable_hangcheck,\n\t\t\t     i915_gem_context_is_persistent(ctx));\n\n\t\tspin_lock_irq(&ctx->stale.lock);\n\t\tGEM_BUG_ON(i915_sw_fence_signaled(&pos->fence));\n\t\tlist_safe_reset_next(pos, next, link);\n\t\tlist_del_init(&pos->link);  \n\n\t\ti915_sw_fence_complete(&pos->fence);\n\t}\n\tspin_unlock_irq(&ctx->stale.lock);\n}\n\nstatic void engines_idle_release(struct i915_gem_context *ctx,\n\t\t\t\t struct i915_gem_engines *engines)\n{\n\tstruct i915_gem_engines_iter it;\n\tstruct intel_context *ce;\n\n\tINIT_LIST_HEAD(&engines->link);\n\n\tengines->ctx = i915_gem_context_get(ctx);\n\n\tfor_each_gem_engine(ce, engines, it) {\n\t\tint err;\n\n\t\t \n\t\tintel_context_close(ce);\n\t\tif (!intel_context_pin_if_active(ce))\n\t\t\tcontinue;\n\n\t\t \n\t\terr = i915_sw_fence_await_active(&engines->fence,\n\t\t\t\t\t\t &ce->active,\n\t\t\t\t\t\t I915_ACTIVE_AWAIT_BARRIER);\n\t\tintel_context_unpin(ce);\n\t\tif (err)\n\t\t\tgoto kill;\n\t}\n\n\tspin_lock_irq(&ctx->stale.lock);\n\tif (!i915_gem_context_is_closed(ctx))\n\t\tlist_add_tail(&engines->link, &ctx->stale.engines);\n\tspin_unlock_irq(&ctx->stale.lock);\n\nkill:\n\tif (list_empty(&engines->link))  \n\t\tkill_engines(engines, true,\n\t\t\t     i915_gem_context_is_persistent(ctx));\n\n\ti915_sw_fence_commit(&engines->fence);\n}\n\nstatic void set_closed_name(struct i915_gem_context *ctx)\n{\n\tchar *s;\n\n\t \n\n\ts = strrchr(ctx->name, '[');\n\tif (!s)\n\t\treturn;\n\n\t*s = '<';\n\n\ts = strchr(s + 1, ']');\n\tif (s)\n\t\t*s = '>';\n}\n\nstatic void context_close(struct i915_gem_context *ctx)\n{\n\tstruct i915_drm_client *client;\n\n\t \n\tmutex_lock(&ctx->engines_mutex);\n\tunpin_engines(__context_engines_static(ctx));\n\tengines_idle_release(ctx, rcu_replace_pointer(ctx->engines, NULL, 1));\n\ti915_gem_context_set_closed(ctx);\n\tmutex_unlock(&ctx->engines_mutex);\n\n\tmutex_lock(&ctx->mutex);\n\n\tset_closed_name(ctx);\n\n\t \n\tlut_close(ctx);\n\n\tctx->file_priv = ERR_PTR(-EBADF);\n\n\tclient = ctx->client;\n\tif (client) {\n\t\tspin_lock(&client->ctx_lock);\n\t\tlist_del_rcu(&ctx->client_link);\n\t\tspin_unlock(&client->ctx_lock);\n\t}\n\n\tmutex_unlock(&ctx->mutex);\n\n\t \n\tkill_context(ctx);\n\n\ti915_gem_context_put(ctx);\n}\n\nstatic int __context_set_persistence(struct i915_gem_context *ctx, bool state)\n{\n\tif (i915_gem_context_is_persistent(ctx) == state)\n\t\treturn 0;\n\n\tif (state) {\n\t\t \n\t\tif (!ctx->i915->params.enable_hangcheck)\n\t\t\treturn -EINVAL;\n\n\t\ti915_gem_context_set_persistence(ctx);\n\t} else {\n\t\t \n\t\tif (!(ctx->i915->caps.scheduler & I915_SCHEDULER_CAP_PREEMPTION))\n\t\t\treturn -ENODEV;\n\n\t\t \n\t\tif (!intel_has_reset_engine(to_gt(ctx->i915)))\n\t\t\treturn -ENODEV;\n\n\t\ti915_gem_context_clear_persistence(ctx);\n\t}\n\n\treturn 0;\n}\n\nstatic struct i915_gem_context *\ni915_gem_create_context(struct drm_i915_private *i915,\n\t\t\tconst struct i915_gem_proto_context *pc)\n{\n\tstruct i915_gem_context *ctx;\n\tstruct i915_address_space *vm = NULL;\n\tstruct i915_gem_engines *e;\n\tint err;\n\tint i;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tkref_init(&ctx->ref);\n\tctx->i915 = i915;\n\tctx->sched = pc->sched;\n\tmutex_init(&ctx->mutex);\n\tINIT_LIST_HEAD(&ctx->link);\n\tINIT_WORK(&ctx->release_work, i915_gem_context_release_work);\n\n\tspin_lock_init(&ctx->stale.lock);\n\tINIT_LIST_HEAD(&ctx->stale.engines);\n\n\tif (pc->vm) {\n\t\tvm = i915_vm_get(pc->vm);\n\t} else if (HAS_FULL_PPGTT(i915)) {\n\t\tstruct i915_ppgtt *ppgtt;\n\n\t\tppgtt = i915_ppgtt_create(to_gt(i915), 0);\n\t\tif (IS_ERR(ppgtt)) {\n\t\t\tdrm_dbg(&i915->drm, \"PPGTT setup failed (%ld)\\n\",\n\t\t\t\tPTR_ERR(ppgtt));\n\t\t\terr = PTR_ERR(ppgtt);\n\t\t\tgoto err_ctx;\n\t\t}\n\t\tvm = &ppgtt->vm;\n\t}\n\tif (vm)\n\t\tctx->vm = vm;\n\n\tmutex_init(&ctx->engines_mutex);\n\tif (pc->num_user_engines >= 0) {\n\t\ti915_gem_context_set_user_engines(ctx);\n\t\te = user_engines(ctx, pc->num_user_engines, pc->user_engines);\n\t} else {\n\t\ti915_gem_context_clear_user_engines(ctx);\n\t\te = default_engines(ctx, pc->legacy_rcs_sseu);\n\t}\n\tif (IS_ERR(e)) {\n\t\terr = PTR_ERR(e);\n\t\tgoto err_vm;\n\t}\n\tRCU_INIT_POINTER(ctx->engines, e);\n\n\tINIT_RADIX_TREE(&ctx->handles_vma, GFP_KERNEL);\n\tmutex_init(&ctx->lut_mutex);\n\n\t \n\tctx->remap_slice = ALL_L3_SLICES(i915);\n\n\tctx->user_flags = pc->user_flags;\n\n\tfor (i = 0; i < ARRAY_SIZE(ctx->hang_timestamp); i++)\n\t\tctx->hang_timestamp[i] = jiffies - CONTEXT_FAST_HANG_JIFFIES;\n\n\tif (pc->single_timeline) {\n\t\terr = drm_syncobj_create(&ctx->syncobj,\n\t\t\t\t\t DRM_SYNCOBJ_CREATE_SIGNALED,\n\t\t\t\t\t NULL);\n\t\tif (err)\n\t\t\tgoto err_engines;\n\t}\n\n\tif (pc->uses_protected_content) {\n\t\tctx->pxp_wakeref = intel_runtime_pm_get(&i915->runtime_pm);\n\t\tctx->uses_protected_content = true;\n\t}\n\n\ttrace_i915_context_create(ctx);\n\n\treturn ctx;\n\nerr_engines:\n\tfree_engines(e);\nerr_vm:\n\tif (ctx->vm)\n\t\ti915_vm_put(ctx->vm);\nerr_ctx:\n\tkfree(ctx);\n\treturn ERR_PTR(err);\n}\n\nstatic void init_contexts(struct i915_gem_contexts *gc)\n{\n\tspin_lock_init(&gc->lock);\n\tINIT_LIST_HEAD(&gc->list);\n}\n\nvoid i915_gem_init__contexts(struct drm_i915_private *i915)\n{\n\tinit_contexts(&i915->gem.contexts);\n}\n\n \nstatic void gem_context_register(struct i915_gem_context *ctx,\n\t\t\t\t struct drm_i915_file_private *fpriv,\n\t\t\t\t u32 id)\n{\n\tstruct drm_i915_private *i915 = ctx->i915;\n\tvoid *old;\n\n\tctx->file_priv = fpriv;\n\n\tctx->pid = get_task_pid(current, PIDTYPE_PID);\n\tctx->client = i915_drm_client_get(fpriv->client);\n\n\tsnprintf(ctx->name, sizeof(ctx->name), \"%s[%d]\",\n\t\t current->comm, pid_nr(ctx->pid));\n\n\tspin_lock(&ctx->client->ctx_lock);\n\tlist_add_tail_rcu(&ctx->client_link, &ctx->client->ctx_list);\n\tspin_unlock(&ctx->client->ctx_lock);\n\n\tspin_lock(&i915->gem.contexts.lock);\n\tlist_add_tail(&ctx->link, &i915->gem.contexts.list);\n\tspin_unlock(&i915->gem.contexts.lock);\n\n\t \n\told = xa_store(&fpriv->context_xa, id, ctx, GFP_KERNEL);\n\tWARN_ON(old);\n}\n\nint i915_gem_context_open(struct drm_i915_private *i915,\n\t\t\t  struct drm_file *file)\n{\n\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\tstruct i915_gem_proto_context *pc;\n\tstruct i915_gem_context *ctx;\n\tint err;\n\n\tmutex_init(&file_priv->proto_context_lock);\n\txa_init_flags(&file_priv->proto_context_xa, XA_FLAGS_ALLOC);\n\n\t \n\txa_init_flags(&file_priv->context_xa, XA_FLAGS_ALLOC1);\n\n\t \n\txa_init_flags(&file_priv->vm_xa, XA_FLAGS_ALLOC1);\n\n\tpc = proto_context_create(i915, 0);\n\tif (IS_ERR(pc)) {\n\t\terr = PTR_ERR(pc);\n\t\tgoto err;\n\t}\n\n\tctx = i915_gem_create_context(i915, pc);\n\tproto_context_close(i915, pc);\n\tif (IS_ERR(ctx)) {\n\t\terr = PTR_ERR(ctx);\n\t\tgoto err;\n\t}\n\n\tgem_context_register(ctx, file_priv, 0);\n\n\treturn 0;\n\nerr:\n\txa_destroy(&file_priv->vm_xa);\n\txa_destroy(&file_priv->context_xa);\n\txa_destroy(&file_priv->proto_context_xa);\n\tmutex_destroy(&file_priv->proto_context_lock);\n\treturn err;\n}\n\nvoid i915_gem_context_close(struct drm_file *file)\n{\n\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\tstruct i915_gem_proto_context *pc;\n\tstruct i915_address_space *vm;\n\tstruct i915_gem_context *ctx;\n\tunsigned long idx;\n\n\txa_for_each(&file_priv->proto_context_xa, idx, pc)\n\t\tproto_context_close(file_priv->i915, pc);\n\txa_destroy(&file_priv->proto_context_xa);\n\tmutex_destroy(&file_priv->proto_context_lock);\n\n\txa_for_each(&file_priv->context_xa, idx, ctx)\n\t\tcontext_close(ctx);\n\txa_destroy(&file_priv->context_xa);\n\n\txa_for_each(&file_priv->vm_xa, idx, vm)\n\t\ti915_vm_put(vm);\n\txa_destroy(&file_priv->vm_xa);\n}\n\nint i915_gem_vm_create_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file)\n{\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tstruct drm_i915_gem_vm_control *args = data;\n\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\tstruct i915_ppgtt *ppgtt;\n\tu32 id;\n\tint err;\n\n\tif (!HAS_FULL_PPGTT(i915))\n\t\treturn -ENODEV;\n\n\tif (args->flags)\n\t\treturn -EINVAL;\n\n\tppgtt = i915_ppgtt_create(to_gt(i915), 0);\n\tif (IS_ERR(ppgtt))\n\t\treturn PTR_ERR(ppgtt);\n\n\tif (args->extensions) {\n\t\terr = i915_user_extensions(u64_to_user_ptr(args->extensions),\n\t\t\t\t\t   NULL, 0,\n\t\t\t\t\t   ppgtt);\n\t\tif (err)\n\t\t\tgoto err_put;\n\t}\n\n\terr = xa_alloc(&file_priv->vm_xa, &id, &ppgtt->vm,\n\t\t       xa_limit_32b, GFP_KERNEL);\n\tif (err)\n\t\tgoto err_put;\n\n\tGEM_BUG_ON(id == 0);  \n\targs->vm_id = id;\n\treturn 0;\n\nerr_put:\n\ti915_vm_put(&ppgtt->vm);\n\treturn err;\n}\n\nint i915_gem_vm_destroy_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *file)\n{\n\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\tstruct drm_i915_gem_vm_control *args = data;\n\tstruct i915_address_space *vm;\n\n\tif (args->flags)\n\t\treturn -EINVAL;\n\n\tif (args->extensions)\n\t\treturn -EINVAL;\n\n\tvm = xa_erase(&file_priv->vm_xa, args->vm_id);\n\tif (!vm)\n\t\treturn -ENOENT;\n\n\ti915_vm_put(vm);\n\treturn 0;\n}\n\nstatic int get_ppgtt(struct drm_i915_file_private *file_priv,\n\t\t     struct i915_gem_context *ctx,\n\t\t     struct drm_i915_gem_context_param *args)\n{\n\tstruct i915_address_space *vm;\n\tint err;\n\tu32 id;\n\n\tif (!i915_gem_context_has_full_ppgtt(ctx))\n\t\treturn -ENODEV;\n\n\tvm = ctx->vm;\n\tGEM_BUG_ON(!vm);\n\n\t \n\ti915_vm_get(vm);\n\n\terr = xa_alloc(&file_priv->vm_xa, &id, vm, xa_limit_32b, GFP_KERNEL);\n\tif (err) {\n\t\ti915_vm_put(vm);\n\t\treturn err;\n\t}\n\n\tGEM_BUG_ON(id == 0);  \n\targs->value = id;\n\targs->size = 0;\n\n\treturn err;\n}\n\nint\ni915_gem_user_to_context_sseu(struct intel_gt *gt,\n\t\t\t      const struct drm_i915_gem_context_param_sseu *user,\n\t\t\t      struct intel_sseu *context)\n{\n\tconst struct sseu_dev_info *device = &gt->info.sseu;\n\tstruct drm_i915_private *i915 = gt->i915;\n\tunsigned int dev_subslice_mask = intel_sseu_get_hsw_subslices(device, 0);\n\n\t \n\tif (!user->slice_mask || !user->subslice_mask ||\n\t    !user->min_eus_per_subslice || !user->max_eus_per_subslice)\n\t\treturn -EINVAL;\n\n\t \n\tif (user->max_eus_per_subslice < user->min_eus_per_subslice)\n\t\treturn -EINVAL;\n\n\t \n\tif (overflows_type(user->slice_mask, context->slice_mask) ||\n\t    overflows_type(user->subslice_mask, context->subslice_mask) ||\n\t    overflows_type(user->min_eus_per_subslice,\n\t\t\t   context->min_eus_per_subslice) ||\n\t    overflows_type(user->max_eus_per_subslice,\n\t\t\t   context->max_eus_per_subslice))\n\t\treturn -EINVAL;\n\n\t \n\tif (user->slice_mask & ~device->slice_mask)\n\t\treturn -EINVAL;\n\n\tif (user->subslice_mask & ~dev_subslice_mask)\n\t\treturn -EINVAL;\n\n\tif (user->max_eus_per_subslice > device->max_eus_per_subslice)\n\t\treturn -EINVAL;\n\n\tcontext->slice_mask = user->slice_mask;\n\tcontext->subslice_mask = user->subslice_mask;\n\tcontext->min_eus_per_subslice = user->min_eus_per_subslice;\n\tcontext->max_eus_per_subslice = user->max_eus_per_subslice;\n\n\t \n\tif (GRAPHICS_VER(i915) == 11) {\n\t\tunsigned int hw_s = hweight8(device->slice_mask);\n\t\tunsigned int hw_ss_per_s = hweight8(dev_subslice_mask);\n\t\tunsigned int req_s = hweight8(context->slice_mask);\n\t\tunsigned int req_ss = hweight8(context->subslice_mask);\n\n\t\t \n\t\tif (req_s > 1 && req_ss != hw_ss_per_s)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (req_ss > 4 && (req_ss & 1))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (req_s == 1 && req_ss < hw_ss_per_s &&\n\t\t    req_ss > (hw_ss_per_s / 2))\n\t\t\treturn -EINVAL;\n\n\t\t \n\n\t\t \n\t\tif (req_s != 1 && req_s != hw_s)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (req_s == 1 &&\n\t\t    (req_ss != hw_ss_per_s && req_ss != (hw_ss_per_s / 2)))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif ((user->min_eus_per_subslice !=\n\t\t     device->max_eus_per_subslice) ||\n\t\t    (user->max_eus_per_subslice !=\n\t\t     device->max_eus_per_subslice))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int set_sseu(struct i915_gem_context *ctx,\n\t\t    struct drm_i915_gem_context_param *args)\n{\n\tstruct drm_i915_private *i915 = ctx->i915;\n\tstruct drm_i915_gem_context_param_sseu user_sseu;\n\tstruct intel_context *ce;\n\tstruct intel_sseu sseu;\n\tunsigned long lookup;\n\tint ret;\n\n\tif (args->size < sizeof(user_sseu))\n\t\treturn -EINVAL;\n\n\tif (GRAPHICS_VER(i915) != 11)\n\t\treturn -ENODEV;\n\n\tif (copy_from_user(&user_sseu, u64_to_user_ptr(args->value),\n\t\t\t   sizeof(user_sseu)))\n\t\treturn -EFAULT;\n\n\tif (user_sseu.rsvd)\n\t\treturn -EINVAL;\n\n\tif (user_sseu.flags & ~(I915_CONTEXT_SSEU_FLAG_ENGINE_INDEX))\n\t\treturn -EINVAL;\n\n\tlookup = 0;\n\tif (user_sseu.flags & I915_CONTEXT_SSEU_FLAG_ENGINE_INDEX)\n\t\tlookup |= LOOKUP_USER_INDEX;\n\n\tce = lookup_user_engine(ctx, lookup, &user_sseu.engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\t \n\tif (ce->engine->class != RENDER_CLASS) {\n\t\tret = -ENODEV;\n\t\tgoto out_ce;\n\t}\n\n\tret = i915_gem_user_to_context_sseu(ce->engine->gt, &user_sseu, &sseu);\n\tif (ret)\n\t\tgoto out_ce;\n\n\tret = intel_context_reconfigure_sseu(ce, sseu);\n\tif (ret)\n\t\tgoto out_ce;\n\n\targs->size = sizeof(user_sseu);\n\nout_ce:\n\tintel_context_put(ce);\n\treturn ret;\n}\n\nstatic int\nset_persistence(struct i915_gem_context *ctx,\n\t\tconst struct drm_i915_gem_context_param *args)\n{\n\tif (args->size)\n\t\treturn -EINVAL;\n\n\treturn __context_set_persistence(ctx, args->value);\n}\n\nstatic int set_priority(struct i915_gem_context *ctx,\n\t\t\tconst struct drm_i915_gem_context_param *args)\n{\n\tstruct i915_gem_engines_iter it;\n\tstruct intel_context *ce;\n\tint err;\n\n\terr = validate_priority(ctx->i915, args);\n\tif (err)\n\t\treturn err;\n\n\tctx->sched.priority = args->value;\n\n\tfor_each_gem_engine(ce, i915_gem_context_lock_engines(ctx), it) {\n\t\tif (!intel_engine_has_timeslices(ce->engine))\n\t\t\tcontinue;\n\n\t\tif (ctx->sched.priority >= I915_PRIORITY_NORMAL &&\n\t\t    intel_engine_has_semaphores(ce->engine))\n\t\t\tintel_context_set_use_semaphores(ce);\n\t\telse\n\t\t\tintel_context_clear_use_semaphores(ce);\n\t}\n\ti915_gem_context_unlock_engines(ctx);\n\n\treturn 0;\n}\n\nstatic int get_protected(struct i915_gem_context *ctx,\n\t\t\t struct drm_i915_gem_context_param *args)\n{\n\targs->size = 0;\n\targs->value = i915_gem_context_uses_protected_content(ctx);\n\n\treturn 0;\n}\n\nstatic int ctx_setparam(struct drm_i915_file_private *fpriv,\n\t\t\tstruct i915_gem_context *ctx,\n\t\t\tstruct drm_i915_gem_context_param *args)\n{\n\tint ret = 0;\n\n\tswitch (args->param) {\n\tcase I915_CONTEXT_PARAM_NO_ERROR_CAPTURE:\n\t\tif (args->size)\n\t\t\tret = -EINVAL;\n\t\telse if (args->value)\n\t\t\ti915_gem_context_set_no_error_capture(ctx);\n\t\telse\n\t\t\ti915_gem_context_clear_no_error_capture(ctx);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_BANNABLE:\n\t\tif (args->size)\n\t\t\tret = -EINVAL;\n\t\telse if (!capable(CAP_SYS_ADMIN) && !args->value)\n\t\t\tret = -EPERM;\n\t\telse if (args->value)\n\t\t\ti915_gem_context_set_bannable(ctx);\n\t\telse if (i915_gem_context_uses_protected_content(ctx))\n\t\t\tret = -EPERM;  \n\t\telse\n\t\t\ti915_gem_context_clear_bannable(ctx);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_RECOVERABLE:\n\t\tif (args->size)\n\t\t\tret = -EINVAL;\n\t\telse if (!args->value)\n\t\t\ti915_gem_context_clear_recoverable(ctx);\n\t\telse if (i915_gem_context_uses_protected_content(ctx))\n\t\t\tret = -EPERM;  \n\t\telse\n\t\t\ti915_gem_context_set_recoverable(ctx);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PRIORITY:\n\t\tret = set_priority(ctx, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_SSEU:\n\t\tret = set_sseu(ctx, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PERSISTENCE:\n\t\tret = set_persistence(ctx, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PROTECTED_CONTENT:\n\tcase I915_CONTEXT_PARAM_NO_ZEROMAP:\n\tcase I915_CONTEXT_PARAM_BAN_PERIOD:\n\tcase I915_CONTEXT_PARAM_RINGSIZE:\n\tcase I915_CONTEXT_PARAM_VM:\n\tcase I915_CONTEXT_PARAM_ENGINES:\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstruct create_ext {\n\tstruct i915_gem_proto_context *pc;\n\tstruct drm_i915_file_private *fpriv;\n};\n\nstatic int create_setparam(struct i915_user_extension __user *ext, void *data)\n{\n\tstruct drm_i915_gem_context_create_ext_setparam local;\n\tconst struct create_ext *arg = data;\n\n\tif (copy_from_user(&local, ext, sizeof(local)))\n\t\treturn -EFAULT;\n\n\tif (local.param.ctx_id)\n\t\treturn -EINVAL;\n\n\treturn set_proto_ctx_param(arg->fpriv, arg->pc, &local.param);\n}\n\nstatic int invalid_ext(struct i915_user_extension __user *ext, void *data)\n{\n\treturn -EINVAL;\n}\n\nstatic const i915_user_extension_fn create_extensions[] = {\n\t[I915_CONTEXT_CREATE_EXT_SETPARAM] = create_setparam,\n\t[I915_CONTEXT_CREATE_EXT_CLONE] = invalid_ext,\n};\n\nstatic bool client_is_banned(struct drm_i915_file_private *file_priv)\n{\n\treturn atomic_read(&file_priv->ban_score) >= I915_CLIENT_SCORE_BANNED;\n}\n\nstatic inline struct i915_gem_context *\n__context_lookup(struct drm_i915_file_private *file_priv, u32 id)\n{\n\tstruct i915_gem_context *ctx;\n\n\trcu_read_lock();\n\tctx = xa_load(&file_priv->context_xa, id);\n\tif (ctx && !kref_get_unless_zero(&ctx->ref))\n\t\tctx = NULL;\n\trcu_read_unlock();\n\n\treturn ctx;\n}\n\nstatic struct i915_gem_context *\nfinalize_create_context_locked(struct drm_i915_file_private *file_priv,\n\t\t\t       struct i915_gem_proto_context *pc, u32 id)\n{\n\tstruct i915_gem_context *ctx;\n\tvoid *old;\n\n\tlockdep_assert_held(&file_priv->proto_context_lock);\n\n\tctx = i915_gem_create_context(file_priv->i915, pc);\n\tif (IS_ERR(ctx))\n\t\treturn ctx;\n\n\t \n\ti915_gem_context_get(ctx);\n\n\tgem_context_register(ctx, file_priv, id);\n\n\told = xa_erase(&file_priv->proto_context_xa, id);\n\tGEM_BUG_ON(old != pc);\n\tproto_context_close(file_priv->i915, pc);\n\n\treturn ctx;\n}\n\nstruct i915_gem_context *\ni915_gem_context_lookup(struct drm_i915_file_private *file_priv, u32 id)\n{\n\tstruct i915_gem_proto_context *pc;\n\tstruct i915_gem_context *ctx;\n\n\tctx = __context_lookup(file_priv, id);\n\tif (ctx)\n\t\treturn ctx;\n\n\tmutex_lock(&file_priv->proto_context_lock);\n\t \n\tctx = __context_lookup(file_priv, id);\n\tif (!ctx) {\n\t\tpc = xa_load(&file_priv->proto_context_xa, id);\n\t\tif (!pc)\n\t\t\tctx = ERR_PTR(-ENOENT);\n\t\telse\n\t\t\tctx = finalize_create_context_locked(file_priv, pc, id);\n\t}\n\tmutex_unlock(&file_priv->proto_context_lock);\n\n\treturn ctx;\n}\n\nint i915_gem_context_create_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t  struct drm_file *file)\n{\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tstruct drm_i915_gem_context_create_ext *args = data;\n\tstruct create_ext ext_data;\n\tint ret;\n\tu32 id;\n\n\tif (!DRIVER_CAPS(i915)->has_logical_contexts)\n\t\treturn -ENODEV;\n\n\tif (args->flags & I915_CONTEXT_CREATE_FLAGS_UNKNOWN)\n\t\treturn -EINVAL;\n\n\tret = intel_gt_terminally_wedged(to_gt(i915));\n\tif (ret)\n\t\treturn ret;\n\n\text_data.fpriv = file->driver_priv;\n\tif (client_is_banned(ext_data.fpriv)) {\n\t\tdrm_dbg(&i915->drm,\n\t\t\t\"client %s[%d] banned from creating ctx\\n\",\n\t\t\tcurrent->comm, task_pid_nr(current));\n\t\treturn -EIO;\n\t}\n\n\text_data.pc = proto_context_create(i915, args->flags);\n\tif (IS_ERR(ext_data.pc))\n\t\treturn PTR_ERR(ext_data.pc);\n\n\tif (args->flags & I915_CONTEXT_CREATE_FLAGS_USE_EXTENSIONS) {\n\t\tret = i915_user_extensions(u64_to_user_ptr(args->extensions),\n\t\t\t\t\t   create_extensions,\n\t\t\t\t\t   ARRAY_SIZE(create_extensions),\n\t\t\t\t\t   &ext_data);\n\t\tif (ret)\n\t\t\tgoto err_pc;\n\t}\n\n\tif (GRAPHICS_VER(i915) > 12) {\n\t\tstruct i915_gem_context *ctx;\n\n\t\t \n\t\tret = xa_alloc(&ext_data.fpriv->context_xa, &id, NULL,\n\t\t\t       xa_limit_32b, GFP_KERNEL);\n\t\tif (ret)\n\t\t\tgoto err_pc;\n\n\t\tctx = i915_gem_create_context(i915, ext_data.pc);\n\t\tif (IS_ERR(ctx)) {\n\t\t\tret = PTR_ERR(ctx);\n\t\t\tgoto err_pc;\n\t\t}\n\n\t\tproto_context_close(i915, ext_data.pc);\n\t\tgem_context_register(ctx, ext_data.fpriv, id);\n\t} else {\n\t\tret = proto_context_register(ext_data.fpriv, ext_data.pc, &id);\n\t\tif (ret < 0)\n\t\t\tgoto err_pc;\n\t}\n\n\targs->ctx_id = id;\n\n\treturn 0;\n\nerr_pc:\n\tproto_context_close(i915, ext_data.pc);\n\treturn ret;\n}\n\nint i915_gem_context_destroy_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t   struct drm_file *file)\n{\n\tstruct drm_i915_gem_context_destroy *args = data;\n\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\tstruct i915_gem_proto_context *pc;\n\tstruct i915_gem_context *ctx;\n\n\tif (args->pad != 0)\n\t\treturn -EINVAL;\n\n\tif (!args->ctx_id)\n\t\treturn -ENOENT;\n\n\t \n\tmutex_lock(&file_priv->proto_context_lock);\n\tctx = xa_erase(&file_priv->context_xa, args->ctx_id);\n\tpc = xa_erase(&file_priv->proto_context_xa, args->ctx_id);\n\tmutex_unlock(&file_priv->proto_context_lock);\n\n\tif (!ctx && !pc)\n\t\treturn -ENOENT;\n\tGEM_WARN_ON(ctx && pc);\n\n\tif (pc)\n\t\tproto_context_close(file_priv->i915, pc);\n\n\tif (ctx)\n\t\tcontext_close(ctx);\n\n\treturn 0;\n}\n\nstatic int get_sseu(struct i915_gem_context *ctx,\n\t\t    struct drm_i915_gem_context_param *args)\n{\n\tstruct drm_i915_gem_context_param_sseu user_sseu;\n\tstruct intel_context *ce;\n\tunsigned long lookup;\n\tint err;\n\n\tif (args->size == 0)\n\t\tgoto out;\n\telse if (args->size < sizeof(user_sseu))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&user_sseu, u64_to_user_ptr(args->value),\n\t\t\t   sizeof(user_sseu)))\n\t\treturn -EFAULT;\n\n\tif (user_sseu.rsvd)\n\t\treturn -EINVAL;\n\n\tif (user_sseu.flags & ~(I915_CONTEXT_SSEU_FLAG_ENGINE_INDEX))\n\t\treturn -EINVAL;\n\n\tlookup = 0;\n\tif (user_sseu.flags & I915_CONTEXT_SSEU_FLAG_ENGINE_INDEX)\n\t\tlookup |= LOOKUP_USER_INDEX;\n\n\tce = lookup_user_engine(ctx, lookup, &user_sseu.engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\terr = intel_context_lock_pinned(ce);  \n\tif (err) {\n\t\tintel_context_put(ce);\n\t\treturn err;\n\t}\n\n\tuser_sseu.slice_mask = ce->sseu.slice_mask;\n\tuser_sseu.subslice_mask = ce->sseu.subslice_mask;\n\tuser_sseu.min_eus_per_subslice = ce->sseu.min_eus_per_subslice;\n\tuser_sseu.max_eus_per_subslice = ce->sseu.max_eus_per_subslice;\n\n\tintel_context_unlock_pinned(ce);\n\tintel_context_put(ce);\n\n\tif (copy_to_user(u64_to_user_ptr(args->value), &user_sseu,\n\t\t\t sizeof(user_sseu)))\n\t\treturn -EFAULT;\n\nout:\n\targs->size = sizeof(user_sseu);\n\n\treturn 0;\n}\n\nint i915_gem_context_getparam_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t    struct drm_file *file)\n{\n\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\tstruct drm_i915_gem_context_param *args = data;\n\tstruct i915_gem_context *ctx;\n\tstruct i915_address_space *vm;\n\tint ret = 0;\n\n\tctx = i915_gem_context_lookup(file_priv, args->ctx_id);\n\tif (IS_ERR(ctx))\n\t\treturn PTR_ERR(ctx);\n\n\tswitch (args->param) {\n\tcase I915_CONTEXT_PARAM_GTT_SIZE:\n\t\targs->size = 0;\n\t\tvm = i915_gem_context_get_eb_vm(ctx);\n\t\targs->value = vm->total;\n\t\ti915_vm_put(vm);\n\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_NO_ERROR_CAPTURE:\n\t\targs->size = 0;\n\t\targs->value = i915_gem_context_no_error_capture(ctx);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_BANNABLE:\n\t\targs->size = 0;\n\t\targs->value = i915_gem_context_is_bannable(ctx);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_RECOVERABLE:\n\t\targs->size = 0;\n\t\targs->value = i915_gem_context_is_recoverable(ctx);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PRIORITY:\n\t\targs->size = 0;\n\t\targs->value = ctx->sched.priority;\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_SSEU:\n\t\tret = get_sseu(ctx, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_VM:\n\t\tret = get_ppgtt(file_priv, ctx, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PERSISTENCE:\n\t\targs->size = 0;\n\t\targs->value = i915_gem_context_is_persistent(ctx);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_PROTECTED_CONTENT:\n\t\tret = get_protected(ctx, args);\n\t\tbreak;\n\n\tcase I915_CONTEXT_PARAM_NO_ZEROMAP:\n\tcase I915_CONTEXT_PARAM_BAN_PERIOD:\n\tcase I915_CONTEXT_PARAM_ENGINES:\n\tcase I915_CONTEXT_PARAM_RINGSIZE:\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\ti915_gem_context_put(ctx);\n\treturn ret;\n}\n\nint i915_gem_context_setparam_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t    struct drm_file *file)\n{\n\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\tstruct drm_i915_gem_context_param *args = data;\n\tstruct i915_gem_proto_context *pc;\n\tstruct i915_gem_context *ctx;\n\tint ret = 0;\n\n\tmutex_lock(&file_priv->proto_context_lock);\n\tctx = __context_lookup(file_priv, args->ctx_id);\n\tif (!ctx) {\n\t\tpc = xa_load(&file_priv->proto_context_xa, args->ctx_id);\n\t\tif (pc) {\n\t\t\t \n\t\t\tWARN_ON(GRAPHICS_VER(file_priv->i915) > 12);\n\t\t\tret = set_proto_ctx_param(file_priv, pc, args);\n\t\t} else {\n\t\t\tret = -ENOENT;\n\t\t}\n\t}\n\tmutex_unlock(&file_priv->proto_context_lock);\n\n\tif (ctx) {\n\t\tret = ctx_setparam(file_priv, ctx, args);\n\t\ti915_gem_context_put(ctx);\n\t}\n\n\treturn ret;\n}\n\nint i915_gem_context_reset_stats_ioctl(struct drm_device *dev,\n\t\t\t\t       void *data, struct drm_file *file)\n{\n\tstruct drm_i915_private *i915 = to_i915(dev);\n\tstruct drm_i915_reset_stats *args = data;\n\tstruct i915_gem_context *ctx;\n\n\tif (args->flags || args->pad)\n\t\treturn -EINVAL;\n\n\tctx = i915_gem_context_lookup(file->driver_priv, args->ctx_id);\n\tif (IS_ERR(ctx))\n\t\treturn PTR_ERR(ctx);\n\n\t \n\n\tif (capable(CAP_SYS_ADMIN))\n\t\targs->reset_count = i915_reset_count(&i915->gpu_error);\n\telse\n\t\targs->reset_count = 0;\n\n\targs->batch_active = atomic_read(&ctx->guilty_count);\n\targs->batch_pending = atomic_read(&ctx->active_count);\n\n\ti915_gem_context_put(ctx);\n\treturn 0;\n}\n\n \nstruct intel_context *\ni915_gem_engines_iter_next(struct i915_gem_engines_iter *it)\n{\n\tconst struct i915_gem_engines *e = it->engines;\n\tstruct intel_context *ctx;\n\n\tif (unlikely(!e))\n\t\treturn NULL;\n\n\tdo {\n\t\tif (it->idx >= e->num_engines)\n\t\t\treturn NULL;\n\n\t\tctx = e->engines[it->idx++];\n\t} while (!ctx);\n\n\treturn ctx;\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_SELFTEST)\n#include \"selftests/mock_context.c\"\n#include \"selftests/i915_gem_context.c\"\n#endif\n\nvoid i915_gem_context_module_exit(void)\n{\n\tkmem_cache_destroy(slab_luts);\n}\n\nint __init i915_gem_context_module_init(void)\n{\n\tslab_luts = KMEM_CACHE(i915_lut_handle, 0);\n\tif (!slab_luts)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}