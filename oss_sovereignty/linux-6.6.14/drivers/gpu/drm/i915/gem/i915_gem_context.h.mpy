{
  "module_name": "i915_gem_context.h",
  "hash_id": "7c50342bbd663532bb63760bce9b0eeb5293b2ee6ab8d7c985cf1623e29cabdd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gem/i915_gem_context.h",
  "human_readable_source": " \n\n#ifndef __I915_GEM_CONTEXT_H__\n#define __I915_GEM_CONTEXT_H__\n\n#include \"i915_gem_context_types.h\"\n\n#include \"gt/intel_context.h\"\n\n#include \"i915_drv.h\"\n#include \"i915_gem.h\"\n#include \"i915_scheduler.h\"\n#include \"intel_device_info.h\"\n\nstruct drm_device;\nstruct drm_file;\n\nstatic inline bool i915_gem_context_is_closed(const struct i915_gem_context *ctx)\n{\n\treturn test_bit(CONTEXT_CLOSED, &ctx->flags);\n}\n\nstatic inline void i915_gem_context_set_closed(struct i915_gem_context *ctx)\n{\n\tGEM_BUG_ON(i915_gem_context_is_closed(ctx));\n\tset_bit(CONTEXT_CLOSED, &ctx->flags);\n}\n\nstatic inline bool i915_gem_context_no_error_capture(const struct i915_gem_context *ctx)\n{\n\treturn test_bit(UCONTEXT_NO_ERROR_CAPTURE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_set_no_error_capture(struct i915_gem_context *ctx)\n{\n\tset_bit(UCONTEXT_NO_ERROR_CAPTURE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_clear_no_error_capture(struct i915_gem_context *ctx)\n{\n\tclear_bit(UCONTEXT_NO_ERROR_CAPTURE, &ctx->user_flags);\n}\n\nstatic inline bool i915_gem_context_is_bannable(const struct i915_gem_context *ctx)\n{\n\treturn test_bit(UCONTEXT_BANNABLE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_set_bannable(struct i915_gem_context *ctx)\n{\n\tset_bit(UCONTEXT_BANNABLE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_clear_bannable(struct i915_gem_context *ctx)\n{\n\tclear_bit(UCONTEXT_BANNABLE, &ctx->user_flags);\n}\n\nstatic inline bool i915_gem_context_is_recoverable(const struct i915_gem_context *ctx)\n{\n\treturn test_bit(UCONTEXT_RECOVERABLE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_set_recoverable(struct i915_gem_context *ctx)\n{\n\tset_bit(UCONTEXT_RECOVERABLE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_clear_recoverable(struct i915_gem_context *ctx)\n{\n\tclear_bit(UCONTEXT_RECOVERABLE, &ctx->user_flags);\n}\n\nstatic inline bool i915_gem_context_is_persistent(const struct i915_gem_context *ctx)\n{\n\treturn test_bit(UCONTEXT_PERSISTENCE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_set_persistence(struct i915_gem_context *ctx)\n{\n\tset_bit(UCONTEXT_PERSISTENCE, &ctx->user_flags);\n}\n\nstatic inline void i915_gem_context_clear_persistence(struct i915_gem_context *ctx)\n{\n\tclear_bit(UCONTEXT_PERSISTENCE, &ctx->user_flags);\n}\n\nstatic inline bool\ni915_gem_context_user_engines(const struct i915_gem_context *ctx)\n{\n\treturn test_bit(CONTEXT_USER_ENGINES, &ctx->flags);\n}\n\nstatic inline void\ni915_gem_context_set_user_engines(struct i915_gem_context *ctx)\n{\n\tset_bit(CONTEXT_USER_ENGINES, &ctx->flags);\n}\n\nstatic inline void\ni915_gem_context_clear_user_engines(struct i915_gem_context *ctx)\n{\n\tclear_bit(CONTEXT_USER_ENGINES, &ctx->flags);\n}\n\nstatic inline bool\ni915_gem_context_uses_protected_content(const struct i915_gem_context *ctx)\n{\n\treturn ctx->uses_protected_content;\n}\n\n \nvoid i915_gem_init__contexts(struct drm_i915_private *i915);\n\nint i915_gem_context_open(struct drm_i915_private *i915,\n\t\t\t  struct drm_file *file);\nvoid i915_gem_context_close(struct drm_file *file);\n\nvoid i915_gem_context_release(struct kref *ctx_ref);\n\nint i915_gem_vm_create_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file);\nint i915_gem_vm_destroy_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *file);\n\nint i915_gem_context_create_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t  struct drm_file *file);\nint i915_gem_context_destroy_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t   struct drm_file *file);\nint i915_gem_context_getparam_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t    struct drm_file *file_priv);\nint i915_gem_context_setparam_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t    struct drm_file *file_priv);\nint i915_gem_context_reset_stats_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t       struct drm_file *file);\n\nstruct i915_gem_context *\ni915_gem_context_lookup(struct drm_i915_file_private *file_priv, u32 id);\n\nstatic inline struct i915_gem_context *\ni915_gem_context_get(struct i915_gem_context *ctx)\n{\n\tkref_get(&ctx->ref);\n\treturn ctx;\n}\n\nstatic inline void i915_gem_context_put(struct i915_gem_context *ctx)\n{\n\tkref_put(&ctx->ref, i915_gem_context_release);\n}\n\nstatic inline struct i915_address_space *\ni915_gem_context_vm(struct i915_gem_context *ctx)\n{\n\treturn rcu_dereference_protected(ctx->vm, lockdep_is_held(&ctx->mutex));\n}\n\nstatic inline bool i915_gem_context_has_full_ppgtt(struct i915_gem_context *ctx)\n{\n\tGEM_BUG_ON(!!ctx->vm != HAS_FULL_PPGTT(ctx->i915));\n\n\treturn !!ctx->vm;\n}\n\nstatic inline struct i915_address_space *\ni915_gem_context_get_eb_vm(struct i915_gem_context *ctx)\n{\n\tstruct i915_address_space *vm;\n\n\tvm = ctx->vm;\n\tif (!vm)\n\t\tvm = &to_gt(ctx->i915)->ggtt->vm;\n\tvm = i915_vm_get(vm);\n\n\treturn vm;\n}\n\nstatic inline struct i915_gem_engines *\ni915_gem_context_engines(struct i915_gem_context *ctx)\n{\n\treturn rcu_dereference_protected(ctx->engines,\n\t\t\t\t\t lockdep_is_held(&ctx->engines_mutex));\n}\n\nstatic inline struct i915_gem_engines *\ni915_gem_context_lock_engines(struct i915_gem_context *ctx)\n\t__acquires(&ctx->engines_mutex)\n{\n\tmutex_lock(&ctx->engines_mutex);\n\treturn i915_gem_context_engines(ctx);\n}\n\nstatic inline void\ni915_gem_context_unlock_engines(struct i915_gem_context *ctx)\n\t__releases(&ctx->engines_mutex)\n{\n\tmutex_unlock(&ctx->engines_mutex);\n}\n\nstatic inline struct intel_context *\ni915_gem_context_get_engine(struct i915_gem_context *ctx, unsigned int idx)\n{\n\tstruct intel_context *ce;\n\n\trcu_read_lock(); {\n\t\tstruct i915_gem_engines *e = rcu_dereference(ctx->engines);\n\t\tif (unlikely(!e))  \n\t\t\tce = ERR_PTR(-ENOENT);\n\t\telse if (likely(idx < e->num_engines && e->engines[idx]))\n\t\t\tce = intel_context_get(e->engines[idx]);\n\t\telse\n\t\t\tce = ERR_PTR(-EINVAL);\n\t} rcu_read_unlock();\n\n\treturn ce;\n}\n\nstatic inline void\ni915_gem_engines_iter_init(struct i915_gem_engines_iter *it,\n\t\t\t   struct i915_gem_engines *engines)\n{\n\tit->engines = engines;\n\tit->idx = 0;\n}\n\nstruct intel_context *\ni915_gem_engines_iter_next(struct i915_gem_engines_iter *it);\n\n#define for_each_gem_engine(ce, engines, it) \\\n\tfor (i915_gem_engines_iter_init(&(it), (engines)); \\\n\t     ((ce) = i915_gem_engines_iter_next(&(it)));)\n\nvoid i915_gem_context_module_exit(void);\nint i915_gem_context_module_init(void);\n\nstruct i915_lut_handle *i915_lut_handle_alloc(void);\nvoid i915_lut_handle_free(struct i915_lut_handle *lut);\n\nint i915_gem_user_to_context_sseu(struct intel_gt *gt,\n\t\t\t\t  const struct drm_i915_gem_context_param_sseu *user,\n\t\t\t\t  struct intel_sseu *context);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}