{
  "module_name": "Kconfig.profile",
  "hash_id": "aa9d89d814dcb87030a4ffaf46ad197281f5e11a4205f344854c1b7c48fa2c97",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/Kconfig.profile",
  "human_readable_source": "config DRM_I915_REQUEST_TIMEOUT\n\tint \"Default timeout for requests (ms)\"\n\tdefault 20000 # milliseconds\n\thelp\n\t  Configures the default timeout after which any user submissions will\n\t  be forcefully terminated.\n\n\t  Beware setting this value lower, or close to heartbeat interval\n\t  rounded to whole seconds times three, in order to avoid allowing\n\t  misbehaving applications causing total rendering failure in unrelated\n\t  clients.\n\n\t  May be 0 to disable the timeout.\n\nconfig DRM_I915_FENCE_TIMEOUT\n\tint \"Timeout for unsignaled foreign fences (ms, jiffy granularity)\"\n\tdefault 10000 # milliseconds\n\thelp\n\t  When listening to a foreign fence, we install a supplementary timer\n\t  to ensure that we are always signaled and our userspace is able to\n\t  make forward progress. This value specifies the timeout used for an\n\t  unsignaled foreign fence.\n\n\t  May be 0 to disable the timeout, and rely on the foreign fence being\n\t  eventually signaled.\n\nconfig DRM_I915_USERFAULT_AUTOSUSPEND\n\tint \"Runtime autosuspend delay for userspace GGTT mmaps (ms)\"\n\tdefault 250 # milliseconds\n\thelp\n\t  On runtime suspend, as we suspend the device, we have to revoke\n\t  userspace GGTT mmaps and force userspace to take a pagefault on\n\t  their next access. The revocation and subsequent recreation of\n\t  the GGTT mmap can be very slow and so we impose a small hysteris\n\t  that complements the runtime-pm autosuspend and provides a lower\n\t  floor on the autosuspend delay.\n\n\t  May be 0 to disable the extra delay and solely use the device level\n\t  runtime pm autosuspend delay tunable.\n\nconfig DRM_I915_HEARTBEAT_INTERVAL\n\tint \"Interval between heartbeat pulses (ms)\"\n\tdefault 2500 # milliseconds\n\thelp\n\t  The driver sends a periodic heartbeat down all active engines to\n\t  check the health of the GPU and undertake regular house-keeping of\n\t  internal driver state.\n\n\t  This is adjustable via\n\t  /sys/class/drm/card?/engine/*/heartbeat_interval_ms\n\n\t  May be 0 to disable heartbeats and therefore disable automatic GPU\n\t  hang detection.\n\nconfig DRM_I915_PREEMPT_TIMEOUT\n\tint \"Preempt timeout (ms, jiffy granularity)\"\n\tdefault 640 # milliseconds\n\thelp\n\t  How long to wait (in milliseconds) for a preemption event to occur\n\t  when submitting a new context. If the current context does not hit\n\t  an arbitration point and yield to HW before the timer expires, the\n\t  HW will be reset to allow the more important context to execute.\n\n\t  This is adjustable via\n\t  /sys/class/drm/card?/engine/*/preempt_timeout_ms\n\n\t  May be 0 to disable the timeout.\n\n\t  The compiled in default may get overridden at driver probe time on\n\t  certain platforms and certain engines which will be reflected in the\n\t  sysfs control.\n\nconfig DRM_I915_PREEMPT_TIMEOUT_COMPUTE\n\tint \"Preempt timeout for compute engines (ms, jiffy granularity)\"\n\tdefault 7500 # milliseconds\n\thelp\n\t  How long to wait (in milliseconds) for a preemption event to occur\n\t  when submitting a new context to a compute capable engine. If the\n\t  current context does not hit an arbitration point and yield to HW\n\t  before the timer expires, the HW will be reset to allow the more\n\t  important context to execute.\n\n\t  This is adjustable via\n\t  /sys/class/drm/card?/engine/*/preempt_timeout_ms\n\n\t  May be 0 to disable the timeout.\n\n\t  The compiled in default may get overridden at driver probe time on\n\t  certain platforms and certain engines which will be reflected in the\n\t  sysfs control.\n\nconfig DRM_I915_MAX_REQUEST_BUSYWAIT\n\tint \"Busywait for request completion limit (ns)\"\n\tdefault 8000 # nanoseconds\n\thelp\n\t  Before sleeping waiting for a request (GPU operation) to complete,\n\t  we may spend some time polling for its completion. As the IRQ may\n\t  take a non-negligible time to setup, we do a short spin first to\n\t  check if the request will complete in the time it would have taken\n\t  us to enable the interrupt.\n\n\t  This is adjustable via\n\t  /sys/class/drm/card?/engine/*/max_busywait_duration_ns\n\n\t  May be 0 to disable the initial spin. In practice, we estimate\n\t  the cost of enabling the interrupt (if currently disabled) to be\n\t  a few microseconds.\n\nconfig DRM_I915_STOP_TIMEOUT\n\tint \"How long to wait for an engine to quiesce gracefully before reset (ms)\"\n\tdefault 100 # milliseconds\n\thelp\n\t  By stopping submission and sleeping for a short time before resetting\n\t  the GPU, we allow the innocent contexts also on the system to quiesce.\n\t  It is then less likely for a hanging context to cause collateral\n\t  damage as the system is reset in order to recover. The corollary is\n\t  that the reset itself may take longer and so be more disruptive to\n\t  interactive or low latency workloads.\n\n\t  This is adjustable via\n\t  /sys/class/drm/card?/engine/*/stop_timeout_ms\n\nconfig DRM_I915_TIMESLICE_DURATION\n\tint \"Scheduling quantum for userspace batches (ms, jiffy granularity)\"\n\tdefault 1 # milliseconds\n\thelp\n\t  When two user batches of equal priority are executing, we will\n\t  alternate execution of each batch to ensure forward progress of\n\t  all users. This is necessary in some cases where there may be\n\t  an implicit dependency between those batches that requires\n\t  concurrent execution in order for them to proceed, e.g. they\n\t  interact with each other via userspace semaphores. Each context\n\t  is scheduled for execution for the timeslice duration, before\n\t  switching to the next context.\n\n\t  This is adjustable via\n\t  /sys/class/drm/card?/engine/*/timeslice_duration_ms\n\n\t  May be 0 to disable timeslicing.\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}