{
  "module_name": "intel_pxp.c",
  "hash_id": "15f0ba7a7a062e67e4773b9522f8d05d65df210be2573fc5dfe9a095a3fa0e3e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/pxp/intel_pxp.c",
  "human_readable_source": "\n \n#include <linux/workqueue.h>\n\n#include \"gem/i915_gem_context.h\"\n\n#include \"gt/intel_context.h\"\n#include \"gt/intel_gt.h\"\n\n#include \"i915_drv.h\"\n\n#include \"intel_pxp.h\"\n#include \"intel_pxp_gsccs.h\"\n#include \"intel_pxp_irq.h\"\n#include \"intel_pxp_regs.h\"\n#include \"intel_pxp_session.h\"\n#include \"intel_pxp_tee.h\"\n#include \"intel_pxp_types.h\"\n\n \n\nbool intel_pxp_is_supported(const struct intel_pxp *pxp)\n{\n\treturn IS_ENABLED(CONFIG_DRM_I915_PXP) && pxp;\n}\n\nbool intel_pxp_is_enabled(const struct intel_pxp *pxp)\n{\n\treturn IS_ENABLED(CONFIG_DRM_I915_PXP) && pxp && pxp->ce;\n}\n\nbool intel_pxp_is_active(const struct intel_pxp *pxp)\n{\n\treturn IS_ENABLED(CONFIG_DRM_I915_PXP) && pxp && pxp->arb_is_valid;\n}\n\nstatic void kcr_pxp_set_status(const struct intel_pxp *pxp, bool enable)\n{\n\tu32 val = enable ? _MASKED_BIT_ENABLE(KCR_INIT_ALLOW_DISPLAY_ME_WRITES) :\n\t\t  _MASKED_BIT_DISABLE(KCR_INIT_ALLOW_DISPLAY_ME_WRITES);\n\n\tintel_uncore_write(pxp->ctrl_gt->uncore, KCR_INIT(pxp->kcr_base), val);\n}\n\nstatic void kcr_pxp_enable(const struct intel_pxp *pxp)\n{\n\tkcr_pxp_set_status(pxp, true);\n}\n\nstatic void kcr_pxp_disable(const struct intel_pxp *pxp)\n{\n\tkcr_pxp_set_status(pxp, false);\n}\n\nstatic int create_vcs_context(struct intel_pxp *pxp)\n{\n\tstatic struct lock_class_key pxp_lock;\n\tstruct intel_gt *gt = pxp->ctrl_gt;\n\tstruct intel_engine_cs *engine;\n\tstruct intel_context *ce;\n\tint i;\n\n\t \n\tfor (i = 0, engine = NULL; !engine; i++)\n\t\tengine = gt->engine_class[VIDEO_DECODE_CLASS][i];\n\n\tGEM_BUG_ON(!engine || engine->class != VIDEO_DECODE_CLASS);\n\n\tce = intel_engine_create_pinned_context(engine, engine->gt->vm, SZ_4K,\n\t\t\t\t\t\tI915_GEM_HWS_PXP_ADDR,\n\t\t\t\t\t\t&pxp_lock, \"pxp_context\");\n\tif (IS_ERR(ce)) {\n\t\tdrm_err(&gt->i915->drm, \"failed to create VCS ctx for PXP\\n\");\n\t\treturn PTR_ERR(ce);\n\t}\n\n\tpxp->ce = ce;\n\n\treturn 0;\n}\n\nstatic void destroy_vcs_context(struct intel_pxp *pxp)\n{\n\tif (pxp->ce)\n\t\tintel_engine_destroy_pinned_context(fetch_and_zero(&pxp->ce));\n}\n\nstatic void pxp_init_full(struct intel_pxp *pxp)\n{\n\tstruct intel_gt *gt = pxp->ctrl_gt;\n\tint ret;\n\n\t \n\tinit_completion(&pxp->termination);\n\tcomplete_all(&pxp->termination);\n\n\tif (pxp->ctrl_gt->type == GT_MEDIA)\n\t\tpxp->kcr_base = MTL_KCR_BASE;\n\telse\n\t\tpxp->kcr_base = GEN12_KCR_BASE;\n\n\tintel_pxp_session_management_init(pxp);\n\n\tret = create_vcs_context(pxp);\n\tif (ret)\n\t\treturn;\n\n\tif (HAS_ENGINE(pxp->ctrl_gt, GSC0))\n\t\tret = intel_pxp_gsccs_init(pxp);\n\telse\n\t\tret = intel_pxp_tee_component_init(pxp);\n\tif (ret)\n\t\tgoto out_context;\n\n\tdrm_info(&gt->i915->drm, \"Protected Xe Path (PXP) protected content support initialized\\n\");\n\n\treturn;\n\nout_context:\n\tdestroy_vcs_context(pxp);\n}\n\nstatic struct intel_gt *find_gt_for_required_teelink(struct drm_i915_private *i915)\n{\n\t \n\tif (IS_ENABLED(CONFIG_INTEL_MEI_PXP) && IS_ENABLED(CONFIG_INTEL_MEI_GSC) &&\n\t    intel_huc_is_loaded_by_gsc(&to_gt(i915)->uc.huc) && intel_uc_uses_huc(&to_gt(i915)->uc))\n\t\treturn to_gt(i915);\n\n\treturn NULL;\n}\n\nstatic struct intel_gt *find_gt_for_required_protected_content(struct drm_i915_private *i915)\n{\n\tif (!IS_ENABLED(CONFIG_DRM_I915_PXP) || !INTEL_INFO(i915)->has_pxp)\n\t\treturn NULL;\n\n\t \n\tif (i915->media_gt && HAS_ENGINE(i915->media_gt, GSC0) &&\n\t    intel_uc_fw_is_loadable(&i915->media_gt->uc.gsc.fw) &&\n\t    intel_uc_fw_is_loadable(&i915->media_gt->uc.huc.fw))\n\t\treturn i915->media_gt;\n\n\t \n\tif (IS_ENABLED(CONFIG_INTEL_MEI_PXP) && !i915->media_gt && VDBOX_MASK(to_gt(i915)))\n\t\treturn to_gt(i915);\n\n\treturn NULL;\n}\n\nint intel_pxp_init(struct drm_i915_private *i915)\n{\n\tstruct intel_gt *gt;\n\tbool is_full_feature = false;\n\n\t \n\tgt = find_gt_for_required_protected_content(i915);\n\tif (gt)\n\t\tis_full_feature = true;\n\telse\n\t\tgt = find_gt_for_required_teelink(i915);\n\n\tif (!gt)\n\t\treturn -ENODEV;\n\n\t \n\ti915->pxp = kzalloc(sizeof(*i915->pxp), GFP_KERNEL);\n\tif (!i915->pxp)\n\t\treturn -ENOMEM;\n\n\t \n\ti915->pxp->ctrl_gt = gt;\n\tmutex_init(&i915->pxp->tee_mutex);\n\n\t \n\tif (is_full_feature)\n\t\tpxp_init_full(i915->pxp);\n\telse\n\t\tintel_pxp_tee_component_init(i915->pxp);\n\n\treturn 0;\n}\n\nvoid intel_pxp_fini(struct drm_i915_private *i915)\n{\n\tif (!i915->pxp)\n\t\treturn;\n\n\ti915->pxp->arb_is_valid = false;\n\n\tif (HAS_ENGINE(i915->pxp->ctrl_gt, GSC0))\n\t\tintel_pxp_gsccs_fini(i915->pxp);\n\telse\n\t\tintel_pxp_tee_component_fini(i915->pxp);\n\n\tdestroy_vcs_context(i915->pxp);\n\n\tkfree(i915->pxp);\n\ti915->pxp = NULL;\n}\n\nvoid intel_pxp_mark_termination_in_progress(struct intel_pxp *pxp)\n{\n\tpxp->arb_is_valid = false;\n\treinit_completion(&pxp->termination);\n}\n\nstatic void pxp_queue_termination(struct intel_pxp *pxp)\n{\n\tstruct intel_gt *gt = pxp->ctrl_gt;\n\n\t \n\tspin_lock_irq(gt->irq_lock);\n\tintel_pxp_mark_termination_in_progress(pxp);\n\tpxp->session_events |= PXP_TERMINATION_REQUEST;\n\tqueue_work(system_unbound_wq, &pxp->session_work);\n\tspin_unlock_irq(gt->irq_lock);\n}\n\nstatic bool pxp_component_bound(struct intel_pxp *pxp)\n{\n\tbool bound = false;\n\n\tmutex_lock(&pxp->tee_mutex);\n\tif (pxp->pxp_component)\n\t\tbound = true;\n\tmutex_unlock(&pxp->tee_mutex);\n\n\treturn bound;\n}\n\nint intel_pxp_get_backend_timeout_ms(struct intel_pxp *pxp)\n{\n\tif (HAS_ENGINE(pxp->ctrl_gt, GSC0))\n\t\treturn GSCFW_MAX_ROUND_TRIP_LATENCY_MS;\n\telse\n\t\treturn 250;\n}\n\nstatic int __pxp_global_teardown_final(struct intel_pxp *pxp)\n{\n\tint timeout;\n\n\tif (!pxp->arb_is_valid)\n\t\treturn 0;\n\t \n\tintel_pxp_mark_termination_in_progress(pxp);\n\tintel_pxp_terminate(pxp, false);\n\n\ttimeout = intel_pxp_get_backend_timeout_ms(pxp);\n\n\tif (!wait_for_completion_timeout(&pxp->termination, msecs_to_jiffies(timeout)))\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nstatic int __pxp_global_teardown_restart(struct intel_pxp *pxp)\n{\n\tint timeout;\n\n\tif (pxp->arb_is_valid)\n\t\treturn 0;\n\t \n\tpxp_queue_termination(pxp);\n\n\ttimeout = intel_pxp_get_backend_timeout_ms(pxp);\n\n\tif (!wait_for_completion_timeout(&pxp->termination, msecs_to_jiffies(timeout)))\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nvoid intel_pxp_end(struct intel_pxp *pxp)\n{\n\tstruct drm_i915_private *i915 = pxp->ctrl_gt->i915;\n\tintel_wakeref_t wakeref;\n\n\tif (!intel_pxp_is_enabled(pxp))\n\t\treturn;\n\n\twakeref = intel_runtime_pm_get(&i915->runtime_pm);\n\n\tmutex_lock(&pxp->arb_mutex);\n\n\tif (__pxp_global_teardown_final(pxp))\n\t\tdrm_dbg(&i915->drm, \"PXP end timed out\\n\");\n\n\tmutex_unlock(&pxp->arb_mutex);\n\n\tintel_pxp_fini_hw(pxp);\n\tintel_runtime_pm_put(&i915->runtime_pm, wakeref);\n}\n\n \nint intel_pxp_get_readiness_status(struct intel_pxp *pxp)\n{\n\tif (!intel_pxp_is_enabled(pxp))\n\t\treturn -ENODEV;\n\n\tif (HAS_ENGINE(pxp->ctrl_gt, GSC0)) {\n\t\tif (wait_for(intel_pxp_gsccs_is_ready_for_sessions(pxp), 250))\n\t\t\treturn 2;\n\t} else {\n\t\tif (wait_for(pxp_component_bound(pxp), 250))\n\t\t\treturn 2;\n\t}\n\treturn 1;\n}\n\n \nint intel_pxp_start(struct intel_pxp *pxp)\n{\n\tint ret = 0;\n\n\tret = intel_pxp_get_readiness_status(pxp);\n\tif (ret < 0)\n\t\treturn ret;\n\telse if (ret > 1)\n\t\treturn -EIO;  \n\n\tmutex_lock(&pxp->arb_mutex);\n\n\tret = __pxp_global_teardown_restart(pxp);\n\tif (ret)\n\t\tgoto unlock;\n\n\t \n\tbarrier();\n\n\tif (!pxp->arb_is_valid)\n\t\tret = -EIO;\n\nunlock:\n\tmutex_unlock(&pxp->arb_mutex);\n\treturn ret;\n}\n\nvoid intel_pxp_init_hw(struct intel_pxp *pxp)\n{\n\tkcr_pxp_enable(pxp);\n\tintel_pxp_irq_enable(pxp);\n}\n\nvoid intel_pxp_fini_hw(struct intel_pxp *pxp)\n{\n\tkcr_pxp_disable(pxp);\n\tintel_pxp_irq_disable(pxp);\n}\n\nint intel_pxp_key_check(struct intel_pxp *pxp,\n\t\t\tstruct drm_i915_gem_object *obj,\n\t\t\tbool assign)\n{\n\tif (!intel_pxp_is_active(pxp))\n\t\treturn -ENODEV;\n\n\tif (!i915_gem_object_is_protected(obj))\n\t\treturn -EINVAL;\n\n\tGEM_BUG_ON(!pxp->key_instance);\n\n\t \n\tif (!obj->pxp_key_instance && assign)\n\t\tobj->pxp_key_instance = pxp->key_instance;\n\n\tif (obj->pxp_key_instance != pxp->key_instance)\n\t\treturn -ENOEXEC;\n\n\treturn 0;\n}\n\nvoid intel_pxp_invalidate(struct intel_pxp *pxp)\n{\n\tstruct drm_i915_private *i915 = pxp->ctrl_gt->i915;\n\tstruct i915_gem_context *ctx, *cn;\n\n\t \n\tspin_lock_irq(&i915->gem.contexts.lock);\n\tlist_for_each_entry_safe(ctx, cn, &i915->gem.contexts.list, link) {\n\t\tstruct i915_gem_engines_iter it;\n\t\tstruct intel_context *ce;\n\n\t\tif (!kref_get_unless_zero(&ctx->ref))\n\t\t\tcontinue;\n\n\t\tif (likely(!i915_gem_context_uses_protected_content(ctx))) {\n\t\t\ti915_gem_context_put(ctx);\n\t\t\tcontinue;\n\t\t}\n\n\t\tspin_unlock_irq(&i915->gem.contexts.lock);\n\n\t\t \n\t\tfor_each_gem_engine(ce, i915_gem_context_lock_engines(ctx), it)\n\t\t\tintel_context_ban(ce, NULL);\n\t\ti915_gem_context_unlock_engines(ctx);\n\n\t\t \n\t\tif (ctx->pxp_wakeref) {\n\t\t\tintel_runtime_pm_put(&i915->runtime_pm,\n\t\t\t\t\t     ctx->pxp_wakeref);\n\t\t\tctx->pxp_wakeref = 0;\n\t\t}\n\n\t\tspin_lock_irq(&i915->gem.contexts.lock);\n\t\tlist_safe_reset_next(ctx, cn, link);\n\t\ti915_gem_context_put(ctx);\n\t}\n\tspin_unlock_irq(&i915->gem.contexts.lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}