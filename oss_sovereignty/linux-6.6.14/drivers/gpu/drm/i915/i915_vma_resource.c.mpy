{
  "module_name": "i915_vma_resource.c",
  "hash_id": "99ac55b0a0b1c300cb709876d463a336eec003f807568935edefc6ffe2b48e47",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/i915_vma_resource.c",
  "human_readable_source": "\n \n\n#include <linux/interval_tree_generic.h>\n#include <linux/sched/mm.h>\n\n#include \"i915_sw_fence.h\"\n#include \"i915_vma_resource.h\"\n#include \"i915_drv.h\"\n#include \"intel_memory_region.h\"\n\n#include \"gt/intel_gtt.h\"\n\nstatic struct kmem_cache *slab_vma_resources;\n\n \n#define VMA_RES_START(_node) ((_node)->start - (_node)->guard)\n#define VMA_RES_LAST(_node) ((_node)->start + (_node)->node_size + (_node)->guard - 1)\nINTERVAL_TREE_DEFINE(struct i915_vma_resource, rb,\n\t\t     u64, __subtree_last,\n\t\t     VMA_RES_START, VMA_RES_LAST, static, vma_res_itree);\n\n \n\n \nstruct i915_vma_resource *i915_vma_resource_alloc(void)\n{\n\tstruct i915_vma_resource *vma_res =\n\t\tkmem_cache_zalloc(slab_vma_resources, GFP_KERNEL);\n\n\treturn vma_res ? vma_res : ERR_PTR(-ENOMEM);\n}\n\n \nvoid i915_vma_resource_free(struct i915_vma_resource *vma_res)\n{\n\tif (vma_res)\n\t\tkmem_cache_free(slab_vma_resources, vma_res);\n}\n\nstatic const char *get_driver_name(struct dma_fence *fence)\n{\n\treturn \"vma unbind fence\";\n}\n\nstatic const char *get_timeline_name(struct dma_fence *fence)\n{\n\treturn \"unbound\";\n}\n\nstatic void unbind_fence_free_rcu(struct rcu_head *head)\n{\n\tstruct i915_vma_resource *vma_res =\n\t\tcontainer_of(head, typeof(*vma_res), unbind_fence.rcu);\n\n\ti915_vma_resource_free(vma_res);\n}\n\nstatic void unbind_fence_release(struct dma_fence *fence)\n{\n\tstruct i915_vma_resource *vma_res =\n\t\tcontainer_of(fence, typeof(*vma_res), unbind_fence);\n\n\ti915_sw_fence_fini(&vma_res->chain);\n\n\tcall_rcu(&fence->rcu, unbind_fence_free_rcu);\n}\n\nstatic struct dma_fence_ops unbind_fence_ops = {\n\t.get_driver_name = get_driver_name,\n\t.get_timeline_name = get_timeline_name,\n\t.release = unbind_fence_release,\n};\n\nstatic void __i915_vma_resource_unhold(struct i915_vma_resource *vma_res)\n{\n\tstruct i915_address_space *vm;\n\n\tif (!refcount_dec_and_test(&vma_res->hold_count))\n\t\treturn;\n\n\tdma_fence_signal(&vma_res->unbind_fence);\n\n\tvm = vma_res->vm;\n\tif (vma_res->wakeref)\n\t\tintel_runtime_pm_put(&vm->i915->runtime_pm, vma_res->wakeref);\n\n\tvma_res->vm = NULL;\n\tif (!RB_EMPTY_NODE(&vma_res->rb)) {\n\t\tmutex_lock(&vm->mutex);\n\t\tvma_res_itree_remove(vma_res, &vm->pending_unbind);\n\t\tmutex_unlock(&vm->mutex);\n\t}\n\n\tif (vma_res->bi.pages_rsgt)\n\t\ti915_refct_sgt_put(vma_res->bi.pages_rsgt);\n}\n\n \nvoid i915_vma_resource_unhold(struct i915_vma_resource *vma_res,\n\t\t\t      bool lockdep_cookie)\n{\n\tdma_fence_end_signalling(lockdep_cookie);\n\n\tif (IS_ENABLED(CONFIG_PROVE_LOCKING)) {\n\t\tunsigned long irq_flags;\n\n\t\t \n\t\tspin_lock_irqsave(&vma_res->lock, irq_flags);\n\t\tspin_unlock_irqrestore(&vma_res->lock, irq_flags);\n\t}\n\n\t__i915_vma_resource_unhold(vma_res);\n}\n\n \nbool i915_vma_resource_hold(struct i915_vma_resource *vma_res,\n\t\t\t    bool *lockdep_cookie)\n{\n\tbool held = refcount_inc_not_zero(&vma_res->hold_count);\n\n\tif (held)\n\t\t*lockdep_cookie = dma_fence_begin_signalling();\n\n\treturn held;\n}\n\nstatic void i915_vma_resource_unbind_work(struct work_struct *work)\n{\n\tstruct i915_vma_resource *vma_res =\n\t\tcontainer_of(work, typeof(*vma_res), work);\n\tstruct i915_address_space *vm = vma_res->vm;\n\tbool lockdep_cookie;\n\n\tlockdep_cookie = dma_fence_begin_signalling();\n\tif (likely(!vma_res->skip_pte_rewrite))\n\t\tvma_res->ops->unbind_vma(vm, vma_res);\n\n\tdma_fence_end_signalling(lockdep_cookie);\n\t__i915_vma_resource_unhold(vma_res);\n\ti915_vma_resource_put(vma_res);\n}\n\nstatic int\ni915_vma_resource_fence_notify(struct i915_sw_fence *fence,\n\t\t\t       enum i915_sw_fence_notify state)\n{\n\tstruct i915_vma_resource *vma_res =\n\t\tcontainer_of(fence, typeof(*vma_res), chain);\n\tstruct dma_fence *unbind_fence =\n\t\t&vma_res->unbind_fence;\n\n\tswitch (state) {\n\tcase FENCE_COMPLETE:\n\t\tdma_fence_get(unbind_fence);\n\t\tif (vma_res->immediate_unbind) {\n\t\t\ti915_vma_resource_unbind_work(&vma_res->work);\n\t\t} else {\n\t\t\tINIT_WORK(&vma_res->work, i915_vma_resource_unbind_work);\n\t\t\tqueue_work(system_unbound_wq, &vma_res->work);\n\t\t}\n\t\tbreak;\n\tcase FENCE_FREE:\n\t\ti915_vma_resource_put(vma_res);\n\t\tbreak;\n\t}\n\n\treturn NOTIFY_DONE;\n}\n\n \nstruct dma_fence *i915_vma_resource_unbind(struct i915_vma_resource *vma_res,\n\t\t\t\t\t   u32 *tlb)\n{\n\tstruct i915_address_space *vm = vma_res->vm;\n\n\tvma_res->tlb = tlb;\n\n\t \n\ti915_vma_resource_get(vma_res);\n\n\t \n\tif (vma_res->needs_wakeref)\n\t\tvma_res->wakeref = intel_runtime_pm_get_if_in_use(&vm->i915->runtime_pm);\n\n\tif (atomic_read(&vma_res->chain.pending) <= 1) {\n\t\tRB_CLEAR_NODE(&vma_res->rb);\n\t\tvma_res->immediate_unbind = 1;\n\t} else {\n\t\tvma_res_itree_insert(vma_res, &vma_res->vm->pending_unbind);\n\t}\n\n\ti915_sw_fence_commit(&vma_res->chain);\n\n\treturn &vma_res->unbind_fence;\n}\n\n \nvoid __i915_vma_resource_init(struct i915_vma_resource *vma_res)\n{\n\tspin_lock_init(&vma_res->lock);\n\tdma_fence_init(&vma_res->unbind_fence, &unbind_fence_ops,\n\t\t       &vma_res->lock, 0, 0);\n\trefcount_set(&vma_res->hold_count, 1);\n\ti915_sw_fence_init(&vma_res->chain, i915_vma_resource_fence_notify);\n}\n\nstatic void\ni915_vma_resource_color_adjust_range(struct i915_address_space *vm,\n\t\t\t\t     u64 *start,\n\t\t\t\t     u64 *end)\n{\n\tif (i915_vm_has_cache_coloring(vm)) {\n\t\tif (*start)\n\t\t\t*start -= I915_GTT_PAGE_SIZE;\n\t\t*end += I915_GTT_PAGE_SIZE;\n\t}\n}\n\n \nint i915_vma_resource_bind_dep_sync(struct i915_address_space *vm,\n\t\t\t\t    u64 offset,\n\t\t\t\t    u64 size,\n\t\t\t\t    bool intr)\n{\n\tstruct i915_vma_resource *node;\n\tu64 last = offset + size - 1;\n\n\tlockdep_assert_held(&vm->mutex);\n\tmight_sleep();\n\n\ti915_vma_resource_color_adjust_range(vm, &offset, &last);\n\tnode = vma_res_itree_iter_first(&vm->pending_unbind, offset, last);\n\twhile (node) {\n\t\tint ret = dma_fence_wait(&node->unbind_fence, intr);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tnode = vma_res_itree_iter_next(node, offset, last);\n\t}\n\n\treturn 0;\n}\n\n \nvoid i915_vma_resource_bind_dep_sync_all(struct i915_address_space *vm)\n{\n\tstruct i915_vma_resource *node;\n\tstruct dma_fence *fence;\n\n\tdo {\n\t\tfence = NULL;\n\t\tmutex_lock(&vm->mutex);\n\t\tnode = vma_res_itree_iter_first(&vm->pending_unbind, 0,\n\t\t\t\t\t\tU64_MAX);\n\t\tif (node)\n\t\t\tfence = dma_fence_get_rcu(&node->unbind_fence);\n\t\tmutex_unlock(&vm->mutex);\n\n\t\tif (fence) {\n\t\t\t \n\t\t\tdma_fence_wait(fence, false);\n\t\t\tdma_fence_put(fence);\n\t\t}\n\t} while (node);\n}\n\n \nint i915_vma_resource_bind_dep_await(struct i915_address_space *vm,\n\t\t\t\t     struct i915_sw_fence *sw_fence,\n\t\t\t\t     u64 offset,\n\t\t\t\t     u64 size,\n\t\t\t\t     bool intr,\n\t\t\t\t     gfp_t gfp)\n{\n\tstruct i915_vma_resource *node;\n\tu64 last = offset + size - 1;\n\n\tlockdep_assert_held(&vm->mutex);\n\tmight_alloc(gfp);\n\tmight_sleep();\n\n\ti915_vma_resource_color_adjust_range(vm, &offset, &last);\n\tnode = vma_res_itree_iter_first(&vm->pending_unbind, offset, last);\n\twhile (node) {\n\t\tint ret;\n\n\t\tret = i915_sw_fence_await_dma_fence(sw_fence,\n\t\t\t\t\t\t    &node->unbind_fence,\n\t\t\t\t\t\t    0, gfp);\n\t\tif (ret < 0) {\n\t\t\tret = dma_fence_wait(&node->unbind_fence, intr);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tnode = vma_res_itree_iter_next(node, offset, last);\n\t}\n\n\treturn 0;\n}\n\nvoid i915_vma_resource_module_exit(void)\n{\n\tkmem_cache_destroy(slab_vma_resources);\n}\n\nint __init i915_vma_resource_module_init(void)\n{\n\tslab_vma_resources = KMEM_CACHE(i915_vma_resource, SLAB_HWCACHE_ALIGN);\n\tif (!slab_vma_resources)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}