{
  "module_name": "intel_uncore.c",
  "hash_id": "43bc7df95d15cbf8b74059c372685ac10b27c7b88f5ba1bbe4816d15382ff3e8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/intel_uncore.c",
  "human_readable_source": " \n\n#include <drm/drm_managed.h>\n#include <linux/pm_runtime.h>\n\n#include \"gt/intel_engine_regs.h\"\n#include \"gt/intel_gt_regs.h\"\n\n#include \"i915_drv.h\"\n#include \"i915_iosf_mbi.h\"\n#include \"i915_reg.h\"\n#include \"i915_trace.h\"\n#include \"i915_vgpu.h\"\n\n#define FORCEWAKE_ACK_TIMEOUT_MS 50\n#define GT_FIFO_TIMEOUT_MS\t 10\n\n#define __raw_posting_read(...) ((void)__raw_uncore_read32(__VA_ARGS__))\n\nstatic void\nfw_domains_get(struct intel_uncore *uncore, enum forcewake_domains fw_domains)\n{\n\tuncore->fw_get_funcs->force_wake_get(uncore, fw_domains);\n}\n\nvoid\nintel_uncore_mmio_debug_init_early(struct drm_i915_private *i915)\n{\n\tspin_lock_init(&i915->mmio_debug.lock);\n\ti915->mmio_debug.unclaimed_mmio_check = 1;\n\n\ti915->uncore.debug = &i915->mmio_debug;\n}\n\nstatic void mmio_debug_suspend(struct intel_uncore *uncore)\n{\n\tif (!uncore->debug)\n\t\treturn;\n\n\tspin_lock(&uncore->debug->lock);\n\n\t \n\tif (!uncore->debug->suspend_count++) {\n\t\tuncore->debug->saved_mmio_check = uncore->debug->unclaimed_mmio_check;\n\t\tuncore->debug->unclaimed_mmio_check = 0;\n\t}\n\n\tspin_unlock(&uncore->debug->lock);\n}\n\nstatic bool check_for_unclaimed_mmio(struct intel_uncore *uncore);\n\nstatic void mmio_debug_resume(struct intel_uncore *uncore)\n{\n\tif (!uncore->debug)\n\t\treturn;\n\n\tspin_lock(&uncore->debug->lock);\n\n\tif (!--uncore->debug->suspend_count)\n\t\tuncore->debug->unclaimed_mmio_check = uncore->debug->saved_mmio_check;\n\n\tif (check_for_unclaimed_mmio(uncore))\n\t\tdrm_info(&uncore->i915->drm,\n\t\t\t \"Invalid mmio detected during user access\\n\");\n\n\tspin_unlock(&uncore->debug->lock);\n}\n\nstatic const char * const forcewake_domain_names[] = {\n\t\"render\",\n\t\"gt\",\n\t\"media\",\n\t\"vdbox0\",\n\t\"vdbox1\",\n\t\"vdbox2\",\n\t\"vdbox3\",\n\t\"vdbox4\",\n\t\"vdbox5\",\n\t\"vdbox6\",\n\t\"vdbox7\",\n\t\"vebox0\",\n\t\"vebox1\",\n\t\"vebox2\",\n\t\"vebox3\",\n\t\"gsc\",\n};\n\nconst char *\nintel_uncore_forcewake_domain_to_str(const enum forcewake_domain_id id)\n{\n\tBUILD_BUG_ON(ARRAY_SIZE(forcewake_domain_names) != FW_DOMAIN_ID_COUNT);\n\n\tif (id >= 0 && id < FW_DOMAIN_ID_COUNT)\n\t\treturn forcewake_domain_names[id];\n\n\tWARN_ON(id);\n\n\treturn \"unknown\";\n}\n\n#define fw_ack(d) readl((d)->reg_ack)\n#define fw_set(d, val) writel(_MASKED_BIT_ENABLE((val)), (d)->reg_set)\n#define fw_clear(d, val) writel(_MASKED_BIT_DISABLE((val)), (d)->reg_set)\n\nstatic inline void\nfw_domain_reset(const struct intel_uncore_forcewake_domain *d)\n{\n\t \n\t \n\tif (GRAPHICS_VER(d->uncore->i915) >= 12)\n\t\tfw_clear(d, 0xefff);\n\telse\n\t\tfw_clear(d, 0xffff);\n}\n\nstatic inline void\nfw_domain_arm_timer(struct intel_uncore_forcewake_domain *d)\n{\n\tGEM_BUG_ON(d->uncore->fw_domains_timer & d->mask);\n\td->uncore->fw_domains_timer |= d->mask;\n\td->wake_count++;\n\thrtimer_start_range_ns(&d->timer,\n\t\t\t       NSEC_PER_MSEC,\n\t\t\t       NSEC_PER_MSEC,\n\t\t\t       HRTIMER_MODE_REL);\n}\n\nstatic inline int\n__wait_for_ack(const struct intel_uncore_forcewake_domain *d,\n\t       const u32 ack,\n\t       const u32 value)\n{\n\treturn wait_for_atomic((fw_ack(d) & ack) == value,\n\t\t\t       FORCEWAKE_ACK_TIMEOUT_MS);\n}\n\nstatic inline int\nwait_ack_clear(const struct intel_uncore_forcewake_domain *d,\n\t       const u32 ack)\n{\n\treturn __wait_for_ack(d, ack, 0);\n}\n\nstatic inline int\nwait_ack_set(const struct intel_uncore_forcewake_domain *d,\n\t     const u32 ack)\n{\n\treturn __wait_for_ack(d, ack, ack);\n}\n\nstatic inline void\nfw_domain_wait_ack_clear(const struct intel_uncore_forcewake_domain *d)\n{\n\tif (!wait_ack_clear(d, FORCEWAKE_KERNEL))\n\t\treturn;\n\n\tif (fw_ack(d) == ~0)\n\t\tdrm_err(&d->uncore->i915->drm,\n\t\t\t\"%s: MMIO unreliable (forcewake register returns 0xFFFFFFFF)!\\n\",\n\t\t\tintel_uncore_forcewake_domain_to_str(d->id));\n\telse\n\t\tdrm_err(&d->uncore->i915->drm,\n\t\t\t\"%s: timed out waiting for forcewake ack to clear.\\n\",\n\t\t\tintel_uncore_forcewake_domain_to_str(d->id));\n\n\tadd_taint_for_CI(d->uncore->i915, TAINT_WARN);  \n}\n\nenum ack_type {\n\tACK_CLEAR = 0,\n\tACK_SET\n};\n\nstatic int\nfw_domain_wait_ack_with_fallback(const struct intel_uncore_forcewake_domain *d,\n\t\t\t\t const enum ack_type type)\n{\n\tconst u32 ack_bit = FORCEWAKE_KERNEL;\n\tconst u32 value = type == ACK_SET ? ack_bit : 0;\n\tunsigned int pass;\n\tbool ack_detected;\n\n\t \n\n\tpass = 1;\n\tdo {\n\t\twait_ack_clear(d, FORCEWAKE_KERNEL_FALLBACK);\n\n\t\tfw_set(d, FORCEWAKE_KERNEL_FALLBACK);\n\t\t \n\t\tudelay(10 * pass);\n\t\twait_ack_set(d, FORCEWAKE_KERNEL_FALLBACK);\n\n\t\tack_detected = (fw_ack(d) & ack_bit) == value;\n\n\t\tfw_clear(d, FORCEWAKE_KERNEL_FALLBACK);\n\t} while (!ack_detected && pass++ < 10);\n\n\tdrm_dbg(&d->uncore->i915->drm,\n\t\t\"%s had to use fallback to %s ack, 0x%x (passes %u)\\n\",\n\t\tintel_uncore_forcewake_domain_to_str(d->id),\n\t\ttype == ACK_SET ? \"set\" : \"clear\",\n\t\tfw_ack(d),\n\t\tpass);\n\n\treturn ack_detected ? 0 : -ETIMEDOUT;\n}\n\nstatic inline void\nfw_domain_wait_ack_clear_fallback(const struct intel_uncore_forcewake_domain *d)\n{\n\tif (likely(!wait_ack_clear(d, FORCEWAKE_KERNEL)))\n\t\treturn;\n\n\tif (fw_domain_wait_ack_with_fallback(d, ACK_CLEAR))\n\t\tfw_domain_wait_ack_clear(d);\n}\n\nstatic inline void\nfw_domain_get(const struct intel_uncore_forcewake_domain *d)\n{\n\tfw_set(d, FORCEWAKE_KERNEL);\n}\n\nstatic inline void\nfw_domain_wait_ack_set(const struct intel_uncore_forcewake_domain *d)\n{\n\tif (wait_ack_set(d, FORCEWAKE_KERNEL)) {\n\t\tdrm_err(&d->uncore->i915->drm,\n\t\t\t\"%s: timed out waiting for forcewake ack request.\\n\",\n\t\t\tintel_uncore_forcewake_domain_to_str(d->id));\n\t\tadd_taint_for_CI(d->uncore->i915, TAINT_WARN);  \n\t}\n}\n\nstatic inline void\nfw_domain_wait_ack_set_fallback(const struct intel_uncore_forcewake_domain *d)\n{\n\tif (likely(!wait_ack_set(d, FORCEWAKE_KERNEL)))\n\t\treturn;\n\n\tif (fw_domain_wait_ack_with_fallback(d, ACK_SET))\n\t\tfw_domain_wait_ack_set(d);\n}\n\nstatic inline void\nfw_domain_put(const struct intel_uncore_forcewake_domain *d)\n{\n\tfw_clear(d, FORCEWAKE_KERNEL);\n}\n\nstatic void\nfw_domains_get_normal(struct intel_uncore *uncore, enum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *d;\n\tunsigned int tmp;\n\n\tGEM_BUG_ON(fw_domains & ~uncore->fw_domains);\n\n\tfor_each_fw_domain_masked(d, fw_domains, uncore, tmp) {\n\t\tfw_domain_wait_ack_clear(d);\n\t\tfw_domain_get(d);\n\t}\n\n\tfor_each_fw_domain_masked(d, fw_domains, uncore, tmp)\n\t\tfw_domain_wait_ack_set(d);\n\n\tuncore->fw_domains_active |= fw_domains;\n}\n\nstatic void\nfw_domains_get_with_fallback(struct intel_uncore *uncore,\n\t\t\t     enum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *d;\n\tunsigned int tmp;\n\n\tGEM_BUG_ON(fw_domains & ~uncore->fw_domains);\n\n\tfor_each_fw_domain_masked(d, fw_domains, uncore, tmp) {\n\t\tfw_domain_wait_ack_clear_fallback(d);\n\t\tfw_domain_get(d);\n\t}\n\n\tfor_each_fw_domain_masked(d, fw_domains, uncore, tmp)\n\t\tfw_domain_wait_ack_set_fallback(d);\n\n\tuncore->fw_domains_active |= fw_domains;\n}\n\nstatic void\nfw_domains_put(struct intel_uncore *uncore, enum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *d;\n\tunsigned int tmp;\n\n\tGEM_BUG_ON(fw_domains & ~uncore->fw_domains);\n\n\tfor_each_fw_domain_masked(d, fw_domains, uncore, tmp)\n\t\tfw_domain_put(d);\n\n\tuncore->fw_domains_active &= ~fw_domains;\n}\n\nstatic void\nfw_domains_reset(struct intel_uncore *uncore,\n\t\t enum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *d;\n\tunsigned int tmp;\n\n\tif (!fw_domains)\n\t\treturn;\n\n\tGEM_BUG_ON(fw_domains & ~uncore->fw_domains);\n\n\tfor_each_fw_domain_masked(d, fw_domains, uncore, tmp)\n\t\tfw_domain_reset(d);\n}\n\nstatic inline u32 gt_thread_status(struct intel_uncore *uncore)\n{\n\tu32 val;\n\n\tval = __raw_uncore_read32(uncore, GEN6_GT_THREAD_STATUS_REG);\n\tval &= GEN6_GT_THREAD_STATUS_CORE_MASK;\n\n\treturn val;\n}\n\nstatic void __gen6_gt_wait_for_thread_c0(struct intel_uncore *uncore)\n{\n\t \n\tdrm_WARN_ONCE(&uncore->i915->drm,\n\t\t      wait_for_atomic_us(gt_thread_status(uncore) == 0, 5000),\n\t\t      \"GT thread status wait timed out\\n\");\n}\n\nstatic void fw_domains_get_with_thread_status(struct intel_uncore *uncore,\n\t\t\t\t\t      enum forcewake_domains fw_domains)\n{\n\tfw_domains_get_normal(uncore, fw_domains);\n\n\t \n\t__gen6_gt_wait_for_thread_c0(uncore);\n}\n\nstatic inline u32 fifo_free_entries(struct intel_uncore *uncore)\n{\n\tu32 count = __raw_uncore_read32(uncore, GTFIFOCTL);\n\n\treturn count & GT_FIFO_FREE_ENTRIES_MASK;\n}\n\nstatic void __gen6_gt_wait_for_fifo(struct intel_uncore *uncore)\n{\n\tu32 n;\n\n\t \n\tif (IS_VALLEYVIEW(uncore->i915))\n\t\tn = fifo_free_entries(uncore);\n\telse\n\t\tn = uncore->fifo_count;\n\n\tif (n <= GT_FIFO_NUM_RESERVED_ENTRIES) {\n\t\tif (wait_for_atomic((n = fifo_free_entries(uncore)) >\n\t\t\t\t    GT_FIFO_NUM_RESERVED_ENTRIES,\n\t\t\t\t    GT_FIFO_TIMEOUT_MS)) {\n\t\t\tdrm_dbg(&uncore->i915->drm,\n\t\t\t\t\"GT_FIFO timeout, entries: %u\\n\", n);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tuncore->fifo_count = n - 1;\n}\n\nstatic enum hrtimer_restart\nintel_uncore_fw_release_timer(struct hrtimer *timer)\n{\n\tstruct intel_uncore_forcewake_domain *domain =\n\t       container_of(timer, struct intel_uncore_forcewake_domain, timer);\n\tstruct intel_uncore *uncore = domain->uncore;\n\tunsigned long irqflags;\n\n\tassert_rpm_device_not_suspended(uncore->rpm);\n\n\tif (xchg(&domain->active, false))\n\t\treturn HRTIMER_RESTART;\n\n\tspin_lock_irqsave(&uncore->lock, irqflags);\n\n\tuncore->fw_domains_timer &= ~domain->mask;\n\n\tGEM_BUG_ON(!domain->wake_count);\n\tif (--domain->wake_count == 0)\n\t\tfw_domains_put(uncore, domain->mask);\n\n\tspin_unlock_irqrestore(&uncore->lock, irqflags);\n\n\treturn HRTIMER_NORESTART;\n}\n\n \nstatic unsigned int\nintel_uncore_forcewake_reset(struct intel_uncore *uncore)\n{\n\tunsigned long irqflags;\n\tstruct intel_uncore_forcewake_domain *domain;\n\tint retry_count = 100;\n\tenum forcewake_domains fw, active_domains;\n\n\tiosf_mbi_assert_punit_acquired();\n\n\t \n\twhile (1) {\n\t\tunsigned int tmp;\n\n\t\tactive_domains = 0;\n\n\t\tfor_each_fw_domain(domain, uncore, tmp) {\n\t\t\tsmp_store_mb(domain->active, false);\n\t\t\tif (hrtimer_cancel(&domain->timer) == 0)\n\t\t\t\tcontinue;\n\n\t\t\tintel_uncore_fw_release_timer(&domain->timer);\n\t\t}\n\n\t\tspin_lock_irqsave(&uncore->lock, irqflags);\n\n\t\tfor_each_fw_domain(domain, uncore, tmp) {\n\t\t\tif (hrtimer_active(&domain->timer))\n\t\t\t\tactive_domains |= domain->mask;\n\t\t}\n\n\t\tif (active_domains == 0)\n\t\t\tbreak;\n\n\t\tif (--retry_count == 0) {\n\t\t\tdrm_err(&uncore->i915->drm, \"Timed out waiting for forcewake timers to finish\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&uncore->lock, irqflags);\n\t\tcond_resched();\n\t}\n\n\tdrm_WARN_ON(&uncore->i915->drm, active_domains);\n\n\tfw = uncore->fw_domains_active;\n\tif (fw)\n\t\tfw_domains_put(uncore, fw);\n\n\tfw_domains_reset(uncore, uncore->fw_domains);\n\tassert_forcewakes_inactive(uncore);\n\n\tspin_unlock_irqrestore(&uncore->lock, irqflags);\n\n\treturn fw;  \n}\n\nstatic bool\nfpga_check_for_unclaimed_mmio(struct intel_uncore *uncore)\n{\n\tu32 dbg;\n\n\tdbg = __raw_uncore_read32(uncore, FPGA_DBG);\n\tif (likely(!(dbg & FPGA_DBG_RM_NOCLAIM)))\n\t\treturn false;\n\n\t \n\tif (unlikely(dbg == ~0))\n\t\tdrm_err(&uncore->i915->drm,\n\t\t\t\"Lost access to MMIO BAR; all registers now read back as 0xFFFFFFFF!\\n\");\n\n\t__raw_uncore_write32(uncore, FPGA_DBG, FPGA_DBG_RM_NOCLAIM);\n\n\treturn true;\n}\n\nstatic bool\nvlv_check_for_unclaimed_mmio(struct intel_uncore *uncore)\n{\n\tu32 cer;\n\n\tcer = __raw_uncore_read32(uncore, CLAIM_ER);\n\tif (likely(!(cer & (CLAIM_ER_OVERFLOW | CLAIM_ER_CTR_MASK))))\n\t\treturn false;\n\n\t__raw_uncore_write32(uncore, CLAIM_ER, CLAIM_ER_CLR);\n\n\treturn true;\n}\n\nstatic bool\ngen6_check_for_fifo_debug(struct intel_uncore *uncore)\n{\n\tu32 fifodbg;\n\n\tfifodbg = __raw_uncore_read32(uncore, GTFIFODBG);\n\n\tif (unlikely(fifodbg)) {\n\t\tdrm_dbg(&uncore->i915->drm, \"GTFIFODBG = 0x08%x\\n\", fifodbg);\n\t\t__raw_uncore_write32(uncore, GTFIFODBG, fifodbg);\n\t}\n\n\treturn fifodbg;\n}\n\nstatic bool\ncheck_for_unclaimed_mmio(struct intel_uncore *uncore)\n{\n\tbool ret = false;\n\n\tlockdep_assert_held(&uncore->debug->lock);\n\n\tif (uncore->debug->suspend_count)\n\t\treturn false;\n\n\tif (intel_uncore_has_fpga_dbg_unclaimed(uncore))\n\t\tret |= fpga_check_for_unclaimed_mmio(uncore);\n\n\tif (intel_uncore_has_dbg_unclaimed(uncore))\n\t\tret |= vlv_check_for_unclaimed_mmio(uncore);\n\n\tif (intel_uncore_has_fifo(uncore))\n\t\tret |= gen6_check_for_fifo_debug(uncore);\n\n\treturn ret;\n}\n\nstatic void forcewake_early_sanitize(struct intel_uncore *uncore,\n\t\t\t\t     unsigned int restore_forcewake)\n{\n\tGEM_BUG_ON(!intel_uncore_has_forcewake(uncore));\n\n\t \n\tif (IS_CHERRYVIEW(uncore->i915)) {\n\t\t__raw_uncore_write32(uncore, GTFIFOCTL,\n\t\t\t\t     __raw_uncore_read32(uncore, GTFIFOCTL) |\n\t\t\t\t     GT_FIFO_CTL_BLOCK_ALL_POLICY_STALL |\n\t\t\t\t     GT_FIFO_CTL_RC6_POLICY_STALL);\n\t}\n\n\tiosf_mbi_punit_acquire();\n\tintel_uncore_forcewake_reset(uncore);\n\tif (restore_forcewake) {\n\t\tspin_lock_irq(&uncore->lock);\n\t\tfw_domains_get(uncore, restore_forcewake);\n\n\t\tif (intel_uncore_has_fifo(uncore))\n\t\t\tuncore->fifo_count = fifo_free_entries(uncore);\n\t\tspin_unlock_irq(&uncore->lock);\n\t}\n\tiosf_mbi_punit_release();\n}\n\nvoid intel_uncore_suspend(struct intel_uncore *uncore)\n{\n\tif (!intel_uncore_has_forcewake(uncore))\n\t\treturn;\n\n\tiosf_mbi_punit_acquire();\n\tiosf_mbi_unregister_pmic_bus_access_notifier_unlocked(\n\t\t&uncore->pmic_bus_access_nb);\n\tuncore->fw_domains_saved = intel_uncore_forcewake_reset(uncore);\n\tiosf_mbi_punit_release();\n}\n\nvoid intel_uncore_resume_early(struct intel_uncore *uncore)\n{\n\tunsigned int restore_forcewake;\n\n\tif (intel_uncore_unclaimed_mmio(uncore))\n\t\tdrm_dbg(&uncore->i915->drm, \"unclaimed mmio detected on resume, clearing\\n\");\n\n\tif (!intel_uncore_has_forcewake(uncore))\n\t\treturn;\n\n\trestore_forcewake = fetch_and_zero(&uncore->fw_domains_saved);\n\tforcewake_early_sanitize(uncore, restore_forcewake);\n\n\tiosf_mbi_register_pmic_bus_access_notifier(&uncore->pmic_bus_access_nb);\n}\n\nvoid intel_uncore_runtime_resume(struct intel_uncore *uncore)\n{\n\tif (!intel_uncore_has_forcewake(uncore))\n\t\treturn;\n\n\tiosf_mbi_register_pmic_bus_access_notifier(&uncore->pmic_bus_access_nb);\n}\n\nstatic void __intel_uncore_forcewake_get(struct intel_uncore *uncore,\n\t\t\t\t\t enum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *domain;\n\tunsigned int tmp;\n\n\tfw_domains &= uncore->fw_domains;\n\n\tfor_each_fw_domain_masked(domain, fw_domains, uncore, tmp) {\n\t\tif (domain->wake_count++) {\n\t\t\tfw_domains &= ~domain->mask;\n\t\t\tdomain->active = true;\n\t\t}\n\t}\n\n\tif (fw_domains)\n\t\tfw_domains_get(uncore, fw_domains);\n}\n\n \nvoid intel_uncore_forcewake_get(struct intel_uncore *uncore,\n\t\t\t\tenum forcewake_domains fw_domains)\n{\n\tunsigned long irqflags;\n\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\tassert_rpm_wakelock_held(uncore->rpm);\n\n\tspin_lock_irqsave(&uncore->lock, irqflags);\n\t__intel_uncore_forcewake_get(uncore, fw_domains);\n\tspin_unlock_irqrestore(&uncore->lock, irqflags);\n}\n\n \nvoid intel_uncore_forcewake_user_get(struct intel_uncore *uncore)\n{\n\tspin_lock_irq(&uncore->lock);\n\tif (!uncore->user_forcewake_count++) {\n\t\tintel_uncore_forcewake_get__locked(uncore, FORCEWAKE_ALL);\n\t\tmmio_debug_suspend(uncore);\n\t}\n\tspin_unlock_irq(&uncore->lock);\n}\n\n \nvoid intel_uncore_forcewake_user_put(struct intel_uncore *uncore)\n{\n\tspin_lock_irq(&uncore->lock);\n\tif (!--uncore->user_forcewake_count) {\n\t\tmmio_debug_resume(uncore);\n\t\tintel_uncore_forcewake_put__locked(uncore, FORCEWAKE_ALL);\n\t}\n\tspin_unlock_irq(&uncore->lock);\n}\n\n \nvoid intel_uncore_forcewake_get__locked(struct intel_uncore *uncore,\n\t\t\t\t\tenum forcewake_domains fw_domains)\n{\n\tlockdep_assert_held(&uncore->lock);\n\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\t__intel_uncore_forcewake_get(uncore, fw_domains);\n}\n\nstatic void __intel_uncore_forcewake_put(struct intel_uncore *uncore,\n\t\t\t\t\t enum forcewake_domains fw_domains,\n\t\t\t\t\t bool delayed)\n{\n\tstruct intel_uncore_forcewake_domain *domain;\n\tunsigned int tmp;\n\n\tfw_domains &= uncore->fw_domains;\n\n\tfor_each_fw_domain_masked(domain, fw_domains, uncore, tmp) {\n\t\tGEM_BUG_ON(!domain->wake_count);\n\n\t\tif (--domain->wake_count) {\n\t\t\tdomain->active = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (delayed &&\n\t\t    !(domain->uncore->fw_domains_timer & domain->mask))\n\t\t\tfw_domain_arm_timer(domain);\n\t\telse\n\t\t\tfw_domains_put(uncore, domain->mask);\n\t}\n}\n\n \nvoid intel_uncore_forcewake_put(struct intel_uncore *uncore,\n\t\t\t\tenum forcewake_domains fw_domains)\n{\n\tunsigned long irqflags;\n\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\tspin_lock_irqsave(&uncore->lock, irqflags);\n\t__intel_uncore_forcewake_put(uncore, fw_domains, false);\n\tspin_unlock_irqrestore(&uncore->lock, irqflags);\n}\n\nvoid intel_uncore_forcewake_put_delayed(struct intel_uncore *uncore,\n\t\t\t\t\tenum forcewake_domains fw_domains)\n{\n\tunsigned long irqflags;\n\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\tspin_lock_irqsave(&uncore->lock, irqflags);\n\t__intel_uncore_forcewake_put(uncore, fw_domains, true);\n\tspin_unlock_irqrestore(&uncore->lock, irqflags);\n}\n\n \nvoid intel_uncore_forcewake_flush(struct intel_uncore *uncore,\n\t\t\t\t  enum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *domain;\n\tunsigned int tmp;\n\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\tfw_domains &= uncore->fw_domains;\n\tfor_each_fw_domain_masked(domain, fw_domains, uncore, tmp) {\n\t\tWRITE_ONCE(domain->active, false);\n\t\tif (hrtimer_cancel(&domain->timer))\n\t\t\tintel_uncore_fw_release_timer(&domain->timer);\n\t}\n}\n\n \nvoid intel_uncore_forcewake_put__locked(struct intel_uncore *uncore,\n\t\t\t\t\tenum forcewake_domains fw_domains)\n{\n\tlockdep_assert_held(&uncore->lock);\n\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\t__intel_uncore_forcewake_put(uncore, fw_domains, false);\n}\n\nvoid assert_forcewakes_inactive(struct intel_uncore *uncore)\n{\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\tdrm_WARN(&uncore->i915->drm, uncore->fw_domains_active,\n\t\t \"Expected all fw_domains to be inactive, but %08x are still on\\n\",\n\t\t uncore->fw_domains_active);\n}\n\nvoid assert_forcewakes_active(struct intel_uncore *uncore,\n\t\t\t      enum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *domain;\n\tunsigned int tmp;\n\n\tif (!IS_ENABLED(CONFIG_DRM_I915_DEBUG_RUNTIME_PM))\n\t\treturn;\n\n\tif (!uncore->fw_get_funcs)\n\t\treturn;\n\n\tspin_lock_irq(&uncore->lock);\n\n\tassert_rpm_wakelock_held(uncore->rpm);\n\n\tfw_domains &= uncore->fw_domains;\n\tdrm_WARN(&uncore->i915->drm, fw_domains & ~uncore->fw_domains_active,\n\t\t \"Expected %08x fw_domains to be active, but %08x are off\\n\",\n\t\t fw_domains, fw_domains & ~uncore->fw_domains_active);\n\n\t \n\tfor_each_fw_domain_masked(domain, fw_domains, uncore, tmp) {\n\t\tunsigned int actual = READ_ONCE(domain->wake_count);\n\t\tunsigned int expect = 1;\n\n\t\tif (uncore->fw_domains_timer & domain->mask)\n\t\t\texpect++;  \n\n\t\tif (drm_WARN(&uncore->i915->drm, actual < expect,\n\t\t\t     \"Expected domain %d to be held awake by caller, count=%d\\n\",\n\t\t\t     domain->id, actual))\n\t\t\tbreak;\n\t}\n\n\tspin_unlock_irq(&uncore->lock);\n}\n\n \n#define NEEDS_FORCE_WAKE(reg) ({ \\\n\tu32 __reg = (reg); \\\n\t__reg < 0x40000 || __reg >= 0x116000; \\\n})\n\nstatic int fw_range_cmp(u32 offset, const struct intel_forcewake_range *entry)\n{\n\tif (offset < entry->start)\n\t\treturn -1;\n\telse if (offset > entry->end)\n\t\treturn 1;\n\telse\n\t\treturn 0;\n}\n\n \n#define BSEARCH(key, base, num, cmp) ({                                 \\\n\tunsigned int start__ = 0, end__ = (num);                        \\\n\ttypeof(base) result__ = NULL;                                   \\\n\twhile (start__ < end__) {                                       \\\n\t\tunsigned int mid__ = start__ + (end__ - start__) / 2;   \\\n\t\tint ret__ = (cmp)((key), (base) + mid__);               \\\n\t\tif (ret__ < 0) {                                        \\\n\t\t\tend__ = mid__;                                  \\\n\t\t} else if (ret__ > 0) {                                 \\\n\t\t\tstart__ = mid__ + 1;                            \\\n\t\t} else {                                                \\\n\t\t\tresult__ = (base) + mid__;                      \\\n\t\t\tbreak;                                          \\\n\t\t}                                                       \\\n\t}                                                               \\\n\tresult__;                                                       \\\n})\n\nstatic enum forcewake_domains\nfind_fw_domain(struct intel_uncore *uncore, u32 offset)\n{\n\tconst struct intel_forcewake_range *entry;\n\n\tif (IS_GSI_REG(offset))\n\t\toffset += uncore->gsi_offset;\n\n\tentry = BSEARCH(offset,\n\t\t\tuncore->fw_domains_table,\n\t\t\tuncore->fw_domains_table_entries,\n\t\t\tfw_range_cmp);\n\n\tif (!entry)\n\t\treturn 0;\n\n\t \n\tif (entry->domains == FORCEWAKE_ALL)\n\t\treturn uncore->fw_domains;\n\n\tdrm_WARN(&uncore->i915->drm, entry->domains & ~uncore->fw_domains,\n\t\t \"Uninitialized forcewake domain(s) 0x%x accessed at 0x%x\\n\",\n\t\t entry->domains & ~uncore->fw_domains, offset);\n\n\treturn entry->domains;\n}\n\n \n\nstatic const struct i915_range gen8_shadowed_regs[] = {\n\t{ .start =  0x2030, .end =  0x2030 },\n\t{ .start =  0xA008, .end =  0xA00C },\n\t{ .start = 0x12030, .end = 0x12030 },\n\t{ .start = 0x1a030, .end = 0x1a030 },\n\t{ .start = 0x22030, .end = 0x22030 },\n};\n\nstatic const struct i915_range gen11_shadowed_regs[] = {\n\t{ .start =   0x2030, .end =   0x2030 },\n\t{ .start =   0x2550, .end =   0x2550 },\n\t{ .start =   0xA008, .end =   0xA00C },\n\t{ .start =  0x22030, .end =  0x22030 },\n\t{ .start =  0x22230, .end =  0x22230 },\n\t{ .start =  0x22510, .end =  0x22550 },\n\t{ .start = 0x1C0030, .end = 0x1C0030 },\n\t{ .start = 0x1C0230, .end = 0x1C0230 },\n\t{ .start = 0x1C0510, .end = 0x1C0550 },\n\t{ .start = 0x1C4030, .end = 0x1C4030 },\n\t{ .start = 0x1C4230, .end = 0x1C4230 },\n\t{ .start = 0x1C4510, .end = 0x1C4550 },\n\t{ .start = 0x1C8030, .end = 0x1C8030 },\n\t{ .start = 0x1C8230, .end = 0x1C8230 },\n\t{ .start = 0x1C8510, .end = 0x1C8550 },\n\t{ .start = 0x1D0030, .end = 0x1D0030 },\n\t{ .start = 0x1D0230, .end = 0x1D0230 },\n\t{ .start = 0x1D0510, .end = 0x1D0550 },\n\t{ .start = 0x1D4030, .end = 0x1D4030 },\n\t{ .start = 0x1D4230, .end = 0x1D4230 },\n\t{ .start = 0x1D4510, .end = 0x1D4550 },\n\t{ .start = 0x1D8030, .end = 0x1D8030 },\n\t{ .start = 0x1D8230, .end = 0x1D8230 },\n\t{ .start = 0x1D8510, .end = 0x1D8550 },\n};\n\nstatic const struct i915_range gen12_shadowed_regs[] = {\n\t{ .start =   0x2030, .end =   0x2030 },\n\t{ .start =   0x2510, .end =   0x2550 },\n\t{ .start =   0xA008, .end =   0xA00C },\n\t{ .start =   0xA188, .end =   0xA188 },\n\t{ .start =   0xA278, .end =   0xA278 },\n\t{ .start =   0xA540, .end =   0xA56C },\n\t{ .start =   0xC4C8, .end =   0xC4C8 },\n\t{ .start =   0xC4D4, .end =   0xC4D4 },\n\t{ .start =   0xC600, .end =   0xC600 },\n\t{ .start =  0x22030, .end =  0x22030 },\n\t{ .start =  0x22510, .end =  0x22550 },\n\t{ .start = 0x1C0030, .end = 0x1C0030 },\n\t{ .start = 0x1C0510, .end = 0x1C0550 },\n\t{ .start = 0x1C4030, .end = 0x1C4030 },\n\t{ .start = 0x1C4510, .end = 0x1C4550 },\n\t{ .start = 0x1C8030, .end = 0x1C8030 },\n\t{ .start = 0x1C8510, .end = 0x1C8550 },\n\t{ .start = 0x1D0030, .end = 0x1D0030 },\n\t{ .start = 0x1D0510, .end = 0x1D0550 },\n\t{ .start = 0x1D4030, .end = 0x1D4030 },\n\t{ .start = 0x1D4510, .end = 0x1D4550 },\n\t{ .start = 0x1D8030, .end = 0x1D8030 },\n\t{ .start = 0x1D8510, .end = 0x1D8550 },\n\n\t \n\t{ .start = 0x1E0030, .end = 0x1E0030 },\n\t{ .start = 0x1E0510, .end = 0x1E0550 },\n\t{ .start = 0x1E4030, .end = 0x1E4030 },\n\t{ .start = 0x1E4510, .end = 0x1E4550 },\n\t{ .start = 0x1E8030, .end = 0x1E8030 },\n\t{ .start = 0x1E8510, .end = 0x1E8550 },\n\t{ .start = 0x1F0030, .end = 0x1F0030 },\n\t{ .start = 0x1F0510, .end = 0x1F0550 },\n\t{ .start = 0x1F4030, .end = 0x1F4030 },\n\t{ .start = 0x1F4510, .end = 0x1F4550 },\n\t{ .start = 0x1F8030, .end = 0x1F8030 },\n\t{ .start = 0x1F8510, .end = 0x1F8550 },\n};\n\nstatic const struct i915_range dg2_shadowed_regs[] = {\n\t{ .start =   0x2030, .end =   0x2030 },\n\t{ .start =   0x2510, .end =   0x2550 },\n\t{ .start =   0xA008, .end =   0xA00C },\n\t{ .start =   0xA188, .end =   0xA188 },\n\t{ .start =   0xA278, .end =   0xA278 },\n\t{ .start =   0xA540, .end =   0xA56C },\n\t{ .start =   0xC4C8, .end =   0xC4C8 },\n\t{ .start =   0xC4E0, .end =   0xC4E0 },\n\t{ .start =   0xC600, .end =   0xC600 },\n\t{ .start =   0xC658, .end =   0xC658 },\n\t{ .start =  0x22030, .end =  0x22030 },\n\t{ .start =  0x22510, .end =  0x22550 },\n\t{ .start = 0x1C0030, .end = 0x1C0030 },\n\t{ .start = 0x1C0510, .end = 0x1C0550 },\n\t{ .start = 0x1C4030, .end = 0x1C4030 },\n\t{ .start = 0x1C4510, .end = 0x1C4550 },\n\t{ .start = 0x1C8030, .end = 0x1C8030 },\n\t{ .start = 0x1C8510, .end = 0x1C8550 },\n\t{ .start = 0x1D0030, .end = 0x1D0030 },\n\t{ .start = 0x1D0510, .end = 0x1D0550 },\n\t{ .start = 0x1D4030, .end = 0x1D4030 },\n\t{ .start = 0x1D4510, .end = 0x1D4550 },\n\t{ .start = 0x1D8030, .end = 0x1D8030 },\n\t{ .start = 0x1D8510, .end = 0x1D8550 },\n\t{ .start = 0x1E0030, .end = 0x1E0030 },\n\t{ .start = 0x1E0510, .end = 0x1E0550 },\n\t{ .start = 0x1E4030, .end = 0x1E4030 },\n\t{ .start = 0x1E4510, .end = 0x1E4550 },\n\t{ .start = 0x1E8030, .end = 0x1E8030 },\n\t{ .start = 0x1E8510, .end = 0x1E8550 },\n\t{ .start = 0x1F0030, .end = 0x1F0030 },\n\t{ .start = 0x1F0510, .end = 0x1F0550 },\n\t{ .start = 0x1F4030, .end = 0x1F4030 },\n\t{ .start = 0x1F4510, .end = 0x1F4550 },\n\t{ .start = 0x1F8030, .end = 0x1F8030 },\n\t{ .start = 0x1F8510, .end = 0x1F8550 },\n};\n\nstatic const struct i915_range pvc_shadowed_regs[] = {\n\t{ .start =   0x2030, .end =   0x2030 },\n\t{ .start =   0x2510, .end =   0x2550 },\n\t{ .start =   0xA008, .end =   0xA00C },\n\t{ .start =   0xA188, .end =   0xA188 },\n\t{ .start =   0xA278, .end =   0xA278 },\n\t{ .start =   0xA540, .end =   0xA56C },\n\t{ .start =   0xC4C8, .end =   0xC4C8 },\n\t{ .start =   0xC4E0, .end =   0xC4E0 },\n\t{ .start =   0xC600, .end =   0xC600 },\n\t{ .start =   0xC658, .end =   0xC658 },\n\t{ .start =  0x22030, .end =  0x22030 },\n\t{ .start =  0x22510, .end =  0x22550 },\n\t{ .start = 0x1C0030, .end = 0x1C0030 },\n\t{ .start = 0x1C0510, .end = 0x1C0550 },\n\t{ .start = 0x1C4030, .end = 0x1C4030 },\n\t{ .start = 0x1C4510, .end = 0x1C4550 },\n\t{ .start = 0x1C8030, .end = 0x1C8030 },\n\t{ .start = 0x1C8510, .end = 0x1C8550 },\n\t{ .start = 0x1D0030, .end = 0x1D0030 },\n\t{ .start = 0x1D0510, .end = 0x1D0550 },\n\t{ .start = 0x1D4030, .end = 0x1D4030 },\n\t{ .start = 0x1D4510, .end = 0x1D4550 },\n\t{ .start = 0x1D8030, .end = 0x1D8030 },\n\t{ .start = 0x1D8510, .end = 0x1D8550 },\n\t{ .start = 0x1E0030, .end = 0x1E0030 },\n\t{ .start = 0x1E0510, .end = 0x1E0550 },\n\t{ .start = 0x1E4030, .end = 0x1E4030 },\n\t{ .start = 0x1E4510, .end = 0x1E4550 },\n\t{ .start = 0x1E8030, .end = 0x1E8030 },\n\t{ .start = 0x1E8510, .end = 0x1E8550 },\n\t{ .start = 0x1F0030, .end = 0x1F0030 },\n\t{ .start = 0x1F0510, .end = 0x1F0550 },\n\t{ .start = 0x1F4030, .end = 0x1F4030 },\n\t{ .start = 0x1F4510, .end = 0x1F4550 },\n\t{ .start = 0x1F8030, .end = 0x1F8030 },\n\t{ .start = 0x1F8510, .end = 0x1F8550 },\n};\n\nstatic const struct i915_range mtl_shadowed_regs[] = {\n\t{ .start =   0x2030, .end =   0x2030 },\n\t{ .start =   0x2510, .end =   0x2550 },\n\t{ .start =   0xA008, .end =   0xA00C },\n\t{ .start =   0xA188, .end =   0xA188 },\n\t{ .start =   0xA278, .end =   0xA278 },\n\t{ .start =   0xA540, .end =   0xA56C },\n\t{ .start =   0xC050, .end =   0xC050 },\n\t{ .start =   0xC340, .end =   0xC340 },\n\t{ .start =   0xC4C8, .end =   0xC4C8 },\n\t{ .start =   0xC4E0, .end =   0xC4E0 },\n\t{ .start =   0xC600, .end =   0xC600 },\n\t{ .start =   0xC658, .end =   0xC658 },\n\t{ .start =   0xCFD4, .end =   0xCFDC },\n\t{ .start =  0x22030, .end =  0x22030 },\n\t{ .start =  0x22510, .end =  0x22550 },\n};\n\nstatic const struct i915_range xelpmp_shadowed_regs[] = {\n\t{ .start = 0x1C0030, .end = 0x1C0030 },\n\t{ .start = 0x1C0510, .end = 0x1C0550 },\n\t{ .start = 0x1C8030, .end = 0x1C8030 },\n\t{ .start = 0x1C8510, .end = 0x1C8550 },\n\t{ .start = 0x1D0030, .end = 0x1D0030 },\n\t{ .start = 0x1D0510, .end = 0x1D0550 },\n\t{ .start = 0x38A008, .end = 0x38A00C },\n\t{ .start = 0x38A188, .end = 0x38A188 },\n\t{ .start = 0x38A278, .end = 0x38A278 },\n\t{ .start = 0x38A540, .end = 0x38A56C },\n\t{ .start = 0x38A618, .end = 0x38A618 },\n\t{ .start = 0x38C050, .end = 0x38C050 },\n\t{ .start = 0x38C340, .end = 0x38C340 },\n\t{ .start = 0x38C4C8, .end = 0x38C4C8 },\n\t{ .start = 0x38C4E0, .end = 0x38C4E4 },\n\t{ .start = 0x38C600, .end = 0x38C600 },\n\t{ .start = 0x38C658, .end = 0x38C658 },\n\t{ .start = 0x38CFD4, .end = 0x38CFDC },\n};\n\nstatic int mmio_range_cmp(u32 key, const struct i915_range *range)\n{\n\tif (key < range->start)\n\t\treturn -1;\n\telse if (key > range->end)\n\t\treturn 1;\n\telse\n\t\treturn 0;\n}\n\nstatic bool is_shadowed(struct intel_uncore *uncore, u32 offset)\n{\n\tif (drm_WARN_ON(&uncore->i915->drm, !uncore->shadowed_reg_table))\n\t\treturn false;\n\n\tif (IS_GSI_REG(offset))\n\t\toffset += uncore->gsi_offset;\n\n\treturn BSEARCH(offset,\n\t\t       uncore->shadowed_reg_table,\n\t\t       uncore->shadowed_reg_table_entries,\n\t\t       mmio_range_cmp);\n}\n\nstatic enum forcewake_domains\ngen6_reg_write_fw_domains(struct intel_uncore *uncore, i915_reg_t reg)\n{\n\treturn FORCEWAKE_RENDER;\n}\n\n#define __fwtable_reg_read_fw_domains(uncore, offset) \\\n({ \\\n\tenum forcewake_domains __fwd = 0; \\\n\tif (NEEDS_FORCE_WAKE((offset))) \\\n\t\t__fwd = find_fw_domain(uncore, offset); \\\n\t__fwd; \\\n})\n\n#define __fwtable_reg_write_fw_domains(uncore, offset) \\\n({ \\\n\tenum forcewake_domains __fwd = 0; \\\n\tconst u32 __offset = (offset); \\\n\tif (NEEDS_FORCE_WAKE((__offset)) && !is_shadowed(uncore, __offset)) \\\n\t\t__fwd = find_fw_domain(uncore, __offset); \\\n\t__fwd; \\\n})\n\n#define GEN_FW_RANGE(s, e, d) \\\n\t{ .start = (s), .end = (e), .domains = (d) }\n\n \n\nstatic const struct intel_forcewake_range __gen6_fw_ranges[] = {\n\tGEN_FW_RANGE(0x0, 0x3ffff, FORCEWAKE_RENDER),\n};\n\nstatic const struct intel_forcewake_range __vlv_fw_ranges[] = {\n\tGEN_FW_RANGE(0x2000, 0x3fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x5000, 0x7fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xb000, 0x11fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x12000, 0x13fff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x22000, 0x23fff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x2e000, 0x2ffff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x30000, 0x3ffff, FORCEWAKE_MEDIA),\n};\n\nstatic const struct intel_forcewake_range __chv_fw_ranges[] = {\n\tGEN_FW_RANGE(0x2000, 0x3fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x4000, 0x4fff, FORCEWAKE_RENDER | FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x5200, 0x7fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8000, 0x82ff, FORCEWAKE_RENDER | FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x8300, 0x84ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8500, 0x85ff, FORCEWAKE_RENDER | FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x8800, 0x88ff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x9000, 0xafff, FORCEWAKE_RENDER | FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0xb000, 0xb47f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xd000, 0xd7ff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0xe000, 0xe7ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xf000, 0xffff, FORCEWAKE_RENDER | FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x12000, 0x13fff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x1a000, 0x1bfff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x1e800, 0x1e9ff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x30000, 0x37fff, FORCEWAKE_MEDIA),\n};\n\nstatic const struct intel_forcewake_range __gen9_fw_ranges[] = {\n\tGEN_FW_RANGE(0x0, 0xaff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xb00, 0x1fff, 0),  \n\tGEN_FW_RANGE(0x2000, 0x26ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x2700, 0x2fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x3000, 0x3fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x4000, 0x51ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x5200, 0x7fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8000, 0x812f, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8130, 0x813f, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x8140, 0x815f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8160, 0x82ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8300, 0x84ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8500, 0x87ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8800, 0x89ff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x8a00, 0x8bff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8c00, 0x8cff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8d00, 0x93ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x9400, 0x97ff, FORCEWAKE_RENDER | FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x9800, 0xafff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xb000, 0xb47f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xb480, 0xcfff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xd000, 0xd7ff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0xd800, 0xdfff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xe000, 0xe8ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xe900, 0x11fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x12000, 0x13fff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x14000, 0x19fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x1a000, 0x1e9ff, FORCEWAKE_MEDIA),\n\tGEN_FW_RANGE(0x1ea00, 0x243ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x24400, 0x247ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x24800, 0x2ffff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x30000, 0x3ffff, FORCEWAKE_MEDIA),\n};\n\nstatic const struct intel_forcewake_range __gen11_fw_ranges[] = {\n\tGEN_FW_RANGE(0x0, 0x1fff, 0),  \n\tGEN_FW_RANGE(0x2000, 0x26ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x2700, 0x2fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x3000, 0x3fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x4000, 0x51ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x5200, 0x7fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8000, 0x813f, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8140, 0x815f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8160, 0x82ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8300, 0x84ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8500, 0x87ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8800, 0x8bff, 0),\n\tGEN_FW_RANGE(0x8c00, 0x8cff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8d00, 0x94cf, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x94d0, 0x955f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x9560, 0x95ff, 0),\n\tGEN_FW_RANGE(0x9600, 0xafff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xb000, 0xb47f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xb480, 0xdeff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xdf00, 0xe8ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xe900, 0x16dff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x16e00, 0x19fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x1a000, 0x23fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x24000, 0x2407f, 0),\n\tGEN_FW_RANGE(0x24080, 0x2417f, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x24180, 0x242ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x24300, 0x243ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x24400, 0x24fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x25000, 0x3ffff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x40000, 0x1bffff, 0),\n\tGEN_FW_RANGE(0x1c0000, 0x1c3fff, FORCEWAKE_MEDIA_VDBOX0),\n\tGEN_FW_RANGE(0x1c4000, 0x1c7fff, 0),\n\tGEN_FW_RANGE(0x1c8000, 0x1cffff, FORCEWAKE_MEDIA_VEBOX0),\n\tGEN_FW_RANGE(0x1d0000, 0x1d3fff, FORCEWAKE_MEDIA_VDBOX2),\n\tGEN_FW_RANGE(0x1d4000, 0x1dbfff, 0)\n};\n\nstatic const struct intel_forcewake_range __gen12_fw_ranges[] = {\n\tGEN_FW_RANGE(0x0, 0x1fff, 0),  \n\tGEN_FW_RANGE(0x2000, 0x26ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x2700, 0x27ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x2800, 0x2aff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x2b00, 0x2fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x3000, 0x3fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x4000, 0x51ff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x5200, 0x7fff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x8000, 0x813f, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8140, 0x815f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8160, 0x81ff, 0),  \n\tGEN_FW_RANGE(0x8200, 0x82ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8300, 0x84ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8500, 0x94cf, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x94d0, 0x955f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x9560, 0x97ff, 0),  \n\tGEN_FW_RANGE(0x9800, 0xafff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xb000, 0xb3ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xb400, 0xcfff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0xd000, 0xd7ff, 0),\n\tGEN_FW_RANGE(0xd800, 0xd8ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xd900, 0xdbff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xdc00, 0xefff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0xf000, 0x147ff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x14800, 0x1ffff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x20000, 0x20fff, FORCEWAKE_MEDIA_VDBOX0),\n\tGEN_FW_RANGE(0x21000, 0x21fff, FORCEWAKE_MEDIA_VDBOX2),\n\tGEN_FW_RANGE(0x22000, 0x23fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x24000, 0x2417f, 0),  \n\tGEN_FW_RANGE(0x24180, 0x249ff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x24a00, 0x251ff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x25200, 0x255ff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x25600, 0x2567f, FORCEWAKE_MEDIA_VDBOX0),\n\tGEN_FW_RANGE(0x25680, 0x259ff, FORCEWAKE_MEDIA_VDBOX2),  \n\tGEN_FW_RANGE(0x25a00, 0x25a7f, FORCEWAKE_MEDIA_VDBOX0),\n\tGEN_FW_RANGE(0x25a80, 0x2ffff, FORCEWAKE_MEDIA_VDBOX2),  \n\tGEN_FW_RANGE(0x30000, 0x3ffff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x40000, 0x1bffff, 0),\n\tGEN_FW_RANGE(0x1c0000, 0x1c3fff, FORCEWAKE_MEDIA_VDBOX0),  \n\tGEN_FW_RANGE(0x1c4000, 0x1c7fff, 0),\n\tGEN_FW_RANGE(0x1c8000, 0x1cbfff, FORCEWAKE_MEDIA_VEBOX0),  \n\tGEN_FW_RANGE(0x1cc000, 0x1cffff, FORCEWAKE_MEDIA_VDBOX0),  \n\tGEN_FW_RANGE(0x1d0000, 0x1d3fff, FORCEWAKE_MEDIA_VDBOX2),  \n};\n\n \n#define XEHP_FWRANGES(FW_RANGE_D800)\t\t\t\t\t\\\n\tGEN_FW_RANGE(0x0, 0x1fff, 0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x2000, 0x26ff, FORCEWAKE_RENDER),\t\t\t\t\\\n\tGEN_FW_RANGE(0x2700, 0x4aff, FORCEWAKE_GT),\t\t\t\t\\\n\tGEN_FW_RANGE(0x4b00, 0x51ff, 0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x5200, 0x7fff, FORCEWAKE_RENDER),\t\t\t\t\\\n\tGEN_FW_RANGE(0x8000, 0x813f, FORCEWAKE_GT),\t\t\t\t\\\n\tGEN_FW_RANGE(0x8140, 0x815f, FORCEWAKE_RENDER),\t\t\t\t\\\n\tGEN_FW_RANGE(0x8160, 0x81ff, 0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x8200, 0x82ff, FORCEWAKE_GT),\t\t\t\t\\\n\tGEN_FW_RANGE(0x8300, 0x84ff, FORCEWAKE_RENDER),\t\t\t\t\\\n\tGEN_FW_RANGE(0x8500, 0x8cff, FORCEWAKE_GT),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x8d00, 0x8fff, FORCEWAKE_RENDER),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x9000, 0x94cf, FORCEWAKE_GT),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x94d0, 0x955f, FORCEWAKE_RENDER),\t\t\t\t\\\n\tGEN_FW_RANGE(0x9560, 0x967f, 0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x9680, 0x97ff, FORCEWAKE_RENDER),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x9800, 0xcfff, FORCEWAKE_GT),  \t\t\t\t\t\t\\\n\tGEN_FW_RANGE(0xd000, 0xd7ff, 0),\t\t\t\t\t\\\n\tGEN_FW_RANGE(0xd800, 0xd87f, FW_RANGE_D800),\t\t\t\\\n\tGEN_FW_RANGE(0xd880, 0xdbff, FORCEWAKE_GT),\t\t\t\t\\\n\tGEN_FW_RANGE(0xdc00, 0xdcff, FORCEWAKE_RENDER),\t\t\t\t\\\n\tGEN_FW_RANGE(0xdd00, 0xde7f, FORCEWAKE_GT),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0xde80, 0xe8ff, FORCEWAKE_RENDER),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0xe900, 0xffff, FORCEWAKE_GT),  \t\t\t\t\t\t\\\n\tGEN_FW_RANGE(0x10000, 0x12fff, 0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x13000, 0x131ff, FORCEWAKE_MEDIA_VDBOX0),  \t\\\n\tGEN_FW_RANGE(0x13200, 0x13fff, FORCEWAKE_MEDIA_VDBOX2),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x14000, 0x141ff, FORCEWAKE_MEDIA_VDBOX0),  \t\\\n\tGEN_FW_RANGE(0x14200, 0x143ff, FORCEWAKE_MEDIA_VDBOX2),  \t\\\n\tGEN_FW_RANGE(0x14400, 0x145ff, FORCEWAKE_MEDIA_VDBOX4),  \t\\\n\tGEN_FW_RANGE(0x14600, 0x147ff, FORCEWAKE_MEDIA_VDBOX6),  \t\\\n\tGEN_FW_RANGE(0x14800, 0x14fff, FORCEWAKE_RENDER),\t\t\t\\\n\tGEN_FW_RANGE(0x15000, 0x16dff, FORCEWAKE_GT),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x16e00, 0x1ffff, FORCEWAKE_RENDER),\t\t\t\\\n\tGEN_FW_RANGE(0x20000, 0x21fff, FORCEWAKE_MEDIA_VDBOX0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x22000, 0x23fff, FORCEWAKE_GT),\t\t\t\t\\\n\tGEN_FW_RANGE(0x24000, 0x2417f, 0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x24180, 0x249ff, FORCEWAKE_GT),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x24a00, 0x251ff, FORCEWAKE_RENDER),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x25200, 0x25fff, FORCEWAKE_GT),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x26000, 0x2ffff, FORCEWAKE_RENDER),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x30000, 0x3ffff, FORCEWAKE_GT),\t\t\t\t\\\n\tGEN_FW_RANGE(0x40000, 0x1bffff, 0),\t\t\t\t\t\\\n\tGEN_FW_RANGE(0x1c0000, 0x1c3fff, FORCEWAKE_MEDIA_VDBOX0),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x1c4000, 0x1c7fff, FORCEWAKE_MEDIA_VDBOX1),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x1c8000, 0x1cbfff, FORCEWAKE_MEDIA_VEBOX0),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x1cc000, 0x1ccfff, FORCEWAKE_MEDIA_VDBOX0),\t\t\\\n\tGEN_FW_RANGE(0x1cd000, 0x1cdfff, FORCEWAKE_MEDIA_VDBOX2),\t\t\\\n\tGEN_FW_RANGE(0x1ce000, 0x1cefff, FORCEWAKE_MEDIA_VDBOX4),\t\t\\\n\tGEN_FW_RANGE(0x1cf000, 0x1cffff, FORCEWAKE_MEDIA_VDBOX6),\t\t\\\n\tGEN_FW_RANGE(0x1d0000, 0x1d3fff, FORCEWAKE_MEDIA_VDBOX2),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x1d4000, 0x1d7fff, FORCEWAKE_MEDIA_VDBOX3),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x1d8000, 0x1dffff, FORCEWAKE_MEDIA_VEBOX1),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x1e0000, 0x1e3fff, FORCEWAKE_MEDIA_VDBOX4),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x1e4000, 0x1e7fff, FORCEWAKE_MEDIA_VDBOX5),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x1e8000, 0x1effff, FORCEWAKE_MEDIA_VEBOX2),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x1f0000, 0x1f3fff, FORCEWAKE_MEDIA_VDBOX6),  \t\t\t\t\t\\\n\tGEN_FW_RANGE(0x1f4000, 0x1f7fff, FORCEWAKE_MEDIA_VDBOX7),  \t\t\t\t\\\n\tGEN_FW_RANGE(0x1f8000, 0x1fa0ff, FORCEWAKE_MEDIA_VEBOX3),\n\nstatic const struct intel_forcewake_range __xehp_fw_ranges[] = {\n\tXEHP_FWRANGES(FORCEWAKE_GT)\n};\n\nstatic const struct intel_forcewake_range __dg2_fw_ranges[] = {\n\tXEHP_FWRANGES(FORCEWAKE_RENDER)\n};\n\nstatic const struct intel_forcewake_range __pvc_fw_ranges[] = {\n\tGEN_FW_RANGE(0x0, 0xaff, 0),\n\tGEN_FW_RANGE(0xb00, 0xbff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xc00, 0xfff, 0),\n\tGEN_FW_RANGE(0x1000, 0x1fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x2000, 0x26ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x2700, 0x2fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x3000, 0x3fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x4000, 0x813f, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x8140, 0x817f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x8180, 0x81ff, 0),\n\tGEN_FW_RANGE(0x8200, 0x94cf, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x94d0, 0x955f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x9560, 0x967f, 0),  \n\tGEN_FW_RANGE(0x9680, 0x97ff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x9800, 0xcfff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0xd000, 0xd3ff, 0),\n\tGEN_FW_RANGE(0xd400, 0xdbff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xdc00, 0xdcff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xdd00, 0xde7f, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0xde80, 0xe8ff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0xe900, 0x11fff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x12000, 0x12fff, 0),  \n\tGEN_FW_RANGE(0x13000, 0x19fff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x1a000, 0x21fff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x22000, 0x23fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x24000, 0x2417f, 0),  \n\tGEN_FW_RANGE(0x24180, 0x25fff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x26000, 0x2ffff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x30000, 0x3ffff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x40000, 0x1bffff, 0),\n\tGEN_FW_RANGE(0x1c0000, 0x1c3fff, FORCEWAKE_MEDIA_VDBOX0),  \n\tGEN_FW_RANGE(0x1c4000, 0x1cffff, FORCEWAKE_MEDIA_VDBOX1),  \n\tGEN_FW_RANGE(0x1d0000, 0x23ffff, FORCEWAKE_MEDIA_VDBOX2),  \n\tGEN_FW_RANGE(0x240000, 0x3dffff, 0),\n\tGEN_FW_RANGE(0x3e0000, 0x3effff, FORCEWAKE_GT),\n};\n\nstatic const struct intel_forcewake_range __mtl_fw_ranges[] = {\n\tGEN_FW_RANGE(0x0, 0xaff, 0),\n\tGEN_FW_RANGE(0xb00, 0xbff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xc00, 0xfff, 0),\n\tGEN_FW_RANGE(0x1000, 0x1fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x2000, 0x26ff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x2700, 0x2fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x3000, 0x3fff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x4000, 0x51ff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x5200, 0x7fff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x8000, 0x813f, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x8140, 0x817f, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x8180, 0x81ff, 0),\n\tGEN_FW_RANGE(0x8200, 0x94cf, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x94d0, 0x955f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0x9560, 0x967f, 0),  \n\tGEN_FW_RANGE(0x9680, 0x97ff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x9800, 0xcfff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0xd000, 0xd7ff, 0),  \n\tGEN_FW_RANGE(0xd800, 0xd87f, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xd880, 0xdbff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xdc00, 0xdcff, FORCEWAKE_RENDER),\n\tGEN_FW_RANGE(0xdd00, 0xde7f, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0xde80, 0xe8ff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0xe900, 0xe9ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0xea00, 0x147ff, 0),  \n\tGEN_FW_RANGE(0x14800, 0x19fff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x1a000, 0x21fff, FORCEWAKE_RENDER),  \n\tGEN_FW_RANGE(0x22000, 0x23fff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x24000, 0x2ffff, 0),  \n\tGEN_FW_RANGE(0x30000, 0x3ffff, FORCEWAKE_GT)\n};\n\n \nstatic const struct intel_forcewake_range __xelpmp_fw_ranges[] = {\n\tGEN_FW_RANGE(0x0, 0x115fff, 0),  \n\tGEN_FW_RANGE(0x116000, 0x11ffff, FORCEWAKE_GSC),  \n\tGEN_FW_RANGE(0x120000, 0x1bffff, 0),  \n\tGEN_FW_RANGE(0x1c0000, 0x1c7fff, FORCEWAKE_MEDIA_VDBOX0),  \n\tGEN_FW_RANGE(0x1c8000, 0x1cbfff, FORCEWAKE_MEDIA_VEBOX0),  \n\tGEN_FW_RANGE(0x1cc000, 0x1cffff, FORCEWAKE_MEDIA_VDBOX0),  \n\tGEN_FW_RANGE(0x1d0000, 0x1d7fff, FORCEWAKE_MEDIA_VDBOX2),  \n\tGEN_FW_RANGE(0x1d8000, 0x1da0ff, FORCEWAKE_MEDIA_VEBOX1),\n\tGEN_FW_RANGE(0x1da100, 0x380aff, 0),  \n\tGEN_FW_RANGE(0x380b00, 0x380bff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x380c00, 0x380fff, 0),\n\tGEN_FW_RANGE(0x381000, 0x38817f, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x388180, 0x3882ff, 0),  \n\tGEN_FW_RANGE(0x388300, 0x38955f, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x389560, 0x389fff, 0),  \n\tGEN_FW_RANGE(0x38a000, 0x38cfff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x38d000, 0x38d11f, 0),\n\tGEN_FW_RANGE(0x38d120, 0x391fff, FORCEWAKE_GT),  \n\tGEN_FW_RANGE(0x392000, 0x392fff, 0),  \n\tGEN_FW_RANGE(0x393000, 0x3931ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x393200, 0x39323f, FORCEWAKE_ALL),  \n\tGEN_FW_RANGE(0x393240, 0x3933ff, FORCEWAKE_GT),\n\tGEN_FW_RANGE(0x393400, 0x3934ff, FORCEWAKE_ALL),  \n\tGEN_FW_RANGE(0x393500, 0x393c7f, 0),  \n\tGEN_FW_RANGE(0x393c80, 0x393dff, FORCEWAKE_GT),\n};\n\nstatic void\nilk_dummy_write(struct intel_uncore *uncore)\n{\n\t \n\t__raw_uncore_write32(uncore, RING_MI_MODE(RENDER_RING_BASE), 0);\n}\n\nstatic void\n__unclaimed_reg_debug(struct intel_uncore *uncore,\n\t\t      const i915_reg_t reg,\n\t\t      const bool read)\n{\n\tif (drm_WARN(&uncore->i915->drm,\n\t\t     check_for_unclaimed_mmio(uncore),\n\t\t     \"Unclaimed %s register 0x%x\\n\",\n\t\t     read ? \"read from\" : \"write to\",\n\t\t     i915_mmio_reg_offset(reg)))\n\t\t \n\t\tuncore->i915->params.mmio_debug--;\n}\n\nstatic void\n__unclaimed_previous_reg_debug(struct intel_uncore *uncore,\n\t\t\t       const i915_reg_t reg,\n\t\t\t       const bool read)\n{\n\tif (check_for_unclaimed_mmio(uncore))\n\t\tdrm_dbg(&uncore->i915->drm,\n\t\t\t\"Unclaimed access detected before %s register 0x%x\\n\",\n\t\t\tread ? \"read from\" : \"write to\",\n\t\t\ti915_mmio_reg_offset(reg));\n}\n\nstatic inline bool __must_check\nunclaimed_reg_debug_header(struct intel_uncore *uncore,\n\t\t\t   const i915_reg_t reg, const bool read)\n{\n\tif (likely(!uncore->i915->params.mmio_debug) || !uncore->debug)\n\t\treturn false;\n\n\t \n\tlockdep_assert_held(&uncore->lock);\n\n\tspin_lock(&uncore->debug->lock);\n\t__unclaimed_previous_reg_debug(uncore, reg, read);\n\n\treturn true;\n}\n\nstatic inline void\nunclaimed_reg_debug_footer(struct intel_uncore *uncore,\n\t\t\t   const i915_reg_t reg, const bool read)\n{\n\t \n\tlockdep_assert_held(&uncore->lock);\n\n\t__unclaimed_reg_debug(uncore, reg, read);\n\tspin_unlock(&uncore->debug->lock);\n}\n\n#define __vgpu_read(x) \\\nstatic u##x \\\nvgpu_read##x(struct intel_uncore *uncore, i915_reg_t reg, bool trace) { \\\n\tu##x val = __raw_uncore_read##x(uncore, reg); \\\n\ttrace_i915_reg_rw(false, reg, val, sizeof(val), trace); \\\n\treturn val; \\\n}\n__vgpu_read(8)\n__vgpu_read(16)\n__vgpu_read(32)\n__vgpu_read(64)\n\n#define GEN2_READ_HEADER(x) \\\n\tu##x val = 0; \\\n\tassert_rpm_wakelock_held(uncore->rpm);\n\n#define GEN2_READ_FOOTER \\\n\ttrace_i915_reg_rw(false, reg, val, sizeof(val), trace); \\\n\treturn val\n\n#define __gen2_read(x) \\\nstatic u##x \\\ngen2_read##x(struct intel_uncore *uncore, i915_reg_t reg, bool trace) { \\\n\tGEN2_READ_HEADER(x); \\\n\tval = __raw_uncore_read##x(uncore, reg); \\\n\tGEN2_READ_FOOTER; \\\n}\n\n#define __gen5_read(x) \\\nstatic u##x \\\ngen5_read##x(struct intel_uncore *uncore, i915_reg_t reg, bool trace) { \\\n\tGEN2_READ_HEADER(x); \\\n\tilk_dummy_write(uncore); \\\n\tval = __raw_uncore_read##x(uncore, reg); \\\n\tGEN2_READ_FOOTER; \\\n}\n\n__gen5_read(8)\n__gen5_read(16)\n__gen5_read(32)\n__gen5_read(64)\n__gen2_read(8)\n__gen2_read(16)\n__gen2_read(32)\n__gen2_read(64)\n\n#undef __gen5_read\n#undef __gen2_read\n\n#undef GEN2_READ_FOOTER\n#undef GEN2_READ_HEADER\n\n#define GEN6_READ_HEADER(x) \\\n\tu32 offset = i915_mmio_reg_offset(reg); \\\n\tunsigned long irqflags; \\\n\tbool unclaimed_reg_debug; \\\n\tu##x val = 0; \\\n\tassert_rpm_wakelock_held(uncore->rpm); \\\n\tspin_lock_irqsave(&uncore->lock, irqflags); \\\n\tunclaimed_reg_debug = unclaimed_reg_debug_header(uncore, reg, true)\n\n#define GEN6_READ_FOOTER \\\n\tif (unclaimed_reg_debug) \\\n\t\tunclaimed_reg_debug_footer(uncore, reg, true);\t\\\n\tspin_unlock_irqrestore(&uncore->lock, irqflags); \\\n\ttrace_i915_reg_rw(false, reg, val, sizeof(val), trace); \\\n\treturn val\n\nstatic noinline void ___force_wake_auto(struct intel_uncore *uncore,\n\t\t\t\t\tenum forcewake_domains fw_domains)\n{\n\tstruct intel_uncore_forcewake_domain *domain;\n\tunsigned int tmp;\n\n\tGEM_BUG_ON(fw_domains & ~uncore->fw_domains);\n\n\tfor_each_fw_domain_masked(domain, fw_domains, uncore, tmp)\n\t\tfw_domain_arm_timer(domain);\n\n\tfw_domains_get(uncore, fw_domains);\n}\n\nstatic inline void __force_wake_auto(struct intel_uncore *uncore,\n\t\t\t\t     enum forcewake_domains fw_domains)\n{\n\tGEM_BUG_ON(!fw_domains);\n\n\t \n\tfw_domains &= uncore->fw_domains;\n\tfw_domains &= ~uncore->fw_domains_active;\n\n\tif (fw_domains)\n\t\t___force_wake_auto(uncore, fw_domains);\n}\n\n#define __gen_fwtable_read(x) \\\nstatic u##x \\\nfwtable_read##x(struct intel_uncore *uncore, i915_reg_t reg, bool trace) \\\n{ \\\n\tenum forcewake_domains fw_engine; \\\n\tGEN6_READ_HEADER(x); \\\n\tfw_engine = __fwtable_reg_read_fw_domains(uncore, offset); \\\n\tif (fw_engine) \\\n\t\t__force_wake_auto(uncore, fw_engine); \\\n\tval = __raw_uncore_read##x(uncore, reg); \\\n\tGEN6_READ_FOOTER; \\\n}\n\nstatic enum forcewake_domains\nfwtable_reg_read_fw_domains(struct intel_uncore *uncore, i915_reg_t reg) {\n\treturn __fwtable_reg_read_fw_domains(uncore, i915_mmio_reg_offset(reg));\n}\n\n__gen_fwtable_read(8)\n__gen_fwtable_read(16)\n__gen_fwtable_read(32)\n__gen_fwtable_read(64)\n\n#undef __gen_fwtable_read\n#undef GEN6_READ_FOOTER\n#undef GEN6_READ_HEADER\n\n#define GEN2_WRITE_HEADER \\\n\ttrace_i915_reg_rw(true, reg, val, sizeof(val), trace); \\\n\tassert_rpm_wakelock_held(uncore->rpm); \\\n\n#define GEN2_WRITE_FOOTER\n\n#define __gen2_write(x) \\\nstatic void \\\ngen2_write##x(struct intel_uncore *uncore, i915_reg_t reg, u##x val, bool trace) { \\\n\tGEN2_WRITE_HEADER; \\\n\t__raw_uncore_write##x(uncore, reg, val); \\\n\tGEN2_WRITE_FOOTER; \\\n}\n\n#define __gen5_write(x) \\\nstatic void \\\ngen5_write##x(struct intel_uncore *uncore, i915_reg_t reg, u##x val, bool trace) { \\\n\tGEN2_WRITE_HEADER; \\\n\tilk_dummy_write(uncore); \\\n\t__raw_uncore_write##x(uncore, reg, val); \\\n\tGEN2_WRITE_FOOTER; \\\n}\n\n__gen5_write(8)\n__gen5_write(16)\n__gen5_write(32)\n__gen2_write(8)\n__gen2_write(16)\n__gen2_write(32)\n\n#undef __gen5_write\n#undef __gen2_write\n\n#undef GEN2_WRITE_FOOTER\n#undef GEN2_WRITE_HEADER\n\n#define GEN6_WRITE_HEADER \\\n\tu32 offset = i915_mmio_reg_offset(reg); \\\n\tunsigned long irqflags; \\\n\tbool unclaimed_reg_debug; \\\n\ttrace_i915_reg_rw(true, reg, val, sizeof(val), trace); \\\n\tassert_rpm_wakelock_held(uncore->rpm); \\\n\tspin_lock_irqsave(&uncore->lock, irqflags); \\\n\tunclaimed_reg_debug = unclaimed_reg_debug_header(uncore, reg, false)\n\n#define GEN6_WRITE_FOOTER \\\n\tif (unclaimed_reg_debug) \\\n\t\tunclaimed_reg_debug_footer(uncore, reg, false); \\\n\tspin_unlock_irqrestore(&uncore->lock, irqflags)\n\n#define __gen6_write(x) \\\nstatic void \\\ngen6_write##x(struct intel_uncore *uncore, i915_reg_t reg, u##x val, bool trace) { \\\n\tGEN6_WRITE_HEADER; \\\n\tif (NEEDS_FORCE_WAKE(offset)) \\\n\t\t__gen6_gt_wait_for_fifo(uncore); \\\n\t__raw_uncore_write##x(uncore, reg, val); \\\n\tGEN6_WRITE_FOOTER; \\\n}\n__gen6_write(8)\n__gen6_write(16)\n__gen6_write(32)\n\n#define __gen_fwtable_write(x) \\\nstatic void \\\nfwtable_write##x(struct intel_uncore *uncore, i915_reg_t reg, u##x val, bool trace) { \\\n\tenum forcewake_domains fw_engine; \\\n\tGEN6_WRITE_HEADER; \\\n\tfw_engine = __fwtable_reg_write_fw_domains(uncore, offset); \\\n\tif (fw_engine) \\\n\t\t__force_wake_auto(uncore, fw_engine); \\\n\t__raw_uncore_write##x(uncore, reg, val); \\\n\tGEN6_WRITE_FOOTER; \\\n}\n\nstatic enum forcewake_domains\nfwtable_reg_write_fw_domains(struct intel_uncore *uncore, i915_reg_t reg)\n{\n\treturn __fwtable_reg_write_fw_domains(uncore, i915_mmio_reg_offset(reg));\n}\n\n__gen_fwtable_write(8)\n__gen_fwtable_write(16)\n__gen_fwtable_write(32)\n\n#undef __gen_fwtable_write\n#undef GEN6_WRITE_FOOTER\n#undef GEN6_WRITE_HEADER\n\n#define __vgpu_write(x) \\\nstatic void \\\nvgpu_write##x(struct intel_uncore *uncore, i915_reg_t reg, u##x val, bool trace) { \\\n\ttrace_i915_reg_rw(true, reg, val, sizeof(val), trace); \\\n\t__raw_uncore_write##x(uncore, reg, val); \\\n}\n__vgpu_write(8)\n__vgpu_write(16)\n__vgpu_write(32)\n\n#define ASSIGN_RAW_WRITE_MMIO_VFUNCS(uncore, x) \\\ndo { \\\n\t(uncore)->funcs.mmio_writeb = x##_write8; \\\n\t(uncore)->funcs.mmio_writew = x##_write16; \\\n\t(uncore)->funcs.mmio_writel = x##_write32; \\\n} while (0)\n\n#define ASSIGN_RAW_READ_MMIO_VFUNCS(uncore, x) \\\ndo { \\\n\t(uncore)->funcs.mmio_readb = x##_read8; \\\n\t(uncore)->funcs.mmio_readw = x##_read16; \\\n\t(uncore)->funcs.mmio_readl = x##_read32; \\\n\t(uncore)->funcs.mmio_readq = x##_read64; \\\n} while (0)\n\n#define ASSIGN_WRITE_MMIO_VFUNCS(uncore, x) \\\ndo { \\\n\tASSIGN_RAW_WRITE_MMIO_VFUNCS((uncore), x); \\\n\t(uncore)->funcs.write_fw_domains = x##_reg_write_fw_domains; \\\n} while (0)\n\n#define ASSIGN_READ_MMIO_VFUNCS(uncore, x) \\\ndo { \\\n\tASSIGN_RAW_READ_MMIO_VFUNCS(uncore, x); \\\n\t(uncore)->funcs.read_fw_domains = x##_reg_read_fw_domains; \\\n} while (0)\n\nstatic int __fw_domain_init(struct intel_uncore *uncore,\n\t\t\t    enum forcewake_domain_id domain_id,\n\t\t\t    i915_reg_t reg_set,\n\t\t\t    i915_reg_t reg_ack)\n{\n\tstruct intel_uncore_forcewake_domain *d;\n\n\tGEM_BUG_ON(domain_id >= FW_DOMAIN_ID_COUNT);\n\tGEM_BUG_ON(uncore->fw_domain[domain_id]);\n\n\tif (i915_inject_probe_failure(uncore->i915))\n\t\treturn -ENOMEM;\n\n\td = kzalloc(sizeof(*d), GFP_KERNEL);\n\tif (!d)\n\t\treturn -ENOMEM;\n\n\tdrm_WARN_ON(&uncore->i915->drm, !i915_mmio_reg_valid(reg_set));\n\tdrm_WARN_ON(&uncore->i915->drm, !i915_mmio_reg_valid(reg_ack));\n\n\td->uncore = uncore;\n\td->wake_count = 0;\n\td->reg_set = uncore->regs + i915_mmio_reg_offset(reg_set) + uncore->gsi_offset;\n\td->reg_ack = uncore->regs + i915_mmio_reg_offset(reg_ack) + uncore->gsi_offset;\n\n\td->id = domain_id;\n\n\tBUILD_BUG_ON(FORCEWAKE_RENDER != (1 << FW_DOMAIN_ID_RENDER));\n\tBUILD_BUG_ON(FORCEWAKE_GT != (1 << FW_DOMAIN_ID_GT));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA != (1 << FW_DOMAIN_ID_MEDIA));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX0 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX0));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX1 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX1));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX2 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX2));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX3 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX3));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX4 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX4));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX5 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX5));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX6 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX6));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VDBOX7 != (1 << FW_DOMAIN_ID_MEDIA_VDBOX7));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VEBOX0 != (1 << FW_DOMAIN_ID_MEDIA_VEBOX0));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VEBOX1 != (1 << FW_DOMAIN_ID_MEDIA_VEBOX1));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VEBOX2 != (1 << FW_DOMAIN_ID_MEDIA_VEBOX2));\n\tBUILD_BUG_ON(FORCEWAKE_MEDIA_VEBOX3 != (1 << FW_DOMAIN_ID_MEDIA_VEBOX3));\n\tBUILD_BUG_ON(FORCEWAKE_GSC != (1 << FW_DOMAIN_ID_GSC));\n\n\td->mask = BIT(domain_id);\n\n\thrtimer_init(&d->timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\td->timer.function = intel_uncore_fw_release_timer;\n\n\tuncore->fw_domains |= BIT(domain_id);\n\n\tfw_domain_reset(d);\n\n\tuncore->fw_domain[domain_id] = d;\n\n\treturn 0;\n}\n\nstatic void fw_domain_fini(struct intel_uncore *uncore,\n\t\t\t   enum forcewake_domain_id domain_id)\n{\n\tstruct intel_uncore_forcewake_domain *d;\n\n\tGEM_BUG_ON(domain_id >= FW_DOMAIN_ID_COUNT);\n\n\td = fetch_and_zero(&uncore->fw_domain[domain_id]);\n\tif (!d)\n\t\treturn;\n\n\tuncore->fw_domains &= ~BIT(domain_id);\n\tdrm_WARN_ON(&uncore->i915->drm, d->wake_count);\n\tdrm_WARN_ON(&uncore->i915->drm, hrtimer_cancel(&d->timer));\n\tkfree(d);\n}\n\nstatic void intel_uncore_fw_domains_fini(struct intel_uncore *uncore)\n{\n\tstruct intel_uncore_forcewake_domain *d;\n\tint tmp;\n\n\tfor_each_fw_domain(d, uncore, tmp)\n\t\tfw_domain_fini(uncore, d->id);\n}\n\nstatic const struct intel_uncore_fw_get uncore_get_fallback = {\n\t.force_wake_get = fw_domains_get_with_fallback\n};\n\nstatic const struct intel_uncore_fw_get uncore_get_normal = {\n\t.force_wake_get = fw_domains_get_normal,\n};\n\nstatic const struct intel_uncore_fw_get uncore_get_thread_status = {\n\t.force_wake_get = fw_domains_get_with_thread_status\n};\n\nstatic int intel_uncore_fw_domains_init(struct intel_uncore *uncore)\n{\n\tstruct drm_i915_private *i915 = uncore->i915;\n\tint ret = 0;\n\n\tGEM_BUG_ON(!intel_uncore_has_forcewake(uncore));\n\n#define fw_domain_init(uncore__, id__, set__, ack__) \\\n\t(ret ?: (ret = __fw_domain_init((uncore__), (id__), (set__), (ack__))))\n\n\tif (GRAPHICS_VER(i915) >= 11) {\n\t\tintel_engine_mask_t emask;\n\t\tint i;\n\n\t\t \n\t\temask = uncore->gt->info.engine_mask;\n\n\t\tuncore->fw_get_funcs = &uncore_get_fallback;\n\t\tif (GRAPHICS_VER_FULL(i915) >= IP_VER(12, 70))\n\t\t\tfw_domain_init(uncore, FW_DOMAIN_ID_GT,\n\t\t\t\t       FORCEWAKE_GT_GEN9,\n\t\t\t\t       FORCEWAKE_ACK_GT_MTL);\n\t\telse\n\t\t\tfw_domain_init(uncore, FW_DOMAIN_ID_GT,\n\t\t\t\t       FORCEWAKE_GT_GEN9,\n\t\t\t\t       FORCEWAKE_ACK_GT_GEN9);\n\n\t\tif (RCS_MASK(uncore->gt) || CCS_MASK(uncore->gt))\n\t\t\tfw_domain_init(uncore, FW_DOMAIN_ID_RENDER,\n\t\t\t\t       FORCEWAKE_RENDER_GEN9,\n\t\t\t\t       FORCEWAKE_ACK_RENDER_GEN9);\n\n\t\tfor (i = 0; i < I915_MAX_VCS; i++) {\n\t\t\tif (!__HAS_ENGINE(emask, _VCS(i)))\n\t\t\t\tcontinue;\n\n\t\t\tfw_domain_init(uncore, FW_DOMAIN_ID_MEDIA_VDBOX0 + i,\n\t\t\t\t       FORCEWAKE_MEDIA_VDBOX_GEN11(i),\n\t\t\t\t       FORCEWAKE_ACK_MEDIA_VDBOX_GEN11(i));\n\t\t}\n\t\tfor (i = 0; i < I915_MAX_VECS; i++) {\n\t\t\tif (!__HAS_ENGINE(emask, _VECS(i)))\n\t\t\t\tcontinue;\n\n\t\t\tfw_domain_init(uncore, FW_DOMAIN_ID_MEDIA_VEBOX0 + i,\n\t\t\t\t       FORCEWAKE_MEDIA_VEBOX_GEN11(i),\n\t\t\t\t       FORCEWAKE_ACK_MEDIA_VEBOX_GEN11(i));\n\t\t}\n\n\t\tif (uncore->gt->type == GT_MEDIA)\n\t\t\tfw_domain_init(uncore, FW_DOMAIN_ID_GSC,\n\t\t\t\t       FORCEWAKE_REQ_GSC, FORCEWAKE_ACK_GSC);\n\t} else if (IS_GRAPHICS_VER(i915, 9, 10)) {\n\t\tuncore->fw_get_funcs = &uncore_get_fallback;\n\t\tfw_domain_init(uncore, FW_DOMAIN_ID_RENDER,\n\t\t\t       FORCEWAKE_RENDER_GEN9,\n\t\t\t       FORCEWAKE_ACK_RENDER_GEN9);\n\t\tfw_domain_init(uncore, FW_DOMAIN_ID_GT,\n\t\t\t       FORCEWAKE_GT_GEN9,\n\t\t\t       FORCEWAKE_ACK_GT_GEN9);\n\t\tfw_domain_init(uncore, FW_DOMAIN_ID_MEDIA,\n\t\t\t       FORCEWAKE_MEDIA_GEN9, FORCEWAKE_ACK_MEDIA_GEN9);\n\t} else if (IS_VALLEYVIEW(i915) || IS_CHERRYVIEW(i915)) {\n\t\tuncore->fw_get_funcs = &uncore_get_normal;\n\t\tfw_domain_init(uncore, FW_DOMAIN_ID_RENDER,\n\t\t\t       FORCEWAKE_VLV, FORCEWAKE_ACK_VLV);\n\t\tfw_domain_init(uncore, FW_DOMAIN_ID_MEDIA,\n\t\t\t       FORCEWAKE_MEDIA_VLV, FORCEWAKE_ACK_MEDIA_VLV);\n\t} else if (IS_HASWELL(i915) || IS_BROADWELL(i915)) {\n\t\tuncore->fw_get_funcs = &uncore_get_thread_status;\n\t\tfw_domain_init(uncore, FW_DOMAIN_ID_RENDER,\n\t\t\t       FORCEWAKE_MT, FORCEWAKE_ACK_HSW);\n\t} else if (IS_IVYBRIDGE(i915)) {\n\t\tu32 ecobus;\n\n\t\t \n\n\t\t \n\t\tuncore->fw_get_funcs = &uncore_get_thread_status;\n\n\t\t \n\n\t\t__raw_uncore_write32(uncore, FORCEWAKE, 0);\n\t\t__raw_posting_read(uncore, ECOBUS);\n\n\t\tret = __fw_domain_init(uncore, FW_DOMAIN_ID_RENDER,\n\t\t\t\t       FORCEWAKE_MT, FORCEWAKE_MT_ACK);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tspin_lock_irq(&uncore->lock);\n\t\tfw_domains_get_with_thread_status(uncore, FORCEWAKE_RENDER);\n\t\tecobus = __raw_uncore_read32(uncore, ECOBUS);\n\t\tfw_domains_put(uncore, FORCEWAKE_RENDER);\n\t\tspin_unlock_irq(&uncore->lock);\n\n\t\tif (!(ecobus & FORCEWAKE_MT_ENABLE)) {\n\t\t\tdrm_info(&i915->drm, \"No MT forcewake available on Ivybridge, this can result in issues\\n\");\n\t\t\tdrm_info(&i915->drm, \"when using vblank-synced partial screen updates.\\n\");\n\t\t\tfw_domain_fini(uncore, FW_DOMAIN_ID_RENDER);\n\t\t\tfw_domain_init(uncore, FW_DOMAIN_ID_RENDER,\n\t\t\t\t       FORCEWAKE, FORCEWAKE_ACK);\n\t\t}\n\t} else if (GRAPHICS_VER(i915) == 6) {\n\t\tuncore->fw_get_funcs = &uncore_get_thread_status;\n\t\tfw_domain_init(uncore, FW_DOMAIN_ID_RENDER,\n\t\t\t       FORCEWAKE, FORCEWAKE_ACK);\n\t}\n\n#undef fw_domain_init\n\n\t \n\tdrm_WARN_ON(&i915->drm, !ret && uncore->fw_domains == 0);\n\nout:\n\tif (ret)\n\t\tintel_uncore_fw_domains_fini(uncore);\n\n\treturn ret;\n}\n\n#define ASSIGN_FW_DOMAINS_TABLE(uncore, d) \\\n{ \\\n\t(uncore)->fw_domains_table = \\\n\t\t\t(struct intel_forcewake_range *)(d); \\\n\t(uncore)->fw_domains_table_entries = ARRAY_SIZE((d)); \\\n}\n\n#define ASSIGN_SHADOW_TABLE(uncore, d) \\\n{ \\\n\t(uncore)->shadowed_reg_table = d; \\\n\t(uncore)->shadowed_reg_table_entries = ARRAY_SIZE((d)); \\\n}\n\nstatic int i915_pmic_bus_access_notifier(struct notifier_block *nb,\n\t\t\t\t\t unsigned long action, void *data)\n{\n\tstruct intel_uncore *uncore = container_of(nb,\n\t\t\tstruct intel_uncore, pmic_bus_access_nb);\n\n\tswitch (action) {\n\tcase MBI_PMIC_BUS_ACCESS_BEGIN:\n\t\t \n\t\tdisable_rpm_wakeref_asserts(uncore->rpm);\n\t\tintel_uncore_forcewake_get(uncore, FORCEWAKE_ALL);\n\t\tenable_rpm_wakeref_asserts(uncore->rpm);\n\t\tbreak;\n\tcase MBI_PMIC_BUS_ACCESS_END:\n\t\tintel_uncore_forcewake_put(uncore, FORCEWAKE_ALL);\n\t\tbreak;\n\t}\n\n\treturn NOTIFY_OK;\n}\n\nstatic void uncore_unmap_mmio(struct drm_device *drm, void *regs)\n{\n\tiounmap((void __iomem *)regs);\n}\n\nint intel_uncore_setup_mmio(struct intel_uncore *uncore, phys_addr_t phys_addr)\n{\n\tstruct drm_i915_private *i915 = uncore->i915;\n\tint mmio_size;\n\n\t \n\tif (IS_DGFX(i915) || GRAPHICS_VER_FULL(i915) >= IP_VER(12, 70))\n\t\tmmio_size = 4 * 1024 * 1024;\n\telse if (GRAPHICS_VER(i915) >= 5)\n\t\tmmio_size = 2 * 1024 * 1024;\n\telse\n\t\tmmio_size = 512 * 1024;\n\n\tuncore->regs = ioremap(phys_addr, mmio_size);\n\tif (uncore->regs == NULL) {\n\t\tdrm_err(&i915->drm, \"failed to map registers\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn drmm_add_action_or_reset(&i915->drm, uncore_unmap_mmio,\n\t\t\t\t\t(void __force *)uncore->regs);\n}\n\nvoid intel_uncore_init_early(struct intel_uncore *uncore,\n\t\t\t     struct intel_gt *gt)\n{\n\tspin_lock_init(&uncore->lock);\n\tuncore->i915 = gt->i915;\n\tuncore->gt = gt;\n\tuncore->rpm = &gt->i915->runtime_pm;\n}\n\nstatic void uncore_raw_init(struct intel_uncore *uncore)\n{\n\tGEM_BUG_ON(intel_uncore_has_forcewake(uncore));\n\n\tif (intel_vgpu_active(uncore->i915)) {\n\t\tASSIGN_RAW_WRITE_MMIO_VFUNCS(uncore, vgpu);\n\t\tASSIGN_RAW_READ_MMIO_VFUNCS(uncore, vgpu);\n\t} else if (GRAPHICS_VER(uncore->i915) == 5) {\n\t\tASSIGN_RAW_WRITE_MMIO_VFUNCS(uncore, gen5);\n\t\tASSIGN_RAW_READ_MMIO_VFUNCS(uncore, gen5);\n\t} else {\n\t\tASSIGN_RAW_WRITE_MMIO_VFUNCS(uncore, gen2);\n\t\tASSIGN_RAW_READ_MMIO_VFUNCS(uncore, gen2);\n\t}\n}\n\nstatic int uncore_media_forcewake_init(struct intel_uncore *uncore)\n{\n\tstruct drm_i915_private *i915 = uncore->i915;\n\n\tif (MEDIA_VER(i915) >= 13) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __xelpmp_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, xelpmp_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else {\n\t\tMISSING_CASE(MEDIA_VER(i915));\n\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n\nstatic int uncore_forcewake_init(struct intel_uncore *uncore)\n{\n\tstruct drm_i915_private *i915 = uncore->i915;\n\tint ret;\n\n\tGEM_BUG_ON(!intel_uncore_has_forcewake(uncore));\n\n\tret = intel_uncore_fw_domains_init(uncore);\n\tif (ret)\n\t\treturn ret;\n\tforcewake_early_sanitize(uncore, 0);\n\n\tASSIGN_READ_MMIO_VFUNCS(uncore, fwtable);\n\n\tif (uncore->gt->type == GT_MEDIA)\n\t\treturn uncore_media_forcewake_init(uncore);\n\n\tif (GRAPHICS_VER_FULL(i915) >= IP_VER(12, 70)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __mtl_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, mtl_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (GRAPHICS_VER_FULL(i915) >= IP_VER(12, 60)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __pvc_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, pvc_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (GRAPHICS_VER_FULL(i915) >= IP_VER(12, 55)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __dg2_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, dg2_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (GRAPHICS_VER_FULL(i915) >= IP_VER(12, 50)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __xehp_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, gen12_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (GRAPHICS_VER(i915) >= 12) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __gen12_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, gen12_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (GRAPHICS_VER(i915) == 11) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __gen11_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, gen11_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (IS_GRAPHICS_VER(i915, 9, 10)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __gen9_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, gen8_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (IS_CHERRYVIEW(i915)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __chv_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, gen8_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (GRAPHICS_VER(i915) == 8) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __gen6_fw_ranges);\n\t\tASSIGN_SHADOW_TABLE(uncore, gen8_shadowed_regs);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, fwtable);\n\t} else if (IS_VALLEYVIEW(i915)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __vlv_fw_ranges);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, gen6);\n\t} else if (IS_GRAPHICS_VER(i915, 6, 7)) {\n\t\tASSIGN_FW_DOMAINS_TABLE(uncore, __gen6_fw_ranges);\n\t\tASSIGN_WRITE_MMIO_VFUNCS(uncore, gen6);\n\t}\n\n\tuncore->pmic_bus_access_nb.notifier_call = i915_pmic_bus_access_notifier;\n\tiosf_mbi_register_pmic_bus_access_notifier(&uncore->pmic_bus_access_nb);\n\n\treturn 0;\n}\n\nstatic int sanity_check_mmio_access(struct intel_uncore *uncore)\n{\n\tstruct drm_i915_private *i915 = uncore->i915;\n\n\tif (GRAPHICS_VER(i915) < 8)\n\t\treturn 0;\n\n\t \n#define COND (__raw_uncore_read32(uncore, FORCEWAKE_MT) != ~0)\n\tif (wait_for(COND, 2000) == -ETIMEDOUT) {\n\t\tdrm_err(&i915->drm, \"Device is non-operational; MMIO access returns 0xFFFFFFFF!\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nint intel_uncore_init_mmio(struct intel_uncore *uncore)\n{\n\tstruct drm_i915_private *i915 = uncore->i915;\n\tint ret;\n\n\tret = sanity_check_mmio_access(uncore);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (IS_DGFX(i915) &&\n\t    !(__raw_uncore_read32(uncore, GU_CNTL) & LMEM_INIT)) {\n\t\tdrm_err(&i915->drm, \"LMEM not initialized by firmware\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (GRAPHICS_VER(i915) > 5 && !intel_vgpu_active(i915))\n\t\tuncore->flags |= UNCORE_HAS_FORCEWAKE;\n\n\tif (!intel_uncore_has_forcewake(uncore)) {\n\t\tuncore_raw_init(uncore);\n\t} else {\n\t\tret = uncore_forcewake_init(uncore);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t \n\tGEM_BUG_ON(intel_uncore_has_forcewake(uncore) != !!uncore->fw_get_funcs);\n\tGEM_BUG_ON(intel_uncore_has_forcewake(uncore) != !!uncore->funcs.read_fw_domains);\n\tGEM_BUG_ON(intel_uncore_has_forcewake(uncore) != !!uncore->funcs.write_fw_domains);\n\n\tif (HAS_FPGA_DBG_UNCLAIMED(i915))\n\t\tuncore->flags |= UNCORE_HAS_FPGA_DBG_UNCLAIMED;\n\n\tif (IS_VALLEYVIEW(i915) || IS_CHERRYVIEW(i915))\n\t\tuncore->flags |= UNCORE_HAS_DBG_UNCLAIMED;\n\n\tif (IS_GRAPHICS_VER(i915, 6, 7))\n\t\tuncore->flags |= UNCORE_HAS_FIFO;\n\n\t \n\tif (intel_uncore_unclaimed_mmio(uncore))\n\t\tdrm_dbg(&i915->drm, \"unclaimed mmio detected on uncore init, clearing\\n\");\n\n\treturn 0;\n}\n\n \nvoid intel_uncore_prune_engine_fw_domains(struct intel_uncore *uncore,\n\t\t\t\t\t  struct intel_gt *gt)\n{\n\tenum forcewake_domains fw_domains = uncore->fw_domains;\n\tenum forcewake_domain_id domain_id;\n\tint i;\n\n\tif (!intel_uncore_has_forcewake(uncore) || GRAPHICS_VER(uncore->i915) < 11)\n\t\treturn;\n\n\tfor (i = 0; i < I915_MAX_VCS; i++) {\n\t\tdomain_id = FW_DOMAIN_ID_MEDIA_VDBOX0 + i;\n\n\t\tif (HAS_ENGINE(gt, _VCS(i)))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (GRAPHICS_VER_FULL(uncore->i915) >= IP_VER(12, 50) && i % 2 == 0) {\n\t\t\tif ((i + 1 < I915_MAX_VCS) && HAS_ENGINE(gt, _VCS(i + 1)))\n\t\t\t\tcontinue;\n\n\t\t\tif (HAS_ENGINE(gt, _VECS(i / 2)))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (fw_domains & BIT(domain_id))\n\t\t\tfw_domain_fini(uncore, domain_id);\n\t}\n\n\tfor (i = 0; i < I915_MAX_VECS; i++) {\n\t\tdomain_id = FW_DOMAIN_ID_MEDIA_VEBOX0 + i;\n\n\t\tif (HAS_ENGINE(gt, _VECS(i)))\n\t\t\tcontinue;\n\n\t\tif (fw_domains & BIT(domain_id))\n\t\t\tfw_domain_fini(uncore, domain_id);\n\t}\n\n\tif ((fw_domains & BIT(FW_DOMAIN_ID_GSC)) && !HAS_ENGINE(gt, GSC0))\n\t\tfw_domain_fini(uncore, FW_DOMAIN_ID_GSC);\n}\n\n \nstatic void driver_initiated_flr(struct intel_uncore *uncore)\n{\n\tstruct drm_i915_private *i915 = uncore->i915;\n\tconst unsigned int flr_timeout_ms = 3000;  \n\tint ret;\n\n\tdrm_dbg(&i915->drm, \"Triggering Driver-FLR\\n\");\n\n\t \n\tret = intel_wait_for_register_fw(uncore, GU_CNTL, DRIVERFLR, 0, flr_timeout_ms);\n\tif (ret) {\n\t\tdrm_err(&i915->drm,\n\t\t\t\"Failed to wait for Driver-FLR bit to clear! %d\\n\",\n\t\t\tret);\n\t\treturn;\n\t}\n\tintel_uncore_write_fw(uncore, GU_DEBUG, DRIVERFLR_STATUS);\n\n\t \n\tintel_uncore_rmw_fw(uncore, GU_CNTL, 0, DRIVERFLR);\n\n\t \n\tret = intel_wait_for_register_fw(uncore, GU_CNTL,\n\t\t\t\t\t DRIVERFLR, 0,\n\t\t\t\t\t flr_timeout_ms);\n\tif (ret) {\n\t\tdrm_err(&i915->drm, \"Driver-FLR-teardown wait completion failed! %d\\n\", ret);\n\t\treturn;\n\t}\n\n\t \n\tret = intel_wait_for_register_fw(uncore, GU_DEBUG,\n\t\t\t\t\t DRIVERFLR_STATUS, DRIVERFLR_STATUS,\n\t\t\t\t\t flr_timeout_ms);\n\tif (ret) {\n\t\tdrm_err(&i915->drm, \"Driver-FLR-reinit wait completion failed! %d\\n\", ret);\n\t\treturn;\n\t}\n\n\t \n\tintel_uncore_write_fw(uncore, GU_DEBUG, DRIVERFLR_STATUS);\n}\n\n \nvoid intel_uncore_fini_mmio(struct drm_device *dev, void *data)\n{\n\tstruct intel_uncore *uncore = data;\n\n\tif (intel_uncore_has_forcewake(uncore)) {\n\t\tiosf_mbi_punit_acquire();\n\t\tiosf_mbi_unregister_pmic_bus_access_notifier_unlocked(\n\t\t\t&uncore->pmic_bus_access_nb);\n\t\tintel_uncore_forcewake_reset(uncore);\n\t\tintel_uncore_fw_domains_fini(uncore);\n\t\tiosf_mbi_punit_release();\n\t}\n\n\tif (intel_uncore_needs_flr_on_fini(uncore))\n\t\tdriver_initiated_flr(uncore);\n}\n\n \nint __intel_wait_for_register_fw(struct intel_uncore *uncore,\n\t\t\t\t i915_reg_t reg,\n\t\t\t\t u32 mask,\n\t\t\t\t u32 value,\n\t\t\t\t unsigned int fast_timeout_us,\n\t\t\t\t unsigned int slow_timeout_ms,\n\t\t\t\t u32 *out_value)\n{\n\tu32 reg_value = 0;\n#define done (((reg_value = intel_uncore_read_fw(uncore, reg)) & mask) == value)\n\tint ret;\n\n\t \n\tmight_sleep_if(slow_timeout_ms);\n\tGEM_BUG_ON(fast_timeout_us > 20000);\n\tGEM_BUG_ON(!fast_timeout_us && !slow_timeout_ms);\n\n\tret = -ETIMEDOUT;\n\tif (fast_timeout_us && fast_timeout_us <= 20000)\n\t\tret = _wait_for_atomic(done, fast_timeout_us, 0);\n\tif (ret && slow_timeout_ms)\n\t\tret = wait_for(done, slow_timeout_ms);\n\n\tif (out_value)\n\t\t*out_value = reg_value;\n\n\treturn ret;\n#undef done\n}\n\n \nint __intel_wait_for_register(struct intel_uncore *uncore,\n\t\t\t      i915_reg_t reg,\n\t\t\t      u32 mask,\n\t\t\t      u32 value,\n\t\t\t      unsigned int fast_timeout_us,\n\t\t\t      unsigned int slow_timeout_ms,\n\t\t\t      u32 *out_value)\n{\n\tunsigned fw =\n\t\tintel_uncore_forcewake_for_reg(uncore, reg, FW_REG_READ);\n\tu32 reg_value;\n\tint ret;\n\n\tmight_sleep_if(slow_timeout_ms);\n\n\tspin_lock_irq(&uncore->lock);\n\tintel_uncore_forcewake_get__locked(uncore, fw);\n\n\tret = __intel_wait_for_register_fw(uncore,\n\t\t\t\t\t   reg, mask, value,\n\t\t\t\t\t   fast_timeout_us, 0, &reg_value);\n\n\tintel_uncore_forcewake_put__locked(uncore, fw);\n\tspin_unlock_irq(&uncore->lock);\n\n\tif (ret && slow_timeout_ms)\n\t\tret = __wait_for(reg_value = intel_uncore_read_notrace(uncore,\n\t\t\t\t\t\t\t\t       reg),\n\t\t\t\t (reg_value & mask) == value,\n\t\t\t\t slow_timeout_ms * 1000, 10, 1000);\n\n\t \n\ttrace_i915_reg_rw(false, reg, reg_value, sizeof(reg_value), true);\n\n\tif (out_value)\n\t\t*out_value = reg_value;\n\n\treturn ret;\n}\n\nbool intel_uncore_unclaimed_mmio(struct intel_uncore *uncore)\n{\n\tbool ret;\n\n\tif (!uncore->debug)\n\t\treturn false;\n\n\tspin_lock_irq(&uncore->debug->lock);\n\tret = check_for_unclaimed_mmio(uncore);\n\tspin_unlock_irq(&uncore->debug->lock);\n\n\treturn ret;\n}\n\nbool\nintel_uncore_arm_unclaimed_mmio_detection(struct intel_uncore *uncore)\n{\n\tbool ret = false;\n\n\tif (drm_WARN_ON(&uncore->i915->drm, !uncore->debug))\n\t\treturn false;\n\n\tspin_lock_irq(&uncore->debug->lock);\n\n\tif (unlikely(uncore->debug->unclaimed_mmio_check <= 0))\n\t\tgoto out;\n\n\tif (unlikely(check_for_unclaimed_mmio(uncore))) {\n\t\tif (!uncore->i915->params.mmio_debug) {\n\t\t\tdrm_dbg(&uncore->i915->drm,\n\t\t\t\t\"Unclaimed register detected, \"\n\t\t\t\t\"enabling oneshot unclaimed register reporting. \"\n\t\t\t\t\"Please use i915.mmio_debug=N for more information.\\n\");\n\t\t\tuncore->i915->params.mmio_debug++;\n\t\t}\n\t\tuncore->debug->unclaimed_mmio_check--;\n\t\tret = true;\n\t}\n\nout:\n\tspin_unlock_irq(&uncore->debug->lock);\n\n\treturn ret;\n}\n\n \nenum forcewake_domains\nintel_uncore_forcewake_for_reg(struct intel_uncore *uncore,\n\t\t\t       i915_reg_t reg, unsigned int op)\n{\n\tenum forcewake_domains fw_domains = 0;\n\n\tdrm_WARN_ON(&uncore->i915->drm, !op);\n\n\tif (!intel_uncore_has_forcewake(uncore))\n\t\treturn 0;\n\n\tif (op & FW_REG_READ)\n\t\tfw_domains = uncore->funcs.read_fw_domains(uncore, reg);\n\n\tif (op & FW_REG_WRITE)\n\t\tfw_domains |= uncore->funcs.write_fw_domains(uncore, reg);\n\n\tdrm_WARN_ON(&uncore->i915->drm, fw_domains & ~uncore->fw_domains);\n\n\treturn fw_domains;\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_SELFTEST)\n#include \"selftests/mock_uncore.c\"\n#include \"selftests/intel_uncore.c\"\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}