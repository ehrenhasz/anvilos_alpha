{
  "module_name": "gen6_engine_cs.c",
  "hash_id": "c3f516ad60f5970a6850df962cde9f12317639a02cca20cb63fe2aaf9f51c831",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/gen6_engine_cs.c",
  "human_readable_source": "\n \n\n#include \"gen6_engine_cs.h\"\n#include \"intel_engine.h\"\n#include \"intel_engine_regs.h\"\n#include \"intel_gpu_commands.h\"\n#include \"intel_gt.h\"\n#include \"intel_gt_irq.h\"\n#include \"intel_gt_pm_irq.h\"\n#include \"intel_ring.h\"\n\n#define HWS_SCRATCH_ADDR\t(I915_GEM_HWS_SCRATCH * sizeof(u32))\n\n \nstatic int\ngen6_emit_post_sync_nonzero_flush(struct i915_request *rq)\n{\n\tu32 scratch_addr =\n\t\tintel_gt_scratch_offset(rq->engine->gt,\n\t\t\t\t\tINTEL_GT_SCRATCH_FIELD_RENDER_FLUSH);\n\tu32 *cs;\n\n\tcs = intel_ring_begin(rq, 6);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = GFX_OP_PIPE_CONTROL(5);\n\t*cs++ = PIPE_CONTROL_CS_STALL | PIPE_CONTROL_STALL_AT_SCOREBOARD;\n\t*cs++ = scratch_addr | PIPE_CONTROL_GLOBAL_GTT;\n\t*cs++ = 0;  \n\t*cs++ = 0;  \n\t*cs++ = MI_NOOP;\n\tintel_ring_advance(rq, cs);\n\n\tcs = intel_ring_begin(rq, 6);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = GFX_OP_PIPE_CONTROL(5);\n\t*cs++ = PIPE_CONTROL_QW_WRITE;\n\t*cs++ = scratch_addr | PIPE_CONTROL_GLOBAL_GTT;\n\t*cs++ = 0;\n\t*cs++ = 0;\n\t*cs++ = MI_NOOP;\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nint gen6_emit_flush_rcs(struct i915_request *rq, u32 mode)\n{\n\tu32 scratch_addr =\n\t\tintel_gt_scratch_offset(rq->engine->gt,\n\t\t\t\t\tINTEL_GT_SCRATCH_FIELD_RENDER_FLUSH);\n\tu32 *cs, flags = 0;\n\tint ret;\n\n\t \n\tret = gen6_emit_post_sync_nonzero_flush(rq);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (mode & EMIT_FLUSH) {\n\t\tflags |= PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH;\n\t\tflags |= PIPE_CONTROL_DEPTH_CACHE_FLUSH;\n\t\t \n\t\tflags |= PIPE_CONTROL_CS_STALL;\n\t}\n\tif (mode & EMIT_INVALIDATE) {\n\t\tflags |= PIPE_CONTROL_TLB_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_INSTRUCTION_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_TEXTURE_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_VF_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_CONST_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_STATE_CACHE_INVALIDATE;\n\t\t \n\t\tflags |= PIPE_CONTROL_QW_WRITE | PIPE_CONTROL_CS_STALL;\n\t}\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = GFX_OP_PIPE_CONTROL(4);\n\t*cs++ = flags;\n\t*cs++ = scratch_addr | PIPE_CONTROL_GLOBAL_GTT;\n\t*cs++ = 0;\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nu32 *gen6_emit_breadcrumb_rcs(struct i915_request *rq, u32 *cs)\n{\n\t \n\t*cs++ = GFX_OP_PIPE_CONTROL(4);\n\t*cs++ = PIPE_CONTROL_CS_STALL | PIPE_CONTROL_STALL_AT_SCOREBOARD;\n\t*cs++ = 0;\n\t*cs++ = 0;\n\n\t*cs++ = GFX_OP_PIPE_CONTROL(4);\n\t*cs++ = PIPE_CONTROL_QW_WRITE;\n\t*cs++ = intel_gt_scratch_offset(rq->engine->gt,\n\t\t\t\t\tINTEL_GT_SCRATCH_FIELD_DEFAULT) |\n\t\tPIPE_CONTROL_GLOBAL_GTT;\n\t*cs++ = 0;\n\n\t \n\t*cs++ = GFX_OP_PIPE_CONTROL(4);\n\t*cs++ = (PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |\n\t\t PIPE_CONTROL_DEPTH_CACHE_FLUSH |\n\t\t PIPE_CONTROL_DC_FLUSH_ENABLE |\n\t\t PIPE_CONTROL_QW_WRITE |\n\t\t PIPE_CONTROL_CS_STALL);\n\t*cs++ = i915_request_active_seqno(rq) |\n\t\tPIPE_CONTROL_GLOBAL_GTT;\n\t*cs++ = rq->fence.seqno;\n\n\t*cs++ = MI_USER_INTERRUPT;\n\t*cs++ = MI_NOOP;\n\n\trq->tail = intel_ring_offset(rq, cs);\n\tassert_ring_tail_valid(rq->ring, rq->tail);\n\n\treturn cs;\n}\n\nstatic int mi_flush_dw(struct i915_request *rq, u32 flags)\n{\n\tu32 cmd, *cs;\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\tcmd = MI_FLUSH_DW;\n\n\t \n\tcmd |= MI_FLUSH_DW_STORE_INDEX | MI_FLUSH_DW_OP_STOREDW;\n\n\t \n\tcmd |= flags;\n\n\t*cs++ = cmd;\n\t*cs++ = HWS_SCRATCH_ADDR | MI_FLUSH_DW_USE_GTT;\n\t*cs++ = 0;\n\t*cs++ = MI_NOOP;\n\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstatic int gen6_flush_dw(struct i915_request *rq, u32 mode, u32 invflags)\n{\n\treturn mi_flush_dw(rq, mode & EMIT_INVALIDATE ? invflags : 0);\n}\n\nint gen6_emit_flush_xcs(struct i915_request *rq, u32 mode)\n{\n\treturn gen6_flush_dw(rq, mode, MI_INVALIDATE_TLB);\n}\n\nint gen6_emit_flush_vcs(struct i915_request *rq, u32 mode)\n{\n\treturn gen6_flush_dw(rq, mode, MI_INVALIDATE_TLB | MI_INVALIDATE_BSD);\n}\n\nint gen6_emit_bb_start(struct i915_request *rq,\n\t\t       u64 offset, u32 len,\n\t\t       unsigned int dispatch_flags)\n{\n\tu32 security;\n\tu32 *cs;\n\n\tsecurity = MI_BATCH_NON_SECURE_I965;\n\tif (dispatch_flags & I915_DISPATCH_SECURE)\n\t\tsecurity = 0;\n\n\tcs = intel_ring_begin(rq, 2);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\tcs = __gen6_emit_bb_start(cs, offset, security);\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nint\nhsw_emit_bb_start(struct i915_request *rq,\n\t\t  u64 offset, u32 len,\n\t\t  unsigned int dispatch_flags)\n{\n\tu32 security;\n\tu32 *cs;\n\n\tsecurity = MI_BATCH_PPGTT_HSW | MI_BATCH_NON_SECURE_HSW;\n\tif (dispatch_flags & I915_DISPATCH_SECURE)\n\t\tsecurity = 0;\n\n\tcs = intel_ring_begin(rq, 2);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\tcs = __gen6_emit_bb_start(cs, offset, security);\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstatic int gen7_stall_cs(struct i915_request *rq)\n{\n\tu32 *cs;\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = GFX_OP_PIPE_CONTROL(4);\n\t*cs++ = PIPE_CONTROL_CS_STALL | PIPE_CONTROL_STALL_AT_SCOREBOARD;\n\t*cs++ = 0;\n\t*cs++ = 0;\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nint gen7_emit_flush_rcs(struct i915_request *rq, u32 mode)\n{\n\tu32 scratch_addr =\n\t\tintel_gt_scratch_offset(rq->engine->gt,\n\t\t\t\t\tINTEL_GT_SCRATCH_FIELD_RENDER_FLUSH);\n\tu32 *cs, flags = 0;\n\n\t \n\tflags |= PIPE_CONTROL_CS_STALL;\n\n\t \n\tflags |= PIPE_CONTROL_QW_WRITE;\n\tflags |= PIPE_CONTROL_GLOBAL_GTT_IVB;\n\n\t \n\tif (mode & EMIT_FLUSH) {\n\t\tflags |= PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH;\n\t\tflags |= PIPE_CONTROL_DEPTH_CACHE_FLUSH;\n\t\tflags |= PIPE_CONTROL_DC_FLUSH_ENABLE;\n\t\tflags |= PIPE_CONTROL_FLUSH_ENABLE;\n\t}\n\tif (mode & EMIT_INVALIDATE) {\n\t\tflags |= PIPE_CONTROL_TLB_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_INSTRUCTION_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_TEXTURE_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_VF_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_CONST_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_STATE_CACHE_INVALIDATE;\n\t\tflags |= PIPE_CONTROL_MEDIA_STATE_CLEAR;\n\n\t\t \n\t\tgen7_stall_cs(rq);\n\t}\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = GFX_OP_PIPE_CONTROL(4);\n\t*cs++ = flags;\n\t*cs++ = scratch_addr;\n\t*cs++ = 0;\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nu32 *gen7_emit_breadcrumb_rcs(struct i915_request *rq, u32 *cs)\n{\n\t*cs++ = GFX_OP_PIPE_CONTROL(4);\n\t*cs++ = (PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |\n\t\t PIPE_CONTROL_DEPTH_CACHE_FLUSH |\n\t\t PIPE_CONTROL_DC_FLUSH_ENABLE |\n\t\t PIPE_CONTROL_FLUSH_ENABLE |\n\t\t PIPE_CONTROL_QW_WRITE |\n\t\t PIPE_CONTROL_GLOBAL_GTT_IVB |\n\t\t PIPE_CONTROL_CS_STALL);\n\t*cs++ = i915_request_active_seqno(rq);\n\t*cs++ = rq->fence.seqno;\n\n\t*cs++ = MI_USER_INTERRUPT;\n\t*cs++ = MI_NOOP;\n\n\trq->tail = intel_ring_offset(rq, cs);\n\tassert_ring_tail_valid(rq->ring, rq->tail);\n\n\treturn cs;\n}\n\nu32 *gen6_emit_breadcrumb_xcs(struct i915_request *rq, u32 *cs)\n{\n\tGEM_BUG_ON(i915_request_active_timeline(rq)->hwsp_ggtt != rq->engine->status_page.vma);\n\tGEM_BUG_ON(offset_in_page(rq->hwsp_seqno) != I915_GEM_HWS_SEQNO_ADDR);\n\n\t*cs++ = MI_FLUSH_DW | MI_FLUSH_DW_OP_STOREDW | MI_FLUSH_DW_STORE_INDEX;\n\t*cs++ = I915_GEM_HWS_SEQNO_ADDR | MI_FLUSH_DW_USE_GTT;\n\t*cs++ = rq->fence.seqno;\n\n\t*cs++ = MI_USER_INTERRUPT;\n\n\trq->tail = intel_ring_offset(rq, cs);\n\tassert_ring_tail_valid(rq->ring, rq->tail);\n\n\treturn cs;\n}\n\n#define GEN7_XCS_WA 32\nu32 *gen7_emit_breadcrumb_xcs(struct i915_request *rq, u32 *cs)\n{\n\tint i;\n\n\tGEM_BUG_ON(i915_request_active_timeline(rq)->hwsp_ggtt != rq->engine->status_page.vma);\n\tGEM_BUG_ON(offset_in_page(rq->hwsp_seqno) != I915_GEM_HWS_SEQNO_ADDR);\n\n\t*cs++ = MI_FLUSH_DW | MI_INVALIDATE_TLB |\n\t\tMI_FLUSH_DW_OP_STOREDW | MI_FLUSH_DW_STORE_INDEX;\n\t*cs++ = I915_GEM_HWS_SEQNO_ADDR | MI_FLUSH_DW_USE_GTT;\n\t*cs++ = rq->fence.seqno;\n\n\tfor (i = 0; i < GEN7_XCS_WA; i++) {\n\t\t*cs++ = MI_STORE_DWORD_INDEX;\n\t\t*cs++ = I915_GEM_HWS_SEQNO_ADDR;\n\t\t*cs++ = rq->fence.seqno;\n\t}\n\n\t*cs++ = MI_FLUSH_DW;\n\t*cs++ = 0;\n\t*cs++ = 0;\n\n\t*cs++ = MI_USER_INTERRUPT;\n\t*cs++ = MI_NOOP;\n\n\trq->tail = intel_ring_offset(rq, cs);\n\tassert_ring_tail_valid(rq->ring, rq->tail);\n\n\treturn cs;\n}\n#undef GEN7_XCS_WA\n\nvoid gen6_irq_enable(struct intel_engine_cs *engine)\n{\n\tENGINE_WRITE(engine, RING_IMR,\n\t\t     ~(engine->irq_enable_mask | engine->irq_keep_mask));\n\n\t \n\tENGINE_POSTING_READ(engine, RING_IMR);\n\n\tgen5_gt_enable_irq(engine->gt, engine->irq_enable_mask);\n}\n\nvoid gen6_irq_disable(struct intel_engine_cs *engine)\n{\n\tENGINE_WRITE(engine, RING_IMR, ~engine->irq_keep_mask);\n\tgen5_gt_disable_irq(engine->gt, engine->irq_enable_mask);\n}\n\nvoid hsw_irq_enable_vecs(struct intel_engine_cs *engine)\n{\n\tENGINE_WRITE(engine, RING_IMR, ~engine->irq_enable_mask);\n\n\t \n\tENGINE_POSTING_READ(engine, RING_IMR);\n\n\tgen6_gt_pm_unmask_irq(engine->gt, engine->irq_enable_mask);\n}\n\nvoid hsw_irq_disable_vecs(struct intel_engine_cs *engine)\n{\n\tENGINE_WRITE(engine, RING_IMR, ~0);\n\tgen6_gt_pm_mask_irq(engine->gt, engine->irq_enable_mask);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}