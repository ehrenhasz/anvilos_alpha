{
  "module_name": "intel_engine.h",
  "hash_id": "bfcff6526acd30f1891b6b0779c597e840b21897d51d2a452b7afbd29fae2d78",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/intel_engine.h",
  "human_readable_source": " \n#ifndef _INTEL_RINGBUFFER_H_\n#define _INTEL_RINGBUFFER_H_\n\n#include <asm/cacheflush.h>\n#include <drm/drm_util.h>\n#include <drm/drm_cache.h>\n\n#include <linux/hashtable.h>\n#include <linux/irq_work.h>\n#include <linux/random.h>\n#include <linux/seqlock.h>\n\n#include \"i915_pmu.h\"\n#include \"i915_request.h\"\n#include \"i915_selftest.h\"\n#include \"intel_engine_types.h\"\n#include \"intel_gt_types.h\"\n#include \"intel_timeline.h\"\n#include \"intel_workarounds.h\"\n\nstruct drm_printer;\nstruct intel_context;\nstruct intel_gt;\nstruct lock_class_key;\n\n \n#define CACHELINE_BYTES 64\n#define CACHELINE_DWORDS (CACHELINE_BYTES / sizeof(u32))\n\n#define ENGINE_TRACE(e, fmt, ...) do {\t\t\t\t\t\\\n\tconst struct intel_engine_cs *e__ __maybe_unused = (e);\t\t\\\n\tGEM_TRACE(\"%s %s: \" fmt,\t\t\t\t\t\\\n\t\t  dev_name(e__->i915->drm.dev), e__->name,\t\t\\\n\t\t  ##__VA_ARGS__);\t\t\t\t\t\\\n} while (0)\n\n \n\n#define __ENGINE_REG_OP(op__, engine__, ...) \\\n\tintel_uncore_##op__((engine__)->uncore, __VA_ARGS__)\n\n#define __ENGINE_READ_OP(op__, engine__, reg__) \\\n\t__ENGINE_REG_OP(op__, (engine__), reg__((engine__)->mmio_base))\n\n#define ENGINE_READ16(...)\t__ENGINE_READ_OP(read16, __VA_ARGS__)\n#define ENGINE_READ(...)\t__ENGINE_READ_OP(read, __VA_ARGS__)\n#define ENGINE_READ_FW(...)\t__ENGINE_READ_OP(read_fw, __VA_ARGS__)\n#define ENGINE_POSTING_READ(...) __ENGINE_READ_OP(posting_read_fw, __VA_ARGS__)\n#define ENGINE_POSTING_READ16(...) __ENGINE_READ_OP(posting_read16, __VA_ARGS__)\n\n#define ENGINE_READ64(engine__, lower_reg__, upper_reg__) \\\n\t__ENGINE_REG_OP(read64_2x32, (engine__), \\\n\t\t\tlower_reg__((engine__)->mmio_base), \\\n\t\t\tupper_reg__((engine__)->mmio_base))\n\n#define ENGINE_READ_IDX(engine__, reg__, idx__) \\\n\t__ENGINE_REG_OP(read, (engine__), reg__((engine__)->mmio_base, (idx__)))\n\n#define __ENGINE_WRITE_OP(op__, engine__, reg__, val__) \\\n\t__ENGINE_REG_OP(op__, (engine__), reg__((engine__)->mmio_base), (val__))\n\n#define ENGINE_WRITE16(...)\t__ENGINE_WRITE_OP(write16, __VA_ARGS__)\n#define ENGINE_WRITE(...)\t__ENGINE_WRITE_OP(write, __VA_ARGS__)\n#define ENGINE_WRITE_FW(...)\t__ENGINE_WRITE_OP(write_fw, __VA_ARGS__)\n\n#define GEN6_RING_FAULT_REG_READ(engine__) \\\n\tintel_uncore_read((engine__)->uncore, RING_FAULT_REG(engine__))\n\n#define GEN6_RING_FAULT_REG_POSTING_READ(engine__) \\\n\tintel_uncore_posting_read((engine__)->uncore, RING_FAULT_REG(engine__))\n\n#define GEN6_RING_FAULT_REG_RMW(engine__, clear__, set__) \\\n({ \\\n\tu32 __val; \\\n\\\n\t__val = intel_uncore_read((engine__)->uncore, \\\n\t\t\t\t  RING_FAULT_REG(engine__)); \\\n\t__val &= ~(clear__); \\\n\t__val |= (set__); \\\n\tintel_uncore_write((engine__)->uncore, RING_FAULT_REG(engine__), \\\n\t\t\t   __val); \\\n})\n\n \n\nstatic inline unsigned int\nexeclists_num_ports(const struct intel_engine_execlists * const execlists)\n{\n\treturn execlists->port_mask + 1;\n}\n\nstatic inline struct i915_request *\nexeclists_active(const struct intel_engine_execlists *execlists)\n{\n\tstruct i915_request * const *cur, * const *old, *active;\n\n\tcur = READ_ONCE(execlists->active);\n\tsmp_rmb();  \n\tdo {\n\t\told = cur;\n\n\t\tactive = READ_ONCE(*cur);\n\t\tcur = READ_ONCE(execlists->active);\n\n\t\tsmp_rmb();  \n\t} while (unlikely(cur != old));\n\n\treturn active;\n}\n\nstruct i915_request *\nexeclists_unwind_incomplete_requests(struct intel_engine_execlists *execlists);\n\nstatic inline u32\nintel_read_status_page(const struct intel_engine_cs *engine, int reg)\n{\n\t \n\treturn READ_ONCE(engine->status_page.addr[reg]);\n}\n\nstatic inline void\nintel_write_status_page(struct intel_engine_cs *engine, int reg, u32 value)\n{\n\t \n\tdrm_clflush_virt_range(&engine->status_page.addr[reg], sizeof(value));\n\tWRITE_ONCE(engine->status_page.addr[reg], value);\n\tdrm_clflush_virt_range(&engine->status_page.addr[reg], sizeof(value));\n}\n\n \n#define I915_GEM_HWS_PREEMPT\t\t0x32\n#define I915_GEM_HWS_PREEMPT_ADDR\t(I915_GEM_HWS_PREEMPT * sizeof(u32))\n#define I915_GEM_HWS_SEQNO\t\t0x40\n#define I915_GEM_HWS_SEQNO_ADDR\t\t(I915_GEM_HWS_SEQNO * sizeof(u32))\n#define I915_GEM_HWS_MIGRATE\t\t(0x42 * sizeof(u32))\n#define I915_GEM_HWS_PXP\t\t0x60\n#define I915_GEM_HWS_PXP_ADDR\t\t(I915_GEM_HWS_PXP * sizeof(u32))\n#define I915_GEM_HWS_GSC\t\t0x62\n#define I915_GEM_HWS_GSC_ADDR\t\t(I915_GEM_HWS_GSC * sizeof(u32))\n#define I915_GEM_HWS_SCRATCH\t\t0x80\n\n#define I915_HWS_CSB_BUF0_INDEX\t\t0x10\n#define I915_HWS_CSB_WRITE_INDEX\t0x1f\n#define ICL_HWS_CSB_WRITE_INDEX\t\t0x2f\n#define INTEL_HWS_CSB_WRITE_INDEX(__i915) \\\n\t(GRAPHICS_VER(__i915) >= 11 ? ICL_HWS_CSB_WRITE_INDEX : I915_HWS_CSB_WRITE_INDEX)\n\nvoid intel_engine_stop(struct intel_engine_cs *engine);\nvoid intel_engine_cleanup(struct intel_engine_cs *engine);\n\nint intel_engines_init_mmio(struct intel_gt *gt);\nint intel_engines_init(struct intel_gt *gt);\n\nvoid intel_engine_free_request_pool(struct intel_engine_cs *engine);\n\nvoid intel_engines_release(struct intel_gt *gt);\nvoid intel_engines_free(struct intel_gt *gt);\n\nint intel_engine_init_common(struct intel_engine_cs *engine);\nvoid intel_engine_cleanup_common(struct intel_engine_cs *engine);\n\nint intel_engine_resume(struct intel_engine_cs *engine);\n\nint intel_ring_submission_setup(struct intel_engine_cs *engine);\n\nint intel_engine_stop_cs(struct intel_engine_cs *engine);\nvoid intel_engine_cancel_stop_cs(struct intel_engine_cs *engine);\n\nvoid intel_engine_wait_for_pending_mi_fw(struct intel_engine_cs *engine);\n\nvoid intel_engine_set_hwsp_writemask(struct intel_engine_cs *engine, u32 mask);\n\nu64 intel_engine_get_active_head(const struct intel_engine_cs *engine);\nu64 intel_engine_get_last_batch_head(const struct intel_engine_cs *engine);\n\nvoid intel_engine_get_instdone(const struct intel_engine_cs *engine,\n\t\t\t       struct intel_instdone *instdone);\n\nvoid intel_engine_init_execlists(struct intel_engine_cs *engine);\n\nbool intel_engine_irq_enable(struct intel_engine_cs *engine);\nvoid intel_engine_irq_disable(struct intel_engine_cs *engine);\n\nstatic inline void __intel_engine_reset(struct intel_engine_cs *engine,\n\t\t\t\t\tbool stalled)\n{\n\tif (engine->reset.rewind)\n\t\tengine->reset.rewind(engine, stalled);\n\tengine->serial++;  \n}\n\nbool intel_engines_are_idle(struct intel_gt *gt);\nbool intel_engine_is_idle(struct intel_engine_cs *engine);\n\nvoid __intel_engine_flush_submission(struct intel_engine_cs *engine, bool sync);\nstatic inline void intel_engine_flush_submission(struct intel_engine_cs *engine)\n{\n\t__intel_engine_flush_submission(engine, true);\n}\n\nvoid intel_engines_reset_default_submission(struct intel_gt *gt);\n\nbool intel_engine_can_store_dword(struct intel_engine_cs *engine);\n\n__printf(3, 4)\nvoid intel_engine_dump(struct intel_engine_cs *engine,\n\t\t       struct drm_printer *m,\n\t\t       const char *header, ...);\nvoid intel_engine_dump_active_requests(struct list_head *requests,\n\t\t\t\t       struct i915_request *hung_rq,\n\t\t\t\t       struct drm_printer *m);\n\nktime_t intel_engine_get_busy_time(struct intel_engine_cs *engine,\n\t\t\t\t   ktime_t *now);\n\nvoid intel_engine_get_hung_entity(struct intel_engine_cs *engine,\n\t\t\t\t  struct intel_context **ce, struct i915_request **rq);\n\nu32 intel_engine_context_size(struct intel_gt *gt, u8 class);\nstruct intel_context *\nintel_engine_create_pinned_context(struct intel_engine_cs *engine,\n\t\t\t\t   struct i915_address_space *vm,\n\t\t\t\t   unsigned int ring_size,\n\t\t\t\t   unsigned int hwsp,\n\t\t\t\t   struct lock_class_key *key,\n\t\t\t\t   const char *name);\n\nvoid intel_engine_destroy_pinned_context(struct intel_context *ce);\n\nvoid xehp_enable_ccs_engines(struct intel_engine_cs *engine);\n\n#define ENGINE_PHYSICAL\t0\n#define ENGINE_MOCK\t1\n#define ENGINE_VIRTUAL\t2\n\nstatic inline bool intel_engine_uses_guc(const struct intel_engine_cs *engine)\n{\n\treturn engine->gt->submission_method >= INTEL_SUBMISSION_GUC;\n}\n\nstatic inline bool\nintel_engine_has_preempt_reset(const struct intel_engine_cs *engine)\n{\n\tif (!CONFIG_DRM_I915_PREEMPT_TIMEOUT)\n\t\treturn false;\n\n\treturn intel_engine_has_preemption(engine);\n}\n\n#define FORCE_VIRTUAL\tBIT(0)\nstruct intel_context *\nintel_engine_create_virtual(struct intel_engine_cs **siblings,\n\t\t\t    unsigned int count, unsigned long flags);\n\nstatic inline struct intel_context *\nintel_engine_create_parallel(struct intel_engine_cs **engines,\n\t\t\t     unsigned int num_engines,\n\t\t\t     unsigned int width)\n{\n\tGEM_BUG_ON(!engines[0]->cops->create_parallel);\n\treturn engines[0]->cops->create_parallel(engines, num_engines, width);\n}\n\nstatic inline bool\nintel_virtual_engine_has_heartbeat(const struct intel_engine_cs *engine)\n{\n\t \n\tGEM_BUG_ON(!intel_engine_uses_guc(engine));\n\n\treturn intel_guc_virtual_engine_has_heartbeat(engine);\n}\n\nstatic inline bool\nintel_engine_has_heartbeat(const struct intel_engine_cs *engine)\n{\n\tif (!CONFIG_DRM_I915_HEARTBEAT_INTERVAL)\n\t\treturn false;\n\n\tif (intel_engine_is_virtual(engine))\n\t\treturn intel_virtual_engine_has_heartbeat(engine);\n\telse\n\t\treturn READ_ONCE(engine->props.heartbeat_interval_ms);\n}\n\nstatic inline struct intel_engine_cs *\nintel_engine_get_sibling(struct intel_engine_cs *engine, unsigned int sibling)\n{\n\tGEM_BUG_ON(!intel_engine_is_virtual(engine));\n\treturn engine->cops->get_sibling(engine, sibling);\n}\n\nstatic inline void\nintel_engine_set_hung_context(struct intel_engine_cs *engine,\n\t\t\t      struct intel_context *ce)\n{\n\tengine->hung_ce = ce;\n}\n\nstatic inline void\nintel_engine_clear_hung_context(struct intel_engine_cs *engine)\n{\n\tintel_engine_set_hung_context(engine, NULL);\n}\n\nstatic inline struct intel_context *\nintel_engine_get_hung_context(struct intel_engine_cs *engine)\n{\n\treturn engine->hung_ce;\n}\n\nu64 intel_clamp_heartbeat_interval_ms(struct intel_engine_cs *engine, u64 value);\nu64 intel_clamp_max_busywait_duration_ns(struct intel_engine_cs *engine, u64 value);\nu64 intel_clamp_preempt_timeout_ms(struct intel_engine_cs *engine, u64 value);\nu64 intel_clamp_stop_timeout_ms(struct intel_engine_cs *engine, u64 value);\nu64 intel_clamp_timeslice_duration_ms(struct intel_engine_cs *engine, u64 value);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}