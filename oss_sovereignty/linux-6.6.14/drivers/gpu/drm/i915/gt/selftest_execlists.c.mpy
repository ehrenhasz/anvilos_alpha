{
  "module_name": "selftest_execlists.c",
  "hash_id": "bf6ff5e52248513d120673085c80fa7ccd339db99644a6bc1683d1ed1c60747a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/selftest_execlists.c",
  "human_readable_source": "\n \n\n#include <linux/prime_numbers.h>\n\n#include \"gem/i915_gem_internal.h\"\n#include \"gem/i915_gem_pm.h\"\n#include \"gt/intel_engine_heartbeat.h\"\n#include \"gt/intel_reset.h\"\n#include \"gt/selftest_engine_heartbeat.h\"\n\n#include \"i915_selftest.h\"\n#include \"selftests/i915_random.h\"\n#include \"selftests/igt_flush_test.h\"\n#include \"selftests/igt_live_test.h\"\n#include \"selftests/igt_spinner.h\"\n#include \"selftests/lib_sw_fence.h\"\n\n#include \"gem/selftests/igt_gem_utils.h\"\n#include \"gem/selftests/mock_context.h\"\n\n#define CS_GPR(engine, n) ((engine)->mmio_base + 0x600 + (n) * 4)\n#define NUM_GPR 16\n#define NUM_GPR_DW (NUM_GPR * 2)  \n\nstatic bool is_active(struct i915_request *rq)\n{\n\tif (i915_request_is_active(rq))\n\t\treturn true;\n\n\tif (i915_request_on_hold(rq))\n\t\treturn true;\n\n\tif (i915_request_has_initial_breadcrumb(rq) && i915_request_started(rq))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int wait_for_submit(struct intel_engine_cs *engine,\n\t\t\t   struct i915_request *rq,\n\t\t\t   unsigned long timeout)\n{\n\t \n\ttasklet_hi_schedule(&engine->sched_engine->tasklet);\n\n\ttimeout += jiffies;\n\tdo {\n\t\tbool done = time_after(jiffies, timeout);\n\n\t\tif (i915_request_completed(rq))  \n\t\t\treturn 0;\n\n\t\t \n\t\tintel_engine_flush_submission(engine);\n\t\tif (!READ_ONCE(engine->execlists.pending[0]) && is_active(rq))\n\t\t\treturn 0;\n\n\t\tif (done)\n\t\t\treturn -ETIME;\n\n\t\tcond_resched();\n\t} while (1);\n}\n\nstatic int wait_for_reset(struct intel_engine_cs *engine,\n\t\t\t  struct i915_request *rq,\n\t\t\t  unsigned long timeout)\n{\n\ttimeout += jiffies;\n\n\tdo {\n\t\tcond_resched();\n\t\tintel_engine_flush_submission(engine);\n\n\t\tif (READ_ONCE(engine->execlists.pending[0]))\n\t\t\tcontinue;\n\n\t\tif (i915_request_completed(rq))\n\t\t\tbreak;\n\n\t\tif (READ_ONCE(rq->fence.error))\n\t\t\tbreak;\n\t} while (time_before(jiffies, timeout));\n\n\tif (rq->fence.error != -EIO) {\n\t\tpr_err(\"%s: hanging request %llx:%lld not reset\\n\",\n\t\t       engine->name,\n\t\t       rq->fence.context,\n\t\t       rq->fence.seqno);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (i915_request_wait(rq, 0,\n\t\t\t      max(0l, (long)(timeout - jiffies)) + 1) < 0) {\n\t\tpr_err(\"%s: hanging request %llx:%lld did not complete\\n\",\n\t\t       engine->name,\n\t\t       rq->fence.context,\n\t\t       rq->fence.seqno);\n\t\treturn -ETIME;\n\t}\n\n\treturn 0;\n}\n\nstatic int live_sanitycheck(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tstruct igt_spinner spin;\n\tint err = 0;\n\n\tif (!HAS_LOGICAL_RING_CONTEXTS(gt->i915))\n\t\treturn 0;\n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce;\n\t\tstruct i915_request *rq;\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tbreak;\n\t\t}\n\n\t\trq = igt_spinner_create_request(&spin, ce, MI_NOOP);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out_ctx;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t\tif (!igt_wait_for_spinner(&spin, rq)) {\n\t\t\tGEM_TRACE(\"spinner failed to start\\n\");\n\t\t\tGEM_TRACE_DUMP();\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -EIO;\n\t\t\tgoto out_ctx;\n\t\t}\n\n\t\tigt_spinner_end(&spin);\n\t\tif (igt_flush_test(gt->i915)) {\n\t\t\terr = -EIO;\n\t\t\tgoto out_ctx;\n\t\t}\n\nout_ctx:\n\t\tintel_context_put(ce);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int live_unlite_restore(struct intel_gt *gt, int prio)\n{\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tstruct igt_spinner spin;\n\tint err = -ENOMEM;\n\n\t \n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn err;\n\n\terr = 0;\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce[2] = {};\n\t\tstruct i915_request *rq[2];\n\t\tstruct igt_live_test t;\n\t\tint n;\n\n\t\tif (prio && !intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tst_engine_heartbeat_disable(engine);\n\n\t\tfor (n = 0; n < ARRAY_SIZE(ce); n++) {\n\t\t\tstruct intel_context *tmp;\n\n\t\t\ttmp = intel_context_create(engine);\n\t\t\tif (IS_ERR(tmp)) {\n\t\t\t\terr = PTR_ERR(tmp);\n\t\t\t\tgoto err_ce;\n\t\t\t}\n\n\t\t\terr = intel_context_pin(tmp);\n\t\t\tif (err) {\n\t\t\t\tintel_context_put(tmp);\n\t\t\t\tgoto err_ce;\n\t\t\t}\n\n\t\t\t \n\t\t\tmemset(tmp->ring->vaddr,\n\t\t\t       POISON_INUSE,  \n\t\t\t       tmp->ring->vma->size);\n\n\t\t\tce[n] = tmp;\n\t\t}\n\t\tGEM_BUG_ON(!ce[1]->ring->size);\n\t\tintel_ring_reset(ce[1]->ring, ce[1]->ring->size / 2);\n\t\tlrc_update_regs(ce[1], engine, ce[1]->ring->head);\n\n\t\trq[0] = igt_spinner_create_request(&spin, ce[0], MI_ARB_CHECK);\n\t\tif (IS_ERR(rq[0])) {\n\t\t\terr = PTR_ERR(rq[0]);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\ti915_request_get(rq[0]);\n\t\ti915_request_add(rq[0]);\n\t\tGEM_BUG_ON(rq[0]->postfix > ce[1]->ring->emit);\n\n\t\tif (!igt_wait_for_spinner(&spin, rq[0])) {\n\t\t\ti915_request_put(rq[0]);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\trq[1] = i915_request_create(ce[1]);\n\t\tif (IS_ERR(rq[1])) {\n\t\t\terr = PTR_ERR(rq[1]);\n\t\t\ti915_request_put(rq[0]);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\tif (!prio) {\n\t\t\t \n\t\t\ti915_request_await_dma_fence(rq[1], &rq[0]->fence);\n\t\t}\n\n\t\ti915_request_get(rq[1]);\n\t\ti915_request_add(rq[1]);\n\t\tGEM_BUG_ON(rq[1]->postfix <= rq[0]->postfix);\n\t\ti915_request_put(rq[0]);\n\n\t\tif (prio) {\n\t\t\tstruct i915_sched_attr attr = {\n\t\t\t\t.priority = prio,\n\t\t\t};\n\n\t\t\t \n\t\t\tengine->sched_engine->schedule(rq[1], &attr);\n\t\t}\n\n\t\t \n\t\trq[0] = i915_request_create(ce[0]);\n\t\tif (IS_ERR(rq[0])) {\n\t\t\terr = PTR_ERR(rq[0]);\n\t\t\ti915_request_put(rq[1]);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\ti915_request_await_dma_fence(rq[0], &rq[1]->fence);\n\t\ti915_request_get(rq[0]);\n\t\ti915_request_add(rq[0]);\n\t\tGEM_BUG_ON(rq[0]->postfix > rq[1]->postfix);\n\t\ti915_request_put(rq[1]);\n\t\ti915_request_put(rq[0]);\n\nerr_ce:\n\t\tintel_engine_flush_submission(engine);\n\t\tigt_spinner_end(&spin);\n\t\tfor (n = 0; n < ARRAY_SIZE(ce); n++) {\n\t\t\tif (IS_ERR_OR_NULL(ce[n]))\n\t\t\t\tbreak;\n\n\t\t\tintel_context_unpin(ce[n]);\n\t\t\tintel_context_put(ce[n]);\n\t\t}\n\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (igt_live_test_end(&t))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int live_unlite_switch(void *arg)\n{\n\treturn live_unlite_restore(arg, 0);\n}\n\nstatic int live_unlite_preempt(void *arg)\n{\n\treturn live_unlite_restore(arg, I915_PRIORITY_MAX);\n}\n\nstatic int live_unlite_ring(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct igt_spinner spin;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce[2] = {};\n\t\tstruct i915_request *rq;\n\t\tstruct igt_live_test t;\n\t\tint n;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tst_engine_heartbeat_disable(engine);\n\n\t\tfor (n = 0; n < ARRAY_SIZE(ce); n++) {\n\t\t\tstruct intel_context *tmp;\n\n\t\t\ttmp = intel_context_create(engine);\n\t\t\tif (IS_ERR(tmp)) {\n\t\t\t\terr = PTR_ERR(tmp);\n\t\t\t\tgoto err_ce;\n\t\t\t}\n\n\t\t\terr = intel_context_pin(tmp);\n\t\t\tif (err) {\n\t\t\t\tintel_context_put(tmp);\n\t\t\t\tgoto err_ce;\n\t\t\t}\n\n\t\t\tmemset32(tmp->ring->vaddr,\n\t\t\t\t 0xdeadbeef,  \n\t\t\t\t tmp->ring->vma->size / sizeof(u32));\n\n\t\t\tce[n] = tmp;\n\t\t}\n\n\t\t \n\t\trq = igt_spinner_create_request(&spin, ce[0], MI_ARB_CHECK);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\ti915_request_get(rq);\n\t\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\n\t\ti915_request_add(rq);\n\n\t\tif (!igt_wait_for_spinner(&spin, rq)) {\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\ti915_request_put(rq);\n\t\t\terr = -ETIME;\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\t \n\t\tn = 0;\n\t\twhile (intel_ring_direction(ce[0]->ring,\n\t\t\t\t\t    rq->wa_tail,\n\t\t\t\t\t    ce[0]->ring->tail) <= 0) {\n\t\t\tstruct i915_request *tmp;\n\n\t\t\ttmp = intel_context_create_request(ce[0]);\n\t\t\tif (IS_ERR(tmp)) {\n\t\t\t\terr = PTR_ERR(tmp);\n\t\t\t\ti915_request_put(rq);\n\t\t\t\tgoto err_ce;\n\t\t\t}\n\n\t\t\ti915_request_add(tmp);\n\t\t\tintel_engine_flush_submission(engine);\n\t\t\tn++;\n\t\t}\n\t\tintel_engine_flush_submission(engine);\n\t\tpr_debug(\"%s: Filled ring with %d nop tails {size:%x, tail:%x, emit:%x, rq.tail:%x}\\n\",\n\t\t\t engine->name, n,\n\t\t\t ce[0]->ring->size,\n\t\t\t ce[0]->ring->tail,\n\t\t\t ce[0]->ring->emit,\n\t\t\t rq->tail);\n\t\tGEM_BUG_ON(intel_ring_direction(ce[0]->ring,\n\t\t\t\t\t\trq->tail,\n\t\t\t\t\t\tce[0]->ring->tail) <= 0);\n\t\ti915_request_put(rq);\n\n\t\t \n\t\trq = intel_context_create_request(ce[1]);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\n\t\ti915_request_get(rq);\n\t\ti915_request_add(rq);\n\n\t\terr = wait_for_submit(engine, rq, HZ / 2);\n\t\ti915_request_put(rq);\n\t\tif (err) {\n\t\t\tpr_err(\"%s: preemption request was not submitted\\n\",\n\t\t\t       engine->name);\n\t\t\terr = -ETIME;\n\t\t}\n\n\t\tpr_debug(\"%s: ring[0]:{ tail:%x, emit:%x }, ring[1]:{ tail:%x, emit:%x }\\n\",\n\t\t\t engine->name,\n\t\t\t ce[0]->ring->tail, ce[0]->ring->emit,\n\t\t\t ce[1]->ring->tail, ce[1]->ring->emit);\n\nerr_ce:\n\t\tintel_engine_flush_submission(engine);\n\t\tigt_spinner_end(&spin);\n\t\tfor (n = 0; n < ARRAY_SIZE(ce); n++) {\n\t\t\tif (IS_ERR_OR_NULL(ce[n]))\n\t\t\t\tbreak;\n\n\t\t\tintel_context_unpin(ce[n]);\n\t\t\tintel_context_put(ce[n]);\n\t\t}\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (igt_live_test_end(&t))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int live_pin_rewind(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce;\n\t\tstruct i915_request *rq;\n\t\tstruct intel_ring *ring;\n\t\tstruct igt_live_test t;\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tbreak;\n\t\t}\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tbreak;\n\t\t}\n\n\t\terr = intel_context_pin(ce);\n\t\tif (err) {\n\t\t\tintel_context_put(ce);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\terr = i915_active_acquire(&ce->active);\n\t\tif (err) {\n\t\t\tintel_context_unpin(ce);\n\t\t\tintel_context_put(ce);\n\t\t\tbreak;\n\t\t}\n\t\tring = ce->ring;\n\n\t\t \n\t\tmemset32(ring->vaddr, STACK_MAGIC, ring->size / sizeof(u32));\n\t\tring->emit = ring->size / 2;\n\t\tring->tail = ring->emit;\n\t\tGEM_BUG_ON(ring->head);\n\n\t\tintel_context_unpin(ce);\n\n\t\t \n\t\tGEM_BUG_ON(intel_context_is_pinned(ce));\n\t\trq = intel_context_create_request(ce);\n\t\ti915_active_release(&ce->active);  \n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tbreak;\n\t\t}\n\t\tGEM_BUG_ON(!rq->head);\n\t\ti915_request_add(rq);\n\n\t\t \n\t\tif (igt_live_test_end(&t)) {\n\t\t\terr = -EIO;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn err;\n}\n\nstatic int engine_lock_reset_tasklet(struct intel_engine_cs *engine)\n{\n\ttasklet_disable(&engine->sched_engine->tasklet);\n\tlocal_bh_disable();\n\n\tif (test_and_set_bit(I915_RESET_ENGINE + engine->id,\n\t\t\t     &engine->gt->reset.flags)) {\n\t\tlocal_bh_enable();\n\t\ttasklet_enable(&engine->sched_engine->tasklet);\n\n\t\tintel_gt_set_wedged(engine->gt);\n\t\treturn -EBUSY;\n\t}\n\n\treturn 0;\n}\n\nstatic void engine_unlock_reset_tasklet(struct intel_engine_cs *engine)\n{\n\tclear_and_wake_up_bit(I915_RESET_ENGINE + engine->id,\n\t\t\t      &engine->gt->reset.flags);\n\n\tlocal_bh_enable();\n\ttasklet_enable(&engine->sched_engine->tasklet);\n}\n\nstatic int live_hold_reset(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tstruct igt_spinner spin;\n\tint err = 0;\n\n\t \n\n\tif (!intel_has_reset_engine(gt))\n\t\treturn 0;\n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce;\n\t\tstruct i915_request *rq;\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tbreak;\n\t\t}\n\n\t\tst_engine_heartbeat_disable(engine);\n\n\t\trq = igt_spinner_create_request(&spin, ce, MI_ARB_CHECK);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out;\n\t\t}\n\t\ti915_request_add(rq);\n\n\t\tif (!igt_wait_for_spinner(&spin, rq)) {\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -ETIME;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\n\t\terr = engine_lock_reset_tasklet(engine);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tengine->sched_engine->tasklet.callback(&engine->sched_engine->tasklet);\n\t\tGEM_BUG_ON(execlists_active(&engine->execlists) != rq);\n\n\t\ti915_request_get(rq);\n\t\texeclists_hold(engine, rq);\n\t\tGEM_BUG_ON(!i915_request_on_hold(rq));\n\n\t\t__intel_engine_reset_bh(engine, NULL);\n\t\tGEM_BUG_ON(rq->fence.error != -EIO);\n\n\t\tengine_unlock_reset_tasklet(engine);\n\n\t\t \n\t\tif (!i915_request_wait(rq, 0, HZ / 5)) {\n\t\t\tpr_err(\"%s: on hold request completed!\\n\",\n\t\t\t       engine->name);\n\t\t\ti915_request_put(rq);\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tGEM_BUG_ON(!i915_request_on_hold(rq));\n\n\t\t \n\t\texeclists_unhold(engine, rq);\n\t\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\t\tpr_err(\"%s: held request did not complete!\\n\",\n\t\t\t       engine->name);\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -ETIME;\n\t\t}\n\t\ti915_request_put(rq);\n\nout:\n\t\tst_engine_heartbeat_enable(engine);\n\t\tintel_context_put(ce);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic const char *error_repr(int err)\n{\n\treturn err ? \"bad\" : \"good\";\n}\n\nstatic int live_error_interrupt(void *arg)\n{\n\tstatic const struct error_phase {\n\t\tenum { GOOD = 0, BAD = -EIO } error[2];\n\t} phases[] = {\n\t\t{ { BAD,  GOOD } },\n\t\t{ { BAD,  BAD  } },\n\t\t{ { BAD,  GOOD } },\n\t\t{ { GOOD, GOOD } },  \n\t};\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\n\tif (!intel_has_reset_engine(gt))\n\t\treturn 0;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tconst struct error_phase *p;\n\t\tint err = 0;\n\n\t\tst_engine_heartbeat_disable(engine);\n\n\t\tfor (p = phases; p->error[0] != GOOD; p++) {\n\t\t\tstruct i915_request *client[ARRAY_SIZE(phases->error)];\n\t\t\tu32 *cs;\n\t\t\tint i;\n\n\t\t\tmemset(client, 0, sizeof(*client));\n\t\t\tfor (i = 0; i < ARRAY_SIZE(client); i++) {\n\t\t\t\tstruct intel_context *ce;\n\t\t\t\tstruct i915_request *rq;\n\n\t\t\t\tce = intel_context_create(engine);\n\t\t\t\tif (IS_ERR(ce)) {\n\t\t\t\t\terr = PTR_ERR(ce);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\trq = intel_context_create_request(ce);\n\t\t\t\tintel_context_put(ce);\n\t\t\t\tif (IS_ERR(rq)) {\n\t\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tif (rq->engine->emit_init_breadcrumb) {\n\t\t\t\t\terr = rq->engine->emit_init_breadcrumb(rq);\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\ti915_request_add(rq);\n\t\t\t\t\t\tgoto out;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tcs = intel_ring_begin(rq, 2);\n\t\t\t\tif (IS_ERR(cs)) {\n\t\t\t\t\ti915_request_add(rq);\n\t\t\t\t\terr = PTR_ERR(cs);\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\tif (p->error[i]) {\n\t\t\t\t\t*cs++ = 0xdeadbeef;\n\t\t\t\t\t*cs++ = 0xdeadbeef;\n\t\t\t\t} else {\n\t\t\t\t\t*cs++ = MI_NOOP;\n\t\t\t\t\t*cs++ = MI_NOOP;\n\t\t\t\t}\n\n\t\t\t\tclient[i] = i915_request_get(rq);\n\t\t\t\ti915_request_add(rq);\n\t\t\t}\n\n\t\t\terr = wait_for_submit(engine, client[0], HZ / 2);\n\t\t\tif (err) {\n\t\t\t\tpr_err(\"%s: first request did not start within time!\\n\",\n\t\t\t\t       engine->name);\n\t\t\t\terr = -ETIME;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tfor (i = 0; i < ARRAY_SIZE(client); i++) {\n\t\t\t\tif (i915_request_wait(client[i], 0, HZ / 5) < 0)\n\t\t\t\t\tpr_debug(\"%s: %s request incomplete!\\n\",\n\t\t\t\t\t\t engine->name,\n\t\t\t\t\t\t error_repr(p->error[i]));\n\n\t\t\t\tif (!i915_request_started(client[i])) {\n\t\t\t\t\tpr_err(\"%s: %s request not started!\\n\",\n\t\t\t\t\t       engine->name,\n\t\t\t\t\t       error_repr(p->error[i]));\n\t\t\t\t\terr = -ETIME;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tintel_engine_flush_submission(engine);\n\t\t\t\tif (client[i]->fence.error != p->error[i]) {\n\t\t\t\t\tpr_err(\"%s: %s request (%s) with wrong error code: %d\\n\",\n\t\t\t\t\t       engine->name,\n\t\t\t\t\t       error_repr(p->error[i]),\n\t\t\t\t\t       i915_request_completed(client[i]) ? \"completed\" : \"running\",\n\t\t\t\t\t       client[i]->fence.error);\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t}\n\nout:\n\t\t\tfor (i = 0; i < ARRAY_SIZE(client); i++)\n\t\t\t\tif (client[i])\n\t\t\t\t\ti915_request_put(client[i]);\n\t\t\tif (err) {\n\t\t\t\tpr_err(\"%s: failed at phase[%zd] { %d, %d }\\n\",\n\t\t\t\t       engine->name, p - phases,\n\t\t\t\t       p->error[0], p->error[1]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (err) {\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int\nemit_semaphore_chain(struct i915_request *rq, struct i915_vma *vma, int idx)\n{\n\tu32 *cs;\n\n\tcs = intel_ring_begin(rq, 10);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_ENABLE;\n\n\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\tMI_SEMAPHORE_GLOBAL_GTT |\n\t\tMI_SEMAPHORE_POLL |\n\t\tMI_SEMAPHORE_SAD_NEQ_SDD;\n\t*cs++ = 0;\n\t*cs++ = i915_ggtt_offset(vma) + 4 * idx;\n\t*cs++ = 0;\n\n\tif (idx > 0) {\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*cs++ = i915_ggtt_offset(vma) + 4 * (idx - 1);\n\t\t*cs++ = 0;\n\t\t*cs++ = 1;\n\t} else {\n\t\t*cs++ = MI_NOOP;\n\t\t*cs++ = MI_NOOP;\n\t\t*cs++ = MI_NOOP;\n\t\t*cs++ = MI_NOOP;\n\t}\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_DISABLE;\n\n\tintel_ring_advance(rq, cs);\n\treturn 0;\n}\n\nstatic struct i915_request *\nsemaphore_queue(struct intel_engine_cs *engine, struct i915_vma *vma, int idx)\n{\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tint err;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn ERR_CAST(ce);\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\tgoto out_ce;\n\n\terr = 0;\n\tif (rq->engine->emit_init_breadcrumb)\n\t\terr = rq->engine->emit_init_breadcrumb(rq);\n\tif (err == 0)\n\t\terr = emit_semaphore_chain(rq, vma, idx);\n\tif (err == 0)\n\t\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (err)\n\t\trq = ERR_PTR(err);\n\nout_ce:\n\tintel_context_put(ce);\n\treturn rq;\n}\n\nstatic int\nrelease_queue(struct intel_engine_cs *engine,\n\t      struct i915_vma *vma,\n\t      int idx, int prio)\n{\n\tstruct i915_sched_attr attr = {\n\t\t.priority = prio,\n\t};\n\tstruct i915_request *rq;\n\tu32 *cs;\n\n\trq = intel_engine_create_kernel_request(engine);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs)) {\n\t\ti915_request_add(rq);\n\t\treturn PTR_ERR(cs);\n\t}\n\n\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t*cs++ = i915_ggtt_offset(vma) + 4 * (idx - 1);\n\t*cs++ = 0;\n\t*cs++ = 1;\n\n\tintel_ring_advance(rq, cs);\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\tlocal_bh_disable();\n\tengine->sched_engine->schedule(rq, &attr);\n\tlocal_bh_enable();  \n\n\ti915_request_put(rq);\n\n\treturn 0;\n}\n\nstatic int\nslice_semaphore_queue(struct intel_engine_cs *outer,\n\t\t      struct i915_vma *vma,\n\t\t      int count)\n{\n\tstruct intel_engine_cs *engine;\n\tstruct i915_request *head;\n\tenum intel_engine_id id;\n\tint err, i, n = 0;\n\n\thead = semaphore_queue(outer, vma, n++);\n\tif (IS_ERR(head))\n\t\treturn PTR_ERR(head);\n\n\tfor_each_engine(engine, outer->gt, id) {\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tfor (i = 0; i < count; i++) {\n\t\t\tstruct i915_request *rq;\n\n\t\t\trq = semaphore_queue(engine, vma, n++);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ti915_request_put(rq);\n\t\t}\n\t}\n\n\terr = release_queue(outer, vma, n, I915_PRIORITY_BARRIER);\n\tif (err)\n\t\tgoto out;\n\n\tif (i915_request_wait(head, 0,\n\t\t\t      2 * outer->gt->info.num_engines * (count + 2) * (count + 3)) < 0) {\n\t\tpr_err(\"%s: Failed to slice along semaphore chain of length (%d, %d)!\\n\",\n\t\t       outer->name, count, n);\n\t\tGEM_TRACE_DUMP();\n\t\tintel_gt_set_wedged(outer->gt);\n\t\terr = -EIO;\n\t}\n\nout:\n\ti915_request_put(head);\n\treturn err;\n}\n\nstatic int live_timeslice_preempt(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct drm_i915_gem_object *obj;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tstruct i915_vma *vma;\n\tvoid *vaddr;\n\tint err = 0;\n\n\t \n\tif (!CONFIG_DRM_I915_TIMESLICE_DURATION)\n\t\treturn 0;\n\n\tobj = i915_gem_object_create_internal(gt->i915, PAGE_SIZE);\n\tif (IS_ERR(obj))\n\t\treturn PTR_ERR(obj);\n\n\tvma = i915_vma_instance(obj, &gt->ggtt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto err_obj;\n\t}\n\n\tvaddr = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WC);\n\tif (IS_ERR(vaddr)) {\n\t\terr = PTR_ERR(vaddr);\n\t\tgoto err_obj;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_GLOBAL);\n\tif (err)\n\t\tgoto err_map;\n\n\terr = i915_vma_sync(vma);\n\tif (err)\n\t\tgoto err_pin;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tmemset(vaddr, 0, PAGE_SIZE);\n\n\t\tst_engine_heartbeat_disable(engine);\n\t\terr = slice_semaphore_queue(engine, vma, 5);\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (err)\n\t\t\tgoto err_pin;\n\n\t\tif (igt_flush_test(gt->i915)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_pin;\n\t\t}\n\t}\n\nerr_pin:\n\ti915_vma_unpin(vma);\nerr_map:\n\ti915_gem_object_unpin_map(obj);\nerr_obj:\n\ti915_gem_object_put(obj);\n\treturn err;\n}\n\nstatic struct i915_request *\ncreate_rewinder(struct intel_context *ce,\n\t\tstruct i915_request *wait,\n\t\tvoid *slot, int idx)\n{\n\tconst u32 offset =\n\t\ti915_ggtt_offset(ce->engine->status_page.vma) +\n\t\toffset_in_page(slot);\n\tstruct i915_request *rq;\n\tu32 *cs;\n\tint err;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn rq;\n\n\tif (wait) {\n\t\terr = i915_request_await_dma_fence(rq, &wait->fence);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tcs = intel_ring_begin(rq, 14);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err;\n\t}\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_ENABLE;\n\t*cs++ = MI_NOOP;\n\n\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\tMI_SEMAPHORE_GLOBAL_GTT |\n\t\tMI_SEMAPHORE_POLL |\n\t\tMI_SEMAPHORE_SAD_GTE_SDD;\n\t*cs++ = idx;\n\t*cs++ = offset;\n\t*cs++ = 0;\n\n\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t*cs++ = i915_mmio_reg_offset(RING_TIMESTAMP(rq->engine->mmio_base));\n\t*cs++ = offset + idx * sizeof(u32);\n\t*cs++ = 0;\n\n\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t*cs++ = offset;\n\t*cs++ = 0;\n\t*cs++ = idx + 1;\n\n\tintel_ring_advance(rq, cs);\n\n\terr = 0;\nerr:\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (err) {\n\t\ti915_request_put(rq);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn rq;\n}\n\nstatic int live_timeslice_rewind(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\tif (!CONFIG_DRM_I915_TIMESLICE_DURATION)\n\t\treturn 0;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tenum { A1, A2, B1 };\n\t\tenum { X = 1, Z, Y };\n\t\tstruct i915_request *rq[3] = {};\n\t\tstruct intel_context *ce;\n\t\tunsigned long timeslice;\n\t\tint i, err = 0;\n\t\tu32 *slot;\n\n\t\tif (!intel_engine_has_timeslices(engine))\n\t\t\tcontinue;\n\n\t\t \n\n\t\tst_engine_heartbeat_disable(engine);\n\t\ttimeslice = xchg(&engine->props.timeslice_duration_ms, 1);\n\n\t\tslot = memset32(engine->status_page.addr + 1000, 0, 4);\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tgoto err;\n\t\t}\n\n\t\trq[A1] = create_rewinder(ce, NULL, slot, X);\n\t\tif (IS_ERR(rq[A1])) {\n\t\t\tintel_context_put(ce);\n\t\t\tgoto err;\n\t\t}\n\n\t\trq[A2] = create_rewinder(ce, NULL, slot, Y);\n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq[A2]))\n\t\t\tgoto err;\n\n\t\terr = wait_for_submit(engine, rq[A2], HZ / 2);\n\t\tif (err) {\n\t\t\tpr_err(\"%s: failed to submit first context\\n\",\n\t\t\t       engine->name);\n\t\t\tgoto err;\n\t\t}\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tgoto err;\n\t\t}\n\n\t\trq[B1] = create_rewinder(ce, rq[A1], slot, Z);\n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq[2]))\n\t\t\tgoto err;\n\n\t\terr = wait_for_submit(engine, rq[B1], HZ / 2);\n\t\tif (err) {\n\t\t\tpr_err(\"%s: failed to submit second context\\n\",\n\t\t\t       engine->name);\n\t\t\tgoto err;\n\t\t}\n\n\t\t \n\t\tENGINE_TRACE(engine, \"forcing tasklet for rewind\\n\");\n\t\twhile (i915_request_is_active(rq[A2])) {  \n\t\t\t \n\t\t\tdel_timer(&engine->execlists.timer);\n\t\t\ttasklet_hi_schedule(&engine->sched_engine->tasklet);\n\t\t\tintel_engine_flush_submission(engine);\n\t\t}\n\t\t \n\t\tGEM_BUG_ON(!i915_request_is_active(rq[A1]));\n\t\tGEM_BUG_ON(!i915_request_is_active(rq[B1]));\n\t\tGEM_BUG_ON(i915_request_is_active(rq[A2]));\n\n\t\t \n\t\tslot[0] = 1;\n\t\twmb();  \n\n\t\tfor (i = 1; i <= 3; i++) {\n\t\t\tunsigned long timeout = jiffies + HZ / 2;\n\n\t\t\twhile (!READ_ONCE(slot[i]) &&\n\t\t\t       time_before(jiffies, timeout))\n\t\t\t\t;\n\n\t\t\tif (!time_before(jiffies, timeout)) {\n\t\t\t\tpr_err(\"%s: rq[%d] timed out\\n\",\n\t\t\t\t       engine->name, i - 1);\n\t\t\t\terr = -ETIME;\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tpr_debug(\"%s: slot[%d]:%x\\n\", engine->name, i, slot[i]);\n\t\t}\n\n\t\t \n\t\tif (slot[Z] - slot[X] >= slot[Y] - slot[X]) {\n\t\t\tpr_err(\"%s: timeslicing did not run context B [%u] before A [%u]!\\n\",\n\t\t\t       engine->name,\n\t\t\t       slot[Z] - slot[X],\n\t\t\t       slot[Y] - slot[X]);\n\t\t\terr = -EINVAL;\n\t\t}\n\nerr:\n\t\tmemset32(&slot[0], -1, 4);\n\t\twmb();\n\n\t\tengine->props.timeslice_duration_ms = timeslice;\n\t\tst_engine_heartbeat_enable(engine);\n\t\tfor (i = 0; i < 3; i++)\n\t\t\ti915_request_put(rq[i]);\n\t\tif (igt_flush_test(gt->i915))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic struct i915_request *nop_request(struct intel_engine_cs *engine)\n{\n\tstruct i915_request *rq;\n\n\trq = intel_engine_create_kernel_request(engine);\n\tif (IS_ERR(rq))\n\t\treturn rq;\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\treturn rq;\n}\n\nstatic long slice_timeout(struct intel_engine_cs *engine)\n{\n\tlong timeout;\n\n\t \n\ttimeout = 2 * msecs_to_jiffies_timeout(timeslice(engine));\n\n\t \n\ttimeout += HZ / 5;\n\n\treturn timeout + 1;\n}\n\nstatic int live_timeslice_queue(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct drm_i915_gem_object *obj;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tstruct i915_vma *vma;\n\tvoid *vaddr;\n\tint err = 0;\n\n\t \n\tif (!CONFIG_DRM_I915_TIMESLICE_DURATION)\n\t\treturn 0;\n\n\tobj = i915_gem_object_create_internal(gt->i915, PAGE_SIZE);\n\tif (IS_ERR(obj))\n\t\treturn PTR_ERR(obj);\n\n\tvma = i915_vma_instance(obj, &gt->ggtt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto err_obj;\n\t}\n\n\tvaddr = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WC);\n\tif (IS_ERR(vaddr)) {\n\t\terr = PTR_ERR(vaddr);\n\t\tgoto err_obj;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_GLOBAL);\n\tif (err)\n\t\tgoto err_map;\n\n\terr = i915_vma_sync(vma);\n\tif (err)\n\t\tgoto err_pin;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_sched_attr attr = { .priority = I915_PRIORITY_MAX };\n\t\tstruct i915_request *rq, *nop;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tst_engine_heartbeat_disable(engine);\n\t\tmemset(vaddr, 0, PAGE_SIZE);\n\n\t\t \n\t\trq = semaphore_queue(engine, vma, 0);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_heartbeat;\n\t\t}\n\t\tengine->sched_engine->schedule(rq, &attr);\n\t\terr = wait_for_submit(engine, rq, HZ / 2);\n\t\tif (err) {\n\t\t\tpr_err(\"%s: Timed out trying to submit semaphores\\n\",\n\t\t\t       engine->name);\n\t\t\tgoto err_rq;\n\t\t}\n\n\t\t \n\t\tnop = nop_request(engine);\n\t\tif (IS_ERR(nop)) {\n\t\t\terr = PTR_ERR(nop);\n\t\t\tgoto err_rq;\n\t\t}\n\t\terr = wait_for_submit(engine, nop, HZ / 2);\n\t\ti915_request_put(nop);\n\t\tif (err) {\n\t\t\tpr_err(\"%s: Timed out trying to submit nop\\n\",\n\t\t\t       engine->name);\n\t\t\tgoto err_rq;\n\t\t}\n\n\t\tGEM_BUG_ON(i915_request_completed(rq));\n\t\tGEM_BUG_ON(execlists_active(&engine->execlists) != rq);\n\n\t\t \n\t\terr = release_queue(engine, vma, 1, effective_prio(rq));\n\t\tif (err)\n\t\t\tgoto err_rq;\n\n\t\t \n\t\tdo {\n\t\t\tcond_resched();\n\t\t\tintel_engine_flush_submission(engine);\n\t\t} while (READ_ONCE(engine->execlists.pending[0]));\n\n\t\t \n\t\tif (i915_request_wait(rq, 0, slice_timeout(engine)) < 0) {\n\t\t\tstruct drm_printer p =\n\t\t\t\tdrm_info_printer(gt->i915->drm.dev);\n\n\t\t\tpr_err(\"%s: Failed to timeslice into queue\\n\",\n\t\t\t       engine->name);\n\t\t\tintel_engine_dump(engine, &p,\n\t\t\t\t\t  \"%s\\n\", engine->name);\n\n\t\t\tmemset(vaddr, 0xff, PAGE_SIZE);\n\t\t\terr = -EIO;\n\t\t}\nerr_rq:\n\t\ti915_request_put(rq);\nerr_heartbeat:\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nerr_pin:\n\ti915_vma_unpin(vma);\nerr_map:\n\ti915_gem_object_unpin_map(obj);\nerr_obj:\n\ti915_gem_object_put(obj);\n\treturn err;\n}\n\nstatic int live_timeslice_nopreempt(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tstruct igt_spinner spin;\n\tint err = 0;\n\n\t \n\tif (!CONFIG_DRM_I915_TIMESLICE_DURATION)\n\t\treturn 0;\n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce;\n\t\tstruct i915_request *rq;\n\t\tunsigned long timeslice;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tbreak;\n\t\t}\n\n\t\tst_engine_heartbeat_disable(engine);\n\t\ttimeslice = xchg(&engine->props.timeslice_duration_ms, 1);\n\n\t\t \n\n\t\trq = igt_spinner_create_request(&spin, ce, MI_ARB_CHECK);\n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out_heartbeat;\n\t\t}\n\n\t\ti915_request_get(rq);\n\t\ti915_request_add(rq);\n\n\t\tif (!igt_wait_for_spinner(&spin, rq)) {\n\t\t\ti915_request_put(rq);\n\t\t\terr = -ETIME;\n\t\t\tgoto out_spin;\n\t\t}\n\n\t\tset_bit(I915_FENCE_FLAG_NOPREEMPT, &rq->fence.flags);\n\t\ti915_request_put(rq);\n\n\t\t \n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tgoto out_spin;\n\t\t}\n\n\t\trq = intel_context_create_request(ce);\n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out_spin;\n\t\t}\n\n\t\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\n\t\ti915_request_get(rq);\n\t\ti915_request_add(rq);\n\n\t\t \n\t\tif (wait_for_submit(engine, rq, HZ / 2)) {\n\t\t\ti915_request_put(rq);\n\t\t\terr = -ETIME;\n\t\t\tgoto out_spin;\n\t\t}\n\n\t\t \n\t\tif (i915_request_wait(rq, 0, slice_timeout(engine)) >= 0) {\n\t\t\tpr_err(\"%s: I915_PRIORITY_BARRIER request completed, bypassing no-preempt request\\n\",\n\t\t\t       engine->name);\n\t\t\terr = -EINVAL;\n\t\t}\n\t\ti915_request_put(rq);\n\nout_spin:\n\t\tigt_spinner_end(&spin);\nout_heartbeat:\n\t\txchg(&engine->props.timeslice_duration_ms, timeslice);\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\tif (igt_flush_test(gt->i915)) {\n\t\t\terr = -EIO;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int live_busywait_preempt(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct i915_gem_context *ctx_hi, *ctx_lo;\n\tstruct intel_engine_cs *engine;\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\tenum intel_engine_id id;\n\tu32 *map;\n\tint err;\n\n\t \n\n\tctx_hi = kernel_context(gt->i915, NULL);\n\tif (IS_ERR(ctx_hi))\n\t\treturn PTR_ERR(ctx_hi);\n\n\tctx_hi->sched.priority = I915_CONTEXT_MAX_USER_PRIORITY;\n\n\tctx_lo = kernel_context(gt->i915, NULL);\n\tif (IS_ERR(ctx_lo)) {\n\t\terr = PTR_ERR(ctx_lo);\n\t\tgoto err_ctx_hi;\n\t}\n\n\tctx_lo->sched.priority = I915_CONTEXT_MIN_USER_PRIORITY;\n\n\tobj = i915_gem_object_create_internal(gt->i915, PAGE_SIZE);\n\tif (IS_ERR(obj)) {\n\t\terr = PTR_ERR(obj);\n\t\tgoto err_ctx_lo;\n\t}\n\n\tmap = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WC);\n\tif (IS_ERR(map)) {\n\t\terr = PTR_ERR(map);\n\t\tgoto err_obj;\n\t}\n\n\tvma = i915_vma_instance(obj, &gt->ggtt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto err_map;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_GLOBAL);\n\tif (err)\n\t\tgoto err_map;\n\n\terr = i915_vma_sync(vma);\n\tif (err)\n\t\tgoto err_vma;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_request *lo, *hi;\n\t\tstruct igt_live_test t;\n\t\tu32 *cs;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_vma;\n\t\t}\n\n\t\t \n\n\t\tlo = igt_request_alloc(ctx_lo, engine);\n\t\tif (IS_ERR(lo)) {\n\t\t\terr = PTR_ERR(lo);\n\t\t\tgoto err_vma;\n\t\t}\n\n\t\tcs = intel_ring_begin(lo, 8);\n\t\tif (IS_ERR(cs)) {\n\t\t\terr = PTR_ERR(cs);\n\t\t\ti915_request_add(lo);\n\t\t\tgoto err_vma;\n\t\t}\n\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*cs++ = i915_ggtt_offset(vma);\n\t\t*cs++ = 0;\n\t\t*cs++ = 1;\n\n\t\t \n\n\t\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\t\tMI_SEMAPHORE_GLOBAL_GTT |\n\t\t\tMI_SEMAPHORE_POLL |\n\t\t\tMI_SEMAPHORE_SAD_EQ_SDD;\n\t\t*cs++ = 0;\n\t\t*cs++ = i915_ggtt_offset(vma);\n\t\t*cs++ = 0;\n\n\t\tintel_ring_advance(lo, cs);\n\n\t\ti915_request_get(lo);\n\t\ti915_request_add(lo);\n\n\t\tif (wait_for(READ_ONCE(*map), 10)) {\n\t\t\ti915_request_put(lo);\n\t\t\terr = -ETIMEDOUT;\n\t\t\tgoto err_vma;\n\t\t}\n\n\t\t \n\t\tif (i915_request_wait(lo, 0, 1) != -ETIME) {\n\t\t\ti915_request_put(lo);\n\t\t\tpr_err(\"%s: Busywaiting request did not!\\n\",\n\t\t\t       engine->name);\n\t\t\terr = -EIO;\n\t\t\tgoto err_vma;\n\t\t}\n\n\t\thi = igt_request_alloc(ctx_hi, engine);\n\t\tif (IS_ERR(hi)) {\n\t\t\terr = PTR_ERR(hi);\n\t\t\ti915_request_put(lo);\n\t\t\tgoto err_vma;\n\t\t}\n\n\t\tcs = intel_ring_begin(hi, 4);\n\t\tif (IS_ERR(cs)) {\n\t\t\terr = PTR_ERR(cs);\n\t\t\ti915_request_add(hi);\n\t\t\ti915_request_put(lo);\n\t\t\tgoto err_vma;\n\t\t}\n\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*cs++ = i915_ggtt_offset(vma);\n\t\t*cs++ = 0;\n\t\t*cs++ = 0;\n\n\t\tintel_ring_advance(hi, cs);\n\t\ti915_request_add(hi);\n\n\t\tif (i915_request_wait(lo, 0, HZ / 5) < 0) {\n\t\t\tstruct drm_printer p = drm_info_printer(gt->i915->drm.dev);\n\n\t\t\tpr_err(\"%s: Failed to preempt semaphore busywait!\\n\",\n\t\t\t       engine->name);\n\n\t\t\tintel_engine_dump(engine, &p, \"%s\\n\", engine->name);\n\t\t\tGEM_TRACE_DUMP();\n\n\t\t\ti915_request_put(lo);\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -EIO;\n\t\t\tgoto err_vma;\n\t\t}\n\t\tGEM_BUG_ON(READ_ONCE(*map));\n\t\ti915_request_put(lo);\n\n\t\tif (igt_live_test_end(&t)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_vma;\n\t\t}\n\t}\n\n\terr = 0;\nerr_vma:\n\ti915_vma_unpin(vma);\nerr_map:\n\ti915_gem_object_unpin_map(obj);\nerr_obj:\n\ti915_gem_object_put(obj);\nerr_ctx_lo:\n\tkernel_context_close(ctx_lo);\nerr_ctx_hi:\n\tkernel_context_close(ctx_hi);\n\treturn err;\n}\n\nstatic struct i915_request *\nspinner_create_request(struct igt_spinner *spin,\n\t\t       struct i915_gem_context *ctx,\n\t\t       struct intel_engine_cs *engine,\n\t\t       u32 arb)\n{\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\n\tce = i915_gem_context_get_engine(ctx, engine->legacy_idx);\n\tif (IS_ERR(ce))\n\t\treturn ERR_CAST(ce);\n\n\trq = igt_spinner_create_request(spin, ce, arb);\n\tintel_context_put(ce);\n\treturn rq;\n}\n\nstatic int live_preempt(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct i915_gem_context *ctx_hi, *ctx_lo;\n\tstruct igt_spinner spin_hi, spin_lo;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = -ENOMEM;\n\n\tctx_hi = kernel_context(gt->i915, NULL);\n\tif (!ctx_hi)\n\t\treturn -ENOMEM;\n\tctx_hi->sched.priority = I915_CONTEXT_MAX_USER_PRIORITY;\n\n\tctx_lo = kernel_context(gt->i915, NULL);\n\tif (!ctx_lo)\n\t\tgoto err_ctx_hi;\n\tctx_lo->sched.priority = I915_CONTEXT_MIN_USER_PRIORITY;\n\n\tif (igt_spinner_init(&spin_hi, gt))\n\t\tgoto err_ctx_lo;\n\n\tif (igt_spinner_init(&spin_lo, gt))\n\t\tgoto err_spin_hi;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct igt_live_test t;\n\t\tstruct i915_request *rq;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\trq = spinner_create_request(&spin_lo, ctx_lo, engine,\n\t\t\t\t\t    MI_ARB_CHECK);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t\tif (!igt_wait_for_spinner(&spin_lo, rq)) {\n\t\t\tGEM_TRACE(\"lo spinner failed to start\\n\");\n\t\t\tGEM_TRACE_DUMP();\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -EIO;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\trq = spinner_create_request(&spin_hi, ctx_hi, engine,\n\t\t\t\t\t    MI_ARB_CHECK);\n\t\tif (IS_ERR(rq)) {\n\t\t\tigt_spinner_end(&spin_lo);\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t\tif (!igt_wait_for_spinner(&spin_hi, rq)) {\n\t\t\tGEM_TRACE(\"hi spinner failed to start\\n\");\n\t\t\tGEM_TRACE_DUMP();\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -EIO;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\tigt_spinner_end(&spin_hi);\n\t\tigt_spinner_end(&spin_lo);\n\n\t\tif (igt_live_test_end(&t)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\t}\n\n\terr = 0;\nerr_spin_lo:\n\tigt_spinner_fini(&spin_lo);\nerr_spin_hi:\n\tigt_spinner_fini(&spin_hi);\nerr_ctx_lo:\n\tkernel_context_close(ctx_lo);\nerr_ctx_hi:\n\tkernel_context_close(ctx_hi);\n\treturn err;\n}\n\nstatic int live_late_preempt(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct i915_gem_context *ctx_hi, *ctx_lo;\n\tstruct igt_spinner spin_hi, spin_lo;\n\tstruct intel_engine_cs *engine;\n\tstruct i915_sched_attr attr = {};\n\tenum intel_engine_id id;\n\tint err = -ENOMEM;\n\n\tctx_hi = kernel_context(gt->i915, NULL);\n\tif (!ctx_hi)\n\t\treturn -ENOMEM;\n\n\tctx_lo = kernel_context(gt->i915, NULL);\n\tif (!ctx_lo)\n\t\tgoto err_ctx_hi;\n\n\tif (igt_spinner_init(&spin_hi, gt))\n\t\tgoto err_ctx_lo;\n\n\tif (igt_spinner_init(&spin_lo, gt))\n\t\tgoto err_spin_hi;\n\n\t \n\tctx_lo->sched.priority = 1;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct igt_live_test t;\n\t\tstruct i915_request *rq;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\trq = spinner_create_request(&spin_lo, ctx_lo, engine,\n\t\t\t\t\t    MI_ARB_CHECK);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t\tif (!igt_wait_for_spinner(&spin_lo, rq)) {\n\t\t\tpr_err(\"First context failed to start\\n\");\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\trq = spinner_create_request(&spin_hi, ctx_hi, engine,\n\t\t\t\t\t    MI_NOOP);\n\t\tif (IS_ERR(rq)) {\n\t\t\tigt_spinner_end(&spin_lo);\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t\tif (igt_wait_for_spinner(&spin_hi, rq)) {\n\t\t\tpr_err(\"Second context overtook first?\\n\");\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\tattr.priority = I915_PRIORITY_MAX;\n\t\tengine->sched_engine->schedule(rq, &attr);\n\n\t\tif (!igt_wait_for_spinner(&spin_hi, rq)) {\n\t\t\tpr_err(\"High priority context failed to preempt the low priority context\\n\");\n\t\t\tGEM_TRACE_DUMP();\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\tigt_spinner_end(&spin_hi);\n\t\tigt_spinner_end(&spin_lo);\n\n\t\tif (igt_live_test_end(&t)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\t}\n\n\terr = 0;\nerr_spin_lo:\n\tigt_spinner_fini(&spin_lo);\nerr_spin_hi:\n\tigt_spinner_fini(&spin_hi);\nerr_ctx_lo:\n\tkernel_context_close(ctx_lo);\nerr_ctx_hi:\n\tkernel_context_close(ctx_hi);\n\treturn err;\n\nerr_wedged:\n\tigt_spinner_end(&spin_hi);\n\tigt_spinner_end(&spin_lo);\n\tintel_gt_set_wedged(gt);\n\terr = -EIO;\n\tgoto err_spin_lo;\n}\n\nstruct preempt_client {\n\tstruct igt_spinner spin;\n\tstruct i915_gem_context *ctx;\n};\n\nstatic int preempt_client_init(struct intel_gt *gt, struct preempt_client *c)\n{\n\tc->ctx = kernel_context(gt->i915, NULL);\n\tif (!c->ctx)\n\t\treturn -ENOMEM;\n\n\tif (igt_spinner_init(&c->spin, gt))\n\t\tgoto err_ctx;\n\n\treturn 0;\n\nerr_ctx:\n\tkernel_context_close(c->ctx);\n\treturn -ENOMEM;\n}\n\nstatic void preempt_client_fini(struct preempt_client *c)\n{\n\tigt_spinner_fini(&c->spin);\n\tkernel_context_close(c->ctx);\n}\n\nstatic int live_nopreempt(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct preempt_client a, b;\n\tenum intel_engine_id id;\n\tint err = -ENOMEM;\n\n\t \n\n\tif (preempt_client_init(gt, &a))\n\t\treturn -ENOMEM;\n\tif (preempt_client_init(gt, &b))\n\t\tgoto err_client_a;\n\tb.ctx->sched.priority = I915_PRIORITY_MAX;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_request *rq_a, *rq_b;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tengine->execlists.preempt_hang.count = 0;\n\n\t\trq_a = spinner_create_request(&a.spin,\n\t\t\t\t\t      a.ctx, engine,\n\t\t\t\t\t      MI_ARB_CHECK);\n\t\tif (IS_ERR(rq_a)) {\n\t\t\terr = PTR_ERR(rq_a);\n\t\t\tgoto err_client_b;\n\t\t}\n\n\t\t \n\t\t__set_bit(I915_FENCE_FLAG_NOPREEMPT, &rq_a->fence.flags);\n\n\t\ti915_request_add(rq_a);\n\t\tif (!igt_wait_for_spinner(&a.spin, rq_a)) {\n\t\t\tpr_err(\"First client failed to start\\n\");\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\trq_b = spinner_create_request(&b.spin,\n\t\t\t\t\t      b.ctx, engine,\n\t\t\t\t\t      MI_ARB_CHECK);\n\t\tif (IS_ERR(rq_b)) {\n\t\t\terr = PTR_ERR(rq_b);\n\t\t\tgoto err_client_b;\n\t\t}\n\n\t\ti915_request_add(rq_b);\n\n\t\t \n\t\tGEM_BUG_ON(rq_prio(rq_b) <= rq_prio(rq_a));\n\n\t\t \n\t\tif (igt_wait_for_spinner(&b.spin, rq_b)) {\n\t\t\tpr_err(\"Second client started too early!\\n\");\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\tigt_spinner_end(&a.spin);\n\n\t\tif (!igt_wait_for_spinner(&b.spin, rq_b)) {\n\t\t\tpr_err(\"Second client failed to start\\n\");\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\tigt_spinner_end(&b.spin);\n\n\t\tif (engine->execlists.preempt_hang.count) {\n\t\t\tpr_err(\"Preemption recorded x%d; should have been suppressed!\\n\",\n\t\t\t       engine->execlists.preempt_hang.count);\n\t\t\terr = -EINVAL;\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\tif (igt_flush_test(gt->i915))\n\t\t\tgoto err_wedged;\n\t}\n\n\terr = 0;\nerr_client_b:\n\tpreempt_client_fini(&b);\nerr_client_a:\n\tpreempt_client_fini(&a);\n\treturn err;\n\nerr_wedged:\n\tigt_spinner_end(&b.spin);\n\tigt_spinner_end(&a.spin);\n\tintel_gt_set_wedged(gt);\n\terr = -EIO;\n\tgoto err_client_b;\n}\n\nstruct live_preempt_cancel {\n\tstruct intel_engine_cs *engine;\n\tstruct preempt_client a, b;\n};\n\nstatic int __cancel_active0(struct live_preempt_cancel *arg)\n{\n\tstruct i915_request *rq;\n\tstruct igt_live_test t;\n\tint err;\n\n\t \n\tGEM_TRACE(\"%s(%s)\\n\", __func__, arg->engine->name);\n\tif (igt_live_test_begin(&t, arg->engine->i915,\n\t\t\t\t__func__, arg->engine->name))\n\t\treturn -EIO;\n\n\trq = spinner_create_request(&arg->a.spin,\n\t\t\t\t    arg->a.ctx, arg->engine,\n\t\t\t\t    MI_ARB_CHECK);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tclear_bit(CONTEXT_BANNED, &rq->context->flags);\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (!igt_wait_for_spinner(&arg->a.spin, rq)) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\tintel_context_ban(rq->context, rq);\n\terr = intel_engine_pulse(arg->engine);\n\tif (err)\n\t\tgoto out;\n\n\terr = wait_for_reset(arg->engine, rq, HZ / 2);\n\tif (err) {\n\t\tpr_err(\"Cancelled inflight0 request did not reset\\n\");\n\t\tgoto out;\n\t}\n\nout:\n\ti915_request_put(rq);\n\tif (igt_live_test_end(&t))\n\t\terr = -EIO;\n\treturn err;\n}\n\nstatic int __cancel_active1(struct live_preempt_cancel *arg)\n{\n\tstruct i915_request *rq[2] = {};\n\tstruct igt_live_test t;\n\tint err;\n\n\t \n\tGEM_TRACE(\"%s(%s)\\n\", __func__, arg->engine->name);\n\tif (igt_live_test_begin(&t, arg->engine->i915,\n\t\t\t\t__func__, arg->engine->name))\n\t\treturn -EIO;\n\n\trq[0] = spinner_create_request(&arg->a.spin,\n\t\t\t\t       arg->a.ctx, arg->engine,\n\t\t\t\t       MI_NOOP);  \n\tif (IS_ERR(rq[0]))\n\t\treturn PTR_ERR(rq[0]);\n\n\tclear_bit(CONTEXT_BANNED, &rq[0]->context->flags);\n\ti915_request_get(rq[0]);\n\ti915_request_add(rq[0]);\n\tif (!igt_wait_for_spinner(&arg->a.spin, rq[0])) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\trq[1] = spinner_create_request(&arg->b.spin,\n\t\t\t\t       arg->b.ctx, arg->engine,\n\t\t\t\t       MI_ARB_CHECK);\n\tif (IS_ERR(rq[1])) {\n\t\terr = PTR_ERR(rq[1]);\n\t\tgoto out;\n\t}\n\n\tclear_bit(CONTEXT_BANNED, &rq[1]->context->flags);\n\ti915_request_get(rq[1]);\n\terr = i915_request_await_dma_fence(rq[1], &rq[0]->fence);\n\ti915_request_add(rq[1]);\n\tif (err)\n\t\tgoto out;\n\n\tintel_context_ban(rq[1]->context, rq[1]);\n\terr = intel_engine_pulse(arg->engine);\n\tif (err)\n\t\tgoto out;\n\n\tigt_spinner_end(&arg->a.spin);\n\terr = wait_for_reset(arg->engine, rq[1], HZ / 2);\n\tif (err)\n\t\tgoto out;\n\n\tif (rq[0]->fence.error != 0) {\n\t\tpr_err(\"Normal inflight0 request did not complete\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (rq[1]->fence.error != -EIO) {\n\t\tpr_err(\"Cancelled inflight1 request did not report -EIO\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\nout:\n\ti915_request_put(rq[1]);\n\ti915_request_put(rq[0]);\n\tif (igt_live_test_end(&t))\n\t\terr = -EIO;\n\treturn err;\n}\n\nstatic int __cancel_queued(struct live_preempt_cancel *arg)\n{\n\tstruct i915_request *rq[3] = {};\n\tstruct igt_live_test t;\n\tint err;\n\n\t \n\tGEM_TRACE(\"%s(%s)\\n\", __func__, arg->engine->name);\n\tif (igt_live_test_begin(&t, arg->engine->i915,\n\t\t\t\t__func__, arg->engine->name))\n\t\treturn -EIO;\n\n\trq[0] = spinner_create_request(&arg->a.spin,\n\t\t\t\t       arg->a.ctx, arg->engine,\n\t\t\t\t       MI_ARB_CHECK);\n\tif (IS_ERR(rq[0]))\n\t\treturn PTR_ERR(rq[0]);\n\n\tclear_bit(CONTEXT_BANNED, &rq[0]->context->flags);\n\ti915_request_get(rq[0]);\n\ti915_request_add(rq[0]);\n\tif (!igt_wait_for_spinner(&arg->a.spin, rq[0])) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\trq[1] = igt_request_alloc(arg->b.ctx, arg->engine);\n\tif (IS_ERR(rq[1])) {\n\t\terr = PTR_ERR(rq[1]);\n\t\tgoto out;\n\t}\n\n\tclear_bit(CONTEXT_BANNED, &rq[1]->context->flags);\n\ti915_request_get(rq[1]);\n\terr = i915_request_await_dma_fence(rq[1], &rq[0]->fence);\n\ti915_request_add(rq[1]);\n\tif (err)\n\t\tgoto out;\n\n\trq[2] = spinner_create_request(&arg->b.spin,\n\t\t\t\t       arg->a.ctx, arg->engine,\n\t\t\t\t       MI_ARB_CHECK);\n\tif (IS_ERR(rq[2])) {\n\t\terr = PTR_ERR(rq[2]);\n\t\tgoto out;\n\t}\n\n\ti915_request_get(rq[2]);\n\terr = i915_request_await_dma_fence(rq[2], &rq[1]->fence);\n\ti915_request_add(rq[2]);\n\tif (err)\n\t\tgoto out;\n\n\tintel_context_ban(rq[2]->context, rq[2]);\n\terr = intel_engine_pulse(arg->engine);\n\tif (err)\n\t\tgoto out;\n\n\terr = wait_for_reset(arg->engine, rq[2], HZ / 2);\n\tif (err)\n\t\tgoto out;\n\n\tif (rq[0]->fence.error != -EIO) {\n\t\tpr_err(\"Cancelled inflight0 request did not report -EIO\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t \n\tif (intel_engine_has_semaphores(rq[1]->engine) &&\n\t    rq[1]->fence.error != 0) {\n\t\tpr_err(\"Normal inflight1 request did not complete\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (rq[2]->fence.error != -EIO) {\n\t\tpr_err(\"Cancelled queued request did not report -EIO\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\nout:\n\ti915_request_put(rq[2]);\n\ti915_request_put(rq[1]);\n\ti915_request_put(rq[0]);\n\tif (igt_live_test_end(&t))\n\t\terr = -EIO;\n\treturn err;\n}\n\nstatic int __cancel_hostile(struct live_preempt_cancel *arg)\n{\n\tstruct i915_request *rq;\n\tint err;\n\n\t \n\tif (!CONFIG_DRM_I915_PREEMPT_TIMEOUT)\n\t\treturn 0;\n\n\tif (!intel_has_reset_engine(arg->engine->gt))\n\t\treturn 0;\n\n\tGEM_TRACE(\"%s(%s)\\n\", __func__, arg->engine->name);\n\trq = spinner_create_request(&arg->a.spin,\n\t\t\t\t    arg->a.ctx, arg->engine,\n\t\t\t\t    MI_NOOP);  \n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tclear_bit(CONTEXT_BANNED, &rq->context->flags);\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (!igt_wait_for_spinner(&arg->a.spin, rq)) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\tintel_context_ban(rq->context, rq);\n\terr = intel_engine_pulse(arg->engine);  \n\tif (err)\n\t\tgoto out;\n\n\terr = wait_for_reset(arg->engine, rq, HZ / 2);\n\tif (err) {\n\t\tpr_err(\"Cancelled inflight0 request did not reset\\n\");\n\t\tgoto out;\n\t}\n\nout:\n\ti915_request_put(rq);\n\tif (igt_flush_test(arg->engine->i915))\n\t\terr = -EIO;\n\treturn err;\n}\n\nstatic void force_reset_timeout(struct intel_engine_cs *engine)\n{\n\tengine->reset_timeout.probability = 999;\n\tatomic_set(&engine->reset_timeout.times, -1);\n}\n\nstatic void cancel_reset_timeout(struct intel_engine_cs *engine)\n{\n\tmemset(&engine->reset_timeout, 0, sizeof(engine->reset_timeout));\n}\n\nstatic int __cancel_fail(struct live_preempt_cancel *arg)\n{\n\tstruct intel_engine_cs *engine = arg->engine;\n\tstruct i915_request *rq;\n\tint err;\n\n\tif (!CONFIG_DRM_I915_PREEMPT_TIMEOUT)\n\t\treturn 0;\n\n\tif (!intel_has_reset_engine(engine->gt))\n\t\treturn 0;\n\n\tGEM_TRACE(\"%s(%s)\\n\", __func__, engine->name);\n\trq = spinner_create_request(&arg->a.spin,\n\t\t\t\t    arg->a.ctx, engine,\n\t\t\t\t    MI_NOOP);  \n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tclear_bit(CONTEXT_BANNED, &rq->context->flags);\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (!igt_wait_for_spinner(&arg->a.spin, rq)) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\tintel_context_set_banned(rq->context);\n\n\terr = intel_engine_pulse(engine);\n\tif (err)\n\t\tgoto out;\n\n\tforce_reset_timeout(engine);\n\n\t \n\twhile (!engine->execlists.pending[0])\n\t\tintel_engine_flush_submission(engine);\n\tdel_timer_sync(&engine->execlists.preempt);\n\tintel_engine_flush_submission(engine);\n\n\tcancel_reset_timeout(engine);\n\n\t \n\tintel_engine_set_heartbeat(engine, 1);\n\terr = wait_for_reset(engine, rq, HZ / 2);\n\tintel_engine_set_heartbeat(engine,\n\t\t\t\t   engine->defaults.heartbeat_interval_ms);\n\tif (err) {\n\t\tpr_err(\"Cancelled inflight0 request did not reset\\n\");\n\t\tgoto out;\n\t}\n\nout:\n\ti915_request_put(rq);\n\tif (igt_flush_test(engine->i915))\n\t\terr = -EIO;\n\treturn err;\n}\n\nstatic int live_preempt_cancel(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct live_preempt_cancel data;\n\tenum intel_engine_id id;\n\tint err = -ENOMEM;\n\n\t \n\n\tif (preempt_client_init(gt, &data.a))\n\t\treturn -ENOMEM;\n\tif (preempt_client_init(gt, &data.b))\n\t\tgoto err_client_a;\n\n\tfor_each_engine(data.engine, gt, id) {\n\t\tif (!intel_engine_has_preemption(data.engine))\n\t\t\tcontinue;\n\n\t\terr = __cancel_active0(&data);\n\t\tif (err)\n\t\t\tgoto err_wedged;\n\n\t\terr = __cancel_active1(&data);\n\t\tif (err)\n\t\t\tgoto err_wedged;\n\n\t\terr = __cancel_queued(&data);\n\t\tif (err)\n\t\t\tgoto err_wedged;\n\n\t\terr = __cancel_hostile(&data);\n\t\tif (err)\n\t\t\tgoto err_wedged;\n\n\t\terr = __cancel_fail(&data);\n\t\tif (err)\n\t\t\tgoto err_wedged;\n\t}\n\n\terr = 0;\nerr_client_b:\n\tpreempt_client_fini(&data.b);\nerr_client_a:\n\tpreempt_client_fini(&data.a);\n\treturn err;\n\nerr_wedged:\n\tGEM_TRACE_DUMP();\n\tigt_spinner_end(&data.b.spin);\n\tigt_spinner_end(&data.a.spin);\n\tintel_gt_set_wedged(gt);\n\tgoto err_client_b;\n}\n\nstatic int live_suppress_self_preempt(void *arg)\n{\n\tstruct i915_sched_attr attr = { .priority = I915_PRIORITY_MAX };\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct preempt_client a, b;\n\tenum intel_engine_id id;\n\tint err = -ENOMEM;\n\n\t \n\n\tif (intel_uc_uses_guc_submission(&gt->uc))\n\t\treturn 0;  \n\n\tif (intel_vgpu_active(gt->i915))\n\t\treturn 0;  \n\n\tif (preempt_client_init(gt, &a))\n\t\treturn -ENOMEM;\n\tif (preempt_client_init(gt, &b))\n\t\tgoto err_client_a;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_request *rq_a, *rq_b;\n\t\tint depth;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (igt_flush_test(gt->i915))\n\t\t\tgoto err_wedged;\n\n\t\tst_engine_heartbeat_disable(engine);\n\t\tengine->execlists.preempt_hang.count = 0;\n\n\t\trq_a = spinner_create_request(&a.spin,\n\t\t\t\t\t      a.ctx, engine,\n\t\t\t\t\t      MI_NOOP);\n\t\tif (IS_ERR(rq_a)) {\n\t\t\terr = PTR_ERR(rq_a);\n\t\t\tst_engine_heartbeat_enable(engine);\n\t\t\tgoto err_client_b;\n\t\t}\n\n\t\ti915_request_add(rq_a);\n\t\tif (!igt_wait_for_spinner(&a.spin, rq_a)) {\n\t\t\tpr_err(\"First client failed to start\\n\");\n\t\t\tst_engine_heartbeat_enable(engine);\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\t \n\t\tmod_timer(&engine->execlists.timer, jiffies + HZ);\n\t\tfor (depth = 0; depth < 8; depth++) {\n\t\t\trq_b = spinner_create_request(&b.spin,\n\t\t\t\t\t\t      b.ctx, engine,\n\t\t\t\t\t\t      MI_NOOP);\n\t\t\tif (IS_ERR(rq_b)) {\n\t\t\t\terr = PTR_ERR(rq_b);\n\t\t\t\tst_engine_heartbeat_enable(engine);\n\t\t\t\tgoto err_client_b;\n\t\t\t}\n\t\t\ti915_request_add(rq_b);\n\n\t\t\tGEM_BUG_ON(i915_request_completed(rq_a));\n\t\t\tengine->sched_engine->schedule(rq_a, &attr);\n\t\t\tigt_spinner_end(&a.spin);\n\n\t\t\tif (!igt_wait_for_spinner(&b.spin, rq_b)) {\n\t\t\t\tpr_err(\"Second client failed to start\\n\");\n\t\t\t\tst_engine_heartbeat_enable(engine);\n\t\t\t\tgoto err_wedged;\n\t\t\t}\n\n\t\t\tswap(a, b);\n\t\t\trq_a = rq_b;\n\t\t}\n\t\tigt_spinner_end(&a.spin);\n\n\t\tif (engine->execlists.preempt_hang.count) {\n\t\t\tpr_err(\"Preemption on %s recorded x%d, depth %d; should have been suppressed!\\n\",\n\t\t\t       engine->name,\n\t\t\t       engine->execlists.preempt_hang.count,\n\t\t\t       depth);\n\t\t\tst_engine_heartbeat_enable(engine);\n\t\t\terr = -EINVAL;\n\t\t\tgoto err_client_b;\n\t\t}\n\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (igt_flush_test(gt->i915))\n\t\t\tgoto err_wedged;\n\t}\n\n\terr = 0;\nerr_client_b:\n\tpreempt_client_fini(&b);\nerr_client_a:\n\tpreempt_client_fini(&a);\n\treturn err;\n\nerr_wedged:\n\tigt_spinner_end(&b.spin);\n\tigt_spinner_end(&a.spin);\n\tintel_gt_set_wedged(gt);\n\terr = -EIO;\n\tgoto err_client_b;\n}\n\nstatic int live_chain_preempt(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct preempt_client hi, lo;\n\tenum intel_engine_id id;\n\tint err = -ENOMEM;\n\n\t \n\n\tif (preempt_client_init(gt, &hi))\n\t\treturn -ENOMEM;\n\n\tif (preempt_client_init(gt, &lo))\n\t\tgoto err_client_hi;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_sched_attr attr = { .priority = I915_PRIORITY_MAX };\n\t\tstruct igt_live_test t;\n\t\tstruct i915_request *rq;\n\t\tint ring_size, count, i;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\trq = spinner_create_request(&lo.spin,\n\t\t\t\t\t    lo.ctx, engine,\n\t\t\t\t\t    MI_ARB_CHECK);\n\t\tif (IS_ERR(rq))\n\t\t\tgoto err_wedged;\n\n\t\ti915_request_get(rq);\n\t\ti915_request_add(rq);\n\n\t\tring_size = rq->wa_tail - rq->head;\n\t\tif (ring_size < 0)\n\t\t\tring_size += rq->ring->size;\n\t\tring_size = rq->ring->size / ring_size;\n\t\tpr_debug(\"%s(%s): Using maximum of %d requests\\n\",\n\t\t\t __func__, engine->name, ring_size);\n\n\t\tigt_spinner_end(&lo.spin);\n\t\tif (i915_request_wait(rq, 0, HZ / 2) < 0) {\n\t\t\tpr_err(\"Timed out waiting to flush %s\\n\", engine->name);\n\t\t\ti915_request_put(rq);\n\t\t\tgoto err_wedged;\n\t\t}\n\t\ti915_request_put(rq);\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_wedged;\n\t\t}\n\n\t\tfor_each_prime_number_from(count, 1, ring_size) {\n\t\t\trq = spinner_create_request(&hi.spin,\n\t\t\t\t\t\t    hi.ctx, engine,\n\t\t\t\t\t\t    MI_ARB_CHECK);\n\t\t\tif (IS_ERR(rq))\n\t\t\t\tgoto err_wedged;\n\t\t\ti915_request_add(rq);\n\t\t\tif (!igt_wait_for_spinner(&hi.spin, rq))\n\t\t\t\tgoto err_wedged;\n\n\t\t\trq = spinner_create_request(&lo.spin,\n\t\t\t\t\t\t    lo.ctx, engine,\n\t\t\t\t\t\t    MI_ARB_CHECK);\n\t\t\tif (IS_ERR(rq))\n\t\t\t\tgoto err_wedged;\n\t\t\ti915_request_add(rq);\n\n\t\t\tfor (i = 0; i < count; i++) {\n\t\t\t\trq = igt_request_alloc(lo.ctx, engine);\n\t\t\t\tif (IS_ERR(rq))\n\t\t\t\t\tgoto err_wedged;\n\t\t\t\ti915_request_add(rq);\n\t\t\t}\n\n\t\t\trq = igt_request_alloc(hi.ctx, engine);\n\t\t\tif (IS_ERR(rq))\n\t\t\t\tgoto err_wedged;\n\n\t\t\ti915_request_get(rq);\n\t\t\ti915_request_add(rq);\n\t\t\tengine->sched_engine->schedule(rq, &attr);\n\n\t\t\tigt_spinner_end(&hi.spin);\n\t\t\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\t\t\tstruct drm_printer p =\n\t\t\t\t\tdrm_info_printer(gt->i915->drm.dev);\n\n\t\t\t\tpr_err(\"Failed to preempt over chain of %d\\n\",\n\t\t\t\t       count);\n\t\t\t\tintel_engine_dump(engine, &p,\n\t\t\t\t\t\t  \"%s\\n\", engine->name);\n\t\t\t\ti915_request_put(rq);\n\t\t\t\tgoto err_wedged;\n\t\t\t}\n\t\t\tigt_spinner_end(&lo.spin);\n\t\t\ti915_request_put(rq);\n\n\t\t\trq = igt_request_alloc(lo.ctx, engine);\n\t\t\tif (IS_ERR(rq))\n\t\t\t\tgoto err_wedged;\n\n\t\t\ti915_request_get(rq);\n\t\t\ti915_request_add(rq);\n\n\t\t\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\t\t\tstruct drm_printer p =\n\t\t\t\t\tdrm_info_printer(gt->i915->drm.dev);\n\n\t\t\t\tpr_err(\"Failed to flush low priority chain of %d requests\\n\",\n\t\t\t\t       count);\n\t\t\t\tintel_engine_dump(engine, &p,\n\t\t\t\t\t\t  \"%s\\n\", engine->name);\n\n\t\t\t\ti915_request_put(rq);\n\t\t\t\tgoto err_wedged;\n\t\t\t}\n\t\t\ti915_request_put(rq);\n\t\t}\n\n\t\tif (igt_live_test_end(&t)) {\n\t\t\terr = -EIO;\n\t\t\tgoto err_wedged;\n\t\t}\n\t}\n\n\terr = 0;\nerr_client_lo:\n\tpreempt_client_fini(&lo);\nerr_client_hi:\n\tpreempt_client_fini(&hi);\n\treturn err;\n\nerr_wedged:\n\tigt_spinner_end(&hi.spin);\n\tigt_spinner_end(&lo.spin);\n\tintel_gt_set_wedged(gt);\n\terr = -EIO;\n\tgoto err_client_lo;\n}\n\nstatic int create_gang(struct intel_engine_cs *engine,\n\t\t       struct i915_request **prev)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tstruct i915_vma *vma;\n\tu32 *cs;\n\tint err;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\tobj = i915_gem_object_create_internal(engine->i915, 4096);\n\tif (IS_ERR(obj)) {\n\t\terr = PTR_ERR(obj);\n\t\tgoto err_ce;\n\t}\n\n\tvma = i915_vma_instance(obj, ce->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto err_obj;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\tif (err)\n\t\tgoto err_obj;\n\n\tcs = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WC);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_obj;\n\t}\n\n\t \n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_ENABLE;\n\n\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\tMI_SEMAPHORE_POLL |\n\t\tMI_SEMAPHORE_SAD_EQ_SDD;\n\t*cs++ = 0;\n\t*cs++ = lower_32_bits(i915_vma_offset(vma));\n\t*cs++ = upper_32_bits(i915_vma_offset(vma));\n\n\tif (*prev) {\n\t\tu64 offset = i915_vma_offset((*prev)->batch);\n\n\t\t \n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4;\n\t\t*cs++ = lower_32_bits(offset);\n\t\t*cs++ = upper_32_bits(offset);\n\t\t*cs++ = 0;\n\t}\n\n\t*cs++ = MI_BATCH_BUFFER_END;\n\ti915_gem_object_flush_map(obj);\n\ti915_gem_object_unpin_map(obj);\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_obj;\n\t}\n\n\trq->batch = i915_vma_get(vma);\n\ti915_request_get(rq);\n\n\terr = igt_vma_move_to_active_unlocked(vma, rq, 0);\n\tif (!err)\n\t\terr = rq->engine->emit_bb_start(rq,\n\t\t\t\t\t\ti915_vma_offset(vma),\n\t\t\t\t\t\tPAGE_SIZE, 0);\n\ti915_request_add(rq);\n\tif (err)\n\t\tgoto err_rq;\n\n\ti915_gem_object_put(obj);\n\tintel_context_put(ce);\n\n\trq->mock.link.next = &(*prev)->mock.link;\n\t*prev = rq;\n\treturn 0;\n\nerr_rq:\n\ti915_vma_put(rq->batch);\n\ti915_request_put(rq);\nerr_obj:\n\ti915_gem_object_put(obj);\nerr_ce:\n\tintel_context_put(ce);\n\treturn err;\n}\n\nstatic int __live_preempt_ring(struct intel_engine_cs *engine,\n\t\t\t       struct igt_spinner *spin,\n\t\t\t       int queue_sz, int ring_sz)\n{\n\tstruct intel_context *ce[2] = {};\n\tstruct i915_request *rq;\n\tstruct igt_live_test t;\n\tint err = 0;\n\tint n;\n\n\tif (igt_live_test_begin(&t, engine->i915, __func__, engine->name))\n\t\treturn -EIO;\n\n\tfor (n = 0; n < ARRAY_SIZE(ce); n++) {\n\t\tstruct intel_context *tmp;\n\n\t\ttmp = intel_context_create(engine);\n\t\tif (IS_ERR(tmp)) {\n\t\t\terr = PTR_ERR(tmp);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\ttmp->ring_size = ring_sz;\n\n\t\terr = intel_context_pin(tmp);\n\t\tif (err) {\n\t\t\tintel_context_put(tmp);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\tmemset32(tmp->ring->vaddr,\n\t\t\t 0xdeadbeef,  \n\t\t\t tmp->ring->vma->size / sizeof(u32));\n\n\t\tce[n] = tmp;\n\t}\n\n\trq = igt_spinner_create_request(spin, ce[0], MI_ARB_CHECK);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_ce;\n\t}\n\n\ti915_request_get(rq);\n\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\n\ti915_request_add(rq);\n\n\tif (!igt_wait_for_spinner(spin, rq)) {\n\t\tintel_gt_set_wedged(engine->gt);\n\t\ti915_request_put(rq);\n\t\terr = -ETIME;\n\t\tgoto err_ce;\n\t}\n\n\t \n\tn = 0;\n\twhile (ce[0]->ring->tail - rq->wa_tail <= queue_sz) {\n\t\tstruct i915_request *tmp;\n\n\t\ttmp = intel_context_create_request(ce[0]);\n\t\tif (IS_ERR(tmp)) {\n\t\t\terr = PTR_ERR(tmp);\n\t\t\ti915_request_put(rq);\n\t\t\tgoto err_ce;\n\t\t}\n\n\t\ti915_request_add(tmp);\n\t\tintel_engine_flush_submission(engine);\n\t\tn++;\n\t}\n\tintel_engine_flush_submission(engine);\n\tpr_debug(\"%s: Filled %d with %d nop tails {size:%x, tail:%x, emit:%x, rq.tail:%x}\\n\",\n\t\t engine->name, queue_sz, n,\n\t\t ce[0]->ring->size,\n\t\t ce[0]->ring->tail,\n\t\t ce[0]->ring->emit,\n\t\t rq->tail);\n\ti915_request_put(rq);\n\n\t \n\trq = intel_context_create_request(ce[1]);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_ce;\n\t}\n\n\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\terr = wait_for_submit(engine, rq, HZ / 2);\n\ti915_request_put(rq);\n\tif (err) {\n\t\tpr_err(\"%s: preemption request was not submitted\\n\",\n\t\t       engine->name);\n\t\terr = -ETIME;\n\t}\n\n\tpr_debug(\"%s: ring[0]:{ tail:%x, emit:%x }, ring[1]:{ tail:%x, emit:%x }\\n\",\n\t\t engine->name,\n\t\t ce[0]->ring->tail, ce[0]->ring->emit,\n\t\t ce[1]->ring->tail, ce[1]->ring->emit);\n\nerr_ce:\n\tintel_engine_flush_submission(engine);\n\tigt_spinner_end(spin);\n\tfor (n = 0; n < ARRAY_SIZE(ce); n++) {\n\t\tif (IS_ERR_OR_NULL(ce[n]))\n\t\t\tbreak;\n\n\t\tintel_context_unpin(ce[n]);\n\t\tintel_context_put(ce[n]);\n\t}\n\tif (igt_live_test_end(&t))\n\t\terr = -EIO;\n\treturn err;\n}\n\nstatic int live_preempt_ring(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct igt_spinner spin;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tint n;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\tst_engine_heartbeat_disable(engine);\n\n\t\tfor (n = 0; n <= 3; n++) {\n\t\t\terr = __live_preempt_ring(engine, &spin,\n\t\t\t\t\t\t  n * SZ_4K / 4, SZ_4K);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int live_preempt_gang(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_request *rq = NULL;\n\t\tstruct igt_live_test t;\n\t\tIGT_TIMEOUT(end_time);\n\t\tint prio = 0;\n\t\tint err = 0;\n\t\tu32 *cs;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name))\n\t\t\treturn -EIO;\n\n\t\tdo {\n\t\t\tstruct i915_sched_attr attr = { .priority = prio++ };\n\n\t\t\terr = create_gang(engine, &rq);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tengine->sched_engine->schedule(rq, &attr);\n\t\t} while (prio <= I915_PRIORITY_MAX &&\n\t\t\t !__igt_timeout(end_time, NULL));\n\t\tpr_debug(\"%s: Preempt chain of %d requests\\n\",\n\t\t\t engine->name, prio);\n\n\t\t \n\t\tcs = i915_gem_object_pin_map_unlocked(rq->batch->obj, I915_MAP_WC);\n\t\tif (!IS_ERR(cs)) {\n\t\t\t*cs = 0;\n\t\t\ti915_gem_object_unpin_map(rq->batch->obj);\n\t\t} else {\n\t\t\terr = PTR_ERR(cs);\n\t\t\tintel_gt_set_wedged(gt);\n\t\t}\n\n\t\twhile (rq) {  \n\t\t\tstruct i915_request *n = list_next_entry(rq, mock.link);\n\n\t\t\tif (err == 0 && i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\t\t\tstruct drm_printer p =\n\t\t\t\t\tdrm_info_printer(engine->i915->drm.dev);\n\n\t\t\t\tpr_err(\"Failed to flush chain of %d requests, at %d\\n\",\n\t\t\t\t       prio, rq_prio(rq));\n\t\t\t\tintel_engine_dump(engine, &p,\n\t\t\t\t\t\t  \"%s\\n\", engine->name);\n\n\t\t\t\terr = -ETIME;\n\t\t\t}\n\n\t\t\ti915_vma_put(rq->batch);\n\t\t\ti915_request_put(rq);\n\t\t\trq = n;\n\t\t}\n\n\t\tif (igt_live_test_end(&t))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic struct i915_vma *\ncreate_gpr_user(struct intel_engine_cs *engine,\n\t\tstruct i915_vma *result,\n\t\tunsigned int offset)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\tu32 *cs;\n\tint err;\n\tint i;\n\n\tobj = i915_gem_object_create_internal(engine->i915, 4096);\n\tif (IS_ERR(obj))\n\t\treturn ERR_CAST(obj);\n\n\tvma = i915_vma_instance(obj, result->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn vma;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\tif (err) {\n\t\ti915_vma_put(vma);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tcs = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WC);\n\tif (IS_ERR(cs)) {\n\t\ti915_vma_put(vma);\n\t\treturn ERR_CAST(cs);\n\t}\n\n\t \n\t*cs++ = MI_LOAD_REGISTER_IMM(1);\n\t*cs++ = CS_GPR(engine, 0);\n\t*cs++ = 1;\n\n\tfor (i = 1; i < NUM_GPR; i++) {\n\t\tu64 addr;\n\n\t\t \n\t\t*cs++ = MI_MATH(4);\n\t\t*cs++ = MI_MATH_LOAD(MI_MATH_REG_SRCA, MI_MATH_REG(i));\n\t\t*cs++ = MI_MATH_LOAD(MI_MATH_REG_SRCB, MI_MATH_REG(0));\n\t\t*cs++ = MI_MATH_ADD;\n\t\t*cs++ = MI_MATH_STORE(MI_MATH_REG(i), MI_MATH_REG_ACCU);\n\n\t\taddr = i915_vma_offset(result) + offset + i * sizeof(*cs);\n\t\t*cs++ = MI_STORE_REGISTER_MEM_GEN8;\n\t\t*cs++ = CS_GPR(engine, 2 * i);\n\t\t*cs++ = lower_32_bits(addr);\n\t\t*cs++ = upper_32_bits(addr);\n\n\t\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\t\tMI_SEMAPHORE_POLL |\n\t\t\tMI_SEMAPHORE_SAD_GTE_SDD;\n\t\t*cs++ = i;\n\t\t*cs++ = lower_32_bits(i915_vma_offset(result));\n\t\t*cs++ = upper_32_bits(i915_vma_offset(result));\n\t}\n\n\t*cs++ = MI_BATCH_BUFFER_END;\n\ti915_gem_object_flush_map(obj);\n\ti915_gem_object_unpin_map(obj);\n\n\treturn vma;\n}\n\nstatic struct i915_vma *create_global(struct intel_gt *gt, size_t sz)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\tint err;\n\n\tobj = i915_gem_object_create_internal(gt->i915, sz);\n\tif (IS_ERR(obj))\n\t\treturn ERR_CAST(obj);\n\n\tvma = i915_vma_instance(obj, &gt->ggtt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn vma;\n\t}\n\n\terr = i915_ggtt_pin(vma, NULL, 0, 0);\n\tif (err) {\n\t\ti915_vma_put(vma);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn vma;\n}\n\nstatic struct i915_request *\ncreate_gpr_client(struct intel_engine_cs *engine,\n\t\t  struct i915_vma *global,\n\t\t  unsigned int offset)\n{\n\tstruct i915_vma *batch, *vma;\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tint err;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn ERR_CAST(ce);\n\n\tvma = i915_vma_instance(global->obj, ce->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto out_ce;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\tif (err)\n\t\tgoto out_ce;\n\n\tbatch = create_gpr_user(engine, vma, offset);\n\tif (IS_ERR(batch)) {\n\t\terr = PTR_ERR(batch);\n\t\tgoto out_vma;\n\t}\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto out_batch;\n\t}\n\n\terr = igt_vma_move_to_active_unlocked(vma, rq, 0);\n\n\ti915_vma_lock(batch);\n\tif (!err)\n\t\terr = i915_vma_move_to_active(batch, rq, 0);\n\tif (!err)\n\t\terr = rq->engine->emit_bb_start(rq,\n\t\t\t\t\t\ti915_vma_offset(batch),\n\t\t\t\t\t\tPAGE_SIZE, 0);\n\ti915_vma_unlock(batch);\n\ti915_vma_unpin(batch);\n\n\tif (!err)\n\t\ti915_request_get(rq);\n\ti915_request_add(rq);\n\nout_batch:\n\ti915_vma_put(batch);\nout_vma:\n\ti915_vma_unpin(vma);\nout_ce:\n\tintel_context_put(ce);\n\treturn err ? ERR_PTR(err) : rq;\n}\n\nstatic int preempt_user(struct intel_engine_cs *engine,\n\t\t\tstruct i915_vma *global,\n\t\t\tint id)\n{\n\tstruct i915_sched_attr attr = {\n\t\t.priority = I915_PRIORITY_MAX\n\t};\n\tstruct i915_request *rq;\n\tint err = 0;\n\tu32 *cs;\n\n\trq = intel_engine_create_kernel_request(engine);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs)) {\n\t\ti915_request_add(rq);\n\t\treturn PTR_ERR(cs);\n\t}\n\n\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t*cs++ = i915_ggtt_offset(global);\n\t*cs++ = 0;\n\t*cs++ = id;\n\n\tintel_ring_advance(rq, cs);\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\tengine->sched_engine->schedule(rq, &attr);\n\n\tif (i915_request_wait(rq, 0, HZ / 2) < 0)\n\t\terr = -ETIME;\n\ti915_request_put(rq);\n\n\treturn err;\n}\n\nstatic int live_preempt_user(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct i915_vma *global;\n\tenum intel_engine_id id;\n\tu32 *result;\n\tint err = 0;\n\n\t \n\n\tglobal = create_global(gt, 4096);\n\tif (IS_ERR(global))\n\t\treturn PTR_ERR(global);\n\n\tresult = i915_gem_object_pin_map_unlocked(global->obj, I915_MAP_WC);\n\tif (IS_ERR(result)) {\n\t\ti915_vma_unpin_and_release(&global, 0);\n\t\treturn PTR_ERR(result);\n\t}\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_request *client[3] = {};\n\t\tstruct igt_live_test t;\n\t\tint i;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\tif (GRAPHICS_VER(gt->i915) == 8 && engine->class != RENDER_CLASS)\n\t\t\tcontinue;  \n\n\t\tif (igt_live_test_begin(&t, gt->i915, __func__, engine->name)) {\n\t\t\terr = -EIO;\n\t\t\tbreak;\n\t\t}\n\n\t\tmemset(result, 0, 4096);\n\n\t\tfor (i = 0; i < ARRAY_SIZE(client); i++) {\n\t\t\tstruct i915_request *rq;\n\n\t\t\trq = create_gpr_client(engine, global,\n\t\t\t\t\t       NUM_GPR * i * sizeof(u32));\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tgoto end_test;\n\t\t\t}\n\n\t\t\tclient[i] = rq;\n\t\t}\n\n\t\t \n\t\tfor (i = 1; i <= NUM_GPR; i++) {\n\t\t\terr = preempt_user(engine, global, i);\n\t\t\tif (err)\n\t\t\t\tgoto end_test;\n\t\t}\n\n\t\tif (READ_ONCE(result[0]) != NUM_GPR) {\n\t\t\tpr_err(\"%s: Failed to release semaphore\\n\",\n\t\t\t       engine->name);\n\t\t\terr = -EIO;\n\t\t\tgoto end_test;\n\t\t}\n\n\t\tfor (i = 0; i < ARRAY_SIZE(client); i++) {\n\t\t\tint gpr;\n\n\t\t\tif (i915_request_wait(client[i], 0, HZ / 2) < 0) {\n\t\t\t\terr = -ETIME;\n\t\t\t\tgoto end_test;\n\t\t\t}\n\n\t\t\tfor (gpr = 1; gpr < NUM_GPR; gpr++) {\n\t\t\t\tif (result[NUM_GPR * i + gpr] != 1) {\n\t\t\t\t\tpr_err(\"%s: Invalid result, client %d, gpr %d, result: %d\\n\",\n\t\t\t\t\t       engine->name,\n\t\t\t\t\t       i, gpr, result[NUM_GPR * i + gpr]);\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tgoto end_test;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\nend_test:\n\t\tfor (i = 0; i < ARRAY_SIZE(client); i++) {\n\t\t\tif (!client[i])\n\t\t\t\tbreak;\n\n\t\t\ti915_request_put(client[i]);\n\t\t}\n\n\t\t \n\t\tsmp_store_mb(result[0], -1);\n\t\tif (igt_live_test_end(&t))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\ti915_vma_unpin_and_release(&global, I915_VMA_RELEASE_MAP);\n\treturn err;\n}\n\nstatic int live_preempt_timeout(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct i915_gem_context *ctx_hi, *ctx_lo;\n\tstruct igt_spinner spin_lo;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = -ENOMEM;\n\n\t \n\tif (!CONFIG_DRM_I915_PREEMPT_TIMEOUT)\n\t\treturn 0;\n\n\tif (!intel_has_reset_engine(gt))\n\t\treturn 0;\n\n\tctx_hi = kernel_context(gt->i915, NULL);\n\tif (!ctx_hi)\n\t\treturn -ENOMEM;\n\tctx_hi->sched.priority = I915_CONTEXT_MAX_USER_PRIORITY;\n\n\tctx_lo = kernel_context(gt->i915, NULL);\n\tif (!ctx_lo)\n\t\tgoto err_ctx_hi;\n\tctx_lo->sched.priority = I915_CONTEXT_MIN_USER_PRIORITY;\n\n\tif (igt_spinner_init(&spin_lo, gt))\n\t\tgoto err_ctx_lo;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tunsigned long saved_timeout;\n\t\tstruct i915_request *rq;\n\n\t\tif (!intel_engine_has_preemption(engine))\n\t\t\tcontinue;\n\n\t\trq = spinner_create_request(&spin_lo, ctx_lo, engine,\n\t\t\t\t\t    MI_NOOP);  \n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t\tif (!igt_wait_for_spinner(&spin_lo, rq)) {\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -EIO;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\trq = igt_request_alloc(ctx_hi, engine);\n\t\tif (IS_ERR(rq)) {\n\t\t\tigt_spinner_end(&spin_lo);\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\t \n\t\twhile (READ_ONCE(engine->execlists.pending[0]))\n\t\t\tcpu_relax();\n\n\t\tsaved_timeout = engine->props.preempt_timeout_ms;\n\t\tengine->props.preempt_timeout_ms = 1;  \n\n\t\ti915_request_get(rq);\n\t\ti915_request_add(rq);\n\n\t\tintel_engine_flush_submission(engine);\n\t\tengine->props.preempt_timeout_ms = saved_timeout;\n\n\t\tif (i915_request_wait(rq, 0, HZ / 10) < 0) {\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\ti915_request_put(rq);\n\t\t\terr = -ETIME;\n\t\t\tgoto err_spin_lo;\n\t\t}\n\n\t\tigt_spinner_end(&spin_lo);\n\t\ti915_request_put(rq);\n\t}\n\n\terr = 0;\nerr_spin_lo:\n\tigt_spinner_fini(&spin_lo);\nerr_ctx_lo:\n\tkernel_context_close(ctx_lo);\nerr_ctx_hi:\n\tkernel_context_close(ctx_hi);\n\treturn err;\n}\n\nstatic int random_range(struct rnd_state *rnd, int min, int max)\n{\n\treturn i915_prandom_u32_max_state(max - min, rnd) + min;\n}\n\nstatic int random_priority(struct rnd_state *rnd)\n{\n\treturn random_range(rnd, I915_PRIORITY_MIN, I915_PRIORITY_MAX);\n}\n\nstruct preempt_smoke {\n\tstruct intel_gt *gt;\n\tstruct kthread_work work;\n\tstruct i915_gem_context **contexts;\n\tstruct intel_engine_cs *engine;\n\tstruct drm_i915_gem_object *batch;\n\tunsigned int ncontext;\n\tstruct rnd_state prng;\n\tunsigned long count;\n\tint result;\n};\n\nstatic struct i915_gem_context *smoke_context(struct preempt_smoke *smoke)\n{\n\treturn smoke->contexts[i915_prandom_u32_max_state(smoke->ncontext,\n\t\t\t\t\t\t\t  &smoke->prng)];\n}\n\nstatic int smoke_submit(struct preempt_smoke *smoke,\n\t\t\tstruct i915_gem_context *ctx, int prio,\n\t\t\tstruct drm_i915_gem_object *batch)\n{\n\tstruct i915_request *rq;\n\tstruct i915_vma *vma = NULL;\n\tint err = 0;\n\n\tif (batch) {\n\t\tstruct i915_address_space *vm;\n\n\t\tvm = i915_gem_context_get_eb_vm(ctx);\n\t\tvma = i915_vma_instance(batch, vm, NULL);\n\t\ti915_vm_put(vm);\n\t\tif (IS_ERR(vma))\n\t\t\treturn PTR_ERR(vma);\n\n\t\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tctx->sched.priority = prio;\n\n\trq = igt_request_alloc(ctx, smoke->engine);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto unpin;\n\t}\n\n\tif (vma) {\n\t\terr = igt_vma_move_to_active_unlocked(vma, rq, 0);\n\t\tif (!err)\n\t\t\terr = rq->engine->emit_bb_start(rq,\n\t\t\t\t\t\t\ti915_vma_offset(vma),\n\t\t\t\t\t\t\tPAGE_SIZE, 0);\n\t}\n\n\ti915_request_add(rq);\n\nunpin:\n\tif (vma)\n\t\ti915_vma_unpin(vma);\n\n\treturn err;\n}\n\nstatic void smoke_crescendo_work(struct kthread_work *work)\n{\n\tstruct preempt_smoke *smoke = container_of(work, typeof(*smoke), work);\n\tIGT_TIMEOUT(end_time);\n\tunsigned long count;\n\n\tcount = 0;\n\tdo {\n\t\tstruct i915_gem_context *ctx = smoke_context(smoke);\n\n\t\tsmoke->result = smoke_submit(smoke, ctx,\n\t\t\t\t\t     count % I915_PRIORITY_MAX,\n\t\t\t\t\t     smoke->batch);\n\n\t\tcount++;\n\t} while (!smoke->result && count < smoke->ncontext &&\n\t\t !__igt_timeout(end_time, NULL));\n\n\tsmoke->count = count;\n}\n\nstatic int smoke_crescendo(struct preempt_smoke *smoke, unsigned int flags)\n#define BATCH BIT(0)\n{\n\tstruct kthread_worker *worker[I915_NUM_ENGINES] = {};\n\tstruct preempt_smoke *arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tunsigned long count;\n\tint err = 0;\n\n\targ = kmalloc_array(I915_NUM_ENGINES, sizeof(*arg), GFP_KERNEL);\n\tif (!arg)\n\t\treturn -ENOMEM;\n\n\tmemset(arg, 0, I915_NUM_ENGINES * sizeof(*arg));\n\n\tfor_each_engine(engine, smoke->gt, id) {\n\t\targ[id] = *smoke;\n\t\targ[id].engine = engine;\n\t\tif (!(flags & BATCH))\n\t\t\targ[id].batch = NULL;\n\t\targ[id].count = 0;\n\n\t\tworker[id] = kthread_create_worker(0, \"igt/smoke:%d\", id);\n\t\tif (IS_ERR(worker[id])) {\n\t\t\terr = PTR_ERR(worker[id]);\n\t\t\tbreak;\n\t\t}\n\n\t\tkthread_init_work(&arg[id].work, smoke_crescendo_work);\n\t\tkthread_queue_work(worker[id], &arg[id].work);\n\t}\n\n\tcount = 0;\n\tfor_each_engine(engine, smoke->gt, id) {\n\t\tif (IS_ERR_OR_NULL(worker[id]))\n\t\t\tcontinue;\n\n\t\tkthread_flush_work(&arg[id].work);\n\t\tif (arg[id].result && !err)\n\t\t\terr = arg[id].result;\n\n\t\tcount += arg[id].count;\n\n\t\tkthread_destroy_worker(worker[id]);\n\t}\n\n\tpr_info(\"Submitted %lu crescendo:%x requests across %d engines and %d contexts\\n\",\n\t\tcount, flags, smoke->gt->info.num_engines, smoke->ncontext);\n\n\tkfree(arg);\n\treturn 0;\n}\n\nstatic int smoke_random(struct preempt_smoke *smoke, unsigned int flags)\n{\n\tenum intel_engine_id id;\n\tIGT_TIMEOUT(end_time);\n\tunsigned long count;\n\n\tcount = 0;\n\tdo {\n\t\tfor_each_engine(smoke->engine, smoke->gt, id) {\n\t\t\tstruct i915_gem_context *ctx = smoke_context(smoke);\n\t\t\tint err;\n\n\t\t\terr = smoke_submit(smoke,\n\t\t\t\t\t   ctx, random_priority(&smoke->prng),\n\t\t\t\t\t   flags & BATCH ? smoke->batch : NULL);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\n\t\t\tcount++;\n\t\t}\n\t} while (count < smoke->ncontext && !__igt_timeout(end_time, NULL));\n\n\tpr_info(\"Submitted %lu random:%x requests across %d engines and %d contexts\\n\",\n\t\tcount, flags, smoke->gt->info.num_engines, smoke->ncontext);\n\treturn 0;\n}\n\nstatic int live_preempt_smoke(void *arg)\n{\n\tstruct preempt_smoke smoke = {\n\t\t.gt = arg,\n\t\t.prng = I915_RND_STATE_INITIALIZER(i915_selftest.random_seed),\n\t\t.ncontext = 256,\n\t};\n\tconst unsigned int phase[] = { 0, BATCH };\n\tstruct igt_live_test t;\n\tint err = -ENOMEM;\n\tu32 *cs;\n\tint n;\n\n\tsmoke.contexts = kmalloc_array(smoke.ncontext,\n\t\t\t\t       sizeof(*smoke.contexts),\n\t\t\t\t       GFP_KERNEL);\n\tif (!smoke.contexts)\n\t\treturn -ENOMEM;\n\n\tsmoke.batch =\n\t\ti915_gem_object_create_internal(smoke.gt->i915, PAGE_SIZE);\n\tif (IS_ERR(smoke.batch)) {\n\t\terr = PTR_ERR(smoke.batch);\n\t\tgoto err_free;\n\t}\n\n\tcs = i915_gem_object_pin_map_unlocked(smoke.batch, I915_MAP_WB);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_batch;\n\t}\n\tfor (n = 0; n < PAGE_SIZE / sizeof(*cs) - 1; n++)\n\t\tcs[n] = MI_ARB_CHECK;\n\tcs[n] = MI_BATCH_BUFFER_END;\n\ti915_gem_object_flush_map(smoke.batch);\n\ti915_gem_object_unpin_map(smoke.batch);\n\n\tif (igt_live_test_begin(&t, smoke.gt->i915, __func__, \"all\")) {\n\t\terr = -EIO;\n\t\tgoto err_batch;\n\t}\n\n\tfor (n = 0; n < smoke.ncontext; n++) {\n\t\tsmoke.contexts[n] = kernel_context(smoke.gt->i915, NULL);\n\t\tif (!smoke.contexts[n])\n\t\t\tgoto err_ctx;\n\t}\n\n\tfor (n = 0; n < ARRAY_SIZE(phase); n++) {\n\t\terr = smoke_crescendo(&smoke, phase[n]);\n\t\tif (err)\n\t\t\tgoto err_ctx;\n\n\t\terr = smoke_random(&smoke, phase[n]);\n\t\tif (err)\n\t\t\tgoto err_ctx;\n\t}\n\nerr_ctx:\n\tif (igt_live_test_end(&t))\n\t\terr = -EIO;\n\n\tfor (n = 0; n < smoke.ncontext; n++) {\n\t\tif (!smoke.contexts[n])\n\t\t\tbreak;\n\t\tkernel_context_close(smoke.contexts[n]);\n\t}\n\nerr_batch:\n\ti915_gem_object_put(smoke.batch);\nerr_free:\n\tkfree(smoke.contexts);\n\n\treturn err;\n}\n\nstatic int nop_virtual_engine(struct intel_gt *gt,\n\t\t\t      struct intel_engine_cs **siblings,\n\t\t\t      unsigned int nsibling,\n\t\t\t      unsigned int nctx,\n\t\t\t      unsigned int flags)\n#define CHAIN BIT(0)\n{\n\tIGT_TIMEOUT(end_time);\n\tstruct i915_request *request[16] = {};\n\tstruct intel_context *ve[16];\n\tunsigned long n, prime, nc;\n\tstruct igt_live_test t;\n\tktime_t times[2] = {};\n\tint err;\n\n\tGEM_BUG_ON(!nctx || nctx > ARRAY_SIZE(ve));\n\n\tfor (n = 0; n < nctx; n++) {\n\t\tve[n] = intel_engine_create_virtual(siblings, nsibling, 0);\n\t\tif (IS_ERR(ve[n])) {\n\t\t\terr = PTR_ERR(ve[n]);\n\t\t\tnctx = n;\n\t\t\tgoto out;\n\t\t}\n\n\t\terr = intel_context_pin(ve[n]);\n\t\tif (err) {\n\t\t\tintel_context_put(ve[n]);\n\t\t\tnctx = n;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\terr = igt_live_test_begin(&t, gt->i915, __func__, ve[0]->engine->name);\n\tif (err)\n\t\tgoto out;\n\n\tfor_each_prime_number_from(prime, 1, 8192) {\n\t\ttimes[1] = ktime_get_raw();\n\n\t\tif (flags & CHAIN) {\n\t\t\tfor (nc = 0; nc < nctx; nc++) {\n\t\t\t\tfor (n = 0; n < prime; n++) {\n\t\t\t\t\tstruct i915_request *rq;\n\n\t\t\t\t\trq = i915_request_create(ve[nc]);\n\t\t\t\t\tif (IS_ERR(rq)) {\n\t\t\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\t\t\tgoto out;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (request[nc])\n\t\t\t\t\t\ti915_request_put(request[nc]);\n\t\t\t\t\trequest[nc] = i915_request_get(rq);\n\t\t\t\t\ti915_request_add(rq);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tfor (n = 0; n < prime; n++) {\n\t\t\t\tfor (nc = 0; nc < nctx; nc++) {\n\t\t\t\t\tstruct i915_request *rq;\n\n\t\t\t\t\trq = i915_request_create(ve[nc]);\n\t\t\t\t\tif (IS_ERR(rq)) {\n\t\t\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\t\t\tgoto out;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (request[nc])\n\t\t\t\t\t\ti915_request_put(request[nc]);\n\t\t\t\t\trequest[nc] = i915_request_get(rq);\n\t\t\t\t\ti915_request_add(rq);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (nc = 0; nc < nctx; nc++) {\n\t\t\tif (i915_request_wait(request[nc], 0, HZ / 10) < 0) {\n\t\t\t\tpr_err(\"%s(%s): wait for %llx:%lld timed out\\n\",\n\t\t\t\t       __func__, ve[0]->engine->name,\n\t\t\t\t       request[nc]->fence.context,\n\t\t\t\t       request[nc]->fence.seqno);\n\n\t\t\t\tGEM_TRACE(\"%s(%s) failed at request %llx:%lld\\n\",\n\t\t\t\t\t  __func__, ve[0]->engine->name,\n\t\t\t\t\t  request[nc]->fence.context,\n\t\t\t\t\t  request[nc]->fence.seqno);\n\t\t\t\tGEM_TRACE_DUMP();\n\t\t\t\tintel_gt_set_wedged(gt);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\ttimes[1] = ktime_sub(ktime_get_raw(), times[1]);\n\t\tif (prime == 1)\n\t\t\ttimes[0] = times[1];\n\n\t\tfor (nc = 0; nc < nctx; nc++) {\n\t\t\ti915_request_put(request[nc]);\n\t\t\trequest[nc] = NULL;\n\t\t}\n\n\t\tif (__igt_timeout(end_time, NULL))\n\t\t\tbreak;\n\t}\n\n\terr = igt_live_test_end(&t);\n\tif (err)\n\t\tgoto out;\n\n\tpr_info(\"Requestx%d latencies on %s: 1 = %lluns, %lu = %lluns\\n\",\n\t\tnctx, ve[0]->engine->name, ktime_to_ns(times[0]),\n\t\tprime, div64_u64(ktime_to_ns(times[1]), prime));\n\nout:\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\tfor (nc = 0; nc < nctx; nc++) {\n\t\ti915_request_put(request[nc]);\n\t\tintel_context_unpin(ve[nc]);\n\t\tintel_context_put(ve[nc]);\n\t}\n\treturn err;\n}\n\nstatic unsigned int\n__select_siblings(struct intel_gt *gt,\n\t\t  unsigned int class,\n\t\t  struct intel_engine_cs **siblings,\n\t\t  bool (*filter)(const struct intel_engine_cs *))\n{\n\tunsigned int n = 0;\n\tunsigned int inst;\n\n\tfor (inst = 0; inst <= MAX_ENGINE_INSTANCE; inst++) {\n\t\tif (!gt->engine_class[class][inst])\n\t\t\tcontinue;\n\n\t\tif (filter && !filter(gt->engine_class[class][inst]))\n\t\t\tcontinue;\n\n\t\tsiblings[n++] = gt->engine_class[class][inst];\n\t}\n\n\treturn n;\n}\n\nstatic unsigned int\nselect_siblings(struct intel_gt *gt,\n\t\tunsigned int class,\n\t\tstruct intel_engine_cs **siblings)\n{\n\treturn __select_siblings(gt, class, siblings, NULL);\n}\n\nstatic int live_virtual_engine(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *siblings[MAX_ENGINE_INSTANCE + 1];\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tunsigned int class;\n\tint err;\n\n\tif (intel_uc_uses_guc_submission(&gt->uc))\n\t\treturn 0;\n\n\tfor_each_engine(engine, gt, id) {\n\t\terr = nop_virtual_engine(gt, &engine, 1, 1, 0);\n\t\tif (err) {\n\t\t\tpr_err(\"Failed to wrap engine %s: err=%d\\n\",\n\t\t\t       engine->name, err);\n\t\t\treturn err;\n\t\t}\n\t}\n\n\tfor (class = 0; class <= MAX_ENGINE_CLASS; class++) {\n\t\tint nsibling, n;\n\n\t\tnsibling = select_siblings(gt, class, siblings);\n\t\tif (nsibling < 2)\n\t\t\tcontinue;\n\n\t\tfor (n = 1; n <= nsibling + 1; n++) {\n\t\t\terr = nop_virtual_engine(gt, siblings, nsibling,\n\t\t\t\t\t\t n, 0);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\n\t\terr = nop_virtual_engine(gt, siblings, nsibling, n, CHAIN);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int mask_virtual_engine(struct intel_gt *gt,\n\t\t\t       struct intel_engine_cs **siblings,\n\t\t\t       unsigned int nsibling)\n{\n\tstruct i915_request *request[MAX_ENGINE_INSTANCE + 1];\n\tstruct intel_context *ve;\n\tstruct igt_live_test t;\n\tunsigned int n;\n\tint err;\n\n\t \n\n\tve = intel_engine_create_virtual(siblings, nsibling, 0);\n\tif (IS_ERR(ve)) {\n\t\terr = PTR_ERR(ve);\n\t\tgoto out_close;\n\t}\n\n\terr = intel_context_pin(ve);\n\tif (err)\n\t\tgoto out_put;\n\n\terr = igt_live_test_begin(&t, gt->i915, __func__, ve->engine->name);\n\tif (err)\n\t\tgoto out_unpin;\n\n\tfor (n = 0; n < nsibling; n++) {\n\t\trequest[n] = i915_request_create(ve);\n\t\tif (IS_ERR(request[n])) {\n\t\t\terr = PTR_ERR(request[n]);\n\t\t\tnsibling = n;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\trequest[n]->execution_mask = siblings[nsibling - n - 1]->mask;\n\n\t\ti915_request_get(request[n]);\n\t\ti915_request_add(request[n]);\n\t}\n\n\tfor (n = 0; n < nsibling; n++) {\n\t\tif (i915_request_wait(request[n], 0, HZ / 10) < 0) {\n\t\t\tpr_err(\"%s(%s): wait for %llx:%lld timed out\\n\",\n\t\t\t       __func__, ve->engine->name,\n\t\t\t       request[n]->fence.context,\n\t\t\t       request[n]->fence.seqno);\n\n\t\t\tGEM_TRACE(\"%s(%s) failed at request %llx:%lld\\n\",\n\t\t\t\t  __func__, ve->engine->name,\n\t\t\t\t  request[n]->fence.context,\n\t\t\t\t  request[n]->fence.seqno);\n\t\t\tGEM_TRACE_DUMP();\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (request[n]->engine != siblings[nsibling - n - 1]) {\n\t\t\tpr_err(\"Executed on wrong sibling '%s', expected '%s'\\n\",\n\t\t\t       request[n]->engine->name,\n\t\t\t       siblings[nsibling - n - 1]->name);\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\terr = igt_live_test_end(&t);\nout:\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\tfor (n = 0; n < nsibling; n++)\n\t\ti915_request_put(request[n]);\n\nout_unpin:\n\tintel_context_unpin(ve);\nout_put:\n\tintel_context_put(ve);\nout_close:\n\treturn err;\n}\n\nstatic int live_virtual_mask(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *siblings[MAX_ENGINE_INSTANCE + 1];\n\tunsigned int class;\n\tint err;\n\n\tif (intel_uc_uses_guc_submission(&gt->uc))\n\t\treturn 0;\n\n\tfor (class = 0; class <= MAX_ENGINE_CLASS; class++) {\n\t\tunsigned int nsibling;\n\n\t\tnsibling = select_siblings(gt, class, siblings);\n\t\tif (nsibling < 2)\n\t\t\tcontinue;\n\n\t\terr = mask_virtual_engine(gt, siblings, nsibling);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int slicein_virtual_engine(struct intel_gt *gt,\n\t\t\t\t  struct intel_engine_cs **siblings,\n\t\t\t\t  unsigned int nsibling)\n{\n\tconst long timeout = slice_timeout(siblings[0]);\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tstruct igt_spinner spin;\n\tunsigned int n;\n\tint err = 0;\n\n\t \n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\tfor (n = 0; n < nsibling; n++) {\n\t\tce = intel_context_create(siblings[n]);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tgoto out;\n\t\t}\n\n\t\trq = igt_spinner_create_request(&spin, ce, MI_ARB_CHECK);\n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t}\n\n\tce = intel_engine_create_virtual(siblings, nsibling, 0);\n\tif (IS_ERR(ce)) {\n\t\terr = PTR_ERR(ce);\n\t\tgoto out;\n\t}\n\n\trq = intel_context_create_request(ce);\n\tintel_context_put(ce);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto out;\n\t}\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (i915_request_wait(rq, 0, timeout) < 0) {\n\t\tGEM_TRACE_ERR(\"%s(%s) failed to slice in virtual request\\n\",\n\t\t\t      __func__, rq->engine->name);\n\t\tGEM_TRACE_DUMP();\n\t\tintel_gt_set_wedged(gt);\n\t\terr = -EIO;\n\t}\n\ti915_request_put(rq);\n\nout:\n\tigt_spinner_end(&spin);\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int sliceout_virtual_engine(struct intel_gt *gt,\n\t\t\t\t   struct intel_engine_cs **siblings,\n\t\t\t\t   unsigned int nsibling)\n{\n\tconst long timeout = slice_timeout(siblings[0]);\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tstruct igt_spinner spin;\n\tunsigned int n;\n\tint err = 0;\n\n\t \n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\t \n\tfor (n = 0; n < nsibling; n++) {\n\t\tce = intel_engine_create_virtual(siblings, nsibling, 0);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tgoto out;\n\t\t}\n\n\t\trq = igt_spinner_create_request(&spin, ce, MI_ARB_CHECK);\n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out;\n\t\t}\n\n\t\ti915_request_add(rq);\n\t}\n\n\tfor (n = 0; !err && n < nsibling; n++) {\n\t\tce = intel_context_create(siblings[n]);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tgoto out;\n\t\t}\n\n\t\trq = intel_context_create_request(ce);\n\t\tintel_context_put(ce);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out;\n\t\t}\n\n\t\ti915_request_get(rq);\n\t\ti915_request_add(rq);\n\t\tif (i915_request_wait(rq, 0, timeout) < 0) {\n\t\t\tGEM_TRACE_ERR(\"%s(%s) failed to slice out virtual request\\n\",\n\t\t\t\t      __func__, siblings[n]->name);\n\t\t\tGEM_TRACE_DUMP();\n\t\t\tintel_gt_set_wedged(gt);\n\t\t\terr = -EIO;\n\t\t}\n\t\ti915_request_put(rq);\n\t}\n\nout:\n\tigt_spinner_end(&spin);\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int live_virtual_slice(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *siblings[MAX_ENGINE_INSTANCE + 1];\n\tunsigned int class;\n\tint err;\n\n\tif (intel_uc_uses_guc_submission(&gt->uc))\n\t\treturn 0;\n\n\tfor (class = 0; class <= MAX_ENGINE_CLASS; class++) {\n\t\tunsigned int nsibling;\n\n\t\tnsibling = __select_siblings(gt, class, siblings,\n\t\t\t\t\t     intel_engine_has_timeslices);\n\t\tif (nsibling < 2)\n\t\t\tcontinue;\n\n\t\terr = slicein_virtual_engine(gt, siblings, nsibling);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = sliceout_virtual_engine(gt, siblings, nsibling);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int preserved_virtual_engine(struct intel_gt *gt,\n\t\t\t\t    struct intel_engine_cs **siblings,\n\t\t\t\t    unsigned int nsibling)\n{\n\tstruct i915_request *last = NULL;\n\tstruct intel_context *ve;\n\tstruct i915_vma *scratch;\n\tstruct igt_live_test t;\n\tunsigned int n;\n\tint err = 0;\n\tu32 *cs;\n\n\tscratch =\n\t\t__vm_create_scratch_for_read_pinned(&siblings[0]->gt->ggtt->vm,\n\t\t\t\t\t\t    PAGE_SIZE);\n\tif (IS_ERR(scratch))\n\t\treturn PTR_ERR(scratch);\n\n\terr = i915_vma_sync(scratch);\n\tif (err)\n\t\tgoto out_scratch;\n\n\tve = intel_engine_create_virtual(siblings, nsibling, 0);\n\tif (IS_ERR(ve)) {\n\t\terr = PTR_ERR(ve);\n\t\tgoto out_scratch;\n\t}\n\n\terr = intel_context_pin(ve);\n\tif (err)\n\t\tgoto out_put;\n\n\terr = igt_live_test_begin(&t, gt->i915, __func__, ve->engine->name);\n\tif (err)\n\t\tgoto out_unpin;\n\n\tfor (n = 0; n < NUM_GPR_DW; n++) {\n\t\tstruct intel_engine_cs *engine = siblings[n % nsibling];\n\t\tstruct i915_request *rq;\n\n\t\trq = i915_request_create(ve);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out_end;\n\t\t}\n\n\t\ti915_request_put(last);\n\t\tlast = i915_request_get(rq);\n\n\t\tcs = intel_ring_begin(rq, 8);\n\t\tif (IS_ERR(cs)) {\n\t\t\ti915_request_add(rq);\n\t\t\terr = PTR_ERR(cs);\n\t\t\tgoto out_end;\n\t\t}\n\n\t\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t\t*cs++ = CS_GPR(engine, n);\n\t\t*cs++ = i915_ggtt_offset(scratch) + n * sizeof(u32);\n\t\t*cs++ = 0;\n\n\t\t*cs++ = MI_LOAD_REGISTER_IMM(1);\n\t\t*cs++ = CS_GPR(engine, (n + 1) % NUM_GPR_DW);\n\t\t*cs++ = n + 1;\n\n\t\t*cs++ = MI_NOOP;\n\t\tintel_ring_advance(rq, cs);\n\n\t\t \n\t\trq->execution_mask = engine->mask;\n\t\ti915_request_add(rq);\n\t}\n\n\tif (i915_request_wait(last, 0, HZ / 5) < 0) {\n\t\terr = -ETIME;\n\t\tgoto out_end;\n\t}\n\n\tcs = i915_gem_object_pin_map_unlocked(scratch->obj, I915_MAP_WB);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto out_end;\n\t}\n\n\tfor (n = 0; n < NUM_GPR_DW; n++) {\n\t\tif (cs[n] != n) {\n\t\t\tpr_err(\"Incorrect value[%d] found for GPR[%d]\\n\",\n\t\t\t       cs[n], n);\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\ti915_gem_object_unpin_map(scratch->obj);\n\nout_end:\n\tif (igt_live_test_end(&t))\n\t\terr = -EIO;\n\ti915_request_put(last);\nout_unpin:\n\tintel_context_unpin(ve);\nout_put:\n\tintel_context_put(ve);\nout_scratch:\n\ti915_vma_unpin_and_release(&scratch, 0);\n\treturn err;\n}\n\nstatic int live_virtual_preserved(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *siblings[MAX_ENGINE_INSTANCE + 1];\n\tunsigned int class;\n\n\t \n\n\tif (intel_uc_uses_guc_submission(&gt->uc))\n\t\treturn 0;\n\n\t \n\tif (GRAPHICS_VER(gt->i915) < 9)\n\t\treturn 0;\n\n\tfor (class = 0; class <= MAX_ENGINE_CLASS; class++) {\n\t\tint nsibling, err;\n\n\t\tnsibling = select_siblings(gt, class, siblings);\n\t\tif (nsibling < 2)\n\t\t\tcontinue;\n\n\t\terr = preserved_virtual_engine(gt, siblings, nsibling);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int reset_virtual_engine(struct intel_gt *gt,\n\t\t\t\tstruct intel_engine_cs **siblings,\n\t\t\t\tunsigned int nsibling)\n{\n\tstruct intel_engine_cs *engine;\n\tstruct intel_context *ve;\n\tstruct igt_spinner spin;\n\tstruct i915_request *rq;\n\tunsigned int n;\n\tint err = 0;\n\n\t \n\n\tif (igt_spinner_init(&spin, gt))\n\t\treturn -ENOMEM;\n\n\tve = intel_engine_create_virtual(siblings, nsibling, 0);\n\tif (IS_ERR(ve)) {\n\t\terr = PTR_ERR(ve);\n\t\tgoto out_spin;\n\t}\n\n\tfor (n = 0; n < nsibling; n++)\n\t\tst_engine_heartbeat_disable(siblings[n]);\n\n\trq = igt_spinner_create_request(&spin, ve, MI_ARB_CHECK);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto out_heartbeat;\n\t}\n\ti915_request_add(rq);\n\n\tif (!igt_wait_for_spinner(&spin, rq)) {\n\t\tintel_gt_set_wedged(gt);\n\t\terr = -ETIME;\n\t\tgoto out_heartbeat;\n\t}\n\n\tengine = rq->engine;\n\tGEM_BUG_ON(engine == ve->engine);\n\n\t \n\terr = engine_lock_reset_tasklet(engine);\n\tif (err)\n\t\tgoto out_heartbeat;\n\n\tengine->sched_engine->tasklet.callback(&engine->sched_engine->tasklet);\n\tGEM_BUG_ON(execlists_active(&engine->execlists) != rq);\n\n\t \n\tspin_lock_irq(&engine->sched_engine->lock);\n\t__unwind_incomplete_requests(engine);\n\tspin_unlock_irq(&engine->sched_engine->lock);\n\tGEM_BUG_ON(rq->engine != engine);\n\n\t \n\texeclists_hold(engine, rq);\n\tGEM_BUG_ON(!i915_request_on_hold(rq));\n\n\t__intel_engine_reset_bh(engine, NULL);\n\tGEM_BUG_ON(rq->fence.error != -EIO);\n\n\t \n\tengine_unlock_reset_tasklet(engine);\n\n\t \n\ti915_request_get(rq);\n\tif (!i915_request_wait(rq, 0, HZ / 5)) {\n\t\tpr_err(\"%s: on hold request completed!\\n\",\n\t\t       engine->name);\n\t\tintel_gt_set_wedged(gt);\n\t\terr = -EIO;\n\t\tgoto out_rq;\n\t}\n\tGEM_BUG_ON(!i915_request_on_hold(rq));\n\n\t \n\texeclists_unhold(engine, rq);\n\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\tpr_err(\"%s: held request did not complete!\\n\",\n\t\t       engine->name);\n\t\tintel_gt_set_wedged(gt);\n\t\terr = -ETIME;\n\t}\n\nout_rq:\n\ti915_request_put(rq);\nout_heartbeat:\n\tfor (n = 0; n < nsibling; n++)\n\t\tst_engine_heartbeat_enable(siblings[n]);\n\n\tintel_context_put(ve);\nout_spin:\n\tigt_spinner_fini(&spin);\n\treturn err;\n}\n\nstatic int live_virtual_reset(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *siblings[MAX_ENGINE_INSTANCE + 1];\n\tunsigned int class;\n\n\t \n\n\tif (intel_uc_uses_guc_submission(&gt->uc))\n\t\treturn 0;\n\n\tif (!intel_has_reset_engine(gt))\n\t\treturn 0;\n\n\tfor (class = 0; class <= MAX_ENGINE_CLASS; class++) {\n\t\tint nsibling, err;\n\n\t\tnsibling = select_siblings(gt, class, siblings);\n\t\tif (nsibling < 2)\n\t\t\tcontinue;\n\n\t\terr = reset_virtual_engine(gt, siblings, nsibling);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nint intel_execlists_live_selftests(struct drm_i915_private *i915)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(live_sanitycheck),\n\t\tSUBTEST(live_unlite_switch),\n\t\tSUBTEST(live_unlite_preempt),\n\t\tSUBTEST(live_unlite_ring),\n\t\tSUBTEST(live_pin_rewind),\n\t\tSUBTEST(live_hold_reset),\n\t\tSUBTEST(live_error_interrupt),\n\t\tSUBTEST(live_timeslice_preempt),\n\t\tSUBTEST(live_timeslice_rewind),\n\t\tSUBTEST(live_timeslice_queue),\n\t\tSUBTEST(live_timeslice_nopreempt),\n\t\tSUBTEST(live_busywait_preempt),\n\t\tSUBTEST(live_preempt),\n\t\tSUBTEST(live_late_preempt),\n\t\tSUBTEST(live_nopreempt),\n\t\tSUBTEST(live_preempt_cancel),\n\t\tSUBTEST(live_suppress_self_preempt),\n\t\tSUBTEST(live_chain_preempt),\n\t\tSUBTEST(live_preempt_ring),\n\t\tSUBTEST(live_preempt_gang),\n\t\tSUBTEST(live_preempt_timeout),\n\t\tSUBTEST(live_preempt_user),\n\t\tSUBTEST(live_preempt_smoke),\n\t\tSUBTEST(live_virtual_engine),\n\t\tSUBTEST(live_virtual_mask),\n\t\tSUBTEST(live_virtual_preserved),\n\t\tSUBTEST(live_virtual_slice),\n\t\tSUBTEST(live_virtual_reset),\n\t};\n\n\tif (to_gt(i915)->submission_method != INTEL_SUBMISSION_ELSP)\n\t\treturn 0;\n\n\tif (intel_gt_is_wedged(to_gt(i915)))\n\t\treturn 0;\n\n\treturn intel_gt_live_subtests(tests, to_gt(i915));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}