{
  "module_name": "gen8_ppgtt.c",
  "hash_id": "05990afd2ece3632dff5937d227252722e3ff718c0b3afb608ec4279c116ef55",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/gen8_ppgtt.c",
  "human_readable_source": "\n \n\n#include <linux/log2.h>\n\n#include \"gem/i915_gem_lmem.h\"\n\n#include \"gen8_ppgtt.h\"\n#include \"i915_scatterlist.h\"\n#include \"i915_trace.h\"\n#include \"i915_pvinfo.h\"\n#include \"i915_vgpu.h\"\n#include \"intel_gt.h\"\n#include \"intel_gtt.h\"\n\nstatic u64 gen8_pde_encode(const dma_addr_t addr,\n\t\t\t   const enum i915_cache_level level)\n{\n\tu64 pde = addr | GEN8_PAGE_PRESENT | GEN8_PAGE_RW;\n\n\tif (level != I915_CACHE_NONE)\n\t\tpde |= PPAT_CACHED_PDE;\n\telse\n\t\tpde |= PPAT_UNCACHED;\n\n\treturn pde;\n}\n\nstatic u64 gen8_pte_encode(dma_addr_t addr,\n\t\t\t   unsigned int pat_index,\n\t\t\t   u32 flags)\n{\n\tgen8_pte_t pte = addr | GEN8_PAGE_PRESENT | GEN8_PAGE_RW;\n\n\tif (unlikely(flags & PTE_READ_ONLY))\n\t\tpte &= ~GEN8_PAGE_RW;\n\n\t \n\tswitch (pat_index) {\n\tcase I915_CACHE_NONE:\n\t\tpte |= PPAT_UNCACHED;\n\t\tbreak;\n\tcase I915_CACHE_WT:\n\t\tpte |= PPAT_DISPLAY_ELLC;\n\t\tbreak;\n\tdefault:\n\t\tpte |= PPAT_CACHED;\n\t\tbreak;\n\t}\n\n\treturn pte;\n}\n\nstatic u64 gen12_pte_encode(dma_addr_t addr,\n\t\t\t    unsigned int pat_index,\n\t\t\t    u32 flags)\n{\n\tgen8_pte_t pte = addr | GEN8_PAGE_PRESENT | GEN8_PAGE_RW;\n\n\tif (unlikely(flags & PTE_READ_ONLY))\n\t\tpte &= ~GEN8_PAGE_RW;\n\n\tif (flags & PTE_LM)\n\t\tpte |= GEN12_PPGTT_PTE_LM;\n\n\tif (pat_index & BIT(0))\n\t\tpte |= GEN12_PPGTT_PTE_PAT0;\n\n\tif (pat_index & BIT(1))\n\t\tpte |= GEN12_PPGTT_PTE_PAT1;\n\n\tif (pat_index & BIT(2))\n\t\tpte |= GEN12_PPGTT_PTE_PAT2;\n\n\tif (pat_index & BIT(3))\n\t\tpte |= MTL_PPGTT_PTE_PAT3;\n\n\treturn pte;\n}\n\nstatic void gen8_ppgtt_notify_vgt(struct i915_ppgtt *ppgtt, bool create)\n{\n\tstruct drm_i915_private *i915 = ppgtt->vm.i915;\n\tstruct intel_uncore *uncore = ppgtt->vm.gt->uncore;\n\tenum vgt_g2v_type msg;\n\tint i;\n\n\tif (create)\n\t\tatomic_inc(px_used(ppgtt->pd));  \n\telse\n\t\tatomic_dec(px_used(ppgtt->pd));\n\n\tmutex_lock(&i915->vgpu.lock);\n\n\tif (i915_vm_is_4lvl(&ppgtt->vm)) {\n\t\tconst u64 daddr = px_dma(ppgtt->pd);\n\n\t\tintel_uncore_write(uncore,\n\t\t\t\t   vgtif_reg(pdp[0].lo), lower_32_bits(daddr));\n\t\tintel_uncore_write(uncore,\n\t\t\t\t   vgtif_reg(pdp[0].hi), upper_32_bits(daddr));\n\n\t\tmsg = create ?\n\t\t\tVGT_G2V_PPGTT_L4_PAGE_TABLE_CREATE :\n\t\t\tVGT_G2V_PPGTT_L4_PAGE_TABLE_DESTROY;\n\t} else {\n\t\tfor (i = 0; i < GEN8_3LVL_PDPES; i++) {\n\t\t\tconst u64 daddr = i915_page_dir_dma_addr(ppgtt, i);\n\n\t\t\tintel_uncore_write(uncore,\n\t\t\t\t\t   vgtif_reg(pdp[i].lo),\n\t\t\t\t\t   lower_32_bits(daddr));\n\t\t\tintel_uncore_write(uncore,\n\t\t\t\t\t   vgtif_reg(pdp[i].hi),\n\t\t\t\t\t   upper_32_bits(daddr));\n\t\t}\n\n\t\tmsg = create ?\n\t\t\tVGT_G2V_PPGTT_L3_PAGE_TABLE_CREATE :\n\t\t\tVGT_G2V_PPGTT_L3_PAGE_TABLE_DESTROY;\n\t}\n\n\t \n\tintel_uncore_write(uncore, vgtif_reg(g2v_notify), msg);\n\n\tmutex_unlock(&i915->vgpu.lock);\n}\n\n \n#define GEN8_PAGE_SIZE (SZ_4K)  \n#define GEN8_PTE_SHIFT (ilog2(GEN8_PAGE_SIZE))\n#define GEN8_PDES (GEN8_PAGE_SIZE / sizeof(u64))\n#define gen8_pd_shift(lvl) ((lvl) * ilog2(GEN8_PDES))\n#define gen8_pd_index(i, lvl) i915_pde_index((i), gen8_pd_shift(lvl))\n#define __gen8_pte_shift(lvl) (GEN8_PTE_SHIFT + gen8_pd_shift(lvl))\n#define __gen8_pte_index(a, lvl) i915_pde_index((a), __gen8_pte_shift(lvl))\n\n#define as_pd(x) container_of((x), typeof(struct i915_page_directory), pt)\n\nstatic unsigned int\ngen8_pd_range(u64 start, u64 end, int lvl, unsigned int *idx)\n{\n\tconst int shift = gen8_pd_shift(lvl);\n\tconst u64 mask = ~0ull << gen8_pd_shift(lvl + 1);\n\n\tGEM_BUG_ON(start >= end);\n\tend += ~mask >> gen8_pd_shift(1);\n\n\t*idx = i915_pde_index(start, shift);\n\tif ((start ^ end) & mask)\n\t\treturn GEN8_PDES - *idx;\n\telse\n\t\treturn i915_pde_index(end, shift) - *idx;\n}\n\nstatic bool gen8_pd_contains(u64 start, u64 end, int lvl)\n{\n\tconst u64 mask = ~0ull << gen8_pd_shift(lvl + 1);\n\n\tGEM_BUG_ON(start >= end);\n\treturn (start ^ end) & mask && (start & ~mask) == 0;\n}\n\nstatic unsigned int gen8_pt_count(u64 start, u64 end)\n{\n\tGEM_BUG_ON(start >= end);\n\tif ((start ^ end) >> gen8_pd_shift(1))\n\t\treturn GEN8_PDES - (start & (GEN8_PDES - 1));\n\telse\n\t\treturn end - start;\n}\n\nstatic unsigned int gen8_pd_top_count(const struct i915_address_space *vm)\n{\n\tunsigned int shift = __gen8_pte_shift(vm->top);\n\n\treturn (vm->total + (1ull << shift) - 1) >> shift;\n}\n\nstatic struct i915_page_directory *\ngen8_pdp_for_page_index(struct i915_address_space * const vm, const u64 idx)\n{\n\tstruct i915_ppgtt * const ppgtt = i915_vm_to_ppgtt(vm);\n\n\tif (vm->top == 2)\n\t\treturn ppgtt->pd;\n\telse\n\t\treturn i915_pd_entry(ppgtt->pd, gen8_pd_index(idx, vm->top));\n}\n\nstatic struct i915_page_directory *\ngen8_pdp_for_page_address(struct i915_address_space * const vm, const u64 addr)\n{\n\treturn gen8_pdp_for_page_index(vm, addr >> GEN8_PTE_SHIFT);\n}\n\nstatic void __gen8_ppgtt_cleanup(struct i915_address_space *vm,\n\t\t\t\t struct i915_page_directory *pd,\n\t\t\t\t int count, int lvl)\n{\n\tif (lvl) {\n\t\tvoid **pde = pd->entry;\n\n\t\tdo {\n\t\t\tif (!*pde)\n\t\t\t\tcontinue;\n\n\t\t\t__gen8_ppgtt_cleanup(vm, *pde, GEN8_PDES, lvl - 1);\n\t\t} while (pde++, --count);\n\t}\n\n\tfree_px(vm, &pd->pt, lvl);\n}\n\nstatic void gen8_ppgtt_cleanup(struct i915_address_space *vm)\n{\n\tstruct i915_ppgtt *ppgtt = i915_vm_to_ppgtt(vm);\n\n\tif (intel_vgpu_active(vm->i915))\n\t\tgen8_ppgtt_notify_vgt(ppgtt, false);\n\n\tif (ppgtt->pd)\n\t\t__gen8_ppgtt_cleanup(vm, ppgtt->pd,\n\t\t\t\t     gen8_pd_top_count(vm), vm->top);\n\n\tfree_scratch(vm);\n}\n\nstatic u64 __gen8_ppgtt_clear(struct i915_address_space * const vm,\n\t\t\t      struct i915_page_directory * const pd,\n\t\t\t      u64 start, const u64 end, int lvl)\n{\n\tconst struct drm_i915_gem_object * const scratch = vm->scratch[lvl];\n\tunsigned int idx, len;\n\n\tGEM_BUG_ON(end > vm->total >> GEN8_PTE_SHIFT);\n\n\tlen = gen8_pd_range(start, end, lvl--, &idx);\n\tDBG(\"%s(%p):{ lvl:%d, start:%llx, end:%llx, idx:%d, len:%d, used:%d }\\n\",\n\t    __func__, vm, lvl + 1, start, end,\n\t    idx, len, atomic_read(px_used(pd)));\n\tGEM_BUG_ON(!len || len >= atomic_read(px_used(pd)));\n\n\tdo {\n\t\tstruct i915_page_table *pt = pd->entry[idx];\n\n\t\tif (atomic_fetch_inc(&pt->used) >> gen8_pd_shift(1) &&\n\t\t    gen8_pd_contains(start, end, lvl)) {\n\t\t\tDBG(\"%s(%p):{ lvl:%d, idx:%d, start:%llx, end:%llx } removing pd\\n\",\n\t\t\t    __func__, vm, lvl + 1, idx, start, end);\n\t\t\tclear_pd_entry(pd, idx, scratch);\n\t\t\t__gen8_ppgtt_cleanup(vm, as_pd(pt), I915_PDES, lvl);\n\t\t\tstart += (u64)I915_PDES << gen8_pd_shift(lvl);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (lvl) {\n\t\t\tstart = __gen8_ppgtt_clear(vm, as_pd(pt),\n\t\t\t\t\t\t   start, end, lvl);\n\t\t} else {\n\t\t\tunsigned int count;\n\t\t\tunsigned int pte = gen8_pd_index(start, 0);\n\t\t\tunsigned int num_ptes;\n\t\t\tu64 *vaddr;\n\n\t\t\tcount = gen8_pt_count(start, end);\n\t\t\tDBG(\"%s(%p):{ lvl:%d, start:%llx, end:%llx, idx:%d, len:%d, used:%d } removing pte\\n\",\n\t\t\t    __func__, vm, lvl, start, end,\n\t\t\t    gen8_pd_index(start, 0), count,\n\t\t\t    atomic_read(&pt->used));\n\t\t\tGEM_BUG_ON(!count || count >= atomic_read(&pt->used));\n\n\t\t\tnum_ptes = count;\n\t\t\tif (pt->is_compact) {\n\t\t\t\tGEM_BUG_ON(num_ptes % 16);\n\t\t\t\tGEM_BUG_ON(pte % 16);\n\t\t\t\tnum_ptes /= 16;\n\t\t\t\tpte /= 16;\n\t\t\t}\n\n\t\t\tvaddr = px_vaddr(pt);\n\t\t\tmemset64(vaddr + pte,\n\t\t\t\t vm->scratch[0]->encode,\n\t\t\t\t num_ptes);\n\n\t\t\tatomic_sub(count, &pt->used);\n\t\t\tstart += count;\n\t\t}\n\n\t\tif (release_pd_entry(pd, idx, pt, scratch))\n\t\t\tfree_px(vm, pt, lvl);\n\t} while (idx++, --len);\n\n\treturn start;\n}\n\nstatic void gen8_ppgtt_clear(struct i915_address_space *vm,\n\t\t\t     u64 start, u64 length)\n{\n\tGEM_BUG_ON(!IS_ALIGNED(start, BIT_ULL(GEN8_PTE_SHIFT)));\n\tGEM_BUG_ON(!IS_ALIGNED(length, BIT_ULL(GEN8_PTE_SHIFT)));\n\tGEM_BUG_ON(range_overflows(start, length, vm->total));\n\n\tstart >>= GEN8_PTE_SHIFT;\n\tlength >>= GEN8_PTE_SHIFT;\n\tGEM_BUG_ON(length == 0);\n\n\t__gen8_ppgtt_clear(vm, i915_vm_to_ppgtt(vm)->pd,\n\t\t\t   start, start + length, vm->top);\n}\n\nstatic void __gen8_ppgtt_alloc(struct i915_address_space * const vm,\n\t\t\t       struct i915_vm_pt_stash *stash,\n\t\t\t       struct i915_page_directory * const pd,\n\t\t\t       u64 * const start, const u64 end, int lvl)\n{\n\tunsigned int idx, len;\n\n\tGEM_BUG_ON(end > vm->total >> GEN8_PTE_SHIFT);\n\n\tlen = gen8_pd_range(*start, end, lvl--, &idx);\n\tDBG(\"%s(%p):{ lvl:%d, start:%llx, end:%llx, idx:%d, len:%d, used:%d }\\n\",\n\t    __func__, vm, lvl + 1, *start, end,\n\t    idx, len, atomic_read(px_used(pd)));\n\tGEM_BUG_ON(!len || (idx + len - 1) >> gen8_pd_shift(1));\n\n\tspin_lock(&pd->lock);\n\tGEM_BUG_ON(!atomic_read(px_used(pd)));  \n\tdo {\n\t\tstruct i915_page_table *pt = pd->entry[idx];\n\n\t\tif (!pt) {\n\t\t\tspin_unlock(&pd->lock);\n\n\t\t\tDBG(\"%s(%p):{ lvl:%d, idx:%d } allocating new tree\\n\",\n\t\t\t    __func__, vm, lvl + 1, idx);\n\n\t\t\tpt = stash->pt[!!lvl];\n\t\t\t__i915_gem_object_pin_pages(pt->base);\n\n\t\t\tfill_px(pt, vm->scratch[lvl]->encode);\n\n\t\t\tspin_lock(&pd->lock);\n\t\t\tif (likely(!pd->entry[idx])) {\n\t\t\t\tstash->pt[!!lvl] = pt->stash;\n\t\t\t\tatomic_set(&pt->used, 0);\n\t\t\t\tset_pd_entry(pd, idx, pt);\n\t\t\t} else {\n\t\t\t\tpt = pd->entry[idx];\n\t\t\t}\n\t\t}\n\n\t\tif (lvl) {\n\t\t\tatomic_inc(&pt->used);\n\t\t\tspin_unlock(&pd->lock);\n\n\t\t\t__gen8_ppgtt_alloc(vm, stash,\n\t\t\t\t\t   as_pd(pt), start, end, lvl);\n\n\t\t\tspin_lock(&pd->lock);\n\t\t\tatomic_dec(&pt->used);\n\t\t\tGEM_BUG_ON(!atomic_read(&pt->used));\n\t\t} else {\n\t\t\tunsigned int count = gen8_pt_count(*start, end);\n\n\t\t\tDBG(\"%s(%p):{ lvl:%d, start:%llx, end:%llx, idx:%d, len:%d, used:%d } inserting pte\\n\",\n\t\t\t    __func__, vm, lvl, *start, end,\n\t\t\t    gen8_pd_index(*start, 0), count,\n\t\t\t    atomic_read(&pt->used));\n\n\t\t\tatomic_add(count, &pt->used);\n\t\t\t \n\t\t\tGEM_BUG_ON(atomic_read(&pt->used) > NALLOC * I915_PDES);\n\t\t\t*start += count;\n\t\t}\n\t} while (idx++, --len);\n\tspin_unlock(&pd->lock);\n}\n\nstatic void gen8_ppgtt_alloc(struct i915_address_space *vm,\n\t\t\t     struct i915_vm_pt_stash *stash,\n\t\t\t     u64 start, u64 length)\n{\n\tGEM_BUG_ON(!IS_ALIGNED(start, BIT_ULL(GEN8_PTE_SHIFT)));\n\tGEM_BUG_ON(!IS_ALIGNED(length, BIT_ULL(GEN8_PTE_SHIFT)));\n\tGEM_BUG_ON(range_overflows(start, length, vm->total));\n\n\tstart >>= GEN8_PTE_SHIFT;\n\tlength >>= GEN8_PTE_SHIFT;\n\tGEM_BUG_ON(length == 0);\n\n\t__gen8_ppgtt_alloc(vm, stash, i915_vm_to_ppgtt(vm)->pd,\n\t\t\t   &start, start + length, vm->top);\n}\n\nstatic void __gen8_ppgtt_foreach(struct i915_address_space *vm,\n\t\t\t\t struct i915_page_directory *pd,\n\t\t\t\t u64 *start, u64 end, int lvl,\n\t\t\t\t void (*fn)(struct i915_address_space *vm,\n\t\t\t\t\t    struct i915_page_table *pt,\n\t\t\t\t\t    void *data),\n\t\t\t\t void *data)\n{\n\tunsigned int idx, len;\n\n\tlen = gen8_pd_range(*start, end, lvl--, &idx);\n\n\tspin_lock(&pd->lock);\n\tdo {\n\t\tstruct i915_page_table *pt = pd->entry[idx];\n\n\t\tatomic_inc(&pt->used);\n\t\tspin_unlock(&pd->lock);\n\n\t\tif (lvl) {\n\t\t\t__gen8_ppgtt_foreach(vm, as_pd(pt), start, end, lvl,\n\t\t\t\t\t     fn, data);\n\t\t} else {\n\t\t\tfn(vm, pt, data);\n\t\t\t*start += gen8_pt_count(*start, end);\n\t\t}\n\n\t\tspin_lock(&pd->lock);\n\t\tatomic_dec(&pt->used);\n\t} while (idx++, --len);\n\tspin_unlock(&pd->lock);\n}\n\nstatic void gen8_ppgtt_foreach(struct i915_address_space *vm,\n\t\t\t       u64 start, u64 length,\n\t\t\t       void (*fn)(struct i915_address_space *vm,\n\t\t\t\t\t  struct i915_page_table *pt,\n\t\t\t\t\t  void *data),\n\t\t\t       void *data)\n{\n\tstart >>= GEN8_PTE_SHIFT;\n\tlength >>= GEN8_PTE_SHIFT;\n\n\t__gen8_ppgtt_foreach(vm, i915_vm_to_ppgtt(vm)->pd,\n\t\t\t     &start, start + length, vm->top,\n\t\t\t     fn, data);\n}\n\nstatic __always_inline u64\ngen8_ppgtt_insert_pte(struct i915_ppgtt *ppgtt,\n\t\t      struct i915_page_directory *pdp,\n\t\t      struct sgt_dma *iter,\n\t\t      u64 idx,\n\t\t      unsigned int pat_index,\n\t\t      u32 flags)\n{\n\tstruct i915_page_directory *pd;\n\tconst gen8_pte_t pte_encode = ppgtt->vm.pte_encode(0, pat_index, flags);\n\tgen8_pte_t *vaddr;\n\n\tpd = i915_pd_entry(pdp, gen8_pd_index(idx, 2));\n\tvaddr = px_vaddr(i915_pt_entry(pd, gen8_pd_index(idx, 1)));\n\tdo {\n\t\tGEM_BUG_ON(sg_dma_len(iter->sg) < I915_GTT_PAGE_SIZE);\n\t\tvaddr[gen8_pd_index(idx, 0)] = pte_encode | iter->dma;\n\n\t\titer->dma += I915_GTT_PAGE_SIZE;\n\t\tif (iter->dma >= iter->max) {\n\t\t\titer->sg = __sg_next(iter->sg);\n\t\t\tif (!iter->sg || sg_dma_len(iter->sg) == 0) {\n\t\t\t\tidx = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\titer->dma = sg_dma_address(iter->sg);\n\t\t\titer->max = iter->dma + sg_dma_len(iter->sg);\n\t\t}\n\n\t\tif (gen8_pd_index(++idx, 0) == 0) {\n\t\t\tif (gen8_pd_index(idx, 1) == 0) {\n\t\t\t\t \n\t\t\t\tif (gen8_pd_index(idx, 2) == 0)\n\t\t\t\t\tbreak;\n\n\t\t\t\tpd = pdp->entry[gen8_pd_index(idx, 2)];\n\t\t\t}\n\n\t\t\tdrm_clflush_virt_range(vaddr, PAGE_SIZE);\n\t\t\tvaddr = px_vaddr(i915_pt_entry(pd, gen8_pd_index(idx, 1)));\n\t\t}\n\t} while (1);\n\tdrm_clflush_virt_range(vaddr, PAGE_SIZE);\n\n\treturn idx;\n}\n\nstatic void\nxehpsdv_ppgtt_insert_huge(struct i915_address_space *vm,\n\t\t\t  struct i915_vma_resource *vma_res,\n\t\t\t  struct sgt_dma *iter,\n\t\t\t  unsigned int pat_index,\n\t\t\t  u32 flags)\n{\n\tconst gen8_pte_t pte_encode = vm->pte_encode(0, pat_index, flags);\n\tunsigned int rem = sg_dma_len(iter->sg);\n\tu64 start = vma_res->start;\n\tu64 end = start + vma_res->vma_size;\n\n\tGEM_BUG_ON(!i915_vm_is_4lvl(vm));\n\n\tdo {\n\t\tstruct i915_page_directory * const pdp =\n\t\t\tgen8_pdp_for_page_address(vm, start);\n\t\tstruct i915_page_directory * const pd =\n\t\t\ti915_pd_entry(pdp, __gen8_pte_index(start, 2));\n\t\tstruct i915_page_table *pt =\n\t\t\ti915_pt_entry(pd, __gen8_pte_index(start, 1));\n\t\tgen8_pte_t encode = pte_encode;\n\t\tunsigned int page_size;\n\t\tgen8_pte_t *vaddr;\n\t\tu16 index, max, nent, i;\n\n\t\tmax = I915_PDES;\n\t\tnent = 1;\n\n\t\tif (vma_res->bi.page_sizes.sg & I915_GTT_PAGE_SIZE_2M &&\n\t\t    IS_ALIGNED(iter->dma, I915_GTT_PAGE_SIZE_2M) &&\n\t\t    rem >= I915_GTT_PAGE_SIZE_2M &&\n\t\t    !__gen8_pte_index(start, 0)) {\n\t\t\tindex = __gen8_pte_index(start, 1);\n\t\t\tencode |= GEN8_PDE_PS_2M;\n\t\t\tpage_size = I915_GTT_PAGE_SIZE_2M;\n\n\t\t\tvaddr = px_vaddr(pd);\n\t\t} else {\n\t\t\tindex =  __gen8_pte_index(start, 0);\n\t\t\tpage_size = I915_GTT_PAGE_SIZE;\n\n\t\t\tif (vma_res->bi.page_sizes.sg & I915_GTT_PAGE_SIZE_64K) {\n\t\t\t\t \n\t\t\t\tif ((encode & GEN12_PPGTT_PTE_LM) &&\n\t\t\t\t    end - start >= SZ_2M && !index) {\n\t\t\t\t\tindex = __gen8_pte_index(start, 0) / 16;\n\t\t\t\t\tpage_size = I915_GTT_PAGE_SIZE_64K;\n\n\t\t\t\t\tmax /= 16;\n\n\t\t\t\t\tvaddr = px_vaddr(pd);\n\t\t\t\t\tvaddr[__gen8_pte_index(start, 1)] |= GEN12_PDE_64K;\n\n\t\t\t\t\tpt->is_compact = true;\n\t\t\t\t} else if (IS_ALIGNED(iter->dma, I915_GTT_PAGE_SIZE_64K) &&\n\t\t\t\t\t   rem >= I915_GTT_PAGE_SIZE_64K &&\n\t\t\t\t\t   !(index % 16)) {\n\t\t\t\t\tencode |= GEN12_PTE_PS64;\n\t\t\t\t\tpage_size = I915_GTT_PAGE_SIZE_64K;\n\t\t\t\t\tnent = 16;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tvaddr = px_vaddr(pt);\n\t\t}\n\n\t\tdo {\n\t\t\tGEM_BUG_ON(rem < page_size);\n\n\t\t\tfor (i = 0; i < nent; i++) {\n\t\t\t\tvaddr[index++] =\n\t\t\t\t\tencode | (iter->dma + i *\n\t\t\t\t\t\t  I915_GTT_PAGE_SIZE);\n\t\t\t}\n\n\t\t\tstart += page_size;\n\t\t\titer->dma += page_size;\n\t\t\trem -= page_size;\n\t\t\tif (iter->dma >= iter->max) {\n\t\t\t\titer->sg = __sg_next(iter->sg);\n\t\t\t\tif (!iter->sg)\n\t\t\t\t\tbreak;\n\n\t\t\t\trem = sg_dma_len(iter->sg);\n\t\t\t\tif (!rem)\n\t\t\t\t\tbreak;\n\n\t\t\t\titer->dma = sg_dma_address(iter->sg);\n\t\t\t\titer->max = iter->dma + rem;\n\n\t\t\t\tif (unlikely(!IS_ALIGNED(iter->dma, page_size)))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t} while (rem >= page_size && index < max);\n\n\t\tdrm_clflush_virt_range(vaddr, PAGE_SIZE);\n\t\tvma_res->page_sizes_gtt |= page_size;\n\t} while (iter->sg && sg_dma_len(iter->sg));\n}\n\nstatic void gen8_ppgtt_insert_huge(struct i915_address_space *vm,\n\t\t\t\t   struct i915_vma_resource *vma_res,\n\t\t\t\t   struct sgt_dma *iter,\n\t\t\t\t   unsigned int pat_index,\n\t\t\t\t   u32 flags)\n{\n\tconst gen8_pte_t pte_encode = vm->pte_encode(0, pat_index, flags);\n\tunsigned int rem = sg_dma_len(iter->sg);\n\tu64 start = vma_res->start;\n\n\tGEM_BUG_ON(!i915_vm_is_4lvl(vm));\n\n\tdo {\n\t\tstruct i915_page_directory * const pdp =\n\t\t\tgen8_pdp_for_page_address(vm, start);\n\t\tstruct i915_page_directory * const pd =\n\t\t\ti915_pd_entry(pdp, __gen8_pte_index(start, 2));\n\t\tgen8_pte_t encode = pte_encode;\n\t\tunsigned int maybe_64K = -1;\n\t\tunsigned int page_size;\n\t\tgen8_pte_t *vaddr;\n\t\tu16 index;\n\n\t\tif (vma_res->bi.page_sizes.sg & I915_GTT_PAGE_SIZE_2M &&\n\t\t    IS_ALIGNED(iter->dma, I915_GTT_PAGE_SIZE_2M) &&\n\t\t    rem >= I915_GTT_PAGE_SIZE_2M &&\n\t\t    !__gen8_pte_index(start, 0)) {\n\t\t\tindex = __gen8_pte_index(start, 1);\n\t\t\tencode |= GEN8_PDE_PS_2M;\n\t\t\tpage_size = I915_GTT_PAGE_SIZE_2M;\n\n\t\t\tvaddr = px_vaddr(pd);\n\t\t} else {\n\t\t\tstruct i915_page_table *pt =\n\t\t\t\ti915_pt_entry(pd, __gen8_pte_index(start, 1));\n\n\t\t\tindex = __gen8_pte_index(start, 0);\n\t\t\tpage_size = I915_GTT_PAGE_SIZE;\n\n\t\t\tif (!index &&\n\t\t\t    vma_res->bi.page_sizes.sg & I915_GTT_PAGE_SIZE_64K &&\n\t\t\t    IS_ALIGNED(iter->dma, I915_GTT_PAGE_SIZE_64K) &&\n\t\t\t    (IS_ALIGNED(rem, I915_GTT_PAGE_SIZE_64K) ||\n\t\t\t     rem >= (I915_PDES - index) * I915_GTT_PAGE_SIZE))\n\t\t\t\tmaybe_64K = __gen8_pte_index(start, 1);\n\n\t\t\tvaddr = px_vaddr(pt);\n\t\t}\n\n\t\tdo {\n\t\t\tGEM_BUG_ON(sg_dma_len(iter->sg) < page_size);\n\t\t\tvaddr[index++] = encode | iter->dma;\n\n\t\t\tstart += page_size;\n\t\t\titer->dma += page_size;\n\t\t\trem -= page_size;\n\t\t\tif (iter->dma >= iter->max) {\n\t\t\t\titer->sg = __sg_next(iter->sg);\n\t\t\t\tif (!iter->sg)\n\t\t\t\t\tbreak;\n\n\t\t\t\trem = sg_dma_len(iter->sg);\n\t\t\t\tif (!rem)\n\t\t\t\t\tbreak;\n\n\t\t\t\titer->dma = sg_dma_address(iter->sg);\n\t\t\t\titer->max = iter->dma + rem;\n\n\t\t\t\tif (maybe_64K != -1 && index < I915_PDES &&\n\t\t\t\t    !(IS_ALIGNED(iter->dma, I915_GTT_PAGE_SIZE_64K) &&\n\t\t\t\t      (IS_ALIGNED(rem, I915_GTT_PAGE_SIZE_64K) ||\n\t\t\t\t       rem >= (I915_PDES - index) * I915_GTT_PAGE_SIZE)))\n\t\t\t\t\tmaybe_64K = -1;\n\n\t\t\t\tif (unlikely(!IS_ALIGNED(iter->dma, page_size)))\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t} while (rem >= page_size && index < I915_PDES);\n\n\t\tdrm_clflush_virt_range(vaddr, PAGE_SIZE);\n\n\t\t \n\t\tif (maybe_64K != -1 &&\n\t\t    (index == I915_PDES ||\n\t\t     (i915_vm_has_scratch_64K(vm) &&\n\t\t      !iter->sg && IS_ALIGNED(vma_res->start +\n\t\t\t\t\t      vma_res->node_size,\n\t\t\t\t\t      I915_GTT_PAGE_SIZE_2M)))) {\n\t\t\tvaddr = px_vaddr(pd);\n\t\t\tvaddr[maybe_64K] |= GEN8_PDE_IPS_64K;\n\t\t\tdrm_clflush_virt_range(vaddr, PAGE_SIZE);\n\t\t\tpage_size = I915_GTT_PAGE_SIZE_64K;\n\n\t\t\t \n\t\t\tif (I915_SELFTEST_ONLY(vm->scrub_64K)) {\n\t\t\t\tu16 i;\n\n\t\t\t\tencode = vm->scratch[0]->encode;\n\t\t\t\tvaddr = px_vaddr(i915_pt_entry(pd, maybe_64K));\n\n\t\t\t\tfor (i = 1; i < index; i += 16)\n\t\t\t\t\tmemset64(vaddr + i, encode, 15);\n\n\t\t\t\tdrm_clflush_virt_range(vaddr, PAGE_SIZE);\n\t\t\t}\n\t\t}\n\n\t\tvma_res->page_sizes_gtt |= page_size;\n\t} while (iter->sg && sg_dma_len(iter->sg));\n}\n\nstatic void gen8_ppgtt_insert(struct i915_address_space *vm,\n\t\t\t      struct i915_vma_resource *vma_res,\n\t\t\t      unsigned int pat_index,\n\t\t\t      u32 flags)\n{\n\tstruct i915_ppgtt * const ppgtt = i915_vm_to_ppgtt(vm);\n\tstruct sgt_dma iter = sgt_dma(vma_res);\n\n\tif (vma_res->bi.page_sizes.sg > I915_GTT_PAGE_SIZE) {\n\t\tif (GRAPHICS_VER_FULL(vm->i915) >= IP_VER(12, 50))\n\t\t\txehpsdv_ppgtt_insert_huge(vm, vma_res, &iter, pat_index, flags);\n\t\telse\n\t\t\tgen8_ppgtt_insert_huge(vm, vma_res, &iter, pat_index, flags);\n\t} else  {\n\t\tu64 idx = vma_res->start >> GEN8_PTE_SHIFT;\n\n\t\tdo {\n\t\t\tstruct i915_page_directory * const pdp =\n\t\t\t\tgen8_pdp_for_page_index(vm, idx);\n\n\t\t\tidx = gen8_ppgtt_insert_pte(ppgtt, pdp, &iter, idx,\n\t\t\t\t\t\t    pat_index, flags);\n\t\t} while (idx);\n\n\t\tvma_res->page_sizes_gtt = I915_GTT_PAGE_SIZE;\n\t}\n}\n\nstatic void gen8_ppgtt_insert_entry(struct i915_address_space *vm,\n\t\t\t\t    dma_addr_t addr,\n\t\t\t\t    u64 offset,\n\t\t\t\t    unsigned int pat_index,\n\t\t\t\t    u32 flags)\n{\n\tu64 idx = offset >> GEN8_PTE_SHIFT;\n\tstruct i915_page_directory * const pdp =\n\t\tgen8_pdp_for_page_index(vm, idx);\n\tstruct i915_page_directory *pd =\n\t\ti915_pd_entry(pdp, gen8_pd_index(idx, 2));\n\tstruct i915_page_table *pt = i915_pt_entry(pd, gen8_pd_index(idx, 1));\n\tgen8_pte_t *vaddr;\n\n\tGEM_BUG_ON(pt->is_compact);\n\n\tvaddr = px_vaddr(pt);\n\tvaddr[gen8_pd_index(idx, 0)] = vm->pte_encode(addr, pat_index, flags);\n\tdrm_clflush_virt_range(&vaddr[gen8_pd_index(idx, 0)], sizeof(*vaddr));\n}\n\nstatic void __xehpsdv_ppgtt_insert_entry_lm(struct i915_address_space *vm,\n\t\t\t\t\t    dma_addr_t addr,\n\t\t\t\t\t    u64 offset,\n\t\t\t\t\t    unsigned int pat_index,\n\t\t\t\t\t    u32 flags)\n{\n\tu64 idx = offset >> GEN8_PTE_SHIFT;\n\tstruct i915_page_directory * const pdp =\n\t\tgen8_pdp_for_page_index(vm, idx);\n\tstruct i915_page_directory *pd =\n\t\ti915_pd_entry(pdp, gen8_pd_index(idx, 2));\n\tstruct i915_page_table *pt = i915_pt_entry(pd, gen8_pd_index(idx, 1));\n\tgen8_pte_t *vaddr;\n\n\tGEM_BUG_ON(!IS_ALIGNED(addr, SZ_64K));\n\tGEM_BUG_ON(!IS_ALIGNED(offset, SZ_64K));\n\n\t \n\n\tif (!pt->is_compact) {\n\t\tvaddr = px_vaddr(pd);\n\t\tvaddr[gen8_pd_index(idx, 1)] |= GEN12_PDE_64K;\n\t\tpt->is_compact = true;\n\t}\n\n\tvaddr = px_vaddr(pt);\n\tvaddr[gen8_pd_index(idx, 0) / 16] = vm->pte_encode(addr, pat_index, flags);\n}\n\nstatic void xehpsdv_ppgtt_insert_entry(struct i915_address_space *vm,\n\t\t\t\t       dma_addr_t addr,\n\t\t\t\t       u64 offset,\n\t\t\t\t       unsigned int pat_index,\n\t\t\t\t       u32 flags)\n{\n\tif (flags & PTE_LM)\n\t\treturn __xehpsdv_ppgtt_insert_entry_lm(vm, addr, offset,\n\t\t\t\t\t\t       pat_index, flags);\n\n\treturn gen8_ppgtt_insert_entry(vm, addr, offset, pat_index, flags);\n}\n\nstatic int gen8_init_scratch(struct i915_address_space *vm)\n{\n\tu32 pte_flags;\n\tint ret;\n\tint i;\n\n\t \n\tif (vm->has_read_only && vm->gt->vm && !i915_is_ggtt(vm->gt->vm)) {\n\t\tstruct i915_address_space *clone = vm->gt->vm;\n\n\t\tGEM_BUG_ON(!clone->has_read_only);\n\n\t\tvm->scratch_order = clone->scratch_order;\n\t\tfor (i = 0; i <= vm->top; i++)\n\t\t\tvm->scratch[i] = i915_gem_object_get(clone->scratch[i]);\n\n\t\treturn 0;\n\t}\n\n\tret = setup_scratch_page(vm);\n\tif (ret)\n\t\treturn ret;\n\n\tpte_flags = vm->has_read_only;\n\tif (i915_gem_object_is_lmem(vm->scratch[0]))\n\t\tpte_flags |= PTE_LM;\n\n\tvm->scratch[0]->encode =\n\t\tvm->pte_encode(px_dma(vm->scratch[0]),\n\t\t\t       i915_gem_get_pat_index(vm->i915,\n\t\t\t\t\t\t      I915_CACHE_NONE),\n\t\t\t       pte_flags);\n\n\tfor (i = 1; i <= vm->top; i++) {\n\t\tstruct drm_i915_gem_object *obj;\n\n\t\tobj = vm->alloc_pt_dma(vm, I915_GTT_PAGE_SIZE_4K);\n\t\tif (IS_ERR(obj)) {\n\t\t\tret = PTR_ERR(obj);\n\t\t\tgoto free_scratch;\n\t\t}\n\n\t\tret = map_pt_dma(vm, obj);\n\t\tif (ret) {\n\t\t\ti915_gem_object_put(obj);\n\t\t\tgoto free_scratch;\n\t\t}\n\n\t\tfill_px(obj, vm->scratch[i - 1]->encode);\n\t\tobj->encode = gen8_pde_encode(px_dma(obj), I915_CACHE_NONE);\n\n\t\tvm->scratch[i] = obj;\n\t}\n\n\treturn 0;\n\nfree_scratch:\n\twhile (i--)\n\t\ti915_gem_object_put(vm->scratch[i]);\n\tvm->scratch[0] = NULL;\n\treturn ret;\n}\n\nstatic int gen8_preallocate_top_level_pdp(struct i915_ppgtt *ppgtt)\n{\n\tstruct i915_address_space *vm = &ppgtt->vm;\n\tstruct i915_page_directory *pd = ppgtt->pd;\n\tunsigned int idx;\n\n\tGEM_BUG_ON(vm->top != 2);\n\tGEM_BUG_ON(gen8_pd_top_count(vm) != GEN8_3LVL_PDPES);\n\n\tfor (idx = 0; idx < GEN8_3LVL_PDPES; idx++) {\n\t\tstruct i915_page_directory *pde;\n\t\tint err;\n\n\t\tpde = alloc_pd(vm);\n\t\tif (IS_ERR(pde))\n\t\t\treturn PTR_ERR(pde);\n\n\t\terr = map_pt_dma(vm, pde->pt.base);\n\t\tif (err) {\n\t\t\tfree_pd(vm, pde);\n\t\t\treturn err;\n\t\t}\n\n\t\tfill_px(pde, vm->scratch[1]->encode);\n\t\tset_pd_entry(pd, idx, pde);\n\t\tatomic_inc(px_used(pde));  \n\t}\n\twmb();\n\n\treturn 0;\n}\n\nstatic struct i915_page_directory *\ngen8_alloc_top_pd(struct i915_address_space *vm)\n{\n\tconst unsigned int count = gen8_pd_top_count(vm);\n\tstruct i915_page_directory *pd;\n\tint err;\n\n\tGEM_BUG_ON(count > I915_PDES);\n\n\tpd = __alloc_pd(count);\n\tif (unlikely(!pd))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpd->pt.base = vm->alloc_pt_dma(vm, I915_GTT_PAGE_SIZE_4K);\n\tif (IS_ERR(pd->pt.base)) {\n\t\terr = PTR_ERR(pd->pt.base);\n\t\tpd->pt.base = NULL;\n\t\tgoto err_pd;\n\t}\n\n\terr = map_pt_dma(vm, pd->pt.base);\n\tif (err)\n\t\tgoto err_pd;\n\n\tfill_page_dma(px_base(pd), vm->scratch[vm->top]->encode, count);\n\tatomic_inc(px_used(pd));  \n\treturn pd;\n\nerr_pd:\n\tfree_pd(vm, pd);\n\treturn ERR_PTR(err);\n}\n\n \nstruct i915_ppgtt *gen8_ppgtt_create(struct intel_gt *gt,\n\t\t\t\t     unsigned long lmem_pt_obj_flags)\n{\n\tstruct i915_page_directory *pd;\n\tstruct i915_ppgtt *ppgtt;\n\tint err;\n\n\tppgtt = kzalloc(sizeof(*ppgtt), GFP_KERNEL);\n\tif (!ppgtt)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tppgtt_init(ppgtt, gt, lmem_pt_obj_flags);\n\tppgtt->vm.top = i915_vm_is_4lvl(&ppgtt->vm) ? 3 : 2;\n\tppgtt->vm.pd_shift = ilog2(SZ_4K * SZ_4K / sizeof(gen8_pte_t));\n\n\t \n\tppgtt->vm.has_read_only = !IS_GRAPHICS_VER(gt->i915, 11, 12);\n\n\tif (HAS_LMEM(gt->i915))\n\t\tppgtt->vm.alloc_pt_dma = alloc_pt_lmem;\n\telse\n\t\tppgtt->vm.alloc_pt_dma = alloc_pt_dma;\n\n\t \n\tppgtt->vm.alloc_scratch_dma = alloc_pt_dma;\n\n\tif (GRAPHICS_VER(gt->i915) >= 12)\n\t\tppgtt->vm.pte_encode = gen12_pte_encode;\n\telse\n\t\tppgtt->vm.pte_encode = gen8_pte_encode;\n\n\tppgtt->vm.bind_async_flags = I915_VMA_LOCAL_BIND;\n\tppgtt->vm.insert_entries = gen8_ppgtt_insert;\n\tif (HAS_64K_PAGES(gt->i915))\n\t\tppgtt->vm.insert_page = xehpsdv_ppgtt_insert_entry;\n\telse\n\t\tppgtt->vm.insert_page = gen8_ppgtt_insert_entry;\n\tppgtt->vm.allocate_va_range = gen8_ppgtt_alloc;\n\tppgtt->vm.clear_range = gen8_ppgtt_clear;\n\tppgtt->vm.foreach = gen8_ppgtt_foreach;\n\tppgtt->vm.cleanup = gen8_ppgtt_cleanup;\n\n\terr = gen8_init_scratch(&ppgtt->vm);\n\tif (err)\n\t\tgoto err_put;\n\n\tpd = gen8_alloc_top_pd(&ppgtt->vm);\n\tif (IS_ERR(pd)) {\n\t\terr = PTR_ERR(pd);\n\t\tgoto err_put;\n\t}\n\tppgtt->pd = pd;\n\n\tif (!i915_vm_is_4lvl(&ppgtt->vm)) {\n\t\terr = gen8_preallocate_top_level_pdp(ppgtt);\n\t\tif (err)\n\t\t\tgoto err_put;\n\t}\n\n\tif (intel_vgpu_active(gt->i915))\n\t\tgen8_ppgtt_notify_vgt(ppgtt, true);\n\n\treturn ppgtt;\n\nerr_put:\n\ti915_vm_put(&ppgtt->vm);\n\treturn ERR_PTR(err);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}