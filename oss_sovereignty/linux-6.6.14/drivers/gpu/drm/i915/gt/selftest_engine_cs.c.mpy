{
  "module_name": "selftest_engine_cs.c",
  "hash_id": "5dbed2e0e34f8871d0aa49b4dd71b3f7dd8e313e0e44c462a75fffe8782a979f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/selftest_engine_cs.c",
  "human_readable_source": "\n \n\n#include <linux/sort.h>\n\n#include \"intel_gpu_commands.h\"\n#include \"intel_gt_pm.h\"\n#include \"intel_rps.h\"\n\n#include \"i915_selftest.h\"\n#include \"selftests/igt_flush_test.h\"\n\n#define COUNT 5\n\nstatic int cmp_u32(const void *A, const void *B)\n{\n\tconst u32 *a = A, *b = B;\n\n\treturn *a - *b;\n}\n\nstatic void perf_begin(struct intel_gt *gt)\n{\n\tintel_gt_pm_get(gt);\n\n\t \n\tatomic_inc(&gt->rps.num_waiters);\n\tqueue_work(gt->i915->unordered_wq, &gt->rps.work);\n\tflush_work(&gt->rps.work);\n}\n\nstatic int perf_end(struct intel_gt *gt)\n{\n\tatomic_dec(&gt->rps.num_waiters);\n\tintel_gt_pm_put(gt);\n\n\treturn igt_flush_test(gt->i915);\n}\n\nstatic i915_reg_t timestamp_reg(struct intel_engine_cs *engine)\n{\n\tstruct drm_i915_private *i915 = engine->i915;\n\n\tif (GRAPHICS_VER(i915) == 5 || IS_G4X(i915))\n\t\treturn RING_TIMESTAMP_UDW(engine->mmio_base);\n\telse\n\t\treturn RING_TIMESTAMP(engine->mmio_base);\n}\n\nstatic int write_timestamp(struct i915_request *rq, int slot)\n{\n\tstruct intel_timeline *tl =\n\t\trcu_dereference_protected(rq->timeline,\n\t\t\t\t\t  !i915_request_signaled(rq));\n\tu32 cmd;\n\tu32 *cs;\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\tcmd = MI_STORE_REGISTER_MEM | MI_USE_GGTT;\n\tif (GRAPHICS_VER(rq->i915) >= 8)\n\t\tcmd++;\n\t*cs++ = cmd;\n\t*cs++ = i915_mmio_reg_offset(timestamp_reg(rq->engine));\n\t*cs++ = tl->hwsp_offset + slot * sizeof(u32);\n\t*cs++ = 0;\n\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstatic struct i915_vma *create_empty_batch(struct intel_context *ce)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\tu32 *cs;\n\tint err;\n\n\tobj = i915_gem_object_create_internal(ce->engine->i915, PAGE_SIZE);\n\tif (IS_ERR(obj))\n\t\treturn ERR_CAST(obj);\n\n\tcs = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WB);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_put;\n\t}\n\n\tcs[0] = MI_BATCH_BUFFER_END;\n\n\ti915_gem_object_flush_map(obj);\n\n\tvma = i915_vma_instance(obj, ce->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto err_unpin;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\tif (err)\n\t\tgoto err_unpin;\n\n\ti915_gem_object_unpin_map(obj);\n\treturn vma;\n\nerr_unpin:\n\ti915_gem_object_unpin_map(obj);\nerr_put:\n\ti915_gem_object_put(obj);\n\treturn ERR_PTR(err);\n}\n\nstatic u32 trifilter(u32 *a)\n{\n\tu64 sum;\n\n\tsort(a, COUNT, sizeof(*a), cmp_u32, NULL);\n\n\tsum = mul_u32_u32(a[2], 2);\n\tsum += a[1];\n\tsum += a[3];\n\n\treturn sum >> 2;\n}\n\nstatic int perf_mi_bb_start(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\tif (GRAPHICS_VER(gt->i915) < 4)  \n\t\treturn 0;\n\n\tperf_begin(gt);\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce = engine->kernel_context;\n\t\tstruct i915_vma *batch;\n\t\tu32 cycles[COUNT];\n\t\tint i;\n\n\t\tif (GRAPHICS_VER(engine->i915) < 7 && engine->id != RCS0)\n\t\t\tcontinue;\n\n\t\tintel_engine_pm_get(engine);\n\n\t\tbatch = create_empty_batch(ce);\n\t\tif (IS_ERR(batch)) {\n\t\t\terr = PTR_ERR(batch);\n\t\t\tintel_engine_pm_put(engine);\n\t\t\tbreak;\n\t\t}\n\n\t\terr = i915_vma_sync(batch);\n\t\tif (err) {\n\t\t\tintel_engine_pm_put(engine);\n\t\t\ti915_vma_put(batch);\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (i = 0; i < ARRAY_SIZE(cycles); i++) {\n\t\t\tstruct i915_request *rq;\n\n\t\t\trq = i915_request_create(ce);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\terr = write_timestamp(rq, 2);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\terr = rq->engine->emit_bb_start(rq,\n\t\t\t\t\t\t\ti915_vma_offset(batch), 8,\n\t\t\t\t\t\t\t0);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\terr = write_timestamp(rq, 3);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\nout:\n\t\t\ti915_request_get(rq);\n\t\t\ti915_request_add(rq);\n\n\t\t\tif (i915_request_wait(rq, 0, HZ / 5) < 0)\n\t\t\t\terr = -EIO;\n\t\t\ti915_request_put(rq);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\tcycles[i] = rq->hwsp_seqno[3] - rq->hwsp_seqno[2];\n\t\t}\n\t\ti915_vma_put(batch);\n\t\tintel_engine_pm_put(engine);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\tpr_info(\"%s: MI_BB_START cycles: %u\\n\",\n\t\t\tengine->name, trifilter(cycles));\n\t}\n\tif (perf_end(gt))\n\t\terr = -EIO;\n\n\treturn err;\n}\n\nstatic struct i915_vma *create_nop_batch(struct intel_context *ce)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\tu32 *cs;\n\tint err;\n\n\tobj = i915_gem_object_create_internal(ce->engine->i915, SZ_64K);\n\tif (IS_ERR(obj))\n\t\treturn ERR_CAST(obj);\n\n\tcs = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WB);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_put;\n\t}\n\n\tmemset(cs, 0, SZ_64K);\n\tcs[SZ_64K / sizeof(*cs) - 1] = MI_BATCH_BUFFER_END;\n\n\ti915_gem_object_flush_map(obj);\n\n\tvma = i915_vma_instance(obj, ce->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto err_unpin;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\tif (err)\n\t\tgoto err_unpin;\n\n\ti915_gem_object_unpin_map(obj);\n\treturn vma;\n\nerr_unpin:\n\ti915_gem_object_unpin_map(obj);\nerr_put:\n\ti915_gem_object_put(obj);\n\treturn ERR_PTR(err);\n}\n\nstatic int perf_mi_noop(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\tif (GRAPHICS_VER(gt->i915) < 4)  \n\t\treturn 0;\n\n\tperf_begin(gt);\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce = engine->kernel_context;\n\t\tstruct i915_vma *base, *nop;\n\t\tu32 cycles[COUNT];\n\t\tint i;\n\n\t\tif (GRAPHICS_VER(engine->i915) < 7 && engine->id != RCS0)\n\t\t\tcontinue;\n\n\t\tintel_engine_pm_get(engine);\n\n\t\tbase = create_empty_batch(ce);\n\t\tif (IS_ERR(base)) {\n\t\t\terr = PTR_ERR(base);\n\t\t\tintel_engine_pm_put(engine);\n\t\t\tbreak;\n\t\t}\n\n\t\terr = i915_vma_sync(base);\n\t\tif (err) {\n\t\t\ti915_vma_put(base);\n\t\t\tintel_engine_pm_put(engine);\n\t\t\tbreak;\n\t\t}\n\n\t\tnop = create_nop_batch(ce);\n\t\tif (IS_ERR(nop)) {\n\t\t\terr = PTR_ERR(nop);\n\t\t\ti915_vma_put(base);\n\t\t\tintel_engine_pm_put(engine);\n\t\t\tbreak;\n\t\t}\n\n\t\terr = i915_vma_sync(nop);\n\t\tif (err) {\n\t\t\ti915_vma_put(nop);\n\t\t\ti915_vma_put(base);\n\t\t\tintel_engine_pm_put(engine);\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (i = 0; i < ARRAY_SIZE(cycles); i++) {\n\t\t\tstruct i915_request *rq;\n\n\t\t\trq = i915_request_create(ce);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\terr = write_timestamp(rq, 2);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\terr = rq->engine->emit_bb_start(rq,\n\t\t\t\t\t\t\ti915_vma_offset(base), 8,\n\t\t\t\t\t\t\t0);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\terr = write_timestamp(rq, 3);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\terr = rq->engine->emit_bb_start(rq,\n\t\t\t\t\t\t\ti915_vma_offset(nop),\n\t\t\t\t\t\t\ti915_vma_size(nop),\n\t\t\t\t\t\t\t0);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\terr = write_timestamp(rq, 4);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\nout:\n\t\t\ti915_request_get(rq);\n\t\t\ti915_request_add(rq);\n\n\t\t\tif (i915_request_wait(rq, 0, HZ / 5) < 0)\n\t\t\t\terr = -EIO;\n\t\t\ti915_request_put(rq);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\tcycles[i] =\n\t\t\t\t(rq->hwsp_seqno[4] - rq->hwsp_seqno[3]) -\n\t\t\t\t(rq->hwsp_seqno[3] - rq->hwsp_seqno[2]);\n\t\t}\n\t\ti915_vma_put(nop);\n\t\ti915_vma_put(base);\n\t\tintel_engine_pm_put(engine);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\tpr_info(\"%s: 16K MI_NOOP cycles: %u\\n\",\n\t\t\tengine->name, trifilter(cycles));\n\t}\n\tif (perf_end(gt))\n\t\terr = -EIO;\n\n\treturn err;\n}\n\nint intel_engine_cs_perf_selftests(struct drm_i915_private *i915)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(perf_mi_bb_start),\n\t\tSUBTEST(perf_mi_noop),\n\t};\n\n\tif (intel_gt_is_wedged(to_gt(i915)))\n\t\treturn 0;\n\n\treturn intel_gt_live_subtests(tests, to_gt(i915));\n}\n\nstatic int intel_mmio_bases_check(void *arg)\n{\n\tint i, j;\n\n\tfor (i = 0; i < ARRAY_SIZE(intel_engines); i++) {\n\t\tconst struct engine_info *info = &intel_engines[i];\n\t\tu8 prev = U8_MAX;\n\n\t\tfor (j = 0; j < MAX_MMIO_BASES; j++) {\n\t\t\tu8 ver = info->mmio_bases[j].graphics_ver;\n\t\t\tu32 base = info->mmio_bases[j].base;\n\n\t\t\tif (ver >= prev) {\n\t\t\t\tpr_err(\"%s(%s, class:%d, instance:%d): mmio base for graphics ver %u is before the one for ver %u\\n\",\n\t\t\t\t       __func__,\n\t\t\t\t       intel_engine_class_repr(info->class),\n\t\t\t\t       info->class, info->instance,\n\t\t\t\t       prev, ver);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tif (ver == 0)\n\t\t\t\tbreak;\n\n\t\t\tif (!base) {\n\t\t\t\tpr_err(\"%s(%s, class:%d, instance:%d): invalid mmio base (%x) for graphics ver %u at entry %u\\n\",\n\t\t\t\t       __func__,\n\t\t\t\t       intel_engine_class_repr(info->class),\n\t\t\t\t       info->class, info->instance,\n\t\t\t\t       base, ver, j);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tprev = ver;\n\t\t}\n\n\t\tpr_debug(\"%s: min graphics version supported for %s%d is %u\\n\",\n\t\t\t __func__,\n\t\t\t intel_engine_class_repr(info->class),\n\t\t\t info->instance,\n\t\t\t prev);\n\t}\n\n\treturn 0;\n}\n\nint intel_engine_cs_mock_selftests(void)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(intel_mmio_bases_check),\n\t};\n\n\treturn i915_subtests(tests, NULL);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}