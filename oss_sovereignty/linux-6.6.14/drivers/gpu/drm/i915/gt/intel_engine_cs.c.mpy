{
  "module_name": "intel_engine_cs.c",
  "hash_id": "72676fad428b13e5c74b7ce9eb4e774a3aa34ae7986297268ea8003632166204",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/intel_engine_cs.c",
  "human_readable_source": "\n \n\n#include <linux/string_helpers.h>\n\n#include <drm/drm_print.h>\n\n#include \"gem/i915_gem_context.h\"\n#include \"gem/i915_gem_internal.h\"\n#include \"gt/intel_gt_print.h\"\n#include \"gt/intel_gt_regs.h\"\n\n#include \"i915_cmd_parser.h\"\n#include \"i915_drv.h\"\n#include \"i915_irq.h\"\n#include \"i915_reg.h\"\n#include \"intel_breadcrumbs.h\"\n#include \"intel_context.h\"\n#include \"intel_engine.h\"\n#include \"intel_engine_pm.h\"\n#include \"intel_engine_regs.h\"\n#include \"intel_engine_user.h\"\n#include \"intel_execlists_submission.h\"\n#include \"intel_gt.h\"\n#include \"intel_gt_mcr.h\"\n#include \"intel_gt_pm.h\"\n#include \"intel_gt_requests.h\"\n#include \"intel_lrc.h\"\n#include \"intel_lrc_reg.h\"\n#include \"intel_reset.h\"\n#include \"intel_ring.h\"\n#include \"uc/intel_guc_submission.h\"\n\n \n#define HSW_CXT_TOTAL_SIZE\t\t(17 * PAGE_SIZE)\n\n#define DEFAULT_LR_CONTEXT_RENDER_SIZE\t(22 * PAGE_SIZE)\n#define GEN8_LR_CONTEXT_RENDER_SIZE\t(20 * PAGE_SIZE)\n#define GEN9_LR_CONTEXT_RENDER_SIZE\t(22 * PAGE_SIZE)\n#define GEN11_LR_CONTEXT_RENDER_SIZE\t(14 * PAGE_SIZE)\n\n#define GEN8_LR_CONTEXT_OTHER_SIZE\t( 2 * PAGE_SIZE)\n\n#define MAX_MMIO_BASES 3\nstruct engine_info {\n\tu8 class;\n\tu8 instance;\n\t \n\tstruct engine_mmio_base {\n\t\tu32 graphics_ver : 8;\n\t\tu32 base : 24;\n\t} mmio_bases[MAX_MMIO_BASES];\n};\n\nstatic const struct engine_info intel_engines[] = {\n\t[RCS0] = {\n\t\t.class = RENDER_CLASS,\n\t\t.instance = 0,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 1, .base = RENDER_RING_BASE }\n\t\t},\n\t},\n\t[BCS0] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 0,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 6, .base = BLT_RING_BASE }\n\t\t},\n\t},\n\t[BCS1] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 1,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS1_RING_BASE }\n\t\t},\n\t},\n\t[BCS2] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 2,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS2_RING_BASE }\n\t\t},\n\t},\n\t[BCS3] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 3,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS3_RING_BASE }\n\t\t},\n\t},\n\t[BCS4] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 4,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS4_RING_BASE }\n\t\t},\n\t},\n\t[BCS5] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 5,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS5_RING_BASE }\n\t\t},\n\t},\n\t[BCS6] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 6,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS6_RING_BASE }\n\t\t},\n\t},\n\t[BCS7] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 7,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS7_RING_BASE }\n\t\t},\n\t},\n\t[BCS8] = {\n\t\t.class = COPY_ENGINE_CLASS,\n\t\t.instance = 8,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHPC_BCS8_RING_BASE }\n\t\t},\n\t},\n\t[VCS0] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 0,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 11, .base = GEN11_BSD_RING_BASE },\n\t\t\t{ .graphics_ver = 6, .base = GEN6_BSD_RING_BASE },\n\t\t\t{ .graphics_ver = 4, .base = BSD_RING_BASE }\n\t\t},\n\t},\n\t[VCS1] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 1,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 11, .base = GEN11_BSD2_RING_BASE },\n\t\t\t{ .graphics_ver = 8, .base = GEN8_BSD2_RING_BASE }\n\t\t},\n\t},\n\t[VCS2] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 2,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 11, .base = GEN11_BSD3_RING_BASE }\n\t\t},\n\t},\n\t[VCS3] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 3,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 11, .base = GEN11_BSD4_RING_BASE }\n\t\t},\n\t},\n\t[VCS4] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 4,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHP_BSD5_RING_BASE }\n\t\t},\n\t},\n\t[VCS5] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 5,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHP_BSD6_RING_BASE }\n\t\t},\n\t},\n\t[VCS6] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 6,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHP_BSD7_RING_BASE }\n\t\t},\n\t},\n\t[VCS7] = {\n\t\t.class = VIDEO_DECODE_CLASS,\n\t\t.instance = 7,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHP_BSD8_RING_BASE }\n\t\t},\n\t},\n\t[VECS0] = {\n\t\t.class = VIDEO_ENHANCEMENT_CLASS,\n\t\t.instance = 0,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 11, .base = GEN11_VEBOX_RING_BASE },\n\t\t\t{ .graphics_ver = 7, .base = VEBOX_RING_BASE }\n\t\t},\n\t},\n\t[VECS1] = {\n\t\t.class = VIDEO_ENHANCEMENT_CLASS,\n\t\t.instance = 1,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 11, .base = GEN11_VEBOX2_RING_BASE }\n\t\t},\n\t},\n\t[VECS2] = {\n\t\t.class = VIDEO_ENHANCEMENT_CLASS,\n\t\t.instance = 2,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHP_VEBOX3_RING_BASE }\n\t\t},\n\t},\n\t[VECS3] = {\n\t\t.class = VIDEO_ENHANCEMENT_CLASS,\n\t\t.instance = 3,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = XEHP_VEBOX4_RING_BASE }\n\t\t},\n\t},\n\t[CCS0] = {\n\t\t.class = COMPUTE_CLASS,\n\t\t.instance = 0,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = GEN12_COMPUTE0_RING_BASE }\n\t\t}\n\t},\n\t[CCS1] = {\n\t\t.class = COMPUTE_CLASS,\n\t\t.instance = 1,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = GEN12_COMPUTE1_RING_BASE }\n\t\t}\n\t},\n\t[CCS2] = {\n\t\t.class = COMPUTE_CLASS,\n\t\t.instance = 2,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = GEN12_COMPUTE2_RING_BASE }\n\t\t}\n\t},\n\t[CCS3] = {\n\t\t.class = COMPUTE_CLASS,\n\t\t.instance = 3,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = GEN12_COMPUTE3_RING_BASE }\n\t\t}\n\t},\n\t[GSC0] = {\n\t\t.class = OTHER_CLASS,\n\t\t.instance = OTHER_GSC_INSTANCE,\n\t\t.mmio_bases = {\n\t\t\t{ .graphics_ver = 12, .base = MTL_GSC_RING_BASE }\n\t\t}\n\t},\n};\n\n \nu32 intel_engine_context_size(struct intel_gt *gt, u8 class)\n{\n\tstruct intel_uncore *uncore = gt->uncore;\n\tu32 cxt_size;\n\n\tBUILD_BUG_ON(I915_GTT_PAGE_SIZE != PAGE_SIZE);\n\n\tswitch (class) {\n\tcase COMPUTE_CLASS:\n\t\tfallthrough;\n\tcase RENDER_CLASS:\n\t\tswitch (GRAPHICS_VER(gt->i915)) {\n\t\tdefault:\n\t\t\tMISSING_CASE(GRAPHICS_VER(gt->i915));\n\t\t\treturn DEFAULT_LR_CONTEXT_RENDER_SIZE;\n\t\tcase 12:\n\t\tcase 11:\n\t\t\treturn GEN11_LR_CONTEXT_RENDER_SIZE;\n\t\tcase 9:\n\t\t\treturn GEN9_LR_CONTEXT_RENDER_SIZE;\n\t\tcase 8:\n\t\t\treturn GEN8_LR_CONTEXT_RENDER_SIZE;\n\t\tcase 7:\n\t\t\tif (IS_HASWELL(gt->i915))\n\t\t\t\treturn HSW_CXT_TOTAL_SIZE;\n\n\t\t\tcxt_size = intel_uncore_read(uncore, GEN7_CXT_SIZE);\n\t\t\treturn round_up(GEN7_CXT_TOTAL_SIZE(cxt_size) * 64,\n\t\t\t\t\tPAGE_SIZE);\n\t\tcase 6:\n\t\t\tcxt_size = intel_uncore_read(uncore, CXT_SIZE);\n\t\t\treturn round_up(GEN6_CXT_TOTAL_SIZE(cxt_size) * 64,\n\t\t\t\t\tPAGE_SIZE);\n\t\tcase 5:\n\t\tcase 4:\n\t\t\t \n\t\t\tcxt_size = intel_uncore_read(uncore, CXT_SIZE) + 1;\n\t\t\tdrm_dbg(&gt->i915->drm,\n\t\t\t\t\"graphics_ver = %d CXT_SIZE = %d bytes [0x%08x]\\n\",\n\t\t\t\tGRAPHICS_VER(gt->i915), cxt_size * 64,\n\t\t\t\tcxt_size - 1);\n\t\t\treturn round_up(cxt_size * 64, PAGE_SIZE);\n\t\tcase 3:\n\t\tcase 2:\n\t\t \n\t\tcase 1:\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tMISSING_CASE(class);\n\t\tfallthrough;\n\tcase VIDEO_DECODE_CLASS:\n\tcase VIDEO_ENHANCEMENT_CLASS:\n\tcase COPY_ENGINE_CLASS:\n\tcase OTHER_CLASS:\n\t\tif (GRAPHICS_VER(gt->i915) < 8)\n\t\t\treturn 0;\n\t\treturn GEN8_LR_CONTEXT_OTHER_SIZE;\n\t}\n}\n\nstatic u32 __engine_mmio_base(struct drm_i915_private *i915,\n\t\t\t      const struct engine_mmio_base *bases)\n{\n\tint i;\n\n\tfor (i = 0; i < MAX_MMIO_BASES; i++)\n\t\tif (GRAPHICS_VER(i915) >= bases[i].graphics_ver)\n\t\t\tbreak;\n\n\tGEM_BUG_ON(i == MAX_MMIO_BASES);\n\tGEM_BUG_ON(!bases[i].base);\n\n\treturn bases[i].base;\n}\n\nstatic void __sprint_engine_name(struct intel_engine_cs *engine)\n{\n\t \n\tGEM_WARN_ON(snprintf(engine->name, sizeof(engine->name), \"%s'%u\",\n\t\t\t     intel_engine_class_repr(engine->class),\n\t\t\t     engine->instance) >= sizeof(engine->name));\n}\n\nvoid intel_engine_set_hwsp_writemask(struct intel_engine_cs *engine, u32 mask)\n{\n\t \n\tif (GRAPHICS_VER(engine->i915) < 6 && engine->class != RENDER_CLASS)\n\t\treturn;\n\n\tif (GRAPHICS_VER(engine->i915) >= 3)\n\t\tENGINE_WRITE(engine, RING_HWSTAM, mask);\n\telse\n\t\tENGINE_WRITE16(engine, RING_HWSTAM, mask);\n}\n\nstatic void intel_engine_sanitize_mmio(struct intel_engine_cs *engine)\n{\n\t \n\tintel_engine_set_hwsp_writemask(engine, ~0u);\n}\n\nstatic void nop_irq_handler(struct intel_engine_cs *engine, u16 iir)\n{\n\tGEM_DEBUG_WARN_ON(iir);\n}\n\nstatic u32 get_reset_domain(u8 ver, enum intel_engine_id id)\n{\n\tu32 reset_domain;\n\n\tif (ver >= 11) {\n\t\tstatic const u32 engine_reset_domains[] = {\n\t\t\t[RCS0]  = GEN11_GRDOM_RENDER,\n\t\t\t[BCS0]  = GEN11_GRDOM_BLT,\n\t\t\t[BCS1]  = XEHPC_GRDOM_BLT1,\n\t\t\t[BCS2]  = XEHPC_GRDOM_BLT2,\n\t\t\t[BCS3]  = XEHPC_GRDOM_BLT3,\n\t\t\t[BCS4]  = XEHPC_GRDOM_BLT4,\n\t\t\t[BCS5]  = XEHPC_GRDOM_BLT5,\n\t\t\t[BCS6]  = XEHPC_GRDOM_BLT6,\n\t\t\t[BCS7]  = XEHPC_GRDOM_BLT7,\n\t\t\t[BCS8]  = XEHPC_GRDOM_BLT8,\n\t\t\t[VCS0]  = GEN11_GRDOM_MEDIA,\n\t\t\t[VCS1]  = GEN11_GRDOM_MEDIA2,\n\t\t\t[VCS2]  = GEN11_GRDOM_MEDIA3,\n\t\t\t[VCS3]  = GEN11_GRDOM_MEDIA4,\n\t\t\t[VCS4]  = GEN11_GRDOM_MEDIA5,\n\t\t\t[VCS5]  = GEN11_GRDOM_MEDIA6,\n\t\t\t[VCS6]  = GEN11_GRDOM_MEDIA7,\n\t\t\t[VCS7]  = GEN11_GRDOM_MEDIA8,\n\t\t\t[VECS0] = GEN11_GRDOM_VECS,\n\t\t\t[VECS1] = GEN11_GRDOM_VECS2,\n\t\t\t[VECS2] = GEN11_GRDOM_VECS3,\n\t\t\t[VECS3] = GEN11_GRDOM_VECS4,\n\t\t\t[CCS0]  = GEN11_GRDOM_RENDER,\n\t\t\t[CCS1]  = GEN11_GRDOM_RENDER,\n\t\t\t[CCS2]  = GEN11_GRDOM_RENDER,\n\t\t\t[CCS3]  = GEN11_GRDOM_RENDER,\n\t\t\t[GSC0]  = GEN12_GRDOM_GSC,\n\t\t};\n\t\tGEM_BUG_ON(id >= ARRAY_SIZE(engine_reset_domains) ||\n\t\t\t   !engine_reset_domains[id]);\n\t\treset_domain = engine_reset_domains[id];\n\t} else {\n\t\tstatic const u32 engine_reset_domains[] = {\n\t\t\t[RCS0]  = GEN6_GRDOM_RENDER,\n\t\t\t[BCS0]  = GEN6_GRDOM_BLT,\n\t\t\t[VCS0]  = GEN6_GRDOM_MEDIA,\n\t\t\t[VCS1]  = GEN8_GRDOM_MEDIA2,\n\t\t\t[VECS0] = GEN6_GRDOM_VECS,\n\t\t};\n\t\tGEM_BUG_ON(id >= ARRAY_SIZE(engine_reset_domains) ||\n\t\t\t   !engine_reset_domains[id]);\n\t\treset_domain = engine_reset_domains[id];\n\t}\n\n\treturn reset_domain;\n}\n\nstatic int intel_engine_setup(struct intel_gt *gt, enum intel_engine_id id,\n\t\t\t      u8 logical_instance)\n{\n\tconst struct engine_info *info = &intel_engines[id];\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct intel_engine_cs *engine;\n\tu8 guc_class;\n\n\tBUILD_BUG_ON(MAX_ENGINE_CLASS >= BIT(GEN11_ENGINE_CLASS_WIDTH));\n\tBUILD_BUG_ON(MAX_ENGINE_INSTANCE >= BIT(GEN11_ENGINE_INSTANCE_WIDTH));\n\tBUILD_BUG_ON(I915_MAX_VCS > (MAX_ENGINE_INSTANCE + 1));\n\tBUILD_BUG_ON(I915_MAX_VECS > (MAX_ENGINE_INSTANCE + 1));\n\n\tif (GEM_DEBUG_WARN_ON(id >= ARRAY_SIZE(gt->engine)))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(info->class > MAX_ENGINE_CLASS))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(info->instance > MAX_ENGINE_INSTANCE))\n\t\treturn -EINVAL;\n\n\tif (GEM_DEBUG_WARN_ON(gt->engine_class[info->class][info->instance]))\n\t\treturn -EINVAL;\n\n\tengine = kzalloc(sizeof(*engine), GFP_KERNEL);\n\tif (!engine)\n\t\treturn -ENOMEM;\n\n\tBUILD_BUG_ON(BITS_PER_TYPE(engine->mask) < I915_NUM_ENGINES);\n\n\tINIT_LIST_HEAD(&engine->pinned_contexts_list);\n\tengine->id = id;\n\tengine->legacy_idx = INVALID_ENGINE;\n\tengine->mask = BIT(id);\n\tengine->reset_domain = get_reset_domain(GRAPHICS_VER(gt->i915),\n\t\t\t\t\t\tid);\n\tengine->i915 = i915;\n\tengine->gt = gt;\n\tengine->uncore = gt->uncore;\n\tguc_class = engine_class_to_guc_class(info->class);\n\tengine->guc_id = MAKE_GUC_ID(guc_class, info->instance);\n\tengine->mmio_base = __engine_mmio_base(i915, info->mmio_bases);\n\n\tengine->irq_handler = nop_irq_handler;\n\n\tengine->class = info->class;\n\tengine->instance = info->instance;\n\tengine->logical_mask = BIT(logical_instance);\n\t__sprint_engine_name(engine);\n\n\tif ((engine->class == COMPUTE_CLASS && !RCS_MASK(engine->gt) &&\n\t     __ffs(CCS_MASK(engine->gt)) == engine->instance) ||\n\t     engine->class == RENDER_CLASS)\n\t\tengine->flags |= I915_ENGINE_FIRST_RENDER_COMPUTE;\n\n\t \n\tif (engine->class == RENDER_CLASS || engine->class == COMPUTE_CLASS) {\n\t\tengine->flags |= I915_ENGINE_HAS_RCS_REG_STATE;\n\t\tengine->flags |= I915_ENGINE_HAS_EU_PRIORITY;\n\t}\n\n\tengine->props.heartbeat_interval_ms =\n\t\tCONFIG_DRM_I915_HEARTBEAT_INTERVAL;\n\tengine->props.max_busywait_duration_ns =\n\t\tCONFIG_DRM_I915_MAX_REQUEST_BUSYWAIT;\n\tengine->props.preempt_timeout_ms =\n\t\tCONFIG_DRM_I915_PREEMPT_TIMEOUT;\n\tengine->props.stop_timeout_ms =\n\t\tCONFIG_DRM_I915_STOP_TIMEOUT;\n\tengine->props.timeslice_duration_ms =\n\t\tCONFIG_DRM_I915_TIMESLICE_DURATION;\n\n\t \n\tif (GRAPHICS_VER(i915) == 12 && (engine->flags & I915_ENGINE_HAS_RCS_REG_STATE))\n\t\tengine->props.preempt_timeout_ms = CONFIG_DRM_I915_PREEMPT_TIMEOUT_COMPUTE;\n\n\t \n#define CLAMP_PROP(field) \\\n\tdo { \\\n\t\tu64 clamp = intel_clamp_##field(engine, engine->props.field); \\\n\t\tif (clamp != engine->props.field) { \\\n\t\t\tdrm_notice(&engine->i915->drm, \\\n\t\t\t\t   \"Warning, clamping %s to %lld to prevent overflow\\n\", \\\n\t\t\t\t   #field, clamp); \\\n\t\t\tengine->props.field = clamp; \\\n\t\t} \\\n\t} while (0)\n\n\tCLAMP_PROP(heartbeat_interval_ms);\n\tCLAMP_PROP(max_busywait_duration_ns);\n\tCLAMP_PROP(preempt_timeout_ms);\n\tCLAMP_PROP(stop_timeout_ms);\n\tCLAMP_PROP(timeslice_duration_ms);\n\n#undef CLAMP_PROP\n\n\tengine->defaults = engine->props;  \n\n\tengine->context_size = intel_engine_context_size(gt, engine->class);\n\tif (WARN_ON(engine->context_size > BIT(20)))\n\t\tengine->context_size = 0;\n\tif (engine->context_size)\n\t\tDRIVER_CAPS(i915)->has_logical_contexts = true;\n\n\tewma__engine_latency_init(&engine->latency);\n\n\tATOMIC_INIT_NOTIFIER_HEAD(&engine->context_status_notifier);\n\n\t \n\tintel_engine_sanitize_mmio(engine);\n\n\tgt->engine_class[info->class][info->instance] = engine;\n\tgt->engine[id] = engine;\n\n\treturn 0;\n}\n\nu64 intel_clamp_heartbeat_interval_ms(struct intel_engine_cs *engine, u64 value)\n{\n\tvalue = min_t(u64, value, jiffies_to_msecs(MAX_SCHEDULE_TIMEOUT));\n\n\treturn value;\n}\n\nu64 intel_clamp_max_busywait_duration_ns(struct intel_engine_cs *engine, u64 value)\n{\n\tvalue = min(value, jiffies_to_nsecs(2));\n\n\treturn value;\n}\n\nu64 intel_clamp_preempt_timeout_ms(struct intel_engine_cs *engine, u64 value)\n{\n\t \n\tif (intel_guc_submission_is_wanted(&engine->gt->uc.guc))\n\t\tvalue = min_t(u64, value, guc_policy_max_preempt_timeout_ms());\n\n\tvalue = min_t(u64, value, jiffies_to_msecs(MAX_SCHEDULE_TIMEOUT));\n\n\treturn value;\n}\n\nu64 intel_clamp_stop_timeout_ms(struct intel_engine_cs *engine, u64 value)\n{\n\tvalue = min_t(u64, value, jiffies_to_msecs(MAX_SCHEDULE_TIMEOUT));\n\n\treturn value;\n}\n\nu64 intel_clamp_timeslice_duration_ms(struct intel_engine_cs *engine, u64 value)\n{\n\t \n\tif (intel_guc_submission_is_wanted(&engine->gt->uc.guc))\n\t\tvalue = min_t(u64, value, guc_policy_max_exec_quantum_ms());\n\n\tvalue = min_t(u64, value, jiffies_to_msecs(MAX_SCHEDULE_TIMEOUT));\n\n\treturn value;\n}\n\nstatic void __setup_engine_capabilities(struct intel_engine_cs *engine)\n{\n\tstruct drm_i915_private *i915 = engine->i915;\n\n\tif (engine->class == VIDEO_DECODE_CLASS) {\n\t\t \n\t\tif (GRAPHICS_VER(i915) >= 11 ||\n\t\t    (GRAPHICS_VER(i915) >= 9 && engine->instance == 0))\n\t\t\tengine->uabi_capabilities |=\n\t\t\t\tI915_VIDEO_CLASS_CAPABILITY_HEVC;\n\n\t\t \n\t\tif ((GRAPHICS_VER(i915) >= 11 &&\n\t\t     (engine->gt->info.vdbox_sfc_access &\n\t\t      BIT(engine->instance))) ||\n\t\t    (GRAPHICS_VER(i915) >= 9 && engine->instance == 0))\n\t\t\tengine->uabi_capabilities |=\n\t\t\t\tI915_VIDEO_AND_ENHANCE_CLASS_CAPABILITY_SFC;\n\t} else if (engine->class == VIDEO_ENHANCEMENT_CLASS) {\n\t\tif (GRAPHICS_VER(i915) >= 9 &&\n\t\t    engine->gt->info.sfc_mask & BIT(engine->instance))\n\t\t\tengine->uabi_capabilities |=\n\t\t\t\tI915_VIDEO_AND_ENHANCE_CLASS_CAPABILITY_SFC;\n\t}\n}\n\nstatic void intel_setup_engine_capabilities(struct intel_gt *gt)\n{\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\tfor_each_engine(engine, gt, id)\n\t\t__setup_engine_capabilities(engine);\n}\n\n \nvoid intel_engines_release(struct intel_gt *gt)\n{\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\tGEM_BUG_ON(intel_gt_pm_is_awake(gt));\n\tif (!INTEL_INFO(gt->i915)->gpu_reset_clobbers_display)\n\t\t__intel_gt_reset(gt, ALL_ENGINES);\n\n\t \n\tfor_each_engine(engine, gt, id) {\n\t\tif (!engine->release)\n\t\t\tcontinue;\n\n\t\tintel_wakeref_wait_for_idle(&engine->wakeref);\n\t\tGEM_BUG_ON(intel_engine_pm_is_awake(engine));\n\n\t\tengine->release(engine);\n\t\tengine->release = NULL;\n\n\t\tmemset(&engine->reset, 0, sizeof(engine->reset));\n\t}\n}\n\nvoid intel_engine_free_request_pool(struct intel_engine_cs *engine)\n{\n\tif (!engine->request_pool)\n\t\treturn;\n\n\tkmem_cache_free(i915_request_slab_cache(), engine->request_pool);\n}\n\nvoid intel_engines_free(struct intel_gt *gt)\n{\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\trcu_barrier();\n\n\tfor_each_engine(engine, gt, id) {\n\t\tintel_engine_free_request_pool(engine);\n\t\tkfree(engine);\n\t\tgt->engine[id] = NULL;\n\t}\n}\n\nstatic\nbool gen11_vdbox_has_sfc(struct intel_gt *gt,\n\t\t\t unsigned int physical_vdbox,\n\t\t\t unsigned int logical_vdbox, u16 vdbox_mask)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\n\t \n\tif ((gt->info.sfc_mask & BIT(physical_vdbox / 2)) == 0)\n\t\treturn false;\n\telse if (MEDIA_VER(i915) >= 12)\n\t\treturn (physical_vdbox % 2 == 0) ||\n\t\t\t!(BIT(physical_vdbox - 1) & vdbox_mask);\n\telse if (MEDIA_VER(i915) == 11)\n\t\treturn logical_vdbox % 2 == 0;\n\n\treturn false;\n}\n\nstatic void engine_mask_apply_media_fuses(struct intel_gt *gt)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tunsigned int logical_vdbox = 0;\n\tunsigned int i;\n\tu32 media_fuse, fuse1;\n\tu16 vdbox_mask;\n\tu16 vebox_mask;\n\n\tif (MEDIA_VER(gt->i915) < 11)\n\t\treturn;\n\n\t \n\tmedia_fuse = intel_uncore_read(gt->uncore, GEN11_GT_VEBOX_VDBOX_DISABLE);\n\tif (MEDIA_VER_FULL(i915) < IP_VER(12, 50))\n\t\tmedia_fuse = ~media_fuse;\n\n\tvdbox_mask = media_fuse & GEN11_GT_VDBOX_DISABLE_MASK;\n\tvebox_mask = (media_fuse & GEN11_GT_VEBOX_DISABLE_MASK) >>\n\t\t      GEN11_GT_VEBOX_DISABLE_SHIFT;\n\n\tif (MEDIA_VER_FULL(i915) >= IP_VER(12, 50)) {\n\t\tfuse1 = intel_uncore_read(gt->uncore, HSW_PAVP_FUSE1);\n\t\tgt->info.sfc_mask = REG_FIELD_GET(XEHP_SFC_ENABLE_MASK, fuse1);\n\t} else {\n\t\tgt->info.sfc_mask = ~0;\n\t}\n\n\tfor (i = 0; i < I915_MAX_VCS; i++) {\n\t\tif (!HAS_ENGINE(gt, _VCS(i))) {\n\t\t\tvdbox_mask &= ~BIT(i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!(BIT(i) & vdbox_mask)) {\n\t\t\tgt->info.engine_mask &= ~BIT(_VCS(i));\n\t\t\tdrm_dbg(&i915->drm, \"vcs%u fused off\\n\", i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (gen11_vdbox_has_sfc(gt, i, logical_vdbox, vdbox_mask))\n\t\t\tgt->info.vdbox_sfc_access |= BIT(i);\n\t\tlogical_vdbox++;\n\t}\n\tdrm_dbg(&i915->drm, \"vdbox enable: %04x, instances: %04lx\\n\",\n\t\tvdbox_mask, VDBOX_MASK(gt));\n\tGEM_BUG_ON(vdbox_mask != VDBOX_MASK(gt));\n\n\tfor (i = 0; i < I915_MAX_VECS; i++) {\n\t\tif (!HAS_ENGINE(gt, _VECS(i))) {\n\t\t\tvebox_mask &= ~BIT(i);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!(BIT(i) & vebox_mask)) {\n\t\t\tgt->info.engine_mask &= ~BIT(_VECS(i));\n\t\t\tdrm_dbg(&i915->drm, \"vecs%u fused off\\n\", i);\n\t\t}\n\t}\n\tdrm_dbg(&i915->drm, \"vebox enable: %04x, instances: %04lx\\n\",\n\t\tvebox_mask, VEBOX_MASK(gt));\n\tGEM_BUG_ON(vebox_mask != VEBOX_MASK(gt));\n}\n\nstatic void engine_mask_apply_compute_fuses(struct intel_gt *gt)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct intel_gt_info *info = &gt->info;\n\tint ss_per_ccs = info->sseu.max_subslices / I915_MAX_CCS;\n\tunsigned long ccs_mask;\n\tunsigned int i;\n\n\tif (GRAPHICS_VER(i915) < 11)\n\t\treturn;\n\n\tif (hweight32(CCS_MASK(gt)) <= 1)\n\t\treturn;\n\n\tccs_mask = intel_slicemask_from_xehp_dssmask(info->sseu.compute_subslice_mask,\n\t\t\t\t\t\t     ss_per_ccs);\n\t \n\tfor_each_clear_bit(i, &ccs_mask, I915_MAX_CCS) {\n\t\tinfo->engine_mask &= ~BIT(_CCS(i));\n\t\tdrm_dbg(&i915->drm, \"ccs%u fused off\\n\", i);\n\t}\n}\n\nstatic void engine_mask_apply_copy_fuses(struct intel_gt *gt)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct intel_gt_info *info = &gt->info;\n\tunsigned long meml3_mask;\n\tunsigned long quad;\n\n\tif (!(GRAPHICS_VER_FULL(i915) >= IP_VER(12, 60) &&\n\t      GRAPHICS_VER_FULL(i915) < IP_VER(12, 70)))\n\t\treturn;\n\n\tmeml3_mask = intel_uncore_read(gt->uncore, GEN10_MIRROR_FUSE3);\n\tmeml3_mask = REG_FIELD_GET(GEN12_MEML3_EN_MASK, meml3_mask);\n\n\t \n\tfor_each_clear_bit(quad, &meml3_mask, GEN12_MAX_MSLICES) {\n\t\tunsigned int instance = quad * 2 + 1;\n\t\tintel_engine_mask_t mask = GENMASK(_BCS(instance + 1),\n\t\t\t\t\t\t   _BCS(instance));\n\n\t\tif (mask & info->engine_mask) {\n\t\t\tdrm_dbg(&i915->drm, \"bcs%u fused off\\n\", instance);\n\t\t\tdrm_dbg(&i915->drm, \"bcs%u fused off\\n\", instance + 1);\n\n\t\t\tinfo->engine_mask &= ~mask;\n\t\t}\n\t}\n}\n\n \nstatic intel_engine_mask_t init_engine_mask(struct intel_gt *gt)\n{\n\tstruct intel_gt_info *info = &gt->info;\n\n\tGEM_BUG_ON(!info->engine_mask);\n\n\tengine_mask_apply_media_fuses(gt);\n\tengine_mask_apply_compute_fuses(gt);\n\tengine_mask_apply_copy_fuses(gt);\n\n\t \n\tif (__HAS_ENGINE(info->engine_mask, GSC0) && !intel_uc_wants_gsc_uc(&gt->uc)) {\n\t\tdrm_notice(&gt->i915->drm,\n\t\t\t   \"No GSC FW selected, disabling GSC CS and media C6\\n\");\n\t\tinfo->engine_mask &= ~BIT(GSC0);\n\t}\n\n\treturn info->engine_mask;\n}\n\nstatic void populate_logical_ids(struct intel_gt *gt, u8 *logical_ids,\n\t\t\t\t u8 class, const u8 *map, u8 num_instances)\n{\n\tint i, j;\n\tu8 current_logical_id = 0;\n\n\tfor (j = 0; j < num_instances; ++j) {\n\t\tfor (i = 0; i < ARRAY_SIZE(intel_engines); ++i) {\n\t\t\tif (!HAS_ENGINE(gt, i) ||\n\t\t\t    intel_engines[i].class != class)\n\t\t\t\tcontinue;\n\n\t\t\tif (intel_engines[i].instance == map[j]) {\n\t\t\t\tlogical_ids[intel_engines[i].instance] =\n\t\t\t\t\tcurrent_logical_id++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void setup_logical_ids(struct intel_gt *gt, u8 *logical_ids, u8 class)\n{\n\t \n\tif (MEDIA_VER(gt->i915) >= 11 && class == VIDEO_DECODE_CLASS) {\n\t\tconst u8 map[] = { 0, 2, 4, 6, 1, 3, 5, 7 };\n\n\t\tpopulate_logical_ids(gt, logical_ids, class,\n\t\t\t\t     map, ARRAY_SIZE(map));\n\t} else {\n\t\tint i;\n\t\tu8 map[MAX_ENGINE_INSTANCE + 1];\n\n\t\tfor (i = 0; i < MAX_ENGINE_INSTANCE + 1; ++i)\n\t\t\tmap[i] = i;\n\t\tpopulate_logical_ids(gt, logical_ids, class,\n\t\t\t\t     map, ARRAY_SIZE(map));\n\t}\n}\n\n \nint intel_engines_init_mmio(struct intel_gt *gt)\n{\n\tstruct drm_i915_private *i915 = gt->i915;\n\tconst unsigned int engine_mask = init_engine_mask(gt);\n\tunsigned int mask = 0;\n\tunsigned int i, class;\n\tu8 logical_ids[MAX_ENGINE_INSTANCE + 1];\n\tint err;\n\n\tdrm_WARN_ON(&i915->drm, engine_mask == 0);\n\tdrm_WARN_ON(&i915->drm, engine_mask &\n\t\t    GENMASK(BITS_PER_TYPE(mask) - 1, I915_NUM_ENGINES));\n\n\tif (i915_inject_probe_failure(i915))\n\t\treturn -ENODEV;\n\n\tfor (class = 0; class < MAX_ENGINE_CLASS + 1; ++class) {\n\t\tsetup_logical_ids(gt, logical_ids, class);\n\n\t\tfor (i = 0; i < ARRAY_SIZE(intel_engines); ++i) {\n\t\t\tu8 instance = intel_engines[i].instance;\n\n\t\t\tif (intel_engines[i].class != class ||\n\t\t\t    !HAS_ENGINE(gt, i))\n\t\t\t\tcontinue;\n\n\t\t\terr = intel_engine_setup(gt, i,\n\t\t\t\t\t\t logical_ids[instance]);\n\t\t\tif (err)\n\t\t\t\tgoto cleanup;\n\n\t\t\tmask |= BIT(i);\n\t\t}\n\t}\n\n\t \n\tif (drm_WARN_ON(&i915->drm, mask != engine_mask))\n\t\tgt->info.engine_mask = mask;\n\n\tgt->info.num_engines = hweight32(mask);\n\n\tintel_gt_check_and_clear_faults(gt);\n\n\tintel_setup_engine_capabilities(gt);\n\n\tintel_uncore_prune_engine_fw_domains(gt->uncore, gt);\n\n\treturn 0;\n\ncleanup:\n\tintel_engines_free(gt);\n\treturn err;\n}\n\nvoid intel_engine_init_execlists(struct intel_engine_cs *engine)\n{\n\tstruct intel_engine_execlists * const execlists = &engine->execlists;\n\n\texeclists->port_mask = 1;\n\tGEM_BUG_ON(!is_power_of_2(execlists_num_ports(execlists)));\n\tGEM_BUG_ON(execlists_num_ports(execlists) > EXECLIST_MAX_PORTS);\n\n\tmemset(execlists->pending, 0, sizeof(execlists->pending));\n\texeclists->active =\n\t\tmemset(execlists->inflight, 0, sizeof(execlists->inflight));\n}\n\nstatic void cleanup_status_page(struct intel_engine_cs *engine)\n{\n\tstruct i915_vma *vma;\n\n\t \n\tintel_engine_set_hwsp_writemask(engine, ~0u);\n\n\tvma = fetch_and_zero(&engine->status_page.vma);\n\tif (!vma)\n\t\treturn;\n\n\tif (!HWS_NEEDS_PHYSICAL(engine->i915))\n\t\ti915_vma_unpin(vma);\n\n\ti915_gem_object_unpin_map(vma->obj);\n\ti915_gem_object_put(vma->obj);\n}\n\nstatic int pin_ggtt_status_page(struct intel_engine_cs *engine,\n\t\t\t\tstruct i915_gem_ww_ctx *ww,\n\t\t\t\tstruct i915_vma *vma)\n{\n\tunsigned int flags;\n\n\tif (!HAS_LLC(engine->i915) && i915_ggtt_has_aperture(engine->gt->ggtt))\n\t\t \n\t\tflags = PIN_MAPPABLE;\n\telse\n\t\tflags = PIN_HIGH;\n\n\treturn i915_ggtt_pin(vma, ww, 0, flags);\n}\n\nstatic int init_status_page(struct intel_engine_cs *engine)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_gem_ww_ctx ww;\n\tstruct i915_vma *vma;\n\tvoid *vaddr;\n\tint ret;\n\n\tINIT_LIST_HEAD(&engine->status_page.timelines);\n\n\t \n\tobj = i915_gem_object_create_internal(engine->i915, PAGE_SIZE);\n\tif (IS_ERR(obj)) {\n\t\tdrm_err(&engine->i915->drm,\n\t\t\t\"Failed to allocate status page\\n\");\n\t\treturn PTR_ERR(obj);\n\t}\n\n\ti915_gem_object_set_cache_coherency(obj, I915_CACHE_LLC);\n\n\tvma = i915_vma_instance(obj, &engine->gt->ggtt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\tret = PTR_ERR(vma);\n\t\tgoto err_put;\n\t}\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\tret = i915_gem_object_lock(obj, &ww);\n\tif (!ret && !HWS_NEEDS_PHYSICAL(engine->i915))\n\t\tret = pin_ggtt_status_page(engine, &ww, vma);\n\tif (ret)\n\t\tgoto err;\n\n\tvaddr = i915_gem_object_pin_map(obj, I915_MAP_WB);\n\tif (IS_ERR(vaddr)) {\n\t\tret = PTR_ERR(vaddr);\n\t\tgoto err_unpin;\n\t}\n\n\tengine->status_page.addr = memset(vaddr, 0, PAGE_SIZE);\n\tengine->status_page.vma = vma;\n\nerr_unpin:\n\tif (ret)\n\t\ti915_vma_unpin(vma);\nerr:\n\tif (ret == -EDEADLK) {\n\t\tret = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!ret)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\nerr_put:\n\tif (ret)\n\t\ti915_gem_object_put(obj);\n\treturn ret;\n}\n\nstatic int intel_engine_init_tlb_invalidation(struct intel_engine_cs *engine)\n{\n\tstatic const union intel_engine_tlb_inv_reg gen8_regs[] = {\n\t\t[RENDER_CLASS].reg\t\t= GEN8_RTCR,\n\t\t[VIDEO_DECODE_CLASS].reg\t= GEN8_M1TCR,  \n\t\t[VIDEO_ENHANCEMENT_CLASS].reg\t= GEN8_VTCR,\n\t\t[COPY_ENGINE_CLASS].reg\t\t= GEN8_BTCR,\n\t};\n\tstatic const union intel_engine_tlb_inv_reg gen12_regs[] = {\n\t\t[RENDER_CLASS].reg\t\t= GEN12_GFX_TLB_INV_CR,\n\t\t[VIDEO_DECODE_CLASS].reg\t= GEN12_VD_TLB_INV_CR,\n\t\t[VIDEO_ENHANCEMENT_CLASS].reg\t= GEN12_VE_TLB_INV_CR,\n\t\t[COPY_ENGINE_CLASS].reg\t\t= GEN12_BLT_TLB_INV_CR,\n\t\t[COMPUTE_CLASS].reg\t\t= GEN12_COMPCTX_TLB_INV_CR,\n\t};\n\tstatic const union intel_engine_tlb_inv_reg xehp_regs[] = {\n\t\t[RENDER_CLASS].mcr_reg\t\t  = XEHP_GFX_TLB_INV_CR,\n\t\t[VIDEO_DECODE_CLASS].mcr_reg\t  = XEHP_VD_TLB_INV_CR,\n\t\t[VIDEO_ENHANCEMENT_CLASS].mcr_reg = XEHP_VE_TLB_INV_CR,\n\t\t[COPY_ENGINE_CLASS].mcr_reg\t  = XEHP_BLT_TLB_INV_CR,\n\t\t[COMPUTE_CLASS].mcr_reg\t\t  = XEHP_COMPCTX_TLB_INV_CR,\n\t};\n\tstatic const union intel_engine_tlb_inv_reg xelpmp_regs[] = {\n\t\t[VIDEO_DECODE_CLASS].reg\t  = GEN12_VD_TLB_INV_CR,\n\t\t[VIDEO_ENHANCEMENT_CLASS].reg     = GEN12_VE_TLB_INV_CR,\n\t\t[OTHER_CLASS].reg\t\t  = XELPMP_GSC_TLB_INV_CR,\n\t};\n\tstruct drm_i915_private *i915 = engine->i915;\n\tconst unsigned int instance = engine->instance;\n\tconst unsigned int class = engine->class;\n\tconst union intel_engine_tlb_inv_reg *regs;\n\tunion intel_engine_tlb_inv_reg reg;\n\tunsigned int num = 0;\n\tu32 val;\n\n\t \n\n\tif (engine->gt->type == GT_MEDIA) {\n\t\tif (MEDIA_VER_FULL(i915) == IP_VER(13, 0)) {\n\t\t\tregs = xelpmp_regs;\n\t\t\tnum = ARRAY_SIZE(xelpmp_regs);\n\t\t}\n\t} else {\n\t\tif (GRAPHICS_VER_FULL(i915) == IP_VER(12, 71) ||\n\t\t    GRAPHICS_VER_FULL(i915) == IP_VER(12, 70) ||\n\t\t    GRAPHICS_VER_FULL(i915) == IP_VER(12, 50) ||\n\t\t    GRAPHICS_VER_FULL(i915) == IP_VER(12, 55)) {\n\t\t\tregs = xehp_regs;\n\t\t\tnum = ARRAY_SIZE(xehp_regs);\n\t\t} else if (GRAPHICS_VER_FULL(i915) == IP_VER(12, 0) ||\n\t\t\t   GRAPHICS_VER_FULL(i915) == IP_VER(12, 10)) {\n\t\t\tregs = gen12_regs;\n\t\t\tnum = ARRAY_SIZE(gen12_regs);\n\t\t} else if (GRAPHICS_VER(i915) >= 8 && GRAPHICS_VER(i915) <= 11) {\n\t\t\tregs = gen8_regs;\n\t\t\tnum = ARRAY_SIZE(gen8_regs);\n\t\t} else if (GRAPHICS_VER(i915) < 8) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (gt_WARN_ONCE(engine->gt, !num,\n\t\t\t \"Platform does not implement TLB invalidation!\"))\n\t\treturn -ENODEV;\n\n\tif (gt_WARN_ON_ONCE(engine->gt,\n\t\t\t    class >= num ||\n\t\t\t    (!regs[class].reg.reg &&\n\t\t\t     !regs[class].mcr_reg.reg)))\n\t\treturn -ERANGE;\n\n\treg = regs[class];\n\n\tif (regs == xelpmp_regs && class == OTHER_CLASS) {\n\t\t \n\t\tGEM_WARN_ON(instance != OTHER_GSC_INSTANCE);\n\t\tval = 1;\n\t} else if (regs == gen8_regs && class == VIDEO_DECODE_CLASS && instance == 1) {\n\t\treg.reg = GEN8_M2TCR;\n\t\tval = 0;\n\t} else {\n\t\tval = instance;\n\t}\n\n\tval = BIT(val);\n\n\tengine->tlb_inv.mcr = regs == xehp_regs;\n\tengine->tlb_inv.reg = reg;\n\tengine->tlb_inv.done = val;\n\n\tif (GRAPHICS_VER(i915) >= 12 &&\n\t    (engine->class == VIDEO_DECODE_CLASS ||\n\t     engine->class == VIDEO_ENHANCEMENT_CLASS ||\n\t     engine->class == COMPUTE_CLASS ||\n\t     engine->class == OTHER_CLASS))\n\t\tengine->tlb_inv.request = _MASKED_BIT_ENABLE(val);\n\telse\n\t\tengine->tlb_inv.request = val;\n\n\treturn 0;\n}\n\nstatic int engine_setup_common(struct intel_engine_cs *engine)\n{\n\tint err;\n\n\tinit_llist_head(&engine->barrier_tasks);\n\n\terr = intel_engine_init_tlb_invalidation(engine);\n\tif (err)\n\t\treturn err;\n\n\terr = init_status_page(engine);\n\tif (err)\n\t\treturn err;\n\n\tengine->breadcrumbs = intel_breadcrumbs_create(engine);\n\tif (!engine->breadcrumbs) {\n\t\terr = -ENOMEM;\n\t\tgoto err_status;\n\t}\n\n\tengine->sched_engine = i915_sched_engine_create(ENGINE_PHYSICAL);\n\tif (!engine->sched_engine) {\n\t\terr = -ENOMEM;\n\t\tgoto err_sched_engine;\n\t}\n\tengine->sched_engine->private_data = engine;\n\n\terr = intel_engine_init_cmd_parser(engine);\n\tif (err)\n\t\tgoto err_cmd_parser;\n\n\tintel_engine_init_execlists(engine);\n\tintel_engine_init__pm(engine);\n\tintel_engine_init_retire(engine);\n\n\t \n\tengine->sseu =\n\t\tintel_sseu_from_device_info(&engine->gt->info.sseu);\n\n\tintel_engine_init_workarounds(engine);\n\tintel_engine_init_whitelist(engine);\n\tintel_engine_init_ctx_wa(engine);\n\n\tif (GRAPHICS_VER(engine->i915) >= 12)\n\t\tengine->flags |= I915_ENGINE_HAS_RELATIVE_MMIO;\n\n\treturn 0;\n\nerr_cmd_parser:\n\ti915_sched_engine_put(engine->sched_engine);\nerr_sched_engine:\n\tintel_breadcrumbs_put(engine->breadcrumbs);\nerr_status:\n\tcleanup_status_page(engine);\n\treturn err;\n}\n\nstruct measure_breadcrumb {\n\tstruct i915_request rq;\n\tstruct intel_ring ring;\n\tu32 cs[2048];\n};\n\nstatic int measure_breadcrumb_dw(struct intel_context *ce)\n{\n\tstruct intel_engine_cs *engine = ce->engine;\n\tstruct measure_breadcrumb *frame;\n\tint dw;\n\n\tGEM_BUG_ON(!engine->gt->scratch);\n\n\tframe = kzalloc(sizeof(*frame), GFP_KERNEL);\n\tif (!frame)\n\t\treturn -ENOMEM;\n\n\tframe->rq.i915 = engine->i915;\n\tframe->rq.engine = engine;\n\tframe->rq.context = ce;\n\trcu_assign_pointer(frame->rq.timeline, ce->timeline);\n\tframe->rq.hwsp_seqno = ce->timeline->hwsp_seqno;\n\n\tframe->ring.vaddr = frame->cs;\n\tframe->ring.size = sizeof(frame->cs);\n\tframe->ring.wrap =\n\t\tBITS_PER_TYPE(frame->ring.size) - ilog2(frame->ring.size);\n\tframe->ring.effective_size = frame->ring.size;\n\tintel_ring_update_space(&frame->ring);\n\tframe->rq.ring = &frame->ring;\n\n\tmutex_lock(&ce->timeline->mutex);\n\tspin_lock_irq(&engine->sched_engine->lock);\n\n\tdw = engine->emit_fini_breadcrumb(&frame->rq, frame->cs) - frame->cs;\n\n\tspin_unlock_irq(&engine->sched_engine->lock);\n\tmutex_unlock(&ce->timeline->mutex);\n\n\tGEM_BUG_ON(dw & 1);  \n\n\tkfree(frame);\n\treturn dw;\n}\n\nstruct intel_context *\nintel_engine_create_pinned_context(struct intel_engine_cs *engine,\n\t\t\t\t   struct i915_address_space *vm,\n\t\t\t\t   unsigned int ring_size,\n\t\t\t\t   unsigned int hwsp,\n\t\t\t\t   struct lock_class_key *key,\n\t\t\t\t   const char *name)\n{\n\tstruct intel_context *ce;\n\tint err;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn ce;\n\n\t__set_bit(CONTEXT_BARRIER_BIT, &ce->flags);\n\tce->timeline = page_pack_bits(NULL, hwsp);\n\tce->ring = NULL;\n\tce->ring_size = ring_size;\n\n\ti915_vm_put(ce->vm);\n\tce->vm = i915_vm_get(vm);\n\n\terr = intel_context_pin(ce);  \n\tif (err) {\n\t\tintel_context_put(ce);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tlist_add_tail(&ce->pinned_contexts_link, &engine->pinned_contexts_list);\n\n\t \n\tlockdep_set_class_and_name(&ce->timeline->mutex, key, name);\n\n\treturn ce;\n}\n\nvoid intel_engine_destroy_pinned_context(struct intel_context *ce)\n{\n\tstruct intel_engine_cs *engine = ce->engine;\n\tstruct i915_vma *hwsp = engine->status_page.vma;\n\n\tGEM_BUG_ON(ce->timeline->hwsp_ggtt != hwsp);\n\n\tmutex_lock(&hwsp->vm->mutex);\n\tlist_del(&ce->timeline->engine_link);\n\tmutex_unlock(&hwsp->vm->mutex);\n\n\tlist_del(&ce->pinned_contexts_link);\n\tintel_context_unpin(ce);\n\tintel_context_put(ce);\n}\n\nstatic struct intel_context *\ncreate_kernel_context(struct intel_engine_cs *engine)\n{\n\tstatic struct lock_class_key kernel;\n\n\treturn intel_engine_create_pinned_context(engine, engine->gt->vm, SZ_4K,\n\t\t\t\t\t\t  I915_GEM_HWS_SEQNO_ADDR,\n\t\t\t\t\t\t  &kernel, \"kernel_context\");\n}\n\n \nstatic int engine_init_common(struct intel_engine_cs *engine)\n{\n\tstruct intel_context *ce;\n\tint ret;\n\n\tengine->set_default_submission(engine);\n\n\t \n\tce = create_kernel_context(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\tret = measure_breadcrumb_dw(ce);\n\tif (ret < 0)\n\t\tgoto err_context;\n\n\tengine->emit_fini_breadcrumb_dw = ret;\n\tengine->kernel_context = ce;\n\n\treturn 0;\n\nerr_context:\n\tintel_engine_destroy_pinned_context(ce);\n\treturn ret;\n}\n\nint intel_engines_init(struct intel_gt *gt)\n{\n\tint (*setup)(struct intel_engine_cs *engine);\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err;\n\n\tif (intel_uc_uses_guc_submission(&gt->uc)) {\n\t\tgt->submission_method = INTEL_SUBMISSION_GUC;\n\t\tsetup = intel_guc_submission_setup;\n\t} else if (HAS_EXECLISTS(gt->i915)) {\n\t\tgt->submission_method = INTEL_SUBMISSION_ELSP;\n\t\tsetup = intel_execlists_submission_setup;\n\t} else {\n\t\tgt->submission_method = INTEL_SUBMISSION_RING;\n\t\tsetup = intel_ring_submission_setup;\n\t}\n\n\tfor_each_engine(engine, gt, id) {\n\t\terr = engine_setup_common(engine);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = setup(engine);\n\t\tif (err) {\n\t\t\tintel_engine_cleanup_common(engine);\n\t\t\treturn err;\n\t\t}\n\n\t\t \n\t\tGEM_BUG_ON(engine->release == NULL);\n\n\t\terr = engine_init_common(engine);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tintel_engine_add_user(engine);\n\t}\n\n\treturn 0;\n}\n\n \nvoid intel_engine_cleanup_common(struct intel_engine_cs *engine)\n{\n\tGEM_BUG_ON(!list_empty(&engine->sched_engine->requests));\n\n\ti915_sched_engine_put(engine->sched_engine);\n\tintel_breadcrumbs_put(engine->breadcrumbs);\n\n\tintel_engine_fini_retire(engine);\n\tintel_engine_cleanup_cmd_parser(engine);\n\n\tif (engine->default_state)\n\t\tfput(engine->default_state);\n\n\tif (engine->kernel_context)\n\t\tintel_engine_destroy_pinned_context(engine->kernel_context);\n\n\tGEM_BUG_ON(!llist_empty(&engine->barrier_tasks));\n\tcleanup_status_page(engine);\n\n\tintel_wa_list_free(&engine->ctx_wa_list);\n\tintel_wa_list_free(&engine->wa_list);\n\tintel_wa_list_free(&engine->whitelist);\n}\n\n \nint intel_engine_resume(struct intel_engine_cs *engine)\n{\n\tintel_engine_apply_workarounds(engine);\n\tintel_engine_apply_whitelist(engine);\n\n\treturn engine->resume(engine);\n}\n\nu64 intel_engine_get_active_head(const struct intel_engine_cs *engine)\n{\n\tstruct drm_i915_private *i915 = engine->i915;\n\n\tu64 acthd;\n\n\tif (GRAPHICS_VER(i915) >= 8)\n\t\tacthd = ENGINE_READ64(engine, RING_ACTHD, RING_ACTHD_UDW);\n\telse if (GRAPHICS_VER(i915) >= 4)\n\t\tacthd = ENGINE_READ(engine, RING_ACTHD);\n\telse\n\t\tacthd = ENGINE_READ(engine, ACTHD);\n\n\treturn acthd;\n}\n\nu64 intel_engine_get_last_batch_head(const struct intel_engine_cs *engine)\n{\n\tu64 bbaddr;\n\n\tif (GRAPHICS_VER(engine->i915) >= 8)\n\t\tbbaddr = ENGINE_READ64(engine, RING_BBADDR, RING_BBADDR_UDW);\n\telse\n\t\tbbaddr = ENGINE_READ(engine, RING_BBADDR);\n\n\treturn bbaddr;\n}\n\nstatic unsigned long stop_timeout(const struct intel_engine_cs *engine)\n{\n\tif (in_atomic() || irqs_disabled())  \n\t\treturn 0;\n\n\t \n\treturn READ_ONCE(engine->props.stop_timeout_ms);\n}\n\nstatic int __intel_engine_stop_cs(struct intel_engine_cs *engine,\n\t\t\t\t  int fast_timeout_us,\n\t\t\t\t  int slow_timeout_ms)\n{\n\tstruct intel_uncore *uncore = engine->uncore;\n\tconst i915_reg_t mode = RING_MI_MODE(engine->mmio_base);\n\tint err;\n\n\tintel_uncore_write_fw(uncore, mode, _MASKED_BIT_ENABLE(STOP_RING));\n\n\t \n\tif (IS_MTL_GRAPHICS_STEP(engine->i915, M, STEP_A0, STEP_B0) ||\n\t    (GRAPHICS_VER(engine->i915) >= 11 &&\n\t    GRAPHICS_VER_FULL(engine->i915) < IP_VER(12, 70)))\n\t\tintel_uncore_write_fw(uncore, RING_MODE_GEN7(engine->mmio_base),\n\t\t\t\t      _MASKED_BIT_ENABLE(GEN12_GFX_PREFETCH_DISABLE));\n\n\terr = __intel_wait_for_register_fw(engine->uncore, mode,\n\t\t\t\t\t   MODE_IDLE, MODE_IDLE,\n\t\t\t\t\t   fast_timeout_us,\n\t\t\t\t\t   slow_timeout_ms,\n\t\t\t\t\t   NULL);\n\n\t \n\tintel_uncore_posting_read_fw(uncore, mode);\n\treturn err;\n}\n\nint intel_engine_stop_cs(struct intel_engine_cs *engine)\n{\n\tint err = 0;\n\n\tif (GRAPHICS_VER(engine->i915) < 3)\n\t\treturn -ENODEV;\n\n\tENGINE_TRACE(engine, \"\\n\");\n\t \n\tif (__intel_engine_stop_cs(engine, 1000, stop_timeout(engine))) {\n\t\tENGINE_TRACE(engine,\n\t\t\t     \"timed out on STOP_RING -> IDLE; HEAD:%04x, TAIL:%04x\\n\",\n\t\t\t     ENGINE_READ_FW(engine, RING_HEAD) & HEAD_ADDR,\n\t\t\t     ENGINE_READ_FW(engine, RING_TAIL) & TAIL_ADDR);\n\n\t\t \n\t\tif ((ENGINE_READ_FW(engine, RING_HEAD) & HEAD_ADDR) !=\n\t\t    (ENGINE_READ_FW(engine, RING_TAIL) & TAIL_ADDR))\n\t\t\terr = -ETIMEDOUT;\n\t}\n\n\treturn err;\n}\n\nvoid intel_engine_cancel_stop_cs(struct intel_engine_cs *engine)\n{\n\tENGINE_TRACE(engine, \"\\n\");\n\n\tENGINE_WRITE_FW(engine, RING_MI_MODE, _MASKED_BIT_DISABLE(STOP_RING));\n}\n\nstatic u32 __cs_pending_mi_force_wakes(struct intel_engine_cs *engine)\n{\n\tstatic const i915_reg_t _reg[I915_NUM_ENGINES] = {\n\t\t[RCS0] = MSG_IDLE_CS,\n\t\t[BCS0] = MSG_IDLE_BCS,\n\t\t[VCS0] = MSG_IDLE_VCS0,\n\t\t[VCS1] = MSG_IDLE_VCS1,\n\t\t[VCS2] = MSG_IDLE_VCS2,\n\t\t[VCS3] = MSG_IDLE_VCS3,\n\t\t[VCS4] = MSG_IDLE_VCS4,\n\t\t[VCS5] = MSG_IDLE_VCS5,\n\t\t[VCS6] = MSG_IDLE_VCS6,\n\t\t[VCS7] = MSG_IDLE_VCS7,\n\t\t[VECS0] = MSG_IDLE_VECS0,\n\t\t[VECS1] = MSG_IDLE_VECS1,\n\t\t[VECS2] = MSG_IDLE_VECS2,\n\t\t[VECS3] = MSG_IDLE_VECS3,\n\t\t[CCS0] = MSG_IDLE_CS,\n\t\t[CCS1] = MSG_IDLE_CS,\n\t\t[CCS2] = MSG_IDLE_CS,\n\t\t[CCS3] = MSG_IDLE_CS,\n\t};\n\tu32 val;\n\n\tif (!_reg[engine->id].reg)\n\t\treturn 0;\n\n\tval = intel_uncore_read(engine->uncore, _reg[engine->id]);\n\n\t \n\treturn (val & (val >> 16) & MSG_IDLE_FW_MASK) >> MSG_IDLE_FW_SHIFT;\n}\n\nstatic void __gpm_wait_for_fw_complete(struct intel_gt *gt, u32 fw_mask)\n{\n\tint ret;\n\n\t \n\tudelay(1);\n\n\t \n\tret =  __intel_wait_for_register_fw(gt->uncore,\n\t\t\t\t\t    GEN9_PWRGT_DOMAIN_STATUS,\n\t\t\t\t\t    fw_mask, fw_mask, 5000, 0, NULL);\n\n\t \n\tudelay(1);\n\n\tif (ret)\n\t\tGT_TRACE(gt, \"Failed to complete pending forcewake %d\\n\", ret);\n}\n\n \nvoid intel_engine_wait_for_pending_mi_fw(struct intel_engine_cs *engine)\n{\n\tu32 fw_pending = __cs_pending_mi_force_wakes(engine);\n\n\tif (fw_pending)\n\t\t__gpm_wait_for_fw_complete(engine->gt, fw_pending);\n}\n\n \nvoid intel_engine_get_instdone(const struct intel_engine_cs *engine,\n\t\t\t       struct intel_instdone *instdone)\n{\n\tstruct drm_i915_private *i915 = engine->i915;\n\tstruct intel_uncore *uncore = engine->uncore;\n\tu32 mmio_base = engine->mmio_base;\n\tint slice;\n\tint subslice;\n\tint iter;\n\n\tmemset(instdone, 0, sizeof(*instdone));\n\n\tif (GRAPHICS_VER(i915) >= 8) {\n\t\tinstdone->instdone =\n\t\t\tintel_uncore_read(uncore, RING_INSTDONE(mmio_base));\n\n\t\tif (engine->id != RCS0)\n\t\t\treturn;\n\n\t\tinstdone->slice_common =\n\t\t\tintel_uncore_read(uncore, GEN7_SC_INSTDONE);\n\t\tif (GRAPHICS_VER(i915) >= 12) {\n\t\t\tinstdone->slice_common_extra[0] =\n\t\t\t\tintel_uncore_read(uncore, GEN12_SC_INSTDONE_EXTRA);\n\t\t\tinstdone->slice_common_extra[1] =\n\t\t\t\tintel_uncore_read(uncore, GEN12_SC_INSTDONE_EXTRA2);\n\t\t}\n\n\t\tfor_each_ss_steering(iter, engine->gt, slice, subslice) {\n\t\t\tinstdone->sampler[slice][subslice] =\n\t\t\t\tintel_gt_mcr_read(engine->gt,\n\t\t\t\t\t\t  GEN8_SAMPLER_INSTDONE,\n\t\t\t\t\t\t  slice, subslice);\n\t\t\tinstdone->row[slice][subslice] =\n\t\t\t\tintel_gt_mcr_read(engine->gt,\n\t\t\t\t\t\t  GEN8_ROW_INSTDONE,\n\t\t\t\t\t\t  slice, subslice);\n\t\t}\n\n\t\tif (GRAPHICS_VER_FULL(i915) >= IP_VER(12, 55)) {\n\t\t\tfor_each_ss_steering(iter, engine->gt, slice, subslice)\n\t\t\t\tinstdone->geom_svg[slice][subslice] =\n\t\t\t\t\tintel_gt_mcr_read(engine->gt,\n\t\t\t\t\t\t\t  XEHPG_INSTDONE_GEOM_SVG,\n\t\t\t\t\t\t\t  slice, subslice);\n\t\t}\n\t} else if (GRAPHICS_VER(i915) >= 7) {\n\t\tinstdone->instdone =\n\t\t\tintel_uncore_read(uncore, RING_INSTDONE(mmio_base));\n\n\t\tif (engine->id != RCS0)\n\t\t\treturn;\n\n\t\tinstdone->slice_common =\n\t\t\tintel_uncore_read(uncore, GEN7_SC_INSTDONE);\n\t\tinstdone->sampler[0][0] =\n\t\t\tintel_uncore_read(uncore, GEN7_SAMPLER_INSTDONE);\n\t\tinstdone->row[0][0] =\n\t\t\tintel_uncore_read(uncore, GEN7_ROW_INSTDONE);\n\t} else if (GRAPHICS_VER(i915) >= 4) {\n\t\tinstdone->instdone =\n\t\t\tintel_uncore_read(uncore, RING_INSTDONE(mmio_base));\n\t\tif (engine->id == RCS0)\n\t\t\t \n\t\t\tinstdone->slice_common =\n\t\t\t\tintel_uncore_read(uncore, GEN4_INSTDONE1);\n\t} else {\n\t\tinstdone->instdone = intel_uncore_read(uncore, GEN2_INSTDONE);\n\t}\n}\n\nstatic bool ring_is_idle(struct intel_engine_cs *engine)\n{\n\tbool idle = true;\n\n\tif (I915_SELFTEST_ONLY(!engine->mmio_base))\n\t\treturn true;\n\n\tif (!intel_engine_pm_get_if_awake(engine))\n\t\treturn true;\n\n\t \n\tif ((ENGINE_READ(engine, RING_HEAD) & HEAD_ADDR) !=\n\t    (ENGINE_READ(engine, RING_TAIL) & TAIL_ADDR))\n\t\tidle = false;\n\n\t \n\tif (GRAPHICS_VER(engine->i915) > 2 &&\n\t    !(ENGINE_READ(engine, RING_MI_MODE) & MODE_IDLE))\n\t\tidle = false;\n\n\tintel_engine_pm_put(engine);\n\n\treturn idle;\n}\n\nvoid __intel_engine_flush_submission(struct intel_engine_cs *engine, bool sync)\n{\n\tstruct tasklet_struct *t = &engine->sched_engine->tasklet;\n\n\tif (!t->callback)\n\t\treturn;\n\n\tlocal_bh_disable();\n\tif (tasklet_trylock(t)) {\n\t\t \n\t\tif (__tasklet_is_enabled(t))\n\t\t\tt->callback(t);\n\t\ttasklet_unlock(t);\n\t}\n\tlocal_bh_enable();\n\n\t \n\tif (sync)\n\t\ttasklet_unlock_wait(t);\n}\n\n \nbool intel_engine_is_idle(struct intel_engine_cs *engine)\n{\n\t \n\tif (intel_gt_is_wedged(engine->gt))\n\t\treturn true;\n\n\tif (!intel_engine_pm_is_awake(engine))\n\t\treturn true;\n\n\t \n\tintel_synchronize_hardirq(engine->i915);\n\tintel_engine_flush_submission(engine);\n\n\t \n\tif (!i915_sched_engine_is_empty(engine->sched_engine))\n\t\treturn false;\n\n\t \n\treturn ring_is_idle(engine);\n}\n\nbool intel_engines_are_idle(struct intel_gt *gt)\n{\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\tif (intel_gt_is_wedged(gt))\n\t\treturn true;\n\n\t \n\tif (!READ_ONCE(gt->awake))\n\t\treturn true;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tif (!intel_engine_is_idle(engine))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nbool intel_engine_irq_enable(struct intel_engine_cs *engine)\n{\n\tif (!engine->irq_enable)\n\t\treturn false;\n\n\t \n\tspin_lock(engine->gt->irq_lock);\n\tengine->irq_enable(engine);\n\tspin_unlock(engine->gt->irq_lock);\n\n\treturn true;\n}\n\nvoid intel_engine_irq_disable(struct intel_engine_cs *engine)\n{\n\tif (!engine->irq_disable)\n\t\treturn;\n\n\t \n\tspin_lock(engine->gt->irq_lock);\n\tengine->irq_disable(engine);\n\tspin_unlock(engine->gt->irq_lock);\n}\n\nvoid intel_engines_reset_default_submission(struct intel_gt *gt)\n{\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tif (engine->sanitize)\n\t\t\tengine->sanitize(engine);\n\n\t\tengine->set_default_submission(engine);\n\t}\n}\n\nbool intel_engine_can_store_dword(struct intel_engine_cs *engine)\n{\n\tswitch (GRAPHICS_VER(engine->i915)) {\n\tcase 2:\n\t\treturn false;  \n\tcase 3:\n\t\t \n\t\treturn !(IS_I915G(engine->i915) || IS_I915GM(engine->i915));\n\tcase 4:\n\t\treturn !IS_I965G(engine->i915);  \n\tcase 6:\n\t\treturn engine->class != VIDEO_DECODE_CLASS;  \n\tdefault:\n\t\treturn true;\n\t}\n}\n\nstatic struct intel_timeline *get_timeline(struct i915_request *rq)\n{\n\tstruct intel_timeline *tl;\n\n\t \n\trcu_read_lock();\n\ttl = rcu_dereference(rq->timeline);\n\tif (!kref_get_unless_zero(&tl->kref))\n\t\ttl = NULL;\n\trcu_read_unlock();\n\n\treturn tl;\n}\n\nstatic int print_ring(char *buf, int sz, struct i915_request *rq)\n{\n\tint len = 0;\n\n\tif (!i915_request_signaled(rq)) {\n\t\tstruct intel_timeline *tl = get_timeline(rq);\n\n\t\tlen = scnprintf(buf, sz,\n\t\t\t\t\"ring:{start:%08x, hwsp:%08x, seqno:%08x, runtime:%llums}, \",\n\t\t\t\ti915_ggtt_offset(rq->ring->vma),\n\t\t\t\ttl ? tl->hwsp_offset : 0,\n\t\t\t\thwsp_seqno(rq),\n\t\t\t\tDIV_ROUND_CLOSEST_ULL(intel_context_get_total_runtime_ns(rq->context),\n\t\t\t\t\t\t      1000 * 1000));\n\n\t\tif (tl)\n\t\t\tintel_timeline_put(tl);\n\t}\n\n\treturn len;\n}\n\nstatic void hexdump(struct drm_printer *m, const void *buf, size_t len)\n{\n\tconst size_t rowsize = 8 * sizeof(u32);\n\tconst void *prev = NULL;\n\tbool skip = false;\n\tsize_t pos;\n\n\tfor (pos = 0; pos < len; pos += rowsize) {\n\t\tchar line[128];\n\n\t\tif (prev && !memcmp(prev, buf + pos, rowsize)) {\n\t\t\tif (!skip) {\n\t\t\t\tdrm_printf(m, \"*\\n\");\n\t\t\t\tskip = true;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tWARN_ON_ONCE(hex_dump_to_buffer(buf + pos, len - pos,\n\t\t\t\t\t\trowsize, sizeof(u32),\n\t\t\t\t\t\tline, sizeof(line),\n\t\t\t\t\t\tfalse) >= sizeof(line));\n\t\tdrm_printf(m, \"[%04zx] %s\\n\", pos, line);\n\n\t\tprev = buf + pos;\n\t\tskip = false;\n\t}\n}\n\nstatic const char *repr_timer(const struct timer_list *t)\n{\n\tif (!READ_ONCE(t->expires))\n\t\treturn \"inactive\";\n\n\tif (timer_pending(t))\n\t\treturn \"active\";\n\n\treturn \"expired\";\n}\n\nstatic void intel_engine_print_registers(struct intel_engine_cs *engine,\n\t\t\t\t\t struct drm_printer *m)\n{\n\tstruct drm_i915_private *i915 = engine->i915;\n\tstruct intel_engine_execlists * const execlists = &engine->execlists;\n\tu64 addr;\n\n\tif (engine->id == RENDER_CLASS && IS_GRAPHICS_VER(i915, 4, 7))\n\t\tdrm_printf(m, \"\\tCCID: 0x%08x\\n\", ENGINE_READ(engine, CCID));\n\tif (HAS_EXECLISTS(i915)) {\n\t\tdrm_printf(m, \"\\tEL_STAT_HI: 0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_EXECLIST_STATUS_HI));\n\t\tdrm_printf(m, \"\\tEL_STAT_LO: 0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_EXECLIST_STATUS_LO));\n\t}\n\tdrm_printf(m, \"\\tRING_START: 0x%08x\\n\",\n\t\t   ENGINE_READ(engine, RING_START));\n\tdrm_printf(m, \"\\tRING_HEAD:  0x%08x\\n\",\n\t\t   ENGINE_READ(engine, RING_HEAD) & HEAD_ADDR);\n\tdrm_printf(m, \"\\tRING_TAIL:  0x%08x\\n\",\n\t\t   ENGINE_READ(engine, RING_TAIL) & TAIL_ADDR);\n\tdrm_printf(m, \"\\tRING_CTL:   0x%08x%s\\n\",\n\t\t   ENGINE_READ(engine, RING_CTL),\n\t\t   ENGINE_READ(engine, RING_CTL) & (RING_WAIT | RING_WAIT_SEMAPHORE) ? \" [waiting]\" : \"\");\n\tif (GRAPHICS_VER(engine->i915) > 2) {\n\t\tdrm_printf(m, \"\\tRING_MODE:  0x%08x%s\\n\",\n\t\t\t   ENGINE_READ(engine, RING_MI_MODE),\n\t\t\t   ENGINE_READ(engine, RING_MI_MODE) & (MODE_IDLE) ? \" [idle]\" : \"\");\n\t}\n\n\tif (GRAPHICS_VER(i915) >= 6) {\n\t\tdrm_printf(m, \"\\tRING_IMR:   0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_IMR));\n\t\tdrm_printf(m, \"\\tRING_ESR:   0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_ESR));\n\t\tdrm_printf(m, \"\\tRING_EMR:   0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_EMR));\n\t\tdrm_printf(m, \"\\tRING_EIR:   0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_EIR));\n\t}\n\n\taddr = intel_engine_get_active_head(engine);\n\tdrm_printf(m, \"\\tACTHD:  0x%08x_%08x\\n\",\n\t\t   upper_32_bits(addr), lower_32_bits(addr));\n\taddr = intel_engine_get_last_batch_head(engine);\n\tdrm_printf(m, \"\\tBBADDR: 0x%08x_%08x\\n\",\n\t\t   upper_32_bits(addr), lower_32_bits(addr));\n\tif (GRAPHICS_VER(i915) >= 8)\n\t\taddr = ENGINE_READ64(engine, RING_DMA_FADD, RING_DMA_FADD_UDW);\n\telse if (GRAPHICS_VER(i915) >= 4)\n\t\taddr = ENGINE_READ(engine, RING_DMA_FADD);\n\telse\n\t\taddr = ENGINE_READ(engine, DMA_FADD_I8XX);\n\tdrm_printf(m, \"\\tDMA_FADDR: 0x%08x_%08x\\n\",\n\t\t   upper_32_bits(addr), lower_32_bits(addr));\n\tif (GRAPHICS_VER(i915) >= 4) {\n\t\tdrm_printf(m, \"\\tIPEIR: 0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_IPEIR));\n\t\tdrm_printf(m, \"\\tIPEHR: 0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_IPEHR));\n\t} else {\n\t\tdrm_printf(m, \"\\tIPEIR: 0x%08x\\n\", ENGINE_READ(engine, IPEIR));\n\t\tdrm_printf(m, \"\\tIPEHR: 0x%08x\\n\", ENGINE_READ(engine, IPEHR));\n\t}\n\n\tif (HAS_EXECLISTS(i915) && !intel_engine_uses_guc(engine)) {\n\t\tstruct i915_request * const *port, *rq;\n\t\tconst u32 *hws =\n\t\t\t&engine->status_page.addr[I915_HWS_CSB_BUF0_INDEX];\n\t\tconst u8 num_entries = execlists->csb_size;\n\t\tunsigned int idx;\n\t\tu8 read, write;\n\n\t\tdrm_printf(m, \"\\tExeclist tasklet queued? %s (%s), preempt? %s, timeslice? %s\\n\",\n\t\t\t   str_yes_no(test_bit(TASKLET_STATE_SCHED, &engine->sched_engine->tasklet.state)),\n\t\t\t   str_enabled_disabled(!atomic_read(&engine->sched_engine->tasklet.count)),\n\t\t\t   repr_timer(&engine->execlists.preempt),\n\t\t\t   repr_timer(&engine->execlists.timer));\n\n\t\tread = execlists->csb_head;\n\t\twrite = READ_ONCE(*execlists->csb_write);\n\n\t\tdrm_printf(m, \"\\tExeclist status: 0x%08x %08x; CSB read:%d, write:%d, entries:%d\\n\",\n\t\t\t   ENGINE_READ(engine, RING_EXECLIST_STATUS_LO),\n\t\t\t   ENGINE_READ(engine, RING_EXECLIST_STATUS_HI),\n\t\t\t   read, write, num_entries);\n\n\t\tif (read >= num_entries)\n\t\t\tread = 0;\n\t\tif (write >= num_entries)\n\t\t\twrite = 0;\n\t\tif (read > write)\n\t\t\twrite += num_entries;\n\t\twhile (read < write) {\n\t\t\tidx = ++read % num_entries;\n\t\t\tdrm_printf(m, \"\\tExeclist CSB[%d]: 0x%08x, context: %d\\n\",\n\t\t\t\t   idx, hws[idx * 2], hws[idx * 2 + 1]);\n\t\t}\n\n\t\ti915_sched_engine_active_lock_bh(engine->sched_engine);\n\t\trcu_read_lock();\n\t\tfor (port = execlists->active; (rq = *port); port++) {\n\t\t\tchar hdr[160];\n\t\t\tint len;\n\n\t\t\tlen = scnprintf(hdr, sizeof(hdr),\n\t\t\t\t\t\"\\t\\tActive[%d]:  ccid:%08x%s%s, \",\n\t\t\t\t\t(int)(port - execlists->active),\n\t\t\t\t\trq->context->lrc.ccid,\n\t\t\t\t\tintel_context_is_closed(rq->context) ? \"!\" : \"\",\n\t\t\t\t\tintel_context_is_banned(rq->context) ? \"*\" : \"\");\n\t\t\tlen += print_ring(hdr + len, sizeof(hdr) - len, rq);\n\t\t\tscnprintf(hdr + len, sizeof(hdr) - len, \"rq: \");\n\t\t\ti915_request_show(m, rq, hdr, 0);\n\t\t}\n\t\tfor (port = execlists->pending; (rq = *port); port++) {\n\t\t\tchar hdr[160];\n\t\t\tint len;\n\n\t\t\tlen = scnprintf(hdr, sizeof(hdr),\n\t\t\t\t\t\"\\t\\tPending[%d]: ccid:%08x%s%s, \",\n\t\t\t\t\t(int)(port - execlists->pending),\n\t\t\t\t\trq->context->lrc.ccid,\n\t\t\t\t\tintel_context_is_closed(rq->context) ? \"!\" : \"\",\n\t\t\t\t\tintel_context_is_banned(rq->context) ? \"*\" : \"\");\n\t\t\tlen += print_ring(hdr + len, sizeof(hdr) - len, rq);\n\t\t\tscnprintf(hdr + len, sizeof(hdr) - len, \"rq: \");\n\t\t\ti915_request_show(m, rq, hdr, 0);\n\t\t}\n\t\trcu_read_unlock();\n\t\ti915_sched_engine_active_unlock_bh(engine->sched_engine);\n\t} else if (GRAPHICS_VER(i915) > 6) {\n\t\tdrm_printf(m, \"\\tPP_DIR_BASE: 0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_PP_DIR_BASE));\n\t\tdrm_printf(m, \"\\tPP_DIR_BASE_READ: 0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_PP_DIR_BASE_READ));\n\t\tdrm_printf(m, \"\\tPP_DIR_DCLV: 0x%08x\\n\",\n\t\t\t   ENGINE_READ(engine, RING_PP_DIR_DCLV));\n\t}\n}\n\nstatic void print_request_ring(struct drm_printer *m, struct i915_request *rq)\n{\n\tstruct i915_vma_resource *vma_res = rq->batch_res;\n\tvoid *ring;\n\tint size;\n\n\tdrm_printf(m,\n\t\t   \"[head %04x, postfix %04x, tail %04x, batch 0x%08x_%08x]:\\n\",\n\t\t   rq->head, rq->postfix, rq->tail,\n\t\t   vma_res ? upper_32_bits(vma_res->start) : ~0u,\n\t\t   vma_res ? lower_32_bits(vma_res->start) : ~0u);\n\n\tsize = rq->tail - rq->head;\n\tif (rq->tail < rq->head)\n\t\tsize += rq->ring->size;\n\n\tring = kmalloc(size, GFP_ATOMIC);\n\tif (ring) {\n\t\tconst void *vaddr = rq->ring->vaddr;\n\t\tunsigned int head = rq->head;\n\t\tunsigned int len = 0;\n\n\t\tif (rq->tail < head) {\n\t\t\tlen = rq->ring->size - head;\n\t\t\tmemcpy(ring, vaddr + head, len);\n\t\t\thead = 0;\n\t\t}\n\t\tmemcpy(ring + len, vaddr + head, size - len);\n\n\t\thexdump(m, ring, size);\n\t\tkfree(ring);\n\t}\n}\n\nstatic unsigned long read_ul(void *p, size_t x)\n{\n\treturn *(unsigned long *)(p + x);\n}\n\nstatic void print_properties(struct intel_engine_cs *engine,\n\t\t\t     struct drm_printer *m)\n{\n\tstatic const struct pmap {\n\t\tsize_t offset;\n\t\tconst char *name;\n\t} props[] = {\n#define P(x) { \\\n\t.offset = offsetof(typeof(engine->props), x), \\\n\t.name = #x \\\n}\n\t\tP(heartbeat_interval_ms),\n\t\tP(max_busywait_duration_ns),\n\t\tP(preempt_timeout_ms),\n\t\tP(stop_timeout_ms),\n\t\tP(timeslice_duration_ms),\n\n\t\t{},\n#undef P\n\t};\n\tconst struct pmap *p;\n\n\tdrm_printf(m, \"\\tProperties:\\n\");\n\tfor (p = props; p->name; p++)\n\t\tdrm_printf(m, \"\\t\\t%s: %lu [default %lu]\\n\",\n\t\t\t   p->name,\n\t\t\t   read_ul(&engine->props, p->offset),\n\t\t\t   read_ul(&engine->defaults, p->offset));\n}\n\nstatic void engine_dump_request(struct i915_request *rq, struct drm_printer *m, const char *msg)\n{\n\tstruct intel_timeline *tl = get_timeline(rq);\n\n\ti915_request_show(m, rq, msg, 0);\n\n\tdrm_printf(m, \"\\t\\tring->start:  0x%08x\\n\",\n\t\t   i915_ggtt_offset(rq->ring->vma));\n\tdrm_printf(m, \"\\t\\tring->head:   0x%08x\\n\",\n\t\t   rq->ring->head);\n\tdrm_printf(m, \"\\t\\tring->tail:   0x%08x\\n\",\n\t\t   rq->ring->tail);\n\tdrm_printf(m, \"\\t\\tring->emit:   0x%08x\\n\",\n\t\t   rq->ring->emit);\n\tdrm_printf(m, \"\\t\\tring->space:  0x%08x\\n\",\n\t\t   rq->ring->space);\n\n\tif (tl) {\n\t\tdrm_printf(m, \"\\t\\tring->hwsp:   0x%08x\\n\",\n\t\t\t   tl->hwsp_offset);\n\t\tintel_timeline_put(tl);\n\t}\n\n\tprint_request_ring(m, rq);\n\n\tif (rq->context->lrc_reg_state) {\n\t\tdrm_printf(m, \"Logical Ring Context:\\n\");\n\t\thexdump(m, rq->context->lrc_reg_state, PAGE_SIZE);\n\t}\n}\n\nvoid intel_engine_dump_active_requests(struct list_head *requests,\n\t\t\t\t       struct i915_request *hung_rq,\n\t\t\t\t       struct drm_printer *m)\n{\n\tstruct i915_request *rq;\n\tconst char *msg;\n\tenum i915_request_state state;\n\n\tlist_for_each_entry(rq, requests, sched.link) {\n\t\tif (rq == hung_rq)\n\t\t\tcontinue;\n\n\t\tstate = i915_test_request_state(rq);\n\t\tif (state < I915_REQUEST_QUEUED)\n\t\t\tcontinue;\n\n\t\tif (state == I915_REQUEST_ACTIVE)\n\t\t\tmsg = \"\\t\\tactive on engine\";\n\t\telse\n\t\t\tmsg = \"\\t\\tactive in queue\";\n\n\t\tengine_dump_request(rq, m, msg);\n\t}\n}\n\nstatic void engine_dump_active_requests(struct intel_engine_cs *engine,\n\t\t\t\t\tstruct drm_printer *m)\n{\n\tstruct intel_context *hung_ce = NULL;\n\tstruct i915_request *hung_rq = NULL;\n\n\t \n\tintel_engine_get_hung_entity(engine, &hung_ce, &hung_rq);\n\n\tdrm_printf(m, \"\\tRequests:\\n\");\n\n\tif (hung_rq)\n\t\tengine_dump_request(hung_rq, m, \"\\t\\thung\");\n\telse if (hung_ce)\n\t\tdrm_printf(m, \"\\t\\tGot hung ce but no hung rq!\\n\");\n\n\tif (intel_uc_uses_guc_submission(&engine->gt->uc))\n\t\tintel_guc_dump_active_requests(engine, hung_rq, m);\n\telse\n\t\tintel_execlists_dump_active_requests(engine, hung_rq, m);\n\n\tif (hung_rq)\n\t\ti915_request_put(hung_rq);\n}\n\nvoid intel_engine_dump(struct intel_engine_cs *engine,\n\t\t       struct drm_printer *m,\n\t\t       const char *header, ...)\n{\n\tstruct i915_gpu_error * const error = &engine->i915->gpu_error;\n\tstruct i915_request *rq;\n\tintel_wakeref_t wakeref;\n\tktime_t dummy;\n\n\tif (header) {\n\t\tva_list ap;\n\n\t\tva_start(ap, header);\n\t\tdrm_vprintf(m, header, &ap);\n\t\tva_end(ap);\n\t}\n\n\tif (intel_gt_is_wedged(engine->gt))\n\t\tdrm_printf(m, \"*** WEDGED ***\\n\");\n\n\tdrm_printf(m, \"\\tAwake? %d\\n\", atomic_read(&engine->wakeref.count));\n\tdrm_printf(m, \"\\tBarriers?: %s\\n\",\n\t\t   str_yes_no(!llist_empty(&engine->barrier_tasks)));\n\tdrm_printf(m, \"\\tLatency: %luus\\n\",\n\t\t   ewma__engine_latency_read(&engine->latency));\n\tif (intel_engine_supports_stats(engine))\n\t\tdrm_printf(m, \"\\tRuntime: %llums\\n\",\n\t\t\t   ktime_to_ms(intel_engine_get_busy_time(engine,\n\t\t\t\t\t\t\t\t  &dummy)));\n\tdrm_printf(m, \"\\tForcewake: %x domains, %d active\\n\",\n\t\t   engine->fw_domain, READ_ONCE(engine->fw_active));\n\n\trcu_read_lock();\n\trq = READ_ONCE(engine->heartbeat.systole);\n\tif (rq)\n\t\tdrm_printf(m, \"\\tHeartbeat: %d ms ago\\n\",\n\t\t\t   jiffies_to_msecs(jiffies - rq->emitted_jiffies));\n\trcu_read_unlock();\n\tdrm_printf(m, \"\\tReset count: %d (global %d)\\n\",\n\t\t   i915_reset_engine_count(error, engine),\n\t\t   i915_reset_count(error));\n\tprint_properties(engine, m);\n\n\tengine_dump_active_requests(engine, m);\n\n\tdrm_printf(m, \"\\tMMIO base:  0x%08x\\n\", engine->mmio_base);\n\twakeref = intel_runtime_pm_get_if_in_use(engine->uncore->rpm);\n\tif (wakeref) {\n\t\tintel_engine_print_registers(engine, m);\n\t\tintel_runtime_pm_put(engine->uncore->rpm, wakeref);\n\t} else {\n\t\tdrm_printf(m, \"\\tDevice is asleep; skipping register dump\\n\");\n\t}\n\n\tintel_execlists_show_requests(engine, m, i915_request_show, 8);\n\n\tdrm_printf(m, \"HWSP:\\n\");\n\thexdump(m, engine->status_page.addr, PAGE_SIZE);\n\n\tdrm_printf(m, \"Idle? %s\\n\", str_yes_no(intel_engine_is_idle(engine)));\n\n\tintel_engine_print_breadcrumbs(engine, m);\n}\n\n \nktime_t intel_engine_get_busy_time(struct intel_engine_cs *engine, ktime_t *now)\n{\n\treturn engine->busyness(engine, now);\n}\n\nstruct intel_context *\nintel_engine_create_virtual(struct intel_engine_cs **siblings,\n\t\t\t    unsigned int count, unsigned long flags)\n{\n\tif (count == 0)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (count == 1 && !(flags & FORCE_VIRTUAL))\n\t\treturn intel_context_create(siblings[0]);\n\n\tGEM_BUG_ON(!siblings[0]->cops->create_virtual);\n\treturn siblings[0]->cops->create_virtual(siblings, count, flags);\n}\n\nstatic struct i915_request *engine_execlist_find_hung_request(struct intel_engine_cs *engine)\n{\n\tstruct i915_request *request, *active = NULL;\n\n\t \n\tGEM_BUG_ON(intel_uc_uses_guc_submission(&engine->gt->uc));\n\n\t \n\tlockdep_assert_held(&engine->sched_engine->lock);\n\n\trcu_read_lock();\n\trequest = execlists_active(&engine->execlists);\n\tif (request) {\n\t\tstruct intel_timeline *tl = request->context->timeline;\n\n\t\tlist_for_each_entry_from_reverse(request, &tl->requests, link) {\n\t\t\tif (__i915_request_is_complete(request))\n\t\t\t\tbreak;\n\n\t\t\tactive = request;\n\t\t}\n\t}\n\trcu_read_unlock();\n\tif (active)\n\t\treturn active;\n\n\tlist_for_each_entry(request, &engine->sched_engine->requests,\n\t\t\t    sched.link) {\n\t\tif (i915_test_request_state(request) != I915_REQUEST_ACTIVE)\n\t\t\tcontinue;\n\n\t\tactive = request;\n\t\tbreak;\n\t}\n\n\treturn active;\n}\n\nvoid intel_engine_get_hung_entity(struct intel_engine_cs *engine,\n\t\t\t\t  struct intel_context **ce, struct i915_request **rq)\n{\n\tunsigned long flags;\n\n\t*ce = intel_engine_get_hung_context(engine);\n\tif (*ce) {\n\t\tintel_engine_clear_hung_context(engine);\n\n\t\t*rq = intel_context_get_active_request(*ce);\n\t\treturn;\n\t}\n\n\t \n\tif (intel_uc_uses_guc_submission(&engine->gt->uc))\n\t\treturn;\n\n\tspin_lock_irqsave(&engine->sched_engine->lock, flags);\n\t*rq = engine_execlist_find_hung_request(engine);\n\tif (*rq)\n\t\t*rq = i915_request_get_rcu(*rq);\n\tspin_unlock_irqrestore(&engine->sched_engine->lock, flags);\n}\n\nvoid xehp_enable_ccs_engines(struct intel_engine_cs *engine)\n{\n\t \n\tif (!CCS_MASK(engine->gt))\n\t\treturn;\n\n\tintel_uncore_write(engine->uncore, GEN12_RCU_MODE,\n\t\t\t   _MASKED_BIT_ENABLE(GEN12_RCU_MODE_CCS_ENABLE));\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_SELFTEST)\n#include \"mock_engine.c\"\n#include \"selftest_engine.c\"\n#include \"selftest_engine_cs.c\"\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}