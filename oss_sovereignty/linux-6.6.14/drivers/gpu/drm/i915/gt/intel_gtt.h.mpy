{
  "module_name": "intel_gtt.h",
  "hash_id": "8cd4817e0fe4f9f16b58074c9e4d8bd82ed47c7b76b93ad3ee6c9ba9de5a9047",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/intel_gtt.h",
  "human_readable_source": " \n \n\n#ifndef __INTEL_GTT_H__\n#define __INTEL_GTT_H__\n\n#include <linux/io-mapping.h>\n#include <linux/kref.h>\n#include <linux/mm.h>\n#include <linux/pagevec.h>\n#include <linux/scatterlist.h>\n#include <linux/workqueue.h>\n\n#include <drm/drm_mm.h>\n\n#include \"gt/intel_reset.h\"\n#include \"i915_selftest.h\"\n#include \"i915_vma_resource.h\"\n#include \"i915_vma_types.h\"\n#include \"i915_params.h\"\n#include \"intel_memory_region.h\"\n\n#define I915_GFP_ALLOW_FAIL (GFP_KERNEL | __GFP_RETRY_MAYFAIL | __GFP_NOWARN)\n\n#if IS_ENABLED(CONFIG_DRM_I915_TRACE_GTT)\n#define DBG(...) trace_printk(__VA_ARGS__)\n#else\n#define DBG(...)\n#endif\n\n#define NALLOC 3  \n\n#define I915_GTT_PAGE_SIZE_4K\tBIT_ULL(12)\n#define I915_GTT_PAGE_SIZE_64K\tBIT_ULL(16)\n#define I915_GTT_PAGE_SIZE_2M\tBIT_ULL(21)\n\n#define I915_GTT_PAGE_SIZE I915_GTT_PAGE_SIZE_4K\n#define I915_GTT_MAX_PAGE_SIZE I915_GTT_PAGE_SIZE_2M\n\n#define I915_GTT_PAGE_MASK -I915_GTT_PAGE_SIZE\n\n#define I915_GTT_MIN_ALIGNMENT I915_GTT_PAGE_SIZE\n\n#define I915_FENCE_REG_NONE -1\n#define I915_MAX_NUM_FENCES 32\n \n#define I915_MAX_NUM_FENCE_BITS 6\n\ntypedef u32 gen6_pte_t;\ntypedef u64 gen8_pte_t;\n\n#define ggtt_total_entries(ggtt) ((ggtt)->vm.total >> PAGE_SHIFT)\n\n#define I915_PTES(pte_len)\t\t((unsigned int)(PAGE_SIZE / (pte_len)))\n#define I915_PTE_MASK(pte_len)\t\t(I915_PTES(pte_len) - 1)\n#define I915_PDES\t\t\t512\n#define I915_PDE_MASK\t\t\t(I915_PDES - 1)\n\n \n#define GEN6_GTT_ADDR_ENCODE(addr)\t((addr) | (((addr) >> 28) & 0xff0))\n#define GEN6_PTE_ADDR_ENCODE(addr)\tGEN6_GTT_ADDR_ENCODE(addr)\n#define GEN6_PDE_ADDR_ENCODE(addr)\tGEN6_GTT_ADDR_ENCODE(addr)\n#define GEN6_PTE_CACHE_LLC\t\t(2 << 1)\n#define GEN6_PTE_UNCACHED\t\t(1 << 1)\n#define GEN6_PTE_VALID\t\t\tREG_BIT(0)\n\n#define GEN6_PTES\t\t\tI915_PTES(sizeof(gen6_pte_t))\n#define GEN6_PD_SIZE\t\t        (I915_PDES * PAGE_SIZE)\n#define GEN6_PD_ALIGN\t\t\t(PAGE_SIZE * 16)\n#define GEN6_PDE_SHIFT\t\t\t22\n#define GEN6_PDE_VALID\t\t\tREG_BIT(0)\n#define NUM_PTE(pde_shift)     (1 << (pde_shift - PAGE_SHIFT))\n\n#define GEN7_PTE_CACHE_L3_LLC\t\t(3 << 1)\n\n#define BYT_PTE_SNOOPED_BY_CPU_CACHES\tREG_BIT(2)\n#define BYT_PTE_WRITEABLE\t\tREG_BIT(1)\n\n#define MTL_PPGTT_PTE_PAT3\tBIT_ULL(62)\n#define GEN12_PPGTT_PTE_LM\tBIT_ULL(11)\n#define GEN12_PPGTT_PTE_PAT2\tBIT_ULL(7)\n#define GEN12_PPGTT_PTE_PAT1\tBIT_ULL(4)\n#define GEN12_PPGTT_PTE_PAT0\tBIT_ULL(3)\n\n#define GEN12_GGTT_PTE_LM\t\tBIT_ULL(1)\n#define MTL_GGTT_PTE_PAT0\t\tBIT_ULL(52)\n#define MTL_GGTT_PTE_PAT1\t\tBIT_ULL(53)\n#define GEN12_GGTT_PTE_ADDR_MASK\tGENMASK_ULL(45, 12)\n#define MTL_GGTT_PTE_PAT_MASK\t\tGENMASK_ULL(53, 52)\n\n#define GEN12_PDE_64K BIT(6)\n#define GEN12_PTE_PS64 BIT(8)\n\n \n#define HSW_CACHEABILITY_CONTROL(bits)\t((((bits) & 0x7) << 1) | \\\n\t\t\t\t\t (((bits) & 0x8) << (11 - 3)))\n#define HSW_WB_LLC_AGE3\t\t\tHSW_CACHEABILITY_CONTROL(0x2)\n#define HSW_WB_LLC_AGE0\t\t\tHSW_CACHEABILITY_CONTROL(0x3)\n#define HSW_WB_ELLC_LLC_AGE3\t\tHSW_CACHEABILITY_CONTROL(0x8)\n#define HSW_WB_ELLC_LLC_AGE0\t\tHSW_CACHEABILITY_CONTROL(0xb)\n#define HSW_WT_ELLC_LLC_AGE3\t\tHSW_CACHEABILITY_CONTROL(0x7)\n#define HSW_WT_ELLC_LLC_AGE0\t\tHSW_CACHEABILITY_CONTROL(0x6)\n#define HSW_PTE_UNCACHED\t\t(0)\n#define HSW_GTT_ADDR_ENCODE(addr)\t((addr) | (((addr) >> 28) & 0x7f0))\n#define HSW_PTE_ADDR_ENCODE(addr)\tHSW_GTT_ADDR_ENCODE(addr)\n\n \n#define GEN8_3LVL_PDPES\t\t\t4\n\n#define PPAT_UNCACHED\t\t\t(_PAGE_PWT | _PAGE_PCD)\n#define PPAT_CACHED_PDE\t\t\t0  \n#define PPAT_CACHED\t\t\t_PAGE_PAT  \n#define PPAT_DISPLAY_ELLC\t\t_PAGE_PCD  \n\n#define CHV_PPAT_SNOOP\t\t\tREG_BIT(6)\n#define GEN8_PPAT_AGE(x)\t\t((x)<<4)\n#define GEN8_PPAT_LLCeLLC\t\t(3<<2)\n#define GEN8_PPAT_LLCELLC\t\t(2<<2)\n#define GEN8_PPAT_LLC\t\t\t(1<<2)\n#define GEN8_PPAT_WB\t\t\t(3<<0)\n#define GEN8_PPAT_WT\t\t\t(2<<0)\n#define GEN8_PPAT_WC\t\t\t(1<<0)\n#define GEN8_PPAT_UC\t\t\t(0<<0)\n#define GEN8_PPAT_ELLC_OVERRIDE\t\t(0<<2)\n#define GEN8_PPAT(i, x)\t\t\t((u64)(x) << ((i) * 8))\n\n#define GEN8_PAGE_PRESENT\t\tBIT_ULL(0)\n#define GEN8_PAGE_RW\t\t\tBIT_ULL(1)\n\n#define GEN8_PDE_IPS_64K BIT(11)\n#define GEN8_PDE_PS_2M   BIT(7)\n\n#define MTL_PPAT_L4_CACHE_POLICY_MASK\tREG_GENMASK(3, 2)\n#define MTL_PAT_INDEX_COH_MODE_MASK\tREG_GENMASK(1, 0)\n#define MTL_PPAT_L4_3_UC\tREG_FIELD_PREP(MTL_PPAT_L4_CACHE_POLICY_MASK, 3)\n#define MTL_PPAT_L4_1_WT\tREG_FIELD_PREP(MTL_PPAT_L4_CACHE_POLICY_MASK, 1)\n#define MTL_PPAT_L4_0_WB\tREG_FIELD_PREP(MTL_PPAT_L4_CACHE_POLICY_MASK, 0)\n#define MTL_3_COH_2W\tREG_FIELD_PREP(MTL_PAT_INDEX_COH_MODE_MASK, 3)\n#define MTL_2_COH_1W\tREG_FIELD_PREP(MTL_PAT_INDEX_COH_MODE_MASK, 2)\n\nstruct drm_i915_gem_object;\nstruct i915_fence_reg;\nstruct i915_vma;\nstruct intel_gt;\n\n#define for_each_sgt_daddr(__dp, __iter, __sgt) \\\n\t__for_each_sgt_daddr(__dp, __iter, __sgt, I915_GTT_PAGE_SIZE)\n\nstruct i915_page_table {\n\tstruct drm_i915_gem_object *base;\n\tunion {\n\t\tatomic_t used;\n\t\tstruct i915_page_table *stash;\n\t};\n\tbool is_compact;\n};\n\nstruct i915_page_directory {\n\tstruct i915_page_table pt;\n\tspinlock_t lock;\n\tvoid **entry;\n};\n\n#define __px_choose_expr(x, type, expr, other) \\\n\t__builtin_choose_expr( \\\n\t__builtin_types_compatible_p(typeof(x), type) || \\\n\t__builtin_types_compatible_p(typeof(x), const type), \\\n\t({ type __x = (type)(x); expr; }), \\\n\tother)\n\n#define px_base(px) \\\n\t__px_choose_expr(px, struct drm_i915_gem_object *, __x, \\\n\t__px_choose_expr(px, struct i915_page_table *, __x->base, \\\n\t__px_choose_expr(px, struct i915_page_directory *, __x->pt.base, \\\n\t(void)0)))\n\nstruct page *__px_page(struct drm_i915_gem_object *p);\ndma_addr_t __px_dma(struct drm_i915_gem_object *p);\n#define px_dma(px) (__px_dma(px_base(px)))\n\nvoid *__px_vaddr(struct drm_i915_gem_object *p);\n#define px_vaddr(px) (__px_vaddr(px_base(px)))\n\n#define px_pt(px) \\\n\t__px_choose_expr(px, struct i915_page_table *, __x, \\\n\t__px_choose_expr(px, struct i915_page_directory *, &__x->pt, \\\n\t(void)0))\n#define px_used(px) (&px_pt(px)->used)\n\nstruct i915_vm_pt_stash {\n\t \n\tstruct i915_page_table *pt[2];\n\t \n\tint pt_sz;\n};\n\nstruct i915_vma_ops {\n\t \n\tvoid (*bind_vma)(struct i915_address_space *vm,\n\t\t\t struct i915_vm_pt_stash *stash,\n\t\t\t struct i915_vma_resource *vma_res,\n\t\t\t unsigned int pat_index,\n\t\t\t u32 flags);\n\t \n\tvoid (*unbind_vma)(struct i915_address_space *vm,\n\t\t\t   struct i915_vma_resource *vma_res);\n\n};\n\nstruct i915_address_space {\n\tstruct kref ref;\n\tstruct work_struct release_work;\n\n\tstruct drm_mm mm;\n\tstruct intel_gt *gt;\n\tstruct drm_i915_private *i915;\n\tstruct device *dma;\n\tu64 total;\t\t \n\tu64 reserved;\t\t \n\tu64 min_alignment[INTEL_MEMORY_STOLEN_LOCAL + 1];\n\n\tunsigned int bind_async_flags;\n\n\tstruct mutex mutex;  \n\n\tstruct kref resv_ref;  \n\tstruct dma_resv _resv;  \n#define VM_CLASS_GGTT 0\n#define VM_CLASS_PPGTT 1\n#define VM_CLASS_DPT 2\n\n\tstruct drm_i915_gem_object *scratch[4];\n\t \n\tstruct list_head bound_list;\n\n\t \n\tstruct list_head unbound_list;\n\n\t \n\tbool is_ggtt:1;\n\n\t \n\tbool is_dpt:1;\n\n\t \n\tbool has_read_only:1;\n\n\t \n\tbool skip_pte_rewrite:1;\n\n\tu8 top;\n\tu8 pd_shift;\n\tu8 scratch_order;\n\n\t \n\tunsigned long lmem_pt_obj_flags;\n\n\t \n\tstruct rb_root_cached pending_unbind;\n\n\tstruct drm_i915_gem_object *\n\t\t(*alloc_pt_dma)(struct i915_address_space *vm, int sz);\n\tstruct drm_i915_gem_object *\n\t\t(*alloc_scratch_dma)(struct i915_address_space *vm, int sz);\n\n\tu64 (*pte_encode)(dma_addr_t addr,\n\t\t\t  unsigned int pat_index,\n\t\t\t  u32 flags);  \n#define PTE_READ_ONLY\tBIT(0)\n#define PTE_LM\t\tBIT(1)\n\n\tvoid (*allocate_va_range)(struct i915_address_space *vm,\n\t\t\t\t  struct i915_vm_pt_stash *stash,\n\t\t\t\t  u64 start, u64 length);\n\tvoid (*clear_range)(struct i915_address_space *vm,\n\t\t\t    u64 start, u64 length);\n\tvoid (*scratch_range)(struct i915_address_space *vm,\n\t\t\t      u64 start, u64 length);\n\tvoid (*insert_page)(struct i915_address_space *vm,\n\t\t\t    dma_addr_t addr,\n\t\t\t    u64 offset,\n\t\t\t    unsigned int pat_index,\n\t\t\t    u32 flags);\n\tvoid (*insert_entries)(struct i915_address_space *vm,\n\t\t\t       struct i915_vma_resource *vma_res,\n\t\t\t       unsigned int pat_index,\n\t\t\t       u32 flags);\n\tvoid (*raw_insert_page)(struct i915_address_space *vm,\n\t\t\t\tdma_addr_t addr,\n\t\t\t\tu64 offset,\n\t\t\t\tunsigned int pat_index,\n\t\t\t\tu32 flags);\n\tvoid (*raw_insert_entries)(struct i915_address_space *vm,\n\t\t\t\t   struct i915_vma_resource *vma_res,\n\t\t\t\t   unsigned int pat_index,\n\t\t\t\t   u32 flags);\n\tvoid (*cleanup)(struct i915_address_space *vm);\n\n\tvoid (*foreach)(struct i915_address_space *vm,\n\t\t\tu64 start, u64 length,\n\t\t\tvoid (*fn)(struct i915_address_space *vm,\n\t\t\t\t   struct i915_page_table *pt,\n\t\t\t\t   void *data),\n\t\t\tvoid *data);\n\n\tstruct i915_vma_ops vma_ops;\n\n\tI915_SELFTEST_DECLARE(struct fault_attr fault_attr);\n\tI915_SELFTEST_DECLARE(bool scrub_64K);\n};\n\n \nstruct i915_ggtt {\n\tstruct i915_address_space vm;\n\n\tstruct io_mapping iomap;\t \n\tstruct resource gmadr;           \n\tresource_size_t mappable_end;\t \n\n\t \n\tvoid __iomem *gsm;\n\tvoid (*invalidate)(struct i915_ggtt *ggtt);\n\n\t \n\tstruct i915_ppgtt *alias;\n\n\tbool do_idle_maps;\n\n\tint mtrr;\n\n\t \n\tu32 bit_6_swizzle_x;\n\t \n\tu32 bit_6_swizzle_y;\n\n\tu32 pin_bias;\n\n\tunsigned int num_fences;\n\tstruct i915_fence_reg *fence_regs;\n\tstruct list_head fence_list;\n\n\t \n\tstruct list_head userfault_list;\n\n\tstruct mutex error_mutex;\n\tstruct drm_mm_node error_capture;\n\tstruct drm_mm_node uc_fw;\n\n\t \n\tstruct list_head gt_list;\n};\n\nstruct i915_ppgtt {\n\tstruct i915_address_space vm;\n\n\tstruct i915_page_directory *pd;\n};\n\n#define i915_is_ggtt(vm) ((vm)->is_ggtt)\n#define i915_is_dpt(vm) ((vm)->is_dpt)\n#define i915_is_ggtt_or_dpt(vm) (i915_is_ggtt(vm) || i915_is_dpt(vm))\n\nbool intel_vm_no_concurrent_access_wa(struct drm_i915_private *i915);\n\nint __must_check\ni915_vm_lock_objects(struct i915_address_space *vm, struct i915_gem_ww_ctx *ww);\n\nstatic inline bool\ni915_vm_is_4lvl(const struct i915_address_space *vm)\n{\n\treturn (vm->total - 1) >> 32;\n}\n\nstatic inline bool\ni915_vm_has_scratch_64K(struct i915_address_space *vm)\n{\n\treturn vm->scratch_order == get_order(I915_GTT_PAGE_SIZE_64K);\n}\n\nstatic inline u64 i915_vm_min_alignment(struct i915_address_space *vm,\n\t\t\t\t\tenum intel_memory_type type)\n{\n\t \n\tif ((int)type >= ARRAY_SIZE(vm->min_alignment))\n\t\ttype = INTEL_MEMORY_SYSTEM;\n\n\treturn vm->min_alignment[type];\n}\n\nstatic inline u64 i915_vm_obj_min_alignment(struct i915_address_space *vm,\n\t\t\t\t\t    struct drm_i915_gem_object  *obj)\n{\n\tstruct intel_memory_region *mr = READ_ONCE(obj->mm.region);\n\tenum intel_memory_type type = mr ? mr->type : INTEL_MEMORY_SYSTEM;\n\n\treturn i915_vm_min_alignment(vm, type);\n}\n\nstatic inline bool\ni915_vm_has_cache_coloring(struct i915_address_space *vm)\n{\n\treturn i915_is_ggtt(vm) && vm->mm.color_adjust;\n}\n\nstatic inline struct i915_ggtt *\ni915_vm_to_ggtt(struct i915_address_space *vm)\n{\n\tBUILD_BUG_ON(offsetof(struct i915_ggtt, vm));\n\tGEM_BUG_ON(!i915_is_ggtt(vm));\n\treturn container_of(vm, struct i915_ggtt, vm);\n}\n\nstatic inline struct i915_ppgtt *\ni915_vm_to_ppgtt(struct i915_address_space *vm)\n{\n\tBUILD_BUG_ON(offsetof(struct i915_ppgtt, vm));\n\tGEM_BUG_ON(i915_is_ggtt_or_dpt(vm));\n\treturn container_of(vm, struct i915_ppgtt, vm);\n}\n\nstatic inline struct i915_address_space *\ni915_vm_get(struct i915_address_space *vm)\n{\n\tkref_get(&vm->ref);\n\treturn vm;\n}\n\nstatic inline struct i915_address_space *\ni915_vm_tryget(struct i915_address_space *vm)\n{\n\treturn kref_get_unless_zero(&vm->ref) ? vm : NULL;\n}\n\nstatic inline void assert_vm_alive(struct i915_address_space *vm)\n{\n\tGEM_BUG_ON(!kref_read(&vm->ref));\n}\n\n \nstatic inline struct dma_resv *i915_vm_resv_get(struct i915_address_space *vm)\n{\n\tkref_get(&vm->resv_ref);\n\treturn &vm->_resv;\n}\n\nvoid i915_vm_release(struct kref *kref);\n\nvoid i915_vm_resv_release(struct kref *kref);\n\nstatic inline void i915_vm_put(struct i915_address_space *vm)\n{\n\tkref_put(&vm->ref, i915_vm_release);\n}\n\n \nstatic inline void i915_vm_resv_put(struct i915_address_space *vm)\n{\n\tkref_put(&vm->resv_ref, i915_vm_resv_release);\n}\n\nvoid i915_address_space_init(struct i915_address_space *vm, int subclass);\nvoid i915_address_space_fini(struct i915_address_space *vm);\n\nstatic inline u32 i915_pte_index(u64 address, unsigned int pde_shift)\n{\n\tconst u32 mask = NUM_PTE(pde_shift) - 1;\n\n\treturn (address >> PAGE_SHIFT) & mask;\n}\n\n \nstatic inline u32 i915_pte_count(u64 addr, u64 length, unsigned int pde_shift)\n{\n\tconst u64 mask = ~((1ULL << pde_shift) - 1);\n\tu64 end;\n\n\tGEM_BUG_ON(length == 0);\n\tGEM_BUG_ON(offset_in_page(addr | length));\n\n\tend = addr + length;\n\n\tif ((addr & mask) != (end & mask))\n\t\treturn NUM_PTE(pde_shift) - i915_pte_index(addr, pde_shift);\n\n\treturn i915_pte_index(end, pde_shift) - i915_pte_index(addr, pde_shift);\n}\n\nstatic inline u32 i915_pde_index(u64 addr, u32 shift)\n{\n\treturn (addr >> shift) & I915_PDE_MASK;\n}\n\nstatic inline struct i915_page_table *\ni915_pt_entry(const struct i915_page_directory * const pd,\n\t      const unsigned short n)\n{\n\treturn pd->entry[n];\n}\n\nstatic inline struct i915_page_directory *\ni915_pd_entry(const struct i915_page_directory * const pdp,\n\t      const unsigned short n)\n{\n\treturn pdp->entry[n];\n}\n\nstatic inline dma_addr_t\ni915_page_dir_dma_addr(const struct i915_ppgtt *ppgtt, const unsigned int n)\n{\n\tstruct i915_page_table *pt = ppgtt->pd->entry[n];\n\n\treturn __px_dma(pt ? px_base(pt) : ppgtt->vm.scratch[ppgtt->vm.top]);\n}\n\nvoid ppgtt_init(struct i915_ppgtt *ppgtt, struct intel_gt *gt,\n\t\tunsigned long lmem_pt_obj_flags);\nvoid intel_ggtt_bind_vma(struct i915_address_space *vm,\n\t\t\t struct i915_vm_pt_stash *stash,\n\t\t\t struct i915_vma_resource *vma_res,\n\t\t\t unsigned int pat_index,\n\t\t\t u32 flags);\nvoid intel_ggtt_unbind_vma(struct i915_address_space *vm,\n\t\t\t   struct i915_vma_resource *vma_res);\n\nint i915_ggtt_probe_hw(struct drm_i915_private *i915);\nint i915_ggtt_init_hw(struct drm_i915_private *i915);\nint i915_ggtt_enable_hw(struct drm_i915_private *i915);\nint i915_init_ggtt(struct drm_i915_private *i915);\nvoid i915_ggtt_driver_release(struct drm_i915_private *i915);\nvoid i915_ggtt_driver_late_release(struct drm_i915_private *i915);\nstruct i915_ggtt *i915_ggtt_create(struct drm_i915_private *i915);\n\nstatic inline bool i915_ggtt_has_aperture(const struct i915_ggtt *ggtt)\n{\n\treturn ggtt->mappable_end > 0;\n}\n\nint i915_ppgtt_init_hw(struct intel_gt *gt);\n\nstruct i915_ppgtt *i915_ppgtt_create(struct intel_gt *gt,\n\t\t\t\t     unsigned long lmem_pt_obj_flags);\n\nvoid i915_ggtt_suspend_vm(struct i915_address_space *vm);\nbool i915_ggtt_resume_vm(struct i915_address_space *vm);\nvoid i915_ggtt_suspend(struct i915_ggtt *gtt);\nvoid i915_ggtt_resume(struct i915_ggtt *ggtt);\n\nvoid\nfill_page_dma(struct drm_i915_gem_object *p, const u64 val, unsigned int count);\n\n#define fill_px(px, v) fill_page_dma(px_base(px), (v), PAGE_SIZE / sizeof(u64))\n#define fill32_px(px, v) do {\t\t\t\t\t\t\\\n\tu64 v__ = lower_32_bits(v);\t\t\t\t\t\\\n\tfill_px((px), v__ << 32 | v__);\t\t\t\t\t\\\n} while (0)\n\nint setup_scratch_page(struct i915_address_space *vm);\nvoid free_scratch(struct i915_address_space *vm);\n\nstruct drm_i915_gem_object *alloc_pt_dma(struct i915_address_space *vm, int sz);\nstruct drm_i915_gem_object *alloc_pt_lmem(struct i915_address_space *vm, int sz);\nstruct i915_page_table *alloc_pt(struct i915_address_space *vm, int sz);\nstruct i915_page_directory *alloc_pd(struct i915_address_space *vm);\nstruct i915_page_directory *__alloc_pd(int npde);\n\nint map_pt_dma(struct i915_address_space *vm, struct drm_i915_gem_object *obj);\nint map_pt_dma_locked(struct i915_address_space *vm, struct drm_i915_gem_object *obj);\n\nvoid free_px(struct i915_address_space *vm,\n\t     struct i915_page_table *pt, int lvl);\n#define free_pt(vm, px) free_px(vm, px, 0)\n#define free_pd(vm, px) free_px(vm, px_pt(px), 1)\n\nvoid\n__set_pd_entry(struct i915_page_directory * const pd,\n\t       const unsigned short idx,\n\t       struct i915_page_table *pt,\n\t       u64 (*encode)(const dma_addr_t, const enum i915_cache_level));\n\n#define set_pd_entry(pd, idx, to) \\\n\t__set_pd_entry((pd), (idx), px_pt(to), gen8_pde_encode)\n\nvoid\nclear_pd_entry(struct i915_page_directory * const pd,\n\t       const unsigned short idx,\n\t       const struct drm_i915_gem_object * const scratch);\n\nbool\nrelease_pd_entry(struct i915_page_directory * const pd,\n\t\t const unsigned short idx,\n\t\t struct i915_page_table * const pt,\n\t\t const struct drm_i915_gem_object * const scratch);\nvoid gen6_ggtt_invalidate(struct i915_ggtt *ggtt);\n\nvoid ppgtt_bind_vma(struct i915_address_space *vm,\n\t\t    struct i915_vm_pt_stash *stash,\n\t\t    struct i915_vma_resource *vma_res,\n\t\t    unsigned int pat_index,\n\t\t    u32 flags);\nvoid ppgtt_unbind_vma(struct i915_address_space *vm,\n\t\t      struct i915_vma_resource *vma_res);\n\nvoid gtt_write_workarounds(struct intel_gt *gt);\n\nvoid setup_private_pat(struct intel_gt *gt);\n\nint i915_vm_alloc_pt_stash(struct i915_address_space *vm,\n\t\t\t   struct i915_vm_pt_stash *stash,\n\t\t\t   u64 size);\nint i915_vm_map_pt_stash(struct i915_address_space *vm,\n\t\t\t struct i915_vm_pt_stash *stash);\nvoid i915_vm_free_pt_stash(struct i915_address_space *vm,\n\t\t\t   struct i915_vm_pt_stash *stash);\n\nstruct i915_vma *\n__vm_create_scratch_for_read(struct i915_address_space *vm, unsigned long size);\n\nstruct i915_vma *\n__vm_create_scratch_for_read_pinned(struct i915_address_space *vm, unsigned long size);\n\nstatic inline struct sgt_dma {\n\tstruct scatterlist *sg;\n\tdma_addr_t dma, max;\n} sgt_dma(struct i915_vma_resource *vma_res) {\n\tstruct scatterlist *sg = vma_res->bi.pages->sgl;\n\tdma_addr_t addr = sg_dma_address(sg);\n\n\treturn (struct sgt_dma){ sg, addr, addr + sg_dma_len(sg) };\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}