{
  "module_name": "selftest_lrc.c",
  "hash_id": "ad09bed6a6bc8c493f93ff77ed2362159f20ec28ced8beeac22d6ffa915f90b6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/selftest_lrc.c",
  "human_readable_source": "\n \n\n#include <linux/prime_numbers.h>\n\n#include \"gem/i915_gem_internal.h\"\n\n#include \"i915_selftest.h\"\n#include \"intel_engine_heartbeat.h\"\n#include \"intel_engine_pm.h\"\n#include \"intel_reset.h\"\n#include \"intel_ring.h\"\n#include \"selftest_engine_heartbeat.h\"\n#include \"selftests/i915_random.h\"\n#include \"selftests/igt_flush_test.h\"\n#include \"selftests/igt_live_test.h\"\n#include \"selftests/igt_spinner.h\"\n#include \"selftests/lib_sw_fence.h\"\n#include \"shmem_utils.h\"\n\n#include \"gem/selftests/igt_gem_utils.h\"\n#include \"gem/selftests/mock_context.h\"\n\n#define CS_GPR(engine, n) ((engine)->mmio_base + 0x600 + (n) * 4)\n#define NUM_GPR 16\n#define NUM_GPR_DW (NUM_GPR * 2)  \n\n#define LRI_HEADER MI_INSTR(0x22, 0)\n#define LRI_LENGTH_MASK GENMASK(7, 0)\n\nstatic struct i915_vma *create_scratch(struct intel_gt *gt)\n{\n\treturn __vm_create_scratch_for_read_pinned(&gt->ggtt->vm, PAGE_SIZE);\n}\n\nstatic bool is_active(struct i915_request *rq)\n{\n\tif (i915_request_is_active(rq))\n\t\treturn true;\n\n\tif (i915_request_on_hold(rq))\n\t\treturn true;\n\n\tif (i915_request_has_initial_breadcrumb(rq) && i915_request_started(rq))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int wait_for_submit(struct intel_engine_cs *engine,\n\t\t\t   struct i915_request *rq,\n\t\t\t   unsigned long timeout)\n{\n\t \n\ttasklet_hi_schedule(&engine->sched_engine->tasklet);\n\n\ttimeout += jiffies;\n\tdo {\n\t\tbool done = time_after(jiffies, timeout);\n\n\t\tif (i915_request_completed(rq))  \n\t\t\treturn 0;\n\n\t\t \n\t\tintel_engine_flush_submission(engine);\n\t\tif (!READ_ONCE(engine->execlists.pending[0]) && is_active(rq))\n\t\t\treturn 0;\n\n\t\tif (done)\n\t\t\treturn -ETIME;\n\n\t\tcond_resched();\n\t} while (1);\n}\n\nstatic int emit_semaphore_signal(struct intel_context *ce, void *slot)\n{\n\tconst u32 offset =\n\t\ti915_ggtt_offset(ce->engine->status_page.vma) +\n\t\toffset_in_page(slot);\n\tstruct i915_request *rq;\n\tu32 *cs;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs)) {\n\t\ti915_request_add(rq);\n\t\treturn PTR_ERR(cs);\n\t}\n\n\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t*cs++ = offset;\n\t*cs++ = 0;\n\t*cs++ = 1;\n\n\tintel_ring_advance(rq, cs);\n\n\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\n\ti915_request_add(rq);\n\treturn 0;\n}\n\nstatic int context_flush(struct intel_context *ce, long timeout)\n{\n\tstruct i915_request *rq;\n\tstruct dma_fence *fence;\n\tint err = 0;\n\n\trq = intel_engine_create_kernel_request(ce->engine);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tfence = i915_active_fence_get(&ce->timeline->last_request);\n\tif (fence) {\n\t\ti915_request_await_dma_fence(rq, fence);\n\t\tdma_fence_put(fence);\n\t}\n\n\trq = i915_request_get(rq);\n\ti915_request_add(rq);\n\tif (i915_request_wait(rq, 0, timeout) < 0)\n\t\terr = -ETIME;\n\ti915_request_put(rq);\n\n\trmb();  \n\treturn err;\n}\n\nstatic int get_lri_mask(struct intel_engine_cs *engine, u32 lri)\n{\n\tif ((lri & MI_LRI_LRM_CS_MMIO) == 0)\n\t\treturn ~0u;\n\n\tif (GRAPHICS_VER(engine->i915) < 12)\n\t\treturn 0xfff;\n\n\tswitch (engine->class) {\n\tdefault:\n\tcase RENDER_CLASS:\n\tcase COMPUTE_CLASS:\n\t\treturn 0x07ff;\n\tcase COPY_ENGINE_CLASS:\n\t\treturn 0x0fff;\n\tcase VIDEO_DECODE_CLASS:\n\tcase VIDEO_ENHANCEMENT_CLASS:\n\t\treturn 0x3fff;\n\t}\n}\n\nstatic int live_lrc_layout(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tu32 *lrc;\n\tint err;\n\n\t \n\n\tlrc = (u32 *)__get_free_page(GFP_KERNEL);  \n\tif (!lrc)\n\t\treturn -ENOMEM;\n\tGEM_BUG_ON(offset_in_page(lrc));\n\n\terr = 0;\n\tfor_each_engine(engine, gt, id) {\n\t\tu32 *hw;\n\t\tint dw;\n\n\t\tif (!engine->default_state)\n\t\t\tcontinue;\n\n\t\thw = shmem_pin_map(engine->default_state);\n\t\tif (!hw) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\thw += LRC_STATE_OFFSET / sizeof(*hw);\n\n\t\t__lrc_init_regs(memset(lrc, POISON_INUSE, PAGE_SIZE),\n\t\t\t\tengine->kernel_context, engine, true);\n\n\t\tdw = 0;\n\t\tdo {\n\t\t\tu32 lri = READ_ONCE(hw[dw]);\n\t\t\tu32 lri_mask;\n\n\t\t\tif (lri == 0) {\n\t\t\t\tdw++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (lrc[dw] == 0) {\n\t\t\t\tpr_debug(\"%s: skipped instruction %x at dword %d\\n\",\n\t\t\t\t\t engine->name, lri, dw);\n\t\t\t\tdw++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif ((lri & GENMASK(31, 23)) != LRI_HEADER) {\n\t\t\t\tpr_err(\"%s: Expected LRI command at dword %d, found %08x\\n\",\n\t\t\t\t       engine->name, dw, lri);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (lrc[dw] != lri) {\n\t\t\t\tpr_err(\"%s: LRI command mismatch at dword %d, expected %08x found %08x\\n\",\n\t\t\t\t       engine->name, dw, lri, lrc[dw]);\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t \n\t\t\tlri_mask = get_lri_mask(engine, lri);\n\n\t\t\tlri &= 0x7f;\n\t\t\tlri++;\n\t\t\tdw++;\n\n\t\t\twhile (lri) {\n\t\t\t\tu32 offset = READ_ONCE(hw[dw]);\n\n\t\t\t\tif ((offset ^ lrc[dw]) & lri_mask) {\n\t\t\t\t\tpr_err(\"%s: Different registers found at dword %d, expected %x, found %x\\n\",\n\t\t\t\t\t       engine->name, dw, offset, lrc[dw]);\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t \n\t\t\t\tdw += 2;\n\t\t\t\tlri -= 2;\n\t\t\t}\n\t\t} while (!err && (lrc[dw] & ~BIT(0)) != MI_BATCH_BUFFER_END);\n\n\t\tif (err) {\n\t\t\tpr_info(\"%s: HW register image:\\n\", engine->name);\n\t\t\tigt_hexdump(hw, PAGE_SIZE);\n\n\t\t\tpr_info(\"%s: SW register image:\\n\", engine->name);\n\t\t\tigt_hexdump(lrc, PAGE_SIZE);\n\t\t}\n\n\t\tshmem_unpin_map(engine->default_state, hw);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tfree_page((unsigned long)lrc);\n\treturn err;\n}\n\nstatic int find_offset(const u32 *lri, u32 offset)\n{\n\tint i;\n\n\tfor (i = 0; i < PAGE_SIZE / sizeof(u32); i++)\n\t\tif (lri[i] == offset)\n\t\t\treturn i;\n\n\treturn -1;\n}\n\nstatic int live_lrc_fixed(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\tconst struct {\n\t\t\tu32 reg;\n\t\t\tu32 offset;\n\t\t\tconst char *name;\n\t\t} tbl[] = {\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_START(engine->mmio_base)),\n\t\t\t\tCTX_RING_START - 1,\n\t\t\t\t\"RING_START\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_CTL(engine->mmio_base)),\n\t\t\t\tCTX_RING_CTL - 1,\n\t\t\t\t\"RING_CTL\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_HEAD(engine->mmio_base)),\n\t\t\t\tCTX_RING_HEAD - 1,\n\t\t\t\t\"RING_HEAD\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_TAIL(engine->mmio_base)),\n\t\t\t\tCTX_RING_TAIL - 1,\n\t\t\t\t\"RING_TAIL\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_MI_MODE(engine->mmio_base)),\n\t\t\t\tlrc_ring_mi_mode(engine),\n\t\t\t\t\"RING_MI_MODE\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_BBSTATE(engine->mmio_base)),\n\t\t\t\tCTX_BB_STATE - 1,\n\t\t\t\t\"BB_STATE\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_BB_PER_CTX_PTR(engine->mmio_base)),\n\t\t\t\tlrc_ring_wa_bb_per_ctx(engine),\n\t\t\t\t\"RING_BB_PER_CTX_PTR\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_INDIRECT_CTX(engine->mmio_base)),\n\t\t\t\tlrc_ring_indirect_ptr(engine),\n\t\t\t\t\"RING_INDIRECT_CTX_PTR\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_INDIRECT_CTX_OFFSET(engine->mmio_base)),\n\t\t\t\tlrc_ring_indirect_offset(engine),\n\t\t\t\t\"RING_INDIRECT_CTX_OFFSET\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_CTX_TIMESTAMP(engine->mmio_base)),\n\t\t\t\tCTX_TIMESTAMP - 1,\n\t\t\t\t\"RING_CTX_TIMESTAMP\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(GEN8_RING_CS_GPR(engine->mmio_base, 0)),\n\t\t\t\tlrc_ring_gpr0(engine),\n\t\t\t\t\"RING_CS_GPR0\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_CMD_BUF_CCTL(engine->mmio_base)),\n\t\t\t\tlrc_ring_cmd_buf_cctl(engine),\n\t\t\t\t\"RING_CMD_BUF_CCTL\"\n\t\t\t},\n\t\t\t{\n\t\t\t\ti915_mmio_reg_offset(RING_BB_OFFSET(engine->mmio_base)),\n\t\t\t\tlrc_ring_bb_offset(engine),\n\t\t\t\t\"RING_BB_OFFSET\"\n\t\t\t},\n\t\t\t{ },\n\t\t}, *t;\n\t\tu32 *hw;\n\n\t\tif (!engine->default_state)\n\t\t\tcontinue;\n\n\t\thw = shmem_pin_map(engine->default_state);\n\t\tif (!hw) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\thw += LRC_STATE_OFFSET / sizeof(*hw);\n\n\t\tfor (t = tbl; t->name; t++) {\n\t\t\tint dw = find_offset(hw, t->reg);\n\n\t\t\tif (dw != t->offset) {\n\t\t\t\tpr_err(\"%s: Offset for %s [0x%x] mismatch, found %x, expected %x\\n\",\n\t\t\t\t       engine->name,\n\t\t\t\t       t->name,\n\t\t\t\t       t->reg,\n\t\t\t\t       dw,\n\t\t\t\t       t->offset);\n\t\t\t\terr = -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\tshmem_unpin_map(engine->default_state, hw);\n\t}\n\n\treturn err;\n}\n\nstatic int __live_lrc_state(struct intel_engine_cs *engine,\n\t\t\t    struct i915_vma *scratch)\n{\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tstruct i915_gem_ww_ctx ww;\n\tenum {\n\t\tRING_START_IDX = 0,\n\t\tRING_TAIL_IDX,\n\t\tMAX_IDX\n\t};\n\tu32 expected[MAX_IDX];\n\tu32 *cs;\n\tint err;\n\tint n;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\ti915_gem_ww_ctx_init(&ww, false);\nretry:\n\terr = i915_gem_object_lock(scratch->obj, &ww);\n\tif (!err)\n\t\terr = intel_context_pin_ww(ce, &ww);\n\tif (err)\n\t\tgoto err_put;\n\n\trq = i915_request_create(ce);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_unpin;\n\t}\n\n\tcs = intel_ring_begin(rq, 4 * MAX_IDX);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\ti915_request_add(rq);\n\t\tgoto err_unpin;\n\t}\n\n\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t*cs++ = i915_mmio_reg_offset(RING_START(engine->mmio_base));\n\t*cs++ = i915_ggtt_offset(scratch) + RING_START_IDX * sizeof(u32);\n\t*cs++ = 0;\n\n\texpected[RING_START_IDX] = i915_ggtt_offset(ce->ring->vma);\n\n\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t*cs++ = i915_mmio_reg_offset(RING_TAIL(engine->mmio_base));\n\t*cs++ = i915_ggtt_offset(scratch) + RING_TAIL_IDX * sizeof(u32);\n\t*cs++ = 0;\n\n\terr = i915_vma_move_to_active(scratch, rq, EXEC_OBJECT_WRITE);\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (err)\n\t\tgoto err_rq;\n\n\tintel_engine_flush_submission(engine);\n\texpected[RING_TAIL_IDX] = ce->ring->tail;\n\n\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\terr = -ETIME;\n\t\tgoto err_rq;\n\t}\n\n\tcs = i915_gem_object_pin_map(scratch->obj, I915_MAP_WB);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_rq;\n\t}\n\n\tfor (n = 0; n < MAX_IDX; n++) {\n\t\tif (cs[n] != expected[n]) {\n\t\t\tpr_err(\"%s: Stored register[%d] value[0x%x] did not match expected[0x%x]\\n\",\n\t\t\t       engine->name, n, cs[n], expected[n]);\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\ti915_gem_object_unpin_map(scratch->obj);\n\nerr_rq:\n\ti915_request_put(rq);\nerr_unpin:\n\tintel_context_unpin(ce);\nerr_put:\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\tintel_context_put(ce);\n\treturn err;\n}\n\nstatic int live_lrc_state(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct i915_vma *scratch;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tscratch = create_scratch(gt);\n\tif (IS_ERR(scratch))\n\t\treturn PTR_ERR(scratch);\n\n\tfor_each_engine(engine, gt, id) {\n\t\terr = __live_lrc_state(engine, scratch);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\ti915_vma_unpin_and_release(&scratch, 0);\n\treturn err;\n}\n\nstatic int gpr_make_dirty(struct intel_context *ce)\n{\n\tstruct i915_request *rq;\n\tu32 *cs;\n\tint n;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tcs = intel_ring_begin(rq, 2 * NUM_GPR_DW + 2);\n\tif (IS_ERR(cs)) {\n\t\ti915_request_add(rq);\n\t\treturn PTR_ERR(cs);\n\t}\n\n\t*cs++ = MI_LOAD_REGISTER_IMM(NUM_GPR_DW);\n\tfor (n = 0; n < NUM_GPR_DW; n++) {\n\t\t*cs++ = CS_GPR(ce->engine, n);\n\t\t*cs++ = STACK_MAGIC;\n\t}\n\t*cs++ = MI_NOOP;\n\n\tintel_ring_advance(rq, cs);\n\n\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\n\ti915_request_add(rq);\n\n\treturn 0;\n}\n\nstatic struct i915_request *\n__gpr_read(struct intel_context *ce, struct i915_vma *scratch, u32 *slot)\n{\n\tconst u32 offset =\n\t\ti915_ggtt_offset(ce->engine->status_page.vma) +\n\t\toffset_in_page(slot);\n\tstruct i915_request *rq;\n\tu32 *cs;\n\tint err;\n\tint n;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn rq;\n\n\tcs = intel_ring_begin(rq, 6 + 4 * NUM_GPR_DW);\n\tif (IS_ERR(cs)) {\n\t\ti915_request_add(rq);\n\t\treturn ERR_CAST(cs);\n\t}\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_ENABLE;\n\t*cs++ = MI_NOOP;\n\n\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\tMI_SEMAPHORE_GLOBAL_GTT |\n\t\tMI_SEMAPHORE_POLL |\n\t\tMI_SEMAPHORE_SAD_NEQ_SDD;\n\t*cs++ = 0;\n\t*cs++ = offset;\n\t*cs++ = 0;\n\n\tfor (n = 0; n < NUM_GPR_DW; n++) {\n\t\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t\t*cs++ = CS_GPR(ce->engine, n);\n\t\t*cs++ = i915_ggtt_offset(scratch) + n * sizeof(u32);\n\t\t*cs++ = 0;\n\t}\n\n\terr = igt_vma_move_to_active_unlocked(scratch, rq, EXEC_OBJECT_WRITE);\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (err) {\n\t\ti915_request_put(rq);\n\t\trq = ERR_PTR(err);\n\t}\n\n\treturn rq;\n}\n\nstatic int __live_lrc_gpr(struct intel_engine_cs *engine,\n\t\t\t  struct i915_vma *scratch,\n\t\t\t  bool preempt)\n{\n\tu32 *slot = memset32(engine->status_page.addr + 1000, 0, 4);\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tu32 *cs;\n\tint err;\n\tint n;\n\n\tif (GRAPHICS_VER(engine->i915) < 9 && engine->class != RENDER_CLASS)\n\t\treturn 0;  \n\n\terr = gpr_make_dirty(engine->kernel_context);\n\tif (err)\n\t\treturn err;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\trq = __gpr_read(ce, scratch, slot);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_put;\n\t}\n\n\terr = wait_for_submit(engine, rq, HZ / 2);\n\tif (err)\n\t\tgoto err_rq;\n\n\tif (preempt) {\n\t\terr = gpr_make_dirty(engine->kernel_context);\n\t\tif (err)\n\t\t\tgoto err_rq;\n\n\t\terr = emit_semaphore_signal(engine->kernel_context, slot);\n\t\tif (err)\n\t\t\tgoto err_rq;\n\n\t\terr = wait_for_submit(engine, rq, HZ / 2);\n\t\tif (err)\n\t\t\tgoto err_rq;\n\t} else {\n\t\tslot[0] = 1;\n\t\twmb();\n\t}\n\n\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\terr = -ETIME;\n\t\tgoto err_rq;\n\t}\n\n\tcs = i915_gem_object_pin_map_unlocked(scratch->obj, I915_MAP_WB);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_rq;\n\t}\n\n\tfor (n = 0; n < NUM_GPR_DW; n++) {\n\t\tif (cs[n]) {\n\t\t\tpr_err(\"%s: GPR[%d].%s was not zero, found 0x%08x!\\n\",\n\t\t\t       engine->name,\n\t\t\t       n / 2, n & 1 ? \"udw\" : \"ldw\",\n\t\t\t       cs[n]);\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\ti915_gem_object_unpin_map(scratch->obj);\n\nerr_rq:\n\tmemset32(&slot[0], -1, 4);\n\twmb();\n\ti915_request_put(rq);\nerr_put:\n\tintel_context_put(ce);\n\treturn err;\n}\n\nstatic int live_lrc_gpr(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct i915_vma *scratch;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tscratch = create_scratch(gt);\n\tif (IS_ERR(scratch))\n\t\treturn PTR_ERR(scratch);\n\n\tfor_each_engine(engine, gt, id) {\n\t\tst_engine_heartbeat_disable(engine);\n\n\t\terr = __live_lrc_gpr(engine, scratch, false);\n\t\tif (err)\n\t\t\tgoto err;\n\n\t\terr = __live_lrc_gpr(engine, scratch, true);\n\t\tif (err)\n\t\t\tgoto err;\n\nerr:\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (igt_flush_test(gt->i915))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\ti915_vma_unpin_and_release(&scratch, 0);\n\treturn err;\n}\n\nstatic struct i915_request *\ncreate_timestamp(struct intel_context *ce, void *slot, int idx)\n{\n\tconst u32 offset =\n\t\ti915_ggtt_offset(ce->engine->status_page.vma) +\n\t\toffset_in_page(slot);\n\tstruct i915_request *rq;\n\tu32 *cs;\n\tint err;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn rq;\n\n\tcs = intel_ring_begin(rq, 10);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err;\n\t}\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_ENABLE;\n\t*cs++ = MI_NOOP;\n\n\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\tMI_SEMAPHORE_GLOBAL_GTT |\n\t\tMI_SEMAPHORE_POLL |\n\t\tMI_SEMAPHORE_SAD_NEQ_SDD;\n\t*cs++ = 0;\n\t*cs++ = offset;\n\t*cs++ = 0;\n\n\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t*cs++ = i915_mmio_reg_offset(RING_CTX_TIMESTAMP(rq->engine->mmio_base));\n\t*cs++ = offset + idx * sizeof(u32);\n\t*cs++ = 0;\n\n\tintel_ring_advance(rq, cs);\n\n\terr = 0;\nerr:\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\tif (err) {\n\t\ti915_request_put(rq);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn rq;\n}\n\nstruct lrc_timestamp {\n\tstruct intel_engine_cs *engine;\n\tstruct intel_context *ce[2];\n\tu32 poison;\n};\n\nstatic bool timestamp_advanced(u32 start, u32 end)\n{\n\treturn (s32)(end - start) > 0;\n}\n\nstatic int __lrc_timestamp(const struct lrc_timestamp *arg, bool preempt)\n{\n\tu32 *slot = memset32(arg->engine->status_page.addr + 1000, 0, 4);\n\tstruct i915_request *rq;\n\tu32 timestamp;\n\tint err = 0;\n\n\targ->ce[0]->lrc_reg_state[CTX_TIMESTAMP] = arg->poison;\n\trq = create_timestamp(arg->ce[0], slot, 1);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\terr = wait_for_submit(rq->engine, rq, HZ / 2);\n\tif (err)\n\t\tgoto err;\n\n\tif (preempt) {\n\t\targ->ce[1]->lrc_reg_state[CTX_TIMESTAMP] = 0xdeadbeef;\n\t\terr = emit_semaphore_signal(arg->ce[1], slot);\n\t\tif (err)\n\t\t\tgoto err;\n\t} else {\n\t\tslot[0] = 1;\n\t\twmb();\n\t}\n\n\t \n\terr = context_flush(arg->ce[0], HZ / 2);\n\tif (err)\n\t\tgoto err;\n\n\tif (!timestamp_advanced(arg->poison, slot[1])) {\n\t\tpr_err(\"%s(%s): invalid timestamp on restore, context:%x, request:%x\\n\",\n\t\t       arg->engine->name, preempt ? \"preempt\" : \"simple\",\n\t\t       arg->poison, slot[1]);\n\t\terr = -EINVAL;\n\t}\n\n\ttimestamp = READ_ONCE(arg->ce[0]->lrc_reg_state[CTX_TIMESTAMP]);\n\tif (!timestamp_advanced(slot[1], timestamp)) {\n\t\tpr_err(\"%s(%s): invalid timestamp on save, request:%x, context:%x\\n\",\n\t\t       arg->engine->name, preempt ? \"preempt\" : \"simple\",\n\t\t       slot[1], timestamp);\n\t\terr = -EINVAL;\n\t}\n\nerr:\n\tmemset32(slot, -1, 4);\n\ti915_request_put(rq);\n\treturn err;\n}\n\nstatic int live_lrc_timestamp(void *arg)\n{\n\tstruct lrc_timestamp data = {};\n\tstruct intel_gt *gt = arg;\n\tenum intel_engine_id id;\n\tconst u32 poison[] = {\n\t\t0,\n\t\tS32_MAX,\n\t\t(u32)S32_MAX + 1,\n\t\tU32_MAX,\n\t};\n\n\t \n\n\tfor_each_engine(data.engine, gt, id) {\n\t\tint i, err = 0;\n\n\t\tst_engine_heartbeat_disable(data.engine);\n\n\t\tfor (i = 0; i < ARRAY_SIZE(data.ce); i++) {\n\t\t\tstruct intel_context *tmp;\n\n\t\t\ttmp = intel_context_create(data.engine);\n\t\t\tif (IS_ERR(tmp)) {\n\t\t\t\terr = PTR_ERR(tmp);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\terr = intel_context_pin(tmp);\n\t\t\tif (err) {\n\t\t\t\tintel_context_put(tmp);\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\t\tdata.ce[i] = tmp;\n\t\t}\n\n\t\tfor (i = 0; i < ARRAY_SIZE(poison); i++) {\n\t\t\tdata.poison = poison[i];\n\n\t\t\terr = __lrc_timestamp(&data, false);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\n\t\t\terr = __lrc_timestamp(&data, true);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\nerr:\n\t\tst_engine_heartbeat_enable(data.engine);\n\t\tfor (i = 0; i < ARRAY_SIZE(data.ce); i++) {\n\t\t\tif (!data.ce[i])\n\t\t\t\tbreak;\n\n\t\t\tintel_context_unpin(data.ce[i]);\n\t\t\tintel_context_put(data.ce[i]);\n\t\t}\n\n\t\tif (igt_flush_test(gt->i915))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic struct i915_vma *\ncreate_user_vma(struct i915_address_space *vm, unsigned long size)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\tint err;\n\n\tobj = i915_gem_object_create_internal(vm->i915, size);\n\tif (IS_ERR(obj))\n\t\treturn ERR_CAST(obj);\n\n\tvma = i915_vma_instance(obj, vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn vma;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\tif (err) {\n\t\ti915_gem_object_put(obj);\n\t\treturn ERR_PTR(err);\n\t}\n\n\treturn vma;\n}\n\nstatic u32 safe_poison(u32 offset, u32 poison)\n{\n\t \n\tif (offset == i915_mmio_reg_offset(RING_PREDICATE_RESULT(0)))\n\t\tpoison &= ~REG_BIT(0);\n\n\treturn poison;\n}\n\nstatic struct i915_vma *\nstore_context(struct intel_context *ce, struct i915_vma *scratch)\n{\n\tstruct i915_vma *batch;\n\tu32 dw, x, *cs, *hw;\n\tu32 *defaults;\n\n\tbatch = create_user_vma(ce->vm, SZ_64K);\n\tif (IS_ERR(batch))\n\t\treturn batch;\n\n\tcs = i915_gem_object_pin_map_unlocked(batch->obj, I915_MAP_WC);\n\tif (IS_ERR(cs)) {\n\t\ti915_vma_put(batch);\n\t\treturn ERR_CAST(cs);\n\t}\n\n\tdefaults = shmem_pin_map(ce->engine->default_state);\n\tif (!defaults) {\n\t\ti915_gem_object_unpin_map(batch->obj);\n\t\ti915_vma_put(batch);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tx = 0;\n\tdw = 0;\n\thw = defaults;\n\thw += LRC_STATE_OFFSET / sizeof(*hw);\n\tdo {\n\t\tu32 len = hw[dw] & LRI_LENGTH_MASK;\n\n\t\t \n\t\tif ((hw[dw] >> INSTR_CLIENT_SHIFT) != INSTR_MI_CLIENT)\n\t\t\tbreak;\n\n\t\tif (hw[dw] == 0) {\n\t\t\tdw++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif ((hw[dw] & GENMASK(31, 23)) != LRI_HEADER) {\n\t\t\t \n\t\t\tdw += len + 2;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!len) {\n\t\t\tpr_err(\"%s: invalid LRI found in context image\\n\",\n\t\t\t       ce->engine->name);\n\t\t\tigt_hexdump(defaults, PAGE_SIZE);\n\t\t\tbreak;\n\t\t}\n\n\t\tdw++;\n\t\tlen = (len + 1) / 2;\n\t\twhile (len--) {\n\t\t\t*cs++ = MI_STORE_REGISTER_MEM_GEN8;\n\t\t\t*cs++ = hw[dw];\n\t\t\t*cs++ = lower_32_bits(i915_vma_offset(scratch) + x);\n\t\t\t*cs++ = upper_32_bits(i915_vma_offset(scratch) + x);\n\n\t\t\tdw += 2;\n\t\t\tx += 4;\n\t\t}\n\t} while (dw < PAGE_SIZE / sizeof(u32) &&\n\t\t (hw[dw] & ~BIT(0)) != MI_BATCH_BUFFER_END);\n\n\t*cs++ = MI_BATCH_BUFFER_END;\n\n\tshmem_unpin_map(ce->engine->default_state, defaults);\n\n\ti915_gem_object_flush_map(batch->obj);\n\ti915_gem_object_unpin_map(batch->obj);\n\n\treturn batch;\n}\n\nstatic struct i915_request *\nrecord_registers(struct intel_context *ce,\n\t\t struct i915_vma *before,\n\t\t struct i915_vma *after,\n\t\t u32 *sema)\n{\n\tstruct i915_vma *b_before, *b_after;\n\tstruct i915_request *rq;\n\tu32 *cs;\n\tint err;\n\n\tb_before = store_context(ce, before);\n\tif (IS_ERR(b_before))\n\t\treturn ERR_CAST(b_before);\n\n\tb_after = store_context(ce, after);\n\tif (IS_ERR(b_after)) {\n\t\trq = ERR_CAST(b_after);\n\t\tgoto err_before;\n\t}\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\tgoto err_after;\n\n\terr = igt_vma_move_to_active_unlocked(before, rq, EXEC_OBJECT_WRITE);\n\tif (err)\n\t\tgoto err_rq;\n\n\terr = igt_vma_move_to_active_unlocked(b_before, rq, 0);\n\tif (err)\n\t\tgoto err_rq;\n\n\terr = igt_vma_move_to_active_unlocked(after, rq, EXEC_OBJECT_WRITE);\n\tif (err)\n\t\tgoto err_rq;\n\n\terr = igt_vma_move_to_active_unlocked(b_after, rq, 0);\n\tif (err)\n\t\tgoto err_rq;\n\n\tcs = intel_ring_begin(rq, 14);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_rq;\n\t}\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_DISABLE;\n\t*cs++ = MI_BATCH_BUFFER_START_GEN8 | BIT(8);\n\t*cs++ = lower_32_bits(i915_vma_offset(b_before));\n\t*cs++ = upper_32_bits(i915_vma_offset(b_before));\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_ENABLE;\n\t*cs++ = MI_SEMAPHORE_WAIT |\n\t\tMI_SEMAPHORE_GLOBAL_GTT |\n\t\tMI_SEMAPHORE_POLL |\n\t\tMI_SEMAPHORE_SAD_NEQ_SDD;\n\t*cs++ = 0;\n\t*cs++ = i915_ggtt_offset(ce->engine->status_page.vma) +\n\t\toffset_in_page(sema);\n\t*cs++ = 0;\n\t*cs++ = MI_NOOP;\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_DISABLE;\n\t*cs++ = MI_BATCH_BUFFER_START_GEN8 | BIT(8);\n\t*cs++ = lower_32_bits(i915_vma_offset(b_after));\n\t*cs++ = upper_32_bits(i915_vma_offset(b_after));\n\n\tintel_ring_advance(rq, cs);\n\n\tWRITE_ONCE(*sema, 0);\n\ti915_request_get(rq);\n\ti915_request_add(rq);\nerr_after:\n\ti915_vma_put(b_after);\nerr_before:\n\ti915_vma_put(b_before);\n\treturn rq;\n\nerr_rq:\n\ti915_request_add(rq);\n\trq = ERR_PTR(err);\n\tgoto err_after;\n}\n\nstatic struct i915_vma *load_context(struct intel_context *ce, u32 poison)\n{\n\tstruct i915_vma *batch;\n\tu32 dw, *cs, *hw;\n\tu32 *defaults;\n\n\tbatch = create_user_vma(ce->vm, SZ_64K);\n\tif (IS_ERR(batch))\n\t\treturn batch;\n\n\tcs = i915_gem_object_pin_map_unlocked(batch->obj, I915_MAP_WC);\n\tif (IS_ERR(cs)) {\n\t\ti915_vma_put(batch);\n\t\treturn ERR_CAST(cs);\n\t}\n\n\tdefaults = shmem_pin_map(ce->engine->default_state);\n\tif (!defaults) {\n\t\ti915_gem_object_unpin_map(batch->obj);\n\t\ti915_vma_put(batch);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tdw = 0;\n\thw = defaults;\n\thw += LRC_STATE_OFFSET / sizeof(*hw);\n\tdo {\n\t\tu32 len = hw[dw] & LRI_LENGTH_MASK;\n\n\t\t \n\t\tif ((hw[dw] >> INSTR_CLIENT_SHIFT) != INSTR_MI_CLIENT)\n\t\t\tbreak;\n\n\t\tif (hw[dw] == 0) {\n\t\t\tdw++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif ((hw[dw] & GENMASK(31, 23)) != LRI_HEADER) {\n\t\t\tdw += len + 2;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!len) {\n\t\t\tpr_err(\"%s: invalid LRI found in context image\\n\",\n\t\t\t       ce->engine->name);\n\t\t\tigt_hexdump(defaults, PAGE_SIZE);\n\t\t\tbreak;\n\t\t}\n\n\t\tdw++;\n\t\tlen = (len + 1) / 2;\n\t\t*cs++ = MI_LOAD_REGISTER_IMM(len);\n\t\twhile (len--) {\n\t\t\t*cs++ = hw[dw];\n\t\t\t*cs++ = safe_poison(hw[dw] & get_lri_mask(ce->engine,\n\t\t\t\t\t\t\t\t  MI_LRI_LRM_CS_MMIO),\n\t\t\t\t\t    poison);\n\t\t\tdw += 2;\n\t\t}\n\t} while (dw < PAGE_SIZE / sizeof(u32) &&\n\t\t (hw[dw] & ~BIT(0)) != MI_BATCH_BUFFER_END);\n\n\t*cs++ = MI_BATCH_BUFFER_END;\n\n\tshmem_unpin_map(ce->engine->default_state, defaults);\n\n\ti915_gem_object_flush_map(batch->obj);\n\ti915_gem_object_unpin_map(batch->obj);\n\n\treturn batch;\n}\n\nstatic int poison_registers(struct intel_context *ce, u32 poison, u32 *sema)\n{\n\tstruct i915_request *rq;\n\tstruct i915_vma *batch;\n\tu32 *cs;\n\tint err;\n\n\tbatch = load_context(ce, poison);\n\tif (IS_ERR(batch))\n\t\treturn PTR_ERR(batch);\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_batch;\n\t}\n\n\terr = igt_vma_move_to_active_unlocked(batch, rq, 0);\n\tif (err)\n\t\tgoto err_rq;\n\n\tcs = intel_ring_begin(rq, 8);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto err_rq;\n\t}\n\n\t*cs++ = MI_ARB_ON_OFF | MI_ARB_DISABLE;\n\t*cs++ = MI_BATCH_BUFFER_START_GEN8 | BIT(8);\n\t*cs++ = lower_32_bits(i915_vma_offset(batch));\n\t*cs++ = upper_32_bits(i915_vma_offset(batch));\n\n\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t*cs++ = i915_ggtt_offset(ce->engine->status_page.vma) +\n\t\toffset_in_page(sema);\n\t*cs++ = 0;\n\t*cs++ = 1;\n\n\tintel_ring_advance(rq, cs);\n\n\trq->sched.attr.priority = I915_PRIORITY_BARRIER;\nerr_rq:\n\ti915_request_add(rq);\nerr_batch:\n\ti915_vma_put(batch);\n\treturn err;\n}\n\nstatic bool is_moving(u32 a, u32 b)\n{\n\treturn a != b;\n}\n\nstatic int compare_isolation(struct intel_engine_cs *engine,\n\t\t\t     struct i915_vma *ref[2],\n\t\t\t     struct i915_vma *result[2],\n\t\t\t     struct intel_context *ce,\n\t\t\t     u32 poison)\n{\n\tu32 x, dw, *hw, *lrc;\n\tu32 *A[2], *B[2];\n\tu32 *defaults;\n\tint err = 0;\n\n\tA[0] = i915_gem_object_pin_map_unlocked(ref[0]->obj, I915_MAP_WC);\n\tif (IS_ERR(A[0]))\n\t\treturn PTR_ERR(A[0]);\n\n\tA[1] = i915_gem_object_pin_map_unlocked(ref[1]->obj, I915_MAP_WC);\n\tif (IS_ERR(A[1])) {\n\t\terr = PTR_ERR(A[1]);\n\t\tgoto err_A0;\n\t}\n\n\tB[0] = i915_gem_object_pin_map_unlocked(result[0]->obj, I915_MAP_WC);\n\tif (IS_ERR(B[0])) {\n\t\terr = PTR_ERR(B[0]);\n\t\tgoto err_A1;\n\t}\n\n\tB[1] = i915_gem_object_pin_map_unlocked(result[1]->obj, I915_MAP_WC);\n\tif (IS_ERR(B[1])) {\n\t\terr = PTR_ERR(B[1]);\n\t\tgoto err_B0;\n\t}\n\n\tlrc = i915_gem_object_pin_map_unlocked(ce->state->obj,\n\t\t\t\t\t       intel_gt_coherent_map_type(engine->gt,\n\t\t\t\t\t\t\t\t\t  ce->state->obj,\n\t\t\t\t\t\t\t\t\t  false));\n\tif (IS_ERR(lrc)) {\n\t\terr = PTR_ERR(lrc);\n\t\tgoto err_B1;\n\t}\n\tlrc += LRC_STATE_OFFSET / sizeof(*hw);\n\n\tdefaults = shmem_pin_map(ce->engine->default_state);\n\tif (!defaults) {\n\t\terr = -ENOMEM;\n\t\tgoto err_lrc;\n\t}\n\n\tx = 0;\n\tdw = 0;\n\thw = defaults;\n\thw += LRC_STATE_OFFSET / sizeof(*hw);\n\tdo {\n\t\tu32 len = hw[dw] & LRI_LENGTH_MASK;\n\n\t\t \n\t\tif ((hw[dw] >> INSTR_CLIENT_SHIFT) != INSTR_MI_CLIENT)\n\t\t\tbreak;\n\n\t\tif (hw[dw] == 0) {\n\t\t\tdw++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif ((hw[dw] & GENMASK(31, 23)) != LRI_HEADER) {\n\t\t\tdw += len + 2;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!len) {\n\t\t\tpr_err(\"%s: invalid LRI found in context image\\n\",\n\t\t\t       engine->name);\n\t\t\tigt_hexdump(defaults, PAGE_SIZE);\n\t\t\tbreak;\n\t\t}\n\n\t\tdw++;\n\t\tlen = (len + 1) / 2;\n\t\twhile (len--) {\n\t\t\tif (!is_moving(A[0][x], A[1][x]) &&\n\t\t\t    (A[0][x] != B[0][x] || A[1][x] != B[1][x])) {\n\t\t\t\tswitch (hw[dw] & 4095) {\n\t\t\t\tcase 0x30:  \n\t\t\t\tcase 0x34:  \n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tpr_err(\"%s[%d]: Mismatch for register %4x, default %08x, reference %08x, result (%08x, %08x), poison %08x, context %08x\\n\",\n\t\t\t\t\t       engine->name, dw,\n\t\t\t\t\t       hw[dw], hw[dw + 1],\n\t\t\t\t\t       A[0][x], B[0][x], B[1][x],\n\t\t\t\t\t       poison, lrc[dw + 1]);\n\t\t\t\t\terr = -EINVAL;\n\t\t\t\t}\n\t\t\t}\n\t\t\tdw += 2;\n\t\t\tx++;\n\t\t}\n\t} while (dw < PAGE_SIZE / sizeof(u32) &&\n\t\t (hw[dw] & ~BIT(0)) != MI_BATCH_BUFFER_END);\n\n\tshmem_unpin_map(ce->engine->default_state, defaults);\nerr_lrc:\n\ti915_gem_object_unpin_map(ce->state->obj);\nerr_B1:\n\ti915_gem_object_unpin_map(result[1]->obj);\nerr_B0:\n\ti915_gem_object_unpin_map(result[0]->obj);\nerr_A1:\n\ti915_gem_object_unpin_map(ref[1]->obj);\nerr_A0:\n\ti915_gem_object_unpin_map(ref[0]->obj);\n\treturn err;\n}\n\nstatic struct i915_vma *\ncreate_result_vma(struct i915_address_space *vm, unsigned long sz)\n{\n\tstruct i915_vma *vma;\n\tvoid *ptr;\n\n\tvma = create_user_vma(vm, sz);\n\tif (IS_ERR(vma))\n\t\treturn vma;\n\n\t \n\tptr = i915_gem_object_pin_map_unlocked(vma->obj, I915_MAP_WC);\n\tif (IS_ERR(ptr)) {\n\t\ti915_vma_put(vma);\n\t\treturn ERR_CAST(ptr);\n\t}\n\n\tmemset(ptr, POISON_INUSE, vma->size);\n\ti915_gem_object_flush_map(vma->obj);\n\ti915_gem_object_unpin_map(vma->obj);\n\n\treturn vma;\n}\n\nstatic int __lrc_isolation(struct intel_engine_cs *engine, u32 poison)\n{\n\tu32 *sema = memset32(engine->status_page.addr + 1000, 0, 1);\n\tstruct i915_vma *ref[2], *result[2];\n\tstruct intel_context *A, *B;\n\tstruct i915_request *rq;\n\tint err;\n\n\tA = intel_context_create(engine);\n\tif (IS_ERR(A))\n\t\treturn PTR_ERR(A);\n\n\tB = intel_context_create(engine);\n\tif (IS_ERR(B)) {\n\t\terr = PTR_ERR(B);\n\t\tgoto err_A;\n\t}\n\n\tref[0] = create_result_vma(A->vm, SZ_64K);\n\tif (IS_ERR(ref[0])) {\n\t\terr = PTR_ERR(ref[0]);\n\t\tgoto err_B;\n\t}\n\n\tref[1] = create_result_vma(A->vm, SZ_64K);\n\tif (IS_ERR(ref[1])) {\n\t\terr = PTR_ERR(ref[1]);\n\t\tgoto err_ref0;\n\t}\n\n\trq = record_registers(A, ref[0], ref[1], sema);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_ref1;\n\t}\n\n\tWRITE_ONCE(*sema, 1);\n\twmb();\n\n\tif (i915_request_wait(rq, 0, HZ / 2) < 0) {\n\t\ti915_request_put(rq);\n\t\terr = -ETIME;\n\t\tgoto err_ref1;\n\t}\n\ti915_request_put(rq);\n\n\tresult[0] = create_result_vma(A->vm, SZ_64K);\n\tif (IS_ERR(result[0])) {\n\t\terr = PTR_ERR(result[0]);\n\t\tgoto err_ref1;\n\t}\n\n\tresult[1] = create_result_vma(A->vm, SZ_64K);\n\tif (IS_ERR(result[1])) {\n\t\terr = PTR_ERR(result[1]);\n\t\tgoto err_result0;\n\t}\n\n\trq = record_registers(A, result[0], result[1], sema);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_result1;\n\t}\n\n\terr = poison_registers(B, poison, sema);\n\tif (err == 0 && i915_request_wait(rq, 0, HZ / 2) < 0) {\n\t\tpr_err(\"%s(%s): wait for results timed out\\n\",\n\t\t       __func__, engine->name);\n\t\terr = -ETIME;\n\t}\n\n\t \n\tWRITE_ONCE(*sema, -1);\n\ti915_request_put(rq);\n\tif (err)\n\t\tgoto err_result1;\n\n\terr = compare_isolation(engine, ref, result, A, poison);\n\nerr_result1:\n\ti915_vma_put(result[1]);\nerr_result0:\n\ti915_vma_put(result[0]);\nerr_ref1:\n\ti915_vma_put(ref[1]);\nerr_ref0:\n\ti915_vma_put(ref[0]);\nerr_B:\n\tintel_context_put(B);\nerr_A:\n\tintel_context_put(A);\n\treturn err;\n}\n\nstatic bool skip_isolation(const struct intel_engine_cs *engine)\n{\n\tif (engine->class == COPY_ENGINE_CLASS && GRAPHICS_VER(engine->i915) == 9)\n\t\treturn true;\n\n\tif (engine->class == RENDER_CLASS && GRAPHICS_VER(engine->i915) == 11)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int live_lrc_isolation(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tconst u32 poison[] = {\n\t\tSTACK_MAGIC,\n\t\t0x3a3a3a3a,\n\t\t0x5c5c5c5c,\n\t\t0xffffffff,\n\t\t0xffff0000,\n\t};\n\tint err = 0;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\tint i;\n\n\t\t \n\t\tif (!IS_ENABLED(CONFIG_DRM_I915_SELFTEST_BROKEN) &&\n\t\t    skip_isolation(engine))\n\t\t\tcontinue;\n\n\t\tintel_engine_pm_get(engine);\n\t\tfor (i = 0; i < ARRAY_SIZE(poison); i++) {\n\t\t\tint result;\n\n\t\t\tresult = __lrc_isolation(engine, poison[i]);\n\t\t\tif (result && !err)\n\t\t\t\terr = result;\n\n\t\t\tresult = __lrc_isolation(engine, ~poison[i]);\n\t\t\tif (result && !err)\n\t\t\t\terr = result;\n\t\t}\n\t\tintel_engine_pm_put(engine);\n\t\tif (igt_flush_test(gt->i915)) {\n\t\t\terr = -EIO;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn err;\n}\n\nstatic int indirect_ctx_submit_req(struct intel_context *ce)\n{\n\tstruct i915_request *rq;\n\tint err = 0;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\tif (i915_request_wait(rq, 0, HZ / 5) < 0)\n\t\terr = -ETIME;\n\n\ti915_request_put(rq);\n\n\treturn err;\n}\n\n#define CTX_BB_CANARY_OFFSET (3 * 1024)\n#define CTX_BB_CANARY_INDEX  (CTX_BB_CANARY_OFFSET / sizeof(u32))\n\nstatic u32 *\nemit_indirect_ctx_bb_canary(const struct intel_context *ce, u32 *cs)\n{\n\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 |\n\t\tMI_SRM_LRM_GLOBAL_GTT |\n\t\tMI_LRI_LRM_CS_MMIO;\n\t*cs++ = i915_mmio_reg_offset(RING_START(0));\n\t*cs++ = i915_ggtt_offset(ce->state) +\n\t\tcontext_wa_bb_offset(ce) +\n\t\tCTX_BB_CANARY_OFFSET;\n\t*cs++ = 0;\n\n\treturn cs;\n}\n\nstatic void\nindirect_ctx_bb_setup(struct intel_context *ce)\n{\n\tu32 *cs = context_indirect_bb(ce);\n\n\tcs[CTX_BB_CANARY_INDEX] = 0xdeadf00d;\n\n\tsetup_indirect_ctx_bb(ce, ce->engine, emit_indirect_ctx_bb_canary);\n}\n\nstatic bool check_ring_start(struct intel_context *ce)\n{\n\tconst u32 * const ctx_bb = (void *)(ce->lrc_reg_state) -\n\t\tLRC_STATE_OFFSET + context_wa_bb_offset(ce);\n\n\tif (ctx_bb[CTX_BB_CANARY_INDEX] == ce->lrc_reg_state[CTX_RING_START])\n\t\treturn true;\n\n\tpr_err(\"ring start mismatch: canary 0x%08x vs state 0x%08x\\n\",\n\t       ctx_bb[CTX_BB_CANARY_INDEX],\n\t       ce->lrc_reg_state[CTX_RING_START]);\n\n\treturn false;\n}\n\nstatic int indirect_ctx_bb_check(struct intel_context *ce)\n{\n\tint err;\n\n\terr = indirect_ctx_submit_req(ce);\n\tif (err)\n\t\treturn err;\n\n\tif (!check_ring_start(ce))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int __live_lrc_indirect_ctx_bb(struct intel_engine_cs *engine)\n{\n\tstruct intel_context *a, *b;\n\tint err;\n\n\ta = intel_context_create(engine);\n\tif (IS_ERR(a))\n\t\treturn PTR_ERR(a);\n\terr = intel_context_pin(a);\n\tif (err)\n\t\tgoto put_a;\n\n\tb = intel_context_create(engine);\n\tif (IS_ERR(b)) {\n\t\terr = PTR_ERR(b);\n\t\tgoto unpin_a;\n\t}\n\terr = intel_context_pin(b);\n\tif (err)\n\t\tgoto put_b;\n\n\t \n\tif (!a->wa_bb_page) {\n\t\tGEM_BUG_ON(b->wa_bb_page);\n\t\tGEM_BUG_ON(GRAPHICS_VER(engine->i915) == 12);\n\t\tgoto unpin_b;\n\t}\n\n\t \n\tindirect_ctx_bb_setup(a);\n\tindirect_ctx_bb_setup(b);\n\n\terr = indirect_ctx_bb_check(a);\n\tif (err)\n\t\tgoto unpin_b;\n\n\terr = indirect_ctx_bb_check(b);\n\nunpin_b:\n\tintel_context_unpin(b);\nput_b:\n\tintel_context_put(b);\nunpin_a:\n\tintel_context_unpin(a);\nput_a:\n\tintel_context_put(a);\n\n\treturn err;\n}\n\nstatic int live_lrc_indirect_ctx_bb(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tintel_engine_pm_get(engine);\n\t\terr = __live_lrc_indirect_ctx_bb(engine);\n\t\tintel_engine_pm_put(engine);\n\n\t\tif (igt_flush_test(gt->i915))\n\t\t\terr = -EIO;\n\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nstatic void garbage_reset(struct intel_engine_cs *engine,\n\t\t\t  struct i915_request *rq)\n{\n\tconst unsigned int bit = I915_RESET_ENGINE + engine->id;\n\tunsigned long *lock = &engine->gt->reset.flags;\n\n\tlocal_bh_disable();\n\tif (!test_and_set_bit(bit, lock)) {\n\t\ttasklet_disable(&engine->sched_engine->tasklet);\n\n\t\tif (!rq->fence.error)\n\t\t\t__intel_engine_reset_bh(engine, NULL);\n\n\t\ttasklet_enable(&engine->sched_engine->tasklet);\n\t\tclear_and_wake_up_bit(bit, lock);\n\t}\n\tlocal_bh_enable();\n}\n\nstatic struct i915_request *garbage(struct intel_context *ce,\n\t\t\t\t    struct rnd_state *prng)\n{\n\tstruct i915_request *rq;\n\tint err;\n\n\terr = intel_context_pin(ce);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tprandom_bytes_state(prng,\n\t\t\t    ce->lrc_reg_state,\n\t\t\t    ce->engine->context_size -\n\t\t\t    LRC_STATE_OFFSET);\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_unpin;\n\t}\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\treturn rq;\n\nerr_unpin:\n\tintel_context_unpin(ce);\n\treturn ERR_PTR(err);\n}\n\nstatic int __lrc_garbage(struct intel_engine_cs *engine, struct rnd_state *prng)\n{\n\tstruct intel_context *ce;\n\tstruct i915_request *hang;\n\tint err = 0;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\thang = garbage(ce, prng);\n\tif (IS_ERR(hang)) {\n\t\terr = PTR_ERR(hang);\n\t\tgoto err_ce;\n\t}\n\n\tif (wait_for_submit(engine, hang, HZ / 2)) {\n\t\ti915_request_put(hang);\n\t\terr = -ETIME;\n\t\tgoto err_ce;\n\t}\n\n\tintel_context_set_banned(ce);\n\tgarbage_reset(engine, hang);\n\n\tintel_engine_flush_submission(engine);\n\tif (!hang->fence.error) {\n\t\ti915_request_put(hang);\n\t\tpr_err(\"%s: corrupted context was not reset\\n\",\n\t\t       engine->name);\n\t\terr = -EINVAL;\n\t\tgoto err_ce;\n\t}\n\n\tif (i915_request_wait(hang, 0, HZ / 2) < 0) {\n\t\tpr_err(\"%s: corrupted context did not recover\\n\",\n\t\t       engine->name);\n\t\ti915_request_put(hang);\n\t\terr = -EIO;\n\t\tgoto err_ce;\n\t}\n\ti915_request_put(hang);\n\nerr_ce:\n\tintel_context_put(ce);\n\treturn err;\n}\n\nstatic int live_lrc_garbage(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\n\tif (!IS_ENABLED(CONFIG_DRM_I915_SELFTEST_BROKEN))\n\t\treturn 0;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tI915_RND_STATE(prng);\n\t\tint err = 0, i;\n\n\t\tif (!intel_has_reset_engine(engine->gt))\n\t\t\tcontinue;\n\n\t\tintel_engine_pm_get(engine);\n\t\tfor (i = 0; i < 3; i++) {\n\t\t\terr = __lrc_garbage(engine, &prng);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t}\n\t\tintel_engine_pm_put(engine);\n\n\t\tif (igt_flush_test(gt->i915))\n\t\t\terr = -EIO;\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int __live_pphwsp_runtime(struct intel_engine_cs *engine)\n{\n\tstruct intel_context *ce;\n\tstruct i915_request *rq;\n\tIGT_TIMEOUT(end_time);\n\tint err;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\tce->stats.runtime.num_underflow = 0;\n\tce->stats.runtime.max_underflow = 0;\n\n\tdo {\n\t\tunsigned int loop = 1024;\n\n\t\twhile (loop) {\n\t\t\trq = intel_context_create_request(ce);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tgoto err_rq;\n\t\t\t}\n\n\t\t\tif (--loop == 0)\n\t\t\t\ti915_request_get(rq);\n\n\t\t\ti915_request_add(rq);\n\t\t}\n\n\t\tif (__igt_timeout(end_time, NULL))\n\t\t\tbreak;\n\n\t\ti915_request_put(rq);\n\t} while (1);\n\n\terr = i915_request_wait(rq, 0, HZ / 5);\n\tif (err < 0) {\n\t\tpr_err(\"%s: request not completed!\\n\", engine->name);\n\t\tgoto err_wait;\n\t}\n\n\tigt_flush_test(engine->i915);\n\n\tpr_info(\"%s: pphwsp runtime %lluns, average %lluns\\n\",\n\t\tengine->name,\n\t\tintel_context_get_total_runtime_ns(ce),\n\t\tintel_context_get_avg_runtime_ns(ce));\n\n\terr = 0;\n\tif (ce->stats.runtime.num_underflow) {\n\t\tpr_err(\"%s: pphwsp underflow %u time(s), max %u cycles!\\n\",\n\t\t       engine->name,\n\t\t       ce->stats.runtime.num_underflow,\n\t\t       ce->stats.runtime.max_underflow);\n\t\tGEM_TRACE_DUMP();\n\t\terr = -EOVERFLOW;\n\t}\n\nerr_wait:\n\ti915_request_put(rq);\nerr_rq:\n\tintel_context_put(ce);\n\treturn err;\n}\n\nstatic int live_pphwsp_runtime(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\terr = __live_pphwsp_runtime(engine);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\treturn err;\n}\n\nint intel_lrc_live_selftests(struct drm_i915_private *i915)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(live_lrc_layout),\n\t\tSUBTEST(live_lrc_fixed),\n\t\tSUBTEST(live_lrc_state),\n\t\tSUBTEST(live_lrc_gpr),\n\t\tSUBTEST(live_lrc_isolation),\n\t\tSUBTEST(live_lrc_timestamp),\n\t\tSUBTEST(live_lrc_garbage),\n\t\tSUBTEST(live_pphwsp_runtime),\n\t\tSUBTEST(live_lrc_indirect_ctx_bb),\n\t};\n\n\tif (!HAS_LOGICAL_RING_CONTEXTS(i915))\n\t\treturn 0;\n\n\treturn intel_gt_live_subtests(tests, to_gt(i915));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}