{
  "module_name": "selftest_ring_submission.c",
  "hash_id": "9f3aabdd3f77003f0e43502783f45a3db8cc951d8b43f2ee76d033f9f061aa7e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/selftest_ring_submission.c",
  "human_readable_source": "\n \n\n#include \"intel_engine_pm.h\"\n#include \"selftests/igt_flush_test.h\"\n\nstatic struct i915_vma *create_wally(struct intel_engine_cs *engine)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\tu32 *cs;\n\tint err;\n\n\tobj = i915_gem_object_create_internal(engine->i915, 4096);\n\tif (IS_ERR(obj))\n\t\treturn ERR_CAST(obj);\n\n\tvma = i915_vma_instance(obj, engine->gt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn vma;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER | PIN_HIGH);\n\tif (err) {\n\t\ti915_gem_object_put(obj);\n\t\treturn ERR_PTR(err);\n\t}\n\n\terr = i915_vma_sync(vma);\n\tif (err) {\n\t\ti915_gem_object_put(obj);\n\t\treturn ERR_PTR(err);\n\t}\n\n\tcs = i915_gem_object_pin_map_unlocked(obj, I915_MAP_WC);\n\tif (IS_ERR(cs)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn ERR_CAST(cs);\n\t}\n\n\tif (GRAPHICS_VER(engine->i915) >= 6) {\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4;\n\t\t*cs++ = 0;\n\t} else if (GRAPHICS_VER(engine->i915) >= 4) {\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*cs++ = 0;\n\t} else {\n\t\t*cs++ = MI_STORE_DWORD_IMM | MI_MEM_VIRTUAL;\n\t}\n\t*cs++ = i915_vma_offset(vma) + 4000;\n\t*cs++ = STACK_MAGIC;\n\n\t*cs++ = MI_BATCH_BUFFER_END;\n\n\ti915_gem_object_flush_map(obj);\n\ti915_gem_object_unpin_map(obj);\n\n\tvma->private = intel_context_create(engine);  \n\tif (IS_ERR(vma->private)) {\n\t\tvma = ERR_CAST(vma->private);\n\t\ti915_gem_object_put(obj);\n\t}\n\n\treturn vma;\n}\n\nstatic int context_sync(struct intel_context *ce)\n{\n\tstruct i915_request *rq;\n\tint err = 0;\n\n\trq = intel_context_create_request(ce);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\tif (i915_request_wait(rq, 0, HZ / 5) < 0)\n\t\terr = -ETIME;\n\ti915_request_put(rq);\n\n\treturn err;\n}\n\nstatic int new_context_sync(struct intel_engine_cs *engine)\n{\n\tstruct intel_context *ce;\n\tint err;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\terr = context_sync(ce);\n\tintel_context_put(ce);\n\n\treturn err;\n}\n\nstatic int mixed_contexts_sync(struct intel_engine_cs *engine, u32 *result)\n{\n\tint pass;\n\tint err;\n\n\tfor (pass = 0; pass < 2; pass++) {\n\t\tWRITE_ONCE(*result, 0);\n\t\terr = context_sync(engine->kernel_context);\n\t\tif (err || READ_ONCE(*result)) {\n\t\t\tif (!err) {\n\t\t\t\tpr_err(\"pass[%d] wa_bb emitted for the kernel context\\n\",\n\t\t\t\t       pass);\n\t\t\t\terr = -EINVAL;\n\t\t\t}\n\t\t\treturn err;\n\t\t}\n\n\t\tWRITE_ONCE(*result, 0);\n\t\terr = new_context_sync(engine);\n\t\tif (READ_ONCE(*result) != STACK_MAGIC) {\n\t\t\tif (!err) {\n\t\t\t\tpr_err(\"pass[%d] wa_bb *NOT* emitted after the kernel context\\n\",\n\t\t\t\t       pass);\n\t\t\t\terr = -EINVAL;\n\t\t\t}\n\t\t\treturn err;\n\t\t}\n\n\t\tWRITE_ONCE(*result, 0);\n\t\terr = new_context_sync(engine);\n\t\tif (READ_ONCE(*result) != STACK_MAGIC) {\n\t\t\tif (!err) {\n\t\t\t\tpr_err(\"pass[%d] wa_bb *NOT* emitted for the user context switch\\n\",\n\t\t\t\t       pass);\n\t\t\t\terr = -EINVAL;\n\t\t\t}\n\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int double_context_sync_00(struct intel_engine_cs *engine, u32 *result)\n{\n\tstruct intel_context *ce;\n\tint err, i;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\tfor (i = 0; i < 2; i++) {\n\t\tWRITE_ONCE(*result, 0);\n\t\terr = context_sync(ce);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\tintel_context_put(ce);\n\tif (err)\n\t\treturn err;\n\n\tif (READ_ONCE(*result)) {\n\t\tpr_err(\"wa_bb emitted between the same user context\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int kernel_context_sync_00(struct intel_engine_cs *engine, u32 *result)\n{\n\tstruct intel_context *ce;\n\tint err, i;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\tfor (i = 0; i < 2; i++) {\n\t\tWRITE_ONCE(*result, 0);\n\t\terr = context_sync(ce);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\terr = context_sync(engine->kernel_context);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\tintel_context_put(ce);\n\tif (err)\n\t\treturn err;\n\n\tif (READ_ONCE(*result)) {\n\t\tpr_err(\"wa_bb emitted between the same user context [with intervening kernel]\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int __live_ctx_switch_wa(struct intel_engine_cs *engine)\n{\n\tstruct i915_vma *bb;\n\tu32 *result;\n\tint err;\n\n\tbb = create_wally(engine);\n\tif (IS_ERR(bb))\n\t\treturn PTR_ERR(bb);\n\n\tresult = i915_gem_object_pin_map_unlocked(bb->obj, I915_MAP_WC);\n\tif (IS_ERR(result)) {\n\t\tintel_context_put(bb->private);\n\t\ti915_vma_unpin_and_release(&bb, 0);\n\t\treturn PTR_ERR(result);\n\t}\n\tresult += 1000;\n\n\tengine->wa_ctx.vma = bb;\n\n\terr = mixed_contexts_sync(engine, result);\n\tif (err)\n\t\tgoto out;\n\n\terr = double_context_sync_00(engine, result);\n\tif (err)\n\t\tgoto out;\n\n\terr = kernel_context_sync_00(engine, result);\n\tif (err)\n\t\tgoto out;\n\nout:\n\tintel_context_put(engine->wa_ctx.vma->private);\n\ti915_vma_unpin_and_release(&engine->wa_ctx.vma, I915_VMA_RELEASE_MAP);\n\treturn err;\n}\n\nstatic int live_ctx_switch_wa(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_vma *saved_wa;\n\t\tint err;\n\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\tif (IS_GRAPHICS_VER(gt->i915, 4, 5))\n\t\t\tcontinue;  \n\n\t\tsaved_wa = fetch_and_zero(&engine->wa_ctx.vma);\n\n\t\tintel_engine_pm_get(engine);\n\t\terr = __live_ctx_switch_wa(engine);\n\t\tintel_engine_pm_put(engine);\n\t\tif (igt_flush_test(gt->i915))\n\t\t\terr = -EIO;\n\n\t\tengine->wa_ctx.vma = saved_wa;\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nint intel_ring_submission_live_selftests(struct drm_i915_private *i915)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(live_ctx_switch_wa),\n\t};\n\n\tif (to_gt(i915)->submission_method > INTEL_SUBMISSION_RING)\n\t\treturn 0;\n\n\treturn intel_gt_live_subtests(tests, to_gt(i915));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}