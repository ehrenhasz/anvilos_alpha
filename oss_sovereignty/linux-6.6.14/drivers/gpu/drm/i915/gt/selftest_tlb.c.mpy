{
  "module_name": "selftest_tlb.c",
  "hash_id": "f90279401b3829f352381a65590a1b020f6526ea5946c21f6bd903a9dbc763cf",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/selftest_tlb.c",
  "human_readable_source": "\n \n\n#include \"i915_selftest.h\"\n\n#include \"gem/i915_gem_internal.h\"\n#include \"gem/i915_gem_lmem.h\"\n#include \"gem/i915_gem_region.h\"\n\n#include \"gen8_engine_cs.h\"\n#include \"i915_gem_ww.h\"\n#include \"intel_engine_regs.h\"\n#include \"intel_gpu_commands.h\"\n#include \"intel_context.h\"\n#include \"intel_gt.h\"\n#include \"intel_ring.h\"\n\n#include \"selftests/igt_flush_test.h\"\n#include \"selftests/i915_random.h\"\n\nstatic void vma_set_qw(struct i915_vma *vma, u64 addr, u64 val)\n{\n\tGEM_BUG_ON(addr < i915_vma_offset(vma));\n\tGEM_BUG_ON(addr >= i915_vma_offset(vma) + i915_vma_size(vma) + sizeof(val));\n\tmemset64(page_mask_bits(vma->obj->mm.mapping) +\n\t\t (addr - i915_vma_offset(vma)), val, 1);\n}\n\nstatic int\npte_tlbinv(struct intel_context *ce,\n\t   struct i915_vma *va,\n\t   struct i915_vma *vb,\n\t   u64 align,\n\t   void (*tlbinv)(struct i915_address_space *vm, u64 addr, u64 length),\n\t   u64 length,\n\t   struct rnd_state *prng)\n{\n\tconst unsigned int pat_index =\n\t\ti915_gem_get_pat_index(ce->vm->i915, I915_CACHE_NONE);\n\tstruct drm_i915_gem_object *batch;\n\tstruct drm_mm_node vb_node;\n\tstruct i915_request *rq;\n\tstruct i915_vma *vma;\n\tu64 addr;\n\tint err;\n\tu32 *cs;\n\n\tbatch = i915_gem_object_create_internal(ce->vm->i915, 4096);\n\tif (IS_ERR(batch))\n\t\treturn PTR_ERR(batch);\n\n\tvma = i915_vma_instance(batch, ce->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\terr = PTR_ERR(vma);\n\t\tgoto out;\n\t}\n\n\terr = i915_vma_pin(vma, 0, 0, PIN_USER);\n\tif (err)\n\t\tgoto out;\n\n\t \n\taddr = round_up(vma->node.start + vma->node.size, align);\n\t \n\taddr = igt_random_offset(prng, addr, min(ce->vm->total, BIT_ULL(48)),\n\t\t\t\t va->size, align);\n\terr = i915_vma_pin(va,  0, 0, addr | PIN_OFFSET_FIXED | PIN_USER);\n\tif (err) {\n\t\tpr_err(\"Cannot pin at %llx+%llx\\n\", addr, va->size);\n\t\tgoto out;\n\t}\n\tGEM_BUG_ON(i915_vma_offset(va) != addr);\n\tif (vb != va) {\n\t\tvb_node = vb->node;\n\t\tvb->node = va->node;  \n\t}\n\n\t \n\tif (align == SZ_64K)\n\t\taddr = round_up(addr, SZ_2M);\n\taddr = igt_random_offset(prng, addr, addr + align, 8, 8);\n\n\tif (va != vb)\n\t\tpr_info(\"%s(%s): Sampling %llx, with alignment %llx, using PTE size %x (phys %x, sg %x), invalidate:%llx+%llx\\n\",\n\t\t\tce->engine->name, va->obj->mm.region->name ?: \"smem\",\n\t\t\taddr, align, va->resource->page_sizes_gtt,\n\t\t\tva->page_sizes.phys, va->page_sizes.sg,\n\t\t\taddr & -length, length);\n\n\tcs = i915_gem_object_pin_map_unlocked(batch, I915_MAP_WC);\n\t*cs++ = MI_NOOP;  \n\t \n\t*cs++ = MI_CONDITIONAL_BATCH_BUFFER_END | MI_DO_COMPARE | 2;\n\t*cs++ = 0;  \n\t*cs++ = lower_32_bits(addr);\n\t*cs++ = upper_32_bits(addr);\n\tvma_set_qw(va, addr, -1);\n\tvma_set_qw(vb, addr, 0);\n\n\t \n\t*cs++ = MI_BATCH_BUFFER_START | BIT(8) | 1;\n\t*cs++ = lower_32_bits(i915_vma_offset(vma));\n\t*cs++ = upper_32_bits(i915_vma_offset(vma));\n\n\ti915_gem_object_flush_map(batch);\n\n\trq = i915_request_create(ce);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto out_va;\n\t}\n\n\terr = rq->engine->emit_bb_start(rq, i915_vma_offset(vma), 0, 0);\n\tif (err) {\n\t\ti915_request_add(rq);\n\t\tgoto out_va;\n\t}\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\t \n\tmsleep(10);\n\tif (va == vb) {\n\t\tif (!i915_request_completed(rq)) {\n\t\t\tpr_err(\"%s(%s): Semaphore sanitycheck failed %llx, with alignment %llx, using PTE size %x (phys %x, sg %x)\\n\",\n\t\t\t       ce->engine->name, va->obj->mm.region->name ?: \"smem\",\n\t\t\t       addr, align, va->resource->page_sizes_gtt,\n\t\t\t       va->page_sizes.phys, va->page_sizes.sg);\n\t\t\terr = -EIO;\n\t\t}\n\t} else if (!i915_request_completed(rq)) {\n\t\tstruct i915_vma_resource vb_res = {\n\t\t\t.bi.pages = vb->obj->mm.pages,\n\t\t\t.bi.page_sizes = vb->obj->mm.page_sizes,\n\t\t\t.start = i915_vma_offset(vb),\n\t\t\t.vma_size = i915_vma_size(vb)\n\t\t};\n\t\tunsigned int pte_flags = 0;\n\n\t\t \n\t\tif (i915_gem_object_is_lmem(vb->obj))\n\t\t\tpte_flags |= PTE_LM;\n\t\tce->vm->insert_entries(ce->vm, &vb_res, pat_index, pte_flags);\n\n\t\t \n\t\ttlbinv(ce->vm, addr & -length, length);\n\n\t\tif (wait_for(i915_request_completed(rq), HZ / 2)) {\n\t\t\tpr_err(\"%s: Request did not complete; the COND_BBE did not read the updated PTE\\n\",\n\t\t\t       ce->engine->name);\n\t\t\terr = -EINVAL;\n\t\t}\n\t} else {\n\t\tpr_err(\"Spinner ended unexpectedly\\n\");\n\t\terr = -EIO;\n\t}\n\ti915_request_put(rq);\n\n\tcs = page_mask_bits(batch->mm.mapping);\n\t*cs = MI_BATCH_BUFFER_END;\n\twmb();\n\nout_va:\n\tif (vb != va)\n\t\tvb->node = vb_node;\n\ti915_vma_unpin(va);\n\tif (i915_vma_unbind_unlocked(va))\n\t\terr = -EIO;\nout:\n\ti915_gem_object_put(batch);\n\treturn err;\n}\n\nstatic struct drm_i915_gem_object *create_lmem(struct intel_gt *gt)\n{\n\tstruct intel_memory_region *mr = gt->i915->mm.regions[INTEL_REGION_LMEM_0];\n\tresource_size_t size = SZ_1G;\n\n\t \n\tif (mr && size > mr->io_size / 4)\n\t\tsize = mr->io_size / 4;\n\n\treturn i915_gem_object_create_lmem(gt->i915, size, I915_BO_ALLOC_CONTIGUOUS);\n}\n\nstatic struct drm_i915_gem_object *create_smem(struct intel_gt *gt)\n{\n\t \n\treturn i915_gem_object_create_internal(gt->i915, SZ_4M);\n}\n\nstatic int\nmem_tlbinv(struct intel_gt *gt,\n\t   struct drm_i915_gem_object *(*create_fn)(struct intel_gt *),\n\t   void (*tlbinv)(struct i915_address_space *vm, u64 addr, u64 length))\n{\n\tunsigned int ppgtt_size = RUNTIME_INFO(gt->i915)->ppgtt_size;\n\tstruct intel_engine_cs *engine;\n\tstruct drm_i915_gem_object *A, *B;\n\tstruct i915_ppgtt *ppgtt;\n\tstruct i915_vma *va, *vb;\n\tenum intel_engine_id id;\n\tI915_RND_STATE(prng);\n\tvoid *vaddr;\n\tint err;\n\n\t \n\n\tA = create_fn(gt);\n\tif (IS_ERR(A))\n\t\treturn PTR_ERR(A);\n\n\tvaddr = i915_gem_object_pin_map_unlocked(A, I915_MAP_WC);\n\tif (IS_ERR(vaddr)) {\n\t\terr = PTR_ERR(vaddr);\n\t\tgoto out_a;\n\t}\n\n\tB = create_fn(gt);\n\tif (IS_ERR(B)) {\n\t\terr = PTR_ERR(B);\n\t\tgoto out_a;\n\t}\n\n\tvaddr = i915_gem_object_pin_map_unlocked(B, I915_MAP_WC);\n\tif (IS_ERR(vaddr)) {\n\t\terr = PTR_ERR(vaddr);\n\t\tgoto out_b;\n\t}\n\n\tGEM_BUG_ON(A->base.size != B->base.size);\n\tif ((A->mm.page_sizes.phys | B->mm.page_sizes.phys) & (A->base.size - 1))\n\t\tpr_warn(\"Failed to allocate contiguous pages for size %zx\\n\",\n\t\t\tA->base.size);\n\n\tppgtt = i915_ppgtt_create(gt, 0);\n\tif (IS_ERR(ppgtt)) {\n\t\terr = PTR_ERR(ppgtt);\n\t\tgoto out_b;\n\t}\n\n\tva = i915_vma_instance(A, &ppgtt->vm, NULL);\n\tif (IS_ERR(va)) {\n\t\terr = PTR_ERR(va);\n\t\tgoto out_vm;\n\t}\n\n\tvb = i915_vma_instance(B, &ppgtt->vm, NULL);\n\tif (IS_ERR(vb)) {\n\t\terr = PTR_ERR(vb);\n\t\tgoto out_vm;\n\t}\n\n\terr = 0;\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_gem_ww_ctx ww;\n\t\tstruct intel_context *ce;\n\t\tint bit;\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce)) {\n\t\t\terr = PTR_ERR(ce);\n\t\t\tbreak;\n\t\t}\n\n\t\ti915_vm_put(ce->vm);\n\t\tce->vm = i915_vm_get(&ppgtt->vm);\n\n\t\tfor_i915_gem_ww(&ww, err, true)\n\t\t\terr = intel_context_pin_ww(ce, &ww);\n\t\tif (err)\n\t\t\tgoto err_put;\n\n\t\tfor_each_set_bit(bit,\n\t\t\t\t (unsigned long *)&RUNTIME_INFO(gt->i915)->page_sizes,\n\t\t\t\t BITS_PER_TYPE(RUNTIME_INFO(gt->i915)->page_sizes)) {\n\t\t\tunsigned int len;\n\n\t\t\tif (BIT_ULL(bit) < i915_vm_obj_min_alignment(va->vm, va->obj))\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\terr = pte_tlbinv(ce, va, va,\n\t\t\t\t\t BIT_ULL(bit),\n\t\t\t\t\t NULL, SZ_4K,\n\t\t\t\t\t &prng);\n\t\t\tif (err)\n\t\t\t\tgoto err_unpin;\n\n\t\t\tfor (len = 2; len <= ppgtt_size; len = min(2 * len, ppgtt_size)) {\n\t\t\t\terr = pte_tlbinv(ce, va, vb,\n\t\t\t\t\t\t BIT_ULL(bit),\n\t\t\t\t\t\t tlbinv,\n\t\t\t\t\t\t BIT_ULL(len),\n\t\t\t\t\t\t &prng);\n\t\t\t\tif (err)\n\t\t\t\t\tgoto err_unpin;\n\t\t\t\tif (len == ppgtt_size)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nerr_unpin:\n\t\tintel_context_unpin(ce);\nerr_put:\n\t\tintel_context_put(ce);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\nout_vm:\n\ti915_vm_put(&ppgtt->vm);\nout_b:\n\ti915_gem_object_put(B);\nout_a:\n\ti915_gem_object_put(A);\n\treturn err;\n}\n\nstatic void tlbinv_full(struct i915_address_space *vm, u64 addr, u64 length)\n{\n\tintel_gt_invalidate_tlb_full(vm->gt, intel_gt_tlb_seqno(vm->gt) | 1);\n}\n\nstatic int invalidate_full(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tint err;\n\n\tif (GRAPHICS_VER(gt->i915) < 8)\n\t\treturn 0;  \n\n\terr = mem_tlbinv(gt, create_smem, tlbinv_full);\n\tif (err == 0)\n\t\terr = mem_tlbinv(gt, create_lmem, tlbinv_full);\n\tif (err == -ENODEV || err == -ENXIO)\n\t\terr = 0;\n\n\treturn err;\n}\n\nint intel_tlb_live_selftests(struct drm_i915_private *i915)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(invalidate_full),\n\t};\n\tstruct intel_gt *gt;\n\tunsigned int i;\n\n\tfor_each_gt(gt, i915, i) {\n\t\tint err;\n\n\t\tif (intel_gt_is_wedged(gt))\n\t\t\tcontinue;\n\n\t\terr = intel_gt_live_subtests(tests, gt);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}