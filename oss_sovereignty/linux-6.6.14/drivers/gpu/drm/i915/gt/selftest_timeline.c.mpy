{
  "module_name": "selftest_timeline.c",
  "hash_id": "29522ad4af8ad71525524f43a8d4ce9ef020c3b5fbe1aff27c2a9039a9e6cbdd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/selftest_timeline.c",
  "human_readable_source": "\n \n\n#include <linux/prime_numbers.h>\n#include <linux/string_helpers.h>\n\n#include \"intel_context.h\"\n#include \"intel_engine_heartbeat.h\"\n#include \"intel_engine_pm.h\"\n#include \"intel_engine_regs.h\"\n#include \"intel_gpu_commands.h\"\n#include \"intel_gt.h\"\n#include \"intel_gt_requests.h\"\n#include \"intel_ring.h\"\n#include \"selftest_engine_heartbeat.h\"\n\n#include \"../selftests/i915_random.h\"\n#include \"../i915_selftest.h\"\n\n#include \"selftests/igt_flush_test.h\"\n#include \"selftests/lib_sw_fence.h\"\n#include \"selftests/mock_gem_device.h\"\n#include \"selftests/mock_timeline.h\"\n\nstatic struct page *hwsp_page(struct intel_timeline *tl)\n{\n\tstruct drm_i915_gem_object *obj = tl->hwsp_ggtt->obj;\n\n\tGEM_BUG_ON(!i915_gem_object_has_pinned_pages(obj));\n\treturn sg_page(obj->mm.pages->sgl);\n}\n\nstatic unsigned long hwsp_cacheline(struct intel_timeline *tl)\n{\n\tunsigned long address = (unsigned long)page_address(hwsp_page(tl));\n\n\treturn (address + offset_in_page(tl->hwsp_offset)) / TIMELINE_SEQNO_BYTES;\n}\n\nstatic int selftest_tl_pin(struct intel_timeline *tl)\n{\n\tstruct i915_gem_ww_ctx ww;\n\tint err;\n\n\ti915_gem_ww_ctx_init(&ww, false);\nretry:\n\terr = i915_gem_object_lock(tl->hwsp_ggtt->obj, &ww);\n\tif (!err)\n\t\terr = intel_timeline_pin(tl, &ww);\n\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\treturn err;\n}\n\n \n#define CACHELINES_PER_PAGE (PAGE_SIZE / TIMELINE_SEQNO_BYTES / 2)\n\nstruct mock_hwsp_freelist {\n\tstruct intel_gt *gt;\n\tstruct radix_tree_root cachelines;\n\tstruct intel_timeline **history;\n\tunsigned long count, max;\n\tstruct rnd_state prng;\n};\n\nenum {\n\tSHUFFLE = BIT(0),\n};\n\nstatic void __mock_hwsp_record(struct mock_hwsp_freelist *state,\n\t\t\t       unsigned int idx,\n\t\t\t       struct intel_timeline *tl)\n{\n\ttl = xchg(&state->history[idx], tl);\n\tif (tl) {\n\t\tradix_tree_delete(&state->cachelines, hwsp_cacheline(tl));\n\t\tintel_timeline_unpin(tl);\n\t\tintel_timeline_put(tl);\n\t}\n}\n\nstatic int __mock_hwsp_timeline(struct mock_hwsp_freelist *state,\n\t\t\t\tunsigned int count,\n\t\t\t\tunsigned int flags)\n{\n\tstruct intel_timeline *tl;\n\tunsigned int idx;\n\n\twhile (count--) {\n\t\tunsigned long cacheline;\n\t\tint err;\n\n\t\ttl = intel_timeline_create(state->gt);\n\t\tif (IS_ERR(tl))\n\t\t\treturn PTR_ERR(tl);\n\n\t\terr = selftest_tl_pin(tl);\n\t\tif (err) {\n\t\t\tintel_timeline_put(tl);\n\t\t\treturn err;\n\t\t}\n\n\t\tcacheline = hwsp_cacheline(tl);\n\t\terr = radix_tree_insert(&state->cachelines, cacheline, tl);\n\t\tif (err) {\n\t\t\tif (err == -EEXIST) {\n\t\t\t\tpr_err(\"HWSP cacheline %lu already used; duplicate allocation!\\n\",\n\t\t\t\t       cacheline);\n\t\t\t}\n\t\t\tintel_timeline_unpin(tl);\n\t\t\tintel_timeline_put(tl);\n\t\t\treturn err;\n\t\t}\n\n\t\tidx = state->count++ % state->max;\n\t\t__mock_hwsp_record(state, idx, tl);\n\t}\n\n\tif (flags & SHUFFLE)\n\t\ti915_prandom_shuffle(state->history,\n\t\t\t\t     sizeof(*state->history),\n\t\t\t\t     min(state->count, state->max),\n\t\t\t\t     &state->prng);\n\n\tcount = i915_prandom_u32_max_state(min(state->count, state->max),\n\t\t\t\t\t   &state->prng);\n\twhile (count--) {\n\t\tidx = --state->count % state->max;\n\t\t__mock_hwsp_record(state, idx, NULL);\n\t}\n\n\treturn 0;\n}\n\nstatic int mock_hwsp_freelist(void *arg)\n{\n\tstruct mock_hwsp_freelist state;\n\tstruct drm_i915_private *i915;\n\tconst struct {\n\t\tconst char *name;\n\t\tunsigned int flags;\n\t} phases[] = {\n\t\t{ \"linear\", 0 },\n\t\t{ \"shuffled\", SHUFFLE },\n\t\t{ },\n\t}, *p;\n\tunsigned int na;\n\tint err = 0;\n\n\ti915 = mock_gem_device();\n\tif (!i915)\n\t\treturn -ENOMEM;\n\n\tINIT_RADIX_TREE(&state.cachelines, GFP_KERNEL);\n\tstate.prng = I915_RND_STATE_INITIALIZER(i915_selftest.random_seed);\n\n\tstate.gt = to_gt(i915);\n\n\t \n\n\tstate.max = PAGE_SIZE / sizeof(*state.history);\n\tstate.count = 0;\n\tstate.history = kcalloc(state.max, sizeof(*state.history), GFP_KERNEL);\n\tif (!state.history) {\n\t\terr = -ENOMEM;\n\t\tgoto err_put;\n\t}\n\n\tfor (p = phases; p->name; p++) {\n\t\tpr_debug(\"%s(%s)\\n\", __func__, p->name);\n\t\tfor_each_prime_number_from(na, 1, 2 * CACHELINES_PER_PAGE) {\n\t\t\terr = __mock_hwsp_timeline(&state, na, p->flags);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tfor (na = 0; na < state.max; na++)\n\t\t__mock_hwsp_record(&state, na, NULL);\n\tkfree(state.history);\nerr_put:\n\tmock_destroy_device(i915);\n\treturn err;\n}\n\nstruct __igt_sync {\n\tconst char *name;\n\tu32 seqno;\n\tbool expected;\n\tbool set;\n};\n\nstatic int __igt_sync(struct intel_timeline *tl,\n\t\t      u64 ctx,\n\t\t      const struct __igt_sync *p,\n\t\t      const char *name)\n{\n\tint ret;\n\n\tif (__intel_timeline_sync_is_later(tl, ctx, p->seqno) != p->expected) {\n\t\tpr_err(\"%s: %s(ctx=%llu, seqno=%u) expected passed %s but failed\\n\",\n\t\t       name, p->name, ctx, p->seqno, str_yes_no(p->expected));\n\t\treturn -EINVAL;\n\t}\n\n\tif (p->set) {\n\t\tret = __intel_timeline_sync_set(tl, ctx, p->seqno);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int igt_sync(void *arg)\n{\n\tconst struct __igt_sync pass[] = {\n\t\t{ \"unset\", 0, false, false },\n\t\t{ \"new\", 0, false, true },\n\t\t{ \"0a\", 0, true, true },\n\t\t{ \"1a\", 1, false, true },\n\t\t{ \"1b\", 1, true, true },\n\t\t{ \"0b\", 0, true, false },\n\t\t{ \"2a\", 2, false, true },\n\t\t{ \"4\", 4, false, true },\n\t\t{ \"INT_MAX\", INT_MAX, false, true },\n\t\t{ \"INT_MAX-1\", INT_MAX-1, true, false },\n\t\t{ \"INT_MAX+1\", (u32)INT_MAX+1, false, true },\n\t\t{ \"INT_MAX\", INT_MAX, true, false },\n\t\t{ \"UINT_MAX\", UINT_MAX, false, true },\n\t\t{ \"wrap\", 0, false, true },\n\t\t{ \"unwrap\", UINT_MAX, true, false },\n\t\t{},\n\t}, *p;\n\tstruct intel_timeline tl;\n\tint order, offset;\n\tint ret = -ENODEV;\n\n\tmock_timeline_init(&tl, 0);\n\tfor (p = pass; p->name; p++) {\n\t\tfor (order = 1; order < 64; order++) {\n\t\t\tfor (offset = -1; offset <= (order > 1); offset++) {\n\t\t\t\tu64 ctx = BIT_ULL(order) + offset;\n\n\t\t\t\tret = __igt_sync(&tl, ctx, p, \"1\");\n\t\t\t\tif (ret)\n\t\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\tmock_timeline_fini(&tl);\n\n\tmock_timeline_init(&tl, 0);\n\tfor (order = 1; order < 64; order++) {\n\t\tfor (offset = -1; offset <= (order > 1); offset++) {\n\t\t\tu64 ctx = BIT_ULL(order) + offset;\n\n\t\t\tfor (p = pass; p->name; p++) {\n\t\t\t\tret = __igt_sync(&tl, ctx, p, \"2\");\n\t\t\t\tif (ret)\n\t\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\nout:\n\tmock_timeline_fini(&tl);\n\treturn ret;\n}\n\nstatic unsigned int random_engine(struct rnd_state *rnd)\n{\n\treturn i915_prandom_u32_max_state(I915_NUM_ENGINES, rnd);\n}\n\nstatic int bench_sync(void *arg)\n{\n\tstruct rnd_state prng;\n\tstruct intel_timeline tl;\n\tunsigned long end_time, count;\n\tu64 prng32_1M;\n\tktime_t kt;\n\tint order, last_order;\n\n\tmock_timeline_init(&tl, 0);\n\n\t \n\tprandom_seed_state(&prng, i915_selftest.random_seed);\n\tcount = 0;\n\tkt = ktime_get();\n\tend_time = jiffies + HZ/10;\n\tdo {\n\t\tu32 x;\n\n\t\t \n\t\tWRITE_ONCE(x, prandom_u32_state(&prng));\n\n\t\tcount++;\n\t} while (!time_after(jiffies, end_time));\n\tkt = ktime_sub(ktime_get(), kt);\n\tpr_debug(\"%s: %lu random evaluations, %lluns/prng\\n\",\n\t\t __func__, count, (long long)div64_ul(ktime_to_ns(kt), count));\n\tprng32_1M = div64_ul(ktime_to_ns(kt) << 20, count);\n\n\t \n\tprandom_seed_state(&prng, i915_selftest.random_seed);\n\tcount = 0;\n\tkt = ktime_get();\n\tend_time = jiffies + HZ/10;\n\tdo {\n\t\tu64 id = i915_prandom_u64_state(&prng);\n\n\t\t__intel_timeline_sync_set(&tl, id, 0);\n\t\tcount++;\n\t} while (!time_after(jiffies, end_time));\n\tkt = ktime_sub(ktime_get(), kt);\n\tkt = ktime_sub_ns(kt, (count * prng32_1M * 2) >> 20);\n\tpr_info(\"%s: %lu random insertions, %lluns/insert\\n\",\n\t\t__func__, count, (long long)div64_ul(ktime_to_ns(kt), count));\n\n\t \n\tprandom_seed_state(&prng, i915_selftest.random_seed);\n\tend_time = count;\n\tkt = ktime_get();\n\twhile (end_time--) {\n\t\tu64 id = i915_prandom_u64_state(&prng);\n\n\t\tif (!__intel_timeline_sync_is_later(&tl, id, 0)) {\n\t\t\tmock_timeline_fini(&tl);\n\t\t\tpr_err(\"Lookup of %llu failed\\n\", id);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tkt = ktime_sub(ktime_get(), kt);\n\tkt = ktime_sub_ns(kt, (count * prng32_1M * 2) >> 20);\n\tpr_info(\"%s: %lu random lookups, %lluns/lookup\\n\",\n\t\t__func__, count, (long long)div64_ul(ktime_to_ns(kt), count));\n\n\tmock_timeline_fini(&tl);\n\tcond_resched();\n\n\tmock_timeline_init(&tl, 0);\n\n\t \n\tcount = 0;\n\tkt = ktime_get();\n\tend_time = jiffies + HZ/10;\n\tdo {\n\t\t__intel_timeline_sync_set(&tl, count++, 0);\n\t} while (!time_after(jiffies, end_time));\n\tkt = ktime_sub(ktime_get(), kt);\n\tpr_info(\"%s: %lu in-order insertions, %lluns/insert\\n\",\n\t\t__func__, count, (long long)div64_ul(ktime_to_ns(kt), count));\n\n\t \n\tend_time = count;\n\tkt = ktime_get();\n\twhile (end_time--) {\n\t\tif (!__intel_timeline_sync_is_later(&tl, end_time, 0)) {\n\t\t\tpr_err(\"Lookup of %lu failed\\n\", end_time);\n\t\t\tmock_timeline_fini(&tl);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\tkt = ktime_sub(ktime_get(), kt);\n\tpr_info(\"%s: %lu in-order lookups, %lluns/lookup\\n\",\n\t\t__func__, count, (long long)div64_ul(ktime_to_ns(kt), count));\n\n\tmock_timeline_fini(&tl);\n\tcond_resched();\n\n\tmock_timeline_init(&tl, 0);\n\n\t \n\tprandom_seed_state(&prng, i915_selftest.random_seed);\n\tcount = 0;\n\tkt = ktime_get();\n\tend_time = jiffies + HZ/10;\n\tdo {\n\t\tu32 id = random_engine(&prng);\n\t\tu32 seqno = prandom_u32_state(&prng);\n\n\t\tif (!__intel_timeline_sync_is_later(&tl, id, seqno))\n\t\t\t__intel_timeline_sync_set(&tl, id, seqno);\n\n\t\tcount++;\n\t} while (!time_after(jiffies, end_time));\n\tkt = ktime_sub(ktime_get(), kt);\n\tkt = ktime_sub_ns(kt, (count * prng32_1M * 2) >> 20);\n\tpr_info(\"%s: %lu repeated insert/lookups, %lluns/op\\n\",\n\t\t__func__, count, (long long)div64_ul(ktime_to_ns(kt), count));\n\tmock_timeline_fini(&tl);\n\tcond_resched();\n\n\t \n\tfor (last_order = 1, order = 1; order < 32;\n\t     ({ int tmp = last_order; last_order = order; order += tmp; })) {\n\t\tunsigned int mask = BIT(order) - 1;\n\n\t\tmock_timeline_init(&tl, 0);\n\n\t\tcount = 0;\n\t\tkt = ktime_get();\n\t\tend_time = jiffies + HZ/10;\n\t\tdo {\n\t\t\t \n\t\t\tu64 id = (u64)(count & mask) << order;\n\n\t\t\t__intel_timeline_sync_is_later(&tl, id, 0);\n\t\t\t__intel_timeline_sync_set(&tl, id, 0);\n\n\t\t\tcount++;\n\t\t} while (!time_after(jiffies, end_time));\n\t\tkt = ktime_sub(ktime_get(), kt);\n\t\tpr_info(\"%s: %lu cyclic/%d insert/lookups, %lluns/op\\n\",\n\t\t\t__func__, count, order,\n\t\t\t(long long)div64_ul(ktime_to_ns(kt), count));\n\t\tmock_timeline_fini(&tl);\n\t\tcond_resched();\n\t}\n\n\treturn 0;\n}\n\nint intel_timeline_mock_selftests(void)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(mock_hwsp_freelist),\n\t\tSUBTEST(igt_sync),\n\t\tSUBTEST(bench_sync),\n\t};\n\n\treturn i915_subtests(tests, NULL);\n}\n\nstatic int emit_ggtt_store_dw(struct i915_request *rq, u32 addr, u32 value)\n{\n\tu32 *cs;\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\tif (GRAPHICS_VER(rq->i915) >= 8) {\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*cs++ = addr;\n\t\t*cs++ = 0;\n\t\t*cs++ = value;\n\t} else if (GRAPHICS_VER(rq->i915) >= 4) {\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*cs++ = 0;\n\t\t*cs++ = addr;\n\t\t*cs++ = value;\n\t} else {\n\t\t*cs++ = MI_STORE_DWORD_IMM | MI_MEM_VIRTUAL;\n\t\t*cs++ = addr;\n\t\t*cs++ = value;\n\t\t*cs++ = MI_NOOP;\n\t}\n\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstatic struct i915_request *\nchecked_tl_write(struct intel_timeline *tl, struct intel_engine_cs *engine, u32 value)\n{\n\tstruct i915_request *rq;\n\tint err;\n\n\terr = selftest_tl_pin(tl);\n\tif (err) {\n\t\trq = ERR_PTR(err);\n\t\tgoto out;\n\t}\n\n\tif (READ_ONCE(*tl->hwsp_seqno) != tl->seqno) {\n\t\tpr_err(\"Timeline created with incorrect breadcrumb, found %x, expected %x\\n\",\n\t\t       *tl->hwsp_seqno, tl->seqno);\n\t\tintel_timeline_unpin(tl);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\trq = intel_engine_create_kernel_request(engine);\n\tif (IS_ERR(rq))\n\t\tgoto out_unpin;\n\n\ti915_request_get(rq);\n\n\terr = emit_ggtt_store_dw(rq, tl->hwsp_offset, value);\n\ti915_request_add(rq);\n\tif (err) {\n\t\ti915_request_put(rq);\n\t\trq = ERR_PTR(err);\n\t}\n\nout_unpin:\n\tintel_timeline_unpin(tl);\nout:\n\tif (IS_ERR(rq))\n\t\tpr_err(\"Failed to write to timeline!\\n\");\n\treturn rq;\n}\n\nstatic int live_hwsp_engine(void *arg)\n{\n#define NUM_TIMELINES 4096\n\tstruct intel_gt *gt = arg;\n\tstruct intel_timeline **timelines;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tunsigned long count, n;\n\tint err = 0;\n\n\t \n\n\ttimelines = kvmalloc_array(NUM_TIMELINES * I915_NUM_ENGINES,\n\t\t\t\t   sizeof(*timelines),\n\t\t\t\t   GFP_KERNEL);\n\tif (!timelines)\n\t\treturn -ENOMEM;\n\n\tcount = 0;\n\tfor_each_engine(engine, gt, id) {\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\tintel_engine_pm_get(engine);\n\n\t\tfor (n = 0; n < NUM_TIMELINES; n++) {\n\t\t\tstruct intel_timeline *tl;\n\t\t\tstruct i915_request *rq;\n\n\t\t\ttl = intel_timeline_create(gt);\n\t\t\tif (IS_ERR(tl)) {\n\t\t\t\terr = PTR_ERR(tl);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\trq = checked_tl_write(tl, engine, count);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\tintel_timeline_put(tl);\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\ttimelines[count++] = tl;\n\t\t\ti915_request_put(rq);\n\t\t}\n\n\t\tintel_engine_pm_put(engine);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\tfor (n = 0; n < count; n++) {\n\t\tstruct intel_timeline *tl = timelines[n];\n\n\t\tif (!err && READ_ONCE(*tl->hwsp_seqno) != n) {\n\t\t\tGEM_TRACE_ERR(\"Invalid seqno:%lu stored in timeline %llu @ %x, found 0x%x\\n\",\n\t\t\t\t      n, tl->fence_context, tl->hwsp_offset, *tl->hwsp_seqno);\n\t\t\tGEM_TRACE_DUMP();\n\t\t\terr = -EINVAL;\n\t\t}\n\t\tintel_timeline_put(tl);\n\t}\n\n\tkvfree(timelines);\n\treturn err;\n#undef NUM_TIMELINES\n}\n\nstatic int live_hwsp_alternate(void *arg)\n{\n#define NUM_TIMELINES 4096\n\tstruct intel_gt *gt = arg;\n\tstruct intel_timeline **timelines;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tunsigned long count, n;\n\tint err = 0;\n\n\t \n\n\ttimelines = kvmalloc_array(NUM_TIMELINES * I915_NUM_ENGINES,\n\t\t\t\t   sizeof(*timelines),\n\t\t\t\t   GFP_KERNEL);\n\tif (!timelines)\n\t\treturn -ENOMEM;\n\n\tcount = 0;\n\tfor (n = 0; n < NUM_TIMELINES; n++) {\n\t\tfor_each_engine(engine, gt, id) {\n\t\t\tstruct intel_timeline *tl;\n\t\t\tstruct i915_request *rq;\n\n\t\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\t\tcontinue;\n\n\t\t\ttl = intel_timeline_create(gt);\n\t\t\tif (IS_ERR(tl)) {\n\t\t\t\terr = PTR_ERR(tl);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tintel_engine_pm_get(engine);\n\t\t\trq = checked_tl_write(tl, engine, count);\n\t\t\tintel_engine_pm_put(engine);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\tintel_timeline_put(tl);\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimelines[count++] = tl;\n\t\t\ti915_request_put(rq);\n\t\t}\n\t}\n\nout:\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\tfor (n = 0; n < count; n++) {\n\t\tstruct intel_timeline *tl = timelines[n];\n\n\t\tif (!err && READ_ONCE(*tl->hwsp_seqno) != n) {\n\t\t\tGEM_TRACE_ERR(\"Invalid seqno:%lu stored in timeline %llu @ %x, found 0x%x\\n\",\n\t\t\t\t      n, tl->fence_context, tl->hwsp_offset, *tl->hwsp_seqno);\n\t\t\tGEM_TRACE_DUMP();\n\t\t\terr = -EINVAL;\n\t\t}\n\t\tintel_timeline_put(tl);\n\t}\n\n\tkvfree(timelines);\n\treturn err;\n#undef NUM_TIMELINES\n}\n\nstatic int live_hwsp_wrap(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tstruct intel_timeline *tl;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\ttl = intel_timeline_create(gt);\n\tif (IS_ERR(tl))\n\t\treturn PTR_ERR(tl);\n\n\tif (!tl->has_initial_breadcrumb)\n\t\tgoto out_free;\n\n\terr = selftest_tl_pin(tl);\n\tif (err)\n\t\tgoto out_free;\n\n\tfor_each_engine(engine, gt, id) {\n\t\tconst u32 *hwsp_seqno[2];\n\t\tstruct i915_request *rq;\n\t\tu32 seqno[2];\n\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\trq = intel_engine_create_kernel_request(engine);\n\t\tif (IS_ERR(rq)) {\n\t\t\terr = PTR_ERR(rq);\n\t\t\tgoto out;\n\t\t}\n\n\t\ttl->seqno = -4u;\n\n\t\tmutex_lock_nested(&tl->mutex, SINGLE_DEPTH_NESTING);\n\t\terr = intel_timeline_get_seqno(tl, rq, &seqno[0]);\n\t\tmutex_unlock(&tl->mutex);\n\t\tif (err) {\n\t\t\ti915_request_add(rq);\n\t\t\tgoto out;\n\t\t}\n\t\tpr_debug(\"seqno[0]:%08x, hwsp_offset:%08x\\n\",\n\t\t\t seqno[0], tl->hwsp_offset);\n\n\t\terr = emit_ggtt_store_dw(rq, tl->hwsp_offset, seqno[0]);\n\t\tif (err) {\n\t\t\ti915_request_add(rq);\n\t\t\tgoto out;\n\t\t}\n\t\thwsp_seqno[0] = tl->hwsp_seqno;\n\n\t\tmutex_lock_nested(&tl->mutex, SINGLE_DEPTH_NESTING);\n\t\terr = intel_timeline_get_seqno(tl, rq, &seqno[1]);\n\t\tmutex_unlock(&tl->mutex);\n\t\tif (err) {\n\t\t\ti915_request_add(rq);\n\t\t\tgoto out;\n\t\t}\n\t\tpr_debug(\"seqno[1]:%08x, hwsp_offset:%08x\\n\",\n\t\t\t seqno[1], tl->hwsp_offset);\n\n\t\terr = emit_ggtt_store_dw(rq, tl->hwsp_offset, seqno[1]);\n\t\tif (err) {\n\t\t\ti915_request_add(rq);\n\t\t\tgoto out;\n\t\t}\n\t\thwsp_seqno[1] = tl->hwsp_seqno;\n\n\t\t \n\t\tGEM_BUG_ON(seqno[1] >= seqno[0]);\n\t\tGEM_BUG_ON(hwsp_seqno[0] == hwsp_seqno[1]);\n\n\t\ti915_request_add(rq);\n\n\t\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\t\tpr_err(\"Wait for timeline writes timed out!\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (READ_ONCE(*hwsp_seqno[0]) != seqno[0] ||\n\t\t    READ_ONCE(*hwsp_seqno[1]) != seqno[1]) {\n\t\t\tpr_err(\"Bad timeline values: found (%x, %x), expected (%x, %x)\\n\",\n\t\t\t       *hwsp_seqno[0], *hwsp_seqno[1],\n\t\t\t       seqno[0], seqno[1]);\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tintel_gt_retire_requests(gt);  \n\t}\n\nout:\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\tintel_timeline_unpin(tl);\nout_free:\n\tintel_timeline_put(tl);\n\treturn err;\n}\n\nstatic int emit_read_hwsp(struct i915_request *rq,\n\t\t\t  u32 seqno, u32 hwsp,\n\t\t\t  u32 *addr)\n{\n\tconst u32 gpr = i915_mmio_reg_offset(GEN8_RING_CS_GPR(rq->engine->mmio_base, 0));\n\tu32 *cs;\n\n\tcs = intel_ring_begin(rq, 12);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t*cs++ = *addr;\n\t*cs++ = 0;\n\t*cs++ = seqno;\n\t*addr += 4;\n\n\t*cs++ = MI_LOAD_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t*cs++ = gpr;\n\t*cs++ = hwsp;\n\t*cs++ = 0;\n\n\t*cs++ = MI_STORE_REGISTER_MEM_GEN8 | MI_USE_GGTT;\n\t*cs++ = gpr;\n\t*cs++ = *addr;\n\t*cs++ = 0;\n\t*addr += 4;\n\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstruct hwsp_watcher {\n\tstruct i915_vma *vma;\n\tstruct i915_request *rq;\n\tu32 addr;\n\tu32 *map;\n};\n\nstatic bool cmp_lt(u32 a, u32 b)\n{\n\treturn a < b;\n}\n\nstatic bool cmp_gte(u32 a, u32 b)\n{\n\treturn a >= b;\n}\n\nstatic int setup_watcher(struct hwsp_watcher *w, struct intel_gt *gt,\n\t\t\t struct intel_timeline *tl)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_vma *vma;\n\n\tobj = i915_gem_object_create_internal(gt->i915, SZ_2M);\n\tif (IS_ERR(obj))\n\t\treturn PTR_ERR(obj);\n\n\t \n\ti915_gem_object_set_pat_index(obj, tl->hwsp_ggtt->obj->pat_index);\n\tw->map = i915_gem_object_pin_map_unlocked(obj,\n\t\t\t\t\t\t  page_unmask_bits(tl->hwsp_ggtt->obj->mm.mapping));\n\tif (IS_ERR(w->map)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn PTR_ERR(w->map);\n\t}\n\n\tvma = i915_gem_object_ggtt_pin(obj, NULL, 0, 0, 0);\n\tif (IS_ERR(vma)) {\n\t\ti915_gem_object_put(obj);\n\t\treturn PTR_ERR(vma);\n\t}\n\n\tw->vma = vma;\n\tw->addr = i915_ggtt_offset(vma);\n\treturn 0;\n}\n\nstatic void switch_tl_lock(struct i915_request *from, struct i915_request *to)\n{\n\t \n\n\tif (from) {\n\t\tlockdep_unpin_lock(&from->context->timeline->mutex, from->cookie);\n\t\tmutex_unlock(&from->context->timeline->mutex);\n\t}\n\n\tif (to) {\n\t\tmutex_lock(&to->context->timeline->mutex);\n\t\tto->cookie = lockdep_pin_lock(&to->context->timeline->mutex);\n\t}\n}\n\nstatic int create_watcher(struct hwsp_watcher *w,\n\t\t\t  struct intel_engine_cs *engine,\n\t\t\t  int ringsz)\n{\n\tstruct intel_context *ce;\n\n\tce = intel_context_create(engine);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\tce->ring_size = ringsz;\n\tw->rq = intel_context_create_request(ce);\n\tintel_context_put(ce);\n\tif (IS_ERR(w->rq))\n\t\treturn PTR_ERR(w->rq);\n\n\tw->addr = i915_ggtt_offset(w->vma);\n\n\tswitch_tl_lock(w->rq, NULL);\n\n\treturn 0;\n}\n\nstatic int check_watcher(struct hwsp_watcher *w, const char *name,\n\t\t\t bool (*op)(u32 hwsp, u32 seqno))\n{\n\tstruct i915_request *rq = fetch_and_zero(&w->rq);\n\tu32 offset, end;\n\tint err;\n\n\tGEM_BUG_ON(w->addr - i915_ggtt_offset(w->vma) > w->vma->size);\n\n\ti915_request_get(rq);\n\tswitch_tl_lock(NULL, rq);\n\ti915_request_add(rq);\n\n\tif (i915_request_wait(rq, 0, HZ) < 0) {\n\t\terr = -ETIME;\n\t\tgoto out;\n\t}\n\n\terr = 0;\n\toffset = 0;\n\tend = (w->addr - i915_ggtt_offset(w->vma)) / sizeof(*w->map);\n\twhile (offset < end) {\n\t\tif (!op(w->map[offset + 1], w->map[offset])) {\n\t\t\tpr_err(\"Watcher '%s' found HWSP value %x for seqno %x\\n\",\n\t\t\t       name, w->map[offset + 1], w->map[offset]);\n\t\t\terr = -EINVAL;\n\t\t}\n\n\t\toffset += 2;\n\t}\n\nout:\n\ti915_request_put(rq);\n\treturn err;\n}\n\nstatic void cleanup_watcher(struct hwsp_watcher *w)\n{\n\tif (w->rq) {\n\t\tswitch_tl_lock(NULL, w->rq);\n\n\t\ti915_request_add(w->rq);\n\t}\n\n\ti915_vma_unpin_and_release(&w->vma, I915_VMA_RELEASE_MAP);\n}\n\nstatic bool retire_requests(struct intel_timeline *tl)\n{\n\tstruct i915_request *rq, *rn;\n\n\tmutex_lock(&tl->mutex);\n\tlist_for_each_entry_safe(rq, rn, &tl->requests, link)\n\t\tif (!i915_request_retire(rq))\n\t\t\tbreak;\n\tmutex_unlock(&tl->mutex);\n\n\treturn !i915_active_fence_isset(&tl->last_request);\n}\n\nstatic struct i915_request *wrap_timeline(struct i915_request *rq)\n{\n\tstruct intel_context *ce = rq->context;\n\tstruct intel_timeline *tl = ce->timeline;\n\tu32 seqno = rq->fence.seqno;\n\n\twhile (tl->seqno >= seqno) {  \n\t\ti915_request_put(rq);\n\t\trq = intel_context_create_request(ce);\n\t\tif (IS_ERR(rq))\n\t\t\treturn rq;\n\n\t\ti915_request_get(rq);\n\t\ti915_request_add(rq);\n\t}\n\n\ti915_request_put(rq);\n\trq = i915_request_create(ce);\n\tif (IS_ERR(rq))\n\t\treturn rq;\n\n\ti915_request_get(rq);\n\ti915_request_add(rq);\n\n\treturn rq;\n}\n\nstatic int live_hwsp_read(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct hwsp_watcher watcher[2] = {};\n\tstruct intel_engine_cs *engine;\n\tstruct intel_timeline *tl;\n\tenum intel_engine_id id;\n\tint err = 0;\n\tint i;\n\n\t \n\n\tif (GRAPHICS_VER(gt->i915) < 8)  \n\t\treturn 0;\n\n\ttl = intel_timeline_create(gt);\n\tif (IS_ERR(tl))\n\t\treturn PTR_ERR(tl);\n\n\tif (!tl->has_initial_breadcrumb)\n\t\tgoto out_free;\n\n\tselftest_tl_pin(tl);\n\n\tfor (i = 0; i < ARRAY_SIZE(watcher); i++) {\n\t\terr = setup_watcher(&watcher[i], gt, tl);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce;\n\t\tunsigned long count = 0;\n\t\tIGT_TIMEOUT(end_time);\n\n\t\t \n\t\terr = create_watcher(&watcher[1], engine, SZ_512K);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\tdo {\n\t\t\tstruct i915_sw_fence *submit;\n\t\t\tstruct i915_request *rq;\n\t\t\tu32 hwsp, dummy;\n\n\t\t\tsubmit = heap_fence_create(GFP_KERNEL);\n\t\t\tif (!submit) {\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\terr = create_watcher(&watcher[0], engine, SZ_4K);\n\t\t\tif (err)\n\t\t\t\tgoto out;\n\n\t\t\tce = intel_context_create(engine);\n\t\t\tif (IS_ERR(ce)) {\n\t\t\t\terr = PTR_ERR(ce);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tce->timeline = intel_timeline_get(tl);\n\n\t\t\t \n\t\t\terr = intel_context_pin(ce);\n\t\t\tif (err) {\n\t\t\t\tintel_context_put(ce);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t \n\t\t\ttl->seqno = -12u + 2 * (count & 3);\n\t\t\t__intel_timeline_get_seqno(tl, &dummy);\n\n\t\t\trq = i915_request_create(ce);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tintel_context_unpin(ce);\n\t\t\t\tintel_context_put(ce);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\terr = i915_sw_fence_await_dma_fence(&rq->submit,\n\t\t\t\t\t\t\t    &watcher[0].rq->fence, 0,\n\t\t\t\t\t\t\t    GFP_KERNEL);\n\t\t\tif (err < 0) {\n\t\t\t\ti915_request_add(rq);\n\t\t\t\tintel_context_unpin(ce);\n\t\t\t\tintel_context_put(ce);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tswitch_tl_lock(rq, watcher[0].rq);\n\t\t\terr = intel_timeline_read_hwsp(rq, watcher[0].rq, &hwsp);\n\t\t\tif (err == 0)\n\t\t\t\terr = emit_read_hwsp(watcher[0].rq,  \n\t\t\t\t\t\t     rq->fence.seqno, hwsp,\n\t\t\t\t\t\t     &watcher[0].addr);\n\t\t\tswitch_tl_lock(watcher[0].rq, rq);\n\t\t\tif (err) {\n\t\t\t\ti915_request_add(rq);\n\t\t\t\tintel_context_unpin(ce);\n\t\t\t\tintel_context_put(ce);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tswitch_tl_lock(rq, watcher[1].rq);\n\t\t\terr = intel_timeline_read_hwsp(rq, watcher[1].rq, &hwsp);\n\t\t\tif (err == 0)\n\t\t\t\terr = emit_read_hwsp(watcher[1].rq,  \n\t\t\t\t\t\t     rq->fence.seqno, hwsp,\n\t\t\t\t\t\t     &watcher[1].addr);\n\t\t\tswitch_tl_lock(watcher[1].rq, rq);\n\t\t\tif (err) {\n\t\t\t\ti915_request_add(rq);\n\t\t\t\tintel_context_unpin(ce);\n\t\t\t\tintel_context_put(ce);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ti915_request_get(rq);\n\t\t\ti915_request_add(rq);\n\n\t\t\trq = wrap_timeline(rq);\n\t\t\tintel_context_unpin(ce);\n\t\t\tintel_context_put(ce);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\terr = i915_sw_fence_await_dma_fence(&watcher[1].rq->submit,\n\t\t\t\t\t\t\t    &rq->fence, 0,\n\t\t\t\t\t\t\t    GFP_KERNEL);\n\t\t\tif (err < 0) {\n\t\t\t\ti915_request_put(rq);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\terr = check_watcher(&watcher[0], \"before\", cmp_lt);\n\t\t\ti915_sw_fence_commit(submit);\n\t\t\theap_fence_put(submit);\n\t\t\tif (err) {\n\t\t\t\ti915_request_put(rq);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tcount++;\n\n\t\t\t \n\t\t\tif (i915_request_wait(rq,\n\t\t\t\t\t      I915_WAIT_INTERRUPTIBLE,\n\t\t\t\t\t      HZ) < 0) {\n\t\t\t\terr = -ETIME;\n\t\t\t\ti915_request_put(rq);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tretire_requests(tl);\n\t\t\ti915_request_put(rq);\n\n\t\t\t \n\t\t\tif (8 * watcher[1].rq->ring->emit >\n\t\t\t    3 * watcher[1].rq->ring->size)\n\t\t\t\tbreak;\n\n\t\t} while (!__igt_timeout(end_time, NULL) &&\n\t\t\t count < (PAGE_SIZE / TIMELINE_SEQNO_BYTES - 1) / 2);\n\n\t\tpr_info(\"%s: simulated %lu wraps\\n\", engine->name, count);\n\t\terr = check_watcher(&watcher[1], \"after\", cmp_gte);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\nout:\n\tfor (i = 0; i < ARRAY_SIZE(watcher); i++)\n\t\tcleanup_watcher(&watcher[i]);\n\n\tintel_timeline_unpin(tl);\n\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\nout_free:\n\tintel_timeline_put(tl);\n\treturn err;\n}\n\nstatic int live_hwsp_rollover_kernel(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct intel_context *ce = engine->kernel_context;\n\t\tstruct intel_timeline *tl = ce->timeline;\n\t\tstruct i915_request *rq[3] = {};\n\t\tint i;\n\n\t\tst_engine_heartbeat_disable(engine);\n\t\tif (intel_gt_wait_for_idle(gt, HZ / 2)) {\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tGEM_BUG_ON(i915_active_fence_isset(&tl->last_request));\n\t\ttl->seqno = -2u;\n\t\tWRITE_ONCE(*(u32 *)tl->hwsp_seqno, tl->seqno);\n\n\t\tfor (i = 0; i < ARRAY_SIZE(rq); i++) {\n\t\t\tstruct i915_request *this;\n\n\t\t\tthis = i915_request_create(ce);\n\t\t\tif (IS_ERR(this)) {\n\t\t\t\terr = PTR_ERR(this);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tpr_debug(\"%s: create fence.seqnp:%d\\n\",\n\t\t\t\t engine->name,\n\t\t\t\t lower_32_bits(this->fence.seqno));\n\n\t\t\tGEM_BUG_ON(rcu_access_pointer(this->timeline) != tl);\n\n\t\t\trq[i] = i915_request_get(this);\n\t\t\ti915_request_add(this);\n\t\t}\n\n\t\t \n\t\tGEM_BUG_ON(rq[2]->fence.seqno > rq[0]->fence.seqno);\n\n\t\tif (i915_request_wait(rq[2], 0, HZ / 5) < 0) {\n\t\t\tpr_err(\"Wait for timeline wrap timed out!\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tfor (i = 0; i < ARRAY_SIZE(rq); i++) {\n\t\t\tif (!i915_request_completed(rq[i])) {\n\t\t\t\tpr_err(\"Pre-wrap request not completed!\\n\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\nout:\n\t\tfor (i = 0; i < ARRAY_SIZE(rq); i++)\n\t\t\ti915_request_put(rq[i]);\n\t\tst_engine_heartbeat_enable(engine);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\treturn err;\n}\n\nstatic int live_hwsp_rollover_user(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tint err = 0;\n\n\t \n\n\tfor_each_engine(engine, gt, id) {\n\t\tstruct i915_request *rq[3] = {};\n\t\tstruct intel_timeline *tl;\n\t\tstruct intel_context *ce;\n\t\tint i;\n\n\t\tce = intel_context_create(engine);\n\t\tif (IS_ERR(ce))\n\t\t\treturn PTR_ERR(ce);\n\n\t\terr = intel_context_alloc_state(ce);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\ttl = ce->timeline;\n\t\tif (!tl->has_initial_breadcrumb)\n\t\t\tgoto out;\n\n\t\terr = intel_context_pin(ce);\n\t\tif (err)\n\t\t\tgoto out;\n\n\t\ttl->seqno = -4u;\n\t\tWRITE_ONCE(*(u32 *)tl->hwsp_seqno, tl->seqno);\n\n\t\tfor (i = 0; i < ARRAY_SIZE(rq); i++) {\n\t\t\tstruct i915_request *this;\n\n\t\t\tthis = intel_context_create_request(ce);\n\t\t\tif (IS_ERR(this)) {\n\t\t\t\terr = PTR_ERR(this);\n\t\t\t\tgoto out_unpin;\n\t\t\t}\n\n\t\t\tpr_debug(\"%s: create fence.seqnp:%d\\n\",\n\t\t\t\t engine->name,\n\t\t\t\t lower_32_bits(this->fence.seqno));\n\n\t\t\tGEM_BUG_ON(rcu_access_pointer(this->timeline) != tl);\n\n\t\t\trq[i] = i915_request_get(this);\n\t\t\ti915_request_add(this);\n\t\t}\n\n\t\t \n\t\tGEM_BUG_ON(rq[2]->fence.seqno > rq[0]->fence.seqno);\n\n\t\tif (i915_request_wait(rq[2], 0, HZ / 5) < 0) {\n\t\t\tpr_err(\"Wait for timeline wrap timed out!\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out_unpin;\n\t\t}\n\n\t\tfor (i = 0; i < ARRAY_SIZE(rq); i++) {\n\t\t\tif (!i915_request_completed(rq[i])) {\n\t\t\t\tpr_err(\"Pre-wrap request not completed!\\n\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto out_unpin;\n\t\t\t}\n\t\t}\nout_unpin:\n\t\tintel_context_unpin(ce);\nout:\n\t\tfor (i = 0; i < ARRAY_SIZE(rq); i++)\n\t\t\ti915_request_put(rq[i]);\n\t\tintel_context_put(ce);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\tif (igt_flush_test(gt->i915))\n\t\terr = -EIO;\n\n\treturn err;\n}\n\nstatic int live_hwsp_recycle(void *arg)\n{\n\tstruct intel_gt *gt = arg;\n\tstruct intel_engine_cs *engine;\n\tenum intel_engine_id id;\n\tunsigned long count;\n\tint err = 0;\n\n\t \n\n\tcount = 0;\n\tfor_each_engine(engine, gt, id) {\n\t\tIGT_TIMEOUT(end_time);\n\n\t\tif (!intel_engine_can_store_dword(engine))\n\t\t\tcontinue;\n\n\t\tintel_engine_pm_get(engine);\n\n\t\tdo {\n\t\t\tstruct intel_timeline *tl;\n\t\t\tstruct i915_request *rq;\n\n\t\t\ttl = intel_timeline_create(gt);\n\t\t\tif (IS_ERR(tl)) {\n\t\t\t\terr = PTR_ERR(tl);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\trq = checked_tl_write(tl, engine, count);\n\t\t\tif (IS_ERR(rq)) {\n\t\t\t\tintel_timeline_put(tl);\n\t\t\t\terr = PTR_ERR(rq);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (i915_request_wait(rq, 0, HZ / 5) < 0) {\n\t\t\t\tpr_err(\"Wait for timeline writes timed out!\\n\");\n\t\t\t\ti915_request_put(rq);\n\t\t\t\tintel_timeline_put(tl);\n\t\t\t\terr = -EIO;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (READ_ONCE(*tl->hwsp_seqno) != count) {\n\t\t\t\tGEM_TRACE_ERR(\"Invalid seqno:%lu stored in timeline %llu @ %x found 0x%x\\n\",\n\t\t\t\t\t      count, tl->fence_context,\n\t\t\t\t\t      tl->hwsp_offset, *tl->hwsp_seqno);\n\t\t\t\tGEM_TRACE_DUMP();\n\t\t\t\terr = -EINVAL;\n\t\t\t}\n\n\t\t\ti915_request_put(rq);\n\t\t\tintel_timeline_put(tl);\n\t\t\tcount++;\n\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t} while (!__igt_timeout(end_time, NULL));\n\n\t\tintel_engine_pm_put(engine);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nint intel_timeline_live_selftests(struct drm_i915_private *i915)\n{\n\tstatic const struct i915_subtest tests[] = {\n\t\tSUBTEST(live_hwsp_recycle),\n\t\tSUBTEST(live_hwsp_engine),\n\t\tSUBTEST(live_hwsp_alternate),\n\t\tSUBTEST(live_hwsp_wrap),\n\t\tSUBTEST(live_hwsp_read),\n\t\tSUBTEST(live_hwsp_rollover_kernel),\n\t\tSUBTEST(live_hwsp_rollover_user),\n\t};\n\n\tif (intel_gt_is_wedged(to_gt(i915)))\n\t\treturn 0;\n\n\treturn intel_gt_live_subtests(tests, to_gt(i915));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}