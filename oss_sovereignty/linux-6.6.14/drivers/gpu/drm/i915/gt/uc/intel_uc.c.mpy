{
  "module_name": "intel_uc.c",
  "hash_id": "9af10b690ad36001390ab006f293d0ec4f2a1f7510630b48da724261f8549918",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/uc/intel_uc.c",
  "human_readable_source": "\n \n\n#include <linux/string_helpers.h>\n\n#include \"gt/intel_gt.h\"\n#include \"gt/intel_gt_print.h\"\n#include \"gt/intel_reset.h\"\n#include \"intel_gsc_fw.h\"\n#include \"intel_gsc_uc.h\"\n#include \"intel_guc.h\"\n#include \"intel_guc_ads.h\"\n#include \"intel_guc_print.h\"\n#include \"intel_guc_submission.h\"\n#include \"gt/intel_rps.h\"\n#include \"intel_uc.h\"\n\n#include \"i915_drv.h\"\n#include \"i915_hwmon.h\"\n\nstatic const struct intel_uc_ops uc_ops_off;\nstatic const struct intel_uc_ops uc_ops_on;\n\nstatic void uc_expand_default_options(struct intel_uc *uc)\n{\n\tstruct drm_i915_private *i915 = uc_to_gt(uc)->i915;\n\n\tif (i915->params.enable_guc != -1)\n\t\treturn;\n\n\t \n\tif (GRAPHICS_VER(i915) < 12) {\n\t\ti915->params.enable_guc = 0;\n\t\treturn;\n\t}\n\n\t \n\tif (IS_TIGERLAKE(i915) || IS_ROCKETLAKE(i915)) {\n\t\ti915->params.enable_guc = 0;\n\t\treturn;\n\t}\n\n\t \n\tif (IS_ALDERLAKE_S(i915) && !IS_RAPTORLAKE_S(i915)) {\n\t\ti915->params.enable_guc = ENABLE_GUC_LOAD_HUC;\n\t\treturn;\n\t}\n\n\t \n\ti915->params.enable_guc = ENABLE_GUC_LOAD_HUC | ENABLE_GUC_SUBMISSION;\n\n\t \n\tif (IS_XEHPSDV(i915) || IS_PONTEVECCHIO(i915))\n\t\ti915->params.enable_guc &= ~ENABLE_GUC_LOAD_HUC;\n}\n\n \nstatic int __intel_uc_reset_hw(struct intel_uc *uc)\n{\n\tstruct intel_gt *gt = uc_to_gt(uc);\n\tint ret;\n\tu32 guc_status;\n\n\tret = i915_inject_probe_error(gt->i915, -ENXIO);\n\tif (ret)\n\t\treturn ret;\n\n\tret = intel_reset_guc(gt);\n\tif (ret) {\n\t\tgt_err(gt, \"Failed to reset GuC, ret = %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tguc_status = intel_uncore_read(gt->uncore, GUC_STATUS);\n\tgt_WARN(gt, !(guc_status & GS_MIA_IN_RESET),\n\t\t\"GuC status: 0x%x, MIA core expected to be in reset\\n\",\n\t\tguc_status);\n\n\treturn ret;\n}\n\nstatic void __confirm_options(struct intel_uc *uc)\n{\n\tstruct intel_gt *gt = uc_to_gt(uc);\n\tstruct drm_i915_private *i915 = gt->i915;\n\n\tgt_dbg(gt, \"enable_guc=%d (guc:%s submission:%s huc:%s slpc:%s)\\n\",\n\t       i915->params.enable_guc,\n\t       str_yes_no(intel_uc_wants_guc(uc)),\n\t       str_yes_no(intel_uc_wants_guc_submission(uc)),\n\t       str_yes_no(intel_uc_wants_huc(uc)),\n\t       str_yes_no(intel_uc_wants_guc_slpc(uc)));\n\n\tif (i915->params.enable_guc == 0) {\n\t\tGEM_BUG_ON(intel_uc_wants_guc(uc));\n\t\tGEM_BUG_ON(intel_uc_wants_guc_submission(uc));\n\t\tGEM_BUG_ON(intel_uc_wants_huc(uc));\n\t\tGEM_BUG_ON(intel_uc_wants_guc_slpc(uc));\n\t\treturn;\n\t}\n\n\tif (!intel_uc_supports_guc(uc))\n\t\tgt_info(gt,  \"Incompatible option enable_guc=%d - %s\\n\",\n\t\t\ti915->params.enable_guc, \"GuC is not supported!\");\n\n\tif (i915->params.enable_guc & ENABLE_GUC_LOAD_HUC &&\n\t    !intel_uc_supports_huc(uc))\n\t\tgt_info(gt, \"Incompatible option enable_guc=%d - %s\\n\",\n\t\t\ti915->params.enable_guc, \"HuC is not supported!\");\n\n\tif (i915->params.enable_guc & ENABLE_GUC_SUBMISSION &&\n\t    !intel_uc_supports_guc_submission(uc))\n\t\tgt_info(gt, \"Incompatible option enable_guc=%d - %s\\n\",\n\t\t\ti915->params.enable_guc, \"GuC submission is N/A\");\n\n\tif (i915->params.enable_guc & ~ENABLE_GUC_MASK)\n\t\tgt_info(gt, \"Incompatible option enable_guc=%d - %s\\n\",\n\t\t\ti915->params.enable_guc, \"undocumented flag\");\n}\n\nvoid intel_uc_init_early(struct intel_uc *uc)\n{\n\tuc_expand_default_options(uc);\n\n\tintel_guc_init_early(&uc->guc);\n\tintel_huc_init_early(&uc->huc);\n\tintel_gsc_uc_init_early(&uc->gsc);\n\n\t__confirm_options(uc);\n\n\tif (intel_uc_wants_guc(uc))\n\t\tuc->ops = &uc_ops_on;\n\telse\n\t\tuc->ops = &uc_ops_off;\n}\n\nvoid intel_uc_init_late(struct intel_uc *uc)\n{\n\tintel_guc_init_late(&uc->guc);\n\tintel_gsc_uc_load_start(&uc->gsc);\n}\n\nvoid intel_uc_driver_late_release(struct intel_uc *uc)\n{\n}\n\n \nvoid intel_uc_init_mmio(struct intel_uc *uc)\n{\n\tintel_guc_init_send_regs(&uc->guc);\n}\n\nstatic void __uc_capture_load_err_log(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\n\tif (guc->log.vma && !uc->load_err_log)\n\t\tuc->load_err_log = i915_gem_object_get(guc->log.vma->obj);\n}\n\nstatic void __uc_free_load_err_log(struct intel_uc *uc)\n{\n\tstruct drm_i915_gem_object *log = fetch_and_zero(&uc->load_err_log);\n\n\tif (log)\n\t\ti915_gem_object_put(log);\n}\n\nvoid intel_uc_driver_remove(struct intel_uc *uc)\n{\n\tintel_uc_fini_hw(uc);\n\tintel_uc_fini(uc);\n\t__uc_free_load_err_log(uc);\n}\n\n \nstatic void guc_clear_mmio_msg(struct intel_guc *guc)\n{\n\tintel_uncore_write(guc_to_gt(guc)->uncore, SOFT_SCRATCH(15), 0);\n}\n\nstatic void guc_get_mmio_msg(struct intel_guc *guc)\n{\n\tu32 val;\n\n\tspin_lock_irq(&guc->irq_lock);\n\n\tval = intel_uncore_read(guc_to_gt(guc)->uncore, SOFT_SCRATCH(15));\n\tguc->mmio_msg |= val & guc->msg_enabled_mask;\n\n\t \n\tguc_clear_mmio_msg(guc);\n\n\tspin_unlock_irq(&guc->irq_lock);\n}\n\nstatic void guc_handle_mmio_msg(struct intel_guc *guc)\n{\n\t \n\tGEM_BUG_ON(!intel_guc_ct_enabled(&guc->ct));\n\n\tspin_lock_irq(&guc->irq_lock);\n\tif (guc->mmio_msg) {\n\t\tintel_guc_to_host_process_recv_msg(guc, &guc->mmio_msg, 1);\n\t\tguc->mmio_msg = 0;\n\t}\n\tspin_unlock_irq(&guc->irq_lock);\n}\n\nstatic int guc_enable_communication(struct intel_guc *guc)\n{\n\tstruct intel_gt *gt = guc_to_gt(guc);\n\tstruct drm_i915_private *i915 = gt->i915;\n\tint ret;\n\n\tGEM_BUG_ON(intel_guc_ct_enabled(&guc->ct));\n\n\tret = i915_inject_probe_error(i915, -ENXIO);\n\tif (ret)\n\t\treturn ret;\n\n\tret = intel_guc_ct_enable(&guc->ct);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tguc_get_mmio_msg(guc);\n\tguc_handle_mmio_msg(guc);\n\n\tintel_guc_enable_interrupts(guc);\n\n\t \n\tspin_lock_irq(gt->irq_lock);\n\tintel_guc_ct_event_handler(&guc->ct);\n\tspin_unlock_irq(gt->irq_lock);\n\n\tguc_dbg(guc, \"communication enabled\\n\");\n\n\treturn 0;\n}\n\nstatic void guc_disable_communication(struct intel_guc *guc)\n{\n\t \n\tguc_clear_mmio_msg(guc);\n\n\tintel_guc_disable_interrupts(guc);\n\n\tintel_guc_ct_disable(&guc->ct);\n\n\t \n\tguc_get_mmio_msg(guc);\n\n\tguc_dbg(guc, \"communication disabled\\n\");\n}\n\nstatic void __uc_fetch_firmwares(struct intel_uc *uc)\n{\n\tstruct intel_gt *gt = uc_to_gt(uc);\n\tint err;\n\n\tGEM_BUG_ON(!intel_uc_wants_guc(uc));\n\n\terr = intel_uc_fw_fetch(&uc->guc.fw);\n\tif (err) {\n\t\t \n\t\tif (intel_uc_wants_huc(uc)) {\n\t\t\tgt_dbg(gt, \"Failed to fetch GuC fw (%pe) disabling HuC\\n\", ERR_PTR(err));\n\t\t\tintel_uc_fw_change_status(&uc->huc.fw,\n\t\t\t\t\t\t  INTEL_UC_FIRMWARE_ERROR);\n\t\t}\n\n\t\tif (intel_uc_wants_gsc_uc(uc)) {\n\t\t\tgt_dbg(gt, \"Failed to fetch GuC fw (%pe) disabling GSC\\n\", ERR_PTR(err));\n\t\t\tintel_uc_fw_change_status(&uc->gsc.fw,\n\t\t\t\t\t\t  INTEL_UC_FIRMWARE_ERROR);\n\t\t}\n\n\t\treturn;\n\t}\n\n\tif (intel_uc_wants_huc(uc))\n\t\tintel_uc_fw_fetch(&uc->huc.fw);\n\n\tif (intel_uc_wants_gsc_uc(uc))\n\t\tintel_uc_fw_fetch(&uc->gsc.fw);\n}\n\nstatic void __uc_cleanup_firmwares(struct intel_uc *uc)\n{\n\tintel_uc_fw_cleanup_fetch(&uc->gsc.fw);\n\tintel_uc_fw_cleanup_fetch(&uc->huc.fw);\n\tintel_uc_fw_cleanup_fetch(&uc->guc.fw);\n}\n\nstatic int __uc_init(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\tstruct intel_huc *huc = &uc->huc;\n\tint ret;\n\n\tGEM_BUG_ON(!intel_uc_wants_guc(uc));\n\n\tif (!intel_uc_uses_guc(uc))\n\t\treturn 0;\n\n\tif (i915_inject_probe_failure(uc_to_gt(uc)->i915))\n\t\treturn -ENOMEM;\n\n\tret = intel_guc_init(guc);\n\tif (ret)\n\t\treturn ret;\n\n\tif (intel_uc_uses_huc(uc))\n\t\tintel_huc_init(huc);\n\n\tif (intel_uc_uses_gsc_uc(uc))\n\t\tintel_gsc_uc_init(&uc->gsc);\n\n\treturn 0;\n}\n\nstatic void __uc_fini(struct intel_uc *uc)\n{\n\tintel_gsc_uc_fini(&uc->gsc);\n\tintel_huc_fini(&uc->huc);\n\tintel_guc_fini(&uc->guc);\n}\n\nstatic int __uc_sanitize(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\tstruct intel_huc *huc = &uc->huc;\n\n\tGEM_BUG_ON(!intel_uc_supports_guc(uc));\n\n\tintel_huc_sanitize(huc);\n\tintel_guc_sanitize(guc);\n\n\treturn __intel_uc_reset_hw(uc);\n}\n\n \nstatic int uc_init_wopcm(struct intel_uc *uc)\n{\n\tstruct intel_gt *gt = uc_to_gt(uc);\n\tstruct intel_uncore *uncore = gt->uncore;\n\tu32 base = intel_wopcm_guc_base(&gt->wopcm);\n\tu32 size = intel_wopcm_guc_size(&gt->wopcm);\n\tu32 huc_agent = intel_uc_uses_huc(uc) ? HUC_LOADING_AGENT_GUC : 0;\n\tu32 mask;\n\tint err;\n\n\tif (unlikely(!base || !size)) {\n\t\tgt_probe_error(gt, \"Unsuccessful WOPCM partitioning\\n\");\n\t\treturn -E2BIG;\n\t}\n\n\tGEM_BUG_ON(!intel_uc_supports_guc(uc));\n\tGEM_BUG_ON(!(base & GUC_WOPCM_OFFSET_MASK));\n\tGEM_BUG_ON(base & ~GUC_WOPCM_OFFSET_MASK);\n\tGEM_BUG_ON(!(size & GUC_WOPCM_SIZE_MASK));\n\tGEM_BUG_ON(size & ~GUC_WOPCM_SIZE_MASK);\n\n\terr = i915_inject_probe_error(gt->i915, -ENXIO);\n\tif (err)\n\t\treturn err;\n\n\tmask = GUC_WOPCM_SIZE_MASK | GUC_WOPCM_SIZE_LOCKED;\n\terr = intel_uncore_write_and_verify(uncore, GUC_WOPCM_SIZE, size, mask,\n\t\t\t\t\t    size | GUC_WOPCM_SIZE_LOCKED);\n\tif (err)\n\t\tgoto err_out;\n\n\tmask = GUC_WOPCM_OFFSET_MASK | GUC_WOPCM_OFFSET_VALID | huc_agent;\n\terr = intel_uncore_write_and_verify(uncore, DMA_GUC_WOPCM_OFFSET,\n\t\t\t\t\t    base | huc_agent, mask,\n\t\t\t\t\t    base | huc_agent |\n\t\t\t\t\t    GUC_WOPCM_OFFSET_VALID);\n\tif (err)\n\t\tgoto err_out;\n\n\treturn 0;\n\nerr_out:\n\tgt_probe_error(gt, \"Failed to init uC WOPCM registers!\\n\");\n\tgt_probe_error(gt, \"%s(%#x)=%#x\\n\", \"DMA_GUC_WOPCM_OFFSET\",\n\t\t       i915_mmio_reg_offset(DMA_GUC_WOPCM_OFFSET),\n\t\t       intel_uncore_read(uncore, DMA_GUC_WOPCM_OFFSET));\n\tgt_probe_error(gt, \"%s(%#x)=%#x\\n\", \"GUC_WOPCM_SIZE\",\n\t\t       i915_mmio_reg_offset(GUC_WOPCM_SIZE),\n\t\t       intel_uncore_read(uncore, GUC_WOPCM_SIZE));\n\n\treturn err;\n}\n\nstatic bool uc_is_wopcm_locked(struct intel_uc *uc)\n{\n\tstruct intel_gt *gt = uc_to_gt(uc);\n\tstruct intel_uncore *uncore = gt->uncore;\n\n\treturn (intel_uncore_read(uncore, GUC_WOPCM_SIZE) & GUC_WOPCM_SIZE_LOCKED) ||\n\t       (intel_uncore_read(uncore, DMA_GUC_WOPCM_OFFSET) & GUC_WOPCM_OFFSET_VALID);\n}\n\nstatic int __uc_check_hw(struct intel_uc *uc)\n{\n\tif (uc->fw_table_invalid)\n\t\treturn -EIO;\n\n\tif (!intel_uc_supports_guc(uc))\n\t\treturn 0;\n\n\t \n\tif (uc_is_wopcm_locked(uc))\n\t\treturn -EIO;\n\n\treturn 0;\n}\n\nstatic void print_fw_ver(struct intel_gt *gt, struct intel_uc_fw *fw)\n{\n\tgt_info(gt, \"%s firmware %s version %u.%u.%u\\n\",\n\t\tintel_uc_fw_type_repr(fw->type), fw->file_selected.path,\n\t\tfw->file_selected.ver.major,\n\t\tfw->file_selected.ver.minor,\n\t\tfw->file_selected.ver.patch);\n}\n\nstatic int __uc_init_hw(struct intel_uc *uc)\n{\n\tstruct intel_gt *gt = uc_to_gt(uc);\n\tstruct drm_i915_private *i915 = gt->i915;\n\tstruct intel_guc *guc = &uc->guc;\n\tstruct intel_huc *huc = &uc->huc;\n\tint ret, attempts;\n\tbool pl1en = false;\n\n\tGEM_BUG_ON(!intel_uc_supports_guc(uc));\n\tGEM_BUG_ON(!intel_uc_wants_guc(uc));\n\n\tprint_fw_ver(gt, &guc->fw);\n\n\tif (intel_uc_uses_huc(uc))\n\t\tprint_fw_ver(gt, &huc->fw);\n\n\tif (!intel_uc_fw_is_loadable(&guc->fw)) {\n\t\tret = __uc_check_hw(uc) ||\n\t\t      intel_uc_fw_is_overridden(&guc->fw) ||\n\t\t      intel_uc_wants_guc_submission(uc) ?\n\t\t      intel_uc_fw_status_to_error(guc->fw.status) : 0;\n\t\tgoto err_out;\n\t}\n\n\tret = uc_init_wopcm(uc);\n\tif (ret)\n\t\tgoto err_out;\n\n\tintel_guc_reset_interrupts(guc);\n\n\t \n\t \n\tif (GRAPHICS_VER(i915) == 9)\n\t\tattempts = 3;\n\telse\n\t\tattempts = 1;\n\n\t \n\ti915_hwmon_power_max_disable(gt->i915, &pl1en);\n\n\tintel_rps_raise_unslice(&uc_to_gt(uc)->rps);\n\n\twhile (attempts--) {\n\t\t \n\t\tret = __uc_sanitize(uc);\n\t\tif (ret)\n\t\t\tgoto err_rps;\n\n\t\tintel_huc_fw_upload(huc);\n\t\tintel_guc_ads_reset(guc);\n\t\tintel_guc_write_params(guc);\n\t\tret = intel_guc_fw_upload(guc);\n\t\tif (ret == 0)\n\t\t\tbreak;\n\n\t\tgt_dbg(gt, \"GuC fw load failed (%pe) will reset and retry %d more time(s)\\n\",\n\t\t       ERR_PTR(ret), attempts);\n\t}\n\n\t \n\tif (ret)\n\t\tgoto err_log_capture;\n\n\tret = guc_enable_communication(guc);\n\tif (ret)\n\t\tgoto err_log_capture;\n\n\t \n\tif (intel_huc_is_loaded_by_gsc(huc))\n\t\tintel_huc_update_auth_status(huc);\n\telse\n\t\tintel_huc_auth(huc, INTEL_HUC_AUTH_BY_GUC);\n\n\tif (intel_uc_uses_guc_submission(uc)) {\n\t\tret = intel_guc_submission_enable(guc);\n\t\tif (ret)\n\t\t\tgoto err_log_capture;\n\t}\n\n\tif (intel_uc_uses_guc_slpc(uc)) {\n\t\tret = intel_guc_slpc_enable(&guc->slpc);\n\t\tif (ret)\n\t\t\tgoto err_submission;\n\t} else {\n\t\t \n\t\tintel_rps_lower_unslice(&uc_to_gt(uc)->rps);\n\t}\n\n\ti915_hwmon_power_max_restore(gt->i915, pl1en);\n\n\tguc_info(guc, \"submission %s\\n\", str_enabled_disabled(intel_uc_uses_guc_submission(uc)));\n\tguc_info(guc, \"SLPC %s\\n\", str_enabled_disabled(intel_uc_uses_guc_slpc(uc)));\n\n\treturn 0;\n\n\t \nerr_submission:\n\tintel_guc_submission_disable(guc);\nerr_log_capture:\n\t__uc_capture_load_err_log(uc);\nerr_rps:\n\t \n\tintel_rps_lower_unslice(&uc_to_gt(uc)->rps);\n\n\ti915_hwmon_power_max_restore(gt->i915, pl1en);\nerr_out:\n\t__uc_sanitize(uc);\n\n\tif (!ret) {\n\t\tgt_notice(gt, \"GuC is uninitialized\\n\");\n\t\t \n\t\treturn 0;\n\t}\n\n\tgt_probe_error(gt, \"GuC initialization failed %pe\\n\", ERR_PTR(ret));\n\n\t \n\treturn -EIO;\n}\n\nstatic void __uc_fini_hw(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\n\tif (!intel_guc_is_fw_running(guc))\n\t\treturn;\n\n\tif (intel_uc_uses_guc_submission(uc))\n\t\tintel_guc_submission_disable(guc);\n\n\t__uc_sanitize(uc);\n}\n\n \nvoid intel_uc_reset_prepare(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\n\tuc->reset_in_progress = true;\n\n\t \n\tif (!intel_uc_supports_guc(uc))\n\t\treturn;\n\n\t \n\tif (!intel_guc_is_ready(guc))\n\t\tgoto sanitize;\n\n\tif (intel_uc_uses_guc_submission(uc))\n\t\tintel_guc_submission_reset_prepare(guc);\n\nsanitize:\n\t__uc_sanitize(uc);\n}\n\nvoid intel_uc_reset(struct intel_uc *uc, intel_engine_mask_t stalled)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\n\t \n\tif (intel_uc_uses_guc_submission(uc))\n\t\tintel_guc_submission_reset(guc, stalled);\n}\n\nvoid intel_uc_reset_finish(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\n\tuc->reset_in_progress = false;\n\n\t \n\tif (intel_guc_is_fw_running(guc) && intel_uc_uses_guc_submission(uc))\n\t\tintel_guc_submission_reset_finish(guc);\n}\n\nvoid intel_uc_cancel_requests(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\n\t \n\tif (intel_uc_uses_guc_submission(uc))\n\t\tintel_guc_submission_cancel_requests(guc);\n}\n\nvoid intel_uc_runtime_suspend(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\n\tif (!intel_guc_is_ready(guc)) {\n\t\tguc->interrupts.enabled = false;\n\t\treturn;\n\t}\n\n\t \n#define OUTSTANDING_CTB_TIMEOUT_PERIOD\t(HZ / 5)\n\tintel_guc_wait_for_pending_msg(guc, &guc->outstanding_submission_g2h,\n\t\t\t\t       false, OUTSTANDING_CTB_TIMEOUT_PERIOD);\n\tGEM_WARN_ON(atomic_read(&guc->outstanding_submission_g2h));\n\n\tguc_disable_communication(guc);\n}\n\nvoid intel_uc_suspend(struct intel_uc *uc)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\tintel_wakeref_t wakeref;\n\tint err;\n\n\t \n\tintel_gsc_uc_flush_work(&uc->gsc);\n\n\tif (!intel_guc_is_ready(guc)) {\n\t\tguc->interrupts.enabled = false;\n\t\treturn;\n\t}\n\n\twith_intel_runtime_pm(&uc_to_gt(uc)->i915->runtime_pm, wakeref) {\n\t\terr = intel_guc_suspend(guc);\n\t\tif (err)\n\t\t\tguc_dbg(guc, \"Failed to suspend, %pe\", ERR_PTR(err));\n\t}\n}\n\nstatic void __uc_resume_mappings(struct intel_uc *uc)\n{\n\tintel_uc_fw_resume_mapping(&uc->guc.fw);\n\tintel_uc_fw_resume_mapping(&uc->huc.fw);\n}\n\nstatic int __uc_resume(struct intel_uc *uc, bool enable_communication)\n{\n\tstruct intel_guc *guc = &uc->guc;\n\tstruct intel_gt *gt = guc_to_gt(guc);\n\tint err;\n\n\tif (!intel_guc_is_fw_running(guc))\n\t\treturn 0;\n\n\t \n\tGEM_BUG_ON(enable_communication == intel_guc_ct_enabled(&guc->ct));\n\n\tif (enable_communication)\n\t\tguc_enable_communication(guc);\n\n\t \n\tif (enable_communication && intel_uc_uses_guc_slpc(uc))\n\t\tintel_guc_pm_intrmsk_enable(gt);\n\n\terr = intel_guc_resume(guc);\n\tif (err) {\n\t\tguc_dbg(guc, \"Failed to resume, %pe\", ERR_PTR(err));\n\t\treturn err;\n\t}\n\n\tintel_gsc_uc_resume(&uc->gsc);\n\n\treturn 0;\n}\n\nint intel_uc_resume(struct intel_uc *uc)\n{\n\t \n\treturn __uc_resume(uc, false);\n}\n\nint intel_uc_runtime_resume(struct intel_uc *uc)\n{\n\t \n\treturn __uc_resume(uc, true);\n}\n\nstatic const struct intel_uc_ops uc_ops_off = {\n\t.init_hw = __uc_check_hw,\n\t.fini = __uc_fini,  \n};\n\nstatic const struct intel_uc_ops uc_ops_on = {\n\t.sanitize = __uc_sanitize,\n\n\t.init_fw = __uc_fetch_firmwares,\n\t.fini_fw = __uc_cleanup_firmwares,\n\n\t.init = __uc_init,\n\t.fini = __uc_fini,\n\n\t.init_hw = __uc_init_hw,\n\t.fini_hw = __uc_fini_hw,\n\n\t.resume_mappings = __uc_resume_mappings,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}