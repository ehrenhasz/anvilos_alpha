{
  "module_name": "intel_huc.c",
  "hash_id": "95cbe2c1ce799987899b7549371d87e705b1e26f24755e5ee506780d4273027e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/uc/intel_huc.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n\n#include \"gt/intel_gt.h\"\n#include \"intel_guc_reg.h\"\n#include \"intel_huc.h\"\n#include \"intel_huc_print.h\"\n#include \"i915_drv.h\"\n#include \"i915_reg.h\"\n#include \"pxp/intel_pxp_cmd_interface_43.h\"\n\n#include <linux/device/bus.h>\n#include <linux/mei_aux.h>\n\n \n\n \n\n \n#define GSC_INIT_TIMEOUT_MS 10000\n#define PXP_INIT_TIMEOUT_MS 5000\n\nstatic int sw_fence_dummy_notify(struct i915_sw_fence *sf,\n\t\t\t\t enum i915_sw_fence_notify state)\n{\n\treturn NOTIFY_DONE;\n}\n\nstatic void __delayed_huc_load_complete(struct intel_huc *huc)\n{\n\tif (!i915_sw_fence_done(&huc->delayed_load.fence))\n\t\ti915_sw_fence_complete(&huc->delayed_load.fence);\n}\n\nstatic void delayed_huc_load_complete(struct intel_huc *huc)\n{\n\thrtimer_cancel(&huc->delayed_load.timer);\n\t__delayed_huc_load_complete(huc);\n}\n\nstatic void __gsc_init_error(struct intel_huc *huc)\n{\n\thuc->delayed_load.status = INTEL_HUC_DELAYED_LOAD_ERROR;\n\t__delayed_huc_load_complete(huc);\n}\n\nstatic void gsc_init_error(struct intel_huc *huc)\n{\n\thrtimer_cancel(&huc->delayed_load.timer);\n\t__gsc_init_error(huc);\n}\n\nstatic void gsc_init_done(struct intel_huc *huc)\n{\n\thrtimer_cancel(&huc->delayed_load.timer);\n\n\t \n\thuc->delayed_load.status = INTEL_HUC_WAITING_ON_PXP;\n\tif (!i915_sw_fence_done(&huc->delayed_load.fence))\n\t\thrtimer_start(&huc->delayed_load.timer,\n\t\t\t      ms_to_ktime(PXP_INIT_TIMEOUT_MS),\n\t\t\t      HRTIMER_MODE_REL);\n}\n\nstatic enum hrtimer_restart huc_delayed_load_timer_callback(struct hrtimer *hrtimer)\n{\n\tstruct intel_huc *huc = container_of(hrtimer, struct intel_huc, delayed_load.timer);\n\n\tif (!intel_huc_is_authenticated(huc, INTEL_HUC_AUTH_BY_GSC)) {\n\t\tif (huc->delayed_load.status == INTEL_HUC_WAITING_ON_GSC)\n\t\t\thuc_notice(huc, \"timed out waiting for MEI GSC\\n\");\n\t\telse if (huc->delayed_load.status == INTEL_HUC_WAITING_ON_PXP)\n\t\t\thuc_notice(huc, \"timed out waiting for MEI PXP\\n\");\n\t\telse\n\t\t\tMISSING_CASE(huc->delayed_load.status);\n\n\t\t__gsc_init_error(huc);\n\t}\n\n\treturn HRTIMER_NORESTART;\n}\n\nstatic void huc_delayed_load_start(struct intel_huc *huc)\n{\n\tktime_t delay;\n\n\tGEM_BUG_ON(intel_huc_is_authenticated(huc, INTEL_HUC_AUTH_BY_GSC));\n\n\t \n\tswitch (huc->delayed_load.status) {\n\tcase INTEL_HUC_WAITING_ON_GSC:\n\t\tdelay = ms_to_ktime(GSC_INIT_TIMEOUT_MS);\n\t\tbreak;\n\tcase INTEL_HUC_WAITING_ON_PXP:\n\t\tdelay = ms_to_ktime(PXP_INIT_TIMEOUT_MS);\n\t\tbreak;\n\tdefault:\n\t\tgsc_init_error(huc);\n\t\treturn;\n\t}\n\n\t \n\tGEM_BUG_ON(!i915_sw_fence_done(&huc->delayed_load.fence));\n\ti915_sw_fence_fini(&huc->delayed_load.fence);\n\ti915_sw_fence_reinit(&huc->delayed_load.fence);\n\ti915_sw_fence_await(&huc->delayed_load.fence);\n\ti915_sw_fence_commit(&huc->delayed_load.fence);\n\n\thrtimer_start(&huc->delayed_load.timer, delay, HRTIMER_MODE_REL);\n}\n\nstatic int gsc_notifier(struct notifier_block *nb, unsigned long action, void *data)\n{\n\tstruct device *dev = data;\n\tstruct intel_huc *huc = container_of(nb, struct intel_huc, delayed_load.nb);\n\tstruct intel_gsc_intf *intf = &huc_to_gt(huc)->gsc.intf[0];\n\n\tif (!intf->adev || &intf->adev->aux_dev.dev != dev)\n\t\treturn 0;\n\n\tswitch (action) {\n\tcase BUS_NOTIFY_BOUND_DRIVER:  \n\t\tgsc_init_done(huc);\n\t\tbreak;\n\n\tcase BUS_NOTIFY_DRIVER_NOT_BOUND:  \n\tcase BUS_NOTIFY_UNBIND_DRIVER:  \n\t\thuc_info(huc, \"MEI driver not bound, disabling load\\n\");\n\t\tgsc_init_error(huc);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nvoid intel_huc_register_gsc_notifier(struct intel_huc *huc, const struct bus_type *bus)\n{\n\tint ret;\n\n\tif (!intel_huc_is_loaded_by_gsc(huc))\n\t\treturn;\n\n\thuc->delayed_load.nb.notifier_call = gsc_notifier;\n\tret = bus_register_notifier(bus, &huc->delayed_load.nb);\n\tif (ret) {\n\t\thuc_err(huc, \"failed to register GSC notifier %pe\\n\", ERR_PTR(ret));\n\t\thuc->delayed_load.nb.notifier_call = NULL;\n\t\tgsc_init_error(huc);\n\t}\n}\n\nvoid intel_huc_unregister_gsc_notifier(struct intel_huc *huc, const struct bus_type *bus)\n{\n\tif (!huc->delayed_load.nb.notifier_call)\n\t\treturn;\n\n\tdelayed_huc_load_complete(huc);\n\n\tbus_unregister_notifier(bus, &huc->delayed_load.nb);\n\thuc->delayed_load.nb.notifier_call = NULL;\n}\n\nstatic void delayed_huc_load_init(struct intel_huc *huc)\n{\n\t \n\ti915_sw_fence_init(&huc->delayed_load.fence,\n\t\t\t   sw_fence_dummy_notify);\n\ti915_sw_fence_commit(&huc->delayed_load.fence);\n\n\thrtimer_init(&huc->delayed_load.timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\thuc->delayed_load.timer.function = huc_delayed_load_timer_callback;\n}\n\nstatic void delayed_huc_load_fini(struct intel_huc *huc)\n{\n\t \n\tdelayed_huc_load_complete(huc);\n\ti915_sw_fence_fini(&huc->delayed_load.fence);\n}\n\nint intel_huc_sanitize(struct intel_huc *huc)\n{\n\tdelayed_huc_load_complete(huc);\n\tintel_uc_fw_sanitize(&huc->fw);\n\treturn 0;\n}\n\nstatic bool vcs_supported(struct intel_gt *gt)\n{\n\tintel_engine_mask_t mask = gt->info.engine_mask;\n\n\t \n\tGEM_BUG_ON(!gt_is_root(gt) && !gt->info.engine_mask);\n\n\tif (gt_is_root(gt))\n\t\tmask = INTEL_INFO(gt->i915)->platform_engine_mask;\n\telse\n\t\tmask = gt->info.engine_mask;\n\n\treturn __ENGINE_INSTANCES_MASK(mask, VCS0, I915_MAX_VCS);\n}\n\nvoid intel_huc_init_early(struct intel_huc *huc)\n{\n\tstruct drm_i915_private *i915 = huc_to_gt(huc)->i915;\n\tstruct intel_gt *gt = huc_to_gt(huc);\n\n\tintel_uc_fw_init_early(&huc->fw, INTEL_UC_FW_TYPE_HUC, true);\n\n\t \n\tdelayed_huc_load_init(huc);\n\n\tif (!vcs_supported(gt)) {\n\t\tintel_uc_fw_change_status(&huc->fw, INTEL_UC_FIRMWARE_NOT_SUPPORTED);\n\t\treturn;\n\t}\n\n\tif (GRAPHICS_VER(i915) >= 11) {\n\t\thuc->status[INTEL_HUC_AUTH_BY_GUC].reg = GEN11_HUC_KERNEL_LOAD_INFO;\n\t\thuc->status[INTEL_HUC_AUTH_BY_GUC].mask = HUC_LOAD_SUCCESSFUL;\n\t\thuc->status[INTEL_HUC_AUTH_BY_GUC].value = HUC_LOAD_SUCCESSFUL;\n\t} else {\n\t\thuc->status[INTEL_HUC_AUTH_BY_GUC].reg = HUC_STATUS2;\n\t\thuc->status[INTEL_HUC_AUTH_BY_GUC].mask = HUC_FW_VERIFIED;\n\t\thuc->status[INTEL_HUC_AUTH_BY_GUC].value = HUC_FW_VERIFIED;\n\t}\n\n\tif (IS_DG2(i915)) {\n\t\thuc->status[INTEL_HUC_AUTH_BY_GSC].reg = GEN11_HUC_KERNEL_LOAD_INFO;\n\t\thuc->status[INTEL_HUC_AUTH_BY_GSC].mask = HUC_LOAD_SUCCESSFUL;\n\t\thuc->status[INTEL_HUC_AUTH_BY_GSC].value = HUC_LOAD_SUCCESSFUL;\n\t} else {\n\t\thuc->status[INTEL_HUC_AUTH_BY_GSC].reg = HECI_FWSTS(MTL_GSC_HECI1_BASE, 5);\n\t\thuc->status[INTEL_HUC_AUTH_BY_GSC].mask = HECI1_FWSTS5_HUC_AUTH_DONE;\n\t\thuc->status[INTEL_HUC_AUTH_BY_GSC].value = HECI1_FWSTS5_HUC_AUTH_DONE;\n\t}\n}\n\n#define HUC_LOAD_MODE_STRING(x) (x ? \"GSC\" : \"legacy\")\nstatic int check_huc_loading_mode(struct intel_huc *huc)\n{\n\tstruct intel_gt *gt = huc_to_gt(huc);\n\tbool gsc_enabled = huc->fw.has_gsc_headers;\n\n\t \n\tif (HAS_GUC_DEPRIVILEGE(gt->i915))\n\t\thuc->loaded_via_gsc = intel_uncore_read(gt->uncore, GUC_SHIM_CONTROL2) &\n\t\t\t\t      GSC_LOADS_HUC;\n\n\tif (huc->loaded_via_gsc && !gsc_enabled) {\n\t\thuc_err(huc, \"HW requires a GSC-enabled blob, but we found a legacy one\\n\");\n\t\treturn -ENOEXEC;\n\t}\n\n\t \n\tif (!huc->loaded_via_gsc && gsc_enabled && !huc->fw.dma_start_offset) {\n\t\thuc_err(huc, \"HW in DMA mode, but we have an incompatible GSC-enabled blob\\n\");\n\t\treturn -ENOEXEC;\n\t}\n\n\t \n\tif (huc->loaded_via_gsc) {\n\t\tif (IS_DG2(gt->i915)) {\n\t\t\tif (!IS_ENABLED(CONFIG_INTEL_MEI_PXP) ||\n\t\t\t    !IS_ENABLED(CONFIG_INTEL_MEI_GSC)) {\n\t\t\t\thuc_info(huc, \"can't load due to missing mei modules\\n\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} else {\n\t\t\tif (!HAS_ENGINE(gt, GSC0)) {\n\t\t\t\thuc_info(huc, \"can't load due to missing GSCCS\\n\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t}\n\n\thuc_dbg(huc, \"loaded by GSC = %s\\n\", str_yes_no(huc->loaded_via_gsc));\n\n\treturn 0;\n}\n\nint intel_huc_init(struct intel_huc *huc)\n{\n\tstruct intel_gt *gt = huc_to_gt(huc);\n\tint err;\n\n\terr = check_huc_loading_mode(huc);\n\tif (err)\n\t\tgoto out;\n\n\tif (HAS_ENGINE(gt, GSC0)) {\n\t\tstruct i915_vma *vma;\n\n\t\tvma = intel_guc_allocate_vma(&gt->uc.guc, PXP43_HUC_AUTH_INOUT_SIZE * 2);\n\t\tif (IS_ERR(vma)) {\n\t\t\terr = PTR_ERR(vma);\n\t\t\thuc_info(huc, \"Failed to allocate heci pkt\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\thuc->heci_pkt = vma;\n\t}\n\n\terr = intel_uc_fw_init(&huc->fw);\n\tif (err)\n\t\tgoto out_pkt;\n\n\tintel_uc_fw_change_status(&huc->fw, INTEL_UC_FIRMWARE_LOADABLE);\n\n\treturn 0;\n\nout_pkt:\n\tif (huc->heci_pkt)\n\t\ti915_vma_unpin_and_release(&huc->heci_pkt, 0);\nout:\n\tintel_uc_fw_change_status(&huc->fw, INTEL_UC_FIRMWARE_INIT_FAIL);\n\thuc_info(huc, \"initialization failed %pe\\n\", ERR_PTR(err));\n\treturn err;\n}\n\nvoid intel_huc_fini(struct intel_huc *huc)\n{\n\t \n\tdelayed_huc_load_fini(huc);\n\n\tif (huc->heci_pkt)\n\t\ti915_vma_unpin_and_release(&huc->heci_pkt, 0);\n\n\tif (intel_uc_fw_is_loadable(&huc->fw))\n\t\tintel_uc_fw_fini(&huc->fw);\n}\n\nvoid intel_huc_suspend(struct intel_huc *huc)\n{\n\tif (!intel_uc_fw_is_loadable(&huc->fw))\n\t\treturn;\n\n\t \n\tdelayed_huc_load_complete(huc);\n}\n\nstatic const char *auth_mode_string(struct intel_huc *huc,\n\t\t\t\t    enum intel_huc_authentication_type type)\n{\n\tbool partial = huc->fw.has_gsc_headers && type == INTEL_HUC_AUTH_BY_GUC;\n\n\treturn partial ? \"clear media\" : \"all workloads\";\n}\n\nint intel_huc_wait_for_auth_complete(struct intel_huc *huc,\n\t\t\t\t     enum intel_huc_authentication_type type)\n{\n\tstruct intel_gt *gt = huc_to_gt(huc);\n\tint ret;\n\n\tret = __intel_wait_for_register(gt->uncore,\n\t\t\t\t\thuc->status[type].reg,\n\t\t\t\t\thuc->status[type].mask,\n\t\t\t\t\thuc->status[type].value,\n\t\t\t\t\t2, 50, NULL);\n\n\t \n\tdelayed_huc_load_complete(huc);\n\n\tif (ret) {\n\t\thuc_err(huc, \"firmware not verified for %s: %pe\\n\",\n\t\t\tauth_mode_string(huc, type), ERR_PTR(ret));\n\t\tintel_uc_fw_change_status(&huc->fw, INTEL_UC_FIRMWARE_LOAD_FAIL);\n\t\treturn ret;\n\t}\n\n\tintel_uc_fw_change_status(&huc->fw, INTEL_UC_FIRMWARE_RUNNING);\n\thuc_info(huc, \"authenticated for %s\\n\", auth_mode_string(huc, type));\n\treturn 0;\n}\n\n \nint intel_huc_auth(struct intel_huc *huc, enum intel_huc_authentication_type type)\n{\n\tstruct intel_gt *gt = huc_to_gt(huc);\n\tstruct intel_guc *guc = &gt->uc.guc;\n\tint ret;\n\n\tif (!intel_uc_fw_is_loaded(&huc->fw))\n\t\treturn -ENOEXEC;\n\n\t \n\tif (intel_huc_is_loaded_by_gsc(huc))\n\t\treturn -ENODEV;\n\n\tif (intel_huc_is_authenticated(huc, type))\n\t\treturn -EEXIST;\n\n\tret = i915_inject_probe_error(gt->i915, -ENXIO);\n\tif (ret)\n\t\tgoto fail;\n\n\tswitch (type) {\n\tcase INTEL_HUC_AUTH_BY_GUC:\n\t\tret = intel_guc_auth_huc(guc, intel_guc_ggtt_offset(guc, huc->fw.rsa_data));\n\t\tbreak;\n\tcase INTEL_HUC_AUTH_BY_GSC:\n\t\tret = intel_huc_fw_auth_via_gsccs(huc);\n\t\tbreak;\n\tdefault:\n\t\tMISSING_CASE(type);\n\t\tret = -EINVAL;\n\t}\n\tif (ret)\n\t\tgoto fail;\n\n\t \n\tret = intel_huc_wait_for_auth_complete(huc, type);\n\tif (ret)\n\t\tgoto fail;\n\n\treturn 0;\n\nfail:\n\thuc_probe_error(huc, \"%s authentication failed %pe\\n\",\n\t\t\tauth_mode_string(huc, type), ERR_PTR(ret));\n\treturn ret;\n}\n\nbool intel_huc_is_authenticated(struct intel_huc *huc,\n\t\t\t\tenum intel_huc_authentication_type type)\n{\n\tstruct intel_gt *gt = huc_to_gt(huc);\n\tintel_wakeref_t wakeref;\n\tu32 status = 0;\n\n\twith_intel_runtime_pm(gt->uncore->rpm, wakeref)\n\t\tstatus = intel_uncore_read(gt->uncore, huc->status[type].reg);\n\n\treturn (status & huc->status[type].mask) == huc->status[type].value;\n}\n\nstatic bool huc_is_fully_authenticated(struct intel_huc *huc)\n{\n\tstruct intel_uc_fw *huc_fw = &huc->fw;\n\n\tif (!huc_fw->has_gsc_headers)\n\t\treturn intel_huc_is_authenticated(huc, INTEL_HUC_AUTH_BY_GUC);\n\telse if (intel_huc_is_loaded_by_gsc(huc) || HAS_ENGINE(huc_to_gt(huc), GSC0))\n\t\treturn intel_huc_is_authenticated(huc, INTEL_HUC_AUTH_BY_GSC);\n\telse\n\t\treturn false;\n}\n\n \nint intel_huc_check_status(struct intel_huc *huc)\n{\n\tstruct intel_uc_fw *huc_fw = &huc->fw;\n\n\tswitch (__intel_uc_fw_status(huc_fw)) {\n\tcase INTEL_UC_FIRMWARE_NOT_SUPPORTED:\n\t\treturn -ENODEV;\n\tcase INTEL_UC_FIRMWARE_DISABLED:\n\t\treturn -EOPNOTSUPP;\n\tcase INTEL_UC_FIRMWARE_MISSING:\n\t\treturn -ENOPKG;\n\tcase INTEL_UC_FIRMWARE_ERROR:\n\t\treturn -ENOEXEC;\n\tcase INTEL_UC_FIRMWARE_INIT_FAIL:\n\t\treturn -ENOMEM;\n\tcase INTEL_UC_FIRMWARE_LOAD_FAIL:\n\t\treturn -EIO;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tif (huc_is_fully_authenticated(huc))\n\t\treturn 1;  \n\telse if (huc_fw->has_gsc_headers && !intel_huc_is_loaded_by_gsc(huc) &&\n\t\t intel_huc_is_authenticated(huc, INTEL_HUC_AUTH_BY_GUC))\n\t\treturn 2;  \n\telse\n\t\treturn 0;\n}\n\nstatic bool huc_has_delayed_load(struct intel_huc *huc)\n{\n\treturn intel_huc_is_loaded_by_gsc(huc) &&\n\t       (huc->delayed_load.status != INTEL_HUC_DELAYED_LOAD_ERROR);\n}\n\nvoid intel_huc_update_auth_status(struct intel_huc *huc)\n{\n\tif (!intel_uc_fw_is_loadable(&huc->fw))\n\t\treturn;\n\n\tif (!huc->fw.has_gsc_headers)\n\t\treturn;\n\n\tif (huc_is_fully_authenticated(huc))\n\t\tintel_uc_fw_change_status(&huc->fw,\n\t\t\t\t\t  INTEL_UC_FIRMWARE_RUNNING);\n\telse if (huc_has_delayed_load(huc))\n\t\thuc_delayed_load_start(huc);\n}\n\n \nvoid intel_huc_load_status(struct intel_huc *huc, struct drm_printer *p)\n{\n\tstruct intel_gt *gt = huc_to_gt(huc);\n\tintel_wakeref_t wakeref;\n\n\tif (!intel_huc_is_supported(huc)) {\n\t\tdrm_printf(p, \"HuC not supported\\n\");\n\t\treturn;\n\t}\n\n\tif (!intel_huc_is_wanted(huc)) {\n\t\tdrm_printf(p, \"HuC disabled\\n\");\n\t\treturn;\n\t}\n\n\tintel_uc_fw_dump(&huc->fw, p);\n\n\twith_intel_runtime_pm(gt->uncore->rpm, wakeref)\n\t\tdrm_printf(p, \"HuC status: 0x%08x\\n\",\n\t\t\t   intel_uncore_read(gt->uncore, huc->status[INTEL_HUC_AUTH_BY_GUC].reg));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}