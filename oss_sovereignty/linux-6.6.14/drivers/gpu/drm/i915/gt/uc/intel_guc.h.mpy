{
  "module_name": "intel_guc.h",
  "hash_id": "7448285609b19377f4e96dc0e795400d56951387d63f11535fc75538cfb28dd9",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/gt/uc/intel_guc.h",
  "human_readable_source": " \n \n\n#ifndef _INTEL_GUC_H_\n#define _INTEL_GUC_H_\n\n#include <linux/delay.h>\n#include <linux/iosys-map.h>\n#include <linux/xarray.h>\n\n#include \"intel_guc_ct.h\"\n#include \"intel_guc_fw.h\"\n#include \"intel_guc_fwif.h\"\n#include \"intel_guc_log.h\"\n#include \"intel_guc_reg.h\"\n#include \"intel_guc_slpc_types.h\"\n#include \"intel_uc_fw.h\"\n#include \"intel_uncore.h\"\n#include \"i915_utils.h\"\n#include \"i915_vma.h\"\n\nstruct __guc_ads_blob;\nstruct intel_guc_state_capture;\n\n \nstruct intel_guc {\n\t \n\tstruct intel_uc_fw fw;\n\t \n\tstruct intel_guc_log log;\n\t \n\tstruct intel_guc_ct ct;\n\t \n\tstruct intel_guc_slpc slpc;\n\t \n\tstruct intel_guc_state_capture *capture;\n\n\t \n\tstruct dentry *dbgfs_node;\n\n\t \n\tstruct i915_sched_engine *sched_engine;\n\t \n\tstruct i915_request *stalled_request;\n\t \n\tenum {\n\t\tSTALL_NONE,\n\t\tSTALL_REGISTER_CONTEXT,\n\t\tSTALL_MOVE_LRC_TAIL,\n\t\tSTALL_ADD_REQUEST,\n\t} submission_stall_reason;\n\n\t \n\t \n\tspinlock_t irq_lock;\n\t \n\tunsigned int msg_enabled_mask;\n\n\t \n\tatomic_t outstanding_submission_g2h;\n\n\t \n\tstruct {\n\t\tbool enabled;\n\t\tvoid (*reset)(struct intel_guc *guc);\n\t\tvoid (*enable)(struct intel_guc *guc);\n\t\tvoid (*disable)(struct intel_guc *guc);\n\t} interrupts;\n\n\t \n\tstruct {\n\t\t \n\t\tspinlock_t lock;\n\t\t \n\t\tstruct ida guc_ids;\n\t\t \n\t\tint num_guc_ids;\n\t\t \n\t\tunsigned long *guc_ids_bitmap;\n\t\t \n\t\tstruct list_head guc_id_list;\n\t\t \n\t\tunsigned int guc_ids_in_use;\n\t\t \n\t\tstruct list_head destroyed_contexts;\n\t\t \n\t\tstruct work_struct destroyed_worker;\n\t\t \n\t\tstruct work_struct reset_fail_worker;\n\t\t \n\t\tintel_engine_mask_t reset_fail_mask;\n\t\t \n\t\tunsigned int sched_disable_delay_ms;\n\t\t \n\t\tunsigned int sched_disable_gucid_threshold;\n\t} submission_state;\n\n\t \n\tbool submission_supported;\n\t \n\tbool submission_selected;\n\t \n\tbool submission_initialized;\n\t \n\tstruct intel_uc_fw_ver submission_version;\n\n\t \n\tbool rc_supported;\n\t \n\tbool rc_selected;\n\n\t \n\tstruct i915_vma *ads_vma;\n\t \n\tstruct iosys_map ads_map;\n\t \n\tu32 ads_regset_size;\n\t \n\tu32 ads_regset_count[I915_NUM_ENGINES];\n\t \n\tstruct guc_mmio_reg *ads_regset;\n\t \n\tu32 ads_golden_ctxt_size;\n\t \n\tu32 ads_capture_size;\n\t \n\tu32 ads_engine_usage_size;\n\n\t \n\tstruct i915_vma *lrc_desc_pool_v69;\n\t \n\tvoid *lrc_desc_pool_vaddr_v69;\n\n\t \n\tstruct xarray context_lookup;\n\n\t \n\tu32 params[GUC_CTL_MAX_DWORDS];\n\n\t \n\tstruct {\n\t\tu32 base;\n\t\tunsigned int count;\n\t\tenum forcewake_domains fw_domains;\n\t} send_regs;\n\n\t \n\ti915_reg_t notify_reg;\n\n\t \n\tu32 mmio_msg;\n\n\t \n\tstruct mutex send_mutex;\n\n\t \n\tstruct {\n\t\t \n\t\tspinlock_t lock;\n\n\t\t \n\t\tu64 gt_stamp;\n\n\t\t \n\t\tunsigned long ping_delay;\n\n\t\t \n\t\tstruct delayed_work work;\n\n\t\t \n\t\tu32 shift;\n\n\t\t \n\t\tunsigned long last_stat_jiffies;\n\t} timestamp;\n\n#ifdef CONFIG_DRM_I915_SELFTEST\n\t \n\tint number_guc_id_stolen;\n#endif\n};\n\n \n#define MAKE_GUC_VER(maj, min, pat)\t(((maj) << 16) | ((min) << 8) | (pat))\n#define MAKE_GUC_VER_STRUCT(ver)\tMAKE_GUC_VER((ver).major, (ver).minor, (ver).patch)\n#define GUC_SUBMIT_VER(guc)\t\tMAKE_GUC_VER_STRUCT((guc)->submission_version)\n\nstatic inline struct intel_guc *log_to_guc(struct intel_guc_log *log)\n{\n\treturn container_of(log, struct intel_guc, log);\n}\n\nstatic\ninline int intel_guc_send(struct intel_guc *guc, const u32 *action, u32 len)\n{\n\treturn intel_guc_ct_send(&guc->ct, action, len, NULL, 0, 0);\n}\n\nstatic\ninline int intel_guc_send_nb(struct intel_guc *guc, const u32 *action, u32 len,\n\t\t\t     u32 g2h_len_dw)\n{\n\treturn intel_guc_ct_send(&guc->ct, action, len, NULL, 0,\n\t\t\t\t MAKE_SEND_FLAGS(g2h_len_dw));\n}\n\nstatic inline int\nintel_guc_send_and_receive(struct intel_guc *guc, const u32 *action, u32 len,\n\t\t\t   u32 *response_buf, u32 response_buf_size)\n{\n\treturn intel_guc_ct_send(&guc->ct, action, len,\n\t\t\t\t response_buf, response_buf_size, 0);\n}\n\nstatic inline int intel_guc_send_busy_loop(struct intel_guc *guc,\n\t\t\t\t\t   const u32 *action,\n\t\t\t\t\t   u32 len,\n\t\t\t\t\t   u32 g2h_len_dw,\n\t\t\t\t\t   bool loop)\n{\n\tint err;\n\tunsigned int sleep_period_ms = 1;\n\tbool not_atomic = !in_atomic() && !irqs_disabled();\n\n\t \n\n\t \n\tmight_sleep_if(loop && not_atomic);\n\nretry:\n\terr = intel_guc_send_nb(guc, action, len, g2h_len_dw);\n\tif (unlikely(err == -EBUSY && loop)) {\n\t\tif (likely(not_atomic)) {\n\t\t\tif (msleep_interruptible(sleep_period_ms))\n\t\t\t\treturn -EINTR;\n\t\t\tsleep_period_ms = sleep_period_ms << 1;\n\t\t} else {\n\t\t\tcpu_relax();\n\t\t}\n\t\tgoto retry;\n\t}\n\n\treturn err;\n}\n\n \nstatic inline void intel_guc_to_host_event_handler(struct intel_guc *guc)\n{\n\tif (guc->interrupts.enabled)\n\t\tintel_guc_ct_event_handler(&guc->ct);\n}\n\n \n#define GUC_GGTT_TOP\t0xFEE00000\n\n \nstatic inline u32 intel_guc_ggtt_offset(struct intel_guc *guc,\n\t\t\t\t\tstruct i915_vma *vma)\n{\n\tu32 offset = i915_ggtt_offset(vma);\n\n\tGEM_BUG_ON(offset < i915_ggtt_pin_bias(vma));\n\tGEM_BUG_ON(range_overflows_t(u64, offset, vma->size, GUC_GGTT_TOP));\n\n\treturn offset;\n}\n\nvoid intel_guc_init_early(struct intel_guc *guc);\nvoid intel_guc_init_late(struct intel_guc *guc);\nvoid intel_guc_init_send_regs(struct intel_guc *guc);\nvoid intel_guc_write_params(struct intel_guc *guc);\nint intel_guc_init(struct intel_guc *guc);\nvoid intel_guc_fini(struct intel_guc *guc);\nvoid intel_guc_notify(struct intel_guc *guc);\nint intel_guc_send_mmio(struct intel_guc *guc, const u32 *action, u32 len,\n\t\t\tu32 *response_buf, u32 response_buf_size);\nint intel_guc_to_host_process_recv_msg(struct intel_guc *guc,\n\t\t\t\t       const u32 *payload, u32 len);\nint intel_guc_auth_huc(struct intel_guc *guc, u32 rsa_offset);\nint intel_guc_suspend(struct intel_guc *guc);\nint intel_guc_resume(struct intel_guc *guc);\nstruct i915_vma *intel_guc_allocate_vma(struct intel_guc *guc, u32 size);\nint intel_guc_allocate_and_map_vma(struct intel_guc *guc, u32 size,\n\t\t\t\t   struct i915_vma **out_vma, void **out_vaddr);\nint intel_guc_self_cfg32(struct intel_guc *guc, u16 key, u32 value);\nint intel_guc_self_cfg64(struct intel_guc *guc, u16 key, u64 value);\n\nstatic inline bool intel_guc_is_supported(struct intel_guc *guc)\n{\n\treturn intel_uc_fw_is_supported(&guc->fw);\n}\n\nstatic inline bool intel_guc_is_wanted(struct intel_guc *guc)\n{\n\treturn intel_uc_fw_is_enabled(&guc->fw);\n}\n\nstatic inline bool intel_guc_is_used(struct intel_guc *guc)\n{\n\tGEM_BUG_ON(__intel_uc_fw_status(&guc->fw) == INTEL_UC_FIRMWARE_SELECTED);\n\treturn intel_uc_fw_is_available(&guc->fw);\n}\n\nstatic inline bool intel_guc_is_fw_running(struct intel_guc *guc)\n{\n\treturn intel_uc_fw_is_running(&guc->fw);\n}\n\nstatic inline bool intel_guc_is_ready(struct intel_guc *guc)\n{\n\treturn intel_guc_is_fw_running(guc) && intel_guc_ct_enabled(&guc->ct);\n}\n\nstatic inline void intel_guc_reset_interrupts(struct intel_guc *guc)\n{\n\tguc->interrupts.reset(guc);\n}\n\nstatic inline void intel_guc_enable_interrupts(struct intel_guc *guc)\n{\n\tguc->interrupts.enable(guc);\n}\n\nstatic inline void intel_guc_disable_interrupts(struct intel_guc *guc)\n{\n\tguc->interrupts.disable(guc);\n}\n\nstatic inline int intel_guc_sanitize(struct intel_guc *guc)\n{\n\tintel_uc_fw_sanitize(&guc->fw);\n\tintel_guc_disable_interrupts(guc);\n\tintel_guc_ct_sanitize(&guc->ct);\n\tguc->mmio_msg = 0;\n\n\treturn 0;\n}\n\nstatic inline void intel_guc_enable_msg(struct intel_guc *guc, u32 mask)\n{\n\tspin_lock_irq(&guc->irq_lock);\n\tguc->msg_enabled_mask |= mask;\n\tspin_unlock_irq(&guc->irq_lock);\n}\n\nstatic inline void intel_guc_disable_msg(struct intel_guc *guc, u32 mask)\n{\n\tspin_lock_irq(&guc->irq_lock);\n\tguc->msg_enabled_mask &= ~mask;\n\tspin_unlock_irq(&guc->irq_lock);\n}\n\nint intel_guc_wait_for_idle(struct intel_guc *guc, long timeout);\n\nint intel_guc_deregister_done_process_msg(struct intel_guc *guc,\n\t\t\t\t\t  const u32 *msg, u32 len);\nint intel_guc_sched_done_process_msg(struct intel_guc *guc,\n\t\t\t\t     const u32 *msg, u32 len);\nint intel_guc_context_reset_process_msg(struct intel_guc *guc,\n\t\t\t\t\tconst u32 *msg, u32 len);\nint intel_guc_engine_failure_process_msg(struct intel_guc *guc,\n\t\t\t\t\t const u32 *msg, u32 len);\nint intel_guc_error_capture_process_msg(struct intel_guc *guc,\n\t\t\t\t\tconst u32 *msg, u32 len);\n\nstruct intel_engine_cs *\nintel_guc_lookup_engine(struct intel_guc *guc, u8 guc_class, u8 instance);\n\nvoid intel_guc_find_hung_context(struct intel_engine_cs *engine);\n\nint intel_guc_global_policies_update(struct intel_guc *guc);\n\nvoid intel_guc_context_ban(struct intel_context *ce, struct i915_request *rq);\n\nvoid intel_guc_submission_reset_prepare(struct intel_guc *guc);\nvoid intel_guc_submission_reset(struct intel_guc *guc, intel_engine_mask_t stalled);\nvoid intel_guc_submission_reset_finish(struct intel_guc *guc);\nvoid intel_guc_submission_cancel_requests(struct intel_guc *guc);\n\nvoid intel_guc_load_status(struct intel_guc *guc, struct drm_printer *p);\n\nvoid intel_guc_write_barrier(struct intel_guc *guc);\n\nvoid intel_guc_dump_time_info(struct intel_guc *guc, struct drm_printer *p);\n\nint intel_guc_sched_disable_gucid_threshold_max(struct intel_guc *guc);\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}