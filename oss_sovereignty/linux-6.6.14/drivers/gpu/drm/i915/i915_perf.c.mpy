{
  "module_name": "i915_perf.c",
  "hash_id": "0c56a95d3ffa9de2f8ee60a4e62de7bf76b155581e7548840d33d1adcdc7ccb6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/i915_perf.c",
  "human_readable_source": " \n\n\n \n\n \n\n#include <linux/anon_inodes.h>\n#include <linux/nospec.h>\n#include <linux/sizes.h>\n#include <linux/uuid.h>\n\n#include \"gem/i915_gem_context.h\"\n#include \"gem/i915_gem_internal.h\"\n#include \"gt/intel_engine_pm.h\"\n#include \"gt/intel_engine_regs.h\"\n#include \"gt/intel_engine_user.h\"\n#include \"gt/intel_execlists_submission.h\"\n#include \"gt/intel_gpu_commands.h\"\n#include \"gt/intel_gt.h\"\n#include \"gt/intel_gt_clock_utils.h\"\n#include \"gt/intel_gt_mcr.h\"\n#include \"gt/intel_gt_regs.h\"\n#include \"gt/intel_lrc.h\"\n#include \"gt/intel_lrc_reg.h\"\n#include \"gt/intel_rc6.h\"\n#include \"gt/intel_ring.h\"\n#include \"gt/uc/intel_guc_slpc.h\"\n\n#include \"i915_drv.h\"\n#include \"i915_file_private.h\"\n#include \"i915_perf.h\"\n#include \"i915_perf_oa_regs.h\"\n#include \"i915_reg.h\"\n\n \n#define OA_BUFFER_SIZE\t\tSZ_16M\n\n#define OA_TAKEN(tail, head)\t((tail - head) & (OA_BUFFER_SIZE - 1))\n\n \n#define OA_TAIL_MARGIN_NSEC\t100000ULL\n#define INVALID_TAIL_PTR\t0xffffffff\n\n \n#define DEFAULT_POLL_FREQUENCY_HZ 200\n#define DEFAULT_POLL_PERIOD_NS (NSEC_PER_SEC / DEFAULT_POLL_FREQUENCY_HZ)\n\n \nstatic u32 i915_perf_stream_paranoid = true;\n\n \n#define OA_EXPONENT_MAX 31\n\n#define INVALID_CTX_ID 0xffffffff\n\n \n#define OAREPORT_REASON_MASK           0x3f\n#define OAREPORT_REASON_MASK_EXTENDED  0x7f\n#define OAREPORT_REASON_SHIFT          19\n#define OAREPORT_REASON_TIMER          (1<<0)\n#define OAREPORT_REASON_CTX_SWITCH     (1<<3)\n#define OAREPORT_REASON_CLK_RATIO      (1<<5)\n\n#define HAS_MI_SET_PREDICATE(i915) (GRAPHICS_VER_FULL(i915) >= IP_VER(12, 50))\n\n \nstatic int oa_sample_rate_hard_limit;\n\n \nstatic u32 i915_oa_max_sample_rate = 100000;\n\n \nstatic const struct i915_oa_format oa_formats[I915_OA_FORMAT_MAX] = {\n\t[I915_OA_FORMAT_A13]\t    = { 0, 64 },\n\t[I915_OA_FORMAT_A29]\t    = { 1, 128 },\n\t[I915_OA_FORMAT_A13_B8_C8]  = { 2, 128 },\n\t \n\t[I915_OA_FORMAT_B4_C8]\t    = { 4, 64 },\n\t[I915_OA_FORMAT_A45_B8_C8]  = { 5, 256 },\n\t[I915_OA_FORMAT_B4_C8_A16]  = { 6, 128 },\n\t[I915_OA_FORMAT_C4_B8]\t    = { 7, 64 },\n\t[I915_OA_FORMAT_A12]\t\t    = { 0, 64 },\n\t[I915_OA_FORMAT_A12_B8_C8]\t    = { 2, 128 },\n\t[I915_OA_FORMAT_A32u40_A4u32_B8_C8] = { 5, 256 },\n\t[I915_OAR_FORMAT_A32u40_A4u32_B8_C8]    = { 5, 256 },\n\t[I915_OA_FORMAT_A24u40_A14u32_B8_C8]    = { 5, 256 },\n\t[I915_OAM_FORMAT_MPEC8u64_B8_C8]\t= { 1, 192, TYPE_OAM, HDR_64_BIT },\n\t[I915_OAM_FORMAT_MPEC8u32_B8_C8]\t= { 2, 128, TYPE_OAM, HDR_64_BIT },\n};\n\nstatic const u32 mtl_oa_base[] = {\n\t[PERF_GROUP_OAM_SAMEDIA_0] = 0x393000,\n};\n\n#define SAMPLE_OA_REPORT      (1<<0)\n\n \nstruct perf_open_properties {\n\tu32 sample_flags;\n\n\tu64 single_context:1;\n\tu64 hold_preemption:1;\n\tu64 ctx_handle;\n\n\t \n\tint metrics_set;\n\tint oa_format;\n\tbool oa_periodic;\n\tint oa_period_exponent;\n\n\tstruct intel_engine_cs *engine;\n\n\tbool has_sseu;\n\tstruct intel_sseu sseu;\n\n\tu64 poll_oa_period;\n};\n\nstruct i915_oa_config_bo {\n\tstruct llist_node node;\n\n\tstruct i915_oa_config *oa_config;\n\tstruct i915_vma *vma;\n};\n\nstatic struct ctl_table_header *sysctl_header;\n\nstatic enum hrtimer_restart oa_poll_check_timer_cb(struct hrtimer *hrtimer);\n\nvoid i915_oa_config_release(struct kref *ref)\n{\n\tstruct i915_oa_config *oa_config =\n\t\tcontainer_of(ref, typeof(*oa_config), ref);\n\n\tkfree(oa_config->flex_regs);\n\tkfree(oa_config->b_counter_regs);\n\tkfree(oa_config->mux_regs);\n\n\tkfree_rcu(oa_config, rcu);\n}\n\nstruct i915_oa_config *\ni915_perf_get_oa_config(struct i915_perf *perf, int metrics_set)\n{\n\tstruct i915_oa_config *oa_config;\n\n\trcu_read_lock();\n\toa_config = idr_find(&perf->metrics_idr, metrics_set);\n\tif (oa_config)\n\t\toa_config = i915_oa_config_get(oa_config);\n\trcu_read_unlock();\n\n\treturn oa_config;\n}\n\nstatic void free_oa_config_bo(struct i915_oa_config_bo *oa_bo)\n{\n\ti915_oa_config_put(oa_bo->oa_config);\n\ti915_vma_put(oa_bo->vma);\n\tkfree(oa_bo);\n}\n\nstatic inline const\nstruct i915_perf_regs *__oa_regs(struct i915_perf_stream *stream)\n{\n\treturn &stream->engine->oa_group->regs;\n}\n\nstatic u32 gen12_oa_hw_tail_read(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\treturn intel_uncore_read(uncore, __oa_regs(stream)->oa_tail_ptr) &\n\t       GEN12_OAG_OATAILPTR_MASK;\n}\n\nstatic u32 gen8_oa_hw_tail_read(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\treturn intel_uncore_read(uncore, GEN8_OATAILPTR) & GEN8_OATAILPTR_MASK;\n}\n\nstatic u32 gen7_oa_hw_tail_read(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tu32 oastatus1 = intel_uncore_read(uncore, GEN7_OASTATUS1);\n\n\treturn oastatus1 & GEN7_OASTATUS1_TAIL_MASK;\n}\n\n#define oa_report_header_64bit(__s) \\\n\t((__s)->oa_buffer.format->header == HDR_64_BIT)\n\nstatic u64 oa_report_id(struct i915_perf_stream *stream, void *report)\n{\n\treturn oa_report_header_64bit(stream) ? *(u64 *)report : *(u32 *)report;\n}\n\nstatic u64 oa_report_reason(struct i915_perf_stream *stream, void *report)\n{\n\treturn (oa_report_id(stream, report) >> OAREPORT_REASON_SHIFT) &\n\t       (GRAPHICS_VER(stream->perf->i915) == 12 ?\n\t\tOAREPORT_REASON_MASK_EXTENDED :\n\t\tOAREPORT_REASON_MASK);\n}\n\nstatic void oa_report_id_clear(struct i915_perf_stream *stream, u32 *report)\n{\n\tif (oa_report_header_64bit(stream))\n\t\t*(u64 *)report = 0;\n\telse\n\t\t*report = 0;\n}\n\nstatic bool oa_report_ctx_invalid(struct i915_perf_stream *stream, void *report)\n{\n\treturn !(oa_report_id(stream, report) &\n\t       stream->perf->gen8_valid_ctx_bit);\n}\n\nstatic u64 oa_timestamp(struct i915_perf_stream *stream, void *report)\n{\n\treturn oa_report_header_64bit(stream) ?\n\t\t*((u64 *)report + 1) :\n\t\t*((u32 *)report + 1);\n}\n\nstatic void oa_timestamp_clear(struct i915_perf_stream *stream, u32 *report)\n{\n\tif (oa_report_header_64bit(stream))\n\t\t*(u64 *)&report[2] = 0;\n\telse\n\t\treport[1] = 0;\n}\n\nstatic u32 oa_context_id(struct i915_perf_stream *stream, u32 *report)\n{\n\tu32 ctx_id = oa_report_header_64bit(stream) ? report[4] : report[2];\n\n\treturn ctx_id & stream->specific_ctx_id_mask;\n}\n\nstatic void oa_context_id_squash(struct i915_perf_stream *stream, u32 *report)\n{\n\tif (oa_report_header_64bit(stream))\n\t\treport[4] = INVALID_CTX_ID;\n\telse\n\t\treport[2] = INVALID_CTX_ID;\n}\n\n \nstatic bool oa_buffer_check_unlocked(struct i915_perf_stream *stream)\n{\n\tu32 gtt_offset = i915_ggtt_offset(stream->oa_buffer.vma);\n\tint report_size = stream->oa_buffer.format->size;\n\tu32 head, tail, read_tail;\n\tunsigned long flags;\n\tbool pollin;\n\tu32 hw_tail;\n\tu32 partial_report_size;\n\n\t \n\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\thw_tail = stream->perf->ops.oa_hw_tail_read(stream);\n\n\t \n\tpartial_report_size = OA_TAKEN(hw_tail, stream->oa_buffer.tail);\n\tpartial_report_size %= report_size;\n\n\t \n\thw_tail = OA_TAKEN(hw_tail, partial_report_size);\n\n\t \n\thead = stream->oa_buffer.head - gtt_offset;\n\tread_tail = stream->oa_buffer.tail - gtt_offset;\n\n\ttail = hw_tail;\n\n\t \n\twhile (OA_TAKEN(tail, read_tail) >= report_size) {\n\t\tvoid *report = stream->oa_buffer.vaddr + tail;\n\n\t\tif (oa_report_id(stream, report) ||\n\t\t    oa_timestamp(stream, report))\n\t\t\tbreak;\n\n\t\ttail = (tail - report_size) & (OA_BUFFER_SIZE - 1);\n\t}\n\n\tif (OA_TAKEN(hw_tail, tail) > report_size &&\n\t    __ratelimit(&stream->perf->tail_pointer_race))\n\t\tdrm_notice(&stream->uncore->i915->drm,\n\t\t\t   \"unlanded report(s) head=0x%x tail=0x%x hw_tail=0x%x\\n\",\n\t\t head, tail, hw_tail);\n\n\tstream->oa_buffer.tail = gtt_offset + tail;\n\n\tpollin = OA_TAKEN(stream->oa_buffer.tail,\n\t\t\t  stream->oa_buffer.head) >= report_size;\n\n\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\n\treturn pollin;\n}\n\n \nstatic int append_oa_status(struct i915_perf_stream *stream,\n\t\t\t    char __user *buf,\n\t\t\t    size_t count,\n\t\t\t    size_t *offset,\n\t\t\t    enum drm_i915_perf_record_type type)\n{\n\tstruct drm_i915_perf_record_header header = { type, 0, sizeof(header) };\n\n\tif ((count - *offset) < header.size)\n\t\treturn -ENOSPC;\n\n\tif (copy_to_user(buf + *offset, &header, sizeof(header)))\n\t\treturn -EFAULT;\n\n\t(*offset) += header.size;\n\n\treturn 0;\n}\n\n \nstatic int append_oa_sample(struct i915_perf_stream *stream,\n\t\t\t    char __user *buf,\n\t\t\t    size_t count,\n\t\t\t    size_t *offset,\n\t\t\t    const u8 *report)\n{\n\tint report_size = stream->oa_buffer.format->size;\n\tstruct drm_i915_perf_record_header header;\n\tint report_size_partial;\n\tu8 *oa_buf_end;\n\n\theader.type = DRM_I915_PERF_RECORD_SAMPLE;\n\theader.pad = 0;\n\theader.size = stream->sample_size;\n\n\tif ((count - *offset) < header.size)\n\t\treturn -ENOSPC;\n\n\tbuf += *offset;\n\tif (copy_to_user(buf, &header, sizeof(header)))\n\t\treturn -EFAULT;\n\tbuf += sizeof(header);\n\n\toa_buf_end = stream->oa_buffer.vaddr + OA_BUFFER_SIZE;\n\treport_size_partial = oa_buf_end - report;\n\n\tif (report_size_partial < report_size) {\n\t\tif (copy_to_user(buf, report, report_size_partial))\n\t\t\treturn -EFAULT;\n\t\tbuf += report_size_partial;\n\n\t\tif (copy_to_user(buf, stream->oa_buffer.vaddr,\n\t\t\t\t report_size - report_size_partial))\n\t\t\treturn -EFAULT;\n\t} else if (copy_to_user(buf, report, report_size)) {\n\t\treturn -EFAULT;\n\t}\n\n\t(*offset) += header.size;\n\n\treturn 0;\n}\n\n \nstatic int gen8_append_oa_reports(struct i915_perf_stream *stream,\n\t\t\t\t  char __user *buf,\n\t\t\t\t  size_t count,\n\t\t\t\t  size_t *offset)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tint report_size = stream->oa_buffer.format->size;\n\tu8 *oa_buf_base = stream->oa_buffer.vaddr;\n\tu32 gtt_offset = i915_ggtt_offset(stream->oa_buffer.vma);\n\tu32 mask = (OA_BUFFER_SIZE - 1);\n\tsize_t start_offset = *offset;\n\tunsigned long flags;\n\tu32 head, tail;\n\tint ret = 0;\n\n\tif (drm_WARN_ON(&uncore->i915->drm, !stream->enabled))\n\t\treturn -EIO;\n\n\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\thead = stream->oa_buffer.head;\n\ttail = stream->oa_buffer.tail;\n\n\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\n\t \n\thead -= gtt_offset;\n\ttail -= gtt_offset;\n\n\t \n\tif (drm_WARN_ONCE(&uncore->i915->drm,\n\t\t\t  head > OA_BUFFER_SIZE ||\n\t\t\t  tail > OA_BUFFER_SIZE,\n\t\t\t  \"Inconsistent OA buffer pointers: head = %u, tail = %u\\n\",\n\t\t\t  head, tail))\n\t\treturn -EIO;\n\n\n\tfor ( ;\n\t     OA_TAKEN(tail, head);\n\t     head = (head + report_size) & mask) {\n\t\tu8 *report = oa_buf_base + head;\n\t\tu32 *report32 = (void *)report;\n\t\tu32 ctx_id;\n\t\tu64 reason;\n\n\t\t \n\t\treason = oa_report_reason(stream, report);\n\t\tctx_id = oa_context_id(stream, report32);\n\n\t\t \n\n\t\tif (oa_report_ctx_invalid(stream, report) &&\n\t\t    GRAPHICS_VER_FULL(stream->engine->i915) < IP_VER(12, 50)) {\n\t\t\tctx_id = INVALID_CTX_ID;\n\t\t\toa_context_id_squash(stream, report32);\n\t\t}\n\n\t\t \n\t\tif (!stream->ctx ||\n\t\t    stream->specific_ctx_id == ctx_id ||\n\t\t    stream->oa_buffer.last_ctx_id == stream->specific_ctx_id ||\n\t\t    reason & OAREPORT_REASON_CTX_SWITCH) {\n\n\t\t\t \n\t\t\tif (stream->ctx &&\n\t\t\t    stream->specific_ctx_id != ctx_id) {\n\t\t\t\toa_context_id_squash(stream, report32);\n\t\t\t}\n\n\t\t\tret = append_oa_sample(stream, buf, count, offset,\n\t\t\t\t\t       report);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\n\t\t\tstream->oa_buffer.last_ctx_id = ctx_id;\n\t\t}\n\n\t\tif (is_power_of_2(report_size)) {\n\t\t\t \n\t\t\toa_report_id_clear(stream, report32);\n\t\t\toa_timestamp_clear(stream, report32);\n\t\t} else {\n\t\t\tu8 *oa_buf_end = stream->oa_buffer.vaddr +\n\t\t\t\t\t OA_BUFFER_SIZE;\n\t\t\tu32 part = oa_buf_end - (u8 *)report32;\n\n\t\t\t \n\t\t\tif (report_size <= part) {\n\t\t\t\tmemset(report32, 0, report_size);\n\t\t\t} else {\n\t\t\t\tmemset(report32, 0, part);\n\t\t\t\tmemset(oa_buf_base, 0, report_size - part);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (start_offset != *offset) {\n\t\ti915_reg_t oaheadptr;\n\n\t\toaheadptr = GRAPHICS_VER(stream->perf->i915) == 12 ?\n\t\t\t    __oa_regs(stream)->oa_head_ptr :\n\t\t\t    GEN8_OAHEADPTR;\n\n\t\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\t\t \n\t\thead += gtt_offset;\n\t\tintel_uncore_write(uncore, oaheadptr,\n\t\t\t\t   head & GEN12_OAG_OAHEADPTR_MASK);\n\t\tstream->oa_buffer.head = head;\n\n\t\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\t}\n\n\treturn ret;\n}\n\n \nstatic int gen8_oa_read(struct i915_perf_stream *stream,\n\t\t\tchar __user *buf,\n\t\t\tsize_t count,\n\t\t\tsize_t *offset)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tu32 oastatus;\n\ti915_reg_t oastatus_reg;\n\tint ret;\n\n\tif (drm_WARN_ON(&uncore->i915->drm, !stream->oa_buffer.vaddr))\n\t\treturn -EIO;\n\n\toastatus_reg = GRAPHICS_VER(stream->perf->i915) == 12 ?\n\t\t       __oa_regs(stream)->oa_status :\n\t\t       GEN8_OASTATUS;\n\n\toastatus = intel_uncore_read(uncore, oastatus_reg);\n\n\t \n\tif (oastatus & GEN8_OASTATUS_OABUFFER_OVERFLOW) {\n\t\tret = append_oa_status(stream, buf, count, offset,\n\t\t\t\t       DRM_I915_PERF_RECORD_OA_BUFFER_LOST);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"OA buffer overflow (exponent = %d): force restart\\n\",\n\t\t\tstream->period_exponent);\n\n\t\tstream->perf->ops.oa_disable(stream);\n\t\tstream->perf->ops.oa_enable(stream);\n\n\t\t \n\t\toastatus = intel_uncore_read(uncore, oastatus_reg);\n\t}\n\n\tif (oastatus & GEN8_OASTATUS_REPORT_LOST) {\n\t\tret = append_oa_status(stream, buf, count, offset,\n\t\t\t\t       DRM_I915_PERF_RECORD_OA_REPORT_LOST);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tintel_uncore_rmw(uncore, oastatus_reg,\n\t\t\t\t GEN8_OASTATUS_COUNTER_OVERFLOW |\n\t\t\t\t GEN8_OASTATUS_REPORT_LOST,\n\t\t\t\t IS_GRAPHICS_VER(uncore->i915, 8, 11) ?\n\t\t\t\t (GEN8_OASTATUS_HEAD_POINTER_WRAP |\n\t\t\t\t  GEN8_OASTATUS_TAIL_POINTER_WRAP) : 0);\n\t}\n\n\treturn gen8_append_oa_reports(stream, buf, count, offset);\n}\n\n \nstatic int gen7_append_oa_reports(struct i915_perf_stream *stream,\n\t\t\t\t  char __user *buf,\n\t\t\t\t  size_t count,\n\t\t\t\t  size_t *offset)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tint report_size = stream->oa_buffer.format->size;\n\tu8 *oa_buf_base = stream->oa_buffer.vaddr;\n\tu32 gtt_offset = i915_ggtt_offset(stream->oa_buffer.vma);\n\tu32 mask = (OA_BUFFER_SIZE - 1);\n\tsize_t start_offset = *offset;\n\tunsigned long flags;\n\tu32 head, tail;\n\tint ret = 0;\n\n\tif (drm_WARN_ON(&uncore->i915->drm, !stream->enabled))\n\t\treturn -EIO;\n\n\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\thead = stream->oa_buffer.head;\n\ttail = stream->oa_buffer.tail;\n\n\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\n\t \n\thead -= gtt_offset;\n\ttail -= gtt_offset;\n\n\t \n\tif (drm_WARN_ONCE(&uncore->i915->drm,\n\t\t\t  head > OA_BUFFER_SIZE || head % report_size ||\n\t\t\t  tail > OA_BUFFER_SIZE || tail % report_size,\n\t\t\t  \"Inconsistent OA buffer pointers: head = %u, tail = %u\\n\",\n\t\t\t  head, tail))\n\t\treturn -EIO;\n\n\n\tfor ( ;\n\t     OA_TAKEN(tail, head);\n\t     head = (head + report_size) & mask) {\n\t\tu8 *report = oa_buf_base + head;\n\t\tu32 *report32 = (void *)report;\n\n\t\t \n\t\tif (drm_WARN_ON(&uncore->i915->drm,\n\t\t\t\t(OA_BUFFER_SIZE - head) < report_size)) {\n\t\t\tdrm_err(&uncore->i915->drm,\n\t\t\t\t\"Spurious OA head ptr: non-integral report offset\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (report32[0] == 0) {\n\t\t\tif (__ratelimit(&stream->perf->spurious_report_rs))\n\t\t\t\tdrm_notice(&uncore->i915->drm,\n\t\t\t\t\t   \"Skipping spurious, invalid OA report\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = append_oa_sample(stream, buf, count, offset, report);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\t \n\t\treport32[0] = 0;\n\t\treport32[1] = 0;\n\t}\n\n\tif (start_offset != *offset) {\n\t\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\t\t \n\t\thead += gtt_offset;\n\n\t\tintel_uncore_write(uncore, GEN7_OASTATUS2,\n\t\t\t\t   (head & GEN7_OASTATUS2_HEAD_MASK) |\n\t\t\t\t   GEN7_OASTATUS2_MEM_SELECT_GGTT);\n\t\tstream->oa_buffer.head = head;\n\n\t\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\t}\n\n\treturn ret;\n}\n\n \nstatic int gen7_oa_read(struct i915_perf_stream *stream,\n\t\t\tchar __user *buf,\n\t\t\tsize_t count,\n\t\t\tsize_t *offset)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tu32 oastatus1;\n\tint ret;\n\n\tif (drm_WARN_ON(&uncore->i915->drm, !stream->oa_buffer.vaddr))\n\t\treturn -EIO;\n\n\toastatus1 = intel_uncore_read(uncore, GEN7_OASTATUS1);\n\n\t \n\toastatus1 &= ~stream->perf->gen7_latched_oastatus1;\n\n\t \n\tif (unlikely(oastatus1 & GEN7_OASTATUS1_OABUFFER_OVERFLOW)) {\n\t\tret = append_oa_status(stream, buf, count, offset,\n\t\t\t\t       DRM_I915_PERF_RECORD_OA_BUFFER_LOST);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"OA buffer overflow (exponent = %d): force restart\\n\",\n\t\t\tstream->period_exponent);\n\n\t\tstream->perf->ops.oa_disable(stream);\n\t\tstream->perf->ops.oa_enable(stream);\n\n\t\toastatus1 = intel_uncore_read(uncore, GEN7_OASTATUS1);\n\t}\n\n\tif (unlikely(oastatus1 & GEN7_OASTATUS1_REPORT_LOST)) {\n\t\tret = append_oa_status(stream, buf, count, offset,\n\t\t\t\t       DRM_I915_PERF_RECORD_OA_REPORT_LOST);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tstream->perf->gen7_latched_oastatus1 |=\n\t\t\tGEN7_OASTATUS1_REPORT_LOST;\n\t}\n\n\treturn gen7_append_oa_reports(stream, buf, count, offset);\n}\n\n \nstatic int i915_oa_wait_unlocked(struct i915_perf_stream *stream)\n{\n\t \n\tif (!stream->periodic)\n\t\treturn -EIO;\n\n\treturn wait_event_interruptible(stream->poll_wq,\n\t\t\t\t\toa_buffer_check_unlocked(stream));\n}\n\n \nstatic void i915_oa_poll_wait(struct i915_perf_stream *stream,\n\t\t\t      struct file *file,\n\t\t\t      poll_table *wait)\n{\n\tpoll_wait(file, &stream->poll_wq, wait);\n}\n\n \nstatic int i915_oa_read(struct i915_perf_stream *stream,\n\t\t\tchar __user *buf,\n\t\t\tsize_t count,\n\t\t\tsize_t *offset)\n{\n\treturn stream->perf->ops.read(stream, buf, count, offset);\n}\n\nstatic struct intel_context *oa_pin_context(struct i915_perf_stream *stream)\n{\n\tstruct i915_gem_engines_iter it;\n\tstruct i915_gem_context *ctx = stream->ctx;\n\tstruct intel_context *ce;\n\tstruct i915_gem_ww_ctx ww;\n\tint err = -ENODEV;\n\n\tfor_each_gem_engine(ce, i915_gem_context_lock_engines(ctx), it) {\n\t\tif (ce->engine != stream->engine)  \n\t\t\tcontinue;\n\n\t\terr = 0;\n\t\tbreak;\n\t}\n\ti915_gem_context_unlock_engines(ctx);\n\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\t \n\terr = intel_context_pin_ww(ce, &ww);\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tstream->pinned_ctx = ce;\n\treturn stream->pinned_ctx;\n}\n\nstatic int\n__store_reg_to_mem(struct i915_request *rq, i915_reg_t reg, u32 ggtt_offset)\n{\n\tu32 *cs, cmd;\n\n\tcmd = MI_STORE_REGISTER_MEM | MI_SRM_LRM_GLOBAL_GTT;\n\tif (GRAPHICS_VER(rq->i915) >= 8)\n\t\tcmd++;\n\n\tcs = intel_ring_begin(rq, 4);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = cmd;\n\t*cs++ = i915_mmio_reg_offset(reg);\n\t*cs++ = ggtt_offset;\n\t*cs++ = 0;\n\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstatic int\n__read_reg(struct intel_context *ce, i915_reg_t reg, u32 ggtt_offset)\n{\n\tstruct i915_request *rq;\n\tint err;\n\n\trq = i915_request_create(ce);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\ti915_request_get(rq);\n\n\terr = __store_reg_to_mem(rq, reg, ggtt_offset);\n\n\ti915_request_add(rq);\n\tif (!err && i915_request_wait(rq, 0, HZ / 2) < 0)\n\t\terr = -ETIME;\n\n\ti915_request_put(rq);\n\n\treturn err;\n}\n\nstatic int\ngen12_guc_sw_ctx_id(struct intel_context *ce, u32 *ctx_id)\n{\n\tstruct i915_vma *scratch;\n\tu32 *val;\n\tint err;\n\n\tscratch = __vm_create_scratch_for_read_pinned(&ce->engine->gt->ggtt->vm, 4);\n\tif (IS_ERR(scratch))\n\t\treturn PTR_ERR(scratch);\n\n\terr = i915_vma_sync(scratch);\n\tif (err)\n\t\tgoto err_scratch;\n\n\terr = __read_reg(ce, RING_EXECLIST_STATUS_HI(ce->engine->mmio_base),\n\t\t\t i915_ggtt_offset(scratch));\n\tif (err)\n\t\tgoto err_scratch;\n\n\tval = i915_gem_object_pin_map_unlocked(scratch->obj, I915_MAP_WB);\n\tif (IS_ERR(val)) {\n\t\terr = PTR_ERR(val);\n\t\tgoto err_scratch;\n\t}\n\n\t*ctx_id = *val;\n\ti915_gem_object_unpin_map(scratch->obj);\n\nerr_scratch:\n\ti915_vma_unpin_and_release(&scratch, 0);\n\treturn err;\n}\n\n \nstatic int gen12_get_render_context_id(struct i915_perf_stream *stream)\n{\n\tu32 ctx_id, mask;\n\tint ret;\n\n\tif (intel_engine_uses_guc(stream->engine)) {\n\t\tret = gen12_guc_sw_ctx_id(stream->pinned_ctx, &ctx_id);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tmask = ((1U << GEN12_GUC_SW_CTX_ID_WIDTH) - 1) <<\n\t\t\t(GEN12_GUC_SW_CTX_ID_SHIFT - 32);\n\t} else if (GRAPHICS_VER_FULL(stream->engine->i915) >= IP_VER(12, 50)) {\n\t\tctx_id = (XEHP_MAX_CONTEXT_HW_ID - 1) <<\n\t\t\t(XEHP_SW_CTX_ID_SHIFT - 32);\n\n\t\tmask = ((1U << XEHP_SW_CTX_ID_WIDTH) - 1) <<\n\t\t\t(XEHP_SW_CTX_ID_SHIFT - 32);\n\t} else {\n\t\tctx_id = (GEN12_MAX_CONTEXT_HW_ID - 1) <<\n\t\t\t (GEN11_SW_CTX_ID_SHIFT - 32);\n\n\t\tmask = ((1U << GEN11_SW_CTX_ID_WIDTH) - 1) <<\n\t\t\t(GEN11_SW_CTX_ID_SHIFT - 32);\n\t}\n\tstream->specific_ctx_id = ctx_id & mask;\n\tstream->specific_ctx_id_mask = mask;\n\n\treturn 0;\n}\n\nstatic bool oa_find_reg_in_lri(u32 *state, u32 reg, u32 *offset, u32 end)\n{\n\tu32 idx = *offset;\n\tu32 len = min(MI_LRI_LEN(state[idx]) + idx, end);\n\tbool found = false;\n\n\tidx++;\n\tfor (; idx < len; idx += 2) {\n\t\tif (state[idx] == reg) {\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t*offset = idx;\n\treturn found;\n}\n\nstatic u32 oa_context_image_offset(struct intel_context *ce, u32 reg)\n{\n\tu32 offset, len = (ce->engine->context_size - PAGE_SIZE) / 4;\n\tu32 *state = ce->lrc_reg_state;\n\n\tif (drm_WARN_ON(&ce->engine->i915->drm, !state))\n\t\treturn U32_MAX;\n\n\tfor (offset = 0; offset < len; ) {\n\t\tif (IS_MI_LRI_CMD(state[offset])) {\n\t\t\t \n\t\t\tdrm_WARN_ON(&ce->engine->i915->drm,\n\t\t\t\t    MI_LRI_LEN(state[offset]) & 0x1);\n\n\t\t\tif (oa_find_reg_in_lri(state, reg, &offset, len))\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\toffset++;\n\t\t}\n\t}\n\n\treturn offset < len ? offset : U32_MAX;\n}\n\nstatic int set_oa_ctx_ctrl_offset(struct intel_context *ce)\n{\n\ti915_reg_t reg = GEN12_OACTXCONTROL(ce->engine->mmio_base);\n\tstruct i915_perf *perf = &ce->engine->i915->perf;\n\tu32 offset = perf->ctx_oactxctrl_offset;\n\n\t \n\tif (offset)\n\t\tgoto exit;\n\n\toffset = oa_context_image_offset(ce, i915_mmio_reg_offset(reg));\n\tperf->ctx_oactxctrl_offset = offset;\n\n\tdrm_dbg(&ce->engine->i915->drm,\n\t\t\"%s oa ctx control at 0x%08x dword offset\\n\",\n\t\tce->engine->name, offset);\n\nexit:\n\treturn offset && offset != U32_MAX ? 0 : -ENODEV;\n}\n\nstatic bool engine_supports_mi_query(struct intel_engine_cs *engine)\n{\n\treturn engine->class == RENDER_CLASS;\n}\n\n \nstatic int oa_get_render_ctx_id(struct i915_perf_stream *stream)\n{\n\tstruct intel_context *ce;\n\tint ret = 0;\n\n\tce = oa_pin_context(stream);\n\tif (IS_ERR(ce))\n\t\treturn PTR_ERR(ce);\n\n\tif (engine_supports_mi_query(stream->engine) &&\n\t    HAS_LOGICAL_RING_CONTEXTS(stream->perf->i915)) {\n\t\t \n\t\tret = set_oa_ctx_ctrl_offset(ce);\n\t\tif (ret) {\n\t\t\tintel_context_unpin(ce);\n\t\t\tdrm_err(&stream->perf->i915->drm,\n\t\t\t\t\"Enabling perf query failed for %s\\n\",\n\t\t\t\tstream->engine->name);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tswitch (GRAPHICS_VER(ce->engine->i915)) {\n\tcase 7: {\n\t\t \n\t\tstream->specific_ctx_id = i915_ggtt_offset(ce->state);\n\t\tstream->specific_ctx_id_mask = 0;\n\t\tbreak;\n\t}\n\n\tcase 8:\n\tcase 9:\n\t\tif (intel_engine_uses_guc(ce->engine)) {\n\t\t\t \n\t\t\tstream->specific_ctx_id = ce->lrc.lrca >> 12;\n\n\t\t\t \n\t\t\tstream->specific_ctx_id_mask =\n\t\t\t\t(1U << (GEN8_CTX_ID_WIDTH - 1)) - 1;\n\t\t} else {\n\t\t\tstream->specific_ctx_id_mask =\n\t\t\t\t(1U << GEN8_CTX_ID_WIDTH) - 1;\n\t\t\tstream->specific_ctx_id = stream->specific_ctx_id_mask;\n\t\t}\n\t\tbreak;\n\n\tcase 11:\n\tcase 12:\n\t\tret = gen12_get_render_context_id(stream);\n\t\tbreak;\n\n\tdefault:\n\t\tMISSING_CASE(GRAPHICS_VER(ce->engine->i915));\n\t}\n\n\tce->tag = stream->specific_ctx_id;\n\n\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\"filtering on ctx_id=0x%x ctx_id_mask=0x%x\\n\",\n\t\tstream->specific_ctx_id,\n\t\tstream->specific_ctx_id_mask);\n\n\treturn ret;\n}\n\n \nstatic void oa_put_render_ctx_id(struct i915_perf_stream *stream)\n{\n\tstruct intel_context *ce;\n\n\tce = fetch_and_zero(&stream->pinned_ctx);\n\tif (ce) {\n\t\tce->tag = 0;  \n\t\tintel_context_unpin(ce);\n\t}\n\n\tstream->specific_ctx_id = INVALID_CTX_ID;\n\tstream->specific_ctx_id_mask = 0;\n}\n\nstatic void\nfree_oa_buffer(struct i915_perf_stream *stream)\n{\n\ti915_vma_unpin_and_release(&stream->oa_buffer.vma,\n\t\t\t\t   I915_VMA_RELEASE_MAP);\n\n\tstream->oa_buffer.vaddr = NULL;\n}\n\nstatic void\nfree_oa_configs(struct i915_perf_stream *stream)\n{\n\tstruct i915_oa_config_bo *oa_bo, *tmp;\n\n\ti915_oa_config_put(stream->oa_config);\n\tllist_for_each_entry_safe(oa_bo, tmp, stream->oa_config_bos.first, node)\n\t\tfree_oa_config_bo(oa_bo);\n}\n\nstatic void\nfree_noa_wait(struct i915_perf_stream *stream)\n{\n\ti915_vma_unpin_and_release(&stream->noa_wait, 0);\n}\n\nstatic bool engine_supports_oa(const struct intel_engine_cs *engine)\n{\n\treturn engine->oa_group;\n}\n\nstatic bool engine_supports_oa_format(struct intel_engine_cs *engine, int type)\n{\n\treturn engine->oa_group && engine->oa_group->type == type;\n}\n\nstatic void i915_oa_stream_destroy(struct i915_perf_stream *stream)\n{\n\tstruct i915_perf *perf = stream->perf;\n\tstruct intel_gt *gt = stream->engine->gt;\n\tstruct i915_perf_group *g = stream->engine->oa_group;\n\n\tif (WARN_ON(stream != g->exclusive_stream))\n\t\treturn;\n\n\t \n\tWRITE_ONCE(g->exclusive_stream, NULL);\n\tperf->ops.disable_metric_set(stream);\n\n\tfree_oa_buffer(stream);\n\n\t \n\tif (stream->override_gucrc)\n\t\tdrm_WARN_ON(&gt->i915->drm,\n\t\t\t    intel_guc_slpc_unset_gucrc_mode(&gt->uc.guc.slpc));\n\n\tintel_uncore_forcewake_put(stream->uncore, FORCEWAKE_ALL);\n\tintel_engine_pm_put(stream->engine);\n\n\tif (stream->ctx)\n\t\toa_put_render_ctx_id(stream);\n\n\tfree_oa_configs(stream);\n\tfree_noa_wait(stream);\n\n\tif (perf->spurious_report_rs.missed) {\n\t\tdrm_notice(&gt->i915->drm,\n\t\t\t   \"%d spurious OA report notices suppressed due to ratelimiting\\n\",\n\t\t\t   perf->spurious_report_rs.missed);\n\t}\n}\n\nstatic void gen7_init_oa_buffer(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tu32 gtt_offset = i915_ggtt_offset(stream->oa_buffer.vma);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\t \n\tintel_uncore_write(uncore, GEN7_OASTATUS2,  \n\t\t\t   gtt_offset | GEN7_OASTATUS2_MEM_SELECT_GGTT);\n\tstream->oa_buffer.head = gtt_offset;\n\n\tintel_uncore_write(uncore, GEN7_OABUFFER, gtt_offset);\n\n\tintel_uncore_write(uncore, GEN7_OASTATUS1,  \n\t\t\t   gtt_offset | OABUFFER_SIZE_16M);\n\n\t \n\tstream->oa_buffer.tail = gtt_offset;\n\n\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\n\t \n\tstream->perf->gen7_latched_oastatus1 = 0;\n\n\t \n\tmemset(stream->oa_buffer.vaddr, 0, OA_BUFFER_SIZE);\n}\n\nstatic void gen8_init_oa_buffer(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tu32 gtt_offset = i915_ggtt_offset(stream->oa_buffer.vma);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\tintel_uncore_write(uncore, GEN8_OASTATUS, 0);\n\tintel_uncore_write(uncore, GEN8_OAHEADPTR, gtt_offset);\n\tstream->oa_buffer.head = gtt_offset;\n\n\tintel_uncore_write(uncore, GEN8_OABUFFER_UDW, 0);\n\n\t \n\tintel_uncore_write(uncore, GEN8_OABUFFER, gtt_offset |\n\t\t   OABUFFER_SIZE_16M | GEN8_OABUFFER_MEM_SELECT_GGTT);\n\tintel_uncore_write(uncore, GEN8_OATAILPTR, gtt_offset & GEN8_OATAILPTR_MASK);\n\n\t \n\tstream->oa_buffer.tail = gtt_offset;\n\n\t \n\tstream->oa_buffer.last_ctx_id = INVALID_CTX_ID;\n\n\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\n\t \n\tmemset(stream->oa_buffer.vaddr, 0, OA_BUFFER_SIZE);\n}\n\nstatic void gen12_init_oa_buffer(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tu32 gtt_offset = i915_ggtt_offset(stream->oa_buffer.vma);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&stream->oa_buffer.ptr_lock, flags);\n\n\tintel_uncore_write(uncore, __oa_regs(stream)->oa_status, 0);\n\tintel_uncore_write(uncore, __oa_regs(stream)->oa_head_ptr,\n\t\t\t   gtt_offset & GEN12_OAG_OAHEADPTR_MASK);\n\tstream->oa_buffer.head = gtt_offset;\n\n\t \n\tintel_uncore_write(uncore, __oa_regs(stream)->oa_buffer, gtt_offset |\n\t\t\t   OABUFFER_SIZE_16M | GEN8_OABUFFER_MEM_SELECT_GGTT);\n\tintel_uncore_write(uncore, __oa_regs(stream)->oa_tail_ptr,\n\t\t\t   gtt_offset & GEN12_OAG_OATAILPTR_MASK);\n\n\t \n\tstream->oa_buffer.tail = gtt_offset;\n\n\t \n\tstream->oa_buffer.last_ctx_id = INVALID_CTX_ID;\n\n\tspin_unlock_irqrestore(&stream->oa_buffer.ptr_lock, flags);\n\n\t \n\tmemset(stream->oa_buffer.vaddr, 0,\n\t       stream->oa_buffer.vma->size);\n}\n\nstatic int alloc_oa_buffer(struct i915_perf_stream *stream)\n{\n\tstruct drm_i915_private *i915 = stream->perf->i915;\n\tstruct intel_gt *gt = stream->engine->gt;\n\tstruct drm_i915_gem_object *bo;\n\tstruct i915_vma *vma;\n\tint ret;\n\n\tif (drm_WARN_ON(&i915->drm, stream->oa_buffer.vma))\n\t\treturn -ENODEV;\n\n\tBUILD_BUG_ON_NOT_POWER_OF_2(OA_BUFFER_SIZE);\n\tBUILD_BUG_ON(OA_BUFFER_SIZE < SZ_128K || OA_BUFFER_SIZE > SZ_16M);\n\n\tbo = i915_gem_object_create_shmem(stream->perf->i915, OA_BUFFER_SIZE);\n\tif (IS_ERR(bo)) {\n\t\tdrm_err(&i915->drm, \"Failed to allocate OA buffer\\n\");\n\t\treturn PTR_ERR(bo);\n\t}\n\n\ti915_gem_object_set_cache_coherency(bo, I915_CACHE_LLC);\n\n\t \n\tvma = i915_vma_instance(bo, &gt->ggtt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\tret = PTR_ERR(vma);\n\t\tgoto err_unref;\n\t}\n\n\t \n\tret = i915_vma_pin(vma, 0, SZ_16M, PIN_GLOBAL | PIN_HIGH);\n\tif (ret) {\n\t\tdrm_err(&gt->i915->drm, \"Failed to pin OA buffer %d\\n\", ret);\n\t\tgoto err_unref;\n\t}\n\n\tstream->oa_buffer.vma = vma;\n\n\tstream->oa_buffer.vaddr =\n\t\ti915_gem_object_pin_map_unlocked(bo, I915_MAP_WB);\n\tif (IS_ERR(stream->oa_buffer.vaddr)) {\n\t\tret = PTR_ERR(stream->oa_buffer.vaddr);\n\t\tgoto err_unpin;\n\t}\n\n\treturn 0;\n\nerr_unpin:\n\t__i915_vma_unpin(vma);\n\nerr_unref:\n\ti915_gem_object_put(bo);\n\n\tstream->oa_buffer.vaddr = NULL;\n\tstream->oa_buffer.vma = NULL;\n\n\treturn ret;\n}\n\nstatic u32 *save_restore_register(struct i915_perf_stream *stream, u32 *cs,\n\t\t\t\t  bool save, i915_reg_t reg, u32 offset,\n\t\t\t\t  u32 dword_count)\n{\n\tu32 cmd;\n\tu32 d;\n\n\tcmd = save ? MI_STORE_REGISTER_MEM : MI_LOAD_REGISTER_MEM;\n\tcmd |= MI_SRM_LRM_GLOBAL_GTT;\n\tif (GRAPHICS_VER(stream->perf->i915) >= 8)\n\t\tcmd++;\n\n\tfor (d = 0; d < dword_count; d++) {\n\t\t*cs++ = cmd;\n\t\t*cs++ = i915_mmio_reg_offset(reg) + 4 * d;\n\t\t*cs++ = i915_ggtt_offset(stream->noa_wait) + offset + 4 * d;\n\t\t*cs++ = 0;\n\t}\n\n\treturn cs;\n}\n\nstatic int alloc_noa_wait(struct i915_perf_stream *stream)\n{\n\tstruct drm_i915_private *i915 = stream->perf->i915;\n\tstruct intel_gt *gt = stream->engine->gt;\n\tstruct drm_i915_gem_object *bo;\n\tstruct i915_vma *vma;\n\tconst u64 delay_ticks = 0xffffffffffffffff -\n\t\tintel_gt_ns_to_clock_interval(to_gt(stream->perf->i915),\n\t\tatomic64_read(&stream->perf->noa_programming_delay));\n\tconst u32 base = stream->engine->mmio_base;\n#define CS_GPR(x) GEN8_RING_CS_GPR(base, x)\n\tu32 *batch, *ts0, *cs, *jump;\n\tstruct i915_gem_ww_ctx ww;\n\tint ret, i;\n\tenum {\n\t\tSTART_TS,\n\t\tNOW_TS,\n\t\tDELTA_TS,\n\t\tJUMP_PREDICATE,\n\t\tDELTA_TARGET,\n\t\tN_CS_GPR\n\t};\n\ti915_reg_t mi_predicate_result = HAS_MI_SET_PREDICATE(i915) ?\n\t\t\t\t\t  MI_PREDICATE_RESULT_2_ENGINE(base) :\n\t\t\t\t\t  MI_PREDICATE_RESULT_1(RENDER_RING_BASE);\n\n\t \n\tbo = i915_gem_object_create_internal(i915, 8192);\n\tif (IS_ERR(bo)) {\n\t\tdrm_err(&i915->drm,\n\t\t\t\"Failed to allocate NOA wait batchbuffer\\n\");\n\t\treturn PTR_ERR(bo);\n\t}\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\tret = i915_gem_object_lock(bo, &ww);\n\tif (ret)\n\t\tgoto out_ww;\n\n\t \n\tvma = i915_vma_instance(bo, &gt->ggtt->vm, NULL);\n\tif (IS_ERR(vma)) {\n\t\tret = PTR_ERR(vma);\n\t\tgoto out_ww;\n\t}\n\n\tret = i915_vma_pin_ww(vma, &ww, 0, 0, PIN_GLOBAL | PIN_HIGH);\n\tif (ret)\n\t\tgoto out_ww;\n\n\tbatch = cs = i915_gem_object_pin_map(bo, I915_MAP_WB);\n\tif (IS_ERR(batch)) {\n\t\tret = PTR_ERR(batch);\n\t\tgoto err_unpin;\n\t}\n\n\tstream->noa_wait = vma;\n\n#define GPR_SAVE_OFFSET 4096\n#define PREDICATE_SAVE_OFFSET 4160\n\n\t \n\tfor (i = 0; i < N_CS_GPR; i++)\n\t\tcs = save_restore_register(\n\t\t\tstream, cs, true  , CS_GPR(i),\n\t\t\tGPR_SAVE_OFFSET + 8 * i, 2);\n\tcs = save_restore_register(\n\t\tstream, cs, true  , mi_predicate_result,\n\t\tPREDICATE_SAVE_OFFSET, 1);\n\n\t \n\tts0 = cs;\n\n\t \n\t*cs++ = MI_LOAD_REGISTER_IMM(1);\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(START_TS)) + 4;\n\t*cs++ = 0;\n\t*cs++ = MI_LOAD_REGISTER_REG | (3 - 2);\n\t*cs++ = i915_mmio_reg_offset(RING_TIMESTAMP(base));\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(START_TS));\n\n\t \n\tjump = cs;\n\n\t \n\t*cs++ = MI_LOAD_REGISTER_IMM(1);\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(NOW_TS)) + 4;\n\t*cs++ = 0;\n\t*cs++ = MI_LOAD_REGISTER_REG | (3 - 2);\n\t*cs++ = i915_mmio_reg_offset(RING_TIMESTAMP(base));\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(NOW_TS));\n\n\t \n\t*cs++ = MI_MATH(5);\n\t*cs++ = MI_MATH_LOAD(MI_MATH_REG_SRCA, MI_MATH_REG(NOW_TS));\n\t*cs++ = MI_MATH_LOAD(MI_MATH_REG_SRCB, MI_MATH_REG(START_TS));\n\t*cs++ = MI_MATH_SUB;\n\t*cs++ = MI_MATH_STORE(MI_MATH_REG(DELTA_TS), MI_MATH_REG_ACCU);\n\t*cs++ = MI_MATH_STORE(MI_MATH_REG(JUMP_PREDICATE), MI_MATH_REG_CF);\n\n\t \n\t*cs++ = MI_LOAD_REGISTER_REG | (3 - 2);\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(JUMP_PREDICATE));\n\t*cs++ = i915_mmio_reg_offset(mi_predicate_result);\n\n\tif (HAS_MI_SET_PREDICATE(i915))\n\t\t*cs++ = MI_SET_PREDICATE | 1;\n\n\t \n\t*cs++ = (GRAPHICS_VER(i915) < 8 ?\n\t\t MI_BATCH_BUFFER_START :\n\t\t MI_BATCH_BUFFER_START_GEN8) |\n\t\tMI_BATCH_PREDICATE;\n\t*cs++ = i915_ggtt_offset(vma) + (ts0 - batch) * 4;\n\t*cs++ = 0;\n\n\tif (HAS_MI_SET_PREDICATE(i915))\n\t\t*cs++ = MI_SET_PREDICATE;\n\n\t \n\t*cs++ = MI_LOAD_REGISTER_IMM(2);\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(DELTA_TARGET));\n\t*cs++ = lower_32_bits(delay_ticks);\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(DELTA_TARGET)) + 4;\n\t*cs++ = upper_32_bits(delay_ticks);\n\n\t*cs++ = MI_MATH(4);\n\t*cs++ = MI_MATH_LOAD(MI_MATH_REG_SRCA, MI_MATH_REG(DELTA_TS));\n\t*cs++ = MI_MATH_LOAD(MI_MATH_REG_SRCB, MI_MATH_REG(DELTA_TARGET));\n\t*cs++ = MI_MATH_ADD;\n\t*cs++ = MI_MATH_STOREINV(MI_MATH_REG(JUMP_PREDICATE), MI_MATH_REG_CF);\n\n\t*cs++ = MI_ARB_CHECK;\n\n\t \n\t*cs++ = MI_LOAD_REGISTER_REG | (3 - 2);\n\t*cs++ = i915_mmio_reg_offset(CS_GPR(JUMP_PREDICATE));\n\t*cs++ = i915_mmio_reg_offset(mi_predicate_result);\n\n\tif (HAS_MI_SET_PREDICATE(i915))\n\t\t*cs++ = MI_SET_PREDICATE | 1;\n\n\t \n\t*cs++ = (GRAPHICS_VER(i915) < 8 ?\n\t\t MI_BATCH_BUFFER_START :\n\t\t MI_BATCH_BUFFER_START_GEN8) |\n\t\tMI_BATCH_PREDICATE;\n\t*cs++ = i915_ggtt_offset(vma) + (jump - batch) * 4;\n\t*cs++ = 0;\n\n\tif (HAS_MI_SET_PREDICATE(i915))\n\t\t*cs++ = MI_SET_PREDICATE;\n\n\t \n\tfor (i = 0; i < N_CS_GPR; i++)\n\t\tcs = save_restore_register(\n\t\t\tstream, cs, false  , CS_GPR(i),\n\t\t\tGPR_SAVE_OFFSET + 8 * i, 2);\n\tcs = save_restore_register(\n\t\tstream, cs, false  , mi_predicate_result,\n\t\tPREDICATE_SAVE_OFFSET, 1);\n\n\t \n\t*cs++ = MI_BATCH_BUFFER_END;\n\n\tGEM_BUG_ON(cs - batch > PAGE_SIZE / sizeof(*batch));\n\n\ti915_gem_object_flush_map(bo);\n\t__i915_gem_object_release_map(bo);\n\n\tgoto out_ww;\n\nerr_unpin:\n\ti915_vma_unpin_and_release(&vma, 0);\nout_ww:\n\tif (ret == -EDEADLK) {\n\t\tret = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!ret)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\tif (ret)\n\t\ti915_gem_object_put(bo);\n\treturn ret;\n}\n\nstatic u32 *write_cs_mi_lri(u32 *cs,\n\t\t\t    const struct i915_oa_reg *reg_data,\n\t\t\t    u32 n_regs)\n{\n\tu32 i;\n\n\tfor (i = 0; i < n_regs; i++) {\n\t\tif ((i % MI_LOAD_REGISTER_IMM_MAX_REGS) == 0) {\n\t\t\tu32 n_lri = min_t(u32,\n\t\t\t\t\t  n_regs - i,\n\t\t\t\t\t  MI_LOAD_REGISTER_IMM_MAX_REGS);\n\n\t\t\t*cs++ = MI_LOAD_REGISTER_IMM(n_lri);\n\t\t}\n\t\t*cs++ = i915_mmio_reg_offset(reg_data[i].addr);\n\t\t*cs++ = reg_data[i].value;\n\t}\n\n\treturn cs;\n}\n\nstatic int num_lri_dwords(int num_regs)\n{\n\tint count = 0;\n\n\tif (num_regs > 0) {\n\t\tcount += DIV_ROUND_UP(num_regs, MI_LOAD_REGISTER_IMM_MAX_REGS);\n\t\tcount += num_regs * 2;\n\t}\n\n\treturn count;\n}\n\nstatic struct i915_oa_config_bo *\nalloc_oa_config_buffer(struct i915_perf_stream *stream,\n\t\t       struct i915_oa_config *oa_config)\n{\n\tstruct drm_i915_gem_object *obj;\n\tstruct i915_oa_config_bo *oa_bo;\n\tstruct i915_gem_ww_ctx ww;\n\tsize_t config_length = 0;\n\tu32 *cs;\n\tint err;\n\n\toa_bo = kzalloc(sizeof(*oa_bo), GFP_KERNEL);\n\tif (!oa_bo)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tconfig_length += num_lri_dwords(oa_config->mux_regs_len);\n\tconfig_length += num_lri_dwords(oa_config->b_counter_regs_len);\n\tconfig_length += num_lri_dwords(oa_config->flex_regs_len);\n\tconfig_length += 3;  \n\tconfig_length = ALIGN(sizeof(u32) * config_length, I915_GTT_PAGE_SIZE);\n\n\tobj = i915_gem_object_create_shmem(stream->perf->i915, config_length);\n\tif (IS_ERR(obj)) {\n\t\terr = PTR_ERR(obj);\n\t\tgoto err_free;\n\t}\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\terr = i915_gem_object_lock(obj, &ww);\n\tif (err)\n\t\tgoto out_ww;\n\n\tcs = i915_gem_object_pin_map(obj, I915_MAP_WB);\n\tif (IS_ERR(cs)) {\n\t\terr = PTR_ERR(cs);\n\t\tgoto out_ww;\n\t}\n\n\tcs = write_cs_mi_lri(cs,\n\t\t\t     oa_config->mux_regs,\n\t\t\t     oa_config->mux_regs_len);\n\tcs = write_cs_mi_lri(cs,\n\t\t\t     oa_config->b_counter_regs,\n\t\t\t     oa_config->b_counter_regs_len);\n\tcs = write_cs_mi_lri(cs,\n\t\t\t     oa_config->flex_regs,\n\t\t\t     oa_config->flex_regs_len);\n\n\t \n\t*cs++ = (GRAPHICS_VER(stream->perf->i915) < 8 ?\n\t\t MI_BATCH_BUFFER_START :\n\t\t MI_BATCH_BUFFER_START_GEN8);\n\t*cs++ = i915_ggtt_offset(stream->noa_wait);\n\t*cs++ = 0;\n\n\ti915_gem_object_flush_map(obj);\n\t__i915_gem_object_release_map(obj);\n\n\toa_bo->vma = i915_vma_instance(obj,\n\t\t\t\t       &stream->engine->gt->ggtt->vm,\n\t\t\t\t       NULL);\n\tif (IS_ERR(oa_bo->vma)) {\n\t\terr = PTR_ERR(oa_bo->vma);\n\t\tgoto out_ww;\n\t}\n\n\toa_bo->oa_config = i915_oa_config_get(oa_config);\n\tllist_add(&oa_bo->node, &stream->oa_config_bos);\n\nout_ww:\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\ti915_gem_ww_ctx_fini(&ww);\n\n\tif (err)\n\t\ti915_gem_object_put(obj);\nerr_free:\n\tif (err) {\n\t\tkfree(oa_bo);\n\t\treturn ERR_PTR(err);\n\t}\n\treturn oa_bo;\n}\n\nstatic struct i915_vma *\nget_oa_vma(struct i915_perf_stream *stream, struct i915_oa_config *oa_config)\n{\n\tstruct i915_oa_config_bo *oa_bo;\n\n\t \n\tllist_for_each_entry(oa_bo, stream->oa_config_bos.first, node) {\n\t\tif (oa_bo->oa_config == oa_config &&\n\t\t    memcmp(oa_bo->oa_config->uuid,\n\t\t\t   oa_config->uuid,\n\t\t\t   sizeof(oa_config->uuid)) == 0)\n\t\t\tgoto out;\n\t}\n\n\toa_bo = alloc_oa_config_buffer(stream, oa_config);\n\tif (IS_ERR(oa_bo))\n\t\treturn ERR_CAST(oa_bo);\n\nout:\n\treturn i915_vma_get(oa_bo->vma);\n}\n\nstatic int\nemit_oa_config(struct i915_perf_stream *stream,\n\t       struct i915_oa_config *oa_config,\n\t       struct intel_context *ce,\n\t       struct i915_active *active)\n{\n\tstruct i915_request *rq;\n\tstruct i915_vma *vma;\n\tstruct i915_gem_ww_ctx ww;\n\tint err;\n\n\tvma = get_oa_vma(stream, oa_config);\n\tif (IS_ERR(vma))\n\t\treturn PTR_ERR(vma);\n\n\ti915_gem_ww_ctx_init(&ww, true);\nretry:\n\terr = i915_gem_object_lock(vma->obj, &ww);\n\tif (err)\n\t\tgoto err;\n\n\terr = i915_vma_pin_ww(vma, &ww, 0, 0, PIN_GLOBAL | PIN_HIGH);\n\tif (err)\n\t\tgoto err;\n\n\tintel_engine_pm_get(ce->engine);\n\trq = i915_request_create(ce);\n\tintel_engine_pm_put(ce->engine);\n\tif (IS_ERR(rq)) {\n\t\terr = PTR_ERR(rq);\n\t\tgoto err_vma_unpin;\n\t}\n\n\tif (!IS_ERR_OR_NULL(active)) {\n\t\t \n\t\terr = i915_request_await_active(rq, active,\n\t\t\t\t\t\tI915_ACTIVE_AWAIT_ACTIVE);\n\t\tif (err)\n\t\t\tgoto err_add_request;\n\n\t\terr = i915_active_add_request(active, rq);\n\t\tif (err)\n\t\t\tgoto err_add_request;\n\t}\n\n\terr = i915_vma_move_to_active(vma, rq, 0);\n\tif (err)\n\t\tgoto err_add_request;\n\n\terr = rq->engine->emit_bb_start(rq,\n\t\t\t\t\ti915_vma_offset(vma), 0,\n\t\t\t\t\tI915_DISPATCH_SECURE);\n\tif (err)\n\t\tgoto err_add_request;\n\nerr_add_request:\n\ti915_request_add(rq);\nerr_vma_unpin:\n\ti915_vma_unpin(vma);\nerr:\n\tif (err == -EDEADLK) {\n\t\terr = i915_gem_ww_ctx_backoff(&ww);\n\t\tif (!err)\n\t\t\tgoto retry;\n\t}\n\n\ti915_gem_ww_ctx_fini(&ww);\n\ti915_vma_put(vma);\n\treturn err;\n}\n\nstatic struct intel_context *oa_context(struct i915_perf_stream *stream)\n{\n\treturn stream->pinned_ctx ?: stream->engine->kernel_context;\n}\n\nstatic int\nhsw_enable_metric_set(struct i915_perf_stream *stream,\n\t\t      struct i915_active *active)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\t \n\tintel_uncore_rmw(uncore, GEN7_MISCCPCTL,\n\t\t\t GEN7_DOP_CLOCK_GATE_ENABLE, 0);\n\tintel_uncore_rmw(uncore, GEN6_UCGCTL1,\n\t\t\t 0, GEN6_CSUNIT_CLOCK_GATE_DISABLE);\n\n\treturn emit_oa_config(stream,\n\t\t\t      stream->oa_config, oa_context(stream),\n\t\t\t      active);\n}\n\nstatic void hsw_disable_metric_set(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\tintel_uncore_rmw(uncore, GEN6_UCGCTL1,\n\t\t\t GEN6_CSUNIT_CLOCK_GATE_DISABLE, 0);\n\tintel_uncore_rmw(uncore, GEN7_MISCCPCTL,\n\t\t\t 0, GEN7_DOP_CLOCK_GATE_ENABLE);\n\n\tintel_uncore_rmw(uncore, GDT_CHICKEN_BITS, GT_NOA_ENABLE, 0);\n}\n\nstatic u32 oa_config_flex_reg(const struct i915_oa_config *oa_config,\n\t\t\t      i915_reg_t reg)\n{\n\tu32 mmio = i915_mmio_reg_offset(reg);\n\tint i;\n\n\t \n\tif (!oa_config)\n\t\treturn 0;\n\n\tfor (i = 0; i < oa_config->flex_regs_len; i++) {\n\t\tif (i915_mmio_reg_offset(oa_config->flex_regs[i].addr) == mmio)\n\t\t\treturn oa_config->flex_regs[i].value;\n\t}\n\n\treturn 0;\n}\n \nstatic void\ngen8_update_reg_state_unlocked(const struct intel_context *ce,\n\t\t\t       const struct i915_perf_stream *stream)\n{\n\tu32 ctx_oactxctrl = stream->perf->ctx_oactxctrl_offset;\n\tu32 ctx_flexeu0 = stream->perf->ctx_flexeu0_offset;\n\t \n\tstatic const i915_reg_t flex_regs[] = {\n\t\tEU_PERF_CNTL0,\n\t\tEU_PERF_CNTL1,\n\t\tEU_PERF_CNTL2,\n\t\tEU_PERF_CNTL3,\n\t\tEU_PERF_CNTL4,\n\t\tEU_PERF_CNTL5,\n\t\tEU_PERF_CNTL6,\n\t};\n\tu32 *reg_state = ce->lrc_reg_state;\n\tint i;\n\n\treg_state[ctx_oactxctrl + 1] =\n\t\t(stream->period_exponent << GEN8_OA_TIMER_PERIOD_SHIFT) |\n\t\t(stream->periodic ? GEN8_OA_TIMER_ENABLE : 0) |\n\t\tGEN8_OA_COUNTER_RESUME;\n\n\tfor (i = 0; i < ARRAY_SIZE(flex_regs); i++)\n\t\treg_state[ctx_flexeu0 + i * 2 + 1] =\n\t\t\toa_config_flex_reg(stream->oa_config, flex_regs[i]);\n}\n\nstruct flex {\n\ti915_reg_t reg;\n\tu32 offset;\n\tu32 value;\n};\n\nstatic int\ngen8_store_flex(struct i915_request *rq,\n\t\tstruct intel_context *ce,\n\t\tconst struct flex *flex, unsigned int count)\n{\n\tu32 offset;\n\tu32 *cs;\n\n\tcs = intel_ring_begin(rq, 4 * count);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\toffset = i915_ggtt_offset(ce->state) + LRC_STATE_OFFSET;\n\tdo {\n\t\t*cs++ = MI_STORE_DWORD_IMM_GEN4 | MI_USE_GGTT;\n\t\t*cs++ = offset + flex->offset * sizeof(u32);\n\t\t*cs++ = 0;\n\t\t*cs++ = flex->value;\n\t} while (flex++, --count);\n\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstatic int\ngen8_load_flex(struct i915_request *rq,\n\t       struct intel_context *ce,\n\t       const struct flex *flex, unsigned int count)\n{\n\tu32 *cs;\n\n\tGEM_BUG_ON(!count || count > 63);\n\n\tcs = intel_ring_begin(rq, 2 * count + 2);\n\tif (IS_ERR(cs))\n\t\treturn PTR_ERR(cs);\n\n\t*cs++ = MI_LOAD_REGISTER_IMM(count);\n\tdo {\n\t\t*cs++ = i915_mmio_reg_offset(flex->reg);\n\t\t*cs++ = flex->value;\n\t} while (flex++, --count);\n\t*cs++ = MI_NOOP;\n\n\tintel_ring_advance(rq, cs);\n\n\treturn 0;\n}\n\nstatic int gen8_modify_context(struct intel_context *ce,\n\t\t\t       const struct flex *flex, unsigned int count)\n{\n\tstruct i915_request *rq;\n\tint err;\n\n\trq = intel_engine_create_kernel_request(ce->engine);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\t \n\terr = intel_context_prepare_remote_request(ce, rq);\n\tif (err == 0)\n\t\terr = gen8_store_flex(rq, ce, flex, count);\n\n\ti915_request_add(rq);\n\treturn err;\n}\n\nstatic int\ngen8_modify_self(struct intel_context *ce,\n\t\t const struct flex *flex, unsigned int count,\n\t\t struct i915_active *active)\n{\n\tstruct i915_request *rq;\n\tint err;\n\n\tintel_engine_pm_get(ce->engine);\n\trq = i915_request_create(ce);\n\tintel_engine_pm_put(ce->engine);\n\tif (IS_ERR(rq))\n\t\treturn PTR_ERR(rq);\n\n\tif (!IS_ERR_OR_NULL(active)) {\n\t\terr = i915_active_add_request(active, rq);\n\t\tif (err)\n\t\t\tgoto err_add_request;\n\t}\n\n\terr = gen8_load_flex(rq, ce, flex, count);\n\tif (err)\n\t\tgoto err_add_request;\n\nerr_add_request:\n\ti915_request_add(rq);\n\treturn err;\n}\n\nstatic int gen8_configure_context(struct i915_perf_stream *stream,\n\t\t\t\t  struct i915_gem_context *ctx,\n\t\t\t\t  struct flex *flex, unsigned int count)\n{\n\tstruct i915_gem_engines_iter it;\n\tstruct intel_context *ce;\n\tint err = 0;\n\n\tfor_each_gem_engine(ce, i915_gem_context_lock_engines(ctx), it) {\n\t\tGEM_BUG_ON(ce == ce->engine->kernel_context);\n\n\t\tif (ce->engine->class != RENDER_CLASS)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!intel_context_pin_if_active(ce))\n\t\t\tcontinue;\n\n\t\tflex->value = intel_sseu_make_rpcs(ce->engine->gt, &ce->sseu);\n\t\terr = gen8_modify_context(ce, flex, count);\n\n\t\tintel_context_unpin(ce);\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\ti915_gem_context_unlock_engines(ctx);\n\n\treturn err;\n}\n\nstatic int gen12_configure_oar_context(struct i915_perf_stream *stream,\n\t\t\t\t       struct i915_active *active)\n{\n\tint err;\n\tstruct intel_context *ce = stream->pinned_ctx;\n\tu32 format = stream->oa_buffer.format->format;\n\tu32 offset = stream->perf->ctx_oactxctrl_offset;\n\tstruct flex regs_context[] = {\n\t\t{\n\t\t\tGEN8_OACTXCONTROL,\n\t\t\toffset + 1,\n\t\t\tactive ? GEN8_OA_COUNTER_RESUME : 0,\n\t\t},\n\t};\n\t \n#define GEN12_OAR_OACONTROL_OFFSET 0x5B0\n\tstruct flex regs_lri[] = {\n\t\t{\n\t\t\tGEN12_OAR_OACONTROL,\n\t\t\tGEN12_OAR_OACONTROL_OFFSET + 1,\n\t\t\t(format << GEN12_OAR_OACONTROL_COUNTER_FORMAT_SHIFT) |\n\t\t\t(active ? GEN12_OAR_OACONTROL_COUNTER_ENABLE : 0)\n\t\t},\n\t\t{\n\t\t\tRING_CONTEXT_CONTROL(ce->engine->mmio_base),\n\t\t\tCTX_CONTEXT_CONTROL,\n\t\t\t_MASKED_FIELD(GEN12_CTX_CTRL_OAR_CONTEXT_ENABLE,\n\t\t\t\t      active ?\n\t\t\t\t      GEN12_CTX_CTRL_OAR_CONTEXT_ENABLE :\n\t\t\t\t      0)\n\t\t},\n\t};\n\n\t \n\terr = intel_context_lock_pinned(ce);\n\tif (err)\n\t\treturn err;\n\n\terr = gen8_modify_context(ce, regs_context,\n\t\t\t\t  ARRAY_SIZE(regs_context));\n\tintel_context_unlock_pinned(ce);\n\tif (err)\n\t\treturn err;\n\n\t \n\treturn gen8_modify_self(ce, regs_lri, ARRAY_SIZE(regs_lri), active);\n}\n\n \nstatic int\noa_configure_all_contexts(struct i915_perf_stream *stream,\n\t\t\t  struct flex *regs,\n\t\t\t  size_t num_regs,\n\t\t\t  struct i915_active *active)\n{\n\tstruct drm_i915_private *i915 = stream->perf->i915;\n\tstruct intel_engine_cs *engine;\n\tstruct intel_gt *gt = stream->engine->gt;\n\tstruct i915_gem_context *ctx, *cn;\n\tint err;\n\n\tlockdep_assert_held(&gt->perf.lock);\n\n\t \n\tspin_lock(&i915->gem.contexts.lock);\n\tlist_for_each_entry_safe(ctx, cn, &i915->gem.contexts.list, link) {\n\t\tif (!kref_get_unless_zero(&ctx->ref))\n\t\t\tcontinue;\n\n\t\tspin_unlock(&i915->gem.contexts.lock);\n\n\t\terr = gen8_configure_context(stream, ctx, regs, num_regs);\n\t\tif (err) {\n\t\t\ti915_gem_context_put(ctx);\n\t\t\treturn err;\n\t\t}\n\n\t\tspin_lock(&i915->gem.contexts.lock);\n\t\tlist_safe_reset_next(ctx, cn, link);\n\t\ti915_gem_context_put(ctx);\n\t}\n\tspin_unlock(&i915->gem.contexts.lock);\n\n\t \n\tfor_each_uabi_engine(engine, i915) {\n\t\tstruct intel_context *ce = engine->kernel_context;\n\n\t\tif (engine->class != RENDER_CLASS)\n\t\t\tcontinue;\n\n\t\tregs[0].value = intel_sseu_make_rpcs(engine->gt, &ce->sseu);\n\n\t\terr = gen8_modify_self(ce, regs, num_regs, active);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int\ngen12_configure_all_contexts(struct i915_perf_stream *stream,\n\t\t\t     const struct i915_oa_config *oa_config,\n\t\t\t     struct i915_active *active)\n{\n\tstruct flex regs[] = {\n\t\t{\n\t\t\tGEN8_R_PWR_CLK_STATE(RENDER_RING_BASE),\n\t\t\tCTX_R_PWR_CLK_STATE,\n\t\t},\n\t};\n\n\tif (stream->engine->class != RENDER_CLASS)\n\t\treturn 0;\n\n\treturn oa_configure_all_contexts(stream,\n\t\t\t\t\t regs, ARRAY_SIZE(regs),\n\t\t\t\t\t active);\n}\n\nstatic int\nlrc_configure_all_contexts(struct i915_perf_stream *stream,\n\t\t\t   const struct i915_oa_config *oa_config,\n\t\t\t   struct i915_active *active)\n{\n\tu32 ctx_oactxctrl = stream->perf->ctx_oactxctrl_offset;\n\t \n\tconst u32 ctx_flexeu0 = stream->perf->ctx_flexeu0_offset;\n#define ctx_flexeuN(N) (ctx_flexeu0 + 2 * (N) + 1)\n\tstruct flex regs[] = {\n\t\t{\n\t\t\tGEN8_R_PWR_CLK_STATE(RENDER_RING_BASE),\n\t\t\tCTX_R_PWR_CLK_STATE,\n\t\t},\n\t\t{\n\t\t\tGEN8_OACTXCONTROL,\n\t\t\tctx_oactxctrl + 1,\n\t\t},\n\t\t{ EU_PERF_CNTL0, ctx_flexeuN(0) },\n\t\t{ EU_PERF_CNTL1, ctx_flexeuN(1) },\n\t\t{ EU_PERF_CNTL2, ctx_flexeuN(2) },\n\t\t{ EU_PERF_CNTL3, ctx_flexeuN(3) },\n\t\t{ EU_PERF_CNTL4, ctx_flexeuN(4) },\n\t\t{ EU_PERF_CNTL5, ctx_flexeuN(5) },\n\t\t{ EU_PERF_CNTL6, ctx_flexeuN(6) },\n\t};\n#undef ctx_flexeuN\n\tint i;\n\n\tregs[1].value =\n\t\t(stream->period_exponent << GEN8_OA_TIMER_PERIOD_SHIFT) |\n\t\t(stream->periodic ? GEN8_OA_TIMER_ENABLE : 0) |\n\t\tGEN8_OA_COUNTER_RESUME;\n\n\tfor (i = 2; i < ARRAY_SIZE(regs); i++)\n\t\tregs[i].value = oa_config_flex_reg(oa_config, regs[i].reg);\n\n\treturn oa_configure_all_contexts(stream,\n\t\t\t\t\t regs, ARRAY_SIZE(regs),\n\t\t\t\t\t active);\n}\n\nstatic int\ngen8_enable_metric_set(struct i915_perf_stream *stream,\n\t\t       struct i915_active *active)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tstruct i915_oa_config *oa_config = stream->oa_config;\n\tint ret;\n\n\t \n\tif (IS_GRAPHICS_VER(stream->perf->i915, 9, 11)) {\n\t\tintel_uncore_write(uncore, GEN8_OA_DEBUG,\n\t\t\t\t   _MASKED_BIT_ENABLE(GEN9_OA_DEBUG_DISABLE_CLK_RATIO_REPORTS |\n\t\t\t\t\t\t      GEN9_OA_DEBUG_INCLUDE_CLK_RATIO));\n\t}\n\n\t \n\tret = lrc_configure_all_contexts(stream, oa_config, active);\n\tif (ret)\n\t\treturn ret;\n\n\treturn emit_oa_config(stream,\n\t\t\t      stream->oa_config, oa_context(stream),\n\t\t\t      active);\n}\n\nstatic u32 oag_report_ctx_switches(const struct i915_perf_stream *stream)\n{\n\treturn _MASKED_FIELD(GEN12_OAG_OA_DEBUG_DISABLE_CTX_SWITCH_REPORTS,\n\t\t\t     (stream->sample_flags & SAMPLE_OA_REPORT) ?\n\t\t\t     0 : GEN12_OAG_OA_DEBUG_DISABLE_CTX_SWITCH_REPORTS);\n}\n\nstatic int\ngen12_enable_metric_set(struct i915_perf_stream *stream,\n\t\t\tstruct i915_active *active)\n{\n\tstruct drm_i915_private *i915 = stream->perf->i915;\n\tstruct intel_uncore *uncore = stream->uncore;\n\tstruct i915_oa_config *oa_config = stream->oa_config;\n\tbool periodic = stream->periodic;\n\tu32 period_exponent = stream->period_exponent;\n\tu32 sqcnt1;\n\tint ret;\n\n\t \n\tif (IS_XEHPSDV(i915) || IS_DG2(i915)) {\n\t\tintel_gt_mcr_multicast_write(uncore->gt, GEN8_ROW_CHICKEN,\n\t\t\t\t\t     _MASKED_BIT_ENABLE(STALL_DOP_GATING_DISABLE));\n\t\tintel_uncore_write(uncore, GEN7_ROW_CHICKEN2,\n\t\t\t\t   _MASKED_BIT_ENABLE(GEN12_DISABLE_DOP_GATING));\n\t}\n\n\tintel_uncore_write(uncore, __oa_regs(stream)->oa_debug,\n\t\t\t    \n\t\t\t   _MASKED_BIT_ENABLE(GEN12_OAG_OA_DEBUG_DISABLE_CLK_RATIO_REPORTS |\n\t\t\t\t\t      GEN12_OAG_OA_DEBUG_INCLUDE_CLK_RATIO) |\n\t\t\t    \n\t\t\t   oag_report_ctx_switches(stream));\n\n\tintel_uncore_write(uncore, __oa_regs(stream)->oa_ctx_ctrl, periodic ?\n\t\t\t   (GEN12_OAG_OAGLBCTXCTRL_COUNTER_RESUME |\n\t\t\t    GEN12_OAG_OAGLBCTXCTRL_TIMER_ENABLE |\n\t\t\t    (period_exponent << GEN12_OAG_OAGLBCTXCTRL_TIMER_PERIOD_SHIFT))\n\t\t\t    : 0);\n\n\t \n\tsqcnt1 = GEN12_SQCNT1_PMON_ENABLE |\n\t\t (HAS_OA_BPC_REPORTING(i915) ? GEN12_SQCNT1_OABPC : 0);\n\n\tintel_uncore_rmw(uncore, GEN12_SQCNT1, 0, sqcnt1);\n\n\t \n\tret = gen12_configure_all_contexts(stream, oa_config, active);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (stream->ctx) {\n\t\tret = gen12_configure_oar_context(stream, active);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn emit_oa_config(stream,\n\t\t\t      stream->oa_config, oa_context(stream),\n\t\t\t      active);\n}\n\nstatic void gen8_disable_metric_set(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\t \n\tlrc_configure_all_contexts(stream, NULL, NULL);\n\n\tintel_uncore_rmw(uncore, GDT_CHICKEN_BITS, GT_NOA_ENABLE, 0);\n}\n\nstatic void gen11_disable_metric_set(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\t \n\tlrc_configure_all_contexts(stream, NULL, NULL);\n\n\t \n\tintel_uncore_rmw(uncore, RPM_CONFIG1, GEN10_GT_NOA_ENABLE, 0);\n}\n\nstatic void gen12_disable_metric_set(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tstruct drm_i915_private *i915 = stream->perf->i915;\n\tu32 sqcnt1;\n\n\t \n\tif (IS_XEHPSDV(i915) || IS_DG2(i915)) {\n\t\tintel_gt_mcr_multicast_write(uncore->gt, GEN8_ROW_CHICKEN,\n\t\t\t\t\t     _MASKED_BIT_DISABLE(STALL_DOP_GATING_DISABLE));\n\t\tintel_uncore_write(uncore, GEN7_ROW_CHICKEN2,\n\t\t\t\t   _MASKED_BIT_DISABLE(GEN12_DISABLE_DOP_GATING));\n\t}\n\n\t \n\tgen12_configure_all_contexts(stream, NULL, NULL);\n\n\t \n\tif (stream->ctx)\n\t\tgen12_configure_oar_context(stream, NULL);\n\n\t \n\tintel_uncore_rmw(uncore, RPM_CONFIG1, GEN10_GT_NOA_ENABLE, 0);\n\n\tsqcnt1 = GEN12_SQCNT1_PMON_ENABLE |\n\t\t (HAS_OA_BPC_REPORTING(i915) ? GEN12_SQCNT1_OABPC : 0);\n\n\t \n\tintel_uncore_rmw(uncore, GEN12_SQCNT1, sqcnt1, 0);\n}\n\nstatic void gen7_oa_enable(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tstruct i915_gem_context *ctx = stream->ctx;\n\tu32 ctx_id = stream->specific_ctx_id;\n\tbool periodic = stream->periodic;\n\tu32 period_exponent = stream->period_exponent;\n\tu32 report_format = stream->oa_buffer.format->format;\n\n\t \n\tgen7_init_oa_buffer(stream);\n\n\tintel_uncore_write(uncore, GEN7_OACONTROL,\n\t\t\t   (ctx_id & GEN7_OACONTROL_CTX_MASK) |\n\t\t\t   (period_exponent <<\n\t\t\t    GEN7_OACONTROL_TIMER_PERIOD_SHIFT) |\n\t\t\t   (periodic ? GEN7_OACONTROL_TIMER_ENABLE : 0) |\n\t\t\t   (report_format << GEN7_OACONTROL_FORMAT_SHIFT) |\n\t\t\t   (ctx ? GEN7_OACONTROL_PER_CTX_ENABLE : 0) |\n\t\t\t   GEN7_OACONTROL_ENABLE);\n}\n\nstatic void gen8_oa_enable(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\tu32 report_format = stream->oa_buffer.format->format;\n\n\t \n\tgen8_init_oa_buffer(stream);\n\n\t \n\tintel_uncore_write(uncore, GEN8_OACONTROL,\n\t\t\t   (report_format << GEN8_OA_REPORT_FORMAT_SHIFT) |\n\t\t\t   GEN8_OA_COUNTER_ENABLE);\n}\n\nstatic void gen12_oa_enable(struct i915_perf_stream *stream)\n{\n\tconst struct i915_perf_regs *regs;\n\tu32 val;\n\n\t \n\tif (!(stream->sample_flags & SAMPLE_OA_REPORT))\n\t\treturn;\n\n\tgen12_init_oa_buffer(stream);\n\n\tregs = __oa_regs(stream);\n\tval = (stream->oa_buffer.format->format << regs->oa_ctrl_counter_format_shift) |\n\t      GEN12_OAG_OACONTROL_OA_COUNTER_ENABLE;\n\n\tintel_uncore_write(stream->uncore, regs->oa_ctrl, val);\n}\n\n \nstatic void i915_oa_stream_enable(struct i915_perf_stream *stream)\n{\n\tstream->pollin = false;\n\n\tstream->perf->ops.oa_enable(stream);\n\n\tif (stream->sample_flags & SAMPLE_OA_REPORT)\n\t\thrtimer_start(&stream->poll_check_timer,\n\t\t\t      ns_to_ktime(stream->poll_oa_period),\n\t\t\t      HRTIMER_MODE_REL_PINNED);\n}\n\nstatic void gen7_oa_disable(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\tintel_uncore_write(uncore, GEN7_OACONTROL, 0);\n\tif (intel_wait_for_register(uncore,\n\t\t\t\t    GEN7_OACONTROL, GEN7_OACONTROL_ENABLE, 0,\n\t\t\t\t    50))\n\t\tdrm_err(&stream->perf->i915->drm,\n\t\t\t\"wait for OA to be disabled timed out\\n\");\n}\n\nstatic void gen8_oa_disable(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\tintel_uncore_write(uncore, GEN8_OACONTROL, 0);\n\tif (intel_wait_for_register(uncore,\n\t\t\t\t    GEN8_OACONTROL, GEN8_OA_COUNTER_ENABLE, 0,\n\t\t\t\t    50))\n\t\tdrm_err(&stream->perf->i915->drm,\n\t\t\t\"wait for OA to be disabled timed out\\n\");\n}\n\nstatic void gen12_oa_disable(struct i915_perf_stream *stream)\n{\n\tstruct intel_uncore *uncore = stream->uncore;\n\n\tintel_uncore_write(uncore, __oa_regs(stream)->oa_ctrl, 0);\n\tif (intel_wait_for_register(uncore,\n\t\t\t\t    __oa_regs(stream)->oa_ctrl,\n\t\t\t\t    GEN12_OAG_OACONTROL_OA_COUNTER_ENABLE, 0,\n\t\t\t\t    50))\n\t\tdrm_err(&stream->perf->i915->drm,\n\t\t\t\"wait for OA to be disabled timed out\\n\");\n\n\tintel_uncore_write(uncore, GEN12_OA_TLB_INV_CR, 1);\n\tif (intel_wait_for_register(uncore,\n\t\t\t\t    GEN12_OA_TLB_INV_CR,\n\t\t\t\t    1, 0,\n\t\t\t\t    50))\n\t\tdrm_err(&stream->perf->i915->drm,\n\t\t\t\"wait for OA tlb invalidate timed out\\n\");\n}\n\n \nstatic void i915_oa_stream_disable(struct i915_perf_stream *stream)\n{\n\tstream->perf->ops.oa_disable(stream);\n\n\tif (stream->sample_flags & SAMPLE_OA_REPORT)\n\t\thrtimer_cancel(&stream->poll_check_timer);\n}\n\nstatic const struct i915_perf_stream_ops i915_oa_stream_ops = {\n\t.destroy = i915_oa_stream_destroy,\n\t.enable = i915_oa_stream_enable,\n\t.disable = i915_oa_stream_disable,\n\t.wait_unlocked = i915_oa_wait_unlocked,\n\t.poll_wait = i915_oa_poll_wait,\n\t.read = i915_oa_read,\n};\n\nstatic int i915_perf_stream_enable_sync(struct i915_perf_stream *stream)\n{\n\tstruct i915_active *active;\n\tint err;\n\n\tactive = i915_active_create();\n\tif (!active)\n\t\treturn -ENOMEM;\n\n\terr = stream->perf->ops.enable_metric_set(stream, active);\n\tif (err == 0)\n\t\t__i915_active_wait(active, TASK_UNINTERRUPTIBLE);\n\n\ti915_active_put(active);\n\treturn err;\n}\n\nstatic void\nget_default_sseu_config(struct intel_sseu *out_sseu,\n\t\t\tstruct intel_engine_cs *engine)\n{\n\tconst struct sseu_dev_info *devinfo_sseu = &engine->gt->info.sseu;\n\n\t*out_sseu = intel_sseu_from_device_info(devinfo_sseu);\n\n\tif (GRAPHICS_VER(engine->i915) == 11) {\n\t\t \n\t\tout_sseu->subslice_mask =\n\t\t\t~(~0 << (hweight8(out_sseu->subslice_mask) / 2));\n\t\tout_sseu->slice_mask = 0x1;\n\t}\n}\n\nstatic int\nget_sseu_config(struct intel_sseu *out_sseu,\n\t\tstruct intel_engine_cs *engine,\n\t\tconst struct drm_i915_gem_context_param_sseu *drm_sseu)\n{\n\tif (drm_sseu->engine.engine_class != engine->uabi_class ||\n\t    drm_sseu->engine.engine_instance != engine->uabi_instance)\n\t\treturn -EINVAL;\n\n\treturn i915_gem_user_to_context_sseu(engine->gt, drm_sseu, out_sseu);\n}\n\n \nu32 i915_perf_oa_timestamp_frequency(struct drm_i915_private *i915)\n{\n\t \n\tif (IS_DG2(i915) || IS_METEORLAKE(i915)) {\n\t\tintel_wakeref_t wakeref;\n\t\tu32 reg, shift;\n\n\t\twith_intel_runtime_pm(to_gt(i915)->uncore->rpm, wakeref)\n\t\t\treg = intel_uncore_read(to_gt(i915)->uncore, RPM_CONFIG0);\n\n\t\tshift = REG_FIELD_GET(GEN10_RPM_CONFIG0_CTC_SHIFT_PARAMETER_MASK,\n\t\t\t\t      reg);\n\n\t\treturn to_gt(i915)->clock_frequency << (3 - shift);\n\t}\n\n\treturn to_gt(i915)->clock_frequency;\n}\n\n \nstatic int i915_oa_stream_init(struct i915_perf_stream *stream,\n\t\t\t       struct drm_i915_perf_open_param *param,\n\t\t\t       struct perf_open_properties *props)\n{\n\tstruct drm_i915_private *i915 = stream->perf->i915;\n\tstruct i915_perf *perf = stream->perf;\n\tstruct i915_perf_group *g;\n\tstruct intel_gt *gt;\n\tint ret;\n\n\tif (!props->engine) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"OA engine not specified\\n\");\n\t\treturn -EINVAL;\n\t}\n\tgt = props->engine->gt;\n\tg = props->engine->oa_group;\n\n\t \n\tif (!perf->metrics_kobj) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"OA metrics weren't advertised via sysfs\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!(props->sample_flags & SAMPLE_OA_REPORT) &&\n\t    (GRAPHICS_VER(perf->i915) < 12 || !stream->ctx)) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"Only OA report sampling supported\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!perf->ops.enable_metric_set) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"OA unit not supported\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\t \n\tif (g->exclusive_stream) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"OA unit already in use\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\tif (!props->oa_format) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"OA report format not specified\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tstream->engine = props->engine;\n\tstream->uncore = stream->engine->gt->uncore;\n\n\tstream->sample_size = sizeof(struct drm_i915_perf_record_header);\n\n\tstream->oa_buffer.format = &perf->oa_formats[props->oa_format];\n\tif (drm_WARN_ON(&i915->drm, stream->oa_buffer.format->size == 0))\n\t\treturn -EINVAL;\n\n\tstream->sample_flags = props->sample_flags;\n\tstream->sample_size += stream->oa_buffer.format->size;\n\n\tstream->hold_preemption = props->hold_preemption;\n\n\tstream->periodic = props->oa_periodic;\n\tif (stream->periodic)\n\t\tstream->period_exponent = props->oa_period_exponent;\n\n\tif (stream->ctx) {\n\t\tret = oa_get_render_ctx_id(stream);\n\t\tif (ret) {\n\t\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\t\"Invalid context id to filter with\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = alloc_noa_wait(stream);\n\tif (ret) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"Unable to allocate NOA wait batch buffer\\n\");\n\t\tgoto err_noa_wait_alloc;\n\t}\n\n\tstream->oa_config = i915_perf_get_oa_config(perf, props->metrics_set);\n\tif (!stream->oa_config) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"Invalid OA config id=%i\\n\", props->metrics_set);\n\t\tret = -EINVAL;\n\t\tgoto err_config;\n\t}\n\n\t \n\tintel_engine_pm_get(stream->engine);\n\tintel_uncore_forcewake_get(stream->uncore, FORCEWAKE_ALL);\n\n\t \n\tif (intel_uc_uses_guc_rc(&gt->uc) &&\n\t    (IS_DG2_GRAPHICS_STEP(gt->i915, G10, STEP_A0, STEP_C0) ||\n\t     IS_DG2_GRAPHICS_STEP(gt->i915, G11, STEP_A0, STEP_B0))) {\n\t\tret = intel_guc_slpc_override_gucrc_mode(&gt->uc.guc.slpc,\n\t\t\t\t\t\t\t SLPC_GUCRC_MODE_GUCRC_NO_RC6);\n\t\tif (ret) {\n\t\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\t\"Unable to override gucrc mode\\n\");\n\t\t\tgoto err_gucrc;\n\t\t}\n\n\t\tstream->override_gucrc = true;\n\t}\n\n\tret = alloc_oa_buffer(stream);\n\tif (ret)\n\t\tgoto err_oa_buf_alloc;\n\n\tstream->ops = &i915_oa_stream_ops;\n\n\tstream->engine->gt->perf.sseu = props->sseu;\n\tWRITE_ONCE(g->exclusive_stream, stream);\n\n\tret = i915_perf_stream_enable_sync(stream);\n\tif (ret) {\n\t\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\t\"Unable to enable metric set\\n\");\n\t\tgoto err_enable;\n\t}\n\n\tdrm_dbg(&stream->perf->i915->drm,\n\t\t\"opening stream oa config uuid=%s\\n\",\n\t\t  stream->oa_config->uuid);\n\n\thrtimer_init(&stream->poll_check_timer,\n\t\t     CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tstream->poll_check_timer.function = oa_poll_check_timer_cb;\n\tinit_waitqueue_head(&stream->poll_wq);\n\tspin_lock_init(&stream->oa_buffer.ptr_lock);\n\tmutex_init(&stream->lock);\n\n\treturn 0;\n\nerr_enable:\n\tWRITE_ONCE(g->exclusive_stream, NULL);\n\tperf->ops.disable_metric_set(stream);\n\n\tfree_oa_buffer(stream);\n\nerr_oa_buf_alloc:\n\tif (stream->override_gucrc)\n\t\tintel_guc_slpc_unset_gucrc_mode(&gt->uc.guc.slpc);\n\nerr_gucrc:\n\tintel_uncore_forcewake_put(stream->uncore, FORCEWAKE_ALL);\n\tintel_engine_pm_put(stream->engine);\n\n\tfree_oa_configs(stream);\n\nerr_config:\n\tfree_noa_wait(stream);\n\nerr_noa_wait_alloc:\n\tif (stream->ctx)\n\t\toa_put_render_ctx_id(stream);\n\n\treturn ret;\n}\n\nvoid i915_oa_init_reg_state(const struct intel_context *ce,\n\t\t\t    const struct intel_engine_cs *engine)\n{\n\tstruct i915_perf_stream *stream;\n\n\tif (engine->class != RENDER_CLASS)\n\t\treturn;\n\n\t \n\tstream = READ_ONCE(engine->oa_group->exclusive_stream);\n\tif (stream && GRAPHICS_VER(stream->perf->i915) < 12)\n\t\tgen8_update_reg_state_unlocked(ce, stream);\n}\n\n \nstatic ssize_t i915_perf_read(struct file *file,\n\t\t\t      char __user *buf,\n\t\t\t      size_t count,\n\t\t\t      loff_t *ppos)\n{\n\tstruct i915_perf_stream *stream = file->private_data;\n\tsize_t offset = 0;\n\tint ret;\n\n\t \n\tif (!stream->enabled || !(stream->sample_flags & SAMPLE_OA_REPORT))\n\t\treturn -EIO;\n\n\tif (!(file->f_flags & O_NONBLOCK)) {\n\t\t \n\t\tdo {\n\t\t\tret = stream->ops->wait_unlocked(stream);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tmutex_lock(&stream->lock);\n\t\t\tret = stream->ops->read(stream, buf, count, &offset);\n\t\t\tmutex_unlock(&stream->lock);\n\t\t} while (!offset && !ret);\n\t} else {\n\t\tmutex_lock(&stream->lock);\n\t\tret = stream->ops->read(stream, buf, count, &offset);\n\t\tmutex_unlock(&stream->lock);\n\t}\n\n\t \n\tif (ret != -ENOSPC)\n\t\tstream->pollin = false;\n\n\t \n\treturn offset ?: (ret ?: -EAGAIN);\n}\n\nstatic enum hrtimer_restart oa_poll_check_timer_cb(struct hrtimer *hrtimer)\n{\n\tstruct i915_perf_stream *stream =\n\t\tcontainer_of(hrtimer, typeof(*stream), poll_check_timer);\n\n\tif (oa_buffer_check_unlocked(stream)) {\n\t\tstream->pollin = true;\n\t\twake_up(&stream->poll_wq);\n\t}\n\n\thrtimer_forward_now(hrtimer,\n\t\t\t    ns_to_ktime(stream->poll_oa_period));\n\n\treturn HRTIMER_RESTART;\n}\n\n \nstatic __poll_t i915_perf_poll_locked(struct i915_perf_stream *stream,\n\t\t\t\t      struct file *file,\n\t\t\t\t      poll_table *wait)\n{\n\t__poll_t events = 0;\n\n\tstream->ops->poll_wait(stream, file, wait);\n\n\t \n\tif (stream->pollin)\n\t\tevents |= EPOLLIN;\n\n\treturn events;\n}\n\n \nstatic __poll_t i915_perf_poll(struct file *file, poll_table *wait)\n{\n\tstruct i915_perf_stream *stream = file->private_data;\n\t__poll_t ret;\n\n\tmutex_lock(&stream->lock);\n\tret = i915_perf_poll_locked(stream, file, wait);\n\tmutex_unlock(&stream->lock);\n\n\treturn ret;\n}\n\n \nstatic void i915_perf_enable_locked(struct i915_perf_stream *stream)\n{\n\tif (stream->enabled)\n\t\treturn;\n\n\t \n\tstream->enabled = true;\n\n\tif (stream->ops->enable)\n\t\tstream->ops->enable(stream);\n\n\tif (stream->hold_preemption)\n\t\tintel_context_set_nopreempt(stream->pinned_ctx);\n}\n\n \nstatic void i915_perf_disable_locked(struct i915_perf_stream *stream)\n{\n\tif (!stream->enabled)\n\t\treturn;\n\n\t \n\tstream->enabled = false;\n\n\tif (stream->hold_preemption)\n\t\tintel_context_clear_nopreempt(stream->pinned_ctx);\n\n\tif (stream->ops->disable)\n\t\tstream->ops->disable(stream);\n}\n\nstatic long i915_perf_config_locked(struct i915_perf_stream *stream,\n\t\t\t\t    unsigned long metrics_set)\n{\n\tstruct i915_oa_config *config;\n\tlong ret = stream->oa_config->id;\n\n\tconfig = i915_perf_get_oa_config(stream->perf, metrics_set);\n\tif (!config)\n\t\treturn -EINVAL;\n\n\tif (config != stream->oa_config) {\n\t\tint err;\n\n\t\t \n\t\terr = emit_oa_config(stream, config, oa_context(stream), NULL);\n\t\tif (!err)\n\t\t\tconfig = xchg(&stream->oa_config, config);\n\t\telse\n\t\t\tret = err;\n\t}\n\n\ti915_oa_config_put(config);\n\n\treturn ret;\n}\n\n \nstatic long i915_perf_ioctl_locked(struct i915_perf_stream *stream,\n\t\t\t\t   unsigned int cmd,\n\t\t\t\t   unsigned long arg)\n{\n\tswitch (cmd) {\n\tcase I915_PERF_IOCTL_ENABLE:\n\t\ti915_perf_enable_locked(stream);\n\t\treturn 0;\n\tcase I915_PERF_IOCTL_DISABLE:\n\t\ti915_perf_disable_locked(stream);\n\t\treturn 0;\n\tcase I915_PERF_IOCTL_CONFIG:\n\t\treturn i915_perf_config_locked(stream, arg);\n\t}\n\n\treturn -EINVAL;\n}\n\n \nstatic long i915_perf_ioctl(struct file *file,\n\t\t\t    unsigned int cmd,\n\t\t\t    unsigned long arg)\n{\n\tstruct i915_perf_stream *stream = file->private_data;\n\tlong ret;\n\n\tmutex_lock(&stream->lock);\n\tret = i915_perf_ioctl_locked(stream, cmd, arg);\n\tmutex_unlock(&stream->lock);\n\n\treturn ret;\n}\n\n \nstatic void i915_perf_destroy_locked(struct i915_perf_stream *stream)\n{\n\tif (stream->enabled)\n\t\ti915_perf_disable_locked(stream);\n\n\tif (stream->ops->destroy)\n\t\tstream->ops->destroy(stream);\n\n\tif (stream->ctx)\n\t\ti915_gem_context_put(stream->ctx);\n\n\tkfree(stream);\n}\n\n \nstatic int i915_perf_release(struct inode *inode, struct file *file)\n{\n\tstruct i915_perf_stream *stream = file->private_data;\n\tstruct i915_perf *perf = stream->perf;\n\tstruct intel_gt *gt = stream->engine->gt;\n\n\t \n\tmutex_lock(&gt->perf.lock);\n\ti915_perf_destroy_locked(stream);\n\tmutex_unlock(&gt->perf.lock);\n\n\t \n\tdrm_dev_put(&perf->i915->drm);\n\n\treturn 0;\n}\n\n\nstatic const struct file_operations fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.llseek\t\t= no_llseek,\n\t.release\t= i915_perf_release,\n\t.poll\t\t= i915_perf_poll,\n\t.read\t\t= i915_perf_read,\n\t.unlocked_ioctl\t= i915_perf_ioctl,\n\t \n\t.compat_ioctl   = i915_perf_ioctl,\n};\n\n\n \nstatic int\ni915_perf_open_ioctl_locked(struct i915_perf *perf,\n\t\t\t    struct drm_i915_perf_open_param *param,\n\t\t\t    struct perf_open_properties *props,\n\t\t\t    struct drm_file *file)\n{\n\tstruct i915_gem_context *specific_ctx = NULL;\n\tstruct i915_perf_stream *stream = NULL;\n\tunsigned long f_flags = 0;\n\tbool privileged_op = true;\n\tint stream_fd;\n\tint ret;\n\n\tif (props->single_context) {\n\t\tu32 ctx_handle = props->ctx_handle;\n\t\tstruct drm_i915_file_private *file_priv = file->driver_priv;\n\n\t\tspecific_ctx = i915_gem_context_lookup(file_priv, ctx_handle);\n\t\tif (IS_ERR(specific_ctx)) {\n\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\"Failed to look up context with ID %u for opening perf stream\\n\",\n\t\t\t\t  ctx_handle);\n\t\t\tret = PTR_ERR(specific_ctx);\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\t \n\tif (IS_HASWELL(perf->i915) && specific_ctx)\n\t\tprivileged_op = false;\n\telse if (GRAPHICS_VER(perf->i915) == 12 && specific_ctx &&\n\t\t (props->sample_flags & SAMPLE_OA_REPORT) == 0)\n\t\tprivileged_op = false;\n\n\tif (props->hold_preemption) {\n\t\tif (!props->single_context) {\n\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\"preemption disable with no context\\n\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\t\tprivileged_op = true;\n\t}\n\n\t \n\tif (props->has_sseu)\n\t\tprivileged_op = true;\n\telse\n\t\tget_default_sseu_config(&props->sseu, props->engine);\n\n\t \n\tif (privileged_op &&\n\t    i915_perf_stream_paranoid && !perfmon_capable()) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Insufficient privileges to open i915 perf stream\\n\");\n\t\tret = -EACCES;\n\t\tgoto err_ctx;\n\t}\n\n\tstream = kzalloc(sizeof(*stream), GFP_KERNEL);\n\tif (!stream) {\n\t\tret = -ENOMEM;\n\t\tgoto err_ctx;\n\t}\n\n\tstream->perf = perf;\n\tstream->ctx = specific_ctx;\n\tstream->poll_oa_period = props->poll_oa_period;\n\n\tret = i915_oa_stream_init(stream, param, props);\n\tif (ret)\n\t\tgoto err_alloc;\n\n\t \n\tif (WARN_ON(stream->sample_flags != props->sample_flags)) {\n\t\tret = -ENODEV;\n\t\tgoto err_flags;\n\t}\n\n\tif (param->flags & I915_PERF_FLAG_FD_CLOEXEC)\n\t\tf_flags |= O_CLOEXEC;\n\tif (param->flags & I915_PERF_FLAG_FD_NONBLOCK)\n\t\tf_flags |= O_NONBLOCK;\n\n\tstream_fd = anon_inode_getfd(\"[i915_perf]\", &fops, stream, f_flags);\n\tif (stream_fd < 0) {\n\t\tret = stream_fd;\n\t\tgoto err_flags;\n\t}\n\n\tif (!(param->flags & I915_PERF_FLAG_DISABLED))\n\t\ti915_perf_enable_locked(stream);\n\n\t \n\tdrm_dev_get(&perf->i915->drm);\n\n\treturn stream_fd;\n\nerr_flags:\n\tif (stream->ops->destroy)\n\t\tstream->ops->destroy(stream);\nerr_alloc:\n\tkfree(stream);\nerr_ctx:\n\tif (specific_ctx)\n\t\ti915_gem_context_put(specific_ctx);\nerr:\n\treturn ret;\n}\n\nstatic u64 oa_exponent_to_ns(struct i915_perf *perf, int exponent)\n{\n\tu64 nom = (2ULL << exponent) * NSEC_PER_SEC;\n\tu32 den = i915_perf_oa_timestamp_frequency(perf->i915);\n\n\treturn div_u64(nom + den - 1, den);\n}\n\nstatic __always_inline bool\noa_format_valid(struct i915_perf *perf, enum drm_i915_oa_format format)\n{\n\treturn test_bit(format, perf->format_mask);\n}\n\nstatic __always_inline void\noa_format_add(struct i915_perf *perf, enum drm_i915_oa_format format)\n{\n\t__set_bit(format, perf->format_mask);\n}\n\n \nstatic int read_properties_unlocked(struct i915_perf *perf,\n\t\t\t\t    u64 __user *uprops,\n\t\t\t\t    u32 n_props,\n\t\t\t\t    struct perf_open_properties *props)\n{\n\tstruct drm_i915_gem_context_param_sseu user_sseu;\n\tconst struct i915_oa_format *f;\n\tu64 __user *uprop = uprops;\n\tbool config_instance = false;\n\tbool config_class = false;\n\tbool config_sseu = false;\n\tu8 class, instance;\n\tu32 i;\n\tint ret;\n\n\tmemset(props, 0, sizeof(struct perf_open_properties));\n\tprops->poll_oa_period = DEFAULT_POLL_PERIOD_NS;\n\n\t \n\tif (!n_props || n_props >= DRM_I915_PERF_PROP_MAX) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Invalid number of i915 perf properties given\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tclass = I915_ENGINE_CLASS_RENDER;\n\tinstance = 0;\n\n\tfor (i = 0; i < n_props; i++) {\n\t\tu64 oa_period, oa_freq_hz;\n\t\tu64 id, value;\n\n\t\tret = get_user(id, uprop);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = get_user(value, uprop + 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (id == 0 || id >= DRM_I915_PERF_PROP_MAX) {\n\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\"Unknown i915 perf property ID\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tswitch ((enum drm_i915_perf_property_id)id) {\n\t\tcase DRM_I915_PERF_PROP_CTX_HANDLE:\n\t\t\tprops->single_context = 1;\n\t\t\tprops->ctx_handle = value;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_SAMPLE_OA:\n\t\t\tif (value)\n\t\t\t\tprops->sample_flags |= SAMPLE_OA_REPORT;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_OA_METRICS_SET:\n\t\t\tif (value == 0) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"Unknown OA metric set ID\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tprops->metrics_set = value;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_OA_FORMAT:\n\t\t\tif (value == 0 || value >= I915_OA_FORMAT_MAX) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"Out-of-range OA report format %llu\\n\",\n\t\t\t\t\t  value);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tif (!oa_format_valid(perf, value)) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"Unsupported OA report format %llu\\n\",\n\t\t\t\t\t  value);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tprops->oa_format = value;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_OA_EXPONENT:\n\t\t\tif (value > OA_EXPONENT_MAX) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"OA timer exponent too high (> %u)\\n\",\n\t\t\t\t\t OA_EXPONENT_MAX);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t \n\n\t\t\tBUILD_BUG_ON(sizeof(oa_period) != 8);\n\t\t\toa_period = oa_exponent_to_ns(perf, value);\n\n\t\t\t \n\t\t\tif (oa_period <= NSEC_PER_SEC) {\n\t\t\t\tu64 tmp = NSEC_PER_SEC;\n\t\t\t\tdo_div(tmp, oa_period);\n\t\t\t\toa_freq_hz = tmp;\n\t\t\t} else\n\t\t\t\toa_freq_hz = 0;\n\n\t\t\tif (oa_freq_hz > i915_oa_max_sample_rate && !perfmon_capable()) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"OA exponent would exceed the max sampling frequency (sysctl dev.i915.oa_max_sample_rate) %uHz without CAP_PERFMON or CAP_SYS_ADMIN privileges\\n\",\n\t\t\t\t\t  i915_oa_max_sample_rate);\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\n\t\t\tprops->oa_periodic = true;\n\t\t\tprops->oa_period_exponent = value;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_HOLD_PREEMPTION:\n\t\t\tprops->hold_preemption = !!value;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_GLOBAL_SSEU: {\n\t\t\tif (GRAPHICS_VER_FULL(perf->i915) >= IP_VER(12, 50)) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"SSEU config not supported on gfx %x\\n\",\n\t\t\t\t\tGRAPHICS_VER_FULL(perf->i915));\n\t\t\t\treturn -ENODEV;\n\t\t\t}\n\n\t\t\tif (copy_from_user(&user_sseu,\n\t\t\t\t\t   u64_to_user_ptr(value),\n\t\t\t\t\t   sizeof(user_sseu))) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"Unable to copy global sseu parameter\\n\");\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t\tconfig_sseu = true;\n\t\t\tbreak;\n\t\t}\n\t\tcase DRM_I915_PERF_PROP_POLL_OA_PERIOD:\n\t\t\tif (value < 100000  ) {\n\t\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\t\"OA availability timer too small (%lluns < 100us)\\n\",\n\t\t\t\t\t  value);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tprops->poll_oa_period = value;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_OA_ENGINE_CLASS:\n\t\t\tclass = (u8)value;\n\t\t\tconfig_class = true;\n\t\t\tbreak;\n\t\tcase DRM_I915_PERF_PROP_OA_ENGINE_INSTANCE:\n\t\t\tinstance = (u8)value;\n\t\t\tconfig_instance = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tMISSING_CASE(id);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tuprop += 2;\n\t}\n\n\tif ((config_class && !config_instance) ||\n\t    (config_instance && !config_class)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"OA engine-class and engine-instance parameters must be passed together\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tprops->engine = intel_engine_lookup_user(perf->i915, class, instance);\n\tif (!props->engine) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"OA engine class and instance invalid %d:%d\\n\",\n\t\t\tclass, instance);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!engine_supports_oa(props->engine)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Engine not supported by OA %d:%d\\n\",\n\t\t\tclass, instance);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (IS_MTL_MEDIA_STEP(props->engine->i915, STEP_A0, STEP_C0) &&\n\t    props->engine->oa_group->type == TYPE_OAM &&\n\t    intel_check_bios_c6_setup(&props->engine->gt->rc6)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"OAM requires media C6 to be disabled in BIOS\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ti = array_index_nospec(props->oa_format, I915_OA_FORMAT_MAX);\n\tf = &perf->oa_formats[i];\n\tif (!engine_supports_oa_format(props->engine, f->type)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Invalid OA format %d for class %d\\n\",\n\t\t\tf->type, props->engine->class);\n\t\treturn -EINVAL;\n\t}\n\n\tif (config_sseu) {\n\t\tret = get_sseu_config(&props->sseu, props->engine, &user_sseu);\n\t\tif (ret) {\n\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\"Invalid SSEU configuration\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tprops->has_sseu = true;\n\t}\n\n\treturn 0;\n}\n\n \nint i915_perf_open_ioctl(struct drm_device *dev, void *data,\n\t\t\t struct drm_file *file)\n{\n\tstruct i915_perf *perf = &to_i915(dev)->perf;\n\tstruct drm_i915_perf_open_param *param = data;\n\tstruct intel_gt *gt;\n\tstruct perf_open_properties props;\n\tu32 known_open_flags;\n\tint ret;\n\n\tif (!perf->i915)\n\t\treturn -ENOTSUPP;\n\n\tknown_open_flags = I915_PERF_FLAG_FD_CLOEXEC |\n\t\t\t   I915_PERF_FLAG_FD_NONBLOCK |\n\t\t\t   I915_PERF_FLAG_DISABLED;\n\tif (param->flags & ~known_open_flags) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Unknown drm_i915_perf_open_param flag\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = read_properties_unlocked(perf,\n\t\t\t\t       u64_to_user_ptr(param->properties_ptr),\n\t\t\t\t       param->num_properties,\n\t\t\t\t       &props);\n\tif (ret)\n\t\treturn ret;\n\n\tgt = props.engine->gt;\n\n\tmutex_lock(&gt->perf.lock);\n\tret = i915_perf_open_ioctl_locked(perf, param, &props, file);\n\tmutex_unlock(&gt->perf.lock);\n\n\treturn ret;\n}\n\n \nvoid i915_perf_register(struct drm_i915_private *i915)\n{\n\tstruct i915_perf *perf = &i915->perf;\n\tstruct intel_gt *gt = to_gt(i915);\n\n\tif (!perf->i915)\n\t\treturn;\n\n\t \n\tmutex_lock(&gt->perf.lock);\n\n\tperf->metrics_kobj =\n\t\tkobject_create_and_add(\"metrics\",\n\t\t\t\t       &i915->drm.primary->kdev->kobj);\n\n\tmutex_unlock(&gt->perf.lock);\n}\n\n \nvoid i915_perf_unregister(struct drm_i915_private *i915)\n{\n\tstruct i915_perf *perf = &i915->perf;\n\n\tif (!perf->metrics_kobj)\n\t\treturn;\n\n\tkobject_put(perf->metrics_kobj);\n\tperf->metrics_kobj = NULL;\n}\n\nstatic bool gen8_is_valid_flex_addr(struct i915_perf *perf, u32 addr)\n{\n\tstatic const i915_reg_t flex_eu_regs[] = {\n\t\tEU_PERF_CNTL0,\n\t\tEU_PERF_CNTL1,\n\t\tEU_PERF_CNTL2,\n\t\tEU_PERF_CNTL3,\n\t\tEU_PERF_CNTL4,\n\t\tEU_PERF_CNTL5,\n\t\tEU_PERF_CNTL6,\n\t};\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(flex_eu_regs); i++) {\n\t\tif (i915_mmio_reg_offset(flex_eu_regs[i]) == addr)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic bool reg_in_range_table(u32 addr, const struct i915_range *table)\n{\n\twhile (table->start || table->end) {\n\t\tif (addr >= table->start && addr <= table->end)\n\t\t\treturn true;\n\n\t\ttable++;\n\t}\n\n\treturn false;\n}\n\n#define REG_EQUAL(addr, mmio) \\\n\t((addr) == i915_mmio_reg_offset(mmio))\n\nstatic const struct i915_range gen7_oa_b_counters[] = {\n\t{ .start = 0x2710, .end = 0x272c },\t \n\t{ .start = 0x2740, .end = 0x275c },\t \n\t{ .start = 0x2770, .end = 0x27ac },\t \n\t{}\n};\n\nstatic const struct i915_range gen12_oa_b_counters[] = {\n\t{ .start = 0x2b2c, .end = 0x2b2c },\t \n\t{ .start = 0xd900, .end = 0xd91c },\t \n\t{ .start = 0xd920, .end = 0xd93c },\t \n\t{ .start = 0xd940, .end = 0xd97c },\t \n\t{ .start = 0xdc00, .end = 0xdc3c },\t \n\t{ .start = 0xdc40, .end = 0xdc40 },\t \n\t{ .start = 0xdc44, .end = 0xdc44 },\t \n\t{}\n};\n\nstatic const struct i915_range mtl_oam_b_counters[] = {\n\t{ .start = 0x393000, .end = 0x39301c },\t \n\t{ .start = 0x393020, .end = 0x39303c },\t \n\t{ .start = 0x393040, .end = 0x39307c },\t \n\t{ .start = 0x393200, .end = 0x39323C },\t \n\t{}\n};\n\nstatic const struct i915_range xehp_oa_b_counters[] = {\n\t{ .start = 0xdc48, .end = 0xdc48 },\t \n\t{ .start = 0xdd00, .end = 0xdd48 },\t \n\t{}\n};\n\nstatic const struct i915_range gen7_oa_mux_regs[] = {\n\t{ .start = 0x91b8, .end = 0x91cc },\t \n\t{ .start = 0x9800, .end = 0x9888 },\t \n\t{ .start = 0xe180, .end = 0xe180 },\t \n\t{}\n};\n\nstatic const struct i915_range hsw_oa_mux_regs[] = {\n\t{ .start = 0x09e80, .end = 0x09ea4 },  \n\t{ .start = 0x09ec0, .end = 0x09ec0 },  \n\t{ .start = 0x25100, .end = 0x2ff90 },\n\t{}\n};\n\nstatic const struct i915_range chv_oa_mux_regs[] = {\n\t{ .start = 0x182300, .end = 0x1823a4 },\n\t{}\n};\n\nstatic const struct i915_range gen8_oa_mux_regs[] = {\n\t{ .start = 0x0d00, .end = 0x0d2c },\t \n\t{ .start = 0x20cc, .end = 0x20cc },\t \n\t{}\n};\n\nstatic const struct i915_range gen11_oa_mux_regs[] = {\n\t{ .start = 0x91c8, .end = 0x91dc },\t \n\t{}\n};\n\nstatic const struct i915_range gen12_oa_mux_regs[] = {\n\t{ .start = 0x0d00, .end = 0x0d04 },      \n\t{ .start = 0x0d0c, .end = 0x0d2c },      \n\t{ .start = 0x9840, .end = 0x9840 },\t \n\t{ .start = 0x9884, .end = 0x9888 },\t \n\t{ .start = 0x20cc, .end = 0x20cc },\t \n\t{}\n};\n\n \nstatic const struct i915_range mtl_oa_mux_regs[] = {\n\t{ .start = 0x0d00, .end = 0x0d04 },\t \n\t{ .start = 0x0d0c, .end = 0x0d2c },\t \n\t{ .start = 0x9840, .end = 0x9840 },\t \n\t{ .start = 0x9884, .end = 0x9888 },\t \n\t{ .start = 0x38d100, .end = 0x38d114},\t \n\t{}\n};\n\nstatic bool gen7_is_valid_b_counter_addr(struct i915_perf *perf, u32 addr)\n{\n\treturn reg_in_range_table(addr, gen7_oa_b_counters);\n}\n\nstatic bool gen8_is_valid_mux_addr(struct i915_perf *perf, u32 addr)\n{\n\treturn reg_in_range_table(addr, gen7_oa_mux_regs) ||\n\t\treg_in_range_table(addr, gen8_oa_mux_regs);\n}\n\nstatic bool gen11_is_valid_mux_addr(struct i915_perf *perf, u32 addr)\n{\n\treturn reg_in_range_table(addr, gen7_oa_mux_regs) ||\n\t\treg_in_range_table(addr, gen8_oa_mux_regs) ||\n\t\treg_in_range_table(addr, gen11_oa_mux_regs);\n}\n\nstatic bool hsw_is_valid_mux_addr(struct i915_perf *perf, u32 addr)\n{\n\treturn reg_in_range_table(addr, gen7_oa_mux_regs) ||\n\t\treg_in_range_table(addr, hsw_oa_mux_regs);\n}\n\nstatic bool chv_is_valid_mux_addr(struct i915_perf *perf, u32 addr)\n{\n\treturn reg_in_range_table(addr, gen7_oa_mux_regs) ||\n\t\treg_in_range_table(addr, chv_oa_mux_regs);\n}\n\nstatic bool gen12_is_valid_b_counter_addr(struct i915_perf *perf, u32 addr)\n{\n\treturn reg_in_range_table(addr, gen12_oa_b_counters);\n}\n\nstatic bool mtl_is_valid_oam_b_counter_addr(struct i915_perf *perf, u32 addr)\n{\n\tif (HAS_OAM(perf->i915) &&\n\t    GRAPHICS_VER_FULL(perf->i915) >= IP_VER(12, 70))\n\t\treturn reg_in_range_table(addr, mtl_oam_b_counters);\n\n\treturn false;\n}\n\nstatic bool xehp_is_valid_b_counter_addr(struct i915_perf *perf, u32 addr)\n{\n\treturn reg_in_range_table(addr, xehp_oa_b_counters) ||\n\t\treg_in_range_table(addr, gen12_oa_b_counters) ||\n\t\tmtl_is_valid_oam_b_counter_addr(perf, addr);\n}\n\nstatic bool gen12_is_valid_mux_addr(struct i915_perf *perf, u32 addr)\n{\n\tif (IS_METEORLAKE(perf->i915))\n\t\treturn reg_in_range_table(addr, mtl_oa_mux_regs);\n\telse\n\t\treturn reg_in_range_table(addr, gen12_oa_mux_regs);\n}\n\nstatic u32 mask_reg_value(u32 reg, u32 val)\n{\n\t \n\tif (REG_EQUAL(reg, HALF_SLICE_CHICKEN2))\n\t\tval = val & ~_MASKED_BIT_ENABLE(GEN8_ST_PO_DISABLE);\n\n\t \n\tif (REG_EQUAL(reg, WAIT_FOR_RC6_EXIT))\n\t\tval = val & ~_MASKED_BIT_ENABLE(HSW_WAIT_FOR_RC6_EXIT_ENABLE);\n\n\treturn val;\n}\n\nstatic struct i915_oa_reg *alloc_oa_regs(struct i915_perf *perf,\n\t\t\t\t\t bool (*is_valid)(struct i915_perf *perf, u32 addr),\n\t\t\t\t\t u32 __user *regs,\n\t\t\t\t\t u32 n_regs)\n{\n\tstruct i915_oa_reg *oa_regs;\n\tint err;\n\tu32 i;\n\n\tif (!n_regs)\n\t\treturn NULL;\n\n\t \n\tGEM_BUG_ON(!is_valid);\n\tif (!is_valid)\n\t\treturn ERR_PTR(-EINVAL);\n\n\toa_regs = kmalloc_array(n_regs, sizeof(*oa_regs), GFP_KERNEL);\n\tif (!oa_regs)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor (i = 0; i < n_regs; i++) {\n\t\tu32 addr, value;\n\n\t\terr = get_user(addr, regs);\n\t\tif (err)\n\t\t\tgoto addr_err;\n\n\t\tif (!is_valid(perf, addr)) {\n\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\"Invalid oa_reg address: %X\\n\", addr);\n\t\t\terr = -EINVAL;\n\t\t\tgoto addr_err;\n\t\t}\n\n\t\terr = get_user(value, regs + 1);\n\t\tif (err)\n\t\t\tgoto addr_err;\n\n\t\toa_regs[i].addr = _MMIO(addr);\n\t\toa_regs[i].value = mask_reg_value(addr, value);\n\n\t\tregs += 2;\n\t}\n\n\treturn oa_regs;\n\naddr_err:\n\tkfree(oa_regs);\n\treturn ERR_PTR(err);\n}\n\nstatic ssize_t show_dynamic_id(struct kobject *kobj,\n\t\t\t       struct kobj_attribute *attr,\n\t\t\t       char *buf)\n{\n\tstruct i915_oa_config *oa_config =\n\t\tcontainer_of(attr, typeof(*oa_config), sysfs_metric_id);\n\n\treturn sprintf(buf, \"%d\\n\", oa_config->id);\n}\n\nstatic int create_dynamic_oa_sysfs_entry(struct i915_perf *perf,\n\t\t\t\t\t struct i915_oa_config *oa_config)\n{\n\tsysfs_attr_init(&oa_config->sysfs_metric_id.attr);\n\toa_config->sysfs_metric_id.attr.name = \"id\";\n\toa_config->sysfs_metric_id.attr.mode = S_IRUGO;\n\toa_config->sysfs_metric_id.show = show_dynamic_id;\n\toa_config->sysfs_metric_id.store = NULL;\n\n\toa_config->attrs[0] = &oa_config->sysfs_metric_id.attr;\n\toa_config->attrs[1] = NULL;\n\n\toa_config->sysfs_metric.name = oa_config->uuid;\n\toa_config->sysfs_metric.attrs = oa_config->attrs;\n\n\treturn sysfs_create_group(perf->metrics_kobj,\n\t\t\t\t  &oa_config->sysfs_metric);\n}\n\n \nint i915_perf_add_config_ioctl(struct drm_device *dev, void *data,\n\t\t\t       struct drm_file *file)\n{\n\tstruct i915_perf *perf = &to_i915(dev)->perf;\n\tstruct drm_i915_perf_oa_config *args = data;\n\tstruct i915_oa_config *oa_config, *tmp;\n\tstruct i915_oa_reg *regs;\n\tint err, id;\n\n\tif (!perf->i915)\n\t\treturn -ENOTSUPP;\n\n\tif (!perf->metrics_kobj) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"OA metrics weren't advertised via sysfs\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (i915_perf_stream_paranoid && !perfmon_capable()) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Insufficient privileges to add i915 OA config\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tif ((!args->mux_regs_ptr || !args->n_mux_regs) &&\n\t    (!args->boolean_regs_ptr || !args->n_boolean_regs) &&\n\t    (!args->flex_regs_ptr || !args->n_flex_regs)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"No OA registers given\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\toa_config = kzalloc(sizeof(*oa_config), GFP_KERNEL);\n\tif (!oa_config) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Failed to allocate memory for the OA config\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\toa_config->perf = perf;\n\tkref_init(&oa_config->ref);\n\n\tif (!uuid_is_valid(args->uuid)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Invalid uuid format for OA config\\n\");\n\t\terr = -EINVAL;\n\t\tgoto reg_err;\n\t}\n\n\t \n\tmemcpy(oa_config->uuid, args->uuid, sizeof(args->uuid));\n\n\toa_config->mux_regs_len = args->n_mux_regs;\n\tregs = alloc_oa_regs(perf,\n\t\t\t     perf->ops.is_valid_mux_reg,\n\t\t\t     u64_to_user_ptr(args->mux_regs_ptr),\n\t\t\t     args->n_mux_regs);\n\n\tif (IS_ERR(regs)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Failed to create OA config for mux_regs\\n\");\n\t\terr = PTR_ERR(regs);\n\t\tgoto reg_err;\n\t}\n\toa_config->mux_regs = regs;\n\n\toa_config->b_counter_regs_len = args->n_boolean_regs;\n\tregs = alloc_oa_regs(perf,\n\t\t\t     perf->ops.is_valid_b_counter_reg,\n\t\t\t     u64_to_user_ptr(args->boolean_regs_ptr),\n\t\t\t     args->n_boolean_regs);\n\n\tif (IS_ERR(regs)) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Failed to create OA config for b_counter_regs\\n\");\n\t\terr = PTR_ERR(regs);\n\t\tgoto reg_err;\n\t}\n\toa_config->b_counter_regs = regs;\n\n\tif (GRAPHICS_VER(perf->i915) < 8) {\n\t\tif (args->n_flex_regs != 0) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto reg_err;\n\t\t}\n\t} else {\n\t\toa_config->flex_regs_len = args->n_flex_regs;\n\t\tregs = alloc_oa_regs(perf,\n\t\t\t\t     perf->ops.is_valid_flex_reg,\n\t\t\t\t     u64_to_user_ptr(args->flex_regs_ptr),\n\t\t\t\t     args->n_flex_regs);\n\n\t\tif (IS_ERR(regs)) {\n\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\"Failed to create OA config for flex_regs\\n\");\n\t\t\terr = PTR_ERR(regs);\n\t\t\tgoto reg_err;\n\t\t}\n\t\toa_config->flex_regs = regs;\n\t}\n\n\terr = mutex_lock_interruptible(&perf->metrics_lock);\n\tif (err)\n\t\tgoto reg_err;\n\n\t \n\tidr_for_each_entry(&perf->metrics_idr, tmp, id) {\n\t\tif (!strcmp(tmp->uuid, oa_config->uuid)) {\n\t\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\t\"OA config already exists with this uuid\\n\");\n\t\t\terr = -EADDRINUSE;\n\t\t\tgoto sysfs_err;\n\t\t}\n\t}\n\n\terr = create_dynamic_oa_sysfs_entry(perf, oa_config);\n\tif (err) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Failed to create sysfs entry for OA config\\n\");\n\t\tgoto sysfs_err;\n\t}\n\n\t \n\toa_config->id = idr_alloc(&perf->metrics_idr,\n\t\t\t\t  oa_config, 2,\n\t\t\t\t  0, GFP_KERNEL);\n\tif (oa_config->id < 0) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Failed to create sysfs entry for OA config\\n\");\n\t\terr = oa_config->id;\n\t\tgoto sysfs_err;\n\t}\n\tid = oa_config->id;\n\n\tdrm_dbg(&perf->i915->drm,\n\t\t\"Added config %s id=%i\\n\", oa_config->uuid, oa_config->id);\n\tmutex_unlock(&perf->metrics_lock);\n\n\treturn id;\n\nsysfs_err:\n\tmutex_unlock(&perf->metrics_lock);\nreg_err:\n\ti915_oa_config_put(oa_config);\n\tdrm_dbg(&perf->i915->drm,\n\t\t\"Failed to add new OA config\\n\");\n\treturn err;\n}\n\n \nint i915_perf_remove_config_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t  struct drm_file *file)\n{\n\tstruct i915_perf *perf = &to_i915(dev)->perf;\n\tu64 *arg = data;\n\tstruct i915_oa_config *oa_config;\n\tint ret;\n\n\tif (!perf->i915)\n\t\treturn -ENOTSUPP;\n\n\tif (i915_perf_stream_paranoid && !perfmon_capable()) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Insufficient privileges to remove i915 OA config\\n\");\n\t\treturn -EACCES;\n\t}\n\n\tret = mutex_lock_interruptible(&perf->metrics_lock);\n\tif (ret)\n\t\treturn ret;\n\n\toa_config = idr_find(&perf->metrics_idr, *arg);\n\tif (!oa_config) {\n\t\tdrm_dbg(&perf->i915->drm,\n\t\t\t\"Failed to remove unknown OA config\\n\");\n\t\tret = -ENOENT;\n\t\tgoto err_unlock;\n\t}\n\n\tGEM_BUG_ON(*arg != oa_config->id);\n\n\tsysfs_remove_group(perf->metrics_kobj, &oa_config->sysfs_metric);\n\n\tidr_remove(&perf->metrics_idr, *arg);\n\n\tmutex_unlock(&perf->metrics_lock);\n\n\tdrm_dbg(&perf->i915->drm,\n\t\t\"Removed config %s id=%i\\n\", oa_config->uuid, oa_config->id);\n\n\ti915_oa_config_put(oa_config);\n\n\treturn 0;\n\nerr_unlock:\n\tmutex_unlock(&perf->metrics_lock);\n\treturn ret;\n}\n\nstatic struct ctl_table oa_table[] = {\n\t{\n\t .procname = \"perf_stream_paranoid\",\n\t .data = &i915_perf_stream_paranoid,\n\t .maxlen = sizeof(i915_perf_stream_paranoid),\n\t .mode = 0644,\n\t .proc_handler = proc_dointvec_minmax,\n\t .extra1 = SYSCTL_ZERO,\n\t .extra2 = SYSCTL_ONE,\n\t },\n\t{\n\t .procname = \"oa_max_sample_rate\",\n\t .data = &i915_oa_max_sample_rate,\n\t .maxlen = sizeof(i915_oa_max_sample_rate),\n\t .mode = 0644,\n\t .proc_handler = proc_dointvec_minmax,\n\t .extra1 = SYSCTL_ZERO,\n\t .extra2 = &oa_sample_rate_hard_limit,\n\t },\n\t{}\n};\n\nstatic u32 num_perf_groups_per_gt(struct intel_gt *gt)\n{\n\treturn 1;\n}\n\nstatic u32 __oam_engine_group(struct intel_engine_cs *engine)\n{\n\tif (GRAPHICS_VER_FULL(engine->i915) >= IP_VER(12, 70)) {\n\t\t \n\t\tdrm_WARN_ON(&engine->i915->drm,\n\t\t\t    engine->gt->type != GT_MEDIA);\n\n\t\treturn PERF_GROUP_OAM_SAMEDIA_0;\n\t}\n\n\treturn PERF_GROUP_INVALID;\n}\n\nstatic u32 __oa_engine_group(struct intel_engine_cs *engine)\n{\n\tswitch (engine->class) {\n\tcase RENDER_CLASS:\n\t\treturn PERF_GROUP_OAG;\n\n\tcase VIDEO_DECODE_CLASS:\n\tcase VIDEO_ENHANCEMENT_CLASS:\n\t\treturn __oam_engine_group(engine);\n\n\tdefault:\n\t\treturn PERF_GROUP_INVALID;\n\t}\n}\n\nstatic struct i915_perf_regs __oam_regs(u32 base)\n{\n\treturn (struct i915_perf_regs) {\n\t\tbase,\n\t\tGEN12_OAM_HEAD_POINTER(base),\n\t\tGEN12_OAM_TAIL_POINTER(base),\n\t\tGEN12_OAM_BUFFER(base),\n\t\tGEN12_OAM_CONTEXT_CONTROL(base),\n\t\tGEN12_OAM_CONTROL(base),\n\t\tGEN12_OAM_DEBUG(base),\n\t\tGEN12_OAM_STATUS(base),\n\t\tGEN12_OAM_CONTROL_COUNTER_FORMAT_SHIFT,\n\t};\n}\n\nstatic struct i915_perf_regs __oag_regs(void)\n{\n\treturn (struct i915_perf_regs) {\n\t\t0,\n\t\tGEN12_OAG_OAHEADPTR,\n\t\tGEN12_OAG_OATAILPTR,\n\t\tGEN12_OAG_OABUFFER,\n\t\tGEN12_OAG_OAGLBCTXCTRL,\n\t\tGEN12_OAG_OACONTROL,\n\t\tGEN12_OAG_OA_DEBUG,\n\t\tGEN12_OAG_OASTATUS,\n\t\tGEN12_OAG_OACONTROL_OA_COUNTER_FORMAT_SHIFT,\n\t};\n}\n\nstatic void oa_init_groups(struct intel_gt *gt)\n{\n\tint i, num_groups = gt->perf.num_perf_groups;\n\n\tfor (i = 0; i < num_groups; i++) {\n\t\tstruct i915_perf_group *g = &gt->perf.group[i];\n\n\t\t \n\t\tif (g->num_engines == 0)\n\t\t\tcontinue;\n\n\t\tif (i == PERF_GROUP_OAG && gt->type != GT_MEDIA) {\n\t\t\tg->regs = __oag_regs();\n\t\t\tg->type = TYPE_OAG;\n\t\t} else if (GRAPHICS_VER_FULL(gt->i915) >= IP_VER(12, 70)) {\n\t\t\tg->regs = __oam_regs(mtl_oa_base[i]);\n\t\t\tg->type = TYPE_OAM;\n\t\t}\n\t}\n}\n\nstatic int oa_init_gt(struct intel_gt *gt)\n{\n\tu32 num_groups = num_perf_groups_per_gt(gt);\n\tstruct intel_engine_cs *engine;\n\tstruct i915_perf_group *g;\n\tintel_engine_mask_t tmp;\n\n\tg = kcalloc(num_groups, sizeof(*g), GFP_KERNEL);\n\tif (!g)\n\t\treturn -ENOMEM;\n\n\tfor_each_engine_masked(engine, gt, ALL_ENGINES, tmp) {\n\t\tu32 index = __oa_engine_group(engine);\n\n\t\tengine->oa_group = NULL;\n\t\tif (index < num_groups) {\n\t\t\tg[index].num_engines++;\n\t\t\tengine->oa_group = &g[index];\n\t\t}\n\t}\n\n\tgt->perf.num_perf_groups = num_groups;\n\tgt->perf.group = g;\n\n\toa_init_groups(gt);\n\n\treturn 0;\n}\n\nstatic int oa_init_engine_groups(struct i915_perf *perf)\n{\n\tstruct intel_gt *gt;\n\tint i, ret;\n\n\tfor_each_gt(gt, perf->i915, i) {\n\t\tret = oa_init_gt(gt);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void oa_init_supported_formats(struct i915_perf *perf)\n{\n\tstruct drm_i915_private *i915 = perf->i915;\n\tenum intel_platform platform = INTEL_INFO(i915)->platform;\n\n\tswitch (platform) {\n\tcase INTEL_HASWELL:\n\t\toa_format_add(perf, I915_OA_FORMAT_A13);\n\t\toa_format_add(perf, I915_OA_FORMAT_A13);\n\t\toa_format_add(perf, I915_OA_FORMAT_A29);\n\t\toa_format_add(perf, I915_OA_FORMAT_A13_B8_C8);\n\t\toa_format_add(perf, I915_OA_FORMAT_B4_C8);\n\t\toa_format_add(perf, I915_OA_FORMAT_A45_B8_C8);\n\t\toa_format_add(perf, I915_OA_FORMAT_B4_C8_A16);\n\t\toa_format_add(perf, I915_OA_FORMAT_C4_B8);\n\t\tbreak;\n\n\tcase INTEL_BROADWELL:\n\tcase INTEL_CHERRYVIEW:\n\tcase INTEL_SKYLAKE:\n\tcase INTEL_BROXTON:\n\tcase INTEL_KABYLAKE:\n\tcase INTEL_GEMINILAKE:\n\tcase INTEL_COFFEELAKE:\n\tcase INTEL_COMETLAKE:\n\tcase INTEL_ICELAKE:\n\tcase INTEL_ELKHARTLAKE:\n\tcase INTEL_JASPERLAKE:\n\tcase INTEL_TIGERLAKE:\n\tcase INTEL_ROCKETLAKE:\n\tcase INTEL_DG1:\n\tcase INTEL_ALDERLAKE_S:\n\tcase INTEL_ALDERLAKE_P:\n\t\toa_format_add(perf, I915_OA_FORMAT_A12);\n\t\toa_format_add(perf, I915_OA_FORMAT_A12_B8_C8);\n\t\toa_format_add(perf, I915_OA_FORMAT_A32u40_A4u32_B8_C8);\n\t\toa_format_add(perf, I915_OA_FORMAT_C4_B8);\n\t\tbreak;\n\n\tcase INTEL_DG2:\n\t\toa_format_add(perf, I915_OAR_FORMAT_A32u40_A4u32_B8_C8);\n\t\toa_format_add(perf, I915_OA_FORMAT_A24u40_A14u32_B8_C8);\n\t\tbreak;\n\n\tcase INTEL_METEORLAKE:\n\t\toa_format_add(perf, I915_OAR_FORMAT_A32u40_A4u32_B8_C8);\n\t\toa_format_add(perf, I915_OA_FORMAT_A24u40_A14u32_B8_C8);\n\t\toa_format_add(perf, I915_OAM_FORMAT_MPEC8u64_B8_C8);\n\t\toa_format_add(perf, I915_OAM_FORMAT_MPEC8u32_B8_C8);\n\t\tbreak;\n\n\tdefault:\n\t\tMISSING_CASE(platform);\n\t}\n}\n\nstatic void i915_perf_init_info(struct drm_i915_private *i915)\n{\n\tstruct i915_perf *perf = &i915->perf;\n\n\tswitch (GRAPHICS_VER(i915)) {\n\tcase 8:\n\t\tperf->ctx_oactxctrl_offset = 0x120;\n\t\tperf->ctx_flexeu0_offset = 0x2ce;\n\t\tperf->gen8_valid_ctx_bit = BIT(25);\n\t\tbreak;\n\tcase 9:\n\t\tperf->ctx_oactxctrl_offset = 0x128;\n\t\tperf->ctx_flexeu0_offset = 0x3de;\n\t\tperf->gen8_valid_ctx_bit = BIT(16);\n\t\tbreak;\n\tcase 11:\n\t\tperf->ctx_oactxctrl_offset = 0x124;\n\t\tperf->ctx_flexeu0_offset = 0x78e;\n\t\tperf->gen8_valid_ctx_bit = BIT(16);\n\t\tbreak;\n\tcase 12:\n\t\tperf->gen8_valid_ctx_bit = BIT(16);\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tMISSING_CASE(GRAPHICS_VER(i915));\n\t}\n}\n\n \nint i915_perf_init(struct drm_i915_private *i915)\n{\n\tstruct i915_perf *perf = &i915->perf;\n\n\tperf->oa_formats = oa_formats;\n\tif (IS_HASWELL(i915)) {\n\t\tperf->ops.is_valid_b_counter_reg = gen7_is_valid_b_counter_addr;\n\t\tperf->ops.is_valid_mux_reg = hsw_is_valid_mux_addr;\n\t\tperf->ops.is_valid_flex_reg = NULL;\n\t\tperf->ops.enable_metric_set = hsw_enable_metric_set;\n\t\tperf->ops.disable_metric_set = hsw_disable_metric_set;\n\t\tperf->ops.oa_enable = gen7_oa_enable;\n\t\tperf->ops.oa_disable = gen7_oa_disable;\n\t\tperf->ops.read = gen7_oa_read;\n\t\tperf->ops.oa_hw_tail_read = gen7_oa_hw_tail_read;\n\t} else if (HAS_LOGICAL_RING_CONTEXTS(i915)) {\n\t\t \n\t\tperf->ops.read = gen8_oa_read;\n\t\ti915_perf_init_info(i915);\n\n\t\tif (IS_GRAPHICS_VER(i915, 8, 9)) {\n\t\t\tperf->ops.is_valid_b_counter_reg =\n\t\t\t\tgen7_is_valid_b_counter_addr;\n\t\t\tperf->ops.is_valid_mux_reg =\n\t\t\t\tgen8_is_valid_mux_addr;\n\t\t\tperf->ops.is_valid_flex_reg =\n\t\t\t\tgen8_is_valid_flex_addr;\n\n\t\t\tif (IS_CHERRYVIEW(i915)) {\n\t\t\t\tperf->ops.is_valid_mux_reg =\n\t\t\t\t\tchv_is_valid_mux_addr;\n\t\t\t}\n\n\t\t\tperf->ops.oa_enable = gen8_oa_enable;\n\t\t\tperf->ops.oa_disable = gen8_oa_disable;\n\t\t\tperf->ops.enable_metric_set = gen8_enable_metric_set;\n\t\t\tperf->ops.disable_metric_set = gen8_disable_metric_set;\n\t\t\tperf->ops.oa_hw_tail_read = gen8_oa_hw_tail_read;\n\t\t} else if (GRAPHICS_VER(i915) == 11) {\n\t\t\tperf->ops.is_valid_b_counter_reg =\n\t\t\t\tgen7_is_valid_b_counter_addr;\n\t\t\tperf->ops.is_valid_mux_reg =\n\t\t\t\tgen11_is_valid_mux_addr;\n\t\t\tperf->ops.is_valid_flex_reg =\n\t\t\t\tgen8_is_valid_flex_addr;\n\n\t\t\tperf->ops.oa_enable = gen8_oa_enable;\n\t\t\tperf->ops.oa_disable = gen8_oa_disable;\n\t\t\tperf->ops.enable_metric_set = gen8_enable_metric_set;\n\t\t\tperf->ops.disable_metric_set = gen11_disable_metric_set;\n\t\t\tperf->ops.oa_hw_tail_read = gen8_oa_hw_tail_read;\n\t\t} else if (GRAPHICS_VER(i915) == 12) {\n\t\t\tperf->ops.is_valid_b_counter_reg =\n\t\t\t\tHAS_OA_SLICE_CONTRIB_LIMITS(i915) ?\n\t\t\t\txehp_is_valid_b_counter_addr :\n\t\t\t\tgen12_is_valid_b_counter_addr;\n\t\t\tperf->ops.is_valid_mux_reg =\n\t\t\t\tgen12_is_valid_mux_addr;\n\t\t\tperf->ops.is_valid_flex_reg =\n\t\t\t\tgen8_is_valid_flex_addr;\n\n\t\t\tperf->ops.oa_enable = gen12_oa_enable;\n\t\t\tperf->ops.oa_disable = gen12_oa_disable;\n\t\t\tperf->ops.enable_metric_set = gen12_enable_metric_set;\n\t\t\tperf->ops.disable_metric_set = gen12_disable_metric_set;\n\t\t\tperf->ops.oa_hw_tail_read = gen12_oa_hw_tail_read;\n\t\t}\n\t}\n\n\tif (perf->ops.enable_metric_set) {\n\t\tstruct intel_gt *gt;\n\t\tint i, ret;\n\n\t\tfor_each_gt(gt, i915, i)\n\t\t\tmutex_init(&gt->perf.lock);\n\n\t\t \n\t\toa_sample_rate_hard_limit = to_gt(i915)->clock_frequency / 2;\n\n\t\tmutex_init(&perf->metrics_lock);\n\t\tidr_init_base(&perf->metrics_idr, 1);\n\n\t\t \n\t\tratelimit_state_init(&perf->spurious_report_rs, 5 * HZ, 10);\n\t\t \n\t\tratelimit_set_flags(&perf->spurious_report_rs,\n\t\t\t\t    RATELIMIT_MSG_ON_RELEASE);\n\n\t\tratelimit_state_init(&perf->tail_pointer_race,\n\t\t\t\t     5 * HZ, 10);\n\t\tratelimit_set_flags(&perf->tail_pointer_race,\n\t\t\t\t    RATELIMIT_MSG_ON_RELEASE);\n\n\t\tatomic64_set(&perf->noa_programming_delay,\n\t\t\t     500 * 1000  );\n\n\t\tperf->i915 = i915;\n\n\t\tret = oa_init_engine_groups(perf);\n\t\tif (ret) {\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"OA initialization failed %d\\n\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\toa_init_supported_formats(perf);\n\t}\n\n\treturn 0;\n}\n\nstatic int destroy_config(int id, void *p, void *data)\n{\n\ti915_oa_config_put(p);\n\treturn 0;\n}\n\nint i915_perf_sysctl_register(void)\n{\n\tsysctl_header = register_sysctl(\"dev/i915\", oa_table);\n\treturn 0;\n}\n\nvoid i915_perf_sysctl_unregister(void)\n{\n\tunregister_sysctl_table(sysctl_header);\n}\n\n \nvoid i915_perf_fini(struct drm_i915_private *i915)\n{\n\tstruct i915_perf *perf = &i915->perf;\n\tstruct intel_gt *gt;\n\tint i;\n\n\tif (!perf->i915)\n\t\treturn;\n\n\tfor_each_gt(gt, perf->i915, i)\n\t\tkfree(gt->perf.group);\n\n\tidr_for_each(&perf->metrics_idr, destroy_config, perf);\n\tidr_destroy(&perf->metrics_idr);\n\n\tmemset(&perf->ops, 0, sizeof(perf->ops));\n\tperf->i915 = NULL;\n}\n\n \nint i915_perf_ioctl_version(struct drm_i915_private *i915)\n{\n\t \n\n\t \n\tif (IS_MTL_MEDIA_STEP(i915, STEP_A0, STEP_C0)) {\n\t\tstruct intel_gt *gt;\n\t\tint i;\n\n\t\tfor_each_gt(gt, i915, i) {\n\t\t\tif (gt->type == GT_MEDIA &&\n\t\t\t    intel_check_bios_c6_setup(&gt->rc6))\n\t\t\t\treturn 6;\n\t\t}\n\t}\n\n\treturn 7;\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_SELFTEST)\n#include \"selftests/i915_perf.c\"\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}