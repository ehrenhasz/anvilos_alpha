{
  "module_name": "i915_request.h",
  "hash_id": "6be4aff9f83baa1a3135c38c7c7bb6426e9f4cf7caba3d31a83e1f3122c695f6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/i915_request.h",
  "human_readable_source": " \n\n#ifndef I915_REQUEST_H\n#define I915_REQUEST_H\n\n#include <linux/dma-fence.h>\n#include <linux/hrtimer.h>\n#include <linux/irq_work.h>\n#include <linux/llist.h>\n#include <linux/lockdep.h>\n\n#include \"gem/i915_gem_context_types.h\"\n#include \"gt/intel_context_types.h\"\n#include \"gt/intel_engine_types.h\"\n#include \"gt/intel_timeline_types.h\"\n\n#include \"i915_gem.h\"\n#include \"i915_scheduler.h\"\n#include \"i915_selftest.h\"\n#include \"i915_sw_fence.h\"\n#include \"i915_vma_resource.h\"\n\n#include <uapi/drm/i915_drm.h>\n\nstruct drm_file;\nstruct drm_i915_gem_object;\nstruct drm_printer;\nstruct i915_deps;\nstruct i915_request;\n\n#if IS_ENABLED(CONFIG_DRM_I915_CAPTURE_ERROR)\nstruct i915_capture_list {\n\tstruct i915_vma_resource *vma_res;\n\tstruct i915_capture_list *next;\n};\n\nvoid i915_request_free_capture_list(struct i915_capture_list *capture);\n#else\n#define i915_request_free_capture_list(_a) do {} while (0)\n#endif\n\n#define RQ_TRACE(rq, fmt, ...) do {\t\t\t\t\t\\\n\tconst struct i915_request *rq__ = (rq);\t\t\t\t\\\n\tENGINE_TRACE(rq__->engine, \"fence %llx:%lld, current %d \" fmt,\t\\\n\t\t     rq__->fence.context, rq__->fence.seqno,\t\t\\\n\t\t     hwsp_seqno(rq__), ##__VA_ARGS__);\t\t\t\\\n} while (0)\n\nenum {\n\t \n\tI915_FENCE_FLAG_ACTIVE = DMA_FENCE_FLAG_USER_BITS,\n\n\t \n\tI915_FENCE_FLAG_PQUEUE,\n\n\t \n\tI915_FENCE_FLAG_HOLD,\n\n\t \n\tI915_FENCE_FLAG_INITIAL_BREADCRUMB,\n\n\t \n\tI915_FENCE_FLAG_SIGNAL,\n\n\t \n\tI915_FENCE_FLAG_NOPREEMPT,\n\n\t \n\tI915_FENCE_FLAG_SENTINEL,\n\n\t \n\tI915_FENCE_FLAG_BOOST,\n\n\t \n\tI915_FENCE_FLAG_SUBMIT_PARALLEL,\n\n\t \n\tI915_FENCE_FLAG_SKIP_PARALLEL,\n\n\t \n\tI915_FENCE_FLAG_COMPOSITE,\n};\n\n \nstruct i915_request {\n\tstruct dma_fence fence;\n\tspinlock_t lock;\n\n\tstruct drm_i915_private *i915;\n\n\t \n\tstruct intel_engine_cs *engine;\n\tstruct intel_context *context;\n\tstruct intel_ring *ring;\n\tstruct intel_timeline __rcu *timeline;\n\n\tstruct list_head signal_link;\n\tstruct llist_node signal_node;\n\n\t \n\tunsigned long rcustate;\n\n\t \n\tstruct pin_cookie cookie;\n\n\t \n\tstruct i915_sw_fence submit;\n\tunion {\n\t\twait_queue_entry_t submitq;\n\t\tstruct i915_sw_dma_fence_cb dmaq;\n\t\tstruct i915_request_duration_cb {\n\t\t\tstruct dma_fence_cb cb;\n\t\t\tktime_t emitted;\n\t\t} duration;\n\t};\n\tstruct llist_head execute_cb;\n\tstruct i915_sw_fence semaphore;\n\t \n\tstruct irq_work submit_work;\n\n\t \n\tstruct i915_sched_node sched;\n\tstruct i915_dependency dep;\n\tintel_engine_mask_t execution_mask;\n\n\t \n\tconst u32 *hwsp_seqno;\n\n\t \n\tu32 head;\n\n\t \n\tu32 infix;\n\n\t \n\tu32 postfix;\n\n\t \n\tu32 tail;\n\n\t \n\tu32 wa_tail;\n\n\t \n\tu32 reserved_space;\n\n\t \n\tI915_SELFTEST_DECLARE(struct i915_vma *batch);\n\n\tstruct i915_vma_resource *batch_res;\n\n#if IS_ENABLED(CONFIG_DRM_I915_CAPTURE_ERROR)\n\t \n\tstruct i915_capture_list *capture_list;\n#endif\n\n\t \n\tunsigned long emitted_jiffies;\n\n\t \n\tstruct list_head link;\n\n\t \n\tstruct i915_request_watchdog {\n\t\tstruct llist_node link;\n\t\tstruct hrtimer timer;\n\t} watchdog;\n\n\t \n\tstruct list_head guc_fence_link;\n\n\t \n#define\tGUC_PRIO_INIT\t0xff\n#define\tGUC_PRIO_FINI\t0xfe\n\tu8 guc_prio;\n\n\t \n\twait_queue_entry_t hucq;\n\n\tI915_SELFTEST_DECLARE(struct {\n\t\tstruct list_head link;\n\t\tunsigned long delay;\n\t} mock;)\n};\n\n#define I915_FENCE_GFP (GFP_KERNEL | __GFP_RETRY_MAYFAIL | __GFP_NOWARN)\n\nextern const struct dma_fence_ops i915_fence_ops;\n\nstatic inline bool dma_fence_is_i915(const struct dma_fence *fence)\n{\n\treturn fence->ops == &i915_fence_ops;\n}\n\nstruct kmem_cache *i915_request_slab_cache(void);\n\nstruct i915_request * __must_check\n__i915_request_create(struct intel_context *ce, gfp_t gfp);\nstruct i915_request * __must_check\ni915_request_create(struct intel_context *ce);\n\nvoid __i915_request_skip(struct i915_request *rq);\nbool i915_request_set_error_once(struct i915_request *rq, int error);\nstruct i915_request *i915_request_mark_eio(struct i915_request *rq);\n\nstruct i915_request *__i915_request_commit(struct i915_request *request);\nvoid __i915_request_queue(struct i915_request *rq,\n\t\t\t  const struct i915_sched_attr *attr);\nvoid __i915_request_queue_bh(struct i915_request *rq);\n\nbool i915_request_retire(struct i915_request *rq);\nvoid i915_request_retire_upto(struct i915_request *rq);\n\nstatic inline struct i915_request *\nto_request(struct dma_fence *fence)\n{\n\t \n\tBUILD_BUG_ON(offsetof(struct i915_request, fence) != 0);\n\tGEM_BUG_ON(fence && !dma_fence_is_i915(fence));\n\treturn container_of(fence, struct i915_request, fence);\n}\n\nstatic inline struct i915_request *\ni915_request_get(struct i915_request *rq)\n{\n\treturn to_request(dma_fence_get(&rq->fence));\n}\n\nstatic inline struct i915_request *\ni915_request_get_rcu(struct i915_request *rq)\n{\n\treturn to_request(dma_fence_get_rcu(&rq->fence));\n}\n\nstatic inline void\ni915_request_put(struct i915_request *rq)\n{\n\tdma_fence_put(&rq->fence);\n}\n\nint i915_request_await_object(struct i915_request *to,\n\t\t\t      struct drm_i915_gem_object *obj,\n\t\t\t      bool write);\nint i915_request_await_dma_fence(struct i915_request *rq,\n\t\t\t\t struct dma_fence *fence);\nint i915_request_await_deps(struct i915_request *rq, const struct i915_deps *deps);\nint i915_request_await_execution(struct i915_request *rq,\n\t\t\t\t struct dma_fence *fence);\n\nvoid i915_request_add(struct i915_request *rq);\n\nbool __i915_request_submit(struct i915_request *request);\nvoid i915_request_submit(struct i915_request *request);\n\nvoid __i915_request_unsubmit(struct i915_request *request);\nvoid i915_request_unsubmit(struct i915_request *request);\n\nvoid i915_request_cancel(struct i915_request *rq, int error);\n\nlong i915_request_wait_timeout(struct i915_request *rq,\n\t\t\t       unsigned int flags,\n\t\t\t       long timeout)\n\t__attribute__((nonnull(1)));\n\nlong i915_request_wait(struct i915_request *rq,\n\t\t       unsigned int flags,\n\t\t       long timeout)\n\t__attribute__((nonnull(1)));\n#define I915_WAIT_INTERRUPTIBLE\tBIT(0)\n#define I915_WAIT_PRIORITY\tBIT(1)  \n#define I915_WAIT_ALL\t\tBIT(2)  \n\nvoid i915_request_show(struct drm_printer *m,\n\t\t       const struct i915_request *rq,\n\t\t       const char *prefix,\n\t\t       int indent);\n\nstatic inline bool i915_request_signaled(const struct i915_request *rq)\n{\n\t \n\treturn test_bit(DMA_FENCE_FLAG_SIGNALED_BIT, &rq->fence.flags);\n}\n\nstatic inline bool i915_request_is_active(const struct i915_request *rq)\n{\n\treturn test_bit(I915_FENCE_FLAG_ACTIVE, &rq->fence.flags);\n}\n\nstatic inline bool i915_request_in_priority_queue(const struct i915_request *rq)\n{\n\treturn test_bit(I915_FENCE_FLAG_PQUEUE, &rq->fence.flags);\n}\n\nstatic inline bool\ni915_request_has_initial_breadcrumb(const struct i915_request *rq)\n{\n\treturn test_bit(I915_FENCE_FLAG_INITIAL_BREADCRUMB, &rq->fence.flags);\n}\n\n \nstatic inline bool i915_seqno_passed(u32 seq1, u32 seq2)\n{\n\treturn (s32)(seq1 - seq2) >= 0;\n}\n\nstatic inline u32 __hwsp_seqno(const struct i915_request *rq)\n{\n\tconst u32 *hwsp = READ_ONCE(rq->hwsp_seqno);\n\n\treturn READ_ONCE(*hwsp);\n}\n\n \nstatic inline u32 hwsp_seqno(const struct i915_request *rq)\n{\n\tu32 seqno;\n\n\trcu_read_lock();  \n\tseqno = __hwsp_seqno(rq);\n\trcu_read_unlock();\n\n\treturn seqno;\n}\n\nstatic inline bool __i915_request_has_started(const struct i915_request *rq)\n{\n\treturn i915_seqno_passed(__hwsp_seqno(rq), rq->fence.seqno - 1);\n}\n\n \nstatic inline bool i915_request_started(const struct i915_request *rq)\n{\n\tbool result;\n\n\tif (i915_request_signaled(rq))\n\t\treturn true;\n\n\tresult = true;\n\trcu_read_lock();  \n\tif (likely(!i915_request_signaled(rq)))\n\t\t \n\t\tresult = __i915_request_has_started(rq);\n\trcu_read_unlock();\n\n\treturn result;\n}\n\n \nstatic inline bool i915_request_is_running(const struct i915_request *rq)\n{\n\tbool result;\n\n\tif (!i915_request_is_active(rq))\n\t\treturn false;\n\n\trcu_read_lock();\n\tresult = __i915_request_has_started(rq) && i915_request_is_active(rq);\n\trcu_read_unlock();\n\n\treturn result;\n}\n\n \nstatic inline bool i915_request_is_ready(const struct i915_request *rq)\n{\n\treturn !list_empty(&rq->sched.link);\n}\n\nstatic inline bool __i915_request_is_complete(const struct i915_request *rq)\n{\n\treturn i915_seqno_passed(__hwsp_seqno(rq), rq->fence.seqno);\n}\n\nstatic inline bool i915_request_completed(const struct i915_request *rq)\n{\n\tbool result;\n\n\tif (i915_request_signaled(rq))\n\t\treturn true;\n\n\tresult = true;\n\trcu_read_lock();  \n\tif (likely(!i915_request_signaled(rq)))\n\t\tresult = __i915_request_is_complete(rq);\n\trcu_read_unlock();\n\n\treturn result;\n}\n\nstatic inline void i915_request_mark_complete(struct i915_request *rq)\n{\n\tWRITE_ONCE(rq->hwsp_seqno,  \n\t\t   (u32 *)&rq->fence.seqno);\n}\n\nstatic inline bool i915_request_has_waitboost(const struct i915_request *rq)\n{\n\treturn test_bit(I915_FENCE_FLAG_BOOST, &rq->fence.flags);\n}\n\nstatic inline bool i915_request_has_nopreempt(const struct i915_request *rq)\n{\n\t \n\treturn unlikely(test_bit(I915_FENCE_FLAG_NOPREEMPT, &rq->fence.flags));\n}\n\nstatic inline bool i915_request_has_sentinel(const struct i915_request *rq)\n{\n\treturn unlikely(test_bit(I915_FENCE_FLAG_SENTINEL, &rq->fence.flags));\n}\n\nstatic inline bool i915_request_on_hold(const struct i915_request *rq)\n{\n\treturn unlikely(test_bit(I915_FENCE_FLAG_HOLD, &rq->fence.flags));\n}\n\nstatic inline void i915_request_set_hold(struct i915_request *rq)\n{\n\tset_bit(I915_FENCE_FLAG_HOLD, &rq->fence.flags);\n}\n\nstatic inline void i915_request_clear_hold(struct i915_request *rq)\n{\n\tclear_bit(I915_FENCE_FLAG_HOLD, &rq->fence.flags);\n}\n\nstatic inline struct intel_timeline *\ni915_request_timeline(const struct i915_request *rq)\n{\n\t \n\treturn rcu_dereference_protected(rq->timeline,\n\t\t\t\t\t lockdep_is_held(&rcu_access_pointer(rq->timeline)->mutex) ||\n\t\t\t\t\t test_bit(CONTEXT_IS_PARKING, &rq->context->flags));\n}\n\nstatic inline struct i915_gem_context *\ni915_request_gem_context(const struct i915_request *rq)\n{\n\t \n\treturn rcu_dereference_protected(rq->context->gem_context, true);\n}\n\nstatic inline struct intel_timeline *\ni915_request_active_timeline(const struct i915_request *rq)\n{\n\t \n\treturn rcu_dereference_protected(rq->timeline,\n\t\t\t\t\t lockdep_is_held(&rq->engine->sched_engine->lock));\n}\n\nstatic inline u32\ni915_request_active_seqno(const struct i915_request *rq)\n{\n\tu32 hwsp_phys_base =\n\t\tpage_mask_bits(i915_request_active_timeline(rq)->hwsp_offset);\n\tu32 hwsp_relative_offset = offset_in_page(rq->hwsp_seqno);\n\n\t \n\n\treturn hwsp_phys_base + hwsp_relative_offset;\n}\n\nbool\ni915_request_active_engine(struct i915_request *rq,\n\t\t\t   struct intel_engine_cs **active);\n\nvoid i915_request_notify_execute_cb_imm(struct i915_request *rq);\n\nenum i915_request_state {\n\tI915_REQUEST_UNKNOWN = 0,\n\tI915_REQUEST_COMPLETE,\n\tI915_REQUEST_PENDING,\n\tI915_REQUEST_QUEUED,\n\tI915_REQUEST_ACTIVE,\n};\n\nenum i915_request_state i915_test_request_state(struct i915_request *rq);\n\nvoid i915_request_module_exit(void);\nint i915_request_module_init(void);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}