{
  "module_name": "intel_pmdemand.c",
  "hash_id": "32a2b0fc68d7a531fd65763489960f49512fe271010a6899ad28225229bda21a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/display/intel_pmdemand.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n\n#include \"i915_drv.h\"\n#include \"i915_reg.h\"\n#include \"intel_atomic.h\"\n#include \"intel_bw.h\"\n#include \"intel_cdclk.h\"\n#include \"intel_de.h\"\n#include \"intel_display_trace.h\"\n#include \"intel_pmdemand.h\"\n#include \"skl_watermark.h\"\n\nstatic struct intel_global_state *\nintel_pmdemand_duplicate_state(struct intel_global_obj *obj)\n{\n\tstruct intel_pmdemand_state *pmdemand_state;\n\n\tpmdemand_state = kmemdup(obj->state, sizeof(*pmdemand_state), GFP_KERNEL);\n\tif (!pmdemand_state)\n\t\treturn NULL;\n\n\treturn &pmdemand_state->base;\n}\n\nstatic void intel_pmdemand_destroy_state(struct intel_global_obj *obj,\n\t\t\t\t\t struct intel_global_state *state)\n{\n\tkfree(state);\n}\n\nstatic const struct intel_global_state_funcs intel_pmdemand_funcs = {\n\t.atomic_duplicate_state = intel_pmdemand_duplicate_state,\n\t.atomic_destroy_state = intel_pmdemand_destroy_state,\n};\n\nstatic struct intel_pmdemand_state *\nintel_atomic_get_pmdemand_state(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tstruct intel_global_state *pmdemand_state =\n\t\tintel_atomic_get_global_obj_state(state,\n\t\t\t\t\t\t  &i915->display.pmdemand.obj);\n\n\tif (IS_ERR(pmdemand_state))\n\t\treturn ERR_CAST(pmdemand_state);\n\n\treturn to_intel_pmdemand_state(pmdemand_state);\n}\n\nstatic struct intel_pmdemand_state *\nintel_atomic_get_old_pmdemand_state(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tstruct intel_global_state *pmdemand_state =\n\t\tintel_atomic_get_old_global_obj_state(state,\n\t\t\t\t\t\t      &i915->display.pmdemand.obj);\n\n\tif (!pmdemand_state)\n\t\treturn NULL;\n\n\treturn to_intel_pmdemand_state(pmdemand_state);\n}\n\nstatic struct intel_pmdemand_state *\nintel_atomic_get_new_pmdemand_state(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tstruct intel_global_state *pmdemand_state =\n\t\tintel_atomic_get_new_global_obj_state(state,\n\t\t\t\t\t\t      &i915->display.pmdemand.obj);\n\n\tif (!pmdemand_state)\n\t\treturn NULL;\n\n\treturn to_intel_pmdemand_state(pmdemand_state);\n}\n\nint intel_pmdemand_init(struct drm_i915_private *i915)\n{\n\tstruct intel_pmdemand_state *pmdemand_state;\n\n\tpmdemand_state = kzalloc(sizeof(*pmdemand_state), GFP_KERNEL);\n\tif (!pmdemand_state)\n\t\treturn -ENOMEM;\n\n\tintel_atomic_global_obj_init(i915, &i915->display.pmdemand.obj,\n\t\t\t\t     &pmdemand_state->base,\n\t\t\t\t     &intel_pmdemand_funcs);\n\n\tif (IS_MTL_DISPLAY_STEP(i915, STEP_A0, STEP_C0))\n\t\t \n\t\tintel_de_rmw(i915, XELPD_CHICKEN_DCPR_3, 0, DMD_RSP_TIMEOUT_DISABLE);\n\n\treturn 0;\n}\n\nvoid intel_pmdemand_init_early(struct drm_i915_private *i915)\n{\n\tmutex_init(&i915->display.pmdemand.lock);\n\tinit_waitqueue_head(&i915->display.pmdemand.waitqueue);\n}\n\nvoid\nintel_pmdemand_update_phys_mask(struct drm_i915_private *i915,\n\t\t\t\tstruct intel_encoder *encoder,\n\t\t\t\tstruct intel_pmdemand_state *pmdemand_state,\n\t\t\t\tbool set_bit)\n{\n\tenum phy phy;\n\n\tif (DISPLAY_VER(i915) < 14)\n\t\treturn;\n\n\tif (!encoder)\n\t\treturn;\n\n\tphy = intel_port_to_phy(i915, encoder->port);\n\tif (intel_phy_is_tc(i915, phy))\n\t\treturn;\n\n\tif (set_bit)\n\t\tpmdemand_state->active_combo_phys_mask |= BIT(phy);\n\telse\n\t\tpmdemand_state->active_combo_phys_mask &= ~BIT(phy);\n}\n\nvoid\nintel_pmdemand_update_port_clock(struct drm_i915_private *i915,\n\t\t\t\t struct intel_pmdemand_state *pmdemand_state,\n\t\t\t\t enum pipe pipe, int port_clock)\n{\n\tif (DISPLAY_VER(i915) < 14)\n\t\treturn;\n\n\tpmdemand_state->ddi_clocks[pipe] = port_clock;\n}\n\nstatic void\nintel_pmdemand_update_max_ddiclk(struct drm_i915_private *i915,\n\t\t\t\t struct intel_atomic_state *state,\n\t\t\t\t struct intel_pmdemand_state *pmdemand_state)\n{\n\tint max_ddiclk = 0;\n\tconst struct intel_crtc_state *new_crtc_state;\n\tstruct intel_crtc *crtc;\n\tint i;\n\n\tfor_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i)\n\t\tintel_pmdemand_update_port_clock(i915, pmdemand_state,\n\t\t\t\t\t\t crtc->pipe,\n\t\t\t\t\t\t new_crtc_state->port_clock);\n\n\tfor (i = 0; i < ARRAY_SIZE(pmdemand_state->ddi_clocks); i++)\n\t\tmax_ddiclk = max(pmdemand_state->ddi_clocks[i], max_ddiclk);\n\n\tpmdemand_state->params.ddiclk_max = DIV_ROUND_UP(max_ddiclk, 1000);\n}\n\nstatic void\nintel_pmdemand_update_connector_phys(struct drm_i915_private *i915,\n\t\t\t\t     struct intel_atomic_state *state,\n\t\t\t\t     struct drm_connector_state *conn_state,\n\t\t\t\t     bool set_bit,\n\t\t\t\t     struct intel_pmdemand_state *pmdemand_state)\n{\n\tstruct intel_encoder *encoder = to_intel_encoder(conn_state->best_encoder);\n\tstruct intel_crtc *crtc = to_intel_crtc(conn_state->crtc);\n\tstruct intel_crtc_state *crtc_state;\n\n\tif (!crtc)\n\t\treturn;\n\n\tif (set_bit)\n\t\tcrtc_state = intel_atomic_get_new_crtc_state(state, crtc);\n\telse\n\t\tcrtc_state = intel_atomic_get_old_crtc_state(state, crtc);\n\n\tif (!crtc_state->hw.active)\n\t\treturn;\n\n\tintel_pmdemand_update_phys_mask(i915, encoder, pmdemand_state,\n\t\t\t\t\tset_bit);\n}\n\nstatic void\nintel_pmdemand_update_active_non_tc_phys(struct drm_i915_private *i915,\n\t\t\t\t\t struct intel_atomic_state *state,\n\t\t\t\t\t struct intel_pmdemand_state *pmdemand_state)\n{\n\tstruct drm_connector_state *old_conn_state;\n\tstruct drm_connector_state *new_conn_state;\n\tstruct drm_connector *connector;\n\tint i;\n\n\tfor_each_oldnew_connector_in_state(&state->base, connector,\n\t\t\t\t\t   old_conn_state, new_conn_state, i) {\n\t\tif (!intel_connector_needs_modeset(state, connector))\n\t\t\tcontinue;\n\n\t\t \n\t\tintel_pmdemand_update_connector_phys(i915, state,\n\t\t\t\t\t\t     old_conn_state, false,\n\t\t\t\t\t\t     pmdemand_state);\n\n\t\t \n\t\tintel_pmdemand_update_connector_phys(i915, state,\n\t\t\t\t\t\t     new_conn_state, true,\n\t\t\t\t\t\t     pmdemand_state);\n\t}\n\n\tpmdemand_state->params.active_phys =\n\t\tmin_t(u16, hweight16(pmdemand_state->active_combo_phys_mask),\n\t\t      7);\n}\n\nstatic bool\nintel_pmdemand_encoder_has_tc_phy(struct drm_i915_private *i915,\n\t\t\t\t  struct intel_encoder *encoder)\n{\n\tenum phy phy;\n\n\tif (!encoder)\n\t\treturn false;\n\n\tphy = intel_port_to_phy(i915, encoder->port);\n\n\treturn intel_phy_is_tc(i915, phy);\n}\n\nstatic bool\nintel_pmdemand_connector_needs_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tstruct drm_connector_state *old_conn_state;\n\tstruct drm_connector_state *new_conn_state;\n\tstruct drm_connector *connector;\n\tint i;\n\n\tfor_each_oldnew_connector_in_state(&state->base, connector,\n\t\t\t\t\t   old_conn_state, new_conn_state, i) {\n\t\tstruct intel_encoder *old_encoder =\n\t\t\tto_intel_encoder(old_conn_state->best_encoder);\n\t\tstruct intel_encoder *new_encoder =\n\t\t\tto_intel_encoder(new_conn_state->best_encoder);\n\n\t\tif (!intel_connector_needs_modeset(state, connector))\n\t\t\tcontinue;\n\n\t\tif (old_encoder == new_encoder ||\n\t\t    (intel_pmdemand_encoder_has_tc_phy(i915, old_encoder) &&\n\t\t     intel_pmdemand_encoder_has_tc_phy(i915, new_encoder)))\n\t\t\tcontinue;\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic bool intel_pmdemand_needs_update(struct intel_atomic_state *state)\n{\n\tconst struct intel_bw_state *new_bw_state, *old_bw_state;\n\tconst struct intel_cdclk_state *new_cdclk_state, *old_cdclk_state;\n\tconst struct intel_crtc_state *new_crtc_state, *old_crtc_state;\n\tconst struct intel_dbuf_state *new_dbuf_state, *old_dbuf_state;\n\tstruct intel_crtc *crtc;\n\tint i;\n\n\tnew_bw_state = intel_atomic_get_new_bw_state(state);\n\told_bw_state = intel_atomic_get_old_bw_state(state);\n\tif (new_bw_state && new_bw_state->qgv_point_peakbw !=\n\t    old_bw_state->qgv_point_peakbw)\n\t\treturn true;\n\n\tnew_dbuf_state = intel_atomic_get_new_dbuf_state(state);\n\told_dbuf_state = intel_atomic_get_old_dbuf_state(state);\n\tif (new_dbuf_state &&\n\t    (new_dbuf_state->active_pipes !=\n\t     old_dbuf_state->active_pipes ||\n\t     new_dbuf_state->enabled_slices !=\n\t     old_dbuf_state->enabled_slices))\n\t\treturn true;\n\n\tnew_cdclk_state = intel_atomic_get_new_cdclk_state(state);\n\told_cdclk_state = intel_atomic_get_old_cdclk_state(state);\n\tif (new_cdclk_state &&\n\t    (new_cdclk_state->actual.cdclk !=\n\t     old_cdclk_state->actual.cdclk ||\n\t     new_cdclk_state->actual.voltage_level !=\n\t     old_cdclk_state->actual.voltage_level))\n\t\treturn true;\n\n\tfor_each_oldnew_intel_crtc_in_state(state, crtc, old_crtc_state,\n\t\t\t\t\t    new_crtc_state, i)\n\t\tif (new_crtc_state->port_clock != old_crtc_state->port_clock)\n\t\t\treturn true;\n\n\treturn intel_pmdemand_connector_needs_update(state);\n}\n\nint intel_pmdemand_atomic_check(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_bw_state *new_bw_state;\n\tconst struct intel_cdclk_state *new_cdclk_state;\n\tconst struct intel_dbuf_state *new_dbuf_state;\n\tstruct intel_pmdemand_state *new_pmdemand_state;\n\n\tif (DISPLAY_VER(i915) < 14)\n\t\treturn 0;\n\n\tif (!intel_pmdemand_needs_update(state))\n\t\treturn 0;\n\n\tnew_pmdemand_state = intel_atomic_get_pmdemand_state(state);\n\tif (IS_ERR(new_pmdemand_state))\n\t\treturn PTR_ERR(new_pmdemand_state);\n\n\tnew_bw_state = intel_atomic_get_bw_state(state);\n\tif (IS_ERR(new_bw_state))\n\t\treturn PTR_ERR(new_bw_state);\n\n\t \n\tnew_pmdemand_state->params.qclk_gv_index = 0;\n\tnew_pmdemand_state->params.qclk_gv_bw = new_bw_state->qgv_point_peakbw;\n\n\tnew_dbuf_state = intel_atomic_get_dbuf_state(state);\n\tif (IS_ERR(new_dbuf_state))\n\t\treturn PTR_ERR(new_dbuf_state);\n\n\tnew_pmdemand_state->params.active_pipes =\n\t\tmin_t(u8, hweight8(new_dbuf_state->active_pipes), 3);\n\tnew_pmdemand_state->params.active_dbufs =\n\t\tmin_t(u8, hweight8(new_dbuf_state->enabled_slices), 3);\n\n\tnew_cdclk_state = intel_atomic_get_cdclk_state(state);\n\tif (IS_ERR(new_cdclk_state))\n\t\treturn PTR_ERR(new_cdclk_state);\n\n\tnew_pmdemand_state->params.voltage_index =\n\t\tnew_cdclk_state->actual.voltage_level;\n\tnew_pmdemand_state->params.cdclk_freq_mhz =\n\t\tDIV_ROUND_UP(new_cdclk_state->actual.cdclk, 1000);\n\n\tintel_pmdemand_update_max_ddiclk(i915, state, new_pmdemand_state);\n\n\tintel_pmdemand_update_active_non_tc_phys(i915, state, new_pmdemand_state);\n\n\t \n\tnew_pmdemand_state->params.plls =\n\t\tmin_t(u16, new_pmdemand_state->params.active_phys + 1, 7);\n\n\t \n\tnew_pmdemand_state->params.scalers = 7;\n\n\tif (state->base.allow_modeset)\n\t\treturn intel_atomic_serialize_global_state(&new_pmdemand_state->base);\n\telse\n\t\treturn intel_atomic_lock_global_state(&new_pmdemand_state->base);\n}\n\nstatic bool intel_pmdemand_check_prev_transaction(struct drm_i915_private *i915)\n{\n\treturn !(intel_de_wait_for_clear(i915,\n\t\t\t\t\t XELPDP_INITIATE_PMDEMAND_REQUEST(1),\n\t\t\t\t\t XELPDP_PMDEMAND_REQ_ENABLE, 10) ||\n\t\t intel_de_wait_for_clear(i915,\n\t\t\t\t\t GEN12_DCPR_STATUS_1,\n\t\t\t\t\t XELPDP_PMDEMAND_INFLIGHT_STATUS, 10));\n}\n\nvoid\nintel_pmdemand_init_pmdemand_params(struct drm_i915_private *i915,\n\t\t\t\t    struct intel_pmdemand_state *pmdemand_state)\n{\n\tu32 reg1, reg2;\n\n\tif (DISPLAY_VER(i915) < 14)\n\t\treturn;\n\n\tmutex_lock(&i915->display.pmdemand.lock);\n\tif (drm_WARN_ON(&i915->drm,\n\t\t\t!intel_pmdemand_check_prev_transaction(i915))) {\n\t\tmemset(&pmdemand_state->params, 0,\n\t\t       sizeof(pmdemand_state->params));\n\t\tgoto unlock;\n\t}\n\n\treg1 = intel_de_read(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(0));\n\n\treg2 = intel_de_read(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(1));\n\n\t \n\tpmdemand_state->params.qclk_gv_bw =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_QCLK_GV_BW_MASK, reg1);\n\tpmdemand_state->params.voltage_index =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_VOLTAGE_INDEX_MASK, reg1);\n\tpmdemand_state->params.qclk_gv_index =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_QCLK_GV_INDEX_MASK, reg1);\n\tpmdemand_state->params.active_pipes =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_PIPES_MASK, reg1);\n\tpmdemand_state->params.active_dbufs =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_DBUFS_MASK, reg1);\n\tpmdemand_state->params.active_phys =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_PHYS_MASK, reg1);\n\n\t \n\tpmdemand_state->params.cdclk_freq_mhz =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_CDCLK_FREQ_MASK, reg2);\n\tpmdemand_state->params.ddiclk_max =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_DDICLK_FREQ_MASK, reg2);\n\tpmdemand_state->params.scalers =\n\t\tREG_FIELD_GET(XELPDP_PMDEMAND_SCALERS_MASK, reg2);\n\nunlock:\n\tmutex_unlock(&i915->display.pmdemand.lock);\n}\n\nstatic bool intel_pmdemand_req_complete(struct drm_i915_private *i915)\n{\n\treturn !(intel_de_read(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(1)) &\n\t\t XELPDP_PMDEMAND_REQ_ENABLE);\n}\n\nstatic void intel_pmdemand_wait(struct drm_i915_private *i915)\n{\n\tif (!wait_event_timeout(i915->display.pmdemand.waitqueue,\n\t\t\t\tintel_pmdemand_req_complete(i915),\n\t\t\t\tmsecs_to_jiffies_timeout(10)))\n\t\tdrm_err(&i915->drm,\n\t\t\t\"timed out waiting for Punit PM Demand Response\\n\");\n}\n\n \nvoid intel_pmdemand_program_dbuf(struct drm_i915_private *i915,\n\t\t\t\t u8 dbuf_slices)\n{\n\tu32 dbufs = min_t(u32, hweight8(dbuf_slices), 3);\n\n\tmutex_lock(&i915->display.pmdemand.lock);\n\tif (drm_WARN_ON(&i915->drm,\n\t\t\t!intel_pmdemand_check_prev_transaction(i915)))\n\t\tgoto unlock;\n\n\tintel_de_rmw(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(0),\n\t\t     XELPDP_PMDEMAND_DBUFS_MASK,\n\t\t     REG_FIELD_PREP(XELPDP_PMDEMAND_DBUFS_MASK, dbufs));\n\tintel_de_rmw(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(1), 0,\n\t\t     XELPDP_PMDEMAND_REQ_ENABLE);\n\n\tintel_pmdemand_wait(i915);\n\nunlock:\n\tmutex_unlock(&i915->display.pmdemand.lock);\n}\n\nstatic void\nintel_pmdemand_update_params(const struct intel_pmdemand_state *new,\n\t\t\t     const struct intel_pmdemand_state *old,\n\t\t\t     u32 *reg1, u32 *reg2, bool serialized)\n{\n\t \n\n#define update_reg(reg, field, mask) do { \\\n\tu32 current_val = serialized ? 0 : REG_FIELD_GET((mask), *(reg)); \\\n\tu32 old_val = old ? old->params.field : 0; \\\n\tu32 new_val = new->params.field; \\\n\\\n\t*(reg) &= ~(mask); \\\n\t*(reg) |= REG_FIELD_PREP((mask), max3(old_val, new_val, current_val)); \\\n} while (0)\n\n\t \n\tupdate_reg(reg1, qclk_gv_bw, XELPDP_PMDEMAND_QCLK_GV_BW_MASK);\n\tupdate_reg(reg1, voltage_index, XELPDP_PMDEMAND_VOLTAGE_INDEX_MASK);\n\tupdate_reg(reg1, qclk_gv_index, XELPDP_PMDEMAND_QCLK_GV_INDEX_MASK);\n\tupdate_reg(reg1, active_pipes, XELPDP_PMDEMAND_PIPES_MASK);\n\tupdate_reg(reg1, active_dbufs, XELPDP_PMDEMAND_DBUFS_MASK);\n\tupdate_reg(reg1, active_phys, XELPDP_PMDEMAND_PHYS_MASK);\n\n\t \n\tupdate_reg(reg2, cdclk_freq_mhz, XELPDP_PMDEMAND_CDCLK_FREQ_MASK);\n\tupdate_reg(reg2, ddiclk_max, XELPDP_PMDEMAND_DDICLK_FREQ_MASK);\n\tupdate_reg(reg2, scalers, XELPDP_PMDEMAND_SCALERS_MASK);\n\tupdate_reg(reg2, plls, XELPDP_PMDEMAND_PLLS_MASK);\n\n#undef update_reg\n}\n\nstatic void\nintel_pmdemand_program_params(struct drm_i915_private *i915,\n\t\t\t      const struct intel_pmdemand_state *new,\n\t\t\t      const struct intel_pmdemand_state *old,\n\t\t\t      bool serialized)\n{\n\tbool changed = false;\n\tu32 reg1, mod_reg1;\n\tu32 reg2, mod_reg2;\n\n\tmutex_lock(&i915->display.pmdemand.lock);\n\tif (drm_WARN_ON(&i915->drm,\n\t\t\t!intel_pmdemand_check_prev_transaction(i915)))\n\t\tgoto unlock;\n\n\treg1 = intel_de_read(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(0));\n\tmod_reg1 = reg1;\n\n\treg2 = intel_de_read(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(1));\n\tmod_reg2 = reg2;\n\n\tintel_pmdemand_update_params(new, old, &mod_reg1, &mod_reg2,\n\t\t\t\t     serialized);\n\n\tif (reg1 != mod_reg1) {\n\t\tintel_de_write(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(0),\n\t\t\t       mod_reg1);\n\t\tchanged = true;\n\t}\n\n\tif (reg2 != mod_reg2) {\n\t\tintel_de_write(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(1),\n\t\t\t       mod_reg2);\n\t\tchanged = true;\n\t}\n\n\t \n\tif (!changed)\n\t\tgoto unlock;\n\n\tdrm_dbg_kms(&i915->drm,\n\t\t    \"initate pmdemand request values: (0x%x 0x%x)\\n\",\n\t\t    mod_reg1, mod_reg2);\n\n\tintel_de_rmw(i915, XELPDP_INITIATE_PMDEMAND_REQUEST(1), 0,\n\t\t     XELPDP_PMDEMAND_REQ_ENABLE);\n\n\tintel_pmdemand_wait(i915);\n\nunlock:\n\tmutex_unlock(&i915->display.pmdemand.lock);\n}\n\nstatic bool\nintel_pmdemand_state_changed(const struct intel_pmdemand_state *new,\n\t\t\t     const struct intel_pmdemand_state *old)\n{\n\treturn memcmp(&new->params, &old->params, sizeof(new->params)) != 0;\n}\n\nvoid intel_pmdemand_pre_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_pmdemand_state *new_pmdemand_state =\n\t\tintel_atomic_get_new_pmdemand_state(state);\n\tconst struct intel_pmdemand_state *old_pmdemand_state =\n\t\tintel_atomic_get_old_pmdemand_state(state);\n\n\tif (DISPLAY_VER(i915) < 14)\n\t\treturn;\n\n\tif (!new_pmdemand_state ||\n\t    !intel_pmdemand_state_changed(new_pmdemand_state,\n\t\t\t\t\t  old_pmdemand_state))\n\t\treturn;\n\n\tWARN_ON(!new_pmdemand_state->base.changed);\n\n\tintel_pmdemand_program_params(i915, new_pmdemand_state,\n\t\t\t\t      old_pmdemand_state,\n\t\t\t\t      intel_atomic_global_state_is_serialized(state));\n}\n\nvoid intel_pmdemand_post_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_pmdemand_state *new_pmdemand_state =\n\t\tintel_atomic_get_new_pmdemand_state(state);\n\tconst struct intel_pmdemand_state *old_pmdemand_state =\n\t\tintel_atomic_get_old_pmdemand_state(state);\n\n\tif (DISPLAY_VER(i915) < 14)\n\t\treturn;\n\n\tif (!new_pmdemand_state ||\n\t    !intel_pmdemand_state_changed(new_pmdemand_state,\n\t\t\t\t\t  old_pmdemand_state))\n\t\treturn;\n\n\tWARN_ON(!new_pmdemand_state->base.changed);\n\n\tintel_pmdemand_program_params(i915, new_pmdemand_state, NULL,\n\t\t\t\t      intel_atomic_global_state_is_serialized(state));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}