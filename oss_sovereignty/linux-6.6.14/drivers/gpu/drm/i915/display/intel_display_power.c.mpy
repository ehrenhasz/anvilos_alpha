{
  "module_name": "intel_display_power.c",
  "hash_id": "e37e94c386b21812363f888892a2b1682a4f37f6a420f9595d1d3c89d80dc412",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/display/intel_display_power.c",
  "human_readable_source": " \n \n\n#include <linux/string_helpers.h>\n\n#include \"i915_drv.h\"\n#include \"i915_irq.h\"\n#include \"i915_reg.h\"\n#include \"intel_backlight_regs.h\"\n#include \"intel_cdclk.h\"\n#include \"intel_clock_gating.h\"\n#include \"intel_combo_phy.h\"\n#include \"intel_de.h\"\n#include \"intel_display_power.h\"\n#include \"intel_display_power_map.h\"\n#include \"intel_display_power_well.h\"\n#include \"intel_display_types.h\"\n#include \"intel_dmc.h\"\n#include \"intel_mchbar_regs.h\"\n#include \"intel_pch_refclk.h\"\n#include \"intel_pcode.h\"\n#include \"intel_pmdemand.h\"\n#include \"intel_pps_regs.h\"\n#include \"intel_snps_phy.h\"\n#include \"skl_watermark.h\"\n#include \"skl_watermark_regs.h\"\n#include \"vlv_sideband.h\"\n\n#define for_each_power_domain_well(__dev_priv, __power_well, __domain)\t\\\n\tfor_each_power_well(__dev_priv, __power_well)\t\t\t\t\\\n\t\tfor_each_if(test_bit((__domain), (__power_well)->domains.bits))\n\n#define for_each_power_domain_well_reverse(__dev_priv, __power_well, __domain) \\\n\tfor_each_power_well_reverse(__dev_priv, __power_well)\t\t        \\\n\t\tfor_each_if(test_bit((__domain), (__power_well)->domains.bits))\n\nconst char *\nintel_display_power_domain_str(enum intel_display_power_domain domain)\n{\n\tswitch (domain) {\n\tcase POWER_DOMAIN_DISPLAY_CORE:\n\t\treturn \"DISPLAY_CORE\";\n\tcase POWER_DOMAIN_PIPE_A:\n\t\treturn \"PIPE_A\";\n\tcase POWER_DOMAIN_PIPE_B:\n\t\treturn \"PIPE_B\";\n\tcase POWER_DOMAIN_PIPE_C:\n\t\treturn \"PIPE_C\";\n\tcase POWER_DOMAIN_PIPE_D:\n\t\treturn \"PIPE_D\";\n\tcase POWER_DOMAIN_PIPE_PANEL_FITTER_A:\n\t\treturn \"PIPE_PANEL_FITTER_A\";\n\tcase POWER_DOMAIN_PIPE_PANEL_FITTER_B:\n\t\treturn \"PIPE_PANEL_FITTER_B\";\n\tcase POWER_DOMAIN_PIPE_PANEL_FITTER_C:\n\t\treturn \"PIPE_PANEL_FITTER_C\";\n\tcase POWER_DOMAIN_PIPE_PANEL_FITTER_D:\n\t\treturn \"PIPE_PANEL_FITTER_D\";\n\tcase POWER_DOMAIN_TRANSCODER_A:\n\t\treturn \"TRANSCODER_A\";\n\tcase POWER_DOMAIN_TRANSCODER_B:\n\t\treturn \"TRANSCODER_B\";\n\tcase POWER_DOMAIN_TRANSCODER_C:\n\t\treturn \"TRANSCODER_C\";\n\tcase POWER_DOMAIN_TRANSCODER_D:\n\t\treturn \"TRANSCODER_D\";\n\tcase POWER_DOMAIN_TRANSCODER_EDP:\n\t\treturn \"TRANSCODER_EDP\";\n\tcase POWER_DOMAIN_TRANSCODER_DSI_A:\n\t\treturn \"TRANSCODER_DSI_A\";\n\tcase POWER_DOMAIN_TRANSCODER_DSI_C:\n\t\treturn \"TRANSCODER_DSI_C\";\n\tcase POWER_DOMAIN_TRANSCODER_VDSC_PW2:\n\t\treturn \"TRANSCODER_VDSC_PW2\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_A:\n\t\treturn \"PORT_DDI_LANES_A\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_B:\n\t\treturn \"PORT_DDI_LANES_B\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_C:\n\t\treturn \"PORT_DDI_LANES_C\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_D:\n\t\treturn \"PORT_DDI_LANES_D\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_E:\n\t\treturn \"PORT_DDI_LANES_E\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_F:\n\t\treturn \"PORT_DDI_LANES_F\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_TC1:\n\t\treturn \"PORT_DDI_LANES_TC1\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_TC2:\n\t\treturn \"PORT_DDI_LANES_TC2\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_TC3:\n\t\treturn \"PORT_DDI_LANES_TC3\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_TC4:\n\t\treturn \"PORT_DDI_LANES_TC4\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_TC5:\n\t\treturn \"PORT_DDI_LANES_TC5\";\n\tcase POWER_DOMAIN_PORT_DDI_LANES_TC6:\n\t\treturn \"PORT_DDI_LANES_TC6\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_A:\n\t\treturn \"PORT_DDI_IO_A\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_B:\n\t\treturn \"PORT_DDI_IO_B\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_C:\n\t\treturn \"PORT_DDI_IO_C\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_D:\n\t\treturn \"PORT_DDI_IO_D\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_E:\n\t\treturn \"PORT_DDI_IO_E\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_F:\n\t\treturn \"PORT_DDI_IO_F\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_TC1:\n\t\treturn \"PORT_DDI_IO_TC1\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_TC2:\n\t\treturn \"PORT_DDI_IO_TC2\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_TC3:\n\t\treturn \"PORT_DDI_IO_TC3\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_TC4:\n\t\treturn \"PORT_DDI_IO_TC4\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_TC5:\n\t\treturn \"PORT_DDI_IO_TC5\";\n\tcase POWER_DOMAIN_PORT_DDI_IO_TC6:\n\t\treturn \"PORT_DDI_IO_TC6\";\n\tcase POWER_DOMAIN_PORT_DSI:\n\t\treturn \"PORT_DSI\";\n\tcase POWER_DOMAIN_PORT_CRT:\n\t\treturn \"PORT_CRT\";\n\tcase POWER_DOMAIN_PORT_OTHER:\n\t\treturn \"PORT_OTHER\";\n\tcase POWER_DOMAIN_VGA:\n\t\treturn \"VGA\";\n\tcase POWER_DOMAIN_AUDIO_MMIO:\n\t\treturn \"AUDIO_MMIO\";\n\tcase POWER_DOMAIN_AUDIO_PLAYBACK:\n\t\treturn \"AUDIO_PLAYBACK\";\n\tcase POWER_DOMAIN_AUX_IO_A:\n\t\treturn \"AUX_IO_A\";\n\tcase POWER_DOMAIN_AUX_IO_B:\n\t\treturn \"AUX_IO_B\";\n\tcase POWER_DOMAIN_AUX_IO_C:\n\t\treturn \"AUX_IO_C\";\n\tcase POWER_DOMAIN_AUX_IO_D:\n\t\treturn \"AUX_IO_D\";\n\tcase POWER_DOMAIN_AUX_IO_E:\n\t\treturn \"AUX_IO_E\";\n\tcase POWER_DOMAIN_AUX_IO_F:\n\t\treturn \"AUX_IO_F\";\n\tcase POWER_DOMAIN_AUX_A:\n\t\treturn \"AUX_A\";\n\tcase POWER_DOMAIN_AUX_B:\n\t\treturn \"AUX_B\";\n\tcase POWER_DOMAIN_AUX_C:\n\t\treturn \"AUX_C\";\n\tcase POWER_DOMAIN_AUX_D:\n\t\treturn \"AUX_D\";\n\tcase POWER_DOMAIN_AUX_E:\n\t\treturn \"AUX_E\";\n\tcase POWER_DOMAIN_AUX_F:\n\t\treturn \"AUX_F\";\n\tcase POWER_DOMAIN_AUX_USBC1:\n\t\treturn \"AUX_USBC1\";\n\tcase POWER_DOMAIN_AUX_USBC2:\n\t\treturn \"AUX_USBC2\";\n\tcase POWER_DOMAIN_AUX_USBC3:\n\t\treturn \"AUX_USBC3\";\n\tcase POWER_DOMAIN_AUX_USBC4:\n\t\treturn \"AUX_USBC4\";\n\tcase POWER_DOMAIN_AUX_USBC5:\n\t\treturn \"AUX_USBC5\";\n\tcase POWER_DOMAIN_AUX_USBC6:\n\t\treturn \"AUX_USBC6\";\n\tcase POWER_DOMAIN_AUX_TBT1:\n\t\treturn \"AUX_TBT1\";\n\tcase POWER_DOMAIN_AUX_TBT2:\n\t\treturn \"AUX_TBT2\";\n\tcase POWER_DOMAIN_AUX_TBT3:\n\t\treturn \"AUX_TBT3\";\n\tcase POWER_DOMAIN_AUX_TBT4:\n\t\treturn \"AUX_TBT4\";\n\tcase POWER_DOMAIN_AUX_TBT5:\n\t\treturn \"AUX_TBT5\";\n\tcase POWER_DOMAIN_AUX_TBT6:\n\t\treturn \"AUX_TBT6\";\n\tcase POWER_DOMAIN_GMBUS:\n\t\treturn \"GMBUS\";\n\tcase POWER_DOMAIN_INIT:\n\t\treturn \"INIT\";\n\tcase POWER_DOMAIN_MODESET:\n\t\treturn \"MODESET\";\n\tcase POWER_DOMAIN_GT_IRQ:\n\t\treturn \"GT_IRQ\";\n\tcase POWER_DOMAIN_DC_OFF:\n\t\treturn \"DC_OFF\";\n\tcase POWER_DOMAIN_TC_COLD_OFF:\n\t\treturn \"TC_COLD_OFF\";\n\tdefault:\n\t\tMISSING_CASE(domain);\n\t\treturn \"?\";\n\t}\n}\n\n \nbool __intel_display_power_is_enabled(struct drm_i915_private *dev_priv,\n\t\t\t\t      enum intel_display_power_domain domain)\n{\n\tstruct i915_power_well *power_well;\n\tbool is_enabled;\n\n\tif (dev_priv->runtime_pm.suspended)\n\t\treturn false;\n\n\tis_enabled = true;\n\n\tfor_each_power_domain_well_reverse(dev_priv, power_well, domain) {\n\t\tif (intel_power_well_is_always_on(power_well))\n\t\t\tcontinue;\n\n\t\tif (!intel_power_well_is_enabled_cached(power_well)) {\n\t\t\tis_enabled = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn is_enabled;\n}\n\n \nbool intel_display_power_is_enabled(struct drm_i915_private *dev_priv,\n\t\t\t\t    enum intel_display_power_domain domain)\n{\n\tstruct i915_power_domains *power_domains;\n\tbool ret;\n\n\tpower_domains = &dev_priv->display.power.domains;\n\n\tmutex_lock(&power_domains->lock);\n\tret = __intel_display_power_is_enabled(dev_priv, domain);\n\tmutex_unlock(&power_domains->lock);\n\n\treturn ret;\n}\n\nstatic u32\nsanitize_target_dc_state(struct drm_i915_private *i915,\n\t\t\t u32 target_dc_state)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tstatic const u32 states[] = {\n\t\tDC_STATE_EN_UPTO_DC6,\n\t\tDC_STATE_EN_UPTO_DC5,\n\t\tDC_STATE_EN_DC3CO,\n\t\tDC_STATE_DISABLE,\n\t};\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(states) - 1; i++) {\n\t\tif (target_dc_state != states[i])\n\t\t\tcontinue;\n\n\t\tif (power_domains->allowed_dc_mask & target_dc_state)\n\t\t\tbreak;\n\n\t\ttarget_dc_state = states[i + 1];\n\t}\n\n\treturn target_dc_state;\n}\n\n \nvoid intel_display_power_set_target_dc_state(struct drm_i915_private *dev_priv,\n\t\t\t\t\t     u32 state)\n{\n\tstruct i915_power_well *power_well;\n\tbool dc_off_enabled;\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\n\tmutex_lock(&power_domains->lock);\n\tpower_well = lookup_power_well(dev_priv, SKL_DISP_DC_OFF);\n\n\tif (drm_WARN_ON(&dev_priv->drm, !power_well))\n\t\tgoto unlock;\n\n\tstate = sanitize_target_dc_state(dev_priv, state);\n\n\tif (state == power_domains->target_dc_state)\n\t\tgoto unlock;\n\n\tdc_off_enabled = intel_power_well_is_enabled(dev_priv, power_well);\n\t \n\tif (!dc_off_enabled)\n\t\tintel_power_well_enable(dev_priv, power_well);\n\n\tpower_domains->target_dc_state = state;\n\n\tif (!dc_off_enabled)\n\t\tintel_power_well_disable(dev_priv, power_well);\n\nunlock:\n\tmutex_unlock(&power_domains->lock);\n}\n\n#define POWER_DOMAIN_MASK (GENMASK_ULL(POWER_DOMAIN_NUM - 1, 0))\n\nstatic void __async_put_domains_mask(struct i915_power_domains *power_domains,\n\t\t\t\t     struct intel_power_domain_mask *mask)\n{\n\tbitmap_or(mask->bits,\n\t\t  power_domains->async_put_domains[0].bits,\n\t\t  power_domains->async_put_domains[1].bits,\n\t\t  POWER_DOMAIN_NUM);\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_DEBUG_RUNTIME_PM)\n\nstatic bool\nassert_async_put_domain_masks_disjoint(struct i915_power_domains *power_domains)\n{\n\tstruct drm_i915_private *i915 = container_of(power_domains,\n\t\t\t\t\t\t     struct drm_i915_private,\n\t\t\t\t\t\t     display.power.domains);\n\n\treturn !drm_WARN_ON(&i915->drm,\n\t\t\t    bitmap_intersects(power_domains->async_put_domains[0].bits,\n\t\t\t\t\t      power_domains->async_put_domains[1].bits,\n\t\t\t\t\t      POWER_DOMAIN_NUM));\n}\n\nstatic bool\n__async_put_domains_state_ok(struct i915_power_domains *power_domains)\n{\n\tstruct drm_i915_private *i915 = container_of(power_domains,\n\t\t\t\t\t\t     struct drm_i915_private,\n\t\t\t\t\t\t     display.power.domains);\n\tstruct intel_power_domain_mask async_put_mask;\n\tenum intel_display_power_domain domain;\n\tbool err = false;\n\n\terr |= !assert_async_put_domain_masks_disjoint(power_domains);\n\t__async_put_domains_mask(power_domains, &async_put_mask);\n\terr |= drm_WARN_ON(&i915->drm,\n\t\t\t   !!power_domains->async_put_wakeref !=\n\t\t\t   !bitmap_empty(async_put_mask.bits, POWER_DOMAIN_NUM));\n\n\tfor_each_power_domain(domain, &async_put_mask)\n\t\terr |= drm_WARN_ON(&i915->drm,\n\t\t\t\t   power_domains->domain_use_count[domain] != 1);\n\n\treturn !err;\n}\n\nstatic void print_power_domains(struct i915_power_domains *power_domains,\n\t\t\t\tconst char *prefix, struct intel_power_domain_mask *mask)\n{\n\tstruct drm_i915_private *i915 = container_of(power_domains,\n\t\t\t\t\t\t     struct drm_i915_private,\n\t\t\t\t\t\t     display.power.domains);\n\tenum intel_display_power_domain domain;\n\n\tdrm_dbg(&i915->drm, \"%s (%d):\\n\", prefix, bitmap_weight(mask->bits, POWER_DOMAIN_NUM));\n\tfor_each_power_domain(domain, mask)\n\t\tdrm_dbg(&i915->drm, \"%s use_count %d\\n\",\n\t\t\tintel_display_power_domain_str(domain),\n\t\t\tpower_domains->domain_use_count[domain]);\n}\n\nstatic void\nprint_async_put_domains_state(struct i915_power_domains *power_domains)\n{\n\tstruct drm_i915_private *i915 = container_of(power_domains,\n\t\t\t\t\t\t     struct drm_i915_private,\n\t\t\t\t\t\t     display.power.domains);\n\n\tdrm_dbg(&i915->drm, \"async_put_wakeref %u\\n\",\n\t\tpower_domains->async_put_wakeref);\n\n\tprint_power_domains(power_domains, \"async_put_domains[0]\",\n\t\t\t    &power_domains->async_put_domains[0]);\n\tprint_power_domains(power_domains, \"async_put_domains[1]\",\n\t\t\t    &power_domains->async_put_domains[1]);\n}\n\nstatic void\nverify_async_put_domains_state(struct i915_power_domains *power_domains)\n{\n\tif (!__async_put_domains_state_ok(power_domains))\n\t\tprint_async_put_domains_state(power_domains);\n}\n\n#else\n\nstatic void\nassert_async_put_domain_masks_disjoint(struct i915_power_domains *power_domains)\n{\n}\n\nstatic void\nverify_async_put_domains_state(struct i915_power_domains *power_domains)\n{\n}\n\n#endif  \n\nstatic void async_put_domains_mask(struct i915_power_domains *power_domains,\n\t\t\t\t   struct intel_power_domain_mask *mask)\n\n{\n\tassert_async_put_domain_masks_disjoint(power_domains);\n\n\t__async_put_domains_mask(power_domains, mask);\n}\n\nstatic void\nasync_put_domains_clear_domain(struct i915_power_domains *power_domains,\n\t\t\t       enum intel_display_power_domain domain)\n{\n\tassert_async_put_domain_masks_disjoint(power_domains);\n\n\tclear_bit(domain, power_domains->async_put_domains[0].bits);\n\tclear_bit(domain, power_domains->async_put_domains[1].bits);\n}\n\nstatic void\ncancel_async_put_work(struct i915_power_domains *power_domains, bool sync)\n{\n\tif (sync)\n\t\tcancel_delayed_work_sync(&power_domains->async_put_work);\n\telse\n\t\tcancel_delayed_work(&power_domains->async_put_work);\n\n\tpower_domains->async_put_next_delay = 0;\n}\n\nstatic bool\nintel_display_power_grab_async_put_ref(struct drm_i915_private *dev_priv,\n\t\t\t\t       enum intel_display_power_domain domain)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct intel_power_domain_mask async_put_mask;\n\tbool ret = false;\n\n\tasync_put_domains_mask(power_domains, &async_put_mask);\n\tif (!test_bit(domain, async_put_mask.bits))\n\t\tgoto out_verify;\n\n\tasync_put_domains_clear_domain(power_domains, domain);\n\n\tret = true;\n\n\tasync_put_domains_mask(power_domains, &async_put_mask);\n\tif (!bitmap_empty(async_put_mask.bits, POWER_DOMAIN_NUM))\n\t\tgoto out_verify;\n\n\tcancel_async_put_work(power_domains, false);\n\tintel_runtime_pm_put_raw(&dev_priv->runtime_pm,\n\t\t\t\t fetch_and_zero(&power_domains->async_put_wakeref));\nout_verify:\n\tverify_async_put_domains_state(power_domains);\n\n\treturn ret;\n}\n\nstatic void\n__intel_display_power_get_domain(struct drm_i915_private *dev_priv,\n\t\t\t\t enum intel_display_power_domain domain)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *power_well;\n\n\tif (intel_display_power_grab_async_put_ref(dev_priv, domain))\n\t\treturn;\n\n\tfor_each_power_domain_well(dev_priv, power_well, domain)\n\t\tintel_power_well_get(dev_priv, power_well);\n\n\tpower_domains->domain_use_count[domain]++;\n}\n\n \nintel_wakeref_t intel_display_power_get(struct drm_i915_private *dev_priv,\n\t\t\t\t\tenum intel_display_power_domain domain)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tintel_wakeref_t wakeref = intel_runtime_pm_get(&dev_priv->runtime_pm);\n\n\tmutex_lock(&power_domains->lock);\n\t__intel_display_power_get_domain(dev_priv, domain);\n\tmutex_unlock(&power_domains->lock);\n\n\treturn wakeref;\n}\n\n \nintel_wakeref_t\nintel_display_power_get_if_enabled(struct drm_i915_private *dev_priv,\n\t\t\t\t   enum intel_display_power_domain domain)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tintel_wakeref_t wakeref;\n\tbool is_enabled;\n\n\twakeref = intel_runtime_pm_get_if_in_use(&dev_priv->runtime_pm);\n\tif (!wakeref)\n\t\treturn false;\n\n\tmutex_lock(&power_domains->lock);\n\n\tif (__intel_display_power_is_enabled(dev_priv, domain)) {\n\t\t__intel_display_power_get_domain(dev_priv, domain);\n\t\tis_enabled = true;\n\t} else {\n\t\tis_enabled = false;\n\t}\n\n\tmutex_unlock(&power_domains->lock);\n\n\tif (!is_enabled) {\n\t\tintel_runtime_pm_put(&dev_priv->runtime_pm, wakeref);\n\t\twakeref = 0;\n\t}\n\n\treturn wakeref;\n}\n\nstatic void\n__intel_display_power_put_domain(struct drm_i915_private *dev_priv,\n\t\t\t\t enum intel_display_power_domain domain)\n{\n\tstruct i915_power_domains *power_domains;\n\tstruct i915_power_well *power_well;\n\tconst char *name = intel_display_power_domain_str(domain);\n\tstruct intel_power_domain_mask async_put_mask;\n\n\tpower_domains = &dev_priv->display.power.domains;\n\n\tdrm_WARN(&dev_priv->drm, !power_domains->domain_use_count[domain],\n\t\t \"Use count on domain %s is already zero\\n\",\n\t\t name);\n\tasync_put_domains_mask(power_domains, &async_put_mask);\n\tdrm_WARN(&dev_priv->drm,\n\t\t test_bit(domain, async_put_mask.bits),\n\t\t \"Async disabling of domain %s is pending\\n\",\n\t\t name);\n\n\tpower_domains->domain_use_count[domain]--;\n\n\tfor_each_power_domain_well_reverse(dev_priv, power_well, domain)\n\t\tintel_power_well_put(dev_priv, power_well);\n}\n\nstatic void __intel_display_power_put(struct drm_i915_private *dev_priv,\n\t\t\t\t      enum intel_display_power_domain domain)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\n\tmutex_lock(&power_domains->lock);\n\t__intel_display_power_put_domain(dev_priv, domain);\n\tmutex_unlock(&power_domains->lock);\n}\n\nstatic void\nqueue_async_put_domains_work(struct i915_power_domains *power_domains,\n\t\t\t     intel_wakeref_t wakeref,\n\t\t\t     int delay_ms)\n{\n\tstruct drm_i915_private *i915 = container_of(power_domains,\n\t\t\t\t\t\t     struct drm_i915_private,\n\t\t\t\t\t\t     display.power.domains);\n\tdrm_WARN_ON(&i915->drm, power_domains->async_put_wakeref);\n\tpower_domains->async_put_wakeref = wakeref;\n\tdrm_WARN_ON(&i915->drm, !queue_delayed_work(system_unbound_wq,\n\t\t\t\t\t\t    &power_domains->async_put_work,\n\t\t\t\t\t\t    msecs_to_jiffies(delay_ms)));\n}\n\nstatic void\nrelease_async_put_domains(struct i915_power_domains *power_domains,\n\t\t\t  struct intel_power_domain_mask *mask)\n{\n\tstruct drm_i915_private *dev_priv =\n\t\tcontainer_of(power_domains, struct drm_i915_private,\n\t\t\t     display.power.domains);\n\tstruct intel_runtime_pm *rpm = &dev_priv->runtime_pm;\n\tenum intel_display_power_domain domain;\n\tintel_wakeref_t wakeref;\n\n\t \n\tassert_rpm_raw_wakeref_held(rpm);\n\twakeref = intel_runtime_pm_get(rpm);\n\n\tfor_each_power_domain(domain, mask) {\n\t\t \n\t\tasync_put_domains_clear_domain(power_domains, domain);\n\t\t__intel_display_power_put_domain(dev_priv, domain);\n\t}\n\n\tintel_runtime_pm_put(rpm, wakeref);\n}\n\nstatic void\nintel_display_power_put_async_work(struct work_struct *work)\n{\n\tstruct drm_i915_private *dev_priv =\n\t\tcontainer_of(work, struct drm_i915_private,\n\t\t\t     display.power.domains.async_put_work.work);\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct intel_runtime_pm *rpm = &dev_priv->runtime_pm;\n\tintel_wakeref_t new_work_wakeref = intel_runtime_pm_get_raw(rpm);\n\tintel_wakeref_t old_work_wakeref = 0;\n\n\tmutex_lock(&power_domains->lock);\n\n\t \n\told_work_wakeref = fetch_and_zero(&power_domains->async_put_wakeref);\n\tif (!old_work_wakeref)\n\t\tgoto out_verify;\n\n\trelease_async_put_domains(power_domains,\n\t\t\t\t  &power_domains->async_put_domains[0]);\n\n\t \n\tif (!bitmap_empty(power_domains->async_put_domains[1].bits, POWER_DOMAIN_NUM)) {\n\t\tbitmap_copy(power_domains->async_put_domains[0].bits,\n\t\t\t    power_domains->async_put_domains[1].bits,\n\t\t\t    POWER_DOMAIN_NUM);\n\t\tbitmap_zero(power_domains->async_put_domains[1].bits,\n\t\t\t    POWER_DOMAIN_NUM);\n\t\tqueue_async_put_domains_work(power_domains,\n\t\t\t\t\t     fetch_and_zero(&new_work_wakeref),\n\t\t\t\t\t     power_domains->async_put_next_delay);\n\t\tpower_domains->async_put_next_delay = 0;\n\t} else {\n\t\t \n\t\tcancel_async_put_work(power_domains, false);\n\t}\n\nout_verify:\n\tverify_async_put_domains_state(power_domains);\n\n\tmutex_unlock(&power_domains->lock);\n\n\tif (old_work_wakeref)\n\t\tintel_runtime_pm_put_raw(rpm, old_work_wakeref);\n\tif (new_work_wakeref)\n\t\tintel_runtime_pm_put_raw(rpm, new_work_wakeref);\n}\n\n \nvoid __intel_display_power_put_async(struct drm_i915_private *i915,\n\t\t\t\t     enum intel_display_power_domain domain,\n\t\t\t\t     intel_wakeref_t wakeref,\n\t\t\t\t     int delay_ms)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tstruct intel_runtime_pm *rpm = &i915->runtime_pm;\n\tintel_wakeref_t work_wakeref = intel_runtime_pm_get_raw(rpm);\n\n\tdelay_ms = delay_ms >= 0 ? delay_ms : 100;\n\n\tmutex_lock(&power_domains->lock);\n\n\tif (power_domains->domain_use_count[domain] > 1) {\n\t\t__intel_display_power_put_domain(i915, domain);\n\n\t\tgoto out_verify;\n\t}\n\n\tdrm_WARN_ON(&i915->drm, power_domains->domain_use_count[domain] != 1);\n\n\t \n\tif (power_domains->async_put_wakeref) {\n\t\tset_bit(domain, power_domains->async_put_domains[1].bits);\n\t\tpower_domains->async_put_next_delay = max(power_domains->async_put_next_delay,\n\t\t\t\t\t\t\t  delay_ms);\n\t} else {\n\t\tset_bit(domain, power_domains->async_put_domains[0].bits);\n\t\tqueue_async_put_domains_work(power_domains,\n\t\t\t\t\t     fetch_and_zero(&work_wakeref),\n\t\t\t\t\t     delay_ms);\n\t}\n\nout_verify:\n\tverify_async_put_domains_state(power_domains);\n\n\tmutex_unlock(&power_domains->lock);\n\n\tif (work_wakeref)\n\t\tintel_runtime_pm_put_raw(rpm, work_wakeref);\n\n\tintel_runtime_pm_put(rpm, wakeref);\n}\n\n \nvoid intel_display_power_flush_work(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tstruct intel_power_domain_mask async_put_mask;\n\tintel_wakeref_t work_wakeref;\n\n\tmutex_lock(&power_domains->lock);\n\n\twork_wakeref = fetch_and_zero(&power_domains->async_put_wakeref);\n\tif (!work_wakeref)\n\t\tgoto out_verify;\n\n\tasync_put_domains_mask(power_domains, &async_put_mask);\n\trelease_async_put_domains(power_domains, &async_put_mask);\n\tcancel_async_put_work(power_domains, false);\n\nout_verify:\n\tverify_async_put_domains_state(power_domains);\n\n\tmutex_unlock(&power_domains->lock);\n\n\tif (work_wakeref)\n\t\tintel_runtime_pm_put_raw(&i915->runtime_pm, work_wakeref);\n}\n\n \nstatic void\nintel_display_power_flush_work_sync(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\n\tintel_display_power_flush_work(i915);\n\tcancel_async_put_work(power_domains, true);\n\n\tverify_async_put_domains_state(power_domains);\n\n\tdrm_WARN_ON(&i915->drm, power_domains->async_put_wakeref);\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_DEBUG_RUNTIME_PM)\n \nvoid intel_display_power_put(struct drm_i915_private *dev_priv,\n\t\t\t     enum intel_display_power_domain domain,\n\t\t\t     intel_wakeref_t wakeref)\n{\n\t__intel_display_power_put(dev_priv, domain);\n\tintel_runtime_pm_put(&dev_priv->runtime_pm, wakeref);\n}\n#else\n \nvoid intel_display_power_put_unchecked(struct drm_i915_private *dev_priv,\n\t\t\t\t       enum intel_display_power_domain domain)\n{\n\t__intel_display_power_put(dev_priv, domain);\n\tintel_runtime_pm_put_unchecked(&dev_priv->runtime_pm);\n}\n#endif\n\nvoid\nintel_display_power_get_in_set(struct drm_i915_private *i915,\n\t\t\t       struct intel_display_power_domain_set *power_domain_set,\n\t\t\t       enum intel_display_power_domain domain)\n{\n\tintel_wakeref_t __maybe_unused wf;\n\n\tdrm_WARN_ON(&i915->drm, test_bit(domain, power_domain_set->mask.bits));\n\n\twf = intel_display_power_get(i915, domain);\n#if IS_ENABLED(CONFIG_DRM_I915_DEBUG_RUNTIME_PM)\n\tpower_domain_set->wakerefs[domain] = wf;\n#endif\n\tset_bit(domain, power_domain_set->mask.bits);\n}\n\nbool\nintel_display_power_get_in_set_if_enabled(struct drm_i915_private *i915,\n\t\t\t\t\t  struct intel_display_power_domain_set *power_domain_set,\n\t\t\t\t\t  enum intel_display_power_domain domain)\n{\n\tintel_wakeref_t wf;\n\n\tdrm_WARN_ON(&i915->drm, test_bit(domain, power_domain_set->mask.bits));\n\n\twf = intel_display_power_get_if_enabled(i915, domain);\n\tif (!wf)\n\t\treturn false;\n\n#if IS_ENABLED(CONFIG_DRM_I915_DEBUG_RUNTIME_PM)\n\tpower_domain_set->wakerefs[domain] = wf;\n#endif\n\tset_bit(domain, power_domain_set->mask.bits);\n\n\treturn true;\n}\n\nvoid\nintel_display_power_put_mask_in_set(struct drm_i915_private *i915,\n\t\t\t\t    struct intel_display_power_domain_set *power_domain_set,\n\t\t\t\t    struct intel_power_domain_mask *mask)\n{\n\tenum intel_display_power_domain domain;\n\n\tdrm_WARN_ON(&i915->drm,\n\t\t    !bitmap_subset(mask->bits, power_domain_set->mask.bits, POWER_DOMAIN_NUM));\n\n\tfor_each_power_domain(domain, mask) {\n\t\tintel_wakeref_t __maybe_unused wf = -1;\n\n#if IS_ENABLED(CONFIG_DRM_I915_DEBUG_RUNTIME_PM)\n\t\twf = fetch_and_zero(&power_domain_set->wakerefs[domain]);\n#endif\n\t\tintel_display_power_put(i915, domain, wf);\n\t\tclear_bit(domain, power_domain_set->mask.bits);\n\t}\n}\n\nstatic int\nsanitize_disable_power_well_option(const struct drm_i915_private *dev_priv,\n\t\t\t\t   int disable_power_well)\n{\n\tif (disable_power_well >= 0)\n\t\treturn !!disable_power_well;\n\n\treturn 1;\n}\n\nstatic u32 get_allowed_dc_mask(const struct drm_i915_private *dev_priv,\n\t\t\t       int enable_dc)\n{\n\tu32 mask;\n\tint requested_dc;\n\tint max_dc;\n\n\tif (!HAS_DISPLAY(dev_priv))\n\t\treturn 0;\n\n\tif (IS_DG2(dev_priv))\n\t\tmax_dc = 1;\n\telse if (IS_DG1(dev_priv))\n\t\tmax_dc = 3;\n\telse if (DISPLAY_VER(dev_priv) >= 12)\n\t\tmax_dc = 4;\n\telse if (IS_GEMINILAKE(dev_priv) || IS_BROXTON(dev_priv))\n\t\tmax_dc = 1;\n\telse if (DISPLAY_VER(dev_priv) >= 9)\n\t\tmax_dc = 2;\n\telse\n\t\tmax_dc = 0;\n\n\t \n\tmask = IS_GEMINILAKE(dev_priv) || IS_BROXTON(dev_priv) ||\n\t\tDISPLAY_VER(dev_priv) >= 11 ?\n\t       DC_STATE_EN_DC9 : 0;\n\n\tif (!dev_priv->params.disable_power_well)\n\t\tmax_dc = 0;\n\n\tif (enable_dc >= 0 && enable_dc <= max_dc) {\n\t\trequested_dc = enable_dc;\n\t} else if (enable_dc == -1) {\n\t\trequested_dc = max_dc;\n\t} else if (enable_dc > max_dc && enable_dc <= 4) {\n\t\tdrm_dbg_kms(&dev_priv->drm,\n\t\t\t    \"Adjusting requested max DC state (%d->%d)\\n\",\n\t\t\t    enable_dc, max_dc);\n\t\trequested_dc = max_dc;\n\t} else {\n\t\tdrm_err(&dev_priv->drm,\n\t\t\t\"Unexpected value for enable_dc (%d)\\n\", enable_dc);\n\t\trequested_dc = max_dc;\n\t}\n\n\tswitch (requested_dc) {\n\tcase 4:\n\t\tmask |= DC_STATE_EN_DC3CO | DC_STATE_EN_UPTO_DC6;\n\t\tbreak;\n\tcase 3:\n\t\tmask |= DC_STATE_EN_DC3CO | DC_STATE_EN_UPTO_DC5;\n\t\tbreak;\n\tcase 2:\n\t\tmask |= DC_STATE_EN_UPTO_DC6;\n\t\tbreak;\n\tcase 1:\n\t\tmask |= DC_STATE_EN_UPTO_DC5;\n\t\tbreak;\n\t}\n\n\tdrm_dbg_kms(&dev_priv->drm, \"Allowed DC state mask %02x\\n\", mask);\n\n\treturn mask;\n}\n\n \nint intel_power_domains_init(struct drm_i915_private *dev_priv)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\n\tdev_priv->params.disable_power_well =\n\t\tsanitize_disable_power_well_option(dev_priv,\n\t\t\t\t\t\t   dev_priv->params.disable_power_well);\n\tpower_domains->allowed_dc_mask =\n\t\tget_allowed_dc_mask(dev_priv, dev_priv->params.enable_dc);\n\n\tpower_domains->target_dc_state =\n\t\tsanitize_target_dc_state(dev_priv, DC_STATE_EN_UPTO_DC6);\n\n\tmutex_init(&power_domains->lock);\n\n\tINIT_DELAYED_WORK(&power_domains->async_put_work,\n\t\t\t  intel_display_power_put_async_work);\n\n\treturn intel_display_power_map_init(power_domains);\n}\n\n \nvoid intel_power_domains_cleanup(struct drm_i915_private *dev_priv)\n{\n\tintel_display_power_map_cleanup(&dev_priv->display.power.domains);\n}\n\nstatic void intel_power_domains_sync_hw(struct drm_i915_private *dev_priv)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *power_well;\n\n\tmutex_lock(&power_domains->lock);\n\tfor_each_power_well(dev_priv, power_well)\n\t\tintel_power_well_sync_hw(dev_priv, power_well);\n\tmutex_unlock(&power_domains->lock);\n}\n\nstatic void gen9_dbuf_slice_set(struct drm_i915_private *dev_priv,\n\t\t\t\tenum dbuf_slice slice, bool enable)\n{\n\ti915_reg_t reg = DBUF_CTL_S(slice);\n\tbool state;\n\n\tintel_de_rmw(dev_priv, reg, DBUF_POWER_REQUEST,\n\t\t     enable ? DBUF_POWER_REQUEST : 0);\n\tintel_de_posting_read(dev_priv, reg);\n\tudelay(10);\n\n\tstate = intel_de_read(dev_priv, reg) & DBUF_POWER_STATE;\n\tdrm_WARN(&dev_priv->drm, enable != state,\n\t\t \"DBuf slice %d power %s timeout!\\n\",\n\t\t slice, str_enable_disable(enable));\n}\n\nvoid gen9_dbuf_slices_update(struct drm_i915_private *dev_priv,\n\t\t\t     u8 req_slices)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tu8 slice_mask = DISPLAY_INFO(dev_priv)->dbuf.slice_mask;\n\tenum dbuf_slice slice;\n\n\tdrm_WARN(&dev_priv->drm, req_slices & ~slice_mask,\n\t\t \"Invalid set of dbuf slices (0x%x) requested (total dbuf slices 0x%x)\\n\",\n\t\t req_slices, slice_mask);\n\n\tdrm_dbg_kms(&dev_priv->drm, \"Updating dbuf slices to 0x%x\\n\",\n\t\t    req_slices);\n\n\t \n\tmutex_lock(&power_domains->lock);\n\n\tfor_each_dbuf_slice(dev_priv, slice)\n\t\tgen9_dbuf_slice_set(dev_priv, slice, req_slices & BIT(slice));\n\n\tdev_priv->display.dbuf.enabled_slices = req_slices;\n\n\tmutex_unlock(&power_domains->lock);\n}\n\nstatic void gen9_dbuf_enable(struct drm_i915_private *dev_priv)\n{\n\tu8 slices_mask;\n\n\tdev_priv->display.dbuf.enabled_slices =\n\t\tintel_enabled_dbuf_slices_mask(dev_priv);\n\n\tslices_mask = BIT(DBUF_S1) | dev_priv->display.dbuf.enabled_slices;\n\n\tif (DISPLAY_VER(dev_priv) >= 14)\n\t\tintel_pmdemand_program_dbuf(dev_priv, slices_mask);\n\n\t \n\tgen9_dbuf_slices_update(dev_priv, slices_mask);\n}\n\nstatic void gen9_dbuf_disable(struct drm_i915_private *dev_priv)\n{\n\tgen9_dbuf_slices_update(dev_priv, 0);\n\n\tif (DISPLAY_VER(dev_priv) >= 14)\n\t\tintel_pmdemand_program_dbuf(dev_priv, 0);\n}\n\nstatic void gen12_dbuf_slices_config(struct drm_i915_private *dev_priv)\n{\n\tenum dbuf_slice slice;\n\n\tif (IS_ALDERLAKE_P(dev_priv))\n\t\treturn;\n\n\tfor_each_dbuf_slice(dev_priv, slice)\n\t\tintel_de_rmw(dev_priv, DBUF_CTL_S(slice),\n\t\t\t     DBUF_TRACKER_STATE_SERVICE_MASK,\n\t\t\t     DBUF_TRACKER_STATE_SERVICE(8));\n}\n\nstatic void icl_mbus_init(struct drm_i915_private *dev_priv)\n{\n\tunsigned long abox_regs = DISPLAY_INFO(dev_priv)->abox_mask;\n\tu32 mask, val, i;\n\n\tif (IS_ALDERLAKE_P(dev_priv) || DISPLAY_VER(dev_priv) >= 14)\n\t\treturn;\n\n\tmask = MBUS_ABOX_BT_CREDIT_POOL1_MASK |\n\t\tMBUS_ABOX_BT_CREDIT_POOL2_MASK |\n\t\tMBUS_ABOX_B_CREDIT_MASK |\n\t\tMBUS_ABOX_BW_CREDIT_MASK;\n\tval = MBUS_ABOX_BT_CREDIT_POOL1(16) |\n\t\tMBUS_ABOX_BT_CREDIT_POOL2(16) |\n\t\tMBUS_ABOX_B_CREDIT(1) |\n\t\tMBUS_ABOX_BW_CREDIT(1);\n\n\t \n\tif (DISPLAY_VER(dev_priv) == 12)\n\t\tabox_regs |= BIT(0);\n\n\tfor_each_set_bit(i, &abox_regs, sizeof(abox_regs))\n\t\tintel_de_rmw(dev_priv, MBUS_ABOX_CTL(i), mask, val);\n}\n\nstatic void hsw_assert_cdclk(struct drm_i915_private *dev_priv)\n{\n\tu32 val = intel_de_read(dev_priv, LCPLL_CTL);\n\n\t \n\n\tif (val & LCPLL_CD_SOURCE_FCLK)\n\t\tdrm_err(&dev_priv->drm, \"CDCLK source is not LCPLL\\n\");\n\n\tif (val & LCPLL_PLL_DISABLE)\n\t\tdrm_err(&dev_priv->drm, \"LCPLL is disabled\\n\");\n\n\tif ((val & LCPLL_REF_MASK) != LCPLL_REF_NON_SSC)\n\t\tdrm_err(&dev_priv->drm, \"LCPLL not using non-SSC reference\\n\");\n}\n\nstatic void assert_can_disable_lcpll(struct drm_i915_private *dev_priv)\n{\n\tstruct intel_crtc *crtc;\n\n\tfor_each_intel_crtc(&dev_priv->drm, crtc)\n\t\tI915_STATE_WARN(dev_priv, crtc->active,\n\t\t\t\t\"CRTC for pipe %c enabled\\n\",\n\t\t\t\tpipe_name(crtc->pipe));\n\n\tI915_STATE_WARN(dev_priv, intel_de_read(dev_priv, HSW_PWR_WELL_CTL2),\n\t\t\t\"Display power well on\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\tintel_de_read(dev_priv, SPLL_CTL) & SPLL_PLL_ENABLE,\n\t\t\t\"SPLL enabled\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\tintel_de_read(dev_priv, WRPLL_CTL(0)) & WRPLL_PLL_ENABLE,\n\t\t\t\"WRPLL1 enabled\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\tintel_de_read(dev_priv, WRPLL_CTL(1)) & WRPLL_PLL_ENABLE,\n\t\t\t\"WRPLL2 enabled\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\tintel_de_read(dev_priv, PP_STATUS(0)) & PP_ON,\n\t\t\t\"Panel power on\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\tintel_de_read(dev_priv, BLC_PWM_CPU_CTL2) & BLM_PWM_ENABLE,\n\t\t\t\"CPU PWM1 enabled\\n\");\n\tif (IS_HASWELL(dev_priv))\n\t\tI915_STATE_WARN(dev_priv,\n\t\t\t\tintel_de_read(dev_priv, HSW_BLC_PWM2_CTL) & BLM_PWM_ENABLE,\n\t\t\t\t\"CPU PWM2 enabled\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\tintel_de_read(dev_priv, BLC_PWM_PCH_CTL1) & BLM_PCH_PWM_ENABLE,\n\t\t\t\"PCH PWM1 enabled\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\t(intel_de_read(dev_priv, UTIL_PIN_CTL) & (UTIL_PIN_ENABLE | UTIL_PIN_MODE_MASK)) == (UTIL_PIN_ENABLE | UTIL_PIN_MODE_PWM),\n\t\t\t\"Utility pin enabled in PWM mode\\n\");\n\tI915_STATE_WARN(dev_priv,\n\t\t\tintel_de_read(dev_priv, PCH_GTC_CTL) & PCH_GTC_ENABLE,\n\t\t\t\"PCH GTC enabled\\n\");\n\n\t \n\tI915_STATE_WARN(dev_priv, intel_irqs_enabled(dev_priv),\n\t\t\t\"IRQs enabled\\n\");\n}\n\nstatic u32 hsw_read_dcomp(struct drm_i915_private *dev_priv)\n{\n\tif (IS_HASWELL(dev_priv))\n\t\treturn intel_de_read(dev_priv, D_COMP_HSW);\n\telse\n\t\treturn intel_de_read(dev_priv, D_COMP_BDW);\n}\n\nstatic void hsw_write_dcomp(struct drm_i915_private *dev_priv, u32 val)\n{\n\tif (IS_HASWELL(dev_priv)) {\n\t\tif (snb_pcode_write(&dev_priv->uncore, GEN6_PCODE_WRITE_D_COMP, val))\n\t\t\tdrm_dbg_kms(&dev_priv->drm,\n\t\t\t\t    \"Failed to write to D_COMP\\n\");\n\t} else {\n\t\tintel_de_write(dev_priv, D_COMP_BDW, val);\n\t\tintel_de_posting_read(dev_priv, D_COMP_BDW);\n\t}\n}\n\n \nstatic void hsw_disable_lcpll(struct drm_i915_private *dev_priv,\n\t\t\t      bool switch_to_fclk, bool allow_power_down)\n{\n\tu32 val;\n\n\tassert_can_disable_lcpll(dev_priv);\n\n\tval = intel_de_read(dev_priv, LCPLL_CTL);\n\n\tif (switch_to_fclk) {\n\t\tval |= LCPLL_CD_SOURCE_FCLK;\n\t\tintel_de_write(dev_priv, LCPLL_CTL, val);\n\n\t\tif (wait_for_us(intel_de_read(dev_priv, LCPLL_CTL) &\n\t\t\t\tLCPLL_CD_SOURCE_FCLK_DONE, 1))\n\t\t\tdrm_err(&dev_priv->drm, \"Switching to FCLK failed\\n\");\n\n\t\tval = intel_de_read(dev_priv, LCPLL_CTL);\n\t}\n\n\tval |= LCPLL_PLL_DISABLE;\n\tintel_de_write(dev_priv, LCPLL_CTL, val);\n\tintel_de_posting_read(dev_priv, LCPLL_CTL);\n\n\tif (intel_de_wait_for_clear(dev_priv, LCPLL_CTL, LCPLL_PLL_LOCK, 1))\n\t\tdrm_err(&dev_priv->drm, \"LCPLL still locked\\n\");\n\n\tval = hsw_read_dcomp(dev_priv);\n\tval |= D_COMP_COMP_DISABLE;\n\thsw_write_dcomp(dev_priv, val);\n\tndelay(100);\n\n\tif (wait_for((hsw_read_dcomp(dev_priv) &\n\t\t      D_COMP_RCOMP_IN_PROGRESS) == 0, 1))\n\t\tdrm_err(&dev_priv->drm, \"D_COMP RCOMP still in progress\\n\");\n\n\tif (allow_power_down) {\n\t\tintel_de_rmw(dev_priv, LCPLL_CTL, 0, LCPLL_POWER_DOWN_ALLOW);\n\t\tintel_de_posting_read(dev_priv, LCPLL_CTL);\n\t}\n}\n\n \nstatic void hsw_restore_lcpll(struct drm_i915_private *dev_priv)\n{\n\tu32 val;\n\n\tval = intel_de_read(dev_priv, LCPLL_CTL);\n\n\tif ((val & (LCPLL_PLL_LOCK | LCPLL_PLL_DISABLE | LCPLL_CD_SOURCE_FCLK |\n\t\t    LCPLL_POWER_DOWN_ALLOW)) == LCPLL_PLL_LOCK)\n\t\treturn;\n\n\t \n\tintel_uncore_forcewake_get(&dev_priv->uncore, FORCEWAKE_ALL);\n\n\tif (val & LCPLL_POWER_DOWN_ALLOW) {\n\t\tval &= ~LCPLL_POWER_DOWN_ALLOW;\n\t\tintel_de_write(dev_priv, LCPLL_CTL, val);\n\t\tintel_de_posting_read(dev_priv, LCPLL_CTL);\n\t}\n\n\tval = hsw_read_dcomp(dev_priv);\n\tval |= D_COMP_COMP_FORCE;\n\tval &= ~D_COMP_COMP_DISABLE;\n\thsw_write_dcomp(dev_priv, val);\n\n\tval = intel_de_read(dev_priv, LCPLL_CTL);\n\tval &= ~LCPLL_PLL_DISABLE;\n\tintel_de_write(dev_priv, LCPLL_CTL, val);\n\n\tif (intel_de_wait_for_set(dev_priv, LCPLL_CTL, LCPLL_PLL_LOCK, 5))\n\t\tdrm_err(&dev_priv->drm, \"LCPLL not locked yet\\n\");\n\n\tif (val & LCPLL_CD_SOURCE_FCLK) {\n\t\tintel_de_rmw(dev_priv, LCPLL_CTL, LCPLL_CD_SOURCE_FCLK, 0);\n\n\t\tif (wait_for_us((intel_de_read(dev_priv, LCPLL_CTL) &\n\t\t\t\t LCPLL_CD_SOURCE_FCLK_DONE) == 0, 1))\n\t\t\tdrm_err(&dev_priv->drm,\n\t\t\t\t\"Switching back to LCPLL failed\\n\");\n\t}\n\n\tintel_uncore_forcewake_put(&dev_priv->uncore, FORCEWAKE_ALL);\n\n\tintel_update_cdclk(dev_priv);\n\tintel_cdclk_dump_config(dev_priv, &dev_priv->display.cdclk.hw, \"Current CDCLK\");\n}\n\n \nstatic void hsw_enable_pc8(struct drm_i915_private *dev_priv)\n{\n\tdrm_dbg_kms(&dev_priv->drm, \"Enabling package C8+\\n\");\n\n\tif (HAS_PCH_LPT_LP(dev_priv))\n\t\tintel_de_rmw(dev_priv, SOUTH_DSPCLK_GATE_D,\n\t\t\t     PCH_LP_PARTITION_LEVEL_DISABLE, 0);\n\n\tlpt_disable_clkout_dp(dev_priv);\n\thsw_disable_lcpll(dev_priv, true, true);\n}\n\nstatic void hsw_disable_pc8(struct drm_i915_private *dev_priv)\n{\n\tdrm_dbg_kms(&dev_priv->drm, \"Disabling package C8+\\n\");\n\n\thsw_restore_lcpll(dev_priv);\n\tintel_init_pch_refclk(dev_priv);\n\n\t \n\tintel_clock_gating_init(dev_priv);\n}\n\nstatic void intel_pch_reset_handshake(struct drm_i915_private *dev_priv,\n\t\t\t\t      bool enable)\n{\n\ti915_reg_t reg;\n\tu32 reset_bits;\n\n\tif (IS_IVYBRIDGE(dev_priv)) {\n\t\treg = GEN7_MSG_CTL;\n\t\treset_bits = WAIT_FOR_PCH_FLR_ACK | WAIT_FOR_PCH_RESET_ACK;\n\t} else {\n\t\treg = HSW_NDE_RSTWRN_OPT;\n\t\treset_bits = RESET_PCH_HANDSHAKE_ENABLE;\n\t}\n\n\tif (DISPLAY_VER(dev_priv) >= 14)\n\t\treset_bits |= MTL_RESET_PICA_HANDSHAKE_EN;\n\n\tintel_de_rmw(dev_priv, reg, reset_bits, enable ? reset_bits : 0);\n}\n\nstatic void skl_display_core_init(struct drm_i915_private *dev_priv,\n\t\t\t\t  bool resume)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *well;\n\n\tgen9_set_dc_state(dev_priv, DC_STATE_DISABLE);\n\n\t \n\tintel_pch_reset_handshake(dev_priv, !HAS_PCH_NOP(dev_priv));\n\n\tif (!HAS_DISPLAY(dev_priv))\n\t\treturn;\n\n\t \n\tmutex_lock(&power_domains->lock);\n\n\twell = lookup_power_well(dev_priv, SKL_DISP_PW_1);\n\tintel_power_well_enable(dev_priv, well);\n\n\twell = lookup_power_well(dev_priv, SKL_DISP_PW_MISC_IO);\n\tintel_power_well_enable(dev_priv, well);\n\n\tmutex_unlock(&power_domains->lock);\n\n\tintel_cdclk_init_hw(dev_priv);\n\n\tgen9_dbuf_enable(dev_priv);\n\n\tif (resume)\n\t\tintel_dmc_load_program(dev_priv);\n}\n\nstatic void skl_display_core_uninit(struct drm_i915_private *dev_priv)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *well;\n\n\tif (!HAS_DISPLAY(dev_priv))\n\t\treturn;\n\n\tgen9_disable_dc_states(dev_priv);\n\t \n\n\tgen9_dbuf_disable(dev_priv);\n\n\tintel_cdclk_uninit_hw(dev_priv);\n\n\t \n\t \n\n\tmutex_lock(&power_domains->lock);\n\n\t \n\twell = lookup_power_well(dev_priv, SKL_DISP_PW_1);\n\tintel_power_well_disable(dev_priv, well);\n\n\tmutex_unlock(&power_domains->lock);\n\n\tusleep_range(10, 30);\t\t \n}\n\nstatic void bxt_display_core_init(struct drm_i915_private *dev_priv, bool resume)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *well;\n\n\tgen9_set_dc_state(dev_priv, DC_STATE_DISABLE);\n\n\t \n\tintel_pch_reset_handshake(dev_priv, false);\n\n\tif (!HAS_DISPLAY(dev_priv))\n\t\treturn;\n\n\t \n\tmutex_lock(&power_domains->lock);\n\n\twell = lookup_power_well(dev_priv, SKL_DISP_PW_1);\n\tintel_power_well_enable(dev_priv, well);\n\n\tmutex_unlock(&power_domains->lock);\n\n\tintel_cdclk_init_hw(dev_priv);\n\n\tgen9_dbuf_enable(dev_priv);\n\n\tif (resume)\n\t\tintel_dmc_load_program(dev_priv);\n}\n\nstatic void bxt_display_core_uninit(struct drm_i915_private *dev_priv)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *well;\n\n\tif (!HAS_DISPLAY(dev_priv))\n\t\treturn;\n\n\tgen9_disable_dc_states(dev_priv);\n\t \n\n\tgen9_dbuf_disable(dev_priv);\n\n\tintel_cdclk_uninit_hw(dev_priv);\n\n\t \n\n\t \n\tmutex_lock(&power_domains->lock);\n\n\twell = lookup_power_well(dev_priv, SKL_DISP_PW_1);\n\tintel_power_well_disable(dev_priv, well);\n\n\tmutex_unlock(&power_domains->lock);\n\n\tusleep_range(10, 30);\t\t \n}\n\nstruct buddy_page_mask {\n\tu32 page_mask;\n\tu8 type;\n\tu8 num_channels;\n};\n\nstatic const struct buddy_page_mask tgl_buddy_page_masks[] = {\n\t{ .num_channels = 1, .type = INTEL_DRAM_DDR4,   .page_mask = 0xF },\n\t{ .num_channels = 1, .type = INTEL_DRAM_DDR5,\t.page_mask = 0xF },\n\t{ .num_channels = 2, .type = INTEL_DRAM_LPDDR4, .page_mask = 0x1C },\n\t{ .num_channels = 2, .type = INTEL_DRAM_LPDDR5, .page_mask = 0x1C },\n\t{ .num_channels = 2, .type = INTEL_DRAM_DDR4,   .page_mask = 0x1F },\n\t{ .num_channels = 2, .type = INTEL_DRAM_DDR5,   .page_mask = 0x1E },\n\t{ .num_channels = 4, .type = INTEL_DRAM_LPDDR4, .page_mask = 0x38 },\n\t{ .num_channels = 4, .type = INTEL_DRAM_LPDDR5, .page_mask = 0x38 },\n\t{}\n};\n\nstatic const struct buddy_page_mask wa_1409767108_buddy_page_masks[] = {\n\t{ .num_channels = 1, .type = INTEL_DRAM_LPDDR4, .page_mask = 0x1 },\n\t{ .num_channels = 1, .type = INTEL_DRAM_DDR4,   .page_mask = 0x1 },\n\t{ .num_channels = 1, .type = INTEL_DRAM_DDR5,   .page_mask = 0x1 },\n\t{ .num_channels = 1, .type = INTEL_DRAM_LPDDR5, .page_mask = 0x1 },\n\t{ .num_channels = 2, .type = INTEL_DRAM_LPDDR4, .page_mask = 0x3 },\n\t{ .num_channels = 2, .type = INTEL_DRAM_DDR4,   .page_mask = 0x3 },\n\t{ .num_channels = 2, .type = INTEL_DRAM_DDR5,   .page_mask = 0x3 },\n\t{ .num_channels = 2, .type = INTEL_DRAM_LPDDR5, .page_mask = 0x3 },\n\t{}\n};\n\nstatic void tgl_bw_buddy_init(struct drm_i915_private *dev_priv)\n{\n\tenum intel_dram_type type = dev_priv->dram_info.type;\n\tu8 num_channels = dev_priv->dram_info.num_channels;\n\tconst struct buddy_page_mask *table;\n\tunsigned long abox_mask = DISPLAY_INFO(dev_priv)->abox_mask;\n\tint config, i;\n\n\t \n\tif (IS_DGFX(dev_priv) && !IS_DG1(dev_priv))\n\t\treturn;\n\n\tif (IS_ALDERLAKE_S(dev_priv) ||\n\t    (IS_ROCKETLAKE(dev_priv) && IS_DISPLAY_STEP(dev_priv, STEP_A0, STEP_B0)))\n\t\t \n\t\ttable = wa_1409767108_buddy_page_masks;\n\telse\n\t\ttable = tgl_buddy_page_masks;\n\n\tfor (config = 0; table[config].page_mask != 0; config++)\n\t\tif (table[config].num_channels == num_channels &&\n\t\t    table[config].type == type)\n\t\t\tbreak;\n\n\tif (table[config].page_mask == 0) {\n\t\tdrm_dbg(&dev_priv->drm,\n\t\t\t\"Unknown memory configuration; disabling address buddy logic.\\n\");\n\t\tfor_each_set_bit(i, &abox_mask, sizeof(abox_mask))\n\t\t\tintel_de_write(dev_priv, BW_BUDDY_CTL(i),\n\t\t\t\t       BW_BUDDY_DISABLE);\n\t} else {\n\t\tfor_each_set_bit(i, &abox_mask, sizeof(abox_mask)) {\n\t\t\tintel_de_write(dev_priv, BW_BUDDY_PAGE_MASK(i),\n\t\t\t\t       table[config].page_mask);\n\n\t\t\t \n\t\t\tif (DISPLAY_VER(dev_priv) == 12)\n\t\t\t\tintel_de_rmw(dev_priv, BW_BUDDY_CTL(i),\n\t\t\t\t\t     BW_BUDDY_TLB_REQ_TIMER_MASK,\n\t\t\t\t\t     BW_BUDDY_TLB_REQ_TIMER(0x8));\n\t\t}\n\t}\n}\n\nstatic void icl_display_core_init(struct drm_i915_private *dev_priv,\n\t\t\t\t  bool resume)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *well;\n\n\tgen9_set_dc_state(dev_priv, DC_STATE_DISABLE);\n\n\t \n\tif (INTEL_PCH_TYPE(dev_priv) >= PCH_TGP &&\n\t    INTEL_PCH_TYPE(dev_priv) < PCH_DG1)\n\t\tintel_de_rmw(dev_priv, SOUTH_DSPCLK_GATE_D, 0,\n\t\t\t     PCH_DPMGUNIT_CLOCK_GATE_DISABLE);\n\n\t \n\tintel_pch_reset_handshake(dev_priv, !HAS_PCH_NOP(dev_priv));\n\n\tif (!HAS_DISPLAY(dev_priv))\n\t\treturn;\n\n\t \n\tintel_combo_phy_init(dev_priv);\n\n\t \n\tmutex_lock(&power_domains->lock);\n\twell = lookup_power_well(dev_priv, SKL_DISP_PW_1);\n\tintel_power_well_enable(dev_priv, well);\n\tmutex_unlock(&power_domains->lock);\n\n\tif (DISPLAY_VER(dev_priv) == 14)\n\t\tintel_de_rmw(dev_priv, DC_STATE_EN,\n\t\t\t     HOLD_PHY_PG1_LATCH | HOLD_PHY_CLKREQ_PG1_LATCH, 0);\n\n\t \n\tintel_cdclk_init_hw(dev_priv);\n\n\tif (DISPLAY_VER(dev_priv) >= 12)\n\t\tgen12_dbuf_slices_config(dev_priv);\n\n\t \n\tgen9_dbuf_enable(dev_priv);\n\n\t \n\ticl_mbus_init(dev_priv);\n\n\t \n\tif (DISPLAY_VER(dev_priv) >= 12)\n\t\ttgl_bw_buddy_init(dev_priv);\n\n\t \n\tif (IS_DG2(dev_priv))\n\t\tintel_snps_phy_wait_for_calibration(dev_priv);\n\n\tif (resume)\n\t\tintel_dmc_load_program(dev_priv);\n\n\t \n\tif (DISPLAY_VER(dev_priv) >= 12)\n\t\tintel_de_rmw(dev_priv, GEN11_CHICKEN_DCPR_2, 0,\n\t\t\t     DCPR_CLEAR_MEMSTAT_DIS | DCPR_SEND_RESP_IMM |\n\t\t\t     DCPR_MASK_LPMODE | DCPR_MASK_MAXLATENCY_MEMUP_CLR);\n\n\t \n\tif (DISPLAY_VER(dev_priv) >= 13)\n\t\tintel_de_write(dev_priv, XELPD_DISPLAY_ERR_FATAL_MASK, ~0);\n}\n\nstatic void icl_display_core_uninit(struct drm_i915_private *dev_priv)\n{\n\tstruct i915_power_domains *power_domains = &dev_priv->display.power.domains;\n\tstruct i915_power_well *well;\n\n\tif (!HAS_DISPLAY(dev_priv))\n\t\treturn;\n\n\tgen9_disable_dc_states(dev_priv);\n\tintel_dmc_disable_program(dev_priv);\n\n\t \n\n\t \n\tgen9_dbuf_disable(dev_priv);\n\n\t \n\tintel_cdclk_uninit_hw(dev_priv);\n\n\tif (DISPLAY_VER(dev_priv) == 14)\n\t\tintel_de_rmw(dev_priv, DC_STATE_EN, 0,\n\t\t\t     HOLD_PHY_PG1_LATCH | HOLD_PHY_CLKREQ_PG1_LATCH);\n\n\t \n\tmutex_lock(&power_domains->lock);\n\twell = lookup_power_well(dev_priv, SKL_DISP_PW_1);\n\tintel_power_well_disable(dev_priv, well);\n\tmutex_unlock(&power_domains->lock);\n\n\t \n\tintel_combo_phy_uninit(dev_priv);\n}\n\nstatic void chv_phy_control_init(struct drm_i915_private *dev_priv)\n{\n\tstruct i915_power_well *cmn_bc =\n\t\tlookup_power_well(dev_priv, VLV_DISP_PW_DPIO_CMN_BC);\n\tstruct i915_power_well *cmn_d =\n\t\tlookup_power_well(dev_priv, CHV_DISP_PW_DPIO_CMN_D);\n\n\t \n\tdev_priv->display.power.chv_phy_control =\n\t\tPHY_LDO_SEQ_DELAY(PHY_LDO_DELAY_600NS, DPIO_PHY0) |\n\t\tPHY_LDO_SEQ_DELAY(PHY_LDO_DELAY_600NS, DPIO_PHY1) |\n\t\tPHY_CH_POWER_MODE(PHY_CH_DEEP_PSR, DPIO_PHY0, DPIO_CH0) |\n\t\tPHY_CH_POWER_MODE(PHY_CH_DEEP_PSR, DPIO_PHY0, DPIO_CH1) |\n\t\tPHY_CH_POWER_MODE(PHY_CH_DEEP_PSR, DPIO_PHY1, DPIO_CH0);\n\n\t \n\tif (intel_power_well_is_enabled(dev_priv, cmn_bc)) {\n\t\tu32 status = intel_de_read(dev_priv, DPLL(PIPE_A));\n\t\tunsigned int mask;\n\n\t\tmask = status & DPLL_PORTB_READY_MASK;\n\t\tif (mask == 0xf)\n\t\t\tmask = 0x0;\n\t\telse\n\t\t\tdev_priv->display.power.chv_phy_control |=\n\t\t\t\tPHY_CH_POWER_DOWN_OVRD_EN(DPIO_PHY0, DPIO_CH0);\n\n\t\tdev_priv->display.power.chv_phy_control |=\n\t\t\tPHY_CH_POWER_DOWN_OVRD(mask, DPIO_PHY0, DPIO_CH0);\n\n\t\tmask = (status & DPLL_PORTC_READY_MASK) >> 4;\n\t\tif (mask == 0xf)\n\t\t\tmask = 0x0;\n\t\telse\n\t\t\tdev_priv->display.power.chv_phy_control |=\n\t\t\t\tPHY_CH_POWER_DOWN_OVRD_EN(DPIO_PHY0, DPIO_CH1);\n\n\t\tdev_priv->display.power.chv_phy_control |=\n\t\t\tPHY_CH_POWER_DOWN_OVRD(mask, DPIO_PHY0, DPIO_CH1);\n\n\t\tdev_priv->display.power.chv_phy_control |= PHY_COM_LANE_RESET_DEASSERT(DPIO_PHY0);\n\n\t\tdev_priv->display.power.chv_phy_assert[DPIO_PHY0] = false;\n\t} else {\n\t\tdev_priv->display.power.chv_phy_assert[DPIO_PHY0] = true;\n\t}\n\n\tif (intel_power_well_is_enabled(dev_priv, cmn_d)) {\n\t\tu32 status = intel_de_read(dev_priv, DPIO_PHY_STATUS);\n\t\tunsigned int mask;\n\n\t\tmask = status & DPLL_PORTD_READY_MASK;\n\n\t\tif (mask == 0xf)\n\t\t\tmask = 0x0;\n\t\telse\n\t\t\tdev_priv->display.power.chv_phy_control |=\n\t\t\t\tPHY_CH_POWER_DOWN_OVRD_EN(DPIO_PHY1, DPIO_CH0);\n\n\t\tdev_priv->display.power.chv_phy_control |=\n\t\t\tPHY_CH_POWER_DOWN_OVRD(mask, DPIO_PHY1, DPIO_CH0);\n\n\t\tdev_priv->display.power.chv_phy_control |= PHY_COM_LANE_RESET_DEASSERT(DPIO_PHY1);\n\n\t\tdev_priv->display.power.chv_phy_assert[DPIO_PHY1] = false;\n\t} else {\n\t\tdev_priv->display.power.chv_phy_assert[DPIO_PHY1] = true;\n\t}\n\n\tdrm_dbg_kms(&dev_priv->drm, \"Initial PHY_CONTROL=0x%08x\\n\",\n\t\t    dev_priv->display.power.chv_phy_control);\n\n\t \n}\n\nstatic void vlv_cmnlane_wa(struct drm_i915_private *dev_priv)\n{\n\tstruct i915_power_well *cmn =\n\t\tlookup_power_well(dev_priv, VLV_DISP_PW_DPIO_CMN_BC);\n\tstruct i915_power_well *disp2d =\n\t\tlookup_power_well(dev_priv, VLV_DISP_PW_DISP2D);\n\n\t \n\tif (intel_power_well_is_enabled(dev_priv, cmn) &&\n\t    intel_power_well_is_enabled(dev_priv, disp2d) &&\n\t    intel_de_read(dev_priv, DPIO_CTL) & DPIO_CMNRST)\n\t\treturn;\n\n\tdrm_dbg_kms(&dev_priv->drm, \"toggling display PHY side reset\\n\");\n\n\t \n\tintel_power_well_enable(dev_priv, disp2d);\n\n\t \n\tintel_power_well_disable(dev_priv, cmn);\n}\n\nstatic bool vlv_punit_is_power_gated(struct drm_i915_private *dev_priv, u32 reg0)\n{\n\tbool ret;\n\n\tvlv_punit_get(dev_priv);\n\tret = (vlv_punit_read(dev_priv, reg0) & SSPM0_SSC_MASK) == SSPM0_SSC_PWR_GATE;\n\tvlv_punit_put(dev_priv);\n\n\treturn ret;\n}\n\nstatic void assert_ved_power_gated(struct drm_i915_private *dev_priv)\n{\n\tdrm_WARN(&dev_priv->drm,\n\t\t !vlv_punit_is_power_gated(dev_priv, PUNIT_REG_VEDSSPM0),\n\t\t \"VED not power gated\\n\");\n}\n\nstatic void assert_isp_power_gated(struct drm_i915_private *dev_priv)\n{\n\tstatic const struct pci_device_id isp_ids[] = {\n\t\t{PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x0f38)},\n\t\t{PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x22b8)},\n\t\t{}\n\t};\n\n\tdrm_WARN(&dev_priv->drm, !pci_dev_present(isp_ids) &&\n\t\t !vlv_punit_is_power_gated(dev_priv, PUNIT_REG_ISPSSPM0),\n\t\t \"ISP not power gated\\n\");\n}\n\nstatic void intel_power_domains_verify_state(struct drm_i915_private *dev_priv);\n\n \nvoid intel_power_domains_init_hw(struct drm_i915_private *i915, bool resume)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\n\tpower_domains->initializing = true;\n\n\tif (DISPLAY_VER(i915) >= 11) {\n\t\ticl_display_core_init(i915, resume);\n\t} else if (IS_GEMINILAKE(i915) || IS_BROXTON(i915)) {\n\t\tbxt_display_core_init(i915, resume);\n\t} else if (DISPLAY_VER(i915) == 9) {\n\t\tskl_display_core_init(i915, resume);\n\t} else if (IS_CHERRYVIEW(i915)) {\n\t\tmutex_lock(&power_domains->lock);\n\t\tchv_phy_control_init(i915);\n\t\tmutex_unlock(&power_domains->lock);\n\t\tassert_isp_power_gated(i915);\n\t} else if (IS_VALLEYVIEW(i915)) {\n\t\tmutex_lock(&power_domains->lock);\n\t\tvlv_cmnlane_wa(i915);\n\t\tmutex_unlock(&power_domains->lock);\n\t\tassert_ved_power_gated(i915);\n\t\tassert_isp_power_gated(i915);\n\t} else if (IS_BROADWELL(i915) || IS_HASWELL(i915)) {\n\t\thsw_assert_cdclk(i915);\n\t\tintel_pch_reset_handshake(i915, !HAS_PCH_NOP(i915));\n\t} else if (IS_IVYBRIDGE(i915)) {\n\t\tintel_pch_reset_handshake(i915, !HAS_PCH_NOP(i915));\n\t}\n\n\t \n\tdrm_WARN_ON(&i915->drm, power_domains->init_wakeref);\n\tpower_domains->init_wakeref =\n\t\tintel_display_power_get(i915, POWER_DOMAIN_INIT);\n\n\t \n\tif (!i915->params.disable_power_well) {\n\t\tdrm_WARN_ON(&i915->drm, power_domains->disable_wakeref);\n\t\ti915->display.power.domains.disable_wakeref = intel_display_power_get(i915,\n\t\t\t\t\t\t\t\t\t\t      POWER_DOMAIN_INIT);\n\t}\n\tintel_power_domains_sync_hw(i915);\n\n\tpower_domains->initializing = false;\n}\n\n \nvoid intel_power_domains_driver_remove(struct drm_i915_private *i915)\n{\n\tintel_wakeref_t wakeref __maybe_unused =\n\t\tfetch_and_zero(&i915->display.power.domains.init_wakeref);\n\n\t \n\tif (!i915->params.disable_power_well)\n\t\tintel_display_power_put(i915, POWER_DOMAIN_INIT,\n\t\t\t\t\tfetch_and_zero(&i915->display.power.domains.disable_wakeref));\n\n\tintel_display_power_flush_work_sync(i915);\n\n\tintel_power_domains_verify_state(i915);\n\n\t \n\tintel_runtime_pm_put(&i915->runtime_pm, wakeref);\n}\n\n \nvoid intel_power_domains_sanitize_state(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tstruct i915_power_well *power_well;\n\n\tmutex_lock(&power_domains->lock);\n\n\tfor_each_power_well_reverse(i915, power_well) {\n\t\tif (power_well->desc->always_on || power_well->count ||\n\t\t    !intel_power_well_is_enabled(i915, power_well))\n\t\t\tcontinue;\n\n\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t    \"BIOS left unused %s power well enabled, disabling it\\n\",\n\t\t\t    intel_power_well_name(power_well));\n\t\tintel_power_well_disable(i915, power_well);\n\t}\n\n\tmutex_unlock(&power_domains->lock);\n}\n\n \nvoid intel_power_domains_enable(struct drm_i915_private *i915)\n{\n\tintel_wakeref_t wakeref __maybe_unused =\n\t\tfetch_and_zero(&i915->display.power.domains.init_wakeref);\n\n\tintel_display_power_put(i915, POWER_DOMAIN_INIT, wakeref);\n\tintel_power_domains_verify_state(i915);\n}\n\n \nvoid intel_power_domains_disable(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\n\tdrm_WARN_ON(&i915->drm, power_domains->init_wakeref);\n\tpower_domains->init_wakeref =\n\t\tintel_display_power_get(i915, POWER_DOMAIN_INIT);\n\n\tintel_power_domains_verify_state(i915);\n}\n\n \nvoid intel_power_domains_suspend(struct drm_i915_private *i915, bool s2idle)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tintel_wakeref_t wakeref __maybe_unused =\n\t\tfetch_and_zero(&power_domains->init_wakeref);\n\n\tintel_display_power_put(i915, POWER_DOMAIN_INIT, wakeref);\n\n\t \n\tif (!(power_domains->allowed_dc_mask & DC_STATE_EN_DC9) && s2idle &&\n\t    intel_dmc_has_payload(i915)) {\n\t\tintel_display_power_flush_work(i915);\n\t\tintel_power_domains_verify_state(i915);\n\t\treturn;\n\t}\n\n\t \n\tif (!i915->params.disable_power_well)\n\t\tintel_display_power_put(i915, POWER_DOMAIN_INIT,\n\t\t\t\t\tfetch_and_zero(&i915->display.power.domains.disable_wakeref));\n\n\tintel_display_power_flush_work(i915);\n\tintel_power_domains_verify_state(i915);\n\n\tif (DISPLAY_VER(i915) >= 11)\n\t\ticl_display_core_uninit(i915);\n\telse if (IS_GEMINILAKE(i915) || IS_BROXTON(i915))\n\t\tbxt_display_core_uninit(i915);\n\telse if (DISPLAY_VER(i915) == 9)\n\t\tskl_display_core_uninit(i915);\n\n\tpower_domains->display_core_suspended = true;\n}\n\n \nvoid intel_power_domains_resume(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\n\tif (power_domains->display_core_suspended) {\n\t\tintel_power_domains_init_hw(i915, true);\n\t\tpower_domains->display_core_suspended = false;\n\t} else {\n\t\tdrm_WARN_ON(&i915->drm, power_domains->init_wakeref);\n\t\tpower_domains->init_wakeref =\n\t\t\tintel_display_power_get(i915, POWER_DOMAIN_INIT);\n\t}\n\n\tintel_power_domains_verify_state(i915);\n}\n\n#if IS_ENABLED(CONFIG_DRM_I915_DEBUG_RUNTIME_PM)\n\nstatic void intel_power_domains_dump_info(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tstruct i915_power_well *power_well;\n\n\tfor_each_power_well(i915, power_well) {\n\t\tenum intel_display_power_domain domain;\n\n\t\tdrm_dbg(&i915->drm, \"%-25s %d\\n\",\n\t\t\tintel_power_well_name(power_well), intel_power_well_refcount(power_well));\n\n\t\tfor_each_power_domain(domain, intel_power_well_domains(power_well))\n\t\t\tdrm_dbg(&i915->drm, \"  %-23s %d\\n\",\n\t\t\t\tintel_display_power_domain_str(domain),\n\t\t\t\tpower_domains->domain_use_count[domain]);\n\t}\n}\n\n \nstatic void intel_power_domains_verify_state(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tstruct i915_power_well *power_well;\n\tbool dump_domain_info;\n\n\tmutex_lock(&power_domains->lock);\n\n\tverify_async_put_domains_state(power_domains);\n\n\tdump_domain_info = false;\n\tfor_each_power_well(i915, power_well) {\n\t\tenum intel_display_power_domain domain;\n\t\tint domains_count;\n\t\tbool enabled;\n\n\t\tenabled = intel_power_well_is_enabled(i915, power_well);\n\t\tif ((intel_power_well_refcount(power_well) ||\n\t\t     intel_power_well_is_always_on(power_well)) !=\n\t\t    enabled)\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"power well %s state mismatch (refcount %d/enabled %d)\",\n\t\t\t\tintel_power_well_name(power_well),\n\t\t\t\tintel_power_well_refcount(power_well), enabled);\n\n\t\tdomains_count = 0;\n\t\tfor_each_power_domain(domain, intel_power_well_domains(power_well))\n\t\t\tdomains_count += power_domains->domain_use_count[domain];\n\n\t\tif (intel_power_well_refcount(power_well) != domains_count) {\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"power well %s refcount/domain refcount mismatch \"\n\t\t\t\t\"(refcount %d/domains refcount %d)\\n\",\n\t\t\t\tintel_power_well_name(power_well),\n\t\t\t\tintel_power_well_refcount(power_well),\n\t\t\t\tdomains_count);\n\t\t\tdump_domain_info = true;\n\t\t}\n\t}\n\n\tif (dump_domain_info) {\n\t\tstatic bool dumped;\n\n\t\tif (!dumped) {\n\t\t\tintel_power_domains_dump_info(i915);\n\t\t\tdumped = true;\n\t\t}\n\t}\n\n\tmutex_unlock(&power_domains->lock);\n}\n\n#else\n\nstatic void intel_power_domains_verify_state(struct drm_i915_private *i915)\n{\n}\n\n#endif\n\nvoid intel_display_power_suspend_late(struct drm_i915_private *i915)\n{\n\tif (DISPLAY_VER(i915) >= 11 || IS_GEMINILAKE(i915) ||\n\t    IS_BROXTON(i915)) {\n\t\tbxt_enable_dc9(i915);\n\t} else if (IS_HASWELL(i915) || IS_BROADWELL(i915)) {\n\t\thsw_enable_pc8(i915);\n\t}\n\n\t \n\tif (INTEL_PCH_TYPE(i915) >= PCH_CNP && INTEL_PCH_TYPE(i915) < PCH_DG1)\n\t\tintel_de_rmw(i915, SOUTH_CHICKEN1, SBCLK_RUN_REFCLK_DIS, SBCLK_RUN_REFCLK_DIS);\n}\n\nvoid intel_display_power_resume_early(struct drm_i915_private *i915)\n{\n\tif (DISPLAY_VER(i915) >= 11 || IS_GEMINILAKE(i915) ||\n\t    IS_BROXTON(i915)) {\n\t\tgen9_sanitize_dc_state(i915);\n\t\tbxt_disable_dc9(i915);\n\t} else if (IS_HASWELL(i915) || IS_BROADWELL(i915)) {\n\t\thsw_disable_pc8(i915);\n\t}\n\n\t \n\tif (INTEL_PCH_TYPE(i915) >= PCH_CNP && INTEL_PCH_TYPE(i915) < PCH_DG1)\n\t\tintel_de_rmw(i915, SOUTH_CHICKEN1, SBCLK_RUN_REFCLK_DIS, 0);\n}\n\nvoid intel_display_power_suspend(struct drm_i915_private *i915)\n{\n\tif (DISPLAY_VER(i915) >= 11) {\n\t\ticl_display_core_uninit(i915);\n\t\tbxt_enable_dc9(i915);\n\t} else if (IS_GEMINILAKE(i915) || IS_BROXTON(i915)) {\n\t\tbxt_display_core_uninit(i915);\n\t\tbxt_enable_dc9(i915);\n\t} else if (IS_HASWELL(i915) || IS_BROADWELL(i915)) {\n\t\thsw_enable_pc8(i915);\n\t}\n}\n\nvoid intel_display_power_resume(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\n\tif (DISPLAY_VER(i915) >= 11) {\n\t\tbxt_disable_dc9(i915);\n\t\ticl_display_core_init(i915, true);\n\t\tif (intel_dmc_has_payload(i915)) {\n\t\t\tif (power_domains->allowed_dc_mask & DC_STATE_EN_UPTO_DC6)\n\t\t\t\tskl_enable_dc6(i915);\n\t\t\telse if (power_domains->allowed_dc_mask & DC_STATE_EN_UPTO_DC5)\n\t\t\t\tgen9_enable_dc5(i915);\n\t\t}\n\t} else if (IS_GEMINILAKE(i915) || IS_BROXTON(i915)) {\n\t\tbxt_disable_dc9(i915);\n\t\tbxt_display_core_init(i915, true);\n\t\tif (intel_dmc_has_payload(i915) &&\n\t\t    (power_domains->allowed_dc_mask & DC_STATE_EN_UPTO_DC5))\n\t\t\tgen9_enable_dc5(i915);\n\t} else if (IS_HASWELL(i915) || IS_BROADWELL(i915)) {\n\t\thsw_disable_pc8(i915);\n\t}\n}\n\nvoid intel_display_power_debug(struct drm_i915_private *i915, struct seq_file *m)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tint i;\n\n\tmutex_lock(&power_domains->lock);\n\n\tseq_printf(m, \"%-25s %s\\n\", \"Power well/domain\", \"Use count\");\n\tfor (i = 0; i < power_domains->power_well_count; i++) {\n\t\tstruct i915_power_well *power_well;\n\t\tenum intel_display_power_domain power_domain;\n\n\t\tpower_well = &power_domains->power_wells[i];\n\t\tseq_printf(m, \"%-25s %d\\n\", intel_power_well_name(power_well),\n\t\t\t   intel_power_well_refcount(power_well));\n\n\t\tfor_each_power_domain(power_domain, intel_power_well_domains(power_well))\n\t\t\tseq_printf(m, \"  %-23s %d\\n\",\n\t\t\t\t   intel_display_power_domain_str(power_domain),\n\t\t\t\t   power_domains->domain_use_count[power_domain]);\n\t}\n\n\tmutex_unlock(&power_domains->lock);\n}\n\nstruct intel_ddi_port_domains {\n\tenum port port_start;\n\tenum port port_end;\n\tenum aux_ch aux_ch_start;\n\tenum aux_ch aux_ch_end;\n\n\tenum intel_display_power_domain ddi_lanes;\n\tenum intel_display_power_domain ddi_io;\n\tenum intel_display_power_domain aux_io;\n\tenum intel_display_power_domain aux_legacy_usbc;\n\tenum intel_display_power_domain aux_tbt;\n};\n\nstatic const struct intel_ddi_port_domains\ni9xx_port_domains[] = {\n\t{\n\t\t.port_start = PORT_A,\n\t\t.port_end = PORT_F,\n\t\t.aux_ch_start = AUX_CH_A,\n\t\t.aux_ch_end = AUX_CH_F,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_A,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_A,\n\t\t.aux_io = POWER_DOMAIN_AUX_IO_A,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_A,\n\t\t.aux_tbt = POWER_DOMAIN_INVALID,\n\t},\n};\n\nstatic const struct intel_ddi_port_domains\nd11_port_domains[] = {\n\t{\n\t\t.port_start = PORT_A,\n\t\t.port_end = PORT_B,\n\t\t.aux_ch_start = AUX_CH_A,\n\t\t.aux_ch_end = AUX_CH_B,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_A,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_A,\n\t\t.aux_io = POWER_DOMAIN_AUX_IO_A,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_A,\n\t\t.aux_tbt = POWER_DOMAIN_INVALID,\n\t}, {\n\t\t.port_start = PORT_C,\n\t\t.port_end = PORT_F,\n\t\t.aux_ch_start = AUX_CH_C,\n\t\t.aux_ch_end = AUX_CH_F,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_C,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_C,\n\t\t.aux_io = POWER_DOMAIN_AUX_IO_C,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_C,\n\t\t.aux_tbt = POWER_DOMAIN_AUX_TBT1,\n\t},\n};\n\nstatic const struct intel_ddi_port_domains\nd12_port_domains[] = {\n\t{\n\t\t.port_start = PORT_A,\n\t\t.port_end = PORT_C,\n\t\t.aux_ch_start = AUX_CH_A,\n\t\t.aux_ch_end = AUX_CH_C,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_A,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_A,\n\t\t.aux_io = POWER_DOMAIN_AUX_IO_A,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_A,\n\t\t.aux_tbt = POWER_DOMAIN_INVALID,\n\t}, {\n\t\t.port_start = PORT_TC1,\n\t\t.port_end = PORT_TC6,\n\t\t.aux_ch_start = AUX_CH_USBC1,\n\t\t.aux_ch_end = AUX_CH_USBC6,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_TC1,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_TC1,\n\t\t.aux_io = POWER_DOMAIN_INVALID,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_USBC1,\n\t\t.aux_tbt = POWER_DOMAIN_AUX_TBT1,\n\t},\n};\n\nstatic const struct intel_ddi_port_domains\nd13_port_domains[] = {\n\t{\n\t\t.port_start = PORT_A,\n\t\t.port_end = PORT_C,\n\t\t.aux_ch_start = AUX_CH_A,\n\t\t.aux_ch_end = AUX_CH_C,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_A,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_A,\n\t\t.aux_io = POWER_DOMAIN_AUX_IO_A,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_A,\n\t\t.aux_tbt = POWER_DOMAIN_INVALID,\n\t}, {\n\t\t.port_start = PORT_TC1,\n\t\t.port_end = PORT_TC4,\n\t\t.aux_ch_start = AUX_CH_USBC1,\n\t\t.aux_ch_end = AUX_CH_USBC4,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_TC1,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_TC1,\n\t\t.aux_io = POWER_DOMAIN_INVALID,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_USBC1,\n\t\t.aux_tbt = POWER_DOMAIN_AUX_TBT1,\n\t}, {\n\t\t.port_start = PORT_D_XELPD,\n\t\t.port_end = PORT_E_XELPD,\n\t\t.aux_ch_start = AUX_CH_D_XELPD,\n\t\t.aux_ch_end = AUX_CH_E_XELPD,\n\n\t\t.ddi_lanes = POWER_DOMAIN_PORT_DDI_LANES_D,\n\t\t.ddi_io = POWER_DOMAIN_PORT_DDI_IO_D,\n\t\t.aux_io = POWER_DOMAIN_AUX_IO_D,\n\t\t.aux_legacy_usbc = POWER_DOMAIN_AUX_D,\n\t\t.aux_tbt = POWER_DOMAIN_INVALID,\n\t},\n};\n\nstatic void\nintel_port_domains_for_platform(struct drm_i915_private *i915,\n\t\t\t\tconst struct intel_ddi_port_domains **domains,\n\t\t\t\tint *domains_size)\n{\n\tif (DISPLAY_VER(i915) >= 13) {\n\t\t*domains = d13_port_domains;\n\t\t*domains_size = ARRAY_SIZE(d13_port_domains);\n\t} else if (DISPLAY_VER(i915) >= 12) {\n\t\t*domains = d12_port_domains;\n\t\t*domains_size = ARRAY_SIZE(d12_port_domains);\n\t} else if (DISPLAY_VER(i915) >= 11) {\n\t\t*domains = d11_port_domains;\n\t\t*domains_size = ARRAY_SIZE(d11_port_domains);\n\t} else {\n\t\t*domains = i9xx_port_domains;\n\t\t*domains_size = ARRAY_SIZE(i9xx_port_domains);\n\t}\n}\n\nstatic const struct intel_ddi_port_domains *\nintel_port_domains_for_port(struct drm_i915_private *i915, enum port port)\n{\n\tconst struct intel_ddi_port_domains *domains;\n\tint domains_size;\n\tint i;\n\n\tintel_port_domains_for_platform(i915, &domains, &domains_size);\n\tfor (i = 0; i < domains_size; i++)\n\t\tif (port >= domains[i].port_start && port <= domains[i].port_end)\n\t\t\treturn &domains[i];\n\n\treturn NULL;\n}\n\nenum intel_display_power_domain\nintel_display_power_ddi_io_domain(struct drm_i915_private *i915, enum port port)\n{\n\tconst struct intel_ddi_port_domains *domains = intel_port_domains_for_port(i915, port);\n\n\tif (drm_WARN_ON(&i915->drm, !domains || domains->ddi_io == POWER_DOMAIN_INVALID))\n\t\treturn POWER_DOMAIN_PORT_DDI_IO_A;\n\n\treturn domains->ddi_io + (int)(port - domains->port_start);\n}\n\nenum intel_display_power_domain\nintel_display_power_ddi_lanes_domain(struct drm_i915_private *i915, enum port port)\n{\n\tconst struct intel_ddi_port_domains *domains = intel_port_domains_for_port(i915, port);\n\n\tif (drm_WARN_ON(&i915->drm, !domains || domains->ddi_lanes == POWER_DOMAIN_INVALID))\n\t\treturn POWER_DOMAIN_PORT_DDI_LANES_A;\n\n\treturn domains->ddi_lanes + (int)(port - domains->port_start);\n}\n\nstatic const struct intel_ddi_port_domains *\nintel_port_domains_for_aux_ch(struct drm_i915_private *i915, enum aux_ch aux_ch)\n{\n\tconst struct intel_ddi_port_domains *domains;\n\tint domains_size;\n\tint i;\n\n\tintel_port_domains_for_platform(i915, &domains, &domains_size);\n\tfor (i = 0; i < domains_size; i++)\n\t\tif (aux_ch >= domains[i].aux_ch_start && aux_ch <= domains[i].aux_ch_end)\n\t\t\treturn &domains[i];\n\n\treturn NULL;\n}\n\nenum intel_display_power_domain\nintel_display_power_aux_io_domain(struct drm_i915_private *i915, enum aux_ch aux_ch)\n{\n\tconst struct intel_ddi_port_domains *domains = intel_port_domains_for_aux_ch(i915, aux_ch);\n\n\tif (drm_WARN_ON(&i915->drm, !domains || domains->aux_io == POWER_DOMAIN_INVALID))\n\t\treturn POWER_DOMAIN_AUX_IO_A;\n\n\treturn domains->aux_io + (int)(aux_ch - domains->aux_ch_start);\n}\n\nenum intel_display_power_domain\nintel_display_power_legacy_aux_domain(struct drm_i915_private *i915, enum aux_ch aux_ch)\n{\n\tconst struct intel_ddi_port_domains *domains = intel_port_domains_for_aux_ch(i915, aux_ch);\n\n\tif (drm_WARN_ON(&i915->drm, !domains || domains->aux_legacy_usbc == POWER_DOMAIN_INVALID))\n\t\treturn POWER_DOMAIN_AUX_A;\n\n\treturn domains->aux_legacy_usbc + (int)(aux_ch - domains->aux_ch_start);\n}\n\nenum intel_display_power_domain\nintel_display_power_tbt_aux_domain(struct drm_i915_private *i915, enum aux_ch aux_ch)\n{\n\tconst struct intel_ddi_port_domains *domains = intel_port_domains_for_aux_ch(i915, aux_ch);\n\n\tif (drm_WARN_ON(&i915->drm, !domains || domains->aux_tbt == POWER_DOMAIN_INVALID))\n\t\treturn POWER_DOMAIN_AUX_TBT1;\n\n\treturn domains->aux_tbt + (int)(aux_ch - domains->aux_ch_start);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}