{
  "module_name": "skl_watermark.c",
  "hash_id": "0b03cfd5ebadcc240523f3363062ef37d9416fa98d4496b8838136db7c2e5640",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/display/skl_watermark.c",
  "human_readable_source": "\n \n\n#include <drm/drm_blend.h>\n\n#include \"i915_drv.h\"\n#include \"i915_fixed.h\"\n#include \"i915_reg.h\"\n#include \"i9xx_wm.h\"\n#include \"intel_atomic.h\"\n#include \"intel_atomic_plane.h\"\n#include \"intel_bw.h\"\n#include \"intel_crtc.h\"\n#include \"intel_de.h\"\n#include \"intel_display.h\"\n#include \"intel_display_power.h\"\n#include \"intel_display_types.h\"\n#include \"intel_fb.h\"\n#include \"intel_pcode.h\"\n#include \"intel_wm.h\"\n#include \"skl_watermark.h\"\n#include \"skl_watermark_regs.h\"\n\nstatic void skl_sagv_disable(struct drm_i915_private *i915);\n\n \nstruct skl_wm_params {\n\tbool x_tiled, y_tiled;\n\tbool rc_surface;\n\tbool is_planar;\n\tu32 width;\n\tu8 cpp;\n\tu32 plane_pixel_rate;\n\tu32 y_min_scanlines;\n\tu32 plane_bytes_per_line;\n\tuint_fixed_16_16_t plane_blocks_per_line;\n\tuint_fixed_16_16_t y_tile_minimum;\n\tu32 linetime_us;\n\tu32 dbuf_block_size;\n};\n\nu8 intel_enabled_dbuf_slices_mask(struct drm_i915_private *i915)\n{\n\tu8 enabled_slices = 0;\n\tenum dbuf_slice slice;\n\n\tfor_each_dbuf_slice(i915, slice) {\n\t\tif (intel_de_read(i915, DBUF_CTL_S(slice)) & DBUF_POWER_STATE)\n\t\t\tenabled_slices |= BIT(slice);\n\t}\n\n\treturn enabled_slices;\n}\n\n \nstatic bool skl_needs_memory_bw_wa(struct drm_i915_private *i915)\n{\n\treturn DISPLAY_VER(i915) == 9;\n}\n\nstatic bool\nintel_has_sagv(struct drm_i915_private *i915)\n{\n\treturn HAS_SAGV(i915) &&\n\t\ti915->display.sagv.status != I915_SAGV_NOT_CONTROLLED;\n}\n\nstatic u32\nintel_sagv_block_time(struct drm_i915_private *i915)\n{\n\tif (DISPLAY_VER(i915) >= 14) {\n\t\tu32 val;\n\n\t\tval = intel_de_read(i915, MTL_LATENCY_SAGV);\n\n\t\treturn REG_FIELD_GET(MTL_LATENCY_QCLK_SAGV, val);\n\t} else if (DISPLAY_VER(i915) >= 12) {\n\t\tu32 val = 0;\n\t\tint ret;\n\n\t\tret = snb_pcode_read(&i915->uncore,\n\t\t\t\t     GEN12_PCODE_READ_SAGV_BLOCK_TIME_US,\n\t\t\t\t     &val, NULL);\n\t\tif (ret) {\n\t\t\tdrm_dbg_kms(&i915->drm, \"Couldn't read SAGV block time!\\n\");\n\t\t\treturn 0;\n\t\t}\n\n\t\treturn val;\n\t} else if (DISPLAY_VER(i915) == 11) {\n\t\treturn 10;\n\t} else if (HAS_SAGV(i915)) {\n\t\treturn 30;\n\t} else {\n\t\treturn 0;\n\t}\n}\n\nstatic void intel_sagv_init(struct drm_i915_private *i915)\n{\n\tif (!HAS_SAGV(i915))\n\t\ti915->display.sagv.status = I915_SAGV_NOT_CONTROLLED;\n\n\t \n\tif (DISPLAY_VER(i915) < 11)\n\t\tskl_sagv_disable(i915);\n\n\tdrm_WARN_ON(&i915->drm, i915->display.sagv.status == I915_SAGV_UNKNOWN);\n\n\ti915->display.sagv.block_time_us = intel_sagv_block_time(i915);\n\n\tdrm_dbg_kms(&i915->drm, \"SAGV supported: %s, original SAGV block time: %u us\\n\",\n\t\t    str_yes_no(intel_has_sagv(i915)), i915->display.sagv.block_time_us);\n\n\t \n\tif (drm_WARN(&i915->drm, i915->display.sagv.block_time_us > U16_MAX,\n\t\t     \"Excessive SAGV block time %u, ignoring\\n\",\n\t\t     i915->display.sagv.block_time_us))\n\t\ti915->display.sagv.block_time_us = 0;\n\n\tif (!intel_has_sagv(i915))\n\t\ti915->display.sagv.block_time_us = 0;\n}\n\n \nstatic void skl_sagv_enable(struct drm_i915_private *i915)\n{\n\tint ret;\n\n\tif (!intel_has_sagv(i915))\n\t\treturn;\n\n\tif (i915->display.sagv.status == I915_SAGV_ENABLED)\n\t\treturn;\n\n\tdrm_dbg_kms(&i915->drm, \"Enabling SAGV\\n\");\n\tret = snb_pcode_write(&i915->uncore, GEN9_PCODE_SAGV_CONTROL,\n\t\t\t      GEN9_SAGV_ENABLE);\n\n\t \n\n\t \n\tif (IS_SKYLAKE(i915) && ret == -ENXIO) {\n\t\tdrm_dbg(&i915->drm, \"No SAGV found on system, ignoring\\n\");\n\t\ti915->display.sagv.status = I915_SAGV_NOT_CONTROLLED;\n\t\treturn;\n\t} else if (ret < 0) {\n\t\tdrm_err(&i915->drm, \"Failed to enable SAGV\\n\");\n\t\treturn;\n\t}\n\n\ti915->display.sagv.status = I915_SAGV_ENABLED;\n}\n\nstatic void skl_sagv_disable(struct drm_i915_private *i915)\n{\n\tint ret;\n\n\tif (!intel_has_sagv(i915))\n\t\treturn;\n\n\tif (i915->display.sagv.status == I915_SAGV_DISABLED)\n\t\treturn;\n\n\tdrm_dbg_kms(&i915->drm, \"Disabling SAGV\\n\");\n\t \n\tret = skl_pcode_request(&i915->uncore, GEN9_PCODE_SAGV_CONTROL,\n\t\t\t\tGEN9_SAGV_DISABLE,\n\t\t\t\tGEN9_SAGV_IS_DISABLED, GEN9_SAGV_IS_DISABLED,\n\t\t\t\t1);\n\t \n\tif (IS_SKYLAKE(i915) && ret == -ENXIO) {\n\t\tdrm_dbg(&i915->drm, \"No SAGV found on system, ignoring\\n\");\n\t\ti915->display.sagv.status = I915_SAGV_NOT_CONTROLLED;\n\t\treturn;\n\t} else if (ret < 0) {\n\t\tdrm_err(&i915->drm, \"Failed to disable SAGV (%d)\\n\", ret);\n\t\treturn;\n\t}\n\n\ti915->display.sagv.status = I915_SAGV_DISABLED;\n}\n\nstatic void skl_sagv_pre_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_bw_state *new_bw_state =\n\t\tintel_atomic_get_new_bw_state(state);\n\n\tif (!new_bw_state)\n\t\treturn;\n\n\tif (!intel_can_enable_sagv(i915, new_bw_state))\n\t\tskl_sagv_disable(i915);\n}\n\nstatic void skl_sagv_post_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_bw_state *new_bw_state =\n\t\tintel_atomic_get_new_bw_state(state);\n\n\tif (!new_bw_state)\n\t\treturn;\n\n\tif (intel_can_enable_sagv(i915, new_bw_state))\n\t\tskl_sagv_enable(i915);\n}\n\nstatic void icl_sagv_pre_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_bw_state *old_bw_state =\n\t\tintel_atomic_get_old_bw_state(state);\n\tconst struct intel_bw_state *new_bw_state =\n\t\tintel_atomic_get_new_bw_state(state);\n\tu16 old_mask, new_mask;\n\n\tif (!new_bw_state)\n\t\treturn;\n\n\told_mask = old_bw_state->qgv_points_mask;\n\tnew_mask = old_bw_state->qgv_points_mask | new_bw_state->qgv_points_mask;\n\n\tif (old_mask == new_mask)\n\t\treturn;\n\n\tWARN_ON(!new_bw_state->base.changed);\n\n\tdrm_dbg_kms(&i915->drm, \"Restricting QGV points: 0x%x -> 0x%x\\n\",\n\t\t    old_mask, new_mask);\n\n\t \n\ticl_pcode_restrict_qgv_points(i915, new_mask);\n}\n\nstatic void icl_sagv_post_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_bw_state *old_bw_state =\n\t\tintel_atomic_get_old_bw_state(state);\n\tconst struct intel_bw_state *new_bw_state =\n\t\tintel_atomic_get_new_bw_state(state);\n\tu16 old_mask, new_mask;\n\n\tif (!new_bw_state)\n\t\treturn;\n\n\told_mask = old_bw_state->qgv_points_mask | new_bw_state->qgv_points_mask;\n\tnew_mask = new_bw_state->qgv_points_mask;\n\n\tif (old_mask == new_mask)\n\t\treturn;\n\n\tWARN_ON(!new_bw_state->base.changed);\n\n\tdrm_dbg_kms(&i915->drm, \"Relaxing QGV points: 0x%x -> 0x%x\\n\",\n\t\t    old_mask, new_mask);\n\n\t \n\ticl_pcode_restrict_qgv_points(i915, new_mask);\n}\n\nvoid intel_sagv_pre_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\n\t \n\tif (!intel_has_sagv(i915))\n\t\treturn;\n\n\tif (DISPLAY_VER(i915) >= 11)\n\t\ticl_sagv_pre_plane_update(state);\n\telse\n\t\tskl_sagv_pre_plane_update(state);\n}\n\nvoid intel_sagv_post_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\n\t \n\tif (!intel_has_sagv(i915))\n\t\treturn;\n\n\tif (DISPLAY_VER(i915) >= 11)\n\t\ticl_sagv_post_plane_update(state);\n\telse\n\t\tskl_sagv_post_plane_update(state);\n}\n\nstatic bool skl_crtc_can_enable_sagv(const struct intel_crtc_state *crtc_state)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tenum plane_id plane_id;\n\tint max_level = INT_MAX;\n\n\tif (!intel_has_sagv(i915))\n\t\treturn false;\n\n\tif (!crtc_state->hw.active)\n\t\treturn true;\n\n\tif (crtc_state->hw.pipe_mode.flags & DRM_MODE_FLAG_INTERLACE)\n\t\treturn false;\n\n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tconst struct skl_plane_wm *wm =\n\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\t\tint level;\n\n\t\t \n\t\tif (!wm->wm[0].enable)\n\t\t\tcontinue;\n\n\t\t \n\t\tfor (level = i915->display.wm.num_levels - 1;\n\t\t     !wm->wm[level].enable; --level)\n\t\t     { }\n\n\t\t \n\t\tmax_level = min(level, max_level);\n\t}\n\n\t \n\tif (max_level == INT_MAX)\n\t\treturn true;\n\n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tconst struct skl_plane_wm *wm =\n\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\t \n\t\tif (wm->wm[0].enable && !wm->wm[max_level].can_sagv)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool tgl_crtc_can_enable_sagv(const struct intel_crtc_state *crtc_state)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tenum plane_id plane_id;\n\n\tif (!crtc_state->hw.active)\n\t\treturn true;\n\n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tconst struct skl_plane_wm *wm =\n\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\tif (wm->wm[0].enable && !wm->sagv.wm0.enable)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool intel_crtc_can_enable_sagv(const struct intel_crtc_state *crtc_state)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\n\tif (!i915->params.enable_sagv)\n\t\treturn false;\n\n\tif (DISPLAY_VER(i915) >= 12)\n\t\treturn tgl_crtc_can_enable_sagv(crtc_state);\n\telse\n\t\treturn skl_crtc_can_enable_sagv(crtc_state);\n}\n\nbool intel_can_enable_sagv(struct drm_i915_private *i915,\n\t\t\t   const struct intel_bw_state *bw_state)\n{\n\tif (DISPLAY_VER(i915) < 11 &&\n\t    bw_state->active_pipes && !is_power_of_2(bw_state->active_pipes))\n\t\treturn false;\n\n\treturn bw_state->pipe_sagv_reject == 0;\n}\n\nstatic int intel_compute_sagv_mask(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tint ret;\n\tstruct intel_crtc *crtc;\n\tstruct intel_crtc_state *new_crtc_state;\n\tstruct intel_bw_state *new_bw_state = NULL;\n\tconst struct intel_bw_state *old_bw_state = NULL;\n\tint i;\n\n\tfor_each_new_intel_crtc_in_state(state, crtc,\n\t\t\t\t\t new_crtc_state, i) {\n\t\tnew_bw_state = intel_atomic_get_bw_state(state);\n\t\tif (IS_ERR(new_bw_state))\n\t\t\treturn PTR_ERR(new_bw_state);\n\n\t\told_bw_state = intel_atomic_get_old_bw_state(state);\n\n\t\tif (intel_crtc_can_enable_sagv(new_crtc_state))\n\t\t\tnew_bw_state->pipe_sagv_reject &= ~BIT(crtc->pipe);\n\t\telse\n\t\t\tnew_bw_state->pipe_sagv_reject |= BIT(crtc->pipe);\n\t}\n\n\tif (!new_bw_state)\n\t\treturn 0;\n\n\tnew_bw_state->active_pipes =\n\t\tintel_calc_active_pipes(state, old_bw_state->active_pipes);\n\n\tif (new_bw_state->active_pipes != old_bw_state->active_pipes) {\n\t\tret = intel_atomic_lock_global_state(&new_bw_state->base);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (intel_can_enable_sagv(i915, new_bw_state) !=\n\t    intel_can_enable_sagv(i915, old_bw_state)) {\n\t\tret = intel_atomic_serialize_global_state(&new_bw_state->base);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (new_bw_state->pipe_sagv_reject != old_bw_state->pipe_sagv_reject) {\n\t\tret = intel_atomic_lock_global_state(&new_bw_state->base);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tfor_each_new_intel_crtc_in_state(state, crtc,\n\t\t\t\t\t new_crtc_state, i) {\n\t\tstruct skl_pipe_wm *pipe_wm = &new_crtc_state->wm.skl.optimal;\n\n\t\t \n\t\tpipe_wm->use_sagv_wm = !HAS_HW_SAGV_WM(i915) &&\n\t\t\tDISPLAY_VER(i915) >= 12 &&\n\t\t\tintel_can_enable_sagv(i915, new_bw_state);\n\t}\n\n\treturn 0;\n}\n\nstatic u16 skl_ddb_entry_init(struct skl_ddb_entry *entry,\n\t\t\t      u16 start, u16 end)\n{\n\tentry->start = start;\n\tentry->end = end;\n\n\treturn end;\n}\n\nstatic int intel_dbuf_slice_size(struct drm_i915_private *i915)\n{\n\treturn DISPLAY_INFO(i915)->dbuf.size /\n\t\thweight8(DISPLAY_INFO(i915)->dbuf.slice_mask);\n}\n\nstatic void\nskl_ddb_entry_for_slices(struct drm_i915_private *i915, u8 slice_mask,\n\t\t\t struct skl_ddb_entry *ddb)\n{\n\tint slice_size = intel_dbuf_slice_size(i915);\n\n\tif (!slice_mask) {\n\t\tddb->start = 0;\n\t\tddb->end = 0;\n\t\treturn;\n\t}\n\n\tddb->start = (ffs(slice_mask) - 1) * slice_size;\n\tddb->end = fls(slice_mask) * slice_size;\n\n\tWARN_ON(ddb->start >= ddb->end);\n\tWARN_ON(ddb->end > DISPLAY_INFO(i915)->dbuf.size);\n}\n\nstatic unsigned int mbus_ddb_offset(struct drm_i915_private *i915, u8 slice_mask)\n{\n\tstruct skl_ddb_entry ddb;\n\n\tif (slice_mask & (BIT(DBUF_S1) | BIT(DBUF_S2)))\n\t\tslice_mask = BIT(DBUF_S1);\n\telse if (slice_mask & (BIT(DBUF_S3) | BIT(DBUF_S4)))\n\t\tslice_mask = BIT(DBUF_S3);\n\n\tskl_ddb_entry_for_slices(i915, slice_mask, &ddb);\n\n\treturn ddb.start;\n}\n\nu32 skl_ddb_dbuf_slice_mask(struct drm_i915_private *i915,\n\t\t\t    const struct skl_ddb_entry *entry)\n{\n\tint slice_size = intel_dbuf_slice_size(i915);\n\tenum dbuf_slice start_slice, end_slice;\n\tu8 slice_mask = 0;\n\n\tif (!skl_ddb_entry_size(entry))\n\t\treturn 0;\n\n\tstart_slice = entry->start / slice_size;\n\tend_slice = (entry->end - 1) / slice_size;\n\n\t \n\twhile (start_slice <= end_slice) {\n\t\tslice_mask |= BIT(start_slice);\n\t\tstart_slice++;\n\t}\n\n\treturn slice_mask;\n}\n\nstatic unsigned int intel_crtc_ddb_weight(const struct intel_crtc_state *crtc_state)\n{\n\tconst struct drm_display_mode *pipe_mode = &crtc_state->hw.pipe_mode;\n\tint hdisplay, vdisplay;\n\n\tif (!crtc_state->hw.active)\n\t\treturn 0;\n\n\t \n\tdrm_mode_get_hv_timing(pipe_mode, &hdisplay, &vdisplay);\n\n\treturn hdisplay;\n}\n\nstatic void intel_crtc_dbuf_weights(const struct intel_dbuf_state *dbuf_state,\n\t\t\t\t    enum pipe for_pipe,\n\t\t\t\t    unsigned int *weight_start,\n\t\t\t\t    unsigned int *weight_end,\n\t\t\t\t    unsigned int *weight_total)\n{\n\tstruct drm_i915_private *i915 =\n\t\tto_i915(dbuf_state->base.state->base.dev);\n\tenum pipe pipe;\n\n\t*weight_start = 0;\n\t*weight_end = 0;\n\t*weight_total = 0;\n\n\tfor_each_pipe(i915, pipe) {\n\t\tint weight = dbuf_state->weight[pipe];\n\n\t\t \n\t\tif (dbuf_state->slices[pipe] != dbuf_state->slices[for_pipe])\n\t\t\tcontinue;\n\n\t\t*weight_total += weight;\n\t\tif (pipe < for_pipe) {\n\t\t\t*weight_start += weight;\n\t\t\t*weight_end += weight;\n\t\t} else if (pipe == for_pipe) {\n\t\t\t*weight_end += weight;\n\t\t}\n\t}\n}\n\nstatic int\nskl_crtc_allocate_ddb(struct intel_atomic_state *state, struct intel_crtc *crtc)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tunsigned int weight_total, weight_start, weight_end;\n\tconst struct intel_dbuf_state *old_dbuf_state =\n\t\tintel_atomic_get_old_dbuf_state(state);\n\tstruct intel_dbuf_state *new_dbuf_state =\n\t\tintel_atomic_get_new_dbuf_state(state);\n\tstruct intel_crtc_state *crtc_state;\n\tstruct skl_ddb_entry ddb_slices;\n\tenum pipe pipe = crtc->pipe;\n\tunsigned int mbus_offset = 0;\n\tu32 ddb_range_size;\n\tu32 dbuf_slice_mask;\n\tu32 start, end;\n\tint ret;\n\n\tif (new_dbuf_state->weight[pipe] == 0) {\n\t\tskl_ddb_entry_init(&new_dbuf_state->ddb[pipe], 0, 0);\n\t\tgoto out;\n\t}\n\n\tdbuf_slice_mask = new_dbuf_state->slices[pipe];\n\n\tskl_ddb_entry_for_slices(i915, dbuf_slice_mask, &ddb_slices);\n\tmbus_offset = mbus_ddb_offset(i915, dbuf_slice_mask);\n\tddb_range_size = skl_ddb_entry_size(&ddb_slices);\n\n\tintel_crtc_dbuf_weights(new_dbuf_state, pipe,\n\t\t\t\t&weight_start, &weight_end, &weight_total);\n\n\tstart = ddb_range_size * weight_start / weight_total;\n\tend = ddb_range_size * weight_end / weight_total;\n\n\tskl_ddb_entry_init(&new_dbuf_state->ddb[pipe],\n\t\t\t   ddb_slices.start - mbus_offset + start,\n\t\t\t   ddb_slices.start - mbus_offset + end);\n\nout:\n\tif (old_dbuf_state->slices[pipe] == new_dbuf_state->slices[pipe] &&\n\t    skl_ddb_entry_equal(&old_dbuf_state->ddb[pipe],\n\t\t\t\t&new_dbuf_state->ddb[pipe]))\n\t\treturn 0;\n\n\tret = intel_atomic_lock_global_state(&new_dbuf_state->base);\n\tif (ret)\n\t\treturn ret;\n\n\tcrtc_state = intel_atomic_get_crtc_state(&state->base, crtc);\n\tif (IS_ERR(crtc_state))\n\t\treturn PTR_ERR(crtc_state);\n\n\t \n\tcrtc_state->wm.skl.ddb.start = mbus_offset + new_dbuf_state->ddb[pipe].start;\n\tcrtc_state->wm.skl.ddb.end = mbus_offset + new_dbuf_state->ddb[pipe].end;\n\n\tdrm_dbg_kms(&i915->drm,\n\t\t    \"[CRTC:%d:%s] dbuf slices 0x%x -> 0x%x, ddb (%d - %d) -> (%d - %d), active pipes 0x%x -> 0x%x\\n\",\n\t\t    crtc->base.base.id, crtc->base.name,\n\t\t    old_dbuf_state->slices[pipe], new_dbuf_state->slices[pipe],\n\t\t    old_dbuf_state->ddb[pipe].start, old_dbuf_state->ddb[pipe].end,\n\t\t    new_dbuf_state->ddb[pipe].start, new_dbuf_state->ddb[pipe].end,\n\t\t    old_dbuf_state->active_pipes, new_dbuf_state->active_pipes);\n\n\treturn 0;\n}\n\nstatic int skl_compute_wm_params(const struct intel_crtc_state *crtc_state,\n\t\t\t\t int width, const struct drm_format_info *format,\n\t\t\t\t u64 modifier, unsigned int rotation,\n\t\t\t\t u32 plane_pixel_rate, struct skl_wm_params *wp,\n\t\t\t\t int color_plane);\n\nstatic void skl_compute_plane_wm(const struct intel_crtc_state *crtc_state,\n\t\t\t\t struct intel_plane *plane,\n\t\t\t\t int level,\n\t\t\t\t unsigned int latency,\n\t\t\t\t const struct skl_wm_params *wp,\n\t\t\t\t const struct skl_wm_level *result_prev,\n\t\t\t\t struct skl_wm_level *result  );\n\nstatic unsigned int skl_wm_latency(struct drm_i915_private *i915, int level,\n\t\t\t\t   const struct skl_wm_params *wp)\n{\n\tunsigned int latency = i915->display.wm.skl_latency[level];\n\n\tif (latency == 0)\n\t\treturn 0;\n\n\t \n\tif ((IS_KABYLAKE(i915) || IS_COFFEELAKE(i915) || IS_COMETLAKE(i915)) &&\n\t    skl_watermark_ipc_enabled(i915))\n\t\tlatency += 4;\n\n\tif (skl_needs_memory_bw_wa(i915) && wp && wp->x_tiled)\n\t\tlatency += 15;\n\n\treturn latency;\n}\n\nstatic unsigned int\nskl_cursor_allocation(const struct intel_crtc_state *crtc_state,\n\t\t      int num_active)\n{\n\tstruct intel_plane *plane = to_intel_plane(crtc_state->uapi.crtc->cursor);\n\tstruct drm_i915_private *i915 = to_i915(crtc_state->uapi.crtc->dev);\n\tstruct skl_wm_level wm = {};\n\tint ret, min_ddb_alloc = 0;\n\tstruct skl_wm_params wp;\n\tint level;\n\n\tret = skl_compute_wm_params(crtc_state, 256,\n\t\t\t\t    drm_format_info(DRM_FORMAT_ARGB8888),\n\t\t\t\t    DRM_FORMAT_MOD_LINEAR,\n\t\t\t\t    DRM_MODE_ROTATE_0,\n\t\t\t\t    crtc_state->pixel_rate, &wp, 0);\n\tdrm_WARN_ON(&i915->drm, ret);\n\n\tfor (level = 0; level < i915->display.wm.num_levels; level++) {\n\t\tunsigned int latency = skl_wm_latency(i915, level, &wp);\n\n\t\tskl_compute_plane_wm(crtc_state, plane, level, latency, &wp, &wm, &wm);\n\t\tif (wm.min_ddb_alloc == U16_MAX)\n\t\t\tbreak;\n\n\t\tmin_ddb_alloc = wm.min_ddb_alloc;\n\t}\n\n\treturn max(num_active == 1 ? 32 : 8, min_ddb_alloc);\n}\n\nstatic void skl_ddb_entry_init_from_hw(struct skl_ddb_entry *entry, u32 reg)\n{\n\tskl_ddb_entry_init(entry,\n\t\t\t   REG_FIELD_GET(PLANE_BUF_START_MASK, reg),\n\t\t\t   REG_FIELD_GET(PLANE_BUF_END_MASK, reg));\n\tif (entry->end)\n\t\tentry->end++;\n}\n\nstatic void\nskl_ddb_get_hw_plane_state(struct drm_i915_private *i915,\n\t\t\t   const enum pipe pipe,\n\t\t\t   const enum plane_id plane_id,\n\t\t\t   struct skl_ddb_entry *ddb,\n\t\t\t   struct skl_ddb_entry *ddb_y)\n{\n\tu32 val;\n\n\t \n\tif (plane_id == PLANE_CURSOR) {\n\t\tval = intel_de_read(i915, CUR_BUF_CFG(pipe));\n\t\tskl_ddb_entry_init_from_hw(ddb, val);\n\t\treturn;\n\t}\n\n\tval = intel_de_read(i915, PLANE_BUF_CFG(pipe, plane_id));\n\tskl_ddb_entry_init_from_hw(ddb, val);\n\n\tif (DISPLAY_VER(i915) >= 11)\n\t\treturn;\n\n\tval = intel_de_read(i915, PLANE_NV12_BUF_CFG(pipe, plane_id));\n\tskl_ddb_entry_init_from_hw(ddb_y, val);\n}\n\nstatic void skl_pipe_ddb_get_hw_state(struct intel_crtc *crtc,\n\t\t\t\t      struct skl_ddb_entry *ddb,\n\t\t\t\t      struct skl_ddb_entry *ddb_y)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tenum intel_display_power_domain power_domain;\n\tenum pipe pipe = crtc->pipe;\n\tintel_wakeref_t wakeref;\n\tenum plane_id plane_id;\n\n\tpower_domain = POWER_DOMAIN_PIPE(pipe);\n\twakeref = intel_display_power_get_if_enabled(i915, power_domain);\n\tif (!wakeref)\n\t\treturn;\n\n\tfor_each_plane_id_on_crtc(crtc, plane_id)\n\t\tskl_ddb_get_hw_plane_state(i915, pipe,\n\t\t\t\t\t   plane_id,\n\t\t\t\t\t   &ddb[plane_id],\n\t\t\t\t\t   &ddb_y[plane_id]);\n\n\tintel_display_power_put(i915, power_domain, wakeref);\n}\n\nstruct dbuf_slice_conf_entry {\n\tu8 active_pipes;\n\tu8 dbuf_mask[I915_MAX_PIPES];\n\tbool join_mbus;\n};\n\n \nstatic const struct dbuf_slice_conf_entry icl_allowed_dbufs[] =\n \n{\n\t{\n\t\t.active_pipes = BIT(PIPE_A),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{}\n};\n\n \nstatic const struct dbuf_slice_conf_entry tgl_allowed_dbufs[] =\n \n{\n\t{\n\t\t.active_pipes = BIT(PIPE_A),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S2),\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_C] = BIT(DBUF_S2) | BIT(DBUF_S1),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_D] = BIT(DBUF_S2) | BIT(DBUF_S1),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_D] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_D] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_D] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_C] = BIT(DBUF_S1),\n\t\t\t[PIPE_D] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t\t[PIPE_D] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t\t[PIPE_D] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S1),\n\t\t\t[PIPE_C] = BIT(DBUF_S2),\n\t\t\t[PIPE_D] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{}\n};\n\nstatic const struct dbuf_slice_conf_entry dg2_allowed_dbufs[] = {\n\t{\n\t\t.active_pipes = BIT(PIPE_A),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_D] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_D] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_D] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S2),\n\t\t\t[PIPE_D] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_C] = BIT(DBUF_S3),\n\t\t\t[PIPE_D] = BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3),\n\t\t\t[PIPE_D] = BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3),\n\t\t\t[PIPE_D] = BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1),\n\t\t\t[PIPE_B] = BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3),\n\t\t\t[PIPE_D] = BIT(DBUF_S4),\n\t\t},\n\t},\n\t{}\n};\n\nstatic const struct dbuf_slice_conf_entry adlp_allowed_dbufs[] = {\n\t \n\t{\n\t\t.active_pipes = BIT(PIPE_A),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2) | BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t\t.join_mbus = true,\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S1) | BIT(DBUF_S2) | BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t\t.join_mbus = true,\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t\t.join_mbus = false,\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t\t.join_mbus = false,\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_C),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_B) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{\n\t\t.active_pipes = BIT(PIPE_A) | BIT(PIPE_B) | BIT(PIPE_C) | BIT(PIPE_D),\n\t\t.dbuf_mask = {\n\t\t\t[PIPE_A] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t\t[PIPE_B] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_C] = BIT(DBUF_S3) | BIT(DBUF_S4),\n\t\t\t[PIPE_D] = BIT(DBUF_S1) | BIT(DBUF_S2),\n\t\t},\n\t},\n\t{}\n\n};\n\nstatic bool check_mbus_joined(u8 active_pipes,\n\t\t\t      const struct dbuf_slice_conf_entry *dbuf_slices)\n{\n\tint i;\n\n\tfor (i = 0; dbuf_slices[i].active_pipes != 0; i++) {\n\t\tif (dbuf_slices[i].active_pipes == active_pipes)\n\t\t\treturn dbuf_slices[i].join_mbus;\n\t}\n\treturn false;\n}\n\nstatic bool adlp_check_mbus_joined(u8 active_pipes)\n{\n\treturn check_mbus_joined(active_pipes, adlp_allowed_dbufs);\n}\n\nstatic u8 compute_dbuf_slices(enum pipe pipe, u8 active_pipes, bool join_mbus,\n\t\t\t      const struct dbuf_slice_conf_entry *dbuf_slices)\n{\n\tint i;\n\n\tfor (i = 0; dbuf_slices[i].active_pipes != 0; i++) {\n\t\tif (dbuf_slices[i].active_pipes == active_pipes &&\n\t\t    dbuf_slices[i].join_mbus == join_mbus)\n\t\t\treturn dbuf_slices[i].dbuf_mask[pipe];\n\t}\n\treturn 0;\n}\n\n \nstatic u8 icl_compute_dbuf_slices(enum pipe pipe, u8 active_pipes, bool join_mbus)\n{\n\t \n\treturn compute_dbuf_slices(pipe, active_pipes, join_mbus,\n\t\t\t\t   icl_allowed_dbufs);\n}\n\nstatic u8 tgl_compute_dbuf_slices(enum pipe pipe, u8 active_pipes, bool join_mbus)\n{\n\treturn compute_dbuf_slices(pipe, active_pipes, join_mbus,\n\t\t\t\t   tgl_allowed_dbufs);\n}\n\nstatic u8 adlp_compute_dbuf_slices(enum pipe pipe, u8 active_pipes, bool join_mbus)\n{\n\treturn compute_dbuf_slices(pipe, active_pipes, join_mbus,\n\t\t\t\t   adlp_allowed_dbufs);\n}\n\nstatic u8 dg2_compute_dbuf_slices(enum pipe pipe, u8 active_pipes, bool join_mbus)\n{\n\treturn compute_dbuf_slices(pipe, active_pipes, join_mbus,\n\t\t\t\t   dg2_allowed_dbufs);\n}\n\nstatic u8 skl_compute_dbuf_slices(struct intel_crtc *crtc, u8 active_pipes, bool join_mbus)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tenum pipe pipe = crtc->pipe;\n\n\tif (IS_DG2(i915))\n\t\treturn dg2_compute_dbuf_slices(pipe, active_pipes, join_mbus);\n\telse if (DISPLAY_VER(i915) >= 13)\n\t\treturn adlp_compute_dbuf_slices(pipe, active_pipes, join_mbus);\n\telse if (DISPLAY_VER(i915) == 12)\n\t\treturn tgl_compute_dbuf_slices(pipe, active_pipes, join_mbus);\n\telse if (DISPLAY_VER(i915) == 11)\n\t\treturn icl_compute_dbuf_slices(pipe, active_pipes, join_mbus);\n\t \n\treturn active_pipes & BIT(pipe) ? BIT(DBUF_S1) : 0;\n}\n\nstatic bool\nuse_minimal_wm0_only(const struct intel_crtc_state *crtc_state,\n\t\t     struct intel_plane *plane)\n{\n\tstruct drm_i915_private *i915 = to_i915(plane->base.dev);\n\n\treturn DISPLAY_VER(i915) >= 13 &&\n\t       crtc_state->uapi.async_flip &&\n\t       plane->async_flip;\n}\n\nstatic u64\nskl_total_relative_data_rate(const struct intel_crtc_state *crtc_state)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tenum plane_id plane_id;\n\tu64 data_rate = 0;\n\n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tif (plane_id == PLANE_CURSOR)\n\t\t\tcontinue;\n\n\t\tdata_rate += crtc_state->rel_data_rate[plane_id];\n\n\t\tif (DISPLAY_VER(i915) < 11)\n\t\t\tdata_rate += crtc_state->rel_data_rate_y[plane_id];\n\t}\n\n\treturn data_rate;\n}\n\nstatic const struct skl_wm_level *\nskl_plane_wm_level(const struct skl_pipe_wm *pipe_wm,\n\t\t   enum plane_id plane_id,\n\t\t   int level)\n{\n\tconst struct skl_plane_wm *wm = &pipe_wm->planes[plane_id];\n\n\tif (level == 0 && pipe_wm->use_sagv_wm)\n\t\treturn &wm->sagv.wm0;\n\n\treturn &wm->wm[level];\n}\n\nstatic const struct skl_wm_level *\nskl_plane_trans_wm(const struct skl_pipe_wm *pipe_wm,\n\t\t   enum plane_id plane_id)\n{\n\tconst struct skl_plane_wm *wm = &pipe_wm->planes[plane_id];\n\n\tif (pipe_wm->use_sagv_wm)\n\t\treturn &wm->sagv.trans_wm;\n\n\treturn &wm->trans_wm;\n}\n\n \nstatic void\nskl_check_wm_level(struct skl_wm_level *wm, const struct skl_ddb_entry *ddb)\n{\n\tif (wm->min_ddb_alloc > skl_ddb_entry_size(ddb))\n\t\tmemset(wm, 0, sizeof(*wm));\n}\n\nstatic void\nskl_check_nv12_wm_level(struct skl_wm_level *wm, struct skl_wm_level *uv_wm,\n\t\t\tconst struct skl_ddb_entry *ddb_y, const struct skl_ddb_entry *ddb)\n{\n\tif (wm->min_ddb_alloc > skl_ddb_entry_size(ddb_y) ||\n\t    uv_wm->min_ddb_alloc > skl_ddb_entry_size(ddb)) {\n\t\tmemset(wm, 0, sizeof(*wm));\n\t\tmemset(uv_wm, 0, sizeof(*uv_wm));\n\t}\n}\n\nstatic bool skl_need_wm_copy_wa(struct drm_i915_private *i915, int level,\n\t\t\t\tconst struct skl_plane_wm *wm)\n{\n\t \n\treturn level > 0 && !wm->wm[level].enable;\n}\n\nstruct skl_plane_ddb_iter {\n\tu64 data_rate;\n\tu16 start, size;\n};\n\nstatic void\nskl_allocate_plane_ddb(struct skl_plane_ddb_iter *iter,\n\t\t       struct skl_ddb_entry *ddb,\n\t\t       const struct skl_wm_level *wm,\n\t\t       u64 data_rate)\n{\n\tu16 size, extra = 0;\n\n\tif (data_rate) {\n\t\textra = min_t(u16, iter->size,\n\t\t\t      DIV64_U64_ROUND_UP(iter->size * data_rate,\n\t\t\t\t\t\t iter->data_rate));\n\t\titer->size -= extra;\n\t\titer->data_rate -= data_rate;\n\t}\n\n\t \n\tsize = wm->min_ddb_alloc + extra;\n\tif (size)\n\t\titer->start = skl_ddb_entry_init(ddb, iter->start,\n\t\t\t\t\t\t iter->start + size);\n}\n\nstatic int\nskl_crtc_allocate_plane_ddb(struct intel_atomic_state *state,\n\t\t\t    struct intel_crtc *crtc)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tstruct intel_crtc_state *crtc_state =\n\t\tintel_atomic_get_new_crtc_state(state, crtc);\n\tconst struct intel_dbuf_state *dbuf_state =\n\t\tintel_atomic_get_new_dbuf_state(state);\n\tconst struct skl_ddb_entry *alloc = &dbuf_state->ddb[crtc->pipe];\n\tint num_active = hweight8(dbuf_state->active_pipes);\n\tstruct skl_plane_ddb_iter iter;\n\tenum plane_id plane_id;\n\tu16 cursor_size;\n\tu32 blocks;\n\tint level;\n\n\t \n\tmemset(crtc_state->wm.skl.plane_ddb, 0, sizeof(crtc_state->wm.skl.plane_ddb));\n\tmemset(crtc_state->wm.skl.plane_ddb_y, 0, sizeof(crtc_state->wm.skl.plane_ddb_y));\n\n\tif (!crtc_state->hw.active)\n\t\treturn 0;\n\n\titer.start = alloc->start;\n\titer.size = skl_ddb_entry_size(alloc);\n\tif (iter.size == 0)\n\t\treturn 0;\n\n\t \n\tcursor_size = skl_cursor_allocation(crtc_state, num_active);\n\titer.size -= cursor_size;\n\tskl_ddb_entry_init(&crtc_state->wm.skl.plane_ddb[PLANE_CURSOR],\n\t\t\t   alloc->end - cursor_size, alloc->end);\n\n\titer.data_rate = skl_total_relative_data_rate(crtc_state);\n\n\t \n\tfor (level = i915->display.wm.num_levels - 1; level >= 0; level--) {\n\t\tblocks = 0;\n\t\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\t\tconst struct skl_plane_wm *wm =\n\t\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\t\tif (plane_id == PLANE_CURSOR) {\n\t\t\t\tconst struct skl_ddb_entry *ddb =\n\t\t\t\t\t&crtc_state->wm.skl.plane_ddb[plane_id];\n\n\t\t\t\tif (wm->wm[level].min_ddb_alloc > skl_ddb_entry_size(ddb)) {\n\t\t\t\t\tdrm_WARN_ON(&i915->drm,\n\t\t\t\t\t\t    wm->wm[level].min_ddb_alloc != U16_MAX);\n\t\t\t\t\tblocks = U32_MAX;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tblocks += wm->wm[level].min_ddb_alloc;\n\t\t\tblocks += wm->uv_wm[level].min_ddb_alloc;\n\t\t}\n\n\t\tif (blocks <= iter.size) {\n\t\t\titer.size -= blocks;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (level < 0) {\n\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t    \"Requested display configuration exceeds system DDB limitations\");\n\t\tdrm_dbg_kms(&i915->drm, \"minimum required %d/%d\\n\",\n\t\t\t    blocks, iter.size);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (iter.data_rate == 0)\n\t\titer.size = 0;\n\n\t \n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tstruct skl_ddb_entry *ddb =\n\t\t\t&crtc_state->wm.skl.plane_ddb[plane_id];\n\t\tstruct skl_ddb_entry *ddb_y =\n\t\t\t&crtc_state->wm.skl.plane_ddb_y[plane_id];\n\t\tconst struct skl_plane_wm *wm =\n\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\tif (plane_id == PLANE_CURSOR)\n\t\t\tcontinue;\n\n\t\tif (DISPLAY_VER(i915) < 11 &&\n\t\t    crtc_state->nv12_planes & BIT(plane_id)) {\n\t\t\tskl_allocate_plane_ddb(&iter, ddb_y, &wm->wm[level],\n\t\t\t\t\t       crtc_state->rel_data_rate_y[plane_id]);\n\t\t\tskl_allocate_plane_ddb(&iter, ddb, &wm->uv_wm[level],\n\t\t\t\t\t       crtc_state->rel_data_rate[plane_id]);\n\t\t} else {\n\t\t\tskl_allocate_plane_ddb(&iter, ddb, &wm->wm[level],\n\t\t\t\t\t       crtc_state->rel_data_rate[plane_id]);\n\t\t}\n\t}\n\tdrm_WARN_ON(&i915->drm, iter.size != 0 || iter.data_rate != 0);\n\n\t \n\tfor (level++; level < i915->display.wm.num_levels; level++) {\n\t\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\t\tconst struct skl_ddb_entry *ddb =\n\t\t\t\t&crtc_state->wm.skl.plane_ddb[plane_id];\n\t\t\tconst struct skl_ddb_entry *ddb_y =\n\t\t\t\t&crtc_state->wm.skl.plane_ddb_y[plane_id];\n\t\t\tstruct skl_plane_wm *wm =\n\t\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\t\tif (DISPLAY_VER(i915) < 11 &&\n\t\t\t    crtc_state->nv12_planes & BIT(plane_id))\n\t\t\t\tskl_check_nv12_wm_level(&wm->wm[level],\n\t\t\t\t\t\t\t&wm->uv_wm[level],\n\t\t\t\t\t\t\tddb_y, ddb);\n\t\t\telse\n\t\t\t\tskl_check_wm_level(&wm->wm[level], ddb);\n\n\t\t\tif (skl_need_wm_copy_wa(i915, level, wm)) {\n\t\t\t\twm->wm[level].blocks = wm->wm[level - 1].blocks;\n\t\t\t\twm->wm[level].lines = wm->wm[level - 1].lines;\n\t\t\t\twm->wm[level].ignore_lines = wm->wm[level - 1].ignore_lines;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tconst struct skl_ddb_entry *ddb =\n\t\t\t&crtc_state->wm.skl.plane_ddb[plane_id];\n\t\tconst struct skl_ddb_entry *ddb_y =\n\t\t\t&crtc_state->wm.skl.plane_ddb_y[plane_id];\n\t\tstruct skl_plane_wm *wm =\n\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\tif (DISPLAY_VER(i915) < 11 &&\n\t\t    crtc_state->nv12_planes & BIT(plane_id)) {\n\t\t\tskl_check_wm_level(&wm->trans_wm, ddb_y);\n\t\t} else {\n\t\t\tWARN_ON(skl_ddb_entry_size(ddb_y));\n\n\t\t\tskl_check_wm_level(&wm->trans_wm, ddb);\n\t\t}\n\n\t\tskl_check_wm_level(&wm->sagv.wm0, ddb);\n\t\tskl_check_wm_level(&wm->sagv.trans_wm, ddb);\n\t}\n\n\treturn 0;\n}\n\n \nstatic uint_fixed_16_16_t\nskl_wm_method1(const struct drm_i915_private *i915, u32 pixel_rate,\n\t       u8 cpp, u32 latency, u32 dbuf_block_size)\n{\n\tu32 wm_intermediate_val;\n\tuint_fixed_16_16_t ret;\n\n\tif (latency == 0)\n\t\treturn FP_16_16_MAX;\n\n\twm_intermediate_val = latency * pixel_rate * cpp;\n\tret = div_fixed16(wm_intermediate_val, 1000 * dbuf_block_size);\n\n\tif (DISPLAY_VER(i915) >= 10)\n\t\tret = add_fixed16_u32(ret, 1);\n\n\treturn ret;\n}\n\nstatic uint_fixed_16_16_t\nskl_wm_method2(u32 pixel_rate, u32 pipe_htotal, u32 latency,\n\t       uint_fixed_16_16_t plane_blocks_per_line)\n{\n\tu32 wm_intermediate_val;\n\tuint_fixed_16_16_t ret;\n\n\tif (latency == 0)\n\t\treturn FP_16_16_MAX;\n\n\twm_intermediate_val = latency * pixel_rate;\n\twm_intermediate_val = DIV_ROUND_UP(wm_intermediate_val,\n\t\t\t\t\t   pipe_htotal * 1000);\n\tret = mul_u32_fixed16(wm_intermediate_val, plane_blocks_per_line);\n\treturn ret;\n}\n\nstatic uint_fixed_16_16_t\nintel_get_linetime_us(const struct intel_crtc_state *crtc_state)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc_state->uapi.crtc->dev);\n\tu32 pixel_rate;\n\tu32 crtc_htotal;\n\tuint_fixed_16_16_t linetime_us;\n\n\tif (!crtc_state->hw.active)\n\t\treturn u32_to_fixed16(0);\n\n\tpixel_rate = crtc_state->pixel_rate;\n\n\tif (drm_WARN_ON(&i915->drm, pixel_rate == 0))\n\t\treturn u32_to_fixed16(0);\n\n\tcrtc_htotal = crtc_state->hw.pipe_mode.crtc_htotal;\n\tlinetime_us = div_fixed16(crtc_htotal * 1000, pixel_rate);\n\n\treturn linetime_us;\n}\n\nstatic int\nskl_compute_wm_params(const struct intel_crtc_state *crtc_state,\n\t\t      int width, const struct drm_format_info *format,\n\t\t      u64 modifier, unsigned int rotation,\n\t\t      u32 plane_pixel_rate, struct skl_wm_params *wp,\n\t\t      int color_plane)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tu32 interm_pbpl;\n\n\t \n\tif (color_plane == 1 &&\n\t    !intel_format_info_is_yuv_semiplanar(format, modifier)) {\n\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t    \"Non planar format have single plane\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\twp->x_tiled = modifier == I915_FORMAT_MOD_X_TILED;\n\twp->y_tiled = modifier != I915_FORMAT_MOD_X_TILED &&\n\t\tintel_fb_is_tiled_modifier(modifier);\n\twp->rc_surface = intel_fb_is_ccs_modifier(modifier);\n\twp->is_planar = intel_format_info_is_yuv_semiplanar(format, modifier);\n\n\twp->width = width;\n\tif (color_plane == 1 && wp->is_planar)\n\t\twp->width /= 2;\n\n\twp->cpp = format->cpp[color_plane];\n\twp->plane_pixel_rate = plane_pixel_rate;\n\n\tif (DISPLAY_VER(i915) >= 11 &&\n\t    modifier == I915_FORMAT_MOD_Yf_TILED  && wp->cpp == 1)\n\t\twp->dbuf_block_size = 256;\n\telse\n\t\twp->dbuf_block_size = 512;\n\n\tif (drm_rotation_90_or_270(rotation)) {\n\t\tswitch (wp->cpp) {\n\t\tcase 1:\n\t\t\twp->y_min_scanlines = 16;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\twp->y_min_scanlines = 8;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\twp->y_min_scanlines = 4;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tMISSING_CASE(wp->cpp);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\twp->y_min_scanlines = 4;\n\t}\n\n\tif (skl_needs_memory_bw_wa(i915))\n\t\twp->y_min_scanlines *= 2;\n\n\twp->plane_bytes_per_line = wp->width * wp->cpp;\n\tif (wp->y_tiled) {\n\t\tinterm_pbpl = DIV_ROUND_UP(wp->plane_bytes_per_line *\n\t\t\t\t\t   wp->y_min_scanlines,\n\t\t\t\t\t   wp->dbuf_block_size);\n\n\t\tif (DISPLAY_VER(i915) >= 10)\n\t\t\tinterm_pbpl++;\n\n\t\twp->plane_blocks_per_line = div_fixed16(interm_pbpl,\n\t\t\t\t\t\t\twp->y_min_scanlines);\n\t} else {\n\t\tinterm_pbpl = DIV_ROUND_UP(wp->plane_bytes_per_line,\n\t\t\t\t\t   wp->dbuf_block_size);\n\n\t\tif (!wp->x_tiled || DISPLAY_VER(i915) >= 10)\n\t\t\tinterm_pbpl++;\n\n\t\twp->plane_blocks_per_line = u32_to_fixed16(interm_pbpl);\n\t}\n\n\twp->y_tile_minimum = mul_u32_fixed16(wp->y_min_scanlines,\n\t\t\t\t\t     wp->plane_blocks_per_line);\n\n\twp->linetime_us = fixed16_to_u32_round_up(intel_get_linetime_us(crtc_state));\n\n\treturn 0;\n}\n\nstatic int\nskl_compute_plane_wm_params(const struct intel_crtc_state *crtc_state,\n\t\t\t    const struct intel_plane_state *plane_state,\n\t\t\t    struct skl_wm_params *wp, int color_plane)\n{\n\tconst struct drm_framebuffer *fb = plane_state->hw.fb;\n\tint width;\n\n\t \n\twidth = drm_rect_width(&plane_state->uapi.src) >> 16;\n\n\treturn skl_compute_wm_params(crtc_state, width,\n\t\t\t\t     fb->format, fb->modifier,\n\t\t\t\t     plane_state->hw.rotation,\n\t\t\t\t     intel_plane_pixel_rate(crtc_state, plane_state),\n\t\t\t\t     wp, color_plane);\n}\n\nstatic bool skl_wm_has_lines(struct drm_i915_private *i915, int level)\n{\n\tif (DISPLAY_VER(i915) >= 10)\n\t\treturn true;\n\n\t \n\treturn level > 0;\n}\n\nstatic int skl_wm_max_lines(struct drm_i915_private *i915)\n{\n\tif (DISPLAY_VER(i915) >= 13)\n\t\treturn 255;\n\telse\n\t\treturn 31;\n}\n\nstatic void skl_compute_plane_wm(const struct intel_crtc_state *crtc_state,\n\t\t\t\t struct intel_plane *plane,\n\t\t\t\t int level,\n\t\t\t\t unsigned int latency,\n\t\t\t\t const struct skl_wm_params *wp,\n\t\t\t\t const struct skl_wm_level *result_prev,\n\t\t\t\t struct skl_wm_level *result  )\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc_state->uapi.crtc->dev);\n\tuint_fixed_16_16_t method1, method2;\n\tuint_fixed_16_16_t selected_result;\n\tu32 blocks, lines, min_ddb_alloc = 0;\n\n\tif (latency == 0 ||\n\t    (use_minimal_wm0_only(crtc_state, plane) && level > 0)) {\n\t\t \n\t\tresult->min_ddb_alloc = U16_MAX;\n\t\treturn;\n\t}\n\n\tmethod1 = skl_wm_method1(i915, wp->plane_pixel_rate,\n\t\t\t\t wp->cpp, latency, wp->dbuf_block_size);\n\tmethod2 = skl_wm_method2(wp->plane_pixel_rate,\n\t\t\t\t crtc_state->hw.pipe_mode.crtc_htotal,\n\t\t\t\t latency,\n\t\t\t\t wp->plane_blocks_per_line);\n\n\tif (wp->y_tiled) {\n\t\tselected_result = max_fixed16(method2, wp->y_tile_minimum);\n\t} else {\n\t\tif ((wp->cpp * crtc_state->hw.pipe_mode.crtc_htotal /\n\t\t     wp->dbuf_block_size < 1) &&\n\t\t     (wp->plane_bytes_per_line / wp->dbuf_block_size < 1)) {\n\t\t\tselected_result = method2;\n\t\t} else if (latency >= wp->linetime_us) {\n\t\t\tif (DISPLAY_VER(i915) == 9)\n\t\t\t\tselected_result = min_fixed16(method1, method2);\n\t\t\telse\n\t\t\t\tselected_result = method2;\n\t\t} else {\n\t\t\tselected_result = method1;\n\t\t}\n\t}\n\n\tblocks = fixed16_to_u32_round_up(selected_result) + 1;\n\t \n\tif (skl_wm_has_lines(i915, level))\n\t\tblocks = max(blocks,\n\t\t\t     fixed16_to_u32_round_up(wp->plane_blocks_per_line));\n\tlines = div_round_up_fixed16(selected_result,\n\t\t\t\t     wp->plane_blocks_per_line);\n\n\tif (DISPLAY_VER(i915) == 9) {\n\t\t \n\t\tif (level == 0 && wp->rc_surface)\n\t\t\tblocks += fixed16_to_u32_round_up(wp->y_tile_minimum);\n\n\t\t \n\t\tif (level >= 1 && level <= 7) {\n\t\t\tif (wp->y_tiled) {\n\t\t\t\tblocks += fixed16_to_u32_round_up(wp->y_tile_minimum);\n\t\t\t\tlines += wp->y_min_scanlines;\n\t\t\t} else {\n\t\t\t\tblocks++;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (result_prev->blocks > blocks)\n\t\t\t\tblocks = result_prev->blocks;\n\t\t}\n\t}\n\n\tif (DISPLAY_VER(i915) >= 11) {\n\t\tif (wp->y_tiled) {\n\t\t\tint extra_lines;\n\n\t\t\tif (lines % wp->y_min_scanlines == 0)\n\t\t\t\textra_lines = wp->y_min_scanlines;\n\t\t\telse\n\t\t\t\textra_lines = wp->y_min_scanlines * 2 -\n\t\t\t\t\tlines % wp->y_min_scanlines;\n\n\t\t\tmin_ddb_alloc = mul_round_up_u32_fixed16(lines + extra_lines,\n\t\t\t\t\t\t\t\t wp->plane_blocks_per_line);\n\t\t} else {\n\t\t\tmin_ddb_alloc = blocks + DIV_ROUND_UP(blocks, 10);\n\t\t}\n\t}\n\n\tif (!skl_wm_has_lines(i915, level))\n\t\tlines = 0;\n\n\tif (lines > skl_wm_max_lines(i915)) {\n\t\t \n\t\tresult->min_ddb_alloc = U16_MAX;\n\t\treturn;\n\t}\n\n\t \n\tresult->blocks = blocks;\n\tresult->lines = lines;\n\t \n\tresult->min_ddb_alloc = max(min_ddb_alloc, blocks) + 1;\n\tresult->enable = true;\n\n\tif (DISPLAY_VER(i915) < 12 && i915->display.sagv.block_time_us)\n\t\tresult->can_sagv = latency >= i915->display.sagv.block_time_us;\n}\n\nstatic void\nskl_compute_wm_levels(const struct intel_crtc_state *crtc_state,\n\t\t      struct intel_plane *plane,\n\t\t      const struct skl_wm_params *wm_params,\n\t\t      struct skl_wm_level *levels)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc_state->uapi.crtc->dev);\n\tstruct skl_wm_level *result_prev = &levels[0];\n\tint level;\n\n\tfor (level = 0; level < i915->display.wm.num_levels; level++) {\n\t\tstruct skl_wm_level *result = &levels[level];\n\t\tunsigned int latency = skl_wm_latency(i915, level, wm_params);\n\n\t\tskl_compute_plane_wm(crtc_state, plane, level, latency,\n\t\t\t\t     wm_params, result_prev, result);\n\n\t\tresult_prev = result;\n\t}\n}\n\nstatic void tgl_compute_sagv_wm(const struct intel_crtc_state *crtc_state,\n\t\t\t\tstruct intel_plane *plane,\n\t\t\t\tconst struct skl_wm_params *wm_params,\n\t\t\t\tstruct skl_plane_wm *plane_wm)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc_state->uapi.crtc->dev);\n\tstruct skl_wm_level *sagv_wm = &plane_wm->sagv.wm0;\n\tstruct skl_wm_level *levels = plane_wm->wm;\n\tunsigned int latency = 0;\n\n\tif (i915->display.sagv.block_time_us)\n\t\tlatency = i915->display.sagv.block_time_us +\n\t\t\tskl_wm_latency(i915, 0, wm_params);\n\n\tskl_compute_plane_wm(crtc_state, plane, 0, latency,\n\t\t\t     wm_params, &levels[0],\n\t\t\t     sagv_wm);\n}\n\nstatic void skl_compute_transition_wm(struct drm_i915_private *i915,\n\t\t\t\t      struct skl_wm_level *trans_wm,\n\t\t\t\t      const struct skl_wm_level *wm0,\n\t\t\t\t      const struct skl_wm_params *wp)\n{\n\tu16 trans_min, trans_amount, trans_y_tile_min;\n\tu16 wm0_blocks, trans_offset, blocks;\n\n\t \n\tif (!skl_watermark_ipc_enabled(i915))\n\t\treturn;\n\n\t \n\tif (DISPLAY_VER(i915) == 9)\n\t\treturn;\n\n\tif (DISPLAY_VER(i915) >= 11)\n\t\ttrans_min = 4;\n\telse\n\t\ttrans_min = 14;\n\n\t \n\tif (DISPLAY_VER(i915) == 10)\n\t\ttrans_amount = 0;\n\telse\n\t\ttrans_amount = 10;  \n\n\ttrans_offset = trans_min + trans_amount;\n\n\t \n\twm0_blocks = wm0->blocks - 1;\n\n\tif (wp->y_tiled) {\n\t\ttrans_y_tile_min =\n\t\t\t(u16)mul_round_up_u32_fixed16(2, wp->y_tile_minimum);\n\t\tblocks = max(wm0_blocks, trans_y_tile_min) + trans_offset;\n\t} else {\n\t\tblocks = wm0_blocks + trans_offset;\n\t}\n\tblocks++;\n\n\t \n\ttrans_wm->blocks = blocks;\n\ttrans_wm->min_ddb_alloc = max_t(u16, wm0->min_ddb_alloc, blocks + 1);\n\ttrans_wm->enable = true;\n}\n\nstatic int skl_build_plane_wm_single(struct intel_crtc_state *crtc_state,\n\t\t\t\t     const struct intel_plane_state *plane_state,\n\t\t\t\t     struct intel_plane *plane, int color_plane)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tstruct skl_plane_wm *wm = &crtc_state->wm.skl.raw.planes[plane->id];\n\tstruct skl_wm_params wm_params;\n\tint ret;\n\n\tret = skl_compute_plane_wm_params(crtc_state, plane_state,\n\t\t\t\t\t  &wm_params, color_plane);\n\tif (ret)\n\t\treturn ret;\n\n\tskl_compute_wm_levels(crtc_state, plane, &wm_params, wm->wm);\n\n\tskl_compute_transition_wm(i915, &wm->trans_wm,\n\t\t\t\t  &wm->wm[0], &wm_params);\n\n\tif (DISPLAY_VER(i915) >= 12) {\n\t\ttgl_compute_sagv_wm(crtc_state, plane, &wm_params, wm);\n\n\t\tskl_compute_transition_wm(i915, &wm->sagv.trans_wm,\n\t\t\t\t\t  &wm->sagv.wm0, &wm_params);\n\t}\n\n\treturn 0;\n}\n\nstatic int skl_build_plane_wm_uv(struct intel_crtc_state *crtc_state,\n\t\t\t\t const struct intel_plane_state *plane_state,\n\t\t\t\t struct intel_plane *plane)\n{\n\tstruct skl_plane_wm *wm = &crtc_state->wm.skl.raw.planes[plane->id];\n\tstruct skl_wm_params wm_params;\n\tint ret;\n\n\twm->is_planar = true;\n\n\t \n\tret = skl_compute_plane_wm_params(crtc_state, plane_state,\n\t\t\t\t\t  &wm_params, 1);\n\tif (ret)\n\t\treturn ret;\n\n\tskl_compute_wm_levels(crtc_state, plane, &wm_params, wm->uv_wm);\n\n\treturn 0;\n}\n\nstatic int skl_build_plane_wm(struct intel_crtc_state *crtc_state,\n\t\t\t      const struct intel_plane_state *plane_state)\n{\n\tstruct intel_plane *plane = to_intel_plane(plane_state->uapi.plane);\n\tenum plane_id plane_id = plane->id;\n\tstruct skl_plane_wm *wm = &crtc_state->wm.skl.raw.planes[plane_id];\n\tconst struct drm_framebuffer *fb = plane_state->hw.fb;\n\tint ret;\n\n\tmemset(wm, 0, sizeof(*wm));\n\n\tif (!intel_wm_plane_visible(crtc_state, plane_state))\n\t\treturn 0;\n\n\tret = skl_build_plane_wm_single(crtc_state, plane_state,\n\t\t\t\t\tplane, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tif (fb->format->is_yuv && fb->format->num_planes > 1) {\n\t\tret = skl_build_plane_wm_uv(crtc_state, plane_state,\n\t\t\t\t\t    plane);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int icl_build_plane_wm(struct intel_crtc_state *crtc_state,\n\t\t\t      const struct intel_plane_state *plane_state)\n{\n\tstruct intel_plane *plane = to_intel_plane(plane_state->uapi.plane);\n\tstruct drm_i915_private *i915 = to_i915(plane->base.dev);\n\tenum plane_id plane_id = plane->id;\n\tstruct skl_plane_wm *wm = &crtc_state->wm.skl.raw.planes[plane_id];\n\tint ret;\n\n\t \n\tif (plane_state->planar_slave)\n\t\treturn 0;\n\n\tmemset(wm, 0, sizeof(*wm));\n\n\tif (plane_state->planar_linked_plane) {\n\t\tconst struct drm_framebuffer *fb = plane_state->hw.fb;\n\n\t\tdrm_WARN_ON(&i915->drm,\n\t\t\t    !intel_wm_plane_visible(crtc_state, plane_state));\n\t\tdrm_WARN_ON(&i915->drm, !fb->format->is_yuv ||\n\t\t\t    fb->format->num_planes == 1);\n\n\t\tret = skl_build_plane_wm_single(crtc_state, plane_state,\n\t\t\t\t\t\tplane_state->planar_linked_plane, 0);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = skl_build_plane_wm_single(crtc_state, plane_state,\n\t\t\t\t\t\tplane, 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (intel_wm_plane_visible(crtc_state, plane_state)) {\n\t\tret = skl_build_plane_wm_single(crtc_state, plane_state,\n\t\t\t\t\t\tplane, 0);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic bool\nskl_is_vblank_too_short(const struct intel_crtc_state *crtc_state,\n\t\t\tint wm0_lines, int latency)\n{\n\tconst struct drm_display_mode *adjusted_mode =\n\t\t&crtc_state->hw.adjusted_mode;\n\n\t \n\treturn crtc_state->framestart_delay +\n\t\tintel_usecs_to_scanlines(adjusted_mode, latency) +\n\t\twm0_lines >\n\t\tadjusted_mode->crtc_vtotal - adjusted_mode->crtc_vblank_start;\n}\n\nstatic int skl_max_wm0_lines(const struct intel_crtc_state *crtc_state)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tenum plane_id plane_id;\n\tint wm0_lines = 0;\n\n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tconst struct skl_plane_wm *wm = &crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\t \n\t\twm0_lines = max_t(int, wm0_lines, wm->wm[0].lines);\n\t}\n\n\treturn wm0_lines;\n}\n\nstatic int skl_max_wm_level_for_vblank(struct intel_crtc_state *crtc_state,\n\t\t\t\t       int wm0_lines)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tint level;\n\n\tfor (level = i915->display.wm.num_levels - 1; level >= 0; level--) {\n\t\tint latency;\n\n\t\t \n\t\tlatency = skl_wm_latency(i915, level, NULL);\n\t\tif (latency == 0)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (level == 0)\n\t\t\tlatency = 0;\n\n\t\tif (!skl_is_vblank_too_short(crtc_state, wm0_lines, latency))\n\t\t\treturn level;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int skl_wm_check_vblank(struct intel_crtc_state *crtc_state)\n{\n\tstruct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tint wm0_lines, level;\n\n\tif (!crtc_state->hw.active)\n\t\treturn 0;\n\n\twm0_lines = skl_max_wm0_lines(crtc_state);\n\n\tlevel = skl_max_wm_level_for_vblank(crtc_state, wm0_lines);\n\tif (level < 0)\n\t\treturn level;\n\n\t \n\tcrtc_state->wm_level_disabled = level < i915->display.wm.num_levels - 1;\n\n\tfor (level++; level < i915->display.wm.num_levels; level++) {\n\t\tenum plane_id plane_id;\n\n\t\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\t\tstruct skl_plane_wm *wm =\n\t\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\t\t \n\t\t\twm->wm[level].enable = false;\n\t\t\twm->uv_wm[level].enable = false;\n\t\t}\n\t}\n\n\tif (DISPLAY_VER(i915) >= 12 &&\n\t    i915->display.sagv.block_time_us &&\n\t    skl_is_vblank_too_short(crtc_state, wm0_lines,\n\t\t\t\t    i915->display.sagv.block_time_us)) {\n\t\tenum plane_id plane_id;\n\n\t\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\t\tstruct skl_plane_wm *wm =\n\t\t\t\t&crtc_state->wm.skl.optimal.planes[plane_id];\n\n\t\t\twm->sagv.wm0.enable = false;\n\t\t\twm->sagv.trans_wm.enable = false;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int skl_build_pipe_wm(struct intel_atomic_state *state,\n\t\t\t     struct intel_crtc *crtc)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tstruct intel_crtc_state *crtc_state =\n\t\tintel_atomic_get_new_crtc_state(state, crtc);\n\tconst struct intel_plane_state *plane_state;\n\tstruct intel_plane *plane;\n\tint ret, i;\n\n\tfor_each_new_intel_plane_in_state(state, plane, plane_state, i) {\n\t\t \n\t\tif (plane->pipe != crtc->pipe)\n\t\t\tcontinue;\n\n\t\tif (DISPLAY_VER(i915) >= 11)\n\t\t\tret = icl_build_plane_wm(crtc_state, plane_state);\n\t\telse\n\t\t\tret = skl_build_plane_wm(crtc_state, plane_state);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tcrtc_state->wm.skl.optimal = crtc_state->wm.skl.raw;\n\n\treturn skl_wm_check_vblank(crtc_state);\n}\n\nstatic void skl_ddb_entry_write(struct drm_i915_private *i915,\n\t\t\t\ti915_reg_t reg,\n\t\t\t\tconst struct skl_ddb_entry *entry)\n{\n\tif (entry->end)\n\t\tintel_de_write_fw(i915, reg,\n\t\t\t\t  PLANE_BUF_END(entry->end - 1) |\n\t\t\t\t  PLANE_BUF_START(entry->start));\n\telse\n\t\tintel_de_write_fw(i915, reg, 0);\n}\n\nstatic void skl_write_wm_level(struct drm_i915_private *i915,\n\t\t\t       i915_reg_t reg,\n\t\t\t       const struct skl_wm_level *level)\n{\n\tu32 val = 0;\n\n\tif (level->enable)\n\t\tval |= PLANE_WM_EN;\n\tif (level->ignore_lines)\n\t\tval |= PLANE_WM_IGNORE_LINES;\n\tval |= REG_FIELD_PREP(PLANE_WM_BLOCKS_MASK, level->blocks);\n\tval |= REG_FIELD_PREP(PLANE_WM_LINES_MASK, level->lines);\n\n\tintel_de_write_fw(i915, reg, val);\n}\n\nvoid skl_write_plane_wm(struct intel_plane *plane,\n\t\t\tconst struct intel_crtc_state *crtc_state)\n{\n\tstruct drm_i915_private *i915 = to_i915(plane->base.dev);\n\tenum plane_id plane_id = plane->id;\n\tenum pipe pipe = plane->pipe;\n\tconst struct skl_pipe_wm *pipe_wm = &crtc_state->wm.skl.optimal;\n\tconst struct skl_ddb_entry *ddb =\n\t\t&crtc_state->wm.skl.plane_ddb[plane_id];\n\tconst struct skl_ddb_entry *ddb_y =\n\t\t&crtc_state->wm.skl.plane_ddb_y[plane_id];\n\tint level;\n\n\tfor (level = 0; level < i915->display.wm.num_levels; level++)\n\t\tskl_write_wm_level(i915, PLANE_WM(pipe, plane_id, level),\n\t\t\t\t   skl_plane_wm_level(pipe_wm, plane_id, level));\n\n\tskl_write_wm_level(i915, PLANE_WM_TRANS(pipe, plane_id),\n\t\t\t   skl_plane_trans_wm(pipe_wm, plane_id));\n\n\tif (HAS_HW_SAGV_WM(i915)) {\n\t\tconst struct skl_plane_wm *wm = &pipe_wm->planes[plane_id];\n\n\t\tskl_write_wm_level(i915, PLANE_WM_SAGV(pipe, plane_id),\n\t\t\t\t   &wm->sagv.wm0);\n\t\tskl_write_wm_level(i915, PLANE_WM_SAGV_TRANS(pipe, plane_id),\n\t\t\t\t   &wm->sagv.trans_wm);\n\t}\n\n\tskl_ddb_entry_write(i915,\n\t\t\t    PLANE_BUF_CFG(pipe, plane_id), ddb);\n\n\tif (DISPLAY_VER(i915) < 11)\n\t\tskl_ddb_entry_write(i915,\n\t\t\t\t    PLANE_NV12_BUF_CFG(pipe, plane_id), ddb_y);\n}\n\nvoid skl_write_cursor_wm(struct intel_plane *plane,\n\t\t\t const struct intel_crtc_state *crtc_state)\n{\n\tstruct drm_i915_private *i915 = to_i915(plane->base.dev);\n\tenum plane_id plane_id = plane->id;\n\tenum pipe pipe = plane->pipe;\n\tconst struct skl_pipe_wm *pipe_wm = &crtc_state->wm.skl.optimal;\n\tconst struct skl_ddb_entry *ddb =\n\t\t&crtc_state->wm.skl.plane_ddb[plane_id];\n\tint level;\n\n\tfor (level = 0; level < i915->display.wm.num_levels; level++)\n\t\tskl_write_wm_level(i915, CUR_WM(pipe, level),\n\t\t\t\t   skl_plane_wm_level(pipe_wm, plane_id, level));\n\n\tskl_write_wm_level(i915, CUR_WM_TRANS(pipe),\n\t\t\t   skl_plane_trans_wm(pipe_wm, plane_id));\n\n\tif (HAS_HW_SAGV_WM(i915)) {\n\t\tconst struct skl_plane_wm *wm = &pipe_wm->planes[plane_id];\n\n\t\tskl_write_wm_level(i915, CUR_WM_SAGV(pipe),\n\t\t\t\t   &wm->sagv.wm0);\n\t\tskl_write_wm_level(i915, CUR_WM_SAGV_TRANS(pipe),\n\t\t\t\t   &wm->sagv.trans_wm);\n\t}\n\n\tskl_ddb_entry_write(i915, CUR_BUF_CFG(pipe), ddb);\n}\n\nstatic bool skl_wm_level_equals(const struct skl_wm_level *l1,\n\t\t\t\tconst struct skl_wm_level *l2)\n{\n\treturn l1->enable == l2->enable &&\n\t\tl1->ignore_lines == l2->ignore_lines &&\n\t\tl1->lines == l2->lines &&\n\t\tl1->blocks == l2->blocks;\n}\n\nstatic bool skl_plane_wm_equals(struct drm_i915_private *i915,\n\t\t\t\tconst struct skl_plane_wm *wm1,\n\t\t\t\tconst struct skl_plane_wm *wm2)\n{\n\tint level;\n\n\tfor (level = 0; level < i915->display.wm.num_levels; level++) {\n\t\t \n\t\tif (!skl_wm_level_equals(&wm1->wm[level], &wm2->wm[level]))\n\t\t\treturn false;\n\t}\n\n\treturn skl_wm_level_equals(&wm1->trans_wm, &wm2->trans_wm) &&\n\t\tskl_wm_level_equals(&wm1->sagv.wm0, &wm2->sagv.wm0) &&\n\t\tskl_wm_level_equals(&wm1->sagv.trans_wm, &wm2->sagv.trans_wm);\n}\n\nstatic bool skl_ddb_entries_overlap(const struct skl_ddb_entry *a,\n\t\t\t\t    const struct skl_ddb_entry *b)\n{\n\treturn a->start < b->end && b->start < a->end;\n}\n\nstatic void skl_ddb_entry_union(struct skl_ddb_entry *a,\n\t\t\t\tconst struct skl_ddb_entry *b)\n{\n\tif (a->end && b->end) {\n\t\ta->start = min(a->start, b->start);\n\t\ta->end = max(a->end, b->end);\n\t} else if (b->end) {\n\t\ta->start = b->start;\n\t\ta->end = b->end;\n\t}\n}\n\nbool skl_ddb_allocation_overlaps(const struct skl_ddb_entry *ddb,\n\t\t\t\t const struct skl_ddb_entry *entries,\n\t\t\t\t int num_entries, int ignore_idx)\n{\n\tint i;\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tif (i != ignore_idx &&\n\t\t    skl_ddb_entries_overlap(ddb, &entries[i]))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int\nskl_ddb_add_affected_planes(const struct intel_crtc_state *old_crtc_state,\n\t\t\t    struct intel_crtc_state *new_crtc_state)\n{\n\tstruct intel_atomic_state *state = to_intel_atomic_state(new_crtc_state->uapi.state);\n\tstruct intel_crtc *crtc = to_intel_crtc(new_crtc_state->uapi.crtc);\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tstruct intel_plane *plane;\n\n\tfor_each_intel_plane_on_crtc(&i915->drm, crtc, plane) {\n\t\tstruct intel_plane_state *plane_state;\n\t\tenum plane_id plane_id = plane->id;\n\n\t\tif (skl_ddb_entry_equal(&old_crtc_state->wm.skl.plane_ddb[plane_id],\n\t\t\t\t\t&new_crtc_state->wm.skl.plane_ddb[plane_id]) &&\n\t\t    skl_ddb_entry_equal(&old_crtc_state->wm.skl.plane_ddb_y[plane_id],\n\t\t\t\t\t&new_crtc_state->wm.skl.plane_ddb_y[plane_id]))\n\t\t\tcontinue;\n\n\t\tplane_state = intel_atomic_get_plane_state(state, plane);\n\t\tif (IS_ERR(plane_state))\n\t\t\treturn PTR_ERR(plane_state);\n\n\t\tnew_crtc_state->update_planes |= BIT(plane_id);\n\t\tnew_crtc_state->async_flip_planes = 0;\n\t\tnew_crtc_state->do_async_flip = false;\n\t}\n\n\treturn 0;\n}\n\nstatic u8 intel_dbuf_enabled_slices(const struct intel_dbuf_state *dbuf_state)\n{\n\tstruct drm_i915_private *i915 = to_i915(dbuf_state->base.state->base.dev);\n\tu8 enabled_slices;\n\tenum pipe pipe;\n\n\t \n\tenabled_slices = BIT(DBUF_S1);\n\n\tfor_each_pipe(i915, pipe)\n\t\tenabled_slices |= dbuf_state->slices[pipe];\n\n\treturn enabled_slices;\n}\n\nstatic int\nskl_compute_ddb(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_dbuf_state *old_dbuf_state;\n\tstruct intel_dbuf_state *new_dbuf_state = NULL;\n\tconst struct intel_crtc_state *old_crtc_state;\n\tstruct intel_crtc_state *new_crtc_state;\n\tstruct intel_crtc *crtc;\n\tint ret, i;\n\n\tfor_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tnew_dbuf_state = intel_atomic_get_dbuf_state(state);\n\t\tif (IS_ERR(new_dbuf_state))\n\t\t\treturn PTR_ERR(new_dbuf_state);\n\n\t\told_dbuf_state = intel_atomic_get_old_dbuf_state(state);\n\t\tbreak;\n\t}\n\n\tif (!new_dbuf_state)\n\t\treturn 0;\n\n\tnew_dbuf_state->active_pipes =\n\t\tintel_calc_active_pipes(state, old_dbuf_state->active_pipes);\n\n\tif (old_dbuf_state->active_pipes != new_dbuf_state->active_pipes) {\n\t\tret = intel_atomic_lock_global_state(&new_dbuf_state->base);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (HAS_MBUS_JOINING(i915))\n\t\tnew_dbuf_state->joined_mbus =\n\t\t\tadlp_check_mbus_joined(new_dbuf_state->active_pipes);\n\n\tfor_each_intel_crtc(&i915->drm, crtc) {\n\t\tenum pipe pipe = crtc->pipe;\n\n\t\tnew_dbuf_state->slices[pipe] =\n\t\t\tskl_compute_dbuf_slices(crtc, new_dbuf_state->active_pipes,\n\t\t\t\t\t\tnew_dbuf_state->joined_mbus);\n\n\t\tif (old_dbuf_state->slices[pipe] == new_dbuf_state->slices[pipe])\n\t\t\tcontinue;\n\n\t\tret = intel_atomic_lock_global_state(&new_dbuf_state->base);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tnew_dbuf_state->enabled_slices = intel_dbuf_enabled_slices(new_dbuf_state);\n\n\tif (old_dbuf_state->enabled_slices != new_dbuf_state->enabled_slices ||\n\t    old_dbuf_state->joined_mbus != new_dbuf_state->joined_mbus) {\n\t\tret = intel_atomic_serialize_global_state(&new_dbuf_state->base);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (old_dbuf_state->joined_mbus != new_dbuf_state->joined_mbus) {\n\t\t\t \n\t\t\tret = intel_modeset_all_pipes(state, \"MBUS joining change\");\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t    \"Enabled dbuf slices 0x%x -> 0x%x (total dbuf slices 0x%x), mbus joined? %s->%s\\n\",\n\t\t\t    old_dbuf_state->enabled_slices,\n\t\t\t    new_dbuf_state->enabled_slices,\n\t\t\t    DISPLAY_INFO(i915)->dbuf.slice_mask,\n\t\t\t    str_yes_no(old_dbuf_state->joined_mbus),\n\t\t\t    str_yes_no(new_dbuf_state->joined_mbus));\n\t}\n\n\tfor_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tenum pipe pipe = crtc->pipe;\n\n\t\tnew_dbuf_state->weight[pipe] = intel_crtc_ddb_weight(new_crtc_state);\n\n\t\tif (old_dbuf_state->weight[pipe] == new_dbuf_state->weight[pipe])\n\t\t\tcontinue;\n\n\t\tret = intel_atomic_lock_global_state(&new_dbuf_state->base);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tfor_each_intel_crtc(&i915->drm, crtc) {\n\t\tret = skl_crtc_allocate_ddb(state, crtc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tfor_each_oldnew_intel_crtc_in_state(state, crtc, old_crtc_state,\n\t\t\t\t\t    new_crtc_state, i) {\n\t\tret = skl_crtc_allocate_plane_ddb(state, crtc);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tret = skl_ddb_add_affected_planes(old_crtc_state,\n\t\t\t\t\t\t  new_crtc_state);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic char enast(bool enable)\n{\n\treturn enable ? '*' : ' ';\n}\n\nstatic void\nskl_print_wm_changes(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_crtc_state *old_crtc_state;\n\tconst struct intel_crtc_state *new_crtc_state;\n\tstruct intel_plane *plane;\n\tstruct intel_crtc *crtc;\n\tint i;\n\n\tif (!drm_debug_enabled(DRM_UT_KMS))\n\t\treturn;\n\n\tfor_each_oldnew_intel_crtc_in_state(state, crtc, old_crtc_state,\n\t\t\t\t\t    new_crtc_state, i) {\n\t\tconst struct skl_pipe_wm *old_pipe_wm, *new_pipe_wm;\n\n\t\told_pipe_wm = &old_crtc_state->wm.skl.optimal;\n\t\tnew_pipe_wm = &new_crtc_state->wm.skl.optimal;\n\n\t\tfor_each_intel_plane_on_crtc(&i915->drm, crtc, plane) {\n\t\t\tenum plane_id plane_id = plane->id;\n\t\t\tconst struct skl_ddb_entry *old, *new;\n\n\t\t\told = &old_crtc_state->wm.skl.plane_ddb[plane_id];\n\t\t\tnew = &new_crtc_state->wm.skl.plane_ddb[plane_id];\n\n\t\t\tif (skl_ddb_entry_equal(old, new))\n\t\t\t\tcontinue;\n\n\t\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t\t    \"[PLANE:%d:%s] ddb (%4d - %4d) -> (%4d - %4d), size %4d -> %4d\\n\",\n\t\t\t\t    plane->base.base.id, plane->base.name,\n\t\t\t\t    old->start, old->end, new->start, new->end,\n\t\t\t\t    skl_ddb_entry_size(old), skl_ddb_entry_size(new));\n\t\t}\n\n\t\tfor_each_intel_plane_on_crtc(&i915->drm, crtc, plane) {\n\t\t\tenum plane_id plane_id = plane->id;\n\t\t\tconst struct skl_plane_wm *old_wm, *new_wm;\n\n\t\t\told_wm = &old_pipe_wm->planes[plane_id];\n\t\t\tnew_wm = &new_pipe_wm->planes[plane_id];\n\n\t\t\tif (skl_plane_wm_equals(i915, old_wm, new_wm))\n\t\t\t\tcontinue;\n\n\t\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t\t    \"[PLANE:%d:%s]   level %cwm0,%cwm1,%cwm2,%cwm3,%cwm4,%cwm5,%cwm6,%cwm7,%ctwm,%cswm,%cstwm\"\n\t\t\t\t    \" -> %cwm0,%cwm1,%cwm2,%cwm3,%cwm4,%cwm5,%cwm6,%cwm7,%ctwm,%cswm,%cstwm\\n\",\n\t\t\t\t    plane->base.base.id, plane->base.name,\n\t\t\t\t    enast(old_wm->wm[0].enable), enast(old_wm->wm[1].enable),\n\t\t\t\t    enast(old_wm->wm[2].enable), enast(old_wm->wm[3].enable),\n\t\t\t\t    enast(old_wm->wm[4].enable), enast(old_wm->wm[5].enable),\n\t\t\t\t    enast(old_wm->wm[6].enable), enast(old_wm->wm[7].enable),\n\t\t\t\t    enast(old_wm->trans_wm.enable),\n\t\t\t\t    enast(old_wm->sagv.wm0.enable),\n\t\t\t\t    enast(old_wm->sagv.trans_wm.enable),\n\t\t\t\t    enast(new_wm->wm[0].enable), enast(new_wm->wm[1].enable),\n\t\t\t\t    enast(new_wm->wm[2].enable), enast(new_wm->wm[3].enable),\n\t\t\t\t    enast(new_wm->wm[4].enable), enast(new_wm->wm[5].enable),\n\t\t\t\t    enast(new_wm->wm[6].enable), enast(new_wm->wm[7].enable),\n\t\t\t\t    enast(new_wm->trans_wm.enable),\n\t\t\t\t    enast(new_wm->sagv.wm0.enable),\n\t\t\t\t    enast(new_wm->sagv.trans_wm.enable));\n\n\t\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t\t    \"[PLANE:%d:%s]   lines %c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%4d\"\n\t\t\t\t      \" -> %c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%3d,%c%4d\\n\",\n\t\t\t\t    plane->base.base.id, plane->base.name,\n\t\t\t\t    enast(old_wm->wm[0].ignore_lines), old_wm->wm[0].lines,\n\t\t\t\t    enast(old_wm->wm[1].ignore_lines), old_wm->wm[1].lines,\n\t\t\t\t    enast(old_wm->wm[2].ignore_lines), old_wm->wm[2].lines,\n\t\t\t\t    enast(old_wm->wm[3].ignore_lines), old_wm->wm[3].lines,\n\t\t\t\t    enast(old_wm->wm[4].ignore_lines), old_wm->wm[4].lines,\n\t\t\t\t    enast(old_wm->wm[5].ignore_lines), old_wm->wm[5].lines,\n\t\t\t\t    enast(old_wm->wm[6].ignore_lines), old_wm->wm[6].lines,\n\t\t\t\t    enast(old_wm->wm[7].ignore_lines), old_wm->wm[7].lines,\n\t\t\t\t    enast(old_wm->trans_wm.ignore_lines), old_wm->trans_wm.lines,\n\t\t\t\t    enast(old_wm->sagv.wm0.ignore_lines), old_wm->sagv.wm0.lines,\n\t\t\t\t    enast(old_wm->sagv.trans_wm.ignore_lines), old_wm->sagv.trans_wm.lines,\n\t\t\t\t    enast(new_wm->wm[0].ignore_lines), new_wm->wm[0].lines,\n\t\t\t\t    enast(new_wm->wm[1].ignore_lines), new_wm->wm[1].lines,\n\t\t\t\t    enast(new_wm->wm[2].ignore_lines), new_wm->wm[2].lines,\n\t\t\t\t    enast(new_wm->wm[3].ignore_lines), new_wm->wm[3].lines,\n\t\t\t\t    enast(new_wm->wm[4].ignore_lines), new_wm->wm[4].lines,\n\t\t\t\t    enast(new_wm->wm[5].ignore_lines), new_wm->wm[5].lines,\n\t\t\t\t    enast(new_wm->wm[6].ignore_lines), new_wm->wm[6].lines,\n\t\t\t\t    enast(new_wm->wm[7].ignore_lines), new_wm->wm[7].lines,\n\t\t\t\t    enast(new_wm->trans_wm.ignore_lines), new_wm->trans_wm.lines,\n\t\t\t\t    enast(new_wm->sagv.wm0.ignore_lines), new_wm->sagv.wm0.lines,\n\t\t\t\t    enast(new_wm->sagv.trans_wm.ignore_lines), new_wm->sagv.trans_wm.lines);\n\n\t\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t\t    \"[PLANE:%d:%s]  blocks %4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%5d\"\n\t\t\t\t    \" -> %4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%5d\\n\",\n\t\t\t\t    plane->base.base.id, plane->base.name,\n\t\t\t\t    old_wm->wm[0].blocks, old_wm->wm[1].blocks,\n\t\t\t\t    old_wm->wm[2].blocks, old_wm->wm[3].blocks,\n\t\t\t\t    old_wm->wm[4].blocks, old_wm->wm[5].blocks,\n\t\t\t\t    old_wm->wm[6].blocks, old_wm->wm[7].blocks,\n\t\t\t\t    old_wm->trans_wm.blocks,\n\t\t\t\t    old_wm->sagv.wm0.blocks,\n\t\t\t\t    old_wm->sagv.trans_wm.blocks,\n\t\t\t\t    new_wm->wm[0].blocks, new_wm->wm[1].blocks,\n\t\t\t\t    new_wm->wm[2].blocks, new_wm->wm[3].blocks,\n\t\t\t\t    new_wm->wm[4].blocks, new_wm->wm[5].blocks,\n\t\t\t\t    new_wm->wm[6].blocks, new_wm->wm[7].blocks,\n\t\t\t\t    new_wm->trans_wm.blocks,\n\t\t\t\t    new_wm->sagv.wm0.blocks,\n\t\t\t\t    new_wm->sagv.trans_wm.blocks);\n\n\t\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t\t    \"[PLANE:%d:%s] min_ddb %4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%5d\"\n\t\t\t\t    \" -> %4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%4d,%5d\\n\",\n\t\t\t\t    plane->base.base.id, plane->base.name,\n\t\t\t\t    old_wm->wm[0].min_ddb_alloc, old_wm->wm[1].min_ddb_alloc,\n\t\t\t\t    old_wm->wm[2].min_ddb_alloc, old_wm->wm[3].min_ddb_alloc,\n\t\t\t\t    old_wm->wm[4].min_ddb_alloc, old_wm->wm[5].min_ddb_alloc,\n\t\t\t\t    old_wm->wm[6].min_ddb_alloc, old_wm->wm[7].min_ddb_alloc,\n\t\t\t\t    old_wm->trans_wm.min_ddb_alloc,\n\t\t\t\t    old_wm->sagv.wm0.min_ddb_alloc,\n\t\t\t\t    old_wm->sagv.trans_wm.min_ddb_alloc,\n\t\t\t\t    new_wm->wm[0].min_ddb_alloc, new_wm->wm[1].min_ddb_alloc,\n\t\t\t\t    new_wm->wm[2].min_ddb_alloc, new_wm->wm[3].min_ddb_alloc,\n\t\t\t\t    new_wm->wm[4].min_ddb_alloc, new_wm->wm[5].min_ddb_alloc,\n\t\t\t\t    new_wm->wm[6].min_ddb_alloc, new_wm->wm[7].min_ddb_alloc,\n\t\t\t\t    new_wm->trans_wm.min_ddb_alloc,\n\t\t\t\t    new_wm->sagv.wm0.min_ddb_alloc,\n\t\t\t\t    new_wm->sagv.trans_wm.min_ddb_alloc);\n\t\t}\n\t}\n}\n\nstatic bool skl_plane_selected_wm_equals(struct intel_plane *plane,\n\t\t\t\t\t const struct skl_pipe_wm *old_pipe_wm,\n\t\t\t\t\t const struct skl_pipe_wm *new_pipe_wm)\n{\n\tstruct drm_i915_private *i915 = to_i915(plane->base.dev);\n\tint level;\n\n\tfor (level = 0; level < i915->display.wm.num_levels; level++) {\n\t\t \n\t\tif (!skl_wm_level_equals(skl_plane_wm_level(old_pipe_wm, plane->id, level),\n\t\t\t\t\t skl_plane_wm_level(new_pipe_wm, plane->id, level)))\n\t\t\treturn false;\n\t}\n\n\tif (HAS_HW_SAGV_WM(i915)) {\n\t\tconst struct skl_plane_wm *old_wm = &old_pipe_wm->planes[plane->id];\n\t\tconst struct skl_plane_wm *new_wm = &new_pipe_wm->planes[plane->id];\n\n\t\tif (!skl_wm_level_equals(&old_wm->sagv.wm0, &new_wm->sagv.wm0) ||\n\t\t    !skl_wm_level_equals(&old_wm->sagv.trans_wm, &new_wm->sagv.trans_wm))\n\t\t\treturn false;\n\t}\n\n\treturn skl_wm_level_equals(skl_plane_trans_wm(old_pipe_wm, plane->id),\n\t\t\t\t   skl_plane_trans_wm(new_pipe_wm, plane->id));\n}\n\n \nstatic int skl_wm_add_affected_planes(struct intel_atomic_state *state,\n\t\t\t\t      struct intel_crtc *crtc)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tconst struct intel_crtc_state *old_crtc_state =\n\t\tintel_atomic_get_old_crtc_state(state, crtc);\n\tstruct intel_crtc_state *new_crtc_state =\n\t\tintel_atomic_get_new_crtc_state(state, crtc);\n\tstruct intel_plane *plane;\n\n\tfor_each_intel_plane_on_crtc(&i915->drm, crtc, plane) {\n\t\tstruct intel_plane_state *plane_state;\n\t\tenum plane_id plane_id = plane->id;\n\n\t\t \n\t\tif (!intel_crtc_needs_modeset(new_crtc_state) &&\n\t\t    skl_plane_selected_wm_equals(plane,\n\t\t\t\t\t\t &old_crtc_state->wm.skl.optimal,\n\t\t\t\t\t\t &new_crtc_state->wm.skl.optimal))\n\t\t\tcontinue;\n\n\t\tplane_state = intel_atomic_get_plane_state(state, plane);\n\t\tif (IS_ERR(plane_state))\n\t\t\treturn PTR_ERR(plane_state);\n\n\t\tnew_crtc_state->update_planes |= BIT(plane_id);\n\t\tnew_crtc_state->async_flip_planes = 0;\n\t\tnew_crtc_state->do_async_flip = false;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nskl_compute_wm(struct intel_atomic_state *state)\n{\n\tstruct intel_crtc *crtc;\n\tstruct intel_crtc_state __maybe_unused *new_crtc_state;\n\tint ret, i;\n\n\tfor_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tret = skl_build_pipe_wm(state, crtc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = skl_compute_ddb(state);\n\tif (ret)\n\t\treturn ret;\n\n\tret = intel_compute_sagv_mask(state);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tfor_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tret = skl_wm_add_affected_planes(state, crtc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tskl_print_wm_changes(state);\n\n\treturn 0;\n}\n\nstatic void skl_wm_level_from_reg_val(u32 val, struct skl_wm_level *level)\n{\n\tlevel->enable = val & PLANE_WM_EN;\n\tlevel->ignore_lines = val & PLANE_WM_IGNORE_LINES;\n\tlevel->blocks = REG_FIELD_GET(PLANE_WM_BLOCKS_MASK, val);\n\tlevel->lines = REG_FIELD_GET(PLANE_WM_LINES_MASK, val);\n}\n\nstatic void skl_pipe_wm_get_hw_state(struct intel_crtc *crtc,\n\t\t\t\t     struct skl_pipe_wm *out)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tenum pipe pipe = crtc->pipe;\n\tenum plane_id plane_id;\n\tint level;\n\tu32 val;\n\n\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\tstruct skl_plane_wm *wm = &out->planes[plane_id];\n\n\t\tfor (level = 0; level < i915->display.wm.num_levels; level++) {\n\t\t\tif (plane_id != PLANE_CURSOR)\n\t\t\t\tval = intel_de_read(i915, PLANE_WM(pipe, plane_id, level));\n\t\t\telse\n\t\t\t\tval = intel_de_read(i915, CUR_WM(pipe, level));\n\n\t\t\tskl_wm_level_from_reg_val(val, &wm->wm[level]);\n\t\t}\n\n\t\tif (plane_id != PLANE_CURSOR)\n\t\t\tval = intel_de_read(i915, PLANE_WM_TRANS(pipe, plane_id));\n\t\telse\n\t\t\tval = intel_de_read(i915, CUR_WM_TRANS(pipe));\n\n\t\tskl_wm_level_from_reg_val(val, &wm->trans_wm);\n\n\t\tif (HAS_HW_SAGV_WM(i915)) {\n\t\t\tif (plane_id != PLANE_CURSOR)\n\t\t\t\tval = intel_de_read(i915, PLANE_WM_SAGV(pipe, plane_id));\n\t\t\telse\n\t\t\t\tval = intel_de_read(i915, CUR_WM_SAGV(pipe));\n\n\t\t\tskl_wm_level_from_reg_val(val, &wm->sagv.wm0);\n\n\t\t\tif (plane_id != PLANE_CURSOR)\n\t\t\t\tval = intel_de_read(i915, PLANE_WM_SAGV_TRANS(pipe, plane_id));\n\t\t\telse\n\t\t\t\tval = intel_de_read(i915, CUR_WM_SAGV_TRANS(pipe));\n\n\t\t\tskl_wm_level_from_reg_val(val, &wm->sagv.trans_wm);\n\t\t} else if (DISPLAY_VER(i915) >= 12) {\n\t\t\twm->sagv.wm0 = wm->wm[0];\n\t\t\twm->sagv.trans_wm = wm->trans_wm;\n\t\t}\n\t}\n}\n\nstatic void skl_wm_get_hw_state(struct drm_i915_private *i915)\n{\n\tstruct intel_dbuf_state *dbuf_state =\n\t\tto_intel_dbuf_state(i915->display.dbuf.obj.state);\n\tstruct intel_crtc *crtc;\n\n\tif (HAS_MBUS_JOINING(i915))\n\t\tdbuf_state->joined_mbus = intel_de_read(i915, MBUS_CTL) & MBUS_JOIN;\n\n\tfor_each_intel_crtc(&i915->drm, crtc) {\n\t\tstruct intel_crtc_state *crtc_state =\n\t\t\tto_intel_crtc_state(crtc->base.state);\n\t\tenum pipe pipe = crtc->pipe;\n\t\tunsigned int mbus_offset;\n\t\tenum plane_id plane_id;\n\t\tu8 slices;\n\n\t\tmemset(&crtc_state->wm.skl.optimal, 0,\n\t\t       sizeof(crtc_state->wm.skl.optimal));\n\t\tif (crtc_state->hw.active)\n\t\t\tskl_pipe_wm_get_hw_state(crtc, &crtc_state->wm.skl.optimal);\n\t\tcrtc_state->wm.skl.raw = crtc_state->wm.skl.optimal;\n\n\t\tmemset(&dbuf_state->ddb[pipe], 0, sizeof(dbuf_state->ddb[pipe]));\n\n\t\tfor_each_plane_id_on_crtc(crtc, plane_id) {\n\t\t\tstruct skl_ddb_entry *ddb =\n\t\t\t\t&crtc_state->wm.skl.plane_ddb[plane_id];\n\t\t\tstruct skl_ddb_entry *ddb_y =\n\t\t\t\t&crtc_state->wm.skl.plane_ddb_y[plane_id];\n\n\t\t\tif (!crtc_state->hw.active)\n\t\t\t\tcontinue;\n\n\t\t\tskl_ddb_get_hw_plane_state(i915, crtc->pipe,\n\t\t\t\t\t\t   plane_id, ddb, ddb_y);\n\n\t\t\tskl_ddb_entry_union(&dbuf_state->ddb[pipe], ddb);\n\t\t\tskl_ddb_entry_union(&dbuf_state->ddb[pipe], ddb_y);\n\t\t}\n\n\t\tdbuf_state->weight[pipe] = intel_crtc_ddb_weight(crtc_state);\n\n\t\t \n\t\tslices = skl_compute_dbuf_slices(crtc, dbuf_state->active_pipes,\n\t\t\t\t\t\t dbuf_state->joined_mbus);\n\t\tmbus_offset = mbus_ddb_offset(i915, slices);\n\t\tcrtc_state->wm.skl.ddb.start = mbus_offset + dbuf_state->ddb[pipe].start;\n\t\tcrtc_state->wm.skl.ddb.end = mbus_offset + dbuf_state->ddb[pipe].end;\n\n\t\t \n\t\tdbuf_state->slices[pipe] =\n\t\t\tskl_ddb_dbuf_slice_mask(i915, &crtc_state->wm.skl.ddb);\n\n\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t    \"[CRTC:%d:%s] dbuf slices 0x%x, ddb (%d - %d), active pipes 0x%x, mbus joined: %s\\n\",\n\t\t\t    crtc->base.base.id, crtc->base.name,\n\t\t\t    dbuf_state->slices[pipe], dbuf_state->ddb[pipe].start,\n\t\t\t    dbuf_state->ddb[pipe].end, dbuf_state->active_pipes,\n\t\t\t    str_yes_no(dbuf_state->joined_mbus));\n\t}\n\n\tdbuf_state->enabled_slices = i915->display.dbuf.enabled_slices;\n}\n\nstatic bool skl_dbuf_is_misconfigured(struct drm_i915_private *i915)\n{\n\tconst struct intel_dbuf_state *dbuf_state =\n\t\tto_intel_dbuf_state(i915->display.dbuf.obj.state);\n\tstruct skl_ddb_entry entries[I915_MAX_PIPES] = {};\n\tstruct intel_crtc *crtc;\n\n\tfor_each_intel_crtc(&i915->drm, crtc) {\n\t\tconst struct intel_crtc_state *crtc_state =\n\t\t\tto_intel_crtc_state(crtc->base.state);\n\n\t\tentries[crtc->pipe] = crtc_state->wm.skl.ddb;\n\t}\n\n\tfor_each_intel_crtc(&i915->drm, crtc) {\n\t\tconst struct intel_crtc_state *crtc_state =\n\t\t\tto_intel_crtc_state(crtc->base.state);\n\t\tu8 slices;\n\n\t\tslices = skl_compute_dbuf_slices(crtc, dbuf_state->active_pipes,\n\t\t\t\t\t\t dbuf_state->joined_mbus);\n\t\tif (dbuf_state->slices[crtc->pipe] & ~slices)\n\t\t\treturn true;\n\n\t\tif (skl_ddb_allocation_overlaps(&crtc_state->wm.skl.ddb, entries,\n\t\t\t\t\t\tI915_MAX_PIPES, crtc->pipe))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic void skl_wm_sanitize(struct drm_i915_private *i915)\n{\n\tstruct intel_crtc *crtc;\n\n\t \n\tif (!skl_dbuf_is_misconfigured(i915))\n\t\treturn;\n\n\tdrm_dbg_kms(&i915->drm, \"BIOS has misprogrammed the DBUF, disabling all planes\\n\");\n\n\tfor_each_intel_crtc(&i915->drm, crtc) {\n\t\tstruct intel_plane *plane = to_intel_plane(crtc->base.primary);\n\t\tconst struct intel_plane_state *plane_state =\n\t\t\tto_intel_plane_state(plane->base.state);\n\t\tstruct intel_crtc_state *crtc_state =\n\t\t\tto_intel_crtc_state(crtc->base.state);\n\n\t\tif (plane_state->uapi.visible)\n\t\t\tintel_plane_disable_noatomic(crtc, plane);\n\n\t\tdrm_WARN_ON(&i915->drm, crtc_state->active_planes != 0);\n\n\t\tmemset(&crtc_state->wm.skl.ddb, 0, sizeof(crtc_state->wm.skl.ddb));\n\t}\n}\n\nstatic void skl_wm_get_hw_state_and_sanitize(struct drm_i915_private *i915)\n{\n\tskl_wm_get_hw_state(i915);\n\tskl_wm_sanitize(i915);\n}\n\nvoid intel_wm_state_verify(struct intel_crtc *crtc,\n\t\t\t   struct intel_crtc_state *new_crtc_state)\n{\n\tstruct drm_i915_private *i915 = to_i915(crtc->base.dev);\n\tstruct skl_hw_state {\n\t\tstruct skl_ddb_entry ddb[I915_MAX_PLANES];\n\t\tstruct skl_ddb_entry ddb_y[I915_MAX_PLANES];\n\t\tstruct skl_pipe_wm wm;\n\t} *hw;\n\tconst struct skl_pipe_wm *sw_wm = &new_crtc_state->wm.skl.optimal;\n\tstruct intel_plane *plane;\n\tu8 hw_enabled_slices;\n\tint level;\n\n\tif (DISPLAY_VER(i915) < 9 || !new_crtc_state->hw.active)\n\t\treturn;\n\n\thw = kzalloc(sizeof(*hw), GFP_KERNEL);\n\tif (!hw)\n\t\treturn;\n\n\tskl_pipe_wm_get_hw_state(crtc, &hw->wm);\n\n\tskl_pipe_ddb_get_hw_state(crtc, hw->ddb, hw->ddb_y);\n\n\thw_enabled_slices = intel_enabled_dbuf_slices_mask(i915);\n\n\tif (DISPLAY_VER(i915) >= 11 &&\n\t    hw_enabled_slices != i915->display.dbuf.enabled_slices)\n\t\tdrm_err(&i915->drm,\n\t\t\t\"mismatch in DBUF Slices (expected 0x%x, got 0x%x)\\n\",\n\t\t\ti915->display.dbuf.enabled_slices,\n\t\t\thw_enabled_slices);\n\n\tfor_each_intel_plane_on_crtc(&i915->drm, crtc, plane) {\n\t\tconst struct skl_ddb_entry *hw_ddb_entry, *sw_ddb_entry;\n\t\tconst struct skl_wm_level *hw_wm_level, *sw_wm_level;\n\n\t\t \n\t\tfor (level = 0; level < i915->display.wm.num_levels; level++) {\n\t\t\thw_wm_level = &hw->wm.planes[plane->id].wm[level];\n\t\t\tsw_wm_level = skl_plane_wm_level(sw_wm, plane->id, level);\n\n\t\t\tif (skl_wm_level_equals(hw_wm_level, sw_wm_level))\n\t\t\t\tcontinue;\n\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"[PLANE:%d:%s] mismatch in WM%d (expected e=%d b=%u l=%u, got e=%d b=%u l=%u)\\n\",\n\t\t\t\tplane->base.base.id, plane->base.name, level,\n\t\t\t\tsw_wm_level->enable,\n\t\t\t\tsw_wm_level->blocks,\n\t\t\t\tsw_wm_level->lines,\n\t\t\t\thw_wm_level->enable,\n\t\t\t\thw_wm_level->blocks,\n\t\t\t\thw_wm_level->lines);\n\t\t}\n\n\t\thw_wm_level = &hw->wm.planes[plane->id].trans_wm;\n\t\tsw_wm_level = skl_plane_trans_wm(sw_wm, plane->id);\n\n\t\tif (!skl_wm_level_equals(hw_wm_level, sw_wm_level)) {\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"[PLANE:%d:%s] mismatch in trans WM (expected e=%d b=%u l=%u, got e=%d b=%u l=%u)\\n\",\n\t\t\t\tplane->base.base.id, plane->base.name,\n\t\t\t\tsw_wm_level->enable,\n\t\t\t\tsw_wm_level->blocks,\n\t\t\t\tsw_wm_level->lines,\n\t\t\t\thw_wm_level->enable,\n\t\t\t\thw_wm_level->blocks,\n\t\t\t\thw_wm_level->lines);\n\t\t}\n\n\t\thw_wm_level = &hw->wm.planes[plane->id].sagv.wm0;\n\t\tsw_wm_level = &sw_wm->planes[plane->id].sagv.wm0;\n\n\t\tif (HAS_HW_SAGV_WM(i915) &&\n\t\t    !skl_wm_level_equals(hw_wm_level, sw_wm_level)) {\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"[PLANE:%d:%s] mismatch in SAGV WM (expected e=%d b=%u l=%u, got e=%d b=%u l=%u)\\n\",\n\t\t\t\tplane->base.base.id, plane->base.name,\n\t\t\t\tsw_wm_level->enable,\n\t\t\t\tsw_wm_level->blocks,\n\t\t\t\tsw_wm_level->lines,\n\t\t\t\thw_wm_level->enable,\n\t\t\t\thw_wm_level->blocks,\n\t\t\t\thw_wm_level->lines);\n\t\t}\n\n\t\thw_wm_level = &hw->wm.planes[plane->id].sagv.trans_wm;\n\t\tsw_wm_level = &sw_wm->planes[plane->id].sagv.trans_wm;\n\n\t\tif (HAS_HW_SAGV_WM(i915) &&\n\t\t    !skl_wm_level_equals(hw_wm_level, sw_wm_level)) {\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"[PLANE:%d:%s] mismatch in SAGV trans WM (expected e=%d b=%u l=%u, got e=%d b=%u l=%u)\\n\",\n\t\t\t\tplane->base.base.id, plane->base.name,\n\t\t\t\tsw_wm_level->enable,\n\t\t\t\tsw_wm_level->blocks,\n\t\t\t\tsw_wm_level->lines,\n\t\t\t\thw_wm_level->enable,\n\t\t\t\thw_wm_level->blocks,\n\t\t\t\thw_wm_level->lines);\n\t\t}\n\n\t\t \n\t\thw_ddb_entry = &hw->ddb[PLANE_CURSOR];\n\t\tsw_ddb_entry = &new_crtc_state->wm.skl.plane_ddb[PLANE_CURSOR];\n\n\t\tif (!skl_ddb_entry_equal(hw_ddb_entry, sw_ddb_entry)) {\n\t\t\tdrm_err(&i915->drm,\n\t\t\t\t\"[PLANE:%d:%s] mismatch in DDB (expected (%u,%u), found (%u,%u))\\n\",\n\t\t\t\tplane->base.base.id, plane->base.name,\n\t\t\t\tsw_ddb_entry->start, sw_ddb_entry->end,\n\t\t\t\thw_ddb_entry->start, hw_ddb_entry->end);\n\t\t}\n\t}\n\n\tkfree(hw);\n}\n\nbool skl_watermark_ipc_enabled(struct drm_i915_private *i915)\n{\n\treturn i915->display.wm.ipc_enabled;\n}\n\nvoid skl_watermark_ipc_update(struct drm_i915_private *i915)\n{\n\tif (!HAS_IPC(i915))\n\t\treturn;\n\n\tintel_de_rmw(i915, DISP_ARB_CTL2, DISP_IPC_ENABLE,\n\t\t     skl_watermark_ipc_enabled(i915) ? DISP_IPC_ENABLE : 0);\n}\n\nstatic bool skl_watermark_ipc_can_enable(struct drm_i915_private *i915)\n{\n\t \n\tif (IS_SKYLAKE(i915))\n\t\treturn false;\n\n\t \n\tif (IS_KABYLAKE(i915) ||\n\t    IS_COFFEELAKE(i915) ||\n\t    IS_COMETLAKE(i915))\n\t\treturn i915->dram_info.symmetric_memory;\n\n\treturn true;\n}\n\nvoid skl_watermark_ipc_init(struct drm_i915_private *i915)\n{\n\tif (!HAS_IPC(i915))\n\t\treturn;\n\n\ti915->display.wm.ipc_enabled = skl_watermark_ipc_can_enable(i915);\n\n\tskl_watermark_ipc_update(i915);\n}\n\nstatic void\nadjust_wm_latency(struct drm_i915_private *i915,\n\t\t  u16 wm[], int num_levels, int read_latency)\n{\n\tbool wm_lv_0_adjust_needed = i915->dram_info.wm_lv_0_adjust_needed;\n\tint i, level;\n\n\t \n\tfor (level = 1; level < num_levels; level++) {\n\t\tif (wm[level] == 0) {\n\t\t\tfor (i = level + 1; i < num_levels; i++)\n\t\t\t\twm[i] = 0;\n\n\t\t\tnum_levels = level;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (wm[0] == 0) {\n\t\tfor (level = 0; level < num_levels; level++)\n\t\t\twm[level] += read_latency;\n\t}\n\n\t \n\tif (wm_lv_0_adjust_needed)\n\t\twm[0] += 1;\n}\n\nstatic void mtl_read_wm_latency(struct drm_i915_private *i915, u16 wm[])\n{\n\tint num_levels = i915->display.wm.num_levels;\n\tu32 val;\n\n\tval = intel_de_read(i915, MTL_LATENCY_LP0_LP1);\n\twm[0] = REG_FIELD_GET(MTL_LATENCY_LEVEL_EVEN_MASK, val);\n\twm[1] = REG_FIELD_GET(MTL_LATENCY_LEVEL_ODD_MASK, val);\n\n\tval = intel_de_read(i915, MTL_LATENCY_LP2_LP3);\n\twm[2] = REG_FIELD_GET(MTL_LATENCY_LEVEL_EVEN_MASK, val);\n\twm[3] = REG_FIELD_GET(MTL_LATENCY_LEVEL_ODD_MASK, val);\n\n\tval = intel_de_read(i915, MTL_LATENCY_LP4_LP5);\n\twm[4] = REG_FIELD_GET(MTL_LATENCY_LEVEL_EVEN_MASK, val);\n\twm[5] = REG_FIELD_GET(MTL_LATENCY_LEVEL_ODD_MASK, val);\n\n\tadjust_wm_latency(i915, wm, num_levels, 6);\n}\n\nstatic void skl_read_wm_latency(struct drm_i915_private *i915, u16 wm[])\n{\n\tint num_levels = i915->display.wm.num_levels;\n\tint read_latency = DISPLAY_VER(i915) >= 12 ? 3 : 2;\n\tint mult = IS_DG2(i915) ? 2 : 1;\n\tu32 val;\n\tint ret;\n\n\t \n\tval = 0;  \n\tret = snb_pcode_read(&i915->uncore, GEN9_PCODE_READ_MEM_LATENCY, &val, NULL);\n\tif (ret) {\n\t\tdrm_err(&i915->drm, \"SKL Mailbox read error = %d\\n\", ret);\n\t\treturn;\n\t}\n\n\twm[0] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_0_4_MASK, val) * mult;\n\twm[1] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_1_5_MASK, val) * mult;\n\twm[2] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_2_6_MASK, val) * mult;\n\twm[3] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_3_7_MASK, val) * mult;\n\n\t \n\tval = 1;  \n\tret = snb_pcode_read(&i915->uncore, GEN9_PCODE_READ_MEM_LATENCY, &val, NULL);\n\tif (ret) {\n\t\tdrm_err(&i915->drm, \"SKL Mailbox read error = %d\\n\", ret);\n\t\treturn;\n\t}\n\n\twm[4] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_0_4_MASK, val) * mult;\n\twm[5] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_1_5_MASK, val) * mult;\n\twm[6] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_2_6_MASK, val) * mult;\n\twm[7] = REG_FIELD_GET(GEN9_MEM_LATENCY_LEVEL_3_7_MASK, val) * mult;\n\n\tadjust_wm_latency(i915, wm, num_levels, read_latency);\n}\n\nstatic void skl_setup_wm_latency(struct drm_i915_private *i915)\n{\n\tif (HAS_HW_SAGV_WM(i915))\n\t\ti915->display.wm.num_levels = 6;\n\telse\n\t\ti915->display.wm.num_levels = 8;\n\n\tif (DISPLAY_VER(i915) >= 14)\n\t\tmtl_read_wm_latency(i915, i915->display.wm.skl_latency);\n\telse\n\t\tskl_read_wm_latency(i915, i915->display.wm.skl_latency);\n\n\tintel_print_wm_latency(i915, \"Gen9 Plane\", i915->display.wm.skl_latency);\n}\n\nstatic const struct intel_wm_funcs skl_wm_funcs = {\n\t.compute_global_watermarks = skl_compute_wm,\n\t.get_hw_state = skl_wm_get_hw_state_and_sanitize,\n};\n\nvoid skl_wm_init(struct drm_i915_private *i915)\n{\n\tintel_sagv_init(i915);\n\n\tskl_setup_wm_latency(i915);\n\n\ti915->display.funcs.wm = &skl_wm_funcs;\n}\n\nstatic struct intel_global_state *intel_dbuf_duplicate_state(struct intel_global_obj *obj)\n{\n\tstruct intel_dbuf_state *dbuf_state;\n\n\tdbuf_state = kmemdup(obj->state, sizeof(*dbuf_state), GFP_KERNEL);\n\tif (!dbuf_state)\n\t\treturn NULL;\n\n\treturn &dbuf_state->base;\n}\n\nstatic void intel_dbuf_destroy_state(struct intel_global_obj *obj,\n\t\t\t\t     struct intel_global_state *state)\n{\n\tkfree(state);\n}\n\nstatic const struct intel_global_state_funcs intel_dbuf_funcs = {\n\t.atomic_duplicate_state = intel_dbuf_duplicate_state,\n\t.atomic_destroy_state = intel_dbuf_destroy_state,\n};\n\nstruct intel_dbuf_state *\nintel_atomic_get_dbuf_state(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tstruct intel_global_state *dbuf_state;\n\n\tdbuf_state = intel_atomic_get_global_obj_state(state, &i915->display.dbuf.obj);\n\tif (IS_ERR(dbuf_state))\n\t\treturn ERR_CAST(dbuf_state);\n\n\treturn to_intel_dbuf_state(dbuf_state);\n}\n\nint intel_dbuf_init(struct drm_i915_private *i915)\n{\n\tstruct intel_dbuf_state *dbuf_state;\n\n\tdbuf_state = kzalloc(sizeof(*dbuf_state), GFP_KERNEL);\n\tif (!dbuf_state)\n\t\treturn -ENOMEM;\n\n\tintel_atomic_global_obj_init(i915, &i915->display.dbuf.obj,\n\t\t\t\t     &dbuf_state->base, &intel_dbuf_funcs);\n\n\treturn 0;\n}\n\n \nstatic void update_mbus_pre_enable(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tu32 mbus_ctl, dbuf_min_tracker_val;\n\tenum dbuf_slice slice;\n\tconst struct intel_dbuf_state *dbuf_state =\n\t\tintel_atomic_get_new_dbuf_state(state);\n\n\tif (!HAS_MBUS_JOINING(i915))\n\t\treturn;\n\n\t \n\tif (dbuf_state->joined_mbus) {\n\t\tmbus_ctl = MBUS_HASHING_MODE_1x4 | MBUS_JOIN |\n\t\t\tMBUS_JOIN_PIPE_SELECT_NONE;\n\t\tdbuf_min_tracker_val = DBUF_MIN_TRACKER_STATE_SERVICE(3);\n\t} else {\n\t\tmbus_ctl = MBUS_HASHING_MODE_2x2 |\n\t\t\tMBUS_JOIN_PIPE_SELECT_NONE;\n\t\tdbuf_min_tracker_val = DBUF_MIN_TRACKER_STATE_SERVICE(1);\n\t}\n\n\tintel_de_rmw(i915, MBUS_CTL,\n\t\t     MBUS_HASHING_MODE_MASK | MBUS_JOIN |\n\t\t     MBUS_JOIN_PIPE_SELECT_MASK, mbus_ctl);\n\n\tfor_each_dbuf_slice(i915, slice)\n\t\tintel_de_rmw(i915, DBUF_CTL_S(slice),\n\t\t\t     DBUF_MIN_TRACKER_STATE_SERVICE_MASK,\n\t\t\t     dbuf_min_tracker_val);\n}\n\nvoid intel_dbuf_pre_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_dbuf_state *new_dbuf_state =\n\t\tintel_atomic_get_new_dbuf_state(state);\n\tconst struct intel_dbuf_state *old_dbuf_state =\n\t\tintel_atomic_get_old_dbuf_state(state);\n\n\tif (!new_dbuf_state ||\n\t    (new_dbuf_state->enabled_slices == old_dbuf_state->enabled_slices &&\n\t     new_dbuf_state->joined_mbus == old_dbuf_state->joined_mbus))\n\t\treturn;\n\n\tWARN_ON(!new_dbuf_state->base.changed);\n\n\tupdate_mbus_pre_enable(state);\n\tgen9_dbuf_slices_update(i915,\n\t\t\t\told_dbuf_state->enabled_slices |\n\t\t\t\tnew_dbuf_state->enabled_slices);\n}\n\nvoid intel_dbuf_post_plane_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_dbuf_state *new_dbuf_state =\n\t\tintel_atomic_get_new_dbuf_state(state);\n\tconst struct intel_dbuf_state *old_dbuf_state =\n\t\tintel_atomic_get_old_dbuf_state(state);\n\n\tif (!new_dbuf_state ||\n\t    (new_dbuf_state->enabled_slices == old_dbuf_state->enabled_slices &&\n\t     new_dbuf_state->joined_mbus == old_dbuf_state->joined_mbus))\n\t\treturn;\n\n\tWARN_ON(!new_dbuf_state->base.changed);\n\n\tgen9_dbuf_slices_update(i915,\n\t\t\t\tnew_dbuf_state->enabled_slices);\n}\n\nstatic bool xelpdp_is_only_pipe_per_dbuf_bank(enum pipe pipe, u8 active_pipes)\n{\n\tswitch (pipe) {\n\tcase PIPE_A:\n\t\treturn !(active_pipes & BIT(PIPE_D));\n\tcase PIPE_D:\n\t\treturn !(active_pipes & BIT(PIPE_A));\n\tcase PIPE_B:\n\t\treturn !(active_pipes & BIT(PIPE_C));\n\tcase PIPE_C:\n\t\treturn !(active_pipes & BIT(PIPE_B));\n\tdefault:  \n\t\tMISSING_CASE(pipe);\n\t\tbreak;\n\t}\n\n\treturn false;\n}\n\nvoid intel_mbus_dbox_update(struct intel_atomic_state *state)\n{\n\tstruct drm_i915_private *i915 = to_i915(state->base.dev);\n\tconst struct intel_dbuf_state *new_dbuf_state, *old_dbuf_state;\n\tconst struct intel_crtc_state *new_crtc_state;\n\tconst struct intel_crtc *crtc;\n\tu32 val = 0;\n\tint i;\n\n\tif (DISPLAY_VER(i915) < 11)\n\t\treturn;\n\n\tnew_dbuf_state = intel_atomic_get_new_dbuf_state(state);\n\told_dbuf_state = intel_atomic_get_old_dbuf_state(state);\n\tif (!new_dbuf_state ||\n\t    (new_dbuf_state->joined_mbus == old_dbuf_state->joined_mbus &&\n\t     new_dbuf_state->active_pipes == old_dbuf_state->active_pipes))\n\t\treturn;\n\n\tif (DISPLAY_VER(i915) >= 14)\n\t\tval |= MBUS_DBOX_I_CREDIT(2);\n\n\tif (DISPLAY_VER(i915) >= 12) {\n\t\tval |= MBUS_DBOX_B2B_TRANSACTIONS_MAX(16);\n\t\tval |= MBUS_DBOX_B2B_TRANSACTIONS_DELAY(1);\n\t\tval |= MBUS_DBOX_REGULATE_B2B_TRANSACTIONS_EN;\n\t}\n\n\tif (DISPLAY_VER(i915) >= 14)\n\t\tval |= new_dbuf_state->joined_mbus ? MBUS_DBOX_A_CREDIT(12) :\n\t\t\t\t\t\t     MBUS_DBOX_A_CREDIT(8);\n\telse if (IS_ALDERLAKE_P(i915))\n\t\t \n\t\tval |= new_dbuf_state->joined_mbus ? MBUS_DBOX_A_CREDIT(6) :\n\t\t\t\t\t\t     MBUS_DBOX_A_CREDIT(4);\n\telse\n\t\tval |= MBUS_DBOX_A_CREDIT(2);\n\n\tif (DISPLAY_VER(i915) >= 14) {\n\t\tval |= MBUS_DBOX_B_CREDIT(0xA);\n\t} else if (IS_ALDERLAKE_P(i915)) {\n\t\tval |= MBUS_DBOX_BW_CREDIT(2);\n\t\tval |= MBUS_DBOX_B_CREDIT(8);\n\t} else if (DISPLAY_VER(i915) >= 12) {\n\t\tval |= MBUS_DBOX_BW_CREDIT(2);\n\t\tval |= MBUS_DBOX_B_CREDIT(12);\n\t} else {\n\t\tval |= MBUS_DBOX_BW_CREDIT(1);\n\t\tval |= MBUS_DBOX_B_CREDIT(8);\n\t}\n\n\tfor_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tu32 pipe_val = val;\n\n\t\tif (!new_crtc_state->hw.active)\n\t\t\tcontinue;\n\n\t\tif (DISPLAY_VER(i915) >= 14) {\n\t\t\tif (xelpdp_is_only_pipe_per_dbuf_bank(crtc->pipe,\n\t\t\t\t\t\t\t      new_dbuf_state->active_pipes))\n\t\t\t\tpipe_val |= MBUS_DBOX_BW_8CREDITS_MTL;\n\t\t\telse\n\t\t\t\tpipe_val |= MBUS_DBOX_BW_4CREDITS_MTL;\n\t\t}\n\n\t\tintel_de_write(i915, PIPE_MBUS_DBOX_CTL(crtc->pipe), pipe_val);\n\t}\n}\n\nstatic int skl_watermark_ipc_status_show(struct seq_file *m, void *data)\n{\n\tstruct drm_i915_private *i915 = m->private;\n\n\tseq_printf(m, \"Isochronous Priority Control: %s\\n\",\n\t\t   str_yes_no(skl_watermark_ipc_enabled(i915)));\n\treturn 0;\n}\n\nstatic int skl_watermark_ipc_status_open(struct inode *inode, struct file *file)\n{\n\tstruct drm_i915_private *i915 = inode->i_private;\n\n\treturn single_open(file, skl_watermark_ipc_status_show, i915);\n}\n\nstatic ssize_t skl_watermark_ipc_status_write(struct file *file,\n\t\t\t\t\t      const char __user *ubuf,\n\t\t\t\t\t      size_t len, loff_t *offp)\n{\n\tstruct seq_file *m = file->private_data;\n\tstruct drm_i915_private *i915 = m->private;\n\tintel_wakeref_t wakeref;\n\tbool enable;\n\tint ret;\n\n\tret = kstrtobool_from_user(ubuf, len, &enable);\n\tif (ret < 0)\n\t\treturn ret;\n\n\twith_intel_runtime_pm(&i915->runtime_pm, wakeref) {\n\t\tif (!skl_watermark_ipc_enabled(i915) && enable)\n\t\t\tdrm_info(&i915->drm,\n\t\t\t\t \"Enabling IPC: WM will be proper only after next commit\\n\");\n\t\ti915->display.wm.ipc_enabled = enable;\n\t\tskl_watermark_ipc_update(i915);\n\t}\n\n\treturn len;\n}\n\nstatic const struct file_operations skl_watermark_ipc_status_fops = {\n\t.owner = THIS_MODULE,\n\t.open = skl_watermark_ipc_status_open,\n\t.read = seq_read,\n\t.llseek = seq_lseek,\n\t.release = single_release,\n\t.write = skl_watermark_ipc_status_write\n};\n\nstatic int intel_sagv_status_show(struct seq_file *m, void *unused)\n{\n\tstruct drm_i915_private *i915 = m->private;\n\tstatic const char * const sagv_status[] = {\n\t\t[I915_SAGV_UNKNOWN] = \"unknown\",\n\t\t[I915_SAGV_DISABLED] = \"disabled\",\n\t\t[I915_SAGV_ENABLED] = \"enabled\",\n\t\t[I915_SAGV_NOT_CONTROLLED] = \"not controlled\",\n\t};\n\n\tseq_printf(m, \"SAGV available: %s\\n\", str_yes_no(intel_has_sagv(i915)));\n\tseq_printf(m, \"SAGV modparam: %s\\n\", str_enabled_disabled(i915->params.enable_sagv));\n\tseq_printf(m, \"SAGV status: %s\\n\", sagv_status[i915->display.sagv.status]);\n\tseq_printf(m, \"SAGV block time: %d usec\\n\", i915->display.sagv.block_time_us);\n\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(intel_sagv_status);\n\nvoid skl_watermark_debugfs_register(struct drm_i915_private *i915)\n{\n\tstruct drm_minor *minor = i915->drm.primary;\n\n\tif (HAS_IPC(i915))\n\t\tdebugfs_create_file(\"i915_ipc_status\", 0644, minor->debugfs_root, i915,\n\t\t\t\t    &skl_watermark_ipc_status_fops);\n\n\tif (HAS_SAGV(i915))\n\t\tdebugfs_create_file(\"i915_sagv_status\", 0444, minor->debugfs_root, i915,\n\t\t\t\t    &intel_sagv_status_fops);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}