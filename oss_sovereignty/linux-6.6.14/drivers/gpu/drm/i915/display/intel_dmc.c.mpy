{
  "module_name": "intel_dmc.c",
  "hash_id": "d3b50ba50f7bfe624c0a2a6ff1ea7b1f207f34651a39ba816dfe7a0da075a4ff",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/i915/display/intel_dmc.c",
  "human_readable_source": " \n\n#include <linux/firmware.h>\n\n#include \"i915_drv.h\"\n#include \"i915_reg.h\"\n#include \"intel_de.h\"\n#include \"intel_dmc.h\"\n#include \"intel_dmc_regs.h\"\n\n \n\nenum intel_dmc_id {\n\tDMC_FW_MAIN = 0,\n\tDMC_FW_PIPEA,\n\tDMC_FW_PIPEB,\n\tDMC_FW_PIPEC,\n\tDMC_FW_PIPED,\n\tDMC_FW_MAX\n};\n\nstruct intel_dmc {\n\tstruct drm_i915_private *i915;\n\tstruct work_struct work;\n\tconst char *fw_path;\n\tu32 max_fw_size;  \n\tu32 version;\n\tstruct dmc_fw_info {\n\t\tu32 mmio_count;\n\t\ti915_reg_t mmioaddr[20];\n\t\tu32 mmiodata[20];\n\t\tu32 dmc_offset;\n\t\tu32 start_mmioaddr;\n\t\tu32 dmc_fw_size;  \n\t\tu32 *payload;\n\t\tbool present;\n\t} dmc_info[DMC_FW_MAX];\n};\n\n \nstatic struct intel_dmc *i915_to_dmc(struct drm_i915_private *i915)\n{\n\treturn i915->display.dmc.dmc;\n}\n\n#define DMC_VERSION(major, minor)\t((major) << 16 | (minor))\n#define DMC_VERSION_MAJOR(version)\t((version) >> 16)\n#define DMC_VERSION_MINOR(version)\t((version) & 0xffff)\n\n#define DMC_PATH(platform) \\\n\t\"i915/\" __stringify(platform) \"_dmc.bin\"\n\n \n#define DMC_LEGACY_PATH(platform, major, minor) \\\n\t\"i915/\"\t\t\t\t\t\\\n\t__stringify(platform) \"_dmc_ver\"\t\\\n\t__stringify(major) \"_\"\t\t\t\\\n\t__stringify(minor) \".bin\"\n\n#define XELPDP_DMC_MAX_FW_SIZE\t\t0x7000\n#define DISPLAY_VER13_DMC_MAX_FW_SIZE\t0x20000\n#define DISPLAY_VER12_DMC_MAX_FW_SIZE\tICL_DMC_MAX_FW_SIZE\n\n#define MTL_DMC_PATH\t\t\tDMC_PATH(mtl)\nMODULE_FIRMWARE(MTL_DMC_PATH);\n\n#define DG2_DMC_PATH\t\t\tDMC_LEGACY_PATH(dg2, 2, 08)\nMODULE_FIRMWARE(DG2_DMC_PATH);\n\n#define ADLP_DMC_PATH\t\t\tDMC_PATH(adlp)\n#define ADLP_DMC_FALLBACK_PATH\t\tDMC_LEGACY_PATH(adlp, 2, 16)\nMODULE_FIRMWARE(ADLP_DMC_PATH);\nMODULE_FIRMWARE(ADLP_DMC_FALLBACK_PATH);\n\n#define ADLS_DMC_PATH\t\t\tDMC_LEGACY_PATH(adls, 2, 01)\nMODULE_FIRMWARE(ADLS_DMC_PATH);\n\n#define DG1_DMC_PATH\t\t\tDMC_LEGACY_PATH(dg1, 2, 02)\nMODULE_FIRMWARE(DG1_DMC_PATH);\n\n#define RKL_DMC_PATH\t\t\tDMC_LEGACY_PATH(rkl, 2, 03)\nMODULE_FIRMWARE(RKL_DMC_PATH);\n\n#define TGL_DMC_PATH\t\t\tDMC_LEGACY_PATH(tgl, 2, 12)\nMODULE_FIRMWARE(TGL_DMC_PATH);\n\n#define ICL_DMC_PATH\t\t\tDMC_LEGACY_PATH(icl, 1, 09)\n#define ICL_DMC_MAX_FW_SIZE\t\t0x6000\nMODULE_FIRMWARE(ICL_DMC_PATH);\n\n#define GLK_DMC_PATH\t\t\tDMC_LEGACY_PATH(glk, 1, 04)\n#define GLK_DMC_MAX_FW_SIZE\t\t0x4000\nMODULE_FIRMWARE(GLK_DMC_PATH);\n\n#define KBL_DMC_PATH\t\t\tDMC_LEGACY_PATH(kbl, 1, 04)\n#define KBL_DMC_MAX_FW_SIZE\t\tBXT_DMC_MAX_FW_SIZE\nMODULE_FIRMWARE(KBL_DMC_PATH);\n\n#define SKL_DMC_PATH\t\t\tDMC_LEGACY_PATH(skl, 1, 27)\n#define SKL_DMC_MAX_FW_SIZE\t\tBXT_DMC_MAX_FW_SIZE\nMODULE_FIRMWARE(SKL_DMC_PATH);\n\n#define BXT_DMC_PATH\t\t\tDMC_LEGACY_PATH(bxt, 1, 07)\n#define BXT_DMC_MAX_FW_SIZE\t\t0x3000\nMODULE_FIRMWARE(BXT_DMC_PATH);\n\n#define DMC_DEFAULT_FW_OFFSET\t\t0xFFFFFFFF\n#define PACKAGE_MAX_FW_INFO_ENTRIES\t20\n#define PACKAGE_V2_MAX_FW_INFO_ENTRIES\t32\n#define DMC_V1_MAX_MMIO_COUNT\t\t8\n#define DMC_V3_MAX_MMIO_COUNT\t\t20\n#define DMC_V1_MMIO_START_RANGE\t\t0x80000\n\n#define PIPE_TO_DMC_ID(pipe)\t\t (DMC_FW_PIPEA + ((pipe) - PIPE_A))\n\nstruct intel_css_header {\n\t \n\tu32 module_type;\n\n\t \n\tu32 header_len;\n\n\t \n\tu32 header_ver;\n\n\t \n\tu32 module_id;\n\n\t \n\tu32 module_vendor;\n\n\t \n\tu32 date;\n\n\t \n\tu32 size;\n\n\t \n\tu32 key_size;\n\n\t \n\tu32 modulus_size;\n\n\t \n\tu32 exponent_size;\n\n\t \n\tu32 reserved1[12];\n\n\t \n\tu32 version;\n\n\t \n\tu32 reserved2[8];\n\n\t \n\tu32 kernel_header_info;\n} __packed;\n\nstruct intel_fw_info {\n\tu8 reserved1;\n\n\t \n\tu8 dmc_id;\n\n\t \n\tchar stepping;\n\n\t \n\tchar substepping;\n\n\tu32 offset;\n\tu32 reserved2;\n} __packed;\n\nstruct intel_package_header {\n\t \n\tu8 header_len;\n\n\t \n\tu8 header_ver;\n\n\tu8 reserved[10];\n\n\t \n\tu32 num_entries;\n} __packed;\n\nstruct intel_dmc_header_base {\n\t \n\tu32 signature;\n\n\t \n\tu8 header_len;\n\n\t \n\tu8 header_ver;\n\n\t \n\tu16 dmcc_ver;\n\n\t \n\tu32 project;\n\n\t \n\tu32 fw_size;\n\n\t \n\tu32 fw_version;\n} __packed;\n\nstruct intel_dmc_header_v1 {\n\tstruct intel_dmc_header_base base;\n\n\t \n\tu32 mmio_count;\n\n\t \n\tu32 mmioaddr[DMC_V1_MAX_MMIO_COUNT];\n\n\t \n\tu32 mmiodata[DMC_V1_MAX_MMIO_COUNT];\n\n\t \n\tchar dfile[32];\n\n\tu32 reserved1[2];\n} __packed;\n\nstruct intel_dmc_header_v3 {\n\tstruct intel_dmc_header_base base;\n\n\t \n\tu32 start_mmioaddr;\n\n\tu32 reserved[9];\n\n\t \n\tchar dfile[32];\n\n\t \n\tu32 mmio_count;\n\n\t \n\tu32 mmioaddr[DMC_V3_MAX_MMIO_COUNT];\n\n\t \n\tu32 mmiodata[DMC_V3_MAX_MMIO_COUNT];\n} __packed;\n\nstruct stepping_info {\n\tchar stepping;\n\tchar substepping;\n};\n\n#define for_each_dmc_id(__dmc_id) \\\n\tfor ((__dmc_id) = DMC_FW_MAIN; (__dmc_id) < DMC_FW_MAX; (__dmc_id)++)\n\nstatic bool is_valid_dmc_id(enum intel_dmc_id dmc_id)\n{\n\treturn dmc_id >= DMC_FW_MAIN && dmc_id < DMC_FW_MAX;\n}\n\nstatic bool has_dmc_id_fw(struct drm_i915_private *i915, enum intel_dmc_id dmc_id)\n{\n\tstruct intel_dmc *dmc = i915_to_dmc(i915);\n\n\treturn dmc && dmc->dmc_info[dmc_id].payload;\n}\n\nbool intel_dmc_has_payload(struct drm_i915_private *i915)\n{\n\treturn has_dmc_id_fw(i915, DMC_FW_MAIN);\n}\n\nstatic const struct stepping_info *\nintel_get_stepping_info(struct drm_i915_private *i915,\n\t\t\tstruct stepping_info *si)\n{\n\tconst char *step_name = intel_step_name(RUNTIME_INFO(i915)->step.display_step);\n\n\tsi->stepping = step_name[0];\n\tsi->substepping = step_name[1];\n\treturn si;\n}\n\nstatic void gen9_set_dc_state_debugmask(struct drm_i915_private *i915)\n{\n\t \n\tintel_de_rmw(i915, DC_STATE_DEBUG, 0,\n\t\t     DC_STATE_DEBUG_MASK_CORES | DC_STATE_DEBUG_MASK_MEMORY_UP);\n\tintel_de_posting_read(i915, DC_STATE_DEBUG);\n}\n\nstatic void disable_event_handler(struct drm_i915_private *i915,\n\t\t\t\t  i915_reg_t ctl_reg, i915_reg_t htp_reg)\n{\n\tintel_de_write(i915, ctl_reg,\n\t\t       REG_FIELD_PREP(DMC_EVT_CTL_TYPE_MASK,\n\t\t\t\t      DMC_EVT_CTL_TYPE_EDGE_0_1) |\n\t\t       REG_FIELD_PREP(DMC_EVT_CTL_EVENT_ID_MASK,\n\t\t\t\t      DMC_EVT_CTL_EVENT_ID_FALSE));\n\tintel_de_write(i915, htp_reg, 0);\n}\n\nstatic void\ndisable_flip_queue_event(struct drm_i915_private *i915,\n\t\t\t i915_reg_t ctl_reg, i915_reg_t htp_reg)\n{\n\tu32 event_ctl;\n\tu32 event_htp;\n\n\tevent_ctl = intel_de_read(i915, ctl_reg);\n\tevent_htp = intel_de_read(i915, htp_reg);\n\tif (event_ctl != (DMC_EVT_CTL_ENABLE |\n\t\t\t  DMC_EVT_CTL_RECURRING |\n\t\t\t  REG_FIELD_PREP(DMC_EVT_CTL_TYPE_MASK,\n\t\t\t\t\t DMC_EVT_CTL_TYPE_EDGE_0_1) |\n\t\t\t  REG_FIELD_PREP(DMC_EVT_CTL_EVENT_ID_MASK,\n\t\t\t\t\t DMC_EVT_CTL_EVENT_ID_CLK_MSEC)) ||\n\t    !event_htp) {\n\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t    \"Unexpected DMC event configuration (control %08x htp %08x)\\n\",\n\t\t\t    event_ctl, event_htp);\n\t\treturn;\n\t}\n\n\tdisable_event_handler(i915, ctl_reg, htp_reg);\n}\n\nstatic bool\nget_flip_queue_event_regs(struct drm_i915_private *i915, enum intel_dmc_id dmc_id,\n\t\t\t  i915_reg_t *ctl_reg, i915_reg_t *htp_reg)\n{\n\tif (dmc_id == DMC_FW_MAIN) {\n\t\tif (DISPLAY_VER(i915) == 12) {\n\t\t\t*ctl_reg = DMC_EVT_CTL(i915, dmc_id, 3);\n\t\t\t*htp_reg = DMC_EVT_HTP(i915, dmc_id, 3);\n\n\t\t\treturn true;\n\t\t}\n\t} else if (dmc_id >= DMC_FW_PIPEA && dmc_id <= DMC_FW_PIPED) {\n\t\tif (IS_DG2(i915)) {\n\t\t\t*ctl_reg = DMC_EVT_CTL(i915, dmc_id, 2);\n\t\t\t*htp_reg = DMC_EVT_HTP(i915, dmc_id, 2);\n\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic void\ndisable_all_flip_queue_events(struct drm_i915_private *i915)\n{\n\tenum intel_dmc_id dmc_id;\n\n\t \n\tif (!IS_TIGERLAKE(i915))\n\t\treturn;\n\n\tfor_each_dmc_id(dmc_id) {\n\t\ti915_reg_t ctl_reg;\n\t\ti915_reg_t htp_reg;\n\n\t\tif (!has_dmc_id_fw(i915, dmc_id))\n\t\t\tcontinue;\n\n\t\tif (!get_flip_queue_event_regs(i915, dmc_id, &ctl_reg, &htp_reg))\n\t\t\tcontinue;\n\n\t\tdisable_flip_queue_event(i915, ctl_reg, htp_reg);\n\t}\n}\n\nstatic void disable_all_event_handlers(struct drm_i915_private *i915)\n{\n\tenum intel_dmc_id dmc_id;\n\n\t \n\tif (DISPLAY_VER(i915) < 12)\n\t\treturn;\n\n\tfor_each_dmc_id(dmc_id) {\n\t\tint handler;\n\n\t\tif (!has_dmc_id_fw(i915, dmc_id))\n\t\t\tcontinue;\n\n\t\tfor (handler = 0; handler < DMC_EVENT_HANDLER_COUNT_GEN12; handler++)\n\t\t\tdisable_event_handler(i915,\n\t\t\t\t\t      DMC_EVT_CTL(i915, dmc_id, handler),\n\t\t\t\t\t      DMC_EVT_HTP(i915, dmc_id, handler));\n\t}\n}\n\nstatic void adlp_pipedmc_clock_gating_wa(struct drm_i915_private *i915, bool enable)\n{\n\tenum pipe pipe;\n\n\t \n\tif (enable)\n\t\tfor (pipe = PIPE_A; pipe <= PIPE_D; pipe++)\n\t\t\tintel_de_rmw(i915, CLKGATE_DIS_PSL_EXT(pipe),\n\t\t\t\t     0, PIPEDMC_GATING_DIS);\n\telse\n\t\tfor (pipe = PIPE_C; pipe <= PIPE_D; pipe++)\n\t\t\tintel_de_rmw(i915, CLKGATE_DIS_PSL_EXT(pipe),\n\t\t\t\t     PIPEDMC_GATING_DIS, 0);\n}\n\nstatic void mtl_pipedmc_clock_gating_wa(struct drm_i915_private *i915)\n{\n\t \n\tintel_de_rmw(i915, GEN9_CLKGATE_DIS_0, 0,\n\t\t     MTL_PIPEDMC_GATING_DIS_A | MTL_PIPEDMC_GATING_DIS_B);\n}\n\nstatic void pipedmc_clock_gating_wa(struct drm_i915_private *i915, bool enable)\n{\n\tif (DISPLAY_VER(i915) >= 14 && enable)\n\t\tmtl_pipedmc_clock_gating_wa(i915);\n\telse if (DISPLAY_VER(i915) == 13)\n\t\tadlp_pipedmc_clock_gating_wa(i915, enable);\n}\n\nvoid intel_dmc_enable_pipe(struct drm_i915_private *i915, enum pipe pipe)\n{\n\tenum intel_dmc_id dmc_id = PIPE_TO_DMC_ID(pipe);\n\n\tif (!is_valid_dmc_id(dmc_id) || !has_dmc_id_fw(i915, dmc_id))\n\t\treturn;\n\n\tif (DISPLAY_VER(i915) >= 14)\n\t\tintel_de_rmw(i915, MTL_PIPEDMC_CONTROL, 0, PIPEDMC_ENABLE_MTL(pipe));\n\telse\n\t\tintel_de_rmw(i915, PIPEDMC_CONTROL(pipe), 0, PIPEDMC_ENABLE);\n}\n\nvoid intel_dmc_disable_pipe(struct drm_i915_private *i915, enum pipe pipe)\n{\n\tenum intel_dmc_id dmc_id = PIPE_TO_DMC_ID(pipe);\n\n\tif (!is_valid_dmc_id(dmc_id) || !has_dmc_id_fw(i915, dmc_id))\n\t\treturn;\n\n\tif (DISPLAY_VER(i915) >= 14)\n\t\tintel_de_rmw(i915, MTL_PIPEDMC_CONTROL, PIPEDMC_ENABLE_MTL(pipe), 0);\n\telse\n\t\tintel_de_rmw(i915, PIPEDMC_CONTROL(pipe), PIPEDMC_ENABLE, 0);\n}\n\nstatic bool is_dmc_evt_ctl_reg(struct drm_i915_private *i915,\n\t\t\t       enum intel_dmc_id dmc_id, i915_reg_t reg)\n{\n\tu32 offset = i915_mmio_reg_offset(reg);\n\tu32 start = i915_mmio_reg_offset(DMC_EVT_CTL(i915, dmc_id, 0));\n\tu32 end = i915_mmio_reg_offset(DMC_EVT_CTL(i915, dmc_id, DMC_EVENT_HANDLER_COUNT_GEN12));\n\n\treturn offset >= start && offset < end;\n}\n\nstatic bool disable_dmc_evt(struct drm_i915_private *i915,\n\t\t\t    enum intel_dmc_id dmc_id,\n\t\t\t    i915_reg_t reg, u32 data)\n{\n\tif (!is_dmc_evt_ctl_reg(i915, dmc_id, reg))\n\t\treturn false;\n\n\t \n\tif (dmc_id != DMC_FW_MAIN)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic u32 dmc_mmiodata(struct drm_i915_private *i915,\n\t\t\tstruct intel_dmc *dmc,\n\t\t\tenum intel_dmc_id dmc_id, int i)\n{\n\tif (disable_dmc_evt(i915, dmc_id,\n\t\t\t    dmc->dmc_info[dmc_id].mmioaddr[i],\n\t\t\t    dmc->dmc_info[dmc_id].mmiodata[i]))\n\t\treturn REG_FIELD_PREP(DMC_EVT_CTL_TYPE_MASK,\n\t\t\t\t      DMC_EVT_CTL_TYPE_EDGE_0_1) |\n\t\t\tREG_FIELD_PREP(DMC_EVT_CTL_EVENT_ID_MASK,\n\t\t\t\t       DMC_EVT_CTL_EVENT_ID_FALSE);\n\telse\n\t\treturn dmc->dmc_info[dmc_id].mmiodata[i];\n}\n\n \nvoid intel_dmc_load_program(struct drm_i915_private *i915)\n{\n\tstruct i915_power_domains *power_domains = &i915->display.power.domains;\n\tstruct intel_dmc *dmc = i915_to_dmc(i915);\n\tenum intel_dmc_id dmc_id;\n\tu32 i;\n\n\tif (!intel_dmc_has_payload(i915))\n\t\treturn;\n\n\tpipedmc_clock_gating_wa(i915, true);\n\n\tdisable_all_event_handlers(i915);\n\n\tassert_rpm_wakelock_held(&i915->runtime_pm);\n\n\tpreempt_disable();\n\n\tfor_each_dmc_id(dmc_id) {\n\t\tfor (i = 0; i < dmc->dmc_info[dmc_id].dmc_fw_size; i++) {\n\t\t\tintel_de_write_fw(i915,\n\t\t\t\t\t  DMC_PROGRAM(dmc->dmc_info[dmc_id].start_mmioaddr, i),\n\t\t\t\t\t  dmc->dmc_info[dmc_id].payload[i]);\n\t\t}\n\t}\n\n\tpreempt_enable();\n\n\tfor_each_dmc_id(dmc_id) {\n\t\tfor (i = 0; i < dmc->dmc_info[dmc_id].mmio_count; i++) {\n\t\t\tintel_de_write(i915, dmc->dmc_info[dmc_id].mmioaddr[i],\n\t\t\t\t       dmc_mmiodata(i915, dmc, dmc_id, i));\n\t\t}\n\t}\n\n\tpower_domains->dc_state = 0;\n\n\tgen9_set_dc_state_debugmask(i915);\n\n\t \n\tdisable_all_flip_queue_events(i915);\n\n\tpipedmc_clock_gating_wa(i915, false);\n}\n\n \nvoid intel_dmc_disable_program(struct drm_i915_private *i915)\n{\n\tif (!intel_dmc_has_payload(i915))\n\t\treturn;\n\n\tpipedmc_clock_gating_wa(i915, true);\n\tdisable_all_event_handlers(i915);\n\tpipedmc_clock_gating_wa(i915, false);\n}\n\nvoid assert_dmc_loaded(struct drm_i915_private *i915)\n{\n\tstruct intel_dmc *dmc = i915_to_dmc(i915);\n\n\tdrm_WARN_ONCE(&i915->drm, !dmc, \"DMC not initialized\\n\");\n\tdrm_WARN_ONCE(&i915->drm, dmc &&\n\t\t      !intel_de_read(i915, DMC_PROGRAM(dmc->dmc_info[DMC_FW_MAIN].start_mmioaddr, 0)),\n\t\t      \"DMC program storage start is NULL\\n\");\n\tdrm_WARN_ONCE(&i915->drm, !intel_de_read(i915, DMC_SSP_BASE),\n\t\t      \"DMC SSP Base Not fine\\n\");\n\tdrm_WARN_ONCE(&i915->drm, !intel_de_read(i915, DMC_HTP_SKL),\n\t\t      \"DMC HTP Not fine\\n\");\n}\n\nstatic bool fw_info_matches_stepping(const struct intel_fw_info *fw_info,\n\t\t\t\t     const struct stepping_info *si)\n{\n\tif ((fw_info->substepping == '*' && si->stepping == fw_info->stepping) ||\n\t    (si->stepping == fw_info->stepping && si->substepping == fw_info->substepping) ||\n\t     \n\t    (si->stepping == '*' && si->substepping == fw_info->substepping) ||\n\t    (fw_info->stepping == '*' && fw_info->substepping == '*'))\n\t\treturn true;\n\n\treturn false;\n}\n\n \nstatic void dmc_set_fw_offset(struct intel_dmc *dmc,\n\t\t\t      const struct intel_fw_info *fw_info,\n\t\t\t      unsigned int num_entries,\n\t\t\t      const struct stepping_info *si,\n\t\t\t      u8 package_ver)\n{\n\tstruct drm_i915_private *i915 = dmc->i915;\n\tenum intel_dmc_id dmc_id;\n\tunsigned int i;\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tdmc_id = package_ver <= 1 ? DMC_FW_MAIN : fw_info[i].dmc_id;\n\n\t\tif (!is_valid_dmc_id(dmc_id)) {\n\t\t\tdrm_dbg(&i915->drm, \"Unsupported firmware id: %u\\n\", dmc_id);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tif (dmc->dmc_info[dmc_id].present)\n\t\t\tcontinue;\n\n\t\tif (fw_info_matches_stepping(&fw_info[i], si)) {\n\t\t\tdmc->dmc_info[dmc_id].present = true;\n\t\t\tdmc->dmc_info[dmc_id].dmc_offset = fw_info[i].offset;\n\t\t}\n\t}\n}\n\nstatic bool dmc_mmio_addr_sanity_check(struct intel_dmc *dmc,\n\t\t\t\t       const u32 *mmioaddr, u32 mmio_count,\n\t\t\t\t       int header_ver, enum intel_dmc_id dmc_id)\n{\n\tstruct drm_i915_private *i915 = dmc->i915;\n\tu32 start_range, end_range;\n\tint i;\n\n\tif (header_ver == 1) {\n\t\tstart_range = DMC_MMIO_START_RANGE;\n\t\tend_range = DMC_MMIO_END_RANGE;\n\t} else if (dmc_id == DMC_FW_MAIN) {\n\t\tstart_range = TGL_MAIN_MMIO_START;\n\t\tend_range = TGL_MAIN_MMIO_END;\n\t} else if (DISPLAY_VER(i915) >= 13) {\n\t\tstart_range = ADLP_PIPE_MMIO_START;\n\t\tend_range = ADLP_PIPE_MMIO_END;\n\t} else if (DISPLAY_VER(i915) >= 12) {\n\t\tstart_range = TGL_PIPE_MMIO_START(dmc_id);\n\t\tend_range = TGL_PIPE_MMIO_END(dmc_id);\n\t} else {\n\t\tdrm_warn(&i915->drm, \"Unknown mmio range for sanity check\");\n\t\treturn false;\n\t}\n\n\tfor (i = 0; i < mmio_count; i++) {\n\t\tif (mmioaddr[i] < start_range || mmioaddr[i] > end_range)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic u32 parse_dmc_fw_header(struct intel_dmc *dmc,\n\t\t\t       const struct intel_dmc_header_base *dmc_header,\n\t\t\t       size_t rem_size, enum intel_dmc_id dmc_id)\n{\n\tstruct drm_i915_private *i915 = dmc->i915;\n\tstruct dmc_fw_info *dmc_info = &dmc->dmc_info[dmc_id];\n\tunsigned int header_len_bytes, dmc_header_size, payload_size, i;\n\tconst u32 *mmioaddr, *mmiodata;\n\tu32 mmio_count, mmio_count_max, start_mmioaddr;\n\tu8 *payload;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(dmc_info->mmioaddr) < DMC_V3_MAX_MMIO_COUNT ||\n\t\t     ARRAY_SIZE(dmc_info->mmioaddr) < DMC_V1_MAX_MMIO_COUNT);\n\n\t \n\tif (rem_size < sizeof(struct intel_dmc_header_base))\n\t\tgoto error_truncated;\n\n\t \n\tif (dmc_header->header_ver == 3) {\n\t\tconst struct intel_dmc_header_v3 *v3 =\n\t\t\t(const struct intel_dmc_header_v3 *)dmc_header;\n\n\t\tif (rem_size < sizeof(struct intel_dmc_header_v3))\n\t\t\tgoto error_truncated;\n\n\t\tmmioaddr = v3->mmioaddr;\n\t\tmmiodata = v3->mmiodata;\n\t\tmmio_count = v3->mmio_count;\n\t\tmmio_count_max = DMC_V3_MAX_MMIO_COUNT;\n\t\t \n\t\theader_len_bytes = dmc_header->header_len * 4;\n\t\tstart_mmioaddr = v3->start_mmioaddr;\n\t\tdmc_header_size = sizeof(*v3);\n\t} else if (dmc_header->header_ver == 1) {\n\t\tconst struct intel_dmc_header_v1 *v1 =\n\t\t\t(const struct intel_dmc_header_v1 *)dmc_header;\n\n\t\tif (rem_size < sizeof(struct intel_dmc_header_v1))\n\t\t\tgoto error_truncated;\n\n\t\tmmioaddr = v1->mmioaddr;\n\t\tmmiodata = v1->mmiodata;\n\t\tmmio_count = v1->mmio_count;\n\t\tmmio_count_max = DMC_V1_MAX_MMIO_COUNT;\n\t\theader_len_bytes = dmc_header->header_len;\n\t\tstart_mmioaddr = DMC_V1_MMIO_START_RANGE;\n\t\tdmc_header_size = sizeof(*v1);\n\t} else {\n\t\tdrm_err(&i915->drm, \"Unknown DMC fw header version: %u\\n\",\n\t\t\tdmc_header->header_ver);\n\t\treturn 0;\n\t}\n\n\tif (header_len_bytes != dmc_header_size) {\n\t\tdrm_err(&i915->drm, \"DMC firmware has wrong dmc header length \"\n\t\t\t\"(%u bytes)\\n\", header_len_bytes);\n\t\treturn 0;\n\t}\n\n\t \n\tif (mmio_count > mmio_count_max) {\n\t\tdrm_err(&i915->drm, \"DMC firmware has wrong mmio count %u\\n\", mmio_count);\n\t\treturn 0;\n\t}\n\n\tif (!dmc_mmio_addr_sanity_check(dmc, mmioaddr, mmio_count,\n\t\t\t\t\tdmc_header->header_ver, dmc_id)) {\n\t\tdrm_err(&i915->drm, \"DMC firmware has Wrong MMIO Addresses\\n\");\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < mmio_count; i++) {\n\t\tdmc_info->mmioaddr[i] = _MMIO(mmioaddr[i]);\n\t\tdmc_info->mmiodata[i] = mmiodata[i];\n\t}\n\tdmc_info->mmio_count = mmio_count;\n\tdmc_info->start_mmioaddr = start_mmioaddr;\n\n\trem_size -= header_len_bytes;\n\n\t \n\tpayload_size = dmc_header->fw_size * 4;\n\tif (rem_size < payload_size)\n\t\tgoto error_truncated;\n\n\tif (payload_size > dmc->max_fw_size) {\n\t\tdrm_err(&i915->drm, \"DMC FW too big (%u bytes)\\n\", payload_size);\n\t\treturn 0;\n\t}\n\tdmc_info->dmc_fw_size = dmc_header->fw_size;\n\n\tdmc_info->payload = kmalloc(payload_size, GFP_KERNEL);\n\tif (!dmc_info->payload)\n\t\treturn 0;\n\n\tpayload = (u8 *)(dmc_header) + header_len_bytes;\n\tmemcpy(dmc_info->payload, payload, payload_size);\n\n\treturn header_len_bytes + payload_size;\n\nerror_truncated:\n\tdrm_err(&i915->drm, \"Truncated DMC firmware, refusing.\\n\");\n\treturn 0;\n}\n\nstatic u32\nparse_dmc_fw_package(struct intel_dmc *dmc,\n\t\t     const struct intel_package_header *package_header,\n\t\t     const struct stepping_info *si,\n\t\t     size_t rem_size)\n{\n\tstruct drm_i915_private *i915 = dmc->i915;\n\tu32 package_size = sizeof(struct intel_package_header);\n\tu32 num_entries, max_entries;\n\tconst struct intel_fw_info *fw_info;\n\n\tif (rem_size < package_size)\n\t\tgoto error_truncated;\n\n\tif (package_header->header_ver == 1) {\n\t\tmax_entries = PACKAGE_MAX_FW_INFO_ENTRIES;\n\t} else if (package_header->header_ver == 2) {\n\t\tmax_entries = PACKAGE_V2_MAX_FW_INFO_ENTRIES;\n\t} else {\n\t\tdrm_err(&i915->drm, \"DMC firmware has unknown header version %u\\n\",\n\t\t\tpackage_header->header_ver);\n\t\treturn 0;\n\t}\n\n\t \n\tpackage_size += max_entries * sizeof(struct intel_fw_info);\n\tif (rem_size < package_size)\n\t\tgoto error_truncated;\n\n\tif (package_header->header_len * 4 != package_size) {\n\t\tdrm_err(&i915->drm, \"DMC firmware has wrong package header length \"\n\t\t\t\"(%u bytes)\\n\", package_size);\n\t\treturn 0;\n\t}\n\n\tnum_entries = package_header->num_entries;\n\tif (WARN_ON(package_header->num_entries > max_entries))\n\t\tnum_entries = max_entries;\n\n\tfw_info = (const struct intel_fw_info *)\n\t\t((u8 *)package_header + sizeof(*package_header));\n\tdmc_set_fw_offset(dmc, fw_info, num_entries, si,\n\t\t\t  package_header->header_ver);\n\n\t \n\treturn package_size;\n\nerror_truncated:\n\tdrm_err(&i915->drm, \"Truncated DMC firmware, refusing.\\n\");\n\treturn 0;\n}\n\n \nstatic u32 parse_dmc_fw_css(struct intel_dmc *dmc,\n\t\t\t    struct intel_css_header *css_header,\n\t\t\t    size_t rem_size)\n{\n\tstruct drm_i915_private *i915 = dmc->i915;\n\n\tif (rem_size < sizeof(struct intel_css_header)) {\n\t\tdrm_err(&i915->drm, \"Truncated DMC firmware, refusing.\\n\");\n\t\treturn 0;\n\t}\n\n\tif (sizeof(struct intel_css_header) !=\n\t    (css_header->header_len * 4)) {\n\t\tdrm_err(&i915->drm, \"DMC firmware has wrong CSS header length \"\n\t\t\t\"(%u bytes)\\n\",\n\t\t\t(css_header->header_len * 4));\n\t\treturn 0;\n\t}\n\n\tdmc->version = css_header->version;\n\n\treturn sizeof(struct intel_css_header);\n}\n\nstatic void parse_dmc_fw(struct intel_dmc *dmc, const struct firmware *fw)\n{\n\tstruct drm_i915_private *i915 = dmc->i915;\n\tstruct intel_css_header *css_header;\n\tstruct intel_package_header *package_header;\n\tstruct intel_dmc_header_base *dmc_header;\n\tstruct stepping_info display_info = { '*', '*'};\n\tconst struct stepping_info *si = intel_get_stepping_info(i915, &display_info);\n\tenum intel_dmc_id dmc_id;\n\tu32 readcount = 0;\n\tu32 r, offset;\n\n\tif (!fw)\n\t\treturn;\n\n\t \n\tcss_header = (struct intel_css_header *)fw->data;\n\tr = parse_dmc_fw_css(dmc, css_header, fw->size);\n\tif (!r)\n\t\treturn;\n\n\treadcount += r;\n\n\t \n\tpackage_header = (struct intel_package_header *)&fw->data[readcount];\n\tr = parse_dmc_fw_package(dmc, package_header, si, fw->size - readcount);\n\tif (!r)\n\t\treturn;\n\n\treadcount += r;\n\n\tfor_each_dmc_id(dmc_id) {\n\t\tif (!dmc->dmc_info[dmc_id].present)\n\t\t\tcontinue;\n\n\t\toffset = readcount + dmc->dmc_info[dmc_id].dmc_offset * 4;\n\t\tif (offset > fw->size) {\n\t\t\tdrm_err(&i915->drm, \"Reading beyond the fw_size\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tdmc_header = (struct intel_dmc_header_base *)&fw->data[offset];\n\t\tparse_dmc_fw_header(dmc, dmc_header, fw->size - offset, dmc_id);\n\t}\n}\n\nstatic void intel_dmc_runtime_pm_get(struct drm_i915_private *i915)\n{\n\tdrm_WARN_ON(&i915->drm, i915->display.dmc.wakeref);\n\ti915->display.dmc.wakeref = intel_display_power_get(i915, POWER_DOMAIN_INIT);\n}\n\nstatic void intel_dmc_runtime_pm_put(struct drm_i915_private *i915)\n{\n\tintel_wakeref_t wakeref __maybe_unused =\n\t\tfetch_and_zero(&i915->display.dmc.wakeref);\n\n\tintel_display_power_put(i915, POWER_DOMAIN_INIT, wakeref);\n}\n\nstatic const char *dmc_fallback_path(struct drm_i915_private *i915)\n{\n\tif (IS_ALDERLAKE_P(i915))\n\t\treturn ADLP_DMC_FALLBACK_PATH;\n\n\treturn NULL;\n}\n\nstatic void dmc_load_work_fn(struct work_struct *work)\n{\n\tstruct intel_dmc *dmc = container_of(work, typeof(*dmc), work);\n\tstruct drm_i915_private *i915 = dmc->i915;\n\tconst struct firmware *fw = NULL;\n\tconst char *fallback_path;\n\tint err;\n\n\terr = request_firmware(&fw, dmc->fw_path, i915->drm.dev);\n\n\tif (err == -ENOENT && !i915->params.dmc_firmware_path) {\n\t\tfallback_path = dmc_fallback_path(i915);\n\t\tif (fallback_path) {\n\t\t\tdrm_dbg_kms(&i915->drm, \"%s not found, falling back to %s\\n\",\n\t\t\t\t    dmc->fw_path, fallback_path);\n\t\t\terr = request_firmware(&fw, fallback_path, i915->drm.dev);\n\t\t\tif (err == 0)\n\t\t\t\tdmc->fw_path = fallback_path;\n\t\t}\n\t}\n\n\tparse_dmc_fw(dmc, fw);\n\n\tif (intel_dmc_has_payload(i915)) {\n\t\tintel_dmc_load_program(i915);\n\t\tintel_dmc_runtime_pm_put(i915);\n\n\t\tdrm_info(&i915->drm, \"Finished loading DMC firmware %s (v%u.%u)\\n\",\n\t\t\t dmc->fw_path, DMC_VERSION_MAJOR(dmc->version),\n\t\t\t DMC_VERSION_MINOR(dmc->version));\n\t} else {\n\t\tdrm_notice(&i915->drm,\n\t\t\t   \"Failed to load DMC firmware %s.\"\n\t\t\t   \" Disabling runtime power management.\\n\",\n\t\t\t   dmc->fw_path);\n\t\tdrm_notice(&i915->drm, \"DMC firmware homepage: %s\",\n\t\t\t   INTEL_UC_FIRMWARE_URL);\n\t}\n\n\trelease_firmware(fw);\n}\n\n \nvoid intel_dmc_init(struct drm_i915_private *i915)\n{\n\tstruct intel_dmc *dmc;\n\n\tif (!HAS_DMC(i915))\n\t\treturn;\n\n\t \n\tintel_dmc_runtime_pm_get(i915);\n\n\tdmc = kzalloc(sizeof(*dmc), GFP_KERNEL);\n\tif (!dmc)\n\t\treturn;\n\n\tdmc->i915 = i915;\n\n\tINIT_WORK(&dmc->work, dmc_load_work_fn);\n\n\tif (IS_METEORLAKE(i915)) {\n\t\tdmc->fw_path = MTL_DMC_PATH;\n\t\tdmc->max_fw_size = XELPDP_DMC_MAX_FW_SIZE;\n\t} else if (IS_DG2(i915)) {\n\t\tdmc->fw_path = DG2_DMC_PATH;\n\t\tdmc->max_fw_size = DISPLAY_VER13_DMC_MAX_FW_SIZE;\n\t} else if (IS_ALDERLAKE_P(i915)) {\n\t\tdmc->fw_path = ADLP_DMC_PATH;\n\t\tdmc->max_fw_size = DISPLAY_VER13_DMC_MAX_FW_SIZE;\n\t} else if (IS_ALDERLAKE_S(i915)) {\n\t\tdmc->fw_path = ADLS_DMC_PATH;\n\t\tdmc->max_fw_size = DISPLAY_VER12_DMC_MAX_FW_SIZE;\n\t} else if (IS_DG1(i915)) {\n\t\tdmc->fw_path = DG1_DMC_PATH;\n\t\tdmc->max_fw_size = DISPLAY_VER12_DMC_MAX_FW_SIZE;\n\t} else if (IS_ROCKETLAKE(i915)) {\n\t\tdmc->fw_path = RKL_DMC_PATH;\n\t\tdmc->max_fw_size = DISPLAY_VER12_DMC_MAX_FW_SIZE;\n\t} else if (IS_TIGERLAKE(i915)) {\n\t\tdmc->fw_path = TGL_DMC_PATH;\n\t\tdmc->max_fw_size = DISPLAY_VER12_DMC_MAX_FW_SIZE;\n\t} else if (DISPLAY_VER(i915) == 11) {\n\t\tdmc->fw_path = ICL_DMC_PATH;\n\t\tdmc->max_fw_size = ICL_DMC_MAX_FW_SIZE;\n\t} else if (IS_GEMINILAKE(i915)) {\n\t\tdmc->fw_path = GLK_DMC_PATH;\n\t\tdmc->max_fw_size = GLK_DMC_MAX_FW_SIZE;\n\t} else if (IS_KABYLAKE(i915) ||\n\t\t   IS_COFFEELAKE(i915) ||\n\t\t   IS_COMETLAKE(i915)) {\n\t\tdmc->fw_path = KBL_DMC_PATH;\n\t\tdmc->max_fw_size = KBL_DMC_MAX_FW_SIZE;\n\t} else if (IS_SKYLAKE(i915)) {\n\t\tdmc->fw_path = SKL_DMC_PATH;\n\t\tdmc->max_fw_size = SKL_DMC_MAX_FW_SIZE;\n\t} else if (IS_BROXTON(i915)) {\n\t\tdmc->fw_path = BXT_DMC_PATH;\n\t\tdmc->max_fw_size = BXT_DMC_MAX_FW_SIZE;\n\t}\n\n\tif (i915->params.dmc_firmware_path) {\n\t\tif (strlen(i915->params.dmc_firmware_path) == 0) {\n\t\t\tdrm_info(&i915->drm,\n\t\t\t\t \"Disabling DMC firmware and runtime PM\\n\");\n\t\t\tgoto out;\n\t\t}\n\n\t\tdmc->fw_path = i915->params.dmc_firmware_path;\n\t}\n\n\tif (!dmc->fw_path) {\n\t\tdrm_dbg_kms(&i915->drm,\n\t\t\t    \"No known DMC firmware for platform, disabling runtime PM\\n\");\n\t\tgoto out;\n\t}\n\n\ti915->display.dmc.dmc = dmc;\n\n\tdrm_dbg_kms(&i915->drm, \"Loading %s\\n\", dmc->fw_path);\n\tqueue_work(i915->unordered_wq, &dmc->work);\n\n\treturn;\n\nout:\n\tkfree(dmc);\n}\n\n \nvoid intel_dmc_suspend(struct drm_i915_private *i915)\n{\n\tstruct intel_dmc *dmc = i915_to_dmc(i915);\n\n\tif (!HAS_DMC(i915))\n\t\treturn;\n\n\tif (dmc)\n\t\tflush_work(&dmc->work);\n\n\t \n\tif (!intel_dmc_has_payload(i915))\n\t\tintel_dmc_runtime_pm_put(i915);\n}\n\n \nvoid intel_dmc_resume(struct drm_i915_private *i915)\n{\n\tif (!HAS_DMC(i915))\n\t\treturn;\n\n\t \n\tif (!intel_dmc_has_payload(i915))\n\t\tintel_dmc_runtime_pm_get(i915);\n}\n\n \nvoid intel_dmc_fini(struct drm_i915_private *i915)\n{\n\tstruct intel_dmc *dmc = i915_to_dmc(i915);\n\tenum intel_dmc_id dmc_id;\n\n\tif (!HAS_DMC(i915))\n\t\treturn;\n\n\tintel_dmc_suspend(i915);\n\tdrm_WARN_ON(&i915->drm, i915->display.dmc.wakeref);\n\n\tif (dmc) {\n\t\tfor_each_dmc_id(dmc_id)\n\t\t\tkfree(dmc->dmc_info[dmc_id].payload);\n\n\t\tkfree(dmc);\n\t\ti915->display.dmc.dmc = NULL;\n\t}\n}\n\nvoid intel_dmc_print_error_state(struct drm_i915_error_state_buf *m,\n\t\t\t\t struct drm_i915_private *i915)\n{\n\tstruct intel_dmc *dmc = i915_to_dmc(i915);\n\n\tif (!HAS_DMC(i915))\n\t\treturn;\n\n\ti915_error_printf(m, \"DMC initialized: %s\\n\", str_yes_no(dmc));\n\ti915_error_printf(m, \"DMC loaded: %s\\n\",\n\t\t\t  str_yes_no(intel_dmc_has_payload(i915)));\n\tif (dmc)\n\t\ti915_error_printf(m, \"DMC fw version: %d.%d\\n\",\n\t\t\t\t  DMC_VERSION_MAJOR(dmc->version),\n\t\t\t\t  DMC_VERSION_MINOR(dmc->version));\n}\n\nstatic int intel_dmc_debugfs_status_show(struct seq_file *m, void *unused)\n{\n\tstruct drm_i915_private *i915 = m->private;\n\tstruct intel_dmc *dmc = i915_to_dmc(i915);\n\tintel_wakeref_t wakeref;\n\ti915_reg_t dc5_reg, dc6_reg = INVALID_MMIO_REG;\n\n\tif (!HAS_DMC(i915))\n\t\treturn -ENODEV;\n\n\twakeref = intel_runtime_pm_get(&i915->runtime_pm);\n\n\tseq_printf(m, \"DMC initialized: %s\\n\", str_yes_no(dmc));\n\tseq_printf(m, \"fw loaded: %s\\n\",\n\t\t   str_yes_no(intel_dmc_has_payload(i915)));\n\tseq_printf(m, \"path: %s\\n\", dmc ? dmc->fw_path : \"N/A\");\n\tseq_printf(m, \"Pipe A fw needed: %s\\n\",\n\t\t   str_yes_no(GRAPHICS_VER(i915) >= 12));\n\tseq_printf(m, \"Pipe A fw loaded: %s\\n\",\n\t\t   str_yes_no(has_dmc_id_fw(i915, DMC_FW_PIPEA)));\n\tseq_printf(m, \"Pipe B fw needed: %s\\n\",\n\t\t   str_yes_no(IS_ALDERLAKE_P(i915) ||\n\t\t\t      DISPLAY_VER(i915) >= 14));\n\tseq_printf(m, \"Pipe B fw loaded: %s\\n\",\n\t\t   str_yes_no(has_dmc_id_fw(i915, DMC_FW_PIPEB)));\n\n\tif (!intel_dmc_has_payload(i915))\n\t\tgoto out;\n\n\tseq_printf(m, \"version: %d.%d\\n\", DMC_VERSION_MAJOR(dmc->version),\n\t\t   DMC_VERSION_MINOR(dmc->version));\n\n\tif (DISPLAY_VER(i915) >= 12) {\n\t\ti915_reg_t dc3co_reg;\n\n\t\tif (IS_DGFX(i915) || DISPLAY_VER(i915) >= 14) {\n\t\t\tdc3co_reg = DG1_DMC_DEBUG3;\n\t\t\tdc5_reg = DG1_DMC_DEBUG_DC5_COUNT;\n\t\t} else {\n\t\t\tdc3co_reg = TGL_DMC_DEBUG3;\n\t\t\tdc5_reg = TGL_DMC_DEBUG_DC5_COUNT;\n\t\t\tdc6_reg = TGL_DMC_DEBUG_DC6_COUNT;\n\t\t}\n\n\t\tseq_printf(m, \"DC3CO count: %d\\n\",\n\t\t\t   intel_de_read(i915, dc3co_reg));\n\t} else {\n\t\tdc5_reg = IS_BROXTON(i915) ? BXT_DMC_DC3_DC5_COUNT :\n\t\t\tSKL_DMC_DC3_DC5_COUNT;\n\t\tif (!IS_GEMINILAKE(i915) && !IS_BROXTON(i915))\n\t\t\tdc6_reg = SKL_DMC_DC5_DC6_COUNT;\n\t}\n\n\tseq_printf(m, \"DC3 -> DC5 count: %d\\n\", intel_de_read(i915, dc5_reg));\n\tif (i915_mmio_reg_valid(dc6_reg))\n\t\tseq_printf(m, \"DC5 -> DC6 count: %d\\n\",\n\t\t\t   intel_de_read(i915, dc6_reg));\n\n\tseq_printf(m, \"program base: 0x%08x\\n\",\n\t\t   intel_de_read(i915, DMC_PROGRAM(dmc->dmc_info[DMC_FW_MAIN].start_mmioaddr, 0)));\n\nout:\n\tseq_printf(m, \"ssp base: 0x%08x\\n\",\n\t\t   intel_de_read(i915, DMC_SSP_BASE));\n\tseq_printf(m, \"htp: 0x%08x\\n\", intel_de_read(i915, DMC_HTP_SKL));\n\n\tintel_runtime_pm_put(&i915->runtime_pm, wakeref);\n\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(intel_dmc_debugfs_status);\n\nvoid intel_dmc_debugfs_register(struct drm_i915_private *i915)\n{\n\tstruct drm_minor *minor = i915->drm.primary;\n\n\tdebugfs_create_file(\"i915_dmc_info\", 0444, minor->debugfs_root,\n\t\t\t    i915, &intel_dmc_debugfs_status_fops);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}