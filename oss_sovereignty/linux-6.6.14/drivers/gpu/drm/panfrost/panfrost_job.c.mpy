{
  "module_name": "panfrost_job.c",
  "hash_id": "f037413cc5c059db70ae328b02d417a02be384d0d0a29e51d831493b08162265",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/panfrost/panfrost_job.c",
  "human_readable_source": "\n \n \n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/iopoll.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/dma-resv.h>\n#include <drm/gpu_scheduler.h>\n#include <drm/panfrost_drm.h>\n\n#include \"panfrost_device.h\"\n#include \"panfrost_devfreq.h\"\n#include \"panfrost_job.h\"\n#include \"panfrost_features.h\"\n#include \"panfrost_issues.h\"\n#include \"panfrost_gem.h\"\n#include \"panfrost_regs.h\"\n#include \"panfrost_gpu.h\"\n#include \"panfrost_mmu.h\"\n#include \"panfrost_dump.h\"\n\n#define JOB_TIMEOUT_MS 500\n\n#define job_write(dev, reg, data) writel(data, dev->iomem + (reg))\n#define job_read(dev, reg) readl(dev->iomem + (reg))\n\nstruct panfrost_queue_state {\n\tstruct drm_gpu_scheduler sched;\n\tu64 fence_context;\n\tu64 emit_seqno;\n};\n\nstruct panfrost_job_slot {\n\tstruct panfrost_queue_state queue[NUM_JOB_SLOTS];\n\tspinlock_t job_lock;\n\tint irq;\n};\n\nstatic struct panfrost_job *\nto_panfrost_job(struct drm_sched_job *sched_job)\n{\n\treturn container_of(sched_job, struct panfrost_job, base);\n}\n\nstruct panfrost_fence {\n\tstruct dma_fence base;\n\tstruct drm_device *dev;\n\t \n\tu64 seqno;\n\tint queue;\n};\n\nstatic inline struct panfrost_fence *\nto_panfrost_fence(struct dma_fence *fence)\n{\n\treturn (struct panfrost_fence *)fence;\n}\n\nstatic const char *panfrost_fence_get_driver_name(struct dma_fence *fence)\n{\n\treturn \"panfrost\";\n}\n\nstatic const char *panfrost_fence_get_timeline_name(struct dma_fence *fence)\n{\n\tstruct panfrost_fence *f = to_panfrost_fence(fence);\n\n\tswitch (f->queue) {\n\tcase 0:\n\t\treturn \"panfrost-js-0\";\n\tcase 1:\n\t\treturn \"panfrost-js-1\";\n\tcase 2:\n\t\treturn \"panfrost-js-2\";\n\tdefault:\n\t\treturn NULL;\n\t}\n}\n\nstatic const struct dma_fence_ops panfrost_fence_ops = {\n\t.get_driver_name = panfrost_fence_get_driver_name,\n\t.get_timeline_name = panfrost_fence_get_timeline_name,\n};\n\nstatic struct dma_fence *panfrost_fence_create(struct panfrost_device *pfdev, int js_num)\n{\n\tstruct panfrost_fence *fence;\n\tstruct panfrost_job_slot *js = pfdev->js;\n\n\tfence = kzalloc(sizeof(*fence), GFP_KERNEL);\n\tif (!fence)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfence->dev = pfdev->ddev;\n\tfence->queue = js_num;\n\tfence->seqno = ++js->queue[js_num].emit_seqno;\n\tdma_fence_init(&fence->base, &panfrost_fence_ops, &js->job_lock,\n\t\t       js->queue[js_num].fence_context, fence->seqno);\n\n\treturn &fence->base;\n}\n\nint panfrost_job_get_slot(struct panfrost_job *job)\n{\n\t \n\tif (job->requirements & PANFROST_JD_REQ_FS)\n\t\treturn 0;\n\n \n#if 0\n\tif (job->requirements & PANFROST_JD_REQ_ONLY_COMPUTE) {\n\t\tif ((job->requirements & PANFROST_JD_REQ_CORE_GRP_MASK) &&\n\t\t    (job->pfdev->features.nr_core_groups == 2))\n\t\t\treturn 2;\n\t\tif (panfrost_has_hw_issue(job->pfdev, HW_ISSUE_8987))\n\t\t\treturn 2;\n\t}\n#endif\n\treturn 1;\n}\n\nstatic void panfrost_job_write_affinity(struct panfrost_device *pfdev,\n\t\t\t\t\tu32 requirements,\n\t\t\t\t\tint js)\n{\n\tu64 affinity;\n\n\t \n\taffinity = pfdev->features.shader_present;\n\n\tjob_write(pfdev, JS_AFFINITY_NEXT_LO(js), lower_32_bits(affinity));\n\tjob_write(pfdev, JS_AFFINITY_NEXT_HI(js), upper_32_bits(affinity));\n}\n\nstatic u32\npanfrost_get_job_chain_flag(const struct panfrost_job *job)\n{\n\tstruct panfrost_fence *f = to_panfrost_fence(job->done_fence);\n\n\tif (!panfrost_has_hw_feature(job->pfdev, HW_FEATURE_JOBCHAIN_DISAMBIGUATION))\n\t\treturn 0;\n\n\treturn (f->seqno & 1) ? JS_CONFIG_JOB_CHAIN_FLAG : 0;\n}\n\nstatic struct panfrost_job *\npanfrost_dequeue_job(struct panfrost_device *pfdev, int slot)\n{\n\tstruct panfrost_job *job = pfdev->jobs[slot][0];\n\n\tWARN_ON(!job);\n\tpfdev->jobs[slot][0] = pfdev->jobs[slot][1];\n\tpfdev->jobs[slot][1] = NULL;\n\n\treturn job;\n}\n\nstatic unsigned int\npanfrost_enqueue_job(struct panfrost_device *pfdev, int slot,\n\t\t     struct panfrost_job *job)\n{\n\tif (WARN_ON(!job))\n\t\treturn 0;\n\n\tif (!pfdev->jobs[slot][0]) {\n\t\tpfdev->jobs[slot][0] = job;\n\t\treturn 0;\n\t}\n\n\tWARN_ON(pfdev->jobs[slot][1]);\n\tpfdev->jobs[slot][1] = job;\n\tWARN_ON(panfrost_get_job_chain_flag(job) ==\n\t\tpanfrost_get_job_chain_flag(pfdev->jobs[slot][0]));\n\treturn 1;\n}\n\nstatic void panfrost_job_hw_submit(struct panfrost_job *job, int js)\n{\n\tstruct panfrost_device *pfdev = job->pfdev;\n\tunsigned int subslot;\n\tu32 cfg;\n\tu64 jc_head = job->jc;\n\tint ret;\n\n\tpanfrost_devfreq_record_busy(&pfdev->pfdevfreq);\n\n\tret = pm_runtime_get_sync(pfdev->dev);\n\tif (ret < 0)\n\t\treturn;\n\n\tif (WARN_ON(job_read(pfdev, JS_COMMAND_NEXT(js)))) {\n\t\treturn;\n\t}\n\n\tcfg = panfrost_mmu_as_get(pfdev, job->mmu);\n\n\tjob_write(pfdev, JS_HEAD_NEXT_LO(js), lower_32_bits(jc_head));\n\tjob_write(pfdev, JS_HEAD_NEXT_HI(js), upper_32_bits(jc_head));\n\n\tpanfrost_job_write_affinity(pfdev, job->requirements, js);\n\n\t \n\tcfg |= JS_CONFIG_THREAD_PRI(8) |\n\t\tJS_CONFIG_START_FLUSH_CLEAN_INVALIDATE |\n\t\tJS_CONFIG_END_FLUSH_CLEAN_INVALIDATE |\n\t\tpanfrost_get_job_chain_flag(job);\n\n\tif (panfrost_has_hw_feature(pfdev, HW_FEATURE_FLUSH_REDUCTION))\n\t\tcfg |= JS_CONFIG_ENABLE_FLUSH_REDUCTION;\n\n\tif (panfrost_has_hw_issue(pfdev, HW_ISSUE_10649))\n\t\tcfg |= JS_CONFIG_START_MMU;\n\n\tjob_write(pfdev, JS_CONFIG_NEXT(js), cfg);\n\n\tif (panfrost_has_hw_feature(pfdev, HW_FEATURE_FLUSH_REDUCTION))\n\t\tjob_write(pfdev, JS_FLUSH_ID_NEXT(js), job->flush_id);\n\n\t \n\n\tspin_lock(&pfdev->js->job_lock);\n\tsubslot = panfrost_enqueue_job(pfdev, js, job);\n\t \n\tif (!atomic_read(&pfdev->reset.pending)) {\n\t\tjob_write(pfdev, JS_COMMAND_NEXT(js), JS_COMMAND_START);\n\t\tdev_dbg(pfdev->dev,\n\t\t\t\"JS: Submitting atom %p to js[%d][%d] with head=0x%llx AS %d\",\n\t\t\tjob, js, subslot, jc_head, cfg & 0xf);\n\t}\n\tspin_unlock(&pfdev->js->job_lock);\n}\n\nstatic int panfrost_acquire_object_fences(struct drm_gem_object **bos,\n\t\t\t\t\t  int bo_count,\n\t\t\t\t\t  struct drm_sched_job *job)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < bo_count; i++) {\n\t\tret = dma_resv_reserve_fences(bos[i]->resv, 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\tret = drm_sched_job_add_implicit_dependencies(job, bos[i],\n\t\t\t\t\t\t\t      true);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void panfrost_attach_object_fences(struct drm_gem_object **bos,\n\t\t\t\t\t  int bo_count,\n\t\t\t\t\t  struct dma_fence *fence)\n{\n\tint i;\n\n\tfor (i = 0; i < bo_count; i++)\n\t\tdma_resv_add_fence(bos[i]->resv, fence, DMA_RESV_USAGE_WRITE);\n}\n\nint panfrost_job_push(struct panfrost_job *job)\n{\n\tstruct panfrost_device *pfdev = job->pfdev;\n\tstruct ww_acquire_ctx acquire_ctx;\n\tint ret = 0;\n\n\tret = drm_gem_lock_reservations(job->bos, job->bo_count,\n\t\t\t\t\t    &acquire_ctx);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&pfdev->sched_lock);\n\tdrm_sched_job_arm(&job->base);\n\n\tjob->render_done_fence = dma_fence_get(&job->base.s_fence->finished);\n\n\tret = panfrost_acquire_object_fences(job->bos, job->bo_count,\n\t\t\t\t\t     &job->base);\n\tif (ret) {\n\t\tmutex_unlock(&pfdev->sched_lock);\n\t\tgoto unlock;\n\t}\n\n\tkref_get(&job->refcount);  \n\n\tdrm_sched_entity_push_job(&job->base);\n\n\tmutex_unlock(&pfdev->sched_lock);\n\n\tpanfrost_attach_object_fences(job->bos, job->bo_count,\n\t\t\t\t      job->render_done_fence);\n\nunlock:\n\tdrm_gem_unlock_reservations(job->bos, job->bo_count, &acquire_ctx);\n\n\treturn ret;\n}\n\nstatic void panfrost_job_cleanup(struct kref *ref)\n{\n\tstruct panfrost_job *job = container_of(ref, struct panfrost_job,\n\t\t\t\t\t\trefcount);\n\tunsigned int i;\n\n\tdma_fence_put(job->done_fence);\n\tdma_fence_put(job->render_done_fence);\n\n\tif (job->mappings) {\n\t\tfor (i = 0; i < job->bo_count; i++) {\n\t\t\tif (!job->mappings[i])\n\t\t\t\tbreak;\n\n\t\t\tatomic_dec(&job->mappings[i]->obj->gpu_usecount);\n\t\t\tpanfrost_gem_mapping_put(job->mappings[i]);\n\t\t}\n\t\tkvfree(job->mappings);\n\t}\n\n\tif (job->bos) {\n\t\tfor (i = 0; i < job->bo_count; i++)\n\t\t\tdrm_gem_object_put(job->bos[i]);\n\n\t\tkvfree(job->bos);\n\t}\n\n\tkfree(job);\n}\n\nvoid panfrost_job_put(struct panfrost_job *job)\n{\n\tkref_put(&job->refcount, panfrost_job_cleanup);\n}\n\nstatic void panfrost_job_free(struct drm_sched_job *sched_job)\n{\n\tstruct panfrost_job *job = to_panfrost_job(sched_job);\n\n\tdrm_sched_job_cleanup(sched_job);\n\n\tpanfrost_job_put(job);\n}\n\nstatic struct dma_fence *panfrost_job_run(struct drm_sched_job *sched_job)\n{\n\tstruct panfrost_job *job = to_panfrost_job(sched_job);\n\tstruct panfrost_device *pfdev = job->pfdev;\n\tint slot = panfrost_job_get_slot(job);\n\tstruct dma_fence *fence = NULL;\n\n\tif (unlikely(job->base.s_fence->finished.error))\n\t\treturn NULL;\n\n\t \n\tif (!job->jc)\n\t\treturn NULL;\n\n\tfence = panfrost_fence_create(pfdev, slot);\n\tif (IS_ERR(fence))\n\t\treturn fence;\n\n\tif (job->done_fence)\n\t\tdma_fence_put(job->done_fence);\n\tjob->done_fence = dma_fence_get(fence);\n\n\tpanfrost_job_hw_submit(job, slot);\n\n\treturn fence;\n}\n\nvoid panfrost_job_enable_interrupts(struct panfrost_device *pfdev)\n{\n\tint j;\n\tu32 irq_mask = 0;\n\n\tfor (j = 0; j < NUM_JOB_SLOTS; j++) {\n\t\tirq_mask |= MK_JS_MASK(j);\n\t}\n\n\tjob_write(pfdev, JOB_INT_CLEAR, irq_mask);\n\tjob_write(pfdev, JOB_INT_MASK, irq_mask);\n}\n\nstatic void panfrost_job_handle_err(struct panfrost_device *pfdev,\n\t\t\t\t    struct panfrost_job *job,\n\t\t\t\t    unsigned int js)\n{\n\tu32 js_status = job_read(pfdev, JS_STATUS(js));\n\tconst char *exception_name = panfrost_exception_name(js_status);\n\tbool signal_fence = true;\n\n\tif (!panfrost_exception_is_fault(js_status)) {\n\t\tdev_dbg(pfdev->dev, \"js event, js=%d, status=%s, head=0x%x, tail=0x%x\",\n\t\t\tjs, exception_name,\n\t\t\tjob_read(pfdev, JS_HEAD_LO(js)),\n\t\t\tjob_read(pfdev, JS_TAIL_LO(js)));\n\t} else {\n\t\tdev_err(pfdev->dev, \"js fault, js=%d, status=%s, head=0x%x, tail=0x%x\",\n\t\t\tjs, exception_name,\n\t\t\tjob_read(pfdev, JS_HEAD_LO(js)),\n\t\t\tjob_read(pfdev, JS_TAIL_LO(js)));\n\t}\n\n\tif (js_status == DRM_PANFROST_EXCEPTION_STOPPED) {\n\t\t \n\t\tjob->jc = job_read(pfdev, JS_TAIL_LO(js)) |\n\t\t\t  ((u64)job_read(pfdev, JS_TAIL_HI(js)) << 32);\n\n\t\t \n\t\tsignal_fence = false;\n\t} else if (js_status == DRM_PANFROST_EXCEPTION_TERMINATED) {\n\t\t \n\t\tdma_fence_set_error(job->done_fence, -ECANCELED);\n\t\tjob->jc = 0;\n\t} else if (panfrost_exception_is_fault(js_status)) {\n\t\t \n\t\tdma_fence_set_error(job->done_fence, -EINVAL);\n\t\tjob->jc = 0;\n\t}\n\n\tpanfrost_mmu_as_put(pfdev, job->mmu);\n\tpanfrost_devfreq_record_idle(&pfdev->pfdevfreq);\n\n\tif (signal_fence)\n\t\tdma_fence_signal_locked(job->done_fence);\n\n\tpm_runtime_put_autosuspend(pfdev->dev);\n\n\tif (panfrost_exception_needs_reset(pfdev, js_status)) {\n\t\tatomic_set(&pfdev->reset.pending, 1);\n\t\tdrm_sched_fault(&pfdev->js->queue[js].sched);\n\t}\n}\n\nstatic void panfrost_job_handle_done(struct panfrost_device *pfdev,\n\t\t\t\t     struct panfrost_job *job)\n{\n\t \n\tjob->jc = 0;\n\tpanfrost_mmu_as_put(pfdev, job->mmu);\n\tpanfrost_devfreq_record_idle(&pfdev->pfdevfreq);\n\n\tdma_fence_signal_locked(job->done_fence);\n\tpm_runtime_put_autosuspend(pfdev->dev);\n}\n\nstatic void panfrost_job_handle_irq(struct panfrost_device *pfdev, u32 status)\n{\n\tstruct panfrost_job *done[NUM_JOB_SLOTS][2] = {};\n\tstruct panfrost_job *failed[NUM_JOB_SLOTS] = {};\n\tu32 js_state = 0, js_events = 0;\n\tunsigned int i, j;\n\n\t \n\twhile (status) {\n\t\tu32 js_state_mask = 0;\n\n\t\tfor (j = 0; j < NUM_JOB_SLOTS; j++) {\n\t\t\tif (status & MK_JS_MASK(j))\n\t\t\t\tjs_state_mask |= MK_JS_MASK(j);\n\n\t\t\tif (status & JOB_INT_MASK_DONE(j)) {\n\t\t\t\tif (done[j][0])\n\t\t\t\t\tdone[j][1] = panfrost_dequeue_job(pfdev, j);\n\t\t\t\telse\n\t\t\t\t\tdone[j][0] = panfrost_dequeue_job(pfdev, j);\n\t\t\t}\n\n\t\t\tif (status & JOB_INT_MASK_ERR(j)) {\n\t\t\t\t \n\t\t\t\tjob_write(pfdev, JS_COMMAND_NEXT(j), JS_COMMAND_NOP);\n\t\t\t\tfailed[j] = panfrost_dequeue_job(pfdev, j);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tjob_write(pfdev, JOB_INT_CLEAR, status);\n\t\tjs_state &= ~js_state_mask;\n\t\tjs_state |= job_read(pfdev, JOB_INT_JS_STATE) & js_state_mask;\n\t\tjs_events |= status;\n\t\tstatus = job_read(pfdev, JOB_INT_RAWSTAT);\n\t}\n\n\t \n\tfor (j = 0; j < NUM_JOB_SLOTS; j++) {\n\t\tif (!(js_events & MK_JS_MASK(j)))\n\t\t\tcontinue;\n\n\t\tif (failed[j]) {\n\t\t\tpanfrost_job_handle_err(pfdev, failed[j], j);\n\t\t} else if (pfdev->jobs[j][0] && !(js_state & MK_JS_MASK(j))) {\n\t\t\t \n\t\t\tif (WARN_ON(!done[j][0]))\n\t\t\t\tdone[j][0] = panfrost_dequeue_job(pfdev, j);\n\t\t\telse\n\t\t\t\tdone[j][1] = panfrost_dequeue_job(pfdev, j);\n\t\t}\n\n\t\tfor (i = 0; i < ARRAY_SIZE(done[0]) && done[j][i]; i++)\n\t\t\tpanfrost_job_handle_done(pfdev, done[j][i]);\n\t}\n\n\t \n\tfor (j = 0; j < NUM_JOB_SLOTS; j++) {\n\t\tif (!(js_events & MK_JS_MASK(j)))\n\t\t\tcontinue;\n\n\t\tif (!failed[j] || !pfdev->jobs[j][0])\n\t\t\tcontinue;\n\n\t\tif (pfdev->jobs[j][0]->jc == 0) {\n\t\t\t \n\t\t\tstruct panfrost_job *canceled = panfrost_dequeue_job(pfdev, j);\n\n\t\t\tdma_fence_set_error(canceled->done_fence, -ECANCELED);\n\t\t\tpanfrost_job_handle_done(pfdev, canceled);\n\t\t} else if (!atomic_read(&pfdev->reset.pending)) {\n\t\t\t \n\t\t\tjob_write(pfdev, JS_COMMAND_NEXT(j), JS_COMMAND_START);\n\t\t}\n\t}\n}\n\nstatic void panfrost_job_handle_irqs(struct panfrost_device *pfdev)\n{\n\tu32 status = job_read(pfdev, JOB_INT_RAWSTAT);\n\n\twhile (status) {\n\t\tpm_runtime_mark_last_busy(pfdev->dev);\n\n\t\tspin_lock(&pfdev->js->job_lock);\n\t\tpanfrost_job_handle_irq(pfdev, status);\n\t\tspin_unlock(&pfdev->js->job_lock);\n\t\tstatus = job_read(pfdev, JOB_INT_RAWSTAT);\n\t}\n}\n\nstatic u32 panfrost_active_slots(struct panfrost_device *pfdev,\n\t\t\t\t u32 *js_state_mask, u32 js_state)\n{\n\tu32 rawstat;\n\n\tif (!(js_state & *js_state_mask))\n\t\treturn 0;\n\n\trawstat = job_read(pfdev, JOB_INT_RAWSTAT);\n\tif (rawstat) {\n\t\tunsigned int i;\n\n\t\tfor (i = 0; i < NUM_JOB_SLOTS; i++) {\n\t\t\tif (rawstat & MK_JS_MASK(i))\n\t\t\t\t*js_state_mask &= ~MK_JS_MASK(i);\n\t\t}\n\t}\n\n\treturn js_state & *js_state_mask;\n}\n\nstatic void\npanfrost_reset(struct panfrost_device *pfdev,\n\t       struct drm_sched_job *bad)\n{\n\tu32 js_state, js_state_mask = 0xffffffff;\n\tunsigned int i, j;\n\tbool cookie;\n\tint ret;\n\n\tif (!atomic_read(&pfdev->reset.pending))\n\t\treturn;\n\n\t \n\tfor (i = 0; i < NUM_JOB_SLOTS; i++)\n\t\tdrm_sched_stop(&pfdev->js->queue[i].sched, bad);\n\n\tcookie = dma_fence_begin_signalling();\n\n\tif (bad)\n\t\tdrm_sched_increase_karma(bad);\n\n\t \n\tjob_write(pfdev, JOB_INT_MASK, 0);\n\tsynchronize_irq(pfdev->js->irq);\n\n\tfor (i = 0; i < NUM_JOB_SLOTS; i++) {\n\t\t \n\t\tjob_write(pfdev, JS_COMMAND_NEXT(i), JS_COMMAND_NOP);\n\t\tjob_write(pfdev, JS_COMMAND(i), JS_COMMAND_SOFT_STOP);\n\t}\n\n\t \n\tret = readl_poll_timeout(pfdev->iomem + JOB_INT_JS_STATE, js_state,\n\t\t\t\t !panfrost_active_slots(pfdev, &js_state_mask, js_state),\n\t\t\t\t 10, 10000);\n\n\tif (ret)\n\t\tdev_err(pfdev->dev, \"Soft-stop failed\\n\");\n\n\t \n\tpanfrost_job_handle_irqs(pfdev);\n\n\t \n\tspin_lock(&pfdev->js->job_lock);\n\tfor (i = 0; i < NUM_JOB_SLOTS; i++) {\n\t\tfor (j = 0; j < ARRAY_SIZE(pfdev->jobs[0]) && pfdev->jobs[i][j]; j++) {\n\t\t\tpm_runtime_put_noidle(pfdev->dev);\n\t\t\tpanfrost_devfreq_record_idle(&pfdev->pfdevfreq);\n\t\t}\n\t}\n\tmemset(pfdev->jobs, 0, sizeof(pfdev->jobs));\n\tspin_unlock(&pfdev->js->job_lock);\n\n\t \n\tpanfrost_device_reset(pfdev);\n\n\t \n\tjob_write(pfdev, JOB_INT_MASK, 0);\n\n\t \n\tatomic_set(&pfdev->reset.pending, 0);\n\n\t \n\tdma_fence_end_signalling(cookie);\n\tfor (i = 0; i < NUM_JOB_SLOTS; i++)\n\t\tdrm_sched_resubmit_jobs(&pfdev->js->queue[i].sched);\n\tcookie = dma_fence_begin_signalling();\n\n\t \n\tfor (i = 0; i < NUM_JOB_SLOTS; i++)\n\t\tdrm_sched_start(&pfdev->js->queue[i].sched, true);\n\n\t \n\tjob_write(pfdev, JOB_INT_MASK,\n\t\t  GENMASK(16 + NUM_JOB_SLOTS - 1, 16) |\n\t\t  GENMASK(NUM_JOB_SLOTS - 1, 0));\n\n\tdma_fence_end_signalling(cookie);\n}\n\nstatic enum drm_gpu_sched_stat panfrost_job_timedout(struct drm_sched_job\n\t\t\t\t\t\t     *sched_job)\n{\n\tstruct panfrost_job *job = to_panfrost_job(sched_job);\n\tstruct panfrost_device *pfdev = job->pfdev;\n\tint js = panfrost_job_get_slot(job);\n\n\t \n\tif (dma_fence_is_signaled(job->done_fence))\n\t\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n\n\t \n\tsynchronize_irq(pfdev->js->irq);\n\n\tif (dma_fence_is_signaled(job->done_fence)) {\n\t\tdev_warn(pfdev->dev, \"unexpectedly high interrupt latency\\n\");\n\t\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n\t}\n\n\tdev_err(pfdev->dev, \"gpu sched timeout, js=%d, config=0x%x, status=0x%x, head=0x%x, tail=0x%x, sched_job=%p\",\n\t\tjs,\n\t\tjob_read(pfdev, JS_CONFIG(js)),\n\t\tjob_read(pfdev, JS_STATUS(js)),\n\t\tjob_read(pfdev, JS_HEAD_LO(js)),\n\t\tjob_read(pfdev, JS_TAIL_LO(js)),\n\t\tsched_job);\n\n\tpanfrost_core_dump(job);\n\n\tatomic_set(&pfdev->reset.pending, 1);\n\tpanfrost_reset(pfdev, sched_job);\n\n\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n}\n\nstatic void panfrost_reset_work(struct work_struct *work)\n{\n\tstruct panfrost_device *pfdev;\n\n\tpfdev = container_of(work, struct panfrost_device, reset.work);\n\tpanfrost_reset(pfdev, NULL);\n}\n\nstatic const struct drm_sched_backend_ops panfrost_sched_ops = {\n\t.run_job = panfrost_job_run,\n\t.timedout_job = panfrost_job_timedout,\n\t.free_job = panfrost_job_free\n};\n\nstatic irqreturn_t panfrost_job_irq_handler_thread(int irq, void *data)\n{\n\tstruct panfrost_device *pfdev = data;\n\n\tpanfrost_job_handle_irqs(pfdev);\n\tjob_write(pfdev, JOB_INT_MASK,\n\t\t  GENMASK(16 + NUM_JOB_SLOTS - 1, 16) |\n\t\t  GENMASK(NUM_JOB_SLOTS - 1, 0));\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t panfrost_job_irq_handler(int irq, void *data)\n{\n\tstruct panfrost_device *pfdev = data;\n\tu32 status = job_read(pfdev, JOB_INT_STAT);\n\n\tif (!status)\n\t\treturn IRQ_NONE;\n\n\tjob_write(pfdev, JOB_INT_MASK, 0);\n\treturn IRQ_WAKE_THREAD;\n}\n\nint panfrost_job_init(struct panfrost_device *pfdev)\n{\n\tstruct panfrost_job_slot *js;\n\tunsigned int nentries = 2;\n\tint ret, j;\n\n\t \n\tif (!panfrost_has_hw_feature(pfdev, HW_FEATURE_JOBCHAIN_DISAMBIGUATION))\n\t\tnentries = 1;\n\n\tpfdev->js = js = devm_kzalloc(pfdev->dev, sizeof(*js), GFP_KERNEL);\n\tif (!js)\n\t\treturn -ENOMEM;\n\n\tINIT_WORK(&pfdev->reset.work, panfrost_reset_work);\n\tspin_lock_init(&js->job_lock);\n\n\tjs->irq = platform_get_irq_byname(to_platform_device(pfdev->dev), \"job\");\n\tif (js->irq <= 0)\n\t\treturn -ENODEV;\n\n\tret = devm_request_threaded_irq(pfdev->dev, js->irq,\n\t\t\t\t\tpanfrost_job_irq_handler,\n\t\t\t\t\tpanfrost_job_irq_handler_thread,\n\t\t\t\t\tIRQF_SHARED, KBUILD_MODNAME \"-job\",\n\t\t\t\t\tpfdev);\n\tif (ret) {\n\t\tdev_err(pfdev->dev, \"failed to request job irq\");\n\t\treturn ret;\n\t}\n\n\tpfdev->reset.wq = alloc_ordered_workqueue(\"panfrost-reset\", 0);\n\tif (!pfdev->reset.wq)\n\t\treturn -ENOMEM;\n\n\tfor (j = 0; j < NUM_JOB_SLOTS; j++) {\n\t\tjs->queue[j].fence_context = dma_fence_context_alloc(1);\n\n\t\tret = drm_sched_init(&js->queue[j].sched,\n\t\t\t\t     &panfrost_sched_ops,\n\t\t\t\t     nentries, 0,\n\t\t\t\t     msecs_to_jiffies(JOB_TIMEOUT_MS),\n\t\t\t\t     pfdev->reset.wq,\n\t\t\t\t     NULL, \"pan_js\", pfdev->dev);\n\t\tif (ret) {\n\t\t\tdev_err(pfdev->dev, \"Failed to create scheduler: %d.\", ret);\n\t\t\tgoto err_sched;\n\t\t}\n\t}\n\n\tpanfrost_job_enable_interrupts(pfdev);\n\n\treturn 0;\n\nerr_sched:\n\tfor (j--; j >= 0; j--)\n\t\tdrm_sched_fini(&js->queue[j].sched);\n\n\tdestroy_workqueue(pfdev->reset.wq);\n\treturn ret;\n}\n\nvoid panfrost_job_fini(struct panfrost_device *pfdev)\n{\n\tstruct panfrost_job_slot *js = pfdev->js;\n\tint j;\n\n\tjob_write(pfdev, JOB_INT_MASK, 0);\n\n\tfor (j = 0; j < NUM_JOB_SLOTS; j++) {\n\t\tdrm_sched_fini(&js->queue[j].sched);\n\t}\n\n\tcancel_work_sync(&pfdev->reset.work);\n\tdestroy_workqueue(pfdev->reset.wq);\n}\n\nint panfrost_job_open(struct panfrost_file_priv *panfrost_priv)\n{\n\tstruct panfrost_device *pfdev = panfrost_priv->pfdev;\n\tstruct panfrost_job_slot *js = pfdev->js;\n\tstruct drm_gpu_scheduler *sched;\n\tint ret, i;\n\n\tfor (i = 0; i < NUM_JOB_SLOTS; i++) {\n\t\tsched = &js->queue[i].sched;\n\t\tret = drm_sched_entity_init(&panfrost_priv->sched_entity[i],\n\t\t\t\t\t    DRM_SCHED_PRIORITY_NORMAL, &sched,\n\t\t\t\t\t    1, NULL);\n\t\tif (WARN_ON(ret))\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nvoid panfrost_job_close(struct panfrost_file_priv *panfrost_priv)\n{\n\tstruct panfrost_device *pfdev = panfrost_priv->pfdev;\n\tint i;\n\n\tfor (i = 0; i < NUM_JOB_SLOTS; i++)\n\t\tdrm_sched_entity_destroy(&panfrost_priv->sched_entity[i]);\n\n\t \n\tspin_lock(&pfdev->js->job_lock);\n\tfor (i = 0; i < NUM_JOB_SLOTS; i++) {\n\t\tstruct drm_sched_entity *entity = &panfrost_priv->sched_entity[i];\n\t\tint j;\n\n\t\tfor (j = ARRAY_SIZE(pfdev->jobs[0]) - 1; j >= 0; j--) {\n\t\t\tstruct panfrost_job *job = pfdev->jobs[i][j];\n\t\t\tu32 cmd;\n\n\t\t\tif (!job || job->base.entity != entity)\n\t\t\t\tcontinue;\n\n\t\t\tif (j == 1) {\n\t\t\t\t \n\t\t\t\tjob_write(pfdev, JS_COMMAND_NEXT(i), JS_COMMAND_NOP);\n\t\t\t\t \n\t\t\t\tjob->jc = 0;\n\t\t\t}\n\n\t\t\tif (panfrost_has_hw_feature(pfdev, HW_FEATURE_JOBCHAIN_DISAMBIGUATION)) {\n\t\t\t\tcmd = panfrost_get_job_chain_flag(job) ?\n\t\t\t\t      JS_COMMAND_HARD_STOP_1 :\n\t\t\t\t      JS_COMMAND_HARD_STOP_0;\n\t\t\t} else {\n\t\t\t\tcmd = JS_COMMAND_HARD_STOP;\n\t\t\t}\n\n\t\t\tjob_write(pfdev, JS_COMMAND(i), cmd);\n\t\t}\n\t}\n\tspin_unlock(&pfdev->js->job_lock);\n}\n\nint panfrost_job_is_idle(struct panfrost_device *pfdev)\n{\n\tstruct panfrost_job_slot *js = pfdev->js;\n\tint i;\n\n\tfor (i = 0; i < NUM_JOB_SLOTS; i++) {\n\t\t \n\t\tif (atomic_read(&js->queue[i].sched.hw_rq_count))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}