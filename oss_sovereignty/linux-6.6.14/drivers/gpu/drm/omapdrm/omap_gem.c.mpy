{
  "module_name": "omap_gem.c",
  "hash_id": "a8cc32a8701e6a5921ed73039b8ac29d40b8af78917ac22bcbed16de1c688b4c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/omapdrm/omap_gem.c",
  "human_readable_source": "\n \n\n#include <linux/dma-mapping.h>\n#include <linux/seq_file.h>\n#include <linux/shmem_fs.h>\n#include <linux/spinlock.h>\n#include <linux/pfn_t.h>\n\n#include <drm/drm_prime.h>\n#include <drm/drm_vma_manager.h>\n\n#include \"omap_drv.h\"\n#include \"omap_dmm_tiler.h\"\n\n \n\n \n#define OMAP_BO_MEM_DMA_API\t0x01000000\t \n#define OMAP_BO_MEM_SHMEM\t0x02000000\t \n#define OMAP_BO_MEM_DMABUF\t0x08000000\t \n\nstruct omap_gem_object {\n\tstruct drm_gem_object base;\n\n\tstruct list_head mm_list;\n\n\tu32 flags;\n\n\t \n\tu16 width, height;\n\n\t \n\tu32 roll;\n\n\t \n\tstruct mutex lock;\n\n\t \n\tdma_addr_t dma_addr;\n\n\t \n\trefcount_t pin_cnt;\n\n\t \n\tstruct sg_table *sgt;\n\n\t \n\tstruct tiler_block *block;\n\n\t \n\tstruct page **pages;\n\n\t \n\tdma_addr_t *dma_addrs;\n\n\t \n\tvoid *vaddr;\n};\n\n#define to_omap_bo(x) container_of(x, struct omap_gem_object, base)\n\n \n#define NUM_USERGART_ENTRIES 2\nstruct omap_drm_usergart_entry {\n\tstruct tiler_block *block;\t \n\tdma_addr_t dma_addr;\n\tstruct drm_gem_object *obj;\t \n\tpgoff_t obj_pgoff;\t\t \n};\n\nstruct omap_drm_usergart {\n\tstruct omap_drm_usergart_entry entry[NUM_USERGART_ENTRIES];\n\tint height;\t\t\t\t \n\tint height_shift;\t\t \n\tint slot_shift;\t\t\t \n\tint stride_pfn;\t\t\t \n\tint last;\t\t\t\t \n};\n\n \n\n \nu64 omap_gem_mmap_offset(struct drm_gem_object *obj)\n{\n\tstruct drm_device *dev = obj->dev;\n\tint ret;\n\tsize_t size;\n\n\t \n\tsize = omap_gem_mmap_size(obj);\n\tret = drm_gem_create_mmap_offset_size(obj, size);\n\tif (ret) {\n\t\tdev_err(dev->dev, \"could not allocate mmap offset\\n\");\n\t\treturn 0;\n\t}\n\n\treturn drm_vma_node_offset_addr(&obj->vma_node);\n}\n\nstatic bool omap_gem_is_contiguous(struct omap_gem_object *omap_obj)\n{\n\tif (omap_obj->flags & OMAP_BO_MEM_DMA_API)\n\t\treturn true;\n\n\tif ((omap_obj->flags & OMAP_BO_MEM_DMABUF) && omap_obj->sgt->nents == 1)\n\t\treturn true;\n\n\treturn false;\n}\n\n \n\nstatic void omap_gem_evict_entry(struct drm_gem_object *obj,\n\t\tenum tiler_fmt fmt, struct omap_drm_usergart_entry *entry)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tstruct omap_drm_private *priv = obj->dev->dev_private;\n\tint n = priv->usergart[fmt].height;\n\tsize_t size = PAGE_SIZE * n;\n\tloff_t off = omap_gem_mmap_offset(obj) +\n\t\t\t(entry->obj_pgoff << PAGE_SHIFT);\n\tconst int m = DIV_ROUND_UP(omap_obj->width << fmt, PAGE_SIZE);\n\n\tif (m > 1) {\n\t\tint i;\n\t\t \n\t\tfor (i = n; i > 0; i--) {\n\t\t\tunmap_mapping_range(obj->dev->anon_inode->i_mapping,\n\t\t\t\t\t    off, PAGE_SIZE, 1);\n\t\t\toff += PAGE_SIZE * m;\n\t\t}\n\t} else {\n\t\tunmap_mapping_range(obj->dev->anon_inode->i_mapping,\n\t\t\t\t    off, size, 1);\n\t}\n\n\tentry->obj = NULL;\n}\n\n \nstatic void omap_gem_evict(struct drm_gem_object *obj)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tstruct omap_drm_private *priv = obj->dev->dev_private;\n\n\tif (omap_obj->flags & OMAP_BO_TILED_MASK) {\n\t\tenum tiler_fmt fmt = gem2fmt(omap_obj->flags);\n\t\tint i;\n\n\t\tfor (i = 0; i < NUM_USERGART_ENTRIES; i++) {\n\t\t\tstruct omap_drm_usergart_entry *entry =\n\t\t\t\t&priv->usergart[fmt].entry[i];\n\n\t\t\tif (entry->obj == obj)\n\t\t\t\tomap_gem_evict_entry(obj, fmt, entry);\n\t\t}\n\t}\n}\n\n \n\n \nstatic int omap_gem_attach_pages(struct drm_gem_object *obj)\n{\n\tstruct drm_device *dev = obj->dev;\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tstruct page **pages;\n\tint npages = obj->size >> PAGE_SHIFT;\n\tint i, ret;\n\tdma_addr_t *addrs;\n\n\tlockdep_assert_held(&omap_obj->lock);\n\n\t \n\tif (!(omap_obj->flags & OMAP_BO_MEM_SHMEM) || omap_obj->pages)\n\t\treturn 0;\n\n\tpages = drm_gem_get_pages(obj);\n\tif (IS_ERR(pages)) {\n\t\tdev_err(obj->dev->dev, \"could not get pages: %ld\\n\", PTR_ERR(pages));\n\t\treturn PTR_ERR(pages);\n\t}\n\n\t \n\tif (omap_obj->flags & (OMAP_BO_WC|OMAP_BO_UNCACHED)) {\n\t\taddrs = kmalloc_array(npages, sizeof(*addrs), GFP_KERNEL);\n\t\tif (!addrs) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto free_pages;\n\t\t}\n\n\t\tfor (i = 0; i < npages; i++) {\n\t\t\taddrs[i] = dma_map_page(dev->dev, pages[i],\n\t\t\t\t\t0, PAGE_SIZE, DMA_TO_DEVICE);\n\n\t\t\tif (dma_mapping_error(dev->dev, addrs[i])) {\n\t\t\t\tdev_warn(dev->dev,\n\t\t\t\t\t\"%s: failed to map page\\n\", __func__);\n\n\t\t\t\tfor (i = i - 1; i >= 0; --i) {\n\t\t\t\t\tdma_unmap_page(dev->dev, addrs[i],\n\t\t\t\t\t\tPAGE_SIZE, DMA_TO_DEVICE);\n\t\t\t\t}\n\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto free_addrs;\n\t\t\t}\n\t\t}\n\t} else {\n\t\taddrs = kcalloc(npages, sizeof(*addrs), GFP_KERNEL);\n\t\tif (!addrs) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto free_pages;\n\t\t}\n\t}\n\n\tomap_obj->dma_addrs = addrs;\n\tomap_obj->pages = pages;\n\n\treturn 0;\n\nfree_addrs:\n\tkfree(addrs);\nfree_pages:\n\tdrm_gem_put_pages(obj, pages, true, false);\n\n\treturn ret;\n}\n\n \nstatic void omap_gem_detach_pages(struct drm_gem_object *obj)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tunsigned int npages = obj->size >> PAGE_SHIFT;\n\tunsigned int i;\n\n\tlockdep_assert_held(&omap_obj->lock);\n\n\tfor (i = 0; i < npages; i++) {\n\t\tif (omap_obj->dma_addrs[i])\n\t\t\tdma_unmap_page(obj->dev->dev, omap_obj->dma_addrs[i],\n\t\t\t\t       PAGE_SIZE, DMA_TO_DEVICE);\n\t}\n\n\tkfree(omap_obj->dma_addrs);\n\tomap_obj->dma_addrs = NULL;\n\n\tdrm_gem_put_pages(obj, omap_obj->pages, true, false);\n\tomap_obj->pages = NULL;\n}\n\n \nu32 omap_gem_flags(struct drm_gem_object *obj)\n{\n\treturn to_omap_bo(obj)->flags;\n}\n\n \nsize_t omap_gem_mmap_size(struct drm_gem_object *obj)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tsize_t size = obj->size;\n\n\tif (omap_obj->flags & OMAP_BO_TILED_MASK) {\n\t\t \n\t\tsize = tiler_vsize(gem2fmt(omap_obj->flags),\n\t\t\t\tomap_obj->width, omap_obj->height);\n\t}\n\n\treturn size;\n}\n\n \n\n \nstatic vm_fault_t omap_gem_fault_1d(struct drm_gem_object *obj,\n\t\tstruct vm_area_struct *vma, struct vm_fault *vmf)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tunsigned long pfn;\n\tpgoff_t pgoff;\n\n\t \n\tpgoff = (vmf->address - vma->vm_start) >> PAGE_SHIFT;\n\n\tif (omap_obj->pages) {\n\t\tomap_gem_cpu_sync_page(obj, pgoff);\n\t\tpfn = page_to_pfn(omap_obj->pages[pgoff]);\n\t} else {\n\t\tBUG_ON(!omap_gem_is_contiguous(omap_obj));\n\t\tpfn = (omap_obj->dma_addr >> PAGE_SHIFT) + pgoff;\n\t}\n\n\tVERB(\"Inserting %p pfn %lx, pa %lx\", (void *)vmf->address,\n\t\t\tpfn, pfn << PAGE_SHIFT);\n\n\treturn vmf_insert_mixed(vma, vmf->address,\n\t\t\t__pfn_to_pfn_t(pfn, PFN_DEV));\n}\n\n \nstatic vm_fault_t omap_gem_fault_2d(struct drm_gem_object *obj,\n\t\tstruct vm_area_struct *vma, struct vm_fault *vmf)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tstruct omap_drm_private *priv = obj->dev->dev_private;\n\tstruct omap_drm_usergart_entry *entry;\n\tenum tiler_fmt fmt = gem2fmt(omap_obj->flags);\n\tstruct page *pages[64];   \n\tunsigned long pfn;\n\tpgoff_t pgoff, base_pgoff;\n\tunsigned long vaddr;\n\tint i, err, slots;\n\tvm_fault_t ret = VM_FAULT_NOPAGE;\n\n\t \n\tconst int n = priv->usergart[fmt].height;\n\tconst int n_shift = priv->usergart[fmt].height_shift;\n\n\t \n\tconst int m = DIV_ROUND_UP(omap_obj->width << fmt, PAGE_SIZE);\n\n\t \n\tpgoff = (vmf->address - vma->vm_start) >> PAGE_SHIFT;\n\n\t \n\tbase_pgoff = round_down(pgoff, m << n_shift);\n\n\t \n\tslots = omap_obj->width >> priv->usergart[fmt].slot_shift;\n\n\tvaddr = vmf->address - ((pgoff - base_pgoff) << PAGE_SHIFT);\n\n\tentry = &priv->usergart[fmt].entry[priv->usergart[fmt].last];\n\n\t \n\tif (entry->obj)\n\t\tomap_gem_evict_entry(entry->obj, fmt, entry);\n\n\tentry->obj = obj;\n\tentry->obj_pgoff = base_pgoff;\n\n\t \n\tbase_pgoff = (base_pgoff >> n_shift) * slots;\n\n\t \n\tif (m > 1) {\n\t\tint off = pgoff % m;\n\t\tentry->obj_pgoff += off;\n\t\tbase_pgoff /= m;\n\t\tslots = min(slots - (off << n_shift), n);\n\t\tbase_pgoff += off << n_shift;\n\t\tvaddr += off << PAGE_SHIFT;\n\t}\n\n\t \n\tmemcpy(pages, &omap_obj->pages[base_pgoff],\n\t\t\tsizeof(struct page *) * slots);\n\tmemset(pages + slots, 0,\n\t\t\tsizeof(struct page *) * (n - slots));\n\n\terr = tiler_pin(entry->block, pages, ARRAY_SIZE(pages), 0, true);\n\tif (err) {\n\t\tret = vmf_error(err);\n\t\tdev_err(obj->dev->dev, \"failed to pin: %d\\n\", err);\n\t\treturn ret;\n\t}\n\n\tpfn = entry->dma_addr >> PAGE_SHIFT;\n\n\tVERB(\"Inserting %p pfn %lx, pa %lx\", (void *)vmf->address,\n\t\t\tpfn, pfn << PAGE_SHIFT);\n\n\tfor (i = n; i > 0; i--) {\n\t\tret = vmf_insert_mixed(vma,\n\t\t\tvaddr, __pfn_to_pfn_t(pfn, PFN_DEV));\n\t\tif (ret & VM_FAULT_ERROR)\n\t\t\tbreak;\n\t\tpfn += priv->usergart[fmt].stride_pfn;\n\t\tvaddr += PAGE_SIZE * m;\n\t}\n\n\t \n\tpriv->usergart[fmt].last = (priv->usergart[fmt].last + 1)\n\t\t\t\t % NUM_USERGART_ENTRIES;\n\n\treturn ret;\n}\n\n \nstatic vm_fault_t omap_gem_fault(struct vm_fault *vmf)\n{\n\tstruct vm_area_struct *vma = vmf->vma;\n\tstruct drm_gem_object *obj = vma->vm_private_data;\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tint err;\n\tvm_fault_t ret;\n\n\t \n\tmutex_lock(&omap_obj->lock);\n\n\t \n\terr = omap_gem_attach_pages(obj);\n\tif (err) {\n\t\tret = vmf_error(err);\n\t\tgoto fail;\n\t}\n\n\t \n\n\tif (omap_obj->flags & OMAP_BO_TILED_MASK)\n\t\tret = omap_gem_fault_2d(obj, vma, vmf);\n\telse\n\t\tret = omap_gem_fault_1d(obj, vma, vmf);\n\n\nfail:\n\tmutex_unlock(&omap_obj->lock);\n\treturn ret;\n}\n\nstatic int omap_gem_object_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\n\tvm_flags_set(vma, VM_DONTEXPAND | VM_DONTDUMP | VM_IO | VM_MIXEDMAP);\n\n\tif (omap_obj->flags & OMAP_BO_WC) {\n\t\tvma->vm_page_prot = pgprot_writecombine(vm_get_page_prot(vma->vm_flags));\n\t} else if (omap_obj->flags & OMAP_BO_UNCACHED) {\n\t\tvma->vm_page_prot = pgprot_noncached(vm_get_page_prot(vma->vm_flags));\n\t} else {\n\t\t \n\t\tif (WARN_ON(!obj->filp))\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tvma->vm_pgoff -= drm_vma_node_start(&obj->vma_node);\n\t\tvma_set_file(vma, obj->filp);\n\n\t\tvma->vm_page_prot = vm_get_page_prot(vma->vm_flags);\n\t}\n\n\tvma->vm_page_prot = pgprot_decrypted(vma->vm_page_prot);\n\n\treturn 0;\n}\n\n \n\n \nint omap_gem_dumb_create(struct drm_file *file, struct drm_device *dev,\n\t\tstruct drm_mode_create_dumb *args)\n{\n\tunion omap_gem_size gsize;\n\n\targs->pitch = DIV_ROUND_UP(args->width * args->bpp, 8);\n\n\targs->size = PAGE_ALIGN(args->pitch * args->height);\n\n\tgsize = (union omap_gem_size){\n\t\t.bytes = args->size,\n\t};\n\n\treturn omap_gem_new_handle(dev, file, gsize,\n\t\t\tOMAP_BO_SCANOUT | OMAP_BO_WC, &args->handle);\n}\n\n \nint omap_gem_dumb_map_offset(struct drm_file *file, struct drm_device *dev,\n\t\tu32 handle, u64 *offset)\n{\n\tstruct drm_gem_object *obj;\n\tint ret = 0;\n\n\t \n\tobj = drm_gem_object_lookup(file, handle);\n\tif (obj == NULL) {\n\t\tret = -ENOENT;\n\t\tgoto fail;\n\t}\n\n\t*offset = omap_gem_mmap_offset(obj);\n\n\tdrm_gem_object_put(obj);\n\nfail:\n\treturn ret;\n}\n\n#ifdef CONFIG_DRM_FBDEV_EMULATION\n \nint omap_gem_roll(struct drm_gem_object *obj, u32 roll)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tu32 npages = obj->size >> PAGE_SHIFT;\n\tint ret = 0;\n\n\tif (roll > npages) {\n\t\tdev_err(obj->dev->dev, \"invalid roll: %d\\n\", roll);\n\t\treturn -EINVAL;\n\t}\n\n\tomap_obj->roll = roll;\n\n\tmutex_lock(&omap_obj->lock);\n\n\t \n\tif (omap_obj->block) {\n\t\tret = omap_gem_attach_pages(obj);\n\t\tif (ret)\n\t\t\tgoto fail;\n\n\t\tret = tiler_pin(omap_obj->block, omap_obj->pages, npages,\n\t\t\t\troll, true);\n\t\tif (ret)\n\t\t\tdev_err(obj->dev->dev, \"could not repin: %d\\n\", ret);\n\t}\n\nfail:\n\tmutex_unlock(&omap_obj->lock);\n\n\treturn ret;\n}\n#endif\n\n \n\n \nstatic inline bool omap_gem_is_cached_coherent(struct drm_gem_object *obj)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\n\treturn !((omap_obj->flags & OMAP_BO_MEM_SHMEM) &&\n\t\t((omap_obj->flags & OMAP_BO_CACHE_MASK) == OMAP_BO_CACHED));\n}\n\n \nvoid omap_gem_cpu_sync_page(struct drm_gem_object *obj, int pgoff)\n{\n\tstruct drm_device *dev = obj->dev;\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\n\tif (omap_gem_is_cached_coherent(obj))\n\t\treturn;\n\n\tif (omap_obj->dma_addrs[pgoff]) {\n\t\tdma_unmap_page(dev->dev, omap_obj->dma_addrs[pgoff],\n\t\t\t\tPAGE_SIZE, DMA_TO_DEVICE);\n\t\tomap_obj->dma_addrs[pgoff] = 0;\n\t}\n}\n\n \nvoid omap_gem_dma_sync_buffer(struct drm_gem_object *obj,\n\t\tenum dma_data_direction dir)\n{\n\tstruct drm_device *dev = obj->dev;\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tint i, npages = obj->size >> PAGE_SHIFT;\n\tstruct page **pages = omap_obj->pages;\n\tbool dirty = false;\n\n\tif (omap_gem_is_cached_coherent(obj))\n\t\treturn;\n\n\tfor (i = 0; i < npages; i++) {\n\t\tif (!omap_obj->dma_addrs[i]) {\n\t\t\tdma_addr_t addr;\n\n\t\t\taddr = dma_map_page(dev->dev, pages[i], 0,\n\t\t\t\t\t    PAGE_SIZE, dir);\n\t\t\tif (dma_mapping_error(dev->dev, addr)) {\n\t\t\t\tdev_warn(dev->dev, \"%s: failed to map page\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tdirty = true;\n\t\t\tomap_obj->dma_addrs[i] = addr;\n\t\t}\n\t}\n\n\tif (dirty) {\n\t\tunmap_mapping_range(obj->filp->f_mapping, 0,\n\t\t\t\t    omap_gem_mmap_size(obj), 1);\n\t}\n}\n\nstatic int omap_gem_pin_tiler(struct drm_gem_object *obj)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tu32 npages = obj->size >> PAGE_SHIFT;\n\tenum tiler_fmt fmt = gem2fmt(omap_obj->flags);\n\tstruct tiler_block *block;\n\tint ret;\n\n\tBUG_ON(omap_obj->block);\n\n\tif (omap_obj->flags & OMAP_BO_TILED_MASK) {\n\t\tblock = tiler_reserve_2d(fmt, omap_obj->width, omap_obj->height,\n\t\t\t\t\t PAGE_SIZE);\n\t} else {\n\t\tblock = tiler_reserve_1d(obj->size);\n\t}\n\n\tif (IS_ERR(block)) {\n\t\tret = PTR_ERR(block);\n\t\tdev_err(obj->dev->dev, \"could not remap: %d (%d)\\n\", ret, fmt);\n\t\tgoto fail;\n\t}\n\n\t \n\tret = tiler_pin(block, omap_obj->pages, npages, omap_obj->roll, true);\n\tif (ret) {\n\t\ttiler_release(block);\n\t\tdev_err(obj->dev->dev, \"could not pin: %d\\n\", ret);\n\t\tgoto fail;\n\t}\n\n\tomap_obj->dma_addr = tiler_ssptr(block);\n\tomap_obj->block = block;\n\n\tDBG(\"got dma address: %pad\", &omap_obj->dma_addr);\n\nfail:\n\treturn ret;\n}\n\n \nint omap_gem_pin(struct drm_gem_object *obj, dma_addr_t *dma_addr)\n{\n\tstruct omap_drm_private *priv = obj->dev->dev_private;\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tint ret = 0;\n\n\tmutex_lock(&omap_obj->lock);\n\n\tif (!omap_gem_is_contiguous(omap_obj)) {\n\t\tif (refcount_read(&omap_obj->pin_cnt) == 0) {\n\n\t\t\trefcount_set(&omap_obj->pin_cnt, 1);\n\n\t\t\tret = omap_gem_attach_pages(obj);\n\t\t\tif (ret)\n\t\t\t\tgoto fail;\n\n\t\t\tif (omap_obj->flags & OMAP_BO_SCANOUT) {\n\t\t\t\tif (priv->has_dmm) {\n\t\t\t\t\tret = omap_gem_pin_tiler(obj);\n\t\t\t\t\tif (ret)\n\t\t\t\t\t\tgoto fail;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\trefcount_inc(&omap_obj->pin_cnt);\n\t\t}\n\t}\n\n\tif (dma_addr)\n\t\t*dma_addr = omap_obj->dma_addr;\n\nfail:\n\tmutex_unlock(&omap_obj->lock);\n\n\treturn ret;\n}\n\n \nstatic void omap_gem_unpin_locked(struct drm_gem_object *obj)\n{\n\tstruct omap_drm_private *priv = obj->dev->dev_private;\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tint ret;\n\n\tif (omap_gem_is_contiguous(omap_obj))\n\t\treturn;\n\n\tif (refcount_dec_and_test(&omap_obj->pin_cnt)) {\n\t\tif (omap_obj->sgt) {\n\t\t\tsg_free_table(omap_obj->sgt);\n\t\t\tkfree(omap_obj->sgt);\n\t\t\tomap_obj->sgt = NULL;\n\t\t}\n\t\tif (!(omap_obj->flags & OMAP_BO_SCANOUT))\n\t\t\treturn;\n\t\tif (priv->has_dmm) {\n\t\t\tret = tiler_unpin(omap_obj->block);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(obj->dev->dev,\n\t\t\t\t\t\"could not unpin pages: %d\\n\", ret);\n\t\t\t}\n\t\t\tret = tiler_release(omap_obj->block);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(obj->dev->dev,\n\t\t\t\t\t\"could not release unmap: %d\\n\", ret);\n\t\t\t}\n\t\t\tomap_obj->dma_addr = 0;\n\t\t\tomap_obj->block = NULL;\n\t\t}\n\t}\n}\n\n \nvoid omap_gem_unpin(struct drm_gem_object *obj)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\n\tmutex_lock(&omap_obj->lock);\n\tomap_gem_unpin_locked(obj);\n\tmutex_unlock(&omap_obj->lock);\n}\n\n \nint omap_gem_rotated_dma_addr(struct drm_gem_object *obj, u32 orient,\n\t\tint x, int y, dma_addr_t *dma_addr)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tint ret = -EINVAL;\n\n\tmutex_lock(&omap_obj->lock);\n\n\tif ((refcount_read(&omap_obj->pin_cnt) > 0) && omap_obj->block &&\n\t\t\t(omap_obj->flags & OMAP_BO_TILED_MASK)) {\n\t\t*dma_addr = tiler_tsptr(omap_obj->block, orient, x, y);\n\t\tret = 0;\n\t}\n\n\tmutex_unlock(&omap_obj->lock);\n\n\treturn ret;\n}\n\n \nint omap_gem_tiled_stride(struct drm_gem_object *obj, u32 orient)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tint ret = -EINVAL;\n\tif (omap_obj->flags & OMAP_BO_TILED_MASK)\n\t\tret = tiler_stride(gem2fmt(omap_obj->flags), orient);\n\treturn ret;\n}\n\n \nint omap_gem_get_pages(struct drm_gem_object *obj, struct page ***pages,\n\t\tbool remap)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tint ret = 0;\n\n\tmutex_lock(&omap_obj->lock);\n\n\tif (remap) {\n\t\tret = omap_gem_attach_pages(obj);\n\t\tif (ret)\n\t\t\tgoto unlock;\n\t}\n\n\tif (!omap_obj->pages) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock;\n\t}\n\n\t*pages = omap_obj->pages;\n\nunlock:\n\tmutex_unlock(&omap_obj->lock);\n\n\treturn ret;\n}\n\n \nint omap_gem_put_pages(struct drm_gem_object *obj)\n{\n\t \n\treturn 0;\n}\n\nstruct sg_table *omap_gem_get_sg(struct drm_gem_object *obj,\n\t\tenum dma_data_direction dir)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tdma_addr_t addr;\n\tstruct sg_table *sgt;\n\tstruct scatterlist *sg;\n\tunsigned int count, len, stride, i;\n\tint ret;\n\n\tret = omap_gem_pin(obj, &addr);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tmutex_lock(&omap_obj->lock);\n\n\tsgt = omap_obj->sgt;\n\tif (sgt)\n\t\tgoto out;\n\n\tsgt = kzalloc(sizeof(*sgt), GFP_KERNEL);\n\tif (!sgt) {\n\t\tret = -ENOMEM;\n\t\tgoto err_unpin;\n\t}\n\n\tif (addr) {\n\t\tif (omap_obj->flags & OMAP_BO_TILED_MASK) {\n\t\t\tenum tiler_fmt fmt = gem2fmt(omap_obj->flags);\n\n\t\t\tlen = omap_obj->width << (int)fmt;\n\t\t\tcount = omap_obj->height;\n\t\t\tstride = tiler_stride(fmt, 0);\n\t\t} else {\n\t\t\tlen = obj->size;\n\t\t\tcount = 1;\n\t\t\tstride = 0;\n\t\t}\n\t} else {\n\t\tcount = obj->size >> PAGE_SHIFT;\n\t}\n\n\tret = sg_alloc_table(sgt, count, GFP_KERNEL);\n\tif (ret)\n\t\tgoto err_free;\n\n\t \n\tomap_gem_dma_sync_buffer(obj, dir);\n\n\tif (addr) {\n\t\tfor_each_sg(sgt->sgl, sg, count, i) {\n\t\t\tsg_set_page(sg, phys_to_page(addr), len,\n\t\t\t\toffset_in_page(addr));\n\t\t\tsg_dma_address(sg) = addr;\n\t\t\tsg_dma_len(sg) = len;\n\n\t\t\taddr += stride;\n\t\t}\n\t} else {\n\t\tfor_each_sg(sgt->sgl, sg, count, i) {\n\t\t\tsg_set_page(sg, omap_obj->pages[i], PAGE_SIZE, 0);\n\t\t\tsg_dma_address(sg) = omap_obj->dma_addrs[i];\n\t\t\tsg_dma_len(sg) =  PAGE_SIZE;\n\t\t}\n\t}\n\n\tomap_obj->sgt = sgt;\nout:\n\tmutex_unlock(&omap_obj->lock);\n\treturn sgt;\n\nerr_free:\n\tkfree(sgt);\nerr_unpin:\n\tmutex_unlock(&omap_obj->lock);\n\tomap_gem_unpin(obj);\n\treturn ERR_PTR(ret);\n}\n\nvoid omap_gem_put_sg(struct drm_gem_object *obj, struct sg_table *sgt)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\n\tif (WARN_ON(omap_obj->sgt != sgt))\n\t\treturn;\n\n\tomap_gem_unpin(obj);\n}\n\n#ifdef CONFIG_DRM_FBDEV_EMULATION\n \nvoid *omap_gem_vaddr(struct drm_gem_object *obj)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tvoid *vaddr;\n\tint ret;\n\n\tmutex_lock(&omap_obj->lock);\n\n\tif (!omap_obj->vaddr) {\n\t\tret = omap_gem_attach_pages(obj);\n\t\tif (ret) {\n\t\t\tvaddr = ERR_PTR(ret);\n\t\t\tgoto unlock;\n\t\t}\n\n\t\tomap_obj->vaddr = vmap(omap_obj->pages, obj->size >> PAGE_SHIFT,\n\t\t\t\tVM_MAP, pgprot_writecombine(PAGE_KERNEL));\n\t}\n\n\tvaddr = omap_obj->vaddr;\n\nunlock:\n\tmutex_unlock(&omap_obj->lock);\n\treturn vaddr;\n}\n#endif\n\n \n\n#ifdef CONFIG_PM\n \nint omap_gem_resume(struct drm_device *dev)\n{\n\tstruct omap_drm_private *priv = dev->dev_private;\n\tstruct omap_gem_object *omap_obj;\n\tint ret = 0;\n\n\tmutex_lock(&priv->list_lock);\n\tlist_for_each_entry(omap_obj, &priv->obj_list, mm_list) {\n\t\tif (omap_obj->block) {\n\t\t\tstruct drm_gem_object *obj = &omap_obj->base;\n\t\t\tu32 npages = obj->size >> PAGE_SHIFT;\n\n\t\t\tWARN_ON(!omap_obj->pages);   \n\t\t\tret = tiler_pin(omap_obj->block,\n\t\t\t\t\tomap_obj->pages, npages,\n\t\t\t\t\tomap_obj->roll, true);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(dev->dev, \"could not repin: %d\\n\", ret);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\ndone:\n\tmutex_unlock(&priv->list_lock);\n\treturn ret;\n}\n#endif\n\n \n\n#ifdef CONFIG_DEBUG_FS\nvoid omap_gem_describe(struct drm_gem_object *obj, struct seq_file *m)\n{\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\tu64 off;\n\n\toff = drm_vma_node_start(&obj->vma_node);\n\n\tmutex_lock(&omap_obj->lock);\n\n\tseq_printf(m, \"%08x: %2d (%2d) %08llx %pad (%2d) %p %4d\",\n\t\t\tomap_obj->flags, obj->name, kref_read(&obj->refcount),\n\t\t\toff, &omap_obj->dma_addr,\n\t\t\trefcount_read(&omap_obj->pin_cnt),\n\t\t\tomap_obj->vaddr, omap_obj->roll);\n\n\tif (omap_obj->flags & OMAP_BO_TILED_MASK) {\n\t\tseq_printf(m, \" %dx%d\", omap_obj->width, omap_obj->height);\n\t\tif (omap_obj->block) {\n\t\t\tstruct tcm_area *area = &omap_obj->block->area;\n\t\t\tseq_printf(m, \" (%dx%d, %dx%d)\",\n\t\t\t\t\tarea->p0.x, area->p0.y,\n\t\t\t\t\tarea->p1.x, area->p1.y);\n\t\t}\n\t} else {\n\t\tseq_printf(m, \" %zu\", obj->size);\n\t}\n\n\tmutex_unlock(&omap_obj->lock);\n\n\tseq_printf(m, \"\\n\");\n}\n\nvoid omap_gem_describe_objects(struct list_head *list, struct seq_file *m)\n{\n\tstruct omap_gem_object *omap_obj;\n\tint count = 0;\n\tsize_t size = 0;\n\n\tlist_for_each_entry(omap_obj, list, mm_list) {\n\t\tstruct drm_gem_object *obj = &omap_obj->base;\n\t\tseq_printf(m, \"   \");\n\t\tomap_gem_describe(obj, m);\n\t\tcount++;\n\t\tsize += obj->size;\n\t}\n\n\tseq_printf(m, \"Total %d objects, %zu bytes\\n\", count, size);\n}\n#endif\n\n \n\nstatic void omap_gem_free_object(struct drm_gem_object *obj)\n{\n\tstruct drm_device *dev = obj->dev;\n\tstruct omap_drm_private *priv = dev->dev_private;\n\tstruct omap_gem_object *omap_obj = to_omap_bo(obj);\n\n\tomap_gem_evict(obj);\n\n\tmutex_lock(&priv->list_lock);\n\tlist_del(&omap_obj->mm_list);\n\tmutex_unlock(&priv->list_lock);\n\n\t \n\tmutex_lock(&omap_obj->lock);\n\n\t \n\tWARN_ON(refcount_read(&omap_obj->pin_cnt) > 0);\n\n\tif (omap_obj->pages) {\n\t\tif (omap_obj->flags & OMAP_BO_MEM_DMABUF)\n\t\t\tkfree(omap_obj->pages);\n\t\telse\n\t\t\tomap_gem_detach_pages(obj);\n\t}\n\n\tif (omap_obj->flags & OMAP_BO_MEM_DMA_API) {\n\t\tdma_free_wc(dev->dev, obj->size, omap_obj->vaddr,\n\t\t\t    omap_obj->dma_addr);\n\t} else if (omap_obj->vaddr) {\n\t\tvunmap(omap_obj->vaddr);\n\t} else if (obj->import_attach) {\n\t\tdrm_prime_gem_destroy(obj, omap_obj->sgt);\n\t}\n\n\tmutex_unlock(&omap_obj->lock);\n\n\tdrm_gem_object_release(obj);\n\n\tmutex_destroy(&omap_obj->lock);\n\n\tkfree(omap_obj);\n}\n\nstatic bool omap_gem_validate_flags(struct drm_device *dev, u32 flags)\n{\n\tstruct omap_drm_private *priv = dev->dev_private;\n\n\tswitch (flags & OMAP_BO_CACHE_MASK) {\n\tcase OMAP_BO_CACHED:\n\tcase OMAP_BO_WC:\n\tcase OMAP_BO_CACHE_MASK:\n\t\tbreak;\n\n\tdefault:\n\t\treturn false;\n\t}\n\n\tif (flags & OMAP_BO_TILED_MASK) {\n\t\tif (!priv->usergart)\n\t\t\treturn false;\n\n\t\tswitch (flags & OMAP_BO_TILED_MASK) {\n\t\tcase OMAP_BO_TILED_8:\n\t\tcase OMAP_BO_TILED_16:\n\t\tcase OMAP_BO_TILED_32:\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}\n\nstatic const struct vm_operations_struct omap_gem_vm_ops = {\n\t.fault = omap_gem_fault,\n\t.open = drm_gem_vm_open,\n\t.close = drm_gem_vm_close,\n};\n\nstatic const struct drm_gem_object_funcs omap_gem_object_funcs = {\n\t.free = omap_gem_free_object,\n\t.export = omap_gem_prime_export,\n\t.mmap = omap_gem_object_mmap,\n\t.vm_ops = &omap_gem_vm_ops,\n};\n\n \nstruct drm_gem_object *omap_gem_new(struct drm_device *dev,\n\t\tunion omap_gem_size gsize, u32 flags)\n{\n\tstruct omap_drm_private *priv = dev->dev_private;\n\tstruct omap_gem_object *omap_obj;\n\tstruct drm_gem_object *obj;\n\tstruct address_space *mapping;\n\tsize_t size;\n\tint ret;\n\n\tif (!omap_gem_validate_flags(dev, flags))\n\t\treturn NULL;\n\n\t \n\tif (flags & OMAP_BO_TILED_MASK) {\n\t\t \n\t\tflags |= OMAP_BO_MEM_SHMEM;\n\n\t\t \n\t\tflags &= ~(OMAP_BO_CACHED|OMAP_BO_WC|OMAP_BO_UNCACHED);\n\t\tflags |= tiler_get_cpu_cache_flags();\n\t} else if ((flags & OMAP_BO_SCANOUT) && !priv->has_dmm) {\n\t\t \n\t\tflags |= OMAP_BO_MEM_DMA_API;\n\t} else if (!(flags & OMAP_BO_MEM_DMABUF)) {\n\t\t \n\t\tflags |= OMAP_BO_MEM_SHMEM;\n\t}\n\n\t \n\tomap_obj = kzalloc(sizeof(*omap_obj), GFP_KERNEL);\n\tif (!omap_obj)\n\t\treturn NULL;\n\n\tobj = &omap_obj->base;\n\tomap_obj->flags = flags;\n\tmutex_init(&omap_obj->lock);\n\n\tif (flags & OMAP_BO_TILED_MASK) {\n\t\t \n\t\ttiler_align(gem2fmt(flags), &gsize.tiled.width,\n\t\t\t    &gsize.tiled.height);\n\n\t\tsize = tiler_size(gem2fmt(flags), gsize.tiled.width,\n\t\t\t\t  gsize.tiled.height);\n\n\t\tomap_obj->width = gsize.tiled.width;\n\t\tomap_obj->height = gsize.tiled.height;\n\t} else {\n\t\tsize = PAGE_ALIGN(gsize.bytes);\n\t}\n\n\tobj->funcs = &omap_gem_object_funcs;\n\n\t \n\tif (!(flags & OMAP_BO_MEM_SHMEM)) {\n\t\tdrm_gem_private_object_init(dev, obj, size);\n\t} else {\n\t\tret = drm_gem_object_init(dev, obj, size);\n\t\tif (ret)\n\t\t\tgoto err_free;\n\n\t\tmapping = obj->filp->f_mapping;\n\t\tmapping_set_gfp_mask(mapping, GFP_USER | __GFP_DMA32);\n\t}\n\n\t \n\tif (flags & OMAP_BO_MEM_DMA_API) {\n\t\tomap_obj->vaddr = dma_alloc_wc(dev->dev, size,\n\t\t\t\t\t       &omap_obj->dma_addr,\n\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!omap_obj->vaddr)\n\t\t\tgoto err_release;\n\t}\n\n\tmutex_lock(&priv->list_lock);\n\tlist_add(&omap_obj->mm_list, &priv->obj_list);\n\tmutex_unlock(&priv->list_lock);\n\n\treturn obj;\n\nerr_release:\n\tdrm_gem_object_release(obj);\nerr_free:\n\tkfree(omap_obj);\n\treturn NULL;\n}\n\nstruct drm_gem_object *omap_gem_new_dmabuf(struct drm_device *dev, size_t size,\n\t\t\t\t\t   struct sg_table *sgt)\n{\n\tstruct omap_drm_private *priv = dev->dev_private;\n\tstruct omap_gem_object *omap_obj;\n\tstruct drm_gem_object *obj;\n\tunion omap_gem_size gsize;\n\n\t \n\tif (sgt->orig_nents != 1 && !priv->has_dmm)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tgsize.bytes = PAGE_ALIGN(size);\n\tobj = omap_gem_new(dev, gsize, OMAP_BO_MEM_DMABUF | OMAP_BO_WC);\n\tif (!obj)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tomap_obj = to_omap_bo(obj);\n\n\tmutex_lock(&omap_obj->lock);\n\n\tomap_obj->sgt = sgt;\n\n\tif (sgt->orig_nents == 1) {\n\t\tomap_obj->dma_addr = sg_dma_address(sgt->sgl);\n\t} else {\n\t\t \n\t\tstruct page **pages;\n\t\tunsigned int npages;\n\t\tunsigned int ret;\n\n\t\tnpages = DIV_ROUND_UP(size, PAGE_SIZE);\n\t\tpages = kcalloc(npages, sizeof(*pages), GFP_KERNEL);\n\t\tif (!pages) {\n\t\t\tomap_gem_free_object(obj);\n\t\t\tobj = ERR_PTR(-ENOMEM);\n\t\t\tgoto done;\n\t\t}\n\n\t\tomap_obj->pages = pages;\n\t\tret = drm_prime_sg_to_page_array(sgt, pages, npages);\n\t\tif (ret) {\n\t\t\tomap_gem_free_object(obj);\n\t\t\tobj = ERR_PTR(-ENOMEM);\n\t\t\tgoto done;\n\t\t}\n\t}\n\ndone:\n\tmutex_unlock(&omap_obj->lock);\n\treturn obj;\n}\n\n \nint omap_gem_new_handle(struct drm_device *dev, struct drm_file *file,\n\t\tunion omap_gem_size gsize, u32 flags, u32 *handle)\n{\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\tobj = omap_gem_new(dev, gsize, flags);\n\tif (!obj)\n\t\treturn -ENOMEM;\n\n\tret = drm_gem_handle_create(file, obj, handle);\n\tif (ret) {\n\t\tomap_gem_free_object(obj);\n\t\treturn ret;\n\t}\n\n\t \n\tdrm_gem_object_put(obj);\n\n\treturn 0;\n}\n\n \n\n \nvoid omap_gem_init(struct drm_device *dev)\n{\n\tstruct omap_drm_private *priv = dev->dev_private;\n\tstruct omap_drm_usergart *usergart;\n\tconst enum tiler_fmt fmts[] = {\n\t\t\tTILFMT_8BIT, TILFMT_16BIT, TILFMT_32BIT\n\t};\n\tint i, j;\n\n\tif (!dmm_is_available()) {\n\t\t \n\t\tdev_warn(dev->dev, \"DMM not available, disable DMM support\\n\");\n\t\treturn;\n\t}\n\n\tusergart = kcalloc(3, sizeof(*usergart), GFP_KERNEL);\n\tif (!usergart)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(fmts); i++) {\n\t\tu16 h = 1, w = PAGE_SIZE >> i;\n\n\t\ttiler_align(fmts[i], &w, &h);\n\t\t \n\t\tusergart[i].height = h;\n\t\tusergart[i].height_shift = ilog2(h);\n\t\tusergart[i].stride_pfn = tiler_stride(fmts[i], 0) >> PAGE_SHIFT;\n\t\tusergart[i].slot_shift = ilog2((PAGE_SIZE / h) >> i);\n\t\tfor (j = 0; j < NUM_USERGART_ENTRIES; j++) {\n\t\t\tstruct omap_drm_usergart_entry *entry;\n\t\t\tstruct tiler_block *block;\n\n\t\t\tentry = &usergart[i].entry[j];\n\t\t\tblock = tiler_reserve_2d(fmts[i], w, h, PAGE_SIZE);\n\t\t\tif (IS_ERR(block)) {\n\t\t\t\tdev_err(dev->dev,\n\t\t\t\t\t\t\"reserve failed: %d, %d, %ld\\n\",\n\t\t\t\t\t\ti, j, PTR_ERR(block));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tentry->dma_addr = tiler_ssptr(block);\n\t\t\tentry->block = block;\n\n\t\t\tDBG(\"%d:%d: %dx%d: dma_addr=%pad stride=%d\", i, j, w, h,\n\t\t\t\t\t&entry->dma_addr,\n\t\t\t\t\tusergart[i].stride_pfn << PAGE_SHIFT);\n\t\t}\n\t}\n\n\tpriv->usergart = usergart;\n\tpriv->has_dmm = true;\n}\n\nvoid omap_gem_deinit(struct drm_device *dev)\n{\n\tstruct omap_drm_private *priv = dev->dev_private;\n\n\t \n\tkfree(priv->usergart);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}