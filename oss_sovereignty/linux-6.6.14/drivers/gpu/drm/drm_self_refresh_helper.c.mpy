{
  "module_name": "drm_self_refresh_helper.c",
  "hash_id": "bf401ec59350754daa925a4df45ede4a6c9c1049e03680c134b5dd9dd6e49438",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/drm_self_refresh_helper.c",
  "human_readable_source": "\n \n#include <linux/average.h>\n#include <linux/bitops.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n\n#include <drm/drm_atomic.h>\n#include <drm/drm_atomic_helper.h>\n#include <drm/drm_connector.h>\n#include <drm/drm_crtc.h>\n#include <drm/drm_device.h>\n#include <drm/drm_mode_config.h>\n#include <drm/drm_modeset_lock.h>\n#include <drm/drm_print.h>\n#include <drm/drm_self_refresh_helper.h>\n\n \n\n#define SELF_REFRESH_AVG_SEED_MS 200\n\nDECLARE_EWMA(psr_time, 4, 4)\n\nstruct drm_self_refresh_data {\n\tstruct drm_crtc *crtc;\n\tstruct delayed_work entry_work;\n\n\tstruct mutex avg_mutex;\n\tstruct ewma_psr_time entry_avg_ms;\n\tstruct ewma_psr_time exit_avg_ms;\n};\n\nstatic void drm_self_refresh_helper_entry_work(struct work_struct *work)\n{\n\tstruct drm_self_refresh_data *sr_data = container_of(\n\t\t\t\tto_delayed_work(work),\n\t\t\t\tstruct drm_self_refresh_data, entry_work);\n\tstruct drm_crtc *crtc = sr_data->crtc;\n\tstruct drm_device *dev = crtc->dev;\n\tstruct drm_modeset_acquire_ctx ctx;\n\tstruct drm_atomic_state *state;\n\tstruct drm_connector *conn;\n\tstruct drm_connector_state *conn_state;\n\tstruct drm_crtc_state *crtc_state;\n\tint i, ret = 0;\n\n\tdrm_modeset_acquire_init(&ctx, 0);\n\n\tstate = drm_atomic_state_alloc(dev);\n\tif (!state) {\n\t\tret = -ENOMEM;\n\t\tgoto out_drop_locks;\n\t}\n\nretry:\n\tstate->acquire_ctx = &ctx;\n\n\tcrtc_state = drm_atomic_get_crtc_state(state, crtc);\n\tif (IS_ERR(crtc_state)) {\n\t\tret = PTR_ERR(crtc_state);\n\t\tgoto out;\n\t}\n\n\tif (!crtc_state->enable)\n\t\tgoto out;\n\n\tret = drm_atomic_add_affected_connectors(state, crtc);\n\tif (ret)\n\t\tgoto out;\n\n\tfor_each_new_connector_in_state(state, conn, conn_state, i) {\n\t\tif (!conn_state->self_refresh_aware)\n\t\t\tgoto out;\n\t}\n\n\tcrtc_state->active = false;\n\tcrtc_state->self_refresh_active = true;\n\n\tret = drm_atomic_commit(state);\n\tif (ret)\n\t\tgoto out;\n\nout:\n\tif (ret == -EDEADLK) {\n\t\tdrm_atomic_state_clear(state);\n\t\tret = drm_modeset_backoff(&ctx);\n\t\tif (!ret)\n\t\t\tgoto retry;\n\t}\n\n\tdrm_atomic_state_put(state);\n\nout_drop_locks:\n\tdrm_modeset_drop_locks(&ctx);\n\tdrm_modeset_acquire_fini(&ctx);\n}\n\n \nvoid\ndrm_self_refresh_helper_update_avg_times(struct drm_atomic_state *state,\n\t\t\t\t\t unsigned int commit_time_ms,\n\t\t\t\t\t unsigned int new_self_refresh_mask)\n{\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *old_crtc_state;\n\tint i;\n\n\tfor_each_old_crtc_in_state(state, crtc, old_crtc_state, i) {\n\t\tbool new_self_refresh_active = new_self_refresh_mask & BIT(i);\n\t\tstruct drm_self_refresh_data *sr_data = crtc->self_refresh_data;\n\t\tstruct ewma_psr_time *time;\n\n\t\tif (old_crtc_state->self_refresh_active ==\n\t\t    new_self_refresh_active)\n\t\t\tcontinue;\n\n\t\tif (new_self_refresh_active)\n\t\t\ttime = &sr_data->entry_avg_ms;\n\t\telse\n\t\t\ttime = &sr_data->exit_avg_ms;\n\n\t\tmutex_lock(&sr_data->avg_mutex);\n\t\tewma_psr_time_add(time, commit_time_ms);\n\t\tmutex_unlock(&sr_data->avg_mutex);\n\t}\n}\nEXPORT_SYMBOL(drm_self_refresh_helper_update_avg_times);\n\n \nvoid drm_self_refresh_helper_alter_state(struct drm_atomic_state *state)\n{\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *crtc_state;\n\tint i;\n\n\tif (state->async_update || !state->allow_modeset) {\n\t\tfor_each_old_crtc_in_state(state, crtc, crtc_state, i) {\n\t\t\tif (crtc_state->self_refresh_active) {\n\t\t\t\tstate->async_update = false;\n\t\t\t\tstate->allow_modeset = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor_each_new_crtc_in_state(state, crtc, crtc_state, i) {\n\t\tstruct drm_self_refresh_data *sr_data;\n\t\tunsigned int delay;\n\n\t\t \n\t\tif (crtc_state->self_refresh_active)\n\t\t\tcontinue;\n\n\t\tsr_data = crtc->self_refresh_data;\n\t\tif (!sr_data)\n\t\t\tcontinue;\n\n\t\tmutex_lock(&sr_data->avg_mutex);\n\t\tdelay = (ewma_psr_time_read(&sr_data->entry_avg_ms) +\n\t\t\t ewma_psr_time_read(&sr_data->exit_avg_ms)) * 2;\n\t\tmutex_unlock(&sr_data->avg_mutex);\n\n\t\tmod_delayed_work(system_wq, &sr_data->entry_work,\n\t\t\t\t msecs_to_jiffies(delay));\n\t}\n}\nEXPORT_SYMBOL(drm_self_refresh_helper_alter_state);\n\n \nint drm_self_refresh_helper_init(struct drm_crtc *crtc)\n{\n\tstruct drm_self_refresh_data *sr_data = crtc->self_refresh_data;\n\n\t \n\tif (WARN_ON(sr_data))\n\t\treturn -EINVAL;\n\n\tsr_data = kzalloc(sizeof(*sr_data), GFP_KERNEL);\n\tif (!sr_data)\n\t\treturn -ENOMEM;\n\n\tINIT_DELAYED_WORK(&sr_data->entry_work,\n\t\t\t  drm_self_refresh_helper_entry_work);\n\tsr_data->crtc = crtc;\n\tmutex_init(&sr_data->avg_mutex);\n\tewma_psr_time_init(&sr_data->entry_avg_ms);\n\tewma_psr_time_init(&sr_data->exit_avg_ms);\n\n\t \n\tewma_psr_time_add(&sr_data->entry_avg_ms, SELF_REFRESH_AVG_SEED_MS);\n\tewma_psr_time_add(&sr_data->exit_avg_ms, SELF_REFRESH_AVG_SEED_MS);\n\n\tcrtc->self_refresh_data = sr_data;\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_self_refresh_helper_init);\n\n \nvoid drm_self_refresh_helper_cleanup(struct drm_crtc *crtc)\n{\n\tstruct drm_self_refresh_data *sr_data = crtc->self_refresh_data;\n\n\t \n\tif (!sr_data)\n\t\treturn;\n\n\tcrtc->self_refresh_data = NULL;\n\n\tcancel_delayed_work_sync(&sr_data->entry_work);\n\tkfree(sr_data);\n}\nEXPORT_SYMBOL(drm_self_refresh_helper_cleanup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}