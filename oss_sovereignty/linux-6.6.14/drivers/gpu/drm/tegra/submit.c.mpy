{
  "module_name": "submit.c",
  "hash_id": "a92a0595df7ae6956adbc7fa53e059e8fe6e684249f7f443037c0704520b3191",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/tegra/submit.c",
  "human_readable_source": "\n \n\n#include <linux/dma-fence-array.h>\n#include <linux/dma-mapping.h>\n#include <linux/file.h>\n#include <linux/host1x.h>\n#include <linux/iommu.h>\n#include <linux/kref.h>\n#include <linux/list.h>\n#include <linux/nospec.h>\n#include <linux/pm_runtime.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <linux/sync_file.h>\n\n#include <drm/drm_drv.h>\n#include <drm/drm_file.h>\n#include <drm/drm_syncobj.h>\n\n#include \"drm.h\"\n#include \"gem.h\"\n#include \"submit.h\"\n#include \"uapi.h\"\n\n#define SUBMIT_ERR(context, fmt, ...) \\\n\tdev_err_ratelimited(context->client->base.dev, \\\n\t\t\"%s: job submission failed: \" fmt \"\\n\", \\\n\t\tcurrent->comm, ##__VA_ARGS__)\n\nstruct gather_bo {\n\tstruct host1x_bo base;\n\n\tstruct kref ref;\n\n\tstruct device *dev;\n\tu32 *gather_data;\n\tdma_addr_t gather_data_dma;\n\tsize_t gather_data_words;\n};\n\nstatic struct host1x_bo *gather_bo_get(struct host1x_bo *host_bo)\n{\n\tstruct gather_bo *bo = container_of(host_bo, struct gather_bo, base);\n\n\tkref_get(&bo->ref);\n\n\treturn host_bo;\n}\n\nstatic void gather_bo_release(struct kref *ref)\n{\n\tstruct gather_bo *bo = container_of(ref, struct gather_bo, ref);\n\n\tdma_free_attrs(bo->dev, bo->gather_data_words * 4, bo->gather_data, bo->gather_data_dma,\n\t\t       0);\n\tkfree(bo);\n}\n\nstatic void gather_bo_put(struct host1x_bo *host_bo)\n{\n\tstruct gather_bo *bo = container_of(host_bo, struct gather_bo, base);\n\n\tkref_put(&bo->ref, gather_bo_release);\n}\n\nstatic struct host1x_bo_mapping *\ngather_bo_pin(struct device *dev, struct host1x_bo *bo, enum dma_data_direction direction)\n{\n\tstruct gather_bo *gather = container_of(bo, struct gather_bo, base);\n\tstruct host1x_bo_mapping *map;\n\tint err;\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (!map)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tkref_init(&map->ref);\n\tmap->bo = host1x_bo_get(bo);\n\tmap->direction = direction;\n\tmap->dev = dev;\n\n\tmap->sgt = kzalloc(sizeof(*map->sgt), GFP_KERNEL);\n\tif (!map->sgt) {\n\t\terr = -ENOMEM;\n\t\tgoto free;\n\t}\n\n\terr = dma_get_sgtable(gather->dev, map->sgt, gather->gather_data, gather->gather_data_dma,\n\t\t\t      gather->gather_data_words * 4);\n\tif (err)\n\t\tgoto free_sgt;\n\n\terr = dma_map_sgtable(dev, map->sgt, direction, 0);\n\tif (err)\n\t\tgoto free_sgt;\n\n\tmap->phys = sg_dma_address(map->sgt->sgl);\n\tmap->size = gather->gather_data_words * 4;\n\tmap->chunks = err;\n\n\treturn map;\n\nfree_sgt:\n\tsg_free_table(map->sgt);\n\tkfree(map->sgt);\nfree:\n\tkfree(map);\n\treturn ERR_PTR(err);\n}\n\nstatic void gather_bo_unpin(struct host1x_bo_mapping *map)\n{\n\tif (!map)\n\t\treturn;\n\n\tdma_unmap_sgtable(map->dev, map->sgt, map->direction, 0);\n\tsg_free_table(map->sgt);\n\tkfree(map->sgt);\n\thost1x_bo_put(map->bo);\n\n\tkfree(map);\n}\n\nstatic void *gather_bo_mmap(struct host1x_bo *host_bo)\n{\n\tstruct gather_bo *bo = container_of(host_bo, struct gather_bo, base);\n\n\treturn bo->gather_data;\n}\n\nstatic void gather_bo_munmap(struct host1x_bo *host_bo, void *addr)\n{\n}\n\nstatic const struct host1x_bo_ops gather_bo_ops = {\n\t.get = gather_bo_get,\n\t.put = gather_bo_put,\n\t.pin = gather_bo_pin,\n\t.unpin = gather_bo_unpin,\n\t.mmap = gather_bo_mmap,\n\t.munmap = gather_bo_munmap,\n};\n\nstatic struct tegra_drm_mapping *\ntegra_drm_mapping_get(struct tegra_drm_context *context, u32 id)\n{\n\tstruct tegra_drm_mapping *mapping;\n\n\txa_lock(&context->mappings);\n\n\tmapping = xa_load(&context->mappings, id);\n\tif (mapping)\n\t\tkref_get(&mapping->ref);\n\n\txa_unlock(&context->mappings);\n\n\treturn mapping;\n}\n\nstatic void *alloc_copy_user_array(void __user *from, size_t count, size_t size)\n{\n\tsize_t copy_len;\n\tvoid *data;\n\n\tif (check_mul_overflow(count, size, &copy_len))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (copy_len > 0x4000)\n\t\treturn ERR_PTR(-E2BIG);\n\n\tdata = vmemdup_user(from, copy_len);\n\tif (IS_ERR(data))\n\t\treturn ERR_CAST(data);\n\n\treturn data;\n}\n\nstatic int submit_copy_gather_data(struct gather_bo **pbo, struct device *dev,\n\t\t\t\t   struct tegra_drm_context *context,\n\t\t\t\t   struct drm_tegra_channel_submit *args)\n{\n\tstruct gather_bo *bo;\n\tsize_t copy_len;\n\n\tif (args->gather_data_words == 0) {\n\t\tSUBMIT_ERR(context, \"gather_data_words cannot be zero\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (check_mul_overflow((size_t)args->gather_data_words, (size_t)4, &copy_len)) {\n\t\tSUBMIT_ERR(context, \"gather_data_words is too large\");\n\t\treturn -EINVAL;\n\t}\n\n\tbo = kzalloc(sizeof(*bo), GFP_KERNEL);\n\tif (!bo) {\n\t\tSUBMIT_ERR(context, \"failed to allocate memory for bo info\");\n\t\treturn -ENOMEM;\n\t}\n\n\thost1x_bo_init(&bo->base, &gather_bo_ops);\n\tkref_init(&bo->ref);\n\tbo->dev = dev;\n\n\tbo->gather_data = dma_alloc_attrs(dev, copy_len, &bo->gather_data_dma,\n\t\t\t\t\t  GFP_KERNEL | __GFP_NOWARN, 0);\n\tif (!bo->gather_data) {\n\t\tSUBMIT_ERR(context, \"failed to allocate memory for gather data\");\n\t\tkfree(bo);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (copy_from_user(bo->gather_data, u64_to_user_ptr(args->gather_data_ptr), copy_len)) {\n\t\tSUBMIT_ERR(context, \"failed to copy gather data from userspace\");\n\t\tdma_free_attrs(dev, copy_len, bo->gather_data, bo->gather_data_dma, 0);\n\t\tkfree(bo);\n\t\treturn -EFAULT;\n\t}\n\n\tbo->gather_data_words = args->gather_data_words;\n\n\t*pbo = bo;\n\n\treturn 0;\n}\n\nstatic int submit_write_reloc(struct tegra_drm_context *context, struct gather_bo *bo,\n\t\t\t      struct drm_tegra_submit_buf *buf, struct tegra_drm_mapping *mapping)\n{\n\t \n\tdma_addr_t iova = mapping->iova + buf->reloc.target_offset;\n\tu32 written_ptr;\n\n#ifdef CONFIG_ARCH_DMA_ADDR_T_64BIT\n\tif (buf->flags & DRM_TEGRA_SUBMIT_RELOC_SECTOR_LAYOUT)\n\t\tiova |= BIT_ULL(39);\n#endif\n\n\twritten_ptr = iova >> buf->reloc.shift;\n\n\tif (buf->reloc.gather_offset_words >= bo->gather_data_words) {\n\t\tSUBMIT_ERR(context,\n\t\t\t   \"relocation has too large gather offset (%u vs gather length %zu)\",\n\t\t\t   buf->reloc.gather_offset_words, bo->gather_data_words);\n\t\treturn -EINVAL;\n\t}\n\n\tbuf->reloc.gather_offset_words = array_index_nospec(buf->reloc.gather_offset_words,\n\t\t\t\t\t\t\t    bo->gather_data_words);\n\n\tbo->gather_data[buf->reloc.gather_offset_words] = written_ptr;\n\n\treturn 0;\n}\n\nstatic int submit_process_bufs(struct tegra_drm_context *context, struct gather_bo *bo,\n\t\t\t       struct drm_tegra_channel_submit *args,\n\t\t\t       struct tegra_drm_submit_data *job_data)\n{\n\tstruct tegra_drm_used_mapping *mappings;\n\tstruct drm_tegra_submit_buf *bufs;\n\tint err;\n\tu32 i;\n\n\tbufs = alloc_copy_user_array(u64_to_user_ptr(args->bufs_ptr), args->num_bufs,\n\t\t\t\t     sizeof(*bufs));\n\tif (IS_ERR(bufs)) {\n\t\tSUBMIT_ERR(context, \"failed to copy bufs array from userspace\");\n\t\treturn PTR_ERR(bufs);\n\t}\n\n\tmappings = kcalloc(args->num_bufs, sizeof(*mappings), GFP_KERNEL);\n\tif (!mappings) {\n\t\tSUBMIT_ERR(context, \"failed to allocate memory for mapping info\");\n\t\terr = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\tfor (i = 0; i < args->num_bufs; i++) {\n\t\tstruct drm_tegra_submit_buf *buf = &bufs[i];\n\t\tstruct tegra_drm_mapping *mapping;\n\n\t\tif (buf->flags & ~DRM_TEGRA_SUBMIT_RELOC_SECTOR_LAYOUT) {\n\t\t\tSUBMIT_ERR(context, \"invalid flag specified for buffer\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto drop_refs;\n\t\t}\n\n\t\tmapping = tegra_drm_mapping_get(context, buf->mapping);\n\t\tif (!mapping) {\n\t\t\tSUBMIT_ERR(context, \"invalid mapping ID '%u' for buffer\", buf->mapping);\n\t\t\terr = -EINVAL;\n\t\t\tgoto drop_refs;\n\t\t}\n\n\t\terr = submit_write_reloc(context, bo, buf, mapping);\n\t\tif (err) {\n\t\t\ttegra_drm_mapping_put(mapping);\n\t\t\tgoto drop_refs;\n\t\t}\n\n\t\tmappings[i].mapping = mapping;\n\t\tmappings[i].flags = buf->flags;\n\t}\n\n\tjob_data->used_mappings = mappings;\n\tjob_data->num_used_mappings = i;\n\n\terr = 0;\n\n\tgoto done;\n\ndrop_refs:\n\twhile (i--)\n\t\ttegra_drm_mapping_put(mappings[i].mapping);\n\n\tkfree(mappings);\n\tjob_data->used_mappings = NULL;\n\ndone:\n\tkvfree(bufs);\n\n\treturn err;\n}\n\nstatic int submit_get_syncpt(struct tegra_drm_context *context, struct host1x_job *job,\n\t\t\t     struct xarray *syncpoints, struct drm_tegra_channel_submit *args)\n{\n\tstruct host1x_syncpt *sp;\n\n\tif (args->syncpt.flags) {\n\t\tSUBMIT_ERR(context, \"invalid flag specified for syncpt\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tsp = xa_load(syncpoints, args->syncpt.id);\n\tif (!sp) {\n\t\tSUBMIT_ERR(context, \"syncpoint specified in syncpt was not allocated\");\n\t\treturn -EINVAL;\n\t}\n\n\tjob->syncpt = host1x_syncpt_get(sp);\n\tjob->syncpt_incrs = args->syncpt.increments;\n\n\treturn 0;\n}\n\nstatic int submit_job_add_gather(struct host1x_job *job, struct tegra_drm_context *context,\n\t\t\t\t struct drm_tegra_submit_cmd_gather_uptr *cmd,\n\t\t\t\t struct gather_bo *bo, u32 *offset,\n\t\t\t\t struct tegra_drm_submit_data *job_data,\n\t\t\t\t u32 *class)\n{\n\tu32 next_offset;\n\n\tif (cmd->reserved[0] || cmd->reserved[1] || cmd->reserved[2]) {\n\t\tSUBMIT_ERR(context, \"non-zero reserved field in GATHER_UPTR command\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (cmd->words > 16383) {\n\t\tSUBMIT_ERR(context, \"too many words in GATHER_UPTR command\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (check_add_overflow(*offset, cmd->words, &next_offset)) {\n\t\tSUBMIT_ERR(context, \"too many total words in job\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (next_offset > bo->gather_data_words) {\n\t\tSUBMIT_ERR(context, \"GATHER_UPTR command overflows gather data\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (tegra_drm_fw_validate(context->client, bo->gather_data, *offset,\n\t\t\t\t  cmd->words, job_data, class)) {\n\t\tSUBMIT_ERR(context, \"job was rejected by firewall\");\n\t\treturn -EINVAL;\n\t}\n\n\thost1x_job_add_gather(job, &bo->base, cmd->words, *offset * 4);\n\n\t*offset = next_offset;\n\n\treturn 0;\n}\n\nstatic struct host1x_job *\nsubmit_create_job(struct tegra_drm_context *context, struct gather_bo *bo,\n\t\t  struct drm_tegra_channel_submit *args, struct tegra_drm_submit_data *job_data,\n\t\t  struct xarray *syncpoints)\n{\n\tstruct drm_tegra_submit_cmd *cmds;\n\tu32 i, gather_offset = 0, class;\n\tstruct host1x_job *job;\n\tint err;\n\n\t \n\tclass = context->client->base.class;\n\n\tcmds = alloc_copy_user_array(u64_to_user_ptr(args->cmds_ptr), args->num_cmds,\n\t\t\t\t     sizeof(*cmds));\n\tif (IS_ERR(cmds)) {\n\t\tSUBMIT_ERR(context, \"failed to copy cmds array from userspace\");\n\t\treturn ERR_CAST(cmds);\n\t}\n\n\tjob = host1x_job_alloc(context->channel, args->num_cmds, 0, true);\n\tif (!job) {\n\t\tSUBMIT_ERR(context, \"failed to allocate memory for job\");\n\t\tjob = ERR_PTR(-ENOMEM);\n\t\tgoto done;\n\t}\n\n\terr = submit_get_syncpt(context, job, syncpoints, args);\n\tif (err < 0)\n\t\tgoto free_job;\n\n\tjob->client = &context->client->base;\n\tjob->class = context->client->base.class;\n\tjob->serialize = true;\n\n\tfor (i = 0; i < args->num_cmds; i++) {\n\t\tstruct drm_tegra_submit_cmd *cmd = &cmds[i];\n\n\t\tif (cmd->flags) {\n\t\t\tSUBMIT_ERR(context, \"unknown flags given for cmd\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto free_job;\n\t\t}\n\n\t\tif (cmd->type == DRM_TEGRA_SUBMIT_CMD_GATHER_UPTR) {\n\t\t\terr = submit_job_add_gather(job, context, &cmd->gather_uptr, bo,\n\t\t\t\t\t\t    &gather_offset, job_data, &class);\n\t\t\tif (err)\n\t\t\t\tgoto free_job;\n\t\t} else if (cmd->type == DRM_TEGRA_SUBMIT_CMD_WAIT_SYNCPT) {\n\t\t\tif (cmd->wait_syncpt.reserved[0] || cmd->wait_syncpt.reserved[1]) {\n\t\t\t\tSUBMIT_ERR(context, \"non-zero reserved value\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto free_job;\n\t\t\t}\n\n\t\t\thost1x_job_add_wait(job, cmd->wait_syncpt.id, cmd->wait_syncpt.value,\n\t\t\t\t\t    false, class);\n\t\t} else if (cmd->type == DRM_TEGRA_SUBMIT_CMD_WAIT_SYNCPT_RELATIVE) {\n\t\t\tif (cmd->wait_syncpt.reserved[0] || cmd->wait_syncpt.reserved[1]) {\n\t\t\t\tSUBMIT_ERR(context, \"non-zero reserved value\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto free_job;\n\t\t\t}\n\n\t\t\tif (cmd->wait_syncpt.id != args->syncpt.id) {\n\t\t\t\tSUBMIT_ERR(context, \"syncpoint ID in CMD_WAIT_SYNCPT_RELATIVE is not used by the job\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto free_job;\n\t\t\t}\n\n\t\t\thost1x_job_add_wait(job, cmd->wait_syncpt.id, cmd->wait_syncpt.value,\n\t\t\t\t\t    true, class);\n\t\t} else {\n\t\t\tSUBMIT_ERR(context, \"unknown cmd type\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto free_job;\n\t\t}\n\t}\n\n\tif (gather_offset == 0) {\n\t\tSUBMIT_ERR(context, \"job must have at least one gather\");\n\t\terr = -EINVAL;\n\t\tgoto free_job;\n\t}\n\n\tgoto done;\n\nfree_job:\n\thost1x_job_put(job);\n\tjob = ERR_PTR(err);\n\ndone:\n\tkvfree(cmds);\n\n\treturn job;\n}\n\nstatic void release_job(struct host1x_job *job)\n{\n\tstruct tegra_drm_client *client = container_of(job->client, struct tegra_drm_client, base);\n\tstruct tegra_drm_submit_data *job_data = job->user_data;\n\tu32 i;\n\n\tif (job->memory_context)\n\t\thost1x_memory_context_put(job->memory_context);\n\n\tfor (i = 0; i < job_data->num_used_mappings; i++)\n\t\ttegra_drm_mapping_put(job_data->used_mappings[i].mapping);\n\n\tkfree(job_data->used_mappings);\n\tkfree(job_data);\n\n\tpm_runtime_mark_last_busy(client->base.dev);\n\tpm_runtime_put_autosuspend(client->base.dev);\n}\n\nint tegra_drm_ioctl_channel_submit(struct drm_device *drm, void *data,\n\t\t\t\t   struct drm_file *file)\n{\n\tstruct tegra_drm_file *fpriv = file->driver_priv;\n\tstruct drm_tegra_channel_submit *args = data;\n\tstruct tegra_drm_submit_data *job_data;\n\tstruct drm_syncobj *syncobj = NULL;\n\tstruct tegra_drm_context *context;\n\tstruct host1x_job *job;\n\tstruct gather_bo *bo;\n\tu32 i;\n\tint err;\n\n\tmutex_lock(&fpriv->lock);\n\n\tcontext = xa_load(&fpriv->contexts, args->context);\n\tif (!context) {\n\t\tmutex_unlock(&fpriv->lock);\n\t\tpr_err_ratelimited(\"%s: %s: invalid channel context '%#x'\", __func__,\n\t\t\t\t   current->comm, args->context);\n\t\treturn -EINVAL;\n\t}\n\n\tif (args->syncobj_in) {\n\t\tstruct dma_fence *fence;\n\n\t\terr = drm_syncobj_find_fence(file, args->syncobj_in, 0, 0, &fence);\n\t\tif (err) {\n\t\t\tSUBMIT_ERR(context, \"invalid syncobj_in '%#x'\", args->syncobj_in);\n\t\t\tgoto unlock;\n\t\t}\n\n\t\terr = dma_fence_wait_timeout(fence, true, msecs_to_jiffies(10000));\n\t\tdma_fence_put(fence);\n\t\tif (err) {\n\t\t\tSUBMIT_ERR(context, \"wait for syncobj_in timed out\");\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\tif (args->syncobj_out) {\n\t\tsyncobj = drm_syncobj_find(file, args->syncobj_out);\n\t\tif (!syncobj) {\n\t\t\tSUBMIT_ERR(context, \"invalid syncobj_out '%#x'\", args->syncobj_out);\n\t\t\terr = -ENOENT;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\t \n\terr = submit_copy_gather_data(&bo, drm->dev, context, args);\n\tif (err)\n\t\tgoto unlock;\n\n\tjob_data = kzalloc(sizeof(*job_data), GFP_KERNEL);\n\tif (!job_data) {\n\t\tSUBMIT_ERR(context, \"failed to allocate memory for job data\");\n\t\terr = -ENOMEM;\n\t\tgoto put_bo;\n\t}\n\n\t \n\terr = submit_process_bufs(context, bo, args, job_data);\n\tif (err)\n\t\tgoto free_job_data;\n\n\t \n\tjob = submit_create_job(context, bo, args, job_data, &fpriv->syncpoints);\n\tif (IS_ERR(job)) {\n\t\terr = PTR_ERR(job);\n\t\tgoto free_job_data;\n\t}\n\n\t \n\terr = host1x_job_pin(job, context->client->base.dev);\n\tif (err) {\n\t\tSUBMIT_ERR(context, \"failed to pin job: %d\", err);\n\t\tgoto put_job;\n\t}\n\n\tif (context->client->ops->get_streamid_offset) {\n\t\terr = context->client->ops->get_streamid_offset(\n\t\t\tcontext->client, &job->engine_streamid_offset);\n\t\tif (err) {\n\t\t\tSUBMIT_ERR(context, \"failed to get streamid offset: %d\", err);\n\t\t\tgoto unpin_job;\n\t\t}\n\t}\n\n\tif (context->memory_context && context->client->ops->can_use_memory_ctx) {\n\t\tbool supported;\n\n\t\terr = context->client->ops->can_use_memory_ctx(context->client, &supported);\n\t\tif (err) {\n\t\t\tSUBMIT_ERR(context, \"failed to detect if engine can use memory context: %d\", err);\n\t\t\tgoto unpin_job;\n\t\t}\n\n\t\tif (supported) {\n\t\t\tjob->memory_context = context->memory_context;\n\t\t\thost1x_memory_context_get(job->memory_context);\n\t\t}\n\t} else if (context->client->ops->get_streamid_offset) {\n\t\t \n\t\tif (!tegra_dev_iommu_get_stream_id(context->client->base.dev,\n\t\t\t\t\t\t   &job->engine_fallback_streamid))\n\t\t\tjob->engine_fallback_streamid = TEGRA_STREAM_ID_BYPASS;\n\t}\n\n\t \n\terr = pm_runtime_resume_and_get(context->client->base.dev);\n\tif (err < 0) {\n\t\tSUBMIT_ERR(context, \"could not power up engine: %d\", err);\n\t\tgoto put_memory_context;\n\t}\n\n\tjob->user_data = job_data;\n\tjob->release = release_job;\n\tjob->timeout = 10000;\n\n\t \n\tjob_data = NULL;\n\n\t \n\terr = host1x_job_submit(job);\n\tif (err) {\n\t\tSUBMIT_ERR(context, \"host1x job submission failed: %d\", err);\n\t\tgoto unpin_job;\n\t}\n\n\t \n\targs->syncpt.value = job->syncpt_end;\n\n\tif (syncobj) {\n\t\tstruct dma_fence *fence = host1x_fence_create(job->syncpt, job->syncpt_end, true);\n\t\tif (IS_ERR(fence)) {\n\t\t\terr = PTR_ERR(fence);\n\t\t\tSUBMIT_ERR(context, \"failed to create postfence: %d\", err);\n\t\t}\n\n\t\tdrm_syncobj_replace_fence(syncobj, fence);\n\t}\n\n\tgoto put_job;\n\nput_memory_context:\n\tif (job->memory_context)\n\t\thost1x_memory_context_put(job->memory_context);\nunpin_job:\n\thost1x_job_unpin(job);\nput_job:\n\thost1x_job_put(job);\nfree_job_data:\n\tif (job_data && job_data->used_mappings) {\n\t\tfor (i = 0; i < job_data->num_used_mappings; i++)\n\t\t\ttegra_drm_mapping_put(job_data->used_mappings[i].mapping);\n\n\t\tkfree(job_data->used_mappings);\n\t}\n\n\tkfree(job_data);\nput_bo:\n\tgather_bo_put(&bo->base);\nunlock:\n\tif (syncobj)\n\t\tdrm_syncobj_put(syncobj);\n\n\tmutex_unlock(&fpriv->lock);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}