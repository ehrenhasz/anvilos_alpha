{
  "module_name": "etnaviv_gpu.c",
  "hash_id": "9e301330d6c2047134c38e7a7cab8dd743854fa4382312e9841b2ab123bc737f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/etnaviv/etnaviv_gpu.c",
  "human_readable_source": "\n \n\n#include <linux/clk.h>\n#include <linux/component.h>\n#include <linux/delay.h>\n#include <linux/dma-fence.h>\n#include <linux/dma-mapping.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/pm_runtime.h>\n#include <linux/regulator/consumer.h>\n#include <linux/thermal.h>\n\n#include \"etnaviv_cmdbuf.h\"\n#include \"etnaviv_dump.h\"\n#include \"etnaviv_gpu.h\"\n#include \"etnaviv_gem.h\"\n#include \"etnaviv_mmu.h\"\n#include \"etnaviv_perfmon.h\"\n#include \"etnaviv_sched.h\"\n#include \"common.xml.h\"\n#include \"state.xml.h\"\n#include \"state_hi.xml.h\"\n#include \"cmdstream.xml.h\"\n\nstatic const struct platform_device_id gpu_ids[] = {\n\t{ .name = \"etnaviv-gpu,2d\" },\n\t{ },\n};\n\n \n\nint etnaviv_gpu_get_param(struct etnaviv_gpu *gpu, u32 param, u64 *value)\n{\n\tstruct etnaviv_drm_private *priv = gpu->drm->dev_private;\n\n\tswitch (param) {\n\tcase ETNAVIV_PARAM_GPU_MODEL:\n\t\t*value = gpu->identity.model;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_REVISION:\n\t\t*value = gpu->identity.revision;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_0:\n\t\t*value = gpu->identity.features;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_1:\n\t\t*value = gpu->identity.minor_features0;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_2:\n\t\t*value = gpu->identity.minor_features1;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_3:\n\t\t*value = gpu->identity.minor_features2;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_4:\n\t\t*value = gpu->identity.minor_features3;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_5:\n\t\t*value = gpu->identity.minor_features4;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_6:\n\t\t*value = gpu->identity.minor_features5;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_7:\n\t\t*value = gpu->identity.minor_features6;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_8:\n\t\t*value = gpu->identity.minor_features7;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_9:\n\t\t*value = gpu->identity.minor_features8;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_10:\n\t\t*value = gpu->identity.minor_features9;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_11:\n\t\t*value = gpu->identity.minor_features10;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_FEATURES_12:\n\t\t*value = gpu->identity.minor_features11;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_STREAM_COUNT:\n\t\t*value = gpu->identity.stream_count;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_REGISTER_MAX:\n\t\t*value = gpu->identity.register_max;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_THREAD_COUNT:\n\t\t*value = gpu->identity.thread_count;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_VERTEX_CACHE_SIZE:\n\t\t*value = gpu->identity.vertex_cache_size;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_SHADER_CORE_COUNT:\n\t\t*value = gpu->identity.shader_core_count;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_PIXEL_PIPES:\n\t\t*value = gpu->identity.pixel_pipes;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_VERTEX_OUTPUT_BUFFER_SIZE:\n\t\t*value = gpu->identity.vertex_output_buffer_size;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_BUFFER_SIZE:\n\t\t*value = gpu->identity.buffer_size;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_INSTRUCTION_COUNT:\n\t\t*value = gpu->identity.instruction_count;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_NUM_CONSTANTS:\n\t\t*value = gpu->identity.num_constants;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_NUM_VARYINGS:\n\t\t*value = gpu->identity.varyings_count;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_SOFTPIN_START_ADDR:\n\t\tif (priv->mmu_global->version == ETNAVIV_IOMMU_V2)\n\t\t\t*value = ETNAVIV_SOFTPIN_START_ADDRESS;\n\t\telse\n\t\t\t*value = ~0ULL;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_PRODUCT_ID:\n\t\t*value = gpu->identity.product_id;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_CUSTOMER_ID:\n\t\t*value = gpu->identity.customer_id;\n\t\tbreak;\n\n\tcase ETNAVIV_PARAM_GPU_ECO_ID:\n\t\t*value = gpu->identity.eco_id;\n\t\tbreak;\n\n\tdefault:\n\t\tDBG(\"%s: invalid param: %u\", dev_name(gpu->dev), param);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n\n#define etnaviv_is_model_rev(gpu, mod, rev) \\\n\t((gpu)->identity.model == chipModel_##mod && \\\n\t (gpu)->identity.revision == rev)\n#define etnaviv_field(val, field) \\\n\t(((val) & field##__MASK) >> field##__SHIFT)\n\nstatic void etnaviv_hw_specs(struct etnaviv_gpu *gpu)\n{\n\tif (gpu->identity.minor_features0 &\n\t    chipMinorFeatures0_MORE_MINOR_FEATURES) {\n\t\tu32 specs[4];\n\t\tunsigned int streams;\n\n\t\tspecs[0] = gpu_read(gpu, VIVS_HI_CHIP_SPECS);\n\t\tspecs[1] = gpu_read(gpu, VIVS_HI_CHIP_SPECS_2);\n\t\tspecs[2] = gpu_read(gpu, VIVS_HI_CHIP_SPECS_3);\n\t\tspecs[3] = gpu_read(gpu, VIVS_HI_CHIP_SPECS_4);\n\n\t\tgpu->identity.stream_count = etnaviv_field(specs[0],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_STREAM_COUNT);\n\t\tgpu->identity.register_max = etnaviv_field(specs[0],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_REGISTER_MAX);\n\t\tgpu->identity.thread_count = etnaviv_field(specs[0],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_THREAD_COUNT);\n\t\tgpu->identity.vertex_cache_size = etnaviv_field(specs[0],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_VERTEX_CACHE_SIZE);\n\t\tgpu->identity.shader_core_count = etnaviv_field(specs[0],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_SHADER_CORE_COUNT);\n\t\tgpu->identity.pixel_pipes = etnaviv_field(specs[0],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_PIXEL_PIPES);\n\t\tgpu->identity.vertex_output_buffer_size =\n\t\t\tetnaviv_field(specs[0],\n\t\t\t\tVIVS_HI_CHIP_SPECS_VERTEX_OUTPUT_BUFFER_SIZE);\n\n\t\tgpu->identity.buffer_size = etnaviv_field(specs[1],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_2_BUFFER_SIZE);\n\t\tgpu->identity.instruction_count = etnaviv_field(specs[1],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_2_INSTRUCTION_COUNT);\n\t\tgpu->identity.num_constants = etnaviv_field(specs[1],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_2_NUM_CONSTANTS);\n\n\t\tgpu->identity.varyings_count = etnaviv_field(specs[2],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_3_VARYINGS_COUNT);\n\n\t\t \n\t\tstreams = etnaviv_field(specs[3],\n\t\t\t\t\tVIVS_HI_CHIP_SPECS_4_STREAM_COUNT);\n\t\tif (streams)\n\t\t\tgpu->identity.stream_count = streams;\n\t}\n\n\t \n\tif (gpu->identity.stream_count == 0) {\n\t\tif (gpu->identity.model >= 0x1000)\n\t\t\tgpu->identity.stream_count = 4;\n\t\telse\n\t\t\tgpu->identity.stream_count = 1;\n\t}\n\n\t \n\tif (gpu->identity.register_max)\n\t\tgpu->identity.register_max = 1 << gpu->identity.register_max;\n\telse if (gpu->identity.model == chipModel_GC400)\n\t\tgpu->identity.register_max = 32;\n\telse\n\t\tgpu->identity.register_max = 64;\n\n\t \n\tif (gpu->identity.thread_count)\n\t\tgpu->identity.thread_count = 1 << gpu->identity.thread_count;\n\telse if (gpu->identity.model == chipModel_GC400)\n\t\tgpu->identity.thread_count = 64;\n\telse if (gpu->identity.model == chipModel_GC500 ||\n\t\t gpu->identity.model == chipModel_GC530)\n\t\tgpu->identity.thread_count = 128;\n\telse\n\t\tgpu->identity.thread_count = 256;\n\n\tif (gpu->identity.vertex_cache_size == 0)\n\t\tgpu->identity.vertex_cache_size = 8;\n\n\tif (gpu->identity.shader_core_count == 0) {\n\t\tif (gpu->identity.model >= 0x1000)\n\t\t\tgpu->identity.shader_core_count = 2;\n\t\telse\n\t\t\tgpu->identity.shader_core_count = 1;\n\t}\n\n\tif (gpu->identity.pixel_pipes == 0)\n\t\tgpu->identity.pixel_pipes = 1;\n\n\t \n\tif (gpu->identity.vertex_output_buffer_size) {\n\t\tgpu->identity.vertex_output_buffer_size =\n\t\t\t1 << gpu->identity.vertex_output_buffer_size;\n\t} else if (gpu->identity.model == chipModel_GC400) {\n\t\tif (gpu->identity.revision < 0x4000)\n\t\t\tgpu->identity.vertex_output_buffer_size = 512;\n\t\telse if (gpu->identity.revision < 0x4200)\n\t\t\tgpu->identity.vertex_output_buffer_size = 256;\n\t\telse\n\t\t\tgpu->identity.vertex_output_buffer_size = 128;\n\t} else {\n\t\tgpu->identity.vertex_output_buffer_size = 512;\n\t}\n\n\tswitch (gpu->identity.instruction_count) {\n\tcase 0:\n\t\tif (etnaviv_is_model_rev(gpu, GC2000, 0x5108) ||\n\t\t    gpu->identity.model == chipModel_GC880)\n\t\t\tgpu->identity.instruction_count = 512;\n\t\telse\n\t\t\tgpu->identity.instruction_count = 256;\n\t\tbreak;\n\n\tcase 1:\n\t\tgpu->identity.instruction_count = 1024;\n\t\tbreak;\n\n\tcase 2:\n\t\tgpu->identity.instruction_count = 2048;\n\t\tbreak;\n\n\tdefault:\n\t\tgpu->identity.instruction_count = 256;\n\t\tbreak;\n\t}\n\n\tif (gpu->identity.num_constants == 0)\n\t\tgpu->identity.num_constants = 168;\n\n\tif (gpu->identity.varyings_count == 0) {\n\t\tif (gpu->identity.minor_features1 & chipMinorFeatures1_HALTI0)\n\t\t\tgpu->identity.varyings_count = 12;\n\t\telse\n\t\t\tgpu->identity.varyings_count = 8;\n\t}\n\n\t \n\tif (etnaviv_is_model_rev(gpu, GC5000, 0x5434) ||\n\t    etnaviv_is_model_rev(gpu, GC4000, 0x5222) ||\n\t    etnaviv_is_model_rev(gpu, GC4000, 0x5245) ||\n\t    etnaviv_is_model_rev(gpu, GC4000, 0x5208) ||\n\t    etnaviv_is_model_rev(gpu, GC3000, 0x5435) ||\n\t    etnaviv_is_model_rev(gpu, GC2200, 0x5244) ||\n\t    etnaviv_is_model_rev(gpu, GC2100, 0x5108) ||\n\t    etnaviv_is_model_rev(gpu, GC2000, 0x5108) ||\n\t    etnaviv_is_model_rev(gpu, GC1500, 0x5246) ||\n\t    etnaviv_is_model_rev(gpu, GC880, 0x5107) ||\n\t    etnaviv_is_model_rev(gpu, GC880, 0x5106))\n\t\tgpu->identity.varyings_count -= 1;\n}\n\nstatic void etnaviv_hw_identify(struct etnaviv_gpu *gpu)\n{\n\tu32 chipIdentity;\n\n\tchipIdentity = gpu_read(gpu, VIVS_HI_CHIP_IDENTITY);\n\n\t \n\tif (etnaviv_field(chipIdentity, VIVS_HI_CHIP_IDENTITY_FAMILY) == 0x01) {\n\t\tgpu->identity.model    = chipModel_GC500;\n\t\tgpu->identity.revision = etnaviv_field(chipIdentity,\n\t\t\t\t\t VIVS_HI_CHIP_IDENTITY_REVISION);\n\t} else {\n\t\tu32 chipDate = gpu_read(gpu, VIVS_HI_CHIP_DATE);\n\n\t\tgpu->identity.model = gpu_read(gpu, VIVS_HI_CHIP_MODEL);\n\t\tgpu->identity.revision = gpu_read(gpu, VIVS_HI_CHIP_REV);\n\t\tgpu->identity.customer_id = gpu_read(gpu, VIVS_HI_CHIP_CUSTOMER_ID);\n\n\t\t \n\t\tif (!etnaviv_is_model_rev(gpu, GC600, 0x19)) {\n\t\t\tgpu->identity.product_id = gpu_read(gpu, VIVS_HI_CHIP_PRODUCT_ID);\n\t\t\tgpu->identity.eco_id = gpu_read(gpu, VIVS_HI_CHIP_ECO_ID);\n\t\t}\n\n\t\t \n\t\tif ((gpu->identity.model & 0xff00) == 0x0400 &&\n\t\t    gpu->identity.model != chipModel_GC420) {\n\t\t\tgpu->identity.model = gpu->identity.model & 0x0400;\n\t\t}\n\n\t\t \n\t\tif (etnaviv_is_model_rev(gpu, GC300, 0x2201)) {\n\t\t\tu32 chipTime = gpu_read(gpu, VIVS_HI_CHIP_TIME);\n\n\t\t\tif (chipDate == 0x20080814 && chipTime == 0x12051100) {\n\t\t\t\t \n\t\t\t\tgpu->identity.revision = 0x1051;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (etnaviv_is_model_rev(gpu, GC2000, 0xffff5450)) {\n\t\t\tgpu->identity.model = chipModel_GC3000;\n\t\t\tgpu->identity.revision &= 0xffff;\n\t\t}\n\n\t\tif (etnaviv_is_model_rev(gpu, GC1000, 0x5037) && (chipDate == 0x20120617))\n\t\t\tgpu->identity.eco_id = 1;\n\n\t\tif (etnaviv_is_model_rev(gpu, GC320, 0x5303) && (chipDate == 0x20140511))\n\t\t\tgpu->identity.eco_id = 1;\n\t}\n\n\tdev_info(gpu->dev, \"model: GC%x, revision: %x\\n\",\n\t\t gpu->identity.model, gpu->identity.revision);\n\n\tgpu->idle_mask = ~VIVS_HI_IDLE_STATE_AXI_LP;\n\t \n\tif (etnaviv_fill_identity_from_hwdb(gpu))\n\t\treturn;\n\n\tgpu->identity.features = gpu_read(gpu, VIVS_HI_CHIP_FEATURE);\n\n\t \n\tif (gpu->identity.model == chipModel_GC700)\n\t\tgpu->identity.features &= ~chipFeatures_FAST_CLEAR;\n\n\t \n\tif ((gpu->identity.model == chipModel_GC500 &&\n\t     gpu->identity.revision <= 2) ||\n\t    gpu->identity.model == chipModel_GC300)\n\t\tgpu->identity.features |= chipFeatures_PIPE_2D;\n\n\tif ((gpu->identity.model == chipModel_GC500 &&\n\t     gpu->identity.revision < 2) ||\n\t    (gpu->identity.model == chipModel_GC300 &&\n\t     gpu->identity.revision < 0x2000)) {\n\n\t\t \n\t\tgpu->identity.minor_features0 = 0;\n\t\tgpu->identity.minor_features1 = 0;\n\t\tgpu->identity.minor_features2 = 0;\n\t\tgpu->identity.minor_features3 = 0;\n\t\tgpu->identity.minor_features4 = 0;\n\t\tgpu->identity.minor_features5 = 0;\n\t} else\n\t\tgpu->identity.minor_features0 =\n\t\t\t\tgpu_read(gpu, VIVS_HI_CHIP_MINOR_FEATURE_0);\n\n\tif (gpu->identity.minor_features0 &\n\t    chipMinorFeatures0_MORE_MINOR_FEATURES) {\n\t\tgpu->identity.minor_features1 =\n\t\t\t\tgpu_read(gpu, VIVS_HI_CHIP_MINOR_FEATURE_1);\n\t\tgpu->identity.minor_features2 =\n\t\t\t\tgpu_read(gpu, VIVS_HI_CHIP_MINOR_FEATURE_2);\n\t\tgpu->identity.minor_features3 =\n\t\t\t\tgpu_read(gpu, VIVS_HI_CHIP_MINOR_FEATURE_3);\n\t\tgpu->identity.minor_features4 =\n\t\t\t\tgpu_read(gpu, VIVS_HI_CHIP_MINOR_FEATURE_4);\n\t\tgpu->identity.minor_features5 =\n\t\t\t\tgpu_read(gpu, VIVS_HI_CHIP_MINOR_FEATURE_5);\n\t}\n\n\t \n\tif (gpu->identity.model == chipModel_GC600 ||\n\t    gpu->identity.model == chipModel_GC300)\n\t\tgpu->idle_mask = VIVS_HI_IDLE_STATE_TX |\n\t\t\t\t VIVS_HI_IDLE_STATE_RA |\n\t\t\t\t VIVS_HI_IDLE_STATE_SE |\n\t\t\t\t VIVS_HI_IDLE_STATE_PA |\n\t\t\t\t VIVS_HI_IDLE_STATE_SH |\n\t\t\t\t VIVS_HI_IDLE_STATE_PE |\n\t\t\t\t VIVS_HI_IDLE_STATE_DE |\n\t\t\t\t VIVS_HI_IDLE_STATE_FE;\n\n\tetnaviv_hw_specs(gpu);\n}\n\nstatic void etnaviv_gpu_load_clock(struct etnaviv_gpu *gpu, u32 clock)\n{\n\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, clock |\n\t\t  VIVS_HI_CLOCK_CONTROL_FSCALE_CMD_LOAD);\n\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, clock);\n}\n\nstatic void etnaviv_gpu_update_clock(struct etnaviv_gpu *gpu)\n{\n\tif (gpu->identity.minor_features2 &\n\t    chipMinorFeatures2_DYNAMIC_FREQUENCY_SCALING) {\n\t\tclk_set_rate(gpu->clk_core,\n\t\t\t     gpu->base_rate_core >> gpu->freq_scale);\n\t\tclk_set_rate(gpu->clk_shader,\n\t\t\t     gpu->base_rate_shader >> gpu->freq_scale);\n\t} else {\n\t\tunsigned int fscale = 1 << (6 - gpu->freq_scale);\n\t\tu32 clock = gpu_read(gpu, VIVS_HI_CLOCK_CONTROL);\n\n\t\tclock &= ~VIVS_HI_CLOCK_CONTROL_FSCALE_VAL__MASK;\n\t\tclock |= VIVS_HI_CLOCK_CONTROL_FSCALE_VAL(fscale);\n\t\tetnaviv_gpu_load_clock(gpu, clock);\n\t}\n\n\t \n\tgpu->fe_waitcycles = clamp(gpu->base_rate_core >> (15 - gpu->freq_scale),\n\t\t\t\t   200UL, 0xffffUL);\n}\n\nstatic int etnaviv_hw_reset(struct etnaviv_gpu *gpu)\n{\n\tu32 control, idle;\n\tunsigned long timeout;\n\tbool failed = true;\n\n\t \n\ttimeout = jiffies + msecs_to_jiffies(1000);\n\n\twhile (time_is_after_jiffies(timeout)) {\n\t\t \n\t\tunsigned int fscale = 1 << (6 - gpu->freq_scale);\n\t\tcontrol = VIVS_HI_CLOCK_CONTROL_FSCALE_VAL(fscale);\n\t\tetnaviv_gpu_load_clock(gpu, control);\n\n\t\t \n\t\tcontrol |= VIVS_HI_CLOCK_CONTROL_ISOLATE_GPU;\n\t\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, control);\n\n\t\tif (gpu->sec_mode == ETNA_SEC_KERNEL) {\n\t\t\tgpu_write(gpu, VIVS_MMUv2_AHB_CONTROL,\n\t\t\t          VIVS_MMUv2_AHB_CONTROL_RESET);\n\t\t} else {\n\t\t\t \n\t\t\tcontrol |= VIVS_HI_CLOCK_CONTROL_SOFT_RESET;\n\t\t\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, control);\n\t\t}\n\n\t\t \n\t\tusleep_range(10, 20);\n\n\t\t \n\t\tcontrol &= ~VIVS_HI_CLOCK_CONTROL_SOFT_RESET;\n\t\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, control);\n\n\t\t \n\t\tcontrol &= ~VIVS_HI_CLOCK_CONTROL_ISOLATE_GPU;\n\t\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, control);\n\n\t\t \n\t\tidle = gpu_read(gpu, VIVS_HI_IDLE_STATE);\n\n\t\t \n\t\tif ((idle & VIVS_HI_IDLE_STATE_FE) == 0) {\n\t\t\tdev_dbg(gpu->dev, \"FE is not idle\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tcontrol = gpu_read(gpu, VIVS_HI_CLOCK_CONTROL);\n\n\t\t \n\t\tif (((control & VIVS_HI_CLOCK_CONTROL_IDLE_3D) == 0) ||\n\t\t    ((control & VIVS_HI_CLOCK_CONTROL_IDLE_2D) == 0)) {\n\t\t\tdev_dbg(gpu->dev, \"GPU is not idle\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tcontrol |= VIVS_HI_CLOCK_CONTROL_DISABLE_DEBUG_REGISTERS;\n\t\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, control);\n\n\t\tfailed = false;\n\t\tbreak;\n\t}\n\n\tif (failed) {\n\t\tidle = gpu_read(gpu, VIVS_HI_IDLE_STATE);\n\t\tcontrol = gpu_read(gpu, VIVS_HI_CLOCK_CONTROL);\n\n\t\tdev_err(gpu->dev, \"GPU failed to reset: FE %sidle, 3D %sidle, 2D %sidle\\n\",\n\t\t\tidle & VIVS_HI_IDLE_STATE_FE ? \"\" : \"not \",\n\t\t\tcontrol & VIVS_HI_CLOCK_CONTROL_IDLE_3D ? \"\" : \"not \",\n\t\t\tcontrol & VIVS_HI_CLOCK_CONTROL_IDLE_2D ? \"\" : \"not \");\n\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tetnaviv_gpu_update_clock(gpu);\n\n\tgpu->state = ETNA_GPU_STATE_RESET;\n\tgpu->exec_state = -1;\n\tif (gpu->mmu_context)\n\t\tetnaviv_iommu_context_put(gpu->mmu_context);\n\tgpu->mmu_context = NULL;\n\n\treturn 0;\n}\n\nstatic void etnaviv_gpu_enable_mlcg(struct etnaviv_gpu *gpu)\n{\n\tu32 pmc, ppc;\n\n\t \n\tppc = gpu_read_power(gpu, VIVS_PM_POWER_CONTROLS);\n\tppc |= VIVS_PM_POWER_CONTROLS_ENABLE_MODULE_CLOCK_GATING;\n\n\t \n\tif (gpu->identity.revision == 0x4301 ||\n\t    gpu->identity.revision == 0x4302)\n\t\tppc |= VIVS_PM_POWER_CONTROLS_DISABLE_STALL_MODULE_CLOCK_GATING;\n\n\tgpu_write_power(gpu, VIVS_PM_POWER_CONTROLS, ppc);\n\n\tpmc = gpu_read_power(gpu, VIVS_PM_MODULE_CONTROLS);\n\n\t \n\tif (gpu->identity.model >= chipModel_GC400 &&\n\t    gpu->identity.model != chipModel_GC420 &&\n\t    !(gpu->identity.minor_features3 & chipMinorFeatures3_BUG_FIXES12))\n\t\tpmc |= VIVS_PM_MODULE_CONTROLS_DISABLE_MODULE_CLOCK_GATING_PA;\n\n\t \n\tif (gpu->identity.revision < 0x5000 &&\n\t    gpu->identity.minor_features0 & chipMinorFeatures0_HZ &&\n\t    !(gpu->identity.minor_features1 &\n\t      chipMinorFeatures1_DISABLE_PE_GATING))\n\t\tpmc |= VIVS_PM_MODULE_CONTROLS_DISABLE_MODULE_CLOCK_GATING_PE;\n\n\tif (gpu->identity.revision < 0x5422)\n\t\tpmc |= BIT(15);  \n\n\t \n\tif (etnaviv_is_model_rev(gpu, GC4000, 0x5222) ||\n\t    etnaviv_is_model_rev(gpu, GC2000, 0x5108) ||\n\t    etnaviv_is_model_rev(gpu, GC2000, 0x6202) ||\n\t    etnaviv_is_model_rev(gpu, GC2000, 0x6203))\n\t\tpmc |= VIVS_PM_MODULE_CONTROLS_DISABLE_MODULE_CLOCK_GATING_TX;\n\n\t \n\tif (etnaviv_is_model_rev(gpu, GC7000, 0x6202))\n\t\tpmc |= VIVS_PM_MODULE_CONTROLS_DISABLE_MODULE_CLOCK_GATING_SE |\n\t\t       VIVS_PM_MODULE_CONTROLS_DISABLE_MODULE_CLOCK_GATING_RA;\n\n\tpmc |= VIVS_PM_MODULE_CONTROLS_DISABLE_MODULE_CLOCK_GATING_RA_HZ;\n\tpmc |= VIVS_PM_MODULE_CONTROLS_DISABLE_MODULE_CLOCK_GATING_RA_EZ;\n\n\tgpu_write_power(gpu, VIVS_PM_MODULE_CONTROLS, pmc);\n}\n\nvoid etnaviv_gpu_start_fe(struct etnaviv_gpu *gpu, u32 address, u16 prefetch)\n{\n\tgpu_write(gpu, VIVS_FE_COMMAND_ADDRESS, address);\n\tgpu_write(gpu, VIVS_FE_COMMAND_CONTROL,\n\t\t  VIVS_FE_COMMAND_CONTROL_ENABLE |\n\t\t  VIVS_FE_COMMAND_CONTROL_PREFETCH(prefetch));\n\n\tif (gpu->sec_mode == ETNA_SEC_KERNEL) {\n\t\tgpu_write(gpu, VIVS_MMUv2_SEC_COMMAND_CONTROL,\n\t\t\t  VIVS_MMUv2_SEC_COMMAND_CONTROL_ENABLE |\n\t\t\t  VIVS_MMUv2_SEC_COMMAND_CONTROL_PREFETCH(prefetch));\n\t}\n}\n\nstatic void etnaviv_gpu_start_fe_idleloop(struct etnaviv_gpu *gpu,\n\t\t\t\t\t  struct etnaviv_iommu_context *context)\n{\n\tu16 prefetch;\n\tu32 address;\n\n\tWARN_ON(gpu->state != ETNA_GPU_STATE_INITIALIZED);\n\n\t \n\tetnaviv_iommu_restore(gpu, context);\n\n\t \n\tprefetch = etnaviv_buffer_init(gpu);\n\taddress = etnaviv_cmdbuf_get_va(&gpu->buffer,\n\t\t\t\t\t&gpu->mmu_context->cmdbuf_mapping);\n\n\tetnaviv_gpu_start_fe(gpu, address, prefetch);\n\n\tgpu->state = ETNA_GPU_STATE_RUNNING;\n}\n\nstatic void etnaviv_gpu_setup_pulse_eater(struct etnaviv_gpu *gpu)\n{\n\t \n\tu32 pulse_eater = 0x01590880;\n\n\tif (etnaviv_is_model_rev(gpu, GC4000, 0x5208) ||\n\t    etnaviv_is_model_rev(gpu, GC4000, 0x5222)) {\n\t\tpulse_eater |= BIT(23);\n\n\t}\n\n\tif (etnaviv_is_model_rev(gpu, GC1000, 0x5039) ||\n\t    etnaviv_is_model_rev(gpu, GC1000, 0x5040)) {\n\t\tpulse_eater &= ~BIT(16);\n\t\tpulse_eater |= BIT(17);\n\t}\n\n\tif ((gpu->identity.revision > 0x5420) &&\n\t    (gpu->identity.features & chipFeatures_PIPE_3D))\n\t{\n\t\t \n\t\tpulse_eater = gpu_read_power(gpu, VIVS_PM_PULSE_EATER);\n\t\tpulse_eater |= BIT(18);\n\t}\n\n\tgpu_write_power(gpu, VIVS_PM_PULSE_EATER, pulse_eater);\n}\n\nstatic void etnaviv_gpu_hw_init(struct etnaviv_gpu *gpu)\n{\n\tWARN_ON(!(gpu->state == ETNA_GPU_STATE_IDENTIFIED ||\n\t\t  gpu->state == ETNA_GPU_STATE_RESET));\n\n\tif ((etnaviv_is_model_rev(gpu, GC320, 0x5007) ||\n\t     etnaviv_is_model_rev(gpu, GC320, 0x5220)) &&\n\t    gpu_read(gpu, VIVS_HI_CHIP_TIME) != 0x2062400) {\n\t\tu32 mc_memory_debug;\n\n\t\tmc_memory_debug = gpu_read(gpu, VIVS_MC_DEBUG_MEMORY) & ~0xff;\n\n\t\tif (gpu->identity.revision == 0x5007)\n\t\t\tmc_memory_debug |= 0x0c;\n\t\telse\n\t\t\tmc_memory_debug |= 0x08;\n\n\t\tgpu_write(gpu, VIVS_MC_DEBUG_MEMORY, mc_memory_debug);\n\t}\n\n\t \n\tetnaviv_gpu_enable_mlcg(gpu);\n\n\t \n\tgpu_write(gpu, VIVS_HI_AXI_CONFIG,\n\t\t  VIVS_HI_AXI_CONFIG_AWCACHE(2) |\n\t\t  VIVS_HI_AXI_CONFIG_ARCACHE(2));\n\n\t \n\tif (etnaviv_is_model_rev(gpu, GC2000, 0x5108)) {\n\t\tu32 bus_config = gpu_read(gpu, VIVS_MC_BUS_CONFIG);\n\t\tbus_config &= ~(VIVS_MC_BUS_CONFIG_FE_BUS_CONFIG__MASK |\n\t\t\t\tVIVS_MC_BUS_CONFIG_TX_BUS_CONFIG__MASK);\n\t\tbus_config |= VIVS_MC_BUS_CONFIG_FE_BUS_CONFIG(1) |\n\t\t\t      VIVS_MC_BUS_CONFIG_TX_BUS_CONFIG(0);\n\t\tgpu_write(gpu, VIVS_MC_BUS_CONFIG, bus_config);\n\t}\n\n\tif (gpu->sec_mode == ETNA_SEC_KERNEL) {\n\t\tu32 val = gpu_read(gpu, VIVS_MMUv2_AHB_CONTROL);\n\t\tval |= VIVS_MMUv2_AHB_CONTROL_NONSEC_ACCESS;\n\t\tgpu_write(gpu, VIVS_MMUv2_AHB_CONTROL, val);\n\t}\n\n\t \n\tetnaviv_gpu_setup_pulse_eater(gpu);\n\n\tgpu_write(gpu, VIVS_HI_INTR_ENBL, ~0U);\n\n\tgpu->state = ETNA_GPU_STATE_INITIALIZED;\n}\n\nint etnaviv_gpu_init(struct etnaviv_gpu *gpu)\n{\n\tstruct etnaviv_drm_private *priv = gpu->drm->dev_private;\n\tdma_addr_t cmdbuf_paddr;\n\tint ret, i;\n\n\tret = pm_runtime_get_sync(gpu->dev);\n\tif (ret < 0) {\n\t\tdev_err(gpu->dev, \"Failed to enable GPU power domain\\n\");\n\t\tgoto pm_put;\n\t}\n\n\tetnaviv_hw_identify(gpu);\n\n\tif (gpu->identity.model == 0) {\n\t\tdev_err(gpu->dev, \"Unknown GPU model\\n\");\n\t\tret = -ENXIO;\n\t\tgoto fail;\n\t}\n\n\tif (gpu->identity.nn_core_count > 0)\n\t\tdev_warn(gpu->dev, \"etnaviv has been instantiated on a NPU, \"\n                                   \"for which the UAPI is still experimental\\n\");\n\n\t \n\tif (gpu->identity.features & chipFeatures_PIPE_VG &&\n\t    gpu->identity.features & chipFeatures_FE20) {\n\t\tdev_info(gpu->dev, \"Ignoring GPU with VG and FE2.0\\n\");\n\t\tret = -ENXIO;\n\t\tgoto fail;\n\t}\n\n\t \n\tif ((gpu->identity.minor_features7 & chipMinorFeatures7_BIT_SECURITY) &&\n\t    (gpu->identity.minor_features10 & chipMinorFeatures10_SECURITY_AHB))\n\t\tgpu->sec_mode = ETNA_SEC_KERNEL;\n\n\tgpu->state = ETNA_GPU_STATE_IDENTIFIED;\n\n\tret = etnaviv_hw_reset(gpu);\n\tif (ret) {\n\t\tdev_err(gpu->dev, \"GPU reset failed\\n\");\n\t\tgoto fail;\n\t}\n\n\tret = etnaviv_iommu_global_init(gpu);\n\tif (ret)\n\t\tgoto fail;\n\n\t \n\tif (dma_addressing_limited(gpu->dev))\n\t\tpriv->shm_gfp_mask |= GFP_DMA32;\n\n\t \n\tret = etnaviv_cmdbuf_init(priv->cmdbuf_suballoc, &gpu->buffer,\n\t\t\t\t  PAGE_SIZE);\n\tif (ret) {\n\t\tdev_err(gpu->dev, \"could not create command buffer\\n\");\n\t\tgoto fail;\n\t}\n\n\t \n\tcmdbuf_paddr = ALIGN_DOWN(etnaviv_cmdbuf_get_pa(&gpu->buffer), SZ_128M);\n\n\tif (!(gpu->identity.features & chipFeatures_PIPE_3D) ||\n\t    (gpu->identity.minor_features0 & chipMinorFeatures0_MC20)) {\n\t\tif (cmdbuf_paddr >= SZ_2G)\n\t\t\tpriv->mmu_global->memory_base = SZ_2G;\n\t\telse\n\t\t\tpriv->mmu_global->memory_base = cmdbuf_paddr;\n\t} else if (cmdbuf_paddr + SZ_128M >= SZ_2G) {\n\t\tdev_info(gpu->dev,\n\t\t\t \"Need to move linear window on MC1.0, disabling TS\\n\");\n\t\tgpu->identity.features &= ~chipFeatures_FAST_CLEAR;\n\t\tpriv->mmu_global->memory_base = SZ_2G;\n\t}\n\n\t \n\tspin_lock_init(&gpu->event_spinlock);\n\tinit_completion(&gpu->event_free);\n\tbitmap_zero(gpu->event_bitmap, ETNA_NR_EVENTS);\n\tfor (i = 0; i < ARRAY_SIZE(gpu->event); i++)\n\t\tcomplete(&gpu->event_free);\n\n\t \n\tmutex_lock(&gpu->lock);\n\tetnaviv_gpu_hw_init(gpu);\n\tmutex_unlock(&gpu->lock);\n\n\tpm_runtime_mark_last_busy(gpu->dev);\n\tpm_runtime_put_autosuspend(gpu->dev);\n\n\treturn 0;\n\nfail:\n\tpm_runtime_mark_last_busy(gpu->dev);\npm_put:\n\tpm_runtime_put_autosuspend(gpu->dev);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_DEBUG_FS\nstruct dma_debug {\n\tu32 address[2];\n\tu32 state[2];\n};\n\nstatic void verify_dma(struct etnaviv_gpu *gpu, struct dma_debug *debug)\n{\n\tu32 i;\n\n\tdebug->address[0] = gpu_read(gpu, VIVS_FE_DMA_ADDRESS);\n\tdebug->state[0]   = gpu_read(gpu, VIVS_FE_DMA_DEBUG_STATE);\n\n\tfor (i = 0; i < 500; i++) {\n\t\tdebug->address[1] = gpu_read(gpu, VIVS_FE_DMA_ADDRESS);\n\t\tdebug->state[1]   = gpu_read(gpu, VIVS_FE_DMA_DEBUG_STATE);\n\n\t\tif (debug->address[0] != debug->address[1])\n\t\t\tbreak;\n\n\t\tif (debug->state[0] != debug->state[1])\n\t\t\tbreak;\n\t}\n}\n\nint etnaviv_gpu_debugfs(struct etnaviv_gpu *gpu, struct seq_file *m)\n{\n\tstruct dma_debug debug;\n\tu32 dma_lo, dma_hi, axi, idle;\n\tint ret;\n\n\tseq_printf(m, \"%s Status:\\n\", dev_name(gpu->dev));\n\n\tret = pm_runtime_get_sync(gpu->dev);\n\tif (ret < 0)\n\t\tgoto pm_put;\n\n\tdma_lo = gpu_read(gpu, VIVS_FE_DMA_LOW);\n\tdma_hi = gpu_read(gpu, VIVS_FE_DMA_HIGH);\n\taxi = gpu_read(gpu, VIVS_HI_AXI_STATUS);\n\tidle = gpu_read(gpu, VIVS_HI_IDLE_STATE);\n\n\tverify_dma(gpu, &debug);\n\n\tseq_puts(m, \"\\tidentity\\n\");\n\tseq_printf(m, \"\\t model: 0x%x\\n\", gpu->identity.model);\n\tseq_printf(m, \"\\t revision: 0x%x\\n\", gpu->identity.revision);\n\tseq_printf(m, \"\\t product_id: 0x%x\\n\", gpu->identity.product_id);\n\tseq_printf(m, \"\\t customer_id: 0x%x\\n\", gpu->identity.customer_id);\n\tseq_printf(m, \"\\t eco_id: 0x%x\\n\", gpu->identity.eco_id);\n\n\tseq_puts(m, \"\\tfeatures\\n\");\n\tseq_printf(m, \"\\t major_features: 0x%08x\\n\",\n\t\t   gpu->identity.features);\n\tseq_printf(m, \"\\t minor_features0: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features0);\n\tseq_printf(m, \"\\t minor_features1: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features1);\n\tseq_printf(m, \"\\t minor_features2: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features2);\n\tseq_printf(m, \"\\t minor_features3: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features3);\n\tseq_printf(m, \"\\t minor_features4: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features4);\n\tseq_printf(m, \"\\t minor_features5: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features5);\n\tseq_printf(m, \"\\t minor_features6: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features6);\n\tseq_printf(m, \"\\t minor_features7: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features7);\n\tseq_printf(m, \"\\t minor_features8: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features8);\n\tseq_printf(m, \"\\t minor_features9: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features9);\n\tseq_printf(m, \"\\t minor_features10: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features10);\n\tseq_printf(m, \"\\t minor_features11: 0x%08x\\n\",\n\t\t   gpu->identity.minor_features11);\n\n\tseq_puts(m, \"\\tspecs\\n\");\n\tseq_printf(m, \"\\t stream_count:  %d\\n\",\n\t\t\tgpu->identity.stream_count);\n\tseq_printf(m, \"\\t register_max: %d\\n\",\n\t\t\tgpu->identity.register_max);\n\tseq_printf(m, \"\\t thread_count: %d\\n\",\n\t\t\tgpu->identity.thread_count);\n\tseq_printf(m, \"\\t vertex_cache_size: %d\\n\",\n\t\t\tgpu->identity.vertex_cache_size);\n\tseq_printf(m, \"\\t shader_core_count: %d\\n\",\n\t\t\tgpu->identity.shader_core_count);\n\tseq_printf(m, \"\\t nn_core_count: %d\\n\",\n\t\t\tgpu->identity.nn_core_count);\n\tseq_printf(m, \"\\t pixel_pipes: %d\\n\",\n\t\t\tgpu->identity.pixel_pipes);\n\tseq_printf(m, \"\\t vertex_output_buffer_size: %d\\n\",\n\t\t\tgpu->identity.vertex_output_buffer_size);\n\tseq_printf(m, \"\\t buffer_size: %d\\n\",\n\t\t\tgpu->identity.buffer_size);\n\tseq_printf(m, \"\\t instruction_count: %d\\n\",\n\t\t\tgpu->identity.instruction_count);\n\tseq_printf(m, \"\\t num_constants: %d\\n\",\n\t\t\tgpu->identity.num_constants);\n\tseq_printf(m, \"\\t varyings_count: %d\\n\",\n\t\t\tgpu->identity.varyings_count);\n\n\tseq_printf(m, \"\\taxi: 0x%08x\\n\", axi);\n\tseq_printf(m, \"\\tidle: 0x%08x\\n\", idle);\n\tidle |= ~gpu->idle_mask & ~VIVS_HI_IDLE_STATE_AXI_LP;\n\tif ((idle & VIVS_HI_IDLE_STATE_FE) == 0)\n\t\tseq_puts(m, \"\\t FE is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_DE) == 0)\n\t\tseq_puts(m, \"\\t DE is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_PE) == 0)\n\t\tseq_puts(m, \"\\t PE is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_SH) == 0)\n\t\tseq_puts(m, \"\\t SH is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_PA) == 0)\n\t\tseq_puts(m, \"\\t PA is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_SE) == 0)\n\t\tseq_puts(m, \"\\t SE is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_RA) == 0)\n\t\tseq_puts(m, \"\\t RA is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_TX) == 0)\n\t\tseq_puts(m, \"\\t TX is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_VG) == 0)\n\t\tseq_puts(m, \"\\t VG is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_IM) == 0)\n\t\tseq_puts(m, \"\\t IM is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_FP) == 0)\n\t\tseq_puts(m, \"\\t FP is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_TS) == 0)\n\t\tseq_puts(m, \"\\t TS is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_BL) == 0)\n\t\tseq_puts(m, \"\\t BL is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_ASYNCFE) == 0)\n\t\tseq_puts(m, \"\\t ASYNCFE is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_MC) == 0)\n\t\tseq_puts(m, \"\\t MC is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_PPA) == 0)\n\t\tseq_puts(m, \"\\t PPA is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_WD) == 0)\n\t\tseq_puts(m, \"\\t WD is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_NN) == 0)\n\t\tseq_puts(m, \"\\t NN is not idle\\n\");\n\tif ((idle & VIVS_HI_IDLE_STATE_TP) == 0)\n\t\tseq_puts(m, \"\\t TP is not idle\\n\");\n\tif (idle & VIVS_HI_IDLE_STATE_AXI_LP)\n\t\tseq_puts(m, \"\\t AXI low power mode\\n\");\n\n\tif (gpu->identity.features & chipFeatures_DEBUG_MODE) {\n\t\tu32 read0 = gpu_read(gpu, VIVS_MC_DEBUG_READ0);\n\t\tu32 read1 = gpu_read(gpu, VIVS_MC_DEBUG_READ1);\n\t\tu32 write = gpu_read(gpu, VIVS_MC_DEBUG_WRITE);\n\n\t\tseq_puts(m, \"\\tMC\\n\");\n\t\tseq_printf(m, \"\\t read0: 0x%08x\\n\", read0);\n\t\tseq_printf(m, \"\\t read1: 0x%08x\\n\", read1);\n\t\tseq_printf(m, \"\\t write: 0x%08x\\n\", write);\n\t}\n\n\tseq_puts(m, \"\\tDMA \");\n\n\tif (debug.address[0] == debug.address[1] &&\n\t    debug.state[0] == debug.state[1]) {\n\t\tseq_puts(m, \"seems to be stuck\\n\");\n\t} else if (debug.address[0] == debug.address[1]) {\n\t\tseq_puts(m, \"address is constant\\n\");\n\t} else {\n\t\tseq_puts(m, \"is running\\n\");\n\t}\n\n\tseq_printf(m, \"\\t address 0: 0x%08x\\n\", debug.address[0]);\n\tseq_printf(m, \"\\t address 1: 0x%08x\\n\", debug.address[1]);\n\tseq_printf(m, \"\\t state 0: 0x%08x\\n\", debug.state[0]);\n\tseq_printf(m, \"\\t state 1: 0x%08x\\n\", debug.state[1]);\n\tseq_printf(m, \"\\t last fetch 64 bit word: 0x%08x 0x%08x\\n\",\n\t\t   dma_lo, dma_hi);\n\n\tret = 0;\n\n\tpm_runtime_mark_last_busy(gpu->dev);\npm_put:\n\tpm_runtime_put_autosuspend(gpu->dev);\n\n\treturn ret;\n}\n#endif\n\n \nstruct etnaviv_fence {\n\tstruct etnaviv_gpu *gpu;\n\tstruct dma_fence base;\n};\n\nstatic inline struct etnaviv_fence *to_etnaviv_fence(struct dma_fence *fence)\n{\n\treturn container_of(fence, struct etnaviv_fence, base);\n}\n\nstatic const char *etnaviv_fence_get_driver_name(struct dma_fence *fence)\n{\n\treturn \"etnaviv\";\n}\n\nstatic const char *etnaviv_fence_get_timeline_name(struct dma_fence *fence)\n{\n\tstruct etnaviv_fence *f = to_etnaviv_fence(fence);\n\n\treturn dev_name(f->gpu->dev);\n}\n\nstatic bool etnaviv_fence_signaled(struct dma_fence *fence)\n{\n\tstruct etnaviv_fence *f = to_etnaviv_fence(fence);\n\n\treturn (s32)(f->gpu->completed_fence - f->base.seqno) >= 0;\n}\n\nstatic void etnaviv_fence_release(struct dma_fence *fence)\n{\n\tstruct etnaviv_fence *f = to_etnaviv_fence(fence);\n\n\tkfree_rcu(f, base.rcu);\n}\n\nstatic const struct dma_fence_ops etnaviv_fence_ops = {\n\t.get_driver_name = etnaviv_fence_get_driver_name,\n\t.get_timeline_name = etnaviv_fence_get_timeline_name,\n\t.signaled = etnaviv_fence_signaled,\n\t.release = etnaviv_fence_release,\n};\n\nstatic struct dma_fence *etnaviv_gpu_fence_alloc(struct etnaviv_gpu *gpu)\n{\n\tstruct etnaviv_fence *f;\n\n\t \n\tlockdep_assert_held(&gpu->lock);\n\n\tf = kzalloc(sizeof(*f), GFP_KERNEL);\n\tif (!f)\n\t\treturn NULL;\n\n\tf->gpu = gpu;\n\n\tdma_fence_init(&f->base, &etnaviv_fence_ops, &gpu->fence_spinlock,\n\t\t       gpu->fence_context, ++gpu->next_fence);\n\n\treturn &f->base;\n}\n\n \nstatic inline bool fence_after(u32 a, u32 b)\n{\n\treturn (s32)(a - b) > 0;\n}\n\n \n\nstatic int event_alloc(struct etnaviv_gpu *gpu, unsigned nr_events,\n\tunsigned int *events)\n{\n\tunsigned long timeout = msecs_to_jiffies(10 * 10000);\n\tunsigned i, acquired = 0, rpm_count = 0;\n\tint ret;\n\n\tfor (i = 0; i < nr_events; i++) {\n\t\tunsigned long remaining;\n\n\t\tremaining = wait_for_completion_timeout(&gpu->event_free, timeout);\n\n\t\tif (!remaining) {\n\t\t\tdev_err(gpu->dev, \"wait_for_completion_timeout failed\");\n\t\t\tret = -EBUSY;\n\t\t\tgoto out;\n\t\t}\n\n\t\tacquired++;\n\t\ttimeout = remaining;\n\t}\n\n\tspin_lock(&gpu->event_spinlock);\n\n\tfor (i = 0; i < nr_events; i++) {\n\t\tint event = find_first_zero_bit(gpu->event_bitmap, ETNA_NR_EVENTS);\n\n\t\tevents[i] = event;\n\t\tmemset(&gpu->event[event], 0, sizeof(struct etnaviv_event));\n\t\tset_bit(event, gpu->event_bitmap);\n\t}\n\n\tspin_unlock(&gpu->event_spinlock);\n\n\tfor (i = 0; i < nr_events; i++) {\n\t\tret = pm_runtime_resume_and_get(gpu->dev);\n\t\tif (ret)\n\t\t\tgoto out_rpm;\n\t\trpm_count++;\n\t}\n\n\treturn 0;\n\nout_rpm:\n\tfor (i = 0; i < rpm_count; i++)\n\t\tpm_runtime_put_autosuspend(gpu->dev);\nout:\n\tfor (i = 0; i < acquired; i++)\n\t\tcomplete(&gpu->event_free);\n\n\treturn ret;\n}\n\nstatic void event_free(struct etnaviv_gpu *gpu, unsigned int event)\n{\n\tif (!test_bit(event, gpu->event_bitmap)) {\n\t\tdev_warn(gpu->dev, \"event %u is already marked as free\",\n\t\t\t event);\n\t} else {\n\t\tclear_bit(event, gpu->event_bitmap);\n\t\tcomplete(&gpu->event_free);\n\t}\n\n\tpm_runtime_put_autosuspend(gpu->dev);\n}\n\n \nint etnaviv_gpu_wait_fence_interruptible(struct etnaviv_gpu *gpu,\n\tu32 id, struct drm_etnaviv_timespec *timeout)\n{\n\tstruct dma_fence *fence;\n\tint ret;\n\n\t \n\trcu_read_lock();\n\tfence = xa_load(&gpu->user_fences, id);\n\tif (fence)\n\t\tfence = dma_fence_get_rcu(fence);\n\trcu_read_unlock();\n\n\tif (!fence)\n\t\treturn 0;\n\n\tif (!timeout) {\n\t\t \n\t\tret = dma_fence_is_signaled(fence) ? 0 : -EBUSY;\n\t} else {\n\t\tunsigned long remaining = etnaviv_timeout_to_jiffies(timeout);\n\n\t\tret = dma_fence_wait_timeout(fence, true, remaining);\n\t\tif (ret == 0)\n\t\t\tret = -ETIMEDOUT;\n\t\telse if (ret != -ERESTARTSYS)\n\t\t\tret = 0;\n\n\t}\n\n\tdma_fence_put(fence);\n\treturn ret;\n}\n\n \nint etnaviv_gpu_wait_obj_inactive(struct etnaviv_gpu *gpu,\n\tstruct etnaviv_gem_object *etnaviv_obj,\n\tstruct drm_etnaviv_timespec *timeout)\n{\n\tunsigned long remaining;\n\tlong ret;\n\n\tif (!timeout)\n\t\treturn !is_active(etnaviv_obj) ? 0 : -EBUSY;\n\n\tremaining = etnaviv_timeout_to_jiffies(timeout);\n\n\tret = wait_event_interruptible_timeout(gpu->fence_event,\n\t\t\t\t\t       !is_active(etnaviv_obj),\n\t\t\t\t\t       remaining);\n\tif (ret > 0)\n\t\treturn 0;\n\telse if (ret == -ERESTARTSYS)\n\t\treturn -ERESTARTSYS;\n\telse\n\t\treturn -ETIMEDOUT;\n}\n\nstatic void sync_point_perfmon_sample(struct etnaviv_gpu *gpu,\n\tstruct etnaviv_event *event, unsigned int flags)\n{\n\tconst struct etnaviv_gem_submit *submit = event->submit;\n\tunsigned int i;\n\n\tfor (i = 0; i < submit->nr_pmrs; i++) {\n\t\tconst struct etnaviv_perfmon_request *pmr = submit->pmrs + i;\n\n\t\tif (pmr->flags == flags)\n\t\t\tetnaviv_perfmon_process(gpu, pmr, submit->exec_state);\n\t}\n}\n\nstatic void sync_point_perfmon_sample_pre(struct etnaviv_gpu *gpu,\n\tstruct etnaviv_event *event)\n{\n\tu32 val;\n\n\t \n\tval = gpu_read_power(gpu, VIVS_PM_POWER_CONTROLS);\n\tval &= ~VIVS_PM_POWER_CONTROLS_ENABLE_MODULE_CLOCK_GATING;\n\tgpu_write_power(gpu, VIVS_PM_POWER_CONTROLS, val);\n\n\t \n\tval = gpu_read(gpu, VIVS_HI_CLOCK_CONTROL);\n\tval &= ~VIVS_HI_CLOCK_CONTROL_DISABLE_DEBUG_REGISTERS;\n\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, val);\n\n\tsync_point_perfmon_sample(gpu, event, ETNA_PM_PROCESS_PRE);\n}\n\nstatic void sync_point_perfmon_sample_post(struct etnaviv_gpu *gpu,\n\tstruct etnaviv_event *event)\n{\n\tconst struct etnaviv_gem_submit *submit = event->submit;\n\tunsigned int i;\n\tu32 val;\n\n\tsync_point_perfmon_sample(gpu, event, ETNA_PM_PROCESS_POST);\n\n\tfor (i = 0; i < submit->nr_pmrs; i++) {\n\t\tconst struct etnaviv_perfmon_request *pmr = submit->pmrs + i;\n\n\t\t*pmr->bo_vma = pmr->sequence;\n\t}\n\n\t \n\tval = gpu_read(gpu, VIVS_HI_CLOCK_CONTROL);\n\tval |= VIVS_HI_CLOCK_CONTROL_DISABLE_DEBUG_REGISTERS;\n\tgpu_write(gpu, VIVS_HI_CLOCK_CONTROL, val);\n\n\t \n\tval = gpu_read_power(gpu, VIVS_PM_POWER_CONTROLS);\n\tval |= VIVS_PM_POWER_CONTROLS_ENABLE_MODULE_CLOCK_GATING;\n\tgpu_write_power(gpu, VIVS_PM_POWER_CONTROLS, val);\n}\n\n\n \nstruct dma_fence *etnaviv_gpu_submit(struct etnaviv_gem_submit *submit)\n{\n\tstruct etnaviv_gpu *gpu = submit->gpu;\n\tstruct dma_fence *gpu_fence;\n\tunsigned int i, nr_events = 1, event[3];\n\tint ret;\n\n\t \n\tif (submit->nr_pmrs)\n\t\tnr_events = 3;\n\n\tret = event_alloc(gpu, nr_events, event);\n\tif (ret) {\n\t\tDRM_ERROR(\"no free events\\n\");\n\t\tpm_runtime_put_noidle(gpu->dev);\n\t\treturn NULL;\n\t}\n\n\tmutex_lock(&gpu->lock);\n\n\tgpu_fence = etnaviv_gpu_fence_alloc(gpu);\n\tif (!gpu_fence) {\n\t\tfor (i = 0; i < nr_events; i++)\n\t\t\tevent_free(gpu, event[i]);\n\n\t\tgoto out_unlock;\n\t}\n\n\tif (gpu->state == ETNA_GPU_STATE_INITIALIZED)\n\t\tetnaviv_gpu_start_fe_idleloop(gpu, submit->mmu_context);\n\n\tif (submit->prev_mmu_context)\n\t\tetnaviv_iommu_context_put(submit->prev_mmu_context);\n\tsubmit->prev_mmu_context = etnaviv_iommu_context_get(gpu->mmu_context);\n\n\tif (submit->nr_pmrs) {\n\t\tgpu->event[event[1]].sync_point = &sync_point_perfmon_sample_pre;\n\t\tkref_get(&submit->refcount);\n\t\tgpu->event[event[1]].submit = submit;\n\t\tetnaviv_sync_point_queue(gpu, event[1]);\n\t}\n\n\tgpu->event[event[0]].fence = gpu_fence;\n\tsubmit->cmdbuf.user_size = submit->cmdbuf.size - 8;\n\tetnaviv_buffer_queue(gpu, submit->exec_state, submit->mmu_context,\n\t\t\t     event[0], &submit->cmdbuf);\n\n\tif (submit->nr_pmrs) {\n\t\tgpu->event[event[2]].sync_point = &sync_point_perfmon_sample_post;\n\t\tkref_get(&submit->refcount);\n\t\tgpu->event[event[2]].submit = submit;\n\t\tetnaviv_sync_point_queue(gpu, event[2]);\n\t}\n\nout_unlock:\n\tmutex_unlock(&gpu->lock);\n\n\treturn gpu_fence;\n}\n\nstatic void sync_point_worker(struct work_struct *work)\n{\n\tstruct etnaviv_gpu *gpu = container_of(work, struct etnaviv_gpu,\n\t\t\t\t\t       sync_point_work);\n\tstruct etnaviv_event *event = &gpu->event[gpu->sync_point_event];\n\tu32 addr = gpu_read(gpu, VIVS_FE_DMA_ADDRESS);\n\n\tevent->sync_point(gpu, event);\n\tetnaviv_submit_put(event->submit);\n\tevent_free(gpu, gpu->sync_point_event);\n\n\t \n\tetnaviv_gpu_start_fe(gpu, addr + 2, 2);\n}\n\nvoid etnaviv_gpu_recover_hang(struct etnaviv_gem_submit *submit)\n{\n\tstruct etnaviv_gpu *gpu = submit->gpu;\n\tchar *comm = NULL, *cmd = NULL;\n\tstruct task_struct *task;\n\tunsigned int i;\n\n\tdev_err(gpu->dev, \"recover hung GPU!\\n\");\n\n\ttask = get_pid_task(submit->pid, PIDTYPE_PID);\n\tif (task) {\n\t\tcomm = kstrdup(task->comm, GFP_KERNEL);\n\t\tcmd = kstrdup_quotable_cmdline(task, GFP_KERNEL);\n\t\tput_task_struct(task);\n\t}\n\n\tif (comm && cmd)\n\t\tdev_err(gpu->dev, \"offending task: %s (%s)\\n\", comm, cmd);\n\n\tkfree(cmd);\n\tkfree(comm);\n\n\tif (pm_runtime_get_sync(gpu->dev) < 0)\n\t\tgoto pm_put;\n\n\tmutex_lock(&gpu->lock);\n\n\tetnaviv_hw_reset(gpu);\n\n\t \n\tspin_lock(&gpu->event_spinlock);\n\tfor_each_set_bit(i, gpu->event_bitmap, ETNA_NR_EVENTS)\n\t\tevent_free(gpu, i);\n\tspin_unlock(&gpu->event_spinlock);\n\n\tetnaviv_gpu_hw_init(gpu);\n\n\tmutex_unlock(&gpu->lock);\n\tpm_runtime_mark_last_busy(gpu->dev);\npm_put:\n\tpm_runtime_put_autosuspend(gpu->dev);\n}\n\nstatic void dump_mmu_fault(struct etnaviv_gpu *gpu)\n{\n\tstatic const char *fault_reasons[] = {\n\t\t\"slave not present\",\n\t\t\"page not present\",\n\t\t\"write violation\",\n\t\t\"out of bounds\",\n\t\t\"read security violation\",\n\t\t\"write security violation\",\n\t};\n\n\tu32 status_reg, status;\n\tint i;\n\n\tif (gpu->sec_mode == ETNA_SEC_NONE)\n\t\tstatus_reg = VIVS_MMUv2_STATUS;\n\telse\n\t\tstatus_reg = VIVS_MMUv2_SEC_STATUS;\n\n\tstatus = gpu_read(gpu, status_reg);\n\tdev_err_ratelimited(gpu->dev, \"MMU fault status 0x%08x\\n\", status);\n\n\tfor (i = 0; i < 4; i++) {\n\t\tconst char *reason = \"unknown\";\n\t\tu32 address_reg;\n\t\tu32 mmu_status;\n\n\t\tmmu_status = (status >> (i * 4)) & VIVS_MMUv2_STATUS_EXCEPTION0__MASK;\n\t\tif (!mmu_status)\n\t\t\tcontinue;\n\n\t\tif ((mmu_status - 1) < ARRAY_SIZE(fault_reasons))\n\t\t\treason = fault_reasons[mmu_status - 1];\n\n\t\tif (gpu->sec_mode == ETNA_SEC_NONE)\n\t\t\taddress_reg = VIVS_MMUv2_EXCEPTION_ADDR(i);\n\t\telse\n\t\t\taddress_reg = VIVS_MMUv2_SEC_EXCEPTION_ADDR;\n\n\t\tdev_err_ratelimited(gpu->dev,\n\t\t\t\t    \"MMU %d fault (%s) addr 0x%08x\\n\",\n\t\t\t\t    i, reason, gpu_read(gpu, address_reg));\n\t}\n}\n\nstatic irqreturn_t irq_handler(int irq, void *data)\n{\n\tstruct etnaviv_gpu *gpu = data;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tu32 intr = gpu_read(gpu, VIVS_HI_INTR_ACKNOWLEDGE);\n\n\tif (intr != 0) {\n\t\tint event;\n\n\t\tpm_runtime_mark_last_busy(gpu->dev);\n\n\t\tdev_dbg(gpu->dev, \"intr 0x%08x\\n\", intr);\n\n\t\tif (intr & VIVS_HI_INTR_ACKNOWLEDGE_AXI_BUS_ERROR) {\n\t\t\tdev_err(gpu->dev, \"AXI bus error\\n\");\n\t\t\tintr &= ~VIVS_HI_INTR_ACKNOWLEDGE_AXI_BUS_ERROR;\n\t\t}\n\n\t\tif (intr & VIVS_HI_INTR_ACKNOWLEDGE_MMU_EXCEPTION) {\n\t\t\tdump_mmu_fault(gpu);\n\t\t\tgpu->state = ETNA_GPU_STATE_FAULT;\n\t\t\tdrm_sched_fault(&gpu->sched);\n\t\t\tintr &= ~VIVS_HI_INTR_ACKNOWLEDGE_MMU_EXCEPTION;\n\t\t}\n\n\t\twhile ((event = ffs(intr)) != 0) {\n\t\t\tstruct dma_fence *fence;\n\n\t\t\tevent -= 1;\n\n\t\t\tintr &= ~(1 << event);\n\n\t\t\tdev_dbg(gpu->dev, \"event %u\\n\", event);\n\n\t\t\tif (gpu->event[event].sync_point) {\n\t\t\t\tgpu->sync_point_event = event;\n\t\t\t\tqueue_work(gpu->wq, &gpu->sync_point_work);\n\t\t\t}\n\n\t\t\tfence = gpu->event[event].fence;\n\t\t\tif (!fence)\n\t\t\t\tcontinue;\n\n\t\t\tgpu->event[event].fence = NULL;\n\n\t\t\t \n\t\t\tif (fence_after(fence->seqno, gpu->completed_fence))\n\t\t\t\tgpu->completed_fence = fence->seqno;\n\t\t\tdma_fence_signal(fence);\n\n\t\t\tevent_free(gpu, event);\n\t\t}\n\n\t\tret = IRQ_HANDLED;\n\t}\n\n\treturn ret;\n}\n\nstatic int etnaviv_gpu_clk_enable(struct etnaviv_gpu *gpu)\n{\n\tint ret;\n\n\tret = clk_prepare_enable(gpu->clk_reg);\n\tif (ret)\n\t\treturn ret;\n\n\tret = clk_prepare_enable(gpu->clk_bus);\n\tif (ret)\n\t\tgoto disable_clk_reg;\n\n\tret = clk_prepare_enable(gpu->clk_core);\n\tif (ret)\n\t\tgoto disable_clk_bus;\n\n\tret = clk_prepare_enable(gpu->clk_shader);\n\tif (ret)\n\t\tgoto disable_clk_core;\n\n\treturn 0;\n\ndisable_clk_core:\n\tclk_disable_unprepare(gpu->clk_core);\ndisable_clk_bus:\n\tclk_disable_unprepare(gpu->clk_bus);\ndisable_clk_reg:\n\tclk_disable_unprepare(gpu->clk_reg);\n\n\treturn ret;\n}\n\nstatic int etnaviv_gpu_clk_disable(struct etnaviv_gpu *gpu)\n{\n\tclk_disable_unprepare(gpu->clk_shader);\n\tclk_disable_unprepare(gpu->clk_core);\n\tclk_disable_unprepare(gpu->clk_bus);\n\tclk_disable_unprepare(gpu->clk_reg);\n\n\treturn 0;\n}\n\nint etnaviv_gpu_wait_idle(struct etnaviv_gpu *gpu, unsigned int timeout_ms)\n{\n\tunsigned long timeout = jiffies + msecs_to_jiffies(timeout_ms);\n\n\tdo {\n\t\tu32 idle = gpu_read(gpu, VIVS_HI_IDLE_STATE);\n\n\t\tif ((idle & gpu->idle_mask) == gpu->idle_mask)\n\t\t\treturn 0;\n\n\t\tif (time_is_before_jiffies(timeout)) {\n\t\t\tdev_warn(gpu->dev,\n\t\t\t\t \"timed out waiting for idle: idle=0x%x\\n\",\n\t\t\t\t idle);\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\n\t\tudelay(5);\n\t} while (1);\n}\n\nstatic void etnaviv_gpu_hw_suspend(struct etnaviv_gpu *gpu)\n{\n\tif (gpu->state == ETNA_GPU_STATE_RUNNING) {\n\t\t \n\t\tmutex_lock(&gpu->lock);\n\t\tetnaviv_buffer_end(gpu);\n\t\tmutex_unlock(&gpu->lock);\n\n\t\t \n\t\tetnaviv_gpu_wait_idle(gpu, 100);\n\n\t\tgpu->state = ETNA_GPU_STATE_INITIALIZED;\n\t}\n\n\tgpu->exec_state = -1;\n}\n\nstatic int etnaviv_gpu_hw_resume(struct etnaviv_gpu *gpu)\n{\n\tint ret;\n\n\tret = mutex_lock_killable(&gpu->lock);\n\tif (ret)\n\t\treturn ret;\n\n\tetnaviv_gpu_update_clock(gpu);\n\tetnaviv_gpu_hw_init(gpu);\n\n\tmutex_unlock(&gpu->lock);\n\n\treturn 0;\n}\n\nstatic int\netnaviv_gpu_cooling_get_max_state(struct thermal_cooling_device *cdev,\n\t\t\t\t  unsigned long *state)\n{\n\t*state = 6;\n\n\treturn 0;\n}\n\nstatic int\netnaviv_gpu_cooling_get_cur_state(struct thermal_cooling_device *cdev,\n\t\t\t\t  unsigned long *state)\n{\n\tstruct etnaviv_gpu *gpu = cdev->devdata;\n\n\t*state = gpu->freq_scale;\n\n\treturn 0;\n}\n\nstatic int\netnaviv_gpu_cooling_set_cur_state(struct thermal_cooling_device *cdev,\n\t\t\t\t  unsigned long state)\n{\n\tstruct etnaviv_gpu *gpu = cdev->devdata;\n\n\tmutex_lock(&gpu->lock);\n\tgpu->freq_scale = state;\n\tif (!pm_runtime_suspended(gpu->dev))\n\t\tetnaviv_gpu_update_clock(gpu);\n\tmutex_unlock(&gpu->lock);\n\n\treturn 0;\n}\n\nstatic const struct thermal_cooling_device_ops cooling_ops = {\n\t.get_max_state = etnaviv_gpu_cooling_get_max_state,\n\t.get_cur_state = etnaviv_gpu_cooling_get_cur_state,\n\t.set_cur_state = etnaviv_gpu_cooling_set_cur_state,\n};\n\nstatic int etnaviv_gpu_bind(struct device *dev, struct device *master,\n\tvoid *data)\n{\n\tstruct drm_device *drm = data;\n\tstruct etnaviv_drm_private *priv = drm->dev_private;\n\tstruct etnaviv_gpu *gpu = dev_get_drvdata(dev);\n\tint ret;\n\n\tif (IS_ENABLED(CONFIG_DRM_ETNAVIV_THERMAL)) {\n\t\tgpu->cooling = thermal_of_cooling_device_register(dev->of_node,\n\t\t\t\t(char *)dev_name(dev), gpu, &cooling_ops);\n\t\tif (IS_ERR(gpu->cooling))\n\t\t\treturn PTR_ERR(gpu->cooling);\n\t}\n\n\tgpu->wq = alloc_ordered_workqueue(dev_name(dev), 0);\n\tif (!gpu->wq) {\n\t\tret = -ENOMEM;\n\t\tgoto out_thermal;\n\t}\n\n\tret = etnaviv_sched_init(gpu);\n\tif (ret)\n\t\tgoto out_workqueue;\n\n\tif (!IS_ENABLED(CONFIG_PM)) {\n\t\tret = etnaviv_gpu_clk_enable(gpu);\n\t\tif (ret < 0)\n\t\t\tgoto out_sched;\n\t}\n\n\tgpu->drm = drm;\n\tgpu->fence_context = dma_fence_context_alloc(1);\n\txa_init_flags(&gpu->user_fences, XA_FLAGS_ALLOC);\n\tspin_lock_init(&gpu->fence_spinlock);\n\n\tINIT_WORK(&gpu->sync_point_work, sync_point_worker);\n\tinit_waitqueue_head(&gpu->fence_event);\n\n\tpriv->gpu[priv->num_gpus++] = gpu;\n\n\treturn 0;\n\nout_sched:\n\tetnaviv_sched_fini(gpu);\n\nout_workqueue:\n\tdestroy_workqueue(gpu->wq);\n\nout_thermal:\n\tif (IS_ENABLED(CONFIG_DRM_ETNAVIV_THERMAL))\n\t\tthermal_cooling_device_unregister(gpu->cooling);\n\n\treturn ret;\n}\n\nstatic void etnaviv_gpu_unbind(struct device *dev, struct device *master,\n\tvoid *data)\n{\n\tstruct etnaviv_gpu *gpu = dev_get_drvdata(dev);\n\n\tDBG(\"%s\", dev_name(gpu->dev));\n\n\tdestroy_workqueue(gpu->wq);\n\n\tetnaviv_sched_fini(gpu);\n\n\tif (IS_ENABLED(CONFIG_PM)) {\n\t\tpm_runtime_get_sync(gpu->dev);\n\t\tpm_runtime_put_sync_suspend(gpu->dev);\n\t} else {\n\t\tetnaviv_gpu_hw_suspend(gpu);\n\t\tetnaviv_gpu_clk_disable(gpu);\n\t}\n\n\tif (gpu->mmu_context)\n\t\tetnaviv_iommu_context_put(gpu->mmu_context);\n\n\tetnaviv_cmdbuf_free(&gpu->buffer);\n\tetnaviv_iommu_global_fini(gpu);\n\n\tgpu->drm = NULL;\n\txa_destroy(&gpu->user_fences);\n\n\tif (IS_ENABLED(CONFIG_DRM_ETNAVIV_THERMAL))\n\t\tthermal_cooling_device_unregister(gpu->cooling);\n\tgpu->cooling = NULL;\n}\n\nstatic const struct component_ops gpu_ops = {\n\t.bind = etnaviv_gpu_bind,\n\t.unbind = etnaviv_gpu_unbind,\n};\n\nstatic const struct of_device_id etnaviv_gpu_match[] = {\n\t{\n\t\t.compatible = \"vivante,gc\"\n\t},\n\t{   }\n};\nMODULE_DEVICE_TABLE(of, etnaviv_gpu_match);\n\nstatic int etnaviv_gpu_platform_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct etnaviv_gpu *gpu;\n\tint err;\n\n\tgpu = devm_kzalloc(dev, sizeof(*gpu), GFP_KERNEL);\n\tif (!gpu)\n\t\treturn -ENOMEM;\n\n\tgpu->dev = &pdev->dev;\n\tmutex_init(&gpu->lock);\n\tmutex_init(&gpu->sched_lock);\n\n\t \n\tgpu->mmio = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(gpu->mmio))\n\t\treturn PTR_ERR(gpu->mmio);\n\n\t \n\tgpu->irq = platform_get_irq(pdev, 0);\n\tif (gpu->irq < 0)\n\t\treturn gpu->irq;\n\n\terr = devm_request_irq(&pdev->dev, gpu->irq, irq_handler, 0,\n\t\t\t       dev_name(gpu->dev), gpu);\n\tif (err) {\n\t\tdev_err(dev, \"failed to request IRQ%u: %d\\n\", gpu->irq, err);\n\t\treturn err;\n\t}\n\n\t \n\tgpu->clk_reg = devm_clk_get_optional(&pdev->dev, \"reg\");\n\tDBG(\"clk_reg: %p\", gpu->clk_reg);\n\tif (IS_ERR(gpu->clk_reg))\n\t\treturn PTR_ERR(gpu->clk_reg);\n\n\tgpu->clk_bus = devm_clk_get_optional(&pdev->dev, \"bus\");\n\tDBG(\"clk_bus: %p\", gpu->clk_bus);\n\tif (IS_ERR(gpu->clk_bus))\n\t\treturn PTR_ERR(gpu->clk_bus);\n\n\tgpu->clk_core = devm_clk_get(&pdev->dev, \"core\");\n\tDBG(\"clk_core: %p\", gpu->clk_core);\n\tif (IS_ERR(gpu->clk_core))\n\t\treturn PTR_ERR(gpu->clk_core);\n\tgpu->base_rate_core = clk_get_rate(gpu->clk_core);\n\n\tgpu->clk_shader = devm_clk_get_optional(&pdev->dev, \"shader\");\n\tDBG(\"clk_shader: %p\", gpu->clk_shader);\n\tif (IS_ERR(gpu->clk_shader))\n\t\treturn PTR_ERR(gpu->clk_shader);\n\tgpu->base_rate_shader = clk_get_rate(gpu->clk_shader);\n\n\t \n\tdev_set_drvdata(dev, gpu);\n\n\t \n\tpm_runtime_use_autosuspend(gpu->dev);\n\tpm_runtime_set_autosuspend_delay(gpu->dev, 200);\n\tpm_runtime_enable(gpu->dev);\n\n\terr = component_add(&pdev->dev, &gpu_ops);\n\tif (err < 0) {\n\t\tdev_err(&pdev->dev, \"failed to register component: %d\\n\", err);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic int etnaviv_gpu_platform_remove(struct platform_device *pdev)\n{\n\tcomponent_del(&pdev->dev, &gpu_ops);\n\tpm_runtime_disable(&pdev->dev);\n\treturn 0;\n}\n\nstatic int etnaviv_gpu_rpm_suspend(struct device *dev)\n{\n\tstruct etnaviv_gpu *gpu = dev_get_drvdata(dev);\n\tu32 idle, mask;\n\n\t \n\tif (atomic_read(&gpu->sched.hw_rq_count))\n\t\treturn -EBUSY;\n\n\t \n\tmask = gpu->idle_mask & ~(VIVS_HI_IDLE_STATE_FE |\n\t\t\t\t  VIVS_HI_IDLE_STATE_MC);\n\tidle = gpu_read(gpu, VIVS_HI_IDLE_STATE) & mask;\n\tif (idle != mask) {\n\t\tdev_warn_ratelimited(dev, \"GPU not yet idle, mask: 0x%08x\\n\",\n\t\t\t\t     idle);\n\t\treturn -EBUSY;\n\t}\n\n\tetnaviv_gpu_hw_suspend(gpu);\n\n\tgpu->state = ETNA_GPU_STATE_IDENTIFIED;\n\n\treturn etnaviv_gpu_clk_disable(gpu);\n}\n\nstatic int etnaviv_gpu_rpm_resume(struct device *dev)\n{\n\tstruct etnaviv_gpu *gpu = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = etnaviv_gpu_clk_enable(gpu);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (gpu->state == ETNA_GPU_STATE_IDENTIFIED) {\n\t\tret = etnaviv_gpu_hw_resume(gpu);\n\t\tif (ret) {\n\t\t\tetnaviv_gpu_clk_disable(gpu);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops etnaviv_gpu_pm_ops = {\n\tRUNTIME_PM_OPS(etnaviv_gpu_rpm_suspend, etnaviv_gpu_rpm_resume, NULL)\n};\n\nstruct platform_driver etnaviv_gpu_driver = {\n\t.driver = {\n\t\t.name = \"etnaviv-gpu\",\n\t\t.owner = THIS_MODULE,\n\t\t.pm = pm_ptr(&etnaviv_gpu_pm_ops),\n\t\t.of_match_table = etnaviv_gpu_match,\n\t},\n\t.probe = etnaviv_gpu_platform_probe,\n\t.remove = etnaviv_gpu_platform_remove,\n\t.id_table = gpu_ids,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}