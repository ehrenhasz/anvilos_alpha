{
  "module_name": "etnaviv_iommu.c",
  "hash_id": "9fbd410e73c2105b04d3e1dfc29c927abd9aeea0c0763bcab2fc2ba718adf641",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/etnaviv/etnaviv_iommu.c",
  "human_readable_source": "\n \n\n#include <linux/bitops.h>\n#include <linux/dma-mapping.h>\n#include <linux/platform_device.h>\n#include <linux/sizes.h>\n#include <linux/slab.h>\n\n#include \"etnaviv_gpu.h\"\n#include \"etnaviv_mmu.h\"\n#include \"state_hi.xml.h\"\n\n#define PT_SIZE\t\tSZ_2M\n#define PT_ENTRIES\t(PT_SIZE / sizeof(u32))\n\n#define GPU_MEM_START\t0x80000000\n\nstruct etnaviv_iommuv1_context {\n\tstruct etnaviv_iommu_context base;\n\tu32 *pgtable_cpu;\n\tdma_addr_t pgtable_dma;\n};\n\nstatic struct etnaviv_iommuv1_context *\nto_v1_context(struct etnaviv_iommu_context *context)\n{\n\treturn container_of(context, struct etnaviv_iommuv1_context, base);\n}\n\nstatic void etnaviv_iommuv1_free(struct etnaviv_iommu_context *context)\n{\n\tstruct etnaviv_iommuv1_context *v1_context = to_v1_context(context);\n\n\tdrm_mm_takedown(&context->mm);\n\n\tdma_free_wc(context->global->dev, PT_SIZE, v1_context->pgtable_cpu,\n\t\t    v1_context->pgtable_dma);\n\n\tcontext->global->v1.shared_context = NULL;\n\n\tkfree(v1_context);\n}\n\nstatic int etnaviv_iommuv1_map(struct etnaviv_iommu_context *context,\n\t\t\t       unsigned long iova, phys_addr_t paddr,\n\t\t\t       size_t size, int prot)\n{\n\tstruct etnaviv_iommuv1_context *v1_context = to_v1_context(context);\n\tunsigned int index = (iova - GPU_MEM_START) / SZ_4K;\n\n\tif (size != SZ_4K)\n\t\treturn -EINVAL;\n\n\tv1_context->pgtable_cpu[index] = paddr;\n\n\treturn 0;\n}\n\nstatic size_t etnaviv_iommuv1_unmap(struct etnaviv_iommu_context *context,\n\tunsigned long iova, size_t size)\n{\n\tstruct etnaviv_iommuv1_context *v1_context = to_v1_context(context);\n\tunsigned int index = (iova - GPU_MEM_START) / SZ_4K;\n\n\tif (size != SZ_4K)\n\t\treturn -EINVAL;\n\n\tv1_context->pgtable_cpu[index] = context->global->bad_page_dma;\n\n\treturn SZ_4K;\n}\n\nstatic size_t etnaviv_iommuv1_dump_size(struct etnaviv_iommu_context *context)\n{\n\treturn PT_SIZE;\n}\n\nstatic void etnaviv_iommuv1_dump(struct etnaviv_iommu_context *context,\n\t\t\t\t void *buf)\n{\n\tstruct etnaviv_iommuv1_context *v1_context = to_v1_context(context);\n\n\tmemcpy(buf, v1_context->pgtable_cpu, PT_SIZE);\n}\n\nstatic void etnaviv_iommuv1_restore(struct etnaviv_gpu *gpu,\n\t\t\t     struct etnaviv_iommu_context *context)\n{\n\tstruct etnaviv_iommuv1_context *v1_context = to_v1_context(context);\n\tu32 pgtable;\n\n\tif (gpu->mmu_context)\n\t\tetnaviv_iommu_context_put(gpu->mmu_context);\n\tgpu->mmu_context = etnaviv_iommu_context_get(context);\n\n\t \n\tgpu_write(gpu, VIVS_MC_MEMORY_BASE_ADDR_RA, context->global->memory_base);\n\tgpu_write(gpu, VIVS_MC_MEMORY_BASE_ADDR_FE, context->global->memory_base);\n\tgpu_write(gpu, VIVS_MC_MEMORY_BASE_ADDR_TX, context->global->memory_base);\n\tgpu_write(gpu, VIVS_MC_MEMORY_BASE_ADDR_PEZ, context->global->memory_base);\n\tgpu_write(gpu, VIVS_MC_MEMORY_BASE_ADDR_PE, context->global->memory_base);\n\n\t \n\tpgtable = (u32)v1_context->pgtable_dma;\n\n\tgpu_write(gpu, VIVS_MC_MMU_FE_PAGE_TABLE, pgtable);\n\tgpu_write(gpu, VIVS_MC_MMU_TX_PAGE_TABLE, pgtable);\n\tgpu_write(gpu, VIVS_MC_MMU_PE_PAGE_TABLE, pgtable);\n\tgpu_write(gpu, VIVS_MC_MMU_PEZ_PAGE_TABLE, pgtable);\n\tgpu_write(gpu, VIVS_MC_MMU_RA_PAGE_TABLE, pgtable);\n}\n\n\nconst struct etnaviv_iommu_ops etnaviv_iommuv1_ops = {\n\t.free = etnaviv_iommuv1_free,\n\t.map = etnaviv_iommuv1_map,\n\t.unmap = etnaviv_iommuv1_unmap,\n\t.dump_size = etnaviv_iommuv1_dump_size,\n\t.dump = etnaviv_iommuv1_dump,\n\t.restore = etnaviv_iommuv1_restore,\n};\n\nstruct etnaviv_iommu_context *\netnaviv_iommuv1_context_alloc(struct etnaviv_iommu_global *global)\n{\n\tstruct etnaviv_iommuv1_context *v1_context;\n\tstruct etnaviv_iommu_context *context;\n\n\tmutex_lock(&global->lock);\n\n\t \n\tif (global->v1.shared_context) {\n\t\tcontext = global->v1.shared_context;\n\t\tetnaviv_iommu_context_get(context);\n\t\tmutex_unlock(&global->lock);\n\t\treturn context;\n\t}\n\n\tv1_context = kzalloc(sizeof(*v1_context), GFP_KERNEL);\n\tif (!v1_context) {\n\t\tmutex_unlock(&global->lock);\n\t\treturn NULL;\n\t}\n\n\tv1_context->pgtable_cpu = dma_alloc_wc(global->dev, PT_SIZE,\n\t\t\t\t\t       &v1_context->pgtable_dma,\n\t\t\t\t\t       GFP_KERNEL);\n\tif (!v1_context->pgtable_cpu)\n\t\tgoto out_free;\n\n\tmemset32(v1_context->pgtable_cpu, global->bad_page_dma, PT_ENTRIES);\n\n\tcontext = &v1_context->base;\n\tcontext->global = global;\n\tkref_init(&context->refcount);\n\tmutex_init(&context->lock);\n\tINIT_LIST_HEAD(&context->mappings);\n\tdrm_mm_init(&context->mm, GPU_MEM_START, PT_ENTRIES * SZ_4K);\n\tcontext->global->v1.shared_context = context;\n\n\tmutex_unlock(&global->lock);\n\n\treturn context;\n\nout_free:\n\tmutex_unlock(&global->lock);\n\tkfree(v1_context);\n\treturn NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}