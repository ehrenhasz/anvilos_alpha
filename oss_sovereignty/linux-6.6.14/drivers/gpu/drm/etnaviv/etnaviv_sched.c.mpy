{
  "module_name": "etnaviv_sched.c",
  "hash_id": "4f77a937cdc34f7f316d1ee8b019e7378e326847245cc3ed68f5d121760fd56a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/etnaviv/etnaviv_sched.c",
  "human_readable_source": "\n \n\n#include <linux/moduleparam.h>\n\n#include \"etnaviv_drv.h\"\n#include \"etnaviv_dump.h\"\n#include \"etnaviv_gem.h\"\n#include \"etnaviv_gpu.h\"\n#include \"etnaviv_sched.h\"\n#include \"state.xml.h\"\n\nstatic int etnaviv_job_hang_limit = 0;\nmodule_param_named(job_hang_limit, etnaviv_job_hang_limit, int , 0444);\nstatic int etnaviv_hw_jobs_limit = 4;\nmodule_param_named(hw_job_limit, etnaviv_hw_jobs_limit, int , 0444);\n\nstatic struct dma_fence *etnaviv_sched_run_job(struct drm_sched_job *sched_job)\n{\n\tstruct etnaviv_gem_submit *submit = to_etnaviv_submit(sched_job);\n\tstruct dma_fence *fence = NULL;\n\n\tif (likely(!sched_job->s_fence->finished.error))\n\t\tfence = etnaviv_gpu_submit(submit);\n\telse\n\t\tdev_dbg(submit->gpu->dev, \"skipping bad job\\n\");\n\n\treturn fence;\n}\n\nstatic enum drm_gpu_sched_stat etnaviv_sched_timedout_job(struct drm_sched_job\n\t\t\t\t\t\t\t  *sched_job)\n{\n\tstruct etnaviv_gem_submit *submit = to_etnaviv_submit(sched_job);\n\tstruct etnaviv_gpu *gpu = submit->gpu;\n\tu32 dma_addr;\n\tint change;\n\n\t \n\tdrm_sched_stop(&gpu->sched, sched_job);\n\n\t \n\tif (dma_fence_is_signaled(submit->out_fence))\n\t\tgoto out_no_timeout;\n\n\t \n\tdma_addr = gpu_read(gpu, VIVS_FE_DMA_ADDRESS);\n\tchange = dma_addr - gpu->hangcheck_dma_addr;\n\tif (gpu->state == ETNA_GPU_STATE_RUNNING &&\n\t    (gpu->completed_fence != gpu->hangcheck_fence ||\n\t     change < 0 || change > 16)) {\n\t\tgpu->hangcheck_dma_addr = dma_addr;\n\t\tgpu->hangcheck_fence = gpu->completed_fence;\n\t\tgoto out_no_timeout;\n\t}\n\n\tif(sched_job)\n\t\tdrm_sched_increase_karma(sched_job);\n\n\t \n\tetnaviv_core_dump(submit);\n\tetnaviv_gpu_recover_hang(submit);\n\n\tdrm_sched_resubmit_jobs(&gpu->sched);\n\n\tdrm_sched_start(&gpu->sched, true);\n\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n\nout_no_timeout:\n\t \n\tdrm_sched_start(&gpu->sched, true);\n\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n}\n\nstatic void etnaviv_sched_free_job(struct drm_sched_job *sched_job)\n{\n\tstruct etnaviv_gem_submit *submit = to_etnaviv_submit(sched_job);\n\n\tdrm_sched_job_cleanup(sched_job);\n\n\tetnaviv_submit_put(submit);\n}\n\nstatic const struct drm_sched_backend_ops etnaviv_sched_ops = {\n\t.run_job = etnaviv_sched_run_job,\n\t.timedout_job = etnaviv_sched_timedout_job,\n\t.free_job = etnaviv_sched_free_job,\n};\n\nint etnaviv_sched_push_job(struct etnaviv_gem_submit *submit)\n{\n\tstruct etnaviv_gpu *gpu = submit->gpu;\n\tint ret;\n\n\t \n\tmutex_lock(&gpu->sched_lock);\n\n\tdrm_sched_job_arm(&submit->sched_job);\n\n\tsubmit->out_fence = dma_fence_get(&submit->sched_job.s_fence->finished);\n\tret = xa_alloc_cyclic(&gpu->user_fences, &submit->out_fence_id,\n\t\t\t      submit->out_fence, xa_limit_32b,\n\t\t\t      &gpu->next_user_fence, GFP_KERNEL);\n\tif (ret < 0) {\n\t\tdrm_sched_job_cleanup(&submit->sched_job);\n\t\tgoto out_unlock;\n\t}\n\n\t \n\tkref_get(&submit->refcount);\n\n\tdrm_sched_entity_push_job(&submit->sched_job);\n\nout_unlock:\n\tmutex_unlock(&gpu->sched_lock);\n\n\treturn ret;\n}\n\nint etnaviv_sched_init(struct etnaviv_gpu *gpu)\n{\n\tint ret;\n\n\tret = drm_sched_init(&gpu->sched, &etnaviv_sched_ops,\n\t\t\t     etnaviv_hw_jobs_limit, etnaviv_job_hang_limit,\n\t\t\t     msecs_to_jiffies(500), NULL, NULL,\n\t\t\t     dev_name(gpu->dev), gpu->dev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nvoid etnaviv_sched_fini(struct etnaviv_gpu *gpu)\n{\n\tdrm_sched_fini(&gpu->sched);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}