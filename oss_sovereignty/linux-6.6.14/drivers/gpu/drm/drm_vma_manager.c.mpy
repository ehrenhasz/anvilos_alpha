{
  "module_name": "drm_vma_manager.c",
  "hash_id": "2819207ab5c1b67d9460d45144d1dc14838fa126ef6c1a08b98d155aa0ae7d16",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/drm_vma_manager.c",
  "human_readable_source": "\n \n\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/rbtree.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/types.h>\n\n#include <drm/drm_mm.h>\n#include <drm/drm_vma_manager.h>\n\n \n\n \nvoid drm_vma_offset_manager_init(struct drm_vma_offset_manager *mgr,\n\t\t\t\t unsigned long page_offset, unsigned long size)\n{\n\trwlock_init(&mgr->vm_lock);\n\tdrm_mm_init(&mgr->vm_addr_space_mm, page_offset, size);\n}\nEXPORT_SYMBOL(drm_vma_offset_manager_init);\n\n \nvoid drm_vma_offset_manager_destroy(struct drm_vma_offset_manager *mgr)\n{\n\tdrm_mm_takedown(&mgr->vm_addr_space_mm);\n}\nEXPORT_SYMBOL(drm_vma_offset_manager_destroy);\n\n \nstruct drm_vma_offset_node *drm_vma_offset_lookup_locked(struct drm_vma_offset_manager *mgr,\n\t\t\t\t\t\t\t unsigned long start,\n\t\t\t\t\t\t\t unsigned long pages)\n{\n\tstruct drm_mm_node *node, *best;\n\tstruct rb_node *iter;\n\tunsigned long offset;\n\n\titer = mgr->vm_addr_space_mm.interval_tree.rb_root.rb_node;\n\tbest = NULL;\n\n\twhile (likely(iter)) {\n\t\tnode = rb_entry(iter, struct drm_mm_node, rb);\n\t\toffset = node->start;\n\t\tif (start >= offset) {\n\t\t\titer = iter->rb_right;\n\t\t\tbest = node;\n\t\t\tif (start == offset)\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\titer = iter->rb_left;\n\t\t}\n\t}\n\n\t \n\tif (best) {\n\t\toffset = best->start + best->size;\n\t\tif (offset < start + pages)\n\t\t\tbest = NULL;\n\t}\n\n\tif (!best)\n\t\treturn NULL;\n\n\treturn container_of(best, struct drm_vma_offset_node, vm_node);\n}\nEXPORT_SYMBOL(drm_vma_offset_lookup_locked);\n\n \nint drm_vma_offset_add(struct drm_vma_offset_manager *mgr,\n\t\t       struct drm_vma_offset_node *node, unsigned long pages)\n{\n\tint ret = 0;\n\n\twrite_lock(&mgr->vm_lock);\n\n\tif (!drm_mm_node_allocated(&node->vm_node))\n\t\tret = drm_mm_insert_node(&mgr->vm_addr_space_mm,\n\t\t\t\t\t &node->vm_node, pages);\n\n\twrite_unlock(&mgr->vm_lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_vma_offset_add);\n\n \nvoid drm_vma_offset_remove(struct drm_vma_offset_manager *mgr,\n\t\t\t   struct drm_vma_offset_node *node)\n{\n\twrite_lock(&mgr->vm_lock);\n\n\tif (drm_mm_node_allocated(&node->vm_node)) {\n\t\tdrm_mm_remove_node(&node->vm_node);\n\t\tmemset(&node->vm_node, 0, sizeof(node->vm_node));\n\t}\n\n\twrite_unlock(&mgr->vm_lock);\n}\nEXPORT_SYMBOL(drm_vma_offset_remove);\n\nstatic int vma_node_allow(struct drm_vma_offset_node *node,\n\t\t\t  struct drm_file *tag, bool ref_counted)\n{\n\tstruct rb_node **iter;\n\tstruct rb_node *parent = NULL;\n\tstruct drm_vma_offset_file *new, *entry;\n\tint ret = 0;\n\n\t \n\tnew = kmalloc(sizeof(*entry), GFP_KERNEL);\n\n\twrite_lock(&node->vm_lock);\n\n\titer = &node->vm_files.rb_node;\n\n\twhile (likely(*iter)) {\n\t\tparent = *iter;\n\t\tentry = rb_entry(*iter, struct drm_vma_offset_file, vm_rb);\n\n\t\tif (tag == entry->vm_tag) {\n\t\t\tif (ref_counted)\n\t\t\t\tentry->vm_count++;\n\t\t\tgoto unlock;\n\t\t} else if (tag > entry->vm_tag) {\n\t\t\titer = &(*iter)->rb_right;\n\t\t} else {\n\t\t\titer = &(*iter)->rb_left;\n\t\t}\n\t}\n\n\tif (!new) {\n\t\tret = -ENOMEM;\n\t\tgoto unlock;\n\t}\n\n\tnew->vm_tag = tag;\n\tnew->vm_count = 1;\n\trb_link_node(&new->vm_rb, parent, iter);\n\trb_insert_color(&new->vm_rb, &node->vm_files);\n\tnew = NULL;\n\nunlock:\n\twrite_unlock(&node->vm_lock);\n\tkfree(new);\n\treturn ret;\n}\n\n \nint drm_vma_node_allow(struct drm_vma_offset_node *node, struct drm_file *tag)\n{\n\treturn vma_node_allow(node, tag, true);\n}\nEXPORT_SYMBOL(drm_vma_node_allow);\n\n \nint drm_vma_node_allow_once(struct drm_vma_offset_node *node, struct drm_file *tag)\n{\n\treturn vma_node_allow(node, tag, false);\n}\nEXPORT_SYMBOL(drm_vma_node_allow_once);\n\n \nvoid drm_vma_node_revoke(struct drm_vma_offset_node *node,\n\t\t\t struct drm_file *tag)\n{\n\tstruct drm_vma_offset_file *entry;\n\tstruct rb_node *iter;\n\n\twrite_lock(&node->vm_lock);\n\n\titer = node->vm_files.rb_node;\n\twhile (likely(iter)) {\n\t\tentry = rb_entry(iter, struct drm_vma_offset_file, vm_rb);\n\t\tif (tag == entry->vm_tag) {\n\t\t\tif (!--entry->vm_count) {\n\t\t\t\trb_erase(&entry->vm_rb, &node->vm_files);\n\t\t\t\tkfree(entry);\n\t\t\t}\n\t\t\tbreak;\n\t\t} else if (tag > entry->vm_tag) {\n\t\t\titer = iter->rb_right;\n\t\t} else {\n\t\t\titer = iter->rb_left;\n\t\t}\n\t}\n\n\twrite_unlock(&node->vm_lock);\n}\nEXPORT_SYMBOL(drm_vma_node_revoke);\n\n \nbool drm_vma_node_is_allowed(struct drm_vma_offset_node *node,\n\t\t\t     struct drm_file *tag)\n{\n\tstruct drm_vma_offset_file *entry;\n\tstruct rb_node *iter;\n\n\tread_lock(&node->vm_lock);\n\n\titer = node->vm_files.rb_node;\n\twhile (likely(iter)) {\n\t\tentry = rb_entry(iter, struct drm_vma_offset_file, vm_rb);\n\t\tif (tag == entry->vm_tag)\n\t\t\tbreak;\n\t\telse if (tag > entry->vm_tag)\n\t\t\titer = iter->rb_right;\n\t\telse\n\t\t\titer = iter->rb_left;\n\t}\n\n\tread_unlock(&node->vm_lock);\n\n\treturn iter;\n}\nEXPORT_SYMBOL(drm_vma_node_is_allowed);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}