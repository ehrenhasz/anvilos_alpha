{
  "module_name": "drm_bufs.c",
  "hash_id": "8d8b650389cfed7b170f262933316bdaa87a1a9a13508f98bd1ffd38ad0e1f8d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/drm_bufs.c",
  "human_readable_source": " \n\n#include <linux/export.h>\n#include <linux/log2.h>\n#include <linux/mm.h>\n#include <linux/mman.h>\n#include <linux/nospec.h>\n#include <linux/pci.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n\n#include <asm/shmparam.h>\n\n#include <drm/drm_device.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_file.h>\n#include <drm/drm_print.h>\n\n#include \"drm_legacy.h\"\n\n\nstatic struct drm_map_list *drm_find_matching_map(struct drm_device *dev,\n\t\t\t\t\t\t  struct drm_local_map *map)\n{\n\tstruct drm_map_list *entry;\n\n\tlist_for_each_entry(entry, &dev->maplist, head) {\n\t\t \n\t\tif (!entry->map ||\n\t\t    map->type != entry->map->type ||\n\t\t    entry->master != dev->master)\n\t\t\tcontinue;\n\t\tswitch (map->type) {\n\t\tcase _DRM_SHM:\n\t\t\tif (map->flags != _DRM_CONTAINS_LOCK)\n\t\t\t\tbreak;\n\t\t\treturn entry;\n\t\tcase _DRM_REGISTERS:\n\t\tcase _DRM_FRAME_BUFFER:\n\t\t\tif ((entry->map->offset & 0xffffffff) ==\n\t\t\t    (map->offset & 0xffffffff))\n\t\t\t\treturn entry;\n\t\t\tbreak;\n\t\tdefault:  \n\t\t\tbreak;\n\t\t}\n\t\tif (entry->map->offset == map->offset)\n\t\t\treturn entry;\n\t}\n\n\treturn NULL;\n}\n\nstatic int drm_map_handle(struct drm_device *dev, struct drm_hash_item *hash,\n\t\t\t  unsigned long user_token, int hashed_handle, int shm)\n{\n\tint use_hashed_handle, shift;\n\tunsigned long add;\n\n#if (BITS_PER_LONG == 64)\n\tuse_hashed_handle = ((user_token & 0xFFFFFFFF00000000UL) || hashed_handle);\n#elif (BITS_PER_LONG == 32)\n\tuse_hashed_handle = hashed_handle;\n#else\n#error Unsupported long size. Neither 64 nor 32 bits.\n#endif\n\n\tif (!use_hashed_handle) {\n\t\tint ret;\n\n\t\thash->key = user_token >> PAGE_SHIFT;\n\t\tret = drm_ht_insert_item(&dev->map_hash, hash);\n\t\tif (ret != -EINVAL)\n\t\t\treturn ret;\n\t}\n\n\tshift = 0;\n\tadd = DRM_MAP_HASH_OFFSET >> PAGE_SHIFT;\n\tif (shm && (SHMLBA > PAGE_SIZE)) {\n\t\tint bits = ilog2(SHMLBA >> PAGE_SHIFT) + 1;\n\n\t\t \n\t\tshift = bits;\n\t\tadd |= ((user_token >> PAGE_SHIFT) & ((1UL << bits) - 1UL));\n\t}\n\n\treturn drm_ht_just_insert_please(&dev->map_hash, hash,\n\t\t\t\t\t user_token, 32 - PAGE_SHIFT - 3,\n\t\t\t\t\t shift, add);\n}\n\n \nstatic int drm_addmap_core(struct drm_device *dev, resource_size_t offset,\n\t\t\t   unsigned int size, enum drm_map_type type,\n\t\t\t   enum drm_map_flags flags,\n\t\t\t   struct drm_map_list **maplist)\n{\n\tstruct drm_local_map *map;\n\tstruct drm_map_list *list;\n\tunsigned long user_token;\n\tint ret;\n\n\tmap = kmalloc(sizeof(*map), GFP_KERNEL);\n\tif (!map)\n\t\treturn -ENOMEM;\n\n\tmap->offset = offset;\n\tmap->size = size;\n\tmap->flags = flags;\n\tmap->type = type;\n\n\t \n\tif ((map->flags & _DRM_REMOVABLE) && map->type != _DRM_SHM) {\n\t\tkfree(map);\n\t\treturn -EINVAL;\n\t}\n\tDRM_DEBUG(\"offset = 0x%08llx, size = 0x%08lx, type = %d\\n\",\n\t\t  (unsigned long long)map->offset, map->size, map->type);\n\n\t \n\tif (map->type == _DRM_SHM)\n\t\tmap->size = PAGE_ALIGN(map->size);\n\n\tif ((map->offset & (~(resource_size_t)PAGE_MASK)) || (map->size & (~PAGE_MASK))) {\n\t\tkfree(map);\n\t\treturn -EINVAL;\n\t}\n\tmap->mtrr = -1;\n\tmap->handle = NULL;\n\n\tswitch (map->type) {\n\tcase _DRM_REGISTERS:\n\tcase _DRM_FRAME_BUFFER:\n#if !defined(__sparc__) && !defined(__alpha__) && !defined(__ia64__) && !defined(__powerpc64__) && !defined(__x86_64__) && !defined(__arm__)\n\t\tif (map->offset + (map->size-1) < map->offset ||\n\t\t    map->offset < virt_to_phys(high_memory)) {\n\t\t\tkfree(map);\n\t\t\treturn -EINVAL;\n\t\t}\n#endif\n\t\t \n\t\tlist = drm_find_matching_map(dev, map);\n\t\tif (list != NULL) {\n\t\t\tif (list->map->size != map->size) {\n\t\t\t\tDRM_DEBUG(\"Matching maps of type %d with \"\n\t\t\t\t\t  \"mismatched sizes, (%ld vs %ld)\\n\",\n\t\t\t\t\t  map->type, map->size,\n\t\t\t\t\t  list->map->size);\n\t\t\t\tlist->map->size = map->size;\n\t\t\t}\n\n\t\t\tkfree(map);\n\t\t\t*maplist = list;\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (map->type == _DRM_FRAME_BUFFER ||\n\t\t    (map->flags & _DRM_WRITE_COMBINING)) {\n\t\t\tmap->mtrr =\n\t\t\t\tarch_phys_wc_add(map->offset, map->size);\n\t\t}\n\t\tif (map->type == _DRM_REGISTERS) {\n\t\t\tif (map->flags & _DRM_WRITE_COMBINING)\n\t\t\t\tmap->handle = ioremap_wc(map->offset,\n\t\t\t\t\t\t\t map->size);\n\t\t\telse\n\t\t\t\tmap->handle = ioremap(map->offset, map->size);\n\t\t\tif (!map->handle) {\n\t\t\t\tkfree(map);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\tcase _DRM_SHM:\n\t\tlist = drm_find_matching_map(dev, map);\n\t\tif (list != NULL) {\n\t\t\tif (list->map->size != map->size) {\n\t\t\t\tDRM_DEBUG(\"Matching maps of type %d with \"\n\t\t\t\t\t  \"mismatched sizes, (%ld vs %ld)\\n\",\n\t\t\t\t\t  map->type, map->size, list->map->size);\n\t\t\t\tlist->map->size = map->size;\n\t\t\t}\n\n\t\t\tkfree(map);\n\t\t\t*maplist = list;\n\t\t\treturn 0;\n\t\t}\n\t\tmap->handle = vmalloc_user(map->size);\n\t\tDRM_DEBUG(\"%lu %d %p\\n\",\n\t\t\t  map->size, order_base_2(map->size), map->handle);\n\t\tif (!map->handle) {\n\t\t\tkfree(map);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tmap->offset = (unsigned long)map->handle;\n\t\tif (map->flags & _DRM_CONTAINS_LOCK) {\n\t\t\t \n\t\t\tif (dev->master->lock.hw_lock != NULL) {\n\t\t\t\tvfree(map->handle);\n\t\t\t\tkfree(map);\n\t\t\t\treturn -EBUSY;\n\t\t\t}\n\t\t\tdev->sigdata.lock = dev->master->lock.hw_lock = map->handle;\t \n\t\t}\n\t\tbreak;\n\tcase _DRM_AGP: {\n\t\tstruct drm_agp_mem *entry;\n\t\tint valid = 0;\n\n\t\tif (!dev->agp) {\n\t\t\tkfree(map);\n\t\t\treturn -EINVAL;\n\t\t}\n#ifdef __alpha__\n\t\tmap->offset += dev->hose->mem_space->start;\n#endif\n\t\t \n\t\tif (map->offset < dev->agp->base ||\n\t\t    map->offset > dev->agp->base +\n\t\t    dev->agp->agp_info.aper_size * 1024 * 1024 - 1) {\n\t\t\tmap->offset += dev->agp->base;\n\t\t}\n\t\tmap->mtrr = dev->agp->agp_mtrr;\t \n\n\t\t \n\t\tlist_for_each_entry(entry, &dev->agp->memory, head) {\n\t\t\tif ((map->offset >= entry->bound) &&\n\t\t\t    (map->offset + map->size <= entry->bound + entry->pages * PAGE_SIZE)) {\n\t\t\t\tvalid = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!list_empty(&dev->agp->memory) && !valid) {\n\t\t\tkfree(map);\n\t\t\treturn -EPERM;\n\t\t}\n\t\tDRM_DEBUG(\"AGP offset = 0x%08llx, size = 0x%08lx\\n\",\n\t\t\t  (unsigned long long)map->offset, map->size);\n\n\t\tbreak;\n\t}\n\tcase _DRM_SCATTER_GATHER:\n\t\tif (!dev->sg) {\n\t\t\tkfree(map);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmap->offset += (unsigned long)dev->sg->virtual;\n\t\tbreak;\n\tcase _DRM_CONSISTENT:\n\t\t \n\t\tmap->handle = dma_alloc_coherent(dev->dev,\n\t\t\t\t\t\t map->size,\n\t\t\t\t\t\t &map->offset,\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (!map->handle) {\n\t\t\tkfree(map);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tkfree(map);\n\t\treturn -EINVAL;\n\t}\n\n\tlist = kzalloc(sizeof(*list), GFP_KERNEL);\n\tif (!list) {\n\t\tif (map->type == _DRM_REGISTERS)\n\t\t\tiounmap(map->handle);\n\t\tkfree(map);\n\t\treturn -EINVAL;\n\t}\n\tlist->map = map;\n\n\tmutex_lock(&dev->struct_mutex);\n\tlist_add(&list->head, &dev->maplist);\n\n\t \n\t \n\tuser_token = (map->type == _DRM_SHM) ? (unsigned long)map->handle :\n\t\tmap->offset;\n\tret = drm_map_handle(dev, &list->hash, user_token, 0,\n\t\t\t     (map->type == _DRM_SHM));\n\tif (ret) {\n\t\tif (map->type == _DRM_REGISTERS)\n\t\t\tiounmap(map->handle);\n\t\tkfree(map);\n\t\tkfree(list);\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\treturn ret;\n\t}\n\n\tlist->user_token = list->hash.key << PAGE_SHIFT;\n\tmutex_unlock(&dev->struct_mutex);\n\n\tif (!(map->flags & _DRM_DRIVER))\n\t\tlist->master = dev->master;\n\t*maplist = list;\n\treturn 0;\n}\n\nint drm_legacy_addmap(struct drm_device *dev, resource_size_t offset,\n\t\t      unsigned int size, enum drm_map_type type,\n\t\t      enum drm_map_flags flags, struct drm_local_map **map_ptr)\n{\n\tstruct drm_map_list *list;\n\tint rc;\n\n\trc = drm_addmap_core(dev, offset, size, type, flags, &list);\n\tif (!rc)\n\t\t*map_ptr = list->map;\n\treturn rc;\n}\nEXPORT_SYMBOL(drm_legacy_addmap);\n\nstruct drm_local_map *drm_legacy_findmap(struct drm_device *dev,\n\t\t\t\t\t unsigned int token)\n{\n\tstruct drm_map_list *_entry;\n\n\tlist_for_each_entry(_entry, &dev->maplist, head)\n\t\tif (_entry->user_token == token)\n\t\t\treturn _entry->map;\n\treturn NULL;\n}\nEXPORT_SYMBOL(drm_legacy_findmap);\n\n \nint drm_legacy_addmap_ioctl(struct drm_device *dev, void *data,\n\t\t\t    struct drm_file *file_priv)\n{\n\tstruct drm_map *map = data;\n\tstruct drm_map_list *maplist;\n\tint err;\n\n\tif (!(capable(CAP_SYS_ADMIN) || map->type == _DRM_AGP || map->type == _DRM_SHM))\n\t\treturn -EPERM;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\terr = drm_addmap_core(dev, map->offset, map->size, map->type,\n\t\t\t      map->flags, &maplist);\n\n\tif (err)\n\t\treturn err;\n\n\t \n\tmap->handle = (void *)(unsigned long)maplist->user_token;\n\n\t \n\tmap->mtrr = -1;\n\n\treturn 0;\n}\n\n \nint drm_legacy_getmap_ioctl(struct drm_device *dev, void *data,\n\t\t\t    struct drm_file *file_priv)\n{\n\tstruct drm_map *map = data;\n\tstruct drm_map_list *r_list = NULL;\n\tstruct list_head *list;\n\tint idx;\n\tint i;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tidx = map->offset;\n\tif (idx < 0)\n\t\treturn -EINVAL;\n\n\ti = 0;\n\tmutex_lock(&dev->struct_mutex);\n\tlist_for_each(list, &dev->maplist) {\n\t\tif (i == idx) {\n\t\t\tr_list = list_entry(list, struct drm_map_list, head);\n\t\t\tbreak;\n\t\t}\n\t\ti++;\n\t}\n\tif (!r_list || !r_list->map) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\treturn -EINVAL;\n\t}\n\n\tmap->offset = r_list->map->offset;\n\tmap->size = r_list->map->size;\n\tmap->type = r_list->map->type;\n\tmap->flags = r_list->map->flags;\n\tmap->handle = (void *)(unsigned long) r_list->user_token;\n\tmap->mtrr = arch_phys_wc_index(r_list->map->mtrr);\n\n\tmutex_unlock(&dev->struct_mutex);\n\n\treturn 0;\n}\n\n \nint drm_legacy_rmmap_locked(struct drm_device *dev, struct drm_local_map *map)\n{\n\tstruct drm_map_list *r_list = NULL, *list_t;\n\tint found = 0;\n\tstruct drm_master *master;\n\n\t \n\tlist_for_each_entry_safe(r_list, list_t, &dev->maplist, head) {\n\t\tif (r_list->map == map) {\n\t\t\tmaster = r_list->master;\n\t\t\tlist_del(&r_list->head);\n\t\t\tdrm_ht_remove_key(&dev->map_hash,\n\t\t\t\t\t  r_list->user_token >> PAGE_SHIFT);\n\t\t\tkfree(r_list);\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found)\n\t\treturn -EINVAL;\n\n\tswitch (map->type) {\n\tcase _DRM_REGISTERS:\n\t\tiounmap(map->handle);\n\t\tfallthrough;\n\tcase _DRM_FRAME_BUFFER:\n\t\tarch_phys_wc_del(map->mtrr);\n\t\tbreak;\n\tcase _DRM_SHM:\n\t\tvfree(map->handle);\n\t\tif (master) {\n\t\t\tif (dev->sigdata.lock == master->lock.hw_lock)\n\t\t\t\tdev->sigdata.lock = NULL;\n\t\t\tmaster->lock.hw_lock = NULL;    \n\t\t\tmaster->lock.file_priv = NULL;\n\t\t\twake_up_interruptible_all(&master->lock.lock_queue);\n\t\t}\n\t\tbreak;\n\tcase _DRM_AGP:\n\tcase _DRM_SCATTER_GATHER:\n\t\tbreak;\n\tcase _DRM_CONSISTENT:\n\t\tdma_free_coherent(dev->dev,\n\t\t\t\t  map->size,\n\t\t\t\t  map->handle,\n\t\t\t\t  map->offset);\n\t\tbreak;\n\t}\n\tkfree(map);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_legacy_rmmap_locked);\n\nvoid drm_legacy_rmmap(struct drm_device *dev, struct drm_local_map *map)\n{\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn;\n\n\tmutex_lock(&dev->struct_mutex);\n\tdrm_legacy_rmmap_locked(dev, map);\n\tmutex_unlock(&dev->struct_mutex);\n}\nEXPORT_SYMBOL(drm_legacy_rmmap);\n\nvoid drm_legacy_master_rmmaps(struct drm_device *dev, struct drm_master *master)\n{\n\tstruct drm_map_list *r_list, *list_temp;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn;\n\n\tmutex_lock(&dev->struct_mutex);\n\tlist_for_each_entry_safe(r_list, list_temp, &dev->maplist, head) {\n\t\tif (r_list->master == master) {\n\t\t\tdrm_legacy_rmmap_locked(dev, r_list->map);\n\t\t\tr_list = NULL;\n\t\t}\n\t}\n\tmutex_unlock(&dev->struct_mutex);\n}\n\nvoid drm_legacy_rmmaps(struct drm_device *dev)\n{\n\tstruct drm_map_list *r_list, *list_temp;\n\n\tlist_for_each_entry_safe(r_list, list_temp, &dev->maplist, head)\n\t\tdrm_legacy_rmmap(dev, r_list->map);\n}\n\n \nint drm_legacy_rmmap_ioctl(struct drm_device *dev, void *data,\n\t\t\t   struct drm_file *file_priv)\n{\n\tstruct drm_map *request = data;\n\tstruct drm_local_map *map = NULL;\n\tstruct drm_map_list *r_list;\n\tint ret;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&dev->struct_mutex);\n\tlist_for_each_entry(r_list, &dev->maplist, head) {\n\t\tif (r_list->map &&\n\t\t    r_list->user_token == (unsigned long)request->handle &&\n\t\t    r_list->map->flags & _DRM_REMOVABLE) {\n\t\t\tmap = r_list->map;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (list_empty(&dev->maplist) || !map) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif ((map->type == _DRM_REGISTERS) || (map->type == _DRM_FRAME_BUFFER)) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\treturn 0;\n\t}\n\n\tret = drm_legacy_rmmap_locked(dev, map);\n\n\tmutex_unlock(&dev->struct_mutex);\n\n\treturn ret;\n}\n\n \nstatic void drm_cleanup_buf_error(struct drm_device *dev,\n\t\t\t\t  struct drm_buf_entry *entry)\n{\n\tdrm_dma_handle_t *dmah;\n\tint i;\n\n\tif (entry->seg_count) {\n\t\tfor (i = 0; i < entry->seg_count; i++) {\n\t\t\tif (entry->seglist[i]) {\n\t\t\t\tdmah = entry->seglist[i];\n\t\t\t\tdma_free_coherent(dev->dev,\n\t\t\t\t\t\t  dmah->size,\n\t\t\t\t\t\t  dmah->vaddr,\n\t\t\t\t\t\t  dmah->busaddr);\n\t\t\t\tkfree(dmah);\n\t\t\t}\n\t\t}\n\t\tkfree(entry->seglist);\n\n\t\tentry->seg_count = 0;\n\t}\n\n\tif (entry->buf_count) {\n\t\tfor (i = 0; i < entry->buf_count; i++) {\n\t\t\tkfree(entry->buflist[i].dev_private);\n\t\t}\n\t\tkfree(entry->buflist);\n\n\t\tentry->buf_count = 0;\n\t}\n}\n\n#if IS_ENABLED(CONFIG_AGP)\n \nint drm_legacy_addbufs_agp(struct drm_device *dev,\n\t\t\t   struct drm_buf_desc *request)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf_entry *entry;\n\tstruct drm_agp_mem *agp_entry;\n\tstruct drm_buf *buf;\n\tunsigned long offset;\n\tunsigned long agp_offset;\n\tint count;\n\tint order;\n\tint size;\n\tint alignment;\n\tint page_order;\n\tint total;\n\tint byte_count;\n\tint i, valid;\n\tstruct drm_buf **temp_buflist;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tcount = request->count;\n\torder = order_base_2(request->size);\n\tsize = 1 << order;\n\n\talignment = (request->flags & _DRM_PAGE_ALIGN)\n\t    ? PAGE_ALIGN(size) : size;\n\tpage_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;\n\ttotal = PAGE_SIZE << page_order;\n\n\tbyte_count = 0;\n\tagp_offset = dev->agp->base + request->agp_start;\n\n\tDRM_DEBUG(\"count:      %d\\n\", count);\n\tDRM_DEBUG(\"order:      %d\\n\", order);\n\tDRM_DEBUG(\"size:       %d\\n\", size);\n\tDRM_DEBUG(\"agp_offset: %lx\\n\", agp_offset);\n\tDRM_DEBUG(\"alignment:  %d\\n\", alignment);\n\tDRM_DEBUG(\"page_order: %d\\n\", page_order);\n\tDRM_DEBUG(\"total:      %d\\n\", total);\n\n\tif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\n\t\treturn -EINVAL;\n\n\t \n\tvalid = 0;\n\tlist_for_each_entry(agp_entry, &dev->agp->memory, head) {\n\t\tif ((agp_offset >= agp_entry->bound) &&\n\t\t    (agp_offset + total * count <= agp_entry->bound + agp_entry->pages * PAGE_SIZE)) {\n\t\t\tvalid = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!list_empty(&dev->agp->memory) && !valid) {\n\t\tDRM_DEBUG(\"zone invalid\\n\");\n\t\treturn -EINVAL;\n\t}\n\tspin_lock(&dev->buf_lock);\n\tif (dev->buf_use) {\n\t\tspin_unlock(&dev->buf_lock);\n\t\treturn -EBUSY;\n\t}\n\tatomic_inc(&dev->buf_alloc);\n\tspin_unlock(&dev->buf_lock);\n\n\tmutex_lock(&dev->struct_mutex);\n\tentry = &dma->bufs[order];\n\tif (entry->buf_count) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\t \n\t}\n\n\tif (count < 0 || count > 4096) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -EINVAL;\n\t}\n\n\tentry->buflist = kcalloc(count, sizeof(*entry->buflist), GFP_KERNEL);\n\tif (!entry->buflist) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\n\tentry->buf_size = size;\n\tentry->page_order = page_order;\n\n\toffset = 0;\n\n\twhile (entry->buf_count < count) {\n\t\tbuf = &entry->buflist[entry->buf_count];\n\t\tbuf->idx = dma->buf_count + entry->buf_count;\n\t\tbuf->total = alignment;\n\t\tbuf->order = order;\n\t\tbuf->used = 0;\n\n\t\tbuf->offset = (dma->byte_count + offset);\n\t\tbuf->bus_address = agp_offset + offset;\n\t\tbuf->address = (void *)(agp_offset + offset);\n\t\tbuf->next = NULL;\n\t\tbuf->waiting = 0;\n\t\tbuf->pending = 0;\n\t\tbuf->file_priv = NULL;\n\n\t\tbuf->dev_priv_size = dev->driver->dev_priv_size;\n\t\tbuf->dev_private = kzalloc(buf->dev_priv_size, GFP_KERNEL);\n\t\tif (!buf->dev_private) {\n\t\t\t \n\t\t\tentry->buf_count = count;\n\t\t\tdrm_cleanup_buf_error(dev, entry);\n\t\t\tmutex_unlock(&dev->struct_mutex);\n\t\t\tatomic_dec(&dev->buf_alloc);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tDRM_DEBUG(\"buffer %d @ %p\\n\", entry->buf_count, buf->address);\n\n\t\toffset += alignment;\n\t\tentry->buf_count++;\n\t\tbyte_count += PAGE_SIZE << page_order;\n\t}\n\n\tDRM_DEBUG(\"byte_count: %d\\n\", byte_count);\n\n\ttemp_buflist = krealloc(dma->buflist,\n\t\t\t\t(dma->buf_count + entry->buf_count) *\n\t\t\t\tsizeof(*dma->buflist), GFP_KERNEL);\n\tif (!temp_buflist) {\n\t\t \n\t\tdrm_cleanup_buf_error(dev, entry);\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\tdma->buflist = temp_buflist;\n\n\tfor (i = 0; i < entry->buf_count; i++) {\n\t\tdma->buflist[i + dma->buf_count] = &entry->buflist[i];\n\t}\n\n\tdma->buf_count += entry->buf_count;\n\tdma->seg_count += entry->seg_count;\n\tdma->page_count += byte_count >> PAGE_SHIFT;\n\tdma->byte_count += byte_count;\n\n\tDRM_DEBUG(\"dma->buf_count : %d\\n\", dma->buf_count);\n\tDRM_DEBUG(\"entry->buf_count : %d\\n\", entry->buf_count);\n\n\tmutex_unlock(&dev->struct_mutex);\n\n\trequest->count = entry->buf_count;\n\trequest->size = size;\n\n\tdma->flags = _DRM_DMA_USE_AGP;\n\n\tatomic_dec(&dev->buf_alloc);\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_legacy_addbufs_agp);\n#endif  \n\nint drm_legacy_addbufs_pci(struct drm_device *dev,\n\t\t\t   struct drm_buf_desc *request)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tint count;\n\tint order;\n\tint size;\n\tint total;\n\tint page_order;\n\tstruct drm_buf_entry *entry;\n\tdrm_dma_handle_t *dmah;\n\tstruct drm_buf *buf;\n\tint alignment;\n\tunsigned long offset;\n\tint i;\n\tint byte_count;\n\tint page_count;\n\tunsigned long *temp_pagelist;\n\tstruct drm_buf **temp_buflist;\n\n\tif (!drm_core_check_feature(dev, DRIVER_PCI_DMA))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcount = request->count;\n\torder = order_base_2(request->size);\n\tsize = 1 << order;\n\n\tDRM_DEBUG(\"count=%d, size=%d (%d), order=%d\\n\",\n\t\t  request->count, request->size, size, order);\n\n\tif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\n\t\treturn -EINVAL;\n\n\talignment = (request->flags & _DRM_PAGE_ALIGN)\n\t    ? PAGE_ALIGN(size) : size;\n\tpage_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;\n\ttotal = PAGE_SIZE << page_order;\n\n\tspin_lock(&dev->buf_lock);\n\tif (dev->buf_use) {\n\t\tspin_unlock(&dev->buf_lock);\n\t\treturn -EBUSY;\n\t}\n\tatomic_inc(&dev->buf_alloc);\n\tspin_unlock(&dev->buf_lock);\n\n\tmutex_lock(&dev->struct_mutex);\n\tentry = &dma->bufs[order];\n\tif (entry->buf_count) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\t \n\t}\n\n\tif (count < 0 || count > 4096) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -EINVAL;\n\t}\n\n\tentry->buflist = kcalloc(count, sizeof(*entry->buflist), GFP_KERNEL);\n\tif (!entry->buflist) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\n\tentry->seglist = kcalloc(count, sizeof(*entry->seglist), GFP_KERNEL);\n\tif (!entry->seglist) {\n\t\tkfree(entry->buflist);\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\ttemp_pagelist = kmalloc_array(dma->page_count + (count << page_order),\n\t\t\t\t      sizeof(*dma->pagelist),\n\t\t\t\t      GFP_KERNEL);\n\tif (!temp_pagelist) {\n\t\tkfree(entry->buflist);\n\t\tkfree(entry->seglist);\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\tmemcpy(temp_pagelist,\n\t       dma->pagelist, dma->page_count * sizeof(*dma->pagelist));\n\tDRM_DEBUG(\"pagelist: %d entries\\n\",\n\t\t  dma->page_count + (count << page_order));\n\n\tentry->buf_size = size;\n\tentry->page_order = page_order;\n\tbyte_count = 0;\n\tpage_count = 0;\n\n\twhile (entry->buf_count < count) {\n\t\tdmah = kmalloc(sizeof(drm_dma_handle_t), GFP_KERNEL);\n\t\tif (!dmah) {\n\t\t\t \n\t\t\tentry->buf_count = count;\n\t\t\tentry->seg_count = count;\n\t\t\tdrm_cleanup_buf_error(dev, entry);\n\t\t\tkfree(temp_pagelist);\n\t\t\tmutex_unlock(&dev->struct_mutex);\n\t\t\tatomic_dec(&dev->buf_alloc);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tdmah->size = total;\n\t\tdmah->vaddr = dma_alloc_coherent(dev->dev,\n\t\t\t\t\t\t dmah->size,\n\t\t\t\t\t\t &dmah->busaddr,\n\t\t\t\t\t\t GFP_KERNEL);\n\t\tif (!dmah->vaddr) {\n\t\t\tkfree(dmah);\n\n\t\t\t \n\t\t\tentry->buf_count = count;\n\t\t\tentry->seg_count = count;\n\t\t\tdrm_cleanup_buf_error(dev, entry);\n\t\t\tkfree(temp_pagelist);\n\t\t\tmutex_unlock(&dev->struct_mutex);\n\t\t\tatomic_dec(&dev->buf_alloc);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tentry->seglist[entry->seg_count++] = dmah;\n\t\tfor (i = 0; i < (1 << page_order); i++) {\n\t\t\tDRM_DEBUG(\"page %d @ 0x%08lx\\n\",\n\t\t\t\t  dma->page_count + page_count,\n\t\t\t\t  (unsigned long)dmah->vaddr + PAGE_SIZE * i);\n\t\t\ttemp_pagelist[dma->page_count + page_count++]\n\t\t\t\t= (unsigned long)dmah->vaddr + PAGE_SIZE * i;\n\t\t}\n\t\tfor (offset = 0;\n\t\t     offset + size <= total && entry->buf_count < count;\n\t\t     offset += alignment, ++entry->buf_count) {\n\t\t\tbuf = &entry->buflist[entry->buf_count];\n\t\t\tbuf->idx = dma->buf_count + entry->buf_count;\n\t\t\tbuf->total = alignment;\n\t\t\tbuf->order = order;\n\t\t\tbuf->used = 0;\n\t\t\tbuf->offset = (dma->byte_count + byte_count + offset);\n\t\t\tbuf->address = (void *)(dmah->vaddr + offset);\n\t\t\tbuf->bus_address = dmah->busaddr + offset;\n\t\t\tbuf->next = NULL;\n\t\t\tbuf->waiting = 0;\n\t\t\tbuf->pending = 0;\n\t\t\tbuf->file_priv = NULL;\n\n\t\t\tbuf->dev_priv_size = dev->driver->dev_priv_size;\n\t\t\tbuf->dev_private = kzalloc(buf->dev_priv_size,\n\t\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!buf->dev_private) {\n\t\t\t\t \n\t\t\t\tentry->buf_count = count;\n\t\t\t\tentry->seg_count = count;\n\t\t\t\tdrm_cleanup_buf_error(dev, entry);\n\t\t\t\tkfree(temp_pagelist);\n\t\t\t\tmutex_unlock(&dev->struct_mutex);\n\t\t\t\tatomic_dec(&dev->buf_alloc);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\tDRM_DEBUG(\"buffer %d @ %p\\n\",\n\t\t\t\t  entry->buf_count, buf->address);\n\t\t}\n\t\tbyte_count += PAGE_SIZE << page_order;\n\t}\n\n\ttemp_buflist = krealloc(dma->buflist,\n\t\t\t\t(dma->buf_count + entry->buf_count) *\n\t\t\t\tsizeof(*dma->buflist), GFP_KERNEL);\n\tif (!temp_buflist) {\n\t\t \n\t\tdrm_cleanup_buf_error(dev, entry);\n\t\tkfree(temp_pagelist);\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\tdma->buflist = temp_buflist;\n\n\tfor (i = 0; i < entry->buf_count; i++) {\n\t\tdma->buflist[i + dma->buf_count] = &entry->buflist[i];\n\t}\n\n\t \n\tif (dma->page_count) {\n\t\tkfree(dma->pagelist);\n\t}\n\tdma->pagelist = temp_pagelist;\n\n\tdma->buf_count += entry->buf_count;\n\tdma->seg_count += entry->seg_count;\n\tdma->page_count += entry->seg_count << page_order;\n\tdma->byte_count += PAGE_SIZE * (entry->seg_count << page_order);\n\n\tmutex_unlock(&dev->struct_mutex);\n\n\trequest->count = entry->buf_count;\n\trequest->size = size;\n\n\tif (request->flags & _DRM_PCI_BUFFER_RO)\n\t\tdma->flags = _DRM_DMA_USE_PCI_RO;\n\n\tatomic_dec(&dev->buf_alloc);\n\treturn 0;\n\n}\nEXPORT_SYMBOL(drm_legacy_addbufs_pci);\n\nstatic int drm_legacy_addbufs_sg(struct drm_device *dev,\n\t\t\t\t struct drm_buf_desc *request)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf_entry *entry;\n\tstruct drm_buf *buf;\n\tunsigned long offset;\n\tunsigned long agp_offset;\n\tint count;\n\tint order;\n\tint size;\n\tint alignment;\n\tint page_order;\n\tint total;\n\tint byte_count;\n\tint i;\n\tstruct drm_buf **temp_buflist;\n\n\tif (!drm_core_check_feature(dev, DRIVER_SG))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcount = request->count;\n\torder = order_base_2(request->size);\n\tsize = 1 << order;\n\n\talignment = (request->flags & _DRM_PAGE_ALIGN)\n\t    ? PAGE_ALIGN(size) : size;\n\tpage_order = order - PAGE_SHIFT > 0 ? order - PAGE_SHIFT : 0;\n\ttotal = PAGE_SIZE << page_order;\n\n\tbyte_count = 0;\n\tagp_offset = request->agp_start;\n\n\tDRM_DEBUG(\"count:      %d\\n\", count);\n\tDRM_DEBUG(\"order:      %d\\n\", order);\n\tDRM_DEBUG(\"size:       %d\\n\", size);\n\tDRM_DEBUG(\"agp_offset: %lu\\n\", agp_offset);\n\tDRM_DEBUG(\"alignment:  %d\\n\", alignment);\n\tDRM_DEBUG(\"page_order: %d\\n\", page_order);\n\tDRM_DEBUG(\"total:      %d\\n\", total);\n\n\tif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\n\t\treturn -EINVAL;\n\n\tspin_lock(&dev->buf_lock);\n\tif (dev->buf_use) {\n\t\tspin_unlock(&dev->buf_lock);\n\t\treturn -EBUSY;\n\t}\n\tatomic_inc(&dev->buf_alloc);\n\tspin_unlock(&dev->buf_lock);\n\n\tmutex_lock(&dev->struct_mutex);\n\tentry = &dma->bufs[order];\n\tif (entry->buf_count) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\t \n\t}\n\n\tif (count < 0 || count > 4096) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -EINVAL;\n\t}\n\n\tentry->buflist = kcalloc(count, sizeof(*entry->buflist), GFP_KERNEL);\n\tif (!entry->buflist) {\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\n\tentry->buf_size = size;\n\tentry->page_order = page_order;\n\n\toffset = 0;\n\n\twhile (entry->buf_count < count) {\n\t\tbuf = &entry->buflist[entry->buf_count];\n\t\tbuf->idx = dma->buf_count + entry->buf_count;\n\t\tbuf->total = alignment;\n\t\tbuf->order = order;\n\t\tbuf->used = 0;\n\n\t\tbuf->offset = (dma->byte_count + offset);\n\t\tbuf->bus_address = agp_offset + offset;\n\t\tbuf->address = (void *)(agp_offset + offset\n\t\t\t\t\t+ (unsigned long)dev->sg->virtual);\n\t\tbuf->next = NULL;\n\t\tbuf->waiting = 0;\n\t\tbuf->pending = 0;\n\t\tbuf->file_priv = NULL;\n\n\t\tbuf->dev_priv_size = dev->driver->dev_priv_size;\n\t\tbuf->dev_private = kzalloc(buf->dev_priv_size, GFP_KERNEL);\n\t\tif (!buf->dev_private) {\n\t\t\t \n\t\t\tentry->buf_count = count;\n\t\t\tdrm_cleanup_buf_error(dev, entry);\n\t\t\tmutex_unlock(&dev->struct_mutex);\n\t\t\tatomic_dec(&dev->buf_alloc);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tDRM_DEBUG(\"buffer %d @ %p\\n\", entry->buf_count, buf->address);\n\n\t\toffset += alignment;\n\t\tentry->buf_count++;\n\t\tbyte_count += PAGE_SIZE << page_order;\n\t}\n\n\tDRM_DEBUG(\"byte_count: %d\\n\", byte_count);\n\n\ttemp_buflist = krealloc(dma->buflist,\n\t\t\t\t(dma->buf_count + entry->buf_count) *\n\t\t\t\tsizeof(*dma->buflist), GFP_KERNEL);\n\tif (!temp_buflist) {\n\t\t \n\t\tdrm_cleanup_buf_error(dev, entry);\n\t\tmutex_unlock(&dev->struct_mutex);\n\t\tatomic_dec(&dev->buf_alloc);\n\t\treturn -ENOMEM;\n\t}\n\tdma->buflist = temp_buflist;\n\n\tfor (i = 0; i < entry->buf_count; i++) {\n\t\tdma->buflist[i + dma->buf_count] = &entry->buflist[i];\n\t}\n\n\tdma->buf_count += entry->buf_count;\n\tdma->seg_count += entry->seg_count;\n\tdma->page_count += byte_count >> PAGE_SHIFT;\n\tdma->byte_count += byte_count;\n\n\tDRM_DEBUG(\"dma->buf_count : %d\\n\", dma->buf_count);\n\tDRM_DEBUG(\"entry->buf_count : %d\\n\", entry->buf_count);\n\n\tmutex_unlock(&dev->struct_mutex);\n\n\trequest->count = entry->buf_count;\n\trequest->size = size;\n\n\tdma->flags = _DRM_DMA_USE_SG;\n\n\tatomic_dec(&dev->buf_alloc);\n\treturn 0;\n}\n\n \nint drm_legacy_addbufs(struct drm_device *dev, void *data,\n\t\t       struct drm_file *file_priv)\n{\n\tstruct drm_buf_desc *request = data;\n\tint ret;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EOPNOTSUPP;\n\n#if IS_ENABLED(CONFIG_AGP)\n\tif (request->flags & _DRM_AGP_BUFFER)\n\t\tret = drm_legacy_addbufs_agp(dev, request);\n\telse\n#endif\n\tif (request->flags & _DRM_SG_BUFFER)\n\t\tret = drm_legacy_addbufs_sg(dev, request);\n\telse if (request->flags & _DRM_FB_BUFFER)\n\t\tret = -EINVAL;\n\telse\n\t\tret = drm_legacy_addbufs_pci(dev, request);\n\n\treturn ret;\n}\n\n \nint __drm_legacy_infobufs(struct drm_device *dev,\n\t\t\tvoid *data, int *p,\n\t\t\tint (*f)(void *, int, struct drm_buf_entry *))\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tint i;\n\tint count;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tspin_lock(&dev->buf_lock);\n\tif (atomic_read(&dev->buf_alloc)) {\n\t\tspin_unlock(&dev->buf_lock);\n\t\treturn -EBUSY;\n\t}\n\t++dev->buf_use;\t\t \n\tspin_unlock(&dev->buf_lock);\n\n\tfor (i = 0, count = 0; i < DRM_MAX_ORDER + 1; i++) {\n\t\tif (dma->bufs[i].buf_count)\n\t\t\t++count;\n\t}\n\n\tDRM_DEBUG(\"count = %d\\n\", count);\n\n\tif (*p >= count) {\n\t\tfor (i = 0, count = 0; i < DRM_MAX_ORDER + 1; i++) {\n\t\t\tstruct drm_buf_entry *from = &dma->bufs[i];\n\n\t\t\tif (from->buf_count) {\n\t\t\t\tif (f(data, count, from) < 0)\n\t\t\t\t\treturn -EFAULT;\n\t\t\t\tDRM_DEBUG(\"%d %d %d %d %d\\n\",\n\t\t\t\t\t  i,\n\t\t\t\t\t  dma->bufs[i].buf_count,\n\t\t\t\t\t  dma->bufs[i].buf_size,\n\t\t\t\t\t  dma->bufs[i].low_mark,\n\t\t\t\t\t  dma->bufs[i].high_mark);\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\t*p = count;\n\n\treturn 0;\n}\n\nstatic int copy_one_buf(void *data, int count, struct drm_buf_entry *from)\n{\n\tstruct drm_buf_info *request = data;\n\tstruct drm_buf_desc __user *to = &request->list[count];\n\tstruct drm_buf_desc v = {.count = from->buf_count,\n\t\t\t\t .size = from->buf_size,\n\t\t\t\t .low_mark = from->low_mark,\n\t\t\t\t .high_mark = from->high_mark};\n\n\tif (copy_to_user(to, &v, offsetof(struct drm_buf_desc, flags)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nint drm_legacy_infobufs(struct drm_device *dev, void *data,\n\t\t\tstruct drm_file *file_priv)\n{\n\tstruct drm_buf_info *request = data;\n\n\treturn __drm_legacy_infobufs(dev, data, &request->count, copy_one_buf);\n}\n\n \nint drm_legacy_markbufs(struct drm_device *dev, void *data,\n\t\t\tstruct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf_desc *request = data;\n\tint order;\n\tstruct drm_buf_entry *entry;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tDRM_DEBUG(\"%d, %d, %d\\n\",\n\t\t  request->size, request->low_mark, request->high_mark);\n\torder = order_base_2(request->size);\n\tif (order < DRM_MIN_ORDER || order > DRM_MAX_ORDER)\n\t\treturn -EINVAL;\n\tentry = &dma->bufs[order];\n\n\tif (request->low_mark < 0 || request->low_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\tif (request->high_mark < 0 || request->high_mark > entry->buf_count)\n\t\treturn -EINVAL;\n\n\tentry->low_mark = request->low_mark;\n\tentry->high_mark = request->high_mark;\n\n\treturn 0;\n}\n\n \nint drm_legacy_freebufs(struct drm_device *dev, void *data,\n\t\t\tstruct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf_free *request = data;\n\tint i;\n\tint idx;\n\tstruct drm_buf *buf;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tDRM_DEBUG(\"%d\\n\", request->count);\n\tfor (i = 0; i < request->count; i++) {\n\t\tif (copy_from_user(&idx, &request->list[i], sizeof(idx)))\n\t\t\treturn -EFAULT;\n\t\tif (idx < 0 || idx >= dma->buf_count) {\n\t\t\tDRM_ERROR(\"Index %d (of %d max)\\n\",\n\t\t\t\t  idx, dma->buf_count - 1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tidx = array_index_nospec(idx, dma->buf_count);\n\t\tbuf = dma->buflist[idx];\n\t\tif (buf->file_priv != file_priv) {\n\t\t\tDRM_ERROR(\"Process %d freeing buffer not owned\\n\",\n\t\t\t\t  task_pid_nr(current));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tdrm_legacy_free_buffer(dev, buf);\n\t}\n\n\treturn 0;\n}\n\n \nint __drm_legacy_mapbufs(struct drm_device *dev, void *data, int *p,\n\t\t\t void __user **v,\n\t\t\t int (*f)(void *, int, unsigned long,\n\t\t\t\t struct drm_buf *),\n\t\t\t\t struct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tint retcode = 0;\n\tunsigned long virtual;\n\tint i;\n\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!drm_core_check_feature(dev, DRIVER_HAVE_DMA))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!dma)\n\t\treturn -EINVAL;\n\n\tspin_lock(&dev->buf_lock);\n\tif (atomic_read(&dev->buf_alloc)) {\n\t\tspin_unlock(&dev->buf_lock);\n\t\treturn -EBUSY;\n\t}\n\tdev->buf_use++;\t\t \n\tspin_unlock(&dev->buf_lock);\n\n\tif (*p >= dma->buf_count) {\n\t\tif ((dev->agp && (dma->flags & _DRM_DMA_USE_AGP))\n\t\t    || (drm_core_check_feature(dev, DRIVER_SG)\n\t\t\t&& (dma->flags & _DRM_DMA_USE_SG))) {\n\t\t\tstruct drm_local_map *map = dev->agp_buffer_map;\n\t\t\tunsigned long token = dev->agp_buffer_token;\n\n\t\t\tif (!map) {\n\t\t\t\tretcode = -EINVAL;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tvirtual = vm_mmap(file_priv->filp, 0, map->size,\n\t\t\t\t\t  PROT_READ | PROT_WRITE,\n\t\t\t\t\t  MAP_SHARED,\n\t\t\t\t\t  token);\n\t\t} else {\n\t\t\tvirtual = vm_mmap(file_priv->filp, 0, dma->byte_count,\n\t\t\t\t\t  PROT_READ | PROT_WRITE,\n\t\t\t\t\t  MAP_SHARED, 0);\n\t\t}\n\t\tif (virtual > -1024UL) {\n\t\t\t \n\t\t\tretcode = (signed long)virtual;\n\t\t\tgoto done;\n\t\t}\n\t\t*v = (void __user *)virtual;\n\n\t\tfor (i = 0; i < dma->buf_count; i++) {\n\t\t\tif (f(data, i, virtual, dma->buflist[i]) < 0) {\n\t\t\t\tretcode = -EFAULT;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n      done:\n\t*p = dma->buf_count;\n\tDRM_DEBUG(\"%d buffers, retcode = %d\\n\", *p, retcode);\n\n\treturn retcode;\n}\n\nstatic int map_one_buf(void *data, int idx, unsigned long virtual,\n\t\t\tstruct drm_buf *buf)\n{\n\tstruct drm_buf_map *request = data;\n\tunsigned long address = virtual + buf->offset;\t \n\n\tif (copy_to_user(&request->list[idx].idx, &buf->idx,\n\t\t\t sizeof(request->list[0].idx)))\n\t\treturn -EFAULT;\n\tif (copy_to_user(&request->list[idx].total, &buf->total,\n\t\t\t sizeof(request->list[0].total)))\n\t\treturn -EFAULT;\n\tif (clear_user(&request->list[idx].used, sizeof(int)))\n\t\treturn -EFAULT;\n\tif (copy_to_user(&request->list[idx].address, &address,\n\t\t\t sizeof(address)))\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nint drm_legacy_mapbufs(struct drm_device *dev, void *data,\n\t\t       struct drm_file *file_priv)\n{\n\tstruct drm_buf_map *request = data;\n\n\treturn __drm_legacy_mapbufs(dev, data, &request->count,\n\t\t\t\t    &request->virtual, map_one_buf,\n\t\t\t\t    file_priv);\n}\n\nint drm_legacy_dma_ioctl(struct drm_device *dev, void *data,\n\t\t  struct drm_file *file_priv)\n{\n\tif (!drm_core_check_feature(dev, DRIVER_LEGACY))\n\t\treturn -EOPNOTSUPP;\n\n\tif (dev->driver->dma_ioctl)\n\t\treturn dev->driver->dma_ioctl(dev, data, file_priv);\n\telse\n\t\treturn -EINVAL;\n}\n\nstruct drm_local_map *drm_legacy_getsarea(struct drm_device *dev)\n{\n\tstruct drm_map_list *entry;\n\n\tlist_for_each_entry(entry, &dev->maplist, head) {\n\t\tif (entry->map && entry->map->type == _DRM_SHM &&\n\t\t    (entry->map->flags & _DRM_CONTAINS_LOCK)) {\n\t\t\treturn entry->map;\n\t\t}\n\t}\n\treturn NULL;\n}\nEXPORT_SYMBOL(drm_legacy_getsarea);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}