{
  "module_name": "virtgpu_ioctl.c",
  "hash_id": "5f780f3a0590dc933558eb8cc073cf05fbd031aca652359f854dffcbeb53ecac",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/virtio/virtgpu_ioctl.c",
  "human_readable_source": " \n\n#include <linux/file.h>\n#include <linux/sync_file.h>\n#include <linux/uaccess.h>\n\n#include <drm/drm_file.h>\n#include <drm/virtgpu_drm.h>\n\n#include \"virtgpu_drv.h\"\n\n#define VIRTGPU_BLOB_FLAG_USE_MASK (VIRTGPU_BLOB_FLAG_USE_MAPPABLE | \\\n\t\t\t\t    VIRTGPU_BLOB_FLAG_USE_SHAREABLE | \\\n\t\t\t\t    VIRTGPU_BLOB_FLAG_USE_CROSS_DEVICE)\n\n \nstatic void virtio_gpu_create_context_locked(struct virtio_gpu_device *vgdev,\n\t\t\t\t\t     struct virtio_gpu_fpriv *vfpriv)\n{\n\tchar dbgname[TASK_COMM_LEN];\n\n\tget_task_comm(dbgname, current);\n\tvirtio_gpu_cmd_context_create(vgdev, vfpriv->ctx_id,\n\t\t\t\t      vfpriv->context_init, strlen(dbgname),\n\t\t\t\t      dbgname);\n\n\tvfpriv->context_created = true;\n}\n\nvoid virtio_gpu_create_context(struct drm_device *dev, struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\n\n\tmutex_lock(&vfpriv->context_lock);\n\tif (vfpriv->context_created)\n\t\tgoto out_unlock;\n\n\tvirtio_gpu_create_context_locked(vgdev, vfpriv);\n\nout_unlock:\n\tmutex_unlock(&vfpriv->context_lock);\n}\n\nstatic int virtio_gpu_map_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct drm_virtgpu_map *virtio_gpu_map = data;\n\n\treturn virtio_gpu_mode_dumb_mmap(file, vgdev->ddev,\n\t\t\t\t\t virtio_gpu_map->handle,\n\t\t\t\t\t &virtio_gpu_map->offset);\n}\n\nstatic int virtio_gpu_getparam_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t     struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct drm_virtgpu_getparam *param = data;\n\tint value;\n\n\tswitch (param->param) {\n\tcase VIRTGPU_PARAM_3D_FEATURES:\n\t\tvalue = vgdev->has_virgl_3d ? 1 : 0;\n\t\tbreak;\n\tcase VIRTGPU_PARAM_CAPSET_QUERY_FIX:\n\t\tvalue = 1;\n\t\tbreak;\n\tcase VIRTGPU_PARAM_RESOURCE_BLOB:\n\t\tvalue = vgdev->has_resource_blob ? 1 : 0;\n\t\tbreak;\n\tcase VIRTGPU_PARAM_HOST_VISIBLE:\n\t\tvalue = vgdev->has_host_visible ? 1 : 0;\n\t\tbreak;\n\tcase VIRTGPU_PARAM_CROSS_DEVICE:\n\t\tvalue = vgdev->has_resource_assign_uuid ? 1 : 0;\n\t\tbreak;\n\tcase VIRTGPU_PARAM_CONTEXT_INIT:\n\t\tvalue = vgdev->has_context_init ? 1 : 0;\n\t\tbreak;\n\tcase VIRTGPU_PARAM_SUPPORTED_CAPSET_IDs:\n\t\tvalue = vgdev->capset_id_mask;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\tif (copy_to_user(u64_to_user_ptr(param->value), &value, sizeof(int)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int virtio_gpu_resource_create_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t\t    struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct drm_virtgpu_resource_create *rc = data;\n\tstruct virtio_gpu_fence *fence;\n\tint ret;\n\tstruct virtio_gpu_object *qobj;\n\tstruct drm_gem_object *obj;\n\tuint32_t handle = 0;\n\tstruct virtio_gpu_object_params params = { 0 };\n\n\tif (vgdev->has_virgl_3d) {\n\t\tvirtio_gpu_create_context(dev, file);\n\t\tparams.virgl = true;\n\t\tparams.target = rc->target;\n\t\tparams.bind = rc->bind;\n\t\tparams.depth = rc->depth;\n\t\tparams.array_size = rc->array_size;\n\t\tparams.last_level = rc->last_level;\n\t\tparams.nr_samples = rc->nr_samples;\n\t\tparams.flags = rc->flags;\n\t} else {\n\t\tif (rc->depth > 1)\n\t\t\treturn -EINVAL;\n\t\tif (rc->nr_samples > 1)\n\t\t\treturn -EINVAL;\n\t\tif (rc->last_level > 1)\n\t\t\treturn -EINVAL;\n\t\tif (rc->target != 2)\n\t\t\treturn -EINVAL;\n\t\tif (rc->array_size > 1)\n\t\t\treturn -EINVAL;\n\t}\n\n\tparams.format = rc->format;\n\tparams.width = rc->width;\n\tparams.height = rc->height;\n\tparams.size = rc->size;\n\t \n\tif (params.size == 0)\n\t\tparams.size = PAGE_SIZE;\n\n\tfence = virtio_gpu_fence_alloc(vgdev, vgdev->fence_drv.context, 0);\n\tif (!fence)\n\t\treturn -ENOMEM;\n\tret = virtio_gpu_object_create(vgdev, &params, &qobj, fence);\n\tdma_fence_put(&fence->f);\n\tif (ret < 0)\n\t\treturn ret;\n\tobj = &qobj->base.base;\n\n\tret = drm_gem_handle_create(file, obj, &handle);\n\tif (ret) {\n\t\tdrm_gem_object_release(obj);\n\t\treturn ret;\n\t}\n\n\trc->res_handle = qobj->hw_res_handle;  \n\trc->bo_handle = handle;\n\n\t \n\tdrm_gem_object_put(obj);\n\n\treturn 0;\n}\n\nstatic int virtio_gpu_resource_info_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t\t  struct drm_file *file)\n{\n\tstruct drm_virtgpu_resource_info *ri = data;\n\tstruct drm_gem_object *gobj = NULL;\n\tstruct virtio_gpu_object *qobj = NULL;\n\n\tgobj = drm_gem_object_lookup(file, ri->bo_handle);\n\tif (gobj == NULL)\n\t\treturn -ENOENT;\n\n\tqobj = gem_to_virtio_gpu_obj(gobj);\n\n\tri->size = qobj->base.base.size;\n\tri->res_handle = qobj->hw_res_handle;\n\tif (qobj->host3d_blob || qobj->guest_blob)\n\t\tri->blob_mem = qobj->blob_mem;\n\n\tdrm_gem_object_put(gobj);\n\treturn 0;\n}\n\nstatic int virtio_gpu_transfer_from_host_ioctl(struct drm_device *dev,\n\t\t\t\t\t       void *data,\n\t\t\t\t\t       struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\n\tstruct drm_virtgpu_3d_transfer_from_host *args = data;\n\tstruct virtio_gpu_object *bo;\n\tstruct virtio_gpu_object_array *objs;\n\tstruct virtio_gpu_fence *fence;\n\tint ret;\n\tu32 offset = args->offset;\n\n\tif (vgdev->has_virgl_3d == false)\n\t\treturn -ENOSYS;\n\n\tvirtio_gpu_create_context(dev, file);\n\tobjs = virtio_gpu_array_from_handles(file, &args->bo_handle, 1);\n\tif (objs == NULL)\n\t\treturn -ENOENT;\n\n\tbo = gem_to_virtio_gpu_obj(objs->objs[0]);\n\tif (bo->guest_blob && !bo->host3d_blob) {\n\t\tret = -EINVAL;\n\t\tgoto err_put_free;\n\t}\n\n\tif (!bo->host3d_blob && (args->stride || args->layer_stride)) {\n\t\tret = -EINVAL;\n\t\tgoto err_put_free;\n\t}\n\n\tret = virtio_gpu_array_lock_resv(objs);\n\tif (ret != 0)\n\t\tgoto err_put_free;\n\n\tfence = virtio_gpu_fence_alloc(vgdev, vgdev->fence_drv.context, 0);\n\tif (!fence) {\n\t\tret = -ENOMEM;\n\t\tgoto err_unlock;\n\t}\n\n\tvirtio_gpu_cmd_transfer_from_host_3d\n\t\t(vgdev, vfpriv->ctx_id, offset, args->level, args->stride,\n\t\t args->layer_stride, &args->box, objs, fence);\n\tdma_fence_put(&fence->f);\n\tvirtio_gpu_notify(vgdev);\n\treturn 0;\n\nerr_unlock:\n\tvirtio_gpu_array_unlock_resv(objs);\nerr_put_free:\n\tvirtio_gpu_array_put_free(objs);\n\treturn ret;\n}\n\nstatic int virtio_gpu_transfer_to_host_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t\t     struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\n\tstruct drm_virtgpu_3d_transfer_to_host *args = data;\n\tstruct virtio_gpu_object *bo;\n\tstruct virtio_gpu_object_array *objs;\n\tstruct virtio_gpu_fence *fence;\n\tint ret;\n\tu32 offset = args->offset;\n\n\tobjs = virtio_gpu_array_from_handles(file, &args->bo_handle, 1);\n\tif (objs == NULL)\n\t\treturn -ENOENT;\n\n\tbo = gem_to_virtio_gpu_obj(objs->objs[0]);\n\tif (bo->guest_blob && !bo->host3d_blob) {\n\t\tret = -EINVAL;\n\t\tgoto err_put_free;\n\t}\n\n\tif (!vgdev->has_virgl_3d) {\n\t\tvirtio_gpu_cmd_transfer_to_host_2d\n\t\t\t(vgdev, offset,\n\t\t\t args->box.w, args->box.h, args->box.x, args->box.y,\n\t\t\t objs, NULL);\n\t} else {\n\t\tvirtio_gpu_create_context(dev, file);\n\n\t\tif (!bo->host3d_blob && (args->stride || args->layer_stride)) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_put_free;\n\t\t}\n\n\t\tret = virtio_gpu_array_lock_resv(objs);\n\t\tif (ret != 0)\n\t\t\tgoto err_put_free;\n\n\t\tret = -ENOMEM;\n\t\tfence = virtio_gpu_fence_alloc(vgdev, vgdev->fence_drv.context,\n\t\t\t\t\t       0);\n\t\tif (!fence)\n\t\t\tgoto err_unlock;\n\n\t\tvirtio_gpu_cmd_transfer_to_host_3d\n\t\t\t(vgdev,\n\t\t\t vfpriv ? vfpriv->ctx_id : 0, offset, args->level,\n\t\t\t args->stride, args->layer_stride, &args->box, objs,\n\t\t\t fence);\n\t\tdma_fence_put(&fence->f);\n\t}\n\tvirtio_gpu_notify(vgdev);\n\treturn 0;\n\nerr_unlock:\n\tvirtio_gpu_array_unlock_resv(objs);\nerr_put_free:\n\tvirtio_gpu_array_put_free(objs);\n\treturn ret;\n}\n\nstatic int virtio_gpu_wait_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t struct drm_file *file)\n{\n\tstruct drm_virtgpu_3d_wait *args = data;\n\tstruct drm_gem_object *obj;\n\tlong timeout = 15 * HZ;\n\tint ret;\n\n\tobj = drm_gem_object_lookup(file, args->handle);\n\tif (obj == NULL)\n\t\treturn -ENOENT;\n\n\tif (args->flags & VIRTGPU_WAIT_NOWAIT) {\n\t\tret = dma_resv_test_signaled(obj->resv, DMA_RESV_USAGE_READ);\n\t} else {\n\t\tret = dma_resv_wait_timeout(obj->resv, DMA_RESV_USAGE_READ,\n\t\t\t\t\t    true, timeout);\n\t}\n\tif (ret == 0)\n\t\tret = -EBUSY;\n\telse if (ret > 0)\n\t\tret = 0;\n\n\tdrm_gem_object_put(obj);\n\treturn ret;\n}\n\nstatic int virtio_gpu_get_caps_ioctl(struct drm_device *dev,\n\t\t\t\tvoid *data, struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct drm_virtgpu_get_caps *args = data;\n\tunsigned size, host_caps_size;\n\tint i;\n\tint found_valid = -1;\n\tint ret;\n\tstruct virtio_gpu_drv_cap_cache *cache_ent;\n\tvoid *ptr;\n\n\tif (vgdev->num_capsets == 0)\n\t\treturn -ENOSYS;\n\n\t \n\tif (args->size == 0)\n\t\treturn -EINVAL;\n\n\tspin_lock(&vgdev->display_info_lock);\n\tfor (i = 0; i < vgdev->num_capsets; i++) {\n\t\tif (vgdev->capsets[i].id == args->cap_set_id) {\n\t\t\tif (vgdev->capsets[i].max_version >= args->cap_set_ver) {\n\t\t\t\tfound_valid = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (found_valid == -1) {\n\t\tspin_unlock(&vgdev->display_info_lock);\n\t\treturn -EINVAL;\n\t}\n\n\thost_caps_size = vgdev->capsets[found_valid].max_size;\n\t \n\tsize = min(args->size, host_caps_size);\n\n\tlist_for_each_entry(cache_ent, &vgdev->cap_cache, head) {\n\t\tif (cache_ent->id == args->cap_set_id &&\n\t\t    cache_ent->version == args->cap_set_ver) {\n\t\t\tspin_unlock(&vgdev->display_info_lock);\n\t\t\tgoto copy_exit;\n\t\t}\n\t}\n\tspin_unlock(&vgdev->display_info_lock);\n\n\t \n\tret = virtio_gpu_cmd_get_capset(vgdev, found_valid, args->cap_set_ver,\n\t\t\t\t\t&cache_ent);\n\tif (ret)\n\t\treturn ret;\n\tvirtio_gpu_notify(vgdev);\n\ncopy_exit:\n\tret = wait_event_timeout(vgdev->resp_wq,\n\t\t\t\t atomic_read(&cache_ent->is_valid), 5 * HZ);\n\tif (!ret)\n\t\treturn -EBUSY;\n\n\t \n\tsmp_rmb();\n\n\tptr = cache_ent->caps_cache;\n\n\tif (copy_to_user(u64_to_user_ptr(args->addr), ptr, size))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n\nstatic int verify_blob(struct virtio_gpu_device *vgdev,\n\t\t       struct virtio_gpu_fpriv *vfpriv,\n\t\t       struct virtio_gpu_object_params *params,\n\t\t       struct drm_virtgpu_resource_create_blob *rc_blob,\n\t\t       bool *guest_blob, bool *host3d_blob)\n{\n\tif (!vgdev->has_resource_blob)\n\t\treturn -EINVAL;\n\n\tif (rc_blob->blob_flags & ~VIRTGPU_BLOB_FLAG_USE_MASK)\n\t\treturn -EINVAL;\n\n\tif (rc_blob->blob_flags & VIRTGPU_BLOB_FLAG_USE_CROSS_DEVICE) {\n\t\tif (!vgdev->has_resource_assign_uuid)\n\t\t\treturn -EINVAL;\n\t}\n\n\tswitch (rc_blob->blob_mem) {\n\tcase VIRTGPU_BLOB_MEM_GUEST:\n\t\t*guest_blob = true;\n\t\tbreak;\n\tcase VIRTGPU_BLOB_MEM_HOST3D_GUEST:\n\t\t*guest_blob = true;\n\t\tfallthrough;\n\tcase VIRTGPU_BLOB_MEM_HOST3D:\n\t\t*host3d_blob = true;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (*host3d_blob) {\n\t\tif (!vgdev->has_virgl_3d)\n\t\t\treturn -EINVAL;\n\n\t\t \n\t\tif (rc_blob->cmd_size % 4 != 0)\n\t\t\treturn -EINVAL;\n\n\t\tparams->ctx_id = vfpriv->ctx_id;\n\t\tparams->blob_id = rc_blob->blob_id;\n\t} else {\n\t\tif (rc_blob->blob_id != 0)\n\t\t\treturn -EINVAL;\n\n\t\tif (rc_blob->cmd_size != 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\tparams->blob_mem = rc_blob->blob_mem;\n\tparams->size = rc_blob->size;\n\tparams->blob = true;\n\tparams->blob_flags = rc_blob->blob_flags;\n\treturn 0;\n}\n\nstatic int virtio_gpu_resource_create_blob_ioctl(struct drm_device *dev,\n\t\t\t\t\t\t void *data,\n\t\t\t\t\t\t struct drm_file *file)\n{\n\tint ret = 0;\n\tuint32_t handle = 0;\n\tbool guest_blob = false;\n\tbool host3d_blob = false;\n\tstruct drm_gem_object *obj;\n\tstruct virtio_gpu_object *bo;\n\tstruct virtio_gpu_object_params params = { 0 };\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\n\tstruct drm_virtgpu_resource_create_blob *rc_blob = data;\n\n\tif (verify_blob(vgdev, vfpriv, &params, rc_blob,\n\t\t\t&guest_blob, &host3d_blob))\n\t\treturn -EINVAL;\n\n\tif (vgdev->has_virgl_3d)\n\t\tvirtio_gpu_create_context(dev, file);\n\n\tif (rc_blob->cmd_size) {\n\t\tvoid *buf;\n\n\t\tbuf = memdup_user(u64_to_user_ptr(rc_blob->cmd),\n\t\t\t\t  rc_blob->cmd_size);\n\n\t\tif (IS_ERR(buf))\n\t\t\treturn PTR_ERR(buf);\n\n\t\tvirtio_gpu_cmd_submit(vgdev, buf, rc_blob->cmd_size,\n\t\t\t\t      vfpriv->ctx_id, NULL, NULL);\n\t}\n\n\tif (guest_blob)\n\t\tret = virtio_gpu_object_create(vgdev, &params, &bo, NULL);\n\telse if (!guest_blob && host3d_blob)\n\t\tret = virtio_gpu_vram_create(vgdev, &params, &bo);\n\telse\n\t\treturn -EINVAL;\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbo->guest_blob = guest_blob;\n\tbo->host3d_blob = host3d_blob;\n\tbo->blob_mem = rc_blob->blob_mem;\n\tbo->blob_flags = rc_blob->blob_flags;\n\n\tobj = &bo->base.base;\n\tif (params.blob_flags & VIRTGPU_BLOB_FLAG_USE_CROSS_DEVICE) {\n\t\tret = virtio_gpu_resource_assign_uuid(vgdev, bo);\n\t\tif (ret) {\n\t\t\tdrm_gem_object_release(obj);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = drm_gem_handle_create(file, obj, &handle);\n\tif (ret) {\n\t\tdrm_gem_object_release(obj);\n\t\treturn ret;\n\t}\n\n\trc_blob->res_handle = bo->hw_res_handle;\n\trc_blob->bo_handle = handle;\n\n\t \n\tdrm_gem_object_put(obj);\n\n\treturn 0;\n}\n\nstatic int virtio_gpu_context_init_ioctl(struct drm_device *dev,\n\t\t\t\t\t void *data, struct drm_file *file)\n{\n\tint ret = 0;\n\tuint32_t num_params, i, param, value;\n\tuint64_t valid_ring_mask;\n\tsize_t len;\n\tstruct drm_virtgpu_context_set_param *ctx_set_params = NULL;\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\n\tstruct drm_virtgpu_context_init *args = data;\n\n\tnum_params = args->num_params;\n\tlen = num_params * sizeof(struct drm_virtgpu_context_set_param);\n\n\tif (!vgdev->has_context_init || !vgdev->has_virgl_3d)\n\t\treturn -EINVAL;\n\n\t \n\tif (num_params > 3)\n\t\treturn -EINVAL;\n\n\tctx_set_params = memdup_user(u64_to_user_ptr(args->ctx_set_params),\n\t\t\t\t     len);\n\n\tif (IS_ERR(ctx_set_params))\n\t\treturn PTR_ERR(ctx_set_params);\n\n\tmutex_lock(&vfpriv->context_lock);\n\tif (vfpriv->context_created) {\n\t\tret = -EEXIST;\n\t\tgoto out_unlock;\n\t}\n\n\tfor (i = 0; i < num_params; i++) {\n\t\tparam = ctx_set_params[i].param;\n\t\tvalue = ctx_set_params[i].value;\n\n\t\tswitch (param) {\n\t\tcase VIRTGPU_CONTEXT_PARAM_CAPSET_ID:\n\t\t\tif (value > MAX_CAPSET_ID) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\n\t\t\tif ((vgdev->capset_id_mask & (1ULL << value)) == 0) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\n\t\t\t \n\t\t\tif (vfpriv->context_init &\n\t\t\t    VIRTIO_GPU_CONTEXT_INIT_CAPSET_ID_MASK) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\n\t\t\tvfpriv->context_init |= value;\n\t\t\tbreak;\n\t\tcase VIRTGPU_CONTEXT_PARAM_NUM_RINGS:\n\t\t\tif (vfpriv->base_fence_ctx) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\n\t\t\tif (value > MAX_RINGS) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\n\t\t\tvfpriv->base_fence_ctx = dma_fence_context_alloc(value);\n\t\t\tvfpriv->num_rings = value;\n\t\t\tbreak;\n\t\tcase VIRTGPU_CONTEXT_PARAM_POLL_RINGS_MASK:\n\t\t\tif (vfpriv->ring_idx_mask) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\n\t\t\tvfpriv->ring_idx_mask = value;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (vfpriv->ring_idx_mask) {\n\t\tvalid_ring_mask = 0;\n\t\tfor (i = 0; i < vfpriv->num_rings; i++)\n\t\t\tvalid_ring_mask |= 1ULL << i;\n\n\t\tif (~valid_ring_mask & vfpriv->ring_idx_mask) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tvirtio_gpu_create_context_locked(vgdev, vfpriv);\n\tvirtio_gpu_notify(vgdev);\n\nout_unlock:\n\tmutex_unlock(&vfpriv->context_lock);\n\tkfree(ctx_set_params);\n\treturn ret;\n}\n\nstruct drm_ioctl_desc virtio_gpu_ioctls[DRM_VIRTIO_NUM_IOCTLS] = {\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_MAP, virtio_gpu_map_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_EXECBUFFER, virtio_gpu_execbuffer_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_GETPARAM, virtio_gpu_getparam_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_RESOURCE_CREATE,\n\t\t\t  virtio_gpu_resource_create_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_RESOURCE_INFO, virtio_gpu_resource_info_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\t \n\tDRM_IOCTL_DEF_DRV(VIRTGPU_TRANSFER_FROM_HOST,\n\t\t\t  virtio_gpu_transfer_from_host_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_TRANSFER_TO_HOST,\n\t\t\t  virtio_gpu_transfer_to_host_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_WAIT, virtio_gpu_wait_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_GET_CAPS, virtio_gpu_get_caps_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_RESOURCE_CREATE_BLOB,\n\t\t\t  virtio_gpu_resource_create_blob_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\tDRM_IOCTL_DEF_DRV(VIRTGPU_CONTEXT_INIT, virtio_gpu_context_init_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}