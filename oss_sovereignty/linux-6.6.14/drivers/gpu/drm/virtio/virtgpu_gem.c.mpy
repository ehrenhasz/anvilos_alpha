{
  "module_name": "virtgpu_gem.c",
  "hash_id": "e27c2fa752bd44dcbac5900545a91077c440962bd3eff0c3221caefadcb105f7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/virtio/virtgpu_gem.c",
  "human_readable_source": " \n\n#include <drm/drm_file.h>\n#include <drm/drm_fourcc.h>\n\n#include \"virtgpu_drv.h\"\n\nstatic int virtio_gpu_gem_create(struct drm_file *file,\n\t\t\t\t struct drm_device *dev,\n\t\t\t\t struct virtio_gpu_object_params *params,\n\t\t\t\t struct drm_gem_object **obj_p,\n\t\t\t\t uint32_t *handle_p)\n{\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tstruct virtio_gpu_object *obj;\n\tint ret;\n\tu32 handle;\n\n\tret = virtio_gpu_object_create(vgdev, params, &obj, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = drm_gem_handle_create(file, &obj->base.base, &handle);\n\tif (ret) {\n\t\tdrm_gem_object_release(&obj->base.base);\n\t\treturn ret;\n\t}\n\n\t*obj_p = &obj->base.base;\n\n\t \n\tdrm_gem_object_put(&obj->base.base);\n\n\t*handle_p = handle;\n\treturn 0;\n}\n\nint virtio_gpu_mode_dumb_create(struct drm_file *file_priv,\n\t\t\t\tstruct drm_device *dev,\n\t\t\t\tstruct drm_mode_create_dumb *args)\n{\n\tstruct drm_gem_object *gobj;\n\tstruct virtio_gpu_object_params params = { 0 };\n\tstruct virtio_gpu_device *vgdev = dev->dev_private;\n\tint ret;\n\tuint32_t pitch;\n\n\tif (args->bpp != 32)\n\t\treturn -EINVAL;\n\n\tpitch = args->width * 4;\n\targs->size = pitch * args->height;\n\targs->size = ALIGN(args->size, PAGE_SIZE);\n\n\tparams.format = virtio_gpu_translate_format(DRM_FORMAT_HOST_XRGB8888);\n\tparams.width = args->width;\n\tparams.height = args->height;\n\tparams.size = args->size;\n\tparams.dumb = true;\n\n\tif (vgdev->has_resource_blob && !vgdev->has_virgl_3d) {\n\t\tparams.blob_mem = VIRTGPU_BLOB_MEM_GUEST;\n\t\tparams.blob_flags = VIRTGPU_BLOB_FLAG_USE_SHAREABLE;\n\t\tparams.blob = true;\n\t}\n\n\tret = virtio_gpu_gem_create(file_priv, dev, &params, &gobj,\n\t\t\t\t    &args->handle);\n\tif (ret)\n\t\tgoto fail;\n\n\targs->pitch = pitch;\n\treturn ret;\n\nfail:\n\treturn ret;\n}\n\nint virtio_gpu_mode_dumb_mmap(struct drm_file *file_priv,\n\t\t\t      struct drm_device *dev,\n\t\t\t      uint32_t handle, uint64_t *offset_p)\n{\n\tstruct drm_gem_object *gobj;\n\n\tBUG_ON(!offset_p);\n\tgobj = drm_gem_object_lookup(file_priv, handle);\n\tif (gobj == NULL)\n\t\treturn -ENOENT;\n\t*offset_p = drm_vma_node_offset_addr(&gobj->vma_node);\n\tdrm_gem_object_put(gobj);\n\treturn 0;\n}\n\nint virtio_gpu_gem_object_open(struct drm_gem_object *obj,\n\t\t\t       struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = obj->dev->dev_private;\n\tstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\n\tstruct virtio_gpu_object_array *objs;\n\n\tif (!vgdev->has_virgl_3d)\n\t\tgoto out_notify;\n\n\t \n\tvirtio_gpu_create_context(obj->dev, file);\n\n\tobjs = virtio_gpu_array_alloc(1);\n\tif (!objs)\n\t\treturn -ENOMEM;\n\tvirtio_gpu_array_add_obj(objs, obj);\n\n\tvirtio_gpu_cmd_context_attach_resource(vgdev, vfpriv->ctx_id,\n\t\t\t\t\t       objs);\nout_notify:\n\tvirtio_gpu_notify(vgdev);\n\treturn 0;\n}\n\nvoid virtio_gpu_gem_object_close(struct drm_gem_object *obj,\n\t\t\t\t struct drm_file *file)\n{\n\tstruct virtio_gpu_device *vgdev = obj->dev->dev_private;\n\tstruct virtio_gpu_fpriv *vfpriv = file->driver_priv;\n\tstruct virtio_gpu_object_array *objs;\n\n\tif (!vgdev->has_virgl_3d)\n\t\treturn;\n\n\tobjs = virtio_gpu_array_alloc(1);\n\tif (!objs)\n\t\treturn;\n\tvirtio_gpu_array_add_obj(objs, obj);\n\n\tvirtio_gpu_cmd_context_detach_resource(vgdev, vfpriv->ctx_id,\n\t\t\t\t\t       objs);\n\tvirtio_gpu_notify(vgdev);\n}\n\nstruct virtio_gpu_object_array *virtio_gpu_array_alloc(u32 nents)\n{\n\tstruct virtio_gpu_object_array *objs;\n\n\tobjs = kmalloc(struct_size(objs, objs, nents), GFP_KERNEL);\n\tif (!objs)\n\t\treturn NULL;\n\n\tobjs->nents = 0;\n\tobjs->total = nents;\n\treturn objs;\n}\n\nstatic void virtio_gpu_array_free(struct virtio_gpu_object_array *objs)\n{\n\tkfree(objs);\n}\n\nstruct virtio_gpu_object_array*\nvirtio_gpu_array_from_handles(struct drm_file *drm_file, u32 *handles, u32 nents)\n{\n\tstruct virtio_gpu_object_array *objs;\n\tu32 i;\n\n\tobjs = virtio_gpu_array_alloc(nents);\n\tif (!objs)\n\t\treturn NULL;\n\n\tfor (i = 0; i < nents; i++) {\n\t\tobjs->objs[i] = drm_gem_object_lookup(drm_file, handles[i]);\n\t\tif (!objs->objs[i]) {\n\t\t\tobjs->nents = i;\n\t\t\tvirtio_gpu_array_put_free(objs);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\tobjs->nents = i;\n\treturn objs;\n}\n\nvoid virtio_gpu_array_add_obj(struct virtio_gpu_object_array *objs,\n\t\t\t      struct drm_gem_object *obj)\n{\n\tif (WARN_ON_ONCE(objs->nents == objs->total))\n\t\treturn;\n\n\tdrm_gem_object_get(obj);\n\tobjs->objs[objs->nents] = obj;\n\tobjs->nents++;\n}\n\nint virtio_gpu_array_lock_resv(struct virtio_gpu_object_array *objs)\n{\n\tunsigned int i;\n\tint ret;\n\n\tif (objs->nents == 1) {\n\t\tret = dma_resv_lock_interruptible(objs->objs[0]->resv, NULL);\n\t} else {\n\t\tret = drm_gem_lock_reservations(objs->objs, objs->nents,\n\t\t\t\t\t\t&objs->ticket);\n\t}\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < objs->nents; ++i) {\n\t\tret = dma_resv_reserve_fences(objs->objs[i]->resv, 1);\n\t\tif (ret) {\n\t\t\tvirtio_gpu_array_unlock_resv(objs);\n\t\t\treturn ret;\n\t\t}\n\t}\n\treturn ret;\n}\n\nvoid virtio_gpu_array_unlock_resv(struct virtio_gpu_object_array *objs)\n{\n\tif (objs->nents == 1) {\n\t\tdma_resv_unlock(objs->objs[0]->resv);\n\t} else {\n\t\tdrm_gem_unlock_reservations(objs->objs, objs->nents,\n\t\t\t\t\t    &objs->ticket);\n\t}\n}\n\nvoid virtio_gpu_array_add_fence(struct virtio_gpu_object_array *objs,\n\t\t\t\tstruct dma_fence *fence)\n{\n\tint i;\n\n\tfor (i = 0; i < objs->nents; i++)\n\t\tdma_resv_add_fence(objs->objs[i]->resv, fence,\n\t\t\t\t   DMA_RESV_USAGE_WRITE);\n}\n\nvoid virtio_gpu_array_put_free(struct virtio_gpu_object_array *objs)\n{\n\tu32 i;\n\n\tif (!objs)\n\t\treturn;\n\n\tfor (i = 0; i < objs->nents; i++)\n\t\tdrm_gem_object_put(objs->objs[i]);\n\tvirtio_gpu_array_free(objs);\n}\n\nvoid virtio_gpu_array_put_free_delayed(struct virtio_gpu_device *vgdev,\n\t\t\t\t       struct virtio_gpu_object_array *objs)\n{\n\tspin_lock(&vgdev->obj_free_lock);\n\tlist_add_tail(&objs->next, &vgdev->obj_free_list);\n\tspin_unlock(&vgdev->obj_free_lock);\n\tschedule_work(&vgdev->obj_free_work);\n}\n\nvoid virtio_gpu_array_put_free_work(struct work_struct *work)\n{\n\tstruct virtio_gpu_device *vgdev =\n\t\tcontainer_of(work, struct virtio_gpu_device, obj_free_work);\n\tstruct virtio_gpu_object_array *objs;\n\n\tspin_lock(&vgdev->obj_free_lock);\n\twhile (!list_empty(&vgdev->obj_free_list)) {\n\t\tobjs = list_first_entry(&vgdev->obj_free_list,\n\t\t\t\t\tstruct virtio_gpu_object_array, next);\n\t\tlist_del(&objs->next);\n\t\tspin_unlock(&vgdev->obj_free_lock);\n\t\tvirtio_gpu_array_put_free(objs);\n\t\tspin_lock(&vgdev->obj_free_lock);\n\t}\n\tspin_unlock(&vgdev->obj_free_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}