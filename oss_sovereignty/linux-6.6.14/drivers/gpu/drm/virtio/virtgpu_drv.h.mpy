{
  "module_name": "virtgpu_drv.h",
  "hash_id": "ef55c2845892b64df52b1e0da0754a62f6faf36718e80c9c901a0a282cccbf03",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/virtio/virtgpu_drv.h",
  "human_readable_source": " \n\n#ifndef VIRTIO_DRV_H\n#define VIRTIO_DRV_H\n\n#include <linux/dma-direction.h>\n#include <linux/virtio.h>\n#include <linux/virtio_ids.h>\n#include <linux/virtio_config.h>\n#include <linux/virtio_gpu.h>\n\n#include <drm/drm_atomic.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_encoder.h>\n#include <drm/drm_fourcc.h>\n#include <drm/drm_framebuffer.h>\n#include <drm/drm_gem.h>\n#include <drm/drm_gem_shmem_helper.h>\n#include <drm/drm_ioctl.h>\n#include <drm/drm_probe_helper.h>\n#include <drm/virtgpu_drm.h>\n\n#define DRIVER_NAME \"virtio_gpu\"\n#define DRIVER_DESC \"virtio GPU\"\n#define DRIVER_DATE \"0\"\n\n#define DRIVER_MAJOR 0\n#define DRIVER_MINOR 1\n#define DRIVER_PATCHLEVEL 0\n\n#define STATE_INITIALIZING 0\n#define STATE_OK 1\n#define STATE_ERR 2\n\n#define MAX_CAPSET_ID 63\n#define MAX_RINGS 64\n\nstruct virtio_gpu_object_params {\n\tunsigned long size;\n\tbool dumb;\n\t \n\tbool virgl;\n\tbool blob;\n\n\t \n\tuint32_t format;\n\tuint32_t width;\n\tuint32_t height;\n\tuint32_t target;\n\tuint32_t bind;\n\tuint32_t depth;\n\tuint32_t array_size;\n\tuint32_t last_level;\n\tuint32_t nr_samples;\n\tuint32_t flags;\n\n\t \n\tuint32_t ctx_id;\n\tuint32_t blob_mem;\n\tuint32_t blob_flags;\n\tuint64_t blob_id;\n};\n\nstruct virtio_gpu_object {\n\tstruct drm_gem_shmem_object base;\n\tuint32_t hw_res_handle;\n\tbool dumb;\n\tbool created;\n\tbool host3d_blob, guest_blob;\n\tuint32_t blob_mem, blob_flags;\n\n\tint uuid_state;\n\tuuid_t uuid;\n};\n#define gem_to_virtio_gpu_obj(gobj) \\\n\tcontainer_of((gobj), struct virtio_gpu_object, base.base)\n\nstruct virtio_gpu_object_shmem {\n\tstruct virtio_gpu_object base;\n};\n\nstruct virtio_gpu_object_vram {\n\tstruct virtio_gpu_object base;\n\tuint32_t map_state;\n\tuint32_t map_info;\n\tstruct drm_mm_node vram_node;\n};\n\n#define to_virtio_gpu_shmem(virtio_gpu_object) \\\n\tcontainer_of((virtio_gpu_object), struct virtio_gpu_object_shmem, base)\n\n#define to_virtio_gpu_vram(virtio_gpu_object) \\\n\tcontainer_of((virtio_gpu_object), struct virtio_gpu_object_vram, base)\n\nstruct virtio_gpu_object_array {\n\tstruct ww_acquire_ctx ticket;\n\tstruct list_head next;\n\tu32 nents, total;\n\tstruct drm_gem_object *objs[];\n};\n\nstruct virtio_gpu_vbuffer;\nstruct virtio_gpu_device;\n\ntypedef void (*virtio_gpu_resp_cb)(struct virtio_gpu_device *vgdev,\n\t\t\t\t   struct virtio_gpu_vbuffer *vbuf);\n\nstruct virtio_gpu_fence_driver {\n\tatomic64_t       last_fence_id;\n\tuint64_t         current_fence_id;\n\tuint64_t         context;\n\tstruct list_head fences;\n\tspinlock_t       lock;\n};\n\nstruct virtio_gpu_fence_event {\n\tstruct drm_pending_event base;\n\tstruct drm_event event;\n};\n\nstruct virtio_gpu_fence {\n\tstruct dma_fence f;\n\tuint32_t ring_idx;\n\tuint64_t fence_id;\n\tbool emit_fence_info;\n\tstruct virtio_gpu_fence_event *e;\n\tstruct virtio_gpu_fence_driver *drv;\n\tstruct list_head node;\n};\n\nstruct virtio_gpu_vbuffer {\n\tchar *buf;\n\tint size;\n\n\tvoid *data_buf;\n\tuint32_t data_size;\n\n\tchar *resp_buf;\n\tint resp_size;\n\tvirtio_gpu_resp_cb resp_cb;\n\tvoid *resp_cb_data;\n\n\tstruct virtio_gpu_object_array *objs;\n\tstruct list_head list;\n\n\tuint32_t seqno;\n};\n\nstruct virtio_gpu_output {\n\tint index;\n\tstruct drm_crtc crtc;\n\tstruct drm_connector conn;\n\tstruct drm_encoder enc;\n\tstruct virtio_gpu_display_one info;\n\tstruct virtio_gpu_update_cursor cursor;\n\tstruct edid *edid;\n\tint cur_x;\n\tint cur_y;\n\tbool needs_modeset;\n};\n#define drm_crtc_to_virtio_gpu_output(x) \\\n\tcontainer_of(x, struct virtio_gpu_output, crtc)\n\nstruct virtio_gpu_framebuffer {\n\tstruct drm_framebuffer base;\n\tstruct virtio_gpu_fence *fence;\n};\n#define to_virtio_gpu_framebuffer(x) \\\n\tcontainer_of(x, struct virtio_gpu_framebuffer, base)\n\nstruct virtio_gpu_queue {\n\tstruct virtqueue *vq;\n\tspinlock_t qlock;\n\twait_queue_head_t ack_queue;\n\tstruct work_struct dequeue_work;\n\tuint32_t seqno;\n};\n\nstruct virtio_gpu_drv_capset {\n\tuint32_t id;\n\tuint32_t max_version;\n\tuint32_t max_size;\n};\n\nstruct virtio_gpu_drv_cap_cache {\n\tstruct list_head head;\n\tvoid *caps_cache;\n\tuint32_t id;\n\tuint32_t version;\n\tuint32_t size;\n\tatomic_t is_valid;\n};\n\nstruct virtio_gpu_device {\n\tstruct drm_device *ddev;\n\n\tstruct virtio_device *vdev;\n\n\tstruct virtio_gpu_output outputs[VIRTIO_GPU_MAX_SCANOUTS];\n\tuint32_t num_scanouts;\n\n\tstruct virtio_gpu_queue ctrlq;\n\tstruct virtio_gpu_queue cursorq;\n\tstruct kmem_cache *vbufs;\n\n\tatomic_t pending_commands;\n\n\tstruct ida\tresource_ida;\n\n\twait_queue_head_t resp_wq;\n\t \n\tspinlock_t display_info_lock;\n\tbool display_info_pending;\n\n\tstruct virtio_gpu_fence_driver fence_drv;\n\n\tstruct ida\tctx_id_ida;\n\n\tbool has_virgl_3d;\n\tbool has_edid;\n\tbool has_indirect;\n\tbool has_resource_assign_uuid;\n\tbool has_resource_blob;\n\tbool has_host_visible;\n\tbool has_context_init;\n\tstruct virtio_shm_region host_visible_region;\n\tstruct drm_mm host_visible_mm;\n\n\tstruct work_struct config_changed_work;\n\n\tstruct work_struct obj_free_work;\n\tspinlock_t obj_free_lock;\n\tstruct list_head obj_free_list;\n\n\tstruct virtio_gpu_drv_capset *capsets;\n\tuint32_t num_capsets;\n\tuint64_t capset_id_mask;\n\tstruct list_head cap_cache;\n\n\t \n\tspinlock_t resource_export_lock;\n\t \n\tspinlock_t host_visible_lock;\n};\n\nstruct virtio_gpu_fpriv {\n\tuint32_t ctx_id;\n\tuint32_t context_init;\n\tbool context_created;\n\tuint32_t num_rings;\n\tuint64_t base_fence_ctx;\n\tuint64_t ring_idx_mask;\n\tstruct mutex context_lock;\n};\n\n \n#define DRM_VIRTIO_NUM_IOCTLS 12\nextern struct drm_ioctl_desc virtio_gpu_ioctls[DRM_VIRTIO_NUM_IOCTLS];\nvoid virtio_gpu_create_context(struct drm_device *dev, struct drm_file *file);\n\n \nint virtio_gpu_init(struct virtio_device *vdev, struct drm_device *dev);\nvoid virtio_gpu_deinit(struct drm_device *dev);\nvoid virtio_gpu_release(struct drm_device *dev);\nint virtio_gpu_driver_open(struct drm_device *dev, struct drm_file *file);\nvoid virtio_gpu_driver_postclose(struct drm_device *dev, struct drm_file *file);\n\n \nint virtio_gpu_gem_object_open(struct drm_gem_object *obj,\n\t\t\t       struct drm_file *file);\nvoid virtio_gpu_gem_object_close(struct drm_gem_object *obj,\n\t\t\t\t struct drm_file *file);\nint virtio_gpu_mode_dumb_create(struct drm_file *file_priv,\n\t\t\t\tstruct drm_device *dev,\n\t\t\t\tstruct drm_mode_create_dumb *args);\nint virtio_gpu_mode_dumb_mmap(struct drm_file *file_priv,\n\t\t\t      struct drm_device *dev,\n\t\t\t      uint32_t handle, uint64_t *offset_p);\n\nstruct virtio_gpu_object_array *virtio_gpu_array_alloc(u32 nents);\nstruct virtio_gpu_object_array*\nvirtio_gpu_array_from_handles(struct drm_file *drm_file, u32 *handles, u32 nents);\nvoid virtio_gpu_array_add_obj(struct virtio_gpu_object_array *objs,\n\t\t\t      struct drm_gem_object *obj);\nint virtio_gpu_array_lock_resv(struct virtio_gpu_object_array *objs);\nvoid virtio_gpu_array_unlock_resv(struct virtio_gpu_object_array *objs);\nvoid virtio_gpu_array_add_fence(struct virtio_gpu_object_array *objs,\n\t\t\t\tstruct dma_fence *fence);\nvoid virtio_gpu_array_put_free(struct virtio_gpu_object_array *objs);\nvoid virtio_gpu_array_put_free_delayed(struct virtio_gpu_device *vgdev,\n\t\t\t\t       struct virtio_gpu_object_array *objs);\nvoid virtio_gpu_array_put_free_work(struct work_struct *work);\n\n \nint virtio_gpu_alloc_vbufs(struct virtio_gpu_device *vgdev);\nvoid virtio_gpu_free_vbufs(struct virtio_gpu_device *vgdev);\nvoid virtio_gpu_cmd_create_resource(struct virtio_gpu_device *vgdev,\n\t\t\t\t    struct virtio_gpu_object *bo,\n\t\t\t\t    struct virtio_gpu_object_params *params,\n\t\t\t\t    struct virtio_gpu_object_array *objs,\n\t\t\t\t    struct virtio_gpu_fence *fence);\nvoid virtio_gpu_cmd_unref_resource(struct virtio_gpu_device *vgdev,\n\t\t\t\t   struct virtio_gpu_object *bo);\nvoid virtio_gpu_cmd_transfer_to_host_2d(struct virtio_gpu_device *vgdev,\n\t\t\t\t\tuint64_t offset,\n\t\t\t\t\tuint32_t width, uint32_t height,\n\t\t\t\t\tuint32_t x, uint32_t y,\n\t\t\t\t\tstruct virtio_gpu_object_array *objs,\n\t\t\t\t\tstruct virtio_gpu_fence *fence);\nvoid virtio_gpu_cmd_resource_flush(struct virtio_gpu_device *vgdev,\n\t\t\t\t   uint32_t resource_id,\n\t\t\t\t   uint32_t x, uint32_t y,\n\t\t\t\t   uint32_t width, uint32_t height,\n\t\t\t\t   struct virtio_gpu_object_array *objs,\n\t\t\t\t   struct virtio_gpu_fence *fence);\nvoid virtio_gpu_cmd_set_scanout(struct virtio_gpu_device *vgdev,\n\t\t\t\tuint32_t scanout_id, uint32_t resource_id,\n\t\t\t\tuint32_t width, uint32_t height,\n\t\t\t\tuint32_t x, uint32_t y);\nvoid virtio_gpu_object_attach(struct virtio_gpu_device *vgdev,\n\t\t\t      struct virtio_gpu_object *obj,\n\t\t\t      struct virtio_gpu_mem_entry *ents,\n\t\t\t      unsigned int nents);\nint virtio_gpu_attach_status_page(struct virtio_gpu_device *vgdev);\nint virtio_gpu_detach_status_page(struct virtio_gpu_device *vgdev);\nvoid virtio_gpu_cursor_ping(struct virtio_gpu_device *vgdev,\n\t\t\t    struct virtio_gpu_output *output);\nint virtio_gpu_cmd_get_display_info(struct virtio_gpu_device *vgdev);\nint virtio_gpu_cmd_get_capset_info(struct virtio_gpu_device *vgdev, int idx);\nint virtio_gpu_cmd_get_capset(struct virtio_gpu_device *vgdev,\n\t\t\t      int idx, int version,\n\t\t\t      struct virtio_gpu_drv_cap_cache **cache_p);\nint virtio_gpu_cmd_get_edids(struct virtio_gpu_device *vgdev);\nvoid virtio_gpu_cmd_context_create(struct virtio_gpu_device *vgdev, uint32_t id,\n\t\t\t\t   uint32_t context_init, uint32_t nlen,\n\t\t\t\t   const char *name);\nvoid virtio_gpu_cmd_context_destroy(struct virtio_gpu_device *vgdev,\n\t\t\t\t    uint32_t id);\nvoid virtio_gpu_cmd_context_attach_resource(struct virtio_gpu_device *vgdev,\n\t\t\t\t\t    uint32_t ctx_id,\n\t\t\t\t\t    struct virtio_gpu_object_array *objs);\nvoid virtio_gpu_cmd_context_detach_resource(struct virtio_gpu_device *vgdev,\n\t\t\t\t\t    uint32_t ctx_id,\n\t\t\t\t\t    struct virtio_gpu_object_array *objs);\nvoid virtio_gpu_cmd_submit(struct virtio_gpu_device *vgdev,\n\t\t\t   void *data, uint32_t data_size,\n\t\t\t   uint32_t ctx_id,\n\t\t\t   struct virtio_gpu_object_array *objs,\n\t\t\t   struct virtio_gpu_fence *fence);\nvoid virtio_gpu_cmd_transfer_from_host_3d(struct virtio_gpu_device *vgdev,\n\t\t\t\t\t  uint32_t ctx_id,\n\t\t\t\t\t  uint64_t offset, uint32_t level,\n\t\t\t\t\t  uint32_t stride,\n\t\t\t\t\t  uint32_t layer_stride,\n\t\t\t\t\t  struct drm_virtgpu_3d_box *box,\n\t\t\t\t\t  struct virtio_gpu_object_array *objs,\n\t\t\t\t\t  struct virtio_gpu_fence *fence);\nvoid virtio_gpu_cmd_transfer_to_host_3d(struct virtio_gpu_device *vgdev,\n\t\t\t\t\tuint32_t ctx_id,\n\t\t\t\t\tuint64_t offset, uint32_t level,\n\t\t\t\t\tuint32_t stride,\n\t\t\t\t\tuint32_t layer_stride,\n\t\t\t\t\tstruct drm_virtgpu_3d_box *box,\n\t\t\t\t\tstruct virtio_gpu_object_array *objs,\n\t\t\t\t\tstruct virtio_gpu_fence *fence);\nvoid\nvirtio_gpu_cmd_resource_create_3d(struct virtio_gpu_device *vgdev,\n\t\t\t\t  struct virtio_gpu_object *bo,\n\t\t\t\t  struct virtio_gpu_object_params *params,\n\t\t\t\t  struct virtio_gpu_object_array *objs,\n\t\t\t\t  struct virtio_gpu_fence *fence);\nvoid virtio_gpu_ctrl_ack(struct virtqueue *vq);\nvoid virtio_gpu_cursor_ack(struct virtqueue *vq);\nvoid virtio_gpu_fence_ack(struct virtqueue *vq);\nvoid virtio_gpu_dequeue_ctrl_func(struct work_struct *work);\nvoid virtio_gpu_dequeue_cursor_func(struct work_struct *work);\nvoid virtio_gpu_dequeue_fence_func(struct work_struct *work);\n\nvoid virtio_gpu_notify(struct virtio_gpu_device *vgdev);\n\nint\nvirtio_gpu_cmd_resource_assign_uuid(struct virtio_gpu_device *vgdev,\n\t\t\t\t    struct virtio_gpu_object_array *objs);\n\nint virtio_gpu_cmd_map(struct virtio_gpu_device *vgdev,\n\t\t       struct virtio_gpu_object_array *objs, uint64_t offset);\n\nvoid virtio_gpu_cmd_unmap(struct virtio_gpu_device *vgdev,\n\t\t\t  struct virtio_gpu_object *bo);\n\nvoid\nvirtio_gpu_cmd_resource_create_blob(struct virtio_gpu_device *vgdev,\n\t\t\t\t    struct virtio_gpu_object *bo,\n\t\t\t\t    struct virtio_gpu_object_params *params,\n\t\t\t\t    struct virtio_gpu_mem_entry *ents,\n\t\t\t\t    uint32_t nents);\nvoid\nvirtio_gpu_cmd_set_scanout_blob(struct virtio_gpu_device *vgdev,\n\t\t\t\tuint32_t scanout_id,\n\t\t\t\tstruct virtio_gpu_object *bo,\n\t\t\t\tstruct drm_framebuffer *fb,\n\t\t\t\tuint32_t width, uint32_t height,\n\t\t\t\tuint32_t x, uint32_t y);\n\n \nint virtio_gpu_modeset_init(struct virtio_gpu_device *vgdev);\nvoid virtio_gpu_modeset_fini(struct virtio_gpu_device *vgdev);\n\n \nuint32_t virtio_gpu_translate_format(uint32_t drm_fourcc);\nstruct drm_plane *virtio_gpu_plane_init(struct virtio_gpu_device *vgdev,\n\t\t\t\t\tenum drm_plane_type type,\n\t\t\t\t\tint index);\n\n \nstruct virtio_gpu_fence *virtio_gpu_fence_alloc(struct virtio_gpu_device *vgdev,\n\t\t\t\t\t\tuint64_t base_fence_ctx,\n\t\t\t\t\t\tuint32_t ring_idx);\nvoid virtio_gpu_fence_emit(struct virtio_gpu_device *vgdev,\n\t\t\t  struct virtio_gpu_ctrl_hdr *cmd_hdr,\n\t\t\t  struct virtio_gpu_fence *fence);\nvoid virtio_gpu_fence_event_process(struct virtio_gpu_device *vdev,\n\t\t\t\t    u64 fence_id);\n\n \nvoid virtio_gpu_cleanup_object(struct virtio_gpu_object *bo);\nstruct drm_gem_object *virtio_gpu_create_object(struct drm_device *dev,\n\t\t\t\t\t\tsize_t size);\nint virtio_gpu_object_create(struct virtio_gpu_device *vgdev,\n\t\t\t     struct virtio_gpu_object_params *params,\n\t\t\t     struct virtio_gpu_object **bo_ptr,\n\t\t\t     struct virtio_gpu_fence *fence);\n\nbool virtio_gpu_is_shmem(struct virtio_gpu_object *bo);\n\nint virtio_gpu_resource_id_get(struct virtio_gpu_device *vgdev,\n\t\t\t       uint32_t *resid);\n \nint virtio_gpu_resource_assign_uuid(struct virtio_gpu_device *vgdev,\n\t\t\t\t    struct virtio_gpu_object *bo);\nstruct dma_buf *virtgpu_gem_prime_export(struct drm_gem_object *obj,\n\t\t\t\t\t int flags);\nstruct drm_gem_object *virtgpu_gem_prime_import(struct drm_device *dev,\n\t\t\t\t\t\tstruct dma_buf *buf);\nint virtgpu_gem_prime_get_uuid(struct drm_gem_object *obj,\n\t\t\t       uuid_t *uuid);\nstruct drm_gem_object *virtgpu_gem_prime_import_sg_table(\n\tstruct drm_device *dev, struct dma_buf_attachment *attach,\n\tstruct sg_table *sgt);\n\n \nvoid virtio_gpu_debugfs_init(struct drm_minor *minor);\n\n \nbool virtio_gpu_is_vram(struct virtio_gpu_object *bo);\nint virtio_gpu_vram_create(struct virtio_gpu_device *vgdev,\n\t\t\t   struct virtio_gpu_object_params *params,\n\t\t\t   struct virtio_gpu_object **bo_ptr);\nstruct sg_table *virtio_gpu_vram_map_dma_buf(struct virtio_gpu_object *bo,\n\t\t\t\t\t     struct device *dev,\n\t\t\t\t\t     enum dma_data_direction dir);\nvoid virtio_gpu_vram_unmap_dma_buf(struct device *dev,\n\t\t\t\t   struct sg_table *sgt,\n\t\t\t\t   enum dma_data_direction dir);\n\n \nint virtio_gpu_execbuffer_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file);\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}