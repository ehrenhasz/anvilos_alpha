{
  "module_name": "drm_gem_shmem_helper.c",
  "hash_id": "6490a97b7d9b09a2c30aefb153e07e19bad7b75911c04d062c9dfe7a2f3d4ce8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/drm_gem_shmem_helper.c",
  "human_readable_source": "\n \n\n#include <linux/dma-buf.h>\n#include <linux/export.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/shmem_fs.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n\n#ifdef CONFIG_X86\n#include <asm/set_memory.h>\n#endif\n\n#include <drm/drm.h>\n#include <drm/drm_device.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_gem_shmem_helper.h>\n#include <drm/drm_prime.h>\n#include <drm/drm_print.h>\n\nMODULE_IMPORT_NS(DMA_BUF);\n\n \n\nstatic const struct drm_gem_object_funcs drm_gem_shmem_funcs = {\n\t.free = drm_gem_shmem_object_free,\n\t.print_info = drm_gem_shmem_object_print_info,\n\t.pin = drm_gem_shmem_object_pin,\n\t.unpin = drm_gem_shmem_object_unpin,\n\t.get_sg_table = drm_gem_shmem_object_get_sg_table,\n\t.vmap = drm_gem_shmem_object_vmap,\n\t.vunmap = drm_gem_shmem_object_vunmap,\n\t.mmap = drm_gem_shmem_object_mmap,\n\t.vm_ops = &drm_gem_shmem_vm_ops,\n};\n\nstatic struct drm_gem_shmem_object *\n__drm_gem_shmem_create(struct drm_device *dev, size_t size, bool private)\n{\n\tstruct drm_gem_shmem_object *shmem;\n\tstruct drm_gem_object *obj;\n\tint ret = 0;\n\n\tsize = PAGE_ALIGN(size);\n\n\tif (dev->driver->gem_create_object) {\n\t\tobj = dev->driver->gem_create_object(dev, size);\n\t\tif (IS_ERR(obj))\n\t\t\treturn ERR_CAST(obj);\n\t\tshmem = to_drm_gem_shmem_obj(obj);\n\t} else {\n\t\tshmem = kzalloc(sizeof(*shmem), GFP_KERNEL);\n\t\tif (!shmem)\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\tobj = &shmem->base;\n\t}\n\n\tif (!obj->funcs)\n\t\tobj->funcs = &drm_gem_shmem_funcs;\n\n\tif (private) {\n\t\tdrm_gem_private_object_init(dev, obj, size);\n\t\tshmem->map_wc = false;  \n\t} else {\n\t\tret = drm_gem_object_init(dev, obj, size);\n\t}\n\tif (ret) {\n\t\tdrm_gem_private_object_fini(obj);\n\t\tgoto err_free;\n\t}\n\n\tret = drm_gem_create_mmap_offset(obj);\n\tif (ret)\n\t\tgoto err_release;\n\n\tINIT_LIST_HEAD(&shmem->madv_list);\n\n\tif (!private) {\n\t\t \n\t\tmapping_set_gfp_mask(obj->filp->f_mapping, GFP_HIGHUSER |\n\t\t\t\t     __GFP_RETRY_MAYFAIL | __GFP_NOWARN);\n\t}\n\n\treturn shmem;\n\nerr_release:\n\tdrm_gem_object_release(obj);\nerr_free:\n\tkfree(obj);\n\n\treturn ERR_PTR(ret);\n}\n \nstruct drm_gem_shmem_object *drm_gem_shmem_create(struct drm_device *dev, size_t size)\n{\n\treturn __drm_gem_shmem_create(dev, size, false);\n}\nEXPORT_SYMBOL_GPL(drm_gem_shmem_create);\n\n \nvoid drm_gem_shmem_free(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\n\tif (obj->import_attach) {\n\t\tdrm_prime_gem_destroy(obj, shmem->sgt);\n\t} else {\n\t\tdma_resv_lock(shmem->base.resv, NULL);\n\n\t\tdrm_WARN_ON(obj->dev, shmem->vmap_use_count);\n\n\t\tif (shmem->sgt) {\n\t\t\tdma_unmap_sgtable(obj->dev->dev, shmem->sgt,\n\t\t\t\t\t  DMA_BIDIRECTIONAL, 0);\n\t\t\tsg_free_table(shmem->sgt);\n\t\t\tkfree(shmem->sgt);\n\t\t}\n\t\tif (shmem->pages)\n\t\t\tdrm_gem_shmem_put_pages(shmem);\n\n\t\tdrm_WARN_ON(obj->dev, shmem->pages_use_count);\n\n\t\tdma_resv_unlock(shmem->base.resv);\n\t}\n\n\tdrm_gem_object_release(obj);\n\tkfree(shmem);\n}\nEXPORT_SYMBOL_GPL(drm_gem_shmem_free);\n\nstatic int drm_gem_shmem_get_pages(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\tstruct page **pages;\n\n\tdma_resv_assert_held(shmem->base.resv);\n\n\tif (shmem->pages_use_count++ > 0)\n\t\treturn 0;\n\n\tpages = drm_gem_get_pages(obj);\n\tif (IS_ERR(pages)) {\n\t\tdrm_dbg_kms(obj->dev, \"Failed to get pages (%ld)\\n\",\n\t\t\t    PTR_ERR(pages));\n\t\tshmem->pages_use_count = 0;\n\t\treturn PTR_ERR(pages);\n\t}\n\n\t \n#ifdef CONFIG_X86\n\tif (shmem->map_wc)\n\t\tset_pages_array_wc(pages, obj->size >> PAGE_SHIFT);\n#endif\n\n\tshmem->pages = pages;\n\n\treturn 0;\n}\n\n \nvoid drm_gem_shmem_put_pages(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\n\tdma_resv_assert_held(shmem->base.resv);\n\n\tif (drm_WARN_ON_ONCE(obj->dev, !shmem->pages_use_count))\n\t\treturn;\n\n\tif (--shmem->pages_use_count > 0)\n\t\treturn;\n\n#ifdef CONFIG_X86\n\tif (shmem->map_wc)\n\t\tset_pages_array_wb(shmem->pages, obj->size >> PAGE_SHIFT);\n#endif\n\n\tdrm_gem_put_pages(obj, shmem->pages,\n\t\t\t  shmem->pages_mark_dirty_on_put,\n\t\t\t  shmem->pages_mark_accessed_on_put);\n\tshmem->pages = NULL;\n}\nEXPORT_SYMBOL(drm_gem_shmem_put_pages);\n\nstatic int drm_gem_shmem_pin_locked(struct drm_gem_shmem_object *shmem)\n{\n\tint ret;\n\n\tdma_resv_assert_held(shmem->base.resv);\n\n\tret = drm_gem_shmem_get_pages(shmem);\n\n\treturn ret;\n}\n\nstatic void drm_gem_shmem_unpin_locked(struct drm_gem_shmem_object *shmem)\n{\n\tdma_resv_assert_held(shmem->base.resv);\n\n\tdrm_gem_shmem_put_pages(shmem);\n}\n\n \nint drm_gem_shmem_pin(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\tint ret;\n\n\tdrm_WARN_ON(obj->dev, obj->import_attach);\n\n\tret = dma_resv_lock_interruptible(shmem->base.resv, NULL);\n\tif (ret)\n\t\treturn ret;\n\tret = drm_gem_shmem_pin_locked(shmem);\n\tdma_resv_unlock(shmem->base.resv);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_shmem_pin);\n\n \nvoid drm_gem_shmem_unpin(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\n\tdrm_WARN_ON(obj->dev, obj->import_attach);\n\n\tdma_resv_lock(shmem->base.resv, NULL);\n\tdrm_gem_shmem_unpin_locked(shmem);\n\tdma_resv_unlock(shmem->base.resv);\n}\nEXPORT_SYMBOL(drm_gem_shmem_unpin);\n\n \nint drm_gem_shmem_vmap(struct drm_gem_shmem_object *shmem,\n\t\t       struct iosys_map *map)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\tint ret = 0;\n\n\tif (obj->import_attach) {\n\t\tret = dma_buf_vmap(obj->import_attach->dmabuf, map);\n\t\tif (!ret) {\n\t\t\tif (drm_WARN_ON(obj->dev, map->is_iomem)) {\n\t\t\t\tdma_buf_vunmap(obj->import_attach->dmabuf, map);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tpgprot_t prot = PAGE_KERNEL;\n\n\t\tdma_resv_assert_held(shmem->base.resv);\n\n\t\tif (shmem->vmap_use_count++ > 0) {\n\t\t\tiosys_map_set_vaddr(map, shmem->vaddr);\n\t\t\treturn 0;\n\t\t}\n\n\t\tret = drm_gem_shmem_get_pages(shmem);\n\t\tif (ret)\n\t\t\tgoto err_zero_use;\n\n\t\tif (shmem->map_wc)\n\t\t\tprot = pgprot_writecombine(prot);\n\t\tshmem->vaddr = vmap(shmem->pages, obj->size >> PAGE_SHIFT,\n\t\t\t\t    VM_MAP, prot);\n\t\tif (!shmem->vaddr)\n\t\t\tret = -ENOMEM;\n\t\telse\n\t\t\tiosys_map_set_vaddr(map, shmem->vaddr);\n\t}\n\n\tif (ret) {\n\t\tdrm_dbg_kms(obj->dev, \"Failed to vmap pages, error %d\\n\", ret);\n\t\tgoto err_put_pages;\n\t}\n\n\treturn 0;\n\nerr_put_pages:\n\tif (!obj->import_attach)\n\t\tdrm_gem_shmem_put_pages(shmem);\nerr_zero_use:\n\tshmem->vmap_use_count = 0;\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_shmem_vmap);\n\n \nvoid drm_gem_shmem_vunmap(struct drm_gem_shmem_object *shmem,\n\t\t\t  struct iosys_map *map)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\n\tif (obj->import_attach) {\n\t\tdma_buf_vunmap(obj->import_attach->dmabuf, map);\n\t} else {\n\t\tdma_resv_assert_held(shmem->base.resv);\n\n\t\tif (drm_WARN_ON_ONCE(obj->dev, !shmem->vmap_use_count))\n\t\t\treturn;\n\n\t\tif (--shmem->vmap_use_count > 0)\n\t\t\treturn;\n\n\t\tvunmap(shmem->vaddr);\n\t\tdrm_gem_shmem_put_pages(shmem);\n\t}\n\n\tshmem->vaddr = NULL;\n}\nEXPORT_SYMBOL(drm_gem_shmem_vunmap);\n\nstatic int\ndrm_gem_shmem_create_with_handle(struct drm_file *file_priv,\n\t\t\t\t struct drm_device *dev, size_t size,\n\t\t\t\t uint32_t *handle)\n{\n\tstruct drm_gem_shmem_object *shmem;\n\tint ret;\n\n\tshmem = drm_gem_shmem_create(dev, size);\n\tif (IS_ERR(shmem))\n\t\treturn PTR_ERR(shmem);\n\n\t \n\tret = drm_gem_handle_create(file_priv, &shmem->base, handle);\n\t \n\tdrm_gem_object_put(&shmem->base);\n\n\treturn ret;\n}\n\n \nint drm_gem_shmem_madvise(struct drm_gem_shmem_object *shmem, int madv)\n{\n\tdma_resv_assert_held(shmem->base.resv);\n\n\tif (shmem->madv >= 0)\n\t\tshmem->madv = madv;\n\n\tmadv = shmem->madv;\n\n\treturn (madv >= 0);\n}\nEXPORT_SYMBOL(drm_gem_shmem_madvise);\n\nvoid drm_gem_shmem_purge(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\tstruct drm_device *dev = obj->dev;\n\n\tdma_resv_assert_held(shmem->base.resv);\n\n\tdrm_WARN_ON(obj->dev, !drm_gem_shmem_is_purgeable(shmem));\n\n\tdma_unmap_sgtable(dev->dev, shmem->sgt, DMA_BIDIRECTIONAL, 0);\n\tsg_free_table(shmem->sgt);\n\tkfree(shmem->sgt);\n\tshmem->sgt = NULL;\n\n\tdrm_gem_shmem_put_pages(shmem);\n\n\tshmem->madv = -1;\n\n\tdrm_vma_node_unmap(&obj->vma_node, dev->anon_inode->i_mapping);\n\tdrm_gem_free_mmap_offset(obj);\n\n\t \n\tshmem_truncate_range(file_inode(obj->filp), 0, (loff_t)-1);\n\n\tinvalidate_mapping_pages(file_inode(obj->filp)->i_mapping, 0, (loff_t)-1);\n}\nEXPORT_SYMBOL(drm_gem_shmem_purge);\n\n \nint drm_gem_shmem_dumb_create(struct drm_file *file, struct drm_device *dev,\n\t\t\t      struct drm_mode_create_dumb *args)\n{\n\tu32 min_pitch = DIV_ROUND_UP(args->width * args->bpp, 8);\n\n\tif (!args->pitch || !args->size) {\n\t\targs->pitch = min_pitch;\n\t\targs->size = PAGE_ALIGN(args->pitch * args->height);\n\t} else {\n\t\t \n\t\tif (args->pitch < min_pitch)\n\t\t\targs->pitch = min_pitch;\n\t\tif (args->size < args->pitch * args->height)\n\t\t\targs->size = PAGE_ALIGN(args->pitch * args->height);\n\t}\n\n\treturn drm_gem_shmem_create_with_handle(file, dev, args->size, &args->handle);\n}\nEXPORT_SYMBOL_GPL(drm_gem_shmem_dumb_create);\n\nstatic vm_fault_t drm_gem_shmem_fault(struct vm_fault *vmf)\n{\n\tstruct vm_area_struct *vma = vmf->vma;\n\tstruct drm_gem_object *obj = vma->vm_private_data;\n\tstruct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);\n\tloff_t num_pages = obj->size >> PAGE_SHIFT;\n\tvm_fault_t ret;\n\tstruct page *page;\n\tpgoff_t page_offset;\n\n\t \n\tpage_offset = (vmf->address - vma->vm_start) >> PAGE_SHIFT;\n\n\tdma_resv_lock(shmem->base.resv, NULL);\n\n\tif (page_offset >= num_pages ||\n\t    drm_WARN_ON_ONCE(obj->dev, !shmem->pages) ||\n\t    shmem->madv < 0) {\n\t\tret = VM_FAULT_SIGBUS;\n\t} else {\n\t\tpage = shmem->pages[page_offset];\n\n\t\tret = vmf_insert_pfn(vma, vmf->address, page_to_pfn(page));\n\t}\n\n\tdma_resv_unlock(shmem->base.resv);\n\n\treturn ret;\n}\n\nstatic void drm_gem_shmem_vm_open(struct vm_area_struct *vma)\n{\n\tstruct drm_gem_object *obj = vma->vm_private_data;\n\tstruct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);\n\n\tdrm_WARN_ON(obj->dev, obj->import_attach);\n\n\tdma_resv_lock(shmem->base.resv, NULL);\n\n\t \n\tif (!drm_WARN_ON_ONCE(obj->dev, !shmem->pages_use_count))\n\t\tshmem->pages_use_count++;\n\n\tdma_resv_unlock(shmem->base.resv);\n\n\tdrm_gem_vm_open(vma);\n}\n\nstatic void drm_gem_shmem_vm_close(struct vm_area_struct *vma)\n{\n\tstruct drm_gem_object *obj = vma->vm_private_data;\n\tstruct drm_gem_shmem_object *shmem = to_drm_gem_shmem_obj(obj);\n\n\tdma_resv_lock(shmem->base.resv, NULL);\n\tdrm_gem_shmem_put_pages(shmem);\n\tdma_resv_unlock(shmem->base.resv);\n\n\tdrm_gem_vm_close(vma);\n}\n\nconst struct vm_operations_struct drm_gem_shmem_vm_ops = {\n\t.fault = drm_gem_shmem_fault,\n\t.open = drm_gem_shmem_vm_open,\n\t.close = drm_gem_shmem_vm_close,\n};\nEXPORT_SYMBOL_GPL(drm_gem_shmem_vm_ops);\n\n \nint drm_gem_shmem_mmap(struct drm_gem_shmem_object *shmem, struct vm_area_struct *vma)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\tint ret;\n\n\tif (obj->import_attach) {\n\t\t \n\t\tvma->vm_private_data = NULL;\n\t\tvma->vm_ops = NULL;\n\n\t\tret = dma_buf_mmap(obj->dma_buf, vma, 0);\n\n\t\t \n\t\tif (!ret)\n\t\t\tdrm_gem_object_put(obj);\n\n\t\treturn ret;\n\t}\n\n\tdma_resv_lock(shmem->base.resv, NULL);\n\tret = drm_gem_shmem_get_pages(shmem);\n\tdma_resv_unlock(shmem->base.resv);\n\n\tif (ret)\n\t\treturn ret;\n\n\tvm_flags_set(vma, VM_PFNMAP | VM_DONTEXPAND | VM_DONTDUMP);\n\tvma->vm_page_prot = vm_get_page_prot(vma->vm_flags);\n\tif (shmem->map_wc)\n\t\tvma->vm_page_prot = pgprot_writecombine(vma->vm_page_prot);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(drm_gem_shmem_mmap);\n\n \nvoid drm_gem_shmem_print_info(const struct drm_gem_shmem_object *shmem,\n\t\t\t      struct drm_printer *p, unsigned int indent)\n{\n\tif (shmem->base.import_attach)\n\t\treturn;\n\n\tdrm_printf_indent(p, indent, \"pages_use_count=%u\\n\", shmem->pages_use_count);\n\tdrm_printf_indent(p, indent, \"vmap_use_count=%u\\n\", shmem->vmap_use_count);\n\tdrm_printf_indent(p, indent, \"vaddr=%p\\n\", shmem->vaddr);\n}\nEXPORT_SYMBOL(drm_gem_shmem_print_info);\n\n \nstruct sg_table *drm_gem_shmem_get_sg_table(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\n\tdrm_WARN_ON(obj->dev, obj->import_attach);\n\n\treturn drm_prime_pages_to_sg(obj->dev, shmem->pages, obj->size >> PAGE_SHIFT);\n}\nEXPORT_SYMBOL_GPL(drm_gem_shmem_get_sg_table);\n\nstatic struct sg_table *drm_gem_shmem_get_pages_sgt_locked(struct drm_gem_shmem_object *shmem)\n{\n\tstruct drm_gem_object *obj = &shmem->base;\n\tint ret;\n\tstruct sg_table *sgt;\n\n\tif (shmem->sgt)\n\t\treturn shmem->sgt;\n\n\tdrm_WARN_ON(obj->dev, obj->import_attach);\n\n\tret = drm_gem_shmem_get_pages(shmem);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tsgt = drm_gem_shmem_get_sg_table(shmem);\n\tif (IS_ERR(sgt)) {\n\t\tret = PTR_ERR(sgt);\n\t\tgoto err_put_pages;\n\t}\n\t \n\tret = dma_map_sgtable(obj->dev->dev, sgt, DMA_BIDIRECTIONAL, 0);\n\tif (ret)\n\t\tgoto err_free_sgt;\n\n\tshmem->sgt = sgt;\n\n\treturn sgt;\n\nerr_free_sgt:\n\tsg_free_table(sgt);\n\tkfree(sgt);\nerr_put_pages:\n\tdrm_gem_shmem_put_pages(shmem);\n\treturn ERR_PTR(ret);\n}\n\n \nstruct sg_table *drm_gem_shmem_get_pages_sgt(struct drm_gem_shmem_object *shmem)\n{\n\tint ret;\n\tstruct sg_table *sgt;\n\n\tret = dma_resv_lock_interruptible(shmem->base.resv, NULL);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tsgt = drm_gem_shmem_get_pages_sgt_locked(shmem);\n\tdma_resv_unlock(shmem->base.resv);\n\n\treturn sgt;\n}\nEXPORT_SYMBOL_GPL(drm_gem_shmem_get_pages_sgt);\n\n \nstruct drm_gem_object *\ndrm_gem_shmem_prime_import_sg_table(struct drm_device *dev,\n\t\t\t\t    struct dma_buf_attachment *attach,\n\t\t\t\t    struct sg_table *sgt)\n{\n\tsize_t size = PAGE_ALIGN(attach->dmabuf->size);\n\tstruct drm_gem_shmem_object *shmem;\n\n\tshmem = __drm_gem_shmem_create(dev, size, true);\n\tif (IS_ERR(shmem))\n\t\treturn ERR_CAST(shmem);\n\n\tshmem->sgt = sgt;\n\n\tdrm_dbg_prime(dev, \"size = %zu\\n\", size);\n\n\treturn &shmem->base;\n}\nEXPORT_SYMBOL_GPL(drm_gem_shmem_prime_import_sg_table);\n\nMODULE_DESCRIPTION(\"DRM SHMEM memory-management helpers\");\nMODULE_IMPORT_NS(DMA_BUF);\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}