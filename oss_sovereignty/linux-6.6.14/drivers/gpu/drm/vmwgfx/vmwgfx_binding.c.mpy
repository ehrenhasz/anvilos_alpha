{
  "module_name": "vmwgfx_binding.c",
  "hash_id": "3d173b0a631d60160d45d4386e32b7eb1882cd708f80c97a3340f2b4c92dc891",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/vmwgfx_binding.c",
  "human_readable_source": "\n \n \n\n#include \"vmwgfx_drv.h\"\n#include \"vmwgfx_binding.h\"\n#include \"device_include/svga3d_reg.h\"\n\n#define VMW_BINDING_RT_BIT     0\n#define VMW_BINDING_PS_BIT     1\n#define VMW_BINDING_SO_T_BIT   2\n#define VMW_BINDING_VB_BIT     3\n#define VMW_BINDING_UAV_BIT    4\n#define VMW_BINDING_CS_UAV_BIT 5\n#define VMW_BINDING_NUM_BITS   6\n\n#define VMW_BINDING_PS_SR_BIT  0\n\n \nstruct vmw_ctx_binding_state {\n\tstruct vmw_private *dev_priv;\n\tstruct list_head list;\n\tstruct vmw_ctx_bindinfo_view render_targets[SVGA3D_RT_MAX];\n\tstruct vmw_ctx_bindinfo_tex texture_units[SVGA3D_NUM_TEXTURE_UNITS];\n\tstruct vmw_ctx_bindinfo_view ds_view;\n\tstruct vmw_ctx_bindinfo_so_target so_targets[SVGA3D_DX_MAX_SOTARGETS];\n\tstruct vmw_ctx_bindinfo_vb vertex_buffers[SVGA3D_DX_MAX_VERTEXBUFFERS];\n\tstruct vmw_ctx_bindinfo_ib index_buffer;\n\tstruct vmw_dx_shader_bindings per_shader[SVGA3D_NUM_SHADERTYPE];\n\tstruct vmw_ctx_bindinfo_uav ua_views[VMW_MAX_UAV_BIND_TYPE];\n\tstruct vmw_ctx_bindinfo_so so_state;\n\n\tunsigned long dirty;\n\tDECLARE_BITMAP(dirty_vb, SVGA3D_DX_MAX_VERTEXBUFFERS);\n\n\tu32 bind_cmd_buffer[VMW_MAX_VIEW_BINDINGS];\n\tu32 bind_cmd_count;\n\tu32 bind_first_slot;\n};\n\nstatic int vmw_binding_scrub_shader(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_render_target(struct vmw_ctx_bindinfo *bi,\n\t\t\t\t\t   bool rebind);\nstatic int vmw_binding_scrub_texture(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_cb(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_dx_rt(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_sr(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_so_target(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_emit_dirty(struct vmw_ctx_binding_state *cbs);\nstatic int vmw_binding_scrub_dx_shader(struct vmw_ctx_bindinfo *bi,\n\t\t\t\t       bool rebind);\nstatic int vmw_binding_scrub_ib(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_vb(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_uav(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_cs_uav(struct vmw_ctx_bindinfo *bi, bool rebind);\nstatic int vmw_binding_scrub_so(struct vmw_ctx_bindinfo *bi, bool rebind);\n\nstatic void vmw_binding_build_asserts(void) __attribute__ ((unused));\n\ntypedef int (*vmw_scrub_func)(struct vmw_ctx_bindinfo *, bool);\n\n \nstruct vmw_binding_info {\n\tsize_t size;\n\tconst size_t *offsets;\n\tvmw_scrub_func scrub_func;\n};\n\n \nstatic const size_t vmw_binding_shader_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, per_shader[0].shader),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[1].shader),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[2].shader),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[3].shader),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[4].shader),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[5].shader),\n};\nstatic const size_t vmw_binding_rt_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, render_targets),\n};\nstatic const size_t vmw_binding_tex_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, texture_units),\n};\nstatic const size_t vmw_binding_cb_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, per_shader[0].const_buffers),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[1].const_buffers),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[2].const_buffers),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[3].const_buffers),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[4].const_buffers),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[5].const_buffers),\n};\nstatic const size_t vmw_binding_dx_ds_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, ds_view),\n};\nstatic const size_t vmw_binding_sr_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, per_shader[0].shader_res),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[1].shader_res),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[2].shader_res),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[3].shader_res),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[4].shader_res),\n\toffsetof(struct vmw_ctx_binding_state, per_shader[5].shader_res),\n};\nstatic const size_t vmw_binding_so_target_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, so_targets),\n};\nstatic const size_t vmw_binding_vb_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, vertex_buffers),\n};\nstatic const size_t vmw_binding_ib_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, index_buffer),\n};\nstatic const size_t vmw_binding_uav_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, ua_views[0].views),\n};\nstatic const size_t vmw_binding_cs_uav_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, ua_views[1].views),\n};\nstatic const size_t vmw_binding_so_offsets[] = {\n\toffsetof(struct vmw_ctx_binding_state, so_state),\n};\n\nstatic const struct vmw_binding_info vmw_binding_infos[] = {\n\t[vmw_ctx_binding_shader] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_shader),\n\t\t.offsets = vmw_binding_shader_offsets,\n\t\t.scrub_func = vmw_binding_scrub_shader},\n\t[vmw_ctx_binding_rt] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_view),\n\t\t.offsets = vmw_binding_rt_offsets,\n\t\t.scrub_func = vmw_binding_scrub_render_target},\n\t[vmw_ctx_binding_tex] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_tex),\n\t\t.offsets = vmw_binding_tex_offsets,\n\t\t.scrub_func = vmw_binding_scrub_texture},\n\t[vmw_ctx_binding_cb] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_cb),\n\t\t.offsets = vmw_binding_cb_offsets,\n\t\t.scrub_func = vmw_binding_scrub_cb},\n\t[vmw_ctx_binding_dx_shader] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_shader),\n\t\t.offsets = vmw_binding_shader_offsets,\n\t\t.scrub_func = vmw_binding_scrub_dx_shader},\n\t[vmw_ctx_binding_dx_rt] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_view),\n\t\t.offsets = vmw_binding_rt_offsets,\n\t\t.scrub_func = vmw_binding_scrub_dx_rt},\n\t[vmw_ctx_binding_sr] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_view),\n\t\t.offsets = vmw_binding_sr_offsets,\n\t\t.scrub_func = vmw_binding_scrub_sr},\n\t[vmw_ctx_binding_ds] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_view),\n\t\t.offsets = vmw_binding_dx_ds_offsets,\n\t\t.scrub_func = vmw_binding_scrub_dx_rt},\n\t[vmw_ctx_binding_so_target] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_so_target),\n\t\t.offsets = vmw_binding_so_target_offsets,\n\t\t.scrub_func = vmw_binding_scrub_so_target},\n\t[vmw_ctx_binding_vb] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_vb),\n\t\t.offsets = vmw_binding_vb_offsets,\n\t\t.scrub_func = vmw_binding_scrub_vb},\n\t[vmw_ctx_binding_ib] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_ib),\n\t\t.offsets = vmw_binding_ib_offsets,\n\t\t.scrub_func = vmw_binding_scrub_ib},\n\t[vmw_ctx_binding_uav] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_view),\n\t\t.offsets = vmw_binding_uav_offsets,\n\t\t.scrub_func = vmw_binding_scrub_uav},\n\t[vmw_ctx_binding_cs_uav] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_view),\n\t\t.offsets = vmw_binding_cs_uav_offsets,\n\t\t.scrub_func = vmw_binding_scrub_cs_uav},\n\t[vmw_ctx_binding_so] = {\n\t\t.size = sizeof(struct vmw_ctx_bindinfo_so),\n\t\t.offsets = vmw_binding_so_offsets,\n\t\t.scrub_func = vmw_binding_scrub_so},\n};\n\n \nstatic const struct vmw_resource *\nvmw_cbs_context(const struct vmw_ctx_binding_state *cbs)\n{\n\tif (list_empty(&cbs->list))\n\t\treturn NULL;\n\n\treturn list_first_entry(&cbs->list, struct vmw_ctx_bindinfo,\n\t\t\t\tctx_list)->ctx;\n}\n\n \nstatic struct vmw_ctx_bindinfo *\nvmw_binding_loc(struct vmw_ctx_binding_state *cbs,\n\t\tenum vmw_ctx_binding_type bt, u32 shader_slot, u32 slot)\n{\n\tconst struct vmw_binding_info *b = &vmw_binding_infos[bt];\n\tsize_t offset = b->offsets[shader_slot] + b->size*slot;\n\n\treturn (struct vmw_ctx_bindinfo *)((u8 *) cbs + offset);\n}\n\n \nstatic void vmw_binding_drop(struct vmw_ctx_bindinfo *bi)\n{\n\tlist_del(&bi->ctx_list);\n\tif (!list_empty(&bi->res_list))\n\t\tlist_del(&bi->res_list);\n\tbi->ctx = NULL;\n}\n\n \nvoid vmw_binding_add(struct vmw_ctx_binding_state *cbs,\n\t\t    const struct vmw_ctx_bindinfo *bi,\n\t\t    u32 shader_slot, u32 slot)\n{\n\tstruct vmw_ctx_bindinfo *loc =\n\t\tvmw_binding_loc(cbs, bi->bt, shader_slot, slot);\n\tconst struct vmw_binding_info *b = &vmw_binding_infos[bi->bt];\n\n\tif (loc->ctx != NULL)\n\t\tvmw_binding_drop(loc);\n\n\tmemcpy(loc, bi, b->size);\n\tloc->scrubbed = false;\n\tlist_add(&loc->ctx_list, &cbs->list);\n\tINIT_LIST_HEAD(&loc->res_list);\n}\n\n \nvoid vmw_binding_cb_offset_update(struct vmw_ctx_binding_state *cbs,\n\t\t\t\t  u32 shader_slot, u32 slot, u32 offsetInBytes)\n{\n\tstruct vmw_ctx_bindinfo *loc =\n\t\tvmw_binding_loc(cbs, vmw_ctx_binding_cb, shader_slot, slot);\n\tstruct vmw_ctx_bindinfo_cb *loc_cb =\n\t\t(struct vmw_ctx_bindinfo_cb *)((u8 *) loc);\n\tloc_cb->offset = offsetInBytes;\n}\n\n \nvoid vmw_binding_add_uav_index(struct vmw_ctx_binding_state *cbs, uint32 slot,\n\t\t\t       uint32 index)\n{\n\tcbs->ua_views[slot].index = index;\n}\n\n \nstatic void vmw_binding_transfer(struct vmw_ctx_binding_state *cbs,\n\t\t\t\t const struct vmw_ctx_binding_state *from,\n\t\t\t\t const struct vmw_ctx_bindinfo *bi)\n{\n\tsize_t offset = (unsigned long)bi - (unsigned long)from;\n\tstruct vmw_ctx_bindinfo *loc = (struct vmw_ctx_bindinfo *)\n\t\t((unsigned long) cbs + offset);\n\n\tif (loc->ctx != NULL) {\n\t\tWARN_ON(bi->scrubbed);\n\n\t\tvmw_binding_drop(loc);\n\t}\n\n\tif (bi->res != NULL) {\n\t\tmemcpy(loc, bi, vmw_binding_infos[bi->bt].size);\n\t\tlist_add_tail(&loc->ctx_list, &cbs->list);\n\t\tlist_add_tail(&loc->res_list, &loc->res->binding_head);\n\t}\n}\n\n \nvoid vmw_binding_state_kill(struct vmw_ctx_binding_state *cbs)\n{\n\tstruct vmw_ctx_bindinfo *entry, *next;\n\n\tvmw_binding_state_scrub(cbs);\n\tlist_for_each_entry_safe(entry, next, &cbs->list, ctx_list)\n\t\tvmw_binding_drop(entry);\n}\n\n \nvoid vmw_binding_state_scrub(struct vmw_ctx_binding_state *cbs)\n{\n\tstruct vmw_ctx_bindinfo *entry;\n\n\tlist_for_each_entry(entry, &cbs->list, ctx_list) {\n\t\tif (!entry->scrubbed) {\n\t\t\t(void) vmw_binding_infos[entry->bt].scrub_func\n\t\t\t\t(entry, false);\n\t\t\tentry->scrubbed = true;\n\t\t}\n\t}\n\n\t(void) vmw_binding_emit_dirty(cbs);\n}\n\n \nvoid vmw_binding_res_list_kill(struct list_head *head)\n{\n\tstruct vmw_ctx_bindinfo *entry, *next;\n\n\tvmw_binding_res_list_scrub(head);\n\tlist_for_each_entry_safe(entry, next, head, res_list)\n\t\tvmw_binding_drop(entry);\n}\n\n \nvoid vmw_binding_res_list_scrub(struct list_head *head)\n{\n\tstruct vmw_ctx_bindinfo *entry;\n\n\tlist_for_each_entry(entry, head, res_list) {\n\t\tif (!entry->scrubbed) {\n\t\t\t(void) vmw_binding_infos[entry->bt].scrub_func\n\t\t\t\t(entry, false);\n\t\t\tentry->scrubbed = true;\n\t\t}\n\t}\n\n\tlist_for_each_entry(entry, head, res_list) {\n\t\tstruct vmw_ctx_binding_state *cbs =\n\t\t\tvmw_context_binding_state(entry->ctx);\n\n\t\t(void) vmw_binding_emit_dirty(cbs);\n\t}\n}\n\n\n \nvoid vmw_binding_state_commit(struct vmw_ctx_binding_state *to,\n\t\t\t      struct vmw_ctx_binding_state *from)\n{\n\tstruct vmw_ctx_bindinfo *entry, *next;\n\n\tlist_for_each_entry_safe(entry, next, &from->list, ctx_list) {\n\t\tvmw_binding_transfer(to, from, entry);\n\t\tvmw_binding_drop(entry);\n\t}\n\n\t \n\tto->ua_views[0].index = from->ua_views[0].index;\n\tto->ua_views[1].index = from->ua_views[1].index;\n}\n\n \nint vmw_binding_rebind_all(struct vmw_ctx_binding_state *cbs)\n{\n\tstruct vmw_ctx_bindinfo *entry;\n\tint ret;\n\n\tlist_for_each_entry(entry, &cbs->list, ctx_list) {\n\t\tif (likely(!entry->scrubbed))\n\t\t\tcontinue;\n\n\t\tif ((entry->res == NULL || entry->res->id ==\n\t\t\t    SVGA3D_INVALID_ID))\n\t\t\tcontinue;\n\n\t\tret = vmw_binding_infos[entry->bt].scrub_func(entry, true);\n\t\tif (unlikely(ret != 0))\n\t\t\treturn ret;\n\n\t\tentry->scrubbed = false;\n\t}\n\n\treturn vmw_binding_emit_dirty(cbs);\n}\n\n \nstatic int vmw_binding_scrub_shader(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_shader *binding =\n\t\tcontainer_of(bi, typeof(*binding), bi);\n\tstruct vmw_private *dev_priv = bi->ctx->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdSetShader body;\n\t} *cmd;\n\n\tcmd = VMW_CMD_RESERVE(dev_priv, sizeof(*cmd));\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_SET_SHADER;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.cid = bi->ctx->id;\n\tcmd->body.type = binding->shader_slot + SVGA3D_SHADERTYPE_MIN;\n\tcmd->body.shid = ((rebind) ? bi->res->id : SVGA3D_INVALID_ID);\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_render_target(struct vmw_ctx_bindinfo *bi,\n\t\t\t\t\t   bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_view *binding =\n\t\tcontainer_of(bi, typeof(*binding), bi);\n\tstruct vmw_private *dev_priv = bi->ctx->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdSetRenderTarget body;\n\t} *cmd;\n\n\tcmd = VMW_CMD_RESERVE(dev_priv, sizeof(*cmd));\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_SETRENDERTARGET;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.cid = bi->ctx->id;\n\tcmd->body.type = binding->slot;\n\tcmd->body.target.sid = ((rebind) ? bi->res->id : SVGA3D_INVALID_ID);\n\tcmd->body.target.face = 0;\n\tcmd->body.target.mipmap = 0;\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_texture(struct vmw_ctx_bindinfo *bi,\n\t\t\t\t     bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_tex *binding =\n\t\tcontainer_of(bi, typeof(*binding), bi);\n\tstruct vmw_private *dev_priv = bi->ctx->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tstruct {\n\t\t\tSVGA3dCmdSetTextureState c;\n\t\t\tSVGA3dTextureState s1;\n\t\t} body;\n\t} *cmd;\n\n\tcmd = VMW_CMD_RESERVE(dev_priv, sizeof(*cmd));\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_SETTEXTURESTATE;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.c.cid = bi->ctx->id;\n\tcmd->body.s1.stage = binding->texture_stage;\n\tcmd->body.s1.name = SVGA3D_TS_BIND_TEXTURE;\n\tcmd->body.s1.value = ((rebind) ? bi->res->id : SVGA3D_INVALID_ID);\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_dx_shader(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_shader *binding =\n\t\tcontainer_of(bi, typeof(*binding), bi);\n\tstruct vmw_private *dev_priv = bi->ctx->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetShader body;\n\t} *cmd;\n\n\tcmd = VMW_CMD_CTX_RESERVE(dev_priv, sizeof(*cmd), bi->ctx->id);\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_SHADER;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.type = binding->shader_slot + SVGA3D_SHADERTYPE_MIN;\n\tcmd->body.shaderId = ((rebind) ? bi->res->id : SVGA3D_INVALID_ID);\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_cb(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_cb *binding =\n\t\tcontainer_of(bi, typeof(*binding), bi);\n\tstruct vmw_private *dev_priv = bi->ctx->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetSingleConstantBuffer body;\n\t} *cmd;\n\n\tcmd = VMW_CMD_CTX_RESERVE(dev_priv, sizeof(*cmd), bi->ctx->id);\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_SINGLE_CONSTANT_BUFFER;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.slot = binding->slot;\n\tcmd->body.type = binding->shader_slot + SVGA3D_SHADERTYPE_MIN;\n\tif (rebind) {\n\t\tcmd->body.offsetInBytes = binding->offset;\n\t\tcmd->body.sizeInBytes = binding->size;\n\t\tcmd->body.sid = bi->res->id;\n\t} else {\n\t\tcmd->body.offsetInBytes = 0;\n\t\tcmd->body.sizeInBytes = 0;\n\t\tcmd->body.sid = SVGA3D_INVALID_ID;\n\t}\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\n\treturn 0;\n}\n\n \nstatic void vmw_collect_view_ids(struct vmw_ctx_binding_state *cbs,\n\t\t\t\t const struct vmw_ctx_bindinfo_view *biv,\n\t\t\t\t u32 max_num)\n{\n\tunsigned long i;\n\n\tcbs->bind_cmd_count = 0;\n\tcbs->bind_first_slot = 0;\n\n\tfor (i = 0; i < max_num; ++i, ++biv) {\n\t\tif (!biv->bi.ctx)\n\t\t\tbreak;\n\n\t\tcbs->bind_cmd_buffer[cbs->bind_cmd_count++] =\n\t\t\t((biv->bi.scrubbed) ?\n\t\t\t SVGA3D_INVALID_ID : biv->bi.res->id);\n\t}\n}\n\n \nstatic void vmw_collect_dirty_view_ids(struct vmw_ctx_binding_state *cbs,\n\t\t\t\t       const struct vmw_ctx_bindinfo *bi,\n\t\t\t\t       unsigned long *dirty,\n\t\t\t\t       u32 max_num)\n{\n\tconst struct vmw_ctx_bindinfo_view *biv =\n\t\tcontainer_of(bi, struct vmw_ctx_bindinfo_view, bi);\n\tunsigned long i, next_bit;\n\n\tcbs->bind_cmd_count = 0;\n\ti = find_first_bit(dirty, max_num);\n\tnext_bit = i;\n\tcbs->bind_first_slot = i;\n\n\tbiv += i;\n\tfor (; i < max_num; ++i, ++biv) {\n\t\tcbs->bind_cmd_buffer[cbs->bind_cmd_count++] =\n\t\t\t((!biv->bi.ctx || biv->bi.scrubbed) ?\n\t\t\t SVGA3D_INVALID_ID : biv->bi.res->id);\n\n\t\tif (next_bit == i) {\n\t\t\tnext_bit = find_next_bit(dirty, max_num, i + 1);\n\t\t\tif (next_bit >= max_num)\n\t\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nstatic int vmw_emit_set_sr(struct vmw_ctx_binding_state *cbs,\n\t\t\t   int shader_slot)\n{\n\tconst struct vmw_ctx_bindinfo *loc =\n\t\t&cbs->per_shader[shader_slot].shader_res[0].bi;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetShaderResources body;\n\t} *cmd;\n\tsize_t cmd_size, view_id_size;\n\tconst struct vmw_resource *ctx = vmw_cbs_context(cbs);\n\n\tvmw_collect_dirty_view_ids(cbs, loc,\n\t\t\t\t   cbs->per_shader[shader_slot].dirty_sr,\n\t\t\t\t   SVGA3D_DX_MAX_SRVIEWS);\n\tif (cbs->bind_cmd_count == 0)\n\t\treturn 0;\n\n\tview_id_size = cbs->bind_cmd_count*sizeof(uint32);\n\tcmd_size = sizeof(*cmd) + view_id_size;\n\tcmd = VMW_CMD_CTX_RESERVE(ctx->dev_priv, cmd_size, ctx->id);\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_SHADER_RESOURCES;\n\tcmd->header.size = sizeof(cmd->body) + view_id_size;\n\tcmd->body.type = shader_slot + SVGA3D_SHADERTYPE_MIN;\n\tcmd->body.startView = cbs->bind_first_slot;\n\n\tmemcpy(&cmd[1], cbs->bind_cmd_buffer, view_id_size);\n\n\tvmw_cmd_commit(ctx->dev_priv, cmd_size);\n\tbitmap_clear(cbs->per_shader[shader_slot].dirty_sr,\n\t\t     cbs->bind_first_slot, cbs->bind_cmd_count);\n\n\treturn 0;\n}\n\n \nstatic int vmw_emit_set_rt(struct vmw_ctx_binding_state *cbs)\n{\n\tconst struct vmw_ctx_bindinfo_view *loc = &cbs->render_targets[0];\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetRenderTargets body;\n\t} *cmd;\n\tsize_t cmd_size, view_id_size;\n\tconst struct vmw_resource *ctx = vmw_cbs_context(cbs);\n\n\tvmw_collect_view_ids(cbs, loc, SVGA3D_DX_MAX_RENDER_TARGETS);\n\tview_id_size = cbs->bind_cmd_count*sizeof(uint32);\n\tcmd_size = sizeof(*cmd) + view_id_size;\n\tcmd = VMW_CMD_CTX_RESERVE(ctx->dev_priv, cmd_size, ctx->id);\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_RENDERTARGETS;\n\tcmd->header.size = sizeof(cmd->body) + view_id_size;\n\n\tif (cbs->ds_view.bi.ctx && !cbs->ds_view.bi.scrubbed)\n\t\tcmd->body.depthStencilViewId = cbs->ds_view.bi.res->id;\n\telse\n\t\tcmd->body.depthStencilViewId = SVGA3D_INVALID_ID;\n\n\tmemcpy(&cmd[1], cbs->bind_cmd_buffer, view_id_size);\n\n\tvmw_cmd_commit(ctx->dev_priv, cmd_size);\n\n\treturn 0;\n\n}\n\n \nstatic void vmw_collect_so_targets(struct vmw_ctx_binding_state *cbs,\n\t\t\t\t   const struct vmw_ctx_bindinfo_so_target *biso,\n\t\t\t\t   u32 max_num)\n{\n\tunsigned long i;\n\tSVGA3dSoTarget *so_buffer = (SVGA3dSoTarget *) cbs->bind_cmd_buffer;\n\n\tcbs->bind_cmd_count = 0;\n\tcbs->bind_first_slot = 0;\n\n\tfor (i = 0; i < max_num; ++i, ++biso, ++so_buffer,\n\t\t    ++cbs->bind_cmd_count) {\n\t\tif (!biso->bi.ctx)\n\t\t\tbreak;\n\n\t\tif (!biso->bi.scrubbed) {\n\t\t\tso_buffer->sid = biso->bi.res->id;\n\t\t\tso_buffer->offset = biso->offset;\n\t\t\tso_buffer->sizeInBytes = biso->size;\n\t\t} else {\n\t\t\tso_buffer->sid = SVGA3D_INVALID_ID;\n\t\t\tso_buffer->offset = 0;\n\t\t\tso_buffer->sizeInBytes = 0;\n\t\t}\n\t}\n}\n\n \nstatic int vmw_emit_set_so_target(struct vmw_ctx_binding_state *cbs)\n{\n\tconst struct vmw_ctx_bindinfo_so_target *loc = &cbs->so_targets[0];\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetSOTargets body;\n\t} *cmd;\n\tsize_t cmd_size, so_target_size;\n\tconst struct vmw_resource *ctx = vmw_cbs_context(cbs);\n\n\tvmw_collect_so_targets(cbs, loc, SVGA3D_DX_MAX_SOTARGETS);\n\tif (cbs->bind_cmd_count == 0)\n\t\treturn 0;\n\n\tso_target_size = cbs->bind_cmd_count*sizeof(SVGA3dSoTarget);\n\tcmd_size = sizeof(*cmd) + so_target_size;\n\tcmd = VMW_CMD_CTX_RESERVE(ctx->dev_priv, cmd_size, ctx->id);\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_SOTARGETS;\n\tcmd->header.size = sizeof(cmd->body) + so_target_size;\n\tmemcpy(&cmd[1], cbs->bind_cmd_buffer, so_target_size);\n\n\tvmw_cmd_commit(ctx->dev_priv, cmd_size);\n\n\treturn 0;\n\n}\n\n \nstatic int vmw_binding_emit_dirty_ps(struct vmw_ctx_binding_state *cbs)\n{\n\tstruct vmw_dx_shader_bindings *sb = &cbs->per_shader[0];\n\tu32 i;\n\tint ret;\n\n\tfor (i = 0; i < SVGA3D_NUM_SHADERTYPE_DX10; ++i, ++sb) {\n\t\tif (!test_bit(VMW_BINDING_PS_SR_BIT, &sb->dirty))\n\t\t\tcontinue;\n\n\t\tret = vmw_emit_set_sr(cbs, i);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\t__clear_bit(VMW_BINDING_PS_SR_BIT, &sb->dirty);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void vmw_collect_dirty_vbs(struct vmw_ctx_binding_state *cbs,\n\t\t\t\t  const struct vmw_ctx_bindinfo *bi,\n\t\t\t\t  unsigned long *dirty,\n\t\t\t\t  u32 max_num)\n{\n\tconst struct vmw_ctx_bindinfo_vb *biv =\n\t\tcontainer_of(bi, struct vmw_ctx_bindinfo_vb, bi);\n\tunsigned long i, next_bit;\n\tSVGA3dVertexBuffer *vbs = (SVGA3dVertexBuffer *) &cbs->bind_cmd_buffer;\n\n\tcbs->bind_cmd_count = 0;\n\ti = find_first_bit(dirty, max_num);\n\tnext_bit = i;\n\tcbs->bind_first_slot = i;\n\n\tbiv += i;\n\tfor (; i < max_num; ++i, ++biv, ++vbs) {\n\t\tif (!biv->bi.ctx || biv->bi.scrubbed) {\n\t\t\tvbs->sid = SVGA3D_INVALID_ID;\n\t\t\tvbs->stride = 0;\n\t\t\tvbs->offset = 0;\n\t\t} else {\n\t\t\tvbs->sid = biv->bi.res->id;\n\t\t\tvbs->stride = biv->stride;\n\t\t\tvbs->offset = biv->offset;\n\t\t}\n\t\tcbs->bind_cmd_count++;\n\t\tif (next_bit == i) {\n\t\t\tnext_bit = find_next_bit(dirty, max_num, i + 1);\n\t\t\tif (next_bit >= max_num)\n\t\t\t\tbreak;\n\t\t}\n\t}\n}\n\n \nstatic int vmw_emit_set_vb(struct vmw_ctx_binding_state *cbs)\n{\n\tconst struct vmw_ctx_bindinfo *loc =\n\t\t&cbs->vertex_buffers[0].bi;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetVertexBuffers body;\n\t} *cmd;\n\tsize_t cmd_size, set_vb_size;\n\tconst struct vmw_resource *ctx = vmw_cbs_context(cbs);\n\n\tvmw_collect_dirty_vbs(cbs, loc, cbs->dirty_vb,\n\t\t\t     SVGA3D_DX_MAX_VERTEXBUFFERS);\n\tif (cbs->bind_cmd_count == 0)\n\t\treturn 0;\n\n\tset_vb_size = cbs->bind_cmd_count*sizeof(SVGA3dVertexBuffer);\n\tcmd_size = sizeof(*cmd) + set_vb_size;\n\tcmd = VMW_CMD_CTX_RESERVE(ctx->dev_priv, cmd_size, ctx->id);\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_VERTEX_BUFFERS;\n\tcmd->header.size = sizeof(cmd->body) + set_vb_size;\n\tcmd->body.startBuffer = cbs->bind_first_slot;\n\n\tmemcpy(&cmd[1], cbs->bind_cmd_buffer, set_vb_size);\n\n\tvmw_cmd_commit(ctx->dev_priv, cmd_size);\n\tbitmap_clear(cbs->dirty_vb,\n\t\t     cbs->bind_first_slot, cbs->bind_cmd_count);\n\n\treturn 0;\n}\n\nstatic int vmw_emit_set_uav(struct vmw_ctx_binding_state *cbs)\n{\n\tconst struct vmw_ctx_bindinfo_view *loc = &cbs->ua_views[0].views[0];\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetUAViews body;\n\t} *cmd;\n\tsize_t cmd_size, view_id_size;\n\tconst struct vmw_resource *ctx = vmw_cbs_context(cbs);\n\n\tvmw_collect_view_ids(cbs, loc, vmw_max_num_uavs(cbs->dev_priv));\n\tview_id_size = cbs->bind_cmd_count*sizeof(uint32);\n\tcmd_size = sizeof(*cmd) + view_id_size;\n\tcmd = VMW_CMD_CTX_RESERVE(ctx->dev_priv, cmd_size, ctx->id);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_UA_VIEWS;\n\tcmd->header.size = sizeof(cmd->body) + view_id_size;\n\n\t \n\tcmd->body.uavSpliceIndex = cbs->ua_views[0].index;\n\n\tmemcpy(&cmd[1], cbs->bind_cmd_buffer, view_id_size);\n\n\tvmw_cmd_commit(ctx->dev_priv, cmd_size);\n\n\treturn 0;\n}\n\nstatic int vmw_emit_set_cs_uav(struct vmw_ctx_binding_state *cbs)\n{\n\tconst struct vmw_ctx_bindinfo_view *loc = &cbs->ua_views[1].views[0];\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetCSUAViews body;\n\t} *cmd;\n\tsize_t cmd_size, view_id_size;\n\tconst struct vmw_resource *ctx = vmw_cbs_context(cbs);\n\n\tvmw_collect_view_ids(cbs, loc, vmw_max_num_uavs(cbs->dev_priv));\n\tview_id_size = cbs->bind_cmd_count*sizeof(uint32);\n\tcmd_size = sizeof(*cmd) + view_id_size;\n\tcmd = VMW_CMD_CTX_RESERVE(ctx->dev_priv, cmd_size, ctx->id);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_CS_UA_VIEWS;\n\tcmd->header.size = sizeof(cmd->body) + view_id_size;\n\n\t \n\tcmd->body.startIndex = cbs->ua_views[1].index;\n\n\tmemcpy(&cmd[1], cbs->bind_cmd_buffer, view_id_size);\n\n\tvmw_cmd_commit(ctx->dev_priv, cmd_size);\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_emit_dirty(struct vmw_ctx_binding_state *cbs)\n{\n\tint ret = 0;\n\tunsigned long hit = 0;\n\n\twhile ((hit = find_next_bit(&cbs->dirty, VMW_BINDING_NUM_BITS, hit))\n\t      < VMW_BINDING_NUM_BITS) {\n\n\t\tswitch (hit) {\n\t\tcase VMW_BINDING_RT_BIT:\n\t\t\tret = vmw_emit_set_rt(cbs);\n\t\t\tbreak;\n\t\tcase VMW_BINDING_PS_BIT:\n\t\t\tret = vmw_binding_emit_dirty_ps(cbs);\n\t\t\tbreak;\n\t\tcase VMW_BINDING_SO_T_BIT:\n\t\t\tret = vmw_emit_set_so_target(cbs);\n\t\t\tbreak;\n\t\tcase VMW_BINDING_VB_BIT:\n\t\t\tret = vmw_emit_set_vb(cbs);\n\t\t\tbreak;\n\t\tcase VMW_BINDING_UAV_BIT:\n\t\t\tret = vmw_emit_set_uav(cbs);\n\t\t\tbreak;\n\t\tcase VMW_BINDING_CS_UAV_BIT:\n\t\t\tret = vmw_emit_set_cs_uav(cbs);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t__clear_bit(hit, &cbs->dirty);\n\t\thit++;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_sr(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_view *biv =\n\t\tcontainer_of(bi, struct vmw_ctx_bindinfo_view, bi);\n\tstruct vmw_ctx_binding_state *cbs =\n\t\tvmw_context_binding_state(bi->ctx);\n\n\t__set_bit(biv->slot, cbs->per_shader[biv->shader_slot].dirty_sr);\n\t__set_bit(VMW_BINDING_PS_SR_BIT,\n\t\t  &cbs->per_shader[biv->shader_slot].dirty);\n\t__set_bit(VMW_BINDING_PS_BIT, &cbs->dirty);\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_dx_rt(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_binding_state *cbs =\n\t\tvmw_context_binding_state(bi->ctx);\n\n\t__set_bit(VMW_BINDING_RT_BIT, &cbs->dirty);\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_so_target(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_binding_state *cbs =\n\t\tvmw_context_binding_state(bi->ctx);\n\n\t__set_bit(VMW_BINDING_SO_T_BIT, &cbs->dirty);\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_vb(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_vb *bivb =\n\t\tcontainer_of(bi, struct vmw_ctx_bindinfo_vb, bi);\n\tstruct vmw_ctx_binding_state *cbs =\n\t\tvmw_context_binding_state(bi->ctx);\n\n\t__set_bit(bivb->slot, cbs->dirty_vb);\n\t__set_bit(VMW_BINDING_VB_BIT, &cbs->dirty);\n\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_ib(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_ib *binding =\n\t\tcontainer_of(bi, typeof(*binding), bi);\n\tstruct vmw_private *dev_priv = bi->ctx->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetIndexBuffer body;\n\t} *cmd;\n\n\tcmd = VMW_CMD_CTX_RESERVE(dev_priv, sizeof(*cmd), bi->ctx->id);\n\tif (unlikely(cmd == NULL))\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_INDEX_BUFFER;\n\tcmd->header.size = sizeof(cmd->body);\n\tif (rebind) {\n\t\tcmd->body.sid = bi->res->id;\n\t\tcmd->body.format = binding->format;\n\t\tcmd->body.offset = binding->offset;\n\t} else {\n\t\tcmd->body.sid = SVGA3D_INVALID_ID;\n\t\tcmd->body.format = 0;\n\t\tcmd->body.offset = 0;\n\t}\n\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\n\treturn 0;\n}\n\nstatic int vmw_binding_scrub_uav(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_binding_state *cbs = vmw_context_binding_state(bi->ctx);\n\n\t__set_bit(VMW_BINDING_UAV_BIT, &cbs->dirty);\n\treturn 0;\n}\n\nstatic int vmw_binding_scrub_cs_uav(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_binding_state *cbs = vmw_context_binding_state(bi->ctx);\n\n\t__set_bit(VMW_BINDING_CS_UAV_BIT, &cbs->dirty);\n\treturn 0;\n}\n\n \nstatic int vmw_binding_scrub_so(struct vmw_ctx_bindinfo *bi, bool rebind)\n{\n\tstruct vmw_ctx_bindinfo_so *binding =\n\t\tcontainer_of(bi, typeof(*binding), bi);\n\tstruct vmw_private *dev_priv = bi->ctx->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXSetStreamOutput body;\n\t} *cmd;\n\n\tcmd = VMW_CMD_CTX_RESERVE(dev_priv, sizeof(*cmd), bi->ctx->id);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_DX_SET_STREAMOUTPUT;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.soid = rebind ? bi->res->id : SVGA3D_INVALID_ID;\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\n\treturn 0;\n}\n\n \nstruct vmw_ctx_binding_state *\nvmw_binding_state_alloc(struct vmw_private *dev_priv)\n{\n\tstruct vmw_ctx_binding_state *cbs;\n\n\tcbs = vzalloc(sizeof(*cbs));\n\tif (!cbs) {\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tcbs->dev_priv = dev_priv;\n\tINIT_LIST_HEAD(&cbs->list);\n\n\treturn cbs;\n}\n\n \nvoid vmw_binding_state_free(struct vmw_ctx_binding_state *cbs)\n{\n\tvfree(cbs);\n}\n\n \nstruct list_head *vmw_binding_state_list(struct vmw_ctx_binding_state *cbs)\n{\n\treturn &cbs->list;\n}\n\n \nvoid vmw_binding_state_reset(struct vmw_ctx_binding_state *cbs)\n{\n\tstruct vmw_ctx_bindinfo *entry, *next;\n\n\tlist_for_each_entry_safe(entry, next, &cbs->list, ctx_list)\n\t\tvmw_binding_drop(entry);\n}\n\n \nu32 vmw_binding_dirtying(enum vmw_ctx_binding_type binding_type)\n{\n\tstatic u32 is_binding_dirtying[vmw_ctx_binding_max] = {\n\t\t[vmw_ctx_binding_rt] = VMW_RES_DIRTY_SET,\n\t\t[vmw_ctx_binding_dx_rt] = VMW_RES_DIRTY_SET,\n\t\t[vmw_ctx_binding_ds] = VMW_RES_DIRTY_SET,\n\t\t[vmw_ctx_binding_so_target] = VMW_RES_DIRTY_SET,\n\t\t[vmw_ctx_binding_uav] = VMW_RES_DIRTY_SET,\n\t\t[vmw_ctx_binding_cs_uav] = VMW_RES_DIRTY_SET,\n\t};\n\n\t \n\tBUILD_BUG_ON(vmw_ctx_binding_max != 14);\n\treturn is_binding_dirtying[binding_type];\n}\n\n \nstatic void vmw_binding_build_asserts(void)\n{\n\tBUILD_BUG_ON(SVGA3D_NUM_SHADERTYPE_DX10 != 3);\n\tBUILD_BUG_ON(SVGA3D_DX_MAX_RENDER_TARGETS > SVGA3D_RT_MAX);\n\tBUILD_BUG_ON(sizeof(uint32) != sizeof(u32));\n\n\t \n\tBUILD_BUG_ON(VMW_MAX_VIEW_BINDINGS < SVGA3D_RT_MAX);\n\tBUILD_BUG_ON(VMW_MAX_VIEW_BINDINGS < SVGA3D_DX_MAX_SRVIEWS);\n\tBUILD_BUG_ON(VMW_MAX_VIEW_BINDINGS < SVGA3D_DX_MAX_CONSTBUFFERS);\n\n\t \n\tBUILD_BUG_ON(SVGA3D_DX_MAX_SOTARGETS*sizeof(SVGA3dSoTarget) >\n\t\t     VMW_MAX_VIEW_BINDINGS*sizeof(u32));\n\tBUILD_BUG_ON(SVGA3D_DX_MAX_VERTEXBUFFERS*sizeof(SVGA3dVertexBuffer) >\n\t\t     VMW_MAX_VIEW_BINDINGS*sizeof(u32));\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}