{
  "module_name": "vmwgfx_drv.c",
  "hash_id": "8135db71ea0b69099b552ac0a56eb1eca5378db48969d348e2983b7499dcb9a0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/vmwgfx_drv.c",
  "human_readable_source": "\n \n\n\n#include \"vmwgfx_drv.h\"\n\n#include \"vmwgfx_bo.h\"\n#include \"vmwgfx_binding.h\"\n#include \"vmwgfx_devcaps.h\"\n#include \"vmwgfx_mksstat.h\"\n#include \"ttm_object.h\"\n\n#include <drm/drm_aperture.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_fbdev_generic.h>\n#include <drm/drm_gem_ttm_helper.h>\n#include <drm/drm_ioctl.h>\n#include <drm/drm_module.h>\n#include <drm/drm_sysfs.h>\n#include <drm/ttm/ttm_range_manager.h>\n#include <drm/ttm/ttm_placement.h>\n#include <generated/utsrelease.h>\n\n#ifdef CONFIG_X86\n#include <asm/hypervisor.h>\n#endif\n#include <linux/cc_platform.h>\n#include <linux/dma-mapping.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/version.h>\n\n#define VMWGFX_DRIVER_DESC \"Linux drm driver for VMware graphics devices\"\n\n \n\n#define DRM_IOCTL_VMW_GET_PARAM\t\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_GET_PARAM,\t\t\\\n\t\t struct drm_vmw_getparam_arg)\n#define DRM_IOCTL_VMW_ALLOC_DMABUF\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_ALLOC_DMABUF,\t\\\n\t\tunion drm_vmw_alloc_dmabuf_arg)\n#define DRM_IOCTL_VMW_UNREF_DMABUF\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UNREF_DMABUF,\t\\\n\t\tstruct drm_vmw_unref_dmabuf_arg)\n#define DRM_IOCTL_VMW_CURSOR_BYPASS\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_CURSOR_BYPASS,\t\\\n\t\t struct drm_vmw_cursor_bypass_arg)\n\n#define DRM_IOCTL_VMW_CONTROL_STREAM\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_CONTROL_STREAM,\t\\\n\t\t struct drm_vmw_control_stream_arg)\n#define DRM_IOCTL_VMW_CLAIM_STREAM\t\t\t\t\\\n\tDRM_IOR(DRM_COMMAND_BASE + DRM_VMW_CLAIM_STREAM,\t\\\n\t\t struct drm_vmw_stream_arg)\n#define DRM_IOCTL_VMW_UNREF_STREAM\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UNREF_STREAM,\t\\\n\t\t struct drm_vmw_stream_arg)\n\n#define DRM_IOCTL_VMW_CREATE_CONTEXT\t\t\t\t\\\n\tDRM_IOR(DRM_COMMAND_BASE + DRM_VMW_CREATE_CONTEXT,\t\\\n\t\tstruct drm_vmw_context_arg)\n#define DRM_IOCTL_VMW_UNREF_CONTEXT\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UNREF_CONTEXT,\t\\\n\t\tstruct drm_vmw_context_arg)\n#define DRM_IOCTL_VMW_CREATE_SURFACE\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_CREATE_SURFACE,\t\\\n\t\t union drm_vmw_surface_create_arg)\n#define DRM_IOCTL_VMW_UNREF_SURFACE\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UNREF_SURFACE,\t\\\n\t\t struct drm_vmw_surface_arg)\n#define DRM_IOCTL_VMW_REF_SURFACE\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_REF_SURFACE,\t\\\n\t\t union drm_vmw_surface_reference_arg)\n#define DRM_IOCTL_VMW_EXECBUF\t\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_EXECBUF,\t\t\\\n\t\tstruct drm_vmw_execbuf_arg)\n#define DRM_IOCTL_VMW_GET_3D_CAP\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_GET_3D_CAP,\t\t\\\n\t\t struct drm_vmw_get_3d_cap_arg)\n#define DRM_IOCTL_VMW_FENCE_WAIT\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_FENCE_WAIT,\t\t\\\n\t\t struct drm_vmw_fence_wait_arg)\n#define DRM_IOCTL_VMW_FENCE_SIGNALED\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_FENCE_SIGNALED,\t\\\n\t\t struct drm_vmw_fence_signaled_arg)\n#define DRM_IOCTL_VMW_FENCE_UNREF\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_FENCE_UNREF,\t\t\\\n\t\t struct drm_vmw_fence_arg)\n#define DRM_IOCTL_VMW_FENCE_EVENT\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_FENCE_EVENT,\t\t\\\n\t\t struct drm_vmw_fence_event_arg)\n#define DRM_IOCTL_VMW_PRESENT\t\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_PRESENT,\t\t\\\n\t\t struct drm_vmw_present_arg)\n#define DRM_IOCTL_VMW_PRESENT_READBACK\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_PRESENT_READBACK,\t\\\n\t\t struct drm_vmw_present_readback_arg)\n#define DRM_IOCTL_VMW_UPDATE_LAYOUT\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UPDATE_LAYOUT,\t\\\n\t\t struct drm_vmw_update_layout_arg)\n#define DRM_IOCTL_VMW_CREATE_SHADER\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_CREATE_SHADER,\t\\\n\t\t struct drm_vmw_shader_create_arg)\n#define DRM_IOCTL_VMW_UNREF_SHADER\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_UNREF_SHADER,\t\\\n\t\t struct drm_vmw_shader_arg)\n#define DRM_IOCTL_VMW_GB_SURFACE_CREATE\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_GB_SURFACE_CREATE,\t\\\n\t\t union drm_vmw_gb_surface_create_arg)\n#define DRM_IOCTL_VMW_GB_SURFACE_REF\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_GB_SURFACE_REF,\t\\\n\t\t union drm_vmw_gb_surface_reference_arg)\n#define DRM_IOCTL_VMW_SYNCCPU\t\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_SYNCCPU,\t\t\\\n\t\t struct drm_vmw_synccpu_arg)\n#define DRM_IOCTL_VMW_CREATE_EXTENDED_CONTEXT\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_CREATE_EXTENDED_CONTEXT,\t\\\n\t\tstruct drm_vmw_context_arg)\n#define DRM_IOCTL_VMW_GB_SURFACE_CREATE_EXT\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_GB_SURFACE_CREATE_EXT,\t\\\n\t\tunion drm_vmw_gb_surface_create_ext_arg)\n#define DRM_IOCTL_VMW_GB_SURFACE_REF_EXT\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_GB_SURFACE_REF_EXT,\t\t\\\n\t\tunion drm_vmw_gb_surface_reference_ext_arg)\n#define DRM_IOCTL_VMW_MSG\t\t\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_MSG,\t\t\t\\\n\t\tstruct drm_vmw_msg_arg)\n#define DRM_IOCTL_VMW_MKSSTAT_RESET\t\t\t\t\\\n\tDRM_IO(DRM_COMMAND_BASE + DRM_VMW_MKSSTAT_RESET)\n#define DRM_IOCTL_VMW_MKSSTAT_ADD\t\t\t\t\\\n\tDRM_IOWR(DRM_COMMAND_BASE + DRM_VMW_MKSSTAT_ADD,\t\\\n\t\tstruct drm_vmw_mksstat_add_arg)\n#define DRM_IOCTL_VMW_MKSSTAT_REMOVE\t\t\t\t\\\n\tDRM_IOW(DRM_COMMAND_BASE + DRM_VMW_MKSSTAT_REMOVE,\t\\\n\t\tstruct drm_vmw_mksstat_remove_arg)\n\n \n\nstatic const struct drm_ioctl_desc vmw_ioctls[] = {\n\tDRM_IOCTL_DEF_DRV(VMW_GET_PARAM, vmw_getparam_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_ALLOC_DMABUF, vmw_gem_object_create_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_UNREF_DMABUF, vmw_bo_unref_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_CURSOR_BYPASS,\n\t\t\t  vmw_kms_cursor_bypass_ioctl,\n\t\t\t  DRM_MASTER),\n\n\tDRM_IOCTL_DEF_DRV(VMW_CONTROL_STREAM, vmw_overlay_ioctl,\n\t\t\t  DRM_MASTER),\n\tDRM_IOCTL_DEF_DRV(VMW_CLAIM_STREAM, vmw_stream_claim_ioctl,\n\t\t\t  DRM_MASTER),\n\tDRM_IOCTL_DEF_DRV(VMW_UNREF_STREAM, vmw_stream_unref_ioctl,\n\t\t\t  DRM_MASTER),\n\n\tDRM_IOCTL_DEF_DRV(VMW_CREATE_CONTEXT, vmw_context_define_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_UNREF_CONTEXT, vmw_context_destroy_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_CREATE_SURFACE, vmw_surface_define_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_UNREF_SURFACE, vmw_surface_destroy_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_REF_SURFACE, vmw_surface_reference_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_EXECBUF, vmw_execbuf_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_FENCE_WAIT, vmw_fence_obj_wait_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_FENCE_SIGNALED,\n\t\t\t  vmw_fence_obj_signaled_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_FENCE_UNREF, vmw_fence_obj_unref_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_FENCE_EVENT, vmw_fence_event_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_GET_3D_CAP, vmw_get_cap_3d_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\n\t \n\tDRM_IOCTL_DEF_DRV(VMW_PRESENT, vmw_present_ioctl,\n\t\t\t  DRM_MASTER | DRM_AUTH),\n\tDRM_IOCTL_DEF_DRV(VMW_PRESENT_READBACK,\n\t\t\t  vmw_present_readback_ioctl,\n\t\t\t  DRM_MASTER | DRM_AUTH),\n\t \n\tDRM_IOCTL_DEF_DRV(VMW_UPDATE_LAYOUT,\n\t\t\t  vmw_kms_update_layout_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_CREATE_SHADER,\n\t\t\t  vmw_shader_define_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_UNREF_SHADER,\n\t\t\t  vmw_shader_destroy_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_GB_SURFACE_CREATE,\n\t\t\t  vmw_gb_surface_define_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_GB_SURFACE_REF,\n\t\t\t  vmw_gb_surface_reference_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_SYNCCPU,\n\t\t\t  vmw_user_bo_synccpu_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_CREATE_EXTENDED_CONTEXT,\n\t\t\t  vmw_extended_context_define_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_GB_SURFACE_CREATE_EXT,\n\t\t\t  vmw_gb_surface_define_ext_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_GB_SURFACE_REF_EXT,\n\t\t\t  vmw_gb_surface_reference_ext_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_MSG,\n\t\t\t  vmw_msg_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_MKSSTAT_RESET,\n\t\t\t  vmw_mksstat_reset_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_MKSSTAT_ADD,\n\t\t\t  vmw_mksstat_add_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(VMW_MKSSTAT_REMOVE,\n\t\t\t  vmw_mksstat_remove_ioctl,\n\t\t\t  DRM_RENDER_ALLOW),\n};\n\nstatic const struct pci_device_id vmw_pci_id_list[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_VMWARE, VMWGFX_PCI_ID_SVGA2) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_VMWARE, VMWGFX_PCI_ID_SVGA3) },\n\t{ }\n};\nMODULE_DEVICE_TABLE(pci, vmw_pci_id_list);\n\nstatic int vmw_restrict_iommu;\nstatic int vmw_force_coherent;\nstatic int vmw_restrict_dma_mask;\nstatic int vmw_assume_16bpp;\n\nstatic int vmw_probe(struct pci_dev *, const struct pci_device_id *);\nstatic int vmwgfx_pm_notifier(struct notifier_block *nb, unsigned long val,\n\t\t\t      void *ptr);\n\nMODULE_PARM_DESC(restrict_iommu, \"Try to limit IOMMU usage for TTM pages\");\nmodule_param_named(restrict_iommu, vmw_restrict_iommu, int, 0600);\nMODULE_PARM_DESC(force_coherent, \"Force coherent TTM pages\");\nmodule_param_named(force_coherent, vmw_force_coherent, int, 0600);\nMODULE_PARM_DESC(restrict_dma_mask, \"Restrict DMA mask to 44 bits with IOMMU\");\nmodule_param_named(restrict_dma_mask, vmw_restrict_dma_mask, int, 0600);\nMODULE_PARM_DESC(assume_16bpp, \"Assume 16-bpp when filtering modes\");\nmodule_param_named(assume_16bpp, vmw_assume_16bpp, int, 0600);\n\n\nstruct bitmap_name {\n\tuint32 value;\n\tconst char *name;\n};\n\nstatic const struct bitmap_name cap1_names[] = {\n\t{ SVGA_CAP_RECT_COPY, \"rect copy\" },\n\t{ SVGA_CAP_CURSOR, \"cursor\" },\n\t{ SVGA_CAP_CURSOR_BYPASS, \"cursor bypass\" },\n\t{ SVGA_CAP_CURSOR_BYPASS_2, \"cursor bypass 2\" },\n\t{ SVGA_CAP_8BIT_EMULATION, \"8bit emulation\" },\n\t{ SVGA_CAP_ALPHA_CURSOR, \"alpha cursor\" },\n\t{ SVGA_CAP_3D, \"3D\" },\n\t{ SVGA_CAP_EXTENDED_FIFO, \"extended fifo\" },\n\t{ SVGA_CAP_MULTIMON, \"multimon\" },\n\t{ SVGA_CAP_PITCHLOCK, \"pitchlock\" },\n\t{ SVGA_CAP_IRQMASK, \"irq mask\" },\n\t{ SVGA_CAP_DISPLAY_TOPOLOGY, \"display topology\" },\n\t{ SVGA_CAP_GMR, \"gmr\" },\n\t{ SVGA_CAP_TRACES, \"traces\" },\n\t{ SVGA_CAP_GMR2, \"gmr2\" },\n\t{ SVGA_CAP_SCREEN_OBJECT_2, \"screen object 2\" },\n\t{ SVGA_CAP_COMMAND_BUFFERS, \"command buffers\" },\n\t{ SVGA_CAP_CMD_BUFFERS_2, \"command buffers 2\" },\n\t{ SVGA_CAP_GBOBJECTS, \"gbobject\" },\n\t{ SVGA_CAP_DX, \"dx\" },\n\t{ SVGA_CAP_HP_CMD_QUEUE, \"hp cmd queue\" },\n\t{ SVGA_CAP_NO_BB_RESTRICTION, \"no bb restriction\" },\n\t{ SVGA_CAP_CAP2_REGISTER, \"cap2 register\" },\n};\n\n\nstatic const struct bitmap_name cap2_names[] = {\n\t{ SVGA_CAP2_GROW_OTABLE, \"grow otable\" },\n\t{ SVGA_CAP2_INTRA_SURFACE_COPY, \"intra surface copy\" },\n\t{ SVGA_CAP2_DX2, \"dx2\" },\n\t{ SVGA_CAP2_GB_MEMSIZE_2, \"gb memsize 2\" },\n\t{ SVGA_CAP2_SCREENDMA_REG, \"screendma reg\" },\n\t{ SVGA_CAP2_OTABLE_PTDEPTH_2, \"otable ptdepth2\" },\n\t{ SVGA_CAP2_NON_MS_TO_MS_STRETCHBLT, \"non ms to ms stretchblt\" },\n\t{ SVGA_CAP2_CURSOR_MOB, \"cursor mob\" },\n\t{ SVGA_CAP2_MSHINT, \"mshint\" },\n\t{ SVGA_CAP2_CB_MAX_SIZE_4MB, \"cb max size 4mb\" },\n\t{ SVGA_CAP2_DX3, \"dx3\" },\n\t{ SVGA_CAP2_FRAME_TYPE, \"frame type\" },\n\t{ SVGA_CAP2_COTABLE_COPY, \"cotable copy\" },\n\t{ SVGA_CAP2_TRACE_FULL_FB, \"trace full fb\" },\n\t{ SVGA_CAP2_EXTRA_REGS, \"extra regs\" },\n\t{ SVGA_CAP2_LO_STAGING, \"lo staging\" },\n};\n\nstatic void vmw_print_bitmap(struct drm_device *drm,\n\t\t\t     const char *prefix, uint32_t bitmap,\n\t\t\t     const struct bitmap_name *bnames,\n\t\t\t     uint32_t num_names)\n{\n\tchar buf[512];\n\tuint32_t i;\n\tuint32_t offset = 0;\n\tfor (i = 0; i < num_names; ++i) {\n\t\tif ((bitmap & bnames[i].value) != 0) {\n\t\t\toffset += snprintf(buf + offset,\n\t\t\t\t\t   ARRAY_SIZE(buf) - offset,\n\t\t\t\t\t   \"%s, \", bnames[i].name);\n\t\t\tbitmap &= ~bnames[i].value;\n\t\t}\n\t}\n\n\tdrm_info(drm, \"%s: %s\\n\", prefix, buf);\n\tif (bitmap != 0)\n\t\tdrm_dbg(drm, \"%s: unknown enums: %x\\n\", prefix, bitmap);\n}\n\n\nstatic void vmw_print_sm_type(struct vmw_private *dev_priv)\n{\n\tstatic const char *names[] = {\n\t\t[VMW_SM_LEGACY] = \"Legacy\",\n\t\t[VMW_SM_4] = \"SM4\",\n\t\t[VMW_SM_4_1] = \"SM4_1\",\n\t\t[VMW_SM_5] = \"SM_5\",\n\t\t[VMW_SM_5_1X] = \"SM_5_1X\",\n\t\t[VMW_SM_MAX] = \"Invalid\"\n\t};\n\tBUILD_BUG_ON(ARRAY_SIZE(names) != (VMW_SM_MAX + 1));\n\tdrm_info(&dev_priv->drm, \"Available shader model: %s.\\n\",\n\t\t names[dev_priv->sm_type]);\n}\n\n \nstatic int vmw_dummy_query_bo_create(struct vmw_private *dev_priv)\n{\n\tint ret;\n\tstruct vmw_bo *vbo;\n\tstruct ttm_bo_kmap_obj map;\n\tvolatile SVGA3dQueryResult *result;\n\tbool dummy;\n\tstruct vmw_bo_params bo_params = {\n\t\t.domain = VMW_BO_DOMAIN_SYS,\n\t\t.busy_domain = VMW_BO_DOMAIN_SYS,\n\t\t.bo_type = ttm_bo_type_kernel,\n\t\t.size = PAGE_SIZE,\n\t\t.pin = true\n\t};\n\n\t \n\tret = vmw_bo_create(dev_priv, &bo_params, &vbo);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_bo_reserve(&vbo->tbo, false, true, NULL);\n\tBUG_ON(ret != 0);\n\tvmw_bo_pin_reserved(vbo, true);\n\n\tret = ttm_bo_kmap(&vbo->tbo, 0, 1, &map);\n\tif (likely(ret == 0)) {\n\t\tresult = ttm_kmap_obj_virtual(&map, &dummy);\n\t\tresult->totalSize = sizeof(*result);\n\t\tresult->state = SVGA3D_QUERYSTATE_PENDING;\n\t\tresult->result32 = 0xff;\n\t\tttm_bo_kunmap(&map);\n\t}\n\tvmw_bo_pin_reserved(vbo, false);\n\tttm_bo_unreserve(&vbo->tbo);\n\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Dummy query buffer map failed.\\n\");\n\t\tvmw_bo_unreference(&vbo);\n\t} else\n\t\tdev_priv->dummy_query_bo = vbo;\n\n\treturn ret;\n}\n\nstatic int vmw_device_init(struct vmw_private *dev_priv)\n{\n\tbool uses_fb_traces = false;\n\n\tdev_priv->enable_state = vmw_read(dev_priv, SVGA_REG_ENABLE);\n\tdev_priv->config_done_state = vmw_read(dev_priv, SVGA_REG_CONFIG_DONE);\n\tdev_priv->traces_state = vmw_read(dev_priv, SVGA_REG_TRACES);\n\n\tvmw_write(dev_priv, SVGA_REG_ENABLE, SVGA_REG_ENABLE_ENABLE |\n\t\t  SVGA_REG_ENABLE_HIDE);\n\n\tuses_fb_traces = !vmw_cmd_supported(dev_priv) &&\n\t\t\t (dev_priv->capabilities & SVGA_CAP_TRACES) != 0;\n\n\tvmw_write(dev_priv, SVGA_REG_TRACES, uses_fb_traces);\n\tdev_priv->fifo = vmw_fifo_create(dev_priv);\n\tif (IS_ERR(dev_priv->fifo)) {\n\t\tint err = PTR_ERR(dev_priv->fifo);\n\t\tdev_priv->fifo = NULL;\n\t\treturn err;\n\t} else if (!dev_priv->fifo) {\n\t\tvmw_write(dev_priv, SVGA_REG_CONFIG_DONE, 1);\n\t}\n\n\tdev_priv->last_read_seqno = vmw_fence_read(dev_priv);\n\tatomic_set(&dev_priv->marker_seq, dev_priv->last_read_seqno);\n\treturn 0;\n}\n\nstatic void vmw_device_fini(struct vmw_private *vmw)\n{\n\t \n\tvmw_write(vmw, SVGA_REG_SYNC, SVGA_SYNC_GENERIC);\n\twhile (vmw_read(vmw, SVGA_REG_BUSY) != 0)\n\t\t;\n\n\tvmw->last_read_seqno = vmw_fence_read(vmw);\n\n\tvmw_write(vmw, SVGA_REG_CONFIG_DONE,\n\t\t  vmw->config_done_state);\n\tvmw_write(vmw, SVGA_REG_ENABLE,\n\t\t  vmw->enable_state);\n\tvmw_write(vmw, SVGA_REG_TRACES,\n\t\t  vmw->traces_state);\n\n\tvmw_fifo_destroy(vmw);\n}\n\n \nstatic int vmw_request_device_late(struct vmw_private *dev_priv)\n{\n\tint ret;\n\n\tif (dev_priv->has_mob) {\n\t\tret = vmw_otables_setup(dev_priv);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tDRM_ERROR(\"Unable to initialize \"\n\t\t\t\t  \"guest Memory OBjects.\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (dev_priv->cman) {\n\t\tret = vmw_cmdbuf_set_pool_size(dev_priv->cman, 256*4096);\n\t\tif (ret) {\n\t\t\tstruct vmw_cmdbuf_man *man = dev_priv->cman;\n\n\t\t\tdev_priv->cman = NULL;\n\t\t\tvmw_cmdbuf_man_destroy(man);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int vmw_request_device(struct vmw_private *dev_priv)\n{\n\tint ret;\n\n\tret = vmw_device_init(dev_priv);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Unable to initialize the device.\\n\");\n\t\treturn ret;\n\t}\n\tvmw_fence_fifo_up(dev_priv->fman);\n\tdev_priv->cman = vmw_cmdbuf_man_create(dev_priv);\n\tif (IS_ERR(dev_priv->cman)) {\n\t\tdev_priv->cman = NULL;\n\t\tdev_priv->sm_type = VMW_SM_LEGACY;\n\t}\n\n\tret = vmw_request_device_late(dev_priv);\n\tif (ret)\n\t\tgoto out_no_mob;\n\n\tret = vmw_dummy_query_bo_create(dev_priv);\n\tif (unlikely(ret != 0))\n\t\tgoto out_no_query_bo;\n\n\treturn 0;\n\nout_no_query_bo:\n\tif (dev_priv->cman)\n\t\tvmw_cmdbuf_remove_pool(dev_priv->cman);\n\tif (dev_priv->has_mob) {\n\t\tstruct ttm_resource_manager *man;\n\n\t\tman = ttm_manager_type(&dev_priv->bdev, VMW_PL_MOB);\n\t\tttm_resource_manager_evict_all(&dev_priv->bdev, man);\n\t\tvmw_otables_takedown(dev_priv);\n\t}\n\tif (dev_priv->cman)\n\t\tvmw_cmdbuf_man_destroy(dev_priv->cman);\nout_no_mob:\n\tvmw_fence_fifo_down(dev_priv->fman);\n\tvmw_device_fini(dev_priv);\n\treturn ret;\n}\n\n \nstatic void vmw_release_device_early(struct vmw_private *dev_priv)\n{\n\t \n\n\tBUG_ON(dev_priv->pinned_bo != NULL);\n\n\tvmw_bo_unreference(&dev_priv->dummy_query_bo);\n\tif (dev_priv->cman)\n\t\tvmw_cmdbuf_remove_pool(dev_priv->cman);\n\n\tif (dev_priv->has_mob) {\n\t\tstruct ttm_resource_manager *man;\n\n\t\tman = ttm_manager_type(&dev_priv->bdev, VMW_PL_MOB);\n\t\tttm_resource_manager_evict_all(&dev_priv->bdev, man);\n\t\tvmw_otables_takedown(dev_priv);\n\t}\n}\n\n \nstatic void vmw_release_device_late(struct vmw_private *dev_priv)\n{\n\tvmw_fence_fifo_down(dev_priv->fman);\n\tif (dev_priv->cman)\n\t\tvmw_cmdbuf_man_destroy(dev_priv->cman);\n\n\tvmw_device_fini(dev_priv);\n}\n\n \nstatic void vmw_get_initial_size(struct vmw_private *dev_priv)\n{\n\tuint32_t width;\n\tuint32_t height;\n\n\twidth = vmw_read(dev_priv, SVGA_REG_WIDTH);\n\theight = vmw_read(dev_priv, SVGA_REG_HEIGHT);\n\n\twidth = max_t(uint32_t, width, VMWGFX_MIN_INITIAL_WIDTH);\n\theight = max_t(uint32_t, height, VMWGFX_MIN_INITIAL_HEIGHT);\n\n\tif (width > dev_priv->fb_max_width ||\n\t    height > dev_priv->fb_max_height) {\n\n\t\t \n\n\t\twidth  = VMWGFX_MIN_INITIAL_WIDTH;\n\t\theight = VMWGFX_MIN_INITIAL_HEIGHT;\n\t}\n\n\tdev_priv->initial_width = width;\n\tdev_priv->initial_height = height;\n}\n\n \nstatic int vmw_dma_select_mode(struct vmw_private *dev_priv)\n{\n\tstatic const char *names[vmw_dma_map_max] = {\n\t\t[vmw_dma_alloc_coherent] = \"Using coherent TTM pages.\",\n\t\t[vmw_dma_map_populate] = \"Caching DMA mappings.\",\n\t\t[vmw_dma_map_bind] = \"Giving up DMA mappings early.\"};\n\n\t \n\tif (cc_platform_has(CC_ATTR_MEM_ENCRYPT))\n\t\treturn -EINVAL;\n\n\tif (vmw_force_coherent)\n\t\tdev_priv->map_mode = vmw_dma_alloc_coherent;\n\telse if (vmw_restrict_iommu)\n\t\tdev_priv->map_mode = vmw_dma_map_bind;\n\telse\n\t\tdev_priv->map_mode = vmw_dma_map_populate;\n\n\tdrm_info(&dev_priv->drm,\n\t\t \"DMA map mode: %s\\n\", names[dev_priv->map_mode]);\n\treturn 0;\n}\n\n \nstatic int vmw_dma_masks(struct vmw_private *dev_priv)\n{\n\tstruct drm_device *dev = &dev_priv->drm;\n\tint ret = 0;\n\n\tret = dma_set_mask_and_coherent(dev->dev, DMA_BIT_MASK(64));\n\tif (sizeof(unsigned long) == 4 || vmw_restrict_dma_mask) {\n\t\tdrm_info(&dev_priv->drm,\n\t\t\t \"Restricting DMA addresses to 44 bits.\\n\");\n\t\treturn dma_set_mask_and_coherent(dev->dev, DMA_BIT_MASK(44));\n\t}\n\n\treturn ret;\n}\n\nstatic int vmw_vram_manager_init(struct vmw_private *dev_priv)\n{\n\tint ret;\n\tret = ttm_range_man_init(&dev_priv->bdev, TTM_PL_VRAM, false,\n\t\t\t\t dev_priv->vram_size >> PAGE_SHIFT);\n\tttm_resource_manager_set_used(ttm_manager_type(&dev_priv->bdev, TTM_PL_VRAM), false);\n\treturn ret;\n}\n\nstatic void vmw_vram_manager_fini(struct vmw_private *dev_priv)\n{\n\tttm_range_man_fini(&dev_priv->bdev, TTM_PL_VRAM);\n}\n\nstatic int vmw_setup_pci_resources(struct vmw_private *dev,\n\t\t\t\t   u32 pci_id)\n{\n\tresource_size_t rmmio_start;\n\tresource_size_t rmmio_size;\n\tresource_size_t fifo_start;\n\tresource_size_t fifo_size;\n\tint ret;\n\tstruct pci_dev *pdev = to_pci_dev(dev->drm.dev);\n\n\tpci_set_master(pdev);\n\n\tret = pci_request_regions(pdev, \"vmwgfx probe\");\n\tif (ret)\n\t\treturn ret;\n\n\tdev->pci_id = pci_id;\n\tif (pci_id == VMWGFX_PCI_ID_SVGA3) {\n\t\trmmio_start = pci_resource_start(pdev, 0);\n\t\trmmio_size = pci_resource_len(pdev, 0);\n\t\tdev->vram_start = pci_resource_start(pdev, 2);\n\t\tdev->vram_size = pci_resource_len(pdev, 2);\n\n\t\tdrm_info(&dev->drm,\n\t\t\t\"Register MMIO at 0x%pa size is %llu kiB\\n\",\n\t\t\t &rmmio_start, (uint64_t)rmmio_size / 1024);\n\t\tdev->rmmio = devm_ioremap(dev->drm.dev,\n\t\t\t\t\t  rmmio_start,\n\t\t\t\t\t  rmmio_size);\n\t\tif (!dev->rmmio) {\n\t\t\tdrm_err(&dev->drm,\n\t\t\t\t\"Failed mapping registers mmio memory.\\n\");\n\t\t\tpci_release_regions(pdev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t} else if (pci_id == VMWGFX_PCI_ID_SVGA2) {\n\t\tdev->io_start = pci_resource_start(pdev, 0);\n\t\tdev->vram_start = pci_resource_start(pdev, 1);\n\t\tdev->vram_size = pci_resource_len(pdev, 1);\n\t\tfifo_start = pci_resource_start(pdev, 2);\n\t\tfifo_size = pci_resource_len(pdev, 2);\n\n\t\tdrm_info(&dev->drm,\n\t\t\t \"FIFO at %pa size is %llu kiB\\n\",\n\t\t\t &fifo_start, (uint64_t)fifo_size / 1024);\n\t\tdev->fifo_mem = devm_memremap(dev->drm.dev,\n\t\t\t\t\t      fifo_start,\n\t\t\t\t\t      fifo_size,\n\t\t\t\t\t      MEMREMAP_WB);\n\n\t\tif (IS_ERR(dev->fifo_mem)) {\n\t\t\tdrm_err(&dev->drm,\n\t\t\t\t  \"Failed mapping FIFO memory.\\n\");\n\t\t\tpci_release_regions(pdev);\n\t\t\treturn PTR_ERR(dev->fifo_mem);\n\t\t}\n\t} else {\n\t\tpci_release_regions(pdev);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tdrm_info(&dev->drm,\n\t\t \"VRAM at %pa size is %llu kiB\\n\",\n\t\t &dev->vram_start, (uint64_t)dev->vram_size / 1024);\n\n\treturn 0;\n}\n\nstatic int vmw_detect_version(struct vmw_private *dev)\n{\n\tuint32_t svga_id;\n\n\tvmw_write(dev, SVGA_REG_ID, vmw_is_svga_v3(dev) ?\n\t\t\t  SVGA_ID_3 : SVGA_ID_2);\n\tsvga_id = vmw_read(dev, SVGA_REG_ID);\n\tif (svga_id != SVGA_ID_2 && svga_id != SVGA_ID_3) {\n\t\tdrm_err(&dev->drm,\n\t\t\t\"Unsupported SVGA ID 0x%x on chipset 0x%x\\n\",\n\t\t\tsvga_id, dev->pci_id);\n\t\treturn -ENOSYS;\n\t}\n\tBUG_ON(vmw_is_svga_v3(dev) && (svga_id != SVGA_ID_3));\n\tdrm_info(&dev->drm,\n\t\t \"Running on SVGA version %d.\\n\", (svga_id & 0xff));\n\treturn 0;\n}\n\nstatic void vmw_write_driver_id(struct vmw_private *dev)\n{\n\tif ((dev->capabilities2 & SVGA_CAP2_DX2) != 0) {\n\t\tvmw_write(dev,  SVGA_REG_GUEST_DRIVER_ID,\n\t\t\t  SVGA_REG_GUEST_DRIVER_ID_LINUX);\n\n\t\tvmw_write(dev, SVGA_REG_GUEST_DRIVER_VERSION1,\n\t\t\t  LINUX_VERSION_MAJOR << 24 |\n\t\t\t  LINUX_VERSION_PATCHLEVEL << 16 |\n\t\t\t  LINUX_VERSION_SUBLEVEL);\n\t\tvmw_write(dev, SVGA_REG_GUEST_DRIVER_VERSION2,\n\t\t\t  VMWGFX_DRIVER_MAJOR << 24 |\n\t\t\t  VMWGFX_DRIVER_MINOR << 16 |\n\t\t\t  VMWGFX_DRIVER_PATCHLEVEL);\n\t\tvmw_write(dev, SVGA_REG_GUEST_DRIVER_VERSION3, 0);\n\n\t\tvmw_write(dev, SVGA_REG_GUEST_DRIVER_ID,\n\t\t\t  SVGA_REG_GUEST_DRIVER_ID_SUBMIT);\n\t}\n}\n\nstatic void vmw_sw_context_init(struct vmw_private *dev_priv)\n{\n\tstruct vmw_sw_context *sw_context = &dev_priv->ctx;\n\n\thash_init(sw_context->res_ht);\n}\n\nstatic void vmw_sw_context_fini(struct vmw_private *dev_priv)\n{\n\tstruct vmw_sw_context *sw_context = &dev_priv->ctx;\n\n\tvfree(sw_context->cmd_bounce);\n\tif (sw_context->staged_bindings)\n\t\tvmw_binding_state_free(sw_context->staged_bindings);\n}\n\nstatic int vmw_driver_load(struct vmw_private *dev_priv, u32 pci_id)\n{\n\tint ret;\n\tenum vmw_res_type i;\n\tbool refuse_dma = false;\n\tstruct pci_dev *pdev = to_pci_dev(dev_priv->drm.dev);\n\n\tdev_priv->drm.dev_private = dev_priv;\n\n\tvmw_sw_context_init(dev_priv);\n\n\tmutex_init(&dev_priv->cmdbuf_mutex);\n\tmutex_init(&dev_priv->binding_mutex);\n\tspin_lock_init(&dev_priv->resource_lock);\n\tspin_lock_init(&dev_priv->hw_lock);\n\tspin_lock_init(&dev_priv->waiter_lock);\n\tspin_lock_init(&dev_priv->cursor_lock);\n\n\tret = vmw_setup_pci_resources(dev_priv, pci_id);\n\tif (ret)\n\t\treturn ret;\n\tret = vmw_detect_version(dev_priv);\n\tif (ret)\n\t\tgoto out_no_pci_or_version;\n\n\n\tfor (i = vmw_res_context; i < vmw_res_max; ++i) {\n\t\tidr_init_base(&dev_priv->res_idr[i], 1);\n\t\tINIT_LIST_HEAD(&dev_priv->res_lru[i]);\n\t}\n\n\tinit_waitqueue_head(&dev_priv->fence_queue);\n\tinit_waitqueue_head(&dev_priv->fifo_queue);\n\tdev_priv->fence_queue_waiters = 0;\n\tdev_priv->fifo_queue_waiters = 0;\n\n\tdev_priv->used_memory_size = 0;\n\n\tdev_priv->assume_16bpp = !!vmw_assume_16bpp;\n\n\tdev_priv->capabilities = vmw_read(dev_priv, SVGA_REG_CAPABILITIES);\n\tvmw_print_bitmap(&dev_priv->drm, \"Capabilities\",\n\t\t\t dev_priv->capabilities,\n\t\t\t cap1_names, ARRAY_SIZE(cap1_names));\n\tif (dev_priv->capabilities & SVGA_CAP_CAP2_REGISTER) {\n\t\tdev_priv->capabilities2 = vmw_read(dev_priv, SVGA_REG_CAP2);\n\t\tvmw_print_bitmap(&dev_priv->drm, \"Capabilities2\",\n\t\t\t\t dev_priv->capabilities2,\n\t\t\t\t cap2_names, ARRAY_SIZE(cap2_names));\n\t}\n\n\tif (!vmwgfx_supported(dev_priv)) {\n\t\tvmw_disable_backdoor();\n\t\tdrm_err_once(&dev_priv->drm,\n\t\t\t     \"vmwgfx seems to be running on an unsupported hypervisor.\");\n\t\tdrm_err_once(&dev_priv->drm,\n\t\t\t     \"This configuration is likely broken.\");\n\t\tdrm_err_once(&dev_priv->drm,\n\t\t\t     \"Please switch to a supported graphics device to avoid problems.\");\n\t}\n\n\tret = vmw_dma_select_mode(dev_priv);\n\tif (unlikely(ret != 0)) {\n\t\tdrm_info(&dev_priv->drm,\n\t\t\t \"Restricting capabilities since DMA not available.\\n\");\n\t\trefuse_dma = true;\n\t\tif (dev_priv->capabilities & SVGA_CAP_GBOBJECTS)\n\t\t\tdrm_info(&dev_priv->drm,\n\t\t\t\t \"Disabling 3D acceleration.\\n\");\n\t}\n\n\tdev_priv->vram_size = vmw_read(dev_priv, SVGA_REG_VRAM_SIZE);\n\tdev_priv->fifo_mem_size = vmw_read(dev_priv, SVGA_REG_MEM_SIZE);\n\tdev_priv->fb_max_width = vmw_read(dev_priv, SVGA_REG_MAX_WIDTH);\n\tdev_priv->fb_max_height = vmw_read(dev_priv, SVGA_REG_MAX_HEIGHT);\n\n\tvmw_get_initial_size(dev_priv);\n\n\tif (dev_priv->capabilities & SVGA_CAP_GMR2) {\n\t\tdev_priv->max_gmr_ids =\n\t\t\tvmw_read(dev_priv, SVGA_REG_GMR_MAX_IDS);\n\t\tdev_priv->max_gmr_pages =\n\t\t\tvmw_read(dev_priv, SVGA_REG_GMRS_MAX_PAGES);\n\t\tdev_priv->memory_size =\n\t\t\tvmw_read(dev_priv, SVGA_REG_MEMORY_SIZE);\n\t\tdev_priv->memory_size -= dev_priv->vram_size;\n\t} else {\n\t\t \n\t\tdev_priv->memory_size = 512*1024*1024;\n\t}\n\tdev_priv->max_mob_pages = 0;\n\tdev_priv->max_mob_size = 0;\n\tif (dev_priv->capabilities & SVGA_CAP_GBOBJECTS) {\n\t\tuint64_t mem_size;\n\n\t\tif (dev_priv->capabilities2 & SVGA_CAP2_GB_MEMSIZE_2)\n\t\t\tmem_size = vmw_read(dev_priv,\n\t\t\t\t\t    SVGA_REG_GBOBJECT_MEM_SIZE_KB);\n\t\telse\n\t\t\tmem_size =\n\t\t\t\tvmw_read(dev_priv,\n\t\t\t\t\t SVGA_REG_SUGGESTED_GBOBJECT_MEM_SIZE_KB);\n\n\t\t \n\t\tif (!(dev_priv->capabilities & SVGA_CAP_3D))\n\t\t\tmem_size *= 3;\n\n\t\tdev_priv->max_mob_pages = mem_size * 1024 / PAGE_SIZE;\n\t\tdev_priv->max_primary_mem =\n\t\t\tvmw_read(dev_priv, SVGA_REG_MAX_PRIMARY_MEM);\n\t\tdev_priv->max_mob_size =\n\t\t\tvmw_read(dev_priv, SVGA_REG_MOB_MAX_SIZE);\n\t\tdev_priv->stdu_max_width =\n\t\t\tvmw_read(dev_priv, SVGA_REG_SCREENTARGET_MAX_WIDTH);\n\t\tdev_priv->stdu_max_height =\n\t\t\tvmw_read(dev_priv, SVGA_REG_SCREENTARGET_MAX_HEIGHT);\n\n\t\tvmw_write(dev_priv, SVGA_REG_DEV_CAP,\n\t\t\t  SVGA3D_DEVCAP_MAX_TEXTURE_WIDTH);\n\t\tdev_priv->texture_max_width = vmw_read(dev_priv,\n\t\t\t\t\t\t       SVGA_REG_DEV_CAP);\n\t\tvmw_write(dev_priv, SVGA_REG_DEV_CAP,\n\t\t\t  SVGA3D_DEVCAP_MAX_TEXTURE_HEIGHT);\n\t\tdev_priv->texture_max_height = vmw_read(dev_priv,\n\t\t\t\t\t\t\tSVGA_REG_DEV_CAP);\n\t} else {\n\t\tdev_priv->texture_max_width = 8192;\n\t\tdev_priv->texture_max_height = 8192;\n\t\tdev_priv->max_primary_mem = dev_priv->vram_size;\n\t}\n\tdrm_info(&dev_priv->drm,\n\t\t \"Legacy memory limits: VRAM = %llu kB, FIFO = %llu kB, surface = %u kB\\n\",\n\t\t (u64)dev_priv->vram_size / 1024,\n\t\t (u64)dev_priv->fifo_mem_size / 1024,\n\t\t dev_priv->memory_size / 1024);\n\n\tdrm_info(&dev_priv->drm,\n\t\t \"MOB limits: max mob size = %u kB, max mob pages = %u\\n\",\n\t\t dev_priv->max_mob_size / 1024, dev_priv->max_mob_pages);\n\n\tret = vmw_dma_masks(dev_priv);\n\tif (unlikely(ret != 0))\n\t\tgoto out_err0;\n\n\tdma_set_max_seg_size(dev_priv->drm.dev, U32_MAX);\n\n\tif (dev_priv->capabilities & SVGA_CAP_GMR2) {\n\t\tdrm_info(&dev_priv->drm,\n\t\t\t \"Max GMR ids is %u\\n\",\n\t\t\t (unsigned)dev_priv->max_gmr_ids);\n\t\tdrm_info(&dev_priv->drm,\n\t\t\t \"Max number of GMR pages is %u\\n\",\n\t\t\t (unsigned)dev_priv->max_gmr_pages);\n\t}\n\tdrm_info(&dev_priv->drm,\n\t\t \"Maximum display memory size is %llu kiB\\n\",\n\t\t (uint64_t)dev_priv->max_primary_mem / 1024);\n\n\t \n\tif (!(dev_priv->capabilities & SVGA_CAP_DISPLAY_TOPOLOGY) &&\n\t    !(dev_priv->capabilities & SVGA_CAP_PITCHLOCK) &&\n\t    !vmw_fifo_have_pitchlock(dev_priv)) {\n\t\tret = -ENOSYS;\n\t\tDRM_ERROR(\"Hardware has no pitchlock\\n\");\n\t\tgoto out_err0;\n\t}\n\n\tdev_priv->tdev = ttm_object_device_init(&vmw_prime_dmabuf_ops);\n\n\tif (unlikely(dev_priv->tdev == NULL)) {\n\t\tdrm_err(&dev_priv->drm,\n\t\t\t\"Unable to initialize TTM object management.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_err0;\n\t}\n\n\tif (dev_priv->capabilities & SVGA_CAP_IRQMASK) {\n\t\tret = vmw_irq_install(dev_priv);\n\t\tif (ret != 0) {\n\t\t\tdrm_err(&dev_priv->drm,\n\t\t\t\t\"Failed installing irq: %d\\n\", ret);\n\t\t\tgoto out_no_irq;\n\t\t}\n\t}\n\n\tdev_priv->fman = vmw_fence_manager_init(dev_priv);\n\tif (unlikely(dev_priv->fman == NULL)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_fman;\n\t}\n\n\tret = ttm_device_init(&dev_priv->bdev, &vmw_bo_driver,\n\t\t\t      dev_priv->drm.dev,\n\t\t\t      dev_priv->drm.anon_inode->i_mapping,\n\t\t\t      dev_priv->drm.vma_offset_manager,\n\t\t\t      dev_priv->map_mode == vmw_dma_alloc_coherent,\n\t\t\t      false);\n\tif (unlikely(ret != 0)) {\n\t\tdrm_err(&dev_priv->drm,\n\t\t\t\"Failed initializing TTM buffer object driver.\\n\");\n\t\tgoto out_no_bdev;\n\t}\n\n\t \n\n\tret = vmw_vram_manager_init(dev_priv);\n\tif (unlikely(ret != 0)) {\n\t\tdrm_err(&dev_priv->drm,\n\t\t\t\"Failed initializing memory manager for VRAM.\\n\");\n\t\tgoto out_no_vram;\n\t}\n\n\tret = vmw_devcaps_create(dev_priv);\n\tif (unlikely(ret != 0)) {\n\t\tdrm_err(&dev_priv->drm,\n\t\t\t\"Failed initializing device caps.\\n\");\n\t\tgoto out_no_vram;\n\t}\n\n\t \n\tdev_priv->has_gmr = true;\n\t \n\tif (((dev_priv->capabilities & (SVGA_CAP_GMR | SVGA_CAP_GMR2)) == 0) ||\n\t    refuse_dma ||\n\t    vmw_gmrid_man_init(dev_priv, VMW_PL_GMR) != 0) {\n\t\tdrm_info(&dev_priv->drm,\n\t\t\t  \"No GMR memory available. \"\n\t\t\t \"Graphics memory resources are very limited.\\n\");\n\t\tdev_priv->has_gmr = false;\n\t}\n\n\tif (dev_priv->capabilities & SVGA_CAP_GBOBJECTS && !refuse_dma) {\n\t\tdev_priv->has_mob = true;\n\n\t\tif (vmw_gmrid_man_init(dev_priv, VMW_PL_MOB) != 0) {\n\t\t\tdrm_info(&dev_priv->drm,\n\t\t\t\t \"No MOB memory available. \"\n\t\t\t\t \"3D will be disabled.\\n\");\n\t\t\tdev_priv->has_mob = false;\n\t\t}\n\t\tif (vmw_sys_man_init(dev_priv) != 0) {\n\t\t\tdrm_info(&dev_priv->drm,\n\t\t\t\t \"No MOB page table memory available. \"\n\t\t\t\t \"3D will be disabled.\\n\");\n\t\t\tdev_priv->has_mob = false;\n\t\t}\n\t}\n\n\tif (dev_priv->has_mob && (dev_priv->capabilities & SVGA_CAP_DX)) {\n\t\tif (vmw_devcap_get(dev_priv, SVGA3D_DEVCAP_DXCONTEXT))\n\t\t\tdev_priv->sm_type = VMW_SM_4;\n\t}\n\n\t \n\tif (has_sm4_context(dev_priv) &&\n\t    (dev_priv->capabilities2 & SVGA_CAP2_DX2)) {\n\t\tif (vmw_devcap_get(dev_priv, SVGA3D_DEVCAP_SM41))\n\t\t\tdev_priv->sm_type = VMW_SM_4_1;\n\t\tif (has_sm4_1_context(dev_priv) &&\n\t\t\t\t(dev_priv->capabilities2 & SVGA_CAP2_DX3)) {\n\t\t\tif (vmw_devcap_get(dev_priv, SVGA3D_DEVCAP_SM5)) {\n\t\t\t\tdev_priv->sm_type = VMW_SM_5;\n\t\t\t\tif (vmw_devcap_get(dev_priv, SVGA3D_DEVCAP_GL43))\n\t\t\t\t\tdev_priv->sm_type = VMW_SM_5_1X;\n\t\t\t}\n\t\t}\n\t}\n\n\tret = vmw_kms_init(dev_priv);\n\tif (unlikely(ret != 0))\n\t\tgoto out_no_kms;\n\tvmw_overlay_init(dev_priv);\n\n\tret = vmw_request_device(dev_priv);\n\tif (ret)\n\t\tgoto out_no_fifo;\n\n\tvmw_print_sm_type(dev_priv);\n\tvmw_host_printf(\"vmwgfx: Module Version: %d.%d.%d (kernel: %s)\",\n\t\t\tVMWGFX_DRIVER_MAJOR, VMWGFX_DRIVER_MINOR,\n\t\t\tVMWGFX_DRIVER_PATCHLEVEL, UTS_RELEASE);\n\tvmw_write_driver_id(dev_priv);\n\n\tdev_priv->pm_nb.notifier_call = vmwgfx_pm_notifier;\n\tregister_pm_notifier(&dev_priv->pm_nb);\n\n\treturn 0;\n\nout_no_fifo:\n\tvmw_overlay_close(dev_priv);\n\tvmw_kms_close(dev_priv);\nout_no_kms:\n\tif (dev_priv->has_mob) {\n\t\tvmw_gmrid_man_fini(dev_priv, VMW_PL_MOB);\n\t\tvmw_sys_man_fini(dev_priv);\n\t}\n\tif (dev_priv->has_gmr)\n\t\tvmw_gmrid_man_fini(dev_priv, VMW_PL_GMR);\n\tvmw_devcaps_destroy(dev_priv);\n\tvmw_vram_manager_fini(dev_priv);\nout_no_vram:\n\tttm_device_fini(&dev_priv->bdev);\nout_no_bdev:\n\tvmw_fence_manager_takedown(dev_priv->fman);\nout_no_fman:\n\tif (dev_priv->capabilities & SVGA_CAP_IRQMASK)\n\t\tvmw_irq_uninstall(&dev_priv->drm);\nout_no_irq:\n\tttm_object_device_release(&dev_priv->tdev);\nout_err0:\n\tfor (i = vmw_res_context; i < vmw_res_max; ++i)\n\t\tidr_destroy(&dev_priv->res_idr[i]);\n\n\tif (dev_priv->ctx.staged_bindings)\n\t\tvmw_binding_state_free(dev_priv->ctx.staged_bindings);\nout_no_pci_or_version:\n\tpci_release_regions(pdev);\n\treturn ret;\n}\n\nstatic void vmw_driver_unload(struct drm_device *dev)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct pci_dev *pdev = to_pci_dev(dev->dev);\n\tenum vmw_res_type i;\n\n\tunregister_pm_notifier(&dev_priv->pm_nb);\n\n\tvmw_sw_context_fini(dev_priv);\n\tvmw_fifo_resource_dec(dev_priv);\n\n\tvmw_svga_disable(dev_priv);\n\n\tvmw_kms_close(dev_priv);\n\tvmw_overlay_close(dev_priv);\n\n\tif (dev_priv->has_gmr)\n\t\tvmw_gmrid_man_fini(dev_priv, VMW_PL_GMR);\n\n\tvmw_release_device_early(dev_priv);\n\tif (dev_priv->has_mob) {\n\t\tvmw_gmrid_man_fini(dev_priv, VMW_PL_MOB);\n\t\tvmw_sys_man_fini(dev_priv);\n\t}\n\tvmw_devcaps_destroy(dev_priv);\n\tvmw_vram_manager_fini(dev_priv);\n\tttm_device_fini(&dev_priv->bdev);\n\tvmw_release_device_late(dev_priv);\n\tvmw_fence_manager_takedown(dev_priv->fman);\n\tif (dev_priv->capabilities & SVGA_CAP_IRQMASK)\n\t\tvmw_irq_uninstall(&dev_priv->drm);\n\n\tttm_object_device_release(&dev_priv->tdev);\n\n\tfor (i = vmw_res_context; i < vmw_res_max; ++i)\n\t\tidr_destroy(&dev_priv->res_idr[i]);\n\n\tvmw_mksstat_remove_all(dev_priv);\n\n\tpci_release_regions(pdev);\n}\n\nstatic void vmw_postclose(struct drm_device *dev,\n\t\t\t struct drm_file *file_priv)\n{\n\tstruct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);\n\n\tttm_object_file_release(&vmw_fp->tfile);\n\tkfree(vmw_fp);\n}\n\nstatic int vmw_driver_open(struct drm_device *dev, struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_fpriv *vmw_fp;\n\tint ret = -ENOMEM;\n\n\tvmw_fp = kzalloc(sizeof(*vmw_fp), GFP_KERNEL);\n\tif (unlikely(!vmw_fp))\n\t\treturn ret;\n\n\tvmw_fp->tfile = ttm_object_file_init(dev_priv->tdev);\n\tif (unlikely(vmw_fp->tfile == NULL))\n\t\tgoto out_no_tfile;\n\n\tfile_priv->driver_priv = vmw_fp;\n\n\treturn 0;\n\nout_no_tfile:\n\tkfree(vmw_fp);\n\treturn ret;\n}\n\nstatic long vmw_generic_ioctl(struct file *filp, unsigned int cmd,\n\t\t\t      unsigned long arg,\n\t\t\t      long (*ioctl_func)(struct file *, unsigned int,\n\t\t\t\t\t\t unsigned long))\n{\n\tstruct drm_file *file_priv = filp->private_data;\n\tstruct drm_device *dev = file_priv->minor->dev;\n\tunsigned int nr = DRM_IOCTL_NR(cmd);\n\tunsigned int flags;\n\n\t \n\n\tif ((nr >= DRM_COMMAND_BASE) && (nr < DRM_COMMAND_END)\n\t    && (nr < DRM_COMMAND_BASE + dev->driver->num_ioctls)) {\n\t\tconst struct drm_ioctl_desc *ioctl =\n\t\t\t&vmw_ioctls[nr - DRM_COMMAND_BASE];\n\n\t\tif (nr == DRM_COMMAND_BASE + DRM_VMW_EXECBUF) {\n\t\t\treturn ioctl_func(filp, cmd, arg);\n\t\t} else if (nr == DRM_COMMAND_BASE + DRM_VMW_UPDATE_LAYOUT) {\n\t\t\tif (!drm_is_current_master(file_priv) &&\n\t\t\t    !capable(CAP_SYS_ADMIN))\n\t\t\t\treturn -EACCES;\n\t\t}\n\n\t\tif (unlikely(ioctl->cmd != cmd))\n\t\t\tgoto out_io_encoding;\n\n\t\tflags = ioctl->flags;\n\t} else if (!drm_ioctl_flags(nr, &flags))\n\t\treturn -EINVAL;\n\n\treturn ioctl_func(filp, cmd, arg);\n\nout_io_encoding:\n\tDRM_ERROR(\"Invalid command format, ioctl %d\\n\",\n\t\t  nr - DRM_COMMAND_BASE);\n\n\treturn -EINVAL;\n}\n\nstatic long vmw_unlocked_ioctl(struct file *filp, unsigned int cmd,\n\t\t\t       unsigned long arg)\n{\n\treturn vmw_generic_ioctl(filp, cmd, arg, &drm_ioctl);\n}\n\n#ifdef CONFIG_COMPAT\nstatic long vmw_compat_ioctl(struct file *filp, unsigned int cmd,\n\t\t\t     unsigned long arg)\n{\n\treturn vmw_generic_ioctl(filp, cmd, arg, &drm_compat_ioctl);\n}\n#endif\n\nstatic void vmw_master_set(struct drm_device *dev,\n\t\t\t   struct drm_file *file_priv,\n\t\t\t   bool from_open)\n{\n\t \n\tif (!from_open)\n\t\tdrm_sysfs_hotplug_event(dev);\n}\n\nstatic void vmw_master_drop(struct drm_device *dev,\n\t\t\t    struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\n\tvmw_kms_legacy_hotspot_clear(dev_priv);\n}\n\nbool vmwgfx_supported(struct vmw_private *vmw)\n{\n#if defined(CONFIG_X86)\n\treturn hypervisor_is_type(X86_HYPER_VMWARE);\n#elif defined(CONFIG_ARM64)\n\t \n\treturn vmw->pci_id == VMWGFX_PCI_ID_SVGA3;\n#else\n\tdrm_warn_once(&vmw->drm,\n\t\t      \"vmwgfx is running on an unknown architecture.\");\n\treturn false;\n#endif\n}\n\n \nstatic void __vmw_svga_enable(struct vmw_private *dev_priv)\n{\n\tstruct ttm_resource_manager *man = ttm_manager_type(&dev_priv->bdev, TTM_PL_VRAM);\n\n\tif (!ttm_resource_manager_used(man)) {\n\t\tvmw_write(dev_priv, SVGA_REG_ENABLE, SVGA_REG_ENABLE_ENABLE);\n\t\tttm_resource_manager_set_used(man, true);\n\t}\n}\n\n \nvoid vmw_svga_enable(struct vmw_private *dev_priv)\n{\n\t__vmw_svga_enable(dev_priv);\n}\n\n \nstatic void __vmw_svga_disable(struct vmw_private *dev_priv)\n{\n\tstruct ttm_resource_manager *man = ttm_manager_type(&dev_priv->bdev, TTM_PL_VRAM);\n\n\tif (ttm_resource_manager_used(man)) {\n\t\tttm_resource_manager_set_used(man, false);\n\t\tvmw_write(dev_priv, SVGA_REG_ENABLE,\n\t\t\t  SVGA_REG_ENABLE_HIDE |\n\t\t\t  SVGA_REG_ENABLE_ENABLE);\n\t}\n}\n\n \nvoid vmw_svga_disable(struct vmw_private *dev_priv)\n{\n\tstruct ttm_resource_manager *man = ttm_manager_type(&dev_priv->bdev, TTM_PL_VRAM);\n\t \n\tvmw_kms_lost_device(&dev_priv->drm);\n\tif (ttm_resource_manager_used(man)) {\n\t\tif (ttm_resource_manager_evict_all(&dev_priv->bdev, man))\n\t\t\tDRM_ERROR(\"Failed evicting VRAM buffers.\\n\");\n\t\tttm_resource_manager_set_used(man, false);\n\t\tvmw_write(dev_priv, SVGA_REG_ENABLE,\n\t\t\t  SVGA_REG_ENABLE_HIDE |\n\t\t\t  SVGA_REG_ENABLE_ENABLE);\n\t}\n}\n\nstatic void vmw_remove(struct pci_dev *pdev)\n{\n\tstruct drm_device *dev = pci_get_drvdata(pdev);\n\n\tdrm_dev_unregister(dev);\n\tvmw_driver_unload(dev);\n}\n\nstatic void vmw_debugfs_resource_managers_init(struct vmw_private *vmw)\n{\n\tstruct drm_minor *minor = vmw->drm.primary;\n\tstruct dentry *root = minor->debugfs_root;\n\n\tttm_resource_manager_create_debugfs(ttm_manager_type(&vmw->bdev, TTM_PL_SYSTEM),\n\t\t\t\t\t    root, \"system_ttm\");\n\tttm_resource_manager_create_debugfs(ttm_manager_type(&vmw->bdev, TTM_PL_VRAM),\n\t\t\t\t\t    root, \"vram_ttm\");\n\tttm_resource_manager_create_debugfs(ttm_manager_type(&vmw->bdev, VMW_PL_GMR),\n\t\t\t\t\t    root, \"gmr_ttm\");\n\tttm_resource_manager_create_debugfs(ttm_manager_type(&vmw->bdev, VMW_PL_MOB),\n\t\t\t\t\t    root, \"mob_ttm\");\n\tttm_resource_manager_create_debugfs(ttm_manager_type(&vmw->bdev, VMW_PL_SYSTEM),\n\t\t\t\t\t    root, \"system_mob_ttm\");\n}\n\nstatic int vmwgfx_pm_notifier(struct notifier_block *nb, unsigned long val,\n\t\t\t      void *ptr)\n{\n\tstruct vmw_private *dev_priv =\n\t\tcontainer_of(nb, struct vmw_private, pm_nb);\n\n\tswitch (val) {\n\tcase PM_HIBERNATION_PREPARE:\n\t\t \n\t\tdev_priv->suspend_locked = true;\n\t\tbreak;\n\tcase PM_POST_HIBERNATION:\n\tcase PM_POST_RESTORE:\n\t\tif (READ_ONCE(dev_priv->suspend_locked)) {\n\t\t\tdev_priv->suspend_locked = false;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int vmw_pci_suspend(struct pci_dev *pdev, pm_message_t state)\n{\n\tstruct drm_device *dev = pci_get_drvdata(pdev);\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\n\tif (dev_priv->refuse_hibernation)\n\t\treturn -EBUSY;\n\n\tpci_save_state(pdev);\n\tpci_disable_device(pdev);\n\tpci_set_power_state(pdev, PCI_D3hot);\n\treturn 0;\n}\n\nstatic int vmw_pci_resume(struct pci_dev *pdev)\n{\n\tpci_set_power_state(pdev, PCI_D0);\n\tpci_restore_state(pdev);\n\treturn pci_enable_device(pdev);\n}\n\nstatic int vmw_pm_suspend(struct device *kdev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(kdev);\n\tstruct pm_message dummy;\n\n\tdummy.event = 0;\n\n\treturn vmw_pci_suspend(pdev, dummy);\n}\n\nstatic int vmw_pm_resume(struct device *kdev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(kdev);\n\n\treturn vmw_pci_resume(pdev);\n}\n\nstatic int vmw_pm_freeze(struct device *kdev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(kdev);\n\tstruct drm_device *dev = pci_get_drvdata(pdev);\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct ttm_operation_ctx ctx = {\n\t\t.interruptible = false,\n\t\t.no_wait_gpu = false\n\t};\n\tint ret;\n\n\t \n\tret = vmw_kms_suspend(&dev_priv->drm);\n\tif (ret) {\n\t\tDRM_ERROR(\"Failed to freeze modesetting.\\n\");\n\t\treturn ret;\n\t}\n\n\tvmw_execbuf_release_pinned_bo(dev_priv);\n\tvmw_resource_evict_all(dev_priv);\n\tvmw_release_device_early(dev_priv);\n\twhile (ttm_device_swapout(&dev_priv->bdev, &ctx, GFP_KERNEL) > 0);\n\tvmw_fifo_resource_dec(dev_priv);\n\tif (atomic_read(&dev_priv->num_fifo_resources) != 0) {\n\t\tDRM_ERROR(\"Can't hibernate while 3D resources are active.\\n\");\n\t\tvmw_fifo_resource_inc(dev_priv);\n\t\tWARN_ON(vmw_request_device_late(dev_priv));\n\t\tdev_priv->suspend_locked = false;\n\t\tif (dev_priv->suspend_state)\n\t\t\tvmw_kms_resume(dev);\n\t\treturn -EBUSY;\n\t}\n\n\tvmw_fence_fifo_down(dev_priv->fman);\n\t__vmw_svga_disable(dev_priv);\n\n\tvmw_release_device_late(dev_priv);\n\treturn 0;\n}\n\nstatic int vmw_pm_restore(struct device *kdev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(kdev);\n\tstruct drm_device *dev = pci_get_drvdata(pdev);\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tint ret;\n\n\tvmw_detect_version(dev_priv);\n\n\tvmw_fifo_resource_inc(dev_priv);\n\n\tret = vmw_request_device(dev_priv);\n\tif (ret)\n\t\treturn ret;\n\n\t__vmw_svga_enable(dev_priv);\n\n\tvmw_fence_fifo_up(dev_priv->fman);\n\tdev_priv->suspend_locked = false;\n\tif (dev_priv->suspend_state)\n\t\tvmw_kms_resume(&dev_priv->drm);\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops vmw_pm_ops = {\n\t.freeze = vmw_pm_freeze,\n\t.thaw = vmw_pm_restore,\n\t.restore = vmw_pm_restore,\n\t.suspend = vmw_pm_suspend,\n\t.resume = vmw_pm_resume,\n};\n\nstatic const struct file_operations vmwgfx_driver_fops = {\n\t.owner = THIS_MODULE,\n\t.open = drm_open,\n\t.release = drm_release,\n\t.unlocked_ioctl = vmw_unlocked_ioctl,\n\t.mmap = drm_gem_mmap,\n\t.poll = drm_poll,\n\t.read = drm_read,\n#if defined(CONFIG_COMPAT)\n\t.compat_ioctl = vmw_compat_ioctl,\n#endif\n\t.llseek = noop_llseek,\n};\n\nstatic const struct drm_driver driver = {\n\t.driver_features =\n\tDRIVER_MODESET | DRIVER_RENDER | DRIVER_ATOMIC | DRIVER_GEM,\n\t.ioctls = vmw_ioctls,\n\t.num_ioctls = ARRAY_SIZE(vmw_ioctls),\n\t.master_set = vmw_master_set,\n\t.master_drop = vmw_master_drop,\n\t.open = vmw_driver_open,\n\t.postclose = vmw_postclose,\n\n\t.dumb_create = vmw_dumb_create,\n\t.dumb_map_offset = drm_gem_ttm_dumb_map_offset,\n\n\t.prime_fd_to_handle = vmw_prime_fd_to_handle,\n\t.prime_handle_to_fd = vmw_prime_handle_to_fd,\n\n\t.fops = &vmwgfx_driver_fops,\n\t.name = VMWGFX_DRIVER_NAME,\n\t.desc = VMWGFX_DRIVER_DESC,\n\t.date = VMWGFX_DRIVER_DATE,\n\t.major = VMWGFX_DRIVER_MAJOR,\n\t.minor = VMWGFX_DRIVER_MINOR,\n\t.patchlevel = VMWGFX_DRIVER_PATCHLEVEL\n};\n\nstatic struct pci_driver vmw_pci_driver = {\n\t.name = VMWGFX_DRIVER_NAME,\n\t.id_table = vmw_pci_id_list,\n\t.probe = vmw_probe,\n\t.remove = vmw_remove,\n\t.driver = {\n\t\t.pm = &vmw_pm_ops\n\t}\n};\n\nstatic int vmw_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstruct vmw_private *vmw;\n\tint ret;\n\n\tret = drm_aperture_remove_conflicting_pci_framebuffers(pdev, &driver);\n\tif (ret)\n\t\tgoto out_error;\n\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\tgoto out_error;\n\n\tvmw = devm_drm_dev_alloc(&pdev->dev, &driver,\n\t\t\t\t struct vmw_private, drm);\n\tif (IS_ERR(vmw)) {\n\t\tret = PTR_ERR(vmw);\n\t\tgoto out_error;\n\t}\n\n\tpci_set_drvdata(pdev, &vmw->drm);\n\n\tret = vmw_driver_load(vmw, ent->device);\n\tif (ret)\n\t\tgoto out_error;\n\n\tret = drm_dev_register(&vmw->drm, 0);\n\tif (ret)\n\t\tgoto out_unload;\n\n\tvmw_fifo_resource_inc(vmw);\n\tvmw_svga_enable(vmw);\n\tdrm_fbdev_generic_setup(&vmw->drm,  0);\n\n\tvmw_debugfs_gem_init(vmw);\n\tvmw_debugfs_resource_managers_init(vmw);\n\n\treturn 0;\nout_unload:\n\tvmw_driver_unload(&vmw->drm);\nout_error:\n\treturn ret;\n}\n\ndrm_module_pci_driver(vmw_pci_driver);\n\nMODULE_AUTHOR(\"VMware Inc. and others\");\nMODULE_DESCRIPTION(\"Standalone drm driver for the VMware SVGA device\");\nMODULE_LICENSE(\"GPL and additional rights\");\nMODULE_VERSION(__stringify(VMWGFX_DRIVER_MAJOR) \".\"\n\t       __stringify(VMWGFX_DRIVER_MINOR) \".\"\n\t       __stringify(VMWGFX_DRIVER_PATCHLEVEL) \".\"\n\t       \"0\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}