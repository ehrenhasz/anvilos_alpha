{
  "module_name": "vmwgfx_cmdbuf.c",
  "hash_id": "c4b0b1e384fcae61c160edc54b81a8cd42e0e4bb8364e1bd825b7ae18221ee34",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/vmwgfx_cmdbuf.c",
  "human_readable_source": "\n \n\n#include \"vmwgfx_bo.h\"\n#include \"vmwgfx_drv.h\"\n\n#include <drm/ttm/ttm_bo.h>\n\n#include <linux/dmapool.h>\n#include <linux/pci.h>\n\n \n#define VMW_CMDBUF_INLINE_ALIGN 64\n#define VMW_CMDBUF_INLINE_SIZE \\\n\t(1024 - ALIGN(sizeof(SVGACBHeader), VMW_CMDBUF_INLINE_ALIGN))\n\n \nstruct vmw_cmdbuf_context {\n\tstruct list_head submitted;\n\tstruct list_head hw_submitted;\n\tstruct list_head preempted;\n\tunsigned num_hw_submitted;\n\tbool block_submission;\n};\n\n \nstruct vmw_cmdbuf_man {\n\tstruct mutex cur_mutex;\n\tstruct mutex space_mutex;\n\tstruct mutex error_mutex;\n\tstruct work_struct work;\n\tstruct vmw_private *dev_priv;\n\tstruct vmw_cmdbuf_context ctx[SVGA_CB_CONTEXT_MAX];\n\tstruct list_head error;\n\tstruct drm_mm mm;\n\tstruct vmw_bo *cmd_space;\n\tu8 *map;\n\tstruct vmw_cmdbuf_header *cur;\n\tsize_t cur_pos;\n\tsize_t default_size;\n\tunsigned max_hw_submitted;\n\tspinlock_t lock;\n\tstruct dma_pool *headers;\n\tstruct dma_pool *dheaders;\n\twait_queue_head_t alloc_queue;\n\twait_queue_head_t idle_queue;\n\tbool irq_on;\n\tbool using_mob;\n\tbool has_pool;\n\tdma_addr_t handle;\n\tsize_t size;\n\tu32 num_contexts;\n};\n\n \nstruct vmw_cmdbuf_header {\n\tstruct vmw_cmdbuf_man *man;\n\tSVGACBHeader *cb_header;\n\tSVGACBContext cb_context;\n\tstruct list_head list;\n\tstruct drm_mm_node node;\n\tdma_addr_t handle;\n\tu8 *cmd;\n\tsize_t size;\n\tsize_t reserved;\n\tbool inline_space;\n};\n\n \nstruct vmw_cmdbuf_dheader {\n\tSVGACBHeader cb_header;\n\tu8 cmd[VMW_CMDBUF_INLINE_SIZE] __aligned(VMW_CMDBUF_INLINE_ALIGN);\n};\n\n \nstruct vmw_cmdbuf_alloc_info {\n\tsize_t page_size;\n\tstruct drm_mm_node *node;\n\tbool done;\n};\n\n \n#define for_each_cmdbuf_ctx(_man, _i, _ctx)\t\t\t\t\\\n\tfor (_i = 0, _ctx = &(_man)->ctx[0]; (_i) < (_man)->num_contexts; \\\n\t     ++(_i), ++(_ctx))\n\nstatic int vmw_cmdbuf_startstop(struct vmw_cmdbuf_man *man, u32 context,\n\t\t\t\tbool enable);\nstatic int vmw_cmdbuf_preempt(struct vmw_cmdbuf_man *man, u32 context);\n\n \nstatic int vmw_cmdbuf_cur_lock(struct vmw_cmdbuf_man *man, bool interruptible)\n{\n\tif (interruptible) {\n\t\tif (mutex_lock_interruptible(&man->cur_mutex))\n\t\t\treturn -ERESTARTSYS;\n\t} else {\n\t\tmutex_lock(&man->cur_mutex);\n\t}\n\n\treturn 0;\n}\n\n \nstatic void vmw_cmdbuf_cur_unlock(struct vmw_cmdbuf_man *man)\n{\n\tmutex_unlock(&man->cur_mutex);\n}\n\n \nstatic void vmw_cmdbuf_header_inline_free(struct vmw_cmdbuf_header *header)\n{\n\tstruct vmw_cmdbuf_dheader *dheader;\n\n\tif (WARN_ON_ONCE(!header->inline_space))\n\t\treturn;\n\n\tdheader = container_of(header->cb_header, struct vmw_cmdbuf_dheader,\n\t\t\t       cb_header);\n\tdma_pool_free(header->man->dheaders, dheader, header->handle);\n\tkfree(header);\n}\n\n \nstatic void __vmw_cmdbuf_header_free(struct vmw_cmdbuf_header *header)\n{\n\tstruct vmw_cmdbuf_man *man = header->man;\n\n\tlockdep_assert_held_once(&man->lock);\n\n\tif (header->inline_space) {\n\t\tvmw_cmdbuf_header_inline_free(header);\n\t\treturn;\n\t}\n\n\tdrm_mm_remove_node(&header->node);\n\twake_up_all(&man->alloc_queue);\n\tif (header->cb_header)\n\t\tdma_pool_free(man->headers, header->cb_header,\n\t\t\t      header->handle);\n\tkfree(header);\n}\n\n \nvoid vmw_cmdbuf_header_free(struct vmw_cmdbuf_header *header)\n{\n\tstruct vmw_cmdbuf_man *man = header->man;\n\n\t \n\tif (header->inline_space) {\n\t\tvmw_cmdbuf_header_inline_free(header);\n\t\treturn;\n\t}\n\tspin_lock(&man->lock);\n\t__vmw_cmdbuf_header_free(header);\n\tspin_unlock(&man->lock);\n}\n\n\n \nstatic int vmw_cmdbuf_header_submit(struct vmw_cmdbuf_header *header)\n{\n\tstruct vmw_cmdbuf_man *man = header->man;\n\tu32 val;\n\n\tval = upper_32_bits(header->handle);\n\tvmw_write(man->dev_priv, SVGA_REG_COMMAND_HIGH, val);\n\n\tval = lower_32_bits(header->handle);\n\tval |= header->cb_context & SVGA_CB_CONTEXT_MASK;\n\tvmw_write(man->dev_priv, SVGA_REG_COMMAND_LOW, val);\n\n\treturn header->cb_header->status;\n}\n\n \nstatic void vmw_cmdbuf_ctx_init(struct vmw_cmdbuf_context *ctx)\n{\n\tINIT_LIST_HEAD(&ctx->hw_submitted);\n\tINIT_LIST_HEAD(&ctx->submitted);\n\tINIT_LIST_HEAD(&ctx->preempted);\n\tctx->num_hw_submitted = 0;\n}\n\n \nstatic void vmw_cmdbuf_ctx_submit(struct vmw_cmdbuf_man *man,\n\t\t\t\t  struct vmw_cmdbuf_context *ctx)\n{\n\twhile (ctx->num_hw_submitted < man->max_hw_submitted &&\n\t       !list_empty(&ctx->submitted) &&\n\t       !ctx->block_submission) {\n\t\tstruct vmw_cmdbuf_header *entry;\n\t\tSVGACBStatus status;\n\n\t\tentry = list_first_entry(&ctx->submitted,\n\t\t\t\t\t struct vmw_cmdbuf_header,\n\t\t\t\t\t list);\n\n\t\tstatus = vmw_cmdbuf_header_submit(entry);\n\n\t\t \n\t\tif (WARN_ON_ONCE(status == SVGA_CB_STATUS_QUEUE_FULL)) {\n\t\t\tentry->cb_header->status = SVGA_CB_STATUS_NONE;\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_move_tail(&entry->list, &ctx->hw_submitted);\n\t\tctx->num_hw_submitted++;\n\t}\n\n}\n\n \nstatic void vmw_cmdbuf_ctx_process(struct vmw_cmdbuf_man *man,\n\t\t\t\t   struct vmw_cmdbuf_context *ctx,\n\t\t\t\t   int *notempty)\n{\n\tstruct vmw_cmdbuf_header *entry, *next;\n\n\tvmw_cmdbuf_ctx_submit(man, ctx);\n\n\tlist_for_each_entry_safe(entry, next, &ctx->hw_submitted, list) {\n\t\tSVGACBStatus status = entry->cb_header->status;\n\n\t\tif (status == SVGA_CB_STATUS_NONE)\n\t\t\tbreak;\n\n\t\tlist_del(&entry->list);\n\t\twake_up_all(&man->idle_queue);\n\t\tctx->num_hw_submitted--;\n\t\tswitch (status) {\n\t\tcase SVGA_CB_STATUS_COMPLETED:\n\t\t\t__vmw_cmdbuf_header_free(entry);\n\t\t\tbreak;\n\t\tcase SVGA_CB_STATUS_COMMAND_ERROR:\n\t\t\tWARN_ONCE(true, \"Command buffer error.\\n\");\n\t\t\tentry->cb_header->status = SVGA_CB_STATUS_NONE;\n\t\t\tlist_add_tail(&entry->list, &man->error);\n\t\t\tschedule_work(&man->work);\n\t\t\tbreak;\n\t\tcase SVGA_CB_STATUS_PREEMPTED:\n\t\t\tentry->cb_header->status = SVGA_CB_STATUS_NONE;\n\t\t\tlist_add_tail(&entry->list, &ctx->preempted);\n\t\t\tbreak;\n\t\tcase SVGA_CB_STATUS_CB_HEADER_ERROR:\n\t\t\tWARN_ONCE(true, \"Command buffer header error.\\n\");\n\t\t\t__vmw_cmdbuf_header_free(entry);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tWARN_ONCE(true, \"Undefined command buffer status.\\n\");\n\t\t\t__vmw_cmdbuf_header_free(entry);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tvmw_cmdbuf_ctx_submit(man, ctx);\n\tif (!list_empty(&ctx->submitted))\n\t\t(*notempty)++;\n}\n\n \nstatic void vmw_cmdbuf_man_process(struct vmw_cmdbuf_man *man)\n{\n\tint notempty;\n\tstruct vmw_cmdbuf_context *ctx;\n\tint i;\n\nretry:\n\tnotempty = 0;\n\tfor_each_cmdbuf_ctx(man, i, ctx)\n\t\tvmw_cmdbuf_ctx_process(man, ctx, &notempty);\n\n\tif (man->irq_on && !notempty) {\n\t\tvmw_generic_waiter_remove(man->dev_priv,\n\t\t\t\t\t  SVGA_IRQFLAG_COMMAND_BUFFER,\n\t\t\t\t\t  &man->dev_priv->cmdbuf_waiters);\n\t\tman->irq_on = false;\n\t} else if (!man->irq_on && notempty) {\n\t\tvmw_generic_waiter_add(man->dev_priv,\n\t\t\t\t       SVGA_IRQFLAG_COMMAND_BUFFER,\n\t\t\t\t       &man->dev_priv->cmdbuf_waiters);\n\t\tman->irq_on = true;\n\n\t\t \n\t\tgoto retry;\n\t}\n}\n\n \nstatic void vmw_cmdbuf_ctx_add(struct vmw_cmdbuf_man *man,\n\t\t\t       struct vmw_cmdbuf_header *header,\n\t\t\t       SVGACBContext cb_context)\n{\n\tif (!(header->cb_header->flags & SVGA_CB_FLAG_DX_CONTEXT))\n\t\theader->cb_header->dxContext = 0;\n\theader->cb_context = cb_context;\n\tlist_add_tail(&header->list, &man->ctx[cb_context].submitted);\n\n\tvmw_cmdbuf_man_process(man);\n}\n\n \nvoid vmw_cmdbuf_irqthread(struct vmw_cmdbuf_man *man)\n{\n\tspin_lock(&man->lock);\n\tvmw_cmdbuf_man_process(man);\n\tspin_unlock(&man->lock);\n}\n\n \nstatic void vmw_cmdbuf_work_func(struct work_struct *work)\n{\n\tstruct vmw_cmdbuf_man *man =\n\t\tcontainer_of(work, struct vmw_cmdbuf_man, work);\n\tstruct vmw_cmdbuf_header *entry, *next;\n\tuint32_t dummy = 0;\n\tbool send_fence = false;\n\tstruct list_head restart_head[SVGA_CB_CONTEXT_MAX];\n\tint i;\n\tstruct vmw_cmdbuf_context *ctx;\n\tbool global_block = false;\n\n\tfor_each_cmdbuf_ctx(man, i, ctx)\n\t\tINIT_LIST_HEAD(&restart_head[i]);\n\n\tmutex_lock(&man->error_mutex);\n\tspin_lock(&man->lock);\n\tlist_for_each_entry_safe(entry, next, &man->error, list) {\n\t\tSVGACBHeader *cb_hdr = entry->cb_header;\n\t\tSVGA3dCmdHeader *header = (SVGA3dCmdHeader *)\n\t\t\t(entry->cmd + cb_hdr->errorOffset);\n\t\tu32 error_cmd_size, new_start_offset;\n\t\tconst char *cmd_name;\n\n\t\tlist_del_init(&entry->list);\n\t\tglobal_block = true;\n\n\t\tif (!vmw_cmd_describe(header, &error_cmd_size, &cmd_name)) {\n\t\t\tVMW_DEBUG_USER(\"Unknown command causing device error.\\n\");\n\t\t\tVMW_DEBUG_USER(\"Command buffer offset is %lu\\n\",\n\t\t\t\t       (unsigned long) cb_hdr->errorOffset);\n\t\t\t__vmw_cmdbuf_header_free(entry);\n\t\t\tsend_fence = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tVMW_DEBUG_USER(\"Command \\\"%s\\\" causing device error.\\n\",\n\t\t\t       cmd_name);\n\t\tVMW_DEBUG_USER(\"Command buffer offset is %lu\\n\",\n\t\t\t       (unsigned long) cb_hdr->errorOffset);\n\t\tVMW_DEBUG_USER(\"Command size is %lu\\n\",\n\t\t\t       (unsigned long) error_cmd_size);\n\n\t\tnew_start_offset = cb_hdr->errorOffset + error_cmd_size;\n\n\t\tif (new_start_offset >= cb_hdr->length) {\n\t\t\t__vmw_cmdbuf_header_free(entry);\n\t\t\tsend_fence = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (man->using_mob)\n\t\t\tcb_hdr->ptr.mob.mobOffset += new_start_offset;\n\t\telse\n\t\t\tcb_hdr->ptr.pa += (u64) new_start_offset;\n\n\t\tentry->cmd += new_start_offset;\n\t\tcb_hdr->length -= new_start_offset;\n\t\tcb_hdr->errorOffset = 0;\n\t\tcb_hdr->offset = 0;\n\n\t\tlist_add_tail(&entry->list, &restart_head[entry->cb_context]);\n\t}\n\n\tfor_each_cmdbuf_ctx(man, i, ctx)\n\t\tman->ctx[i].block_submission = true;\n\n\tspin_unlock(&man->lock);\n\n\t \n\tif (global_block && vmw_cmdbuf_preempt(man, 0))\n\t\tDRM_ERROR(\"Failed preempting command buffer contexts\\n\");\n\n\tspin_lock(&man->lock);\n\tfor_each_cmdbuf_ctx(man, i, ctx) {\n\t\t \n\t\tvmw_cmdbuf_ctx_process(man, ctx, &dummy);\n\n\t\t \n\t\tlist_splice_init(&ctx->preempted, restart_head[i].prev);\n\n\t\t \n\n\t\tctx->block_submission = false;\n\t\tlist_splice_init(&restart_head[i], &ctx->submitted);\n\t}\n\n\tvmw_cmdbuf_man_process(man);\n\tspin_unlock(&man->lock);\n\n\tif (global_block && vmw_cmdbuf_startstop(man, 0, true))\n\t\tDRM_ERROR(\"Failed restarting command buffer contexts\\n\");\n\n\t \n\tif (send_fence) {\n\t\tvmw_cmd_send_fence(man->dev_priv, &dummy);\n\t\twake_up_all(&man->idle_queue);\n\t}\n\n\tmutex_unlock(&man->error_mutex);\n}\n\n \nstatic bool vmw_cmdbuf_man_idle(struct vmw_cmdbuf_man *man,\n\t\t\t\tbool check_preempted)\n{\n\tstruct vmw_cmdbuf_context *ctx;\n\tbool idle = false;\n\tint i;\n\n\tspin_lock(&man->lock);\n\tvmw_cmdbuf_man_process(man);\n\tfor_each_cmdbuf_ctx(man, i, ctx) {\n\t\tif (!list_empty(&ctx->submitted) ||\n\t\t    !list_empty(&ctx->hw_submitted) ||\n\t\t    (check_preempted && !list_empty(&ctx->preempted)))\n\t\t\tgoto out_unlock;\n\t}\n\n\tidle = list_empty(&man->error);\n\nout_unlock:\n\tspin_unlock(&man->lock);\n\n\treturn idle;\n}\n\n \nstatic void __vmw_cmdbuf_cur_flush(struct vmw_cmdbuf_man *man)\n{\n\tstruct vmw_cmdbuf_header *cur = man->cur;\n\n\tlockdep_assert_held_once(&man->cur_mutex);\n\n\tif (!cur)\n\t\treturn;\n\n\tspin_lock(&man->lock);\n\tif (man->cur_pos == 0) {\n\t\t__vmw_cmdbuf_header_free(cur);\n\t\tgoto out_unlock;\n\t}\n\n\tman->cur->cb_header->length = man->cur_pos;\n\tvmw_cmdbuf_ctx_add(man, man->cur, SVGA_CB_CONTEXT_0);\nout_unlock:\n\tspin_unlock(&man->lock);\n\tman->cur = NULL;\n\tman->cur_pos = 0;\n}\n\n \nint vmw_cmdbuf_cur_flush(struct vmw_cmdbuf_man *man,\n\t\t\t bool interruptible)\n{\n\tint ret = vmw_cmdbuf_cur_lock(man, interruptible);\n\n\tif (ret)\n\t\treturn ret;\n\n\t__vmw_cmdbuf_cur_flush(man);\n\tvmw_cmdbuf_cur_unlock(man);\n\n\treturn 0;\n}\n\n \nint vmw_cmdbuf_idle(struct vmw_cmdbuf_man *man, bool interruptible,\n\t\t    unsigned long timeout)\n{\n\tint ret;\n\n\tret = vmw_cmdbuf_cur_flush(man, interruptible);\n\tvmw_generic_waiter_add(man->dev_priv,\n\t\t\t       SVGA_IRQFLAG_COMMAND_BUFFER,\n\t\t\t       &man->dev_priv->cmdbuf_waiters);\n\n\tif (interruptible) {\n\t\tret = wait_event_interruptible_timeout\n\t\t\t(man->idle_queue, vmw_cmdbuf_man_idle(man, true),\n\t\t\t timeout);\n\t} else {\n\t\tret = wait_event_timeout\n\t\t\t(man->idle_queue, vmw_cmdbuf_man_idle(man, true),\n\t\t\t timeout);\n\t}\n\tvmw_generic_waiter_remove(man->dev_priv,\n\t\t\t\t  SVGA_IRQFLAG_COMMAND_BUFFER,\n\t\t\t\t  &man->dev_priv->cmdbuf_waiters);\n\tif (ret == 0) {\n\t\tif (!vmw_cmdbuf_man_idle(man, true))\n\t\t\tret = -EBUSY;\n\t\telse\n\t\t\tret = 0;\n\t}\n\tif (ret > 0)\n\t\tret = 0;\n\n\treturn ret;\n}\n\n \nstatic bool vmw_cmdbuf_try_alloc(struct vmw_cmdbuf_man *man,\n\t\t\t\t struct vmw_cmdbuf_alloc_info *info)\n{\n\tint ret;\n\n\tif (info->done)\n\t\treturn true;\n\n\tmemset(info->node, 0, sizeof(*info->node));\n\tspin_lock(&man->lock);\n\tret = drm_mm_insert_node(&man->mm, info->node, info->page_size);\n\tif (ret) {\n\t\tvmw_cmdbuf_man_process(man);\n\t\tret = drm_mm_insert_node(&man->mm, info->node, info->page_size);\n\t}\n\n\tspin_unlock(&man->lock);\n\tinfo->done = !ret;\n\n\treturn info->done;\n}\n\n \nstatic int vmw_cmdbuf_alloc_space(struct vmw_cmdbuf_man *man,\n\t\t\t\t  struct drm_mm_node *node,\n\t\t\t\t  size_t size,\n\t\t\t\t  bool interruptible)\n{\n\tstruct vmw_cmdbuf_alloc_info info;\n\n\tinfo.page_size = PFN_UP(size);\n\tinfo.node = node;\n\tinfo.done = false;\n\n\t \n\tif (interruptible) {\n\t\tif (mutex_lock_interruptible(&man->space_mutex))\n\t\t\treturn -ERESTARTSYS;\n\t} else {\n\t\tmutex_lock(&man->space_mutex);\n\t}\n\n\t \n\tif (vmw_cmdbuf_try_alloc(man, &info))\n\t\tgoto out_unlock;\n\n\tvmw_generic_waiter_add(man->dev_priv,\n\t\t\t       SVGA_IRQFLAG_COMMAND_BUFFER,\n\t\t\t       &man->dev_priv->cmdbuf_waiters);\n\n\tif (interruptible) {\n\t\tint ret;\n\n\t\tret = wait_event_interruptible\n\t\t\t(man->alloc_queue, vmw_cmdbuf_try_alloc(man, &info));\n\t\tif (ret) {\n\t\t\tvmw_generic_waiter_remove\n\t\t\t\t(man->dev_priv, SVGA_IRQFLAG_COMMAND_BUFFER,\n\t\t\t\t &man->dev_priv->cmdbuf_waiters);\n\t\t\tmutex_unlock(&man->space_mutex);\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\twait_event(man->alloc_queue, vmw_cmdbuf_try_alloc(man, &info));\n\t}\n\tvmw_generic_waiter_remove(man->dev_priv,\n\t\t\t\t  SVGA_IRQFLAG_COMMAND_BUFFER,\n\t\t\t\t  &man->dev_priv->cmdbuf_waiters);\n\nout_unlock:\n\tmutex_unlock(&man->space_mutex);\n\n\treturn 0;\n}\n\n \nstatic int vmw_cmdbuf_space_pool(struct vmw_cmdbuf_man *man,\n\t\t\t\t struct vmw_cmdbuf_header *header,\n\t\t\t\t size_t size,\n\t\t\t\t bool interruptible)\n{\n\tSVGACBHeader *cb_hdr;\n\tsize_t offset;\n\tint ret;\n\n\tif (!man->has_pool)\n\t\treturn -ENOMEM;\n\n\tret = vmw_cmdbuf_alloc_space(man, &header->node,  size, interruptible);\n\n\tif (ret)\n\t\treturn ret;\n\n\theader->cb_header = dma_pool_zalloc(man->headers, GFP_KERNEL,\n\t\t\t\t\t    &header->handle);\n\tif (!header->cb_header) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_cb_header;\n\t}\n\n\theader->size = header->node.size << PAGE_SHIFT;\n\tcb_hdr = header->cb_header;\n\toffset = header->node.start << PAGE_SHIFT;\n\theader->cmd = man->map + offset;\n\tif (man->using_mob) {\n\t\tcb_hdr->flags = SVGA_CB_FLAG_MOB;\n\t\tcb_hdr->ptr.mob.mobid = man->cmd_space->tbo.resource->start;\n\t\tcb_hdr->ptr.mob.mobOffset = offset;\n\t} else {\n\t\tcb_hdr->ptr.pa = (u64)man->handle + (u64)offset;\n\t}\n\n\treturn 0;\n\nout_no_cb_header:\n\tspin_lock(&man->lock);\n\tdrm_mm_remove_node(&header->node);\n\tspin_unlock(&man->lock);\n\n\treturn ret;\n}\n\n \nstatic int vmw_cmdbuf_space_inline(struct vmw_cmdbuf_man *man,\n\t\t\t\t   struct vmw_cmdbuf_header *header,\n\t\t\t\t   int size)\n{\n\tstruct vmw_cmdbuf_dheader *dheader;\n\tSVGACBHeader *cb_hdr;\n\n\tif (WARN_ON_ONCE(size > VMW_CMDBUF_INLINE_SIZE))\n\t\treturn -ENOMEM;\n\n\tdheader = dma_pool_zalloc(man->dheaders, GFP_KERNEL,\n\t\t\t\t  &header->handle);\n\tif (!dheader)\n\t\treturn -ENOMEM;\n\n\theader->inline_space = true;\n\theader->size = VMW_CMDBUF_INLINE_SIZE;\n\tcb_hdr = &dheader->cb_header;\n\theader->cb_header = cb_hdr;\n\theader->cmd = dheader->cmd;\n\tcb_hdr->status = SVGA_CB_STATUS_NONE;\n\tcb_hdr->flags = SVGA_CB_FLAG_NONE;\n\tcb_hdr->ptr.pa = (u64)header->handle +\n\t\t(u64)offsetof(struct vmw_cmdbuf_dheader, cmd);\n\n\treturn 0;\n}\n\n \nvoid *vmw_cmdbuf_alloc(struct vmw_cmdbuf_man *man,\n\t\t       size_t size, bool interruptible,\n\t\t       struct vmw_cmdbuf_header **p_header)\n{\n\tstruct vmw_cmdbuf_header *header;\n\tint ret = 0;\n\n\t*p_header = NULL;\n\n\theader = kzalloc(sizeof(*header), GFP_KERNEL);\n\tif (!header)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (size <= VMW_CMDBUF_INLINE_SIZE)\n\t\tret = vmw_cmdbuf_space_inline(man, header, size);\n\telse\n\t\tret = vmw_cmdbuf_space_pool(man, header, size, interruptible);\n\n\tif (ret) {\n\t\tkfree(header);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\theader->man = man;\n\tINIT_LIST_HEAD(&header->list);\n\theader->cb_header->status = SVGA_CB_STATUS_NONE;\n\t*p_header = header;\n\n\treturn header->cmd;\n}\n\n \nstatic void *vmw_cmdbuf_reserve_cur(struct vmw_cmdbuf_man *man,\n\t\t\t\t    size_t size,\n\t\t\t\t    int ctx_id,\n\t\t\t\t    bool interruptible)\n{\n\tstruct vmw_cmdbuf_header *cur;\n\tvoid *ret;\n\n\tif (vmw_cmdbuf_cur_lock(man, interruptible))\n\t\treturn ERR_PTR(-ERESTARTSYS);\n\n\tcur = man->cur;\n\tif (cur && (size + man->cur_pos > cur->size ||\n\t\t    ((cur->cb_header->flags & SVGA_CB_FLAG_DX_CONTEXT) &&\n\t\t     ctx_id != cur->cb_header->dxContext)))\n\t\t__vmw_cmdbuf_cur_flush(man);\n\n\tif (!man->cur) {\n\t\tret = vmw_cmdbuf_alloc(man,\n\t\t\t\t       max_t(size_t, size, man->default_size),\n\t\t\t\t       interruptible, &man->cur);\n\t\tif (IS_ERR(ret)) {\n\t\t\tvmw_cmdbuf_cur_unlock(man);\n\t\t\treturn ret;\n\t\t}\n\n\t\tcur = man->cur;\n\t}\n\n\tif (ctx_id != SVGA3D_INVALID_ID) {\n\t\tcur->cb_header->flags |= SVGA_CB_FLAG_DX_CONTEXT;\n\t\tcur->cb_header->dxContext = ctx_id;\n\t}\n\n\tcur->reserved = size;\n\n\treturn (void *) (man->cur->cmd + man->cur_pos);\n}\n\n \nstatic void vmw_cmdbuf_commit_cur(struct vmw_cmdbuf_man *man,\n\t\t\t\t  size_t size, bool flush)\n{\n\tstruct vmw_cmdbuf_header *cur = man->cur;\n\n\tlockdep_assert_held_once(&man->cur_mutex);\n\n\tWARN_ON(size > cur->reserved);\n\tman->cur_pos += size;\n\tif (!size)\n\t\tcur->cb_header->flags &= ~SVGA_CB_FLAG_DX_CONTEXT;\n\tif (flush)\n\t\t__vmw_cmdbuf_cur_flush(man);\n\tvmw_cmdbuf_cur_unlock(man);\n}\n\n \nvoid *vmw_cmdbuf_reserve(struct vmw_cmdbuf_man *man, size_t size,\n\t\t\t int ctx_id, bool interruptible,\n\t\t\t struct vmw_cmdbuf_header *header)\n{\n\tif (!header)\n\t\treturn vmw_cmdbuf_reserve_cur(man, size, ctx_id, interruptible);\n\n\tif (size > header->size)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (ctx_id != SVGA3D_INVALID_ID) {\n\t\theader->cb_header->flags |= SVGA_CB_FLAG_DX_CONTEXT;\n\t\theader->cb_header->dxContext = ctx_id;\n\t}\n\n\theader->reserved = size;\n\treturn header->cmd;\n}\n\n \nvoid vmw_cmdbuf_commit(struct vmw_cmdbuf_man *man, size_t size,\n\t\t       struct vmw_cmdbuf_header *header, bool flush)\n{\n\tif (!header) {\n\t\tvmw_cmdbuf_commit_cur(man, size, flush);\n\t\treturn;\n\t}\n\n\t(void) vmw_cmdbuf_cur_lock(man, false);\n\t__vmw_cmdbuf_cur_flush(man);\n\tWARN_ON(size > header->reserved);\n\tman->cur = header;\n\tman->cur_pos = size;\n\tif (!size)\n\t\theader->cb_header->flags &= ~SVGA_CB_FLAG_DX_CONTEXT;\n\tif (flush)\n\t\t__vmw_cmdbuf_cur_flush(man);\n\tvmw_cmdbuf_cur_unlock(man);\n}\n\n\n \nstatic int vmw_cmdbuf_send_device_command(struct vmw_cmdbuf_man *man,\n\t\t\t\t\t  const void *command,\n\t\t\t\t\t  size_t size)\n{\n\tstruct vmw_cmdbuf_header *header;\n\tint status;\n\tvoid *cmd = vmw_cmdbuf_alloc(man, size, false, &header);\n\n\tif (IS_ERR(cmd))\n\t\treturn PTR_ERR(cmd);\n\n\tmemcpy(cmd, command, size);\n\theader->cb_header->length = size;\n\theader->cb_context = SVGA_CB_CONTEXT_DEVICE;\n\tspin_lock(&man->lock);\n\tstatus = vmw_cmdbuf_header_submit(header);\n\tspin_unlock(&man->lock);\n\tvmw_cmdbuf_header_free(header);\n\n\tif (status != SVGA_CB_STATUS_COMPLETED) {\n\t\tDRM_ERROR(\"Device context command failed with status %d\\n\",\n\t\t\t  status);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int vmw_cmdbuf_preempt(struct vmw_cmdbuf_man *man, u32 context)\n{\n\tstruct {\n\t\tuint32 id;\n\t\tSVGADCCmdPreempt body;\n\t} __packed cmd;\n\n\tcmd.id = SVGA_DC_CMD_PREEMPT;\n\tcmd.body.context = SVGA_CB_CONTEXT_0 + context;\n\tcmd.body.ignoreIDZero = 0;\n\n\treturn vmw_cmdbuf_send_device_command(man, &cmd, sizeof(cmd));\n}\n\n\n \nstatic int vmw_cmdbuf_startstop(struct vmw_cmdbuf_man *man, u32 context,\n\t\t\t\tbool enable)\n{\n\tstruct {\n\t\tuint32 id;\n\t\tSVGADCCmdStartStop body;\n\t} __packed cmd;\n\n\tcmd.id = SVGA_DC_CMD_START_STOP_CONTEXT;\n\tcmd.body.enable = (enable) ? 1 : 0;\n\tcmd.body.context = SVGA_CB_CONTEXT_0 + context;\n\n\treturn vmw_cmdbuf_send_device_command(man, &cmd, sizeof(cmd));\n}\n\n \nint vmw_cmdbuf_set_pool_size(struct vmw_cmdbuf_man *man, size_t size)\n{\n\tstruct vmw_private *dev_priv = man->dev_priv;\n\tint ret;\n\n\tif (man->has_pool)\n\t\treturn -EINVAL;\n\n\t \n\tsize = PAGE_ALIGN(size);\n\tman->map = dma_alloc_coherent(dev_priv->drm.dev, size,\n\t\t\t\t      &man->handle, GFP_KERNEL);\n\tif (man->map) {\n\t\tman->using_mob = false;\n\t} else {\n\t\tstruct vmw_bo_params bo_params = {\n\t\t\t.domain = VMW_BO_DOMAIN_MOB,\n\t\t\t.busy_domain = VMW_BO_DOMAIN_MOB,\n\t\t\t.bo_type = ttm_bo_type_kernel,\n\t\t\t.size = size,\n\t\t\t.pin = true\n\t\t};\n\t\t \n\t\tif (!(dev_priv->capabilities & SVGA_CAP_DX) ||\n\t\t    !dev_priv->has_mob)\n\t\t\treturn -ENOMEM;\n\n\t\tret = vmw_bo_create(dev_priv, &bo_params, &man->cmd_space);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tman->map = vmw_bo_map_and_cache(man->cmd_space);\n\t\tman->using_mob = man->map;\n\t}\n\n\tman->size = size;\n\tdrm_mm_init(&man->mm, 0, size >> PAGE_SHIFT);\n\n\tman->has_pool = true;\n\n\t \n\tman->default_size = VMW_CMDBUF_INLINE_SIZE;\n\tdrm_info(&dev_priv->drm,\n\t\t \"Using command buffers with %s pool.\\n\",\n\t\t (man->using_mob) ? \"MOB\" : \"DMA\");\n\n\treturn 0;\n}\n\n \nstruct vmw_cmdbuf_man *vmw_cmdbuf_man_create(struct vmw_private *dev_priv)\n{\n\tstruct vmw_cmdbuf_man *man;\n\tstruct vmw_cmdbuf_context *ctx;\n\tunsigned int i;\n\tint ret;\n\n\tif (!(dev_priv->capabilities & SVGA_CAP_COMMAND_BUFFERS))\n\t\treturn ERR_PTR(-ENOSYS);\n\n\tman = kzalloc(sizeof(*man), GFP_KERNEL);\n\tif (!man)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tman->num_contexts = (dev_priv->capabilities & SVGA_CAP_HP_CMD_QUEUE) ?\n\t\t2 : 1;\n\tman->headers = dma_pool_create(\"vmwgfx cmdbuf\",\n\t\t\t\t       dev_priv->drm.dev,\n\t\t\t\t       sizeof(SVGACBHeader),\n\t\t\t\t       64, PAGE_SIZE);\n\tif (!man->headers) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_pool;\n\t}\n\n\tman->dheaders = dma_pool_create(\"vmwgfx inline cmdbuf\",\n\t\t\t\t\tdev_priv->drm.dev,\n\t\t\t\t\tsizeof(struct vmw_cmdbuf_dheader),\n\t\t\t\t\t64, PAGE_SIZE);\n\tif (!man->dheaders) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_dpool;\n\t}\n\n\tfor_each_cmdbuf_ctx(man, i, ctx)\n\t\tvmw_cmdbuf_ctx_init(ctx);\n\n\tINIT_LIST_HEAD(&man->error);\n\tspin_lock_init(&man->lock);\n\tmutex_init(&man->cur_mutex);\n\tmutex_init(&man->space_mutex);\n\tmutex_init(&man->error_mutex);\n\tman->default_size = VMW_CMDBUF_INLINE_SIZE;\n\tinit_waitqueue_head(&man->alloc_queue);\n\tinit_waitqueue_head(&man->idle_queue);\n\tman->dev_priv = dev_priv;\n\tman->max_hw_submitted = SVGA_CB_MAX_QUEUED_PER_CONTEXT - 1;\n\tINIT_WORK(&man->work, &vmw_cmdbuf_work_func);\n\tvmw_generic_waiter_add(dev_priv, SVGA_IRQFLAG_ERROR,\n\t\t\t       &dev_priv->error_waiters);\n\tret = vmw_cmdbuf_startstop(man, 0, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"Failed starting command buffer contexts\\n\");\n\t\tvmw_cmdbuf_man_destroy(man);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn man;\n\nout_no_dpool:\n\tdma_pool_destroy(man->headers);\nout_no_pool:\n\tkfree(man);\n\n\treturn ERR_PTR(ret);\n}\n\n \nvoid vmw_cmdbuf_remove_pool(struct vmw_cmdbuf_man *man)\n{\n\tif (!man->has_pool)\n\t\treturn;\n\n\tman->has_pool = false;\n\tman->default_size = VMW_CMDBUF_INLINE_SIZE;\n\t(void) vmw_cmdbuf_idle(man, false, 10*HZ);\n\tif (man->using_mob)\n\t\tvmw_bo_unreference(&man->cmd_space);\n\telse\n\t\tdma_free_coherent(man->dev_priv->drm.dev,\n\t\t\t\t  man->size, man->map, man->handle);\n}\n\n \nvoid vmw_cmdbuf_man_destroy(struct vmw_cmdbuf_man *man)\n{\n\tWARN_ON_ONCE(man->has_pool);\n\t(void) vmw_cmdbuf_idle(man, false, 10*HZ);\n\n\tif (vmw_cmdbuf_startstop(man, 0, false))\n\t\tDRM_ERROR(\"Failed stopping command buffer contexts.\\n\");\n\n\tvmw_generic_waiter_remove(man->dev_priv, SVGA_IRQFLAG_ERROR,\n\t\t\t\t  &man->dev_priv->error_waiters);\n\t(void) cancel_work_sync(&man->work);\n\tdma_pool_destroy(man->dheaders);\n\tdma_pool_destroy(man->headers);\n\tmutex_destroy(&man->cur_mutex);\n\tmutex_destroy(&man->space_mutex);\n\tmutex_destroy(&man->error_mutex);\n\tkfree(man);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}