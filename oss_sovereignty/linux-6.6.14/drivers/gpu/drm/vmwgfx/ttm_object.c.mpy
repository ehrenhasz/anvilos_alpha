{
  "module_name": "ttm_object.c",
  "hash_id": "b766708d60f8e4b555b3deb6b2c52b190bf83d3872836d52ea6d4f8a9cabfc98",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/ttm_object.c",
  "human_readable_source": " \n \n \n \n\n\n#define pr_fmt(fmt) \"[TTM] \" fmt\n\n#include \"ttm_object.h\"\n#include \"vmwgfx_drv.h\"\n\n#include <linux/list.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/atomic.h>\n#include <linux/module.h>\n#include <linux/hashtable.h>\n\nMODULE_IMPORT_NS(DMA_BUF);\n\n#define VMW_TTM_OBJECT_REF_HT_ORDER 10\n\n \nstruct ttm_object_file {\n\tstruct ttm_object_device *tdev;\n\tspinlock_t lock;\n\tstruct list_head ref_list;\n\tDECLARE_HASHTABLE(ref_hash, VMW_TTM_OBJECT_REF_HT_ORDER);\n\tstruct kref refcount;\n};\n\n \n\nstruct ttm_object_device {\n\tspinlock_t object_lock;\n\tatomic_t object_count;\n\tstruct dma_buf_ops ops;\n\tvoid (*dmabuf_release)(struct dma_buf *dma_buf);\n\tstruct idr idr;\n};\n\n \n\nstruct ttm_ref_object {\n\tstruct rcu_head rcu_head;\n\tstruct vmwgfx_hash_item hash;\n\tstruct list_head head;\n\tstruct kref kref;\n\tstruct ttm_base_object *obj;\n\tstruct ttm_object_file *tfile;\n};\n\nstatic void ttm_prime_dmabuf_release(struct dma_buf *dma_buf);\n\nstatic inline struct ttm_object_file *\nttm_object_file_ref(struct ttm_object_file *tfile)\n{\n\tkref_get(&tfile->refcount);\n\treturn tfile;\n}\n\nstatic int ttm_tfile_find_ref_rcu(struct ttm_object_file *tfile,\n\t\t\t\t  uint64_t key,\n\t\t\t\t  struct vmwgfx_hash_item **p_hash)\n{\n\tstruct vmwgfx_hash_item *hash;\n\n\thash_for_each_possible_rcu(tfile->ref_hash, hash, head, key) {\n\t\tif (hash->key == key) {\n\t\t\t*p_hash = hash;\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}\n\nstatic int ttm_tfile_find_ref(struct ttm_object_file *tfile,\n\t\t\t      uint64_t key,\n\t\t\t      struct vmwgfx_hash_item **p_hash)\n{\n\tstruct vmwgfx_hash_item *hash;\n\n\thash_for_each_possible(tfile->ref_hash, hash, head, key) {\n\t\tif (hash->key == key) {\n\t\t\t*p_hash = hash;\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}\n\nstatic void ttm_object_file_destroy(struct kref *kref)\n{\n\tstruct ttm_object_file *tfile =\n\t\tcontainer_of(kref, struct ttm_object_file, refcount);\n\n\tkfree(tfile);\n}\n\n\nstatic inline void ttm_object_file_unref(struct ttm_object_file **p_tfile)\n{\n\tstruct ttm_object_file *tfile = *p_tfile;\n\n\t*p_tfile = NULL;\n\tkref_put(&tfile->refcount, ttm_object_file_destroy);\n}\n\n\nint ttm_base_object_init(struct ttm_object_file *tfile,\n\t\t\t struct ttm_base_object *base,\n\t\t\t bool shareable,\n\t\t\t enum ttm_object_type object_type,\n\t\t\t void (*refcount_release) (struct ttm_base_object **))\n{\n\tstruct ttm_object_device *tdev = tfile->tdev;\n\tint ret;\n\n\tbase->shareable = shareable;\n\tbase->tfile = ttm_object_file_ref(tfile);\n\tbase->refcount_release = refcount_release;\n\tbase->object_type = object_type;\n\tkref_init(&base->refcount);\n\tidr_preload(GFP_KERNEL);\n\tspin_lock(&tdev->object_lock);\n\tret = idr_alloc(&tdev->idr, base, 1, 0, GFP_NOWAIT);\n\tspin_unlock(&tdev->object_lock);\n\tidr_preload_end();\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbase->handle = ret;\n\tret = ttm_ref_object_add(tfile, base, NULL, false);\n\tif (unlikely(ret != 0))\n\t\tgoto out_err1;\n\n\tttm_base_object_unref(&base);\n\n\treturn 0;\nout_err1:\n\tspin_lock(&tdev->object_lock);\n\tidr_remove(&tdev->idr, base->handle);\n\tspin_unlock(&tdev->object_lock);\n\treturn ret;\n}\n\nstatic void ttm_release_base(struct kref *kref)\n{\n\tstruct ttm_base_object *base =\n\t    container_of(kref, struct ttm_base_object, refcount);\n\tstruct ttm_object_device *tdev = base->tfile->tdev;\n\n\tspin_lock(&tdev->object_lock);\n\tidr_remove(&tdev->idr, base->handle);\n\tspin_unlock(&tdev->object_lock);\n\n\t \n\n\tttm_object_file_unref(&base->tfile);\n\tif (base->refcount_release)\n\t\tbase->refcount_release(&base);\n}\n\nvoid ttm_base_object_unref(struct ttm_base_object **p_base)\n{\n\tstruct ttm_base_object *base = *p_base;\n\n\t*p_base = NULL;\n\n\tkref_put(&base->refcount, ttm_release_base);\n}\n\nstruct ttm_base_object *ttm_base_object_lookup(struct ttm_object_file *tfile,\n\t\t\t\t\t       uint64_t key)\n{\n\tstruct ttm_base_object *base = NULL;\n\tstruct vmwgfx_hash_item *hash;\n\tint ret;\n\n\tspin_lock(&tfile->lock);\n\tret = ttm_tfile_find_ref(tfile, key, &hash);\n\n\tif (likely(ret == 0)) {\n\t\tbase = hlist_entry(hash, struct ttm_ref_object, hash)->obj;\n\t\tif (!kref_get_unless_zero(&base->refcount))\n\t\t\tbase = NULL;\n\t}\n\tspin_unlock(&tfile->lock);\n\n\n\treturn base;\n}\n\nstruct ttm_base_object *\nttm_base_object_lookup_for_ref(struct ttm_object_device *tdev, uint64_t key)\n{\n\tstruct ttm_base_object *base;\n\n\trcu_read_lock();\n\tbase = idr_find(&tdev->idr, key);\n\n\tif (base && !kref_get_unless_zero(&base->refcount))\n\t\tbase = NULL;\n\trcu_read_unlock();\n\n\treturn base;\n}\n\nint ttm_ref_object_add(struct ttm_object_file *tfile,\n\t\t       struct ttm_base_object *base,\n\t\t       bool *existed,\n\t\t       bool require_existed)\n{\n\tstruct ttm_ref_object *ref;\n\tstruct vmwgfx_hash_item *hash;\n\tint ret = -EINVAL;\n\n\tif (base->tfile != tfile && !base->shareable)\n\t\treturn -EPERM;\n\n\tif (existed != NULL)\n\t\t*existed = true;\n\n\twhile (ret == -EINVAL) {\n\t\trcu_read_lock();\n\t\tret = ttm_tfile_find_ref_rcu(tfile, base->handle, &hash);\n\n\t\tif (ret == 0) {\n\t\t\tref = hlist_entry(hash, struct ttm_ref_object, hash);\n\t\t\tif (kref_get_unless_zero(&ref->kref)) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\trcu_read_unlock();\n\t\tif (require_existed)\n\t\t\treturn -EPERM;\n\n\t\tref = kmalloc(sizeof(*ref), GFP_KERNEL);\n\t\tif (unlikely(ref == NULL)) {\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tref->hash.key = base->handle;\n\t\tref->obj = base;\n\t\tref->tfile = tfile;\n\t\tkref_init(&ref->kref);\n\n\t\tspin_lock(&tfile->lock);\n\t\thash_add_rcu(tfile->ref_hash, &ref->hash.head, ref->hash.key);\n\t\tret = 0;\n\n\t\tlist_add_tail(&ref->head, &tfile->ref_list);\n\t\tkref_get(&base->refcount);\n\t\tspin_unlock(&tfile->lock);\n\t\tif (existed != NULL)\n\t\t\t*existed = false;\n\t}\n\n\treturn ret;\n}\n\nstatic void __releases(tfile->lock) __acquires(tfile->lock)\nttm_ref_object_release(struct kref *kref)\n{\n\tstruct ttm_ref_object *ref =\n\t    container_of(kref, struct ttm_ref_object, kref);\n\tstruct ttm_object_file *tfile = ref->tfile;\n\n\thash_del_rcu(&ref->hash.head);\n\tlist_del(&ref->head);\n\tspin_unlock(&tfile->lock);\n\n\tttm_base_object_unref(&ref->obj);\n\tkfree_rcu(ref, rcu_head);\n\tspin_lock(&tfile->lock);\n}\n\nint ttm_ref_object_base_unref(struct ttm_object_file *tfile,\n\t\t\t      unsigned long key)\n{\n\tstruct ttm_ref_object *ref;\n\tstruct vmwgfx_hash_item *hash;\n\tint ret;\n\n\tspin_lock(&tfile->lock);\n\tret = ttm_tfile_find_ref(tfile, key, &hash);\n\tif (unlikely(ret != 0)) {\n\t\tspin_unlock(&tfile->lock);\n\t\treturn -EINVAL;\n\t}\n\tref = hlist_entry(hash, struct ttm_ref_object, hash);\n\tkref_put(&ref->kref, ttm_ref_object_release);\n\tspin_unlock(&tfile->lock);\n\treturn 0;\n}\n\nvoid ttm_object_file_release(struct ttm_object_file **p_tfile)\n{\n\tstruct ttm_ref_object *ref;\n\tstruct list_head *list;\n\tstruct ttm_object_file *tfile = *p_tfile;\n\n\t*p_tfile = NULL;\n\tspin_lock(&tfile->lock);\n\n\t \n\n\twhile (!list_empty(&tfile->ref_list)) {\n\t\tlist = tfile->ref_list.next;\n\t\tref = list_entry(list, struct ttm_ref_object, head);\n\t\tttm_ref_object_release(&ref->kref);\n\t}\n\n\tspin_unlock(&tfile->lock);\n\n\tttm_object_file_unref(&tfile);\n}\n\nstruct ttm_object_file *ttm_object_file_init(struct ttm_object_device *tdev)\n{\n\tstruct ttm_object_file *tfile = kmalloc(sizeof(*tfile), GFP_KERNEL);\n\n\tif (unlikely(tfile == NULL))\n\t\treturn NULL;\n\n\tspin_lock_init(&tfile->lock);\n\ttfile->tdev = tdev;\n\tkref_init(&tfile->refcount);\n\tINIT_LIST_HEAD(&tfile->ref_list);\n\n\thash_init(tfile->ref_hash);\n\n\treturn tfile;\n}\n\nstruct ttm_object_device *\nttm_object_device_init(const struct dma_buf_ops *ops)\n{\n\tstruct ttm_object_device *tdev = kmalloc(sizeof(*tdev), GFP_KERNEL);\n\n\tif (unlikely(tdev == NULL))\n\t\treturn NULL;\n\n\tspin_lock_init(&tdev->object_lock);\n\tatomic_set(&tdev->object_count, 0);\n\n\t \n\tidr_init_base(&tdev->idr, VMWGFX_NUM_MOB + 1);\n\ttdev->ops = *ops;\n\ttdev->dmabuf_release = tdev->ops.release;\n\ttdev->ops.release = ttm_prime_dmabuf_release;\n\treturn tdev;\n}\n\nvoid ttm_object_device_release(struct ttm_object_device **p_tdev)\n{\n\tstruct ttm_object_device *tdev = *p_tdev;\n\n\t*p_tdev = NULL;\n\n\tWARN_ON_ONCE(!idr_is_empty(&tdev->idr));\n\tidr_destroy(&tdev->idr);\n\n\tkfree(tdev);\n}\n\n \nstatic bool __must_check get_dma_buf_unless_doomed(struct dma_buf *dmabuf)\n{\n\treturn atomic_long_inc_not_zero(&dmabuf->file->f_count) != 0L;\n}\n\n \nstatic void ttm_prime_refcount_release(struct ttm_base_object **p_base)\n{\n\tstruct ttm_base_object *base = *p_base;\n\tstruct ttm_prime_object *prime;\n\n\t*p_base = NULL;\n\tprime = container_of(base, struct ttm_prime_object, base);\n\tBUG_ON(prime->dma_buf != NULL);\n\tmutex_destroy(&prime->mutex);\n\tif (prime->refcount_release)\n\t\tprime->refcount_release(&base);\n}\n\n \nstatic void ttm_prime_dmabuf_release(struct dma_buf *dma_buf)\n{\n\tstruct ttm_prime_object *prime =\n\t\t(struct ttm_prime_object *) dma_buf->priv;\n\tstruct ttm_base_object *base = &prime->base;\n\tstruct ttm_object_device *tdev = base->tfile->tdev;\n\n\tif (tdev->dmabuf_release)\n\t\ttdev->dmabuf_release(dma_buf);\n\tmutex_lock(&prime->mutex);\n\tif (prime->dma_buf == dma_buf)\n\t\tprime->dma_buf = NULL;\n\tmutex_unlock(&prime->mutex);\n\tttm_base_object_unref(&base);\n}\n\n \nint ttm_prime_fd_to_handle(struct ttm_object_file *tfile,\n\t\t\t   int fd, u32 *handle)\n{\n\tstruct ttm_object_device *tdev = tfile->tdev;\n\tstruct dma_buf *dma_buf;\n\tstruct ttm_prime_object *prime;\n\tstruct ttm_base_object *base;\n\tint ret;\n\n\tdma_buf = dma_buf_get(fd);\n\tif (IS_ERR(dma_buf))\n\t\treturn PTR_ERR(dma_buf);\n\n\tif (dma_buf->ops != &tdev->ops)\n\t\treturn -ENOSYS;\n\n\tprime = (struct ttm_prime_object *) dma_buf->priv;\n\tbase = &prime->base;\n\t*handle = base->handle;\n\tret = ttm_ref_object_add(tfile, base, NULL, false);\n\n\tdma_buf_put(dma_buf);\n\n\treturn ret;\n}\n\n \nint ttm_prime_handle_to_fd(struct ttm_object_file *tfile,\n\t\t\t   uint32_t handle, uint32_t flags,\n\t\t\t   int *prime_fd)\n{\n\tstruct ttm_object_device *tdev = tfile->tdev;\n\tstruct ttm_base_object *base;\n\tstruct dma_buf *dma_buf;\n\tstruct ttm_prime_object *prime;\n\tint ret;\n\n\tbase = ttm_base_object_lookup(tfile, handle);\n\tif (unlikely(base == NULL ||\n\t\t     base->object_type != ttm_prime_type)) {\n\t\tret = -ENOENT;\n\t\tgoto out_unref;\n\t}\n\n\tprime = container_of(base, struct ttm_prime_object, base);\n\tif (unlikely(!base->shareable)) {\n\t\tret = -EPERM;\n\t\tgoto out_unref;\n\t}\n\n\tret = mutex_lock_interruptible(&prime->mutex);\n\tif (unlikely(ret != 0)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto out_unref;\n\t}\n\n\tdma_buf = prime->dma_buf;\n\tif (!dma_buf || !get_dma_buf_unless_doomed(dma_buf)) {\n\t\tDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\n\t\texp_info.ops = &tdev->ops;\n\t\texp_info.size = prime->size;\n\t\texp_info.flags = flags;\n\t\texp_info.priv = prime;\n\n\t\t \n\n\t\tdma_buf = dma_buf_export(&exp_info);\n\t\tif (IS_ERR(dma_buf)) {\n\t\t\tret = PTR_ERR(dma_buf);\n\t\t\tmutex_unlock(&prime->mutex);\n\t\t\tgoto out_unref;\n\t\t}\n\n\t\t \n\t\tbase = NULL;\n\t\tprime->dma_buf = dma_buf;\n\t}\n\tmutex_unlock(&prime->mutex);\n\n\tret = dma_buf_fd(dma_buf, flags);\n\tif (ret >= 0) {\n\t\t*prime_fd = ret;\n\t\tret = 0;\n\t} else\n\t\tdma_buf_put(dma_buf);\n\nout_unref:\n\tif (base)\n\t\tttm_base_object_unref(&base);\n\treturn ret;\n}\n\n \nint ttm_prime_object_init(struct ttm_object_file *tfile, size_t size,\n\t\t\t  struct ttm_prime_object *prime, bool shareable,\n\t\t\t  enum ttm_object_type type,\n\t\t\t  void (*refcount_release) (struct ttm_base_object **))\n{\n\tmutex_init(&prime->mutex);\n\tprime->size = PAGE_ALIGN(size);\n\tprime->real_type = type;\n\tprime->dma_buf = NULL;\n\tprime->refcount_release = refcount_release;\n\treturn ttm_base_object_init(tfile, &prime->base, shareable,\n\t\t\t\t    ttm_prime_type,\n\t\t\t\t    ttm_prime_refcount_release);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}