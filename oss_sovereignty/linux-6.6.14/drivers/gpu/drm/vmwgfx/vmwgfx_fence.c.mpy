{
  "module_name": "vmwgfx_fence.c",
  "hash_id": "387494a82818caa0b09d4220258054f03da9bf239a86fac46688e59fce876455",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/vmwgfx_fence.c",
  "human_readable_source": "\n \n\n#include <linux/sched/signal.h>\n\n#include \"vmwgfx_drv.h\"\n\n#define VMW_FENCE_WRAP (1 << 31)\n\nstruct vmw_fence_manager {\n\tint num_fence_objects;\n\tstruct vmw_private *dev_priv;\n\tspinlock_t lock;\n\tstruct list_head fence_list;\n\tstruct work_struct work;\n\tbool fifo_down;\n\tstruct list_head cleanup_list;\n\tuint32_t pending_actions[VMW_ACTION_MAX];\n\tstruct mutex goal_irq_mutex;\n\tbool goal_irq_on;  \n\tbool seqno_valid;  \n\tu64 ctx;\n};\n\nstruct vmw_user_fence {\n\tstruct ttm_base_object base;\n\tstruct vmw_fence_obj fence;\n};\n\n \nstruct vmw_event_fence_action {\n\tstruct vmw_fence_action action;\n\n\tstruct drm_pending_event *event;\n\tstruct vmw_fence_obj *fence;\n\tstruct drm_device *dev;\n\n\tuint32_t *tv_sec;\n\tuint32_t *tv_usec;\n};\n\nstatic struct vmw_fence_manager *\nfman_from_fence(struct vmw_fence_obj *fence)\n{\n\treturn container_of(fence->base.lock, struct vmw_fence_manager, lock);\n}\n\nstatic u32 vmw_fence_goal_read(struct vmw_private *vmw)\n{\n\tif ((vmw->capabilities2 & SVGA_CAP2_EXTRA_REGS) != 0)\n\t\treturn vmw_read(vmw, SVGA_REG_FENCE_GOAL);\n\telse\n\t\treturn vmw_fifo_mem_read(vmw, SVGA_FIFO_FENCE_GOAL);\n}\n\nstatic void vmw_fence_goal_write(struct vmw_private *vmw, u32 value)\n{\n\tif ((vmw->capabilities2 & SVGA_CAP2_EXTRA_REGS) != 0)\n\t\tvmw_write(vmw, SVGA_REG_FENCE_GOAL, value);\n\telse\n\t\tvmw_fifo_mem_write(vmw, SVGA_FIFO_FENCE_GOAL, value);\n}\n\n \n\nstatic void vmw_fence_obj_destroy(struct dma_fence *f)\n{\n\tstruct vmw_fence_obj *fence =\n\t\tcontainer_of(f, struct vmw_fence_obj, base);\n\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\n\tspin_lock(&fman->lock);\n\tlist_del_init(&fence->head);\n\t--fman->num_fence_objects;\n\tspin_unlock(&fman->lock);\n\tfence->destroy(fence);\n}\n\nstatic const char *vmw_fence_get_driver_name(struct dma_fence *f)\n{\n\treturn \"vmwgfx\";\n}\n\nstatic const char *vmw_fence_get_timeline_name(struct dma_fence *f)\n{\n\treturn \"svga\";\n}\n\nstatic bool vmw_fence_enable_signaling(struct dma_fence *f)\n{\n\tstruct vmw_fence_obj *fence =\n\t\tcontainer_of(f, struct vmw_fence_obj, base);\n\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\tstruct vmw_private *dev_priv = fman->dev_priv;\n\n\tu32 seqno = vmw_fence_read(dev_priv);\n\tif (seqno - fence->base.seqno < VMW_FENCE_WRAP)\n\t\treturn false;\n\n\treturn true;\n}\n\nstruct vmwgfx_wait_cb {\n\tstruct dma_fence_cb base;\n\tstruct task_struct *task;\n};\n\nstatic void\nvmwgfx_wait_cb(struct dma_fence *fence, struct dma_fence_cb *cb)\n{\n\tstruct vmwgfx_wait_cb *wait =\n\t\tcontainer_of(cb, struct vmwgfx_wait_cb, base);\n\n\twake_up_process(wait->task);\n}\n\nstatic void __vmw_fences_update(struct vmw_fence_manager *fman);\n\nstatic long vmw_fence_wait(struct dma_fence *f, bool intr, signed long timeout)\n{\n\tstruct vmw_fence_obj *fence =\n\t\tcontainer_of(f, struct vmw_fence_obj, base);\n\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\tstruct vmw_private *dev_priv = fman->dev_priv;\n\tstruct vmwgfx_wait_cb cb;\n\tlong ret = timeout;\n\n\tif (likely(vmw_fence_obj_signaled(fence)))\n\t\treturn timeout;\n\n\tvmw_seqno_waiter_add(dev_priv);\n\n\tspin_lock(f->lock);\n\n\tif (test_bit(DMA_FENCE_FLAG_SIGNALED_BIT, &f->flags))\n\t\tgoto out;\n\n\tif (intr && signal_pending(current)) {\n\t\tret = -ERESTARTSYS;\n\t\tgoto out;\n\t}\n\n\tcb.base.func = vmwgfx_wait_cb;\n\tcb.task = current;\n\tlist_add(&cb.base.node, &f->cb_list);\n\n\tfor (;;) {\n\t\t__vmw_fences_update(fman);\n\n\t\t \n\t\tif (intr)\n\t\t\t__set_current_state(TASK_INTERRUPTIBLE);\n\t\telse\n\t\t\t__set_current_state(TASK_UNINTERRUPTIBLE);\n\n\t\tif (test_bit(DMA_FENCE_FLAG_SIGNALED_BIT, &f->flags)) {\n\t\t\tif (ret == 0 && timeout > 0)\n\t\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (intr && signal_pending(current)) {\n\t\t\tret = -ERESTARTSYS;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ret == 0)\n\t\t\tbreak;\n\n\t\tspin_unlock(f->lock);\n\n\t\tret = schedule_timeout(ret);\n\n\t\tspin_lock(f->lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\tif (!list_empty(&cb.base.node))\n\t\tlist_del(&cb.base.node);\n\nout:\n\tspin_unlock(f->lock);\n\n\tvmw_seqno_waiter_remove(dev_priv);\n\n\treturn ret;\n}\n\nstatic const struct dma_fence_ops vmw_fence_ops = {\n\t.get_driver_name = vmw_fence_get_driver_name,\n\t.get_timeline_name = vmw_fence_get_timeline_name,\n\t.enable_signaling = vmw_fence_enable_signaling,\n\t.wait = vmw_fence_wait,\n\t.release = vmw_fence_obj_destroy,\n};\n\n\n \n\nstatic void vmw_fence_work_func(struct work_struct *work)\n{\n\tstruct vmw_fence_manager *fman =\n\t\tcontainer_of(work, struct vmw_fence_manager, work);\n\tstruct list_head list;\n\tstruct vmw_fence_action *action, *next_action;\n\tbool seqno_valid;\n\n\tdo {\n\t\tINIT_LIST_HEAD(&list);\n\t\tmutex_lock(&fman->goal_irq_mutex);\n\n\t\tspin_lock(&fman->lock);\n\t\tlist_splice_init(&fman->cleanup_list, &list);\n\t\tseqno_valid = fman->seqno_valid;\n\t\tspin_unlock(&fman->lock);\n\n\t\tif (!seqno_valid && fman->goal_irq_on) {\n\t\t\tfman->goal_irq_on = false;\n\t\t\tvmw_goal_waiter_remove(fman->dev_priv);\n\t\t}\n\t\tmutex_unlock(&fman->goal_irq_mutex);\n\n\t\tif (list_empty(&list))\n\t\t\treturn;\n\n\t\t \n\n\t\tlist_for_each_entry_safe(action, next_action, &list, head) {\n\t\t\tlist_del_init(&action->head);\n\t\t\tif (action->cleanup)\n\t\t\t\taction->cleanup(action);\n\t\t}\n\t} while (1);\n}\n\nstruct vmw_fence_manager *vmw_fence_manager_init(struct vmw_private *dev_priv)\n{\n\tstruct vmw_fence_manager *fman = kzalloc(sizeof(*fman), GFP_KERNEL);\n\n\tif (unlikely(!fman))\n\t\treturn NULL;\n\n\tfman->dev_priv = dev_priv;\n\tspin_lock_init(&fman->lock);\n\tINIT_LIST_HEAD(&fman->fence_list);\n\tINIT_LIST_HEAD(&fman->cleanup_list);\n\tINIT_WORK(&fman->work, &vmw_fence_work_func);\n\tfman->fifo_down = true;\n\tmutex_init(&fman->goal_irq_mutex);\n\tfman->ctx = dma_fence_context_alloc(1);\n\n\treturn fman;\n}\n\nvoid vmw_fence_manager_takedown(struct vmw_fence_manager *fman)\n{\n\tbool lists_empty;\n\n\t(void) cancel_work_sync(&fman->work);\n\n\tspin_lock(&fman->lock);\n\tlists_empty = list_empty(&fman->fence_list) &&\n\t\tlist_empty(&fman->cleanup_list);\n\tspin_unlock(&fman->lock);\n\n\tBUG_ON(!lists_empty);\n\tkfree(fman);\n}\n\nstatic int vmw_fence_obj_init(struct vmw_fence_manager *fman,\n\t\t\t      struct vmw_fence_obj *fence, u32 seqno,\n\t\t\t      void (*destroy) (struct vmw_fence_obj *fence))\n{\n\tint ret = 0;\n\n\tdma_fence_init(&fence->base, &vmw_fence_ops, &fman->lock,\n\t\t       fman->ctx, seqno);\n\tINIT_LIST_HEAD(&fence->seq_passed_actions);\n\tfence->destroy = destroy;\n\n\tspin_lock(&fman->lock);\n\tif (unlikely(fman->fifo_down)) {\n\t\tret = -EBUSY;\n\t\tgoto out_unlock;\n\t}\n\tlist_add_tail(&fence->head, &fman->fence_list);\n\t++fman->num_fence_objects;\n\nout_unlock:\n\tspin_unlock(&fman->lock);\n\treturn ret;\n\n}\n\nstatic void vmw_fences_perform_actions(struct vmw_fence_manager *fman,\n\t\t\t\tstruct list_head *list)\n{\n\tstruct vmw_fence_action *action, *next_action;\n\n\tlist_for_each_entry_safe(action, next_action, list, head) {\n\t\tlist_del_init(&action->head);\n\t\tfman->pending_actions[action->type]--;\n\t\tif (action->seq_passed != NULL)\n\t\t\taction->seq_passed(action);\n\n\t\t \n\n\t\tlist_add_tail(&action->head, &fman->cleanup_list);\n\t}\n}\n\n \nstatic bool vmw_fence_goal_new_locked(struct vmw_fence_manager *fman,\n\t\t\t\t      u32 passed_seqno)\n{\n\tu32 goal_seqno;\n\tstruct vmw_fence_obj *fence;\n\n\tif (likely(!fman->seqno_valid))\n\t\treturn false;\n\n\tgoal_seqno = vmw_fence_goal_read(fman->dev_priv);\n\tif (likely(passed_seqno - goal_seqno >= VMW_FENCE_WRAP))\n\t\treturn false;\n\n\tfman->seqno_valid = false;\n\tlist_for_each_entry(fence, &fman->fence_list, head) {\n\t\tif (!list_empty(&fence->seq_passed_actions)) {\n\t\t\tfman->seqno_valid = true;\n\t\t\tvmw_fence_goal_write(fman->dev_priv,\n\t\t\t\t\t     fence->base.seqno);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}\n\n\n \nstatic bool vmw_fence_goal_check_locked(struct vmw_fence_obj *fence)\n{\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\tu32 goal_seqno;\n\n\tif (dma_fence_is_signaled_locked(&fence->base))\n\t\treturn false;\n\n\tgoal_seqno = vmw_fence_goal_read(fman->dev_priv);\n\tif (likely(fman->seqno_valid &&\n\t\t   goal_seqno - fence->base.seqno < VMW_FENCE_WRAP))\n\t\treturn false;\n\n\tvmw_fence_goal_write(fman->dev_priv, fence->base.seqno);\n\tfman->seqno_valid = true;\n\n\treturn true;\n}\n\nstatic void __vmw_fences_update(struct vmw_fence_manager *fman)\n{\n\tstruct vmw_fence_obj *fence, *next_fence;\n\tstruct list_head action_list;\n\tbool needs_rerun;\n\tuint32_t seqno, new_seqno;\n\n\tseqno = vmw_fence_read(fman->dev_priv);\nrerun:\n\tlist_for_each_entry_safe(fence, next_fence, &fman->fence_list, head) {\n\t\tif (seqno - fence->base.seqno < VMW_FENCE_WRAP) {\n\t\t\tlist_del_init(&fence->head);\n\t\t\tdma_fence_signal_locked(&fence->base);\n\t\t\tINIT_LIST_HEAD(&action_list);\n\t\t\tlist_splice_init(&fence->seq_passed_actions,\n\t\t\t\t\t &action_list);\n\t\t\tvmw_fences_perform_actions(fman, &action_list);\n\t\t} else\n\t\t\tbreak;\n\t}\n\n\t \n\n\tneeds_rerun = vmw_fence_goal_new_locked(fman, seqno);\n\tif (unlikely(needs_rerun)) {\n\t\tnew_seqno = vmw_fence_read(fman->dev_priv);\n\t\tif (new_seqno != seqno) {\n\t\t\tseqno = new_seqno;\n\t\t\tgoto rerun;\n\t\t}\n\t}\n\n\tif (!list_empty(&fman->cleanup_list))\n\t\t(void) schedule_work(&fman->work);\n}\n\nvoid vmw_fences_update(struct vmw_fence_manager *fman)\n{\n\tspin_lock(&fman->lock);\n\t__vmw_fences_update(fman);\n\tspin_unlock(&fman->lock);\n}\n\nbool vmw_fence_obj_signaled(struct vmw_fence_obj *fence)\n{\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\n\tif (test_bit(DMA_FENCE_FLAG_SIGNALED_BIT, &fence->base.flags))\n\t\treturn true;\n\n\tvmw_fences_update(fman);\n\n\treturn dma_fence_is_signaled(&fence->base);\n}\n\nint vmw_fence_obj_wait(struct vmw_fence_obj *fence, bool lazy,\n\t\t       bool interruptible, unsigned long timeout)\n{\n\tlong ret = dma_fence_wait_timeout(&fence->base, interruptible, timeout);\n\n\tif (likely(ret > 0))\n\t\treturn 0;\n\telse if (ret == 0)\n\t\treturn -EBUSY;\n\telse\n\t\treturn ret;\n}\n\nstatic void vmw_fence_destroy(struct vmw_fence_obj *fence)\n{\n\tdma_fence_free(&fence->base);\n}\n\nint vmw_fence_create(struct vmw_fence_manager *fman,\n\t\t     uint32_t seqno,\n\t\t     struct vmw_fence_obj **p_fence)\n{\n\tstruct vmw_fence_obj *fence;\n \tint ret;\n\n\tfence = kzalloc(sizeof(*fence), GFP_KERNEL);\n\tif (unlikely(!fence))\n\t\treturn -ENOMEM;\n\n\tret = vmw_fence_obj_init(fman, fence, seqno,\n\t\t\t\t vmw_fence_destroy);\n\tif (unlikely(ret != 0))\n\t\tgoto out_err_init;\n\n\t*p_fence = fence;\n\treturn 0;\n\nout_err_init:\n\tkfree(fence);\n\treturn ret;\n}\n\n\nstatic void vmw_user_fence_destroy(struct vmw_fence_obj *fence)\n{\n\tstruct vmw_user_fence *ufence =\n\t\tcontainer_of(fence, struct vmw_user_fence, fence);\n\n\tttm_base_object_kfree(ufence, base);\n}\n\nstatic void vmw_user_fence_base_release(struct ttm_base_object **p_base)\n{\n\tstruct ttm_base_object *base = *p_base;\n\tstruct vmw_user_fence *ufence =\n\t\tcontainer_of(base, struct vmw_user_fence, base);\n\tstruct vmw_fence_obj *fence = &ufence->fence;\n\n\t*p_base = NULL;\n\tvmw_fence_obj_unreference(&fence);\n}\n\nint vmw_user_fence_create(struct drm_file *file_priv,\n\t\t\t  struct vmw_fence_manager *fman,\n\t\t\t  uint32_t seqno,\n\t\t\t  struct vmw_fence_obj **p_fence,\n\t\t\t  uint32_t *p_handle)\n{\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_user_fence *ufence;\n\tstruct vmw_fence_obj *tmp;\n\tint ret;\n\n\tufence = kzalloc(sizeof(*ufence), GFP_KERNEL);\n\tif (unlikely(!ufence)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_object;\n\t}\n\n\tret = vmw_fence_obj_init(fman, &ufence->fence, seqno,\n\t\t\t\t vmw_user_fence_destroy);\n\tif (unlikely(ret != 0)) {\n\t\tkfree(ufence);\n\t\tgoto out_no_object;\n\t}\n\n\t \n\ttmp = vmw_fence_obj_reference(&ufence->fence);\n\n\tret = ttm_base_object_init(tfile, &ufence->base, false,\n\t\t\t\t   VMW_RES_FENCE,\n\t\t\t\t   &vmw_user_fence_base_release);\n\n\n\tif (unlikely(ret != 0)) {\n\t\t \n\t\tvmw_fence_obj_unreference(&tmp);\n\t\tgoto out_err;\n\t}\n\n\t*p_fence = &ufence->fence;\n\t*p_handle = ufence->base.handle;\n\n\treturn 0;\nout_err:\n\ttmp = &ufence->fence;\n\tvmw_fence_obj_unreference(&tmp);\nout_no_object:\n\treturn ret;\n}\n\n \n\nvoid vmw_fence_fifo_down(struct vmw_fence_manager *fman)\n{\n\tstruct list_head action_list;\n\tint ret;\n\n\t \n\n\tspin_lock(&fman->lock);\n\tfman->fifo_down = true;\n\twhile (!list_empty(&fman->fence_list)) {\n\t\tstruct vmw_fence_obj *fence =\n\t\t\tlist_entry(fman->fence_list.prev, struct vmw_fence_obj,\n\t\t\t\t   head);\n\t\tdma_fence_get(&fence->base);\n\t\tspin_unlock(&fman->lock);\n\n\t\tret = vmw_fence_obj_wait(fence, false, false,\n\t\t\t\t\t VMW_FENCE_WAIT_TIMEOUT);\n\n\t\tif (unlikely(ret != 0)) {\n\t\t\tlist_del_init(&fence->head);\n\t\t\tdma_fence_signal(&fence->base);\n\t\t\tINIT_LIST_HEAD(&action_list);\n\t\t\tlist_splice_init(&fence->seq_passed_actions,\n\t\t\t\t\t &action_list);\n\t\t\tvmw_fences_perform_actions(fman, &action_list);\n\t\t}\n\n\t\tBUG_ON(!list_empty(&fence->head));\n\t\tdma_fence_put(&fence->base);\n\t\tspin_lock(&fman->lock);\n\t}\n\tspin_unlock(&fman->lock);\n}\n\nvoid vmw_fence_fifo_up(struct vmw_fence_manager *fman)\n{\n\tspin_lock(&fman->lock);\n\tfman->fifo_down = false;\n\tspin_unlock(&fman->lock);\n}\n\n\n \nstatic struct ttm_base_object *\nvmw_fence_obj_lookup(struct ttm_object_file *tfile, u32 handle)\n{\n\tstruct ttm_base_object *base = ttm_base_object_lookup(tfile, handle);\n\n\tif (!base) {\n\t\tpr_err(\"Invalid fence object handle 0x%08lx.\\n\",\n\t\t       (unsigned long)handle);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (base->refcount_release != vmw_user_fence_base_release) {\n\t\tpr_err(\"Invalid fence object handle 0x%08lx.\\n\",\n\t\t       (unsigned long)handle);\n\t\tttm_base_object_unref(&base);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\treturn base;\n}\n\n\nint vmw_fence_obj_wait_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file_priv)\n{\n\tstruct drm_vmw_fence_wait_arg *arg =\n\t    (struct drm_vmw_fence_wait_arg *)data;\n\tunsigned long timeout;\n\tstruct ttm_base_object *base;\n\tstruct vmw_fence_obj *fence;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tuint64_t wait_timeout = ((uint64_t)arg->timeout_us * HZ);\n\n\t \n\n\twait_timeout = (wait_timeout >> 20) + (wait_timeout >> 24) -\n\t  (wait_timeout >> 26);\n\n\tif (!arg->cookie_valid) {\n\t\targ->cookie_valid = 1;\n\t\targ->kernel_cookie = jiffies + wait_timeout;\n\t}\n\n\tbase = vmw_fence_obj_lookup(tfile, arg->handle);\n\tif (IS_ERR(base))\n\t\treturn PTR_ERR(base);\n\n\tfence = &(container_of(base, struct vmw_user_fence, base)->fence);\n\n\ttimeout = jiffies;\n\tif (time_after_eq(timeout, (unsigned long)arg->kernel_cookie)) {\n\t\tret = ((vmw_fence_obj_signaled(fence)) ?\n\t\t       0 : -EBUSY);\n\t\tgoto out;\n\t}\n\n\ttimeout = (unsigned long)arg->kernel_cookie - timeout;\n\n\tret = vmw_fence_obj_wait(fence, arg->lazy, true, timeout);\n\nout:\n\tttm_base_object_unref(&base);\n\n\t \n\n\tif (ret == 0 && (arg->wait_options & DRM_VMW_WAIT_OPTION_UNREF))\n\t\treturn ttm_ref_object_base_unref(tfile, arg->handle);\n\treturn ret;\n}\n\nint vmw_fence_obj_signaled_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t struct drm_file *file_priv)\n{\n\tstruct drm_vmw_fence_signaled_arg *arg =\n\t\t(struct drm_vmw_fence_signaled_arg *) data;\n\tstruct ttm_base_object *base;\n\tstruct vmw_fence_obj *fence;\n\tstruct vmw_fence_manager *fman;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\n\tbase = vmw_fence_obj_lookup(tfile, arg->handle);\n\tif (IS_ERR(base))\n\t\treturn PTR_ERR(base);\n\n\tfence = &(container_of(base, struct vmw_user_fence, base)->fence);\n\tfman = fman_from_fence(fence);\n\n\targ->signaled = vmw_fence_obj_signaled(fence);\n\n\targ->signaled_flags = arg->flags;\n\tspin_lock(&fman->lock);\n\targ->passed_seqno = dev_priv->last_read_seqno;\n\tspin_unlock(&fman->lock);\n\n\tttm_base_object_unref(&base);\n\n\treturn 0;\n}\n\n\nint vmw_fence_obj_unref_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *file_priv)\n{\n\tstruct drm_vmw_fence_arg *arg =\n\t\t(struct drm_vmw_fence_arg *) data;\n\n\treturn ttm_ref_object_base_unref(vmw_fpriv(file_priv)->tfile,\n\t\t\t\t\t arg->handle);\n}\n\n \nstatic void vmw_event_fence_action_seq_passed(struct vmw_fence_action *action)\n{\n\tstruct vmw_event_fence_action *eaction =\n\t\tcontainer_of(action, struct vmw_event_fence_action, action);\n\tstruct drm_device *dev = eaction->dev;\n\tstruct drm_pending_event *event = eaction->event;\n\n\tif (unlikely(event == NULL))\n\t\treturn;\n\n\tspin_lock_irq(&dev->event_lock);\n\n\tif (likely(eaction->tv_sec != NULL)) {\n\t\tstruct timespec64 ts;\n\n\t\tktime_get_ts64(&ts);\n\t\t \n\t\t*eaction->tv_sec = ts.tv_sec;\n\t\t*eaction->tv_usec = ts.tv_nsec / NSEC_PER_USEC;\n\t}\n\n\tdrm_send_event_locked(dev, eaction->event);\n\teaction->event = NULL;\n\tspin_unlock_irq(&dev->event_lock);\n}\n\n \nstatic void vmw_event_fence_action_cleanup(struct vmw_fence_action *action)\n{\n\tstruct vmw_event_fence_action *eaction =\n\t\tcontainer_of(action, struct vmw_event_fence_action, action);\n\n\tvmw_fence_obj_unreference(&eaction->fence);\n\tkfree(eaction);\n}\n\n\n \nstatic void vmw_fence_obj_add_action(struct vmw_fence_obj *fence,\n\t\t\t      struct vmw_fence_action *action)\n{\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\tbool run_update = false;\n\n\tmutex_lock(&fman->goal_irq_mutex);\n\tspin_lock(&fman->lock);\n\n\tfman->pending_actions[action->type]++;\n\tif (dma_fence_is_signaled_locked(&fence->base)) {\n\t\tstruct list_head action_list;\n\n\t\tINIT_LIST_HEAD(&action_list);\n\t\tlist_add_tail(&action->head, &action_list);\n\t\tvmw_fences_perform_actions(fman, &action_list);\n\t} else {\n\t\tlist_add_tail(&action->head, &fence->seq_passed_actions);\n\n\t\t \n\t\trun_update = vmw_fence_goal_check_locked(fence);\n\t}\n\n\tspin_unlock(&fman->lock);\n\n\tif (run_update) {\n\t\tif (!fman->goal_irq_on) {\n\t\t\tfman->goal_irq_on = true;\n\t\t\tvmw_goal_waiter_add(fman->dev_priv);\n\t\t}\n\t\tvmw_fences_update(fman);\n\t}\n\tmutex_unlock(&fman->goal_irq_mutex);\n\n}\n\n \n\nint vmw_event_fence_action_queue(struct drm_file *file_priv,\n\t\t\t\t struct vmw_fence_obj *fence,\n\t\t\t\t struct drm_pending_event *event,\n\t\t\t\t uint32_t *tv_sec,\n\t\t\t\t uint32_t *tv_usec,\n\t\t\t\t bool interruptible)\n{\n\tstruct vmw_event_fence_action *eaction;\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\n\teaction = kzalloc(sizeof(*eaction), GFP_KERNEL);\n\tif (unlikely(!eaction))\n\t\treturn -ENOMEM;\n\n\teaction->event = event;\n\n\teaction->action.seq_passed = vmw_event_fence_action_seq_passed;\n\teaction->action.cleanup = vmw_event_fence_action_cleanup;\n\teaction->action.type = VMW_ACTION_EVENT;\n\n\teaction->fence = vmw_fence_obj_reference(fence);\n\teaction->dev = &fman->dev_priv->drm;\n\teaction->tv_sec = tv_sec;\n\teaction->tv_usec = tv_usec;\n\n\tvmw_fence_obj_add_action(fence, &eaction->action);\n\n\treturn 0;\n}\n\nstruct vmw_event_fence_pending {\n\tstruct drm_pending_event base;\n\tstruct drm_vmw_event_fence event;\n};\n\nstatic int vmw_event_fence_action_create(struct drm_file *file_priv,\n\t\t\t\t  struct vmw_fence_obj *fence,\n\t\t\t\t  uint32_t flags,\n\t\t\t\t  uint64_t user_data,\n\t\t\t\t  bool interruptible)\n{\n\tstruct vmw_event_fence_pending *event;\n\tstruct vmw_fence_manager *fman = fman_from_fence(fence);\n\tstruct drm_device *dev = &fman->dev_priv->drm;\n\tint ret;\n\n\tevent = kzalloc(sizeof(*event), GFP_KERNEL);\n\tif (unlikely(!event)) {\n\t\tDRM_ERROR(\"Failed to allocate an event.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_no_space;\n\t}\n\n\tevent->event.base.type = DRM_VMW_EVENT_FENCE_SIGNALED;\n\tevent->event.base.length = sizeof(*event);\n\tevent->event.user_data = user_data;\n\n\tret = drm_event_reserve_init(dev, file_priv, &event->base, &event->event.base);\n\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Failed to allocate event space for this file.\\n\");\n\t\tkfree(event);\n\t\tgoto out_no_space;\n\t}\n\n\tif (flags & DRM_VMW_FE_FLAG_REQ_TIME)\n\t\tret = vmw_event_fence_action_queue(file_priv, fence,\n\t\t\t\t\t\t   &event->base,\n\t\t\t\t\t\t   &event->event.tv_sec,\n\t\t\t\t\t\t   &event->event.tv_usec,\n\t\t\t\t\t\t   interruptible);\n\telse\n\t\tret = vmw_event_fence_action_queue(file_priv, fence,\n\t\t\t\t\t\t   &event->base,\n\t\t\t\t\t\t   NULL,\n\t\t\t\t\t\t   NULL,\n\t\t\t\t\t\t   interruptible);\n\tif (ret != 0)\n\t\tgoto out_no_queue;\n\n\treturn 0;\n\nout_no_queue:\n\tdrm_event_cancel_free(dev, &event->base);\nout_no_space:\n\treturn ret;\n}\n\nint vmw_fence_event_ioctl(struct drm_device *dev, void *data,\n\t\t\t  struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct drm_vmw_fence_event_arg *arg =\n\t\t(struct drm_vmw_fence_event_arg *) data;\n\tstruct vmw_fence_obj *fence = NULL;\n\tstruct vmw_fpriv *vmw_fp = vmw_fpriv(file_priv);\n\tstruct ttm_object_file *tfile = vmw_fp->tfile;\n\tstruct drm_vmw_fence_rep __user *user_fence_rep =\n\t\t(struct drm_vmw_fence_rep __user *)(unsigned long)\n\t\targ->fence_rep;\n\tuint32_t handle;\n\tint ret;\n\n\t \n\tif (arg->handle) {\n\t\tstruct ttm_base_object *base =\n\t\t\tvmw_fence_obj_lookup(tfile, arg->handle);\n\n\t\tif (IS_ERR(base))\n\t\t\treturn PTR_ERR(base);\n\n\t\tfence = &(container_of(base, struct vmw_user_fence,\n\t\t\t\t       base)->fence);\n\t\t(void) vmw_fence_obj_reference(fence);\n\n\t\tif (user_fence_rep != NULL) {\n\t\t\tret = ttm_ref_object_add(vmw_fp->tfile, base,\n\t\t\t\t\t\t NULL, false);\n\t\t\tif (unlikely(ret != 0)) {\n\t\t\t\tDRM_ERROR(\"Failed to reference a fence \"\n\t\t\t\t\t  \"object.\\n\");\n\t\t\t\tgoto out_no_ref_obj;\n\t\t\t}\n\t\t\thandle = base->handle;\n\t\t}\n\t\tttm_base_object_unref(&base);\n\t}\n\n\t \n\tif (!fence) {\n\t\tret = vmw_execbuf_fence_commands(file_priv, dev_priv,\n\t\t\t\t\t\t &fence,\n\t\t\t\t\t\t (user_fence_rep) ?\n\t\t\t\t\t\t &handle : NULL);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tDRM_ERROR(\"Fence event failed to create fence.\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tBUG_ON(fence == NULL);\n\n\tret = vmw_event_fence_action_create(file_priv, fence,\n\t\t\t\t\t    arg->flags,\n\t\t\t\t\t    arg->user_data,\n\t\t\t\t\t    true);\n\tif (unlikely(ret != 0)) {\n\t\tif (ret != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Failed to attach event to fence.\\n\");\n\t\tgoto out_no_create;\n\t}\n\n\tvmw_execbuf_copy_fence_user(dev_priv, vmw_fp, 0, user_fence_rep, fence,\n\t\t\t\t    handle, -1);\n\tvmw_fence_obj_unreference(&fence);\n\treturn 0;\nout_no_create:\n\tif (user_fence_rep != NULL)\n\t\tttm_ref_object_base_unref(tfile, handle);\nout_no_ref_obj:\n\tvmw_fence_obj_unreference(&fence);\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}