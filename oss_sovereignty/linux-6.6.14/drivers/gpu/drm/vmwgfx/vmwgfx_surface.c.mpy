{
  "module_name": "vmwgfx_surface.c",
  "hash_id": "372a285e10dd47282a5a992661ef731ab5e1a6332a665c5101547ed819ff9f16",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/vmwgfx_surface.c",
  "human_readable_source": "\n \n\n#include \"vmwgfx_bo.h\"\n#include \"vmwgfx_drv.h\"\n#include \"vmwgfx_resource_priv.h\"\n#include \"vmwgfx_so.h\"\n#include \"vmwgfx_binding.h\"\n#include \"vmw_surface_cache.h\"\n#include \"device_include/svga3d_surfacedefs.h\"\n\n#include <drm/ttm/ttm_placement.h>\n\n#define SVGA3D_FLAGS_64(upper32, lower32) (((uint64_t)upper32 << 32) | lower32)\n#define SVGA3D_FLAGS_UPPER_32(svga3d_flags) (svga3d_flags >> 32)\n#define SVGA3D_FLAGS_LOWER_32(svga3d_flags) \\\n\t(svga3d_flags & ((uint64_t)U32_MAX))\n\n \nstruct vmw_user_surface {\n\tstruct ttm_prime_object prime;\n\tstruct vmw_surface srf;\n\tstruct drm_master *master;\n};\n\n \nstruct vmw_surface_offset {\n\tuint32_t face;\n\tuint32_t mip;\n\tuint32_t bo_offset;\n};\n\n \nstruct vmw_surface_dirty {\n\tstruct vmw_surface_cache cache;\n\tu32 num_subres;\n\tSVGA3dBox boxes[];\n};\n\nstatic void vmw_user_surface_free(struct vmw_resource *res);\nstatic struct vmw_resource *\nvmw_user_surface_base_to_res(struct ttm_base_object *base);\nstatic int vmw_legacy_srf_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf);\nstatic int vmw_legacy_srf_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf);\nstatic int vmw_legacy_srf_create(struct vmw_resource *res);\nstatic int vmw_legacy_srf_destroy(struct vmw_resource *res);\nstatic int vmw_gb_surface_create(struct vmw_resource *res);\nstatic int vmw_gb_surface_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf);\nstatic int vmw_gb_surface_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf);\nstatic int vmw_gb_surface_destroy(struct vmw_resource *res);\nstatic int\nvmw_gb_surface_define_internal(struct drm_device *dev,\n\t\t\t       struct drm_vmw_gb_surface_create_ext_req *req,\n\t\t\t       struct drm_vmw_gb_surface_create_rep *rep,\n\t\t\t       struct drm_file *file_priv);\nstatic int\nvmw_gb_surface_reference_internal(struct drm_device *dev,\n\t\t\t\t  struct drm_vmw_surface_arg *req,\n\t\t\t\t  struct drm_vmw_gb_surface_ref_ext_rep *rep,\n\t\t\t\t  struct drm_file *file_priv);\n\nstatic void vmw_surface_dirty_free(struct vmw_resource *res);\nstatic int vmw_surface_dirty_alloc(struct vmw_resource *res);\nstatic int vmw_surface_dirty_sync(struct vmw_resource *res);\nstatic void vmw_surface_dirty_range_add(struct vmw_resource *res, size_t start,\n\t\t\t\t\tsize_t end);\nstatic int vmw_surface_clean(struct vmw_resource *res);\n\nstatic const struct vmw_user_resource_conv user_surface_conv = {\n\t.object_type = VMW_RES_SURFACE,\n\t.base_obj_to_res = vmw_user_surface_base_to_res,\n\t.res_free = vmw_user_surface_free\n};\n\nconst struct vmw_user_resource_conv *user_surface_converter =\n\t&user_surface_conv;\n\nstatic const struct vmw_res_func vmw_legacy_surface_func = {\n\t.res_type = vmw_res_surface,\n\t.needs_guest_memory = false,\n\t.may_evict = true,\n\t.prio = 1,\n\t.dirty_prio = 1,\n\t.type_name = \"legacy surfaces\",\n\t.domain = VMW_BO_DOMAIN_GMR,\n\t.busy_domain = VMW_BO_DOMAIN_GMR | VMW_BO_DOMAIN_VRAM,\n\t.create = &vmw_legacy_srf_create,\n\t.destroy = &vmw_legacy_srf_destroy,\n\t.bind = &vmw_legacy_srf_bind,\n\t.unbind = &vmw_legacy_srf_unbind\n};\n\nstatic const struct vmw_res_func vmw_gb_surface_func = {\n\t.res_type = vmw_res_surface,\n\t.needs_guest_memory = true,\n\t.may_evict = true,\n\t.prio = 1,\n\t.dirty_prio = 2,\n\t.type_name = \"guest backed surfaces\",\n\t.domain = VMW_BO_DOMAIN_MOB,\n\t.busy_domain = VMW_BO_DOMAIN_MOB,\n\t.create = vmw_gb_surface_create,\n\t.destroy = vmw_gb_surface_destroy,\n\t.bind = vmw_gb_surface_bind,\n\t.unbind = vmw_gb_surface_unbind,\n\t.dirty_alloc = vmw_surface_dirty_alloc,\n\t.dirty_free = vmw_surface_dirty_free,\n\t.dirty_sync = vmw_surface_dirty_sync,\n\t.dirty_range_add = vmw_surface_dirty_range_add,\n\t.clean = vmw_surface_clean,\n};\n\n \nstruct vmw_surface_dma {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdSurfaceDMA body;\n\tSVGA3dCopyBox cb;\n\tSVGA3dCmdSurfaceDMASuffix suffix;\n};\n\n \nstruct vmw_surface_define {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdDefineSurface body;\n};\n\n \nstruct vmw_surface_destroy {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdDestroySurface body;\n};\n\n\n \nstatic inline uint32_t vmw_surface_dma_size(const struct vmw_surface *srf)\n{\n\treturn srf->metadata.num_sizes * sizeof(struct vmw_surface_dma);\n}\n\n\n \nstatic inline uint32_t vmw_surface_define_size(const struct vmw_surface *srf)\n{\n\treturn sizeof(struct vmw_surface_define) + srf->metadata.num_sizes *\n\t\tsizeof(SVGA3dSize);\n}\n\n\n \nstatic inline uint32_t vmw_surface_destroy_size(void)\n{\n\treturn sizeof(struct vmw_surface_destroy);\n}\n\n \nstatic void vmw_surface_destroy_encode(uint32_t id,\n\t\t\t\t       void *cmd_space)\n{\n\tstruct vmw_surface_destroy *cmd = (struct vmw_surface_destroy *)\n\t\tcmd_space;\n\n\tcmd->header.id = SVGA_3D_CMD_SURFACE_DESTROY;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.sid = id;\n}\n\n \nstatic void vmw_surface_define_encode(const struct vmw_surface *srf,\n\t\t\t\t      void *cmd_space)\n{\n\tstruct vmw_surface_define *cmd = (struct vmw_surface_define *)\n\t\tcmd_space;\n\tstruct drm_vmw_size *src_size;\n\tSVGA3dSize *cmd_size;\n\tuint32_t cmd_len;\n\tint i;\n\n\tcmd_len = sizeof(cmd->body) + srf->metadata.num_sizes *\n\t\tsizeof(SVGA3dSize);\n\n\tcmd->header.id = SVGA_3D_CMD_SURFACE_DEFINE;\n\tcmd->header.size = cmd_len;\n\tcmd->body.sid = srf->res.id;\n\t \n\tcmd->body.surfaceFlags = (SVGA3dSurface1Flags)srf->metadata.flags;\n\tcmd->body.format = srf->metadata.format;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i)\n\t\tcmd->body.face[i].numMipLevels = srf->metadata.mip_levels[i];\n\n\tcmd += 1;\n\tcmd_size = (SVGA3dSize *) cmd;\n\tsrc_size = srf->metadata.sizes;\n\n\tfor (i = 0; i < srf->metadata.num_sizes; ++i, cmd_size++, src_size++) {\n\t\tcmd_size->width = src_size->width;\n\t\tcmd_size->height = src_size->height;\n\t\tcmd_size->depth = src_size->depth;\n\t}\n}\n\n \nstatic void vmw_surface_dma_encode(struct vmw_surface *srf,\n\t\t\t\t   void *cmd_space,\n\t\t\t\t   const SVGAGuestPtr *ptr,\n\t\t\t\t   bool to_surface)\n{\n\tuint32_t i;\n\tstruct vmw_surface_dma *cmd = (struct vmw_surface_dma *)cmd_space;\n\tconst struct SVGA3dSurfaceDesc *desc =\n\t\tvmw_surface_get_desc(srf->metadata.format);\n\n\tfor (i = 0; i < srf->metadata.num_sizes; ++i) {\n\t\tSVGA3dCmdHeader *header = &cmd->header;\n\t\tSVGA3dCmdSurfaceDMA *body = &cmd->body;\n\t\tSVGA3dCopyBox *cb = &cmd->cb;\n\t\tSVGA3dCmdSurfaceDMASuffix *suffix = &cmd->suffix;\n\t\tconst struct vmw_surface_offset *cur_offset = &srf->offsets[i];\n\t\tconst struct drm_vmw_size *cur_size = &srf->metadata.sizes[i];\n\n\t\theader->id = SVGA_3D_CMD_SURFACE_DMA;\n\t\theader->size = sizeof(*body) + sizeof(*cb) + sizeof(*suffix);\n\n\t\tbody->guest.ptr = *ptr;\n\t\tbody->guest.ptr.offset += cur_offset->bo_offset;\n\t\tbody->guest.pitch = vmw_surface_calculate_pitch(desc, cur_size);\n\t\tbody->host.sid = srf->res.id;\n\t\tbody->host.face = cur_offset->face;\n\t\tbody->host.mipmap = cur_offset->mip;\n\t\tbody->transfer = ((to_surface) ?  SVGA3D_WRITE_HOST_VRAM :\n\t\t\t\t  SVGA3D_READ_HOST_VRAM);\n\t\tcb->x = 0;\n\t\tcb->y = 0;\n\t\tcb->z = 0;\n\t\tcb->srcx = 0;\n\t\tcb->srcy = 0;\n\t\tcb->srcz = 0;\n\t\tcb->w = cur_size->width;\n\t\tcb->h = cur_size->height;\n\t\tcb->d = cur_size->depth;\n\n\t\tsuffix->suffixSize = sizeof(*suffix);\n\t\tsuffix->maximumOffset =\n\t\t\tvmw_surface_get_image_buffer_size(desc, cur_size,\n\t\t\t\t\t\t\t    body->guest.pitch);\n\t\tsuffix->flags.discard = 0;\n\t\tsuffix->flags.unsynchronized = 0;\n\t\tsuffix->flags.reserved = 0;\n\t\t++cmd;\n\t}\n};\n\n\n \nstatic void vmw_hw_surface_destroy(struct vmw_resource *res)\n{\n\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tvoid *cmd;\n\n\tif (res->func->destroy == vmw_gb_surface_destroy) {\n\t\t(void) vmw_gb_surface_destroy(res);\n\t\treturn;\n\t}\n\n\tif (res->id != -1) {\n\n\t\tcmd = VMW_CMD_RESERVE(dev_priv, vmw_surface_destroy_size());\n\t\tif (unlikely(!cmd))\n\t\t\treturn;\n\n\t\tvmw_surface_destroy_encode(res->id, cmd);\n\t\tvmw_cmd_commit(dev_priv, vmw_surface_destroy_size());\n\n\t\t \n\n\t\tmutex_lock(&dev_priv->cmdbuf_mutex);\n\t\tdev_priv->used_memory_size -= res->guest_memory_size;\n\t\tmutex_unlock(&dev_priv->cmdbuf_mutex);\n\t}\n}\n\n \nstatic int vmw_legacy_srf_create(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\tint ret;\n\n\tif (likely(res->id != -1))\n\t\treturn 0;\n\n\tsrf = vmw_res_to_srf(res);\n\tif (unlikely(dev_priv->used_memory_size + res->guest_memory_size >=\n\t\t     dev_priv->memory_size))\n\t\treturn -EBUSY;\n\n\t \n\n\tret = vmw_resource_alloc_id(res);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Failed to allocate a surface id.\\n\");\n\t\tgoto out_no_id;\n\t}\n\n\tif (unlikely(res->id >= SVGA3D_HB_MAX_SURFACE_IDS)) {\n\t\tret = -EBUSY;\n\t\tgoto out_no_fifo;\n\t}\n\n\t \n\n\tsubmit_size = vmw_surface_define_size(srf);\n\tcmd = VMW_CMD_RESERVE(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_fifo;\n\t}\n\n\tvmw_surface_define_encode(srf, cmd);\n\tvmw_cmd_commit(dev_priv, submit_size);\n\tvmw_fifo_resource_inc(dev_priv);\n\n\t \n\n\tdev_priv->used_memory_size += res->guest_memory_size;\n\treturn 0;\n\nout_no_fifo:\n\tvmw_resource_release_id(res);\nout_no_id:\n\treturn ret;\n}\n\n \nstatic int vmw_legacy_srf_dma(struct vmw_resource *res,\n\t\t\t      struct ttm_validate_buffer *val_buf,\n\t\t\t      bool bind)\n{\n\tSVGAGuestPtr ptr;\n\tstruct vmw_fence_obj *fence;\n\tuint32_t submit_size;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tuint8_t *cmd;\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\n\tBUG_ON(!val_buf->bo);\n\tsubmit_size = vmw_surface_dma_size(srf);\n\tcmd = VMW_CMD_RESERVE(dev_priv, submit_size);\n\tif (unlikely(!cmd))\n\t\treturn -ENOMEM;\n\n\tvmw_bo_get_guest_ptr(val_buf->bo, &ptr);\n\tvmw_surface_dma_encode(srf, cmd, &ptr, bind);\n\n\tvmw_cmd_commit(dev_priv, submit_size);\n\n\t \n\n\t(void) vmw_execbuf_fence_commands(NULL, dev_priv,\n\t\t\t\t\t  &fence, NULL);\n\n\tvmw_bo_fence_single(val_buf->bo, fence);\n\n\tif (likely(fence != NULL))\n\t\tvmw_fence_obj_unreference(&fence);\n\n\treturn 0;\n}\n\n \nstatic int vmw_legacy_srf_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf)\n{\n\tif (!res->guest_memory_dirty)\n\t\treturn 0;\n\n\treturn vmw_legacy_srf_dma(res, val_buf, true);\n}\n\n\n \nstatic int vmw_legacy_srf_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf)\n{\n\tif (unlikely(readback))\n\t\treturn vmw_legacy_srf_dma(res, val_buf, false);\n\treturn 0;\n}\n\n \nstatic int vmw_legacy_srf_destroy(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\n\tBUG_ON(res->id == -1);\n\n\t \n\n\tsubmit_size = vmw_surface_destroy_size();\n\tcmd = VMW_CMD_RESERVE(dev_priv, submit_size);\n\tif (unlikely(!cmd))\n\t\treturn -ENOMEM;\n\n\tvmw_surface_destroy_encode(res->id, cmd);\n\tvmw_cmd_commit(dev_priv, submit_size);\n\n\t \n\n\tdev_priv->used_memory_size -= res->guest_memory_size;\n\n\t \n\n\tvmw_resource_release_id(res);\n\tvmw_fifo_resource_dec(dev_priv);\n\n\treturn 0;\n}\n\n\n \nstatic int vmw_surface_init(struct vmw_private *dev_priv,\n\t\t\t    struct vmw_surface *srf,\n\t\t\t    void (*res_free) (struct vmw_resource *res))\n{\n\tint ret;\n\tstruct vmw_resource *res = &srf->res;\n\n\tBUG_ON(!res_free);\n\tret = vmw_resource_init(dev_priv, res, true, res_free,\n\t\t\t\t(dev_priv->has_mob) ? &vmw_gb_surface_func :\n\t\t\t\t&vmw_legacy_surface_func);\n\n\tif (unlikely(ret != 0)) {\n\t\tres_free(res);\n\t\treturn ret;\n\t}\n\n\t \n\n\tINIT_LIST_HEAD(&srf->view_list);\n\tres->hw_destroy = vmw_hw_surface_destroy;\n\treturn ret;\n}\n\n \nstatic struct vmw_resource *\nvmw_user_surface_base_to_res(struct ttm_base_object *base)\n{\n\treturn &(container_of(base, struct vmw_user_surface,\n\t\t\t      prime.base)->srf.res);\n}\n\n \nstatic void vmw_user_surface_free(struct vmw_resource *res)\n{\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tstruct vmw_user_surface *user_srf =\n\t    container_of(srf, struct vmw_user_surface, srf);\n\n\tWARN_ON_ONCE(res->dirty);\n\tif (user_srf->master)\n\t\tdrm_master_put(&user_srf->master);\n\tkfree(srf->offsets);\n\tkfree(srf->metadata.sizes);\n\tkfree(srf->snooper.image);\n\tttm_prime_object_kfree(user_srf, prime);\n}\n\n \nstatic void vmw_user_surface_base_release(struct ttm_base_object **p_base)\n{\n\tstruct ttm_base_object *base = *p_base;\n\tstruct vmw_user_surface *user_srf =\n\t    container_of(base, struct vmw_user_surface, prime.base);\n\tstruct vmw_resource *res = &user_srf->srf.res;\n\n\t*p_base = NULL;\n\tvmw_resource_unreference(&res);\n}\n\n \nint vmw_surface_destroy_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *file_priv)\n{\n\tstruct drm_vmw_surface_arg *arg = (struct drm_vmw_surface_arg *)data;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\n\treturn ttm_ref_object_base_unref(tfile, arg->sid);\n}\n\n \nint vmw_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tstruct vmw_surface_metadata *metadata;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tunion drm_vmw_surface_create_arg *arg =\n\t    (union drm_vmw_surface_create_arg *)data;\n\tstruct drm_vmw_surface_create_req *req = &arg->req;\n\tstruct drm_vmw_surface_arg *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tint i, j;\n\tuint32_t cur_bo_offset;\n\tstruct drm_vmw_size *cur_size;\n\tstruct vmw_surface_offset *cur_offset;\n\tuint32_t num_sizes;\n\tconst SVGA3dSurfaceDesc *desc;\n\n\tnum_sizes = 0;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tif (req->mip_levels[i] > DRM_VMW_MAX_MIP_LEVELS)\n\t\t\treturn -EINVAL;\n\t\tnum_sizes += req->mip_levels[i];\n\t}\n\n\tif (num_sizes > DRM_VMW_MAX_SURFACE_FACES * DRM_VMW_MAX_MIP_LEVELS ||\n\t    num_sizes == 0)\n\t\treturn -EINVAL;\n\n\tdesc = vmw_surface_get_desc(req->format);\n\tif (unlikely(desc->blockDesc == SVGA3DBLOCKDESC_NONE)) {\n\t\tVMW_DEBUG_USER(\"Invalid format %d for surface creation.\\n\",\n\t\t\t       req->format);\n\t\treturn -EINVAL;\n\t}\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_unlock;\n\t}\n\n\tsrf = &user_srf->srf;\n\tmetadata = &srf->metadata;\n\tres = &srf->res;\n\n\t \n\tmetadata->flags = (SVGA3dSurfaceAllFlags)req->flags;\n\tmetadata->format = req->format;\n\tmetadata->scanout = req->scanout;\n\n\tmemcpy(metadata->mip_levels, req->mip_levels,\n\t       sizeof(metadata->mip_levels));\n\tmetadata->num_sizes = num_sizes;\n\tmetadata->sizes =\n\t\tmemdup_array_user((struct drm_vmw_size __user *)(unsigned long)\n\t\t\t    req->size_addr,\n\t\t\t    metadata->num_sizes, sizeof(*metadata->sizes));\n\tif (IS_ERR(metadata->sizes)) {\n\t\tret = PTR_ERR(metadata->sizes);\n\t\tgoto out_no_sizes;\n\t}\n\tsrf->offsets = kmalloc_array(metadata->num_sizes, sizeof(*srf->offsets),\n\t\t\t\t     GFP_KERNEL);\n\tif (unlikely(!srf->offsets)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_offsets;\n\t}\n\n\tmetadata->base_size = *srf->metadata.sizes;\n\tmetadata->autogen_filter = SVGA3D_TEX_FILTER_NONE;\n\tmetadata->multisample_count = 0;\n\tmetadata->multisample_pattern = SVGA3D_MS_PATTERN_NONE;\n\tmetadata->quality_level = SVGA3D_MS_QUALITY_NONE;\n\n\tcur_bo_offset = 0;\n\tcur_offset = srf->offsets;\n\tcur_size = metadata->sizes;\n\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tfor (j = 0; j < metadata->mip_levels[i]; ++j) {\n\t\t\tuint32_t stride = vmw_surface_calculate_pitch(\n\t\t\t\t\t\t  desc, cur_size);\n\n\t\t\tcur_offset->face = i;\n\t\t\tcur_offset->mip = j;\n\t\t\tcur_offset->bo_offset = cur_bo_offset;\n\t\t\tcur_bo_offset += vmw_surface_get_image_buffer_size\n\t\t\t\t(desc, cur_size, stride);\n\t\t\t++cur_offset;\n\t\t\t++cur_size;\n\t\t}\n\t}\n\tres->guest_memory_size = cur_bo_offset;\n\tif (metadata->scanout &&\n\t    metadata->num_sizes == 1 &&\n\t    metadata->sizes[0].width == VMW_CURSOR_SNOOP_WIDTH &&\n\t    metadata->sizes[0].height == VMW_CURSOR_SNOOP_HEIGHT &&\n\t    metadata->format == VMW_CURSOR_SNOOP_FORMAT) {\n\t\tconst struct SVGA3dSurfaceDesc *desc =\n\t\t\tvmw_surface_get_desc(VMW_CURSOR_SNOOP_FORMAT);\n\t\tconst u32 cursor_size_bytes = VMW_CURSOR_SNOOP_WIDTH *\n\t\t\t\t\t      VMW_CURSOR_SNOOP_HEIGHT *\n\t\t\t\t\t      desc->pitchBytesPerBlock;\n\t\tsrf->snooper.image = kzalloc(cursor_size_bytes, GFP_KERNEL);\n\t\tif (!srf->snooper.image) {\n\t\t\tDRM_ERROR(\"Failed to allocate cursor_image\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_no_copy;\n\t\t}\n\t} else {\n\t\tsrf->snooper.image = NULL;\n\t}\n\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile = NULL;\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_file_get_master(file_priv);\n\n\t \n\n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\tif (unlikely(ret != 0))\n\t\tgoto out_unlock;\n\n\t \n\tif (dev_priv->has_mob && req->shareable) {\n\t\tstruct vmw_bo_params params = {\n\t\t\t.domain = VMW_BO_DOMAIN_SYS,\n\t\t\t.busy_domain = VMW_BO_DOMAIN_SYS,\n\t\t\t.bo_type = ttm_bo_type_device,\n\t\t\t.size = res->guest_memory_size,\n\t\t\t.pin = false\n\t\t};\n\n\t\tret = vmw_gem_object_create(dev_priv,\n\t\t\t\t\t    &params,\n\t\t\t\t\t    &res->guest_memory_bo);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tvmw_resource_unreference(&res);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\ttmp = vmw_resource_reference(&srf->res);\n\tret = ttm_prime_object_init(tfile, res->guest_memory_size, &user_srf->prime,\n\t\t\t\t    req->shareable, VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->sid = user_srf->prime.base.handle;\n\tvmw_resource_unreference(&res);\n\n\treturn 0;\nout_no_copy:\n\tkfree(srf->offsets);\nout_no_offsets:\n\tkfree(metadata->sizes);\nout_no_sizes:\n\tttm_prime_object_kfree(user_srf, prime);\nout_unlock:\n\treturn ret;\n}\n\n\nstatic int\nvmw_surface_handle_reference(struct vmw_private *dev_priv,\n\t\t\t     struct drm_file *file_priv,\n\t\t\t     uint32_t u_handle,\n\t\t\t     enum drm_vmw_handle_type handle_type,\n\t\t\t     struct ttm_base_object **base_p)\n{\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_user_surface *user_srf;\n\tuint32_t handle;\n\tstruct ttm_base_object *base;\n\tint ret;\n\n\tif (handle_type == DRM_VMW_HANDLE_PRIME) {\n\t\tret = ttm_prime_fd_to_handle(tfile, u_handle, &handle);\n\t\tif (unlikely(ret != 0))\n\t\t\treturn ret;\n\t} else {\n\t\thandle = u_handle;\n\t}\n\n\tret = -EINVAL;\n\tbase = ttm_base_object_lookup_for_ref(dev_priv->tdev, handle);\n\tif (unlikely(!base)) {\n\t\tVMW_DEBUG_USER(\"Could not find surface to reference.\\n\");\n\t\tgoto out_no_lookup;\n\t}\n\n\tif (unlikely(ttm_base_object_type(base) != VMW_RES_SURFACE)) {\n\t\tVMW_DEBUG_USER(\"Referenced object is not a surface.\\n\");\n\t\tgoto out_bad_resource;\n\t}\n\tif (handle_type != DRM_VMW_HANDLE_PRIME) {\n\t\tbool require_exist = false;\n\n\t\tuser_srf = container_of(base, struct vmw_user_surface,\n\t\t\t\t\tprime.base);\n\n\t\t \n\t\tif (drm_is_primary_client(file_priv) &&\n\t\t    !file_priv->authenticated) {\n\t\t\tret = -EACCES;\n\t\t\tgoto out_bad_resource;\n\t\t}\n\n\t\t \n\t\tif (drm_is_primary_client(file_priv) &&\n\t\t    user_srf->master != file_priv->master)\n\t\t\trequire_exist = true;\n\n\t\tif (unlikely(drm_is_render_client(file_priv)))\n\t\t\trequire_exist = true;\n\n\t\tret = ttm_ref_object_add(tfile, base, NULL, require_exist);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tDRM_ERROR(\"Could not add a reference to a surface.\\n\");\n\t\t\tgoto out_bad_resource;\n\t\t}\n\t}\n\n\t*base_p = base;\n\treturn 0;\n\nout_bad_resource:\n\tttm_base_object_unref(&base);\nout_no_lookup:\n\tif (handle_type == DRM_VMW_HANDLE_PRIME)\n\t\t(void) ttm_ref_object_base_unref(tfile, handle);\n\n\treturn ret;\n}\n\n \nint vmw_surface_reference_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tunion drm_vmw_surface_reference_arg *arg =\n\t    (union drm_vmw_surface_reference_arg *)data;\n\tstruct drm_vmw_surface_arg *req = &arg->req;\n\tstruct drm_vmw_surface_create_req *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_surface *srf;\n\tstruct vmw_user_surface *user_srf;\n\tstruct drm_vmw_size __user *user_sizes;\n\tstruct ttm_base_object *base;\n\tint ret;\n\n\tret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,\n\t\t\t\t\t   req->handle_type, &base);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(base, struct vmw_user_surface, prime.base);\n\tsrf = &user_srf->srf;\n\n\t \n\trep->flags = (uint32_t)srf->metadata.flags;\n\trep->format = srf->metadata.format;\n\tmemcpy(rep->mip_levels, srf->metadata.mip_levels,\n\t       sizeof(srf->metadata.mip_levels));\n\tuser_sizes = (struct drm_vmw_size __user *)(unsigned long)\n\t    rep->size_addr;\n\n\tif (user_sizes)\n\t\tret = copy_to_user(user_sizes, &srf->metadata.base_size,\n\t\t\t\t   sizeof(srf->metadata.base_size));\n\tif (unlikely(ret != 0)) {\n\t\tVMW_DEBUG_USER(\"copy_to_user failed %p %u\\n\", user_sizes,\n\t\t\t       srf->metadata.num_sizes);\n\t\tttm_ref_object_base_unref(tfile, base->handle);\n\t\tret = -EFAULT;\n\t}\n\n\tttm_base_object_unref(&base);\n\n\treturn ret;\n}\n\n \nstatic int vmw_gb_surface_create(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tstruct vmw_surface_metadata *metadata = &srf->metadata;\n\tuint32_t cmd_len, cmd_id, submit_len;\n\tint ret;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface body;\n\t} *cmd;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface_v2 body;\n\t} *cmd2;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface_v3 body;\n\t} *cmd3;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface_v4 body;\n\t} *cmd4;\n\n\tif (likely(res->id != -1))\n\t\treturn 0;\n\n\tvmw_fifo_resource_inc(dev_priv);\n\tret = vmw_resource_alloc_id(res);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Failed to allocate a surface id.\\n\");\n\t\tgoto out_no_id;\n\t}\n\n\tif (unlikely(res->id >= VMWGFX_NUM_GB_SURFACE)) {\n\t\tret = -EBUSY;\n\t\tgoto out_no_fifo;\n\t}\n\n\tif (has_sm5_context(dev_priv) && metadata->array_size > 0) {\n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE_V4;\n\t\tcmd_len = sizeof(cmd4->body);\n\t\tsubmit_len = sizeof(*cmd4);\n\t} else if (has_sm4_1_context(dev_priv) && metadata->array_size > 0) {\n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE_V3;\n\t\tcmd_len = sizeof(cmd3->body);\n\t\tsubmit_len = sizeof(*cmd3);\n\t} else if (metadata->array_size > 0) {\n\t\t \n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE_V2;\n\t\tcmd_len = sizeof(cmd2->body);\n\t\tsubmit_len = sizeof(*cmd2);\n\t} else {\n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE;\n\t\tcmd_len = sizeof(cmd->body);\n\t\tsubmit_len = sizeof(*cmd);\n\t}\n\n\tcmd = VMW_CMD_RESERVE(dev_priv, submit_len);\n\tcmd2 = (typeof(cmd2))cmd;\n\tcmd3 = (typeof(cmd3))cmd;\n\tcmd4 = (typeof(cmd4))cmd;\n\tif (unlikely(!cmd)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_fifo;\n\t}\n\n\tif (has_sm5_context(dev_priv) && metadata->array_size > 0) {\n\t\tcmd4->header.id = cmd_id;\n\t\tcmd4->header.size = cmd_len;\n\t\tcmd4->body.sid = srf->res.id;\n\t\tcmd4->body.surfaceFlags = metadata->flags;\n\t\tcmd4->body.format = metadata->format;\n\t\tcmd4->body.numMipLevels = metadata->mip_levels[0];\n\t\tcmd4->body.multisampleCount = metadata->multisample_count;\n\t\tcmd4->body.multisamplePattern = metadata->multisample_pattern;\n\t\tcmd4->body.qualityLevel = metadata->quality_level;\n\t\tcmd4->body.autogenFilter = metadata->autogen_filter;\n\t\tcmd4->body.size.width = metadata->base_size.width;\n\t\tcmd4->body.size.height = metadata->base_size.height;\n\t\tcmd4->body.size.depth = metadata->base_size.depth;\n\t\tcmd4->body.arraySize = metadata->array_size;\n\t\tcmd4->body.bufferByteStride = metadata->buffer_byte_stride;\n\t} else if (has_sm4_1_context(dev_priv) && metadata->array_size > 0) {\n\t\tcmd3->header.id = cmd_id;\n\t\tcmd3->header.size = cmd_len;\n\t\tcmd3->body.sid = srf->res.id;\n\t\tcmd3->body.surfaceFlags = metadata->flags;\n\t\tcmd3->body.format = metadata->format;\n\t\tcmd3->body.numMipLevels = metadata->mip_levels[0];\n\t\tcmd3->body.multisampleCount = metadata->multisample_count;\n\t\tcmd3->body.multisamplePattern = metadata->multisample_pattern;\n\t\tcmd3->body.qualityLevel = metadata->quality_level;\n\t\tcmd3->body.autogenFilter = metadata->autogen_filter;\n\t\tcmd3->body.size.width = metadata->base_size.width;\n\t\tcmd3->body.size.height = metadata->base_size.height;\n\t\tcmd3->body.size.depth = metadata->base_size.depth;\n\t\tcmd3->body.arraySize = metadata->array_size;\n\t} else if (metadata->array_size > 0) {\n\t\tcmd2->header.id = cmd_id;\n\t\tcmd2->header.size = cmd_len;\n\t\tcmd2->body.sid = srf->res.id;\n\t\tcmd2->body.surfaceFlags = metadata->flags;\n\t\tcmd2->body.format = metadata->format;\n\t\tcmd2->body.numMipLevels = metadata->mip_levels[0];\n\t\tcmd2->body.multisampleCount = metadata->multisample_count;\n\t\tcmd2->body.autogenFilter = metadata->autogen_filter;\n\t\tcmd2->body.size.width = metadata->base_size.width;\n\t\tcmd2->body.size.height = metadata->base_size.height;\n\t\tcmd2->body.size.depth = metadata->base_size.depth;\n\t\tcmd2->body.arraySize = metadata->array_size;\n\t} else {\n\t\tcmd->header.id = cmd_id;\n\t\tcmd->header.size = cmd_len;\n\t\tcmd->body.sid = srf->res.id;\n\t\tcmd->body.surfaceFlags = metadata->flags;\n\t\tcmd->body.format = metadata->format;\n\t\tcmd->body.numMipLevels = metadata->mip_levels[0];\n\t\tcmd->body.multisampleCount = metadata->multisample_count;\n\t\tcmd->body.autogenFilter = metadata->autogen_filter;\n\t\tcmd->body.size.width = metadata->base_size.width;\n\t\tcmd->body.size.height = metadata->base_size.height;\n\t\tcmd->body.size.depth = metadata->base_size.depth;\n\t}\n\n\tvmw_cmd_commit(dev_priv, submit_len);\n\n\treturn 0;\n\nout_no_fifo:\n\tvmw_resource_release_id(res);\nout_no_id:\n\tvmw_fifo_resource_dec(dev_priv);\n\treturn ret;\n}\n\n\nstatic int vmw_gb_surface_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdBindGBSurface body;\n\t} *cmd1;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdUpdateGBSurface body;\n\t} *cmd2;\n\tuint32_t submit_size;\n\tstruct ttm_buffer_object *bo = val_buf->bo;\n\n\tBUG_ON(bo->resource->mem_type != VMW_PL_MOB);\n\n\tsubmit_size = sizeof(*cmd1) + (res->guest_memory_dirty ? sizeof(*cmd2) : 0);\n\n\tcmd1 = VMW_CMD_RESERVE(dev_priv, submit_size);\n\tif (unlikely(!cmd1))\n\t\treturn -ENOMEM;\n\n\tcmd1->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;\n\tcmd1->header.size = sizeof(cmd1->body);\n\tcmd1->body.sid = res->id;\n\tcmd1->body.mobid = bo->resource->start;\n\tif (res->guest_memory_dirty) {\n\t\tcmd2 = (void *) &cmd1[1];\n\t\tcmd2->header.id = SVGA_3D_CMD_UPDATE_GB_SURFACE;\n\t\tcmd2->header.size = sizeof(cmd2->body);\n\t\tcmd2->body.sid = res->id;\n\t}\n\tvmw_cmd_commit(dev_priv, submit_size);\n\n\tif (res->guest_memory_bo->dirty && res->guest_memory_dirty) {\n\t\t \n\t\tvmw_bo_dirty_clear_res(res);\n\t}\n\n\tres->guest_memory_dirty = false;\n\n\treturn 0;\n}\n\nstatic int vmw_gb_surface_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct ttm_buffer_object *bo = val_buf->bo;\n\tstruct vmw_fence_obj *fence;\n\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdReadbackGBSurface body;\n\t} *cmd1;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdInvalidateGBSurface body;\n\t} *cmd2;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdBindGBSurface body;\n\t} *cmd3;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\n\n\tBUG_ON(bo->resource->mem_type != VMW_PL_MOB);\n\n\tsubmit_size = sizeof(*cmd3) + (readback ? sizeof(*cmd1) : sizeof(*cmd2));\n\tcmd = VMW_CMD_RESERVE(dev_priv, submit_size);\n\tif (unlikely(!cmd))\n\t\treturn -ENOMEM;\n\n\tif (readback) {\n\t\tcmd1 = (void *) cmd;\n\t\tcmd1->header.id = SVGA_3D_CMD_READBACK_GB_SURFACE;\n\t\tcmd1->header.size = sizeof(cmd1->body);\n\t\tcmd1->body.sid = res->id;\n\t\tcmd3 = (void *) &cmd1[1];\n\t} else {\n\t\tcmd2 = (void *) cmd;\n\t\tcmd2->header.id = SVGA_3D_CMD_INVALIDATE_GB_SURFACE;\n\t\tcmd2->header.size = sizeof(cmd2->body);\n\t\tcmd2->body.sid = res->id;\n\t\tcmd3 = (void *) &cmd2[1];\n\t}\n\n\tcmd3->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;\n\tcmd3->header.size = sizeof(cmd3->body);\n\tcmd3->body.sid = res->id;\n\tcmd3->body.mobid = SVGA3D_INVALID_ID;\n\n\tvmw_cmd_commit(dev_priv, submit_size);\n\n\t \n\n\t(void) vmw_execbuf_fence_commands(NULL, dev_priv,\n\t\t\t\t\t  &fence, NULL);\n\n\tvmw_bo_fence_single(val_buf->bo, fence);\n\n\tif (likely(fence != NULL))\n\t\tvmw_fence_obj_unreference(&fence);\n\n\treturn 0;\n}\n\nstatic int vmw_gb_surface_destroy(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDestroyGBSurface body;\n\t} *cmd;\n\n\tif (likely(res->id == -1))\n\t\treturn 0;\n\n\tmutex_lock(&dev_priv->binding_mutex);\n\tvmw_view_surface_list_destroy(dev_priv, &srf->view_list);\n\tvmw_binding_res_list_scrub(&res->binding_head);\n\n\tcmd = VMW_CMD_RESERVE(dev_priv, sizeof(*cmd));\n\tif (unlikely(!cmd)) {\n\t\tmutex_unlock(&dev_priv->binding_mutex);\n\t\treturn -ENOMEM;\n\t}\n\n\tcmd->header.id = SVGA_3D_CMD_DESTROY_GB_SURFACE;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.sid = res->id;\n\tvmw_cmd_commit(dev_priv, sizeof(*cmd));\n\tmutex_unlock(&dev_priv->binding_mutex);\n\tvmw_resource_release_id(res);\n\tvmw_fifo_resource_dec(dev_priv);\n\n\treturn 0;\n}\n\n \nint vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file_priv)\n{\n\tunion drm_vmw_gb_surface_create_arg *arg =\n\t    (union drm_vmw_gb_surface_create_arg *)data;\n\tstruct drm_vmw_gb_surface_create_rep *rep = &arg->rep;\n\tstruct drm_vmw_gb_surface_create_ext_req req_ext;\n\n\treq_ext.base = arg->req;\n\treq_ext.version = drm_vmw_gb_surface_v1;\n\treq_ext.svga3d_flags_upper_32_bits = 0;\n\treq_ext.multisample_pattern = SVGA3D_MS_PATTERN_NONE;\n\treq_ext.quality_level = SVGA3D_MS_QUALITY_NONE;\n\treq_ext.buffer_byte_stride = 0;\n\treq_ext.must_be_zero = 0;\n\n\treturn vmw_gb_surface_define_internal(dev, &req_ext, rep, file_priv);\n}\n\n \nint vmw_gb_surface_reference_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t   struct drm_file *file_priv)\n{\n\tunion drm_vmw_gb_surface_reference_arg *arg =\n\t    (union drm_vmw_gb_surface_reference_arg *)data;\n\tstruct drm_vmw_surface_arg *req = &arg->req;\n\tstruct drm_vmw_gb_surface_ref_rep *rep = &arg->rep;\n\tstruct drm_vmw_gb_surface_ref_ext_rep rep_ext;\n\tint ret;\n\n\tret = vmw_gb_surface_reference_internal(dev, req, &rep_ext, file_priv);\n\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\trep->creq = rep_ext.creq.base;\n\trep->crep = rep_ext.crep;\n\n\treturn ret;\n}\n\n \nint vmw_gb_surface_define_ext_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file_priv)\n{\n\tunion drm_vmw_gb_surface_create_ext_arg *arg =\n\t    (union drm_vmw_gb_surface_create_ext_arg *)data;\n\tstruct drm_vmw_gb_surface_create_ext_req *req = &arg->req;\n\tstruct drm_vmw_gb_surface_create_rep *rep = &arg->rep;\n\n\treturn vmw_gb_surface_define_internal(dev, req, rep, file_priv);\n}\n\n \nint vmw_gb_surface_reference_ext_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t   struct drm_file *file_priv)\n{\n\tunion drm_vmw_gb_surface_reference_ext_arg *arg =\n\t    (union drm_vmw_gb_surface_reference_ext_arg *)data;\n\tstruct drm_vmw_surface_arg *req = &arg->req;\n\tstruct drm_vmw_gb_surface_ref_ext_rep *rep = &arg->rep;\n\n\treturn vmw_gb_surface_reference_internal(dev, req, rep, file_priv);\n}\n\n \nstatic int\nvmw_gb_surface_define_internal(struct drm_device *dev,\n\t\t\t       struct drm_vmw_gb_surface_create_ext_req *req,\n\t\t\t       struct drm_vmw_gb_surface_create_rep *rep,\n\t\t\t       struct drm_file *file_priv)\n{\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface_metadata metadata = {0};\n\tstruct vmw_surface *srf;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tint ret = 0;\n\tuint32_t backup_handle = 0;\n\tSVGA3dSurfaceAllFlags svga3d_flags_64 =\n\t\tSVGA3D_FLAGS_64(req->svga3d_flags_upper_32_bits,\n\t\t\t\treq->base.svga3d_flags);\n\n\t \n\tif (req->base.array_size > 0 && !has_sm4_context(dev_priv)) {\n\t\tVMW_DEBUG_USER(\"SM4 surface not supported.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!has_sm4_1_context(dev_priv)) {\n\t\tif (req->svga3d_flags_upper_32_bits != 0)\n\t\t\tret = -EINVAL;\n\n\t\tif (req->base.multisample_count != 0)\n\t\t\tret = -EINVAL;\n\n\t\tif (req->multisample_pattern != SVGA3D_MS_PATTERN_NONE)\n\t\t\tret = -EINVAL;\n\n\t\tif (req->quality_level != SVGA3D_MS_QUALITY_NONE)\n\t\t\tret = -EINVAL;\n\n\t\tif (ret) {\n\t\t\tVMW_DEBUG_USER(\"SM4.1 surface not supported.\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (req->buffer_byte_stride > 0 && !has_sm5_context(dev_priv)) {\n\t\tVMW_DEBUG_USER(\"SM5 surface not supported.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif ((svga3d_flags_64 & SVGA3D_SURFACE_MULTISAMPLE) &&\n\t    req->base.multisample_count == 0) {\n\t\tVMW_DEBUG_USER(\"Invalid sample count.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (req->base.mip_levels > DRM_VMW_MAX_MIP_LEVELS) {\n\t\tVMW_DEBUG_USER(\"Invalid mip level.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmetadata.flags = svga3d_flags_64;\n\tmetadata.format = req->base.format;\n\tmetadata.mip_levels[0] = req->base.mip_levels;\n\tmetadata.multisample_count = req->base.multisample_count;\n\tmetadata.multisample_pattern = req->multisample_pattern;\n\tmetadata.quality_level = req->quality_level;\n\tmetadata.array_size = req->base.array_size;\n\tmetadata.buffer_byte_stride = req->buffer_byte_stride;\n\tmetadata.num_sizes = 1;\n\tmetadata.base_size = req->base.base_size;\n\tmetadata.scanout = req->base.drm_surface_flags &\n\t\tdrm_vmw_surface_flag_scanout;\n\n\t \n\tret = vmw_gb_surface_define(dev_priv, &metadata, &srf);\n\tif (ret != 0) {\n\t\tVMW_DEBUG_USER(\"Failed to define surface.\\n\");\n\t\treturn ret;\n\t}\n\n\tuser_srf = container_of(srf, struct vmw_user_surface, srf);\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_file_get_master(file_priv);\n\n\tres = &user_srf->srf.res;\n\n\tif (req->base.buffer_handle != SVGA3D_INVALID_ID) {\n\t\tret = vmw_user_bo_lookup(file_priv, req->base.buffer_handle,\n\t\t\t\t\t &res->guest_memory_bo);\n\t\tif (ret == 0) {\n\t\t\tif (res->guest_memory_bo->tbo.base.size < res->guest_memory_size) {\n\t\t\t\tVMW_DEBUG_USER(\"Surface backup buffer too small.\\n\");\n\t\t\t\tvmw_user_bo_unref(&res->guest_memory_bo);\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t} else {\n\t\t\t\tbackup_handle = req->base.buffer_handle;\n\t\t\t}\n\t\t}\n\t} else if (req->base.drm_surface_flags &\n\t\t   (drm_vmw_surface_flag_create_buffer |\n\t\t    drm_vmw_surface_flag_coherent)) {\n\t\tret = vmw_gem_object_create_with_handle(dev_priv, file_priv,\n\t\t\t\t\t\t\tres->guest_memory_size,\n\t\t\t\t\t\t\t&backup_handle,\n\t\t\t\t\t\t\t&res->guest_memory_bo);\n\t}\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\tif (req->base.drm_surface_flags & drm_vmw_surface_flag_coherent) {\n\t\tstruct vmw_bo *backup = res->guest_memory_bo;\n\n\t\tttm_bo_reserve(&backup->tbo, false, false, NULL);\n\t\tif (!res->func->dirty_alloc)\n\t\t\tret = -EINVAL;\n\t\tif (!ret)\n\t\t\tret = vmw_bo_dirty_add(backup);\n\t\tif (!ret) {\n\t\t\tres->coherent = true;\n\t\t\tret = res->func->dirty_alloc(res);\n\t\t}\n\t\tttm_bo_unreserve(&backup->tbo);\n\t\tif (ret) {\n\t\t\tvmw_resource_unreference(&res);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t}\n\n\ttmp = vmw_resource_reference(res);\n\tret = ttm_prime_object_init(tfile, res->guest_memory_size, &user_srf->prime,\n\t\t\t\t    req->base.drm_surface_flags &\n\t\t\t\t    drm_vmw_surface_flag_shareable,\n\t\t\t\t    VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->handle      = user_srf->prime.base.handle;\n\trep->backup_size = res->guest_memory_size;\n\tif (res->guest_memory_bo) {\n\t\trep->buffer_map_handle =\n\t\t\tdrm_vma_node_offset_addr(&res->guest_memory_bo->tbo.base.vma_node);\n\t\trep->buffer_size = res->guest_memory_bo->tbo.base.size;\n\t\trep->buffer_handle = backup_handle;\n\t} else {\n\t\trep->buffer_map_handle = 0;\n\t\trep->buffer_size = 0;\n\t\trep->buffer_handle = SVGA3D_INVALID_ID;\n\t}\n\tvmw_resource_unreference(&res);\n\nout_unlock:\n\treturn ret;\n}\n\n \nstatic int\nvmw_gb_surface_reference_internal(struct drm_device *dev,\n\t\t\t\t  struct drm_vmw_surface_arg *req,\n\t\t\t\t  struct drm_vmw_gb_surface_ref_ext_rep *rep,\n\t\t\t\t  struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_surface *srf;\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface_metadata *metadata;\n\tstruct ttm_base_object *base;\n\tu32 backup_handle;\n\tint ret;\n\n\tret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,\n\t\t\t\t\t   req->handle_type, &base);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(base, struct vmw_user_surface, prime.base);\n\tsrf = &user_srf->srf;\n\tif (!srf->res.guest_memory_bo) {\n\t\tDRM_ERROR(\"Shared GB surface is missing a backup buffer.\\n\");\n\t\tgoto out_bad_resource;\n\t}\n\tmetadata = &srf->metadata;\n\n\tmutex_lock(&dev_priv->cmdbuf_mutex);  \n\tret = drm_gem_handle_create(file_priv, &srf->res.guest_memory_bo->tbo.base,\n\t\t\t\t    &backup_handle);\n\tmutex_unlock(&dev_priv->cmdbuf_mutex);\n\tif (ret != 0) {\n\t\tdrm_err(dev, \"Wasn't able to create a backing handle for surface sid = %u.\\n\",\n\t\t\treq->sid);\n\t\tgoto out_bad_resource;\n\t}\n\n\trep->creq.base.svga3d_flags = SVGA3D_FLAGS_LOWER_32(metadata->flags);\n\trep->creq.base.format = metadata->format;\n\trep->creq.base.mip_levels = metadata->mip_levels[0];\n\trep->creq.base.drm_surface_flags = 0;\n\trep->creq.base.multisample_count = metadata->multisample_count;\n\trep->creq.base.autogen_filter = metadata->autogen_filter;\n\trep->creq.base.array_size = metadata->array_size;\n\trep->creq.base.buffer_handle = backup_handle;\n\trep->creq.base.base_size = metadata->base_size;\n\trep->crep.handle = user_srf->prime.base.handle;\n\trep->crep.backup_size = srf->res.guest_memory_size;\n\trep->crep.buffer_handle = backup_handle;\n\trep->crep.buffer_map_handle =\n\t\tdrm_vma_node_offset_addr(&srf->res.guest_memory_bo->tbo.base.vma_node);\n\trep->crep.buffer_size = srf->res.guest_memory_bo->tbo.base.size;\n\n\trep->creq.version = drm_vmw_gb_surface_v1;\n\trep->creq.svga3d_flags_upper_32_bits =\n\t\tSVGA3D_FLAGS_UPPER_32(metadata->flags);\n\trep->creq.multisample_pattern = metadata->multisample_pattern;\n\trep->creq.quality_level = metadata->quality_level;\n\trep->creq.must_be_zero = 0;\n\nout_bad_resource:\n\tttm_base_object_unref(&base);\n\n\treturn ret;\n}\n\n \nstatic void vmw_subres_dirty_add(struct vmw_surface_dirty *dirty,\n\t\t\t\t const struct vmw_surface_loc *loc_start,\n\t\t\t\t const struct vmw_surface_loc *loc_end)\n{\n\tconst struct vmw_surface_cache *cache = &dirty->cache;\n\tSVGA3dBox *box = &dirty->boxes[loc_start->sub_resource];\n\tu32 mip = loc_start->sub_resource % cache->num_mip_levels;\n\tconst struct drm_vmw_size *size = &cache->mip[mip].size;\n\tu32 box_c2 = box->z + box->d;\n\n\tif (WARN_ON(loc_start->sub_resource >= dirty->num_subres))\n\t\treturn;\n\n\tif (box->d == 0 || box->z > loc_start->z)\n\t\tbox->z = loc_start->z;\n\tif (box_c2 < loc_end->z)\n\t\tbox->d = loc_end->z - box->z;\n\n\tif (loc_start->z + 1 == loc_end->z) {\n\t\tbox_c2 = box->y + box->h;\n\t\tif (box->h == 0 || box->y > loc_start->y)\n\t\t\tbox->y = loc_start->y;\n\t\tif (box_c2 < loc_end->y)\n\t\t\tbox->h = loc_end->y - box->y;\n\n\t\tif (loc_start->y + 1 == loc_end->y) {\n\t\t\tbox_c2 = box->x + box->w;\n\t\t\tif (box->w == 0 || box->x > loc_start->x)\n\t\t\t\tbox->x = loc_start->x;\n\t\t\tif (box_c2 < loc_end->x)\n\t\t\t\tbox->w = loc_end->x - box->x;\n\t\t} else {\n\t\t\tbox->x = 0;\n\t\t\tbox->w = size->width;\n\t\t}\n\t} else {\n\t\tbox->y = 0;\n\t\tbox->h = size->height;\n\t\tbox->x = 0;\n\t\tbox->w = size->width;\n\t}\n}\n\n \nstatic void vmw_subres_dirty_full(struct vmw_surface_dirty *dirty, u32 subres)\n{\n\tconst struct vmw_surface_cache *cache = &dirty->cache;\n\tu32 mip = subres % cache->num_mip_levels;\n\tconst struct drm_vmw_size *size = &cache->mip[mip].size;\n\tSVGA3dBox *box = &dirty->boxes[subres];\n\n\tbox->x = 0;\n\tbox->y = 0;\n\tbox->z = 0;\n\tbox->w = size->width;\n\tbox->h = size->height;\n\tbox->d = size->depth;\n}\n\n \nstatic void vmw_surface_tex_dirty_range_add(struct vmw_resource *res,\n\t\t\t\t\t    size_t start, size_t end)\n{\n\tstruct vmw_surface_dirty *dirty =\n\t\t(struct vmw_surface_dirty *) res->dirty;\n\tsize_t backup_end = res->guest_memory_offset + res->guest_memory_size;\n\tstruct vmw_surface_loc loc1, loc2;\n\tconst struct vmw_surface_cache *cache;\n\n\tstart = max_t(size_t, start, res->guest_memory_offset) - res->guest_memory_offset;\n\tend = min(end, backup_end) - res->guest_memory_offset;\n\tcache = &dirty->cache;\n\tvmw_surface_get_loc(cache, &loc1, start);\n\tvmw_surface_get_loc(cache, &loc2, end - 1);\n\tvmw_surface_inc_loc(cache, &loc2);\n\n\tif (loc1.sheet != loc2.sheet) {\n\t\tu32 sub_res;\n\n\t\t \n\t\tfor (sub_res = 0; sub_res < dirty->num_subres; ++sub_res)\n\t\t\tvmw_subres_dirty_full(dirty, sub_res);\n\t\treturn;\n\t}\n\tif (loc1.sub_resource + 1 == loc2.sub_resource) {\n\t\t \n\t\tvmw_subres_dirty_add(dirty, &loc1, &loc2);\n\t} else {\n\t\t \n\t\tstruct vmw_surface_loc loc_min, loc_max;\n\t\tu32 sub_res;\n\n\t\tvmw_surface_max_loc(cache, loc1.sub_resource, &loc_max);\n\t\tvmw_subres_dirty_add(dirty, &loc1, &loc_max);\n\t\tvmw_surface_min_loc(cache, loc2.sub_resource - 1, &loc_min);\n\t\tvmw_subres_dirty_add(dirty, &loc_min, &loc2);\n\t\tfor (sub_res = loc1.sub_resource + 1;\n\t\t     sub_res < loc2.sub_resource - 1; ++sub_res)\n\t\t\tvmw_subres_dirty_full(dirty, sub_res);\n\t}\n}\n\n \nstatic void vmw_surface_buf_dirty_range_add(struct vmw_resource *res,\n\t\t\t\t\t    size_t start, size_t end)\n{\n\tstruct vmw_surface_dirty *dirty =\n\t\t(struct vmw_surface_dirty *) res->dirty;\n\tconst struct vmw_surface_cache *cache = &dirty->cache;\n\tsize_t backup_end = res->guest_memory_offset + cache->mip_chain_bytes;\n\tSVGA3dBox *box = &dirty->boxes[0];\n\tu32 box_c2;\n\n\tbox->h = box->d = 1;\n\tstart = max_t(size_t, start, res->guest_memory_offset) - res->guest_memory_offset;\n\tend = min(end, backup_end) - res->guest_memory_offset;\n\tbox_c2 = box->x + box->w;\n\tif (box->w == 0 || box->x > start)\n\t\tbox->x = start;\n\tif (box_c2 < end)\n\t\tbox->w = end - box->x;\n}\n\n \nstatic void vmw_surface_dirty_range_add(struct vmw_resource *res, size_t start,\n\t\t\t\t\tsize_t end)\n{\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\n\tif (WARN_ON(end <= res->guest_memory_offset ||\n\t\t    start >= res->guest_memory_offset + res->guest_memory_size))\n\t\treturn;\n\n\tif (srf->metadata.format == SVGA3D_BUFFER)\n\t\tvmw_surface_buf_dirty_range_add(res, start, end);\n\telse\n\t\tvmw_surface_tex_dirty_range_add(res, start, end);\n}\n\n \nstatic int vmw_surface_dirty_sync(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tu32 i, num_dirty;\n\tstruct vmw_surface_dirty *dirty =\n\t\t(struct vmw_surface_dirty *) res->dirty;\n\tsize_t alloc_size;\n\tconst struct vmw_surface_cache *cache = &dirty->cache;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDXUpdateSubResource body;\n\t} *cmd1;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdUpdateGBImage body;\n\t} *cmd2;\n\tvoid *cmd;\n\n\tnum_dirty = 0;\n\tfor (i = 0; i < dirty->num_subres; ++i) {\n\t\tconst SVGA3dBox *box = &dirty->boxes[i];\n\n\t\tif (box->d)\n\t\t\tnum_dirty++;\n\t}\n\n\tif (!num_dirty)\n\t\tgoto out;\n\n\talloc_size = num_dirty * ((has_sm4_context(dev_priv)) ? sizeof(*cmd1) : sizeof(*cmd2));\n\tcmd = VMW_CMD_RESERVE(dev_priv, alloc_size);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd1 = cmd;\n\tcmd2 = cmd;\n\n\tfor (i = 0; i < dirty->num_subres; ++i) {\n\t\tconst SVGA3dBox *box = &dirty->boxes[i];\n\n\t\tif (!box->d)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (has_sm4_context(dev_priv)) {\n\t\t\tcmd1->header.id = SVGA_3D_CMD_DX_UPDATE_SUBRESOURCE;\n\t\t\tcmd1->header.size = sizeof(cmd1->body);\n\t\t\tcmd1->body.sid = res->id;\n\t\t\tcmd1->body.subResource = i;\n\t\t\tcmd1->body.box = *box;\n\t\t\tcmd1++;\n\t\t} else {\n\t\t\tcmd2->header.id = SVGA_3D_CMD_UPDATE_GB_IMAGE;\n\t\t\tcmd2->header.size = sizeof(cmd2->body);\n\t\t\tcmd2->body.image.sid = res->id;\n\t\t\tcmd2->body.image.face = i / cache->num_mip_levels;\n\t\t\tcmd2->body.image.mipmap = i -\n\t\t\t\t(cache->num_mip_levels * cmd2->body.image.face);\n\t\t\tcmd2->body.box = *box;\n\t\t\tcmd2++;\n\t\t}\n\n\t}\n\tvmw_cmd_commit(dev_priv, alloc_size);\n out:\n\tmemset(&dirty->boxes[0], 0, sizeof(dirty->boxes[0]) *\n\t       dirty->num_subres);\n\n\treturn 0;\n}\n\n \nstatic int vmw_surface_dirty_alloc(struct vmw_resource *res)\n{\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tconst struct vmw_surface_metadata *metadata = &srf->metadata;\n\tstruct vmw_surface_dirty *dirty;\n\tu32 num_layers = 1;\n\tu32 num_mip;\n\tu32 num_subres;\n\tu32 num_samples;\n\tsize_t dirty_size;\n\tint ret;\n\n\tif (metadata->array_size)\n\t\tnum_layers = metadata->array_size;\n\telse if (metadata->flags & SVGA3D_SURFACE_CUBEMAP)\n\t\tnum_layers *= SVGA3D_MAX_SURFACE_FACES;\n\n\tnum_mip = metadata->mip_levels[0];\n\tif (!num_mip)\n\t\tnum_mip = 1;\n\n\tnum_subres = num_layers * num_mip;\n\tdirty_size = struct_size(dirty, boxes, num_subres);\n\n\tdirty = kvzalloc(dirty_size, GFP_KERNEL);\n\tif (!dirty) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_dirty;\n\t}\n\n\tnum_samples = max_t(u32, 1, metadata->multisample_count);\n\tret = vmw_surface_setup_cache(&metadata->base_size, metadata->format,\n\t\t\t\t      num_mip, num_layers, num_samples,\n\t\t\t\t      &dirty->cache);\n\tif (ret)\n\t\tgoto out_no_cache;\n\n\tdirty->num_subres = num_subres;\n\tres->dirty = (struct vmw_resource_dirty *) dirty;\n\n\treturn 0;\n\nout_no_cache:\n\tkvfree(dirty);\nout_no_dirty:\n\treturn ret;\n}\n\n \nstatic void vmw_surface_dirty_free(struct vmw_resource *res)\n{\n\tstruct vmw_surface_dirty *dirty =\n\t\t(struct vmw_surface_dirty *) res->dirty;\n\n\tkvfree(dirty);\n\tres->dirty = NULL;\n}\n\n \nstatic int vmw_surface_clean(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tsize_t alloc_size;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdReadbackGBSurface body;\n\t} *cmd;\n\n\talloc_size = sizeof(*cmd);\n\tcmd = VMW_CMD_RESERVE(dev_priv, alloc_size);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->header.id = SVGA_3D_CMD_READBACK_GB_SURFACE;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.sid = res->id;\n\tvmw_cmd_commit(dev_priv, alloc_size);\n\n\treturn 0;\n}\n\n \nint vmw_gb_surface_define(struct vmw_private *dev_priv,\n\t\t\t  const struct vmw_surface_metadata *req,\n\t\t\t  struct vmw_surface **srf_out)\n{\n\tstruct vmw_surface_metadata *metadata;\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tu32 sample_count = 1;\n\tu32 num_layers = 1;\n\tint ret;\n\n\t*srf_out = NULL;\n\n\tif (req->scanout) {\n\t\tif (!vmw_surface_is_screen_target_format(req->format)) {\n\t\t\tVMW_DEBUG_USER(\"Invalid Screen Target surface format.\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (req->base_size.width > dev_priv->texture_max_width ||\n\t\t    req->base_size.height > dev_priv->texture_max_height) {\n\t\t\tVMW_DEBUG_USER(\"%ux%u\\n, exceed max surface size %ux%u\",\n\t\t\t\t       req->base_size.width,\n\t\t\t\t       req->base_size.height,\n\t\t\t\t       dev_priv->texture_max_width,\n\t\t\t\t       dev_priv->texture_max_height);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tconst SVGA3dSurfaceDesc *desc =\n\t\t\tvmw_surface_get_desc(req->format);\n\n\t\tif (desc->blockDesc == SVGA3DBLOCKDESC_NONE) {\n\t\t\tVMW_DEBUG_USER(\"Invalid surface format.\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (req->autogen_filter != SVGA3D_TEX_FILTER_NONE)\n\t\treturn -EINVAL;\n\n\tif (req->num_sizes != 1)\n\t\treturn -EINVAL;\n\n\tif (req->sizes != NULL)\n\t\treturn -EINVAL;\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_unlock;\n\t}\n\n\t*srf_out  = &user_srf->srf;\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile = NULL;\n\n\tsrf = &user_srf->srf;\n\tsrf->metadata = *req;\n\tsrf->offsets = NULL;\n\n\tmetadata = &srf->metadata;\n\n\tif (metadata->array_size)\n\t\tnum_layers = req->array_size;\n\telse if (metadata->flags & SVGA3D_SURFACE_CUBEMAP)\n\t\tnum_layers = SVGA3D_MAX_SURFACE_FACES;\n\n\tif (metadata->flags & SVGA3D_SURFACE_MULTISAMPLE)\n\t\tsample_count = metadata->multisample_count;\n\n\tsrf->res.guest_memory_size =\n\t\tvmw_surface_get_serialized_size_extended(\n\t\t\t\tmetadata->format,\n\t\t\t\tmetadata->base_size,\n\t\t\t\tmetadata->mip_levels[0],\n\t\t\t\tnum_layers,\n\t\t\t\tsample_count);\n\n\tif (metadata->flags & SVGA3D_SURFACE_BIND_STREAM_OUTPUT)\n\t\tsrf->res.guest_memory_size += sizeof(SVGA3dDXSOState);\n\n\t \n\tif (dev_priv->active_display_unit == vmw_du_screen_target &&\n\t    metadata->scanout &&\n\t    metadata->base_size.width <= dev_priv->stdu_max_width &&\n\t    metadata->base_size.height <= dev_priv->stdu_max_height)\n\t\tmetadata->flags |= SVGA3D_SURFACE_SCREENTARGET;\n\n\t \n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\n\treturn ret;\n\nout_unlock:\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}