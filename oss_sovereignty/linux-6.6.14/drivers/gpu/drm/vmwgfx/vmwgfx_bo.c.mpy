{
  "module_name": "vmwgfx_bo.c",
  "hash_id": "032926bead80d51d6c499745ba8ef383300e9a77f1baa6b6b85dcefdc676b98c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/vmwgfx_bo.c",
  "human_readable_source": "\n \n\n#include \"vmwgfx_bo.h\"\n#include \"vmwgfx_drv.h\"\n\n\n#include <drm/ttm/ttm_placement.h>\n\nstatic void vmw_bo_release(struct vmw_bo *vbo)\n{\n\tWARN_ON(vbo->tbo.base.funcs &&\n\t\tkref_read(&vbo->tbo.base.refcount) != 0);\n\tvmw_bo_unmap(vbo);\n\tdrm_gem_object_release(&vbo->tbo.base);\n}\n\n \nstatic void vmw_bo_free(struct ttm_buffer_object *bo)\n{\n\tstruct vmw_bo *vbo = to_vmw_bo(&bo->base);\n\n\tWARN_ON(vbo->dirty);\n\tWARN_ON(!RB_EMPTY_ROOT(&vbo->res_tree));\n\tvmw_bo_release(vbo);\n\tkfree(vbo);\n}\n\n \nstatic int vmw_bo_pin_in_placement(struct vmw_private *dev_priv,\n\t\t\t\t   struct vmw_bo *buf,\n\t\t\t\t   struct ttm_placement *placement,\n\t\t\t\t   bool interruptible)\n{\n\tstruct ttm_operation_ctx ctx = {interruptible, false };\n\tstruct ttm_buffer_object *bo = &buf->tbo;\n\tint ret;\n\n\tvmw_execbuf_release_pinned_bo(dev_priv);\n\n\tret = ttm_bo_reserve(bo, interruptible, false, NULL);\n\tif (unlikely(ret != 0))\n\t\tgoto err;\n\n\tret = ttm_bo_validate(bo, placement, &ctx);\n\tif (!ret)\n\t\tvmw_bo_pin_reserved(buf, true);\n\n\tttm_bo_unreserve(bo);\nerr:\n\treturn ret;\n}\n\n\n \nint vmw_bo_pin_in_vram_or_gmr(struct vmw_private *dev_priv,\n\t\t\t      struct vmw_bo *buf,\n\t\t\t      bool interruptible)\n{\n\tstruct ttm_operation_ctx ctx = {interruptible, false };\n\tstruct ttm_buffer_object *bo = &buf->tbo;\n\tint ret;\n\n\tvmw_execbuf_release_pinned_bo(dev_priv);\n\n\tret = ttm_bo_reserve(bo, interruptible, false, NULL);\n\tif (unlikely(ret != 0))\n\t\tgoto err;\n\n\tvmw_bo_placement_set(buf,\n\t\t\t     VMW_BO_DOMAIN_GMR | VMW_BO_DOMAIN_VRAM,\n\t\t\t     VMW_BO_DOMAIN_GMR);\n\tret = ttm_bo_validate(bo, &buf->placement, &ctx);\n\tif (likely(ret == 0) || ret == -ERESTARTSYS)\n\t\tgoto out_unreserve;\n\n\tvmw_bo_placement_set(buf,\n\t\t\t     VMW_BO_DOMAIN_VRAM,\n\t\t\t     VMW_BO_DOMAIN_VRAM);\n\tret = ttm_bo_validate(bo, &buf->placement, &ctx);\n\nout_unreserve:\n\tif (!ret)\n\t\tvmw_bo_pin_reserved(buf, true);\n\n\tttm_bo_unreserve(bo);\nerr:\n\treturn ret;\n}\n\n\n \nint vmw_bo_pin_in_vram(struct vmw_private *dev_priv,\n\t\t       struct vmw_bo *buf,\n\t\t       bool interruptible)\n{\n\treturn vmw_bo_pin_in_placement(dev_priv, buf, &vmw_vram_placement,\n\t\t\t\t       interruptible);\n}\n\n\n \nint vmw_bo_pin_in_start_of_vram(struct vmw_private *dev_priv,\n\t\t\t\tstruct vmw_bo *buf,\n\t\t\t\tbool interruptible)\n{\n\tstruct ttm_operation_ctx ctx = {interruptible, false };\n\tstruct ttm_buffer_object *bo = &buf->tbo;\n\tint ret = 0;\n\n\tvmw_execbuf_release_pinned_bo(dev_priv);\n\tret = ttm_bo_reserve(bo, interruptible, false, NULL);\n\tif (unlikely(ret != 0))\n\t\tgoto err_unlock;\n\n\t \n\tif (bo->resource->mem_type == TTM_PL_VRAM &&\n\t    bo->resource->start < PFN_UP(bo->resource->size) &&\n\t    bo->resource->start > 0 &&\n\t    buf->tbo.pin_count == 0) {\n\t\tctx.interruptible = false;\n\t\tvmw_bo_placement_set(buf,\n\t\t\t\t     VMW_BO_DOMAIN_SYS,\n\t\t\t\t     VMW_BO_DOMAIN_SYS);\n\t\t(void)ttm_bo_validate(bo, &buf->placement, &ctx);\n\t}\n\n\tvmw_bo_placement_set(buf,\n\t\t\t     VMW_BO_DOMAIN_VRAM,\n\t\t\t     VMW_BO_DOMAIN_VRAM);\n\tbuf->places[0].lpfn = PFN_UP(bo->resource->size);\n\tret = ttm_bo_validate(bo, &buf->placement, &ctx);\n\n\t \n\tWARN_ON(ret == 0 && bo->resource->start != 0);\n\tif (!ret)\n\t\tvmw_bo_pin_reserved(buf, true);\n\n\tttm_bo_unreserve(bo);\nerr_unlock:\n\n\treturn ret;\n}\n\n\n \nint vmw_bo_unpin(struct vmw_private *dev_priv,\n\t\t struct vmw_bo *buf,\n\t\t bool interruptible)\n{\n\tstruct ttm_buffer_object *bo = &buf->tbo;\n\tint ret;\n\n\tret = ttm_bo_reserve(bo, interruptible, false, NULL);\n\tif (unlikely(ret != 0))\n\t\tgoto err;\n\n\tvmw_bo_pin_reserved(buf, false);\n\n\tttm_bo_unreserve(bo);\n\nerr:\n\treturn ret;\n}\n\n \nvoid vmw_bo_get_guest_ptr(const struct ttm_buffer_object *bo,\n\t\t\t  SVGAGuestPtr *ptr)\n{\n\tif (bo->resource->mem_type == TTM_PL_VRAM) {\n\t\tptr->gmrId = SVGA_GMR_FRAMEBUFFER;\n\t\tptr->offset = bo->resource->start << PAGE_SHIFT;\n\t} else {\n\t\tptr->gmrId = bo->resource->start;\n\t\tptr->offset = 0;\n\t}\n}\n\n\n \nvoid vmw_bo_pin_reserved(struct vmw_bo *vbo, bool pin)\n{\n\tstruct ttm_operation_ctx ctx = { false, true };\n\tstruct ttm_place pl;\n\tstruct ttm_placement placement;\n\tstruct ttm_buffer_object *bo = &vbo->tbo;\n\tuint32_t old_mem_type = bo->resource->mem_type;\n\tint ret;\n\n\tdma_resv_assert_held(bo->base.resv);\n\n\tif (pin == !!bo->pin_count)\n\t\treturn;\n\n\tpl.fpfn = 0;\n\tpl.lpfn = 0;\n\tpl.mem_type = bo->resource->mem_type;\n\tpl.flags = bo->resource->placement;\n\n\tmemset(&placement, 0, sizeof(placement));\n\tplacement.num_placement = 1;\n\tplacement.placement = &pl;\n\n\tret = ttm_bo_validate(bo, &placement, &ctx);\n\n\tBUG_ON(ret != 0 || bo->resource->mem_type != old_mem_type);\n\n\tif (pin)\n\t\tttm_bo_pin(bo);\n\telse\n\t\tttm_bo_unpin(bo);\n}\n\n \nvoid *vmw_bo_map_and_cache(struct vmw_bo *vbo)\n{\n\tstruct ttm_buffer_object *bo = &vbo->tbo;\n\tbool not_used;\n\tvoid *virtual;\n\tint ret;\n\n\tvirtual = ttm_kmap_obj_virtual(&vbo->map, &not_used);\n\tif (virtual)\n\t\treturn virtual;\n\n\tret = ttm_bo_kmap(bo, 0, PFN_UP(bo->base.size), &vbo->map);\n\tif (ret)\n\t\tDRM_ERROR(\"Buffer object map failed: %d.\\n\", ret);\n\n\treturn ttm_kmap_obj_virtual(&vbo->map, &not_used);\n}\n\n\n \nvoid vmw_bo_unmap(struct vmw_bo *vbo)\n{\n\tif (vbo->map.bo == NULL)\n\t\treturn;\n\n\tttm_bo_kunmap(&vbo->map);\n\tvbo->map.bo = NULL;\n}\n\n\n \nstatic int vmw_bo_init(struct vmw_private *dev_priv,\n\t\t       struct vmw_bo *vmw_bo,\n\t\t       struct vmw_bo_params *params,\n\t\t       void (*destroy)(struct ttm_buffer_object *))\n{\n\tstruct ttm_operation_ctx ctx = {\n\t\t.interruptible = params->bo_type != ttm_bo_type_kernel,\n\t\t.no_wait_gpu = false\n\t};\n\tstruct ttm_device *bdev = &dev_priv->bdev;\n\tstruct drm_device *vdev = &dev_priv->drm;\n\tint ret;\n\n\tmemset(vmw_bo, 0, sizeof(*vmw_bo));\n\n\tBUILD_BUG_ON(TTM_MAX_BO_PRIORITY <= 3);\n\tvmw_bo->tbo.priority = 3;\n\tvmw_bo->res_tree = RB_ROOT;\n\n\tparams->size = ALIGN(params->size, PAGE_SIZE);\n\tdrm_gem_private_object_init(vdev, &vmw_bo->tbo.base, params->size);\n\n\tvmw_bo_placement_set(vmw_bo, params->domain, params->busy_domain);\n\tret = ttm_bo_init_reserved(bdev, &vmw_bo->tbo, params->bo_type,\n\t\t\t\t   &vmw_bo->placement, 0, &ctx, NULL,\n\t\t\t\t   NULL, destroy);\n\tif (unlikely(ret))\n\t\treturn ret;\n\n\tif (params->pin)\n\t\tttm_bo_pin(&vmw_bo->tbo);\n\tttm_bo_unreserve(&vmw_bo->tbo);\n\n\treturn 0;\n}\n\nint vmw_bo_create(struct vmw_private *vmw,\n\t\t  struct vmw_bo_params *params,\n\t\t  struct vmw_bo **p_bo)\n{\n\tint ret;\n\n\t*p_bo = kmalloc(sizeof(**p_bo), GFP_KERNEL);\n\tif (unlikely(!*p_bo)) {\n\t\tDRM_ERROR(\"Failed to allocate a buffer.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tret = vmw_bo_init(vmw, *p_bo, params, vmw_bo_free);\n\tif (unlikely(ret != 0))\n\t\tgoto out_error;\n\n\treturn ret;\nout_error:\n\t*p_bo = NULL;\n\treturn ret;\n}\n\n \nstatic int vmw_user_bo_synccpu_grab(struct vmw_bo *vmw_bo,\n\t\t\t\t    uint32_t flags)\n{\n\tbool nonblock = !!(flags & drm_vmw_synccpu_dontblock);\n\tstruct ttm_buffer_object *bo = &vmw_bo->tbo;\n\tint ret;\n\n\tif (flags & drm_vmw_synccpu_allow_cs) {\n\t\tlong lret;\n\n\t\tlret = dma_resv_wait_timeout(bo->base.resv, DMA_RESV_USAGE_READ,\n\t\t\t\t\t     true, nonblock ? 0 :\n\t\t\t\t\t     MAX_SCHEDULE_TIMEOUT);\n\t\tif (!lret)\n\t\t\treturn -EBUSY;\n\t\telse if (lret < 0)\n\t\t\treturn lret;\n\t\treturn 0;\n\t}\n\n\tret = ttm_bo_reserve(bo, true, nonblock, NULL);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_bo_wait(bo, true, nonblock);\n\tif (likely(ret == 0))\n\t\tatomic_inc(&vmw_bo->cpu_writers);\n\n\tttm_bo_unreserve(bo);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\treturn ret;\n}\n\n \nstatic int vmw_user_bo_synccpu_release(struct drm_file *filp,\n\t\t\t\t       uint32_t handle,\n\t\t\t\t       uint32_t flags)\n{\n\tstruct vmw_bo *vmw_bo;\n\tint ret = vmw_user_bo_lookup(filp, handle, &vmw_bo);\n\n\tif (!ret) {\n\t\tif (!(flags & drm_vmw_synccpu_allow_cs)) {\n\t\t\tatomic_dec(&vmw_bo->cpu_writers);\n\t\t}\n\t\tvmw_user_bo_unref(&vmw_bo);\n\t}\n\n\treturn ret;\n}\n\n\n \nint vmw_user_bo_synccpu_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *file_priv)\n{\n\tstruct drm_vmw_synccpu_arg *arg =\n\t\t(struct drm_vmw_synccpu_arg *) data;\n\tstruct vmw_bo *vbo;\n\tint ret;\n\n\tif ((arg->flags & (drm_vmw_synccpu_read | drm_vmw_synccpu_write)) == 0\n\t    || (arg->flags & ~(drm_vmw_synccpu_read | drm_vmw_synccpu_write |\n\t\t\t       drm_vmw_synccpu_dontblock |\n\t\t\t       drm_vmw_synccpu_allow_cs)) != 0) {\n\t\tDRM_ERROR(\"Illegal synccpu flags.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (arg->op) {\n\tcase drm_vmw_synccpu_grab:\n\t\tret = vmw_user_bo_lookup(file_priv, arg->handle, &vbo);\n\t\tif (unlikely(ret != 0))\n\t\t\treturn ret;\n\n\t\tret = vmw_user_bo_synccpu_grab(vbo, arg->flags);\n\t\tvmw_user_bo_unref(&vbo);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tif (ret == -ERESTARTSYS || ret == -EBUSY)\n\t\t\t\treturn -EBUSY;\n\t\t\tDRM_ERROR(\"Failed synccpu grab on handle 0x%08x.\\n\",\n\t\t\t\t  (unsigned int) arg->handle);\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\tcase drm_vmw_synccpu_release:\n\t\tret = vmw_user_bo_synccpu_release(file_priv,\n\t\t\t\t\t\t  arg->handle,\n\t\t\t\t\t\t  arg->flags);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tDRM_ERROR(\"Failed synccpu release on handle 0x%08x.\\n\",\n\t\t\t\t  (unsigned int) arg->handle);\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tDRM_ERROR(\"Invalid synccpu operation.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n \nint vmw_bo_unref_ioctl(struct drm_device *dev, void *data,\n\t\t       struct drm_file *file_priv)\n{\n\tstruct drm_vmw_unref_dmabuf_arg *arg =\n\t    (struct drm_vmw_unref_dmabuf_arg *)data;\n\n\treturn drm_gem_handle_delete(file_priv, arg->handle);\n}\n\n\n \nint vmw_user_bo_lookup(struct drm_file *filp,\n\t\t       u32 handle,\n\t\t       struct vmw_bo **out)\n{\n\tstruct drm_gem_object *gobj;\n\n\tgobj = drm_gem_object_lookup(filp, handle);\n\tif (!gobj) {\n\t\tDRM_ERROR(\"Invalid buffer object handle 0x%08lx.\\n\",\n\t\t\t  (unsigned long)handle);\n\t\treturn -ESRCH;\n\t}\n\n\t*out = to_vmw_bo(gobj);\n\n\treturn 0;\n}\n\n \nvoid vmw_bo_fence_single(struct ttm_buffer_object *bo,\n\t\t\t struct vmw_fence_obj *fence)\n{\n\tstruct ttm_device *bdev = bo->bdev;\n\tstruct vmw_private *dev_priv = vmw_priv_from_ttm(bdev);\n\tint ret;\n\n\tif (fence == NULL)\n\t\tvmw_execbuf_fence_commands(NULL, dev_priv, &fence, NULL);\n\telse\n\t\tdma_fence_get(&fence->base);\n\n\tret = dma_resv_reserve_fences(bo->base.resv, 1);\n\tif (!ret)\n\t\tdma_resv_add_fence(bo->base.resv, &fence->base,\n\t\t\t\t   DMA_RESV_USAGE_KERNEL);\n\telse\n\t\t \n\t\tdma_fence_wait(&fence->base, false);\n\tdma_fence_put(&fence->base);\n}\n\n\n \nint vmw_dumb_create(struct drm_file *file_priv,\n\t\t    struct drm_device *dev,\n\t\t    struct drm_mode_create_dumb *args)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_bo *vbo;\n\tint cpp = DIV_ROUND_UP(args->bpp, 8);\n\tint ret;\n\n\tswitch (cpp) {\n\tcase 1:  \n\tcase 2:  \n\tcase 4:  \n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\targs->pitch = args->width * cpp;\n\targs->size = ALIGN(args->pitch * args->height, PAGE_SIZE);\n\n\tret = vmw_gem_object_create_with_handle(dev_priv, file_priv,\n\t\t\t\t\t\targs->size, &args->handle,\n\t\t\t\t\t\t&vbo);\n\t \n\tdrm_gem_object_put(&vbo->tbo.base);\n\treturn ret;\n}\n\n \nvoid vmw_bo_swap_notify(struct ttm_buffer_object *bo)\n{\n\t \n\tvmw_bo_unmap(to_vmw_bo(&bo->base));\n}\n\n\n \nvoid vmw_bo_move_notify(struct ttm_buffer_object *bo,\n\t\t\tstruct ttm_resource *mem)\n{\n\tstruct vmw_bo *vbo = to_vmw_bo(&bo->base);\n\n\t \n\tif (mem->mem_type == TTM_PL_VRAM || bo->resource->mem_type == TTM_PL_VRAM)\n\t\tvmw_bo_unmap(vbo);\n\n\t \n\tif (mem->mem_type != VMW_PL_MOB && bo->resource->mem_type == VMW_PL_MOB)\n\t\tvmw_resource_unbind_list(vbo);\n}\n\nstatic u32\nset_placement_list(struct ttm_place *pl, u32 domain)\n{\n\tu32 n = 0;\n\n\t \n\tif (domain & VMW_BO_DOMAIN_MOB) {\n\t\tpl[n].mem_type = VMW_PL_MOB;\n\t\tpl[n].flags = 0;\n\t\tpl[n].fpfn = 0;\n\t\tpl[n].lpfn = 0;\n\t\tn++;\n\t}\n\tif (domain & VMW_BO_DOMAIN_GMR) {\n\t\tpl[n].mem_type = VMW_PL_GMR;\n\t\tpl[n].flags = 0;\n\t\tpl[n].fpfn = 0;\n\t\tpl[n].lpfn = 0;\n\t\tn++;\n\t}\n\tif (domain & VMW_BO_DOMAIN_VRAM) {\n\t\tpl[n].mem_type = TTM_PL_VRAM;\n\t\tpl[n].flags = 0;\n\t\tpl[n].fpfn = 0;\n\t\tpl[n].lpfn = 0;\n\t\tn++;\n\t}\n\tif (domain & VMW_BO_DOMAIN_WAITABLE_SYS) {\n\t\tpl[n].mem_type = VMW_PL_SYSTEM;\n\t\tpl[n].flags = 0;\n\t\tpl[n].fpfn = 0;\n\t\tpl[n].lpfn = 0;\n\t\tn++;\n\t}\n\tif (domain & VMW_BO_DOMAIN_SYS) {\n\t\tpl[n].mem_type = TTM_PL_SYSTEM;\n\t\tpl[n].flags = 0;\n\t\tpl[n].fpfn = 0;\n\t\tpl[n].lpfn = 0;\n\t\tn++;\n\t}\n\n\tWARN_ON(!n);\n\tif (!n) {\n\t\tpl[n].mem_type = TTM_PL_SYSTEM;\n\t\tpl[n].flags = 0;\n\t\tpl[n].fpfn = 0;\n\t\tpl[n].lpfn = 0;\n\t\tn++;\n\t}\n\treturn n;\n}\n\nvoid vmw_bo_placement_set(struct vmw_bo *bo, u32 domain, u32 busy_domain)\n{\n\tstruct ttm_device *bdev = bo->tbo.bdev;\n\tstruct vmw_private *vmw = vmw_priv_from_ttm(bdev);\n\tstruct ttm_placement *pl = &bo->placement;\n\tbool mem_compatible = false;\n\tu32 i;\n\n\tpl->placement = bo->places;\n\tpl->num_placement = set_placement_list(bo->places, domain);\n\n\tif (drm_debug_enabled(DRM_UT_DRIVER) && bo->tbo.resource) {\n\t\tfor (i = 0; i < pl->num_placement; ++i) {\n\t\t\tif (bo->tbo.resource->mem_type == TTM_PL_SYSTEM ||\n\t\t\t    bo->tbo.resource->mem_type == pl->placement[i].mem_type)\n\t\t\t\tmem_compatible = true;\n\t\t}\n\t\tif (!mem_compatible)\n\t\t\tdrm_warn(&vmw->drm,\n\t\t\t\t \"%s: Incompatible transition from \"\n\t\t\t\t \"bo->base.resource->mem_type = %u to domain = %u\\n\",\n\t\t\t\t __func__, bo->tbo.resource->mem_type, domain);\n\t}\n\n\tpl->busy_placement = bo->busy_places;\n\tpl->num_busy_placement = set_placement_list(bo->busy_places, busy_domain);\n}\n\nvoid vmw_bo_placement_set_default_accelerated(struct vmw_bo *bo)\n{\n\tstruct ttm_device *bdev = bo->tbo.bdev;\n\tstruct vmw_private *vmw = vmw_priv_from_ttm(bdev);\n\tu32 domain = VMW_BO_DOMAIN_GMR | VMW_BO_DOMAIN_VRAM;\n\n\tif (vmw->has_mob)\n\t\tdomain = VMW_BO_DOMAIN_MOB;\n\n\tvmw_bo_placement_set(bo, domain, domain);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}