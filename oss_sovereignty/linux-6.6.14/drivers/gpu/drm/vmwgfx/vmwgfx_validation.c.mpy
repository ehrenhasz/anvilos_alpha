{
  "module_name": "vmwgfx_validation.c",
  "hash_id": "db16c56bf079f40391116b961fb26510336ffd56499aec7940d1df08f1d33dff",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vmwgfx/vmwgfx_validation.c",
  "human_readable_source": "\n \n#include \"vmwgfx_bo.h\"\n#include \"vmwgfx_drv.h\"\n#include \"vmwgfx_resource_priv.h\"\n#include \"vmwgfx_validation.h\"\n\n#include <linux/slab.h>\n\n\n#define VMWGFX_VALIDATION_MEM_GRAN (16*PAGE_SIZE)\n\n \nstruct vmw_validation_bo_node {\n\tstruct ttm_validate_buffer base;\n\tstruct vmwgfx_hash_item hash;\n\tunsigned int coherent_count;\n};\n \nstruct vmw_validation_res_node {\n\tstruct list_head head;\n\tstruct vmwgfx_hash_item hash;\n\tstruct vmw_resource *res;\n\tstruct vmw_bo *new_guest_memory_bo;\n\tunsigned long new_guest_memory_offset;\n\tu32 no_buffer_needed : 1;\n\tu32 switching_guest_memory_bo : 1;\n\tu32 first_usage : 1;\n\tu32 reserved : 1;\n\tu32 dirty : 1;\n\tu32 dirty_set : 1;\n\tunsigned long private[];\n};\n\n \nvoid *vmw_validation_mem_alloc(struct vmw_validation_context *ctx,\n\t\t\t       unsigned int size)\n{\n\tvoid *addr;\n\n\tsize = vmw_validation_align(size);\n\tif (size > PAGE_SIZE)\n\t\treturn NULL;\n\n\tif (ctx->mem_size_left < size) {\n\t\tstruct page *page;\n\n\t\tif (ctx->vm && ctx->vm_size_left < PAGE_SIZE) {\n\t\t\tctx->vm_size_left += VMWGFX_VALIDATION_MEM_GRAN;\n\t\t\tctx->total_mem += VMWGFX_VALIDATION_MEM_GRAN;\n\t\t}\n\n\t\tpage = alloc_page(GFP_KERNEL | __GFP_ZERO);\n\t\tif (!page)\n\t\t\treturn NULL;\n\n\t\tif (ctx->vm)\n\t\t\tctx->vm_size_left -= PAGE_SIZE;\n\n\t\tlist_add_tail(&page->lru, &ctx->page_list);\n\t\tctx->page_address = page_address(page);\n\t\tctx->mem_size_left = PAGE_SIZE;\n\t}\n\n\taddr = (void *) (ctx->page_address + (PAGE_SIZE - ctx->mem_size_left));\n\tctx->mem_size_left -= size;\n\n\treturn addr;\n}\n\n \nstatic void vmw_validation_mem_free(struct vmw_validation_context *ctx)\n{\n\tstruct page *entry, *next;\n\n\tlist_for_each_entry_safe(entry, next, &ctx->page_list, lru) {\n\t\tlist_del_init(&entry->lru);\n\t\t__free_page(entry);\n\t}\n\n\tctx->mem_size_left = 0;\n\tif (ctx->vm && ctx->total_mem) {\n\t\tctx->total_mem = 0;\n\t\tctx->vm_size_left = 0;\n\t}\n}\n\n \nstatic struct vmw_validation_bo_node *\nvmw_validation_find_bo_dup(struct vmw_validation_context *ctx,\n\t\t\t   struct vmw_bo *vbo)\n{\n\tstruct  vmw_validation_bo_node *bo_node = NULL;\n\n\tif (!ctx->merge_dups)\n\t\treturn NULL;\n\n\tif (ctx->sw_context) {\n\t\tstruct vmwgfx_hash_item *hash;\n\t\tunsigned long key = (unsigned long) vbo;\n\n\t\thash_for_each_possible_rcu(ctx->sw_context->res_ht, hash, head, key) {\n\t\t\tif (hash->key == key) {\n\t\t\t\tbo_node = container_of(hash, typeof(*bo_node), hash);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstruct  vmw_validation_bo_node *entry;\n\n\t\tlist_for_each_entry(entry, &ctx->bo_list, base.head) {\n\t\t\tif (entry->base.bo == &vbo->tbo) {\n\t\t\t\tbo_node = entry;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn bo_node;\n}\n\n \nstatic struct vmw_validation_res_node *\nvmw_validation_find_res_dup(struct vmw_validation_context *ctx,\n\t\t\t    struct vmw_resource *res)\n{\n\tstruct  vmw_validation_res_node *res_node = NULL;\n\n\tif (!ctx->merge_dups)\n\t\treturn NULL;\n\n\tif (ctx->sw_context) {\n\t\tstruct vmwgfx_hash_item *hash;\n\t\tunsigned long key = (unsigned long) res;\n\n\t\thash_for_each_possible_rcu(ctx->sw_context->res_ht, hash, head, key) {\n\t\t\tif (hash->key == key) {\n\t\t\t\tres_node = container_of(hash, typeof(*res_node), hash);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstruct  vmw_validation_res_node *entry;\n\n\t\tlist_for_each_entry(entry, &ctx->resource_ctx_list, head) {\n\t\t\tif (entry->res == res) {\n\t\t\t\tres_node = entry;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tlist_for_each_entry(entry, &ctx->resource_list, head) {\n\t\t\tif (entry->res == res) {\n\t\t\t\tres_node = entry;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t}\nout:\n\treturn res_node;\n}\n\n \nint vmw_validation_add_bo(struct vmw_validation_context *ctx,\n\t\t\t  struct vmw_bo *vbo)\n{\n\tstruct vmw_validation_bo_node *bo_node;\n\n\tbo_node = vmw_validation_find_bo_dup(ctx, vbo);\n\tif (!bo_node) {\n\t\tstruct ttm_validate_buffer *val_buf;\n\n\t\tbo_node = vmw_validation_mem_alloc(ctx, sizeof(*bo_node));\n\t\tif (!bo_node)\n\t\t\treturn -ENOMEM;\n\n\t\tif (ctx->sw_context) {\n\t\t\tbo_node->hash.key = (unsigned long) vbo;\n\t\t\thash_add_rcu(ctx->sw_context->res_ht, &bo_node->hash.head,\n\t\t\t\tbo_node->hash.key);\n\t\t}\n\t\tval_buf = &bo_node->base;\n\t\tval_buf->bo = ttm_bo_get_unless_zero(&vbo->tbo);\n\t\tif (!val_buf->bo)\n\t\t\treturn -ESRCH;\n\t\tval_buf->num_shared = 0;\n\t\tlist_add_tail(&val_buf->head, &ctx->bo_list);\n\t}\n\n\treturn 0;\n}\n\n \nint vmw_validation_add_resource(struct vmw_validation_context *ctx,\n\t\t\t\tstruct vmw_resource *res,\n\t\t\t\tsize_t priv_size,\n\t\t\t\tu32 dirty,\n\t\t\t\tvoid **p_node,\n\t\t\t\tbool *first_usage)\n{\n\tstruct vmw_validation_res_node *node;\n\n\tnode = vmw_validation_find_res_dup(ctx, res);\n\tif (node) {\n\t\tnode->first_usage = 0;\n\t\tgoto out_fill;\n\t}\n\n\tnode = vmw_validation_mem_alloc(ctx, sizeof(*node) + priv_size);\n\tif (!node) {\n\t\tVMW_DEBUG_USER(\"Failed to allocate a resource validation entry.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (ctx->sw_context) {\n\t\tnode->hash.key = (unsigned long) res;\n\t\thash_add_rcu(ctx->sw_context->res_ht, &node->hash.head, node->hash.key);\n\t}\n\tnode->res = vmw_resource_reference_unless_doomed(res);\n\tif (!node->res)\n\t\treturn -ESRCH;\n\n\tnode->first_usage = 1;\n\tif (!res->dev_priv->has_mob) {\n\t\tlist_add_tail(&node->head, &ctx->resource_list);\n\t} else {\n\t\tswitch (vmw_res_type(res)) {\n\t\tcase vmw_res_context:\n\t\tcase vmw_res_dx_context:\n\t\t\tlist_add(&node->head, &ctx->resource_ctx_list);\n\t\t\tbreak;\n\t\tcase vmw_res_cotable:\n\t\t\tlist_add_tail(&node->head, &ctx->resource_ctx_list);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlist_add_tail(&node->head, &ctx->resource_list);\n\t\t\tbreak;\n\t\t}\n\t}\n\nout_fill:\n\tif (dirty) {\n\t\tnode->dirty_set = 1;\n\t\t \n\t\tnode->dirty = (dirty & VMW_RES_DIRTY_SET) ? 1 : 0;\n\t}\n\tif (first_usage)\n\t\t*first_usage = node->first_usage;\n\tif (p_node)\n\t\t*p_node = &node->private;\n\n\treturn 0;\n}\n\n \nvoid vmw_validation_res_set_dirty(struct vmw_validation_context *ctx,\n\t\t\t\t  void *val_private, u32 dirty)\n{\n\tstruct vmw_validation_res_node *val;\n\n\tif (!dirty)\n\t\treturn;\n\n\tval = container_of(val_private, typeof(*val), private);\n\tval->dirty_set = 1;\n\t \n\tval->dirty = (dirty & VMW_RES_DIRTY_SET) ? 1 : 0;\n}\n\n \nvoid vmw_validation_res_switch_backup(struct vmw_validation_context *ctx,\n\t\t\t\t      void *val_private,\n\t\t\t\t      struct vmw_bo *vbo,\n\t\t\t\t      unsigned long guest_memory_offset)\n{\n\tstruct vmw_validation_res_node *val;\n\n\tval = container_of(val_private, typeof(*val), private);\n\n\tval->switching_guest_memory_bo = 1;\n\tif (val->first_usage)\n\t\tval->no_buffer_needed = 1;\n\n\tval->new_guest_memory_bo = vbo;\n\tval->new_guest_memory_offset = guest_memory_offset;\n}\n\n \nint vmw_validation_res_reserve(struct vmw_validation_context *ctx,\n\t\t\t       bool intr)\n{\n\tstruct vmw_validation_res_node *val;\n\tint ret = 0;\n\n\tlist_splice_init(&ctx->resource_ctx_list, &ctx->resource_list);\n\n\tlist_for_each_entry(val, &ctx->resource_list, head) {\n\t\tstruct vmw_resource *res = val->res;\n\n\t\tret = vmw_resource_reserve(res, intr, val->no_buffer_needed);\n\t\tif (ret)\n\t\t\tgoto out_unreserve;\n\n\t\tval->reserved = 1;\n\t\tif (res->guest_memory_bo) {\n\t\t\tstruct vmw_bo *vbo = res->guest_memory_bo;\n\n\t\t\tvmw_bo_placement_set(vbo,\n\t\t\t\t\t     res->func->domain,\n\t\t\t\t\t     res->func->busy_domain);\n\t\t\tret = vmw_validation_add_bo(ctx, vbo);\n\t\t\tif (ret)\n\t\t\t\tgoto out_unreserve;\n\t\t}\n\n\t\tif (val->switching_guest_memory_bo && val->new_guest_memory_bo &&\n\t\t    res->coherent) {\n\t\t\tstruct vmw_validation_bo_node *bo_node =\n\t\t\t\tvmw_validation_find_bo_dup(ctx,\n\t\t\t\t\t\t\t   val->new_guest_memory_bo);\n\n\t\t\tif (WARN_ON(!bo_node)) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unreserve;\n\t\t\t}\n\t\t\tbo_node->coherent_count++;\n\t\t}\n\t}\n\n\treturn 0;\n\nout_unreserve:\n\tvmw_validation_res_unreserve(ctx, true);\n\treturn ret;\n}\n\n \nvoid vmw_validation_res_unreserve(struct vmw_validation_context *ctx,\n\t\t\t\t bool backoff)\n{\n\tstruct vmw_validation_res_node *val;\n\n\tlist_splice_init(&ctx->resource_ctx_list, &ctx->resource_list);\n\tif (backoff)\n\t\tlist_for_each_entry(val, &ctx->resource_list, head) {\n\t\t\tif (val->reserved)\n\t\t\t\tvmw_resource_unreserve(val->res,\n\t\t\t\t\t\t       false, false, false,\n\t\t\t\t\t\t       NULL, 0);\n\t\t}\n\telse\n\t\tlist_for_each_entry(val, &ctx->resource_list, head) {\n\t\t\tif (val->reserved)\n\t\t\t\tvmw_resource_unreserve(val->res,\n\t\t\t\t\t\t       val->dirty_set,\n\t\t\t\t\t\t       val->dirty,\n\t\t\t\t\t\t       val->switching_guest_memory_bo,\n\t\t\t\t\t\t       val->new_guest_memory_bo,\n\t\t\t\t\t\t       val->new_guest_memory_offset);\n\t\t}\n}\n\n \nstatic int vmw_validation_bo_validate_single(struct ttm_buffer_object *bo,\n\t\t\t\t\t     bool interruptible)\n{\n\tstruct vmw_bo *vbo = to_vmw_bo(&bo->base);\n\tstruct ttm_operation_ctx ctx = {\n\t\t.interruptible = interruptible,\n\t\t.no_wait_gpu = false\n\t};\n\tint ret;\n\n\tif (atomic_read(&vbo->cpu_writers))\n\t\treturn -EBUSY;\n\n\tif (vbo->tbo.pin_count > 0)\n\t\treturn 0;\n\n\tret = ttm_bo_validate(bo, &vbo->placement, &ctx);\n\tif (ret == 0 || ret == -ERESTARTSYS)\n\t\treturn ret;\n\n\t \n\tctx.allow_res_evict = true;\n\n\treturn ttm_bo_validate(bo, &vbo->placement, &ctx);\n}\n\n \nint vmw_validation_bo_validate(struct vmw_validation_context *ctx, bool intr)\n{\n\tstruct vmw_validation_bo_node *entry;\n\tint ret;\n\n\tlist_for_each_entry(entry, &ctx->bo_list, base.head) {\n\t\tstruct vmw_bo *vbo = to_vmw_bo(&entry->base.bo->base);\n\n\t\tret = vmw_validation_bo_validate_single(entry->base.bo, intr);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\tif (entry->coherent_count) {\n\t\t\tunsigned int coherent_count = entry->coherent_count;\n\n\t\t\twhile (coherent_count) {\n\t\t\t\tret = vmw_bo_dirty_add(vbo);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\n\t\t\t\tcoherent_count--;\n\t\t\t}\n\t\t\tentry->coherent_count -= coherent_count;\n\t\t}\n\n\t\tif (vbo->dirty)\n\t\t\tvmw_bo_dirty_scan(vbo);\n\t}\n\treturn 0;\n}\n\n \nint vmw_validation_res_validate(struct vmw_validation_context *ctx, bool intr)\n{\n\tstruct vmw_validation_res_node *val;\n\tint ret;\n\n\tlist_for_each_entry(val, &ctx->resource_list, head) {\n\t\tstruct vmw_resource *res = val->res;\n\t\tstruct vmw_bo *backup = res->guest_memory_bo;\n\n\t\tret = vmw_resource_validate(res, intr, val->dirty_set &&\n\t\t\t\t\t    val->dirty);\n\t\tif (ret) {\n\t\t\tif (ret != -ERESTARTSYS)\n\t\t\t\tDRM_ERROR(\"Failed to validate resource.\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tif (backup && res->guest_memory_bo && backup != res->guest_memory_bo) {\n\t\t\tstruct vmw_bo *vbo = res->guest_memory_bo;\n\n\t\t\tvmw_bo_placement_set(vbo, res->func->domain,\n\t\t\t\t\t     res->func->busy_domain);\n\t\t\tret = vmw_validation_add_bo(ctx, vbo);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\treturn 0;\n}\n\n \nvoid vmw_validation_drop_ht(struct vmw_validation_context *ctx)\n{\n\tstruct vmw_validation_bo_node *entry;\n\tstruct vmw_validation_res_node *val;\n\n\tif (!ctx->sw_context)\n\t\treturn;\n\n\tlist_for_each_entry(entry, &ctx->bo_list, base.head)\n\t\thash_del_rcu(&entry->hash.head);\n\n\tlist_for_each_entry(val, &ctx->resource_list, head)\n\t\thash_del_rcu(&val->hash.head);\n\n\tlist_for_each_entry(val, &ctx->resource_ctx_list, head)\n\t\thash_del_rcu(&entry->hash.head);\n\n\tctx->sw_context = NULL;\n}\n\n \nvoid vmw_validation_unref_lists(struct vmw_validation_context *ctx)\n{\n\tstruct vmw_validation_bo_node *entry;\n\tstruct vmw_validation_res_node *val;\n\n\tlist_for_each_entry(entry, &ctx->bo_list, base.head) {\n\t\tttm_bo_put(entry->base.bo);\n\t\tentry->base.bo = NULL;\n\t}\n\n\tlist_splice_init(&ctx->resource_ctx_list, &ctx->resource_list);\n\tlist_for_each_entry(val, &ctx->resource_list, head)\n\t\tvmw_resource_unreference(&val->res);\n\n\t \n\tINIT_LIST_HEAD(&ctx->bo_list);\n\tINIT_LIST_HEAD(&ctx->resource_list);\n\n\tvmw_validation_mem_free(ctx);\n}\n\n \nint vmw_validation_prepare(struct vmw_validation_context *ctx,\n\t\t\t   struct mutex *mutex,\n\t\t\t   bool intr)\n{\n\tint ret = 0;\n\n\tif (mutex) {\n\t\tif (intr)\n\t\t\tret = mutex_lock_interruptible(mutex);\n\t\telse\n\t\t\tmutex_lock(mutex);\n\t\tif (ret)\n\t\t\treturn -ERESTARTSYS;\n\t}\n\n\tctx->res_mutex = mutex;\n\tret = vmw_validation_res_reserve(ctx, intr);\n\tif (ret)\n\t\tgoto out_no_res_reserve;\n\n\tret = vmw_validation_bo_reserve(ctx, intr);\n\tif (ret)\n\t\tgoto out_no_bo_reserve;\n\n\tret = vmw_validation_bo_validate(ctx, intr);\n\tif (ret)\n\t\tgoto out_no_validate;\n\n\tret = vmw_validation_res_validate(ctx, intr);\n\tif (ret)\n\t\tgoto out_no_validate;\n\n\treturn 0;\n\nout_no_validate:\n\tvmw_validation_bo_backoff(ctx);\nout_no_bo_reserve:\n\tvmw_validation_res_unreserve(ctx, true);\nout_no_res_reserve:\n\tif (mutex)\n\t\tmutex_unlock(mutex);\n\n\treturn ret;\n}\n\n \nvoid vmw_validation_revert(struct vmw_validation_context *ctx)\n{\n\tvmw_validation_bo_backoff(ctx);\n\tvmw_validation_res_unreserve(ctx, true);\n\tif (ctx->res_mutex)\n\t\tmutex_unlock(ctx->res_mutex);\n\tvmw_validation_unref_lists(ctx);\n}\n\n \nvoid vmw_validation_done(struct vmw_validation_context *ctx,\n\t\t\t struct vmw_fence_obj *fence)\n{\n\tvmw_validation_bo_fence(ctx, fence);\n\tvmw_validation_res_unreserve(ctx, false);\n\tif (ctx->res_mutex)\n\t\tmutex_unlock(ctx->res_mutex);\n\tvmw_validation_unref_lists(ctx);\n}\n\n \nint vmw_validation_preload_bo(struct vmw_validation_context *ctx)\n{\n\tunsigned int size = sizeof(struct vmw_validation_bo_node);\n\n\tif (!vmw_validation_mem_alloc(ctx, size))\n\t\treturn -ENOMEM;\n\n\tctx->mem_size_left += size;\n\treturn 0;\n}\n\n \nint vmw_validation_preload_res(struct vmw_validation_context *ctx,\n\t\t\t       unsigned int size)\n{\n\tsize = vmw_validation_align(sizeof(struct vmw_validation_res_node) +\n\t\t\t\t    size) +\n\t\tvmw_validation_align(sizeof(struct vmw_validation_bo_node));\n\tif (!vmw_validation_mem_alloc(ctx, size))\n\t\treturn -ENOMEM;\n\n\tctx->mem_size_left += size;\n\treturn 0;\n}\n\n \nvoid vmw_validation_bo_backoff(struct vmw_validation_context *ctx)\n{\n\tstruct vmw_validation_bo_node *entry;\n\n\t \n\tlist_for_each_entry(entry, &ctx->bo_list, base.head) {\n\t\tif (entry->coherent_count) {\n\t\t\tunsigned int coherent_count = entry->coherent_count;\n\t\t\tstruct vmw_bo *vbo = to_vmw_bo(&entry->base.bo->base);\n\n\t\t\twhile (coherent_count--)\n\t\t\t\tvmw_bo_dirty_release(vbo);\n\t\t}\n\t}\n\n\tttm_eu_backoff_reservation(&ctx->ticket, &ctx->bo_list);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}