{
  "module_name": "vbva_base.c",
  "hash_id": "e0270af7a84b50159a25be300e6eb1b2ccc3da407a717bf162ac3132ededc469",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vboxvideo/vbva_base.c",
  "human_readable_source": "\n \n\n#include <linux/vbox_err.h>\n#include \"vbox_drv.h\"\n#include \"vboxvideo_guest.h\"\n#include \"hgsmi_channels.h\"\n\n \n\nstatic u32 vbva_buffer_available(const struct vbva_buffer *vbva)\n{\n\ts32 diff = vbva->data_offset - vbva->free_offset;\n\n\treturn diff > 0 ? diff : vbva->data_len + diff;\n}\n\nstatic void vbva_buffer_place_data_at(struct vbva_buf_ctx *vbva_ctx,\n\t\t\t\t      const void *p, u32 len, u32 offset)\n{\n\tstruct vbva_buffer *vbva = vbva_ctx->vbva;\n\tu32 bytes_till_boundary = vbva->data_len - offset;\n\tu8 *dst = &vbva->data[offset];\n\ts32 diff = len - bytes_till_boundary;\n\n\tif (diff <= 0) {\n\t\t \n\t\tmemcpy(dst, p, len);\n\t} else {\n\t\t \n\t\tmemcpy(dst, p, bytes_till_boundary);\n\t\tmemcpy(&vbva->data[0], (u8 *)p + bytes_till_boundary, diff);\n\t}\n}\n\nstatic void vbva_buffer_flush(struct gen_pool *ctx)\n{\n\tstruct vbva_flush *p;\n\n\tp = hgsmi_buffer_alloc(ctx, sizeof(*p), HGSMI_CH_VBVA, VBVA_FLUSH);\n\tif (!p)\n\t\treturn;\n\n\tp->reserved = 0;\n\n\thgsmi_buffer_submit(ctx, p);\n\thgsmi_buffer_free(ctx, p);\n}\n\nbool vbva_write(struct vbva_buf_ctx *vbva_ctx, struct gen_pool *ctx,\n\t\tconst void *p, u32 len)\n{\n\tstruct vbva_record *record;\n\tstruct vbva_buffer *vbva;\n\tu32 available;\n\n\tvbva = vbva_ctx->vbva;\n\trecord = vbva_ctx->record;\n\n\tif (!vbva || vbva_ctx->buffer_overflow ||\n\t    !record || !(record->len_and_flags & VBVA_F_RECORD_PARTIAL))\n\t\treturn false;\n\n\tavailable = vbva_buffer_available(vbva);\n\n\twhile (len > 0) {\n\t\tu32 chunk = len;\n\n\t\tif (chunk >= available) {\n\t\t\tvbva_buffer_flush(ctx);\n\t\t\tavailable = vbva_buffer_available(vbva);\n\t\t}\n\n\t\tif (chunk >= available) {\n\t\t\tif (WARN_ON(available <= vbva->partial_write_tresh)) {\n\t\t\t\tvbva_ctx->buffer_overflow = true;\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tchunk = available - vbva->partial_write_tresh;\n\t\t}\n\n\t\tvbva_buffer_place_data_at(vbva_ctx, p, chunk,\n\t\t\t\t\t  vbva->free_offset);\n\n\t\tvbva->free_offset = (vbva->free_offset + chunk) %\n\t\t\t\t    vbva->data_len;\n\t\trecord->len_and_flags += chunk;\n\t\tavailable -= chunk;\n\t\tlen -= chunk;\n\t\tp += chunk;\n\t}\n\n\treturn true;\n}\n\nstatic bool vbva_inform_host(struct vbva_buf_ctx *vbva_ctx,\n\t\t\t     struct gen_pool *ctx, s32 screen, bool enable)\n{\n\tstruct vbva_enable_ex *p;\n\tbool ret;\n\n\tp = hgsmi_buffer_alloc(ctx, sizeof(*p), HGSMI_CH_VBVA, VBVA_ENABLE);\n\tif (!p)\n\t\treturn false;\n\n\tp->base.flags = enable ? VBVA_F_ENABLE : VBVA_F_DISABLE;\n\tp->base.offset = vbva_ctx->buffer_offset;\n\tp->base.result = VERR_NOT_SUPPORTED;\n\tif (screen >= 0) {\n\t\tp->base.flags |= VBVA_F_EXTENDED | VBVA_F_ABSOFFSET;\n\t\tp->screen_id = screen;\n\t}\n\n\thgsmi_buffer_submit(ctx, p);\n\n\tif (enable)\n\t\tret = p->base.result >= 0;\n\telse\n\t\tret = true;\n\n\thgsmi_buffer_free(ctx, p);\n\n\treturn ret;\n}\n\nbool vbva_enable(struct vbva_buf_ctx *vbva_ctx, struct gen_pool *ctx,\n\t\t struct vbva_buffer *vbva, s32 screen)\n{\n\tbool ret = false;\n\n\tmemset(vbva, 0, sizeof(*vbva));\n\tvbva->partial_write_tresh = 256;\n\tvbva->data_len = vbva_ctx->buffer_length - sizeof(struct vbva_buffer);\n\tvbva_ctx->vbva = vbva;\n\n\tret = vbva_inform_host(vbva_ctx, ctx, screen, true);\n\tif (!ret)\n\t\tvbva_disable(vbva_ctx, ctx, screen);\n\n\treturn ret;\n}\n\nvoid vbva_disable(struct vbva_buf_ctx *vbva_ctx, struct gen_pool *ctx,\n\t\t  s32 screen)\n{\n\tvbva_ctx->buffer_overflow = false;\n\tvbva_ctx->record = NULL;\n\tvbva_ctx->vbva = NULL;\n\n\tvbva_inform_host(vbva_ctx, ctx, screen, false);\n}\n\nbool vbva_buffer_begin_update(struct vbva_buf_ctx *vbva_ctx,\n\t\t\t      struct gen_pool *ctx)\n{\n\tstruct vbva_record *record;\n\tu32 next;\n\n\tif (!vbva_ctx->vbva ||\n\t    !(vbva_ctx->vbva->host_flags.host_events & VBVA_F_MODE_ENABLED))\n\t\treturn false;\n\n\tWARN_ON(vbva_ctx->buffer_overflow || vbva_ctx->record);\n\n\tnext = (vbva_ctx->vbva->record_free_index + 1) % VBVA_MAX_RECORDS;\n\n\t \n\tif (next == vbva_ctx->vbva->record_first_index)\n\t\tvbva_buffer_flush(ctx);\n\n\t \n\tif (next == vbva_ctx->vbva->record_first_index)\n\t\treturn false;\n\n\trecord = &vbva_ctx->vbva->records[vbva_ctx->vbva->record_free_index];\n\trecord->len_and_flags = VBVA_F_RECORD_PARTIAL;\n\tvbva_ctx->vbva->record_free_index = next;\n\t \n\tvbva_ctx->record = record;\n\n\treturn true;\n}\n\nvoid vbva_buffer_end_update(struct vbva_buf_ctx *vbva_ctx)\n{\n\tstruct vbva_record *record = vbva_ctx->record;\n\n\tWARN_ON(!vbva_ctx->vbva || !record ||\n\t\t!(record->len_and_flags & VBVA_F_RECORD_PARTIAL));\n\n\t \n\trecord->len_and_flags &= ~VBVA_F_RECORD_PARTIAL;\n\n\tvbva_ctx->buffer_overflow = false;\n\tvbva_ctx->record = NULL;\n}\n\nvoid vbva_setup_buffer_context(struct vbva_buf_ctx *vbva_ctx,\n\t\t\t       u32 buffer_offset, u32 buffer_length)\n{\n\tvbva_ctx->buffer_offset = buffer_offset;\n\tvbva_ctx->buffer_length = buffer_length;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}