{
  "module_name": "aldebaran.c",
  "hash_id": "5dbbf80d13b7dbe6c5cbd76294fdf7a60291546b45a1c8a5c08b494feb843040",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/aldebaran.c",
  "human_readable_source": " \n\n#include \"aldebaran.h\"\n#include \"amdgpu_reset.h\"\n#include \"amdgpu_amdkfd.h\"\n#include \"amdgpu_dpm.h\"\n#include \"amdgpu_job.h\"\n#include \"amdgpu_ring.h\"\n#include \"amdgpu_ras.h\"\n#include \"amdgpu_psp.h\"\n#include \"amdgpu_xgmi.h\"\n\nstatic bool aldebaran_is_mode2_default(struct amdgpu_reset_control *reset_ctl)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)reset_ctl->handle;\n\n\tif ((adev->ip_versions[MP1_HWIP][0] == IP_VERSION(13, 0, 2) &&\n\t     adev->gmc.xgmi.connected_to_cpu))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic struct amdgpu_reset_handler *\naldebaran_get_reset_handler(struct amdgpu_reset_control *reset_ctl,\n\t\t\t    struct amdgpu_reset_context *reset_context)\n{\n\tstruct amdgpu_reset_handler *handler;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)reset_ctl->handle;\n\n\tif (reset_context->method != AMD_RESET_METHOD_NONE) {\n\t\tdev_dbg(adev->dev, \"Getting reset handler for method %d\\n\",\n\t\t\treset_context->method);\n\t\tlist_for_each_entry(handler, &reset_ctl->reset_handlers,\n\t\t\t\t     handler_list) {\n\t\t\tif (handler->reset_method == reset_context->method)\n\t\t\t\treturn handler;\n\t\t}\n\t}\n\n\tif (aldebaran_is_mode2_default(reset_ctl)) {\n\t\tlist_for_each_entry(handler, &reset_ctl->reset_handlers,\n\t\t\t\t     handler_list) {\n\t\t\tif (handler->reset_method == AMD_RESET_METHOD_MODE2) {\n\t\t\t\treset_context->method = AMD_RESET_METHOD_MODE2;\n\t\t\t\treturn handler;\n\t\t\t}\n\t\t}\n\t}\n\n\tdev_dbg(adev->dev, \"Reset handler not found!\\n\");\n\n\treturn NULL;\n}\n\nstatic int aldebaran_mode2_suspend_ip(struct amdgpu_device *adev)\n{\n\tint r, i;\n\n\tamdgpu_device_set_pg_state(adev, AMD_PG_STATE_UNGATE);\n\tamdgpu_device_set_cg_state(adev, AMD_CG_STATE_UNGATE);\n\n\tfor (i = adev->num_ip_blocks - 1; i >= 0; i--) {\n\t\tif (!(adev->ip_blocks[i].version->type ==\n\t\t\t      AMD_IP_BLOCK_TYPE_GFX ||\n\t\t      adev->ip_blocks[i].version->type ==\n\t\t\t      AMD_IP_BLOCK_TYPE_SDMA))\n\t\t\tcontinue;\n\n\t\tr = adev->ip_blocks[i].version->funcs->suspend(adev);\n\n\t\tif (r) {\n\t\t\tdev_err(adev->dev,\n\t\t\t\t\"suspend of IP block <%s> failed %d\\n\",\n\t\t\t\tadev->ip_blocks[i].version->funcs->name, r);\n\t\t\treturn r;\n\t\t}\n\n\t\tadev->ip_blocks[i].status.hw = false;\n\t}\n\n\treturn r;\n}\n\nstatic int\naldebaran_mode2_prepare_hwcontext(struct amdgpu_reset_control *reset_ctl,\n\t\t\t\t  struct amdgpu_reset_context *reset_context)\n{\n\tint r = 0;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)reset_ctl->handle;\n\n\tdev_dbg(adev->dev, \"Aldebaran prepare hw context\\n\");\n\t \n\tif (!amdgpu_sriov_vf(adev))\n\t\tr = aldebaran_mode2_suspend_ip(adev);\n\n\treturn r;\n}\n\nstatic void aldebaran_async_reset(struct work_struct *work)\n{\n\tstruct amdgpu_reset_handler *handler;\n\tstruct amdgpu_reset_control *reset_ctl =\n\t\tcontainer_of(work, struct amdgpu_reset_control, reset_work);\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)reset_ctl->handle;\n\n\tlist_for_each_entry(handler, &reset_ctl->reset_handlers,\n\t\t\t     handler_list) {\n\t\tif (handler->reset_method == reset_ctl->active_reset) {\n\t\t\tdev_dbg(adev->dev, \"Resetting device\\n\");\n\t\t\thandler->do_reset(adev);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic int aldebaran_mode2_reset(struct amdgpu_device *adev)\n{\n\t \n\tpci_clear_master(adev->pdev);\n\tadev->asic_reset_res = amdgpu_dpm_mode2_reset(adev);\n\treturn adev->asic_reset_res;\n}\n\nstatic int\naldebaran_mode2_perform_reset(struct amdgpu_reset_control *reset_ctl,\n\t\t\t      struct amdgpu_reset_context *reset_context)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)reset_ctl->handle;\n\tstruct list_head *reset_device_list = reset_context->reset_device_list;\n\tstruct amdgpu_device *tmp_adev = NULL;\n\tint r = 0;\n\n\tdev_dbg(adev->dev, \"aldebaran perform hw reset\\n\");\n\n\tif (reset_device_list == NULL)\n\t\treturn -EINVAL;\n\n\tif (adev->ip_versions[MP1_HWIP][0] == IP_VERSION(13, 0, 2) &&\n\t    reset_context->hive == NULL) {\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\tlist_for_each_entry(tmp_adev, reset_device_list, reset_list) {\n\t\tmutex_lock(&tmp_adev->reset_cntl->reset_lock);\n\t\ttmp_adev->reset_cntl->active_reset = AMD_RESET_METHOD_MODE2;\n\t}\n\t \n\tlist_for_each_entry(tmp_adev, reset_device_list, reset_list) {\n\t\t \n\t\tif (tmp_adev->gmc.xgmi.num_physical_nodes > 1) {\n\t\t\tif (!queue_work(system_unbound_wq,\n\t\t\t\t\t&tmp_adev->reset_cntl->reset_work))\n\t\t\t\tr = -EALREADY;\n\t\t} else\n\t\t\tr = aldebaran_mode2_reset(tmp_adev);\n\t\tif (r) {\n\t\t\tdev_err(tmp_adev->dev,\n\t\t\t\t\"ASIC reset failed with error, %d for drm dev, %s\",\n\t\t\t\tr, adev_to_drm(tmp_adev)->unique);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (!r) {\n\t\tlist_for_each_entry(tmp_adev, reset_device_list, reset_list) {\n\t\t\tif (tmp_adev->gmc.xgmi.num_physical_nodes > 1) {\n\t\t\t\tflush_work(&tmp_adev->reset_cntl->reset_work);\n\t\t\t\tr = tmp_adev->asic_reset_res;\n\t\t\t\tif (r)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tlist_for_each_entry(tmp_adev, reset_device_list, reset_list) {\n\t\tmutex_unlock(&tmp_adev->reset_cntl->reset_lock);\n\t\ttmp_adev->reset_cntl->active_reset = AMD_RESET_METHOD_NONE;\n\t}\n\n\treturn r;\n}\n\nstatic int aldebaran_mode2_restore_ip(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_firmware_info *ucode_list[AMDGPU_UCODE_ID_MAXIMUM];\n\tstruct amdgpu_firmware_info *ucode;\n\tstruct amdgpu_ip_block *cmn_block;\n\tint ucode_count = 0;\n\tint i, r;\n\n\tdev_dbg(adev->dev, \"Reloading ucodes after reset\\n\");\n\tfor (i = 0; i < adev->firmware.max_ucodes; i++) {\n\t\tucode = &adev->firmware.ucode[i];\n\t\tif (!ucode->fw)\n\t\t\tcontinue;\n\t\tswitch (ucode->ucode_id) {\n\t\tcase AMDGPU_UCODE_ID_SDMA0:\n\t\tcase AMDGPU_UCODE_ID_SDMA1:\n\t\tcase AMDGPU_UCODE_ID_SDMA2:\n\t\tcase AMDGPU_UCODE_ID_SDMA3:\n\t\tcase AMDGPU_UCODE_ID_SDMA4:\n\t\tcase AMDGPU_UCODE_ID_SDMA5:\n\t\tcase AMDGPU_UCODE_ID_SDMA6:\n\t\tcase AMDGPU_UCODE_ID_SDMA7:\n\t\tcase AMDGPU_UCODE_ID_CP_MEC1:\n\t\tcase AMDGPU_UCODE_ID_CP_MEC1_JT:\n\t\tcase AMDGPU_UCODE_ID_RLC_RESTORE_LIST_CNTL:\n\t\tcase AMDGPU_UCODE_ID_RLC_RESTORE_LIST_GPM_MEM:\n\t\tcase AMDGPU_UCODE_ID_RLC_RESTORE_LIST_SRM_MEM:\n\t\tcase AMDGPU_UCODE_ID_RLC_G:\n\t\t\tucode_list[ucode_count++] = ucode;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tcmn_block =\n\t\tamdgpu_device_ip_get_ip_block(adev, AMD_IP_BLOCK_TYPE_COMMON);\n\tif (unlikely(!cmn_block)) {\n\t\tdev_err(adev->dev, \"Failed to get BIF handle\\n\");\n\t\treturn -EINVAL;\n\t}\n\tr = cmn_block->version->funcs->resume(adev);\n\tif (r)\n\t\treturn r;\n\n\t \n\tadev->gfxhub.funcs->init(adev);\n\tr = adev->gfxhub.funcs->gart_enable(adev);\n\tif (r) {\n\t\tdev_err(adev->dev, \"GFXHUB gart reenable failed after reset\\n\");\n\t\treturn r;\n\t}\n\n\t \n\tr = psp_load_fw_list(&adev->psp, ucode_list, ucode_count);\n\tif (r) {\n\t\tdev_err(adev->dev, \"GFX ucode load failed after reset\\n\");\n\t\treturn r;\n\t}\n\n\t \n\tadev->gfx.rlc.funcs->resume(adev);\n\n\t \n\tr = amdgpu_dpm_wait_for_event(adev, SMU_EVENT_RESET_COMPLETE, 0);\n\tif (r) {\n\t\tdev_err(adev->dev,\n\t\t\t\"Failed to get response from firmware after reset\\n\");\n\t\treturn r;\n\t}\n\n\tfor (i = 0; i < adev->num_ip_blocks; i++) {\n\t\tif (!(adev->ip_blocks[i].version->type ==\n\t\t\t      AMD_IP_BLOCK_TYPE_GFX ||\n\t\t      adev->ip_blocks[i].version->type ==\n\t\t\t      AMD_IP_BLOCK_TYPE_SDMA))\n\t\t\tcontinue;\n\t\tr = adev->ip_blocks[i].version->funcs->resume(adev);\n\t\tif (r) {\n\t\t\tdev_err(adev->dev,\n\t\t\t\t\"resume of IP block <%s> failed %d\\n\",\n\t\t\t\tadev->ip_blocks[i].version->funcs->name, r);\n\t\t\treturn r;\n\t\t}\n\n\t\tadev->ip_blocks[i].status.hw = true;\n\t}\n\n\tfor (i = 0; i < adev->num_ip_blocks; i++) {\n\t\tif (!(adev->ip_blocks[i].version->type ==\n\t\t\t      AMD_IP_BLOCK_TYPE_GFX ||\n\t\t      adev->ip_blocks[i].version->type ==\n\t\t\t      AMD_IP_BLOCK_TYPE_SDMA ||\n\t\t      adev->ip_blocks[i].version->type ==\n\t\t\t      AMD_IP_BLOCK_TYPE_COMMON))\n\t\t\tcontinue;\n\n\t\tif (adev->ip_blocks[i].version->funcs->late_init) {\n\t\t\tr = adev->ip_blocks[i].version->funcs->late_init(\n\t\t\t\t(void *)adev);\n\t\t\tif (r) {\n\t\t\t\tdev_err(adev->dev,\n\t\t\t\t\t\"late_init of IP block <%s> failed %d after reset\\n\",\n\t\t\t\t\tadev->ip_blocks[i].version->funcs->name,\n\t\t\t\t\tr);\n\t\t\t\treturn r;\n\t\t\t}\n\t\t}\n\t\tadev->ip_blocks[i].status.late_initialized = true;\n\t}\n\n\tamdgpu_ras_set_error_query_ready(adev, true);\n\n\tamdgpu_device_set_cg_state(adev, AMD_CG_STATE_GATE);\n\tamdgpu_device_set_pg_state(adev, AMD_PG_STATE_GATE);\n\n\treturn r;\n}\n\nstatic int\naldebaran_mode2_restore_hwcontext(struct amdgpu_reset_control *reset_ctl,\n\t\t\t\t  struct amdgpu_reset_context *reset_context)\n{\n\tstruct list_head *reset_device_list = reset_context->reset_device_list;\n\tstruct amdgpu_device *tmp_adev = NULL;\n\tint r;\n\n\tif (reset_device_list == NULL)\n\t\treturn -EINVAL;\n\n\tif (reset_context->reset_req_dev->ip_versions[MP1_HWIP][0] ==\n\t\t    IP_VERSION(13, 0, 2) &&\n\t    reset_context->hive == NULL) {\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\tlist_for_each_entry(tmp_adev, reset_device_list, reset_list) {\n\t\tdev_info(tmp_adev->dev,\n\t\t\t \"GPU reset succeeded, trying to resume\\n\");\n\t\tr = aldebaran_mode2_restore_ip(tmp_adev);\n\t\tif (r)\n\t\t\tgoto end;\n\n\t\t \n\t\tamdgpu_register_gpu_instance(tmp_adev);\n\n\t\t \n\t\tamdgpu_ras_resume(tmp_adev);\n\n\t\t \n\t\tif (reset_context->hive &&\n\t\t    tmp_adev->gmc.xgmi.num_physical_nodes > 1)\n\t\t\tr = amdgpu_xgmi_update_topology(reset_context->hive,\n\t\t\t\t\t\t\ttmp_adev);\n\n\t\tif (!r) {\n\t\t\tamdgpu_irq_gpu_reset_resume_helper(tmp_adev);\n\n\t\t\tr = amdgpu_ib_ring_tests(tmp_adev);\n\t\t\tif (r) {\n\t\t\t\tdev_err(tmp_adev->dev,\n\t\t\t\t\t\"ib ring test failed (%d).\\n\", r);\n\t\t\t\tr = -EAGAIN;\n\t\t\t\ttmp_adev->asic_reset_res = r;\n\t\t\t\tgoto end;\n\t\t\t}\n\t\t}\n\t}\n\nend:\n\treturn r;\n}\n\nstatic struct amdgpu_reset_handler aldebaran_mode2_handler = {\n\t.reset_method\t\t= AMD_RESET_METHOD_MODE2,\n\t.prepare_env\t\t= NULL,\n\t.prepare_hwcontext\t= aldebaran_mode2_prepare_hwcontext,\n\t.perform_reset\t\t= aldebaran_mode2_perform_reset,\n\t.restore_hwcontext\t= aldebaran_mode2_restore_hwcontext,\n\t.restore_env\t\t= NULL,\n\t.do_reset\t\t= aldebaran_mode2_reset,\n};\n\nint aldebaran_reset_init(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_reset_control *reset_ctl;\n\n\treset_ctl = kzalloc(sizeof(*reset_ctl), GFP_KERNEL);\n\tif (!reset_ctl)\n\t\treturn -ENOMEM;\n\n\treset_ctl->handle = adev;\n\treset_ctl->async_reset = aldebaran_async_reset;\n\treset_ctl->active_reset = AMD_RESET_METHOD_NONE;\n\treset_ctl->get_reset_handler = aldebaran_get_reset_handler;\n\n\tINIT_LIST_HEAD(&reset_ctl->reset_handlers);\n\tINIT_WORK(&reset_ctl->reset_work, reset_ctl->async_reset);\n\t \n\tamdgpu_reset_add_handler(reset_ctl, &aldebaran_mode2_handler);\n\n\tadev->reset_cntl = reset_ctl;\n\n\treturn 0;\n}\n\nint aldebaran_reset_fini(struct amdgpu_device *adev)\n{\n\tkfree(adev->reset_cntl);\n\tadev->reset_cntl = NULL;\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}