{
  "module_name": "amdgpu_hmm.c",
  "hash_id": "1d16eadede8a430b8bf1b29731ba8ee497ec430a1cd646c7fb7b7dd4bd3a61d5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_hmm.c",
  "human_readable_source": " \n \n\n \n\n#include <linux/firmware.h>\n#include <linux/module.h>\n#include <drm/drm.h>\n\n#include \"amdgpu.h\"\n#include \"amdgpu_amdkfd.h\"\n#include \"amdgpu_hmm.h\"\n\n#define MAX_WALK_BYTE\t(2UL << 30)\n\n \nstatic bool amdgpu_hmm_invalidate_gfx(struct mmu_interval_notifier *mni,\n\t\t\t\t      const struct mmu_notifier_range *range,\n\t\t\t\t      unsigned long cur_seq)\n{\n\tstruct amdgpu_bo *bo = container_of(mni, struct amdgpu_bo, notifier);\n\tstruct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);\n\tlong r;\n\n\tif (!mmu_notifier_range_blockable(range))\n\t\treturn false;\n\n\tmutex_lock(&adev->notifier_lock);\n\n\tmmu_interval_set_seq(mni, cur_seq);\n\n\tr = dma_resv_wait_timeout(bo->tbo.base.resv, DMA_RESV_USAGE_BOOKKEEP,\n\t\t\t\t  false, MAX_SCHEDULE_TIMEOUT);\n\tmutex_unlock(&adev->notifier_lock);\n\tif (r <= 0)\n\t\tDRM_ERROR(\"(%ld) failed to wait for user bo\\n\", r);\n\treturn true;\n}\n\nstatic const struct mmu_interval_notifier_ops amdgpu_hmm_gfx_ops = {\n\t.invalidate = amdgpu_hmm_invalidate_gfx,\n};\n\n \nstatic bool amdgpu_hmm_invalidate_hsa(struct mmu_interval_notifier *mni,\n\t\t\t\t      const struct mmu_notifier_range *range,\n\t\t\t\t      unsigned long cur_seq)\n{\n\tstruct amdgpu_bo *bo = container_of(mni, struct amdgpu_bo, notifier);\n\n\tif (!mmu_notifier_range_blockable(range))\n\t\treturn false;\n\n\tamdgpu_amdkfd_evict_userptr(mni, cur_seq, bo->kfd_bo);\n\n\treturn true;\n}\n\nstatic const struct mmu_interval_notifier_ops amdgpu_hmm_hsa_ops = {\n\t.invalidate = amdgpu_hmm_invalidate_hsa,\n};\n\n \nint amdgpu_hmm_register(struct amdgpu_bo *bo, unsigned long addr)\n{\n\tif (bo->kfd_bo)\n\t\treturn mmu_interval_notifier_insert(&bo->notifier, current->mm,\n\t\t\t\t\t\t    addr, amdgpu_bo_size(bo),\n\t\t\t\t\t\t    &amdgpu_hmm_hsa_ops);\n\treturn mmu_interval_notifier_insert(&bo->notifier, current->mm, addr,\n\t\t\t\t\t    amdgpu_bo_size(bo),\n\t\t\t\t\t    &amdgpu_hmm_gfx_ops);\n}\n\n \nvoid amdgpu_hmm_unregister(struct amdgpu_bo *bo)\n{\n\tif (!bo->notifier.mm)\n\t\treturn;\n\tmmu_interval_notifier_remove(&bo->notifier);\n\tbo->notifier.mm = NULL;\n}\n\nint amdgpu_hmm_range_get_pages(struct mmu_interval_notifier *notifier,\n\t\t\t       uint64_t start, uint64_t npages, bool readonly,\n\t\t\t       void *owner, struct page **pages,\n\t\t\t       struct hmm_range **phmm_range)\n{\n\tstruct hmm_range *hmm_range;\n\tunsigned long end;\n\tunsigned long timeout;\n\tunsigned long i;\n\tunsigned long *pfns;\n\tint r = 0;\n\n\thmm_range = kzalloc(sizeof(*hmm_range), GFP_KERNEL);\n\tif (unlikely(!hmm_range))\n\t\treturn -ENOMEM;\n\n\tpfns = kvmalloc_array(npages, sizeof(*pfns), GFP_KERNEL);\n\tif (unlikely(!pfns)) {\n\t\tr = -ENOMEM;\n\t\tgoto out_free_range;\n\t}\n\n\thmm_range->notifier = notifier;\n\thmm_range->default_flags = HMM_PFN_REQ_FAULT;\n\tif (!readonly)\n\t\thmm_range->default_flags |= HMM_PFN_REQ_WRITE;\n\thmm_range->hmm_pfns = pfns;\n\thmm_range->start = start;\n\tend = start + npages * PAGE_SIZE;\n\thmm_range->dev_private_owner = owner;\n\n\tdo {\n\t\thmm_range->end = min(hmm_range->start + MAX_WALK_BYTE, end);\n\n\t\tpr_debug(\"hmm range: start = 0x%lx, end = 0x%lx\",\n\t\t\thmm_range->start, hmm_range->end);\n\n\t\t \n\t\ttimeout = max((hmm_range->end - hmm_range->start) >> 27, 1UL);\n\t\ttimeout *= HMM_RANGE_DEFAULT_TIMEOUT;\n\t\ttimeout = jiffies + msecs_to_jiffies(timeout);\n\nretry:\n\t\thmm_range->notifier_seq = mmu_interval_read_begin(notifier);\n\t\tr = hmm_range_fault(hmm_range);\n\t\tif (unlikely(r)) {\n\t\t\t \n\t\t\tif (r == -EBUSY && !time_after(jiffies, timeout))\n\t\t\t\tgoto retry;\n\t\t\tgoto out_free_pfns;\n\t\t}\n\n\t\tif (hmm_range->end == end)\n\t\t\tbreak;\n\t\thmm_range->hmm_pfns += MAX_WALK_BYTE >> PAGE_SHIFT;\n\t\thmm_range->start = hmm_range->end;\n\t\tschedule();\n\t} while (hmm_range->end < end);\n\n\thmm_range->start = start;\n\thmm_range->hmm_pfns = pfns;\n\n\t \n\tfor (i = 0; pages && i < npages; i++)\n\t\tpages[i] = hmm_pfn_to_page(pfns[i]);\n\n\t*phmm_range = hmm_range;\n\n\treturn 0;\n\nout_free_pfns:\n\tkvfree(pfns);\nout_free_range:\n\tkfree(hmm_range);\n\n\treturn r;\n}\n\nbool amdgpu_hmm_range_get_pages_done(struct hmm_range *hmm_range)\n{\n\tbool r;\n\n\tr = mmu_interval_read_retry(hmm_range->notifier,\n\t\t\t\t    hmm_range->notifier_seq);\n\tkvfree(hmm_range->hmm_pfns);\n\tkfree(hmm_range);\n\n\treturn r;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}