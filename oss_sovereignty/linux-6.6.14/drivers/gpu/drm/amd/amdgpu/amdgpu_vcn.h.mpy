{
  "module_name": "amdgpu_vcn.h",
  "hash_id": "30bcdeef0df64a1c1d5beff9694d7ce9f07716ffe022c7f37abcd2e19fc39883",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_vcn.h",
  "human_readable_source": " \n\n#ifndef __AMDGPU_VCN_H__\n#define __AMDGPU_VCN_H__\n\n#include \"amdgpu_ras.h\"\n\n#define AMDGPU_VCN_STACK_SIZE\t\t(128*1024)\n#define AMDGPU_VCN_CONTEXT_SIZE \t(512*1024)\n\n#define AMDGPU_VCN_FIRMWARE_OFFSET\t256\n#define AMDGPU_VCN_MAX_ENC_RINGS\t3\n\n#define AMDGPU_MAX_VCN_INSTANCES\t4\n#define AMDGPU_MAX_VCN_ENC_RINGS  AMDGPU_VCN_MAX_ENC_RINGS * AMDGPU_MAX_VCN_INSTANCES\n\n#define AMDGPU_VCN_HARVEST_VCN0 (1 << 0)\n#define AMDGPU_VCN_HARVEST_VCN1 (1 << 1)\n\n#define VCN_DEC_KMD_CMD \t\t0x80000000\n#define VCN_DEC_CMD_FENCE\t\t0x00000000\n#define VCN_DEC_CMD_TRAP\t\t0x00000001\n#define VCN_DEC_CMD_WRITE_REG\t\t0x00000004\n#define VCN_DEC_CMD_REG_READ_COND_WAIT\t0x00000006\n#define VCN_DEC_CMD_PACKET_START\t0x0000000a\n#define VCN_DEC_CMD_PACKET_END\t\t0x0000000b\n\n#define VCN_DEC_SW_CMD_NO_OP\t\t0x00000000\n#define VCN_DEC_SW_CMD_END\t\t0x00000001\n#define VCN_DEC_SW_CMD_IB\t\t0x00000002\n#define VCN_DEC_SW_CMD_FENCE\t\t0x00000003\n#define VCN_DEC_SW_CMD_TRAP\t\t0x00000004\n#define VCN_DEC_SW_CMD_IB_AUTO\t\t0x00000005\n#define VCN_DEC_SW_CMD_SEMAPHORE\t0x00000006\n#define VCN_DEC_SW_CMD_PREEMPT_FENCE\t0x00000009\n#define VCN_DEC_SW_CMD_REG_WRITE\t0x0000000b\n#define VCN_DEC_SW_CMD_REG_WAIT\t\t0x0000000c\n\n#define VCN_ENC_CMD_NO_OP\t\t0x00000000\n#define VCN_ENC_CMD_END \t\t0x00000001\n#define VCN_ENC_CMD_IB\t\t\t0x00000002\n#define VCN_ENC_CMD_FENCE\t\t0x00000003\n#define VCN_ENC_CMD_TRAP\t\t0x00000004\n#define VCN_ENC_CMD_REG_WRITE\t\t0x0000000b\n#define VCN_ENC_CMD_REG_WAIT\t\t0x0000000c\n\n#define VCN_AON_SOC_ADDRESS_2_0 \t0x1f800\n#define VCN1_AON_SOC_ADDRESS_3_0 \t0x48000\n#define VCN_VID_IP_ADDRESS_2_0\t\t0x0\n#define VCN_AON_IP_ADDRESS_2_0\t\t0x30000\n\n#define mmUVD_RBC_XX_IB_REG_CHECK \t\t\t\t\t0x026b\n#define mmUVD_RBC_XX_IB_REG_CHECK_BASE_IDX \t\t\t\t1\n#define mmUVD_REG_XX_MASK \t\t\t\t\t\t0x026c\n#define mmUVD_REG_XX_MASK_BASE_IDX \t\t\t\t\t1\n\n \n#define VCN_IDLE_TIMEOUT\tmsecs_to_jiffies(1000)\n\n#define RREG32_SOC15_DPG_MODE_1_0(ip, inst_idx, reg, mask, sram_sel) \t\t\t\\\n\t({\tWREG32_SOC15(ip, inst_idx, mmUVD_DPG_LMA_MASK, mask); \t\t\t\\\n\t\tWREG32_SOC15(ip, inst_idx, mmUVD_DPG_LMA_CTL, \t\t\t\t\\\n\t\t\tUVD_DPG_LMA_CTL__MASK_EN_MASK | \t\t\t\t\\\n\t\t\t((adev->reg_offset[ip##_HWIP][inst_idx][reg##_BASE_IDX] + reg) \t\\\n\t\t\t<< UVD_DPG_LMA_CTL__READ_WRITE_ADDR__SHIFT) | \t\t\t\\\n\t\t\t(sram_sel << UVD_DPG_LMA_CTL__SRAM_SEL__SHIFT)); \t\t\\\n\t\tRREG32_SOC15(ip, inst_idx, mmUVD_DPG_LMA_DATA); \t\t\t\\\n\t})\n\n#define WREG32_SOC15_DPG_MODE_1_0(ip, inst_idx, reg, value, mask, sram_sel) \t\t\\\n\tdo { \t\t\t\t\t\t\t\t\t\t\\\n\t\tWREG32_SOC15(ip, inst_idx, mmUVD_DPG_LMA_DATA, value); \t\t\t\\\n\t\tWREG32_SOC15(ip, inst_idx, mmUVD_DPG_LMA_MASK, mask); \t\t\t\\\n\t\tWREG32_SOC15(ip, inst_idx, mmUVD_DPG_LMA_CTL, \t\t\t\t\\\n\t\t\tUVD_DPG_LMA_CTL__READ_WRITE_MASK | \t\t\t\t\\\n\t\t\t((adev->reg_offset[ip##_HWIP][inst_idx][reg##_BASE_IDX] + reg) \t\\\n\t\t\t<< UVD_DPG_LMA_CTL__READ_WRITE_ADDR__SHIFT) | \t\t\t\\\n\t\t\t(sram_sel << UVD_DPG_LMA_CTL__SRAM_SEL__SHIFT)); \t\t\\\n\t} while (0)\n\n#define SOC15_DPG_MODE_OFFSET(ip, inst_idx, reg) \t\t\t\t\t\t\\\n\t({\t\t\t\t\t\t\t\t\t\t\t\\\n\t\tuint32_t internal_reg_offset, addr;\t\t\t\t\t\t\\\n\t\tbool video_range, video1_range, aon_range, aon1_range;\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\t\t\t\\\n\t\taddr = (adev->reg_offset[ip##_HWIP][inst_idx][reg##_BASE_IDX] + reg);\t\t\\\n\t\taddr <<= 2; \t\t\t\t\t\t\t\t\t\\\n\t\tvideo_range = ((((0xFFFFF & addr) >= (VCN_VID_SOC_ADDRESS_2_0)) && \t\t\\\n\t\t\t\t((0xFFFFF & addr) < ((VCN_VID_SOC_ADDRESS_2_0 + 0x2600)))));\t\\\n\t\tvideo1_range = ((((0xFFFFF & addr) >= (VCN1_VID_SOC_ADDRESS_3_0)) && \t\t\\\n\t\t\t\t((0xFFFFF & addr) < ((VCN1_VID_SOC_ADDRESS_3_0 + 0x2600)))));\t\\\n\t\taon_range   = ((((0xFFFFF & addr) >= (VCN_AON_SOC_ADDRESS_2_0)) && \t\t\\\n\t\t\t\t((0xFFFFF & addr) < ((VCN_AON_SOC_ADDRESS_2_0 + 0x600)))));\t\\\n\t\taon1_range   = ((((0xFFFFF & addr) >= (VCN1_AON_SOC_ADDRESS_3_0)) && \t\t\\\n\t\t\t\t((0xFFFFF & addr) < ((VCN1_AON_SOC_ADDRESS_3_0 + 0x600)))));\t\\\n\t\tif (video_range) \t\t\t\t\t\t\t\t\\\n\t\t\tinternal_reg_offset = ((0xFFFFF & addr) - (VCN_VID_SOC_ADDRESS_2_0) + \t\\\n\t\t\t\t(VCN_VID_IP_ADDRESS_2_0));\t\t\t\t\t\\\n\t\telse if (aon_range)\t\t\t\t\t\t\t\t\\\n\t\t\tinternal_reg_offset = ((0xFFFFF & addr) - (VCN_AON_SOC_ADDRESS_2_0) + \t\\\n\t\t\t\t(VCN_AON_IP_ADDRESS_2_0));\t\t\t\t\t\\\n\t\telse if (video1_range) \t\t\t\t\t\t\t\t\\\n\t\t\tinternal_reg_offset = ((0xFFFFF & addr) - (VCN1_VID_SOC_ADDRESS_3_0) + \t\\\n\t\t\t\t(VCN_VID_IP_ADDRESS_2_0));\t\t\t\t\t\\\n\t\telse if (aon1_range)\t\t\t\t\t\t\t\t\\\n\t\t\tinternal_reg_offset = ((0xFFFFF & addr) - (VCN1_AON_SOC_ADDRESS_3_0) + \t\\\n\t\t\t\t(VCN_AON_IP_ADDRESS_2_0));\t\t\t\t\t\\\n\t\telse\t\t\t\t\t\t\t\t\t\t\\\n\t\t\tinternal_reg_offset = (0xFFFFF & addr);\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\t\t\t\\\n\t\tinternal_reg_offset >>= 2;\t\t\t\t\t\t\t\\\n\t})\n\n#define RREG32_SOC15_DPG_MODE(inst_idx, offset, mask_en) \t\t\t\t\t\\\n\t({\t\t\t\t\t\t\t\t\t\t\t\\\n\t\tWREG32_SOC15(VCN, inst_idx, mmUVD_DPG_LMA_CTL, \t\t\t\t\t\\\n\t\t\t(0x0 << UVD_DPG_LMA_CTL__READ_WRITE__SHIFT |\t\t\t\t\\\n\t\t\tmask_en << UVD_DPG_LMA_CTL__MASK_EN__SHIFT |\t\t\t\t\\\n\t\t\toffset << UVD_DPG_LMA_CTL__READ_WRITE_ADDR__SHIFT));\t\t\t\\\n\t\tRREG32_SOC15(VCN, inst_idx, mmUVD_DPG_LMA_DATA);\t\t\t\t\\\n\t})\n\n#define WREG32_SOC15_DPG_MODE(inst_idx, offset, value, mask_en, indirect)             \\\n\tdo {                                                                          \\\n\t\tif (!indirect) {                                                      \\\n\t\t\tWREG32_SOC15(VCN, GET_INST(VCN, inst_idx),                    \\\n\t\t\t\t     mmUVD_DPG_LMA_DATA, value);                      \\\n\t\t\tWREG32_SOC15(                                                 \\\n\t\t\t\tVCN, GET_INST(VCN, inst_idx),                         \\\n\t\t\t\tmmUVD_DPG_LMA_CTL,                                    \\\n\t\t\t\t(0x1 << UVD_DPG_LMA_CTL__READ_WRITE__SHIFT |          \\\n\t\t\t\t mask_en << UVD_DPG_LMA_CTL__MASK_EN__SHIFT |         \\\n\t\t\t\t offset << UVD_DPG_LMA_CTL__READ_WRITE_ADDR__SHIFT)); \\\n\t\t} else {                                                              \\\n\t\t\t*adev->vcn.inst[inst_idx].dpg_sram_curr_addr++ =              \\\n\t\t\t\toffset;                                               \\\n\t\t\t*adev->vcn.inst[inst_idx].dpg_sram_curr_addr++ =              \\\n\t\t\t\tvalue;                                                \\\n\t\t}                                                                     \\\n\t} while (0)\n\n#define AMDGPU_FW_SHARED_FLAG_0_UNIFIED_QUEUE (1 << 2)\n#define AMDGPU_FW_SHARED_FLAG_0_DRM_KEY_INJECT (1 << 4)\n#define AMDGPU_VCN_FW_SHARED_FLAG_0_RB\t(1 << 6)\n#define AMDGPU_VCN_MULTI_QUEUE_FLAG\t(1 << 8)\n#define AMDGPU_VCN_SW_RING_FLAG\t\t(1 << 9)\n#define AMDGPU_VCN_FW_LOGGING_FLAG\t(1 << 10)\n#define AMDGPU_VCN_SMU_VERSION_INFO_FLAG (1 << 11)\n#define AMDGPU_VCN_SMU_DPM_INTERFACE_FLAG (1 << 11)\n#define AMDGPU_VCN_VF_RB_SETUP_FLAG (1 << 14)\n\n#define AMDGPU_VCN_IB_FLAG_DECODE_BUFFER\t0x00000001\n#define AMDGPU_VCN_CMD_FLAG_MSG_BUFFER\t\t0x00000001\n\n#define VCN_CODEC_DISABLE_MASK_AV1  (1 << 0)\n#define VCN_CODEC_DISABLE_MASK_VP9  (1 << 1)\n#define VCN_CODEC_DISABLE_MASK_HEVC (1 << 2)\n#define VCN_CODEC_DISABLE_MASK_H264 (1 << 3)\n\n#define AMDGPU_VCN_SMU_DPM_INTERFACE_DGPU (0)\n#define AMDGPU_VCN_SMU_DPM_INTERFACE_APU (1)\n\n#define AMDGPU_DRM_KEY_INJECT_WORKAROUND_VCNFW_ASD_HANDSHAKING 2\n\nenum fw_queue_mode {\n\tFW_QUEUE_RING_RESET = 1,\n\tFW_QUEUE_DPG_HOLD_OFF = 2,\n};\n\nenum engine_status_constants {\n\tUVD_PGFSM_STATUS__UVDM_UVDU_PWR_ON = 0x2AAAA0,\n\tUVD_PGFSM_STATUS__UVDM_UVDU_PWR_ON_2_0 = 0xAAAA0,\n\tUVD_PGFSM_STATUS__UVDM_UVDU_UVDLM_PWR_ON_3_0 = 0x2A2A8AA0,\n\tUVD_PGFSM_CONFIG__UVDM_UVDU_PWR_ON = 0x00000002,\n\tUVD_STATUS__UVD_BUSY = 0x00000004,\n\tGB_ADDR_CONFIG_DEFAULT = 0x26010011,\n\tUVD_STATUS__IDLE = 0x2,\n\tUVD_STATUS__BUSY = 0x5,\n\tUVD_POWER_STATUS__UVD_POWER_STATUS_TILES_OFF = 0x1,\n\tUVD_STATUS__RBC_BUSY = 0x1,\n\tUVD_PGFSM_STATUS_UVDJ_PWR_ON = 0,\n};\n\nenum internal_dpg_state {\n\tVCN_DPG_STATE__UNPAUSE = 0,\n\tVCN_DPG_STATE__PAUSE,\n};\n\nstruct dpg_pause_state {\n\tenum internal_dpg_state fw_based;\n\tenum internal_dpg_state jpeg;\n};\n\nstruct amdgpu_vcn_reg{\n\tunsigned\tdata0;\n\tunsigned\tdata1;\n\tunsigned\tcmd;\n\tunsigned\tnop;\n\tunsigned\tcontext_id;\n\tunsigned\tib_vmid;\n\tunsigned\tib_bar_low;\n\tunsigned\tib_bar_high;\n\tunsigned\tib_size;\n\tunsigned\tgp_scratch8;\n\tunsigned\tscratch9;\n};\n\nstruct amdgpu_vcn_fw_shared {\n\tvoid        *cpu_addr;\n\tuint64_t    gpu_addr;\n\tuint32_t    mem_size;\n\tuint32_t    log_offset;\n};\n\nstruct amdgpu_vcn_inst {\n\tstruct amdgpu_bo\t*vcpu_bo;\n\tvoid\t\t\t*cpu_addr;\n\tuint64_t\t\tgpu_addr;\n\tvoid\t\t\t*saved_bo;\n\tstruct amdgpu_ring\tring_dec;\n\tstruct amdgpu_ring\tring_enc[AMDGPU_VCN_MAX_ENC_RINGS];\n\tatomic_t\t\tsched_score;\n\tstruct amdgpu_irq_src\tirq;\n\tstruct amdgpu_irq_src\tras_poison_irq;\n\tstruct amdgpu_vcn_reg\texternal;\n\tstruct amdgpu_bo\t*dpg_sram_bo;\n\tstruct dpg_pause_state\tpause_state;\n\tvoid\t\t\t*dpg_sram_cpu_addr;\n\tuint64_t\t\tdpg_sram_gpu_addr;\n\tuint32_t\t\t*dpg_sram_curr_addr;\n\tatomic_t\t\tdpg_enc_submission_cnt;\n\tstruct amdgpu_vcn_fw_shared fw_shared;\n\tuint8_t\t\t\taid_id;\n};\n\nstruct amdgpu_vcn_ras {\n\tstruct amdgpu_ras_block_object ras_block;\n};\n\nstruct amdgpu_vcn {\n\tunsigned\t\tfw_version;\n\tstruct delayed_work\tidle_work;\n\tconst struct firmware\t*fw;\t \n\tunsigned\t\tnum_enc_rings;\n\tenum amd_powergating_state cur_state;\n\tbool\t\t\tindirect_sram;\n\n\tuint8_t\tnum_vcn_inst;\n\tstruct amdgpu_vcn_inst\t inst[AMDGPU_MAX_VCN_INSTANCES];\n\tuint8_t\t\t\t vcn_config[AMDGPU_MAX_VCN_INSTANCES];\n\tuint32_t\t\t vcn_codec_disable_mask[AMDGPU_MAX_VCN_INSTANCES];\n\tstruct amdgpu_vcn_reg\t internal;\n\tstruct mutex\t\t vcn_pg_lock;\n\tstruct mutex\t\tvcn1_jpeg1_workaround;\n\tatomic_t\t\t total_submission_cnt;\n\n\tunsigned\tharvest_config;\n\tint (*pause_dpg_mode)(struct amdgpu_device *adev,\n\t\tint inst_idx, struct dpg_pause_state *new_state);\n\n\tstruct ras_common_if    *ras_if;\n\tstruct amdgpu_vcn_ras   *ras;\n\n\tuint16_t inst_mask;\n\tuint8_t\tnum_inst_per_aid;\n};\n\nstruct amdgpu_fw_shared_rb_ptrs_struct {\n\t \n\tuint32_t  rptr;\n\tuint32_t  wptr;\n};\n\nstruct amdgpu_fw_shared_multi_queue {\n\tuint8_t decode_queue_mode;\n\tuint8_t encode_generalpurpose_queue_mode;\n\tuint8_t encode_lowlatency_queue_mode;\n\tuint8_t encode_realtime_queue_mode;\n\tuint8_t padding[4];\n};\n\nstruct amdgpu_fw_shared_sw_ring {\n\tuint8_t is_enabled;\n\tuint8_t padding[3];\n};\n\nstruct amdgpu_fw_shared_unified_queue_struct {\n\tuint8_t is_enabled;\n\tuint8_t queue_mode;\n\tuint8_t queue_status;\n\tuint8_t padding[5];\n};\n\nstruct amdgpu_fw_shared_fw_logging {\n\tuint8_t is_enabled;\n\tuint32_t addr_lo;\n\tuint32_t addr_hi;\n\tuint32_t size;\n};\n\nstruct amdgpu_fw_shared_smu_interface_info {\n\tuint8_t smu_interface_type;\n\tuint8_t padding[3];\n};\n\nstruct amdgpu_fw_shared {\n\tuint32_t present_flag_0;\n\tuint8_t pad[44];\n\tstruct amdgpu_fw_shared_rb_ptrs_struct rb;\n\tuint8_t pad1[1];\n\tstruct amdgpu_fw_shared_multi_queue multi_queue;\n\tstruct amdgpu_fw_shared_sw_ring sw_ring;\n\tstruct amdgpu_fw_shared_fw_logging fw_log;\n\tstruct amdgpu_fw_shared_smu_interface_info smu_interface_info;\n};\n\nstruct amdgpu_fw_shared_rb_setup {\n\tuint32_t is_rb_enabled_flags;\n\tuint32_t rb_addr_lo;\n\tuint32_t rb_addr_hi;\n\tuint32_t  rb_size;\n\tuint32_t  rb4_addr_lo;\n\tuint32_t  rb4_addr_hi;\n\tuint32_t  rb4_size;\n\tuint32_t  reserved[6];\n};\n\nstruct amdgpu_fw_shared_drm_key_wa {\n\tuint8_t  method;\n\tuint8_t  reserved[3];\n};\n\nstruct amdgpu_vcn4_fw_shared {\n\tuint32_t present_flag_0;\n\tuint8_t pad[12];\n\tstruct amdgpu_fw_shared_unified_queue_struct sq;\n\tuint8_t pad1[8];\n\tstruct amdgpu_fw_shared_fw_logging fw_log;\n\tuint8_t pad2[20];\n\tstruct amdgpu_fw_shared_rb_setup rb_setup;\n\tstruct amdgpu_fw_shared_smu_interface_info smu_dpm_interface;\n\tstruct amdgpu_fw_shared_drm_key_wa drm_key_wa;\n};\n\nstruct amdgpu_vcn_fwlog {\n\tuint32_t rptr;\n\tuint32_t wptr;\n\tuint32_t buffer_size;\n\tuint32_t header_size;\n\tuint8_t wrapped;\n};\n\nstruct amdgpu_vcn_decode_buffer {\n\tuint32_t valid_buf_flag;\n\tuint32_t msg_buffer_address_hi;\n\tuint32_t msg_buffer_address_lo;\n\tuint32_t pad[30];\n};\n\n#define VCN_BLOCK_ENCODE_DISABLE_MASK 0x80\n#define VCN_BLOCK_DECODE_DISABLE_MASK 0x40\n#define VCN_BLOCK_QUEUE_DISABLE_MASK 0xC0\n\nenum vcn_ring_type {\n\tVCN_ENCODE_RING,\n\tVCN_DECODE_RING,\n\tVCN_UNIFIED_RING,\n};\n\nint amdgpu_vcn_early_init(struct amdgpu_device *adev);\nint amdgpu_vcn_sw_init(struct amdgpu_device *adev);\nint amdgpu_vcn_sw_fini(struct amdgpu_device *adev);\nint amdgpu_vcn_suspend(struct amdgpu_device *adev);\nint amdgpu_vcn_resume(struct amdgpu_device *adev);\nvoid amdgpu_vcn_ring_begin_use(struct amdgpu_ring *ring);\nvoid amdgpu_vcn_ring_end_use(struct amdgpu_ring *ring);\n\nbool amdgpu_vcn_is_disabled_vcn(struct amdgpu_device *adev,\n\t\t\t\tenum vcn_ring_type type, uint32_t vcn_instance);\n\nint amdgpu_vcn_dec_ring_test_ring(struct amdgpu_ring *ring);\nint amdgpu_vcn_dec_ring_test_ib(struct amdgpu_ring *ring, long timeout);\nint amdgpu_vcn_dec_sw_ring_test_ring(struct amdgpu_ring *ring);\nint amdgpu_vcn_dec_sw_ring_test_ib(struct amdgpu_ring *ring, long timeout);\nint amdgpu_vcn_unified_ring_test_ib(struct amdgpu_ring *ring, long timeout);\n\nint amdgpu_vcn_enc_ring_test_ring(struct amdgpu_ring *ring);\nint amdgpu_vcn_enc_ring_test_ib(struct amdgpu_ring *ring, long timeout);\n\nenum amdgpu_ring_priority_level amdgpu_vcn_get_enc_ring_prio(int ring);\n\nvoid amdgpu_vcn_setup_ucode(struct amdgpu_device *adev);\n\nvoid amdgpu_vcn_fwlog_init(struct amdgpu_vcn_inst *vcn);\nvoid amdgpu_debugfs_vcn_fwlog_init(struct amdgpu_device *adev,\n                                   uint8_t i, struct amdgpu_vcn_inst *vcn);\n\nint amdgpu_vcn_process_poison_irq(struct amdgpu_device *adev,\n\t\t\tstruct amdgpu_irq_src *source,\n\t\t\tstruct amdgpu_iv_entry *entry);\nint amdgpu_vcn_ras_late_init(struct amdgpu_device *adev,\n\t\t\tstruct ras_common_if *ras_block);\nint amdgpu_vcn_ras_sw_init(struct amdgpu_device *adev);\n\nint amdgpu_vcn_psp_update_sram(struct amdgpu_device *adev, int inst_idx,\n\t\t\t       enum AMDGPU_UCODE_ID ucode_id);\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}