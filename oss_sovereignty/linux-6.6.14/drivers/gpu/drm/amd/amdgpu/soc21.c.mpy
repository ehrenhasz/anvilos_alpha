{
  "module_name": "soc21.c",
  "hash_id": "73baeb5a07b28fe9c19819c8617123c45bc008918ceff66c45cee67b3d18b774",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/soc21.c",
  "human_readable_source": " \n#include <linux/firmware.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n\n#include \"amdgpu.h\"\n#include \"amdgpu_atombios.h\"\n#include \"amdgpu_ih.h\"\n#include \"amdgpu_uvd.h\"\n#include \"amdgpu_vce.h\"\n#include \"amdgpu_ucode.h\"\n#include \"amdgpu_psp.h\"\n#include \"amdgpu_smu.h\"\n#include \"atom.h\"\n#include \"amd_pcie.h\"\n\n#include \"gc/gc_11_0_0_offset.h\"\n#include \"gc/gc_11_0_0_sh_mask.h\"\n#include \"mp/mp_13_0_0_offset.h\"\n\n#include \"soc15.h\"\n#include \"soc15_common.h\"\n#include \"soc21.h\"\n#include \"mxgpu_nv.h\"\n\nstatic const struct amd_ip_funcs soc21_common_ip_funcs;\n\n \nstatic const struct amdgpu_video_codec_info vcn_4_0_0_video_codecs_encode_array_vcn0[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 2304, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 4096, 2304, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_AV1, 8192, 4352, 0)},\n};\n\nstatic const struct amdgpu_video_codec_info vcn_4_0_0_video_codecs_encode_array_vcn1[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 2304, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 4096, 2304, 0)},\n};\n\nstatic const struct amdgpu_video_codecs vcn_4_0_0_video_codecs_encode_vcn0 = {\n\t.codec_count = ARRAY_SIZE(vcn_4_0_0_video_codecs_encode_array_vcn0),\n\t.codec_array = vcn_4_0_0_video_codecs_encode_array_vcn0,\n};\n\nstatic const struct amdgpu_video_codecs vcn_4_0_0_video_codecs_encode_vcn1 = {\n\t.codec_count = ARRAY_SIZE(vcn_4_0_0_video_codecs_encode_array_vcn1),\n\t.codec_array = vcn_4_0_0_video_codecs_encode_array_vcn1,\n};\n\nstatic const struct amdgpu_video_codec_info vcn_4_0_0_video_codecs_decode_array_vcn0[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 8192, 4352, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VP9, 8192, 4352, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_AV1, 8192, 4352, 0)},\n};\n\nstatic const struct amdgpu_video_codec_info vcn_4_0_0_video_codecs_decode_array_vcn1[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 8192, 4352, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VP9, 8192, 4352, 0)},\n};\n\nstatic const struct amdgpu_video_codecs vcn_4_0_0_video_codecs_decode_vcn0 = {\n\t.codec_count = ARRAY_SIZE(vcn_4_0_0_video_codecs_decode_array_vcn0),\n\t.codec_array = vcn_4_0_0_video_codecs_decode_array_vcn0,\n};\n\nstatic const struct amdgpu_video_codecs vcn_4_0_0_video_codecs_decode_vcn1 = {\n\t.codec_count = ARRAY_SIZE(vcn_4_0_0_video_codecs_decode_array_vcn1),\n\t.codec_array = vcn_4_0_0_video_codecs_decode_array_vcn1,\n};\n\n \nstatic struct amdgpu_video_codec_info sriov_vcn_4_0_0_video_codecs_encode_array_vcn0[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 2304, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 4096, 2304, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_AV1, 8192, 4352, 0)},\n};\n\nstatic struct amdgpu_video_codec_info sriov_vcn_4_0_0_video_codecs_encode_array_vcn1[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 2304, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 4096, 2304, 0)},\n};\n\nstatic struct amdgpu_video_codecs sriov_vcn_4_0_0_video_codecs_encode_vcn0 = {\n\t.codec_count = ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_encode_array_vcn0),\n\t.codec_array = sriov_vcn_4_0_0_video_codecs_encode_array_vcn0,\n};\n\nstatic struct amdgpu_video_codecs sriov_vcn_4_0_0_video_codecs_encode_vcn1 = {\n\t.codec_count = ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_encode_array_vcn1),\n\t.codec_array = sriov_vcn_4_0_0_video_codecs_encode_array_vcn1,\n};\n\nstatic struct amdgpu_video_codec_info sriov_vcn_4_0_0_video_codecs_decode_array_vcn0[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG2, 4096, 4096, 3)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4, 4096, 4096, 5)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VC1, 4096, 4096, 4)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 8192, 4352, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VP9, 8192, 4352, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_AV1, 8192, 4352, 0)},\n};\n\nstatic struct amdgpu_video_codec_info sriov_vcn_4_0_0_video_codecs_decode_array_vcn1[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG2, 4096, 4096, 3)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4, 4096, 4096, 5)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VC1, 4096, 4096, 4)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 8192, 4352, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VP9, 8192, 4352, 0)},\n};\n\nstatic struct amdgpu_video_codecs sriov_vcn_4_0_0_video_codecs_decode_vcn0 = {\n\t.codec_count = ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_decode_array_vcn0),\n\t.codec_array = sriov_vcn_4_0_0_video_codecs_decode_array_vcn0,\n};\n\nstatic struct amdgpu_video_codecs sriov_vcn_4_0_0_video_codecs_decode_vcn1 = {\n\t.codec_count = ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_decode_array_vcn1),\n\t.codec_array = sriov_vcn_4_0_0_video_codecs_decode_array_vcn1,\n};\n\nstatic int soc21_query_video_codecs(struct amdgpu_device *adev, bool encode,\n\t\t\t\t const struct amdgpu_video_codecs **codecs)\n{\n\tif (adev->vcn.num_vcn_inst == hweight8(adev->vcn.harvest_config))\n\t\treturn -EINVAL;\n\n\tswitch (adev->ip_versions[UVD_HWIP][0]) {\n\tcase IP_VERSION(4, 0, 0):\n\tcase IP_VERSION(4, 0, 2):\n\tcase IP_VERSION(4, 0, 4):\n\t\tif (amdgpu_sriov_vf(adev)) {\n\t\t\tif ((adev->vcn.harvest_config & AMDGPU_VCN_HARVEST_VCN0) ||\n\t\t\t!amdgpu_sriov_is_av1_support(adev)) {\n\t\t\t\tif (encode)\n\t\t\t\t\t*codecs = &sriov_vcn_4_0_0_video_codecs_encode_vcn1;\n\t\t\t\telse\n\t\t\t\t\t*codecs = &sriov_vcn_4_0_0_video_codecs_decode_vcn1;\n\t\t\t} else {\n\t\t\t\tif (encode)\n\t\t\t\t\t*codecs = &sriov_vcn_4_0_0_video_codecs_encode_vcn0;\n\t\t\t\telse\n\t\t\t\t\t*codecs = &sriov_vcn_4_0_0_video_codecs_decode_vcn0;\n\t\t\t}\n\t\t} else {\n\t\t\tif ((adev->vcn.harvest_config & AMDGPU_VCN_HARVEST_VCN0)) {\n\t\t\t\tif (encode)\n\t\t\t\t\t*codecs = &vcn_4_0_0_video_codecs_encode_vcn1;\n\t\t\t\telse\n\t\t\t\t\t*codecs = &vcn_4_0_0_video_codecs_decode_vcn1;\n\t\t\t} else {\n\t\t\t\tif (encode)\n\t\t\t\t\t*codecs = &vcn_4_0_0_video_codecs_encode_vcn0;\n\t\t\t\telse\n\t\t\t\t\t*codecs = &vcn_4_0_0_video_codecs_decode_vcn0;\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic u32 soc21_didt_rreg(struct amdgpu_device *adev, u32 reg)\n{\n\tunsigned long flags, address, data;\n\tu32 r;\n\n\taddress = SOC15_REG_OFFSET(GC, 0, regDIDT_IND_INDEX);\n\tdata = SOC15_REG_OFFSET(GC, 0, regDIDT_IND_DATA);\n\n\tspin_lock_irqsave(&adev->didt_idx_lock, flags);\n\tWREG32(address, (reg));\n\tr = RREG32(data);\n\tspin_unlock_irqrestore(&adev->didt_idx_lock, flags);\n\treturn r;\n}\n\nstatic void soc21_didt_wreg(struct amdgpu_device *adev, u32 reg, u32 v)\n{\n\tunsigned long flags, address, data;\n\n\taddress = SOC15_REG_OFFSET(GC, 0, regDIDT_IND_INDEX);\n\tdata = SOC15_REG_OFFSET(GC, 0, regDIDT_IND_DATA);\n\n\tspin_lock_irqsave(&adev->didt_idx_lock, flags);\n\tWREG32(address, (reg));\n\tWREG32(data, (v));\n\tspin_unlock_irqrestore(&adev->didt_idx_lock, flags);\n}\n\nstatic u32 soc21_get_config_memsize(struct amdgpu_device *adev)\n{\n\treturn adev->nbio.funcs->get_memsize(adev);\n}\n\nstatic u32 soc21_get_xclk(struct amdgpu_device *adev)\n{\n\treturn adev->clock.spll.reference_freq;\n}\n\n\nvoid soc21_grbm_select(struct amdgpu_device *adev,\n\t\t     u32 me, u32 pipe, u32 queue, u32 vmid)\n{\n\tu32 grbm_gfx_cntl = 0;\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, PIPEID, pipe);\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, MEID, me);\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, VMID, vmid);\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, QUEUEID, queue);\n\n\tWREG32_SOC15(GC, 0, regGRBM_GFX_CNTL, grbm_gfx_cntl);\n}\n\nstatic bool soc21_read_disabled_bios(struct amdgpu_device *adev)\n{\n\t \n\treturn false;\n}\n\nstatic struct soc15_allowed_register_entry soc21_allowed_read_registers[] = {\n\t{ SOC15_REG_ENTRY(GC, 0, regGRBM_STATUS)},\n\t{ SOC15_REG_ENTRY(GC, 0, regGRBM_STATUS2)},\n\t{ SOC15_REG_ENTRY(GC, 0, regGRBM_STATUS_SE0)},\n\t{ SOC15_REG_ENTRY(GC, 0, regGRBM_STATUS_SE1)},\n\t{ SOC15_REG_ENTRY(GC, 0, regGRBM_STATUS_SE2)},\n\t{ SOC15_REG_ENTRY(GC, 0, regGRBM_STATUS_SE3)},\n\t{ SOC15_REG_ENTRY(SDMA0, 0, regSDMA0_STATUS_REG)},\n\t{ SOC15_REG_ENTRY(SDMA1, 0, regSDMA1_STATUS_REG)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_STAT)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_STALLED_STAT1)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_STALLED_STAT2)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_STALLED_STAT3)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_CPF_BUSY_STAT)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_CPF_STALLED_STAT1)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_CPF_STATUS)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_CPC_BUSY_STAT)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_CPC_STALLED_STAT1)},\n\t{ SOC15_REG_ENTRY(GC, 0, regCP_CPC_STATUS)},\n\t{ SOC15_REG_ENTRY(GC, 0, regGB_ADDR_CONFIG)},\n};\n\nstatic uint32_t soc21_read_indexed_register(struct amdgpu_device *adev, u32 se_num,\n\t\t\t\t\t u32 sh_num, u32 reg_offset)\n{\n\tuint32_t val;\n\n\tmutex_lock(&adev->grbm_idx_mutex);\n\tif (se_num != 0xffffffff || sh_num != 0xffffffff)\n\t\tamdgpu_gfx_select_se_sh(adev, se_num, sh_num, 0xffffffff, 0);\n\n\tval = RREG32(reg_offset);\n\n\tif (se_num != 0xffffffff || sh_num != 0xffffffff)\n\t\tamdgpu_gfx_select_se_sh(adev, 0xffffffff, 0xffffffff, 0xffffffff, 0);\n\tmutex_unlock(&adev->grbm_idx_mutex);\n\treturn val;\n}\n\nstatic uint32_t soc21_get_register_value(struct amdgpu_device *adev,\n\t\t\t\t      bool indexed, u32 se_num,\n\t\t\t\t      u32 sh_num, u32 reg_offset)\n{\n\tif (indexed) {\n\t\treturn soc21_read_indexed_register(adev, se_num, sh_num, reg_offset);\n\t} else {\n\t\tif (reg_offset == SOC15_REG_OFFSET(GC, 0, regGB_ADDR_CONFIG) && adev->gfx.config.gb_addr_config)\n\t\t\treturn adev->gfx.config.gb_addr_config;\n\t\treturn RREG32(reg_offset);\n\t}\n}\n\nstatic int soc21_read_register(struct amdgpu_device *adev, u32 se_num,\n\t\t\t    u32 sh_num, u32 reg_offset, u32 *value)\n{\n\tuint32_t i;\n\tstruct soc15_allowed_register_entry  *en;\n\n\t*value = 0;\n\tfor (i = 0; i < ARRAY_SIZE(soc21_allowed_read_registers); i++) {\n\t\ten = &soc21_allowed_read_registers[i];\n\t\tif (!adev->reg_offset[en->hwip][en->inst])\n\t\t\tcontinue;\n\t\telse if (reg_offset != (adev->reg_offset[en->hwip][en->inst][en->seg]\n\t\t\t\t\t+ en->reg_offset))\n\t\t\tcontinue;\n\n\t\t*value = soc21_get_register_value(adev,\n\t\t\t\t\t       soc21_allowed_read_registers[i].grbm_indexed,\n\t\t\t\t\t       se_num, sh_num, reg_offset);\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}\n\n#if 0\nstatic int soc21_asic_mode1_reset(struct amdgpu_device *adev)\n{\n\tu32 i;\n\tint ret = 0;\n\n\tamdgpu_atombios_scratch_regs_engine_hung(adev, true);\n\n\t \n\tpci_clear_master(adev->pdev);\n\n\tamdgpu_device_cache_pci_state(adev->pdev);\n\n\tif (amdgpu_dpm_is_mode1_reset_supported(adev)) {\n\t\tdev_info(adev->dev, \"GPU smu mode1 reset\\n\");\n\t\tret = amdgpu_dpm_mode1_reset(adev);\n\t} else {\n\t\tdev_info(adev->dev, \"GPU psp mode1 reset\\n\");\n\t\tret = psp_gpu_reset(adev);\n\t}\n\n\tif (ret)\n\t\tdev_err(adev->dev, \"GPU mode1 reset failed\\n\");\n\tamdgpu_device_load_pci_state(adev->pdev);\n\n\t \n\tfor (i = 0; i < adev->usec_timeout; i++) {\n\t\tu32 memsize = adev->nbio.funcs->get_memsize(adev);\n\n\t\tif (memsize != 0xffffffff)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n\n\tamdgpu_atombios_scratch_regs_engine_hung(adev, false);\n\n\treturn ret;\n}\n#endif\n\nstatic enum amd_reset_method\nsoc21_asic_reset_method(struct amdgpu_device *adev)\n{\n\tif (amdgpu_reset_method == AMD_RESET_METHOD_MODE1 ||\n\t    amdgpu_reset_method == AMD_RESET_METHOD_MODE2 ||\n\t    amdgpu_reset_method == AMD_RESET_METHOD_BACO)\n\t\treturn amdgpu_reset_method;\n\n\tif (amdgpu_reset_method != -1)\n\t\tdev_warn(adev->dev, \"Specified reset method:%d isn't supported, using AUTO instead.\\n\",\n\t\t\t\t  amdgpu_reset_method);\n\n\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\tcase IP_VERSION(13, 0, 0):\n\tcase IP_VERSION(13, 0, 7):\n\tcase IP_VERSION(13, 0, 10):\n\t\treturn AMD_RESET_METHOD_MODE1;\n\tcase IP_VERSION(13, 0, 4):\n\tcase IP_VERSION(13, 0, 11):\n\t\treturn AMD_RESET_METHOD_MODE2;\n\tdefault:\n\t\tif (amdgpu_dpm_is_baco_supported(adev))\n\t\t\treturn AMD_RESET_METHOD_BACO;\n\t\telse\n\t\t\treturn AMD_RESET_METHOD_MODE1;\n\t}\n}\n\nstatic int soc21_asic_reset(struct amdgpu_device *adev)\n{\n\tint ret = 0;\n\n\tswitch (soc21_asic_reset_method(adev)) {\n\tcase AMD_RESET_METHOD_PCI:\n\t\tdev_info(adev->dev, \"PCI reset\\n\");\n\t\tret = amdgpu_device_pci_reset(adev);\n\t\tbreak;\n\tcase AMD_RESET_METHOD_BACO:\n\t\tdev_info(adev->dev, \"BACO reset\\n\");\n\t\tret = amdgpu_dpm_baco_reset(adev);\n\t\tbreak;\n\tcase AMD_RESET_METHOD_MODE2:\n\t\tdev_info(adev->dev, \"MODE2 reset\\n\");\n\t\tret = amdgpu_dpm_mode2_reset(adev);\n\t\tbreak;\n\tdefault:\n\t\tdev_info(adev->dev, \"MODE1 reset\\n\");\n\t\tret = amdgpu_device_mode1_reset(adev);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int soc21_set_uvd_clocks(struct amdgpu_device *adev, u32 vclk, u32 dclk)\n{\n\t \n\treturn 0;\n}\n\nstatic int soc21_set_vce_clocks(struct amdgpu_device *adev, u32 evclk, u32 ecclk)\n{\n\t \n\treturn 0;\n}\n\nstatic void soc21_program_aspm(struct amdgpu_device *adev)\n{\n\tif (!amdgpu_device_should_use_aspm(adev))\n\t\treturn;\n\n\tif (!(adev->flags & AMD_IS_APU) &&\n\t    (adev->nbio.funcs->program_aspm))\n\t\tadev->nbio.funcs->program_aspm(adev);\n}\n\nconst struct amdgpu_ip_block_version soc21_common_ip_block = {\n\t.type = AMD_IP_BLOCK_TYPE_COMMON,\n\t.major = 1,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &soc21_common_ip_funcs,\n};\n\nstatic bool soc21_need_full_reset(struct amdgpu_device *adev)\n{\n\tswitch (adev->ip_versions[GC_HWIP][0]) {\n\tcase IP_VERSION(11, 0, 0):\n\t\treturn amdgpu_ras_is_supported(adev, AMDGPU_RAS_BLOCK__UMC);\n\tcase IP_VERSION(11, 0, 2):\n\tcase IP_VERSION(11, 0, 3):\n\t\treturn false;\n\tdefault:\n\t\treturn true;\n\t}\n}\n\nstatic bool soc21_need_reset_on_init(struct amdgpu_device *adev)\n{\n\tu32 sol_reg;\n\n\tif (adev->flags & AMD_IS_APU)\n\t\treturn false;\n\n\t \n\tsol_reg = RREG32_SOC15(MP0, 0, regMP0_SMN_C2PMSG_81);\n\tif (sol_reg)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void soc21_init_doorbell_index(struct amdgpu_device *adev)\n{\n\tadev->doorbell_index.kiq = AMDGPU_NAVI10_DOORBELL_KIQ;\n\tadev->doorbell_index.mec_ring0 = AMDGPU_NAVI10_DOORBELL_MEC_RING0;\n\tadev->doorbell_index.mec_ring1 = AMDGPU_NAVI10_DOORBELL_MEC_RING1;\n\tadev->doorbell_index.mec_ring2 = AMDGPU_NAVI10_DOORBELL_MEC_RING2;\n\tadev->doorbell_index.mec_ring3 = AMDGPU_NAVI10_DOORBELL_MEC_RING3;\n\tadev->doorbell_index.mec_ring4 = AMDGPU_NAVI10_DOORBELL_MEC_RING4;\n\tadev->doorbell_index.mec_ring5 = AMDGPU_NAVI10_DOORBELL_MEC_RING5;\n\tadev->doorbell_index.mec_ring6 = AMDGPU_NAVI10_DOORBELL_MEC_RING6;\n\tadev->doorbell_index.mec_ring7 = AMDGPU_NAVI10_DOORBELL_MEC_RING7;\n\tadev->doorbell_index.userqueue_start = AMDGPU_NAVI10_DOORBELL_USERQUEUE_START;\n\tadev->doorbell_index.userqueue_end = AMDGPU_NAVI10_DOORBELL_USERQUEUE_END;\n\tadev->doorbell_index.gfx_ring0 = AMDGPU_NAVI10_DOORBELL_GFX_RING0;\n\tadev->doorbell_index.gfx_ring1 = AMDGPU_NAVI10_DOORBELL_GFX_RING1;\n\tadev->doorbell_index.gfx_userqueue_start =\n\t\tAMDGPU_NAVI10_DOORBELL_GFX_USERQUEUE_START;\n\tadev->doorbell_index.gfx_userqueue_end =\n\t\tAMDGPU_NAVI10_DOORBELL_GFX_USERQUEUE_END;\n\tadev->doorbell_index.mes_ring0 = AMDGPU_NAVI10_DOORBELL_MES_RING0;\n\tadev->doorbell_index.mes_ring1 = AMDGPU_NAVI10_DOORBELL_MES_RING1;\n\tadev->doorbell_index.sdma_engine[0] = AMDGPU_NAVI10_DOORBELL_sDMA_ENGINE0;\n\tadev->doorbell_index.sdma_engine[1] = AMDGPU_NAVI10_DOORBELL_sDMA_ENGINE1;\n\tadev->doorbell_index.ih = AMDGPU_NAVI10_DOORBELL_IH;\n\tadev->doorbell_index.vcn.vcn_ring0_1 = AMDGPU_NAVI10_DOORBELL64_VCN0_1;\n\tadev->doorbell_index.vcn.vcn_ring2_3 = AMDGPU_NAVI10_DOORBELL64_VCN2_3;\n\tadev->doorbell_index.vcn.vcn_ring4_5 = AMDGPU_NAVI10_DOORBELL64_VCN4_5;\n\tadev->doorbell_index.vcn.vcn_ring6_7 = AMDGPU_NAVI10_DOORBELL64_VCN6_7;\n\tadev->doorbell_index.first_non_cp = AMDGPU_NAVI10_DOORBELL64_FIRST_NON_CP;\n\tadev->doorbell_index.last_non_cp = AMDGPU_NAVI10_DOORBELL64_LAST_NON_CP;\n\n\tadev->doorbell_index.max_assignment = AMDGPU_NAVI10_DOORBELL_MAX_ASSIGNMENT << 1;\n\tadev->doorbell_index.sdma_doorbell_range = 20;\n}\n\nstatic void soc21_pre_asic_init(struct amdgpu_device *adev)\n{\n}\n\nstatic int soc21_update_umd_stable_pstate(struct amdgpu_device *adev,\n\t\t\t\t\t  bool enter)\n{\n\tif (enter)\n\t\tamdgpu_gfx_rlc_enter_safe_mode(adev, 0);\n\telse\n\t\tamdgpu_gfx_rlc_exit_safe_mode(adev, 0);\n\n\tif (adev->gfx.funcs->update_perfmon_mgcg)\n\t\tadev->gfx.funcs->update_perfmon_mgcg(adev, !enter);\n\n\treturn 0;\n}\n\nstatic const struct amdgpu_asic_funcs soc21_asic_funcs = {\n\t.read_disabled_bios = &soc21_read_disabled_bios,\n\t.read_bios_from_rom = &amdgpu_soc15_read_bios_from_rom,\n\t.read_register = &soc21_read_register,\n\t.reset = &soc21_asic_reset,\n\t.reset_method = &soc21_asic_reset_method,\n\t.get_xclk = &soc21_get_xclk,\n\t.set_uvd_clocks = &soc21_set_uvd_clocks,\n\t.set_vce_clocks = &soc21_set_vce_clocks,\n\t.get_config_memsize = &soc21_get_config_memsize,\n\t.init_doorbell_index = &soc21_init_doorbell_index,\n\t.need_full_reset = &soc21_need_full_reset,\n\t.need_reset_on_init = &soc21_need_reset_on_init,\n\t.get_pcie_replay_count = &amdgpu_nbio_get_pcie_replay_count,\n\t.supports_baco = &amdgpu_dpm_is_baco_supported,\n\t.pre_asic_init = &soc21_pre_asic_init,\n\t.query_video_codecs = &soc21_query_video_codecs,\n\t.update_umd_stable_pstate = &soc21_update_umd_stable_pstate,\n};\n\nstatic int soc21_common_early_init(void *handle)\n{\n#define MMIO_REG_HOLE_OFFSET (0x80000 - PAGE_SIZE)\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tadev->rmmio_remap.reg_offset = MMIO_REG_HOLE_OFFSET;\n\tadev->rmmio_remap.bus_addr = adev->rmmio_base + MMIO_REG_HOLE_OFFSET;\n\tadev->smc_rreg = NULL;\n\tadev->smc_wreg = NULL;\n\tadev->pcie_rreg = &amdgpu_device_indirect_rreg;\n\tadev->pcie_wreg = &amdgpu_device_indirect_wreg;\n\tadev->pcie_rreg64 = &amdgpu_device_indirect_rreg64;\n\tadev->pcie_wreg64 = &amdgpu_device_indirect_wreg64;\n\tadev->pciep_rreg = amdgpu_device_pcie_port_rreg;\n\tadev->pciep_wreg = amdgpu_device_pcie_port_wreg;\n\n\t \n\tadev->uvd_ctx_rreg = NULL;\n\tadev->uvd_ctx_wreg = NULL;\n\n\tadev->didt_rreg = &soc21_didt_rreg;\n\tadev->didt_wreg = &soc21_didt_wreg;\n\n\tadev->asic_funcs = &soc21_asic_funcs;\n\n\tadev->rev_id = amdgpu_device_get_rev_id(adev);\n\tadev->external_rev_id = 0xff;\n\tswitch (adev->ip_versions[GC_HWIP][0]) {\n\tcase IP_VERSION(11, 0, 0):\n\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n#if 0\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGLS |\n#endif\n\t\t\tAMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_REPEATER_FGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_FGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_PERF_CLK |\n\t\t\tAMD_CG_SUPPORT_VCN_MGCG |\n\t\t\tAMD_CG_SUPPORT_JPEG_MGCG |\n\t\t\tAMD_CG_SUPPORT_ATHUB_MGCG |\n\t\t\tAMD_CG_SUPPORT_ATHUB_LS |\n\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\tAMD_CG_SUPPORT_IH_CG |\n\t\t\tAMD_CG_SUPPORT_HDP_SD;\n\t\tadev->pg_flags = AMD_PG_SUPPORT_VCN |\n\t\t\tAMD_PG_SUPPORT_VCN_DPG |\n\t\t\tAMD_PG_SUPPORT_JPEG |\n\t\t\tAMD_PG_SUPPORT_ATHUB |\n\t\t\tAMD_PG_SUPPORT_MMHUB;\n\t\tadev->external_rev_id = adev->rev_id + 0x1; \n\t\tbreak;\n\tcase IP_VERSION(11, 0, 2):\n\t\tadev->cg_flags =\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_REPEATER_FGCG |\n\t\t\tAMD_CG_SUPPORT_VCN_MGCG |\n\t\t\tAMD_CG_SUPPORT_JPEG_MGCG |\n\t\t\tAMD_CG_SUPPORT_ATHUB_MGCG |\n\t\t\tAMD_CG_SUPPORT_ATHUB_LS |\n\t\t\tAMD_CG_SUPPORT_IH_CG |\n\t\t\tAMD_CG_SUPPORT_HDP_SD;\n\t\tadev->pg_flags =\n\t\t\tAMD_PG_SUPPORT_VCN |\n\t\t\tAMD_PG_SUPPORT_VCN_DPG |\n\t\t\tAMD_PG_SUPPORT_JPEG |\n\t\t\tAMD_PG_SUPPORT_ATHUB |\n\t\t\tAMD_PG_SUPPORT_MMHUB;\n\t\tadev->external_rev_id = adev->rev_id + 0x10;\n\t\tbreak;\n\tcase IP_VERSION(11, 0, 1):\n\t\tadev->cg_flags =\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_FGCG |\n\t\t\tAMD_CG_SUPPORT_REPEATER_FGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_PERF_CLK |\n\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\tAMD_CG_SUPPORT_HDP_MGCG |\n\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\tAMD_CG_SUPPORT_ATHUB_MGCG |\n\t\t\tAMD_CG_SUPPORT_ATHUB_LS |\n\t\t\tAMD_CG_SUPPORT_IH_CG |\n\t\t\tAMD_CG_SUPPORT_BIF_MGCG |\n\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\tAMD_CG_SUPPORT_VCN_MGCG |\n\t\t\tAMD_CG_SUPPORT_JPEG_MGCG;\n\t\tadev->pg_flags =\n\t\t\tAMD_PG_SUPPORT_GFX_PG |\n\t\t\tAMD_PG_SUPPORT_VCN |\n\t\t\tAMD_PG_SUPPORT_VCN_DPG |\n\t\t\tAMD_PG_SUPPORT_JPEG;\n\t\tadev->external_rev_id = adev->rev_id + 0x1;\n\t\tbreak;\n\tcase IP_VERSION(11, 0, 3):\n\t\tadev->cg_flags = AMD_CG_SUPPORT_VCN_MGCG |\n\t\t\tAMD_CG_SUPPORT_JPEG_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_REPEATER_FGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_HDP_SD |\n\t\t\tAMD_CG_SUPPORT_ATHUB_MGCG |\n\t\t\tAMD_CG_SUPPORT_ATHUB_LS;\n\t\tadev->pg_flags = AMD_PG_SUPPORT_VCN |\n\t\t\tAMD_PG_SUPPORT_VCN_DPG |\n\t\t\tAMD_PG_SUPPORT_JPEG;\n\t\tadev->external_rev_id = adev->rev_id + 0x20;\n\t\tbreak;\n\tcase IP_VERSION(11, 0, 4):\n\t\tadev->cg_flags =\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_FGCG |\n\t\t\tAMD_CG_SUPPORT_REPEATER_FGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_PERF_CLK |\n\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\tAMD_CG_SUPPORT_HDP_MGCG |\n\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\tAMD_CG_SUPPORT_ATHUB_MGCG |\n\t\t\tAMD_CG_SUPPORT_ATHUB_LS |\n\t\t\tAMD_CG_SUPPORT_IH_CG |\n\t\t\tAMD_CG_SUPPORT_BIF_MGCG |\n\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\tAMD_CG_SUPPORT_VCN_MGCG |\n\t\t\tAMD_CG_SUPPORT_JPEG_MGCG;\n\t\tadev->pg_flags = AMD_PG_SUPPORT_VCN |\n\t\t\tAMD_PG_SUPPORT_VCN_DPG |\n\t\t\tAMD_PG_SUPPORT_GFX_PG |\n\t\t\tAMD_PG_SUPPORT_JPEG;\n\t\tadev->external_rev_id = adev->rev_id + 0x80;\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\tif (amdgpu_sriov_vf(adev)) {\n\t\tamdgpu_virt_init_setting(adev);\n\t\txgpu_nv_mailbox_set_irq_funcs(adev);\n\t}\n\n\treturn 0;\n}\n\nstatic int soc21_common_late_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (amdgpu_sriov_vf(adev)) {\n\t\txgpu_nv_mailbox_get_irq(adev);\n\t\tif ((adev->vcn.harvest_config & AMDGPU_VCN_HARVEST_VCN0) ||\n\t\t!amdgpu_sriov_is_av1_support(adev)) {\n\t\t\tamdgpu_virt_update_sriov_video_codec(adev,\n\t\t\t\t\t\t\t     sriov_vcn_4_0_0_video_codecs_encode_array_vcn1,\n\t\t\t\t\t\t\t     ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_encode_array_vcn1),\n\t\t\t\t\t\t\t     sriov_vcn_4_0_0_video_codecs_decode_array_vcn1,\n\t\t\t\t\t\t\t     ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_decode_array_vcn1));\n\t\t} else {\n\t\t\tamdgpu_virt_update_sriov_video_codec(adev,\n\t\t\t\t\t\t\t     sriov_vcn_4_0_0_video_codecs_encode_array_vcn0,\n\t\t\t\t\t\t\t     ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_encode_array_vcn0),\n\t\t\t\t\t\t\t     sriov_vcn_4_0_0_video_codecs_decode_array_vcn0,\n\t\t\t\t\t\t\t     ARRAY_SIZE(sriov_vcn_4_0_0_video_codecs_decode_array_vcn0));\n\t\t}\n\t} else {\n\t\tif (adev->nbio.ras &&\n\t\t    adev->nbio.ras_err_event_athub_irq.funcs)\n\t\t\t \n\t\t\tamdgpu_irq_get(adev, &adev->nbio.ras_err_event_athub_irq, 0);\n\t}\n\n\t \n\tadev->nbio.funcs->enable_doorbell_selfring_aperture(adev, true);\n\n\treturn 0;\n}\n\nstatic int soc21_common_sw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (amdgpu_sriov_vf(adev))\n\t\txgpu_nv_mailbox_add_irq_id(adev);\n\n\treturn 0;\n}\n\nstatic int soc21_common_sw_fini(void *handle)\n{\n\treturn 0;\n}\n\nstatic int soc21_common_hw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\t \n\tsoc21_program_aspm(adev);\n\t \n\tadev->nbio.funcs->init_registers(adev);\n\t \n\tif (adev->nbio.funcs->remap_hdp_registers && !amdgpu_sriov_vf(adev))\n\t\tadev->nbio.funcs->remap_hdp_registers(adev);\n\t \n\tadev->nbio.funcs->enable_doorbell_aperture(adev, true);\n\n\treturn 0;\n}\n\nstatic int soc21_common_hw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\t \n\tadev->nbio.funcs->enable_doorbell_aperture(adev, false);\n\tadev->nbio.funcs->enable_doorbell_selfring_aperture(adev, false);\n\n\tif (amdgpu_sriov_vf(adev)) {\n\t\txgpu_nv_mailbox_put_irq(adev);\n\t} else {\n\t\tif (adev->nbio.ras &&\n\t\t    adev->nbio.ras_err_event_athub_irq.funcs)\n\t\t\tamdgpu_irq_put(adev, &adev->nbio.ras_err_event_athub_irq, 0);\n\t}\n\n\treturn 0;\n}\n\nstatic int soc21_common_suspend(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn soc21_common_hw_fini(adev);\n}\n\nstatic int soc21_common_resume(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn soc21_common_hw_init(adev);\n}\n\nstatic bool soc21_common_is_idle(void *handle)\n{\n\treturn true;\n}\n\nstatic int soc21_common_wait_for_idle(void *handle)\n{\n\treturn 0;\n}\n\nstatic int soc21_common_soft_reset(void *handle)\n{\n\treturn 0;\n}\n\nstatic int soc21_common_set_clockgating_state(void *handle,\n\t\t\t\t\t   enum amd_clockgating_state state)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tswitch (adev->ip_versions[NBIO_HWIP][0]) {\n\tcase IP_VERSION(4, 3, 0):\n\tcase IP_VERSION(4, 3, 1):\n\tcase IP_VERSION(7, 7, 0):\n\t\tadev->nbio.funcs->update_medium_grain_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->nbio.funcs->update_medium_grain_light_sleep(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->hdp.funcs->update_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int soc21_common_set_powergating_state(void *handle,\n\t\t\t\t\t   enum amd_powergating_state state)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tswitch (adev->ip_versions[LSDMA_HWIP][0]) {\n\tcase IP_VERSION(6, 0, 0):\n\tcase IP_VERSION(6, 0, 2):\n\t\tadev->lsdma.funcs->update_memory_power_gating(adev,\n\t\t\t\tstate == AMD_PG_STATE_GATE);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic void soc21_common_get_clockgating_state(void *handle, u64 *flags)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tadev->nbio.funcs->get_clockgating_state(adev, flags);\n\n\tadev->hdp.funcs->get_clock_gating_state(adev, flags);\n\n\treturn;\n}\n\nstatic const struct amd_ip_funcs soc21_common_ip_funcs = {\n\t.name = \"soc21_common\",\n\t.early_init = soc21_common_early_init,\n\t.late_init = soc21_common_late_init,\n\t.sw_init = soc21_common_sw_init,\n\t.sw_fini = soc21_common_sw_fini,\n\t.hw_init = soc21_common_hw_init,\n\t.hw_fini = soc21_common_hw_fini,\n\t.suspend = soc21_common_suspend,\n\t.resume = soc21_common_resume,\n\t.is_idle = soc21_common_is_idle,\n\t.wait_for_idle = soc21_common_wait_for_idle,\n\t.soft_reset = soc21_common_soft_reset,\n\t.set_clockgating_state = soc21_common_set_clockgating_state,\n\t.set_powergating_state = soc21_common_set_powergating_state,\n\t.get_clockgating_state = soc21_common_get_clockgating_state,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}