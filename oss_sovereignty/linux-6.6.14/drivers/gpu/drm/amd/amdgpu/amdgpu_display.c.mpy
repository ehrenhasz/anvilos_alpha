{
  "module_name": "amdgpu_display.c",
  "hash_id": "8ea6a75edcbc08283b7ee688bdc100435e8eb8c10b3a30ede1bfd372571e1649",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_display.c",
  "human_readable_source": " \n\n#include <drm/amdgpu_drm.h>\n#include \"amdgpu.h\"\n#include \"amdgpu_i2c.h\"\n#include \"atom.h\"\n#include \"amdgpu_connectors.h\"\n#include \"amdgpu_display.h\"\n#include \"soc15_common.h\"\n#include \"gc/gc_11_0_0_offset.h\"\n#include \"gc/gc_11_0_0_sh_mask.h\"\n#include <asm/div64.h>\n\n#include <linux/pci.h>\n#include <linux/pm_runtime.h>\n#include <drm/drm_crtc_helper.h>\n#include <drm/drm_damage_helper.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_edid.h>\n#include <drm/drm_fb_helper.h>\n#include <drm/drm_gem_framebuffer_helper.h>\n#include <drm/drm_fourcc.h>\n#include <drm/drm_modeset_helper.h>\n#include <drm/drm_vblank.h>\n\n \nvoid amdgpu_display_hotplug_work_func(struct work_struct *work)\n{\n\tstruct amdgpu_device *adev = container_of(work, struct amdgpu_device,\n\t\t\t\t\t\t  hotplug_work.work);\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_mode_config *mode_config = &dev->mode_config;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\n\tmutex_lock(&mode_config->mutex);\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter)\n\t\tamdgpu_connector_hotplug(connector);\n\tdrm_connector_list_iter_end(&iter);\n\tmutex_unlock(&mode_config->mutex);\n\t \n\tdrm_helper_hpd_irq_event(dev);\n}\n\nstatic int amdgpu_display_framebuffer_init(struct drm_device *dev,\n\t\t\t\t\t   struct amdgpu_framebuffer *rfb,\n\t\t\t\t\t   const struct drm_mode_fb_cmd2 *mode_cmd,\n\t\t\t\t\t   struct drm_gem_object *obj);\n\nstatic void amdgpu_display_flip_callback(struct dma_fence *f,\n\t\t\t\t\t struct dma_fence_cb *cb)\n{\n\tstruct amdgpu_flip_work *work =\n\t\tcontainer_of(cb, struct amdgpu_flip_work, cb);\n\n\tdma_fence_put(f);\n\tschedule_work(&work->flip_work.work);\n}\n\nstatic bool amdgpu_display_flip_handle_fence(struct amdgpu_flip_work *work,\n\t\t\t\t\t     struct dma_fence **f)\n{\n\tstruct dma_fence *fence = *f;\n\n\tif (fence == NULL)\n\t\treturn false;\n\n\t*f = NULL;\n\n\tif (!dma_fence_add_callback(fence, &work->cb,\n\t\t\t\t    amdgpu_display_flip_callback))\n\t\treturn true;\n\n\tdma_fence_put(fence);\n\treturn false;\n}\n\nstatic void amdgpu_display_flip_work_func(struct work_struct *__work)\n{\n\tstruct delayed_work *delayed_work =\n\t\tcontainer_of(__work, struct delayed_work, work);\n\tstruct amdgpu_flip_work *work =\n\t\tcontainer_of(delayed_work, struct amdgpu_flip_work, flip_work);\n\tstruct amdgpu_device *adev = work->adev;\n\tstruct amdgpu_crtc *amdgpu_crtc = adev->mode_info.crtcs[work->crtc_id];\n\n\tstruct drm_crtc *crtc = &amdgpu_crtc->base;\n\tunsigned long flags;\n\tunsigned int i;\n\tint vpos, hpos;\n\n\tfor (i = 0; i < work->shared_count; ++i)\n\t\tif (amdgpu_display_flip_handle_fence(work, &work->shared[i]))\n\t\t\treturn;\n\n\t \n\tif (amdgpu_crtc->enabled &&\n\t    (amdgpu_display_get_crtc_scanoutpos(adev_to_drm(adev), work->crtc_id, 0,\n\t\t\t\t\t\t&vpos, &hpos, NULL, NULL,\n\t\t\t\t\t\t&crtc->hwmode)\n\t     & (DRM_SCANOUTPOS_VALID | DRM_SCANOUTPOS_IN_VBLANK)) ==\n\t    (DRM_SCANOUTPOS_VALID | DRM_SCANOUTPOS_IN_VBLANK) &&\n\t    (int)(work->target_vblank -\n\t\t  amdgpu_get_vblank_counter_kms(crtc)) > 0) {\n\t\tschedule_delayed_work(&work->flip_work, usecs_to_jiffies(1000));\n\t\treturn;\n\t}\n\n\t \n\tspin_lock_irqsave(&crtc->dev->event_lock, flags);\n\n\t \n\tadev->mode_info.funcs->page_flip(adev, work->crtc_id, work->base, work->async);\n\n\t \n\tamdgpu_crtc->pflip_status = AMDGPU_FLIP_SUBMITTED;\n\tspin_unlock_irqrestore(&crtc->dev->event_lock, flags);\n\n\n\tdrm_dbg_vbl(adev_to_drm(adev),\n\t\t    \"crtc:%d[%p], pflip_stat:AMDGPU_FLIP_SUBMITTED, work: %p,\\n\",\n\t\t    amdgpu_crtc->crtc_id, amdgpu_crtc, work);\n\n}\n\n \nstatic void amdgpu_display_unpin_work_func(struct work_struct *__work)\n{\n\tstruct amdgpu_flip_work *work =\n\t\tcontainer_of(__work, struct amdgpu_flip_work, unpin_work);\n\tint r;\n\n\t \n\tr = amdgpu_bo_reserve(work->old_abo, true);\n\tif (likely(r == 0)) {\n\t\tamdgpu_bo_unpin(work->old_abo);\n\t\tamdgpu_bo_unreserve(work->old_abo);\n\t} else\n\t\tDRM_ERROR(\"failed to reserve buffer after flip\\n\");\n\n\tamdgpu_bo_unref(&work->old_abo);\n\tkfree(work->shared);\n\tkfree(work);\n}\n\nint amdgpu_display_crtc_page_flip_target(struct drm_crtc *crtc,\n\t\t\t\tstruct drm_framebuffer *fb,\n\t\t\t\tstruct drm_pending_vblank_event *event,\n\t\t\t\tuint32_t page_flip_flags, uint32_t target,\n\t\t\t\tstruct drm_modeset_acquire_ctx *ctx)\n{\n\tstruct drm_device *dev = crtc->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\n\tstruct drm_gem_object *obj;\n\tstruct amdgpu_flip_work *work;\n\tstruct amdgpu_bo *new_abo;\n\tunsigned long flags;\n\tu64 tiling_flags;\n\tint i, r;\n\n\twork = kzalloc(sizeof(*work), GFP_KERNEL);\n\tif (work == NULL)\n\t\treturn -ENOMEM;\n\n\tINIT_DELAYED_WORK(&work->flip_work, amdgpu_display_flip_work_func);\n\tINIT_WORK(&work->unpin_work, amdgpu_display_unpin_work_func);\n\n\twork->event = event;\n\twork->adev = adev;\n\twork->crtc_id = amdgpu_crtc->crtc_id;\n\twork->async = (page_flip_flags & DRM_MODE_PAGE_FLIP_ASYNC) != 0;\n\n\t \n\tobj = crtc->primary->fb->obj[0];\n\n\t \n\twork->old_abo = gem_to_amdgpu_bo(obj);\n\tamdgpu_bo_ref(work->old_abo);\n\n\tobj = fb->obj[0];\n\tnew_abo = gem_to_amdgpu_bo(obj);\n\n\t \n\tr = amdgpu_bo_reserve(new_abo, false);\n\tif (unlikely(r != 0)) {\n\t\tDRM_ERROR(\"failed to reserve new abo buffer before flip\\n\");\n\t\tgoto cleanup;\n\t}\n\n\tif (!adev->enable_virtual_display) {\n\t\tr = amdgpu_bo_pin(new_abo,\n\t\t\t\t  amdgpu_display_supported_domains(adev, new_abo->flags));\n\t\tif (unlikely(r != 0)) {\n\t\t\tDRM_ERROR(\"failed to pin new abo buffer before flip\\n\");\n\t\t\tgoto unreserve;\n\t\t}\n\t}\n\n\tr = amdgpu_ttm_alloc_gart(&new_abo->tbo);\n\tif (unlikely(r != 0)) {\n\t\tDRM_ERROR(\"%p bind failed\\n\", new_abo);\n\t\tgoto unpin;\n\t}\n\n\tr = dma_resv_get_fences(new_abo->tbo.base.resv, DMA_RESV_USAGE_WRITE,\n\t\t\t\t&work->shared_count,\n\t\t\t\t&work->shared);\n\tif (unlikely(r != 0)) {\n\t\tDRM_ERROR(\"failed to get fences for buffer\\n\");\n\t\tgoto unpin;\n\t}\n\n\tamdgpu_bo_get_tiling_flags(new_abo, &tiling_flags);\n\tamdgpu_bo_unreserve(new_abo);\n\n\tif (!adev->enable_virtual_display)\n\t\twork->base = amdgpu_bo_gpu_offset(new_abo);\n\twork->target_vblank = target - (uint32_t)drm_crtc_vblank_count(crtc) +\n\t\tamdgpu_get_vblank_counter_kms(crtc);\n\n\t \n\tspin_lock_irqsave(&crtc->dev->event_lock, flags);\n\tif (amdgpu_crtc->pflip_status != AMDGPU_FLIP_NONE) {\n\t\tDRM_DEBUG_DRIVER(\"flip queue: crtc already busy\\n\");\n\t\tspin_unlock_irqrestore(&crtc->dev->event_lock, flags);\n\t\tr = -EBUSY;\n\t\tgoto pflip_cleanup;\n\t}\n\n\tamdgpu_crtc->pflip_status = AMDGPU_FLIP_PENDING;\n\tamdgpu_crtc->pflip_works = work;\n\n\n\tDRM_DEBUG_DRIVER(\"crtc:%d[%p], pflip_stat:AMDGPU_FLIP_PENDING, work: %p,\\n\",\n\t\t\t\t\t amdgpu_crtc->crtc_id, amdgpu_crtc, work);\n\t \n\tcrtc->primary->fb = fb;\n\tspin_unlock_irqrestore(&crtc->dev->event_lock, flags);\n\tamdgpu_display_flip_work_func(&work->flip_work.work);\n\treturn 0;\n\npflip_cleanup:\n\tif (unlikely(amdgpu_bo_reserve(new_abo, false) != 0)) {\n\t\tDRM_ERROR(\"failed to reserve new abo in error path\\n\");\n\t\tgoto cleanup;\n\t}\nunpin:\n\tif (!adev->enable_virtual_display)\n\t\tamdgpu_bo_unpin(new_abo);\n\nunreserve:\n\tamdgpu_bo_unreserve(new_abo);\n\ncleanup:\n\tamdgpu_bo_unref(&work->old_abo);\n\tfor (i = 0; i < work->shared_count; ++i)\n\t\tdma_fence_put(work->shared[i]);\n\tkfree(work->shared);\n\tkfree(work);\n\n\treturn r;\n}\n\nint amdgpu_display_crtc_set_config(struct drm_mode_set *set,\n\t\t\t\t   struct drm_modeset_acquire_ctx *ctx)\n{\n\tstruct drm_device *dev;\n\tstruct amdgpu_device *adev;\n\tstruct drm_crtc *crtc;\n\tbool active = false;\n\tint ret;\n\n\tif (!set || !set->crtc)\n\t\treturn -EINVAL;\n\n\tdev = set->crtc->dev;\n\n\tret = pm_runtime_get_sync(dev->dev);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = drm_crtc_helper_set_config(set, ctx);\n\n\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head)\n\t\tif (crtc->enabled)\n\t\t\tactive = true;\n\n\tpm_runtime_mark_last_busy(dev->dev);\n\n\tadev = drm_to_adev(dev);\n\t \n\tif (active && !adev->have_disp_power_ref) {\n\t\tadev->have_disp_power_ref = true;\n\t\treturn ret;\n\t}\n\t \n\tif (!active && adev->have_disp_power_ref)\n\t\tadev->have_disp_power_ref = false;\nout:\n\t \n\tpm_runtime_put_autosuspend(dev->dev);\n\treturn ret;\n}\n\nstatic const char *encoder_names[41] = {\n\t\"NONE\",\n\t\"INTERNAL_LVDS\",\n\t\"INTERNAL_TMDS1\",\n\t\"INTERNAL_TMDS2\",\n\t\"INTERNAL_DAC1\",\n\t\"INTERNAL_DAC2\",\n\t\"INTERNAL_SDVOA\",\n\t\"INTERNAL_SDVOB\",\n\t\"SI170B\",\n\t\"CH7303\",\n\t\"CH7301\",\n\t\"INTERNAL_DVO1\",\n\t\"EXTERNAL_SDVOA\",\n\t\"EXTERNAL_SDVOB\",\n\t\"TITFP513\",\n\t\"INTERNAL_LVTM1\",\n\t\"VT1623\",\n\t\"HDMI_SI1930\",\n\t\"HDMI_INTERNAL\",\n\t\"INTERNAL_KLDSCP_TMDS1\",\n\t\"INTERNAL_KLDSCP_DVO1\",\n\t\"INTERNAL_KLDSCP_DAC1\",\n\t\"INTERNAL_KLDSCP_DAC2\",\n\t\"SI178\",\n\t\"MVPU_FPGA\",\n\t\"INTERNAL_DDI\",\n\t\"VT1625\",\n\t\"HDMI_SI1932\",\n\t\"DP_AN9801\",\n\t\"DP_DP501\",\n\t\"INTERNAL_UNIPHY\",\n\t\"INTERNAL_KLDSCP_LVTMA\",\n\t\"INTERNAL_UNIPHY1\",\n\t\"INTERNAL_UNIPHY2\",\n\t\"NUTMEG\",\n\t\"TRAVIS\",\n\t\"INTERNAL_VCE\",\n\t\"INTERNAL_UNIPHY3\",\n\t\"HDMI_ANX9805\",\n\t\"INTERNAL_AMCLK\",\n\t\"VIRTUAL\",\n};\n\nstatic const char *hpd_names[6] = {\n\t\"HPD1\",\n\t\"HPD2\",\n\t\"HPD3\",\n\t\"HPD4\",\n\t\"HPD5\",\n\t\"HPD6\",\n};\n\nvoid amdgpu_display_print_display_setup(struct drm_device *dev)\n{\n\tstruct drm_connector *connector;\n\tstruct amdgpu_connector *amdgpu_connector;\n\tstruct drm_encoder *encoder;\n\tstruct amdgpu_encoder *amdgpu_encoder;\n\tstruct drm_connector_list_iter iter;\n\tuint32_t devices;\n\tint i = 0;\n\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tDRM_INFO(\"AMDGPU Display Connectors\\n\");\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\tamdgpu_connector = to_amdgpu_connector(connector);\n\t\tDRM_INFO(\"Connector %d:\\n\", i);\n\t\tDRM_INFO(\"  %s\\n\", connector->name);\n\t\tif (amdgpu_connector->hpd.hpd != AMDGPU_HPD_NONE)\n\t\t\tDRM_INFO(\"  %s\\n\", hpd_names[amdgpu_connector->hpd.hpd]);\n\t\tif (amdgpu_connector->ddc_bus) {\n\t\t\tDRM_INFO(\"  DDC: 0x%x 0x%x 0x%x 0x%x 0x%x 0x%x 0x%x 0x%x\\n\",\n\t\t\t\t amdgpu_connector->ddc_bus->rec.mask_clk_reg,\n\t\t\t\t amdgpu_connector->ddc_bus->rec.mask_data_reg,\n\t\t\t\t amdgpu_connector->ddc_bus->rec.a_clk_reg,\n\t\t\t\t amdgpu_connector->ddc_bus->rec.a_data_reg,\n\t\t\t\t amdgpu_connector->ddc_bus->rec.en_clk_reg,\n\t\t\t\t amdgpu_connector->ddc_bus->rec.en_data_reg,\n\t\t\t\t amdgpu_connector->ddc_bus->rec.y_clk_reg,\n\t\t\t\t amdgpu_connector->ddc_bus->rec.y_data_reg);\n\t\t\tif (amdgpu_connector->router.ddc_valid)\n\t\t\t\tDRM_INFO(\"  DDC Router 0x%x/0x%x\\n\",\n\t\t\t\t\t amdgpu_connector->router.ddc_mux_control_pin,\n\t\t\t\t\t amdgpu_connector->router.ddc_mux_state);\n\t\t\tif (amdgpu_connector->router.cd_valid)\n\t\t\t\tDRM_INFO(\"  Clock/Data Router 0x%x/0x%x\\n\",\n\t\t\t\t\t amdgpu_connector->router.cd_mux_control_pin,\n\t\t\t\t\t amdgpu_connector->router.cd_mux_state);\n\t\t} else {\n\t\t\tif (connector->connector_type == DRM_MODE_CONNECTOR_VGA ||\n\t\t\t    connector->connector_type == DRM_MODE_CONNECTOR_DVII ||\n\t\t\t    connector->connector_type == DRM_MODE_CONNECTOR_DVID ||\n\t\t\t    connector->connector_type == DRM_MODE_CONNECTOR_DVIA ||\n\t\t\t    connector->connector_type == DRM_MODE_CONNECTOR_HDMIA ||\n\t\t\t    connector->connector_type == DRM_MODE_CONNECTOR_HDMIB)\n\t\t\t\tDRM_INFO(\"  DDC: no ddc bus - possible BIOS bug - please report to xorg-driver-ati@lists.x.org\\n\");\n\t\t}\n\t\tDRM_INFO(\"  Encoders:\\n\");\n\t\tlist_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {\n\t\t\tamdgpu_encoder = to_amdgpu_encoder(encoder);\n\t\t\tdevices = amdgpu_encoder->devices & amdgpu_connector->devices;\n\t\t\tif (devices) {\n\t\t\t\tif (devices & ATOM_DEVICE_CRT1_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    CRT1: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_CRT2_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    CRT2: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_LCD1_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    LCD1: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_DFP1_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    DFP1: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_DFP2_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    DFP2: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_DFP3_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    DFP3: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_DFP4_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    DFP4: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_DFP5_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    DFP5: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_DFP6_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    DFP6: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_TV1_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    TV1: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t\tif (devices & ATOM_DEVICE_CV_SUPPORT)\n\t\t\t\t\tDRM_INFO(\"    CV: %s\\n\", encoder_names[amdgpu_encoder->encoder_id]);\n\t\t\t}\n\t\t}\n\t\ti++;\n\t}\n\tdrm_connector_list_iter_end(&iter);\n}\n\nbool amdgpu_display_ddc_probe(struct amdgpu_connector *amdgpu_connector,\n\t\t\t      bool use_aux)\n{\n\tu8 out = 0x0;\n\tu8 buf[8];\n\tint ret;\n\tstruct i2c_msg msgs[] = {\n\t\t{\n\t\t\t.addr = DDC_ADDR,\n\t\t\t.flags = 0,\n\t\t\t.len = 1,\n\t\t\t.buf = &out,\n\t\t},\n\t\t{\n\t\t\t.addr = DDC_ADDR,\n\t\t\t.flags = I2C_M_RD,\n\t\t\t.len = 8,\n\t\t\t.buf = buf,\n\t\t}\n\t};\n\n\t \n\tif (amdgpu_connector->router.ddc_valid)\n\t\tamdgpu_i2c_router_select_ddc_port(amdgpu_connector);\n\n\tif (use_aux)\n\t\tret = i2c_transfer(&amdgpu_connector->ddc_bus->aux.ddc, msgs, 2);\n\telse\n\t\tret = i2c_transfer(&amdgpu_connector->ddc_bus->adapter, msgs, 2);\n\n\tif (ret != 2)\n\t\t \n\t\treturn false;\n\t \n\tif (drm_edid_header_is_valid(buf) < 6) {\n\t\t \n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic int amdgpu_dirtyfb(struct drm_framebuffer *fb, struct drm_file *file,\n\t\t\t  unsigned int flags, unsigned int color,\n\t\t\t  struct drm_clip_rect *clips, unsigned int num_clips)\n{\n\n\tif (file)\n\t\treturn -ENOSYS;\n\n\treturn drm_atomic_helper_dirtyfb(fb, file, flags, color, clips,\n\t\t\t\t\t num_clips);\n}\n\nstatic const struct drm_framebuffer_funcs amdgpu_fb_funcs = {\n\t.destroy = drm_gem_fb_destroy,\n\t.create_handle = drm_gem_fb_create_handle,\n};\n\nstatic const struct drm_framebuffer_funcs amdgpu_fb_funcs_atomic = {\n\t.destroy = drm_gem_fb_destroy,\n\t.create_handle = drm_gem_fb_create_handle,\n\t.dirty = amdgpu_dirtyfb\n};\n\nuint32_t amdgpu_display_supported_domains(struct amdgpu_device *adev,\n\t\t\t\t\t  uint64_t bo_flags)\n{\n\tuint32_t domain = AMDGPU_GEM_DOMAIN_VRAM;\n\n#if defined(CONFIG_DRM_AMD_DC)\n\t \n\tif ((bo_flags & AMDGPU_GEM_CREATE_CPU_GTT_USWC) &&\n\t    amdgpu_bo_support_uswc(bo_flags) &&\n\t    adev->dc_enabled &&\n\t    adev->mode_info.gpu_vm_support)\n\t\tdomain |= AMDGPU_GEM_DOMAIN_GTT;\n#endif\n\n\treturn domain;\n}\n\nstatic const struct drm_format_info dcc_formats[] = {\n\t{ .format = DRM_FORMAT_XRGB8888, .depth = 24, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t { .format = DRM_FORMAT_XBGR8888, .depth = 24, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t{ .format = DRM_FORMAT_ARGB8888, .depth = 32, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t   .has_alpha = true, },\n\t{ .format = DRM_FORMAT_ABGR8888, .depth = 32, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_BGRA8888, .depth = 32, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_XRGB2101010, .depth = 30, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t{ .format = DRM_FORMAT_XBGR2101010, .depth = 30, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t{ .format = DRM_FORMAT_ARGB2101010, .depth = 30, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_ABGR2101010, .depth = 30, .num_planes = 2,\n\t  .cpp = { 4, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_RGB565, .depth = 16, .num_planes = 2,\n\t  .cpp = { 2, 0, }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n};\n\nstatic const struct drm_format_info dcc_retile_formats[] = {\n\t{ .format = DRM_FORMAT_XRGB8888, .depth = 24, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t { .format = DRM_FORMAT_XBGR8888, .depth = 24, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t{ .format = DRM_FORMAT_ARGB8888, .depth = 32, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t   .has_alpha = true, },\n\t{ .format = DRM_FORMAT_ABGR8888, .depth = 32, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_BGRA8888, .depth = 32, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_XRGB2101010, .depth = 30, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t{ .format = DRM_FORMAT_XBGR2101010, .depth = 30, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n\t{ .format = DRM_FORMAT_ARGB2101010, .depth = 30, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_ABGR2101010, .depth = 30, .num_planes = 3,\n\t  .cpp = { 4, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1,\n\t  .has_alpha = true, },\n\t{ .format = DRM_FORMAT_RGB565, .depth = 16, .num_planes = 3,\n\t  .cpp = { 2, 0, 0 }, .block_w = {1, 1, 1}, .block_h = {1, 1, 1}, .hsub = 1, .vsub = 1, },\n};\n\nstatic const struct drm_format_info *\nlookup_format_info(const struct drm_format_info formats[],\n\t\t  int num_formats, u32 format)\n{\n\tint i;\n\n\tfor (i = 0; i < num_formats; i++) {\n\t\tif (formats[i].format == format)\n\t\t\treturn &formats[i];\n\t}\n\n\treturn NULL;\n}\n\nconst struct drm_format_info *\namdgpu_lookup_format_info(u32 format, uint64_t modifier)\n{\n\tif (!IS_AMD_FMT_MOD(modifier))\n\t\treturn NULL;\n\n\tif (AMD_FMT_MOD_GET(DCC_RETILE, modifier))\n\t\treturn lookup_format_info(dcc_retile_formats,\n\t\t\t\t\t  ARRAY_SIZE(dcc_retile_formats),\n\t\t\t\t\t  format);\n\n\tif (AMD_FMT_MOD_GET(DCC, modifier))\n\t\treturn lookup_format_info(dcc_formats, ARRAY_SIZE(dcc_formats),\n\t\t\t\t\t  format);\n\n\t \n\treturn NULL;\n}\n\n\n \nstatic int\nextract_render_dcc_offset(struct amdgpu_device *adev,\n\t\t\t  struct drm_gem_object *obj,\n\t\t\t  uint64_t *offset)\n{\n\tstruct amdgpu_bo *rbo;\n\tint r = 0;\n\tuint32_t metadata[10];  \n\tuint32_t size;\n\n\trbo = gem_to_amdgpu_bo(obj);\n\tr = amdgpu_bo_reserve(rbo, false);\n\n\tif (unlikely(r)) {\n\t\t \n\t\tif (r != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Unable to reserve buffer: %d\\n\", r);\n\t\treturn r;\n\t}\n\n\tr = amdgpu_bo_get_metadata(rbo, metadata, sizeof(metadata), &size, NULL);\n\tamdgpu_bo_unreserve(rbo);\n\n\tif (r)\n\t\treturn r;\n\n\t \n\tif (size < 40  || metadata[0] != 1)\n\t\treturn -EINVAL;\n\n\tif (adev->family >= AMDGPU_FAMILY_NV) {\n\t\t \n\t\t*offset = ((u64)metadata[9] << 16u) |\n\t\t\t  ((metadata[8] & 0xFF000000u) >> 16);\n\t} else {\n\t\t \n\t\t*offset = ((u64)metadata[9] << 8u) |\n\t\t\t  ((u64)(metadata[7] & 0x1FE0000u) << 23);\n\t}\n\n\treturn 0;\n}\n\nstatic int convert_tiling_flags_to_modifier(struct amdgpu_framebuffer *afb)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(afb->base.dev);\n\tuint64_t modifier = 0;\n\tint num_pipes = 0;\n\tint num_pkrs = 0;\n\n\tnum_pkrs = adev->gfx.config.gb_addr_config_fields.num_pkrs;\n\tnum_pipes = adev->gfx.config.gb_addr_config_fields.num_pipes;\n\n\tif (!afb->tiling_flags || !AMDGPU_TILING_GET(afb->tiling_flags, SWIZZLE_MODE)) {\n\t\tmodifier = DRM_FORMAT_MOD_LINEAR;\n\t} else {\n\t\tint swizzle = AMDGPU_TILING_GET(afb->tiling_flags, SWIZZLE_MODE);\n\t\tbool has_xor = swizzle >= 16;\n\t\tint block_size_bits;\n\t\tint version;\n\t\tint pipe_xor_bits = 0;\n\t\tint bank_xor_bits = 0;\n\t\tint packers = 0;\n\t\tint rb = 0;\n\t\tint pipes = ilog2(num_pipes);\n\t\tuint32_t dcc_offset = AMDGPU_TILING_GET(afb->tiling_flags, DCC_OFFSET_256B);\n\n\t\tswitch (swizzle >> 2) {\n\t\tcase 0:  \n\t\t\tblock_size_bits = 8;\n\t\t\tbreak;\n\t\tcase 1:  \n\t\tcase 5:  \n\t\t\tblock_size_bits = 12;\n\t\t\tbreak;\n\t\tcase 2:  \n\t\tcase 4:  \n\t\tcase 6:  \n\t\t\tblock_size_bits = 16;\n\t\t\tbreak;\n\t\tcase 7:  \n\t\t\tblock_size_bits = 18;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (adev->ip_versions[GC_HWIP][0] >= IP_VERSION(11, 0, 0))\n\t\t\tversion = AMD_FMT_MOD_TILE_VER_GFX11;\n\t\telse if (adev->ip_versions[GC_HWIP][0] >= IP_VERSION(10, 3, 0))\n\t\t\tversion = AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS;\n\t\telse if (adev->ip_versions[GC_HWIP][0] >= IP_VERSION(10, 0, 0))\n\t\t\tversion = AMD_FMT_MOD_TILE_VER_GFX10;\n\t\telse\n\t\t\tversion = AMD_FMT_MOD_TILE_VER_GFX9;\n\n\t\tswitch (swizzle & 3) {\n\t\tcase 0:  \n\t\t\treturn -EINVAL;\n\t\tcase 1:  \n\t\t\tif (adev->ip_versions[GC_HWIP][0] < IP_VERSION(11, 0, 0)) {\n\t\t\t\tif (!has_xor)\n\t\t\t\t\tversion = AMD_FMT_MOD_TILE_VER_GFX9;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tif (adev->ip_versions[GC_HWIP][0] < IP_VERSION(11, 0, 0)) {\n\t\t\t\tif (!has_xor && afb->base.format->cpp[0] != 4)\n\t\t\t\t\tversion = AMD_FMT_MOD_TILE_VER_GFX9;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (has_xor) {\n\t\t\tif (num_pipes == num_pkrs && num_pkrs == 0) {\n\t\t\t\tDRM_ERROR(\"invalid number of pipes and packers\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tswitch (version) {\n\t\t\tcase AMD_FMT_MOD_TILE_VER_GFX11:\n\t\t\t\tpipe_xor_bits = min(block_size_bits - 8, pipes);\n\t\t\t\tpackers = ilog2(adev->gfx.config.gb_addr_config_fields.num_pkrs);\n\t\t\t\tbreak;\n\t\t\tcase AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS:\n\t\t\t\tpipe_xor_bits = min(block_size_bits - 8, pipes);\n\t\t\t\tpackers = min(block_size_bits - 8 - pipe_xor_bits,\n\t\t\t\t\t      ilog2(adev->gfx.config.gb_addr_config_fields.num_pkrs));\n\t\t\t\tbreak;\n\t\t\tcase AMD_FMT_MOD_TILE_VER_GFX10:\n\t\t\t\tpipe_xor_bits = min(block_size_bits - 8, pipes);\n\t\t\t\tbreak;\n\t\t\tcase AMD_FMT_MOD_TILE_VER_GFX9:\n\t\t\t\trb = ilog2(adev->gfx.config.gb_addr_config_fields.num_se) +\n\t\t\t\t     ilog2(adev->gfx.config.gb_addr_config_fields.num_rb_per_se);\n\t\t\t\tpipe_xor_bits = min(block_size_bits - 8, pipes +\n\t\t\t\t\t\t    ilog2(adev->gfx.config.gb_addr_config_fields.num_se));\n\t\t\t\tbank_xor_bits = min(block_size_bits - 8 - pipe_xor_bits,\n\t\t\t\t\t\t    ilog2(adev->gfx.config.gb_addr_config_fields.num_banks));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tmodifier = AMD_FMT_MOD |\n\t\t\t   AMD_FMT_MOD_SET(TILE, AMDGPU_TILING_GET(afb->tiling_flags, SWIZZLE_MODE)) |\n\t\t\t   AMD_FMT_MOD_SET(TILE_VERSION, version) |\n\t\t\t   AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t\t   AMD_FMT_MOD_SET(BANK_XOR_BITS, bank_xor_bits) |\n\t\t\t   AMD_FMT_MOD_SET(PACKERS, packers);\n\n\t\tif (dcc_offset != 0) {\n\t\t\tbool dcc_i64b = AMDGPU_TILING_GET(afb->tiling_flags, DCC_INDEPENDENT_64B) != 0;\n\t\t\tbool dcc_i128b = version >= AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS;\n\t\t\tconst struct drm_format_info *format_info;\n\t\t\tu64 render_dcc_offset;\n\n\t\t\t \n\t\t\tbool dcc_constant_encode = (adev->asic_type > CHIP_RAVEN ||\n\t\t\t\t\t\t   (adev->asic_type == CHIP_RAVEN &&\n\t\t\t\t\t\t    adev->external_rev_id >= 0x81)) &&\n\t\t\t\t\t\t    adev->ip_versions[GC_HWIP][0] < IP_VERSION(11, 0, 0);\n\n\t\t\tint max_cblock_size = dcc_i64b ? AMD_FMT_MOD_DCC_BLOCK_64B :\n\t\t\t\t\t      dcc_i128b ? AMD_FMT_MOD_DCC_BLOCK_128B :\n\t\t\t\t\t      AMD_FMT_MOD_DCC_BLOCK_256B;\n\n\t\t\tmodifier |= AMD_FMT_MOD_SET(DCC, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, dcc_constant_encode) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, dcc_i64b) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_128B, dcc_i128b) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, max_cblock_size);\n\n\t\t\tafb->base.offsets[1] = dcc_offset * 256 + afb->base.offsets[0];\n\t\t\tafb->base.pitches[1] =\n\t\t\t\tAMDGPU_TILING_GET(afb->tiling_flags, DCC_PITCH_MAX) + 1;\n\n\t\t\t \n\t\t\tif (extract_render_dcc_offset(adev, afb->base.obj[0],\n\t\t\t\t\t\t      &render_dcc_offset) == 0 &&\n\t\t\t    render_dcc_offset != 0 &&\n\t\t\t    render_dcc_offset != afb->base.offsets[1] &&\n\t\t\t    render_dcc_offset < UINT_MAX) {\n\t\t\t\tuint32_t dcc_block_bits;   \n\n\t\t\t\tmodifier |= AMD_FMT_MOD_SET(DCC_RETILE, 1);\n\t\t\t\tafb->base.offsets[2] = render_dcc_offset;\n\n\t\t\t\tif (adev->family >= AMDGPU_FAMILY_NV) {\n\t\t\t\t\tint extra_pipe = 0;\n\n\t\t\t\t\tif ((adev->ip_versions[GC_HWIP][0] >= IP_VERSION(10, 3, 0)) &&\n\t\t\t\t\t    pipes == packers && pipes > 1)\n\t\t\t\t\t\textra_pipe = 1;\n\n\t\t\t\t\tdcc_block_bits = max(20, 16 + pipes + extra_pipe);\n\t\t\t\t} else {\n\t\t\t\t\tmodifier |= AMD_FMT_MOD_SET(RB, rb) |\n\t\t\t\t\t\t    AMD_FMT_MOD_SET(PIPE, pipes);\n\t\t\t\t\tdcc_block_bits = max(20, 18 + rb);\n\t\t\t\t}\n\n\t\t\t\tdcc_block_bits -= ilog2(afb->base.format->cpp[0]);\n\t\t\t\tafb->base.pitches[2] = ALIGN(afb->base.width,\n\t\t\t\t\t\t\t     1u << ((dcc_block_bits + 1) / 2));\n\t\t\t}\n\t\t\tformat_info = amdgpu_lookup_format_info(afb->base.format->format,\n\t\t\t\t\t\t\t\tmodifier);\n\t\t\tif (!format_info)\n\t\t\t\treturn -EINVAL;\n\n\t\t\tafb->base.format = format_info;\n\t\t}\n\t}\n\n\tafb->base.modifier = modifier;\n\tafb->base.flags |= DRM_MODE_FB_MODIFIERS;\n\treturn 0;\n}\n\n \nstatic int check_tiling_flags_gfx6(struct amdgpu_framebuffer *afb)\n{\n\tu64 micro_tile_mode;\n\n\t \n\tif (AMDGPU_TILING_GET(afb->tiling_flags, SWIZZLE_MODE) == 0)\n\t\treturn 0;\n\n\tmicro_tile_mode = AMDGPU_TILING_GET(afb->tiling_flags, MICRO_TILE_MODE);\n\tswitch (micro_tile_mode) {\n\tcase 0:  \n\tcase 3:  \n\t\treturn 0;\n\tdefault:\n\t\tdrm_dbg_kms(afb->base.dev,\n\t\t\t    \"Micro tile mode %llu not supported for scanout\\n\",\n\t\t\t    micro_tile_mode);\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void get_block_dimensions(unsigned int block_log2, unsigned int cpp,\n\t\t\t\t unsigned int *width, unsigned int *height)\n{\n\tunsigned int cpp_log2 = ilog2(cpp);\n\tunsigned int pixel_log2 = block_log2 - cpp_log2;\n\tunsigned int width_log2 = (pixel_log2 + 1) / 2;\n\tunsigned int height_log2 = pixel_log2 - width_log2;\n\n\t*width = 1 << width_log2;\n\t*height = 1 << height_log2;\n}\n\nstatic unsigned int get_dcc_block_size(uint64_t modifier, bool rb_aligned,\n\t\t\t\t       bool pipe_aligned)\n{\n\tunsigned int ver = AMD_FMT_MOD_GET(TILE_VERSION, modifier);\n\n\tswitch (ver) {\n\tcase AMD_FMT_MOD_TILE_VER_GFX9: {\n\t\t \n\t\treturn max(10 + (rb_aligned ? (int)AMD_FMT_MOD_GET(RB, modifier) : 0), 12);\n\t}\n\tcase AMD_FMT_MOD_TILE_VER_GFX10:\n\tcase AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS:\n\tcase AMD_FMT_MOD_TILE_VER_GFX11: {\n\t\tint pipes_log2 = AMD_FMT_MOD_GET(PIPE_XOR_BITS, modifier);\n\n\t\tif (ver >= AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS && pipes_log2 > 1 &&\n\t\t    AMD_FMT_MOD_GET(PACKERS, modifier) == pipes_log2)\n\t\t\t++pipes_log2;\n\n\t\treturn max(8 + (pipe_aligned ? pipes_log2 : 0), 12);\n\t}\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic int amdgpu_display_verify_plane(struct amdgpu_framebuffer *rfb, int plane,\n\t\t\t\t       const struct drm_format_info *format,\n\t\t\t\t       unsigned int block_width, unsigned int block_height,\n\t\t\t\t       unsigned int block_size_log2)\n{\n\tunsigned int width = rfb->base.width /\n\t\t((plane && plane < format->num_planes) ? format->hsub : 1);\n\tunsigned int height = rfb->base.height /\n\t\t((plane && plane < format->num_planes) ? format->vsub : 1);\n\tunsigned int cpp = plane < format->num_planes ? format->cpp[plane] : 1;\n\tunsigned int block_pitch = block_width * cpp;\n\tunsigned int min_pitch = ALIGN(width * cpp, block_pitch);\n\tunsigned int block_size = 1 << block_size_log2;\n\tuint64_t size;\n\n\tif (rfb->base.pitches[plane] % block_pitch) {\n\t\tdrm_dbg_kms(rfb->base.dev,\n\t\t\t    \"pitch %d for plane %d is not a multiple of block pitch %d\\n\",\n\t\t\t    rfb->base.pitches[plane], plane, block_pitch);\n\t\treturn -EINVAL;\n\t}\n\tif (rfb->base.pitches[plane] < min_pitch) {\n\t\tdrm_dbg_kms(rfb->base.dev,\n\t\t\t    \"pitch %d for plane %d is less than minimum pitch %d\\n\",\n\t\t\t    rfb->base.pitches[plane], plane, min_pitch);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (rfb->base.offsets[plane] % block_size) {\n\t\tdrm_dbg_kms(rfb->base.dev,\n\t\t\t    \"offset 0x%x for plane %d is not a multiple of block pitch 0x%x\\n\",\n\t\t\t    rfb->base.offsets[plane], plane, block_size);\n\t\treturn -EINVAL;\n\t}\n\n\tsize = rfb->base.offsets[plane] +\n\t\t(uint64_t)rfb->base.pitches[plane] / block_pitch *\n\t\tblock_size * DIV_ROUND_UP(height, block_height);\n\n\tif (rfb->base.obj[0]->size < size) {\n\t\tdrm_dbg_kms(rfb->base.dev,\n\t\t\t    \"BO size 0x%zx is less than 0x%llx required for plane %d\\n\",\n\t\t\t    rfb->base.obj[0]->size, size, plane);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n\nstatic int amdgpu_display_verify_sizes(struct amdgpu_framebuffer *rfb)\n{\n\tconst struct drm_format_info *format_info = drm_format_info(rfb->base.format->format);\n\tuint64_t modifier = rfb->base.modifier;\n\tint ret;\n\tunsigned int i, block_width, block_height, block_size_log2;\n\n\tif (rfb->base.dev->mode_config.fb_modifiers_not_supported)\n\t\treturn 0;\n\n\tfor (i = 0; i < format_info->num_planes; ++i) {\n\t\tif (modifier == DRM_FORMAT_MOD_LINEAR) {\n\t\t\tblock_width = 256 / format_info->cpp[i];\n\t\t\tblock_height = 1;\n\t\t\tblock_size_log2 = 8;\n\t\t} else {\n\t\t\tint swizzle = AMD_FMT_MOD_GET(TILE, modifier);\n\n\t\t\tswitch ((swizzle & ~3) + 1) {\n\t\t\tcase DC_SW_256B_S:\n\t\t\t\tblock_size_log2 = 8;\n\t\t\t\tbreak;\n\t\t\tcase DC_SW_4KB_S:\n\t\t\tcase DC_SW_4KB_S_X:\n\t\t\t\tblock_size_log2 = 12;\n\t\t\t\tbreak;\n\t\t\tcase DC_SW_64KB_S:\n\t\t\tcase DC_SW_64KB_S_T:\n\t\t\tcase DC_SW_64KB_S_X:\n\t\t\t\tblock_size_log2 = 16;\n\t\t\t\tbreak;\n\t\t\tcase DC_SW_VAR_S_X:\n\t\t\t\tblock_size_log2 = 18;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tdrm_dbg_kms(rfb->base.dev,\n\t\t\t\t\t    \"Swizzle mode with unknown block size: %d\\n\", swizzle);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tget_block_dimensions(block_size_log2, format_info->cpp[i],\n\t\t\t\t\t     &block_width, &block_height);\n\t\t}\n\n\t\tret = amdgpu_display_verify_plane(rfb, i, format_info,\n\t\t\t\t\t\t  block_width, block_height, block_size_log2);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (AMD_FMT_MOD_GET(DCC, modifier)) {\n\t\tif (AMD_FMT_MOD_GET(DCC_RETILE, modifier)) {\n\t\t\tblock_size_log2 = get_dcc_block_size(modifier, false, false);\n\t\t\tget_block_dimensions(block_size_log2 + 8, format_info->cpp[0],\n\t\t\t\t\t     &block_width, &block_height);\n\t\t\tret = amdgpu_display_verify_plane(rfb, i, format_info,\n\t\t\t\t\t\t\t  block_width, block_height,\n\t\t\t\t\t\t\t  block_size_log2);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\t++i;\n\t\t\tblock_size_log2 = get_dcc_block_size(modifier, true, true);\n\t\t} else {\n\t\t\tbool pipe_aligned = AMD_FMT_MOD_GET(DCC_PIPE_ALIGN, modifier);\n\n\t\t\tblock_size_log2 = get_dcc_block_size(modifier, true, pipe_aligned);\n\t\t}\n\t\tget_block_dimensions(block_size_log2 + 8, format_info->cpp[0],\n\t\t\t\t     &block_width, &block_height);\n\t\tret = amdgpu_display_verify_plane(rfb, i, format_info,\n\t\t\t\t\t\t  block_width, block_height, block_size_log2);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int amdgpu_display_get_fb_info(const struct amdgpu_framebuffer *amdgpu_fb,\n\t\t\t\t      uint64_t *tiling_flags, bool *tmz_surface)\n{\n\tstruct amdgpu_bo *rbo;\n\tint r;\n\n\tif (!amdgpu_fb) {\n\t\t*tiling_flags = 0;\n\t\t*tmz_surface = false;\n\t\treturn 0;\n\t}\n\n\trbo = gem_to_amdgpu_bo(amdgpu_fb->base.obj[0]);\n\tr = amdgpu_bo_reserve(rbo, false);\n\n\tif (unlikely(r)) {\n\t\t \n\t\tif (r != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Unable to reserve buffer: %d\\n\", r);\n\t\treturn r;\n\t}\n\n\tif (tiling_flags)\n\t\tamdgpu_bo_get_tiling_flags(rbo, tiling_flags);\n\n\tif (tmz_surface)\n\t\t*tmz_surface = amdgpu_bo_encrypted(rbo);\n\n\tamdgpu_bo_unreserve(rbo);\n\n\treturn r;\n}\n\nstatic int amdgpu_display_gem_fb_verify_and_init(struct drm_device *dev,\n\t\t\t\t\t\t struct amdgpu_framebuffer *rfb,\n\t\t\t\t\t\t struct drm_file *file_priv,\n\t\t\t\t\t\t const struct drm_mode_fb_cmd2 *mode_cmd,\n\t\t\t\t\t\t struct drm_gem_object *obj)\n{\n\tint ret;\n\n\trfb->base.obj[0] = obj;\n\tdrm_helper_mode_fill_fb_struct(dev, &rfb->base, mode_cmd);\n\t \n\tif (!drm_any_plane_has_format(dev, mode_cmd->pixel_format,\n\t\t\t\t      mode_cmd->modifier[0])) {\n\t\tdrm_dbg_kms(dev,\n\t\t\t    \"unsupported pixel format %p4cc / modifier 0x%llx\\n\",\n\t\t\t    &mode_cmd->pixel_format, mode_cmd->modifier[0]);\n\n\t\tret = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tret = amdgpu_display_framebuffer_init(dev, rfb, mode_cmd, obj);\n\tif (ret)\n\t\tgoto err;\n\n\tif (drm_drv_uses_atomic_modeset(dev))\n\t\tret = drm_framebuffer_init(dev, &rfb->base,\n\t\t\t\t\t   &amdgpu_fb_funcs_atomic);\n\telse\n\t\tret = drm_framebuffer_init(dev, &rfb->base, &amdgpu_fb_funcs);\n\n\tif (ret)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tdrm_dbg_kms(dev, \"Failed to verify and init gem fb: %d\\n\", ret);\n\trfb->base.obj[0] = NULL;\n\treturn ret;\n}\n\nstatic int amdgpu_display_framebuffer_init(struct drm_device *dev,\n\t\t\t\t\t   struct amdgpu_framebuffer *rfb,\n\t\t\t\t\t   const struct drm_mode_fb_cmd2 *mode_cmd,\n\t\t\t\t\t   struct drm_gem_object *obj)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tint ret, i;\n\n\t \n\tfor (i = 1; i < rfb->base.format->num_planes; ++i) {\n\t\tif (mode_cmd->handles[i] != mode_cmd->handles[0]) {\n\t\t\tdrm_dbg_kms(dev, \"Plane 0 and %d have different BOs: %u vs. %u\\n\",\n\t\t\t\t    i, mode_cmd->handles[0], mode_cmd->handles[i]);\n\t\t\tret = -EINVAL;\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = amdgpu_display_get_fb_info(rfb, &rfb->tiling_flags, &rfb->tmz_surface);\n\tif (ret)\n\t\treturn ret;\n\n\tif (dev->mode_config.fb_modifiers_not_supported && !adev->enable_virtual_display) {\n\t\tdrm_WARN_ONCE(dev, adev->family >= AMDGPU_FAMILY_AI,\n\t\t\t      \"GFX9+ requires FB check based on format modifier\\n\");\n\t\tret = check_tiling_flags_gfx6(rfb);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (!dev->mode_config.fb_modifiers_not_supported &&\n\t    !(rfb->base.flags & DRM_MODE_FB_MODIFIERS)) {\n\t\tret = convert_tiling_flags_to_modifier(rfb);\n\t\tif (ret) {\n\t\t\tdrm_dbg_kms(dev, \"Failed to convert tiling flags 0x%llX to a modifier\",\n\t\t\t\t    rfb->tiling_flags);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = amdgpu_display_verify_sizes(rfb);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < rfb->base.format->num_planes; ++i) {\n\t\tdrm_gem_object_get(rfb->base.obj[0]);\n\t\trfb->base.obj[i] = rfb->base.obj[0];\n\t}\n\n\treturn 0;\n}\n\nstruct drm_framebuffer *\namdgpu_display_user_framebuffer_create(struct drm_device *dev,\n\t\t\t\t       struct drm_file *file_priv,\n\t\t\t\t       const struct drm_mode_fb_cmd2 *mode_cmd)\n{\n\tstruct amdgpu_framebuffer *amdgpu_fb;\n\tstruct drm_gem_object *obj;\n\tstruct amdgpu_bo *bo;\n\tuint32_t domains;\n\tint ret;\n\n\tobj = drm_gem_object_lookup(file_priv, mode_cmd->handles[0]);\n\tif (obj ==  NULL) {\n\t\tdrm_dbg_kms(dev,\n\t\t\t    \"No GEM object associated to handle 0x%08X, can't create framebuffer\\n\",\n\t\t\t    mode_cmd->handles[0]);\n\n\t\treturn ERR_PTR(-ENOENT);\n\t}\n\n\t \n\tbo = gem_to_amdgpu_bo(obj);\n\tdomains = amdgpu_display_supported_domains(drm_to_adev(dev), bo->flags);\n\tif (obj->import_attach && !(domains & AMDGPU_GEM_DOMAIN_GTT)) {\n\t\tdrm_dbg_kms(dev, \"Cannot create framebuffer from imported dma_buf\\n\");\n\t\tdrm_gem_object_put(obj);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tamdgpu_fb = kzalloc(sizeof(*amdgpu_fb), GFP_KERNEL);\n\tif (amdgpu_fb == NULL) {\n\t\tdrm_gem_object_put(obj);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tret = amdgpu_display_gem_fb_verify_and_init(dev, amdgpu_fb, file_priv,\n\t\t\t\t\t\t    mode_cmd, obj);\n\tif (ret) {\n\t\tkfree(amdgpu_fb);\n\t\tdrm_gem_object_put(obj);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tdrm_gem_object_put(obj);\n\treturn &amdgpu_fb->base;\n}\n\nconst struct drm_mode_config_funcs amdgpu_mode_funcs = {\n\t.fb_create = amdgpu_display_user_framebuffer_create,\n};\n\nstatic const struct drm_prop_enum_list amdgpu_underscan_enum_list[] = {\n\t{ UNDERSCAN_OFF, \"off\" },\n\t{ UNDERSCAN_ON, \"on\" },\n\t{ UNDERSCAN_AUTO, \"auto\" },\n};\n\nstatic const struct drm_prop_enum_list amdgpu_audio_enum_list[] = {\n\t{ AMDGPU_AUDIO_DISABLE, \"off\" },\n\t{ AMDGPU_AUDIO_ENABLE, \"on\" },\n\t{ AMDGPU_AUDIO_AUTO, \"auto\" },\n};\n\n \nstatic const struct drm_prop_enum_list amdgpu_dither_enum_list[] = {\n\t{ AMDGPU_FMT_DITHER_DISABLE, \"off\" },\n\t{ AMDGPU_FMT_DITHER_ENABLE, \"on\" },\n};\n\nint amdgpu_display_modeset_create_props(struct amdgpu_device *adev)\n{\n\tint sz;\n\n\tadev->mode_info.coherent_mode_property =\n\t\tdrm_property_create_range(adev_to_drm(adev), 0, \"coherent\", 0, 1);\n\tif (!adev->mode_info.coherent_mode_property)\n\t\treturn -ENOMEM;\n\n\tadev->mode_info.load_detect_property =\n\t\tdrm_property_create_range(adev_to_drm(adev), 0, \"load detection\", 0, 1);\n\tif (!adev->mode_info.load_detect_property)\n\t\treturn -ENOMEM;\n\n\tdrm_mode_create_scaling_mode_property(adev_to_drm(adev));\n\n\tsz = ARRAY_SIZE(amdgpu_underscan_enum_list);\n\tadev->mode_info.underscan_property =\n\t\tdrm_property_create_enum(adev_to_drm(adev), 0,\n\t\t\t\t\t \"underscan\",\n\t\t\t\t\t amdgpu_underscan_enum_list, sz);\n\n\tadev->mode_info.underscan_hborder_property =\n\t\tdrm_property_create_range(adev_to_drm(adev), 0,\n\t\t\t\t\t  \"underscan hborder\", 0, 128);\n\tif (!adev->mode_info.underscan_hborder_property)\n\t\treturn -ENOMEM;\n\n\tadev->mode_info.underscan_vborder_property =\n\t\tdrm_property_create_range(adev_to_drm(adev), 0,\n\t\t\t\t\t  \"underscan vborder\", 0, 128);\n\tif (!adev->mode_info.underscan_vborder_property)\n\t\treturn -ENOMEM;\n\n\tsz = ARRAY_SIZE(amdgpu_audio_enum_list);\n\tadev->mode_info.audio_property =\n\t\tdrm_property_create_enum(adev_to_drm(adev), 0,\n\t\t\t\t\t \"audio\",\n\t\t\t\t\t amdgpu_audio_enum_list, sz);\n\n\tsz = ARRAY_SIZE(amdgpu_dither_enum_list);\n\tadev->mode_info.dither_property =\n\t\tdrm_property_create_enum(adev_to_drm(adev), 0,\n\t\t\t\t\t \"dither\",\n\t\t\t\t\t amdgpu_dither_enum_list, sz);\n\n\tif (adev->dc_enabled) {\n\t\tadev->mode_info.abm_level_property =\n\t\t\tdrm_property_create_range(adev_to_drm(adev), 0,\n\t\t\t\t\t\t  \"abm level\", 0, 4);\n\t\tif (!adev->mode_info.abm_level_property)\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nvoid amdgpu_display_update_priority(struct amdgpu_device *adev)\n{\n\t \n\tif ((amdgpu_disp_priority == 0) || (amdgpu_disp_priority > 2))\n\t\tadev->mode_info.disp_priority = 0;\n\telse\n\t\tadev->mode_info.disp_priority = amdgpu_disp_priority;\n\n}\n\nstatic bool amdgpu_display_is_hdtv_mode(const struct drm_display_mode *mode)\n{\n\t \n\tif ((mode->vdisplay == 480 && mode->hdisplay == 720) ||  \n\t    (mode->vdisplay == 576) ||  \n\t    (mode->vdisplay == 720) ||  \n\t    (mode->vdisplay == 1080))  \n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nbool amdgpu_display_crtc_scaling_mode_fixup(struct drm_crtc *crtc,\n\t\t\t\t\tconst struct drm_display_mode *mode,\n\t\t\t\t\tstruct drm_display_mode *adjusted_mode)\n{\n\tstruct drm_device *dev = crtc->dev;\n\tstruct drm_encoder *encoder;\n\tstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\n\tstruct amdgpu_encoder *amdgpu_encoder;\n\tstruct drm_connector *connector;\n\tu32 src_v = 1, dst_v = 1;\n\tu32 src_h = 1, dst_h = 1;\n\n\tamdgpu_crtc->h_border = 0;\n\tamdgpu_crtc->v_border = 0;\n\n\tlist_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {\n\t\tif (encoder->crtc != crtc)\n\t\t\tcontinue;\n\t\tamdgpu_encoder = to_amdgpu_encoder(encoder);\n\t\tconnector = amdgpu_get_connector_for_encoder(encoder);\n\n\t\t \n\t\tif (amdgpu_encoder->rmx_type == RMX_OFF)\n\t\t\tamdgpu_crtc->rmx_type = RMX_OFF;\n\t\telse if (mode->hdisplay < amdgpu_encoder->native_mode.hdisplay ||\n\t\t\t mode->vdisplay < amdgpu_encoder->native_mode.vdisplay)\n\t\t\tamdgpu_crtc->rmx_type = amdgpu_encoder->rmx_type;\n\t\telse\n\t\t\tamdgpu_crtc->rmx_type = RMX_OFF;\n\t\t \n\t\tmemcpy(&amdgpu_crtc->native_mode,\n\t\t       &amdgpu_encoder->native_mode,\n\t\t       sizeof(struct drm_display_mode));\n\t\tsrc_v = crtc->mode.vdisplay;\n\t\tdst_v = amdgpu_crtc->native_mode.vdisplay;\n\t\tsrc_h = crtc->mode.hdisplay;\n\t\tdst_h = amdgpu_crtc->native_mode.hdisplay;\n\n\t\t \n\t\tif ((!(mode->flags & DRM_MODE_FLAG_INTERLACE)) &&\n\t\t    ((amdgpu_encoder->underscan_type == UNDERSCAN_ON) ||\n\t\t     ((amdgpu_encoder->underscan_type == UNDERSCAN_AUTO) &&\n\t\t      connector->display_info.is_hdmi &&\n\t\t      amdgpu_display_is_hdtv_mode(mode)))) {\n\t\t\tif (amdgpu_encoder->underscan_hborder != 0)\n\t\t\t\tamdgpu_crtc->h_border = amdgpu_encoder->underscan_hborder;\n\t\t\telse\n\t\t\t\tamdgpu_crtc->h_border = (mode->hdisplay >> 5) + 16;\n\t\t\tif (amdgpu_encoder->underscan_vborder != 0)\n\t\t\t\tamdgpu_crtc->v_border = amdgpu_encoder->underscan_vborder;\n\t\t\telse\n\t\t\t\tamdgpu_crtc->v_border = (mode->vdisplay >> 5) + 16;\n\t\t\tamdgpu_crtc->rmx_type = RMX_FULL;\n\t\t\tsrc_v = crtc->mode.vdisplay;\n\t\t\tdst_v = crtc->mode.vdisplay - (amdgpu_crtc->v_border * 2);\n\t\t\tsrc_h = crtc->mode.hdisplay;\n\t\t\tdst_h = crtc->mode.hdisplay - (amdgpu_crtc->h_border * 2);\n\t\t}\n\t}\n\tif (amdgpu_crtc->rmx_type != RMX_OFF) {\n\t\tfixed20_12 a, b;\n\n\t\ta.full = dfixed_const(src_v);\n\t\tb.full = dfixed_const(dst_v);\n\t\tamdgpu_crtc->vsc.full = dfixed_div(a, b);\n\t\ta.full = dfixed_const(src_h);\n\t\tb.full = dfixed_const(dst_h);\n\t\tamdgpu_crtc->hsc.full = dfixed_div(a, b);\n\t} else {\n\t\tamdgpu_crtc->vsc.full = dfixed_const(1);\n\t\tamdgpu_crtc->hsc.full = dfixed_const(1);\n\t}\n\treturn true;\n}\n\n \nint amdgpu_display_get_crtc_scanoutpos(struct drm_device *dev,\n\t\t\tunsigned int pipe, unsigned int flags, int *vpos,\n\t\t\tint *hpos, ktime_t *stime, ktime_t *etime,\n\t\t\tconst struct drm_display_mode *mode)\n{\n\tu32 vbl = 0, position = 0;\n\tint vbl_start, vbl_end, vtotal, ret = 0;\n\tbool in_vbl = true;\n\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\n\t \n\n\t \n\tif (stime)\n\t\t*stime = ktime_get();\n\n\tif (amdgpu_display_page_flip_get_scanoutpos(adev, pipe, &vbl, &position) == 0)\n\t\tret |= DRM_SCANOUTPOS_VALID;\n\n\t \n\tif (etime)\n\t\t*etime = ktime_get();\n\n\t \n\n\t \n\t*vpos = position & 0x1fff;\n\t*hpos = (position >> 16) & 0x1fff;\n\n\t \n\tif (vbl > 0) {\n\t\t \n\t\tret |= DRM_SCANOUTPOS_ACCURATE;\n\t\tvbl_start = vbl & 0x1fff;\n\t\tvbl_end = (vbl >> 16) & 0x1fff;\n\t} else {\n\t\t \n\t\tvbl_start = mode->crtc_vdisplay;\n\t\tvbl_end = 0;\n\t}\n\n\t \n\tif (flags & GET_DISTANCE_TO_VBLANKSTART) {\n\t\t \n\t\t*hpos = *vpos - vbl_start;\n\t}\n\n\t \n\tif (!(flags & USE_REAL_VBLANKSTART))\n\t\tvbl_start -= adev->mode_info.crtcs[pipe]->lb_vblank_lead_lines;\n\n\t \n\tif ((*vpos < vbl_start) && (*vpos >= vbl_end))\n\t\tin_vbl = false;\n\n\t \n\tif (in_vbl)\n\t\tret |= DRM_SCANOUTPOS_IN_VBLANK;\n\n\t \n\tif (flags & GET_DISTANCE_TO_VBLANKSTART) {\n\t\t \n\t\t*vpos -= vbl_start;\n\t\treturn ret;\n\t}\n\n\t \n\n\t \n\tif (in_vbl && (*vpos >= vbl_start)) {\n\t\tvtotal = mode->crtc_vtotal;\n\n\t\t \n\t\t*vpos = (*vpos < vtotal) ? (*vpos - vtotal) : 0;\n\t}\n\n\t \n\t*vpos = *vpos - vbl_end;\n\n\treturn ret;\n}\n\nint amdgpu_display_crtc_idx_to_irq_type(struct amdgpu_device *adev, int crtc)\n{\n\tif (crtc < 0 || crtc >= adev->mode_info.num_crtc)\n\t\treturn AMDGPU_CRTC_IRQ_NONE;\n\n\tswitch (crtc) {\n\tcase 0:\n\t\treturn AMDGPU_CRTC_IRQ_VBLANK1;\n\tcase 1:\n\t\treturn AMDGPU_CRTC_IRQ_VBLANK2;\n\tcase 2:\n\t\treturn AMDGPU_CRTC_IRQ_VBLANK3;\n\tcase 3:\n\t\treturn AMDGPU_CRTC_IRQ_VBLANK4;\n\tcase 4:\n\t\treturn AMDGPU_CRTC_IRQ_VBLANK5;\n\tcase 5:\n\t\treturn AMDGPU_CRTC_IRQ_VBLANK6;\n\tdefault:\n\t\treturn AMDGPU_CRTC_IRQ_NONE;\n\t}\n}\n\nbool amdgpu_crtc_get_scanout_position(struct drm_crtc *crtc,\n\t\t\tbool in_vblank_irq, int *vpos,\n\t\t\tint *hpos, ktime_t *stime, ktime_t *etime,\n\t\t\tconst struct drm_display_mode *mode)\n{\n\tstruct drm_device *dev = crtc->dev;\n\tunsigned int pipe = crtc->index;\n\n\treturn amdgpu_display_get_crtc_scanoutpos(dev, pipe, 0, vpos, hpos,\n\t\t\t\t\t\t  stime, etime, mode);\n}\n\nstatic bool\namdgpu_display_robj_is_fb(struct amdgpu_device *adev, struct amdgpu_bo *robj)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_fb_helper *fb_helper = dev->fb_helper;\n\n\tif (!fb_helper || !fb_helper->buffer)\n\t\treturn false;\n\n\tif (gem_to_amdgpu_bo(fb_helper->buffer->gem) != robj)\n\t\treturn false;\n\n\treturn true;\n}\n\nint amdgpu_display_suspend_helper(struct amdgpu_device *adev)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_crtc *crtc;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\tint r;\n\n\tdrm_kms_helper_poll_disable(dev);\n\n\t \n\tdrm_modeset_lock_all(dev);\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter)\n\t\tdrm_helper_connector_dpms(connector,\n\t\t\t\t\t  DRM_MODE_DPMS_OFF);\n\tdrm_connector_list_iter_end(&iter);\n\tdrm_modeset_unlock_all(dev);\n\t \n\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\tstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\n\t\tstruct drm_framebuffer *fb = crtc->primary->fb;\n\t\tstruct amdgpu_bo *robj;\n\n\t\tif (amdgpu_crtc->cursor_bo && !adev->enable_virtual_display) {\n\t\t\tstruct amdgpu_bo *aobj = gem_to_amdgpu_bo(amdgpu_crtc->cursor_bo);\n\n\t\t\tr = amdgpu_bo_reserve(aobj, true);\n\t\t\tif (r == 0) {\n\t\t\t\tamdgpu_bo_unpin(aobj);\n\t\t\t\tamdgpu_bo_unreserve(aobj);\n\t\t\t}\n\t\t}\n\n\t\tif (!fb || !fb->obj[0])\n\t\t\tcontinue;\n\n\t\trobj = gem_to_amdgpu_bo(fb->obj[0]);\n\t\tif (!amdgpu_display_robj_is_fb(adev, robj)) {\n\t\t\tr = amdgpu_bo_reserve(robj, true);\n\t\t\tif (r == 0) {\n\t\t\t\tamdgpu_bo_unpin(robj);\n\t\t\t\tamdgpu_bo_unreserve(robj);\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nint amdgpu_display_resume_helper(struct amdgpu_device *adev)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\tstruct drm_crtc *crtc;\n\tint r;\n\n\t \n\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\tstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\n\n\t\tif (amdgpu_crtc->cursor_bo && !adev->enable_virtual_display) {\n\t\t\tstruct amdgpu_bo *aobj = gem_to_amdgpu_bo(amdgpu_crtc->cursor_bo);\n\n\t\t\tr = amdgpu_bo_reserve(aobj, true);\n\t\t\tif (r == 0) {\n\t\t\t\tr = amdgpu_bo_pin(aobj, AMDGPU_GEM_DOMAIN_VRAM);\n\t\t\t\tif (r != 0)\n\t\t\t\t\tdev_err(adev->dev, \"Failed to pin cursor BO (%d)\\n\", r);\n\t\t\t\tamdgpu_crtc->cursor_addr = amdgpu_bo_gpu_offset(aobj);\n\t\t\t\tamdgpu_bo_unreserve(aobj);\n\t\t\t}\n\t\t}\n\t}\n\n\tdrm_helper_resume_force_mode(dev);\n\n\t \n\tdrm_modeset_lock_all(dev);\n\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter)\n\t\tdrm_helper_connector_dpms(connector,\n\t\t\t\t\t  DRM_MODE_DPMS_ON);\n\tdrm_connector_list_iter_end(&iter);\n\n\tdrm_modeset_unlock_all(dev);\n\n\tdrm_kms_helper_poll_enable(dev);\n\n\treturn 0;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}