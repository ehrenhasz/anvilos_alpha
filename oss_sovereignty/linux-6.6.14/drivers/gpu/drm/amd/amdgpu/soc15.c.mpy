{
  "module_name": "soc15.c",
  "hash_id": "fbd4a298e18faa2cfbadfd44e6f0d8a3010e271f366af5c6446c68fe134208fa",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/soc15.c",
  "human_readable_source": " \n#include <linux/firmware.h>\n#include <linux/slab.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n\n#include <drm/amdgpu_drm.h>\n\n#include \"amdgpu.h\"\n#include \"amdgpu_atombios.h\"\n#include \"amdgpu_ih.h\"\n#include \"amdgpu_uvd.h\"\n#include \"amdgpu_vce.h\"\n#include \"amdgpu_ucode.h\"\n#include \"amdgpu_psp.h\"\n#include \"atom.h\"\n#include \"amd_pcie.h\"\n\n#include \"uvd/uvd_7_0_offset.h\"\n#include \"gc/gc_9_0_offset.h\"\n#include \"gc/gc_9_0_sh_mask.h\"\n#include \"sdma0/sdma0_4_0_offset.h\"\n#include \"sdma1/sdma1_4_0_offset.h\"\n#include \"nbio/nbio_7_0_default.h\"\n#include \"nbio/nbio_7_0_offset.h\"\n#include \"nbio/nbio_7_0_sh_mask.h\"\n#include \"nbio/nbio_7_0_smn.h\"\n#include \"mp/mp_9_0_offset.h\"\n\n#include \"soc15.h\"\n#include \"soc15_common.h\"\n#include \"gfx_v9_0.h\"\n#include \"gmc_v9_0.h\"\n#include \"gfxhub_v1_0.h\"\n#include \"mmhub_v1_0.h\"\n#include \"df_v1_7.h\"\n#include \"df_v3_6.h\"\n#include \"nbio_v6_1.h\"\n#include \"nbio_v7_0.h\"\n#include \"nbio_v7_4.h\"\n#include \"hdp_v4_0.h\"\n#include \"vega10_ih.h\"\n#include \"vega20_ih.h\"\n#include \"navi10_ih.h\"\n#include \"sdma_v4_0.h\"\n#include \"uvd_v7_0.h\"\n#include \"vce_v4_0.h\"\n#include \"vcn_v1_0.h\"\n#include \"vcn_v2_0.h\"\n#include \"jpeg_v2_0.h\"\n#include \"vcn_v2_5.h\"\n#include \"jpeg_v2_5.h\"\n#include \"smuio_v9_0.h\"\n#include \"smuio_v11_0.h\"\n#include \"smuio_v13_0.h\"\n#include \"amdgpu_vkms.h\"\n#include \"mxgpu_ai.h\"\n#include \"amdgpu_ras.h\"\n#include \"amdgpu_xgmi.h\"\n#include <uapi/linux/kfd_ioctl.h>\n\n#define mmMP0_MISC_CGTT_CTRL0                                                                   0x01b9\n#define mmMP0_MISC_CGTT_CTRL0_BASE_IDX                                                          0\n#define mmMP0_MISC_LIGHT_SLEEP_CTRL                                                             0x01ba\n#define mmMP0_MISC_LIGHT_SLEEP_CTRL_BASE_IDX                                                    0\n\nstatic const struct amd_ip_funcs soc15_common_ip_funcs;\n\n \nstatic const struct amdgpu_video_codec_info vega_video_codecs_encode_array[] =\n{\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 2304, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 4096, 2304, 0)},\n};\n\nstatic const struct amdgpu_video_codecs vega_video_codecs_encode =\n{\n\t.codec_count = ARRAY_SIZE(vega_video_codecs_encode_array),\n\t.codec_array = vega_video_codecs_encode_array,\n};\n\n \nstatic const struct amdgpu_video_codec_info vega_video_codecs_decode_array[] =\n{\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG2, 4096, 4096, 3)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4, 4096, 4096, 5)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VC1, 4096, 4096, 4)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 4096, 4096, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n};\n\nstatic const struct amdgpu_video_codecs vega_video_codecs_decode =\n{\n\t.codec_count = ARRAY_SIZE(vega_video_codecs_decode_array),\n\t.codec_array = vega_video_codecs_decode_array,\n};\n\n \nstatic const struct amdgpu_video_codec_info rv_video_codecs_decode_array[] =\n{\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG2, 4096, 4096, 3)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4, 4096, 4096, 5)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VC1, 4096, 4096, 4)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 4096, 4096, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VP9, 4096, 4096, 0)},\n};\n\nstatic const struct amdgpu_video_codecs rv_video_codecs_decode =\n{\n\t.codec_count = ARRAY_SIZE(rv_video_codecs_decode_array),\n\t.codec_array = rv_video_codecs_decode_array,\n};\n\n \nstatic const struct amdgpu_video_codec_info rn_video_codecs_decode_array[] =\n{\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG2, 4096, 4096, 3)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4, 4096, 4096, 5)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VC1, 4096, 4096, 4)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 8192, 4352, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VP9, 8192, 4352, 0)},\n};\n\nstatic const struct amdgpu_video_codecs rn_video_codecs_decode =\n{\n\t.codec_count = ARRAY_SIZE(rn_video_codecs_decode_array),\n\t.codec_array = rn_video_codecs_decode_array,\n};\n\nstatic const struct amdgpu_video_codec_info vcn_4_0_3_video_codecs_decode_array[] = {\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_MPEG4_AVC, 4096, 4096, 52)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_HEVC, 8192, 4352, 186)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_JPEG, 4096, 4096, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_VP9, 8192, 4352, 0)},\n\t{codec_info_build(AMDGPU_INFO_VIDEO_CAPS_CODEC_IDX_AV1, 8192, 4352, 0)},\n};\n\nstatic const struct amdgpu_video_codecs vcn_4_0_3_video_codecs_decode = {\n\t.codec_count = ARRAY_SIZE(vcn_4_0_3_video_codecs_decode_array),\n\t.codec_array = vcn_4_0_3_video_codecs_decode_array,\n};\n\nstatic const struct amdgpu_video_codecs vcn_4_0_3_video_codecs_encode = {\n\t.codec_count = 0,\n\t.codec_array = NULL,\n};\n\nstatic int soc15_query_video_codecs(struct amdgpu_device *adev, bool encode,\n\t\t\t\t    const struct amdgpu_video_codecs **codecs)\n{\n\tif (adev->ip_versions[VCE_HWIP][0]) {\n\t\tswitch (adev->ip_versions[VCE_HWIP][0]) {\n\t\tcase IP_VERSION(4, 0, 0):\n\t\tcase IP_VERSION(4, 1, 0):\n\t\t\tif (encode)\n\t\t\t\t*codecs = &vega_video_codecs_encode;\n\t\t\telse\n\t\t\t\t*codecs = &vega_video_codecs_decode;\n\t\t\treturn 0;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tswitch (adev->ip_versions[UVD_HWIP][0]) {\n\t\tcase IP_VERSION(1, 0, 0):\n\t\tcase IP_VERSION(1, 0, 1):\n\t\t\tif (encode)\n\t\t\t\t*codecs = &vega_video_codecs_encode;\n\t\t\telse\n\t\t\t\t*codecs = &rv_video_codecs_decode;\n\t\t\treturn 0;\n\t\tcase IP_VERSION(2, 5, 0):\n\t\tcase IP_VERSION(2, 6, 0):\n\t\tcase IP_VERSION(2, 2, 0):\n\t\t\tif (encode)\n\t\t\t\t*codecs = &vega_video_codecs_encode;\n\t\t\telse\n\t\t\t\t*codecs = &rn_video_codecs_decode;\n\t\t\treturn 0;\n\t\tcase IP_VERSION(4, 0, 3):\n\t\t\tif (encode)\n\t\t\t\t*codecs = &vcn_4_0_3_video_codecs_encode;\n\t\t\telse\n\t\t\t\t*codecs = &vcn_4_0_3_video_codecs_decode;\n\t\t\treturn 0;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n}\n\nstatic u32 soc15_uvd_ctx_rreg(struct amdgpu_device *adev, u32 reg)\n{\n\tunsigned long flags, address, data;\n\tu32 r;\n\n\taddress = SOC15_REG_OFFSET(UVD, 0, mmUVD_CTX_INDEX);\n\tdata = SOC15_REG_OFFSET(UVD, 0, mmUVD_CTX_DATA);\n\n\tspin_lock_irqsave(&adev->uvd_ctx_idx_lock, flags);\n\tWREG32(address, ((reg) & 0x1ff));\n\tr = RREG32(data);\n\tspin_unlock_irqrestore(&adev->uvd_ctx_idx_lock, flags);\n\treturn r;\n}\n\nstatic void soc15_uvd_ctx_wreg(struct amdgpu_device *adev, u32 reg, u32 v)\n{\n\tunsigned long flags, address, data;\n\n\taddress = SOC15_REG_OFFSET(UVD, 0, mmUVD_CTX_INDEX);\n\tdata = SOC15_REG_OFFSET(UVD, 0, mmUVD_CTX_DATA);\n\n\tspin_lock_irqsave(&adev->uvd_ctx_idx_lock, flags);\n\tWREG32(address, ((reg) & 0x1ff));\n\tWREG32(data, (v));\n\tspin_unlock_irqrestore(&adev->uvd_ctx_idx_lock, flags);\n}\n\nstatic u32 soc15_didt_rreg(struct amdgpu_device *adev, u32 reg)\n{\n\tunsigned long flags, address, data;\n\tu32 r;\n\n\taddress = SOC15_REG_OFFSET(GC, 0, mmDIDT_IND_INDEX);\n\tdata = SOC15_REG_OFFSET(GC, 0, mmDIDT_IND_DATA);\n\n\tspin_lock_irqsave(&adev->didt_idx_lock, flags);\n\tWREG32(address, (reg));\n\tr = RREG32(data);\n\tspin_unlock_irqrestore(&adev->didt_idx_lock, flags);\n\treturn r;\n}\n\nstatic void soc15_didt_wreg(struct amdgpu_device *adev, u32 reg, u32 v)\n{\n\tunsigned long flags, address, data;\n\n\taddress = SOC15_REG_OFFSET(GC, 0, mmDIDT_IND_INDEX);\n\tdata = SOC15_REG_OFFSET(GC, 0, mmDIDT_IND_DATA);\n\n\tspin_lock_irqsave(&adev->didt_idx_lock, flags);\n\tWREG32(address, (reg));\n\tWREG32(data, (v));\n\tspin_unlock_irqrestore(&adev->didt_idx_lock, flags);\n}\n\nstatic u32 soc15_gc_cac_rreg(struct amdgpu_device *adev, u32 reg)\n{\n\tunsigned long flags;\n\tu32 r;\n\n\tspin_lock_irqsave(&adev->gc_cac_idx_lock, flags);\n\tWREG32_SOC15(GC, 0, mmGC_CAC_IND_INDEX, (reg));\n\tr = RREG32_SOC15(GC, 0, mmGC_CAC_IND_DATA);\n\tspin_unlock_irqrestore(&adev->gc_cac_idx_lock, flags);\n\treturn r;\n}\n\nstatic void soc15_gc_cac_wreg(struct amdgpu_device *adev, u32 reg, u32 v)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&adev->gc_cac_idx_lock, flags);\n\tWREG32_SOC15(GC, 0, mmGC_CAC_IND_INDEX, (reg));\n\tWREG32_SOC15(GC, 0, mmGC_CAC_IND_DATA, (v));\n\tspin_unlock_irqrestore(&adev->gc_cac_idx_lock, flags);\n}\n\nstatic u32 soc15_se_cac_rreg(struct amdgpu_device *adev, u32 reg)\n{\n\tunsigned long flags;\n\tu32 r;\n\n\tspin_lock_irqsave(&adev->se_cac_idx_lock, flags);\n\tWREG32_SOC15(GC, 0, mmSE_CAC_IND_INDEX, (reg));\n\tr = RREG32_SOC15(GC, 0, mmSE_CAC_IND_DATA);\n\tspin_unlock_irqrestore(&adev->se_cac_idx_lock, flags);\n\treturn r;\n}\n\nstatic void soc15_se_cac_wreg(struct amdgpu_device *adev, u32 reg, u32 v)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&adev->se_cac_idx_lock, flags);\n\tWREG32_SOC15(GC, 0, mmSE_CAC_IND_INDEX, (reg));\n\tWREG32_SOC15(GC, 0, mmSE_CAC_IND_DATA, (v));\n\tspin_unlock_irqrestore(&adev->se_cac_idx_lock, flags);\n}\n\nstatic u32 soc15_get_config_memsize(struct amdgpu_device *adev)\n{\n\treturn adev->nbio.funcs->get_memsize(adev);\n}\n\nstatic u32 soc15_get_xclk(struct amdgpu_device *adev)\n{\n\tu32 reference_clock = adev->clock.spll.reference_freq;\n\n\tif (adev->ip_versions[MP1_HWIP][0] == IP_VERSION(12, 0, 0) ||\n\t    adev->ip_versions[MP1_HWIP][0] == IP_VERSION(12, 0, 1) ||\n\t    adev->ip_versions[MP1_HWIP][0] == IP_VERSION(13, 0, 6))\n\t\treturn 10000;\n\tif (adev->ip_versions[MP1_HWIP][0] == IP_VERSION(10, 0, 0) ||\n\t    adev->ip_versions[MP1_HWIP][0] == IP_VERSION(10, 0, 1))\n\t\treturn reference_clock / 4;\n\n\treturn reference_clock;\n}\n\n\nvoid soc15_grbm_select(struct amdgpu_device *adev,\n\t\t     u32 me, u32 pipe, u32 queue, u32 vmid, int xcc_id)\n{\n\tu32 grbm_gfx_cntl = 0;\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, PIPEID, pipe);\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, MEID, me);\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, VMID, vmid);\n\tgrbm_gfx_cntl = REG_SET_FIELD(grbm_gfx_cntl, GRBM_GFX_CNTL, QUEUEID, queue);\n\n\tWREG32_SOC15_RLC_SHADOW(GC, xcc_id, mmGRBM_GFX_CNTL, grbm_gfx_cntl);\n}\n\nstatic bool soc15_read_disabled_bios(struct amdgpu_device *adev)\n{\n\t \n\treturn false;\n}\n\nstatic struct soc15_allowed_register_entry soc15_allowed_read_registers[] = {\n\t{ SOC15_REG_ENTRY(GC, 0, mmGRBM_STATUS)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmGRBM_STATUS2)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmGRBM_STATUS_SE0)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmGRBM_STATUS_SE1)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmGRBM_STATUS_SE2)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmGRBM_STATUS_SE3)},\n\t{ SOC15_REG_ENTRY(SDMA0, 0, mmSDMA0_STATUS_REG)},\n\t{ SOC15_REG_ENTRY(SDMA1, 0, mmSDMA1_STATUS_REG)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_STAT)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_STALLED_STAT1)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_STALLED_STAT2)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_STALLED_STAT3)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_CPF_BUSY_STAT)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_CPF_STALLED_STAT1)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_CPF_STATUS)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_CPC_BUSY_STAT)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_CPC_STALLED_STAT1)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmCP_CPC_STATUS)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmGB_ADDR_CONFIG)},\n\t{ SOC15_REG_ENTRY(GC, 0, mmDB_DEBUG2)},\n};\n\nstatic uint32_t soc15_read_indexed_register(struct amdgpu_device *adev, u32 se_num,\n\t\t\t\t\t u32 sh_num, u32 reg_offset)\n{\n\tuint32_t val;\n\n\tmutex_lock(&adev->grbm_idx_mutex);\n\tif (se_num != 0xffffffff || sh_num != 0xffffffff)\n\t\tamdgpu_gfx_select_se_sh(adev, se_num, sh_num, 0xffffffff, 0);\n\n\tval = RREG32(reg_offset);\n\n\tif (se_num != 0xffffffff || sh_num != 0xffffffff)\n\t\tamdgpu_gfx_select_se_sh(adev, 0xffffffff, 0xffffffff, 0xffffffff, 0);\n\tmutex_unlock(&adev->grbm_idx_mutex);\n\treturn val;\n}\n\nstatic uint32_t soc15_get_register_value(struct amdgpu_device *adev,\n\t\t\t\t\t bool indexed, u32 se_num,\n\t\t\t\t\t u32 sh_num, u32 reg_offset)\n{\n\tif (indexed) {\n\t\treturn soc15_read_indexed_register(adev, se_num, sh_num, reg_offset);\n\t} else {\n\t\tif (reg_offset == SOC15_REG_OFFSET(GC, 0, mmGB_ADDR_CONFIG))\n\t\t\treturn adev->gfx.config.gb_addr_config;\n\t\telse if (reg_offset == SOC15_REG_OFFSET(GC, 0, mmDB_DEBUG2))\n\t\t\treturn adev->gfx.config.db_debug2;\n\t\treturn RREG32(reg_offset);\n\t}\n}\n\nstatic int soc15_read_register(struct amdgpu_device *adev, u32 se_num,\n\t\t\t    u32 sh_num, u32 reg_offset, u32 *value)\n{\n\tuint32_t i;\n\tstruct soc15_allowed_register_entry  *en;\n\n\t*value = 0;\n\tfor (i = 0; i < ARRAY_SIZE(soc15_allowed_read_registers); i++) {\n\t\ten = &soc15_allowed_read_registers[i];\n\t\tif (!adev->reg_offset[en->hwip][en->inst])\n\t\t\tcontinue;\n\t\telse if (reg_offset != (adev->reg_offset[en->hwip][en->inst][en->seg]\n\t\t\t\t\t+ en->reg_offset))\n\t\t\tcontinue;\n\n\t\t*value = soc15_get_register_value(adev,\n\t\t\t\t\t\t  soc15_allowed_read_registers[i].grbm_indexed,\n\t\t\t\t\t\t  se_num, sh_num, reg_offset);\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}\n\n\n \n\nvoid soc15_program_register_sequence(struct amdgpu_device *adev,\n\t\t\t\t\t     const struct soc15_reg_golden *regs,\n\t\t\t\t\t     const u32 array_size)\n{\n\tconst struct soc15_reg_golden *entry;\n\tu32 tmp, reg;\n\tint i;\n\n\tfor (i = 0; i < array_size; ++i) {\n\t\tentry = &regs[i];\n\t\treg =  adev->reg_offset[entry->hwip][entry->instance][entry->segment] + entry->reg;\n\n\t\tif (entry->and_mask == 0xffffffff) {\n\t\t\ttmp = entry->or_mask;\n\t\t} else {\n\t\t\ttmp = (entry->hwip == GC_HWIP) ?\n\t\t\t\tRREG32_SOC15_IP(GC, reg) : RREG32(reg);\n\n\t\t\ttmp &= ~(entry->and_mask);\n\t\t\ttmp |= (entry->or_mask & entry->and_mask);\n\t\t}\n\n\t\tif (reg == SOC15_REG_OFFSET(GC, 0, mmPA_SC_BINNER_EVENT_CNTL_3) ||\n\t\t\treg == SOC15_REG_OFFSET(GC, 0, mmPA_SC_ENHANCE) ||\n\t\t\treg == SOC15_REG_OFFSET(GC, 0, mmPA_SC_ENHANCE_1) ||\n\t\t\treg == SOC15_REG_OFFSET(GC, 0, mmSH_MEM_CONFIG))\n\t\t\tWREG32_RLC(reg, tmp);\n\t\telse\n\t\t\t(entry->hwip == GC_HWIP) ?\n\t\t\t\tWREG32_SOC15_IP(GC, reg, tmp) : WREG32(reg, tmp);\n\n\t}\n\n}\n\nstatic int soc15_asic_baco_reset(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\tint ret = 0;\n\n\t \n\tif (ras && adev->ras_enabled)\n\t\tadev->nbio.funcs->enable_doorbell_interrupt(adev, false);\n\n\tret = amdgpu_dpm_baco_reset(adev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (ras && adev->ras_enabled)\n\t\tadev->nbio.funcs->enable_doorbell_interrupt(adev, true);\n\n\treturn 0;\n}\n\nstatic enum amd_reset_method\nsoc15_asic_reset_method(struct amdgpu_device *adev)\n{\n\tbool baco_reset = false;\n\tbool connected_to_cpu = false;\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\n        if (adev->gmc.xgmi.supported && adev->gmc.xgmi.connected_to_cpu)\n                connected_to_cpu = true;\n\n\tif (amdgpu_reset_method == AMD_RESET_METHOD_MODE1 ||\n\t    amdgpu_reset_method == AMD_RESET_METHOD_MODE2 ||\n\t    amdgpu_reset_method == AMD_RESET_METHOD_BACO ||\n\t    amdgpu_reset_method == AMD_RESET_METHOD_PCI) {\n\t\t \n                if (connected_to_cpu)\n                        return AMD_RESET_METHOD_MODE2;\n                return amdgpu_reset_method;\n        }\n\n\tif (amdgpu_reset_method != -1)\n\t\tdev_warn(adev->dev, \"Specified reset method:%d isn't supported, using AUTO instead.\\n\",\n\t\t\t\t  amdgpu_reset_method);\n\n\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\tcase IP_VERSION(10, 0, 0):\n\tcase IP_VERSION(10, 0, 1):\n\tcase IP_VERSION(12, 0, 0):\n\tcase IP_VERSION(12, 0, 1):\n\t\treturn AMD_RESET_METHOD_MODE2;\n\tcase IP_VERSION(9, 0, 0):\n\tcase IP_VERSION(11, 0, 2):\n\t\tif (adev->asic_type == CHIP_VEGA20) {\n\t\t\tif (adev->psp.sos.fw_version >= 0x80067)\n\t\t\t\tbaco_reset = amdgpu_dpm_is_baco_supported(adev);\n\t\t\t \n\t\t\tif (ras && adev->ras_enabled &&\n\t\t\t    adev->pm.fw_version <= 0x283400)\n\t\t\t\tbaco_reset = false;\n\t\t} else {\n\t\t\tbaco_reset = amdgpu_dpm_is_baco_supported(adev);\n\t\t}\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 2):\n\t\t  \n\t\tif (connected_to_cpu)\n\t\t\treturn AMD_RESET_METHOD_MODE2;\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 6):\n\t\t \n\t\tif (amdgpu_gpu_recovery == 4 || amdgpu_gpu_recovery == 5)\n\t\t\treturn AMD_RESET_METHOD_MODE2;\n\t\telse if (!(adev->flags & AMD_IS_APU))\n\t\t\treturn AMD_RESET_METHOD_MODE1;\n\t\telse\n\t\t\treturn AMD_RESET_METHOD_MODE2;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (baco_reset)\n\t\treturn AMD_RESET_METHOD_BACO;\n\telse\n\t\treturn AMD_RESET_METHOD_MODE1;\n}\n\nstatic int soc15_asic_reset(struct amdgpu_device *adev)\n{\n\t \n\tif ((adev->apu_flags & AMD_APU_IS_RAVEN) ||\n\t    (adev->apu_flags & AMD_APU_IS_RAVEN2))\n\t\treturn 0;\n\n\tswitch (soc15_asic_reset_method(adev)) {\n\tcase AMD_RESET_METHOD_PCI:\n\t\tdev_info(adev->dev, \"PCI reset\\n\");\n\t\treturn amdgpu_device_pci_reset(adev);\n\tcase AMD_RESET_METHOD_BACO:\n\t\tdev_info(adev->dev, \"BACO reset\\n\");\n\t\treturn soc15_asic_baco_reset(adev);\n\tcase AMD_RESET_METHOD_MODE2:\n\t\tdev_info(adev->dev, \"MODE2 reset\\n\");\n\t\treturn amdgpu_dpm_mode2_reset(adev);\n\tdefault:\n\t\tdev_info(adev->dev, \"MODE1 reset\\n\");\n\t\treturn amdgpu_device_mode1_reset(adev);\n\t}\n}\n\nstatic bool soc15_supports_baco(struct amdgpu_device *adev)\n{\n\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\tcase IP_VERSION(9, 0, 0):\n\tcase IP_VERSION(11, 0, 2):\n\t\tif (adev->asic_type == CHIP_VEGA20) {\n\t\t\tif (adev->psp.sos.fw_version >= 0x80067)\n\t\t\t\treturn amdgpu_dpm_is_baco_supported(adev);\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn amdgpu_dpm_is_baco_supported(adev);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\n \n\nstatic int soc15_set_uvd_clocks(struct amdgpu_device *adev, u32 vclk, u32 dclk)\n{\n\t \n\treturn 0;\n}\n\nstatic int soc15_set_vce_clocks(struct amdgpu_device *adev, u32 evclk, u32 ecclk)\n{\n\t \n\n\treturn 0;\n}\n\nstatic void soc15_program_aspm(struct amdgpu_device *adev)\n{\n\tif (!amdgpu_device_should_use_aspm(adev))\n\t\treturn;\n\n\tif (!(adev->flags & AMD_IS_APU) &&\n\t    (adev->nbio.funcs->program_aspm))\n\t\tadev->nbio.funcs->program_aspm(adev);\n}\n\nconst struct amdgpu_ip_block_version vega10_common_ip_block =\n{\n\t.type = AMD_IP_BLOCK_TYPE_COMMON,\n\t.major = 2,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &soc15_common_ip_funcs,\n};\n\nstatic void soc15_reg_base_init(struct amdgpu_device *adev)\n{\n\t \n\tswitch (adev->asic_type) {\n\tcase CHIP_VEGA10:\n\tcase CHIP_VEGA12:\n\tcase CHIP_RAVEN:\n\tcase CHIP_RENOIR:\n\t\tvega10_reg_base_init(adev);\n\t\tbreak;\n\tcase CHIP_VEGA20:\n\t\tvega20_reg_base_init(adev);\n\t\tbreak;\n\tcase CHIP_ARCTURUS:\n\t\tarct_reg_base_init(adev);\n\t\tbreak;\n\tcase CHIP_ALDEBARAN:\n\t\taldebaran_reg_base_init(adev);\n\t\tbreak;\n\tdefault:\n\t\tDRM_ERROR(\"Unsupported asic type: %d!\\n\", adev->asic_type);\n\t\tbreak;\n\t}\n}\n\nvoid soc15_set_virt_ops(struct amdgpu_device *adev)\n{\n\tadev->virt.ops = &xgpu_ai_virt_ops;\n\n\t \n\tsoc15_reg_base_init(adev);\n}\n\nstatic bool soc15_need_full_reset(struct amdgpu_device *adev)\n{\n\t \n\treturn true;\n}\n\nstatic void soc15_get_pcie_usage(struct amdgpu_device *adev, uint64_t *count0,\n\t\t\t\t uint64_t *count1)\n{\n\tuint32_t perfctr = 0;\n\tuint64_t cnt0_of, cnt1_of;\n\tint tmp;\n\n\t \n\tif (adev->flags & AMD_IS_APU)\n\t\treturn;\n\n\t \n\t \n\t \n\tperfctr = REG_SET_FIELD(perfctr, PCIE_PERF_CNTL_TXCLK, EVENT0_SEL, 40);\n\tperfctr = REG_SET_FIELD(perfctr, PCIE_PERF_CNTL_TXCLK, EVENT1_SEL, 104);\n\n\t \n\tWREG32_PCIE(smnPCIE_PERF_CNTL_TXCLK, perfctr);\n\t \n\tWREG32_PCIE(smnPCIE_PERF_COUNT_CNTL, 0x00000005);\n\n\tmsleep(1000);\n\n\t \n\tWREG32_PCIE(smnPCIE_PERF_COUNT_CNTL, 0x00000002);\n\n\t \n\ttmp = RREG32_PCIE(smnPCIE_PERF_CNTL_TXCLK);\n\tcnt0_of = REG_GET_FIELD(tmp, PCIE_PERF_CNTL_TXCLK, COUNTER0_UPPER);\n\tcnt1_of = REG_GET_FIELD(tmp, PCIE_PERF_CNTL_TXCLK, COUNTER1_UPPER);\n\n\t \n\t*count0 = RREG32_PCIE(smnPCIE_PERF_COUNT0_TXCLK) | (cnt0_of << 32);\n\t*count1 = RREG32_PCIE(smnPCIE_PERF_COUNT1_TXCLK) | (cnt1_of << 32);\n}\n\nstatic void vega20_get_pcie_usage(struct amdgpu_device *adev, uint64_t *count0,\n\t\t\t\t uint64_t *count1)\n{\n\tuint32_t perfctr = 0;\n\tuint64_t cnt0_of, cnt1_of;\n\tint tmp;\n\n\t \n\tif (adev->flags & AMD_IS_APU)\n\t\treturn;\n\n\t \n\t \n\t \n\tperfctr = REG_SET_FIELD(perfctr, PCIE_PERF_CNTL_TXCLK3,\n\t\t\t\tEVENT0_SEL, 40);\n\tperfctr = REG_SET_FIELD(perfctr, PCIE_PERF_CNTL_TXCLK3,\n\t\t\t\tEVENT1_SEL, 108);\n\n\t \n\tWREG32_PCIE(smnPCIE_PERF_CNTL_TXCLK3, perfctr);\n\t \n\tWREG32_PCIE(smnPCIE_PERF_COUNT_CNTL, 0x00000005);\n\n\tmsleep(1000);\n\n\t \n\tWREG32_PCIE(smnPCIE_PERF_COUNT_CNTL, 0x00000002);\n\n\t \n\ttmp = RREG32_PCIE(smnPCIE_PERF_CNTL_TXCLK3);\n\tcnt0_of = REG_GET_FIELD(tmp, PCIE_PERF_CNTL_TXCLK3, COUNTER0_UPPER);\n\tcnt1_of = REG_GET_FIELD(tmp, PCIE_PERF_CNTL_TXCLK3, COUNTER1_UPPER);\n\n\t \n\t*count0 = RREG32_PCIE(smnPCIE_PERF_COUNT0_TXCLK3) | (cnt0_of << 32);\n\t*count1 = RREG32_PCIE(smnPCIE_PERF_COUNT1_TXCLK3) | (cnt1_of << 32);\n}\n\nstatic bool soc15_need_reset_on_init(struct amdgpu_device *adev)\n{\n\tu32 sol_reg;\n\n\t \n\tif (adev->asic_type == CHIP_RENOIR)\n\t\treturn true;\n\n\t \n\tif (!amdgpu_passthrough(adev))\n\t\treturn false;\n\n\tif (adev->flags & AMD_IS_APU)\n\t\treturn false;\n\n\t \n\tsol_reg = RREG32_SOC15(MP0, 0, mmMP0_SMN_C2PMSG_81);\n\tif (sol_reg)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic uint64_t soc15_get_pcie_replay_count(struct amdgpu_device *adev)\n{\n\tuint64_t nak_r, nak_g;\n\n\t \n\tnak_r = RREG32_PCIE(smnPCIE_RX_NUM_NAK);\n\tnak_g = RREG32_PCIE(smnPCIE_RX_NUM_NAK_GENERATED);\n\n\t \n\treturn (nak_r + nak_g);\n}\n\nstatic void soc15_pre_asic_init(struct amdgpu_device *adev)\n{\n\tgmc_v9_0_restore_registers(adev);\n}\n\nstatic const struct amdgpu_asic_funcs soc15_asic_funcs =\n{\n\t.read_disabled_bios = &soc15_read_disabled_bios,\n\t.read_bios_from_rom = &amdgpu_soc15_read_bios_from_rom,\n\t.read_register = &soc15_read_register,\n\t.reset = &soc15_asic_reset,\n\t.reset_method = &soc15_asic_reset_method,\n\t.get_xclk = &soc15_get_xclk,\n\t.set_uvd_clocks = &soc15_set_uvd_clocks,\n\t.set_vce_clocks = &soc15_set_vce_clocks,\n\t.get_config_memsize = &soc15_get_config_memsize,\n\t.need_full_reset = &soc15_need_full_reset,\n\t.init_doorbell_index = &vega10_doorbell_index_init,\n\t.get_pcie_usage = &soc15_get_pcie_usage,\n\t.need_reset_on_init = &soc15_need_reset_on_init,\n\t.get_pcie_replay_count = &soc15_get_pcie_replay_count,\n\t.supports_baco = &soc15_supports_baco,\n\t.pre_asic_init = &soc15_pre_asic_init,\n\t.query_video_codecs = &soc15_query_video_codecs,\n};\n\nstatic const struct amdgpu_asic_funcs vega20_asic_funcs =\n{\n\t.read_disabled_bios = &soc15_read_disabled_bios,\n\t.read_bios_from_rom = &amdgpu_soc15_read_bios_from_rom,\n\t.read_register = &soc15_read_register,\n\t.reset = &soc15_asic_reset,\n\t.reset_method = &soc15_asic_reset_method,\n\t.get_xclk = &soc15_get_xclk,\n\t.set_uvd_clocks = &soc15_set_uvd_clocks,\n\t.set_vce_clocks = &soc15_set_vce_clocks,\n\t.get_config_memsize = &soc15_get_config_memsize,\n\t.need_full_reset = &soc15_need_full_reset,\n\t.init_doorbell_index = &vega20_doorbell_index_init,\n\t.get_pcie_usage = &vega20_get_pcie_usage,\n\t.need_reset_on_init = &soc15_need_reset_on_init,\n\t.get_pcie_replay_count = &soc15_get_pcie_replay_count,\n\t.supports_baco = &soc15_supports_baco,\n\t.pre_asic_init = &soc15_pre_asic_init,\n\t.query_video_codecs = &soc15_query_video_codecs,\n};\n\nstatic const struct amdgpu_asic_funcs aqua_vanjaram_asic_funcs =\n{\n\t.read_disabled_bios = &soc15_read_disabled_bios,\n\t.read_bios_from_rom = &amdgpu_soc15_read_bios_from_rom,\n\t.read_register = &soc15_read_register,\n\t.reset = &soc15_asic_reset,\n\t.reset_method = &soc15_asic_reset_method,\n\t.get_xclk = &soc15_get_xclk,\n\t.set_uvd_clocks = &soc15_set_uvd_clocks,\n\t.set_vce_clocks = &soc15_set_vce_clocks,\n\t.get_config_memsize = &soc15_get_config_memsize,\n\t.need_full_reset = &soc15_need_full_reset,\n\t.init_doorbell_index = &aqua_vanjaram_doorbell_index_init,\n\t.get_pcie_usage = &amdgpu_nbio_get_pcie_usage,\n\t.need_reset_on_init = &soc15_need_reset_on_init,\n\t.get_pcie_replay_count = &amdgpu_nbio_get_pcie_replay_count,\n\t.supports_baco = &soc15_supports_baco,\n\t.pre_asic_init = &soc15_pre_asic_init,\n\t.query_video_codecs = &soc15_query_video_codecs,\n\t.encode_ext_smn_addressing = &aqua_vanjaram_encode_ext_smn_addressing,\n};\n\nstatic int soc15_common_early_init(void *handle)\n{\n#define MMIO_REG_HOLE_OFFSET (0x80000 - PAGE_SIZE)\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (!amdgpu_sriov_vf(adev)) {\n\t\tadev->rmmio_remap.reg_offset = MMIO_REG_HOLE_OFFSET;\n\t\tadev->rmmio_remap.bus_addr = adev->rmmio_base + MMIO_REG_HOLE_OFFSET;\n\t}\n\tadev->smc_rreg = NULL;\n\tadev->smc_wreg = NULL;\n\tadev->pcie_rreg = &amdgpu_device_indirect_rreg;\n\tadev->pcie_wreg = &amdgpu_device_indirect_wreg;\n\tadev->pcie_rreg_ext = &amdgpu_device_indirect_rreg_ext;\n\tadev->pcie_wreg_ext = &amdgpu_device_indirect_wreg_ext;\n\tadev->pcie_rreg64 = &amdgpu_device_indirect_rreg64;\n\tadev->pcie_wreg64 = &amdgpu_device_indirect_wreg64;\n\tadev->uvd_ctx_rreg = &soc15_uvd_ctx_rreg;\n\tadev->uvd_ctx_wreg = &soc15_uvd_ctx_wreg;\n\tadev->didt_rreg = &soc15_didt_rreg;\n\tadev->didt_wreg = &soc15_didt_wreg;\n\tadev->gc_cac_rreg = &soc15_gc_cac_rreg;\n\tadev->gc_cac_wreg = &soc15_gc_cac_wreg;\n\tadev->se_cac_rreg = &soc15_se_cac_rreg;\n\tadev->se_cac_wreg = &soc15_se_cac_wreg;\n\n\tadev->rev_id = amdgpu_device_get_rev_id(adev);\n\tadev->external_rev_id = 0xFF;\n\t \n\tswitch (adev->ip_versions[GC_HWIP][0]) {\n\tcase IP_VERSION(9, 0, 1):\n\t\tadev->asic_funcs = &soc15_asic_funcs;\n\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_RLC_LS |\n\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_BIF_MGCG |\n\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\tAMD_CG_SUPPORT_DRM_MGCG |\n\t\t\tAMD_CG_SUPPORT_DRM_LS |\n\t\t\tAMD_CG_SUPPORT_ROM_MGCG |\n\t\t\tAMD_CG_SUPPORT_DF_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\tAMD_CG_SUPPORT_MC_LS;\n\t\tadev->pg_flags = 0;\n\t\tadev->external_rev_id = 0x1;\n\t\tbreak;\n\tcase IP_VERSION(9, 2, 1):\n\t\tadev->asic_funcs = &soc15_asic_funcs;\n\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\tAMD_CG_SUPPORT_BIF_MGCG |\n\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\tAMD_CG_SUPPORT_HDP_MGCG |\n\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\tAMD_CG_SUPPORT_ROM_MGCG |\n\t\t\tAMD_CG_SUPPORT_VCE_MGCG |\n\t\t\tAMD_CG_SUPPORT_UVD_MGCG;\n\t\tadev->pg_flags = 0;\n\t\tadev->external_rev_id = adev->rev_id + 0x14;\n\t\tbreak;\n\tcase IP_VERSION(9, 4, 0):\n\t\tadev->asic_funcs = &vega20_asic_funcs;\n\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_3D_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\tAMD_CG_SUPPORT_BIF_MGCG |\n\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\tAMD_CG_SUPPORT_HDP_MGCG |\n\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\tAMD_CG_SUPPORT_ROM_MGCG |\n\t\t\tAMD_CG_SUPPORT_VCE_MGCG |\n\t\t\tAMD_CG_SUPPORT_UVD_MGCG;\n\t\tadev->pg_flags = 0;\n\t\tadev->external_rev_id = adev->rev_id + 0x28;\n\t\tbreak;\n\tcase IP_VERSION(9, 1, 0):\n\tcase IP_VERSION(9, 2, 2):\n\t\tadev->asic_funcs = &soc15_asic_funcs;\n\n\t\tif (adev->rev_id >= 0x8)\n\t\t\tadev->apu_flags |= AMD_APU_IS_RAVEN2;\n\n\t\tif (adev->apu_flags & AMD_APU_IS_RAVEN2)\n\t\t\tadev->external_rev_id = adev->rev_id + 0x79;\n\t\telse if (adev->apu_flags & AMD_APU_IS_PICASSO)\n\t\t\tadev->external_rev_id = adev->rev_id + 0x41;\n\t\telse if (adev->rev_id == 1)\n\t\t\tadev->external_rev_id = adev->rev_id + 0x20;\n\t\telse\n\t\t\tadev->external_rev_id = adev->rev_id + 0x01;\n\n\t\tif (adev->apu_flags & AMD_APU_IS_RAVEN2) {\n\t\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_3D_CGCG |\n\t\t\t\tAMD_CG_SUPPORT_GFX_3D_CGLS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\t\tAMD_CG_SUPPORT_VCN_MGCG;\n\n\t\t\tadev->pg_flags = AMD_PG_SUPPORT_SDMA | AMD_PG_SUPPORT_VCN;\n\t\t} else if (adev->apu_flags & AMD_APU_IS_PICASSO) {\n\t\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_3D_CGLS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\t\tAMD_CG_SUPPORT_VCN_MGCG;\n\n\t\t\t \n\t\t\tadev->pg_flags = AMD_PG_SUPPORT_SDMA |\n\t\t\t\tAMD_PG_SUPPORT_VCN;\n\t\t} else {\n\t\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_RLC_LS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_3D_CGLS |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\t\tAMD_CG_SUPPORT_BIF_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_BIF_LS |\n\t\t\t\tAMD_CG_SUPPORT_HDP_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\t\tAMD_CG_SUPPORT_DRM_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_DRM_LS |\n\t\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\t\tAMD_CG_SUPPORT_VCN_MGCG;\n\n\t\t\tadev->pg_flags = AMD_PG_SUPPORT_SDMA | AMD_PG_SUPPORT_VCN;\n\t\t}\n\t\tbreak;\n\tcase IP_VERSION(9, 4, 1):\n\t\tadev->asic_funcs = &vega20_asic_funcs;\n\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\tAMD_CG_SUPPORT_HDP_MGCG |\n\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\tAMD_CG_SUPPORT_MC_MGCG |\n\t\t\tAMD_CG_SUPPORT_MC_LS |\n\t\t\tAMD_CG_SUPPORT_IH_CG |\n\t\t\tAMD_CG_SUPPORT_VCN_MGCG |\n\t\t\tAMD_CG_SUPPORT_JPEG_MGCG;\n\t\tadev->pg_flags = AMD_PG_SUPPORT_VCN | AMD_PG_SUPPORT_VCN_DPG;\n\t\tadev->external_rev_id = adev->rev_id + 0x32;\n\t\tbreak;\n\tcase IP_VERSION(9, 3, 0):\n\t\tadev->asic_funcs = &soc15_asic_funcs;\n\n\t\tif (adev->apu_flags & AMD_APU_IS_RENOIR)\n\t\t\tadev->external_rev_id = adev->rev_id + 0x91;\n\t\telse\n\t\t\tadev->external_rev_id = adev->rev_id + 0xa1;\n\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\t\t AMD_CG_SUPPORT_GFX_MGLS |\n\t\t\t\t AMD_CG_SUPPORT_GFX_3D_CGCG |\n\t\t\t\t AMD_CG_SUPPORT_GFX_3D_CGLS |\n\t\t\t\t AMD_CG_SUPPORT_GFX_CGCG |\n\t\t\t\t AMD_CG_SUPPORT_GFX_CGLS |\n\t\t\t\t AMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\t\t AMD_CG_SUPPORT_MC_MGCG |\n\t\t\t\t AMD_CG_SUPPORT_MC_LS |\n\t\t\t\t AMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\t\t AMD_CG_SUPPORT_SDMA_LS |\n\t\t\t\t AMD_CG_SUPPORT_BIF_LS |\n\t\t\t\t AMD_CG_SUPPORT_HDP_LS |\n\t\t\t\t AMD_CG_SUPPORT_VCN_MGCG |\n\t\t\t\t AMD_CG_SUPPORT_JPEG_MGCG |\n\t\t\t\t AMD_CG_SUPPORT_IH_CG |\n\t\t\t\t AMD_CG_SUPPORT_ATHUB_LS |\n\t\t\t\t AMD_CG_SUPPORT_ATHUB_MGCG |\n\t\t\t\t AMD_CG_SUPPORT_DF_MGCG;\n\t\tadev->pg_flags = AMD_PG_SUPPORT_SDMA |\n\t\t\t\t AMD_PG_SUPPORT_VCN |\n\t\t\t\t AMD_PG_SUPPORT_JPEG |\n\t\t\t\t AMD_PG_SUPPORT_VCN_DPG;\n\t\tbreak;\n\tcase IP_VERSION(9, 4, 2):\n\t\tadev->asic_funcs = &vega20_asic_funcs;\n\t\tadev->cg_flags = AMD_CG_SUPPORT_GFX_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_MGLS |\n\t\t\tAMD_CG_SUPPORT_GFX_CP_LS |\n\t\t\tAMD_CG_SUPPORT_HDP_LS |\n\t\t\tAMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\tAMD_CG_SUPPORT_SDMA_LS |\n\t\t\tAMD_CG_SUPPORT_IH_CG |\n\t\t\tAMD_CG_SUPPORT_VCN_MGCG | AMD_CG_SUPPORT_JPEG_MGCG;\n\t\tadev->pg_flags = AMD_PG_SUPPORT_VCN_DPG;\n\t\tadev->external_rev_id = adev->rev_id + 0x3c;\n\t\tbreak;\n\tcase IP_VERSION(9, 4, 3):\n\t\tadev->asic_funcs = &aqua_vanjaram_asic_funcs;\n\t\tadev->cg_flags =\n\t\t\tAMD_CG_SUPPORT_GFX_MGCG | AMD_CG_SUPPORT_GFX_CGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_CGLS | AMD_CG_SUPPORT_SDMA_MGCG |\n\t\t\tAMD_CG_SUPPORT_GFX_FGCG | AMD_CG_SUPPORT_REPEATER_FGCG |\n\t\t\tAMD_CG_SUPPORT_VCN_MGCG | AMD_CG_SUPPORT_JPEG_MGCG |\n\t\t\tAMD_CG_SUPPORT_IH_CG;\n\t\tadev->pg_flags =\n\t\t\tAMD_PG_SUPPORT_VCN |\n\t\t\tAMD_PG_SUPPORT_VCN_DPG |\n\t\t\tAMD_PG_SUPPORT_JPEG;\n\t\tadev->external_rev_id = adev->rev_id + 0x46;\n\t\t \n\t\tif (!amdgpu_sriov_vf(adev)) {\n\t\t\tadev->rmmio_remap.reg_offset = 0x1A000;\n\t\t\tadev->rmmio_remap.bus_addr = adev->rmmio_base + 0x1A000;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\tif (amdgpu_sriov_vf(adev)) {\n\t\tamdgpu_virt_init_setting(adev);\n\t\txgpu_ai_mailbox_set_irq_funcs(adev);\n\t}\n\n\treturn 0;\n}\n\nstatic int soc15_common_late_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (amdgpu_sriov_vf(adev))\n\t\txgpu_ai_mailbox_get_irq(adev);\n\n\t \n\tadev->nbio.funcs->enable_doorbell_selfring_aperture(adev, true);\n\n\treturn 0;\n}\n\nstatic int soc15_common_sw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (amdgpu_sriov_vf(adev))\n\t\txgpu_ai_mailbox_add_irq_id(adev);\n\n\tif (adev->df.funcs &&\n\t    adev->df.funcs->sw_init)\n\t\tadev->df.funcs->sw_init(adev);\n\n\treturn 0;\n}\n\nstatic int soc15_common_sw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (adev->df.funcs &&\n\t    adev->df.funcs->sw_fini)\n\t\tadev->df.funcs->sw_fini(adev);\n\treturn 0;\n}\n\nstatic void soc15_sdma_doorbell_range_init(struct amdgpu_device *adev)\n{\n\tint i;\n\n\t \n\tif (!amdgpu_sriov_vf(adev)) {\n\t\tfor (i = 0; i < adev->sdma.num_instances; i++) {\n\t\t\tadev->nbio.funcs->sdma_doorbell_range(adev, i,\n\t\t\t\ttrue, adev->doorbell_index.sdma_engine[i] << 1,\n\t\t\t\tadev->doorbell_index.sdma_doorbell_range);\n\t\t}\n\t}\n}\n\nstatic int soc15_common_hw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\t \n\tsoc15_program_aspm(adev);\n\t \n\tadev->nbio.funcs->init_registers(adev);\n\t \n\tif (adev->nbio.funcs->remap_hdp_registers && !amdgpu_sriov_vf(adev))\n\t\tadev->nbio.funcs->remap_hdp_registers(adev);\n\n\t \n\tadev->nbio.funcs->enable_doorbell_aperture(adev, true);\n\n\t \n\tsoc15_sdma_doorbell_range_init(adev);\n\n\treturn 0;\n}\n\nstatic int soc15_common_hw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\t \n\tadev->nbio.funcs->enable_doorbell_aperture(adev, false);\n\tadev->nbio.funcs->enable_doorbell_selfring_aperture(adev, false);\n\n\tif (amdgpu_sriov_vf(adev))\n\t\txgpu_ai_mailbox_put_irq(adev);\n\n\tif (adev->nbio.ras_if &&\n\t    amdgpu_ras_is_supported(adev, adev->nbio.ras_if->block)) {\n\t\tif (adev->nbio.ras &&\n\t\t    adev->nbio.ras->init_ras_controller_interrupt)\n\t\t\tamdgpu_irq_put(adev, &adev->nbio.ras_controller_irq, 0);\n\t\tif (adev->nbio.ras &&\n\t\t    adev->nbio.ras->init_ras_err_event_athub_interrupt)\n\t\t\tamdgpu_irq_put(adev, &adev->nbio.ras_err_event_athub_irq, 0);\n\t}\n\n\treturn 0;\n}\n\nstatic int soc15_common_suspend(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn soc15_common_hw_fini(adev);\n}\n\nstatic int soc15_common_resume(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn soc15_common_hw_init(adev);\n}\n\nstatic bool soc15_common_is_idle(void *handle)\n{\n\treturn true;\n}\n\nstatic int soc15_common_wait_for_idle(void *handle)\n{\n\treturn 0;\n}\n\nstatic int soc15_common_soft_reset(void *handle)\n{\n\treturn 0;\n}\n\nstatic void soc15_update_drm_clock_gating(struct amdgpu_device *adev, bool enable)\n{\n\tuint32_t def, data;\n\n\tdef = data = RREG32(SOC15_REG_OFFSET(MP0, 0, mmMP0_MISC_CGTT_CTRL0));\n\n\tif (enable && (adev->cg_flags & AMD_CG_SUPPORT_DRM_MGCG))\n\t\tdata &= ~(0x01000000 |\n\t\t\t  0x02000000 |\n\t\t\t  0x04000000 |\n\t\t\t  0x08000000 |\n\t\t\t  0x10000000 |\n\t\t\t  0x20000000 |\n\t\t\t  0x40000000 |\n\t\t\t  0x80000000);\n\telse\n\t\tdata |= (0x01000000 |\n\t\t\t 0x02000000 |\n\t\t\t 0x04000000 |\n\t\t\t 0x08000000 |\n\t\t\t 0x10000000 |\n\t\t\t 0x20000000 |\n\t\t\t 0x40000000 |\n\t\t\t 0x80000000);\n\n\tif (def != data)\n\t\tWREG32(SOC15_REG_OFFSET(MP0, 0, mmMP0_MISC_CGTT_CTRL0), data);\n}\n\nstatic void soc15_update_drm_light_sleep(struct amdgpu_device *adev, bool enable)\n{\n\tuint32_t def, data;\n\n\tdef = data = RREG32(SOC15_REG_OFFSET(MP0, 0, mmMP0_MISC_LIGHT_SLEEP_CTRL));\n\n\tif (enable && (adev->cg_flags & AMD_CG_SUPPORT_DRM_LS))\n\t\tdata |= 1;\n\telse\n\t\tdata &= ~1;\n\n\tif (def != data)\n\t\tWREG32(SOC15_REG_OFFSET(MP0, 0, mmMP0_MISC_LIGHT_SLEEP_CTRL), data);\n}\n\nstatic int soc15_common_set_clockgating_state(void *handle,\n\t\t\t\t\t    enum amd_clockgating_state state)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (amdgpu_sriov_vf(adev))\n\t\treturn 0;\n\n\tswitch (adev->ip_versions[NBIO_HWIP][0]) {\n\tcase IP_VERSION(6, 1, 0):\n\tcase IP_VERSION(6, 2, 0):\n\tcase IP_VERSION(7, 4, 0):\n\t\tadev->nbio.funcs->update_medium_grain_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->nbio.funcs->update_medium_grain_light_sleep(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->hdp.funcs->update_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tsoc15_update_drm_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tsoc15_update_drm_light_sleep(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->smuio.funcs->update_rom_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->df.funcs->update_medium_grain_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tbreak;\n\tcase IP_VERSION(7, 0, 0):\n\tcase IP_VERSION(7, 0, 1):\n\tcase IP_VERSION(2, 5, 0):\n\t\tadev->nbio.funcs->update_medium_grain_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->nbio.funcs->update_medium_grain_light_sleep(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tadev->hdp.funcs->update_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tsoc15_update_drm_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tsoc15_update_drm_light_sleep(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tbreak;\n\tcase IP_VERSION(7, 4, 1):\n\tcase IP_VERSION(7, 4, 4):\n\t\tadev->hdp.funcs->update_clock_gating(adev,\n\t\t\t\tstate == AMD_CG_STATE_GATE);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void soc15_common_get_clockgating_state(void *handle, u64 *flags)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tint data;\n\n\tif (amdgpu_sriov_vf(adev))\n\t\t*flags = 0;\n\n\tif (adev->nbio.funcs && adev->nbio.funcs->get_clockgating_state)\n\t\tadev->nbio.funcs->get_clockgating_state(adev, flags);\n\n\tif (adev->hdp.funcs && adev->hdp.funcs->get_clock_gating_state)\n\t\tadev->hdp.funcs->get_clock_gating_state(adev, flags);\n\n\tif (adev->ip_versions[MP0_HWIP][0] != IP_VERSION(13, 0, 2)) {\n\n\t\t \n\t\tdata = RREG32(SOC15_REG_OFFSET(MP0, 0, mmMP0_MISC_CGTT_CTRL0));\n\t\tif (!(data & 0x01000000))\n\t\t\t*flags |= AMD_CG_SUPPORT_DRM_MGCG;\n\n\t\t \n\t\tdata = RREG32(SOC15_REG_OFFSET(MP0, 0, mmMP0_MISC_LIGHT_SLEEP_CTRL));\n\t\tif (data & 0x1)\n\t\t\t*flags |= AMD_CG_SUPPORT_DRM_LS;\n\t}\n\n\t \n\tif (adev->smuio.funcs && adev->smuio.funcs->get_clock_gating_state)\n\t\tadev->smuio.funcs->get_clock_gating_state(adev, flags);\n\n\tif (adev->df.funcs && adev->df.funcs->get_clockgating_state)\n\t\tadev->df.funcs->get_clockgating_state(adev, flags);\n}\n\nstatic int soc15_common_set_powergating_state(void *handle,\n\t\t\t\t\t    enum amd_powergating_state state)\n{\n\t \n\treturn 0;\n}\n\nstatic const struct amd_ip_funcs soc15_common_ip_funcs = {\n\t.name = \"soc15_common\",\n\t.early_init = soc15_common_early_init,\n\t.late_init = soc15_common_late_init,\n\t.sw_init = soc15_common_sw_init,\n\t.sw_fini = soc15_common_sw_fini,\n\t.hw_init = soc15_common_hw_init,\n\t.hw_fini = soc15_common_hw_fini,\n\t.suspend = soc15_common_suspend,\n\t.resume = soc15_common_resume,\n\t.is_idle = soc15_common_is_idle,\n\t.wait_for_idle = soc15_common_wait_for_idle,\n\t.soft_reset = soc15_common_soft_reset,\n\t.set_clockgating_state = soc15_common_set_clockgating_state,\n\t.set_powergating_state = soc15_common_set_powergating_state,\n\t.get_clockgating_state= soc15_common_get_clockgating_state,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}