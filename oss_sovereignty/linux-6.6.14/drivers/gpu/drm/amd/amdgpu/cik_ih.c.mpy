{
  "module_name": "cik_ih.c",
  "hash_id": "affc0dc9560f4d936a2128227e6bffef5e61a094ccd0cc7020815f6d7eadee70",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/cik_ih.c",
  "human_readable_source": " \n\n#include <linux/pci.h>\n\n#include \"amdgpu.h\"\n#include \"amdgpu_ih.h\"\n#include \"cikd.h\"\n\n#include \"bif/bif_4_1_d.h\"\n#include \"bif/bif_4_1_sh_mask.h\"\n\n#include \"oss/oss_2_0_d.h\"\n#include \"oss/oss_2_0_sh_mask.h\"\n\n \n\nstatic void cik_ih_set_interrupt_funcs(struct amdgpu_device *adev);\n\n \nstatic void cik_ih_enable_interrupts(struct amdgpu_device *adev)\n{\n\tu32 ih_cntl = RREG32(mmIH_CNTL);\n\tu32 ih_rb_cntl = RREG32(mmIH_RB_CNTL);\n\n\tih_cntl |= IH_CNTL__ENABLE_INTR_MASK;\n\tih_rb_cntl |= IH_RB_CNTL__RB_ENABLE_MASK;\n\tWREG32(mmIH_CNTL, ih_cntl);\n\tWREG32(mmIH_RB_CNTL, ih_rb_cntl);\n\tadev->irq.ih.enabled = true;\n}\n\n \nstatic void cik_ih_disable_interrupts(struct amdgpu_device *adev)\n{\n\tu32 ih_rb_cntl = RREG32(mmIH_RB_CNTL);\n\tu32 ih_cntl = RREG32(mmIH_CNTL);\n\n\tih_rb_cntl &= ~IH_RB_CNTL__RB_ENABLE_MASK;\n\tih_cntl &= ~IH_CNTL__ENABLE_INTR_MASK;\n\tWREG32(mmIH_RB_CNTL, ih_rb_cntl);\n\tWREG32(mmIH_CNTL, ih_cntl);\n\t \n\tWREG32(mmIH_RB_RPTR, 0);\n\tWREG32(mmIH_RB_WPTR, 0);\n\tadev->irq.ih.enabled = false;\n\tadev->irq.ih.rptr = 0;\n}\n\n \nstatic int cik_ih_irq_init(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_ih_ring *ih = &adev->irq.ih;\n\tint rb_bufsz;\n\tu32 interrupt_cntl, ih_cntl, ih_rb_cntl;\n\n\t \n\tcik_ih_disable_interrupts(adev);\n\n\t \n\tWREG32(mmINTERRUPT_CNTL2, adev->dummy_page_addr >> 8);\n\tinterrupt_cntl = RREG32(mmINTERRUPT_CNTL);\n\t \n\tinterrupt_cntl &= ~INTERRUPT_CNTL__IH_DUMMY_RD_OVERRIDE_MASK;\n\t \n\tinterrupt_cntl &= ~INTERRUPT_CNTL__IH_REQ_NONSNOOP_EN_MASK;\n\tWREG32(mmINTERRUPT_CNTL, interrupt_cntl);\n\n\tWREG32(mmIH_RB_BASE, adev->irq.ih.gpu_addr >> 8);\n\trb_bufsz = order_base_2(adev->irq.ih.ring_size / 4);\n\n\tih_rb_cntl = (IH_RB_CNTL__WPTR_OVERFLOW_ENABLE_MASK |\n\t\t      IH_RB_CNTL__WPTR_OVERFLOW_CLEAR_MASK |\n\t\t      (rb_bufsz << 1));\n\n\tih_rb_cntl |= IH_RB_CNTL__WPTR_WRITEBACK_ENABLE_MASK;\n\n\t \n\tWREG32(mmIH_RB_WPTR_ADDR_LO, lower_32_bits(ih->wptr_addr));\n\tWREG32(mmIH_RB_WPTR_ADDR_HI, upper_32_bits(ih->wptr_addr) & 0xFF);\n\n\tWREG32(mmIH_RB_CNTL, ih_rb_cntl);\n\n\t \n\tWREG32(mmIH_RB_RPTR, 0);\n\tWREG32(mmIH_RB_WPTR, 0);\n\n\t \n\tih_cntl = (0x10 << IH_CNTL__MC_WRREQ_CREDIT__SHIFT) |\n\t\t(0x10 << IH_CNTL__MC_WR_CLEAN_CNT__SHIFT) |\n\t\t(0 << IH_CNTL__MC_VMID__SHIFT);\n\t \n\tif (adev->irq.msi_enabled)\n\t\tih_cntl |= IH_CNTL__RPTR_REARM_MASK;\n\tWREG32(mmIH_CNTL, ih_cntl);\n\n\tpci_set_master(adev->pdev);\n\n\t \n\tcik_ih_enable_interrupts(adev);\n\n\treturn 0;\n}\n\n \nstatic void cik_ih_irq_disable(struct amdgpu_device *adev)\n{\n\tcik_ih_disable_interrupts(adev);\n\t \n\tmdelay(1);\n}\n\n \nstatic u32 cik_ih_get_wptr(struct amdgpu_device *adev,\n\t\t\t   struct amdgpu_ih_ring *ih)\n{\n\tu32 wptr, tmp;\n\n\twptr = le32_to_cpu(*ih->wptr_cpu);\n\n\tif (wptr & IH_RB_WPTR__RB_OVERFLOW_MASK) {\n\t\twptr &= ~IH_RB_WPTR__RB_OVERFLOW_MASK;\n\t\t \n\t\tdev_warn(adev->dev, \"IH ring buffer overflow (0x%08X, 0x%08X, 0x%08X)\\n\",\n\t\t\t wptr, ih->rptr, (wptr + 16) & ih->ptr_mask);\n\t\tih->rptr = (wptr + 16) & ih->ptr_mask;\n\t\ttmp = RREG32(mmIH_RB_CNTL);\n\t\ttmp |= IH_RB_CNTL__WPTR_OVERFLOW_CLEAR_MASK;\n\t\tWREG32(mmIH_RB_CNTL, tmp);\n\t}\n\treturn (wptr & ih->ptr_mask);\n}\n\n \n\n  \nstatic void cik_ih_decode_iv(struct amdgpu_device *adev,\n\t\t\t     struct amdgpu_ih_ring *ih,\n\t\t\t     struct amdgpu_iv_entry *entry)\n{\n\t \n\tu32 ring_index = ih->rptr >> 2;\n\tuint32_t dw[4];\n\n\tdw[0] = le32_to_cpu(ih->ring[ring_index + 0]);\n\tdw[1] = le32_to_cpu(ih->ring[ring_index + 1]);\n\tdw[2] = le32_to_cpu(ih->ring[ring_index + 2]);\n\tdw[3] = le32_to_cpu(ih->ring[ring_index + 3]);\n\n\tentry->client_id = AMDGPU_IRQ_CLIENTID_LEGACY;\n\tentry->src_id = dw[0] & 0xff;\n\tentry->src_data[0] = dw[1] & 0xfffffff;\n\tentry->ring_id = dw[2] & 0xff;\n\tentry->vmid = (dw[2] >> 8) & 0xff;\n\tentry->pasid = (dw[2] >> 16) & 0xffff;\n\n\t \n\tih->rptr += 16;\n}\n\n \nstatic void cik_ih_set_rptr(struct amdgpu_device *adev,\n\t\t\t    struct amdgpu_ih_ring *ih)\n{\n\tWREG32(mmIH_RB_RPTR, ih->rptr);\n}\n\nstatic int cik_ih_early_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tint ret;\n\n\tret = amdgpu_irq_add_domain(adev);\n\tif (ret)\n\t\treturn ret;\n\n\tcik_ih_set_interrupt_funcs(adev);\n\n\treturn 0;\n}\n\nstatic int cik_ih_sw_init(void *handle)\n{\n\tint r;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tr = amdgpu_ih_ring_init(adev, &adev->irq.ih, 64 * 1024, false);\n\tif (r)\n\t\treturn r;\n\n\tr = amdgpu_irq_init(adev);\n\n\treturn r;\n}\n\nstatic int cik_ih_sw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tamdgpu_irq_fini_sw(adev);\n\tamdgpu_irq_remove_domain(adev);\n\n\treturn 0;\n}\n\nstatic int cik_ih_hw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn cik_ih_irq_init(adev);\n}\n\nstatic int cik_ih_hw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tcik_ih_irq_disable(adev);\n\n\treturn 0;\n}\n\nstatic int cik_ih_suspend(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn cik_ih_hw_fini(adev);\n}\n\nstatic int cik_ih_resume(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn cik_ih_hw_init(adev);\n}\n\nstatic bool cik_ih_is_idle(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tu32 tmp = RREG32(mmSRBM_STATUS);\n\n\tif (tmp & SRBM_STATUS__IH_BUSY_MASK)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int cik_ih_wait_for_idle(void *handle)\n{\n\tunsigned i;\n\tu32 tmp;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tfor (i = 0; i < adev->usec_timeout; i++) {\n\t\t \n\t\ttmp = RREG32(mmSRBM_STATUS) & SRBM_STATUS__IH_BUSY_MASK;\n\t\tif (!tmp)\n\t\t\treturn 0;\n\t\tudelay(1);\n\t}\n\treturn -ETIMEDOUT;\n}\n\nstatic int cik_ih_soft_reset(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tu32 srbm_soft_reset = 0;\n\tu32 tmp = RREG32(mmSRBM_STATUS);\n\n\tif (tmp & SRBM_STATUS__IH_BUSY_MASK)\n\t\tsrbm_soft_reset |= SRBM_SOFT_RESET__SOFT_RESET_IH_MASK;\n\n\tif (srbm_soft_reset) {\n\t\ttmp = RREG32(mmSRBM_SOFT_RESET);\n\t\ttmp |= srbm_soft_reset;\n\t\tdev_info(adev->dev, \"SRBM_SOFT_RESET=0x%08X\\n\", tmp);\n\t\tWREG32(mmSRBM_SOFT_RESET, tmp);\n\t\ttmp = RREG32(mmSRBM_SOFT_RESET);\n\n\t\tudelay(50);\n\n\t\ttmp &= ~srbm_soft_reset;\n\t\tWREG32(mmSRBM_SOFT_RESET, tmp);\n\t\ttmp = RREG32(mmSRBM_SOFT_RESET);\n\n\t\t \n\t\tudelay(50);\n\t}\n\n\treturn 0;\n}\n\nstatic int cik_ih_set_clockgating_state(void *handle,\n\t\t\t\t\t  enum amd_clockgating_state state)\n{\n\treturn 0;\n}\n\nstatic int cik_ih_set_powergating_state(void *handle,\n\t\t\t\t\t  enum amd_powergating_state state)\n{\n\treturn 0;\n}\n\nstatic const struct amd_ip_funcs cik_ih_ip_funcs = {\n\t.name = \"cik_ih\",\n\t.early_init = cik_ih_early_init,\n\t.late_init = NULL,\n\t.sw_init = cik_ih_sw_init,\n\t.sw_fini = cik_ih_sw_fini,\n\t.hw_init = cik_ih_hw_init,\n\t.hw_fini = cik_ih_hw_fini,\n\t.suspend = cik_ih_suspend,\n\t.resume = cik_ih_resume,\n\t.is_idle = cik_ih_is_idle,\n\t.wait_for_idle = cik_ih_wait_for_idle,\n\t.soft_reset = cik_ih_soft_reset,\n\t.set_clockgating_state = cik_ih_set_clockgating_state,\n\t.set_powergating_state = cik_ih_set_powergating_state,\n};\n\nstatic const struct amdgpu_ih_funcs cik_ih_funcs = {\n\t.get_wptr = cik_ih_get_wptr,\n\t.decode_iv = cik_ih_decode_iv,\n\t.set_rptr = cik_ih_set_rptr\n};\n\nstatic void cik_ih_set_interrupt_funcs(struct amdgpu_device *adev)\n{\n\tadev->irq.ih_funcs = &cik_ih_funcs;\n}\n\nconst struct amdgpu_ip_block_version cik_ih_ip_block = {\n\t.type = AMD_IP_BLOCK_TYPE_IH,\n\t.major = 2,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &cik_ih_ip_funcs,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}