{
  "module_name": "amdgpu_ih.c",
  "hash_id": "51bcf486d290f187999a688b86d2208d4e8f23fef51a98816a1bcc9844b30534",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_ih.c",
  "human_readable_source": " \n\n#include <linux/dma-mapping.h>\n\n#include \"amdgpu.h\"\n#include \"amdgpu_ih.h\"\n\n \nint amdgpu_ih_ring_init(struct amdgpu_device *adev, struct amdgpu_ih_ring *ih,\n\t\t\tunsigned ring_size, bool use_bus_addr)\n{\n\tu32 rb_bufsz;\n\tint r;\n\n\t \n\trb_bufsz = order_base_2(ring_size / 4);\n\tring_size = (1 << rb_bufsz) * 4;\n\tih->ring_size = ring_size;\n\tih->ptr_mask = ih->ring_size - 1;\n\tih->rptr = 0;\n\tih->use_bus_addr = use_bus_addr;\n\n\tif (use_bus_addr) {\n\t\tdma_addr_t dma_addr;\n\n\t\tif (ih->ring)\n\t\t\treturn 0;\n\n\t\t \n\t\tih->ring = dma_alloc_coherent(adev->dev, ih->ring_size + 8,\n\t\t\t\t\t      &dma_addr, GFP_KERNEL);\n\t\tif (ih->ring == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tih->gpu_addr = dma_addr;\n\t\tih->wptr_addr = dma_addr + ih->ring_size;\n\t\tih->wptr_cpu = &ih->ring[ih->ring_size / 4];\n\t\tih->rptr_addr = dma_addr + ih->ring_size + 4;\n\t\tih->rptr_cpu = &ih->ring[(ih->ring_size / 4) + 1];\n\t} else {\n\t\tunsigned wptr_offs, rptr_offs;\n\n\t\tr = amdgpu_device_wb_get(adev, &wptr_offs);\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tr = amdgpu_device_wb_get(adev, &rptr_offs);\n\t\tif (r) {\n\t\t\tamdgpu_device_wb_free(adev, wptr_offs);\n\t\t\treturn r;\n\t\t}\n\n\t\tr = amdgpu_bo_create_kernel(adev, ih->ring_size, PAGE_SIZE,\n\t\t\t\t\t    AMDGPU_GEM_DOMAIN_GTT,\n\t\t\t\t\t    &ih->ring_obj, &ih->gpu_addr,\n\t\t\t\t\t    (void **)&ih->ring);\n\t\tif (r) {\n\t\t\tamdgpu_device_wb_free(adev, rptr_offs);\n\t\t\tamdgpu_device_wb_free(adev, wptr_offs);\n\t\t\treturn r;\n\t\t}\n\n\t\tih->wptr_addr = adev->wb.gpu_addr + wptr_offs * 4;\n\t\tih->wptr_cpu = &adev->wb.wb[wptr_offs];\n\t\tih->rptr_addr = adev->wb.gpu_addr + rptr_offs * 4;\n\t\tih->rptr_cpu = &adev->wb.wb[rptr_offs];\n\t}\n\n\tinit_waitqueue_head(&ih->wait_process);\n\treturn 0;\n}\n\n \nvoid amdgpu_ih_ring_fini(struct amdgpu_device *adev, struct amdgpu_ih_ring *ih)\n{\n\n\tif (!ih->ring)\n\t\treturn;\n\n\tif (ih->use_bus_addr) {\n\n\t\t \n\t\tdma_free_coherent(adev->dev, ih->ring_size + 8,\n\t\t\t\t  (void *)ih->ring, ih->gpu_addr);\n\t\tih->ring = NULL;\n\t} else {\n\t\tamdgpu_bo_free_kernel(&ih->ring_obj, &ih->gpu_addr,\n\t\t\t\t      (void **)&ih->ring);\n\t\tamdgpu_device_wb_free(adev, (ih->wptr_addr - ih->gpu_addr) / 4);\n\t\tamdgpu_device_wb_free(adev, (ih->rptr_addr - ih->gpu_addr) / 4);\n\t}\n}\n\n \nvoid amdgpu_ih_ring_write(struct amdgpu_device *adev, struct amdgpu_ih_ring *ih,\n\t\t\t  const uint32_t *iv, unsigned int num_dw)\n{\n\tuint32_t wptr = le32_to_cpu(*ih->wptr_cpu) >> 2;\n\tunsigned int i;\n\n\tfor (i = 0; i < num_dw; ++i)\n\t        ih->ring[wptr++] = cpu_to_le32(iv[i]);\n\n\twptr <<= 2;\n\twptr &= ih->ptr_mask;\n\n\t \n\tif (wptr != READ_ONCE(ih->rptr)) {\n\t\twmb();\n\t\tWRITE_ONCE(*ih->wptr_cpu, cpu_to_le32(wptr));\n\t} else if (adev->irq.retry_cam_enabled) {\n\t\tdev_warn_once(adev->dev, \"IH soft ring buffer overflow 0x%X, 0x%X\\n\",\n\t\t\t      wptr, ih->rptr);\n\t}\n}\n\n \nint amdgpu_ih_wait_on_checkpoint_process_ts(struct amdgpu_device *adev,\n\t\t\t\t\tstruct amdgpu_ih_ring *ih)\n{\n\tuint32_t checkpoint_wptr;\n\tuint64_t checkpoint_ts;\n\tlong timeout = HZ;\n\n\tif (!ih->enabled || adev->shutdown)\n\t\treturn -ENODEV;\n\n\tcheckpoint_wptr = amdgpu_ih_get_wptr(adev, ih);\n\t \n\trmb();\n\tcheckpoint_ts = amdgpu_ih_decode_iv_ts(adev, ih, checkpoint_wptr, -1);\n\n\treturn wait_event_interruptible_timeout(ih->wait_process,\n\t\t    amdgpu_ih_ts_after(checkpoint_ts, ih->processed_timestamp) ||\n\t\t    ih->rptr == amdgpu_ih_get_wptr(adev, ih), timeout);\n}\n\n \nint amdgpu_ih_process(struct amdgpu_device *adev, struct amdgpu_ih_ring *ih)\n{\n\tunsigned int count;\n\tu32 wptr;\n\n\tif (!ih->enabled || adev->shutdown)\n\t\treturn IRQ_NONE;\n\n\twptr = amdgpu_ih_get_wptr(adev, ih);\n\nrestart_ih:\n\tcount  = AMDGPU_IH_MAX_NUM_IVS;\n\tDRM_DEBUG(\"%s: rptr %d, wptr %d\\n\", __func__, ih->rptr, wptr);\n\n\t \n\trmb();\n\n\twhile (ih->rptr != wptr && --count) {\n\t\tamdgpu_irq_dispatch(adev, ih);\n\t\tih->rptr &= ih->ptr_mask;\n\t}\n\n\tamdgpu_ih_set_rptr(adev, ih);\n\twake_up_all(&ih->wait_process);\n\n\t \n\twptr = amdgpu_ih_get_wptr(adev, ih);\n\tif (wptr != ih->rptr)\n\t\tgoto restart_ih;\n\n\treturn IRQ_HANDLED;\n}\n\n \nvoid amdgpu_ih_decode_iv_helper(struct amdgpu_device *adev,\n\t\t\t\tstruct amdgpu_ih_ring *ih,\n\t\t\t\tstruct amdgpu_iv_entry *entry)\n{\n\t \n\tu32 ring_index = ih->rptr >> 2;\n\tuint32_t dw[8];\n\n\tdw[0] = le32_to_cpu(ih->ring[ring_index + 0]);\n\tdw[1] = le32_to_cpu(ih->ring[ring_index + 1]);\n\tdw[2] = le32_to_cpu(ih->ring[ring_index + 2]);\n\tdw[3] = le32_to_cpu(ih->ring[ring_index + 3]);\n\tdw[4] = le32_to_cpu(ih->ring[ring_index + 4]);\n\tdw[5] = le32_to_cpu(ih->ring[ring_index + 5]);\n\tdw[6] = le32_to_cpu(ih->ring[ring_index + 6]);\n\tdw[7] = le32_to_cpu(ih->ring[ring_index + 7]);\n\n\tentry->client_id = dw[0] & 0xff;\n\tentry->src_id = (dw[0] >> 8) & 0xff;\n\tentry->ring_id = (dw[0] >> 16) & 0xff;\n\tentry->vmid = (dw[0] >> 24) & 0xf;\n\tentry->vmid_src = (dw[0] >> 31);\n\tentry->timestamp = dw[1] | ((u64)(dw[2] & 0xffff) << 32);\n\tentry->timestamp_src = dw[2] >> 31;\n\tentry->pasid = dw[3] & 0xffff;\n\tentry->node_id = (dw[3] >> 16) & 0xff;\n\tentry->src_data[0] = dw[4];\n\tentry->src_data[1] = dw[5];\n\tentry->src_data[2] = dw[6];\n\tentry->src_data[3] = dw[7];\n\n\t \n\tih->rptr += 32;\n}\n\nuint64_t amdgpu_ih_decode_iv_ts_helper(struct amdgpu_ih_ring *ih, u32 rptr,\n\t\t\t\t       signed int offset)\n{\n\tuint32_t iv_size = 32;\n\tuint32_t ring_index;\n\tuint32_t dw1, dw2;\n\n\trptr += iv_size * offset;\n\tring_index = (rptr & ih->ptr_mask) >> 2;\n\n\tdw1 = le32_to_cpu(ih->ring[ring_index + 1]);\n\tdw2 = le32_to_cpu(ih->ring[ring_index + 2]);\n\treturn dw1 | ((u64)(dw2 & 0xffff) << 32);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}