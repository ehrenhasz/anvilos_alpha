{
  "module_name": "amdgpu_vram_mgr.c",
  "hash_id": "bffb34c78137f660a969c3f941b0ccd4b172e5d7373d76ae52062fe23a95a24a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_vram_mgr.c",
  "human_readable_source": " \n\n#include <linux/dma-mapping.h>\n#include <drm/ttm/ttm_range_manager.h>\n\n#include \"amdgpu.h\"\n#include \"amdgpu_vm.h\"\n#include \"amdgpu_res_cursor.h\"\n#include \"amdgpu_atomfirmware.h\"\n#include \"atom.h\"\n\nstruct amdgpu_vram_reservation {\n\tu64 start;\n\tu64 size;\n\tstruct list_head allocated;\n\tstruct list_head blocks;\n};\n\nstatic inline struct amdgpu_vram_mgr *\nto_vram_mgr(struct ttm_resource_manager *man)\n{\n\treturn container_of(man, struct amdgpu_vram_mgr, manager);\n}\n\nstatic inline struct amdgpu_device *\nto_amdgpu_device(struct amdgpu_vram_mgr *mgr)\n{\n\treturn container_of(mgr, struct amdgpu_device, mman.vram_mgr);\n}\n\nstatic inline struct drm_buddy_block *\namdgpu_vram_mgr_first_block(struct list_head *list)\n{\n\treturn list_first_entry_or_null(list, struct drm_buddy_block, link);\n}\n\nstatic inline bool amdgpu_is_vram_mgr_blocks_contiguous(struct list_head *head)\n{\n\tstruct drm_buddy_block *block;\n\tu64 start, size;\n\n\tblock = amdgpu_vram_mgr_first_block(head);\n\tif (!block)\n\t\treturn false;\n\n\twhile (head != block->link.next) {\n\t\tstart = amdgpu_vram_mgr_block_start(block);\n\t\tsize = amdgpu_vram_mgr_block_size(block);\n\n\t\tblock = list_entry(block->link.next, struct drm_buddy_block, link);\n\t\tif (start + size != amdgpu_vram_mgr_block_start(block))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n\n\n \nstatic ssize_t amdgpu_mem_info_vram_total_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\treturn sysfs_emit(buf, \"%llu\\n\", adev->gmc.real_vram_size);\n}\n\n \nstatic ssize_t amdgpu_mem_info_vis_vram_total_show(struct device *dev,\n\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\treturn sysfs_emit(buf, \"%llu\\n\", adev->gmc.visible_vram_size);\n}\n\n \nstatic ssize_t amdgpu_mem_info_vram_used_show(struct device *dev,\n\t\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t\t      char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tstruct ttm_resource_manager *man = &adev->mman.vram_mgr.manager;\n\n\treturn sysfs_emit(buf, \"%llu\\n\", ttm_resource_manager_usage(man));\n}\n\n \nstatic ssize_t amdgpu_mem_info_vis_vram_used_show(struct device *dev,\n\t\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t\t  char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\treturn sysfs_emit(buf, \"%llu\\n\",\n\t\t\t  amdgpu_vram_mgr_vis_usage(&adev->mman.vram_mgr));\n}\n\n \nstatic ssize_t amdgpu_mem_info_vram_vendor(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\tswitch (adev->gmc.vram_vendor) {\n\tcase SAMSUNG:\n\t\treturn sysfs_emit(buf, \"samsung\\n\");\n\tcase INFINEON:\n\t\treturn sysfs_emit(buf, \"infineon\\n\");\n\tcase ELPIDA:\n\t\treturn sysfs_emit(buf, \"elpida\\n\");\n\tcase ETRON:\n\t\treturn sysfs_emit(buf, \"etron\\n\");\n\tcase NANYA:\n\t\treturn sysfs_emit(buf, \"nanya\\n\");\n\tcase HYNIX:\n\t\treturn sysfs_emit(buf, \"hynix\\n\");\n\tcase MOSEL:\n\t\treturn sysfs_emit(buf, \"mosel\\n\");\n\tcase WINBOND:\n\t\treturn sysfs_emit(buf, \"winbond\\n\");\n\tcase ESMT:\n\t\treturn sysfs_emit(buf, \"esmt\\n\");\n\tcase MICRON:\n\t\treturn sysfs_emit(buf, \"micron\\n\");\n\tdefault:\n\t\treturn sysfs_emit(buf, \"unknown\\n\");\n\t}\n}\n\nstatic DEVICE_ATTR(mem_info_vram_total, S_IRUGO,\n\t\t   amdgpu_mem_info_vram_total_show, NULL);\nstatic DEVICE_ATTR(mem_info_vis_vram_total, S_IRUGO,\n\t\t   amdgpu_mem_info_vis_vram_total_show,NULL);\nstatic DEVICE_ATTR(mem_info_vram_used, S_IRUGO,\n\t\t   amdgpu_mem_info_vram_used_show, NULL);\nstatic DEVICE_ATTR(mem_info_vis_vram_used, S_IRUGO,\n\t\t   amdgpu_mem_info_vis_vram_used_show, NULL);\nstatic DEVICE_ATTR(mem_info_vram_vendor, S_IRUGO,\n\t\t   amdgpu_mem_info_vram_vendor, NULL);\n\nstatic struct attribute *amdgpu_vram_mgr_attributes[] = {\n\t&dev_attr_mem_info_vram_total.attr,\n\t&dev_attr_mem_info_vis_vram_total.attr,\n\t&dev_attr_mem_info_vram_used.attr,\n\t&dev_attr_mem_info_vis_vram_used.attr,\n\t&dev_attr_mem_info_vram_vendor.attr,\n\tNULL\n};\n\nconst struct attribute_group amdgpu_vram_mgr_attr_group = {\n\t.attrs = amdgpu_vram_mgr_attributes\n};\n\n \nstatic u64 amdgpu_vram_mgr_vis_size(struct amdgpu_device *adev,\n\t\t\t\t    struct drm_buddy_block *block)\n{\n\tu64 start = amdgpu_vram_mgr_block_start(block);\n\tu64 end = start + amdgpu_vram_mgr_block_size(block);\n\n\tif (start >= adev->gmc.visible_vram_size)\n\t\treturn 0;\n\n\treturn (end > adev->gmc.visible_vram_size ?\n\t\tadev->gmc.visible_vram_size : end) - start;\n}\n\n \nu64 amdgpu_vram_mgr_bo_visible_size(struct amdgpu_bo *bo)\n{\n\tstruct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);\n\tstruct ttm_resource *res = bo->tbo.resource;\n\tstruct amdgpu_vram_mgr_resource *vres = to_amdgpu_vram_mgr_resource(res);\n\tstruct drm_buddy_block *block;\n\tu64 usage = 0;\n\n\tif (amdgpu_gmc_vram_full_visible(&adev->gmc))\n\t\treturn amdgpu_bo_size(bo);\n\n\tif (res->start >= adev->gmc.visible_vram_size >> PAGE_SHIFT)\n\t\treturn 0;\n\n\tlist_for_each_entry(block, &vres->blocks, link)\n\t\tusage += amdgpu_vram_mgr_vis_size(adev, block);\n\n\treturn usage;\n}\n\n \nstatic void amdgpu_vram_mgr_do_reserve(struct ttm_resource_manager *man)\n{\n\tstruct amdgpu_vram_mgr *mgr = to_vram_mgr(man);\n\tstruct amdgpu_device *adev = to_amdgpu_device(mgr);\n\tstruct drm_buddy *mm = &mgr->mm;\n\tstruct amdgpu_vram_reservation *rsv, *temp;\n\tstruct drm_buddy_block *block;\n\tuint64_t vis_usage;\n\n\tlist_for_each_entry_safe(rsv, temp, &mgr->reservations_pending, blocks) {\n\t\tif (drm_buddy_alloc_blocks(mm, rsv->start, rsv->start + rsv->size,\n\t\t\t\t\t   rsv->size, mm->chunk_size, &rsv->allocated,\n\t\t\t\t\t   DRM_BUDDY_RANGE_ALLOCATION))\n\t\t\tcontinue;\n\n\t\tblock = amdgpu_vram_mgr_first_block(&rsv->allocated);\n\t\tif (!block)\n\t\t\tcontinue;\n\n\t\tdev_dbg(adev->dev, \"Reservation 0x%llx - %lld, Succeeded\\n\",\n\t\t\trsv->start, rsv->size);\n\n\t\tvis_usage = amdgpu_vram_mgr_vis_size(adev, block);\n\t\tatomic64_add(vis_usage, &mgr->vis_usage);\n\t\tspin_lock(&man->bdev->lru_lock);\n\t\tman->usage += rsv->size;\n\t\tspin_unlock(&man->bdev->lru_lock);\n\t\tlist_move(&rsv->blocks, &mgr->reserved_pages);\n\t}\n}\n\n \nint amdgpu_vram_mgr_reserve_range(struct amdgpu_vram_mgr *mgr,\n\t\t\t\t  uint64_t start, uint64_t size)\n{\n\tstruct amdgpu_vram_reservation *rsv;\n\n\trsv = kzalloc(sizeof(*rsv), GFP_KERNEL);\n\tif (!rsv)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&rsv->allocated);\n\tINIT_LIST_HEAD(&rsv->blocks);\n\n\trsv->start = start;\n\trsv->size = size;\n\n\tmutex_lock(&mgr->lock);\n\tlist_add_tail(&rsv->blocks, &mgr->reservations_pending);\n\tamdgpu_vram_mgr_do_reserve(&mgr->manager);\n\tmutex_unlock(&mgr->lock);\n\n\treturn 0;\n}\n\n \nint amdgpu_vram_mgr_query_page_status(struct amdgpu_vram_mgr *mgr,\n\t\t\t\t      uint64_t start)\n{\n\tstruct amdgpu_vram_reservation *rsv;\n\tint ret;\n\n\tmutex_lock(&mgr->lock);\n\n\tlist_for_each_entry(rsv, &mgr->reservations_pending, blocks) {\n\t\tif (rsv->start <= start &&\n\t\t    (start < (rsv->start + rsv->size))) {\n\t\t\tret = -EBUSY;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tlist_for_each_entry(rsv, &mgr->reserved_pages, blocks) {\n\t\tif (rsv->start <= start &&\n\t\t    (start < (rsv->start + rsv->size))) {\n\t\t\tret = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = -ENOENT;\nout:\n\tmutex_unlock(&mgr->lock);\n\treturn ret;\n}\n\nstatic void amdgpu_dummy_vram_mgr_debug(struct ttm_resource_manager *man,\n\t\t\t\t  struct drm_printer *printer)\n{\n\tDRM_DEBUG_DRIVER(\"Dummy vram mgr debug\\n\");\n}\n\nstatic bool amdgpu_dummy_vram_mgr_compatible(struct ttm_resource_manager *man,\n\t\t\t\t       struct ttm_resource *res,\n\t\t\t\t       const struct ttm_place *place,\n\t\t\t\t       size_t size)\n{\n\tDRM_DEBUG_DRIVER(\"Dummy vram mgr compatible\\n\");\n\treturn false;\n}\n\nstatic bool amdgpu_dummy_vram_mgr_intersects(struct ttm_resource_manager *man,\n\t\t\t\t       struct ttm_resource *res,\n\t\t\t\t       const struct ttm_place *place,\n\t\t\t\t       size_t size)\n{\n\tDRM_DEBUG_DRIVER(\"Dummy vram mgr intersects\\n\");\n\treturn true;\n}\n\nstatic void amdgpu_dummy_vram_mgr_del(struct ttm_resource_manager *man,\n\t\t\t\tstruct ttm_resource *res)\n{\n\tDRM_DEBUG_DRIVER(\"Dummy vram mgr deleted\\n\");\n}\n\nstatic int amdgpu_dummy_vram_mgr_new(struct ttm_resource_manager *man,\n\t\t\t       struct ttm_buffer_object *tbo,\n\t\t\t       const struct ttm_place *place,\n\t\t\t       struct ttm_resource **res)\n{\n\tDRM_DEBUG_DRIVER(\"Dummy vram mgr new\\n\");\n\treturn -ENOSPC;\n}\n\n \nstatic int amdgpu_vram_mgr_new(struct ttm_resource_manager *man,\n\t\t\t       struct ttm_buffer_object *tbo,\n\t\t\t       const struct ttm_place *place,\n\t\t\t       struct ttm_resource **res)\n{\n\tu64 vis_usage = 0, max_bytes, cur_size, min_block_size;\n\tstruct amdgpu_vram_mgr *mgr = to_vram_mgr(man);\n\tstruct amdgpu_device *adev = to_amdgpu_device(mgr);\n\tstruct amdgpu_vram_mgr_resource *vres;\n\tu64 size, remaining_size, lpfn, fpfn;\n\tstruct drm_buddy *mm = &mgr->mm;\n\tstruct drm_buddy_block *block;\n\tunsigned long pages_per_block;\n\tint r;\n\n\tlpfn = (u64)place->lpfn << PAGE_SHIFT;\n\tif (!lpfn)\n\t\tlpfn = man->size;\n\n\tfpfn = (u64)place->fpfn << PAGE_SHIFT;\n\n\tmax_bytes = adev->gmc.mc_vram_size;\n\tif (tbo->type != ttm_bo_type_kernel)\n\t\tmax_bytes -= AMDGPU_VM_RESERVED_VRAM;\n\n\tif (place->flags & TTM_PL_FLAG_CONTIGUOUS) {\n\t\tpages_per_block = ~0ul;\n\t} else {\n#ifdef CONFIG_TRANSPARENT_HUGEPAGE\n\t\tpages_per_block = HPAGE_PMD_NR;\n#else\n\t\t \n\t\tpages_per_block = 2UL << (20UL - PAGE_SHIFT);\n#endif\n\t\tpages_per_block = max_t(uint32_t, pages_per_block,\n\t\t\t\t\ttbo->page_alignment);\n\t}\n\n\tvres = kzalloc(sizeof(*vres), GFP_KERNEL);\n\tif (!vres)\n\t\treturn -ENOMEM;\n\n\tttm_resource_init(tbo, place, &vres->base);\n\n\t \n\tif (ttm_resource_manager_usage(man) > max_bytes) {\n\t\tr = -ENOSPC;\n\t\tgoto error_fini;\n\t}\n\n\tINIT_LIST_HEAD(&vres->blocks);\n\n\tif (place->flags & TTM_PL_FLAG_TOPDOWN)\n\t\tvres->flags |= DRM_BUDDY_TOPDOWN_ALLOCATION;\n\n\tif (fpfn || lpfn != mgr->mm.size)\n\t\t \n\t\tvres->flags |= DRM_BUDDY_RANGE_ALLOCATION;\n\n\tremaining_size = (u64)vres->base.size;\n\n\tmutex_lock(&mgr->lock);\n\twhile (remaining_size) {\n\t\tif (tbo->page_alignment)\n\t\t\tmin_block_size = (u64)tbo->page_alignment << PAGE_SHIFT;\n\t\telse\n\t\t\tmin_block_size = mgr->default_page_size;\n\n\t\tBUG_ON(min_block_size < mm->chunk_size);\n\n\t\t \n\t\tsize = min(remaining_size, 2ULL << 30);\n\n\t\tif ((size >= (u64)pages_per_block << PAGE_SHIFT) &&\n\t\t\t\t!(size & (((u64)pages_per_block << PAGE_SHIFT) - 1)))\n\t\t\tmin_block_size = (u64)pages_per_block << PAGE_SHIFT;\n\n\t\tcur_size = size;\n\n\t\tif (fpfn + size != (u64)place->lpfn << PAGE_SHIFT) {\n\t\t\t \n\t\t\tif (place->flags & TTM_PL_FLAG_CONTIGUOUS) {\n\t\t\t\tsize = roundup_pow_of_two(size);\n\t\t\t\tmin_block_size = size;\n\t\t\t \n\t\t\t} else if (!IS_ALIGNED(size, min_block_size)) {\n\t\t\t\tsize = round_up(size, min_block_size);\n\t\t\t}\n\t\t}\n\n\t\tr = drm_buddy_alloc_blocks(mm, fpfn,\n\t\t\t\t\t   lpfn,\n\t\t\t\t\t   size,\n\t\t\t\t\t   min_block_size,\n\t\t\t\t\t   &vres->blocks,\n\t\t\t\t\t   vres->flags);\n\t\tif (unlikely(r))\n\t\t\tgoto error_free_blocks;\n\n\t\tif (size > remaining_size)\n\t\t\tremaining_size = 0;\n\t\telse\n\t\t\tremaining_size -= size;\n\t}\n\tmutex_unlock(&mgr->lock);\n\n\tif (cur_size != size) {\n\t\tstruct drm_buddy_block *block;\n\t\tstruct list_head *trim_list;\n\t\tu64 original_size;\n\t\tLIST_HEAD(temp);\n\n\t\ttrim_list = &vres->blocks;\n\t\toriginal_size = (u64)vres->base.size;\n\n\t\t \n\t\tif (!list_is_singular(&vres->blocks)) {\n\t\t\tblock = list_last_entry(&vres->blocks, typeof(*block), link);\n\t\t\tlist_move_tail(&block->link, &temp);\n\t\t\ttrim_list = &temp;\n\t\t\t \n\t\t\toriginal_size = amdgpu_vram_mgr_block_size(block) - (size - cur_size);\n\t\t}\n\n\t\tmutex_lock(&mgr->lock);\n\t\tdrm_buddy_block_trim(mm,\n\t\t\t\t     original_size,\n\t\t\t\t     trim_list);\n\t\tmutex_unlock(&mgr->lock);\n\n\t\tif (!list_empty(&temp))\n\t\t\tlist_splice_tail(trim_list, &vres->blocks);\n\t}\n\n\tvres->base.start = 0;\n\tlist_for_each_entry(block, &vres->blocks, link) {\n\t\tunsigned long start;\n\n\t\tstart = amdgpu_vram_mgr_block_start(block) +\n\t\t\tamdgpu_vram_mgr_block_size(block);\n\t\tstart >>= PAGE_SHIFT;\n\n\t\tif (start > PFN_UP(vres->base.size))\n\t\t\tstart -= PFN_UP(vres->base.size);\n\t\telse\n\t\t\tstart = 0;\n\t\tvres->base.start = max(vres->base.start, start);\n\n\t\tvis_usage += amdgpu_vram_mgr_vis_size(adev, block);\n\t}\n\n\tif (amdgpu_is_vram_mgr_blocks_contiguous(&vres->blocks))\n\t\tvres->base.placement |= TTM_PL_FLAG_CONTIGUOUS;\n\n\tif (adev->gmc.xgmi.connected_to_cpu)\n\t\tvres->base.bus.caching = ttm_cached;\n\telse\n\t\tvres->base.bus.caching = ttm_write_combined;\n\n\tatomic64_add(vis_usage, &mgr->vis_usage);\n\t*res = &vres->base;\n\treturn 0;\n\nerror_free_blocks:\n\tdrm_buddy_free_list(mm, &vres->blocks);\n\tmutex_unlock(&mgr->lock);\nerror_fini:\n\tttm_resource_fini(man, &vres->base);\n\tkfree(vres);\n\n\treturn r;\n}\n\n \nstatic void amdgpu_vram_mgr_del(struct ttm_resource_manager *man,\n\t\t\t\tstruct ttm_resource *res)\n{\n\tstruct amdgpu_vram_mgr_resource *vres = to_amdgpu_vram_mgr_resource(res);\n\tstruct amdgpu_vram_mgr *mgr = to_vram_mgr(man);\n\tstruct amdgpu_device *adev = to_amdgpu_device(mgr);\n\tstruct drm_buddy *mm = &mgr->mm;\n\tstruct drm_buddy_block *block;\n\tuint64_t vis_usage = 0;\n\n\tmutex_lock(&mgr->lock);\n\tlist_for_each_entry(block, &vres->blocks, link)\n\t\tvis_usage += amdgpu_vram_mgr_vis_size(adev, block);\n\n\tamdgpu_vram_mgr_do_reserve(man);\n\n\tdrm_buddy_free_list(mm, &vres->blocks);\n\tmutex_unlock(&mgr->lock);\n\n\tatomic64_sub(vis_usage, &mgr->vis_usage);\n\n\tttm_resource_fini(man, res);\n\tkfree(vres);\n}\n\n \nint amdgpu_vram_mgr_alloc_sgt(struct amdgpu_device *adev,\n\t\t\t      struct ttm_resource *res,\n\t\t\t      u64 offset, u64 length,\n\t\t\t      struct device *dev,\n\t\t\t      enum dma_data_direction dir,\n\t\t\t      struct sg_table **sgt)\n{\n\tstruct amdgpu_res_cursor cursor;\n\tstruct scatterlist *sg;\n\tint num_entries = 0;\n\tint i, r;\n\n\t*sgt = kmalloc(sizeof(**sgt), GFP_KERNEL);\n\tif (!*sgt)\n\t\treturn -ENOMEM;\n\n\t \n\tamdgpu_res_first(res, offset, length, &cursor);\n\twhile (cursor.remaining) {\n\t\tnum_entries++;\n\t\tamdgpu_res_next(&cursor, cursor.size);\n\t}\n\n\tr = sg_alloc_table(*sgt, num_entries, GFP_KERNEL);\n\tif (r)\n\t\tgoto error_free;\n\n\t \n\tfor_each_sgtable_sg((*sgt), sg, i)\n\t\tsg->length = 0;\n\n\t \n\tamdgpu_res_first(res, offset, length, &cursor);\n\tfor_each_sgtable_sg((*sgt), sg, i) {\n\t\tphys_addr_t phys = cursor.start + adev->gmc.aper_base;\n\t\tsize_t size = cursor.size;\n\t\tdma_addr_t addr;\n\n\t\taddr = dma_map_resource(dev, phys, size, dir,\n\t\t\t\t\tDMA_ATTR_SKIP_CPU_SYNC);\n\t\tr = dma_mapping_error(dev, addr);\n\t\tif (r)\n\t\t\tgoto error_unmap;\n\n\t\tsg_set_page(sg, NULL, size, 0);\n\t\tsg_dma_address(sg) = addr;\n\t\tsg_dma_len(sg) = size;\n\n\t\tamdgpu_res_next(&cursor, cursor.size);\n\t}\n\n\treturn 0;\n\nerror_unmap:\n\tfor_each_sgtable_sg((*sgt), sg, i) {\n\t\tif (!sg->length)\n\t\t\tcontinue;\n\n\t\tdma_unmap_resource(dev, sg->dma_address,\n\t\t\t\t   sg->length, dir,\n\t\t\t\t   DMA_ATTR_SKIP_CPU_SYNC);\n\t}\n\tsg_free_table(*sgt);\n\nerror_free:\n\tkfree(*sgt);\n\treturn r;\n}\n\n \nvoid amdgpu_vram_mgr_free_sgt(struct device *dev,\n\t\t\t      enum dma_data_direction dir,\n\t\t\t      struct sg_table *sgt)\n{\n\tstruct scatterlist *sg;\n\tint i;\n\n\tfor_each_sgtable_sg(sgt, sg, i)\n\t\tdma_unmap_resource(dev, sg->dma_address,\n\t\t\t\t   sg->length, dir,\n\t\t\t\t   DMA_ATTR_SKIP_CPU_SYNC);\n\tsg_free_table(sgt);\n\tkfree(sgt);\n}\n\n \nuint64_t amdgpu_vram_mgr_vis_usage(struct amdgpu_vram_mgr *mgr)\n{\n\treturn atomic64_read(&mgr->vis_usage);\n}\n\n \nstatic bool amdgpu_vram_mgr_intersects(struct ttm_resource_manager *man,\n\t\t\t\t       struct ttm_resource *res,\n\t\t\t\t       const struct ttm_place *place,\n\t\t\t\t       size_t size)\n{\n\tstruct amdgpu_vram_mgr_resource *mgr = to_amdgpu_vram_mgr_resource(res);\n\tstruct drm_buddy_block *block;\n\n\t \n\tlist_for_each_entry(block, &mgr->blocks, link) {\n\t\tunsigned long fpfn =\n\t\t\tamdgpu_vram_mgr_block_start(block) >> PAGE_SHIFT;\n\t\tunsigned long lpfn = fpfn +\n\t\t\t(amdgpu_vram_mgr_block_size(block) >> PAGE_SHIFT);\n\n\t\tif (place->fpfn < lpfn &&\n\t\t    (!place->lpfn || place->lpfn > fpfn))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\n \nstatic bool amdgpu_vram_mgr_compatible(struct ttm_resource_manager *man,\n\t\t\t\t       struct ttm_resource *res,\n\t\t\t\t       const struct ttm_place *place,\n\t\t\t\t       size_t size)\n{\n\tstruct amdgpu_vram_mgr_resource *mgr = to_amdgpu_vram_mgr_resource(res);\n\tstruct drm_buddy_block *block;\n\n\t \n\tlist_for_each_entry(block, &mgr->blocks, link) {\n\t\tunsigned long fpfn =\n\t\t\tamdgpu_vram_mgr_block_start(block) >> PAGE_SHIFT;\n\t\tunsigned long lpfn = fpfn +\n\t\t\t(amdgpu_vram_mgr_block_size(block) >> PAGE_SHIFT);\n\n\t\tif (fpfn < place->fpfn ||\n\t\t    (place->lpfn && lpfn > place->lpfn))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic void amdgpu_vram_mgr_debug(struct ttm_resource_manager *man,\n\t\t\t\t  struct drm_printer *printer)\n{\n\tstruct amdgpu_vram_mgr *mgr = to_vram_mgr(man);\n\tstruct drm_buddy *mm = &mgr->mm;\n\tstruct amdgpu_vram_reservation *rsv;\n\n\tdrm_printf(printer, \"  vis usage:%llu\\n\",\n\t\t   amdgpu_vram_mgr_vis_usage(mgr));\n\n\tmutex_lock(&mgr->lock);\n\tdrm_printf(printer, \"default_page_size: %lluKiB\\n\",\n\t\t   mgr->default_page_size >> 10);\n\n\tdrm_buddy_print(mm, printer);\n\n\tdrm_printf(printer, \"reserved:\\n\");\n\tlist_for_each_entry(rsv, &mgr->reserved_pages, blocks)\n\t\tdrm_printf(printer, \"%#018llx-%#018llx: %llu\\n\",\n\t\t\trsv->start, rsv->start + rsv->size, rsv->size);\n\tmutex_unlock(&mgr->lock);\n}\n\nstatic const struct ttm_resource_manager_func amdgpu_dummy_vram_mgr_func = {\n\t.alloc\t= amdgpu_dummy_vram_mgr_new,\n\t.free\t= amdgpu_dummy_vram_mgr_del,\n\t.intersects = amdgpu_dummy_vram_mgr_intersects,\n\t.compatible = amdgpu_dummy_vram_mgr_compatible,\n\t.debug\t= amdgpu_dummy_vram_mgr_debug\n};\n\nstatic const struct ttm_resource_manager_func amdgpu_vram_mgr_func = {\n\t.alloc\t= amdgpu_vram_mgr_new,\n\t.free\t= amdgpu_vram_mgr_del,\n\t.intersects = amdgpu_vram_mgr_intersects,\n\t.compatible = amdgpu_vram_mgr_compatible,\n\t.debug\t= amdgpu_vram_mgr_debug\n};\n\n \nint amdgpu_vram_mgr_init(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_vram_mgr *mgr = &adev->mman.vram_mgr;\n\tstruct ttm_resource_manager *man = &mgr->manager;\n\tint err;\n\n\tttm_resource_manager_init(man, &adev->mman.bdev,\n\t\t\t\t  adev->gmc.real_vram_size);\n\n\tmutex_init(&mgr->lock);\n\tINIT_LIST_HEAD(&mgr->reservations_pending);\n\tINIT_LIST_HEAD(&mgr->reserved_pages);\n\tmgr->default_page_size = PAGE_SIZE;\n\n\tif (!adev->gmc.is_app_apu) {\n\t\tman->func = &amdgpu_vram_mgr_func;\n\n\t\terr = drm_buddy_init(&mgr->mm, man->size, PAGE_SIZE);\n\t\tif (err)\n\t\t\treturn err;\n\t} else {\n\t\tman->func = &amdgpu_dummy_vram_mgr_func;\n\t\tDRM_INFO(\"Setup dummy vram mgr\\n\");\n\t}\n\n\tttm_set_driver_manager(&adev->mman.bdev, TTM_PL_VRAM, &mgr->manager);\n\tttm_resource_manager_set_used(man, true);\n\treturn 0;\n}\n\n \nvoid amdgpu_vram_mgr_fini(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_vram_mgr *mgr = &adev->mman.vram_mgr;\n\tstruct ttm_resource_manager *man = &mgr->manager;\n\tint ret;\n\tstruct amdgpu_vram_reservation *rsv, *temp;\n\n\tttm_resource_manager_set_used(man, false);\n\n\tret = ttm_resource_manager_evict_all(&adev->mman.bdev, man);\n\tif (ret)\n\t\treturn;\n\n\tmutex_lock(&mgr->lock);\n\tlist_for_each_entry_safe(rsv, temp, &mgr->reservations_pending, blocks)\n\t\tkfree(rsv);\n\n\tlist_for_each_entry_safe(rsv, temp, &mgr->reserved_pages, blocks) {\n\t\tdrm_buddy_free_list(&mgr->mm, &rsv->allocated);\n\t\tkfree(rsv);\n\t}\n\tif (!adev->gmc.is_app_apu)\n\t\tdrm_buddy_fini(&mgr->mm);\n\tmutex_unlock(&mgr->lock);\n\n\tttm_resource_manager_cleanup(man);\n\tttm_set_driver_manager(&adev->mman.bdev, TTM_PL_VRAM, NULL);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}