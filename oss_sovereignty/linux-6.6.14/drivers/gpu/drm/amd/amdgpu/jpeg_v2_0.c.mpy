{
  "module_name": "jpeg_v2_0.c",
  "hash_id": "0e96e3be7df26a0f9208bac8de42413b2793f518ee413ff7072c8a59df1a7baf",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/jpeg_v2_0.c",
  "human_readable_source": " \n\n#include \"amdgpu.h\"\n#include \"amdgpu_jpeg.h\"\n#include \"amdgpu_pm.h\"\n#include \"soc15.h\"\n#include \"soc15d.h\"\n#include \"jpeg_v2_0.h\"\n\n#include \"vcn/vcn_2_0_0_offset.h\"\n#include \"vcn/vcn_2_0_0_sh_mask.h\"\n#include \"ivsrcid/vcn/irqsrcs_vcn_2_0.h\"\n\nstatic void jpeg_v2_0_set_dec_ring_funcs(struct amdgpu_device *adev);\nstatic void jpeg_v2_0_set_irq_funcs(struct amdgpu_device *adev);\nstatic int jpeg_v2_0_set_powergating_state(void *handle,\n\t\t\t\tenum amd_powergating_state state);\n\n \nstatic int jpeg_v2_0_early_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tadev->jpeg.num_jpeg_inst = 1;\n\tadev->jpeg.num_jpeg_rings = 1;\n\n\tjpeg_v2_0_set_dec_ring_funcs(adev);\n\tjpeg_v2_0_set_irq_funcs(adev);\n\n\treturn 0;\n}\n\n \nstatic int jpeg_v2_0_sw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct amdgpu_ring *ring;\n\tint r;\n\n\t \n\tr = amdgpu_irq_add_id(adev, SOC15_IH_CLIENTID_VCN,\n\t\tVCN_2_0__SRCID__JPEG_DECODE, &adev->jpeg.inst->irq);\n\tif (r)\n\t\treturn r;\n\n\tr = amdgpu_jpeg_sw_init(adev);\n\tif (r)\n\t\treturn r;\n\n\tr = amdgpu_jpeg_resume(adev);\n\tif (r)\n\t\treturn r;\n\n\tring = adev->jpeg.inst->ring_dec;\n\tring->use_doorbell = true;\n\tring->doorbell_index = (adev->doorbell_index.vcn.vcn_ring0_1 << 1) + 1;\n\tring->vm_hub = AMDGPU_MMHUB0(0);\n\tsprintf(ring->name, \"jpeg_dec\");\n\tr = amdgpu_ring_init(adev, ring, 512, &adev->jpeg.inst->irq,\n\t\t\t     0, AMDGPU_RING_PRIO_DEFAULT, NULL);\n\tif (r)\n\t\treturn r;\n\n\tadev->jpeg.internal.jpeg_pitch[0] = mmUVD_JPEG_PITCH_INTERNAL_OFFSET;\n\tadev->jpeg.inst->external.jpeg_pitch[0] = SOC15_REG_OFFSET(JPEG, 0, mmUVD_JPEG_PITCH);\n\n\treturn 0;\n}\n\n \nstatic int jpeg_v2_0_sw_fini(void *handle)\n{\n\tint r;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tr = amdgpu_jpeg_suspend(adev);\n\tif (r)\n\t\treturn r;\n\n\tr = amdgpu_jpeg_sw_fini(adev);\n\n\treturn r;\n}\n\n \nstatic int jpeg_v2_0_hw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct amdgpu_ring *ring = adev->jpeg.inst->ring_dec;\n\tint r;\n\n\tadev->nbio.funcs->vcn_doorbell_range(adev, ring->use_doorbell,\n\t\t(adev->doorbell_index.vcn.vcn_ring0_1 << 1), 0);\n\n\tr = amdgpu_ring_test_helper(ring);\n\tif (!r)\n\t\tDRM_INFO(\"JPEG decode initialized successfully.\\n\");\n\n\treturn r;\n}\n\n \nstatic int jpeg_v2_0_hw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tcancel_delayed_work_sync(&adev->vcn.idle_work);\n\n\tif (adev->jpeg.cur_state != AMD_PG_STATE_GATE &&\n\t      RREG32_SOC15(JPEG, 0, mmUVD_JRBC_STATUS))\n\t\tjpeg_v2_0_set_powergating_state(adev, AMD_PG_STATE_GATE);\n\n\treturn 0;\n}\n\n \nstatic int jpeg_v2_0_suspend(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tint r;\n\n\tr = jpeg_v2_0_hw_fini(adev);\n\tif (r)\n\t\treturn r;\n\n\tr = amdgpu_jpeg_suspend(adev);\n\n\treturn r;\n}\n\n \nstatic int jpeg_v2_0_resume(void *handle)\n{\n\tint r;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tr = amdgpu_jpeg_resume(adev);\n\tif (r)\n\t\treturn r;\n\n\tr = jpeg_v2_0_hw_init(adev);\n\n\treturn r;\n}\n\nstatic int jpeg_v2_0_disable_power_gating(struct amdgpu_device *adev)\n{\n\tuint32_t data;\n\tint r = 0;\n\n\tif (adev->pg_flags & AMD_PG_SUPPORT_JPEG) {\n\t\tdata = 1 << UVD_PGFSM_CONFIG__UVDJ_PWR_CONFIG__SHIFT;\n\t\tWREG32(SOC15_REG_OFFSET(JPEG, 0, mmUVD_PGFSM_CONFIG), data);\n\n\t\tr = SOC15_WAIT_ON_RREG(JPEG, 0,\n\t\t\tmmUVD_PGFSM_STATUS, UVD_PGFSM_STATUS_UVDJ_PWR_ON,\n\t\t\tUVD_PGFSM_STATUS__UVDJ_PWR_STATUS_MASK);\n\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"amdgpu: JPEG disable power gating failed\\n\");\n\t\t\treturn r;\n\t\t}\n\t}\n\n\t \n\tdata = RREG32(SOC15_REG_OFFSET(JPEG, 0, mmUVD_JPEG_POWER_STATUS)) & ~0x1;\n\tWREG32(SOC15_REG_OFFSET(JPEG, 0, mmUVD_JPEG_POWER_STATUS), data);\n\n\treturn 0;\n}\n\nstatic int jpeg_v2_0_enable_power_gating(struct amdgpu_device *adev)\n{\n\tif (adev->pg_flags & AMD_PG_SUPPORT_JPEG) {\n\t\tuint32_t data;\n\t\tint r = 0;\n\n\t\tdata = RREG32(SOC15_REG_OFFSET(JPEG, 0, mmUVD_JPEG_POWER_STATUS));\n\t\tdata &= ~UVD_JPEG_POWER_STATUS__JPEG_POWER_STATUS_MASK;\n\t\tdata |=  0x1; \n\t\tWREG32(SOC15_REG_OFFSET(JPEG, 0, mmUVD_JPEG_POWER_STATUS), data);\n\n\t\tdata = 2 << UVD_PGFSM_CONFIG__UVDJ_PWR_CONFIG__SHIFT;\n\t\tWREG32(SOC15_REG_OFFSET(JPEG, 0, mmUVD_PGFSM_CONFIG), data);\n\n\t\tr = SOC15_WAIT_ON_RREG(JPEG, 0, mmUVD_PGFSM_STATUS,\n\t\t\t(2 << UVD_PGFSM_STATUS__UVDJ_PWR_STATUS__SHIFT),\n\t\t\tUVD_PGFSM_STATUS__UVDJ_PWR_STATUS_MASK);\n\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"amdgpu: JPEG enable power gating failed\\n\");\n\t\t\treturn r;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void jpeg_v2_0_disable_clock_gating(struct amdgpu_device *adev)\n{\n\tuint32_t data;\n\n\tdata = RREG32_SOC15(JPEG, 0, mmJPEG_CGC_CTRL);\n\tif (adev->cg_flags & AMD_CG_SUPPORT_JPEG_MGCG)\n\t\tdata |= 1 << JPEG_CGC_CTRL__DYN_CLOCK_MODE__SHIFT;\n\telse\n\t\tdata &= ~JPEG_CGC_CTRL__DYN_CLOCK_MODE__SHIFT;\n\n\tdata |= 1 << JPEG_CGC_CTRL__CLK_GATE_DLY_TIMER__SHIFT;\n\tdata |= 4 << JPEG_CGC_CTRL__CLK_OFF_DELAY__SHIFT;\n\tWREG32_SOC15(JPEG, 0, mmJPEG_CGC_CTRL, data);\n\n\tdata = RREG32_SOC15(JPEG, 0, mmJPEG_CGC_GATE);\n\tdata &= ~(JPEG_CGC_GATE__JPEG_DEC_MASK\n\t\t| JPEG_CGC_GATE__JPEG2_DEC_MASK\n\t\t| JPEG_CGC_GATE__JPEG_ENC_MASK\n\t\t| JPEG_CGC_GATE__JMCIF_MASK\n\t\t| JPEG_CGC_GATE__JRBBM_MASK);\n\tWREG32_SOC15(JPEG, 0, mmJPEG_CGC_GATE, data);\n}\n\nstatic void jpeg_v2_0_enable_clock_gating(struct amdgpu_device *adev)\n{\n\tuint32_t data;\n\n\tdata = RREG32_SOC15(JPEG, 0, mmJPEG_CGC_CTRL);\n\tif (adev->cg_flags & AMD_CG_SUPPORT_JPEG_MGCG)\n\t\tdata |= 1 << JPEG_CGC_CTRL__DYN_CLOCK_MODE__SHIFT;\n\telse\n\t\tdata |= 0 << JPEG_CGC_CTRL__DYN_CLOCK_MODE__SHIFT;\n\n\tdata |= 1 << JPEG_CGC_CTRL__CLK_GATE_DLY_TIMER__SHIFT;\n\tdata |= 4 << JPEG_CGC_CTRL__CLK_OFF_DELAY__SHIFT;\n\tWREG32_SOC15(JPEG, 0, mmJPEG_CGC_CTRL, data);\n\n\tdata = RREG32_SOC15(JPEG, 0, mmJPEG_CGC_GATE);\n\tdata |= (JPEG_CGC_GATE__JPEG_DEC_MASK\n\t\t|JPEG_CGC_GATE__JPEG2_DEC_MASK\n\t\t|JPEG_CGC_GATE__JPEG_ENC_MASK\n\t\t|JPEG_CGC_GATE__JMCIF_MASK\n\t\t|JPEG_CGC_GATE__JRBBM_MASK);\n\tWREG32_SOC15(JPEG, 0, mmJPEG_CGC_GATE, data);\n}\n\n \nstatic int jpeg_v2_0_start(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_ring *ring = adev->jpeg.inst->ring_dec;\n\tint r;\n\n\tif (adev->pm.dpm_enabled)\n\t\tamdgpu_dpm_enable_jpeg(adev, true);\n\n\t \n\tr = jpeg_v2_0_disable_power_gating(adev);\n\tif (r)\n\t\treturn r;\n\n\t \n\tjpeg_v2_0_disable_clock_gating(adev);\n\n\tWREG32_SOC15(JPEG, 0, mmJPEG_DEC_GFX10_ADDR_CONFIG, adev->gfx.config.gb_addr_config);\n\n\t \n\tWREG32_P(SOC15_REG_OFFSET(JPEG, 0, mmUVD_JMI_CNTL), 0,\n\t\t~UVD_JMI_CNTL__SOFT_RESET_MASK);\n\n\t \n\tWREG32_P(SOC15_REG_OFFSET(JPEG, 0, mmJPEG_SYS_INT_EN),\n\t\tJPEG_SYS_INT_EN__DJRBC_MASK,\n\t\t~JPEG_SYS_INT_EN__DJRBC_MASK);\n\n\tWREG32_SOC15(JPEG, 0, mmUVD_LMI_JRBC_RB_VMID, 0);\n\tWREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_CNTL, (0x00000001L | 0x00000002L));\n\tWREG32_SOC15(JPEG, 0, mmUVD_LMI_JRBC_RB_64BIT_BAR_LOW,\n\t\tlower_32_bits(ring->gpu_addr));\n\tWREG32_SOC15(JPEG, 0, mmUVD_LMI_JRBC_RB_64BIT_BAR_HIGH,\n\t\tupper_32_bits(ring->gpu_addr));\n\tWREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_RPTR, 0);\n\tWREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_WPTR, 0);\n\tWREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_CNTL, 0x00000002L);\n\tWREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_SIZE, ring->ring_size / 4);\n\tring->wptr = RREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_WPTR);\n\n\treturn 0;\n}\n\n \nstatic int jpeg_v2_0_stop(struct amdgpu_device *adev)\n{\n\tint r;\n\n\t \n\tWREG32_P(SOC15_REG_OFFSET(JPEG, 0, mmUVD_JMI_CNTL),\n\t\tUVD_JMI_CNTL__SOFT_RESET_MASK,\n\t\t~UVD_JMI_CNTL__SOFT_RESET_MASK);\n\n\t \n\tjpeg_v2_0_enable_clock_gating(adev);\n\n\t \n\tr = jpeg_v2_0_enable_power_gating(adev);\n\tif (r)\n\t\treturn r;\n\n\tif (adev->pm.dpm_enabled)\n\t\tamdgpu_dpm_enable_jpeg(adev, false);\n\n\treturn 0;\n}\n\n \nstatic uint64_t jpeg_v2_0_dec_ring_get_rptr(struct amdgpu_ring *ring)\n{\n\tstruct amdgpu_device *adev = ring->adev;\n\n\treturn RREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_RPTR);\n}\n\n \nstatic uint64_t jpeg_v2_0_dec_ring_get_wptr(struct amdgpu_ring *ring)\n{\n\tstruct amdgpu_device *adev = ring->adev;\n\n\tif (ring->use_doorbell)\n\t\treturn *ring->wptr_cpu_addr;\n\telse\n\t\treturn RREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_WPTR);\n}\n\n \nstatic void jpeg_v2_0_dec_ring_set_wptr(struct amdgpu_ring *ring)\n{\n\tstruct amdgpu_device *adev = ring->adev;\n\n\tif (ring->use_doorbell) {\n\t\t*ring->wptr_cpu_addr = lower_32_bits(ring->wptr);\n\t\tWDOORBELL32(ring->doorbell_index, lower_32_bits(ring->wptr));\n\t} else {\n\t\tWREG32_SOC15(JPEG, 0, mmUVD_JRBC_RB_WPTR, lower_32_bits(ring->wptr));\n\t}\n}\n\n \nvoid jpeg_v2_0_dec_ring_insert_start(struct amdgpu_ring *ring)\n{\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_JRBC_EXTERNAL_REG_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x68e04);\n\n\tamdgpu_ring_write(ring, PACKETJ(JRBC_DEC_EXTERNAL_REG_WRITE_ADDR,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x80010000);\n}\n\n \nvoid jpeg_v2_0_dec_ring_insert_end(struct amdgpu_ring *ring)\n{\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_JRBC_EXTERNAL_REG_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x68e04);\n\n\tamdgpu_ring_write(ring, PACKETJ(JRBC_DEC_EXTERNAL_REG_WRITE_ADDR,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x00010000);\n}\n\n \nvoid jpeg_v2_0_dec_ring_emit_fence(struct amdgpu_ring *ring, u64 addr, u64 seq,\n\t\t\t\tunsigned flags)\n{\n\tWARN_ON(flags & AMDGPU_FENCE_FLAG_64BIT);\n\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_JPEG_GPCOM_DATA0_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, seq);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JPEG_GPCOM_DATA1_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, seq);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_LMI_JRBC_RB_MEM_WR_64BIT_BAR_LOW_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, lower_32_bits(addr));\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_LMI_JRBC_RB_MEM_WR_64BIT_BAR_HIGH_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, upper_32_bits(addr));\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JPEG_GPCOM_CMD_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x8);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JPEG_GPCOM_CMD_INTERNAL_OFFSET,\n\t\t0, PACKETJ_CONDITION_CHECK0, PACKETJ_TYPE4));\n\tamdgpu_ring_write(ring, 0);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JRBC_EXTERNAL_REG_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x3fbc);\n\n\tamdgpu_ring_write(ring, PACKETJ(JRBC_DEC_EXTERNAL_REG_WRITE_ADDR,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x1);\n\n\tamdgpu_ring_write(ring, PACKETJ(0, 0, 0, PACKETJ_TYPE7));\n\tamdgpu_ring_write(ring, 0);\n}\n\n \nvoid jpeg_v2_0_dec_ring_emit_ib(struct amdgpu_ring *ring,\n\t\t\t\tstruct amdgpu_job *job,\n\t\t\t\tstruct amdgpu_ib *ib,\n\t\t\t\tuint32_t flags)\n{\n\tunsigned vmid = AMDGPU_JOB_GET_VMID(job);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JPEG_IH_CTRL_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, (vmid << JPEG_IH_CTRL__IH_VMID__SHIFT));\n\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_LMI_JRBC_IB_VMID_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, (vmid | (vmid << 4)));\n\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_LMI_JPEG_VMID_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, (vmid | (vmid << 4)));\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_LMI_JRBC_IB_64BIT_BAR_LOW_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, lower_32_bits(ib->gpu_addr));\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_LMI_JRBC_IB_64BIT_BAR_HIGH_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, upper_32_bits(ib->gpu_addr));\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JRBC_IB_SIZE_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, ib->length_dw);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_LMI_JRBC_RB_MEM_RD_64BIT_BAR_LOW_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, lower_32_bits(ring->gpu_addr));\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_LMI_JRBC_RB_MEM_RD_64BIT_BAR_HIGH_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, upper_32_bits(ring->gpu_addr));\n\n\tamdgpu_ring_write(ring,\tPACKETJ(0, 0, PACKETJ_CONDITION_CHECK0, PACKETJ_TYPE2));\n\tamdgpu_ring_write(ring, 0);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JRBC_RB_COND_RD_TIMER_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x01400200);\n\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_JRBC_RB_REF_DATA_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x2);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JRBC_STATUS_INTERNAL_OFFSET,\n\t\t0, PACKETJ_CONDITION_CHECK3, PACKETJ_TYPE3));\n\tamdgpu_ring_write(ring, 0x2);\n}\n\nvoid jpeg_v2_0_dec_ring_emit_reg_wait(struct amdgpu_ring *ring, uint32_t reg,\n\t\t\t\tuint32_t val, uint32_t mask)\n{\n\tuint32_t reg_offset = (reg << 2);\n\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_JRBC_RB_COND_RD_TIMER_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, 0x01400200);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JRBC_RB_REF_DATA_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tamdgpu_ring_write(ring, val);\n\n\tamdgpu_ring_write(ring, PACKETJ(mmUVD_JRBC_EXTERNAL_REG_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tif (reg_offset >= 0x10000 && reg_offset <= 0x105ff) {\n\t\tamdgpu_ring_write(ring, 0);\n\t\tamdgpu_ring_write(ring,\n\t\t\tPACKETJ((reg_offset >> 2), 0, 0, PACKETJ_TYPE3));\n\t} else {\n\t\tamdgpu_ring_write(ring, reg_offset);\n\t\tamdgpu_ring_write(ring,\tPACKETJ(JRBC_DEC_EXTERNAL_REG_WRITE_ADDR,\n\t\t\t0, 0, PACKETJ_TYPE3));\n\t}\n\tamdgpu_ring_write(ring, mask);\n}\n\nvoid jpeg_v2_0_dec_ring_emit_vm_flush(struct amdgpu_ring *ring,\n\t\t\t\tunsigned vmid, uint64_t pd_addr)\n{\n\tstruct amdgpu_vmhub *hub = &ring->adev->vmhub[ring->vm_hub];\n\tuint32_t data0, data1, mask;\n\n\tpd_addr = amdgpu_gmc_emit_flush_gpu_tlb(ring, vmid, pd_addr);\n\n\t \n\tdata0 = hub->ctx0_ptb_addr_lo32 + vmid * hub->ctx_addr_distance;\n\tdata1 = lower_32_bits(pd_addr);\n\tmask = 0xffffffff;\n\tjpeg_v2_0_dec_ring_emit_reg_wait(ring, data0, data1, mask);\n}\n\nvoid jpeg_v2_0_dec_ring_emit_wreg(struct amdgpu_ring *ring, uint32_t reg, uint32_t val)\n{\n\tuint32_t reg_offset = (reg << 2);\n\n\tamdgpu_ring_write(ring,\tPACKETJ(mmUVD_JRBC_EXTERNAL_REG_INTERNAL_OFFSET,\n\t\t0, 0, PACKETJ_TYPE0));\n\tif (reg_offset >= 0x10000 && reg_offset <= 0x105ff) {\n\t\tamdgpu_ring_write(ring, 0);\n\t\tamdgpu_ring_write(ring,\n\t\t\tPACKETJ((reg_offset >> 2), 0, 0, PACKETJ_TYPE0));\n\t} else {\n\t\tamdgpu_ring_write(ring, reg_offset);\n\t\tamdgpu_ring_write(ring,\tPACKETJ(JRBC_DEC_EXTERNAL_REG_WRITE_ADDR,\n\t\t\t0, 0, PACKETJ_TYPE0));\n\t}\n\tamdgpu_ring_write(ring, val);\n}\n\nvoid jpeg_v2_0_dec_ring_nop(struct amdgpu_ring *ring, uint32_t count)\n{\n\tint i;\n\n\tWARN_ON(ring->wptr % 2 || count % 2);\n\n\tfor (i = 0; i < count / 2; i++) {\n\t\tamdgpu_ring_write(ring, PACKETJ(0, 0, 0, PACKETJ_TYPE6));\n\t\tamdgpu_ring_write(ring, 0);\n\t}\n}\n\nstatic bool jpeg_v2_0_is_idle(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\treturn ((RREG32_SOC15(JPEG, 0, mmUVD_JRBC_STATUS) &\n\t\tUVD_JRBC_STATUS__RB_JOB_DONE_MASK) ==\n\t\tUVD_JRBC_STATUS__RB_JOB_DONE_MASK);\n}\n\nstatic int jpeg_v2_0_wait_for_idle(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tint ret;\n\n\tret = SOC15_WAIT_ON_RREG(JPEG, 0, mmUVD_JRBC_STATUS, UVD_JRBC_STATUS__RB_JOB_DONE_MASK,\n\t\tUVD_JRBC_STATUS__RB_JOB_DONE_MASK);\n\n\treturn ret;\n}\n\nstatic int jpeg_v2_0_set_clockgating_state(void *handle,\n\t\t\t\t\t  enum amd_clockgating_state state)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tbool enable = (state == AMD_CG_STATE_GATE);\n\n\tif (enable) {\n\t\tif (!jpeg_v2_0_is_idle(handle))\n\t\t\treturn -EBUSY;\n\t\tjpeg_v2_0_enable_clock_gating(adev);\n\t} else {\n\t\tjpeg_v2_0_disable_clock_gating(adev);\n\t}\n\n\treturn 0;\n}\n\nstatic int jpeg_v2_0_set_powergating_state(void *handle,\n\t\t\t\t\tenum amd_powergating_state state)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tint ret;\n\n\tif (state == adev->jpeg.cur_state)\n\t\treturn 0;\n\n\tif (state == AMD_PG_STATE_GATE)\n\t\tret = jpeg_v2_0_stop(adev);\n\telse\n\t\tret = jpeg_v2_0_start(adev);\n\n\tif (!ret)\n\t\tadev->jpeg.cur_state = state;\n\n\treturn ret;\n}\n\nstatic int jpeg_v2_0_set_interrupt_state(struct amdgpu_device *adev,\n\t\t\t\t\tstruct amdgpu_irq_src *source,\n\t\t\t\t\tunsigned type,\n\t\t\t\t\tenum amdgpu_interrupt_state state)\n{\n\treturn 0;\n}\n\nstatic int jpeg_v2_0_process_interrupt(struct amdgpu_device *adev,\n\t\t\t\t      struct amdgpu_irq_src *source,\n\t\t\t\t      struct amdgpu_iv_entry *entry)\n{\n\tDRM_DEBUG(\"IH: JPEG TRAP\\n\");\n\n\tswitch (entry->src_id) {\n\tcase VCN_2_0__SRCID__JPEG_DECODE:\n\t\tamdgpu_fence_process(adev->jpeg.inst->ring_dec);\n\t\tbreak;\n\tdefault:\n\t\tDRM_ERROR(\"Unhandled interrupt: %d %d\\n\",\n\t\t\t  entry->src_id, entry->src_data[0]);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct amd_ip_funcs jpeg_v2_0_ip_funcs = {\n\t.name = \"jpeg_v2_0\",\n\t.early_init = jpeg_v2_0_early_init,\n\t.late_init = NULL,\n\t.sw_init = jpeg_v2_0_sw_init,\n\t.sw_fini = jpeg_v2_0_sw_fini,\n\t.hw_init = jpeg_v2_0_hw_init,\n\t.hw_fini = jpeg_v2_0_hw_fini,\n\t.suspend = jpeg_v2_0_suspend,\n\t.resume = jpeg_v2_0_resume,\n\t.is_idle = jpeg_v2_0_is_idle,\n\t.wait_for_idle = jpeg_v2_0_wait_for_idle,\n\t.check_soft_reset = NULL,\n\t.pre_soft_reset = NULL,\n\t.soft_reset = NULL,\n\t.post_soft_reset = NULL,\n\t.set_clockgating_state = jpeg_v2_0_set_clockgating_state,\n\t.set_powergating_state = jpeg_v2_0_set_powergating_state,\n};\n\nstatic const struct amdgpu_ring_funcs jpeg_v2_0_dec_ring_vm_funcs = {\n\t.type = AMDGPU_RING_TYPE_VCN_JPEG,\n\t.align_mask = 0xf,\n\t.get_rptr = jpeg_v2_0_dec_ring_get_rptr,\n\t.get_wptr = jpeg_v2_0_dec_ring_get_wptr,\n\t.set_wptr = jpeg_v2_0_dec_ring_set_wptr,\n\t.emit_frame_size =\n\t\tSOC15_FLUSH_GPU_TLB_NUM_WREG * 6 +\n\t\tSOC15_FLUSH_GPU_TLB_NUM_REG_WAIT * 8 +\n\t\t8 +  \n\t\t18 + 18 +  \n\t\t8 + 16,\n\t.emit_ib_size = 24,  \n\t.emit_ib = jpeg_v2_0_dec_ring_emit_ib,\n\t.emit_fence = jpeg_v2_0_dec_ring_emit_fence,\n\t.emit_vm_flush = jpeg_v2_0_dec_ring_emit_vm_flush,\n\t.test_ring = amdgpu_jpeg_dec_ring_test_ring,\n\t.test_ib = amdgpu_jpeg_dec_ring_test_ib,\n\t.insert_nop = jpeg_v2_0_dec_ring_nop,\n\t.insert_start = jpeg_v2_0_dec_ring_insert_start,\n\t.insert_end = jpeg_v2_0_dec_ring_insert_end,\n\t.pad_ib = amdgpu_ring_generic_pad_ib,\n\t.begin_use = amdgpu_jpeg_ring_begin_use,\n\t.end_use = amdgpu_jpeg_ring_end_use,\n\t.emit_wreg = jpeg_v2_0_dec_ring_emit_wreg,\n\t.emit_reg_wait = jpeg_v2_0_dec_ring_emit_reg_wait,\n\t.emit_reg_write_reg_wait = amdgpu_ring_emit_reg_write_reg_wait_helper,\n};\n\nstatic void jpeg_v2_0_set_dec_ring_funcs(struct amdgpu_device *adev)\n{\n\tadev->jpeg.inst->ring_dec->funcs = &jpeg_v2_0_dec_ring_vm_funcs;\n\tDRM_INFO(\"JPEG decode is enabled in VM mode\\n\");\n}\n\nstatic const struct amdgpu_irq_src_funcs jpeg_v2_0_irq_funcs = {\n\t.set = jpeg_v2_0_set_interrupt_state,\n\t.process = jpeg_v2_0_process_interrupt,\n};\n\nstatic void jpeg_v2_0_set_irq_funcs(struct amdgpu_device *adev)\n{\n\tadev->jpeg.inst->irq.num_types = 1;\n\tadev->jpeg.inst->irq.funcs = &jpeg_v2_0_irq_funcs;\n}\n\nconst struct amdgpu_ip_block_version jpeg_v2_0_ip_block = {\n\t\t.type = AMD_IP_BLOCK_TYPE_JPEG,\n\t\t.major = 2,\n\t\t.minor = 0,\n\t\t.rev = 0,\n\t\t.funcs = &jpeg_v2_0_ip_funcs,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}