{
  "module_name": "amdgpu_object.h",
  "hash_id": "0ef2629384018dc04cc8803b107b80ba11e5348b6df16e9f08a98f7c26041351",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_object.h",
  "human_readable_source": " \n#ifndef __AMDGPU_OBJECT_H__\n#define __AMDGPU_OBJECT_H__\n\n#include <drm/amdgpu_drm.h>\n#include \"amdgpu.h\"\n#include \"amdgpu_res_cursor.h\"\n\n#ifdef CONFIG_MMU_NOTIFIER\n#include <linux/mmu_notifier.h>\n#endif\n\n#define AMDGPU_BO_INVALID_OFFSET\tLONG_MAX\n#define AMDGPU_BO_MAX_PLACEMENTS\t3\n\n \n#define AMDGPU_AMDKFD_CREATE_USERPTR_BO\t(1ULL << 63)\n\n#define to_amdgpu_bo_user(abo) container_of((abo), struct amdgpu_bo_user, bo)\n#define to_amdgpu_bo_vm(abo) container_of((abo), struct amdgpu_bo_vm, bo)\n\nstruct amdgpu_bo_param {\n\tunsigned long\t\t\tsize;\n\tint\t\t\t\tbyte_align;\n\tu32\t\t\t\tbo_ptr_size;\n\tu32\t\t\t\tdomain;\n\tu32\t\t\t\tpreferred_domain;\n\tu64\t\t\t\tflags;\n\tenum ttm_bo_type\t\ttype;\n\tbool\t\t\t\tno_wait_gpu;\n\tstruct dma_resv\t\t\t*resv;\n\tvoid\t\t\t\t(*destroy)(struct ttm_buffer_object *bo);\n\t \n\tint8_t\t\t\t\txcp_id_plus1;\n};\n\n \nstruct amdgpu_bo_va_mapping {\n\tstruct amdgpu_bo_va\t\t*bo_va;\n\tstruct list_head\t\tlist;\n\tstruct rb_node\t\t\trb;\n\tuint64_t\t\t\tstart;\n\tuint64_t\t\t\tlast;\n\tuint64_t\t\t\t__subtree_last;\n\tuint64_t\t\t\toffset;\n\tuint64_t\t\t\tflags;\n};\n\n \nstruct amdgpu_bo_va {\n\tstruct amdgpu_vm_bo_base\tbase;\n\n\t \n\tunsigned\t\t\tref_count;\n\n\t \n\tstruct dma_fence\t        *last_pt_update;\n\n\t \n\tstruct list_head\t\tinvalids;\n\tstruct list_head\t\tvalids;\n\n\t \n\tbool\t\t\t\tcleared;\n\n\tbool\t\t\t\tis_xgmi;\n};\n\nstruct amdgpu_bo {\n\t \n\tu32\t\t\t\tpreferred_domains;\n\tu32\t\t\t\tallowed_domains;\n\tstruct ttm_place\t\tplacements[AMDGPU_BO_MAX_PLACEMENTS];\n\tstruct ttm_placement\t\tplacement;\n\tstruct ttm_buffer_object\ttbo;\n\tstruct ttm_bo_kmap_obj\t\tkmap;\n\tu64\t\t\t\tflags;\n\t \n\tstruct amdgpu_vm_bo_base\t*vm_bo;\n\t \n\tstruct amdgpu_bo\t\t*parent;\n\n#ifdef CONFIG_MMU_NOTIFIER\n\tstruct mmu_interval_notifier\tnotifier;\n#endif\n\tstruct kgd_mem                  *kfd_bo;\n\n\t \n\tint8_t\t\t\t\txcp_id;\n};\n\nstruct amdgpu_bo_user {\n\tstruct amdgpu_bo\t\tbo;\n\tu64\t\t\t\ttiling_flags;\n\tu64\t\t\t\tmetadata_flags;\n\tvoid\t\t\t\t*metadata;\n\tu32\t\t\t\tmetadata_size;\n\n};\n\nstruct amdgpu_bo_vm {\n\tstruct amdgpu_bo\t\tbo;\n\tstruct amdgpu_bo\t\t*shadow;\n\tstruct list_head\t\tshadow_list;\n\tstruct amdgpu_vm_bo_base        entries[];\n};\n\nstruct amdgpu_mem_stats {\n\t \n\tuint64_t vram;\n\t \n\tuint64_t visible_vram;\n\t \n\tuint64_t gtt;\n\t \n\tuint64_t cpu;\n\t \n\tuint64_t evicted_vram;\n\t \n\tuint64_t evicted_visible_vram;\n\t \n\tuint64_t requested_vram;\n\t \n\tuint64_t requested_visible_vram;\n\t \n\tuint64_t requested_gtt;\n};\n\nstatic inline struct amdgpu_bo *ttm_to_amdgpu_bo(struct ttm_buffer_object *tbo)\n{\n\treturn container_of(tbo, struct amdgpu_bo, tbo);\n}\n\n \nstatic inline unsigned amdgpu_mem_type_to_domain(u32 mem_type)\n{\n\tswitch (mem_type) {\n\tcase TTM_PL_VRAM:\n\t\treturn AMDGPU_GEM_DOMAIN_VRAM;\n\tcase TTM_PL_TT:\n\t\treturn AMDGPU_GEM_DOMAIN_GTT;\n\tcase TTM_PL_SYSTEM:\n\t\treturn AMDGPU_GEM_DOMAIN_CPU;\n\tcase AMDGPU_PL_GDS:\n\t\treturn AMDGPU_GEM_DOMAIN_GDS;\n\tcase AMDGPU_PL_GWS:\n\t\treturn AMDGPU_GEM_DOMAIN_GWS;\n\tcase AMDGPU_PL_OA:\n\t\treturn AMDGPU_GEM_DOMAIN_OA;\n\tcase AMDGPU_PL_DOORBELL:\n\t\treturn AMDGPU_GEM_DOMAIN_DOORBELL;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\n \nstatic inline int amdgpu_bo_reserve(struct amdgpu_bo *bo, bool no_intr)\n{\n\tstruct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);\n\tint r;\n\n\tr = ttm_bo_reserve(&bo->tbo, !no_intr, false, NULL);\n\tif (unlikely(r != 0)) {\n\t\tif (r != -ERESTARTSYS)\n\t\t\tdev_err(adev->dev, \"%p reserve failed\\n\", bo);\n\t\treturn r;\n\t}\n\treturn 0;\n}\n\nstatic inline void amdgpu_bo_unreserve(struct amdgpu_bo *bo)\n{\n\tttm_bo_unreserve(&bo->tbo);\n}\n\nstatic inline unsigned long amdgpu_bo_size(struct amdgpu_bo *bo)\n{\n\treturn bo->tbo.base.size;\n}\n\nstatic inline unsigned amdgpu_bo_ngpu_pages(struct amdgpu_bo *bo)\n{\n\treturn bo->tbo.base.size / AMDGPU_GPU_PAGE_SIZE;\n}\n\nstatic inline unsigned amdgpu_bo_gpu_page_alignment(struct amdgpu_bo *bo)\n{\n\treturn (bo->tbo.page_alignment << PAGE_SHIFT) / AMDGPU_GPU_PAGE_SIZE;\n}\n\n \nstatic inline u64 amdgpu_bo_mmap_offset(struct amdgpu_bo *bo)\n{\n\treturn drm_vma_node_offset_addr(&bo->tbo.base.vma_node);\n}\n\n \nstatic inline bool amdgpu_bo_in_cpu_visible_vram(struct amdgpu_bo *bo)\n{\n\tstruct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);\n\tstruct amdgpu_res_cursor cursor;\n\n\tif (!bo->tbo.resource || bo->tbo.resource->mem_type != TTM_PL_VRAM)\n\t\treturn false;\n\n\tamdgpu_res_first(bo->tbo.resource, 0, amdgpu_bo_size(bo), &cursor);\n\twhile (cursor.remaining) {\n\t\tif (cursor.start < adev->gmc.visible_vram_size)\n\t\t\treturn true;\n\n\t\tamdgpu_res_next(&cursor, cursor.size);\n\t}\n\n\treturn false;\n}\n\n \nstatic inline bool amdgpu_bo_explicit_sync(struct amdgpu_bo *bo)\n{\n\treturn bo->flags & AMDGPU_GEM_CREATE_EXPLICIT_SYNC;\n}\n\n \nstatic inline bool amdgpu_bo_encrypted(struct amdgpu_bo *bo)\n{\n\treturn bo->flags & AMDGPU_GEM_CREATE_ENCRYPTED;\n}\n\n \nstatic inline struct amdgpu_bo *amdgpu_bo_shadowed(struct amdgpu_bo *bo)\n{\n\tif (bo->tbo.type == ttm_bo_type_kernel)\n\t\treturn to_amdgpu_bo_vm(bo)->shadow;\n\n\treturn NULL;\n}\n\nbool amdgpu_bo_is_amdgpu_bo(struct ttm_buffer_object *bo);\nvoid amdgpu_bo_placement_from_domain(struct amdgpu_bo *abo, u32 domain);\n\nint amdgpu_bo_create(struct amdgpu_device *adev,\n\t\t     struct amdgpu_bo_param *bp,\n\t\t     struct amdgpu_bo **bo_ptr);\nint amdgpu_bo_create_reserved(struct amdgpu_device *adev,\n\t\t\t      unsigned long size, int align,\n\t\t\t      u32 domain, struct amdgpu_bo **bo_ptr,\n\t\t\t      u64 *gpu_addr, void **cpu_addr);\nint amdgpu_bo_create_kernel(struct amdgpu_device *adev,\n\t\t\t    unsigned long size, int align,\n\t\t\t    u32 domain, struct amdgpu_bo **bo_ptr,\n\t\t\t    u64 *gpu_addr, void **cpu_addr);\nint amdgpu_bo_create_kernel_at(struct amdgpu_device *adev,\n\t\t\t       uint64_t offset, uint64_t size,\n\t\t\t       struct amdgpu_bo **bo_ptr, void **cpu_addr);\nint amdgpu_bo_create_user(struct amdgpu_device *adev,\n\t\t\t  struct amdgpu_bo_param *bp,\n\t\t\t  struct amdgpu_bo_user **ubo_ptr);\nint amdgpu_bo_create_vm(struct amdgpu_device *adev,\n\t\t\tstruct amdgpu_bo_param *bp,\n\t\t\tstruct amdgpu_bo_vm **ubo_ptr);\nvoid amdgpu_bo_free_kernel(struct amdgpu_bo **bo, u64 *gpu_addr,\n\t\t\t   void **cpu_addr);\nint amdgpu_bo_kmap(struct amdgpu_bo *bo, void **ptr);\nvoid *amdgpu_bo_kptr(struct amdgpu_bo *bo);\nvoid amdgpu_bo_kunmap(struct amdgpu_bo *bo);\nstruct amdgpu_bo *amdgpu_bo_ref(struct amdgpu_bo *bo);\nvoid amdgpu_bo_unref(struct amdgpu_bo **bo);\nint amdgpu_bo_pin(struct amdgpu_bo *bo, u32 domain);\nint amdgpu_bo_pin_restricted(struct amdgpu_bo *bo, u32 domain,\n\t\t\t     u64 min_offset, u64 max_offset);\nvoid amdgpu_bo_unpin(struct amdgpu_bo *bo);\nint amdgpu_bo_init(struct amdgpu_device *adev);\nvoid amdgpu_bo_fini(struct amdgpu_device *adev);\nint amdgpu_bo_set_tiling_flags(struct amdgpu_bo *bo, u64 tiling_flags);\nvoid amdgpu_bo_get_tiling_flags(struct amdgpu_bo *bo, u64 *tiling_flags);\nint amdgpu_bo_set_metadata (struct amdgpu_bo *bo, void *metadata,\n\t\t\t    uint32_t metadata_size, uint64_t flags);\nint amdgpu_bo_get_metadata(struct amdgpu_bo *bo, void *buffer,\n\t\t\t   size_t buffer_size, uint32_t *metadata_size,\n\t\t\t   uint64_t *flags);\nvoid amdgpu_bo_move_notify(struct ttm_buffer_object *bo,\n\t\t\t   bool evict,\n\t\t\t   struct ttm_resource *new_mem);\nvoid amdgpu_bo_release_notify(struct ttm_buffer_object *bo);\nvm_fault_t amdgpu_bo_fault_reserve_notify(struct ttm_buffer_object *bo);\nvoid amdgpu_bo_fence(struct amdgpu_bo *bo, struct dma_fence *fence,\n\t\t     bool shared);\nint amdgpu_bo_sync_wait_resv(struct amdgpu_device *adev, struct dma_resv *resv,\n\t\t\t     enum amdgpu_sync_mode sync_mode, void *owner,\n\t\t\t     bool intr);\nint amdgpu_bo_sync_wait(struct amdgpu_bo *bo, void *owner, bool intr);\nu64 amdgpu_bo_gpu_offset(struct amdgpu_bo *bo);\nu64 amdgpu_bo_gpu_offset_no_check(struct amdgpu_bo *bo);\nvoid amdgpu_bo_get_memory(struct amdgpu_bo *bo,\n\t\t\t  struct amdgpu_mem_stats *stats);\nvoid amdgpu_bo_add_to_shadow_list(struct amdgpu_bo_vm *vmbo);\nint amdgpu_bo_restore_shadow(struct amdgpu_bo *shadow,\n\t\t\t     struct dma_fence **fence);\nuint32_t amdgpu_bo_get_preferred_domain(struct amdgpu_device *adev,\n\t\t\t\t\t    uint32_t domain);\n\n \nstatic inline struct amdgpu_sa_manager *\nto_amdgpu_sa_manager(struct drm_suballoc_manager *manager)\n{\n\treturn container_of(manager, struct amdgpu_sa_manager, base);\n}\n\nstatic inline uint64_t amdgpu_sa_bo_gpu_addr(struct drm_suballoc *sa_bo)\n{\n\treturn to_amdgpu_sa_manager(sa_bo->manager)->gpu_addr +\n\t\tdrm_suballoc_soffset(sa_bo);\n}\n\nstatic inline void *amdgpu_sa_bo_cpu_addr(struct drm_suballoc *sa_bo)\n{\n\treturn to_amdgpu_sa_manager(sa_bo->manager)->cpu_ptr +\n\t\tdrm_suballoc_soffset(sa_bo);\n}\n\nint amdgpu_sa_bo_manager_init(struct amdgpu_device *adev,\n\t\t\t\t     struct amdgpu_sa_manager *sa_manager,\n\t\t\t\t     unsigned size, u32 align, u32 domain);\nvoid amdgpu_sa_bo_manager_fini(struct amdgpu_device *adev,\n\t\t\t\t      struct amdgpu_sa_manager *sa_manager);\nint amdgpu_sa_bo_manager_start(struct amdgpu_device *adev,\n\t\t\t\t      struct amdgpu_sa_manager *sa_manager);\nint amdgpu_sa_bo_new(struct amdgpu_sa_manager *sa_manager,\n\t\t     struct drm_suballoc **sa_bo,\n\t\t     unsigned int size);\nvoid amdgpu_sa_bo_free(struct amdgpu_device *adev,\n\t\t       struct drm_suballoc **sa_bo,\n\t\t       struct dma_fence *fence);\n#if defined(CONFIG_DEBUG_FS)\nvoid amdgpu_sa_bo_dump_debug_info(struct amdgpu_sa_manager *sa_manager,\n\t\t\t\t\t struct seq_file *m);\nu64 amdgpu_bo_print_info(int id, struct amdgpu_bo *bo, struct seq_file *m);\n#endif\nvoid amdgpu_debugfs_sa_init(struct amdgpu_device *adev);\n\nbool amdgpu_bo_support_uswc(u64 bo_flags);\n\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}