{
  "module_name": "amdgpu_virt.h",
  "hash_id": "8a0ad4169665127c9cf1709284b290f5145d490fc8832f2b121bffeacc2381dc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_virt.h",
  "human_readable_source": " \n#ifndef AMDGPU_VIRT_H\n#define AMDGPU_VIRT_H\n\n#include \"amdgv_sriovmsg.h\"\n\n#define AMDGPU_SRIOV_CAPS_SRIOV_VBIOS  (1 << 0)  \n#define AMDGPU_SRIOV_CAPS_ENABLE_IOV   (1 << 1)  \n#define AMDGPU_SRIOV_CAPS_IS_VF        (1 << 2)  \n#define AMDGPU_PASSTHROUGH_MODE        (1 << 3)  \n#define AMDGPU_SRIOV_CAPS_RUNTIME      (1 << 4)  \n#define AMDGPU_VF_MMIO_ACCESS_PROTECT  (1 << 5)  \n\n \n#define AMDGPU_RLCG_GC_WRITE_LEGACY    (0x8 << 28)\n#define AMDGPU_RLCG_GC_WRITE           (0x0 << 28)\n#define AMDGPU_RLCG_GC_READ            (0x1 << 28)\n#define AMDGPU_RLCG_MMHUB_WRITE        (0x2 << 28)\n\n \n#define AMDGPU_RLCG_VFGATE_DISABLED\t\t0x4000000\n#define AMDGPU_RLCG_WRONG_OPERATION_TYPE\t0x2000000\n#define AMDGPU_RLCG_REG_NOT_IN_RANGE\t\t0x1000000\n\n#define AMDGPU_RLCG_SCRATCH1_ADDRESS_MASK\t0xFFFFF\n\n \n#define mmRCC_IOV_FUNC_IDENTIFIER 0xDE5\n \n#define mmBIF_IOV_FUNC_IDENTIFIER 0x1503\n\nenum amdgpu_sriov_vf_mode {\n\tSRIOV_VF_MODE_BARE_METAL = 0,\n\tSRIOV_VF_MODE_ONE_VF,\n\tSRIOV_VF_MODE_MULTI_VF,\n};\n\nstruct amdgpu_mm_table {\n\tstruct amdgpu_bo\t*bo;\n\tuint32_t\t\t*cpu_addr;\n\tuint64_t\t\tgpu_addr;\n};\n\n#define AMDGPU_VF_ERROR_ENTRY_SIZE    16\n\n \nstruct amdgpu_vf_error_buffer {\n\tstruct mutex lock;\n\tint read_count;\n\tint write_count;\n\tuint16_t code[AMDGPU_VF_ERROR_ENTRY_SIZE];\n\tuint16_t flags[AMDGPU_VF_ERROR_ENTRY_SIZE];\n\tuint64_t data[AMDGPU_VF_ERROR_ENTRY_SIZE];\n};\n\nenum idh_request;\n\n \nstruct amdgpu_virt_ops {\n\tint (*req_full_gpu)(struct amdgpu_device *adev, bool init);\n\tint (*rel_full_gpu)(struct amdgpu_device *adev, bool init);\n\tint (*req_init_data)(struct amdgpu_device *adev);\n\tint (*reset_gpu)(struct amdgpu_device *adev);\n\tint (*wait_reset)(struct amdgpu_device *adev);\n\tvoid (*trans_msg)(struct amdgpu_device *adev, enum idh_request req,\n\t\t\t  u32 data1, u32 data2, u32 data3);\n\tvoid (*ras_poison_handler)(struct amdgpu_device *adev);\n};\n\n \nstruct amdgpu_virt_fw_reserve {\n\tstruct amd_sriov_msg_pf2vf_info_header *p_pf2vf;\n\tstruct amd_sriov_msg_vf2pf_info_header *p_vf2pf;\n\tunsigned int checksum_key;\n};\n\n \n#define AMDGIM_DATAEXCHANGE_OFFSET\t\t(64 * 1024)\n\n#define AMDGIM_GET_STRUCTURE_RESERVED_SIZE(total, u8, u16, u32, u64) \\\n\t\t(total - (((u8)+3) / 4 + ((u16)+1) / 2 + (u32) + (u64)*2))\n\nenum AMDGIM_FEATURE_FLAG {\n\t \n\tAMDGIM_FEATURE_ERROR_LOG_COLLECT = 0x1,\n\t \n\tAMDGIM_FEATURE_GIM_LOAD_UCODES   = 0x2,\n\t \n\tAMDGIM_FEATURE_GIM_FLR_VRAMLOST = 0x4,\n\t \n\tAMDGIM_FEATURE_GIM_MM_BW_MGR = 0x8,\n\t \n\tAMDGIM_FEATURE_PP_ONE_VF = (1 << 4),\n\t \n\tAMDGIM_FEATURE_INDIRECT_REG_ACCESS = (1 << 5),\n\t \n\tAMDGIM_FEATURE_AV1_SUPPORT = (1 << 6),\n};\n\nenum AMDGIM_REG_ACCESS_FLAG {\n\t \n\tAMDGIM_FEATURE_IH_REG_PSP_EN     = (1 << 0),\n\t \n\tAMDGIM_FEATURE_MMHUB_REG_RLC_EN  = (1 << 1),\n\t \n\tAMDGIM_FEATURE_GC_REG_RLC_EN     = (1 << 2),\n};\n\nstruct amdgim_pf2vf_info_v1 {\n\t \n\tstruct amd_sriov_msg_pf2vf_info_header header;\n\t \n\tunsigned int uvd_enc_max_pixels_count;\n\t \n\tunsigned int uvd_enc_max_bandwidth;\n\t \n\tunsigned int vce_enc_max_pixels_count;\n\t \n\tunsigned int vce_enc_max_bandwidth;\n\t \n\tunsigned int mecfw_kboffset;\n\t \n\tunsigned int feature_flags;\n\t \n\tunsigned int checksum;\n} __aligned(4);\n\nstruct amdgim_vf2pf_info_v1 {\n\t \n\tstruct amd_sriov_msg_vf2pf_info_header header;\n\t \n\tchar driver_version[64];\n\t \n\tunsigned int driver_cert;\n\t \n\tunsigned int os_info;\n\t \n\tunsigned int fb_usage;\n\t \n\tunsigned int gfx_usage;\n\t \n\tunsigned int gfx_health;\n\t \n\tunsigned int compute_usage;\n\t \n\tunsigned int compute_health;\n\t \n\tunsigned int vce_enc_usage;\n\t \n\tunsigned int vce_enc_health;\n\t \n\tunsigned int uvd_enc_usage;\n\t \n\tunsigned int uvd_enc_health;\n\tunsigned int checksum;\n} __aligned(4);\n\nstruct amdgim_vf2pf_info_v2 {\n\t \n\tstruct amd_sriov_msg_vf2pf_info_header header;\n\tuint32_t checksum;\n\t \n\tuint8_t driver_version[64];\n\t \n\tuint32_t driver_cert;\n\t \n\tuint32_t os_info;\n\t \n\tuint32_t fb_usage;\n\t \n\tuint32_t gfx_usage;\n\t \n\tuint32_t gfx_health;\n\t \n\tuint32_t compute_usage;\n\t \n\tuint32_t compute_health;\n\t \n\tuint32_t vce_enc_usage;\n\t \n\tuint32_t vce_enc_health;\n\t \n\tuint32_t uvd_enc_usage;\n\t \n\tuint32_t uvd_enc_health;\n\tuint32_t reserved[AMDGIM_GET_STRUCTURE_RESERVED_SIZE(256, 64, 0, (12 + sizeof(struct amd_sriov_msg_vf2pf_info_header)/sizeof(uint32_t)), 0)];\n} __aligned(4);\n\nstruct amdgpu_virt_ras_err_handler_data {\n\t \n\tstruct eeprom_table_record *bps;\n\t \n\tstruct amdgpu_bo **bps_bo;\n\t \n\tint count;\n\t \n\tint last_reserved;\n};\n\n \nstruct amdgpu_virt {\n\tuint32_t\t\t\tcaps;\n\tstruct amdgpu_bo\t\t*csa_obj;\n\tvoid\t\t\t\t*csa_cpu_addr;\n\tbool chained_ib_support;\n\tuint32_t\t\t\treg_val_offs;\n\tstruct amdgpu_irq_src\t\tack_irq;\n\tstruct amdgpu_irq_src\t\trcv_irq;\n\tstruct work_struct\t\tflr_work;\n\tstruct amdgpu_mm_table\t\tmm_table;\n\tconst struct amdgpu_virt_ops\t*ops;\n\tstruct amdgpu_vf_error_buffer\tvf_errors;\n\tstruct amdgpu_virt_fw_reserve\tfw_reserve;\n\tuint32_t gim_feature;\n\tuint32_t reg_access_mode;\n\tint req_init_data_ver;\n\tbool tdr_debug;\n\tstruct amdgpu_virt_ras_err_handler_data *virt_eh_data;\n\tbool ras_init_done;\n\tuint32_t reg_access;\n\n\t \n\tstruct delayed_work vf2pf_work;\n\tuint32_t vf2pf_update_interval_ms;\n\n\t \n\tbool     is_mm_bw_enabled;\n\tuint32_t decode_max_dimension_pixels;\n\tuint32_t decode_max_frame_pixels;\n\tuint32_t encode_max_dimension_pixels;\n\tuint32_t encode_max_frame_pixels;\n\n\t \n\tuint32_t autoload_ucode_id;\n};\n\nstruct amdgpu_video_codec_info;\n\n#define amdgpu_sriov_enabled(adev) \\\n((adev)->virt.caps & AMDGPU_SRIOV_CAPS_ENABLE_IOV)\n\n#define amdgpu_sriov_vf(adev) \\\n((adev)->virt.caps & AMDGPU_SRIOV_CAPS_IS_VF)\n\n#define amdgpu_sriov_bios(adev) \\\n((adev)->virt.caps & AMDGPU_SRIOV_CAPS_SRIOV_VBIOS)\n\n#define amdgpu_sriov_runtime(adev) \\\n((adev)->virt.caps & AMDGPU_SRIOV_CAPS_RUNTIME)\n\n#define amdgpu_sriov_fullaccess(adev) \\\n(amdgpu_sriov_vf((adev)) && !amdgpu_sriov_runtime((adev)))\n\n#define amdgpu_sriov_reg_indirect_en(adev) \\\n(amdgpu_sriov_vf((adev)) && \\\n\t((adev)->virt.gim_feature & (AMDGIM_FEATURE_INDIRECT_REG_ACCESS)))\n\n#define amdgpu_sriov_reg_indirect_ih(adev) \\\n(amdgpu_sriov_vf((adev)) && \\\n\t((adev)->virt.reg_access & (AMDGIM_FEATURE_IH_REG_PSP_EN)))\n\n#define amdgpu_sriov_reg_indirect_mmhub(adev) \\\n(amdgpu_sriov_vf((adev)) && \\\n\t((adev)->virt.reg_access & (AMDGIM_FEATURE_MMHUB_REG_RLC_EN)))\n\n#define amdgpu_sriov_reg_indirect_gc(adev) \\\n(amdgpu_sriov_vf((adev)) && \\\n\t((adev)->virt.reg_access & (AMDGIM_FEATURE_GC_REG_RLC_EN)))\n\n#define amdgpu_sriov_rlcg_error_report_enabled(adev) \\\n        (amdgpu_sriov_reg_indirect_mmhub(adev) || amdgpu_sriov_reg_indirect_gc(adev))\n\n#define amdgpu_passthrough(adev) \\\n((adev)->virt.caps & AMDGPU_PASSTHROUGH_MODE)\n\n#define amdgpu_sriov_vf_mmio_access_protection(adev) \\\n((adev)->virt.caps & AMDGPU_VF_MMIO_ACCESS_PROTECT)\n\nstatic inline bool is_virtual_machine(void)\n{\n#if defined(CONFIG_X86)\n\treturn boot_cpu_has(X86_FEATURE_HYPERVISOR);\n#elif defined(CONFIG_ARM64)\n\treturn !is_kernel_in_hyp_mode();\n#else\n\treturn false;\n#endif\n}\n\n#define amdgpu_sriov_is_pp_one_vf(adev) \\\n\t((adev)->virt.gim_feature & AMDGIM_FEATURE_PP_ONE_VF)\n#define amdgpu_sriov_is_debug(adev) \\\n\t((!amdgpu_in_reset(adev)) && adev->virt.tdr_debug)\n#define amdgpu_sriov_is_normal(adev) \\\n\t((!amdgpu_in_reset(adev)) && (!adev->virt.tdr_debug))\n#define amdgpu_sriov_is_av1_support(adev) \\\n\t((adev)->virt.gim_feature & AMDGIM_FEATURE_AV1_SUPPORT)\nbool amdgpu_virt_mmio_blocked(struct amdgpu_device *adev);\nvoid amdgpu_virt_init_setting(struct amdgpu_device *adev);\nvoid amdgpu_virt_kiq_reg_write_reg_wait(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t reg0, uint32_t rreg1,\n\t\t\t\t\tuint32_t ref, uint32_t mask);\nint amdgpu_virt_request_full_gpu(struct amdgpu_device *adev, bool init);\nint amdgpu_virt_release_full_gpu(struct amdgpu_device *adev, bool init);\nint amdgpu_virt_reset_gpu(struct amdgpu_device *adev);\nvoid amdgpu_virt_request_init_data(struct amdgpu_device *adev);\nint amdgpu_virt_wait_reset(struct amdgpu_device *adev);\nint amdgpu_virt_alloc_mm_table(struct amdgpu_device *adev);\nvoid amdgpu_virt_free_mm_table(struct amdgpu_device *adev);\nvoid amdgpu_virt_release_ras_err_handler_data(struct amdgpu_device *adev);\nvoid amdgpu_virt_init_data_exchange(struct amdgpu_device *adev);\nvoid amdgpu_virt_exchange_data(struct amdgpu_device *adev);\nvoid amdgpu_virt_fini_data_exchange(struct amdgpu_device *adev);\nvoid amdgpu_detect_virtualization(struct amdgpu_device *adev);\n\nbool amdgpu_virt_can_access_debugfs(struct amdgpu_device *adev);\nint amdgpu_virt_enable_access_debugfs(struct amdgpu_device *adev);\nvoid amdgpu_virt_disable_access_debugfs(struct amdgpu_device *adev);\n\nenum amdgpu_sriov_vf_mode amdgpu_virt_get_sriov_vf_mode(struct amdgpu_device *adev);\n\nvoid amdgpu_virt_update_sriov_video_codec(struct amdgpu_device *adev,\n\t\t\tstruct amdgpu_video_codec_info *encode, uint32_t encode_array_size,\n\t\t\tstruct amdgpu_video_codec_info *decode, uint32_t decode_array_size);\nvoid amdgpu_sriov_wreg(struct amdgpu_device *adev,\n\t\t       u32 offset, u32 value,\n\t\t       u32 acc_flags, u32 hwip, u32 xcc_id);\nu32 amdgpu_sriov_rreg(struct amdgpu_device *adev,\n\t\t      u32 offset, u32 acc_flags, u32 hwip, u32 xcc_id);\nbool amdgpu_virt_fw_load_skip_check(struct amdgpu_device *adev,\n\t\t\tuint32_t ucode_id);\nvoid amdgpu_virt_post_reset(struct amdgpu_device *adev);\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}