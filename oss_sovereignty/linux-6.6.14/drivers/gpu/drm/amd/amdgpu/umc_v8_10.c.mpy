{
  "module_name": "umc_v8_10.c",
  "hash_id": "dca5036fba3ec80b77ef301012102a890cf519d81aa211b56061ac5ad2c65f05",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/umc_v8_10.c",
  "human_readable_source": " \n#include \"umc_v8_10.h\"\n#include \"amdgpu_ras.h\"\n#include \"amdgpu_umc.h\"\n#include \"amdgpu.h\"\n#include \"umc/umc_8_10_0_offset.h\"\n#include \"umc/umc_8_10_0_sh_mask.h\"\n\n#define UMC_8_NODE_DIST   0x800000\n#define UMC_8_INST_DIST   0x4000\n\nstruct channelnum_map_colbit {\n\tuint32_t channel_num;\n\tuint32_t col_bit;\n};\n\nconst struct channelnum_map_colbit umc_v8_10_channelnum_map_colbit_table[] = {\n\t{24, 13},\n\t{20, 13},\n\t{16, 12},\n\t{14, 12},\n\t{12, 12},\n\t{10, 12},\n\t{6,  11},\n};\n\nconst uint32_t\n\tumc_v8_10_channel_idx_tbl_ext0[]\n\t\t\t\t[UMC_V8_10_UMC_INSTANCE_NUM]\n\t\t\t\t[UMC_V8_10_CHANNEL_INSTANCE_NUM] = {\n\t   {{1,   5}, {7,  3}},\n\t   {{14, 15}, {13, 12}},\n\t   {{10, 11}, {9,  8}},\n\t   {{6,   2}, {0,  4}}\n\t};\n\nconst uint32_t\n\tumc_v8_10_channel_idx_tbl[]\n\t\t\t\t[UMC_V8_10_UMC_INSTANCE_NUM]\n\t\t\t\t[UMC_V8_10_CHANNEL_INSTANCE_NUM] = {\n\t   {{16, 18}, {17, 19}},\n\t   {{15, 11}, {3,   7}},\n\t   {{1,   5}, {13,  9}},\n\t   {{23, 21}, {22, 20}},\n\t   {{0,   4}, {12,  8}},\n\t   {{14, 10}, {2,   6}}\n\t};\n\nstatic inline uint32_t get_umc_v8_10_reg_offset(struct amdgpu_device *adev,\n\t\t\t\t\t    uint32_t node_inst,\n\t\t\t\t\t    uint32_t umc_inst,\n\t\t\t\t\t    uint32_t ch_inst)\n{\n\treturn adev->umc.channel_offs * ch_inst + UMC_8_INST_DIST * umc_inst +\n\t\tUMC_8_NODE_DIST * node_inst;\n}\n\nstatic int umc_v8_10_clear_error_count_per_channel(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t node_inst, uint32_t umc_inst,\n\t\t\t\t\tuint32_t ch_inst, void *data)\n{\n\tuint32_t ecc_err_cnt_addr;\n\tuint32_t umc_reg_offset =\n\t\tget_umc_v8_10_reg_offset(adev, node_inst, umc_inst, ch_inst);\n\n\tecc_err_cnt_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, regUMCCH0_0_GeccErrCnt);\n\n\t \n\tWREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4,\n\t\t\tUMC_V8_10_CE_CNT_INIT);\n\n\treturn 0;\n}\n\nstatic void umc_v8_10_clear_error_count(struct amdgpu_device *adev)\n{\n\tamdgpu_umc_loop_channels(adev,\n\t\tumc_v8_10_clear_error_count_per_channel, NULL);\n}\n\nstatic void umc_v8_10_query_correctable_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t\t   uint32_t umc_reg_offset,\n\t\t\t\t\t\t   unsigned long *error_count)\n{\n\tuint64_t mc_umc_status;\n\tuint32_t mc_umc_status_addr;\n\n\t \n\tmc_umc_status_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, regMCA_UMC_UMC0_MCUMC_STATUST0);\n\n\t \n\tmc_umc_status = RREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4);\n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, CECC) == 1)\n\t\t*error_count += 1;\n}\n\nstatic void umc_v8_10_query_uncorrectable_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t\t      uint32_t umc_reg_offset,\n\t\t\t\t\t\t      unsigned long *error_count)\n{\n\tuint64_t mc_umc_status;\n\tuint32_t mc_umc_status_addr;\n\n\tmc_umc_status_addr = SOC15_REG_OFFSET(UMC, 0, regMCA_UMC_UMC0_MCUMC_STATUST0);\n\n\t \n\tmc_umc_status = RREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4);\n\tif ((REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1) &&\n\t    (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Deferred) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, PCC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, TCC) == 1))\n\t\t*error_count += 1;\n}\n\nstatic int umc_v8_10_query_ecc_error_count(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t node_inst, uint32_t umc_inst,\n\t\t\t\t\tuint32_t ch_inst, void *data)\n{\n\tstruct ras_err_data *err_data = (struct ras_err_data *)data;\n\tuint32_t umc_reg_offset =\n\t\tget_umc_v8_10_reg_offset(adev, node_inst, umc_inst, ch_inst);\n\n\tumc_v8_10_query_correctable_error_count(adev,\n\t\t\t\t\tumc_reg_offset,\n\t\t\t\t\t&(err_data->ce_count));\n\tumc_v8_10_query_uncorrectable_error_count(adev,\n\t\t\t\t\tumc_reg_offset,\n\t\t\t\t\t&(err_data->ue_count));\n\n\treturn 0;\n}\n\nstatic void umc_v8_10_query_ras_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t   void *ras_error_status)\n{\n\tamdgpu_umc_loop_channels(adev,\n\t\tumc_v8_10_query_ecc_error_count, ras_error_status);\n\n\tumc_v8_10_clear_error_count(adev);\n}\n\nstatic uint32_t umc_v8_10_get_col_bit(uint32_t channel_num)\n{\n\tuint32_t t = 0;\n\n\tfor (t = 0; t < ARRAY_SIZE(umc_v8_10_channelnum_map_colbit_table); t++)\n\t\tif (channel_num == umc_v8_10_channelnum_map_colbit_table[t].channel_num)\n\t\t\treturn umc_v8_10_channelnum_map_colbit_table[t].col_bit;\n\n\t \n\treturn U32_MAX;\n}\n\n \nstatic int umc_v8_10_swizzle_mode_na_to_pa(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t channel_idx,\n\t\t\t\t\tuint64_t na, uint64_t *soc_pa)\n{\n\tuint32_t channel_num = UMC_V8_10_TOTAL_CHANNEL_NUM(adev);\n\tuint32_t col_bit = umc_v8_10_get_col_bit(channel_num);\n\tuint64_t tmp_addr;\n\n\tif (col_bit == U32_MAX)\n\t\treturn -1;\n\n\ttmp_addr = SWIZZLE_MODE_TMP_ADDR(na, channel_num, channel_idx);\n\t*soc_pa = SWIZZLE_MODE_ADDR_HI(tmp_addr, col_bit) |\n\t\tSWIZZLE_MODE_ADDR_MID(na, col_bit) |\n\t\tSWIZZLE_MODE_ADDR_LOW(tmp_addr, col_bit) |\n\t\tSWIZZLE_MODE_ADDR_LSB(na);\n\n\treturn 0;\n}\n\nstatic void umc_v8_10_convert_error_address(struct amdgpu_device *adev,\n\t\t\t\t\t    struct ras_err_data *err_data, uint64_t err_addr,\n\t\t\t\t\t    uint32_t ch_inst, uint32_t umc_inst,\n\t\t\t\t\t    uint32_t node_inst, uint64_t mc_umc_status)\n{\n\tuint64_t na_err_addr_base;\n\tuint64_t na_err_addr, retired_page_addr;\n\tuint32_t channel_index, addr_lsb, col = 0;\n\tint ret = 0;\n\n\tchannel_index =\n\t\tadev->umc.channel_idx_tbl[node_inst * adev->umc.umc_inst_num *\n\t\t\t\t\tadev->umc.channel_inst_num +\n\t\t\t\t\tumc_inst * adev->umc.channel_inst_num +\n\t\t\t\t\tch_inst];\n\n\t \n\taddr_lsb = REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, AddrLsb);\n\terr_addr &= ~((0x1ULL << addr_lsb) - 1);\n\tna_err_addr_base = err_addr & ~(0x3ULL << UMC_V8_10_NA_C5_BIT);\n\n\t \n\tfor (col = 0; col < UMC_V8_10_NA_COL_2BITS_POWER_OF_2_NUM; col++) {\n\t\tna_err_addr = na_err_addr_base | (col << UMC_V8_10_NA_C5_BIT);\n\n\t\t \n\t\tret = umc_v8_10_swizzle_mode_na_to_pa(adev, channel_index,\n\t\t\t\t\t\tna_err_addr, &retired_page_addr);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"Failed to map pa from umc na.\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tdev_info(adev->dev, \"Error Address(PA): 0x%llx\\n\",\n\t\t\tretired_page_addr);\n\t\tamdgpu_umc_fill_error_record(err_data, na_err_addr,\n\t\t\t\tretired_page_addr, channel_index, umc_inst);\n\t}\n}\n\nstatic int umc_v8_10_query_error_address(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t node_inst, uint32_t umc_inst,\n\t\t\t\t\tuint32_t ch_inst, void *data)\n{\n\tuint64_t mc_umc_status_addr;\n\tuint64_t mc_umc_status, err_addr;\n\tuint64_t mc_umc_addrt0;\n\tstruct ras_err_data *err_data = (struct ras_err_data *)data;\n\tuint32_t umc_reg_offset =\n\t\tget_umc_v8_10_reg_offset(adev, node_inst, umc_inst, ch_inst);\n\n\tmc_umc_status_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, regMCA_UMC_UMC0_MCUMC_STATUST0);\n\tmc_umc_status = RREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4);\n\n\tif (mc_umc_status == 0)\n\t\treturn 0;\n\n\tif (!err_data->err_addr) {\n\t\t \n\t\tWREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4, 0x0ULL);\n\t\treturn 0;\n\t}\n\n\t \n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, AddrV) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1) {\n\n\t\tmc_umc_addrt0 = SOC15_REG_OFFSET(UMC, 0, regMCA_UMC_UMC0_MCUMC_ADDRT0);\n\t\terr_addr = RREG64_PCIE((mc_umc_addrt0 + umc_reg_offset) * 4);\n\t\terr_addr = REG_GET_FIELD(err_addr, MCA_UMC_UMC0_MCUMC_ADDRT0, ErrorAddr);\n\n\t\tumc_v8_10_convert_error_address(adev, err_data, err_addr,\n\t\t\t\t\tch_inst, umc_inst, node_inst, mc_umc_status);\n\t}\n\n\t \n\tWREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4, 0x0ULL);\n\n\treturn 0;\n}\n\nstatic void umc_v8_10_query_ras_error_address(struct amdgpu_device *adev,\n\t\t\t\t\t     void *ras_error_status)\n{\n\tamdgpu_umc_loop_channels(adev,\n\t\tumc_v8_10_query_error_address, ras_error_status);\n}\n\nstatic int umc_v8_10_err_cnt_init_per_channel(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t node_inst, uint32_t umc_inst,\n\t\t\t\t\tuint32_t ch_inst, void *data)\n{\n\tuint32_t ecc_err_cnt_sel, ecc_err_cnt_sel_addr;\n\tuint32_t ecc_err_cnt_addr;\n\tuint32_t umc_reg_offset =\n\t\tget_umc_v8_10_reg_offset(adev, node_inst, umc_inst, ch_inst);\n\n\tecc_err_cnt_sel_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, regUMCCH0_0_GeccErrCntSel);\n\tecc_err_cnt_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, regUMCCH0_0_GeccErrCnt);\n\n\tecc_err_cnt_sel = RREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4);\n\n\t \n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel, UMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrInt, 0x1);\n\tWREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4, ecc_err_cnt_sel);\n\t \n\tWREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4, UMC_V8_10_CE_CNT_INIT);\n\n\treturn 0;\n}\n\nstatic void umc_v8_10_err_cnt_init(struct amdgpu_device *adev)\n{\n\tamdgpu_umc_loop_channels(adev,\n\t\tumc_v8_10_err_cnt_init_per_channel, NULL);\n}\n\nstatic bool umc_v8_10_query_ras_poison_mode(struct amdgpu_device *adev)\n{\n\t \n\treturn true;\n}\n\nstatic void umc_v8_10_ecc_info_query_correctable_error_count(struct amdgpu_device *adev,\n\t\t\t\t      uint32_t node_inst, uint32_t umc_inst, uint32_t ch_inst,\n\t\t\t\t      unsigned long *error_count)\n{\n\tuint64_t mc_umc_status;\n\tuint32_t eccinfo_table_idx;\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\n\teccinfo_table_idx = node_inst * adev->umc.umc_inst_num *\n\t\t\t\t  adev->umc.channel_inst_num +\n\t\t\t\t  umc_inst * adev->umc.channel_inst_num +\n\t\t\t\t  ch_inst;\n\n\t \n\tmc_umc_status = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_status;\n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, CECC) == 1) {\n\t\t*error_count += 1;\n\t}\n}\n\nstatic void umc_v8_10_ecc_info_query_uncorrectable_error_count(struct amdgpu_device *adev,\n\t\t\t\t      uint32_t node_inst, uint32_t umc_inst, uint32_t ch_inst,\n\t\t\t\t      unsigned long *error_count)\n{\n\tuint64_t mc_umc_status;\n\tuint32_t eccinfo_table_idx;\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\n\teccinfo_table_idx = node_inst * adev->umc.umc_inst_num *\n\t\t\t\t  adev->umc.channel_inst_num +\n\t\t\t\t  umc_inst * adev->umc.channel_inst_num +\n\t\t\t\t  ch_inst;\n\n\t \n\tmc_umc_status = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_status;\n\tif ((REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1) &&\n\t    (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Deferred) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, PCC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, TCC) == 1)) {\n\t\t*error_count += 1;\n\t}\n}\n\nstatic int umc_v8_10_ecc_info_query_ecc_error_count(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t node_inst, uint32_t umc_inst,\n\t\t\t\t\tuint32_t ch_inst, void *data)\n{\n\tstruct ras_err_data *err_data = (struct ras_err_data *)data;\n\n\tumc_v8_10_ecc_info_query_correctable_error_count(adev,\n\t\t\t\t\tnode_inst, umc_inst, ch_inst,\n\t\t\t\t\t&(err_data->ce_count));\n\tumc_v8_10_ecc_info_query_uncorrectable_error_count(adev,\n\t\t\t\t\tnode_inst, umc_inst, ch_inst,\n\t\t\t\t\t&(err_data->ue_count));\n\treturn 0;\n}\n\nstatic void umc_v8_10_ecc_info_query_ras_error_count(struct amdgpu_device *adev,\n\t\t\t\t\tvoid *ras_error_status)\n{\n\tamdgpu_umc_loop_channels(adev,\n\t\tumc_v8_10_ecc_info_query_ecc_error_count, ras_error_status);\n}\n\nstatic int umc_v8_10_ecc_info_query_error_address(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t node_inst, uint32_t umc_inst,\n\t\t\t\t\tuint32_t ch_inst, void *data)\n{\n\tuint32_t eccinfo_table_idx;\n\tuint64_t mc_umc_status, err_addr;\n\tstruct ras_err_data *err_data = (struct ras_err_data *)data;\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\n\teccinfo_table_idx = node_inst * adev->umc.umc_inst_num *\n\t\t\t\t  adev->umc.channel_inst_num +\n\t\t\t\t  umc_inst * adev->umc.channel_inst_num +\n\t\t\t\t  ch_inst;\n\n\tmc_umc_status = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_status;\n\n\tif (mc_umc_status == 0)\n\t\treturn 0;\n\n\tif (!err_data->err_addr)\n\t\treturn 0;\n\n\t \n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, AddrV) == 1 &&\n\t    (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1)) {\n\n\t\terr_addr = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_addr;\n\t\terr_addr = REG_GET_FIELD(err_addr, MCA_UMC_UMC0_MCUMC_ADDRT0, ErrorAddr);\n\n\t\tumc_v8_10_convert_error_address(adev, err_data, err_addr,\n\t\t\t\t\tch_inst, umc_inst, node_inst, mc_umc_status);\n\t}\n\n\treturn 0;\n}\n\nstatic void umc_v8_10_ecc_info_query_ras_error_address(struct amdgpu_device *adev,\n\t\t\t\t\tvoid *ras_error_status)\n{\n\tamdgpu_umc_loop_channels(adev,\n\t\tumc_v8_10_ecc_info_query_error_address, ras_error_status);\n}\n\nstatic void umc_v8_10_set_eeprom_table_version(struct amdgpu_ras_eeprom_table_header *hdr)\n{\n\thdr->version = RAS_TABLE_VER_V2_1;\n}\n\nconst struct amdgpu_ras_block_hw_ops umc_v8_10_ras_hw_ops = {\n\t.query_ras_error_count = umc_v8_10_query_ras_error_count,\n\t.query_ras_error_address = umc_v8_10_query_ras_error_address,\n};\n\nstruct amdgpu_umc_ras umc_v8_10_ras = {\n\t.ras_block = {\n\t\t.hw_ops = &umc_v8_10_ras_hw_ops,\n\t},\n\t.err_cnt_init = umc_v8_10_err_cnt_init,\n\t.query_ras_poison_mode = umc_v8_10_query_ras_poison_mode,\n\t.ecc_info_query_ras_error_count = umc_v8_10_ecc_info_query_ras_error_count,\n\t.ecc_info_query_ras_error_address = umc_v8_10_ecc_info_query_ras_error_address,\n\t.set_eeprom_table_version = umc_v8_10_set_eeprom_table_version,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}