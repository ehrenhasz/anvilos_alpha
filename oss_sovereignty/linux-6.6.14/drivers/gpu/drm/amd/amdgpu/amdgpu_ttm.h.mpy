{
  "module_name": "amdgpu_ttm.h",
  "hash_id": "ce37c989a8171a7b943f6cba784c6012541119006a785fec047333665cc004c4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.h",
  "human_readable_source": " \n\n#ifndef __AMDGPU_TTM_H__\n#define __AMDGPU_TTM_H__\n\n#include <linux/dma-direction.h>\n#include <drm/gpu_scheduler.h>\n#include \"amdgpu_vram_mgr.h\"\n#include \"amdgpu.h\"\n\n#define AMDGPU_PL_GDS\t\t(TTM_PL_PRIV + 0)\n#define AMDGPU_PL_GWS\t\t(TTM_PL_PRIV + 1)\n#define AMDGPU_PL_OA\t\t(TTM_PL_PRIV + 2)\n#define AMDGPU_PL_PREEMPT\t(TTM_PL_PRIV + 3)\n#define AMDGPU_PL_DOORBELL\t(TTM_PL_PRIV + 4)\n\n#define AMDGPU_GTT_MAX_TRANSFER_SIZE\t512\n#define AMDGPU_GTT_NUM_TRANSFER_WINDOWS\t2\n\n#define AMDGPU_POISON\t0xd0bed0be\n\nextern const struct attribute_group amdgpu_vram_mgr_attr_group;\nextern const struct attribute_group amdgpu_gtt_mgr_attr_group;\n\nstruct hmm_range;\n\nstruct amdgpu_gtt_mgr {\n\tstruct ttm_resource_manager manager;\n\tstruct drm_mm mm;\n\tspinlock_t lock;\n};\n\nstruct amdgpu_mman {\n\tstruct ttm_device\t\tbdev;\n\tstruct ttm_pool\t\t\t*ttm_pools;\n\tbool\t\t\t\tinitialized;\n\tvoid __iomem\t\t\t*aper_base_kaddr;\n\n\t \n\tconst struct amdgpu_buffer_funcs\t*buffer_funcs;\n\tstruct amdgpu_ring\t\t\t*buffer_funcs_ring;\n\tbool\t\t\t\t\tbuffer_funcs_enabled;\n\n\tstruct mutex\t\t\t\tgtt_window_lock;\n\t \n\tstruct drm_sched_entity\t\t\thigh_pr;\n\t \n\tstruct drm_sched_entity\t\t\tlow_pr;\n\n\tstruct amdgpu_vram_mgr vram_mgr;\n\tstruct amdgpu_gtt_mgr gtt_mgr;\n\tstruct ttm_resource_manager preempt_mgr;\n\n\tuint64_t\t\tstolen_vga_size;\n\tstruct amdgpu_bo\t*stolen_vga_memory;\n\tuint64_t\t\tstolen_extended_size;\n\tstruct amdgpu_bo\t*stolen_extended_memory;\n\tbool\t\t\tkeep_stolen_vga_memory;\n\n\tstruct amdgpu_bo\t*stolen_reserved_memory;\n\tuint64_t\t\tstolen_reserved_offset;\n\tuint64_t\t\tstolen_reserved_size;\n\n\t \n\tuint8_t\t\t\t\t*discovery_bin;\n\tuint32_t\t\t\tdiscovery_tmr_size;\n\t \n\tstruct amdgpu_bo\t\t*fw_reserved_memory;\n\n\t \n\tu64\t\tfw_vram_usage_start_offset;\n\tu64\t\tfw_vram_usage_size;\n\tstruct amdgpu_bo\t*fw_vram_usage_reserved_bo;\n\tvoid\t\t*fw_vram_usage_va;\n\n\t \n\tu64\t\tdrv_vram_usage_start_offset;\n\tu64\t\tdrv_vram_usage_size;\n\tstruct amdgpu_bo\t*drv_vram_usage_reserved_bo;\n\tvoid\t\t*drv_vram_usage_va;\n\n\t \n\tstruct amdgpu_bo\t*sdma_access_bo;\n\tvoid\t\t\t*sdma_access_ptr;\n};\n\nstruct amdgpu_copy_mem {\n\tstruct ttm_buffer_object\t*bo;\n\tstruct ttm_resource\t\t*mem;\n\tunsigned long\t\t\toffset;\n};\n\nint amdgpu_gtt_mgr_init(struct amdgpu_device *adev, uint64_t gtt_size);\nvoid amdgpu_gtt_mgr_fini(struct amdgpu_device *adev);\nint amdgpu_preempt_mgr_init(struct amdgpu_device *adev);\nvoid amdgpu_preempt_mgr_fini(struct amdgpu_device *adev);\nint amdgpu_vram_mgr_init(struct amdgpu_device *adev);\nvoid amdgpu_vram_mgr_fini(struct amdgpu_device *adev);\n\nbool amdgpu_gtt_mgr_has_gart_addr(struct ttm_resource *mem);\nvoid amdgpu_gtt_mgr_recover(struct amdgpu_gtt_mgr *mgr);\n\nuint64_t amdgpu_preempt_mgr_usage(struct ttm_resource_manager *man);\n\nu64 amdgpu_vram_mgr_bo_visible_size(struct amdgpu_bo *bo);\nint amdgpu_vram_mgr_alloc_sgt(struct amdgpu_device *adev,\n\t\t\t      struct ttm_resource *mem,\n\t\t\t      u64 offset, u64 size,\n\t\t\t      struct device *dev,\n\t\t\t      enum dma_data_direction dir,\n\t\t\t      struct sg_table **sgt);\nvoid amdgpu_vram_mgr_free_sgt(struct device *dev,\n\t\t\t      enum dma_data_direction dir,\n\t\t\t      struct sg_table *sgt);\nuint64_t amdgpu_vram_mgr_vis_usage(struct amdgpu_vram_mgr *mgr);\nint amdgpu_vram_mgr_reserve_range(struct amdgpu_vram_mgr *mgr,\n\t\t\t\t  uint64_t start, uint64_t size);\nint amdgpu_vram_mgr_query_page_status(struct amdgpu_vram_mgr *mgr,\n\t\t\t\t      uint64_t start);\n\nint amdgpu_ttm_init(struct amdgpu_device *adev);\nvoid amdgpu_ttm_fini(struct amdgpu_device *adev);\nvoid amdgpu_ttm_set_buffer_funcs_status(struct amdgpu_device *adev,\n\t\t\t\t\tbool enable);\n\nint amdgpu_copy_buffer(struct amdgpu_ring *ring, uint64_t src_offset,\n\t\t       uint64_t dst_offset, uint32_t byte_count,\n\t\t       struct dma_resv *resv,\n\t\t       struct dma_fence **fence, bool direct_submit,\n\t\t       bool vm_needs_flush, bool tmz);\nint amdgpu_ttm_copy_mem_to_mem(struct amdgpu_device *adev,\n\t\t\t       const struct amdgpu_copy_mem *src,\n\t\t\t       const struct amdgpu_copy_mem *dst,\n\t\t\t       uint64_t size, bool tmz,\n\t\t\t       struct dma_resv *resv,\n\t\t\t       struct dma_fence **f);\nint amdgpu_fill_buffer(struct amdgpu_bo *bo,\n\t\t\tuint32_t src_data,\n\t\t\tstruct dma_resv *resv,\n\t\t\tstruct dma_fence **fence,\n\t\t\tbool delayed);\n\nint amdgpu_ttm_alloc_gart(struct ttm_buffer_object *bo);\nvoid amdgpu_ttm_recover_gart(struct ttm_buffer_object *tbo);\nuint64_t amdgpu_ttm_domain_start(struct amdgpu_device *adev, uint32_t type);\n\n#if IS_ENABLED(CONFIG_DRM_AMDGPU_USERPTR)\nint amdgpu_ttm_tt_get_user_pages(struct amdgpu_bo *bo, struct page **pages,\n\t\t\t\t struct hmm_range **range);\nvoid amdgpu_ttm_tt_discard_user_pages(struct ttm_tt *ttm,\n\t\t\t\t      struct hmm_range *range);\nbool amdgpu_ttm_tt_get_user_pages_done(struct ttm_tt *ttm,\n\t\t\t\t       struct hmm_range *range);\n#else\nstatic inline int amdgpu_ttm_tt_get_user_pages(struct amdgpu_bo *bo,\n\t\t\t\t\t       struct page **pages,\n\t\t\t\t\t       struct hmm_range **range)\n{\n\treturn -EPERM;\n}\nstatic inline void amdgpu_ttm_tt_discard_user_pages(struct ttm_tt *ttm,\n\t\t\t\t\t\t    struct hmm_range *range)\n{\n}\nstatic inline bool amdgpu_ttm_tt_get_user_pages_done(struct ttm_tt *ttm,\n\t\t\t\t\t\t     struct hmm_range *range)\n{\n\treturn false;\n}\n#endif\n\nvoid amdgpu_ttm_tt_set_user_pages(struct ttm_tt *ttm, struct page **pages);\nint amdgpu_ttm_tt_get_userptr(const struct ttm_buffer_object *tbo,\n\t\t\t      uint64_t *user_addr);\nint amdgpu_ttm_tt_set_userptr(struct ttm_buffer_object *bo,\n\t\t\t      uint64_t addr, uint32_t flags);\nbool amdgpu_ttm_tt_has_userptr(struct ttm_tt *ttm);\nstruct mm_struct *amdgpu_ttm_tt_get_usermm(struct ttm_tt *ttm);\nbool amdgpu_ttm_tt_affect_userptr(struct ttm_tt *ttm, unsigned long start,\n\t\t\t\t  unsigned long end, unsigned long *userptr);\nbool amdgpu_ttm_tt_userptr_invalidated(struct ttm_tt *ttm,\n\t\t\t\t       int *last_invalidated);\nbool amdgpu_ttm_tt_is_userptr(struct ttm_tt *ttm);\nbool amdgpu_ttm_tt_is_readonly(struct ttm_tt *ttm);\nuint64_t amdgpu_ttm_tt_pde_flags(struct ttm_tt *ttm, struct ttm_resource *mem);\nuint64_t amdgpu_ttm_tt_pte_flags(struct amdgpu_device *adev, struct ttm_tt *ttm,\n\t\t\t\t struct ttm_resource *mem);\nint amdgpu_ttm_evict_resources(struct amdgpu_device *adev, int mem_type);\n\nvoid amdgpu_ttm_debugfs_init(struct amdgpu_device *adev);\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}