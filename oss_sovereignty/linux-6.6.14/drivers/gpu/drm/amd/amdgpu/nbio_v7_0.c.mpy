{
  "module_name": "nbio_v7_0.c",
  "hash_id": "fc770d9b2453826114db8d147c6ef753702a5a2de6eb1f52ec35a9571736df91",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/nbio_v7_0.c",
  "human_readable_source": " \n#include \"amdgpu.h\"\n#include \"amdgpu_atombios.h\"\n#include \"nbio_v7_0.h\"\n\n#include \"nbio/nbio_7_0_default.h\"\n#include \"nbio/nbio_7_0_offset.h\"\n#include \"nbio/nbio_7_0_sh_mask.h\"\n#include \"nbio/nbio_7_0_smn.h\"\n#include \"vega10_enum.h\"\n#include <uapi/linux/kfd_ioctl.h>\n\n#define smnNBIF_MGCG_CTRL_LCLK\t0x1013a05c\n\nstatic void nbio_v7_0_remap_hdp_registers(struct amdgpu_device *adev)\n{\n\tWREG32_SOC15(NBIO, 0, mmREMAP_HDP_MEM_FLUSH_CNTL,\n\t\tadev->rmmio_remap.reg_offset + KFD_MMIO_REMAP_HDP_MEM_FLUSH_CNTL);\n\tWREG32_SOC15(NBIO, 0, mmREMAP_HDP_REG_FLUSH_CNTL,\n\t\tadev->rmmio_remap.reg_offset + KFD_MMIO_REMAP_HDP_REG_FLUSH_CNTL);\n}\n\nstatic u32 nbio_v7_0_get_rev_id(struct amdgpu_device *adev)\n{\n\tu32 tmp = RREG32_SOC15(NBIO, 0, mmRCC_DEV0_EPF0_STRAP0);\n\n\ttmp &= RCC_DEV0_EPF0_STRAP0__STRAP_ATI_REV_ID_DEV0_F0_MASK;\n\ttmp >>= RCC_DEV0_EPF0_STRAP0__STRAP_ATI_REV_ID_DEV0_F0__SHIFT;\n\n\treturn tmp;\n}\n\nstatic void nbio_v7_0_mc_access_enable(struct amdgpu_device *adev, bool enable)\n{\n\tif (enable)\n\t\tWREG32_SOC15(NBIO, 0, mmBIF_FB_EN,\n\t\t\tBIF_FB_EN__FB_READ_EN_MASK | BIF_FB_EN__FB_WRITE_EN_MASK);\n\telse\n\t\tWREG32_SOC15(NBIO, 0, mmBIF_FB_EN, 0);\n}\n\nstatic u32 nbio_v7_0_get_memsize(struct amdgpu_device *adev)\n{\n\treturn RREG32_SOC15(NBIO, 0, mmRCC_CONFIG_MEMSIZE);\n}\n\nstatic void nbio_v7_0_sdma_doorbell_range(struct amdgpu_device *adev, int instance,\n\t\t\tbool use_doorbell, int doorbell_index, int doorbell_size)\n{\n\tu32 reg = instance == 0 ? SOC15_REG_OFFSET(NBIO, 0, mmBIF_SDMA0_DOORBELL_RANGE) :\n\t\t\tSOC15_REG_OFFSET(NBIO, 0, mmBIF_SDMA1_DOORBELL_RANGE);\n\n\tu32 doorbell_range = RREG32(reg);\n\n\tif (use_doorbell) {\n\t\tdoorbell_range = REG_SET_FIELD(doorbell_range, BIF_SDMA0_DOORBELL_RANGE, OFFSET, doorbell_index);\n\t\tdoorbell_range = REG_SET_FIELD(doorbell_range, BIF_SDMA0_DOORBELL_RANGE, SIZE, doorbell_size);\n\t} else\n\t\tdoorbell_range = REG_SET_FIELD(doorbell_range, BIF_SDMA0_DOORBELL_RANGE, SIZE, 0);\n\n\tWREG32(reg, doorbell_range);\n}\n\nstatic void nbio_v7_0_vcn_doorbell_range(struct amdgpu_device *adev, bool use_doorbell,\n\t\t\t\t\t int doorbell_index, int instance)\n{\n\tu32 reg = SOC15_REG_OFFSET(NBIO, 0, mmBIF_MMSCH0_DOORBELL_RANGE);\n\n\tu32 doorbell_range = RREG32(reg);\n\n\tif (use_doorbell) {\n\t\tdoorbell_range = REG_SET_FIELD(doorbell_range,\n\t\t\t\t\t       BIF_MMSCH0_DOORBELL_RANGE, OFFSET,\n\t\t\t\t\t       doorbell_index);\n\t\tdoorbell_range = REG_SET_FIELD(doorbell_range,\n\t\t\t\t\t       BIF_MMSCH0_DOORBELL_RANGE, SIZE, 8);\n\t} else\n\t\tdoorbell_range = REG_SET_FIELD(doorbell_range,\n\t\t\t\t\t       BIF_MMSCH0_DOORBELL_RANGE, SIZE, 0);\n\n\tWREG32(reg, doorbell_range);\n}\n\nstatic void nbio_v7_0_enable_doorbell_aperture(struct amdgpu_device *adev,\n\t\t\t\t\t       bool enable)\n{\n\tWREG32_FIELD15(NBIO, 0, RCC_DOORBELL_APER_EN, BIF_DOORBELL_APER_EN, enable ? 1 : 0);\n}\n\nstatic void nbio_v7_0_enable_doorbell_selfring_aperture(struct amdgpu_device *adev,\n\t\t\t\t\t\t\tbool enable)\n{\n\n}\n\nstatic void nbio_v7_0_ih_doorbell_range(struct amdgpu_device *adev,\n\t\t\t\t\tbool use_doorbell, int doorbell_index)\n{\n\tu32 ih_doorbell_range = RREG32_SOC15(NBIO, 0, mmBIF_IH_DOORBELL_RANGE);\n\n\tif (use_doorbell) {\n\t\tih_doorbell_range = REG_SET_FIELD(ih_doorbell_range, BIF_IH_DOORBELL_RANGE, OFFSET, doorbell_index);\n\t\tih_doorbell_range = REG_SET_FIELD(ih_doorbell_range, BIF_IH_DOORBELL_RANGE, SIZE, 2);\n\t} else\n\t\tih_doorbell_range = REG_SET_FIELD(ih_doorbell_range, BIF_IH_DOORBELL_RANGE, SIZE, 0);\n\n\tWREG32_SOC15(NBIO, 0, mmBIF_IH_DOORBELL_RANGE, ih_doorbell_range);\n}\n\nstatic uint32_t nbio_7_0_read_syshub_ind_mmr(struct amdgpu_device *adev, uint32_t offset)\n{\n\tuint32_t data;\n\n\tWREG32_SOC15(NBIO, 0, mmSYSHUB_INDEX, offset);\n\tdata = RREG32_SOC15(NBIO, 0, mmSYSHUB_DATA);\n\n\treturn data;\n}\n\nstatic void nbio_7_0_write_syshub_ind_mmr(struct amdgpu_device *adev, uint32_t offset,\n\t\t\t\t       uint32_t data)\n{\n\tWREG32_SOC15(NBIO, 0, mmSYSHUB_INDEX, offset);\n\tWREG32_SOC15(NBIO, 0, mmSYSHUB_DATA, data);\n}\n\nstatic void nbio_v7_0_update_medium_grain_clock_gating(struct amdgpu_device *adev,\n\t\t\t\t\t\t       bool enable)\n{\n\tuint32_t def, data;\n\n\t \n\tdef = data = RREG32_PCIE(smnNBIF_MGCG_CTRL_LCLK);\n\n\tif (enable && (adev->cg_flags & AMD_CG_SUPPORT_BIF_MGCG))\n\t\tdata |= NBIF_MGCG_CTRL_LCLK__NBIF_MGCG_EN_LCLK_MASK;\n\telse\n\t\tdata &= ~NBIF_MGCG_CTRL_LCLK__NBIF_MGCG_EN_LCLK_MASK;\n\n\tif (def != data)\n\t\tWREG32_PCIE(smnNBIF_MGCG_CTRL_LCLK, data);\n\n\t \n\tdef = data = nbio_7_0_read_syshub_ind_mmr(adev, ixSYSHUB_MMREG_IND_SYSHUB_MGCG_CTRL_SOCCLK);\n\n\tif (enable && (adev->cg_flags & AMD_CG_SUPPORT_BIF_MGCG))\n\t\tdata |= SYSHUB_MMREG_DIRECT_SYSHUB_MGCG_CTRL_SOCCLK__SYSHUB_MGCG_EN_SOCCLK_MASK;\n\telse\n\t\tdata &= ~SYSHUB_MMREG_DIRECT_SYSHUB_MGCG_CTRL_SOCCLK__SYSHUB_MGCG_EN_SOCCLK_MASK;\n\n\tif (def != data)\n\t\tnbio_7_0_write_syshub_ind_mmr(adev, ixSYSHUB_MMREG_IND_SYSHUB_MGCG_CTRL_SOCCLK, data);\n\n\t \n\tdef = data = nbio_7_0_read_syshub_ind_mmr(adev, ixSYSHUB_MMREG_IND_SYSHUB_MGCG_CTRL_SHUBCLK);\n\n\tif (enable && (adev->cg_flags & AMD_CG_SUPPORT_BIF_MGCG))\n\t\tdata |= SYSHUB_MMREG_DIRECT_SYSHUB_MGCG_CTRL_SHUBCLK__SYSHUB_MGCG_EN_SHUBCLK_MASK;\n\telse\n\t\tdata &= ~SYSHUB_MMREG_DIRECT_SYSHUB_MGCG_CTRL_SHUBCLK__SYSHUB_MGCG_EN_SHUBCLK_MASK;\n\n\tif (def != data)\n\t\tnbio_7_0_write_syshub_ind_mmr(adev, ixSYSHUB_MMREG_IND_SYSHUB_MGCG_CTRL_SHUBCLK, data);\n}\n\nstatic void nbio_v7_0_update_medium_grain_light_sleep(struct amdgpu_device *adev,\n\t\t\t\t\t\t      bool enable)\n{\n\tuint32_t def, data;\n\n\tdef = data = RREG32_PCIE(smnPCIE_CNTL2);\n\tif (enable && (adev->cg_flags & AMD_CG_SUPPORT_BIF_LS)) {\n\t\tdata |= (PCIE_CNTL2__SLV_MEM_LS_EN_MASK |\n\t\t\t PCIE_CNTL2__MST_MEM_LS_EN_MASK |\n\t\t\t PCIE_CNTL2__REPLAY_MEM_LS_EN_MASK);\n\t} else {\n\t\tdata &= ~(PCIE_CNTL2__SLV_MEM_LS_EN_MASK |\n\t\t\t  PCIE_CNTL2__MST_MEM_LS_EN_MASK |\n\t\t\t  PCIE_CNTL2__REPLAY_MEM_LS_EN_MASK);\n\t}\n\n\tif (def != data)\n\t\tWREG32_PCIE(smnPCIE_CNTL2, data);\n}\n\nstatic void nbio_v7_0_get_clockgating_state(struct amdgpu_device *adev,\n\t\t\t\t\t    u64 *flags)\n{\n\tint data;\n\n\t \n\tdata = RREG32_PCIE(smnCPM_CONTROL);\n\tif (data & CPM_CONTROL__LCLK_DYN_GATE_ENABLE_MASK)\n\t\t*flags |= AMD_CG_SUPPORT_BIF_MGCG;\n\n\t \n\tdata = RREG32_PCIE(smnPCIE_CNTL2);\n\tif (data & PCIE_CNTL2__SLV_MEM_LS_EN_MASK)\n\t\t*flags |= AMD_CG_SUPPORT_BIF_LS;\n}\n\nstatic void nbio_v7_0_ih_control(struct amdgpu_device *adev)\n{\n\tu32 interrupt_cntl;\n\n\t \n\tWREG32_SOC15(NBIO, 0, mmINTERRUPT_CNTL2, adev->dummy_page_addr >> 8);\n\tinterrupt_cntl = RREG32_SOC15(NBIO, 0, mmINTERRUPT_CNTL);\n\t \n\tinterrupt_cntl = REG_SET_FIELD(interrupt_cntl, INTERRUPT_CNTL, IH_DUMMY_RD_OVERRIDE, 0);\n\t \n\tinterrupt_cntl = REG_SET_FIELD(interrupt_cntl, INTERRUPT_CNTL, IH_REQ_NONSNOOP_EN, 0);\n\tWREG32_SOC15(NBIO, 0, mmINTERRUPT_CNTL, interrupt_cntl);\n}\n\nstatic u32 nbio_v7_0_get_hdp_flush_req_offset(struct amdgpu_device *adev)\n{\n\treturn SOC15_REG_OFFSET(NBIO, 0, mmGPU_HDP_FLUSH_REQ);\n}\n\nstatic u32 nbio_v7_0_get_hdp_flush_done_offset(struct amdgpu_device *adev)\n{\n\treturn SOC15_REG_OFFSET(NBIO, 0, mmGPU_HDP_FLUSH_DONE);\n}\n\nstatic u32 nbio_v7_0_get_pcie_index_offset(struct amdgpu_device *adev)\n{\n\treturn SOC15_REG_OFFSET(NBIO, 0, mmPCIE_INDEX2);\n}\n\nstatic u32 nbio_v7_0_get_pcie_data_offset(struct amdgpu_device *adev)\n{\n\treturn SOC15_REG_OFFSET(NBIO, 0, mmPCIE_DATA2);\n}\n\nconst struct nbio_hdp_flush_reg nbio_v7_0_hdp_flush_reg = {\n\t.ref_and_mask_cp0 = GPU_HDP_FLUSH_DONE__CP0_MASK,\n\t.ref_and_mask_cp1 = GPU_HDP_FLUSH_DONE__CP1_MASK,\n\t.ref_and_mask_cp2 = GPU_HDP_FLUSH_DONE__CP2_MASK,\n\t.ref_and_mask_cp3 = GPU_HDP_FLUSH_DONE__CP3_MASK,\n\t.ref_and_mask_cp4 = GPU_HDP_FLUSH_DONE__CP4_MASK,\n\t.ref_and_mask_cp5 = GPU_HDP_FLUSH_DONE__CP5_MASK,\n\t.ref_and_mask_cp6 = GPU_HDP_FLUSH_DONE__CP6_MASK,\n\t.ref_and_mask_cp7 = GPU_HDP_FLUSH_DONE__CP7_MASK,\n\t.ref_and_mask_cp8 = GPU_HDP_FLUSH_DONE__CP8_MASK,\n\t.ref_and_mask_cp9 = GPU_HDP_FLUSH_DONE__CP9_MASK,\n\t.ref_and_mask_sdma0 = GPU_HDP_FLUSH_DONE__SDMA0_MASK,\n\t.ref_and_mask_sdma1 = GPU_HDP_FLUSH_DONE__SDMA1_MASK,\n};\n\nstatic void nbio_v7_0_init_registers(struct amdgpu_device *adev)\n{\n\tif (amdgpu_sriov_vf(adev))\n\t\tadev->rmmio_remap.reg_offset =\n\t\t\tSOC15_REG_OFFSET(NBIO, 0, mmHDP_MEM_COHERENCY_FLUSH_CNTL) << 2;\n}\n\nconst struct amdgpu_nbio_funcs nbio_v7_0_funcs = {\n\t.get_hdp_flush_req_offset = nbio_v7_0_get_hdp_flush_req_offset,\n\t.get_hdp_flush_done_offset = nbio_v7_0_get_hdp_flush_done_offset,\n\t.get_pcie_index_offset = nbio_v7_0_get_pcie_index_offset,\n\t.get_pcie_data_offset = nbio_v7_0_get_pcie_data_offset,\n\t.get_rev_id = nbio_v7_0_get_rev_id,\n\t.mc_access_enable = nbio_v7_0_mc_access_enable,\n\t.get_memsize = nbio_v7_0_get_memsize,\n\t.sdma_doorbell_range = nbio_v7_0_sdma_doorbell_range,\n\t.vcn_doorbell_range = nbio_v7_0_vcn_doorbell_range,\n\t.enable_doorbell_aperture = nbio_v7_0_enable_doorbell_aperture,\n\t.enable_doorbell_selfring_aperture = nbio_v7_0_enable_doorbell_selfring_aperture,\n\t.ih_doorbell_range = nbio_v7_0_ih_doorbell_range,\n\t.update_medium_grain_clock_gating = nbio_v7_0_update_medium_grain_clock_gating,\n\t.update_medium_grain_light_sleep = nbio_v7_0_update_medium_grain_light_sleep,\n\t.get_clockgating_state = nbio_v7_0_get_clockgating_state,\n\t.ih_control = nbio_v7_0_ih_control,\n\t.init_registers = nbio_v7_0_init_registers,\n\t.remap_hdp_registers = nbio_v7_0_remap_hdp_registers,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}