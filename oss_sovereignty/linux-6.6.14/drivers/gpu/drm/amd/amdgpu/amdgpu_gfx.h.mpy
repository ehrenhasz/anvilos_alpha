{
  "module_name": "amdgpu_gfx.h",
  "hash_id": "3e6fdc268bffcb92863a181be48510897d877430de5e962b7daad3ca56a7370a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_gfx.h",
  "human_readable_source": " \n\n#ifndef __AMDGPU_GFX_H__\n#define __AMDGPU_GFX_H__\n\n \n#include \"clearstate_defs.h\"\n#include \"amdgpu_ring.h\"\n#include \"amdgpu_rlc.h\"\n#include \"amdgpu_imu.h\"\n#include \"soc15.h\"\n#include \"amdgpu_ras.h\"\n#include \"amdgpu_ring_mux.h\"\n\n \n#define AMDGPU_GFX_NORMAL_MODE\t\t\t0x00000000L\n#define AMDGPU_GFX_SAFE_MODE\t\t\t0x00000001L\n#define AMDGPU_GFX_PG_DISABLED_MODE\t\t0x00000002L\n#define AMDGPU_GFX_CG_DISABLED_MODE\t\t0x00000004L\n#define AMDGPU_GFX_LBPW_DISABLED_MODE\t\t0x00000008L\n\n#define AMDGPU_MAX_GC_INSTANCES\t\t8\n#define KGD_MAX_QUEUES\t\t\t128\n\n#define AMDGPU_MAX_GFX_QUEUES KGD_MAX_QUEUES\n#define AMDGPU_MAX_COMPUTE_QUEUES KGD_MAX_QUEUES\n\nenum amdgpu_gfx_pipe_priority {\n\tAMDGPU_GFX_PIPE_PRIO_NORMAL = AMDGPU_RING_PRIO_1,\n\tAMDGPU_GFX_PIPE_PRIO_HIGH = AMDGPU_RING_PRIO_2\n};\n\n#define AMDGPU_GFX_QUEUE_PRIORITY_MINIMUM  0\n#define AMDGPU_GFX_QUEUE_PRIORITY_MAXIMUM  15\n\nenum amdgpu_gfx_partition {\n\tAMDGPU_SPX_PARTITION_MODE = 0,\n\tAMDGPU_DPX_PARTITION_MODE = 1,\n\tAMDGPU_TPX_PARTITION_MODE = 2,\n\tAMDGPU_QPX_PARTITION_MODE = 3,\n\tAMDGPU_CPX_PARTITION_MODE = 4,\n\tAMDGPU_UNKNOWN_COMPUTE_PARTITION_MODE = -1,\n\t \n\tAMDGPU_AUTO_COMPUTE_PARTITION_MODE = -2,\n};\n\n#define NUM_XCC(x) hweight16(x)\n\nenum amdgpu_pkg_type {\n\tAMDGPU_PKG_TYPE_APU = 2,\n\tAMDGPU_PKG_TYPE_UNKNOWN,\n};\n\nenum amdgpu_gfx_ras_mem_id_type {\n\tAMDGPU_GFX_CP_MEM = 0,\n\tAMDGPU_GFX_GCEA_MEM,\n\tAMDGPU_GFX_GC_CANE_MEM,\n\tAMDGPU_GFX_GCUTCL2_MEM,\n\tAMDGPU_GFX_GDS_MEM,\n\tAMDGPU_GFX_LDS_MEM,\n\tAMDGPU_GFX_RLC_MEM,\n\tAMDGPU_GFX_SP_MEM,\n\tAMDGPU_GFX_SPI_MEM,\n\tAMDGPU_GFX_SQC_MEM,\n\tAMDGPU_GFX_SQ_MEM,\n\tAMDGPU_GFX_TA_MEM,\n\tAMDGPU_GFX_TCC_MEM,\n\tAMDGPU_GFX_TCA_MEM,\n\tAMDGPU_GFX_TCI_MEM,\n\tAMDGPU_GFX_TCP_MEM,\n\tAMDGPU_GFX_TD_MEM,\n\tAMDGPU_GFX_TCX_MEM,\n\tAMDGPU_GFX_ATC_L2_MEM,\n\tAMDGPU_GFX_UTCL2_MEM,\n\tAMDGPU_GFX_VML2_MEM,\n\tAMDGPU_GFX_VML2_WALKER_MEM,\n\tAMDGPU_GFX_MEM_TYPE_NUM\n};\n\nstruct amdgpu_mec {\n\tstruct amdgpu_bo\t*hpd_eop_obj;\n\tu64\t\t\thpd_eop_gpu_addr;\n\tstruct amdgpu_bo\t*mec_fw_obj;\n\tu64\t\t\tmec_fw_gpu_addr;\n\tstruct amdgpu_bo\t*mec_fw_data_obj;\n\tu64\t\t\tmec_fw_data_gpu_addr;\n\n\tu32 num_mec;\n\tu32 num_pipe_per_mec;\n\tu32 num_queue_per_pipe;\n\tvoid\t\t\t*mqd_backup[AMDGPU_MAX_COMPUTE_RINGS * AMDGPU_MAX_GC_INSTANCES];\n};\n\nstruct amdgpu_mec_bitmap {\n\t \n\tDECLARE_BITMAP(queue_bitmap, AMDGPU_MAX_COMPUTE_QUEUES);\n};\n\nenum amdgpu_unmap_queues_action {\n\tPREEMPT_QUEUES = 0,\n\tRESET_QUEUES,\n\tDISABLE_PROCESS_QUEUES,\n\tPREEMPT_QUEUES_NO_UNMAP,\n};\n\nstruct kiq_pm4_funcs {\n\t \n\tvoid (*kiq_set_resources)(struct amdgpu_ring *kiq_ring,\n\t\t\t\t\tuint64_t queue_mask);\n\tvoid (*kiq_map_queues)(struct amdgpu_ring *kiq_ring,\n\t\t\t\t\tstruct amdgpu_ring *ring);\n\tvoid (*kiq_unmap_queues)(struct amdgpu_ring *kiq_ring,\n\t\t\t\t struct amdgpu_ring *ring,\n\t\t\t\t enum amdgpu_unmap_queues_action action,\n\t\t\t\t u64 gpu_addr, u64 seq);\n\tvoid (*kiq_query_status)(struct amdgpu_ring *kiq_ring,\n\t\t\t\t\tstruct amdgpu_ring *ring,\n\t\t\t\t\tu64 addr,\n\t\t\t\t\tu64 seq);\n\tvoid (*kiq_invalidate_tlbs)(struct amdgpu_ring *kiq_ring,\n\t\t\t\tuint16_t pasid, uint32_t flush_type,\n\t\t\t\tbool all_hub);\n\t \n\tint set_resources_size;\n\tint map_queues_size;\n\tint unmap_queues_size;\n\tint query_status_size;\n\tint invalidate_tlbs_size;\n};\n\nstruct amdgpu_kiq {\n\tu64\t\t\teop_gpu_addr;\n\tstruct amdgpu_bo\t*eop_obj;\n\tspinlock_t              ring_lock;\n\tstruct amdgpu_ring\tring;\n\tstruct amdgpu_irq_src\tirq;\n\tconst struct kiq_pm4_funcs *pmf;\n\tvoid\t\t\t*mqd_backup;\n};\n\n \n#define AMDGPU_GFX_MAX_SE 4\n#define AMDGPU_GFX_MAX_SH_PER_SE 2\n\nstruct amdgpu_rb_config {\n\tuint32_t rb_backend_disable;\n\tuint32_t user_rb_backend_disable;\n\tuint32_t raster_config;\n\tuint32_t raster_config_1;\n};\n\nstruct gb_addr_config {\n\tuint16_t pipe_interleave_size;\n\tuint8_t num_pipes;\n\tuint8_t max_compress_frags;\n\tuint8_t num_banks;\n\tuint8_t num_se;\n\tuint8_t num_rb_per_se;\n\tuint8_t num_pkrs;\n};\n\nstruct amdgpu_gfx_config {\n\tunsigned max_shader_engines;\n\tunsigned max_tile_pipes;\n\tunsigned max_cu_per_sh;\n\tunsigned max_sh_per_se;\n\tunsigned max_backends_per_se;\n\tunsigned max_texture_channel_caches;\n\tunsigned max_gprs;\n\tunsigned max_gs_threads;\n\tunsigned max_hw_contexts;\n\tunsigned sc_prim_fifo_size_frontend;\n\tunsigned sc_prim_fifo_size_backend;\n\tunsigned sc_hiz_tile_fifo_size;\n\tunsigned sc_earlyz_tile_fifo_size;\n\n\tunsigned num_tile_pipes;\n\tunsigned backend_enable_mask;\n\tunsigned mem_max_burst_length_bytes;\n\tunsigned mem_row_size_in_kb;\n\tunsigned shader_engine_tile_size;\n\tunsigned num_gpus;\n\tunsigned multi_gpu_tile_size;\n\tunsigned mc_arb_ramcfg;\n\tunsigned num_banks;\n\tunsigned num_ranks;\n\tunsigned gb_addr_config;\n\tunsigned num_rbs;\n\tunsigned gs_vgt_table_depth;\n\tunsigned gs_prim_buffer_depth;\n\n\tuint32_t tile_mode_array[32];\n\tuint32_t macrotile_mode_array[16];\n\n\tstruct gb_addr_config gb_addr_config_fields;\n\tstruct amdgpu_rb_config rb_config[AMDGPU_GFX_MAX_SE][AMDGPU_GFX_MAX_SH_PER_SE];\n\n\t \n\tuint32_t double_offchip_lds_buf;\n\t \n\tuint32_t db_debug2;\n\t \n\tuint32_t num_sc_per_sh;\n\tuint32_t num_packer_per_sc;\n\tuint32_t pa_sc_tile_steering_override;\n\t \n\tbool ta_cntl2_truncate_coord_mode;\n\tuint64_t tcc_disabled_mask;\n\tuint32_t gc_num_tcp_per_sa;\n\tuint32_t gc_num_sdp_interface;\n\tuint32_t gc_num_tcps;\n\tuint32_t gc_num_tcp_per_wpg;\n\tuint32_t gc_tcp_l1_size;\n\tuint32_t gc_num_sqc_per_wgp;\n\tuint32_t gc_l1_instruction_cache_size_per_sqc;\n\tuint32_t gc_l1_data_cache_size_per_sqc;\n\tuint32_t gc_gl1c_per_sa;\n\tuint32_t gc_gl1c_size_per_instance;\n\tuint32_t gc_gl2c_per_gpu;\n\tuint32_t gc_tcp_size_per_cu;\n\tuint32_t gc_num_cu_per_sqc;\n\tuint32_t gc_tcc_size;\n};\n\nstruct amdgpu_cu_info {\n\tuint32_t simd_per_cu;\n\tuint32_t max_waves_per_simd;\n\tuint32_t wave_front_size;\n\tuint32_t max_scratch_slots_per_cu;\n\tuint32_t lds_size;\n\n\t \n\tuint32_t number;\n\tuint32_t ao_cu_mask;\n\tuint32_t ao_cu_bitmap[4][4];\n\tuint32_t bitmap[AMDGPU_MAX_GC_INSTANCES][4][4];\n};\n\nstruct amdgpu_gfx_ras {\n\tstruct amdgpu_ras_block_object  ras_block;\n\tvoid (*enable_watchdog_timer)(struct amdgpu_device *adev);\n\tbool (*query_utcl2_poison_status)(struct amdgpu_device *adev);\n\tint (*rlc_gc_fed_irq)(struct amdgpu_device *adev,\n\t\t\t\tstruct amdgpu_irq_src *source,\n\t\t\t\tstruct amdgpu_iv_entry *entry);\n\tint (*poison_consumption_handler)(struct amdgpu_device *adev,\n\t\t\t\t\t\tstruct amdgpu_iv_entry *entry);\n};\n\nstruct amdgpu_gfx_shadow_info {\n\tu32 shadow_size;\n\tu32 shadow_alignment;\n\tu32 csa_size;\n\tu32 csa_alignment;\n};\n\nstruct amdgpu_gfx_funcs {\n\t \n\tuint64_t (*get_gpu_clock_counter)(struct amdgpu_device *adev);\n\tvoid (*select_se_sh)(struct amdgpu_device *adev, u32 se_num,\n\t\t\t     u32 sh_num, u32 instance, int xcc_id);\n\tvoid (*read_wave_data)(struct amdgpu_device *adev, uint32_t xcc_id, uint32_t simd,\n\t\t\t       uint32_t wave, uint32_t *dst, int *no_fields);\n\tvoid (*read_wave_vgprs)(struct amdgpu_device *adev, uint32_t xcc_id, uint32_t simd,\n\t\t\t\tuint32_t wave, uint32_t thread, uint32_t start,\n\t\t\t\tuint32_t size, uint32_t *dst);\n\tvoid (*read_wave_sgprs)(struct amdgpu_device *adev, uint32_t xcc_id, uint32_t simd,\n\t\t\t\tuint32_t wave, uint32_t start, uint32_t size,\n\t\t\t\tuint32_t *dst);\n\tvoid (*select_me_pipe_q)(struct amdgpu_device *adev, u32 me, u32 pipe,\n\t\t\t\t u32 queue, u32 vmid, u32 xcc_id);\n\tvoid (*init_spm_golden)(struct amdgpu_device *adev);\n\tvoid (*update_perfmon_mgcg)(struct amdgpu_device *adev, bool enable);\n\tint (*get_gfx_shadow_info)(struct amdgpu_device *adev,\n\t\t\t\t   struct amdgpu_gfx_shadow_info *shadow_info);\n\tenum amdgpu_gfx_partition\n\t\t\t(*query_partition_mode)(struct amdgpu_device *adev);\n\tint (*switch_partition_mode)(struct amdgpu_device *adev,\n\t\t\t\t     int num_xccs_per_xcp);\n\tint (*ih_node_to_logical_xcc)(struct amdgpu_device *adev, int ih_node);\n};\n\nstruct sq_work {\n\tstruct work_struct\twork;\n\tunsigned ih_data;\n};\n\nstruct amdgpu_pfp {\n\tstruct amdgpu_bo\t\t*pfp_fw_obj;\n\tuint64_t\t\t\tpfp_fw_gpu_addr;\n\tuint32_t\t\t\t*pfp_fw_ptr;\n\n\tstruct amdgpu_bo\t\t*pfp_fw_data_obj;\n\tuint64_t\t\t\tpfp_fw_data_gpu_addr;\n\tuint32_t\t\t\t*pfp_fw_data_ptr;\n};\n\nstruct amdgpu_ce {\n\tstruct amdgpu_bo\t\t*ce_fw_obj;\n\tuint64_t\t\t\tce_fw_gpu_addr;\n\tuint32_t\t\t\t*ce_fw_ptr;\n};\n\nstruct amdgpu_me {\n\tstruct amdgpu_bo\t\t*me_fw_obj;\n\tuint64_t\t\t\tme_fw_gpu_addr;\n\tuint32_t\t\t\t*me_fw_ptr;\n\n\tstruct amdgpu_bo\t\t*me_fw_data_obj;\n\tuint64_t\t\t\tme_fw_data_gpu_addr;\n\tuint32_t\t\t\t*me_fw_data_ptr;\n\n\tuint32_t\t\t\tnum_me;\n\tuint32_t\t\t\tnum_pipe_per_me;\n\tuint32_t\t\t\tnum_queue_per_pipe;\n\tvoid\t\t\t\t*mqd_backup[AMDGPU_MAX_GFX_RINGS];\n\n\t \n\tDECLARE_BITMAP(queue_bitmap, AMDGPU_MAX_GFX_QUEUES);\n};\n\nstruct amdgpu_gfx {\n\tstruct mutex\t\t\tgpu_clock_mutex;\n\tstruct amdgpu_gfx_config\tconfig;\n\tstruct amdgpu_rlc\t\trlc;\n\tstruct amdgpu_pfp\t\tpfp;\n\tstruct amdgpu_ce\t\tce;\n\tstruct amdgpu_me\t\tme;\n\tstruct amdgpu_mec\t\tmec;\n\tstruct amdgpu_mec_bitmap\tmec_bitmap[AMDGPU_MAX_GC_INSTANCES];\n\tstruct amdgpu_kiq\t\tkiq[AMDGPU_MAX_GC_INSTANCES];\n\tstruct amdgpu_imu\t\timu;\n\tbool\t\t\t\trs64_enable;  \n\tconst struct firmware\t\t*me_fw;\t \n\tuint32_t\t\t\tme_fw_version;\n\tconst struct firmware\t\t*pfp_fw;  \n\tuint32_t\t\t\tpfp_fw_version;\n\tconst struct firmware\t\t*ce_fw;\t \n\tuint32_t\t\t\tce_fw_version;\n\tconst struct firmware\t\t*rlc_fw;  \n\tuint32_t\t\t\trlc_fw_version;\n\tconst struct firmware\t\t*mec_fw;  \n\tuint32_t\t\t\tmec_fw_version;\n\tconst struct firmware\t\t*mec2_fw;  \n\tuint32_t\t\t\tmec2_fw_version;\n\tconst struct firmware\t\t*imu_fw;  \n\tuint32_t\t\t\timu_fw_version;\n\tuint32_t\t\t\tme_feature_version;\n\tuint32_t\t\t\tce_feature_version;\n\tuint32_t\t\t\tpfp_feature_version;\n\tuint32_t\t\t\trlc_feature_version;\n\tuint32_t\t\t\trlc_srlc_fw_version;\n\tuint32_t\t\t\trlc_srlc_feature_version;\n\tuint32_t\t\t\trlc_srlg_fw_version;\n\tuint32_t\t\t\trlc_srlg_feature_version;\n\tuint32_t\t\t\trlc_srls_fw_version;\n\tuint32_t\t\t\trlc_srls_feature_version;\n\tuint32_t\t\t\trlcp_ucode_version;\n\tuint32_t\t\t\trlcp_ucode_feature_version;\n\tuint32_t\t\t\trlcv_ucode_version;\n\tuint32_t\t\t\trlcv_ucode_feature_version;\n\tuint32_t\t\t\tmec_feature_version;\n\tuint32_t\t\t\tmec2_feature_version;\n\tbool\t\t\t\tmec_fw_write_wait;\n\tbool\t\t\t\tme_fw_write_wait;\n\tbool\t\t\t\tcp_fw_write_wait;\n\tstruct amdgpu_ring\t\tgfx_ring[AMDGPU_MAX_GFX_RINGS];\n\tunsigned\t\t\tnum_gfx_rings;\n\tstruct amdgpu_ring\t\tcompute_ring[AMDGPU_MAX_COMPUTE_RINGS * AMDGPU_MAX_GC_INSTANCES];\n\tunsigned\t\t\tnum_compute_rings;\n\tstruct amdgpu_irq_src\t\teop_irq;\n\tstruct amdgpu_irq_src\t\tpriv_reg_irq;\n\tstruct amdgpu_irq_src\t\tpriv_inst_irq;\n\tstruct amdgpu_irq_src\t\tcp_ecc_error_irq;\n\tstruct amdgpu_irq_src\t\tsq_irq;\n\tstruct amdgpu_irq_src\t\trlc_gc_fed_irq;\n\tstruct sq_work\t\t\tsq_work;\n\n\t \n\tuint32_t\t\t\tgfx_current_status;\n\t \n\tunsigned\t\t\tce_ram_size;\n\tstruct amdgpu_cu_info\t\tcu_info;\n\tconst struct amdgpu_gfx_funcs\t*funcs;\n\n\t \n\tuint32_t                        grbm_soft_reset;\n\tuint32_t                        srbm_soft_reset;\n\n\t \n\tbool                            gfx_off_state;       \n\tstruct mutex                    gfx_off_mutex;       \n\tuint32_t                        gfx_off_req_count;   \n\tstruct delayed_work             gfx_off_delay_work;  \n\tuint32_t                        gfx_off_residency;   \n\tuint64_t                        gfx_off_entrycount;  \n\n\t \n\tstruct mutex\t\t\tpipe_reserve_mutex;\n\tDECLARE_BITMAP\t\t\t(pipe_reserve_bitmap, AMDGPU_MAX_COMPUTE_QUEUES);\n\n\t \n\tstruct ras_common_if\t\t*ras_if;\n\tstruct amdgpu_gfx_ras\t\t*ras;\n\n\tbool\t\t\t\tis_poweron;\n\n\tstruct amdgpu_ring\t\tsw_gfx_ring[AMDGPU_MAX_SW_GFX_RINGS];\n\tstruct amdgpu_ring_mux          muxer;\n\n\tbool\t\t\t\tcp_gfx_shadow;  \n\n\tuint16_t \t\t\txcc_mask;\n\tuint32_t\t\t\tnum_xcc_per_xcp;\n\tstruct mutex\t\t\tpartition_mutex;\n\tbool\t\t\t\tmcbp;  \n};\n\nstruct amdgpu_gfx_ras_reg_entry {\n\tstruct amdgpu_ras_err_status_reg_entry reg_entry;\n\tenum amdgpu_gfx_ras_mem_id_type mem_id_type;\n\tuint32_t se_num;\n};\n\nstruct amdgpu_gfx_ras_mem_id_entry {\n\tconst struct amdgpu_ras_memory_id_entry *mem_id_ent;\n\tuint32_t size;\n};\n\n#define AMDGPU_GFX_MEMID_ENT(x) {(x), ARRAY_SIZE(x)},\n\n#define amdgpu_gfx_get_gpu_clock_counter(adev) (adev)->gfx.funcs->get_gpu_clock_counter((adev))\n#define amdgpu_gfx_select_se_sh(adev, se, sh, instance, xcc_id) ((adev)->gfx.funcs->select_se_sh((adev), (se), (sh), (instance), (xcc_id)))\n#define amdgpu_gfx_select_me_pipe_q(adev, me, pipe, q, vmid, xcc_id) ((adev)->gfx.funcs->select_me_pipe_q((adev), (me), (pipe), (q), (vmid), (xcc_id)))\n#define amdgpu_gfx_init_spm_golden(adev) (adev)->gfx.funcs->init_spm_golden((adev))\n#define amdgpu_gfx_get_gfx_shadow_info(adev, si) ((adev)->gfx.funcs->get_gfx_shadow_info((adev), (si)))\n\n \nstatic inline u32 amdgpu_gfx_create_bitmask(u32 bit_width)\n{\n\treturn (u32)((1ULL << bit_width) - 1);\n}\n\nvoid amdgpu_gfx_parse_disable_cu(unsigned *mask, unsigned max_se,\n\t\t\t\t unsigned max_sh);\n\nint amdgpu_gfx_kiq_init_ring(struct amdgpu_device *adev,\n\t\t\t     struct amdgpu_ring *ring,\n\t\t\t     struct amdgpu_irq_src *irq, int xcc_id);\n\nvoid amdgpu_gfx_kiq_free_ring(struct amdgpu_ring *ring);\n\nvoid amdgpu_gfx_kiq_fini(struct amdgpu_device *adev, int xcc_id);\nint amdgpu_gfx_kiq_init(struct amdgpu_device *adev,\n\t\t\tunsigned hpd_size, int xcc_id);\n\nint amdgpu_gfx_mqd_sw_init(struct amdgpu_device *adev,\n\t\t\t   unsigned mqd_size, int xcc_id);\nvoid amdgpu_gfx_mqd_sw_fini(struct amdgpu_device *adev, int xcc_id);\nint amdgpu_gfx_disable_kcq(struct amdgpu_device *adev, int xcc_id);\nint amdgpu_gfx_enable_kcq(struct amdgpu_device *adev, int xcc_id);\nint amdgpu_gfx_disable_kgq(struct amdgpu_device *adev, int xcc_id);\nint amdgpu_gfx_enable_kgq(struct amdgpu_device *adev, int xcc_id);\n\nvoid amdgpu_gfx_compute_queue_acquire(struct amdgpu_device *adev);\nvoid amdgpu_gfx_graphics_queue_acquire(struct amdgpu_device *adev);\n\nint amdgpu_gfx_mec_queue_to_bit(struct amdgpu_device *adev, int mec,\n\t\t\t\tint pipe, int queue);\nvoid amdgpu_queue_mask_bit_to_mec_queue(struct amdgpu_device *adev, int bit,\n\t\t\t\t int *mec, int *pipe, int *queue);\nbool amdgpu_gfx_is_mec_queue_enabled(struct amdgpu_device *adev, int xcc_id,\n\t\t\t\t     int mec, int pipe, int queue);\nbool amdgpu_gfx_is_high_priority_compute_queue(struct amdgpu_device *adev,\n\t\t\t\t\t       struct amdgpu_ring *ring);\nbool amdgpu_gfx_is_high_priority_graphics_queue(struct amdgpu_device *adev,\n\t\t\t\t\t\tstruct amdgpu_ring *ring);\nint amdgpu_gfx_me_queue_to_bit(struct amdgpu_device *adev, int me,\n\t\t\t       int pipe, int queue);\nvoid amdgpu_gfx_bit_to_me_queue(struct amdgpu_device *adev, int bit,\n\t\t\t\tint *me, int *pipe, int *queue);\nbool amdgpu_gfx_is_me_queue_enabled(struct amdgpu_device *adev, int me,\n\t\t\t\t    int pipe, int queue);\nvoid amdgpu_gfx_off_ctrl(struct amdgpu_device *adev, bool enable);\nint amdgpu_get_gfx_off_status(struct amdgpu_device *adev, uint32_t *value);\nint amdgpu_gfx_ras_late_init(struct amdgpu_device *adev, struct ras_common_if *ras_block);\nvoid amdgpu_gfx_ras_fini(struct amdgpu_device *adev);\nint amdgpu_get_gfx_off_entrycount(struct amdgpu_device *adev, u64 *value);\nint amdgpu_get_gfx_off_residency(struct amdgpu_device *adev, u32 *residency);\nint amdgpu_set_gfx_off_residency(struct amdgpu_device *adev, bool value);\nint amdgpu_gfx_process_ras_data_cb(struct amdgpu_device *adev,\n\t\tvoid *err_data,\n\t\tstruct amdgpu_iv_entry *entry);\nint amdgpu_gfx_cp_ecc_error_irq(struct amdgpu_device *adev,\n\t\t\t\t  struct amdgpu_irq_src *source,\n\t\t\t\t  struct amdgpu_iv_entry *entry);\nuint32_t amdgpu_kiq_rreg(struct amdgpu_device *adev, uint32_t reg);\nvoid amdgpu_kiq_wreg(struct amdgpu_device *adev, uint32_t reg, uint32_t v);\nint amdgpu_gfx_get_num_kcq(struct amdgpu_device *adev);\nvoid amdgpu_gfx_cp_init_microcode(struct amdgpu_device *adev, uint32_t ucode_id);\n\nint amdgpu_gfx_ras_sw_init(struct amdgpu_device *adev);\nint amdgpu_gfx_poison_consumption_handler(struct amdgpu_device *adev,\n\t\t\t\t\t\tstruct amdgpu_iv_entry *entry);\n\nbool amdgpu_gfx_is_master_xcc(struct amdgpu_device *adev, int xcc_id);\nint amdgpu_gfx_sysfs_init(struct amdgpu_device *adev);\nvoid amdgpu_gfx_sysfs_fini(struct amdgpu_device *adev);\nvoid amdgpu_gfx_ras_error_func(struct amdgpu_device *adev,\n\t\tvoid *ras_error_status,\n\t\tvoid (*func)(struct amdgpu_device *adev, void *ras_error_status,\n\t\t\t\tint xcc_id));\n\nstatic inline const char *amdgpu_gfx_compute_mode_desc(int mode)\n{\n\tswitch (mode) {\n\tcase AMDGPU_SPX_PARTITION_MODE:\n\t\treturn \"SPX\";\n\tcase AMDGPU_DPX_PARTITION_MODE:\n\t\treturn \"DPX\";\n\tcase AMDGPU_TPX_PARTITION_MODE:\n\t\treturn \"TPX\";\n\tcase AMDGPU_QPX_PARTITION_MODE:\n\t\treturn \"QPX\";\n\tcase AMDGPU_CPX_PARTITION_MODE:\n\t\treturn \"CPX\";\n\tdefault:\n\t\treturn \"UNKNOWN\";\n\t}\n\n\treturn \"UNKNOWN\";\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}