{
  "module_name": "umc_v8_7.c",
  "hash_id": "e6f5aaf97039e6fa4f334608bd0f7cfd17ae0770c24628891e9b2c003d5d62e7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/umc_v8_7.c",
  "human_readable_source": " \n#include \"umc_v8_7.h\"\n#include \"amdgpu_ras.h\"\n#include \"amdgpu_umc.h\"\n#include \"amdgpu.h\"\n\n#include \"rsmu/rsmu_0_0_2_offset.h\"\n#include \"rsmu/rsmu_0_0_2_sh_mask.h\"\n#include \"umc/umc_8_7_0_offset.h\"\n#include \"umc/umc_8_7_0_sh_mask.h\"\n\n#define UMC_8_INST_DIST\t\t\t0x40000\n\nconst uint32_t\n\tumc_v8_7_channel_idx_tbl[UMC_V8_7_UMC_INSTANCE_NUM][UMC_V8_7_CHANNEL_INSTANCE_NUM] = {\n\t\t{2, 11},  {4, 13},\n\t\t{1, 8},   {7, 14},\n\t\t{10, 3},  {12, 5},\n\t\t{9, 0},   {15, 6}\n};\n\nstatic inline uint32_t get_umc_v8_7_reg_offset(struct amdgpu_device *adev,\n\t\t\t\t\t    uint32_t umc_inst,\n\t\t\t\t\t    uint32_t ch_inst)\n{\n\treturn adev->umc.channel_offs*ch_inst + UMC_8_INST_DIST*umc_inst;\n}\n\nstatic void umc_v8_7_ecc_info_query_correctable_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t\tuint32_t umc_inst, uint32_t ch_inst,\n\t\t\t\t\t\tunsigned long *error_count)\n{\n\tuint64_t mc_umc_status;\n\tuint32_t eccinfo_table_idx;\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\n\teccinfo_table_idx = umc_inst * adev->umc.channel_inst_num + ch_inst;\n\n\t \n\tmc_umc_status = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_status;\n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, CECC) == 1)\n\t\t*error_count += 1;\n}\n\nstatic void umc_v8_7_ecc_info_querry_uncorrectable_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t\t\tuint32_t umc_inst, uint32_t ch_inst,\n\t\t\t\t\t\t\tunsigned long *error_count)\n{\n\tuint64_t mc_umc_status;\n\tuint32_t eccinfo_table_idx;\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\n\teccinfo_table_idx = umc_inst * adev->umc.channel_inst_num + ch_inst;\n\n\t \n\tmc_umc_status = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_status;\n\tif ((REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1) &&\n\t    (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Deferred) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, PCC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, TCC) == 1))\n\t\t*error_count += 1;\n}\n\nstatic void umc_v8_7_ecc_info_query_ras_error_count(struct amdgpu_device *adev,\n\t\t\t\t\tvoid *ras_error_status)\n{\n\tstruct ras_err_data *err_data = (struct ras_err_data *)ras_error_status;\n\n\tuint32_t umc_inst        = 0;\n\tuint32_t ch_inst         = 0;\n\n\t \n\tLOOP_UMC_INST_AND_CH(umc_inst, ch_inst) {\n\t\tumc_v8_7_ecc_info_query_correctable_error_count(adev,\n\t\t\t\t\t\t\tumc_inst, ch_inst,\n\t\t\t\t\t\t\t&(err_data->ce_count));\n\t\tumc_v8_7_ecc_info_querry_uncorrectable_error_count(adev,\n\t\t\t\t\t\t\tumc_inst, ch_inst,\n\t\t\t\t\t\t\t&(err_data->ue_count));\n\t}\n}\n\nstatic void umc_v8_7_convert_error_address(struct amdgpu_device *adev,\n\t\t\t\t\tstruct ras_err_data *err_data, uint64_t err_addr,\n\t\t\t\t\tuint32_t ch_inst, uint32_t umc_inst)\n{\n\tuint64_t retired_page;\n\tuint32_t channel_index;\n\n\tchannel_index =\n\t\tadev->umc.channel_idx_tbl[umc_inst * adev->umc.channel_inst_num + ch_inst];\n\n\t \n\tretired_page = ADDR_OF_4KB_BLOCK(err_addr) |\n\t\t\tADDR_OF_256B_BLOCK(channel_index) |\n\t\t\tOFFSET_IN_256B_BLOCK(err_addr);\n\n\tamdgpu_umc_fill_error_record(err_data, err_addr,\n\t\t\t\tretired_page, channel_index, umc_inst);\n}\n\nstatic void umc_v8_7_ecc_info_query_error_address(struct amdgpu_device *adev,\n\t\t\t\t\tstruct ras_err_data *err_data,\n\t\t\t\t\tuint32_t ch_inst,\n\t\t\t\t\tuint32_t umc_inst)\n{\n\tuint64_t mc_umc_status, err_addr;\n\tuint32_t eccinfo_table_idx;\n\tstruct amdgpu_ras *ras = amdgpu_ras_get_context(adev);\n\n\teccinfo_table_idx = umc_inst * adev->umc.channel_inst_num + ch_inst;\n\tmc_umc_status = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_status;\n\n\tif (mc_umc_status == 0)\n\t\treturn;\n\n\tif (!err_data->err_addr)\n\t\treturn;\n\n\t \n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1) {\n\n\t\terr_addr = ras->umc_ecc.ecc[eccinfo_table_idx].mca_umc_addr;\n\t\terr_addr = REG_GET_FIELD(err_addr, MCA_UMC_UMC0_MCUMC_ADDRT0, ErrorAddr);\n\n\t\tumc_v8_7_convert_error_address(adev, err_data, err_addr,\n\t\t\t\t\t\tch_inst, umc_inst);\n\t}\n}\n\nstatic void umc_v8_7_ecc_info_query_ras_error_address(struct amdgpu_device *adev,\n\t\t\t\t\tvoid *ras_error_status)\n{\n\tstruct ras_err_data *err_data = (struct ras_err_data *)ras_error_status;\n\n\tuint32_t umc_inst        = 0;\n\tuint32_t ch_inst         = 0;\n\n\t \n\tLOOP_UMC_INST_AND_CH(umc_inst, ch_inst) {\n\t\tumc_v8_7_ecc_info_query_error_address(adev,\n\t\t\t\t\t\terr_data,\n\t\t\t\t\t\tch_inst,\n\t\t\t\t\t\tumc_inst);\n\t}\n}\n\nstatic void umc_v8_7_clear_error_count_per_channel(struct amdgpu_device *adev,\n\t\t\t\t\tuint32_t umc_reg_offset)\n{\n\tuint32_t ecc_err_cnt_addr;\n\tuint32_t ecc_err_cnt_sel, ecc_err_cnt_sel_addr;\n\n\tecc_err_cnt_sel_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmUMCCH0_0_GeccErrCntSel);\n\tecc_err_cnt_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmUMCCH0_0_GeccErrCnt);\n\n\t \n\tecc_err_cnt_sel = RREG32_PCIE((ecc_err_cnt_sel_addr +\n\t\t\t\t\tumc_reg_offset) * 4);\n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel,\n\t\t\t\t\tUMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrCntCsSel, 0);\n\tWREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4,\n\t\t\tecc_err_cnt_sel);\n\n\t \n\tWREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4,\n\t\t\tUMC_V8_7_CE_CNT_INIT);\n\n\t \n\tecc_err_cnt_sel = RREG32_PCIE((ecc_err_cnt_sel_addr +\n\t\t\t\t\tumc_reg_offset) * 4);\n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel,\n\t\t\t\t\tUMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrCntCsSel, 1);\n\tWREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4,\n\t\t\tecc_err_cnt_sel);\n\n\t \n\tWREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4,\n\t\t\tUMC_V8_7_CE_CNT_INIT);\n}\n\nstatic void umc_v8_7_clear_error_count(struct amdgpu_device *adev)\n{\n\tuint32_t umc_inst        = 0;\n\tuint32_t ch_inst         = 0;\n\tuint32_t umc_reg_offset  = 0;\n\n\tLOOP_UMC_INST_AND_CH(umc_inst, ch_inst) {\n\t\tumc_reg_offset = get_umc_v8_7_reg_offset(adev,\n\t\t\t\t\t\tumc_inst,\n\t\t\t\t\t\tch_inst);\n\n\t\tumc_v8_7_clear_error_count_per_channel(adev,\n\t\t\t\t\t\tumc_reg_offset);\n\t}\n}\n\nstatic void umc_v8_7_query_correctable_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t\t   uint32_t umc_reg_offset,\n\t\t\t\t\t\t   unsigned long *error_count)\n{\n\tuint32_t ecc_err_cnt_sel, ecc_err_cnt_sel_addr;\n\tuint32_t ecc_err_cnt, ecc_err_cnt_addr;\n\tuint64_t mc_umc_status;\n\tuint32_t mc_umc_status_addr;\n\n\t \n\tecc_err_cnt_sel_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmUMCCH0_0_GeccErrCntSel);\n\tecc_err_cnt_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmUMCCH0_0_GeccErrCnt);\n\tmc_umc_status_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmMCA_UMC_UMC0_MCUMC_STATUST0);\n\n\t \n\tecc_err_cnt_sel = RREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4);\n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel, UMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrCntCsSel, 0);\n\tWREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4, ecc_err_cnt_sel);\n\n\tecc_err_cnt = RREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4);\n\t*error_count +=\n\t\t(REG_GET_FIELD(ecc_err_cnt, UMCCH0_0_GeccErrCnt, GeccErrCnt) -\n\t\t UMC_V8_7_CE_CNT_INIT);\n\n\t \n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel, UMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrCntCsSel, 1);\n\tWREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4, ecc_err_cnt_sel);\n\n\tecc_err_cnt = RREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4);\n\t*error_count +=\n\t\t(REG_GET_FIELD(ecc_err_cnt, UMCCH0_0_GeccErrCnt, GeccErrCnt) -\n\t\t UMC_V8_7_CE_CNT_INIT);\n\n\t \n\tmc_umc_status = RREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4);\n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, ErrorCodeExt) == 6 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, CECC) == 1)\n\t\t*error_count += 1;\n}\n\nstatic void umc_v8_7_querry_uncorrectable_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t\t      uint32_t umc_reg_offset,\n\t\t\t\t\t\t      unsigned long *error_count)\n{\n\tuint64_t mc_umc_status;\n\tuint32_t mc_umc_status_addr;\n\n\tmc_umc_status_addr = SOC15_REG_OFFSET(UMC, 0, mmMCA_UMC_UMC0_MCUMC_STATUST0);\n\n\t \n\tmc_umc_status = RREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4);\n\tif ((REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1) &&\n\t    (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Deferred) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, PCC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UC) == 1 ||\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, TCC) == 1))\n\t\t*error_count += 1;\n}\n\nstatic void umc_v8_7_query_ras_error_count(struct amdgpu_device *adev,\n\t\t\t\t\t   void *ras_error_status)\n{\n\tstruct ras_err_data *err_data = (struct ras_err_data *)ras_error_status;\n\n\tuint32_t umc_inst        = 0;\n\tuint32_t ch_inst         = 0;\n\tuint32_t umc_reg_offset  = 0;\n\n\tLOOP_UMC_INST_AND_CH(umc_inst, ch_inst) {\n\t\tumc_reg_offset = get_umc_v8_7_reg_offset(adev,\n\t\t\t\t\t\t      umc_inst,\n\t\t\t\t\t\t      ch_inst);\n\n\t\tumc_v8_7_query_correctable_error_count(adev,\n\t\t\t\t\t\t       umc_reg_offset,\n\t\t\t\t\t\t       &(err_data->ce_count));\n\t\tumc_v8_7_querry_uncorrectable_error_count(adev,\n\t\t\t\t\t\t\t  umc_reg_offset,\n\t\t\t\t\t\t\t  &(err_data->ue_count));\n\t}\n\n\tumc_v8_7_clear_error_count(adev);\n}\n\nstatic void umc_v8_7_query_error_address(struct amdgpu_device *adev,\n\t\t\t\t\t struct ras_err_data *err_data,\n\t\t\t\t\t uint32_t umc_reg_offset,\n\t\t\t\t\t uint32_t ch_inst,\n\t\t\t\t\t uint32_t umc_inst)\n{\n\tuint32_t lsb, mc_umc_status_addr;\n\tuint64_t mc_umc_status, err_addr, mc_umc_addrt0;\n\n\tmc_umc_status_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmMCA_UMC_UMC0_MCUMC_STATUST0);\n\tmc_umc_addrt0 =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmMCA_UMC_UMC0_MCUMC_ADDRT0);\n\tmc_umc_status = RREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4);\n\n\tif (mc_umc_status == 0)\n\t\treturn;\n\n\tif (!err_data->err_addr) {\n\t\t \n\t\tWREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4, 0x0ULL);\n\t\treturn;\n\t}\n\n\t \n\tif (REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, Val) == 1 &&\n\t    REG_GET_FIELD(mc_umc_status, MCA_UMC_UMC0_MCUMC_STATUST0, UECC) == 1) {\n\n\t\terr_addr = RREG64_PCIE((mc_umc_addrt0 + umc_reg_offset) * 4);\n\t\t \n\t\tlsb = REG_GET_FIELD(err_addr, MCA_UMC_UMC0_MCUMC_ADDRT0, LSB);\n\t\terr_addr = REG_GET_FIELD(err_addr, MCA_UMC_UMC0_MCUMC_ADDRT0, ErrorAddr);\n\t\terr_addr &= ~((0x1ULL << lsb) - 1);\n\n\t\tumc_v8_7_convert_error_address(adev, err_data, err_addr,\n\t\t\t\t\t\t\t\tch_inst, umc_inst);\n\t}\n\n\t \n\tWREG64_PCIE((mc_umc_status_addr + umc_reg_offset) * 4, 0x0ULL);\n}\n\nstatic void umc_v8_7_query_ras_error_address(struct amdgpu_device *adev,\n\t\t\t\t\t     void *ras_error_status)\n{\n\tstruct ras_err_data *err_data = (struct ras_err_data *)ras_error_status;\n\n\tuint32_t umc_inst        = 0;\n\tuint32_t ch_inst         = 0;\n\tuint32_t umc_reg_offset  = 0;\n\n\tLOOP_UMC_INST_AND_CH(umc_inst, ch_inst) {\n\t\tumc_reg_offset = get_umc_v8_7_reg_offset(adev,\n\t\t\t\t\t\t      umc_inst,\n\t\t\t\t\t\t      ch_inst);\n\n\t\tumc_v8_7_query_error_address(adev,\n\t\t\t\t\t     err_data,\n\t\t\t\t\t     umc_reg_offset,\n\t\t\t\t\t     ch_inst,\n\t\t\t\t\t     umc_inst);\n\t}\n}\n\nstatic void umc_v8_7_err_cnt_init_per_channel(struct amdgpu_device *adev,\n\t\t\t\t\t      uint32_t umc_reg_offset)\n{\n\tuint32_t ecc_err_cnt_sel, ecc_err_cnt_sel_addr;\n\tuint32_t ecc_err_cnt_addr;\n\n\tecc_err_cnt_sel_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmUMCCH0_0_GeccErrCntSel);\n\tecc_err_cnt_addr =\n\t\tSOC15_REG_OFFSET(UMC, 0, mmUMCCH0_0_GeccErrCnt);\n\n\t \n\tecc_err_cnt_sel = RREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4);\n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel, UMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrCntCsSel, 0);\n\t \n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel, UMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrInt, 0x1);\n\tWREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4, ecc_err_cnt_sel);\n\t \n\tWREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4, UMC_V8_7_CE_CNT_INIT);\n\n\t \n\tecc_err_cnt_sel = REG_SET_FIELD(ecc_err_cnt_sel, UMCCH0_0_GeccErrCntSel,\n\t\t\t\t\tGeccErrCntCsSel, 1);\n\tWREG32_PCIE((ecc_err_cnt_sel_addr + umc_reg_offset) * 4, ecc_err_cnt_sel);\n\tWREG32_PCIE((ecc_err_cnt_addr + umc_reg_offset) * 4, UMC_V8_7_CE_CNT_INIT);\n}\n\nstatic void umc_v8_7_err_cnt_init(struct amdgpu_device *adev)\n{\n\tuint32_t umc_inst        = 0;\n\tuint32_t ch_inst         = 0;\n\tuint32_t umc_reg_offset  = 0;\n\n\tLOOP_UMC_INST_AND_CH(umc_inst, ch_inst) {\n\t\tumc_reg_offset = get_umc_v8_7_reg_offset(adev,\n\t\t\t\t\t\t      umc_inst,\n\t\t\t\t\t\t      ch_inst);\n\n\t\tumc_v8_7_err_cnt_init_per_channel(adev, umc_reg_offset);\n\t}\n}\n\nconst struct amdgpu_ras_block_hw_ops umc_v8_7_ras_hw_ops = {\n\t.query_ras_error_count = umc_v8_7_query_ras_error_count,\n\t.query_ras_error_address = umc_v8_7_query_ras_error_address,\n};\n\nstruct amdgpu_umc_ras umc_v8_7_ras = {\n\t.ras_block = {\n\t\t.hw_ops = &umc_v8_7_ras_hw_ops,\n\t},\n\t.err_cnt_init = umc_v8_7_err_cnt_init,\n\t.ecc_info_query_ras_error_count = umc_v8_7_ecc_info_query_ras_error_count,\n\t.ecc_info_query_ras_error_address = umc_v8_7_ecc_info_query_ras_error_address,\n};\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}