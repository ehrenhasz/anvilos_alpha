{
  "module_name": "amdgpu_umc.c",
  "hash_id": "06d6409196544003e83fb34acdb1ccb5019907ffabd888264c44c065cfc0f57e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdgpu/amdgpu_umc.c",
  "human_readable_source": " \n\n#include \"amdgpu.h\"\n#include \"umc_v6_7.h\"\n\nstatic int amdgpu_umc_convert_error_address(struct amdgpu_device *adev,\n\t\t\t\t    struct ras_err_data *err_data, uint64_t err_addr,\n\t\t\t\t    uint32_t ch_inst, uint32_t umc_inst)\n{\n\tswitch (adev->ip_versions[UMC_HWIP][0]) {\n\tcase IP_VERSION(6, 7, 0):\n\t\tumc_v6_7_convert_error_address(adev,\n\t\t\t\terr_data, err_addr, ch_inst, umc_inst);\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(adev->dev,\n\t\t\t \"UMC address to Physical address translation is not supported\\n\");\n\t\treturn AMDGPU_RAS_FAIL;\n\t}\n\n\treturn AMDGPU_RAS_SUCCESS;\n}\n\nint amdgpu_umc_page_retirement_mca(struct amdgpu_device *adev,\n\t\t\tuint64_t err_addr, uint32_t ch_inst, uint32_t umc_inst)\n{\n\tstruct ras_err_data err_data = {0, 0, 0, NULL};\n\tint ret = AMDGPU_RAS_FAIL;\n\n\terr_data.err_addr =\n\t\tkcalloc(adev->umc.max_ras_err_cnt_per_query,\n\t\t\tsizeof(struct eeprom_table_record), GFP_KERNEL);\n\tif (!err_data.err_addr) {\n\t\tdev_warn(adev->dev,\n\t\t\t\"Failed to alloc memory for umc error record in MCA notifier!\\n\");\n\t\treturn AMDGPU_RAS_FAIL;\n\t}\n\n\t \n\tret = amdgpu_umc_convert_error_address(adev, &err_data, err_addr,\n\t\t\t\t\tch_inst, umc_inst);\n\tif (ret)\n\t\tgoto out;\n\n\tif (amdgpu_bad_page_threshold != 0) {\n\t\tamdgpu_ras_add_bad_pages(adev, err_data.err_addr,\n\t\t\t\t\t\terr_data.err_addr_cnt);\n\t\tamdgpu_ras_save_bad_pages(adev, NULL);\n\t}\n\nout:\n\tkfree(err_data.err_addr);\n\treturn ret;\n}\n\nstatic int amdgpu_umc_do_page_retirement(struct amdgpu_device *adev,\n\t\tvoid *ras_error_status,\n\t\tstruct amdgpu_iv_entry *entry,\n\t\tbool reset)\n{\n\tstruct ras_err_data *err_data = (struct ras_err_data *)ras_error_status;\n\tstruct amdgpu_ras *con = amdgpu_ras_get_context(adev);\n\tint ret = 0;\n\n\tkgd2kfd_set_sram_ecc_flag(adev->kfd.dev);\n\tret = amdgpu_dpm_get_ecc_info(adev, (void *)&(con->umc_ecc));\n\tif (ret == -EOPNOTSUPP) {\n\t\tif (adev->umc.ras && adev->umc.ras->ras_block.hw_ops &&\n\t\t    adev->umc.ras->ras_block.hw_ops->query_ras_error_count)\n\t\t    adev->umc.ras->ras_block.hw_ops->query_ras_error_count(adev, ras_error_status);\n\n\t\tif (adev->umc.ras && adev->umc.ras->ras_block.hw_ops &&\n\t\t    adev->umc.ras->ras_block.hw_ops->query_ras_error_address &&\n\t\t    adev->umc.max_ras_err_cnt_per_query) {\n\t\t\terr_data->err_addr =\n\t\t\t\tkcalloc(adev->umc.max_ras_err_cnt_per_query,\n\t\t\t\t\tsizeof(struct eeprom_table_record), GFP_KERNEL);\n\n\t\t\t \n\t\t\tif(!err_data->err_addr)\n\t\t\t\tdev_warn(adev->dev, \"Failed to alloc memory for \"\n\t\t\t\t\t\t\"umc error address record!\\n\");\n\n\t\t\t \n\t\t\tadev->umc.ras->ras_block.hw_ops->query_ras_error_address(adev, ras_error_status);\n\t\t}\n\t} else if (!ret) {\n\t\tif (adev->umc.ras &&\n\t\t    adev->umc.ras->ecc_info_query_ras_error_count)\n\t\t    adev->umc.ras->ecc_info_query_ras_error_count(adev, ras_error_status);\n\n\t\tif (adev->umc.ras &&\n\t\t    adev->umc.ras->ecc_info_query_ras_error_address &&\n\t\t    adev->umc.max_ras_err_cnt_per_query) {\n\t\t\terr_data->err_addr =\n\t\t\t\tkcalloc(adev->umc.max_ras_err_cnt_per_query,\n\t\t\t\t\tsizeof(struct eeprom_table_record), GFP_KERNEL);\n\n\t\t\t \n\t\t\tif(!err_data->err_addr)\n\t\t\t\tdev_warn(adev->dev, \"Failed to alloc memory for \"\n\t\t\t\t\t\t\"umc error address record!\\n\");\n\n\t\t\t \n\t\t\tadev->umc.ras->ecc_info_query_ras_error_address(adev, ras_error_status);\n\t\t}\n\t}\n\n\t \n\tif (err_data->ue_count) {\n\t\tdev_info(adev->dev, \"%ld uncorrectable hardware errors \"\n\t\t\t\t\"detected in UMC block\\n\",\n\t\t\t\terr_data->ue_count);\n\n\t\tif ((amdgpu_bad_page_threshold != 0) &&\n\t\t\terr_data->err_addr_cnt) {\n\t\t\tamdgpu_ras_add_bad_pages(adev, err_data->err_addr,\n\t\t\t\t\t\terr_data->err_addr_cnt);\n\t\t\tamdgpu_ras_save_bad_pages(adev, &(err_data->ue_count));\n\n\t\t\tamdgpu_dpm_send_hbm_bad_pages_num(adev, con->eeprom_control.ras_num_recs);\n\n\t\t\tif (con->update_channel_flag == true) {\n\t\t\t\tamdgpu_dpm_send_hbm_bad_channel_flag(adev, con->eeprom_control.bad_channel_bitmap);\n\t\t\t\tcon->update_channel_flag = false;\n\t\t\t}\n\t\t}\n\n\t\tif (reset)\n\t\t\tamdgpu_ras_reset_gpu(adev);\n\t}\n\n\tkfree(err_data->err_addr);\n\treturn AMDGPU_RAS_SUCCESS;\n}\n\nint amdgpu_umc_poison_handler(struct amdgpu_device *adev, bool reset)\n{\n\tint ret = AMDGPU_RAS_SUCCESS;\n\n\tif (adev->gmc.xgmi.connected_to_cpu ||\n\t\tadev->gmc.is_app_apu) {\n\t\tif (reset) {\n\t\t\t \n\t\t\tkgd2kfd_set_sram_ecc_flag(adev->kfd.dev);\n\t\t\tamdgpu_ras_reset_gpu(adev);\n\t\t}\n\t\treturn ret;\n\t}\n\n\tif (!amdgpu_sriov_vf(adev)) {\n\t\tstruct ras_err_data err_data = {0, 0, 0, NULL};\n\t\tstruct ras_common_if head = {\n\t\t\t.block = AMDGPU_RAS_BLOCK__UMC,\n\t\t};\n\t\tstruct ras_manager *obj = amdgpu_ras_find_obj(adev, &head);\n\n\t\tret = amdgpu_umc_do_page_retirement(adev, &err_data, NULL, reset);\n\n\t\tif (ret == AMDGPU_RAS_SUCCESS && obj) {\n\t\t\tobj->err_data.ue_count += err_data.ue_count;\n\t\t\tobj->err_data.ce_count += err_data.ce_count;\n\t\t}\n\t} else {\n\t\tif (adev->virt.ops && adev->virt.ops->ras_poison_handler)\n\t\t\tadev->virt.ops->ras_poison_handler(adev);\n\t\telse\n\t\t\tdev_warn(adev->dev,\n\t\t\t\t\"No ras_poison_handler interface in SRIOV!\\n\");\n\t}\n\n\treturn ret;\n}\n\nint amdgpu_umc_process_ras_data_cb(struct amdgpu_device *adev,\n\t\tvoid *ras_error_status,\n\t\tstruct amdgpu_iv_entry *entry)\n{\n\treturn amdgpu_umc_do_page_retirement(adev, ras_error_status, entry, true);\n}\n\nint amdgpu_umc_ras_sw_init(struct amdgpu_device *adev)\n{\n\tint err;\n\tstruct amdgpu_umc_ras *ras;\n\n\tif (!adev->umc.ras)\n\t\treturn 0;\n\n\tras = adev->umc.ras;\n\n\terr = amdgpu_ras_register_ras_block(adev, &ras->ras_block);\n\tif (err) {\n\t\tdev_err(adev->dev, \"Failed to register umc ras block!\\n\");\n\t\treturn err;\n\t}\n\n\tstrcpy(adev->umc.ras->ras_block.ras_comm.name, \"umc\");\n\tras->ras_block.ras_comm.block = AMDGPU_RAS_BLOCK__UMC;\n\tras->ras_block.ras_comm.type = AMDGPU_RAS_ERROR__MULTI_UNCORRECTABLE;\n\tadev->umc.ras_if = &ras->ras_block.ras_comm;\n\n\tif (!ras->ras_block.ras_late_init)\n\t\tras->ras_block.ras_late_init = amdgpu_umc_ras_late_init;\n\n\tif (!ras->ras_block.ras_cb)\n\t\tras->ras_block.ras_cb = amdgpu_umc_process_ras_data_cb;\n\n\treturn 0;\n}\n\nint amdgpu_umc_ras_late_init(struct amdgpu_device *adev, struct ras_common_if *ras_block)\n{\n\tint r;\n\n\tr = amdgpu_ras_block_late_init(adev, ras_block);\n\tif (r)\n\t\treturn r;\n\n\tif (amdgpu_ras_is_supported(adev, ras_block->block)) {\n\t\tr = amdgpu_irq_get(adev, &adev->gmc.ecc_irq, 0);\n\t\tif (r)\n\t\t\tgoto late_fini;\n\t}\n\n\t \n\tif (adev->umc.ras &&\n\t    adev->umc.ras->err_cnt_init)\n\t\tadev->umc.ras->err_cnt_init(adev);\n\n\treturn 0;\n\nlate_fini:\n\tamdgpu_ras_block_late_fini(adev, ras_block);\n\treturn r;\n}\n\nint amdgpu_umc_process_ecc_irq(struct amdgpu_device *adev,\n\t\tstruct amdgpu_irq_src *source,\n\t\tstruct amdgpu_iv_entry *entry)\n{\n\tstruct ras_common_if *ras_if = adev->umc.ras_if;\n\tstruct ras_dispatch_if ih_data = {\n\t\t.entry = entry,\n\t};\n\n\tif (!ras_if)\n\t\treturn 0;\n\n\tih_data.head = *ras_if;\n\n\tamdgpu_ras_interrupt_dispatch(adev, &ih_data);\n\treturn 0;\n}\n\nvoid amdgpu_umc_fill_error_record(struct ras_err_data *err_data,\n\t\tuint64_t err_addr,\n\t\tuint64_t retired_page,\n\t\tuint32_t channel_index,\n\t\tuint32_t umc_inst)\n{\n\tstruct eeprom_table_record *err_rec =\n\t\t&err_data->err_addr[err_data->err_addr_cnt];\n\n\terr_rec->address = err_addr;\n\t \n\terr_rec->retired_page = retired_page >> AMDGPU_GPU_PAGE_SHIFT;\n\terr_rec->ts = (uint64_t)ktime_get_real_seconds();\n\terr_rec->err_type = AMDGPU_RAS_EEPROM_ERR_NON_RECOVERABLE;\n\terr_rec->cu = 0;\n\terr_rec->mem_channel = channel_index;\n\terr_rec->mcumc_id = umc_inst;\n\n\terr_data->err_addr_cnt++;\n}\n\nint amdgpu_umc_loop_channels(struct amdgpu_device *adev,\n\t\t\tumc_func func, void *data)\n{\n\tuint32_t node_inst       = 0;\n\tuint32_t umc_inst        = 0;\n\tuint32_t ch_inst         = 0;\n\tint ret = 0;\n\n\tif (adev->umc.node_inst_num) {\n\t\tLOOP_UMC_EACH_NODE_INST_AND_CH(node_inst, umc_inst, ch_inst) {\n\t\t\tret = func(adev, node_inst, umc_inst, ch_inst, data);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(adev->dev, \"Node %d umc %d ch %d func returns %d\\n\",\n\t\t\t\t\tnode_inst, umc_inst, ch_inst, ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tLOOP_UMC_INST_AND_CH(umc_inst, ch_inst) {\n\t\t\tret = func(adev, 0, umc_inst, ch_inst, data);\n\t\t\tif (ret) {\n\t\t\t\tdev_err(adev->dev, \"Umc %d ch %d func returns %d\\n\",\n\t\t\t\t\tumc_inst, ch_inst, ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}