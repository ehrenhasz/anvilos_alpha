{
  "module_name": "kv_dpm.c",
  "hash_id": "6f03b127edce64dbd2f73faeb2c04b2c1447565e7aead57e1946ed8e8fcc58fc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/pm/legacy-dpm/kv_dpm.c",
  "human_readable_source": " \n\n#include \"amdgpu.h\"\n#include \"amdgpu_pm.h\"\n#include \"cikd.h\"\n#include \"atom.h\"\n#include \"amdgpu_atombios.h\"\n#include \"amdgpu_dpm.h\"\n#include \"kv_dpm.h\"\n#include \"gfx_v7_0.h\"\n#include <linux/seq_file.h>\n\n#include \"smu/smu_7_0_0_d.h\"\n#include \"smu/smu_7_0_0_sh_mask.h\"\n\n#include \"gca/gfx_7_2_d.h\"\n#include \"gca/gfx_7_2_sh_mask.h\"\n#include \"legacy_dpm.h\"\n\n#define KV_MAX_DEEPSLEEP_DIVIDER_ID     5\n#define KV_MINIMUM_ENGINE_CLOCK         800\n#define SMC_RAM_END                     0x40000\n\nstatic const struct amd_pm_funcs kv_dpm_funcs;\n\nstatic void kv_dpm_set_irq_funcs(struct amdgpu_device *adev);\nstatic int kv_enable_nb_dpm(struct amdgpu_device *adev,\n\t\t\t    bool enable);\nstatic void kv_init_graphics_levels(struct amdgpu_device *adev);\nstatic int kv_calculate_ds_divider(struct amdgpu_device *adev);\nstatic int kv_calculate_nbps_level_settings(struct amdgpu_device *adev);\nstatic int kv_calculate_dpm_settings(struct amdgpu_device *adev);\nstatic void kv_enable_new_levels(struct amdgpu_device *adev);\nstatic void kv_program_nbps_index_settings(struct amdgpu_device *adev,\n\t\t\t\t\t   struct amdgpu_ps *new_rps);\nstatic int kv_set_enabled_level(struct amdgpu_device *adev, u32 level);\nstatic int kv_set_enabled_levels(struct amdgpu_device *adev);\nstatic int kv_force_dpm_highest(struct amdgpu_device *adev);\nstatic int kv_force_dpm_lowest(struct amdgpu_device *adev);\nstatic void kv_apply_state_adjust_rules(struct amdgpu_device *adev,\n\t\t\t\t\tstruct amdgpu_ps *new_rps,\n\t\t\t\t\tstruct amdgpu_ps *old_rps);\nstatic int kv_set_thermal_temperature_range(struct amdgpu_device *adev,\n\t\t\t\t\t    int min_temp, int max_temp);\nstatic int kv_init_fps_limits(struct amdgpu_device *adev);\n\nstatic void kv_dpm_powergate_samu(struct amdgpu_device *adev, bool gate);\nstatic void kv_dpm_powergate_acp(struct amdgpu_device *adev, bool gate);\n\n\nstatic u32 kv_convert_vid2_to_vid7(struct amdgpu_device *adev,\n\t\t\t\t   struct sumo_vid_mapping_table *vid_mapping_table,\n\t\t\t\t   u32 vid_2bit)\n{\n\tstruct amdgpu_clock_voltage_dependency_table *vddc_sclk_table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\tu32 i;\n\n\tif (vddc_sclk_table && vddc_sclk_table->count) {\n\t\tif (vid_2bit < vddc_sclk_table->count)\n\t\t\treturn vddc_sclk_table->entries[vid_2bit].v;\n\t\telse\n\t\t\treturn vddc_sclk_table->entries[vddc_sclk_table->count - 1].v;\n\t} else {\n\t\tfor (i = 0; i < vid_mapping_table->num_entries; i++) {\n\t\t\tif (vid_mapping_table->entries[i].vid_2bit == vid_2bit)\n\t\t\t\treturn vid_mapping_table->entries[i].vid_7bit;\n\t\t}\n\t\treturn vid_mapping_table->entries[vid_mapping_table->num_entries - 1].vid_7bit;\n\t}\n}\n\nstatic u32 kv_convert_vid7_to_vid2(struct amdgpu_device *adev,\n\t\t\t\t   struct sumo_vid_mapping_table *vid_mapping_table,\n\t\t\t\t   u32 vid_7bit)\n{\n\tstruct amdgpu_clock_voltage_dependency_table *vddc_sclk_table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\tu32 i;\n\n\tif (vddc_sclk_table && vddc_sclk_table->count) {\n\t\tfor (i = 0; i < vddc_sclk_table->count; i++) {\n\t\t\tif (vddc_sclk_table->entries[i].v == vid_7bit)\n\t\t\t\treturn i;\n\t\t}\n\t\treturn vddc_sclk_table->count - 1;\n\t} else {\n\t\tfor (i = 0; i < vid_mapping_table->num_entries; i++) {\n\t\t\tif (vid_mapping_table->entries[i].vid_7bit == vid_7bit)\n\t\t\t\treturn vid_mapping_table->entries[i].vid_2bit;\n\t\t}\n\n\t\treturn vid_mapping_table->entries[vid_mapping_table->num_entries - 1].vid_2bit;\n\t}\n}\n\nstatic void sumo_take_smu_control(struct amdgpu_device *adev, bool enable)\n{\n \n#if 0\n\tu32 v = RREG32(mmDOUT_SCRATCH3);\n\n\tif (enable)\n\t\tv |= 0x4;\n\telse\n\t\tv &= 0xFFFFFFFB;\n\n\tWREG32(mmDOUT_SCRATCH3, v);\n#endif\n}\n\nstatic void sumo_construct_sclk_voltage_mapping_table(struct amdgpu_device *adev,\n\t\t\t\t\t\t      struct sumo_sclk_voltage_mapping_table *sclk_voltage_mapping_table,\n\t\t\t\t\t\t      ATOM_AVAILABLE_SCLK_LIST *table)\n{\n\tu32 i;\n\tu32 n = 0;\n\tu32 prev_sclk = 0;\n\n\tfor (i = 0; i < SUMO_MAX_HARDWARE_POWERLEVELS; i++) {\n\t\tif (table[i].ulSupportedSCLK > prev_sclk) {\n\t\t\tsclk_voltage_mapping_table->entries[n].sclk_frequency =\n\t\t\t\ttable[i].ulSupportedSCLK;\n\t\t\tsclk_voltage_mapping_table->entries[n].vid_2bit =\n\t\t\t\ttable[i].usVoltageIndex;\n\t\t\tprev_sclk = table[i].ulSupportedSCLK;\n\t\t\tn++;\n\t\t}\n\t}\n\n\tsclk_voltage_mapping_table->num_max_dpm_entries = n;\n}\n\nstatic void sumo_construct_vid_mapping_table(struct amdgpu_device *adev,\n\t\t\t\t\t     struct sumo_vid_mapping_table *vid_mapping_table,\n\t\t\t\t\t     ATOM_AVAILABLE_SCLK_LIST *table)\n{\n\tu32 i, j;\n\n\tfor (i = 0; i < SUMO_MAX_HARDWARE_POWERLEVELS; i++) {\n\t\tif (table[i].ulSupportedSCLK != 0) {\n\t\t\tvid_mapping_table->entries[table[i].usVoltageIndex].vid_7bit =\n\t\t\t\ttable[i].usVoltageID;\n\t\t\tvid_mapping_table->entries[table[i].usVoltageIndex].vid_2bit =\n\t\t\t\ttable[i].usVoltageIndex;\n\t\t}\n\t}\n\n\tfor (i = 0; i < SUMO_MAX_NUMBER_VOLTAGES; i++) {\n\t\tif (vid_mapping_table->entries[i].vid_7bit == 0) {\n\t\t\tfor (j = i + 1; j < SUMO_MAX_NUMBER_VOLTAGES; j++) {\n\t\t\t\tif (vid_mapping_table->entries[j].vid_7bit != 0) {\n\t\t\t\t\tvid_mapping_table->entries[i] =\n\t\t\t\t\t\tvid_mapping_table->entries[j];\n\t\t\t\t\tvid_mapping_table->entries[j].vid_7bit = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (j == SUMO_MAX_NUMBER_VOLTAGES)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tvid_mapping_table->num_entries = i;\n}\n\n#if 0\nstatic const struct kv_lcac_config_values sx_local_cac_cfg_kv[] = {\n\t{  0,       4,        1    },\n\t{  1,       4,        1    },\n\t{  2,       5,        1    },\n\t{  3,       4,        2    },\n\t{  4,       1,        1    },\n\t{  5,       5,        2    },\n\t{  6,       6,        1    },\n\t{  7,       9,        2    },\n\t{ 0xffffffff }\n};\n\nstatic const struct kv_lcac_config_values mc0_local_cac_cfg_kv[] = {\n\t{  0,       4,        1    },\n\t{ 0xffffffff }\n};\n\nstatic const struct kv_lcac_config_values mc1_local_cac_cfg_kv[] = {\n\t{  0,       4,        1    },\n\t{ 0xffffffff }\n};\n\nstatic const struct kv_lcac_config_values mc2_local_cac_cfg_kv[] = {\n\t{  0,       4,        1    },\n\t{ 0xffffffff }\n};\n\nstatic const struct kv_lcac_config_values mc3_local_cac_cfg_kv[] = {\n\t{  0,       4,        1    },\n\t{ 0xffffffff }\n};\n\nstatic const struct kv_lcac_config_values cpl_local_cac_cfg_kv[] = {\n\t{  0,       4,        1    },\n\t{  1,       4,        1    },\n\t{  2,       5,        1    },\n\t{  3,       4,        1    },\n\t{  4,       1,        1    },\n\t{  5,       5,        1    },\n\t{  6,       6,        1    },\n\t{  7,       9,        1    },\n\t{  8,       4,        1    },\n\t{  9,       2,        1    },\n\t{  10,      3,        1    },\n\t{  11,      6,        1    },\n\t{  12,      8,        2    },\n\t{  13,      1,        1    },\n\t{  14,      2,        1    },\n\t{  15,      3,        1    },\n\t{  16,      1,        1    },\n\t{  17,      4,        1    },\n\t{  18,      3,        1    },\n\t{  19,      1,        1    },\n\t{  20,      8,        1    },\n\t{  21,      5,        1    },\n\t{  22,      1,        1    },\n\t{  23,      1,        1    },\n\t{  24,      4,        1    },\n\t{  27,      6,        1    },\n\t{  28,      1,        1    },\n\t{ 0xffffffff }\n};\n\nstatic const struct kv_lcac_config_reg sx0_cac_config_reg[] = {\n\t{ 0xc0400d00, 0x003e0000, 17, 0x3fc00000, 22, 0x0001fffe, 1, 0x00000001, 0 }\n};\n\nstatic const struct kv_lcac_config_reg mc0_cac_config_reg[] = {\n\t{ 0xc0400d30, 0x003e0000, 17, 0x3fc00000, 22, 0x0001fffe, 1, 0x00000001, 0 }\n};\n\nstatic const struct kv_lcac_config_reg mc1_cac_config_reg[] = {\n\t{ 0xc0400d3c, 0x003e0000, 17, 0x3fc00000, 22, 0x0001fffe, 1, 0x00000001, 0 }\n};\n\nstatic const struct kv_lcac_config_reg mc2_cac_config_reg[] = {\n\t{ 0xc0400d48, 0x003e0000, 17, 0x3fc00000, 22, 0x0001fffe, 1, 0x00000001, 0 }\n};\n\nstatic const struct kv_lcac_config_reg mc3_cac_config_reg[] = {\n\t{ 0xc0400d54, 0x003e0000, 17, 0x3fc00000, 22, 0x0001fffe, 1, 0x00000001, 0 }\n};\n\nstatic const struct kv_lcac_config_reg cpl_cac_config_reg[] = {\n\t{ 0xc0400d80, 0x003e0000, 17, 0x3fc00000, 22, 0x0001fffe, 1, 0x00000001, 0 }\n};\n#endif\n\nstatic const struct kv_pt_config_reg didt_config_kv[] = {\n\t{ 0x10, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x10, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x10, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x10, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x2, 0x00003fff, 0, 0x4, KV_CONFIGREG_DIDT_IND },\n\t{ 0x2, 0x03ff0000, 16, 0x80, KV_CONFIGREG_DIDT_IND },\n\t{ 0x2, 0x78000000, 27, 0x3, KV_CONFIGREG_DIDT_IND },\n\t{ 0x1, 0x0000ffff, 0, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x1, 0xffff0000, 16, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x0, 0x00000001, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x22, 0x00003fff, 0, 0x4, KV_CONFIGREG_DIDT_IND },\n\t{ 0x22, 0x03ff0000, 16, 0x80, KV_CONFIGREG_DIDT_IND },\n\t{ 0x22, 0x78000000, 27, 0x3, KV_CONFIGREG_DIDT_IND },\n\t{ 0x21, 0x0000ffff, 0, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x21, 0xffff0000, 16, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x20, 0x00000001, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x42, 0x00003fff, 0, 0x4, KV_CONFIGREG_DIDT_IND },\n\t{ 0x42, 0x03ff0000, 16, 0x80, KV_CONFIGREG_DIDT_IND },\n\t{ 0x42, 0x78000000, 27, 0x3, KV_CONFIGREG_DIDT_IND },\n\t{ 0x41, 0x0000ffff, 0, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x41, 0xffff0000, 16, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x40, 0x00000001, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0x000000ff, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0x0000ff00, 8, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0x00ff0000, 16, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0xff000000, 24, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0x62, 0x00003fff, 0, 0x4, KV_CONFIGREG_DIDT_IND },\n\t{ 0x62, 0x03ff0000, 16, 0x80, KV_CONFIGREG_DIDT_IND },\n\t{ 0x62, 0x78000000, 27, 0x3, KV_CONFIGREG_DIDT_IND },\n\t{ 0x61, 0x0000ffff, 0, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x61, 0xffff0000, 16, 0x3FFF, KV_CONFIGREG_DIDT_IND },\n\t{ 0x60, 0x00000001, 0, 0x0, KV_CONFIGREG_DIDT_IND },\n\t{ 0xFFFFFFFF }\n};\n\nstatic struct kv_ps *kv_get_ps(struct amdgpu_ps *rps)\n{\n\tstruct kv_ps *ps = rps->ps_priv;\n\n\treturn ps;\n}\n\nstatic struct kv_power_info *kv_get_pi(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = adev->pm.dpm.priv;\n\n\treturn pi;\n}\n\n#if 0\nstatic void kv_program_local_cac_table(struct amdgpu_device *adev,\n\t\t\t\t       const struct kv_lcac_config_values *local_cac_table,\n\t\t\t\t       const struct kv_lcac_config_reg *local_cac_reg)\n{\n\tu32 i, count, data;\n\tconst struct kv_lcac_config_values *values = local_cac_table;\n\n\twhile (values->block_id != 0xffffffff) {\n\t\tcount = values->signal_id;\n\t\tfor (i = 0; i < count; i++) {\n\t\t\tdata = ((values->block_id << local_cac_reg->block_shift) &\n\t\t\t\tlocal_cac_reg->block_mask);\n\t\t\tdata |= ((i << local_cac_reg->signal_shift) &\n\t\t\t\t local_cac_reg->signal_mask);\n\t\t\tdata |= ((values->t << local_cac_reg->t_shift) &\n\t\t\t\t local_cac_reg->t_mask);\n\t\t\tdata |= ((1 << local_cac_reg->enable_shift) &\n\t\t\t\t local_cac_reg->enable_mask);\n\t\t\tWREG32_SMC(local_cac_reg->cntl, data);\n\t\t}\n\t\tvalues++;\n\t}\n}\n#endif\n\nstatic int kv_program_pt_config_registers(struct amdgpu_device *adev,\n\t\t\t\t\t  const struct kv_pt_config_reg *cac_config_regs)\n{\n\tconst struct kv_pt_config_reg *config_regs = cac_config_regs;\n\tu32 data;\n\tu32 cache = 0;\n\n\tif (config_regs == NULL)\n\t\treturn -EINVAL;\n\n\twhile (config_regs->offset != 0xFFFFFFFF) {\n\t\tif (config_regs->type == KV_CONFIGREG_CACHE) {\n\t\t\tcache |= ((config_regs->value << config_regs->shift) & config_regs->mask);\n\t\t} else {\n\t\t\tswitch (config_regs->type) {\n\t\t\tcase KV_CONFIGREG_SMC_IND:\n\t\t\t\tdata = RREG32_SMC(config_regs->offset);\n\t\t\t\tbreak;\n\t\t\tcase KV_CONFIGREG_DIDT_IND:\n\t\t\t\tdata = RREG32_DIDT(config_regs->offset);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tdata = RREG32(config_regs->offset);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tdata &= ~config_regs->mask;\n\t\t\tdata |= ((config_regs->value << config_regs->shift) & config_regs->mask);\n\t\t\tdata |= cache;\n\t\t\tcache = 0;\n\n\t\t\tswitch (config_regs->type) {\n\t\t\tcase KV_CONFIGREG_SMC_IND:\n\t\t\t\tWREG32_SMC(config_regs->offset, data);\n\t\t\t\tbreak;\n\t\t\tcase KV_CONFIGREG_DIDT_IND:\n\t\t\t\tWREG32_DIDT(config_regs->offset, data);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWREG32(config_regs->offset, data);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tconfig_regs++;\n\t}\n\n\treturn 0;\n}\n\nstatic void kv_do_enable_didt(struct amdgpu_device *adev, bool enable)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 data;\n\n\tif (pi->caps_sq_ramping) {\n\t\tdata = RREG32_DIDT(ixDIDT_SQ_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_SQ_CTRL0__DIDT_CTRL_EN_MASK;\n\t\telse\n\t\t\tdata &= ~DIDT_SQ_CTRL0__DIDT_CTRL_EN_MASK;\n\t\tWREG32_DIDT(ixDIDT_SQ_CTRL0, data);\n\t}\n\n\tif (pi->caps_db_ramping) {\n\t\tdata = RREG32_DIDT(ixDIDT_DB_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_DB_CTRL0__DIDT_CTRL_EN_MASK;\n\t\telse\n\t\t\tdata &= ~DIDT_DB_CTRL0__DIDT_CTRL_EN_MASK;\n\t\tWREG32_DIDT(ixDIDT_DB_CTRL0, data);\n\t}\n\n\tif (pi->caps_td_ramping) {\n\t\tdata = RREG32_DIDT(ixDIDT_TD_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_TD_CTRL0__DIDT_CTRL_EN_MASK;\n\t\telse\n\t\t\tdata &= ~DIDT_TD_CTRL0__DIDT_CTRL_EN_MASK;\n\t\tWREG32_DIDT(ixDIDT_TD_CTRL0, data);\n\t}\n\n\tif (pi->caps_tcp_ramping) {\n\t\tdata = RREG32_DIDT(ixDIDT_TCP_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_TCP_CTRL0__DIDT_CTRL_EN_MASK;\n\t\telse\n\t\t\tdata &= ~DIDT_TCP_CTRL0__DIDT_CTRL_EN_MASK;\n\t\tWREG32_DIDT(ixDIDT_TCP_CTRL0, data);\n\t}\n}\n\nstatic int kv_enable_didt(struct amdgpu_device *adev, bool enable)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tif (pi->caps_sq_ramping ||\n\t    pi->caps_db_ramping ||\n\t    pi->caps_td_ramping ||\n\t    pi->caps_tcp_ramping) {\n\t\tamdgpu_gfx_rlc_enter_safe_mode(adev, 0);\n\n\t\tif (enable) {\n\t\t\tret = kv_program_pt_config_registers(adev, didt_config_kv);\n\t\t\tif (ret) {\n\t\t\t\tamdgpu_gfx_rlc_exit_safe_mode(adev, 0);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\tkv_do_enable_didt(adev, enable);\n\n\t\tamdgpu_gfx_rlc_exit_safe_mode(adev, 0);\n\t}\n\n\treturn 0;\n}\n\n#if 0\nstatic void kv_initialize_hardware_cac_manager(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tif (pi->caps_cac) {\n\t\tWREG32_SMC(ixLCAC_SX0_OVR_SEL, 0);\n\t\tWREG32_SMC(ixLCAC_SX0_OVR_VAL, 0);\n\t\tkv_program_local_cac_table(adev, sx_local_cac_cfg_kv, sx0_cac_config_reg);\n\n\t\tWREG32_SMC(ixLCAC_MC0_OVR_SEL, 0);\n\t\tWREG32_SMC(ixLCAC_MC0_OVR_VAL, 0);\n\t\tkv_program_local_cac_table(adev, mc0_local_cac_cfg_kv, mc0_cac_config_reg);\n\n\t\tWREG32_SMC(ixLCAC_MC1_OVR_SEL, 0);\n\t\tWREG32_SMC(ixLCAC_MC1_OVR_VAL, 0);\n\t\tkv_program_local_cac_table(adev, mc1_local_cac_cfg_kv, mc1_cac_config_reg);\n\n\t\tWREG32_SMC(ixLCAC_MC2_OVR_SEL, 0);\n\t\tWREG32_SMC(ixLCAC_MC2_OVR_VAL, 0);\n\t\tkv_program_local_cac_table(adev, mc2_local_cac_cfg_kv, mc2_cac_config_reg);\n\n\t\tWREG32_SMC(ixLCAC_MC3_OVR_SEL, 0);\n\t\tWREG32_SMC(ixLCAC_MC3_OVR_VAL, 0);\n\t\tkv_program_local_cac_table(adev, mc3_local_cac_cfg_kv, mc3_cac_config_reg);\n\n\t\tWREG32_SMC(ixLCAC_CPL_OVR_SEL, 0);\n\t\tWREG32_SMC(ixLCAC_CPL_OVR_VAL, 0);\n\t\tkv_program_local_cac_table(adev, cpl_local_cac_cfg_kv, cpl_cac_config_reg);\n\t}\n}\n#endif\n\nstatic int kv_enable_smc_cac(struct amdgpu_device *adev, bool enable)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret = 0;\n\n\tif (pi->caps_cac) {\n\t\tif (enable) {\n\t\t\tret = amdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_EnableCac);\n\t\t\tif (ret)\n\t\t\t\tpi->cac_enabled = false;\n\t\t\telse\n\t\t\t\tpi->cac_enabled = true;\n\t\t} else if (pi->cac_enabled) {\n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_DisableCac);\n\t\t\tpi->cac_enabled = false;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int kv_process_firmware_header(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 tmp;\n\tint ret;\n\n\tret = amdgpu_kv_read_smc_sram_dword(adev, SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, DpmTable),\n\t\t\t\t     &tmp, pi->sram_end);\n\n\tif (ret == 0)\n\t\tpi->dpm_table_start = tmp;\n\n\tret = amdgpu_kv_read_smc_sram_dword(adev, SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, SoftRegisters),\n\t\t\t\t     &tmp, pi->sram_end);\n\n\tif (ret == 0)\n\t\tpi->soft_regs_start = tmp;\n\n\treturn ret;\n}\n\nstatic int kv_enable_dpm_voltage_scaling(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tpi->graphics_voltage_change_enable = 1;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, GraphicsVoltageChangeEnable),\n\t\t\t\t   &pi->graphics_voltage_change_enable,\n\t\t\t\t   sizeof(u8), pi->sram_end);\n\n\treturn ret;\n}\n\nstatic int kv_set_dpm_interval(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tpi->graphics_interval = 1;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, GraphicsInterval),\n\t\t\t\t   &pi->graphics_interval,\n\t\t\t\t   sizeof(u8), pi->sram_end);\n\n\treturn ret;\n}\n\nstatic int kv_set_dpm_boot_state(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, GraphicsBootLevel),\n\t\t\t\t   &pi->graphics_boot_level,\n\t\t\t\t   sizeof(u8), pi->sram_end);\n\n\treturn ret;\n}\n\nstatic void kv_program_vc(struct amdgpu_device *adev)\n{\n\tWREG32_SMC(ixCG_FREQ_TRAN_VOTING_0, 0x3FFFC100);\n}\n\nstatic void kv_clear_vc(struct amdgpu_device *adev)\n{\n\tWREG32_SMC(ixCG_FREQ_TRAN_VOTING_0, 0);\n}\n\nstatic int kv_set_divider_value(struct amdgpu_device *adev,\n\t\t\t\tu32 index, u32 sclk)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct atom_clock_dividers dividers;\n\tint ret;\n\n\tret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_ENGINE_PLL_PARAM,\n\t\t\t\t\t\t sclk, false, &dividers);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->graphics_level[index].SclkDid = (u8)dividers.post_div;\n\tpi->graphics_level[index].SclkFrequency = cpu_to_be32(sclk);\n\n\treturn 0;\n}\n\nstatic u16 kv_convert_8bit_index_to_voltage(struct amdgpu_device *adev,\n\t\t\t\t\t    u16 voltage)\n{\n\treturn 6200 - (voltage * 25);\n}\n\nstatic u16 kv_convert_2bit_index_to_voltage(struct amdgpu_device *adev,\n\t\t\t\t\t    u32 vid_2bit)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 vid_8bit = kv_convert_vid2_to_vid7(adev,\n\t\t\t\t\t       &pi->sys_info.vid_mapping_table,\n\t\t\t\t\t       vid_2bit);\n\n\treturn kv_convert_8bit_index_to_voltage(adev, (u16)vid_8bit);\n}\n\n\nstatic int kv_set_vid(struct amdgpu_device *adev, u32 index, u32 vid)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->graphics_level[index].VoltageDownH = (u8)pi->voltage_drop_t;\n\tpi->graphics_level[index].MinVddNb =\n\t\tcpu_to_be32(kv_convert_2bit_index_to_voltage(adev, vid));\n\n\treturn 0;\n}\n\nstatic int kv_set_at(struct amdgpu_device *adev, u32 index, u32 at)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->graphics_level[index].AT = cpu_to_be16((u16)at);\n\n\treturn 0;\n}\n\nstatic void kv_dpm_power_level_enable(struct amdgpu_device *adev,\n\t\t\t\t      u32 index, bool enable)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->graphics_level[index].EnabledForActivity = enable ? 1 : 0;\n}\n\nstatic void kv_start_dpm(struct amdgpu_device *adev)\n{\n\tu32 tmp = RREG32_SMC(ixGENERAL_PWRMGT);\n\n\ttmp |= GENERAL_PWRMGT__GLOBAL_PWRMGT_EN_MASK;\n\tWREG32_SMC(ixGENERAL_PWRMGT, tmp);\n\n\tamdgpu_kv_smc_dpm_enable(adev, true);\n}\n\nstatic void kv_stop_dpm(struct amdgpu_device *adev)\n{\n\tamdgpu_kv_smc_dpm_enable(adev, false);\n}\n\nstatic void kv_start_am(struct amdgpu_device *adev)\n{\n\tu32 sclk_pwrmgt_cntl = RREG32_SMC(ixSCLK_PWRMGT_CNTL);\n\n\tsclk_pwrmgt_cntl &= ~(SCLK_PWRMGT_CNTL__RESET_SCLK_CNT_MASK |\n\t\t\tSCLK_PWRMGT_CNTL__RESET_BUSY_CNT_MASK);\n\tsclk_pwrmgt_cntl |= SCLK_PWRMGT_CNTL__DYNAMIC_PM_EN_MASK;\n\n\tWREG32_SMC(ixSCLK_PWRMGT_CNTL, sclk_pwrmgt_cntl);\n}\n\nstatic void kv_reset_am(struct amdgpu_device *adev)\n{\n\tu32 sclk_pwrmgt_cntl = RREG32_SMC(ixSCLK_PWRMGT_CNTL);\n\n\tsclk_pwrmgt_cntl |= (SCLK_PWRMGT_CNTL__RESET_SCLK_CNT_MASK |\n\t\t\tSCLK_PWRMGT_CNTL__RESET_BUSY_CNT_MASK);\n\n\tWREG32_SMC(ixSCLK_PWRMGT_CNTL, sclk_pwrmgt_cntl);\n}\n\nstatic int kv_freeze_sclk_dpm(struct amdgpu_device *adev, bool freeze)\n{\n\treturn amdgpu_kv_notify_message_to_smu(adev, freeze ?\n\t\t\t\t\tPPSMC_MSG_SCLKDPM_FreezeLevel : PPSMC_MSG_SCLKDPM_UnfreezeLevel);\n}\n\nstatic int kv_force_lowest_valid(struct amdgpu_device *adev)\n{\n\treturn kv_force_dpm_lowest(adev);\n}\n\nstatic int kv_unforce_levels(struct amdgpu_device *adev)\n{\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS)\n\t\treturn amdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_NoForcedLevel);\n\telse\n\t\treturn kv_set_enabled_levels(adev);\n}\n\nstatic int kv_update_sclk_t(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 low_sclk_interrupt_t = 0;\n\tint ret = 0;\n\n\tif (pi->caps_sclk_throttle_low_notification) {\n\t\tlow_sclk_interrupt_t = cpu_to_be32(pi->low_sclk_interrupt_t);\n\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, LowSclkInterruptT),\n\t\t\t\t\t   (u8 *)&low_sclk_interrupt_t,\n\t\t\t\t\t   sizeof(u32), pi->sram_end);\n\t}\n\treturn ret;\n}\n\nstatic int kv_program_bootup_state(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\n\tif (table && table->count) {\n\t\tfor (i = pi->graphics_dpm_level_count - 1; i > 0; i--) {\n\t\t\tif (table->entries[i].clk == pi->boot_pl.sclk)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tpi->graphics_boot_level = (u8)i;\n\t\tkv_dpm_power_level_enable(adev, i, true);\n\t} else {\n\t\tstruct sumo_sclk_voltage_mapping_table *table =\n\t\t\t&pi->sys_info.sclk_voltage_mapping_table;\n\n\t\tif (table->num_max_dpm_entries == 0)\n\t\t\treturn -EINVAL;\n\n\t\tfor (i = pi->graphics_dpm_level_count - 1; i > 0; i--) {\n\t\t\tif (table->entries[i].sclk_frequency == pi->boot_pl.sclk)\n\t\t\t\tbreak;\n\t\t}\n\n\t\tpi->graphics_boot_level = (u8)i;\n\t\tkv_dpm_power_level_enable(adev, i, true);\n\t}\n\treturn 0;\n}\n\nstatic int kv_enable_auto_thermal_throttling(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tpi->graphics_therm_throttle_enable = 1;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, GraphicsThermThrottleEnable),\n\t\t\t\t   &pi->graphics_therm_throttle_enable,\n\t\t\t\t   sizeof(u8), pi->sram_end);\n\n\treturn ret;\n}\n\nstatic int kv_upload_dpm_settings(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, GraphicsLevel),\n\t\t\t\t   (u8 *)&pi->graphics_level,\n\t\t\t\t   sizeof(SMU7_Fusion_GraphicsLevel) * SMU7_MAX_LEVELS_GRAPHICS,\n\t\t\t\t   pi->sram_end);\n\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, GraphicsDpmLevelCount),\n\t\t\t\t   &pi->graphics_dpm_level_count,\n\t\t\t\t   sizeof(u8), pi->sram_end);\n\n\treturn ret;\n}\n\nstatic u32 kv_get_clock_difference(u32 a, u32 b)\n{\n\treturn (a >= b) ? a - b : b - a;\n}\n\nstatic u32 kv_get_clk_bypass(struct amdgpu_device *adev, u32 clk)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 value;\n\n\tif (pi->caps_enable_dfs_bypass) {\n\t\tif (kv_get_clock_difference(clk, 40000) < 200)\n\t\t\tvalue = 3;\n\t\telse if (kv_get_clock_difference(clk, 30000) < 200)\n\t\t\tvalue = 2;\n\t\telse if (kv_get_clock_difference(clk, 20000) < 200)\n\t\t\tvalue = 7;\n\t\telse if (kv_get_clock_difference(clk, 15000) < 200)\n\t\t\tvalue = 6;\n\t\telse if (kv_get_clock_difference(clk, 10000) < 200)\n\t\t\tvalue = 8;\n\t\telse\n\t\t\tvalue = 0;\n\t} else {\n\t\tvalue = 0;\n\t}\n\n\treturn value;\n}\n\nstatic int kv_populate_uvd_table(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_uvd_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\n\tstruct atom_clock_dividers dividers;\n\tint ret;\n\tu32 i;\n\n\tif (table == NULL || table->count == 0)\n\t\treturn 0;\n\n\tpi->uvd_level_count = 0;\n\tfor (i = 0; i < table->count; i++) {\n\t\tif (pi->high_voltage_t &&\n\t\t    (pi->high_voltage_t < table->entries[i].v))\n\t\t\tbreak;\n\n\t\tpi->uvd_level[i].VclkFrequency = cpu_to_be32(table->entries[i].vclk);\n\t\tpi->uvd_level[i].DclkFrequency = cpu_to_be32(table->entries[i].dclk);\n\t\tpi->uvd_level[i].MinVddNb = cpu_to_be16(table->entries[i].v);\n\n\t\tpi->uvd_level[i].VClkBypassCntl =\n\t\t\t(u8)kv_get_clk_bypass(adev, table->entries[i].vclk);\n\t\tpi->uvd_level[i].DClkBypassCntl =\n\t\t\t(u8)kv_get_clk_bypass(adev, table->entries[i].dclk);\n\n\t\tret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_ENGINE_PLL_PARAM,\n\t\t\t\t\t\t\t table->entries[i].vclk, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tpi->uvd_level[i].VclkDivider = (u8)dividers.post_div;\n\n\t\tret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_ENGINE_PLL_PARAM,\n\t\t\t\t\t\t\t table->entries[i].dclk, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tpi->uvd_level[i].DclkDivider = (u8)dividers.post_div;\n\n\t\tpi->uvd_level_count++;\n\t}\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, UvdLevelCount),\n\t\t\t\t   (u8 *)&pi->uvd_level_count,\n\t\t\t\t   sizeof(u8), pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->uvd_interval = 1;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, UVDInterval),\n\t\t\t\t   &pi->uvd_interval,\n\t\t\t\t   sizeof(u8), pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, UvdLevel),\n\t\t\t\t   (u8 *)&pi->uvd_level,\n\t\t\t\t   sizeof(SMU7_Fusion_UvdLevel) * SMU7_MAX_LEVELS_UVD,\n\t\t\t\t   pi->sram_end);\n\n\treturn ret;\n\n}\n\nstatic int kv_populate_vce_table(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\tu32 i;\n\tstruct amdgpu_vce_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\n\tstruct atom_clock_dividers dividers;\n\n\tif (table == NULL || table->count == 0)\n\t\treturn 0;\n\n\tpi->vce_level_count = 0;\n\tfor (i = 0; i < table->count; i++) {\n\t\tif (pi->high_voltage_t &&\n\t\t    pi->high_voltage_t < table->entries[i].v)\n\t\t\tbreak;\n\n\t\tpi->vce_level[i].Frequency = cpu_to_be32(table->entries[i].evclk);\n\t\tpi->vce_level[i].MinVoltage = cpu_to_be16(table->entries[i].v);\n\n\t\tpi->vce_level[i].ClkBypassCntl =\n\t\t\t(u8)kv_get_clk_bypass(adev, table->entries[i].evclk);\n\n\t\tret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_ENGINE_PLL_PARAM,\n\t\t\t\t\t\t\t table->entries[i].evclk, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tpi->vce_level[i].Divider = (u8)dividers.post_div;\n\n\t\tpi->vce_level_count++;\n\t}\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, VceLevelCount),\n\t\t\t\t   (u8 *)&pi->vce_level_count,\n\t\t\t\t   sizeof(u8),\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->vce_interval = 1;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, VCEInterval),\n\t\t\t\t   (u8 *)&pi->vce_interval,\n\t\t\t\t   sizeof(u8),\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, VceLevel),\n\t\t\t\t   (u8 *)&pi->vce_level,\n\t\t\t\t   sizeof(SMU7_Fusion_ExtClkLevel) * SMU7_MAX_LEVELS_VCE,\n\t\t\t\t   pi->sram_end);\n\n\treturn ret;\n}\n\nstatic int kv_populate_samu_table(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table;\n\tstruct atom_clock_dividers dividers;\n\tint ret;\n\tu32 i;\n\n\tif (table == NULL || table->count == 0)\n\t\treturn 0;\n\n\tpi->samu_level_count = 0;\n\tfor (i = 0; i < table->count; i++) {\n\t\tif (pi->high_voltage_t &&\n\t\t    pi->high_voltage_t < table->entries[i].v)\n\t\t\tbreak;\n\n\t\tpi->samu_level[i].Frequency = cpu_to_be32(table->entries[i].clk);\n\t\tpi->samu_level[i].MinVoltage = cpu_to_be16(table->entries[i].v);\n\n\t\tpi->samu_level[i].ClkBypassCntl =\n\t\t\t(u8)kv_get_clk_bypass(adev, table->entries[i].clk);\n\n\t\tret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_ENGINE_PLL_PARAM,\n\t\t\t\t\t\t\t table->entries[i].clk, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tpi->samu_level[i].Divider = (u8)dividers.post_div;\n\n\t\tpi->samu_level_count++;\n\t}\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, SamuLevelCount),\n\t\t\t\t   (u8 *)&pi->samu_level_count,\n\t\t\t\t   sizeof(u8),\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->samu_interval = 1;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, SAMUInterval),\n\t\t\t\t   (u8 *)&pi->samu_interval,\n\t\t\t\t   sizeof(u8),\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, SamuLevel),\n\t\t\t\t   (u8 *)&pi->samu_level,\n\t\t\t\t   sizeof(SMU7_Fusion_ExtClkLevel) * SMU7_MAX_LEVELS_SAMU,\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\n\n\nstatic int kv_populate_acp_table(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table;\n\tstruct atom_clock_dividers dividers;\n\tint ret;\n\tu32 i;\n\n\tif (table == NULL || table->count == 0)\n\t\treturn 0;\n\n\tpi->acp_level_count = 0;\n\tfor (i = 0; i < table->count; i++) {\n\t\tpi->acp_level[i].Frequency = cpu_to_be32(table->entries[i].clk);\n\t\tpi->acp_level[i].MinVoltage = cpu_to_be16(table->entries[i].v);\n\n\t\tret = amdgpu_atombios_get_clock_dividers(adev, COMPUTE_ENGINE_PLL_PARAM,\n\t\t\t\t\t\t\t table->entries[i].clk, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tpi->acp_level[i].Divider = (u8)dividers.post_div;\n\n\t\tpi->acp_level_count++;\n\t}\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, AcpLevelCount),\n\t\t\t\t   (u8 *)&pi->acp_level_count,\n\t\t\t\t   sizeof(u8),\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->acp_interval = 1;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, ACPInterval),\n\t\t\t\t   (u8 *)&pi->acp_interval,\n\t\t\t\t   sizeof(u8),\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, AcpLevel),\n\t\t\t\t   (u8 *)&pi->acp_level,\n\t\t\t\t   sizeof(SMU7_Fusion_ExtClkLevel) * SMU7_MAX_LEVELS_ACP,\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\n\nstatic void kv_calculate_dfs_bypass_settings(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\n\tif (table && table->count) {\n\t\tfor (i = 0; i < pi->graphics_dpm_level_count; i++) {\n\t\t\tif (pi->caps_enable_dfs_bypass) {\n\t\t\t\tif (kv_get_clock_difference(table->entries[i].clk, 40000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 3;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].clk, 30000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 2;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].clk, 26600) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 7;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].clk, 20000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 6;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].clk, 10000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 8;\n\t\t\t\telse\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 0;\n\t\t\t} else {\n\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 0;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstruct sumo_sclk_voltage_mapping_table *table =\n\t\t\t&pi->sys_info.sclk_voltage_mapping_table;\n\t\tfor (i = 0; i < pi->graphics_dpm_level_count; i++) {\n\t\t\tif (pi->caps_enable_dfs_bypass) {\n\t\t\t\tif (kv_get_clock_difference(table->entries[i].sclk_frequency, 40000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 3;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].sclk_frequency, 30000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 2;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].sclk_frequency, 26600) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 7;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].sclk_frequency, 20000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 6;\n\t\t\t\telse if (kv_get_clock_difference(table->entries[i].sclk_frequency, 10000) < 200)\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 8;\n\t\t\t\telse\n\t\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 0;\n\t\t\t} else {\n\t\t\t\tpi->graphics_level[i].ClkBypassCntl = 0;\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic int kv_enable_ulv(struct amdgpu_device *adev, bool enable)\n{\n\treturn amdgpu_kv_notify_message_to_smu(adev, enable ?\n\t\t\t\t\tPPSMC_MSG_EnableULV : PPSMC_MSG_DisableULV);\n}\n\nstatic void kv_reset_acp_boot_level(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->acp_boot_level = 0xff;\n}\n\nstatic void kv_update_current_ps(struct amdgpu_device *adev,\n\t\t\t\t struct amdgpu_ps *rps)\n{\n\tstruct kv_ps *new_ps = kv_get_ps(rps);\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->current_rps = *rps;\n\tpi->current_ps = *new_ps;\n\tpi->current_rps.ps_priv = &pi->current_ps;\n\tadev->pm.dpm.current_ps = &pi->current_rps;\n}\n\nstatic void kv_update_requested_ps(struct amdgpu_device *adev,\n\t\t\t\t   struct amdgpu_ps *rps)\n{\n\tstruct kv_ps *new_ps = kv_get_ps(rps);\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->requested_rps = *rps;\n\tpi->requested_ps = *new_ps;\n\tpi->requested_rps.ps_priv = &pi->requested_ps;\n\tadev->pm.dpm.requested_ps = &pi->requested_rps;\n}\n\nstatic void kv_dpm_enable_bapm(void *handle, bool enable)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tif (pi->bapm_enable) {\n\t\tret = amdgpu_kv_smc_bapm_enable(adev, enable);\n\t\tif (ret)\n\t\t\tDRM_ERROR(\"amdgpu_kv_smc_bapm_enable failed\\n\");\n\t}\n}\n\nstatic bool kv_is_internal_thermal_sensor(enum amdgpu_int_thermal_type sensor)\n{\n\tswitch (sensor) {\n\tcase THERMAL_TYPE_KV:\n\t\treturn true;\n\tcase THERMAL_TYPE_NONE:\n\tcase THERMAL_TYPE_EXTERNAL:\n\tcase THERMAL_TYPE_EXTERNAL_GPIO:\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nstatic int kv_dpm_enable(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret;\n\n\tret = kv_process_firmware_header(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_process_firmware_header failed\\n\");\n\t\treturn ret;\n\t}\n\tkv_init_fps_limits(adev);\n\tkv_init_graphics_levels(adev);\n\tret = kv_program_bootup_state(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_program_bootup_state failed\\n\");\n\t\treturn ret;\n\t}\n\tkv_calculate_dfs_bypass_settings(adev);\n\tret = kv_upload_dpm_settings(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_upload_dpm_settings failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_populate_uvd_table(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_populate_uvd_table failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_populate_vce_table(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_populate_vce_table failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_populate_samu_table(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_populate_samu_table failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_populate_acp_table(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_populate_acp_table failed\\n\");\n\t\treturn ret;\n\t}\n\tkv_program_vc(adev);\n#if 0\n\tkv_initialize_hardware_cac_manager(adev);\n#endif\n\tkv_start_am(adev);\n\tif (pi->enable_auto_thermal_throttling) {\n\t\tret = kv_enable_auto_thermal_throttling(adev);\n\t\tif (ret) {\n\t\t\tDRM_ERROR(\"kv_enable_auto_thermal_throttling failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\tret = kv_enable_dpm_voltage_scaling(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_enable_dpm_voltage_scaling failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_set_dpm_interval(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_set_dpm_interval failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_set_dpm_boot_state(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_set_dpm_boot_state failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_enable_ulv(adev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_enable_ulv failed\\n\");\n\t\treturn ret;\n\t}\n\tkv_start_dpm(adev);\n\tret = kv_enable_didt(adev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_enable_didt failed\\n\");\n\t\treturn ret;\n\t}\n\tret = kv_enable_smc_cac(adev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"kv_enable_smc_cac failed\\n\");\n\t\treturn ret;\n\t}\n\n\tkv_reset_acp_boot_level(adev);\n\n\tret = amdgpu_kv_smc_bapm_enable(adev, false);\n\tif (ret) {\n\t\tDRM_ERROR(\"amdgpu_kv_smc_bapm_enable failed\\n\");\n\t\treturn ret;\n\t}\n\n\tif (adev->irq.installed &&\n\t    kv_is_internal_thermal_sensor(adev->pm.int_thermal_type)) {\n\t\tret = kv_set_thermal_temperature_range(adev, KV_TEMP_RANGE_MIN, KV_TEMP_RANGE_MAX);\n\t\tif (ret) {\n\t\t\tDRM_ERROR(\"kv_set_thermal_temperature_range failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tamdgpu_irq_get(adev, &adev->pm.dpm.thermal.irq,\n\t\t\t       AMDGPU_THERMAL_IRQ_LOW_TO_HIGH);\n\t\tamdgpu_irq_get(adev, &adev->pm.dpm.thermal.irq,\n\t\t\t       AMDGPU_THERMAL_IRQ_HIGH_TO_LOW);\n\t}\n\n\treturn ret;\n}\n\nstatic void kv_dpm_disable(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint err;\n\n\tamdgpu_irq_put(adev, &adev->pm.dpm.thermal.irq,\n\t\t       AMDGPU_THERMAL_IRQ_LOW_TO_HIGH);\n\tamdgpu_irq_put(adev, &adev->pm.dpm.thermal.irq,\n\t\t       AMDGPU_THERMAL_IRQ_HIGH_TO_LOW);\n\n\terr = amdgpu_kv_smc_bapm_enable(adev, false);\n\tif (err)\n\t\tDRM_ERROR(\"amdgpu_kv_smc_bapm_enable failed\\n\");\n\n\tif (adev->asic_type == CHIP_MULLINS)\n\t\tkv_enable_nb_dpm(adev, false);\n\n\t \n\tkv_dpm_powergate_acp(adev, false);\n\tkv_dpm_powergate_samu(adev, false);\n\tif (pi->caps_vce_pg)  \n\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_VCEPowerON);\n\tif (pi->caps_uvd_pg)  \n\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_UVDPowerON);\n\n\tkv_enable_smc_cac(adev, false);\n\tkv_enable_didt(adev, false);\n\tkv_clear_vc(adev);\n\tkv_stop_dpm(adev);\n\tkv_enable_ulv(adev, false);\n\tkv_reset_am(adev);\n\n\tkv_update_current_ps(adev, adev->pm.dpm.boot_ps);\n}\n\n#if 0\nstatic int kv_write_smc_soft_register(struct amdgpu_device *adev,\n\t\t\t\t      u16 reg_offset, u32 value)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\treturn amdgpu_kv_copy_bytes_to_smc(adev, pi->soft_regs_start + reg_offset,\n\t\t\t\t    (u8 *)&value, sizeof(u16), pi->sram_end);\n}\n\nstatic int kv_read_smc_soft_register(struct amdgpu_device *adev,\n\t\t\t\t     u16 reg_offset, u32 *value)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\treturn amdgpu_kv_read_smc_sram_dword(adev, pi->soft_regs_start + reg_offset,\n\t\t\t\t      value, pi->sram_end);\n}\n#endif\n\nstatic void kv_init_sclk_t(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->low_sclk_interrupt_t = 0;\n}\n\nstatic int kv_init_fps_limits(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret = 0;\n\n\tif (pi->caps_fps) {\n\t\tu16 tmp;\n\n\t\ttmp = 45;\n\t\tpi->fps_high_t = cpu_to_be16(tmp);\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, FpsHighT),\n\t\t\t\t\t   (u8 *)&pi->fps_high_t,\n\t\t\t\t\t   sizeof(u16), pi->sram_end);\n\n\t\ttmp = 30;\n\t\tpi->fps_low_t = cpu_to_be16(tmp);\n\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, FpsLowT),\n\t\t\t\t\t   (u8 *)&pi->fps_low_t,\n\t\t\t\t\t   sizeof(u16), pi->sram_end);\n\n\t}\n\treturn ret;\n}\n\nstatic void kv_init_powergate_state(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->uvd_power_gated = false;\n\tpi->vce_power_gated = false;\n\tpi->samu_power_gated = false;\n\tpi->acp_power_gated = false;\n\n}\n\nstatic int kv_enable_uvd_dpm(struct amdgpu_device *adev, bool enable)\n{\n\treturn amdgpu_kv_notify_message_to_smu(adev, enable ?\n\t\t\t\t\tPPSMC_MSG_UVDDPM_Enable : PPSMC_MSG_UVDDPM_Disable);\n}\n\nstatic int kv_enable_vce_dpm(struct amdgpu_device *adev, bool enable)\n{\n\treturn amdgpu_kv_notify_message_to_smu(adev, enable ?\n\t\t\t\t\tPPSMC_MSG_VCEDPM_Enable : PPSMC_MSG_VCEDPM_Disable);\n}\n\nstatic int kv_enable_samu_dpm(struct amdgpu_device *adev, bool enable)\n{\n\treturn amdgpu_kv_notify_message_to_smu(adev, enable ?\n\t\t\t\t\tPPSMC_MSG_SAMUDPM_Enable : PPSMC_MSG_SAMUDPM_Disable);\n}\n\nstatic int kv_enable_acp_dpm(struct amdgpu_device *adev, bool enable)\n{\n\treturn amdgpu_kv_notify_message_to_smu(adev, enable ?\n\t\t\t\t\tPPSMC_MSG_ACPDPM_Enable : PPSMC_MSG_ACPDPM_Disable);\n}\n\nstatic int kv_update_uvd_dpm(struct amdgpu_device *adev, bool gate)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_uvd_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\n\tint ret;\n\tu32 mask;\n\n\tif (!gate) {\n\t\tif (table->count)\n\t\t\tpi->uvd_boot_level = table->count - 1;\n\t\telse\n\t\t\tpi->uvd_boot_level = 0;\n\n\t\tif (!pi->caps_uvd_dpm || pi->caps_stable_p_state) {\n\t\t\tmask = 1 << pi->uvd_boot_level;\n\t\t} else {\n\t\t\tmask = 0x1f;\n\t\t}\n\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, UvdBootLevel),\n\t\t\t\t\t   (uint8_t *)&pi->uvd_boot_level,\n\t\t\t\t\t   sizeof(u8), pi->sram_end);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tamdgpu_kv_send_msg_to_smc_with_parameter(adev,\n\t\t\t\t\t\t  PPSMC_MSG_UVDDPM_SetEnabledMask,\n\t\t\t\t\t\t  mask);\n\t}\n\n\treturn kv_enable_uvd_dpm(adev, !gate);\n}\n\nstatic u8 kv_get_vce_boot_level(struct amdgpu_device *adev, u32 evclk)\n{\n\tu8 i;\n\tstruct amdgpu_vce_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\n\n\tfor (i = 0; i < table->count; i++) {\n\t\tif (table->entries[i].evclk >= evclk)\n\t\t\tbreak;\n\t}\n\n\treturn i;\n}\n\nstatic int kv_update_vce_dpm(struct amdgpu_device *adev,\n\t\t\t     struct amdgpu_ps *amdgpu_new_state,\n\t\t\t     struct amdgpu_ps *amdgpu_current_state)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_vce_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\n\tint ret;\n\n\tif (amdgpu_new_state->evclk > 0 && amdgpu_current_state->evclk == 0) {\n\t\tif (pi->caps_stable_p_state)\n\t\t\tpi->vce_boot_level = table->count - 1;\n\t\telse\n\t\t\tpi->vce_boot_level = kv_get_vce_boot_level(adev, amdgpu_new_state->evclk);\n\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, VceBootLevel),\n\t\t\t\t\t   (u8 *)&pi->vce_boot_level,\n\t\t\t\t\t   sizeof(u8),\n\t\t\t\t\t   pi->sram_end);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (pi->caps_stable_p_state)\n\t\t\tamdgpu_kv_send_msg_to_smc_with_parameter(adev,\n\t\t\t\t\t\t\t  PPSMC_MSG_VCEDPM_SetEnabledMask,\n\t\t\t\t\t\t\t  (1 << pi->vce_boot_level));\n\t\tkv_enable_vce_dpm(adev, true);\n\t} else if (amdgpu_new_state->evclk == 0 && amdgpu_current_state->evclk > 0) {\n\t\tkv_enable_vce_dpm(adev, false);\n\t}\n\n\treturn 0;\n}\n\nstatic int kv_update_samu_dpm(struct amdgpu_device *adev, bool gate)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table;\n\tint ret;\n\n\tif (!gate) {\n\t\tif (pi->caps_stable_p_state)\n\t\t\tpi->samu_boot_level = table->count - 1;\n\t\telse\n\t\t\tpi->samu_boot_level = 0;\n\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, SamuBootLevel),\n\t\t\t\t\t   (u8 *)&pi->samu_boot_level,\n\t\t\t\t\t   sizeof(u8),\n\t\t\t\t\t   pi->sram_end);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (pi->caps_stable_p_state)\n\t\t\tamdgpu_kv_send_msg_to_smc_with_parameter(adev,\n\t\t\t\t\t\t\t  PPSMC_MSG_SAMUDPM_SetEnabledMask,\n\t\t\t\t\t\t\t  (1 << pi->samu_boot_level));\n\t}\n\n\treturn kv_enable_samu_dpm(adev, !gate);\n}\n\nstatic u8 kv_get_acp_boot_level(struct amdgpu_device *adev)\n{\n\treturn 0;\n}\n\nstatic void kv_update_acp_boot_level(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu8 acp_boot_level;\n\n\tif (!pi->caps_stable_p_state) {\n\t\tacp_boot_level = kv_get_acp_boot_level(adev);\n\t\tif (acp_boot_level != pi->acp_boot_level) {\n\t\t\tpi->acp_boot_level = acp_boot_level;\n\t\t\tamdgpu_kv_send_msg_to_smc_with_parameter(adev,\n\t\t\t\t\t\t\t  PPSMC_MSG_ACPDPM_SetEnabledMask,\n\t\t\t\t\t\t\t  (1 << pi->acp_boot_level));\n\t\t}\n\t}\n}\n\nstatic int kv_update_acp_dpm(struct amdgpu_device *adev, bool gate)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table;\n\tint ret;\n\n\tif (!gate) {\n\t\tif (pi->caps_stable_p_state)\n\t\t\tpi->acp_boot_level = table->count - 1;\n\t\telse\n\t\t\tpi->acp_boot_level = kv_get_acp_boot_level(adev);\n\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Fusion_DpmTable, AcpBootLevel),\n\t\t\t\t\t   (u8 *)&pi->acp_boot_level,\n\t\t\t\t\t   sizeof(u8),\n\t\t\t\t\t   pi->sram_end);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (pi->caps_stable_p_state)\n\t\t\tamdgpu_kv_send_msg_to_smc_with_parameter(adev,\n\t\t\t\t\t\t\t  PPSMC_MSG_ACPDPM_SetEnabledMask,\n\t\t\t\t\t\t\t  (1 << pi->acp_boot_level));\n\t}\n\n\treturn kv_enable_acp_dpm(adev, !gate);\n}\n\nstatic void kv_dpm_powergate_uvd(void *handle, bool gate)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->uvd_power_gated = gate;\n\n\tif (gate) {\n\t\t \n\t\tamdgpu_device_ip_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_UVD,\n\t\t\t\t\t\t       AMD_PG_STATE_GATE);\n\t\tkv_update_uvd_dpm(adev, gate);\n\t\tif (pi->caps_uvd_pg)\n\t\t\t \n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_UVDPowerOFF);\n\t} else {\n\t\tif (pi->caps_uvd_pg)\n\t\t\t \n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_UVDPowerON);\n\t\t\t \n\t\tkv_update_uvd_dpm(adev, gate);\n\n\t\tamdgpu_device_ip_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_UVD,\n\t\t\t\t\t\t       AMD_PG_STATE_UNGATE);\n\t}\n}\n\nstatic void kv_dpm_powergate_vce(void *handle, bool gate)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->vce_power_gated = gate;\n\n\tif (gate) {\n\t\t \n\t\tamdgpu_device_ip_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_VCE,\n\t\t\t\t\t\t       AMD_PG_STATE_GATE);\n\t\tkv_enable_vce_dpm(adev, false);\n\t\tif (pi->caps_vce_pg)  \n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_VCEPowerOFF);\n\t} else {\n\t\tif (pi->caps_vce_pg)  \n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_VCEPowerON);\n\t\tkv_enable_vce_dpm(adev, true);\n\t\t \n\t\tamdgpu_device_ip_set_powergating_state(adev, AMD_IP_BLOCK_TYPE_VCE,\n\t\t\t\t\t\t       AMD_PG_STATE_UNGATE);\n\t}\n}\n\n\nstatic void kv_dpm_powergate_samu(struct amdgpu_device *adev, bool gate)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tif (pi->samu_power_gated == gate)\n\t\treturn;\n\n\tpi->samu_power_gated = gate;\n\n\tif (gate) {\n\t\tkv_update_samu_dpm(adev, true);\n\t\tif (pi->caps_samu_pg)\n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_SAMPowerOFF);\n\t} else {\n\t\tif (pi->caps_samu_pg)\n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_SAMPowerON);\n\t\tkv_update_samu_dpm(adev, false);\n\t}\n}\n\nstatic void kv_dpm_powergate_acp(struct amdgpu_device *adev, bool gate)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tif (pi->acp_power_gated == gate)\n\t\treturn;\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS)\n\t\treturn;\n\n\tpi->acp_power_gated = gate;\n\n\tif (gate) {\n\t\tkv_update_acp_dpm(adev, true);\n\t\tif (pi->caps_acp_pg)\n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_ACPPowerOFF);\n\t} else {\n\t\tif (pi->caps_acp_pg)\n\t\t\tamdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_ACPPowerON);\n\t\tkv_update_acp_dpm(adev, false);\n\t}\n}\n\nstatic void kv_set_valid_clock_range(struct amdgpu_device *adev,\n\t\t\t\t     struct amdgpu_ps *new_rps)\n{\n\tstruct kv_ps *new_ps = kv_get_ps(new_rps);\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\n\tif (table && table->count) {\n\t\tfor (i = 0; i < pi->graphics_dpm_level_count; i++) {\n\t\t\tif ((table->entries[i].clk >= new_ps->levels[0].sclk) ||\n\t\t\t    (i == (pi->graphics_dpm_level_count - 1))) {\n\t\t\t\tpi->lowest_valid = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = pi->graphics_dpm_level_count - 1; i > 0; i--) {\n\t\t\tif (table->entries[i].clk <= new_ps->levels[new_ps->num_levels - 1].sclk)\n\t\t\t\tbreak;\n\t\t}\n\t\tpi->highest_valid = i;\n\n\t\tif (pi->lowest_valid > pi->highest_valid) {\n\t\t\tif ((new_ps->levels[0].sclk - table->entries[pi->highest_valid].clk) >\n\t\t\t    (table->entries[pi->lowest_valid].clk - new_ps->levels[new_ps->num_levels - 1].sclk))\n\t\t\t\tpi->highest_valid = pi->lowest_valid;\n\t\t\telse\n\t\t\t\tpi->lowest_valid =  pi->highest_valid;\n\t\t}\n\t} else {\n\t\tstruct sumo_sclk_voltage_mapping_table *table =\n\t\t\t&pi->sys_info.sclk_voltage_mapping_table;\n\n\t\tfor (i = 0; i < (int)pi->graphics_dpm_level_count; i++) {\n\t\t\tif (table->entries[i].sclk_frequency >= new_ps->levels[0].sclk ||\n\t\t\t    i == (int)(pi->graphics_dpm_level_count - 1)) {\n\t\t\t\tpi->lowest_valid = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = pi->graphics_dpm_level_count - 1; i > 0; i--) {\n\t\t\tif (table->entries[i].sclk_frequency <=\n\t\t\t    new_ps->levels[new_ps->num_levels - 1].sclk)\n\t\t\t\tbreak;\n\t\t}\n\t\tpi->highest_valid = i;\n\n\t\tif (pi->lowest_valid > pi->highest_valid) {\n\t\t\tif ((new_ps->levels[0].sclk -\n\t\t\t     table->entries[pi->highest_valid].sclk_frequency) >\n\t\t\t    (table->entries[pi->lowest_valid].sclk_frequency -\n\t\t\t     new_ps->levels[new_ps->num_levels - 1].sclk))\n\t\t\t\tpi->highest_valid = pi->lowest_valid;\n\t\t\telse\n\t\t\t\tpi->lowest_valid =  pi->highest_valid;\n\t\t}\n\t}\n}\n\nstatic int kv_update_dfs_bypass_settings(struct amdgpu_device *adev,\n\t\t\t\t\t struct amdgpu_ps *new_rps)\n{\n\tstruct kv_ps *new_ps = kv_get_ps(new_rps);\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret = 0;\n\tu8 clk_bypass_cntl;\n\n\tif (pi->caps_enable_dfs_bypass) {\n\t\tclk_bypass_cntl = new_ps->need_dfs_bypass ?\n\t\t\tpi->graphics_level[pi->graphics_boot_level].ClkBypassCntl : 0;\n\t\tret = amdgpu_kv_copy_bytes_to_smc(adev,\n\t\t\t\t\t   (pi->dpm_table_start +\n\t\t\t\t\t    offsetof(SMU7_Fusion_DpmTable, GraphicsLevel) +\n\t\t\t\t\t    (pi->graphics_boot_level * sizeof(SMU7_Fusion_GraphicsLevel)) +\n\t\t\t\t\t    offsetof(SMU7_Fusion_GraphicsLevel, ClkBypassCntl)),\n\t\t\t\t\t   &clk_bypass_cntl,\n\t\t\t\t\t   sizeof(u8), pi->sram_end);\n\t}\n\n\treturn ret;\n}\n\nstatic int kv_enable_nb_dpm(struct amdgpu_device *adev,\n\t\t\t    bool enable)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tint ret = 0;\n\n\tif (enable) {\n\t\tif (pi->enable_nb_dpm && !pi->nb_dpm_enabled) {\n\t\t\tret = amdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_NBDPM_Enable);\n\t\t\tif (ret == 0)\n\t\t\t\tpi->nb_dpm_enabled = true;\n\t\t}\n\t} else {\n\t\tif (pi->enable_nb_dpm && pi->nb_dpm_enabled) {\n\t\t\tret = amdgpu_kv_notify_message_to_smu(adev, PPSMC_MSG_NBDPM_Disable);\n\t\t\tif (ret == 0)\n\t\t\t\tpi->nb_dpm_enabled = false;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int kv_dpm_force_performance_level(void *handle,\n\t\t\t\t\t  enum amd_dpm_forced_level level)\n{\n\tint ret;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (level == AMD_DPM_FORCED_LEVEL_HIGH) {\n\t\tret = kv_force_dpm_highest(adev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (level == AMD_DPM_FORCED_LEVEL_LOW) {\n\t\tret = kv_force_dpm_lowest(adev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (level == AMD_DPM_FORCED_LEVEL_AUTO) {\n\t\tret = kv_unforce_levels(adev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tadev->pm.dpm.forced_level = level;\n\n\treturn 0;\n}\n\nstatic int kv_dpm_pre_set_power_state(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_ps requested_ps = *adev->pm.dpm.requested_ps;\n\tstruct amdgpu_ps *new_ps = &requested_ps;\n\n\tkv_update_requested_ps(adev, new_ps);\n\n\tkv_apply_state_adjust_rules(adev,\n\t\t\t\t    &pi->requested_rps,\n\t\t\t\t    &pi->current_rps);\n\n\treturn 0;\n}\n\nstatic int kv_dpm_set_power_state(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_ps *new_ps = &pi->requested_rps;\n\tstruct amdgpu_ps *old_ps = &pi->current_rps;\n\tint ret;\n\n\tif (pi->bapm_enable) {\n\t\tret = amdgpu_kv_smc_bapm_enable(adev, adev->pm.ac_power);\n\t\tif (ret) {\n\t\t\tDRM_ERROR(\"amdgpu_kv_smc_bapm_enable failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS) {\n\t\tif (pi->enable_dpm) {\n\t\t\tkv_set_valid_clock_range(adev, new_ps);\n\t\t\tkv_update_dfs_bypass_settings(adev, new_ps);\n\t\t\tret = kv_calculate_ds_divider(adev);\n\t\t\tif (ret) {\n\t\t\t\tDRM_ERROR(\"kv_calculate_ds_divider failed\\n\");\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t\tkv_calculate_nbps_level_settings(adev);\n\t\t\tkv_calculate_dpm_settings(adev);\n\t\t\tkv_force_lowest_valid(adev);\n\t\t\tkv_enable_new_levels(adev);\n\t\t\tkv_upload_dpm_settings(adev);\n\t\t\tkv_program_nbps_index_settings(adev, new_ps);\n\t\t\tkv_unforce_levels(adev);\n\t\t\tkv_set_enabled_levels(adev);\n\t\t\tkv_force_lowest_valid(adev);\n\t\t\tkv_unforce_levels(adev);\n\n\t\t\tret = kv_update_vce_dpm(adev, new_ps, old_ps);\n\t\t\tif (ret) {\n\t\t\t\tDRM_ERROR(\"kv_update_vce_dpm failed\\n\");\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t\tkv_update_sclk_t(adev);\n\t\t\tif (adev->asic_type == CHIP_MULLINS)\n\t\t\t\tkv_enable_nb_dpm(adev, true);\n\t\t}\n\t} else {\n\t\tif (pi->enable_dpm) {\n\t\t\tkv_set_valid_clock_range(adev, new_ps);\n\t\t\tkv_update_dfs_bypass_settings(adev, new_ps);\n\t\t\tret = kv_calculate_ds_divider(adev);\n\t\t\tif (ret) {\n\t\t\t\tDRM_ERROR(\"kv_calculate_ds_divider failed\\n\");\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t\tkv_calculate_nbps_level_settings(adev);\n\t\t\tkv_calculate_dpm_settings(adev);\n\t\t\tkv_freeze_sclk_dpm(adev, true);\n\t\t\tkv_upload_dpm_settings(adev);\n\t\t\tkv_program_nbps_index_settings(adev, new_ps);\n\t\t\tkv_freeze_sclk_dpm(adev, false);\n\t\t\tkv_set_enabled_levels(adev);\n\t\t\tret = kv_update_vce_dpm(adev, new_ps, old_ps);\n\t\t\tif (ret) {\n\t\t\t\tDRM_ERROR(\"kv_update_vce_dpm failed\\n\");\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t\tkv_update_acp_boot_level(adev);\n\t\t\tkv_update_sclk_t(adev);\n\t\t\tkv_enable_nb_dpm(adev, true);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void kv_dpm_post_set_power_state(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_ps *new_ps = &pi->requested_rps;\n\n\tkv_update_current_ps(adev, new_ps);\n}\n\nstatic void kv_dpm_setup_asic(struct amdgpu_device *adev)\n{\n\tsumo_take_smu_control(adev, true);\n\tkv_init_powergate_state(adev);\n\tkv_init_sclk_t(adev);\n}\n\n#if 0\nstatic void kv_dpm_reset_asic(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS) {\n\t\tkv_force_lowest_valid(adev);\n\t\tkv_init_graphics_levels(adev);\n\t\tkv_program_bootup_state(adev);\n\t\tkv_upload_dpm_settings(adev);\n\t\tkv_force_lowest_valid(adev);\n\t\tkv_unforce_levels(adev);\n\t} else {\n\t\tkv_init_graphics_levels(adev);\n\t\tkv_program_bootup_state(adev);\n\t\tkv_freeze_sclk_dpm(adev, true);\n\t\tkv_upload_dpm_settings(adev);\n\t\tkv_freeze_sclk_dpm(adev, false);\n\t\tkv_set_enabled_level(adev, pi->graphics_boot_level);\n\t}\n}\n#endif\n\nstatic void kv_construct_max_power_limits_table(struct amdgpu_device *adev,\n\t\t\t\t\t\tstruct amdgpu_clock_and_voltage_limits *table)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tif (pi->sys_info.sclk_voltage_mapping_table.num_max_dpm_entries > 0) {\n\t\tint idx = pi->sys_info.sclk_voltage_mapping_table.num_max_dpm_entries - 1;\n\t\ttable->sclk =\n\t\t\tpi->sys_info.sclk_voltage_mapping_table.entries[idx].sclk_frequency;\n\t\ttable->vddc =\n\t\t\tkv_convert_2bit_index_to_voltage(adev,\n\t\t\t\t\t\t\t pi->sys_info.sclk_voltage_mapping_table.entries[idx].vid_2bit);\n\t}\n\n\ttable->mclk = pi->sys_info.nbp_memory_clock[0];\n}\n\nstatic void kv_patch_voltage_values(struct amdgpu_device *adev)\n{\n\tint i;\n\tstruct amdgpu_uvd_clock_voltage_dependency_table *uvd_table =\n\t\t&adev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table;\n\tstruct amdgpu_vce_clock_voltage_dependency_table *vce_table =\n\t\t&adev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\n\tstruct amdgpu_clock_voltage_dependency_table *samu_table =\n\t\t&adev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table;\n\tstruct amdgpu_clock_voltage_dependency_table *acp_table =\n\t\t&adev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table;\n\n\tif (uvd_table->count) {\n\t\tfor (i = 0; i < uvd_table->count; i++)\n\t\t\tuvd_table->entries[i].v =\n\t\t\t\tkv_convert_8bit_index_to_voltage(adev,\n\t\t\t\t\t\t\t\t uvd_table->entries[i].v);\n\t}\n\n\tif (vce_table->count) {\n\t\tfor (i = 0; i < vce_table->count; i++)\n\t\t\tvce_table->entries[i].v =\n\t\t\t\tkv_convert_8bit_index_to_voltage(adev,\n\t\t\t\t\t\t\t\t vce_table->entries[i].v);\n\t}\n\n\tif (samu_table->count) {\n\t\tfor (i = 0; i < samu_table->count; i++)\n\t\t\tsamu_table->entries[i].v =\n\t\t\t\tkv_convert_8bit_index_to_voltage(adev,\n\t\t\t\t\t\t\t\t samu_table->entries[i].v);\n\t}\n\n\tif (acp_table->count) {\n\t\tfor (i = 0; i < acp_table->count; i++)\n\t\t\tacp_table->entries[i].v =\n\t\t\t\tkv_convert_8bit_index_to_voltage(adev,\n\t\t\t\t\t\t\t\t acp_table->entries[i].v);\n\t}\n\n}\n\nstatic void kv_construct_boot_state(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->boot_pl.sclk = pi->sys_info.bootup_sclk;\n\tpi->boot_pl.vddc_index = pi->sys_info.bootup_nb_voltage_index;\n\tpi->boot_pl.ds_divider_index = 0;\n\tpi->boot_pl.ss_divider_index = 0;\n\tpi->boot_pl.allow_gnb_slow = 1;\n\tpi->boot_pl.force_nbp_state = 0;\n\tpi->boot_pl.display_wm = 0;\n\tpi->boot_pl.vce_wm = 0;\n}\n\nstatic int kv_force_dpm_highest(struct amdgpu_device *adev)\n{\n\tint ret;\n\tu32 enable_mask, i;\n\n\tret = amdgpu_kv_dpm_get_enable_mask(adev, &enable_mask);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = SMU7_MAX_LEVELS_GRAPHICS - 1; i > 0; i--) {\n\t\tif (enable_mask & (1 << i))\n\t\t\tbreak;\n\t}\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS)\n\t\treturn amdgpu_kv_send_msg_to_smc_with_parameter(adev, PPSMC_MSG_DPM_ForceState, i);\n\telse\n\t\treturn kv_set_enabled_level(adev, i);\n}\n\nstatic int kv_force_dpm_lowest(struct amdgpu_device *adev)\n{\n\tint ret;\n\tu32 enable_mask, i;\n\n\tret = amdgpu_kv_dpm_get_enable_mask(adev, &enable_mask);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < SMU7_MAX_LEVELS_GRAPHICS; i++) {\n\t\tif (enable_mask & (1 << i))\n\t\t\tbreak;\n\t}\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS)\n\t\treturn amdgpu_kv_send_msg_to_smc_with_parameter(adev, PPSMC_MSG_DPM_ForceState, i);\n\telse\n\t\treturn kv_set_enabled_level(adev, i);\n}\n\nstatic u8 kv_get_sleep_divider_id_from_clock(struct amdgpu_device *adev,\n\t\t\t\t\t     u32 sclk, u32 min_sclk_in_sr)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\tu32 temp;\n\tu32 min = max(min_sclk_in_sr, (u32)KV_MINIMUM_ENGINE_CLOCK);\n\n\tif (sclk < min)\n\t\treturn 0;\n\n\tif (!pi->caps_sclk_ds)\n\t\treturn 0;\n\n\tfor (i = KV_MAX_DEEPSLEEP_DIVIDER_ID; i > 0; i--) {\n\t\ttemp = sclk >> i;\n\t\tif (temp >= min)\n\t\t\tbreak;\n\t}\n\n\treturn (u8)i;\n}\n\nstatic int kv_get_high_voltage_limit(struct amdgpu_device *adev, int *limit)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\tint i;\n\n\tif (table && table->count) {\n\t\tfor (i = table->count - 1; i >= 0; i--) {\n\t\t\tif (pi->high_voltage_t &&\n\t\t\t    (kv_convert_8bit_index_to_voltage(adev, table->entries[i].v) <=\n\t\t\t     pi->high_voltage_t)) {\n\t\t\t\t*limit = i;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstruct sumo_sclk_voltage_mapping_table *table =\n\t\t\t&pi->sys_info.sclk_voltage_mapping_table;\n\n\t\tfor (i = table->num_max_dpm_entries - 1; i >= 0; i--) {\n\t\t\tif (pi->high_voltage_t &&\n\t\t\t    (kv_convert_2bit_index_to_voltage(adev, table->entries[i].vid_2bit) <=\n\t\t\t     pi->high_voltage_t)) {\n\t\t\t\t*limit = i;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t*limit = 0;\n\treturn 0;\n}\n\nstatic void kv_apply_state_adjust_rules(struct amdgpu_device *adev,\n\t\t\t\t\tstruct amdgpu_ps *new_rps,\n\t\t\t\t\tstruct amdgpu_ps *old_rps)\n{\n\tstruct kv_ps *ps = kv_get_ps(new_rps);\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 min_sclk = 10000;  \n\tu32 sclk, mclk = 0;\n\tint i, limit;\n\tbool force_high;\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\tu32 stable_p_state_sclk = 0;\n\tstruct amdgpu_clock_and_voltage_limits *max_limits =\n\t\t&adev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\n\tif (new_rps->vce_active) {\n\t\tnew_rps->evclk = adev->pm.dpm.vce_states[adev->pm.dpm.vce_level].evclk;\n\t\tnew_rps->ecclk = adev->pm.dpm.vce_states[adev->pm.dpm.vce_level].ecclk;\n\t} else {\n\t\tnew_rps->evclk = 0;\n\t\tnew_rps->ecclk = 0;\n\t}\n\n\tmclk = max_limits->mclk;\n\tsclk = min_sclk;\n\n\tif (pi->caps_stable_p_state) {\n\t\tstable_p_state_sclk = (max_limits->sclk * 75) / 100;\n\n\t\tfor (i = table->count - 1; i >= 0; i--) {\n\t\t\tif (stable_p_state_sclk >= table->entries[i].clk) {\n\t\t\t\tstable_p_state_sclk = table->entries[i].clk;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (i > 0)\n\t\t\tstable_p_state_sclk = table->entries[0].clk;\n\n\t\tsclk = stable_p_state_sclk;\n\t}\n\n\tif (new_rps->vce_active) {\n\t\tif (sclk < adev->pm.dpm.vce_states[adev->pm.dpm.vce_level].sclk)\n\t\t\tsclk = adev->pm.dpm.vce_states[adev->pm.dpm.vce_level].sclk;\n\t}\n\n\tps->need_dfs_bypass = true;\n\n\tfor (i = 0; i < ps->num_levels; i++) {\n\t\tif (ps->levels[i].sclk < sclk)\n\t\t\tps->levels[i].sclk = sclk;\n\t}\n\n\tif (table && table->count) {\n\t\tfor (i = 0; i < ps->num_levels; i++) {\n\t\t\tif (pi->high_voltage_t &&\n\t\t\t    (pi->high_voltage_t <\n\t\t\t     kv_convert_8bit_index_to_voltage(adev, ps->levels[i].vddc_index))) {\n\t\t\t\tkv_get_high_voltage_limit(adev, &limit);\n\t\t\t\tps->levels[i].sclk = table->entries[limit].clk;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstruct sumo_sclk_voltage_mapping_table *table =\n\t\t\t&pi->sys_info.sclk_voltage_mapping_table;\n\n\t\tfor (i = 0; i < ps->num_levels; i++) {\n\t\t\tif (pi->high_voltage_t &&\n\t\t\t    (pi->high_voltage_t <\n\t\t\t     kv_convert_8bit_index_to_voltage(adev, ps->levels[i].vddc_index))) {\n\t\t\t\tkv_get_high_voltage_limit(adev, &limit);\n\t\t\t\tps->levels[i].sclk = table->entries[limit].sclk_frequency;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (pi->caps_stable_p_state) {\n\t\tfor (i = 0; i < ps->num_levels; i++) {\n\t\t\tps->levels[i].sclk = stable_p_state_sclk;\n\t\t}\n\t}\n\n\tpi->video_start = new_rps->dclk || new_rps->vclk ||\n\t\tnew_rps->evclk || new_rps->ecclk;\n\n\tif ((new_rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) ==\n\t    ATOM_PPLIB_CLASSIFICATION_UI_BATTERY)\n\t\tpi->battery_state = true;\n\telse\n\t\tpi->battery_state = false;\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS) {\n\t\tps->dpm0_pg_nb_ps_lo = 0x1;\n\t\tps->dpm0_pg_nb_ps_hi = 0x0;\n\t\tps->dpmx_nb_ps_lo = 0x1;\n\t\tps->dpmx_nb_ps_hi = 0x0;\n\t} else {\n\t\tps->dpm0_pg_nb_ps_lo = 0x3;\n\t\tps->dpm0_pg_nb_ps_hi = 0x0;\n\t\tps->dpmx_nb_ps_lo = 0x3;\n\t\tps->dpmx_nb_ps_hi = 0x0;\n\n\t\tif (pi->sys_info.nb_dpm_enable) {\n\t\t\tforce_high = (mclk >= pi->sys_info.nbp_memory_clock[3]) ||\n\t\t\t\tpi->video_start || (adev->pm.dpm.new_active_crtc_count >= 3) ||\n\t\t\t\tpi->disable_nb_ps3_in_battery;\n\t\t\tps->dpm0_pg_nb_ps_lo = force_high ? 0x2 : 0x3;\n\t\t\tps->dpm0_pg_nb_ps_hi = 0x2;\n\t\t\tps->dpmx_nb_ps_lo = force_high ? 0x2 : 0x3;\n\t\t\tps->dpmx_nb_ps_hi = 0x2;\n\t\t}\n\t}\n}\n\nstatic void kv_dpm_power_level_enabled_for_throttle(struct amdgpu_device *adev,\n\t\t\t\t\t\t    u32 index, bool enable)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tpi->graphics_level[index].EnabledForThrottle = enable ? 1 : 0;\n}\n\nstatic int kv_calculate_ds_divider(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 sclk_in_sr = 10000;  \n\tu32 i;\n\n\tif (pi->lowest_valid > pi->highest_valid)\n\t\treturn -EINVAL;\n\n\tfor (i = pi->lowest_valid; i <= pi->highest_valid; i++) {\n\t\tpi->graphics_level[i].DeepSleepDivId =\n\t\t\tkv_get_sleep_divider_id_from_clock(adev,\n\t\t\t\t\t\t\t   be32_to_cpu(pi->graphics_level[i].SclkFrequency),\n\t\t\t\t\t\t\t   sclk_in_sr);\n\t}\n\treturn 0;\n}\n\nstatic int kv_calculate_nbps_level_settings(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\tbool force_high;\n\tstruct amdgpu_clock_and_voltage_limits *max_limits =\n\t\t&adev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\tu32 mclk = max_limits->mclk;\n\n\tif (pi->lowest_valid > pi->highest_valid)\n\t\treturn -EINVAL;\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS) {\n\t\tfor (i = pi->lowest_valid; i <= pi->highest_valid; i++) {\n\t\t\tpi->graphics_level[i].GnbSlow = 1;\n\t\t\tpi->graphics_level[i].ForceNbPs1 = 0;\n\t\t\tpi->graphics_level[i].UpH = 0;\n\t\t}\n\n\t\tif (!pi->sys_info.nb_dpm_enable)\n\t\t\treturn 0;\n\n\t\tforce_high = ((mclk >= pi->sys_info.nbp_memory_clock[3]) ||\n\t\t\t      (adev->pm.dpm.new_active_crtc_count >= 3) || pi->video_start);\n\n\t\tif (force_high) {\n\t\t\tfor (i = pi->lowest_valid; i <= pi->highest_valid; i++)\n\t\t\t\tpi->graphics_level[i].GnbSlow = 0;\n\t\t} else {\n\t\t\tif (pi->battery_state)\n\t\t\t\tpi->graphics_level[0].ForceNbPs1 = 1;\n\n\t\t\tpi->graphics_level[1].GnbSlow = 0;\n\t\t\tpi->graphics_level[2].GnbSlow = 0;\n\t\t\tpi->graphics_level[3].GnbSlow = 0;\n\t\t\tpi->graphics_level[4].GnbSlow = 0;\n\t\t}\n\t} else {\n\t\tfor (i = pi->lowest_valid; i <= pi->highest_valid; i++) {\n\t\t\tpi->graphics_level[i].GnbSlow = 1;\n\t\t\tpi->graphics_level[i].ForceNbPs1 = 0;\n\t\t\tpi->graphics_level[i].UpH = 0;\n\t\t}\n\n\t\tif (pi->sys_info.nb_dpm_enable && pi->battery_state) {\n\t\t\tpi->graphics_level[pi->lowest_valid].UpH = 0x28;\n\t\t\tpi->graphics_level[pi->lowest_valid].GnbSlow = 0;\n\t\t\tif (pi->lowest_valid != pi->highest_valid)\n\t\t\t\tpi->graphics_level[pi->lowest_valid].ForceNbPs1 = 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int kv_calculate_dpm_settings(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\n\tif (pi->lowest_valid > pi->highest_valid)\n\t\treturn -EINVAL;\n\n\tfor (i = pi->lowest_valid; i <= pi->highest_valid; i++)\n\t\tpi->graphics_level[i].DisplayWatermark = (i == pi->highest_valid) ? 1 : 0;\n\n\treturn 0;\n}\n\nstatic void kv_init_graphics_levels(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\tstruct amdgpu_clock_voltage_dependency_table *table =\n\t\t&adev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\n\tif (table && table->count) {\n\t\tu32 vid_2bit;\n\n\t\tpi->graphics_dpm_level_count = 0;\n\t\tfor (i = 0; i < table->count; i++) {\n\t\t\tif (pi->high_voltage_t &&\n\t\t\t    (pi->high_voltage_t <\n\t\t\t     kv_convert_8bit_index_to_voltage(adev, table->entries[i].v)))\n\t\t\t\tbreak;\n\n\t\t\tkv_set_divider_value(adev, i, table->entries[i].clk);\n\t\t\tvid_2bit = kv_convert_vid7_to_vid2(adev,\n\t\t\t\t\t\t\t   &pi->sys_info.vid_mapping_table,\n\t\t\t\t\t\t\t   table->entries[i].v);\n\t\t\tkv_set_vid(adev, i, vid_2bit);\n\t\t\tkv_set_at(adev, i, pi->at[i]);\n\t\t\tkv_dpm_power_level_enabled_for_throttle(adev, i, true);\n\t\t\tpi->graphics_dpm_level_count++;\n\t\t}\n\t} else {\n\t\tstruct sumo_sclk_voltage_mapping_table *table =\n\t\t\t&pi->sys_info.sclk_voltage_mapping_table;\n\n\t\tpi->graphics_dpm_level_count = 0;\n\t\tfor (i = 0; i < table->num_max_dpm_entries; i++) {\n\t\t\tif (pi->high_voltage_t &&\n\t\t\t    pi->high_voltage_t <\n\t\t\t    kv_convert_2bit_index_to_voltage(adev, table->entries[i].vid_2bit))\n\t\t\t\tbreak;\n\n\t\t\tkv_set_divider_value(adev, i, table->entries[i].sclk_frequency);\n\t\t\tkv_set_vid(adev, i, table->entries[i].vid_2bit);\n\t\t\tkv_set_at(adev, i, pi->at[i]);\n\t\t\tkv_dpm_power_level_enabled_for_throttle(adev, i, true);\n\t\t\tpi->graphics_dpm_level_count++;\n\t\t}\n\t}\n\n\tfor (i = 0; i < SMU7_MAX_LEVELS_GRAPHICS; i++)\n\t\tkv_dpm_power_level_enable(adev, i, false);\n}\n\nstatic void kv_enable_new_levels(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i;\n\n\tfor (i = 0; i < SMU7_MAX_LEVELS_GRAPHICS; i++) {\n\t\tif (i >= pi->lowest_valid && i <= pi->highest_valid)\n\t\t\tkv_dpm_power_level_enable(adev, i, true);\n\t}\n}\n\nstatic int kv_set_enabled_level(struct amdgpu_device *adev, u32 level)\n{\n\tu32 new_mask = (1 << level);\n\n\treturn amdgpu_kv_send_msg_to_smc_with_parameter(adev,\n\t\t\t\t\t\t PPSMC_MSG_SCLKDPM_SetEnabledMask,\n\t\t\t\t\t\t new_mask);\n}\n\nstatic int kv_set_enabled_levels(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 i, new_mask = 0;\n\n\tfor (i = pi->lowest_valid; i <= pi->highest_valid; i++)\n\t\tnew_mask |= (1 << i);\n\n\treturn amdgpu_kv_send_msg_to_smc_with_parameter(adev,\n\t\t\t\t\t\t PPSMC_MSG_SCLKDPM_SetEnabledMask,\n\t\t\t\t\t\t new_mask);\n}\n\nstatic void kv_program_nbps_index_settings(struct amdgpu_device *adev,\n\t\t\t\t\t   struct amdgpu_ps *new_rps)\n{\n\tstruct kv_ps *new_ps = kv_get_ps(new_rps);\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 nbdpmconfig1;\n\n\tif (adev->asic_type == CHIP_KABINI || adev->asic_type == CHIP_MULLINS)\n\t\treturn;\n\n\tif (pi->sys_info.nb_dpm_enable) {\n\t\tnbdpmconfig1 = RREG32_SMC(ixNB_DPM_CONFIG_1);\n\t\tnbdpmconfig1 &= ~(NB_DPM_CONFIG_1__Dpm0PgNbPsLo_MASK |\n\t\t\t\tNB_DPM_CONFIG_1__Dpm0PgNbPsHi_MASK |\n\t\t\t\tNB_DPM_CONFIG_1__DpmXNbPsLo_MASK |\n\t\t\t\tNB_DPM_CONFIG_1__DpmXNbPsHi_MASK);\n\t\tnbdpmconfig1 |= (new_ps->dpm0_pg_nb_ps_lo << NB_DPM_CONFIG_1__Dpm0PgNbPsLo__SHIFT) |\n\t\t\t\t(new_ps->dpm0_pg_nb_ps_hi << NB_DPM_CONFIG_1__Dpm0PgNbPsHi__SHIFT) |\n\t\t\t\t(new_ps->dpmx_nb_ps_lo << NB_DPM_CONFIG_1__DpmXNbPsLo__SHIFT) |\n\t\t\t\t(new_ps->dpmx_nb_ps_hi << NB_DPM_CONFIG_1__DpmXNbPsHi__SHIFT);\n\t\tWREG32_SMC(ixNB_DPM_CONFIG_1, nbdpmconfig1);\n\t}\n}\n\nstatic int kv_set_thermal_temperature_range(struct amdgpu_device *adev,\n\t\t\t\t\t    int min_temp, int max_temp)\n{\n\tint low_temp = 0 * 1000;\n\tint high_temp = 255 * 1000;\n\tu32 tmp;\n\n\tif (low_temp < min_temp)\n\t\tlow_temp = min_temp;\n\tif (high_temp > max_temp)\n\t\thigh_temp = max_temp;\n\tif (high_temp < low_temp) {\n\t\tDRM_ERROR(\"invalid thermal range: %d - %d\\n\", low_temp, high_temp);\n\t\treturn -EINVAL;\n\t}\n\n\ttmp = RREG32_SMC(ixCG_THERMAL_INT_CTRL);\n\ttmp &= ~(CG_THERMAL_INT_CTRL__DIG_THERM_INTH_MASK |\n\t\tCG_THERMAL_INT_CTRL__DIG_THERM_INTL_MASK);\n\ttmp |= ((49 + (high_temp / 1000)) << CG_THERMAL_INT_CTRL__DIG_THERM_INTH__SHIFT) |\n\t\t((49 + (low_temp / 1000)) << CG_THERMAL_INT_CTRL__DIG_THERM_INTL__SHIFT);\n\tWREG32_SMC(ixCG_THERMAL_INT_CTRL, tmp);\n\n\tadev->pm.dpm.thermal.min_temp = low_temp;\n\tadev->pm.dpm.thermal.max_temp = high_temp;\n\n\treturn 0;\n}\n\nunion igp_info {\n\tstruct _ATOM_INTEGRATED_SYSTEM_INFO info;\n\tstruct _ATOM_INTEGRATED_SYSTEM_INFO_V2 info_2;\n\tstruct _ATOM_INTEGRATED_SYSTEM_INFO_V5 info_5;\n\tstruct _ATOM_INTEGRATED_SYSTEM_INFO_V6 info_6;\n\tstruct _ATOM_INTEGRATED_SYSTEM_INFO_V1_7 info_7;\n\tstruct _ATOM_INTEGRATED_SYSTEM_INFO_V1_8 info_8;\n};\n\nstatic int kv_parse_sys_info_table(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct amdgpu_mode_info *mode_info = &adev->mode_info;\n\tint index = GetIndexIntoMasterTable(DATA, IntegratedSystemInfo);\n\tunion igp_info *igp_info;\n\tu8 frev, crev;\n\tu16 data_offset;\n\tint i;\n\n\tif (amdgpu_atom_parse_data_header(mode_info->atom_context, index, NULL,\n\t\t\t\t   &frev, &crev, &data_offset)) {\n\t\tigp_info = (union igp_info *)(mode_info->atom_context->bios +\n\t\t\t\t\t      data_offset);\n\n\t\tif (crev != 8) {\n\t\t\tDRM_ERROR(\"Unsupported IGP table: %d %d\\n\", frev, crev);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tpi->sys_info.bootup_sclk = le32_to_cpu(igp_info->info_8.ulBootUpEngineClock);\n\t\tpi->sys_info.bootup_uma_clk = le32_to_cpu(igp_info->info_8.ulBootUpUMAClock);\n\t\tpi->sys_info.bootup_nb_voltage_index =\n\t\t\tle16_to_cpu(igp_info->info_8.usBootUpNBVoltage);\n\t\tif (igp_info->info_8.ucHtcTmpLmt == 0)\n\t\t\tpi->sys_info.htc_tmp_lmt = 203;\n\t\telse\n\t\t\tpi->sys_info.htc_tmp_lmt = igp_info->info_8.ucHtcTmpLmt;\n\t\tif (igp_info->info_8.ucHtcHystLmt == 0)\n\t\t\tpi->sys_info.htc_hyst_lmt = 5;\n\t\telse\n\t\t\tpi->sys_info.htc_hyst_lmt = igp_info->info_8.ucHtcHystLmt;\n\t\tif (pi->sys_info.htc_tmp_lmt <= pi->sys_info.htc_hyst_lmt) {\n\t\t\tDRM_ERROR(\"The htcTmpLmt should be larger than htcHystLmt.\\n\");\n\t\t}\n\n\t\tif (le32_to_cpu(igp_info->info_8.ulSystemConfig) & (1 << 3))\n\t\t\tpi->sys_info.nb_dpm_enable = true;\n\t\telse\n\t\t\tpi->sys_info.nb_dpm_enable = false;\n\n\t\tfor (i = 0; i < KV_NUM_NBPSTATES; i++) {\n\t\t\tpi->sys_info.nbp_memory_clock[i] =\n\t\t\t\tle32_to_cpu(igp_info->info_8.ulNbpStateMemclkFreq[i]);\n\t\t\tpi->sys_info.nbp_n_clock[i] =\n\t\t\t\tle32_to_cpu(igp_info->info_8.ulNbpStateNClkFreq[i]);\n\t\t}\n\t\tif (le32_to_cpu(igp_info->info_8.ulGPUCapInfo) &\n\t\t    SYS_INFO_GPUCAPS__ENABEL_DFS_BYPASS)\n\t\t\tpi->caps_enable_dfs_bypass = true;\n\n\t\tsumo_construct_sclk_voltage_mapping_table(adev,\n\t\t\t\t\t\t\t  &pi->sys_info.sclk_voltage_mapping_table,\n\t\t\t\t\t\t\t  igp_info->info_8.sAvail_SCLK);\n\n\t\tsumo_construct_vid_mapping_table(adev,\n\t\t\t\t\t\t &pi->sys_info.vid_mapping_table,\n\t\t\t\t\t\t igp_info->info_8.sAvail_SCLK);\n\n\t\tkv_construct_max_power_limits_table(adev,\n\t\t\t\t\t\t    &adev->pm.dpm.dyn_state.max_clock_voltage_on_ac);\n\t}\n\treturn 0;\n}\n\nunion power_info {\n\tstruct _ATOM_POWERPLAY_INFO info;\n\tstruct _ATOM_POWERPLAY_INFO_V2 info_2;\n\tstruct _ATOM_POWERPLAY_INFO_V3 info_3;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE pplib;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE2 pplib2;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE3 pplib3;\n};\n\nunion pplib_clock_info {\n\tstruct _ATOM_PPLIB_R600_CLOCK_INFO r600;\n\tstruct _ATOM_PPLIB_RS780_CLOCK_INFO rs780;\n\tstruct _ATOM_PPLIB_EVERGREEN_CLOCK_INFO evergreen;\n\tstruct _ATOM_PPLIB_SUMO_CLOCK_INFO sumo;\n};\n\nunion pplib_power_state {\n\tstruct _ATOM_PPLIB_STATE v1;\n\tstruct _ATOM_PPLIB_STATE_V2 v2;\n};\n\nstatic void kv_patch_boot_state(struct amdgpu_device *adev,\n\t\t\t\tstruct kv_ps *ps)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\tps->num_levels = 1;\n\tps->levels[0] = pi->boot_pl;\n}\n\nstatic void kv_parse_pplib_non_clock_info(struct amdgpu_device *adev,\n\t\t\t\t\t  struct amdgpu_ps *rps,\n\t\t\t\t\t  struct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info,\n\t\t\t\t\t  u8 table_rev)\n{\n\tstruct kv_ps *ps = kv_get_ps(rps);\n\n\trps->caps = le32_to_cpu(non_clock_info->ulCapsAndSettings);\n\trps->class = le16_to_cpu(non_clock_info->usClassification);\n\trps->class2 = le16_to_cpu(non_clock_info->usClassification2);\n\n\tif (ATOM_PPLIB_NONCLOCKINFO_VER1 < table_rev) {\n\t\trps->vclk = le32_to_cpu(non_clock_info->ulVCLK);\n\t\trps->dclk = le32_to_cpu(non_clock_info->ulDCLK);\n\t} else {\n\t\trps->vclk = 0;\n\t\trps->dclk = 0;\n\t}\n\n\tif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT) {\n\t\tadev->pm.dpm.boot_ps = rps;\n\t\tkv_patch_boot_state(adev, ps);\n\t}\n\tif (rps->class & ATOM_PPLIB_CLASSIFICATION_UVDSTATE)\n\t\tadev->pm.dpm.uvd_ps = rps;\n}\n\nstatic void kv_parse_pplib_clock_info(struct amdgpu_device *adev,\n\t\t\t\t      struct amdgpu_ps *rps, int index,\n\t\t\t\t\tunion pplib_clock_info *clock_info)\n{\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct kv_ps *ps = kv_get_ps(rps);\n\tstruct kv_pl *pl = &ps->levels[index];\n\tu32 sclk;\n\n\tsclk = le16_to_cpu(clock_info->sumo.usEngineClockLow);\n\tsclk |= clock_info->sumo.ucEngineClockHigh << 16;\n\tpl->sclk = sclk;\n\tpl->vddc_index = clock_info->sumo.vddcIndex;\n\n\tps->num_levels = index + 1;\n\n\tif (pi->caps_sclk_ds) {\n\t\tpl->ds_divider_index = 5;\n\t\tpl->ss_divider_index = 5;\n\t}\n}\n\nstatic int kv_parse_power_table(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_mode_info *mode_info = &adev->mode_info;\n\tstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info;\n\tunion pplib_power_state *power_state;\n\tint i, j, k, non_clock_array_index, clock_array_index;\n\tunion pplib_clock_info *clock_info;\n\tstruct _StateArray *state_array;\n\tstruct _ClockInfoArray *clock_info_array;\n\tstruct _NonClockInfoArray *non_clock_info_array;\n\tunion power_info *power_info;\n\tint index = GetIndexIntoMasterTable(DATA, PowerPlayInfo);\n\tu16 data_offset;\n\tu8 frev, crev;\n\tu8 *power_state_offset;\n\tstruct kv_ps *ps;\n\n\tif (!amdgpu_atom_parse_data_header(mode_info->atom_context, index, NULL,\n\t\t\t\t   &frev, &crev, &data_offset))\n\t\treturn -EINVAL;\n\tpower_info = (union power_info *)(mode_info->atom_context->bios + data_offset);\n\n\tamdgpu_add_thermal_controller(adev);\n\n\tstate_array = (struct _StateArray *)\n\t\t(mode_info->atom_context->bios + data_offset +\n\t\t le16_to_cpu(power_info->pplib.usStateArrayOffset));\n\tclock_info_array = (struct _ClockInfoArray *)\n\t\t(mode_info->atom_context->bios + data_offset +\n\t\t le16_to_cpu(power_info->pplib.usClockInfoArrayOffset));\n\tnon_clock_info_array = (struct _NonClockInfoArray *)\n\t\t(mode_info->atom_context->bios + data_offset +\n\t\t le16_to_cpu(power_info->pplib.usNonClockInfoArrayOffset));\n\n\tadev->pm.dpm.ps = kcalloc(state_array->ucNumEntries,\n\t\t\t\t  sizeof(struct amdgpu_ps),\n\t\t\t\t  GFP_KERNEL);\n\tif (!adev->pm.dpm.ps)\n\t\treturn -ENOMEM;\n\tpower_state_offset = (u8 *)state_array->states;\n\tfor (i = 0; i < state_array->ucNumEntries; i++) {\n\t\tu8 *idx;\n\t\tpower_state = (union pplib_power_state *)power_state_offset;\n\t\tnon_clock_array_index = power_state->v2.nonClockInfoIndex;\n\t\tnon_clock_info = (struct _ATOM_PPLIB_NONCLOCK_INFO *)\n\t\t\t&non_clock_info_array->nonClockInfo[non_clock_array_index];\n\t\tps = kzalloc(sizeof(struct kv_ps), GFP_KERNEL);\n\t\tif (ps == NULL)\n\t\t\treturn -ENOMEM;\n\t\tadev->pm.dpm.ps[i].ps_priv = ps;\n\t\tk = 0;\n\t\tidx = (u8 *)&power_state->v2.clockInfoIndex[0];\n\t\tfor (j = 0; j < power_state->v2.ucNumDPMLevels; j++) {\n\t\t\tclock_array_index = idx[j];\n\t\t\tif (clock_array_index >= clock_info_array->ucNumEntries)\n\t\t\t\tcontinue;\n\t\t\tif (k >= SUMO_MAX_HARDWARE_POWERLEVELS)\n\t\t\t\tbreak;\n\t\t\tclock_info = (union pplib_clock_info *)\n\t\t\t\t((u8 *)&clock_info_array->clockInfo[0] +\n\t\t\t\t (clock_array_index * clock_info_array->ucEntrySize));\n\t\t\tkv_parse_pplib_clock_info(adev,\n\t\t\t\t\t\t  &adev->pm.dpm.ps[i], k,\n\t\t\t\t\t\t  clock_info);\n\t\t\tk++;\n\t\t}\n\t\tkv_parse_pplib_non_clock_info(adev, &adev->pm.dpm.ps[i],\n\t\t\t\t\t      non_clock_info,\n\t\t\t\t\t      non_clock_info_array->ucEntrySize);\n\t\tpower_state_offset += 2 + power_state->v2.ucNumDPMLevels;\n\t}\n\tadev->pm.dpm.num_ps = state_array->ucNumEntries;\n\n\t \n\tfor (i = 0; i < adev->pm.dpm.num_of_vce_states; i++) {\n\t\tu32 sclk;\n\t\tclock_array_index = adev->pm.dpm.vce_states[i].clk_idx;\n\t\tclock_info = (union pplib_clock_info *)\n\t\t\t&clock_info_array->clockInfo[clock_array_index * clock_info_array->ucEntrySize];\n\t\tsclk = le16_to_cpu(clock_info->sumo.usEngineClockLow);\n\t\tsclk |= clock_info->sumo.ucEngineClockHigh << 16;\n\t\tadev->pm.dpm.vce_states[i].sclk = sclk;\n\t\tadev->pm.dpm.vce_states[i].mclk = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic int kv_dpm_init(struct amdgpu_device *adev)\n{\n\tstruct kv_power_info *pi;\n\tint ret, i;\n\n\tpi = kzalloc(sizeof(struct kv_power_info), GFP_KERNEL);\n\tif (pi == NULL)\n\t\treturn -ENOMEM;\n\tadev->pm.dpm.priv = pi;\n\n\tret = amdgpu_get_platform_caps(adev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_parse_extended_power_table(adev);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < SUMO_MAX_HARDWARE_POWERLEVELS; i++)\n\t\tpi->at[i] = TRINITY_AT_DFLT;\n\n\tpi->sram_end = SMC_RAM_END;\n\n\tpi->enable_nb_dpm = true;\n\n\tpi->caps_power_containment = true;\n\tpi->caps_cac = true;\n\tpi->enable_didt = false;\n\tif (pi->enable_didt) {\n\t\tpi->caps_sq_ramping = true;\n\t\tpi->caps_db_ramping = true;\n\t\tpi->caps_td_ramping = true;\n\t\tpi->caps_tcp_ramping = true;\n\t}\n\n\tif (adev->pm.pp_feature & PP_SCLK_DEEP_SLEEP_MASK)\n\t\tpi->caps_sclk_ds = true;\n\telse\n\t\tpi->caps_sclk_ds = false;\n\n\tpi->enable_auto_thermal_throttling = true;\n\tpi->disable_nb_ps3_in_battery = false;\n\tif (amdgpu_bapm == 0)\n\t\tpi->bapm_enable = false;\n\telse\n\t\tpi->bapm_enable = true;\n\tpi->voltage_drop_t = 0;\n\tpi->caps_sclk_throttle_low_notification = false;\n\tpi->caps_fps = false;  \n\tpi->caps_uvd_pg = (adev->pg_flags & AMD_PG_SUPPORT_UVD) ? true : false;\n\tpi->caps_uvd_dpm = true;\n\tpi->caps_vce_pg = (adev->pg_flags & AMD_PG_SUPPORT_VCE) ? true : false;\n\tpi->caps_samu_pg = (adev->pg_flags & AMD_PG_SUPPORT_SAMU) ? true : false;\n\tpi->caps_acp_pg = (adev->pg_flags & AMD_PG_SUPPORT_ACP) ? true : false;\n\tpi->caps_stable_p_state = false;\n\n\tret = kv_parse_sys_info_table(adev);\n\tif (ret)\n\t\treturn ret;\n\n\tkv_patch_voltage_values(adev);\n\tkv_construct_boot_state(adev);\n\n\tret = kv_parse_power_table(adev);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->enable_dpm = true;\n\n\treturn 0;\n}\n\nstatic void\nkv_dpm_debugfs_print_current_performance_level(void *handle,\n\t\t\t\t\t       struct seq_file *m)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tu32 current_index =\n\t\t(RREG32_SMC(ixTARGET_AND_CURRENT_PROFILE_INDEX) &\n\t\tTARGET_AND_CURRENT_PROFILE_INDEX__CURR_SCLK_INDEX_MASK) >>\n\t\tTARGET_AND_CURRENT_PROFILE_INDEX__CURR_SCLK_INDEX__SHIFT;\n\tu32 sclk, tmp;\n\tu16 vddc;\n\n\tif (current_index >= SMU__NUM_SCLK_DPM_STATE) {\n\t\tseq_printf(m, \"invalid dpm profile %d\\n\", current_index);\n\t} else {\n\t\tsclk = be32_to_cpu(pi->graphics_level[current_index].SclkFrequency);\n\t\ttmp = (RREG32_SMC(ixSMU_VOLTAGE_STATUS) &\n\t\t\tSMU_VOLTAGE_STATUS__SMU_VOLTAGE_CURRENT_LEVEL_MASK) >>\n\t\t\tSMU_VOLTAGE_STATUS__SMU_VOLTAGE_CURRENT_LEVEL__SHIFT;\n\t\tvddc = kv_convert_8bit_index_to_voltage(adev, (u16)tmp);\n\t\tseq_printf(m, \"uvd    %sabled\\n\", pi->uvd_power_gated ? \"dis\" : \"en\");\n\t\tseq_printf(m, \"vce    %sabled\\n\", pi->vce_power_gated ? \"dis\" : \"en\");\n\t\tseq_printf(m, \"power level %d    sclk: %u vddc: %u\\n\",\n\t\t\t   current_index, sclk, vddc);\n\t}\n}\n\nstatic void\nkv_dpm_print_power_state(void *handle, void *request_ps)\n{\n\tint i;\n\tstruct amdgpu_ps *rps = (struct amdgpu_ps *)request_ps;\n\tstruct kv_ps *ps = kv_get_ps(rps);\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tamdgpu_dpm_print_class_info(rps->class, rps->class2);\n\tamdgpu_dpm_print_cap_info(rps->caps);\n\tprintk(\"\\tuvd    vclk: %d dclk: %d\\n\", rps->vclk, rps->dclk);\n\tfor (i = 0; i < ps->num_levels; i++) {\n\t\tstruct kv_pl *pl = &ps->levels[i];\n\t\tprintk(\"\\t\\tpower level %d    sclk: %u vddc: %u\\n\",\n\t\t       i, pl->sclk,\n\t\t       kv_convert_8bit_index_to_voltage(adev, pl->vddc_index));\n\t}\n\tamdgpu_dpm_print_ps_status(adev, rps);\n}\n\nstatic void kv_dpm_fini(struct amdgpu_device *adev)\n{\n\tint i;\n\n\tfor (i = 0; i < adev->pm.dpm.num_ps; i++) {\n\t\tkfree(adev->pm.dpm.ps[i].ps_priv);\n\t}\n\tkfree(adev->pm.dpm.ps);\n\tkfree(adev->pm.dpm.priv);\n\tamdgpu_free_extended_power_table(adev);\n}\n\nstatic void kv_dpm_display_configuration_changed(void *handle)\n{\n\n}\n\nstatic u32 kv_dpm_get_sclk(void *handle, bool low)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tstruct kv_ps *requested_state = kv_get_ps(&pi->requested_rps);\n\n\tif (low)\n\t\treturn requested_state->levels[0].sclk;\n\telse\n\t\treturn requested_state->levels[requested_state->num_levels - 1].sclk;\n}\n\nstatic u32 kv_dpm_get_mclk(void *handle, bool low)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\n\treturn pi->sys_info.bootup_uma_clk;\n}\n\n \nstatic int kv_dpm_get_temp(void *handle)\n{\n\tu32 temp;\n\tint actual_temp = 0;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\ttemp = RREG32_SMC(0xC0300E0C);\n\n\tif (temp)\n\t\tactual_temp = (temp / 8) - 49;\n\telse\n\t\tactual_temp = 0;\n\n\tactual_temp = actual_temp * 1000;\n\n\treturn actual_temp;\n}\n\nstatic int kv_dpm_early_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tadev->powerplay.pp_funcs = &kv_dpm_funcs;\n\tadev->powerplay.pp_handle = adev;\n\tkv_dpm_set_irq_funcs(adev);\n\n\treturn 0;\n}\n\nstatic int kv_dpm_late_init(void *handle)\n{\n\t \n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (!adev->pm.dpm_enabled)\n\t\treturn 0;\n\n\tkv_dpm_powergate_acp(adev, true);\n\tkv_dpm_powergate_samu(adev, true);\n\n\treturn 0;\n}\n\nstatic int kv_dpm_sw_init(void *handle)\n{\n\tint ret;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tret = amdgpu_irq_add_id(adev, AMDGPU_IRQ_CLIENTID_LEGACY, 230,\n\t\t\t\t&adev->pm.dpm.thermal.irq);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_irq_add_id(adev, AMDGPU_IRQ_CLIENTID_LEGACY, 231,\n\t\t\t\t&adev->pm.dpm.thermal.irq);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tadev->pm.dpm.state = POWER_STATE_TYPE_BALANCED;\n\tadev->pm.dpm.user_state = POWER_STATE_TYPE_BALANCED;\n\tadev->pm.dpm.forced_level = AMD_DPM_FORCED_LEVEL_AUTO;\n\tadev->pm.default_sclk = adev->clock.default_sclk;\n\tadev->pm.default_mclk = adev->clock.default_mclk;\n\tadev->pm.current_sclk = adev->clock.default_sclk;\n\tadev->pm.current_mclk = adev->clock.default_mclk;\n\tadev->pm.int_thermal_type = THERMAL_TYPE_NONE;\n\n\tif (amdgpu_dpm == 0)\n\t\treturn 0;\n\n\tINIT_WORK(&adev->pm.dpm.thermal.work, amdgpu_dpm_thermal_work_handler);\n\tret = kv_dpm_init(adev);\n\tif (ret)\n\t\tgoto dpm_failed;\n\tadev->pm.dpm.current_ps = adev->pm.dpm.requested_ps = adev->pm.dpm.boot_ps;\n\tif (amdgpu_dpm == 1)\n\t\tamdgpu_pm_print_power_states(adev);\n\tDRM_INFO(\"amdgpu: dpm initialized\\n\");\n\n\treturn 0;\n\ndpm_failed:\n\tkv_dpm_fini(adev);\n\tDRM_ERROR(\"amdgpu: dpm initialization failed\\n\");\n\treturn ret;\n}\n\nstatic int kv_dpm_sw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tflush_work(&adev->pm.dpm.thermal.work);\n\n\tkv_dpm_fini(adev);\n\n\treturn 0;\n}\n\nstatic int kv_dpm_hw_init(void *handle)\n{\n\tint ret;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (!amdgpu_dpm)\n\t\treturn 0;\n\n\tkv_dpm_setup_asic(adev);\n\tret = kv_dpm_enable(adev);\n\tif (ret)\n\t\tadev->pm.dpm_enabled = false;\n\telse\n\t\tadev->pm.dpm_enabled = true;\n\tamdgpu_legacy_dpm_compute_clocks(adev);\n\treturn ret;\n}\n\nstatic int kv_dpm_hw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (adev->pm.dpm_enabled)\n\t\tkv_dpm_disable(adev);\n\n\treturn 0;\n}\n\nstatic int kv_dpm_suspend(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (adev->pm.dpm_enabled) {\n\t\t \n\t\tkv_dpm_disable(adev);\n\t\t \n\t\tadev->pm.dpm.current_ps = adev->pm.dpm.requested_ps = adev->pm.dpm.boot_ps;\n\t}\n\treturn 0;\n}\n\nstatic int kv_dpm_resume(void *handle)\n{\n\tint ret;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (adev->pm.dpm_enabled) {\n\t\t \n\t\tkv_dpm_setup_asic(adev);\n\t\tret = kv_dpm_enable(adev);\n\t\tif (ret)\n\t\t\tadev->pm.dpm_enabled = false;\n\t\telse\n\t\t\tadev->pm.dpm_enabled = true;\n\t\tif (adev->pm.dpm_enabled)\n\t\t\tamdgpu_legacy_dpm_compute_clocks(adev);\n\t}\n\treturn 0;\n}\n\nstatic bool kv_dpm_is_idle(void *handle)\n{\n\treturn true;\n}\n\nstatic int kv_dpm_wait_for_idle(void *handle)\n{\n\treturn 0;\n}\n\n\nstatic int kv_dpm_soft_reset(void *handle)\n{\n\treturn 0;\n}\n\nstatic int kv_dpm_set_interrupt_state(struct amdgpu_device *adev,\n\t\t\t\t      struct amdgpu_irq_src *src,\n\t\t\t\t      unsigned type,\n\t\t\t\t      enum amdgpu_interrupt_state state)\n{\n\tu32 cg_thermal_int;\n\n\tswitch (type) {\n\tcase AMDGPU_THERMAL_IRQ_LOW_TO_HIGH:\n\t\tswitch (state) {\n\t\tcase AMDGPU_IRQ_STATE_DISABLE:\n\t\t\tcg_thermal_int = RREG32_SMC(ixCG_THERMAL_INT_CTRL);\n\t\t\tcg_thermal_int &= ~CG_THERMAL_INT_CTRL__THERM_INTH_MASK_MASK;\n\t\t\tWREG32_SMC(ixCG_THERMAL_INT_CTRL, cg_thermal_int);\n\t\t\tbreak;\n\t\tcase AMDGPU_IRQ_STATE_ENABLE:\n\t\t\tcg_thermal_int = RREG32_SMC(ixCG_THERMAL_INT_CTRL);\n\t\t\tcg_thermal_int |= CG_THERMAL_INT_CTRL__THERM_INTH_MASK_MASK;\n\t\t\tWREG32_SMC(ixCG_THERMAL_INT_CTRL, cg_thermal_int);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase AMDGPU_THERMAL_IRQ_HIGH_TO_LOW:\n\t\tswitch (state) {\n\t\tcase AMDGPU_IRQ_STATE_DISABLE:\n\t\t\tcg_thermal_int = RREG32_SMC(ixCG_THERMAL_INT_CTRL);\n\t\t\tcg_thermal_int &= ~CG_THERMAL_INT_CTRL__THERM_INTL_MASK_MASK;\n\t\t\tWREG32_SMC(ixCG_THERMAL_INT_CTRL, cg_thermal_int);\n\t\t\tbreak;\n\t\tcase AMDGPU_IRQ_STATE_ENABLE:\n\t\t\tcg_thermal_int = RREG32_SMC(ixCG_THERMAL_INT_CTRL);\n\t\t\tcg_thermal_int |= CG_THERMAL_INT_CTRL__THERM_INTL_MASK_MASK;\n\t\t\tWREG32_SMC(ixCG_THERMAL_INT_CTRL, cg_thermal_int);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int kv_dpm_process_interrupt(struct amdgpu_device *adev,\n\t\t\t\t    struct amdgpu_irq_src *source,\n\t\t\t\t    struct amdgpu_iv_entry *entry)\n{\n\tbool queue_thermal = false;\n\n\tif (entry == NULL)\n\t\treturn -EINVAL;\n\n\tswitch (entry->src_id) {\n\tcase 230:  \n\t\tDRM_DEBUG(\"IH: thermal low to high\\n\");\n\t\tadev->pm.dpm.thermal.high_to_low = false;\n\t\tqueue_thermal = true;\n\t\tbreak;\n\tcase 231:  \n\t\tDRM_DEBUG(\"IH: thermal high to low\\n\");\n\t\tadev->pm.dpm.thermal.high_to_low = true;\n\t\tqueue_thermal = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (queue_thermal)\n\t\tschedule_work(&adev->pm.dpm.thermal.work);\n\n\treturn 0;\n}\n\nstatic int kv_dpm_set_clockgating_state(void *handle,\n\t\t\t\t\t  enum amd_clockgating_state state)\n{\n\treturn 0;\n}\n\nstatic int kv_dpm_set_powergating_state(void *handle,\n\t\t\t\t\t  enum amd_powergating_state state)\n{\n\treturn 0;\n}\n\nstatic inline bool kv_are_power_levels_equal(const struct kv_pl *kv_cpl1,\n\t\t\t\t\t\tconst struct kv_pl *kv_cpl2)\n{\n\treturn ((kv_cpl1->sclk == kv_cpl2->sclk) &&\n\t\t  (kv_cpl1->vddc_index == kv_cpl2->vddc_index) &&\n\t\t  (kv_cpl1->ds_divider_index == kv_cpl2->ds_divider_index) &&\n\t\t  (kv_cpl1->force_nbp_state == kv_cpl2->force_nbp_state));\n}\n\nstatic int kv_check_state_equal(void *handle,\n\t\t\t\tvoid *current_ps,\n\t\t\t\tvoid *request_ps,\n\t\t\t\tbool *equal)\n{\n\tstruct kv_ps *kv_cps;\n\tstruct kv_ps *kv_rps;\n\tint i;\n\tstruct amdgpu_ps *cps = (struct amdgpu_ps *)current_ps;\n\tstruct amdgpu_ps *rps = (struct amdgpu_ps *)request_ps;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tif (adev == NULL || cps == NULL || rps == NULL || equal == NULL)\n\t\treturn -EINVAL;\n\n\tkv_cps = kv_get_ps(cps);\n\tkv_rps = kv_get_ps(rps);\n\n\tif (kv_cps == NULL) {\n\t\t*equal = false;\n\t\treturn 0;\n\t}\n\n\tif (kv_cps->num_levels != kv_rps->num_levels) {\n\t\t*equal = false;\n\t\treturn 0;\n\t}\n\n\tfor (i = 0; i < kv_cps->num_levels; i++) {\n\t\tif (!kv_are_power_levels_equal(&(kv_cps->levels[i]),\n\t\t\t\t\t&(kv_rps->levels[i]))) {\n\t\t\t*equal = false;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\t*equal = ((cps->vclk == rps->vclk) && (cps->dclk == rps->dclk));\n\t*equal &= ((cps->evclk == rps->evclk) && (cps->ecclk == rps->ecclk));\n\n\treturn 0;\n}\n\nstatic int kv_dpm_read_sensor(void *handle, int idx,\n\t\t\t      void *value, int *size)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct kv_power_info *pi = kv_get_pi(adev);\n\tuint32_t sclk;\n\tu32 pl_index =\n\t\t(RREG32_SMC(ixTARGET_AND_CURRENT_PROFILE_INDEX) &\n\t\tTARGET_AND_CURRENT_PROFILE_INDEX__CURR_SCLK_INDEX_MASK) >>\n\t\tTARGET_AND_CURRENT_PROFILE_INDEX__CURR_SCLK_INDEX__SHIFT;\n\n\t \n\tif (*size < 4)\n\t\treturn -EINVAL;\n\n\tswitch (idx) {\n\tcase AMDGPU_PP_SENSOR_GFX_SCLK:\n\t\tif (pl_index < SMU__NUM_SCLK_DPM_STATE) {\n\t\t\tsclk = be32_to_cpu(\n\t\t\t\tpi->graphics_level[pl_index].SclkFrequency);\n\t\t\t*((uint32_t *)value) = sclk;\n\t\t\t*size = 4;\n\t\t\treturn 0;\n\t\t}\n\t\treturn -EINVAL;\n\tcase AMDGPU_PP_SENSOR_GPU_TEMP:\n\t\t*((uint32_t *)value) = kv_dpm_get_temp(adev);\n\t\t*size = 4;\n\t\treturn 0;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int kv_set_powergating_by_smu(void *handle,\n\t\t\t\tuint32_t block_type, bool gate)\n{\n\tswitch (block_type) {\n\tcase AMD_IP_BLOCK_TYPE_UVD:\n\t\tkv_dpm_powergate_uvd(handle, gate);\n\t\tbreak;\n\tcase AMD_IP_BLOCK_TYPE_VCE:\n\t\tkv_dpm_powergate_vce(handle, gate);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic const struct amd_ip_funcs kv_dpm_ip_funcs = {\n\t.name = \"kv_dpm\",\n\t.early_init = kv_dpm_early_init,\n\t.late_init = kv_dpm_late_init,\n\t.sw_init = kv_dpm_sw_init,\n\t.sw_fini = kv_dpm_sw_fini,\n\t.hw_init = kv_dpm_hw_init,\n\t.hw_fini = kv_dpm_hw_fini,\n\t.suspend = kv_dpm_suspend,\n\t.resume = kv_dpm_resume,\n\t.is_idle = kv_dpm_is_idle,\n\t.wait_for_idle = kv_dpm_wait_for_idle,\n\t.soft_reset = kv_dpm_soft_reset,\n\t.set_clockgating_state = kv_dpm_set_clockgating_state,\n\t.set_powergating_state = kv_dpm_set_powergating_state,\n};\n\nconst struct amdgpu_ip_block_version kv_smu_ip_block = {\n\t.type = AMD_IP_BLOCK_TYPE_SMC,\n\t.major = 1,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &kv_dpm_ip_funcs,\n};\n\nstatic const struct amd_pm_funcs kv_dpm_funcs = {\n\t.pre_set_power_state = &kv_dpm_pre_set_power_state,\n\t.set_power_state = &kv_dpm_set_power_state,\n\t.post_set_power_state = &kv_dpm_post_set_power_state,\n\t.display_configuration_changed = &kv_dpm_display_configuration_changed,\n\t.get_sclk = &kv_dpm_get_sclk,\n\t.get_mclk = &kv_dpm_get_mclk,\n\t.print_power_state = &kv_dpm_print_power_state,\n\t.debugfs_print_current_performance_level = &kv_dpm_debugfs_print_current_performance_level,\n\t.force_performance_level = &kv_dpm_force_performance_level,\n\t.set_powergating_by_smu = kv_set_powergating_by_smu,\n\t.enable_bapm = &kv_dpm_enable_bapm,\n\t.get_vce_clock_state = amdgpu_get_vce_clock_state,\n\t.check_state_equal = kv_check_state_equal,\n\t.read_sensor = &kv_dpm_read_sensor,\n\t.pm_compute_clocks = amdgpu_legacy_dpm_compute_clocks,\n};\n\nstatic const struct amdgpu_irq_src_funcs kv_dpm_irq_funcs = {\n\t.set = kv_dpm_set_interrupt_state,\n\t.process = kv_dpm_process_interrupt,\n};\n\nstatic void kv_dpm_set_irq_funcs(struct amdgpu_device *adev)\n{\n\tadev->pm.dpm.thermal.irq.num_types = AMDGPU_THERMAL_IRQ_LAST;\n\tadev->pm.dpm.thermal.irq.funcs = &kv_dpm_irq_funcs;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}