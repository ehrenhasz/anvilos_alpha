{
  "module_name": "amdgpu_pm.c",
  "hash_id": "cbcba0feed518a643f461d01c97297b57299a19eeaec4924703d2f5ee4170003",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/pm/amdgpu_pm.c",
  "human_readable_source": " \n\n#include \"amdgpu.h\"\n#include \"amdgpu_drv.h\"\n#include \"amdgpu_pm.h\"\n#include \"amdgpu_dpm.h\"\n#include \"atom.h\"\n#include <linux/pci.h>\n#include <linux/hwmon.h>\n#include <linux/hwmon-sysfs.h>\n#include <linux/nospec.h>\n#include <linux/pm_runtime.h>\n#include <asm/processor.h>\n\nstatic const struct hwmon_temp_label {\n\tenum PP_HWMON_TEMP channel;\n\tconst char *label;\n} temp_label[] = {\n\t{PP_TEMP_EDGE, \"edge\"},\n\t{PP_TEMP_JUNCTION, \"junction\"},\n\t{PP_TEMP_MEM, \"mem\"},\n};\n\nconst char * const amdgpu_pp_profile_name[] = {\n\t\"BOOTUP_DEFAULT\",\n\t\"3D_FULL_SCREEN\",\n\t\"POWER_SAVING\",\n\t\"VIDEO\",\n\t\"VR\",\n\t\"COMPUTE\",\n\t\"CUSTOM\",\n\t\"WINDOW_3D\",\n\t\"CAPPED\",\n\t\"UNCAPPED\",\n};\n\n \n\nstatic ssize_t amdgpu_get_power_dpm_state(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tenum amd_pm_state_type pm;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tamdgpu_dpm_get_current_power_state(adev, &pm);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\",\n\t\t\t  (pm == POWER_STATE_TYPE_BATTERY) ? \"battery\" :\n\t\t\t  (pm == POWER_STATE_TYPE_BALANCED) ? \"balanced\" : \"performance\");\n}\n\nstatic ssize_t amdgpu_set_power_dpm_state(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  const char *buf,\n\t\t\t\t\t  size_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tenum amd_pm_state_type  state;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tif (strncmp(\"battery\", buf, strlen(\"battery\")) == 0)\n\t\tstate = POWER_STATE_TYPE_BATTERY;\n\telse if (strncmp(\"balanced\", buf, strlen(\"balanced\")) == 0)\n\t\tstate = POWER_STATE_TYPE_BALANCED;\n\telse if (strncmp(\"performance\", buf, strlen(\"performance\")) == 0)\n\t\tstate = POWER_STATE_TYPE_PERFORMANCE;\n\telse\n\t\treturn -EINVAL;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tamdgpu_dpm_set_power_state(adev, state);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn count;\n}\n\n\n \n\nstatic ssize_t amdgpu_get_power_dpm_force_performance_level(struct device *dev,\n\t\t\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t\t\t    char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tenum amd_dpm_forced_level level = 0xff;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tlevel = amdgpu_dpm_get_performance_level(adev);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn sysfs_emit(buf, \"%s\\n\",\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_AUTO) ? \"auto\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_LOW) ? \"low\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_HIGH) ? \"high\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_MANUAL) ? \"manual\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_PROFILE_STANDARD) ? \"profile_standard\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_PROFILE_MIN_SCLK) ? \"profile_min_sclk\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_PROFILE_MIN_MCLK) ? \"profile_min_mclk\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_PROFILE_PEAK) ? \"profile_peak\" :\n\t\t\t  (level == AMD_DPM_FORCED_LEVEL_PERF_DETERMINISM) ? \"perf_determinism\" :\n\t\t\t  \"unknown\");\n}\n\nstatic ssize_t amdgpu_set_power_dpm_force_performance_level(struct device *dev,\n\t\t\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t\t\t    const char *buf,\n\t\t\t\t\t\t\t    size_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tenum amd_dpm_forced_level level;\n\tint ret = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tif (strncmp(\"low\", buf, strlen(\"low\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_LOW;\n\t} else if (strncmp(\"high\", buf, strlen(\"high\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_HIGH;\n\t} else if (strncmp(\"auto\", buf, strlen(\"auto\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_AUTO;\n\t} else if (strncmp(\"manual\", buf, strlen(\"manual\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_MANUAL;\n\t} else if (strncmp(\"profile_exit\", buf, strlen(\"profile_exit\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_PROFILE_EXIT;\n\t} else if (strncmp(\"profile_standard\", buf, strlen(\"profile_standard\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_PROFILE_STANDARD;\n\t} else if (strncmp(\"profile_min_sclk\", buf, strlen(\"profile_min_sclk\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_PROFILE_MIN_SCLK;\n\t} else if (strncmp(\"profile_min_mclk\", buf, strlen(\"profile_min_mclk\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_PROFILE_MIN_MCLK;\n\t} else if (strncmp(\"profile_peak\", buf, strlen(\"profile_peak\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_PROFILE_PEAK;\n\t} else if (strncmp(\"perf_determinism\", buf, strlen(\"perf_determinism\")) == 0) {\n\t\tlevel = AMD_DPM_FORCED_LEVEL_PERF_DETERMINISM;\n\t}  else {\n\t\treturn -EINVAL;\n\t}\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&adev->pm.stable_pstate_ctx_lock);\n\tif (amdgpu_dpm_force_performance_level(adev, level)) {\n\t\tpm_runtime_mark_last_busy(ddev->dev);\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\tmutex_unlock(&adev->pm.stable_pstate_ctx_lock);\n\t\treturn -EINVAL;\n\t}\n\t \n\tadev->pm.stable_pstate_ctx = NULL;\n\tmutex_unlock(&adev->pm.stable_pstate_ctx_lock);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_get_pp_num_states(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tstruct pp_states_info data;\n\tuint32_t i;\n\tint buf_len, ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tif (amdgpu_dpm_get_pp_num_states(adev, &data))\n\t\tmemset(&data, 0, sizeof(data));\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\tbuf_len = sysfs_emit(buf, \"states: %d\\n\", data.nums);\n\tfor (i = 0; i < data.nums; i++)\n\t\tbuf_len += sysfs_emit_at(buf, buf_len, \"%d %s\\n\", i,\n\t\t\t\t(data.states[i] == POWER_STATE_TYPE_INTERNAL_BOOT) ? \"boot\" :\n\t\t\t\t(data.states[i] == POWER_STATE_TYPE_BATTERY) ? \"battery\" :\n\t\t\t\t(data.states[i] == POWER_STATE_TYPE_BALANCED) ? \"balanced\" :\n\t\t\t\t(data.states[i] == POWER_STATE_TYPE_PERFORMANCE) ? \"performance\" : \"default\");\n\n\treturn buf_len;\n}\n\nstatic ssize_t amdgpu_get_pp_cur_state(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tstruct pp_states_info data = {0};\n\tenum amd_pm_state_type pm = 0;\n\tint i = 0, ret = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tamdgpu_dpm_get_current_power_state(adev, &pm);\n\n\tret = amdgpu_dpm_get_pp_num_states(adev, &data);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < data.nums; i++) {\n\t\tif (pm == data.states[i])\n\t\t\tbreak;\n\t}\n\n\tif (i == data.nums)\n\t\ti = -EINVAL;\n\n\treturn sysfs_emit(buf, \"%d\\n\", i);\n}\n\nstatic ssize_t amdgpu_get_pp_force_state(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tif (adev->pm.pp_force_state_enabled)\n\t\treturn amdgpu_get_pp_cur_state(dev, attr, buf);\n\telse\n\t\treturn sysfs_emit(buf, \"\\n\");\n}\n\nstatic ssize_t amdgpu_set_pp_force_state(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tenum amd_pm_state_type state = 0;\n\tstruct pp_states_info data;\n\tunsigned long idx;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tadev->pm.pp_force_state_enabled = false;\n\n\tif (strlen(buf) == 1)\n\t\treturn count;\n\n\tret = kstrtoul(buf, 0, &idx);\n\tif (ret || idx >= ARRAY_SIZE(data.states))\n\t\treturn -EINVAL;\n\n\tidx = array_index_nospec(idx, ARRAY_SIZE(data.states));\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_get_pp_num_states(adev, &data);\n\tif (ret)\n\t\tgoto err_out;\n\n\tstate = data.states[idx];\n\n\t \n\tif (state != POWER_STATE_TYPE_INTERNAL_BOOT &&\n\t    state != POWER_STATE_TYPE_DEFAULT) {\n\t\tret = amdgpu_dpm_dispatch_task(adev,\n\t\t\t\tAMD_PP_TASK_ENABLE_USER_STATE, &state);\n\t\tif (ret)\n\t\t\tgoto err_out;\n\n\t\tadev->pm.pp_force_state_enabled = true;\n\t}\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn count;\n\nerr_out:\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\treturn ret;\n}\n\n \n\nstatic ssize_t amdgpu_get_pp_table(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tchar *table = NULL;\n\tint size, ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tsize = amdgpu_dpm_get_pp_table(adev, &table);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\tif (size <= 0)\n\t\treturn size;\n\n\tif (size >= PAGE_SIZE)\n\t\tsize = PAGE_SIZE - 1;\n\n\tmemcpy(buf, table, size);\n\n\treturn size;\n}\n\nstatic ssize_t amdgpu_set_pp_table(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint ret = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_set_pp_table(adev, buf, count);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\tif (ret)\n\t\treturn ret;\n\n\treturn count;\n}\n\n \n\nstatic ssize_t amdgpu_set_pp_od_clk_voltage(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint ret;\n\tuint32_t parameter_size = 0;\n\tlong parameter[64];\n\tchar buf_cpy[128];\n\tchar *tmp_str;\n\tchar *sub_str;\n\tconst char delimiter[3] = {' ', '\\n', '\\0'};\n\tuint32_t type;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tif (count > 127 || count == 0)\n\t\treturn -EINVAL;\n\n\tif (*buf == 's')\n\t\ttype = PP_OD_EDIT_SCLK_VDDC_TABLE;\n\telse if (*buf == 'p')\n\t\ttype = PP_OD_EDIT_CCLK_VDDC_TABLE;\n\telse if (*buf == 'm')\n\t\ttype = PP_OD_EDIT_MCLK_VDDC_TABLE;\n\telse if (*buf == 'r')\n\t\ttype = PP_OD_RESTORE_DEFAULT_TABLE;\n\telse if (*buf == 'c')\n\t\ttype = PP_OD_COMMIT_DPM_TABLE;\n\telse if (!strncmp(buf, \"vc\", 2))\n\t\ttype = PP_OD_EDIT_VDDC_CURVE;\n\telse if (!strncmp(buf, \"vo\", 2))\n\t\ttype = PP_OD_EDIT_VDDGFX_OFFSET;\n\telse\n\t\treturn -EINVAL;\n\n\tmemcpy(buf_cpy, buf, count);\n\tbuf_cpy[count] = 0;\n\n\ttmp_str = buf_cpy;\n\n\tif ((type == PP_OD_EDIT_VDDC_CURVE) ||\n\t     (type == PP_OD_EDIT_VDDGFX_OFFSET))\n\t\ttmp_str++;\n\twhile (isspace(*++tmp_str));\n\n\twhile ((sub_str = strsep(&tmp_str, delimiter)) != NULL) {\n\t\tif (strlen(sub_str) == 0)\n\t\t\tcontinue;\n\t\tret = kstrtol(sub_str, 0, &parameter[parameter_size]);\n\t\tif (ret)\n\t\t\treturn -EINVAL;\n\t\tparameter_size++;\n\n\t\tif (!tmp_str)\n\t\t\tbreak;\n\n\t\twhile (isspace(*tmp_str))\n\t\t\ttmp_str++;\n\t}\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tif (amdgpu_dpm_set_fine_grain_clk_vol(adev,\n\t\t\t\t\t      type,\n\t\t\t\t\t      parameter,\n\t\t\t\t\t      parameter_size))\n\t\tgoto err_out;\n\n\tif (amdgpu_dpm_odn_edit_dpm_table(adev, type,\n\t\t\t\t\t  parameter, parameter_size))\n\t\tgoto err_out;\n\n\tif (type == PP_OD_COMMIT_DPM_TABLE) {\n\t\tif (amdgpu_dpm_dispatch_task(adev,\n\t\t\t\t\t     AMD_PP_TASK_READJUST_POWER_STATE,\n\t\t\t\t\t     NULL))\n\t\t\tgoto err_out;\n\t}\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn count;\n\nerr_out:\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\treturn -EINVAL;\n}\n\nstatic ssize_t amdgpu_get_pp_od_clk_voltage(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint size = 0;\n\tint ret;\n\tenum pp_clock_type od_clocks[6] = {\n\t\tOD_SCLK,\n\t\tOD_MCLK,\n\t\tOD_VDDC_CURVE,\n\t\tOD_RANGE,\n\t\tOD_VDDGFX_OFFSET,\n\t\tOD_CCLK,\n\t};\n\tuint clk_index;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tfor (clk_index = 0 ; clk_index < 6 ; clk_index++) {\n\t\tret = amdgpu_dpm_emit_clock_levels(adev, od_clocks[clk_index], buf, &size);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\tif (ret == -ENOENT) {\n\t\tsize = amdgpu_dpm_print_clock_levels(adev, OD_SCLK, buf);\n\t\tsize += amdgpu_dpm_print_clock_levels(adev, OD_MCLK, buf + size);\n\t\tsize += amdgpu_dpm_print_clock_levels(adev, OD_VDDC_CURVE, buf + size);\n\t\tsize += amdgpu_dpm_print_clock_levels(adev, OD_VDDGFX_OFFSET, buf + size);\n\t\tsize += amdgpu_dpm_print_clock_levels(adev, OD_RANGE, buf + size);\n\t\tsize += amdgpu_dpm_print_clock_levels(adev, OD_CCLK, buf + size);\n\t}\n\n\tif (size == 0)\n\t\tsize = sysfs_emit(buf, \"\\n\");\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn size;\n}\n\n \nstatic ssize_t amdgpu_set_pp_features(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      const char *buf,\n\t\t\t\t      size_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tuint64_t featuremask;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = kstrtou64(buf, 0, &featuremask);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_set_ppfeature_status(adev, featuremask);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\tif (ret)\n\t\treturn -EINVAL;\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_get_pp_features(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tssize_t size;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tsize = amdgpu_dpm_get_ppfeature_status(adev, buf);\n\tif (size <= 0)\n\t\tsize = sysfs_emit(buf, \"\\n\");\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn size;\n}\n\n \n\nstatic ssize_t amdgpu_get_pp_dpm_clock(struct device *dev,\n\t\tenum pp_clock_type type,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint size = 0;\n\tint ret = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_emit_clock_levels(adev, type, buf, &size);\n\tif (ret == -ENOENT)\n\t\tsize = amdgpu_dpm_print_clock_levels(adev, type, buf);\n\n\tif (size == 0)\n\t\tsize = sysfs_emit(buf, \"\\n\");\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn size;\n}\n\n \n#define AMDGPU_MASK_BUF_MAX\t(32 * 13)\n\nstatic ssize_t amdgpu_read_mask(const char *buf, size_t count, uint32_t *mask)\n{\n\tint ret;\n\tunsigned long level;\n\tchar *sub_str = NULL;\n\tchar *tmp;\n\tchar buf_cpy[AMDGPU_MASK_BUF_MAX + 1];\n\tconst char delimiter[3] = {' ', '\\n', '\\0'};\n\tsize_t bytes;\n\n\t*mask = 0;\n\n\tbytes = min(count, sizeof(buf_cpy) - 1);\n\tmemcpy(buf_cpy, buf, bytes);\n\tbuf_cpy[bytes] = '\\0';\n\ttmp = buf_cpy;\n\twhile ((sub_str = strsep(&tmp, delimiter)) != NULL) {\n\t\tif (strlen(sub_str)) {\n\t\t\tret = kstrtoul(sub_str, 0, &level);\n\t\t\tif (ret || level > 31)\n\t\t\t\treturn -EINVAL;\n\t\t\t*mask |= 1 << level;\n\t\t} else\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_clock(struct device *dev,\n\t\tenum pp_clock_type type,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint ret;\n\tuint32_t mask = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = amdgpu_read_mask(buf, count, &mask);\n\tif (ret)\n\t\treturn ret;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_force_clock_level(adev, type, mask);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\tif (ret)\n\t\treturn -EINVAL;\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_sclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_SCLK, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_sclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_SCLK, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_mclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_MCLK, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_mclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_MCLK, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_socclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_SOCCLK, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_socclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_SOCCLK, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_fclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_FCLK, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_fclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_FCLK, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_vclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_VCLK, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_vclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_VCLK, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_vclk1(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_VCLK1, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_vclk1(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_VCLK1, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_dclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_DCLK, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_dclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_DCLK, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_dclk1(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_DCLK1, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_dclk1(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_DCLK1, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_dcefclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_DCEFCLK, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_dcefclk(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_DCEFCLK, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_dpm_pcie(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\treturn amdgpu_get_pp_dpm_clock(dev, PP_PCIE, buf);\n}\n\nstatic ssize_t amdgpu_set_pp_dpm_pcie(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\treturn amdgpu_set_pp_dpm_clock(dev, PP_PCIE, buf, count);\n}\n\nstatic ssize_t amdgpu_get_pp_sclk_od(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tuint32_t value = 0;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tvalue = amdgpu_dpm_get_sclk_od(adev);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", value);\n}\n\nstatic ssize_t amdgpu_set_pp_sclk_od(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint ret;\n\tlong int value;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = kstrtol(buf, 0, &value);\n\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tamdgpu_dpm_set_sclk_od(adev, (uint32_t)value);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_get_pp_mclk_od(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tuint32_t value = 0;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tvalue = amdgpu_dpm_get_mclk_od(adev);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn sysfs_emit(buf, \"%d\\n\", value);\n}\n\nstatic ssize_t amdgpu_set_pp_mclk_od(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint ret;\n\tlong int value;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = kstrtol(buf, 0, &value);\n\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tamdgpu_dpm_set_mclk_od(adev, (uint32_t)value);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn count;\n}\n\n \n\nstatic ssize_t amdgpu_get_pp_power_profile_mode(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tssize_t size;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tsize = amdgpu_dpm_get_power_profile_mode(adev, buf);\n\tif (size <= 0)\n\t\tsize = sysfs_emit(buf, \"\\n\");\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn size;\n}\n\n\nstatic ssize_t amdgpu_set_pp_power_profile_mode(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tint ret;\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tuint32_t parameter_size = 0;\n\tlong parameter[64];\n\tchar *sub_str, buf_cpy[128];\n\tchar *tmp_str;\n\tuint32_t i = 0;\n\tchar tmp[2];\n\tlong int profile_mode = 0;\n\tconst char delimiter[3] = {' ', '\\n', '\\0'};\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\ttmp[0] = *(buf);\n\ttmp[1] = '\\0';\n\tret = kstrtol(tmp, 0, &profile_mode);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tif (profile_mode == PP_SMC_POWER_PROFILE_CUSTOM) {\n\t\tif (count < 2 || count > 127)\n\t\t\treturn -EINVAL;\n\t\twhile (isspace(*++buf))\n\t\t\ti++;\n\t\tmemcpy(buf_cpy, buf, count-i);\n\t\ttmp_str = buf_cpy;\n\t\twhile ((sub_str = strsep(&tmp_str, delimiter)) != NULL) {\n\t\t\tif (strlen(sub_str) == 0)\n\t\t\t\tcontinue;\n\t\t\tret = kstrtol(sub_str, 0, &parameter[parameter_size]);\n\t\t\tif (ret)\n\t\t\t\treturn -EINVAL;\n\t\t\tparameter_size++;\n\t\t\twhile (isspace(*tmp_str))\n\t\t\t\ttmp_str++;\n\t\t}\n\t}\n\tparameter[parameter_size] = profile_mode;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_set_power_profile_mode(adev, parameter, parameter_size);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\tif (!ret)\n\t\treturn count;\n\n\treturn -EINVAL;\n}\n\nstatic unsigned int amdgpu_hwmon_get_sensor_generic(struct amdgpu_device *adev,\n\t\t\t\t\t\t    enum amd_pp_sensors sensor,\n\t\t\t\t\t\t    void *query)\n{\n\tint r, size = sizeof(uint32_t);\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (r < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn r;\n\t}\n\n\t \n\tr = amdgpu_dpm_read_sensor(adev, sensor, query, &size);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\treturn r;\n}\n\n \nstatic ssize_t amdgpu_get_gpu_busy_percent(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tunsigned int value;\n\tint r;\n\n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_GPU_LOAD, &value);\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%d\\n\", value);\n}\n\n \nstatic ssize_t amdgpu_get_mem_busy_percent(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tunsigned int value;\n\tint r;\n\n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_MEM_LOAD, &value);\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%d\\n\", value);\n}\n\n \nstatic ssize_t amdgpu_get_pcie_bw(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tuint64_t count0 = 0, count1 = 0;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tif (adev->flags & AMD_IS_APU)\n\t\treturn -ENODATA;\n\n\tif (!adev->asic_funcs->get_pcie_usage)\n\t\treturn -ENODATA;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tamdgpu_asic_get_pcie_usage(adev, &count0, &count1);\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn sysfs_emit(buf, \"%llu %llu %i\\n\",\n\t\t\t  count0, count1, pcie_get_mps(adev->pdev));\n}\n\n \nstatic ssize_t amdgpu_get_unique_id(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tchar *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tif (adev->unique_id)\n\t\treturn sysfs_emit(buf, \"%016llx\\n\", adev->unique_id);\n\n\treturn 0;\n}\n\n \nstatic ssize_t amdgpu_get_thermal_throttling_logging(struct device *dev,\n\t\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t\t     char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\treturn sysfs_emit(buf, \"%s: thermal throttling logging %s, with interval %d seconds\\n\",\n\t\t\t  adev_to_drm(adev)->unique,\n\t\t\t  atomic_read(&adev->throttling_logging_enabled) ? \"enabled\" : \"disabled\",\n\t\t\t  adev->throttling_logging_rs.interval / HZ + 1);\n}\n\nstatic ssize_t amdgpu_set_thermal_throttling_logging(struct device *dev,\n\t\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t\t     const char *buf,\n\t\t\t\t\t\t     size_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tlong throttling_logging_interval;\n\tunsigned long flags;\n\tint ret = 0;\n\n\tret = kstrtol(buf, 0, &throttling_logging_interval);\n\tif (ret)\n\t\treturn ret;\n\n\tif (throttling_logging_interval > 3600)\n\t\treturn -EINVAL;\n\n\tif (throttling_logging_interval > 0) {\n\t\traw_spin_lock_irqsave(&adev->throttling_logging_rs.lock, flags);\n\t\t \n\t\tadev->throttling_logging_rs.interval =\n\t\t\t(throttling_logging_interval - 1) * HZ;\n\t\tadev->throttling_logging_rs.begin = 0;\n\t\tadev->throttling_logging_rs.printed = 0;\n\t\tadev->throttling_logging_rs.missed = 0;\n\t\traw_spin_unlock_irqrestore(&adev->throttling_logging_rs.lock, flags);\n\n\t\tatomic_set(&adev->throttling_logging_enabled, 1);\n\t} else {\n\t\tatomic_set(&adev->throttling_logging_enabled, 0);\n\t}\n\n\treturn count;\n}\n\n \nstatic ssize_t amdgpu_get_apu_thermal_cap(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tint ret, size;\n\tu32 limit;\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_get_apu_thermal_limit(adev, &limit);\n\tif (!ret)\n\t\tsize = sysfs_emit(buf, \"%u\\n\", limit);\n\telse\n\t\tsize = sysfs_emit(buf, \"failed to get thermal limit\\n\");\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn size;\n}\n\nstatic ssize_t amdgpu_set_apu_thermal_cap(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t const char *buf,\n\t\t\t\t\t size_t count)\n{\n\tint ret;\n\tu32 value;\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\n\tret = kstrtou32(buf, 10, &value);\n\tif (ret)\n\t\treturn ret;\n\n\tif (value > 100) {\n\t\tdev_err(dev, \"Invalid argument !\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_set_apu_thermal_limit(adev, value);\n\tif (ret) {\n\t\tdev_err(dev, \"failed to update thermal limit\\n\");\n\t\treturn ret;\n\t}\n\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn count;\n}\n\n \nstatic ssize_t amdgpu_get_gpu_metrics(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      char *buf)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tvoid *gpu_metrics;\n\tssize_t size = 0;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(ddev->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn ret;\n\t}\n\n\tsize = amdgpu_dpm_get_gpu_metrics(adev, &gpu_metrics);\n\tif (size <= 0)\n\t\tgoto out;\n\n\tif (size >= PAGE_SIZE)\n\t\tsize = PAGE_SIZE - 1;\n\n\tmemcpy(buf, gpu_metrics, size);\n\nout:\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\n\treturn size;\n}\n\nstatic int amdgpu_show_powershift_percent(struct device *dev,\n\t\t\t\t\tchar *buf, enum amd_pp_sensors sensor)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tuint32_t ss_power;\n\tint r = 0, i;\n\n\tr = amdgpu_hwmon_get_sensor_generic(adev, sensor, (void *)&ss_power);\n\tif (r == -EOPNOTSUPP) {\n\t\t \n\t\tadev = NULL;\n\t\tmutex_lock(&mgpu_info.mutex);\n\t\tfor (i = 0; i < mgpu_info.num_gpu; i++) {\n\t\t\tif (mgpu_info.gpu_ins[i].adev->flags & AMD_IS_APU) {\n\t\t\t\tadev = mgpu_info.gpu_ins[i].adev;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tmutex_unlock(&mgpu_info.mutex);\n\t\tif (adev)\n\t\t\tr = amdgpu_hwmon_get_sensor_generic(adev, sensor, (void *)&ss_power);\n\t}\n\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%u%%\\n\", ss_power);\n}\n\n \n\nstatic ssize_t amdgpu_get_smartshift_apu_power(struct device *dev, struct device_attribute *attr,\n\t\t\t\t\t       char *buf)\n{\n\treturn amdgpu_show_powershift_percent(dev, buf, AMDGPU_PP_SENSOR_SS_APU_SHARE);\n}\n\n \n\nstatic ssize_t amdgpu_get_smartshift_dgpu_power(struct device *dev, struct device_attribute *attr,\n\t\t\t\t\t\tchar *buf)\n{\n\treturn amdgpu_show_powershift_percent(dev, buf, AMDGPU_PP_SENSOR_SS_DGPU_SHARE);\n}\n\n \n\nstatic ssize_t amdgpu_get_smartshift_bias(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  char *buf)\n{\n\tint r = 0;\n\n\tr = sysfs_emit(buf, \"%d\\n\", amdgpu_smartshift_bias);\n\n\treturn r;\n}\n\nstatic ssize_t amdgpu_set_smartshift_bias(struct device *dev,\n\t\t\t\t\t  struct device_attribute *attr,\n\t\t\t\t\t  const char *buf, size_t count)\n{\n\tstruct drm_device *ddev = dev_get_drvdata(dev);\n\tstruct amdgpu_device *adev = drm_to_adev(ddev);\n\tint r = 0;\n\tint bias = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tr = pm_runtime_get_sync(ddev->dev);\n\tif (r < 0) {\n\t\tpm_runtime_put_autosuspend(ddev->dev);\n\t\treturn r;\n\t}\n\n\tr = kstrtoint(buf, 10, &bias);\n\tif (r)\n\t\tgoto out;\n\n\tif (bias > AMDGPU_SMARTSHIFT_MAX_BIAS)\n\t\tbias = AMDGPU_SMARTSHIFT_MAX_BIAS;\n\telse if (bias < AMDGPU_SMARTSHIFT_MIN_BIAS)\n\t\tbias = AMDGPU_SMARTSHIFT_MIN_BIAS;\n\n\tamdgpu_smartshift_bias = bias;\n\tr = count;\n\n\t \n\nout:\n\tpm_runtime_mark_last_busy(ddev->dev);\n\tpm_runtime_put_autosuspend(ddev->dev);\n\treturn r;\n}\n\nstatic int ss_power_attr_update(struct amdgpu_device *adev, struct amdgpu_device_attr *attr,\n\t\t\t\tuint32_t mask, enum amdgpu_device_attr_states *states)\n{\n\tif (!amdgpu_device_supports_smart_shift(adev_to_drm(adev)))\n\t\t*states = ATTR_STATE_UNSUPPORTED;\n\n\treturn 0;\n}\n\nstatic int ss_bias_attr_update(struct amdgpu_device *adev, struct amdgpu_device_attr *attr,\n\t\t\t       uint32_t mask, enum amdgpu_device_attr_states *states)\n{\n\tuint32_t ss_power;\n\n\tif (!amdgpu_device_supports_smart_shift(adev_to_drm(adev)))\n\t\t*states = ATTR_STATE_UNSUPPORTED;\n\telse if (amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_SS_APU_SHARE,\n\t\t (void *)&ss_power))\n\t\t*states = ATTR_STATE_UNSUPPORTED;\n\telse if (amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_SS_DGPU_SHARE,\n\t\t (void *)&ss_power))\n\t\t*states = ATTR_STATE_UNSUPPORTED;\n\n\treturn 0;\n}\n\nstatic struct amdgpu_device_attr amdgpu_device_attrs[] = {\n\tAMDGPU_DEVICE_ATTR_RW(power_dpm_state,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(power_dpm_force_performance_level,\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RO(pp_num_states,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RO(pp_cur_state,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_force_state,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_table,\t\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_sclk,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_mclk,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_socclk,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_fclk,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_vclk,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_vclk1,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_dclk,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_dclk1,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_dcefclk,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_dpm_pcie,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_sclk_od,\t\t\t\tATTR_FLAG_BASIC),\n\tAMDGPU_DEVICE_ATTR_RW(pp_mclk_od,\t\t\t\tATTR_FLAG_BASIC),\n\tAMDGPU_DEVICE_ATTR_RW(pp_power_profile_mode,\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(pp_od_clk_voltage,\t\t\tATTR_FLAG_BASIC),\n\tAMDGPU_DEVICE_ATTR_RO(gpu_busy_percent,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RO(mem_busy_percent,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RO(pcie_bw,\t\t\t\t\tATTR_FLAG_BASIC),\n\tAMDGPU_DEVICE_ATTR_RW(pp_features,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RO(unique_id,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(thermal_throttling_logging,\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RW(apu_thermal_cap,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RO(gpu_metrics,\t\t\t\tATTR_FLAG_BASIC|ATTR_FLAG_ONEVF),\n\tAMDGPU_DEVICE_ATTR_RO(smartshift_apu_power,\t\t\tATTR_FLAG_BASIC,\n\t\t\t      .attr_update = ss_power_attr_update),\n\tAMDGPU_DEVICE_ATTR_RO(smartshift_dgpu_power,\t\t\tATTR_FLAG_BASIC,\n\t\t\t      .attr_update = ss_power_attr_update),\n\tAMDGPU_DEVICE_ATTR_RW(smartshift_bias,\t\t\t\tATTR_FLAG_BASIC,\n\t\t\t      .attr_update = ss_bias_attr_update),\n};\n\nstatic int default_attr_update(struct amdgpu_device *adev, struct amdgpu_device_attr *attr,\n\t\t\t       uint32_t mask, enum amdgpu_device_attr_states *states)\n{\n\tstruct device_attribute *dev_attr = &attr->dev_attr;\n\tuint32_t mp1_ver = adev->ip_versions[MP1_HWIP][0];\n\tuint32_t gc_ver = adev->ip_versions[GC_HWIP][0];\n\tconst char *attr_name = dev_attr->attr.name;\n\n\tif (!(attr->flags & mask)) {\n\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t\treturn 0;\n\t}\n\n#define DEVICE_ATTR_IS(_name)\t(!strcmp(attr_name, #_name))\n\n\tif (DEVICE_ATTR_IS(pp_dpm_socclk)) {\n\t\tif (gc_ver < IP_VERSION(9, 0, 0))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_dpm_dcefclk)) {\n\t\tif (gc_ver < IP_VERSION(9, 0, 0) ||\n\t\t    !amdgpu_device_has_display_hardware(adev))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_dpm_fclk)) {\n\t\tif (mp1_ver < IP_VERSION(10, 0, 0))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_od_clk_voltage)) {\n\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t\tif (amdgpu_dpm_is_overdrive_supported(adev))\n\t\t\t*states = ATTR_STATE_SUPPORTED;\n\t} else if (DEVICE_ATTR_IS(mem_busy_percent)) {\n\t\tif (adev->flags & AMD_IS_APU || gc_ver == IP_VERSION(9, 0, 1))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pcie_bw)) {\n\t\t \n\t\tif (adev->flags & AMD_IS_APU)\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(unique_id)) {\n\t\tswitch (gc_ver) {\n\t\tcase IP_VERSION(9, 0, 1):\n\t\tcase IP_VERSION(9, 4, 0):\n\t\tcase IP_VERSION(9, 4, 1):\n\t\tcase IP_VERSION(9, 4, 2):\n\t\tcase IP_VERSION(9, 4, 3):\n\t\tcase IP_VERSION(10, 3, 0):\n\t\tcase IP_VERSION(11, 0, 0):\n\t\tcase IP_VERSION(11, 0, 1):\n\t\tcase IP_VERSION(11, 0, 2):\n\t\tcase IP_VERSION(11, 0, 3):\n\t\t\t*states = ATTR_STATE_SUPPORTED;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t\t}\n\t} else if (DEVICE_ATTR_IS(pp_features)) {\n\t\tif ((adev->flags & AMD_IS_APU &&\n\t\t     gc_ver != IP_VERSION(9, 4, 3)) ||\n\t\t    gc_ver < IP_VERSION(9, 0, 0))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(gpu_metrics)) {\n\t\tif (gc_ver < IP_VERSION(9, 1, 0))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_dpm_vclk)) {\n\t\tif (!(gc_ver == IP_VERSION(10, 3, 1) ||\n\t\t      gc_ver == IP_VERSION(10, 3, 0) ||\n\t\t      gc_ver == IP_VERSION(10, 1, 2) ||\n\t\t      gc_ver == IP_VERSION(11, 0, 0) ||\n\t\t      gc_ver == IP_VERSION(11, 0, 2) ||\n\t\t      gc_ver == IP_VERSION(11, 0, 3) ||\n\t\t      gc_ver == IP_VERSION(9, 4, 3)))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_dpm_vclk1)) {\n\t\tif (!((gc_ver == IP_VERSION(10, 3, 1) ||\n\t\t\t   gc_ver == IP_VERSION(10, 3, 0) ||\n\t\t\t   gc_ver == IP_VERSION(11, 0, 2) ||\n\t\t\t   gc_ver == IP_VERSION(11, 0, 3)) && adev->vcn.num_vcn_inst >= 2))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_dpm_dclk)) {\n\t\tif (!(gc_ver == IP_VERSION(10, 3, 1) ||\n\t\t      gc_ver == IP_VERSION(10, 3, 0) ||\n\t\t      gc_ver == IP_VERSION(10, 1, 2) ||\n\t\t      gc_ver == IP_VERSION(11, 0, 0) ||\n\t\t      gc_ver == IP_VERSION(11, 0, 2) ||\n\t\t      gc_ver == IP_VERSION(11, 0, 3) ||\n\t\t      gc_ver == IP_VERSION(9, 4, 3)))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_dpm_dclk1)) {\n\t\tif (!((gc_ver == IP_VERSION(10, 3, 1) ||\n\t\t\t   gc_ver == IP_VERSION(10, 3, 0) ||\n\t\t\t   gc_ver == IP_VERSION(11, 0, 2) ||\n\t\t\t   gc_ver == IP_VERSION(11, 0, 3)) && adev->vcn.num_vcn_inst >= 2))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t} else if (DEVICE_ATTR_IS(pp_power_profile_mode)) {\n\t\tif (amdgpu_dpm_get_power_profile_mode(adev, NULL) == -EOPNOTSUPP)\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t\telse if (gc_ver == IP_VERSION(10, 3, 0) && amdgpu_sriov_vf(adev))\n\t\t\t*states = ATTR_STATE_UNSUPPORTED;\n\t}\n\n\tswitch (gc_ver) {\n\tcase IP_VERSION(9, 4, 1):\n\tcase IP_VERSION(9, 4, 2):\n\t\t \n\t\tif (DEVICE_ATTR_IS(pp_dpm_mclk) ||\n\t\t    DEVICE_ATTR_IS(pp_dpm_socclk) ||\n\t\t    DEVICE_ATTR_IS(pp_dpm_fclk)) {\n\t\t\tdev_attr->attr.mode &= ~S_IWUGO;\n\t\t\tdev_attr->store = NULL;\n\t\t}\n\t\tbreak;\n\tcase IP_VERSION(10, 3, 0):\n\t\tif (DEVICE_ATTR_IS(power_dpm_force_performance_level) &&\n\t\t    amdgpu_sriov_vf(adev)) {\n\t\t\tdev_attr->attr.mode &= ~0222;\n\t\t\tdev_attr->store = NULL;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (DEVICE_ATTR_IS(pp_dpm_dcefclk)) {\n\t\t \n\t\tif (gc_ver >= IP_VERSION(10, 0, 0)) {\n\t\t\tdev_attr->attr.mode &= ~S_IWUGO;\n\t\t\tdev_attr->store = NULL;\n\t\t}\n\t}\n\n\t \n\tif (amdgpu_sriov_vf(adev) && !amdgpu_sriov_is_pp_one_vf(adev)) {\n\t\tdev_attr->attr.mode &= ~S_IWUGO;\n\t\tdev_attr->store = NULL;\n\t}\n\n#undef DEVICE_ATTR_IS\n\n\treturn 0;\n}\n\n\nstatic int amdgpu_device_attr_create(struct amdgpu_device *adev,\n\t\t\t\t     struct amdgpu_device_attr *attr,\n\t\t\t\t     uint32_t mask, struct list_head *attr_list)\n{\n\tint ret = 0;\n\tenum amdgpu_device_attr_states attr_states = ATTR_STATE_SUPPORTED;\n\tstruct amdgpu_device_attr_entry *attr_entry;\n\tstruct device_attribute *dev_attr;\n\tconst char *name;\n\n\tint (*attr_update)(struct amdgpu_device *adev, struct amdgpu_device_attr *attr,\n\t\t\t   uint32_t mask, enum amdgpu_device_attr_states *states) = default_attr_update;\n\n\tif (!attr)\n\t\treturn -EINVAL;\n\n\tdev_attr = &attr->dev_attr;\n\tname = dev_attr->attr.name;\n\n\tattr_update = attr->attr_update ? attr->attr_update : default_attr_update;\n\n\tret = attr_update(adev, attr, mask, &attr_states);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"failed to update device file %s, ret = %d\\n\",\n\t\t\tname, ret);\n\t\treturn ret;\n\t}\n\n\tif (attr_states == ATTR_STATE_UNSUPPORTED)\n\t\treturn 0;\n\n\tret = device_create_file(adev->dev, dev_attr);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"failed to create device file %s, ret = %d\\n\",\n\t\t\tname, ret);\n\t}\n\n\tattr_entry = kmalloc(sizeof(*attr_entry), GFP_KERNEL);\n\tif (!attr_entry)\n\t\treturn -ENOMEM;\n\n\tattr_entry->attr = attr;\n\tINIT_LIST_HEAD(&attr_entry->entry);\n\n\tlist_add_tail(&attr_entry->entry, attr_list);\n\n\treturn ret;\n}\n\nstatic void amdgpu_device_attr_remove(struct amdgpu_device *adev, struct amdgpu_device_attr *attr)\n{\n\tstruct device_attribute *dev_attr = &attr->dev_attr;\n\n\tdevice_remove_file(adev->dev, dev_attr);\n}\n\nstatic void amdgpu_device_attr_remove_groups(struct amdgpu_device *adev,\n\t\t\t\t\t     struct list_head *attr_list);\n\nstatic int amdgpu_device_attr_create_groups(struct amdgpu_device *adev,\n\t\t\t\t\t    struct amdgpu_device_attr *attrs,\n\t\t\t\t\t    uint32_t counts,\n\t\t\t\t\t    uint32_t mask,\n\t\t\t\t\t    struct list_head *attr_list)\n{\n\tint ret = 0;\n\tuint32_t i = 0;\n\n\tfor (i = 0; i < counts; i++) {\n\t\tret = amdgpu_device_attr_create(adev, &attrs[i], mask, attr_list);\n\t\tif (ret)\n\t\t\tgoto failed;\n\t}\n\n\treturn 0;\n\nfailed:\n\tamdgpu_device_attr_remove_groups(adev, attr_list);\n\n\treturn ret;\n}\n\nstatic void amdgpu_device_attr_remove_groups(struct amdgpu_device *adev,\n\t\t\t\t\t     struct list_head *attr_list)\n{\n\tstruct amdgpu_device_attr_entry *entry, *entry_tmp;\n\n\tif (list_empty(attr_list))\n\t\treturn ;\n\n\tlist_for_each_entry_safe(entry, entry_tmp, attr_list, entry) {\n\t\tamdgpu_device_attr_remove(adev, entry->attr);\n\t\tlist_del(&entry->entry);\n\t\tkfree(entry);\n\t}\n}\n\nstatic ssize_t amdgpu_hwmon_show_temp(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint channel = to_sensor_dev_attr(attr)->index;\n\tint r, temp = 0;\n\n\tif (channel >= PP_TEMP_MAX)\n\t\treturn -EINVAL;\n\n\tswitch (channel) {\n\tcase PP_TEMP_JUNCTION:\n\t\t \n\t\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_HOTSPOT_TEMP,\n\t\t\t\t\t   (void *)&temp);\n\t\tbreak;\n\tcase PP_TEMP_EDGE:\n\t\t \n\t\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_EDGE_TEMP,\n\t\t\t\t\t   (void *)&temp);\n\t\tbreak;\n\tcase PP_TEMP_MEM:\n\t\t \n\t\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_MEM_TEMP,\n\t\t\t\t\t   (void *)&temp);\n\t\tbreak;\n\tdefault:\n\t\tr = -EINVAL;\n\t\tbreak;\n\t}\n\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%d\\n\", temp);\n}\n\nstatic ssize_t amdgpu_hwmon_show_temp_thresh(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint hyst = to_sensor_dev_attr(attr)->index;\n\tint temp;\n\n\tif (hyst)\n\t\ttemp = adev->pm.dpm.thermal.min_temp;\n\telse\n\t\ttemp = adev->pm.dpm.thermal.max_temp;\n\n\treturn sysfs_emit(buf, \"%d\\n\", temp);\n}\n\nstatic ssize_t amdgpu_hwmon_show_hotspot_temp_thresh(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint hyst = to_sensor_dev_attr(attr)->index;\n\tint temp;\n\n\tif (hyst)\n\t\ttemp = adev->pm.dpm.thermal.min_hotspot_temp;\n\telse\n\t\ttemp = adev->pm.dpm.thermal.max_hotspot_crit_temp;\n\n\treturn sysfs_emit(buf, \"%d\\n\", temp);\n}\n\nstatic ssize_t amdgpu_hwmon_show_mem_temp_thresh(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint hyst = to_sensor_dev_attr(attr)->index;\n\tint temp;\n\n\tif (hyst)\n\t\ttemp = adev->pm.dpm.thermal.min_mem_temp;\n\telse\n\t\ttemp = adev->pm.dpm.thermal.max_mem_crit_temp;\n\n\treturn sysfs_emit(buf, \"%d\\n\", temp);\n}\n\nstatic ssize_t amdgpu_hwmon_show_temp_label(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tint channel = to_sensor_dev_attr(attr)->index;\n\n\tif (channel >= PP_TEMP_MAX)\n\t\treturn -EINVAL;\n\n\treturn sysfs_emit(buf, \"%s\\n\", temp_label[channel].label);\n}\n\nstatic ssize_t amdgpu_hwmon_show_temp_emergency(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint channel = to_sensor_dev_attr(attr)->index;\n\tint temp = 0;\n\n\tif (channel >= PP_TEMP_MAX)\n\t\treturn -EINVAL;\n\n\tswitch (channel) {\n\tcase PP_TEMP_JUNCTION:\n\t\ttemp = adev->pm.dpm.thermal.max_hotspot_emergency_temp;\n\t\tbreak;\n\tcase PP_TEMP_EDGE:\n\t\ttemp = adev->pm.dpm.thermal.max_edge_emergency_temp;\n\t\tbreak;\n\tcase PP_TEMP_MEM:\n\t\ttemp = adev->pm.dpm.thermal.max_mem_emergency_temp;\n\t\tbreak;\n\t}\n\n\treturn sysfs_emit(buf, \"%d\\n\", temp);\n}\n\nstatic ssize_t amdgpu_hwmon_get_pwm1_enable(struct device *dev,\n\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t    char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tu32 pwm_mode = 0;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_get_fan_control_mode(adev, &pwm_mode);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (ret)\n\t\treturn -EINVAL;\n\n\treturn sysfs_emit(buf, \"%u\\n\", pwm_mode);\n}\n\nstatic ssize_t amdgpu_hwmon_set_pwm1_enable(struct device *dev,\n\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t    const char *buf,\n\t\t\t\t\t    size_t count)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint err, ret;\n\tint value;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\terr = kstrtoint(buf, 10, &value);\n\tif (err)\n\t\treturn err;\n\n\tret = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_set_fan_control_mode(adev, value);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (ret)\n\t\treturn -EINVAL;\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_hwmon_get_pwm1_min(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\treturn sysfs_emit(buf, \"%i\\n\", 0);\n}\n\nstatic ssize_t amdgpu_hwmon_get_pwm1_max(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\treturn sysfs_emit(buf, \"%i\\n\", 255);\n}\n\nstatic ssize_t amdgpu_hwmon_set_pwm1(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t count)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint err;\n\tu32 value;\n\tu32 pwm_mode;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\terr = kstrtou32(buf, 10, &value);\n\tif (err)\n\t\treturn err;\n\n\terr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (err < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn err;\n\t}\n\n\terr = amdgpu_dpm_get_fan_control_mode(adev, &pwm_mode);\n\tif (err)\n\t\tgoto out;\n\n\tif (pwm_mode != AMD_FAN_CTRL_MANUAL) {\n\t\tpr_info(\"manual fan speed control should be enabled first\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\terr = amdgpu_dpm_set_fan_speed_pwm(adev, value);\n\nout:\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (err)\n\t\treturn err;\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_hwmon_get_pwm1(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint err;\n\tu32 speed = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\terr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (err < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn err;\n\t}\n\n\terr = amdgpu_dpm_get_fan_speed_pwm(adev, &speed);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (err)\n\t\treturn err;\n\n\treturn sysfs_emit(buf, \"%i\\n\", speed);\n}\n\nstatic ssize_t amdgpu_hwmon_get_fan1_input(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint err;\n\tu32 speed = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\terr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (err < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn err;\n\t}\n\n\terr = amdgpu_dpm_get_fan_speed_rpm(adev, &speed);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (err)\n\t\treturn err;\n\n\treturn sysfs_emit(buf, \"%i\\n\", speed);\n}\n\nstatic ssize_t amdgpu_hwmon_get_fan1_min(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tu32 min_rpm = 0;\n\tint r;\n\n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_MIN_FAN_RPM,\n\t\t\t\t   (void *)&min_rpm);\n\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%d\\n\", min_rpm);\n}\n\nstatic ssize_t amdgpu_hwmon_get_fan1_max(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tu32 max_rpm = 0;\n\tint r;\n\n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_MAX_FAN_RPM,\n\t\t\t\t   (void *)&max_rpm);\n\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%d\\n\", max_rpm);\n}\n\nstatic ssize_t amdgpu_hwmon_get_fan1_target(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint err;\n\tu32 rpm = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\terr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (err < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn err;\n\t}\n\n\terr = amdgpu_dpm_get_fan_speed_rpm(adev, &rpm);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (err)\n\t\treturn err;\n\n\treturn sysfs_emit(buf, \"%i\\n\", rpm);\n}\n\nstatic ssize_t amdgpu_hwmon_set_fan1_target(struct device *dev,\n\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t     const char *buf, size_t count)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint err;\n\tu32 value;\n\tu32 pwm_mode;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\terr = kstrtou32(buf, 10, &value);\n\tif (err)\n\t\treturn err;\n\n\terr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (err < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn err;\n\t}\n\n\terr = amdgpu_dpm_get_fan_control_mode(adev, &pwm_mode);\n\tif (err)\n\t\tgoto out;\n\n\tif (pwm_mode != AMD_FAN_CTRL_MANUAL) {\n\t\terr = -ENODATA;\n\t\tgoto out;\n\t}\n\n\terr = amdgpu_dpm_set_fan_speed_rpm(adev, value);\n\nout:\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (err)\n\t\treturn err;\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_hwmon_get_fan1_enable(struct device *dev,\n\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t    char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tu32 pwm_mode = 0;\n\tint ret;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (ret < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn ret;\n\t}\n\n\tret = amdgpu_dpm_get_fan_control_mode(adev, &pwm_mode);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (ret)\n\t\treturn -EINVAL;\n\n\treturn sysfs_emit(buf, \"%i\\n\", pwm_mode == AMD_FAN_CTRL_AUTO ? 0 : 1);\n}\n\nstatic ssize_t amdgpu_hwmon_set_fan1_enable(struct device *dev,\n\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t    const char *buf,\n\t\t\t\t\t    size_t count)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint err;\n\tint value;\n\tu32 pwm_mode;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\terr = kstrtoint(buf, 10, &value);\n\tif (err)\n\t\treturn err;\n\n\tif (value == 0)\n\t\tpwm_mode = AMD_FAN_CTRL_AUTO;\n\telse if (value == 1)\n\t\tpwm_mode = AMD_FAN_CTRL_MANUAL;\n\telse\n\t\treturn -EINVAL;\n\n\terr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (err < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn err;\n\t}\n\n\terr = amdgpu_dpm_set_fan_control_mode(adev, pwm_mode);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (err)\n\t\treturn -EINVAL;\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_hwmon_show_vddgfx(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tu32 vddgfx;\n\tint r;\n\n\t \n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_VDDGFX,\n\t\t\t\t   (void *)&vddgfx);\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%d\\n\", vddgfx);\n}\n\nstatic ssize_t amdgpu_hwmon_show_vddgfx_label(struct device *dev,\n\t\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t\t      char *buf)\n{\n\treturn sysfs_emit(buf, \"vddgfx\\n\");\n}\n\nstatic ssize_t amdgpu_hwmon_show_vddnb(struct device *dev,\n\t\t\t\t       struct device_attribute *attr,\n\t\t\t\t       char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tu32 vddnb;\n\tint r;\n\n\t \n\tif  (!(adev->flags & AMD_IS_APU))\n\t\treturn -EINVAL;\n\n\t \n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_VDDNB,\n\t\t\t\t   (void *)&vddnb);\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%d\\n\", vddnb);\n}\n\nstatic ssize_t amdgpu_hwmon_show_vddnb_label(struct device *dev,\n\t\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t\t      char *buf)\n{\n\treturn sysfs_emit(buf, \"vddnb\\n\");\n}\n\nstatic unsigned int amdgpu_hwmon_get_power(struct device *dev,\n\t\t\t\t\t   enum amd_pp_sensors sensor)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tunsigned int uw;\n\tu32 query = 0;\n\tint r;\n\n\tr = amdgpu_hwmon_get_sensor_generic(adev, sensor, (void *)&query);\n\tif (r)\n\t\treturn r;\n\n\t \n\tuw = (query >> 8) * 1000000 + (query & 0xff) * 1000;\n\n\treturn uw;\n}\n\nstatic ssize_t amdgpu_hwmon_show_power_avg(struct device *dev,\n\t\t\t\t\t   struct device_attribute *attr,\n\t\t\t\t\t   char *buf)\n{\n\tunsigned int val;\n\n\tval = amdgpu_hwmon_get_power(dev, AMDGPU_PP_SENSOR_GPU_AVG_POWER);\n\tif (val < 0)\n\t\treturn val;\n\n\treturn sysfs_emit(buf, \"%u\\n\", val);\n}\n\nstatic ssize_t amdgpu_hwmon_show_power_input(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *buf)\n{\n\tunsigned int val;\n\n\tval = amdgpu_hwmon_get_power(dev, AMDGPU_PP_SENSOR_GPU_INPUT_POWER);\n\tif (val < 0)\n\t\treturn val;\n\n\treturn sysfs_emit(buf, \"%u\\n\", val);\n}\n\nstatic ssize_t amdgpu_hwmon_show_power_cap_min(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\treturn sysfs_emit(buf, \"%i\\n\", 0);\n}\n\n\nstatic ssize_t amdgpu_hwmon_show_power_cap_generic(struct device *dev,\n\t\t\t\t\tstruct device_attribute *attr,\n\t\t\t\t\tchar *buf,\n\t\t\t\t\tenum pp_power_limit_level pp_limit_level)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tenum pp_power_type power_type = to_sensor_dev_attr(attr)->index;\n\tuint32_t limit;\n\tssize_t size;\n\tint r;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (r < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn r;\n\t}\n\n\tr = amdgpu_dpm_get_power_limit(adev, &limit,\n\t\t\t\t      pp_limit_level, power_type);\n\n\tif (!r)\n\t\tsize = sysfs_emit(buf, \"%u\\n\", limit * 1000000);\n\telse\n\t\tsize = sysfs_emit(buf, \"\\n\");\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\treturn size;\n}\n\n\nstatic ssize_t amdgpu_hwmon_show_power_cap_max(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\treturn amdgpu_hwmon_show_power_cap_generic(dev, attr, buf, PP_PWR_LIMIT_MAX);\n\n}\n\nstatic ssize_t amdgpu_hwmon_show_power_cap(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\treturn amdgpu_hwmon_show_power_cap_generic(dev, attr, buf, PP_PWR_LIMIT_CURRENT);\n\n}\n\nstatic ssize_t amdgpu_hwmon_show_power_cap_default(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\treturn amdgpu_hwmon_show_power_cap_generic(dev, attr, buf, PP_PWR_LIMIT_DEFAULT);\n\n}\n\nstatic ssize_t amdgpu_hwmon_show_power_label(struct device *dev,\n\t\t\t\t\t struct device_attribute *attr,\n\t\t\t\t\t char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tuint32_t gc_ver = adev->ip_versions[GC_HWIP][0];\n\n\tif (gc_ver == IP_VERSION(10, 3, 1))\n\t\treturn sysfs_emit(buf, \"%s\\n\",\n\t\t\t\t  to_sensor_dev_attr(attr)->index == PP_PWR_TYPE_FAST ?\n\t\t\t\t  \"fastPPT\" : \"slowPPT\");\n\telse\n\t\treturn sysfs_emit(buf, \"PPT\\n\");\n}\n\nstatic ssize_t amdgpu_hwmon_set_power_cap(struct device *dev,\n\t\tstruct device_attribute *attr,\n\t\tconst char *buf,\n\t\tsize_t count)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tint limit_type = to_sensor_dev_attr(attr)->index;\n\tint err;\n\tu32 value;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tif (amdgpu_sriov_vf(adev))\n\t\treturn -EINVAL;\n\n\terr = kstrtou32(buf, 10, &value);\n\tif (err)\n\t\treturn err;\n\n\tvalue = value / 1000000;  \n\tvalue |= limit_type << 24;\n\n\terr = pm_runtime_get_sync(adev_to_drm(adev)->dev);\n\tif (err < 0) {\n\t\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\t\treturn err;\n\t}\n\n\terr = amdgpu_dpm_set_power_limit(adev, value);\n\n\tpm_runtime_mark_last_busy(adev_to_drm(adev)->dev);\n\tpm_runtime_put_autosuspend(adev_to_drm(adev)->dev);\n\n\tif (err)\n\t\treturn err;\n\n\treturn count;\n}\n\nstatic ssize_t amdgpu_hwmon_show_sclk(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tuint32_t sclk;\n\tint r;\n\n\t \n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_GFX_SCLK,\n\t\t\t\t   (void *)&sclk);\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%u\\n\", sclk * 10 * 1000);\n}\n\nstatic ssize_t amdgpu_hwmon_show_sclk_label(struct device *dev,\n\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t    char *buf)\n{\n\treturn sysfs_emit(buf, \"sclk\\n\");\n}\n\nstatic ssize_t amdgpu_hwmon_show_mclk(struct device *dev,\n\t\t\t\t      struct device_attribute *attr,\n\t\t\t\t      char *buf)\n{\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tuint32_t mclk;\n\tint r;\n\n\t \n\tr = amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_GFX_MCLK,\n\t\t\t\t   (void *)&mclk);\n\tif (r)\n\t\treturn r;\n\n\treturn sysfs_emit(buf, \"%u\\n\", mclk * 10 * 1000);\n}\n\nstatic ssize_t amdgpu_hwmon_show_mclk_label(struct device *dev,\n\t\t\t\t\t    struct device_attribute *attr,\n\t\t\t\t\t    char *buf)\n{\n\treturn sysfs_emit(buf, \"mclk\\n\");\n}\n\n \n\nstatic SENSOR_DEVICE_ATTR(temp1_input, S_IRUGO, amdgpu_hwmon_show_temp, NULL, PP_TEMP_EDGE);\nstatic SENSOR_DEVICE_ATTR(temp1_crit, S_IRUGO, amdgpu_hwmon_show_temp_thresh, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(temp1_crit_hyst, S_IRUGO, amdgpu_hwmon_show_temp_thresh, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(temp1_emergency, S_IRUGO, amdgpu_hwmon_show_temp_emergency, NULL, PP_TEMP_EDGE);\nstatic SENSOR_DEVICE_ATTR(temp2_input, S_IRUGO, amdgpu_hwmon_show_temp, NULL, PP_TEMP_JUNCTION);\nstatic SENSOR_DEVICE_ATTR(temp2_crit, S_IRUGO, amdgpu_hwmon_show_hotspot_temp_thresh, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(temp2_crit_hyst, S_IRUGO, amdgpu_hwmon_show_hotspot_temp_thresh, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(temp2_emergency, S_IRUGO, amdgpu_hwmon_show_temp_emergency, NULL, PP_TEMP_JUNCTION);\nstatic SENSOR_DEVICE_ATTR(temp3_input, S_IRUGO, amdgpu_hwmon_show_temp, NULL, PP_TEMP_MEM);\nstatic SENSOR_DEVICE_ATTR(temp3_crit, S_IRUGO, amdgpu_hwmon_show_mem_temp_thresh, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(temp3_crit_hyst, S_IRUGO, amdgpu_hwmon_show_mem_temp_thresh, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(temp3_emergency, S_IRUGO, amdgpu_hwmon_show_temp_emergency, NULL, PP_TEMP_MEM);\nstatic SENSOR_DEVICE_ATTR(temp1_label, S_IRUGO, amdgpu_hwmon_show_temp_label, NULL, PP_TEMP_EDGE);\nstatic SENSOR_DEVICE_ATTR(temp2_label, S_IRUGO, amdgpu_hwmon_show_temp_label, NULL, PP_TEMP_JUNCTION);\nstatic SENSOR_DEVICE_ATTR(temp3_label, S_IRUGO, amdgpu_hwmon_show_temp_label, NULL, PP_TEMP_MEM);\nstatic SENSOR_DEVICE_ATTR(pwm1, S_IRUGO | S_IWUSR, amdgpu_hwmon_get_pwm1, amdgpu_hwmon_set_pwm1, 0);\nstatic SENSOR_DEVICE_ATTR(pwm1_enable, S_IRUGO | S_IWUSR, amdgpu_hwmon_get_pwm1_enable, amdgpu_hwmon_set_pwm1_enable, 0);\nstatic SENSOR_DEVICE_ATTR(pwm1_min, S_IRUGO, amdgpu_hwmon_get_pwm1_min, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(pwm1_max, S_IRUGO, amdgpu_hwmon_get_pwm1_max, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(fan1_input, S_IRUGO, amdgpu_hwmon_get_fan1_input, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(fan1_min, S_IRUGO, amdgpu_hwmon_get_fan1_min, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(fan1_max, S_IRUGO, amdgpu_hwmon_get_fan1_max, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(fan1_target, S_IRUGO | S_IWUSR, amdgpu_hwmon_get_fan1_target, amdgpu_hwmon_set_fan1_target, 0);\nstatic SENSOR_DEVICE_ATTR(fan1_enable, S_IRUGO | S_IWUSR, amdgpu_hwmon_get_fan1_enable, amdgpu_hwmon_set_fan1_enable, 0);\nstatic SENSOR_DEVICE_ATTR(in0_input, S_IRUGO, amdgpu_hwmon_show_vddgfx, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(in0_label, S_IRUGO, amdgpu_hwmon_show_vddgfx_label, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(in1_input, S_IRUGO, amdgpu_hwmon_show_vddnb, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(in1_label, S_IRUGO, amdgpu_hwmon_show_vddnb_label, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(power1_average, S_IRUGO, amdgpu_hwmon_show_power_avg, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(power1_input, S_IRUGO, amdgpu_hwmon_show_power_input, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(power1_cap_max, S_IRUGO, amdgpu_hwmon_show_power_cap_max, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(power1_cap_min, S_IRUGO, amdgpu_hwmon_show_power_cap_min, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(power1_cap, S_IRUGO | S_IWUSR, amdgpu_hwmon_show_power_cap, amdgpu_hwmon_set_power_cap, 0);\nstatic SENSOR_DEVICE_ATTR(power1_cap_default, S_IRUGO, amdgpu_hwmon_show_power_cap_default, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(power1_label, S_IRUGO, amdgpu_hwmon_show_power_label, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(power2_average, S_IRUGO, amdgpu_hwmon_show_power_avg, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(power2_cap_max, S_IRUGO, amdgpu_hwmon_show_power_cap_max, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(power2_cap_min, S_IRUGO, amdgpu_hwmon_show_power_cap_min, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(power2_cap, S_IRUGO | S_IWUSR, amdgpu_hwmon_show_power_cap, amdgpu_hwmon_set_power_cap, 1);\nstatic SENSOR_DEVICE_ATTR(power2_cap_default, S_IRUGO, amdgpu_hwmon_show_power_cap_default, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(power2_label, S_IRUGO, amdgpu_hwmon_show_power_label, NULL, 1);\nstatic SENSOR_DEVICE_ATTR(freq1_input, S_IRUGO, amdgpu_hwmon_show_sclk, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(freq1_label, S_IRUGO, amdgpu_hwmon_show_sclk_label, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(freq2_input, S_IRUGO, amdgpu_hwmon_show_mclk, NULL, 0);\nstatic SENSOR_DEVICE_ATTR(freq2_label, S_IRUGO, amdgpu_hwmon_show_mclk_label, NULL, 0);\n\nstatic struct attribute *hwmon_attributes[] = {\n\t&sensor_dev_attr_temp1_input.dev_attr.attr,\n\t&sensor_dev_attr_temp1_crit.dev_attr.attr,\n\t&sensor_dev_attr_temp1_crit_hyst.dev_attr.attr,\n\t&sensor_dev_attr_temp2_input.dev_attr.attr,\n\t&sensor_dev_attr_temp2_crit.dev_attr.attr,\n\t&sensor_dev_attr_temp2_crit_hyst.dev_attr.attr,\n\t&sensor_dev_attr_temp3_input.dev_attr.attr,\n\t&sensor_dev_attr_temp3_crit.dev_attr.attr,\n\t&sensor_dev_attr_temp3_crit_hyst.dev_attr.attr,\n\t&sensor_dev_attr_temp1_emergency.dev_attr.attr,\n\t&sensor_dev_attr_temp2_emergency.dev_attr.attr,\n\t&sensor_dev_attr_temp3_emergency.dev_attr.attr,\n\t&sensor_dev_attr_temp1_label.dev_attr.attr,\n\t&sensor_dev_attr_temp2_label.dev_attr.attr,\n\t&sensor_dev_attr_temp3_label.dev_attr.attr,\n\t&sensor_dev_attr_pwm1.dev_attr.attr,\n\t&sensor_dev_attr_pwm1_enable.dev_attr.attr,\n\t&sensor_dev_attr_pwm1_min.dev_attr.attr,\n\t&sensor_dev_attr_pwm1_max.dev_attr.attr,\n\t&sensor_dev_attr_fan1_input.dev_attr.attr,\n\t&sensor_dev_attr_fan1_min.dev_attr.attr,\n\t&sensor_dev_attr_fan1_max.dev_attr.attr,\n\t&sensor_dev_attr_fan1_target.dev_attr.attr,\n\t&sensor_dev_attr_fan1_enable.dev_attr.attr,\n\t&sensor_dev_attr_in0_input.dev_attr.attr,\n\t&sensor_dev_attr_in0_label.dev_attr.attr,\n\t&sensor_dev_attr_in1_input.dev_attr.attr,\n\t&sensor_dev_attr_in1_label.dev_attr.attr,\n\t&sensor_dev_attr_power1_average.dev_attr.attr,\n\t&sensor_dev_attr_power1_input.dev_attr.attr,\n\t&sensor_dev_attr_power1_cap_max.dev_attr.attr,\n\t&sensor_dev_attr_power1_cap_min.dev_attr.attr,\n\t&sensor_dev_attr_power1_cap.dev_attr.attr,\n\t&sensor_dev_attr_power1_cap_default.dev_attr.attr,\n\t&sensor_dev_attr_power1_label.dev_attr.attr,\n\t&sensor_dev_attr_power2_average.dev_attr.attr,\n\t&sensor_dev_attr_power2_cap_max.dev_attr.attr,\n\t&sensor_dev_attr_power2_cap_min.dev_attr.attr,\n\t&sensor_dev_attr_power2_cap.dev_attr.attr,\n\t&sensor_dev_attr_power2_cap_default.dev_attr.attr,\n\t&sensor_dev_attr_power2_label.dev_attr.attr,\n\t&sensor_dev_attr_freq1_input.dev_attr.attr,\n\t&sensor_dev_attr_freq1_label.dev_attr.attr,\n\t&sensor_dev_attr_freq2_input.dev_attr.attr,\n\t&sensor_dev_attr_freq2_label.dev_attr.attr,\n\tNULL\n};\n\nstatic umode_t hwmon_attributes_visible(struct kobject *kobj,\n\t\t\t\t\tstruct attribute *attr, int index)\n{\n\tstruct device *dev = kobj_to_dev(kobj);\n\tstruct amdgpu_device *adev = dev_get_drvdata(dev);\n\tumode_t effective_mode = attr->mode;\n\tuint32_t gc_ver = adev->ip_versions[GC_HWIP][0];\n\tuint32_t tmp;\n\n\t \n\tif (amdgpu_sriov_vf(adev) && !amdgpu_sriov_is_pp_one_vf(adev))\n\t\treturn 0;\n\n\t \n\tif (amdgpu_sriov_is_pp_one_vf(adev))\n\t\teffective_mode &= ~S_IWUSR;\n\n\t \n\tif (adev->pm.no_fan && (attr == &sensor_dev_attr_pwm1.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_pwm1_enable.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_pwm1_max.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_pwm1_min.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_fan1_input.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_fan1_min.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_fan1_max.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_fan1_target.dev_attr.attr ||\n\t    attr == &sensor_dev_attr_fan1_enable.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif ((adev->flags & AMD_IS_APU) &&\n\t    (attr == &sensor_dev_attr_pwm1.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1_enable.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1_min.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_min.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_target.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_enable.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif ((((adev->flags & AMD_IS_APU) && (adev->family >= AMDGPU_FAMILY_CZ)) ||\n\t    (gc_ver == IP_VERSION(9, 4, 3))) &&\n\t    (attr == &sensor_dev_attr_temp1_crit.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp1_crit_hyst.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif (!adev->pm.dpm_enabled &&\n\t    (attr == &sensor_dev_attr_temp1_crit.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp1_crit_hyst.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1_enable.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1_min.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_min.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_target.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_enable.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif (((amdgpu_dpm_get_fan_speed_pwm(adev, NULL) == -EOPNOTSUPP) &&\n\t      attr == &sensor_dev_attr_pwm1.dev_attr.attr) ||  \n\t    ((amdgpu_dpm_get_fan_control_mode(adev, NULL) == -EOPNOTSUPP) &&\n\t     attr == &sensor_dev_attr_pwm1_enable.dev_attr.attr))  \n\t\teffective_mode &= ~S_IRUGO;\n\n\tif (((amdgpu_dpm_set_fan_speed_pwm(adev, U32_MAX) == -EOPNOTSUPP) &&\n\t      attr == &sensor_dev_attr_pwm1.dev_attr.attr) ||  \n\t      ((amdgpu_dpm_set_fan_control_mode(adev, U32_MAX) == -EOPNOTSUPP) &&\n\t      attr == &sensor_dev_attr_pwm1_enable.dev_attr.attr))  \n\t\teffective_mode &= ~S_IWUSR;\n\n\t \n\tif (((adev->family == AMDGPU_FAMILY_SI) ||\n\t     ((adev->flags & AMD_IS_APU) && (gc_ver != IP_VERSION(10, 3, 1)) &&\n\t      (gc_ver != IP_VERSION(9, 4, 3)))) &&\n\t    (attr == &sensor_dev_attr_power1_cap_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power1_cap_min.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power1_cap.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power1_cap_default.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif (((adev->family == AMDGPU_FAMILY_SI) ||\n\t     ((adev->flags & AMD_IS_APU) && (gc_ver < IP_VERSION(9, 3, 0)))) &&\n\t    (attr == &sensor_dev_attr_power1_average.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif (attr == &sensor_dev_attr_power1_average.dev_attr.attr &&\n\t    amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_GPU_AVG_POWER, (void *)&tmp) == -EOPNOTSUPP)\n\t\treturn 0;\n\tif (attr == &sensor_dev_attr_power1_input.dev_attr.attr &&\n\t    amdgpu_hwmon_get_sensor_generic(adev, AMDGPU_PP_SENSOR_GPU_INPUT_POWER, (void *)&tmp) == -EOPNOTSUPP)\n\t\treturn 0;\n\n\t \n\tif (((amdgpu_dpm_set_fan_speed_pwm(adev, U32_MAX) == -EOPNOTSUPP) &&\n\t      (amdgpu_dpm_get_fan_speed_pwm(adev, NULL) == -EOPNOTSUPP) &&\n\t      (amdgpu_dpm_set_fan_speed_rpm(adev, U32_MAX) == -EOPNOTSUPP) &&\n\t      (amdgpu_dpm_get_fan_speed_rpm(adev, NULL) == -EOPNOTSUPP)) &&\n\t    (attr == &sensor_dev_attr_pwm1_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_pwm1_min.dev_attr.attr))\n\t\treturn 0;\n\n\tif ((amdgpu_dpm_set_fan_speed_rpm(adev, U32_MAX) == -EOPNOTSUPP) &&\n\t     (amdgpu_dpm_get_fan_speed_rpm(adev, NULL) == -EOPNOTSUPP) &&\n\t     (attr == &sensor_dev_attr_fan1_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_fan1_min.dev_attr.attr))\n\t\treturn 0;\n\n\tif ((adev->family == AMDGPU_FAMILY_SI ||\t \n\t     adev->family == AMDGPU_FAMILY_KV ||\t \n\t     (gc_ver == IP_VERSION(9, 4, 3))) &&\n\t    (attr == &sensor_dev_attr_in0_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_in0_label.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif ((!(adev->flags & AMD_IS_APU) || (gc_ver == IP_VERSION(9, 4, 3))) &&\n\t    (attr == &sensor_dev_attr_in1_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_in1_label.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif (((adev->flags & AMD_IS_APU) && (gc_ver != IP_VERSION(9, 4, 3))) &&\n\t    (attr == &sensor_dev_attr_freq2_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_freq2_label.dev_attr.attr))\n\t\treturn 0;\n\n\tif (((adev->flags & AMD_IS_APU) || gc_ver < IP_VERSION(9, 0, 0)) &&\n\t    (gc_ver != IP_VERSION(9, 4, 3)) &&\n\t    (attr == &sensor_dev_attr_temp2_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp2_label.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp2_crit.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp3_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp3_label.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp3_crit.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif ((gc_ver == IP_VERSION(9, 4, 3)) &&\n\t    (attr == &sensor_dev_attr_temp1_input.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp1_label.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif (((adev->flags & AMD_IS_APU) || gc_ver < IP_VERSION(9, 0, 0) ||\n\t    (gc_ver == IP_VERSION(9, 4, 3))) &&\n\t     (attr == &sensor_dev_attr_temp2_crit_hyst.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp3_crit_hyst.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp1_emergency.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp2_emergency.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_temp3_emergency.dev_attr.attr))\n\t\treturn 0;\n\n\t \n\tif (!(gc_ver == IP_VERSION(10, 3, 1)) &&\n\t    (attr == &sensor_dev_attr_power2_average.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power2_cap_max.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power2_cap_min.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power2_cap.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power2_cap_default.dev_attr.attr ||\n\t     attr == &sensor_dev_attr_power2_label.dev_attr.attr))\n\t\treturn 0;\n\n\treturn effective_mode;\n}\n\nstatic const struct attribute_group hwmon_attrgroup = {\n\t.attrs = hwmon_attributes,\n\t.is_visible = hwmon_attributes_visible,\n};\n\nstatic const struct attribute_group *hwmon_groups[] = {\n\t&hwmon_attrgroup,\n\tNULL\n};\n\nint amdgpu_pm_sysfs_init(struct amdgpu_device *adev)\n{\n\tint ret;\n\tuint32_t mask = 0;\n\n\tif (adev->pm.sysfs_initialized)\n\t\treturn 0;\n\n\tINIT_LIST_HEAD(&adev->pm.pm_attr_list);\n\n\tif (adev->pm.dpm_enabled == 0)\n\t\treturn 0;\n\n\tadev->pm.int_hwmon_dev = hwmon_device_register_with_groups(adev->dev,\n\t\t\t\t\t\t\t\t   DRIVER_NAME, adev,\n\t\t\t\t\t\t\t\t   hwmon_groups);\n\tif (IS_ERR(adev->pm.int_hwmon_dev)) {\n\t\tret = PTR_ERR(adev->pm.int_hwmon_dev);\n\t\tdev_err(adev->dev,\n\t\t\t\"Unable to register hwmon device: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tswitch (amdgpu_virt_get_sriov_vf_mode(adev)) {\n\tcase SRIOV_VF_MODE_ONE_VF:\n\t\tmask = ATTR_FLAG_ONEVF;\n\t\tbreak;\n\tcase SRIOV_VF_MODE_MULTI_VF:\n\t\tmask = 0;\n\t\tbreak;\n\tcase SRIOV_VF_MODE_BARE_METAL:\n\tdefault:\n\t\tmask = ATTR_FLAG_MASK_ALL;\n\t\tbreak;\n\t}\n\n\tret = amdgpu_device_attr_create_groups(adev,\n\t\t\t\t\t       amdgpu_device_attrs,\n\t\t\t\t\t       ARRAY_SIZE(amdgpu_device_attrs),\n\t\t\t\t\t       mask,\n\t\t\t\t\t       &adev->pm.pm_attr_list);\n\tif (ret)\n\t\treturn ret;\n\n\tadev->pm.sysfs_initialized = true;\n\n\treturn 0;\n}\n\nvoid amdgpu_pm_sysfs_fini(struct amdgpu_device *adev)\n{\n\tif (adev->pm.int_hwmon_dev)\n\t\thwmon_device_unregister(adev->pm.int_hwmon_dev);\n\n\tamdgpu_device_attr_remove_groups(adev, &adev->pm.pm_attr_list);\n}\n\n \n#if defined(CONFIG_DEBUG_FS)\n\nstatic void amdgpu_debugfs_prints_cpu_info(struct seq_file *m,\n\t\t\t\t\t   struct amdgpu_device *adev)\n{\n\tuint16_t *p_val;\n\tuint32_t size;\n\tint i;\n\tuint32_t num_cpu_cores = amdgpu_dpm_get_num_cpu_cores(adev);\n\n\tif (amdgpu_dpm_is_cclk_dpm_supported(adev)) {\n\t\tp_val = kcalloc(num_cpu_cores, sizeof(uint16_t),\n\t\t\t\tGFP_KERNEL);\n\n\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_CPU_CLK,\n\t\t\t\t\t    (void *)p_val, &size)) {\n\t\t\tfor (i = 0; i < num_cpu_cores; i++)\n\t\t\t\tseq_printf(m, \"\\t%u MHz (CPU%d)\\n\",\n\t\t\t\t\t   *(p_val + i), i);\n\t\t}\n\n\t\tkfree(p_val);\n\t}\n}\n\nstatic int amdgpu_debugfs_pm_info_pp(struct seq_file *m, struct amdgpu_device *adev)\n{\n\tuint32_t mp1_ver = adev->ip_versions[MP1_HWIP][0];\n\tuint32_t gc_ver = adev->ip_versions[GC_HWIP][0];\n\tuint32_t value;\n\tuint64_t value64 = 0;\n\tuint32_t query = 0;\n\tint size;\n\n\t \n\tsize = sizeof(value);\n\tseq_printf(m, \"GFX Clocks and Power:\\n\");\n\n\tamdgpu_debugfs_prints_cpu_info(m, adev);\n\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_GFX_MCLK, (void *)&value, &size))\n\t\tseq_printf(m, \"\\t%u MHz (MCLK)\\n\", value/100);\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_GFX_SCLK, (void *)&value, &size))\n\t\tseq_printf(m, \"\\t%u MHz (SCLK)\\n\", value/100);\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_STABLE_PSTATE_SCLK, (void *)&value, &size))\n\t\tseq_printf(m, \"\\t%u MHz (PSTATE_SCLK)\\n\", value/100);\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_STABLE_PSTATE_MCLK, (void *)&value, &size))\n\t\tseq_printf(m, \"\\t%u MHz (PSTATE_MCLK)\\n\", value/100);\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_VDDGFX, (void *)&value, &size))\n\t\tseq_printf(m, \"\\t%u mV (VDDGFX)\\n\", value);\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_VDDNB, (void *)&value, &size))\n\t\tseq_printf(m, \"\\t%u mV (VDDNB)\\n\", value);\n\tsize = sizeof(uint32_t);\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_GPU_AVG_POWER, (void *)&query, &size))\n\t\tseq_printf(m, \"\\t%u.%u W (average GPU)\\n\", query >> 8, query & 0xff);\n\tsize = sizeof(uint32_t);\n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_GPU_INPUT_POWER, (void *)&query, &size))\n\t\tseq_printf(m, \"\\t%u.%u W (current GPU)\\n\", query >> 8, query & 0xff);\n\tsize = sizeof(value);\n\tseq_printf(m, \"\\n\");\n\n\t \n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_GPU_TEMP, (void *)&value, &size))\n\t\tseq_printf(m, \"GPU Temperature: %u C\\n\", value/1000);\n\n\t \n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_GPU_LOAD, (void *)&value, &size))\n\t\tseq_printf(m, \"GPU Load: %u %%\\n\", value);\n\t \n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_MEM_LOAD, (void *)&value, &size))\n\t\tseq_printf(m, \"MEM Load: %u %%\\n\", value);\n\n\tseq_printf(m, \"\\n\");\n\n\t \n\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_ENABLED_SMC_FEATURES_MASK, (void *)&value64, &size))\n\t\tseq_printf(m, \"SMC Feature Mask: 0x%016llx\\n\", value64);\n\n\t \n\tif (gc_ver != IP_VERSION(9, 4, 0) && mp1_ver > IP_VERSION(9, 0, 0)) {\n\t\t \n\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_VCN_POWER_STATE, (void *)&value, &size)) {\n\t\t\tif (!value) {\n\t\t\t\tseq_printf(m, \"VCN: Disabled\\n\");\n\t\t\t} else {\n\t\t\t\tseq_printf(m, \"VCN: Enabled\\n\");\n\t\t\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_UVD_DCLK, (void *)&value, &size))\n\t\t\t\t\tseq_printf(m, \"\\t%u MHz (DCLK)\\n\", value/100);\n\t\t\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_UVD_VCLK, (void *)&value, &size))\n\t\t\t\t\tseq_printf(m, \"\\t%u MHz (VCLK)\\n\", value/100);\n\t\t\t}\n\t\t}\n\t\tseq_printf(m, \"\\n\");\n\t} else {\n\t\t \n\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_UVD_POWER, (void *)&value, &size)) {\n\t\t\tif (!value) {\n\t\t\t\tseq_printf(m, \"UVD: Disabled\\n\");\n\t\t\t} else {\n\t\t\t\tseq_printf(m, \"UVD: Enabled\\n\");\n\t\t\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_UVD_DCLK, (void *)&value, &size))\n\t\t\t\t\tseq_printf(m, \"\\t%u MHz (DCLK)\\n\", value/100);\n\t\t\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_UVD_VCLK, (void *)&value, &size))\n\t\t\t\t\tseq_printf(m, \"\\t%u MHz (VCLK)\\n\", value/100);\n\t\t\t}\n\t\t}\n\t\tseq_printf(m, \"\\n\");\n\n\t\t \n\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_VCE_POWER, (void *)&value, &size)) {\n\t\t\tif (!value) {\n\t\t\t\tseq_printf(m, \"VCE: Disabled\\n\");\n\t\t\t} else {\n\t\t\t\tseq_printf(m, \"VCE: Enabled\\n\");\n\t\t\t\tif (!amdgpu_dpm_read_sensor(adev, AMDGPU_PP_SENSOR_VCE_ECCLK, (void *)&value, &size))\n\t\t\t\t\tseq_printf(m, \"\\t%u MHz (ECCLK)\\n\", value/100);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic const struct cg_flag_name clocks[] = {\n\t{AMD_CG_SUPPORT_GFX_FGCG, \"Graphics Fine Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_GFX_MGCG, \"Graphics Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_GFX_MGLS, \"Graphics Medium Grain memory Light Sleep\"},\n\t{AMD_CG_SUPPORT_GFX_CGCG, \"Graphics Coarse Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_GFX_CGLS, \"Graphics Coarse Grain memory Light Sleep\"},\n\t{AMD_CG_SUPPORT_GFX_CGTS, \"Graphics Coarse Grain Tree Shader Clock Gating\"},\n\t{AMD_CG_SUPPORT_GFX_CGTS_LS, \"Graphics Coarse Grain Tree Shader Light Sleep\"},\n\t{AMD_CG_SUPPORT_GFX_CP_LS, \"Graphics Command Processor Light Sleep\"},\n\t{AMD_CG_SUPPORT_GFX_RLC_LS, \"Graphics Run List Controller Light Sleep\"},\n\t{AMD_CG_SUPPORT_GFX_3D_CGCG, \"Graphics 3D Coarse Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_GFX_3D_CGLS, \"Graphics 3D Coarse Grain memory Light Sleep\"},\n\t{AMD_CG_SUPPORT_MC_LS, \"Memory Controller Light Sleep\"},\n\t{AMD_CG_SUPPORT_MC_MGCG, \"Memory Controller Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_SDMA_LS, \"System Direct Memory Access Light Sleep\"},\n\t{AMD_CG_SUPPORT_SDMA_MGCG, \"System Direct Memory Access Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_BIF_MGCG, \"Bus Interface Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_BIF_LS, \"Bus Interface Light Sleep\"},\n\t{AMD_CG_SUPPORT_UVD_MGCG, \"Unified Video Decoder Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_VCE_MGCG, \"Video Compression Engine Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_HDP_LS, \"Host Data Path Light Sleep\"},\n\t{AMD_CG_SUPPORT_HDP_MGCG, \"Host Data Path Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_DRM_MGCG, \"Digital Right Management Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_DRM_LS, \"Digital Right Management Light Sleep\"},\n\t{AMD_CG_SUPPORT_ROM_MGCG, \"Rom Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_DF_MGCG, \"Data Fabric Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_VCN_MGCG, \"VCN Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_HDP_DS, \"Host Data Path Deep Sleep\"},\n\t{AMD_CG_SUPPORT_HDP_SD, \"Host Data Path Shutdown\"},\n\t{AMD_CG_SUPPORT_IH_CG, \"Interrupt Handler Clock Gating\"},\n\t{AMD_CG_SUPPORT_JPEG_MGCG, \"JPEG Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_REPEATER_FGCG, \"Repeater Fine Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_GFX_PERF_CLK, \"Perfmon Clock Gating\"},\n\t{AMD_CG_SUPPORT_ATHUB_MGCG, \"Address Translation Hub Medium Grain Clock Gating\"},\n\t{AMD_CG_SUPPORT_ATHUB_LS, \"Address Translation Hub Light Sleep\"},\n\t{0, NULL},\n};\n\nstatic void amdgpu_parse_cg_state(struct seq_file *m, u64 flags)\n{\n\tint i;\n\n\tfor (i = 0; clocks[i].flag; i++)\n\t\tseq_printf(m, \"\\t%s: %s\\n\", clocks[i].name,\n\t\t\t   (flags & clocks[i].flag) ? \"On\" : \"Off\");\n}\n\nstatic int amdgpu_debugfs_pm_info_show(struct seq_file *m, void *unused)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)m->private;\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tu64 flags = 0;\n\tint r;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tr = pm_runtime_get_sync(dev->dev);\n\tif (r < 0) {\n\t\tpm_runtime_put_autosuspend(dev->dev);\n\t\treturn r;\n\t}\n\n\tif (amdgpu_dpm_debugfs_print_current_performance_level(adev, m)) {\n\t\tr = amdgpu_debugfs_pm_info_pp(m, adev);\n\t\tif (r)\n\t\t\tgoto out;\n\t}\n\n\tamdgpu_device_ip_get_clockgating_state(adev, &flags);\n\n\tseq_printf(m, \"Clock Gating Flags Mask: 0x%llx\\n\", flags);\n\tamdgpu_parse_cg_state(m, flags);\n\tseq_printf(m, \"\\n\");\n\nout:\n\tpm_runtime_mark_last_busy(dev->dev);\n\tpm_runtime_put_autosuspend(dev->dev);\n\n\treturn r;\n}\n\nDEFINE_SHOW_ATTRIBUTE(amdgpu_debugfs_pm_info);\n\n \nstatic ssize_t amdgpu_pm_prv_buffer_read(struct file *f, char __user *buf,\n\t\t\t\t\t size_t size, loff_t *pos)\n{\n\tstruct amdgpu_device *adev = file_inode(f)->i_private;\n\tsize_t smu_prv_buf_size;\n\tvoid *smu_prv_buf;\n\tint ret = 0;\n\n\tif (amdgpu_in_reset(adev))\n\t\treturn -EPERM;\n\tif (adev->in_suspend && !adev->in_runpm)\n\t\treturn -EPERM;\n\n\tret = amdgpu_dpm_get_smu_prv_buf_details(adev, &smu_prv_buf, &smu_prv_buf_size);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!smu_prv_buf || !smu_prv_buf_size)\n\t\treturn -EINVAL;\n\n\treturn simple_read_from_buffer(buf, size, pos, smu_prv_buf,\n\t\t\t\t       smu_prv_buf_size);\n}\n\nstatic const struct file_operations amdgpu_debugfs_pm_prv_buffer_fops = {\n\t.owner = THIS_MODULE,\n\t.open = simple_open,\n\t.read = amdgpu_pm_prv_buffer_read,\n\t.llseek = default_llseek,\n};\n\n#endif\n\nvoid amdgpu_debugfs_pm_init(struct amdgpu_device *adev)\n{\n#if defined(CONFIG_DEBUG_FS)\n\tstruct drm_minor *minor = adev_to_drm(adev)->primary;\n\tstruct dentry *root = minor->debugfs_root;\n\n\tif (!adev->pm.dpm_enabled)\n\t\treturn;\n\n\tdebugfs_create_file(\"amdgpu_pm_info\", 0444, root, adev,\n\t\t\t    &amdgpu_debugfs_pm_info_fops);\n\n\tif (adev->pm.smu_prv_buffer_size > 0)\n\t\tdebugfs_create_file_size(\"amdgpu_pm_prv_buffer\", 0444, root,\n\t\t\t\t\t adev,\n\t\t\t\t\t &amdgpu_debugfs_pm_prv_buffer_fops,\n\t\t\t\t\t adev->pm.smu_prv_buffer_size);\n\n\tamdgpu_dpm_stb_debug_fs_init(adev);\n#endif\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}