{
  "module_name": "amdgpu_smu.c",
  "hash_id": "da83ab4ffbc50bc7695bb9bcda16f1189275317332e0a4ea1dd363b5767d6437",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/pm/swsmu/amdgpu_smu.c",
  "human_readable_source": " \n\n#define SWSMU_CODE_LAYER_L1\n\n#include <linux/firmware.h>\n#include <linux/pci.h>\n#include <linux/reboot.h>\n\n#include \"amdgpu.h\"\n#include \"amdgpu_smu.h\"\n#include \"smu_internal.h\"\n#include \"atom.h\"\n#include \"arcturus_ppt.h\"\n#include \"navi10_ppt.h\"\n#include \"sienna_cichlid_ppt.h\"\n#include \"renoir_ppt.h\"\n#include \"vangogh_ppt.h\"\n#include \"aldebaran_ppt.h\"\n#include \"yellow_carp_ppt.h\"\n#include \"cyan_skillfish_ppt.h\"\n#include \"smu_v13_0_0_ppt.h\"\n#include \"smu_v13_0_4_ppt.h\"\n#include \"smu_v13_0_5_ppt.h\"\n#include \"smu_v13_0_6_ppt.h\"\n#include \"smu_v13_0_7_ppt.h\"\n#include \"amd_pcie.h\"\n\n \n#undef pr_err\n#undef pr_warn\n#undef pr_info\n#undef pr_debug\n\nstatic const struct amd_pm_funcs swsmu_pm_funcs;\nstatic int smu_force_smuclk_levels(struct smu_context *smu,\n\t\t\t\t   enum smu_clk_type clk_type,\n\t\t\t\t   uint32_t mask);\nstatic int smu_handle_task(struct smu_context *smu,\n\t\t\t   enum amd_dpm_forced_level level,\n\t\t\t   enum amd_pp_task task_id);\nstatic int smu_reset(struct smu_context *smu);\nstatic int smu_set_fan_speed_pwm(void *handle, u32 speed);\nstatic int smu_set_fan_control_mode(void *handle, u32 value);\nstatic int smu_set_power_limit(void *handle, uint32_t limit);\nstatic int smu_set_fan_speed_rpm(void *handle, uint32_t speed);\nstatic int smu_set_gfx_cgpg(struct smu_context *smu, bool enabled);\nstatic int smu_set_mp1_state(void *handle, enum pp_mp1_state mp1_state);\n\nstatic int smu_sys_get_pp_feature_mask(void *handle,\n\t\t\t\t       char *buf)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\treturn smu_get_pp_feature_mask(smu, buf);\n}\n\nstatic int smu_sys_set_pp_feature_mask(void *handle,\n\t\t\t\t       uint64_t new_mask)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\treturn smu_set_pp_feature_mask(smu, new_mask);\n}\n\nint smu_set_residency_gfxoff(struct smu_context *smu, bool value)\n{\n\tif (!smu->ppt_funcs->set_gfx_off_residency)\n\t\treturn -EINVAL;\n\n\treturn smu_set_gfx_off_residency(smu, value);\n}\n\nint smu_get_residency_gfxoff(struct smu_context *smu, u32 *value)\n{\n\tif (!smu->ppt_funcs->get_gfx_off_residency)\n\t\treturn -EINVAL;\n\n\treturn smu_get_gfx_off_residency(smu, value);\n}\n\nint smu_get_entrycount_gfxoff(struct smu_context *smu, u64 *value)\n{\n\tif (!smu->ppt_funcs->get_gfx_off_entrycount)\n\t\treturn -EINVAL;\n\n\treturn smu_get_gfx_off_entrycount(smu, value);\n}\n\nint smu_get_status_gfxoff(struct smu_context *smu, uint32_t *value)\n{\n\tif (!smu->ppt_funcs->get_gfx_off_status)\n\t\treturn -EINVAL;\n\n\t*value = smu_get_gfx_off_status(smu);\n\n\treturn 0;\n}\n\nint smu_set_soft_freq_range(struct smu_context *smu,\n\t\t\t    enum smu_clk_type clk_type,\n\t\t\t    uint32_t min,\n\t\t\t    uint32_t max)\n{\n\tint ret = 0;\n\n\tif (smu->ppt_funcs->set_soft_freq_limited_range)\n\t\tret = smu->ppt_funcs->set_soft_freq_limited_range(smu,\n\t\t\t\t\t\t\t\t  clk_type,\n\t\t\t\t\t\t\t\t  min,\n\t\t\t\t\t\t\t\t  max);\n\n\treturn ret;\n}\n\nint smu_get_dpm_freq_range(struct smu_context *smu,\n\t\t\t   enum smu_clk_type clk_type,\n\t\t\t   uint32_t *min,\n\t\t\t   uint32_t *max)\n{\n\tint ret = -ENOTSUPP;\n\n\tif (!min && !max)\n\t\treturn -EINVAL;\n\n\tif (smu->ppt_funcs->get_dpm_ultimate_freq)\n\t\tret = smu->ppt_funcs->get_dpm_ultimate_freq(smu,\n\t\t\t\t\t\t\t    clk_type,\n\t\t\t\t\t\t\t    min,\n\t\t\t\t\t\t\t    max);\n\n\treturn ret;\n}\n\nint smu_set_gfx_power_up_by_imu(struct smu_context *smu)\n{\n\tint ret = 0;\n\tstruct amdgpu_device *adev = smu->adev;\n\n\tif (smu->ppt_funcs->set_gfx_power_up_by_imu) {\n\t\tret = smu->ppt_funcs->set_gfx_power_up_by_imu(smu);\n\t\tif (ret)\n\t\t\tdev_err(adev->dev, \"Failed to enable gfx imu!\\n\");\n\t}\n\treturn ret;\n}\n\nstatic u32 smu_get_mclk(void *handle, bool low)\n{\n\tstruct smu_context *smu = handle;\n\tuint32_t clk_freq;\n\tint ret = 0;\n\n\tret = smu_get_dpm_freq_range(smu, SMU_UCLK,\n\t\t\t\t     low ? &clk_freq : NULL,\n\t\t\t\t     !low ? &clk_freq : NULL);\n\tif (ret)\n\t\treturn 0;\n\treturn clk_freq * 100;\n}\n\nstatic u32 smu_get_sclk(void *handle, bool low)\n{\n\tstruct smu_context *smu = handle;\n\tuint32_t clk_freq;\n\tint ret = 0;\n\n\tret = smu_get_dpm_freq_range(smu, SMU_GFXCLK,\n\t\t\t\t     low ? &clk_freq : NULL,\n\t\t\t\t     !low ? &clk_freq : NULL);\n\tif (ret)\n\t\treturn 0;\n\treturn clk_freq * 100;\n}\n\nstatic int smu_set_gfx_imu_enable(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\n\tif (adev->firmware.load_type != AMDGPU_FW_LOAD_PSP)\n\t\treturn 0;\n\n\tif (amdgpu_in_reset(smu->adev) || adev->in_s0ix)\n\t\treturn 0;\n\n\treturn smu_set_gfx_power_up_by_imu(smu);\n}\n\nstatic int smu_dpm_set_vcn_enable(struct smu_context *smu,\n\t\t\t\t  bool enable)\n{\n\tstruct smu_power_context *smu_power = &smu->smu_power;\n\tstruct smu_power_gate *power_gate = &smu_power->power_gate;\n\tint ret = 0;\n\n\tif (!smu->ppt_funcs->dpm_set_vcn_enable)\n\t\treturn 0;\n\n\tif (atomic_read(&power_gate->vcn_gated) ^ enable)\n\t\treturn 0;\n\n\tret = smu->ppt_funcs->dpm_set_vcn_enable(smu, enable);\n\tif (!ret)\n\t\tatomic_set(&power_gate->vcn_gated, !enable);\n\n\treturn ret;\n}\n\nstatic int smu_dpm_set_jpeg_enable(struct smu_context *smu,\n\t\t\t\t   bool enable)\n{\n\tstruct smu_power_context *smu_power = &smu->smu_power;\n\tstruct smu_power_gate *power_gate = &smu_power->power_gate;\n\tint ret = 0;\n\n\tif (!smu->ppt_funcs->dpm_set_jpeg_enable)\n\t\treturn 0;\n\n\tif (atomic_read(&power_gate->jpeg_gated) ^ enable)\n\t\treturn 0;\n\n\tret = smu->ppt_funcs->dpm_set_jpeg_enable(smu, enable);\n\tif (!ret)\n\t\tatomic_set(&power_gate->jpeg_gated, !enable);\n\n\treturn ret;\n}\n\n \nstatic int smu_dpm_set_power_gate(void *handle,\n\t\t\t\t  uint32_t block_type,\n\t\t\t\t  bool gate)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled) {\n\t\tdev_WARN(smu->adev->dev,\n\t\t\t \"SMU uninitialized but power %s requested for %u!\\n\",\n\t\t\t gate ? \"gate\" : \"ungate\", block_type);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tswitch (block_type) {\n\t \n\tcase AMD_IP_BLOCK_TYPE_UVD:\n\tcase AMD_IP_BLOCK_TYPE_VCN:\n\t\tret = smu_dpm_set_vcn_enable(smu, !gate);\n\t\tif (ret)\n\t\t\tdev_err(smu->adev->dev, \"Failed to power %s VCN!\\n\",\n\t\t\t\tgate ? \"gate\" : \"ungate\");\n\t\tbreak;\n\tcase AMD_IP_BLOCK_TYPE_GFX:\n\t\tret = smu_gfx_off_control(smu, gate);\n\t\tif (ret)\n\t\t\tdev_err(smu->adev->dev, \"Failed to %s gfxoff!\\n\",\n\t\t\t\tgate ? \"enable\" : \"disable\");\n\t\tbreak;\n\tcase AMD_IP_BLOCK_TYPE_SDMA:\n\t\tret = smu_powergate_sdma(smu, gate);\n\t\tif (ret)\n\t\t\tdev_err(smu->adev->dev, \"Failed to power %s SDMA!\\n\",\n\t\t\t\tgate ? \"gate\" : \"ungate\");\n\t\tbreak;\n\tcase AMD_IP_BLOCK_TYPE_JPEG:\n\t\tret = smu_dpm_set_jpeg_enable(smu, !gate);\n\t\tif (ret)\n\t\t\tdev_err(smu->adev->dev, \"Failed to power %s JPEG!\\n\",\n\t\t\t\tgate ? \"gate\" : \"ungate\");\n\t\tbreak;\n\tdefault:\n\t\tdev_err(smu->adev->dev, \"Unsupported block type!\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn ret;\n}\n\n \nstatic void smu_set_user_clk_dependencies(struct smu_context *smu, enum smu_clk_type clk)\n{\n\tif (smu->adev->in_suspend)\n\t\treturn;\n\n\tif (clk == SMU_MCLK) {\n\t\tsmu->user_dpm_profile.clk_dependency = 0;\n\t\tsmu->user_dpm_profile.clk_dependency = BIT(SMU_FCLK) | BIT(SMU_SOCCLK);\n\t} else if (clk == SMU_FCLK) {\n\t\t \n\t\tif (smu->user_dpm_profile.clk_dependency == (BIT(SMU_FCLK) | BIT(SMU_SOCCLK)))\n\t\t\treturn;\n\n\t\tsmu->user_dpm_profile.clk_dependency = 0;\n\t\tsmu->user_dpm_profile.clk_dependency = BIT(SMU_MCLK) | BIT(SMU_SOCCLK);\n\t} else if (clk == SMU_SOCCLK) {\n\t\t \n\t\tif (smu->user_dpm_profile.clk_dependency == (BIT(SMU_FCLK) | BIT(SMU_SOCCLK)))\n\t\t\treturn;\n\n\t\tsmu->user_dpm_profile.clk_dependency = 0;\n\t\tsmu->user_dpm_profile.clk_dependency = BIT(SMU_MCLK) | BIT(SMU_FCLK);\n\t} else\n\t\t \n\t\treturn;\n}\n\n \nstatic void smu_restore_dpm_user_profile(struct smu_context *smu)\n{\n\tstruct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);\n\tint ret = 0;\n\n\tif (!smu->adev->in_suspend)\n\t\treturn;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn;\n\n\t \n\tsmu->user_dpm_profile.flags |= SMU_DPM_USER_PROFILE_RESTORE;\n\n\t \n\tif (smu->user_dpm_profile.power_limit) {\n\t\tret = smu_set_power_limit(smu, smu->user_dpm_profile.power_limit);\n\t\tif (ret)\n\t\t\tdev_err(smu->adev->dev, \"Failed to set power limit value\\n\");\n\t}\n\n\t \n\tif (smu_dpm_ctx->dpm_level == AMD_DPM_FORCED_LEVEL_MANUAL) {\n\t\tenum smu_clk_type clk_type;\n\n\t\tfor (clk_type = 0; clk_type < SMU_CLK_COUNT; clk_type++) {\n\t\t\t \n\t\t\tif (!(smu->user_dpm_profile.clk_dependency & BIT(clk_type)) &&\n\t\t\t\t\tsmu->user_dpm_profile.clk_mask[clk_type]) {\n\t\t\t\tret = smu_force_smuclk_levels(smu, clk_type,\n\t\t\t\t\t\tsmu->user_dpm_profile.clk_mask[clk_type]);\n\t\t\t\tif (ret)\n\t\t\t\t\tdev_err(smu->adev->dev,\n\t\t\t\t\t\t\"Failed to set clock type = %d\\n\", clk_type);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (smu->user_dpm_profile.fan_mode == AMD_FAN_CTRL_MANUAL ||\n\t    smu->user_dpm_profile.fan_mode == AMD_FAN_CTRL_NONE) {\n\t\tret = smu_set_fan_control_mode(smu, smu->user_dpm_profile.fan_mode);\n\t\tif (ret != -EOPNOTSUPP) {\n\t\t\tsmu->user_dpm_profile.fan_speed_pwm = 0;\n\t\t\tsmu->user_dpm_profile.fan_speed_rpm = 0;\n\t\t\tsmu->user_dpm_profile.fan_mode = AMD_FAN_CTRL_AUTO;\n\t\t\tdev_err(smu->adev->dev, \"Failed to set manual fan control mode\\n\");\n\t\t}\n\n\t\tif (smu->user_dpm_profile.fan_speed_pwm) {\n\t\t\tret = smu_set_fan_speed_pwm(smu, smu->user_dpm_profile.fan_speed_pwm);\n\t\t\tif (ret != -EOPNOTSUPP)\n\t\t\t\tdev_err(smu->adev->dev, \"Failed to set manual fan speed in pwm\\n\");\n\t\t}\n\n\t\tif (smu->user_dpm_profile.fan_speed_rpm) {\n\t\t\tret = smu_set_fan_speed_rpm(smu, smu->user_dpm_profile.fan_speed_rpm);\n\t\t\tif (ret != -EOPNOTSUPP)\n\t\t\t\tdev_err(smu->adev->dev, \"Failed to set manual fan speed in rpm\\n\");\n\t\t}\n\t}\n\n\t \n\tif (smu->user_dpm_profile.user_od) {\n\t\tif (smu->ppt_funcs->restore_user_od_settings) {\n\t\t\tret = smu->ppt_funcs->restore_user_od_settings(smu);\n\t\t\tif (ret)\n\t\t\t\tdev_err(smu->adev->dev, \"Failed to upload customized OD settings\\n\");\n\t\t}\n\t}\n\n\t \n\tsmu->user_dpm_profile.flags &= ~SMU_DPM_USER_PROFILE_RESTORE;\n}\n\nstatic int smu_get_power_num_states(void *handle,\n\t\t\t\t    struct pp_states_info *state_info)\n{\n\tif (!state_info)\n\t\treturn -EINVAL;\n\n\t \n\tmemset(state_info, 0, sizeof(struct pp_states_info));\n\tstate_info->nums = 1;\n\tstate_info->states[0] = POWER_STATE_TYPE_DEFAULT;\n\n\treturn 0;\n}\n\nbool is_support_sw_smu(struct amdgpu_device *adev)\n{\n\t \n\tif (adev->asic_type == CHIP_VEGA20)\n\t\treturn false;\n\n\tif (adev->ip_versions[MP1_HWIP][0] >= IP_VERSION(11, 0, 0))\n\t\treturn true;\n\n\treturn false;\n}\n\nbool is_support_cclk_dpm(struct amdgpu_device *adev)\n{\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\tif (!smu_feature_is_enabled(smu, SMU_FEATURE_CCLK_DPM_BIT))\n\t\treturn false;\n\n\treturn true;\n}\n\n\nstatic int smu_sys_get_pp_table(void *handle,\n\t\t\t\tchar **table)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu_table->power_play_table && !smu_table->hardcode_pptable)\n\t\treturn -EINVAL;\n\n\tif (smu_table->hardcode_pptable)\n\t\t*table = smu_table->hardcode_pptable;\n\telse\n\t\t*table = smu_table->power_play_table;\n\n\treturn smu_table->power_play_table_size;\n}\n\nstatic int smu_sys_set_pp_table(void *handle,\n\t\t\t\tconst char *buf,\n\t\t\t\tsize_t size)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tATOM_COMMON_TABLE_HEADER *header = (ATOM_COMMON_TABLE_HEADER *)buf;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (header->usStructureSize != size) {\n\t\tdev_err(smu->adev->dev, \"pp table size not matched !\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (!smu_table->hardcode_pptable) {\n\t\tsmu_table->hardcode_pptable = kzalloc(size, GFP_KERNEL);\n\t\tif (!smu_table->hardcode_pptable)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tmemcpy(smu_table->hardcode_pptable, buf, size);\n\tsmu_table->power_play_table = smu_table->hardcode_pptable;\n\tsmu_table->power_play_table_size = size;\n\n\t \n\tsmu->uploading_custom_pp_table = true;\n\n\tret = smu_reset(smu);\n\tif (ret)\n\t\tdev_info(smu->adev->dev, \"smu reset failed, ret = %d\\n\", ret);\n\n\tsmu->uploading_custom_pp_table = false;\n\n\treturn ret;\n}\n\nstatic int smu_get_driver_allowed_feature_mask(struct smu_context *smu)\n{\n\tstruct smu_feature *feature = &smu->smu_feature;\n\tuint32_t allowed_feature_mask[SMU_FEATURE_MAX/32];\n\tint ret = 0;\n\n\t \n\tif (smu->adev->scpm_enabled) {\n\t\tbitmap_fill(feature->allowed, SMU_FEATURE_MAX);\n\t\treturn 0;\n\t}\n\n\tbitmap_zero(feature->allowed, SMU_FEATURE_MAX);\n\n\tret = smu_get_allowed_feature_mask(smu, allowed_feature_mask,\n\t\t\t\t\t     SMU_FEATURE_MAX/32);\n\tif (ret)\n\t\treturn ret;\n\n\tbitmap_or(feature->allowed, feature->allowed,\n\t\t      (unsigned long *)allowed_feature_mask,\n\t\t      feature->feature_num);\n\n\treturn ret;\n}\n\nstatic int smu_set_funcs(struct amdgpu_device *adev)\n{\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\tif (adev->pm.pp_feature & PP_OVERDRIVE_MASK)\n\t\tsmu->od_enabled = true;\n\n\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\tcase IP_VERSION(11, 0, 0):\n\tcase IP_VERSION(11, 0, 5):\n\tcase IP_VERSION(11, 0, 9):\n\t\tnavi10_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(11, 0, 7):\n\tcase IP_VERSION(11, 0, 11):\n\tcase IP_VERSION(11, 0, 12):\n\tcase IP_VERSION(11, 0, 13):\n\t\tsienna_cichlid_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(12, 0, 0):\n\tcase IP_VERSION(12, 0, 1):\n\t\trenoir_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(11, 5, 0):\n\t\tvangogh_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 1):\n\tcase IP_VERSION(13, 0, 3):\n\tcase IP_VERSION(13, 0, 8):\n\t\tyellow_carp_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 4):\n\tcase IP_VERSION(13, 0, 11):\n\t\tsmu_v13_0_4_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 5):\n\t\tsmu_v13_0_5_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(11, 0, 8):\n\t\tcyan_skillfish_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(11, 0, 2):\n\t\tadev->pm.pp_feature &= ~PP_GFXOFF_MASK;\n\t\tarcturus_set_ppt_funcs(smu);\n\t\t \n\t\tsmu->od_enabled = false;\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 2):\n\t\taldebaran_set_ppt_funcs(smu);\n\t\t \n\t\tsmu->od_enabled = true;\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 0):\n\tcase IP_VERSION(13, 0, 10):\n\t\tsmu_v13_0_0_set_ppt_funcs(smu);\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 6):\n\t\tsmu_v13_0_6_set_ppt_funcs(smu);\n\t\t \n\t\tsmu->od_enabled = true;\n\t\tbreak;\n\tcase IP_VERSION(13, 0, 7):\n\t\tsmu_v13_0_7_set_ppt_funcs(smu);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int smu_early_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu;\n\tint r;\n\n\tsmu = kzalloc(sizeof(struct smu_context), GFP_KERNEL);\n\tif (!smu)\n\t\treturn -ENOMEM;\n\n\tsmu->adev = adev;\n\tsmu->pm_enabled = !!amdgpu_dpm;\n\tsmu->is_apu = false;\n\tsmu->smu_baco.state = SMU_BACO_STATE_EXIT;\n\tsmu->smu_baco.platform_support = false;\n\tsmu->user_dpm_profile.fan_mode = -1;\n\n\tmutex_init(&smu->message_lock);\n\n\tadev->powerplay.pp_handle = smu;\n\tadev->powerplay.pp_funcs = &swsmu_pm_funcs;\n\n\tr = smu_set_funcs(adev);\n\tif (r)\n\t\treturn r;\n\treturn smu_init_microcode(smu);\n}\n\nstatic int smu_set_default_dpm_table(struct smu_context *smu)\n{\n\tstruct smu_power_context *smu_power = &smu->smu_power;\n\tstruct smu_power_gate *power_gate = &smu_power->power_gate;\n\tint vcn_gate, jpeg_gate;\n\tint ret = 0;\n\n\tif (!smu->ppt_funcs->set_default_dpm_table)\n\t\treturn 0;\n\n\tvcn_gate = atomic_read(&power_gate->vcn_gated);\n\tjpeg_gate = atomic_read(&power_gate->jpeg_gated);\n\n\tret = smu_dpm_set_vcn_enable(smu, true);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_dpm_set_jpeg_enable(smu, true);\n\tif (ret)\n\t\tgoto err_out;\n\n\tret = smu->ppt_funcs->set_default_dpm_table(smu);\n\tif (ret)\n\t\tdev_err(smu->adev->dev,\n\t\t\t\"Failed to setup default dpm clock tables!\\n\");\n\n\tsmu_dpm_set_jpeg_enable(smu, !jpeg_gate);\nerr_out:\n\tsmu_dpm_set_vcn_enable(smu, !vcn_gate);\n\treturn ret;\n}\n\nstatic int smu_apply_default_config_table_settings(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tint ret = 0;\n\n\tret = smu_get_default_config_table_settings(smu,\n\t\t\t\t\t\t    &adev->pm.config_table);\n\tif (ret)\n\t\treturn ret;\n\n\treturn smu_set_config_table(smu, &adev->pm.config_table);\n}\n\nstatic int smu_late_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\tint ret = 0;\n\n\tsmu_set_fine_grain_gfx_freq_parameters(smu);\n\n\tif (!smu->pm_enabled)\n\t\treturn 0;\n\n\tret = smu_post_init(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to post smu init!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tif (!smu->dc_controlled_by_gpio) {\n\t\tret = smu_set_power_source(smu,\n\t\t\t\t\t   adev->pm.ac_power ? SMU_POWER_SOURCE_AC :\n\t\t\t\t\t   SMU_POWER_SOURCE_DC);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"Failed to switch to %s mode!\\n\",\n\t\t\t\tadev->pm.ac_power ? \"AC\" : \"DC\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif ((adev->ip_versions[MP1_HWIP][0] == IP_VERSION(13, 0, 1)) ||\n\t    (adev->ip_versions[MP1_HWIP][0] == IP_VERSION(13, 0, 3)))\n\t\treturn 0;\n\n\tif (!amdgpu_sriov_vf(adev) || smu->od_enabled) {\n\t\tret = smu_set_default_od_settings(smu);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"Failed to setup default OD settings!\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = smu_populate_umd_state_clk(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to populate UMD state clocks!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_get_asic_power_limits(smu,\n\t\t\t\t\t&smu->current_power_limit,\n\t\t\t\t\t&smu->default_power_limit,\n\t\t\t\t\t&smu->max_power_limit);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to get asic power limits!\\n\");\n\t\treturn ret;\n\t}\n\n\tif (!amdgpu_sriov_vf(adev))\n\t\tsmu_get_unique_id(smu);\n\n\tsmu_get_fan_parameters(smu);\n\n\tsmu_handle_task(smu,\n\t\t\tsmu->smu_dpm.dpm_level,\n\t\t\tAMD_PP_TASK_COMPLETE_INIT);\n\n\tret = smu_apply_default_config_table_settings(smu);\n\tif (ret && (ret != -EOPNOTSUPP)) {\n\t\tdev_err(adev->dev, \"Failed to apply default DriverSmuConfig settings!\\n\");\n\t\treturn ret;\n\t}\n\n\tsmu_restore_dpm_user_profile(smu);\n\n\treturn 0;\n}\n\nstatic int smu_init_fb_allocations(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tstruct smu_table *tables = smu_table->tables;\n\tstruct smu_table *driver_table = &(smu_table->driver_table);\n\tuint32_t max_table_size = 0;\n\tint ret, i;\n\n\t \n\tif (tables[SMU_TABLE_PMSTATUSLOG].size) {\n\t\tret = amdgpu_bo_create_kernel(adev,\n\t\t\t\t\t      tables[SMU_TABLE_PMSTATUSLOG].size,\n\t\t\t\t\t      tables[SMU_TABLE_PMSTATUSLOG].align,\n\t\t\t\t\t      tables[SMU_TABLE_PMSTATUSLOG].domain,\n\t\t\t\t\t      &tables[SMU_TABLE_PMSTATUSLOG].bo,\n\t\t\t\t\t      &tables[SMU_TABLE_PMSTATUSLOG].mc_address,\n\t\t\t\t\t      &tables[SMU_TABLE_PMSTATUSLOG].cpu_addr);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"VRAM allocation for tool table failed!\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tdriver_table->domain = AMDGPU_GEM_DOMAIN_VRAM | AMDGPU_GEM_DOMAIN_GTT;\n\t \n\tfor (i = 0; i < SMU_TABLE_COUNT; i++) {\n\t\tif (tables[i].size == 0)\n\t\t\tcontinue;\n\n\t\t \n\t\tif ((tables[i].domain &\n\t\t    (AMDGPU_GEM_DOMAIN_VRAM | AMDGPU_GEM_DOMAIN_GTT)) ==\n\t\t\t    AMDGPU_GEM_DOMAIN_VRAM)\n\t\t\tdriver_table->domain = AMDGPU_GEM_DOMAIN_VRAM;\n\n\t\tif (i == SMU_TABLE_PMSTATUSLOG)\n\t\t\tcontinue;\n\n\t\tif (max_table_size < tables[i].size)\n\t\t\tmax_table_size = tables[i].size;\n\t}\n\n\tdriver_table->size = max_table_size;\n\tdriver_table->align = PAGE_SIZE;\n\n\tret = amdgpu_bo_create_kernel(adev,\n\t\t\t\t      driver_table->size,\n\t\t\t\t      driver_table->align,\n\t\t\t\t      driver_table->domain,\n\t\t\t\t      &driver_table->bo,\n\t\t\t\t      &driver_table->mc_address,\n\t\t\t\t      &driver_table->cpu_addr);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"VRAM allocation for driver table failed!\\n\");\n\t\tif (tables[SMU_TABLE_PMSTATUSLOG].mc_address)\n\t\t\tamdgpu_bo_free_kernel(&tables[SMU_TABLE_PMSTATUSLOG].bo,\n\t\t\t\t\t      &tables[SMU_TABLE_PMSTATUSLOG].mc_address,\n\t\t\t\t\t      &tables[SMU_TABLE_PMSTATUSLOG].cpu_addr);\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_fini_fb_allocations(struct smu_context *smu)\n{\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tstruct smu_table *tables = smu_table->tables;\n\tstruct smu_table *driver_table = &(smu_table->driver_table);\n\n\tif (tables[SMU_TABLE_PMSTATUSLOG].mc_address)\n\t\tamdgpu_bo_free_kernel(&tables[SMU_TABLE_PMSTATUSLOG].bo,\n\t\t\t\t      &tables[SMU_TABLE_PMSTATUSLOG].mc_address,\n\t\t\t\t      &tables[SMU_TABLE_PMSTATUSLOG].cpu_addr);\n\n\tamdgpu_bo_free_kernel(&driver_table->bo,\n\t\t\t      &driver_table->mc_address,\n\t\t\t      &driver_table->cpu_addr);\n\n\treturn 0;\n}\n\n \nstatic int smu_alloc_memory_pool(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tstruct smu_table *memory_pool = &smu_table->memory_pool;\n\tuint64_t pool_size = smu->pool_size;\n\tint ret = 0;\n\n\tif (pool_size == SMU_MEMORY_POOL_SIZE_ZERO)\n\t\treturn ret;\n\n\tmemory_pool->size = pool_size;\n\tmemory_pool->align = PAGE_SIZE;\n\tmemory_pool->domain = AMDGPU_GEM_DOMAIN_GTT;\n\n\tswitch (pool_size) {\n\tcase SMU_MEMORY_POOL_SIZE_256_MB:\n\tcase SMU_MEMORY_POOL_SIZE_512_MB:\n\tcase SMU_MEMORY_POOL_SIZE_1_GB:\n\tcase SMU_MEMORY_POOL_SIZE_2_GB:\n\t\tret = amdgpu_bo_create_kernel(adev,\n\t\t\t\t\t      memory_pool->size,\n\t\t\t\t\t      memory_pool->align,\n\t\t\t\t\t      memory_pool->domain,\n\t\t\t\t\t      &memory_pool->bo,\n\t\t\t\t\t      &memory_pool->mc_address,\n\t\t\t\t\t      &memory_pool->cpu_addr);\n\t\tif (ret)\n\t\t\tdev_err(adev->dev, \"VRAM allocation for dramlog failed!\\n\");\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_free_memory_pool(struct smu_context *smu)\n{\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tstruct smu_table *memory_pool = &smu_table->memory_pool;\n\n\tif (memory_pool->size == SMU_MEMORY_POOL_SIZE_ZERO)\n\t\treturn 0;\n\n\tamdgpu_bo_free_kernel(&memory_pool->bo,\n\t\t\t      &memory_pool->mc_address,\n\t\t\t      &memory_pool->cpu_addr);\n\n\tmemset(memory_pool, 0, sizeof(struct smu_table));\n\n\treturn 0;\n}\n\nstatic int smu_alloc_dummy_read_table(struct smu_context *smu)\n{\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tstruct smu_table *dummy_read_1_table =\n\t\t\t&smu_table->dummy_read_1_table;\n\tstruct amdgpu_device *adev = smu->adev;\n\tint ret = 0;\n\n\tif (!dummy_read_1_table->size)\n\t\treturn 0;\n\n\tret = amdgpu_bo_create_kernel(adev,\n\t\t\t\t      dummy_read_1_table->size,\n\t\t\t\t      dummy_read_1_table->align,\n\t\t\t\t      dummy_read_1_table->domain,\n\t\t\t\t      &dummy_read_1_table->bo,\n\t\t\t\t      &dummy_read_1_table->mc_address,\n\t\t\t\t      &dummy_read_1_table->cpu_addr);\n\tif (ret)\n\t\tdev_err(adev->dev, \"VRAM allocation for dummy read table failed!\\n\");\n\n\treturn ret;\n}\n\nstatic void smu_free_dummy_read_table(struct smu_context *smu)\n{\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tstruct smu_table *dummy_read_1_table =\n\t\t\t&smu_table->dummy_read_1_table;\n\n\n\tamdgpu_bo_free_kernel(&dummy_read_1_table->bo,\n\t\t\t      &dummy_read_1_table->mc_address,\n\t\t\t      &dummy_read_1_table->cpu_addr);\n\n\tmemset(dummy_read_1_table, 0, sizeof(struct smu_table));\n}\n\nstatic int smu_smc_table_sw_init(struct smu_context *smu)\n{\n\tint ret;\n\n\t \n\tret = smu_init_smc_tables(smu);\n\tif (ret) {\n\t\tdev_err(smu->adev->dev, \"Failed to init smc tables!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = smu_init_power(smu);\n\tif (ret) {\n\t\tdev_err(smu->adev->dev, \"Failed to init smu_init_power!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = smu_init_fb_allocations(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_alloc_memory_pool(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_alloc_dummy_read_table(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_i2c_init(smu);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int smu_smc_table_sw_fini(struct smu_context *smu)\n{\n\tint ret;\n\n\tsmu_i2c_fini(smu);\n\n\tsmu_free_dummy_read_table(smu);\n\n\tret = smu_free_memory_pool(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_fini_fb_allocations(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_fini_power(smu);\n\tif (ret) {\n\t\tdev_err(smu->adev->dev, \"Failed to init smu_fini_power!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_fini_smc_tables(smu);\n\tif (ret) {\n\t\tdev_err(smu->adev->dev, \"Failed to smu_fini_smc_tables!\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void smu_throttling_logging_work_fn(struct work_struct *work)\n{\n\tstruct smu_context *smu = container_of(work, struct smu_context,\n\t\t\t\t\t       throttling_logging_work);\n\n\tsmu_log_thermal_throttling(smu);\n}\n\nstatic void smu_interrupt_work_fn(struct work_struct *work)\n{\n\tstruct smu_context *smu = container_of(work, struct smu_context,\n\t\t\t\t\t       interrupt_work);\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->interrupt_work)\n\t\tsmu->ppt_funcs->interrupt_work(smu);\n}\n\nstatic void smu_swctf_delayed_work_handler(struct work_struct *work)\n{\n\tstruct smu_context *smu =\n\t\tcontainer_of(work, struct smu_context, swctf_delayed_work.work);\n\tstruct smu_temperature_range *range =\n\t\t\t\t&smu->thermal_range;\n\tstruct amdgpu_device *adev = smu->adev;\n\tuint32_t hotspot_tmp, size;\n\n\t \n\tif (range->software_shutdown_temp &&\n\t    smu->ppt_funcs->read_sensor &&\n\t    !smu->ppt_funcs->read_sensor(smu,\n\t\t\t\t\t AMDGPU_PP_SENSOR_HOTSPOT_TEMP,\n\t\t\t\t\t &hotspot_tmp,\n\t\t\t\t\t &size) &&\n\t    hotspot_tmp / 1000 < range->software_shutdown_temp)\n\t\treturn;\n\n\tdev_emerg(adev->dev, \"ERROR: GPU over temperature range(SW CTF) detected!\\n\");\n\tdev_emerg(adev->dev, \"ERROR: System is going to shutdown due to GPU SW CTF!\\n\");\n\torderly_poweroff(true);\n}\n\nstatic int smu_sw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\tint ret;\n\n\tsmu->pool_size = adev->pm.smu_prv_buffer_size;\n\tsmu->smu_feature.feature_num = SMU_FEATURE_MAX;\n\tbitmap_zero(smu->smu_feature.supported, SMU_FEATURE_MAX);\n\tbitmap_zero(smu->smu_feature.allowed, SMU_FEATURE_MAX);\n\n\tINIT_WORK(&smu->throttling_logging_work, smu_throttling_logging_work_fn);\n\tINIT_WORK(&smu->interrupt_work, smu_interrupt_work_fn);\n\tatomic64_set(&smu->throttle_int_counter, 0);\n\tsmu->watermarks_bitmap = 0;\n\tsmu->power_profile_mode = PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT;\n\tsmu->default_power_profile_mode = PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT;\n\n\tatomic_set(&smu->smu_power.power_gate.vcn_gated, 1);\n\tatomic_set(&smu->smu_power.power_gate.jpeg_gated, 1);\n\n\tsmu->workload_mask = 1 << smu->workload_prority[PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT];\n\tsmu->workload_prority[PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT] = 0;\n\tsmu->workload_prority[PP_SMC_POWER_PROFILE_FULLSCREEN3D] = 1;\n\tsmu->workload_prority[PP_SMC_POWER_PROFILE_POWERSAVING] = 2;\n\tsmu->workload_prority[PP_SMC_POWER_PROFILE_VIDEO] = 3;\n\tsmu->workload_prority[PP_SMC_POWER_PROFILE_VR] = 4;\n\tsmu->workload_prority[PP_SMC_POWER_PROFILE_COMPUTE] = 5;\n\tsmu->workload_prority[PP_SMC_POWER_PROFILE_CUSTOM] = 6;\n\n\tsmu->workload_setting[0] = PP_SMC_POWER_PROFILE_BOOTUP_DEFAULT;\n\tsmu->workload_setting[1] = PP_SMC_POWER_PROFILE_FULLSCREEN3D;\n\tsmu->workload_setting[2] = PP_SMC_POWER_PROFILE_POWERSAVING;\n\tsmu->workload_setting[3] = PP_SMC_POWER_PROFILE_VIDEO;\n\tsmu->workload_setting[4] = PP_SMC_POWER_PROFILE_VR;\n\tsmu->workload_setting[5] = PP_SMC_POWER_PROFILE_COMPUTE;\n\tsmu->workload_setting[6] = PP_SMC_POWER_PROFILE_CUSTOM;\n\tsmu->display_config = &adev->pm.pm_display_cfg;\n\n\tsmu->smu_dpm.dpm_level = AMD_DPM_FORCED_LEVEL_AUTO;\n\tsmu->smu_dpm.requested_dpm_level = AMD_DPM_FORCED_LEVEL_AUTO;\n\n\tINIT_DELAYED_WORK(&smu->swctf_delayed_work,\n\t\t\t  smu_swctf_delayed_work_handler);\n\n\tret = smu_smc_table_sw_init(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to sw init smc table!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = smu_get_vbios_bootup_values(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to get VBIOS boot clock values!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_init_pptable_microcode(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to setup pptable firmware!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_register_irq_handler(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to register smc irq handler!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tif (!smu->ppt_funcs->get_fan_control_mode)\n\t\tsmu->adev->pm.no_fan = true;\n\n\treturn 0;\n}\n\nstatic int smu_sw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\tint ret;\n\n\tret = smu_smc_table_sw_fini(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to sw fini smc table!\\n\");\n\t\treturn ret;\n\t}\n\n\tsmu_fini_microcode(smu);\n\n\treturn 0;\n}\n\nstatic int smu_get_thermal_temperature_range(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tstruct smu_temperature_range *range =\n\t\t\t\t&smu->thermal_range;\n\tint ret = 0;\n\n\tif (!smu->ppt_funcs->get_thermal_temperature_range)\n\t\treturn 0;\n\n\tret = smu->ppt_funcs->get_thermal_temperature_range(smu, range);\n\tif (ret)\n\t\treturn ret;\n\n\tadev->pm.dpm.thermal.min_temp = range->min;\n\tadev->pm.dpm.thermal.max_temp = range->max;\n\tadev->pm.dpm.thermal.max_edge_emergency_temp = range->edge_emergency_max;\n\tadev->pm.dpm.thermal.min_hotspot_temp = range->hotspot_min;\n\tadev->pm.dpm.thermal.max_hotspot_crit_temp = range->hotspot_crit_max;\n\tadev->pm.dpm.thermal.max_hotspot_emergency_temp = range->hotspot_emergency_max;\n\tadev->pm.dpm.thermal.min_mem_temp = range->mem_min;\n\tadev->pm.dpm.thermal.max_mem_crit_temp = range->mem_crit_max;\n\tadev->pm.dpm.thermal.max_mem_emergency_temp = range->mem_emergency_max;\n\n\treturn ret;\n}\n\nstatic int smu_smc_hw_setup(struct smu_context *smu)\n{\n\tstruct smu_feature *feature = &smu->smu_feature;\n\tstruct amdgpu_device *adev = smu->adev;\n\tuint8_t pcie_gen = 0, pcie_width = 0;\n\tuint64_t features_supported;\n\tint ret = 0;\n\n\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\tcase IP_VERSION(11, 0, 7):\n\tcase IP_VERSION(11, 0, 11):\n\tcase IP_VERSION(11, 5, 0):\n\tcase IP_VERSION(11, 0, 12):\n\t\tif (adev->in_suspend && smu_is_dpm_running(smu)) {\n\t\t\tdev_info(adev->dev, \"dpm has been enabled\\n\");\n\t\t\tret = smu_system_features_control(smu, true);\n\t\t\tif (ret)\n\t\t\t\tdev_err(adev->dev, \"Failed system features control!\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tret = smu_init_display_count(smu, 0);\n\tif (ret) {\n\t\tdev_info(adev->dev, \"Failed to pre-set display count as 0!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_set_driver_table_location(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to SetDriverDramAddr!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = smu_set_tool_table_location(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to SetToolsDramAddr!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = smu_notify_memory_pool_location(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to SetDramLogDramAddr!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tif (!adev->in_runpm) {\n\t\tret = smu_setup_pptable(smu);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"Failed to setup pptable!\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\n\t \n\tif (!adev->scpm_enabled) {\n\t\t \n\t\tret = smu_write_pptable(smu);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"Failed to transfer pptable to SMC!\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tret = smu_run_btc(smu);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (!adev->scpm_enabled) {\n\t\tret = smu_feature_set_allowed_mask(smu);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"Failed to set driver allowed features mask!\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = smu_system_features_control(smu, true);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to enable requested dpm features!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_feature_get_enabled_mask(smu, &features_supported);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to retrieve supported dpm features!\\n\");\n\t\treturn ret;\n\t}\n\tbitmap_copy(feature->supported,\n\t\t    (unsigned long *)&features_supported,\n\t\t    feature->feature_num);\n\n\tif (!smu_is_dpm_running(smu))\n\t\tdev_info(adev->dev, \"dpm has been disabled\\n\");\n\n\t \n\tret = smu_set_default_dpm_table(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to setup default dpm clock tables!\\n\");\n\t\treturn ret;\n\t}\n\n\tif (adev->pm.pcie_gen_mask & CAIL_PCIE_LINK_SPEED_SUPPORT_GEN4)\n\t\tpcie_gen = 3;\n\telse if (adev->pm.pcie_gen_mask & CAIL_PCIE_LINK_SPEED_SUPPORT_GEN3)\n\t\tpcie_gen = 2;\n\telse if (adev->pm.pcie_gen_mask & CAIL_PCIE_LINK_SPEED_SUPPORT_GEN2)\n\t\tpcie_gen = 1;\n\telse if (adev->pm.pcie_gen_mask & CAIL_PCIE_LINK_SPEED_SUPPORT_GEN1)\n\t\tpcie_gen = 0;\n\n\t \n\tif (adev->pm.pcie_mlw_mask & CAIL_PCIE_LINK_WIDTH_SUPPORT_X16)\n\t\tpcie_width = 6;\n\telse if (adev->pm.pcie_mlw_mask & CAIL_PCIE_LINK_WIDTH_SUPPORT_X12)\n\t\tpcie_width = 5;\n\telse if (adev->pm.pcie_mlw_mask & CAIL_PCIE_LINK_WIDTH_SUPPORT_X8)\n\t\tpcie_width = 4;\n\telse if (adev->pm.pcie_mlw_mask & CAIL_PCIE_LINK_WIDTH_SUPPORT_X4)\n\t\tpcie_width = 3;\n\telse if (adev->pm.pcie_mlw_mask & CAIL_PCIE_LINK_WIDTH_SUPPORT_X2)\n\t\tpcie_width = 2;\n\telse if (adev->pm.pcie_mlw_mask & CAIL_PCIE_LINK_WIDTH_SUPPORT_X1)\n\t\tpcie_width = 1;\n\tret = smu_update_pcie_parameters(smu, pcie_gen, pcie_width);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Attempt to override pcie params failed!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_get_thermal_temperature_range(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to get thermal temperature ranges!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_enable_thermal_alert(smu);\n\tif (ret) {\n\t  dev_err(adev->dev, \"Failed to enable thermal alert!\\n\");\n\t  return ret;\n\t}\n\n\tret = smu_notify_display_change(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to notify display change!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = smu_set_min_dcef_deep_sleep(smu,\n\t\t\t\t\t  smu->smu_table.boot_values.dcefclk / 100);\n\n\treturn ret;\n}\n\nstatic int smu_start_smc_engine(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tint ret = 0;\n\n\tif (adev->firmware.load_type != AMDGPU_FW_LOAD_PSP) {\n\t\tif (adev->ip_versions[MP1_HWIP][0] < IP_VERSION(11, 0, 0)) {\n\t\t\tif (smu->ppt_funcs->load_microcode) {\n\t\t\t\tret = smu->ppt_funcs->load_microcode(smu);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (smu->ppt_funcs->check_fw_status) {\n\t\tret = smu->ppt_funcs->check_fw_status(smu);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"SMC is not ready\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tret = smu_check_fw_version(smu);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\n\nstatic int smu_hw_init(void *handle)\n{\n\tint ret;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\tif (amdgpu_sriov_vf(adev) && !amdgpu_sriov_is_pp_one_vf(adev)) {\n\t\tsmu->pm_enabled = false;\n\t\treturn 0;\n\t}\n\n\tret = smu_start_smc_engine(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"SMC engine is not correctly up!\\n\");\n\t\treturn ret;\n\t}\n\n\tif (smu->is_apu) {\n\t\tret = smu_set_gfx_imu_enable(smu);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tsmu_dpm_set_vcn_enable(smu, true);\n\t\tsmu_dpm_set_jpeg_enable(smu, true);\n\t\tsmu_set_gfx_cgpg(smu, true);\n\t}\n\n\tif (!smu->pm_enabled)\n\t\treturn 0;\n\n\tret = smu_get_driver_allowed_feature_mask(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_smc_hw_setup(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to setup smc hw!\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\tret = smu_init_max_sustainable_clocks(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to init max sustainable clocks!\\n\");\n\t\treturn ret;\n\t}\n\n\tadev->pm.dpm_enabled = true;\n\n\tdev_info(adev->dev, \"SMU is initialized successfully!\\n\");\n\n\treturn 0;\n}\n\nstatic int smu_disable_dpms(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tint ret = 0;\n\tbool use_baco = !smu->is_apu &&\n\t\t((amdgpu_in_reset(adev) &&\n\t\t  (amdgpu_asic_reset_method(adev) == AMD_RESET_METHOD_BACO)) ||\n\t\t ((adev->in_runpm || adev->in_s4) && amdgpu_asic_supports_baco(adev)));\n\n\t \n\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\tcase IP_VERSION(13, 0, 0):\n\tcase IP_VERSION(13, 0, 7):\n\tcase IP_VERSION(13, 0, 10):\n\t\treturn 0;\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tif (smu->uploading_custom_pp_table) {\n\t\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\t\tcase IP_VERSION(11, 0, 0):\n\t\tcase IP_VERSION(11, 0, 5):\n\t\tcase IP_VERSION(11, 0, 9):\n\t\tcase IP_VERSION(11, 0, 7):\n\t\tcase IP_VERSION(11, 0, 11):\n\t\tcase IP_VERSION(11, 5, 0):\n\t\tcase IP_VERSION(11, 0, 12):\n\t\tcase IP_VERSION(11, 0, 13):\n\t\t\treturn 0;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (use_baco) {\n\t\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\t\tcase IP_VERSION(11, 0, 7):\n\t\tcase IP_VERSION(11, 0, 0):\n\t\tcase IP_VERSION(11, 0, 5):\n\t\tcase IP_VERSION(11, 0, 9):\n\t\tcase IP_VERSION(13, 0, 7):\n\t\t\treturn 0;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (amdgpu_in_reset(adev) || adev->in_s0ix) {\n\t\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\t\tcase IP_VERSION(13, 0, 4):\n\t\tcase IP_VERSION(13, 0, 11):\n\t\t\treturn 0;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (use_baco && smu_feature_is_enabled(smu, SMU_FEATURE_BACO_BIT)) {\n\t\tret = smu_disable_all_features_with_exception(smu,\n\t\t\t\t\t\t\t      SMU_FEATURE_BACO_BIT);\n\t\tif (ret)\n\t\t\tdev_err(adev->dev, \"Failed to disable smu features except BACO.\\n\");\n\t} else {\n\t\t \n\t\tif (!adev->scpm_enabled) {\n\t\t\tret = smu_system_features_control(smu, false);\n\t\t\tif (ret)\n\t\t\t\tdev_err(adev->dev, \"Failed to disable smu features.\\n\");\n\t\t}\n\t}\n\n\tif (adev->ip_versions[GC_HWIP][0] >= IP_VERSION(9, 4, 2) &&\n\t    !amdgpu_sriov_vf(adev) && adev->gfx.rlc.funcs->stop)\n\t\tadev->gfx.rlc.funcs->stop(adev);\n\n\treturn ret;\n}\n\nstatic int smu_smc_hw_cleanup(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tint ret = 0;\n\n\tcancel_work_sync(&smu->throttling_logging_work);\n\tcancel_work_sync(&smu->interrupt_work);\n\n\tret = smu_disable_thermal_alert(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Fail to disable thermal alert!\\n\");\n\t\treturn ret;\n\t}\n\n\tcancel_delayed_work_sync(&smu->swctf_delayed_work);\n\n\tret = smu_disable_dpms(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Fail to disable dpm features!\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int smu_hw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\tif (amdgpu_sriov_vf(adev) && !amdgpu_sriov_is_pp_one_vf(adev))\n\t\treturn 0;\n\n\tsmu_dpm_set_vcn_enable(smu, false);\n\tsmu_dpm_set_jpeg_enable(smu, false);\n\n\tadev->vcn.cur_state = AMD_PG_STATE_GATE;\n\tadev->jpeg.cur_state = AMD_PG_STATE_GATE;\n\n\tif (!smu->pm_enabled)\n\t\treturn 0;\n\n\tadev->pm.dpm_enabled = false;\n\n\treturn smu_smc_hw_cleanup(smu);\n}\n\nstatic void smu_late_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\tkfree(smu);\n}\n\nstatic int smu_reset(struct smu_context *smu)\n{\n\tstruct amdgpu_device *adev = smu->adev;\n\tint ret;\n\n\tret = smu_hw_fini(adev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_hw_init(adev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_late_init(adev);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int smu_suspend(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\tint ret;\n\tuint64_t count;\n\n\tif (amdgpu_sriov_vf(adev) && !amdgpu_sriov_is_pp_one_vf(adev))\n\t\treturn 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn 0;\n\n\tadev->pm.dpm_enabled = false;\n\n\tret = smu_smc_hw_cleanup(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tsmu->watermarks_bitmap &= ~(WATERMARKS_LOADED);\n\n\tsmu_set_gfx_cgpg(smu, false);\n\n\t \n\tret = smu_get_entrycount_gfxoff(smu, &count);\n\tif (!ret)\n\t\tadev->gfx.gfx_off_entrycount = count;\n\n\treturn 0;\n}\n\nstatic int smu_resume(void *handle)\n{\n\tint ret;\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\tif (amdgpu_sriov_vf(adev)&& !amdgpu_sriov_is_pp_one_vf(adev))\n\t\treturn 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn 0;\n\n\tdev_info(adev->dev, \"SMU is resuming...\\n\");\n\n\tret = smu_start_smc_engine(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"SMC engine is not correctly up!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_smc_hw_setup(smu);\n\tif (ret) {\n\t\tdev_err(adev->dev, \"Failed to setup smc hw!\\n\");\n\t\treturn ret;\n\t}\n\n\tret = smu_set_gfx_imu_enable(smu);\n\tif (ret)\n\t\treturn ret;\n\n\tsmu_set_gfx_cgpg(smu, true);\n\n\tsmu->disable_uclk_switch = 0;\n\n\tadev->pm.dpm_enabled = true;\n\n\tdev_info(adev->dev, \"SMU is resumed successfully!\\n\");\n\n\treturn 0;\n}\n\nstatic int smu_display_configuration_change(void *handle,\n\t\t\t\t\t    const struct amd_pp_display_configuration *display_config)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!display_config)\n\t\treturn -EINVAL;\n\n\tsmu_set_min_dcef_deep_sleep(smu,\n\t\t\t\t    display_config->min_dcef_deep_sleep_set_clk / 100);\n\n\treturn 0;\n}\n\nstatic int smu_set_clockgating_state(void *handle,\n\t\t\t\t     enum amd_clockgating_state state)\n{\n\treturn 0;\n}\n\nstatic int smu_set_powergating_state(void *handle,\n\t\t\t\t     enum amd_powergating_state state)\n{\n\treturn 0;\n}\n\nstatic int smu_enable_umd_pstate(void *handle,\n\t\t      enum amd_dpm_forced_level *level)\n{\n\tuint32_t profile_mode_mask = AMD_DPM_FORCED_LEVEL_PROFILE_STANDARD |\n\t\t\t\t\tAMD_DPM_FORCED_LEVEL_PROFILE_MIN_SCLK |\n\t\t\t\t\tAMD_DPM_FORCED_LEVEL_PROFILE_MIN_MCLK |\n\t\t\t\t\tAMD_DPM_FORCED_LEVEL_PROFILE_PEAK;\n\n\tstruct smu_context *smu = (struct smu_context*)(handle);\n\tstruct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);\n\n\tif (!smu->is_apu && !smu_dpm_ctx->dpm_context)\n\t\treturn -EINVAL;\n\n\tif (!(smu_dpm_ctx->dpm_level & profile_mode_mask)) {\n\t\t \n\t\tif (*level & profile_mode_mask) {\n\t\t\tsmu_dpm_ctx->saved_dpm_level = smu_dpm_ctx->dpm_level;\n\t\t\tsmu_gpo_control(smu, false);\n\t\t\tsmu_gfx_ulv_control(smu, false);\n\t\t\tsmu_deep_sleep_control(smu, false);\n\t\t\tamdgpu_asic_update_umd_stable_pstate(smu->adev, true);\n\t\t}\n\t} else {\n\t\t \n\t\tif (!(*level & profile_mode_mask)) {\n\t\t\tif (*level == AMD_DPM_FORCED_LEVEL_PROFILE_EXIT)\n\t\t\t\t*level = smu_dpm_ctx->saved_dpm_level;\n\t\t\tamdgpu_asic_update_umd_stable_pstate(smu->adev, false);\n\t\t\tsmu_deep_sleep_control(smu, true);\n\t\t\tsmu_gfx_ulv_control(smu, true);\n\t\t\tsmu_gpo_control(smu, true);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int smu_bump_power_profile_mode(struct smu_context *smu,\n\t\t\t\t\t   long *param,\n\t\t\t\t\t   uint32_t param_size)\n{\n\tint ret = 0;\n\n\tif (smu->ppt_funcs->set_power_profile_mode)\n\t\tret = smu->ppt_funcs->set_power_profile_mode(smu, param, param_size);\n\n\treturn ret;\n}\n\nstatic int smu_adjust_power_state_dynamic(struct smu_context *smu,\n\t\t\t\t   enum amd_dpm_forced_level level,\n\t\t\t\t   bool skip_display_settings)\n{\n\tint ret = 0;\n\tint index = 0;\n\tlong workload;\n\tstruct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);\n\n\tif (!skip_display_settings) {\n\t\tret = smu_display_config_changed(smu);\n\t\tif (ret) {\n\t\t\tdev_err(smu->adev->dev, \"Failed to change display config!\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tret = smu_apply_clocks_adjust_rules(smu);\n\tif (ret) {\n\t\tdev_err(smu->adev->dev, \"Failed to apply clocks adjust rules!\");\n\t\treturn ret;\n\t}\n\n\tif (!skip_display_settings) {\n\t\tret = smu_notify_smc_display_config(smu);\n\t\tif (ret) {\n\t\t\tdev_err(smu->adev->dev, \"Failed to notify smc display config!\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (smu_dpm_ctx->dpm_level != level) {\n\t\tret = smu_asic_set_performance_level(smu, level);\n\t\tif (ret) {\n\t\t\tdev_err(smu->adev->dev, \"Failed to set performance level!\");\n\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tsmu_dpm_ctx->dpm_level = level;\n\t}\n\n\tif (smu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL &&\n\t\tsmu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_PERF_DETERMINISM) {\n\t\tindex = fls(smu->workload_mask);\n\t\tindex = index > 0 && index <= WORKLOAD_POLICY_MAX ? index - 1 : 0;\n\t\tworkload = smu->workload_setting[index];\n\n\t\tif (smu->power_profile_mode != workload)\n\t\t\tsmu_bump_power_profile_mode(smu, &workload, 0);\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_handle_task(struct smu_context *smu,\n\t\t\t   enum amd_dpm_forced_level level,\n\t\t\t   enum amd_pp_task task_id)\n{\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (task_id) {\n\tcase AMD_PP_TASK_DISPLAY_CONFIG_CHANGE:\n\t\tret = smu_pre_display_config_changed(smu);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = smu_adjust_power_state_dynamic(smu, level, false);\n\t\tbreak;\n\tcase AMD_PP_TASK_COMPLETE_INIT:\n\tcase AMD_PP_TASK_READJUST_POWER_STATE:\n\t\tret = smu_adjust_power_state_dynamic(smu, level, true);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_handle_dpm_task(void *handle,\n\t\t\t       enum amd_pp_task task_id,\n\t\t\t       enum amd_pm_state_type *user_state)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_dpm_context *smu_dpm = &smu->smu_dpm;\n\n\treturn smu_handle_task(smu, smu_dpm->dpm_level, task_id);\n\n}\n\nstatic int smu_switch_power_profile(void *handle,\n\t\t\t\t    enum PP_SMC_POWER_PROFILE type,\n\t\t\t\t    bool en)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);\n\tlong workload;\n\tuint32_t index;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!(type < PP_SMC_POWER_PROFILE_CUSTOM))\n\t\treturn -EINVAL;\n\n\tif (!en) {\n\t\tsmu->workload_mask &= ~(1 << smu->workload_prority[type]);\n\t\tindex = fls(smu->workload_mask);\n\t\tindex = index > 0 && index <= WORKLOAD_POLICY_MAX ? index - 1 : 0;\n\t\tworkload = smu->workload_setting[index];\n\t} else {\n\t\tsmu->workload_mask |= (1 << smu->workload_prority[type]);\n\t\tindex = fls(smu->workload_mask);\n\t\tindex = index <= WORKLOAD_POLICY_MAX ? index - 1 : 0;\n\t\tworkload = smu->workload_setting[index];\n\t}\n\n\tif (smu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL &&\n\t\tsmu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_PERF_DETERMINISM)\n\t\tsmu_bump_power_profile_mode(smu, &workload, 0);\n\n\treturn 0;\n}\n\nstatic enum amd_dpm_forced_level smu_get_performance_level(void *handle)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->is_apu && !smu_dpm_ctx->dpm_context)\n\t\treturn -EINVAL;\n\n\treturn smu_dpm_ctx->dpm_level;\n}\n\nstatic int smu_force_performance_level(void *handle,\n\t\t\t\t       enum amd_dpm_forced_level level)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->is_apu && !smu_dpm_ctx->dpm_context)\n\t\treturn -EINVAL;\n\n\tret = smu_enable_umd_pstate(smu, &level);\n\tif (ret)\n\t\treturn ret;\n\n\tret = smu_handle_task(smu, level,\n\t\t\t      AMD_PP_TASK_READJUST_POWER_STATE);\n\n\t \n\tif (!ret && smu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL) {\n\t\tmemset(smu->user_dpm_profile.clk_mask, 0, sizeof(smu->user_dpm_profile.clk_mask));\n\t\tsmu->user_dpm_profile.clk_dependency = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_set_display_count(void *handle, uint32_t count)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\treturn smu_init_display_count(smu, count);\n}\n\nstatic int smu_force_smuclk_levels(struct smu_context *smu,\n\t\t\t enum smu_clk_type clk_type,\n\t\t\t uint32_t mask)\n{\n\tstruct smu_dpm_context *smu_dpm_ctx = &(smu->smu_dpm);\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu_dpm_ctx->dpm_level != AMD_DPM_FORCED_LEVEL_MANUAL) {\n\t\tdev_dbg(smu->adev->dev, \"force clock level is for dpm manual mode only.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->force_clk_levels) {\n\t\tret = smu->ppt_funcs->force_clk_levels(smu, clk_type, mask);\n\t\tif (!ret && !(smu->user_dpm_profile.flags & SMU_DPM_USER_PROFILE_RESTORE)) {\n\t\t\tsmu->user_dpm_profile.clk_mask[clk_type] = mask;\n\t\t\tsmu_set_user_clk_dependencies(smu, clk_type);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_force_ppclk_levels(void *handle,\n\t\t\t\t  enum pp_clock_type type,\n\t\t\t\t  uint32_t mask)\n{\n\tstruct smu_context *smu = handle;\n\tenum smu_clk_type clk_type;\n\n\tswitch (type) {\n\tcase PP_SCLK:\n\t\tclk_type = SMU_SCLK; break;\n\tcase PP_MCLK:\n\t\tclk_type = SMU_MCLK; break;\n\tcase PP_PCIE:\n\t\tclk_type = SMU_PCIE; break;\n\tcase PP_SOCCLK:\n\t\tclk_type = SMU_SOCCLK; break;\n\tcase PP_FCLK:\n\t\tclk_type = SMU_FCLK; break;\n\tcase PP_DCEFCLK:\n\t\tclk_type = SMU_DCEFCLK; break;\n\tcase PP_VCLK:\n\t\tclk_type = SMU_VCLK; break;\n\tcase PP_VCLK1:\n\t\tclk_type = SMU_VCLK1; break;\n\tcase PP_DCLK:\n\t\tclk_type = SMU_DCLK; break;\n\tcase PP_DCLK1:\n\t\tclk_type = SMU_DCLK1; break;\n\tcase OD_SCLK:\n\t\tclk_type = SMU_OD_SCLK; break;\n\tcase OD_MCLK:\n\t\tclk_type = SMU_OD_MCLK; break;\n\tcase OD_VDDC_CURVE:\n\t\tclk_type = SMU_OD_VDDC_CURVE; break;\n\tcase OD_RANGE:\n\t\tclk_type = SMU_OD_RANGE; break;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn smu_force_smuclk_levels(smu, clk_type, mask);\n}\n\n \nstatic int smu_set_mp1_state(void *handle,\n\t\t\t     enum pp_mp1_state mp1_state)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs &&\n\t    smu->ppt_funcs->set_mp1_state)\n\t\tret = smu->ppt_funcs->set_mp1_state(smu, mp1_state);\n\n\treturn ret;\n}\n\nstatic int smu_set_df_cstate(void *handle,\n\t\t\t     enum pp_df_cstate state)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs || !smu->ppt_funcs->set_df_cstate)\n\t\treturn 0;\n\n\tret = smu->ppt_funcs->set_df_cstate(smu, state);\n\tif (ret)\n\t\tdev_err(smu->adev->dev, \"[SetDfCstate] failed!\\n\");\n\n\treturn ret;\n}\n\nint smu_allow_xgmi_power_down(struct smu_context *smu, bool en)\n{\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs || !smu->ppt_funcs->allow_xgmi_power_down)\n\t\treturn 0;\n\n\tret = smu->ppt_funcs->allow_xgmi_power_down(smu, en);\n\tif (ret)\n\t\tdev_err(smu->adev->dev, \"[AllowXgmiPowerDown] failed!\\n\");\n\n\treturn ret;\n}\n\nint smu_write_watermarks_table(struct smu_context *smu)\n{\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\treturn smu_set_watermarks_table(smu, NULL);\n}\n\nstatic int smu_set_watermarks_for_clock_ranges(void *handle,\n\t\t\t\t\t       struct pp_smu_wm_range_sets *clock_ranges)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->disable_watermark)\n\t\treturn 0;\n\n\treturn smu_set_watermarks_table(smu, clock_ranges);\n}\n\nint smu_set_ac_dc(struct smu_context *smu)\n{\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (smu->dc_controlled_by_gpio)\n\t\treturn 0;\n\n\tret = smu_set_power_source(smu,\n\t\t\t\t   smu->adev->pm.ac_power ? SMU_POWER_SOURCE_AC :\n\t\t\t\t   SMU_POWER_SOURCE_DC);\n\tif (ret)\n\t\tdev_err(smu->adev->dev, \"Failed to switch to %s mode!\\n\",\n\t\t       smu->adev->pm.ac_power ? \"AC\" : \"DC\");\n\n\treturn ret;\n}\n\nconst struct amd_ip_funcs smu_ip_funcs = {\n\t.name = \"smu\",\n\t.early_init = smu_early_init,\n\t.late_init = smu_late_init,\n\t.sw_init = smu_sw_init,\n\t.sw_fini = smu_sw_fini,\n\t.hw_init = smu_hw_init,\n\t.hw_fini = smu_hw_fini,\n\t.late_fini = smu_late_fini,\n\t.suspend = smu_suspend,\n\t.resume = smu_resume,\n\t.is_idle = NULL,\n\t.check_soft_reset = NULL,\n\t.wait_for_idle = NULL,\n\t.soft_reset = NULL,\n\t.set_clockgating_state = smu_set_clockgating_state,\n\t.set_powergating_state = smu_set_powergating_state,\n};\n\nconst struct amdgpu_ip_block_version smu_v11_0_ip_block = {\n\t.type = AMD_IP_BLOCK_TYPE_SMC,\n\t.major = 11,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &smu_ip_funcs,\n};\n\nconst struct amdgpu_ip_block_version smu_v12_0_ip_block = {\n\t.type = AMD_IP_BLOCK_TYPE_SMC,\n\t.major = 12,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &smu_ip_funcs,\n};\n\nconst struct amdgpu_ip_block_version smu_v13_0_ip_block = {\n\t.type = AMD_IP_BLOCK_TYPE_SMC,\n\t.major = 13,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &smu_ip_funcs,\n};\n\nstatic int smu_load_microcode(void *handle)\n{\n\tstruct smu_context *smu = handle;\n\tstruct amdgpu_device *adev = smu->adev;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (adev->firmware.load_type == AMDGPU_FW_LOAD_PSP)\n\t\treturn 0;\n\n\tif (smu->ppt_funcs->load_microcode) {\n\t\tret = smu->ppt_funcs->load_microcode(smu);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"Load microcode failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (smu->ppt_funcs->check_fw_status) {\n\t\tret = smu->ppt_funcs->check_fw_status(smu);\n\t\tif (ret) {\n\t\t\tdev_err(adev->dev, \"SMC is not ready\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_set_gfx_cgpg(struct smu_context *smu, bool enabled)\n{\n\tint ret = 0;\n\n\tif (smu->ppt_funcs->set_gfx_cgpg)\n\t\tret = smu->ppt_funcs->set_gfx_cgpg(smu, enabled);\n\n\treturn ret;\n}\n\nstatic int smu_set_fan_speed_rpm(void *handle, uint32_t speed)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->set_fan_speed_rpm)\n\t\treturn -EOPNOTSUPP;\n\n\tif (speed == U32_MAX)\n\t\treturn -EINVAL;\n\n\tret = smu->ppt_funcs->set_fan_speed_rpm(smu, speed);\n\tif (!ret && !(smu->user_dpm_profile.flags & SMU_DPM_USER_PROFILE_RESTORE)) {\n\t\tsmu->user_dpm_profile.flags |= SMU_CUSTOM_FAN_SPEED_RPM;\n\t\tsmu->user_dpm_profile.fan_speed_rpm = speed;\n\n\t\t \n\t\tsmu->user_dpm_profile.flags &= ~SMU_CUSTOM_FAN_SPEED_PWM;\n\t\tsmu->user_dpm_profile.fan_speed_pwm = 0;\n\t}\n\n\treturn ret;\n}\n\n \nint smu_get_power_limit(void *handle,\n\t\t\tuint32_t *limit,\n\t\t\tenum pp_power_limit_level pp_limit_level,\n\t\t\tenum pp_power_type pp_power_type)\n{\n\tstruct smu_context *smu = handle;\n\tstruct amdgpu_device *adev = smu->adev;\n\tenum smu_ppt_limit_level limit_level;\n\tuint32_t limit_type;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tswitch (pp_power_type) {\n\tcase PP_PWR_TYPE_SUSTAINED:\n\t\tlimit_type = SMU_DEFAULT_PPT_LIMIT;\n\t\tbreak;\n\tcase PP_PWR_TYPE_FAST:\n\t\tlimit_type = SMU_FAST_PPT_LIMIT;\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\n\tswitch (pp_limit_level) {\n\tcase PP_PWR_LIMIT_CURRENT:\n\t\tlimit_level = SMU_PPT_LIMIT_CURRENT;\n\t\tbreak;\n\tcase PP_PWR_LIMIT_DEFAULT:\n\t\tlimit_level = SMU_PPT_LIMIT_DEFAULT;\n\t\tbreak;\n\tcase PP_PWR_LIMIT_MAX:\n\t\tlimit_level = SMU_PPT_LIMIT_MAX;\n\t\tbreak;\n\tcase PP_PWR_LIMIT_MIN:\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\n\tif (limit_type != SMU_DEFAULT_PPT_LIMIT) {\n\t\tif (smu->ppt_funcs->get_ppt_limit)\n\t\t\tret = smu->ppt_funcs->get_ppt_limit(smu, limit, limit_type, limit_level);\n\t} else {\n\t\tswitch (limit_level) {\n\t\tcase SMU_PPT_LIMIT_CURRENT:\n\t\t\tswitch (adev->ip_versions[MP1_HWIP][0]) {\n\t\t\tcase IP_VERSION(13, 0, 2):\n\t\t\tcase IP_VERSION(11, 0, 7):\n\t\t\tcase IP_VERSION(11, 0, 11):\n\t\t\tcase IP_VERSION(11, 0, 12):\n\t\t\tcase IP_VERSION(11, 0, 13):\n\t\t\t\tret = smu_get_asic_power_limits(smu,\n\t\t\t\t\t\t\t\t&smu->current_power_limit,\n\t\t\t\t\t\t\t\tNULL,\n\t\t\t\t\t\t\t\tNULL);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t*limit = smu->current_power_limit;\n\t\t\tbreak;\n\t\tcase SMU_PPT_LIMIT_DEFAULT:\n\t\t\t*limit = smu->default_power_limit;\n\t\t\tbreak;\n\t\tcase SMU_PPT_LIMIT_MAX:\n\t\t\t*limit = smu->max_power_limit;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_set_power_limit(void *handle, uint32_t limit)\n{\n\tstruct smu_context *smu = handle;\n\tuint32_t limit_type = limit >> 24;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tlimit &= (1<<24)-1;\n\tif (limit_type != SMU_DEFAULT_PPT_LIMIT)\n\t\tif (smu->ppt_funcs->set_power_limit)\n\t\t\treturn smu->ppt_funcs->set_power_limit(smu, limit_type, limit);\n\n\tif (limit > smu->max_power_limit) {\n\t\tdev_err(smu->adev->dev,\n\t\t\t\"New power limit (%d) is over the max allowed %d\\n\",\n\t\t\tlimit, smu->max_power_limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!limit)\n\t\tlimit = smu->current_power_limit;\n\n\tif (smu->ppt_funcs->set_power_limit) {\n\t\tret = smu->ppt_funcs->set_power_limit(smu, limit_type, limit);\n\t\tif (!ret && !(smu->user_dpm_profile.flags & SMU_DPM_USER_PROFILE_RESTORE))\n\t\t\tsmu->user_dpm_profile.power_limit = limit;\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_print_smuclk_levels(struct smu_context *smu, enum smu_clk_type clk_type, char *buf)\n{\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->print_clk_levels)\n\t\tret = smu->ppt_funcs->print_clk_levels(smu, clk_type, buf);\n\n\treturn ret;\n}\n\nstatic enum smu_clk_type smu_convert_to_smuclk(enum pp_clock_type type)\n{\n\tenum smu_clk_type clk_type;\n\n\tswitch (type) {\n\tcase PP_SCLK:\n\t\tclk_type = SMU_SCLK; break;\n\tcase PP_MCLK:\n\t\tclk_type = SMU_MCLK; break;\n\tcase PP_PCIE:\n\t\tclk_type = SMU_PCIE; break;\n\tcase PP_SOCCLK:\n\t\tclk_type = SMU_SOCCLK; break;\n\tcase PP_FCLK:\n\t\tclk_type = SMU_FCLK; break;\n\tcase PP_DCEFCLK:\n\t\tclk_type = SMU_DCEFCLK; break;\n\tcase PP_VCLK:\n\t\tclk_type = SMU_VCLK; break;\n\tcase PP_VCLK1:\n\t\tclk_type = SMU_VCLK1; break;\n\tcase PP_DCLK:\n\t\tclk_type = SMU_DCLK; break;\n\tcase PP_DCLK1:\n\t\tclk_type = SMU_DCLK1; break;\n\tcase OD_SCLK:\n\t\tclk_type = SMU_OD_SCLK; break;\n\tcase OD_MCLK:\n\t\tclk_type = SMU_OD_MCLK; break;\n\tcase OD_VDDC_CURVE:\n\t\tclk_type = SMU_OD_VDDC_CURVE; break;\n\tcase OD_RANGE:\n\t\tclk_type = SMU_OD_RANGE; break;\n\tcase OD_VDDGFX_OFFSET:\n\t\tclk_type = SMU_OD_VDDGFX_OFFSET; break;\n\tcase OD_CCLK:\n\t\tclk_type = SMU_OD_CCLK; break;\n\tdefault:\n\t\tclk_type = SMU_CLK_COUNT; break;\n\t}\n\n\treturn clk_type;\n}\n\nstatic int smu_print_ppclk_levels(void *handle,\n\t\t\t\t  enum pp_clock_type type,\n\t\t\t\t  char *buf)\n{\n\tstruct smu_context *smu = handle;\n\tenum smu_clk_type clk_type;\n\n\tclk_type = smu_convert_to_smuclk(type);\n\tif (clk_type == SMU_CLK_COUNT)\n\t\treturn -EINVAL;\n\n\treturn smu_print_smuclk_levels(smu, clk_type, buf);\n}\n\nstatic int smu_emit_ppclk_levels(void *handle, enum pp_clock_type type, char *buf, int *offset)\n{\n\tstruct smu_context *smu = handle;\n\tenum smu_clk_type clk_type;\n\n\tclk_type = smu_convert_to_smuclk(type);\n\tif (clk_type == SMU_CLK_COUNT)\n\t\treturn -EINVAL;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->emit_clk_levels)\n\t\treturn -ENOENT;\n\n\treturn smu->ppt_funcs->emit_clk_levels(smu, clk_type, buf, offset);\n\n}\n\nstatic int smu_od_edit_dpm_table(void *handle,\n\t\t\t\t enum PP_OD_DPM_TABLE_COMMAND type,\n\t\t\t\t long *input, uint32_t size)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->od_edit_dpm_table) {\n\t\tret = smu->ppt_funcs->od_edit_dpm_table(smu, type, input, size);\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_read_sensor(void *handle,\n\t\t\t   int sensor,\n\t\t\t   void *data,\n\t\t\t   int *size_arg)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_umd_pstate_table *pstate_table =\n\t\t\t\t&smu->pstate_table;\n\tint ret = 0;\n\tuint32_t *size, size_val;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!data || !size_arg)\n\t\treturn -EINVAL;\n\n\tsize_val = *size_arg;\n\tsize = &size_val;\n\n\tif (smu->ppt_funcs->read_sensor)\n\t\tif (!smu->ppt_funcs->read_sensor(smu, sensor, data, size))\n\t\t\tgoto unlock;\n\n\tswitch (sensor) {\n\tcase AMDGPU_PP_SENSOR_STABLE_PSTATE_SCLK:\n\t\t*((uint32_t *)data) = pstate_table->gfxclk_pstate.standard * 100;\n\t\t*size = 4;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_STABLE_PSTATE_MCLK:\n\t\t*((uint32_t *)data) = pstate_table->uclk_pstate.standard * 100;\n\t\t*size = 4;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_PEAK_PSTATE_SCLK:\n\t\t*((uint32_t *)data) = pstate_table->gfxclk_pstate.peak * 100;\n\t\t*size = 4;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_PEAK_PSTATE_MCLK:\n\t\t*((uint32_t *)data) = pstate_table->uclk_pstate.peak * 100;\n\t\t*size = 4;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_ENABLED_SMC_FEATURES_MASK:\n\t\tret = smu_feature_get_enabled_mask(smu, (uint64_t *)data);\n\t\t*size = 8;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_UVD_POWER:\n\t\t*(uint32_t *)data = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_UVD_BIT) ? 1 : 0;\n\t\t*size = 4;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_VCE_POWER:\n\t\t*(uint32_t *)data = smu_feature_is_enabled(smu, SMU_FEATURE_DPM_VCE_BIT) ? 1 : 0;\n\t\t*size = 4;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_VCN_POWER_STATE:\n\t\t*(uint32_t *)data = atomic_read(&smu->smu_power.power_gate.vcn_gated) ? 0 : 1;\n\t\t*size = 4;\n\t\tbreak;\n\tcase AMDGPU_PP_SENSOR_MIN_FAN_RPM:\n\t\t*(uint32_t *)data = 0;\n\t\t*size = 4;\n\t\tbreak;\n\tdefault:\n\t\t*size = 0;\n\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\nunlock:\n\t\n\t*size_arg = size_val;\n\n\treturn ret;\n}\n\nstatic int smu_get_apu_thermal_limit(void *handle, uint32_t *limit)\n{\n\tint ret = -EINVAL;\n\tstruct smu_context *smu = handle;\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->get_apu_thermal_limit)\n\t\tret = smu->ppt_funcs->get_apu_thermal_limit(smu, limit);\n\n\treturn ret;\n}\n\nstatic int smu_set_apu_thermal_limit(void *handle, uint32_t limit)\n{\n\tint ret = -EINVAL;\n\tstruct smu_context *smu = handle;\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->set_apu_thermal_limit)\n\t\tret = smu->ppt_funcs->set_apu_thermal_limit(smu, limit);\n\n\treturn ret;\n}\n\nstatic int smu_get_power_profile_mode(void *handle, char *buf)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled ||\n\t    !smu->ppt_funcs->get_power_profile_mode)\n\t\treturn -EOPNOTSUPP;\n\tif (!buf)\n\t\treturn -EINVAL;\n\n\treturn smu->ppt_funcs->get_power_profile_mode(smu, buf);\n}\n\nstatic int smu_set_power_profile_mode(void *handle,\n\t\t\t\t      long *param,\n\t\t\t\t      uint32_t param_size)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled ||\n\t    !smu->ppt_funcs->set_power_profile_mode)\n\t\treturn -EOPNOTSUPP;\n\n\treturn smu_bump_power_profile_mode(smu, param, param_size);\n}\n\nstatic int smu_get_fan_control_mode(void *handle, u32 *fan_mode)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->get_fan_control_mode)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!fan_mode)\n\t\treturn -EINVAL;\n\n\t*fan_mode = smu->ppt_funcs->get_fan_control_mode(smu);\n\n\treturn 0;\n}\n\nstatic int smu_set_fan_control_mode(void *handle, u32 value)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->set_fan_control_mode)\n\t\treturn -EOPNOTSUPP;\n\n\tif (value == U32_MAX)\n\t\treturn -EINVAL;\n\n\tret = smu->ppt_funcs->set_fan_control_mode(smu, value);\n\tif (ret)\n\t\tgoto out;\n\n\tif (!(smu->user_dpm_profile.flags & SMU_DPM_USER_PROFILE_RESTORE)) {\n\t\tsmu->user_dpm_profile.fan_mode = value;\n\n\t\t \n\t\tif (value != AMD_FAN_CTRL_MANUAL) {\n\t\t\tsmu->user_dpm_profile.fan_speed_pwm = 0;\n\t\t\tsmu->user_dpm_profile.fan_speed_rpm = 0;\n\t\t\tsmu->user_dpm_profile.flags &= ~(SMU_CUSTOM_FAN_SPEED_RPM | SMU_CUSTOM_FAN_SPEED_PWM);\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}\n\nstatic int smu_get_fan_speed_pwm(void *handle, u32 *speed)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->get_fan_speed_pwm)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!speed)\n\t\treturn -EINVAL;\n\n\tret = smu->ppt_funcs->get_fan_speed_pwm(smu, speed);\n\n\treturn ret;\n}\n\nstatic int smu_set_fan_speed_pwm(void *handle, u32 speed)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->set_fan_speed_pwm)\n\t\treturn -EOPNOTSUPP;\n\n\tif (speed == U32_MAX)\n\t\treturn -EINVAL;\n\n\tret = smu->ppt_funcs->set_fan_speed_pwm(smu, speed);\n\tif (!ret && !(smu->user_dpm_profile.flags & SMU_DPM_USER_PROFILE_RESTORE)) {\n\t\tsmu->user_dpm_profile.flags |= SMU_CUSTOM_FAN_SPEED_PWM;\n\t\tsmu->user_dpm_profile.fan_speed_pwm = speed;\n\n\t\t \n\t\tsmu->user_dpm_profile.flags &= ~SMU_CUSTOM_FAN_SPEED_RPM;\n\t\tsmu->user_dpm_profile.fan_speed_rpm = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_get_fan_speed_rpm(void *handle, uint32_t *speed)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->get_fan_speed_rpm)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!speed)\n\t\treturn -EINVAL;\n\n\tret = smu->ppt_funcs->get_fan_speed_rpm(smu, speed);\n\n\treturn ret;\n}\n\nstatic int smu_set_deep_sleep_dcefclk(void *handle, uint32_t clk)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\treturn smu_set_min_dcef_deep_sleep(smu, clk);\n}\n\nstatic int smu_get_clock_by_type_with_latency(void *handle,\n\t\t\t\t\t      enum amd_pp_clock_type type,\n\t\t\t\t\t      struct pp_clock_levels_with_latency *clocks)\n{\n\tstruct smu_context *smu = handle;\n\tenum smu_clk_type clk_type;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->get_clock_by_type_with_latency) {\n\t\tswitch (type) {\n\t\tcase amd_pp_sys_clock:\n\t\t\tclk_type = SMU_GFXCLK;\n\t\t\tbreak;\n\t\tcase amd_pp_mem_clock:\n\t\t\tclk_type = SMU_MCLK;\n\t\t\tbreak;\n\t\tcase amd_pp_dcef_clock:\n\t\t\tclk_type = SMU_DCEFCLK;\n\t\t\tbreak;\n\t\tcase amd_pp_disp_clock:\n\t\t\tclk_type = SMU_DISPCLK;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(smu->adev->dev, \"Invalid clock type!\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = smu->ppt_funcs->get_clock_by_type_with_latency(smu, clk_type, clocks);\n\t}\n\n\treturn ret;\n}\n\nstatic int smu_display_clock_voltage_request(void *handle,\n\t\t\t\t\t     struct pp_display_clock_request *clock_req)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->display_clock_voltage_request)\n\t\tret = smu->ppt_funcs->display_clock_voltage_request(smu, clock_req);\n\n\treturn ret;\n}\n\n\nstatic int smu_display_disable_memory_clock_switch(void *handle,\n\t\t\t\t\t\t   bool disable_memory_clock_switch)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = -EINVAL;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->display_disable_memory_clock_switch)\n\t\tret = smu->ppt_funcs->display_disable_memory_clock_switch(smu, disable_memory_clock_switch);\n\n\treturn ret;\n}\n\nstatic int smu_set_xgmi_pstate(void *handle,\n\t\t\t       uint32_t pstate)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->set_xgmi_pstate)\n\t\tret = smu->ppt_funcs->set_xgmi_pstate(smu, pstate);\n\n\tif (ret)\n\t\tdev_err(smu->adev->dev, \"Failed to set XGMI pstate!\\n\");\n\n\treturn ret;\n}\n\nstatic int smu_get_baco_capability(void *handle, bool *cap)\n{\n\tstruct smu_context *smu = handle;\n\n\t*cap = false;\n\n\tif (!smu->pm_enabled)\n\t\treturn 0;\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->baco_is_support)\n\t\t*cap = smu->ppt_funcs->baco_is_support(smu);\n\n\treturn 0;\n}\n\nstatic int smu_baco_set_state(void *handle, int state)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (state == 0) {\n\t\tif (smu->ppt_funcs->baco_exit)\n\t\t\tret = smu->ppt_funcs->baco_exit(smu);\n\t} else if (state == 1) {\n\t\tif (smu->ppt_funcs->baco_enter)\n\t\t\tret = smu->ppt_funcs->baco_enter(smu);\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\tif (ret)\n\t\tdev_err(smu->adev->dev, \"Failed to %s BACO state!\\n\",\n\t\t\t\t(state)?\"enter\":\"exit\");\n\n\treturn ret;\n}\n\nbool smu_mode1_reset_is_support(struct smu_context *smu)\n{\n\tbool ret = false;\n\n\tif (!smu->pm_enabled)\n\t\treturn false;\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->mode1_reset_is_support)\n\t\tret = smu->ppt_funcs->mode1_reset_is_support(smu);\n\n\treturn ret;\n}\n\nbool smu_mode2_reset_is_support(struct smu_context *smu)\n{\n\tbool ret = false;\n\n\tif (!smu->pm_enabled)\n\t\treturn false;\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->mode2_reset_is_support)\n\t\tret = smu->ppt_funcs->mode2_reset_is_support(smu);\n\n\treturn ret;\n}\n\nint smu_mode1_reset(struct smu_context *smu)\n{\n\tint ret = 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->mode1_reset)\n\t\tret = smu->ppt_funcs->mode1_reset(smu);\n\n\treturn ret;\n}\n\nstatic int smu_mode2_reset(void *handle)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->mode2_reset)\n\t\tret = smu->ppt_funcs->mode2_reset(smu);\n\n\tif (ret)\n\t\tdev_err(smu->adev->dev, \"Mode2 reset failed!\\n\");\n\n\treturn ret;\n}\n\nstatic int smu_enable_gfx_features(void *handle)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->enable_gfx_features)\n\t\tret = smu->ppt_funcs->enable_gfx_features(smu);\n\n\tif (ret)\n\t\tdev_err(smu->adev->dev, \"enable gfx features failed!\\n\");\n\n\treturn ret;\n}\n\nstatic int smu_get_max_sustainable_clocks_by_dc(void *handle,\n\t\t\t\t\t\tstruct pp_smu_nv_clock_table *max_clocks)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->get_max_sustainable_clocks_by_dc)\n\t\tret = smu->ppt_funcs->get_max_sustainable_clocks_by_dc(smu, max_clocks);\n\n\treturn ret;\n}\n\nstatic int smu_get_uclk_dpm_states(void *handle,\n\t\t\t\t   unsigned int *clock_values_in_khz,\n\t\t\t\t   unsigned int *num_states)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->get_uclk_dpm_states)\n\t\tret = smu->ppt_funcs->get_uclk_dpm_states(smu, clock_values_in_khz, num_states);\n\n\treturn ret;\n}\n\nstatic enum amd_pm_state_type smu_get_current_power_state(void *handle)\n{\n\tstruct smu_context *smu = handle;\n\tenum amd_pm_state_type pm_state = POWER_STATE_TYPE_DEFAULT;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->get_current_power_state)\n\t\tpm_state = smu->ppt_funcs->get_current_power_state(smu);\n\n\treturn pm_state;\n}\n\nstatic int smu_get_dpm_clock_table(void *handle,\n\t\t\t\t   struct dpm_clocks *clock_table)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->get_dpm_clock_table)\n\t\tret = smu->ppt_funcs->get_dpm_clock_table(smu, clock_table);\n\n\treturn ret;\n}\n\nstatic ssize_t smu_sys_get_gpu_metrics(void *handle, void **table)\n{\n\tstruct smu_context *smu = handle;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!smu->ppt_funcs->get_gpu_metrics)\n\t\treturn -EOPNOTSUPP;\n\n\treturn smu->ppt_funcs->get_gpu_metrics(smu, table);\n}\n\nstatic int smu_enable_mgpu_fan_boost(void *handle)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (!smu->pm_enabled || !smu->adev->pm.dpm_enabled)\n\t\treturn -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs->enable_mgpu_fan_boost)\n\t\tret = smu->ppt_funcs->enable_mgpu_fan_boost(smu);\n\n\treturn ret;\n}\n\nstatic int smu_gfx_state_change_set(void *handle,\n\t\t\t\t    uint32_t state)\n{\n\tstruct smu_context *smu = handle;\n\tint ret = 0;\n\n\tif (smu->ppt_funcs->gfx_state_change_set)\n\t\tret = smu->ppt_funcs->gfx_state_change_set(smu, state);\n\n\treturn ret;\n}\n\nint smu_handle_passthrough_sbr(struct smu_context *smu, bool enable)\n{\n\tint ret = 0;\n\n\tif (smu->ppt_funcs->smu_handle_passthrough_sbr)\n\t\tret = smu->ppt_funcs->smu_handle_passthrough_sbr(smu, enable);\n\n\treturn ret;\n}\n\nint smu_get_ecc_info(struct smu_context *smu, void *umc_ecc)\n{\n\tint ret = -EOPNOTSUPP;\n\n\tif (smu->ppt_funcs &&\n\t\tsmu->ppt_funcs->get_ecc_info)\n\t\tret = smu->ppt_funcs->get_ecc_info(smu, umc_ecc);\n\n\treturn ret;\n\n}\n\nstatic int smu_get_prv_buffer_details(void *handle, void **addr, size_t *size)\n{\n\tstruct smu_context *smu = handle;\n\tstruct smu_table_context *smu_table = &smu->smu_table;\n\tstruct smu_table *memory_pool = &smu_table->memory_pool;\n\n\tif (!addr || !size)\n\t\treturn -EINVAL;\n\n\t*addr = NULL;\n\t*size = 0;\n\tif (memory_pool->bo) {\n\t\t*addr = memory_pool->cpu_addr;\n\t\t*size = memory_pool->size;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct amd_pm_funcs swsmu_pm_funcs = {\n\t \n\t.set_fan_control_mode    = smu_set_fan_control_mode,\n\t.get_fan_control_mode    = smu_get_fan_control_mode,\n\t.set_fan_speed_pwm   = smu_set_fan_speed_pwm,\n\t.get_fan_speed_pwm   = smu_get_fan_speed_pwm,\n\t.force_clock_level       = smu_force_ppclk_levels,\n\t.print_clock_levels      = smu_print_ppclk_levels,\n\t.emit_clock_levels       = smu_emit_ppclk_levels,\n\t.force_performance_level = smu_force_performance_level,\n\t.read_sensor             = smu_read_sensor,\n\t.get_apu_thermal_limit       = smu_get_apu_thermal_limit,\n\t.set_apu_thermal_limit       = smu_set_apu_thermal_limit,\n\t.get_performance_level   = smu_get_performance_level,\n\t.get_current_power_state = smu_get_current_power_state,\n\t.get_fan_speed_rpm       = smu_get_fan_speed_rpm,\n\t.set_fan_speed_rpm       = smu_set_fan_speed_rpm,\n\t.get_pp_num_states       = smu_get_power_num_states,\n\t.get_pp_table            = smu_sys_get_pp_table,\n\t.set_pp_table            = smu_sys_set_pp_table,\n\t.switch_power_profile    = smu_switch_power_profile,\n\t \n\t.dispatch_tasks          = smu_handle_dpm_task,\n\t.load_firmware           = smu_load_microcode,\n\t.set_powergating_by_smu  = smu_dpm_set_power_gate,\n\t.set_power_limit         = smu_set_power_limit,\n\t.get_power_limit         = smu_get_power_limit,\n\t.get_power_profile_mode  = smu_get_power_profile_mode,\n\t.set_power_profile_mode  = smu_set_power_profile_mode,\n\t.odn_edit_dpm_table      = smu_od_edit_dpm_table,\n\t.set_mp1_state           = smu_set_mp1_state,\n\t.gfx_state_change_set    = smu_gfx_state_change_set,\n\t \n\t.get_sclk                         = smu_get_sclk,\n\t.get_mclk                         = smu_get_mclk,\n\t.display_configuration_change     = smu_display_configuration_change,\n\t.get_clock_by_type_with_latency   = smu_get_clock_by_type_with_latency,\n\t.display_clock_voltage_request    = smu_display_clock_voltage_request,\n\t.enable_mgpu_fan_boost            = smu_enable_mgpu_fan_boost,\n\t.set_active_display_count         = smu_set_display_count,\n\t.set_min_deep_sleep_dcefclk       = smu_set_deep_sleep_dcefclk,\n\t.get_asic_baco_capability         = smu_get_baco_capability,\n\t.set_asic_baco_state              = smu_baco_set_state,\n\t.get_ppfeature_status             = smu_sys_get_pp_feature_mask,\n\t.set_ppfeature_status             = smu_sys_set_pp_feature_mask,\n\t.asic_reset_mode_2                = smu_mode2_reset,\n\t.asic_reset_enable_gfx_features   = smu_enable_gfx_features,\n\t.set_df_cstate                    = smu_set_df_cstate,\n\t.set_xgmi_pstate                  = smu_set_xgmi_pstate,\n\t.get_gpu_metrics                  = smu_sys_get_gpu_metrics,\n\t.set_watermarks_for_clock_ranges     = smu_set_watermarks_for_clock_ranges,\n\t.display_disable_memory_clock_switch = smu_display_disable_memory_clock_switch,\n\t.get_max_sustainable_clocks_by_dc    = smu_get_max_sustainable_clocks_by_dc,\n\t.get_uclk_dpm_states              = smu_get_uclk_dpm_states,\n\t.get_dpm_clock_table              = smu_get_dpm_clock_table,\n\t.get_smu_prv_buf_details = smu_get_prv_buffer_details,\n};\n\nint smu_wait_for_event(struct smu_context *smu, enum smu_event_type event,\n\t\t       uint64_t event_arg)\n{\n\tint ret = -EINVAL;\n\n\tif (smu->ppt_funcs->wait_for_event)\n\t\tret = smu->ppt_funcs->wait_for_event(smu, event, event_arg);\n\n\treturn ret;\n}\n\nint smu_stb_collect_info(struct smu_context *smu, void *buf, uint32_t size)\n{\n\n\tif (!smu->ppt_funcs->stb_collect_info || !smu->stb_context.enabled)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (size != smu->stb_context.stb_buf_size)\n\t\treturn -EINVAL;\n\n\t \n\treturn smu->ppt_funcs->stb_collect_info(smu, buf, size);\n}\n\n#if defined(CONFIG_DEBUG_FS)\n\nstatic int smu_stb_debugfs_open(struct inode *inode, struct file *filp)\n{\n\tstruct amdgpu_device *adev = filp->f_inode->i_private;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\tunsigned char *buf;\n\tint r;\n\n\tbuf = kvmalloc_array(smu->stb_context.stb_buf_size, sizeof(*buf), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tr = smu_stb_collect_info(smu, buf, smu->stb_context.stb_buf_size);\n\tif (r)\n\t\tgoto out;\n\n\tfilp->private_data = buf;\n\n\treturn 0;\n\nout:\n\tkvfree(buf);\n\treturn r;\n}\n\nstatic ssize_t smu_stb_debugfs_read(struct file *filp, char __user *buf, size_t size,\n\t\t\t\tloff_t *pos)\n{\n\tstruct amdgpu_device *adev = filp->f_inode->i_private;\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\n\tif (!filp->private_data)\n\t\treturn -EINVAL;\n\n\treturn simple_read_from_buffer(buf,\n\t\t\t\t       size,\n\t\t\t\t       pos, filp->private_data,\n\t\t\t\t       smu->stb_context.stb_buf_size);\n}\n\nstatic int smu_stb_debugfs_release(struct inode *inode, struct file *filp)\n{\n\tkvfree(filp->private_data);\n\tfilp->private_data = NULL;\n\n\treturn 0;\n}\n\n \nstatic const struct file_operations smu_stb_debugfs_fops = {\n\t.owner = THIS_MODULE,\n\t.open = smu_stb_debugfs_open,\n\t.read = smu_stb_debugfs_read,\n\t.release = smu_stb_debugfs_release,\n\t.llseek = default_llseek,\n};\n\n#endif\n\nvoid amdgpu_smu_stb_debug_fs_init(struct amdgpu_device *adev)\n{\n#if defined(CONFIG_DEBUG_FS)\n\n\tstruct smu_context *smu = adev->powerplay.pp_handle;\n\n\tif (!smu || (!smu->stb_context.stb_buf_size))\n\t\treturn;\n\n\tdebugfs_create_file_size(\"amdgpu_smu_stb_dump\",\n\t\t\t    S_IRUSR,\n\t\t\t    adev_to_drm(adev)->primary->debugfs_root,\n\t\t\t    adev,\n\t\t\t    &smu_stb_debugfs_fops,\n\t\t\t    smu->stb_context.stb_buf_size);\n#endif\n}\n\nint smu_send_hbm_bad_pages_num(struct smu_context *smu, uint32_t size)\n{\n\tint ret = 0;\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->send_hbm_bad_pages_num)\n\t\tret = smu->ppt_funcs->send_hbm_bad_pages_num(smu, size);\n\n\treturn ret;\n}\n\nint smu_send_hbm_bad_channel_flag(struct smu_context *smu, uint32_t size)\n{\n\tint ret = 0;\n\n\tif (smu->ppt_funcs && smu->ppt_funcs->send_hbm_bad_channel_flag)\n\t\tret = smu->ppt_funcs->send_hbm_bad_channel_flag(smu, size);\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}