{
  "module_name": "hardwaremanager.c",
  "hash_id": "a84ee0a2bfc05d6586c711b0bee6a6595f1b39a7c869a1c79e0787d6c87c7f37",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/pm/powerplay/hwmgr/hardwaremanager.c",
  "human_readable_source": " \n#include \"pp_debug.h\"\n#include <linux/errno.h>\n#include \"hwmgr.h\"\n#include \"hardwaremanager.h\"\n#include \"power_state.h\"\n\n\n#define TEMP_RANGE_MIN (0)\n#define TEMP_RANGE_MAX (80 * 1000)\n\n#define PHM_FUNC_CHECK(hw) \\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tif ((hw) == NULL || (hw)->hwmgr_func == NULL)\t\\\n\t\t\treturn -EINVAL;\t\t\t\t\\\n\t} while (0)\n\nint phm_setup_asic(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (NULL != hwmgr->hwmgr_func->asic_setup)\n\t\treturn hwmgr->hwmgr_func->asic_setup(hwmgr);\n\n\treturn 0;\n}\n\nint phm_power_down_asic(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (NULL != hwmgr->hwmgr_func->power_off_asic)\n\t\treturn hwmgr->hwmgr_func->power_off_asic(hwmgr);\n\n\treturn 0;\n}\n\nint phm_set_power_state(struct pp_hwmgr *hwmgr,\n\t\t    const struct pp_hw_power_state *pcurrent_state,\n\t\t    const struct pp_hw_power_state *pnew_power_state)\n{\n\tstruct phm_set_power_state_input states;\n\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tstates.pcurrent_state = pcurrent_state;\n\tstates.pnew_state = pnew_power_state;\n\n\tif (NULL != hwmgr->hwmgr_func->power_state_set)\n\t\treturn hwmgr->hwmgr_func->power_state_set(hwmgr, &states);\n\n\treturn 0;\n}\n\nint phm_enable_dynamic_state_management(struct pp_hwmgr *hwmgr)\n{\n\tstruct amdgpu_device *adev = NULL;\n\tint ret = -EINVAL;\n\tPHM_FUNC_CHECK(hwmgr);\n\tadev = hwmgr->adev;\n\n\t \n\tif (!hwmgr->pp_one_vf && smum_is_dpm_running(hwmgr)\n\t    && !amdgpu_passthrough(adev) && adev->in_suspend\n\t\t&& adev->asic_type != CHIP_RAVEN) {\n\t\tpr_info(\"dpm has been enabled\\n\");\n\t\treturn 0;\n\t}\n\n\tif (NULL != hwmgr->hwmgr_func->dynamic_state_management_enable)\n\t\tret = hwmgr->hwmgr_func->dynamic_state_management_enable(hwmgr);\n\n\treturn ret;\n}\n\nint phm_disable_dynamic_state_management(struct pp_hwmgr *hwmgr)\n{\n\tint ret = -EINVAL;\n\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (!hwmgr->not_vf)\n\t\treturn 0;\n\n\tif (!smum_is_dpm_running(hwmgr)) {\n\t\tpr_info(\"dpm has been disabled\\n\");\n\t\treturn 0;\n\t}\n\n\tif (hwmgr->hwmgr_func->dynamic_state_management_disable)\n\t\tret = hwmgr->hwmgr_func->dynamic_state_management_disable(hwmgr);\n\n\treturn ret;\n}\n\nint phm_force_dpm_levels(struct pp_hwmgr *hwmgr, enum amd_dpm_forced_level level)\n{\n\tint ret = 0;\n\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->force_dpm_level != NULL)\n\t\tret = hwmgr->hwmgr_func->force_dpm_level(hwmgr, level);\n\n\treturn ret;\n}\n\nint phm_apply_state_adjust_rules(struct pp_hwmgr *hwmgr,\n\t\t\t\t   struct pp_power_state *adjusted_ps,\n\t\t\t     const struct pp_power_state *current_ps)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->apply_state_adjust_rules != NULL)\n\t\treturn hwmgr->hwmgr_func->apply_state_adjust_rules(\n\t\t\t\t\t\t\t\t\thwmgr,\n\t\t\t\t\t\t\t\t adjusted_ps,\n\t\t\t\t\t\t\t\t current_ps);\n\treturn 0;\n}\n\nint phm_apply_clock_adjust_rules(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->apply_clocks_adjust_rules != NULL)\n\t\treturn hwmgr->hwmgr_func->apply_clocks_adjust_rules(hwmgr);\n\treturn 0;\n}\n\nint phm_powerdown_uvd(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->powerdown_uvd != NULL)\n\t\treturn hwmgr->hwmgr_func->powerdown_uvd(hwmgr);\n\treturn 0;\n}\n\n\nint phm_disable_clock_power_gatings(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (NULL != hwmgr->hwmgr_func->disable_clock_power_gating)\n\t\treturn hwmgr->hwmgr_func->disable_clock_power_gating(hwmgr);\n\n\treturn 0;\n}\n\nint phm_pre_display_configuration_changed(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (NULL != hwmgr->hwmgr_func->pre_display_config_changed)\n\t\thwmgr->hwmgr_func->pre_display_config_changed(hwmgr);\n\n\treturn 0;\n\n}\n\nint phm_display_configuration_changed(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (NULL != hwmgr->hwmgr_func->display_config_changed)\n\t\thwmgr->hwmgr_func->display_config_changed(hwmgr);\n\n\treturn 0;\n}\n\nint phm_notify_smc_display_config_after_ps_adjustment(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (NULL != hwmgr->hwmgr_func->notify_smc_display_config_after_ps_adjustment)\n\t\t\thwmgr->hwmgr_func->notify_smc_display_config_after_ps_adjustment(hwmgr);\n\n\treturn 0;\n}\n\nint phm_stop_thermal_controller(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (!hwmgr->not_vf)\n\t\treturn 0;\n\n\tif (hwmgr->hwmgr_func->stop_thermal_controller == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->stop_thermal_controller(hwmgr);\n}\n\nint phm_register_irq_handlers(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->register_irq_handlers != NULL)\n\t\treturn hwmgr->hwmgr_func->register_irq_handlers(hwmgr);\n\n\treturn 0;\n}\n\n \nint phm_start_thermal_controller(struct pp_hwmgr *hwmgr)\n{\n\tint ret = 0;\n\tstruct PP_TemperatureRange range = {\n\t\tTEMP_RANGE_MIN,\n\t\tTEMP_RANGE_MAX,\n\t\tTEMP_RANGE_MAX,\n\t\tTEMP_RANGE_MIN,\n\t\tTEMP_RANGE_MAX,\n\t\tTEMP_RANGE_MAX,\n\t\tTEMP_RANGE_MIN,\n\t\tTEMP_RANGE_MAX,\n\t\tTEMP_RANGE_MAX,\n\t\t0};\n\tstruct amdgpu_device *adev = hwmgr->adev;\n\n\tif (!hwmgr->not_vf)\n\t\treturn 0;\n\n\tif (hwmgr->hwmgr_func->get_thermal_temperature_range)\n\t\thwmgr->hwmgr_func->get_thermal_temperature_range(\n\t\t\t\thwmgr, &range);\n\n\tif (phm_cap_enabled(hwmgr->platform_descriptor.platformCaps,\n\t\t\tPHM_PlatformCaps_ThermalController)\n\t\t\t&& hwmgr->hwmgr_func->start_thermal_controller != NULL)\n\t\tret = hwmgr->hwmgr_func->start_thermal_controller(hwmgr, &range);\n\n\tadev->pm.dpm.thermal.min_temp = range.min;\n\tadev->pm.dpm.thermal.max_temp = range.max;\n\tadev->pm.dpm.thermal.max_edge_emergency_temp = range.edge_emergency_max;\n\tadev->pm.dpm.thermal.min_hotspot_temp = range.hotspot_min;\n\tadev->pm.dpm.thermal.max_hotspot_crit_temp = range.hotspot_crit_max;\n\tadev->pm.dpm.thermal.max_hotspot_emergency_temp = range.hotspot_emergency_max;\n\tadev->pm.dpm.thermal.min_mem_temp = range.mem_min;\n\tadev->pm.dpm.thermal.max_mem_crit_temp = range.mem_crit_max;\n\tadev->pm.dpm.thermal.max_mem_emergency_temp = range.mem_emergency_max;\n\tadev->pm.dpm.thermal.sw_ctf_threshold = range.sw_ctf_threshold;\n\n\treturn ret;\n}\n\n\nbool phm_check_smc_update_required_for_display_configuration(struct pp_hwmgr *hwmgr)\n{\n\tif (hwmgr == NULL ||\n\t    hwmgr->hwmgr_func == NULL)\n\t\treturn false;\n\n\tif (hwmgr->pp_one_vf)\n\t\treturn false;\n\n\tif (hwmgr->hwmgr_func->check_smc_update_required_for_display_configuration == NULL)\n\t\treturn false;\n\n\treturn hwmgr->hwmgr_func->check_smc_update_required_for_display_configuration(hwmgr);\n}\n\n\nint phm_check_states_equal(struct pp_hwmgr *hwmgr,\n\t\t\t\t const struct pp_hw_power_state *pstate1,\n\t\t\t\t const struct pp_hw_power_state *pstate2,\n\t\t\t\t bool *equal)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->check_states_equal == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->check_states_equal(hwmgr, pstate1, pstate2, equal);\n}\n\nint phm_store_dal_configuration_data(struct pp_hwmgr *hwmgr,\n\t\t    const struct amd_pp_display_configuration *display_config)\n{\n\tint index = 0;\n\tint number_of_active_display = 0;\n\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (display_config == NULL)\n\t\treturn -EINVAL;\n\n\tif (NULL != hwmgr->hwmgr_func->set_min_deep_sleep_dcefclk)\n\t\thwmgr->hwmgr_func->set_min_deep_sleep_dcefclk(hwmgr, display_config->min_dcef_deep_sleep_set_clk);\n\n\tfor (index = 0; index < display_config->num_path_including_non_display; index++) {\n\t\tif (display_config->displays[index].controller_id != 0)\n\t\t\tnumber_of_active_display++;\n\t}\n\n\tif (NULL != hwmgr->hwmgr_func->set_active_display_count)\n\t\thwmgr->hwmgr_func->set_active_display_count(hwmgr, number_of_active_display);\n\n\tif (hwmgr->hwmgr_func->store_cc6_data == NULL)\n\t\treturn -EINVAL;\n\n\t \n\n\tif (hwmgr->hwmgr_func->store_cc6_data)\n\t\thwmgr->hwmgr_func->store_cc6_data(hwmgr,\n\t\t\t\tdisplay_config->cpu_pstate_separation_time,\n\t\t\t\tdisplay_config->cpu_cc6_disable,\n\t\t\t\tdisplay_config->cpu_pstate_disable,\n\t\t\t\tdisplay_config->nb_pstate_switch_disable);\n\n\treturn 0;\n}\n\nint phm_get_dal_power_level(struct pp_hwmgr *hwmgr,\n\t\tstruct amd_pp_simple_clock_info *info)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (info == NULL || hwmgr->hwmgr_func->get_dal_power_level == NULL)\n\t\treturn -EINVAL;\n\treturn hwmgr->hwmgr_func->get_dal_power_level(hwmgr, info);\n}\n\nint phm_set_cpu_power_state(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->set_cpu_power_state != NULL)\n\t\treturn hwmgr->hwmgr_func->set_cpu_power_state(hwmgr);\n\n\treturn 0;\n}\n\n\nint phm_get_performance_level(struct pp_hwmgr *hwmgr, const struct pp_hw_power_state *state,\n\t\t\t\tPHM_PerformanceLevelDesignation designation, uint32_t index,\n\t\t\t\tPHM_PerformanceLevel *level)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\tif (hwmgr->hwmgr_func->get_performance_level == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->get_performance_level(hwmgr, state, designation, index, level);\n\n\n}\n\n\n \nint phm_get_clock_info(struct pp_hwmgr *hwmgr, const struct pp_hw_power_state *state, struct pp_clock_info *pclock_info,\n\t\t\tPHM_PerformanceLevelDesignation designation)\n{\n\tint result;\n\tPHM_PerformanceLevel performance_level = {0};\n\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tPP_ASSERT_WITH_CODE((NULL != state), \"Invalid Input!\", return -EINVAL);\n\tPP_ASSERT_WITH_CODE((NULL != pclock_info), \"Invalid Input!\", return -EINVAL);\n\n\tresult = phm_get_performance_level(hwmgr, state, PHM_PerformanceLevelDesignation_Activity, 0, &performance_level);\n\n\tPP_ASSERT_WITH_CODE((0 == result), \"Failed to retrieve minimum clocks.\", return result);\n\n\n\tpclock_info->min_mem_clk = performance_level.memory_clock;\n\tpclock_info->min_eng_clk = performance_level.coreClock;\n\tpclock_info->min_bus_bandwidth = performance_level.nonLocalMemoryFreq * performance_level.nonLocalMemoryWidth;\n\n\n\tresult = phm_get_performance_level(hwmgr, state, designation,\n\t\t\t\t\t(hwmgr->platform_descriptor.hardwareActivityPerformanceLevels - 1), &performance_level);\n\n\tPP_ASSERT_WITH_CODE((0 == result), \"Failed to retrieve maximum clocks.\", return result);\n\n\tpclock_info->max_mem_clk = performance_level.memory_clock;\n\tpclock_info->max_eng_clk = performance_level.coreClock;\n\tpclock_info->max_bus_bandwidth = performance_level.nonLocalMemoryFreq * performance_level.nonLocalMemoryWidth;\n\n\treturn 0;\n}\n\nint phm_get_current_shallow_sleep_clocks(struct pp_hwmgr *hwmgr, const struct pp_hw_power_state *state, struct pp_clock_info *clock_info)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->get_current_shallow_sleep_clocks == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->get_current_shallow_sleep_clocks(hwmgr, state, clock_info);\n\n}\n\nint phm_get_clock_by_type(struct pp_hwmgr *hwmgr, enum amd_pp_clock_type type, struct amd_pp_clocks *clocks)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->get_clock_by_type == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->get_clock_by_type(hwmgr, type, clocks);\n\n}\n\nint phm_get_clock_by_type_with_latency(struct pp_hwmgr *hwmgr,\n\t\tenum amd_pp_clock_type type,\n\t\tstruct pp_clock_levels_with_latency *clocks)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->get_clock_by_type_with_latency == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->get_clock_by_type_with_latency(hwmgr, type, clocks);\n\n}\n\nint phm_get_clock_by_type_with_voltage(struct pp_hwmgr *hwmgr,\n\t\tenum amd_pp_clock_type type,\n\t\tstruct pp_clock_levels_with_voltage *clocks)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->get_clock_by_type_with_voltage == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->get_clock_by_type_with_voltage(hwmgr, type, clocks);\n\n}\n\nint phm_set_watermarks_for_clocks_ranges(struct pp_hwmgr *hwmgr,\n\t\t\t\t\tvoid *clock_ranges)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (!hwmgr->hwmgr_func->set_watermarks_for_clocks_ranges)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->set_watermarks_for_clocks_ranges(hwmgr,\n\t\t\t\t\t\t\t\tclock_ranges);\n}\n\nint phm_display_clock_voltage_request(struct pp_hwmgr *hwmgr,\n\t\tstruct pp_display_clock_request *clock)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (!hwmgr->hwmgr_func->display_clock_voltage_request)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->display_clock_voltage_request(hwmgr, clock);\n}\n\nint phm_get_max_high_clocks(struct pp_hwmgr *hwmgr, struct amd_pp_simple_clock_info *clocks)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (hwmgr->hwmgr_func->get_max_high_clocks == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->get_max_high_clocks(hwmgr, clocks);\n}\n\nint phm_disable_smc_firmware_ctf(struct pp_hwmgr *hwmgr)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (!hwmgr->not_vf)\n\t\treturn 0;\n\n\tif (hwmgr->hwmgr_func->disable_smc_firmware_ctf == NULL)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->disable_smc_firmware_ctf(hwmgr);\n}\n\nint phm_set_active_display_count(struct pp_hwmgr *hwmgr, uint32_t count)\n{\n\tPHM_FUNC_CHECK(hwmgr);\n\n\tif (!hwmgr->hwmgr_func->set_active_display_count)\n\t\treturn -EINVAL;\n\n\treturn hwmgr->hwmgr_func->set_active_display_count(hwmgr, count);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}