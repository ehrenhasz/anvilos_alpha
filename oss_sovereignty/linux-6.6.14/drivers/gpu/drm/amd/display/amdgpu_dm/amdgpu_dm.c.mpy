{
  "module_name": "amdgpu_dm.c",
  "hash_id": "055d38300ff33eec3618239f5006e054e8934473e4732c3d136683136fc04a49",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm.c",
  "human_readable_source": " \n\n \n#define CREATE_TRACE_POINTS\n\n#include \"dm_services_types.h\"\n#include \"dc.h\"\n#include \"link_enc_cfg.h\"\n#include \"dc/inc/core_types.h\"\n#include \"dal_asic_id.h\"\n#include \"dmub/dmub_srv.h\"\n#include \"dc/inc/hw/dmcu.h\"\n#include \"dc/inc/hw/abm.h\"\n#include \"dc/dc_dmub_srv.h\"\n#include \"dc/dc_edid_parser.h\"\n#include \"dc/dc_stat.h\"\n#include \"amdgpu_dm_trace.h\"\n#include \"dpcd_defs.h\"\n#include \"link/protocols/link_dpcd.h\"\n#include \"link_service_types.h\"\n#include \"link/protocols/link_dp_capability.h\"\n#include \"link/protocols/link_ddc.h\"\n\n#include \"vid.h\"\n#include \"amdgpu.h\"\n#include \"amdgpu_display.h\"\n#include \"amdgpu_ucode.h\"\n#include \"atom.h\"\n#include \"amdgpu_dm.h\"\n#include \"amdgpu_dm_plane.h\"\n#include \"amdgpu_dm_crtc.h\"\n#include \"amdgpu_dm_hdcp.h\"\n#include <drm/display/drm_hdcp_helper.h>\n#include \"amdgpu_pm.h\"\n#include \"amdgpu_atombios.h\"\n\n#include \"amd_shared.h\"\n#include \"amdgpu_dm_irq.h\"\n#include \"dm_helpers.h\"\n#include \"amdgpu_dm_mst_types.h\"\n#if defined(CONFIG_DEBUG_FS)\n#include \"amdgpu_dm_debugfs.h\"\n#endif\n#include \"amdgpu_dm_psr.h\"\n#include \"amdgpu_dm_replay.h\"\n\n#include \"ivsrcid/ivsrcid_vislands30.h\"\n\n#include <linux/backlight.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/types.h>\n#include <linux/pm_runtime.h>\n#include <linux/pci.h>\n#include <linux/firmware.h>\n#include <linux/component.h>\n#include <linux/dmi.h>\n\n#include <drm/display/drm_dp_mst_helper.h>\n#include <drm/display/drm_hdmi_helper.h>\n#include <drm/drm_atomic.h>\n#include <drm/drm_atomic_uapi.h>\n#include <drm/drm_atomic_helper.h>\n#include <drm/drm_blend.h>\n#include <drm/drm_fourcc.h>\n#include <drm/drm_edid.h>\n#include <drm/drm_vblank.h>\n#include <drm/drm_audio_component.h>\n#include <drm/drm_gem_atomic_helper.h>\n#include <drm/drm_plane_helper.h>\n\n#include <acpi/video.h>\n\n#include \"ivsrcid/dcn/irqsrcs_dcn_1_0.h\"\n\n#include \"dcn/dcn_1_0_offset.h\"\n#include \"dcn/dcn_1_0_sh_mask.h\"\n#include \"soc15_hw_ip.h\"\n#include \"soc15_common.h\"\n#include \"vega10_ip_offset.h\"\n\n#include \"gc/gc_11_0_0_offset.h\"\n#include \"gc/gc_11_0_0_sh_mask.h\"\n\n#include \"modules/inc/mod_freesync.h\"\n#include \"modules/power/power_helpers.h\"\n\n#define FIRMWARE_RENOIR_DMUB \"amdgpu/renoir_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_RENOIR_DMUB);\n#define FIRMWARE_SIENNA_CICHLID_DMUB \"amdgpu/sienna_cichlid_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_SIENNA_CICHLID_DMUB);\n#define FIRMWARE_NAVY_FLOUNDER_DMUB \"amdgpu/navy_flounder_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_NAVY_FLOUNDER_DMUB);\n#define FIRMWARE_GREEN_SARDINE_DMUB \"amdgpu/green_sardine_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_GREEN_SARDINE_DMUB);\n#define FIRMWARE_VANGOGH_DMUB \"amdgpu/vangogh_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_VANGOGH_DMUB);\n#define FIRMWARE_DIMGREY_CAVEFISH_DMUB \"amdgpu/dimgrey_cavefish_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_DIMGREY_CAVEFISH_DMUB);\n#define FIRMWARE_BEIGE_GOBY_DMUB \"amdgpu/beige_goby_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_BEIGE_GOBY_DMUB);\n#define FIRMWARE_YELLOW_CARP_DMUB \"amdgpu/yellow_carp_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_YELLOW_CARP_DMUB);\n#define FIRMWARE_DCN_314_DMUB \"amdgpu/dcn_3_1_4_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_DCN_314_DMUB);\n#define FIRMWARE_DCN_315_DMUB \"amdgpu/dcn_3_1_5_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_DCN_315_DMUB);\n#define FIRMWARE_DCN316_DMUB \"amdgpu/dcn_3_1_6_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_DCN316_DMUB);\n\n#define FIRMWARE_DCN_V3_2_0_DMCUB \"amdgpu/dcn_3_2_0_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_DCN_V3_2_0_DMCUB);\n#define FIRMWARE_DCN_V3_2_1_DMCUB \"amdgpu/dcn_3_2_1_dmcub.bin\"\nMODULE_FIRMWARE(FIRMWARE_DCN_V3_2_1_DMCUB);\n\n#define FIRMWARE_RAVEN_DMCU\t\t\"amdgpu/raven_dmcu.bin\"\nMODULE_FIRMWARE(FIRMWARE_RAVEN_DMCU);\n\n#define FIRMWARE_NAVI12_DMCU            \"amdgpu/navi12_dmcu.bin\"\nMODULE_FIRMWARE(FIRMWARE_NAVI12_DMCU);\n\n \n#define PSP_HEADER_BYTES 0x100\n\n \n#define PSP_FOOTER_BYTES 0x100\n\n \n\n \nstatic int amdgpu_dm_init(struct amdgpu_device *adev);\nstatic void amdgpu_dm_fini(struct amdgpu_device *adev);\nstatic bool is_freesync_video_mode(const struct drm_display_mode *mode, struct amdgpu_dm_connector *aconnector);\n\nstatic enum drm_mode_subconnector get_subconnector_type(struct dc_link *link)\n{\n\tswitch (link->dpcd_caps.dongle_type) {\n\tcase DISPLAY_DONGLE_NONE:\n\t\treturn DRM_MODE_SUBCONNECTOR_Native;\n\tcase DISPLAY_DONGLE_DP_VGA_CONVERTER:\n\t\treturn DRM_MODE_SUBCONNECTOR_VGA;\n\tcase DISPLAY_DONGLE_DP_DVI_CONVERTER:\n\tcase DISPLAY_DONGLE_DP_DVI_DONGLE:\n\t\treturn DRM_MODE_SUBCONNECTOR_DVID;\n\tcase DISPLAY_DONGLE_DP_HDMI_CONVERTER:\n\tcase DISPLAY_DONGLE_DP_HDMI_DONGLE:\n\t\treturn DRM_MODE_SUBCONNECTOR_HDMIA;\n\tcase DISPLAY_DONGLE_DP_HDMI_MISMATCHED_DONGLE:\n\tdefault:\n\t\treturn DRM_MODE_SUBCONNECTOR_Unknown;\n\t}\n}\n\nstatic void update_subconnector_property(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct dc_link *link = aconnector->dc_link;\n\tstruct drm_connector *connector = &aconnector->base;\n\tenum drm_mode_subconnector subconnector = DRM_MODE_SUBCONNECTOR_Unknown;\n\n\tif (connector->connector_type != DRM_MODE_CONNECTOR_DisplayPort)\n\t\treturn;\n\n\tif (aconnector->dc_sink)\n\t\tsubconnector = get_subconnector_type(link);\n\n\tdrm_object_property_set_value(&connector->base,\n\t\t\tconnector->dev->mode_config.dp_subconnector_property,\n\t\t\tsubconnector);\n}\n\n \nstatic int amdgpu_dm_initialize_drm_device(struct amdgpu_device *adev);\n \nstatic void amdgpu_dm_destroy_drm_device(struct amdgpu_display_manager *dm);\n\nstatic int amdgpu_dm_connector_init(struct amdgpu_display_manager *dm,\n\t\t\t\t    struct amdgpu_dm_connector *amdgpu_dm_connector,\n\t\t\t\t    u32 link_index,\n\t\t\t\t    struct amdgpu_encoder *amdgpu_encoder);\nstatic int amdgpu_dm_encoder_init(struct drm_device *dev,\n\t\t\t\t  struct amdgpu_encoder *aencoder,\n\t\t\t\t  uint32_t link_index);\n\nstatic int amdgpu_dm_connector_get_modes(struct drm_connector *connector);\n\nstatic void amdgpu_dm_atomic_commit_tail(struct drm_atomic_state *state);\n\nstatic int amdgpu_dm_atomic_check(struct drm_device *dev,\n\t\t\t\t  struct drm_atomic_state *state);\n\nstatic void handle_hpd_irq_helper(struct amdgpu_dm_connector *aconnector);\nstatic void handle_hpd_rx_irq(void *param);\n\nstatic bool\nis_timing_unchanged_for_freesync(struct drm_crtc_state *old_crtc_state,\n\t\t\t\t struct drm_crtc_state *new_crtc_state);\n \nstatic u32 dm_vblank_get_counter(struct amdgpu_device *adev, int crtc)\n{\n\tstruct amdgpu_crtc *acrtc = NULL;\n\n\tif (crtc >= adev->mode_info.num_crtc)\n\t\treturn 0;\n\n\tacrtc = adev->mode_info.crtcs[crtc];\n\n\tif (!acrtc->dm_irq_params.stream) {\n\t\tDRM_ERROR(\"dc_stream_state is NULL for crtc '%d'!\\n\",\n\t\t\t  crtc);\n\t\treturn 0;\n\t}\n\n\treturn dc_stream_get_vblank_counter(acrtc->dm_irq_params.stream);\n}\n\nstatic int dm_crtc_get_scanoutpos(struct amdgpu_device *adev, int crtc,\n\t\t\t\t  u32 *vbl, u32 *position)\n{\n\tu32 v_blank_start, v_blank_end, h_position, v_position;\n\tstruct amdgpu_crtc *acrtc = NULL;\n\n\tif ((crtc < 0) || (crtc >= adev->mode_info.num_crtc))\n\t\treturn -EINVAL;\n\n\tacrtc = adev->mode_info.crtcs[crtc];\n\n\tif (!acrtc->dm_irq_params.stream) {\n\t\tDRM_ERROR(\"dc_stream_state is NULL for crtc '%d'!\\n\",\n\t\t\t  crtc);\n\t\treturn 0;\n\t}\n\n\t \n\tdc_stream_get_scanoutpos(acrtc->dm_irq_params.stream,\n\t\t\t\t &v_blank_start,\n\t\t\t\t &v_blank_end,\n\t\t\t\t &h_position,\n\t\t\t\t &v_position);\n\n\t*position = v_position | (h_position << 16);\n\t*vbl = v_blank_start | (v_blank_end << 16);\n\n\treturn 0;\n}\n\nstatic bool dm_is_idle(void *handle)\n{\n\t \n\treturn true;\n}\n\nstatic int dm_wait_for_idle(void *handle)\n{\n\t \n\treturn 0;\n}\n\nstatic bool dm_check_soft_reset(void *handle)\n{\n\treturn false;\n}\n\nstatic int dm_soft_reset(void *handle)\n{\n\t \n\treturn 0;\n}\n\nstatic struct amdgpu_crtc *\nget_crtc_by_otg_inst(struct amdgpu_device *adev,\n\t\t     int otg_inst)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_crtc *crtc;\n\tstruct amdgpu_crtc *amdgpu_crtc;\n\n\tif (WARN_ON(otg_inst == -1))\n\t\treturn adev->mode_info.crtcs[0];\n\n\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\tamdgpu_crtc = to_amdgpu_crtc(crtc);\n\n\t\tif (amdgpu_crtc->otg_inst == otg_inst)\n\t\t\treturn amdgpu_crtc;\n\t}\n\n\treturn NULL;\n}\n\nstatic inline bool is_dc_timing_adjust_needed(struct dm_crtc_state *old_state,\n\t\t\t\t\t      struct dm_crtc_state *new_state)\n{\n\tif (new_state->freesync_config.state ==  VRR_STATE_ACTIVE_FIXED)\n\t\treturn true;\n\telse if (amdgpu_dm_crtc_vrr_active(old_state) != amdgpu_dm_crtc_vrr_active(new_state))\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nstatic inline void reverse_planes_order(struct dc_surface_update *array_of_surface_update,\n\t\t\t\t\tint planes_count)\n{\n\tint i, j;\n\n\tfor (i = 0, j = planes_count - 1; i < j; i++, j--)\n\t\tswap(array_of_surface_update[i], array_of_surface_update[j]);\n}\n\n \nstatic inline bool update_planes_and_stream_adapter(struct dc *dc,\n\t\t\t\t\t\t    int update_type,\n\t\t\t\t\t\t    int planes_count,\n\t\t\t\t\t\t    struct dc_stream_state *stream,\n\t\t\t\t\t\t    struct dc_stream_update *stream_update,\n\t\t\t\t\t\t    struct dc_surface_update *array_of_surface_update)\n{\n\treverse_planes_order(array_of_surface_update, planes_count);\n\n\t \n\tif (update_type == UPDATE_TYPE_FAST)\n\t\tdc_post_update_surfaces_to_stream(dc);\n\n\treturn dc_update_planes_and_stream(dc,\n\t\t\t\t\t   array_of_surface_update,\n\t\t\t\t\t   planes_count,\n\t\t\t\t\t   stream,\n\t\t\t\t\t   stream_update);\n}\n\n \nstatic void dm_pflip_high_irq(void *interrupt_params)\n{\n\tstruct amdgpu_crtc *amdgpu_crtc;\n\tstruct common_irq_params *irq_params = interrupt_params;\n\tstruct amdgpu_device *adev = irq_params->adev;\n\tunsigned long flags;\n\tstruct drm_pending_vblank_event *e;\n\tu32 vpos, hpos, v_blank_start, v_blank_end;\n\tbool vrr_active;\n\n\tamdgpu_crtc = get_crtc_by_otg_inst(adev, irq_params->irq_src - IRQ_TYPE_PFLIP);\n\n\t \n\t \n\tif (amdgpu_crtc == NULL) {\n\t\tDC_LOG_PFLIP(\"CRTC is null, returning.\\n\");\n\t\treturn;\n\t}\n\n\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\n\tif (amdgpu_crtc->pflip_status != AMDGPU_FLIP_SUBMITTED) {\n\t\tDC_LOG_PFLIP(\"amdgpu_crtc->pflip_status = %d !=AMDGPU_FLIP_SUBMITTED(%d) on crtc:%d[%p]\\n\",\n\t\t\t     amdgpu_crtc->pflip_status,\n\t\t\t     AMDGPU_FLIP_SUBMITTED,\n\t\t\t     amdgpu_crtc->crtc_id,\n\t\t\t     amdgpu_crtc);\n\t\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n\t\treturn;\n\t}\n\n\t \n\te = amdgpu_crtc->event;\n\tamdgpu_crtc->event = NULL;\n\n\tWARN_ON(!e);\n\n\tvrr_active = amdgpu_dm_crtc_vrr_active_irq(amdgpu_crtc);\n\n\t \n\tif (!vrr_active ||\n\t    !dc_stream_get_scanoutpos(amdgpu_crtc->dm_irq_params.stream, &v_blank_start,\n\t\t\t\t      &v_blank_end, &hpos, &vpos) ||\n\t    (vpos < v_blank_start)) {\n\t\t \n\t\tdrm_crtc_accurate_vblank_count(&amdgpu_crtc->base);\n\n\t\t \n\t\tif (e) {\n\t\t\tdrm_crtc_send_vblank_event(&amdgpu_crtc->base, e);\n\n\t\t\t \n\t\t\tdrm_crtc_vblank_put(&amdgpu_crtc->base);\n\t\t}\n\t} else if (e) {\n\t\t \n\n\t\t \n\t\te->sequence = drm_crtc_vblank_count(&amdgpu_crtc->base);\n\t\te->pipe = amdgpu_crtc->crtc_id;\n\n\t\tlist_add_tail(&e->base.link, &adev_to_drm(adev)->vblank_event_list);\n\t\te = NULL;\n\t}\n\n\t \n\tamdgpu_crtc->dm_irq_params.last_flip_vblank =\n\t\tamdgpu_get_vblank_counter_kms(&amdgpu_crtc->base);\n\n\tamdgpu_crtc->pflip_status = AMDGPU_FLIP_NONE;\n\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n\n\tDC_LOG_PFLIP(\"crtc:%d[%p], pflip_stat:AMDGPU_FLIP_NONE, vrr[%d]-fp %d\\n\",\n\t\t     amdgpu_crtc->crtc_id, amdgpu_crtc,\n\t\t     vrr_active, (int) !e);\n}\n\nstatic void dm_vupdate_high_irq(void *interrupt_params)\n{\n\tstruct common_irq_params *irq_params = interrupt_params;\n\tstruct amdgpu_device *adev = irq_params->adev;\n\tstruct amdgpu_crtc *acrtc;\n\tstruct drm_device *drm_dev;\n\tstruct drm_vblank_crtc *vblank;\n\tktime_t frame_duration_ns, previous_timestamp;\n\tunsigned long flags;\n\tint vrr_active;\n\n\tacrtc = get_crtc_by_otg_inst(adev, irq_params->irq_src - IRQ_TYPE_VUPDATE);\n\n\tif (acrtc) {\n\t\tvrr_active = amdgpu_dm_crtc_vrr_active_irq(acrtc);\n\t\tdrm_dev = acrtc->base.dev;\n\t\tvblank = &drm_dev->vblank[acrtc->base.index];\n\t\tprevious_timestamp = atomic64_read(&irq_params->previous_timestamp);\n\t\tframe_duration_ns = vblank->time - previous_timestamp;\n\n\t\tif (frame_duration_ns > 0) {\n\t\t\ttrace_amdgpu_refresh_rate_track(acrtc->base.index,\n\t\t\t\t\t\tframe_duration_ns,\n\t\t\t\t\t\tktime_divns(NSEC_PER_SEC, frame_duration_ns));\n\t\t\tatomic64_set(&irq_params->previous_timestamp, vblank->time);\n\t\t}\n\n\t\tDC_LOG_VBLANK(\"crtc:%d, vupdate-vrr:%d\\n\",\n\t\t\t      acrtc->crtc_id,\n\t\t\t      vrr_active);\n\n\t\t \n\t\tif (vrr_active) {\n\t\t\tamdgpu_dm_crtc_handle_vblank(acrtc);\n\n\t\t\t \n\t\t\tif (acrtc->dm_irq_params.stream &&\n\t\t\t    adev->family < AMDGPU_FAMILY_AI) {\n\t\t\t\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\t\t\t\tmod_freesync_handle_v_update(\n\t\t\t\t    adev->dm.freesync_module,\n\t\t\t\t    acrtc->dm_irq_params.stream,\n\t\t\t\t    &acrtc->dm_irq_params.vrr_params);\n\n\t\t\t\tdc_stream_adjust_vmin_vmax(\n\t\t\t\t    adev->dm.dc,\n\t\t\t\t    acrtc->dm_irq_params.stream,\n\t\t\t\t    &acrtc->dm_irq_params.vrr_params.adjust);\n\t\t\t\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n\t\t\t}\n\t\t}\n\t}\n}\n\n \nstatic void dm_crtc_high_irq(void *interrupt_params)\n{\n\tstruct common_irq_params *irq_params = interrupt_params;\n\tstruct amdgpu_device *adev = irq_params->adev;\n\tstruct amdgpu_crtc *acrtc;\n\tunsigned long flags;\n\tint vrr_active;\n\n\tacrtc = get_crtc_by_otg_inst(adev, irq_params->irq_src - IRQ_TYPE_VBLANK);\n\tif (!acrtc)\n\t\treturn;\n\n\tvrr_active = amdgpu_dm_crtc_vrr_active_irq(acrtc);\n\n\tDC_LOG_VBLANK(\"crtc:%d, vupdate-vrr:%d, planes:%d\\n\", acrtc->crtc_id,\n\t\t      vrr_active, acrtc->dm_irq_params.active_planes);\n\n\t \n\tif (!vrr_active)\n\t\tamdgpu_dm_crtc_handle_vblank(acrtc);\n\n\t \n\tamdgpu_dm_crtc_handle_crc_irq(&acrtc->base);\n\n\t \n\tif (adev->family < AMDGPU_FAMILY_AI)\n\t\treturn;\n\n\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\n\tif (acrtc->dm_irq_params.stream &&\n\t    acrtc->dm_irq_params.vrr_params.supported &&\n\t    acrtc->dm_irq_params.freesync_config.state ==\n\t\t    VRR_STATE_ACTIVE_VARIABLE) {\n\t\tmod_freesync_handle_v_update(adev->dm.freesync_module,\n\t\t\t\t\t     acrtc->dm_irq_params.stream,\n\t\t\t\t\t     &acrtc->dm_irq_params.vrr_params);\n\n\t\tdc_stream_adjust_vmin_vmax(adev->dm.dc, acrtc->dm_irq_params.stream,\n\t\t\t\t\t   &acrtc->dm_irq_params.vrr_params.adjust);\n\t}\n\n\t \n\tif (adev->family >= AMDGPU_FAMILY_RV &&\n\t    acrtc->pflip_status == AMDGPU_FLIP_SUBMITTED &&\n\t    acrtc->dm_irq_params.active_planes == 0) {\n\t\tif (acrtc->event) {\n\t\t\tdrm_crtc_send_vblank_event(&acrtc->base, acrtc->event);\n\t\t\tacrtc->event = NULL;\n\t\t\tdrm_crtc_vblank_put(&acrtc->base);\n\t\t}\n\t\tacrtc->pflip_status = AMDGPU_FLIP_NONE;\n\t}\n\n\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n}\n\n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n \nstatic void dm_dcn_vertical_interrupt0_high_irq(void *interrupt_params)\n{\n\tstruct common_irq_params *irq_params = interrupt_params;\n\tstruct amdgpu_device *adev = irq_params->adev;\n\tstruct amdgpu_crtc *acrtc;\n\n\tacrtc = get_crtc_by_otg_inst(adev, irq_params->irq_src - IRQ_TYPE_VLINE0);\n\n\tif (!acrtc)\n\t\treturn;\n\n\tamdgpu_dm_crtc_handle_crc_window_irq(&acrtc->base);\n}\n#endif  \n\n \nstatic void dmub_aux_setconfig_callback(struct amdgpu_device *adev,\n\t\t\t\t\tstruct dmub_notification *notify)\n{\n\tif (adev->dm.dmub_notify)\n\t\tmemcpy(adev->dm.dmub_notify, notify, sizeof(struct dmub_notification));\n\tif (notify->type == DMUB_NOTIFICATION_AUX_REPLY)\n\t\tcomplete(&adev->dm.dmub_aux_transfer_done);\n}\n\n \nstatic void dmub_hpd_callback(struct amdgpu_device *adev,\n\t\t\t      struct dmub_notification *notify)\n{\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct amdgpu_dm_connector *hpd_aconnector = NULL;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\tstruct dc_link *link;\n\tu8 link_index = 0;\n\tstruct drm_device *dev;\n\n\tif (adev == NULL)\n\t\treturn;\n\n\tif (notify == NULL) {\n\t\tDRM_ERROR(\"DMUB HPD callback notification was NULL\");\n\t\treturn;\n\t}\n\n\tif (notify->link_index > adev->dm.dc->link_count) {\n\t\tDRM_ERROR(\"DMUB HPD index (%u)is abnormal\", notify->link_index);\n\t\treturn;\n\t}\n\n\tlink_index = notify->link_index;\n\tlink = adev->dm.dc->links[link_index];\n\tdev = adev->dm.ddev;\n\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\tif (link && aconnector->dc_link == link) {\n\t\t\tif (notify->type == DMUB_NOTIFICATION_HPD)\n\t\t\t\tDRM_INFO(\"DMUB HPD callback: link_index=%u\\n\", link_index);\n\t\t\telse if (notify->type == DMUB_NOTIFICATION_HPD_IRQ)\n\t\t\t\tDRM_INFO(\"DMUB HPD IRQ callback: link_index=%u\\n\", link_index);\n\t\t\telse\n\t\t\t\tDRM_WARN(\"DMUB Unknown HPD callback type %d, link_index=%u\\n\",\n\t\t\t\t\t\tnotify->type, link_index);\n\n\t\t\thpd_aconnector = aconnector;\n\t\t\tbreak;\n\t\t}\n\t}\n\tdrm_connector_list_iter_end(&iter);\n\n\tif (hpd_aconnector) {\n\t\tif (notify->type == DMUB_NOTIFICATION_HPD)\n\t\t\thandle_hpd_irq_helper(hpd_aconnector);\n\t\telse if (notify->type == DMUB_NOTIFICATION_HPD_IRQ)\n\t\t\thandle_hpd_rx_irq(hpd_aconnector);\n\t}\n}\n\n \nstatic bool register_dmub_notify_callback(struct amdgpu_device *adev,\n\t\t\t\t\t  enum dmub_notification_type type,\n\t\t\t\t\t  dmub_notify_interrupt_callback_t callback,\n\t\t\t\t\t  bool dmub_int_thread_offload)\n{\n\tif (callback != NULL && type < ARRAY_SIZE(adev->dm.dmub_thread_offload)) {\n\t\tadev->dm.dmub_callback[type] = callback;\n\t\tadev->dm.dmub_thread_offload[type] = dmub_int_thread_offload;\n\t} else\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic void dm_handle_hpd_work(struct work_struct *work)\n{\n\tstruct dmub_hpd_work *dmub_hpd_wrk;\n\n\tdmub_hpd_wrk = container_of(work, struct dmub_hpd_work, handle_hpd_work);\n\n\tif (!dmub_hpd_wrk->dmub_notify) {\n\t\tDRM_ERROR(\"dmub_hpd_wrk dmub_notify is NULL\");\n\t\treturn;\n\t}\n\n\tif (dmub_hpd_wrk->dmub_notify->type < ARRAY_SIZE(dmub_hpd_wrk->adev->dm.dmub_callback)) {\n\t\tdmub_hpd_wrk->adev->dm.dmub_callback[dmub_hpd_wrk->dmub_notify->type](dmub_hpd_wrk->adev,\n\t\tdmub_hpd_wrk->dmub_notify);\n\t}\n\n\tkfree(dmub_hpd_wrk->dmub_notify);\n\tkfree(dmub_hpd_wrk);\n\n}\n\n#define DMUB_TRACE_MAX_READ 64\n \nstatic void dm_dmub_outbox1_low_irq(void *interrupt_params)\n{\n\tstruct dmub_notification notify;\n\tstruct common_irq_params *irq_params = interrupt_params;\n\tstruct amdgpu_device *adev = irq_params->adev;\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\tstruct dmcub_trace_buf_entry entry = { 0 };\n\tu32 count = 0;\n\tstruct dmub_hpd_work *dmub_hpd_wrk;\n\tstruct dc_link *plink = NULL;\n\n\tif (dc_enable_dmub_notifications(adev->dm.dc) &&\n\t\tirq_params->irq_src == DC_IRQ_SOURCE_DMCUB_OUTBOX) {\n\n\t\tdo {\n\t\t\tdc_stat_get_dmub_notification(adev->dm.dc, &notify);\n\t\t\tif (notify.type >= ARRAY_SIZE(dm->dmub_thread_offload)) {\n\t\t\t\tDRM_ERROR(\"DM: notify type %d invalid!\", notify.type);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!dm->dmub_callback[notify.type]) {\n\t\t\t\tDRM_DEBUG_DRIVER(\"DMUB notification skipped, no handler: type=%d\\n\", notify.type);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (dm->dmub_thread_offload[notify.type] == true) {\n\t\t\t\tdmub_hpd_wrk = kzalloc(sizeof(*dmub_hpd_wrk), GFP_ATOMIC);\n\t\t\t\tif (!dmub_hpd_wrk) {\n\t\t\t\t\tDRM_ERROR(\"Failed to allocate dmub_hpd_wrk\");\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tdmub_hpd_wrk->dmub_notify = kmemdup(&notify, sizeof(struct dmub_notification),\n\t\t\t\t\t\t\t\t    GFP_ATOMIC);\n\t\t\t\tif (!dmub_hpd_wrk->dmub_notify) {\n\t\t\t\t\tkfree(dmub_hpd_wrk);\n\t\t\t\t\tDRM_ERROR(\"Failed to allocate dmub_hpd_wrk->dmub_notify\");\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tINIT_WORK(&dmub_hpd_wrk->handle_hpd_work, dm_handle_hpd_work);\n\t\t\t\tdmub_hpd_wrk->adev = adev;\n\t\t\t\tif (notify.type == DMUB_NOTIFICATION_HPD) {\n\t\t\t\t\tplink = adev->dm.dc->links[notify.link_index];\n\t\t\t\t\tif (plink) {\n\t\t\t\t\t\tplink->hpd_status =\n\t\t\t\t\t\t\tnotify.hpd_status == DP_HPD_PLUG;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tqueue_work(adev->dm.delayed_hpd_wq, &dmub_hpd_wrk->handle_hpd_work);\n\t\t\t} else {\n\t\t\t\tdm->dmub_callback[notify.type](adev, &notify);\n\t\t\t}\n\t\t} while (notify.pending_notification);\n\t}\n\n\n\tdo {\n\t\tif (dc_dmub_srv_get_dmub_outbox0_msg(dm->dc, &entry)) {\n\t\t\ttrace_amdgpu_dmub_trace_high_irq(entry.trace_code, entry.tick_count,\n\t\t\t\t\t\t\tentry.param0, entry.param1);\n\n\t\t\tDRM_DEBUG_DRIVER(\"trace_code:%u, tick_count:%u, param0:%u, param1:%u\\n\",\n\t\t\t\t entry.trace_code, entry.tick_count, entry.param0, entry.param1);\n\t\t} else\n\t\t\tbreak;\n\n\t\tcount++;\n\n\t} while (count <= DMUB_TRACE_MAX_READ);\n\n\tif (count > DMUB_TRACE_MAX_READ)\n\t\tDRM_DEBUG_DRIVER(\"Warning : count > DMUB_TRACE_MAX_READ\");\n}\n\nstatic int dm_set_clockgating_state(void *handle,\n\t\t  enum amd_clockgating_state state)\n{\n\treturn 0;\n}\n\nstatic int dm_set_powergating_state(void *handle,\n\t\t  enum amd_powergating_state state)\n{\n\treturn 0;\n}\n\n \nstatic int dm_early_init(void *handle);\n\n \nstatic void amdgpu_dm_fbc_init(struct drm_connector *connector)\n{\n\tstruct drm_device *dev = connector->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct dm_compressor_info *compressor = &adev->dm.compressor;\n\tstruct amdgpu_dm_connector *aconn = to_amdgpu_dm_connector(connector);\n\tstruct drm_display_mode *mode;\n\tunsigned long max_size = 0;\n\n\tif (adev->dm.dc->fbc_compressor == NULL)\n\t\treturn;\n\n\tif (aconn->dc_link->connector_signal != SIGNAL_TYPE_EDP)\n\t\treturn;\n\n\tif (compressor->bo_ptr)\n\t\treturn;\n\n\n\tlist_for_each_entry(mode, &connector->modes, head) {\n\t\tif (max_size < mode->htotal * mode->vtotal)\n\t\t\tmax_size = mode->htotal * mode->vtotal;\n\t}\n\n\tif (max_size) {\n\t\tint r = amdgpu_bo_create_kernel(adev, max_size * 4, PAGE_SIZE,\n\t\t\t    AMDGPU_GEM_DOMAIN_GTT, &compressor->bo_ptr,\n\t\t\t    &compressor->gpu_addr, &compressor->cpu_addr);\n\n\t\tif (r)\n\t\t\tDRM_ERROR(\"DM: Failed to initialize FBC\\n\");\n\t\telse {\n\t\t\tadev->dm.dc->ctx->fbc_gpu_addr = compressor->gpu_addr;\n\t\t\tDRM_INFO(\"DM: FBC alloc %lu\\n\", max_size*4);\n\t\t}\n\n\t}\n\n}\n\nstatic int amdgpu_dm_audio_component_get_eld(struct device *kdev, int port,\n\t\t\t\t\t  int pipe, bool *enabled,\n\t\t\t\t\t  unsigned char *buf, int max_bytes)\n{\n\tstruct drm_device *dev = dev_get_drvdata(kdev);\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter conn_iter;\n\tstruct amdgpu_dm_connector *aconnector;\n\tint ret = 0;\n\n\t*enabled = false;\n\n\tmutex_lock(&adev->dm.audio_lock);\n\n\tdrm_connector_list_iter_begin(dev, &conn_iter);\n\tdrm_for_each_connector_iter(connector, &conn_iter) {\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\tif (aconnector->audio_inst != port)\n\t\t\tcontinue;\n\n\t\t*enabled = true;\n\t\tret = drm_eld_size(connector->eld);\n\t\tmemcpy(buf, connector->eld, min(max_bytes, ret));\n\n\t\tbreak;\n\t}\n\tdrm_connector_list_iter_end(&conn_iter);\n\n\tmutex_unlock(&adev->dm.audio_lock);\n\n\tDRM_DEBUG_KMS(\"Get ELD : idx=%d ret=%d en=%d\\n\", port, ret, *enabled);\n\n\treturn ret;\n}\n\nstatic const struct drm_audio_component_ops amdgpu_dm_audio_component_ops = {\n\t.get_eld = amdgpu_dm_audio_component_get_eld,\n};\n\nstatic int amdgpu_dm_audio_component_bind(struct device *kdev,\n\t\t\t\t       struct device *hda_kdev, void *data)\n{\n\tstruct drm_device *dev = dev_get_drvdata(kdev);\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct drm_audio_component *acomp = data;\n\n\tacomp->ops = &amdgpu_dm_audio_component_ops;\n\tacomp->dev = kdev;\n\tadev->dm.audio_component = acomp;\n\n\treturn 0;\n}\n\nstatic void amdgpu_dm_audio_component_unbind(struct device *kdev,\n\t\t\t\t\t  struct device *hda_kdev, void *data)\n{\n\tstruct drm_device *dev = dev_get_drvdata(kdev);\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct drm_audio_component *acomp = data;\n\n\tacomp->ops = NULL;\n\tacomp->dev = NULL;\n\tadev->dm.audio_component = NULL;\n}\n\nstatic const struct component_ops amdgpu_dm_audio_component_bind_ops = {\n\t.bind\t= amdgpu_dm_audio_component_bind,\n\t.unbind\t= amdgpu_dm_audio_component_unbind,\n};\n\nstatic int amdgpu_dm_audio_init(struct amdgpu_device *adev)\n{\n\tint i, ret;\n\n\tif (!amdgpu_audio)\n\t\treturn 0;\n\n\tadev->mode_info.audio.enabled = true;\n\n\tadev->mode_info.audio.num_pins = adev->dm.dc->res_pool->audio_count;\n\n\tfor (i = 0; i < adev->mode_info.audio.num_pins; i++) {\n\t\tadev->mode_info.audio.pin[i].channels = -1;\n\t\tadev->mode_info.audio.pin[i].rate = -1;\n\t\tadev->mode_info.audio.pin[i].bits_per_sample = -1;\n\t\tadev->mode_info.audio.pin[i].status_bits = 0;\n\t\tadev->mode_info.audio.pin[i].category_code = 0;\n\t\tadev->mode_info.audio.pin[i].connected = false;\n\t\tadev->mode_info.audio.pin[i].id =\n\t\t\tadev->dm.dc->res_pool->audios[i]->inst;\n\t\tadev->mode_info.audio.pin[i].offset = 0;\n\t}\n\n\tret = component_add(adev->dev, &amdgpu_dm_audio_component_bind_ops);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tadev->dm.audio_registered = true;\n\n\treturn 0;\n}\n\nstatic void amdgpu_dm_audio_fini(struct amdgpu_device *adev)\n{\n\tif (!amdgpu_audio)\n\t\treturn;\n\n\tif (!adev->mode_info.audio.enabled)\n\t\treturn;\n\n\tif (adev->dm.audio_registered) {\n\t\tcomponent_del(adev->dev, &amdgpu_dm_audio_component_bind_ops);\n\t\tadev->dm.audio_registered = false;\n\t}\n\n\t \n\n\tadev->mode_info.audio.enabled = false;\n}\n\nstatic  void amdgpu_dm_audio_eld_notify(struct amdgpu_device *adev, int pin)\n{\n\tstruct drm_audio_component *acomp = adev->dm.audio_component;\n\n\tif (acomp && acomp->audio_ops && acomp->audio_ops->pin_eld_notify) {\n\t\tDRM_DEBUG_KMS(\"Notify ELD: %d\\n\", pin);\n\n\t\tacomp->audio_ops->pin_eld_notify(acomp->audio_ops->audio_ptr,\n\t\t\t\t\t\t pin, -1);\n\t}\n}\n\nstatic int dm_dmub_hw_init(struct amdgpu_device *adev)\n{\n\tconst struct dmcub_firmware_header_v1_0 *hdr;\n\tstruct dmub_srv *dmub_srv = adev->dm.dmub_srv;\n\tstruct dmub_srv_fb_info *fb_info = adev->dm.dmub_fb_info;\n\tconst struct firmware *dmub_fw = adev->dm.dmub_fw;\n\tstruct dmcu *dmcu = adev->dm.dc->res_pool->dmcu;\n\tstruct abm *abm = adev->dm.dc->res_pool->abm;\n\tstruct dmub_srv_hw_params hw_params;\n\tenum dmub_status status;\n\tconst unsigned char *fw_inst_const, *fw_bss_data;\n\tu32 i, fw_inst_const_size, fw_bss_data_size;\n\tbool has_hw_support;\n\n\tif (!dmub_srv)\n\t\t \n\t\treturn 0;\n\n\tif (!fb_info) {\n\t\tDRM_ERROR(\"No framebuffer info for DMUB service.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!dmub_fw) {\n\t\t \n\t\tDRM_ERROR(\"No firmware provided for DMUB.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tstatus = dmub_srv_has_hw_support(dmub_srv, &has_hw_support);\n\tif (status != DMUB_STATUS_OK) {\n\t\tDRM_ERROR(\"Error checking HW support for DMUB: %d\\n\", status);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!has_hw_support) {\n\t\tDRM_INFO(\"DMUB unsupported on ASIC\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tstatus = dmub_srv_hw_reset(dmub_srv);\n\tif (status != DMUB_STATUS_OK)\n\t\tDRM_WARN(\"Error resetting DMUB HW: %d\\n\", status);\n\n\thdr = (const struct dmcub_firmware_header_v1_0 *)dmub_fw->data;\n\n\tfw_inst_const = dmub_fw->data +\n\t\t\tle32_to_cpu(hdr->header.ucode_array_offset_bytes) +\n\t\t\tPSP_HEADER_BYTES;\n\n\tfw_bss_data = dmub_fw->data +\n\t\t      le32_to_cpu(hdr->header.ucode_array_offset_bytes) +\n\t\t      le32_to_cpu(hdr->inst_const_bytes);\n\n\t \n\tfw_inst_const_size = le32_to_cpu(hdr->inst_const_bytes) -\n\t\t\t     PSP_HEADER_BYTES - PSP_FOOTER_BYTES;\n\n\tfw_bss_data_size = le32_to_cpu(hdr->bss_data_bytes);\n\n\t \n\tif (adev->firmware.load_type != AMDGPU_FW_LOAD_PSP) {\n\t\tmemcpy(fb_info->fb[DMUB_WINDOW_0_INST_CONST].cpu_addr, fw_inst_const,\n\t\t\t\tfw_inst_const_size);\n\t}\n\n\tif (fw_bss_data_size)\n\t\tmemcpy(fb_info->fb[DMUB_WINDOW_2_BSS_DATA].cpu_addr,\n\t\t       fw_bss_data, fw_bss_data_size);\n\n\t \n\tmemcpy(fb_info->fb[DMUB_WINDOW_3_VBIOS].cpu_addr, adev->bios,\n\t       adev->bios_size);\n\n\t \n\tmemset(fb_info->fb[DMUB_WINDOW_4_MAILBOX].cpu_addr, 0,\n\tfb_info->fb[DMUB_WINDOW_4_MAILBOX].size);\n\n\tmemset(fb_info->fb[DMUB_WINDOW_5_TRACEBUFF].cpu_addr, 0,\n\t       fb_info->fb[DMUB_WINDOW_5_TRACEBUFF].size);\n\n\tmemset(fb_info->fb[DMUB_WINDOW_6_FW_STATE].cpu_addr, 0,\n\t       fb_info->fb[DMUB_WINDOW_6_FW_STATE].size);\n\n\t \n\tmemset(&hw_params, 0, sizeof(hw_params));\n\thw_params.fb_base = adev->gmc.fb_start;\n\thw_params.fb_offset = adev->vm_manager.vram_base_offset;\n\n\t \n\tif (adev->firmware.load_type != AMDGPU_FW_LOAD_PSP)\n\t\thw_params.load_inst_const = true;\n\n\tif (dmcu)\n\t\thw_params.psp_version = dmcu->psp_version;\n\n\tfor (i = 0; i < fb_info->num_fb; ++i)\n\t\thw_params.fb[i] = &fb_info->fb[i];\n\n\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\tcase IP_VERSION(3, 1, 3):\n\tcase IP_VERSION(3, 1, 4):\n\t\thw_params.dpia_supported = true;\n\t\thw_params.disable_dpia = adev->dm.dc->debug.dpia_debug.bits.disable_dpia;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tstatus = dmub_srv_hw_init(dmub_srv, &hw_params);\n\tif (status != DMUB_STATUS_OK) {\n\t\tDRM_ERROR(\"Error initializing DMUB HW: %d\\n\", status);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tstatus = dmub_srv_wait_for_auto_load(dmub_srv, 100000);\n\tif (status != DMUB_STATUS_OK)\n\t\tDRM_WARN(\"Wait for DMUB auto-load failed: %d\\n\", status);\n\n\t \n\tif (dmcu && abm) {\n\t\tdmcu->funcs->dmcu_init(dmcu);\n\t\tabm->dmcu_is_running = dmcu->funcs->is_dmcu_initialized(dmcu);\n\t}\n\n\tif (!adev->dm.dc->ctx->dmub_srv)\n\t\tadev->dm.dc->ctx->dmub_srv = dc_dmub_srv_create(adev->dm.dc, dmub_srv);\n\tif (!adev->dm.dc->ctx->dmub_srv) {\n\t\tDRM_ERROR(\"Couldn't allocate DC DMUB server!\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tDRM_INFO(\"DMUB hardware initialized: version=0x%08X\\n\",\n\t\t adev->dm.dmcub_fw_version);\n\n\treturn 0;\n}\n\nstatic void dm_dmub_hw_resume(struct amdgpu_device *adev)\n{\n\tstruct dmub_srv *dmub_srv = adev->dm.dmub_srv;\n\tenum dmub_status status;\n\tbool init;\n\n\tif (!dmub_srv) {\n\t\t \n\t\treturn;\n\t}\n\n\tstatus = dmub_srv_is_hw_init(dmub_srv, &init);\n\tif (status != DMUB_STATUS_OK)\n\t\tDRM_WARN(\"DMUB hardware init check failed: %d\\n\", status);\n\n\tif (status == DMUB_STATUS_OK && init) {\n\t\t \n\t\tstatus = dmub_srv_wait_for_auto_load(dmub_srv, 100000);\n\t\tif (status != DMUB_STATUS_OK)\n\t\t\tDRM_WARN(\"Wait for DMUB auto-load failed: %d\\n\", status);\n\t} else {\n\t\t \n\t\tdm_dmub_hw_init(adev);\n\t}\n}\n\nstatic void mmhub_read_system_context(struct amdgpu_device *adev, struct dc_phy_addr_space_config *pa_config)\n{\n\tu64 pt_base;\n\tu32 logical_addr_low;\n\tu32 logical_addr_high;\n\tu32 agp_base, agp_bot, agp_top;\n\tPHYSICAL_ADDRESS_LOC page_table_start, page_table_end, page_table_base;\n\n\tmemset(pa_config, 0, sizeof(*pa_config));\n\n\tagp_base = 0;\n\tagp_bot = adev->gmc.agp_start >> 24;\n\tagp_top = adev->gmc.agp_end >> 24;\n\n\t \n\tif (agp_bot == agp_top) {\n\t\tlogical_addr_low = adev->gmc.fb_start >> 18;\n\t\tif (adev->apu_flags & AMD_APU_IS_RAVEN2)\n\t\t\t \n\t\t\tlogical_addr_high = (adev->gmc.fb_end >> 18) + 0x1;\n\t\telse\n\t\t\tlogical_addr_high = adev->gmc.fb_end >> 18;\n\t} else {\n\t\tlogical_addr_low = min(adev->gmc.fb_start, adev->gmc.agp_start) >> 18;\n\t\tif (adev->apu_flags & AMD_APU_IS_RAVEN2)\n\t\t\t \n\t\t\tlogical_addr_high = max((adev->gmc.fb_end >> 18) + 0x1, adev->gmc.agp_end >> 18);\n\t\telse\n\t\t\tlogical_addr_high = max(adev->gmc.fb_end, adev->gmc.agp_end) >> 18;\n\t}\n\n\tpt_base = amdgpu_gmc_pd_addr(adev->gart.bo);\n\n\tpage_table_start.high_part = upper_32_bits(adev->gmc.gart_start >>\n\t\t\t\t\t\t   AMDGPU_GPU_PAGE_SHIFT);\n\tpage_table_start.low_part = lower_32_bits(adev->gmc.gart_start >>\n\t\t\t\t\t\t  AMDGPU_GPU_PAGE_SHIFT);\n\tpage_table_end.high_part = upper_32_bits(adev->gmc.gart_end >>\n\t\t\t\t\t\t AMDGPU_GPU_PAGE_SHIFT);\n\tpage_table_end.low_part = lower_32_bits(adev->gmc.gart_end >>\n\t\t\t\t\t\tAMDGPU_GPU_PAGE_SHIFT);\n\tpage_table_base.high_part = upper_32_bits(pt_base);\n\tpage_table_base.low_part = lower_32_bits(pt_base);\n\n\tpa_config->system_aperture.start_addr = (uint64_t)logical_addr_low << 18;\n\tpa_config->system_aperture.end_addr = (uint64_t)logical_addr_high << 18;\n\n\tpa_config->system_aperture.agp_base = (uint64_t)agp_base << 24;\n\tpa_config->system_aperture.agp_bot = (uint64_t)agp_bot << 24;\n\tpa_config->system_aperture.agp_top = (uint64_t)agp_top << 24;\n\n\tpa_config->system_aperture.fb_base = adev->gmc.fb_start;\n\tpa_config->system_aperture.fb_offset = adev->vm_manager.vram_base_offset;\n\tpa_config->system_aperture.fb_top = adev->gmc.fb_end;\n\n\tpa_config->gart_config.page_table_start_addr = page_table_start.quad_part << 12;\n\tpa_config->gart_config.page_table_end_addr = page_table_end.quad_part << 12;\n\tpa_config->gart_config.page_table_base_addr = page_table_base.quad_part;\n\n\tpa_config->is_hvm_enabled = adev->mode_info.gpu_vm_support;\n\n}\n\nstatic void force_connector_state(\n\tstruct amdgpu_dm_connector *aconnector,\n\tenum drm_connector_force force_state)\n{\n\tstruct drm_connector *connector = &aconnector->base;\n\n\tmutex_lock(&connector->dev->mode_config.mutex);\n\taconnector->base.force = force_state;\n\tmutex_unlock(&connector->dev->mode_config.mutex);\n\n\tmutex_lock(&aconnector->hpd_lock);\n\tdrm_kms_helper_connector_hotplug_event(connector);\n\tmutex_unlock(&aconnector->hpd_lock);\n}\n\nstatic void dm_handle_hpd_rx_offload_work(struct work_struct *work)\n{\n\tstruct hpd_rx_irq_offload_work *offload_work;\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct dc_link *dc_link;\n\tstruct amdgpu_device *adev;\n\tenum dc_connection_type new_connection_type = dc_connection_none;\n\tunsigned long flags;\n\tunion test_response test_response;\n\n\tmemset(&test_response, 0, sizeof(test_response));\n\n\toffload_work = container_of(work, struct hpd_rx_irq_offload_work, work);\n\taconnector = offload_work->offload_wq->aconnector;\n\n\tif (!aconnector) {\n\t\tDRM_ERROR(\"Can't retrieve aconnector in hpd_rx_irq_offload_work\");\n\t\tgoto skip;\n\t}\n\n\tadev = drm_to_adev(aconnector->base.dev);\n\tdc_link = aconnector->dc_link;\n\n\tmutex_lock(&aconnector->hpd_lock);\n\tif (!dc_link_detect_connection_type(dc_link, &new_connection_type))\n\t\tDRM_ERROR(\"KMS: Failed to detect connector\\n\");\n\tmutex_unlock(&aconnector->hpd_lock);\n\n\tif (new_connection_type == dc_connection_none)\n\t\tgoto skip;\n\n\tif (amdgpu_in_reset(adev))\n\t\tgoto skip;\n\n\tif (offload_work->data.bytes.device_service_irq.bits.UP_REQ_MSG_RDY ||\n\t\toffload_work->data.bytes.device_service_irq.bits.DOWN_REP_MSG_RDY) {\n\t\tdm_handle_mst_sideband_msg_ready_event(&aconnector->mst_mgr, DOWN_OR_UP_MSG_RDY_EVENT);\n\t\tspin_lock_irqsave(&offload_work->offload_wq->offload_lock, flags);\n\t\toffload_work->offload_wq->is_handling_mst_msg_rdy_event = false;\n\t\tspin_unlock_irqrestore(&offload_work->offload_wq->offload_lock, flags);\n\t\tgoto skip;\n\t}\n\n\tmutex_lock(&adev->dm.dc_lock);\n\tif (offload_work->data.bytes.device_service_irq.bits.AUTOMATED_TEST) {\n\t\tdc_link_dp_handle_automated_test(dc_link);\n\n\t\tif (aconnector->timing_changed) {\n\t\t\t \n\t\t\tforce_connector_state(aconnector, DRM_FORCE_OFF);\n\t\t\tmsleep(100);\n\t\t\tforce_connector_state(aconnector, DRM_FORCE_UNSPECIFIED);\n\t\t}\n\n\t\ttest_response.bits.ACK = 1;\n\n\t\tcore_link_write_dpcd(\n\t\tdc_link,\n\t\tDP_TEST_RESPONSE,\n\t\t&test_response.raw,\n\t\tsizeof(test_response));\n\t} else if ((dc_link->connector_signal != SIGNAL_TYPE_EDP) &&\n\t\t\tdc_link_check_link_loss_status(dc_link, &offload_work->data) &&\n\t\t\tdc_link_dp_allow_hpd_rx_irq(dc_link)) {\n\t\t \n\t\tunion hpd_irq_data irq_data;\n\n\t\tmemset(&irq_data, 0, sizeof(irq_data));\n\n\t\t \n\t\tspin_lock_irqsave(&offload_work->offload_wq->offload_lock, flags);\n\t\toffload_work->offload_wq->is_handling_link_loss = false;\n\t\tspin_unlock_irqrestore(&offload_work->offload_wq->offload_lock, flags);\n\n\t\tif ((dc_link_dp_read_hpd_rx_irq_data(dc_link, &irq_data) == DC_OK) &&\n\t\t\tdc_link_check_link_loss_status(dc_link, &irq_data))\n\t\t\tdc_link_dp_handle_link_loss(dc_link);\n\t}\n\tmutex_unlock(&adev->dm.dc_lock);\n\nskip:\n\tkfree(offload_work);\n\n}\n\nstatic struct hpd_rx_irq_offload_work_queue *hpd_rx_irq_create_workqueue(struct dc *dc)\n{\n\tint max_caps = dc->caps.max_links;\n\tint i = 0;\n\tstruct hpd_rx_irq_offload_work_queue *hpd_rx_offload_wq = NULL;\n\n\thpd_rx_offload_wq = kcalloc(max_caps, sizeof(*hpd_rx_offload_wq), GFP_KERNEL);\n\n\tif (!hpd_rx_offload_wq)\n\t\treturn NULL;\n\n\n\tfor (i = 0; i < max_caps; i++) {\n\t\thpd_rx_offload_wq[i].wq =\n\t\t\t\t    create_singlethread_workqueue(\"amdgpu_dm_hpd_rx_offload_wq\");\n\n\t\tif (hpd_rx_offload_wq[i].wq == NULL) {\n\t\t\tDRM_ERROR(\"create amdgpu_dm_hpd_rx_offload_wq fail!\");\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tspin_lock_init(&hpd_rx_offload_wq[i].offload_lock);\n\t}\n\n\treturn hpd_rx_offload_wq;\n\nout_err:\n\tfor (i = 0; i < max_caps; i++) {\n\t\tif (hpd_rx_offload_wq[i].wq)\n\t\t\tdestroy_workqueue(hpd_rx_offload_wq[i].wq);\n\t}\n\tkfree(hpd_rx_offload_wq);\n\treturn NULL;\n}\n\nstruct amdgpu_stutter_quirk {\n\tu16 chip_vendor;\n\tu16 chip_device;\n\tu16 subsys_vendor;\n\tu16 subsys_device;\n\tu8 revision;\n};\n\nstatic const struct amdgpu_stutter_quirk amdgpu_stutter_quirk_list[] = {\n\t \n\t{ 0x1002, 0x15dd, 0x1002, 0x15dd, 0xc8 },\n\t{ 0, 0, 0, 0, 0 },\n};\n\nstatic bool dm_should_disable_stutter(struct pci_dev *pdev)\n{\n\tconst struct amdgpu_stutter_quirk *p = amdgpu_stutter_quirk_list;\n\n\twhile (p && p->chip_device != 0) {\n\t\tif (pdev->vendor == p->chip_vendor &&\n\t\t    pdev->device == p->chip_device &&\n\t\t    pdev->subsystem_vendor == p->subsys_vendor &&\n\t\t    pdev->subsystem_device == p->subsys_device &&\n\t\t    pdev->revision == p->revision) {\n\t\t\treturn true;\n\t\t}\n\t\t++p;\n\t}\n\treturn false;\n}\n\nstatic const struct dmi_system_id hpd_disconnect_quirk_table[] = {\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"Precision 3660\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"Precision 3260\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"Precision 3460\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"OptiPlex Tower Plus 7010\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"OptiPlex Tower 7010\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"OptiPlex SFF Plus 7010\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"OptiPlex SFF 7010\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"OptiPlex Micro Plus 7010\"),\n\t\t},\n\t},\n\t{\n\t\t.matches = {\n\t\t\tDMI_MATCH(DMI_SYS_VENDOR, \"Dell Inc.\"),\n\t\t\tDMI_MATCH(DMI_PRODUCT_NAME, \"OptiPlex Micro 7010\"),\n\t\t},\n\t},\n\t{}\n\t \n};\n\nstatic void retrieve_dmi_info(struct amdgpu_display_manager *dm)\n{\n\tconst struct dmi_system_id *dmi_id;\n\n\tdm->aux_hpd_discon_quirk = false;\n\n\tdmi_id = dmi_first_match(hpd_disconnect_quirk_table);\n\tif (dmi_id) {\n\t\tdm->aux_hpd_discon_quirk = true;\n\t\tDRM_INFO(\"aux_hpd_discon_quirk attached\\n\");\n\t}\n}\n\nstatic int amdgpu_dm_init(struct amdgpu_device *adev)\n{\n\tstruct dc_init_data init_data;\n\tstruct dc_callback_init init_params;\n\tint r;\n\n\tadev->dm.ddev = adev_to_drm(adev);\n\tadev->dm.adev = adev;\n\n\t \n\tmemset(&init_data, 0, sizeof(init_data));\n\tmemset(&init_params, 0, sizeof(init_params));\n\n\tmutex_init(&adev->dm.dpia_aux_lock);\n\tmutex_init(&adev->dm.dc_lock);\n\tmutex_init(&adev->dm.audio_lock);\n\n\tif (amdgpu_dm_irq_init(adev)) {\n\t\tDRM_ERROR(\"amdgpu: failed to initialize DM IRQ support.\\n\");\n\t\tgoto error;\n\t}\n\n\tinit_data.asic_id.chip_family = adev->family;\n\n\tinit_data.asic_id.pci_revision_id = adev->pdev->revision;\n\tinit_data.asic_id.hw_internal_rev = adev->external_rev_id;\n\tinit_data.asic_id.chip_id = adev->pdev->device;\n\n\tinit_data.asic_id.vram_width = adev->gmc.vram_width;\n\t \n\tinit_data.asic_id.atombios_base_address =\n\t\tadev->mode_info.atom_context->bios;\n\n\tinit_data.driver = adev;\n\n\tadev->dm.cgs_device = amdgpu_cgs_create_device(adev);\n\n\tif (!adev->dm.cgs_device) {\n\t\tDRM_ERROR(\"amdgpu: failed to create cgs device.\\n\");\n\t\tgoto error;\n\t}\n\n\tinit_data.cgs_device = adev->dm.cgs_device;\n\n\tinit_data.dce_environment = DCE_ENV_PRODUCTION_DRV;\n\n\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\tcase IP_VERSION(2, 1, 0):\n\t\tswitch (adev->dm.dmcub_fw_version) {\n\t\tcase 0:  \n\t\tcase 0x1:  \n\t\tcase 0x01000000:  \n\t\t\tinit_data.flags.disable_dmcu = false;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tinit_data.flags.disable_dmcu = true;\n\t\t}\n\t\tbreak;\n\tcase IP_VERSION(2, 0, 3):\n\t\tinit_data.flags.disable_dmcu = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tswitch (adev->asic_type) {\n\tcase CHIP_CARRIZO:\n\tcase CHIP_STONEY:\n\t\tinit_data.flags.gpu_vm_support = true;\n\t\tbreak;\n\tdefault:\n\t\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\t\tcase IP_VERSION(1, 0, 0):\n\t\tcase IP_VERSION(1, 0, 1):\n\t\t\t \n\t\t\tif ((adev->apu_flags & AMD_APU_IS_RAVEN2) ||\n\t\t\t    (adev->apu_flags & AMD_APU_IS_PICASSO))\n\t\t\t\tinit_data.flags.gpu_vm_support = true;\n\t\t\tbreak;\n\t\tcase IP_VERSION(2, 1, 0):\n\t\tcase IP_VERSION(3, 0, 1):\n\t\tcase IP_VERSION(3, 1, 2):\n\t\tcase IP_VERSION(3, 1, 3):\n\t\tcase IP_VERSION(3, 1, 4):\n\t\tcase IP_VERSION(3, 1, 5):\n\t\tcase IP_VERSION(3, 1, 6):\n\t\t\tinit_data.flags.gpu_vm_support = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t}\n\tif (init_data.flags.gpu_vm_support &&\n\t    (amdgpu_sg_display == 0))\n\t\tinit_data.flags.gpu_vm_support = false;\n\n\tif (init_data.flags.gpu_vm_support)\n\t\tadev->mode_info.gpu_vm_support = true;\n\n\tif (amdgpu_dc_feature_mask & DC_FBC_MASK)\n\t\tinit_data.flags.fbc_support = true;\n\n\tif (amdgpu_dc_feature_mask & DC_MULTI_MON_PP_MCLK_SWITCH_MASK)\n\t\tinit_data.flags.multi_mon_pp_mclk_switch = true;\n\n\tif (amdgpu_dc_feature_mask & DC_DISABLE_FRACTIONAL_PWM_MASK)\n\t\tinit_data.flags.disable_fractional_pwm = true;\n\n\tif (amdgpu_dc_feature_mask & DC_EDP_NO_POWER_SEQUENCING)\n\t\tinit_data.flags.edp_no_power_sequencing = true;\n\n\tif (amdgpu_dc_feature_mask & DC_DISABLE_LTTPR_DP1_4A)\n\t\tinit_data.flags.allow_lttpr_non_transparent_mode.bits.DP1_4A = true;\n\tif (amdgpu_dc_feature_mask & DC_DISABLE_LTTPR_DP2_0)\n\t\tinit_data.flags.allow_lttpr_non_transparent_mode.bits.DP2_0 = true;\n\n\tinit_data.flags.seamless_boot_edp_requested = false;\n\n\tif (check_seamless_boot_capability(adev)) {\n\t\tinit_data.flags.seamless_boot_edp_requested = true;\n\t\tinit_data.flags.allow_seamless_boot_optimization = true;\n\t\tDRM_INFO(\"Seamless boot condition check passed\\n\");\n\t}\n\n\tinit_data.flags.enable_mipi_converter_optimization = true;\n\n\tinit_data.dcn_reg_offsets = adev->reg_offset[DCE_HWIP][0];\n\tinit_data.nbio_reg_offsets = adev->reg_offset[NBIO_HWIP][0];\n\n\tINIT_LIST_HEAD(&adev->dm.da_list);\n\n\tretrieve_dmi_info(&adev->dm);\n\n\t \n\tadev->dm.dc = dc_create(&init_data);\n\n\tif (adev->dm.dc) {\n\t\tDRM_INFO(\"Display Core v%s initialized on %s\\n\", DC_VER,\n\t\t\t dce_version_to_string(adev->dm.dc->ctx->dce_version));\n\t} else {\n\t\tDRM_INFO(\"Display Core failed to initialize with v%s!\\n\", DC_VER);\n\t\tgoto error;\n\t}\n\n\tif (amdgpu_dc_debug_mask & DC_DISABLE_PIPE_SPLIT) {\n\t\tadev->dm.dc->debug.force_single_disp_pipe_split = false;\n\t\tadev->dm.dc->debug.pipe_split_policy = MPC_SPLIT_AVOID;\n\t}\n\n\tif (adev->asic_type != CHIP_CARRIZO && adev->asic_type != CHIP_STONEY)\n\t\tadev->dm.dc->debug.disable_stutter = amdgpu_pp_feature_mask & PP_STUTTER_MODE ? false : true;\n\tif (dm_should_disable_stutter(adev->pdev))\n\t\tadev->dm.dc->debug.disable_stutter = true;\n\n\tif (amdgpu_dc_debug_mask & DC_DISABLE_STUTTER)\n\t\tadev->dm.dc->debug.disable_stutter = true;\n\n\tif (amdgpu_dc_debug_mask & DC_DISABLE_DSC)\n\t\tadev->dm.dc->debug.disable_dsc = true;\n\n\tif (amdgpu_dc_debug_mask & DC_DISABLE_CLOCK_GATING)\n\t\tadev->dm.dc->debug.disable_clock_gate = true;\n\n\tif (amdgpu_dc_debug_mask & DC_FORCE_SUBVP_MCLK_SWITCH)\n\t\tadev->dm.dc->debug.force_subvp_mclk_switch = true;\n\n\tadev->dm.dc->debug.visual_confirm = amdgpu_dc_visual_confirm;\n\n\t \n\tadev->dm.dc->debug.ignore_cable_id = true;\n\n\t \n\tadev->dm.dc->debug.temp_mst_deallocation_sequence = true;\n\n\tif (adev->dm.dc->caps.dp_hdmi21_pcon_support)\n\t\tDRM_INFO(\"DP-HDMI FRL PCON supported\\n\");\n\n\tr = dm_dmub_hw_init(adev);\n\tif (r) {\n\t\tDRM_ERROR(\"DMUB interface failed to initialize: status=%d\\n\", r);\n\t\tgoto error;\n\t}\n\n\tdc_hardware_init(adev->dm.dc);\n\n\tadev->dm.hpd_rx_offload_wq = hpd_rx_irq_create_workqueue(adev->dm.dc);\n\tif (!adev->dm.hpd_rx_offload_wq) {\n\t\tDRM_ERROR(\"amdgpu: failed to create hpd rx offload workqueue.\\n\");\n\t\tgoto error;\n\t}\n\n\tif ((adev->flags & AMD_IS_APU) && (adev->asic_type >= CHIP_CARRIZO)) {\n\t\tstruct dc_phy_addr_space_config pa_config;\n\n\t\tmmhub_read_system_context(adev, &pa_config);\n\n\t\t \n\t\tdc_setup_system_context(adev->dm.dc, &pa_config);\n\t}\n\n\tadev->dm.freesync_module = mod_freesync_create(adev->dm.dc);\n\tif (!adev->dm.freesync_module) {\n\t\tDRM_ERROR(\n\t\t\"amdgpu: failed to initialize freesync_module.\\n\");\n\t} else\n\t\tDRM_DEBUG_DRIVER(\"amdgpu: freesync_module init done %p.\\n\",\n\t\t\t\tadev->dm.freesync_module);\n\n\tamdgpu_dm_init_color_mod();\n\n\tif (adev->dm.dc->caps.max_links > 0) {\n\t\tadev->dm.vblank_control_workqueue =\n\t\t\tcreate_singlethread_workqueue(\"dm_vblank_control_workqueue\");\n\t\tif (!adev->dm.vblank_control_workqueue)\n\t\t\tDRM_ERROR(\"amdgpu: failed to initialize vblank_workqueue.\\n\");\n\t}\n\n\tif (adev->dm.dc->caps.max_links > 0 && adev->family >= AMDGPU_FAMILY_RV) {\n\t\tadev->dm.hdcp_workqueue = hdcp_create_workqueue(adev, &init_params.cp_psp, adev->dm.dc);\n\n\t\tif (!adev->dm.hdcp_workqueue)\n\t\t\tDRM_ERROR(\"amdgpu: failed to initialize hdcp_workqueue.\\n\");\n\t\telse\n\t\t\tDRM_DEBUG_DRIVER(\"amdgpu: hdcp_workqueue init done %p.\\n\", adev->dm.hdcp_workqueue);\n\n\t\tdc_init_callbacks(adev->dm.dc, &init_params);\n\t}\n\tif (dc_is_dmub_outbox_supported(adev->dm.dc)) {\n\t\tinit_completion(&adev->dm.dmub_aux_transfer_done);\n\t\tadev->dm.dmub_notify = kzalloc(sizeof(struct dmub_notification), GFP_KERNEL);\n\t\tif (!adev->dm.dmub_notify) {\n\t\t\tDRM_INFO(\"amdgpu: fail to allocate adev->dm.dmub_notify\");\n\t\t\tgoto error;\n\t\t}\n\n\t\tadev->dm.delayed_hpd_wq = create_singlethread_workqueue(\"amdgpu_dm_hpd_wq\");\n\t\tif (!adev->dm.delayed_hpd_wq) {\n\t\t\tDRM_ERROR(\"amdgpu: failed to create hpd offload workqueue.\\n\");\n\t\t\tgoto error;\n\t\t}\n\n\t\tamdgpu_dm_outbox_init(adev);\n\t\tif (!register_dmub_notify_callback(adev, DMUB_NOTIFICATION_AUX_REPLY,\n\t\t\tdmub_aux_setconfig_callback, false)) {\n\t\t\tDRM_ERROR(\"amdgpu: fail to register dmub aux callback\");\n\t\t\tgoto error;\n\t\t}\n\t\tif (!register_dmub_notify_callback(adev, DMUB_NOTIFICATION_HPD, dmub_hpd_callback, true)) {\n\t\t\tDRM_ERROR(\"amdgpu: fail to register dmub hpd callback\");\n\t\t\tgoto error;\n\t\t}\n\t\tif (!register_dmub_notify_callback(adev, DMUB_NOTIFICATION_HPD_IRQ, dmub_hpd_callback, true)) {\n\t\t\tDRM_ERROR(\"amdgpu: fail to register dmub hpd callback\");\n\t\t\tgoto error;\n\t\t}\n\t}\n\n\t \n\tif (dc_is_dmub_outbox_supported(adev->dm.dc)) {\n\t\tdc_enable_dmub_outbox(adev->dm.dc);\n\n\t\t \n\t\tif (amdgpu_dc_debug_mask & DC_ENABLE_DPIA_TRACE)\n\t\t\tdc_dmub_srv_enable_dpia_trace(adev->dm.dc);\n\t}\n\n\tif (amdgpu_dm_initialize_drm_device(adev)) {\n\t\tDRM_ERROR(\n\t\t\"amdgpu: failed to initialize sw for display support.\\n\");\n\t\tgoto error;\n\t}\n\n\t \n\tdm_dp_create_fake_mst_encoders(adev);\n\n\t \n\n\t \n\tadev_to_drm(adev)->mode_config.cursor_width = adev->dm.dc->caps.max_cursor_size;\n\tadev_to_drm(adev)->mode_config.cursor_height = adev->dm.dc->caps.max_cursor_size;\n\n\tif (drm_vblank_init(adev_to_drm(adev), adev->dm.display_indexes_num)) {\n\t\tDRM_ERROR(\n\t\t\"amdgpu: failed to initialize sw for display support.\\n\");\n\t\tgoto error;\n\t}\n\n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n\tadev->dm.secure_display_ctxs = amdgpu_dm_crtc_secure_display_create_contexts(adev);\n\tif (!adev->dm.secure_display_ctxs)\n\t\tDRM_ERROR(\"amdgpu: failed to initialize secure display contexts.\\n\");\n#endif\n\n\tDRM_DEBUG_DRIVER(\"KMS initialized.\\n\");\n\n\treturn 0;\nerror:\n\tamdgpu_dm_fini(adev);\n\n\treturn -EINVAL;\n}\n\nstatic int amdgpu_dm_early_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tamdgpu_dm_audio_fini(adev);\n\n\treturn 0;\n}\n\nstatic void amdgpu_dm_fini(struct amdgpu_device *adev)\n{\n\tint i;\n\n\tif (adev->dm.vblank_control_workqueue) {\n\t\tdestroy_workqueue(adev->dm.vblank_control_workqueue);\n\t\tadev->dm.vblank_control_workqueue = NULL;\n\t}\n\n\tamdgpu_dm_destroy_drm_device(&adev->dm);\n\n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n\tif (adev->dm.secure_display_ctxs) {\n\t\tfor (i = 0; i < adev->mode_info.num_crtc; i++) {\n\t\t\tif (adev->dm.secure_display_ctxs[i].crtc) {\n\t\t\t\tflush_work(&adev->dm.secure_display_ctxs[i].notify_ta_work);\n\t\t\t\tflush_work(&adev->dm.secure_display_ctxs[i].forward_roi_work);\n\t\t\t}\n\t\t}\n\t\tkfree(adev->dm.secure_display_ctxs);\n\t\tadev->dm.secure_display_ctxs = NULL;\n\t}\n#endif\n\tif (adev->dm.hdcp_workqueue) {\n\t\thdcp_destroy(&adev->dev->kobj, adev->dm.hdcp_workqueue);\n\t\tadev->dm.hdcp_workqueue = NULL;\n\t}\n\n\tif (adev->dm.dc)\n\t\tdc_deinit_callbacks(adev->dm.dc);\n\n\tif (adev->dm.dc)\n\t\tdc_dmub_srv_destroy(&adev->dm.dc->ctx->dmub_srv);\n\n\tif (dc_enable_dmub_notifications(adev->dm.dc)) {\n\t\tkfree(adev->dm.dmub_notify);\n\t\tadev->dm.dmub_notify = NULL;\n\t\tdestroy_workqueue(adev->dm.delayed_hpd_wq);\n\t\tadev->dm.delayed_hpd_wq = NULL;\n\t}\n\n\tif (adev->dm.dmub_bo)\n\t\tamdgpu_bo_free_kernel(&adev->dm.dmub_bo,\n\t\t\t\t      &adev->dm.dmub_bo_gpu_addr,\n\t\t\t\t      &adev->dm.dmub_bo_cpu_addr);\n\n\tif (adev->dm.hpd_rx_offload_wq) {\n\t\tfor (i = 0; i < adev->dm.dc->caps.max_links; i++) {\n\t\t\tif (adev->dm.hpd_rx_offload_wq[i].wq) {\n\t\t\t\tdestroy_workqueue(adev->dm.hpd_rx_offload_wq[i].wq);\n\t\t\t\tadev->dm.hpd_rx_offload_wq[i].wq = NULL;\n\t\t\t}\n\t\t}\n\n\t\tkfree(adev->dm.hpd_rx_offload_wq);\n\t\tadev->dm.hpd_rx_offload_wq = NULL;\n\t}\n\n\t \n\tif (adev->dm.dc)\n\t\tdc_destroy(&adev->dm.dc);\n\t \n\n\tif (adev->dm.cgs_device) {\n\t\tamdgpu_cgs_destroy_device(adev->dm.cgs_device);\n\t\tadev->dm.cgs_device = NULL;\n\t}\n\tif (adev->dm.freesync_module) {\n\t\tmod_freesync_destroy(adev->dm.freesync_module);\n\t\tadev->dm.freesync_module = NULL;\n\t}\n\n\tmutex_destroy(&adev->dm.audio_lock);\n\tmutex_destroy(&adev->dm.dc_lock);\n\tmutex_destroy(&adev->dm.dpia_aux_lock);\n}\n\nstatic int load_dmcu_fw(struct amdgpu_device *adev)\n{\n\tconst char *fw_name_dmcu = NULL;\n\tint r;\n\tconst struct dmcu_firmware_header_v1_0 *hdr;\n\n\tswitch (adev->asic_type) {\n#if defined(CONFIG_DRM_AMD_DC_SI)\n\tcase CHIP_TAHITI:\n\tcase CHIP_PITCAIRN:\n\tcase CHIP_VERDE:\n\tcase CHIP_OLAND:\n#endif\n\tcase CHIP_BONAIRE:\n\tcase CHIP_HAWAII:\n\tcase CHIP_KAVERI:\n\tcase CHIP_KABINI:\n\tcase CHIP_MULLINS:\n\tcase CHIP_TONGA:\n\tcase CHIP_FIJI:\n\tcase CHIP_CARRIZO:\n\tcase CHIP_STONEY:\n\tcase CHIP_POLARIS11:\n\tcase CHIP_POLARIS10:\n\tcase CHIP_POLARIS12:\n\tcase CHIP_VEGAM:\n\tcase CHIP_VEGA10:\n\tcase CHIP_VEGA12:\n\tcase CHIP_VEGA20:\n\t\treturn 0;\n\tcase CHIP_NAVI12:\n\t\tfw_name_dmcu = FIRMWARE_NAVI12_DMCU;\n\t\tbreak;\n\tcase CHIP_RAVEN:\n\t\tif (ASICREV_IS_PICASSO(adev->external_rev_id))\n\t\t\tfw_name_dmcu = FIRMWARE_RAVEN_DMCU;\n\t\telse if (ASICREV_IS_RAVEN2(adev->external_rev_id))\n\t\t\tfw_name_dmcu = FIRMWARE_RAVEN_DMCU;\n\t\telse\n\t\t\treturn 0;\n\t\tbreak;\n\tdefault:\n\t\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\t\tcase IP_VERSION(2, 0, 2):\n\t\tcase IP_VERSION(2, 0, 3):\n\t\tcase IP_VERSION(2, 0, 0):\n\t\tcase IP_VERSION(2, 1, 0):\n\t\tcase IP_VERSION(3, 0, 0):\n\t\tcase IP_VERSION(3, 0, 2):\n\t\tcase IP_VERSION(3, 0, 3):\n\t\tcase IP_VERSION(3, 0, 1):\n\t\tcase IP_VERSION(3, 1, 2):\n\t\tcase IP_VERSION(3, 1, 3):\n\t\tcase IP_VERSION(3, 1, 4):\n\t\tcase IP_VERSION(3, 1, 5):\n\t\tcase IP_VERSION(3, 1, 6):\n\t\tcase IP_VERSION(3, 2, 0):\n\t\tcase IP_VERSION(3, 2, 1):\n\t\t\treturn 0;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tDRM_ERROR(\"Unsupported ASIC type: 0x%X\\n\", adev->asic_type);\n\t\treturn -EINVAL;\n\t}\n\n\tif (adev->firmware.load_type != AMDGPU_FW_LOAD_PSP) {\n\t\tDRM_DEBUG_KMS(\"dm: DMCU firmware not supported on direct or SMU loading\\n\");\n\t\treturn 0;\n\t}\n\n\tr = amdgpu_ucode_request(adev, &adev->dm.fw_dmcu, fw_name_dmcu);\n\tif (r == -ENODEV) {\n\t\t \n\t\tDRM_DEBUG_KMS(\"dm: DMCU firmware not found\\n\");\n\t\tadev->dm.fw_dmcu = NULL;\n\t\treturn 0;\n\t}\n\tif (r) {\n\t\tdev_err(adev->dev, \"amdgpu_dm: Can't validate firmware \\\"%s\\\"\\n\",\n\t\t\tfw_name_dmcu);\n\t\tamdgpu_ucode_release(&adev->dm.fw_dmcu);\n\t\treturn r;\n\t}\n\n\thdr = (const struct dmcu_firmware_header_v1_0 *)adev->dm.fw_dmcu->data;\n\tadev->firmware.ucode[AMDGPU_UCODE_ID_DMCU_ERAM].ucode_id = AMDGPU_UCODE_ID_DMCU_ERAM;\n\tadev->firmware.ucode[AMDGPU_UCODE_ID_DMCU_ERAM].fw = adev->dm.fw_dmcu;\n\tadev->firmware.fw_size +=\n\t\tALIGN(le32_to_cpu(hdr->header.ucode_size_bytes) - le32_to_cpu(hdr->intv_size_bytes), PAGE_SIZE);\n\n\tadev->firmware.ucode[AMDGPU_UCODE_ID_DMCU_INTV].ucode_id = AMDGPU_UCODE_ID_DMCU_INTV;\n\tadev->firmware.ucode[AMDGPU_UCODE_ID_DMCU_INTV].fw = adev->dm.fw_dmcu;\n\tadev->firmware.fw_size +=\n\t\tALIGN(le32_to_cpu(hdr->intv_size_bytes), PAGE_SIZE);\n\n\tadev->dm.dmcu_fw_version = le32_to_cpu(hdr->header.ucode_version);\n\n\tDRM_DEBUG_KMS(\"PSP loading DMCU firmware\\n\");\n\n\treturn 0;\n}\n\nstatic uint32_t amdgpu_dm_dmub_reg_read(void *ctx, uint32_t address)\n{\n\tstruct amdgpu_device *adev = ctx;\n\n\treturn dm_read_reg(adev->dm.dc->ctx, address);\n}\n\nstatic void amdgpu_dm_dmub_reg_write(void *ctx, uint32_t address,\n\t\t\t\t     uint32_t value)\n{\n\tstruct amdgpu_device *adev = ctx;\n\n\treturn dm_write_reg(adev->dm.dc->ctx, address, value);\n}\n\nstatic int dm_dmub_sw_init(struct amdgpu_device *adev)\n{\n\tstruct dmub_srv_create_params create_params;\n\tstruct dmub_srv_region_params region_params;\n\tstruct dmub_srv_region_info region_info;\n\tstruct dmub_srv_memory_params memory_params;\n\tstruct dmub_srv_fb_info *fb_info;\n\tstruct dmub_srv *dmub_srv;\n\tconst struct dmcub_firmware_header_v1_0 *hdr;\n\tenum dmub_asic dmub_asic;\n\tenum dmub_status status;\n\tint r;\n\n\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\tcase IP_VERSION(2, 1, 0):\n\t\tdmub_asic = DMUB_ASIC_DCN21;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 0):\n\t\tdmub_asic = DMUB_ASIC_DCN30;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 1):\n\t\tdmub_asic = DMUB_ASIC_DCN301;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 2):\n\t\tdmub_asic = DMUB_ASIC_DCN302;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 3):\n\t\tdmub_asic = DMUB_ASIC_DCN303;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 2):\n\tcase IP_VERSION(3, 1, 3):\n\t\tdmub_asic = (adev->external_rev_id == YELLOW_CARP_B0) ? DMUB_ASIC_DCN31B : DMUB_ASIC_DCN31;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 4):\n\t\tdmub_asic = DMUB_ASIC_DCN314;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 5):\n\t\tdmub_asic = DMUB_ASIC_DCN315;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 6):\n\t\tdmub_asic = DMUB_ASIC_DCN316;\n\t\tbreak;\n\tcase IP_VERSION(3, 2, 0):\n\t\tdmub_asic = DMUB_ASIC_DCN32;\n\t\tbreak;\n\tcase IP_VERSION(3, 2, 1):\n\t\tdmub_asic = DMUB_ASIC_DCN321;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn 0;\n\t}\n\n\thdr = (const struct dmcub_firmware_header_v1_0 *)adev->dm.dmub_fw->data;\n\tadev->dm.dmcub_fw_version = le32_to_cpu(hdr->header.ucode_version);\n\n\tif (adev->firmware.load_type == AMDGPU_FW_LOAD_PSP) {\n\t\tadev->firmware.ucode[AMDGPU_UCODE_ID_DMCUB].ucode_id =\n\t\t\tAMDGPU_UCODE_ID_DMCUB;\n\t\tadev->firmware.ucode[AMDGPU_UCODE_ID_DMCUB].fw =\n\t\t\tadev->dm.dmub_fw;\n\t\tadev->firmware.fw_size +=\n\t\t\tALIGN(le32_to_cpu(hdr->inst_const_bytes), PAGE_SIZE);\n\n\t\tDRM_INFO(\"Loading DMUB firmware via PSP: version=0x%08X\\n\",\n\t\t\t adev->dm.dmcub_fw_version);\n\t}\n\n\n\tadev->dm.dmub_srv = kzalloc(sizeof(*adev->dm.dmub_srv), GFP_KERNEL);\n\tdmub_srv = adev->dm.dmub_srv;\n\n\tif (!dmub_srv) {\n\t\tDRM_ERROR(\"Failed to allocate DMUB service!\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(&create_params, 0, sizeof(create_params));\n\tcreate_params.user_ctx = adev;\n\tcreate_params.funcs.reg_read = amdgpu_dm_dmub_reg_read;\n\tcreate_params.funcs.reg_write = amdgpu_dm_dmub_reg_write;\n\tcreate_params.asic = dmub_asic;\n\n\t \n\tstatus = dmub_srv_create(dmub_srv, &create_params);\n\tif (status != DMUB_STATUS_OK) {\n\t\tDRM_ERROR(\"Error creating DMUB service: %d\\n\", status);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tmemset(&region_params, 0, sizeof(region_params));\n\n\tregion_params.inst_const_size = le32_to_cpu(hdr->inst_const_bytes) -\n\t\t\t\t\tPSP_HEADER_BYTES - PSP_FOOTER_BYTES;\n\tregion_params.bss_data_size = le32_to_cpu(hdr->bss_data_bytes);\n\tregion_params.vbios_size = adev->bios_size;\n\tregion_params.fw_bss_data = region_params.bss_data_size ?\n\t\tadev->dm.dmub_fw->data +\n\t\tle32_to_cpu(hdr->header.ucode_array_offset_bytes) +\n\t\tle32_to_cpu(hdr->inst_const_bytes) : NULL;\n\tregion_params.fw_inst_const =\n\t\tadev->dm.dmub_fw->data +\n\t\tle32_to_cpu(hdr->header.ucode_array_offset_bytes) +\n\t\tPSP_HEADER_BYTES;\n\tregion_params.is_mailbox_in_inbox = false;\n\n\tstatus = dmub_srv_calc_region_info(dmub_srv, &region_params,\n\t\t\t\t\t   &region_info);\n\n\tif (status != DMUB_STATUS_OK) {\n\t\tDRM_ERROR(\"Error calculating DMUB region info: %d\\n\", status);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tr = amdgpu_bo_create_kernel(adev, region_info.fb_size, PAGE_SIZE,\n\t\t\t\t    AMDGPU_GEM_DOMAIN_VRAM |\n\t\t\t\t    AMDGPU_GEM_DOMAIN_GTT,\n\t\t\t\t    &adev->dm.dmub_bo,\n\t\t\t\t    &adev->dm.dmub_bo_gpu_addr,\n\t\t\t\t    &adev->dm.dmub_bo_cpu_addr);\n\tif (r)\n\t\treturn r;\n\n\t \n\tmemset(&memory_params, 0, sizeof(memory_params));\n\tmemory_params.cpu_fb_addr = adev->dm.dmub_bo_cpu_addr;\n\tmemory_params.gpu_fb_addr = adev->dm.dmub_bo_gpu_addr;\n\tmemory_params.region_info = &region_info;\n\n\tadev->dm.dmub_fb_info =\n\t\tkzalloc(sizeof(*adev->dm.dmub_fb_info), GFP_KERNEL);\n\tfb_info = adev->dm.dmub_fb_info;\n\n\tif (!fb_info) {\n\t\tDRM_ERROR(\n\t\t\t\"Failed to allocate framebuffer info for DMUB service!\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tstatus = dmub_srv_calc_mem_info(dmub_srv, &memory_params, fb_info);\n\tif (status != DMUB_STATUS_OK) {\n\t\tDRM_ERROR(\"Error calculating DMUB FB info: %d\\n\", status);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int dm_sw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tint r;\n\n\tr = dm_dmub_sw_init(adev);\n\tif (r)\n\t\treturn r;\n\n\treturn load_dmcu_fw(adev);\n}\n\nstatic int dm_sw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tkfree(adev->dm.dmub_fb_info);\n\tadev->dm.dmub_fb_info = NULL;\n\n\tif (adev->dm.dmub_srv) {\n\t\tdmub_srv_destroy(adev->dm.dmub_srv);\n\t\tadev->dm.dmub_srv = NULL;\n\t}\n\n\tamdgpu_ucode_release(&adev->dm.dmub_fw);\n\tamdgpu_ucode_release(&adev->dm.fw_dmcu);\n\n\treturn 0;\n}\n\nstatic int detect_mst_link_for_all_connectors(struct drm_device *dev)\n{\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\tint ret = 0;\n\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\tif (aconnector->dc_link->type == dc_connection_mst_branch &&\n\t\t    aconnector->mst_mgr.aux) {\n\t\t\tDRM_DEBUG_DRIVER(\"DM_MST: starting TM on aconnector: %p [id: %d]\\n\",\n\t\t\t\t\t aconnector,\n\t\t\t\t\t aconnector->base.base.id);\n\n\t\t\tret = drm_dp_mst_topology_mgr_set_mst(&aconnector->mst_mgr, true);\n\t\t\tif (ret < 0) {\n\t\t\t\tDRM_ERROR(\"DM_MST: Failed to start MST\\n\");\n\t\t\t\taconnector->dc_link->type =\n\t\t\t\t\tdc_connection_single;\n\t\t\t\tret = dm_helpers_dp_mst_stop_top_mgr(aconnector->dc_link->ctx,\n\t\t\t\t\t\t\t\t     aconnector->dc_link);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tdrm_connector_list_iter_end(&iter);\n\n\treturn ret;\n}\n\nstatic int dm_late_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tstruct dmcu_iram_parameters params;\n\tunsigned int linear_lut[16];\n\tint i;\n\tstruct dmcu *dmcu = NULL;\n\n\tdmcu = adev->dm.dc->res_pool->dmcu;\n\n\tfor (i = 0; i < 16; i++)\n\t\tlinear_lut[i] = 0xFFFF * i / 15;\n\n\tparams.set = 0;\n\tparams.backlight_ramping_override = false;\n\tparams.backlight_ramping_start = 0xCCCC;\n\tparams.backlight_ramping_reduction = 0xCCCCCCCC;\n\tparams.backlight_lut_array_size = 16;\n\tparams.backlight_lut_array = linear_lut;\n\n\t \n\tparams.min_abm_backlight = 0x28F;\n\t \n\tif (dmcu) {\n\t\tif (!dmcu_load_iram(dmcu, params))\n\t\t\treturn -EINVAL;\n\t} else if (adev->dm.dc->ctx->dmub_srv) {\n\t\tstruct dc_link *edp_links[MAX_NUM_EDP];\n\t\tint edp_num;\n\n\t\tdc_get_edp_links(adev->dm.dc, edp_links, &edp_num);\n\t\tfor (i = 0; i < edp_num; i++) {\n\t\t\tif (!dmub_init_abm_config(adev->dm.dc->res_pool, params, i))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn detect_mst_link_for_all_connectors(adev_to_drm(adev));\n}\n\nstatic void resume_mst_branch_status(struct drm_dp_mst_topology_mgr *mgr)\n{\n\tint ret;\n\tu8 guid[16];\n\tu64 tmp64;\n\n\tmutex_lock(&mgr->lock);\n\tif (!mgr->mst_primary)\n\t\tgoto out_fail;\n\n\tif (drm_dp_read_dpcd_caps(mgr->aux, mgr->dpcd) < 0) {\n\t\tdrm_dbg_kms(mgr->dev, \"dpcd read failed - undocked during suspend?\\n\");\n\t\tgoto out_fail;\n\t}\n\n\tret = drm_dp_dpcd_writeb(mgr->aux, DP_MSTM_CTRL,\n\t\t\t\t DP_MST_EN |\n\t\t\t\t DP_UP_REQ_EN |\n\t\t\t\t DP_UPSTREAM_IS_SRC);\n\tif (ret < 0) {\n\t\tdrm_dbg_kms(mgr->dev, \"mst write failed - undocked during suspend?\\n\");\n\t\tgoto out_fail;\n\t}\n\n\t \n\tret = drm_dp_dpcd_read(mgr->aux, DP_GUID, guid, 16);\n\tif (ret != 16) {\n\t\tdrm_dbg_kms(mgr->dev, \"dpcd read failed - undocked during suspend?\\n\");\n\t\tgoto out_fail;\n\t}\n\n\tif (memchr_inv(guid, 0, 16) == NULL) {\n\t\ttmp64 = get_jiffies_64();\n\t\tmemcpy(&guid[0], &tmp64, sizeof(u64));\n\t\tmemcpy(&guid[8], &tmp64, sizeof(u64));\n\n\t\tret = drm_dp_dpcd_write(mgr->aux, DP_GUID, guid, 16);\n\n\t\tif (ret != 16) {\n\t\t\tdrm_dbg_kms(mgr->dev, \"check mstb guid failed - undocked during suspend?\\n\");\n\t\t\tgoto out_fail;\n\t\t}\n\t}\n\n\tmemcpy(mgr->mst_primary->guid, guid, 16);\n\nout_fail:\n\tmutex_unlock(&mgr->lock);\n}\n\nstatic void s3_handle_mst(struct drm_device *dev, bool suspend)\n{\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\tstruct drm_dp_mst_topology_mgr *mgr;\n\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\tif (aconnector->dc_link->type != dc_connection_mst_branch ||\n\t\t    aconnector->mst_root)\n\t\t\tcontinue;\n\n\t\tmgr = &aconnector->mst_mgr;\n\n\t\tif (suspend) {\n\t\t\tdrm_dp_mst_topology_mgr_suspend(mgr);\n\t\t} else {\n\t\t\t \n\t\t\ttry_to_configure_aux_timeout(aconnector->dc_link->ddc, LINK_AUX_DEFAULT_LTTPR_TIMEOUT_PERIOD);\n\t\t\tif (!dp_is_lttpr_present(aconnector->dc_link))\n\t\t\t\ttry_to_configure_aux_timeout(aconnector->dc_link->ddc, LINK_AUX_DEFAULT_TIMEOUT_PERIOD);\n\n\t\t\t \n\t\t\tresume_mst_branch_status(mgr);\n\t\t}\n\t}\n\tdrm_connector_list_iter_end(&iter);\n}\n\nstatic int amdgpu_dm_smu_write_watermarks_table(struct amdgpu_device *adev)\n{\n\tint ret = 0;\n\n\t \n\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\tcase IP_VERSION(2, 0, 2):\n\tcase IP_VERSION(2, 0, 0):\n\t\tbreak;\n\tdefault:\n\t\treturn 0;\n\t}\n\n\tret = amdgpu_dpm_write_watermarks_table(adev);\n\tif (ret) {\n\t\tDRM_ERROR(\"Failed to update WMTABLE!\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int dm_hw_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\t \n\tamdgpu_dm_init(adev);\n\tamdgpu_dm_hpd_init(adev);\n\n\treturn 0;\n}\n\n \nstatic int dm_hw_fini(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\n\tamdgpu_dm_hpd_fini(adev);\n\n\tamdgpu_dm_irq_fini(adev);\n\tamdgpu_dm_fini(adev);\n\treturn 0;\n}\n\n\nstatic void dm_gpureset_toggle_interrupts(struct amdgpu_device *adev,\n\t\t\t\t struct dc_state *state, bool enable)\n{\n\tenum dc_irq_source irq_source;\n\tstruct amdgpu_crtc *acrtc;\n\tint rc = -EBUSY;\n\tint i = 0;\n\n\tfor (i = 0; i < state->stream_count; i++) {\n\t\tacrtc = get_crtc_by_otg_inst(\n\t\t\t\tadev, state->stream_status[i].primary_otg_inst);\n\n\t\tif (acrtc && state->stream_status[i].plane_count != 0) {\n\t\t\tirq_source = IRQ_TYPE_PFLIP + acrtc->otg_inst;\n\t\t\trc = dc_interrupt_set(adev->dm.dc, irq_source, enable) ? 0 : -EBUSY;\n\t\t\tif (rc)\n\t\t\t\tDRM_WARN(\"Failed to %s pflip interrupts\\n\",\n\t\t\t\t\t enable ? \"enable\" : \"disable\");\n\n\t\t\tif (enable) {\n\t\t\t\tif (amdgpu_dm_crtc_vrr_active(to_dm_crtc_state(acrtc->base.state)))\n\t\t\t\t\trc = amdgpu_dm_crtc_set_vupdate_irq(&acrtc->base, true);\n\t\t\t} else\n\t\t\t\trc = amdgpu_dm_crtc_set_vupdate_irq(&acrtc->base, false);\n\n\t\t\tif (rc)\n\t\t\t\tDRM_WARN(\"Failed to %sable vupdate interrupt\\n\", enable ? \"en\" : \"dis\");\n\n\t\t\tirq_source = IRQ_TYPE_VBLANK + acrtc->otg_inst;\n\t\t\t \n\t\t\tif (!dc_interrupt_set(adev->dm.dc, irq_source, enable))\n\t\t\t\tDRM_WARN(\"Failed to %sable vblank interrupt\\n\", enable ? \"en\" : \"dis\");\n\t\t}\n\t}\n\n}\n\nstatic enum dc_status amdgpu_dm_commit_zero_streams(struct dc *dc)\n{\n\tstruct dc_state *context = NULL;\n\tenum dc_status res = DC_ERROR_UNEXPECTED;\n\tint i;\n\tstruct dc_stream_state *del_streams[MAX_PIPES];\n\tint del_streams_count = 0;\n\n\tmemset(del_streams, 0, sizeof(del_streams));\n\n\tcontext = dc_create_state(dc);\n\tif (context == NULL)\n\t\tgoto context_alloc_fail;\n\n\tdc_resource_state_copy_construct_current(dc, context);\n\n\t \n\tfor (i = 0; i < context->stream_count; i++) {\n\t\tstruct dc_stream_state *stream = context->streams[i];\n\n\t\tdel_streams[del_streams_count++] = stream;\n\t}\n\n\t \n\tfor (i = 0; i < del_streams_count; i++) {\n\t\tif (!dc_rem_all_planes_for_stream(dc, del_streams[i], context)) {\n\t\t\tres = DC_FAIL_DETACH_SURFACES;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tres = dc_remove_stream_from_ctx(dc, context, del_streams[i]);\n\t\tif (res != DC_OK)\n\t\t\tgoto fail;\n\t}\n\n\tres = dc_commit_streams(dc, context->streams, context->stream_count);\n\nfail:\n\tdc_release_state(context);\n\ncontext_alloc_fail:\n\treturn res;\n}\n\nstatic void hpd_rx_irq_work_suspend(struct amdgpu_display_manager *dm)\n{\n\tint i;\n\n\tif (dm->hpd_rx_offload_wq) {\n\t\tfor (i = 0; i < dm->dc->caps.max_links; i++)\n\t\t\tflush_workqueue(dm->hpd_rx_offload_wq[i].wq);\n\t}\n}\n\nstatic int dm_suspend(void *handle)\n{\n\tstruct amdgpu_device *adev = handle;\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\tint ret = 0;\n\n\tif (amdgpu_in_reset(adev)) {\n\t\tmutex_lock(&dm->dc_lock);\n\n\t\tdc_allow_idle_optimizations(adev->dm.dc, false);\n\n\t\tdm->cached_dc_state = dc_copy_state(dm->dc->current_state);\n\n\t\tdm_gpureset_toggle_interrupts(adev, dm->cached_dc_state, false);\n\n\t\tamdgpu_dm_commit_zero_streams(dm->dc);\n\n\t\tamdgpu_dm_irq_suspend(adev);\n\n\t\thpd_rx_irq_work_suspend(dm);\n\n\t\treturn ret;\n\t}\n\n\tWARN_ON(adev->dm.cached_state);\n\tadev->dm.cached_state = drm_atomic_helper_suspend(adev_to_drm(adev));\n\n\ts3_handle_mst(adev_to_drm(adev), true);\n\n\tamdgpu_dm_irq_suspend(adev);\n\n\thpd_rx_irq_work_suspend(dm);\n\n\tdc_set_power_state(dm->dc, DC_ACPI_CM_POWER_STATE_D3);\n\n\treturn 0;\n}\n\nstruct amdgpu_dm_connector *\namdgpu_dm_find_first_crtc_matching_connector(struct drm_atomic_state *state,\n\t\t\t\t\t     struct drm_crtc *crtc)\n{\n\tu32 i;\n\tstruct drm_connector_state *new_con_state;\n\tstruct drm_connector *connector;\n\tstruct drm_crtc *crtc_from_state;\n\n\tfor_each_new_connector_in_state(state, connector, new_con_state, i) {\n\t\tcrtc_from_state = new_con_state->crtc;\n\n\t\tif (crtc_from_state == crtc)\n\t\t\treturn to_amdgpu_dm_connector(connector);\n\t}\n\n\treturn NULL;\n}\n\nstatic void emulated_link_detect(struct dc_link *link)\n{\n\tstruct dc_sink_init_data sink_init_data = { 0 };\n\tstruct display_sink_capability sink_caps = { 0 };\n\tenum dc_edid_status edid_status;\n\tstruct dc_context *dc_ctx = link->ctx;\n\tstruct dc_sink *sink = NULL;\n\tstruct dc_sink *prev_sink = NULL;\n\n\tlink->type = dc_connection_none;\n\tprev_sink = link->local_sink;\n\n\tif (prev_sink)\n\t\tdc_sink_release(prev_sink);\n\n\tswitch (link->connector_signal) {\n\tcase SIGNAL_TYPE_HDMI_TYPE_A: {\n\t\tsink_caps.transaction_type = DDC_TRANSACTION_TYPE_I2C;\n\t\tsink_caps.signal = SIGNAL_TYPE_HDMI_TYPE_A;\n\t\tbreak;\n\t}\n\n\tcase SIGNAL_TYPE_DVI_SINGLE_LINK: {\n\t\tsink_caps.transaction_type = DDC_TRANSACTION_TYPE_I2C;\n\t\tsink_caps.signal = SIGNAL_TYPE_DVI_SINGLE_LINK;\n\t\tbreak;\n\t}\n\n\tcase SIGNAL_TYPE_DVI_DUAL_LINK: {\n\t\tsink_caps.transaction_type = DDC_TRANSACTION_TYPE_I2C;\n\t\tsink_caps.signal = SIGNAL_TYPE_DVI_DUAL_LINK;\n\t\tbreak;\n\t}\n\n\tcase SIGNAL_TYPE_LVDS: {\n\t\tsink_caps.transaction_type = DDC_TRANSACTION_TYPE_I2C;\n\t\tsink_caps.signal = SIGNAL_TYPE_LVDS;\n\t\tbreak;\n\t}\n\n\tcase SIGNAL_TYPE_EDP: {\n\t\tsink_caps.transaction_type =\n\t\t\tDDC_TRANSACTION_TYPE_I2C_OVER_AUX;\n\t\tsink_caps.signal = SIGNAL_TYPE_EDP;\n\t\tbreak;\n\t}\n\n\tcase SIGNAL_TYPE_DISPLAY_PORT: {\n\t\tsink_caps.transaction_type =\n\t\t\tDDC_TRANSACTION_TYPE_I2C_OVER_AUX;\n\t\tsink_caps.signal = SIGNAL_TYPE_VIRTUAL;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tDC_ERROR(\"Invalid connector type! signal:%d\\n\",\n\t\t\tlink->connector_signal);\n\t\treturn;\n\t}\n\n\tsink_init_data.link = link;\n\tsink_init_data.sink_signal = sink_caps.signal;\n\n\tsink = dc_sink_create(&sink_init_data);\n\tif (!sink) {\n\t\tDC_ERROR(\"Failed to create sink!\\n\");\n\t\treturn;\n\t}\n\n\t \n\tlink->local_sink = sink;\n\n\tedid_status = dm_helpers_read_local_edid(\n\t\t\tlink->ctx,\n\t\t\tlink,\n\t\t\tsink);\n\n\tif (edid_status != EDID_OK)\n\t\tDC_ERROR(\"Failed to read EDID\");\n\n}\n\nstatic void dm_gpureset_commit_state(struct dc_state *dc_state,\n\t\t\t\t     struct amdgpu_display_manager *dm)\n{\n\tstruct {\n\t\tstruct dc_surface_update surface_updates[MAX_SURFACES];\n\t\tstruct dc_plane_info plane_infos[MAX_SURFACES];\n\t\tstruct dc_scaling_info scaling_infos[MAX_SURFACES];\n\t\tstruct dc_flip_addrs flip_addrs[MAX_SURFACES];\n\t\tstruct dc_stream_update stream_update;\n\t} *bundle;\n\tint k, m;\n\n\tbundle = kzalloc(sizeof(*bundle), GFP_KERNEL);\n\n\tif (!bundle) {\n\t\tdm_error(\"Failed to allocate update bundle\\n\");\n\t\tgoto cleanup;\n\t}\n\n\tfor (k = 0; k < dc_state->stream_count; k++) {\n\t\tbundle->stream_update.stream = dc_state->streams[k];\n\n\t\tfor (m = 0; m < dc_state->stream_status->plane_count; m++) {\n\t\t\tbundle->surface_updates[m].surface =\n\t\t\t\tdc_state->stream_status->plane_states[m];\n\t\t\tbundle->surface_updates[m].surface->force_full_update =\n\t\t\t\ttrue;\n\t\t}\n\n\t\tupdate_planes_and_stream_adapter(dm->dc,\n\t\t\t\t\t UPDATE_TYPE_FULL,\n\t\t\t\t\t dc_state->stream_status->plane_count,\n\t\t\t\t\t dc_state->streams[k],\n\t\t\t\t\t &bundle->stream_update,\n\t\t\t\t\t bundle->surface_updates);\n\t}\n\ncleanup:\n\tkfree(bundle);\n}\n\nstatic int dm_resume(void *handle)\n{\n\tstruct amdgpu_device *adev = handle;\n\tstruct drm_device *ddev = adev_to_drm(adev);\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *new_crtc_state;\n\tstruct dm_crtc_state *dm_new_crtc_state;\n\tstruct drm_plane *plane;\n\tstruct drm_plane_state *new_plane_state;\n\tstruct dm_plane_state *dm_new_plane_state;\n\tstruct dm_atomic_state *dm_state = to_dm_atomic_state(dm->atomic_obj.state);\n\tenum dc_connection_type new_connection_type = dc_connection_none;\n\tstruct dc_state *dc_state;\n\tint i, r, j, ret;\n\tbool need_hotplug = false;\n\n\tif (amdgpu_in_reset(adev)) {\n\t\tdc_state = dm->cached_dc_state;\n\n\t\t \n\t\tlink_enc_cfg_copy(adev->dm.dc->current_state, dc_state);\n\n\t\tr = dm_dmub_hw_init(adev);\n\t\tif (r)\n\t\t\tDRM_ERROR(\"DMUB interface failed to initialize: status=%d\\n\", r);\n\n\t\tdc_set_power_state(dm->dc, DC_ACPI_CM_POWER_STATE_D0);\n\t\tdc_resume(dm->dc);\n\n\t\tamdgpu_dm_irq_resume_early(adev);\n\n\t\tfor (i = 0; i < dc_state->stream_count; i++) {\n\t\t\tdc_state->streams[i]->mode_changed = true;\n\t\t\tfor (j = 0; j < dc_state->stream_status[i].plane_count; j++) {\n\t\t\t\tdc_state->stream_status[i].plane_states[j]->update_flags.raw\n\t\t\t\t\t= 0xffffffff;\n\t\t\t}\n\t\t}\n\n\t\tif (dc_is_dmub_outbox_supported(adev->dm.dc)) {\n\t\t\tamdgpu_dm_outbox_init(adev);\n\t\t\tdc_enable_dmub_outbox(adev->dm.dc);\n\t\t}\n\n\t\tWARN_ON(!dc_commit_streams(dm->dc, dc_state->streams, dc_state->stream_count));\n\n\t\tdm_gpureset_commit_state(dm->cached_dc_state, dm);\n\n\t\tdm_gpureset_toggle_interrupts(adev, dm->cached_dc_state, true);\n\n\t\tdc_release_state(dm->cached_dc_state);\n\t\tdm->cached_dc_state = NULL;\n\n\t\tamdgpu_dm_irq_resume_late(adev);\n\n\t\tmutex_unlock(&dm->dc_lock);\n\n\t\treturn 0;\n\t}\n\t \n\tdc_release_state(dm_state->context);\n\tdm_state->context = dc_create_state(dm->dc);\n\t \n\tdc_resource_state_construct(dm->dc, dm_state->context);\n\n\t \n\tdm_dmub_hw_resume(adev);\n\n\t \n\tif (dc_is_dmub_outbox_supported(adev->dm.dc)) {\n\t\tamdgpu_dm_outbox_init(adev);\n\t\tdc_enable_dmub_outbox(adev->dm.dc);\n\t}\n\n\t \n\tdc_set_power_state(dm->dc, DC_ACPI_CM_POWER_STATE_D0);\n\n\t \n\tdc_resume(dm->dc);\n\n\t \n\tamdgpu_dm_irq_resume_early(adev);\n\n\t \n\ts3_handle_mst(ddev, false);\n\n\t \n\tdrm_connector_list_iter_begin(ddev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\n\t\tif (!aconnector->dc_link)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (aconnector && aconnector->mst_root)\n\t\t\tcontinue;\n\n\t\tmutex_lock(&aconnector->hpd_lock);\n\t\tif (!dc_link_detect_connection_type(aconnector->dc_link, &new_connection_type))\n\t\t\tDRM_ERROR(\"KMS: Failed to detect connector\\n\");\n\n\t\tif (aconnector->base.force && new_connection_type == dc_connection_none) {\n\t\t\temulated_link_detect(aconnector->dc_link);\n\t\t} else {\n\t\t\tmutex_lock(&dm->dc_lock);\n\t\t\tdc_link_detect(aconnector->dc_link, DETECT_REASON_HPD);\n\t\t\tmutex_unlock(&dm->dc_lock);\n\t\t}\n\n\t\tif (aconnector->fake_enable && aconnector->dc_link->local_sink)\n\t\t\taconnector->fake_enable = false;\n\n\t\tif (aconnector->dc_sink)\n\t\t\tdc_sink_release(aconnector->dc_sink);\n\t\taconnector->dc_sink = NULL;\n\t\tamdgpu_dm_update_connector_after_detect(aconnector);\n\t\tmutex_unlock(&aconnector->hpd_lock);\n\t}\n\tdrm_connector_list_iter_end(&iter);\n\n\t \n\tfor_each_new_crtc_in_state(dm->cached_state, crtc, new_crtc_state, i)\n\t\tnew_crtc_state->active_changed = true;\n\n\t \n\tfor_each_new_crtc_in_state(dm->cached_state, crtc, new_crtc_state, i) {\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\t\tif (dm_new_crtc_state->stream) {\n\t\t\tWARN_ON(kref_read(&dm_new_crtc_state->stream->refcount) > 1);\n\t\t\tdc_stream_release(dm_new_crtc_state->stream);\n\t\t\tdm_new_crtc_state->stream = NULL;\n\t\t}\n\t}\n\n\tfor_each_new_plane_in_state(dm->cached_state, plane, new_plane_state, i) {\n\t\tdm_new_plane_state = to_dm_plane_state(new_plane_state);\n\t\tif (dm_new_plane_state->dc_state) {\n\t\t\tWARN_ON(kref_read(&dm_new_plane_state->dc_state->refcount) > 1);\n\t\t\tdc_plane_state_release(dm_new_plane_state->dc_state);\n\t\t\tdm_new_plane_state->dc_state = NULL;\n\t\t}\n\t}\n\n\tdrm_atomic_helper_resume(ddev, dm->cached_state);\n\n\tdm->cached_state = NULL;\n\n\t \n\tdrm_connector_list_iter_begin(ddev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\tif (aconnector->dc_link->type != dc_connection_mst_branch ||\n\t\t    aconnector->mst_root)\n\t\t\tcontinue;\n\n\t\tret = drm_dp_mst_topology_mgr_resume(&aconnector->mst_mgr, true);\n\n\t\tif (ret < 0) {\n\t\t\tdm_helpers_dp_mst_stop_top_mgr(aconnector->dc_link->ctx,\n\t\t\t\t\taconnector->dc_link);\n\t\t\tneed_hotplug = true;\n\t\t}\n\t}\n\tdrm_connector_list_iter_end(&iter);\n\n\tif (need_hotplug)\n\t\tdrm_kms_helper_hotplug_event(ddev);\n\n\tamdgpu_dm_irq_resume_late(adev);\n\n\tamdgpu_dm_smu_write_watermarks_table(adev);\n\n\treturn 0;\n}\n\n \n\nstatic const struct amd_ip_funcs amdgpu_dm_funcs = {\n\t.name = \"dm\",\n\t.early_init = dm_early_init,\n\t.late_init = dm_late_init,\n\t.sw_init = dm_sw_init,\n\t.sw_fini = dm_sw_fini,\n\t.early_fini = amdgpu_dm_early_fini,\n\t.hw_init = dm_hw_init,\n\t.hw_fini = dm_hw_fini,\n\t.suspend = dm_suspend,\n\t.resume = dm_resume,\n\t.is_idle = dm_is_idle,\n\t.wait_for_idle = dm_wait_for_idle,\n\t.check_soft_reset = dm_check_soft_reset,\n\t.soft_reset = dm_soft_reset,\n\t.set_clockgating_state = dm_set_clockgating_state,\n\t.set_powergating_state = dm_set_powergating_state,\n};\n\nconst struct amdgpu_ip_block_version dm_ip_block = {\n\t.type = AMD_IP_BLOCK_TYPE_DCE,\n\t.major = 1,\n\t.minor = 0,\n\t.rev = 0,\n\t.funcs = &amdgpu_dm_funcs,\n};\n\n\n \n\nstatic const struct drm_mode_config_funcs amdgpu_dm_mode_funcs = {\n\t.fb_create = amdgpu_display_user_framebuffer_create,\n\t.get_format_info = amdgpu_dm_plane_get_format_info,\n\t.atomic_check = amdgpu_dm_atomic_check,\n\t.atomic_commit = drm_atomic_helper_commit,\n};\n\nstatic struct drm_mode_config_helper_funcs amdgpu_dm_mode_config_helperfuncs = {\n\t.atomic_commit_tail = amdgpu_dm_atomic_commit_tail,\n\t.atomic_commit_setup = drm_dp_mst_atomic_setup_commit,\n};\n\nstatic void update_connector_ext_caps(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct amdgpu_dm_backlight_caps *caps;\n\tstruct drm_connector *conn_base;\n\tstruct amdgpu_device *adev;\n\tstruct drm_luminance_range_info *luminance_range;\n\n\tif (aconnector->bl_idx == -1 ||\n\t    aconnector->dc_link->connector_signal != SIGNAL_TYPE_EDP)\n\t\treturn;\n\n\tconn_base = &aconnector->base;\n\tadev = drm_to_adev(conn_base->dev);\n\n\tcaps = &adev->dm.backlight_caps[aconnector->bl_idx];\n\tcaps->ext_caps = &aconnector->dc_link->dpcd_sink_ext_caps;\n\tcaps->aux_support = false;\n\n\tif (caps->ext_caps->bits.oled == 1\n\t     )\n\t\tcaps->aux_support = true;\n\n\tif (amdgpu_backlight == 0)\n\t\tcaps->aux_support = false;\n\telse if (amdgpu_backlight == 1)\n\t\tcaps->aux_support = true;\n\n\tluminance_range = &conn_base->display_info.luminance_range;\n\n\tif (luminance_range->max_luminance) {\n\t\tcaps->aux_min_input_signal = luminance_range->min_luminance;\n\t\tcaps->aux_max_input_signal = luminance_range->max_luminance;\n\t} else {\n\t\tcaps->aux_min_input_signal = 0;\n\t\tcaps->aux_max_input_signal = 512;\n\t}\n}\n\nvoid amdgpu_dm_update_connector_after_detect(\n\t\tstruct amdgpu_dm_connector *aconnector)\n{\n\tstruct drm_connector *connector = &aconnector->base;\n\tstruct drm_device *dev = connector->dev;\n\tstruct dc_sink *sink;\n\n\t \n\tif (aconnector->mst_mgr.mst_state == true)\n\t\treturn;\n\n\tsink = aconnector->dc_link->local_sink;\n\tif (sink)\n\t\tdc_sink_retain(sink);\n\n\t \n\tif (aconnector->base.force != DRM_FORCE_UNSPECIFIED\n\t\t\t&& aconnector->dc_em_sink) {\n\n\t\t \n\t\tmutex_lock(&dev->mode_config.mutex);\n\n\t\tif (sink) {\n\t\t\tif (aconnector->dc_sink) {\n\t\t\t\tamdgpu_dm_update_freesync_caps(connector, NULL);\n\t\t\t\t \n\t\t\t\tdc_sink_release(aconnector->dc_sink);\n\t\t\t}\n\t\t\taconnector->dc_sink = sink;\n\t\t\tdc_sink_retain(aconnector->dc_sink);\n\t\t\tamdgpu_dm_update_freesync_caps(connector,\n\t\t\t\t\taconnector->edid);\n\t\t} else {\n\t\t\tamdgpu_dm_update_freesync_caps(connector, NULL);\n\t\t\tif (!aconnector->dc_sink) {\n\t\t\t\taconnector->dc_sink = aconnector->dc_em_sink;\n\t\t\t\tdc_sink_retain(aconnector->dc_sink);\n\t\t\t}\n\t\t}\n\n\t\tmutex_unlock(&dev->mode_config.mutex);\n\n\t\tif (sink)\n\t\t\tdc_sink_release(sink);\n\t\treturn;\n\t}\n\n\t \n\tif (sink && sink->sink_signal == SIGNAL_TYPE_DISPLAY_PORT_MST) {\n\t\tdc_sink_release(sink);\n\t\treturn;\n\t}\n\n\tif (aconnector->dc_sink == sink) {\n\t\t \n\t\tDRM_DEBUG_DRIVER(\"DCHPD: connector_id=%d: dc_sink didn't change.\\n\",\n\t\t\t\taconnector->connector_id);\n\t\tif (sink)\n\t\t\tdc_sink_release(sink);\n\t\treturn;\n\t}\n\n\tDRM_DEBUG_DRIVER(\"DCHPD: connector_id=%d: Old sink=%p New sink=%p\\n\",\n\t\taconnector->connector_id, aconnector->dc_sink, sink);\n\n\tmutex_lock(&dev->mode_config.mutex);\n\n\t \n\tif (sink) {\n\t\t \n\t\tif (aconnector->dc_sink) {\n\t\t\tamdgpu_dm_update_freesync_caps(connector, NULL);\n\t\t\tdc_sink_release(aconnector->dc_sink);\n\t\t}\n\n\t\taconnector->dc_sink = sink;\n\t\tdc_sink_retain(aconnector->dc_sink);\n\t\tif (sink->dc_edid.length == 0) {\n\t\t\taconnector->edid = NULL;\n\t\t\tif (aconnector->dc_link->aux_mode) {\n\t\t\t\tdrm_dp_cec_unset_edid(\n\t\t\t\t\t&aconnector->dm_dp_aux.aux);\n\t\t\t}\n\t\t} else {\n\t\t\taconnector->edid =\n\t\t\t\t(struct edid *)sink->dc_edid.raw_edid;\n\n\t\t\tif (aconnector->dc_link->aux_mode)\n\t\t\t\tdrm_dp_cec_set_edid(&aconnector->dm_dp_aux.aux,\n\t\t\t\t\t\t    aconnector->edid);\n\t\t}\n\n\t\tif (!aconnector->timing_requested) {\n\t\t\taconnector->timing_requested =\n\t\t\t\tkzalloc(sizeof(struct dc_crtc_timing), GFP_KERNEL);\n\t\t\tif (!aconnector->timing_requested)\n\t\t\t\tdm_error(\"failed to create aconnector->requested_timing\\n\");\n\t\t}\n\n\t\tdrm_connector_update_edid_property(connector, aconnector->edid);\n\t\tamdgpu_dm_update_freesync_caps(connector, aconnector->edid);\n\t\tupdate_connector_ext_caps(aconnector);\n\t} else {\n\t\tdrm_dp_cec_unset_edid(&aconnector->dm_dp_aux.aux);\n\t\tamdgpu_dm_update_freesync_caps(connector, NULL);\n\t\tdrm_connector_update_edid_property(connector, NULL);\n\t\taconnector->num_modes = 0;\n\t\tdc_sink_release(aconnector->dc_sink);\n\t\taconnector->dc_sink = NULL;\n\t\taconnector->edid = NULL;\n\t\tkfree(aconnector->timing_requested);\n\t\taconnector->timing_requested = NULL;\n\t\t \n\t\tif (connector->state->content_protection == DRM_MODE_CONTENT_PROTECTION_ENABLED)\n\t\t\tconnector->state->content_protection = DRM_MODE_CONTENT_PROTECTION_DESIRED;\n\t}\n\n\tmutex_unlock(&dev->mode_config.mutex);\n\n\tupdate_subconnector_property(aconnector);\n\n\tif (sink)\n\t\tdc_sink_release(sink);\n}\n\nstatic void handle_hpd_irq_helper(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct drm_connector *connector = &aconnector->base;\n\tstruct drm_device *dev = connector->dev;\n\tenum dc_connection_type new_connection_type = dc_connection_none;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct dm_connector_state *dm_con_state = to_dm_connector_state(connector->state);\n\tbool ret = false;\n\n\tif (adev->dm.disable_hpd_irq)\n\t\treturn;\n\n\t \n\tmutex_lock(&aconnector->hpd_lock);\n\n\tif (adev->dm.hdcp_workqueue) {\n\t\thdcp_reset_display(adev->dm.hdcp_workqueue, aconnector->dc_link->link_index);\n\t\tdm_con_state->update_hdcp = true;\n\t}\n\tif (aconnector->fake_enable)\n\t\taconnector->fake_enable = false;\n\n\taconnector->timing_changed = false;\n\n\tif (!dc_link_detect_connection_type(aconnector->dc_link, &new_connection_type))\n\t\tDRM_ERROR(\"KMS: Failed to detect connector\\n\");\n\n\tif (aconnector->base.force && new_connection_type == dc_connection_none) {\n\t\temulated_link_detect(aconnector->dc_link);\n\n\t\tdrm_modeset_lock_all(dev);\n\t\tdm_restore_drm_connector_state(dev, connector);\n\t\tdrm_modeset_unlock_all(dev);\n\n\t\tif (aconnector->base.force == DRM_FORCE_UNSPECIFIED)\n\t\t\tdrm_kms_helper_connector_hotplug_event(connector);\n\t} else {\n\t\tmutex_lock(&adev->dm.dc_lock);\n\t\tret = dc_link_detect(aconnector->dc_link, DETECT_REASON_HPD);\n\t\tmutex_unlock(&adev->dm.dc_lock);\n\t\tif (ret) {\n\t\t\tamdgpu_dm_update_connector_after_detect(aconnector);\n\n\t\t\tdrm_modeset_lock_all(dev);\n\t\t\tdm_restore_drm_connector_state(dev, connector);\n\t\t\tdrm_modeset_unlock_all(dev);\n\n\t\t\tif (aconnector->base.force == DRM_FORCE_UNSPECIFIED)\n\t\t\t\tdrm_kms_helper_connector_hotplug_event(connector);\n\t\t}\n\t}\n\tmutex_unlock(&aconnector->hpd_lock);\n\n}\n\nstatic void handle_hpd_irq(void *param)\n{\n\tstruct amdgpu_dm_connector *aconnector = (struct amdgpu_dm_connector *)param;\n\n\thandle_hpd_irq_helper(aconnector);\n\n}\n\nstatic void schedule_hpd_rx_offload_work(struct hpd_rx_irq_offload_work_queue *offload_wq,\n\t\t\t\t\t\t\tunion hpd_irq_data hpd_irq_data)\n{\n\tstruct hpd_rx_irq_offload_work *offload_work =\n\t\t\t\tkzalloc(sizeof(*offload_work), GFP_KERNEL);\n\n\tif (!offload_work) {\n\t\tDRM_ERROR(\"Failed to allocate hpd_rx_irq_offload_work.\\n\");\n\t\treturn;\n\t}\n\n\tINIT_WORK(&offload_work->work, dm_handle_hpd_rx_offload_work);\n\toffload_work->data = hpd_irq_data;\n\toffload_work->offload_wq = offload_wq;\n\n\tqueue_work(offload_wq->wq, &offload_work->work);\n\tDRM_DEBUG_KMS(\"queue work to handle hpd_rx offload work\");\n}\n\nstatic void handle_hpd_rx_irq(void *param)\n{\n\tstruct amdgpu_dm_connector *aconnector = (struct amdgpu_dm_connector *)param;\n\tstruct drm_connector *connector = &aconnector->base;\n\tstruct drm_device *dev = connector->dev;\n\tstruct dc_link *dc_link = aconnector->dc_link;\n\tbool is_mst_root_connector = aconnector->mst_mgr.mst_state;\n\tbool result = false;\n\tenum dc_connection_type new_connection_type = dc_connection_none;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tunion hpd_irq_data hpd_irq_data;\n\tbool link_loss = false;\n\tbool has_left_work = false;\n\tint idx = dc_link->link_index;\n\tstruct hpd_rx_irq_offload_work_queue *offload_wq = &adev->dm.hpd_rx_offload_wq[idx];\n\n\tmemset(&hpd_irq_data, 0, sizeof(hpd_irq_data));\n\n\tif (adev->dm.disable_hpd_irq)\n\t\treturn;\n\n\t \n\tmutex_lock(&aconnector->hpd_lock);\n\n\tresult = dc_link_handle_hpd_rx_irq(dc_link, &hpd_irq_data,\n\t\t\t\t\t\t&link_loss, true, &has_left_work);\n\n\tif (!has_left_work)\n\t\tgoto out;\n\n\tif (hpd_irq_data.bytes.device_service_irq.bits.AUTOMATED_TEST) {\n\t\tschedule_hpd_rx_offload_work(offload_wq, hpd_irq_data);\n\t\tgoto out;\n\t}\n\n\tif (dc_link_dp_allow_hpd_rx_irq(dc_link)) {\n\t\tif (hpd_irq_data.bytes.device_service_irq.bits.UP_REQ_MSG_RDY ||\n\t\t\thpd_irq_data.bytes.device_service_irq.bits.DOWN_REP_MSG_RDY) {\n\t\t\tbool skip = false;\n\n\t\t\t \n\t\t\tspin_lock(&offload_wq->offload_lock);\n\t\t\tskip = offload_wq->is_handling_mst_msg_rdy_event;\n\n\t\t\tif (!skip)\n\t\t\t\toffload_wq->is_handling_mst_msg_rdy_event = true;\n\n\t\t\tspin_unlock(&offload_wq->offload_lock);\n\n\t\t\tif (!skip)\n\t\t\t\tschedule_hpd_rx_offload_work(offload_wq, hpd_irq_data);\n\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (link_loss) {\n\t\t\tbool skip = false;\n\n\t\t\tspin_lock(&offload_wq->offload_lock);\n\t\t\tskip = offload_wq->is_handling_link_loss;\n\n\t\t\tif (!skip)\n\t\t\t\toffload_wq->is_handling_link_loss = true;\n\n\t\t\tspin_unlock(&offload_wq->offload_lock);\n\n\t\t\tif (!skip)\n\t\t\t\tschedule_hpd_rx_offload_work(offload_wq, hpd_irq_data);\n\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tif (result && !is_mst_root_connector) {\n\t\t \n\t\tif (!dc_link_detect_connection_type(dc_link, &new_connection_type))\n\t\t\tDRM_ERROR(\"KMS: Failed to detect connector\\n\");\n\n\t\tif (aconnector->base.force && new_connection_type == dc_connection_none) {\n\t\t\temulated_link_detect(dc_link);\n\n\t\t\tif (aconnector->fake_enable)\n\t\t\t\taconnector->fake_enable = false;\n\n\t\t\tamdgpu_dm_update_connector_after_detect(aconnector);\n\n\n\t\t\tdrm_modeset_lock_all(dev);\n\t\t\tdm_restore_drm_connector_state(dev, connector);\n\t\t\tdrm_modeset_unlock_all(dev);\n\n\t\t\tdrm_kms_helper_connector_hotplug_event(connector);\n\t\t} else {\n\t\t\tbool ret = false;\n\n\t\t\tmutex_lock(&adev->dm.dc_lock);\n\t\t\tret = dc_link_detect(dc_link, DETECT_REASON_HPDRX);\n\t\t\tmutex_unlock(&adev->dm.dc_lock);\n\n\t\t\tif (ret) {\n\t\t\t\tif (aconnector->fake_enable)\n\t\t\t\t\taconnector->fake_enable = false;\n\n\t\t\t\tamdgpu_dm_update_connector_after_detect(aconnector);\n\n\t\t\t\tdrm_modeset_lock_all(dev);\n\t\t\t\tdm_restore_drm_connector_state(dev, connector);\n\t\t\t\tdrm_modeset_unlock_all(dev);\n\n\t\t\t\tdrm_kms_helper_connector_hotplug_event(connector);\n\t\t\t}\n\t\t}\n\t}\n\tif (hpd_irq_data.bytes.device_service_irq.bits.CP_IRQ) {\n\t\tif (adev->dm.hdcp_workqueue)\n\t\t\thdcp_handle_cpirq(adev->dm.hdcp_workqueue,  aconnector->base.index);\n\t}\n\n\tif (dc_link->type != dc_connection_mst_branch)\n\t\tdrm_dp_cec_irq(&aconnector->dm_dp_aux.aux);\n\n\tmutex_unlock(&aconnector->hpd_lock);\n}\n\nstatic void register_hpd_handlers(struct amdgpu_device *adev)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_connector *connector;\n\tstruct amdgpu_dm_connector *aconnector;\n\tconst struct dc_link *dc_link;\n\tstruct dc_interrupt_params int_params = {0};\n\n\tint_params.requested_polarity = INTERRUPT_POLARITY_DEFAULT;\n\tint_params.current_polarity = INTERRUPT_POLARITY_DEFAULT;\n\n\tlist_for_each_entry(connector,\n\t\t\t&dev->mode_config.connector_list, head)\t{\n\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\tdc_link = aconnector->dc_link;\n\n\t\tif (dc_link->irq_source_hpd != DC_IRQ_SOURCE_INVALID) {\n\t\t\tint_params.int_context = INTERRUPT_LOW_IRQ_CONTEXT;\n\t\t\tint_params.irq_source = dc_link->irq_source_hpd;\n\n\t\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\t\thandle_hpd_irq,\n\t\t\t\t\t(void *) aconnector);\n\t\t}\n\n\t\tif (dc_link->irq_source_hpd_rx != DC_IRQ_SOURCE_INVALID) {\n\n\t\t\t \n\t\t\tint_params.int_context = INTERRUPT_LOW_IRQ_CONTEXT;\n\t\t\tint_params.irq_source =\tdc_link->irq_source_hpd_rx;\n\n\t\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\t\thandle_hpd_rx_irq,\n\t\t\t\t\t(void *) aconnector);\n\t\t}\n\n\t\tif (adev->dm.hpd_rx_offload_wq)\n\t\t\tadev->dm.hpd_rx_offload_wq[connector->index].aconnector =\n\t\t\t\taconnector;\n\t}\n}\n\n#if defined(CONFIG_DRM_AMD_DC_SI)\n \nstatic int dce60_register_irq_handlers(struct amdgpu_device *adev)\n{\n\tstruct dc *dc = adev->dm.dc;\n\tstruct common_irq_params *c_irq_params;\n\tstruct dc_interrupt_params int_params = {0};\n\tint r;\n\tint i;\n\tunsigned int client_id = AMDGPU_IRQ_CLIENTID_LEGACY;\n\n\tint_params.requested_polarity = INTERRUPT_POLARITY_DEFAULT;\n\tint_params.current_polarity = INTERRUPT_POLARITY_DEFAULT;\n\n\t \n\n\t \n\tfor (i = 0; i < adev->mode_info.num_crtc; i++) {\n\t\tr = amdgpu_irq_add_id(adev, client_id, i + 1, &adev->crtc_irq);\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add crtc irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i + 1, 0);\n\n\t\tc_irq_params = &adev->dm.vblank_params[int_params.irq_source - DC_IRQ_SOURCE_VBLANK1];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_crtc_high_irq, c_irq_params);\n\t}\n\n\t \n\tfor (i = VISLANDS30_IV_SRCID_D1_GRPH_PFLIP;\n\t\t\ti <= VISLANDS30_IV_SRCID_D6_GRPH_PFLIP; i += 2) {\n\t\tr = amdgpu_irq_add_id(adev, client_id, i, &adev->pageflip_irq);\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add page flip irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.pflip_params[int_params.irq_source - DC_IRQ_SOURCE_PFLIP_FIRST];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_pflip_high_irq, c_irq_params);\n\n\t}\n\n\t \n\tr = amdgpu_irq_add_id(adev, client_id,\n\t\t\tVISLANDS30_IV_SRCID_HOTPLUG_DETECT_A, &adev->hpd_irq);\n\tif (r) {\n\t\tDRM_ERROR(\"Failed to add hpd irq id!\\n\");\n\t\treturn r;\n\t}\n\n\tregister_hpd_handlers(adev);\n\n\treturn 0;\n}\n#endif\n\n \nstatic int dce110_register_irq_handlers(struct amdgpu_device *adev)\n{\n\tstruct dc *dc = adev->dm.dc;\n\tstruct common_irq_params *c_irq_params;\n\tstruct dc_interrupt_params int_params = {0};\n\tint r;\n\tint i;\n\tunsigned int client_id = AMDGPU_IRQ_CLIENTID_LEGACY;\n\n\tif (adev->family >= AMDGPU_FAMILY_AI)\n\t\tclient_id = SOC15_IH_CLIENTID_DCE;\n\n\tint_params.requested_polarity = INTERRUPT_POLARITY_DEFAULT;\n\tint_params.current_polarity = INTERRUPT_POLARITY_DEFAULT;\n\n\t \n\n\t \n\tfor (i = VISLANDS30_IV_SRCID_D1_VERTICAL_INTERRUPT0; i <= VISLANDS30_IV_SRCID_D6_VERTICAL_INTERRUPT0; i++) {\n\t\tr = amdgpu_irq_add_id(adev, client_id, i, &adev->crtc_irq);\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add crtc irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.vblank_params[int_params.irq_source - DC_IRQ_SOURCE_VBLANK1];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_crtc_high_irq, c_irq_params);\n\t}\n\n\t \n\tfor (i = VISLANDS30_IV_SRCID_D1_V_UPDATE_INT; i <= VISLANDS30_IV_SRCID_D6_V_UPDATE_INT; i += 2) {\n\t\tr = amdgpu_irq_add_id(adev, client_id, i, &adev->vupdate_irq);\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add vupdate irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.vupdate_params[int_params.irq_source - DC_IRQ_SOURCE_VUPDATE1];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_vupdate_high_irq, c_irq_params);\n\t}\n\n\t \n\tfor (i = VISLANDS30_IV_SRCID_D1_GRPH_PFLIP;\n\t\t\ti <= VISLANDS30_IV_SRCID_D6_GRPH_PFLIP; i += 2) {\n\t\tr = amdgpu_irq_add_id(adev, client_id, i, &adev->pageflip_irq);\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add page flip irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.pflip_params[int_params.irq_source - DC_IRQ_SOURCE_PFLIP_FIRST];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_pflip_high_irq, c_irq_params);\n\n\t}\n\n\t \n\tr = amdgpu_irq_add_id(adev, client_id,\n\t\t\tVISLANDS30_IV_SRCID_HOTPLUG_DETECT_A, &adev->hpd_irq);\n\tif (r) {\n\t\tDRM_ERROR(\"Failed to add hpd irq id!\\n\");\n\t\treturn r;\n\t}\n\n\tregister_hpd_handlers(adev);\n\n\treturn 0;\n}\n\n \nstatic int dcn10_register_irq_handlers(struct amdgpu_device *adev)\n{\n\tstruct dc *dc = adev->dm.dc;\n\tstruct common_irq_params *c_irq_params;\n\tstruct dc_interrupt_params int_params = {0};\n\tint r;\n\tint i;\n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n\tstatic const unsigned int vrtl_int_srcid[] = {\n\t\tDCN_1_0__SRCID__OTG1_VERTICAL_INTERRUPT0_CONTROL,\n\t\tDCN_1_0__SRCID__OTG2_VERTICAL_INTERRUPT0_CONTROL,\n\t\tDCN_1_0__SRCID__OTG3_VERTICAL_INTERRUPT0_CONTROL,\n\t\tDCN_1_0__SRCID__OTG4_VERTICAL_INTERRUPT0_CONTROL,\n\t\tDCN_1_0__SRCID__OTG5_VERTICAL_INTERRUPT0_CONTROL,\n\t\tDCN_1_0__SRCID__OTG6_VERTICAL_INTERRUPT0_CONTROL\n\t};\n#endif\n\n\tint_params.requested_polarity = INTERRUPT_POLARITY_DEFAULT;\n\tint_params.current_polarity = INTERRUPT_POLARITY_DEFAULT;\n\n\t \n\n\t \n\tfor (i = DCN_1_0__SRCID__DC_D1_OTG_VSTARTUP;\n\t\t\ti <= DCN_1_0__SRCID__DC_D1_OTG_VSTARTUP + adev->mode_info.num_crtc - 1;\n\t\t\ti++) {\n\t\tr = amdgpu_irq_add_id(adev, SOC15_IH_CLIENTID_DCE, i, &adev->crtc_irq);\n\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add crtc irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.vblank_params[int_params.irq_source - DC_IRQ_SOURCE_VBLANK1];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(\n\t\t\tadev, &int_params, dm_crtc_high_irq, c_irq_params);\n\t}\n\n\t \n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n\tfor (i = 0; i <= adev->mode_info.num_crtc - 1; i++) {\n\t\tr = amdgpu_irq_add_id(adev, SOC15_IH_CLIENTID_DCE,\n\t\t\t\tvrtl_int_srcid[i], &adev->vline0_irq);\n\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add vline0 irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, vrtl_int_srcid[i], 0);\n\n\t\tif (int_params.irq_source == DC_IRQ_SOURCE_INVALID) {\n\t\t\tDRM_ERROR(\"Failed to register vline0 irq %d!\\n\", vrtl_int_srcid[i]);\n\t\t\tbreak;\n\t\t}\n\n\t\tc_irq_params = &adev->dm.vline0_params[int_params.irq_source\n\t\t\t\t\t- DC_IRQ_SOURCE_DC1_VLINE0];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_dcn_vertical_interrupt0_high_irq, c_irq_params);\n\t}\n#endif\n\n\t \n\tfor (i = DCN_1_0__SRCID__OTG0_IHC_V_UPDATE_NO_LOCK_INTERRUPT;\n\t     i <= DCN_1_0__SRCID__OTG0_IHC_V_UPDATE_NO_LOCK_INTERRUPT + adev->mode_info.num_crtc - 1;\n\t     i++) {\n\t\tr = amdgpu_irq_add_id(adev, SOC15_IH_CLIENTID_DCE, i, &adev->vupdate_irq);\n\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add vupdate irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.vupdate_params[int_params.irq_source - DC_IRQ_SOURCE_VUPDATE1];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_vupdate_high_irq, c_irq_params);\n\t}\n\n\t \n\tfor (i = DCN_1_0__SRCID__HUBP0_FLIP_INTERRUPT;\n\t\t\ti <= DCN_1_0__SRCID__HUBP0_FLIP_INTERRUPT + dc->caps.max_otg_num - 1;\n\t\t\ti++) {\n\t\tr = amdgpu_irq_add_id(adev, SOC15_IH_CLIENTID_DCE, i, &adev->pageflip_irq);\n\t\tif (r) {\n\t\t\tDRM_ERROR(\"Failed to add page flip irq id!\\n\");\n\t\t\treturn r;\n\t\t}\n\n\t\tint_params.int_context = INTERRUPT_HIGH_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.pflip_params[int_params.irq_source - DC_IRQ_SOURCE_PFLIP_FIRST];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_pflip_high_irq, c_irq_params);\n\n\t}\n\n\t \n\tr = amdgpu_irq_add_id(adev, SOC15_IH_CLIENTID_DCE, DCN_1_0__SRCID__DC_HPD1_INT,\n\t\t\t&adev->hpd_irq);\n\tif (r) {\n\t\tDRM_ERROR(\"Failed to add hpd irq id!\\n\");\n\t\treturn r;\n\t}\n\n\tregister_hpd_handlers(adev);\n\n\treturn 0;\n}\n \nstatic int register_outbox_irq_handlers(struct amdgpu_device *adev)\n{\n\tstruct dc *dc = adev->dm.dc;\n\tstruct common_irq_params *c_irq_params;\n\tstruct dc_interrupt_params int_params = {0};\n\tint r, i;\n\n\tint_params.requested_polarity = INTERRUPT_POLARITY_DEFAULT;\n\tint_params.current_polarity = INTERRUPT_POLARITY_DEFAULT;\n\n\tr = amdgpu_irq_add_id(adev, SOC15_IH_CLIENTID_DCE, DCN_1_0__SRCID__DMCUB_OUTBOX_LOW_PRIORITY_READY_INT,\n\t\t\t&adev->dmub_outbox_irq);\n\tif (r) {\n\t\tDRM_ERROR(\"Failed to add outbox irq id!\\n\");\n\t\treturn r;\n\t}\n\n\tif (dc->ctx->dmub_srv) {\n\t\ti = DCN_1_0__SRCID__DMCUB_OUTBOX_LOW_PRIORITY_READY_INT;\n\t\tint_params.int_context = INTERRUPT_LOW_IRQ_CONTEXT;\n\t\tint_params.irq_source =\n\t\tdc_interrupt_to_irq_source(dc, i, 0);\n\n\t\tc_irq_params = &adev->dm.dmub_outbox_params[0];\n\n\t\tc_irq_params->adev = adev;\n\t\tc_irq_params->irq_src = int_params.irq_source;\n\n\t\tamdgpu_dm_irq_register_interrupt(adev, &int_params,\n\t\t\t\tdm_dmub_outbox1_low_irq, c_irq_params);\n\t}\n\n\treturn 0;\n}\n\n \nint dm_atomic_get_state(struct drm_atomic_state *state,\n\t\t\tstruct dm_atomic_state **dm_state)\n{\n\tstruct drm_device *dev = state->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\tstruct drm_private_state *priv_state;\n\n\tif (*dm_state)\n\t\treturn 0;\n\n\tpriv_state = drm_atomic_get_private_obj_state(state, &dm->atomic_obj);\n\tif (IS_ERR(priv_state))\n\t\treturn PTR_ERR(priv_state);\n\n\t*dm_state = to_dm_atomic_state(priv_state);\n\n\treturn 0;\n}\n\nstatic struct dm_atomic_state *\ndm_atomic_get_new_state(struct drm_atomic_state *state)\n{\n\tstruct drm_device *dev = state->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\tstruct drm_private_obj *obj;\n\tstruct drm_private_state *new_obj_state;\n\tint i;\n\n\tfor_each_new_private_obj_in_state(state, obj, new_obj_state, i) {\n\t\tif (obj->funcs == dm->atomic_obj.funcs)\n\t\t\treturn to_dm_atomic_state(new_obj_state);\n\t}\n\n\treturn NULL;\n}\n\nstatic struct drm_private_state *\ndm_atomic_duplicate_state(struct drm_private_obj *obj)\n{\n\tstruct dm_atomic_state *old_state, *new_state;\n\n\tnew_state = kzalloc(sizeof(*new_state), GFP_KERNEL);\n\tif (!new_state)\n\t\treturn NULL;\n\n\t__drm_atomic_helper_private_obj_duplicate_state(obj, &new_state->base);\n\n\told_state = to_dm_atomic_state(obj->state);\n\n\tif (old_state && old_state->context)\n\t\tnew_state->context = dc_copy_state(old_state->context);\n\n\tif (!new_state->context) {\n\t\tkfree(new_state);\n\t\treturn NULL;\n\t}\n\n\treturn &new_state->base;\n}\n\nstatic void dm_atomic_destroy_state(struct drm_private_obj *obj,\n\t\t\t\t    struct drm_private_state *state)\n{\n\tstruct dm_atomic_state *dm_state = to_dm_atomic_state(state);\n\n\tif (dm_state && dm_state->context)\n\t\tdc_release_state(dm_state->context);\n\n\tkfree(dm_state);\n}\n\nstatic struct drm_private_state_funcs dm_atomic_state_funcs = {\n\t.atomic_duplicate_state = dm_atomic_duplicate_state,\n\t.atomic_destroy_state = dm_atomic_destroy_state,\n};\n\nstatic int amdgpu_dm_mode_config_init(struct amdgpu_device *adev)\n{\n\tstruct dm_atomic_state *state;\n\tint r;\n\n\tadev->mode_info.mode_config_initialized = true;\n\n\tadev_to_drm(adev)->mode_config.funcs = (void *)&amdgpu_dm_mode_funcs;\n\tadev_to_drm(adev)->mode_config.helper_private = &amdgpu_dm_mode_config_helperfuncs;\n\n\tadev_to_drm(adev)->mode_config.max_width = 16384;\n\tadev_to_drm(adev)->mode_config.max_height = 16384;\n\n\tadev_to_drm(adev)->mode_config.preferred_depth = 24;\n\tif (adev->asic_type == CHIP_HAWAII)\n\t\t \n\t\tadev_to_drm(adev)->mode_config.prefer_shadow = 0;\n\telse\n\t\tadev_to_drm(adev)->mode_config.prefer_shadow = 1;\n\t \n\tadev_to_drm(adev)->mode_config.async_page_flip = true;\n\n\tstate = kzalloc(sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn -ENOMEM;\n\n\tstate->context = dc_create_state(adev->dm.dc);\n\tif (!state->context) {\n\t\tkfree(state);\n\t\treturn -ENOMEM;\n\t}\n\n\tdc_resource_state_copy_construct_current(adev->dm.dc, state->context);\n\n\tdrm_atomic_private_obj_init(adev_to_drm(adev),\n\t\t\t\t    &adev->dm.atomic_obj,\n\t\t\t\t    &state->base,\n\t\t\t\t    &dm_atomic_state_funcs);\n\n\tr = amdgpu_display_modeset_create_props(adev);\n\tif (r) {\n\t\tdc_release_state(state->context);\n\t\tkfree(state);\n\t\treturn r;\n\t}\n\n\tr = amdgpu_dm_audio_init(adev);\n\tif (r) {\n\t\tdc_release_state(state->context);\n\t\tkfree(state);\n\t\treturn r;\n\t}\n\n\treturn 0;\n}\n\n#define AMDGPU_DM_DEFAULT_MIN_BACKLIGHT 12\n#define AMDGPU_DM_DEFAULT_MAX_BACKLIGHT 255\n#define AUX_BL_DEFAULT_TRANSITION_TIME_MS 50\n\nstatic void amdgpu_dm_update_backlight_caps(struct amdgpu_display_manager *dm,\n\t\t\t\t\t    int bl_idx)\n{\n#if defined(CONFIG_ACPI)\n\tstruct amdgpu_dm_backlight_caps caps;\n\n\tmemset(&caps, 0, sizeof(caps));\n\n\tif (dm->backlight_caps[bl_idx].caps_valid)\n\t\treturn;\n\n\tamdgpu_acpi_get_backlight_caps(&caps);\n\tif (caps.caps_valid) {\n\t\tdm->backlight_caps[bl_idx].caps_valid = true;\n\t\tif (caps.aux_support)\n\t\t\treturn;\n\t\tdm->backlight_caps[bl_idx].min_input_signal = caps.min_input_signal;\n\t\tdm->backlight_caps[bl_idx].max_input_signal = caps.max_input_signal;\n\t} else {\n\t\tdm->backlight_caps[bl_idx].min_input_signal =\n\t\t\t\tAMDGPU_DM_DEFAULT_MIN_BACKLIGHT;\n\t\tdm->backlight_caps[bl_idx].max_input_signal =\n\t\t\t\tAMDGPU_DM_DEFAULT_MAX_BACKLIGHT;\n\t}\n#else\n\tif (dm->backlight_caps[bl_idx].aux_support)\n\t\treturn;\n\n\tdm->backlight_caps[bl_idx].min_input_signal = AMDGPU_DM_DEFAULT_MIN_BACKLIGHT;\n\tdm->backlight_caps[bl_idx].max_input_signal = AMDGPU_DM_DEFAULT_MAX_BACKLIGHT;\n#endif\n}\n\nstatic int get_brightness_range(const struct amdgpu_dm_backlight_caps *caps,\n\t\t\t\tunsigned int *min, unsigned int *max)\n{\n\tif (!caps)\n\t\treturn 0;\n\n\tif (caps->aux_support) {\n\t\t\n\t\t*max = 1000 * caps->aux_max_input_signal;\n\t\t*min = 1000 * caps->aux_min_input_signal;\n\t} else {\n\t\t\n\t\t*max = 0x101 * caps->max_input_signal;\n\t\t*min = 0x101 * caps->min_input_signal;\n\t}\n\treturn 1;\n}\n\nstatic u32 convert_brightness_from_user(const struct amdgpu_dm_backlight_caps *caps,\n\t\t\t\t\tuint32_t brightness)\n{\n\tunsigned int min, max;\n\n\tif (!get_brightness_range(caps, &min, &max))\n\t\treturn brightness;\n\n\t\n\treturn min + DIV_ROUND_CLOSEST((max - min) * brightness,\n\t\t\t\t       AMDGPU_MAX_BL_LEVEL);\n}\n\nstatic u32 convert_brightness_to_user(const struct amdgpu_dm_backlight_caps *caps,\n\t\t\t\t      uint32_t brightness)\n{\n\tunsigned int min, max;\n\n\tif (!get_brightness_range(caps, &min, &max))\n\t\treturn brightness;\n\n\tif (brightness < min)\n\t\treturn 0;\n\t\n\treturn DIV_ROUND_CLOSEST(AMDGPU_MAX_BL_LEVEL * (brightness - min),\n\t\t\t\t max - min);\n}\n\nstatic void amdgpu_dm_backlight_set_level(struct amdgpu_display_manager *dm,\n\t\t\t\t\t int bl_idx,\n\t\t\t\t\t u32 user_brightness)\n{\n\tstruct amdgpu_dm_backlight_caps caps;\n\tstruct dc_link *link;\n\tu32 brightness;\n\tbool rc;\n\n\tamdgpu_dm_update_backlight_caps(dm, bl_idx);\n\tcaps = dm->backlight_caps[bl_idx];\n\n\tdm->brightness[bl_idx] = user_brightness;\n\t \n\tif (bl_idx == 0)\n\t\tamdgpu_atombios_scratch_regs_set_backlight_level(dm->adev, dm->brightness[bl_idx]);\n\tbrightness = convert_brightness_from_user(&caps, dm->brightness[bl_idx]);\n\tlink = (struct dc_link *)dm->backlight_link[bl_idx];\n\n\t \n\tif (caps.aux_support) {\n\t\trc = dc_link_set_backlight_level_nits(link, true, brightness,\n\t\t\t\t\t\t      AUX_BL_DEFAULT_TRANSITION_TIME_MS);\n\t\tif (!rc)\n\t\t\tDRM_DEBUG(\"DM: Failed to update backlight via AUX on eDP[%d]\\n\", bl_idx);\n\t} else {\n\t\trc = dc_link_set_backlight_level(link, brightness, 0);\n\t\tif (!rc)\n\t\t\tDRM_DEBUG(\"DM: Failed to update backlight on eDP[%d]\\n\", bl_idx);\n\t}\n\n\tif (rc)\n\t\tdm->actual_brightness[bl_idx] = user_brightness;\n}\n\nstatic int amdgpu_dm_backlight_update_status(struct backlight_device *bd)\n{\n\tstruct amdgpu_display_manager *dm = bl_get_data(bd);\n\tint i;\n\n\tfor (i = 0; i < dm->num_of_edps; i++) {\n\t\tif (bd == dm->backlight_dev[i])\n\t\t\tbreak;\n\t}\n\tif (i >= AMDGPU_DM_MAX_NUM_EDP)\n\t\ti = 0;\n\tamdgpu_dm_backlight_set_level(dm, i, bd->props.brightness);\n\n\treturn 0;\n}\n\nstatic u32 amdgpu_dm_backlight_get_level(struct amdgpu_display_manager *dm,\n\t\t\t\t\t int bl_idx)\n{\n\tint ret;\n\tstruct amdgpu_dm_backlight_caps caps;\n\tstruct dc_link *link = (struct dc_link *)dm->backlight_link[bl_idx];\n\n\tamdgpu_dm_update_backlight_caps(dm, bl_idx);\n\tcaps = dm->backlight_caps[bl_idx];\n\n\tif (caps.aux_support) {\n\t\tu32 avg, peak;\n\t\tbool rc;\n\n\t\trc = dc_link_get_backlight_level_nits(link, &avg, &peak);\n\t\tif (!rc)\n\t\t\treturn dm->brightness[bl_idx];\n\t\treturn convert_brightness_to_user(&caps, avg);\n\t}\n\n\tret = dc_link_get_backlight_level(link);\n\n\tif (ret == DC_ERROR_UNEXPECTED)\n\t\treturn dm->brightness[bl_idx];\n\n\treturn convert_brightness_to_user(&caps, ret);\n}\n\nstatic int amdgpu_dm_backlight_get_brightness(struct backlight_device *bd)\n{\n\tstruct amdgpu_display_manager *dm = bl_get_data(bd);\n\tint i;\n\n\tfor (i = 0; i < dm->num_of_edps; i++) {\n\t\tif (bd == dm->backlight_dev[i])\n\t\t\tbreak;\n\t}\n\tif (i >= AMDGPU_DM_MAX_NUM_EDP)\n\t\ti = 0;\n\treturn amdgpu_dm_backlight_get_level(dm, i);\n}\n\nstatic const struct backlight_ops amdgpu_dm_backlight_ops = {\n\t.options = BL_CORE_SUSPENDRESUME,\n\t.get_brightness = amdgpu_dm_backlight_get_brightness,\n\t.update_status\t= amdgpu_dm_backlight_update_status,\n};\n\nstatic void\namdgpu_dm_register_backlight_device(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct drm_device *drm = aconnector->base.dev;\n\tstruct amdgpu_display_manager *dm = &drm_to_adev(drm)->dm;\n\tstruct backlight_properties props = { 0 };\n\tchar bl_name[16];\n\n\tif (aconnector->bl_idx == -1)\n\t\treturn;\n\n\tif (!acpi_video_backlight_use_native()) {\n\t\tdrm_info(drm, \"Skipping amdgpu DM backlight registration\\n\");\n\t\t \n\t\tacpi_video_register_backlight();\n\t\treturn;\n\t}\n\n\tprops.max_brightness = AMDGPU_MAX_BL_LEVEL;\n\tprops.brightness = AMDGPU_MAX_BL_LEVEL;\n\tprops.type = BACKLIGHT_RAW;\n\n\tsnprintf(bl_name, sizeof(bl_name), \"amdgpu_bl%d\",\n\t\t drm->primary->index + aconnector->bl_idx);\n\n\tdm->backlight_dev[aconnector->bl_idx] =\n\t\tbacklight_device_register(bl_name, aconnector->base.kdev, dm,\n\t\t\t\t\t  &amdgpu_dm_backlight_ops, &props);\n\n\tif (IS_ERR(dm->backlight_dev[aconnector->bl_idx])) {\n\t\tDRM_ERROR(\"DM: Backlight registration failed!\\n\");\n\t\tdm->backlight_dev[aconnector->bl_idx] = NULL;\n\t} else\n\t\tDRM_DEBUG_DRIVER(\"DM: Registered Backlight device: %s\\n\", bl_name);\n}\n\nstatic int initialize_plane(struct amdgpu_display_manager *dm,\n\t\t\t    struct amdgpu_mode_info *mode_info, int plane_id,\n\t\t\t    enum drm_plane_type plane_type,\n\t\t\t    const struct dc_plane_cap *plane_cap)\n{\n\tstruct drm_plane *plane;\n\tunsigned long possible_crtcs;\n\tint ret = 0;\n\n\tplane = kzalloc(sizeof(struct drm_plane), GFP_KERNEL);\n\tif (!plane) {\n\t\tDRM_ERROR(\"KMS: Failed to allocate plane\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tplane->type = plane_type;\n\n\t \n\tpossible_crtcs = 1 << plane_id;\n\tif (plane_id >= dm->dc->caps.max_streams)\n\t\tpossible_crtcs = 0xff;\n\n\tret = amdgpu_dm_plane_init(dm, plane, possible_crtcs, plane_cap);\n\n\tif (ret) {\n\t\tDRM_ERROR(\"KMS: Failed to initialize plane\\n\");\n\t\tkfree(plane);\n\t\treturn ret;\n\t}\n\n\tif (mode_info)\n\t\tmode_info->planes[plane_id] = plane;\n\n\treturn ret;\n}\n\n\nstatic void setup_backlight_device(struct amdgpu_display_manager *dm,\n\t\t\t\t   struct amdgpu_dm_connector *aconnector)\n{\n\tstruct dc_link *link = aconnector->dc_link;\n\tint bl_idx = dm->num_of_edps;\n\n\tif (!(link->connector_signal & (SIGNAL_TYPE_EDP | SIGNAL_TYPE_LVDS)) ||\n\t    link->type == dc_connection_none)\n\t\treturn;\n\n\tif (dm->num_of_edps >= AMDGPU_DM_MAX_NUM_EDP) {\n\t\tdrm_warn(adev_to_drm(dm->adev), \"Too much eDP connections, skipping backlight setup for additional eDPs\\n\");\n\t\treturn;\n\t}\n\n\taconnector->bl_idx = bl_idx;\n\n\tamdgpu_dm_update_backlight_caps(dm, bl_idx);\n\tdm->brightness[bl_idx] = AMDGPU_MAX_BL_LEVEL;\n\tdm->backlight_link[bl_idx] = link;\n\tdm->num_of_edps++;\n\n\tupdate_connector_ext_caps(aconnector);\n}\n\nstatic void amdgpu_set_panel_orientation(struct drm_connector *connector);\n\n \nstatic int amdgpu_dm_initialize_drm_device(struct amdgpu_device *adev)\n{\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\ts32 i;\n\tstruct amdgpu_dm_connector *aconnector = NULL;\n\tstruct amdgpu_encoder *aencoder = NULL;\n\tstruct amdgpu_mode_info *mode_info = &adev->mode_info;\n\tu32 link_cnt;\n\ts32 primary_planes;\n\tenum dc_connection_type new_connection_type = dc_connection_none;\n\tconst struct dc_plane_cap *plane;\n\tbool psr_feature_enabled = false;\n\tbool replay_feature_enabled = false;\n\tint max_overlay = dm->dc->caps.max_slave_planes;\n\n\tdm->display_indexes_num = dm->dc->caps.max_streams;\n\t \n\tadev->mode_info.num_crtc = adev->dm.display_indexes_num;\n\n\tamdgpu_dm_set_irq_funcs(adev);\n\n\tlink_cnt = dm->dc->caps.max_links;\n\tif (amdgpu_dm_mode_config_init(dm->adev)) {\n\t\tDRM_ERROR(\"DM: Failed to initialize mode config\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tprimary_planes = dm->dc->caps.max_streams;\n\tASSERT(primary_planes <= AMDGPU_MAX_PLANES);\n\n\t \n\tfor (i = (primary_planes - 1); i >= 0; i--) {\n\t\tplane = &dm->dc->caps.planes[i];\n\n\t\tif (initialize_plane(dm, mode_info, i,\n\t\t\t\t     DRM_PLANE_TYPE_PRIMARY, plane)) {\n\t\t\tDRM_ERROR(\"KMS: Failed to initialize primary plane\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < dm->dc->caps.max_planes; ++i) {\n\t\tstruct dc_plane_cap *plane = &dm->dc->caps.planes[i];\n\n\t\t \n\t\tif (amdgpu_dc_debug_mask & DC_DISABLE_MPO)\n\t\t\tbreak;\n\n\t\tif (plane->type != DC_PLANE_TYPE_DCN_UNIVERSAL)\n\t\t\tcontinue;\n\n\t\tif (!plane->pixel_format_support.argb8888)\n\t\t\tcontinue;\n\n\t\tif (max_overlay-- == 0)\n\t\t\tbreak;\n\n\t\tif (initialize_plane(dm, NULL, primary_planes + i,\n\t\t\t\t     DRM_PLANE_TYPE_OVERLAY, plane)) {\n\t\t\tDRM_ERROR(\"KMS: Failed to initialize overlay plane\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tfor (i = 0; i < dm->dc->caps.max_streams; i++)\n\t\tif (amdgpu_dm_crtc_init(dm, mode_info->planes[i], i)) {\n\t\t\tDRM_ERROR(\"KMS: Failed to initialize crtc\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t \n\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\tcase IP_VERSION(3, 0, 0):\n\tcase IP_VERSION(3, 1, 2):\n\tcase IP_VERSION(3, 1, 3):\n\tcase IP_VERSION(3, 1, 4):\n\tcase IP_VERSION(3, 1, 5):\n\tcase IP_VERSION(3, 1, 6):\n\tcase IP_VERSION(3, 2, 0):\n\tcase IP_VERSION(3, 2, 1):\n\tcase IP_VERSION(2, 1, 0):\n\t\tif (register_outbox_irq_handlers(dm->adev)) {\n\t\t\tDRM_ERROR(\"DM: Failed to initialize IRQ\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tDRM_DEBUG_KMS(\"Unsupported DCN IP version for outbox: 0x%X\\n\",\n\t\t\t      adev->ip_versions[DCE_HWIP][0]);\n\t}\n\n\t \n\tif (!(amdgpu_dc_debug_mask & DC_DISABLE_PSR)) {\n\t\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\t\tcase IP_VERSION(3, 1, 2):\n\t\tcase IP_VERSION(3, 1, 3):\n\t\tcase IP_VERSION(3, 1, 4):\n\t\tcase IP_VERSION(3, 1, 5):\n\t\tcase IP_VERSION(3, 1, 6):\n\t\tcase IP_VERSION(3, 2, 0):\n\t\tcase IP_VERSION(3, 2, 1):\n\t\t\tpsr_feature_enabled = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tpsr_feature_enabled = amdgpu_dc_feature_mask & DC_PSR_MASK;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!(amdgpu_dc_debug_mask & DC_DISABLE_REPLAY)) {\n\t\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\t\tcase IP_VERSION(3, 1, 4):\n\t\tcase IP_VERSION(3, 1, 5):\n\t\tcase IP_VERSION(3, 1, 6):\n\t\tcase IP_VERSION(3, 2, 0):\n\t\tcase IP_VERSION(3, 2, 1):\n\t\t\treplay_feature_enabled = true;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treplay_feature_enabled = amdgpu_dc_feature_mask & DC_REPLAY_MASK;\n\t\t\tbreak;\n\t\t}\n\t}\n\t \n\tfor (i = 0; i < link_cnt; i++) {\n\t\tstruct dc_link *link = NULL;\n\n\t\tif (i > AMDGPU_DM_MAX_DISPLAY_INDEX) {\n\t\t\tDRM_ERROR(\n\t\t\t\t\"KMS: Cannot support more than %d display indexes\\n\",\n\t\t\t\t\tAMDGPU_DM_MAX_DISPLAY_INDEX);\n\t\t\tcontinue;\n\t\t}\n\n\t\taconnector = kzalloc(sizeof(*aconnector), GFP_KERNEL);\n\t\tif (!aconnector)\n\t\t\tgoto fail;\n\n\t\taencoder = kzalloc(sizeof(*aencoder), GFP_KERNEL);\n\t\tif (!aencoder)\n\t\t\tgoto fail;\n\n\t\tif (amdgpu_dm_encoder_init(dm->ddev, aencoder, i)) {\n\t\t\tDRM_ERROR(\"KMS: Failed to initialize encoder\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (amdgpu_dm_connector_init(dm, aconnector, i, aencoder)) {\n\t\t\tDRM_ERROR(\"KMS: Failed to initialize connector\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tlink = dc_get_link_at_index(dm->dc, i);\n\n\t\tif (!dc_link_detect_connection_type(link, &new_connection_type))\n\t\t\tDRM_ERROR(\"KMS: Failed to detect connector\\n\");\n\n\t\tif (aconnector->base.force && new_connection_type == dc_connection_none) {\n\t\t\temulated_link_detect(link);\n\t\t\tamdgpu_dm_update_connector_after_detect(aconnector);\n\t\t} else {\n\t\t\tbool ret = false;\n\n\t\t\tmutex_lock(&dm->dc_lock);\n\t\t\tret = dc_link_detect(link, DETECT_REASON_BOOT);\n\t\t\tmutex_unlock(&dm->dc_lock);\n\n\t\t\tif (ret) {\n\t\t\t\tamdgpu_dm_update_connector_after_detect(aconnector);\n\t\t\t\tsetup_backlight_device(dm, aconnector);\n\n\t\t\t\t \n\t\t\t\tif (replay_feature_enabled && amdgpu_dm_setup_replay(link, aconnector))\n\t\t\t\t\tpsr_feature_enabled = false;\n\n\t\t\t\tif (psr_feature_enabled)\n\t\t\t\t\tamdgpu_dm_set_psr_caps(link);\n\n\t\t\t\t \n\t\t\t\tif (link->psr_settings.psr_feature_enabled)\n\t\t\t\t\tadev_to_drm(adev)->vblank_disable_immediate = false;\n\t\t\t}\n\t\t}\n\t\tamdgpu_set_panel_orientation(&aconnector->base);\n\t}\n\n\t \n\tswitch (adev->asic_type) {\n#if defined(CONFIG_DRM_AMD_DC_SI)\n\tcase CHIP_TAHITI:\n\tcase CHIP_PITCAIRN:\n\tcase CHIP_VERDE:\n\tcase CHIP_OLAND:\n\t\tif (dce60_register_irq_handlers(dm->adev)) {\n\t\t\tDRM_ERROR(\"DM: Failed to initialize IRQ\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t\tbreak;\n#endif\n\tcase CHIP_BONAIRE:\n\tcase CHIP_HAWAII:\n\tcase CHIP_KAVERI:\n\tcase CHIP_KABINI:\n\tcase CHIP_MULLINS:\n\tcase CHIP_TONGA:\n\tcase CHIP_FIJI:\n\tcase CHIP_CARRIZO:\n\tcase CHIP_STONEY:\n\tcase CHIP_POLARIS11:\n\tcase CHIP_POLARIS10:\n\tcase CHIP_POLARIS12:\n\tcase CHIP_VEGAM:\n\tcase CHIP_VEGA10:\n\tcase CHIP_VEGA12:\n\tcase CHIP_VEGA20:\n\t\tif (dce110_register_irq_handlers(dm->adev)) {\n\t\t\tDRM_ERROR(\"DM: Failed to initialize IRQ\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\t\tcase IP_VERSION(1, 0, 0):\n\t\tcase IP_VERSION(1, 0, 1):\n\t\tcase IP_VERSION(2, 0, 2):\n\t\tcase IP_VERSION(2, 0, 3):\n\t\tcase IP_VERSION(2, 0, 0):\n\t\tcase IP_VERSION(2, 1, 0):\n\t\tcase IP_VERSION(3, 0, 0):\n\t\tcase IP_VERSION(3, 0, 2):\n\t\tcase IP_VERSION(3, 0, 3):\n\t\tcase IP_VERSION(3, 0, 1):\n\t\tcase IP_VERSION(3, 1, 2):\n\t\tcase IP_VERSION(3, 1, 3):\n\t\tcase IP_VERSION(3, 1, 4):\n\t\tcase IP_VERSION(3, 1, 5):\n\t\tcase IP_VERSION(3, 1, 6):\n\t\tcase IP_VERSION(3, 2, 0):\n\t\tcase IP_VERSION(3, 2, 1):\n\t\t\tif (dcn10_register_irq_handlers(dm->adev)) {\n\t\t\t\tDRM_ERROR(\"DM: Failed to initialize IRQ\\n\");\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDRM_ERROR(\"Unsupported DCE IP versions: 0x%X\\n\",\n\t\t\t\t\tadev->ip_versions[DCE_HWIP][0]);\n\t\t\tgoto fail;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn 0;\nfail:\n\tkfree(aencoder);\n\tkfree(aconnector);\n\n\treturn -EINVAL;\n}\n\nstatic void amdgpu_dm_destroy_drm_device(struct amdgpu_display_manager *dm)\n{\n\tdrm_atomic_private_obj_fini(&dm->atomic_obj);\n}\n\n \n\n \nstatic void dm_bandwidth_update(struct amdgpu_device *adev)\n{\n\t \n}\n\nstatic const struct amdgpu_display_funcs dm_display_funcs = {\n\t.bandwidth_update = dm_bandwidth_update,  \n\t.vblank_get_counter = dm_vblank_get_counter, \n\t.backlight_set_level = NULL,  \n\t.backlight_get_level = NULL,  \n\t.hpd_sense = NULL, \n\t.hpd_set_polarity = NULL,  \n\t.hpd_get_gpio_reg = NULL,  \n\t.page_flip_get_scanoutpos =\n\t\tdm_crtc_get_scanoutpos, \n\t.add_encoder = NULL,  \n\t.add_connector = NULL,  \n};\n\n#if defined(CONFIG_DEBUG_KERNEL_DC)\n\nstatic ssize_t s3_debug_store(struct device *device,\n\t\t\t      struct device_attribute *attr,\n\t\t\t      const char *buf,\n\t\t\t      size_t count)\n{\n\tint ret;\n\tint s3_state;\n\tstruct drm_device *drm_dev = dev_get_drvdata(device);\n\tstruct amdgpu_device *adev = drm_to_adev(drm_dev);\n\n\tret = kstrtoint(buf, 0, &s3_state);\n\n\tif (ret == 0) {\n\t\tif (s3_state) {\n\t\t\tdm_resume(adev);\n\t\t\tdrm_kms_helper_hotplug_event(adev_to_drm(adev));\n\t\t} else\n\t\t\tdm_suspend(adev);\n\t}\n\n\treturn ret == 0 ? count : 0;\n}\n\nDEVICE_ATTR_WO(s3_debug);\n\n#endif\n\nstatic int dm_init_microcode(struct amdgpu_device *adev)\n{\n\tchar *fw_name_dmub;\n\tint r;\n\n\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\tcase IP_VERSION(2, 1, 0):\n\t\tfw_name_dmub = FIRMWARE_RENOIR_DMUB;\n\t\tif (ASICREV_IS_GREEN_SARDINE(adev->external_rev_id))\n\t\t\tfw_name_dmub = FIRMWARE_GREEN_SARDINE_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 0):\n\t\tif (adev->ip_versions[GC_HWIP][0] == IP_VERSION(10, 3, 0))\n\t\t\tfw_name_dmub = FIRMWARE_SIENNA_CICHLID_DMUB;\n\t\telse\n\t\t\tfw_name_dmub = FIRMWARE_NAVY_FLOUNDER_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 1):\n\t\tfw_name_dmub = FIRMWARE_VANGOGH_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 2):\n\t\tfw_name_dmub = FIRMWARE_DIMGREY_CAVEFISH_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 0, 3):\n\t\tfw_name_dmub = FIRMWARE_BEIGE_GOBY_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 2):\n\tcase IP_VERSION(3, 1, 3):\n\t\tfw_name_dmub = FIRMWARE_YELLOW_CARP_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 4):\n\t\tfw_name_dmub = FIRMWARE_DCN_314_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 5):\n\t\tfw_name_dmub = FIRMWARE_DCN_315_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 1, 6):\n\t\tfw_name_dmub = FIRMWARE_DCN316_DMUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 2, 0):\n\t\tfw_name_dmub = FIRMWARE_DCN_V3_2_0_DMCUB;\n\t\tbreak;\n\tcase IP_VERSION(3, 2, 1):\n\t\tfw_name_dmub = FIRMWARE_DCN_V3_2_1_DMCUB;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn 0;\n\t}\n\tr = amdgpu_ucode_request(adev, &adev->dm.dmub_fw, fw_name_dmub);\n\tif (r)\n\t\tDRM_ERROR(\"DMUB firmware loading failed: %d\\n\", r);\n\treturn r;\n}\n\nstatic int dm_early_init(void *handle)\n{\n\tstruct amdgpu_device *adev = (struct amdgpu_device *)handle;\n\tstruct amdgpu_mode_info *mode_info = &adev->mode_info;\n\tstruct atom_context *ctx = mode_info->atom_context;\n\tint index = GetIndexIntoMasterTable(DATA, Object_Header);\n\tu16 data_offset;\n\n\t \n\tif (!amdgpu_atom_parse_data_header(ctx, index, NULL, NULL, NULL, &data_offset)) {\n\t\tadev->harvest_ip_mask |= AMD_HARVEST_IP_DMU_MASK;\n\t\tdev_info(adev->dev, \"No object header, skipping DM\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\tswitch (adev->asic_type) {\n#if defined(CONFIG_DRM_AMD_DC_SI)\n\tcase CHIP_TAHITI:\n\tcase CHIP_PITCAIRN:\n\tcase CHIP_VERDE:\n\t\tadev->mode_info.num_crtc = 6;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 6;\n\t\tbreak;\n\tcase CHIP_OLAND:\n\t\tadev->mode_info.num_crtc = 2;\n\t\tadev->mode_info.num_hpd = 2;\n\t\tadev->mode_info.num_dig = 2;\n\t\tbreak;\n#endif\n\tcase CHIP_BONAIRE:\n\tcase CHIP_HAWAII:\n\t\tadev->mode_info.num_crtc = 6;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 6;\n\t\tbreak;\n\tcase CHIP_KAVERI:\n\t\tadev->mode_info.num_crtc = 4;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 7;\n\t\tbreak;\n\tcase CHIP_KABINI:\n\tcase CHIP_MULLINS:\n\t\tadev->mode_info.num_crtc = 2;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 6;\n\t\tbreak;\n\tcase CHIP_FIJI:\n\tcase CHIP_TONGA:\n\t\tadev->mode_info.num_crtc = 6;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 7;\n\t\tbreak;\n\tcase CHIP_CARRIZO:\n\t\tadev->mode_info.num_crtc = 3;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 9;\n\t\tbreak;\n\tcase CHIP_STONEY:\n\t\tadev->mode_info.num_crtc = 2;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 9;\n\t\tbreak;\n\tcase CHIP_POLARIS11:\n\tcase CHIP_POLARIS12:\n\t\tadev->mode_info.num_crtc = 5;\n\t\tadev->mode_info.num_hpd = 5;\n\t\tadev->mode_info.num_dig = 5;\n\t\tbreak;\n\tcase CHIP_POLARIS10:\n\tcase CHIP_VEGAM:\n\t\tadev->mode_info.num_crtc = 6;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 6;\n\t\tbreak;\n\tcase CHIP_VEGA10:\n\tcase CHIP_VEGA12:\n\tcase CHIP_VEGA20:\n\t\tadev->mode_info.num_crtc = 6;\n\t\tadev->mode_info.num_hpd = 6;\n\t\tadev->mode_info.num_dig = 6;\n\t\tbreak;\n\tdefault:\n\n\t\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\t\tcase IP_VERSION(2, 0, 2):\n\t\tcase IP_VERSION(3, 0, 0):\n\t\t\tadev->mode_info.num_crtc = 6;\n\t\t\tadev->mode_info.num_hpd = 6;\n\t\t\tadev->mode_info.num_dig = 6;\n\t\t\tbreak;\n\t\tcase IP_VERSION(2, 0, 0):\n\t\tcase IP_VERSION(3, 0, 2):\n\t\t\tadev->mode_info.num_crtc = 5;\n\t\t\tadev->mode_info.num_hpd = 5;\n\t\t\tadev->mode_info.num_dig = 5;\n\t\t\tbreak;\n\t\tcase IP_VERSION(2, 0, 3):\n\t\tcase IP_VERSION(3, 0, 3):\n\t\t\tadev->mode_info.num_crtc = 2;\n\t\t\tadev->mode_info.num_hpd = 2;\n\t\t\tadev->mode_info.num_dig = 2;\n\t\t\tbreak;\n\t\tcase IP_VERSION(1, 0, 0):\n\t\tcase IP_VERSION(1, 0, 1):\n\t\tcase IP_VERSION(3, 0, 1):\n\t\tcase IP_VERSION(2, 1, 0):\n\t\tcase IP_VERSION(3, 1, 2):\n\t\tcase IP_VERSION(3, 1, 3):\n\t\tcase IP_VERSION(3, 1, 4):\n\t\tcase IP_VERSION(3, 1, 5):\n\t\tcase IP_VERSION(3, 1, 6):\n\t\tcase IP_VERSION(3, 2, 0):\n\t\tcase IP_VERSION(3, 2, 1):\n\t\t\tadev->mode_info.num_crtc = 4;\n\t\t\tadev->mode_info.num_hpd = 4;\n\t\t\tadev->mode_info.num_dig = 4;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDRM_ERROR(\"Unsupported DCE IP versions: 0x%x\\n\",\n\t\t\t\t\tadev->ip_versions[DCE_HWIP][0]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (adev->mode_info.funcs == NULL)\n\t\tadev->mode_info.funcs = &dm_display_funcs;\n\n\t \n#if defined(CONFIG_DEBUG_KERNEL_DC)\n\tdevice_create_file(\n\t\tadev_to_drm(adev)->dev,\n\t\t&dev_attr_s3_debug);\n#endif\n\tadev->dc_enabled = true;\n\n\treturn dm_init_microcode(adev);\n}\n\nstatic bool modereset_required(struct drm_crtc_state *crtc_state)\n{\n\treturn !crtc_state->active && drm_atomic_crtc_needs_modeset(crtc_state);\n}\n\nstatic void amdgpu_dm_encoder_destroy(struct drm_encoder *encoder)\n{\n\tdrm_encoder_cleanup(encoder);\n\tkfree(encoder);\n}\n\nstatic const struct drm_encoder_funcs amdgpu_dm_encoder_funcs = {\n\t.destroy = amdgpu_dm_encoder_destroy,\n};\n\nstatic int\nfill_plane_color_attributes(const struct drm_plane_state *plane_state,\n\t\t\t    const enum surface_pixel_format format,\n\t\t\t    enum dc_color_space *color_space)\n{\n\tbool full_range;\n\n\t*color_space = COLOR_SPACE_SRGB;\n\n\t \n\tif (format < SURFACE_PIXEL_FORMAT_VIDEO_BEGIN)\n\t\treturn 0;\n\n\tfull_range = (plane_state->color_range == DRM_COLOR_YCBCR_FULL_RANGE);\n\n\tswitch (plane_state->color_encoding) {\n\tcase DRM_COLOR_YCBCR_BT601:\n\t\tif (full_range)\n\t\t\t*color_space = COLOR_SPACE_YCBCR601;\n\t\telse\n\t\t\t*color_space = COLOR_SPACE_YCBCR601_LIMITED;\n\t\tbreak;\n\n\tcase DRM_COLOR_YCBCR_BT709:\n\t\tif (full_range)\n\t\t\t*color_space = COLOR_SPACE_YCBCR709;\n\t\telse\n\t\t\t*color_space = COLOR_SPACE_YCBCR709_LIMITED;\n\t\tbreak;\n\n\tcase DRM_COLOR_YCBCR_BT2020:\n\t\tif (full_range)\n\t\t\t*color_space = COLOR_SPACE_2020_YCBCR;\n\t\telse\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nfill_dc_plane_info_and_addr(struct amdgpu_device *adev,\n\t\t\t    const struct drm_plane_state *plane_state,\n\t\t\t    const u64 tiling_flags,\n\t\t\t    struct dc_plane_info *plane_info,\n\t\t\t    struct dc_plane_address *address,\n\t\t\t    bool tmz_surface,\n\t\t\t    bool force_disable_dcc)\n{\n\tconst struct drm_framebuffer *fb = plane_state->fb;\n\tconst struct amdgpu_framebuffer *afb =\n\t\tto_amdgpu_framebuffer(plane_state->fb);\n\tint ret;\n\n\tmemset(plane_info, 0, sizeof(*plane_info));\n\n\tswitch (fb->format->format) {\n\tcase DRM_FORMAT_C8:\n\t\tplane_info->format =\n\t\t\tSURFACE_PIXEL_FORMAT_GRPH_PALETA_256_COLORS;\n\t\tbreak;\n\tcase DRM_FORMAT_RGB565:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_RGB565;\n\t\tbreak;\n\tcase DRM_FORMAT_XRGB8888:\n\tcase DRM_FORMAT_ARGB8888:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ARGB8888;\n\t\tbreak;\n\tcase DRM_FORMAT_XRGB2101010:\n\tcase DRM_FORMAT_ARGB2101010:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ARGB2101010;\n\t\tbreak;\n\tcase DRM_FORMAT_XBGR2101010:\n\tcase DRM_FORMAT_ABGR2101010:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ABGR2101010;\n\t\tbreak;\n\tcase DRM_FORMAT_XBGR8888:\n\tcase DRM_FORMAT_ABGR8888:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ABGR8888;\n\t\tbreak;\n\tcase DRM_FORMAT_NV21:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_VIDEO_420_YCbCr;\n\t\tbreak;\n\tcase DRM_FORMAT_NV12:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_VIDEO_420_YCrCb;\n\t\tbreak;\n\tcase DRM_FORMAT_P010:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_VIDEO_420_10bpc_YCrCb;\n\t\tbreak;\n\tcase DRM_FORMAT_XRGB16161616F:\n\tcase DRM_FORMAT_ARGB16161616F:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ARGB16161616F;\n\t\tbreak;\n\tcase DRM_FORMAT_XBGR16161616F:\n\tcase DRM_FORMAT_ABGR16161616F:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ABGR16161616F;\n\t\tbreak;\n\tcase DRM_FORMAT_XRGB16161616:\n\tcase DRM_FORMAT_ARGB16161616:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ARGB16161616;\n\t\tbreak;\n\tcase DRM_FORMAT_XBGR16161616:\n\tcase DRM_FORMAT_ABGR16161616:\n\t\tplane_info->format = SURFACE_PIXEL_FORMAT_GRPH_ABGR16161616;\n\t\tbreak;\n\tdefault:\n\t\tDRM_ERROR(\n\t\t\t\"Unsupported screen format %p4cc\\n\",\n\t\t\t&fb->format->format);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (plane_state->rotation & DRM_MODE_ROTATE_MASK) {\n\tcase DRM_MODE_ROTATE_0:\n\t\tplane_info->rotation = ROTATION_ANGLE_0;\n\t\tbreak;\n\tcase DRM_MODE_ROTATE_90:\n\t\tplane_info->rotation = ROTATION_ANGLE_90;\n\t\tbreak;\n\tcase DRM_MODE_ROTATE_180:\n\t\tplane_info->rotation = ROTATION_ANGLE_180;\n\t\tbreak;\n\tcase DRM_MODE_ROTATE_270:\n\t\tplane_info->rotation = ROTATION_ANGLE_270;\n\t\tbreak;\n\tdefault:\n\t\tplane_info->rotation = ROTATION_ANGLE_0;\n\t\tbreak;\n\t}\n\n\n\tplane_info->visible = true;\n\tplane_info->stereo_format = PLANE_STEREO_FORMAT_NONE;\n\n\tplane_info->layer_index = plane_state->normalized_zpos;\n\n\tret = fill_plane_color_attributes(plane_state, plane_info->format,\n\t\t\t\t\t  &plane_info->color_space);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_dm_plane_fill_plane_buffer_attributes(adev, afb, plane_info->format,\n\t\t\t\t\t   plane_info->rotation, tiling_flags,\n\t\t\t\t\t   &plane_info->tiling_info,\n\t\t\t\t\t   &plane_info->plane_size,\n\t\t\t\t\t   &plane_info->dcc, address,\n\t\t\t\t\t   tmz_surface, force_disable_dcc);\n\tif (ret)\n\t\treturn ret;\n\n\tamdgpu_dm_plane_fill_blending_from_plane_state(\n\t\tplane_state, &plane_info->per_pixel_alpha, &plane_info->pre_multiplied_alpha,\n\t\t&plane_info->global_alpha, &plane_info->global_alpha_value);\n\n\treturn 0;\n}\n\nstatic int fill_dc_plane_attributes(struct amdgpu_device *adev,\n\t\t\t\t    struct dc_plane_state *dc_plane_state,\n\t\t\t\t    struct drm_plane_state *plane_state,\n\t\t\t\t    struct drm_crtc_state *crtc_state)\n{\n\tstruct dm_crtc_state *dm_crtc_state = to_dm_crtc_state(crtc_state);\n\tstruct amdgpu_framebuffer *afb = (struct amdgpu_framebuffer *)plane_state->fb;\n\tstruct dc_scaling_info scaling_info;\n\tstruct dc_plane_info plane_info;\n\tint ret;\n\tbool force_disable_dcc = false;\n\n\tret = amdgpu_dm_plane_fill_dc_scaling_info(adev, plane_state, &scaling_info);\n\tif (ret)\n\t\treturn ret;\n\n\tdc_plane_state->src_rect = scaling_info.src_rect;\n\tdc_plane_state->dst_rect = scaling_info.dst_rect;\n\tdc_plane_state->clip_rect = scaling_info.clip_rect;\n\tdc_plane_state->scaling_quality = scaling_info.scaling_quality;\n\n\tforce_disable_dcc = adev->asic_type == CHIP_RAVEN && adev->in_suspend;\n\tret = fill_dc_plane_info_and_addr(adev, plane_state,\n\t\t\t\t\t  afb->tiling_flags,\n\t\t\t\t\t  &plane_info,\n\t\t\t\t\t  &dc_plane_state->address,\n\t\t\t\t\t  afb->tmz_surface,\n\t\t\t\t\t  force_disable_dcc);\n\tif (ret)\n\t\treturn ret;\n\n\tdc_plane_state->format = plane_info.format;\n\tdc_plane_state->color_space = plane_info.color_space;\n\tdc_plane_state->format = plane_info.format;\n\tdc_plane_state->plane_size = plane_info.plane_size;\n\tdc_plane_state->rotation = plane_info.rotation;\n\tdc_plane_state->horizontal_mirror = plane_info.horizontal_mirror;\n\tdc_plane_state->stereo_format = plane_info.stereo_format;\n\tdc_plane_state->tiling_info = plane_info.tiling_info;\n\tdc_plane_state->visible = plane_info.visible;\n\tdc_plane_state->per_pixel_alpha = plane_info.per_pixel_alpha;\n\tdc_plane_state->pre_multiplied_alpha = plane_info.pre_multiplied_alpha;\n\tdc_plane_state->global_alpha = plane_info.global_alpha;\n\tdc_plane_state->global_alpha_value = plane_info.global_alpha_value;\n\tdc_plane_state->dcc = plane_info.dcc;\n\tdc_plane_state->layer_index = plane_info.layer_index;\n\tdc_plane_state->flip_int_enabled = true;\n\n\t \n\tret = amdgpu_dm_update_plane_color_mgmt(dm_crtc_state, dc_plane_state);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic inline void fill_dc_dirty_rect(struct drm_plane *plane,\n\t\t\t\t      struct rect *dirty_rect, int32_t x,\n\t\t\t\t      s32 y, s32 width, s32 height,\n\t\t\t\t      int *i, bool ffu)\n{\n\tWARN_ON(*i >= DC_MAX_DIRTY_RECTS);\n\n\tdirty_rect->x = x;\n\tdirty_rect->y = y;\n\tdirty_rect->width = width;\n\tdirty_rect->height = height;\n\n\tif (ffu)\n\t\tdrm_dbg(plane->dev,\n\t\t\t\"[PLANE:%d] PSR FFU dirty rect size (%d, %d)\\n\",\n\t\t\tplane->base.id, width, height);\n\telse\n\t\tdrm_dbg(plane->dev,\n\t\t\t\"[PLANE:%d] PSR SU dirty rect at (%d, %d) size (%d, %d)\",\n\t\t\tplane->base.id, x, y, width, height);\n\n\t(*i)++;\n}\n\n \nstatic void fill_dc_dirty_rects(struct drm_plane *plane,\n\t\t\t\tstruct drm_plane_state *old_plane_state,\n\t\t\t\tstruct drm_plane_state *new_plane_state,\n\t\t\t\tstruct drm_crtc_state *crtc_state,\n\t\t\t\tstruct dc_flip_addrs *flip_addrs,\n\t\t\t\tbool *dirty_regions_changed)\n{\n\tstruct dm_crtc_state *dm_crtc_state = to_dm_crtc_state(crtc_state);\n\tstruct rect *dirty_rects = flip_addrs->dirty_rects;\n\tu32 num_clips;\n\tstruct drm_mode_rect *clips;\n\tbool bb_changed;\n\tbool fb_changed;\n\tu32 i = 0;\n\t*dirty_regions_changed = false;\n\n\t \n\tif (plane->type == DRM_PLANE_TYPE_CURSOR)\n\t\treturn;\n\n\tif (new_plane_state->rotation != DRM_MODE_ROTATE_0)\n\t\tgoto ffu;\n\n\tnum_clips = drm_plane_get_damage_clips_count(new_plane_state);\n\tclips = drm_plane_get_damage_clips(new_plane_state);\n\n\tif (!dm_crtc_state->mpo_requested) {\n\t\tif (!num_clips || num_clips > DC_MAX_DIRTY_RECTS)\n\t\t\tgoto ffu;\n\n\t\tfor (; flip_addrs->dirty_rect_count < num_clips; clips++)\n\t\t\tfill_dc_dirty_rect(new_plane_state->plane,\n\t\t\t\t\t   &dirty_rects[flip_addrs->dirty_rect_count],\n\t\t\t\t\t   clips->x1, clips->y1,\n\t\t\t\t\t   clips->x2 - clips->x1, clips->y2 - clips->y1,\n\t\t\t\t\t   &flip_addrs->dirty_rect_count,\n\t\t\t\t\t   false);\n\t\treturn;\n\t}\n\n\t \n\tfb_changed = old_plane_state->fb->base.id !=\n\t\t     new_plane_state->fb->base.id;\n\tbb_changed = (old_plane_state->crtc_x != new_plane_state->crtc_x ||\n\t\t      old_plane_state->crtc_y != new_plane_state->crtc_y ||\n\t\t      old_plane_state->crtc_w != new_plane_state->crtc_w ||\n\t\t      old_plane_state->crtc_h != new_plane_state->crtc_h);\n\n\tdrm_dbg(plane->dev,\n\t\t\"[PLANE:%d] PSR bb_changed:%d fb_changed:%d num_clips:%d\\n\",\n\t\tnew_plane_state->plane->base.id,\n\t\tbb_changed, fb_changed, num_clips);\n\n\t*dirty_regions_changed = bb_changed;\n\n\tif ((num_clips + (bb_changed ? 2 : 0)) > DC_MAX_DIRTY_RECTS)\n\t\tgoto ffu;\n\n\tif (bb_changed) {\n\t\tfill_dc_dirty_rect(new_plane_state->plane, &dirty_rects[i],\n\t\t\t\t   new_plane_state->crtc_x,\n\t\t\t\t   new_plane_state->crtc_y,\n\t\t\t\t   new_plane_state->crtc_w,\n\t\t\t\t   new_plane_state->crtc_h, &i, false);\n\n\t\t \n\t\tfill_dc_dirty_rect(new_plane_state->plane, &dirty_rects[i],\n\t\t\t\t   old_plane_state->crtc_x,\n\t\t\t\t   old_plane_state->crtc_y,\n\t\t\t\t   old_plane_state->crtc_w,\n\t\t\t\t   old_plane_state->crtc_h, &i, false);\n\t}\n\n\tif (num_clips) {\n\t\tfor (; i < num_clips; clips++)\n\t\t\tfill_dc_dirty_rect(new_plane_state->plane,\n\t\t\t\t\t   &dirty_rects[i], clips->x1,\n\t\t\t\t\t   clips->y1, clips->x2 - clips->x1,\n\t\t\t\t\t   clips->y2 - clips->y1, &i, false);\n\t} else if (fb_changed && !bb_changed) {\n\t\tfill_dc_dirty_rect(new_plane_state->plane, &dirty_rects[i],\n\t\t\t\t   new_plane_state->crtc_x,\n\t\t\t\t   new_plane_state->crtc_y,\n\t\t\t\t   new_plane_state->crtc_w,\n\t\t\t\t   new_plane_state->crtc_h, &i, false);\n\t}\n\n\tflip_addrs->dirty_rect_count = i;\n\treturn;\n\nffu:\n\tfill_dc_dirty_rect(new_plane_state->plane, &dirty_rects[0], 0, 0,\n\t\t\t   dm_crtc_state->base.mode.crtc_hdisplay,\n\t\t\t   dm_crtc_state->base.mode.crtc_vdisplay,\n\t\t\t   &flip_addrs->dirty_rect_count, true);\n}\n\nstatic void update_stream_scaling_settings(const struct drm_display_mode *mode,\n\t\t\t\t\t   const struct dm_connector_state *dm_state,\n\t\t\t\t\t   struct dc_stream_state *stream)\n{\n\tenum amdgpu_rmx_type rmx_type;\n\n\tstruct rect src = { 0 };  \n\tstruct rect dst = { 0 };  \n\n\t \n\tif (!mode)\n\t\treturn;\n\n\t \n\tsrc.width = mode->hdisplay;\n\tsrc.height = mode->vdisplay;\n\tdst.width = stream->timing.h_addressable;\n\tdst.height = stream->timing.v_addressable;\n\n\tif (dm_state) {\n\t\trmx_type = dm_state->scaling;\n\t\tif (rmx_type == RMX_ASPECT || rmx_type == RMX_OFF) {\n\t\t\tif (src.width * dst.height <\n\t\t\t\t\tsrc.height * dst.width) {\n\t\t\t\t \n\t\t\t\tdst.width = src.width *\n\t\t\t\t\t\tdst.height / src.height;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tdst.height = src.height *\n\t\t\t\t\t\tdst.width / src.width;\n\t\t\t}\n\t\t} else if (rmx_type == RMX_CENTER) {\n\t\t\tdst = src;\n\t\t}\n\n\t\tdst.x = (stream->timing.h_addressable - dst.width) / 2;\n\t\tdst.y = (stream->timing.v_addressable - dst.height) / 2;\n\n\t\tif (dm_state->underscan_enable) {\n\t\t\tdst.x += dm_state->underscan_hborder / 2;\n\t\t\tdst.y += dm_state->underscan_vborder / 2;\n\t\t\tdst.width -= dm_state->underscan_hborder;\n\t\t\tdst.height -= dm_state->underscan_vborder;\n\t\t}\n\t}\n\n\tstream->src = src;\n\tstream->dst = dst;\n\n\tDRM_DEBUG_KMS(\"Destination Rectangle x:%d  y:%d  width:%d  height:%d\\n\",\n\t\t      dst.x, dst.y, dst.width, dst.height);\n\n}\n\nstatic enum dc_color_depth\nconvert_color_depth_from_display_info(const struct drm_connector *connector,\n\t\t\t\t      bool is_y420, int requested_bpc)\n{\n\tu8 bpc;\n\n\tif (is_y420) {\n\t\tbpc = 8;\n\n\t\t \n\t\tif (connector->display_info.hdmi.y420_dc_modes & DRM_EDID_YCBCR420_DC_48)\n\t\t\tbpc = 16;\n\t\telse if (connector->display_info.hdmi.y420_dc_modes & DRM_EDID_YCBCR420_DC_36)\n\t\t\tbpc = 12;\n\t\telse if (connector->display_info.hdmi.y420_dc_modes & DRM_EDID_YCBCR420_DC_30)\n\t\t\tbpc = 10;\n\t} else {\n\t\tbpc = (uint8_t)connector->display_info.bpc;\n\t\t \n\t\tbpc = bpc ? bpc : 8;\n\t}\n\n\tif (requested_bpc > 0) {\n\t\t \n\t\tbpc = min_t(u8, bpc, requested_bpc);\n\n\t\t \n\t\tbpc = bpc - (bpc & 1);\n\t}\n\n\tswitch (bpc) {\n\tcase 0:\n\t\t \n\t\treturn COLOR_DEPTH_888;\n\tcase 6:\n\t\treturn COLOR_DEPTH_666;\n\tcase 8:\n\t\treturn COLOR_DEPTH_888;\n\tcase 10:\n\t\treturn COLOR_DEPTH_101010;\n\tcase 12:\n\t\treturn COLOR_DEPTH_121212;\n\tcase 14:\n\t\treturn COLOR_DEPTH_141414;\n\tcase 16:\n\t\treturn COLOR_DEPTH_161616;\n\tdefault:\n\t\treturn COLOR_DEPTH_UNDEFINED;\n\t}\n}\n\nstatic enum dc_aspect_ratio\nget_aspect_ratio(const struct drm_display_mode *mode_in)\n{\n\t \n\treturn (enum dc_aspect_ratio) mode_in->picture_aspect_ratio;\n}\n\nstatic enum dc_color_space\nget_output_color_space(const struct dc_crtc_timing *dc_crtc_timing,\n\t\t       const struct drm_connector_state *connector_state)\n{\n\tenum dc_color_space color_space = COLOR_SPACE_SRGB;\n\n\tswitch (connector_state->colorspace) {\n\tcase DRM_MODE_COLORIMETRY_BT601_YCC:\n\t\tif (dc_crtc_timing->flags.Y_ONLY)\n\t\t\tcolor_space = COLOR_SPACE_YCBCR601_LIMITED;\n\t\telse\n\t\t\tcolor_space = COLOR_SPACE_YCBCR601;\n\t\tbreak;\n\tcase DRM_MODE_COLORIMETRY_BT709_YCC:\n\t\tif (dc_crtc_timing->flags.Y_ONLY)\n\t\t\tcolor_space = COLOR_SPACE_YCBCR709_LIMITED;\n\t\telse\n\t\t\tcolor_space = COLOR_SPACE_YCBCR709;\n\t\tbreak;\n\tcase DRM_MODE_COLORIMETRY_OPRGB:\n\t\tcolor_space = COLOR_SPACE_ADOBERGB;\n\t\tbreak;\n\tcase DRM_MODE_COLORIMETRY_BT2020_RGB:\n\tcase DRM_MODE_COLORIMETRY_BT2020_YCC:\n\t\tif (dc_crtc_timing->pixel_encoding == PIXEL_ENCODING_RGB)\n\t\t\tcolor_space = COLOR_SPACE_2020_RGB_FULLRANGE;\n\t\telse\n\t\t\tcolor_space = COLOR_SPACE_2020_YCBCR;\n\t\tbreak;\n\tcase DRM_MODE_COLORIMETRY_DEFAULT:  \n\tdefault:\n\t\tif (dc_crtc_timing->pixel_encoding == PIXEL_ENCODING_RGB) {\n\t\t\tcolor_space = COLOR_SPACE_SRGB;\n\t\t \n\t\t} else if (dc_crtc_timing->pix_clk_100hz > 270300) {\n\t\t\tif (dc_crtc_timing->flags.Y_ONLY)\n\t\t\t\tcolor_space =\n\t\t\t\t\tCOLOR_SPACE_YCBCR709_LIMITED;\n\t\t\telse\n\t\t\t\tcolor_space = COLOR_SPACE_YCBCR709;\n\t\t} else {\n\t\t\tif (dc_crtc_timing->flags.Y_ONLY)\n\t\t\t\tcolor_space =\n\t\t\t\t\tCOLOR_SPACE_YCBCR601_LIMITED;\n\t\t\telse\n\t\t\t\tcolor_space = COLOR_SPACE_YCBCR601;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn color_space;\n}\n\nstatic bool adjust_colour_depth_from_display_info(\n\tstruct dc_crtc_timing *timing_out,\n\tconst struct drm_display_info *info)\n{\n\tenum dc_color_depth depth = timing_out->display_color_depth;\n\tint normalized_clk;\n\n\tdo {\n\t\tnormalized_clk = timing_out->pix_clk_100hz / 10;\n\t\t \n\t\tif (timing_out->pixel_encoding == PIXEL_ENCODING_YCBCR420)\n\t\t\tnormalized_clk /= 2;\n\t\t \n\t\tswitch (depth) {\n\t\tcase COLOR_DEPTH_888:\n\t\t\tbreak;\n\t\tcase COLOR_DEPTH_101010:\n\t\t\tnormalized_clk = (normalized_clk * 30) / 24;\n\t\t\tbreak;\n\t\tcase COLOR_DEPTH_121212:\n\t\t\tnormalized_clk = (normalized_clk * 36) / 24;\n\t\t\tbreak;\n\t\tcase COLOR_DEPTH_161616:\n\t\t\tnormalized_clk = (normalized_clk * 48) / 24;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\treturn false;\n\t\t}\n\t\tif (normalized_clk <= info->max_tmds_clock) {\n\t\t\ttiming_out->display_color_depth = depth;\n\t\t\treturn true;\n\t\t}\n\t} while (--depth > COLOR_DEPTH_666);\n\treturn false;\n}\n\nstatic void fill_stream_properties_from_drm_display_mode(\n\tstruct dc_stream_state *stream,\n\tconst struct drm_display_mode *mode_in,\n\tconst struct drm_connector *connector,\n\tconst struct drm_connector_state *connector_state,\n\tconst struct dc_stream_state *old_stream,\n\tint requested_bpc)\n{\n\tstruct dc_crtc_timing *timing_out = &stream->timing;\n\tconst struct drm_display_info *info = &connector->display_info;\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct hdmi_vendor_infoframe hv_frame;\n\tstruct hdmi_avi_infoframe avi_frame;\n\n\tmemset(&hv_frame, 0, sizeof(hv_frame));\n\tmemset(&avi_frame, 0, sizeof(avi_frame));\n\n\ttiming_out->h_border_left = 0;\n\ttiming_out->h_border_right = 0;\n\ttiming_out->v_border_top = 0;\n\ttiming_out->v_border_bottom = 0;\n\t \n\tif (drm_mode_is_420_only(info, mode_in)\n\t\t\t&& stream->signal == SIGNAL_TYPE_HDMI_TYPE_A)\n\t\ttiming_out->pixel_encoding = PIXEL_ENCODING_YCBCR420;\n\telse if (drm_mode_is_420_also(info, mode_in)\n\t\t\t&& aconnector->force_yuv420_output)\n\t\ttiming_out->pixel_encoding = PIXEL_ENCODING_YCBCR420;\n\telse if ((connector->display_info.color_formats & DRM_COLOR_FORMAT_YCBCR444)\n\t\t\t&& stream->signal == SIGNAL_TYPE_HDMI_TYPE_A)\n\t\ttiming_out->pixel_encoding = PIXEL_ENCODING_YCBCR444;\n\telse\n\t\ttiming_out->pixel_encoding = PIXEL_ENCODING_RGB;\n\n\ttiming_out->timing_3d_format = TIMING_3D_FORMAT_NONE;\n\ttiming_out->display_color_depth = convert_color_depth_from_display_info(\n\t\tconnector,\n\t\t(timing_out->pixel_encoding == PIXEL_ENCODING_YCBCR420),\n\t\trequested_bpc);\n\ttiming_out->scan_type = SCANNING_TYPE_NODATA;\n\ttiming_out->hdmi_vic = 0;\n\n\tif (old_stream) {\n\t\ttiming_out->vic = old_stream->timing.vic;\n\t\ttiming_out->flags.HSYNC_POSITIVE_POLARITY = old_stream->timing.flags.HSYNC_POSITIVE_POLARITY;\n\t\ttiming_out->flags.VSYNC_POSITIVE_POLARITY = old_stream->timing.flags.VSYNC_POSITIVE_POLARITY;\n\t} else {\n\t\ttiming_out->vic = drm_match_cea_mode(mode_in);\n\t\tif (mode_in->flags & DRM_MODE_FLAG_PHSYNC)\n\t\t\ttiming_out->flags.HSYNC_POSITIVE_POLARITY = 1;\n\t\tif (mode_in->flags & DRM_MODE_FLAG_PVSYNC)\n\t\t\ttiming_out->flags.VSYNC_POSITIVE_POLARITY = 1;\n\t}\n\n\tif (stream->signal == SIGNAL_TYPE_HDMI_TYPE_A) {\n\t\tdrm_hdmi_avi_infoframe_from_display_mode(&avi_frame, (struct drm_connector *)connector, mode_in);\n\t\ttiming_out->vic = avi_frame.video_code;\n\t\tdrm_hdmi_vendor_infoframe_from_display_mode(&hv_frame, (struct drm_connector *)connector, mode_in);\n\t\ttiming_out->hdmi_vic = hv_frame.vic;\n\t}\n\n\tif (is_freesync_video_mode(mode_in, aconnector)) {\n\t\ttiming_out->h_addressable = mode_in->hdisplay;\n\t\ttiming_out->h_total = mode_in->htotal;\n\t\ttiming_out->h_sync_width = mode_in->hsync_end - mode_in->hsync_start;\n\t\ttiming_out->h_front_porch = mode_in->hsync_start - mode_in->hdisplay;\n\t\ttiming_out->v_total = mode_in->vtotal;\n\t\ttiming_out->v_addressable = mode_in->vdisplay;\n\t\ttiming_out->v_front_porch = mode_in->vsync_start - mode_in->vdisplay;\n\t\ttiming_out->v_sync_width = mode_in->vsync_end - mode_in->vsync_start;\n\t\ttiming_out->pix_clk_100hz = mode_in->clock * 10;\n\t} else {\n\t\ttiming_out->h_addressable = mode_in->crtc_hdisplay;\n\t\ttiming_out->h_total = mode_in->crtc_htotal;\n\t\ttiming_out->h_sync_width = mode_in->crtc_hsync_end - mode_in->crtc_hsync_start;\n\t\ttiming_out->h_front_porch = mode_in->crtc_hsync_start - mode_in->crtc_hdisplay;\n\t\ttiming_out->v_total = mode_in->crtc_vtotal;\n\t\ttiming_out->v_addressable = mode_in->crtc_vdisplay;\n\t\ttiming_out->v_front_porch = mode_in->crtc_vsync_start - mode_in->crtc_vdisplay;\n\t\ttiming_out->v_sync_width = mode_in->crtc_vsync_end - mode_in->crtc_vsync_start;\n\t\ttiming_out->pix_clk_100hz = mode_in->crtc_clock * 10;\n\t}\n\n\ttiming_out->aspect_ratio = get_aspect_ratio(mode_in);\n\n\tstream->out_transfer_func->type = TF_TYPE_PREDEFINED;\n\tstream->out_transfer_func->tf = TRANSFER_FUNCTION_SRGB;\n\tif (stream->signal == SIGNAL_TYPE_HDMI_TYPE_A) {\n\t\tif (!adjust_colour_depth_from_display_info(timing_out, info) &&\n\t\t    drm_mode_is_420_also(info, mode_in) &&\n\t\t    timing_out->pixel_encoding != PIXEL_ENCODING_YCBCR420) {\n\t\t\ttiming_out->pixel_encoding = PIXEL_ENCODING_YCBCR420;\n\t\t\tadjust_colour_depth_from_display_info(timing_out, info);\n\t\t}\n\t}\n\n\tstream->output_color_space = get_output_color_space(timing_out, connector_state);\n}\n\nstatic void fill_audio_info(struct audio_info *audio_info,\n\t\t\t    const struct drm_connector *drm_connector,\n\t\t\t    const struct dc_sink *dc_sink)\n{\n\tint i = 0;\n\tint cea_revision = 0;\n\tconst struct dc_edid_caps *edid_caps = &dc_sink->edid_caps;\n\n\taudio_info->manufacture_id = edid_caps->manufacturer_id;\n\taudio_info->product_id = edid_caps->product_id;\n\n\tcea_revision = drm_connector->display_info.cea_rev;\n\n\tstrscpy(audio_info->display_name,\n\t\tedid_caps->display_name,\n\t\tAUDIO_INFO_DISPLAY_NAME_SIZE_IN_CHARS);\n\n\tif (cea_revision >= 3) {\n\t\taudio_info->mode_count = edid_caps->audio_mode_count;\n\n\t\tfor (i = 0; i < audio_info->mode_count; ++i) {\n\t\t\taudio_info->modes[i].format_code =\n\t\t\t\t\t(enum audio_format_code)\n\t\t\t\t\t(edid_caps->audio_modes[i].format_code);\n\t\t\taudio_info->modes[i].channel_count =\n\t\t\t\t\tedid_caps->audio_modes[i].channel_count;\n\t\t\taudio_info->modes[i].sample_rates.all =\n\t\t\t\t\tedid_caps->audio_modes[i].sample_rate;\n\t\t\taudio_info->modes[i].sample_size =\n\t\t\t\t\tedid_caps->audio_modes[i].sample_size;\n\t\t}\n\t}\n\n\taudio_info->flags.all = edid_caps->speaker_flags;\n\n\t \n\tif (drm_connector->latency_present[0]) {\n\t\taudio_info->video_latency = drm_connector->video_latency[0];\n\t\taudio_info->audio_latency = drm_connector->audio_latency[0];\n\t}\n\n\t \n\n}\n\nstatic void\ncopy_crtc_timing_for_drm_display_mode(const struct drm_display_mode *src_mode,\n\t\t\t\t      struct drm_display_mode *dst_mode)\n{\n\tdst_mode->crtc_hdisplay = src_mode->crtc_hdisplay;\n\tdst_mode->crtc_vdisplay = src_mode->crtc_vdisplay;\n\tdst_mode->crtc_clock = src_mode->crtc_clock;\n\tdst_mode->crtc_hblank_start = src_mode->crtc_hblank_start;\n\tdst_mode->crtc_hblank_end = src_mode->crtc_hblank_end;\n\tdst_mode->crtc_hsync_start =  src_mode->crtc_hsync_start;\n\tdst_mode->crtc_hsync_end = src_mode->crtc_hsync_end;\n\tdst_mode->crtc_htotal = src_mode->crtc_htotal;\n\tdst_mode->crtc_hskew = src_mode->crtc_hskew;\n\tdst_mode->crtc_vblank_start = src_mode->crtc_vblank_start;\n\tdst_mode->crtc_vblank_end = src_mode->crtc_vblank_end;\n\tdst_mode->crtc_vsync_start = src_mode->crtc_vsync_start;\n\tdst_mode->crtc_vsync_end = src_mode->crtc_vsync_end;\n\tdst_mode->crtc_vtotal = src_mode->crtc_vtotal;\n}\n\nstatic void\ndecide_crtc_timing_for_drm_display_mode(struct drm_display_mode *drm_mode,\n\t\t\t\t\tconst struct drm_display_mode *native_mode,\n\t\t\t\t\tbool scale_enabled)\n{\n\tif (scale_enabled) {\n\t\tcopy_crtc_timing_for_drm_display_mode(native_mode, drm_mode);\n\t} else if (native_mode->clock == drm_mode->clock &&\n\t\t\tnative_mode->htotal == drm_mode->htotal &&\n\t\t\tnative_mode->vtotal == drm_mode->vtotal) {\n\t\tcopy_crtc_timing_for_drm_display_mode(native_mode, drm_mode);\n\t} else {\n\t\t \n\t}\n}\n\nstatic struct dc_sink *\ncreate_fake_sink(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct dc_sink_init_data sink_init_data = { 0 };\n\tstruct dc_sink *sink = NULL;\n\n\tsink_init_data.link = aconnector->dc_link;\n\tsink_init_data.sink_signal = aconnector->dc_link->connector_signal;\n\n\tsink = dc_sink_create(&sink_init_data);\n\tif (!sink) {\n\t\tDRM_ERROR(\"Failed to create sink!\\n\");\n\t\treturn NULL;\n\t}\n\tsink->sink_signal = SIGNAL_TYPE_VIRTUAL;\n\n\treturn sink;\n}\n\nstatic void set_multisync_trigger_params(\n\t\tstruct dc_stream_state *stream)\n{\n\tstruct dc_stream_state *master = NULL;\n\n\tif (stream->triggered_crtc_reset.enabled) {\n\t\tmaster = stream->triggered_crtc_reset.event_source;\n\t\tstream->triggered_crtc_reset.event =\n\t\t\tmaster->timing.flags.VSYNC_POSITIVE_POLARITY ?\n\t\t\tCRTC_EVENT_VSYNC_RISING : CRTC_EVENT_VSYNC_FALLING;\n\t\tstream->triggered_crtc_reset.delay = TRIGGER_DELAY_NEXT_PIXEL;\n\t}\n}\n\nstatic void set_master_stream(struct dc_stream_state *stream_set[],\n\t\t\t      int stream_count)\n{\n\tint j, highest_rfr = 0, master_stream = 0;\n\n\tfor (j = 0;  j < stream_count; j++) {\n\t\tif (stream_set[j] && stream_set[j]->triggered_crtc_reset.enabled) {\n\t\t\tint refresh_rate = 0;\n\n\t\t\trefresh_rate = (stream_set[j]->timing.pix_clk_100hz*100)/\n\t\t\t\t(stream_set[j]->timing.h_total*stream_set[j]->timing.v_total);\n\t\t\tif (refresh_rate > highest_rfr) {\n\t\t\t\thighest_rfr = refresh_rate;\n\t\t\t\tmaster_stream = j;\n\t\t\t}\n\t\t}\n\t}\n\tfor (j = 0;  j < stream_count; j++) {\n\t\tif (stream_set[j])\n\t\t\tstream_set[j]->triggered_crtc_reset.event_source = stream_set[master_stream];\n\t}\n}\n\nstatic void dm_enable_per_frame_crtc_master_sync(struct dc_state *context)\n{\n\tint i = 0;\n\tstruct dc_stream_state *stream;\n\n\tif (context->stream_count < 2)\n\t\treturn;\n\tfor (i = 0; i < context->stream_count ; i++) {\n\t\tif (!context->streams[i])\n\t\t\tcontinue;\n\t\t \n\t}\n\n\tset_master_stream(context->streams, context->stream_count);\n\n\tfor (i = 0; i < context->stream_count ; i++) {\n\t\tstream = context->streams[i];\n\n\t\tif (!stream)\n\t\t\tcontinue;\n\n\t\tset_multisync_trigger_params(stream);\n\t}\n}\n\n \nstatic struct drm_display_mode *\nget_highest_refresh_rate_mode(struct amdgpu_dm_connector *aconnector,\n\t\tbool use_probed_modes)\n{\n\tstruct drm_display_mode *m, *m_pref = NULL;\n\tu16 current_refresh, highest_refresh;\n\tstruct list_head *list_head = use_probed_modes ?\n\t\t&aconnector->base.probed_modes :\n\t\t&aconnector->base.modes;\n\n\tif (aconnector->freesync_vid_base.clock != 0)\n\t\treturn &aconnector->freesync_vid_base;\n\n\t \n\tlist_for_each_entry(m, list_head, head) {\n\t\tif (m->type & DRM_MODE_TYPE_PREFERRED) {\n\t\t\tm_pref = m;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!m_pref) {\n\t\t \n\t\tm_pref = list_first_entry_or_null(\n\t\t\t\t&aconnector->base.modes, struct drm_display_mode, head);\n\t\tif (!m_pref) {\n\t\t\tDRM_DEBUG_DRIVER(\"No preferred mode found in EDID\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\thighest_refresh = drm_mode_vrefresh(m_pref);\n\n\t \n\tlist_for_each_entry(m, list_head, head) {\n\t\tcurrent_refresh  = drm_mode_vrefresh(m);\n\n\t\tif (m->hdisplay == m_pref->hdisplay &&\n\t\t    m->vdisplay == m_pref->vdisplay &&\n\t\t    highest_refresh < current_refresh) {\n\t\t\thighest_refresh = current_refresh;\n\t\t\tm_pref = m;\n\t\t}\n\t}\n\n\tdrm_mode_copy(&aconnector->freesync_vid_base, m_pref);\n\treturn m_pref;\n}\n\nstatic bool is_freesync_video_mode(const struct drm_display_mode *mode,\n\t\tstruct amdgpu_dm_connector *aconnector)\n{\n\tstruct drm_display_mode *high_mode;\n\tint timing_diff;\n\n\thigh_mode = get_highest_refresh_rate_mode(aconnector, false);\n\tif (!high_mode || !mode)\n\t\treturn false;\n\n\ttiming_diff = high_mode->vtotal - mode->vtotal;\n\n\tif (high_mode->clock == 0 || high_mode->clock != mode->clock ||\n\t    high_mode->hdisplay != mode->hdisplay ||\n\t    high_mode->vdisplay != mode->vdisplay ||\n\t    high_mode->hsync_start != mode->hsync_start ||\n\t    high_mode->hsync_end != mode->hsync_end ||\n\t    high_mode->htotal != mode->htotal ||\n\t    high_mode->hskew != mode->hskew ||\n\t    high_mode->vscan != mode->vscan ||\n\t    high_mode->vsync_start - mode->vsync_start != timing_diff ||\n\t    high_mode->vsync_end - mode->vsync_end != timing_diff)\n\t\treturn false;\n\telse\n\t\treturn true;\n}\n\nstatic void update_dsc_caps(struct amdgpu_dm_connector *aconnector,\n\t\t\t    struct dc_sink *sink, struct dc_stream_state *stream,\n\t\t\t    struct dsc_dec_dpcd_caps *dsc_caps)\n{\n\tstream->timing.flags.DSC = 0;\n\tdsc_caps->is_dsc_supported = false;\n\n\tif (aconnector->dc_link && (sink->sink_signal == SIGNAL_TYPE_DISPLAY_PORT ||\n\t    sink->sink_signal == SIGNAL_TYPE_EDP)) {\n\t\tif (sink->link->dpcd_caps.dongle_type == DISPLAY_DONGLE_NONE ||\n\t\t\tsink->link->dpcd_caps.dongle_type == DISPLAY_DONGLE_DP_HDMI_CONVERTER)\n\t\t\tdc_dsc_parse_dsc_dpcd(aconnector->dc_link->ctx->dc,\n\t\t\t\taconnector->dc_link->dpcd_caps.dsc_caps.dsc_basic_caps.raw,\n\t\t\t\taconnector->dc_link->dpcd_caps.dsc_caps.dsc_branch_decoder_caps.raw,\n\t\t\t\tdsc_caps);\n\t}\n}\n\n\nstatic void apply_dsc_policy_for_edp(struct amdgpu_dm_connector *aconnector,\n\t\t\t\t    struct dc_sink *sink, struct dc_stream_state *stream,\n\t\t\t\t    struct dsc_dec_dpcd_caps *dsc_caps,\n\t\t\t\t    uint32_t max_dsc_target_bpp_limit_override)\n{\n\tconst struct dc_link_settings *verified_link_cap = NULL;\n\tu32 link_bw_in_kbps;\n\tu32 edp_min_bpp_x16, edp_max_bpp_x16;\n\tstruct dc *dc = sink->ctx->dc;\n\tstruct dc_dsc_bw_range bw_range = {0};\n\tstruct dc_dsc_config dsc_cfg = {0};\n\tstruct dc_dsc_config_options dsc_options = {0};\n\n\tdc_dsc_get_default_config_option(dc, &dsc_options);\n\tdsc_options.max_target_bpp_limit_override_x16 = max_dsc_target_bpp_limit_override * 16;\n\n\tverified_link_cap = dc_link_get_link_cap(stream->link);\n\tlink_bw_in_kbps = dc_link_bandwidth_kbps(stream->link, verified_link_cap);\n\tedp_min_bpp_x16 = 8 * 16;\n\tedp_max_bpp_x16 = 8 * 16;\n\n\tif (edp_max_bpp_x16 > dsc_caps->edp_max_bits_per_pixel)\n\t\tedp_max_bpp_x16 = dsc_caps->edp_max_bits_per_pixel;\n\n\tif (edp_max_bpp_x16 < edp_min_bpp_x16)\n\t\tedp_min_bpp_x16 = edp_max_bpp_x16;\n\n\tif (dc_dsc_compute_bandwidth_range(dc->res_pool->dscs[0],\n\t\t\t\tdc->debug.dsc_min_slice_height_override,\n\t\t\t\tedp_min_bpp_x16, edp_max_bpp_x16,\n\t\t\t\tdsc_caps,\n\t\t\t\t&stream->timing,\n\t\t\t\tdc_link_get_highest_encoding_format(aconnector->dc_link),\n\t\t\t\t&bw_range)) {\n\n\t\tif (bw_range.max_kbps < link_bw_in_kbps) {\n\t\t\tif (dc_dsc_compute_config(dc->res_pool->dscs[0],\n\t\t\t\t\tdsc_caps,\n\t\t\t\t\t&dsc_options,\n\t\t\t\t\t0,\n\t\t\t\t\t&stream->timing,\n\t\t\t\t\tdc_link_get_highest_encoding_format(aconnector->dc_link),\n\t\t\t\t\t&dsc_cfg)) {\n\t\t\t\tstream->timing.dsc_cfg = dsc_cfg;\n\t\t\t\tstream->timing.flags.DSC = 1;\n\t\t\t\tstream->timing.dsc_cfg.bits_per_pixel = edp_max_bpp_x16;\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (dc_dsc_compute_config(dc->res_pool->dscs[0],\n\t\t\t\tdsc_caps,\n\t\t\t\t&dsc_options,\n\t\t\t\tlink_bw_in_kbps,\n\t\t\t\t&stream->timing,\n\t\t\t\tdc_link_get_highest_encoding_format(aconnector->dc_link),\n\t\t\t\t&dsc_cfg)) {\n\t\tstream->timing.dsc_cfg = dsc_cfg;\n\t\tstream->timing.flags.DSC = 1;\n\t}\n}\n\n\nstatic void apply_dsc_policy_for_stream(struct amdgpu_dm_connector *aconnector,\n\t\t\t\t\tstruct dc_sink *sink, struct dc_stream_state *stream,\n\t\t\t\t\tstruct dsc_dec_dpcd_caps *dsc_caps)\n{\n\tstruct drm_connector *drm_connector = &aconnector->base;\n\tu32 link_bandwidth_kbps;\n\tstruct dc *dc = sink->ctx->dc;\n\tu32 max_supported_bw_in_kbps, timing_bw_in_kbps;\n\tu32 dsc_max_supported_bw_in_kbps;\n\tu32 max_dsc_target_bpp_limit_override =\n\t\tdrm_connector->display_info.max_dsc_bpp;\n\tstruct dc_dsc_config_options dsc_options = {0};\n\n\tdc_dsc_get_default_config_option(dc, &dsc_options);\n\tdsc_options.max_target_bpp_limit_override_x16 = max_dsc_target_bpp_limit_override * 16;\n\n\tlink_bandwidth_kbps = dc_link_bandwidth_kbps(aconnector->dc_link,\n\t\t\t\t\t\t\tdc_link_get_link_cap(aconnector->dc_link));\n\n\t \n\tdc_dsc_policy_set_enable_dsc_when_not_needed(\n\t\taconnector->dsc_settings.dsc_force_enable == DSC_CLK_FORCE_ENABLE);\n\n\tif (aconnector->dc_link && sink->sink_signal == SIGNAL_TYPE_EDP &&\n\t    !aconnector->dc_link->panel_config.dsc.disable_dsc_edp &&\n\t    dc->caps.edp_dsc_support && aconnector->dsc_settings.dsc_force_enable != DSC_CLK_FORCE_DISABLE) {\n\n\t\tapply_dsc_policy_for_edp(aconnector, sink, stream, dsc_caps, max_dsc_target_bpp_limit_override);\n\n\t} else if (aconnector->dc_link && sink->sink_signal == SIGNAL_TYPE_DISPLAY_PORT) {\n\t\tif (sink->link->dpcd_caps.dongle_type == DISPLAY_DONGLE_NONE) {\n\t\t\tif (dc_dsc_compute_config(aconnector->dc_link->ctx->dc->res_pool->dscs[0],\n\t\t\t\t\t\tdsc_caps,\n\t\t\t\t\t\t&dsc_options,\n\t\t\t\t\t\tlink_bandwidth_kbps,\n\t\t\t\t\t\t&stream->timing,\n\t\t\t\t\t\tdc_link_get_highest_encoding_format(aconnector->dc_link),\n\t\t\t\t\t\t&stream->timing.dsc_cfg)) {\n\t\t\t\tstream->timing.flags.DSC = 1;\n\t\t\t\tDRM_DEBUG_DRIVER(\"%s: [%s] DSC is selected from SST RX\\n\", __func__, drm_connector->name);\n\t\t\t}\n\t\t} else if (sink->link->dpcd_caps.dongle_type == DISPLAY_DONGLE_DP_HDMI_CONVERTER) {\n\t\t\ttiming_bw_in_kbps = dc_bandwidth_in_kbps_from_timing(&stream->timing,\n\t\t\t\t\tdc_link_get_highest_encoding_format(aconnector->dc_link));\n\t\t\tmax_supported_bw_in_kbps = link_bandwidth_kbps;\n\t\t\tdsc_max_supported_bw_in_kbps = link_bandwidth_kbps;\n\n\t\t\tif (timing_bw_in_kbps > max_supported_bw_in_kbps &&\n\t\t\t\t\tmax_supported_bw_in_kbps > 0 &&\n\t\t\t\t\tdsc_max_supported_bw_in_kbps > 0)\n\t\t\t\tif (dc_dsc_compute_config(aconnector->dc_link->ctx->dc->res_pool->dscs[0],\n\t\t\t\t\t\tdsc_caps,\n\t\t\t\t\t\t&dsc_options,\n\t\t\t\t\t\tdsc_max_supported_bw_in_kbps,\n\t\t\t\t\t\t&stream->timing,\n\t\t\t\t\t\tdc_link_get_highest_encoding_format(aconnector->dc_link),\n\t\t\t\t\t\t&stream->timing.dsc_cfg)) {\n\t\t\t\t\tstream->timing.flags.DSC = 1;\n\t\t\t\t\tDRM_DEBUG_DRIVER(\"%s: [%s] DSC is selected from DP-HDMI PCON\\n\",\n\t\t\t\t\t\t\t\t\t __func__, drm_connector->name);\n\t\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (aconnector->dsc_settings.dsc_force_enable == DSC_CLK_FORCE_ENABLE)\n\t\tstream->timing.flags.DSC = 1;\n\n\tif (stream->timing.flags.DSC && aconnector->dsc_settings.dsc_num_slices_h)\n\t\tstream->timing.dsc_cfg.num_slices_h = aconnector->dsc_settings.dsc_num_slices_h;\n\n\tif (stream->timing.flags.DSC && aconnector->dsc_settings.dsc_num_slices_v)\n\t\tstream->timing.dsc_cfg.num_slices_v = aconnector->dsc_settings.dsc_num_slices_v;\n\n\tif (stream->timing.flags.DSC && aconnector->dsc_settings.dsc_bits_per_pixel)\n\t\tstream->timing.dsc_cfg.bits_per_pixel = aconnector->dsc_settings.dsc_bits_per_pixel;\n}\n\nstatic struct dc_stream_state *\ncreate_stream_for_sink(struct amdgpu_dm_connector *aconnector,\n\t\t       const struct drm_display_mode *drm_mode,\n\t\t       const struct dm_connector_state *dm_state,\n\t\t       const struct dc_stream_state *old_stream,\n\t\t       int requested_bpc)\n{\n\tstruct drm_display_mode *preferred_mode = NULL;\n\tstruct drm_connector *drm_connector;\n\tconst struct drm_connector_state *con_state = &dm_state->base;\n\tstruct dc_stream_state *stream = NULL;\n\tstruct drm_display_mode mode;\n\tstruct drm_display_mode saved_mode;\n\tstruct drm_display_mode *freesync_mode = NULL;\n\tbool native_mode_found = false;\n\tbool recalculate_timing = false;\n\tbool scale = dm_state->scaling != RMX_OFF;\n\tint mode_refresh;\n\tint preferred_refresh = 0;\n\tenum color_transfer_func tf = TRANSFER_FUNC_UNKNOWN;\n\tstruct dsc_dec_dpcd_caps dsc_caps;\n\n\tstruct dc_sink *sink = NULL;\n\n\tdrm_mode_init(&mode, drm_mode);\n\tmemset(&saved_mode, 0, sizeof(saved_mode));\n\n\tif (aconnector == NULL) {\n\t\tDRM_ERROR(\"aconnector is NULL!\\n\");\n\t\treturn stream;\n\t}\n\n\tdrm_connector = &aconnector->base;\n\n\tif (!aconnector->dc_sink) {\n\t\tsink = create_fake_sink(aconnector);\n\t\tif (!sink)\n\t\t\treturn stream;\n\t} else {\n\t\tsink = aconnector->dc_sink;\n\t\tdc_sink_retain(sink);\n\t}\n\n\tstream = dc_create_stream_for_sink(sink);\n\n\tif (stream == NULL) {\n\t\tDRM_ERROR(\"Failed to create stream for sink!\\n\");\n\t\tgoto finish;\n\t}\n\n\tstream->dm_stream_context = aconnector;\n\n\tstream->timing.flags.LTE_340MCSC_SCRAMBLE =\n\t\tdrm_connector->display_info.hdmi.scdc.scrambling.low_rates;\n\n\tlist_for_each_entry(preferred_mode, &aconnector->base.modes, head) {\n\t\t \n\t\tif (preferred_mode->type & DRM_MODE_TYPE_PREFERRED) {\n\t\t\tnative_mode_found = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!native_mode_found)\n\t\tpreferred_mode = list_first_entry_or_null(\n\t\t\t\t&aconnector->base.modes,\n\t\t\t\tstruct drm_display_mode,\n\t\t\t\thead);\n\n\tmode_refresh = drm_mode_vrefresh(&mode);\n\n\tif (preferred_mode == NULL) {\n\t\t \n\t\tDRM_DEBUG_DRIVER(\"No preferred mode found\\n\");\n\t} else {\n\t\trecalculate_timing = is_freesync_video_mode(&mode, aconnector);\n\t\tif (recalculate_timing) {\n\t\t\tfreesync_mode = get_highest_refresh_rate_mode(aconnector, false);\n\t\t\tdrm_mode_copy(&saved_mode, &mode);\n\t\t\tdrm_mode_copy(&mode, freesync_mode);\n\t\t} else {\n\t\t\tdecide_crtc_timing_for_drm_display_mode(\n\t\t\t\t\t&mode, preferred_mode, scale);\n\n\t\t\tpreferred_refresh = drm_mode_vrefresh(preferred_mode);\n\t\t}\n\t}\n\n\tif (recalculate_timing)\n\t\tdrm_mode_set_crtcinfo(&saved_mode, 0);\n\n\t \n\tif (!scale || mode_refresh != preferred_refresh)\n\t\tfill_stream_properties_from_drm_display_mode(\n\t\t\tstream, &mode, &aconnector->base, con_state, NULL,\n\t\t\trequested_bpc);\n\telse\n\t\tfill_stream_properties_from_drm_display_mode(\n\t\t\tstream, &mode, &aconnector->base, con_state, old_stream,\n\t\t\trequested_bpc);\n\n\tif (aconnector->timing_changed) {\n\t\tDC_LOG_DEBUG(\"%s: overriding timing for automated test, bpc %d, changing to %d\\n\",\n\t\t\t\t__func__,\n\t\t\t\tstream->timing.display_color_depth,\n\t\t\t\taconnector->timing_requested->display_color_depth);\n\t\tstream->timing = *aconnector->timing_requested;\n\t}\n\n\t \n\tupdate_dsc_caps(aconnector, sink, stream, &dsc_caps);\n\tif (aconnector->dsc_settings.dsc_force_enable != DSC_CLK_FORCE_DISABLE && dsc_caps.is_dsc_supported)\n\t\tapply_dsc_policy_for_stream(aconnector, sink, stream, &dsc_caps);\n\n\tupdate_stream_scaling_settings(&mode, dm_state, stream);\n\n\tfill_audio_info(\n\t\t&stream->audio_info,\n\t\tdrm_connector,\n\t\tsink);\n\n\tupdate_stream_signal(stream, sink);\n\n\tif (stream->signal == SIGNAL_TYPE_HDMI_TYPE_A)\n\t\tmod_build_hf_vsif_infopacket(stream, &stream->vsp_infopacket);\n\telse if (stream->signal == SIGNAL_TYPE_DISPLAY_PORT ||\n\t\t\t stream->signal == SIGNAL_TYPE_DISPLAY_PORT_MST ||\n\t\t\t stream->signal == SIGNAL_TYPE_EDP) {\n\t\t \n\t\t \n\t\t \n\t\t \n\t\tstream->use_vsc_sdp_for_colorimetry = false;\n\t\tif (aconnector->dc_sink->sink_signal == SIGNAL_TYPE_DISPLAY_PORT_MST) {\n\t\t\tstream->use_vsc_sdp_for_colorimetry =\n\t\t\t\taconnector->dc_sink->is_vsc_sdp_colorimetry_supported;\n\t\t} else {\n\t\t\tif (stream->link->dpcd_caps.dprx_feature.bits.VSC_SDP_COLORIMETRY_SUPPORTED)\n\t\t\t\tstream->use_vsc_sdp_for_colorimetry = true;\n\t\t}\n\t\tif (stream->out_transfer_func->tf == TRANSFER_FUNCTION_GAMMA22)\n\t\t\ttf = TRANSFER_FUNC_GAMMA_22;\n\t\tmod_build_vsc_infopacket(stream, &stream->vsc_infopacket, stream->output_color_space, tf);\n\n\t\tif (stream->link->psr_settings.psr_feature_enabled)\n\t\t\taconnector->psr_skip_count = AMDGPU_DM_PSR_ENTRY_DELAY;\n\t}\nfinish:\n\tdc_sink_release(sink);\n\n\treturn stream;\n}\n\nstatic enum drm_connector_status\namdgpu_dm_connector_detect(struct drm_connector *connector, bool force)\n{\n\tbool connected;\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\n\t \n\n\tif (aconnector->base.force == DRM_FORCE_UNSPECIFIED &&\n\t    !aconnector->fake_enable)\n\t\tconnected = (aconnector->dc_sink != NULL);\n\telse\n\t\tconnected = (aconnector->base.force == DRM_FORCE_ON ||\n\t\t\t\taconnector->base.force == DRM_FORCE_ON_DIGITAL);\n\n\tupdate_subconnector_property(aconnector);\n\n\treturn (connected ? connector_status_connected :\n\t\t\tconnector_status_disconnected);\n}\n\nint amdgpu_dm_connector_atomic_set_property(struct drm_connector *connector,\n\t\t\t\t\t    struct drm_connector_state *connector_state,\n\t\t\t\t\t    struct drm_property *property,\n\t\t\t\t\t    uint64_t val)\n{\n\tstruct drm_device *dev = connector->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct dm_connector_state *dm_old_state =\n\t\tto_dm_connector_state(connector->state);\n\tstruct dm_connector_state *dm_new_state =\n\t\tto_dm_connector_state(connector_state);\n\n\tint ret = -EINVAL;\n\n\tif (property == dev->mode_config.scaling_mode_property) {\n\t\tenum amdgpu_rmx_type rmx_type;\n\n\t\tswitch (val) {\n\t\tcase DRM_MODE_SCALE_CENTER:\n\t\t\trmx_type = RMX_CENTER;\n\t\t\tbreak;\n\t\tcase DRM_MODE_SCALE_ASPECT:\n\t\t\trmx_type = RMX_ASPECT;\n\t\t\tbreak;\n\t\tcase DRM_MODE_SCALE_FULLSCREEN:\n\t\t\trmx_type = RMX_FULL;\n\t\t\tbreak;\n\t\tcase DRM_MODE_SCALE_NONE:\n\t\tdefault:\n\t\t\trmx_type = RMX_OFF;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (dm_old_state->scaling == rmx_type)\n\t\t\treturn 0;\n\n\t\tdm_new_state->scaling = rmx_type;\n\t\tret = 0;\n\t} else if (property == adev->mode_info.underscan_hborder_property) {\n\t\tdm_new_state->underscan_hborder = val;\n\t\tret = 0;\n\t} else if (property == adev->mode_info.underscan_vborder_property) {\n\t\tdm_new_state->underscan_vborder = val;\n\t\tret = 0;\n\t} else if (property == adev->mode_info.underscan_property) {\n\t\tdm_new_state->underscan_enable = val;\n\t\tret = 0;\n\t} else if (property == adev->mode_info.abm_level_property) {\n\t\tdm_new_state->abm_level = val ?: ABM_LEVEL_IMMEDIATE_DISABLE;\n\t\tret = 0;\n\t}\n\n\treturn ret;\n}\n\nint amdgpu_dm_connector_atomic_get_property(struct drm_connector *connector,\n\t\t\t\t\t    const struct drm_connector_state *state,\n\t\t\t\t\t    struct drm_property *property,\n\t\t\t\t\t    uint64_t *val)\n{\n\tstruct drm_device *dev = connector->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct dm_connector_state *dm_state =\n\t\tto_dm_connector_state(state);\n\tint ret = -EINVAL;\n\n\tif (property == dev->mode_config.scaling_mode_property) {\n\t\tswitch (dm_state->scaling) {\n\t\tcase RMX_CENTER:\n\t\t\t*val = DRM_MODE_SCALE_CENTER;\n\t\t\tbreak;\n\t\tcase RMX_ASPECT:\n\t\t\t*val = DRM_MODE_SCALE_ASPECT;\n\t\t\tbreak;\n\t\tcase RMX_FULL:\n\t\t\t*val = DRM_MODE_SCALE_FULLSCREEN;\n\t\t\tbreak;\n\t\tcase RMX_OFF:\n\t\tdefault:\n\t\t\t*val = DRM_MODE_SCALE_NONE;\n\t\t\tbreak;\n\t\t}\n\t\tret = 0;\n\t} else if (property == adev->mode_info.underscan_hborder_property) {\n\t\t*val = dm_state->underscan_hborder;\n\t\tret = 0;\n\t} else if (property == adev->mode_info.underscan_vborder_property) {\n\t\t*val = dm_state->underscan_vborder;\n\t\tret = 0;\n\t} else if (property == adev->mode_info.underscan_property) {\n\t\t*val = dm_state->underscan_enable;\n\t\tret = 0;\n\t} else if (property == adev->mode_info.abm_level_property) {\n\t\t*val = (dm_state->abm_level != ABM_LEVEL_IMMEDIATE_DISABLE) ?\n\t\t\tdm_state->abm_level : 0;\n\t\tret = 0;\n\t}\n\n\treturn ret;\n}\n\nstatic void amdgpu_dm_connector_unregister(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector = to_amdgpu_dm_connector(connector);\n\n\tdrm_dp_aux_unregister(&amdgpu_dm_connector->dm_dp_aux.aux);\n}\n\nstatic void amdgpu_dm_connector_destroy(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct amdgpu_device *adev = drm_to_adev(connector->dev);\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\n\t \n\tif (aconnector->mst_mgr.dev)\n\t\tdrm_dp_mst_topology_mgr_destroy(&aconnector->mst_mgr);\n\n\tif (aconnector->bl_idx != -1) {\n\t\tbacklight_device_unregister(dm->backlight_dev[aconnector->bl_idx]);\n\t\tdm->backlight_dev[aconnector->bl_idx] = NULL;\n\t}\n\n\tif (aconnector->dc_em_sink)\n\t\tdc_sink_release(aconnector->dc_em_sink);\n\taconnector->dc_em_sink = NULL;\n\tif (aconnector->dc_sink)\n\t\tdc_sink_release(aconnector->dc_sink);\n\taconnector->dc_sink = NULL;\n\n\tdrm_dp_cec_unregister_connector(&aconnector->dm_dp_aux.aux);\n\tdrm_connector_unregister(connector);\n\tdrm_connector_cleanup(connector);\n\tif (aconnector->i2c) {\n\t\ti2c_del_adapter(&aconnector->i2c->base);\n\t\tkfree(aconnector->i2c);\n\t}\n\tkfree(aconnector->dm_dp_aux.aux.name);\n\n\tkfree(connector);\n}\n\nvoid amdgpu_dm_connector_funcs_reset(struct drm_connector *connector)\n{\n\tstruct dm_connector_state *state =\n\t\tto_dm_connector_state(connector->state);\n\n\tif (connector->state)\n\t\t__drm_atomic_helper_connector_destroy_state(connector->state);\n\n\tkfree(state);\n\n\tstate = kzalloc(sizeof(*state), GFP_KERNEL);\n\n\tif (state) {\n\t\tstate->scaling = RMX_OFF;\n\t\tstate->underscan_enable = false;\n\t\tstate->underscan_hborder = 0;\n\t\tstate->underscan_vborder = 0;\n\t\tstate->base.max_requested_bpc = 8;\n\t\tstate->vcpi_slots = 0;\n\t\tstate->pbn = 0;\n\n\t\tif (connector->connector_type == DRM_MODE_CONNECTOR_eDP)\n\t\t\tstate->abm_level = amdgpu_dm_abm_level ?:\n\t\t\t\tABM_LEVEL_IMMEDIATE_DISABLE;\n\n\t\t__drm_atomic_helper_connector_reset(connector, &state->base);\n\t}\n}\n\nstruct drm_connector_state *\namdgpu_dm_connector_atomic_duplicate_state(struct drm_connector *connector)\n{\n\tstruct dm_connector_state *state =\n\t\tto_dm_connector_state(connector->state);\n\n\tstruct dm_connector_state *new_state =\n\t\t\tkmemdup(state, sizeof(*state), GFP_KERNEL);\n\n\tif (!new_state)\n\t\treturn NULL;\n\n\t__drm_atomic_helper_connector_duplicate_state(connector, &new_state->base);\n\n\tnew_state->freesync_capable = state->freesync_capable;\n\tnew_state->abm_level = state->abm_level;\n\tnew_state->scaling = state->scaling;\n\tnew_state->underscan_enable = state->underscan_enable;\n\tnew_state->underscan_hborder = state->underscan_hborder;\n\tnew_state->underscan_vborder = state->underscan_vborder;\n\tnew_state->vcpi_slots = state->vcpi_slots;\n\tnew_state->pbn = state->pbn;\n\treturn &new_state->base;\n}\n\nstatic int\namdgpu_dm_connector_late_register(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\tto_amdgpu_dm_connector(connector);\n\tint r;\n\n\tamdgpu_dm_register_backlight_device(amdgpu_dm_connector);\n\n\tif ((connector->connector_type == DRM_MODE_CONNECTOR_DisplayPort) ||\n\t    (connector->connector_type == DRM_MODE_CONNECTOR_eDP)) {\n\t\tamdgpu_dm_connector->dm_dp_aux.aux.dev = connector->kdev;\n\t\tr = drm_dp_aux_register(&amdgpu_dm_connector->dm_dp_aux.aux);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n#if defined(CONFIG_DEBUG_FS)\n\tconnector_debugfs_init(amdgpu_dm_connector);\n#endif\n\n\treturn 0;\n}\n\nstatic void amdgpu_dm_connector_funcs_force(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct dc_link *dc_link = aconnector->dc_link;\n\tstruct dc_sink *dc_em_sink = aconnector->dc_em_sink;\n\tstruct edid *edid;\n\n\tif (!connector->edid_override)\n\t\treturn;\n\n\tdrm_edid_override_connector_update(&aconnector->base);\n\tedid = aconnector->base.edid_blob_ptr->data;\n\taconnector->edid = edid;\n\n\t \n\tif (dc_em_sink && dc_link) {\n\t\tmemset(&dc_em_sink->edid_caps, 0, sizeof(struct dc_edid_caps));\n\t\tmemmove(dc_em_sink->dc_edid.raw_edid, edid, (edid->extensions + 1) * EDID_LENGTH);\n\t\tdm_helpers_parse_edid_caps(\n\t\t\tdc_link,\n\t\t\t&dc_em_sink->dc_edid,\n\t\t\t&dc_em_sink->edid_caps);\n\t}\n}\n\nstatic const struct drm_connector_funcs amdgpu_dm_connector_funcs = {\n\t.reset = amdgpu_dm_connector_funcs_reset,\n\t.detect = amdgpu_dm_connector_detect,\n\t.fill_modes = drm_helper_probe_single_connector_modes,\n\t.destroy = amdgpu_dm_connector_destroy,\n\t.atomic_duplicate_state = amdgpu_dm_connector_atomic_duplicate_state,\n\t.atomic_destroy_state = drm_atomic_helper_connector_destroy_state,\n\t.atomic_set_property = amdgpu_dm_connector_atomic_set_property,\n\t.atomic_get_property = amdgpu_dm_connector_atomic_get_property,\n\t.late_register = amdgpu_dm_connector_late_register,\n\t.early_unregister = amdgpu_dm_connector_unregister,\n\t.force = amdgpu_dm_connector_funcs_force\n};\n\nstatic int get_modes(struct drm_connector *connector)\n{\n\treturn amdgpu_dm_connector_get_modes(connector);\n}\n\nstatic void create_eml_sink(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct dc_sink_init_data init_params = {\n\t\t\t.link = aconnector->dc_link,\n\t\t\t.sink_signal = SIGNAL_TYPE_VIRTUAL\n\t};\n\tstruct edid *edid;\n\n\tif (!aconnector->base.edid_blob_ptr) {\n\t\t \n\n\t\tdrm_edid_override_connector_update(&aconnector->base);\n\n\t\tif (!aconnector->base.edid_blob_ptr) {\n\t\t\tDRM_ERROR(\"No EDID firmware found on connector: %s ,forcing to OFF!\\n\",\n\t\t\t\t\taconnector->base.name);\n\n\t\t\taconnector->base.force = DRM_FORCE_OFF;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tedid = (struct edid *) aconnector->base.edid_blob_ptr->data;\n\n\taconnector->edid = edid;\n\n\taconnector->dc_em_sink = dc_link_add_remote_sink(\n\t\taconnector->dc_link,\n\t\t(uint8_t *)edid,\n\t\t(edid->extensions + 1) * EDID_LENGTH,\n\t\t&init_params);\n\n\tif (aconnector->base.force == DRM_FORCE_ON) {\n\t\taconnector->dc_sink = aconnector->dc_link->local_sink ?\n\t\taconnector->dc_link->local_sink :\n\t\taconnector->dc_em_sink;\n\t\tdc_sink_retain(aconnector->dc_sink);\n\t}\n}\n\nstatic void handle_edid_mgmt(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct dc_link *link = (struct dc_link *)aconnector->dc_link;\n\n\t \n\tif (link->connector_signal == SIGNAL_TYPE_DISPLAY_PORT) {\n\t\tlink->verified_link_cap.lane_count = LANE_COUNT_FOUR;\n\t\tlink->verified_link_cap.link_rate = LINK_RATE_HIGH2;\n\t}\n\n\tcreate_eml_sink(aconnector);\n}\n\nstatic enum dc_status dm_validate_stream_and_context(struct dc *dc,\n\t\t\t\t\t\tstruct dc_stream_state *stream)\n{\n\tenum dc_status dc_result = DC_ERROR_UNEXPECTED;\n\tstruct dc_plane_state *dc_plane_state = NULL;\n\tstruct dc_state *dc_state = NULL;\n\n\tif (!stream)\n\t\tgoto cleanup;\n\n\tdc_plane_state = dc_create_plane_state(dc);\n\tif (!dc_plane_state)\n\t\tgoto cleanup;\n\n\tdc_state = dc_create_state(dc);\n\tif (!dc_state)\n\t\tgoto cleanup;\n\n\t \n\tdc_plane_state->src_rect.height  = stream->src.height;\n\tdc_plane_state->src_rect.width   = stream->src.width;\n\tdc_plane_state->dst_rect.height  = stream->src.height;\n\tdc_plane_state->dst_rect.width   = stream->src.width;\n\tdc_plane_state->clip_rect.height = stream->src.height;\n\tdc_plane_state->clip_rect.width  = stream->src.width;\n\tdc_plane_state->plane_size.surface_pitch = ((stream->src.width + 255) / 256) * 256;\n\tdc_plane_state->plane_size.surface_size.height = stream->src.height;\n\tdc_plane_state->plane_size.surface_size.width  = stream->src.width;\n\tdc_plane_state->plane_size.chroma_size.height  = stream->src.height;\n\tdc_plane_state->plane_size.chroma_size.width   = stream->src.width;\n\tdc_plane_state->format = SURFACE_PIXEL_FORMAT_GRPH_ARGB8888;\n\tdc_plane_state->tiling_info.gfx9.swizzle = DC_SW_UNKNOWN;\n\tdc_plane_state->rotation = ROTATION_ANGLE_0;\n\tdc_plane_state->is_tiling_rotated = false;\n\tdc_plane_state->tiling_info.gfx8.array_mode = DC_ARRAY_LINEAR_GENERAL;\n\n\tdc_result = dc_validate_stream(dc, stream);\n\tif (dc_result == DC_OK)\n\t\tdc_result = dc_validate_plane(dc, dc_plane_state);\n\n\tif (dc_result == DC_OK)\n\t\tdc_result = dc_add_stream_to_ctx(dc, dc_state, stream);\n\n\tif (dc_result == DC_OK && !dc_add_plane_to_context(\n\t\t\t\t\t\tdc,\n\t\t\t\t\t\tstream,\n\t\t\t\t\t\tdc_plane_state,\n\t\t\t\t\t\tdc_state))\n\t\tdc_result = DC_FAIL_ATTACH_SURFACES;\n\n\tif (dc_result == DC_OK)\n\t\tdc_result = dc_validate_global_state(dc, dc_state, true);\n\ncleanup:\n\tif (dc_state)\n\t\tdc_release_state(dc_state);\n\n\tif (dc_plane_state)\n\t\tdc_plane_state_release(dc_plane_state);\n\n\treturn dc_result;\n}\n\nstruct dc_stream_state *\ncreate_validate_stream_for_sink(struct amdgpu_dm_connector *aconnector,\n\t\t\t\tconst struct drm_display_mode *drm_mode,\n\t\t\t\tconst struct dm_connector_state *dm_state,\n\t\t\t\tconst struct dc_stream_state *old_stream)\n{\n\tstruct drm_connector *connector = &aconnector->base;\n\tstruct amdgpu_device *adev = drm_to_adev(connector->dev);\n\tstruct dc_stream_state *stream;\n\tconst struct drm_connector_state *drm_state = dm_state ? &dm_state->base : NULL;\n\tint requested_bpc = drm_state ? drm_state->max_requested_bpc : 8;\n\tenum dc_status dc_result = DC_OK;\n\n\tdo {\n\t\tstream = create_stream_for_sink(aconnector, drm_mode,\n\t\t\t\t\t\tdm_state, old_stream,\n\t\t\t\t\t\trequested_bpc);\n\t\tif (stream == NULL) {\n\t\t\tDRM_ERROR(\"Failed to create stream for sink!\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tdc_result = dc_validate_stream(adev->dm.dc, stream);\n\t\tif (dc_result == DC_OK && stream->signal == SIGNAL_TYPE_DISPLAY_PORT_MST)\n\t\t\tdc_result = dm_dp_mst_is_port_support_mode(aconnector, stream);\n\n\t\tif (dc_result == DC_OK)\n\t\t\tdc_result = dm_validate_stream_and_context(adev->dm.dc, stream);\n\n\t\tif (dc_result != DC_OK) {\n\t\t\tDRM_DEBUG_KMS(\"Mode %dx%d (clk %d) failed DC validation with error %d (%s)\\n\",\n\t\t\t\t      drm_mode->hdisplay,\n\t\t\t\t      drm_mode->vdisplay,\n\t\t\t\t      drm_mode->clock,\n\t\t\t\t      dc_result,\n\t\t\t\t      dc_status_to_str(dc_result));\n\n\t\t\tdc_stream_release(stream);\n\t\t\tstream = NULL;\n\t\t\trequested_bpc -= 2;  \n\t\t}\n\n\t} while (stream == NULL && requested_bpc >= 6);\n\n\tif (dc_result == DC_FAIL_ENC_VALIDATE && !aconnector->force_yuv420_output) {\n\t\tDRM_DEBUG_KMS(\"Retry forcing YCbCr420 encoding\\n\");\n\n\t\taconnector->force_yuv420_output = true;\n\t\tstream = create_validate_stream_for_sink(aconnector, drm_mode,\n\t\t\t\t\t\tdm_state, old_stream);\n\t\taconnector->force_yuv420_output = false;\n\t}\n\n\treturn stream;\n}\n\nenum drm_mode_status amdgpu_dm_connector_mode_valid(struct drm_connector *connector,\n\t\t\t\t   struct drm_display_mode *mode)\n{\n\tint result = MODE_ERROR;\n\tstruct dc_sink *dc_sink;\n\t \n\tstruct dc_stream_state *stream;\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\n\tif ((mode->flags & DRM_MODE_FLAG_INTERLACE) ||\n\t\t\t(mode->flags & DRM_MODE_FLAG_DBLSCAN))\n\t\treturn result;\n\n\t \n\tif (aconnector->base.force != DRM_FORCE_UNSPECIFIED &&\n\t\t!aconnector->dc_em_sink)\n\t\thandle_edid_mgmt(aconnector);\n\n\tdc_sink = to_amdgpu_dm_connector(connector)->dc_sink;\n\n\tif (dc_sink == NULL && aconnector->base.force != DRM_FORCE_ON_DIGITAL &&\n\t\t\t\taconnector->base.force != DRM_FORCE_ON) {\n\t\tDRM_ERROR(\"dc_sink is NULL!\\n\");\n\t\tgoto fail;\n\t}\n\n\tdrm_mode_set_crtcinfo(mode, 0);\n\n\tstream = create_validate_stream_for_sink(aconnector, mode,\n\t\t\t\t\t\t to_dm_connector_state(connector->state),\n\t\t\t\t\t\t NULL);\n\tif (stream) {\n\t\tdc_stream_release(stream);\n\t\tresult = MODE_OK;\n\t}\n\nfail:\n\t \n\treturn result;\n}\n\nstatic int fill_hdr_info_packet(const struct drm_connector_state *state,\n\t\t\t\tstruct dc_info_packet *out)\n{\n\tstruct hdmi_drm_infoframe frame;\n\tunsigned char buf[30];  \n\tssize_t len;\n\tint ret, i;\n\n\tmemset(out, 0, sizeof(*out));\n\n\tif (!state->hdr_output_metadata)\n\t\treturn 0;\n\n\tret = drm_hdmi_infoframe_set_hdr_metadata(&frame, state);\n\tif (ret)\n\t\treturn ret;\n\n\tlen = hdmi_drm_infoframe_pack_only(&frame, buf, sizeof(buf));\n\tif (len < 0)\n\t\treturn (int)len;\n\n\t \n\tif (len != 30)\n\t\treturn -EINVAL;\n\n\t \n\tswitch (state->connector->connector_type) {\n\tcase DRM_MODE_CONNECTOR_HDMIA:\n\t\tout->hb0 = 0x87;  \n\t\tout->hb1 = 0x01;  \n\t\tout->hb2 = 0x1A;  \n\t\tout->sb[0] = buf[3];  \n\t\ti = 1;\n\t\tbreak;\n\n\tcase DRM_MODE_CONNECTOR_DisplayPort:\n\tcase DRM_MODE_CONNECTOR_eDP:\n\t\tout->hb0 = 0x00;  \n\t\tout->hb1 = 0x87;  \n\t\tout->hb2 = 0x1D;  \n\t\tout->hb3 = (0x13 << 2);  \n\t\tout->sb[0] = 0x01;  \n\t\tout->sb[1] = 0x1A;  \n\t\ti = 2;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&out->sb[i], &buf[4], 26);\n\tout->valid = true;\n\n\tprint_hex_dump(KERN_DEBUG, \"HDR SB:\", DUMP_PREFIX_NONE, 16, 1, out->sb,\n\t\t       sizeof(out->sb), false);\n\n\treturn 0;\n}\n\nstatic int\namdgpu_dm_connector_atomic_check(struct drm_connector *conn,\n\t\t\t\t struct drm_atomic_state *state)\n{\n\tstruct drm_connector_state *new_con_state =\n\t\tdrm_atomic_get_new_connector_state(state, conn);\n\tstruct drm_connector_state *old_con_state =\n\t\tdrm_atomic_get_old_connector_state(state, conn);\n\tstruct drm_crtc *crtc = new_con_state->crtc;\n\tstruct drm_crtc_state *new_crtc_state;\n\tstruct amdgpu_dm_connector *aconn = to_amdgpu_dm_connector(conn);\n\tint ret;\n\n\ttrace_amdgpu_dm_connector_atomic_check(new_con_state);\n\n\tif (conn->connector_type == DRM_MODE_CONNECTOR_DisplayPort) {\n\t\tret = drm_dp_mst_root_conn_atomic_check(new_con_state, &aconn->mst_mgr);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tif (!crtc)\n\t\treturn 0;\n\n\tif (new_con_state->colorspace != old_con_state->colorspace) {\n\t\tnew_crtc_state = drm_atomic_get_crtc_state(state, crtc);\n\t\tif (IS_ERR(new_crtc_state))\n\t\t\treturn PTR_ERR(new_crtc_state);\n\n\t\tnew_crtc_state->mode_changed = true;\n\t}\n\n\tif (!drm_connector_atomic_hdr_metadata_equal(old_con_state, new_con_state)) {\n\t\tstruct dc_info_packet hdr_infopacket;\n\n\t\tret = fill_hdr_info_packet(new_con_state, &hdr_infopacket);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tnew_crtc_state = drm_atomic_get_crtc_state(state, crtc);\n\t\tif (IS_ERR(new_crtc_state))\n\t\t\treturn PTR_ERR(new_crtc_state);\n\n\t\t \n\t\tnew_crtc_state->mode_changed = new_crtc_state->mode_changed ||\n\t\t\t!old_con_state->hdr_output_metadata ||\n\t\t\t!new_con_state->hdr_output_metadata;\n\t}\n\n\treturn 0;\n}\n\nstatic const struct drm_connector_helper_funcs\namdgpu_dm_connector_helper_funcs = {\n\t \n\t.get_modes = get_modes,\n\t.mode_valid = amdgpu_dm_connector_mode_valid,\n\t.atomic_check = amdgpu_dm_connector_atomic_check,\n};\n\nstatic void dm_encoder_helper_disable(struct drm_encoder *encoder)\n{\n\n}\n\nint convert_dc_color_depth_into_bpc(enum dc_color_depth display_color_depth)\n{\n\tswitch (display_color_depth) {\n\tcase COLOR_DEPTH_666:\n\t\treturn 6;\n\tcase COLOR_DEPTH_888:\n\t\treturn 8;\n\tcase COLOR_DEPTH_101010:\n\t\treturn 10;\n\tcase COLOR_DEPTH_121212:\n\t\treturn 12;\n\tcase COLOR_DEPTH_141414:\n\t\treturn 14;\n\tcase COLOR_DEPTH_161616:\n\t\treturn 16;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int dm_encoder_helper_atomic_check(struct drm_encoder *encoder,\n\t\t\t\t\t  struct drm_crtc_state *crtc_state,\n\t\t\t\t\t  struct drm_connector_state *conn_state)\n{\n\tstruct drm_atomic_state *state = crtc_state->state;\n\tstruct drm_connector *connector = conn_state->connector;\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct dm_connector_state *dm_new_connector_state = to_dm_connector_state(conn_state);\n\tconst struct drm_display_mode *adjusted_mode = &crtc_state->adjusted_mode;\n\tstruct drm_dp_mst_topology_mgr *mst_mgr;\n\tstruct drm_dp_mst_port *mst_port;\n\tstruct drm_dp_mst_topology_state *mst_state;\n\tenum dc_color_depth color_depth;\n\tint clock, bpp = 0;\n\tbool is_y420 = false;\n\n\tif (!aconnector->mst_output_port)\n\t\treturn 0;\n\n\tmst_port = aconnector->mst_output_port;\n\tmst_mgr = &aconnector->mst_root->mst_mgr;\n\n\tif (!crtc_state->connectors_changed && !crtc_state->mode_changed)\n\t\treturn 0;\n\n\tmst_state = drm_atomic_get_mst_topology_state(state, mst_mgr);\n\tif (IS_ERR(mst_state))\n\t\treturn PTR_ERR(mst_state);\n\n\tmst_state->pbn_div = dm_mst_get_pbn_divider(aconnector->mst_root->dc_link);\n\n\tif (!state->duplicated) {\n\t\tint max_bpc = conn_state->max_requested_bpc;\n\n\t\tis_y420 = drm_mode_is_420_also(&connector->display_info, adjusted_mode) &&\n\t\t\t  aconnector->force_yuv420_output;\n\t\tcolor_depth = convert_color_depth_from_display_info(connector,\n\t\t\t\t\t\t\t\t    is_y420,\n\t\t\t\t\t\t\t\t    max_bpc);\n\t\tbpp = convert_dc_color_depth_into_bpc(color_depth) * 3;\n\t\tclock = adjusted_mode->clock;\n\t\tdm_new_connector_state->pbn = drm_dp_calc_pbn_mode(clock, bpp << 4);\n\t}\n\n\tdm_new_connector_state->vcpi_slots =\n\t\tdrm_dp_atomic_find_time_slots(state, mst_mgr, mst_port,\n\t\t\t\t\t      dm_new_connector_state->pbn);\n\tif (dm_new_connector_state->vcpi_slots < 0) {\n\t\tDRM_DEBUG_ATOMIC(\"failed finding vcpi slots: %d\\n\", (int)dm_new_connector_state->vcpi_slots);\n\t\treturn dm_new_connector_state->vcpi_slots;\n\t}\n\treturn 0;\n}\n\nconst struct drm_encoder_helper_funcs amdgpu_dm_encoder_helper_funcs = {\n\t.disable = dm_encoder_helper_disable,\n\t.atomic_check = dm_encoder_helper_atomic_check\n};\n\nstatic int dm_update_mst_vcpi_slots_for_dsc(struct drm_atomic_state *state,\n\t\t\t\t\t    struct dc_state *dc_state,\n\t\t\t\t\t    struct dsc_mst_fairness_vars *vars)\n{\n\tstruct dc_stream_state *stream = NULL;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_state *new_con_state;\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct dm_connector_state *dm_conn_state;\n\tint i, j, ret;\n\tint vcpi, pbn_div, pbn, slot_num = 0;\n\n\tfor_each_new_connector_in_state(state, connector, new_con_state, i) {\n\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\n\t\tif (!aconnector->mst_output_port)\n\t\t\tcontinue;\n\n\t\tif (!new_con_state || !new_con_state->crtc)\n\t\t\tcontinue;\n\n\t\tdm_conn_state = to_dm_connector_state(new_con_state);\n\n\t\tfor (j = 0; j < dc_state->stream_count; j++) {\n\t\t\tstream = dc_state->streams[j];\n\t\t\tif (!stream)\n\t\t\t\tcontinue;\n\n\t\t\tif ((struct amdgpu_dm_connector *)stream->dm_stream_context == aconnector)\n\t\t\t\tbreak;\n\n\t\t\tstream = NULL;\n\t\t}\n\n\t\tif (!stream)\n\t\t\tcontinue;\n\n\t\tpbn_div = dm_mst_get_pbn_divider(stream->link);\n\t\t \n\t\tfor (j = 0; j < dc_state->stream_count; j++) {\n\t\t\tif (vars[j].aconnector == aconnector) {\n\t\t\t\tpbn = vars[j].pbn;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (j == dc_state->stream_count)\n\t\t\tcontinue;\n\n\t\tslot_num = DIV_ROUND_UP(pbn, pbn_div);\n\n\t\tif (stream->timing.flags.DSC != 1) {\n\t\t\tdm_conn_state->pbn = pbn;\n\t\t\tdm_conn_state->vcpi_slots = slot_num;\n\n\t\t\tret = drm_dp_mst_atomic_enable_dsc(state, aconnector->mst_output_port,\n\t\t\t\t\t\t\t   dm_conn_state->pbn, false);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tvcpi = drm_dp_mst_atomic_enable_dsc(state, aconnector->mst_output_port, pbn, true);\n\t\tif (vcpi < 0)\n\t\t\treturn vcpi;\n\n\t\tdm_conn_state->pbn = pbn;\n\t\tdm_conn_state->vcpi_slots = vcpi;\n\t}\n\treturn 0;\n}\n\nstatic int to_drm_connector_type(enum signal_type st)\n{\n\tswitch (st) {\n\tcase SIGNAL_TYPE_HDMI_TYPE_A:\n\t\treturn DRM_MODE_CONNECTOR_HDMIA;\n\tcase SIGNAL_TYPE_EDP:\n\t\treturn DRM_MODE_CONNECTOR_eDP;\n\tcase SIGNAL_TYPE_LVDS:\n\t\treturn DRM_MODE_CONNECTOR_LVDS;\n\tcase SIGNAL_TYPE_RGB:\n\t\treturn DRM_MODE_CONNECTOR_VGA;\n\tcase SIGNAL_TYPE_DISPLAY_PORT:\n\tcase SIGNAL_TYPE_DISPLAY_PORT_MST:\n\t\treturn DRM_MODE_CONNECTOR_DisplayPort;\n\tcase SIGNAL_TYPE_DVI_DUAL_LINK:\n\tcase SIGNAL_TYPE_DVI_SINGLE_LINK:\n\t\treturn DRM_MODE_CONNECTOR_DVID;\n\tcase SIGNAL_TYPE_VIRTUAL:\n\t\treturn DRM_MODE_CONNECTOR_VIRTUAL;\n\n\tdefault:\n\t\treturn DRM_MODE_CONNECTOR_Unknown;\n\t}\n}\n\nstatic struct drm_encoder *amdgpu_dm_connector_to_encoder(struct drm_connector *connector)\n{\n\tstruct drm_encoder *encoder;\n\n\t \n\tdrm_connector_for_each_possible_encoder(connector, encoder)\n\t\treturn encoder;\n\n\treturn NULL;\n}\n\nstatic void amdgpu_dm_get_native_mode(struct drm_connector *connector)\n{\n\tstruct drm_encoder *encoder;\n\tstruct amdgpu_encoder *amdgpu_encoder;\n\n\tencoder = amdgpu_dm_connector_to_encoder(connector);\n\n\tif (encoder == NULL)\n\t\treturn;\n\n\tamdgpu_encoder = to_amdgpu_encoder(encoder);\n\n\tamdgpu_encoder->native_mode.clock = 0;\n\n\tif (!list_empty(&connector->probed_modes)) {\n\t\tstruct drm_display_mode *preferred_mode = NULL;\n\n\t\tlist_for_each_entry(preferred_mode,\n\t\t\t\t    &connector->probed_modes,\n\t\t\t\t    head) {\n\t\t\tif (preferred_mode->type & DRM_MODE_TYPE_PREFERRED)\n\t\t\t\tamdgpu_encoder->native_mode = *preferred_mode;\n\n\t\t\tbreak;\n\t\t}\n\n\t}\n}\n\nstatic struct drm_display_mode *\namdgpu_dm_create_common_mode(struct drm_encoder *encoder,\n\t\t\t     char *name,\n\t\t\t     int hdisplay, int vdisplay)\n{\n\tstruct drm_device *dev = encoder->dev;\n\tstruct amdgpu_encoder *amdgpu_encoder = to_amdgpu_encoder(encoder);\n\tstruct drm_display_mode *mode = NULL;\n\tstruct drm_display_mode *native_mode = &amdgpu_encoder->native_mode;\n\n\tmode = drm_mode_duplicate(dev, native_mode);\n\n\tif (mode == NULL)\n\t\treturn NULL;\n\n\tmode->hdisplay = hdisplay;\n\tmode->vdisplay = vdisplay;\n\tmode->type &= ~DRM_MODE_TYPE_PREFERRED;\n\tstrscpy(mode->name, name, DRM_DISPLAY_MODE_LEN);\n\n\treturn mode;\n\n}\n\nstatic void amdgpu_dm_connector_add_common_modes(struct drm_encoder *encoder,\n\t\t\t\t\t\t struct drm_connector *connector)\n{\n\tstruct amdgpu_encoder *amdgpu_encoder = to_amdgpu_encoder(encoder);\n\tstruct drm_display_mode *mode = NULL;\n\tstruct drm_display_mode *native_mode = &amdgpu_encoder->native_mode;\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\t\t\tto_amdgpu_dm_connector(connector);\n\tint i;\n\tint n;\n\tstruct mode_size {\n\t\tchar name[DRM_DISPLAY_MODE_LEN];\n\t\tint w;\n\t\tint h;\n\t} common_modes[] = {\n\t\t{  \"640x480\",  640,  480},\n\t\t{  \"800x600\",  800,  600},\n\t\t{ \"1024x768\", 1024,  768},\n\t\t{ \"1280x720\", 1280,  720},\n\t\t{ \"1280x800\", 1280,  800},\n\t\t{\"1280x1024\", 1280, 1024},\n\t\t{ \"1440x900\", 1440,  900},\n\t\t{\"1680x1050\", 1680, 1050},\n\t\t{\"1600x1200\", 1600, 1200},\n\t\t{\"1920x1080\", 1920, 1080},\n\t\t{\"1920x1200\", 1920, 1200}\n\t};\n\n\tn = ARRAY_SIZE(common_modes);\n\n\tfor (i = 0; i < n; i++) {\n\t\tstruct drm_display_mode *curmode = NULL;\n\t\tbool mode_existed = false;\n\n\t\tif (common_modes[i].w > native_mode->hdisplay ||\n\t\t    common_modes[i].h > native_mode->vdisplay ||\n\t\t   (common_modes[i].w == native_mode->hdisplay &&\n\t\t    common_modes[i].h == native_mode->vdisplay))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry(curmode, &connector->probed_modes, head) {\n\t\t\tif (common_modes[i].w == curmode->hdisplay &&\n\t\t\t    common_modes[i].h == curmode->vdisplay) {\n\t\t\t\tmode_existed = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (mode_existed)\n\t\t\tcontinue;\n\n\t\tmode = amdgpu_dm_create_common_mode(encoder,\n\t\t\t\tcommon_modes[i].name, common_modes[i].w,\n\t\t\t\tcommon_modes[i].h);\n\t\tif (!mode)\n\t\t\tcontinue;\n\n\t\tdrm_mode_probed_add(connector, mode);\n\t\tamdgpu_dm_connector->num_modes++;\n\t}\n}\n\nstatic void amdgpu_set_panel_orientation(struct drm_connector *connector)\n{\n\tstruct drm_encoder *encoder;\n\tstruct amdgpu_encoder *amdgpu_encoder;\n\tconst struct drm_display_mode *native_mode;\n\n\tif (connector->connector_type != DRM_MODE_CONNECTOR_eDP &&\n\t    connector->connector_type != DRM_MODE_CONNECTOR_LVDS)\n\t\treturn;\n\n\tmutex_lock(&connector->dev->mode_config.mutex);\n\tamdgpu_dm_connector_get_modes(connector);\n\tmutex_unlock(&connector->dev->mode_config.mutex);\n\n\tencoder = amdgpu_dm_connector_to_encoder(connector);\n\tif (!encoder)\n\t\treturn;\n\n\tamdgpu_encoder = to_amdgpu_encoder(encoder);\n\n\tnative_mode = &amdgpu_encoder->native_mode;\n\tif (native_mode->hdisplay == 0 || native_mode->vdisplay == 0)\n\t\treturn;\n\n\tdrm_connector_set_panel_orientation_with_quirk(connector,\n\t\t\t\t\t\t       DRM_MODE_PANEL_ORIENTATION_UNKNOWN,\n\t\t\t\t\t\t       native_mode->hdisplay,\n\t\t\t\t\t\t       native_mode->vdisplay);\n}\n\nstatic void amdgpu_dm_connector_ddc_get_modes(struct drm_connector *connector,\n\t\t\t\t\t      struct edid *edid)\n{\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\t\tto_amdgpu_dm_connector(connector);\n\n\tif (edid) {\n\t\t \n\t\tINIT_LIST_HEAD(&connector->probed_modes);\n\t\tamdgpu_dm_connector->num_modes =\n\t\t\t\tdrm_add_edid_modes(connector, edid);\n\n\t\t \n\t\tdrm_mode_sort(&connector->probed_modes);\n\t\tamdgpu_dm_get_native_mode(connector);\n\n\t\t \n\t\tamdgpu_dm_update_freesync_caps(connector, edid);\n\t} else {\n\t\tamdgpu_dm_connector->num_modes = 0;\n\t}\n}\n\nstatic bool is_duplicate_mode(struct amdgpu_dm_connector *aconnector,\n\t\t\t      struct drm_display_mode *mode)\n{\n\tstruct drm_display_mode *m;\n\n\tlist_for_each_entry(m, &aconnector->base.probed_modes, head) {\n\t\tif (drm_mode_equal(m, mode))\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic uint add_fs_modes(struct amdgpu_dm_connector *aconnector)\n{\n\tconst struct drm_display_mode *m;\n\tstruct drm_display_mode *new_mode;\n\tuint i;\n\tu32 new_modes_count = 0;\n\n\t \n\tstatic const u32 common_rates[] = {\n\t\t23976, 24000, 25000, 29970, 30000,\n\t\t48000, 50000, 60000, 72000, 96000, 120000\n\t};\n\n\t \n\n\tm = get_highest_refresh_rate_mode(aconnector, true);\n\tif (!m)\n\t\treturn 0;\n\n\tfor (i = 0; i < ARRAY_SIZE(common_rates); i++) {\n\t\tu64 target_vtotal, target_vtotal_diff;\n\t\tu64 num, den;\n\n\t\tif (drm_mode_vrefresh(m) * 1000 < common_rates[i])\n\t\t\tcontinue;\n\n\t\tif (common_rates[i] < aconnector->min_vfreq * 1000 ||\n\t\t    common_rates[i] > aconnector->max_vfreq * 1000)\n\t\t\tcontinue;\n\n\t\tnum = (unsigned long long)m->clock * 1000 * 1000;\n\t\tden = common_rates[i] * (unsigned long long)m->htotal;\n\t\ttarget_vtotal = div_u64(num, den);\n\t\ttarget_vtotal_diff = target_vtotal - m->vtotal;\n\n\t\t \n\t\tif (m->vsync_start + target_vtotal_diff < m->vdisplay ||\n\t\t    m->vsync_end + target_vtotal_diff < m->vsync_start ||\n\t\t    m->vtotal + target_vtotal_diff < m->vsync_end)\n\t\t\tcontinue;\n\n\t\tnew_mode = drm_mode_duplicate(aconnector->base.dev, m);\n\t\tif (!new_mode)\n\t\t\tgoto out;\n\n\t\tnew_mode->vtotal += (u16)target_vtotal_diff;\n\t\tnew_mode->vsync_start += (u16)target_vtotal_diff;\n\t\tnew_mode->vsync_end += (u16)target_vtotal_diff;\n\t\tnew_mode->type &= ~DRM_MODE_TYPE_PREFERRED;\n\t\tnew_mode->type |= DRM_MODE_TYPE_DRIVER;\n\n\t\tif (!is_duplicate_mode(aconnector, new_mode)) {\n\t\t\tdrm_mode_probed_add(&aconnector->base, new_mode);\n\t\t\tnew_modes_count += 1;\n\t\t} else\n\t\t\tdrm_mode_destroy(aconnector->base.dev, new_mode);\n\t}\n out:\n\treturn new_modes_count;\n}\n\nstatic void amdgpu_dm_connector_add_freesync_modes(struct drm_connector *connector,\n\t\t\t\t\t\t   struct edid *edid)\n{\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\tto_amdgpu_dm_connector(connector);\n\n\tif (!edid)\n\t\treturn;\n\n\tif (amdgpu_dm_connector->max_vfreq - amdgpu_dm_connector->min_vfreq > 10)\n\t\tamdgpu_dm_connector->num_modes +=\n\t\t\tadd_fs_modes(amdgpu_dm_connector);\n}\n\nstatic int amdgpu_dm_connector_get_modes(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\t\tto_amdgpu_dm_connector(connector);\n\tstruct drm_encoder *encoder;\n\tstruct edid *edid = amdgpu_dm_connector->edid;\n\tstruct dc_link_settings *verified_link_cap =\n\t\t\t&amdgpu_dm_connector->dc_link->verified_link_cap;\n\tconst struct dc *dc = amdgpu_dm_connector->dc_link->dc;\n\n\tencoder = amdgpu_dm_connector_to_encoder(connector);\n\n\tif (!drm_edid_is_valid(edid)) {\n\t\tamdgpu_dm_connector->num_modes =\n\t\t\t\tdrm_add_modes_noedid(connector, 640, 480);\n\t\tif (dc->link_srv->dp_get_encoding_format(verified_link_cap) == DP_128b_132b_ENCODING)\n\t\t\tamdgpu_dm_connector->num_modes +=\n\t\t\t\tdrm_add_modes_noedid(connector, 1920, 1080);\n\t} else {\n\t\tamdgpu_dm_connector_ddc_get_modes(connector, edid);\n\t\tamdgpu_dm_connector_add_common_modes(encoder, connector);\n\t\tamdgpu_dm_connector_add_freesync_modes(connector, edid);\n\t}\n\tamdgpu_dm_fbc_init(connector);\n\n\treturn amdgpu_dm_connector->num_modes;\n}\n\nstatic const u32 supported_colorspaces =\n\tBIT(DRM_MODE_COLORIMETRY_BT709_YCC) |\n\tBIT(DRM_MODE_COLORIMETRY_OPRGB) |\n\tBIT(DRM_MODE_COLORIMETRY_BT2020_RGB) |\n\tBIT(DRM_MODE_COLORIMETRY_BT2020_YCC);\n\nvoid amdgpu_dm_connector_init_helper(struct amdgpu_display_manager *dm,\n\t\t\t\t     struct amdgpu_dm_connector *aconnector,\n\t\t\t\t     int connector_type,\n\t\t\t\t     struct dc_link *link,\n\t\t\t\t     int link_index)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(dm->ddev);\n\n\t \n\tif (aconnector->base.funcs->reset)\n\t\taconnector->base.funcs->reset(&aconnector->base);\n\n\taconnector->connector_id = link_index;\n\taconnector->bl_idx = -1;\n\taconnector->dc_link = link;\n\taconnector->base.interlace_allowed = false;\n\taconnector->base.doublescan_allowed = false;\n\taconnector->base.stereo_allowed = false;\n\taconnector->base.dpms = DRM_MODE_DPMS_OFF;\n\taconnector->hpd.hpd = AMDGPU_HPD_NONE;  \n\taconnector->audio_inst = -1;\n\taconnector->pack_sdp_v1_3 = false;\n\taconnector->as_type = ADAPTIVE_SYNC_TYPE_NONE;\n\tmemset(&aconnector->vsdb_info, 0, sizeof(aconnector->vsdb_info));\n\tmutex_init(&aconnector->hpd_lock);\n\tmutex_init(&aconnector->handle_mst_msg_ready);\n\n\t \n\tswitch (connector_type) {\n\tcase DRM_MODE_CONNECTOR_HDMIA:\n\t\taconnector->base.polled = DRM_CONNECTOR_POLL_HPD;\n\t\taconnector->base.ycbcr_420_allowed =\n\t\t\tlink->link_enc->features.hdmi_ycbcr420_supported ? true : false;\n\t\tbreak;\n\tcase DRM_MODE_CONNECTOR_DisplayPort:\n\t\taconnector->base.polled = DRM_CONNECTOR_POLL_HPD;\n\t\tlink->link_enc = link_enc_cfg_get_link_enc(link);\n\t\tASSERT(link->link_enc);\n\t\tif (link->link_enc)\n\t\t\taconnector->base.ycbcr_420_allowed =\n\t\t\tlink->link_enc->features.dp_ycbcr420_supported ? true : false;\n\t\tbreak;\n\tcase DRM_MODE_CONNECTOR_DVID:\n\t\taconnector->base.polled = DRM_CONNECTOR_POLL_HPD;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tdrm_object_attach_property(&aconnector->base.base,\n\t\t\t\tdm->ddev->mode_config.scaling_mode_property,\n\t\t\t\tDRM_MODE_SCALE_NONE);\n\n\tdrm_object_attach_property(&aconnector->base.base,\n\t\t\t\tadev->mode_info.underscan_property,\n\t\t\t\tUNDERSCAN_OFF);\n\tdrm_object_attach_property(&aconnector->base.base,\n\t\t\t\tadev->mode_info.underscan_hborder_property,\n\t\t\t\t0);\n\tdrm_object_attach_property(&aconnector->base.base,\n\t\t\t\tadev->mode_info.underscan_vborder_property,\n\t\t\t\t0);\n\n\tif (!aconnector->mst_root)\n\t\tdrm_connector_attach_max_bpc_property(&aconnector->base, 8, 16);\n\n\taconnector->base.state->max_bpc = 16;\n\taconnector->base.state->max_requested_bpc = aconnector->base.state->max_bpc;\n\n\tif (connector_type == DRM_MODE_CONNECTOR_eDP &&\n\t    (dc_is_dmcu_initialized(adev->dm.dc) || adev->dm.dc->ctx->dmub_srv)) {\n\t\tdrm_object_attach_property(&aconnector->base.base,\n\t\t\t\tadev->mode_info.abm_level_property, 0);\n\t}\n\n\tif (connector_type == DRM_MODE_CONNECTOR_HDMIA) {\n\t\tif (!drm_mode_create_hdmi_colorspace_property(&aconnector->base, supported_colorspaces))\n\t\t\tdrm_connector_attach_colorspace_property(&aconnector->base);\n\t} else if ((connector_type == DRM_MODE_CONNECTOR_DisplayPort && !aconnector->mst_root) ||\n\t\t   connector_type == DRM_MODE_CONNECTOR_eDP) {\n\t\tif (!drm_mode_create_dp_colorspace_property(&aconnector->base, supported_colorspaces))\n\t\t\tdrm_connector_attach_colorspace_property(&aconnector->base);\n\t}\n\n\tif (connector_type == DRM_MODE_CONNECTOR_HDMIA ||\n\t    connector_type == DRM_MODE_CONNECTOR_DisplayPort ||\n\t    connector_type == DRM_MODE_CONNECTOR_eDP) {\n\t\tdrm_connector_attach_hdr_output_metadata_property(&aconnector->base);\n\n\t\tif (!aconnector->mst_root)\n\t\t\tdrm_connector_attach_vrr_capable_property(&aconnector->base);\n\n\t\tif (adev->dm.hdcp_workqueue)\n\t\t\tdrm_connector_attach_content_protection_property(&aconnector->base, true);\n\t}\n}\n\nstatic int amdgpu_dm_i2c_xfer(struct i2c_adapter *i2c_adap,\n\t\t\t      struct i2c_msg *msgs, int num)\n{\n\tstruct amdgpu_i2c_adapter *i2c = i2c_get_adapdata(i2c_adap);\n\tstruct ddc_service *ddc_service = i2c->ddc_service;\n\tstruct i2c_command cmd;\n\tint i;\n\tint result = -EIO;\n\n\tif (!ddc_service->ddc_pin || !ddc_service->ddc_pin->hw_info.hw_supported)\n\t\treturn result;\n\n\tcmd.payloads = kcalloc(num, sizeof(struct i2c_payload), GFP_KERNEL);\n\n\tif (!cmd.payloads)\n\t\treturn result;\n\n\tcmd.number_of_payloads = num;\n\tcmd.engine = I2C_COMMAND_ENGINE_DEFAULT;\n\tcmd.speed = 100;\n\n\tfor (i = 0; i < num; i++) {\n\t\tcmd.payloads[i].write = !(msgs[i].flags & I2C_M_RD);\n\t\tcmd.payloads[i].address = msgs[i].addr;\n\t\tcmd.payloads[i].length = msgs[i].len;\n\t\tcmd.payloads[i].data = msgs[i].buf;\n\t}\n\n\tif (dc_submit_i2c(\n\t\t\tddc_service->ctx->dc,\n\t\t\tddc_service->link->link_index,\n\t\t\t&cmd))\n\t\tresult = num;\n\n\tkfree(cmd.payloads);\n\treturn result;\n}\n\nstatic u32 amdgpu_dm_i2c_func(struct i2c_adapter *adap)\n{\n\treturn I2C_FUNC_I2C | I2C_FUNC_SMBUS_EMUL;\n}\n\nstatic const struct i2c_algorithm amdgpu_dm_i2c_algo = {\n\t.master_xfer = amdgpu_dm_i2c_xfer,\n\t.functionality = amdgpu_dm_i2c_func,\n};\n\nstatic struct amdgpu_i2c_adapter *\ncreate_i2c(struct ddc_service *ddc_service,\n\t   int link_index,\n\t   int *res)\n{\n\tstruct amdgpu_device *adev = ddc_service->ctx->driver_context;\n\tstruct amdgpu_i2c_adapter *i2c;\n\n\ti2c = kzalloc(sizeof(struct amdgpu_i2c_adapter), GFP_KERNEL);\n\tif (!i2c)\n\t\treturn NULL;\n\ti2c->base.owner = THIS_MODULE;\n\ti2c->base.class = I2C_CLASS_DDC;\n\ti2c->base.dev.parent = &adev->pdev->dev;\n\ti2c->base.algo = &amdgpu_dm_i2c_algo;\n\tsnprintf(i2c->base.name, sizeof(i2c->base.name), \"AMDGPU DM i2c hw bus %d\", link_index);\n\ti2c_set_adapdata(&i2c->base, i2c);\n\ti2c->ddc_service = ddc_service;\n\n\treturn i2c;\n}\n\n\n \nstatic int amdgpu_dm_connector_init(struct amdgpu_display_manager *dm,\n\t\t\t\t    struct amdgpu_dm_connector *aconnector,\n\t\t\t\t    u32 link_index,\n\t\t\t\t    struct amdgpu_encoder *aencoder)\n{\n\tint res = 0;\n\tint connector_type;\n\tstruct dc *dc = dm->dc;\n\tstruct dc_link *link = dc_get_link_at_index(dc, link_index);\n\tstruct amdgpu_i2c_adapter *i2c;\n\n\tlink->priv = aconnector;\n\n\n\ti2c = create_i2c(link->ddc, link->link_index, &res);\n\tif (!i2c) {\n\t\tDRM_ERROR(\"Failed to create i2c adapter data\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\taconnector->i2c = i2c;\n\tres = i2c_add_adapter(&i2c->base);\n\n\tif (res) {\n\t\tDRM_ERROR(\"Failed to register hw i2c %d\\n\", link->link_index);\n\t\tgoto out_free;\n\t}\n\n\tconnector_type = to_drm_connector_type(link->connector_signal);\n\n\tres = drm_connector_init_with_ddc(\n\t\t\tdm->ddev,\n\t\t\t&aconnector->base,\n\t\t\t&amdgpu_dm_connector_funcs,\n\t\t\tconnector_type,\n\t\t\t&i2c->base);\n\n\tif (res) {\n\t\tDRM_ERROR(\"connector_init failed\\n\");\n\t\taconnector->connector_id = -1;\n\t\tgoto out_free;\n\t}\n\n\tdrm_connector_helper_add(\n\t\t\t&aconnector->base,\n\t\t\t&amdgpu_dm_connector_helper_funcs);\n\n\tamdgpu_dm_connector_init_helper(\n\t\tdm,\n\t\taconnector,\n\t\tconnector_type,\n\t\tlink,\n\t\tlink_index);\n\n\tdrm_connector_attach_encoder(\n\t\t&aconnector->base, &aencoder->base);\n\n\tif (connector_type == DRM_MODE_CONNECTOR_DisplayPort\n\t\t|| connector_type == DRM_MODE_CONNECTOR_eDP)\n\t\tamdgpu_dm_initialize_dp_connector(dm, aconnector, link->link_index);\n\nout_free:\n\tif (res) {\n\t\tkfree(i2c);\n\t\taconnector->i2c = NULL;\n\t}\n\treturn res;\n}\n\nint amdgpu_dm_get_encoder_crtc_mask(struct amdgpu_device *adev)\n{\n\tswitch (adev->mode_info.num_crtc) {\n\tcase 1:\n\t\treturn 0x1;\n\tcase 2:\n\t\treturn 0x3;\n\tcase 3:\n\t\treturn 0x7;\n\tcase 4:\n\t\treturn 0xf;\n\tcase 5:\n\t\treturn 0x1f;\n\tcase 6:\n\tdefault:\n\t\treturn 0x3f;\n\t}\n}\n\nstatic int amdgpu_dm_encoder_init(struct drm_device *dev,\n\t\t\t\t  struct amdgpu_encoder *aencoder,\n\t\t\t\t  uint32_t link_index)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\n\tint res = drm_encoder_init(dev,\n\t\t\t\t   &aencoder->base,\n\t\t\t\t   &amdgpu_dm_encoder_funcs,\n\t\t\t\t   DRM_MODE_ENCODER_TMDS,\n\t\t\t\t   NULL);\n\n\taencoder->base.possible_crtcs = amdgpu_dm_get_encoder_crtc_mask(adev);\n\n\tif (!res)\n\t\taencoder->encoder_id = link_index;\n\telse\n\t\taencoder->encoder_id = -1;\n\n\tdrm_encoder_helper_add(&aencoder->base, &amdgpu_dm_encoder_helper_funcs);\n\n\treturn res;\n}\n\nstatic void manage_dm_interrupts(struct amdgpu_device *adev,\n\t\t\t\t struct amdgpu_crtc *acrtc,\n\t\t\t\t bool enable)\n{\n\t \n\tint irq_type =\n\t\tamdgpu_display_crtc_idx_to_irq_type(\n\t\t\tadev,\n\t\t\tacrtc->crtc_id);\n\n\tif (enable) {\n\t\tdrm_crtc_vblank_on(&acrtc->base);\n\t\tamdgpu_irq_get(\n\t\t\tadev,\n\t\t\t&adev->pageflip_irq,\n\t\t\tirq_type);\n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n\t\tamdgpu_irq_get(\n\t\t\tadev,\n\t\t\t&adev->vline0_irq,\n\t\t\tirq_type);\n#endif\n\t} else {\n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n\t\tamdgpu_irq_put(\n\t\t\tadev,\n\t\t\t&adev->vline0_irq,\n\t\t\tirq_type);\n#endif\n\t\tamdgpu_irq_put(\n\t\t\tadev,\n\t\t\t&adev->pageflip_irq,\n\t\t\tirq_type);\n\t\tdrm_crtc_vblank_off(&acrtc->base);\n\t}\n}\n\nstatic void dm_update_pflip_irq_state(struct amdgpu_device *adev,\n\t\t\t\t      struct amdgpu_crtc *acrtc)\n{\n\tint irq_type =\n\t\tamdgpu_display_crtc_idx_to_irq_type(adev, acrtc->crtc_id);\n\n\t \n\tamdgpu_irq_update(adev, &adev->pageflip_irq, irq_type);\n}\n\nstatic bool\nis_scaling_state_different(const struct dm_connector_state *dm_state,\n\t\t\t   const struct dm_connector_state *old_dm_state)\n{\n\tif (dm_state->scaling != old_dm_state->scaling)\n\t\treturn true;\n\tif (!dm_state->underscan_enable && old_dm_state->underscan_enable) {\n\t\tif (old_dm_state->underscan_hborder != 0 && old_dm_state->underscan_vborder != 0)\n\t\t\treturn true;\n\t} else  if (dm_state->underscan_enable && !old_dm_state->underscan_enable) {\n\t\tif (dm_state->underscan_hborder != 0 && dm_state->underscan_vborder != 0)\n\t\t\treturn true;\n\t} else if (dm_state->underscan_hborder != old_dm_state->underscan_hborder ||\n\t\t   dm_state->underscan_vborder != old_dm_state->underscan_vborder)\n\t\treturn true;\n\treturn false;\n}\n\nstatic bool is_content_protection_different(struct drm_crtc_state *new_crtc_state,\n\t\t\t\t\t    struct drm_crtc_state *old_crtc_state,\n\t\t\t\t\t    struct drm_connector_state *new_conn_state,\n\t\t\t\t\t    struct drm_connector_state *old_conn_state,\n\t\t\t\t\t    const struct drm_connector *connector,\n\t\t\t\t\t    struct hdcp_workqueue *hdcp_w)\n{\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct dm_connector_state *dm_con_state = to_dm_connector_state(connector->state);\n\n\tpr_debug(\"[HDCP_DM] connector->index: %x connect_status: %x dpms: %x\\n\",\n\t\tconnector->index, connector->status, connector->dpms);\n\tpr_debug(\"[HDCP_DM] state protection old: %x new: %x\\n\",\n\t\told_conn_state->content_protection, new_conn_state->content_protection);\n\n\tif (old_crtc_state)\n\t\tpr_debug(\"[HDCP_DM] old crtc en: %x a: %x m: %x a-chg: %x c-chg: %x\\n\",\n\t\told_crtc_state->enable,\n\t\told_crtc_state->active,\n\t\told_crtc_state->mode_changed,\n\t\told_crtc_state->active_changed,\n\t\told_crtc_state->connectors_changed);\n\n\tif (new_crtc_state)\n\t\tpr_debug(\"[HDCP_DM] NEW crtc en: %x a: %x m: %x a-chg: %x c-chg: %x\\n\",\n\t\tnew_crtc_state->enable,\n\t\tnew_crtc_state->active,\n\t\tnew_crtc_state->mode_changed,\n\t\tnew_crtc_state->active_changed,\n\t\tnew_crtc_state->connectors_changed);\n\n\t \n\tif (old_conn_state->hdcp_content_type != new_conn_state->hdcp_content_type &&\n\t    new_conn_state->content_protection != DRM_MODE_CONTENT_PROTECTION_UNDESIRED) {\n\t\tnew_conn_state->content_protection = DRM_MODE_CONTENT_PROTECTION_DESIRED;\n\t\tpr_debug(\"[HDCP_DM] Type0/1 change %s :true\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t \n\tif (old_conn_state->content_protection == DRM_MODE_CONTENT_PROTECTION_ENABLED &&\n\t    new_conn_state->content_protection == DRM_MODE_CONTENT_PROTECTION_DESIRED) {\n\t\tif (new_crtc_state && new_crtc_state->mode_changed) {\n\t\t\tnew_conn_state->content_protection = DRM_MODE_CONTENT_PROTECTION_DESIRED;\n\t\t\tpr_debug(\"[HDCP_DM] ENABLED->DESIRED & mode_changed %s :true\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t\tnew_conn_state->content_protection = DRM_MODE_CONTENT_PROTECTION_ENABLED;\n\t\tpr_debug(\"[HDCP_DM] ENABLED -> DESIRED %s :false\\n\", __func__);\n\t\treturn false;\n\t}\n\n\t \n\tif (old_conn_state->content_protection == DRM_MODE_CONTENT_PROTECTION_UNDESIRED &&\n\t    new_conn_state->content_protection == DRM_MODE_CONTENT_PROTECTION_ENABLED)\n\t\tnew_conn_state->content_protection = DRM_MODE_CONTENT_PROTECTION_DESIRED;\n\n\t \n\tif (!(old_conn_state->crtc && old_conn_state->crtc->enabled) &&\n\t\tnew_conn_state->crtc && new_conn_state->crtc->enabled &&\n\t\tconnector->state->content_protection == DRM_MODE_CONTENT_PROTECTION_DESIRED) {\n\t\tdm_con_state->update_hdcp = false;\n\t\tpr_debug(\"[HDCP_DM] DESIRED->DESIRED (Stream removed and re-enabled) %s :true\\n\",\n\t\t\t__func__);\n\t\treturn true;\n\t}\n\n\t \n\tif (dm_con_state->update_hdcp &&\n\tnew_conn_state->content_protection == DRM_MODE_CONTENT_PROTECTION_DESIRED &&\n\tconnector->dpms == DRM_MODE_DPMS_ON && aconnector->dc_sink != NULL) {\n\t\tdm_con_state->update_hdcp = false;\n\t\tpr_debug(\"[HDCP_DM] DESIRED->DESIRED (Hot-plug, headless s3, dpms) %s :true\\n\",\n\t\t\t__func__);\n\t\treturn true;\n\t}\n\n\tif (old_conn_state->content_protection == new_conn_state->content_protection) {\n\t\tif (new_conn_state->content_protection >= DRM_MODE_CONTENT_PROTECTION_DESIRED) {\n\t\t\tif (new_crtc_state && new_crtc_state->mode_changed) {\n\t\t\t\tpr_debug(\"[HDCP_DM] DESIRED->DESIRED or ENABLE->ENABLE mode_change %s :true\\n\",\n\t\t\t\t\t__func__);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tpr_debug(\"[HDCP_DM] DESIRED->DESIRED & ENABLE->ENABLE %s :false\\n\",\n\t\t\t\t__func__);\n\t\t\treturn false;\n\t\t}\n\n\t\tpr_debug(\"[HDCP_DM] UNDESIRED->UNDESIRED %s :false\\n\", __func__);\n\t\treturn false;\n\t}\n\n\tif (new_conn_state->content_protection != DRM_MODE_CONTENT_PROTECTION_ENABLED) {\n\t\tpr_debug(\"[HDCP_DM] UNDESIRED->DESIRED or DESIRED->UNDESIRED or ENABLED->UNDESIRED %s :true\\n\",\n\t\t\t__func__);\n\t\treturn true;\n\t}\n\n\tpr_debug(\"[HDCP_DM] DESIRED->ENABLED %s :false\\n\", __func__);\n\treturn false;\n}\n\nstatic void remove_stream(struct amdgpu_device *adev,\n\t\t\t  struct amdgpu_crtc *acrtc,\n\t\t\t  struct dc_stream_state *stream)\n{\n\t \n\n\tacrtc->otg_inst = -1;\n\tacrtc->enabled = false;\n}\n\nstatic void prepare_flip_isr(struct amdgpu_crtc *acrtc)\n{\n\n\tassert_spin_locked(&acrtc->base.dev->event_lock);\n\tWARN_ON(acrtc->event);\n\n\tacrtc->event = acrtc->base.state->event;\n\n\t \n\tacrtc->pflip_status = AMDGPU_FLIP_SUBMITTED;\n\n\t \n\tacrtc->base.state->event = NULL;\n\n\tDC_LOG_PFLIP(\"crtc:%d, pflip_stat:AMDGPU_FLIP_SUBMITTED\\n\",\n\t\t     acrtc->crtc_id);\n}\n\nstatic void update_freesync_state_on_stream(\n\tstruct amdgpu_display_manager *dm,\n\tstruct dm_crtc_state *new_crtc_state,\n\tstruct dc_stream_state *new_stream,\n\tstruct dc_plane_state *surface,\n\tu32 flip_timestamp_in_us)\n{\n\tstruct mod_vrr_params vrr_params;\n\tstruct dc_info_packet vrr_infopacket = {0};\n\tstruct amdgpu_device *adev = dm->adev;\n\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(new_crtc_state->base.crtc);\n\tunsigned long flags;\n\tbool pack_sdp_v1_3 = false;\n\tstruct amdgpu_dm_connector *aconn;\n\tenum vrr_packet_type packet_type = PACKET_TYPE_VRR;\n\n\tif (!new_stream)\n\t\treturn;\n\n\t \n\n\tif (!new_stream->timing.h_total || !new_stream->timing.v_total)\n\t\treturn;\n\n\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\tvrr_params = acrtc->dm_irq_params.vrr_params;\n\n\tif (surface) {\n\t\tmod_freesync_handle_preflip(\n\t\t\tdm->freesync_module,\n\t\t\tsurface,\n\t\t\tnew_stream,\n\t\t\tflip_timestamp_in_us,\n\t\t\t&vrr_params);\n\n\t\tif (adev->family < AMDGPU_FAMILY_AI &&\n\t\t    amdgpu_dm_crtc_vrr_active(new_crtc_state)) {\n\t\t\tmod_freesync_handle_v_update(dm->freesync_module,\n\t\t\t\t\t\t     new_stream, &vrr_params);\n\n\t\t\t \n\t\t\tdc_stream_adjust_vmin_vmax(dm->dc,\n\t\t\t\t\t\t   new_crtc_state->stream,\n\t\t\t\t\t\t   &vrr_params.adjust);\n\t\t}\n\t}\n\n\taconn = (struct amdgpu_dm_connector *)new_stream->dm_stream_context;\n\n\tif (aconn && (aconn->as_type == FREESYNC_TYPE_PCON_IN_WHITELIST || aconn->vsdb_info.replay_mode)) {\n\t\tpack_sdp_v1_3 = aconn->pack_sdp_v1_3;\n\n\t\tif (aconn->vsdb_info.amd_vsdb_version == 1)\n\t\t\tpacket_type = PACKET_TYPE_FS_V1;\n\t\telse if (aconn->vsdb_info.amd_vsdb_version == 2)\n\t\t\tpacket_type = PACKET_TYPE_FS_V2;\n\t\telse if (aconn->vsdb_info.amd_vsdb_version == 3)\n\t\t\tpacket_type = PACKET_TYPE_FS_V3;\n\n\t\tmod_build_adaptive_sync_infopacket(new_stream, aconn->as_type, NULL,\n\t\t\t\t\t&new_stream->adaptive_sync_infopacket);\n\t}\n\n\tmod_freesync_build_vrr_infopacket(\n\t\tdm->freesync_module,\n\t\tnew_stream,\n\t\t&vrr_params,\n\t\tpacket_type,\n\t\tTRANSFER_FUNC_UNKNOWN,\n\t\t&vrr_infopacket,\n\t\tpack_sdp_v1_3);\n\n\tnew_crtc_state->freesync_vrr_info_changed |=\n\t\t(memcmp(&new_crtc_state->vrr_infopacket,\n\t\t\t&vrr_infopacket,\n\t\t\tsizeof(vrr_infopacket)) != 0);\n\n\tacrtc->dm_irq_params.vrr_params = vrr_params;\n\tnew_crtc_state->vrr_infopacket = vrr_infopacket;\n\n\tnew_stream->vrr_infopacket = vrr_infopacket;\n\tnew_stream->allow_freesync = mod_freesync_get_freesync_enabled(&vrr_params);\n\n\tif (new_crtc_state->freesync_vrr_info_changed)\n\t\tDRM_DEBUG_KMS(\"VRR packet update: crtc=%u enabled=%d state=%d\",\n\t\t\t      new_crtc_state->base.crtc->base.id,\n\t\t\t      (int)new_crtc_state->base.vrr_enabled,\n\t\t\t      (int)vrr_params.state);\n\n\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n}\n\nstatic void update_stream_irq_parameters(\n\tstruct amdgpu_display_manager *dm,\n\tstruct dm_crtc_state *new_crtc_state)\n{\n\tstruct dc_stream_state *new_stream = new_crtc_state->stream;\n\tstruct mod_vrr_params vrr_params;\n\tstruct mod_freesync_config config = new_crtc_state->freesync_config;\n\tstruct amdgpu_device *adev = dm->adev;\n\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(new_crtc_state->base.crtc);\n\tunsigned long flags;\n\n\tif (!new_stream)\n\t\treturn;\n\n\t \n\tif (!new_stream->timing.h_total || !new_stream->timing.v_total)\n\t\treturn;\n\n\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\tvrr_params = acrtc->dm_irq_params.vrr_params;\n\n\tif (new_crtc_state->vrr_supported &&\n\t    config.min_refresh_in_uhz &&\n\t    config.max_refresh_in_uhz) {\n\t\t \n\t\tif (config.state == VRR_STATE_ACTIVE_FIXED && config.fixed_refresh_in_uhz &&\n\t\t    (!drm_atomic_crtc_needs_modeset(&new_crtc_state->base) ||\n\t\t     new_crtc_state->freesync_config.state == VRR_STATE_ACTIVE_FIXED)) {\n\t\t\tvrr_params.max_refresh_in_uhz = config.max_refresh_in_uhz;\n\t\t\tvrr_params.min_refresh_in_uhz = config.min_refresh_in_uhz;\n\t\t\tvrr_params.fixed_refresh_in_uhz = config.fixed_refresh_in_uhz;\n\t\t\tvrr_params.state = VRR_STATE_ACTIVE_FIXED;\n\t\t} else {\n\t\t\tconfig.state = new_crtc_state->base.vrr_enabled ?\n\t\t\t\t\t\t     VRR_STATE_ACTIVE_VARIABLE :\n\t\t\t\t\t\t     VRR_STATE_INACTIVE;\n\t\t}\n\t} else {\n\t\tconfig.state = VRR_STATE_UNSUPPORTED;\n\t}\n\n\tmod_freesync_build_vrr_params(dm->freesync_module,\n\t\t\t\t      new_stream,\n\t\t\t\t      &config, &vrr_params);\n\n\tnew_crtc_state->freesync_config = config;\n\t \n\tacrtc->dm_irq_params.freesync_config = config;\n\tacrtc->dm_irq_params.active_planes = new_crtc_state->active_planes;\n\tacrtc->dm_irq_params.vrr_params = vrr_params;\n\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n}\n\nstatic void amdgpu_dm_handle_vrr_transition(struct dm_crtc_state *old_state,\n\t\t\t\t\t    struct dm_crtc_state *new_state)\n{\n\tbool old_vrr_active = amdgpu_dm_crtc_vrr_active(old_state);\n\tbool new_vrr_active = amdgpu_dm_crtc_vrr_active(new_state);\n\n\tif (!old_vrr_active && new_vrr_active) {\n\t\t \n\t\tWARN_ON(amdgpu_dm_crtc_set_vupdate_irq(new_state->base.crtc, true) != 0);\n\t\tWARN_ON(drm_crtc_vblank_get(new_state->base.crtc) != 0);\n\t\tDRM_DEBUG_DRIVER(\"%s: crtc=%u VRR off->on: Get vblank ref\\n\",\n\t\t\t\t __func__, new_state->base.crtc->base.id);\n\t} else if (old_vrr_active && !new_vrr_active) {\n\t\t \n\t\tWARN_ON(amdgpu_dm_crtc_set_vupdate_irq(new_state->base.crtc, false) != 0);\n\t\tdrm_crtc_vblank_put(new_state->base.crtc);\n\t\tDRM_DEBUG_DRIVER(\"%s: crtc=%u VRR on->off: Drop vblank ref\\n\",\n\t\t\t\t __func__, new_state->base.crtc->base.id);\n\t}\n}\n\nstatic void amdgpu_dm_commit_cursors(struct drm_atomic_state *state)\n{\n\tstruct drm_plane *plane;\n\tstruct drm_plane_state *old_plane_state;\n\tint i;\n\n\t \n\tfor_each_old_plane_in_state(state, plane, old_plane_state, i)\n\t\tif (plane->type == DRM_PLANE_TYPE_CURSOR)\n\t\t\tamdgpu_dm_plane_handle_cursor_update(plane, old_plane_state);\n}\n\nstatic inline uint32_t get_mem_type(struct drm_framebuffer *fb)\n{\n\tstruct amdgpu_bo *abo = gem_to_amdgpu_bo(fb->obj[0]);\n\n\treturn abo->tbo.resource ? abo->tbo.resource->mem_type : 0;\n}\n\nstatic void amdgpu_dm_commit_planes(struct drm_atomic_state *state,\n\t\t\t\t    struct drm_device *dev,\n\t\t\t\t    struct amdgpu_display_manager *dm,\n\t\t\t\t    struct drm_crtc *pcrtc,\n\t\t\t\t    bool wait_for_vblank)\n{\n\tu32 i;\n\tu64 timestamp_ns = ktime_get_ns();\n\tstruct drm_plane *plane;\n\tstruct drm_plane_state *old_plane_state, *new_plane_state;\n\tstruct amdgpu_crtc *acrtc_attach = to_amdgpu_crtc(pcrtc);\n\tstruct drm_crtc_state *new_pcrtc_state =\n\t\t\tdrm_atomic_get_new_crtc_state(state, pcrtc);\n\tstruct dm_crtc_state *acrtc_state = to_dm_crtc_state(new_pcrtc_state);\n\tstruct dm_crtc_state *dm_old_crtc_state =\n\t\t\tto_dm_crtc_state(drm_atomic_get_old_crtc_state(state, pcrtc));\n\tint planes_count = 0, vpos, hpos;\n\tunsigned long flags;\n\tu32 target_vblank, last_flip_vblank;\n\tbool vrr_active = amdgpu_dm_crtc_vrr_active(acrtc_state);\n\tbool cursor_update = false;\n\tbool pflip_present = false;\n\tbool dirty_rects_changed = false;\n\tstruct {\n\t\tstruct dc_surface_update surface_updates[MAX_SURFACES];\n\t\tstruct dc_plane_info plane_infos[MAX_SURFACES];\n\t\tstruct dc_scaling_info scaling_infos[MAX_SURFACES];\n\t\tstruct dc_flip_addrs flip_addrs[MAX_SURFACES];\n\t\tstruct dc_stream_update stream_update;\n\t} *bundle;\n\n\tbundle = kzalloc(sizeof(*bundle), GFP_KERNEL);\n\n\tif (!bundle) {\n\t\tdm_error(\"Failed to allocate update bundle\\n\");\n\t\tgoto cleanup;\n\t}\n\n\t \n\tif (acrtc_state->active_planes == 0)\n\t\tamdgpu_dm_commit_cursors(state);\n\n\t \n\tfor_each_oldnew_plane_in_state(state, plane, old_plane_state, new_plane_state, i) {\n\t\tstruct drm_crtc *crtc = new_plane_state->crtc;\n\t\tstruct drm_crtc_state *new_crtc_state;\n\t\tstruct drm_framebuffer *fb = new_plane_state->fb;\n\t\tstruct amdgpu_framebuffer *afb = (struct amdgpu_framebuffer *)fb;\n\t\tbool plane_needs_flip;\n\t\tstruct dc_plane_state *dc_plane;\n\t\tstruct dm_plane_state *dm_new_plane_state = to_dm_plane_state(new_plane_state);\n\n\t\t \n\t\tif (plane->type == DRM_PLANE_TYPE_CURSOR) {\n\t\t\tif ((fb && crtc == pcrtc) ||\n\t\t\t    (old_plane_state->fb && old_plane_state->crtc == pcrtc))\n\t\t\t\tcursor_update = true;\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!fb || !crtc || pcrtc != crtc)\n\t\t\tcontinue;\n\n\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(state, crtc);\n\t\tif (!new_crtc_state->active)\n\t\t\tcontinue;\n\n\t\tdc_plane = dm_new_plane_state->dc_state;\n\t\tif (!dc_plane)\n\t\t\tcontinue;\n\n\t\tbundle->surface_updates[planes_count].surface = dc_plane;\n\t\tif (new_pcrtc_state->color_mgmt_changed) {\n\t\t\tbundle->surface_updates[planes_count].gamma = dc_plane->gamma_correction;\n\t\t\tbundle->surface_updates[planes_count].in_transfer_func = dc_plane->in_transfer_func;\n\t\t\tbundle->surface_updates[planes_count].gamut_remap_matrix = &dc_plane->gamut_remap_matrix;\n\t\t}\n\n\t\tamdgpu_dm_plane_fill_dc_scaling_info(dm->adev, new_plane_state,\n\t\t\t\t     &bundle->scaling_infos[planes_count]);\n\n\t\tbundle->surface_updates[planes_count].scaling_info =\n\t\t\t&bundle->scaling_infos[planes_count];\n\n\t\tplane_needs_flip = old_plane_state->fb && new_plane_state->fb;\n\n\t\tpflip_present = pflip_present || plane_needs_flip;\n\n\t\tif (!plane_needs_flip) {\n\t\t\tplanes_count += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tfill_dc_plane_info_and_addr(\n\t\t\tdm->adev, new_plane_state,\n\t\t\tafb->tiling_flags,\n\t\t\t&bundle->plane_infos[planes_count],\n\t\t\t&bundle->flip_addrs[planes_count].address,\n\t\t\tafb->tmz_surface, false);\n\n\t\tdrm_dbg_state(state->dev, \"plane: id=%d dcc_en=%d\\n\",\n\t\t\t\t new_plane_state->plane->index,\n\t\t\t\t bundle->plane_infos[planes_count].dcc.enable);\n\n\t\tbundle->surface_updates[planes_count].plane_info =\n\t\t\t&bundle->plane_infos[planes_count];\n\n\t\tif (acrtc_state->stream->link->psr_settings.psr_feature_enabled ||\n\t\t    acrtc_state->stream->link->replay_settings.replay_feature_enabled) {\n\t\t\tfill_dc_dirty_rects(plane, old_plane_state,\n\t\t\t\t\t    new_plane_state, new_crtc_state,\n\t\t\t\t\t    &bundle->flip_addrs[planes_count],\n\t\t\t\t\t    &dirty_rects_changed);\n\n\t\t\t \n\t\t\tif (acrtc_state->stream->link->psr_settings.psr_version >= DC_PSR_VERSION_SU_1 &&\n\t\t\t    acrtc_attach->dm_irq_params.allow_psr_entry &&\n#ifdef CONFIG_DRM_AMD_SECURE_DISPLAY\n\t\t\t    !amdgpu_dm_crc_window_is_activated(acrtc_state->base.crtc) &&\n#endif\n\t\t\t    dirty_rects_changed) {\n\t\t\t\tmutex_lock(&dm->dc_lock);\n\t\t\t\tacrtc_state->stream->link->psr_settings.psr_dirty_rects_change_timestamp_ns =\n\t\t\t\ttimestamp_ns;\n\t\t\t\tif (acrtc_state->stream->link->psr_settings.psr_allow_active)\n\t\t\t\t\tamdgpu_dm_psr_disable(acrtc_state->stream);\n\t\t\t\tmutex_unlock(&dm->dc_lock);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (crtc->state->async_flip &&\n\t\t    (acrtc_state->update_type != UPDATE_TYPE_FAST ||\n\t\t     get_mem_type(old_plane_state->fb) != get_mem_type(fb)))\n\t\t\tdrm_warn_once(state->dev,\n\t\t\t\t      \"[PLANE:%d:%s] async flip with non-fast update\\n\",\n\t\t\t\t      plane->base.id, plane->name);\n\n\t\tbundle->flip_addrs[planes_count].flip_immediate =\n\t\t\tcrtc->state->async_flip &&\n\t\t\tacrtc_state->update_type == UPDATE_TYPE_FAST &&\n\t\t\tget_mem_type(old_plane_state->fb) == get_mem_type(fb);\n\n\t\ttimestamp_ns = ktime_get_ns();\n\t\tbundle->flip_addrs[planes_count].flip_timestamp_in_us = div_u64(timestamp_ns, 1000);\n\t\tbundle->surface_updates[planes_count].flip_addr = &bundle->flip_addrs[planes_count];\n\t\tbundle->surface_updates[planes_count].surface = dc_plane;\n\n\t\tif (!bundle->surface_updates[planes_count].surface) {\n\t\t\tDRM_ERROR(\"No surface for CRTC: id=%d\\n\",\n\t\t\t\t\tacrtc_attach->crtc_id);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (plane == pcrtc->primary)\n\t\t\tupdate_freesync_state_on_stream(\n\t\t\t\tdm,\n\t\t\t\tacrtc_state,\n\t\t\t\tacrtc_state->stream,\n\t\t\t\tdc_plane,\n\t\t\t\tbundle->flip_addrs[planes_count].flip_timestamp_in_us);\n\n\t\tdrm_dbg_state(state->dev, \"%s Flipping to hi: 0x%x, low: 0x%x\\n\",\n\t\t\t\t __func__,\n\t\t\t\t bundle->flip_addrs[planes_count].address.grph.addr.high_part,\n\t\t\t\t bundle->flip_addrs[planes_count].address.grph.addr.low_part);\n\n\t\tplanes_count += 1;\n\n\t}\n\n\tif (pflip_present) {\n\t\tif (!vrr_active) {\n\t\t\t \n\t\t\tlast_flip_vblank = amdgpu_get_vblank_counter_kms(pcrtc);\n\t\t} else {\n\t\t\t \n\t\t\tspin_lock_irqsave(&pcrtc->dev->event_lock, flags);\n\t\t\tlast_flip_vblank = acrtc_attach->dm_irq_params.last_flip_vblank;\n\t\t\tspin_unlock_irqrestore(&pcrtc->dev->event_lock, flags);\n\t\t}\n\n\t\ttarget_vblank = last_flip_vblank + wait_for_vblank;\n\n\t\t \n\t\twhile ((acrtc_attach->enabled &&\n\t\t\t(amdgpu_display_get_crtc_scanoutpos(dm->ddev, acrtc_attach->crtc_id,\n\t\t\t\t\t\t\t    0, &vpos, &hpos, NULL,\n\t\t\t\t\t\t\t    NULL, &pcrtc->hwmode)\n\t\t\t & (DRM_SCANOUTPOS_VALID | DRM_SCANOUTPOS_IN_VBLANK)) ==\n\t\t\t(DRM_SCANOUTPOS_VALID | DRM_SCANOUTPOS_IN_VBLANK) &&\n\t\t\t(int)(target_vblank -\n\t\t\t  amdgpu_get_vblank_counter_kms(pcrtc)) > 0)) {\n\t\t\tusleep_range(1000, 1100);\n\t\t}\n\n\t\t \n\t\tif (acrtc_attach->base.state->event &&\n\t\t    acrtc_state->active_planes > 0) {\n\t\t\tdrm_crtc_vblank_get(pcrtc);\n\n\t\t\tspin_lock_irqsave(&pcrtc->dev->event_lock, flags);\n\n\t\t\tWARN_ON(acrtc_attach->pflip_status != AMDGPU_FLIP_NONE);\n\t\t\tprepare_flip_isr(acrtc_attach);\n\n\t\t\tspin_unlock_irqrestore(&pcrtc->dev->event_lock, flags);\n\t\t}\n\n\t\tif (acrtc_state->stream) {\n\t\t\tif (acrtc_state->freesync_vrr_info_changed)\n\t\t\t\tbundle->stream_update.vrr_infopacket =\n\t\t\t\t\t&acrtc_state->stream->vrr_infopacket;\n\t\t}\n\t} else if (cursor_update && acrtc_state->active_planes > 0 &&\n\t\t   acrtc_attach->base.state->event) {\n\t\tdrm_crtc_vblank_get(pcrtc);\n\n\t\tspin_lock_irqsave(&pcrtc->dev->event_lock, flags);\n\n\t\tacrtc_attach->event = acrtc_attach->base.state->event;\n\t\tacrtc_attach->base.state->event = NULL;\n\n\t\tspin_unlock_irqrestore(&pcrtc->dev->event_lock, flags);\n\t}\n\n\t \n\tif ((planes_count || acrtc_state->active_planes == 0) &&\n\t\tacrtc_state->stream) {\n\t\t \n\t\tif (dm->vblank_control_workqueue)\n\t\t\tflush_workqueue(dm->vblank_control_workqueue);\n\n\t\tbundle->stream_update.stream = acrtc_state->stream;\n\t\tif (new_pcrtc_state->mode_changed) {\n\t\t\tbundle->stream_update.src = acrtc_state->stream->src;\n\t\t\tbundle->stream_update.dst = acrtc_state->stream->dst;\n\t\t}\n\n\t\tif (new_pcrtc_state->color_mgmt_changed) {\n\t\t\t \n\t\t\tbundle->stream_update.gamut_remap =\n\t\t\t\t&acrtc_state->stream->gamut_remap_matrix;\n\t\t\tbundle->stream_update.output_csc_transform =\n\t\t\t\t&acrtc_state->stream->csc_color_matrix;\n\t\t\tbundle->stream_update.out_transfer_func =\n\t\t\t\tacrtc_state->stream->out_transfer_func;\n\t\t}\n\n\t\tacrtc_state->stream->abm_level = acrtc_state->abm_level;\n\t\tif (acrtc_state->abm_level != dm_old_crtc_state->abm_level)\n\t\t\tbundle->stream_update.abm_level = &acrtc_state->abm_level;\n\n\t\tmutex_lock(&dm->dc_lock);\n\t\tif ((acrtc_state->update_type > UPDATE_TYPE_FAST) &&\n\t\t\t\tacrtc_state->stream->link->psr_settings.psr_allow_active)\n\t\t\tamdgpu_dm_psr_disable(acrtc_state->stream);\n\t\tmutex_unlock(&dm->dc_lock);\n\n\t\t \n\t\tif (is_dc_timing_adjust_needed(dm_old_crtc_state, acrtc_state)) {\n\t\t\tspin_lock_irqsave(&pcrtc->dev->event_lock, flags);\n\t\t\tdc_stream_adjust_vmin_vmax(\n\t\t\t\tdm->dc, acrtc_state->stream,\n\t\t\t\t&acrtc_attach->dm_irq_params.vrr_params.adjust);\n\t\t\tspin_unlock_irqrestore(&pcrtc->dev->event_lock, flags);\n\t\t}\n\t\tmutex_lock(&dm->dc_lock);\n\t\tupdate_planes_and_stream_adapter(dm->dc,\n\t\t\t\t\t acrtc_state->update_type,\n\t\t\t\t\t planes_count,\n\t\t\t\t\t acrtc_state->stream,\n\t\t\t\t\t &bundle->stream_update,\n\t\t\t\t\t bundle->surface_updates);\n\n\t\t \n\t\tif (dm_old_crtc_state->active_planes != acrtc_state->active_planes)\n\t\t\tdm_update_pflip_irq_state(drm_to_adev(dev),\n\t\t\t\t\t\t  acrtc_attach);\n\n\t\tif ((acrtc_state->update_type > UPDATE_TYPE_FAST) &&\n\t\t\t\tacrtc_state->stream->link->psr_settings.psr_version != DC_PSR_VERSION_UNSUPPORTED &&\n\t\t\t\t!acrtc_state->stream->link->psr_settings.psr_feature_enabled)\n\t\t\tamdgpu_dm_link_setup_psr(acrtc_state->stream);\n\n\t\t \n\t\tif (acrtc_state->update_type == UPDATE_TYPE_FAST &&\n\t\t    acrtc_state->stream->link->psr_settings.psr_feature_enabled) {\n\t\t\tstruct amdgpu_dm_connector *aconn =\n\t\t\t\t(struct amdgpu_dm_connector *)acrtc_state->stream->dm_stream_context;\n\n\t\t\tif (aconn->psr_skip_count > 0)\n\t\t\t\taconn->psr_skip_count--;\n\n\t\t\t \n\t\t\tacrtc_attach->dm_irq_params.allow_psr_entry = !aconn->psr_skip_count;\n\n\t\t\t \n\t\t\tif (acrtc_state->stream->link->psr_settings.psr_version >= DC_PSR_VERSION_SU_1 &&\n\t\t\t    acrtc_attach->dm_irq_params.allow_psr_entry &&\n#ifdef CONFIG_DRM_AMD_SECURE_DISPLAY\n\t\t\t    !amdgpu_dm_crc_window_is_activated(acrtc_state->base.crtc) &&\n#endif\n\t\t\t    !acrtc_state->stream->link->psr_settings.psr_allow_active &&\n\t\t\t    (timestamp_ns -\n\t\t\t    acrtc_state->stream->link->psr_settings.psr_dirty_rects_change_timestamp_ns) >\n\t\t\t    500000000)\n\t\t\t\tamdgpu_dm_psr_enable(acrtc_state->stream);\n\t\t} else {\n\t\t\tacrtc_attach->dm_irq_params.allow_psr_entry = false;\n\t\t}\n\n\t\tmutex_unlock(&dm->dc_lock);\n\t}\n\n\t \n\tif (acrtc_state->active_planes)\n\t\tamdgpu_dm_commit_cursors(state);\n\ncleanup:\n\tkfree(bundle);\n}\n\nstatic void amdgpu_dm_commit_audio(struct drm_device *dev,\n\t\t\t\t   struct drm_atomic_state *state)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_state *old_con_state, *new_con_state;\n\tstruct drm_crtc_state *new_crtc_state;\n\tstruct dm_crtc_state *new_dm_crtc_state;\n\tconst struct dc_stream_status *status;\n\tint i, inst;\n\n\t \n\tfor_each_oldnew_connector_in_state(state, connector, old_con_state, new_con_state, i) {\n\t\tif (old_con_state->crtc != new_con_state->crtc) {\n\t\t\t \n\t\t\tgoto notify;\n\t\t}\n\n\t\tif (!new_con_state->crtc)\n\t\t\tcontinue;\n\n\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(\n\t\t\tstate, new_con_state->crtc);\n\n\t\tif (!new_crtc_state)\n\t\t\tcontinue;\n\n\t\tif (!drm_atomic_crtc_needs_modeset(new_crtc_state))\n\t\t\tcontinue;\n\nnotify:\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\n\t\tmutex_lock(&adev->dm.audio_lock);\n\t\tinst = aconnector->audio_inst;\n\t\taconnector->audio_inst = -1;\n\t\tmutex_unlock(&adev->dm.audio_lock);\n\n\t\tamdgpu_dm_audio_eld_notify(adev, inst);\n\t}\n\n\t \n\tfor_each_new_connector_in_state(state, connector, new_con_state, i) {\n\t\tif (!new_con_state->crtc)\n\t\t\tcontinue;\n\n\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(\n\t\t\tstate, new_con_state->crtc);\n\n\t\tif (!new_crtc_state)\n\t\t\tcontinue;\n\n\t\tif (!drm_atomic_crtc_needs_modeset(new_crtc_state))\n\t\t\tcontinue;\n\n\t\tnew_dm_crtc_state = to_dm_crtc_state(new_crtc_state);\n\t\tif (!new_dm_crtc_state->stream)\n\t\t\tcontinue;\n\n\t\tstatus = dc_stream_get_status(new_dm_crtc_state->stream);\n\t\tif (!status)\n\t\t\tcontinue;\n\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\n\t\tmutex_lock(&adev->dm.audio_lock);\n\t\tinst = status->audio_inst;\n\t\taconnector->audio_inst = inst;\n\t\tmutex_unlock(&adev->dm.audio_lock);\n\n\t\tamdgpu_dm_audio_eld_notify(adev, inst);\n\t}\n}\n\n \nstatic void amdgpu_dm_crtc_copy_transient_flags(struct drm_crtc_state *crtc_state,\n\t\t\t\t\t\tstruct dc_stream_state *stream_state)\n{\n\tstream_state->mode_changed = drm_atomic_crtc_needs_modeset(crtc_state);\n}\n\nstatic void amdgpu_dm_commit_streams(struct drm_atomic_state *state,\n\t\t\t\t\tstruct dc_state *dc_state)\n{\n\tstruct drm_device *dev = state->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\tstruct dm_crtc_state *dm_old_crtc_state, *dm_new_crtc_state;\n\tbool mode_set_reset_required = false;\n\tu32 i;\n\n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state,\n\t\t\t\t      new_crtc_state, i) {\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(crtc);\n\n\t\tdm_old_crtc_state = to_dm_crtc_state(old_crtc_state);\n\n\t\tif (old_crtc_state->active &&\n\t\t    (!new_crtc_state->active ||\n\t\t     drm_atomic_crtc_needs_modeset(new_crtc_state))) {\n\t\t\tmanage_dm_interrupts(adev, acrtc, false);\n\t\t\tdc_stream_release(dm_old_crtc_state->stream);\n\t\t}\n\t}\n\n\tdrm_atomic_helper_calc_timestamping_constants(state);\n\n\t \n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(crtc);\n\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\t\tdm_old_crtc_state = to_dm_crtc_state(old_crtc_state);\n\n\t\tdrm_dbg_state(state->dev,\n\t\t\t\"amdgpu_crtc id:%d crtc_state_flags: enable:%d, active:%d, planes_changed:%d, mode_changed:%d,active_changed:%d,connectors_changed:%d\\n\",\n\t\t\tacrtc->crtc_id,\n\t\t\tnew_crtc_state->enable,\n\t\t\tnew_crtc_state->active,\n\t\t\tnew_crtc_state->planes_changed,\n\t\t\tnew_crtc_state->mode_changed,\n\t\t\tnew_crtc_state->active_changed,\n\t\t\tnew_crtc_state->connectors_changed);\n\n\t\t \n\t\tif (old_crtc_state->active && !new_crtc_state->active) {\n\t\t\tstruct dc_cursor_position position;\n\n\t\t\tmemset(&position, 0, sizeof(position));\n\t\t\tmutex_lock(&dm->dc_lock);\n\t\t\tdc_stream_set_cursor_position(dm_old_crtc_state->stream, &position);\n\t\t\tmutex_unlock(&dm->dc_lock);\n\t\t}\n\n\t\t \n\t\tif (dm_new_crtc_state->stream) {\n\t\t\tamdgpu_dm_crtc_copy_transient_flags(&dm_new_crtc_state->base,\n\t\t\t\t\t\t\t    dm_new_crtc_state->stream);\n\t\t}\n\n\t\t \n\n\t\tif (amdgpu_dm_crtc_modeset_required(new_crtc_state, dm_new_crtc_state->stream, dm_old_crtc_state->stream)) {\n\n\t\t\tDRM_DEBUG_ATOMIC(\"Atomic commit: SET crtc id %d: [%p]\\n\", acrtc->crtc_id, acrtc);\n\n\t\t\tif (!dm_new_crtc_state->stream) {\n\t\t\t\t \n\t\t\t\tDRM_DEBUG_DRIVER(\"%s: Failed to create new stream for crtc %d\\n\",\n\t\t\t\t\t\t__func__, acrtc->base.base.id);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (dm_old_crtc_state->stream)\n\t\t\t\tremove_stream(adev, acrtc, dm_old_crtc_state->stream);\n\n\t\t\tpm_runtime_get_noresume(dev->dev);\n\n\t\t\tacrtc->enabled = true;\n\t\t\tacrtc->hw_mode = new_crtc_state->mode;\n\t\t\tcrtc->hwmode = new_crtc_state->mode;\n\t\t\tmode_set_reset_required = true;\n\t\t} else if (modereset_required(new_crtc_state)) {\n\t\t\tDRM_DEBUG_ATOMIC(\"Atomic commit: RESET. crtc id %d:[%p]\\n\", acrtc->crtc_id, acrtc);\n\t\t\t \n\t\t\tif (dm_old_crtc_state->stream)\n\t\t\t\tremove_stream(adev, acrtc, dm_old_crtc_state->stream);\n\n\t\t\tmode_set_reset_required = true;\n\t\t}\n\t}  \n\n\t \n\tif (mode_set_reset_required) {\n\t\tif (dm->vblank_control_workqueue)\n\t\t\tflush_workqueue(dm->vblank_control_workqueue);\n\n\t\tamdgpu_dm_psr_disable_all(dm);\n\t}\n\n\tdm_enable_per_frame_crtc_master_sync(dc_state);\n\tmutex_lock(&dm->dc_lock);\n\tWARN_ON(!dc_commit_streams(dm->dc, dc_state->streams, dc_state->stream_count));\n\n\t \n\tif (dm->active_vblank_irq_count == 0)\n\t\tdc_allow_idle_optimizations(dm->dc, true);\n\tmutex_unlock(&dm->dc_lock);\n\n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(crtc);\n\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\n\t\tif (dm_new_crtc_state->stream != NULL) {\n\t\t\tconst struct dc_stream_status *status =\n\t\t\t\t\tdc_stream_get_status(dm_new_crtc_state->stream);\n\n\t\t\tif (!status)\n\t\t\t\tstatus = dc_stream_get_status_from_state(dc_state,\n\t\t\t\t\t\t\t\t\t dm_new_crtc_state->stream);\n\t\t\tif (!status)\n\t\t\t\tDC_ERR(\"got no status for stream %p on acrtc%p\\n\", dm_new_crtc_state->stream, acrtc);\n\t\t\telse\n\t\t\t\tacrtc->otg_inst = status->primary_otg_inst;\n\t\t}\n\t}\n}\n\n \nstatic void amdgpu_dm_atomic_commit_tail(struct drm_atomic_state *state)\n{\n\tstruct drm_device *dev = state->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_display_manager *dm = &adev->dm;\n\tstruct dm_atomic_state *dm_state;\n\tstruct dc_state *dc_state = NULL;\n\tu32 i, j;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\tunsigned long flags;\n\tbool wait_for_vblank = true;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_state *old_con_state, *new_con_state;\n\tstruct dm_crtc_state *dm_old_crtc_state, *dm_new_crtc_state;\n\tint crtc_disable_count = 0;\n\n\ttrace_amdgpu_dm_atomic_commit_tail_begin(state);\n\n\tdrm_atomic_helper_update_legacy_modeset_state(dev, state);\n\tdrm_dp_mst_atomic_wait_for_dependencies(state);\n\n\tdm_state = dm_atomic_get_new_state(state);\n\tif (dm_state && dm_state->context) {\n\t\tdc_state = dm_state->context;\n\t\tamdgpu_dm_commit_streams(state, dc_state);\n\t}\n\n\tfor_each_oldnew_connector_in_state(state, connector, old_con_state, new_con_state, i) {\n\t\tstruct dm_connector_state *dm_new_con_state = to_dm_connector_state(new_con_state);\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(dm_new_con_state->base.crtc);\n\t\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\n\t\tif (!adev->dm.hdcp_workqueue)\n\t\t\tcontinue;\n\n\t\tpr_debug(\"[HDCP_DM] -------------- i : %x ----------\\n\", i);\n\n\t\tif (!connector)\n\t\t\tcontinue;\n\n\t\tpr_debug(\"[HDCP_DM] connector->index: %x connect_status: %x dpms: %x\\n\",\n\t\t\tconnector->index, connector->status, connector->dpms);\n\t\tpr_debug(\"[HDCP_DM] state protection old: %x new: %x\\n\",\n\t\t\told_con_state->content_protection, new_con_state->content_protection);\n\n\t\tif (aconnector->dc_sink) {\n\t\t\tif (aconnector->dc_sink->sink_signal != SIGNAL_TYPE_VIRTUAL &&\n\t\t\t\taconnector->dc_sink->sink_signal != SIGNAL_TYPE_NONE) {\n\t\t\t\tpr_debug(\"[HDCP_DM] pipe_ctx dispname=%s\\n\",\n\t\t\t\taconnector->dc_sink->edid_caps.display_name);\n\t\t\t}\n\t\t}\n\n\t\tnew_crtc_state = NULL;\n\t\told_crtc_state = NULL;\n\n\t\tif (acrtc) {\n\t\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(state, &acrtc->base);\n\t\t\told_crtc_state = drm_atomic_get_old_crtc_state(state, &acrtc->base);\n\t\t}\n\n\t\tif (old_crtc_state)\n\t\t\tpr_debug(\"old crtc en: %x a: %x m: %x a-chg: %x c-chg: %x\\n\",\n\t\t\told_crtc_state->enable,\n\t\t\told_crtc_state->active,\n\t\t\told_crtc_state->mode_changed,\n\t\t\told_crtc_state->active_changed,\n\t\t\told_crtc_state->connectors_changed);\n\n\t\tif (new_crtc_state)\n\t\t\tpr_debug(\"NEW crtc en: %x a: %x m: %x a-chg: %x c-chg: %x\\n\",\n\t\t\tnew_crtc_state->enable,\n\t\t\tnew_crtc_state->active,\n\t\t\tnew_crtc_state->mode_changed,\n\t\t\tnew_crtc_state->active_changed,\n\t\t\tnew_crtc_state->connectors_changed);\n\t}\n\n\tfor_each_oldnew_connector_in_state(state, connector, old_con_state, new_con_state, i) {\n\t\tstruct dm_connector_state *dm_new_con_state = to_dm_connector_state(new_con_state);\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(dm_new_con_state->base.crtc);\n\t\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\n\t\tif (!adev->dm.hdcp_workqueue)\n\t\t\tcontinue;\n\n\t\tnew_crtc_state = NULL;\n\t\told_crtc_state = NULL;\n\n\t\tif (acrtc) {\n\t\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(state, &acrtc->base);\n\t\t\told_crtc_state = drm_atomic_get_old_crtc_state(state, &acrtc->base);\n\t\t}\n\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\n\t\tif (dm_new_crtc_state && dm_new_crtc_state->stream == NULL &&\n\t\t    connector->state->content_protection == DRM_MODE_CONTENT_PROTECTION_ENABLED) {\n\t\t\thdcp_reset_display(adev->dm.hdcp_workqueue, aconnector->dc_link->link_index);\n\t\t\tnew_con_state->content_protection = DRM_MODE_CONTENT_PROTECTION_DESIRED;\n\t\t\tdm_new_con_state->update_hdcp = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (is_content_protection_different(new_crtc_state, old_crtc_state, new_con_state,\n\t\t\t\t\t\t\t\t\t\t\told_con_state, connector, adev->dm.hdcp_workqueue)) {\n\t\t\t \n\n\t\t\tbool enable_encryption = false;\n\n\t\t\tif (new_con_state->content_protection == DRM_MODE_CONTENT_PROTECTION_DESIRED)\n\t\t\t\tenable_encryption = true;\n\n\t\t\tif (aconnector->dc_link && aconnector->dc_sink &&\n\t\t\t\taconnector->dc_link->type == dc_connection_mst_branch) {\n\t\t\t\tstruct hdcp_workqueue *hdcp_work = adev->dm.hdcp_workqueue;\n\t\t\t\tstruct hdcp_workqueue *hdcp_w =\n\t\t\t\t\t&hdcp_work[aconnector->dc_link->link_index];\n\n\t\t\t\thdcp_w->hdcp_content_type[connector->index] =\n\t\t\t\t\tnew_con_state->hdcp_content_type;\n\t\t\t\thdcp_w->content_protection[connector->index] =\n\t\t\t\t\tnew_con_state->content_protection;\n\t\t\t}\n\n\t\t\tif (new_crtc_state && new_crtc_state->mode_changed &&\n\t\t\t\tnew_con_state->content_protection >= DRM_MODE_CONTENT_PROTECTION_DESIRED)\n\t\t\t\tenable_encryption = true;\n\n\t\t\tDRM_INFO(\"[HDCP_DM] hdcp_update_display enable_encryption = %x\\n\", enable_encryption);\n\n\t\t\thdcp_update_display(\n\t\t\t\tadev->dm.hdcp_workqueue, aconnector->dc_link->link_index, aconnector,\n\t\t\t\tnew_con_state->hdcp_content_type, enable_encryption);\n\t\t}\n\t}\n\n\t \n\tfor_each_oldnew_connector_in_state(state, connector, old_con_state, new_con_state, i) {\n\t\tstruct dm_connector_state *dm_new_con_state = to_dm_connector_state(new_con_state);\n\t\tstruct dm_connector_state *dm_old_con_state = to_dm_connector_state(old_con_state);\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(dm_new_con_state->base.crtc);\n\t\tstruct dc_surface_update *dummy_updates;\n\t\tstruct dc_stream_update stream_update;\n\t\tstruct dc_info_packet hdr_packet;\n\t\tstruct dc_stream_status *status = NULL;\n\t\tbool abm_changed, hdr_changed, scaling_changed;\n\n\t\tmemset(&stream_update, 0, sizeof(stream_update));\n\n\t\tif (acrtc) {\n\t\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(state, &acrtc->base);\n\t\t\told_crtc_state = drm_atomic_get_old_crtc_state(state, &acrtc->base);\n\t\t}\n\n\t\t \n\t\tif (!acrtc || drm_atomic_crtc_needs_modeset(new_crtc_state))\n\t\t\tcontinue;\n\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\t\tdm_old_crtc_state = to_dm_crtc_state(old_crtc_state);\n\n\t\tscaling_changed = is_scaling_state_different(dm_new_con_state,\n\t\t\t\t\t\t\t     dm_old_con_state);\n\n\t\tabm_changed = dm_new_crtc_state->abm_level !=\n\t\t\t      dm_old_crtc_state->abm_level;\n\n\t\thdr_changed =\n\t\t\t!drm_connector_atomic_hdr_metadata_equal(old_con_state, new_con_state);\n\n\t\tif (!scaling_changed && !abm_changed && !hdr_changed)\n\t\t\tcontinue;\n\n\t\tstream_update.stream = dm_new_crtc_state->stream;\n\t\tif (scaling_changed) {\n\t\t\tupdate_stream_scaling_settings(&dm_new_con_state->base.crtc->mode,\n\t\t\t\t\tdm_new_con_state, dm_new_crtc_state->stream);\n\n\t\t\tstream_update.src = dm_new_crtc_state->stream->src;\n\t\t\tstream_update.dst = dm_new_crtc_state->stream->dst;\n\t\t}\n\n\t\tif (abm_changed) {\n\t\t\tdm_new_crtc_state->stream->abm_level = dm_new_crtc_state->abm_level;\n\n\t\t\tstream_update.abm_level = &dm_new_crtc_state->abm_level;\n\t\t}\n\n\t\tif (hdr_changed) {\n\t\t\tfill_hdr_info_packet(new_con_state, &hdr_packet);\n\t\t\tstream_update.hdr_static_metadata = &hdr_packet;\n\t\t}\n\n\t\tstatus = dc_stream_get_status(dm_new_crtc_state->stream);\n\n\t\tif (WARN_ON(!status))\n\t\t\tcontinue;\n\n\t\tWARN_ON(!status->plane_count);\n\n\t\t \n\t\tdummy_updates = kzalloc(sizeof(struct dc_surface_update) * MAX_SURFACES, GFP_ATOMIC);\n\t\tfor (j = 0; j < status->plane_count; j++)\n\t\t\tdummy_updates[j].surface = status->plane_states[0];\n\n\n\t\tmutex_lock(&dm->dc_lock);\n\t\tdc_update_planes_and_stream(dm->dc,\n\t\t\t\t\t    dummy_updates,\n\t\t\t\t\t    status->plane_count,\n\t\t\t\t\t    dm_new_crtc_state->stream,\n\t\t\t\t\t    &stream_update);\n\t\tmutex_unlock(&dm->dc_lock);\n\t\tkfree(dummy_updates);\n\t}\n\n\t \n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(crtc);\n#ifdef CONFIG_DEBUG_FS\n\t\tenum amdgpu_dm_pipe_crc_source cur_crc_src;\n#endif\n\t\t \n\t\tif (old_crtc_state->active && !new_crtc_state->active)\n\t\t\tcrtc_disable_count++;\n\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\t\tdm_old_crtc_state = to_dm_crtc_state(old_crtc_state);\n\n\t\t \n\t\tupdate_stream_irq_parameters(dm, dm_new_crtc_state);\n\n#ifdef CONFIG_DEBUG_FS\n\t\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\t\tcur_crc_src = acrtc->dm_irq_params.crc_src;\n\t\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n#endif\n\n\t\tif (new_crtc_state->active &&\n\t\t    (!old_crtc_state->active ||\n\t\t     drm_atomic_crtc_needs_modeset(new_crtc_state))) {\n\t\t\tdc_stream_retain(dm_new_crtc_state->stream);\n\t\t\tacrtc->dm_irq_params.stream = dm_new_crtc_state->stream;\n\t\t\tmanage_dm_interrupts(adev, acrtc, true);\n\t\t}\n\t\t \n\t\tamdgpu_dm_handle_vrr_transition(dm_old_crtc_state, dm_new_crtc_state);\n\n#ifdef CONFIG_DEBUG_FS\n\t\tif (new_crtc_state->active &&\n\t\t    (!old_crtc_state->active ||\n\t\t     drm_atomic_crtc_needs_modeset(new_crtc_state))) {\n\t\t\t \n\t\t\tif (amdgpu_dm_is_valid_crc_source(cur_crc_src)) {\n#if defined(CONFIG_DRM_AMD_SECURE_DISPLAY)\n\t\t\t\tif (amdgpu_dm_crc_window_is_activated(crtc)) {\n\t\t\t\t\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\t\t\t\t\tacrtc->dm_irq_params.window_param.update_win = true;\n\n\t\t\t\t\t \n\t\t\t\t\tacrtc->dm_irq_params.window_param.skip_frame_cnt = 2;\n\t\t\t\t\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n\t\t\t\t}\n#endif\n\t\t\t\tif (amdgpu_dm_crtc_configure_crc_source(\n\t\t\t\t\tcrtc, dm_new_crtc_state, cur_crc_src))\n\t\t\t\t\tDRM_DEBUG_DRIVER(\"Failed to configure crc source\");\n\t\t\t}\n\t\t}\n#endif\n\t}\n\n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, j)\n\t\tif (new_crtc_state->async_flip)\n\t\t\twait_for_vblank = false;\n\n\t \n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, j) {\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\n\t\tif (dm_new_crtc_state->stream)\n\t\t\tamdgpu_dm_commit_planes(state, dev, dm, crtc, wait_for_vblank);\n\t}\n\n\t \n\tamdgpu_dm_commit_audio(dev, state);\n\n\t \n\tfor (i = 0; i < dm->num_of_edps; i++) {\n\t\tif (dm->backlight_dev[i] &&\n\t\t    (dm->actual_brightness[i] != dm->brightness[i]))\n\t\t\tamdgpu_dm_backlight_set_level(dm, i, dm->brightness[i]);\n\t}\n\n\t \n\tspin_lock_irqsave(&adev_to_drm(adev)->event_lock, flags);\n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, i) {\n\n\t\tif (new_crtc_state->event)\n\t\t\tdrm_send_event_locked(dev, &new_crtc_state->event->base);\n\n\t\tnew_crtc_state->event = NULL;\n\t}\n\tspin_unlock_irqrestore(&adev_to_drm(adev)->event_lock, flags);\n\n\t \n\tdrm_atomic_helper_commit_hw_done(state);\n\n\tif (wait_for_vblank)\n\t\tdrm_atomic_helper_wait_for_flip_done(dev, state);\n\n\tdrm_atomic_helper_cleanup_planes(dev, state);\n\n\t \n\tif (!adev->in_suspend) {\n\t\t \n\t\tif (!adev->mman.keep_stolen_vga_memory)\n\t\t\tamdgpu_bo_free_kernel(&adev->mman.stolen_vga_memory, NULL, NULL);\n\t\tamdgpu_bo_free_kernel(&adev->mman.stolen_extended_memory, NULL, NULL);\n\t}\n\n\t \n\tfor (i = 0; i < crtc_disable_count; i++)\n\t\tpm_runtime_put_autosuspend(dev->dev);\n\tpm_runtime_mark_last_busy(dev->dev);\n}\n\nstatic int dm_force_atomic_commit(struct drm_connector *connector)\n{\n\tint ret = 0;\n\tstruct drm_device *ddev = connector->dev;\n\tstruct drm_atomic_state *state = drm_atomic_state_alloc(ddev);\n\tstruct amdgpu_crtc *disconnected_acrtc = to_amdgpu_crtc(connector->encoder->crtc);\n\tstruct drm_plane *plane = disconnected_acrtc->base.primary;\n\tstruct drm_connector_state *conn_state;\n\tstruct drm_crtc_state *crtc_state;\n\tstruct drm_plane_state *plane_state;\n\n\tif (!state)\n\t\treturn -ENOMEM;\n\n\tstate->acquire_ctx = ddev->mode_config.acquire_ctx;\n\n\t \n\n\t \n\tconn_state = drm_atomic_get_connector_state(state, connector);\n\n\tret = PTR_ERR_OR_ZERO(conn_state);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tcrtc_state = drm_atomic_get_crtc_state(state, &disconnected_acrtc->base);\n\n\tret = PTR_ERR_OR_ZERO(crtc_state);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tcrtc_state->mode_changed = true;\n\n\t \n\tplane_state = drm_atomic_get_plane_state(state, plane);\n\n\tret = PTR_ERR_OR_ZERO(plane_state);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tret = drm_atomic_commit(state);\n\nout:\n\tdrm_atomic_state_put(state);\n\tif (ret)\n\t\tDRM_ERROR(\"Restoring old state failed with %i\\n\", ret);\n\n\treturn ret;\n}\n\n \nvoid dm_restore_drm_connector_state(struct drm_device *dev,\n\t\t\t\t    struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct amdgpu_crtc *disconnected_acrtc;\n\tstruct dm_crtc_state *acrtc_state;\n\n\tif (!aconnector->dc_sink || !connector->state || !connector->encoder)\n\t\treturn;\n\n\tdisconnected_acrtc = to_amdgpu_crtc(connector->encoder->crtc);\n\tif (!disconnected_acrtc)\n\t\treturn;\n\n\tacrtc_state = to_dm_crtc_state(disconnected_acrtc->base.state);\n\tif (!acrtc_state->stream)\n\t\treturn;\n\n\t \n\tif (acrtc_state->stream->sink != aconnector->dc_sink)\n\t\tdm_force_atomic_commit(&aconnector->base);\n}\n\n \nstatic int do_aquire_global_lock(struct drm_device *dev,\n\t\t\t\t struct drm_atomic_state *state)\n{\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_commit *commit;\n\tlong ret;\n\n\t \n\tret = drm_modeset_lock_all_ctx(dev, state->acquire_ctx);\n\tif (ret)\n\t\treturn ret;\n\n\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\tspin_lock(&crtc->commit_lock);\n\t\tcommit = list_first_entry_or_null(&crtc->commit_list,\n\t\t\t\tstruct drm_crtc_commit, commit_entry);\n\t\tif (commit)\n\t\t\tdrm_crtc_commit_get(commit);\n\t\tspin_unlock(&crtc->commit_lock);\n\n\t\tif (!commit)\n\t\t\tcontinue;\n\n\t\t \n\t\tret = wait_for_completion_interruptible_timeout(&commit->hw_done, 10*HZ);\n\n\t\tif (ret > 0)\n\t\t\tret = wait_for_completion_interruptible_timeout(\n\t\t\t\t\t&commit->flip_done, 10*HZ);\n\n\t\tif (ret == 0)\n\t\t\tDRM_ERROR(\"[CRTC:%d:%s] hw_done or flip_done timed out\\n\",\n\t\t\t\t  crtc->base.id, crtc->name);\n\n\t\tdrm_crtc_commit_put(commit);\n\t}\n\n\treturn ret < 0 ? ret : 0;\n}\n\nstatic void get_freesync_config_for_crtc(\n\tstruct dm_crtc_state *new_crtc_state,\n\tstruct dm_connector_state *new_con_state)\n{\n\tstruct mod_freesync_config config = {0};\n\tstruct amdgpu_dm_connector *aconnector =\n\t\t\tto_amdgpu_dm_connector(new_con_state->base.connector);\n\tstruct drm_display_mode *mode = &new_crtc_state->base.mode;\n\tint vrefresh = drm_mode_vrefresh(mode);\n\tbool fs_vid_mode = false;\n\n\tnew_crtc_state->vrr_supported = new_con_state->freesync_capable &&\n\t\t\t\t\tvrefresh >= aconnector->min_vfreq &&\n\t\t\t\t\tvrefresh <= aconnector->max_vfreq;\n\n\tif (new_crtc_state->vrr_supported) {\n\t\tnew_crtc_state->stream->ignore_msa_timing_param = true;\n\t\tfs_vid_mode = new_crtc_state->freesync_config.state == VRR_STATE_ACTIVE_FIXED;\n\n\t\tconfig.min_refresh_in_uhz = aconnector->min_vfreq * 1000000;\n\t\tconfig.max_refresh_in_uhz = aconnector->max_vfreq * 1000000;\n\t\tconfig.vsif_supported = true;\n\t\tconfig.btr = true;\n\n\t\tif (fs_vid_mode) {\n\t\t\tconfig.state = VRR_STATE_ACTIVE_FIXED;\n\t\t\tconfig.fixed_refresh_in_uhz = new_crtc_state->freesync_config.fixed_refresh_in_uhz;\n\t\t\tgoto out;\n\t\t} else if (new_crtc_state->base.vrr_enabled) {\n\t\t\tconfig.state = VRR_STATE_ACTIVE_VARIABLE;\n\t\t} else {\n\t\t\tconfig.state = VRR_STATE_INACTIVE;\n\t\t}\n\t}\nout:\n\tnew_crtc_state->freesync_config = config;\n}\n\nstatic void reset_freesync_config_for_crtc(\n\tstruct dm_crtc_state *new_crtc_state)\n{\n\tnew_crtc_state->vrr_supported = false;\n\n\tmemset(&new_crtc_state->vrr_infopacket, 0,\n\t       sizeof(new_crtc_state->vrr_infopacket));\n}\n\nstatic bool\nis_timing_unchanged_for_freesync(struct drm_crtc_state *old_crtc_state,\n\t\t\t\t struct drm_crtc_state *new_crtc_state)\n{\n\tconst struct drm_display_mode *old_mode, *new_mode;\n\n\tif (!old_crtc_state || !new_crtc_state)\n\t\treturn false;\n\n\told_mode = &old_crtc_state->mode;\n\tnew_mode = &new_crtc_state->mode;\n\n\tif (old_mode->clock       == new_mode->clock &&\n\t    old_mode->hdisplay    == new_mode->hdisplay &&\n\t    old_mode->vdisplay    == new_mode->vdisplay &&\n\t    old_mode->htotal      == new_mode->htotal &&\n\t    old_mode->vtotal      != new_mode->vtotal &&\n\t    old_mode->hsync_start == new_mode->hsync_start &&\n\t    old_mode->vsync_start != new_mode->vsync_start &&\n\t    old_mode->hsync_end   == new_mode->hsync_end &&\n\t    old_mode->vsync_end   != new_mode->vsync_end &&\n\t    old_mode->hskew       == new_mode->hskew &&\n\t    old_mode->vscan       == new_mode->vscan &&\n\t    (old_mode->vsync_end - old_mode->vsync_start) ==\n\t    (new_mode->vsync_end - new_mode->vsync_start))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void set_freesync_fixed_config(struct dm_crtc_state *dm_new_crtc_state)\n{\n\tu64 num, den, res;\n\tstruct drm_crtc_state *new_crtc_state = &dm_new_crtc_state->base;\n\n\tdm_new_crtc_state->freesync_config.state = VRR_STATE_ACTIVE_FIXED;\n\n\tnum = (unsigned long long)new_crtc_state->mode.clock * 1000 * 1000000;\n\tden = (unsigned long long)new_crtc_state->mode.htotal *\n\t      (unsigned long long)new_crtc_state->mode.vtotal;\n\n\tres = div_u64(num, den);\n\tdm_new_crtc_state->freesync_config.fixed_refresh_in_uhz = res;\n}\n\nstatic int dm_update_crtc_state(struct amdgpu_display_manager *dm,\n\t\t\t struct drm_atomic_state *state,\n\t\t\t struct drm_crtc *crtc,\n\t\t\t struct drm_crtc_state *old_crtc_state,\n\t\t\t struct drm_crtc_state *new_crtc_state,\n\t\t\t bool enable,\n\t\t\t bool *lock_and_validation_needed)\n{\n\tstruct dm_atomic_state *dm_state = NULL;\n\tstruct dm_crtc_state *dm_old_crtc_state, *dm_new_crtc_state;\n\tstruct dc_stream_state *new_stream;\n\tint ret = 0;\n\n\t \n\tstruct amdgpu_crtc *acrtc = NULL;\n\tstruct amdgpu_dm_connector *aconnector = NULL;\n\tstruct drm_connector_state *drm_new_conn_state = NULL, *drm_old_conn_state = NULL;\n\tstruct dm_connector_state *dm_new_conn_state = NULL, *dm_old_conn_state = NULL;\n\n\tnew_stream = NULL;\n\n\tdm_old_crtc_state = to_dm_crtc_state(old_crtc_state);\n\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\tacrtc = to_amdgpu_crtc(crtc);\n\taconnector = amdgpu_dm_find_first_crtc_matching_connector(state, crtc);\n\n\t \n\tif (aconnector && enable) {\n\t\t \n\t\tdrm_new_conn_state = drm_atomic_get_new_connector_state(state,\n\t\t\t\t\t\t\t    &aconnector->base);\n\t\tdrm_old_conn_state = drm_atomic_get_old_connector_state(state,\n\t\t\t\t\t\t\t    &aconnector->base);\n\n\t\tif (IS_ERR(drm_new_conn_state)) {\n\t\t\tret = PTR_ERR_OR_ZERO(drm_new_conn_state);\n\t\t\tgoto fail;\n\t\t}\n\n\t\tdm_new_conn_state = to_dm_connector_state(drm_new_conn_state);\n\t\tdm_old_conn_state = to_dm_connector_state(drm_old_conn_state);\n\n\t\tif (!drm_atomic_crtc_needs_modeset(new_crtc_state))\n\t\t\tgoto skip_modeset;\n\n\t\tnew_stream = create_validate_stream_for_sink(aconnector,\n\t\t\t\t\t\t\t     &new_crtc_state->mode,\n\t\t\t\t\t\t\t     dm_new_conn_state,\n\t\t\t\t\t\t\t     dm_old_crtc_state->stream);\n\n\t\t \n\n\t\tif (!new_stream) {\n\t\t\tDRM_DEBUG_DRIVER(\"%s: Failed to create new stream for crtc %d\\n\",\n\t\t\t\t\t__func__, acrtc->base.base.id);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\t \n\t\tnew_stream->triggered_crtc_reset.enabled =\n\t\t\tdm->force_timing_sync;\n\n\t\tdm_new_crtc_state->abm_level = dm_new_conn_state->abm_level;\n\n\t\tret = fill_hdr_info_packet(drm_new_conn_state,\n\t\t\t\t\t   &new_stream->hdr_static_metadata);\n\t\tif (ret)\n\t\t\tgoto fail;\n\n\t\t \n\t\tif (dm_new_crtc_state->stream &&\n\t\t    is_timing_unchanged_for_freesync(new_crtc_state, old_crtc_state))\n\t\t\tgoto skip_modeset;\n\n\t\tif (dm_new_crtc_state->stream &&\n\t\t    dc_is_stream_unchanged(new_stream, dm_old_crtc_state->stream) &&\n\t\t    dc_is_stream_scaling_unchanged(new_stream, dm_old_crtc_state->stream)) {\n\t\t\tnew_crtc_state->mode_changed = false;\n\t\t\tDRM_DEBUG_DRIVER(\"Mode change not required, setting mode_changed to %d\",\n\t\t\t\t\t new_crtc_state->mode_changed);\n\t\t}\n\t}\n\n\t \n\tif (!drm_atomic_crtc_needs_modeset(new_crtc_state))\n\t\tgoto skip_modeset;\n\n\tdrm_dbg_state(state->dev,\n\t\t\"amdgpu_crtc id:%d crtc_state_flags: enable:%d, active:%d, planes_changed:%d, mode_changed:%d,active_changed:%d,connectors_changed:%d\\n\",\n\t\tacrtc->crtc_id,\n\t\tnew_crtc_state->enable,\n\t\tnew_crtc_state->active,\n\t\tnew_crtc_state->planes_changed,\n\t\tnew_crtc_state->mode_changed,\n\t\tnew_crtc_state->active_changed,\n\t\tnew_crtc_state->connectors_changed);\n\n\t \n\tif (!enable) {\n\n\t\tif (!dm_old_crtc_state->stream)\n\t\t\tgoto skip_modeset;\n\n\t\t \n\t\tif (dm_old_crtc_state->freesync_config.state == VRR_STATE_ACTIVE_FIXED) {\n\t\t\tdm_new_crtc_state->freesync_config.state = VRR_STATE_INACTIVE;\n\t\t\tdm_new_crtc_state->freesync_config.fixed_refresh_in_uhz = 0;\n\t\t}\n\n\t\t \n\t\tif (dm_new_crtc_state->stream &&\n\t\t    dc_is_stream_unchanged(new_stream, dm_old_crtc_state->stream) &&\n\t\t    dc_is_stream_scaling_unchanged(new_stream, dm_old_crtc_state->stream) &&\n\t\t    is_timing_unchanged_for_freesync(new_crtc_state,\n\t\t\t\t\t\t     old_crtc_state)) {\n\t\t\tnew_crtc_state->mode_changed = false;\n\t\t\tDRM_DEBUG_DRIVER(\n\t\t\t\t\"Mode change not required for front porch change, setting mode_changed to %d\",\n\t\t\t\tnew_crtc_state->mode_changed);\n\n\t\t\tset_freesync_fixed_config(dm_new_crtc_state);\n\n\t\t\tgoto skip_modeset;\n\t\t} else if (aconnector &&\n\t\t\t   is_freesync_video_mode(&new_crtc_state->mode,\n\t\t\t\t\t\t  aconnector)) {\n\t\t\tstruct drm_display_mode *high_mode;\n\n\t\t\thigh_mode = get_highest_refresh_rate_mode(aconnector, false);\n\t\t\tif (!drm_mode_equal(&new_crtc_state->mode, high_mode))\n\t\t\t\tset_freesync_fixed_config(dm_new_crtc_state);\n\t\t}\n\n\t\tret = dm_atomic_get_state(state, &dm_state);\n\t\tif (ret)\n\t\t\tgoto fail;\n\n\t\tDRM_DEBUG_DRIVER(\"Disabling DRM crtc: %d\\n\",\n\t\t\t\tcrtc->base.id);\n\n\t\t \n\t\tif (dc_remove_stream_from_ctx(\n\t\t\t\tdm->dc,\n\t\t\t\tdm_state->context,\n\t\t\t\tdm_old_crtc_state->stream) != DC_OK) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tdc_stream_release(dm_old_crtc_state->stream);\n\t\tdm_new_crtc_state->stream = NULL;\n\n\t\treset_freesync_config_for_crtc(dm_new_crtc_state);\n\n\t\t*lock_and_validation_needed = true;\n\n\t} else { \n\t\t \n\t\tif (!aconnector)\n\t\t\tgoto skip_modeset;\n\n\t\tif (modereset_required(new_crtc_state))\n\t\t\tgoto skip_modeset;\n\n\t\tif (amdgpu_dm_crtc_modeset_required(new_crtc_state, new_stream,\n\t\t\t\t     dm_old_crtc_state->stream)) {\n\n\t\t\tWARN_ON(dm_new_crtc_state->stream);\n\n\t\t\tret = dm_atomic_get_state(state, &dm_state);\n\t\t\tif (ret)\n\t\t\t\tgoto fail;\n\n\t\t\tdm_new_crtc_state->stream = new_stream;\n\n\t\t\tdc_stream_retain(new_stream);\n\n\t\t\tDRM_DEBUG_ATOMIC(\"Enabling DRM crtc: %d\\n\",\n\t\t\t\t\t crtc->base.id);\n\n\t\t\tif (dc_add_stream_to_ctx(\n\t\t\t\t\tdm->dc,\n\t\t\t\t\tdm_state->context,\n\t\t\t\t\tdm_new_crtc_state->stream) != DC_OK) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto fail;\n\t\t\t}\n\n\t\t\t*lock_and_validation_needed = true;\n\t\t}\n\t}\n\nskip_modeset:\n\t \n\tif (new_stream)\n\t\tdc_stream_release(new_stream);\n\n\t \n\tif (!(enable && aconnector && new_crtc_state->active))\n\t\treturn 0;\n\t \n\tBUG_ON(dm_new_crtc_state->stream == NULL);\n\n\t \n\tif (is_scaling_state_different(dm_old_conn_state, dm_new_conn_state) ||\n\t\t\t\tdrm_atomic_crtc_needs_modeset(new_crtc_state))\n\t\tupdate_stream_scaling_settings(\n\t\t\t&new_crtc_state->mode, dm_new_conn_state, dm_new_crtc_state->stream);\n\n\t \n\tdm_new_crtc_state->abm_level = dm_new_conn_state->abm_level;\n\n\t \n\tif (dm_new_crtc_state->base.color_mgmt_changed ||\n\t    drm_atomic_crtc_needs_modeset(new_crtc_state)) {\n\t\tret = amdgpu_dm_update_crtc_color_mgmt(dm_new_crtc_state);\n\t\tif (ret)\n\t\t\tgoto fail;\n\t}\n\n\t \n\tget_freesync_config_for_crtc(dm_new_crtc_state,\n\t\t\t\t     dm_new_conn_state);\n\n\treturn ret;\n\nfail:\n\tif (new_stream)\n\t\tdc_stream_release(new_stream);\n\treturn ret;\n}\n\nstatic bool should_reset_plane(struct drm_atomic_state *state,\n\t\t\t       struct drm_plane *plane,\n\t\t\t       struct drm_plane_state *old_plane_state,\n\t\t\t       struct drm_plane_state *new_plane_state)\n{\n\tstruct drm_plane *other;\n\tstruct drm_plane_state *old_other_state, *new_other_state;\n\tstruct drm_crtc_state *new_crtc_state;\n\tstruct amdgpu_device *adev = drm_to_adev(plane->dev);\n\tint i;\n\n\t \n\tif (adev->ip_versions[DCE_HWIP][0] < IP_VERSION(3, 2, 0) && state->allow_modeset)\n\t\treturn true;\n\n\t \n\tif (old_plane_state->crtc != new_plane_state->crtc)\n\t\treturn true;\n\n\t \n\tif (!new_plane_state->crtc)\n\t\treturn false;\n\n\tnew_crtc_state =\n\t\tdrm_atomic_get_new_crtc_state(state, new_plane_state->crtc);\n\n\tif (!new_crtc_state)\n\t\treturn true;\n\n\t \n\tif (new_crtc_state->color_mgmt_changed)\n\t\treturn true;\n\n\tif (drm_atomic_crtc_needs_modeset(new_crtc_state))\n\t\treturn true;\n\n\t \n\tfor_each_oldnew_plane_in_state(state, other, old_other_state, new_other_state, i) {\n\t\tstruct amdgpu_framebuffer *old_afb, *new_afb;\n\n\t\tif (other->type == DRM_PLANE_TYPE_CURSOR)\n\t\t\tcontinue;\n\n\t\tif (old_other_state->crtc != new_plane_state->crtc &&\n\t\t    new_other_state->crtc != new_plane_state->crtc)\n\t\t\tcontinue;\n\n\t\tif (old_other_state->crtc != new_other_state->crtc)\n\t\t\treturn true;\n\n\t\t \n\t\tif (old_other_state->src_w != new_other_state->src_w ||\n\t\t    old_other_state->src_h != new_other_state->src_h ||\n\t\t    old_other_state->crtc_w != new_other_state->crtc_w ||\n\t\t    old_other_state->crtc_h != new_other_state->crtc_h)\n\t\t\treturn true;\n\n\t\t \n\t\tif (old_other_state->rotation != new_other_state->rotation)\n\t\t\treturn true;\n\n\t\t \n\t\tif (old_other_state->pixel_blend_mode !=\n\t\t    new_other_state->pixel_blend_mode)\n\t\t\treturn true;\n\n\t\t \n\t\tif (old_other_state->alpha != new_other_state->alpha)\n\t\t\treturn true;\n\n\t\t \n\t\tif (old_other_state->color_range != new_other_state->color_range ||\n\t\t    old_other_state->color_encoding != new_other_state->color_encoding)\n\t\t\treturn true;\n\n\t\t \n\t\tif (!old_other_state->fb || !new_other_state->fb)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (old_other_state->fb->format != new_other_state->fb->format)\n\t\t\treturn true;\n\n\t\told_afb = (struct amdgpu_framebuffer *)old_other_state->fb;\n\t\tnew_afb = (struct amdgpu_framebuffer *)new_other_state->fb;\n\n\t\t \n\t\tif (old_afb->tiling_flags != new_afb->tiling_flags ||\n\t\t    old_afb->base.modifier != new_afb->base.modifier)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic int dm_check_cursor_fb(struct amdgpu_crtc *new_acrtc,\n\t\t\t      struct drm_plane_state *new_plane_state,\n\t\t\t      struct drm_framebuffer *fb)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(new_acrtc->base.dev);\n\tstruct amdgpu_framebuffer *afb = to_amdgpu_framebuffer(fb);\n\tunsigned int pitch;\n\tbool linear;\n\n\tif (fb->width > new_acrtc->max_cursor_width ||\n\t    fb->height > new_acrtc->max_cursor_height) {\n\t\tDRM_DEBUG_ATOMIC(\"Bad cursor FB size %dx%d\\n\",\n\t\t\t\t new_plane_state->fb->width,\n\t\t\t\t new_plane_state->fb->height);\n\t\treturn -EINVAL;\n\t}\n\tif (new_plane_state->src_w != fb->width << 16 ||\n\t    new_plane_state->src_h != fb->height << 16) {\n\t\tDRM_DEBUG_ATOMIC(\"Cropping not supported for cursor plane\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tpitch = fb->pitches[0] / fb->format->cpp[0];\n\n\tif (fb->width != pitch) {\n\t\tDRM_DEBUG_ATOMIC(\"Cursor FB width %d doesn't match pitch %d\",\n\t\t\t\t fb->width, pitch);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (pitch) {\n\tcase 64:\n\tcase 128:\n\tcase 256:\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tDRM_DEBUG_ATOMIC(\"Bad cursor FB pitch %d px\\n\", pitch);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (!(fb->flags & DRM_MODE_FB_MODIFIERS)) {\n\t\tif (adev->family < AMDGPU_FAMILY_AI) {\n\t\t\tlinear = AMDGPU_TILING_GET(afb->tiling_flags, ARRAY_MODE) != DC_ARRAY_2D_TILED_THIN1 &&\n\t\t\t\t AMDGPU_TILING_GET(afb->tiling_flags, ARRAY_MODE) != DC_ARRAY_1D_TILED_THIN1 &&\n\t\t\t\t AMDGPU_TILING_GET(afb->tiling_flags, MICRO_TILE_MODE) == 0;\n\t\t} else {\n\t\t\tlinear = AMDGPU_TILING_GET(afb->tiling_flags, SWIZZLE_MODE) == 0;\n\t\t}\n\t\tif (!linear) {\n\t\t\tDRM_DEBUG_ATOMIC(\"Cursor FB not linear\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int dm_update_plane_state(struct dc *dc,\n\t\t\t\t struct drm_atomic_state *state,\n\t\t\t\t struct drm_plane *plane,\n\t\t\t\t struct drm_plane_state *old_plane_state,\n\t\t\t\t struct drm_plane_state *new_plane_state,\n\t\t\t\t bool enable,\n\t\t\t\t bool *lock_and_validation_needed,\n\t\t\t\t bool *is_top_most_overlay)\n{\n\n\tstruct dm_atomic_state *dm_state = NULL;\n\tstruct drm_crtc *new_plane_crtc, *old_plane_crtc;\n\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\tstruct dm_crtc_state *dm_new_crtc_state, *dm_old_crtc_state;\n\tstruct dm_plane_state *dm_new_plane_state, *dm_old_plane_state;\n\tstruct amdgpu_crtc *new_acrtc;\n\tbool needs_reset;\n\tint ret = 0;\n\n\n\tnew_plane_crtc = new_plane_state->crtc;\n\told_plane_crtc = old_plane_state->crtc;\n\tdm_new_plane_state = to_dm_plane_state(new_plane_state);\n\tdm_old_plane_state = to_dm_plane_state(old_plane_state);\n\n\tif (plane->type == DRM_PLANE_TYPE_CURSOR) {\n\t\tif (!enable || !new_plane_crtc ||\n\t\t\tdrm_atomic_plane_disabling(plane->state, new_plane_state))\n\t\t\treturn 0;\n\n\t\tnew_acrtc = to_amdgpu_crtc(new_plane_crtc);\n\n\t\tif (new_plane_state->src_x != 0 || new_plane_state->src_y != 0) {\n\t\t\tDRM_DEBUG_ATOMIC(\"Cropping not supported for cursor plane\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (new_plane_state->fb) {\n\t\t\tret = dm_check_cursor_fb(new_acrtc, new_plane_state,\n\t\t\t\t\t\t new_plane_state->fb);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tneeds_reset = should_reset_plane(state, plane, old_plane_state,\n\t\t\t\t\t new_plane_state);\n\n\t \n\tif (!enable) {\n\t\tif (!needs_reset)\n\t\t\treturn 0;\n\n\t\tif (!old_plane_crtc)\n\t\t\treturn 0;\n\n\t\told_crtc_state = drm_atomic_get_old_crtc_state(\n\t\t\t\tstate, old_plane_crtc);\n\t\tdm_old_crtc_state = to_dm_crtc_state(old_crtc_state);\n\n\t\tif (!dm_old_crtc_state->stream)\n\t\t\treturn 0;\n\n\t\tDRM_DEBUG_ATOMIC(\"Disabling DRM plane: %d on DRM crtc %d\\n\",\n\t\t\t\tplane->base.id, old_plane_crtc->base.id);\n\n\t\tret = dm_atomic_get_state(state, &dm_state);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!dc_remove_plane_from_context(\n\t\t\t\tdc,\n\t\t\t\tdm_old_crtc_state->stream,\n\t\t\t\tdm_old_plane_state->dc_state,\n\t\t\t\tdm_state->context)) {\n\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (dm_old_plane_state->dc_state)\n\t\t\tdc_plane_state_release(dm_old_plane_state->dc_state);\n\n\t\tdm_new_plane_state->dc_state = NULL;\n\n\t\t*lock_and_validation_needed = true;\n\n\t} else {  \n\t\tstruct dc_plane_state *dc_new_plane_state;\n\n\t\tif (drm_atomic_plane_disabling(plane->state, new_plane_state))\n\t\t\treturn 0;\n\n\t\tif (!new_plane_crtc)\n\t\t\treturn 0;\n\n\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(state, new_plane_crtc);\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\n\t\tif (!dm_new_crtc_state->stream)\n\t\t\treturn 0;\n\n\t\tif (!needs_reset)\n\t\t\treturn 0;\n\n\t\tret = amdgpu_dm_plane_helper_check_state(new_plane_state, new_crtc_state);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tWARN_ON(dm_new_plane_state->dc_state);\n\n\t\tdc_new_plane_state = dc_create_plane_state(dc);\n\t\tif (!dc_new_plane_state)\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\tif (plane->type == DRM_PLANE_TYPE_OVERLAY) {\n\t\t\tif (is_video_format(new_plane_state->fb->format->format) && *is_top_most_overlay)\n\t\t\t\treturn -EINVAL;\n\n\t\t\t*is_top_most_overlay = false;\n\t\t}\n\n\t\tDRM_DEBUG_ATOMIC(\"Enabling DRM plane: %d on DRM crtc %d\\n\",\n\t\t\t\t plane->base.id, new_plane_crtc->base.id);\n\n\t\tret = fill_dc_plane_attributes(\n\t\t\tdrm_to_adev(new_plane_crtc->dev),\n\t\t\tdc_new_plane_state,\n\t\t\tnew_plane_state,\n\t\t\tnew_crtc_state);\n\t\tif (ret) {\n\t\t\tdc_plane_state_release(dc_new_plane_state);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = dm_atomic_get_state(state, &dm_state);\n\t\tif (ret) {\n\t\t\tdc_plane_state_release(dc_new_plane_state);\n\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tif (!dc_add_plane_to_context(\n\t\t\t\tdc,\n\t\t\t\tdm_new_crtc_state->stream,\n\t\t\t\tdc_new_plane_state,\n\t\t\t\tdm_state->context)) {\n\n\t\t\tdc_plane_state_release(dc_new_plane_state);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tdm_new_plane_state->dc_state = dc_new_plane_state;\n\n\t\tdm_new_crtc_state->mpo_requested |= (plane->type == DRM_PLANE_TYPE_OVERLAY);\n\n\t\t \n\t\tdm_new_plane_state->dc_state->update_flags.bits.full_update = 1;\n\n\t\t*lock_and_validation_needed = true;\n\t}\n\n\n\treturn ret;\n}\n\nstatic void dm_get_oriented_plane_size(struct drm_plane_state *plane_state,\n\t\t\t\t       int *src_w, int *src_h)\n{\n\tswitch (plane_state->rotation & DRM_MODE_ROTATE_MASK) {\n\tcase DRM_MODE_ROTATE_90:\n\tcase DRM_MODE_ROTATE_270:\n\t\t*src_w = plane_state->src_h >> 16;\n\t\t*src_h = plane_state->src_w >> 16;\n\t\tbreak;\n\tcase DRM_MODE_ROTATE_0:\n\tcase DRM_MODE_ROTATE_180:\n\tdefault:\n\t\t*src_w = plane_state->src_w >> 16;\n\t\t*src_h = plane_state->src_h >> 16;\n\t\tbreak;\n\t}\n}\n\nstatic void\ndm_get_plane_scale(struct drm_plane_state *plane_state,\n\t\t   int *out_plane_scale_w, int *out_plane_scale_h)\n{\n\tint plane_src_w, plane_src_h;\n\n\tdm_get_oriented_plane_size(plane_state, &plane_src_w, &plane_src_h);\n\t*out_plane_scale_w = plane_state->crtc_w * 1000 / plane_src_w;\n\t*out_plane_scale_h = plane_state->crtc_h * 1000 / plane_src_h;\n}\n\nstatic int dm_check_crtc_cursor(struct drm_atomic_state *state,\n\t\t\t\tstruct drm_crtc *crtc,\n\t\t\t\tstruct drm_crtc_state *new_crtc_state)\n{\n\tstruct drm_plane *cursor = crtc->cursor, *plane, *underlying;\n\tstruct drm_plane_state *old_plane_state, *new_plane_state;\n\tstruct drm_plane_state *new_cursor_state, *new_underlying_state;\n\tint i;\n\tint cursor_scale_w, cursor_scale_h, underlying_scale_w, underlying_scale_h;\n\tbool any_relevant_change = false;\n\n\t \n\n\t \n\tfor_each_oldnew_plane_in_state(state, plane, old_plane_state, new_plane_state, i) {\n\t\tint new_scale_w, new_scale_h, old_scale_w, old_scale_h;\n\n\t\tif (!new_plane_state || !new_plane_state->fb || new_plane_state->crtc != crtc)\n\t\t\tcontinue;\n\n\t\tif (!old_plane_state || !old_plane_state->fb || old_plane_state->crtc != crtc) {\n\t\t\tany_relevant_change = true;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (new_plane_state->fb == old_plane_state->fb &&\n\t\t    new_plane_state->crtc_w == old_plane_state->crtc_w &&\n\t\t    new_plane_state->crtc_h == old_plane_state->crtc_h)\n\t\t\tcontinue;\n\n\t\tdm_get_plane_scale(new_plane_state, &new_scale_w, &new_scale_h);\n\t\tdm_get_plane_scale(old_plane_state, &old_scale_w, &old_scale_h);\n\n\t\tif (new_scale_w != old_scale_w || new_scale_h != old_scale_h) {\n\t\t\tany_relevant_change = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!any_relevant_change)\n\t\treturn 0;\n\n\tnew_cursor_state = drm_atomic_get_plane_state(state, cursor);\n\tif (IS_ERR(new_cursor_state))\n\t\treturn PTR_ERR(new_cursor_state);\n\n\tif (!new_cursor_state->fb)\n\t\treturn 0;\n\n\tdm_get_plane_scale(new_cursor_state, &cursor_scale_w, &cursor_scale_h);\n\n\t \n\ti = drm_atomic_add_affected_planes(state, crtc);\n\tif (i)\n\t\treturn i;\n\n\tfor_each_new_plane_in_state_reverse(state, underlying, new_underlying_state, i) {\n\t\t \n\t\tif (new_underlying_state->crtc != crtc || underlying == crtc->cursor)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!new_underlying_state->fb)\n\t\t\tcontinue;\n\n\t\tdm_get_plane_scale(new_underlying_state,\n\t\t\t\t   &underlying_scale_w, &underlying_scale_h);\n\n\t\tif (cursor_scale_w != underlying_scale_w ||\n\t\t    cursor_scale_h != underlying_scale_h) {\n\t\t\tdrm_dbg_atomic(crtc->dev,\n\t\t\t\t       \"Cursor [PLANE:%d:%s] scaling doesn't match underlying [PLANE:%d:%s]\\n\",\n\t\t\t\t       cursor->base.id, cursor->name, underlying->base.id, underlying->name);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (new_underlying_state->crtc_x <= 0 &&\n\t\t    new_underlying_state->crtc_y <= 0 &&\n\t\t    new_underlying_state->crtc_x + new_underlying_state->crtc_w >= new_crtc_state->mode.hdisplay &&\n\t\t    new_underlying_state->crtc_y + new_underlying_state->crtc_h >= new_crtc_state->mode.vdisplay)\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int add_affected_mst_dsc_crtcs(struct drm_atomic_state *state, struct drm_crtc *crtc)\n{\n\tstruct drm_connector *connector;\n\tstruct drm_connector_state *conn_state, *old_conn_state;\n\tstruct amdgpu_dm_connector *aconnector = NULL;\n\tint i;\n\n\tfor_each_oldnew_connector_in_state(state, connector, old_conn_state, conn_state, i) {\n\t\tif (!conn_state->crtc)\n\t\t\tconn_state = old_conn_state;\n\n\t\tif (conn_state->crtc != crtc)\n\t\t\tcontinue;\n\n\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\tif (!aconnector->mst_output_port || !aconnector->mst_root)\n\t\t\taconnector = NULL;\n\t\telse\n\t\t\tbreak;\n\t}\n\n\tif (!aconnector)\n\t\treturn 0;\n\n\treturn drm_dp_mst_add_affected_dsc_crtcs(state, &aconnector->mst_root->mst_mgr);\n}\n\n \nstatic int amdgpu_dm_atomic_check(struct drm_device *dev,\n\t\t\t\t  struct drm_atomic_state *state)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct dm_atomic_state *dm_state = NULL;\n\tstruct dc *dc = adev->dm.dc;\n\tstruct drm_connector *connector;\n\tstruct drm_connector_state *old_con_state, *new_con_state;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\tstruct drm_plane *plane;\n\tstruct drm_plane_state *old_plane_state, *new_plane_state;\n\tenum dc_status status;\n\tint ret, i;\n\tbool lock_and_validation_needed = false;\n\tbool is_top_most_overlay = true;\n\tstruct dm_crtc_state *dm_old_crtc_state, *dm_new_crtc_state;\n\tstruct drm_dp_mst_topology_mgr *mgr;\n\tstruct drm_dp_mst_topology_state *mst_state;\n\tstruct dsc_mst_fairness_vars vars[MAX_PIPES];\n\n\ttrace_amdgpu_dm_atomic_check_begin(state);\n\n\tret = drm_atomic_helper_check_modeset(dev, state);\n\tif (ret) {\n\t\tDRM_DEBUG_DRIVER(\"drm_atomic_helper_check_modeset() failed\\n\");\n\t\tgoto fail;\n\t}\n\n\t \n\tfor_each_oldnew_connector_in_state(state, connector, old_con_state, new_con_state, i) {\n\t\tstruct dm_connector_state *dm_old_con_state = to_dm_connector_state(old_con_state);\n\t\tstruct dm_connector_state *dm_new_con_state = to_dm_connector_state(new_con_state);\n\n\t\t \n\t\tif (!new_con_state->crtc)\n\t\t\tcontinue;\n\n\t\tnew_crtc_state = drm_atomic_get_crtc_state(state, new_con_state->crtc);\n\t\tif (IS_ERR(new_crtc_state)) {\n\t\t\tDRM_DEBUG_DRIVER(\"drm_atomic_get_crtc_state() failed\\n\");\n\t\t\tret = PTR_ERR(new_crtc_state);\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (dm_old_con_state->abm_level != dm_new_con_state->abm_level ||\n\t\t    dm_old_con_state->scaling != dm_new_con_state->scaling)\n\t\t\tnew_crtc_state->connectors_changed = true;\n\t}\n\n\tif (dc_resource_is_dsc_encoding_supported(dc)) {\n\t\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\t\tif (drm_atomic_crtc_needs_modeset(new_crtc_state)) {\n\t\t\t\tret = add_affected_mst_dsc_crtcs(state, crtc);\n\t\t\t\tif (ret) {\n\t\t\t\t\tDRM_DEBUG_DRIVER(\"add_affected_mst_dsc_crtcs() failed\\n\");\n\t\t\t\t\tgoto fail;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\tdm_old_crtc_state = to_dm_crtc_state(old_crtc_state);\n\n\t\tif (!drm_atomic_crtc_needs_modeset(new_crtc_state) &&\n\t\t    !new_crtc_state->color_mgmt_changed &&\n\t\t    old_crtc_state->vrr_enabled == new_crtc_state->vrr_enabled &&\n\t\t\tdm_old_crtc_state->dsc_force_changed == false)\n\t\t\tcontinue;\n\n\t\tret = amdgpu_dm_verify_lut_sizes(new_crtc_state);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"amdgpu_dm_verify_lut_sizes() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (!new_crtc_state->enable)\n\t\t\tcontinue;\n\n\t\tret = drm_atomic_add_affected_connectors(state, crtc);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"drm_atomic_add_affected_connectors() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = drm_atomic_add_affected_planes(state, crtc);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"drm_atomic_add_affected_planes() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (dm_old_crtc_state->dsc_force_changed)\n\t\t\tnew_crtc_state->mode_changed = true;\n\t}\n\n\t \n\tdrm_for_each_crtc(crtc, dev) {\n\t\tbool modified = false;\n\n\t\tfor_each_oldnew_plane_in_state(state, plane, old_plane_state, new_plane_state, i) {\n\t\t\tif (plane->type == DRM_PLANE_TYPE_CURSOR)\n\t\t\t\tcontinue;\n\n\t\t\tif (new_plane_state->crtc == crtc ||\n\t\t\t    old_plane_state->crtc == crtc) {\n\t\t\t\tmodified = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!modified)\n\t\t\tcontinue;\n\n\t\tdrm_for_each_plane_mask(plane, state->dev, crtc->state->plane_mask) {\n\t\t\tif (plane->type == DRM_PLANE_TYPE_CURSOR)\n\t\t\t\tcontinue;\n\n\t\t\tnew_plane_state =\n\t\t\t\tdrm_atomic_get_plane_state(state, plane);\n\n\t\t\tif (IS_ERR(new_plane_state)) {\n\t\t\t\tret = PTR_ERR(new_plane_state);\n\t\t\t\tDRM_DEBUG_DRIVER(\"new_plane_state is BAD\\n\");\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tret = drm_atomic_normalize_zpos(dev, state);\n\tif (ret) {\n\t\tdrm_dbg(dev, \"drm_atomic_normalize_zpos() failed\\n\");\n\t\tgoto fail;\n\t}\n\n\t \n\tfor_each_oldnew_plane_in_state_reverse(state, plane, old_plane_state, new_plane_state, i) {\n\t\tif (old_plane_state->fb && new_plane_state->fb &&\n\t\t    get_mem_type(old_plane_state->fb) !=\n\t\t    get_mem_type(new_plane_state->fb))\n\t\t\tlock_and_validation_needed = true;\n\n\t\tret = dm_update_plane_state(dc, state, plane,\n\t\t\t\t\t    old_plane_state,\n\t\t\t\t\t    new_plane_state,\n\t\t\t\t\t    false,\n\t\t\t\t\t    &lock_and_validation_needed,\n\t\t\t\t\t    &is_top_most_overlay);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"dm_update_plane_state() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\t \n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\tret = dm_update_crtc_state(&adev->dm, state, crtc,\n\t\t\t\t\t   old_crtc_state,\n\t\t\t\t\t   new_crtc_state,\n\t\t\t\t\t   false,\n\t\t\t\t\t   &lock_and_validation_needed);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"DISABLE: dm_update_crtc_state() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\t \n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\tret = dm_update_crtc_state(&adev->dm, state, crtc,\n\t\t\t\t\t   old_crtc_state,\n\t\t\t\t\t   new_crtc_state,\n\t\t\t\t\t   true,\n\t\t\t\t\t   &lock_and_validation_needed);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"ENABLE: dm_update_crtc_state() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\t \n\tfor_each_oldnew_plane_in_state_reverse(state, plane, old_plane_state, new_plane_state, i) {\n\t\tret = dm_update_plane_state(dc, state, plane,\n\t\t\t\t\t    old_plane_state,\n\t\t\t\t\t    new_plane_state,\n\t\t\t\t\t    true,\n\t\t\t\t\t    &lock_and_validation_needed,\n\t\t\t\t\t    &is_top_most_overlay);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"dm_update_plane_state() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tif (dc_resource_is_dsc_encoding_supported(dc)) {\n\t\tret = pre_validate_dsc(state, &dm_state, vars);\n\t\tif (ret != 0)\n\t\t\tgoto fail;\n\t}\n\n\t \n\tret = drm_atomic_helper_check_planes(dev, state);\n\tif (ret) {\n\t\tDRM_DEBUG_DRIVER(\"drm_atomic_helper_check_planes() failed\\n\");\n\t\tgoto fail;\n\t}\n\n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tdm_new_crtc_state = to_dm_crtc_state(new_crtc_state);\n\t\tif (dm_new_crtc_state->mpo_requested)\n\t\t\tDRM_DEBUG_DRIVER(\"MPO enablement requested on crtc:[%p]\\n\", crtc);\n\t}\n\n\t \n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tret = dm_check_crtc_cursor(state, crtc, new_crtc_state);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"dm_check_crtc_cursor() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tif (state->legacy_cursor_update) {\n\t\t \n\t\tstate->async_update =\n\t\t\t!drm_atomic_helper_async_check(dev, state);\n\n\t\t \n\t\tif (state->async_update)\n\t\t\treturn 0;\n\t}\n\n\t \n\t \n\tfor_each_oldnew_connector_in_state(state, connector, old_con_state, new_con_state, i) {\n\t\tstruct dm_connector_state *dm_old_con_state = to_dm_connector_state(old_con_state);\n\t\tstruct dm_connector_state *dm_new_con_state = to_dm_connector_state(new_con_state);\n\t\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(dm_new_con_state->base.crtc);\n\n\t\t \n\t\tif (!acrtc || drm_atomic_crtc_needs_modeset(\n\t\t\t\tdrm_atomic_get_new_crtc_state(state, &acrtc->base)))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!is_scaling_state_different(dm_new_con_state, dm_old_con_state))\n\t\t\tcontinue;\n\n\t\tlock_and_validation_needed = true;\n\t}\n\n\t \n\tfor_each_new_mst_mgr_in_state(state, mgr, mst_state, i) {\n\t\tstruct amdgpu_dm_connector *aconnector;\n\t\tstruct drm_connector *connector;\n\t\tstruct drm_connector_list_iter iter;\n\t\tu8 link_coding_cap;\n\n\t\tdrm_connector_list_iter_begin(dev, &iter);\n\t\tdrm_for_each_connector_iter(connector, &iter) {\n\t\t\tif (connector->index == mst_state->mgr->conn_base_id) {\n\t\t\t\taconnector = to_amdgpu_dm_connector(connector);\n\t\t\t\tlink_coding_cap = dc_link_dp_mst_decide_link_encoding_format(aconnector->dc_link);\n\t\t\t\tdrm_dp_mst_update_slots(mst_state, link_coding_cap);\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tdrm_connector_list_iter_end(&iter);\n\t}\n\n\t \n\tif (lock_and_validation_needed) {\n\t\tret = dm_atomic_get_state(state, &dm_state);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"dm_atomic_get_state() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = do_aquire_global_lock(dev, state);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"do_aquire_global_lock() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = compute_mst_dsc_configs_for_state(state, dm_state->context, vars);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"compute_mst_dsc_configs_for_state() failed\\n\");\n\t\t\tret = -EINVAL;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tret = dm_update_mst_vcpi_slots_for_dsc(state, dm_state->context, vars);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"dm_update_mst_vcpi_slots_for_dsc() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\n\t\t \n\t\tret = drm_dp_mst_atomic_check(state);\n\t\tif (ret) {\n\t\t\tDRM_DEBUG_DRIVER(\"drm_dp_mst_atomic_check() failed\\n\");\n\t\t\tgoto fail;\n\t\t}\n\t\tstatus = dc_validate_global_state(dc, dm_state->context, true);\n\t\tif (status != DC_OK) {\n\t\t\tDRM_DEBUG_DRIVER(\"DC global validation failure: %s (%d)\",\n\t\t\t\t       dc_status_to_str(status), status);\n\t\t\tret = -EINVAL;\n\t\t\tgoto fail;\n\t\t}\n\t} else {\n\t\t \n\n\t\tfor (i = 0; i < state->num_private_objs; i++) {\n\t\t\tstruct drm_private_obj *obj = state->private_objs[i].ptr;\n\n\t\t\tif (obj->funcs == adev->dm.atomic_obj.funcs) {\n\t\t\t\tint j = state->num_private_objs-1;\n\n\t\t\t\tdm_atomic_destroy_state(obj,\n\t\t\t\t\t\tstate->private_objs[i].state);\n\n\t\t\t\t \n\t\t\t\tif (i != j)\n\t\t\t\t\tstate->private_objs[i] =\n\t\t\t\t\t\tstate->private_objs[j];\n\n\t\t\t\tstate->private_objs[j].ptr = NULL;\n\t\t\t\tstate->private_objs[j].state = NULL;\n\t\t\t\tstate->private_objs[j].old_state = NULL;\n\t\t\t\tstate->private_objs[j].new_state = NULL;\n\n\t\t\t\tstate->num_private_objs = j;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tstruct dm_crtc_state *dm_new_crtc_state =\n\t\t\tto_dm_crtc_state(new_crtc_state);\n\n\t\t \n\t\tif (new_crtc_state->async_flip && lock_and_validation_needed) {\n\t\t\tdrm_dbg_atomic(crtc->dev,\n\t\t\t\t       \"[CRTC:%d:%s] async flips are only supported for fast updates\\n\",\n\t\t\t\t       crtc->base.id, crtc->name);\n\t\t\tret = -EINVAL;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tdm_new_crtc_state->update_type = lock_and_validation_needed ?\n\t\t\tUPDATE_TYPE_FULL : UPDATE_TYPE_FAST;\n\t}\n\n\t \n\tWARN_ON(ret);\n\n\ttrace_amdgpu_dm_atomic_check_finish(state, ret);\n\n\treturn ret;\n\nfail:\n\tif (ret == -EDEADLK)\n\t\tDRM_DEBUG_DRIVER(\"Atomic check stopped to avoid deadlock.\\n\");\n\telse if (ret == -EINTR || ret == -EAGAIN || ret == -ERESTARTSYS)\n\t\tDRM_DEBUG_DRIVER(\"Atomic check stopped due to signal.\\n\");\n\telse\n\t\tDRM_DEBUG_DRIVER(\"Atomic check failed with err: %d\\n\", ret);\n\n\ttrace_amdgpu_dm_atomic_check_finish(state, ret);\n\n\treturn ret;\n}\n\nstatic bool is_dp_capable_without_timing_msa(struct dc *dc,\n\t\t\t\t\t     struct amdgpu_dm_connector *amdgpu_dm_connector)\n{\n\tu8 dpcd_data;\n\tbool capable = false;\n\n\tif (amdgpu_dm_connector->dc_link &&\n\t\tdm_helpers_dp_read_dpcd(\n\t\t\t\tNULL,\n\t\t\t\tamdgpu_dm_connector->dc_link,\n\t\t\t\tDP_DOWN_STREAM_PORT_COUNT,\n\t\t\t\t&dpcd_data,\n\t\t\t\tsizeof(dpcd_data))) {\n\t\tcapable = (dpcd_data & DP_MSA_TIMING_PAR_IGNORED) ? true:false;\n\t}\n\n\treturn capable;\n}\n\nstatic bool dm_edid_parser_send_cea(struct amdgpu_display_manager *dm,\n\t\tunsigned int offset,\n\t\tunsigned int total_length,\n\t\tu8 *data,\n\t\tunsigned int length,\n\t\tstruct amdgpu_hdmi_vsdb_info *vsdb)\n{\n\tbool res;\n\tunion dmub_rb_cmd cmd;\n\tstruct dmub_cmd_send_edid_cea *input;\n\tstruct dmub_cmd_edid_cea_output *output;\n\n\tif (length > DMUB_EDID_CEA_DATA_CHUNK_BYTES)\n\t\treturn false;\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\n\tinput = &cmd.edid_cea.data.input;\n\n\tcmd.edid_cea.header.type = DMUB_CMD__EDID_CEA;\n\tcmd.edid_cea.header.sub_type = 0;\n\tcmd.edid_cea.header.payload_bytes =\n\t\tsizeof(cmd.edid_cea) - sizeof(cmd.edid_cea.header);\n\tinput->offset = offset;\n\tinput->length = length;\n\tinput->cea_total_length = total_length;\n\tmemcpy(input->payload, data, length);\n\n\tres = dm_execute_dmub_cmd(dm->dc->ctx, &cmd, DM_DMUB_WAIT_TYPE_WAIT_WITH_REPLY);\n\tif (!res) {\n\t\tDRM_ERROR(\"EDID CEA parser failed\\n\");\n\t\treturn false;\n\t}\n\n\toutput = &cmd.edid_cea.data.output;\n\n\tif (output->type == DMUB_CMD__EDID_CEA_ACK) {\n\t\tif (!output->ack.success) {\n\t\t\tDRM_ERROR(\"EDID CEA ack failed at offset %d\\n\",\n\t\t\t\t\toutput->ack.offset);\n\t\t}\n\t} else if (output->type == DMUB_CMD__EDID_CEA_AMD_VSDB) {\n\t\tif (!output->amd_vsdb.vsdb_found)\n\t\t\treturn false;\n\n\t\tvsdb->freesync_supported = output->amd_vsdb.freesync_supported;\n\t\tvsdb->amd_vsdb_version = output->amd_vsdb.amd_vsdb_version;\n\t\tvsdb->min_refresh_rate_hz = output->amd_vsdb.min_frame_rate;\n\t\tvsdb->max_refresh_rate_hz = output->amd_vsdb.max_frame_rate;\n\t} else {\n\t\tDRM_WARN(\"Unknown EDID CEA parser results\\n\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool parse_edid_cea_dmcu(struct amdgpu_display_manager *dm,\n\t\tu8 *edid_ext, int len,\n\t\tstruct amdgpu_hdmi_vsdb_info *vsdb_info)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < len; i += 8) {\n\t\tbool res;\n\t\tint offset;\n\n\t\t \n\t\tif (!dc_edid_parser_send_cea(dm->dc, i, len, &edid_ext[i], 8))\n\t\t\treturn false;\n\n\t\tif (i+8 == len) {\n\t\t\t \n\t\t\tint version, min_rate, max_rate;\n\n\t\t\tres = dc_edid_parser_recv_amd_vsdb(dm->dc, &version, &min_rate, &max_rate);\n\t\t\tif (res) {\n\t\t\t\t \n\t\t\t\tvsdb_info->freesync_supported = 1;\n\t\t\t\tvsdb_info->amd_vsdb_version = version;\n\t\t\t\tvsdb_info->min_refresh_rate_hz = min_rate;\n\t\t\t\tvsdb_info->max_refresh_rate_hz = max_rate;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\t \n\t\t\treturn false;\n\t\t}\n\n\t\t \n\t\tres = dc_edid_parser_recv_cea_ack(dm->dc, &offset);\n\t\tif (!res)\n\t\t\treturn false;\n\t}\n\n\treturn false;\n}\n\nstatic bool parse_edid_cea_dmub(struct amdgpu_display_manager *dm,\n\t\tu8 *edid_ext, int len,\n\t\tstruct amdgpu_hdmi_vsdb_info *vsdb_info)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < len; i += 8) {\n\t\t \n\t\tif (!dm_edid_parser_send_cea(dm, i, len, &edid_ext[i], 8, vsdb_info))\n\t\t\treturn false;\n\t}\n\n\treturn vsdb_info->freesync_supported;\n}\n\nstatic bool parse_edid_cea(struct amdgpu_dm_connector *aconnector,\n\t\tu8 *edid_ext, int len,\n\t\tstruct amdgpu_hdmi_vsdb_info *vsdb_info)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(aconnector->base.dev);\n\tbool ret;\n\n\tmutex_lock(&adev->dm.dc_lock);\n\tif (adev->dm.dmub_srv)\n\t\tret = parse_edid_cea_dmub(&adev->dm, edid_ext, len, vsdb_info);\n\telse\n\t\tret = parse_edid_cea_dmcu(&adev->dm, edid_ext, len, vsdb_info);\n\tmutex_unlock(&adev->dm.dc_lock);\n\treturn ret;\n}\n\nstatic int parse_amd_vsdb(struct amdgpu_dm_connector *aconnector,\n\t\t\t  struct edid *edid, struct amdgpu_hdmi_vsdb_info *vsdb_info)\n{\n\tu8 *edid_ext = NULL;\n\tint i;\n\tint j = 0;\n\n\tif (edid == NULL || edid->extensions == 0)\n\t\treturn -ENODEV;\n\n\t \n\tfor (i = 0; i < edid->extensions; i++) {\n\t\tedid_ext = (void *)(edid + (i + 1));\n\t\tif (edid_ext[0] == DISPLAYID_EXT)\n\t\t\tbreak;\n\t}\n\n\twhile (j < EDID_LENGTH) {\n\t\tstruct amd_vsdb_block *amd_vsdb = (struct amd_vsdb_block *)&edid_ext[j];\n\t\tunsigned int ieeeId = (amd_vsdb->ieee_id[2] << 16) | (amd_vsdb->ieee_id[1] << 8) | (amd_vsdb->ieee_id[0]);\n\n\t\tif (ieeeId == HDMI_AMD_VENDOR_SPECIFIC_DATA_BLOCK_IEEE_REGISTRATION_ID &&\n\t\t\t\tamd_vsdb->version == HDMI_AMD_VENDOR_SPECIFIC_DATA_BLOCK_VERSION_3) {\n\t\t\tvsdb_info->replay_mode = (amd_vsdb->feature_caps & AMD_VSDB_VERSION_3_FEATURECAP_REPLAYMODE) ? true : false;\n\t\t\tvsdb_info->amd_vsdb_version = HDMI_AMD_VENDOR_SPECIFIC_DATA_BLOCK_VERSION_3;\n\t\t\tDRM_DEBUG_KMS(\"Panel supports Replay Mode: %d\\n\", vsdb_info->replay_mode);\n\n\t\t\treturn true;\n\t\t}\n\t\tj++;\n\t}\n\n\treturn false;\n}\n\nstatic int parse_hdmi_amd_vsdb(struct amdgpu_dm_connector *aconnector,\n\t\tstruct edid *edid, struct amdgpu_hdmi_vsdb_info *vsdb_info)\n{\n\tu8 *edid_ext = NULL;\n\tint i;\n\tbool valid_vsdb_found = false;\n\n\t \n\t \n\tif (edid == NULL || edid->extensions == 0)\n\t\treturn -ENODEV;\n\n\t \n\tfor (i = 0; i < edid->extensions; i++) {\n\t\tedid_ext = (uint8_t *)edid + EDID_LENGTH * (i + 1);\n\t\tif (edid_ext[0] == CEA_EXT)\n\t\t\tbreak;\n\t}\n\n\tif (i == edid->extensions)\n\t\treturn -ENODEV;\n\n\t \n\tif (edid_ext[0] != CEA_EXT)\n\t\treturn -ENODEV;\n\n\tvalid_vsdb_found = parse_edid_cea(aconnector, edid_ext, EDID_LENGTH, vsdb_info);\n\n\treturn valid_vsdb_found ? i : -ENODEV;\n}\n\n \nvoid amdgpu_dm_update_freesync_caps(struct drm_connector *connector,\n\t\t\t\t    struct edid *edid)\n{\n\tint i = 0;\n\tstruct detailed_timing *timing;\n\tstruct detailed_non_pixel *data;\n\tstruct detailed_data_monitor_range *range;\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\t\tto_amdgpu_dm_connector(connector);\n\tstruct dm_connector_state *dm_con_state = NULL;\n\tstruct dc_sink *sink;\n\n\tstruct drm_device *dev = connector->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_hdmi_vsdb_info vsdb_info = {0};\n\tbool freesync_capable = false;\n\tenum adaptive_sync_type as_type = ADAPTIVE_SYNC_TYPE_NONE;\n\n\tif (!connector->state) {\n\t\tDRM_ERROR(\"%s - Connector has no state\", __func__);\n\t\tgoto update;\n\t}\n\n\tsink = amdgpu_dm_connector->dc_sink ?\n\t\tamdgpu_dm_connector->dc_sink :\n\t\tamdgpu_dm_connector->dc_em_sink;\n\n\tif (!edid || !sink) {\n\t\tdm_con_state = to_dm_connector_state(connector->state);\n\n\t\tamdgpu_dm_connector->min_vfreq = 0;\n\t\tamdgpu_dm_connector->max_vfreq = 0;\n\t\tamdgpu_dm_connector->pixel_clock_mhz = 0;\n\t\tconnector->display_info.monitor_range.min_vfreq = 0;\n\t\tconnector->display_info.monitor_range.max_vfreq = 0;\n\t\tfreesync_capable = false;\n\n\t\tgoto update;\n\t}\n\n\tdm_con_state = to_dm_connector_state(connector->state);\n\n\tif (!adev->dm.freesync_module)\n\t\tgoto update;\n\n\tif (sink->sink_signal == SIGNAL_TYPE_DISPLAY_PORT\n\t\t|| sink->sink_signal == SIGNAL_TYPE_EDP) {\n\t\tbool edid_check_required = false;\n\n\t\tif (edid) {\n\t\t\tedid_check_required = is_dp_capable_without_timing_msa(\n\t\t\t\t\t\tadev->dm.dc,\n\t\t\t\t\t\tamdgpu_dm_connector);\n\t\t}\n\n\t\tif (edid_check_required == true && (edid->version > 1 ||\n\t\t   (edid->version == 1 && edid->revision > 1))) {\n\t\t\tfor (i = 0; i < 4; i++) {\n\n\t\t\t\ttiming\t= &edid->detailed_timings[i];\n\t\t\t\tdata\t= &timing->data.other_data;\n\t\t\t\trange\t= &data->data.range;\n\t\t\t\t \n\t\t\t\tif (data->type != EDID_DETAIL_MONITOR_RANGE)\n\t\t\t\t\tcontinue;\n\t\t\t\t \n\t\t\t\tif (range->flags != 1)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tamdgpu_dm_connector->min_vfreq = range->min_vfreq;\n\t\t\t\tamdgpu_dm_connector->max_vfreq = range->max_vfreq;\n\t\t\t\tamdgpu_dm_connector->pixel_clock_mhz =\n\t\t\t\t\trange->pixel_clock_mhz * 10;\n\n\t\t\t\tconnector->display_info.monitor_range.min_vfreq = range->min_vfreq;\n\t\t\t\tconnector->display_info.monitor_range.max_vfreq = range->max_vfreq;\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (amdgpu_dm_connector->max_vfreq -\n\t\t\t    amdgpu_dm_connector->min_vfreq > 10) {\n\n\t\t\t\tfreesync_capable = true;\n\t\t\t}\n\t\t}\n\t\tparse_amd_vsdb(amdgpu_dm_connector, edid, &vsdb_info);\n\n\t\tif (vsdb_info.replay_mode) {\n\t\t\tamdgpu_dm_connector->vsdb_info.replay_mode = vsdb_info.replay_mode;\n\t\t\tamdgpu_dm_connector->vsdb_info.amd_vsdb_version = vsdb_info.amd_vsdb_version;\n\t\t\tamdgpu_dm_connector->as_type = ADAPTIVE_SYNC_TYPE_EDP;\n\t\t}\n\n\t} else if (edid && sink->sink_signal == SIGNAL_TYPE_HDMI_TYPE_A) {\n\t\ti = parse_hdmi_amd_vsdb(amdgpu_dm_connector, edid, &vsdb_info);\n\t\tif (i >= 0 && vsdb_info.freesync_supported) {\n\t\t\ttiming  = &edid->detailed_timings[i];\n\t\t\tdata    = &timing->data.other_data;\n\n\t\t\tamdgpu_dm_connector->min_vfreq = vsdb_info.min_refresh_rate_hz;\n\t\t\tamdgpu_dm_connector->max_vfreq = vsdb_info.max_refresh_rate_hz;\n\t\t\tif (amdgpu_dm_connector->max_vfreq - amdgpu_dm_connector->min_vfreq > 10)\n\t\t\t\tfreesync_capable = true;\n\n\t\t\tconnector->display_info.monitor_range.min_vfreq = vsdb_info.min_refresh_rate_hz;\n\t\t\tconnector->display_info.monitor_range.max_vfreq = vsdb_info.max_refresh_rate_hz;\n\t\t}\n\t}\n\n\tas_type = dm_get_adaptive_sync_support_type(amdgpu_dm_connector->dc_link);\n\n\tif (as_type == FREESYNC_TYPE_PCON_IN_WHITELIST) {\n\t\ti = parse_hdmi_amd_vsdb(amdgpu_dm_connector, edid, &vsdb_info);\n\t\tif (i >= 0 && vsdb_info.freesync_supported && vsdb_info.amd_vsdb_version > 0) {\n\n\t\t\tamdgpu_dm_connector->pack_sdp_v1_3 = true;\n\t\t\tamdgpu_dm_connector->as_type = as_type;\n\t\t\tamdgpu_dm_connector->vsdb_info = vsdb_info;\n\n\t\t\tamdgpu_dm_connector->min_vfreq = vsdb_info.min_refresh_rate_hz;\n\t\t\tamdgpu_dm_connector->max_vfreq = vsdb_info.max_refresh_rate_hz;\n\t\t\tif (amdgpu_dm_connector->max_vfreq - amdgpu_dm_connector->min_vfreq > 10)\n\t\t\t\tfreesync_capable = true;\n\n\t\t\tconnector->display_info.monitor_range.min_vfreq = vsdb_info.min_refresh_rate_hz;\n\t\t\tconnector->display_info.monitor_range.max_vfreq = vsdb_info.max_refresh_rate_hz;\n\t\t}\n\t}\n\nupdate:\n\tif (dm_con_state)\n\t\tdm_con_state->freesync_capable = freesync_capable;\n\n\tif (connector->vrr_capable_property)\n\t\tdrm_connector_set_vrr_capable_property(connector,\n\t\t\t\t\t\t       freesync_capable);\n}\n\nvoid amdgpu_dm_trigger_timing_sync(struct drm_device *dev)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct dc *dc = adev->dm.dc;\n\tint i;\n\n\tmutex_lock(&adev->dm.dc_lock);\n\tif (dc->current_state) {\n\t\tfor (i = 0; i < dc->current_state->stream_count; ++i)\n\t\t\tdc->current_state->streams[i]\n\t\t\t\t->triggered_crtc_reset.enabled =\n\t\t\t\tadev->dm.force_timing_sync;\n\n\t\tdm_enable_per_frame_crtc_master_sync(dc->current_state);\n\t\tdc_trigger_sync(dc, dc->current_state);\n\t}\n\tmutex_unlock(&adev->dm.dc_lock);\n}\n\nvoid dm_write_reg_func(const struct dc_context *ctx, uint32_t address,\n\t\t       u32 value, const char *func_name)\n{\n#ifdef DM_CHECK_ADDR_0\n\tif (address == 0) {\n\t\tDC_ERR(\"invalid register write. address = 0\");\n\t\treturn;\n\t}\n#endif\n\tcgs_write_register(ctx->cgs_device, address, value);\n\ttrace_amdgpu_dc_wreg(&ctx->perf_trace->write_count, address, value);\n}\n\nuint32_t dm_read_reg_func(const struct dc_context *ctx, uint32_t address,\n\t\t\t  const char *func_name)\n{\n\tu32 value;\n#ifdef DM_CHECK_ADDR_0\n\tif (address == 0) {\n\t\tDC_ERR(\"invalid register read; address = 0\\n\");\n\t\treturn 0;\n\t}\n#endif\n\n\tif (ctx->dmub_srv &&\n\t    ctx->dmub_srv->reg_helper_offload.gather_in_progress &&\n\t    !ctx->dmub_srv->reg_helper_offload.should_burst_write) {\n\t\tASSERT(false);\n\t\treturn 0;\n\t}\n\n\tvalue = cgs_read_register(ctx->cgs_device, address);\n\n\ttrace_amdgpu_dc_rreg(&ctx->perf_trace->read_count, address, value);\n\n\treturn value;\n}\n\nint amdgpu_dm_process_dmub_aux_transfer_sync(\n\t\tstruct dc_context *ctx,\n\t\tunsigned int link_index,\n\t\tstruct aux_payload *payload,\n\t\tenum aux_return_code_type *operation_result)\n{\n\tstruct amdgpu_device *adev = ctx->driver_context;\n\tstruct dmub_notification *p_notify = adev->dm.dmub_notify;\n\tint ret = -1;\n\n\tmutex_lock(&adev->dm.dpia_aux_lock);\n\tif (!dc_process_dmub_aux_transfer_async(ctx->dc, link_index, payload)) {\n\t\t*operation_result = AUX_RET_ERROR_ENGINE_ACQUIRE;\n\t\tgoto out;\n\t}\n\n\tif (!wait_for_completion_timeout(&adev->dm.dmub_aux_transfer_done, 10 * HZ)) {\n\t\tDRM_ERROR(\"wait_for_completion_timeout timeout!\");\n\t\t*operation_result = AUX_RET_ERROR_TIMEOUT;\n\t\tgoto out;\n\t}\n\n\tif (p_notify->result != AUX_RET_SUCCESS) {\n\t\t \n\t\tif (p_notify->result != AUX_RET_ERROR_PROTOCOL_ERROR) {\n\t\t\tDRM_WARN(\"DPIA AUX failed on 0x%x(%d), error %d\\n\",\n\t\t\t\t\tpayload->address, payload->length,\n\t\t\t\t\tp_notify->result);\n\t\t}\n\t\t*operation_result = AUX_RET_ERROR_INVALID_REPLY;\n\t\tgoto out;\n\t}\n\n\n\tpayload->reply[0] = adev->dm.dmub_notify->aux_reply.command;\n\tif (!payload->write && p_notify->aux_reply.length &&\n\t\t\t(payload->reply[0] == AUX_TRANSACTION_REPLY_AUX_ACK)) {\n\n\t\tif (payload->length != p_notify->aux_reply.length) {\n\t\t\tDRM_WARN(\"invalid read length %d from DPIA AUX 0x%x(%d)!\\n\",\n\t\t\t\tp_notify->aux_reply.length,\n\t\t\t\t\tpayload->address, payload->length);\n\t\t\t*operation_result = AUX_RET_ERROR_INVALID_REPLY;\n\t\t\tgoto out;\n\t\t}\n\n\t\tmemcpy(payload->data, p_notify->aux_reply.data,\n\t\t\t\tp_notify->aux_reply.length);\n\t}\n\n\t \n\tret = p_notify->aux_reply.length;\n\t*operation_result = p_notify->result;\nout:\n\treinit_completion(&adev->dm.dmub_aux_transfer_done);\n\tmutex_unlock(&adev->dm.dpia_aux_lock);\n\treturn ret;\n}\n\nint amdgpu_dm_process_dmub_set_config_sync(\n\t\tstruct dc_context *ctx,\n\t\tunsigned int link_index,\n\t\tstruct set_config_cmd_payload *payload,\n\t\tenum set_config_status *operation_result)\n{\n\tstruct amdgpu_device *adev = ctx->driver_context;\n\tbool is_cmd_complete;\n\tint ret;\n\n\tmutex_lock(&adev->dm.dpia_aux_lock);\n\tis_cmd_complete = dc_process_dmub_set_config_async(ctx->dc,\n\t\t\tlink_index, payload, adev->dm.dmub_notify);\n\n\tif (is_cmd_complete || wait_for_completion_timeout(&adev->dm.dmub_aux_transfer_done, 10 * HZ)) {\n\t\tret = 0;\n\t\t*operation_result = adev->dm.dmub_notify->sc_status;\n\t} else {\n\t\tDRM_ERROR(\"wait_for_completion_timeout timeout!\");\n\t\tret = -1;\n\t\t*operation_result = SET_CONFIG_UNKNOWN_ERROR;\n\t}\n\n\tif (!is_cmd_complete)\n\t\treinit_completion(&adev->dm.dmub_aux_transfer_done);\n\tmutex_unlock(&adev->dm.dpia_aux_lock);\n\treturn ret;\n}\n\n \nbool check_seamless_boot_capability(struct amdgpu_device *adev)\n{\n\tswitch (adev->ip_versions[DCE_HWIP][0]) {\n\tcase IP_VERSION(3, 0, 1):\n\t\tif (!adev->mman.keep_stolen_vga_memory)\n\t\t\treturn true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn false;\n}\n\nbool dm_execute_dmub_cmd(const struct dc_context *ctx, union dmub_rb_cmd *cmd, enum dm_dmub_wait_type wait_type)\n{\n\treturn dc_dmub_srv_cmd_run(ctx->dmub_srv, cmd, wait_type);\n}\n\nbool dm_execute_dmub_cmd_list(const struct dc_context *ctx, unsigned int count, union dmub_rb_cmd *cmd, enum dm_dmub_wait_type wait_type)\n{\n\treturn dc_dmub_srv_cmd_run_list(ctx->dmub_srv, count, cmd, wait_type);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}