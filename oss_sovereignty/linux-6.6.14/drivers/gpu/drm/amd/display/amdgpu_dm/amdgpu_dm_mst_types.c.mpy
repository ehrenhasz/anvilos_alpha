{
  "module_name": "amdgpu_dm_mst_types.c",
  "hash_id": "707cc329383ec10eda56c3f2d82eb47fb5ed1501eb3736d1dd69d838576fddee",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_mst_types.c",
  "human_readable_source": " \n\n#include <drm/display/drm_dp_helper.h>\n#include <drm/display/drm_dp_mst_helper.h>\n#include <drm/drm_atomic.h>\n#include <drm/drm_atomic_helper.h>\n#include \"dm_services.h\"\n#include \"amdgpu.h\"\n#include \"amdgpu_dm.h\"\n#include \"amdgpu_dm_mst_types.h\"\n#include \"amdgpu_dm_hdcp.h\"\n\n#include \"dc.h\"\n#include \"dm_helpers.h\"\n\n#include \"ddc_service_types.h\"\n#include \"dpcd_defs.h\"\n\n#include \"dmub_cmd.h\"\n#if defined(CONFIG_DEBUG_FS)\n#include \"amdgpu_dm_debugfs.h\"\n#endif\n\n#include \"dc/dcn20/dcn20_resource.h\"\n\n#define PEAK_FACTOR_X1000 1006\n\nstatic ssize_t dm_dp_aux_transfer(struct drm_dp_aux *aux,\n\t\t\t\t  struct drm_dp_aux_msg *msg)\n{\n\tssize_t result = 0;\n\tstruct aux_payload payload;\n\tenum aux_return_code_type operation_result;\n\tstruct amdgpu_device *adev;\n\tstruct ddc_service *ddc;\n\n\tif (WARN_ON(msg->size > 16))\n\t\treturn -E2BIG;\n\n\tpayload.address = msg->address;\n\tpayload.data = msg->buffer;\n\tpayload.length = msg->size;\n\tpayload.reply = &msg->reply;\n\tpayload.i2c_over_aux = (msg->request & DP_AUX_NATIVE_WRITE) == 0;\n\tpayload.write = (msg->request & DP_AUX_I2C_READ) == 0;\n\tpayload.mot = (msg->request & DP_AUX_I2C_MOT) != 0;\n\tpayload.write_status_update =\n\t\t\t(msg->request & DP_AUX_I2C_WRITE_STATUS_UPDATE) != 0;\n\tpayload.defer_delay = 0;\n\n\tresult = dc_link_aux_transfer_raw(TO_DM_AUX(aux)->ddc_service, &payload,\n\t\t\t\t      &operation_result);\n\n\t \n\tddc = TO_DM_AUX(aux)->ddc_service;\n\tadev = ddc->ctx->driver_context;\n\tif (adev->dm.aux_hpd_discon_quirk) {\n\t\tif (msg->address == DP_SIDEBAND_MSG_DOWN_REQ_BASE &&\n\t\t\toperation_result == AUX_RET_ERROR_HPD_DISCON) {\n\t\t\tresult = 0;\n\t\t\toperation_result = AUX_RET_SUCCESS;\n\t\t}\n\t}\n\n\tif (payload.write && result >= 0)\n\t\tresult = msg->size;\n\n\tif (result < 0)\n\t\tswitch (operation_result) {\n\t\tcase AUX_RET_SUCCESS:\n\t\t\tbreak;\n\t\tcase AUX_RET_ERROR_HPD_DISCON:\n\t\tcase AUX_RET_ERROR_UNKNOWN:\n\t\tcase AUX_RET_ERROR_INVALID_OPERATION:\n\t\tcase AUX_RET_ERROR_PROTOCOL_ERROR:\n\t\t\tresult = -EIO;\n\t\t\tbreak;\n\t\tcase AUX_RET_ERROR_INVALID_REPLY:\n\t\tcase AUX_RET_ERROR_ENGINE_ACQUIRE:\n\t\t\tresult = -EBUSY;\n\t\t\tbreak;\n\t\tcase AUX_RET_ERROR_TIMEOUT:\n\t\t\tresult = -ETIMEDOUT;\n\t\t\tbreak;\n\t\t}\n\n\treturn result;\n}\n\nstatic void\ndm_dp_mst_connector_destroy(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *aconnector =\n\t\tto_amdgpu_dm_connector(connector);\n\n\tif (aconnector->dc_sink) {\n\t\tdc_link_remove_remote_sink(aconnector->dc_link,\n\t\t\t\t\t   aconnector->dc_sink);\n\t\tdc_sink_release(aconnector->dc_sink);\n\t}\n\n\tkfree(aconnector->edid);\n\n\tdrm_connector_cleanup(connector);\n\tdrm_dp_mst_put_port_malloc(aconnector->mst_output_port);\n\tkfree(aconnector);\n}\n\nstatic int\namdgpu_dm_mst_connector_late_register(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\tto_amdgpu_dm_connector(connector);\n\tint r;\n\n\tr = drm_dp_mst_connector_late_register(connector,\n\t\t\t\t\t       amdgpu_dm_connector->mst_output_port);\n\tif (r < 0)\n\t\treturn r;\n\n#if defined(CONFIG_DEBUG_FS)\n\tconnector_debugfs_init(amdgpu_dm_connector);\n#endif\n\n\treturn 0;\n}\n\nstatic void\namdgpu_dm_mst_connector_early_unregister(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *aconnector =\n\t\tto_amdgpu_dm_connector(connector);\n\tstruct drm_dp_mst_port *port = aconnector->mst_output_port;\n\tstruct amdgpu_dm_connector *root = aconnector->mst_root;\n\tstruct dc_link *dc_link = aconnector->dc_link;\n\tstruct dc_sink *dc_sink = aconnector->dc_sink;\n\n\tdrm_dp_mst_connector_early_unregister(connector, port);\n\n\t \n\tdrm_modeset_lock(&root->mst_mgr.base.lock, NULL);\n\tif (dc_sink) {\n\t\tif (dc_link->sink_count)\n\t\t\tdc_link_remove_remote_sink(dc_link, dc_sink);\n\n\t\tDC_LOG_MST(\"DM_MST: remove remote sink 0x%p, %d remaining\\n\",\n\t\t\tdc_sink, dc_link->sink_count);\n\n\t\tdc_sink_release(dc_sink);\n\t\taconnector->dc_sink = NULL;\n\t\taconnector->edid = NULL;\n\t}\n\n\taconnector->mst_status = MST_STATUS_DEFAULT;\n\tdrm_modeset_unlock(&root->mst_mgr.base.lock);\n}\n\nstatic const struct drm_connector_funcs dm_dp_mst_connector_funcs = {\n\t.fill_modes = drm_helper_probe_single_connector_modes,\n\t.destroy = dm_dp_mst_connector_destroy,\n\t.reset = amdgpu_dm_connector_funcs_reset,\n\t.atomic_duplicate_state = amdgpu_dm_connector_atomic_duplicate_state,\n\t.atomic_destroy_state = drm_atomic_helper_connector_destroy_state,\n\t.atomic_set_property = amdgpu_dm_connector_atomic_set_property,\n\t.atomic_get_property = amdgpu_dm_connector_atomic_get_property,\n\t.late_register = amdgpu_dm_mst_connector_late_register,\n\t.early_unregister = amdgpu_dm_mst_connector_early_unregister,\n};\n\nbool needs_dsc_aux_workaround(struct dc_link *link)\n{\n\tif (link->dpcd_caps.branch_dev_id == DP_BRANCH_DEVICE_ID_90CC24 &&\n\t    (link->dpcd_caps.dpcd_rev.raw == DPCD_REV_14 || link->dpcd_caps.dpcd_rev.raw == DPCD_REV_12) &&\n\t    link->dpcd_caps.sink_count.bits.SINK_COUNT >= 2)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic bool is_synaptics_cascaded_panamera(struct dc_link *link, struct drm_dp_mst_port *port)\n{\n\tu8 branch_vendor_data[4] = { 0 }; \n\n\tif (drm_dp_dpcd_read(port->mgr->aux, DP_BRANCH_VENDOR_SPECIFIC_START, &branch_vendor_data, 4) == 4) {\n\t\tif (link->dpcd_caps.branch_dev_id == DP_BRANCH_DEVICE_ID_90CC24 &&\n\t\t\t\tIS_SYNAPTICS_CASCADED_PANAMERA(link->dpcd_caps.branch_dev_name, branch_vendor_data)) {\n\t\t\tDRM_INFO(\"Synaptics Cascaded MST hub\\n\");\n\t\t\treturn true;\n\t\t}\n\t}\n\n\treturn false;\n}\n\nstatic bool validate_dsc_caps_on_connector(struct amdgpu_dm_connector *aconnector)\n{\n\tstruct dc_sink *dc_sink = aconnector->dc_sink;\n\tstruct drm_dp_mst_port *port = aconnector->mst_output_port;\n\tu8 dsc_caps[16] = { 0 };\n\tu8 dsc_branch_dec_caps_raw[3] = { 0 };\t\n\tu8 *dsc_branch_dec_caps = NULL;\n\n\taconnector->dsc_aux = drm_dp_mst_dsc_aux_for_port(port);\n\n\t \n\tif (!aconnector->dsc_aux && !port->parent->port_parent &&\n\t    needs_dsc_aux_workaround(aconnector->dc_link))\n\t\taconnector->dsc_aux = &aconnector->mst_root->dm_dp_aux.aux;\n\n\t \n\tif (!aconnector->dsc_aux && is_synaptics_cascaded_panamera(aconnector->dc_link, port))\n\t\taconnector->dsc_aux = port->mgr->aux;\n\n\tif (!aconnector->dsc_aux)\n\t\treturn false;\n\n\tif (drm_dp_dpcd_read(aconnector->dsc_aux, DP_DSC_SUPPORT, dsc_caps, 16) < 0)\n\t\treturn false;\n\n\tif (drm_dp_dpcd_read(aconnector->dsc_aux,\n\t\t\tDP_DSC_BRANCH_OVERALL_THROUGHPUT_0, dsc_branch_dec_caps_raw, 3) == 3)\n\t\tdsc_branch_dec_caps = dsc_branch_dec_caps_raw;\n\n\tif (!dc_dsc_parse_dsc_dpcd(aconnector->dc_link->ctx->dc,\n\t\t\t\t  dsc_caps, dsc_branch_dec_caps,\n\t\t\t\t  &dc_sink->dsc_caps.dsc_dec_caps))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool retrieve_downstream_port_device(struct amdgpu_dm_connector *aconnector)\n{\n\tunion dp_downstream_port_present ds_port_present;\n\n\tif (!aconnector->dsc_aux)\n\t\treturn false;\n\n\tif (drm_dp_dpcd_read(aconnector->dsc_aux, DP_DOWNSTREAMPORT_PRESENT, &ds_port_present, 1) < 0) {\n\t\tDRM_INFO(\"Failed to read downstream_port_present 0x05 from DFP of branch device\\n\");\n\t\treturn false;\n\t}\n\n\taconnector->mst_downstream_port_present = ds_port_present;\n\tDRM_INFO(\"Downstream port present %d, type %d\\n\",\n\t\t\tds_port_present.fields.PORT_PRESENT, ds_port_present.fields.PORT_TYPE);\n\n\treturn true;\n}\n\nstatic int dm_dp_mst_get_modes(struct drm_connector *connector)\n{\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tint ret = 0;\n\n\tif (!aconnector)\n\t\treturn drm_add_edid_modes(connector, NULL);\n\n\tif (!aconnector->edid) {\n\t\tstruct edid *edid;\n\n\t\tedid = drm_dp_mst_get_edid(connector, &aconnector->mst_root->mst_mgr, aconnector->mst_output_port);\n\n\t\tif (!edid) {\n\t\t\tamdgpu_dm_set_mst_status(&aconnector->mst_status,\n\t\t\tMST_REMOTE_EDID, false);\n\n\t\t\tdrm_connector_update_edid_property(\n\t\t\t\t&aconnector->base,\n\t\t\t\tNULL);\n\n\t\t\tDRM_DEBUG_KMS(\"Can't get EDID of %s. Add default remote sink.\", connector->name);\n\t\t\tif (!aconnector->dc_sink) {\n\t\t\t\tstruct dc_sink *dc_sink;\n\t\t\t\tstruct dc_sink_init_data init_params = {\n\t\t\t\t\t.link = aconnector->dc_link,\n\t\t\t\t\t.sink_signal = SIGNAL_TYPE_DISPLAY_PORT_MST };\n\n\t\t\t\tdc_sink = dc_link_add_remote_sink(\n\t\t\t\t\taconnector->dc_link,\n\t\t\t\t\tNULL,\n\t\t\t\t\t0,\n\t\t\t\t\t&init_params);\n\n\t\t\t\tif (!dc_sink) {\n\t\t\t\t\tDRM_ERROR(\"Unable to add a remote sink\\n\");\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\tDC_LOG_MST(\"DM_MST: add remote sink 0x%p, %d remaining\\n\",\n\t\t\t\t\tdc_sink, aconnector->dc_link->sink_count);\n\n\t\t\t\tdc_sink->priv = aconnector;\n\t\t\t\taconnector->dc_sink = dc_sink;\n\t\t\t}\n\n\t\t\treturn ret;\n\t\t}\n\n\t\taconnector->edid = edid;\n\t\tamdgpu_dm_set_mst_status(&aconnector->mst_status,\n\t\t\tMST_REMOTE_EDID, true);\n\t}\n\n\tif (aconnector->dc_sink && aconnector->dc_sink->sink_signal == SIGNAL_TYPE_VIRTUAL) {\n\t\tdc_sink_release(aconnector->dc_sink);\n\t\taconnector->dc_sink = NULL;\n\t}\n\n\tif (!aconnector->dc_sink) {\n\t\tstruct dc_sink *dc_sink;\n\t\tstruct dc_sink_init_data init_params = {\n\t\t\t\t.link = aconnector->dc_link,\n\t\t\t\t.sink_signal = SIGNAL_TYPE_DISPLAY_PORT_MST };\n\t\tdc_sink = dc_link_add_remote_sink(\n\t\t\taconnector->dc_link,\n\t\t\t(uint8_t *)aconnector->edid,\n\t\t\t(aconnector->edid->extensions + 1) * EDID_LENGTH,\n\t\t\t&init_params);\n\n\t\tif (!dc_sink) {\n\t\t\tDRM_ERROR(\"Unable to add a remote sink\\n\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tDC_LOG_MST(\"DM_MST: add remote sink 0x%p, %d remaining\\n\",\n\t\t\tdc_sink, aconnector->dc_link->sink_count);\n\n\t\tdc_sink->priv = aconnector;\n\t\t \n\t\taconnector->dc_sink = dc_sink;\n\n\t\t \n\t\tif (aconnector->dc_sink && connector->state) {\n\t\t\tstruct drm_device *dev = connector->dev;\n\t\t\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\n\t\t\tif (adev->dm.hdcp_workqueue) {\n\t\t\t\tstruct hdcp_workqueue *hdcp_work = adev->dm.hdcp_workqueue;\n\t\t\t\tstruct hdcp_workqueue *hdcp_w =\n\t\t\t\t\t&hdcp_work[aconnector->dc_link->link_index];\n\n\t\t\t\tconnector->state->hdcp_content_type =\n\t\t\t\thdcp_w->hdcp_content_type[connector->index];\n\t\t\t\tconnector->state->content_protection =\n\t\t\t\thdcp_w->content_protection[connector->index];\n\t\t\t}\n\t\t}\n\n\t\tif (aconnector->dc_sink) {\n\t\t\tamdgpu_dm_update_freesync_caps(\n\t\t\t\t\tconnector, aconnector->edid);\n\n\t\t\tif (!validate_dsc_caps_on_connector(aconnector))\n\t\t\t\tmemset(&aconnector->dc_sink->dsc_caps,\n\t\t\t\t       0, sizeof(aconnector->dc_sink->dsc_caps));\n\n\t\t\tif (!retrieve_downstream_port_device(aconnector))\n\t\t\t\tmemset(&aconnector->mst_downstream_port_present,\n\t\t\t\t\t0, sizeof(aconnector->mst_downstream_port_present));\n\t\t}\n\t}\n\n\tdrm_connector_update_edid_property(\n\t\t\t\t\t&aconnector->base, aconnector->edid);\n\n\tret = drm_add_edid_modes(connector, aconnector->edid);\n\n\treturn ret;\n}\n\nstatic struct drm_encoder *\ndm_mst_atomic_best_encoder(struct drm_connector *connector,\n\t\t\t   struct drm_atomic_state *state)\n{\n\tstruct drm_connector_state *connector_state = drm_atomic_get_new_connector_state(state,\n\t\t\t\t\t\t\t\t\t\t\t connector);\n\tstruct drm_device *dev = connector->dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_crtc *acrtc = to_amdgpu_crtc(connector_state->crtc);\n\n\treturn &adev->dm.mst_encoders[acrtc->crtc_id].base;\n}\n\nstatic int\ndm_dp_mst_detect(struct drm_connector *connector,\n\t\t struct drm_modeset_acquire_ctx *ctx, bool force)\n{\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct amdgpu_dm_connector *master = aconnector->mst_root;\n\tstruct drm_dp_mst_port *port = aconnector->mst_output_port;\n\tint connection_status;\n\n\tif (drm_connector_is_unregistered(connector))\n\t\treturn connector_status_disconnected;\n\n\tconnection_status = drm_dp_mst_detect_port(connector, ctx, &master->mst_mgr,\n\t\t\t\t\t\t\taconnector->mst_output_port);\n\n\tif (port->pdt != DP_PEER_DEVICE_NONE && !port->dpcd_rev) {\n\t\tuint8_t dpcd_rev;\n\t\tint ret;\n\n\t\tret = drm_dp_dpcd_readb(&port->aux, DP_DP13_DPCD_REV, &dpcd_rev);\n\n\t\tif (ret == 1) {\n\t\t\tport->dpcd_rev = dpcd_rev;\n\n\t\t\t \n\t\t\tif (!dpcd_rev) {\n\t\t\t\tret = drm_dp_dpcd_readb(&port->aux, DP_DPCD_REV, &dpcd_rev);\n\n\t\t\t\tif (ret == 1)\n\t\t\t\t\tport->dpcd_rev = dpcd_rev;\n\t\t\t}\n\n\t\t\tif (!dpcd_rev)\n\t\t\t\tDRM_DEBUG_KMS(\"Can't decide DPCD revision number!\");\n\t\t}\n\n\t\t \n\t\tif (ret != 1)\n\t\t\tDRM_DEBUG_KMS(\"Can't access DPCD\");\n\t} else if (port->pdt == DP_PEER_DEVICE_NONE) {\n\t\tport->dpcd_rev = 0;\n\t}\n\n\t \n\tif (connection_status == connector_status_disconnected && aconnector->dc_sink) {\n\t\tif (aconnector->dc_link->sink_count)\n\t\t\tdc_link_remove_remote_sink(aconnector->dc_link, aconnector->dc_sink);\n\n\t\tDC_LOG_MST(\"DM_MST: remove remote sink 0x%p, %d remaining\\n\",\n\t\t\taconnector->dc_link, aconnector->dc_link->sink_count);\n\n\t\tdc_sink_release(aconnector->dc_sink);\n\t\taconnector->dc_sink = NULL;\n\t\taconnector->edid = NULL;\n\n\t\tamdgpu_dm_set_mst_status(&aconnector->mst_status,\n\t\t\tMST_REMOTE_EDID | MST_ALLOCATE_NEW_PAYLOAD | MST_CLEAR_ALLOCATED_PAYLOAD,\n\t\t\tfalse);\n\t}\n\n\treturn connection_status;\n}\n\nstatic int dm_dp_mst_atomic_check(struct drm_connector *connector,\n\t\t\t\t  struct drm_atomic_state *state)\n{\n\tstruct amdgpu_dm_connector *aconnector = to_amdgpu_dm_connector(connector);\n\tstruct drm_dp_mst_topology_mgr *mst_mgr = &aconnector->mst_root->mst_mgr;\n\tstruct drm_dp_mst_port *mst_port = aconnector->mst_output_port;\n\n\treturn drm_dp_atomic_release_time_slots(state, mst_mgr, mst_port);\n}\n\nstatic const struct drm_connector_helper_funcs dm_dp_mst_connector_helper_funcs = {\n\t.get_modes = dm_dp_mst_get_modes,\n\t.mode_valid = amdgpu_dm_connector_mode_valid,\n\t.atomic_best_encoder = dm_mst_atomic_best_encoder,\n\t.detect_ctx = dm_dp_mst_detect,\n\t.atomic_check = dm_dp_mst_atomic_check,\n};\n\nstatic void amdgpu_dm_encoder_destroy(struct drm_encoder *encoder)\n{\n\tdrm_encoder_cleanup(encoder);\n}\n\nstatic const struct drm_encoder_funcs amdgpu_dm_encoder_funcs = {\n\t.destroy = amdgpu_dm_encoder_destroy,\n};\n\nvoid\ndm_dp_create_fake_mst_encoders(struct amdgpu_device *adev)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tint i;\n\n\tfor (i = 0; i < adev->dm.display_indexes_num; i++) {\n\t\tstruct amdgpu_encoder *amdgpu_encoder = &adev->dm.mst_encoders[i];\n\t\tstruct drm_encoder *encoder = &amdgpu_encoder->base;\n\n\t\tencoder->possible_crtcs = amdgpu_dm_get_encoder_crtc_mask(adev);\n\n\t\tdrm_encoder_init(\n\t\t\tdev,\n\t\t\t&amdgpu_encoder->base,\n\t\t\t&amdgpu_dm_encoder_funcs,\n\t\t\tDRM_MODE_ENCODER_DPMST,\n\t\t\tNULL);\n\n\t\tdrm_encoder_helper_add(encoder, &amdgpu_dm_encoder_helper_funcs);\n\t}\n}\n\nstatic struct drm_connector *\ndm_dp_add_mst_connector(struct drm_dp_mst_topology_mgr *mgr,\n\t\t\tstruct drm_dp_mst_port *port,\n\t\t\tconst char *pathprop)\n{\n\tstruct amdgpu_dm_connector *master = container_of(mgr, struct amdgpu_dm_connector, mst_mgr);\n\tstruct drm_device *dev = master->base.dev;\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_connector *connector;\n\tint i;\n\n\taconnector = kzalloc(sizeof(*aconnector), GFP_KERNEL);\n\tif (!aconnector)\n\t\treturn NULL;\n\n\tconnector = &aconnector->base;\n\taconnector->mst_output_port = port;\n\taconnector->mst_root = master;\n\tamdgpu_dm_set_mst_status(&aconnector->mst_status,\n\t\t\tMST_PROBE, true);\n\n\tif (drm_connector_init(\n\t\tdev,\n\t\tconnector,\n\t\t&dm_dp_mst_connector_funcs,\n\t\tDRM_MODE_CONNECTOR_DisplayPort)) {\n\t\tkfree(aconnector);\n\t\treturn NULL;\n\t}\n\tdrm_connector_helper_add(connector, &dm_dp_mst_connector_helper_funcs);\n\n\tamdgpu_dm_connector_init_helper(\n\t\t&adev->dm,\n\t\taconnector,\n\t\tDRM_MODE_CONNECTOR_DisplayPort,\n\t\tmaster->dc_link,\n\t\tmaster->connector_id);\n\n\tfor (i = 0; i < adev->dm.display_indexes_num; i++) {\n\t\tdrm_connector_attach_encoder(&aconnector->base,\n\t\t\t\t\t     &adev->dm.mst_encoders[i].base);\n\t}\n\n\tconnector->max_bpc_property = master->base.max_bpc_property;\n\tif (connector->max_bpc_property)\n\t\tdrm_connector_attach_max_bpc_property(connector, 8, 16);\n\n\tconnector->vrr_capable_property = master->base.vrr_capable_property;\n\tif (connector->vrr_capable_property)\n\t\tdrm_connector_attach_vrr_capable_property(connector);\n\n\tdrm_object_attach_property(\n\t\t&connector->base,\n\t\tdev->mode_config.path_property,\n\t\t0);\n\tdrm_object_attach_property(\n\t\t&connector->base,\n\t\tdev->mode_config.tile_property,\n\t\t0);\n\n\tdrm_connector_set_path_property(connector, pathprop);\n\n\t \n\tamdgpu_dm_connector_funcs_reset(connector);\n\n\tdrm_dp_mst_get_port_malloc(port);\n\n\treturn connector;\n}\n\nvoid dm_handle_mst_sideband_msg_ready_event(\n\tstruct drm_dp_mst_topology_mgr *mgr,\n\tenum mst_msg_ready_type msg_rdy_type)\n{\n\tuint8_t esi[DP_PSR_ERROR_STATUS - DP_SINK_COUNT_ESI] = { 0 };\n\tuint8_t dret;\n\tbool new_irq_handled = false;\n\tint dpcd_addr;\n\tuint8_t dpcd_bytes_to_read;\n\tconst uint8_t max_process_count = 30;\n\tuint8_t process_count = 0;\n\tu8 retry;\n\tstruct amdgpu_dm_connector *aconnector =\n\t\t\tcontainer_of(mgr, struct amdgpu_dm_connector, mst_mgr);\n\n\n\tconst struct dc_link_status *link_status = dc_link_get_status(aconnector->dc_link);\n\n\tif (link_status->dpcd_caps->dpcd_rev.raw < 0x12) {\n\t\tdpcd_bytes_to_read = DP_LANE0_1_STATUS - DP_SINK_COUNT;\n\t\t \n\t\tdpcd_addr = DP_SINK_COUNT;\n\t} else {\n\t\tdpcd_bytes_to_read = DP_PSR_ERROR_STATUS - DP_SINK_COUNT_ESI;\n\t\t \n\t\tdpcd_addr = DP_SINK_COUNT_ESI;\n\t}\n\n\tmutex_lock(&aconnector->handle_mst_msg_ready);\n\n\twhile (process_count < max_process_count) {\n\t\tu8 ack[DP_PSR_ERROR_STATUS - DP_SINK_COUNT_ESI] = {};\n\n\t\tprocess_count++;\n\n\t\tdret = drm_dp_dpcd_read(\n\t\t\t&aconnector->dm_dp_aux.aux,\n\t\t\tdpcd_addr,\n\t\t\tesi,\n\t\t\tdpcd_bytes_to_read);\n\n\t\tif (dret != dpcd_bytes_to_read) {\n\t\t\tDRM_DEBUG_KMS(\"DPCD read and acked number is not as expected!\");\n\t\t\tbreak;\n\t\t}\n\n\t\tDRM_DEBUG_DRIVER(\"ESI %02x %02x %02x\\n\", esi[0], esi[1], esi[2]);\n\n\t\tswitch (msg_rdy_type) {\n\t\tcase DOWN_REP_MSG_RDY_EVENT:\n\t\t\t \n\t\t\tesi[1] &= DP_DOWN_REP_MSG_RDY;\n\t\t\tbreak;\n\t\tcase UP_REQ_MSG_RDY_EVENT:\n\t\t\t \n\t\t\tesi[1] &= DP_UP_REQ_MSG_RDY;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t \n\t\t\tesi[1] &= (DP_DOWN_REP_MSG_RDY | DP_UP_REQ_MSG_RDY);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!esi[1])\n\t\t\tbreak;\n\n\t\t \n\t\tif (aconnector->mst_mgr.mst_state)\n\t\t\tdrm_dp_mst_hpd_irq_handle_event(&aconnector->mst_mgr,\n\t\t\t\t\t\t esi,\n\t\t\t\t\t\t ack,\n\t\t\t\t\t\t &new_irq_handled);\n\n\t\tif (new_irq_handled) {\n\t\t\t \n\t\t\tfor (retry = 0; retry < 3; retry++) {\n\t\t\t\tssize_t wret;\n\n\t\t\t\twret = drm_dp_dpcd_writeb(&aconnector->dm_dp_aux.aux,\n\t\t\t\t\t\t\t  dpcd_addr + 1,\n\t\t\t\t\t\t\t  ack[1]);\n\t\t\t\tif (wret == 1)\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (retry == 3) {\n\t\t\t\tDRM_ERROR(\"Failed to ack MST event.\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tdrm_dp_mst_hpd_irq_send_new_request(&aconnector->mst_mgr);\n\n\t\t\tnew_irq_handled = false;\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&aconnector->handle_mst_msg_ready);\n\n\tif (process_count == max_process_count)\n\t\tDRM_DEBUG_DRIVER(\"Loop exceeded max iterations\\n\");\n}\n\nstatic void dm_handle_mst_down_rep_msg_ready(struct drm_dp_mst_topology_mgr *mgr)\n{\n\tdm_handle_mst_sideband_msg_ready_event(mgr, DOWN_REP_MSG_RDY_EVENT);\n}\n\nstatic const struct drm_dp_mst_topology_cbs dm_mst_cbs = {\n\t.add_connector = dm_dp_add_mst_connector,\n\t.poll_hpd_irq = dm_handle_mst_down_rep_msg_ready,\n};\n\nvoid amdgpu_dm_initialize_dp_connector(struct amdgpu_display_manager *dm,\n\t\t\t\t       struct amdgpu_dm_connector *aconnector,\n\t\t\t\t       int link_index)\n{\n\tstruct dc_link_settings max_link_enc_cap = {0};\n\n\taconnector->dm_dp_aux.aux.name =\n\t\tkasprintf(GFP_KERNEL, \"AMDGPU DM aux hw bus %d\",\n\t\t\t  link_index);\n\taconnector->dm_dp_aux.aux.transfer = dm_dp_aux_transfer;\n\taconnector->dm_dp_aux.aux.drm_dev = dm->ddev;\n\taconnector->dm_dp_aux.ddc_service = aconnector->dc_link->ddc;\n\n\tdrm_dp_aux_init(&aconnector->dm_dp_aux.aux);\n\tdrm_dp_cec_register_connector(&aconnector->dm_dp_aux.aux,\n\t\t\t\t      &aconnector->base);\n\n\tif (aconnector->base.connector_type == DRM_MODE_CONNECTOR_eDP)\n\t\treturn;\n\n\tdc_link_dp_get_max_link_enc_cap(aconnector->dc_link, &max_link_enc_cap);\n\taconnector->mst_mgr.cbs = &dm_mst_cbs;\n\tdrm_dp_mst_topology_mgr_init(&aconnector->mst_mgr, adev_to_drm(dm->adev),\n\t\t\t\t     &aconnector->dm_dp_aux.aux, 16, 4, aconnector->connector_id);\n\n\tdrm_connector_attach_dp_subconnector_property(&aconnector->base);\n}\n\nint dm_mst_get_pbn_divider(struct dc_link *link)\n{\n\tif (!link)\n\t\treturn 0;\n\n\treturn dc_link_bandwidth_kbps(link,\n\t\t\tdc_link_get_link_cap(link)) / (8 * 1000 * 54);\n}\n\nstruct dsc_mst_fairness_params {\n\tstruct dc_crtc_timing *timing;\n\tstruct dc_sink *sink;\n\tstruct dc_dsc_bw_range bw_range;\n\tbool compression_possible;\n\tstruct drm_dp_mst_port *port;\n\tenum dsc_clock_force_state clock_force_enable;\n\tuint32_t num_slices_h;\n\tuint32_t num_slices_v;\n\tuint32_t bpp_overwrite;\n\tstruct amdgpu_dm_connector *aconnector;\n};\n\nstatic uint16_t get_fec_overhead_multiplier(struct dc_link *dc_link)\n{\n\tu8 link_coding_cap;\n\tuint16_t fec_overhead_multiplier_x1000 = PBN_FEC_OVERHEAD_MULTIPLIER_8B_10B;\n\n\tlink_coding_cap = dc_link_dp_mst_decide_link_encoding_format(dc_link);\n\tif (link_coding_cap == DP_128b_132b_ENCODING)\n\t\tfec_overhead_multiplier_x1000 = PBN_FEC_OVERHEAD_MULTIPLIER_128B_132B;\n\n\treturn fec_overhead_multiplier_x1000;\n}\n\nstatic int kbps_to_peak_pbn(int kbps, uint16_t fec_overhead_multiplier_x1000)\n{\n\tu64 peak_kbps = kbps;\n\n\tpeak_kbps *= 1006;\n\tpeak_kbps *= fec_overhead_multiplier_x1000;\n\tpeak_kbps = div_u64(peak_kbps, 1000 * 1000);\n\treturn (int) DIV64_U64_ROUND_UP(peak_kbps * 64, (54 * 8 * 1000));\n}\n\nstatic void set_dsc_configs_from_fairness_vars(struct dsc_mst_fairness_params *params,\n\t\tstruct dsc_mst_fairness_vars *vars,\n\t\tint count,\n\t\tint k)\n{\n\tstruct drm_connector *drm_connector;\n\tint i;\n\tstruct dc_dsc_config_options dsc_options = {0};\n\n\tfor (i = 0; i < count; i++) {\n\t\tdrm_connector = &params[i].aconnector->base;\n\n\t\tdc_dsc_get_default_config_option(params[i].sink->ctx->dc, &dsc_options);\n\t\tdsc_options.max_target_bpp_limit_override_x16 = drm_connector->display_info.max_dsc_bpp * 16;\n\n\t\tmemset(&params[i].timing->dsc_cfg, 0, sizeof(params[i].timing->dsc_cfg));\n\t\tif (vars[i + k].dsc_enabled && dc_dsc_compute_config(\n\t\t\t\t\tparams[i].sink->ctx->dc->res_pool->dscs[0],\n\t\t\t\t\t&params[i].sink->dsc_caps.dsc_dec_caps,\n\t\t\t\t\t&dsc_options,\n\t\t\t\t\t0,\n\t\t\t\t\tparams[i].timing,\n\t\t\t\t\tdc_link_get_highest_encoding_format(params[i].aconnector->dc_link),\n\t\t\t\t\t&params[i].timing->dsc_cfg)) {\n\t\t\tparams[i].timing->flags.DSC = 1;\n\n\t\t\tif (params[i].bpp_overwrite)\n\t\t\t\tparams[i].timing->dsc_cfg.bits_per_pixel = params[i].bpp_overwrite;\n\t\t\telse\n\t\t\t\tparams[i].timing->dsc_cfg.bits_per_pixel = vars[i + k].bpp_x16;\n\n\t\t\tif (params[i].num_slices_h)\n\t\t\t\tparams[i].timing->dsc_cfg.num_slices_h = params[i].num_slices_h;\n\n\t\t\tif (params[i].num_slices_v)\n\t\t\t\tparams[i].timing->dsc_cfg.num_slices_v = params[i].num_slices_v;\n\t\t} else {\n\t\t\tparams[i].timing->flags.DSC = 0;\n\t\t}\n\t\tparams[i].timing->dsc_cfg.mst_pbn = vars[i + k].pbn;\n\t}\n\n\tfor (i = 0; i < count; i++) {\n\t\tif (params[i].sink) {\n\t\t\tif (params[i].sink->sink_signal != SIGNAL_TYPE_VIRTUAL &&\n\t\t\t\tparams[i].sink->sink_signal != SIGNAL_TYPE_NONE)\n\t\t\t\tDRM_DEBUG_DRIVER(\"%s i=%d dispname=%s\\n\", __func__, i,\n\t\t\t\t\tparams[i].sink->edid_caps.display_name);\n\t\t}\n\n\t\tDRM_DEBUG_DRIVER(\"dsc=%d bits_per_pixel=%d pbn=%d\\n\",\n\t\t\tparams[i].timing->flags.DSC,\n\t\t\tparams[i].timing->dsc_cfg.bits_per_pixel,\n\t\t\tvars[i + k].pbn);\n\t}\n}\n\nstatic int bpp_x16_from_pbn(struct dsc_mst_fairness_params param, int pbn)\n{\n\tstruct dc_dsc_config dsc_config;\n\tu64 kbps;\n\n\tstruct drm_connector *drm_connector = &param.aconnector->base;\n\tstruct dc_dsc_config_options dsc_options = {0};\n\n\tdc_dsc_get_default_config_option(param.sink->ctx->dc, &dsc_options);\n\tdsc_options.max_target_bpp_limit_override_x16 = drm_connector->display_info.max_dsc_bpp * 16;\n\n\tkbps = div_u64((u64)pbn * 994 * 8 * 54, 64);\n\tdc_dsc_compute_config(\n\t\t\tparam.sink->ctx->dc->res_pool->dscs[0],\n\t\t\t&param.sink->dsc_caps.dsc_dec_caps,\n\t\t\t&dsc_options,\n\t\t\t(int) kbps, param.timing,\n\t\t\tdc_link_get_highest_encoding_format(param.aconnector->dc_link),\n\t\t\t&dsc_config);\n\n\treturn dsc_config.bits_per_pixel;\n}\n\nstatic int increase_dsc_bpp(struct drm_atomic_state *state,\n\t\t\t    struct drm_dp_mst_topology_state *mst_state,\n\t\t\t    struct dc_link *dc_link,\n\t\t\t    struct dsc_mst_fairness_params *params,\n\t\t\t    struct dsc_mst_fairness_vars *vars,\n\t\t\t    int count,\n\t\t\t    int k)\n{\n\tint i;\n\tbool bpp_increased[MAX_PIPES];\n\tint initial_slack[MAX_PIPES];\n\tint min_initial_slack;\n\tint next_index;\n\tint remaining_to_increase = 0;\n\tint link_timeslots_used;\n\tint fair_pbn_alloc;\n\tint ret = 0;\n\tuint16_t fec_overhead_multiplier_x1000 = get_fec_overhead_multiplier(dc_link);\n\n\tfor (i = 0; i < count; i++) {\n\t\tif (vars[i + k].dsc_enabled) {\n\t\t\tinitial_slack[i] =\n\t\t\tkbps_to_peak_pbn(params[i].bw_range.max_kbps, fec_overhead_multiplier_x1000) - vars[i + k].pbn;\n\t\t\tbpp_increased[i] = false;\n\t\t\tremaining_to_increase += 1;\n\t\t} else {\n\t\t\tinitial_slack[i] = 0;\n\t\t\tbpp_increased[i] = true;\n\t\t}\n\t}\n\n\twhile (remaining_to_increase) {\n\t\tnext_index = -1;\n\t\tmin_initial_slack = -1;\n\t\tfor (i = 0; i < count; i++) {\n\t\t\tif (!bpp_increased[i]) {\n\t\t\t\tif (min_initial_slack == -1 || min_initial_slack > initial_slack[i]) {\n\t\t\t\t\tmin_initial_slack = initial_slack[i];\n\t\t\t\t\tnext_index = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (next_index == -1)\n\t\t\tbreak;\n\n\t\tlink_timeslots_used = 0;\n\n\t\tfor (i = 0; i < count; i++)\n\t\t\tlink_timeslots_used += DIV_ROUND_UP(vars[i + k].pbn, mst_state->pbn_div);\n\n\t\tfair_pbn_alloc =\n\t\t\t(63 - link_timeslots_used) / remaining_to_increase * mst_state->pbn_div;\n\n\t\tif (initial_slack[next_index] > fair_pbn_alloc) {\n\t\t\tvars[next_index].pbn += fair_pbn_alloc;\n\t\t\tret = drm_dp_atomic_find_time_slots(state,\n\t\t\t\t\t\t\t    params[next_index].port->mgr,\n\t\t\t\t\t\t\t    params[next_index].port,\n\t\t\t\t\t\t\t    vars[next_index].pbn);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tret = drm_dp_mst_atomic_check(state);\n\t\t\tif (ret == 0) {\n\t\t\t\tvars[next_index].bpp_x16 = bpp_x16_from_pbn(params[next_index], vars[next_index].pbn);\n\t\t\t} else {\n\t\t\t\tvars[next_index].pbn -= fair_pbn_alloc;\n\t\t\t\tret = drm_dp_atomic_find_time_slots(state,\n\t\t\t\t\t\t\t\t    params[next_index].port->mgr,\n\t\t\t\t\t\t\t\t    params[next_index].port,\n\t\t\t\t\t\t\t\t    vars[next_index].pbn);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t} else {\n\t\t\tvars[next_index].pbn += initial_slack[next_index];\n\t\t\tret = drm_dp_atomic_find_time_slots(state,\n\t\t\t\t\t\t\t    params[next_index].port->mgr,\n\t\t\t\t\t\t\t    params[next_index].port,\n\t\t\t\t\t\t\t    vars[next_index].pbn);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tret = drm_dp_mst_atomic_check(state);\n\t\t\tif (ret == 0) {\n\t\t\t\tvars[next_index].bpp_x16 = params[next_index].bw_range.max_target_bpp_x16;\n\t\t\t} else {\n\t\t\t\tvars[next_index].pbn -= initial_slack[next_index];\n\t\t\t\tret = drm_dp_atomic_find_time_slots(state,\n\t\t\t\t\t\t\t\t    params[next_index].port->mgr,\n\t\t\t\t\t\t\t\t    params[next_index].port,\n\t\t\t\t\t\t\t\t    vars[next_index].pbn);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\tbpp_increased[next_index] = true;\n\t\tremaining_to_increase--;\n\t}\n\treturn 0;\n}\n\nstatic int try_disable_dsc(struct drm_atomic_state *state,\n\t\t\t   struct dc_link *dc_link,\n\t\t\t   struct dsc_mst_fairness_params *params,\n\t\t\t   struct dsc_mst_fairness_vars *vars,\n\t\t\t   int count,\n\t\t\t   int k)\n{\n\tint i;\n\tbool tried[MAX_PIPES];\n\tint kbps_increase[MAX_PIPES];\n\tint max_kbps_increase;\n\tint next_index;\n\tint remaining_to_try = 0;\n\tint ret;\n\tuint16_t fec_overhead_multiplier_x1000 = get_fec_overhead_multiplier(dc_link);\n\n\tfor (i = 0; i < count; i++) {\n\t\tif (vars[i + k].dsc_enabled\n\t\t\t\t&& vars[i + k].bpp_x16 == params[i].bw_range.max_target_bpp_x16\n\t\t\t\t&& params[i].clock_force_enable == DSC_CLK_FORCE_DEFAULT) {\n\t\t\tkbps_increase[i] = params[i].bw_range.stream_kbps - params[i].bw_range.max_kbps;\n\t\t\ttried[i] = false;\n\t\t\tremaining_to_try += 1;\n\t\t} else {\n\t\t\tkbps_increase[i] = 0;\n\t\t\ttried[i] = true;\n\t\t}\n\t}\n\n\twhile (remaining_to_try) {\n\t\tnext_index = -1;\n\t\tmax_kbps_increase = -1;\n\t\tfor (i = 0; i < count; i++) {\n\t\t\tif (!tried[i]) {\n\t\t\t\tif (max_kbps_increase == -1 || max_kbps_increase < kbps_increase[i]) {\n\t\t\t\t\tmax_kbps_increase = kbps_increase[i];\n\t\t\t\t\tnext_index = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (next_index == -1)\n\t\t\tbreak;\n\n\t\tvars[next_index].pbn = kbps_to_peak_pbn(params[next_index].bw_range.stream_kbps, fec_overhead_multiplier_x1000);\n\t\tret = drm_dp_atomic_find_time_slots(state,\n\t\t\t\t\t\t    params[next_index].port->mgr,\n\t\t\t\t\t\t    params[next_index].port,\n\t\t\t\t\t\t    vars[next_index].pbn);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = drm_dp_mst_atomic_check(state);\n\t\tif (ret == 0) {\n\t\t\tvars[next_index].dsc_enabled = false;\n\t\t\tvars[next_index].bpp_x16 = 0;\n\t\t} else {\n\t\t\tvars[next_index].pbn = kbps_to_peak_pbn(params[next_index].bw_range.max_kbps, fec_overhead_multiplier_x1000);\n\t\t\tret = drm_dp_atomic_find_time_slots(state,\n\t\t\t\t\t\t\t    params[next_index].port->mgr,\n\t\t\t\t\t\t\t    params[next_index].port,\n\t\t\t\t\t\t\t    vars[next_index].pbn);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\ttried[next_index] = true;\n\t\tremaining_to_try--;\n\t}\n\treturn 0;\n}\n\nstatic int compute_mst_dsc_configs_for_link(struct drm_atomic_state *state,\n\t\t\t\t\t    struct dc_state *dc_state,\n\t\t\t\t\t    struct dc_link *dc_link,\n\t\t\t\t\t    struct dsc_mst_fairness_vars *vars,\n\t\t\t\t\t    struct drm_dp_mst_topology_mgr *mgr,\n\t\t\t\t\t    int *link_vars_start_index)\n{\n\tstruct dc_stream_state *stream;\n\tstruct dsc_mst_fairness_params params[MAX_PIPES];\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_dp_mst_topology_state *mst_state = drm_atomic_get_mst_topology_state(state, mgr);\n\tint count = 0;\n\tint i, k, ret;\n\tbool debugfs_overwrite = false;\n\tuint16_t fec_overhead_multiplier_x1000 = get_fec_overhead_multiplier(dc_link);\n\n\tmemset(params, 0, sizeof(params));\n\n\tif (IS_ERR(mst_state))\n\t\treturn PTR_ERR(mst_state);\n\n\t \n\tfor (i = 0; i < dc_state->stream_count; i++) {\n\t\tstruct dc_dsc_policy dsc_policy = {0};\n\n\t\tstream = dc_state->streams[i];\n\n\t\tif (stream->link != dc_link)\n\t\t\tcontinue;\n\n\t\taconnector = (struct amdgpu_dm_connector *)stream->dm_stream_context;\n\t\tif (!aconnector)\n\t\t\tcontinue;\n\n\t\tif (!aconnector->mst_output_port)\n\t\t\tcontinue;\n\n\t\tstream->timing.flags.DSC = 0;\n\n\t\tparams[count].timing = &stream->timing;\n\t\tparams[count].sink = stream->sink;\n\t\tparams[count].aconnector = aconnector;\n\t\tparams[count].port = aconnector->mst_output_port;\n\t\tparams[count].clock_force_enable = aconnector->dsc_settings.dsc_force_enable;\n\t\tif (params[count].clock_force_enable == DSC_CLK_FORCE_ENABLE)\n\t\t\tdebugfs_overwrite = true;\n\t\tparams[count].num_slices_h = aconnector->dsc_settings.dsc_num_slices_h;\n\t\tparams[count].num_slices_v = aconnector->dsc_settings.dsc_num_slices_v;\n\t\tparams[count].bpp_overwrite = aconnector->dsc_settings.dsc_bits_per_pixel;\n\t\tparams[count].compression_possible = stream->sink->dsc_caps.dsc_dec_caps.is_dsc_supported;\n\t\tdc_dsc_get_policy_for_timing(params[count].timing, 0, &dsc_policy);\n\t\tif (!dc_dsc_compute_bandwidth_range(\n\t\t\t\tstream->sink->ctx->dc->res_pool->dscs[0],\n\t\t\t\tstream->sink->ctx->dc->debug.dsc_min_slice_height_override,\n\t\t\t\tdsc_policy.min_target_bpp * 16,\n\t\t\t\tdsc_policy.max_target_bpp * 16,\n\t\t\t\t&stream->sink->dsc_caps.dsc_dec_caps,\n\t\t\t\t&stream->timing,\n\t\t\t\tdc_link_get_highest_encoding_format(dc_link),\n\t\t\t\t&params[count].bw_range))\n\t\t\tparams[count].bw_range.stream_kbps = dc_bandwidth_in_kbps_from_timing(&stream->timing,\n\t\t\t\t\tdc_link_get_highest_encoding_format(dc_link));\n\n\t\tcount++;\n\t}\n\n\tif (count == 0) {\n\t\tASSERT(0);\n\t\treturn 0;\n\t}\n\n\t \n\tk = *link_vars_start_index;\n\t \n\t*link_vars_start_index += count;\n\n\t \n\tfor (i = 0; i < count; i++) {\n\t\tvars[i + k].aconnector = params[i].aconnector;\n\t\tvars[i + k].pbn = kbps_to_peak_pbn(params[i].bw_range.stream_kbps, fec_overhead_multiplier_x1000);\n\t\tvars[i + k].dsc_enabled = false;\n\t\tvars[i + k].bpp_x16 = 0;\n\t\tret = drm_dp_atomic_find_time_slots(state, params[i].port->mgr, params[i].port,\n\t\t\t\t\t\t    vars[i + k].pbn);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\tret = drm_dp_mst_atomic_check(state);\n\tif (ret == 0 && !debugfs_overwrite) {\n\t\tset_dsc_configs_from_fairness_vars(params, vars, count, k);\n\t\treturn 0;\n\t} else if (ret != -ENOSPC) {\n\t\treturn ret;\n\t}\n\n\t \n\tfor (i = 0; i < count; i++) {\n\t\tif (params[i].compression_possible && params[i].clock_force_enable != DSC_CLK_FORCE_DISABLE) {\n\t\t\tvars[i + k].pbn = kbps_to_peak_pbn(params[i].bw_range.min_kbps, fec_overhead_multiplier_x1000);\n\t\t\tvars[i + k].dsc_enabled = true;\n\t\t\tvars[i + k].bpp_x16 = params[i].bw_range.min_target_bpp_x16;\n\t\t\tret = drm_dp_atomic_find_time_slots(state, params[i].port->mgr,\n\t\t\t\t\t\t\t    params[i].port, vars[i + k].pbn);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t} else {\n\t\t\tvars[i + k].pbn = kbps_to_peak_pbn(params[i].bw_range.stream_kbps, fec_overhead_multiplier_x1000);\n\t\t\tvars[i + k].dsc_enabled = false;\n\t\t\tvars[i + k].bpp_x16 = 0;\n\t\t\tret = drm_dp_atomic_find_time_slots(state, params[i].port->mgr,\n\t\t\t\t\t\t\t    params[i].port, vars[i + k].pbn);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\tret = drm_dp_mst_atomic_check(state);\n\tif (ret != 0)\n\t\treturn ret;\n\n\t \n\tret = increase_dsc_bpp(state, mst_state, dc_link, params, vars, count, k);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = try_disable_dsc(state, dc_link, params, vars, count, k);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tset_dsc_configs_from_fairness_vars(params, vars, count, k);\n\n\treturn 0;\n}\n\nstatic bool is_dsc_need_re_compute(\n\tstruct drm_atomic_state *state,\n\tstruct dc_state *dc_state,\n\tstruct dc_link *dc_link)\n{\n\tint i, j;\n\tbool is_dsc_need_re_compute = false;\n\tstruct amdgpu_dm_connector *stream_on_link[MAX_PIPES];\n\tint new_stream_on_link_num = 0;\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct dc_stream_state *stream;\n\tconst struct dc *dc = dc_link->dc;\n\n\t \n\tif (dc_link->type != dc_connection_mst_branch)\n\t\treturn false;\n\n\tif (!(dc_link->dpcd_caps.dsc_caps.dsc_basic_caps.fields.dsc_support.DSC_SUPPORT ||\n\t\tdc_link->dpcd_caps.dsc_caps.dsc_basic_caps.fields.dsc_support.DSC_PASSTHROUGH_SUPPORT))\n\t\treturn false;\n\n\tfor (i = 0; i < MAX_PIPES; i++)\n\t\tstream_on_link[i] = NULL;\n\n\t \n\tfor (i = 0; i < dc_state->stream_count; i++) {\n\t\tstruct drm_crtc_state *new_crtc_state;\n\t\tstruct drm_connector_state *new_conn_state;\n\n\t\tstream = dc_state->streams[i];\n\t\tif (!stream)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (stream->link != dc_link)\n\t\t\tcontinue;\n\n\t\taconnector = (struct amdgpu_dm_connector *) stream->dm_stream_context;\n\t\tif (!aconnector)\n\t\t\tcontinue;\n\n\t\tstream_on_link[new_stream_on_link_num] = aconnector;\n\t\tnew_stream_on_link_num++;\n\n\t\tnew_conn_state = drm_atomic_get_new_connector_state(state, &aconnector->base);\n\t\tif (!new_conn_state)\n\t\t\tcontinue;\n\n\t\tif (IS_ERR(new_conn_state))\n\t\t\tcontinue;\n\n\t\tif (!new_conn_state->crtc)\n\t\t\tcontinue;\n\n\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(state, new_conn_state->crtc);\n\t\tif (!new_crtc_state)\n\t\t\tcontinue;\n\n\t\tif (IS_ERR(new_crtc_state))\n\t\t\tcontinue;\n\n\t\tif (new_crtc_state->enable && new_crtc_state->active) {\n\t\t\tif (new_crtc_state->mode_changed || new_crtc_state->active_changed ||\n\t\t\t\tnew_crtc_state->connectors_changed)\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < dc->current_state->stream_count; i++) {\n\t\tstream = dc->current_state->streams[i];\n\t\t \n\t\tif (stream->link != dc_link)\n\t\t\tcontinue;\n\n\t\taconnector = (struct amdgpu_dm_connector *)stream->dm_stream_context;\n\t\tif (!aconnector)\n\t\t\tcontinue;\n\n\t\tfor (j = 0; j < new_stream_on_link_num; j++) {\n\t\t\tif (stream_on_link[j]) {\n\t\t\t\tif (aconnector == stream_on_link[j])\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (j == new_stream_on_link_num) {\n\t\t\t \n\t\t\tis_dsc_need_re_compute = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn is_dsc_need_re_compute;\n}\n\nint compute_mst_dsc_configs_for_state(struct drm_atomic_state *state,\n\t\t\t\t      struct dc_state *dc_state,\n\t\t\t\t      struct dsc_mst_fairness_vars *vars)\n{\n\tint i, j;\n\tstruct dc_stream_state *stream;\n\tbool computed_streams[MAX_PIPES];\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_dp_mst_topology_mgr *mst_mgr;\n\tstruct resource_pool *res_pool;\n\tint link_vars_start_index = 0;\n\tint ret = 0;\n\n\tfor (i = 0; i < dc_state->stream_count; i++)\n\t\tcomputed_streams[i] = false;\n\n\tfor (i = 0; i < dc_state->stream_count; i++) {\n\t\tstream = dc_state->streams[i];\n\t\tres_pool = stream->ctx->dc->res_pool;\n\n\t\tif (stream->signal != SIGNAL_TYPE_DISPLAY_PORT_MST)\n\t\t\tcontinue;\n\n\t\taconnector = (struct amdgpu_dm_connector *)stream->dm_stream_context;\n\n\t\tif (!aconnector || !aconnector->dc_sink || !aconnector->mst_output_port)\n\t\t\tcontinue;\n\n\t\tif (!aconnector->dc_sink->dsc_caps.dsc_dec_caps.is_dsc_supported)\n\t\t\tcontinue;\n\n\t\tif (computed_streams[i])\n\t\t\tcontinue;\n\n\t\tif (res_pool->funcs->remove_stream_from_ctx &&\n\t\t    res_pool->funcs->remove_stream_from_ctx(stream->ctx->dc, dc_state, stream) != DC_OK)\n\t\t\treturn -EINVAL;\n\n\t\tif (!is_dsc_need_re_compute(state, dc_state, stream->link))\n\t\t\tcontinue;\n\n\t\tmst_mgr = aconnector->mst_output_port->mgr;\n\t\tret = compute_mst_dsc_configs_for_link(state, dc_state, stream->link, vars, mst_mgr,\n\t\t\t\t\t\t       &link_vars_start_index);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\n\t\tfor (j = 0; j < dc_state->stream_count; j++) {\n\t\t\tif (dc_state->streams[j]->link == stream->link)\n\t\t\t\tcomputed_streams[j] = true;\n\t\t}\n\t}\n\n\tfor (i = 0; i < dc_state->stream_count; i++) {\n\t\tstream = dc_state->streams[i];\n\n\t\tif (stream->timing.flags.DSC == 1)\n\t\t\tif (dc_stream_add_dsc_to_resource(stream->ctx->dc, dc_state, stream) != DC_OK)\n\t\t\t\treturn -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int pre_compute_mst_dsc_configs_for_state(struct drm_atomic_state *state,\n\t\t\t\t\t\t struct dc_state *dc_state,\n\t\t\t\t\t\t struct dsc_mst_fairness_vars *vars)\n{\n\tint i, j;\n\tstruct dc_stream_state *stream;\n\tbool computed_streams[MAX_PIPES];\n\tstruct amdgpu_dm_connector *aconnector;\n\tstruct drm_dp_mst_topology_mgr *mst_mgr;\n\tint link_vars_start_index = 0;\n\tint ret = 0;\n\n\tfor (i = 0; i < dc_state->stream_count; i++)\n\t\tcomputed_streams[i] = false;\n\n\tfor (i = 0; i < dc_state->stream_count; i++) {\n\t\tstream = dc_state->streams[i];\n\n\t\tif (stream->signal != SIGNAL_TYPE_DISPLAY_PORT_MST)\n\t\t\tcontinue;\n\n\t\taconnector = (struct amdgpu_dm_connector *)stream->dm_stream_context;\n\n\t\tif (!aconnector || !aconnector->dc_sink || !aconnector->mst_output_port)\n\t\t\tcontinue;\n\n\t\tif (!aconnector->dc_sink->dsc_caps.dsc_dec_caps.is_dsc_supported)\n\t\t\tcontinue;\n\n\t\tif (computed_streams[i])\n\t\t\tcontinue;\n\n\t\tif (!is_dsc_need_re_compute(state, dc_state, stream->link))\n\t\t\tcontinue;\n\n\t\tmst_mgr = aconnector->mst_output_port->mgr;\n\t\tret = compute_mst_dsc_configs_for_link(state, dc_state, stream->link, vars, mst_mgr,\n\t\t\t\t\t\t       &link_vars_start_index);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\n\t\tfor (j = 0; j < dc_state->stream_count; j++) {\n\t\t\tif (dc_state->streams[j]->link == stream->link)\n\t\t\t\tcomputed_streams[j] = true;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int find_crtc_index_in_state_by_stream(struct drm_atomic_state *state,\n\t\t\t\t\t      struct dc_stream_state *stream)\n{\n\tint i;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *new_state, *old_state;\n\n\tfor_each_oldnew_crtc_in_state(state, crtc, old_state, new_state, i) {\n\t\tstruct dm_crtc_state *dm_state = to_dm_crtc_state(new_state);\n\n\t\tif (dm_state->stream == stream)\n\t\t\treturn i;\n\t}\n\treturn -1;\n}\n\nstatic bool is_link_to_dschub(struct dc_link *dc_link)\n{\n\tunion dpcd_dsc_basic_capabilities *dsc_caps =\n\t\t\t&dc_link->dpcd_caps.dsc_caps.dsc_basic_caps;\n\n\t \n\tif (dc_link->type != dc_connection_mst_branch)\n\t\treturn false;\n\n\tif (!(dsc_caps->fields.dsc_support.DSC_SUPPORT ||\n\t      dsc_caps->fields.dsc_support.DSC_PASSTHROUGH_SUPPORT))\n\t\treturn false;\n\treturn true;\n}\n\nstatic bool is_dsc_precompute_needed(struct drm_atomic_state *state)\n{\n\tint i;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\tbool ret = false;\n\n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\tstruct dm_crtc_state *dm_crtc_state = to_dm_crtc_state(new_crtc_state);\n\n\t\tif (!amdgpu_dm_find_first_crtc_matching_connector(state, crtc)) {\n\t\t\tret =  false;\n\t\t\tbreak;\n\t\t}\n\t\tif (dm_crtc_state->stream && dm_crtc_state->stream->link)\n\t\t\tif (is_link_to_dschub(dm_crtc_state->stream->link))\n\t\t\t\tret = true;\n\t}\n\treturn ret;\n}\n\nint pre_validate_dsc(struct drm_atomic_state *state,\n\t\t     struct dm_atomic_state **dm_state_ptr,\n\t\t     struct dsc_mst_fairness_vars *vars)\n{\n\tint i;\n\tstruct dm_atomic_state *dm_state;\n\tstruct dc_state *local_dc_state = NULL;\n\tint ret = 0;\n\n\tif (!is_dsc_precompute_needed(state)) {\n\t\tDRM_INFO_ONCE(\"DSC precompute is not needed.\\n\");\n\t\treturn 0;\n\t}\n\tret = dm_atomic_get_state(state, dm_state_ptr);\n\tif (ret != 0) {\n\t\tDRM_INFO_ONCE(\"dm_atomic_get_state() failed\\n\");\n\t\treturn ret;\n\t}\n\tdm_state = *dm_state_ptr;\n\n\t \n\n\tlocal_dc_state = kmemdup(dm_state->context, sizeof(struct dc_state), GFP_KERNEL);\n\tif (!local_dc_state)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < local_dc_state->stream_count; i++) {\n\t\tstruct dc_stream_state *stream = dm_state->context->streams[i];\n\t\tint ind = find_crtc_index_in_state_by_stream(state, stream);\n\n\t\tif (ind >= 0) {\n\t\t\tstruct amdgpu_dm_connector *aconnector;\n\t\t\tstruct drm_connector_state *drm_new_conn_state;\n\t\t\tstruct dm_connector_state *dm_new_conn_state;\n\t\t\tstruct dm_crtc_state *dm_old_crtc_state;\n\n\t\t\taconnector =\n\t\t\t\tamdgpu_dm_find_first_crtc_matching_connector(state,\n\t\t\t\t\t\t\t\t\t     state->crtcs[ind].ptr);\n\t\t\tdrm_new_conn_state =\n\t\t\t\tdrm_atomic_get_new_connector_state(state,\n\t\t\t\t\t\t\t\t   &aconnector->base);\n\t\t\tdm_new_conn_state = to_dm_connector_state(drm_new_conn_state);\n\t\t\tdm_old_crtc_state = to_dm_crtc_state(state->crtcs[ind].old_state);\n\n\t\t\tlocal_dc_state->streams[i] =\n\t\t\t\tcreate_validate_stream_for_sink(aconnector,\n\t\t\t\t\t\t\t\t&state->crtcs[ind].new_state->mode,\n\t\t\t\t\t\t\t\tdm_new_conn_state,\n\t\t\t\t\t\t\t\tdm_old_crtc_state->stream);\n\t\t\tif (local_dc_state->streams[i] == NULL) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ret != 0)\n\t\tgoto clean_exit;\n\n\tret = pre_compute_mst_dsc_configs_for_state(state, local_dc_state, vars);\n\tif (ret != 0) {\n\t\tDRM_INFO_ONCE(\"pre_compute_mst_dsc_configs_for_state() failed\\n\");\n\t\tret = -EINVAL;\n\t\tgoto clean_exit;\n\t}\n\n\t \n\tfor (i = 0; i < local_dc_state->stream_count; i++) {\n\t\tstruct dc_stream_state *stream = dm_state->context->streams[i];\n\n\t\tif (local_dc_state->streams[i] &&\n\t\t    dc_is_timing_changed(stream, local_dc_state->streams[i])) {\n\t\t\tDRM_INFO_ONCE(\"crtc[%d] needs mode_changed\\n\", i);\n\t\t} else {\n\t\t\tint ind = find_crtc_index_in_state_by_stream(state, stream);\n\n\t\t\tif (ind >= 0)\n\t\t\t\tstate->crtcs[ind].new_state->mode_changed = 0;\n\t\t}\n\t}\nclean_exit:\n\tfor (i = 0; i < local_dc_state->stream_count; i++) {\n\t\tstruct dc_stream_state *stream = dm_state->context->streams[i];\n\n\t\tif (local_dc_state->streams[i] != stream)\n\t\t\tdc_stream_release(local_dc_state->streams[i]);\n\t}\n\n\tkfree(local_dc_state);\n\n\treturn ret;\n}\n\nstatic unsigned int kbps_from_pbn(unsigned int pbn)\n{\n\tunsigned int kbps = pbn;\n\n\tkbps *= (1000000 / PEAK_FACTOR_X1000);\n\tkbps *= 8;\n\tkbps *= 54;\n\tkbps /= 64;\n\n\treturn kbps;\n}\n\nstatic bool is_dsc_common_config_possible(struct dc_stream_state *stream,\n\t\t\t\t\t  struct dc_dsc_bw_range *bw_range)\n{\n\tstruct dc_dsc_policy dsc_policy = {0};\n\n\tdc_dsc_get_policy_for_timing(&stream->timing, 0, &dsc_policy);\n\tdc_dsc_compute_bandwidth_range(stream->sink->ctx->dc->res_pool->dscs[0],\n\t\t\t\t       stream->sink->ctx->dc->debug.dsc_min_slice_height_override,\n\t\t\t\t       dsc_policy.min_target_bpp * 16,\n\t\t\t\t       dsc_policy.max_target_bpp * 16,\n\t\t\t\t       &stream->sink->dsc_caps.dsc_dec_caps,\n\t\t\t\t       &stream->timing, dc_link_get_highest_encoding_format(stream->link), bw_range);\n\n\treturn bw_range->max_target_bpp_x16 && bw_range->min_target_bpp_x16;\n}\n\nenum dc_status dm_dp_mst_is_port_support_mode(\n\tstruct amdgpu_dm_connector *aconnector,\n\tstruct dc_stream_state *stream)\n{\n\tint bpp, pbn, branch_max_throughput_mps = 0;\n\tstruct dc_link_settings cur_link_settings;\n\tunsigned int end_to_end_bw_in_kbps = 0;\n\tunsigned int upper_link_bw_in_kbps = 0, down_link_bw_in_kbps = 0;\n\tunsigned int max_compressed_bw_in_kbps = 0;\n\tstruct dc_dsc_bw_range bw_range = {0};\n\tuint16_t full_pbn = aconnector->mst_output_port->full_pbn;\n\n\t \n\tif (is_dsc_common_config_possible(stream, &bw_range) &&\n\t   (aconnector->mst_output_port->passthrough_aux ||\n\t    aconnector->dsc_aux == &aconnector->mst_output_port->aux)) {\n\t\tcur_link_settings = stream->link->verified_link_cap;\n\n\t\tupper_link_bw_in_kbps = dc_link_bandwidth_kbps(aconnector->dc_link,\n\t\t\t\t\t\t\t       &cur_link_settings);\n\t\tdown_link_bw_in_kbps = kbps_from_pbn(full_pbn);\n\n\t\t \n\t\tend_to_end_bw_in_kbps = min(upper_link_bw_in_kbps,\n\t\t\t\t\t    down_link_bw_in_kbps);\n\n\t\t \n\t\tmax_compressed_bw_in_kbps = bw_range.min_kbps;\n\n\t\tif (end_to_end_bw_in_kbps < max_compressed_bw_in_kbps) {\n\t\t\tDRM_DEBUG_DRIVER(\"Mode does not fit into DSC pass-through bandwidth validation\\n\");\n\t\t\treturn DC_FAIL_BANDWIDTH_VALIDATE;\n\t\t}\n\t} else {\n\t\t \n\t\tbpp = convert_dc_color_depth_into_bpc(stream->timing.display_color_depth) * 3;\n\t\tpbn = drm_dp_calc_pbn_mode(stream->timing.pix_clk_100hz / 10, bpp << 4);\n\t\tif (pbn > full_pbn)\n\t\t\treturn DC_FAIL_BANDWIDTH_VALIDATE;\n\t}\n\n\t \n\tswitch (stream->timing.pixel_encoding) {\n\tcase PIXEL_ENCODING_RGB:\n\tcase PIXEL_ENCODING_YCBCR444:\n\t\tbranch_max_throughput_mps =\n\t\t\taconnector->dc_sink->dsc_caps.dsc_dec_caps.branch_overall_throughput_0_mps;\n\t\tbreak;\n\tcase PIXEL_ENCODING_YCBCR422:\n\tcase PIXEL_ENCODING_YCBCR420:\n\t\tbranch_max_throughput_mps =\n\t\t\taconnector->dc_sink->dsc_caps.dsc_dec_caps.branch_overall_throughput_1_mps;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (branch_max_throughput_mps != 0 &&\n\t\t((stream->timing.pix_clk_100hz / 10) >  branch_max_throughput_mps * 1000))\n\t\treturn DC_FAIL_BANDWIDTH_VALIDATE;\n\n\treturn DC_OK;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}