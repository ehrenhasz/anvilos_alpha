{
  "module_name": "amdgpu_dm_irq.c",
  "hash_id": "eec9bd1e26fcb964725be739cc04f90c84c3bd7ffcf1665528b0c5bffc09f8a9",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_irq.c",
  "human_readable_source": " \n\n#include \"dm_services_types.h\"\n#include \"dc.h\"\n\n#include \"amdgpu.h\"\n#include \"amdgpu_dm.h\"\n#include \"amdgpu_dm_irq.h\"\n\n \n\n \n\n \nstruct amdgpu_dm_irq_handler_data {\n\tstruct list_head list;\n\tinterrupt_handler handler;\n\tvoid *handler_arg;\n\n\tstruct amdgpu_display_manager *dm;\n\t \n\tenum dc_irq_source irq_source;\n\tstruct work_struct work;\n};\n\n#define DM_IRQ_TABLE_LOCK(adev, flags) \\\n\tspin_lock_irqsave(&adev->dm.irq_handler_list_table_lock, flags)\n\n#define DM_IRQ_TABLE_UNLOCK(adev, flags) \\\n\tspin_unlock_irqrestore(&adev->dm.irq_handler_list_table_lock, flags)\n\n \n\nstatic void init_handler_common_data(struct amdgpu_dm_irq_handler_data *hcd,\n\t\t\t\t     void (*ih)(void *),\n\t\t\t\t     void *args,\n\t\t\t\t     struct amdgpu_display_manager *dm)\n{\n\thcd->handler = ih;\n\thcd->handler_arg = args;\n\thcd->dm = dm;\n}\n\n \nstatic void dm_irq_work_func(struct work_struct *work)\n{\n\tstruct amdgpu_dm_irq_handler_data *handler_data =\n\t\tcontainer_of(work, struct amdgpu_dm_irq_handler_data, work);\n\n\thandler_data->handler(handler_data->handler_arg);\n\n\t \n}\n\n \nstatic struct list_head *remove_irq_handler(struct amdgpu_device *adev,\n\t\t\t\t\t    void *ih,\n\t\t\t\t\t    const struct dc_interrupt_params *int_params)\n{\n\tstruct list_head *hnd_list;\n\tstruct list_head *entry, *tmp;\n\tstruct amdgpu_dm_irq_handler_data *handler;\n\tunsigned long irq_table_flags;\n\tbool handler_removed = false;\n\tenum dc_irq_source irq_source;\n\n\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\n\tirq_source = int_params->irq_source;\n\n\tswitch (int_params->int_context) {\n\tcase INTERRUPT_HIGH_IRQ_CONTEXT:\n\t\thnd_list = &adev->dm.irq_handler_list_high_tab[irq_source];\n\t\tbreak;\n\tcase INTERRUPT_LOW_IRQ_CONTEXT:\n\tdefault:\n\t\thnd_list = &adev->dm.irq_handler_list_low_tab[irq_source];\n\t\tbreak;\n\t}\n\n\tlist_for_each_safe(entry, tmp, hnd_list) {\n\n\t\thandler = list_entry(entry, struct amdgpu_dm_irq_handler_data,\n\t\t\t\t     list);\n\n\t\tif (handler == NULL)\n\t\t\tcontinue;\n\n\t\tif (ih == handler->handler) {\n\t\t\t \n\t\t\tlist_del(&handler->list);\n\t\t\thandler_removed = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n\n\tif (handler_removed == false) {\n\t\t \n\t\treturn NULL;\n\t}\n\n\tkfree(handler);\n\n\tDRM_DEBUG_KMS(\n\t\"DM_IRQ: removed irq handler: %p for: dal_src=%d, irq context=%d\\n\",\n\t\tih, int_params->irq_source, int_params->int_context);\n\n\treturn hnd_list;\n}\n\n \nstatic void unregister_all_irq_handlers(struct amdgpu_device *adev)\n{\n\tstruct list_head *hnd_list_low;\n\tstruct list_head *hnd_list_high;\n\tstruct list_head *entry, *tmp;\n\tstruct amdgpu_dm_irq_handler_data *handler;\n\tunsigned long irq_table_flags;\n\tint i;\n\n\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\n\tfor (i = 0; i < DAL_IRQ_SOURCES_NUMBER; i++) {\n\t\thnd_list_low = &adev->dm.irq_handler_list_low_tab[i];\n\t\thnd_list_high = &adev->dm.irq_handler_list_high_tab[i];\n\n\t\tlist_for_each_safe(entry, tmp, hnd_list_low) {\n\n\t\t\thandler = list_entry(entry, struct amdgpu_dm_irq_handler_data,\n\t\t\t\t\t     list);\n\n\t\t\tif (handler == NULL || handler->handler == NULL)\n\t\t\t\tcontinue;\n\n\t\t\tlist_del(&handler->list);\n\t\t\tkfree(handler);\n\t\t}\n\n\t\tlist_for_each_safe(entry, tmp, hnd_list_high) {\n\n\t\t\thandler = list_entry(entry, struct amdgpu_dm_irq_handler_data,\n\t\t\t\t\t     list);\n\n\t\t\tif (handler == NULL || handler->handler == NULL)\n\t\t\t\tcontinue;\n\n\t\t\tlist_del(&handler->list);\n\t\t\tkfree(handler);\n\t\t}\n\t}\n\n\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n}\n\nstatic bool\nvalidate_irq_registration_params(struct dc_interrupt_params *int_params,\n\t\t\t\t void (*ih)(void *))\n{\n\tif (NULL == int_params || NULL == ih) {\n\t\tDRM_ERROR(\"DM_IRQ: invalid input!\\n\");\n\t\treturn false;\n\t}\n\n\tif (int_params->int_context >= INTERRUPT_CONTEXT_NUMBER) {\n\t\tDRM_ERROR(\"DM_IRQ: invalid context: %d!\\n\",\n\t\t\t\tint_params->int_context);\n\t\treturn false;\n\t}\n\n\tif (!DAL_VALID_IRQ_SRC_NUM(int_params->irq_source)) {\n\t\tDRM_ERROR(\"DM_IRQ: invalid irq_source: %d!\\n\",\n\t\t\t\tint_params->irq_source);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool validate_irq_unregistration_params(enum dc_irq_source irq_source,\n\t\t\t\t\t       irq_handler_idx handler_idx)\n{\n\tif (handler_idx == DAL_INVALID_IRQ_HANDLER_IDX) {\n\t\tDRM_ERROR(\"DM_IRQ: invalid handler_idx==NULL!\\n\");\n\t\treturn false;\n\t}\n\n\tif (!DAL_VALID_IRQ_SRC_NUM(irq_source)) {\n\t\tDRM_ERROR(\"DM_IRQ: invalid irq_source:%d!\\n\", irq_source);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n \n\n \nvoid *amdgpu_dm_irq_register_interrupt(struct amdgpu_device *adev,\n\t\t\t\t       struct dc_interrupt_params *int_params,\n\t\t\t\t       void (*ih)(void *),\n\t\t\t\t       void *handler_args)\n{\n\tstruct list_head *hnd_list;\n\tstruct amdgpu_dm_irq_handler_data *handler_data;\n\tunsigned long irq_table_flags;\n\tenum dc_irq_source irq_source;\n\n\tif (false == validate_irq_registration_params(int_params, ih))\n\t\treturn DAL_INVALID_IRQ_HANDLER_IDX;\n\n\thandler_data = kzalloc(sizeof(*handler_data), GFP_KERNEL);\n\tif (!handler_data) {\n\t\tDRM_ERROR(\"DM_IRQ: failed to allocate irq handler!\\n\");\n\t\treturn DAL_INVALID_IRQ_HANDLER_IDX;\n\t}\n\n\tinit_handler_common_data(handler_data, ih, handler_args, &adev->dm);\n\n\tirq_source = int_params->irq_source;\n\n\thandler_data->irq_source = irq_source;\n\n\t \n\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\n\tswitch (int_params->int_context) {\n\tcase INTERRUPT_HIGH_IRQ_CONTEXT:\n\t\thnd_list = &adev->dm.irq_handler_list_high_tab[irq_source];\n\t\tbreak;\n\tcase INTERRUPT_LOW_IRQ_CONTEXT:\n\tdefault:\n\t\thnd_list = &adev->dm.irq_handler_list_low_tab[irq_source];\n\t\tINIT_WORK(&handler_data->work, dm_irq_work_func);\n\t\tbreak;\n\t}\n\n\tlist_add_tail(&handler_data->list, hnd_list);\n\n\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n\n\t \n\n\tDRM_DEBUG_KMS(\n\t\t\"DM_IRQ: added irq handler: %p for: dal_src=%d, irq context=%d\\n\",\n\t\thandler_data,\n\t\tirq_source,\n\t\tint_params->int_context);\n\n\treturn handler_data;\n}\n\n \nvoid amdgpu_dm_irq_unregister_interrupt(struct amdgpu_device *adev,\n\t\t\t\t\tenum dc_irq_source irq_source,\n\t\t\t\t\tvoid *ih)\n{\n\tstruct list_head *handler_list;\n\tstruct dc_interrupt_params int_params;\n\tint i;\n\n\tif (false == validate_irq_unregistration_params(irq_source, ih))\n\t\treturn;\n\n\tmemset(&int_params, 0, sizeof(int_params));\n\n\tint_params.irq_source = irq_source;\n\n\tfor (i = 0; i < INTERRUPT_CONTEXT_NUMBER; i++) {\n\n\t\tint_params.int_context = i;\n\n\t\thandler_list = remove_irq_handler(adev, ih, &int_params);\n\n\t\tif (handler_list != NULL)\n\t\t\tbreak;\n\t}\n\n\tif (handler_list == NULL) {\n\t\t \n\t\tDRM_ERROR(\n\t\t\"DM_IRQ: failed to find irq handler:%p for irq_source:%d!\\n\",\n\t\t\tih, irq_source);\n\t}\n}\n\n \nint amdgpu_dm_irq_init(struct amdgpu_device *adev)\n{\n\tint src;\n\tstruct list_head *lh;\n\n\tDRM_DEBUG_KMS(\"DM_IRQ\\n\");\n\n\tspin_lock_init(&adev->dm.irq_handler_list_table_lock);\n\n\tfor (src = 0; src < DAL_IRQ_SOURCES_NUMBER; src++) {\n\t\t \n\t\tlh = &adev->dm.irq_handler_list_low_tab[src];\n\t\tINIT_LIST_HEAD(lh);\n\t\t \n\t\tINIT_LIST_HEAD(&adev->dm.irq_handler_list_high_tab[src]);\n\t}\n\n\treturn 0;\n}\n\n \nvoid amdgpu_dm_irq_fini(struct amdgpu_device *adev)\n{\n\tint src;\n\tstruct list_head *lh;\n\tstruct list_head *entry, *tmp;\n\tstruct amdgpu_dm_irq_handler_data *handler;\n\tunsigned long irq_table_flags;\n\n\tDRM_DEBUG_KMS(\"DM_IRQ: releasing resources.\\n\");\n\tfor (src = 0; src < DAL_IRQ_SOURCES_NUMBER; src++) {\n\t\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\t\t \n\t\tlh = &adev->dm.irq_handler_list_low_tab[src];\n\t\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n\n\t\tif (!list_empty(lh)) {\n\t\t\tlist_for_each_safe(entry, tmp, lh) {\n\t\t\t\thandler = list_entry(\n\t\t\t\t\tentry,\n\t\t\t\t\tstruct amdgpu_dm_irq_handler_data,\n\t\t\t\t\tlist);\n\t\t\t\tflush_work(&handler->work);\n\t\t\t}\n\t\t}\n\t}\n\t \n\tunregister_all_irq_handlers(adev);\n}\n\nint amdgpu_dm_irq_suspend(struct amdgpu_device *adev)\n{\n\tint src;\n\tstruct list_head *hnd_list_h;\n\tstruct list_head *hnd_list_l;\n\tunsigned long irq_table_flags;\n\tstruct list_head *entry, *tmp;\n\tstruct amdgpu_dm_irq_handler_data *handler;\n\n\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\n\tDRM_DEBUG_KMS(\"DM_IRQ: suspend\\n\");\n\n\t \n\tfor (src = DC_IRQ_SOURCE_HPD1; src <= DC_IRQ_SOURCE_HPD6RX; src++) {\n\t\thnd_list_l = &adev->dm.irq_handler_list_low_tab[src];\n\t\thnd_list_h = &adev->dm.irq_handler_list_high_tab[src];\n\t\tif (!list_empty(hnd_list_l) || !list_empty(hnd_list_h))\n\t\t\tdc_interrupt_set(adev->dm.dc, src, false);\n\n\t\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n\n\t\tif (!list_empty(hnd_list_l)) {\n\t\t\tlist_for_each_safe(entry, tmp, hnd_list_l) {\n\t\t\t\thandler = list_entry(\n\t\t\t\t\tentry,\n\t\t\t\t\tstruct amdgpu_dm_irq_handler_data,\n\t\t\t\t\tlist);\n\t\t\t\tflush_work(&handler->work);\n\t\t\t}\n\t\t}\n\t\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\t}\n\n\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n\treturn 0;\n}\n\nint amdgpu_dm_irq_resume_early(struct amdgpu_device *adev)\n{\n\tint src;\n\tstruct list_head *hnd_list_h, *hnd_list_l;\n\tunsigned long irq_table_flags;\n\n\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\n\tDRM_DEBUG_KMS(\"DM_IRQ: early resume\\n\");\n\n\t \n\tfor (src = DC_IRQ_SOURCE_HPD1RX; src <= DC_IRQ_SOURCE_HPD6RX; src++) {\n\t\thnd_list_l = &adev->dm.irq_handler_list_low_tab[src];\n\t\thnd_list_h = &adev->dm.irq_handler_list_high_tab[src];\n\t\tif (!list_empty(hnd_list_l) || !list_empty(hnd_list_h))\n\t\t\tdc_interrupt_set(adev->dm.dc, src, true);\n\t}\n\n\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n\n\treturn 0;\n}\n\nint amdgpu_dm_irq_resume_late(struct amdgpu_device *adev)\n{\n\tint src;\n\tstruct list_head *hnd_list_h, *hnd_list_l;\n\tunsigned long irq_table_flags;\n\n\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\n\tDRM_DEBUG_KMS(\"DM_IRQ: resume\\n\");\n\n\t \n\tfor (src = DC_IRQ_SOURCE_HPD1; src <= DC_IRQ_SOURCE_HPD6; src++) {\n\t\thnd_list_l = &adev->dm.irq_handler_list_low_tab[src];\n\t\thnd_list_h = &adev->dm.irq_handler_list_high_tab[src];\n\t\tif (!list_empty(hnd_list_l) || !list_empty(hnd_list_h))\n\t\t\tdc_interrupt_set(adev->dm.dc, src, true);\n\t}\n\n\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n\treturn 0;\n}\n\n \nstatic void amdgpu_dm_irq_schedule_work(struct amdgpu_device *adev,\n\t\t\t\t\tenum dc_irq_source irq_source)\n{\n\tstruct  list_head *handler_list = &adev->dm.irq_handler_list_low_tab[irq_source];\n\tstruct  amdgpu_dm_irq_handler_data *handler_data;\n\tbool    work_queued = false;\n\n\tif (list_empty(handler_list))\n\t\treturn;\n\n\tlist_for_each_entry(handler_data, handler_list, list) {\n\t\tif (queue_work(system_highpri_wq, &handler_data->work)) {\n\t\t\twork_queued = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!work_queued) {\n\t\tstruct  amdgpu_dm_irq_handler_data *handler_data_add;\n\t\t \n\t\thandler_data = container_of(handler_list->next, struct amdgpu_dm_irq_handler_data, list);\n\n\t\t \n\t\thandler_data_add = kzalloc(sizeof(*handler_data), GFP_ATOMIC);\n\t\tif (!handler_data_add) {\n\t\t\tDRM_ERROR(\"DM_IRQ: failed to allocate irq handler!\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\thandler_data_add->handler       = handler_data->handler;\n\t\thandler_data_add->handler_arg   = handler_data->handler_arg;\n\t\thandler_data_add->dm            = handler_data->dm;\n\t\thandler_data_add->irq_source    = irq_source;\n\n\t\tlist_add_tail(&handler_data_add->list, handler_list);\n\n\t\tINIT_WORK(&handler_data_add->work, dm_irq_work_func);\n\n\t\tif (queue_work(system_highpri_wq, &handler_data_add->work))\n\t\t\tDRM_DEBUG(\"Queued work for handling interrupt from \"\n\t\t\t\t  \"display for IRQ source %d\\n\",\n\t\t\t\t  irq_source);\n\t\telse\n\t\t\tDRM_ERROR(\"Failed to queue work for handling interrupt \"\n\t\t\t\t  \"from display for IRQ source %d\\n\",\n\t\t\t\t  irq_source);\n\t}\n}\n\n \nstatic void amdgpu_dm_irq_immediate_work(struct amdgpu_device *adev,\n\t\t\t\t\t enum dc_irq_source irq_source)\n{\n\tstruct amdgpu_dm_irq_handler_data *handler_data;\n\tunsigned long irq_table_flags;\n\n\tDM_IRQ_TABLE_LOCK(adev, irq_table_flags);\n\n\tlist_for_each_entry(handler_data,\n\t\t\t    &adev->dm.irq_handler_list_high_tab[irq_source],\n\t\t\t    list) {\n\t\t \n\t\thandler_data->handler(handler_data->handler_arg);\n\t}\n\n\tDM_IRQ_TABLE_UNLOCK(adev, irq_table_flags);\n}\n\n \nstatic int amdgpu_dm_irq_handler(struct amdgpu_device *adev,\n\t\t\t\t struct amdgpu_irq_src *source,\n\t\t\t\t struct amdgpu_iv_entry *entry)\n{\n\n\tenum dc_irq_source src =\n\t\tdc_interrupt_to_irq_source(\n\t\t\tadev->dm.dc,\n\t\t\tentry->src_id,\n\t\t\tentry->src_data[0]);\n\n\tdc_interrupt_ack(adev->dm.dc, src);\n\n\t \n\tamdgpu_dm_irq_immediate_work(adev, src);\n\t \n\tamdgpu_dm_irq_schedule_work(adev, src);\n\n\treturn 0;\n}\n\nstatic enum dc_irq_source amdgpu_dm_hpd_to_dal_irq_source(unsigned int type)\n{\n\tswitch (type) {\n\tcase AMDGPU_HPD_1:\n\t\treturn DC_IRQ_SOURCE_HPD1;\n\tcase AMDGPU_HPD_2:\n\t\treturn DC_IRQ_SOURCE_HPD2;\n\tcase AMDGPU_HPD_3:\n\t\treturn DC_IRQ_SOURCE_HPD3;\n\tcase AMDGPU_HPD_4:\n\t\treturn DC_IRQ_SOURCE_HPD4;\n\tcase AMDGPU_HPD_5:\n\t\treturn DC_IRQ_SOURCE_HPD5;\n\tcase AMDGPU_HPD_6:\n\t\treturn DC_IRQ_SOURCE_HPD6;\n\tdefault:\n\t\treturn DC_IRQ_SOURCE_INVALID;\n\t}\n}\n\nstatic int amdgpu_dm_set_hpd_irq_state(struct amdgpu_device *adev,\n\t\t\t\t       struct amdgpu_irq_src *source,\n\t\t\t\t       unsigned int type,\n\t\t\t\t       enum amdgpu_interrupt_state state)\n{\n\tenum dc_irq_source src = amdgpu_dm_hpd_to_dal_irq_source(type);\n\tbool st = (state == AMDGPU_IRQ_STATE_ENABLE);\n\n\tdc_interrupt_set(adev->dm.dc, src, st);\n\treturn 0;\n}\n\nstatic inline int dm_irq_state(struct amdgpu_device *adev,\n\t\t\t       struct amdgpu_irq_src *source,\n\t\t\t       unsigned int crtc_id,\n\t\t\t       enum amdgpu_interrupt_state state,\n\t\t\t       const enum irq_type dal_irq_type,\n\t\t\t       const char *func)\n{\n\tbool st;\n\tenum dc_irq_source irq_source;\n\n\tstruct amdgpu_crtc *acrtc = adev->mode_info.crtcs[crtc_id];\n\n\tif (!acrtc) {\n\t\tDRM_ERROR(\n\t\t\t\"%s: crtc is NULL at id :%d\\n\",\n\t\t\tfunc,\n\t\t\tcrtc_id);\n\t\treturn 0;\n\t}\n\n\tif (acrtc->otg_inst == -1)\n\t\treturn 0;\n\n\tirq_source = dal_irq_type + acrtc->otg_inst;\n\n\tst = (state == AMDGPU_IRQ_STATE_ENABLE);\n\n\tdc_interrupt_set(adev->dm.dc, irq_source, st);\n\treturn 0;\n}\n\nstatic int amdgpu_dm_set_pflip_irq_state(struct amdgpu_device *adev,\n\t\t\t\t\t struct amdgpu_irq_src *source,\n\t\t\t\t\t unsigned int crtc_id,\n\t\t\t\t\t enum amdgpu_interrupt_state state)\n{\n\treturn dm_irq_state(\n\t\tadev,\n\t\tsource,\n\t\tcrtc_id,\n\t\tstate,\n\t\tIRQ_TYPE_PFLIP,\n\t\t__func__);\n}\n\nstatic int amdgpu_dm_set_crtc_irq_state(struct amdgpu_device *adev,\n\t\t\t\t\tstruct amdgpu_irq_src *source,\n\t\t\t\t\tunsigned int crtc_id,\n\t\t\t\t\tenum amdgpu_interrupt_state state)\n{\n\treturn dm_irq_state(\n\t\tadev,\n\t\tsource,\n\t\tcrtc_id,\n\t\tstate,\n\t\tIRQ_TYPE_VBLANK,\n\t\t__func__);\n}\n\nstatic int amdgpu_dm_set_vline0_irq_state(struct amdgpu_device *adev,\n\t\t\t\t\tstruct amdgpu_irq_src *source,\n\t\t\t\t\tunsigned int crtc_id,\n\t\t\t\t\tenum amdgpu_interrupt_state state)\n{\n\treturn dm_irq_state(\n\t\tadev,\n\t\tsource,\n\t\tcrtc_id,\n\t\tstate,\n\t\tIRQ_TYPE_VLINE0,\n\t\t__func__);\n}\n\nstatic int amdgpu_dm_set_dmub_outbox_irq_state(struct amdgpu_device *adev,\n\t\t\t\t\tstruct amdgpu_irq_src *source,\n\t\t\t\t\tunsigned int crtc_id,\n\t\t\t\t\tenum amdgpu_interrupt_state state)\n{\n\tenum dc_irq_source irq_source = DC_IRQ_SOURCE_DMCUB_OUTBOX;\n\tbool st = (state == AMDGPU_IRQ_STATE_ENABLE);\n\n\tdc_interrupt_set(adev->dm.dc, irq_source, st);\n\treturn 0;\n}\n\nstatic int amdgpu_dm_set_vupdate_irq_state(struct amdgpu_device *adev,\n\t\t\t\t\t   struct amdgpu_irq_src *source,\n\t\t\t\t\t   unsigned int crtc_id,\n\t\t\t\t\t   enum amdgpu_interrupt_state state)\n{\n\treturn dm_irq_state(\n\t\tadev,\n\t\tsource,\n\t\tcrtc_id,\n\t\tstate,\n\t\tIRQ_TYPE_VUPDATE,\n\t\t__func__);\n}\n\nstatic int amdgpu_dm_set_dmub_trace_irq_state(struct amdgpu_device *adev,\n\t\t\t\t\t   struct amdgpu_irq_src *source,\n\t\t\t\t\t   unsigned int type,\n\t\t\t\t\t   enum amdgpu_interrupt_state state)\n{\n\tenum dc_irq_source irq_source = DC_IRQ_SOURCE_DMCUB_OUTBOX0;\n\tbool st = (state == AMDGPU_IRQ_STATE_ENABLE);\n\n\tdc_interrupt_set(adev->dm.dc, irq_source, st);\n\treturn 0;\n}\n\nstatic const struct amdgpu_irq_src_funcs dm_crtc_irq_funcs = {\n\t.set = amdgpu_dm_set_crtc_irq_state,\n\t.process = amdgpu_dm_irq_handler,\n};\n\nstatic const struct amdgpu_irq_src_funcs dm_vline0_irq_funcs = {\n\t.set = amdgpu_dm_set_vline0_irq_state,\n\t.process = amdgpu_dm_irq_handler,\n};\n\nstatic const struct amdgpu_irq_src_funcs dm_dmub_outbox_irq_funcs = {\n\t.set = amdgpu_dm_set_dmub_outbox_irq_state,\n\t.process = amdgpu_dm_irq_handler,\n};\n\nstatic const struct amdgpu_irq_src_funcs dm_vupdate_irq_funcs = {\n\t.set = amdgpu_dm_set_vupdate_irq_state,\n\t.process = amdgpu_dm_irq_handler,\n};\n\nstatic const struct amdgpu_irq_src_funcs dm_dmub_trace_irq_funcs = {\n\t.set = amdgpu_dm_set_dmub_trace_irq_state,\n\t.process = amdgpu_dm_irq_handler,\n};\n\nstatic const struct amdgpu_irq_src_funcs dm_pageflip_irq_funcs = {\n\t.set = amdgpu_dm_set_pflip_irq_state,\n\t.process = amdgpu_dm_irq_handler,\n};\n\nstatic const struct amdgpu_irq_src_funcs dm_hpd_irq_funcs = {\n\t.set = amdgpu_dm_set_hpd_irq_state,\n\t.process = amdgpu_dm_irq_handler,\n};\n\nvoid amdgpu_dm_set_irq_funcs(struct amdgpu_device *adev)\n{\n\tadev->crtc_irq.num_types = adev->mode_info.num_crtc;\n\tadev->crtc_irq.funcs = &dm_crtc_irq_funcs;\n\n\tadev->vline0_irq.num_types = adev->mode_info.num_crtc;\n\tadev->vline0_irq.funcs = &dm_vline0_irq_funcs;\n\n\tadev->dmub_outbox_irq.num_types = 1;\n\tadev->dmub_outbox_irq.funcs = &dm_dmub_outbox_irq_funcs;\n\n\tadev->vupdate_irq.num_types = adev->mode_info.num_crtc;\n\tadev->vupdate_irq.funcs = &dm_vupdate_irq_funcs;\n\n\tadev->dmub_trace_irq.num_types = 1;\n\tadev->dmub_trace_irq.funcs = &dm_dmub_trace_irq_funcs;\n\n\tadev->pageflip_irq.num_types = adev->mode_info.num_crtc;\n\tadev->pageflip_irq.funcs = &dm_pageflip_irq_funcs;\n\n\tadev->hpd_irq.num_types = adev->mode_info.num_hpd;\n\tadev->hpd_irq.funcs = &dm_hpd_irq_funcs;\n}\nvoid amdgpu_dm_outbox_init(struct amdgpu_device *adev)\n{\n\tdc_interrupt_set(adev->dm.dc,\n\t\tDC_IRQ_SOURCE_DMCUB_OUTBOX,\n\t\ttrue);\n}\n\n \nvoid amdgpu_dm_hpd_init(struct amdgpu_device *adev)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\t\t\tto_amdgpu_dm_connector(connector);\n\n\t\tconst struct dc_link *dc_link = amdgpu_dm_connector->dc_link;\n\n\t\tif (dc_link->irq_source_hpd != DC_IRQ_SOURCE_INVALID) {\n\t\t\tdc_interrupt_set(adev->dm.dc,\n\t\t\t\t\tdc_link->irq_source_hpd,\n\t\t\t\t\ttrue);\n\t\t}\n\n\t\tif (dc_link->irq_source_hpd_rx != DC_IRQ_SOURCE_INVALID) {\n\t\t\tdc_interrupt_set(adev->dm.dc,\n\t\t\t\t\tdc_link->irq_source_hpd_rx,\n\t\t\t\t\ttrue);\n\t\t}\n\t}\n\tdrm_connector_list_iter_end(&iter);\n}\n\n \nvoid amdgpu_dm_hpd_fini(struct amdgpu_device *adev)\n{\n\tstruct drm_device *dev = adev_to_drm(adev);\n\tstruct drm_connector *connector;\n\tstruct drm_connector_list_iter iter;\n\n\tdrm_connector_list_iter_begin(dev, &iter);\n\tdrm_for_each_connector_iter(connector, &iter) {\n\t\tstruct amdgpu_dm_connector *amdgpu_dm_connector =\n\t\t\t\tto_amdgpu_dm_connector(connector);\n\t\tconst struct dc_link *dc_link = amdgpu_dm_connector->dc_link;\n\n\t\tif (dc_link->irq_source_hpd != DC_IRQ_SOURCE_INVALID) {\n\t\t\tdc_interrupt_set(adev->dm.dc,\n\t\t\t\t\tdc_link->irq_source_hpd,\n\t\t\t\t\tfalse);\n\t\t}\n\n\t\tif (dc_link->irq_source_hpd_rx != DC_IRQ_SOURCE_INVALID) {\n\t\t\tdc_interrupt_set(adev->dm.dc,\n\t\t\t\t\tdc_link->irq_source_hpd_rx,\n\t\t\t\t\tfalse);\n\t\t}\n\t}\n\tdrm_connector_list_iter_end(&iter);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}