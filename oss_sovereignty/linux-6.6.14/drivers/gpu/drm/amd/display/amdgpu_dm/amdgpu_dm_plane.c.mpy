{
  "module_name": "amdgpu_dm_plane.c",
  "hash_id": "ed27b84de151c956cc1d9ab813e38d48bafa0697c7fa4071ffaf4c359e918a95",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_plane.c",
  "human_readable_source": "\n \n\n#include <drm/drm_atomic_helper.h>\n#include <drm/drm_blend.h>\n#include <drm/drm_gem_atomic_helper.h>\n#include <drm/drm_plane_helper.h>\n#include <drm/drm_fourcc.h>\n\n#include \"amdgpu.h\"\n#include \"dal_asic_id.h\"\n#include \"amdgpu_display.h\"\n#include \"amdgpu_dm_trace.h\"\n#include \"amdgpu_dm_plane.h\"\n#include \"gc/gc_11_0_0_offset.h\"\n#include \"gc/gc_11_0_0_sh_mask.h\"\n\n \nstatic const uint32_t rgb_formats[] = {\n\tDRM_FORMAT_XRGB8888,\n\tDRM_FORMAT_ARGB8888,\n\tDRM_FORMAT_RGBA8888,\n\tDRM_FORMAT_XRGB2101010,\n\tDRM_FORMAT_XBGR2101010,\n\tDRM_FORMAT_ARGB2101010,\n\tDRM_FORMAT_ABGR2101010,\n\tDRM_FORMAT_XRGB16161616,\n\tDRM_FORMAT_XBGR16161616,\n\tDRM_FORMAT_ARGB16161616,\n\tDRM_FORMAT_ABGR16161616,\n\tDRM_FORMAT_XBGR8888,\n\tDRM_FORMAT_ABGR8888,\n\tDRM_FORMAT_RGB565,\n};\n\nstatic const uint32_t overlay_formats[] = {\n\tDRM_FORMAT_XRGB8888,\n\tDRM_FORMAT_ARGB8888,\n\tDRM_FORMAT_RGBA8888,\n\tDRM_FORMAT_XBGR8888,\n\tDRM_FORMAT_ABGR8888,\n\tDRM_FORMAT_RGB565,\n\tDRM_FORMAT_NV21,\n\tDRM_FORMAT_NV12,\n\tDRM_FORMAT_P010\n};\n\nstatic const uint32_t video_formats[] = {\n\tDRM_FORMAT_NV21,\n\tDRM_FORMAT_NV12,\n\tDRM_FORMAT_P010\n};\n\nstatic const u32 cursor_formats[] = {\n\tDRM_FORMAT_ARGB8888\n};\n\nenum dm_micro_swizzle {\n\tMICRO_SWIZZLE_Z = 0,\n\tMICRO_SWIZZLE_S = 1,\n\tMICRO_SWIZZLE_D = 2,\n\tMICRO_SWIZZLE_R = 3\n};\n\nconst struct drm_format_info *amdgpu_dm_plane_get_format_info(const struct drm_mode_fb_cmd2 *cmd)\n{\n\treturn amdgpu_lookup_format_info(cmd->pixel_format, cmd->modifier[0]);\n}\n\nvoid amdgpu_dm_plane_fill_blending_from_plane_state(const struct drm_plane_state *plane_state,\n\t\t\t       bool *per_pixel_alpha, bool *pre_multiplied_alpha,\n\t\t\t       bool *global_alpha, int *global_alpha_value)\n{\n\t*per_pixel_alpha = false;\n\t*pre_multiplied_alpha = true;\n\t*global_alpha = false;\n\t*global_alpha_value = 0xff;\n\n\tif (plane_state->plane->type != DRM_PLANE_TYPE_OVERLAY)\n\t\treturn;\n\n\tif (plane_state->pixel_blend_mode == DRM_MODE_BLEND_PREMULTI ||\n\t\tplane_state->pixel_blend_mode == DRM_MODE_BLEND_COVERAGE) {\n\t\tstatic const uint32_t alpha_formats[] = {\n\t\t\tDRM_FORMAT_ARGB8888,\n\t\t\tDRM_FORMAT_RGBA8888,\n\t\t\tDRM_FORMAT_ABGR8888,\n\t\t\tDRM_FORMAT_ARGB2101010,\n\t\t\tDRM_FORMAT_ABGR2101010,\n\t\t\tDRM_FORMAT_ARGB16161616,\n\t\t\tDRM_FORMAT_ABGR16161616,\n\t\t\tDRM_FORMAT_ARGB16161616F,\n\t\t};\n\t\tuint32_t format = plane_state->fb->format->format;\n\t\tunsigned int i;\n\n\t\tfor (i = 0; i < ARRAY_SIZE(alpha_formats); ++i) {\n\t\t\tif (format == alpha_formats[i]) {\n\t\t\t\t*per_pixel_alpha = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (*per_pixel_alpha && plane_state->pixel_blend_mode == DRM_MODE_BLEND_COVERAGE)\n\t\t\t*pre_multiplied_alpha = false;\n\t}\n\n\tif (plane_state->alpha < 0xffff) {\n\t\t*global_alpha = true;\n\t\t*global_alpha_value = plane_state->alpha >> 8;\n\t}\n}\n\nstatic void add_modifier(uint64_t **mods, uint64_t *size, uint64_t *cap, uint64_t mod)\n{\n\tif (!*mods)\n\t\treturn;\n\n\tif (*cap - *size < 1) {\n\t\tuint64_t new_cap = *cap * 2;\n\t\tuint64_t *new_mods = kmalloc(new_cap * sizeof(uint64_t), GFP_KERNEL);\n\n\t\tif (!new_mods) {\n\t\t\tkfree(*mods);\n\t\t\t*mods = NULL;\n\t\t\treturn;\n\t\t}\n\n\t\tmemcpy(new_mods, *mods, sizeof(uint64_t) * *size);\n\t\tkfree(*mods);\n\t\t*mods = new_mods;\n\t\t*cap = new_cap;\n\t}\n\n\t(*mods)[*size] = mod;\n\t*size += 1;\n}\n\nstatic bool modifier_has_dcc(uint64_t modifier)\n{\n\treturn IS_AMD_FMT_MOD(modifier) && AMD_FMT_MOD_GET(DCC, modifier);\n}\n\nstatic unsigned int modifier_gfx9_swizzle_mode(uint64_t modifier)\n{\n\tif (modifier == DRM_FORMAT_MOD_LINEAR)\n\t\treturn 0;\n\n\treturn AMD_FMT_MOD_GET(TILE, modifier);\n}\n\nstatic void fill_gfx8_tiling_info_from_flags(union dc_tiling_info *tiling_info,\n\t\t\t\t uint64_t tiling_flags)\n{\n\t \n\tif (AMDGPU_TILING_GET(tiling_flags, ARRAY_MODE) == DC_ARRAY_2D_TILED_THIN1) {\n\t\tunsigned int bankw, bankh, mtaspect, tile_split, num_banks;\n\n\t\tbankw = AMDGPU_TILING_GET(tiling_flags, BANK_WIDTH);\n\t\tbankh = AMDGPU_TILING_GET(tiling_flags, BANK_HEIGHT);\n\t\tmtaspect = AMDGPU_TILING_GET(tiling_flags, MACRO_TILE_ASPECT);\n\t\ttile_split = AMDGPU_TILING_GET(tiling_flags, TILE_SPLIT);\n\t\tnum_banks = AMDGPU_TILING_GET(tiling_flags, NUM_BANKS);\n\n\t\t \n\t\ttiling_info->gfx8.num_banks = num_banks;\n\t\ttiling_info->gfx8.array_mode =\n\t\t\t\tDC_ARRAY_2D_TILED_THIN1;\n\t\ttiling_info->gfx8.tile_split = tile_split;\n\t\ttiling_info->gfx8.bank_width = bankw;\n\t\ttiling_info->gfx8.bank_height = bankh;\n\t\ttiling_info->gfx8.tile_aspect = mtaspect;\n\t\ttiling_info->gfx8.tile_mode =\n\t\t\t\tDC_ADDR_SURF_MICRO_TILING_DISPLAY;\n\t} else if (AMDGPU_TILING_GET(tiling_flags, ARRAY_MODE)\n\t\t\t== DC_ARRAY_1D_TILED_THIN1) {\n\t\ttiling_info->gfx8.array_mode = DC_ARRAY_1D_TILED_THIN1;\n\t}\n\n\ttiling_info->gfx8.pipe_config =\n\t\t\tAMDGPU_TILING_GET(tiling_flags, PIPE_CONFIG);\n}\n\nstatic void fill_gfx9_tiling_info_from_device(const struct amdgpu_device *adev,\n\t\t\t\t  union dc_tiling_info *tiling_info)\n{\n\t \n\ttiling_info->gfx9.num_pipes =\n\t\tadev->gfx.config.gb_addr_config_fields.num_pipes;\n\ttiling_info->gfx9.num_banks =\n\t\tadev->gfx.config.gb_addr_config_fields.num_banks;\n\ttiling_info->gfx9.pipe_interleave =\n\t\tadev->gfx.config.gb_addr_config_fields.pipe_interleave_size;\n\ttiling_info->gfx9.num_shader_engines =\n\t\tadev->gfx.config.gb_addr_config_fields.num_se;\n\ttiling_info->gfx9.max_compressed_frags =\n\t\tadev->gfx.config.gb_addr_config_fields.max_compress_frags;\n\ttiling_info->gfx9.num_rb_per_se =\n\t\tadev->gfx.config.gb_addr_config_fields.num_rb_per_se;\n\ttiling_info->gfx9.shaderEnable = 1;\n\tif (adev->ip_versions[GC_HWIP][0] >= IP_VERSION(10, 3, 0))\n\t\ttiling_info->gfx9.num_pkrs = adev->gfx.config.gb_addr_config_fields.num_pkrs;\n}\n\nstatic void fill_gfx9_tiling_info_from_modifier(const struct amdgpu_device *adev,\n\t\t\t\t    union dc_tiling_info *tiling_info,\n\t\t\t\t    uint64_t modifier)\n{\n\tunsigned int mod_bank_xor_bits = AMD_FMT_MOD_GET(BANK_XOR_BITS, modifier);\n\tunsigned int mod_pipe_xor_bits = AMD_FMT_MOD_GET(PIPE_XOR_BITS, modifier);\n\tunsigned int pkrs_log2 = AMD_FMT_MOD_GET(PACKERS, modifier);\n\tunsigned int pipes_log2;\n\n\tpipes_log2 = min(5u, mod_pipe_xor_bits);\n\n\tfill_gfx9_tiling_info_from_device(adev, tiling_info);\n\n\tif (!IS_AMD_FMT_MOD(modifier))\n\t\treturn;\n\n\ttiling_info->gfx9.num_pipes = 1u << pipes_log2;\n\ttiling_info->gfx9.num_shader_engines = 1u << (mod_pipe_xor_bits - pipes_log2);\n\n\tif (adev->family >= AMDGPU_FAMILY_NV) {\n\t\ttiling_info->gfx9.num_pkrs = 1u << pkrs_log2;\n\t} else {\n\t\ttiling_info->gfx9.num_banks = 1u << mod_bank_xor_bits;\n\n\t\t \n\t}\n}\n\nstatic int validate_dcc(struct amdgpu_device *adev,\n\t     const enum surface_pixel_format format,\n\t     const enum dc_rotation_angle rotation,\n\t     const union dc_tiling_info *tiling_info,\n\t     const struct dc_plane_dcc_param *dcc,\n\t     const struct dc_plane_address *address,\n\t     const struct plane_size *plane_size)\n{\n\tstruct dc *dc = adev->dm.dc;\n\tstruct dc_dcc_surface_param input;\n\tstruct dc_surface_dcc_cap output;\n\n\tmemset(&input, 0, sizeof(input));\n\tmemset(&output, 0, sizeof(output));\n\n\tif (!dcc->enable)\n\t\treturn 0;\n\n\tif (format >= SURFACE_PIXEL_FORMAT_VIDEO_BEGIN ||\n\t    !dc->cap_funcs.get_dcc_compression_cap)\n\t\treturn -EINVAL;\n\n\tinput.format = format;\n\tinput.surface_size.width = plane_size->surface_size.width;\n\tinput.surface_size.height = plane_size->surface_size.height;\n\tinput.swizzle_mode = tiling_info->gfx9.swizzle;\n\n\tif (rotation == ROTATION_ANGLE_0 || rotation == ROTATION_ANGLE_180)\n\t\tinput.scan = SCAN_DIRECTION_HORIZONTAL;\n\telse if (rotation == ROTATION_ANGLE_90 || rotation == ROTATION_ANGLE_270)\n\t\tinput.scan = SCAN_DIRECTION_VERTICAL;\n\n\tif (!dc->cap_funcs.get_dcc_compression_cap(dc, &input, &output))\n\t\treturn -EINVAL;\n\n\tif (!output.capable)\n\t\treturn -EINVAL;\n\n\tif (dcc->independent_64b_blks == 0 &&\n\t    output.grph.rgb.independent_64b_blks != 0)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int fill_gfx9_plane_attributes_from_modifiers(struct amdgpu_device *adev,\n\t\t\t\t\t  const struct amdgpu_framebuffer *afb,\n\t\t\t\t\t  const enum surface_pixel_format format,\n\t\t\t\t\t  const enum dc_rotation_angle rotation,\n\t\t\t\t\t  const struct plane_size *plane_size,\n\t\t\t\t\t  union dc_tiling_info *tiling_info,\n\t\t\t\t\t  struct dc_plane_dcc_param *dcc,\n\t\t\t\t\t  struct dc_plane_address *address,\n\t\t\t\t\t  const bool force_disable_dcc)\n{\n\tconst uint64_t modifier = afb->base.modifier;\n\tint ret = 0;\n\n\tfill_gfx9_tiling_info_from_modifier(adev, tiling_info, modifier);\n\ttiling_info->gfx9.swizzle = modifier_gfx9_swizzle_mode(modifier);\n\n\tif (modifier_has_dcc(modifier) && !force_disable_dcc) {\n\t\tuint64_t dcc_address = afb->address + afb->base.offsets[1];\n\t\tbool independent_64b_blks = AMD_FMT_MOD_GET(DCC_INDEPENDENT_64B, modifier);\n\t\tbool independent_128b_blks = AMD_FMT_MOD_GET(DCC_INDEPENDENT_128B, modifier);\n\n\t\tdcc->enable = 1;\n\t\tdcc->meta_pitch = afb->base.pitches[1];\n\t\tdcc->independent_64b_blks = independent_64b_blks;\n\t\tif (AMD_FMT_MOD_GET(TILE_VERSION, modifier) >= AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS) {\n\t\t\tif (independent_64b_blks && independent_128b_blks)\n\t\t\t\tdcc->dcc_ind_blk = hubp_ind_block_64b_no_128bcl;\n\t\t\telse if (independent_128b_blks)\n\t\t\t\tdcc->dcc_ind_blk = hubp_ind_block_128b;\n\t\t\telse if (independent_64b_blks && !independent_128b_blks)\n\t\t\t\tdcc->dcc_ind_blk = hubp_ind_block_64b;\n\t\t\telse\n\t\t\t\tdcc->dcc_ind_blk = hubp_ind_block_unconstrained;\n\t\t} else {\n\t\t\tif (independent_64b_blks)\n\t\t\t\tdcc->dcc_ind_blk = hubp_ind_block_64b;\n\t\t\telse\n\t\t\t\tdcc->dcc_ind_blk = hubp_ind_block_unconstrained;\n\t\t}\n\n\t\taddress->grph.meta_addr.low_part = lower_32_bits(dcc_address);\n\t\taddress->grph.meta_addr.high_part = upper_32_bits(dcc_address);\n\t}\n\n\tret = validate_dcc(adev, format, rotation, tiling_info, dcc, address, plane_size);\n\tif (ret)\n\t\tdrm_dbg_kms(adev_to_drm(adev), \"validate_dcc: returned error: %d\\n\", ret);\n\n\treturn ret;\n}\n\nstatic void add_gfx10_1_modifiers(const struct amdgpu_device *adev,\n\t\t      uint64_t **mods, uint64_t *size, uint64_t *capacity)\n{\n\tint pipe_xor_bits = ilog2(adev->gfx.config.gb_addr_config_fields.num_pipes);\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_RETILE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits));\n\n\n\t \n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_D) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9));\n}\n\nstatic void add_gfx9_modifiers(const struct amdgpu_device *adev,\n\t\t   uint64_t **mods, uint64_t *size, uint64_t *capacity)\n{\n\tint pipes = ilog2(adev->gfx.config.gb_addr_config_fields.num_pipes);\n\tint pipe_xor_bits = min(8, pipes +\n\t\t\t\tilog2(adev->gfx.config.gb_addr_config_fields.num_se));\n\tint bank_xor_bits = min(8 - pipe_xor_bits,\n\t\t\t\tilog2(adev->gfx.config.gb_addr_config_fields.num_banks));\n\tint rb = ilog2(adev->gfx.config.gb_addr_config_fields.num_se) +\n\t\t ilog2(adev->gfx.config.gb_addr_config_fields.num_rb_per_se);\n\n\n\tif (adev->family == AMDGPU_FAMILY_RV) {\n\t\t \n\t\tbool has_constant_encode = adev->asic_type > CHIP_RAVEN || adev->external_rev_id >= 0x81;\n\n\t\t \n\n\t\tif (has_constant_encode) {\n\t\t\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S_X) |\n\t\t\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9) |\n\t\t\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t\t\t    AMD_FMT_MOD_SET(BANK_XOR_BITS, bank_xor_bits) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1));\n\t\t}\n\n\t\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S_X) |\n\t\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9) |\n\t\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t\t    AMD_FMT_MOD_SET(BANK_XOR_BITS, bank_xor_bits) |\n\t\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B) |\n\t\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 0));\n\n\t\tif (has_constant_encode) {\n\t\t\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S_X) |\n\t\t\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9) |\n\t\t\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t\t\t    AMD_FMT_MOD_SET(BANK_XOR_BITS, bank_xor_bits) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_RETILE, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B) |\n\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(RB, rb) |\n\t\t\t\t    AMD_FMT_MOD_SET(PIPE, pipes));\n\t\t}\n\n\t\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S_X) |\n\t\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9) |\n\t\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t\t    AMD_FMT_MOD_SET(BANK_XOR_BITS, bank_xor_bits) |\n\t\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t\t    AMD_FMT_MOD_SET(DCC_RETILE, 1) |\n\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B) |\n\t\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 0) |\n\t\t\t    AMD_FMT_MOD_SET(RB, rb) |\n\t\t\t    AMD_FMT_MOD_SET(PIPE, pipes));\n\t}\n\n\t \n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_D_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(BANK_XOR_BITS, bank_xor_bits));\n\n\tif (adev->family == AMDGPU_FAMILY_RV) {\n\t\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S_X) |\n\t\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9) |\n\t\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t\t    AMD_FMT_MOD_SET(BANK_XOR_BITS, bank_xor_bits));\n\t}\n\n\t \n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_D) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9));\n\n\tif (adev->family == AMDGPU_FAMILY_RV) {\n\t\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S) |\n\t\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9));\n\t}\n}\n\nstatic void add_gfx10_3_modifiers(const struct amdgpu_device *adev,\n\t\t      uint64_t **mods, uint64_t *size, uint64_t *capacity)\n{\n\tint pipe_xor_bits = ilog2(adev->gfx.config.gb_addr_config_fields.num_pipes);\n\tint pkrs = ilog2(adev->gfx.config.gb_addr_config_fields.num_pkrs);\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(PACKERS, pkrs) |\n\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_128B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(PACKERS, pkrs) |\n\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_128B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_128B));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(PACKERS, pkrs) |\n\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_RETILE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_128B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(PACKERS, pkrs) |\n\t\t    AMD_FMT_MOD_SET(DCC, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_RETILE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_CONSTANT_ENCODE, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_128B, 1) |\n\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_128B));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_R_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(PACKERS, pkrs));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S_X) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX10_RBPLUS) |\n\t\t    AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t    AMD_FMT_MOD_SET(PACKERS, pkrs));\n\n\t \n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_D) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9));\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t    AMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_S) |\n\t\t    AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX9));\n}\n\nstatic void add_gfx11_modifiers(struct amdgpu_device *adev,\n\t\t      uint64_t **mods, uint64_t *size, uint64_t *capacity)\n{\n\tint num_pipes = 0;\n\tint pipe_xor_bits = 0;\n\tint num_pkrs = 0;\n\tint pkrs = 0;\n\tu32 gb_addr_config;\n\tu8 i = 0;\n\tunsigned int swizzle_r_x;\n\tuint64_t modifier_r_x;\n\tuint64_t modifier_dcc_best;\n\tuint64_t modifier_dcc_4k;\n\n\t \n\tgb_addr_config = RREG32_SOC15(GC, 0, regGB_ADDR_CONFIG);\n\tASSERT(gb_addr_config != 0);\n\n\tnum_pkrs = 1 << REG_GET_FIELD(gb_addr_config, GB_ADDR_CONFIG, NUM_PKRS);\n\tpkrs = ilog2(num_pkrs);\n\tnum_pipes = 1 << REG_GET_FIELD(gb_addr_config, GB_ADDR_CONFIG, NUM_PIPES);\n\tpipe_xor_bits = ilog2(num_pipes);\n\n\tfor (i = 0; i < 2; i++) {\n\t\t \n\t\t \n\t\tif (num_pipes > 16)\n\t\t\tswizzle_r_x = !i ? AMD_FMT_MOD_TILE_GFX11_256K_R_X : AMD_FMT_MOD_TILE_GFX9_64K_R_X;\n\t\telse\n\t\t\tswizzle_r_x = !i ? AMD_FMT_MOD_TILE_GFX9_64K_R_X : AMD_FMT_MOD_TILE_GFX11_256K_R_X;\n\n\t\tmodifier_r_x = AMD_FMT_MOD |\n\t\t\t       AMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX11) |\n\t\t\t       AMD_FMT_MOD_SET(PIPE_XOR_BITS, pipe_xor_bits) |\n\t\t\t       AMD_FMT_MOD_SET(TILE, swizzle_r_x) |\n\t\t\t       AMD_FMT_MOD_SET(PACKERS, pkrs);\n\n\t\t \n\t\tmodifier_dcc_best = modifier_r_x | AMD_FMT_MOD_SET(DCC, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 0) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_INDEPENDENT_128B, 1) |\n\t\t\t\t    AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_128B);\n\n\t\t \n\t\tmodifier_dcc_4k = modifier_r_x | AMD_FMT_MOD_SET(DCC, 1) |\n\t\t\t\t  AMD_FMT_MOD_SET(DCC_INDEPENDENT_64B, 1) |\n\t\t\t\t  AMD_FMT_MOD_SET(DCC_INDEPENDENT_128B, 1) |\n\t\t\t\t  AMD_FMT_MOD_SET(DCC_MAX_COMPRESSED_BLOCK, AMD_FMT_MOD_DCC_BLOCK_64B);\n\n\t\tadd_modifier(mods, size, capacity, modifier_dcc_best);\n\t\tadd_modifier(mods, size, capacity, modifier_dcc_4k);\n\n\t\tadd_modifier(mods, size, capacity, modifier_dcc_best | AMD_FMT_MOD_SET(DCC_RETILE, 1));\n\t\tadd_modifier(mods, size, capacity, modifier_dcc_4k | AMD_FMT_MOD_SET(DCC_RETILE, 1));\n\n\t\tadd_modifier(mods, size, capacity, modifier_r_x);\n\t}\n\n\tadd_modifier(mods, size, capacity, AMD_FMT_MOD |\n\t\t\tAMD_FMT_MOD_SET(TILE_VERSION, AMD_FMT_MOD_TILE_VER_GFX11) |\n\t\t\tAMD_FMT_MOD_SET(TILE, AMD_FMT_MOD_TILE_GFX9_64K_D));\n}\n\nstatic int get_plane_modifiers(struct amdgpu_device *adev, unsigned int plane_type, uint64_t **mods)\n{\n\tuint64_t size = 0, capacity = 128;\n\t*mods = NULL;\n\n\t \n\tif (adev->family < AMDGPU_FAMILY_AI)\n\t\treturn 0;\n\n\t*mods = kmalloc(capacity * sizeof(uint64_t), GFP_KERNEL);\n\n\tif (plane_type == DRM_PLANE_TYPE_CURSOR) {\n\t\tadd_modifier(mods, &size, &capacity, DRM_FORMAT_MOD_LINEAR);\n\t\tadd_modifier(mods, &size, &capacity, DRM_FORMAT_MOD_INVALID);\n\t\treturn *mods ? 0 : -ENOMEM;\n\t}\n\n\tswitch (adev->family) {\n\tcase AMDGPU_FAMILY_AI:\n\tcase AMDGPU_FAMILY_RV:\n\t\tadd_gfx9_modifiers(adev, mods, &size, &capacity);\n\t\tbreak;\n\tcase AMDGPU_FAMILY_NV:\n\tcase AMDGPU_FAMILY_VGH:\n\tcase AMDGPU_FAMILY_YC:\n\tcase AMDGPU_FAMILY_GC_10_3_6:\n\tcase AMDGPU_FAMILY_GC_10_3_7:\n\t\tif (adev->ip_versions[GC_HWIP][0] >= IP_VERSION(10, 3, 0))\n\t\t\tadd_gfx10_3_modifiers(adev, mods, &size, &capacity);\n\t\telse\n\t\t\tadd_gfx10_1_modifiers(adev, mods, &size, &capacity);\n\t\tbreak;\n\tcase AMDGPU_FAMILY_GC_11_0_0:\n\tcase AMDGPU_FAMILY_GC_11_0_1:\n\t\tadd_gfx11_modifiers(adev, mods, &size, &capacity);\n\t\tbreak;\n\t}\n\n\tadd_modifier(mods, &size, &capacity, DRM_FORMAT_MOD_LINEAR);\n\n\t \n\tadd_modifier(mods, &size, &capacity, DRM_FORMAT_MOD_INVALID);\n\n\tif (!*mods)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic int get_plane_formats(const struct drm_plane *plane,\n\t\t\t     const struct dc_plane_cap *plane_cap,\n\t\t\t     uint32_t *formats, int max_formats)\n{\n\tint i, num_formats = 0;\n\n\t \n\n\tif (plane->type == DRM_PLANE_TYPE_PRIMARY ||\n\t\t(plane_cap && plane_cap->type == DC_PLANE_TYPE_DCN_UNIVERSAL && plane->type != DRM_PLANE_TYPE_CURSOR)) {\n\t\tfor (i = 0; i < ARRAY_SIZE(rgb_formats); ++i) {\n\t\t\tif (num_formats >= max_formats)\n\t\t\t\tbreak;\n\n\t\t\tformats[num_formats++] = rgb_formats[i];\n\t\t}\n\n\t\tif (plane_cap && plane_cap->pixel_format_support.nv12)\n\t\t\tformats[num_formats++] = DRM_FORMAT_NV12;\n\t\tif (plane_cap && plane_cap->pixel_format_support.p010)\n\t\t\tformats[num_formats++] = DRM_FORMAT_P010;\n\t\tif (plane_cap && plane_cap->pixel_format_support.fp16) {\n\t\t\tformats[num_formats++] = DRM_FORMAT_XRGB16161616F;\n\t\t\tformats[num_formats++] = DRM_FORMAT_ARGB16161616F;\n\t\t\tformats[num_formats++] = DRM_FORMAT_XBGR16161616F;\n\t\t\tformats[num_formats++] = DRM_FORMAT_ABGR16161616F;\n\t\t}\n\t} else {\n\t\tswitch (plane->type) {\n\t\tcase DRM_PLANE_TYPE_OVERLAY:\n\t\t\tfor (i = 0; i < ARRAY_SIZE(overlay_formats); ++i) {\n\t\t\t\tif (num_formats >= max_formats)\n\t\t\t\t\tbreak;\n\n\t\t\t\tformats[num_formats++] = overlay_formats[i];\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase DRM_PLANE_TYPE_CURSOR:\n\t\t\tfor (i = 0; i < ARRAY_SIZE(cursor_formats); ++i) {\n\t\t\t\tif (num_formats >= max_formats)\n\t\t\t\t\tbreak;\n\n\t\t\t\tformats[num_formats++] = cursor_formats[i];\n\t\t\t}\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn num_formats;\n}\n\nint amdgpu_dm_plane_fill_plane_buffer_attributes(struct amdgpu_device *adev,\n\t\t\t     const struct amdgpu_framebuffer *afb,\n\t\t\t     const enum surface_pixel_format format,\n\t\t\t     const enum dc_rotation_angle rotation,\n\t\t\t     const uint64_t tiling_flags,\n\t\t\t     union dc_tiling_info *tiling_info,\n\t\t\t     struct plane_size *plane_size,\n\t\t\t     struct dc_plane_dcc_param *dcc,\n\t\t\t     struct dc_plane_address *address,\n\t\t\t     bool tmz_surface,\n\t\t\t     bool force_disable_dcc)\n{\n\tconst struct drm_framebuffer *fb = &afb->base;\n\tint ret;\n\n\tmemset(tiling_info, 0, sizeof(*tiling_info));\n\tmemset(plane_size, 0, sizeof(*plane_size));\n\tmemset(dcc, 0, sizeof(*dcc));\n\tmemset(address, 0, sizeof(*address));\n\n\taddress->tmz_surface = tmz_surface;\n\n\tif (format < SURFACE_PIXEL_FORMAT_VIDEO_BEGIN) {\n\t\tuint64_t addr = afb->address + fb->offsets[0];\n\n\t\tplane_size->surface_size.x = 0;\n\t\tplane_size->surface_size.y = 0;\n\t\tplane_size->surface_size.width = fb->width;\n\t\tplane_size->surface_size.height = fb->height;\n\t\tplane_size->surface_pitch =\n\t\t\tfb->pitches[0] / fb->format->cpp[0];\n\n\t\taddress->type = PLN_ADDR_TYPE_GRAPHICS;\n\t\taddress->grph.addr.low_part = lower_32_bits(addr);\n\t\taddress->grph.addr.high_part = upper_32_bits(addr);\n\t} else if (format < SURFACE_PIXEL_FORMAT_INVALID) {\n\t\tuint64_t luma_addr = afb->address + fb->offsets[0];\n\t\tuint64_t chroma_addr = afb->address + fb->offsets[1];\n\n\t\tplane_size->surface_size.x = 0;\n\t\tplane_size->surface_size.y = 0;\n\t\tplane_size->surface_size.width = fb->width;\n\t\tplane_size->surface_size.height = fb->height;\n\t\tplane_size->surface_pitch =\n\t\t\tfb->pitches[0] / fb->format->cpp[0];\n\n\t\tplane_size->chroma_size.x = 0;\n\t\tplane_size->chroma_size.y = 0;\n\t\t \n\t\tplane_size->chroma_size.width = fb->width / 2;\n\t\tplane_size->chroma_size.height = fb->height / 2;\n\n\t\tplane_size->chroma_pitch =\n\t\t\tfb->pitches[1] / fb->format->cpp[1];\n\n\t\taddress->type = PLN_ADDR_TYPE_VIDEO_PROGRESSIVE;\n\t\taddress->video_progressive.luma_addr.low_part =\n\t\t\tlower_32_bits(luma_addr);\n\t\taddress->video_progressive.luma_addr.high_part =\n\t\t\tupper_32_bits(luma_addr);\n\t\taddress->video_progressive.chroma_addr.low_part =\n\t\t\tlower_32_bits(chroma_addr);\n\t\taddress->video_progressive.chroma_addr.high_part =\n\t\t\tupper_32_bits(chroma_addr);\n\t}\n\n\tif (adev->family >= AMDGPU_FAMILY_AI) {\n\t\tret = fill_gfx9_plane_attributes_from_modifiers(adev, afb, format,\n\t\t\t\t\t\t\t\trotation, plane_size,\n\t\t\t\t\t\t\t\ttiling_info, dcc,\n\t\t\t\t\t\t\t\taddress,\n\t\t\t\t\t\t\t\tforce_disable_dcc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else {\n\t\tfill_gfx8_tiling_info_from_flags(tiling_info, tiling_flags);\n\t}\n\n\treturn 0;\n}\n\nstatic int dm_plane_helper_prepare_fb(struct drm_plane *plane,\n\t\t\t\t      struct drm_plane_state *new_state)\n{\n\tstruct amdgpu_framebuffer *afb;\n\tstruct drm_gem_object *obj;\n\tstruct amdgpu_device *adev;\n\tstruct amdgpu_bo *rbo;\n\tstruct dm_plane_state *dm_plane_state_new, *dm_plane_state_old;\n\tuint32_t domain;\n\tint r;\n\n\tif (!new_state->fb) {\n\t\tDRM_DEBUG_KMS(\"No FB bound\\n\");\n\t\treturn 0;\n\t}\n\n\tafb = to_amdgpu_framebuffer(new_state->fb);\n\tobj = new_state->fb->obj[0];\n\trbo = gem_to_amdgpu_bo(obj);\n\tadev = amdgpu_ttm_adev(rbo->tbo.bdev);\n\n\tr = amdgpu_bo_reserve(rbo, true);\n\tif (r) {\n\t\tdev_err(adev->dev, \"fail to reserve bo (%d)\\n\", r);\n\t\treturn r;\n\t}\n\n\tr = dma_resv_reserve_fences(rbo->tbo.base.resv, 1);\n\tif (r) {\n\t\tdev_err(adev->dev, \"reserving fence slot failed (%d)\\n\", r);\n\t\tgoto error_unlock;\n\t}\n\n\tif (plane->type != DRM_PLANE_TYPE_CURSOR)\n\t\tdomain = amdgpu_display_supported_domains(adev, rbo->flags);\n\telse\n\t\tdomain = AMDGPU_GEM_DOMAIN_VRAM;\n\n\tr = amdgpu_bo_pin(rbo, domain);\n\tif (unlikely(r != 0)) {\n\t\tif (r != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Failed to pin framebuffer with error %d\\n\", r);\n\t\tgoto error_unlock;\n\t}\n\n\tr = amdgpu_ttm_alloc_gart(&rbo->tbo);\n\tif (unlikely(r != 0)) {\n\t\tDRM_ERROR(\"%p bind failed\\n\", rbo);\n\t\tgoto error_unpin;\n\t}\n\n\tr = drm_gem_plane_helper_prepare_fb(plane, new_state);\n\tif (unlikely(r != 0))\n\t\tgoto error_unpin;\n\n\tamdgpu_bo_unreserve(rbo);\n\n\tafb->address = amdgpu_bo_gpu_offset(rbo);\n\n\tamdgpu_bo_ref(rbo);\n\n\t \n\tdm_plane_state_old = to_dm_plane_state(plane->state);\n\tdm_plane_state_new = to_dm_plane_state(new_state);\n\n\tif (dm_plane_state_new->dc_state &&\n\t    dm_plane_state_old->dc_state != dm_plane_state_new->dc_state) {\n\t\tstruct dc_plane_state *plane_state =\n\t\t\tdm_plane_state_new->dc_state;\n\t\tbool force_disable_dcc = !plane_state->dcc.enable;\n\n\t\tamdgpu_dm_plane_fill_plane_buffer_attributes(\n\t\t\tadev, afb, plane_state->format, plane_state->rotation,\n\t\t\tafb->tiling_flags,\n\t\t\t&plane_state->tiling_info, &plane_state->plane_size,\n\t\t\t&plane_state->dcc, &plane_state->address,\n\t\t\tafb->tmz_surface, force_disable_dcc);\n\t}\n\n\treturn 0;\n\nerror_unpin:\n\tamdgpu_bo_unpin(rbo);\n\nerror_unlock:\n\tamdgpu_bo_unreserve(rbo);\n\treturn r;\n}\n\nstatic void dm_plane_helper_cleanup_fb(struct drm_plane *plane,\n\t\t\t\t       struct drm_plane_state *old_state)\n{\n\tstruct amdgpu_bo *rbo;\n\tint r;\n\n\tif (!old_state->fb)\n\t\treturn;\n\n\trbo = gem_to_amdgpu_bo(old_state->fb->obj[0]);\n\tr = amdgpu_bo_reserve(rbo, false);\n\tif (unlikely(r)) {\n\t\tDRM_ERROR(\"failed to reserve rbo before unpin\\n\");\n\t\treturn;\n\t}\n\n\tamdgpu_bo_unpin(rbo);\n\tamdgpu_bo_unreserve(rbo);\n\tamdgpu_bo_unref(&rbo);\n}\n\nstatic void get_min_max_dc_plane_scaling(struct drm_device *dev,\n\t\t\t\t\t struct drm_framebuffer *fb,\n\t\t\t\t\t int *min_downscale, int *max_upscale)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(dev);\n\tstruct dc *dc = adev->dm.dc;\n\t \n\tstruct dc_plane_cap *plane_cap = &dc->caps.planes[0];\n\n\tswitch (fb->format->format) {\n\tcase DRM_FORMAT_P010:\n\tcase DRM_FORMAT_NV12:\n\tcase DRM_FORMAT_NV21:\n\t\t*max_upscale = plane_cap->max_upscale_factor.nv12;\n\t\t*min_downscale = plane_cap->max_downscale_factor.nv12;\n\t\tbreak;\n\n\tcase DRM_FORMAT_XRGB16161616F:\n\tcase DRM_FORMAT_ARGB16161616F:\n\tcase DRM_FORMAT_XBGR16161616F:\n\tcase DRM_FORMAT_ABGR16161616F:\n\t\t*max_upscale = plane_cap->max_upscale_factor.fp16;\n\t\t*min_downscale = plane_cap->max_downscale_factor.fp16;\n\t\tbreak;\n\n\tdefault:\n\t\t*max_upscale = plane_cap->max_upscale_factor.argb8888;\n\t\t*min_downscale = plane_cap->max_downscale_factor.argb8888;\n\t\tbreak;\n\t}\n\n\t \n\tif (*max_upscale == 1)\n\t\t*max_upscale = 1000;\n\n\tif (*min_downscale == 1)\n\t\t*min_downscale = 1000;\n}\n\nint amdgpu_dm_plane_helper_check_state(struct drm_plane_state *state,\n\t\t\t\t       struct drm_crtc_state *new_crtc_state)\n{\n\tstruct drm_framebuffer *fb = state->fb;\n\tint min_downscale, max_upscale;\n\tint min_scale = 0;\n\tint max_scale = INT_MAX;\n\n\t \n\tif (fb && state->crtc) {\n\t\t \n\t\tif (state->plane->type != DRM_PLANE_TYPE_CURSOR) {\n\t\t\tint viewport_width = state->crtc_w;\n\t\t\tint viewport_height = state->crtc_h;\n\n\t\t\tif (state->crtc_x < 0)\n\t\t\t\tviewport_width += state->crtc_x;\n\t\t\telse if (state->crtc_x + state->crtc_w > new_crtc_state->mode.crtc_hdisplay)\n\t\t\t\tviewport_width = new_crtc_state->mode.crtc_hdisplay - state->crtc_x;\n\n\t\t\tif (state->crtc_y < 0)\n\t\t\t\tviewport_height += state->crtc_y;\n\t\t\telse if (state->crtc_y + state->crtc_h > new_crtc_state->mode.crtc_vdisplay)\n\t\t\t\tviewport_height = new_crtc_state->mode.crtc_vdisplay - state->crtc_y;\n\n\t\t\tif (viewport_width < 0 || viewport_height < 0) {\n\t\t\t\tDRM_DEBUG_ATOMIC(\"Plane completely outside of screen\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t} else if (viewport_width < MIN_VIEWPORT_SIZE*2) {  \n\t\t\t\tDRM_DEBUG_ATOMIC(\"Viewport width %d smaller than %d\\n\", viewport_width, MIN_VIEWPORT_SIZE*2);\n\t\t\t\treturn -EINVAL;\n\t\t\t} else if (viewport_height < MIN_VIEWPORT_SIZE) {\n\t\t\t\tDRM_DEBUG_ATOMIC(\"Viewport height %d smaller than %d\\n\", viewport_height, MIN_VIEWPORT_SIZE);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t}\n\n\t\t \n\t\tget_min_max_dc_plane_scaling(state->crtc->dev, fb,\n\t\t\t\t\t     &min_downscale, &max_upscale);\n\t\t \n\t\tmin_scale = (1000 << 16) / max_upscale;\n\t\tmax_scale = (1000 << 16) / min_downscale;\n\t}\n\n\treturn drm_atomic_helper_check_plane_state(\n\t\tstate, new_crtc_state, min_scale, max_scale, true, true);\n}\n\nint amdgpu_dm_plane_fill_dc_scaling_info(struct amdgpu_device *adev,\n\t\t\t\tconst struct drm_plane_state *state,\n\t\t\t\tstruct dc_scaling_info *scaling_info)\n{\n\tint scale_w, scale_h, min_downscale, max_upscale;\n\n\tmemset(scaling_info, 0, sizeof(*scaling_info));\n\n\t \n\tscaling_info->src_rect.x = state->src_x >> 16;\n\tscaling_info->src_rect.y = state->src_y >> 16;\n\n\t \n\tif (((adev->ip_versions[DCE_HWIP][0] == IP_VERSION(1, 0, 0)) ||\n\t    (adev->ip_versions[DCE_HWIP][0] == IP_VERSION(1, 0, 1))) &&\n\t    (state->fb && state->fb->format->format == DRM_FORMAT_NV12 &&\n\t    (scaling_info->src_rect.x != 0 || scaling_info->src_rect.y != 0)))\n\t\treturn -EINVAL;\n\n\tscaling_info->src_rect.width = state->src_w >> 16;\n\tif (scaling_info->src_rect.width == 0)\n\t\treturn -EINVAL;\n\n\tscaling_info->src_rect.height = state->src_h >> 16;\n\tif (scaling_info->src_rect.height == 0)\n\t\treturn -EINVAL;\n\n\tscaling_info->dst_rect.x = state->crtc_x;\n\tscaling_info->dst_rect.y = state->crtc_y;\n\n\tif (state->crtc_w == 0)\n\t\treturn -EINVAL;\n\n\tscaling_info->dst_rect.width = state->crtc_w;\n\n\tif (state->crtc_h == 0)\n\t\treturn -EINVAL;\n\n\tscaling_info->dst_rect.height = state->crtc_h;\n\n\t \n\tscaling_info->clip_rect = scaling_info->dst_rect;\n\n\t \n\tif (state->plane && state->plane->dev && state->fb) {\n\t\tget_min_max_dc_plane_scaling(state->plane->dev, state->fb,\n\t\t\t\t\t     &min_downscale, &max_upscale);\n\t} else {\n\t\tmin_downscale = 250;\n\t\tmax_upscale = 16000;\n\t}\n\n\tscale_w = scaling_info->dst_rect.width * 1000 /\n\t\t  scaling_info->src_rect.width;\n\n\tif (scale_w < min_downscale || scale_w > max_upscale)\n\t\treturn -EINVAL;\n\n\tscale_h = scaling_info->dst_rect.height * 1000 /\n\t\t  scaling_info->src_rect.height;\n\n\tif (scale_h < min_downscale || scale_h > max_upscale)\n\t\treturn -EINVAL;\n\n\t \n\n\treturn 0;\n}\n\nstatic int dm_plane_atomic_check(struct drm_plane *plane,\n\t\t\t\t struct drm_atomic_state *state)\n{\n\tstruct drm_plane_state *new_plane_state = drm_atomic_get_new_plane_state(state,\n\t\t\t\t\t\t\t\t\t\t plane);\n\tstruct amdgpu_device *adev = drm_to_adev(plane->dev);\n\tstruct dc *dc = adev->dm.dc;\n\tstruct dm_plane_state *dm_plane_state;\n\tstruct dc_scaling_info scaling_info;\n\tstruct drm_crtc_state *new_crtc_state;\n\tint ret;\n\n\ttrace_amdgpu_dm_plane_atomic_check(new_plane_state);\n\n\tdm_plane_state = to_dm_plane_state(new_plane_state);\n\n\tif (!dm_plane_state->dc_state)\n\t\treturn 0;\n\n\tnew_crtc_state =\n\t\tdrm_atomic_get_new_crtc_state(state,\n\t\t\t\t\t      new_plane_state->crtc);\n\tif (!new_crtc_state)\n\t\treturn -EINVAL;\n\n\tret = amdgpu_dm_plane_helper_check_state(new_plane_state, new_crtc_state);\n\tif (ret)\n\t\treturn ret;\n\n\tret = amdgpu_dm_plane_fill_dc_scaling_info(adev, new_plane_state, &scaling_info);\n\tif (ret)\n\t\treturn ret;\n\n\tif (dc_validate_plane(dc, dm_plane_state->dc_state) == DC_OK)\n\t\treturn 0;\n\n\treturn -EINVAL;\n}\n\nstatic int dm_plane_atomic_async_check(struct drm_plane *plane,\n\t\t\t\t       struct drm_atomic_state *state)\n{\n\t \n\tif (plane->type != DRM_PLANE_TYPE_CURSOR)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int get_cursor_position(struct drm_plane *plane, struct drm_crtc *crtc,\n\t\t\t       struct dc_cursor_position *position)\n{\n\tstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\n\tint x, y;\n\tint xorigin = 0, yorigin = 0;\n\n\tif (!crtc || !plane->state->fb)\n\t\treturn 0;\n\n\tif ((plane->state->crtc_w > amdgpu_crtc->max_cursor_width) ||\n\t    (plane->state->crtc_h > amdgpu_crtc->max_cursor_height)) {\n\t\tDRM_ERROR(\"%s: bad cursor width or height %d x %d\\n\",\n\t\t\t  __func__,\n\t\t\t  plane->state->crtc_w,\n\t\t\t  plane->state->crtc_h);\n\t\treturn -EINVAL;\n\t}\n\n\tx = plane->state->crtc_x;\n\ty = plane->state->crtc_y;\n\n\tif (x <= -amdgpu_crtc->max_cursor_width ||\n\t    y <= -amdgpu_crtc->max_cursor_height)\n\t\treturn 0;\n\n\tif (x < 0) {\n\t\txorigin = min(-x, amdgpu_crtc->max_cursor_width - 1);\n\t\tx = 0;\n\t}\n\tif (y < 0) {\n\t\tyorigin = min(-y, amdgpu_crtc->max_cursor_height - 1);\n\t\ty = 0;\n\t}\n\tposition->enable = true;\n\tposition->translate_by_source = true;\n\tposition->x = x;\n\tposition->y = y;\n\tposition->x_hotspot = xorigin;\n\tposition->y_hotspot = yorigin;\n\n\treturn 0;\n}\n\nvoid amdgpu_dm_plane_handle_cursor_update(struct drm_plane *plane,\n\t\t\t\t struct drm_plane_state *old_plane_state)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(plane->dev);\n\tstruct amdgpu_framebuffer *afb = to_amdgpu_framebuffer(plane->state->fb);\n\tstruct drm_crtc *crtc = afb ? plane->state->crtc : old_plane_state->crtc;\n\tstruct dm_crtc_state *crtc_state = crtc ? to_dm_crtc_state(crtc->state) : NULL;\n\tstruct amdgpu_crtc *amdgpu_crtc = to_amdgpu_crtc(crtc);\n\tuint64_t address = afb ? afb->address : 0;\n\tstruct dc_cursor_position position = {0};\n\tstruct dc_cursor_attributes attributes;\n\tint ret;\n\n\tif (!plane->state->fb && !old_plane_state->fb)\n\t\treturn;\n\n\tDC_LOG_CURSOR(\"%s: crtc_id=%d with size %d to %d\\n\",\n\t\t      __func__,\n\t\t      amdgpu_crtc->crtc_id,\n\t\t      plane->state->crtc_w,\n\t\t      plane->state->crtc_h);\n\n\tret = get_cursor_position(plane, crtc, &position);\n\tif (ret)\n\t\treturn;\n\n\tif (!position.enable) {\n\t\t \n\t\tif (crtc_state && crtc_state->stream) {\n\t\t\tmutex_lock(&adev->dm.dc_lock);\n\t\t\tdc_stream_set_cursor_position(crtc_state->stream,\n\t\t\t\t\t\t      &position);\n\t\t\tmutex_unlock(&adev->dm.dc_lock);\n\t\t}\n\t\treturn;\n\t}\n\n\tamdgpu_crtc->cursor_width = plane->state->crtc_w;\n\tamdgpu_crtc->cursor_height = plane->state->crtc_h;\n\n\tmemset(&attributes, 0, sizeof(attributes));\n\tattributes.address.high_part = upper_32_bits(address);\n\tattributes.address.low_part  = lower_32_bits(address);\n\tattributes.width             = plane->state->crtc_w;\n\tattributes.height            = plane->state->crtc_h;\n\tattributes.color_format      = CURSOR_MODE_COLOR_PRE_MULTIPLIED_ALPHA;\n\tattributes.rotation_angle    = 0;\n\tattributes.attribute_flags.value = 0;\n\n\t \n\tif (crtc_state->cm_is_degamma_srgb &&\n\t    adev->dm.dc->caps.color.dpp.gamma_corr)\n\t\tattributes.attribute_flags.bits.ENABLE_CURSOR_DEGAMMA = 1;\n\n\tattributes.pitch = afb->base.pitches[0] / afb->base.format->cpp[0];\n\n\tif (crtc_state->stream) {\n\t\tmutex_lock(&adev->dm.dc_lock);\n\t\tif (!dc_stream_set_cursor_attributes(crtc_state->stream,\n\t\t\t\t\t\t\t &attributes))\n\t\t\tDRM_ERROR(\"DC failed to set cursor attributes\\n\");\n\n\t\tif (!dc_stream_set_cursor_position(crtc_state->stream,\n\t\t\t\t\t\t   &position))\n\t\t\tDRM_ERROR(\"DC failed to set cursor position\\n\");\n\t\tmutex_unlock(&adev->dm.dc_lock);\n\t}\n}\n\nstatic void dm_plane_atomic_async_update(struct drm_plane *plane,\n\t\t\t\t\t struct drm_atomic_state *state)\n{\n\tstruct drm_plane_state *new_state = drm_atomic_get_new_plane_state(state,\n\t\t\t\t\t\t\t\t\t   plane);\n\tstruct drm_plane_state *old_state =\n\t\tdrm_atomic_get_old_plane_state(state, plane);\n\n\ttrace_amdgpu_dm_atomic_update_cursor(new_state);\n\n\tswap(plane->state->fb, new_state->fb);\n\n\tplane->state->src_x = new_state->src_x;\n\tplane->state->src_y = new_state->src_y;\n\tplane->state->src_w = new_state->src_w;\n\tplane->state->src_h = new_state->src_h;\n\tplane->state->crtc_x = new_state->crtc_x;\n\tplane->state->crtc_y = new_state->crtc_y;\n\tplane->state->crtc_w = new_state->crtc_w;\n\tplane->state->crtc_h = new_state->crtc_h;\n\n\tamdgpu_dm_plane_handle_cursor_update(plane, old_state);\n}\n\nstatic const struct drm_plane_helper_funcs dm_plane_helper_funcs = {\n\t.prepare_fb = dm_plane_helper_prepare_fb,\n\t.cleanup_fb = dm_plane_helper_cleanup_fb,\n\t.atomic_check = dm_plane_atomic_check,\n\t.atomic_async_check = dm_plane_atomic_async_check,\n\t.atomic_async_update = dm_plane_atomic_async_update\n};\n\nstatic void dm_drm_plane_reset(struct drm_plane *plane)\n{\n\tstruct dm_plane_state *amdgpu_state = NULL;\n\n\tif (plane->state)\n\t\tplane->funcs->atomic_destroy_state(plane, plane->state);\n\n\tamdgpu_state = kzalloc(sizeof(*amdgpu_state), GFP_KERNEL);\n\tWARN_ON(amdgpu_state == NULL);\n\n\tif (amdgpu_state)\n\t\t__drm_atomic_helper_plane_reset(plane, &amdgpu_state->base);\n}\n\nstatic struct drm_plane_state *\ndm_drm_plane_duplicate_state(struct drm_plane *plane)\n{\n\tstruct dm_plane_state *dm_plane_state, *old_dm_plane_state;\n\n\told_dm_plane_state = to_dm_plane_state(plane->state);\n\tdm_plane_state = kzalloc(sizeof(*dm_plane_state), GFP_KERNEL);\n\tif (!dm_plane_state)\n\t\treturn NULL;\n\n\t__drm_atomic_helper_plane_duplicate_state(plane, &dm_plane_state->base);\n\n\tif (old_dm_plane_state->dc_state) {\n\t\tdm_plane_state->dc_state = old_dm_plane_state->dc_state;\n\t\tdc_plane_state_retain(dm_plane_state->dc_state);\n\t}\n\n\treturn &dm_plane_state->base;\n}\n\nstatic bool dm_plane_format_mod_supported(struct drm_plane *plane,\n\t\t\t\t\t  uint32_t format,\n\t\t\t\t\t  uint64_t modifier)\n{\n\tstruct amdgpu_device *adev = drm_to_adev(plane->dev);\n\tconst struct drm_format_info *info = drm_format_info(format);\n\tint i;\n\n\tenum dm_micro_swizzle microtile = modifier_gfx9_swizzle_mode(modifier) & 3;\n\n\tif (!info)\n\t\treturn false;\n\n\t \n\tif (modifier == DRM_FORMAT_MOD_LINEAR ||\n\t    modifier == DRM_FORMAT_MOD_INVALID) {\n\t\treturn true;\n\t}\n\n\t \n\tfor (i = 0; i < plane->modifier_count; i++) {\n\t\tif (modifier == plane->modifiers[i])\n\t\t\tbreak;\n\t}\n\tif (i == plane->modifier_count)\n\t\treturn false;\n\n\t \n\tif (AMD_FMT_MOD_GET(TILE_VERSION, modifier) == AMD_FMT_MOD_TILE_VER_GFX9 &&\n\t    adev->family >= AMDGPU_FAMILY_NV) {\n\t\tif (microtile == MICRO_SWIZZLE_D && info->cpp[0] == 4)\n\t\t\treturn false;\n\t}\n\n\tif (adev->family >= AMDGPU_FAMILY_RV && microtile == MICRO_SWIZZLE_D &&\n\t    info->cpp[0] < 8)\n\t\treturn false;\n\n\tif (modifier_has_dcc(modifier)) {\n\t\t \n\t\tif (info->cpp[0] != 4)\n\t\t\treturn false;\n\t\t \n\t\tif (info->num_planes > 1)\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void dm_drm_plane_destroy_state(struct drm_plane *plane,\n\t\t\t\tstruct drm_plane_state *state)\n{\n\tstruct dm_plane_state *dm_plane_state = to_dm_plane_state(state);\n\n\tif (dm_plane_state->dc_state)\n\t\tdc_plane_state_release(dm_plane_state->dc_state);\n\n\tdrm_atomic_helper_plane_destroy_state(plane, state);\n}\n\nstatic const struct drm_plane_funcs dm_plane_funcs = {\n\t.update_plane\t= drm_atomic_helper_update_plane,\n\t.disable_plane\t= drm_atomic_helper_disable_plane,\n\t.destroy\t= drm_plane_helper_destroy,\n\t.reset = dm_drm_plane_reset,\n\t.atomic_duplicate_state = dm_drm_plane_duplicate_state,\n\t.atomic_destroy_state = dm_drm_plane_destroy_state,\n\t.format_mod_supported = dm_plane_format_mod_supported,\n};\n\nint amdgpu_dm_plane_init(struct amdgpu_display_manager *dm,\n\t\t\t\tstruct drm_plane *plane,\n\t\t\t\tunsigned long possible_crtcs,\n\t\t\t\tconst struct dc_plane_cap *plane_cap)\n{\n\tuint32_t formats[32];\n\tint num_formats;\n\tint res = -EPERM;\n\tunsigned int supported_rotations;\n\tuint64_t *modifiers = NULL;\n\n\tnum_formats = get_plane_formats(plane, plane_cap, formats,\n\t\t\t\t\tARRAY_SIZE(formats));\n\n\tres = get_plane_modifiers(dm->adev, plane->type, &modifiers);\n\tif (res)\n\t\treturn res;\n\n\tif (modifiers == NULL)\n\t\tadev_to_drm(dm->adev)->mode_config.fb_modifiers_not_supported = true;\n\n\tres = drm_universal_plane_init(adev_to_drm(dm->adev), plane, possible_crtcs,\n\t\t\t\t       &dm_plane_funcs, formats, num_formats,\n\t\t\t\t       modifiers, plane->type, NULL);\n\tkfree(modifiers);\n\tif (res)\n\t\treturn res;\n\n\tif (plane->type == DRM_PLANE_TYPE_OVERLAY &&\n\t    plane_cap && plane_cap->per_pixel_alpha) {\n\t\tunsigned int blend_caps = BIT(DRM_MODE_BLEND_PIXEL_NONE) |\n\t\t\t\t\t  BIT(DRM_MODE_BLEND_PREMULTI) |\n\t\t\t\t\t  BIT(DRM_MODE_BLEND_COVERAGE);\n\n\t\tdrm_plane_create_alpha_property(plane);\n\t\tdrm_plane_create_blend_mode_property(plane, blend_caps);\n\t}\n\n\tif (plane->type == DRM_PLANE_TYPE_PRIMARY) {\n\t\tdrm_plane_create_zpos_immutable_property(plane, 0);\n\t} else if (plane->type == DRM_PLANE_TYPE_OVERLAY) {\n\t\tunsigned int zpos = 1 + drm_plane_index(plane);\n\t\tdrm_plane_create_zpos_property(plane, zpos, 1, 254);\n\t} else if (plane->type == DRM_PLANE_TYPE_CURSOR) {\n\t\tdrm_plane_create_zpos_immutable_property(plane, 255);\n\t}\n\n\tif (plane->type == DRM_PLANE_TYPE_PRIMARY &&\n\t    plane_cap &&\n\t    (plane_cap->pixel_format_support.nv12 ||\n\t     plane_cap->pixel_format_support.p010)) {\n\t\t \n\t\tdrm_plane_create_color_properties(\n\t\t\tplane,\n\t\t\tBIT(DRM_COLOR_YCBCR_BT601) |\n\t\t\tBIT(DRM_COLOR_YCBCR_BT709) |\n\t\t\tBIT(DRM_COLOR_YCBCR_BT2020),\n\t\t\tBIT(DRM_COLOR_YCBCR_LIMITED_RANGE) |\n\t\t\tBIT(DRM_COLOR_YCBCR_FULL_RANGE),\n\t\t\tDRM_COLOR_YCBCR_BT709, DRM_COLOR_YCBCR_LIMITED_RANGE);\n\t}\n\n\tsupported_rotations =\n\t\tDRM_MODE_ROTATE_0 | DRM_MODE_ROTATE_90 |\n\t\tDRM_MODE_ROTATE_180 | DRM_MODE_ROTATE_270;\n\n\tif (dm->adev->asic_type >= CHIP_BONAIRE &&\n\t    plane->type != DRM_PLANE_TYPE_CURSOR)\n\t\tdrm_plane_create_rotation_property(plane, DRM_MODE_ROTATE_0,\n\t\t\t\t\t\t   supported_rotations);\n\n\tif (dm->adev->ip_versions[DCE_HWIP][0] > IP_VERSION(3, 0, 1) &&\n\t    plane->type != DRM_PLANE_TYPE_CURSOR)\n\t\tdrm_plane_enable_fb_damage_clips(plane);\n\n\tdrm_plane_helper_add(plane, &dm_plane_helper_funcs);\n\n\t \n\tif (plane->funcs->reset)\n\t\tplane->funcs->reset(plane);\n\n\treturn 0;\n}\n\nbool is_video_format(uint32_t format)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(video_formats); i++)\n\t\tif (format == video_formats[i])\n\t\t\treturn true;\n\n\treturn false;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}