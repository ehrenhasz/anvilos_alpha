{
  "module_name": "kfd_device_queue_manager.h",
  "hash_id": "33104b046e9e88a57e95053db3897823f02d317c03a6451c072940c0efc4b905",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdkfd/kfd_device_queue_manager.h",
  "human_readable_source": " \n \n\n#ifndef KFD_DEVICE_QUEUE_MANAGER_H_\n#define KFD_DEVICE_QUEUE_MANAGER_H_\n\n#include <linux/rwsem.h>\n#include <linux/list.h>\n#include <linux/mutex.h>\n#include <linux/sched/mm.h>\n#include \"kfd_priv.h\"\n#include \"kfd_mqd_manager.h\"\n\n\n#define VMID_NUM 16\n\n#define KFD_MES_PROCESS_QUANTUM\t\t100000\n#define KFD_MES_GANG_QUANTUM\t\t10000\n#define USE_DEFAULT_GRACE_PERIOD 0xffffffff\n\nstruct device_process_node {\n\tstruct qcm_process_device *qpd;\n\tstruct list_head list;\n};\n\nunion SQ_CMD_BITS {\n\tstruct {\n\t\tuint32_t cmd:3;\n\t\tuint32_t:1;\n\t\tuint32_t mode:3;\n\t\tuint32_t check_vmid:1;\n\t\tuint32_t trap_id:3;\n\t\tuint32_t:5;\n\t\tuint32_t wave_id:4;\n\t\tuint32_t simd_id:2;\n\t\tuint32_t:2;\n\t\tuint32_t queue_id:3;\n\t\tuint32_t:1;\n\t\tuint32_t vm_id:4;\n\t} bitfields, bits;\n\tuint32_t u32All;\n\tsigned int i32All;\n\tfloat f32All;\n};\n\nunion GRBM_GFX_INDEX_BITS {\n\tstruct {\n\t\tuint32_t instance_index:8;\n\t\tuint32_t sh_index:8;\n\t\tuint32_t se_index:8;\n\t\tuint32_t:5;\n\t\tuint32_t sh_broadcast_writes:1;\n\t\tuint32_t instance_broadcast_writes:1;\n\t\tuint32_t se_broadcast_writes:1;\n\t} bitfields, bits;\n\tuint32_t u32All;\n\tsigned int i32All;\n\tfloat f32All;\n};\n\n \n\nstruct device_queue_manager_ops {\n\tint\t(*create_queue)(struct device_queue_manager *dqm,\n\t\t\t\tstruct queue *q,\n\t\t\t\tstruct qcm_process_device *qpd,\n\t\t\t\tconst struct kfd_criu_queue_priv_data *qd,\n\t\t\t\tconst void *restore_mqd,\n\t\t\t\tconst void *restore_ctl_stack);\n\n\tint\t(*destroy_queue)(struct device_queue_manager *dqm,\n\t\t\t\tstruct qcm_process_device *qpd,\n\t\t\t\tstruct queue *q);\n\n\tint\t(*update_queue)(struct device_queue_manager *dqm,\n\t\t\t\tstruct queue *q, struct mqd_update_info *minfo);\n\n\tint\t(*register_process)(struct device_queue_manager *dqm,\n\t\t\t\t\tstruct qcm_process_device *qpd);\n\n\tint\t(*unregister_process)(struct device_queue_manager *dqm,\n\t\t\t\t\tstruct qcm_process_device *qpd);\n\n\tint\t(*initialize)(struct device_queue_manager *dqm);\n\tint\t(*start)(struct device_queue_manager *dqm);\n\tint\t(*stop)(struct device_queue_manager *dqm);\n\tvoid\t(*pre_reset)(struct device_queue_manager *dqm);\n\tvoid\t(*uninitialize)(struct device_queue_manager *dqm);\n\tint\t(*create_kernel_queue)(struct device_queue_manager *dqm,\n\t\t\t\t\tstruct kernel_queue *kq,\n\t\t\t\t\tstruct qcm_process_device *qpd);\n\n\tvoid\t(*destroy_kernel_queue)(struct device_queue_manager *dqm,\n\t\t\t\t\tstruct kernel_queue *kq,\n\t\t\t\t\tstruct qcm_process_device *qpd);\n\n\tbool\t(*set_cache_memory_policy)(struct device_queue_manager *dqm,\n\t\t\t\t\t   struct qcm_process_device *qpd,\n\t\t\t\t\t   enum cache_policy default_policy,\n\t\t\t\t\t   enum cache_policy alternate_policy,\n\t\t\t\t\t   void __user *alternate_aperture_base,\n\t\t\t\t\t   uint64_t alternate_aperture_size);\n\n\tint (*process_termination)(struct device_queue_manager *dqm,\n\t\t\tstruct qcm_process_device *qpd);\n\n\tint (*evict_process_queues)(struct device_queue_manager *dqm,\n\t\t\t\t    struct qcm_process_device *qpd);\n\tint (*restore_process_queues)(struct device_queue_manager *dqm,\n\t\t\t\t      struct qcm_process_device *qpd);\n\n\tint\t(*get_wave_state)(struct device_queue_manager *dqm,\n\t\t\t\t  struct queue *q,\n\t\t\t\t  void __user *ctl_stack,\n\t\t\t\t  u32 *ctl_stack_used_size,\n\t\t\t\t  u32 *save_area_used_size);\n\n\tint (*reset_queues)(struct device_queue_manager *dqm,\n\t\t\t\t\tuint16_t pasid);\n\tvoid\t(*get_queue_checkpoint_info)(struct device_queue_manager *dqm,\n\t\t\t\t  const struct queue *q, u32 *mqd_size,\n\t\t\t\t  u32 *ctl_stack_size);\n\n\tint\t(*checkpoint_mqd)(struct device_queue_manager *dqm,\n\t\t\t\t  const struct queue *q,\n\t\t\t\t  void *mqd,\n\t\t\t\t  void *ctl_stack);\n};\n\nstruct device_queue_manager_asic_ops {\n\tint\t(*update_qpd)(struct device_queue_manager *dqm,\n\t\t\t\t\tstruct qcm_process_device *qpd);\n\tbool\t(*set_cache_memory_policy)(struct device_queue_manager *dqm,\n\t\t\t\t\t   struct qcm_process_device *qpd,\n\t\t\t\t\t   enum cache_policy default_policy,\n\t\t\t\t\t   enum cache_policy alternate_policy,\n\t\t\t\t\t   void __user *alternate_aperture_base,\n\t\t\t\t\t   uint64_t alternate_aperture_size);\n\tvoid\t(*init_sdma_vm)(struct device_queue_manager *dqm,\n\t\t\t\tstruct queue *q,\n\t\t\t\tstruct qcm_process_device *qpd);\n\tstruct mqd_manager *\t(*mqd_manager_init)(enum KFD_MQD_TYPE type,\n\t\t\t\t struct kfd_node *dev);\n};\n\n \n\nstruct device_queue_manager {\n\tstruct device_queue_manager_ops ops;\n\tstruct device_queue_manager_asic_ops asic_ops;\n\n\tstruct mqd_manager\t*mqd_mgrs[KFD_MQD_TYPE_MAX];\n\tstruct packet_manager\tpacket_mgr;\n\tstruct kfd_node\t\t*dev;\n\tstruct mutex\t\tlock_hidden;  \n\tstruct list_head\tqueues;\n\tunsigned int\t\tsaved_flags;\n\tunsigned int\t\tprocesses_count;\n\tunsigned int\t\tactive_queue_count;\n\tunsigned int\t\tactive_cp_queue_count;\n\tunsigned int\t\tgws_queue_count;\n\tunsigned int\t\ttotal_queue_count;\n\tunsigned int\t\tnext_pipe_to_allocate;\n\tunsigned int\t\t*allocated_queues;\n\tDECLARE_BITMAP(sdma_bitmap, KFD_MAX_SDMA_QUEUES);\n\tDECLARE_BITMAP(xgmi_sdma_bitmap, KFD_MAX_SDMA_QUEUES);\n\t \n\tuint16_t\t\tvmid_pasid[VMID_NUM];\n\tuint64_t\t\tpipelines_addr;\n\tuint64_t\t\tfence_gpu_addr;\n\tuint64_t\t\t*fence_addr;\n\tstruct kfd_mem_obj\t*fence_mem;\n\tbool\t\t\tactive_runlist;\n\tint\t\t\tsched_policy;\n\tuint32_t\t\ttrap_debug_vmid;\n\n\t \n\tbool\t\t\tis_hws_hang;\n\tbool\t\t\tis_resetting;\n\tstruct work_struct\thw_exception_work;\n\tstruct kfd_mem_obj\thiq_sdma_mqd;\n\tbool\t\t\tsched_running;\n\n\t \n\tuint32_t\t\tcurrent_logical_xcc_start;\n\n\tuint32_t\t\twait_times;\n\n\twait_queue_head_t\tdestroy_wait;\n};\n\nvoid device_queue_manager_init_cik(\n\t\tstruct device_queue_manager_asic_ops *asic_ops);\nvoid device_queue_manager_init_vi(\n\t\tstruct device_queue_manager_asic_ops *asic_ops);\nvoid device_queue_manager_init_v9(\n\t\tstruct device_queue_manager_asic_ops *asic_ops);\nvoid device_queue_manager_init_v10(\n\t\tstruct device_queue_manager_asic_ops *asic_ops);\nvoid device_queue_manager_init_v11(\n\t\tstruct device_queue_manager_asic_ops *asic_ops);\nvoid program_sh_mem_settings(struct device_queue_manager *dqm,\n\t\t\t\t\tstruct qcm_process_device *qpd);\nunsigned int get_cp_queues_num(struct device_queue_manager *dqm);\nunsigned int get_queues_per_pipe(struct device_queue_manager *dqm);\nunsigned int get_pipes_per_mec(struct device_queue_manager *dqm);\nunsigned int get_num_sdma_queues(struct device_queue_manager *dqm);\nunsigned int get_num_xgmi_sdma_queues(struct device_queue_manager *dqm);\nint reserve_debug_trap_vmid(struct device_queue_manager *dqm,\n\t\t\tstruct qcm_process_device *qpd);\nint release_debug_trap_vmid(struct device_queue_manager *dqm,\n\t\t\tstruct qcm_process_device *qpd);\nint suspend_queues(struct kfd_process *p,\n\t\t\tuint32_t num_queues,\n\t\t\tuint32_t grace_period,\n\t\t\tuint64_t exception_clear_mask,\n\t\t\tuint32_t *usr_queue_id_array);\nint resume_queues(struct kfd_process *p,\n\t\tuint32_t num_queues,\n\t\tuint32_t *usr_queue_id_array);\nvoid set_queue_snapshot_entry(struct queue *q,\n\t\t\t      uint64_t exception_clear_mask,\n\t\t\t      struct kfd_queue_snapshot_entry *qss_entry);\nint debug_lock_and_unmap(struct device_queue_manager *dqm);\nint debug_map_and_unlock(struct device_queue_manager *dqm);\nint debug_refresh_runlist(struct device_queue_manager *dqm);\n\nstatic inline unsigned int get_sh_mem_bases_32(struct kfd_process_device *pdd)\n{\n\treturn (pdd->lds_base >> 16) & 0xFF;\n}\n\nstatic inline unsigned int\nget_sh_mem_bases_nybble_64(struct kfd_process_device *pdd)\n{\n\treturn (pdd->lds_base >> 60) & 0x0E;\n}\n\n \nstatic inline void dqm_lock(struct device_queue_manager *dqm)\n{\n\tmutex_lock(&dqm->lock_hidden);\n\tdqm->saved_flags = memalloc_noreclaim_save();\n}\nstatic inline void dqm_unlock(struct device_queue_manager *dqm)\n{\n\tmemalloc_noreclaim_restore(dqm->saved_flags);\n\tmutex_unlock(&dqm->lock_hidden);\n}\n\nstatic inline int read_sdma_queue_counter(uint64_t __user *q_rptr, uint64_t *val)\n{\n\t \n\treturn get_user(*val, q_rptr + 1);\n}\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}