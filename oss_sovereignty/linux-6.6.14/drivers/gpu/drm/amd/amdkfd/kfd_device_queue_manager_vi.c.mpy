{
  "module_name": "kfd_device_queue_manager_vi.c",
  "hash_id": "5c6ee6252bbace4fd4dd20bb214614e43f33fe6bd30046f40d32c26399e4c86c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdkfd/kfd_device_queue_manager_vi.c",
  "human_readable_source": "\n \n\n#include \"kfd_device_queue_manager.h\"\n#include \"gca/gfx_8_0_enum.h\"\n#include \"gca/gfx_8_0_sh_mask.h\"\n#include \"oss/oss_3_0_sh_mask.h\"\n\nstatic bool set_cache_memory_policy_vi(struct device_queue_manager *dqm,\n\t\t\t\t       struct qcm_process_device *qpd,\n\t\t\t\t       enum cache_policy default_policy,\n\t\t\t\t       enum cache_policy alternate_policy,\n\t\t\t\t       void __user *alternate_aperture_base,\n\t\t\t\t       uint64_t alternate_aperture_size);\nstatic int update_qpd_vi(struct device_queue_manager *dqm,\n\t\t\t struct qcm_process_device *qpd);\nstatic void init_sdma_vm(struct device_queue_manager *dqm,\n\t\t\t struct queue *q,\n\t\t\t struct qcm_process_device *qpd);\n\nvoid device_queue_manager_init_vi(\n\tstruct device_queue_manager_asic_ops *asic_ops)\n{\n\tasic_ops->set_cache_memory_policy = set_cache_memory_policy_vi;\n\tasic_ops->update_qpd = update_qpd_vi;\n\tasic_ops->init_sdma_vm = init_sdma_vm;\n\tasic_ops->mqd_manager_init = mqd_manager_init_vi;\n}\n\nstatic uint32_t compute_sh_mem_bases_64bit(unsigned int top_address_nybble)\n{\n\t \n\n\tWARN_ON((top_address_nybble & 1) || top_address_nybble > 0xE ||\n\t\ttop_address_nybble == 0);\n\n\treturn top_address_nybble << 12 |\n\t\t\t(top_address_nybble << 12) <<\n\t\t\tSH_MEM_BASES__SHARED_BASE__SHIFT;\n}\n\nstatic bool set_cache_memory_policy_vi(struct device_queue_manager *dqm,\n\t\tstruct qcm_process_device *qpd,\n\t\tenum cache_policy default_policy,\n\t\tenum cache_policy alternate_policy,\n\t\tvoid __user *alternate_aperture_base,\n\t\tuint64_t alternate_aperture_size)\n{\n\tuint32_t default_mtype;\n\tuint32_t ape1_mtype;\n\n\tdefault_mtype = (default_policy == cache_policy_coherent) ?\n\t\t\tMTYPE_UC :\n\t\t\tMTYPE_NC;\n\n\tape1_mtype = (alternate_policy == cache_policy_coherent) ?\n\t\t\tMTYPE_UC :\n\t\t\tMTYPE_NC;\n\n\tqpd->sh_mem_config =\n\t\t\tSH_MEM_ALIGNMENT_MODE_UNALIGNED <<\n\t\t\t\t   SH_MEM_CONFIG__ALIGNMENT_MODE__SHIFT |\n\t\t\tdefault_mtype << SH_MEM_CONFIG__DEFAULT_MTYPE__SHIFT |\n\t\t\tape1_mtype << SH_MEM_CONFIG__APE1_MTYPE__SHIFT;\n\n\treturn true;\n}\n\nstatic int update_qpd_vi(struct device_queue_manager *dqm,\n\t\t\t struct qcm_process_device *qpd)\n{\n\tstruct kfd_process_device *pdd;\n\tunsigned int temp;\n\n\tpdd = qpd_to_pdd(qpd);\n\n\t \n\tif (qpd->sh_mem_config == 0) {\n\t\tqpd->sh_mem_config =\n\t\t\t\tSH_MEM_ALIGNMENT_MODE_UNALIGNED <<\n\t\t\t\t\tSH_MEM_CONFIG__ALIGNMENT_MODE__SHIFT |\n\t\t\t\tMTYPE_UC <<\n\t\t\t\t\tSH_MEM_CONFIG__DEFAULT_MTYPE__SHIFT |\n\t\t\t\tMTYPE_UC <<\n\t\t\t\t\tSH_MEM_CONFIG__APE1_MTYPE__SHIFT;\n\n\t\tqpd->sh_mem_ape1_limit = 0;\n\t\tqpd->sh_mem_ape1_base = 0;\n\t}\n\n\t \n\ttemp = get_sh_mem_bases_nybble_64(pdd);\n\tqpd->sh_mem_bases = compute_sh_mem_bases_64bit(temp);\n\n\tpr_debug(\"sh_mem_bases nybble: 0x%X and register 0x%X\\n\",\n\t\ttemp, qpd->sh_mem_bases);\n\n\treturn 0;\n}\n\nstatic void init_sdma_vm(struct device_queue_manager *dqm,\n\t\t\t struct queue *q,\n\t\t\t struct qcm_process_device *qpd)\n{\n\t \n\tq->properties.sdma_vm_addr =\n\t\t((get_sh_mem_bases_nybble_64(qpd_to_pdd(qpd))) <<\n\t\t SDMA0_RLC0_VIRTUAL_ADDR__SHARED_BASE__SHIFT) &\n\t\tSDMA0_RLC0_VIRTUAL_ADDR__SHARED_BASE_MASK;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}