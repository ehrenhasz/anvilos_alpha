{
  "module_name": "kfd_process_queue_manager.c",
  "hash_id": "9ef9a040bd2626f76fc8330d9c9597cbb4910f26fd9c07e247978c8d1c8e9378",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdkfd/kfd_process_queue_manager.c",
  "human_readable_source": "\n \n\n#include <linux/slab.h>\n#include <linux/list.h>\n#include \"kfd_device_queue_manager.h\"\n#include \"kfd_priv.h\"\n#include \"kfd_kernel_queue.h\"\n#include \"amdgpu_amdkfd.h\"\n\nstatic inline struct process_queue_node *get_queue_by_qid(\n\t\t\tstruct process_queue_manager *pqm, unsigned int qid)\n{\n\tstruct process_queue_node *pqn;\n\n\tlist_for_each_entry(pqn, &pqm->queues, process_queue_list) {\n\t\tif ((pqn->q && pqn->q->properties.queue_id == qid) ||\n\t\t    (pqn->kq && pqn->kq->queue->properties.queue_id == qid))\n\t\t\treturn pqn;\n\t}\n\n\treturn NULL;\n}\n\nstatic int assign_queue_slot_by_qid(struct process_queue_manager *pqm,\n\t\t\t\t    unsigned int qid)\n{\n\tif (qid >= KFD_MAX_NUM_OF_QUEUES_PER_PROCESS)\n\t\treturn -EINVAL;\n\n\tif (__test_and_set_bit(qid, pqm->queue_slot_bitmap)) {\n\t\tpr_err(\"Cannot create new queue because requested qid(%u) is in use\\n\", qid);\n\t\treturn -ENOSPC;\n\t}\n\n\treturn 0;\n}\n\nstatic int find_available_queue_slot(struct process_queue_manager *pqm,\n\t\t\t\t\tunsigned int *qid)\n{\n\tunsigned long found;\n\n\tfound = find_first_zero_bit(pqm->queue_slot_bitmap,\n\t\t\tKFD_MAX_NUM_OF_QUEUES_PER_PROCESS);\n\n\tpr_debug(\"The new slot id %lu\\n\", found);\n\n\tif (found >= KFD_MAX_NUM_OF_QUEUES_PER_PROCESS) {\n\t\tpr_info(\"Cannot open more queues for process with pasid 0x%x\\n\",\n\t\t\t\tpqm->process->pasid);\n\t\treturn -ENOMEM;\n\t}\n\n\tset_bit(found, pqm->queue_slot_bitmap);\n\t*qid = found;\n\n\treturn 0;\n}\n\nvoid kfd_process_dequeue_from_device(struct kfd_process_device *pdd)\n{\n\tstruct kfd_node *dev = pdd->dev;\n\n\tif (pdd->already_dequeued)\n\t\treturn;\n\n\tdev->dqm->ops.process_termination(dev->dqm, &pdd->qpd);\n\tpdd->already_dequeued = true;\n}\n\nint pqm_set_gws(struct process_queue_manager *pqm, unsigned int qid,\n\t\t\tvoid *gws)\n{\n\tstruct kfd_node *dev = NULL;\n\tstruct process_queue_node *pqn;\n\tstruct kfd_process_device *pdd;\n\tstruct kgd_mem *mem = NULL;\n\tint ret;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (!pqn) {\n\t\tpr_err(\"Queue id does not match any known queue\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (pqn->q)\n\t\tdev = pqn->q->device;\n\tif (WARN_ON(!dev))\n\t\treturn -ENODEV;\n\n\tpdd = kfd_get_process_device_data(dev, pqm->process);\n\tif (!pdd) {\n\t\tpr_err(\"Process device data doesn't exist\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (gws && pdd->qpd.num_gws)\n\t\treturn -EBUSY;\n\n\tif (!gws && pdd->qpd.num_gws == 0)\n\t\treturn -EINVAL;\n\n\tif (KFD_GC_VERSION(dev) != IP_VERSION(9, 4, 3) && !dev->kfd->shared_resources.enable_mes) {\n\t\tif (gws)\n\t\t\tret = amdgpu_amdkfd_add_gws_to_process(pdd->process->kgd_process_info,\n\t\t\t\tgws, &mem);\n\t\telse\n\t\t\tret = amdgpu_amdkfd_remove_gws_from_process(pdd->process->kgd_process_info,\n\t\t\t\tpqn->q->gws);\n\t\tif (unlikely(ret))\n\t\t\treturn ret;\n\t\tpqn->q->gws = mem;\n\t} else {\n\t\t \n\t\tpqn->q->gws = gws ? ERR_PTR(-ENOMEM) : NULL;\n\t}\n\n\tpdd->qpd.num_gws = gws ? dev->adev->gds.gws_size : 0;\n\n\treturn pqn->q->device->dqm->ops.update_queue(pqn->q->device->dqm,\n\t\t\t\t\t\t\tpqn->q, NULL);\n}\n\nvoid kfd_process_dequeue_from_all_devices(struct kfd_process *p)\n{\n\tint i;\n\n\tfor (i = 0; i < p->n_pdds; i++)\n\t\tkfd_process_dequeue_from_device(p->pdds[i]);\n}\n\nint pqm_init(struct process_queue_manager *pqm, struct kfd_process *p)\n{\n\tINIT_LIST_HEAD(&pqm->queues);\n\tpqm->queue_slot_bitmap = bitmap_zalloc(KFD_MAX_NUM_OF_QUEUES_PER_PROCESS,\n\t\t\t\t\t       GFP_KERNEL);\n\tif (!pqm->queue_slot_bitmap)\n\t\treturn -ENOMEM;\n\tpqm->process = p;\n\n\treturn 0;\n}\n\nstatic void pqm_clean_queue_resource(struct process_queue_manager *pqm,\n\t\t\t\t     struct process_queue_node *pqn)\n{\n\tstruct kfd_node *dev;\n\tstruct kfd_process_device *pdd;\n\n\tdev = pqn->q->device;\n\n\tpdd = kfd_get_process_device_data(dev, pqm->process);\n\tif (!pdd) {\n\t\tpr_err(\"Process device data doesn't exist\\n\");\n\t\treturn;\n\t}\n\n\tif (pqn->q->gws) {\n\t\tif (KFD_GC_VERSION(pqn->q->device) != IP_VERSION(9, 4, 3) &&\n\t\t    !dev->kfd->shared_resources.enable_mes)\n\t\t\tamdgpu_amdkfd_remove_gws_from_process(\n\t\t\t\tpqm->process->kgd_process_info, pqn->q->gws);\n\t\tpdd->qpd.num_gws = 0;\n\t}\n\n\tif (dev->kfd->shared_resources.enable_mes) {\n\t\tamdgpu_amdkfd_free_gtt_mem(dev->adev, pqn->q->gang_ctx_bo);\n\t\tif (pqn->q->wptr_bo)\n\t\t\tamdgpu_amdkfd_free_gtt_mem(dev->adev, pqn->q->wptr_bo);\n\t}\n}\n\nvoid pqm_uninit(struct process_queue_manager *pqm)\n{\n\tstruct process_queue_node *pqn, *next;\n\n\tlist_for_each_entry_safe(pqn, next, &pqm->queues, process_queue_list) {\n\t\tif (pqn->q)\n\t\t\tpqm_clean_queue_resource(pqm, pqn);\n\n\t\tkfd_procfs_del_queue(pqn->q);\n\t\tuninit_queue(pqn->q);\n\t\tlist_del(&pqn->process_queue_list);\n\t\tkfree(pqn);\n\t}\n\n\tbitmap_free(pqm->queue_slot_bitmap);\n\tpqm->queue_slot_bitmap = NULL;\n}\n\nstatic int init_user_queue(struct process_queue_manager *pqm,\n\t\t\t\tstruct kfd_node *dev, struct queue **q,\n\t\t\t\tstruct queue_properties *q_properties,\n\t\t\t\tstruct file *f, struct amdgpu_bo *wptr_bo,\n\t\t\t\tunsigned int qid)\n{\n\tint retval;\n\n\t \n\tq_properties->doorbell_ptr = NULL;\n\tq_properties->exception_status = KFD_EC_MASK(EC_QUEUE_NEW);\n\n\t \n\tq_properties->vmid = 0;\n\tq_properties->queue_id = qid;\n\n\tretval = init_queue(q, q_properties);\n\tif (retval != 0)\n\t\treturn retval;\n\n\t(*q)->device = dev;\n\t(*q)->process = pqm->process;\n\n\tif (dev->kfd->shared_resources.enable_mes) {\n\t\tretval = amdgpu_amdkfd_alloc_gtt_mem(dev->adev,\n\t\t\t\t\t\tAMDGPU_MES_GANG_CTX_SIZE,\n\t\t\t\t\t\t&(*q)->gang_ctx_bo,\n\t\t\t\t\t\t&(*q)->gang_ctx_gpu_addr,\n\t\t\t\t\t\t&(*q)->gang_ctx_cpu_ptr,\n\t\t\t\t\t\tfalse);\n\t\tif (retval) {\n\t\t\tpr_err(\"failed to allocate gang context bo\\n\");\n\t\t\tgoto cleanup;\n\t\t}\n\t\tmemset((*q)->gang_ctx_cpu_ptr, 0, AMDGPU_MES_GANG_CTX_SIZE);\n\t\t(*q)->wptr_bo = wptr_bo;\n\t}\n\n\tpr_debug(\"PQM After init queue\");\n\treturn 0;\n\ncleanup:\n\tuninit_queue(*q);\n\t*q = NULL;\n\treturn retval;\n}\n\nint pqm_create_queue(struct process_queue_manager *pqm,\n\t\t\t    struct kfd_node *dev,\n\t\t\t    struct file *f,\n\t\t\t    struct queue_properties *properties,\n\t\t\t    unsigned int *qid,\n\t\t\t    struct amdgpu_bo *wptr_bo,\n\t\t\t    const struct kfd_criu_queue_priv_data *q_data,\n\t\t\t    const void *restore_mqd,\n\t\t\t    const void *restore_ctl_stack,\n\t\t\t    uint32_t *p_doorbell_offset_in_process)\n{\n\tint retval;\n\tstruct kfd_process_device *pdd;\n\tstruct queue *q;\n\tstruct process_queue_node *pqn;\n\tstruct kernel_queue *kq;\n\tenum kfd_queue_type type = properties->type;\n\tunsigned int max_queues = 127;  \n\n\t \n\tif (KFD_GC_VERSION(dev) == IP_VERSION(9, 4, 3))\n\t\tmax_queues = 255;\n\n\tq = NULL;\n\tkq = NULL;\n\n\tpdd = kfd_get_process_device_data(dev, pqm->process);\n\tif (!pdd) {\n\t\tpr_err(\"Process device data doesn't exist\\n\");\n\t\treturn -1;\n\t}\n\n\t \n\tif ((pdd->qpd.is_debug) || (type == KFD_QUEUE_TYPE_DIQ))\n\t\tmax_queues = dev->kfd->device_info.max_no_of_hqd/2;\n\n\tif (pdd->qpd.queue_count >= max_queues)\n\t\treturn -ENOSPC;\n\n\tif (q_data) {\n\t\tretval = assign_queue_slot_by_qid(pqm, q_data->q_id);\n\t\t*qid = q_data->q_id;\n\t} else\n\t\tretval = find_available_queue_slot(pqm, qid);\n\n\tif (retval != 0)\n\t\treturn retval;\n\n\tif (list_empty(&pdd->qpd.queues_list) &&\n\t    list_empty(&pdd->qpd.priv_queue_list))\n\t\tdev->dqm->ops.register_process(dev->dqm, &pdd->qpd);\n\n\tpqn = kzalloc(sizeof(*pqn), GFP_KERNEL);\n\tif (!pqn) {\n\t\tretval = -ENOMEM;\n\t\tgoto err_allocate_pqn;\n\t}\n\n\tswitch (type) {\n\tcase KFD_QUEUE_TYPE_SDMA:\n\tcase KFD_QUEUE_TYPE_SDMA_XGMI:\n\t\t \n\t\tretval = init_user_queue(pqm, dev, &q, properties, f, wptr_bo, *qid);\n\t\tif (retval != 0)\n\t\t\tgoto err_create_queue;\n\t\tpqn->q = q;\n\t\tpqn->kq = NULL;\n\t\tretval = dev->dqm->ops.create_queue(dev->dqm, q, &pdd->qpd, q_data,\n\t\t\t\t\t\t    restore_mqd, restore_ctl_stack);\n\t\tprint_queue(q);\n\t\tbreak;\n\n\tcase KFD_QUEUE_TYPE_COMPUTE:\n\t\t \n\t\tif ((dev->dqm->sched_policy ==\n\t\t     KFD_SCHED_POLICY_HWS_NO_OVERSUBSCRIPTION) &&\n\t\t((dev->dqm->processes_count >= dev->vm_info.vmid_num_kfd) ||\n\t\t(dev->dqm->active_queue_count >= get_cp_queues_num(dev->dqm)))) {\n\t\t\tpr_debug(\"Over-subscription is not allowed when amdkfd.sched_policy == 1\\n\");\n\t\t\tretval = -EPERM;\n\t\t\tgoto err_create_queue;\n\t\t}\n\n\t\tretval = init_user_queue(pqm, dev, &q, properties, f, wptr_bo, *qid);\n\t\tif (retval != 0)\n\t\t\tgoto err_create_queue;\n\t\tpqn->q = q;\n\t\tpqn->kq = NULL;\n\t\tretval = dev->dqm->ops.create_queue(dev->dqm, q, &pdd->qpd, q_data,\n\t\t\t\t\t\t    restore_mqd, restore_ctl_stack);\n\t\tprint_queue(q);\n\t\tbreak;\n\tcase KFD_QUEUE_TYPE_DIQ:\n\t\tkq = kernel_queue_init(dev, KFD_QUEUE_TYPE_DIQ);\n\t\tif (!kq) {\n\t\t\tretval = -ENOMEM;\n\t\t\tgoto err_create_queue;\n\t\t}\n\t\tkq->queue->properties.queue_id = *qid;\n\t\tpqn->kq = kq;\n\t\tpqn->q = NULL;\n\t\tretval = kfd_process_drain_interrupts(pdd);\n\t\tif (retval)\n\t\t\tbreak;\n\n\t\tretval = dev->dqm->ops.create_kernel_queue(dev->dqm,\n\t\t\t\t\t\t\tkq, &pdd->qpd);\n\t\tbreak;\n\tdefault:\n\t\tWARN(1, \"Invalid queue type %d\", type);\n\t\tretval = -EINVAL;\n\t}\n\n\tif (retval != 0) {\n\t\tpr_err(\"Pasid 0x%x DQM create queue type %d failed. ret %d\\n\",\n\t\t\tpqm->process->pasid, type, retval);\n\t\tgoto err_create_queue;\n\t}\n\n\tif (q && p_doorbell_offset_in_process) {\n\t\t \n\t\tuint32_t first_db_index = amdgpu_doorbell_index_on_bar(pdd->dev->adev,\n\t\t\t\t\t\t\t\t       pdd->qpd.proc_doorbells,\n\t\t\t\t\t\t\t\t       0,\n\t\t\t\t\t\t\t\t       pdd->dev->kfd->device_info.doorbell_size);\n\n\t\t*p_doorbell_offset_in_process = (q->properties.doorbell_off\n\t\t\t\t\t\t- first_db_index) * sizeof(uint32_t);\n\t}\n\n\tpr_debug(\"PQM After DQM create queue\\n\");\n\n\tlist_add(&pqn->process_queue_list, &pqm->queues);\n\n\tif (q) {\n\t\tpr_debug(\"PQM done creating queue\\n\");\n\t\tkfd_procfs_add_queue(q);\n\t\tprint_queue_properties(&q->properties);\n\t}\n\n\treturn retval;\n\nerr_create_queue:\n\tuninit_queue(q);\n\tif (kq)\n\t\tkernel_queue_uninit(kq, false);\n\tkfree(pqn);\nerr_allocate_pqn:\n\t \n\tclear_bit(*qid, pqm->queue_slot_bitmap);\n\tif (list_empty(&pdd->qpd.queues_list) &&\n\t    list_empty(&pdd->qpd.priv_queue_list))\n\t\tdev->dqm->ops.unregister_process(dev->dqm, &pdd->qpd);\n\treturn retval;\n}\n\nint pqm_destroy_queue(struct process_queue_manager *pqm, unsigned int qid)\n{\n\tstruct process_queue_node *pqn;\n\tstruct kfd_process_device *pdd;\n\tstruct device_queue_manager *dqm;\n\tstruct kfd_node *dev;\n\tint retval;\n\n\tdqm = NULL;\n\n\tretval = 0;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (!pqn) {\n\t\tpr_err(\"Queue id does not match any known queue\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = NULL;\n\tif (pqn->kq)\n\t\tdev = pqn->kq->dev;\n\tif (pqn->q)\n\t\tdev = pqn->q->device;\n\tif (WARN_ON(!dev))\n\t\treturn -ENODEV;\n\n\tpdd = kfd_get_process_device_data(dev, pqm->process);\n\tif (!pdd) {\n\t\tpr_err(\"Process device data doesn't exist\\n\");\n\t\treturn -1;\n\t}\n\n\tif (pqn->kq) {\n\t\t \n\t\tdqm = pqn->kq->dev->dqm;\n\t\tdqm->ops.destroy_kernel_queue(dqm, pqn->kq, &pdd->qpd);\n\t\tkernel_queue_uninit(pqn->kq, false);\n\t}\n\n\tif (pqn->q) {\n\t\tkfd_procfs_del_queue(pqn->q);\n\t\tdqm = pqn->q->device->dqm;\n\t\tretval = dqm->ops.destroy_queue(dqm, &pdd->qpd, pqn->q);\n\t\tif (retval) {\n\t\t\tpr_err(\"Pasid 0x%x destroy queue %d failed, ret %d\\n\",\n\t\t\t\tpqm->process->pasid,\n\t\t\t\tpqn->q->properties.queue_id, retval);\n\t\t\tif (retval != -ETIME)\n\t\t\t\tgoto err_destroy_queue;\n\t\t}\n\n\t\tpqm_clean_queue_resource(pqm, pqn);\n\t\tuninit_queue(pqn->q);\n\t}\n\n\tlist_del(&pqn->process_queue_list);\n\tkfree(pqn);\n\tclear_bit(qid, pqm->queue_slot_bitmap);\n\n\tif (list_empty(&pdd->qpd.queues_list) &&\n\t    list_empty(&pdd->qpd.priv_queue_list))\n\t\tdqm->ops.unregister_process(dqm, &pdd->qpd);\n\nerr_destroy_queue:\n\treturn retval;\n}\n\nint pqm_update_queue_properties(struct process_queue_manager *pqm,\n\t\t\t\tunsigned int qid, struct queue_properties *p)\n{\n\tint retval;\n\tstruct process_queue_node *pqn;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (!pqn) {\n\t\tpr_debug(\"No queue %d exists for update operation\\n\", qid);\n\t\treturn -EFAULT;\n\t}\n\n\tpqn->q->properties.queue_address = p->queue_address;\n\tpqn->q->properties.queue_size = p->queue_size;\n\tpqn->q->properties.queue_percent = p->queue_percent;\n\tpqn->q->properties.priority = p->priority;\n\tpqn->q->properties.pm4_target_xcc = p->pm4_target_xcc;\n\n\tretval = pqn->q->device->dqm->ops.update_queue(pqn->q->device->dqm,\n\t\t\t\t\t\t\tpqn->q, NULL);\n\tif (retval != 0)\n\t\treturn retval;\n\n\treturn 0;\n}\n\nint pqm_update_mqd(struct process_queue_manager *pqm,\n\t\t\t\tunsigned int qid, struct mqd_update_info *minfo)\n{\n\tint retval;\n\tstruct process_queue_node *pqn;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (!pqn) {\n\t\tpr_debug(\"No queue %d exists for update operation\\n\", qid);\n\t\treturn -EFAULT;\n\t}\n\n\t \n\tif (pqn->q->properties.is_dbg_wa && minfo && minfo->cu_mask.ptr)\n\t\treturn -EBUSY;\n\n\t \n\tif (minfo && minfo->cu_mask.ptr &&\n\t\t\tKFD_GC_VERSION(pqn->q->device) >= IP_VERSION(10, 0, 0)) {\n\t\tint i;\n\n\t\tfor (i = 0; i < minfo->cu_mask.count; i += 2) {\n\t\t\tuint32_t cu_pair = (minfo->cu_mask.ptr[i / 32] >> (i % 32)) & 0x3;\n\n\t\t\tif (cu_pair && cu_pair != 0x3) {\n\t\t\t\tpr_debug(\"CUs must be adjacent pairwise enabled.\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\t}\n\n\tretval = pqn->q->device->dqm->ops.update_queue(pqn->q->device->dqm,\n\t\t\t\t\t\t\tpqn->q, minfo);\n\tif (retval != 0)\n\t\treturn retval;\n\n\tif (minfo && minfo->cu_mask.ptr)\n\t\tpqn->q->properties.is_user_cu_masked = true;\n\n\treturn 0;\n}\n\nstruct kernel_queue *pqm_get_kernel_queue(\n\t\t\t\t\tstruct process_queue_manager *pqm,\n\t\t\t\t\tunsigned int qid)\n{\n\tstruct process_queue_node *pqn;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (pqn && pqn->kq)\n\t\treturn pqn->kq;\n\n\treturn NULL;\n}\n\nstruct queue *pqm_get_user_queue(struct process_queue_manager *pqm,\n\t\t\t\t\tunsigned int qid)\n{\n\tstruct process_queue_node *pqn;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\treturn pqn ? pqn->q : NULL;\n}\n\nint pqm_get_wave_state(struct process_queue_manager *pqm,\n\t\t       unsigned int qid,\n\t\t       void __user *ctl_stack,\n\t\t       u32 *ctl_stack_used_size,\n\t\t       u32 *save_area_used_size)\n{\n\tstruct process_queue_node *pqn;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (!pqn) {\n\t\tpr_debug(\"amdkfd: No queue %d exists for operation\\n\",\n\t\t\t qid);\n\t\treturn -EFAULT;\n\t}\n\n\treturn pqn->q->device->dqm->ops.get_wave_state(pqn->q->device->dqm,\n\t\t\t\t\t\t       pqn->q,\n\t\t\t\t\t\t       ctl_stack,\n\t\t\t\t\t\t       ctl_stack_used_size,\n\t\t\t\t\t\t       save_area_used_size);\n}\n\nint pqm_get_queue_snapshot(struct process_queue_manager *pqm,\n\t\t\t   uint64_t exception_clear_mask,\n\t\t\t   void __user *buf,\n\t\t\t   int *num_qss_entries,\n\t\t\t   uint32_t *entry_size)\n{\n\tstruct process_queue_node *pqn;\n\tstruct kfd_queue_snapshot_entry src;\n\tuint32_t tmp_entry_size = *entry_size, tmp_qss_entries = *num_qss_entries;\n\tint r = 0;\n\n\t*num_qss_entries = 0;\n\tif (!(*entry_size))\n\t\treturn -EINVAL;\n\n\t*entry_size = min_t(size_t, *entry_size, sizeof(struct kfd_queue_snapshot_entry));\n\tmutex_lock(&pqm->process->event_mutex);\n\n\tmemset(&src, 0, sizeof(src));\n\n\tlist_for_each_entry(pqn, &pqm->queues, process_queue_list) {\n\t\tif (!pqn->q)\n\t\t\tcontinue;\n\n\t\tif (*num_qss_entries < tmp_qss_entries) {\n\t\t\tset_queue_snapshot_entry(pqn->q, exception_clear_mask, &src);\n\n\t\t\tif (copy_to_user(buf, &src, *entry_size)) {\n\t\t\t\tr = -EFAULT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbuf += tmp_entry_size;\n\t\t}\n\t\t*num_qss_entries += 1;\n\t}\n\n\tmutex_unlock(&pqm->process->event_mutex);\n\treturn r;\n}\n\nstatic int get_queue_data_sizes(struct kfd_process_device *pdd,\n\t\t\t\tstruct queue *q,\n\t\t\t\tuint32_t *mqd_size,\n\t\t\t\tuint32_t *ctl_stack_size)\n{\n\tint ret;\n\n\tret = pqm_get_queue_checkpoint_info(&pdd->process->pqm,\n\t\t\t\t\t    q->properties.queue_id,\n\t\t\t\t\t    mqd_size,\n\t\t\t\t\t    ctl_stack_size);\n\tif (ret)\n\t\tpr_err(\"Failed to get queue dump info (%d)\\n\", ret);\n\n\treturn ret;\n}\n\nint kfd_process_get_queue_info(struct kfd_process *p,\n\t\t\t       uint32_t *num_queues,\n\t\t\t       uint64_t *priv_data_sizes)\n{\n\tuint32_t extra_data_sizes = 0;\n\tstruct queue *q;\n\tint i;\n\tint ret;\n\n\t*num_queues = 0;\n\n\t \n\tfor (i = 0; i < p->n_pdds; i++) {\n\t\tstruct kfd_process_device *pdd = p->pdds[i];\n\n\t\tlist_for_each_entry(q, &pdd->qpd.queues_list, list) {\n\t\t\tif (q->properties.type == KFD_QUEUE_TYPE_COMPUTE ||\n\t\t\t\tq->properties.type == KFD_QUEUE_TYPE_SDMA ||\n\t\t\t\tq->properties.type == KFD_QUEUE_TYPE_SDMA_XGMI) {\n\t\t\t\tuint32_t mqd_size, ctl_stack_size;\n\n\t\t\t\t*num_queues = *num_queues + 1;\n\n\t\t\t\tret = get_queue_data_sizes(pdd, q, &mqd_size, &ctl_stack_size);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\n\t\t\t\textra_data_sizes += mqd_size + ctl_stack_size;\n\t\t\t} else {\n\t\t\t\tpr_err(\"Unsupported queue type (%d)\\n\", q->properties.type);\n\t\t\t\treturn -EOPNOTSUPP;\n\t\t\t}\n\t\t}\n\t}\n\t*priv_data_sizes = extra_data_sizes +\n\t\t\t\t(*num_queues * sizeof(struct kfd_criu_queue_priv_data));\n\n\treturn 0;\n}\n\nstatic int pqm_checkpoint_mqd(struct process_queue_manager *pqm,\n\t\t\t      unsigned int qid,\n\t\t\t      void *mqd,\n\t\t\t      void *ctl_stack)\n{\n\tstruct process_queue_node *pqn;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (!pqn) {\n\t\tpr_debug(\"amdkfd: No queue %d exists for operation\\n\", qid);\n\t\treturn -EFAULT;\n\t}\n\n\tif (!pqn->q->device->dqm->ops.checkpoint_mqd) {\n\t\tpr_err(\"amdkfd: queue dumping not supported on this device\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\treturn pqn->q->device->dqm->ops.checkpoint_mqd(pqn->q->device->dqm,\n\t\t\t\t\t\t       pqn->q, mqd, ctl_stack);\n}\n\nstatic int criu_checkpoint_queue(struct kfd_process_device *pdd,\n\t\t\t   struct queue *q,\n\t\t\t   struct kfd_criu_queue_priv_data *q_data)\n{\n\tuint8_t *mqd, *ctl_stack;\n\tint ret;\n\n\tmqd = (void *)(q_data + 1);\n\tctl_stack = mqd + q_data->mqd_size;\n\n\tq_data->gpu_id = pdd->user_gpu_id;\n\tq_data->type = q->properties.type;\n\tq_data->format = q->properties.format;\n\tq_data->q_id =  q->properties.queue_id;\n\tq_data->q_address = q->properties.queue_address;\n\tq_data->q_size = q->properties.queue_size;\n\tq_data->priority = q->properties.priority;\n\tq_data->q_percent = q->properties.queue_percent;\n\tq_data->read_ptr_addr = (uint64_t)q->properties.read_ptr;\n\tq_data->write_ptr_addr = (uint64_t)q->properties.write_ptr;\n\tq_data->doorbell_id = q->doorbell_id;\n\n\tq_data->sdma_id = q->sdma_id;\n\n\tq_data->eop_ring_buffer_address =\n\t\tq->properties.eop_ring_buffer_address;\n\n\tq_data->eop_ring_buffer_size = q->properties.eop_ring_buffer_size;\n\n\tq_data->ctx_save_restore_area_address =\n\t\tq->properties.ctx_save_restore_area_address;\n\n\tq_data->ctx_save_restore_area_size =\n\t\tq->properties.ctx_save_restore_area_size;\n\n\tq_data->gws = !!q->gws;\n\n\tret = pqm_checkpoint_mqd(&pdd->process->pqm, q->properties.queue_id, mqd, ctl_stack);\n\tif (ret) {\n\t\tpr_err(\"Failed checkpoint queue_mqd (%d)\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tpr_debug(\"Dumping Queue: gpu_id:%x queue_id:%u\\n\", q_data->gpu_id, q_data->q_id);\n\treturn ret;\n}\n\nstatic int criu_checkpoint_queues_device(struct kfd_process_device *pdd,\n\t\t\t\t   uint8_t __user *user_priv,\n\t\t\t\t   unsigned int *q_index,\n\t\t\t\t   uint64_t *queues_priv_data_offset)\n{\n\tunsigned int q_private_data_size = 0;\n\tuint8_t *q_private_data = NULL;  \n\tstruct queue *q;\n\tint ret = 0;\n\n\tlist_for_each_entry(q, &pdd->qpd.queues_list, list) {\n\t\tstruct kfd_criu_queue_priv_data *q_data;\n\t\tuint64_t q_data_size;\n\t\tuint32_t mqd_size;\n\t\tuint32_t ctl_stack_size;\n\n\t\tif (q->properties.type != KFD_QUEUE_TYPE_COMPUTE &&\n\t\t\tq->properties.type != KFD_QUEUE_TYPE_SDMA &&\n\t\t\tq->properties.type != KFD_QUEUE_TYPE_SDMA_XGMI) {\n\n\t\t\tpr_err(\"Unsupported queue type (%d)\\n\", q->properties.type);\n\t\t\tret = -EOPNOTSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = get_queue_data_sizes(pdd, q, &mqd_size, &ctl_stack_size);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tq_data_size = sizeof(*q_data) + mqd_size + ctl_stack_size;\n\n\t\t \n\t\tif (q_private_data_size < q_data_size) {\n\t\t\tkfree(q_private_data);\n\n\t\t\tq_private_data = kzalloc(q_data_size, GFP_KERNEL);\n\t\t\tif (!q_private_data) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tq_private_data_size = q_data_size;\n\t\t}\n\n\t\tq_data = (struct kfd_criu_queue_priv_data *)q_private_data;\n\n\t\t \n\t\tq_data->mqd_size = mqd_size;\n\t\tq_data->ctl_stack_size = ctl_stack_size;\n\n\t\tret = criu_checkpoint_queue(pdd, q, q_data);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tq_data->object_type = KFD_CRIU_OBJECT_TYPE_QUEUE;\n\n\t\tret = copy_to_user(user_priv + *queues_priv_data_offset,\n\t\t\t\tq_data, q_data_size);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\t*queues_priv_data_offset += q_data_size;\n\t\t*q_index = *q_index + 1;\n\t}\n\n\tkfree(q_private_data);\n\n\treturn ret;\n}\n\nint kfd_criu_checkpoint_queues(struct kfd_process *p,\n\t\t\t uint8_t __user *user_priv_data,\n\t\t\t uint64_t *priv_data_offset)\n{\n\tint ret = 0, pdd_index, q_index = 0;\n\n\tfor (pdd_index = 0; pdd_index < p->n_pdds; pdd_index++) {\n\t\tstruct kfd_process_device *pdd = p->pdds[pdd_index];\n\n\t\t \n\t\tret = criu_checkpoint_queues_device(pdd, user_priv_data, &q_index,\n\t\t\t\t\t      priv_data_offset);\n\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic void set_queue_properties_from_criu(struct queue_properties *qp,\n\t\t\t\t\t  struct kfd_criu_queue_priv_data *q_data)\n{\n\tqp->is_interop = false;\n\tqp->queue_percent = q_data->q_percent;\n\tqp->priority = q_data->priority;\n\tqp->queue_address = q_data->q_address;\n\tqp->queue_size = q_data->q_size;\n\tqp->read_ptr = (uint32_t *) q_data->read_ptr_addr;\n\tqp->write_ptr = (uint32_t *) q_data->write_ptr_addr;\n\tqp->eop_ring_buffer_address = q_data->eop_ring_buffer_address;\n\tqp->eop_ring_buffer_size = q_data->eop_ring_buffer_size;\n\tqp->ctx_save_restore_area_address = q_data->ctx_save_restore_area_address;\n\tqp->ctx_save_restore_area_size = q_data->ctx_save_restore_area_size;\n\tqp->ctl_stack_size = q_data->ctl_stack_size;\n\tqp->type = q_data->type;\n\tqp->format = q_data->format;\n}\n\nint kfd_criu_restore_queue(struct kfd_process *p,\n\t\t\t   uint8_t __user *user_priv_ptr,\n\t\t\t   uint64_t *priv_data_offset,\n\t\t\t   uint64_t max_priv_data_size)\n{\n\tuint8_t *mqd, *ctl_stack, *q_extra_data = NULL;\n\tstruct kfd_criu_queue_priv_data *q_data;\n\tstruct kfd_process_device *pdd;\n\tuint64_t q_extra_data_size;\n\tstruct queue_properties qp;\n\tunsigned int queue_id;\n\tint ret = 0;\n\n\tif (*priv_data_offset + sizeof(*q_data) > max_priv_data_size)\n\t\treturn -EINVAL;\n\n\tq_data = kmalloc(sizeof(*q_data), GFP_KERNEL);\n\tif (!q_data)\n\t\treturn -ENOMEM;\n\n\tret = copy_from_user(q_data, user_priv_ptr + *priv_data_offset, sizeof(*q_data));\n\tif (ret) {\n\t\tret = -EFAULT;\n\t\tgoto exit;\n\t}\n\n\t*priv_data_offset += sizeof(*q_data);\n\tq_extra_data_size = (uint64_t)q_data->ctl_stack_size + q_data->mqd_size;\n\n\tif (*priv_data_offset + q_extra_data_size > max_priv_data_size) {\n\t\tret = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\tq_extra_data = kmalloc(q_extra_data_size, GFP_KERNEL);\n\tif (!q_extra_data) {\n\t\tret = -ENOMEM;\n\t\tgoto exit;\n\t}\n\n\tret = copy_from_user(q_extra_data, user_priv_ptr + *priv_data_offset, q_extra_data_size);\n\tif (ret) {\n\t\tret = -EFAULT;\n\t\tgoto exit;\n\t}\n\n\t*priv_data_offset += q_extra_data_size;\n\n\tpdd = kfd_process_device_data_by_id(p, q_data->gpu_id);\n\tif (!pdd) {\n\t\tpr_err(\"Failed to get pdd\\n\");\n\t\tret = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\t \n\tmqd = q_extra_data;\n\tctl_stack = mqd + q_data->mqd_size;\n\n\tmemset(&qp, 0, sizeof(qp));\n\tset_queue_properties_from_criu(&qp, q_data);\n\n\tprint_queue_properties(&qp);\n\n\tret = pqm_create_queue(&p->pqm, pdd->dev, NULL, &qp, &queue_id, NULL, q_data, mqd, ctl_stack,\n\t\t\t\tNULL);\n\tif (ret) {\n\t\tpr_err(\"Failed to create new queue err:%d\\n\", ret);\n\t\tgoto exit;\n\t}\n\n\tif (q_data->gws)\n\t\tret = pqm_set_gws(&p->pqm, q_data->q_id, pdd->dev->gws);\n\nexit:\n\tif (ret)\n\t\tpr_err(\"Failed to restore queue (%d)\\n\", ret);\n\telse\n\t\tpr_debug(\"Queue id %d was restored successfully\\n\", queue_id);\n\n\tkfree(q_data);\n\n\treturn ret;\n}\n\nint pqm_get_queue_checkpoint_info(struct process_queue_manager *pqm,\n\t\t\t\t  unsigned int qid,\n\t\t\t\t  uint32_t *mqd_size,\n\t\t\t\t  uint32_t *ctl_stack_size)\n{\n\tstruct process_queue_node *pqn;\n\n\tpqn = get_queue_by_qid(pqm, qid);\n\tif (!pqn) {\n\t\tpr_debug(\"amdkfd: No queue %d exists for operation\\n\", qid);\n\t\treturn -EFAULT;\n\t}\n\n\tif (!pqn->q->device->dqm->ops.get_queue_checkpoint_info) {\n\t\tpr_err(\"amdkfd: queue dumping not supported on this device\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tpqn->q->device->dqm->ops.get_queue_checkpoint_info(pqn->q->device->dqm,\n\t\t\t\t\t\t       pqn->q, mqd_size,\n\t\t\t\t\t\t       ctl_stack_size);\n\treturn 0;\n}\n\n#if defined(CONFIG_DEBUG_FS)\n\nint pqm_debugfs_mqds(struct seq_file *m, void *data)\n{\n\tstruct process_queue_manager *pqm = data;\n\tstruct process_queue_node *pqn;\n\tstruct queue *q;\n\tenum KFD_MQD_TYPE mqd_type;\n\tstruct mqd_manager *mqd_mgr;\n\tint r = 0, xcc, num_xccs = 1;\n\tvoid *mqd;\n\tuint64_t size = 0;\n\n\tlist_for_each_entry(pqn, &pqm->queues, process_queue_list) {\n\t\tif (pqn->q) {\n\t\t\tq = pqn->q;\n\t\t\tswitch (q->properties.type) {\n\t\t\tcase KFD_QUEUE_TYPE_SDMA:\n\t\t\tcase KFD_QUEUE_TYPE_SDMA_XGMI:\n\t\t\t\tseq_printf(m, \"  SDMA queue on device %x\\n\",\n\t\t\t\t\t   q->device->id);\n\t\t\t\tmqd_type = KFD_MQD_TYPE_SDMA;\n\t\t\t\tbreak;\n\t\t\tcase KFD_QUEUE_TYPE_COMPUTE:\n\t\t\t\tseq_printf(m, \"  Compute queue on device %x\\n\",\n\t\t\t\t\t   q->device->id);\n\t\t\t\tmqd_type = KFD_MQD_TYPE_CP;\n\t\t\t\tnum_xccs = NUM_XCC(q->device->xcc_mask);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tseq_printf(m,\n\t\t\t\t\"  Bad user queue type %d on device %x\\n\",\n\t\t\t\t\t   q->properties.type, q->device->id);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmqd_mgr = q->device->dqm->mqd_mgrs[mqd_type];\n\t\t\tsize = mqd_mgr->mqd_stride(mqd_mgr,\n\t\t\t\t\t\t\t&q->properties);\n\t\t} else if (pqn->kq) {\n\t\t\tq = pqn->kq->queue;\n\t\t\tmqd_mgr = pqn->kq->mqd_mgr;\n\t\t\tswitch (q->properties.type) {\n\t\t\tcase KFD_QUEUE_TYPE_DIQ:\n\t\t\t\tseq_printf(m, \"  DIQ on device %x\\n\",\n\t\t\t\t\t   pqn->kq->dev->id);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tseq_printf(m,\n\t\t\t\t\"  Bad kernel queue type %d on device %x\\n\",\n\t\t\t\t\t   q->properties.type,\n\t\t\t\t\t   pqn->kq->dev->id);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\tseq_printf(m,\n\t\t\"  Weird: Queue node with neither kernel nor user queue\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor (xcc = 0; xcc < num_xccs; xcc++) {\n\t\t\tmqd = q->mqd + size * xcc;\n\t\t\tr = mqd_mgr->debugfs_show_mqd(m, mqd);\n\t\t\tif (r != 0)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn r;\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}