{
  "module_name": "kfd_smi_events.c",
  "hash_id": "42f153137aa5dc8ca6fd318b5dad2dd31f26ee4e239a4b0e5d8033b83a2787c7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/amd/amdkfd/kfd_smi_events.c",
  "human_readable_source": "\n \n\n#include <linux/poll.h>\n#include <linux/wait.h>\n#include <linux/anon_inodes.h>\n#include <uapi/linux/kfd_ioctl.h>\n#include \"amdgpu.h\"\n#include \"amdgpu_vm.h\"\n#include \"kfd_priv.h\"\n#include \"kfd_smi_events.h\"\n\nstruct kfd_smi_client {\n\tstruct list_head list;\n\tstruct kfifo fifo;\n\twait_queue_head_t wait_queue;\n\t \n\tuint64_t events;\n\tstruct kfd_node *dev;\n\tspinlock_t lock;\n\tstruct rcu_head rcu;\n\tpid_t pid;\n\tbool suser;\n};\n\n#define MAX_KFIFO_SIZE\t1024\n\nstatic __poll_t kfd_smi_ev_poll(struct file *, struct poll_table_struct *);\nstatic ssize_t kfd_smi_ev_read(struct file *, char __user *, size_t, loff_t *);\nstatic ssize_t kfd_smi_ev_write(struct file *, const char __user *, size_t,\n\t\t\t\tloff_t *);\nstatic int kfd_smi_ev_release(struct inode *, struct file *);\n\nstatic const char kfd_smi_name[] = \"kfd_smi_ev\";\n\nstatic const struct file_operations kfd_smi_ev_fops = {\n\t.owner = THIS_MODULE,\n\t.poll = kfd_smi_ev_poll,\n\t.read = kfd_smi_ev_read,\n\t.write = kfd_smi_ev_write,\n\t.release = kfd_smi_ev_release\n};\n\nstatic __poll_t kfd_smi_ev_poll(struct file *filep,\n\t\t\t\tstruct poll_table_struct *wait)\n{\n\tstruct kfd_smi_client *client = filep->private_data;\n\t__poll_t mask = 0;\n\n\tpoll_wait(filep, &client->wait_queue, wait);\n\n\tspin_lock(&client->lock);\n\tif (!kfifo_is_empty(&client->fifo))\n\t\tmask = EPOLLIN | EPOLLRDNORM;\n\tspin_unlock(&client->lock);\n\n\treturn mask;\n}\n\nstatic ssize_t kfd_smi_ev_read(struct file *filep, char __user *user,\n\t\t\t       size_t size, loff_t *offset)\n{\n\tint ret;\n\tsize_t to_copy;\n\tstruct kfd_smi_client *client = filep->private_data;\n\tunsigned char *buf;\n\n\tsize = min_t(size_t, size, MAX_KFIFO_SIZE);\n\tbuf = kmalloc(size, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t \n\tspin_lock(&client->lock);\n\tto_copy = kfifo_len(&client->fifo);\n\tif (!to_copy) {\n\t\tspin_unlock(&client->lock);\n\t\tret = -EAGAIN;\n\t\tgoto ret_err;\n\t}\n\tto_copy = min(size, to_copy);\n\tret = kfifo_out(&client->fifo, buf, to_copy);\n\tspin_unlock(&client->lock);\n\tif (ret <= 0) {\n\t\tret = -EAGAIN;\n\t\tgoto ret_err;\n\t}\n\n\tret = copy_to_user(user, buf, to_copy);\n\tif (ret) {\n\t\tret = -EFAULT;\n\t\tgoto ret_err;\n\t}\n\n\tkfree(buf);\n\treturn to_copy;\n\nret_err:\n\tkfree(buf);\n\treturn ret;\n}\n\nstatic ssize_t kfd_smi_ev_write(struct file *filep, const char __user *user,\n\t\t\t\tsize_t size, loff_t *offset)\n{\n\tstruct kfd_smi_client *client = filep->private_data;\n\tuint64_t events;\n\n\tif (!access_ok(user, size) || size < sizeof(events))\n\t\treturn -EFAULT;\n\tif (copy_from_user(&events, user, sizeof(events)))\n\t\treturn -EFAULT;\n\n\tWRITE_ONCE(client->events, events);\n\n\treturn sizeof(events);\n}\n\nstatic void kfd_smi_ev_client_free(struct rcu_head *p)\n{\n\tstruct kfd_smi_client *ev = container_of(p, struct kfd_smi_client, rcu);\n\n\tkfifo_free(&ev->fifo);\n\tkfree(ev);\n}\n\nstatic int kfd_smi_ev_release(struct inode *inode, struct file *filep)\n{\n\tstruct kfd_smi_client *client = filep->private_data;\n\tstruct kfd_node *dev = client->dev;\n\n\tspin_lock(&dev->smi_lock);\n\tlist_del_rcu(&client->list);\n\tspin_unlock(&dev->smi_lock);\n\n\tcall_rcu(&client->rcu, kfd_smi_ev_client_free);\n\treturn 0;\n}\n\nstatic bool kfd_smi_ev_enabled(pid_t pid, struct kfd_smi_client *client,\n\t\t\t       unsigned int event)\n{\n\tuint64_t all = KFD_SMI_EVENT_MASK_FROM_INDEX(KFD_SMI_EVENT_ALL_PROCESS);\n\tuint64_t events = READ_ONCE(client->events);\n\n\tif (pid && client->pid != pid && !(client->suser && (events & all)))\n\t\treturn false;\n\n\treturn events & KFD_SMI_EVENT_MASK_FROM_INDEX(event);\n}\n\nstatic void add_event_to_kfifo(pid_t pid, struct kfd_node *dev,\n\t\t\t       unsigned int smi_event, char *event_msg, int len)\n{\n\tstruct kfd_smi_client *client;\n\n\trcu_read_lock();\n\n\tlist_for_each_entry_rcu(client, &dev->smi_clients, list) {\n\t\tif (!kfd_smi_ev_enabled(pid, client, smi_event))\n\t\t\tcontinue;\n\t\tspin_lock(&client->lock);\n\t\tif (kfifo_avail(&client->fifo) >= len) {\n\t\t\tkfifo_in(&client->fifo, event_msg, len);\n\t\t\twake_up_all(&client->wait_queue);\n\t\t} else {\n\t\t\tpr_debug(\"smi_event(EventID: %u): no space left\\n\",\n\t\t\t\t\tsmi_event);\n\t\t}\n\t\tspin_unlock(&client->lock);\n\t}\n\n\trcu_read_unlock();\n}\n\n__printf(4, 5)\nstatic void kfd_smi_event_add(pid_t pid, struct kfd_node *dev,\n\t\t\t      unsigned int event, char *fmt, ...)\n{\n\tchar fifo_in[KFD_SMI_EVENT_MSG_SIZE];\n\tint len;\n\tva_list args;\n\n\tif (list_empty(&dev->smi_clients))\n\t\treturn;\n\n\tlen = snprintf(fifo_in, sizeof(fifo_in), \"%x \", event);\n\n\tva_start(args, fmt);\n\tlen += vsnprintf(fifo_in + len, sizeof(fifo_in) - len, fmt, args);\n\tva_end(args);\n\n\tadd_event_to_kfifo(pid, dev, event, fifo_in, len);\n}\n\nvoid kfd_smi_event_update_gpu_reset(struct kfd_node *dev, bool post_reset)\n{\n\tunsigned int event;\n\n\tif (post_reset) {\n\t\tevent = KFD_SMI_EVENT_GPU_POST_RESET;\n\t} else {\n\t\tevent = KFD_SMI_EVENT_GPU_PRE_RESET;\n\t\t++(dev->reset_seq_num);\n\t}\n\tkfd_smi_event_add(0, dev, event, \"%x\\n\", dev->reset_seq_num);\n}\n\nvoid kfd_smi_event_update_thermal_throttling(struct kfd_node *dev,\n\t\t\t\t\t     uint64_t throttle_bitmask)\n{\n\tkfd_smi_event_add(0, dev, KFD_SMI_EVENT_THERMAL_THROTTLE, \"%llx:%llx\\n\",\n\t\t\t  throttle_bitmask,\n\t\t\t  amdgpu_dpm_get_thermal_throttling_counter(dev->adev));\n}\n\nvoid kfd_smi_event_update_vmfault(struct kfd_node *dev, uint16_t pasid)\n{\n\tstruct amdgpu_task_info task_info;\n\n\tmemset(&task_info, 0, sizeof(struct amdgpu_task_info));\n\tamdgpu_vm_get_task_info(dev->adev, pasid, &task_info);\n\t \n\tif (!task_info.pid)\n\t\treturn;\n\n\tkfd_smi_event_add(0, dev, KFD_SMI_EVENT_VMFAULT, \"%x:%s\\n\",\n\t\t\t  task_info.pid, task_info.task_name);\n}\n\nvoid kfd_smi_event_page_fault_start(struct kfd_node *node, pid_t pid,\n\t\t\t\t    unsigned long address, bool write_fault,\n\t\t\t\t    ktime_t ts)\n{\n\tkfd_smi_event_add(pid, node, KFD_SMI_EVENT_PAGE_FAULT_START,\n\t\t\t  \"%lld -%d @%lx(%x) %c\\n\", ktime_to_ns(ts), pid,\n\t\t\t  address, node->id, write_fault ? 'W' : 'R');\n}\n\nvoid kfd_smi_event_page_fault_end(struct kfd_node *node, pid_t pid,\n\t\t\t\t  unsigned long address, bool migration)\n{\n\tkfd_smi_event_add(pid, node, KFD_SMI_EVENT_PAGE_FAULT_END,\n\t\t\t  \"%lld -%d @%lx(%x) %c\\n\", ktime_get_boottime_ns(),\n\t\t\t  pid, address, node->id, migration ? 'M' : 'U');\n}\n\nvoid kfd_smi_event_migration_start(struct kfd_node *node, pid_t pid,\n\t\t\t\t   unsigned long start, unsigned long end,\n\t\t\t\t   uint32_t from, uint32_t to,\n\t\t\t\t   uint32_t prefetch_loc, uint32_t preferred_loc,\n\t\t\t\t   uint32_t trigger)\n{\n\tkfd_smi_event_add(pid, node, KFD_SMI_EVENT_MIGRATE_START,\n\t\t\t  \"%lld -%d @%lx(%lx) %x->%x %x:%x %d\\n\",\n\t\t\t  ktime_get_boottime_ns(), pid, start, end - start,\n\t\t\t  from, to, prefetch_loc, preferred_loc, trigger);\n}\n\nvoid kfd_smi_event_migration_end(struct kfd_node *node, pid_t pid,\n\t\t\t\t unsigned long start, unsigned long end,\n\t\t\t\t uint32_t from, uint32_t to, uint32_t trigger)\n{\n\tkfd_smi_event_add(pid, node, KFD_SMI_EVENT_MIGRATE_END,\n\t\t\t  \"%lld -%d @%lx(%lx) %x->%x %d\\n\",\n\t\t\t  ktime_get_boottime_ns(), pid, start, end - start,\n\t\t\t  from, to, trigger);\n}\n\nvoid kfd_smi_event_queue_eviction(struct kfd_node *node, pid_t pid,\n\t\t\t\t  uint32_t trigger)\n{\n\tkfd_smi_event_add(pid, node, KFD_SMI_EVENT_QUEUE_EVICTION,\n\t\t\t  \"%lld -%d %x %d\\n\", ktime_get_boottime_ns(), pid,\n\t\t\t  node->id, trigger);\n}\n\nvoid kfd_smi_event_queue_restore(struct kfd_node *node, pid_t pid)\n{\n\tkfd_smi_event_add(pid, node, KFD_SMI_EVENT_QUEUE_RESTORE,\n\t\t\t  \"%lld -%d %x\\n\", ktime_get_boottime_ns(), pid,\n\t\t\t  node->id);\n}\n\nvoid kfd_smi_event_queue_restore_rescheduled(struct mm_struct *mm)\n{\n\tstruct kfd_process *p;\n\tint i;\n\n\tp = kfd_lookup_process_by_mm(mm);\n\tif (!p)\n\t\treturn;\n\n\tfor (i = 0; i < p->n_pdds; i++) {\n\t\tstruct kfd_process_device *pdd = p->pdds[i];\n\n\t\tkfd_smi_event_add(p->lead_thread->pid, pdd->dev,\n\t\t\t\t  KFD_SMI_EVENT_QUEUE_RESTORE,\n\t\t\t\t  \"%lld -%d %x %c\\n\", ktime_get_boottime_ns(),\n\t\t\t\t  p->lead_thread->pid, pdd->dev->id, 'R');\n\t}\n\tkfd_unref_process(p);\n}\n\nvoid kfd_smi_event_unmap_from_gpu(struct kfd_node *node, pid_t pid,\n\t\t\t\t  unsigned long address, unsigned long last,\n\t\t\t\t  uint32_t trigger)\n{\n\tkfd_smi_event_add(pid, node, KFD_SMI_EVENT_UNMAP_FROM_GPU,\n\t\t\t  \"%lld -%d @%lx(%lx) %x %d\\n\", ktime_get_boottime_ns(),\n\t\t\t  pid, address, last - address + 1, node->id, trigger);\n}\n\nint kfd_smi_event_open(struct kfd_node *dev, uint32_t *fd)\n{\n\tstruct kfd_smi_client *client;\n\tint ret;\n\n\tclient = kzalloc(sizeof(struct kfd_smi_client), GFP_KERNEL);\n\tif (!client)\n\t\treturn -ENOMEM;\n\tINIT_LIST_HEAD(&client->list);\n\n\tret = kfifo_alloc(&client->fifo, MAX_KFIFO_SIZE, GFP_KERNEL);\n\tif (ret) {\n\t\tkfree(client);\n\t\treturn ret;\n\t}\n\n\tinit_waitqueue_head(&client->wait_queue);\n\tspin_lock_init(&client->lock);\n\tclient->events = 0;\n\tclient->dev = dev;\n\tclient->pid = current->tgid;\n\tclient->suser = capable(CAP_SYS_ADMIN);\n\n\tspin_lock(&dev->smi_lock);\n\tlist_add_rcu(&client->list, &dev->smi_clients);\n\tspin_unlock(&dev->smi_lock);\n\n\tret = anon_inode_getfd(kfd_smi_name, &kfd_smi_ev_fops, (void *)client,\n\t\t\t       O_RDWR);\n\tif (ret < 0) {\n\t\tspin_lock(&dev->smi_lock);\n\t\tlist_del_rcu(&client->list);\n\t\tspin_unlock(&dev->smi_lock);\n\n\t\tsynchronize_rcu();\n\n\t\tkfifo_free(&client->fifo);\n\t\tkfree(client);\n\t\treturn ret;\n\t}\n\t*fd = ret;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}