{
  "module_name": "msm_drv.c",
  "hash_id": "62874b9a81a93c5f205bb1cb3016fd39677ff6954db309dddb5d0098af2fd752",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/msm/msm_drv.c",
  "human_readable_source": "\n \n\n#include <linux/dma-mapping.h>\n#include <linux/fault-inject.h>\n#include <linux/kthread.h>\n#include <linux/of_address.h>\n#include <linux/sched/mm.h>\n#include <linux/uaccess.h>\n#include <uapi/linux/sched/types.h>\n\n#include <drm/drm_aperture.h>\n#include <drm/drm_bridge.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_file.h>\n#include <drm/drm_ioctl.h>\n#include <drm/drm_prime.h>\n#include <drm/drm_of.h>\n#include <drm/drm_vblank.h>\n\n#include \"disp/msm_disp_snapshot.h\"\n#include \"msm_drv.h\"\n#include \"msm_debugfs.h\"\n#include \"msm_fence.h\"\n#include \"msm_gem.h\"\n#include \"msm_gpu.h\"\n#include \"msm_kms.h\"\n#include \"msm_mmu.h\"\n#include \"adreno/adreno_gpu.h\"\n\n \n#define MSM_VERSION_MAJOR\t1\n#define MSM_VERSION_MINOR\t10\n#define MSM_VERSION_PATCHLEVEL\t0\n\nstatic void msm_deinit_vram(struct drm_device *ddev);\n\nstatic const struct drm_mode_config_funcs mode_config_funcs = {\n\t.fb_create = msm_framebuffer_create,\n\t.atomic_check = msm_atomic_check,\n\t.atomic_commit = drm_atomic_helper_commit,\n};\n\nstatic const struct drm_mode_config_helper_funcs mode_config_helper_funcs = {\n\t.atomic_commit_tail = msm_atomic_commit_tail,\n};\n\nstatic char *vram = \"16m\";\nMODULE_PARM_DESC(vram, \"Configure VRAM size (for devices without IOMMU/GPUMMU)\");\nmodule_param(vram, charp, 0);\n\nbool dumpstate;\nMODULE_PARM_DESC(dumpstate, \"Dump KMS state on errors\");\nmodule_param(dumpstate, bool, 0600);\n\nstatic bool modeset = true;\nMODULE_PARM_DESC(modeset, \"Use kernel modesetting [KMS] (1=on (default), 0=disable)\");\nmodule_param(modeset, bool, 0600);\n\n#ifdef CONFIG_FAULT_INJECTION\nDECLARE_FAULT_ATTR(fail_gem_alloc);\nDECLARE_FAULT_ATTR(fail_gem_iova);\n#endif\n\nstatic irqreturn_t msm_irq(int irq, void *arg)\n{\n\tstruct drm_device *dev = arg;\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_kms *kms = priv->kms;\n\n\tBUG_ON(!kms);\n\n\treturn kms->funcs->irq(kms);\n}\n\nstatic void msm_irq_preinstall(struct drm_device *dev)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_kms *kms = priv->kms;\n\n\tBUG_ON(!kms);\n\n\tkms->funcs->irq_preinstall(kms);\n}\n\nstatic int msm_irq_postinstall(struct drm_device *dev)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_kms *kms = priv->kms;\n\n\tBUG_ON(!kms);\n\n\tif (kms->funcs->irq_postinstall)\n\t\treturn kms->funcs->irq_postinstall(kms);\n\n\treturn 0;\n}\n\nstatic int msm_irq_install(struct drm_device *dev, unsigned int irq)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_kms *kms = priv->kms;\n\tint ret;\n\n\tif (irq == IRQ_NOTCONNECTED)\n\t\treturn -ENOTCONN;\n\n\tmsm_irq_preinstall(dev);\n\n\tret = request_irq(irq, msm_irq, 0, dev->driver->name, dev);\n\tif (ret)\n\t\treturn ret;\n\n\tkms->irq_requested = true;\n\n\tret = msm_irq_postinstall(dev);\n\tif (ret) {\n\t\tfree_irq(irq, dev);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void msm_irq_uninstall(struct drm_device *dev)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_kms *kms = priv->kms;\n\n\tkms->funcs->irq_uninstall(kms);\n\tif (kms->irq_requested)\n\t\tfree_irq(kms->irq, dev);\n}\n\nstruct msm_vblank_work {\n\tstruct work_struct work;\n\tstruct drm_crtc *crtc;\n\tbool enable;\n\tstruct msm_drm_private *priv;\n};\n\nstatic void vblank_ctrl_worker(struct work_struct *work)\n{\n\tstruct msm_vblank_work *vbl_work = container_of(work,\n\t\t\t\t\t\tstruct msm_vblank_work, work);\n\tstruct msm_drm_private *priv = vbl_work->priv;\n\tstruct msm_kms *kms = priv->kms;\n\n\tif (vbl_work->enable)\n\t\tkms->funcs->enable_vblank(kms, vbl_work->crtc);\n\telse\n\t\tkms->funcs->disable_vblank(kms,\tvbl_work->crtc);\n\n\tkfree(vbl_work);\n}\n\nstatic int vblank_ctrl_queue_work(struct msm_drm_private *priv,\n\t\t\t\t\tstruct drm_crtc *crtc, bool enable)\n{\n\tstruct msm_vblank_work *vbl_work;\n\n\tvbl_work = kzalloc(sizeof(*vbl_work), GFP_ATOMIC);\n\tif (!vbl_work)\n\t\treturn -ENOMEM;\n\n\tINIT_WORK(&vbl_work->work, vblank_ctrl_worker);\n\n\tvbl_work->crtc = crtc;\n\tvbl_work->enable = enable;\n\tvbl_work->priv = priv;\n\n\tqueue_work(priv->wq, &vbl_work->work);\n\n\treturn 0;\n}\n\nstatic int msm_drm_uninit(struct device *dev)\n{\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct msm_drm_private *priv = platform_get_drvdata(pdev);\n\tstruct drm_device *ddev = priv->dev;\n\tstruct msm_kms *kms = priv->kms;\n\tint i;\n\n\t \n\tif (ddev->registered) {\n\t\tdrm_dev_unregister(ddev);\n\t\tdrm_atomic_helper_shutdown(ddev);\n\t}\n\n\t \n\n\tflush_workqueue(priv->wq);\n\n\t \n\tfor (i = 0; i < priv->num_crtcs; i++) {\n\t\tif (priv->event_thread[i].worker)\n\t\t\tkthread_destroy_worker(priv->event_thread[i].worker);\n\t}\n\n\tmsm_gem_shrinker_cleanup(ddev);\n\n\tdrm_kms_helper_poll_fini(ddev);\n\n\tmsm_perf_debugfs_cleanup(priv);\n\tmsm_rd_debugfs_cleanup(priv);\n\n\tif (kms)\n\t\tmsm_disp_snapshot_destroy(ddev);\n\n\tdrm_mode_config_cleanup(ddev);\n\n\tfor (i = 0; i < priv->num_bridges; i++)\n\t\tdrm_bridge_remove(priv->bridges[i]);\n\tpriv->num_bridges = 0;\n\n\tif (kms) {\n\t\tpm_runtime_get_sync(dev);\n\t\tmsm_irq_uninstall(ddev);\n\t\tpm_runtime_put_sync(dev);\n\t}\n\n\tif (kms && kms->funcs)\n\t\tkms->funcs->destroy(kms);\n\n\tmsm_deinit_vram(ddev);\n\n\tcomponent_unbind_all(dev, ddev);\n\n\tddev->dev_private = NULL;\n\tdrm_dev_put(ddev);\n\n\tdestroy_workqueue(priv->wq);\n\n\treturn 0;\n}\n\nstruct msm_gem_address_space *msm_kms_init_aspace(struct drm_device *dev)\n{\n\tstruct msm_gem_address_space *aspace;\n\tstruct msm_mmu *mmu;\n\tstruct device *mdp_dev = dev->dev;\n\tstruct device *mdss_dev = mdp_dev->parent;\n\tstruct device *iommu_dev;\n\n\t \n\tif (device_iommu_mapped(mdp_dev))\n\t\tiommu_dev = mdp_dev;\n\telse\n\t\tiommu_dev = mdss_dev;\n\n\tmmu = msm_iommu_new(iommu_dev, 0);\n\tif (IS_ERR(mmu))\n\t\treturn ERR_CAST(mmu);\n\n\tif (!mmu) {\n\t\tdrm_info(dev, \"no IOMMU, fallback to phys contig buffers for scanout\\n\");\n\t\treturn NULL;\n\t}\n\n\taspace = msm_gem_address_space_create(mmu, \"mdp_kms\",\n\t\t0x1000, 0x100000000 - 0x1000);\n\tif (IS_ERR(aspace)) {\n\t\tdev_err(mdp_dev, \"aspace create, error %pe\\n\", aspace);\n\t\tmmu->funcs->destroy(mmu);\n\t}\n\n\treturn aspace;\n}\n\nbool msm_use_mmu(struct drm_device *dev)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\n\t \n\treturn priv->is_a2xx ||\n\t\tdevice_iommu_mapped(dev->dev) ||\n\t\tdevice_iommu_mapped(dev->dev->parent);\n}\n\nstatic int msm_init_vram(struct drm_device *dev)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct device_node *node;\n\tunsigned long size = 0;\n\tint ret = 0;\n\n\t \n\n\tnode = of_parse_phandle(dev->dev->of_node, \"memory-region\", 0);\n\tif (node) {\n\t\tstruct resource r;\n\t\tret = of_address_to_resource(node, 0, &r);\n\t\tof_node_put(node);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tsize = r.end - r.start + 1;\n\t\tDRM_INFO(\"using VRAM carveout: %lx@%pa\\n\", size, &r.start);\n\n\t\t \n\t} else if (!msm_use_mmu(dev)) {\n\t\tDRM_INFO(\"using %s VRAM carveout\\n\", vram);\n\t\tsize = memparse(vram, NULL);\n\t}\n\n\tif (size) {\n\t\tunsigned long attrs = 0;\n\t\tvoid *p;\n\n\t\tpriv->vram.size = size;\n\n\t\tdrm_mm_init(&priv->vram.mm, 0, (size >> PAGE_SHIFT) - 1);\n\t\tspin_lock_init(&priv->vram.lock);\n\n\t\tattrs |= DMA_ATTR_NO_KERNEL_MAPPING;\n\t\tattrs |= DMA_ATTR_WRITE_COMBINE;\n\n\t\t \n\t\tp = dma_alloc_attrs(dev->dev, size,\n\t\t\t\t&priv->vram.paddr, GFP_KERNEL, attrs);\n\t\tif (!p) {\n\t\t\tDRM_DEV_ERROR(dev->dev, \"failed to allocate VRAM\\n\");\n\t\t\tpriv->vram.paddr = 0;\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tDRM_DEV_INFO(dev->dev, \"VRAM: %08x->%08x\\n\",\n\t\t\t\t(uint32_t)priv->vram.paddr,\n\t\t\t\t(uint32_t)(priv->vram.paddr + size));\n\t}\n\n\treturn ret;\n}\n\nstatic void msm_deinit_vram(struct drm_device *ddev)\n{\n\tstruct msm_drm_private *priv = ddev->dev_private;\n\tunsigned long attrs = DMA_ATTR_NO_KERNEL_MAPPING;\n\n\tif (!priv->vram.paddr)\n\t\treturn;\n\n\tdrm_mm_takedown(&priv->vram.mm);\n\tdma_free_attrs(ddev->dev, priv->vram.size, NULL, priv->vram.paddr,\n\t\t\tattrs);\n}\n\nstatic int msm_drm_init(struct device *dev, const struct drm_driver *drv)\n{\n\tstruct msm_drm_private *priv = dev_get_drvdata(dev);\n\tstruct drm_device *ddev;\n\tstruct msm_kms *kms;\n\tstruct drm_crtc *crtc;\n\tint ret;\n\n\tif (drm_firmware_drivers_only())\n\t\treturn -ENODEV;\n\n\tddev = drm_dev_alloc(drv, dev);\n\tif (IS_ERR(ddev)) {\n\t\tDRM_DEV_ERROR(dev, \"failed to allocate drm_device\\n\");\n\t\treturn PTR_ERR(ddev);\n\t}\n\tddev->dev_private = priv;\n\tpriv->dev = ddev;\n\n\tpriv->wq = alloc_ordered_workqueue(\"msm\", 0);\n\tif (!priv->wq) {\n\t\tret = -ENOMEM;\n\t\tgoto err_put_dev;\n\t}\n\n\tINIT_LIST_HEAD(&priv->objects);\n\tmutex_init(&priv->obj_lock);\n\n\t \n\tmutex_init(&priv->lru.lock);\n\tdrm_gem_lru_init(&priv->lru.unbacked, &priv->lru.lock);\n\tdrm_gem_lru_init(&priv->lru.pinned,   &priv->lru.lock);\n\tdrm_gem_lru_init(&priv->lru.willneed, &priv->lru.lock);\n\tdrm_gem_lru_init(&priv->lru.dontneed, &priv->lru.lock);\n\n\t \n\tfs_reclaim_acquire(GFP_KERNEL);\n\tmight_lock(&priv->lru.lock);\n\tfs_reclaim_release(GFP_KERNEL);\n\n\tdrm_mode_config_init(ddev);\n\n\tret = msm_init_vram(ddev);\n\tif (ret)\n\t\tgoto err_cleanup_mode_config;\n\n\tdma_set_max_seg_size(dev, UINT_MAX);\n\n\t \n\tret = component_bind_all(dev, ddev);\n\tif (ret)\n\t\tgoto err_deinit_vram;\n\n\t \n\tret = drm_aperture_remove_framebuffers(drv);\n\tif (ret)\n\t\tgoto err_msm_uninit;\n\n\tmsm_gem_shrinker_init(ddev);\n\n\tif (priv->kms_init) {\n\t\tret = priv->kms_init(ddev);\n\t\tif (ret) {\n\t\t\tDRM_DEV_ERROR(dev, \"failed to load kms\\n\");\n\t\t\tpriv->kms = NULL;\n\t\t\tgoto err_msm_uninit;\n\t\t}\n\t\tkms = priv->kms;\n\t} else {\n\t\t \n\t\tWARN_ON(dev->of_node);\n\t\tkms = NULL;\n\t}\n\n\t \n\tddev->mode_config.normalize_zpos = true;\n\n\tif (kms) {\n\t\tkms->dev = ddev;\n\t\tret = kms->funcs->hw_init(kms);\n\t\tif (ret) {\n\t\t\tDRM_DEV_ERROR(dev, \"kms hw init failed: %d\\n\", ret);\n\t\t\tgoto err_msm_uninit;\n\t\t}\n\t}\n\n\tdrm_helper_move_panel_connectors_to_head(ddev);\n\n\tddev->mode_config.funcs = &mode_config_funcs;\n\tddev->mode_config.helper_private = &mode_config_helper_funcs;\n\n\tdrm_for_each_crtc(crtc, ddev) {\n\t\tstruct msm_drm_thread *ev_thread;\n\n\t\t \n\t\tev_thread = &priv->event_thread[drm_crtc_index(crtc)];\n\t\tev_thread->dev = ddev;\n\t\tev_thread->worker = kthread_create_worker(0, \"crtc_event:%d\", crtc->base.id);\n\t\tif (IS_ERR(ev_thread->worker)) {\n\t\t\tret = PTR_ERR(ev_thread->worker);\n\t\t\tDRM_DEV_ERROR(dev, \"failed to create crtc_event kthread\\n\");\n\t\t\tev_thread->worker = NULL;\n\t\t\tgoto err_msm_uninit;\n\t\t}\n\n\t\tsched_set_fifo(ev_thread->worker->task);\n\t}\n\n\tret = drm_vblank_init(ddev, priv->num_crtcs);\n\tif (ret < 0) {\n\t\tDRM_DEV_ERROR(dev, \"failed to initialize vblank\\n\");\n\t\tgoto err_msm_uninit;\n\t}\n\n\tif (kms) {\n\t\tpm_runtime_get_sync(dev);\n\t\tret = msm_irq_install(ddev, kms->irq);\n\t\tpm_runtime_put_sync(dev);\n\t\tif (ret < 0) {\n\t\t\tDRM_DEV_ERROR(dev, \"failed to install IRQ handler\\n\");\n\t\t\tgoto err_msm_uninit;\n\t\t}\n\t}\n\n\tret = drm_dev_register(ddev, 0);\n\tif (ret)\n\t\tgoto err_msm_uninit;\n\n\tif (kms) {\n\t\tret = msm_disp_snapshot_init(ddev);\n\t\tif (ret)\n\t\t\tDRM_DEV_ERROR(dev, \"msm_disp_snapshot_init failed ret = %d\\n\", ret);\n\t}\n\tdrm_mode_config_reset(ddev);\n\n\tret = msm_debugfs_late_init(ddev);\n\tif (ret)\n\t\tgoto err_msm_uninit;\n\n\tdrm_kms_helper_poll_init(ddev);\n\n\tif (kms)\n\t\tmsm_fbdev_setup(ddev);\n\n\treturn 0;\n\nerr_msm_uninit:\n\tmsm_drm_uninit(dev);\n\n\treturn ret;\n\nerr_deinit_vram:\n\tmsm_deinit_vram(ddev);\nerr_cleanup_mode_config:\n\tdrm_mode_config_cleanup(ddev);\n\tdestroy_workqueue(priv->wq);\nerr_put_dev:\n\tdrm_dev_put(ddev);\n\n\treturn ret;\n}\n\n \n\nstatic void load_gpu(struct drm_device *dev)\n{\n\tstatic DEFINE_MUTEX(init_lock);\n\tstruct msm_drm_private *priv = dev->dev_private;\n\n\tmutex_lock(&init_lock);\n\n\tif (!priv->gpu)\n\t\tpriv->gpu = adreno_load_gpu(dev);\n\n\tmutex_unlock(&init_lock);\n}\n\nstatic int context_init(struct drm_device *dev, struct drm_file *file)\n{\n\tstatic atomic_t ident = ATOMIC_INIT(0);\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_file_private *ctx;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&ctx->submitqueues);\n\trwlock_init(&ctx->queuelock);\n\n\tkref_init(&ctx->ref);\n\tmsm_submitqueue_init(dev, ctx);\n\n\tctx->aspace = msm_gpu_create_private_address_space(priv->gpu, current);\n\tfile->driver_priv = ctx;\n\n\tctx->seqno = atomic_inc_return(&ident);\n\n\treturn 0;\n}\n\nstatic int msm_open(struct drm_device *dev, struct drm_file *file)\n{\n\t \n\tload_gpu(dev);\n\n\treturn context_init(dev, file);\n}\n\nstatic void context_close(struct msm_file_private *ctx)\n{\n\tmsm_submitqueue_close(ctx);\n\tmsm_file_private_put(ctx);\n}\n\nstatic void msm_postclose(struct drm_device *dev, struct drm_file *file)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_file_private *ctx = file->driver_priv;\n\n\t \n\tif (priv->gpu)\n\t\tmsm_file_private_set_sysprof(ctx, priv->gpu, 0);\n\n\tcontext_close(ctx);\n}\n\nint msm_crtc_enable_vblank(struct drm_crtc *crtc)\n{\n\tstruct drm_device *dev = crtc->dev;\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_kms *kms = priv->kms;\n\tif (!kms)\n\t\treturn -ENXIO;\n\tdrm_dbg_vbl(dev, \"crtc=%u\", crtc->base.id);\n\treturn vblank_ctrl_queue_work(priv, crtc, true);\n}\n\nvoid msm_crtc_disable_vblank(struct drm_crtc *crtc)\n{\n\tstruct drm_device *dev = crtc->dev;\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_kms *kms = priv->kms;\n\tif (!kms)\n\t\treturn;\n\tdrm_dbg_vbl(dev, \"crtc=%u\", crtc->base.id);\n\tvblank_ctrl_queue_work(priv, crtc, false);\n}\n\n \n\nstatic int msm_ioctl_get_param(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct drm_msm_param *args = data;\n\tstruct msm_gpu *gpu;\n\n\t \n\tif ((args->pipe != MSM_PIPE_3D0) || (args->pad != 0))\n\t\treturn -EINVAL;\n\n\tgpu = priv->gpu;\n\n\tif (!gpu)\n\t\treturn -ENXIO;\n\n\treturn gpu->funcs->get_param(gpu, file->driver_priv,\n\t\t\t\t     args->param, &args->value, &args->len);\n}\n\nstatic int msm_ioctl_set_param(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct drm_msm_param *args = data;\n\tstruct msm_gpu *gpu;\n\n\tif ((args->pipe != MSM_PIPE_3D0) || (args->pad != 0))\n\t\treturn -EINVAL;\n\n\tgpu = priv->gpu;\n\n\tif (!gpu)\n\t\treturn -ENXIO;\n\n\treturn gpu->funcs->set_param(gpu, file->driver_priv,\n\t\t\t\t     args->param, args->value, args->len);\n}\n\nstatic int msm_ioctl_gem_new(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct drm_msm_gem_new *args = data;\n\tuint32_t flags = args->flags;\n\n\tif (args->flags & ~MSM_BO_FLAGS) {\n\t\tDRM_ERROR(\"invalid flags: %08x\\n\", args->flags);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tif (flags & MSM_BO_UNCACHED) {\n\t\tflags &= ~MSM_BO_CACHED;\n\t\tflags |= MSM_BO_WC;\n\t}\n\n\tif (should_fail(&fail_gem_alloc, args->size))\n\t\treturn -ENOMEM;\n\n\treturn msm_gem_new_handle(dev, file, args->size,\n\t\t\targs->flags, &args->handle, NULL);\n}\n\nstatic inline ktime_t to_ktime(struct drm_msm_timespec timeout)\n{\n\treturn ktime_set(timeout.tv_sec, timeout.tv_nsec);\n}\n\nstatic int msm_ioctl_gem_cpu_prep(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct drm_msm_gem_cpu_prep *args = data;\n\tstruct drm_gem_object *obj;\n\tktime_t timeout = to_ktime(args->timeout);\n\tint ret;\n\n\tif (args->op & ~MSM_PREP_FLAGS) {\n\t\tDRM_ERROR(\"invalid op: %08x\\n\", args->op);\n\t\treturn -EINVAL;\n\t}\n\n\tobj = drm_gem_object_lookup(file, args->handle);\n\tif (!obj)\n\t\treturn -ENOENT;\n\n\tret = msm_gem_cpu_prep(obj, args->op, &timeout);\n\n\tdrm_gem_object_put(obj);\n\n\treturn ret;\n}\n\nstatic int msm_ioctl_gem_cpu_fini(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct drm_msm_gem_cpu_fini *args = data;\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\tobj = drm_gem_object_lookup(file, args->handle);\n\tif (!obj)\n\t\treturn -ENOENT;\n\n\tret = msm_gem_cpu_fini(obj);\n\n\tdrm_gem_object_put(obj);\n\n\treturn ret;\n}\n\nstatic int msm_ioctl_gem_info_iova(struct drm_device *dev,\n\t\tstruct drm_file *file, struct drm_gem_object *obj,\n\t\tuint64_t *iova)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_file_private *ctx = file->driver_priv;\n\n\tif (!priv->gpu)\n\t\treturn -EINVAL;\n\n\tif (should_fail(&fail_gem_iova, obj->size))\n\t\treturn -ENOMEM;\n\n\t \n\treturn msm_gem_get_iova(obj, ctx->aspace, iova);\n}\n\nstatic int msm_ioctl_gem_info_set_iova(struct drm_device *dev,\n\t\tstruct drm_file *file, struct drm_gem_object *obj,\n\t\tuint64_t iova)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct msm_file_private *ctx = file->driver_priv;\n\n\tif (!priv->gpu)\n\t\treturn -EINVAL;\n\n\t \n\tif (priv->gpu->aspace == ctx->aspace)\n\t\treturn -EOPNOTSUPP;\n\n\tif (should_fail(&fail_gem_iova, obj->size))\n\t\treturn -ENOMEM;\n\n\treturn msm_gem_set_iova(obj, ctx->aspace, iova);\n}\n\nstatic int msm_ioctl_gem_info(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct drm_msm_gem_info *args = data;\n\tstruct drm_gem_object *obj;\n\tstruct msm_gem_object *msm_obj;\n\tint i, ret = 0;\n\n\tif (args->pad)\n\t\treturn -EINVAL;\n\n\tswitch (args->info) {\n\tcase MSM_INFO_GET_OFFSET:\n\tcase MSM_INFO_GET_IOVA:\n\tcase MSM_INFO_SET_IOVA:\n\tcase MSM_INFO_GET_FLAGS:\n\t\t \n\t\tif (args->len)\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tcase MSM_INFO_SET_NAME:\n\tcase MSM_INFO_GET_NAME:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tobj = drm_gem_object_lookup(file, args->handle);\n\tif (!obj)\n\t\treturn -ENOENT;\n\n\tmsm_obj = to_msm_bo(obj);\n\n\tswitch (args->info) {\n\tcase MSM_INFO_GET_OFFSET:\n\t\targs->value = msm_gem_mmap_offset(obj);\n\t\tbreak;\n\tcase MSM_INFO_GET_IOVA:\n\t\tret = msm_ioctl_gem_info_iova(dev, file, obj, &args->value);\n\t\tbreak;\n\tcase MSM_INFO_SET_IOVA:\n\t\tret = msm_ioctl_gem_info_set_iova(dev, file, obj, args->value);\n\t\tbreak;\n\tcase MSM_INFO_GET_FLAGS:\n\t\tif (obj->import_attach) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\targs->value = to_msm_bo(obj)->flags & MSM_BO_FLAGS;\n\t\tret = 0;\n\t\tbreak;\n\tcase MSM_INFO_SET_NAME:\n\t\t \n\t\tif (args->len >= sizeof(msm_obj->name)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(msm_obj->name, u64_to_user_ptr(args->value),\n\t\t\t\t   args->len)) {\n\t\t\tmsm_obj->name[0] = '\\0';\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tmsm_obj->name[args->len] = '\\0';\n\t\tfor (i = 0; i < args->len; i++) {\n\t\t\tif (!isprint(msm_obj->name[i])) {\n\t\t\t\tmsm_obj->name[i] = '\\0';\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase MSM_INFO_GET_NAME:\n\t\tif (args->value && (args->len < strlen(msm_obj->name))) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\targs->len = strlen(msm_obj->name);\n\t\tif (args->value) {\n\t\t\tif (copy_to_user(u64_to_user_ptr(args->value),\n\t\t\t\t\t msm_obj->name, args->len))\n\t\t\t\tret = -EFAULT;\n\t\t}\n\t\tbreak;\n\t}\n\n\tdrm_gem_object_put(obj);\n\n\treturn ret;\n}\n\nstatic int wait_fence(struct msm_gpu_submitqueue *queue, uint32_t fence_id,\n\t\t      ktime_t timeout, uint32_t flags)\n{\n\tstruct dma_fence *fence;\n\tint ret;\n\n\tif (fence_after(fence_id, queue->last_fence)) {\n\t\tDRM_ERROR_RATELIMITED(\"waiting on invalid fence: %u (of %u)\\n\",\n\t\t\t\t      fence_id, queue->last_fence);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tspin_lock(&queue->idr_lock);\n\tfence = idr_find(&queue->fence_idr, fence_id);\n\tif (fence)\n\t\tfence = dma_fence_get_rcu(fence);\n\tspin_unlock(&queue->idr_lock);\n\n\tif (!fence)\n\t\treturn 0;\n\n\tif (flags & MSM_WAIT_FENCE_BOOST)\n\t\tdma_fence_set_deadline(fence, ktime_get());\n\n\tret = dma_fence_wait_timeout(fence, true, timeout_to_jiffies(&timeout));\n\tif (ret == 0) {\n\t\tret = -ETIMEDOUT;\n\t} else if (ret != -ERESTARTSYS) {\n\t\tret = 0;\n\t}\n\n\tdma_fence_put(fence);\n\n\treturn ret;\n}\n\nstatic int msm_ioctl_wait_fence(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct drm_msm_wait_fence *args = data;\n\tstruct msm_gpu_submitqueue *queue;\n\tint ret;\n\n\tif (args->flags & ~MSM_WAIT_FENCE_FLAGS) {\n\t\tDRM_ERROR(\"invalid flags: %08x\\n\", args->flags);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!priv->gpu)\n\t\treturn 0;\n\n\tqueue = msm_submitqueue_get(file->driver_priv, args->queueid);\n\tif (!queue)\n\t\treturn -ENOENT;\n\n\tret = wait_fence(queue, args->fence, to_ktime(args->timeout), args->flags);\n\n\tmsm_submitqueue_put(queue);\n\n\treturn ret;\n}\n\nstatic int msm_ioctl_gem_madvise(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct drm_msm_gem_madvise *args = data;\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\tswitch (args->madv) {\n\tcase MSM_MADV_DONTNEED:\n\tcase MSM_MADV_WILLNEED:\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tobj = drm_gem_object_lookup(file, args->handle);\n\tif (!obj) {\n\t\treturn -ENOENT;\n\t}\n\n\tret = msm_gem_madvise(obj, args->madv);\n\tif (ret >= 0) {\n\t\targs->retained = ret;\n\t\tret = 0;\n\t}\n\n\tdrm_gem_object_put(obj);\n\n\treturn ret;\n}\n\n\nstatic int msm_ioctl_submitqueue_new(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct drm_msm_submitqueue *args = data;\n\n\tif (args->flags & ~MSM_SUBMITQUEUE_FLAGS)\n\t\treturn -EINVAL;\n\n\treturn msm_submitqueue_create(dev, file->driver_priv, args->prio,\n\t\targs->flags, &args->id);\n}\n\nstatic int msm_ioctl_submitqueue_query(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\treturn msm_submitqueue_query(dev, file->driver_priv, data);\n}\n\nstatic int msm_ioctl_submitqueue_close(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tu32 id = *(u32 *) data;\n\n\treturn msm_submitqueue_remove(file->driver_priv, id);\n}\n\nstatic const struct drm_ioctl_desc msm_ioctls[] = {\n\tDRM_IOCTL_DEF_DRV(MSM_GET_PARAM,    msm_ioctl_get_param,    DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_SET_PARAM,    msm_ioctl_set_param,    DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_GEM_NEW,      msm_ioctl_gem_new,      DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_GEM_INFO,     msm_ioctl_gem_info,     DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_GEM_CPU_PREP, msm_ioctl_gem_cpu_prep, DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_GEM_CPU_FINI, msm_ioctl_gem_cpu_fini, DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_GEM_SUBMIT,   msm_ioctl_gem_submit,   DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_WAIT_FENCE,   msm_ioctl_wait_fence,   DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_GEM_MADVISE,  msm_ioctl_gem_madvise,  DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_SUBMITQUEUE_NEW,   msm_ioctl_submitqueue_new,   DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_SUBMITQUEUE_CLOSE, msm_ioctl_submitqueue_close, DRM_RENDER_ALLOW),\n\tDRM_IOCTL_DEF_DRV(MSM_SUBMITQUEUE_QUERY, msm_ioctl_submitqueue_query, DRM_RENDER_ALLOW),\n};\n\nstatic void msm_show_fdinfo(struct drm_printer *p, struct drm_file *file)\n{\n\tstruct drm_device *dev = file->minor->dev;\n\tstruct msm_drm_private *priv = dev->dev_private;\n\n\tif (!priv->gpu)\n\t\treturn;\n\n\tmsm_gpu_show_fdinfo(priv->gpu, file->driver_priv, p);\n\n\tdrm_show_memory_stats(p, file);\n}\n\nstatic const struct file_operations fops = {\n\t.owner = THIS_MODULE,\n\tDRM_GEM_FOPS,\n\t.show_fdinfo = drm_show_fdinfo,\n};\n\nstatic const struct drm_driver msm_driver = {\n\t.driver_features    = DRIVER_GEM |\n\t\t\t\tDRIVER_RENDER |\n\t\t\t\tDRIVER_ATOMIC |\n\t\t\t\tDRIVER_MODESET |\n\t\t\t\tDRIVER_SYNCOBJ,\n\t.open               = msm_open,\n\t.postclose          = msm_postclose,\n\t.dumb_create        = msm_gem_dumb_create,\n\t.dumb_map_offset    = msm_gem_dumb_map_offset,\n\t.gem_prime_import_sg_table = msm_gem_prime_import_sg_table,\n#ifdef CONFIG_DEBUG_FS\n\t.debugfs_init       = msm_debugfs_init,\n#endif\n\t.show_fdinfo        = msm_show_fdinfo,\n\t.ioctls             = msm_ioctls,\n\t.num_ioctls         = ARRAY_SIZE(msm_ioctls),\n\t.fops               = &fops,\n\t.name               = \"msm\",\n\t.desc               = \"MSM Snapdragon DRM\",\n\t.date               = \"20130625\",\n\t.major              = MSM_VERSION_MAJOR,\n\t.minor              = MSM_VERSION_MINOR,\n\t.patchlevel         = MSM_VERSION_PATCHLEVEL,\n};\n\nint msm_pm_prepare(struct device *dev)\n{\n\tstruct msm_drm_private *priv = dev_get_drvdata(dev);\n\tstruct drm_device *ddev = priv ? priv->dev : NULL;\n\n\tif (!priv || !priv->kms)\n\t\treturn 0;\n\n\treturn drm_mode_config_helper_suspend(ddev);\n}\n\nvoid msm_pm_complete(struct device *dev)\n{\n\tstruct msm_drm_private *priv = dev_get_drvdata(dev);\n\tstruct drm_device *ddev = priv ? priv->dev : NULL;\n\n\tif (!priv || !priv->kms)\n\t\treturn;\n\n\tdrm_mode_config_helper_resume(ddev);\n}\n\nstatic const struct dev_pm_ops msm_pm_ops = {\n\t.prepare = msm_pm_prepare,\n\t.complete = msm_pm_complete,\n};\n\n \n\n \nstatic int add_components_mdp(struct device *master_dev,\n\t\t\t      struct component_match **matchptr)\n{\n\tstruct device_node *np = master_dev->of_node;\n\tstruct device_node *ep_node;\n\n\tfor_each_endpoint_of_node(np, ep_node) {\n\t\tstruct device_node *intf;\n\t\tstruct of_endpoint ep;\n\t\tint ret;\n\n\t\tret = of_graph_parse_endpoint(ep_node, &ep);\n\t\tif (ret) {\n\t\t\tDRM_DEV_ERROR(master_dev, \"unable to parse port endpoint\\n\");\n\t\t\tof_node_put(ep_node);\n\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tif (of_device_is_compatible(np, \"qcom,mdp4\") &&\n\t\t    ep.port == 0)\n\t\t\tcontinue;\n\n\t\t \n\t\tintf = of_graph_get_remote_port_parent(ep_node);\n\t\tif (!intf)\n\t\t\tcontinue;\n\n\t\tif (of_device_is_available(intf))\n\t\t\tdrm_of_component_match_add(master_dev, matchptr,\n\t\t\t\t\t\t   component_compare_of, intf);\n\n\t\tof_node_put(intf);\n\t}\n\n\treturn 0;\n}\n\n \nstatic const struct of_device_id msm_gpu_match[] = {\n\t{ .compatible = \"qcom,adreno\" },\n\t{ .compatible = \"qcom,adreno-3xx\" },\n\t{ .compatible = \"amd,imageon\" },\n\t{ .compatible = \"qcom,kgsl-3d0\" },\n\t{ },\n};\n\nstatic int add_gpu_components(struct device *dev,\n\t\t\t      struct component_match **matchptr)\n{\n\tstruct device_node *np;\n\n\tnp = of_find_matching_node(NULL, msm_gpu_match);\n\tif (!np)\n\t\treturn 0;\n\n\tif (of_device_is_available(np))\n\t\tdrm_of_component_match_add(dev, matchptr, component_compare_of, np);\n\n\tof_node_put(np);\n\n\treturn 0;\n}\n\nstatic int msm_drm_bind(struct device *dev)\n{\n\treturn msm_drm_init(dev, &msm_driver);\n}\n\nstatic void msm_drm_unbind(struct device *dev)\n{\n\tmsm_drm_uninit(dev);\n}\n\nconst struct component_master_ops msm_drm_ops = {\n\t.bind = msm_drm_bind,\n\t.unbind = msm_drm_unbind,\n};\n\nint msm_drv_probe(struct device *master_dev,\n\tint (*kms_init)(struct drm_device *dev))\n{\n\tstruct msm_drm_private *priv;\n\tstruct component_match *match = NULL;\n\tint ret;\n\n\tpriv = devm_kzalloc(master_dev, sizeof(*priv), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tpriv->kms_init = kms_init;\n\tdev_set_drvdata(master_dev, priv);\n\n\t \n\tif (kms_init) {\n\t\tret = add_components_mdp(master_dev, &match);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tret = add_gpu_components(master_dev, &match);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tret = dma_set_mask_and_coherent(master_dev, ~0);\n\tif (ret)\n\t\treturn ret;\n\n\tret = component_master_add_with_match(master_dev, &msm_drm_ops, match);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n \n\nstatic int msm_pdev_probe(struct platform_device *pdev)\n{\n\treturn msm_drv_probe(&pdev->dev, NULL);\n}\n\nstatic int msm_pdev_remove(struct platform_device *pdev)\n{\n\tcomponent_master_del(&pdev->dev, &msm_drm_ops);\n\n\treturn 0;\n}\n\nvoid msm_drv_shutdown(struct platform_device *pdev)\n{\n\tstruct msm_drm_private *priv = platform_get_drvdata(pdev);\n\tstruct drm_device *drm = priv ? priv->dev : NULL;\n\n\t \n\tif (drm && drm->registered && priv->kms)\n\t\tdrm_atomic_helper_shutdown(drm);\n}\n\nstatic struct platform_driver msm_platform_driver = {\n\t.probe      = msm_pdev_probe,\n\t.remove     = msm_pdev_remove,\n\t.shutdown   = msm_drv_shutdown,\n\t.driver     = {\n\t\t.name   = \"msm\",\n\t\t.pm     = &msm_pm_ops,\n\t},\n};\n\nstatic int __init msm_drm_register(void)\n{\n\tif (!modeset)\n\t\treturn -EINVAL;\n\n\tDBG(\"init\");\n\tmsm_mdp_register();\n\tmsm_dpu_register();\n\tmsm_dsi_register();\n\tmsm_hdmi_register();\n\tmsm_dp_register();\n\tadreno_register();\n\tmsm_mdp4_register();\n\tmsm_mdss_register();\n\treturn platform_driver_register(&msm_platform_driver);\n}\n\nstatic void __exit msm_drm_unregister(void)\n{\n\tDBG(\"fini\");\n\tplatform_driver_unregister(&msm_platform_driver);\n\tmsm_mdss_unregister();\n\tmsm_mdp4_unregister();\n\tmsm_dp_unregister();\n\tmsm_hdmi_unregister();\n\tadreno_unregister();\n\tmsm_dsi_unregister();\n\tmsm_mdp_unregister();\n\tmsm_dpu_unregister();\n}\n\nmodule_init(msm_drm_register);\nmodule_exit(msm_drm_unregister);\n\nMODULE_AUTHOR(\"Rob Clark <robdclark@gmail.com\");\nMODULE_DESCRIPTION(\"MSM DRM Driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}