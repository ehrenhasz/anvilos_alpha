{
  "module_name": "adreno_gpu.h",
  "hash_id": "6a4d96fb54c2532fb2c5cf1a3d0552ca9ad7415267892f9a5326d3c0d6d5b5b6",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/msm/adreno/adreno_gpu.h",
  "human_readable_source": " \n \n\n#ifndef __ADRENO_GPU_H__\n#define __ADRENO_GPU_H__\n\n#include <linux/firmware.h>\n#include <linux/iopoll.h>\n\n#include \"msm_gpu.h\"\n\n#include \"adreno_common.xml.h\"\n#include \"adreno_pm4.xml.h\"\n\nextern bool snapshot_debugbus;\nextern bool allow_vram_carveout;\n\nenum {\n\tADRENO_FW_PM4 = 0,\n\tADRENO_FW_SQE = 0,  \n\tADRENO_FW_PFP = 1,\n\tADRENO_FW_GMU = 1,  \n\tADRENO_FW_GPMU = 2,\n\tADRENO_FW_MAX,\n};\n\n \nenum adreno_family {\n\tADRENO_2XX_GEN1,   \n\tADRENO_2XX_GEN2,   \n\tADRENO_3XX,\n\tADRENO_4XX,\n\tADRENO_5XX,\n\tADRENO_6XX_GEN1,   \n\tADRENO_6XX_GEN2,   \n\tADRENO_6XX_GEN3,   \n\tADRENO_6XX_GEN4,   \n};\n\n#define ADRENO_QUIRK_TWO_PASS_USE_WFI\t\tBIT(0)\n#define ADRENO_QUIRK_FAULT_DETECT_MASK\t\tBIT(1)\n#define ADRENO_QUIRK_LMLOADKILL_DISABLE\t\tBIT(2)\n#define ADRENO_QUIRK_HAS_HW_APRIV\t\tBIT(3)\n#define ADRENO_QUIRK_HAS_CACHED_COHERENT\tBIT(4)\n\n \n#define ADRENO_CHIPID_FMT \"u.%u.%u.%u\"\n#define ADRENO_CHIPID_ARGS(_c) \\\n\t(((_c) >> 24) & 0xff), \\\n\t(((_c) >> 16) & 0xff), \\\n\t(((_c) >> 8)  & 0xff), \\\n\t((_c) & 0xff)\n\nstruct adreno_gpu_funcs {\n\tstruct msm_gpu_funcs base;\n\tint (*get_timestamp)(struct msm_gpu *gpu, uint64_t *value);\n};\n\nstruct adreno_reglist {\n\tu32 offset;\n\tu32 value;\n};\n\nextern const struct adreno_reglist a612_hwcg[], a615_hwcg[], a630_hwcg[], a640_hwcg[], a650_hwcg[];\nextern const struct adreno_reglist a660_hwcg[], a690_hwcg[];\n\nstruct adreno_speedbin {\n\tuint16_t fuse;\n\tuint16_t speedbin;\n};\n\nstruct adreno_info {\n\tconst char *machine;\n\t \n\tuint32_t *chip_ids;\n\tenum adreno_family family;\n\tuint32_t revn;\n\tconst char *fw[ADRENO_FW_MAX];\n\tuint32_t gmem;\n\tu64 quirks;\n\tstruct msm_gpu *(*init)(struct drm_device *dev);\n\tconst char *zapfw;\n\tu32 inactive_period;\n\tconst struct adreno_reglist *hwcg;\n\tu64 address_space_size;\n\t \n\tstruct adreno_speedbin *speedbins;\n};\n\n#define ADRENO_CHIP_IDS(tbl...) (uint32_t[]) { tbl, 0 }\n\n \n#define ADRENO_SPEEDBINS(tbl...) (struct adreno_speedbin[]) { tbl {SHRT_MAX, 0} }\n\nstruct adreno_gpu {\n\tstruct msm_gpu base;\n\tconst struct adreno_info *info;\n\tuint32_t chip_id;\n\tuint16_t speedbin;\n\tconst struct adreno_gpu_funcs *funcs;\n\n\t \n\tconst unsigned int *registers;\n\n\t \n\tenum {\n\t\tFW_LOCATION_UNKNOWN = 0,\n\t\tFW_LOCATION_NEW,        \n\t\tFW_LOCATION_LEGACY,     \n\t\tFW_LOCATION_HELPER,\n\t} fwloc;\n\n\t \n\tconst struct firmware *fw[ADRENO_FW_MAX];\n\n\t \n\tconst unsigned int *reg_offsets;\n\tbool gmu_is_wrapper;\n};\n#define to_adreno_gpu(x) container_of(x, struct adreno_gpu, base)\n\nstruct adreno_ocmem {\n\tstruct ocmem *ocmem;\n\tunsigned long base;\n\tvoid *hdl;\n};\n\n \nstruct adreno_platform_config {\n\tuint32_t chip_id;\n\tconst struct adreno_info *info;\n};\n\n#define ADRENO_IDLE_TIMEOUT msecs_to_jiffies(1000)\n\n#define spin_until(X) ({                                   \\\n\tint __ret = -ETIMEDOUT;                            \\\n\tunsigned long __t = jiffies + ADRENO_IDLE_TIMEOUT; \\\n\tdo {                                               \\\n\t\tif (X) {                                   \\\n\t\t\t__ret = 0;                         \\\n\t\t\tbreak;                             \\\n\t\t}                                          \\\n\t} while (time_before(jiffies, __t));               \\\n\t__ret;                                             \\\n})\n\nstatic inline uint8_t adreno_patchid(const struct adreno_gpu *gpu)\n{\n\t \n\tWARN_ON_ONCE(gpu->info->family >= ADRENO_6XX_GEN1);\n\treturn gpu->chip_id & 0xff;\n}\n\nstatic inline bool adreno_is_revn(const struct adreno_gpu *gpu, uint32_t revn)\n{\n\tif (WARN_ON_ONCE(!gpu->info))\n\t\treturn false;\n\treturn gpu->info->revn == revn;\n}\n\nstatic inline bool adreno_has_gmu_wrapper(const struct adreno_gpu *gpu)\n{\n\treturn gpu->gmu_is_wrapper;\n}\n\nstatic inline bool adreno_is_a2xx(const struct adreno_gpu *gpu)\n{\n\tif (WARN_ON_ONCE(!gpu->info))\n\t\treturn false;\n\treturn gpu->info->family <= ADRENO_2XX_GEN2;\n}\n\nstatic inline bool adreno_is_a20x(const struct adreno_gpu *gpu)\n{\n\tif (WARN_ON_ONCE(!gpu->info))\n\t\treturn false;\n\treturn gpu->info->family == ADRENO_2XX_GEN1;\n}\n\nstatic inline bool adreno_is_a225(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 225);\n}\n\nstatic inline bool adreno_is_a305(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 305);\n}\n\nstatic inline bool adreno_is_a306(const struct adreno_gpu *gpu)\n{\n\t \n\treturn adreno_is_revn(gpu, 307);\n}\n\nstatic inline bool adreno_is_a320(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 320);\n}\n\nstatic inline bool adreno_is_a330(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 330);\n}\n\nstatic inline bool adreno_is_a330v2(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_a330(gpu) && (adreno_patchid(gpu) > 0);\n}\n\nstatic inline int adreno_is_a405(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 405);\n}\n\nstatic inline int adreno_is_a420(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 420);\n}\n\nstatic inline int adreno_is_a430(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 430);\n}\n\nstatic inline int adreno_is_a506(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 506);\n}\n\nstatic inline int adreno_is_a508(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 508);\n}\n\nstatic inline int adreno_is_a509(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 509);\n}\n\nstatic inline int adreno_is_a510(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 510);\n}\n\nstatic inline int adreno_is_a512(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 512);\n}\n\nstatic inline int adreno_is_a530(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 530);\n}\n\nstatic inline int adreno_is_a540(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 540);\n}\n\nstatic inline int adreno_is_a610(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 610);\n}\n\nstatic inline int adreno_is_a618(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 618);\n}\n\nstatic inline int adreno_is_a619(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 619);\n}\n\nstatic inline int adreno_is_a619_holi(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_a619(gpu) && adreno_has_gmu_wrapper(gpu);\n}\n\nstatic inline int adreno_is_a630(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 630);\n}\n\nstatic inline int adreno_is_a640(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 640);\n}\n\nstatic inline int adreno_is_a650(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 650);\n}\n\nstatic inline int adreno_is_7c3(const struct adreno_gpu *gpu)\n{\n\treturn gpu->info->chip_ids[0] == 0x06030500;\n}\n\nstatic inline int adreno_is_a660(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 660);\n}\n\nstatic inline int adreno_is_a680(const struct adreno_gpu *gpu)\n{\n\treturn adreno_is_revn(gpu, 680);\n}\n\nstatic inline int adreno_is_a690(const struct adreno_gpu *gpu)\n{\n\treturn gpu->info->chip_ids[0] == 0x06090000;\n}\n\n \nstatic inline int adreno_is_a630_family(const struct adreno_gpu *gpu)\n{\n\tif (WARN_ON_ONCE(!gpu->info))\n\t\treturn false;\n\treturn gpu->info->family == ADRENO_6XX_GEN1;\n}\n\nstatic inline int adreno_is_a660_family(const struct adreno_gpu *gpu)\n{\n\tif (WARN_ON_ONCE(!gpu->info))\n\t\treturn false;\n\treturn gpu->info->family == ADRENO_6XX_GEN4;\n}\n\n \nstatic inline int adreno_is_a650_family(const struct adreno_gpu *gpu)\n{\n\tif (WARN_ON_ONCE(!gpu->info))\n\t\treturn false;\n\treturn gpu->info->family >= ADRENO_6XX_GEN3;\n}\n\nstatic inline int adreno_is_a640_family(const struct adreno_gpu *gpu)\n{\n\tif (WARN_ON_ONCE(!gpu->info))\n\t\treturn false;\n\treturn gpu->info->family == ADRENO_6XX_GEN2;\n}\n\nu64 adreno_private_address_space_size(struct msm_gpu *gpu);\nint adreno_get_param(struct msm_gpu *gpu, struct msm_file_private *ctx,\n\t\t     uint32_t param, uint64_t *value, uint32_t *len);\nint adreno_set_param(struct msm_gpu *gpu, struct msm_file_private *ctx,\n\t\t     uint32_t param, uint64_t value, uint32_t len);\nconst struct firmware *adreno_request_fw(struct adreno_gpu *adreno_gpu,\n\t\tconst char *fwname);\nstruct drm_gem_object *adreno_fw_create_bo(struct msm_gpu *gpu,\n\t\tconst struct firmware *fw, u64 *iova);\nint adreno_hw_init(struct msm_gpu *gpu);\nvoid adreno_recover(struct msm_gpu *gpu);\nvoid adreno_flush(struct msm_gpu *gpu, struct msm_ringbuffer *ring, u32 reg);\nbool adreno_idle(struct msm_gpu *gpu, struct msm_ringbuffer *ring);\n#if defined(CONFIG_DEBUG_FS) || defined(CONFIG_DEV_COREDUMP)\nvoid adreno_show(struct msm_gpu *gpu, struct msm_gpu_state *state,\n\t\tstruct drm_printer *p);\n#endif\nvoid adreno_dump_info(struct msm_gpu *gpu);\nvoid adreno_dump(struct msm_gpu *gpu);\nvoid adreno_wait_ring(struct msm_ringbuffer *ring, uint32_t ndwords);\nstruct msm_ringbuffer *adreno_active_ring(struct msm_gpu *gpu);\n\nint adreno_gpu_ocmem_init(struct device *dev, struct adreno_gpu *adreno_gpu,\n\t\t\t  struct adreno_ocmem *ocmem);\nvoid adreno_gpu_ocmem_cleanup(struct adreno_ocmem *ocmem);\n\nint adreno_gpu_init(struct drm_device *drm, struct platform_device *pdev,\n\t\tstruct adreno_gpu *gpu, const struct adreno_gpu_funcs *funcs,\n\t\tint nr_rings);\nvoid adreno_gpu_cleanup(struct adreno_gpu *gpu);\nint adreno_load_fw(struct adreno_gpu *adreno_gpu);\n\nvoid adreno_gpu_state_destroy(struct msm_gpu_state *state);\n\nint adreno_gpu_state_get(struct msm_gpu *gpu, struct msm_gpu_state *state);\nint adreno_gpu_state_put(struct msm_gpu_state *state);\nvoid adreno_show_object(struct drm_printer *p, void **ptr, int len,\n\t\tbool *encoded);\n\n \nstruct msm_gem_address_space *\nadreno_create_address_space(struct msm_gpu *gpu,\n\t\t\t    struct platform_device *pdev);\n\nstruct msm_gem_address_space *\nadreno_iommu_create_address_space(struct msm_gpu *gpu,\n\t\t\t\t  struct platform_device *pdev,\n\t\t\t\t  unsigned long quirks);\n\nint adreno_fault_handler(struct msm_gpu *gpu, unsigned long iova, int flags,\n\t\t\t struct adreno_smmu_fault_info *info, const char *block,\n\t\t\t u32 scratch[4]);\n\nint adreno_read_speedbin(struct device *dev, u32 *speedbin);\n\n \nint adreno_zap_shader_load(struct msm_gpu *gpu, u32 pasid);\n\n \n\nstatic inline void\nOUT_PKT0(struct msm_ringbuffer *ring, uint16_t regindx, uint16_t cnt)\n{\n\tadreno_wait_ring(ring, cnt+1);\n\tOUT_RING(ring, CP_TYPE0_PKT | ((cnt-1) << 16) | (regindx & 0x7FFF));\n}\n\n \nstatic inline void\nOUT_PKT2(struct msm_ringbuffer *ring)\n{\n\tadreno_wait_ring(ring, 1);\n\tOUT_RING(ring, CP_TYPE2_PKT);\n}\n\nstatic inline void\nOUT_PKT3(struct msm_ringbuffer *ring, uint8_t opcode, uint16_t cnt)\n{\n\tadreno_wait_ring(ring, cnt+1);\n\tOUT_RING(ring, CP_TYPE3_PKT | ((cnt-1) << 16) | ((opcode & 0xFF) << 8));\n}\n\nstatic inline u32 PM4_PARITY(u32 val)\n{\n\treturn (0x9669 >> (0xF & (val ^\n\t\t(val >> 4) ^ (val >> 8) ^ (val >> 12) ^\n\t\t(val >> 16) ^ ((val) >> 20) ^ (val >> 24) ^\n\t\t(val >> 28)))) & 1;\n}\n\n \n#define TYPE4_MAX_PAYLOAD 127\n\n#define PKT4(_reg, _cnt) \\\n\t(CP_TYPE4_PKT | ((_cnt) << 0) | (PM4_PARITY((_cnt)) << 7) | \\\n\t (((_reg) & 0x3FFFF) << 8) | (PM4_PARITY((_reg)) << 27))\n\nstatic inline void\nOUT_PKT4(struct msm_ringbuffer *ring, uint16_t regindx, uint16_t cnt)\n{\n\tadreno_wait_ring(ring, cnt + 1);\n\tOUT_RING(ring, PKT4(regindx, cnt));\n}\n\nstatic inline void\nOUT_PKT7(struct msm_ringbuffer *ring, uint8_t opcode, uint16_t cnt)\n{\n\tadreno_wait_ring(ring, cnt + 1);\n\tOUT_RING(ring, CP_TYPE7_PKT | (cnt << 0) | (PM4_PARITY(cnt) << 15) |\n\t\t((opcode & 0x7F) << 16) | (PM4_PARITY(opcode) << 23));\n}\n\nstruct msm_gpu *a2xx_gpu_init(struct drm_device *dev);\nstruct msm_gpu *a3xx_gpu_init(struct drm_device *dev);\nstruct msm_gpu *a4xx_gpu_init(struct drm_device *dev);\nstruct msm_gpu *a5xx_gpu_init(struct drm_device *dev);\nstruct msm_gpu *a6xx_gpu_init(struct drm_device *dev);\n\nstatic inline uint32_t get_wptr(struct msm_ringbuffer *ring)\n{\n\treturn (ring->cur - ring->start) % (MSM_GPU_RINGBUFFER_SZ >> 2);\n}\n\n \n#define ADRENO_PROTECT_RW(_reg, _len) \\\n\t((1 << 30) | (1 << 29) | \\\n\t((ilog2((_len)) & 0x1F) << 24) | (((_reg) << 2) & 0xFFFFF))\n\n \n#define ADRENO_PROTECT_RDONLY(_reg, _len) \\\n\t((1 << 29) \\\n\t((ilog2((_len)) & 0x1F) << 24) | (((_reg) << 2) & 0xFFFFF))\n\n\n#define gpu_poll_timeout(gpu, addr, val, cond, interval, timeout) \\\n\treadl_poll_timeout((gpu)->mmio + ((addr) << 2), val, cond, \\\n\t\tinterval, timeout)\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}