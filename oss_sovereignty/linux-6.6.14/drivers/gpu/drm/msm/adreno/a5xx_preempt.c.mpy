{
  "module_name": "a5xx_preempt.c",
  "hash_id": "9d3d89f175d64f81393f9a704fa0b4b898c0f0e422407e00f6680b235275ff9f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/msm/adreno/a5xx_preempt.c",
  "human_readable_source": "\n \n\n#include \"msm_gem.h\"\n#include \"a5xx_gpu.h\"\n\n \nstatic inline bool try_preempt_state(struct a5xx_gpu *a5xx_gpu,\n\t\tenum preempt_state old, enum preempt_state new)\n{\n\tenum preempt_state cur = atomic_cmpxchg(&a5xx_gpu->preempt_state,\n\t\told, new);\n\n\treturn (cur == old);\n}\n\n \nstatic inline void set_preempt_state(struct a5xx_gpu *gpu,\n\t\tenum preempt_state new)\n{\n\t \n\tsmp_mb__before_atomic();\n\tatomic_set(&gpu->preempt_state, new);\n\t \n\tsmp_mb__after_atomic();\n}\n\n \nstatic inline void update_wptr(struct msm_gpu *gpu, struct msm_ringbuffer *ring)\n{\n\tunsigned long flags;\n\tuint32_t wptr;\n\n\tif (!ring)\n\t\treturn;\n\n\tspin_lock_irqsave(&ring->preempt_lock, flags);\n\twptr = get_wptr(ring);\n\tspin_unlock_irqrestore(&ring->preempt_lock, flags);\n\n\tgpu_write(gpu, REG_A5XX_CP_RB_WPTR, wptr);\n}\n\n \nstatic struct msm_ringbuffer *get_next_ring(struct msm_gpu *gpu)\n{\n\tunsigned long flags;\n\tint i;\n\n\tfor (i = 0; i < gpu->nr_rings; i++) {\n\t\tbool empty;\n\t\tstruct msm_ringbuffer *ring = gpu->rb[i];\n\n\t\tspin_lock_irqsave(&ring->preempt_lock, flags);\n\t\tempty = (get_wptr(ring) == gpu->funcs->get_rptr(gpu, ring));\n\t\tspin_unlock_irqrestore(&ring->preempt_lock, flags);\n\n\t\tif (!empty)\n\t\t\treturn ring;\n\t}\n\n\treturn NULL;\n}\n\nstatic void a5xx_preempt_timer(struct timer_list *t)\n{\n\tstruct a5xx_gpu *a5xx_gpu = from_timer(a5xx_gpu, t, preempt_timer);\n\tstruct msm_gpu *gpu = &a5xx_gpu->base.base;\n\tstruct drm_device *dev = gpu->dev;\n\n\tif (!try_preempt_state(a5xx_gpu, PREEMPT_TRIGGERED, PREEMPT_FAULTED))\n\t\treturn;\n\n\tDRM_DEV_ERROR(dev->dev, \"%s: preemption timed out\\n\", gpu->name);\n\tkthread_queue_work(gpu->worker, &gpu->recover_work);\n}\n\n \nvoid a5xx_preempt_trigger(struct msm_gpu *gpu)\n{\n\tstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\n\tstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\n\tunsigned long flags;\n\tstruct msm_ringbuffer *ring;\n\n\tif (gpu->nr_rings == 1)\n\t\treturn;\n\n\t \n\tif (!try_preempt_state(a5xx_gpu, PREEMPT_NONE, PREEMPT_START))\n\t\treturn;\n\n\t \n\tring = get_next_ring(gpu);\n\n\t \n\tif (!ring || (a5xx_gpu->cur_ring == ring)) {\n\t\t \n\n\t\tset_preempt_state(a5xx_gpu, PREEMPT_ABORT);\n\t\tupdate_wptr(gpu, a5xx_gpu->cur_ring);\n\t\tset_preempt_state(a5xx_gpu, PREEMPT_NONE);\n\t\treturn;\n\t}\n\n\t \n\tspin_lock_irqsave(&ring->preempt_lock, flags);\n\ta5xx_gpu->preempt[ring->id]->wptr = get_wptr(ring);\n\tspin_unlock_irqrestore(&ring->preempt_lock, flags);\n\n\t \n\tgpu_write64(gpu, REG_A5XX_CP_CONTEXT_SWITCH_RESTORE_ADDR_LO,\n\t\ta5xx_gpu->preempt_iova[ring->id]);\n\n\ta5xx_gpu->next_ring = ring;\n\n\t \n\tmod_timer(&a5xx_gpu->preempt_timer, jiffies + msecs_to_jiffies(10000));\n\n\t \n\tset_preempt_state(a5xx_gpu, PREEMPT_TRIGGERED);\n\n\t \n\twmb();\n\n\t \n\tgpu_write(gpu, REG_A5XX_CP_CONTEXT_SWITCH_CNTL, 1);\n}\n\nvoid a5xx_preempt_irq(struct msm_gpu *gpu)\n{\n\tuint32_t status;\n\tstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\n\tstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\n\tstruct drm_device *dev = gpu->dev;\n\n\tif (!try_preempt_state(a5xx_gpu, PREEMPT_TRIGGERED, PREEMPT_PENDING))\n\t\treturn;\n\n\t \n\tdel_timer(&a5xx_gpu->preempt_timer);\n\n\t \n\tstatus = gpu_read(gpu, REG_A5XX_CP_CONTEXT_SWITCH_CNTL);\n\tif (unlikely(status)) {\n\t\tset_preempt_state(a5xx_gpu, PREEMPT_FAULTED);\n\t\tDRM_DEV_ERROR(dev->dev, \"%s: Preemption failed to complete\\n\",\n\t\t\tgpu->name);\n\t\tkthread_queue_work(gpu->worker, &gpu->recover_work);\n\t\treturn;\n\t}\n\n\ta5xx_gpu->cur_ring = a5xx_gpu->next_ring;\n\ta5xx_gpu->next_ring = NULL;\n\n\tupdate_wptr(gpu, a5xx_gpu->cur_ring);\n\n\tset_preempt_state(a5xx_gpu, PREEMPT_NONE);\n}\n\nvoid a5xx_preempt_hw_init(struct msm_gpu *gpu)\n{\n\tstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\n\tstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\n\tint i;\n\n\t \n\ta5xx_gpu->cur_ring = gpu->rb[0];\n\n\t \n\tif (gpu->nr_rings == 1)\n\t\treturn;\n\n\tfor (i = 0; i < gpu->nr_rings; i++) {\n\t\ta5xx_gpu->preempt[i]->wptr = 0;\n\t\ta5xx_gpu->preempt[i]->rptr = 0;\n\t\ta5xx_gpu->preempt[i]->rbase = gpu->rb[i]->iova;\n\t\ta5xx_gpu->preempt[i]->rptr_addr = shadowptr(a5xx_gpu, gpu->rb[i]);\n\t}\n\n\t \n\tgpu_write64(gpu, REG_A5XX_CP_CONTEXT_SWITCH_SMMU_INFO_LO, 0);\n\n\t \n\tset_preempt_state(a5xx_gpu, PREEMPT_NONE);\n}\n\nstatic int preempt_init_ring(struct a5xx_gpu *a5xx_gpu,\n\t\tstruct msm_ringbuffer *ring)\n{\n\tstruct adreno_gpu *adreno_gpu = &a5xx_gpu->base;\n\tstruct msm_gpu *gpu = &adreno_gpu->base;\n\tstruct a5xx_preempt_record *ptr;\n\tvoid *counters;\n\tstruct drm_gem_object *bo = NULL, *counters_bo = NULL;\n\tu64 iova = 0, counters_iova = 0;\n\n\tptr = msm_gem_kernel_new(gpu->dev,\n\t\tA5XX_PREEMPT_RECORD_SIZE + A5XX_PREEMPT_COUNTER_SIZE,\n\t\tMSM_BO_WC | MSM_BO_MAP_PRIV, gpu->aspace, &bo, &iova);\n\n\tif (IS_ERR(ptr))\n\t\treturn PTR_ERR(ptr);\n\n\t \n\tcounters = msm_gem_kernel_new(gpu->dev,\n\t\tA5XX_PREEMPT_COUNTER_SIZE,\n\t\tMSM_BO_WC, gpu->aspace, &counters_bo, &counters_iova);\n\tif (IS_ERR(counters)) {\n\t\tmsm_gem_kernel_put(bo, gpu->aspace);\n\t\treturn PTR_ERR(counters);\n\t}\n\n\tmsm_gem_object_set_name(bo, \"preempt\");\n\tmsm_gem_object_set_name(counters_bo, \"preempt_counters\");\n\n\ta5xx_gpu->preempt_bo[ring->id] = bo;\n\ta5xx_gpu->preempt_counters_bo[ring->id] = counters_bo;\n\ta5xx_gpu->preempt_iova[ring->id] = iova;\n\ta5xx_gpu->preempt[ring->id] = ptr;\n\n\t \n\n\tptr->magic = A5XX_PREEMPT_RECORD_MAGIC;\n\tptr->info = 0;\n\tptr->data = 0;\n\tptr->cntl = MSM_GPU_RB_CNTL_DEFAULT | AXXX_CP_RB_CNTL_NO_UPDATE;\n\n\tptr->counter = counters_iova;\n\n\treturn 0;\n}\n\nvoid a5xx_preempt_fini(struct msm_gpu *gpu)\n{\n\tstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\n\tstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\n\tint i;\n\n\tfor (i = 0; i < gpu->nr_rings; i++) {\n\t\tmsm_gem_kernel_put(a5xx_gpu->preempt_bo[i], gpu->aspace);\n\t\tmsm_gem_kernel_put(a5xx_gpu->preempt_counters_bo[i], gpu->aspace);\n\t}\n}\n\nvoid a5xx_preempt_init(struct msm_gpu *gpu)\n{\n\tstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\n\tstruct a5xx_gpu *a5xx_gpu = to_a5xx_gpu(adreno_gpu);\n\tint i;\n\n\t \n\tif (gpu->nr_rings <= 1)\n\t\treturn;\n\n\tfor (i = 0; i < gpu->nr_rings; i++) {\n\t\tif (preempt_init_ring(a5xx_gpu, gpu->rb[i])) {\n\t\t\t \n\t\t\ta5xx_preempt_fini(gpu);\n\t\t\tgpu->nr_rings = 1;\n\n\t\t\treturn;\n\t\t}\n\t}\n\n\ttimer_setup(&a5xx_gpu->preempt_timer, a5xx_preempt_timer, 0);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}