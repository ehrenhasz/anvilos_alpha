{
  "module_name": "dpu_core_perf.c",
  "hash_id": "80a3fa984a2675de9d2659b8df54d6db6ccab27df138286a505bc8f848104f9a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/msm/disp/dpu1/dpu_core_perf.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"[drm:%s:%d] \" fmt, __func__, __LINE__\n\n#include <linux/debugfs.h>\n#include <linux/errno.h>\n#include <linux/mutex.h>\n#include <linux/pm_opp.h>\n#include <linux/sort.h>\n#include <linux/clk.h>\n#include <linux/bitmap.h>\n\n#include \"dpu_kms.h\"\n#include \"dpu_trace.h\"\n#include \"dpu_crtc.h\"\n#include \"dpu_core_perf.h\"\n\n \nenum dpu_perf_mode {\n\tDPU_PERF_MODE_NORMAL,\n\tDPU_PERF_MODE_MINIMUM,\n\tDPU_PERF_MODE_FIXED,\n\tDPU_PERF_MODE_MAX\n};\n\n \nstatic u64 _dpu_core_perf_calc_bw(const struct dpu_perf_cfg *perf_cfg,\n\t\tstruct drm_crtc *crtc)\n{\n\tstruct drm_plane *plane;\n\tstruct dpu_plane_state *pstate;\n\tu64 crtc_plane_bw = 0;\n\tu32 bw_factor;\n\n\tdrm_atomic_crtc_for_each_plane(plane, crtc) {\n\t\tpstate = to_dpu_plane_state(plane->state);\n\t\tif (!pstate)\n\t\t\tcontinue;\n\n\t\tcrtc_plane_bw += pstate->plane_fetch_bw;\n\t}\n\n\tbw_factor = perf_cfg->bw_inefficiency_factor;\n\tif (bw_factor) {\n\t\tcrtc_plane_bw *= bw_factor;\n\t\tdo_div(crtc_plane_bw, 100);\n\t}\n\n\treturn crtc_plane_bw;\n}\n\n \nstatic u64 _dpu_core_perf_calc_clk(const struct dpu_perf_cfg *perf_cfg,\n\t\tstruct drm_crtc *crtc, struct drm_crtc_state *state)\n{\n\tstruct drm_plane *plane;\n\tstruct dpu_plane_state *pstate;\n\tstruct drm_display_mode *mode;\n\tu64 crtc_clk;\n\tu32 clk_factor;\n\n\tmode = &state->adjusted_mode;\n\n\tcrtc_clk = mode->vtotal * mode->hdisplay * drm_mode_vrefresh(mode);\n\n\tdrm_atomic_crtc_for_each_plane(plane, crtc) {\n\t\tpstate = to_dpu_plane_state(plane->state);\n\t\tif (!pstate)\n\t\t\tcontinue;\n\n\t\tcrtc_clk = max(pstate->plane_clk, crtc_clk);\n\t}\n\n\tclk_factor = perf_cfg->clk_inefficiency_factor;\n\tif (clk_factor) {\n\t\tcrtc_clk *= clk_factor;\n\t\tdo_div(crtc_clk, 100);\n\t}\n\n\treturn crtc_clk;\n}\n\nstatic struct dpu_kms *_dpu_crtc_get_kms(struct drm_crtc *crtc)\n{\n\tstruct msm_drm_private *priv;\n\tpriv = crtc->dev->dev_private;\n\treturn to_dpu_kms(priv->kms);\n}\n\nstatic void _dpu_core_perf_calc_crtc(const struct dpu_core_perf *core_perf,\n\t\t\t\t     struct drm_crtc *crtc,\n\t\t\t\t     struct drm_crtc_state *state,\n\t\t\t\t     struct dpu_core_perf_params *perf)\n{\n\tconst struct dpu_perf_cfg *perf_cfg = core_perf->perf_cfg;\n\n\tif (!perf_cfg || !crtc || !state || !perf) {\n\t\tDPU_ERROR(\"invalid parameters\\n\");\n\t\treturn;\n\t}\n\n\tmemset(perf, 0, sizeof(struct dpu_core_perf_params));\n\n\tif (core_perf->perf_tune.mode == DPU_PERF_MODE_MINIMUM) {\n\t\tperf->bw_ctl = 0;\n\t\tperf->max_per_pipe_ib = 0;\n\t\tperf->core_clk_rate = 0;\n\t} else if (core_perf->perf_tune.mode == DPU_PERF_MODE_FIXED) {\n\t\tperf->bw_ctl = core_perf->fix_core_ab_vote;\n\t\tperf->max_per_pipe_ib = core_perf->fix_core_ib_vote;\n\t\tperf->core_clk_rate = core_perf->fix_core_clk_rate;\n\t} else {\n\t\tperf->bw_ctl = _dpu_core_perf_calc_bw(perf_cfg, crtc);\n\t\tperf->max_per_pipe_ib = perf_cfg->min_dram_ib;\n\t\tperf->core_clk_rate = _dpu_core_perf_calc_clk(perf_cfg, crtc, state);\n\t}\n\n\tDRM_DEBUG_ATOMIC(\n\t\t\"crtc=%d clk_rate=%llu core_ib=%llu core_ab=%llu\\n\",\n\t\t\tcrtc->base.id, perf->core_clk_rate,\n\t\t\tperf->max_per_pipe_ib, perf->bw_ctl);\n}\n\nint dpu_core_perf_crtc_check(struct drm_crtc *crtc,\n\t\tstruct drm_crtc_state *state)\n{\n\tu32 bw, threshold;\n\tu64 bw_sum_of_intfs = 0;\n\tenum dpu_crtc_client_type curr_client_type;\n\tstruct dpu_crtc_state *dpu_cstate;\n\tstruct drm_crtc *tmp_crtc;\n\tstruct dpu_kms *kms;\n\n\tif (!crtc || !state) {\n\t\tDPU_ERROR(\"invalid crtc\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tkms = _dpu_crtc_get_kms(crtc);\n\n\t \n\tif (dpu_crtc_get_client_type(crtc) == NRT_CLIENT)\n\t\treturn 0;\n\n\tdpu_cstate = to_dpu_crtc_state(state);\n\n\t \n\t_dpu_core_perf_calc_crtc(&kms->perf, crtc, state, &dpu_cstate->new_perf);\n\n\tbw_sum_of_intfs = dpu_cstate->new_perf.bw_ctl;\n\tcurr_client_type = dpu_crtc_get_client_type(crtc);\n\n\tdrm_for_each_crtc(tmp_crtc, crtc->dev) {\n\t\tif (tmp_crtc->enabled &&\n\t\t    dpu_crtc_get_client_type(tmp_crtc) == curr_client_type &&\n\t\t    tmp_crtc != crtc) {\n\t\t\tstruct dpu_crtc_state *tmp_cstate =\n\t\t\t\tto_dpu_crtc_state(tmp_crtc->state);\n\n\t\t\tDRM_DEBUG_ATOMIC(\"crtc:%d bw:%llu ctrl:%d\\n\",\n\t\t\t\t\t tmp_crtc->base.id, tmp_cstate->new_perf.bw_ctl,\n\t\t\t\t\t tmp_cstate->bw_control);\n\n\t\t\tbw_sum_of_intfs += tmp_cstate->new_perf.bw_ctl;\n\t\t}\n\n\t\t \n\t\tbw = DIV_ROUND_UP_ULL(bw_sum_of_intfs, 1000);\n\t\tDRM_DEBUG_ATOMIC(\"calculated bandwidth=%uk\\n\", bw);\n\n\t\tthreshold = kms->perf.perf_cfg->max_bw_high;\n\n\t\tDRM_DEBUG_ATOMIC(\"final threshold bw limit = %d\\n\", threshold);\n\n\t\tif (!threshold) {\n\t\t\tDPU_ERROR(\"no bandwidth limits specified\\n\");\n\t\t\treturn -E2BIG;\n\t\t} else if (bw > threshold) {\n\t\t\tDPU_ERROR(\"exceeds bandwidth: %ukb > %ukb\\n\", bw,\n\t\t\t\t\tthreshold);\n\t\t\treturn -E2BIG;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int _dpu_core_perf_crtc_update_bus(struct dpu_kms *kms,\n\t\tstruct drm_crtc *crtc)\n{\n\tstruct dpu_core_perf_params perf = { 0 };\n\tenum dpu_crtc_client_type curr_client_type\n\t\t\t\t\t= dpu_crtc_get_client_type(crtc);\n\tstruct drm_crtc *tmp_crtc;\n\tstruct dpu_crtc_state *dpu_cstate;\n\tint i, ret = 0;\n\tu64 avg_bw;\n\n\tif (!kms->num_paths)\n\t\treturn 0;\n\n\tdrm_for_each_crtc(tmp_crtc, crtc->dev) {\n\t\tif (tmp_crtc->enabled &&\n\t\t\tcurr_client_type ==\n\t\t\t\tdpu_crtc_get_client_type(tmp_crtc)) {\n\t\t\tdpu_cstate = to_dpu_crtc_state(tmp_crtc->state);\n\n\t\t\tperf.max_per_pipe_ib = max(perf.max_per_pipe_ib,\n\t\t\t\t\tdpu_cstate->new_perf.max_per_pipe_ib);\n\n\t\t\tperf.bw_ctl += dpu_cstate->new_perf.bw_ctl;\n\n\t\t\tDRM_DEBUG_ATOMIC(\"crtc=%d bw=%llu paths:%d\\n\",\n\t\t\t\t  tmp_crtc->base.id,\n\t\t\t\t  dpu_cstate->new_perf.bw_ctl, kms->num_paths);\n\t\t}\n\t}\n\n\tavg_bw = perf.bw_ctl;\n\tdo_div(avg_bw, (kms->num_paths * 1000));  \n\n\tfor (i = 0; i < kms->num_paths; i++)\n\t\ticc_set_bw(kms->path[i], avg_bw, perf.max_per_pipe_ib);\n\n\treturn ret;\n}\n\n \nvoid dpu_core_perf_crtc_release_bw(struct drm_crtc *crtc)\n{\n\tstruct dpu_crtc *dpu_crtc;\n\tstruct dpu_kms *kms;\n\n\tif (!crtc) {\n\t\tDPU_ERROR(\"invalid crtc\\n\");\n\t\treturn;\n\t}\n\n\tkms = _dpu_crtc_get_kms(crtc);\n\tdpu_crtc = to_dpu_crtc(crtc);\n\n\tif (atomic_dec_return(&kms->bandwidth_ref) > 0)\n\t\treturn;\n\n\t \n\tif (kms->perf.enable_bw_release) {\n\t\ttrace_dpu_cmd_release_bw(crtc->base.id);\n\t\tDRM_DEBUG_ATOMIC(\"Release BW crtc=%d\\n\", crtc->base.id);\n\t\tdpu_crtc->cur_perf.bw_ctl = 0;\n\t\t_dpu_core_perf_crtc_update_bus(kms, crtc);\n\t}\n}\n\nstatic u64 _dpu_core_perf_get_core_clk_rate(struct dpu_kms *kms)\n{\n\tu64 clk_rate;\n\tstruct drm_crtc *crtc;\n\tstruct dpu_crtc_state *dpu_cstate;\n\n\tif (kms->perf.perf_tune.mode == DPU_PERF_MODE_FIXED)\n\t\treturn kms->perf.fix_core_clk_rate;\n\n\tif (kms->perf.perf_tune.mode == DPU_PERF_MODE_MINIMUM)\n\t\treturn kms->perf.max_core_clk_rate;\n\n\tclk_rate = 0;\n\tdrm_for_each_crtc(crtc, kms->dev) {\n\t\tif (crtc->enabled) {\n\t\t\tdpu_cstate = to_dpu_crtc_state(crtc->state);\n\t\t\tclk_rate = max(dpu_cstate->new_perf.core_clk_rate,\n\t\t\t\t\t\t\tclk_rate);\n\t\t}\n\t}\n\n\treturn clk_rate;\n}\n\nint dpu_core_perf_crtc_update(struct drm_crtc *crtc,\n\t\t\t      int params_changed)\n{\n\tstruct dpu_core_perf_params *new, *old;\n\tbool update_bus = false, update_clk = false;\n\tu64 clk_rate = 0;\n\tstruct dpu_crtc *dpu_crtc;\n\tstruct dpu_crtc_state *dpu_cstate;\n\tstruct dpu_kms *kms;\n\tint ret;\n\n\tif (!crtc) {\n\t\tDPU_ERROR(\"invalid crtc\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tkms = _dpu_crtc_get_kms(crtc);\n\n\tdpu_crtc = to_dpu_crtc(crtc);\n\tdpu_cstate = to_dpu_crtc_state(crtc->state);\n\n\tDRM_DEBUG_ATOMIC(\"crtc:%d enabled:%d core_clk:%llu\\n\",\n\t\t\tcrtc->base.id, crtc->enabled, kms->perf.core_clk_rate);\n\n\told = &dpu_crtc->cur_perf;\n\tnew = &dpu_cstate->new_perf;\n\n\tif (crtc->enabled) {\n\t\t \n\t\tif ((params_changed && ((new->bw_ctl > old->bw_ctl) ||\n\t\t\t(new->max_per_pipe_ib > old->max_per_pipe_ib)))\t||\n\t\t\t(!params_changed && ((new->bw_ctl < old->bw_ctl) ||\n\t\t\t(new->max_per_pipe_ib < old->max_per_pipe_ib)))) {\n\t\t\tDRM_DEBUG_ATOMIC(\"crtc=%d p=%d new_bw=%llu,old_bw=%llu\\n\",\n\t\t\t\tcrtc->base.id, params_changed,\n\t\t\t\tnew->bw_ctl, old->bw_ctl);\n\t\t\told->bw_ctl = new->bw_ctl;\n\t\t\told->max_per_pipe_ib = new->max_per_pipe_ib;\n\t\t\tupdate_bus = true;\n\t\t}\n\n\t\tif ((params_changed && new->core_clk_rate > old->core_clk_rate) ||\n\t\t    (!params_changed && new->core_clk_rate < old->core_clk_rate)) {\n\t\t\told->core_clk_rate = new->core_clk_rate;\n\t\t\tupdate_clk = true;\n\t\t}\n\t} else {\n\t\tDRM_DEBUG_ATOMIC(\"crtc=%d disable\\n\", crtc->base.id);\n\t\tmemset(old, 0, sizeof(*old));\n\t\tupdate_bus = true;\n\t\tupdate_clk = true;\n\t}\n\n\ttrace_dpu_perf_crtc_update(crtc->base.id, new->bw_ctl,\n\t\tnew->core_clk_rate, !crtc->enabled, update_bus, update_clk);\n\n\tif (update_bus) {\n\t\tret = _dpu_core_perf_crtc_update_bus(kms, crtc);\n\t\tif (ret) {\n\t\t\tDPU_ERROR(\"crtc-%d: failed to update bus bw vote\\n\",\n\t\t\t\t  crtc->base.id);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tif (update_clk) {\n\t\tclk_rate = _dpu_core_perf_get_core_clk_rate(kms);\n\n\t\tDRM_DEBUG_ATOMIC(\"clk:%llu\\n\", clk_rate);\n\n\t\ttrace_dpu_core_perf_update_clk(kms->dev, !crtc->enabled, clk_rate);\n\n\t\tclk_rate = min(clk_rate, kms->perf.max_core_clk_rate);\n\t\tret = dev_pm_opp_set_rate(&kms->pdev->dev, clk_rate);\n\t\tif (ret) {\n\t\t\tDPU_ERROR(\"failed to set core clock rate %llu\\n\", clk_rate);\n\t\t\treturn ret;\n\t\t}\n\n\t\tkms->perf.core_clk_rate = clk_rate;\n\t\tDRM_DEBUG_ATOMIC(\"update clk rate = %lld HZ\\n\", clk_rate);\n\t}\n\treturn 0;\n}\n\n#ifdef CONFIG_DEBUG_FS\n\nstatic ssize_t _dpu_core_perf_mode_write(struct file *file,\n\t\t    const char __user *user_buf, size_t count, loff_t *ppos)\n{\n\tstruct dpu_core_perf *perf = file->private_data;\n\tu32 perf_mode = 0;\n\tint ret;\n\n\tret = kstrtouint_from_user(user_buf, count, 0, &perf_mode);\n\tif (ret)\n\t\treturn ret;\n\n\tif (perf_mode >= DPU_PERF_MODE_MAX)\n\t\treturn -EINVAL;\n\n\tif (perf_mode == DPU_PERF_MODE_FIXED) {\n\t\tDRM_INFO(\"fix performance mode\\n\");\n\t} else if (perf_mode == DPU_PERF_MODE_MINIMUM) {\n\t\t \n\t\tDRM_INFO(\"minimum performance mode\\n\");\n\t} else if (perf_mode == DPU_PERF_MODE_NORMAL) {\n\t\t \n\t\tDRM_INFO(\"normal performance mode\\n\");\n\t}\n\tperf->perf_tune.mode = perf_mode;\n\n\treturn count;\n}\n\nstatic ssize_t _dpu_core_perf_mode_read(struct file *file,\n\t\t\tchar __user *buff, size_t count, loff_t *ppos)\n{\n\tstruct dpu_core_perf *perf = file->private_data;\n\tint len;\n\tchar buf[128];\n\n\tlen = scnprintf(buf, sizeof(buf),\n\t\t\t\"mode %d\\n\",\n\t\t\tperf->perf_tune.mode);\n\n\treturn simple_read_from_buffer(buff, count, ppos, buf, len);\n}\n\nstatic const struct file_operations dpu_core_perf_mode_fops = {\n\t.open = simple_open,\n\t.read = _dpu_core_perf_mode_read,\n\t.write = _dpu_core_perf_mode_write,\n};\n\nint dpu_core_perf_debugfs_init(struct dpu_kms *dpu_kms, struct dentry *parent)\n{\n\tstruct dpu_core_perf *perf = &dpu_kms->perf;\n\tstruct dentry *entry;\n\n\tentry = debugfs_create_dir(\"core_perf\", parent);\n\n\tdebugfs_create_u64(\"max_core_clk_rate\", 0600, entry,\n\t\t\t&perf->max_core_clk_rate);\n\tdebugfs_create_u64(\"core_clk_rate\", 0600, entry,\n\t\t\t&perf->core_clk_rate);\n\tdebugfs_create_u32(\"enable_bw_release\", 0600, entry,\n\t\t\t(u32 *)&perf->enable_bw_release);\n\tdebugfs_create_u32(\"threshold_low\", 0600, entry,\n\t\t\t(u32 *)&perf->perf_cfg->max_bw_low);\n\tdebugfs_create_u32(\"threshold_high\", 0600, entry,\n\t\t\t(u32 *)&perf->perf_cfg->max_bw_high);\n\tdebugfs_create_u32(\"min_core_ib\", 0600, entry,\n\t\t\t(u32 *)&perf->perf_cfg->min_core_ib);\n\tdebugfs_create_u32(\"min_llcc_ib\", 0600, entry,\n\t\t\t(u32 *)&perf->perf_cfg->min_llcc_ib);\n\tdebugfs_create_u32(\"min_dram_ib\", 0600, entry,\n\t\t\t(u32 *)&perf->perf_cfg->min_dram_ib);\n\tdebugfs_create_file(\"perf_mode\", 0600, entry,\n\t\t\t(u32 *)perf, &dpu_core_perf_mode_fops);\n\tdebugfs_create_u64(\"fix_core_clk_rate\", 0600, entry,\n\t\t\t&perf->fix_core_clk_rate);\n\tdebugfs_create_u64(\"fix_core_ib_vote\", 0600, entry,\n\t\t\t&perf->fix_core_ib_vote);\n\tdebugfs_create_u64(\"fix_core_ab_vote\", 0600, entry,\n\t\t\t&perf->fix_core_ab_vote);\n\n\treturn 0;\n}\n#endif\n\nint dpu_core_perf_init(struct dpu_core_perf *perf,\n\t\tconst struct dpu_perf_cfg *perf_cfg,\n\t\tunsigned long max_core_clk_rate)\n{\n\tperf->perf_cfg = perf_cfg;\n\tperf->max_core_clk_rate = max_core_clk_rate;\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}