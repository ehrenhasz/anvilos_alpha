{
  "module_name": "dpu_encoder.c",
  "hash_id": "b27c1ba9bd7f8f40cf53616b25b87bdcdf04480455b3e331cec7398447a758c0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/msm/disp/dpu1/dpu_encoder.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"[drm:%s:%d] \" fmt, __func__, __LINE__\n#include <linux/debugfs.h>\n#include <linux/kthread.h>\n#include <linux/seq_file.h>\n\n#include <drm/drm_atomic.h>\n#include <drm/drm_crtc.h>\n#include <drm/drm_file.h>\n#include <drm/drm_probe_helper.h>\n\n#include \"msm_drv.h\"\n#include \"dpu_kms.h\"\n#include \"dpu_hwio.h\"\n#include \"dpu_hw_catalog.h\"\n#include \"dpu_hw_intf.h\"\n#include \"dpu_hw_ctl.h\"\n#include \"dpu_hw_dspp.h\"\n#include \"dpu_hw_dsc.h\"\n#include \"dpu_hw_merge3d.h\"\n#include \"dpu_formats.h\"\n#include \"dpu_encoder_phys.h\"\n#include \"dpu_crtc.h\"\n#include \"dpu_trace.h\"\n#include \"dpu_core_irq.h\"\n#include \"disp/msm_disp_snapshot.h\"\n\n#define DPU_DEBUG_ENC(e, fmt, ...) DRM_DEBUG_ATOMIC(\"enc%d \" fmt,\\\n\t\t(e) ? (e)->base.base.id : -1, ##__VA_ARGS__)\n\n#define DPU_ERROR_ENC(e, fmt, ...) DPU_ERROR(\"enc%d \" fmt,\\\n\t\t(e) ? (e)->base.base.id : -1, ##__VA_ARGS__)\n\n \n#define NUM_PHYS_ENCODER_TYPES 2\n\n#define MAX_PHYS_ENCODERS_PER_VIRTUAL \\\n\t(MAX_H_TILES_PER_DISPLAY * NUM_PHYS_ENCODER_TYPES)\n\n#define MAX_CHANNELS_PER_ENC 2\n\n#define IDLE_SHORT_TIMEOUT\t1\n\n#define MAX_HDISPLAY_SPLIT 1080\n\n \n#define DPU_ENCODER_FRAME_DONE_TIMEOUT_FRAMES 5\n\n \nenum dpu_enc_rc_events {\n\tDPU_ENC_RC_EVENT_KICKOFF = 1,\n\tDPU_ENC_RC_EVENT_FRAME_DONE,\n\tDPU_ENC_RC_EVENT_PRE_STOP,\n\tDPU_ENC_RC_EVENT_STOP,\n\tDPU_ENC_RC_EVENT_ENTER_IDLE\n};\n\n \nenum dpu_enc_rc_states {\n\tDPU_ENC_RC_STATE_OFF,\n\tDPU_ENC_RC_STATE_PRE_OFF,\n\tDPU_ENC_RC_STATE_ON,\n\tDPU_ENC_RC_STATE_IDLE\n};\n\n \nstruct dpu_encoder_virt {\n\tstruct drm_encoder base;\n\tspinlock_t enc_spinlock;\n\n\tbool enabled;\n\n\tunsigned int num_phys_encs;\n\tstruct dpu_encoder_phys *phys_encs[MAX_PHYS_ENCODERS_PER_VIRTUAL];\n\tstruct dpu_encoder_phys *cur_master;\n\tstruct dpu_encoder_phys *cur_slave;\n\tstruct dpu_hw_pingpong *hw_pp[MAX_CHANNELS_PER_ENC];\n\tstruct dpu_hw_dsc *hw_dsc[MAX_CHANNELS_PER_ENC];\n\n\tunsigned int dsc_mask;\n\n\tbool intfs_swapped;\n\n\tstruct drm_crtc *crtc;\n\tstruct drm_connector *connector;\n\n\tstruct dentry *debugfs_root;\n\tstruct mutex enc_lock;\n\tDECLARE_BITMAP(frame_busy_mask, MAX_PHYS_ENCODERS_PER_VIRTUAL);\n\tvoid (*crtc_frame_event_cb)(void *, u32 event);\n\tvoid *crtc_frame_event_cb_data;\n\n\tatomic_t frame_done_timeout_ms;\n\tstruct timer_list frame_done_timer;\n\n\tstruct msm_display_info disp_info;\n\n\tbool idle_pc_supported;\n\tstruct mutex rc_lock;\n\tenum dpu_enc_rc_states rc_state;\n\tstruct delayed_work delayed_off_work;\n\tstruct msm_display_topology topology;\n\n\tu32 idle_timeout;\n\n\tbool wide_bus_en;\n\n\t \n\tstruct drm_dsc_config *dsc;\n};\n\n#define to_dpu_encoder_virt(x) container_of(x, struct dpu_encoder_virt, base)\n\nstatic u32 dither_matrix[DITHER_MATRIX_SZ] = {\n\t15, 7, 13, 5, 3, 11, 1, 9, 12, 4, 14, 6, 0, 8, 2, 10\n};\n\n\nbool dpu_encoder_is_widebus_enabled(const struct drm_encoder *drm_enc)\n{\n\tconst struct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\treturn dpu_enc->wide_bus_en;\n}\n\nint dpu_encoder_get_crc_values_cnt(const struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tint i, num_intf = 0;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->hw_intf && phys->hw_intf->ops.setup_misr\n\t\t\t\t&& phys->hw_intf->ops.collect_misr)\n\t\t\tnum_intf++;\n\t}\n\n\treturn num_intf;\n}\n\nvoid dpu_encoder_setup_misr(const struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\n\tint i;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (!phys->hw_intf || !phys->hw_intf->ops.setup_misr)\n\t\t\tcontinue;\n\n\t\tphys->hw_intf->ops.setup_misr(phys->hw_intf);\n\t}\n}\n\nint dpu_encoder_get_crc(const struct drm_encoder *drm_enc, u32 *crcs, int pos)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\n\tint i, rc = 0, entries_added = 0;\n\n\tif (!drm_enc->crtc) {\n\t\tDRM_ERROR(\"no crtc found for encoder %d\\n\", drm_enc->index);\n\t\treturn -EINVAL;\n\t}\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (!phys->hw_intf || !phys->hw_intf->ops.collect_misr)\n\t\t\tcontinue;\n\n\t\trc = phys->hw_intf->ops.collect_misr(phys->hw_intf, &crcs[pos + entries_added]);\n\t\tif (rc)\n\t\t\treturn rc;\n\t\tentries_added++;\n\t}\n\n\treturn entries_added;\n}\n\nstatic void _dpu_encoder_setup_dither(struct dpu_hw_pingpong *hw_pp, unsigned bpc)\n{\n\tstruct dpu_hw_dither_cfg dither_cfg = { 0 };\n\n\tif (!hw_pp->ops.setup_dither)\n\t\treturn;\n\n\tswitch (bpc) {\n\tcase 6:\n\t\tdither_cfg.c0_bitdepth = 6;\n\t\tdither_cfg.c1_bitdepth = 6;\n\t\tdither_cfg.c2_bitdepth = 6;\n\t\tdither_cfg.c3_bitdepth = 6;\n\t\tdither_cfg.temporal_en = 0;\n\t\tbreak;\n\tdefault:\n\t\thw_pp->ops.setup_dither(hw_pp, NULL);\n\t\treturn;\n\t}\n\n\tmemcpy(&dither_cfg.matrix, dither_matrix,\n\t\t\tsizeof(u32) * DITHER_MATRIX_SZ);\n\n\thw_pp->ops.setup_dither(hw_pp, &dither_cfg);\n}\n\nstatic char *dpu_encoder_helper_get_intf_type(enum dpu_intf_mode intf_mode)\n{\n\tswitch (intf_mode) {\n\tcase INTF_MODE_VIDEO:\n\t\treturn \"INTF_MODE_VIDEO\";\n\tcase INTF_MODE_CMD:\n\t\treturn \"INTF_MODE_CMD\";\n\tcase INTF_MODE_WB_BLOCK:\n\t\treturn \"INTF_MODE_WB_BLOCK\";\n\tcase INTF_MODE_WB_LINE:\n\t\treturn \"INTF_MODE_WB_LINE\";\n\tdefault:\n\t\treturn \"INTF_MODE_UNKNOWN\";\n\t}\n}\n\nvoid dpu_encoder_helper_report_irq_timeout(struct dpu_encoder_phys *phys_enc,\n\t\tenum dpu_intr_idx intr_idx)\n{\n\tDRM_ERROR(\"irq timeout id=%u, intf_mode=%s intf=%d wb=%d, pp=%d, intr=%d\\n\",\n\t\t\tDRMID(phys_enc->parent),\n\t\t\tdpu_encoder_helper_get_intf_type(phys_enc->intf_mode),\n\t\t\tphys_enc->hw_intf ? phys_enc->hw_intf->idx - INTF_0 : -1,\n\t\t\tphys_enc->hw_wb ? phys_enc->hw_wb->idx - WB_0 : -1,\n\t\t\tphys_enc->hw_pp->idx - PINGPONG_0, intr_idx);\n\n\tdpu_encoder_frame_done_callback(phys_enc->parent, phys_enc,\n\t\t\t\tDPU_ENCODER_FRAME_EVENT_ERROR);\n}\n\nstatic int dpu_encoder_helper_wait_event_timeout(int32_t drm_id,\n\t\tu32 irq_idx, struct dpu_encoder_wait_info *info);\n\nint dpu_encoder_helper_wait_for_irq(struct dpu_encoder_phys *phys_enc,\n\t\tint irq,\n\t\tvoid (*func)(void *arg, int irq_idx),\n\t\tstruct dpu_encoder_wait_info *wait_info)\n{\n\tu32 irq_status;\n\tint ret;\n\n\tif (!wait_info) {\n\t\tDPU_ERROR(\"invalid params\\n\");\n\t\treturn -EINVAL;\n\t}\n\t \n\n\t \n\tif (phys_enc->enable_state == DPU_ENC_DISABLED) {\n\t\tDRM_ERROR(\"encoder is disabled id=%u, callback=%ps, irq=%d\\n\",\n\t\t\t  DRMID(phys_enc->parent), func,\n\t\t\t  irq);\n\t\treturn -EWOULDBLOCK;\n\t}\n\n\tif (irq < 0) {\n\t\tDRM_DEBUG_KMS(\"skip irq wait id=%u, callback=%ps\\n\",\n\t\t\t      DRMID(phys_enc->parent), func);\n\t\treturn 0;\n\t}\n\n\tDRM_DEBUG_KMS(\"id=%u, callback=%ps, irq=%d, pp=%d, pending_cnt=%d\\n\",\n\t\t      DRMID(phys_enc->parent), func,\n\t\t      irq, phys_enc->hw_pp->idx - PINGPONG_0,\n\t\t      atomic_read(wait_info->atomic_cnt));\n\n\tret = dpu_encoder_helper_wait_event_timeout(\n\t\t\tDRMID(phys_enc->parent),\n\t\t\tirq,\n\t\t\twait_info);\n\n\tif (ret <= 0) {\n\t\tirq_status = dpu_core_irq_read(phys_enc->dpu_kms, irq);\n\t\tif (irq_status) {\n\t\t\tunsigned long flags;\n\n\t\t\tDRM_DEBUG_KMS(\"irq not triggered id=%u, callback=%ps, irq=%d, pp=%d, atomic_cnt=%d\\n\",\n\t\t\t\t      DRMID(phys_enc->parent), func,\n\t\t\t\t      irq,\n\t\t\t\t      phys_enc->hw_pp->idx - PINGPONG_0,\n\t\t\t\t      atomic_read(wait_info->atomic_cnt));\n\t\t\tlocal_irq_save(flags);\n\t\t\tfunc(phys_enc, irq);\n\t\t\tlocal_irq_restore(flags);\n\t\t\tret = 0;\n\t\t} else {\n\t\t\tret = -ETIMEDOUT;\n\t\t\tDRM_DEBUG_KMS(\"irq timeout id=%u, callback=%ps, irq=%d, pp=%d, atomic_cnt=%d\\n\",\n\t\t\t\t      DRMID(phys_enc->parent), func,\n\t\t\t\t      irq,\n\t\t\t\t      phys_enc->hw_pp->idx - PINGPONG_0,\n\t\t\t\t      atomic_read(wait_info->atomic_cnt));\n\t\t}\n\t} else {\n\t\tret = 0;\n\t\ttrace_dpu_enc_irq_wait_success(DRMID(phys_enc->parent),\n\t\t\tfunc, irq,\n\t\t\tphys_enc->hw_pp->idx - PINGPONG_0,\n\t\t\tatomic_read(wait_info->atomic_cnt));\n\t}\n\n\treturn ret;\n}\n\nint dpu_encoder_get_vsync_count(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\tstruct dpu_encoder_phys *phys = dpu_enc ? dpu_enc->cur_master : NULL;\n\treturn phys ? atomic_read(&phys->vsync_cnt) : 0;\n}\n\nint dpu_encoder_get_linecount(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct dpu_encoder_phys *phys;\n\tint linecount = 0;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tphys = dpu_enc ? dpu_enc->cur_master : NULL;\n\n\tif (phys && phys->ops.get_line_count)\n\t\tlinecount = phys->ops.get_line_count(phys);\n\n\treturn linecount;\n}\n\nstatic void dpu_encoder_destroy(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\tint i = 0;\n\n\tif (!drm_enc) {\n\t\tDPU_ERROR(\"invalid encoder\\n\");\n\t\treturn;\n\t}\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tDPU_DEBUG_ENC(dpu_enc, \"\\n\");\n\n\tmutex_lock(&dpu_enc->enc_lock);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->ops.destroy) {\n\t\t\tphys->ops.destroy(phys);\n\t\t\t--dpu_enc->num_phys_encs;\n\t\t\tdpu_enc->phys_encs[i] = NULL;\n\t\t}\n\t}\n\n\tif (dpu_enc->num_phys_encs)\n\t\tDPU_ERROR_ENC(dpu_enc, \"expected 0 num_phys_encs not %d\\n\",\n\t\t\t\tdpu_enc->num_phys_encs);\n\tdpu_enc->num_phys_encs = 0;\n\tmutex_unlock(&dpu_enc->enc_lock);\n\n\tdrm_encoder_cleanup(drm_enc);\n\tmutex_destroy(&dpu_enc->enc_lock);\n}\n\nvoid dpu_encoder_helper_split_config(\n\t\tstruct dpu_encoder_phys *phys_enc,\n\t\tenum dpu_intf interface)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct split_pipe_cfg cfg = { 0 };\n\tstruct dpu_hw_mdp *hw_mdptop;\n\tstruct msm_display_info *disp_info;\n\n\tif (!phys_enc->hw_mdptop || !phys_enc->parent) {\n\t\tDPU_ERROR(\"invalid arg(s), encoder %d\\n\", phys_enc != NULL);\n\t\treturn;\n\t}\n\n\tdpu_enc = to_dpu_encoder_virt(phys_enc->parent);\n\thw_mdptop = phys_enc->hw_mdptop;\n\tdisp_info = &dpu_enc->disp_info;\n\n\tif (disp_info->intf_type != INTF_DSI)\n\t\treturn;\n\n\t \n\tif (phys_enc->split_role == ENC_ROLE_SOLO) {\n\t\tif (hw_mdptop->ops.setup_split_pipe)\n\t\t\thw_mdptop->ops.setup_split_pipe(hw_mdptop, &cfg);\n\t\treturn;\n\t}\n\n\tcfg.en = true;\n\tcfg.mode = phys_enc->intf_mode;\n\tcfg.intf = interface;\n\n\tif (cfg.en && phys_enc->ops.needs_single_flush &&\n\t\t\tphys_enc->ops.needs_single_flush(phys_enc))\n\t\tcfg.split_flush_en = true;\n\n\tif (phys_enc->split_role == ENC_ROLE_MASTER) {\n\t\tDPU_DEBUG_ENC(dpu_enc, \"enable %d\\n\", cfg.en);\n\n\t\tif (hw_mdptop->ops.setup_split_pipe)\n\t\t\thw_mdptop->ops.setup_split_pipe(hw_mdptop, &cfg);\n\t}\n}\n\nbool dpu_encoder_use_dsc_merge(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\tint i, intf_count = 0, num_dsc = 0;\n\n\tfor (i = 0; i < MAX_PHYS_ENCODERS_PER_VIRTUAL; i++)\n\t\tif (dpu_enc->phys_encs[i])\n\t\t\tintf_count++;\n\n\t \n\tif (dpu_enc->dsc)\n\t\tnum_dsc = 2;\n\n\treturn (num_dsc > 0) && (num_dsc > intf_count);\n}\n\nstatic struct drm_dsc_config *dpu_encoder_get_dsc_config(struct drm_encoder *drm_enc)\n{\n\tstruct msm_drm_private *priv = drm_enc->dev->dev_private;\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\tint index = dpu_enc->disp_info.h_tile_instance[0];\n\n\tif (dpu_enc->disp_info.intf_type == INTF_DSI)\n\t\treturn msm_dsi_get_dsc_config(priv->dsi[index]);\n\n\treturn NULL;\n}\n\nstatic struct msm_display_topology dpu_encoder_get_topology(\n\t\t\tstruct dpu_encoder_virt *dpu_enc,\n\t\t\tstruct dpu_kms *dpu_kms,\n\t\t\tstruct drm_display_mode *mode,\n\t\t\tstruct drm_crtc_state *crtc_state,\n\t\t\tstruct drm_dsc_config *dsc)\n{\n\tstruct msm_display_topology topology = {0};\n\tint i, intf_count = 0;\n\n\tfor (i = 0; i < MAX_PHYS_ENCODERS_PER_VIRTUAL; i++)\n\t\tif (dpu_enc->phys_encs[i])\n\t\t\tintf_count++;\n\n\t \n\tif (intf_count == 2)\n\t\ttopology.num_lm = 2;\n\telse if (!dpu_kms->catalog->caps->has_3d_merge)\n\t\ttopology.num_lm = 1;\n\telse\n\t\ttopology.num_lm = (mode->hdisplay > MAX_HDISPLAY_SPLIT) ? 2 : 1;\n\n\tif (crtc_state->ctm)\n\t\ttopology.num_dspp = topology.num_lm;\n\n\ttopology.num_intf = intf_count;\n\n\tif (dsc) {\n\t\t \n\t\ttopology.num_dsc = 2;\n\t\ttopology.num_lm = 2;\n\t\ttopology.num_intf = 1;\n\t}\n\n\treturn topology;\n}\n\nstatic int dpu_encoder_virt_atomic_check(\n\t\tstruct drm_encoder *drm_enc,\n\t\tstruct drm_crtc_state *crtc_state,\n\t\tstruct drm_connector_state *conn_state)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct msm_drm_private *priv;\n\tstruct dpu_kms *dpu_kms;\n\tstruct drm_display_mode *adj_mode;\n\tstruct msm_display_topology topology;\n\tstruct dpu_global_state *global_state;\n\tstruct drm_dsc_config *dsc;\n\tint i = 0;\n\tint ret = 0;\n\n\tif (!drm_enc || !crtc_state || !conn_state) {\n\t\tDPU_ERROR(\"invalid arg(s), drm_enc %d, crtc/conn state %d/%d\\n\",\n\t\t\t\tdrm_enc != NULL, crtc_state != NULL, conn_state != NULL);\n\t\treturn -EINVAL;\n\t}\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tDPU_DEBUG_ENC(dpu_enc, \"\\n\");\n\n\tpriv = drm_enc->dev->dev_private;\n\tdpu_kms = to_dpu_kms(priv->kms);\n\tadj_mode = &crtc_state->adjusted_mode;\n\tglobal_state = dpu_kms_get_global_state(crtc_state->state);\n\tif (IS_ERR(global_state))\n\t\treturn PTR_ERR(global_state);\n\n\ttrace_dpu_enc_atomic_check(DRMID(drm_enc));\n\n\t \n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->ops.atomic_check)\n\t\t\tret = phys->ops.atomic_check(phys, crtc_state,\n\t\t\t\t\tconn_state);\n\t\tif (ret) {\n\t\t\tDPU_ERROR_ENC(dpu_enc,\n\t\t\t\t\t\"mode unsupported, phys idx %d\\n\", i);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tdsc = dpu_encoder_get_dsc_config(drm_enc);\n\n\ttopology = dpu_encoder_get_topology(dpu_enc, dpu_kms, adj_mode, crtc_state, dsc);\n\n\t \n\tif (drm_atomic_crtc_needs_modeset(crtc_state)) {\n\t\tdpu_rm_release(global_state, drm_enc);\n\n\t\tif (!crtc_state->active_changed || crtc_state->enable)\n\t\t\tret = dpu_rm_reserve(&dpu_kms->rm, global_state,\n\t\t\t\t\tdrm_enc, crtc_state, topology);\n\t}\n\n\ttrace_dpu_enc_atomic_check_flags(DRMID(drm_enc), adj_mode->flags);\n\n\treturn ret;\n}\n\nstatic void _dpu_encoder_update_vsync_source(struct dpu_encoder_virt *dpu_enc,\n\t\t\tstruct msm_display_info *disp_info)\n{\n\tstruct dpu_vsync_source_cfg vsync_cfg = { 0 };\n\tstruct msm_drm_private *priv;\n\tstruct dpu_kms *dpu_kms;\n\tstruct dpu_hw_mdp *hw_mdptop;\n\tstruct drm_encoder *drm_enc;\n\tstruct dpu_encoder_phys *phys_enc;\n\tint i;\n\n\tif (!dpu_enc || !disp_info) {\n\t\tDPU_ERROR(\"invalid param dpu_enc:%d or disp_info:%d\\n\",\n\t\t\t\t\tdpu_enc != NULL, disp_info != NULL);\n\t\treturn;\n\t} else if (dpu_enc->num_phys_encs > ARRAY_SIZE(dpu_enc->hw_pp)) {\n\t\tDPU_ERROR(\"invalid num phys enc %d/%d\\n\",\n\t\t\t\tdpu_enc->num_phys_encs,\n\t\t\t\t(int) ARRAY_SIZE(dpu_enc->hw_pp));\n\t\treturn;\n\t}\n\n\tdrm_enc = &dpu_enc->base;\n\t \n\tpriv = drm_enc->dev->dev_private;\n\n\tdpu_kms = to_dpu_kms(priv->kms);\n\thw_mdptop = dpu_kms->hw_mdp;\n\tif (!hw_mdptop) {\n\t\tDPU_ERROR(\"invalid mdptop\\n\");\n\t\treturn;\n\t}\n\n\tif (hw_mdptop->ops.setup_vsync_source &&\n\t\t\tdisp_info->is_cmd_mode) {\n\t\tfor (i = 0; i < dpu_enc->num_phys_encs; i++)\n\t\t\tvsync_cfg.ppnumber[i] = dpu_enc->hw_pp[i]->idx;\n\n\t\tvsync_cfg.pp_count = dpu_enc->num_phys_encs;\n\t\tvsync_cfg.frame_rate = drm_mode_vrefresh(&dpu_enc->base.crtc->state->adjusted_mode);\n\n\t\tif (disp_info->is_te_using_watchdog_timer)\n\t\t\tvsync_cfg.vsync_source = DPU_VSYNC_SOURCE_WD_TIMER_0;\n\t\telse\n\t\t\tvsync_cfg.vsync_source = DPU_VSYNC0_SOURCE_GPIO;\n\n\t\thw_mdptop->ops.setup_vsync_source(hw_mdptop, &vsync_cfg);\n\n\t\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\t\tphys_enc = dpu_enc->phys_encs[i];\n\n\t\t\tif (phys_enc->has_intf_te && phys_enc->hw_intf->ops.vsync_sel)\n\t\t\t\tphys_enc->hw_intf->ops.vsync_sel(phys_enc->hw_intf,\n\t\t\t\t\t\tvsync_cfg.vsync_source);\n\t\t}\n\t}\n}\n\nstatic void _dpu_encoder_irq_control(struct drm_encoder *drm_enc, bool enable)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tint i;\n\n\tif (!drm_enc) {\n\t\tDPU_ERROR(\"invalid encoder\\n\");\n\t\treturn;\n\t}\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tDPU_DEBUG_ENC(dpu_enc, \"enable:%d\\n\", enable);\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->ops.irq_control)\n\t\t\tphys->ops.irq_control(phys, enable);\n\t}\n\n}\n\nstatic void _dpu_encoder_resource_control_helper(struct drm_encoder *drm_enc,\n\t\tbool enable)\n{\n\tstruct msm_drm_private *priv;\n\tstruct dpu_kms *dpu_kms;\n\tstruct dpu_encoder_virt *dpu_enc;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tpriv = drm_enc->dev->dev_private;\n\tdpu_kms = to_dpu_kms(priv->kms);\n\n\ttrace_dpu_enc_rc_helper(DRMID(drm_enc), enable);\n\n\tif (!dpu_enc->cur_master) {\n\t\tDPU_ERROR(\"encoder master not set\\n\");\n\t\treturn;\n\t}\n\n\tif (enable) {\n\t\t \n\t\tpm_runtime_get_sync(&dpu_kms->pdev->dev);\n\n\t\t \n\t\t_dpu_encoder_irq_control(drm_enc, true);\n\n\t} else {\n\t\t \n\t\t_dpu_encoder_irq_control(drm_enc, false);\n\n\t\t \n\t\tpm_runtime_put_sync(&dpu_kms->pdev->dev);\n\t}\n\n}\n\nstatic int dpu_encoder_resource_control(struct drm_encoder *drm_enc,\n\t\tu32 sw_event)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct msm_drm_private *priv;\n\tbool is_vid_mode = false;\n\n\tif (!drm_enc || !drm_enc->dev || !drm_enc->crtc) {\n\t\tDPU_ERROR(\"invalid parameters\\n\");\n\t\treturn -EINVAL;\n\t}\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tpriv = drm_enc->dev->dev_private;\n\tis_vid_mode = !dpu_enc->disp_info.is_cmd_mode;\n\n\t \n\tif (!dpu_enc->idle_pc_supported &&\n\t\t\t(sw_event != DPU_ENC_RC_EVENT_KICKOFF &&\n\t\t\tsw_event != DPU_ENC_RC_EVENT_STOP &&\n\t\t\tsw_event != DPU_ENC_RC_EVENT_PRE_STOP))\n\t\treturn 0;\n\n\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event, dpu_enc->idle_pc_supported,\n\t\t\t dpu_enc->rc_state, \"begin\");\n\n\tswitch (sw_event) {\n\tcase DPU_ENC_RC_EVENT_KICKOFF:\n\t\t \n\t\tif (cancel_delayed_work_sync(&dpu_enc->delayed_off_work))\n\t\t\tDPU_DEBUG_ENC(dpu_enc, \"sw_event:%d, work cancelled\\n\",\n\t\t\t\t\tsw_event);\n\n\t\tmutex_lock(&dpu_enc->rc_lock);\n\n\t\t \n\t\tif (dpu_enc->rc_state == DPU_ENC_RC_STATE_ON) {\n\t\t\tDRM_DEBUG_ATOMIC(\"id;%u, sw_event:%d, rc in ON state\\n\",\n\t\t\t\t      DRMID(drm_enc), sw_event);\n\t\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\t\treturn 0;\n\t\t} else if (dpu_enc->rc_state != DPU_ENC_RC_STATE_OFF &&\n\t\t\t\tdpu_enc->rc_state != DPU_ENC_RC_STATE_IDLE) {\n\t\t\tDRM_DEBUG_ATOMIC(\"id;%u, sw_event:%d, rc in state %d\\n\",\n\t\t\t\t      DRMID(drm_enc), sw_event,\n\t\t\t\t      dpu_enc->rc_state);\n\t\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (is_vid_mode && dpu_enc->rc_state == DPU_ENC_RC_STATE_IDLE)\n\t\t\t_dpu_encoder_irq_control(drm_enc, true);\n\t\telse\n\t\t\t_dpu_encoder_resource_control_helper(drm_enc, true);\n\n\t\tdpu_enc->rc_state = DPU_ENC_RC_STATE_ON;\n\n\t\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event,\n\t\t\t\t dpu_enc->idle_pc_supported, dpu_enc->rc_state,\n\t\t\t\t \"kickoff\");\n\n\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\tbreak;\n\n\tcase DPU_ENC_RC_EVENT_FRAME_DONE:\n\t\t \n\t\tif (dpu_enc->rc_state != DPU_ENC_RC_STATE_ON) {\n\t\t\tDRM_DEBUG_KMS(\"id:%d, sw_event:%d,rc:%d-unexpected\\n\",\n\t\t\t\t      DRMID(drm_enc), sw_event,\n\t\t\t\t      dpu_enc->rc_state);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (dpu_crtc_frame_pending(drm_enc->crtc) > 1) {\n\t\t\tDRM_DEBUG_KMS(\"id:%d skip schedule work\\n\",\n\t\t\t\t      DRMID(drm_enc));\n\t\t\treturn 0;\n\t\t}\n\n\t\tqueue_delayed_work(priv->wq, &dpu_enc->delayed_off_work,\n\t\t\t\t   msecs_to_jiffies(dpu_enc->idle_timeout));\n\n\t\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event,\n\t\t\t\t dpu_enc->idle_pc_supported, dpu_enc->rc_state,\n\t\t\t\t \"frame done\");\n\t\tbreak;\n\n\tcase DPU_ENC_RC_EVENT_PRE_STOP:\n\t\t \n\t\tif (cancel_delayed_work_sync(&dpu_enc->delayed_off_work))\n\t\t\tDPU_DEBUG_ENC(dpu_enc, \"sw_event:%d, work cancelled\\n\",\n\t\t\t\t\tsw_event);\n\n\t\tmutex_lock(&dpu_enc->rc_lock);\n\n\t\tif (is_vid_mode &&\n\t\t\t  dpu_enc->rc_state == DPU_ENC_RC_STATE_IDLE) {\n\t\t\t_dpu_encoder_irq_control(drm_enc, true);\n\t\t}\n\t\t \n\t\telse if (dpu_enc->rc_state == DPU_ENC_RC_STATE_OFF ||\n\t\t\t\tdpu_enc->rc_state == DPU_ENC_RC_STATE_IDLE) {\n\t\t\tDRM_DEBUG_KMS(\"id:%u, sw_event:%d, rc in %d state\\n\",\n\t\t\t\t      DRMID(drm_enc), sw_event,\n\t\t\t\t      dpu_enc->rc_state);\n\t\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\t\treturn 0;\n\t\t}\n\n\t\tdpu_enc->rc_state = DPU_ENC_RC_STATE_PRE_OFF;\n\n\t\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event,\n\t\t\t\t dpu_enc->idle_pc_supported, dpu_enc->rc_state,\n\t\t\t\t \"pre stop\");\n\n\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\tbreak;\n\n\tcase DPU_ENC_RC_EVENT_STOP:\n\t\tmutex_lock(&dpu_enc->rc_lock);\n\n\t\t \n\t\tif (dpu_enc->rc_state == DPU_ENC_RC_STATE_OFF) {\n\t\t\tDRM_DEBUG_KMS(\"id: %u, sw_event:%d, rc in OFF state\\n\",\n\t\t\t\t      DRMID(drm_enc), sw_event);\n\t\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\t\treturn 0;\n\t\t} else if (dpu_enc->rc_state == DPU_ENC_RC_STATE_ON) {\n\t\t\tDRM_ERROR(\"id: %u, sw_event:%d, rc in state %d\\n\",\n\t\t\t\t  DRMID(drm_enc), sw_event, dpu_enc->rc_state);\n\t\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t \n\t\tif (dpu_enc->rc_state == DPU_ENC_RC_STATE_PRE_OFF)\n\t\t\t_dpu_encoder_resource_control_helper(drm_enc, false);\n\n\t\tdpu_enc->rc_state = DPU_ENC_RC_STATE_OFF;\n\n\t\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event,\n\t\t\t\t dpu_enc->idle_pc_supported, dpu_enc->rc_state,\n\t\t\t\t \"stop\");\n\n\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\tbreak;\n\n\tcase DPU_ENC_RC_EVENT_ENTER_IDLE:\n\t\tmutex_lock(&dpu_enc->rc_lock);\n\n\t\tif (dpu_enc->rc_state != DPU_ENC_RC_STATE_ON) {\n\t\t\tDRM_ERROR(\"id: %u, sw_event:%d, rc:%d !ON state\\n\",\n\t\t\t\t  DRMID(drm_enc), sw_event, dpu_enc->rc_state);\n\t\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\t\treturn 0;\n\t\t}\n\n\t\t \n\t\tif (dpu_enc->frame_busy_mask[0]) {\n\t\t\tDRM_ERROR(\"id:%u, sw_event:%d, rc:%d frame pending\\n\",\n\t\t\t\t  DRMID(drm_enc), sw_event, dpu_enc->rc_state);\n\t\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (is_vid_mode)\n\t\t\t_dpu_encoder_irq_control(drm_enc, false);\n\t\telse\n\t\t\t_dpu_encoder_resource_control_helper(drm_enc, false);\n\n\t\tdpu_enc->rc_state = DPU_ENC_RC_STATE_IDLE;\n\n\t\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event,\n\t\t\t\t dpu_enc->idle_pc_supported, dpu_enc->rc_state,\n\t\t\t\t \"idle\");\n\n\t\tmutex_unlock(&dpu_enc->rc_lock);\n\t\tbreak;\n\n\tdefault:\n\t\tDRM_ERROR(\"id:%u, unexpected sw_event: %d\\n\", DRMID(drm_enc),\n\t\t\t  sw_event);\n\t\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event,\n\t\t\t\t dpu_enc->idle_pc_supported, dpu_enc->rc_state,\n\t\t\t\t \"error\");\n\t\tbreak;\n\t}\n\n\ttrace_dpu_enc_rc(DRMID(drm_enc), sw_event,\n\t\t\t dpu_enc->idle_pc_supported, dpu_enc->rc_state,\n\t\t\t \"end\");\n\treturn 0;\n}\n\nvoid dpu_encoder_prepare_wb_job(struct drm_encoder *drm_enc,\n\t\tstruct drm_writeback_job *job)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tint i;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->ops.prepare_wb_job)\n\t\t\tphys->ops.prepare_wb_job(phys, job);\n\n\t}\n}\n\nvoid dpu_encoder_cleanup_wb_job(struct drm_encoder *drm_enc,\n\t\tstruct drm_writeback_job *job)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tint i;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->ops.cleanup_wb_job)\n\t\t\tphys->ops.cleanup_wb_job(phys, job);\n\n\t}\n}\n\nstatic void dpu_encoder_virt_atomic_mode_set(struct drm_encoder *drm_enc,\n\t\t\t\t\t     struct drm_crtc_state *crtc_state,\n\t\t\t\t\t     struct drm_connector_state *conn_state)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct msm_drm_private *priv;\n\tstruct dpu_kms *dpu_kms;\n\tstruct dpu_crtc_state *cstate;\n\tstruct dpu_global_state *global_state;\n\tstruct dpu_hw_blk *hw_pp[MAX_CHANNELS_PER_ENC];\n\tstruct dpu_hw_blk *hw_ctl[MAX_CHANNELS_PER_ENC];\n\tstruct dpu_hw_blk *hw_lm[MAX_CHANNELS_PER_ENC];\n\tstruct dpu_hw_blk *hw_dspp[MAX_CHANNELS_PER_ENC] = { NULL };\n\tstruct dpu_hw_blk *hw_dsc[MAX_CHANNELS_PER_ENC];\n\tint num_lm, num_ctl, num_pp, num_dsc;\n\tunsigned int dsc_mask = 0;\n\tint i;\n\n\tif (!drm_enc) {\n\t\tDPU_ERROR(\"invalid encoder\\n\");\n\t\treturn;\n\t}\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tDPU_DEBUG_ENC(dpu_enc, \"\\n\");\n\n\tpriv = drm_enc->dev->dev_private;\n\tdpu_kms = to_dpu_kms(priv->kms);\n\n\tglobal_state = dpu_kms_get_existing_global_state(dpu_kms);\n\tif (IS_ERR_OR_NULL(global_state)) {\n\t\tDPU_ERROR(\"Failed to get global state\");\n\t\treturn;\n\t}\n\n\ttrace_dpu_enc_mode_set(DRMID(drm_enc));\n\n\t \n\tnum_pp = dpu_rm_get_assigned_resources(&dpu_kms->rm, global_state,\n\t\tdrm_enc->base.id, DPU_HW_BLK_PINGPONG, hw_pp,\n\t\tARRAY_SIZE(hw_pp));\n\tnum_ctl = dpu_rm_get_assigned_resources(&dpu_kms->rm, global_state,\n\t\tdrm_enc->base.id, DPU_HW_BLK_CTL, hw_ctl, ARRAY_SIZE(hw_ctl));\n\tnum_lm = dpu_rm_get_assigned_resources(&dpu_kms->rm, global_state,\n\t\tdrm_enc->base.id, DPU_HW_BLK_LM, hw_lm, ARRAY_SIZE(hw_lm));\n\tdpu_rm_get_assigned_resources(&dpu_kms->rm, global_state,\n\t\tdrm_enc->base.id, DPU_HW_BLK_DSPP, hw_dspp,\n\t\tARRAY_SIZE(hw_dspp));\n\n\tfor (i = 0; i < MAX_CHANNELS_PER_ENC; i++)\n\t\tdpu_enc->hw_pp[i] = i < num_pp ? to_dpu_hw_pingpong(hw_pp[i])\n\t\t\t\t\t\t: NULL;\n\n\tnum_dsc = dpu_rm_get_assigned_resources(&dpu_kms->rm, global_state,\n\t\t\t\t\t\tdrm_enc->base.id, DPU_HW_BLK_DSC,\n\t\t\t\t\t\thw_dsc, ARRAY_SIZE(hw_dsc));\n\tfor (i = 0; i < num_dsc; i++) {\n\t\tdpu_enc->hw_dsc[i] = to_dpu_hw_dsc(hw_dsc[i]);\n\t\tdsc_mask |= BIT(dpu_enc->hw_dsc[i]->idx - DSC_0);\n\t}\n\n\tdpu_enc->dsc_mask = dsc_mask;\n\n\tcstate = to_dpu_crtc_state(crtc_state);\n\n\tfor (i = 0; i < num_lm; i++) {\n\t\tint ctl_idx = (i < num_ctl) ? i : (num_ctl-1);\n\n\t\tcstate->mixers[i].hw_lm = to_dpu_hw_mixer(hw_lm[i]);\n\t\tcstate->mixers[i].lm_ctl = to_dpu_hw_ctl(hw_ctl[ctl_idx]);\n\t\tcstate->mixers[i].hw_dspp = to_dpu_hw_dspp(hw_dspp[i]);\n\t}\n\n\tcstate->num_mixers = num_lm;\n\n\tdpu_enc->connector = conn_state->connector;\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (!dpu_enc->hw_pp[i]) {\n\t\t\tDPU_ERROR_ENC(dpu_enc,\n\t\t\t\t\"no pp block assigned at idx: %d\\n\", i);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!hw_ctl[i]) {\n\t\t\tDPU_ERROR_ENC(dpu_enc,\n\t\t\t\t\"no ctl block assigned at idx: %d\\n\", i);\n\t\t\treturn;\n\t\t}\n\n\t\tphys->hw_pp = dpu_enc->hw_pp[i];\n\t\tphys->hw_ctl = to_dpu_hw_ctl(hw_ctl[i]);\n\n\t\tphys->cached_mode = crtc_state->adjusted_mode;\n\t\tif (phys->ops.atomic_mode_set)\n\t\t\tphys->ops.atomic_mode_set(phys, crtc_state, conn_state);\n\t}\n}\n\nstatic void _dpu_encoder_virt_enable_helper(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\tint i;\n\n\tif (!drm_enc || !drm_enc->dev) {\n\t\tDPU_ERROR(\"invalid parameters\\n\");\n\t\treturn;\n\t}\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tif (!dpu_enc || !dpu_enc->cur_master) {\n\t\tDPU_ERROR(\"invalid dpu encoder/master\\n\");\n\t\treturn;\n\t}\n\n\n\tif (dpu_enc->disp_info.intf_type == INTF_DP &&\n\t\tdpu_enc->cur_master->hw_mdptop &&\n\t\tdpu_enc->cur_master->hw_mdptop->ops.intf_audio_select)\n\t\tdpu_enc->cur_master->hw_mdptop->ops.intf_audio_select(\n\t\t\tdpu_enc->cur_master->hw_mdptop);\n\n\t_dpu_encoder_update_vsync_source(dpu_enc, &dpu_enc->disp_info);\n\n\tif (dpu_enc->disp_info.intf_type == INTF_DSI &&\n\t\t\t!WARN_ON(dpu_enc->num_phys_encs == 0)) {\n\t\tunsigned bpc = dpu_enc->connector->display_info.bpc;\n\t\tfor (i = 0; i < MAX_CHANNELS_PER_ENC; i++) {\n\t\t\tif (!dpu_enc->hw_pp[i])\n\t\t\t\tcontinue;\n\t\t\t_dpu_encoder_setup_dither(dpu_enc->hw_pp[i], bpc);\n\t\t}\n\t}\n}\n\nvoid dpu_encoder_virt_runtime_resume(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tmutex_lock(&dpu_enc->enc_lock);\n\n\tif (!dpu_enc->enabled)\n\t\tgoto out;\n\n\tif (dpu_enc->cur_slave && dpu_enc->cur_slave->ops.restore)\n\t\tdpu_enc->cur_slave->ops.restore(dpu_enc->cur_slave);\n\tif (dpu_enc->cur_master && dpu_enc->cur_master->ops.restore)\n\t\tdpu_enc->cur_master->ops.restore(dpu_enc->cur_master);\n\n\t_dpu_encoder_virt_enable_helper(drm_enc);\n\nout:\n\tmutex_unlock(&dpu_enc->enc_lock);\n}\n\nstatic void dpu_encoder_virt_atomic_enable(struct drm_encoder *drm_enc,\n\t\t\t\t\tstruct drm_atomic_state *state)\n{\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\tint ret = 0;\n\tstruct drm_display_mode *cur_mode = NULL;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tdpu_enc->dsc = dpu_encoder_get_dsc_config(drm_enc);\n\n\tmutex_lock(&dpu_enc->enc_lock);\n\tcur_mode = &dpu_enc->base.crtc->state->adjusted_mode;\n\n\ttrace_dpu_enc_enable(DRMID(drm_enc), cur_mode->hdisplay,\n\t\t\t     cur_mode->vdisplay);\n\n\t \n\tif (dpu_enc->cur_slave && dpu_enc->cur_slave->ops.enable)\n\t\tdpu_enc->cur_slave->ops.enable(dpu_enc->cur_slave);\n\n\tif (dpu_enc->cur_master && dpu_enc->cur_master->ops.enable)\n\t\tdpu_enc->cur_master->ops.enable(dpu_enc->cur_master);\n\n\tret = dpu_encoder_resource_control(drm_enc, DPU_ENC_RC_EVENT_KICKOFF);\n\tif (ret) {\n\t\tDPU_ERROR_ENC(dpu_enc, \"dpu resource control failed: %d\\n\",\n\t\t\t\tret);\n\t\tgoto out;\n\t}\n\n\t_dpu_encoder_virt_enable_helper(drm_enc);\n\n\tdpu_enc->enabled = true;\n\nout:\n\tmutex_unlock(&dpu_enc->enc_lock);\n}\n\nstatic void dpu_encoder_virt_atomic_disable(struct drm_encoder *drm_enc,\n\t\t\t\t\tstruct drm_atomic_state *state)\n{\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *old_state = NULL;\n\tint i = 0;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tDPU_DEBUG_ENC(dpu_enc, \"\\n\");\n\n\tcrtc = drm_atomic_get_old_crtc_for_encoder(state, drm_enc);\n\tif (crtc)\n\t\told_state = drm_atomic_get_old_crtc_state(state, crtc);\n\n\t \n\tif (old_state && old_state->self_refresh_active)\n\t\treturn;\n\n\tmutex_lock(&dpu_enc->enc_lock);\n\tdpu_enc->enabled = false;\n\n\ttrace_dpu_enc_disable(DRMID(drm_enc));\n\n\t \n\tdpu_encoder_wait_for_event(drm_enc, MSM_ENC_TX_COMPLETE);\n\n\tdpu_encoder_resource_control(drm_enc, DPU_ENC_RC_EVENT_PRE_STOP);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->ops.disable)\n\t\t\tphys->ops.disable(phys);\n\t}\n\n\n\t \n\tif (atomic_xchg(&dpu_enc->frame_done_timeout_ms, 0)) {\n\t\tDPU_ERROR(\"enc%d timeout pending\\n\", drm_enc->base.id);\n\t\tdel_timer_sync(&dpu_enc->frame_done_timer);\n\t}\n\n\tdpu_encoder_resource_control(drm_enc, DPU_ENC_RC_EVENT_STOP);\n\n\tdpu_enc->connector = NULL;\n\n\tDPU_DEBUG_ENC(dpu_enc, \"encoder disabled\\n\");\n\n\tmutex_unlock(&dpu_enc->enc_lock);\n}\n\nstatic struct dpu_hw_intf *dpu_encoder_get_intf(const struct dpu_mdss_cfg *catalog,\n\t\tstruct dpu_rm *dpu_rm,\n\t\tenum dpu_intf_type type, u32 controller_id)\n{\n\tint i = 0;\n\n\tif (type == INTF_WB)\n\t\treturn NULL;\n\n\tfor (i = 0; i < catalog->intf_count; i++) {\n\t\tif (catalog->intf[i].type == type\n\t\t    && catalog->intf[i].controller_id == controller_id) {\n\t\t\treturn dpu_rm_get_intf(dpu_rm, catalog->intf[i].id);\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nvoid dpu_encoder_vblank_callback(struct drm_encoder *drm_enc,\n\t\tstruct dpu_encoder_phys *phy_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\tunsigned long lock_flags;\n\n\tif (!drm_enc || !phy_enc)\n\t\treturn;\n\n\tDPU_ATRACE_BEGIN(\"encoder_vblank_callback\");\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tatomic_inc(&phy_enc->vsync_cnt);\n\n\tspin_lock_irqsave(&dpu_enc->enc_spinlock, lock_flags);\n\tif (dpu_enc->crtc)\n\t\tdpu_crtc_vblank_callback(dpu_enc->crtc);\n\tspin_unlock_irqrestore(&dpu_enc->enc_spinlock, lock_flags);\n\n\tDPU_ATRACE_END(\"encoder_vblank_callback\");\n}\n\nvoid dpu_encoder_underrun_callback(struct drm_encoder *drm_enc,\n\t\tstruct dpu_encoder_phys *phy_enc)\n{\n\tif (!phy_enc)\n\t\treturn;\n\n\tDPU_ATRACE_BEGIN(\"encoder_underrun_callback\");\n\tatomic_inc(&phy_enc->underrun_cnt);\n\n\t \n\tif (atomic_read(&phy_enc->underrun_cnt) == 1)\n\t\tmsm_disp_snapshot_state(drm_enc->dev);\n\n\ttrace_dpu_enc_underrun_cb(DRMID(drm_enc),\n\t\t\t\t  atomic_read(&phy_enc->underrun_cnt));\n\tDPU_ATRACE_END(\"encoder_underrun_callback\");\n}\n\nvoid dpu_encoder_assign_crtc(struct drm_encoder *drm_enc, struct drm_crtc *crtc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\tunsigned long lock_flags;\n\n\tspin_lock_irqsave(&dpu_enc->enc_spinlock, lock_flags);\n\t \n\tWARN_ON(crtc && dpu_enc->crtc);\n\tdpu_enc->crtc = crtc;\n\tspin_unlock_irqrestore(&dpu_enc->enc_spinlock, lock_flags);\n}\n\nvoid dpu_encoder_toggle_vblank_for_crtc(struct drm_encoder *drm_enc,\n\t\t\t\t\tstruct drm_crtc *crtc, bool enable)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\tunsigned long lock_flags;\n\tint i;\n\n\ttrace_dpu_enc_vblank_cb(DRMID(drm_enc), enable);\n\n\tspin_lock_irqsave(&dpu_enc->enc_spinlock, lock_flags);\n\tif (dpu_enc->crtc != crtc) {\n\t\tspin_unlock_irqrestore(&dpu_enc->enc_spinlock, lock_flags);\n\t\treturn;\n\t}\n\tspin_unlock_irqrestore(&dpu_enc->enc_spinlock, lock_flags);\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->ops.control_vblank_irq)\n\t\t\tphys->ops.control_vblank_irq(phys, enable);\n\t}\n}\n\nvoid dpu_encoder_register_frame_event_callback(struct drm_encoder *drm_enc,\n\t\tvoid (*frame_event_cb)(void *, u32 event),\n\t\tvoid *frame_event_cb_data)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\tunsigned long lock_flags;\n\tbool enable;\n\n\tenable = frame_event_cb ? true : false;\n\n\tif (!drm_enc) {\n\t\tDPU_ERROR(\"invalid encoder\\n\");\n\t\treturn;\n\t}\n\ttrace_dpu_enc_frame_event_cb(DRMID(drm_enc), enable);\n\n\tspin_lock_irqsave(&dpu_enc->enc_spinlock, lock_flags);\n\tdpu_enc->crtc_frame_event_cb = frame_event_cb;\n\tdpu_enc->crtc_frame_event_cb_data = frame_event_cb_data;\n\tspin_unlock_irqrestore(&dpu_enc->enc_spinlock, lock_flags);\n}\n\nvoid dpu_encoder_frame_done_callback(\n\t\tstruct drm_encoder *drm_enc,\n\t\tstruct dpu_encoder_phys *ready_phys, u32 event)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\tunsigned int i;\n\n\tif (event & (DPU_ENCODER_FRAME_EVENT_DONE\n\t\t\t| DPU_ENCODER_FRAME_EVENT_ERROR\n\t\t\t| DPU_ENCODER_FRAME_EVENT_PANEL_DEAD)) {\n\n\t\tif (!dpu_enc->frame_busy_mask[0]) {\n\t\t\t \n\t\t\ttrace_dpu_enc_frame_done_cb_not_busy(DRMID(drm_enc), event,\n\t\t\t\t\tdpu_encoder_helper_get_intf_type(ready_phys->intf_mode),\n\t\t\t\t\tready_phys->hw_intf ? ready_phys->hw_intf->idx : -1,\n\t\t\t\t\tready_phys->hw_wb ? ready_phys->hw_wb->idx : -1);\n\t\t\treturn;\n\t\t}\n\n\t\t \n\t\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\t\tif (dpu_enc->phys_encs[i] == ready_phys) {\n\t\t\t\ttrace_dpu_enc_frame_done_cb(DRMID(drm_enc), i,\n\t\t\t\t\t\tdpu_enc->frame_busy_mask[0]);\n\t\t\t\tclear_bit(i, dpu_enc->frame_busy_mask);\n\t\t\t}\n\t\t}\n\n\t\tif (!dpu_enc->frame_busy_mask[0]) {\n\t\t\tatomic_set(&dpu_enc->frame_done_timeout_ms, 0);\n\t\t\tdel_timer(&dpu_enc->frame_done_timer);\n\n\t\t\tdpu_encoder_resource_control(drm_enc,\n\t\t\t\t\tDPU_ENC_RC_EVENT_FRAME_DONE);\n\n\t\t\tif (dpu_enc->crtc_frame_event_cb)\n\t\t\t\tdpu_enc->crtc_frame_event_cb(\n\t\t\t\t\tdpu_enc->crtc_frame_event_cb_data,\n\t\t\t\t\tevent);\n\t\t}\n\t} else {\n\t\tif (dpu_enc->crtc_frame_event_cb)\n\t\t\tdpu_enc->crtc_frame_event_cb(\n\t\t\t\tdpu_enc->crtc_frame_event_cb_data, event);\n\t}\n}\n\nstatic void dpu_encoder_off_work(struct work_struct *work)\n{\n\tstruct dpu_encoder_virt *dpu_enc = container_of(work,\n\t\t\tstruct dpu_encoder_virt, delayed_off_work.work);\n\n\tdpu_encoder_resource_control(&dpu_enc->base,\n\t\t\t\t\t\tDPU_ENC_RC_EVENT_ENTER_IDLE);\n\n\tdpu_encoder_frame_done_callback(&dpu_enc->base, NULL,\n\t\t\t\tDPU_ENCODER_FRAME_EVENT_IDLE);\n}\n\n \nstatic void _dpu_encoder_trigger_flush(struct drm_encoder *drm_enc,\n\t\tstruct dpu_encoder_phys *phys, uint32_t extra_flush_bits)\n{\n\tstruct dpu_hw_ctl *ctl;\n\tint pending_kickoff_cnt;\n\tu32 ret = UINT_MAX;\n\n\tif (!phys->hw_pp) {\n\t\tDPU_ERROR(\"invalid pingpong hw\\n\");\n\t\treturn;\n\t}\n\n\tctl = phys->hw_ctl;\n\tif (!ctl->ops.trigger_flush) {\n\t\tDPU_ERROR(\"missing trigger cb\\n\");\n\t\treturn;\n\t}\n\n\tpending_kickoff_cnt = dpu_encoder_phys_inc_pending(phys);\n\n\tif (extra_flush_bits && ctl->ops.update_pending_flush)\n\t\tctl->ops.update_pending_flush(ctl, extra_flush_bits);\n\n\tctl->ops.trigger_flush(ctl);\n\n\tif (ctl->ops.get_pending_flush)\n\t\tret = ctl->ops.get_pending_flush(ctl);\n\n\ttrace_dpu_enc_trigger_flush(DRMID(drm_enc),\n\t\t\tdpu_encoder_helper_get_intf_type(phys->intf_mode),\n\t\t\tphys->hw_intf ? phys->hw_intf->idx : -1,\n\t\t\tphys->hw_wb ? phys->hw_wb->idx : -1,\n\t\t\tpending_kickoff_cnt, ctl->idx,\n\t\t\textra_flush_bits, ret);\n}\n\n \nstatic void _dpu_encoder_trigger_start(struct dpu_encoder_phys *phys)\n{\n\tif (!phys) {\n\t\tDPU_ERROR(\"invalid argument(s)\\n\");\n\t\treturn;\n\t}\n\n\tif (!phys->hw_pp) {\n\t\tDPU_ERROR(\"invalid pingpong hw\\n\");\n\t\treturn;\n\t}\n\n\tif (phys->ops.trigger_start && phys->enable_state != DPU_ENC_DISABLED)\n\t\tphys->ops.trigger_start(phys);\n}\n\nvoid dpu_encoder_helper_trigger_start(struct dpu_encoder_phys *phys_enc)\n{\n\tstruct dpu_hw_ctl *ctl;\n\n\tctl = phys_enc->hw_ctl;\n\tif (ctl->ops.trigger_start) {\n\t\tctl->ops.trigger_start(ctl);\n\t\ttrace_dpu_enc_trigger_start(DRMID(phys_enc->parent), ctl->idx);\n\t}\n}\n\nstatic int dpu_encoder_helper_wait_event_timeout(\n\t\tint32_t drm_id,\n\t\tu32 irq_idx,\n\t\tstruct dpu_encoder_wait_info *info)\n{\n\tint rc = 0;\n\ts64 expected_time = ktime_to_ms(ktime_get()) + info->timeout_ms;\n\ts64 jiffies = msecs_to_jiffies(info->timeout_ms);\n\ts64 time;\n\n\tdo {\n\t\trc = wait_event_timeout(*(info->wq),\n\t\t\t\tatomic_read(info->atomic_cnt) == 0, jiffies);\n\t\ttime = ktime_to_ms(ktime_get());\n\n\t\ttrace_dpu_enc_wait_event_timeout(drm_id, irq_idx, rc, time,\n\t\t\t\t\t\t expected_time,\n\t\t\t\t\t\t atomic_read(info->atomic_cnt));\n\t \n\t} while (atomic_read(info->atomic_cnt) && (rc == 0) &&\n\t\t\t(time < expected_time));\n\n\treturn rc;\n}\n\nstatic void dpu_encoder_helper_hw_reset(struct dpu_encoder_phys *phys_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct dpu_hw_ctl *ctl;\n\tint rc;\n\tstruct drm_encoder *drm_enc;\n\n\tdpu_enc = to_dpu_encoder_virt(phys_enc->parent);\n\tctl = phys_enc->hw_ctl;\n\tdrm_enc = phys_enc->parent;\n\n\tif (!ctl->ops.reset)\n\t\treturn;\n\n\tDRM_DEBUG_KMS(\"id:%u ctl %d reset\\n\", DRMID(drm_enc),\n\t\t      ctl->idx);\n\n\trc = ctl->ops.reset(ctl);\n\tif (rc) {\n\t\tDPU_ERROR_ENC(dpu_enc, \"ctl %d reset failure\\n\",  ctl->idx);\n\t\tmsm_disp_snapshot_state(drm_enc->dev);\n\t}\n\n\tphys_enc->enable_state = DPU_ENC_ENABLED;\n}\n\n \nstatic void _dpu_encoder_kickoff_phys(struct dpu_encoder_virt *dpu_enc)\n{\n\tstruct dpu_hw_ctl *ctl;\n\tuint32_t i, pending_flush;\n\tunsigned long lock_flags;\n\n\tpending_flush = 0x0;\n\n\t \n\tspin_lock_irqsave(&dpu_enc->enc_spinlock, lock_flags);\n\n\t \n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tif (phys->enable_state == DPU_ENC_DISABLED)\n\t\t\tcontinue;\n\n\t\tctl = phys->hw_ctl;\n\n\t\t \n\t\tif (phys->split_role != ENC_ROLE_SLAVE)\n\t\t\tset_bit(i, dpu_enc->frame_busy_mask);\n\n\t\tif (!phys->ops.needs_single_flush ||\n\t\t\t\t!phys->ops.needs_single_flush(phys))\n\t\t\t_dpu_encoder_trigger_flush(&dpu_enc->base, phys, 0x0);\n\t\telse if (ctl->ops.get_pending_flush)\n\t\t\tpending_flush |= ctl->ops.get_pending_flush(ctl);\n\t}\n\n\t \n\tif (pending_flush && dpu_enc->cur_master) {\n\t\t_dpu_encoder_trigger_flush(\n\t\t\t\t&dpu_enc->base,\n\t\t\t\tdpu_enc->cur_master,\n\t\t\t\tpending_flush);\n\t}\n\n\t_dpu_encoder_trigger_start(dpu_enc->cur_master);\n\n\tspin_unlock_irqrestore(&dpu_enc->enc_spinlock, lock_flags);\n}\n\nvoid dpu_encoder_trigger_kickoff_pending(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct dpu_encoder_phys *phys;\n\tunsigned int i;\n\tstruct dpu_hw_ctl *ctl;\n\tstruct msm_display_info *disp_info;\n\n\tif (!drm_enc) {\n\t\tDPU_ERROR(\"invalid encoder\\n\");\n\t\treturn;\n\t}\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tdisp_info = &dpu_enc->disp_info;\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tphys = dpu_enc->phys_encs[i];\n\n\t\tctl = phys->hw_ctl;\n\t\tif (ctl->ops.clear_pending_flush)\n\t\t\tctl->ops.clear_pending_flush(ctl);\n\n\t\t \n\t\tif ((phys == dpu_enc->cur_master) &&\n\t\t    disp_info->is_cmd_mode\n\t\t    && ctl->ops.trigger_pending)\n\t\t\tctl->ops.trigger_pending(ctl);\n\t}\n}\n\nstatic u32 _dpu_encoder_calculate_linetime(struct dpu_encoder_virt *dpu_enc,\n\t\tstruct drm_display_mode *mode)\n{\n\tu64 pclk_rate;\n\tu32 pclk_period;\n\tu32 line_time;\n\n\t \n\tif (!dpu_enc->cur_master)\n\t\treturn 0;\n\n\tif (!dpu_enc->cur_master->ops.get_line_count) {\n\t\tDPU_ERROR(\"get_line_count function not defined\\n\");\n\t\treturn 0;\n\t}\n\n\tpclk_rate = mode->clock;  \n\tif (pclk_rate == 0) {\n\t\tDPU_ERROR(\"pclk is 0, cannot calculate line time\\n\");\n\t\treturn 0;\n\t}\n\n\tpclk_period = DIV_ROUND_UP_ULL(1000000000ull, pclk_rate);\n\tif (pclk_period == 0) {\n\t\tDPU_ERROR(\"pclk period is 0\\n\");\n\t\treturn 0;\n\t}\n\n\t \n\tline_time = (pclk_period * mode->htotal) / 1000;\n\tif (line_time == 0) {\n\t\tDPU_ERROR(\"line time calculation is 0\\n\");\n\t\treturn 0;\n\t}\n\n\tDPU_DEBUG_ENC(dpu_enc,\n\t\t\t\"clk_rate=%lldkHz, clk_period=%d, linetime=%dns\\n\",\n\t\t\tpclk_rate, pclk_period, line_time);\n\n\treturn line_time;\n}\n\nint dpu_encoder_vsync_time(struct drm_encoder *drm_enc, ktime_t *wakeup_time)\n{\n\tstruct drm_display_mode *mode;\n\tstruct dpu_encoder_virt *dpu_enc;\n\tu32 cur_line;\n\tu32 line_time;\n\tu32 vtotal, time_to_vsync;\n\tktime_t cur_time;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tif (!drm_enc->crtc || !drm_enc->crtc->state) {\n\t\tDPU_ERROR(\"crtc/crtc state object is NULL\\n\");\n\t\treturn -EINVAL;\n\t}\n\tmode = &drm_enc->crtc->state->adjusted_mode;\n\n\tline_time = _dpu_encoder_calculate_linetime(dpu_enc, mode);\n\tif (!line_time)\n\t\treturn -EINVAL;\n\n\tcur_line = dpu_enc->cur_master->ops.get_line_count(dpu_enc->cur_master);\n\n\tvtotal = mode->vtotal;\n\tif (cur_line >= vtotal)\n\t\ttime_to_vsync = line_time * vtotal;\n\telse\n\t\ttime_to_vsync = line_time * (vtotal - cur_line);\n\n\tif (time_to_vsync == 0) {\n\t\tDPU_ERROR(\"time to vsync should not be zero, vtotal=%d\\n\",\n\t\t\t\tvtotal);\n\t\treturn -EINVAL;\n\t}\n\n\tcur_time = ktime_get();\n\t*wakeup_time = ktime_add_ns(cur_time, time_to_vsync);\n\n\tDPU_DEBUG_ENC(dpu_enc,\n\t\t\t\"cur_line=%u vtotal=%u time_to_vsync=%u, cur_time=%lld, wakeup_time=%lld\\n\",\n\t\t\tcur_line, vtotal, time_to_vsync,\n\t\t\tktime_to_ms(cur_time),\n\t\t\tktime_to_ms(*wakeup_time));\n\treturn 0;\n}\n\nstatic u32\ndpu_encoder_dsc_initial_line_calc(struct drm_dsc_config *dsc,\n\t\t\t\t  u32 enc_ip_width)\n{\n\tint ssm_delay, total_pixels, soft_slice_per_enc;\n\n\tsoft_slice_per_enc = enc_ip_width / dsc->slice_width;\n\n\t \n\tssm_delay = ((dsc->bits_per_component < 10) ? 84 : 92);\n\ttotal_pixels = ssm_delay * 3 + dsc->initial_xmit_delay + 47;\n\tif (soft_slice_per_enc > 1)\n\t\ttotal_pixels += (ssm_delay * 3);\n\treturn DIV_ROUND_UP(total_pixels, dsc->slice_width);\n}\n\nstatic void dpu_encoder_dsc_pipe_cfg(struct dpu_hw_ctl *ctl,\n\t\t\t\t     struct dpu_hw_dsc *hw_dsc,\n\t\t\t\t     struct dpu_hw_pingpong *hw_pp,\n\t\t\t\t     struct drm_dsc_config *dsc,\n\t\t\t\t     u32 common_mode,\n\t\t\t\t     u32 initial_lines)\n{\n\tif (hw_dsc->ops.dsc_config)\n\t\thw_dsc->ops.dsc_config(hw_dsc, dsc, common_mode, initial_lines);\n\n\tif (hw_dsc->ops.dsc_config_thresh)\n\t\thw_dsc->ops.dsc_config_thresh(hw_dsc, dsc);\n\n\tif (hw_pp->ops.setup_dsc)\n\t\thw_pp->ops.setup_dsc(hw_pp);\n\n\tif (hw_dsc->ops.dsc_bind_pingpong_blk)\n\t\thw_dsc->ops.dsc_bind_pingpong_blk(hw_dsc, hw_pp->idx);\n\n\tif (hw_pp->ops.enable_dsc)\n\t\thw_pp->ops.enable_dsc(hw_pp);\n\n\tif (ctl->ops.update_pending_flush_dsc)\n\t\tctl->ops.update_pending_flush_dsc(ctl, hw_dsc->idx);\n}\n\nstatic void dpu_encoder_prep_dsc(struct dpu_encoder_virt *dpu_enc,\n\t\t\t\t struct drm_dsc_config *dsc)\n{\n\t \n\tstruct dpu_encoder_phys *enc_master = dpu_enc->cur_master;\n\tstruct dpu_hw_ctl *ctl = enc_master->hw_ctl;\n\tstruct dpu_hw_dsc *hw_dsc[MAX_CHANNELS_PER_ENC];\n\tstruct dpu_hw_pingpong *hw_pp[MAX_CHANNELS_PER_ENC];\n\tint this_frame_slices;\n\tint intf_ip_w, enc_ip_w;\n\tint dsc_common_mode;\n\tint pic_width;\n\tu32 initial_lines;\n\tint i;\n\n\tfor (i = 0; i < MAX_CHANNELS_PER_ENC; i++) {\n\t\thw_pp[i] = dpu_enc->hw_pp[i];\n\t\thw_dsc[i] = dpu_enc->hw_dsc[i];\n\n\t\tif (!hw_pp[i] || !hw_dsc[i]) {\n\t\t\tDPU_ERROR_ENC(dpu_enc, \"invalid params for DSC\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\tdsc_common_mode = 0;\n\tpic_width = dsc->pic_width;\n\n\tdsc_common_mode = DSC_MODE_MULTIPLEX | DSC_MODE_SPLIT_PANEL;\n\tif (enc_master->intf_mode == INTF_MODE_VIDEO)\n\t\tdsc_common_mode |= DSC_MODE_VIDEO;\n\n\tthis_frame_slices = pic_width / dsc->slice_width;\n\tintf_ip_w = this_frame_slices * dsc->slice_width;\n\n\t \n\tenc_ip_w = intf_ip_w / 2;\n\tinitial_lines = dpu_encoder_dsc_initial_line_calc(dsc, enc_ip_w);\n\n\tfor (i = 0; i < MAX_CHANNELS_PER_ENC; i++)\n\t\tdpu_encoder_dsc_pipe_cfg(ctl, hw_dsc[i], hw_pp[i],\n\t\t\t\t\t dsc, dsc_common_mode, initial_lines);\n}\n\nvoid dpu_encoder_prepare_for_kickoff(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct dpu_encoder_phys *phys;\n\tbool needs_hw_reset = false;\n\tunsigned int i;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\ttrace_dpu_enc_prepare_kickoff(DRMID(drm_enc));\n\n\t \n\tDPU_ATRACE_BEGIN(\"enc_prepare_for_kickoff\");\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tphys = dpu_enc->phys_encs[i];\n\t\tif (phys->ops.prepare_for_kickoff)\n\t\t\tphys->ops.prepare_for_kickoff(phys);\n\t\tif (phys->enable_state == DPU_ENC_ERR_NEEDS_HW_RESET)\n\t\t\tneeds_hw_reset = true;\n\t}\n\tDPU_ATRACE_END(\"enc_prepare_for_kickoff\");\n\n\tdpu_encoder_resource_control(drm_enc, DPU_ENC_RC_EVENT_KICKOFF);\n\n\t \n\tif (needs_hw_reset) {\n\t\ttrace_dpu_enc_prepare_kickoff_reset(DRMID(drm_enc));\n\t\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\t\tdpu_encoder_helper_hw_reset(dpu_enc->phys_encs[i]);\n\t\t}\n\t}\n\n\tif (dpu_enc->dsc)\n\t\tdpu_encoder_prep_dsc(dpu_enc, dpu_enc->dsc);\n}\n\nbool dpu_encoder_is_valid_for_commit(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tunsigned int i;\n\tstruct dpu_encoder_phys *phys;\n\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tif (drm_enc->encoder_type == DRM_MODE_ENCODER_VIRTUAL) {\n\t\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\t\tphys = dpu_enc->phys_encs[i];\n\t\t\tif (phys->ops.is_valid_for_commit && !phys->ops.is_valid_for_commit(phys)) {\n\t\t\t\tDPU_DEBUG(\"invalid FB not kicking off\\n\");\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn true;\n}\n\nvoid dpu_encoder_kickoff(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc;\n\tstruct dpu_encoder_phys *phys;\n\tunsigned long timeout_ms;\n\tunsigned int i;\n\n\tDPU_ATRACE_BEGIN(\"encoder_kickoff\");\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\ttrace_dpu_enc_kickoff(DRMID(drm_enc));\n\n\ttimeout_ms = DPU_ENCODER_FRAME_DONE_TIMEOUT_FRAMES * 1000 /\n\t\t\tdrm_mode_vrefresh(&drm_enc->crtc->state->adjusted_mode);\n\n\tatomic_set(&dpu_enc->frame_done_timeout_ms, timeout_ms);\n\tmod_timer(&dpu_enc->frame_done_timer,\n\t\t\tjiffies + msecs_to_jiffies(timeout_ms));\n\n\t \n\t_dpu_encoder_kickoff_phys(dpu_enc);\n\n\t \n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tphys = dpu_enc->phys_encs[i];\n\t\tif (phys->ops.handle_post_kickoff)\n\t\t\tphys->ops.handle_post_kickoff(phys);\n\t}\n\n\tDPU_ATRACE_END(\"encoder_kickoff\");\n}\n\nstatic void dpu_encoder_helper_reset_mixers(struct dpu_encoder_phys *phys_enc)\n{\n\tstruct dpu_hw_mixer_cfg mixer;\n\tint i, num_lm;\n\tstruct dpu_global_state *global_state;\n\tstruct dpu_hw_blk *hw_lm[2];\n\tstruct dpu_hw_mixer *hw_mixer[2];\n\tstruct dpu_hw_ctl *ctl = phys_enc->hw_ctl;\n\n\tmemset(&mixer, 0, sizeof(mixer));\n\n\t \n\tif (phys_enc->hw_ctl->ops.clear_all_blendstages)\n\t\tphys_enc->hw_ctl->ops.clear_all_blendstages(phys_enc->hw_ctl);\n\n\tglobal_state = dpu_kms_get_existing_global_state(phys_enc->dpu_kms);\n\n\tnum_lm = dpu_rm_get_assigned_resources(&phys_enc->dpu_kms->rm, global_state,\n\t\tphys_enc->parent->base.id, DPU_HW_BLK_LM, hw_lm, ARRAY_SIZE(hw_lm));\n\n\tfor (i = 0; i < num_lm; i++) {\n\t\thw_mixer[i] = to_dpu_hw_mixer(hw_lm[i]);\n\t\tif (phys_enc->hw_ctl->ops.update_pending_flush_mixer)\n\t\t\tphys_enc->hw_ctl->ops.update_pending_flush_mixer(ctl, hw_mixer[i]->idx);\n\n\t\t \n\t\tif (phys_enc->hw_ctl->ops.setup_blendstage)\n\t\t\tphys_enc->hw_ctl->ops.setup_blendstage(ctl, hw_mixer[i]->idx, NULL);\n\t}\n}\n\nstatic void dpu_encoder_dsc_pipe_clr(struct dpu_hw_ctl *ctl,\n\t\t\t\t     struct dpu_hw_dsc *hw_dsc,\n\t\t\t\t     struct dpu_hw_pingpong *hw_pp)\n{\n\tif (hw_dsc->ops.dsc_disable)\n\t\thw_dsc->ops.dsc_disable(hw_dsc);\n\n\tif (hw_pp->ops.disable_dsc)\n\t\thw_pp->ops.disable_dsc(hw_pp);\n\n\tif (hw_dsc->ops.dsc_bind_pingpong_blk)\n\t\thw_dsc->ops.dsc_bind_pingpong_blk(hw_dsc, PINGPONG_NONE);\n\n\tif (ctl->ops.update_pending_flush_dsc)\n\t\tctl->ops.update_pending_flush_dsc(ctl, hw_dsc->idx);\n}\n\nstatic void dpu_encoder_unprep_dsc(struct dpu_encoder_virt *dpu_enc)\n{\n\t \n\tstruct dpu_encoder_phys *enc_master = dpu_enc->cur_master;\n\tstruct dpu_hw_ctl *ctl = enc_master->hw_ctl;\n\tstruct dpu_hw_dsc *hw_dsc[MAX_CHANNELS_PER_ENC];\n\tstruct dpu_hw_pingpong *hw_pp[MAX_CHANNELS_PER_ENC];\n\tint i;\n\n\tfor (i = 0; i < MAX_CHANNELS_PER_ENC; i++) {\n\t\thw_pp[i] = dpu_enc->hw_pp[i];\n\t\thw_dsc[i] = dpu_enc->hw_dsc[i];\n\n\t\tif (hw_pp[i] && hw_dsc[i])\n\t\t\tdpu_encoder_dsc_pipe_clr(ctl, hw_dsc[i], hw_pp[i]);\n\t}\n}\n\nvoid dpu_encoder_helper_phys_cleanup(struct dpu_encoder_phys *phys_enc)\n{\n\tstruct dpu_hw_ctl *ctl = phys_enc->hw_ctl;\n\tstruct dpu_hw_intf_cfg intf_cfg = { 0 };\n\tint i;\n\tstruct dpu_encoder_virt *dpu_enc;\n\n\tdpu_enc = to_dpu_encoder_virt(phys_enc->parent);\n\n\tphys_enc->hw_ctl->ops.reset(ctl);\n\n\tdpu_encoder_helper_reset_mixers(phys_enc);\n\n\t \n\tif (phys_enc->hw_wb) {\n\t\t \n\t\tif (phys_enc->hw_wb->ops.bind_pingpong_blk)\n\t\t\tphys_enc->hw_wb->ops.bind_pingpong_blk(phys_enc->hw_wb, PINGPONG_NONE);\n\n\t\t \n\t\tif (phys_enc->hw_ctl->ops.update_pending_flush_wb)\n\t\t\tphys_enc->hw_ctl->ops.update_pending_flush_wb(ctl, phys_enc->hw_wb->idx);\n\t} else {\n\t\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\t\tif (dpu_enc->phys_encs[i] && phys_enc->hw_intf->ops.bind_pingpong_blk)\n\t\t\t\tphys_enc->hw_intf->ops.bind_pingpong_blk(\n\t\t\t\t\t\tdpu_enc->phys_encs[i]->hw_intf,\n\t\t\t\t\t\tPINGPONG_NONE);\n\n\t\t\t \n\t\t\tif (phys_enc->hw_ctl->ops.update_pending_flush_intf)\n\t\t\t\tphys_enc->hw_ctl->ops.update_pending_flush_intf(phys_enc->hw_ctl,\n\t\t\t\t\t\tdpu_enc->phys_encs[i]->hw_intf->idx);\n\t\t}\n\t}\n\n\t \n\tif (phys_enc->hw_pp->merge_3d) {\n\t\tphys_enc->hw_pp->merge_3d->ops.setup_3d_mode(phys_enc->hw_pp->merge_3d,\n\t\t\t\tBLEND_3D_NONE);\n\t\tif (phys_enc->hw_ctl->ops.update_pending_flush_merge_3d)\n\t\t\tphys_enc->hw_ctl->ops.update_pending_flush_merge_3d(ctl,\n\t\t\t\t\tphys_enc->hw_pp->merge_3d->idx);\n\t}\n\n\tif (dpu_enc->dsc) {\n\t\tdpu_encoder_unprep_dsc(dpu_enc);\n\t\tdpu_enc->dsc = NULL;\n\t}\n\n\tintf_cfg.stream_sel = 0;  \n\tintf_cfg.mode_3d = dpu_encoder_helper_get_3d_blend_mode(phys_enc);\n\tintf_cfg.dsc = dpu_encoder_helper_get_dsc(phys_enc);\n\n\tif (phys_enc->hw_intf)\n\t\tintf_cfg.intf = phys_enc->hw_intf->idx;\n\tif (phys_enc->hw_wb)\n\t\tintf_cfg.wb = phys_enc->hw_wb->idx;\n\n\tif (phys_enc->hw_pp->merge_3d)\n\t\tintf_cfg.merge_3d = phys_enc->hw_pp->merge_3d->idx;\n\n\tif (ctl->ops.reset_intf_cfg)\n\t\tctl->ops.reset_intf_cfg(ctl, &intf_cfg);\n\n\tctl->ops.trigger_flush(ctl);\n\tctl->ops.trigger_start(ctl);\n\tctl->ops.clear_pending_flush(ctl);\n}\n\n#ifdef CONFIG_DEBUG_FS\nstatic int _dpu_encoder_status_show(struct seq_file *s, void *data)\n{\n\tstruct dpu_encoder_virt *dpu_enc = s->private;\n\tint i;\n\n\tmutex_lock(&dpu_enc->enc_lock);\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tseq_printf(s, \"intf:%d  wb:%d  vsync:%8d     underrun:%8d    \",\n\t\t\t\tphys->hw_intf ? phys->hw_intf->idx - INTF_0 : -1,\n\t\t\t\tphys->hw_wb ? phys->hw_wb->idx - WB_0 : -1,\n\t\t\t\tatomic_read(&phys->vsync_cnt),\n\t\t\t\tatomic_read(&phys->underrun_cnt));\n\n\t\tseq_printf(s, \"mode: %s\\n\", dpu_encoder_helper_get_intf_type(phys->intf_mode));\n\t}\n\tmutex_unlock(&dpu_enc->enc_lock);\n\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(_dpu_encoder_status);\n\nstatic int _dpu_encoder_init_debugfs(struct drm_encoder *drm_enc)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(drm_enc);\n\n\tchar name[12];\n\n\tif (!drm_enc->dev) {\n\t\tDPU_ERROR(\"invalid encoder or kms\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tsnprintf(name, sizeof(name), \"encoder%u\", drm_enc->base.id);\n\n\t \n\tdpu_enc->debugfs_root = debugfs_create_dir(name,\n\t\t\tdrm_enc->dev->primary->debugfs_root);\n\n\t \n\tdebugfs_create_file(\"status\", 0600,\n\t\tdpu_enc->debugfs_root, dpu_enc, &_dpu_encoder_status_fops);\n\n\treturn 0;\n}\n#else\nstatic int _dpu_encoder_init_debugfs(struct drm_encoder *drm_enc)\n{\n\treturn 0;\n}\n#endif\n\nstatic int dpu_encoder_late_register(struct drm_encoder *encoder)\n{\n\treturn _dpu_encoder_init_debugfs(encoder);\n}\n\nstatic void dpu_encoder_early_unregister(struct drm_encoder *encoder)\n{\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(encoder);\n\n\tdebugfs_remove_recursive(dpu_enc->debugfs_root);\n}\n\nstatic int dpu_encoder_virt_add_phys_encs(\n\t\tstruct msm_display_info *disp_info,\n\t\tstruct dpu_encoder_virt *dpu_enc,\n\t\tstruct dpu_enc_phys_init_params *params)\n{\n\tstruct dpu_encoder_phys *enc = NULL;\n\n\tDPU_DEBUG_ENC(dpu_enc, \"\\n\");\n\n\t \n\tif (dpu_enc->num_phys_encs + NUM_PHYS_ENCODER_TYPES >=\n\t\t\tARRAY_SIZE(dpu_enc->phys_encs)) {\n\t\tDPU_ERROR_ENC(dpu_enc, \"too many physical encoders %d\\n\",\n\t\t\t  dpu_enc->num_phys_encs);\n\t\treturn -EINVAL;\n\t}\n\n\n\tif (disp_info->intf_type == INTF_WB) {\n\t\tenc = dpu_encoder_phys_wb_init(params);\n\n\t\tif (IS_ERR(enc)) {\n\t\t\tDPU_ERROR_ENC(dpu_enc, \"failed to init wb enc: %ld\\n\",\n\t\t\t\tPTR_ERR(enc));\n\t\t\treturn PTR_ERR(enc);\n\t\t}\n\n\t\tdpu_enc->phys_encs[dpu_enc->num_phys_encs] = enc;\n\t\t++dpu_enc->num_phys_encs;\n\t} else if (disp_info->is_cmd_mode) {\n\t\tenc = dpu_encoder_phys_cmd_init(params);\n\n\t\tif (IS_ERR(enc)) {\n\t\t\tDPU_ERROR_ENC(dpu_enc, \"failed to init cmd enc: %ld\\n\",\n\t\t\t\tPTR_ERR(enc));\n\t\t\treturn PTR_ERR(enc);\n\t\t}\n\n\t\tdpu_enc->phys_encs[dpu_enc->num_phys_encs] = enc;\n\t\t++dpu_enc->num_phys_encs;\n\t} else {\n\t\tenc = dpu_encoder_phys_vid_init(params);\n\n\t\tif (IS_ERR(enc)) {\n\t\t\tDPU_ERROR_ENC(dpu_enc, \"failed to init vid enc: %ld\\n\",\n\t\t\t\tPTR_ERR(enc));\n\t\t\treturn PTR_ERR(enc);\n\t\t}\n\n\t\tdpu_enc->phys_encs[dpu_enc->num_phys_encs] = enc;\n\t\t++dpu_enc->num_phys_encs;\n\t}\n\n\tif (params->split_role == ENC_ROLE_SLAVE)\n\t\tdpu_enc->cur_slave = enc;\n\telse\n\t\tdpu_enc->cur_master = enc;\n\n\treturn 0;\n}\n\nstatic int dpu_encoder_setup_display(struct dpu_encoder_virt *dpu_enc,\n\t\t\t\t struct dpu_kms *dpu_kms,\n\t\t\t\t struct msm_display_info *disp_info)\n{\n\tint ret = 0;\n\tint i = 0;\n\tstruct dpu_enc_phys_init_params phys_params;\n\n\tif (!dpu_enc) {\n\t\tDPU_ERROR(\"invalid arg(s), enc %d\\n\", dpu_enc != NULL);\n\t\treturn -EINVAL;\n\t}\n\n\tdpu_enc->cur_master = NULL;\n\n\tmemset(&phys_params, 0, sizeof(phys_params));\n\tphys_params.dpu_kms = dpu_kms;\n\tphys_params.parent = &dpu_enc->base;\n\tphys_params.enc_spinlock = &dpu_enc->enc_spinlock;\n\n\tWARN_ON(disp_info->num_of_h_tiles < 1);\n\n\tDPU_DEBUG(\"dsi_info->num_of_h_tiles %d\\n\", disp_info->num_of_h_tiles);\n\n\tif (disp_info->intf_type != INTF_WB)\n\t\tdpu_enc->idle_pc_supported =\n\t\t\t\tdpu_kms->catalog->caps->has_idle_pc;\n\n\tmutex_lock(&dpu_enc->enc_lock);\n\tfor (i = 0; i < disp_info->num_of_h_tiles && !ret; i++) {\n\t\t \n\t\tu32 controller_id = disp_info->h_tile_instance[i];\n\n\t\tif (disp_info->num_of_h_tiles > 1) {\n\t\t\tif (i == 0)\n\t\t\t\tphys_params.split_role = ENC_ROLE_MASTER;\n\t\t\telse\n\t\t\t\tphys_params.split_role = ENC_ROLE_SLAVE;\n\t\t} else {\n\t\t\tphys_params.split_role = ENC_ROLE_SOLO;\n\t\t}\n\n\t\tDPU_DEBUG(\"h_tile_instance %d = %d, split_role %d\\n\",\n\t\t\t\ti, controller_id, phys_params.split_role);\n\n\t\tphys_params.hw_intf = dpu_encoder_get_intf(dpu_kms->catalog, &dpu_kms->rm,\n\t\t\t\t\t\t\t   disp_info->intf_type,\n\t\t\t\t\t\t\t   controller_id);\n\n\t\tif (disp_info->intf_type == INTF_WB && controller_id < WB_MAX)\n\t\t\tphys_params.hw_wb = dpu_rm_get_wb(&dpu_kms->rm, controller_id);\n\n\t\tif (!phys_params.hw_intf && !phys_params.hw_wb) {\n\t\t\tDPU_ERROR_ENC(dpu_enc, \"no intf or wb block assigned at idx: %d\\n\", i);\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (phys_params.hw_intf && phys_params.hw_wb) {\n\t\t\tDPU_ERROR_ENC(dpu_enc,\n\t\t\t\t\t\"invalid phys both intf and wb block at idx: %d\\n\", i);\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = dpu_encoder_virt_add_phys_encs(disp_info,\n\t\t\t\tdpu_enc, &phys_params);\n\t\tif (ret) {\n\t\t\tDPU_ERROR_ENC(dpu_enc, \"failed to add phys encs\\n\");\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tmutex_unlock(&dpu_enc->enc_lock);\n\n\treturn ret;\n}\n\nstatic void dpu_encoder_frame_done_timeout(struct timer_list *t)\n{\n\tstruct dpu_encoder_virt *dpu_enc = from_timer(dpu_enc, t,\n\t\t\tframe_done_timer);\n\tstruct drm_encoder *drm_enc = &dpu_enc->base;\n\tu32 event;\n\n\tif (!drm_enc->dev) {\n\t\tDPU_ERROR(\"invalid parameters\\n\");\n\t\treturn;\n\t}\n\n\tif (!dpu_enc->frame_busy_mask[0] || !dpu_enc->crtc_frame_event_cb) {\n\t\tDRM_DEBUG_KMS(\"id:%u invalid timeout frame_busy_mask=%lu\\n\",\n\t\t\t      DRMID(drm_enc), dpu_enc->frame_busy_mask[0]);\n\t\treturn;\n\t} else if (!atomic_xchg(&dpu_enc->frame_done_timeout_ms, 0)) {\n\t\tDRM_DEBUG_KMS(\"id:%u invalid timeout\\n\", DRMID(drm_enc));\n\t\treturn;\n\t}\n\n\tDPU_ERROR_ENC(dpu_enc, \"frame done timeout\\n\");\n\n\tevent = DPU_ENCODER_FRAME_EVENT_ERROR;\n\ttrace_dpu_enc_frame_done_timeout(DRMID(drm_enc), event);\n\tdpu_enc->crtc_frame_event_cb(dpu_enc->crtc_frame_event_cb_data, event);\n}\n\nstatic const struct drm_encoder_helper_funcs dpu_encoder_helper_funcs = {\n\t.atomic_mode_set = dpu_encoder_virt_atomic_mode_set,\n\t.atomic_disable = dpu_encoder_virt_atomic_disable,\n\t.atomic_enable = dpu_encoder_virt_atomic_enable,\n\t.atomic_check = dpu_encoder_virt_atomic_check,\n};\n\nstatic const struct drm_encoder_funcs dpu_encoder_funcs = {\n\t\t.destroy = dpu_encoder_destroy,\n\t\t.late_register = dpu_encoder_late_register,\n\t\t.early_unregister = dpu_encoder_early_unregister,\n};\n\nstruct drm_encoder *dpu_encoder_init(struct drm_device *dev,\n\t\tint drm_enc_mode,\n\t\tstruct msm_display_info *disp_info)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(priv->kms);\n\tstruct drm_encoder *drm_enc = NULL;\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\tint ret = 0;\n\n\tdpu_enc = devm_kzalloc(dev->dev, sizeof(*dpu_enc), GFP_KERNEL);\n\tif (!dpu_enc)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = drm_encoder_init(dev, &dpu_enc->base, &dpu_encoder_funcs,\n\t\t\t       drm_enc_mode, NULL);\n\tif (ret) {\n\t\tdevm_kfree(dev->dev, dpu_enc);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tdrm_encoder_helper_add(&dpu_enc->base, &dpu_encoder_helper_funcs);\n\n\tspin_lock_init(&dpu_enc->enc_spinlock);\n\tdpu_enc->enabled = false;\n\tmutex_init(&dpu_enc->enc_lock);\n\tmutex_init(&dpu_enc->rc_lock);\n\n\tret = dpu_encoder_setup_display(dpu_enc, dpu_kms, disp_info);\n\tif (ret)\n\t\tgoto fail;\n\n\tatomic_set(&dpu_enc->frame_done_timeout_ms, 0);\n\ttimer_setup(&dpu_enc->frame_done_timer,\n\t\t\tdpu_encoder_frame_done_timeout, 0);\n\n\tif (disp_info->intf_type == INTF_DP)\n\t\tdpu_enc->wide_bus_en = msm_dp_wide_bus_available(\n\t\t\t\tpriv->dp[disp_info->h_tile_instance[0]]);\n\n\tINIT_DELAYED_WORK(&dpu_enc->delayed_off_work,\n\t\t\tdpu_encoder_off_work);\n\tdpu_enc->idle_timeout = IDLE_TIMEOUT;\n\n\tmemcpy(&dpu_enc->disp_info, disp_info, sizeof(*disp_info));\n\n\tDPU_DEBUG_ENC(dpu_enc, \"created\\n\");\n\n\treturn &dpu_enc->base;\n\nfail:\n\tDPU_ERROR(\"failed to create encoder\\n\");\n\tif (drm_enc)\n\t\tdpu_encoder_destroy(drm_enc);\n\n\treturn ERR_PTR(ret);\n}\n\nint dpu_encoder_wait_for_event(struct drm_encoder *drm_enc,\n\tenum msm_event_wait event)\n{\n\tint (*fn_wait)(struct dpu_encoder_phys *phys_enc) = NULL;\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\tint i, ret = 0;\n\n\tif (!drm_enc) {\n\t\tDPU_ERROR(\"invalid encoder\\n\");\n\t\treturn -EINVAL;\n\t}\n\tdpu_enc = to_dpu_encoder_virt(drm_enc);\n\tDPU_DEBUG_ENC(dpu_enc, \"\\n\");\n\n\tfor (i = 0; i < dpu_enc->num_phys_encs; i++) {\n\t\tstruct dpu_encoder_phys *phys = dpu_enc->phys_encs[i];\n\n\t\tswitch (event) {\n\t\tcase MSM_ENC_COMMIT_DONE:\n\t\t\tfn_wait = phys->ops.wait_for_commit_done;\n\t\t\tbreak;\n\t\tcase MSM_ENC_TX_COMPLETE:\n\t\t\tfn_wait = phys->ops.wait_for_tx_complete;\n\t\t\tbreak;\n\t\tcase MSM_ENC_VBLANK:\n\t\t\tfn_wait = phys->ops.wait_for_vblank;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDPU_ERROR_ENC(dpu_enc, \"unknown wait event %d\\n\",\n\t\t\t\t\tevent);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (fn_wait) {\n\t\t\tDPU_ATRACE_BEGIN(\"wait_for_completion_event\");\n\t\t\tret = fn_wait(phys);\n\t\t\tDPU_ATRACE_END(\"wait_for_completion_event\");\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nenum dpu_intf_mode dpu_encoder_get_intf_mode(struct drm_encoder *encoder)\n{\n\tstruct dpu_encoder_virt *dpu_enc = NULL;\n\n\tif (!encoder) {\n\t\tDPU_ERROR(\"invalid encoder\\n\");\n\t\treturn INTF_MODE_NONE;\n\t}\n\tdpu_enc = to_dpu_encoder_virt(encoder);\n\n\tif (dpu_enc->cur_master)\n\t\treturn dpu_enc->cur_master->intf_mode;\n\n\tif (dpu_enc->num_phys_encs)\n\t\treturn dpu_enc->phys_encs[0]->intf_mode;\n\n\treturn INTF_MODE_NONE;\n}\n\nunsigned int dpu_encoder_helper_get_dsc(struct dpu_encoder_phys *phys_enc)\n{\n\tstruct drm_encoder *encoder = phys_enc->parent;\n\tstruct dpu_encoder_virt *dpu_enc = to_dpu_encoder_virt(encoder);\n\n\treturn dpu_enc->dsc_mask;\n}\n\nvoid dpu_encoder_phys_init(struct dpu_encoder_phys *phys_enc,\n\t\t\t  struct dpu_enc_phys_init_params *p)\n{\n\tint i;\n\n\tphys_enc->hw_mdptop = p->dpu_kms->hw_mdp;\n\tphys_enc->hw_intf = p->hw_intf;\n\tphys_enc->hw_wb = p->hw_wb;\n\tphys_enc->parent = p->parent;\n\tphys_enc->dpu_kms = p->dpu_kms;\n\tphys_enc->split_role = p->split_role;\n\tphys_enc->enc_spinlock = p->enc_spinlock;\n\tphys_enc->enable_state = DPU_ENC_DISABLED;\n\n\tfor (i = 0; i < ARRAY_SIZE(phys_enc->irq); i++)\n\t\tphys_enc->irq[i] = -EINVAL;\n\n\tatomic_set(&phys_enc->vblank_refcount, 0);\n\tatomic_set(&phys_enc->pending_kickoff_cnt, 0);\n\tatomic_set(&phys_enc->pending_ctlstart_cnt, 0);\n\n\tatomic_set(&phys_enc->vsync_cnt, 0);\n\tatomic_set(&phys_enc->underrun_cnt, 0);\n\n\tinit_waitqueue_head(&phys_enc->pending_kickoff_wq);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}