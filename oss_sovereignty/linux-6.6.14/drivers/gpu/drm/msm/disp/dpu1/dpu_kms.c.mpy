{
  "module_name": "dpu_kms.c",
  "hash_id": "71666c60588543e5c40b5047efd1edcf032fb97db1f2947f7677bcf2bf889054",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/msm/disp/dpu1/dpu_kms.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)\t\"[drm:%s:%d] \" fmt, __func__, __LINE__\n\n#include <linux/debugfs.h>\n#include <linux/dma-buf.h>\n#include <linux/of_irq.h>\n#include <linux/pm_opp.h>\n\n#include <drm/drm_crtc.h>\n#include <drm/drm_file.h>\n#include <drm/drm_framebuffer.h>\n#include <drm/drm_vblank.h>\n#include <drm/drm_writeback.h>\n\n#include \"msm_drv.h\"\n#include \"msm_mmu.h\"\n#include \"msm_mdss.h\"\n#include \"msm_gem.h\"\n#include \"disp/msm_disp_snapshot.h\"\n\n#include \"dpu_core_irq.h\"\n#include \"dpu_crtc.h\"\n#include \"dpu_encoder.h\"\n#include \"dpu_formats.h\"\n#include \"dpu_hw_vbif.h\"\n#include \"dpu_kms.h\"\n#include \"dpu_plane.h\"\n#include \"dpu_vbif.h\"\n#include \"dpu_writeback.h\"\n\n#define CREATE_TRACE_POINTS\n#include \"dpu_trace.h\"\n\n \n#define DPU_DEBUGFS_DIR \"msm_dpu\"\n#define DPU_DEBUGFS_HWMASKNAME \"hw_log_mask\"\n\nstatic int dpu_kms_hw_init(struct msm_kms *kms);\nstatic void _dpu_kms_mmu_destroy(struct dpu_kms *dpu_kms);\n\n#ifdef CONFIG_DEBUG_FS\nstatic int _dpu_danger_signal_status(struct seq_file *s,\n\t\tbool danger_status)\n{\n\tstruct dpu_danger_safe_status status;\n\tstruct dpu_kms *kms = s->private;\n\tint i;\n\n\tif (!kms->hw_mdp) {\n\t\tDPU_ERROR(\"invalid arg(s)\\n\");\n\t\treturn 0;\n\t}\n\n\tmemset(&status, 0, sizeof(struct dpu_danger_safe_status));\n\n\tpm_runtime_get_sync(&kms->pdev->dev);\n\tif (danger_status) {\n\t\tseq_puts(s, \"\\nDanger signal status:\\n\");\n\t\tif (kms->hw_mdp->ops.get_danger_status)\n\t\t\tkms->hw_mdp->ops.get_danger_status(kms->hw_mdp,\n\t\t\t\t\t&status);\n\t} else {\n\t\tseq_puts(s, \"\\nSafe signal status:\\n\");\n\t\tif (kms->hw_mdp->ops.get_safe_status)\n\t\t\tkms->hw_mdp->ops.get_safe_status(kms->hw_mdp,\n\t\t\t\t\t&status);\n\t}\n\tpm_runtime_put_sync(&kms->pdev->dev);\n\n\tseq_printf(s, \"MDP     :  0x%x\\n\", status.mdp);\n\n\tfor (i = SSPP_VIG0; i < SSPP_MAX; i++)\n\t\tseq_printf(s, \"SSPP%d   :  0x%x  \\n\", i - SSPP_VIG0,\n\t\t\t\tstatus.sspp[i]);\n\tseq_puts(s, \"\\n\");\n\n\treturn 0;\n}\n\nstatic int dpu_debugfs_danger_stats_show(struct seq_file *s, void *v)\n{\n\treturn _dpu_danger_signal_status(s, true);\n}\nDEFINE_SHOW_ATTRIBUTE(dpu_debugfs_danger_stats);\n\nstatic int dpu_debugfs_safe_stats_show(struct seq_file *s, void *v)\n{\n\treturn _dpu_danger_signal_status(s, false);\n}\nDEFINE_SHOW_ATTRIBUTE(dpu_debugfs_safe_stats);\n\nstatic ssize_t _dpu_plane_danger_read(struct file *file,\n\t\t\tchar __user *buff, size_t count, loff_t *ppos)\n{\n\tstruct dpu_kms *kms = file->private_data;\n\tint len;\n\tchar buf[40];\n\n\tlen = scnprintf(buf, sizeof(buf), \"%d\\n\", !kms->has_danger_ctrl);\n\n\treturn simple_read_from_buffer(buff, count, ppos, buf, len);\n}\n\nstatic void _dpu_plane_set_danger_state(struct dpu_kms *kms, bool enable)\n{\n\tstruct drm_plane *plane;\n\n\tdrm_for_each_plane(plane, kms->dev) {\n\t\tif (plane->fb && plane->state) {\n\t\t\tdpu_plane_danger_signal_ctrl(plane, enable);\n\t\t\tDPU_DEBUG(\"plane:%d img:%dx%d \",\n\t\t\t\tplane->base.id, plane->fb->width,\n\t\t\t\tplane->fb->height);\n\t\t\tDPU_DEBUG(\"src[%d,%d,%d,%d] dst[%d,%d,%d,%d]\\n\",\n\t\t\t\tplane->state->src_x >> 16,\n\t\t\t\tplane->state->src_y >> 16,\n\t\t\t\tplane->state->src_w >> 16,\n\t\t\t\tplane->state->src_h >> 16,\n\t\t\t\tplane->state->crtc_x, plane->state->crtc_y,\n\t\t\t\tplane->state->crtc_w, plane->state->crtc_h);\n\t\t} else {\n\t\t\tDPU_DEBUG(\"Inactive plane:%d\\n\", plane->base.id);\n\t\t}\n\t}\n}\n\nstatic ssize_t _dpu_plane_danger_write(struct file *file,\n\t\t    const char __user *user_buf, size_t count, loff_t *ppos)\n{\n\tstruct dpu_kms *kms = file->private_data;\n\tint disable_panic;\n\tint ret;\n\n\tret = kstrtouint_from_user(user_buf, count, 0, &disable_panic);\n\tif (ret)\n\t\treturn ret;\n\n\tif (disable_panic) {\n\t\t \n\t\tDPU_DEBUG(\"Disabling danger:\\n\");\n\t\t_dpu_plane_set_danger_state(kms, false);\n\t\tkms->has_danger_ctrl = false;\n\t} else {\n\t\t \n\t\tDPU_DEBUG(\"Enabling danger:\\n\");\n\t\tkms->has_danger_ctrl = true;\n\t\t_dpu_plane_set_danger_state(kms, true);\n\t}\n\n\treturn count;\n}\n\nstatic const struct file_operations dpu_plane_danger_enable = {\n\t.open = simple_open,\n\t.read = _dpu_plane_danger_read,\n\t.write = _dpu_plane_danger_write,\n};\n\nstatic void dpu_debugfs_danger_init(struct dpu_kms *dpu_kms,\n\t\tstruct dentry *parent)\n{\n\tstruct dentry *entry = debugfs_create_dir(\"danger\", parent);\n\n\tdebugfs_create_file(\"danger_status\", 0600, entry,\n\t\t\tdpu_kms, &dpu_debugfs_danger_stats_fops);\n\tdebugfs_create_file(\"safe_status\", 0600, entry,\n\t\t\tdpu_kms, &dpu_debugfs_safe_stats_fops);\n\tdebugfs_create_file(\"disable_danger\", 0600, entry,\n\t\t\tdpu_kms, &dpu_plane_danger_enable);\n\n}\n\n \nstruct dpu_debugfs_regset32 {\n\tuint32_t offset;\n\tuint32_t blk_len;\n\tstruct dpu_kms *dpu_kms;\n};\n\nstatic int dpu_regset32_show(struct seq_file *s, void *data)\n{\n\tstruct dpu_debugfs_regset32 *regset = s->private;\n\tstruct dpu_kms *dpu_kms = regset->dpu_kms;\n\tvoid __iomem *base;\n\tuint32_t i, addr;\n\n\tif (!dpu_kms->mmio)\n\t\treturn 0;\n\n\tbase = dpu_kms->mmio + regset->offset;\n\n\t \n\tif (regset->offset & 0xF) {\n\t\tseq_printf(s, \"[%x]\", regset->offset & ~0xF);\n\t\tfor (i = 0; i < (regset->offset & 0xF); i += 4)\n\t\t\tseq_puts(s, \"         \");\n\t}\n\n\tpm_runtime_get_sync(&dpu_kms->pdev->dev);\n\n\t \n\tfor (i = 0; i < regset->blk_len; i += 4) {\n\t\taddr = regset->offset + i;\n\t\tif ((addr & 0xF) == 0x0)\n\t\t\tseq_printf(s, i ? \"\\n[%x]\" : \"[%x]\", addr);\n\t\tseq_printf(s, \" %08x\", readl_relaxed(base + i));\n\t}\n\tseq_puts(s, \"\\n\");\n\tpm_runtime_put_sync(&dpu_kms->pdev->dev);\n\n\treturn 0;\n}\nDEFINE_SHOW_ATTRIBUTE(dpu_regset32);\n\nvoid dpu_debugfs_create_regset32(const char *name, umode_t mode,\n\t\tvoid *parent,\n\t\tuint32_t offset, uint32_t length, struct dpu_kms *dpu_kms)\n{\n\tstruct dpu_debugfs_regset32 *regset;\n\n\tif (WARN_ON(!name || !dpu_kms || !length))\n\t\treturn;\n\n\tregset = devm_kzalloc(&dpu_kms->pdev->dev, sizeof(*regset), GFP_KERNEL);\n\tif (!regset)\n\t\treturn;\n\n\t \n\tregset->offset = round_down(offset, 4);\n\tregset->blk_len = length;\n\tregset->dpu_kms = dpu_kms;\n\n\tdebugfs_create_file(name, mode, parent, regset, &dpu_regset32_fops);\n}\n\nstatic void dpu_debugfs_sspp_init(struct dpu_kms *dpu_kms, struct dentry *debugfs_root)\n{\n\tstruct dentry *entry = debugfs_create_dir(\"sspp\", debugfs_root);\n\tint i;\n\n\tif (IS_ERR(entry))\n\t\treturn;\n\n\tfor (i = SSPP_NONE; i < SSPP_MAX; i++) {\n\t\tstruct dpu_hw_sspp *hw = dpu_rm_get_sspp(&dpu_kms->rm, i);\n\n\t\tif (!hw)\n\t\t\tcontinue;\n\n\t\t_dpu_hw_sspp_init_debugfs(hw, dpu_kms, entry);\n\t}\n}\n\nstatic int dpu_kms_debugfs_init(struct msm_kms *kms, struct drm_minor *minor)\n{\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(kms);\n\tvoid *p = dpu_hw_util_get_log_mask_ptr();\n\tstruct dentry *entry;\n\tstruct drm_device *dev;\n\tstruct msm_drm_private *priv;\n\tint i;\n\n\tif (!p)\n\t\treturn -EINVAL;\n\n\t \n\tif (minor->type != DRM_MINOR_PRIMARY)\n\t\treturn 0;\n\n\tdev = dpu_kms->dev;\n\tpriv = dev->dev_private;\n\n\tentry = debugfs_create_dir(\"debug\", minor->debugfs_root);\n\n\tdebugfs_create_x32(DPU_DEBUGFS_HWMASKNAME, 0600, entry, p);\n\n\tdpu_debugfs_danger_init(dpu_kms, entry);\n\tdpu_debugfs_vbif_init(dpu_kms, entry);\n\tdpu_debugfs_core_irq_init(dpu_kms, entry);\n\tdpu_debugfs_sspp_init(dpu_kms, entry);\n\n\tfor (i = 0; i < ARRAY_SIZE(priv->dp); i++) {\n\t\tif (priv->dp[i])\n\t\t\tmsm_dp_debugfs_init(priv->dp[i], minor);\n\t}\n\n\treturn dpu_core_perf_debugfs_init(dpu_kms, entry);\n}\n#endif\n\n \n\n \nstruct dpu_global_state *\ndpu_kms_get_existing_global_state(struct dpu_kms *dpu_kms)\n{\n\treturn to_dpu_global_state(dpu_kms->global_state.state);\n}\n\n \nstruct dpu_global_state *dpu_kms_get_global_state(struct drm_atomic_state *s)\n{\n\tstruct msm_drm_private *priv = s->dev->dev_private;\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(priv->kms);\n\tstruct drm_private_state *priv_state;\n\tint ret;\n\n\tret = drm_modeset_lock(&dpu_kms->global_state_lock, s->acquire_ctx);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tpriv_state = drm_atomic_get_private_obj_state(s,\n\t\t\t\t\t\t&dpu_kms->global_state);\n\tif (IS_ERR(priv_state))\n\t\treturn ERR_CAST(priv_state);\n\n\treturn to_dpu_global_state(priv_state);\n}\n\nstatic struct drm_private_state *\ndpu_kms_global_duplicate_state(struct drm_private_obj *obj)\n{\n\tstruct dpu_global_state *state;\n\n\tstate = kmemdup(obj->state, sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn NULL;\n\n\t__drm_atomic_helper_private_obj_duplicate_state(obj, &state->base);\n\n\treturn &state->base;\n}\n\nstatic void dpu_kms_global_destroy_state(struct drm_private_obj *obj,\n\t\t\t\t      struct drm_private_state *state)\n{\n\tstruct dpu_global_state *dpu_state = to_dpu_global_state(state);\n\n\tkfree(dpu_state);\n}\n\nstatic const struct drm_private_state_funcs dpu_kms_global_state_funcs = {\n\t.atomic_duplicate_state = dpu_kms_global_duplicate_state,\n\t.atomic_destroy_state = dpu_kms_global_destroy_state,\n};\n\nstatic int dpu_kms_global_obj_init(struct dpu_kms *dpu_kms)\n{\n\tstruct dpu_global_state *state;\n\n\tdrm_modeset_lock_init(&dpu_kms->global_state_lock);\n\n\tstate = kzalloc(sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn -ENOMEM;\n\n\tdrm_atomic_private_obj_init(dpu_kms->dev, &dpu_kms->global_state,\n\t\t\t\t    &state->base,\n\t\t\t\t    &dpu_kms_global_state_funcs);\n\treturn 0;\n}\n\nstatic int dpu_kms_parse_data_bus_icc_path(struct dpu_kms *dpu_kms)\n{\n\tstruct icc_path *path0;\n\tstruct icc_path *path1;\n\tstruct drm_device *dev = dpu_kms->dev;\n\tstruct device *dpu_dev = dev->dev;\n\n\tpath0 = msm_icc_get(dpu_dev, \"mdp0-mem\");\n\tpath1 = msm_icc_get(dpu_dev, \"mdp1-mem\");\n\n\tif (IS_ERR_OR_NULL(path0))\n\t\treturn PTR_ERR_OR_ZERO(path0);\n\n\tdpu_kms->path[0] = path0;\n\tdpu_kms->num_paths = 1;\n\n\tif (!IS_ERR_OR_NULL(path1)) {\n\t\tdpu_kms->path[1] = path1;\n\t\tdpu_kms->num_paths++;\n\t}\n\treturn 0;\n}\n\nstatic int dpu_kms_enable_vblank(struct msm_kms *kms, struct drm_crtc *crtc)\n{\n\treturn dpu_crtc_vblank(crtc, true);\n}\n\nstatic void dpu_kms_disable_vblank(struct msm_kms *kms, struct drm_crtc *crtc)\n{\n\tdpu_crtc_vblank(crtc, false);\n}\n\nstatic void dpu_kms_enable_commit(struct msm_kms *kms)\n{\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(kms);\n\tpm_runtime_get_sync(&dpu_kms->pdev->dev);\n}\n\nstatic void dpu_kms_disable_commit(struct msm_kms *kms)\n{\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(kms);\n\tpm_runtime_put_sync(&dpu_kms->pdev->dev);\n}\n\nstatic void dpu_kms_flush_commit(struct msm_kms *kms, unsigned crtc_mask)\n{\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(kms);\n\tstruct drm_crtc *crtc;\n\n\tfor_each_crtc_mask(dpu_kms->dev, crtc, crtc_mask) {\n\t\tif (!crtc->state->active)\n\t\t\tcontinue;\n\n\t\ttrace_dpu_kms_commit(DRMID(crtc));\n\t\tdpu_crtc_commit_kickoff(crtc);\n\t}\n}\n\nstatic void dpu_kms_complete_commit(struct msm_kms *kms, unsigned crtc_mask)\n{\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(kms);\n\tstruct drm_crtc *crtc;\n\n\tDPU_ATRACE_BEGIN(\"kms_complete_commit\");\n\n\tfor_each_crtc_mask(dpu_kms->dev, crtc, crtc_mask)\n\t\tdpu_crtc_complete_commit(crtc);\n\n\tDPU_ATRACE_END(\"kms_complete_commit\");\n}\n\nstatic void dpu_kms_wait_for_commit_done(struct msm_kms *kms,\n\t\tstruct drm_crtc *crtc)\n{\n\tstruct drm_encoder *encoder;\n\tstruct drm_device *dev;\n\tint ret;\n\n\tif (!kms || !crtc || !crtc->state) {\n\t\tDPU_ERROR(\"invalid params\\n\");\n\t\treturn;\n\t}\n\n\tdev = crtc->dev;\n\n\tif (!crtc->state->enable) {\n\t\tDPU_DEBUG(\"[crtc:%d] not enable\\n\", crtc->base.id);\n\t\treturn;\n\t}\n\n\tif (!drm_atomic_crtc_effectively_active(crtc->state)) {\n\t\tDPU_DEBUG(\"[crtc:%d] not active\\n\", crtc->base.id);\n\t\treturn;\n\t}\n\n\tlist_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {\n\t\tif (encoder->crtc != crtc)\n\t\t\tcontinue;\n\t\t \n\t\ttrace_dpu_kms_wait_for_commit_done(DRMID(crtc));\n\t\tret = dpu_encoder_wait_for_event(encoder, MSM_ENC_COMMIT_DONE);\n\t\tif (ret && ret != -EWOULDBLOCK) {\n\t\t\tDPU_ERROR(\"wait for commit done returned %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void dpu_kms_wait_flush(struct msm_kms *kms, unsigned crtc_mask)\n{\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(kms);\n\tstruct drm_crtc *crtc;\n\n\tfor_each_crtc_mask(dpu_kms->dev, crtc, crtc_mask)\n\t\tdpu_kms_wait_for_commit_done(kms, crtc);\n}\n\nstatic int _dpu_kms_initialize_dsi(struct drm_device *dev,\n\t\t\t\t    struct msm_drm_private *priv,\n\t\t\t\t    struct dpu_kms *dpu_kms)\n{\n\tstruct drm_encoder *encoder = NULL;\n\tstruct msm_display_info info;\n\tint i, rc = 0;\n\n\tif (!(priv->dsi[0] || priv->dsi[1]))\n\t\treturn rc;\n\n\t \n\tfor (i = 0; i < ARRAY_SIZE(priv->dsi); i++) {\n\t\tint other = (i + 1) % 2;\n\n\t\tif (!priv->dsi[i])\n\t\t\tcontinue;\n\n\t\tif (msm_dsi_is_bonded_dsi(priv->dsi[i]) &&\n\t\t    !msm_dsi_is_master_dsi(priv->dsi[i]))\n\t\t\tcontinue;\n\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.intf_type = INTF_DSI;\n\n\t\tinfo.h_tile_instance[info.num_of_h_tiles++] = i;\n\t\tif (msm_dsi_is_bonded_dsi(priv->dsi[i]))\n\t\t\tinfo.h_tile_instance[info.num_of_h_tiles++] = other;\n\n\t\tinfo.is_cmd_mode = msm_dsi_is_cmd_mode(priv->dsi[i]);\n\n\t\tencoder = dpu_encoder_init(dev, DRM_MODE_ENCODER_DSI, &info);\n\t\tif (IS_ERR(encoder)) {\n\t\t\tDPU_ERROR(\"encoder init failed for dsi display\\n\");\n\t\t\treturn PTR_ERR(encoder);\n\t\t}\n\n\t\trc = msm_dsi_modeset_init(priv->dsi[i], dev, encoder);\n\t\tif (rc) {\n\t\t\tDPU_ERROR(\"modeset_init failed for dsi[%d], rc = %d\\n\",\n\t\t\t\ti, rc);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (msm_dsi_is_bonded_dsi(priv->dsi[i]) && priv->dsi[other]) {\n\t\t\trc = msm_dsi_modeset_init(priv->dsi[other], dev, encoder);\n\t\t\tif (rc) {\n\t\t\t\tDPU_ERROR(\"modeset_init failed for dsi[%d], rc = %d\\n\",\n\t\t\t\t\tother, rc);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn rc;\n}\n\nstatic int _dpu_kms_initialize_displayport(struct drm_device *dev,\n\t\t\t\t\t    struct msm_drm_private *priv,\n\t\t\t\t\t    struct dpu_kms *dpu_kms)\n{\n\tstruct drm_encoder *encoder = NULL;\n\tstruct msm_display_info info;\n\tint rc;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(priv->dp); i++) {\n\t\tif (!priv->dp[i])\n\t\t\tcontinue;\n\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.num_of_h_tiles = 1;\n\t\tinfo.h_tile_instance[0] = i;\n\t\tinfo.intf_type = INTF_DP;\n\n\t\tencoder = dpu_encoder_init(dev, DRM_MODE_ENCODER_TMDS, &info);\n\t\tif (IS_ERR(encoder)) {\n\t\t\tDPU_ERROR(\"encoder init failed for dsi display\\n\");\n\t\t\treturn PTR_ERR(encoder);\n\t\t}\n\n\t\trc = msm_dp_modeset_init(priv->dp[i], dev, encoder);\n\t\tif (rc) {\n\t\t\tDPU_ERROR(\"modeset_init failed for DP, rc = %d\\n\", rc);\n\t\t\tdrm_encoder_cleanup(encoder);\n\t\t\treturn rc;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int _dpu_kms_initialize_hdmi(struct drm_device *dev,\n\t\t\t\t    struct msm_drm_private *priv,\n\t\t\t\t    struct dpu_kms *dpu_kms)\n{\n\tstruct drm_encoder *encoder = NULL;\n\tstruct msm_display_info info;\n\tint rc;\n\n\tif (!priv->hdmi)\n\t\treturn 0;\n\n\tmemset(&info, 0, sizeof(info));\n\tinfo.num_of_h_tiles = 1;\n\tinfo.h_tile_instance[0] = 0;\n\tinfo.intf_type = INTF_HDMI;\n\n\tencoder = dpu_encoder_init(dev, DRM_MODE_ENCODER_TMDS, &info);\n\tif (IS_ERR(encoder)) {\n\t\tDPU_ERROR(\"encoder init failed for HDMI display\\n\");\n\t\treturn PTR_ERR(encoder);\n\t}\n\n\trc = msm_hdmi_modeset_init(priv->hdmi, dev, encoder);\n\tif (rc) {\n\t\tDPU_ERROR(\"modeset_init failed for DP, rc = %d\\n\", rc);\n\t\tdrm_encoder_cleanup(encoder);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int _dpu_kms_initialize_writeback(struct drm_device *dev,\n\t\tstruct msm_drm_private *priv, struct dpu_kms *dpu_kms,\n\t\tconst u32 *wb_formats, int n_formats)\n{\n\tstruct drm_encoder *encoder = NULL;\n\tstruct msm_display_info info;\n\tint rc;\n\n\tmemset(&info, 0, sizeof(info));\n\n\tinfo.num_of_h_tiles = 1;\n\t \n\tinfo.h_tile_instance[0] = WB_2;\n\tinfo.intf_type = INTF_WB;\n\n\tencoder = dpu_encoder_init(dev, DRM_MODE_ENCODER_VIRTUAL, &info);\n\tif (IS_ERR(encoder)) {\n\t\tDPU_ERROR(\"encoder init failed for dsi display\\n\");\n\t\treturn PTR_ERR(encoder);\n\t}\n\n\trc = dpu_writeback_init(dev, encoder, wb_formats,\n\t\t\tn_formats);\n\tif (rc) {\n\t\tDPU_ERROR(\"dpu_writeback_init, rc = %d\\n\", rc);\n\t\tdrm_encoder_cleanup(encoder);\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int _dpu_kms_setup_displays(struct drm_device *dev,\n\t\t\t\t    struct msm_drm_private *priv,\n\t\t\t\t    struct dpu_kms *dpu_kms)\n{\n\tint rc = 0;\n\tint i;\n\n\trc = _dpu_kms_initialize_dsi(dev, priv, dpu_kms);\n\tif (rc) {\n\t\tDPU_ERROR(\"initialize_dsi failed, rc = %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\trc = _dpu_kms_initialize_displayport(dev, priv, dpu_kms);\n\tif (rc) {\n\t\tDPU_ERROR(\"initialize_DP failed, rc = %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\trc = _dpu_kms_initialize_hdmi(dev, priv, dpu_kms);\n\tif (rc) {\n\t\tDPU_ERROR(\"initialize HDMI failed, rc = %d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\tif (dpu_kms->catalog->wb_count) {\n\t\tfor (i = 0; i < dpu_kms->catalog->wb_count; i++) {\n\t\t\tif (dpu_kms->catalog->wb[i].id == WB_2) {\n\t\t\t\trc = _dpu_kms_initialize_writeback(dev, priv, dpu_kms,\n\t\t\t\t\t\tdpu_kms->catalog->wb[i].format_list,\n\t\t\t\t\t\tdpu_kms->catalog->wb[i].num_formats);\n\t\t\t\tif (rc) {\n\t\t\t\t\tDPU_ERROR(\"initialize_WB failed, rc = %d\\n\", rc);\n\t\t\t\t\treturn rc;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn rc;\n}\n\n#define MAX_PLANES 20\nstatic int _dpu_kms_drm_obj_init(struct dpu_kms *dpu_kms)\n{\n\tstruct drm_device *dev;\n\tstruct drm_plane *primary_planes[MAX_PLANES], *plane;\n\tstruct drm_plane *cursor_planes[MAX_PLANES] = { NULL };\n\tstruct drm_crtc *crtc;\n\tstruct drm_encoder *encoder;\n\tunsigned int num_encoders;\n\n\tstruct msm_drm_private *priv;\n\tconst struct dpu_mdss_cfg *catalog;\n\n\tint primary_planes_idx = 0, cursor_planes_idx = 0, i, ret;\n\tint max_crtc_count;\n\tdev = dpu_kms->dev;\n\tpriv = dev->dev_private;\n\tcatalog = dpu_kms->catalog;\n\n\t \n\tret = _dpu_kms_setup_displays(dev, priv, dpu_kms);\n\tif (ret)\n\t\treturn ret;\n\n\tnum_encoders = 0;\n\tdrm_for_each_encoder(encoder, dev)\n\t\tnum_encoders++;\n\n\tmax_crtc_count = min(catalog->mixer_count, num_encoders);\n\n\t \n\tfor (i = 0; i < catalog->sspp_count; i++) {\n\t\tenum drm_plane_type type;\n\n\t\tif ((catalog->sspp[i].features & BIT(DPU_SSPP_CURSOR))\n\t\t\t&& cursor_planes_idx < max_crtc_count)\n\t\t\ttype = DRM_PLANE_TYPE_CURSOR;\n\t\telse if (primary_planes_idx < max_crtc_count)\n\t\t\ttype = DRM_PLANE_TYPE_PRIMARY;\n\t\telse\n\t\t\ttype = DRM_PLANE_TYPE_OVERLAY;\n\n\t\tDPU_DEBUG(\"Create plane type %d with features %lx (cur %lx)\\n\",\n\t\t\t  type, catalog->sspp[i].features,\n\t\t\t  catalog->sspp[i].features & BIT(DPU_SSPP_CURSOR));\n\n\t\tplane = dpu_plane_init(dev, catalog->sspp[i].id, type,\n\t\t\t\t       (1UL << max_crtc_count) - 1);\n\t\tif (IS_ERR(plane)) {\n\t\t\tDPU_ERROR(\"dpu_plane_init failed\\n\");\n\t\t\tret = PTR_ERR(plane);\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (type == DRM_PLANE_TYPE_CURSOR)\n\t\t\tcursor_planes[cursor_planes_idx++] = plane;\n\t\telse if (type == DRM_PLANE_TYPE_PRIMARY)\n\t\t\tprimary_planes[primary_planes_idx++] = plane;\n\t}\n\n\tmax_crtc_count = min(max_crtc_count, primary_planes_idx);\n\n\t \n\tfor (i = 0; i < max_crtc_count; i++) {\n\t\tcrtc = dpu_crtc_init(dev, primary_planes[i], cursor_planes[i]);\n\t\tif (IS_ERR(crtc)) {\n\t\t\tret = PTR_ERR(crtc);\n\t\t\treturn ret;\n\t\t}\n\t\tpriv->num_crtcs++;\n\t}\n\n\t \n\tdrm_for_each_encoder(encoder, dev)\n\t\tencoder->possible_crtcs = (1 << priv->num_crtcs) - 1;\n\n\treturn 0;\n}\n\nstatic void _dpu_kms_hw_destroy(struct dpu_kms *dpu_kms)\n{\n\tint i;\n\n\tif (dpu_kms->hw_intr)\n\t\tdpu_hw_intr_destroy(dpu_kms->hw_intr);\n\tdpu_kms->hw_intr = NULL;\n\n\t \n\t_dpu_kms_mmu_destroy(dpu_kms);\n\n\tif (dpu_kms->catalog) {\n\t\tfor (i = 0; i < ARRAY_SIZE(dpu_kms->hw_vbif); i++) {\n\t\t\tif (dpu_kms->hw_vbif[i]) {\n\t\t\t\tdpu_hw_vbif_destroy(dpu_kms->hw_vbif[i]);\n\t\t\t\tdpu_kms->hw_vbif[i] = NULL;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dpu_kms->rm_init)\n\t\tdpu_rm_destroy(&dpu_kms->rm);\n\tdpu_kms->rm_init = false;\n\n\tdpu_kms->catalog = NULL;\n\n\tif (dpu_kms->vbif[VBIF_NRT])\n\t\tdevm_iounmap(&dpu_kms->pdev->dev, dpu_kms->vbif[VBIF_NRT]);\n\tdpu_kms->vbif[VBIF_NRT] = NULL;\n\n\tif (dpu_kms->vbif[VBIF_RT])\n\t\tdevm_iounmap(&dpu_kms->pdev->dev, dpu_kms->vbif[VBIF_RT]);\n\tdpu_kms->vbif[VBIF_RT] = NULL;\n\n\tif (dpu_kms->hw_mdp)\n\t\tdpu_hw_mdp_destroy(dpu_kms->hw_mdp);\n\tdpu_kms->hw_mdp = NULL;\n\n\tif (dpu_kms->mmio)\n\t\tdevm_iounmap(&dpu_kms->pdev->dev, dpu_kms->mmio);\n\tdpu_kms->mmio = NULL;\n}\n\nstatic void dpu_kms_destroy(struct msm_kms *kms)\n{\n\tstruct dpu_kms *dpu_kms;\n\n\tif (!kms) {\n\t\tDPU_ERROR(\"invalid kms\\n\");\n\t\treturn;\n\t}\n\n\tdpu_kms = to_dpu_kms(kms);\n\n\t_dpu_kms_hw_destroy(dpu_kms);\n\n\tmsm_kms_destroy(&dpu_kms->base);\n\n\tif (dpu_kms->rpm_enabled)\n\t\tpm_runtime_disable(&dpu_kms->pdev->dev);\n}\n\nstatic int dpu_irq_postinstall(struct msm_kms *kms)\n{\n\tstruct msm_drm_private *priv;\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(kms);\n\tint i;\n\n\tif (!dpu_kms || !dpu_kms->dev)\n\t\treturn -EINVAL;\n\n\tpriv = dpu_kms->dev->dev_private;\n\tif (!priv)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < ARRAY_SIZE(priv->dp); i++)\n\t\tmsm_dp_irq_postinstall(priv->dp[i]);\n\n\treturn 0;\n}\n\nstatic void dpu_kms_mdp_snapshot(struct msm_disp_state *disp_state, struct msm_kms *kms)\n{\n\tint i;\n\tstruct dpu_kms *dpu_kms;\n\tconst struct dpu_mdss_cfg *cat;\n\tvoid __iomem *base;\n\n\tdpu_kms = to_dpu_kms(kms);\n\n\tcat = dpu_kms->catalog;\n\n\tpm_runtime_get_sync(&dpu_kms->pdev->dev);\n\n\t \n\tfor (i = 0; i < cat->ctl_count; i++)\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->ctl[i].len,\n\t\t\t\tdpu_kms->mmio + cat->ctl[i].base, cat->ctl[i].name);\n\n\t \n\tfor (i = 0; i < cat->dspp_count; i++) {\n\t\tbase = dpu_kms->mmio + cat->dspp[i].base;\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->dspp[i].len, base, cat->dspp[i].name);\n\n\t\tif (cat->dspp[i].sblk && cat->dspp[i].sblk->pcc.len > 0)\n\t\t\tmsm_disp_snapshot_add_block(disp_state, cat->dspp[i].sblk->pcc.len,\n\t\t\t\t\t\t    base + cat->dspp[i].sblk->pcc.base, \"%s_%s\",\n\t\t\t\t\t\t    cat->dspp[i].name,\n\t\t\t\t\t\t    cat->dspp[i].sblk->pcc.name);\n\t}\n\n\t \n\tfor (i = 0; i < cat->intf_count; i++)\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->intf[i].len,\n\t\t\t\tdpu_kms->mmio + cat->intf[i].base, cat->intf[i].name);\n\n\t \n\tfor (i = 0; i < cat->pingpong_count; i++) {\n\t\tbase = dpu_kms->mmio + cat->pingpong[i].base;\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->pingpong[i].len, base,\n\t\t\t\t\t    cat->pingpong[i].name);\n\n\t\t \n\n\t\tif (cat->pingpong[i].sblk && cat->pingpong[i].sblk->dither.len > 0)\n\t\t\tmsm_disp_snapshot_add_block(disp_state, cat->pingpong[i].sblk->dither.len,\n\t\t\t\t\t\t    base + cat->pingpong[i].sblk->dither.base,\n\t\t\t\t\t\t    \"%s_%s\", cat->pingpong[i].name,\n\t\t\t\t\t\t    cat->pingpong[i].sblk->dither.name);\n\t}\n\n\t \n\tfor (i = 0; i < cat->sspp_count; i++) {\n\t\tbase = dpu_kms->mmio + cat->sspp[i].base;\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->sspp[i].len, base, cat->sspp[i].name);\n\n\t\tif (cat->sspp[i].sblk && cat->sspp[i].sblk->scaler_blk.len > 0)\n\t\t\tmsm_disp_snapshot_add_block(disp_state, cat->sspp[i].sblk->scaler_blk.len,\n\t\t\t\t\t\t    base + cat->sspp[i].sblk->scaler_blk.base,\n\t\t\t\t\t\t    \"%s_%s\", cat->sspp[i].name,\n\t\t\t\t\t\t    cat->sspp[i].sblk->scaler_blk.name);\n\n\t\tif (cat->sspp[i].sblk && cat->sspp[i].sblk->csc_blk.len > 0)\n\t\t\tmsm_disp_snapshot_add_block(disp_state, cat->sspp[i].sblk->csc_blk.len,\n\t\t\t\t\t\t    base + cat->sspp[i].sblk->csc_blk.base,\n\t\t\t\t\t\t    \"%s_%s\", cat->sspp[i].name,\n\t\t\t\t\t\t    cat->sspp[i].sblk->csc_blk.name);\n\t}\n\n\t \n\tfor (i = 0; i < cat->mixer_count; i++)\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->mixer[i].len,\n\t\t\t\tdpu_kms->mmio + cat->mixer[i].base, cat->mixer[i].name);\n\n\t \n\tfor (i = 0; i < cat->wb_count; i++)\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->wb[i].len,\n\t\t\t\tdpu_kms->mmio + cat->wb[i].base, cat->wb[i].name);\n\n\tif (cat->mdp[0].features & BIT(DPU_MDP_PERIPH_0_REMOVED)) {\n\t\tmsm_disp_snapshot_add_block(disp_state, MDP_PERIPH_TOP0,\n\t\t\t\tdpu_kms->mmio + cat->mdp[0].base, \"top\");\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->mdp[0].len - MDP_PERIPH_TOP0_END,\n\t\t\t\tdpu_kms->mmio + cat->mdp[0].base + MDP_PERIPH_TOP0_END, \"top_2\");\n\t} else {\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->mdp[0].len,\n\t\t\t\tdpu_kms->mmio + cat->mdp[0].base, \"top\");\n\t}\n\n\t \n\tfor (i = 0; i < cat->dsc_count; i++) {\n\t\tbase = dpu_kms->mmio + cat->dsc[i].base;\n\t\tmsm_disp_snapshot_add_block(disp_state, cat->dsc[i].len, base, cat->dsc[i].name);\n\n\t\tif (cat->dsc[i].features & BIT(DPU_DSC_HW_REV_1_2)) {\n\t\t\tstruct dpu_dsc_blk enc = cat->dsc[i].sblk->enc;\n\t\t\tstruct dpu_dsc_blk ctl = cat->dsc[i].sblk->ctl;\n\n\t\t\tmsm_disp_snapshot_add_block(disp_state, enc.len, base + enc.base, \"%s_%s\",\n\t\t\t\t\t\t    cat->dsc[i].name, enc.name);\n\t\t\tmsm_disp_snapshot_add_block(disp_state, ctl.len, base + ctl.base, \"%s_%s\",\n\t\t\t\t\t\t    cat->dsc[i].name, ctl.name);\n\t\t}\n\t}\n\n\tpm_runtime_put_sync(&dpu_kms->pdev->dev);\n}\n\nstatic const struct msm_kms_funcs kms_funcs = {\n\t.hw_init         = dpu_kms_hw_init,\n\t.irq_preinstall  = dpu_core_irq_preinstall,\n\t.irq_postinstall = dpu_irq_postinstall,\n\t.irq_uninstall   = dpu_core_irq_uninstall,\n\t.irq             = dpu_core_irq,\n\t.enable_commit   = dpu_kms_enable_commit,\n\t.disable_commit  = dpu_kms_disable_commit,\n\t.flush_commit    = dpu_kms_flush_commit,\n\t.wait_flush      = dpu_kms_wait_flush,\n\t.complete_commit = dpu_kms_complete_commit,\n\t.enable_vblank   = dpu_kms_enable_vblank,\n\t.disable_vblank  = dpu_kms_disable_vblank,\n\t.check_modified_format = dpu_format_check_modified_format,\n\t.get_format      = dpu_get_msm_format,\n\t.destroy         = dpu_kms_destroy,\n\t.snapshot        = dpu_kms_mdp_snapshot,\n#ifdef CONFIG_DEBUG_FS\n\t.debugfs_init    = dpu_kms_debugfs_init,\n#endif\n};\n\nstatic void _dpu_kms_mmu_destroy(struct dpu_kms *dpu_kms)\n{\n\tstruct msm_mmu *mmu;\n\n\tif (!dpu_kms->base.aspace)\n\t\treturn;\n\n\tmmu = dpu_kms->base.aspace->mmu;\n\n\tmmu->funcs->detach(mmu);\n\tmsm_gem_address_space_put(dpu_kms->base.aspace);\n\n\tdpu_kms->base.aspace = NULL;\n}\n\nstatic int _dpu_kms_mmu_init(struct dpu_kms *dpu_kms)\n{\n\tstruct msm_gem_address_space *aspace;\n\n\taspace = msm_kms_init_aspace(dpu_kms->dev);\n\tif (IS_ERR(aspace))\n\t\treturn PTR_ERR(aspace);\n\n\tdpu_kms->base.aspace = aspace;\n\n\treturn 0;\n}\n\nunsigned long dpu_kms_get_clk_rate(struct dpu_kms *dpu_kms, char *clock_name)\n{\n\tstruct clk *clk;\n\n\tclk = msm_clk_bulk_get_clock(dpu_kms->clocks, dpu_kms->num_clocks, clock_name);\n\tif (!clk)\n\t\treturn 0;\n\n\treturn clk_get_rate(clk);\n}\n\n#define\tDPU_PERF_DEFAULT_MAX_CORE_CLK_RATE\t412500000\n\nstatic int dpu_kms_hw_init(struct msm_kms *kms)\n{\n\tstruct dpu_kms *dpu_kms;\n\tstruct drm_device *dev;\n\tint i, rc = -EINVAL;\n\tunsigned long max_core_clk_rate;\n\tu32 core_rev;\n\n\tif (!kms) {\n\t\tDPU_ERROR(\"invalid kms\\n\");\n\t\treturn rc;\n\t}\n\n\tdpu_kms = to_dpu_kms(kms);\n\tdev = dpu_kms->dev;\n\n\tdev->mode_config.cursor_width = 512;\n\tdev->mode_config.cursor_height = 512;\n\n\trc = dpu_kms_global_obj_init(dpu_kms);\n\tif (rc)\n\t\treturn rc;\n\n\tatomic_set(&dpu_kms->bandwidth_ref, 0);\n\n\tdpu_kms->mmio = msm_ioremap(dpu_kms->pdev, \"mdp\");\n\tif (IS_ERR(dpu_kms->mmio)) {\n\t\trc = PTR_ERR(dpu_kms->mmio);\n\t\tDPU_ERROR(\"mdp register memory map failed: %d\\n\", rc);\n\t\tdpu_kms->mmio = NULL;\n\t\tgoto error;\n\t}\n\tDRM_DEBUG(\"mapped dpu address space @%pK\\n\", dpu_kms->mmio);\n\n\tdpu_kms->vbif[VBIF_RT] = msm_ioremap(dpu_kms->pdev, \"vbif\");\n\tif (IS_ERR(dpu_kms->vbif[VBIF_RT])) {\n\t\trc = PTR_ERR(dpu_kms->vbif[VBIF_RT]);\n\t\tDPU_ERROR(\"vbif register memory map failed: %d\\n\", rc);\n\t\tdpu_kms->vbif[VBIF_RT] = NULL;\n\t\tgoto error;\n\t}\n\tdpu_kms->vbif[VBIF_NRT] = msm_ioremap_quiet(dpu_kms->pdev, \"vbif_nrt\");\n\tif (IS_ERR(dpu_kms->vbif[VBIF_NRT])) {\n\t\tdpu_kms->vbif[VBIF_NRT] = NULL;\n\t\tDPU_DEBUG(\"VBIF NRT is not defined\");\n\t}\n\n\tdpu_kms_parse_data_bus_icc_path(dpu_kms);\n\n\trc = pm_runtime_resume_and_get(&dpu_kms->pdev->dev);\n\tif (rc < 0)\n\t\tgoto error;\n\n\tcore_rev = readl_relaxed(dpu_kms->mmio + 0x0);\n\n\tpr_info(\"dpu hardware revision:0x%x\\n\", core_rev);\n\n\tdpu_kms->catalog = of_device_get_match_data(dev->dev);\n\tif (!dpu_kms->catalog) {\n\t\tDPU_ERROR(\"device config not known!\\n\");\n\t\trc = -EINVAL;\n\t\tgoto power_error;\n\t}\n\n\t \n\trc = _dpu_kms_mmu_init(dpu_kms);\n\tif (rc) {\n\t\tDPU_ERROR(\"dpu_kms_mmu_init failed: %d\\n\", rc);\n\t\tgoto power_error;\n\t}\n\n\tdpu_kms->mdss = msm_mdss_get_mdss_data(dpu_kms->pdev->dev.parent);\n\tif (IS_ERR(dpu_kms->mdss)) {\n\t\trc = PTR_ERR(dpu_kms->mdss);\n\t\tDPU_ERROR(\"failed to get MDSS data: %d\\n\", rc);\n\t\tgoto power_error;\n\t}\n\n\tif (!dpu_kms->mdss) {\n\t\trc = -EINVAL;\n\t\tDPU_ERROR(\"NULL MDSS data\\n\");\n\t\tgoto power_error;\n\t}\n\n\trc = dpu_rm_init(&dpu_kms->rm, dpu_kms->catalog, dpu_kms->mdss, dpu_kms->mmio);\n\tif (rc) {\n\t\tDPU_ERROR(\"rm init failed: %d\\n\", rc);\n\t\tgoto power_error;\n\t}\n\n\tdpu_kms->rm_init = true;\n\n\tdpu_kms->hw_mdp = dpu_hw_mdptop_init(dpu_kms->catalog->mdp,\n\t\t\t\t\t     dpu_kms->mmio,\n\t\t\t\t\t     dpu_kms->catalog);\n\tif (IS_ERR(dpu_kms->hw_mdp)) {\n\t\trc = PTR_ERR(dpu_kms->hw_mdp);\n\t\tDPU_ERROR(\"failed to get hw_mdp: %d\\n\", rc);\n\t\tdpu_kms->hw_mdp = NULL;\n\t\tgoto power_error;\n\t}\n\n\tfor (i = 0; i < dpu_kms->catalog->vbif_count; i++) {\n\t\tstruct dpu_hw_vbif *hw;\n\t\tconst struct dpu_vbif_cfg *vbif = &dpu_kms->catalog->vbif[i];\n\n\t\thw = dpu_hw_vbif_init(vbif, dpu_kms->vbif[vbif->id]);\n\t\tif (IS_ERR(hw)) {\n\t\t\trc = PTR_ERR(hw);\n\t\t\tDPU_ERROR(\"failed to init vbif %d: %d\\n\", vbif->id, rc);\n\t\t\tgoto power_error;\n\t\t}\n\n\t\tdpu_kms->hw_vbif[vbif->id] = hw;\n\t}\n\n\t \n\tmax_core_clk_rate = dpu_kms_get_clk_rate(dpu_kms, \"core\");\n\tif (!max_core_clk_rate) {\n\t\tDPU_DEBUG(\"max core clk rate not determined, using default\\n\");\n\t\tmax_core_clk_rate = DPU_PERF_DEFAULT_MAX_CORE_CLK_RATE;\n\t}\n\n\trc = dpu_core_perf_init(&dpu_kms->perf, dpu_kms->catalog->perf, max_core_clk_rate);\n\tif (rc) {\n\t\tDPU_ERROR(\"failed to init perf %d\\n\", rc);\n\t\tgoto perf_err;\n\t}\n\n\tdpu_kms->hw_intr = dpu_hw_intr_init(dpu_kms->mmio, dpu_kms->catalog);\n\tif (IS_ERR_OR_NULL(dpu_kms->hw_intr)) {\n\t\trc = PTR_ERR(dpu_kms->hw_intr);\n\t\tDPU_ERROR(\"hw_intr init failed: %d\\n\", rc);\n\t\tdpu_kms->hw_intr = NULL;\n\t\tgoto hw_intr_init_err;\n\t}\n\n\tdev->mode_config.min_width = 0;\n\tdev->mode_config.min_height = 0;\n\n\t \n\tdev->mode_config.max_width =\n\t\t\tdpu_kms->catalog->caps->max_mixer_width * 2;\n\tdev->mode_config.max_height = 4096;\n\n\tdev->max_vblank_count = 0xffffffff;\n\t \n\tdev->vblank_disable_immediate = true;\n\n\t \n\trc = _dpu_kms_drm_obj_init(dpu_kms);\n\tif (rc) {\n\t\tDPU_ERROR(\"modeset init failed: %d\\n\", rc);\n\t\tgoto drm_obj_init_err;\n\t}\n\n\tdpu_vbif_init_memtypes(dpu_kms);\n\n\tpm_runtime_put_sync(&dpu_kms->pdev->dev);\n\n\treturn 0;\n\ndrm_obj_init_err:\nhw_intr_init_err:\nperf_err:\npower_error:\n\tpm_runtime_put_sync(&dpu_kms->pdev->dev);\nerror:\n\t_dpu_kms_hw_destroy(dpu_kms);\n\n\treturn rc;\n}\n\nstatic int dpu_kms_init(struct drm_device *ddev)\n{\n\tstruct msm_drm_private *priv = ddev->dev_private;\n\tstruct device *dev = ddev->dev;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct dpu_kms *dpu_kms;\n\tint irq;\n\tstruct dev_pm_opp *opp;\n\tint ret = 0;\n\tunsigned long max_freq = ULONG_MAX;\n\n\tdpu_kms = devm_kzalloc(&pdev->dev, sizeof(*dpu_kms), GFP_KERNEL);\n\tif (!dpu_kms)\n\t\treturn -ENOMEM;\n\n\tret = devm_pm_opp_set_clkname(dev, \"core\");\n\tif (ret)\n\t\treturn ret;\n\t \n\tret = devm_pm_opp_of_add_table(dev);\n\tif (ret && ret != -ENODEV) {\n\t\tdev_err(dev, \"invalid OPP table in device tree\\n\");\n\t\treturn ret;\n\t}\n\n\tret = devm_clk_bulk_get_all(&pdev->dev, &dpu_kms->clocks);\n\tif (ret < 0) {\n\t\tDPU_ERROR(\"failed to parse clocks, ret=%d\\n\", ret);\n\t\treturn ret;\n\t}\n\tdpu_kms->num_clocks = ret;\n\n\topp = dev_pm_opp_find_freq_floor(dev, &max_freq);\n\tif (!IS_ERR(opp))\n\t\tdev_pm_opp_put(opp);\n\n\tdev_pm_opp_set_rate(dev, max_freq);\n\n\tret = msm_kms_init(&dpu_kms->base, &kms_funcs);\n\tif (ret) {\n\t\tDPU_ERROR(\"failed to init kms, ret=%d\\n\", ret);\n\t\treturn ret;\n\t}\n\tdpu_kms->dev = ddev;\n\tdpu_kms->pdev = pdev;\n\n\tpm_runtime_enable(&pdev->dev);\n\tdpu_kms->rpm_enabled = true;\n\n\tpriv->kms = &dpu_kms->base;\n\n\tirq = irq_of_parse_and_map(dpu_kms->pdev->dev.of_node, 0);\n\tif (!irq) {\n\t\tDPU_ERROR(\"failed to get irq\\n\");\n\t\treturn -EINVAL;\n\t}\n\tdpu_kms->base.irq = irq;\n\n\treturn 0;\n}\n\nstatic int dpu_dev_probe(struct platform_device *pdev)\n{\n\treturn msm_drv_probe(&pdev->dev, dpu_kms_init);\n}\n\nstatic int dpu_dev_remove(struct platform_device *pdev)\n{\n\tcomponent_master_del(&pdev->dev, &msm_drm_ops);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused dpu_runtime_suspend(struct device *dev)\n{\n\tint i;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct msm_drm_private *priv = platform_get_drvdata(pdev);\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(priv->kms);\n\n\t \n\tdev_pm_opp_set_rate(dev, 0);\n\tclk_bulk_disable_unprepare(dpu_kms->num_clocks, dpu_kms->clocks);\n\n\tfor (i = 0; i < dpu_kms->num_paths; i++)\n\t\ticc_set_bw(dpu_kms->path[i], 0, 0);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused dpu_runtime_resume(struct device *dev)\n{\n\tint rc = -1;\n\tstruct platform_device *pdev = to_platform_device(dev);\n\tstruct msm_drm_private *priv = platform_get_drvdata(pdev);\n\tstruct dpu_kms *dpu_kms = to_dpu_kms(priv->kms);\n\tstruct drm_encoder *encoder;\n\tstruct drm_device *ddev;\n\n\tddev = dpu_kms->dev;\n\n\trc = clk_bulk_prepare_enable(dpu_kms->num_clocks, dpu_kms->clocks);\n\tif (rc) {\n\t\tDPU_ERROR(\"clock enable failed rc:%d\\n\", rc);\n\t\treturn rc;\n\t}\n\n\tdpu_vbif_init_memtypes(dpu_kms);\n\n\tdrm_for_each_encoder(encoder, ddev)\n\t\tdpu_encoder_virt_runtime_resume(encoder);\n\n\treturn rc;\n}\n\nstatic const struct dev_pm_ops dpu_pm_ops = {\n\tSET_RUNTIME_PM_OPS(dpu_runtime_suspend, dpu_runtime_resume, NULL)\n\tSET_SYSTEM_SLEEP_PM_OPS(pm_runtime_force_suspend,\n\t\t\t\tpm_runtime_force_resume)\n\t.prepare = msm_pm_prepare,\n\t.complete = msm_pm_complete,\n};\n\nstatic const struct of_device_id dpu_dt_match[] = {\n\t{ .compatible = \"qcom,msm8998-dpu\", .data = &dpu_msm8998_cfg, },\n\t{ .compatible = \"qcom,qcm2290-dpu\", .data = &dpu_qcm2290_cfg, },\n\t{ .compatible = \"qcom,sdm845-dpu\", .data = &dpu_sdm845_cfg, },\n\t{ .compatible = \"qcom,sc7180-dpu\", .data = &dpu_sc7180_cfg, },\n\t{ .compatible = \"qcom,sc7280-dpu\", .data = &dpu_sc7280_cfg, },\n\t{ .compatible = \"qcom,sc8180x-dpu\", .data = &dpu_sc8180x_cfg, },\n\t{ .compatible = \"qcom,sc8280xp-dpu\", .data = &dpu_sc8280xp_cfg, },\n\t{ .compatible = \"qcom,sm6115-dpu\", .data = &dpu_sm6115_cfg, },\n\t{ .compatible = \"qcom,sm6125-dpu\", .data = &dpu_sm6125_cfg, },\n\t{ .compatible = \"qcom,sm6350-dpu\", .data = &dpu_sm6350_cfg, },\n\t{ .compatible = \"qcom,sm6375-dpu\", .data = &dpu_sm6375_cfg, },\n\t{ .compatible = \"qcom,sm8150-dpu\", .data = &dpu_sm8150_cfg, },\n\t{ .compatible = \"qcom,sm8250-dpu\", .data = &dpu_sm8250_cfg, },\n\t{ .compatible = \"qcom,sm8350-dpu\", .data = &dpu_sm8350_cfg, },\n\t{ .compatible = \"qcom,sm8450-dpu\", .data = &dpu_sm8450_cfg, },\n\t{ .compatible = \"qcom,sm8550-dpu\", .data = &dpu_sm8550_cfg, },\n\t{}\n};\nMODULE_DEVICE_TABLE(of, dpu_dt_match);\n\nstatic struct platform_driver dpu_driver = {\n\t.probe = dpu_dev_probe,\n\t.remove = dpu_dev_remove,\n\t.shutdown = msm_drv_shutdown,\n\t.driver = {\n\t\t.name = \"msm_dpu\",\n\t\t.of_match_table = dpu_dt_match,\n\t\t.pm = &dpu_pm_ops,\n\t},\n};\n\nvoid __init msm_dpu_register(void)\n{\n\tplatform_driver_register(&dpu_driver);\n}\n\nvoid __exit msm_dpu_unregister(void)\n{\n\tplatform_driver_unregister(&dpu_driver);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}