{
  "module_name": "msm_gem_submit.c",
  "hash_id": "afd38737347419168357555ffab41a68d577ade66f5f0a1b287dc4ed67955c23",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/msm/msm_gem_submit.c",
  "human_readable_source": "\n \n\n#include <linux/file.h>\n#include <linux/sync_file.h>\n#include <linux/uaccess.h>\n\n#include <drm/drm_drv.h>\n#include <drm/drm_file.h>\n#include <drm/drm_syncobj.h>\n\n#include \"msm_drv.h\"\n#include \"msm_gpu.h\"\n#include \"msm_gem.h\"\n#include \"msm_gpu_trace.h\"\n\n \n\nstatic struct msm_gem_submit *submit_create(struct drm_device *dev,\n\t\tstruct msm_gpu *gpu,\n\t\tstruct msm_gpu_submitqueue *queue, uint32_t nr_bos,\n\t\tuint32_t nr_cmds)\n{\n\tstatic atomic_t ident = ATOMIC_INIT(0);\n\tstruct msm_gem_submit *submit;\n\tuint64_t sz;\n\tint ret;\n\n\tsz = struct_size(submit, bos, nr_bos) +\n\t\t\t((u64)nr_cmds * sizeof(submit->cmd[0]));\n\n\tif (sz > SIZE_MAX)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tsubmit = kzalloc(sz, GFP_KERNEL);\n\tif (!submit)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tsubmit->hw_fence = msm_fence_alloc();\n\tif (IS_ERR(submit->hw_fence)) {\n\t\tret = PTR_ERR(submit->hw_fence);\n\t\tkfree(submit);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tret = drm_sched_job_init(&submit->base, queue->entity, queue);\n\tif (ret) {\n\t\tkfree(submit->hw_fence);\n\t\tkfree(submit);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tkref_init(&submit->ref);\n\tsubmit->dev = dev;\n\tsubmit->aspace = queue->ctx->aspace;\n\tsubmit->gpu = gpu;\n\tsubmit->cmd = (void *)&submit->bos[nr_bos];\n\tsubmit->queue = queue;\n\tsubmit->pid = get_pid(task_pid(current));\n\tsubmit->ring = gpu->rb[queue->ring_nr];\n\tsubmit->fault_dumped = false;\n\n\t \n\tsubmit->ident = atomic_inc_return(&ident) - 1;\n\n\tINIT_LIST_HEAD(&submit->node);\n\n\treturn submit;\n}\n\nvoid __msm_gem_submit_destroy(struct kref *kref)\n{\n\tstruct msm_gem_submit *submit =\n\t\t\tcontainer_of(kref, struct msm_gem_submit, ref);\n\tunsigned i;\n\n\tif (submit->fence_id) {\n\t\tspin_lock(&submit->queue->idr_lock);\n\t\tidr_remove(&submit->queue->fence_idr, submit->fence_id);\n\t\tspin_unlock(&submit->queue->idr_lock);\n\t}\n\n\tdma_fence_put(submit->user_fence);\n\n\t \n\tif (kref_read(&submit->hw_fence->refcount) == 0) {\n\t\tkfree(submit->hw_fence);\n\t} else {\n\t\tdma_fence_put(submit->hw_fence);\n\t}\n\n\tput_pid(submit->pid);\n\tmsm_submitqueue_put(submit->queue);\n\n\tfor (i = 0; i < submit->nr_cmds; i++)\n\t\tkfree(submit->cmd[i].relocs);\n\n\tkfree(submit);\n}\n\nstatic int submit_lookup_objects(struct msm_gem_submit *submit,\n\t\tstruct drm_msm_gem_submit *args, struct drm_file *file)\n{\n\tunsigned i;\n\tint ret = 0;\n\n\tfor (i = 0; i < args->nr_bos; i++) {\n\t\tstruct drm_msm_gem_submit_bo submit_bo;\n\t\tvoid __user *userptr =\n\t\t\tu64_to_user_ptr(args->bos + (i * sizeof(submit_bo)));\n\n\t\t \n\t\tsubmit->bos[i].flags = 0;\n\n\t\tif (copy_from_user(&submit_bo, userptr, sizeof(submit_bo))) {\n\t\t\tret = -EFAULT;\n\t\t\ti = 0;\n\t\t\tgoto out;\n\t\t}\n\n \n#define MANDATORY_FLAGS (MSM_SUBMIT_BO_READ | MSM_SUBMIT_BO_WRITE)\n\n\t\tif ((submit_bo.flags & ~MSM_SUBMIT_BO_FLAGS) ||\n\t\t\t!(submit_bo.flags & MANDATORY_FLAGS)) {\n\t\t\tDRM_ERROR(\"invalid flags: %x\\n\", submit_bo.flags);\n\t\t\tret = -EINVAL;\n\t\t\ti = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\tsubmit->bos[i].handle = submit_bo.handle;\n\t\tsubmit->bos[i].flags = submit_bo.flags;\n\t\t \n\t\tsubmit->bos[i].iova  = submit_bo.presumed;\n\t}\n\n\tspin_lock(&file->table_lock);\n\n\tfor (i = 0; i < args->nr_bos; i++) {\n\t\tstruct drm_gem_object *obj;\n\n\t\t \n\t\tobj = idr_find(&file->object_idr, submit->bos[i].handle);\n\t\tif (!obj) {\n\t\t\tDRM_ERROR(\"invalid handle %u at index %u\\n\", submit->bos[i].handle, i);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tdrm_gem_object_get(obj);\n\n\t\tsubmit->bos[i].obj = obj;\n\t}\n\nout_unlock:\n\tspin_unlock(&file->table_lock);\n\nout:\n\tsubmit->nr_bos = i;\n\n\treturn ret;\n}\n\nstatic int submit_lookup_cmds(struct msm_gem_submit *submit,\n\t\tstruct drm_msm_gem_submit *args, struct drm_file *file)\n{\n\tunsigned i;\n\tsize_t sz;\n\tint ret = 0;\n\n\tfor (i = 0; i < args->nr_cmds; i++) {\n\t\tstruct drm_msm_gem_submit_cmd submit_cmd;\n\t\tvoid __user *userptr =\n\t\t\tu64_to_user_ptr(args->cmds + (i * sizeof(submit_cmd)));\n\n\t\tret = copy_from_user(&submit_cmd, userptr, sizeof(submit_cmd));\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\tswitch (submit_cmd.type) {\n\t\tcase MSM_SUBMIT_CMD_BUF:\n\t\tcase MSM_SUBMIT_CMD_IB_TARGET_BUF:\n\t\tcase MSM_SUBMIT_CMD_CTX_RESTORE_BUF:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDRM_ERROR(\"invalid type: %08x\\n\", submit_cmd.type);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (submit_cmd.size % 4) {\n\t\t\tDRM_ERROR(\"non-aligned cmdstream buffer size: %u\\n\",\n\t\t\t\t\tsubmit_cmd.size);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tsubmit->cmd[i].type = submit_cmd.type;\n\t\tsubmit->cmd[i].size = submit_cmd.size / 4;\n\t\tsubmit->cmd[i].offset = submit_cmd.submit_offset / 4;\n\t\tsubmit->cmd[i].idx  = submit_cmd.submit_idx;\n\t\tsubmit->cmd[i].nr_relocs = submit_cmd.nr_relocs;\n\n\t\tuserptr = u64_to_user_ptr(submit_cmd.relocs);\n\n\t\tsz = array_size(submit_cmd.nr_relocs,\n\t\t\t\tsizeof(struct drm_msm_gem_submit_reloc));\n\t\t \n\t\tif (sz == SIZE_MAX) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tsubmit->cmd[i].relocs = kmalloc(sz, GFP_KERNEL);\n\t\tif (!submit->cmd[i].relocs) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tret = copy_from_user(submit->cmd[i].relocs, userptr, sz);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\treturn ret;\n}\n\n \nstatic void submit_cleanup_bo(struct msm_gem_submit *submit, int i,\n\t\tunsigned cleanup_flags)\n{\n\tstruct drm_gem_object *obj = submit->bos[i].obj;\n\tunsigned flags = submit->bos[i].flags & cleanup_flags;\n\n\t \n\tsubmit->bos[i].flags &= ~cleanup_flags;\n\n\tif (flags & BO_PINNED)\n\t\tmsm_gem_unpin_locked(obj);\n\n\tif (flags & BO_LOCKED)\n\t\tdma_resv_unlock(obj->resv);\n}\n\nstatic void submit_unlock_unpin_bo(struct msm_gem_submit *submit, int i)\n{\n\tunsigned cleanup_flags = BO_PINNED | BO_LOCKED;\n\tsubmit_cleanup_bo(submit, i, cleanup_flags);\n\n\tif (!(submit->bos[i].flags & BO_VALID))\n\t\tsubmit->bos[i].iova = 0;\n}\n\n \nstatic int submit_lock_objects(struct msm_gem_submit *submit)\n{\n\tint contended, slow_locked = -1, i, ret = 0;\n\nretry:\n\tfor (i = 0; i < submit->nr_bos; i++) {\n\t\tstruct drm_gem_object *obj = submit->bos[i].obj;\n\n\t\tif (slow_locked == i)\n\t\t\tslow_locked = -1;\n\n\t\tcontended = i;\n\n\t\tif (!(submit->bos[i].flags & BO_LOCKED)) {\n\t\t\tret = dma_resv_lock_interruptible(obj->resv,\n\t\t\t\t\t\t\t  &submit->ticket);\n\t\t\tif (ret)\n\t\t\t\tgoto fail;\n\t\t\tsubmit->bos[i].flags |= BO_LOCKED;\n\t\t}\n\t}\n\n\tww_acquire_done(&submit->ticket);\n\n\treturn 0;\n\nfail:\n\tif (ret == -EALREADY) {\n\t\tDRM_ERROR(\"handle %u at index %u already on submit list\\n\",\n\t\t\t\tsubmit->bos[i].handle, i);\n\t\tret = -EINVAL;\n\t}\n\n\tfor (; i >= 0; i--)\n\t\tsubmit_unlock_unpin_bo(submit, i);\n\n\tif (slow_locked > 0)\n\t\tsubmit_unlock_unpin_bo(submit, slow_locked);\n\n\tif (ret == -EDEADLK) {\n\t\tstruct drm_gem_object *obj = submit->bos[contended].obj;\n\t\t \n\t\tret = dma_resv_lock_slow_interruptible(obj->resv,\n\t\t\t\t\t\t       &submit->ticket);\n\t\tif (!ret) {\n\t\t\tsubmit->bos[contended].flags |= BO_LOCKED;\n\t\t\tslow_locked = contended;\n\t\t\tgoto retry;\n\t\t}\n\n\t\t \n\t\tWARN_ON_ONCE(ret == -EALREADY);\n\t}\n\n\treturn ret;\n}\n\nstatic int submit_fence_sync(struct msm_gem_submit *submit, bool no_implicit)\n{\n\tint i, ret = 0;\n\n\tfor (i = 0; i < submit->nr_bos; i++) {\n\t\tstruct drm_gem_object *obj = submit->bos[i].obj;\n\t\tbool write = submit->bos[i].flags & MSM_SUBMIT_BO_WRITE;\n\n\t\t \n\t\tret = dma_resv_reserve_fences(obj->resv, 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\tif (no_implicit)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (submit->bos[i].flags & MSM_SUBMIT_BO_NO_IMPLICIT)\n\t\t\tcontinue;\n\n\t\tret = drm_sched_job_add_implicit_dependencies(&submit->base,\n\t\t\t\t\t\t\t      obj,\n\t\t\t\t\t\t\t      write);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int submit_pin_objects(struct msm_gem_submit *submit)\n{\n\tstruct msm_drm_private *priv = submit->dev->dev_private;\n\tint i, ret = 0;\n\n\tsubmit->valid = true;\n\n\tfor (i = 0; i < submit->nr_bos; i++) {\n\t\tstruct drm_gem_object *obj = submit->bos[i].obj;\n\t\tstruct msm_gem_vma *vma;\n\n\t\t \n\t\tvma = msm_gem_get_vma_locked(obj, submit->aspace);\n\t\tif (IS_ERR(vma)) {\n\t\t\tret = PTR_ERR(vma);\n\t\t\tbreak;\n\t\t}\n\n\t\tret = msm_gem_pin_vma_locked(obj, vma);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (vma->iova == submit->bos[i].iova) {\n\t\t\tsubmit->bos[i].flags |= BO_VALID;\n\t\t} else {\n\t\t\tsubmit->bos[i].iova = vma->iova;\n\t\t\t \n\t\t\tsubmit->bos[i].flags &= ~BO_VALID;\n\t\t\tsubmit->valid = false;\n\t\t}\n\t}\n\n\t \n\tmutex_lock(&priv->lru.lock);\n\tfor (i = 0; i < submit->nr_bos; i++) {\n\t\tmsm_gem_pin_obj_locked(submit->bos[i].obj);\n\t\tsubmit->bos[i].flags |= BO_PINNED;\n\t}\n\tmutex_unlock(&priv->lru.lock);\n\n\treturn ret;\n}\n\nstatic void submit_attach_object_fences(struct msm_gem_submit *submit)\n{\n\tint i;\n\n\tfor (i = 0; i < submit->nr_bos; i++) {\n\t\tstruct drm_gem_object *obj = submit->bos[i].obj;\n\n\t\tif (submit->bos[i].flags & MSM_SUBMIT_BO_WRITE)\n\t\t\tdma_resv_add_fence(obj->resv, submit->user_fence,\n\t\t\t\t\t   DMA_RESV_USAGE_WRITE);\n\t\telse if (submit->bos[i].flags & MSM_SUBMIT_BO_READ)\n\t\t\tdma_resv_add_fence(obj->resv, submit->user_fence,\n\t\t\t\t\t   DMA_RESV_USAGE_READ);\n\t}\n}\n\nstatic int submit_bo(struct msm_gem_submit *submit, uint32_t idx,\n\t\tstruct drm_gem_object **obj, uint64_t *iova, bool *valid)\n{\n\tif (idx >= submit->nr_bos) {\n\t\tDRM_ERROR(\"invalid buffer index: %u (out of %u)\\n\",\n\t\t\t\tidx, submit->nr_bos);\n\t\treturn -EINVAL;\n\t}\n\n\tif (obj)\n\t\t*obj = submit->bos[idx].obj;\n\tif (iova)\n\t\t*iova = submit->bos[idx].iova;\n\tif (valid)\n\t\t*valid = !!(submit->bos[idx].flags & BO_VALID);\n\n\treturn 0;\n}\n\n \nstatic int submit_reloc(struct msm_gem_submit *submit, struct drm_gem_object *obj,\n\t\tuint32_t offset, uint32_t nr_relocs, struct drm_msm_gem_submit_reloc *relocs)\n{\n\tuint32_t i, last_offset = 0;\n\tuint32_t *ptr;\n\tint ret = 0;\n\n\tif (!nr_relocs)\n\t\treturn 0;\n\n\tif (offset % 4) {\n\t\tDRM_ERROR(\"non-aligned cmdstream buffer: %u\\n\", offset);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tptr = msm_gem_get_vaddr_locked(obj);\n\n\tif (IS_ERR(ptr)) {\n\t\tret = PTR_ERR(ptr);\n\t\tDBG(\"failed to map: %d\", ret);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < nr_relocs; i++) {\n\t\tstruct drm_msm_gem_submit_reloc submit_reloc = relocs[i];\n\t\tuint32_t off;\n\t\tuint64_t iova;\n\t\tbool valid;\n\n\t\tif (submit_reloc.submit_offset % 4) {\n\t\t\tDRM_ERROR(\"non-aligned reloc offset: %u\\n\",\n\t\t\t\t\tsubmit_reloc.submit_offset);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\t \n\t\toff = submit_reloc.submit_offset / 4;\n\n\t\tif ((off >= (obj->size / 4)) ||\n\t\t\t\t(off < last_offset)) {\n\t\t\tDRM_ERROR(\"invalid offset %u at reloc %u\\n\", off, i);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = submit_bo(submit, submit_reloc.reloc_idx, NULL, &iova, &valid);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tif (valid)\n\t\t\tcontinue;\n\n\t\tiova += submit_reloc.reloc_offset;\n\n\t\tif (submit_reloc.shift < 0)\n\t\t\tiova >>= -submit_reloc.shift;\n\t\telse\n\t\t\tiova <<= submit_reloc.shift;\n\n\t\tptr[off] = iova | submit_reloc.or;\n\n\t\tlast_offset = off;\n\t}\n\nout:\n\tmsm_gem_put_vaddr_locked(obj);\n\n\treturn ret;\n}\n\n \nstatic void submit_cleanup(struct msm_gem_submit *submit, bool error)\n{\n\tunsigned cleanup_flags = BO_LOCKED;\n\tunsigned i;\n\n\tif (error)\n\t\tcleanup_flags |= BO_PINNED;\n\n\tfor (i = 0; i < submit->nr_bos; i++) {\n\t\tstruct drm_gem_object *obj = submit->bos[i].obj;\n\t\tsubmit_cleanup_bo(submit, i, cleanup_flags);\n\t\tif (error)\n\t\t\tdrm_gem_object_put(obj);\n\t}\n}\n\nvoid msm_submit_retire(struct msm_gem_submit *submit)\n{\n\tint i;\n\n\tfor (i = 0; i < submit->nr_bos; i++) {\n\t\tstruct drm_gem_object *obj = submit->bos[i].obj;\n\n\t\tdrm_gem_object_put(obj);\n\t}\n}\n\nstruct msm_submit_post_dep {\n\tstruct drm_syncobj *syncobj;\n\tuint64_t point;\n\tstruct dma_fence_chain *chain;\n};\n\nstatic struct drm_syncobj **msm_parse_deps(struct msm_gem_submit *submit,\n                                           struct drm_file *file,\n                                           uint64_t in_syncobjs_addr,\n                                           uint32_t nr_in_syncobjs,\n                                           size_t syncobj_stride)\n{\n\tstruct drm_syncobj **syncobjs = NULL;\n\tstruct drm_msm_gem_submit_syncobj syncobj_desc = {0};\n\tint ret = 0;\n\tuint32_t i, j;\n\n\tsyncobjs = kcalloc(nr_in_syncobjs, sizeof(*syncobjs),\n\t                   GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (!syncobjs)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor (i = 0; i < nr_in_syncobjs; ++i) {\n\t\tuint64_t address = in_syncobjs_addr + i * syncobj_stride;\n\n\t\tif (copy_from_user(&syncobj_desc,\n\t\t\t           u64_to_user_ptr(address),\n\t\t\t           min(syncobj_stride, sizeof(syncobj_desc)))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (syncobj_desc.point &&\n\t\t    !drm_core_check_feature(submit->dev, DRIVER_SYNCOBJ_TIMELINE)) {\n\t\t\tret = -EOPNOTSUPP;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (syncobj_desc.flags & ~MSM_SUBMIT_SYNCOBJ_FLAGS) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = drm_sched_job_add_syncobj_dependency(&submit->base, file,\n\t\t\t\t\t\t\t   syncobj_desc.handle, syncobj_desc.point);\n\t\tif (ret)\n\t\t\tbreak;\n\n\t\tif (syncobj_desc.flags & MSM_SUBMIT_SYNCOBJ_RESET) {\n\t\t\tsyncobjs[i] =\n\t\t\t\tdrm_syncobj_find(file, syncobj_desc.handle);\n\t\t\tif (!syncobjs[i]) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ret) {\n\t\tfor (j = 0; j <= i; ++j) {\n\t\t\tif (syncobjs[j])\n\t\t\t\tdrm_syncobj_put(syncobjs[j]);\n\t\t}\n\t\tkfree(syncobjs);\n\t\treturn ERR_PTR(ret);\n\t}\n\treturn syncobjs;\n}\n\nstatic void msm_reset_syncobjs(struct drm_syncobj **syncobjs,\n                               uint32_t nr_syncobjs)\n{\n\tuint32_t i;\n\n\tfor (i = 0; syncobjs && i < nr_syncobjs; ++i) {\n\t\tif (syncobjs[i])\n\t\t\tdrm_syncobj_replace_fence(syncobjs[i], NULL);\n\t}\n}\n\nstatic struct msm_submit_post_dep *msm_parse_post_deps(struct drm_device *dev,\n                                                       struct drm_file *file,\n                                                       uint64_t syncobjs_addr,\n                                                       uint32_t nr_syncobjs,\n                                                       size_t syncobj_stride)\n{\n\tstruct msm_submit_post_dep *post_deps;\n\tstruct drm_msm_gem_submit_syncobj syncobj_desc = {0};\n\tint ret = 0;\n\tuint32_t i, j;\n\n\tpost_deps = kcalloc(nr_syncobjs, sizeof(*post_deps),\n\t\t\t    GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (!post_deps)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor (i = 0; i < nr_syncobjs; ++i) {\n\t\tuint64_t address = syncobjs_addr + i * syncobj_stride;\n\n\t\tif (copy_from_user(&syncobj_desc,\n\t\t\t           u64_to_user_ptr(address),\n\t\t\t           min(syncobj_stride, sizeof(syncobj_desc)))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tpost_deps[i].point = syncobj_desc.point;\n\n\t\tif (syncobj_desc.flags) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (syncobj_desc.point) {\n\t\t\tif (!drm_core_check_feature(dev,\n\t\t\t                            DRIVER_SYNCOBJ_TIMELINE)) {\n\t\t\t\tret = -EOPNOTSUPP;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tpost_deps[i].chain = dma_fence_chain_alloc();\n\t\t\tif (!post_deps[i].chain) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tpost_deps[i].syncobj =\n\t\t\tdrm_syncobj_find(file, syncobj_desc.handle);\n\t\tif (!post_deps[i].syncobj) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (ret) {\n\t\tfor (j = 0; j <= i; ++j) {\n\t\t\tdma_fence_chain_free(post_deps[j].chain);\n\t\t\tif (post_deps[j].syncobj)\n\t\t\t\tdrm_syncobj_put(post_deps[j].syncobj);\n\t\t}\n\n\t\tkfree(post_deps);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn post_deps;\n}\n\nstatic void msm_process_post_deps(struct msm_submit_post_dep *post_deps,\n                                  uint32_t count, struct dma_fence *fence)\n{\n\tuint32_t i;\n\n\tfor (i = 0; post_deps && i < count; ++i) {\n\t\tif (post_deps[i].chain) {\n\t\t\tdrm_syncobj_add_point(post_deps[i].syncobj,\n\t\t\t                      post_deps[i].chain,\n\t\t\t                      fence, post_deps[i].point);\n\t\t\tpost_deps[i].chain = NULL;\n\t\t} else {\n\t\t\tdrm_syncobj_replace_fence(post_deps[i].syncobj,\n\t\t\t                          fence);\n\t\t}\n\t}\n}\n\nint msm_ioctl_gem_submit(struct drm_device *dev, void *data,\n\t\tstruct drm_file *file)\n{\n\tstruct msm_drm_private *priv = dev->dev_private;\n\tstruct drm_msm_gem_submit *args = data;\n\tstruct msm_file_private *ctx = file->driver_priv;\n\tstruct msm_gem_submit *submit = NULL;\n\tstruct msm_gpu *gpu = priv->gpu;\n\tstruct msm_gpu_submitqueue *queue;\n\tstruct msm_ringbuffer *ring;\n\tstruct msm_submit_post_dep *post_deps = NULL;\n\tstruct drm_syncobj **syncobjs_to_reset = NULL;\n\tint out_fence_fd = -1;\n\tbool has_ww_ticket = false;\n\tunsigned i;\n\tint ret;\n\n\tif (!gpu)\n\t\treturn -ENXIO;\n\n\tif (args->pad)\n\t\treturn -EINVAL;\n\n\tif (unlikely(!ctx->aspace) && !capable(CAP_SYS_RAWIO)) {\n\t\tDRM_ERROR_RATELIMITED(\"IOMMU support or CAP_SYS_RAWIO required!\\n\");\n\t\treturn -EPERM;\n\t}\n\n\t \n\tif (MSM_PIPE_ID(args->flags) != MSM_PIPE_3D0)\n\t\treturn -EINVAL;\n\n\tif (MSM_PIPE_FLAGS(args->flags) & ~MSM_SUBMIT_FLAGS)\n\t\treturn -EINVAL;\n\n\tif (args->flags & MSM_SUBMIT_SUDO) {\n\t\tif (!IS_ENABLED(CONFIG_DRM_MSM_GPU_SUDO) ||\n\t\t    !capable(CAP_SYS_RAWIO))\n\t\t\treturn -EINVAL;\n\t}\n\n\tqueue = msm_submitqueue_get(ctx, args->queueid);\n\tif (!queue)\n\t\treturn -ENOENT;\n\n\tring = gpu->rb[queue->ring_nr];\n\n\tif (args->flags & MSM_SUBMIT_FENCE_FD_OUT) {\n\t\tout_fence_fd = get_unused_fd_flags(O_CLOEXEC);\n\t\tif (out_fence_fd < 0) {\n\t\t\tret = out_fence_fd;\n\t\t\tgoto out_post_unlock;\n\t\t}\n\t}\n\n\tsubmit = submit_create(dev, gpu, queue, args->nr_bos, args->nr_cmds);\n\tif (IS_ERR(submit)) {\n\t\tret = PTR_ERR(submit);\n\t\tgoto out_post_unlock;\n\t}\n\n\ttrace_msm_gpu_submit(pid_nr(submit->pid), ring->id, submit->ident,\n\t\targs->nr_bos, args->nr_cmds);\n\n\tret = mutex_lock_interruptible(&queue->lock);\n\tif (ret)\n\t\tgoto out_post_unlock;\n\n\tif (args->flags & MSM_SUBMIT_SUDO)\n\t\tsubmit->in_rb = true;\n\n\tif (args->flags & MSM_SUBMIT_FENCE_FD_IN) {\n\t\tstruct dma_fence *in_fence;\n\n\t\tin_fence = sync_file_get_fence(args->fence_fd);\n\n\t\tif (!in_fence) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tret = drm_sched_job_add_dependency(&submit->base, in_fence);\n\t\tif (ret)\n\t\t\tgoto out_unlock;\n\t}\n\n\tif (args->flags & MSM_SUBMIT_SYNCOBJ_IN) {\n\t\tsyncobjs_to_reset = msm_parse_deps(submit, file,\n\t\t                                   args->in_syncobjs,\n\t\t                                   args->nr_in_syncobjs,\n\t\t                                   args->syncobj_stride);\n\t\tif (IS_ERR(syncobjs_to_reset)) {\n\t\t\tret = PTR_ERR(syncobjs_to_reset);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (args->flags & MSM_SUBMIT_SYNCOBJ_OUT) {\n\t\tpost_deps = msm_parse_post_deps(dev, file,\n\t\t                                args->out_syncobjs,\n\t\t                                args->nr_out_syncobjs,\n\t\t                                args->syncobj_stride);\n\t\tif (IS_ERR(post_deps)) {\n\t\t\tret = PTR_ERR(post_deps);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tret = submit_lookup_objects(submit, args, file);\n\tif (ret)\n\t\tgoto out;\n\n\tret = submit_lookup_cmds(submit, args, file);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tww_acquire_init(&submit->ticket, &reservation_ww_class);\n\thas_ww_ticket = true;\n\tret = submit_lock_objects(submit);\n\tif (ret)\n\t\tgoto out;\n\n\tret = submit_fence_sync(submit, !!(args->flags & MSM_SUBMIT_NO_IMPLICIT));\n\tif (ret)\n\t\tgoto out;\n\n\tret = submit_pin_objects(submit);\n\tif (ret)\n\t\tgoto out;\n\n\tfor (i = 0; i < args->nr_cmds; i++) {\n\t\tstruct drm_gem_object *obj;\n\t\tuint64_t iova;\n\n\t\tret = submit_bo(submit, submit->cmd[i].idx,\n\t\t\t\t&obj, &iova, NULL);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tif (!submit->cmd[i].size ||\n\t\t\t((submit->cmd[i].size + submit->cmd[i].offset) >\n\t\t\t\tobj->size / 4)) {\n\t\t\tDRM_ERROR(\"invalid cmdstream size: %u\\n\", submit->cmd[i].size * 4);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tsubmit->cmd[i].iova = iova + (submit->cmd[i].offset * 4);\n\n\t\tif (submit->valid)\n\t\t\tcontinue;\n\n\t\tif (!gpu->allow_relocs) {\n\t\t\tif (submit->cmd[i].nr_relocs) {\n\t\t\t\tDRM_ERROR(\"relocs not allowed\\n\");\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = submit_reloc(submit, obj, submit->cmd[i].offset * 4,\n\t\t\t\tsubmit->cmd[i].nr_relocs, submit->cmd[i].relocs);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tsubmit->nr_cmds = i;\n\n\tidr_preload(GFP_KERNEL);\n\n\tspin_lock(&queue->idr_lock);\n\n\t \n\tif ((args->flags & MSM_SUBMIT_FENCE_SN_IN) &&\n\t\t\t(!args->fence || idr_find(&queue->fence_idr, args->fence))) {\n\t\tspin_unlock(&queue->idr_lock);\n\t\tidr_preload_end();\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tdrm_sched_job_arm(&submit->base);\n\n\tsubmit->user_fence = dma_fence_get(&submit->base.s_fence->finished);\n\n\tif (args->flags & MSM_SUBMIT_FENCE_SN_IN) {\n\t\t \n\t\tsubmit->fence_id = args->fence;\n\t\tret = idr_alloc_u32(&queue->fence_idr, submit->user_fence,\n\t\t\t\t    &submit->fence_id, submit->fence_id,\n\t\t\t\t    GFP_NOWAIT);\n\t\t \n\t\tWARN_ON(ret);\n\t} else {\n\t\t \n\t\tsubmit->fence_id = idr_alloc_cyclic(&queue->fence_idr,\n\t\t\t\t\t\t    submit->user_fence, 1,\n\t\t\t\t\t\t    INT_MAX, GFP_NOWAIT);\n\t}\n\n\tspin_unlock(&queue->idr_lock);\n\tidr_preload_end();\n\n\tif (submit->fence_id < 0) {\n\t\tret = submit->fence_id;\n\t\tsubmit->fence_id = 0;\n\t}\n\n\tif (ret == 0 && args->flags & MSM_SUBMIT_FENCE_FD_OUT) {\n\t\tstruct sync_file *sync_file = sync_file_create(submit->user_fence);\n\t\tif (!sync_file) {\n\t\t\tret = -ENOMEM;\n\t\t} else {\n\t\t\tfd_install(out_fence_fd, sync_file->file);\n\t\t\targs->fence_fd = out_fence_fd;\n\t\t}\n\t}\n\n\tsubmit_attach_object_fences(submit);\n\n\t \n\tmsm_gem_submit_get(submit);\n\n\tmsm_rd_dump_submit(priv->rd, submit, NULL);\n\n\tdrm_sched_entity_push_job(&submit->base);\n\n\targs->fence = submit->fence_id;\n\tqueue->last_fence = submit->fence_id;\n\n\tmsm_reset_syncobjs(syncobjs_to_reset, args->nr_in_syncobjs);\n\tmsm_process_post_deps(post_deps, args->nr_out_syncobjs,\n\t                      submit->user_fence);\n\n\nout:\n\tsubmit_cleanup(submit, !!ret);\n\tif (has_ww_ticket)\n\t\tww_acquire_fini(&submit->ticket);\nout_unlock:\n\tmutex_unlock(&queue->lock);\nout_post_unlock:\n\tif (ret && (out_fence_fd >= 0))\n\t\tput_unused_fd(out_fence_fd);\n\n\tif (!IS_ERR_OR_NULL(submit)) {\n\t\tmsm_gem_submit_put(submit);\n\t} else {\n\t\t \n\t\tmsm_submitqueue_put(queue);\n\t}\n\tif (!IS_ERR_OR_NULL(post_deps)) {\n\t\tfor (i = 0; i < args->nr_out_syncobjs; ++i) {\n\t\t\tkfree(post_deps[i].chain);\n\t\t\tdrm_syncobj_put(post_deps[i].syncobj);\n\t\t}\n\t\tkfree(post_deps);\n\t}\n\n\tif (!IS_ERR_OR_NULL(syncobjs_to_reset)) {\n\t\tfor (i = 0; i < args->nr_in_syncobjs; ++i) {\n\t\t\tif (syncobjs_to_reset[i])\n\t\t\t\tdrm_syncobj_put(syncobjs_to_reset[i]);\n\t\t}\n\t\tkfree(syncobjs_to_reset);\n\t}\n\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}