{
  "module_name": "drm_gem.c",
  "hash_id": "e27969573d4104389ee15e6059c93285af810d15ce3b3deee94ae211ff7c349f",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/drm_gem.c",
  "human_readable_source": " \n\n#include <linux/dma-buf.h>\n#include <linux/file.h>\n#include <linux/fs.h>\n#include <linux/iosys-map.h>\n#include <linux/mem_encrypt.h>\n#include <linux/mm.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/pagemap.h>\n#include <linux/pagevec.h>\n#include <linux/shmem_fs.h>\n#include <linux/slab.h>\n#include <linux/string_helpers.h>\n#include <linux/types.h>\n#include <linux/uaccess.h>\n\n#include <drm/drm.h>\n#include <drm/drm_device.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_file.h>\n#include <drm/drm_gem.h>\n#include <drm/drm_managed.h>\n#include <drm/drm_print.h>\n#include <drm/drm_vma_manager.h>\n\n#include \"drm_internal.h\"\n\n \n\nstatic void\ndrm_gem_init_release(struct drm_device *dev, void *ptr)\n{\n\tdrm_vma_offset_manager_destroy(dev->vma_offset_manager);\n}\n\n \nint\ndrm_gem_init(struct drm_device *dev)\n{\n\tstruct drm_vma_offset_manager *vma_offset_manager;\n\n\tmutex_init(&dev->object_name_lock);\n\tidr_init_base(&dev->object_name_idr, 1);\n\n\tvma_offset_manager = drmm_kzalloc(dev, sizeof(*vma_offset_manager),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!vma_offset_manager) {\n\t\tDRM_ERROR(\"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tdev->vma_offset_manager = vma_offset_manager;\n\tdrm_vma_offset_manager_init(vma_offset_manager,\n\t\t\t\t    DRM_FILE_PAGE_OFFSET_START,\n\t\t\t\t    DRM_FILE_PAGE_OFFSET_SIZE);\n\n\treturn drmm_add_action(dev, drm_gem_init_release, NULL);\n}\n\n \nint drm_gem_object_init(struct drm_device *dev,\n\t\t\tstruct drm_gem_object *obj, size_t size)\n{\n\tstruct file *filp;\n\n\tdrm_gem_private_object_init(dev, obj, size);\n\n\tfilp = shmem_file_setup(\"drm mm object\", size, VM_NORESERVE);\n\tif (IS_ERR(filp))\n\t\treturn PTR_ERR(filp);\n\n\tobj->filp = filp;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_gem_object_init);\n\n \nvoid drm_gem_private_object_init(struct drm_device *dev,\n\t\t\t\t struct drm_gem_object *obj, size_t size)\n{\n\tBUG_ON((size & (PAGE_SIZE - 1)) != 0);\n\n\tobj->dev = dev;\n\tobj->filp = NULL;\n\n\tkref_init(&obj->refcount);\n\tobj->handle_count = 0;\n\tobj->size = size;\n\tdma_resv_init(&obj->_resv);\n\tif (!obj->resv)\n\t\tobj->resv = &obj->_resv;\n\n\tif (drm_core_check_feature(dev, DRIVER_GEM_GPUVA))\n\t\tdrm_gem_gpuva_init(obj);\n\n\tdrm_vma_node_reset(&obj->vma_node);\n\tINIT_LIST_HEAD(&obj->lru_node);\n}\nEXPORT_SYMBOL(drm_gem_private_object_init);\n\n \nvoid drm_gem_private_object_fini(struct drm_gem_object *obj)\n{\n\tWARN_ON(obj->dma_buf);\n\n\tdma_resv_fini(&obj->_resv);\n}\nEXPORT_SYMBOL(drm_gem_private_object_fini);\n\n \nstatic void drm_gem_object_handle_free(struct drm_gem_object *obj)\n{\n\tstruct drm_device *dev = obj->dev;\n\n\t \n\tif (obj->name) {\n\t\tidr_remove(&dev->object_name_idr, obj->name);\n\t\tobj->name = 0;\n\t}\n}\n\nstatic void drm_gem_object_exported_dma_buf_free(struct drm_gem_object *obj)\n{\n\t \n\tif (obj->dma_buf) {\n\t\tdma_buf_put(obj->dma_buf);\n\t\tobj->dma_buf = NULL;\n\t}\n}\n\nstatic void\ndrm_gem_object_handle_put_unlocked(struct drm_gem_object *obj)\n{\n\tstruct drm_device *dev = obj->dev;\n\tbool final = false;\n\n\tif (WARN_ON(READ_ONCE(obj->handle_count) == 0))\n\t\treturn;\n\n\t \n\n\tmutex_lock(&dev->object_name_lock);\n\tif (--obj->handle_count == 0) {\n\t\tdrm_gem_object_handle_free(obj);\n\t\tdrm_gem_object_exported_dma_buf_free(obj);\n\t\tfinal = true;\n\t}\n\tmutex_unlock(&dev->object_name_lock);\n\n\tif (final)\n\t\tdrm_gem_object_put(obj);\n}\n\n \nstatic int\ndrm_gem_object_release_handle(int id, void *ptr, void *data)\n{\n\tstruct drm_file *file_priv = data;\n\tstruct drm_gem_object *obj = ptr;\n\n\tif (obj->funcs->close)\n\t\tobj->funcs->close(obj, file_priv);\n\n\tdrm_prime_remove_buf_handle(&file_priv->prime, id);\n\tdrm_vma_node_revoke(&obj->vma_node, file_priv);\n\n\tdrm_gem_object_handle_put_unlocked(obj);\n\n\treturn 0;\n}\n\n \nint\ndrm_gem_handle_delete(struct drm_file *filp, u32 handle)\n{\n\tstruct drm_gem_object *obj;\n\n\tspin_lock(&filp->table_lock);\n\n\t \n\tobj = idr_replace(&filp->object_idr, NULL, handle);\n\tspin_unlock(&filp->table_lock);\n\tif (IS_ERR_OR_NULL(obj))\n\t\treturn -EINVAL;\n\n\t \n\tdrm_gem_object_release_handle(handle, obj, filp);\n\n\t \n\tspin_lock(&filp->table_lock);\n\tidr_remove(&filp->object_idr, handle);\n\tspin_unlock(&filp->table_lock);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_gem_handle_delete);\n\n \nint drm_gem_dumb_map_offset(struct drm_file *file, struct drm_device *dev,\n\t\t\t    u32 handle, u64 *offset)\n{\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\tobj = drm_gem_object_lookup(file, handle);\n\tif (!obj)\n\t\treturn -ENOENT;\n\n\t \n\tif (obj->import_attach) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tret = drm_gem_create_mmap_offset(obj);\n\tif (ret)\n\t\tgoto out;\n\n\t*offset = drm_vma_node_offset_addr(&obj->vma_node);\nout:\n\tdrm_gem_object_put(obj);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(drm_gem_dumb_map_offset);\n\n \nint\ndrm_gem_handle_create_tail(struct drm_file *file_priv,\n\t\t\t   struct drm_gem_object *obj,\n\t\t\t   u32 *handlep)\n{\n\tstruct drm_device *dev = obj->dev;\n\tu32 handle;\n\tint ret;\n\n\tWARN_ON(!mutex_is_locked(&dev->object_name_lock));\n\tif (obj->handle_count++ == 0)\n\t\tdrm_gem_object_get(obj);\n\n\t \n\tidr_preload(GFP_KERNEL);\n\tspin_lock(&file_priv->table_lock);\n\n\tret = idr_alloc(&file_priv->object_idr, obj, 1, 0, GFP_NOWAIT);\n\n\tspin_unlock(&file_priv->table_lock);\n\tidr_preload_end();\n\n\tmutex_unlock(&dev->object_name_lock);\n\tif (ret < 0)\n\t\tgoto err_unref;\n\n\thandle = ret;\n\n\tret = drm_vma_node_allow(&obj->vma_node, file_priv);\n\tif (ret)\n\t\tgoto err_remove;\n\n\tif (obj->funcs->open) {\n\t\tret = obj->funcs->open(obj, file_priv);\n\t\tif (ret)\n\t\t\tgoto err_revoke;\n\t}\n\n\t*handlep = handle;\n\treturn 0;\n\nerr_revoke:\n\tdrm_vma_node_revoke(&obj->vma_node, file_priv);\nerr_remove:\n\tspin_lock(&file_priv->table_lock);\n\tidr_remove(&file_priv->object_idr, handle);\n\tspin_unlock(&file_priv->table_lock);\nerr_unref:\n\tdrm_gem_object_handle_put_unlocked(obj);\n\treturn ret;\n}\n\n \nint drm_gem_handle_create(struct drm_file *file_priv,\n\t\t\t  struct drm_gem_object *obj,\n\t\t\t  u32 *handlep)\n{\n\tmutex_lock(&obj->dev->object_name_lock);\n\n\treturn drm_gem_handle_create_tail(file_priv, obj, handlep);\n}\nEXPORT_SYMBOL(drm_gem_handle_create);\n\n\n \nvoid\ndrm_gem_free_mmap_offset(struct drm_gem_object *obj)\n{\n\tstruct drm_device *dev = obj->dev;\n\n\tdrm_vma_offset_remove(dev->vma_offset_manager, &obj->vma_node);\n}\nEXPORT_SYMBOL(drm_gem_free_mmap_offset);\n\n \nint\ndrm_gem_create_mmap_offset_size(struct drm_gem_object *obj, size_t size)\n{\n\tstruct drm_device *dev = obj->dev;\n\n\treturn drm_vma_offset_add(dev->vma_offset_manager, &obj->vma_node,\n\t\t\t\t  size / PAGE_SIZE);\n}\nEXPORT_SYMBOL(drm_gem_create_mmap_offset_size);\n\n \nint drm_gem_create_mmap_offset(struct drm_gem_object *obj)\n{\n\treturn drm_gem_create_mmap_offset_size(obj, obj->size);\n}\nEXPORT_SYMBOL(drm_gem_create_mmap_offset);\n\n \nstatic void drm_gem_check_release_batch(struct folio_batch *fbatch)\n{\n\tcheck_move_unevictable_folios(fbatch);\n\t__folio_batch_release(fbatch);\n\tcond_resched();\n}\n\n \nstruct page **drm_gem_get_pages(struct drm_gem_object *obj)\n{\n\tstruct address_space *mapping;\n\tstruct page **pages;\n\tstruct folio *folio;\n\tstruct folio_batch fbatch;\n\tlong i, j, npages;\n\n\tif (WARN_ON(!obj->filp))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t \n\tmapping = obj->filp->f_mapping;\n\n\t \n\tWARN_ON((obj->size & (PAGE_SIZE - 1)) != 0);\n\n\tnpages = obj->size >> PAGE_SHIFT;\n\n\tpages = kvmalloc_array(npages, sizeof(struct page *), GFP_KERNEL);\n\tif (pages == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tmapping_set_unevictable(mapping);\n\n\ti = 0;\n\twhile (i < npages) {\n\t\tlong nr;\n\t\tfolio = shmem_read_folio_gfp(mapping, i,\n\t\t\t\tmapping_gfp_mask(mapping));\n\t\tif (IS_ERR(folio))\n\t\t\tgoto fail;\n\t\tnr = min(npages - i, folio_nr_pages(folio));\n\t\tfor (j = 0; j < nr; j++, i++)\n\t\t\tpages[i] = folio_file_page(folio, i);\n\n\t\t \n\t\tBUG_ON(mapping_gfp_constraint(mapping, __GFP_DMA32) &&\n\t\t\t\t(folio_pfn(folio) >= 0x00100000UL));\n\t}\n\n\treturn pages;\n\nfail:\n\tmapping_clear_unevictable(mapping);\n\tfolio_batch_init(&fbatch);\n\tj = 0;\n\twhile (j < i) {\n\t\tstruct folio *f = page_folio(pages[j]);\n\t\tif (!folio_batch_add(&fbatch, f))\n\t\t\tdrm_gem_check_release_batch(&fbatch);\n\t\tj += folio_nr_pages(f);\n\t}\n\tif (fbatch.nr)\n\t\tdrm_gem_check_release_batch(&fbatch);\n\n\tkvfree(pages);\n\treturn ERR_CAST(folio);\n}\nEXPORT_SYMBOL(drm_gem_get_pages);\n\n \nvoid drm_gem_put_pages(struct drm_gem_object *obj, struct page **pages,\n\t\tbool dirty, bool accessed)\n{\n\tint i, npages;\n\tstruct address_space *mapping;\n\tstruct folio_batch fbatch;\n\n\tmapping = file_inode(obj->filp)->i_mapping;\n\tmapping_clear_unevictable(mapping);\n\n\t \n\tWARN_ON((obj->size & (PAGE_SIZE - 1)) != 0);\n\n\tnpages = obj->size >> PAGE_SHIFT;\n\n\tfolio_batch_init(&fbatch);\n\tfor (i = 0; i < npages; i++) {\n\t\tstruct folio *folio;\n\n\t\tif (!pages[i])\n\t\t\tcontinue;\n\t\tfolio = page_folio(pages[i]);\n\n\t\tif (dirty)\n\t\t\tfolio_mark_dirty(folio);\n\n\t\tif (accessed)\n\t\t\tfolio_mark_accessed(folio);\n\n\t\t \n\t\tif (!folio_batch_add(&fbatch, folio))\n\t\t\tdrm_gem_check_release_batch(&fbatch);\n\t\ti += folio_nr_pages(folio) - 1;\n\t}\n\tif (folio_batch_count(&fbatch))\n\t\tdrm_gem_check_release_batch(&fbatch);\n\n\tkvfree(pages);\n}\nEXPORT_SYMBOL(drm_gem_put_pages);\n\nstatic int objects_lookup(struct drm_file *filp, u32 *handle, int count,\n\t\t\t  struct drm_gem_object **objs)\n{\n\tint i, ret = 0;\n\tstruct drm_gem_object *obj;\n\n\tspin_lock(&filp->table_lock);\n\n\tfor (i = 0; i < count; i++) {\n\t\t \n\t\tobj = idr_find(&filp->object_idr, handle[i]);\n\t\tif (!obj) {\n\t\t\tret = -ENOENT;\n\t\t\tbreak;\n\t\t}\n\t\tdrm_gem_object_get(obj);\n\t\tobjs[i] = obj;\n\t}\n\tspin_unlock(&filp->table_lock);\n\n\treturn ret;\n}\n\n \nint drm_gem_objects_lookup(struct drm_file *filp, void __user *bo_handles,\n\t\t\t   int count, struct drm_gem_object ***objs_out)\n{\n\tint ret;\n\tu32 *handles;\n\tstruct drm_gem_object **objs;\n\n\tif (!count)\n\t\treturn 0;\n\n\tobjs = kvmalloc_array(count, sizeof(struct drm_gem_object *),\n\t\t\t     GFP_KERNEL | __GFP_ZERO);\n\tif (!objs)\n\t\treturn -ENOMEM;\n\n\t*objs_out = objs;\n\n\thandles = kvmalloc_array(count, sizeof(u32), GFP_KERNEL);\n\tif (!handles) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (copy_from_user(handles, bo_handles, count * sizeof(u32))) {\n\t\tret = -EFAULT;\n\t\tDRM_DEBUG(\"Failed to copy in GEM handles\\n\");\n\t\tgoto out;\n\t}\n\n\tret = objects_lookup(filp, handles, count, objs);\nout:\n\tkvfree(handles);\n\treturn ret;\n\n}\nEXPORT_SYMBOL(drm_gem_objects_lookup);\n\n \nstruct drm_gem_object *\ndrm_gem_object_lookup(struct drm_file *filp, u32 handle)\n{\n\tstruct drm_gem_object *obj = NULL;\n\n\tobjects_lookup(filp, &handle, 1, &obj);\n\treturn obj;\n}\nEXPORT_SYMBOL(drm_gem_object_lookup);\n\n \nlong drm_gem_dma_resv_wait(struct drm_file *filep, u32 handle,\n\t\t\t\t    bool wait_all, unsigned long timeout)\n{\n\tlong ret;\n\tstruct drm_gem_object *obj;\n\n\tobj = drm_gem_object_lookup(filep, handle);\n\tif (!obj) {\n\t\tDRM_DEBUG(\"Failed to look up GEM BO %d\\n\", handle);\n\t\treturn -EINVAL;\n\t}\n\n\tret = dma_resv_wait_timeout(obj->resv, dma_resv_usage_rw(wait_all),\n\t\t\t\t    true, timeout);\n\tif (ret == 0)\n\t\tret = -ETIME;\n\telse if (ret > 0)\n\t\tret = 0;\n\n\tdrm_gem_object_put(obj);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_dma_resv_wait);\n\n \nint\ndrm_gem_close_ioctl(struct drm_device *dev, void *data,\n\t\t    struct drm_file *file_priv)\n{\n\tstruct drm_gem_close *args = data;\n\tint ret;\n\n\tif (!drm_core_check_feature(dev, DRIVER_GEM))\n\t\treturn -EOPNOTSUPP;\n\n\tret = drm_gem_handle_delete(file_priv, args->handle);\n\n\treturn ret;\n}\n\n \nint\ndrm_gem_flink_ioctl(struct drm_device *dev, void *data,\n\t\t    struct drm_file *file_priv)\n{\n\tstruct drm_gem_flink *args = data;\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\tif (!drm_core_check_feature(dev, DRIVER_GEM))\n\t\treturn -EOPNOTSUPP;\n\n\tobj = drm_gem_object_lookup(file_priv, args->handle);\n\tif (obj == NULL)\n\t\treturn -ENOENT;\n\n\tmutex_lock(&dev->object_name_lock);\n\t \n\tif (obj->handle_count == 0) {\n\t\tret = -ENOENT;\n\t\tgoto err;\n\t}\n\n\tif (!obj->name) {\n\t\tret = idr_alloc(&dev->object_name_idr, obj, 1, 0, GFP_KERNEL);\n\t\tif (ret < 0)\n\t\t\tgoto err;\n\n\t\tobj->name = ret;\n\t}\n\n\targs->name = (uint64_t) obj->name;\n\tret = 0;\n\nerr:\n\tmutex_unlock(&dev->object_name_lock);\n\tdrm_gem_object_put(obj);\n\treturn ret;\n}\n\n \nint\ndrm_gem_open_ioctl(struct drm_device *dev, void *data,\n\t\t   struct drm_file *file_priv)\n{\n\tstruct drm_gem_open *args = data;\n\tstruct drm_gem_object *obj;\n\tint ret;\n\tu32 handle;\n\n\tif (!drm_core_check_feature(dev, DRIVER_GEM))\n\t\treturn -EOPNOTSUPP;\n\n\tmutex_lock(&dev->object_name_lock);\n\tobj = idr_find(&dev->object_name_idr, (int) args->name);\n\tif (obj) {\n\t\tdrm_gem_object_get(obj);\n\t} else {\n\t\tmutex_unlock(&dev->object_name_lock);\n\t\treturn -ENOENT;\n\t}\n\n\t \n\tret = drm_gem_handle_create_tail(file_priv, obj, &handle);\n\tif (ret)\n\t\tgoto err;\n\n\targs->handle = handle;\n\targs->size = obj->size;\n\nerr:\n\tdrm_gem_object_put(obj);\n\treturn ret;\n}\n\n \nvoid\ndrm_gem_open(struct drm_device *dev, struct drm_file *file_private)\n{\n\tidr_init_base(&file_private->object_idr, 1);\n\tspin_lock_init(&file_private->table_lock);\n}\n\n \nvoid\ndrm_gem_release(struct drm_device *dev, struct drm_file *file_private)\n{\n\tidr_for_each(&file_private->object_idr,\n\t\t     &drm_gem_object_release_handle, file_private);\n\tidr_destroy(&file_private->object_idr);\n}\n\n \nvoid\ndrm_gem_object_release(struct drm_gem_object *obj)\n{\n\tif (obj->filp)\n\t\tfput(obj->filp);\n\n\tdrm_gem_private_object_fini(obj);\n\n\tdrm_gem_free_mmap_offset(obj);\n\tdrm_gem_lru_remove(obj);\n}\nEXPORT_SYMBOL(drm_gem_object_release);\n\n \nvoid\ndrm_gem_object_free(struct kref *kref)\n{\n\tstruct drm_gem_object *obj =\n\t\tcontainer_of(kref, struct drm_gem_object, refcount);\n\n\tif (WARN_ON(!obj->funcs->free))\n\t\treturn;\n\n\tobj->funcs->free(obj);\n}\nEXPORT_SYMBOL(drm_gem_object_free);\n\n \nvoid drm_gem_vm_open(struct vm_area_struct *vma)\n{\n\tstruct drm_gem_object *obj = vma->vm_private_data;\n\n\tdrm_gem_object_get(obj);\n}\nEXPORT_SYMBOL(drm_gem_vm_open);\n\n \nvoid drm_gem_vm_close(struct vm_area_struct *vma)\n{\n\tstruct drm_gem_object *obj = vma->vm_private_data;\n\n\tdrm_gem_object_put(obj);\n}\nEXPORT_SYMBOL(drm_gem_vm_close);\n\n \nint drm_gem_mmap_obj(struct drm_gem_object *obj, unsigned long obj_size,\n\t\t     struct vm_area_struct *vma)\n{\n\tint ret;\n\n\t \n\tif (obj_size < vma->vm_end - vma->vm_start)\n\t\treturn -EINVAL;\n\n\t \n\tdrm_gem_object_get(obj);\n\n\tvma->vm_private_data = obj;\n\tvma->vm_ops = obj->funcs->vm_ops;\n\n\tif (obj->funcs->mmap) {\n\t\tret = obj->funcs->mmap(obj, vma);\n\t\tif (ret)\n\t\t\tgoto err_drm_gem_object_put;\n\t\tWARN_ON(!(vma->vm_flags & VM_DONTEXPAND));\n\t} else {\n\t\tif (!vma->vm_ops) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_drm_gem_object_put;\n\t\t}\n\n\t\tvm_flags_set(vma, VM_IO | VM_PFNMAP | VM_DONTEXPAND | VM_DONTDUMP);\n\t\tvma->vm_page_prot = pgprot_writecombine(vm_get_page_prot(vma->vm_flags));\n\t\tvma->vm_page_prot = pgprot_decrypted(vma->vm_page_prot);\n\t}\n\n\treturn 0;\n\nerr_drm_gem_object_put:\n\tdrm_gem_object_put(obj);\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_mmap_obj);\n\n \nint drm_gem_mmap(struct file *filp, struct vm_area_struct *vma)\n{\n\tstruct drm_file *priv = filp->private_data;\n\tstruct drm_device *dev = priv->minor->dev;\n\tstruct drm_gem_object *obj = NULL;\n\tstruct drm_vma_offset_node *node;\n\tint ret;\n\n\tif (drm_dev_is_unplugged(dev))\n\t\treturn -ENODEV;\n\n\tdrm_vma_offset_lock_lookup(dev->vma_offset_manager);\n\tnode = drm_vma_offset_exact_lookup_locked(dev->vma_offset_manager,\n\t\t\t\t\t\t  vma->vm_pgoff,\n\t\t\t\t\t\t  vma_pages(vma));\n\tif (likely(node)) {\n\t\tobj = container_of(node, struct drm_gem_object, vma_node);\n\t\t \n\t\tif (!kref_get_unless_zero(&obj->refcount))\n\t\t\tobj = NULL;\n\t}\n\tdrm_vma_offset_unlock_lookup(dev->vma_offset_manager);\n\n\tif (!obj)\n\t\treturn -EINVAL;\n\n\tif (!drm_vma_node_is_allowed(node, priv)) {\n\t\tdrm_gem_object_put(obj);\n\t\treturn -EACCES;\n\t}\n\n\tret = drm_gem_mmap_obj(obj, drm_vma_node_size(node) << PAGE_SHIFT,\n\t\t\t       vma);\n\n\tdrm_gem_object_put(obj);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_mmap);\n\nvoid drm_gem_print_info(struct drm_printer *p, unsigned int indent,\n\t\t\tconst struct drm_gem_object *obj)\n{\n\tdrm_printf_indent(p, indent, \"name=%d\\n\", obj->name);\n\tdrm_printf_indent(p, indent, \"refcount=%u\\n\",\n\t\t\t  kref_read(&obj->refcount));\n\tdrm_printf_indent(p, indent, \"start=%08lx\\n\",\n\t\t\t  drm_vma_node_start(&obj->vma_node));\n\tdrm_printf_indent(p, indent, \"size=%zu\\n\", obj->size);\n\tdrm_printf_indent(p, indent, \"imported=%s\\n\",\n\t\t\t  str_yes_no(obj->import_attach));\n\n\tif (obj->funcs->print_info)\n\t\tobj->funcs->print_info(p, indent, obj);\n}\n\nint drm_gem_pin(struct drm_gem_object *obj)\n{\n\tif (obj->funcs->pin)\n\t\treturn obj->funcs->pin(obj);\n\n\treturn 0;\n}\n\nvoid drm_gem_unpin(struct drm_gem_object *obj)\n{\n\tif (obj->funcs->unpin)\n\t\tobj->funcs->unpin(obj);\n}\n\nint drm_gem_vmap(struct drm_gem_object *obj, struct iosys_map *map)\n{\n\tint ret;\n\n\tdma_resv_assert_held(obj->resv);\n\n\tif (!obj->funcs->vmap)\n\t\treturn -EOPNOTSUPP;\n\n\tret = obj->funcs->vmap(obj, map);\n\tif (ret)\n\t\treturn ret;\n\telse if (iosys_map_is_null(map))\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_gem_vmap);\n\nvoid drm_gem_vunmap(struct drm_gem_object *obj, struct iosys_map *map)\n{\n\tdma_resv_assert_held(obj->resv);\n\n\tif (iosys_map_is_null(map))\n\t\treturn;\n\n\tif (obj->funcs->vunmap)\n\t\tobj->funcs->vunmap(obj, map);\n\n\t \n\tiosys_map_clear(map);\n}\nEXPORT_SYMBOL(drm_gem_vunmap);\n\nint drm_gem_vmap_unlocked(struct drm_gem_object *obj, struct iosys_map *map)\n{\n\tint ret;\n\n\tdma_resv_lock(obj->resv, NULL);\n\tret = drm_gem_vmap(obj, map);\n\tdma_resv_unlock(obj->resv);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_vmap_unlocked);\n\nvoid drm_gem_vunmap_unlocked(struct drm_gem_object *obj, struct iosys_map *map)\n{\n\tdma_resv_lock(obj->resv, NULL);\n\tdrm_gem_vunmap(obj, map);\n\tdma_resv_unlock(obj->resv);\n}\nEXPORT_SYMBOL(drm_gem_vunmap_unlocked);\n\n \nint\ndrm_gem_lock_reservations(struct drm_gem_object **objs, int count,\n\t\t\t  struct ww_acquire_ctx *acquire_ctx)\n{\n\tint contended = -1;\n\tint i, ret;\n\n\tww_acquire_init(acquire_ctx, &reservation_ww_class);\n\nretry:\n\tif (contended != -1) {\n\t\tstruct drm_gem_object *obj = objs[contended];\n\n\t\tret = dma_resv_lock_slow_interruptible(obj->resv,\n\t\t\t\t\t\t\t\t acquire_ctx);\n\t\tif (ret) {\n\t\t\tww_acquire_fini(acquire_ctx);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tfor (i = 0; i < count; i++) {\n\t\tif (i == contended)\n\t\t\tcontinue;\n\n\t\tret = dma_resv_lock_interruptible(objs[i]->resv,\n\t\t\t\t\t\t\t    acquire_ctx);\n\t\tif (ret) {\n\t\t\tint j;\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tdma_resv_unlock(objs[j]->resv);\n\n\t\t\tif (contended != -1 && contended >= i)\n\t\t\t\tdma_resv_unlock(objs[contended]->resv);\n\n\t\t\tif (ret == -EDEADLK) {\n\t\t\t\tcontended = i;\n\t\t\t\tgoto retry;\n\t\t\t}\n\n\t\t\tww_acquire_fini(acquire_ctx);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tww_acquire_done(acquire_ctx);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_gem_lock_reservations);\n\nvoid\ndrm_gem_unlock_reservations(struct drm_gem_object **objs, int count,\n\t\t\t    struct ww_acquire_ctx *acquire_ctx)\n{\n\tint i;\n\n\tfor (i = 0; i < count; i++)\n\t\tdma_resv_unlock(objs[i]->resv);\n\n\tww_acquire_fini(acquire_ctx);\n}\nEXPORT_SYMBOL(drm_gem_unlock_reservations);\n\n \nvoid\ndrm_gem_lru_init(struct drm_gem_lru *lru, struct mutex *lock)\n{\n\tlru->lock = lock;\n\tlru->count = 0;\n\tINIT_LIST_HEAD(&lru->list);\n}\nEXPORT_SYMBOL(drm_gem_lru_init);\n\nstatic void\ndrm_gem_lru_remove_locked(struct drm_gem_object *obj)\n{\n\tobj->lru->count -= obj->size >> PAGE_SHIFT;\n\tWARN_ON(obj->lru->count < 0);\n\tlist_del(&obj->lru_node);\n\tobj->lru = NULL;\n}\n\n \nvoid\ndrm_gem_lru_remove(struct drm_gem_object *obj)\n{\n\tstruct drm_gem_lru *lru = obj->lru;\n\n\tif (!lru)\n\t\treturn;\n\n\tmutex_lock(lru->lock);\n\tdrm_gem_lru_remove_locked(obj);\n\tmutex_unlock(lru->lock);\n}\nEXPORT_SYMBOL(drm_gem_lru_remove);\n\n \nvoid\ndrm_gem_lru_move_tail_locked(struct drm_gem_lru *lru, struct drm_gem_object *obj)\n{\n\tlockdep_assert_held_once(lru->lock);\n\n\tif (obj->lru)\n\t\tdrm_gem_lru_remove_locked(obj);\n\n\tlru->count += obj->size >> PAGE_SHIFT;\n\tlist_add_tail(&obj->lru_node, &lru->list);\n\tobj->lru = lru;\n}\nEXPORT_SYMBOL(drm_gem_lru_move_tail_locked);\n\n \nvoid\ndrm_gem_lru_move_tail(struct drm_gem_lru *lru, struct drm_gem_object *obj)\n{\n\tmutex_lock(lru->lock);\n\tdrm_gem_lru_move_tail_locked(lru, obj);\n\tmutex_unlock(lru->lock);\n}\nEXPORT_SYMBOL(drm_gem_lru_move_tail);\n\n \nunsigned long\ndrm_gem_lru_scan(struct drm_gem_lru *lru,\n\t\t unsigned int nr_to_scan,\n\t\t unsigned long *remaining,\n\t\t bool (*shrink)(struct drm_gem_object *obj))\n{\n\tstruct drm_gem_lru still_in_lru;\n\tstruct drm_gem_object *obj;\n\tunsigned freed = 0;\n\n\tdrm_gem_lru_init(&still_in_lru, lru->lock);\n\n\tmutex_lock(lru->lock);\n\n\twhile (freed < nr_to_scan) {\n\t\tobj = list_first_entry_or_null(&lru->list, typeof(*obj), lru_node);\n\n\t\tif (!obj)\n\t\t\tbreak;\n\n\t\tdrm_gem_lru_move_tail_locked(&still_in_lru, obj);\n\n\t\t \n\t\tif (!kref_get_unless_zero(&obj->refcount))\n\t\t\tcontinue;\n\n\t\t \n\t\tmutex_unlock(lru->lock);\n\n\t\t \n\t\tif (!dma_resv_trylock(obj->resv)) {\n\t\t\t*remaining += obj->size >> PAGE_SHIFT;\n\t\t\tgoto tail;\n\t\t}\n\n\t\tif (shrink(obj)) {\n\t\t\tfreed += obj->size >> PAGE_SHIFT;\n\n\t\t\t \n\t\t\tWARN_ON(obj->lru == &still_in_lru);\n\t\t\tWARN_ON(obj->lru == lru);\n\t\t}\n\n\t\tdma_resv_unlock(obj->resv);\n\ntail:\n\t\tdrm_gem_object_put(obj);\n\t\tmutex_lock(lru->lock);\n\t}\n\n\t \n\tlist_for_each_entry (obj, &still_in_lru.list, lru_node)\n\t\tobj->lru = lru;\n\tlist_splice_tail(&still_in_lru.list, &lru->list);\n\tlru->count += still_in_lru.count;\n\n\tmutex_unlock(lru->lock);\n\n\treturn freed;\n}\nEXPORT_SYMBOL(drm_gem_lru_scan);\n\n \nint drm_gem_evict(struct drm_gem_object *obj)\n{\n\tdma_resv_assert_held(obj->resv);\n\n\tif (!dma_resv_test_signaled(obj->resv, DMA_RESV_USAGE_READ))\n\t\treturn -EBUSY;\n\n\tif (obj->funcs->evict)\n\t\treturn obj->funcs->evict(obj);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_gem_evict);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}