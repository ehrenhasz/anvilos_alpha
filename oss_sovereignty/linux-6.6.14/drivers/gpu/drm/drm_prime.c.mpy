{
  "module_name": "drm_prime.c",
  "hash_id": "17301ef3af99d8dd800b7b3015e53a06c6fe3da7bea5ad1197cb902570da32e1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/drm_prime.c",
  "human_readable_source": " \n\n#include <linux/export.h>\n#include <linux/dma-buf.h>\n#include <linux/rbtree.h>\n#include <linux/module.h>\n\n#include <drm/drm.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_file.h>\n#include <drm/drm_framebuffer.h>\n#include <drm/drm_gem.h>\n#include <drm/drm_prime.h>\n\n#include \"drm_internal.h\"\n\nMODULE_IMPORT_NS(DMA_BUF);\n\n \n\nstruct drm_prime_member {\n\tstruct dma_buf *dma_buf;\n\tuint32_t handle;\n\n\tstruct rb_node dmabuf_rb;\n\tstruct rb_node handle_rb;\n};\n\nstatic int drm_prime_add_buf_handle(struct drm_prime_file_private *prime_fpriv,\n\t\t\t\t    struct dma_buf *dma_buf, uint32_t handle)\n{\n\tstruct drm_prime_member *member;\n\tstruct rb_node **p, *rb;\n\n\tmember = kmalloc(sizeof(*member), GFP_KERNEL);\n\tif (!member)\n\t\treturn -ENOMEM;\n\n\tget_dma_buf(dma_buf);\n\tmember->dma_buf = dma_buf;\n\tmember->handle = handle;\n\n\trb = NULL;\n\tp = &prime_fpriv->dmabufs.rb_node;\n\twhile (*p) {\n\t\tstruct drm_prime_member *pos;\n\n\t\trb = *p;\n\t\tpos = rb_entry(rb, struct drm_prime_member, dmabuf_rb);\n\t\tif (dma_buf > pos->dma_buf)\n\t\t\tp = &rb->rb_right;\n\t\telse\n\t\t\tp = &rb->rb_left;\n\t}\n\trb_link_node(&member->dmabuf_rb, rb, p);\n\trb_insert_color(&member->dmabuf_rb, &prime_fpriv->dmabufs);\n\n\trb = NULL;\n\tp = &prime_fpriv->handles.rb_node;\n\twhile (*p) {\n\t\tstruct drm_prime_member *pos;\n\n\t\trb = *p;\n\t\tpos = rb_entry(rb, struct drm_prime_member, handle_rb);\n\t\tif (handle > pos->handle)\n\t\t\tp = &rb->rb_right;\n\t\telse\n\t\t\tp = &rb->rb_left;\n\t}\n\trb_link_node(&member->handle_rb, rb, p);\n\trb_insert_color(&member->handle_rb, &prime_fpriv->handles);\n\n\treturn 0;\n}\n\nstatic struct dma_buf *drm_prime_lookup_buf_by_handle(struct drm_prime_file_private *prime_fpriv,\n\t\t\t\t\t\t      uint32_t handle)\n{\n\tstruct rb_node *rb;\n\n\trb = prime_fpriv->handles.rb_node;\n\twhile (rb) {\n\t\tstruct drm_prime_member *member;\n\n\t\tmember = rb_entry(rb, struct drm_prime_member, handle_rb);\n\t\tif (member->handle == handle)\n\t\t\treturn member->dma_buf;\n\t\telse if (member->handle < handle)\n\t\t\trb = rb->rb_right;\n\t\telse\n\t\t\trb = rb->rb_left;\n\t}\n\n\treturn NULL;\n}\n\nstatic int drm_prime_lookup_buf_handle(struct drm_prime_file_private *prime_fpriv,\n\t\t\t\t       struct dma_buf *dma_buf,\n\t\t\t\t       uint32_t *handle)\n{\n\tstruct rb_node *rb;\n\n\trb = prime_fpriv->dmabufs.rb_node;\n\twhile (rb) {\n\t\tstruct drm_prime_member *member;\n\n\t\tmember = rb_entry(rb, struct drm_prime_member, dmabuf_rb);\n\t\tif (member->dma_buf == dma_buf) {\n\t\t\t*handle = member->handle;\n\t\t\treturn 0;\n\t\t} else if (member->dma_buf < dma_buf) {\n\t\t\trb = rb->rb_right;\n\t\t} else {\n\t\t\trb = rb->rb_left;\n\t\t}\n\t}\n\n\treturn -ENOENT;\n}\n\nvoid drm_prime_remove_buf_handle(struct drm_prime_file_private *prime_fpriv,\n\t\t\t\t uint32_t handle)\n{\n\tstruct rb_node *rb;\n\n\tmutex_lock(&prime_fpriv->lock);\n\n\trb = prime_fpriv->handles.rb_node;\n\twhile (rb) {\n\t\tstruct drm_prime_member *member;\n\n\t\tmember = rb_entry(rb, struct drm_prime_member, handle_rb);\n\t\tif (member->handle == handle) {\n\t\t\trb_erase(&member->handle_rb, &prime_fpriv->handles);\n\t\t\trb_erase(&member->dmabuf_rb, &prime_fpriv->dmabufs);\n\n\t\t\tdma_buf_put(member->dma_buf);\n\t\t\tkfree(member);\n\t\t\tbreak;\n\t\t} else if (member->handle < handle) {\n\t\t\trb = rb->rb_right;\n\t\t} else {\n\t\t\trb = rb->rb_left;\n\t\t}\n\t}\n\n\tmutex_unlock(&prime_fpriv->lock);\n}\n\nvoid drm_prime_init_file_private(struct drm_prime_file_private *prime_fpriv)\n{\n\tmutex_init(&prime_fpriv->lock);\n\tprime_fpriv->dmabufs = RB_ROOT;\n\tprime_fpriv->handles = RB_ROOT;\n}\n\nvoid drm_prime_destroy_file_private(struct drm_prime_file_private *prime_fpriv)\n{\n\t \n\tWARN_ON(!RB_EMPTY_ROOT(&prime_fpriv->dmabufs));\n}\n\n \nstruct dma_buf *drm_gem_dmabuf_export(struct drm_device *dev,\n\t\t\t\t      struct dma_buf_export_info *exp_info)\n{\n\tstruct drm_gem_object *obj = exp_info->priv;\n\tstruct dma_buf *dma_buf;\n\n\tdma_buf = dma_buf_export(exp_info);\n\tif (IS_ERR(dma_buf))\n\t\treturn dma_buf;\n\n\tdrm_dev_get(dev);\n\tdrm_gem_object_get(obj);\n\tdma_buf->file->f_mapping = obj->dev->anon_inode->i_mapping;\n\n\treturn dma_buf;\n}\nEXPORT_SYMBOL(drm_gem_dmabuf_export);\n\n \nvoid drm_gem_dmabuf_release(struct dma_buf *dma_buf)\n{\n\tstruct drm_gem_object *obj = dma_buf->priv;\n\tstruct drm_device *dev = obj->dev;\n\n\t \n\tdrm_gem_object_put(obj);\n\n\tdrm_dev_put(dev);\n}\nEXPORT_SYMBOL(drm_gem_dmabuf_release);\n\n \nint drm_gem_prime_fd_to_handle(struct drm_device *dev,\n\t\t\t       struct drm_file *file_priv, int prime_fd,\n\t\t\t       uint32_t *handle)\n{\n\tstruct dma_buf *dma_buf;\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\tdma_buf = dma_buf_get(prime_fd);\n\tif (IS_ERR(dma_buf))\n\t\treturn PTR_ERR(dma_buf);\n\n\tmutex_lock(&file_priv->prime.lock);\n\n\tret = drm_prime_lookup_buf_handle(&file_priv->prime,\n\t\t\tdma_buf, handle);\n\tif (ret == 0)\n\t\tgoto out_put;\n\n\t \n\tmutex_lock(&dev->object_name_lock);\n\tif (dev->driver->gem_prime_import)\n\t\tobj = dev->driver->gem_prime_import(dev, dma_buf);\n\telse\n\t\tobj = drm_gem_prime_import(dev, dma_buf);\n\tif (IS_ERR(obj)) {\n\t\tret = PTR_ERR(obj);\n\t\tgoto out_unlock;\n\t}\n\n\tif (obj->dma_buf) {\n\t\tWARN_ON(obj->dma_buf != dma_buf);\n\t} else {\n\t\tobj->dma_buf = dma_buf;\n\t\tget_dma_buf(dma_buf);\n\t}\n\n\t \n\tret = drm_gem_handle_create_tail(file_priv, obj, handle);\n\tdrm_gem_object_put(obj);\n\tif (ret)\n\t\tgoto out_put;\n\n\tret = drm_prime_add_buf_handle(&file_priv->prime,\n\t\t\tdma_buf, *handle);\n\tmutex_unlock(&file_priv->prime.lock);\n\tif (ret)\n\t\tgoto fail;\n\n\tdma_buf_put(dma_buf);\n\n\treturn 0;\n\nfail:\n\t \n\tdrm_gem_handle_delete(file_priv, *handle);\n\tdma_buf_put(dma_buf);\n\treturn ret;\n\nout_unlock:\n\tmutex_unlock(&dev->object_name_lock);\nout_put:\n\tmutex_unlock(&file_priv->prime.lock);\n\tdma_buf_put(dma_buf);\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_prime_fd_to_handle);\n\nint drm_prime_fd_to_handle_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t struct drm_file *file_priv)\n{\n\tstruct drm_prime_handle *args = data;\n\n\tif (dev->driver->prime_fd_to_handle) {\n\t\treturn dev->driver->prime_fd_to_handle(dev, file_priv, args->fd,\n\t\t\t\t\t\t       &args->handle);\n\t}\n\n\treturn drm_gem_prime_fd_to_handle(dev, file_priv, args->fd, &args->handle);\n}\n\nstatic struct dma_buf *export_and_register_object(struct drm_device *dev,\n\t\t\t\t\t\t  struct drm_gem_object *obj,\n\t\t\t\t\t\t  uint32_t flags)\n{\n\tstruct dma_buf *dmabuf;\n\n\t \n\tif (obj->handle_count == 0) {\n\t\tdmabuf = ERR_PTR(-ENOENT);\n\t\treturn dmabuf;\n\t}\n\n\tif (obj->funcs && obj->funcs->export)\n\t\tdmabuf = obj->funcs->export(obj, flags);\n\telse\n\t\tdmabuf = drm_gem_prime_export(obj, flags);\n\tif (IS_ERR(dmabuf)) {\n\t\t \n\t\treturn dmabuf;\n\t}\n\n\t \n\tobj->dma_buf = dmabuf;\n\tget_dma_buf(obj->dma_buf);\n\n\treturn dmabuf;\n}\n\n \nint drm_gem_prime_handle_to_fd(struct drm_device *dev,\n\t\t\t       struct drm_file *file_priv, uint32_t handle,\n\t\t\t       uint32_t flags,\n\t\t\t       int *prime_fd)\n{\n\tstruct drm_gem_object *obj;\n\tint ret = 0;\n\tstruct dma_buf *dmabuf;\n\n\tmutex_lock(&file_priv->prime.lock);\n\tobj = drm_gem_object_lookup(file_priv, handle);\n\tif (!obj)  {\n\t\tret = -ENOENT;\n\t\tgoto out_unlock;\n\t}\n\n\tdmabuf = drm_prime_lookup_buf_by_handle(&file_priv->prime, handle);\n\tif (dmabuf) {\n\t\tget_dma_buf(dmabuf);\n\t\tgoto out_have_handle;\n\t}\n\n\tmutex_lock(&dev->object_name_lock);\n\t \n\tif (obj->import_attach) {\n\t\tdmabuf = obj->import_attach->dmabuf;\n\t\tget_dma_buf(dmabuf);\n\t\tgoto out_have_obj;\n\t}\n\n\tif (obj->dma_buf) {\n\t\tget_dma_buf(obj->dma_buf);\n\t\tdmabuf = obj->dma_buf;\n\t\tgoto out_have_obj;\n\t}\n\n\tdmabuf = export_and_register_object(dev, obj, flags);\n\tif (IS_ERR(dmabuf)) {\n\t\t \n\t\tret = PTR_ERR(dmabuf);\n\t\tmutex_unlock(&dev->object_name_lock);\n\t\tgoto out;\n\t}\n\nout_have_obj:\n\t \n\tret = drm_prime_add_buf_handle(&file_priv->prime,\n\t\t\t\t       dmabuf, handle);\n\tmutex_unlock(&dev->object_name_lock);\n\tif (ret)\n\t\tgoto fail_put_dmabuf;\n\nout_have_handle:\n\tret = dma_buf_fd(dmabuf, flags);\n\t \n\tif (ret < 0) {\n\t\tgoto fail_put_dmabuf;\n\t} else {\n\t\t*prime_fd = ret;\n\t\tret = 0;\n\t}\n\n\tgoto out;\n\nfail_put_dmabuf:\n\tdma_buf_put(dmabuf);\nout:\n\tdrm_gem_object_put(obj);\nout_unlock:\n\tmutex_unlock(&file_priv->prime.lock);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_prime_handle_to_fd);\n\nint drm_prime_handle_to_fd_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t struct drm_file *file_priv)\n{\n\tstruct drm_prime_handle *args = data;\n\n\t \n\tif (args->flags & ~(DRM_CLOEXEC | DRM_RDWR))\n\t\treturn -EINVAL;\n\n\tif (dev->driver->prime_handle_to_fd) {\n\t\treturn dev->driver->prime_handle_to_fd(dev, file_priv,\n\t\t\t\t\t\t       args->handle, args->flags,\n\t\t\t\t\t\t       &args->fd);\n\t}\n\treturn drm_gem_prime_handle_to_fd(dev, file_priv, args->handle,\n\t\t\t\t\t  args->flags, &args->fd);\n}\n\n \n\n \nint drm_gem_map_attach(struct dma_buf *dma_buf,\n\t\t       struct dma_buf_attachment *attach)\n{\n\tstruct drm_gem_object *obj = dma_buf->priv;\n\n\tif (!obj->funcs->get_sg_table)\n\t\treturn -ENOSYS;\n\n\treturn drm_gem_pin(obj);\n}\nEXPORT_SYMBOL(drm_gem_map_attach);\n\n \nvoid drm_gem_map_detach(struct dma_buf *dma_buf,\n\t\t\tstruct dma_buf_attachment *attach)\n{\n\tstruct drm_gem_object *obj = dma_buf->priv;\n\n\tdrm_gem_unpin(obj);\n}\nEXPORT_SYMBOL(drm_gem_map_detach);\n\n \nstruct sg_table *drm_gem_map_dma_buf(struct dma_buf_attachment *attach,\n\t\t\t\t     enum dma_data_direction dir)\n{\n\tstruct drm_gem_object *obj = attach->dmabuf->priv;\n\tstruct sg_table *sgt;\n\tint ret;\n\n\tif (WARN_ON(dir == DMA_NONE))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif (WARN_ON(!obj->funcs->get_sg_table))\n\t\treturn ERR_PTR(-ENOSYS);\n\n\tsgt = obj->funcs->get_sg_table(obj);\n\tif (IS_ERR(sgt))\n\t\treturn sgt;\n\n\tret = dma_map_sgtable(attach->dev, sgt, dir,\n\t\t\t      DMA_ATTR_SKIP_CPU_SYNC);\n\tif (ret) {\n\t\tsg_free_table(sgt);\n\t\tkfree(sgt);\n\t\tsgt = ERR_PTR(ret);\n\t}\n\n\treturn sgt;\n}\nEXPORT_SYMBOL(drm_gem_map_dma_buf);\n\n \nvoid drm_gem_unmap_dma_buf(struct dma_buf_attachment *attach,\n\t\t\t   struct sg_table *sgt,\n\t\t\t   enum dma_data_direction dir)\n{\n\tif (!sgt)\n\t\treturn;\n\n\tdma_unmap_sgtable(attach->dev, sgt, dir, DMA_ATTR_SKIP_CPU_SYNC);\n\tsg_free_table(sgt);\n\tkfree(sgt);\n}\nEXPORT_SYMBOL(drm_gem_unmap_dma_buf);\n\n \nint drm_gem_dmabuf_vmap(struct dma_buf *dma_buf, struct iosys_map *map)\n{\n\tstruct drm_gem_object *obj = dma_buf->priv;\n\n\treturn drm_gem_vmap(obj, map);\n}\nEXPORT_SYMBOL(drm_gem_dmabuf_vmap);\n\n \nvoid drm_gem_dmabuf_vunmap(struct dma_buf *dma_buf, struct iosys_map *map)\n{\n\tstruct drm_gem_object *obj = dma_buf->priv;\n\n\tdrm_gem_vunmap(obj, map);\n}\nEXPORT_SYMBOL(drm_gem_dmabuf_vunmap);\n\n \nint drm_gem_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma)\n{\n\tstruct drm_file *priv;\n\tstruct file *fil;\n\tint ret;\n\n\t \n\tvma->vm_pgoff += drm_vma_node_start(&obj->vma_node);\n\n\tif (obj->funcs && obj->funcs->mmap) {\n\t\tvma->vm_ops = obj->funcs->vm_ops;\n\n\t\tdrm_gem_object_get(obj);\n\t\tret = obj->funcs->mmap(obj, vma);\n\t\tif (ret) {\n\t\t\tdrm_gem_object_put(obj);\n\t\t\treturn ret;\n\t\t}\n\t\tvma->vm_private_data = obj;\n\t\treturn 0;\n\t}\n\n\tpriv = kzalloc(sizeof(*priv), GFP_KERNEL);\n\tfil = kzalloc(sizeof(*fil), GFP_KERNEL);\n\tif (!priv || !fil) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\t \n\tpriv->minor = obj->dev->primary;\n\tfil->private_data = priv;\n\n\tret = drm_vma_node_allow(&obj->vma_node, priv);\n\tif (ret)\n\t\tgoto out;\n\n\tret = obj->dev->driver->fops->mmap(fil, vma);\n\n\tdrm_vma_node_revoke(&obj->vma_node, priv);\nout:\n\tkfree(priv);\n\tkfree(fil);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(drm_gem_prime_mmap);\n\n \nint drm_gem_dmabuf_mmap(struct dma_buf *dma_buf, struct vm_area_struct *vma)\n{\n\tstruct drm_gem_object *obj = dma_buf->priv;\n\n\treturn drm_gem_prime_mmap(obj, vma);\n}\nEXPORT_SYMBOL(drm_gem_dmabuf_mmap);\n\nstatic const struct dma_buf_ops drm_gem_prime_dmabuf_ops =  {\n\t.cache_sgt_mapping = true,\n\t.attach = drm_gem_map_attach,\n\t.detach = drm_gem_map_detach,\n\t.map_dma_buf = drm_gem_map_dma_buf,\n\t.unmap_dma_buf = drm_gem_unmap_dma_buf,\n\t.release = drm_gem_dmabuf_release,\n\t.mmap = drm_gem_dmabuf_mmap,\n\t.vmap = drm_gem_dmabuf_vmap,\n\t.vunmap = drm_gem_dmabuf_vunmap,\n};\n\n \nstruct sg_table *drm_prime_pages_to_sg(struct drm_device *dev,\n\t\t\t\t       struct page **pages, unsigned int nr_pages)\n{\n\tstruct sg_table *sg;\n\tsize_t max_segment = 0;\n\tint err;\n\n\tsg = kmalloc(sizeof(struct sg_table), GFP_KERNEL);\n\tif (!sg)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (dev)\n\t\tmax_segment = dma_max_mapping_size(dev->dev);\n\tif (max_segment == 0)\n\t\tmax_segment = UINT_MAX;\n\terr = sg_alloc_table_from_pages_segment(sg, pages, nr_pages, 0,\n\t\t\t\t\t\tnr_pages << PAGE_SHIFT,\n\t\t\t\t\t\tmax_segment, GFP_KERNEL);\n\tif (err) {\n\t\tkfree(sg);\n\t\tsg = ERR_PTR(err);\n\t}\n\treturn sg;\n}\nEXPORT_SYMBOL(drm_prime_pages_to_sg);\n\n \nunsigned long drm_prime_get_contiguous_size(struct sg_table *sgt)\n{\n\tdma_addr_t expected = sg_dma_address(sgt->sgl);\n\tstruct scatterlist *sg;\n\tunsigned long size = 0;\n\tint i;\n\n\tfor_each_sgtable_dma_sg(sgt, sg, i) {\n\t\tunsigned int len = sg_dma_len(sg);\n\n\t\tif (!len)\n\t\t\tbreak;\n\t\tif (sg_dma_address(sg) != expected)\n\t\t\tbreak;\n\t\texpected += len;\n\t\tsize += len;\n\t}\n\treturn size;\n}\nEXPORT_SYMBOL(drm_prime_get_contiguous_size);\n\n \nstruct dma_buf *drm_gem_prime_export(struct drm_gem_object *obj,\n\t\t\t\t     int flags)\n{\n\tstruct drm_device *dev = obj->dev;\n\tstruct dma_buf_export_info exp_info = {\n\t\t.exp_name = KBUILD_MODNAME,  \n\t\t.owner = dev->driver->fops->owner,\n\t\t.ops = &drm_gem_prime_dmabuf_ops,\n\t\t.size = obj->size,\n\t\t.flags = flags,\n\t\t.priv = obj,\n\t\t.resv = obj->resv,\n\t};\n\n\treturn drm_gem_dmabuf_export(dev, &exp_info);\n}\nEXPORT_SYMBOL(drm_gem_prime_export);\n\n \nstruct drm_gem_object *drm_gem_prime_import_dev(struct drm_device *dev,\n\t\t\t\t\t    struct dma_buf *dma_buf,\n\t\t\t\t\t    struct device *attach_dev)\n{\n\tstruct dma_buf_attachment *attach;\n\tstruct sg_table *sgt;\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\tif (dma_buf->ops == &drm_gem_prime_dmabuf_ops) {\n\t\tobj = dma_buf->priv;\n\t\tif (obj->dev == dev) {\n\t\t\t \n\t\t\tdrm_gem_object_get(obj);\n\t\t\treturn obj;\n\t\t}\n\t}\n\n\tif (!dev->driver->gem_prime_import_sg_table)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tattach = dma_buf_attach(dma_buf, attach_dev);\n\tif (IS_ERR(attach))\n\t\treturn ERR_CAST(attach);\n\n\tget_dma_buf(dma_buf);\n\n\tsgt = dma_buf_map_attachment_unlocked(attach, DMA_BIDIRECTIONAL);\n\tif (IS_ERR(sgt)) {\n\t\tret = PTR_ERR(sgt);\n\t\tgoto fail_detach;\n\t}\n\n\tobj = dev->driver->gem_prime_import_sg_table(dev, attach, sgt);\n\tif (IS_ERR(obj)) {\n\t\tret = PTR_ERR(obj);\n\t\tgoto fail_unmap;\n\t}\n\n\tobj->import_attach = attach;\n\tobj->resv = dma_buf->resv;\n\n\treturn obj;\n\nfail_unmap:\n\tdma_buf_unmap_attachment_unlocked(attach, sgt, DMA_BIDIRECTIONAL);\nfail_detach:\n\tdma_buf_detach(dma_buf, attach);\n\tdma_buf_put(dma_buf);\n\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL(drm_gem_prime_import_dev);\n\n \nstruct drm_gem_object *drm_gem_prime_import(struct drm_device *dev,\n\t\t\t\t\t    struct dma_buf *dma_buf)\n{\n\treturn drm_gem_prime_import_dev(dev, dma_buf, dev->dev);\n}\nEXPORT_SYMBOL(drm_gem_prime_import);\n\n \nint __deprecated drm_prime_sg_to_page_array(struct sg_table *sgt,\n\t\t\t\t\t    struct page **pages,\n\t\t\t\t\t    int max_entries)\n{\n\tstruct sg_page_iter page_iter;\n\tstruct page **p = pages;\n\n\tfor_each_sgtable_page(sgt, &page_iter, 0) {\n\t\tif (WARN_ON(p - pages >= max_entries))\n\t\t\treturn -1;\n\t\t*p++ = sg_page_iter_page(&page_iter);\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_prime_sg_to_page_array);\n\n \nint drm_prime_sg_to_dma_addr_array(struct sg_table *sgt, dma_addr_t *addrs,\n\t\t\t\t   int max_entries)\n{\n\tstruct sg_dma_page_iter dma_iter;\n\tdma_addr_t *a = addrs;\n\n\tfor_each_sgtable_dma_page(sgt, &dma_iter, 0) {\n\t\tif (WARN_ON(a - addrs >= max_entries))\n\t\t\treturn -1;\n\t\t*a++ = sg_page_iter_dma_address(&dma_iter);\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(drm_prime_sg_to_dma_addr_array);\n\n \nvoid drm_prime_gem_destroy(struct drm_gem_object *obj, struct sg_table *sg)\n{\n\tstruct dma_buf_attachment *attach;\n\tstruct dma_buf *dma_buf;\n\n\tattach = obj->import_attach;\n\tif (sg)\n\t\tdma_buf_unmap_attachment_unlocked(attach, sg, DMA_BIDIRECTIONAL);\n\tdma_buf = attach->dmabuf;\n\tdma_buf_detach(attach->dmabuf, attach);\n\t \n\tdma_buf_put(dma_buf);\n}\nEXPORT_SYMBOL(drm_prime_gem_destroy);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}