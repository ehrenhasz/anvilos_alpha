{
  "module_name": "lima_sched.c",
  "hash_id": "6cbef661717ab8624cbc69f001f43e38841beb7242568421d0c0e5aec3dd6642",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/lima/lima_sched.c",
  "human_readable_source": "\n \n\n#include <linux/iosys-map.h>\n#include <linux/kthread.h>\n#include <linux/slab.h>\n#include <linux/vmalloc.h>\n#include <linux/pm_runtime.h>\n\n#include \"lima_devfreq.h\"\n#include \"lima_drv.h\"\n#include \"lima_sched.h\"\n#include \"lima_vm.h\"\n#include \"lima_mmu.h\"\n#include \"lima_l2_cache.h\"\n#include \"lima_gem.h\"\n#include \"lima_trace.h\"\n\nstruct lima_fence {\n\tstruct dma_fence base;\n\tstruct lima_sched_pipe *pipe;\n};\n\nstatic struct kmem_cache *lima_fence_slab;\nstatic int lima_fence_slab_refcnt;\n\nint lima_sched_slab_init(void)\n{\n\tif (!lima_fence_slab) {\n\t\tlima_fence_slab = kmem_cache_create(\n\t\t\t\"lima_fence\", sizeof(struct lima_fence), 0,\n\t\t\tSLAB_HWCACHE_ALIGN, NULL);\n\t\tif (!lima_fence_slab)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tlima_fence_slab_refcnt++;\n\treturn 0;\n}\n\nvoid lima_sched_slab_fini(void)\n{\n\tif (!--lima_fence_slab_refcnt) {\n\t\tkmem_cache_destroy(lima_fence_slab);\n\t\tlima_fence_slab = NULL;\n\t}\n}\n\nstatic inline struct lima_fence *to_lima_fence(struct dma_fence *fence)\n{\n\treturn container_of(fence, struct lima_fence, base);\n}\n\nstatic const char *lima_fence_get_driver_name(struct dma_fence *fence)\n{\n\treturn \"lima\";\n}\n\nstatic const char *lima_fence_get_timeline_name(struct dma_fence *fence)\n{\n\tstruct lima_fence *f = to_lima_fence(fence);\n\n\treturn f->pipe->base.name;\n}\n\nstatic void lima_fence_release_rcu(struct rcu_head *rcu)\n{\n\tstruct dma_fence *f = container_of(rcu, struct dma_fence, rcu);\n\tstruct lima_fence *fence = to_lima_fence(f);\n\n\tkmem_cache_free(lima_fence_slab, fence);\n}\n\nstatic void lima_fence_release(struct dma_fence *fence)\n{\n\tstruct lima_fence *f = to_lima_fence(fence);\n\n\tcall_rcu(&f->base.rcu, lima_fence_release_rcu);\n}\n\nstatic const struct dma_fence_ops lima_fence_ops = {\n\t.get_driver_name = lima_fence_get_driver_name,\n\t.get_timeline_name = lima_fence_get_timeline_name,\n\t.release = lima_fence_release,\n};\n\nstatic struct lima_fence *lima_fence_create(struct lima_sched_pipe *pipe)\n{\n\tstruct lima_fence *fence;\n\n\tfence = kmem_cache_zalloc(lima_fence_slab, GFP_KERNEL);\n\tif (!fence)\n\t\treturn NULL;\n\n\tfence->pipe = pipe;\n\tdma_fence_init(&fence->base, &lima_fence_ops, &pipe->fence_lock,\n\t\t       pipe->fence_context, ++pipe->fence_seqno);\n\n\treturn fence;\n}\n\nstatic inline struct lima_sched_task *to_lima_task(struct drm_sched_job *job)\n{\n\treturn container_of(job, struct lima_sched_task, base);\n}\n\nstatic inline struct lima_sched_pipe *to_lima_pipe(struct drm_gpu_scheduler *sched)\n{\n\treturn container_of(sched, struct lima_sched_pipe, base);\n}\n\nint lima_sched_task_init(struct lima_sched_task *task,\n\t\t\t struct lima_sched_context *context,\n\t\t\t struct lima_bo **bos, int num_bos,\n\t\t\t struct lima_vm *vm)\n{\n\tint err, i;\n\n\ttask->bos = kmemdup(bos, sizeof(*bos) * num_bos, GFP_KERNEL);\n\tif (!task->bos)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < num_bos; i++)\n\t\tdrm_gem_object_get(&bos[i]->base.base);\n\n\terr = drm_sched_job_init(&task->base, &context->base, vm);\n\tif (err) {\n\t\tkfree(task->bos);\n\t\treturn err;\n\t}\n\n\tdrm_sched_job_arm(&task->base);\n\n\ttask->num_bos = num_bos;\n\ttask->vm = lima_vm_get(vm);\n\n\treturn 0;\n}\n\nvoid lima_sched_task_fini(struct lima_sched_task *task)\n{\n\tint i;\n\n\tdrm_sched_job_cleanup(&task->base);\n\n\tif (task->bos) {\n\t\tfor (i = 0; i < task->num_bos; i++)\n\t\t\tdrm_gem_object_put(&task->bos[i]->base.base);\n\t\tkfree(task->bos);\n\t}\n\n\tlima_vm_put(task->vm);\n}\n\nint lima_sched_context_init(struct lima_sched_pipe *pipe,\n\t\t\t    struct lima_sched_context *context,\n\t\t\t    atomic_t *guilty)\n{\n\tstruct drm_gpu_scheduler *sched = &pipe->base;\n\n\treturn drm_sched_entity_init(&context->base, DRM_SCHED_PRIORITY_NORMAL,\n\t\t\t\t     &sched, 1, guilty);\n}\n\nvoid lima_sched_context_fini(struct lima_sched_pipe *pipe,\n\t\t\t     struct lima_sched_context *context)\n{\n\tdrm_sched_entity_destroy(&context->base);\n}\n\nstruct dma_fence *lima_sched_context_queue_task(struct lima_sched_task *task)\n{\n\tstruct dma_fence *fence = dma_fence_get(&task->base.s_fence->finished);\n\n\ttrace_lima_task_submit(task);\n\tdrm_sched_entity_push_job(&task->base);\n\treturn fence;\n}\n\nstatic int lima_pm_busy(struct lima_device *ldev)\n{\n\tint ret;\n\n\t \n\tret = pm_runtime_resume_and_get(ldev->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tlima_devfreq_record_busy(&ldev->devfreq);\n\treturn 0;\n}\n\nstatic void lima_pm_idle(struct lima_device *ldev)\n{\n\tlima_devfreq_record_idle(&ldev->devfreq);\n\n\t \n\tpm_runtime_mark_last_busy(ldev->dev);\n\tpm_runtime_put_autosuspend(ldev->dev);\n}\n\nstatic struct dma_fence *lima_sched_run_job(struct drm_sched_job *job)\n{\n\tstruct lima_sched_task *task = to_lima_task(job);\n\tstruct lima_sched_pipe *pipe = to_lima_pipe(job->sched);\n\tstruct lima_device *ldev = pipe->ldev;\n\tstruct lima_fence *fence;\n\tint i, err;\n\n\t \n\tif (job->s_fence->finished.error < 0)\n\t\treturn NULL;\n\n\tfence = lima_fence_create(pipe);\n\tif (!fence)\n\t\treturn NULL;\n\n\terr = lima_pm_busy(ldev);\n\tif (err < 0) {\n\t\tdma_fence_put(&fence->base);\n\t\treturn NULL;\n\t}\n\n\ttask->fence = &fence->base;\n\n\t \n\tdma_fence_get(task->fence);\n\n\tpipe->current_task = task;\n\n\t \n\tfor (i = 0; i < pipe->num_l2_cache; i++)\n\t\tlima_l2_cache_flush(pipe->l2_cache[i]);\n\n\tlima_vm_put(pipe->current_vm);\n\tpipe->current_vm = lima_vm_get(task->vm);\n\n\tif (pipe->bcast_mmu)\n\t\tlima_mmu_switch_vm(pipe->bcast_mmu, pipe->current_vm);\n\telse {\n\t\tfor (i = 0; i < pipe->num_mmu; i++)\n\t\t\tlima_mmu_switch_vm(pipe->mmu[i], pipe->current_vm);\n\t}\n\n\ttrace_lima_task_run(task);\n\n\tpipe->error = false;\n\tpipe->task_run(pipe, task);\n\n\treturn task->fence;\n}\n\nstatic void lima_sched_build_error_task_list(struct lima_sched_task *task)\n{\n\tstruct lima_sched_error_task *et;\n\tstruct lima_sched_pipe *pipe = to_lima_pipe(task->base.sched);\n\tstruct lima_ip *ip = pipe->processor[0];\n\tint pipe_id = ip->id == lima_ip_gp ? lima_pipe_gp : lima_pipe_pp;\n\tstruct lima_device *dev = ip->dev;\n\tstruct lima_sched_context *sched_ctx =\n\t\tcontainer_of(task->base.entity,\n\t\t\t     struct lima_sched_context, base);\n\tstruct lima_ctx *ctx =\n\t\tcontainer_of(sched_ctx, struct lima_ctx, context[pipe_id]);\n\tstruct lima_dump_task *dt;\n\tstruct lima_dump_chunk *chunk;\n\tstruct lima_dump_chunk_pid *pid_chunk;\n\tstruct lima_dump_chunk_buffer *buffer_chunk;\n\tu32 size, task_size, mem_size;\n\tint i;\n\tstruct iosys_map map;\n\tint ret;\n\n\tmutex_lock(&dev->error_task_list_lock);\n\n\tif (dev->dump.num_tasks >= lima_max_error_tasks) {\n\t\tdev_info(dev->dev, \"fail to save task state from %s pid %d: \"\n\t\t\t \"error task list is full\\n\", ctx->pname, ctx->pid);\n\t\tgoto out;\n\t}\n\n\t \n\tsize = sizeof(struct lima_dump_chunk) + pipe->frame_size;\n\t \n\tsize += sizeof(struct lima_dump_chunk) + sizeof(ctx->pname);\n\t \n\tsize += sizeof(struct lima_dump_chunk);\n\t \n\tfor (i = 0; i < task->num_bos; i++) {\n\t\tstruct lima_bo *bo = task->bos[i];\n\n\t\tsize += sizeof(struct lima_dump_chunk);\n\t\tsize += bo->heap_size ? bo->heap_size : lima_bo_size(bo);\n\t}\n\n\ttask_size = size + sizeof(struct lima_dump_task);\n\tmem_size = task_size + sizeof(*et);\n\tet = kvmalloc(mem_size, GFP_KERNEL);\n\tif (!et) {\n\t\tdev_err(dev->dev, \"fail to alloc task dump buffer of size %x\\n\",\n\t\t\tmem_size);\n\t\tgoto out;\n\t}\n\n\tet->data = et + 1;\n\tet->size = task_size;\n\n\tdt = et->data;\n\tmemset(dt, 0, sizeof(*dt));\n\tdt->id = pipe_id;\n\tdt->size = size;\n\n\tchunk = (struct lima_dump_chunk *)(dt + 1);\n\tmemset(chunk, 0, sizeof(*chunk));\n\tchunk->id = LIMA_DUMP_CHUNK_FRAME;\n\tchunk->size = pipe->frame_size;\n\tmemcpy(chunk + 1, task->frame, pipe->frame_size);\n\tdt->num_chunks++;\n\n\tchunk = (void *)(chunk + 1) + chunk->size;\n\tmemset(chunk, 0, sizeof(*chunk));\n\tchunk->id = LIMA_DUMP_CHUNK_PROCESS_NAME;\n\tchunk->size = sizeof(ctx->pname);\n\tmemcpy(chunk + 1, ctx->pname, sizeof(ctx->pname));\n\tdt->num_chunks++;\n\n\tpid_chunk = (void *)(chunk + 1) + chunk->size;\n\tmemset(pid_chunk, 0, sizeof(*pid_chunk));\n\tpid_chunk->id = LIMA_DUMP_CHUNK_PROCESS_ID;\n\tpid_chunk->pid = ctx->pid;\n\tdt->num_chunks++;\n\n\tbuffer_chunk = (void *)(pid_chunk + 1) + pid_chunk->size;\n\tfor (i = 0; i < task->num_bos; i++) {\n\t\tstruct lima_bo *bo = task->bos[i];\n\t\tvoid *data;\n\n\t\tmemset(buffer_chunk, 0, sizeof(*buffer_chunk));\n\t\tbuffer_chunk->id = LIMA_DUMP_CHUNK_BUFFER;\n\t\tbuffer_chunk->va = lima_vm_get_va(task->vm, bo);\n\n\t\tif (bo->heap_size) {\n\t\t\tbuffer_chunk->size = bo->heap_size;\n\n\t\t\tdata = vmap(bo->base.pages, bo->heap_size >> PAGE_SHIFT,\n\t\t\t\t    VM_MAP, pgprot_writecombine(PAGE_KERNEL));\n\t\t\tif (!data) {\n\t\t\t\tkvfree(et);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tmemcpy(buffer_chunk + 1, data, buffer_chunk->size);\n\n\t\t\tvunmap(data);\n\t\t} else {\n\t\t\tbuffer_chunk->size = lima_bo_size(bo);\n\n\t\t\tret = drm_gem_vmap_unlocked(&bo->base.base, &map);\n\t\t\tif (ret) {\n\t\t\t\tkvfree(et);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tmemcpy(buffer_chunk + 1, map.vaddr, buffer_chunk->size);\n\n\t\t\tdrm_gem_vunmap_unlocked(&bo->base.base, &map);\n\t\t}\n\n\t\tbuffer_chunk = (void *)(buffer_chunk + 1) + buffer_chunk->size;\n\t\tdt->num_chunks++;\n\t}\n\n\tlist_add(&et->list, &dev->error_task_list);\n\tdev->dump.size += et->size;\n\tdev->dump.num_tasks++;\n\n\tdev_info(dev->dev, \"save error task state success\\n\");\n\nout:\n\tmutex_unlock(&dev->error_task_list_lock);\n}\n\nstatic enum drm_gpu_sched_stat lima_sched_timedout_job(struct drm_sched_job *job)\n{\n\tstruct lima_sched_pipe *pipe = to_lima_pipe(job->sched);\n\tstruct lima_sched_task *task = to_lima_task(job);\n\tstruct lima_device *ldev = pipe->ldev;\n\n\tif (!pipe->error)\n\t\tDRM_ERROR(\"lima job timeout\\n\");\n\n\tdrm_sched_stop(&pipe->base, &task->base);\n\n\tdrm_sched_increase_karma(&task->base);\n\n\tif (lima_max_error_tasks)\n\t\tlima_sched_build_error_task_list(task);\n\n\tpipe->task_error(pipe);\n\n\tif (pipe->bcast_mmu)\n\t\tlima_mmu_page_fault_resume(pipe->bcast_mmu);\n\telse {\n\t\tint i;\n\n\t\tfor (i = 0; i < pipe->num_mmu; i++)\n\t\t\tlima_mmu_page_fault_resume(pipe->mmu[i]);\n\t}\n\n\tlima_vm_put(pipe->current_vm);\n\tpipe->current_vm = NULL;\n\tpipe->current_task = NULL;\n\n\tlima_pm_idle(ldev);\n\n\tdrm_sched_resubmit_jobs(&pipe->base);\n\tdrm_sched_start(&pipe->base, true);\n\n\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n}\n\nstatic void lima_sched_free_job(struct drm_sched_job *job)\n{\n\tstruct lima_sched_task *task = to_lima_task(job);\n\tstruct lima_sched_pipe *pipe = to_lima_pipe(job->sched);\n\tstruct lima_vm *vm = task->vm;\n\tstruct lima_bo **bos = task->bos;\n\tint i;\n\n\tdma_fence_put(task->fence);\n\n\tfor (i = 0; i < task->num_bos; i++)\n\t\tlima_vm_bo_del(vm, bos[i]);\n\n\tlima_sched_task_fini(task);\n\tkmem_cache_free(pipe->task_slab, task);\n}\n\nstatic const struct drm_sched_backend_ops lima_sched_ops = {\n\t.run_job = lima_sched_run_job,\n\t.timedout_job = lima_sched_timedout_job,\n\t.free_job = lima_sched_free_job,\n};\n\nstatic void lima_sched_recover_work(struct work_struct *work)\n{\n\tstruct lima_sched_pipe *pipe =\n\t\tcontainer_of(work, struct lima_sched_pipe, recover_work);\n\tint i;\n\n\tfor (i = 0; i < pipe->num_l2_cache; i++)\n\t\tlima_l2_cache_flush(pipe->l2_cache[i]);\n\n\tif (pipe->bcast_mmu) {\n\t\tlima_mmu_flush_tlb(pipe->bcast_mmu);\n\t} else {\n\t\tfor (i = 0; i < pipe->num_mmu; i++)\n\t\t\tlima_mmu_flush_tlb(pipe->mmu[i]);\n\t}\n\n\tif (pipe->task_recover(pipe))\n\t\tdrm_sched_fault(&pipe->base);\n}\n\nint lima_sched_pipe_init(struct lima_sched_pipe *pipe, const char *name)\n{\n\tunsigned int timeout = lima_sched_timeout_ms > 0 ?\n\t\t\t       lima_sched_timeout_ms : 500;\n\n\tpipe->fence_context = dma_fence_context_alloc(1);\n\tspin_lock_init(&pipe->fence_lock);\n\n\tINIT_WORK(&pipe->recover_work, lima_sched_recover_work);\n\n\treturn drm_sched_init(&pipe->base, &lima_sched_ops, 1,\n\t\t\t      lima_job_hang_limit,\n\t\t\t      msecs_to_jiffies(timeout), NULL,\n\t\t\t      NULL, name, pipe->ldev->dev);\n}\n\nvoid lima_sched_pipe_fini(struct lima_sched_pipe *pipe)\n{\n\tdrm_sched_fini(&pipe->base);\n}\n\nvoid lima_sched_pipe_task_done(struct lima_sched_pipe *pipe)\n{\n\tstruct lima_sched_task *task = pipe->current_task;\n\tstruct lima_device *ldev = pipe->ldev;\n\n\tif (pipe->error) {\n\t\tif (task && task->recoverable)\n\t\t\tschedule_work(&pipe->recover_work);\n\t\telse\n\t\t\tdrm_sched_fault(&pipe->base);\n\t} else {\n\t\tpipe->task_fini(pipe);\n\t\tdma_fence_signal(task->fence);\n\n\t\tlima_pm_idle(ldev);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}