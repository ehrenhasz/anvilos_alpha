{
  "module_name": "ttm_resource.c",
  "hash_id": "a2c1da7c1b648a99ca1aee15d6249459b65d0be00fe9d9763701e57f14330d56",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/ttm/ttm_resource.c",
  "human_readable_source": " \n\n#include <linux/iosys-map.h>\n#include <linux/io-mapping.h>\n#include <linux/scatterlist.h>\n\n#include <drm/ttm/ttm_bo.h>\n#include <drm/ttm/ttm_placement.h>\n#include <drm/ttm/ttm_resource.h>\n\n \nvoid ttm_lru_bulk_move_init(struct ttm_lru_bulk_move *bulk)\n{\n\tmemset(bulk, 0, sizeof(*bulk));\n}\nEXPORT_SYMBOL(ttm_lru_bulk_move_init);\n\n \nvoid ttm_lru_bulk_move_tail(struct ttm_lru_bulk_move *bulk)\n{\n\tunsigned i, j;\n\n\tfor (i = 0; i < TTM_NUM_MEM_TYPES; ++i) {\n\t\tfor (j = 0; j < TTM_MAX_BO_PRIORITY; ++j) {\n\t\t\tstruct ttm_lru_bulk_move_pos *pos = &bulk->pos[i][j];\n\t\t\tstruct ttm_resource_manager *man;\n\n\t\t\tif (!pos->first)\n\t\t\t\tcontinue;\n\n\t\t\tlockdep_assert_held(&pos->first->bo->bdev->lru_lock);\n\t\t\tdma_resv_assert_held(pos->first->bo->base.resv);\n\t\t\tdma_resv_assert_held(pos->last->bo->base.resv);\n\n\t\t\tman = ttm_manager_type(pos->first->bo->bdev, i);\n\t\t\tlist_bulk_move_tail(&man->lru[j], &pos->first->lru,\n\t\t\t\t\t    &pos->last->lru);\n\t\t}\n\t}\n}\nEXPORT_SYMBOL(ttm_lru_bulk_move_tail);\n\n \nstatic struct ttm_lru_bulk_move_pos *\nttm_lru_bulk_move_pos(struct ttm_lru_bulk_move *bulk, struct ttm_resource *res)\n{\n\treturn &bulk->pos[res->mem_type][res->bo->priority];\n}\n\n \nstatic void ttm_lru_bulk_move_pos_tail(struct ttm_lru_bulk_move_pos *pos,\n\t\t\t\t       struct ttm_resource *res)\n{\n\tif (pos->last != res) {\n\t\tif (pos->first == res)\n\t\t\tpos->first = list_next_entry(res, lru);\n\t\tlist_move(&res->lru, &pos->last->lru);\n\t\tpos->last = res;\n\t}\n}\n\n \nstatic void ttm_lru_bulk_move_add(struct ttm_lru_bulk_move *bulk,\n\t\t\t\t  struct ttm_resource *res)\n{\n\tstruct ttm_lru_bulk_move_pos *pos = ttm_lru_bulk_move_pos(bulk, res);\n\n\tif (!pos->first) {\n\t\tpos->first = res;\n\t\tpos->last = res;\n\t} else {\n\t\tttm_lru_bulk_move_pos_tail(pos, res);\n\t}\n}\n\n \nstatic void ttm_lru_bulk_move_del(struct ttm_lru_bulk_move *bulk,\n\t\t\t\t  struct ttm_resource *res)\n{\n\tstruct ttm_lru_bulk_move_pos *pos = ttm_lru_bulk_move_pos(bulk, res);\n\n\tif (unlikely(WARN_ON(!pos->first || !pos->last) ||\n\t\t     (pos->first == res && pos->last == res))) {\n\t\tpos->first = NULL;\n\t\tpos->last = NULL;\n\t} else if (pos->first == res) {\n\t\tpos->first = list_next_entry(res, lru);\n\t} else if (pos->last == res) {\n\t\tpos->last = list_prev_entry(res, lru);\n\t} else {\n\t\tlist_move(&res->lru, &pos->last->lru);\n\t}\n}\n\n \nvoid ttm_resource_add_bulk_move(struct ttm_resource *res,\n\t\t\t\tstruct ttm_buffer_object *bo)\n{\n\tif (bo->bulk_move && !bo->pin_count)\n\t\tttm_lru_bulk_move_add(bo->bulk_move, res);\n}\n\n \nvoid ttm_resource_del_bulk_move(struct ttm_resource *res,\n\t\t\t\tstruct ttm_buffer_object *bo)\n{\n\tif (bo->bulk_move && !bo->pin_count)\n\t\tttm_lru_bulk_move_del(bo->bulk_move, res);\n}\n\n \nvoid ttm_resource_move_to_lru_tail(struct ttm_resource *res)\n{\n\tstruct ttm_buffer_object *bo = res->bo;\n\tstruct ttm_device *bdev = bo->bdev;\n\n\tlockdep_assert_held(&bo->bdev->lru_lock);\n\n\tif (bo->pin_count) {\n\t\tlist_move_tail(&res->lru, &bdev->pinned);\n\n\t} else\tif (bo->bulk_move) {\n\t\tstruct ttm_lru_bulk_move_pos *pos =\n\t\t\tttm_lru_bulk_move_pos(bo->bulk_move, res);\n\n\t\tttm_lru_bulk_move_pos_tail(pos, res);\n\t} else {\n\t\tstruct ttm_resource_manager *man;\n\n\t\tman = ttm_manager_type(bdev, res->mem_type);\n\t\tlist_move_tail(&res->lru, &man->lru[bo->priority]);\n\t}\n}\n\n \nvoid ttm_resource_init(struct ttm_buffer_object *bo,\n                       const struct ttm_place *place,\n                       struct ttm_resource *res)\n{\n\tstruct ttm_resource_manager *man;\n\n\tres->start = 0;\n\tres->size = bo->base.size;\n\tres->mem_type = place->mem_type;\n\tres->placement = place->flags;\n\tres->bus.addr = NULL;\n\tres->bus.offset = 0;\n\tres->bus.is_iomem = false;\n\tres->bus.caching = ttm_cached;\n\tres->bo = bo;\n\n\tman = ttm_manager_type(bo->bdev, place->mem_type);\n\tspin_lock(&bo->bdev->lru_lock);\n\tif (bo->pin_count)\n\t\tlist_add_tail(&res->lru, &bo->bdev->pinned);\n\telse\n\t\tlist_add_tail(&res->lru, &man->lru[bo->priority]);\n\tman->usage += res->size;\n\tspin_unlock(&bo->bdev->lru_lock);\n}\nEXPORT_SYMBOL(ttm_resource_init);\n\n \nvoid ttm_resource_fini(struct ttm_resource_manager *man,\n\t\t       struct ttm_resource *res)\n{\n\tstruct ttm_device *bdev = man->bdev;\n\n\tspin_lock(&bdev->lru_lock);\n\tlist_del_init(&res->lru);\n\tman->usage -= res->size;\n\tspin_unlock(&bdev->lru_lock);\n}\nEXPORT_SYMBOL(ttm_resource_fini);\n\nint ttm_resource_alloc(struct ttm_buffer_object *bo,\n\t\t       const struct ttm_place *place,\n\t\t       struct ttm_resource **res_ptr)\n{\n\tstruct ttm_resource_manager *man =\n\t\tttm_manager_type(bo->bdev, place->mem_type);\n\tint ret;\n\n\tret = man->func->alloc(man, bo, place, res_ptr);\n\tif (ret)\n\t\treturn ret;\n\n\tspin_lock(&bo->bdev->lru_lock);\n\tttm_resource_add_bulk_move(*res_ptr, bo);\n\tspin_unlock(&bo->bdev->lru_lock);\n\treturn 0;\n}\n\nvoid ttm_resource_free(struct ttm_buffer_object *bo, struct ttm_resource **res)\n{\n\tstruct ttm_resource_manager *man;\n\n\tif (!*res)\n\t\treturn;\n\n\tspin_lock(&bo->bdev->lru_lock);\n\tttm_resource_del_bulk_move(*res, bo);\n\tspin_unlock(&bo->bdev->lru_lock);\n\tman = ttm_manager_type(bo->bdev, (*res)->mem_type);\n\tman->func->free(man, *res);\n\t*res = NULL;\n}\nEXPORT_SYMBOL(ttm_resource_free);\n\n \nbool ttm_resource_intersects(struct ttm_device *bdev,\n\t\t\t     struct ttm_resource *res,\n\t\t\t     const struct ttm_place *place,\n\t\t\t     size_t size)\n{\n\tstruct ttm_resource_manager *man;\n\n\tif (!res)\n\t\treturn false;\n\n\tman = ttm_manager_type(bdev, res->mem_type);\n\tif (!place || !man->func->intersects)\n\t\treturn true;\n\n\treturn man->func->intersects(man, res, place, size);\n}\n\n \nbool ttm_resource_compatible(struct ttm_device *bdev,\n\t\t\t     struct ttm_resource *res,\n\t\t\t     const struct ttm_place *place,\n\t\t\t     size_t size)\n{\n\tstruct ttm_resource_manager *man;\n\n\tif (!res || !place)\n\t\treturn false;\n\n\tman = ttm_manager_type(bdev, res->mem_type);\n\tif (!man->func->compatible)\n\t\treturn true;\n\n\treturn man->func->compatible(man, res, place, size);\n}\n\nstatic bool ttm_resource_places_compat(struct ttm_resource *res,\n\t\t\t\t       const struct ttm_place *places,\n\t\t\t\t       unsigned num_placement)\n{\n\tstruct ttm_buffer_object *bo = res->bo;\n\tstruct ttm_device *bdev = bo->bdev;\n\tunsigned i;\n\n\tif (res->placement & TTM_PL_FLAG_TEMPORARY)\n\t\treturn false;\n\n\tfor (i = 0; i < num_placement; i++) {\n\t\tconst struct ttm_place *heap = &places[i];\n\n\t\tif (!ttm_resource_compatible(bdev, res, heap, bo->base.size))\n\t\t\tcontinue;\n\n\t\tif ((res->mem_type == heap->mem_type) &&\n\t\t    (!(heap->flags & TTM_PL_FLAG_CONTIGUOUS) ||\n\t\t     (res->placement & TTM_PL_FLAG_CONTIGUOUS)))\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n \nbool ttm_resource_compat(struct ttm_resource *res,\n\t\t\t struct ttm_placement *placement)\n{\n\tif (ttm_resource_places_compat(res, placement->placement,\n\t\t\t\t       placement->num_placement))\n\t\treturn true;\n\n\tif ((placement->busy_placement != placement->placement ||\n\t     placement->num_busy_placement > placement->num_placement) &&\n\t    ttm_resource_places_compat(res, placement->busy_placement,\n\t\t\t\t       placement->num_busy_placement))\n\t\treturn true;\n\n\treturn false;\n}\n\nvoid ttm_resource_set_bo(struct ttm_resource *res,\n\t\t\t struct ttm_buffer_object *bo)\n{\n\tspin_lock(&bo->bdev->lru_lock);\n\tres->bo = bo;\n\tspin_unlock(&bo->bdev->lru_lock);\n}\n\n \nvoid ttm_resource_manager_init(struct ttm_resource_manager *man,\n\t\t\t       struct ttm_device *bdev,\n\t\t\t       uint64_t size)\n{\n\tunsigned i;\n\n\tspin_lock_init(&man->move_lock);\n\tman->bdev = bdev;\n\tman->size = size;\n\tman->usage = 0;\n\n\tfor (i = 0; i < TTM_MAX_BO_PRIORITY; ++i)\n\t\tINIT_LIST_HEAD(&man->lru[i]);\n\tman->move = NULL;\n}\nEXPORT_SYMBOL(ttm_resource_manager_init);\n\n \nint ttm_resource_manager_evict_all(struct ttm_device *bdev,\n\t\t\t\t   struct ttm_resource_manager *man)\n{\n\tstruct ttm_operation_ctx ctx = {\n\t\t.interruptible = false,\n\t\t.no_wait_gpu = false,\n\t\t.force_alloc = true\n\t};\n\tstruct dma_fence *fence;\n\tint ret;\n\tunsigned i;\n\n\t \n\n\tspin_lock(&bdev->lru_lock);\n\tfor (i = 0; i < TTM_MAX_BO_PRIORITY; ++i) {\n\t\twhile (!list_empty(&man->lru[i])) {\n\t\t\tspin_unlock(&bdev->lru_lock);\n\t\t\tret = ttm_mem_evict_first(bdev, man, NULL, &ctx,\n\t\t\t\t\t\t  NULL);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tspin_lock(&bdev->lru_lock);\n\t\t}\n\t}\n\tspin_unlock(&bdev->lru_lock);\n\n\tspin_lock(&man->move_lock);\n\tfence = dma_fence_get(man->move);\n\tspin_unlock(&man->move_lock);\n\n\tif (fence) {\n\t\tret = dma_fence_wait(fence, false);\n\t\tdma_fence_put(fence);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(ttm_resource_manager_evict_all);\n\n \nuint64_t ttm_resource_manager_usage(struct ttm_resource_manager *man)\n{\n\tuint64_t usage;\n\n\tspin_lock(&man->bdev->lru_lock);\n\tusage = man->usage;\n\tspin_unlock(&man->bdev->lru_lock);\n\treturn usage;\n}\nEXPORT_SYMBOL(ttm_resource_manager_usage);\n\n \nvoid ttm_resource_manager_debug(struct ttm_resource_manager *man,\n\t\t\t\tstruct drm_printer *p)\n{\n\tdrm_printf(p, \"  use_type: %d\\n\", man->use_type);\n\tdrm_printf(p, \"  use_tt: %d\\n\", man->use_tt);\n\tdrm_printf(p, \"  size: %llu\\n\", man->size);\n\tdrm_printf(p, \"  usage: %llu\\n\", ttm_resource_manager_usage(man));\n\tif (man->func->debug)\n\t\tman->func->debug(man, p);\n}\nEXPORT_SYMBOL(ttm_resource_manager_debug);\n\n \nstruct ttm_resource *\nttm_resource_manager_first(struct ttm_resource_manager *man,\n\t\t\t   struct ttm_resource_cursor *cursor)\n{\n\tstruct ttm_resource *res;\n\n\tlockdep_assert_held(&man->bdev->lru_lock);\n\n\tfor (cursor->priority = 0; cursor->priority < TTM_MAX_BO_PRIORITY;\n\t     ++cursor->priority)\n\t\tlist_for_each_entry(res, &man->lru[cursor->priority], lru)\n\t\t\treturn res;\n\n\treturn NULL;\n}\n\n \nstruct ttm_resource *\nttm_resource_manager_next(struct ttm_resource_manager *man,\n\t\t\t  struct ttm_resource_cursor *cursor,\n\t\t\t  struct ttm_resource *res)\n{\n\tlockdep_assert_held(&man->bdev->lru_lock);\n\n\tlist_for_each_entry_continue(res, &man->lru[cursor->priority], lru)\n\t\treturn res;\n\n\tfor (++cursor->priority; cursor->priority < TTM_MAX_BO_PRIORITY;\n\t     ++cursor->priority)\n\t\tlist_for_each_entry(res, &man->lru[cursor->priority], lru)\n\t\t\treturn res;\n\n\treturn NULL;\n}\n\nstatic void ttm_kmap_iter_iomap_map_local(struct ttm_kmap_iter *iter,\n\t\t\t\t\t  struct iosys_map *dmap,\n\t\t\t\t\t  pgoff_t i)\n{\n\tstruct ttm_kmap_iter_iomap *iter_io =\n\t\tcontainer_of(iter, typeof(*iter_io), base);\n\tvoid __iomem *addr;\n\nretry:\n\twhile (i >= iter_io->cache.end) {\n\t\titer_io->cache.sg = iter_io->cache.sg ?\n\t\t\tsg_next(iter_io->cache.sg) : iter_io->st->sgl;\n\t\titer_io->cache.i = iter_io->cache.end;\n\t\titer_io->cache.end += sg_dma_len(iter_io->cache.sg) >>\n\t\t\tPAGE_SHIFT;\n\t\titer_io->cache.offs = sg_dma_address(iter_io->cache.sg) -\n\t\t\titer_io->start;\n\t}\n\n\tif (i < iter_io->cache.i) {\n\t\titer_io->cache.end = 0;\n\t\titer_io->cache.sg = NULL;\n\t\tgoto retry;\n\t}\n\n\taddr = io_mapping_map_local_wc(iter_io->iomap, iter_io->cache.offs +\n\t\t\t\t       (((resource_size_t)i - iter_io->cache.i)\n\t\t\t\t\t<< PAGE_SHIFT));\n\tiosys_map_set_vaddr_iomem(dmap, addr);\n}\n\nstatic void ttm_kmap_iter_iomap_unmap_local(struct ttm_kmap_iter *iter,\n\t\t\t\t\t    struct iosys_map *map)\n{\n\tio_mapping_unmap_local(map->vaddr_iomem);\n}\n\nstatic const struct ttm_kmap_iter_ops ttm_kmap_iter_io_ops = {\n\t.map_local =  ttm_kmap_iter_iomap_map_local,\n\t.unmap_local = ttm_kmap_iter_iomap_unmap_local,\n\t.maps_tt = false,\n};\n\n \nstruct ttm_kmap_iter *\nttm_kmap_iter_iomap_init(struct ttm_kmap_iter_iomap *iter_io,\n\t\t\t struct io_mapping *iomap,\n\t\t\t struct sg_table *st,\n\t\t\t resource_size_t start)\n{\n\titer_io->base.ops = &ttm_kmap_iter_io_ops;\n\titer_io->iomap = iomap;\n\titer_io->st = st;\n\titer_io->start = start;\n\tmemset(&iter_io->cache, 0, sizeof(iter_io->cache));\n\n\treturn &iter_io->base;\n}\nEXPORT_SYMBOL(ttm_kmap_iter_iomap_init);\n\n \n\nstatic void ttm_kmap_iter_linear_io_map_local(struct ttm_kmap_iter *iter,\n\t\t\t\t\t      struct iosys_map *dmap,\n\t\t\t\t\t      pgoff_t i)\n{\n\tstruct ttm_kmap_iter_linear_io *iter_io =\n\t\tcontainer_of(iter, typeof(*iter_io), base);\n\n\t*dmap = iter_io->dmap;\n\tiosys_map_incr(dmap, i * PAGE_SIZE);\n}\n\nstatic const struct ttm_kmap_iter_ops ttm_kmap_iter_linear_io_ops = {\n\t.map_local =  ttm_kmap_iter_linear_io_map_local,\n\t.maps_tt = false,\n};\n\n \nstruct ttm_kmap_iter *\nttm_kmap_iter_linear_io_init(struct ttm_kmap_iter_linear_io *iter_io,\n\t\t\t     struct ttm_device *bdev,\n\t\t\t     struct ttm_resource *mem)\n{\n\tint ret;\n\n\tret = ttm_mem_io_reserve(bdev, mem);\n\tif (ret)\n\t\tgoto out_err;\n\tif (!mem->bus.is_iomem) {\n\t\tret = -EINVAL;\n\t\tgoto out_io_free;\n\t}\n\n\tif (mem->bus.addr) {\n\t\tiosys_map_set_vaddr(&iter_io->dmap, mem->bus.addr);\n\t\titer_io->needs_unmap = false;\n\t} else {\n\t\titer_io->needs_unmap = true;\n\t\tmemset(&iter_io->dmap, 0, sizeof(iter_io->dmap));\n\t\tif (mem->bus.caching == ttm_write_combined)\n\t\t\tiosys_map_set_vaddr_iomem(&iter_io->dmap,\n\t\t\t\t\t\t  ioremap_wc(mem->bus.offset,\n\t\t\t\t\t\t\t     mem->size));\n\t\telse if (mem->bus.caching == ttm_cached)\n\t\t\tiosys_map_set_vaddr(&iter_io->dmap,\n\t\t\t\t\t    memremap(mem->bus.offset, mem->size,\n\t\t\t\t\t\t     MEMREMAP_WB |\n\t\t\t\t\t\t     MEMREMAP_WT |\n\t\t\t\t\t\t     MEMREMAP_WC));\n\n\t\t \n\t\tif (iosys_map_is_null(&iter_io->dmap))\n\t\t\tiosys_map_set_vaddr_iomem(&iter_io->dmap,\n\t\t\t\t\t\t  ioremap(mem->bus.offset,\n\t\t\t\t\t\t\t  mem->size));\n\n\t\tif (iosys_map_is_null(&iter_io->dmap)) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_io_free;\n\t\t}\n\t}\n\n\titer_io->base.ops = &ttm_kmap_iter_linear_io_ops;\n\treturn &iter_io->base;\n\nout_io_free:\n\tttm_mem_io_free(bdev, mem);\nout_err:\n\treturn ERR_PTR(ret);\n}\n\n \nvoid\nttm_kmap_iter_linear_io_fini(struct ttm_kmap_iter_linear_io *iter_io,\n\t\t\t     struct ttm_device *bdev,\n\t\t\t     struct ttm_resource *mem)\n{\n\tif (iter_io->needs_unmap && iosys_map_is_set(&iter_io->dmap)) {\n\t\tif (iter_io->dmap.is_iomem)\n\t\t\tiounmap(iter_io->dmap.vaddr_iomem);\n\t\telse\n\t\t\tmemunmap(iter_io->dmap.vaddr);\n\t}\n\n\tttm_mem_io_free(bdev, mem);\n}\n\n#if defined(CONFIG_DEBUG_FS)\n\nstatic int ttm_resource_manager_show(struct seq_file *m, void *unused)\n{\n\tstruct ttm_resource_manager *man =\n\t\t(struct ttm_resource_manager *)m->private;\n\tstruct drm_printer p = drm_seq_file_printer(m);\n\tttm_resource_manager_debug(man, &p);\n\treturn 0;\n}\nDEFINE_SHOW_ATTRIBUTE(ttm_resource_manager);\n\n#endif\n\n \nvoid ttm_resource_manager_create_debugfs(struct ttm_resource_manager *man,\n\t\t\t\t\t struct dentry * parent,\n\t\t\t\t\t const char *name)\n{\n#if defined(CONFIG_DEBUG_FS)\n\tdebugfs_create_file(name, 0444, parent, man, &ttm_resource_manager_fops);\n#endif\n}\nEXPORT_SYMBOL(ttm_resource_manager_create_debugfs);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}