{
  "module_name": "v3d_sched.c",
  "hash_id": "9dc4bb499ab08a5255dd0d3fc2c0bb610ef64398aadf1162b76f69a00935f255",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/v3d/v3d_sched.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/kthread.h>\n\n#include \"v3d_drv.h\"\n#include \"v3d_regs.h\"\n#include \"v3d_trace.h\"\n\nstatic struct v3d_job *\nto_v3d_job(struct drm_sched_job *sched_job)\n{\n\treturn container_of(sched_job, struct v3d_job, base);\n}\n\nstatic struct v3d_bin_job *\nto_bin_job(struct drm_sched_job *sched_job)\n{\n\treturn container_of(sched_job, struct v3d_bin_job, base.base);\n}\n\nstatic struct v3d_render_job *\nto_render_job(struct drm_sched_job *sched_job)\n{\n\treturn container_of(sched_job, struct v3d_render_job, base.base);\n}\n\nstatic struct v3d_tfu_job *\nto_tfu_job(struct drm_sched_job *sched_job)\n{\n\treturn container_of(sched_job, struct v3d_tfu_job, base.base);\n}\n\nstatic struct v3d_csd_job *\nto_csd_job(struct drm_sched_job *sched_job)\n{\n\treturn container_of(sched_job, struct v3d_csd_job, base.base);\n}\n\nstatic void\nv3d_sched_job_free(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_job *job = to_v3d_job(sched_job);\n\n\tv3d_job_cleanup(job);\n}\n\nstatic void\nv3d_switch_perfmon(struct v3d_dev *v3d, struct v3d_job *job)\n{\n\tif (job->perfmon != v3d->active_perfmon)\n\t\tv3d_perfmon_stop(v3d, v3d->active_perfmon, true);\n\n\tif (job->perfmon && v3d->active_perfmon != job->perfmon)\n\t\tv3d_perfmon_start(v3d, job->perfmon);\n}\n\nstatic struct dma_fence *v3d_bin_job_run(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_bin_job *job = to_bin_job(sched_job);\n\tstruct v3d_dev *v3d = job->base.v3d;\n\tstruct drm_device *dev = &v3d->drm;\n\tstruct dma_fence *fence;\n\tunsigned long irqflags;\n\n\tif (unlikely(job->base.base.s_fence->finished.error))\n\t\treturn NULL;\n\n\t \n\tspin_lock_irqsave(&v3d->job_lock, irqflags);\n\tv3d->bin_job = job;\n\t \n\tV3D_CORE_WRITE(0, V3D_PTB_BPOS, 0);\n\tspin_unlock_irqrestore(&v3d->job_lock, irqflags);\n\n\tv3d_invalidate_caches(v3d);\n\n\tfence = v3d_fence_create(v3d, V3D_BIN);\n\tif (IS_ERR(fence))\n\t\treturn NULL;\n\n\tif (job->base.irq_fence)\n\t\tdma_fence_put(job->base.irq_fence);\n\tjob->base.irq_fence = dma_fence_get(fence);\n\n\ttrace_v3d_submit_cl(dev, false, to_v3d_fence(fence)->seqno,\n\t\t\t    job->start, job->end);\n\n\tv3d_switch_perfmon(v3d, &job->base);\n\n\t \n\tif (job->qma) {\n\t\tV3D_CORE_WRITE(0, V3D_CLE_CT0QMA, job->qma);\n\t\tV3D_CORE_WRITE(0, V3D_CLE_CT0QMS, job->qms);\n\t}\n\tif (job->qts) {\n\t\tV3D_CORE_WRITE(0, V3D_CLE_CT0QTS,\n\t\t\t       V3D_CLE_CT0QTS_ENABLE |\n\t\t\t       job->qts);\n\t}\n\tV3D_CORE_WRITE(0, V3D_CLE_CT0QBA, job->start);\n\tV3D_CORE_WRITE(0, V3D_CLE_CT0QEA, job->end);\n\n\treturn fence;\n}\n\nstatic struct dma_fence *v3d_render_job_run(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_render_job *job = to_render_job(sched_job);\n\tstruct v3d_dev *v3d = job->base.v3d;\n\tstruct drm_device *dev = &v3d->drm;\n\tstruct dma_fence *fence;\n\n\tif (unlikely(job->base.base.s_fence->finished.error))\n\t\treturn NULL;\n\n\tv3d->render_job = job;\n\n\t \n\tv3d_invalidate_caches(v3d);\n\n\tfence = v3d_fence_create(v3d, V3D_RENDER);\n\tif (IS_ERR(fence))\n\t\treturn NULL;\n\n\tif (job->base.irq_fence)\n\t\tdma_fence_put(job->base.irq_fence);\n\tjob->base.irq_fence = dma_fence_get(fence);\n\n\ttrace_v3d_submit_cl(dev, true, to_v3d_fence(fence)->seqno,\n\t\t\t    job->start, job->end);\n\n\tv3d_switch_perfmon(v3d, &job->base);\n\n\t \n\n\t \n\tV3D_CORE_WRITE(0, V3D_CLE_CT1QBA, job->start);\n\tV3D_CORE_WRITE(0, V3D_CLE_CT1QEA, job->end);\n\n\treturn fence;\n}\n\nstatic struct dma_fence *\nv3d_tfu_job_run(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_tfu_job *job = to_tfu_job(sched_job);\n\tstruct v3d_dev *v3d = job->base.v3d;\n\tstruct drm_device *dev = &v3d->drm;\n\tstruct dma_fence *fence;\n\n\tfence = v3d_fence_create(v3d, V3D_TFU);\n\tif (IS_ERR(fence))\n\t\treturn NULL;\n\n\tv3d->tfu_job = job;\n\tif (job->base.irq_fence)\n\t\tdma_fence_put(job->base.irq_fence);\n\tjob->base.irq_fence = dma_fence_get(fence);\n\n\ttrace_v3d_submit_tfu(dev, to_v3d_fence(fence)->seqno);\n\n\tV3D_WRITE(V3D_TFU_IIA, job->args.iia);\n\tV3D_WRITE(V3D_TFU_IIS, job->args.iis);\n\tV3D_WRITE(V3D_TFU_ICA, job->args.ica);\n\tV3D_WRITE(V3D_TFU_IUA, job->args.iua);\n\tV3D_WRITE(V3D_TFU_IOA, job->args.ioa);\n\tV3D_WRITE(V3D_TFU_IOS, job->args.ios);\n\tV3D_WRITE(V3D_TFU_COEF0, job->args.coef[0]);\n\tif (job->args.coef[0] & V3D_TFU_COEF0_USECOEF) {\n\t\tV3D_WRITE(V3D_TFU_COEF1, job->args.coef[1]);\n\t\tV3D_WRITE(V3D_TFU_COEF2, job->args.coef[2]);\n\t\tV3D_WRITE(V3D_TFU_COEF3, job->args.coef[3]);\n\t}\n\t \n\tV3D_WRITE(V3D_TFU_ICFG, job->args.icfg | V3D_TFU_ICFG_IOC);\n\n\treturn fence;\n}\n\nstatic struct dma_fence *\nv3d_csd_job_run(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_csd_job *job = to_csd_job(sched_job);\n\tstruct v3d_dev *v3d = job->base.v3d;\n\tstruct drm_device *dev = &v3d->drm;\n\tstruct dma_fence *fence;\n\tint i;\n\n\tv3d->csd_job = job;\n\n\tv3d_invalidate_caches(v3d);\n\n\tfence = v3d_fence_create(v3d, V3D_CSD);\n\tif (IS_ERR(fence))\n\t\treturn NULL;\n\n\tif (job->base.irq_fence)\n\t\tdma_fence_put(job->base.irq_fence);\n\tjob->base.irq_fence = dma_fence_get(fence);\n\n\ttrace_v3d_submit_csd(dev, to_v3d_fence(fence)->seqno);\n\n\tv3d_switch_perfmon(v3d, &job->base);\n\n\tfor (i = 1; i <= 6; i++)\n\t\tV3D_CORE_WRITE(0, V3D_CSD_QUEUED_CFG0 + 4 * i, job->args.cfg[i]);\n\t \n\tV3D_CORE_WRITE(0, V3D_CSD_QUEUED_CFG0, job->args.cfg[0]);\n\n\treturn fence;\n}\n\nstatic struct dma_fence *\nv3d_cache_clean_job_run(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_job *job = to_v3d_job(sched_job);\n\tstruct v3d_dev *v3d = job->v3d;\n\n\tv3d_clean_caches(v3d);\n\n\treturn NULL;\n}\n\nstatic enum drm_gpu_sched_stat\nv3d_gpu_reset_for_timeout(struct v3d_dev *v3d, struct drm_sched_job *sched_job)\n{\n\tenum v3d_queue q;\n\n\tmutex_lock(&v3d->reset_lock);\n\n\t \n\tfor (q = 0; q < V3D_MAX_QUEUES; q++)\n\t\tdrm_sched_stop(&v3d->queue[q].sched, sched_job);\n\n\tif (sched_job)\n\t\tdrm_sched_increase_karma(sched_job);\n\n\t \n\tv3d_reset(v3d);\n\n\tfor (q = 0; q < V3D_MAX_QUEUES; q++)\n\t\tdrm_sched_resubmit_jobs(&v3d->queue[q].sched);\n\n\t \n\tfor (q = 0; q < V3D_MAX_QUEUES; q++) {\n\t\tdrm_sched_start(&v3d->queue[q].sched, true);\n\t}\n\n\tmutex_unlock(&v3d->reset_lock);\n\n\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n}\n\n \nstatic enum drm_gpu_sched_stat\nv3d_cl_job_timedout(struct drm_sched_job *sched_job, enum v3d_queue q,\n\t\t    u32 *timedout_ctca, u32 *timedout_ctra)\n{\n\tstruct v3d_job *job = to_v3d_job(sched_job);\n\tstruct v3d_dev *v3d = job->v3d;\n\tu32 ctca = V3D_CORE_READ(0, V3D_CLE_CTNCA(q));\n\tu32 ctra = V3D_CORE_READ(0, V3D_CLE_CTNRA(q));\n\n\tif (*timedout_ctca != ctca || *timedout_ctra != ctra) {\n\t\t*timedout_ctca = ctca;\n\t\t*timedout_ctra = ctra;\n\t\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n\t}\n\n\treturn v3d_gpu_reset_for_timeout(v3d, sched_job);\n}\n\nstatic enum drm_gpu_sched_stat\nv3d_bin_job_timedout(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_bin_job *job = to_bin_job(sched_job);\n\n\treturn v3d_cl_job_timedout(sched_job, V3D_BIN,\n\t\t\t\t   &job->timedout_ctca, &job->timedout_ctra);\n}\n\nstatic enum drm_gpu_sched_stat\nv3d_render_job_timedout(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_render_job *job = to_render_job(sched_job);\n\n\treturn v3d_cl_job_timedout(sched_job, V3D_RENDER,\n\t\t\t\t   &job->timedout_ctca, &job->timedout_ctra);\n}\n\nstatic enum drm_gpu_sched_stat\nv3d_generic_job_timedout(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_job *job = to_v3d_job(sched_job);\n\n\treturn v3d_gpu_reset_for_timeout(job->v3d, sched_job);\n}\n\nstatic enum drm_gpu_sched_stat\nv3d_csd_job_timedout(struct drm_sched_job *sched_job)\n{\n\tstruct v3d_csd_job *job = to_csd_job(sched_job);\n\tstruct v3d_dev *v3d = job->base.v3d;\n\tu32 batches = V3D_CORE_READ(0, V3D_CSD_CURRENT_CFG4);\n\n\t \n\tif (job->timedout_batches != batches) {\n\t\tjob->timedout_batches = batches;\n\t\treturn DRM_GPU_SCHED_STAT_NOMINAL;\n\t}\n\n\treturn v3d_gpu_reset_for_timeout(v3d, sched_job);\n}\n\nstatic const struct drm_sched_backend_ops v3d_bin_sched_ops = {\n\t.run_job = v3d_bin_job_run,\n\t.timedout_job = v3d_bin_job_timedout,\n\t.free_job = v3d_sched_job_free,\n};\n\nstatic const struct drm_sched_backend_ops v3d_render_sched_ops = {\n\t.run_job = v3d_render_job_run,\n\t.timedout_job = v3d_render_job_timedout,\n\t.free_job = v3d_sched_job_free,\n};\n\nstatic const struct drm_sched_backend_ops v3d_tfu_sched_ops = {\n\t.run_job = v3d_tfu_job_run,\n\t.timedout_job = v3d_generic_job_timedout,\n\t.free_job = v3d_sched_job_free,\n};\n\nstatic const struct drm_sched_backend_ops v3d_csd_sched_ops = {\n\t.run_job = v3d_csd_job_run,\n\t.timedout_job = v3d_csd_job_timedout,\n\t.free_job = v3d_sched_job_free\n};\n\nstatic const struct drm_sched_backend_ops v3d_cache_clean_sched_ops = {\n\t.run_job = v3d_cache_clean_job_run,\n\t.timedout_job = v3d_generic_job_timedout,\n\t.free_job = v3d_sched_job_free\n};\n\nint\nv3d_sched_init(struct v3d_dev *v3d)\n{\n\tint hw_jobs_limit = 1;\n\tint job_hang_limit = 0;\n\tint hang_limit_ms = 500;\n\tint ret;\n\n\tret = drm_sched_init(&v3d->queue[V3D_BIN].sched,\n\t\t\t     &v3d_bin_sched_ops,\n\t\t\t     hw_jobs_limit, job_hang_limit,\n\t\t\t     msecs_to_jiffies(hang_limit_ms), NULL,\n\t\t\t     NULL, \"v3d_bin\", v3d->drm.dev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = drm_sched_init(&v3d->queue[V3D_RENDER].sched,\n\t\t\t     &v3d_render_sched_ops,\n\t\t\t     hw_jobs_limit, job_hang_limit,\n\t\t\t     msecs_to_jiffies(hang_limit_ms), NULL,\n\t\t\t     NULL, \"v3d_render\", v3d->drm.dev);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = drm_sched_init(&v3d->queue[V3D_TFU].sched,\n\t\t\t     &v3d_tfu_sched_ops,\n\t\t\t     hw_jobs_limit, job_hang_limit,\n\t\t\t     msecs_to_jiffies(hang_limit_ms), NULL,\n\t\t\t     NULL, \"v3d_tfu\", v3d->drm.dev);\n\tif (ret)\n\t\tgoto fail;\n\n\tif (v3d_has_csd(v3d)) {\n\t\tret = drm_sched_init(&v3d->queue[V3D_CSD].sched,\n\t\t\t\t     &v3d_csd_sched_ops,\n\t\t\t\t     hw_jobs_limit, job_hang_limit,\n\t\t\t\t     msecs_to_jiffies(hang_limit_ms), NULL,\n\t\t\t\t     NULL, \"v3d_csd\", v3d->drm.dev);\n\t\tif (ret)\n\t\t\tgoto fail;\n\n\t\tret = drm_sched_init(&v3d->queue[V3D_CACHE_CLEAN].sched,\n\t\t\t\t     &v3d_cache_clean_sched_ops,\n\t\t\t\t     hw_jobs_limit, job_hang_limit,\n\t\t\t\t     msecs_to_jiffies(hang_limit_ms), NULL,\n\t\t\t\t     NULL, \"v3d_cache_clean\", v3d->drm.dev);\n\t\tif (ret)\n\t\t\tgoto fail;\n\t}\n\n\treturn 0;\n\nfail:\n\tv3d_sched_fini(v3d);\n\treturn ret;\n}\n\nvoid\nv3d_sched_fini(struct v3d_dev *v3d)\n{\n\tenum v3d_queue q;\n\n\tfor (q = 0; q < V3D_MAX_QUEUES; q++) {\n\t\tif (v3d->queue[q].sched.ready)\n\t\t\tdrm_sched_fini(&v3d->queue[q].sched);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}