{
  "module_name": "rockchip_drm_gem.c",
  "hash_id": "f0e5099fc8f94c9ead180ec912046f1772acbda87f6de2bccfd3af0459111c74",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/rockchip/rockchip_drm_gem.c",
  "human_readable_source": "\n \n\n#include <linux/dma-buf.h>\n#include <linux/iommu.h>\n#include <linux/vmalloc.h>\n\n#include <drm/drm.h>\n#include <drm/drm_fb_helper.h>\n#include <drm/drm_gem.h>\n#include <drm/drm_gem_dma_helper.h>\n#include <drm/drm_prime.h>\n#include <drm/drm_vma_manager.h>\n\n#include \"rockchip_drm_drv.h\"\n#include \"rockchip_drm_gem.h\"\n\nstatic int rockchip_gem_iommu_map(struct rockchip_gem_object *rk_obj)\n{\n\tstruct drm_device *drm = rk_obj->base.dev;\n\tstruct rockchip_drm_private *private = drm->dev_private;\n\tint prot = IOMMU_READ | IOMMU_WRITE;\n\tssize_t ret;\n\n\tmutex_lock(&private->mm_lock);\n\tret = drm_mm_insert_node_generic(&private->mm, &rk_obj->mm,\n\t\t\t\t\t rk_obj->base.size, PAGE_SIZE,\n\t\t\t\t\t 0, 0);\n\tmutex_unlock(&private->mm_lock);\n\n\tif (ret < 0) {\n\t\tDRM_ERROR(\"out of I/O virtual memory: %zd\\n\", ret);\n\t\treturn ret;\n\t}\n\n\trk_obj->dma_addr = rk_obj->mm.start;\n\n\tret = iommu_map_sgtable(private->domain, rk_obj->dma_addr, rk_obj->sgt,\n\t\t\t\tprot);\n\tif (ret < (ssize_t)rk_obj->base.size) {\n\t\tDRM_ERROR(\"failed to map buffer: size=%zd request_size=%zd\\n\",\n\t\t\t  ret, rk_obj->base.size);\n\t\tret = -ENOMEM;\n\t\tgoto err_remove_node;\n\t}\n\n\trk_obj->size = ret;\n\n\treturn 0;\n\nerr_remove_node:\n\tmutex_lock(&private->mm_lock);\n\tdrm_mm_remove_node(&rk_obj->mm);\n\tmutex_unlock(&private->mm_lock);\n\n\treturn ret;\n}\n\nstatic int rockchip_gem_iommu_unmap(struct rockchip_gem_object *rk_obj)\n{\n\tstruct drm_device *drm = rk_obj->base.dev;\n\tstruct rockchip_drm_private *private = drm->dev_private;\n\n\tiommu_unmap(private->domain, rk_obj->dma_addr, rk_obj->size);\n\n\tmutex_lock(&private->mm_lock);\n\n\tdrm_mm_remove_node(&rk_obj->mm);\n\n\tmutex_unlock(&private->mm_lock);\n\n\treturn 0;\n}\n\nstatic int rockchip_gem_get_pages(struct rockchip_gem_object *rk_obj)\n{\n\tstruct drm_device *drm = rk_obj->base.dev;\n\tint ret, i;\n\tstruct scatterlist *s;\n\n\trk_obj->pages = drm_gem_get_pages(&rk_obj->base);\n\tif (IS_ERR(rk_obj->pages))\n\t\treturn PTR_ERR(rk_obj->pages);\n\n\trk_obj->num_pages = rk_obj->base.size >> PAGE_SHIFT;\n\n\trk_obj->sgt = drm_prime_pages_to_sg(rk_obj->base.dev,\n\t\t\t\t\t    rk_obj->pages, rk_obj->num_pages);\n\tif (IS_ERR(rk_obj->sgt)) {\n\t\tret = PTR_ERR(rk_obj->sgt);\n\t\tgoto err_put_pages;\n\t}\n\n\t \n\tfor_each_sgtable_sg(rk_obj->sgt, s, i)\n\t\tsg_dma_address(s) = sg_phys(s);\n\n\tdma_sync_sgtable_for_device(drm->dev, rk_obj->sgt, DMA_TO_DEVICE);\n\n\treturn 0;\n\nerr_put_pages:\n\tdrm_gem_put_pages(&rk_obj->base, rk_obj->pages, false, false);\n\treturn ret;\n}\n\nstatic void rockchip_gem_put_pages(struct rockchip_gem_object *rk_obj)\n{\n\tsg_free_table(rk_obj->sgt);\n\tkfree(rk_obj->sgt);\n\tdrm_gem_put_pages(&rk_obj->base, rk_obj->pages, true, true);\n}\n\nstatic int rockchip_gem_alloc_iommu(struct rockchip_gem_object *rk_obj,\n\t\t\t\t    bool alloc_kmap)\n{\n\tint ret;\n\n\tret = rockchip_gem_get_pages(rk_obj);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = rockchip_gem_iommu_map(rk_obj);\n\tif (ret < 0)\n\t\tgoto err_free;\n\n\tif (alloc_kmap) {\n\t\trk_obj->kvaddr = vmap(rk_obj->pages, rk_obj->num_pages, VM_MAP,\n\t\t\t\t      pgprot_writecombine(PAGE_KERNEL));\n\t\tif (!rk_obj->kvaddr) {\n\t\t\tDRM_ERROR(\"failed to vmap() buffer\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_unmap;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_unmap:\n\trockchip_gem_iommu_unmap(rk_obj);\nerr_free:\n\trockchip_gem_put_pages(rk_obj);\n\n\treturn ret;\n}\n\nstatic int rockchip_gem_alloc_dma(struct rockchip_gem_object *rk_obj,\n\t\t\t\t  bool alloc_kmap)\n{\n\tstruct drm_gem_object *obj = &rk_obj->base;\n\tstruct drm_device *drm = obj->dev;\n\n\trk_obj->dma_attrs = DMA_ATTR_WRITE_COMBINE;\n\n\tif (!alloc_kmap)\n\t\trk_obj->dma_attrs |= DMA_ATTR_NO_KERNEL_MAPPING;\n\n\trk_obj->kvaddr = dma_alloc_attrs(drm->dev, obj->size,\n\t\t\t\t\t &rk_obj->dma_addr, GFP_KERNEL,\n\t\t\t\t\t rk_obj->dma_attrs);\n\tif (!rk_obj->kvaddr) {\n\t\tDRM_ERROR(\"failed to allocate %zu byte dma buffer\", obj->size);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic int rockchip_gem_alloc_buf(struct rockchip_gem_object *rk_obj,\n\t\t\t\t  bool alloc_kmap)\n{\n\tstruct drm_gem_object *obj = &rk_obj->base;\n\tstruct drm_device *drm = obj->dev;\n\tstruct rockchip_drm_private *private = drm->dev_private;\n\n\tif (private->domain)\n\t\treturn rockchip_gem_alloc_iommu(rk_obj, alloc_kmap);\n\telse\n\t\treturn rockchip_gem_alloc_dma(rk_obj, alloc_kmap);\n}\n\nstatic void rockchip_gem_free_iommu(struct rockchip_gem_object *rk_obj)\n{\n\tvunmap(rk_obj->kvaddr);\n\trockchip_gem_iommu_unmap(rk_obj);\n\trockchip_gem_put_pages(rk_obj);\n}\n\nstatic void rockchip_gem_free_dma(struct rockchip_gem_object *rk_obj)\n{\n\tstruct drm_gem_object *obj = &rk_obj->base;\n\tstruct drm_device *drm = obj->dev;\n\n\tdma_free_attrs(drm->dev, obj->size, rk_obj->kvaddr, rk_obj->dma_addr,\n\t\t       rk_obj->dma_attrs);\n}\n\nstatic void rockchip_gem_free_buf(struct rockchip_gem_object *rk_obj)\n{\n\tif (rk_obj->pages)\n\t\trockchip_gem_free_iommu(rk_obj);\n\telse\n\t\trockchip_gem_free_dma(rk_obj);\n}\n\nstatic int rockchip_drm_gem_object_mmap_iommu(struct drm_gem_object *obj,\n\t\t\t\t\t      struct vm_area_struct *vma)\n{\n\tstruct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);\n\tunsigned int count = obj->size >> PAGE_SHIFT;\n\tunsigned long user_count = vma_pages(vma);\n\n\tif (user_count == 0)\n\t\treturn -ENXIO;\n\n\treturn vm_map_pages(vma, rk_obj->pages, count);\n}\n\nstatic int rockchip_drm_gem_object_mmap_dma(struct drm_gem_object *obj,\n\t\t\t\t\t    struct vm_area_struct *vma)\n{\n\tstruct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);\n\tstruct drm_device *drm = obj->dev;\n\n\treturn dma_mmap_attrs(drm->dev, vma, rk_obj->kvaddr, rk_obj->dma_addr,\n\t\t\t      obj->size, rk_obj->dma_attrs);\n}\n\nstatic int rockchip_drm_gem_object_mmap(struct drm_gem_object *obj,\n\t\t\t\t\tstruct vm_area_struct *vma)\n{\n\tint ret;\n\tstruct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);\n\n\t \n\tvma->vm_pgoff = 0;\n\n\t \n\tvm_flags_mod(vma, VM_IO | VM_DONTEXPAND | VM_DONTDUMP, VM_PFNMAP);\n\n\tvma->vm_page_prot = pgprot_writecombine(vm_get_page_prot(vma->vm_flags));\n\tvma->vm_page_prot = pgprot_decrypted(vma->vm_page_prot);\n\n\tif (rk_obj->pages)\n\t\tret = rockchip_drm_gem_object_mmap_iommu(obj, vma);\n\telse\n\t\tret = rockchip_drm_gem_object_mmap_dma(obj, vma);\n\n\treturn ret;\n}\n\nstatic void rockchip_gem_release_object(struct rockchip_gem_object *rk_obj)\n{\n\tdrm_gem_object_release(&rk_obj->base);\n\tkfree(rk_obj);\n}\n\nstatic const struct drm_gem_object_funcs rockchip_gem_object_funcs = {\n\t.free = rockchip_gem_free_object,\n\t.get_sg_table = rockchip_gem_prime_get_sg_table,\n\t.vmap = rockchip_gem_prime_vmap,\n\t.vunmap\t= rockchip_gem_prime_vunmap,\n\t.mmap = rockchip_drm_gem_object_mmap,\n\t.vm_ops = &drm_gem_dma_vm_ops,\n};\n\nstatic struct rockchip_gem_object *\n\trockchip_gem_alloc_object(struct drm_device *drm, unsigned int size)\n{\n\tstruct rockchip_gem_object *rk_obj;\n\tstruct drm_gem_object *obj;\n\n\tsize = round_up(size, PAGE_SIZE);\n\n\trk_obj = kzalloc(sizeof(*rk_obj), GFP_KERNEL);\n\tif (!rk_obj)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tobj = &rk_obj->base;\n\n\tobj->funcs = &rockchip_gem_object_funcs;\n\n\tdrm_gem_object_init(drm, obj, size);\n\n\treturn rk_obj;\n}\n\nstruct rockchip_gem_object *\nrockchip_gem_create_object(struct drm_device *drm, unsigned int size,\n\t\t\t   bool alloc_kmap)\n{\n\tstruct rockchip_gem_object *rk_obj;\n\tint ret;\n\n\trk_obj = rockchip_gem_alloc_object(drm, size);\n\tif (IS_ERR(rk_obj))\n\t\treturn rk_obj;\n\n\tret = rockchip_gem_alloc_buf(rk_obj, alloc_kmap);\n\tif (ret)\n\t\tgoto err_free_rk_obj;\n\n\treturn rk_obj;\n\nerr_free_rk_obj:\n\trockchip_gem_release_object(rk_obj);\n\treturn ERR_PTR(ret);\n}\n\n \nvoid rockchip_gem_free_object(struct drm_gem_object *obj)\n{\n\tstruct drm_device *drm = obj->dev;\n\tstruct rockchip_drm_private *private = drm->dev_private;\n\tstruct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);\n\n\tif (obj->import_attach) {\n\t\tif (private->domain) {\n\t\t\trockchip_gem_iommu_unmap(rk_obj);\n\t\t} else {\n\t\t\tdma_unmap_sgtable(drm->dev, rk_obj->sgt,\n\t\t\t\t\t  DMA_BIDIRECTIONAL, 0);\n\t\t}\n\t\tdrm_prime_gem_destroy(obj, rk_obj->sgt);\n\t} else {\n\t\trockchip_gem_free_buf(rk_obj);\n\t}\n\n\trockchip_gem_release_object(rk_obj);\n}\n\n \nstatic struct rockchip_gem_object *\nrockchip_gem_create_with_handle(struct drm_file *file_priv,\n\t\t\t\tstruct drm_device *drm, unsigned int size,\n\t\t\t\tunsigned int *handle)\n{\n\tstruct rockchip_gem_object *rk_obj;\n\tstruct drm_gem_object *obj;\n\tbool is_framebuffer;\n\tint ret;\n\n\tis_framebuffer = drm->fb_helper && file_priv == drm->fb_helper->client.file;\n\n\trk_obj = rockchip_gem_create_object(drm, size, is_framebuffer);\n\tif (IS_ERR(rk_obj))\n\t\treturn ERR_CAST(rk_obj);\n\n\tobj = &rk_obj->base;\n\n\t \n\tret = drm_gem_handle_create(file_priv, obj, handle);\n\tif (ret)\n\t\tgoto err_handle_create;\n\n\t \n\tdrm_gem_object_put(obj);\n\n\treturn rk_obj;\n\nerr_handle_create:\n\trockchip_gem_free_object(obj);\n\n\treturn ERR_PTR(ret);\n}\n\n \nint rockchip_gem_dumb_create(struct drm_file *file_priv,\n\t\t\t     struct drm_device *dev,\n\t\t\t     struct drm_mode_create_dumb *args)\n{\n\tstruct rockchip_gem_object *rk_obj;\n\tint min_pitch = DIV_ROUND_UP(args->width * args->bpp, 8);\n\n\t \n\targs->pitch = ALIGN(min_pitch, 64);\n\targs->size = args->pitch * args->height;\n\n\trk_obj = rockchip_gem_create_with_handle(file_priv, dev, args->size,\n\t\t\t\t\t\t &args->handle);\n\n\treturn PTR_ERR_OR_ZERO(rk_obj);\n}\n\n \nstruct sg_table *rockchip_gem_prime_get_sg_table(struct drm_gem_object *obj)\n{\n\tstruct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);\n\tstruct drm_device *drm = obj->dev;\n\tstruct sg_table *sgt;\n\tint ret;\n\n\tif (rk_obj->pages)\n\t\treturn drm_prime_pages_to_sg(obj->dev, rk_obj->pages, rk_obj->num_pages);\n\n\tsgt = kzalloc(sizeof(*sgt), GFP_KERNEL);\n\tif (!sgt)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = dma_get_sgtable_attrs(drm->dev, sgt, rk_obj->kvaddr,\n\t\t\t\t    rk_obj->dma_addr, obj->size,\n\t\t\t\t    rk_obj->dma_attrs);\n\tif (ret) {\n\t\tDRM_ERROR(\"failed to allocate sgt, %d\\n\", ret);\n\t\tkfree(sgt);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn sgt;\n}\n\nstatic int\nrockchip_gem_iommu_map_sg(struct drm_device *drm,\n\t\t\t  struct dma_buf_attachment *attach,\n\t\t\t  struct sg_table *sg,\n\t\t\t  struct rockchip_gem_object *rk_obj)\n{\n\trk_obj->sgt = sg;\n\treturn rockchip_gem_iommu_map(rk_obj);\n}\n\nstatic int\nrockchip_gem_dma_map_sg(struct drm_device *drm,\n\t\t\tstruct dma_buf_attachment *attach,\n\t\t\tstruct sg_table *sg,\n\t\t\tstruct rockchip_gem_object *rk_obj)\n{\n\tint err = dma_map_sgtable(drm->dev, sg, DMA_BIDIRECTIONAL, 0);\n\tif (err)\n\t\treturn err;\n\n\tif (drm_prime_get_contiguous_size(sg) < attach->dmabuf->size) {\n\t\tDRM_ERROR(\"failed to map sg_table to contiguous linear address.\\n\");\n\t\tdma_unmap_sgtable(drm->dev, sg, DMA_BIDIRECTIONAL, 0);\n\t\treturn -EINVAL;\n\t}\n\n\trk_obj->dma_addr = sg_dma_address(sg->sgl);\n\trk_obj->sgt = sg;\n\treturn 0;\n}\n\nstruct drm_gem_object *\nrockchip_gem_prime_import_sg_table(struct drm_device *drm,\n\t\t\t\t   struct dma_buf_attachment *attach,\n\t\t\t\t   struct sg_table *sg)\n{\n\tstruct rockchip_drm_private *private = drm->dev_private;\n\tstruct rockchip_gem_object *rk_obj;\n\tint ret;\n\n\trk_obj = rockchip_gem_alloc_object(drm, attach->dmabuf->size);\n\tif (IS_ERR(rk_obj))\n\t\treturn ERR_CAST(rk_obj);\n\n\tif (private->domain)\n\t\tret = rockchip_gem_iommu_map_sg(drm, attach, sg, rk_obj);\n\telse\n\t\tret = rockchip_gem_dma_map_sg(drm, attach, sg, rk_obj);\n\n\tif (ret < 0) {\n\t\tDRM_ERROR(\"failed to import sg table: %d\\n\", ret);\n\t\tgoto err_free_rk_obj;\n\t}\n\n\treturn &rk_obj->base;\n\nerr_free_rk_obj:\n\trockchip_gem_release_object(rk_obj);\n\treturn ERR_PTR(ret);\n}\n\nint rockchip_gem_prime_vmap(struct drm_gem_object *obj, struct iosys_map *map)\n{\n\tstruct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);\n\n\tif (rk_obj->pages) {\n\t\tvoid *vaddr;\n\n\t\tif (rk_obj->kvaddr)\n\t\t\tvaddr = rk_obj->kvaddr;\n\t\telse\n\t\t\tvaddr = vmap(rk_obj->pages, rk_obj->num_pages, VM_MAP,\n\t\t\t\t     pgprot_writecombine(PAGE_KERNEL));\n\n\t\tif (!vaddr)\n\t\t\treturn -ENOMEM;\n\t\tiosys_map_set_vaddr(map, vaddr);\n\t\treturn 0;\n\t}\n\n\tif (rk_obj->dma_attrs & DMA_ATTR_NO_KERNEL_MAPPING)\n\t\treturn -ENOMEM;\n\tiosys_map_set_vaddr(map, rk_obj->kvaddr);\n\n\treturn 0;\n}\n\nvoid rockchip_gem_prime_vunmap(struct drm_gem_object *obj,\n\t\t\t       struct iosys_map *map)\n{\n\tstruct rockchip_gem_object *rk_obj = to_rockchip_obj(obj);\n\n\tif (rk_obj->pages) {\n\t\tif (map->vaddr != rk_obj->kvaddr)\n\t\t\tvunmap(map->vaddr);\n\t\treturn;\n\t}\n\n\t \n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}