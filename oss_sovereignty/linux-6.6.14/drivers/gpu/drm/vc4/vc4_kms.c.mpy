{
  "module_name": "vc4_kms.c",
  "hash_id": "d7738b2d03cfeb45ea1e6262843ed533f8ba12ebe0411f2849f8c4d8ced03fe8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vc4/vc4_kms.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/clk.h>\n#include <linux/sort.h>\n\n#include <drm/drm_atomic.h>\n#include <drm/drm_atomic_helper.h>\n#include <drm/drm_crtc.h>\n#include <drm/drm_fourcc.h>\n#include <drm/drm_gem_framebuffer_helper.h>\n#include <drm/drm_probe_helper.h>\n#include <drm/drm_vblank.h>\n\n#include \"vc4_drv.h\"\n#include \"vc4_regs.h\"\n\nstruct vc4_ctm_state {\n\tstruct drm_private_state base;\n\tstruct drm_color_ctm *ctm;\n\tint fifo;\n};\n\n#define to_vc4_ctm_state(_state)\t\t\t\t\\\n\tcontainer_of_const(_state, struct vc4_ctm_state, base)\n\nstruct vc4_load_tracker_state {\n\tstruct drm_private_state base;\n\tu64 hvs_load;\n\tu64 membus_load;\n};\n\n#define to_vc4_load_tracker_state(_state)\t\t\t\t\\\n\tcontainer_of_const(_state, struct vc4_load_tracker_state, base)\n\nstatic struct vc4_ctm_state *vc4_get_ctm_state(struct drm_atomic_state *state,\n\t\t\t\t\t       struct drm_private_obj *manager)\n{\n\tstruct drm_device *dev = state->dev;\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\tstruct drm_private_state *priv_state;\n\tint ret;\n\n\tret = drm_modeset_lock(&vc4->ctm_state_lock, state->acquire_ctx);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\n\tpriv_state = drm_atomic_get_private_obj_state(state, manager);\n\tif (IS_ERR(priv_state))\n\t\treturn ERR_CAST(priv_state);\n\n\treturn to_vc4_ctm_state(priv_state);\n}\n\nstatic struct drm_private_state *\nvc4_ctm_duplicate_state(struct drm_private_obj *obj)\n{\n\tstruct vc4_ctm_state *state;\n\n\tstate = kmemdup(obj->state, sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn NULL;\n\n\t__drm_atomic_helper_private_obj_duplicate_state(obj, &state->base);\n\n\treturn &state->base;\n}\n\nstatic void vc4_ctm_destroy_state(struct drm_private_obj *obj,\n\t\t\t\t  struct drm_private_state *state)\n{\n\tstruct vc4_ctm_state *ctm_state = to_vc4_ctm_state(state);\n\n\tkfree(ctm_state);\n}\n\nstatic const struct drm_private_state_funcs vc4_ctm_state_funcs = {\n\t.atomic_duplicate_state = vc4_ctm_duplicate_state,\n\t.atomic_destroy_state = vc4_ctm_destroy_state,\n};\n\nstatic void vc4_ctm_obj_fini(struct drm_device *dev, void *unused)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\n\tdrm_atomic_private_obj_fini(&vc4->ctm_manager);\n}\n\nstatic int vc4_ctm_obj_init(struct vc4_dev *vc4)\n{\n\tstruct vc4_ctm_state *ctm_state;\n\n\tdrm_modeset_lock_init(&vc4->ctm_state_lock);\n\n\tctm_state = kzalloc(sizeof(*ctm_state), GFP_KERNEL);\n\tif (!ctm_state)\n\t\treturn -ENOMEM;\n\n\tdrm_atomic_private_obj_init(&vc4->base, &vc4->ctm_manager, &ctm_state->base,\n\t\t\t\t    &vc4_ctm_state_funcs);\n\n\treturn drmm_add_action_or_reset(&vc4->base, vc4_ctm_obj_fini, NULL);\n}\n\n \nstatic u16 vc4_ctm_s31_32_to_s0_9(u64 in)\n{\n\tu16 r;\n\n\t \n\tr = in & BIT_ULL(63) ? BIT(9) : 0;\n\n\tif ((in & GENMASK_ULL(62, 32)) > 0) {\n\t\t \n\t\tr |= GENMASK(8, 0);\n\t} else {\n\t\t \n\t\tr |= (in >> 23) & GENMASK(8, 0);\n\t}\n\n\treturn r;\n}\n\nstatic void\nvc4_ctm_commit(struct vc4_dev *vc4, struct drm_atomic_state *state)\n{\n\tstruct vc4_hvs *hvs = vc4->hvs;\n\tstruct vc4_ctm_state *ctm_state = to_vc4_ctm_state(vc4->ctm_manager.state);\n\tstruct drm_color_ctm *ctm = ctm_state->ctm;\n\n\tif (ctm_state->fifo) {\n\t\tHVS_WRITE(SCALER_OLEDCOEF2,\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[0]),\n\t\t\t\t\tSCALER_OLEDCOEF2_R_TO_R) |\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[3]),\n\t\t\t\t\tSCALER_OLEDCOEF2_R_TO_G) |\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[6]),\n\t\t\t\t\tSCALER_OLEDCOEF2_R_TO_B));\n\t\tHVS_WRITE(SCALER_OLEDCOEF1,\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[1]),\n\t\t\t\t\tSCALER_OLEDCOEF1_G_TO_R) |\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[4]),\n\t\t\t\t\tSCALER_OLEDCOEF1_G_TO_G) |\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[7]),\n\t\t\t\t\tSCALER_OLEDCOEF1_G_TO_B));\n\t\tHVS_WRITE(SCALER_OLEDCOEF0,\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[2]),\n\t\t\t\t\tSCALER_OLEDCOEF0_B_TO_R) |\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[5]),\n\t\t\t\t\tSCALER_OLEDCOEF0_B_TO_G) |\n\t\t\t  VC4_SET_FIELD(vc4_ctm_s31_32_to_s0_9(ctm->matrix[8]),\n\t\t\t\t\tSCALER_OLEDCOEF0_B_TO_B));\n\t}\n\n\tHVS_WRITE(SCALER_OLEDOFFS,\n\t\t  VC4_SET_FIELD(ctm_state->fifo, SCALER_OLEDOFFS_DISPFIFO));\n}\n\nstruct vc4_hvs_state *\nvc4_hvs_get_new_global_state(const struct drm_atomic_state *state)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(state->dev);\n\tstruct drm_private_state *priv_state;\n\n\tpriv_state = drm_atomic_get_new_private_obj_state(state, &vc4->hvs_channels);\n\tif (!priv_state)\n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn to_vc4_hvs_state(priv_state);\n}\n\nstruct vc4_hvs_state *\nvc4_hvs_get_old_global_state(const struct drm_atomic_state *state)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(state->dev);\n\tstruct drm_private_state *priv_state;\n\n\tpriv_state = drm_atomic_get_old_private_obj_state(state, &vc4->hvs_channels);\n\tif (!priv_state)\n\t\treturn ERR_PTR(-EINVAL);\n\n\treturn to_vc4_hvs_state(priv_state);\n}\n\nstruct vc4_hvs_state *\nvc4_hvs_get_global_state(struct drm_atomic_state *state)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(state->dev);\n\tstruct drm_private_state *priv_state;\n\n\tpriv_state = drm_atomic_get_private_obj_state(state, &vc4->hvs_channels);\n\tif (IS_ERR(priv_state))\n\t\treturn ERR_CAST(priv_state);\n\n\treturn to_vc4_hvs_state(priv_state);\n}\n\nstatic void vc4_hvs_pv_muxing_commit(struct vc4_dev *vc4,\n\t\t\t\t     struct drm_atomic_state *state)\n{\n\tstruct vc4_hvs *hvs = vc4->hvs;\n\tstruct drm_crtc_state *crtc_state;\n\tstruct drm_crtc *crtc;\n\tunsigned int i;\n\n\tfor_each_new_crtc_in_state(state, crtc, crtc_state, i) {\n\t\tstruct vc4_crtc *vc4_crtc = to_vc4_crtc(crtc);\n\t\tstruct vc4_crtc_state *vc4_state = to_vc4_crtc_state(crtc_state);\n\t\tu32 dispctrl;\n\t\tu32 dsp3_mux;\n\n\t\tif (!crtc_state->active)\n\t\t\tcontinue;\n\n\t\tif (vc4_state->assigned_channel != 2)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (vc4_crtc->feeds_txp)\n\t\t\tdsp3_mux = VC4_SET_FIELD(3, SCALER_DISPCTRL_DSP3_MUX);\n\t\telse\n\t\t\tdsp3_mux = VC4_SET_FIELD(2, SCALER_DISPCTRL_DSP3_MUX);\n\n\t\tdispctrl = HVS_READ(SCALER_DISPCTRL) &\n\t\t\t   ~SCALER_DISPCTRL_DSP3_MUX_MASK;\n\t\tHVS_WRITE(SCALER_DISPCTRL, dispctrl | dsp3_mux);\n\t}\n}\n\nstatic void vc5_hvs_pv_muxing_commit(struct vc4_dev *vc4,\n\t\t\t\t     struct drm_atomic_state *state)\n{\n\tstruct vc4_hvs *hvs = vc4->hvs;\n\tstruct drm_crtc_state *crtc_state;\n\tstruct drm_crtc *crtc;\n\tunsigned char mux;\n\tunsigned int i;\n\tu32 reg;\n\n\tfor_each_new_crtc_in_state(state, crtc, crtc_state, i) {\n\t\tstruct vc4_crtc_state *vc4_state = to_vc4_crtc_state(crtc_state);\n\t\tstruct vc4_crtc *vc4_crtc = to_vc4_crtc(crtc);\n\t\tunsigned int channel = vc4_state->assigned_channel;\n\n\t\tif (!vc4_state->update_muxing)\n\t\t\tcontinue;\n\n\t\tswitch (vc4_crtc->data->hvs_output) {\n\t\tcase 2:\n\t\t\tdrm_WARN_ON(&vc4->base,\n\t\t\t\t    VC4_GET_FIELD(HVS_READ(SCALER_DISPCTRL),\n\t\t\t\t\t\t  SCALER_DISPCTRL_DSP3_MUX) == channel);\n\n\t\t\tmux = (channel == 2) ? 0 : 1;\n\t\t\treg = HVS_READ(SCALER_DISPECTRL);\n\t\t\tHVS_WRITE(SCALER_DISPECTRL,\n\t\t\t\t  (reg & ~SCALER_DISPECTRL_DSP2_MUX_MASK) |\n\t\t\t\t  VC4_SET_FIELD(mux, SCALER_DISPECTRL_DSP2_MUX));\n\t\t\tbreak;\n\n\t\tcase 3:\n\t\t\tif (channel == VC4_HVS_CHANNEL_DISABLED)\n\t\t\t\tmux = 3;\n\t\t\telse\n\t\t\t\tmux = channel;\n\n\t\t\treg = HVS_READ(SCALER_DISPCTRL);\n\t\t\tHVS_WRITE(SCALER_DISPCTRL,\n\t\t\t\t  (reg & ~SCALER_DISPCTRL_DSP3_MUX_MASK) |\n\t\t\t\t  VC4_SET_FIELD(mux, SCALER_DISPCTRL_DSP3_MUX));\n\t\t\tbreak;\n\n\t\tcase 4:\n\t\t\tif (channel == VC4_HVS_CHANNEL_DISABLED)\n\t\t\t\tmux = 3;\n\t\t\telse\n\t\t\t\tmux = channel;\n\n\t\t\treg = HVS_READ(SCALER_DISPEOLN);\n\t\t\tHVS_WRITE(SCALER_DISPEOLN,\n\t\t\t\t  (reg & ~SCALER_DISPEOLN_DSP4_MUX_MASK) |\n\t\t\t\t  VC4_SET_FIELD(mux, SCALER_DISPEOLN_DSP4_MUX));\n\n\t\t\tbreak;\n\n\t\tcase 5:\n\t\t\tif (channel == VC4_HVS_CHANNEL_DISABLED)\n\t\t\t\tmux = 3;\n\t\t\telse\n\t\t\t\tmux = channel;\n\n\t\t\treg = HVS_READ(SCALER_DISPDITHER);\n\t\t\tHVS_WRITE(SCALER_DISPDITHER,\n\t\t\t\t  (reg & ~SCALER_DISPDITHER_DSP5_MUX_MASK) |\n\t\t\t\t  VC4_SET_FIELD(mux, SCALER_DISPDITHER_DSP5_MUX));\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void vc4_atomic_commit_tail(struct drm_atomic_state *state)\n{\n\tstruct drm_device *dev = state->dev;\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\tstruct vc4_hvs *hvs = vc4->hvs;\n\tstruct drm_crtc_state *new_crtc_state;\n\tstruct vc4_hvs_state *new_hvs_state;\n\tstruct drm_crtc *crtc;\n\tstruct vc4_hvs_state *old_hvs_state;\n\tunsigned int channel;\n\tint i;\n\n\told_hvs_state = vc4_hvs_get_old_global_state(state);\n\tif (WARN_ON(IS_ERR(old_hvs_state)))\n\t\treturn;\n\n\tnew_hvs_state = vc4_hvs_get_new_global_state(state);\n\tif (WARN_ON(IS_ERR(new_hvs_state)))\n\t\treturn;\n\n\tfor_each_new_crtc_in_state(state, crtc, new_crtc_state, i) {\n\t\tstruct vc4_crtc_state *vc4_crtc_state;\n\n\t\tif (!new_crtc_state->commit)\n\t\t\tcontinue;\n\n\t\tvc4_crtc_state = to_vc4_crtc_state(new_crtc_state);\n\t\tvc4_hvs_mask_underrun(hvs, vc4_crtc_state->assigned_channel);\n\t}\n\n\tfor (channel = 0; channel < HVS_NUM_CHANNELS; channel++) {\n\t\tstruct drm_crtc_commit *commit;\n\t\tint ret;\n\n\t\tif (!old_hvs_state->fifo_state[channel].in_use)\n\t\t\tcontinue;\n\n\t\tcommit = old_hvs_state->fifo_state[channel].pending_commit;\n\t\tif (!commit)\n\t\t\tcontinue;\n\n\t\tret = drm_crtc_commit_wait(commit);\n\t\tif (ret)\n\t\t\tdrm_err(dev, \"Timed out waiting for commit\\n\");\n\n\t\tdrm_crtc_commit_put(commit);\n\t\told_hvs_state->fifo_state[channel].pending_commit = NULL;\n\t}\n\n\tif (vc4->is_vc5) {\n\t\tunsigned long state_rate = max(old_hvs_state->core_clock_rate,\n\t\t\t\t\t       new_hvs_state->core_clock_rate);\n\t\tunsigned long core_rate = clamp_t(unsigned long, state_rate,\n\t\t\t\t\t\t  500000000, hvs->max_core_rate);\n\n\t\tdrm_dbg(dev, \"Raising the core clock at %lu Hz\\n\", core_rate);\n\n\t\t \n\t\tWARN_ON(clk_set_min_rate(hvs->core_clk, core_rate));\n\t}\n\n\tdrm_atomic_helper_commit_modeset_disables(dev, state);\n\n\tvc4_ctm_commit(vc4, state);\n\n\tif (vc4->is_vc5)\n\t\tvc5_hvs_pv_muxing_commit(vc4, state);\n\telse\n\t\tvc4_hvs_pv_muxing_commit(vc4, state);\n\n\tdrm_atomic_helper_commit_planes(dev, state,\n\t\t\t\t\tDRM_PLANE_COMMIT_ACTIVE_ONLY);\n\n\tdrm_atomic_helper_commit_modeset_enables(dev, state);\n\n\tdrm_atomic_helper_fake_vblank(state);\n\n\tdrm_atomic_helper_commit_hw_done(state);\n\n\tdrm_atomic_helper_wait_for_flip_done(dev, state);\n\n\tdrm_atomic_helper_cleanup_planes(dev, state);\n\n\tif (vc4->is_vc5) {\n\t\tunsigned long core_rate = min_t(unsigned long,\n\t\t\t\t\t\thvs->max_core_rate,\n\t\t\t\t\t\tnew_hvs_state->core_clock_rate);\n\n\t\tdrm_dbg(dev, \"Running the core clock at %lu Hz\\n\", core_rate);\n\n\t\t \n\t\tWARN_ON(clk_set_min_rate(hvs->core_clk, core_rate));\n\n\t\tdrm_dbg(dev, \"Core clock actual rate: %lu Hz\\n\",\n\t\t\tclk_get_rate(hvs->core_clk));\n\t}\n}\n\nstatic int vc4_atomic_commit_setup(struct drm_atomic_state *state)\n{\n\tstruct drm_crtc_state *crtc_state;\n\tstruct vc4_hvs_state *hvs_state;\n\tstruct drm_crtc *crtc;\n\tunsigned int i;\n\n\thvs_state = vc4_hvs_get_new_global_state(state);\n\tif (WARN_ON(IS_ERR(hvs_state)))\n\t\treturn PTR_ERR(hvs_state);\n\n\tfor_each_new_crtc_in_state(state, crtc, crtc_state, i) {\n\t\tstruct vc4_crtc_state *vc4_crtc_state =\n\t\t\tto_vc4_crtc_state(crtc_state);\n\t\tunsigned int channel =\n\t\t\tvc4_crtc_state->assigned_channel;\n\n\t\tif (channel == VC4_HVS_CHANNEL_DISABLED)\n\t\t\tcontinue;\n\n\t\tif (!hvs_state->fifo_state[channel].in_use)\n\t\t\tcontinue;\n\n\t\thvs_state->fifo_state[channel].pending_commit =\n\t\t\tdrm_crtc_commit_get(crtc_state->commit);\n\t}\n\n\treturn 0;\n}\n\nstatic struct drm_framebuffer *vc4_fb_create(struct drm_device *dev,\n\t\t\t\t\t     struct drm_file *file_priv,\n\t\t\t\t\t     const struct drm_mode_fb_cmd2 *mode_cmd)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\tstruct drm_mode_fb_cmd2 mode_cmd_local;\n\n\tif (WARN_ON_ONCE(vc4->is_vc5))\n\t\treturn ERR_PTR(-ENODEV);\n\n\t \n\tif (!(mode_cmd->flags & DRM_MODE_FB_MODIFIERS)) {\n\t\tstruct drm_gem_object *gem_obj;\n\t\tstruct vc4_bo *bo;\n\n\t\tgem_obj = drm_gem_object_lookup(file_priv,\n\t\t\t\t\t\tmode_cmd->handles[0]);\n\t\tif (!gem_obj) {\n\t\t\tDRM_DEBUG(\"Failed to look up GEM BO %d\\n\",\n\t\t\t\t  mode_cmd->handles[0]);\n\t\t\treturn ERR_PTR(-ENOENT);\n\t\t}\n\t\tbo = to_vc4_bo(gem_obj);\n\n\t\tmode_cmd_local = *mode_cmd;\n\n\t\tif (bo->t_format) {\n\t\t\tmode_cmd_local.modifier[0] =\n\t\t\t\tDRM_FORMAT_MOD_BROADCOM_VC4_T_TILED;\n\t\t} else {\n\t\t\tmode_cmd_local.modifier[0] = DRM_FORMAT_MOD_NONE;\n\t\t}\n\n\t\tdrm_gem_object_put(gem_obj);\n\n\t\tmode_cmd = &mode_cmd_local;\n\t}\n\n\treturn drm_gem_fb_create(dev, file_priv, mode_cmd);\n}\n\n \nstatic int\nvc4_ctm_atomic_check(struct drm_device *dev, struct drm_atomic_state *state)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\tstruct vc4_ctm_state *ctm_state = NULL;\n\tstruct drm_crtc *crtc;\n\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\tstruct drm_color_ctm *ctm;\n\tint i;\n\n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\t \n\t\tif (!new_crtc_state->ctm && old_crtc_state->ctm) {\n\t\t\tctm_state = vc4_get_ctm_state(state, &vc4->ctm_manager);\n\t\t\tif (IS_ERR(ctm_state))\n\t\t\t\treturn PTR_ERR(ctm_state);\n\t\t\tctm_state->fifo = 0;\n\t\t}\n\t}\n\n\tfor_each_oldnew_crtc_in_state(state, crtc, old_crtc_state, new_crtc_state, i) {\n\t\tif (new_crtc_state->ctm == old_crtc_state->ctm)\n\t\t\tcontinue;\n\n\t\tif (!ctm_state) {\n\t\t\tctm_state = vc4_get_ctm_state(state, &vc4->ctm_manager);\n\t\t\tif (IS_ERR(ctm_state))\n\t\t\t\treturn PTR_ERR(ctm_state);\n\t\t}\n\n\t\t \n\t\tif (new_crtc_state->ctm) {\n\t\t\tstruct vc4_crtc_state *vc4_crtc_state =\n\t\t\t\tto_vc4_crtc_state(new_crtc_state);\n\n\t\t\t \n\t\t\tint fifo = vc4_crtc_state->assigned_channel + 1;\n\n\t\t\t \n\t\t\tif (ctm_state->fifo && ctm_state->fifo != fifo) {\n\t\t\t\tDRM_DEBUG_DRIVER(\"Too many CTM configured\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t \n\t\t\tctm = new_crtc_state->ctm->data;\n\t\t\tfor (i = 0; i < ARRAY_SIZE(ctm->matrix); i++) {\n\t\t\t\tu64 val = ctm->matrix[i];\n\n\t\t\t\tval &= ~BIT_ULL(63);\n\t\t\t\tif (val > BIT_ULL(32))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tctm_state->fifo = fifo;\n\t\t\tctm_state->ctm = ctm;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int vc4_load_tracker_atomic_check(struct drm_atomic_state *state)\n{\n\tstruct drm_plane_state *old_plane_state, *new_plane_state;\n\tstruct vc4_dev *vc4 = to_vc4_dev(state->dev);\n\tstruct vc4_load_tracker_state *load_state;\n\tstruct drm_private_state *priv_state;\n\tstruct drm_plane *plane;\n\tint i;\n\n\tpriv_state = drm_atomic_get_private_obj_state(state,\n\t\t\t\t\t\t      &vc4->load_tracker);\n\tif (IS_ERR(priv_state))\n\t\treturn PTR_ERR(priv_state);\n\n\tload_state = to_vc4_load_tracker_state(priv_state);\n\tfor_each_oldnew_plane_in_state(state, plane, old_plane_state,\n\t\t\t\t       new_plane_state, i) {\n\t\tstruct vc4_plane_state *vc4_plane_state;\n\n\t\tif (old_plane_state->fb && old_plane_state->crtc) {\n\t\t\tvc4_plane_state = to_vc4_plane_state(old_plane_state);\n\t\t\tload_state->membus_load -= vc4_plane_state->membus_load;\n\t\t\tload_state->hvs_load -= vc4_plane_state->hvs_load;\n\t\t}\n\n\t\tif (new_plane_state->fb && new_plane_state->crtc) {\n\t\t\tvc4_plane_state = to_vc4_plane_state(new_plane_state);\n\t\t\tload_state->membus_load += vc4_plane_state->membus_load;\n\t\t\tload_state->hvs_load += vc4_plane_state->hvs_load;\n\t\t}\n\t}\n\n\t \n\tif (!vc4->load_tracker_enabled)\n\t\treturn 0;\n\n\t \n\tif (load_state->membus_load > SZ_1G + SZ_512M)\n\t\treturn -ENOSPC;\n\n\t \n\tif (load_state->hvs_load > 240000000ULL)\n\t\treturn -ENOSPC;\n\n\treturn 0;\n}\n\nstatic struct drm_private_state *\nvc4_load_tracker_duplicate_state(struct drm_private_obj *obj)\n{\n\tstruct vc4_load_tracker_state *state;\n\n\tstate = kmemdup(obj->state, sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn NULL;\n\n\t__drm_atomic_helper_private_obj_duplicate_state(obj, &state->base);\n\n\treturn &state->base;\n}\n\nstatic void vc4_load_tracker_destroy_state(struct drm_private_obj *obj,\n\t\t\t\t\t   struct drm_private_state *state)\n{\n\tstruct vc4_load_tracker_state *load_state;\n\n\tload_state = to_vc4_load_tracker_state(state);\n\tkfree(load_state);\n}\n\nstatic const struct drm_private_state_funcs vc4_load_tracker_state_funcs = {\n\t.atomic_duplicate_state = vc4_load_tracker_duplicate_state,\n\t.atomic_destroy_state = vc4_load_tracker_destroy_state,\n};\n\nstatic void vc4_load_tracker_obj_fini(struct drm_device *dev, void *unused)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\n\tdrm_atomic_private_obj_fini(&vc4->load_tracker);\n}\n\nstatic int vc4_load_tracker_obj_init(struct vc4_dev *vc4)\n{\n\tstruct vc4_load_tracker_state *load_state;\n\n\tload_state = kzalloc(sizeof(*load_state), GFP_KERNEL);\n\tif (!load_state)\n\t\treturn -ENOMEM;\n\n\tdrm_atomic_private_obj_init(&vc4->base, &vc4->load_tracker,\n\t\t\t\t    &load_state->base,\n\t\t\t\t    &vc4_load_tracker_state_funcs);\n\n\treturn drmm_add_action_or_reset(&vc4->base, vc4_load_tracker_obj_fini, NULL);\n}\n\nstatic struct drm_private_state *\nvc4_hvs_channels_duplicate_state(struct drm_private_obj *obj)\n{\n\tstruct vc4_hvs_state *old_state = to_vc4_hvs_state(obj->state);\n\tstruct vc4_hvs_state *state;\n\tunsigned int i;\n\n\tstate = kzalloc(sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn NULL;\n\n\t__drm_atomic_helper_private_obj_duplicate_state(obj, &state->base);\n\n\tfor (i = 0; i < HVS_NUM_CHANNELS; i++) {\n\t\tstate->fifo_state[i].in_use = old_state->fifo_state[i].in_use;\n\t\tstate->fifo_state[i].fifo_load = old_state->fifo_state[i].fifo_load;\n\t}\n\n\tstate->core_clock_rate = old_state->core_clock_rate;\n\n\treturn &state->base;\n}\n\nstatic void vc4_hvs_channels_destroy_state(struct drm_private_obj *obj,\n\t\t\t\t\t   struct drm_private_state *state)\n{\n\tstruct vc4_hvs_state *hvs_state = to_vc4_hvs_state(state);\n\tunsigned int i;\n\n\tfor (i = 0; i < HVS_NUM_CHANNELS; i++) {\n\t\tif (!hvs_state->fifo_state[i].pending_commit)\n\t\t\tcontinue;\n\n\t\tdrm_crtc_commit_put(hvs_state->fifo_state[i].pending_commit);\n\t}\n\n\tkfree(hvs_state);\n}\n\nstatic void vc4_hvs_channels_print_state(struct drm_printer *p,\n\t\t\t\t\t const struct drm_private_state *state)\n{\n\tconst struct vc4_hvs_state *hvs_state = to_vc4_hvs_state(state);\n\tunsigned int i;\n\n\tdrm_printf(p, \"HVS State\\n\");\n\tdrm_printf(p, \"\\tCore Clock Rate: %lu\\n\", hvs_state->core_clock_rate);\n\n\tfor (i = 0; i < HVS_NUM_CHANNELS; i++) {\n\t\tdrm_printf(p, \"\\tChannel %d\\n\", i);\n\t\tdrm_printf(p, \"\\t\\tin use=%d\\n\", hvs_state->fifo_state[i].in_use);\n\t\tdrm_printf(p, \"\\t\\tload=%lu\\n\", hvs_state->fifo_state[i].fifo_load);\n\t}\n}\n\nstatic const struct drm_private_state_funcs vc4_hvs_state_funcs = {\n\t.atomic_duplicate_state = vc4_hvs_channels_duplicate_state,\n\t.atomic_destroy_state = vc4_hvs_channels_destroy_state,\n\t.atomic_print_state = vc4_hvs_channels_print_state,\n};\n\nstatic void vc4_hvs_channels_obj_fini(struct drm_device *dev, void *unused)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\n\tdrm_atomic_private_obj_fini(&vc4->hvs_channels);\n}\n\nstatic int vc4_hvs_channels_obj_init(struct vc4_dev *vc4)\n{\n\tstruct vc4_hvs_state *state;\n\n\tstate = kzalloc(sizeof(*state), GFP_KERNEL);\n\tif (!state)\n\t\treturn -ENOMEM;\n\n\tdrm_atomic_private_obj_init(&vc4->base, &vc4->hvs_channels,\n\t\t\t\t    &state->base,\n\t\t\t\t    &vc4_hvs_state_funcs);\n\n\treturn drmm_add_action_or_reset(&vc4->base, vc4_hvs_channels_obj_fini, NULL);\n}\n\nstatic int cmp_vc4_crtc_hvs_output(const void *a, const void *b)\n{\n\tconst struct vc4_crtc *crtc_a =\n\t\tto_vc4_crtc(*(const struct drm_crtc **)a);\n\tconst struct vc4_crtc_data *data_a =\n\t\tvc4_crtc_to_vc4_crtc_data(crtc_a);\n\tconst struct vc4_crtc *crtc_b =\n\t\tto_vc4_crtc(*(const struct drm_crtc **)b);\n\tconst struct vc4_crtc_data *data_b =\n\t\tvc4_crtc_to_vc4_crtc_data(crtc_b);\n\n\treturn data_a->hvs_output - data_b->hvs_output;\n}\n\n \nstatic int vc4_pv_muxing_atomic_check(struct drm_device *dev,\n\t\t\t\t      struct drm_atomic_state *state)\n{\n\tstruct vc4_hvs_state *hvs_new_state;\n\tstruct drm_crtc **sorted_crtcs;\n\tstruct drm_crtc *crtc;\n\tunsigned int unassigned_channels = 0;\n\tunsigned int i;\n\tint ret;\n\n\thvs_new_state = vc4_hvs_get_global_state(state);\n\tif (IS_ERR(hvs_new_state))\n\t\treturn PTR_ERR(hvs_new_state);\n\n\tfor (i = 0; i < ARRAY_SIZE(hvs_new_state->fifo_state); i++)\n\t\tif (!hvs_new_state->fifo_state[i].in_use)\n\t\t\tunassigned_channels |= BIT(i);\n\n\t \n\tsorted_crtcs = kmalloc_array(dev->num_crtcs, sizeof(*sorted_crtcs), GFP_KERNEL);\n\tif (!sorted_crtcs)\n\t\treturn -ENOMEM;\n\n\ti = 0;\n\tdrm_for_each_crtc(crtc, dev)\n\t\tsorted_crtcs[i++] = crtc;\n\n\tsort(sorted_crtcs, i, sizeof(*sorted_crtcs), cmp_vc4_crtc_hvs_output, NULL);\n\n\tfor (i = 0; i < dev->num_crtcs; i++) {\n\t\tstruct vc4_crtc_state *old_vc4_crtc_state, *new_vc4_crtc_state;\n\t\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\t\tstruct vc4_crtc *vc4_crtc;\n\t\tunsigned int matching_channels;\n\t\tunsigned int channel;\n\n\t\tcrtc = sorted_crtcs[i];\n\t\tif (!crtc)\n\t\t\tcontinue;\n\t\tvc4_crtc = to_vc4_crtc(crtc);\n\n\t\told_crtc_state = drm_atomic_get_old_crtc_state(state, crtc);\n\t\tif (!old_crtc_state)\n\t\t\tcontinue;\n\t\told_vc4_crtc_state = to_vc4_crtc_state(old_crtc_state);\n\n\t\tnew_crtc_state = drm_atomic_get_new_crtc_state(state, crtc);\n\t\tif (!new_crtc_state)\n\t\t\tcontinue;\n\t\tnew_vc4_crtc_state = to_vc4_crtc_state(new_crtc_state);\n\n\t\tdrm_dbg(dev, \"%s: Trying to find a channel.\\n\", crtc->name);\n\n\t\t \n\t\tif (old_crtc_state->enable == new_crtc_state->enable) {\n\t\t\tif (new_crtc_state->enable)\n\t\t\t\tdrm_dbg(dev, \"%s: Already enabled, reusing channel %d.\\n\",\n\t\t\t\t\tcrtc->name, new_vc4_crtc_state->assigned_channel);\n\t\t\telse\n\t\t\t\tdrm_dbg(dev, \"%s: Disabled, ignoring.\\n\", crtc->name);\n\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tnew_vc4_crtc_state->update_muxing = true;\n\n\t\t \n\t\tif (!new_crtc_state->enable) {\n\t\t\tchannel = old_vc4_crtc_state->assigned_channel;\n\n\t\t\tdrm_dbg(dev, \"%s: Disabling, Freeing channel %d\\n\",\n\t\t\t\tcrtc->name, channel);\n\n\t\t\thvs_new_state->fifo_state[channel].in_use = false;\n\t\t\tnew_vc4_crtc_state->assigned_channel = VC4_HVS_CHANNEL_DISABLED;\n\t\t\tcontinue;\n\t\t}\n\n\t\tmatching_channels = unassigned_channels & vc4_crtc->data->hvs_available_channels;\n\t\tif (!matching_channels) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_free_crtc_array;\n\t\t}\n\n\t\tchannel = ffs(matching_channels) - 1;\n\n\t\tdrm_dbg(dev, \"Assigned HVS channel %d to CRTC %s\\n\", channel, crtc->name);\n\t\tnew_vc4_crtc_state->assigned_channel = channel;\n\t\tunassigned_channels &= ~BIT(channel);\n\t\thvs_new_state->fifo_state[channel].in_use = true;\n\t}\n\n\tkfree(sorted_crtcs);\n\treturn 0;\n\nerr_free_crtc_array:\n\tkfree(sorted_crtcs);\n\treturn ret;\n}\n\nstatic int\nvc4_core_clock_atomic_check(struct drm_atomic_state *state)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(state->dev);\n\tstruct drm_private_state *priv_state;\n\tstruct vc4_hvs_state *hvs_new_state;\n\tstruct vc4_load_tracker_state *load_state;\n\tstruct drm_crtc_state *old_crtc_state, *new_crtc_state;\n\tstruct drm_crtc *crtc;\n\tunsigned int num_outputs;\n\tunsigned long pixel_rate;\n\tunsigned long cob_rate;\n\tunsigned int i;\n\n\tpriv_state = drm_atomic_get_private_obj_state(state,\n\t\t\t\t\t\t      &vc4->load_tracker);\n\tif (IS_ERR(priv_state))\n\t\treturn PTR_ERR(priv_state);\n\n\tload_state = to_vc4_load_tracker_state(priv_state);\n\n\thvs_new_state = vc4_hvs_get_global_state(state);\n\tif (IS_ERR(hvs_new_state))\n\t\treturn PTR_ERR(hvs_new_state);\n\n\tfor_each_oldnew_crtc_in_state(state, crtc,\n\t\t\t\t      old_crtc_state,\n\t\t\t\t      new_crtc_state,\n\t\t\t\t      i) {\n\t\tif (old_crtc_state->active) {\n\t\t\tstruct vc4_crtc_state *old_vc4_state =\n\t\t\t\tto_vc4_crtc_state(old_crtc_state);\n\t\t\tunsigned int channel = old_vc4_state->assigned_channel;\n\n\t\t\thvs_new_state->fifo_state[channel].fifo_load = 0;\n\t\t}\n\n\t\tif (new_crtc_state->active) {\n\t\t\tstruct vc4_crtc_state *new_vc4_state =\n\t\t\t\tto_vc4_crtc_state(new_crtc_state);\n\t\t\tunsigned int channel = new_vc4_state->assigned_channel;\n\n\t\t\thvs_new_state->fifo_state[channel].fifo_load =\n\t\t\t\tnew_vc4_state->hvs_load;\n\t\t}\n\t}\n\n\tcob_rate = 0;\n\tnum_outputs = 0;\n\tfor (i = 0; i < HVS_NUM_CHANNELS; i++) {\n\t\tif (!hvs_new_state->fifo_state[i].in_use)\n\t\t\tcontinue;\n\n\t\tnum_outputs++;\n\t\tcob_rate = max_t(unsigned long,\n\t\t\t\t hvs_new_state->fifo_state[i].fifo_load,\n\t\t\t\t cob_rate);\n\t}\n\n\tpixel_rate = load_state->hvs_load;\n\tif (num_outputs > 1) {\n\t\tpixel_rate = (pixel_rate * 40) / 100;\n\t} else {\n\t\tpixel_rate = (pixel_rate * 60) / 100;\n\t}\n\n\thvs_new_state->core_clock_rate = max(cob_rate, pixel_rate);\n\n\treturn 0;\n}\n\n\nstatic int\nvc4_atomic_check(struct drm_device *dev, struct drm_atomic_state *state)\n{\n\tint ret;\n\n\tret = vc4_pv_muxing_atomic_check(dev, state);\n\tif (ret)\n\t\treturn ret;\n\n\tret = vc4_ctm_atomic_check(dev, state);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = drm_atomic_helper_check(dev, state);\n\tif (ret)\n\t\treturn ret;\n\n\tret = vc4_load_tracker_atomic_check(state);\n\tif (ret)\n\t\treturn ret;\n\n\treturn vc4_core_clock_atomic_check(state);\n}\n\nstatic struct drm_mode_config_helper_funcs vc4_mode_config_helpers = {\n\t.atomic_commit_setup\t= vc4_atomic_commit_setup,\n\t.atomic_commit_tail\t= vc4_atomic_commit_tail,\n};\n\nstatic const struct drm_mode_config_funcs vc4_mode_funcs = {\n\t.atomic_check = vc4_atomic_check,\n\t.atomic_commit = drm_atomic_helper_commit,\n\t.fb_create = vc4_fb_create,\n};\n\nstatic const struct drm_mode_config_funcs vc5_mode_funcs = {\n\t.atomic_check = vc4_atomic_check,\n\t.atomic_commit = drm_atomic_helper_commit,\n\t.fb_create = drm_gem_fb_create,\n};\n\nint vc4_kms_load(struct drm_device *dev)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(dev);\n\tint ret;\n\n\t \n\tif (!vc4->is_vc5) {\n\t\t \n\t\tvc4->load_tracker_enabled = true;\n\t}\n\n\t \n\tdev->vblank_disable_immediate = true;\n\n\tret = drm_vblank_init(dev, dev->mode_config.num_crtc);\n\tif (ret < 0) {\n\t\tdev_err(dev->dev, \"failed to initialize vblank\\n\");\n\t\treturn ret;\n\t}\n\n\tif (vc4->is_vc5) {\n\t\tdev->mode_config.max_width = 7680;\n\t\tdev->mode_config.max_height = 7680;\n\t} else {\n\t\tdev->mode_config.max_width = 2048;\n\t\tdev->mode_config.max_height = 2048;\n\t}\n\n\tdev->mode_config.funcs = vc4->is_vc5 ? &vc5_mode_funcs : &vc4_mode_funcs;\n\tdev->mode_config.helper_private = &vc4_mode_config_helpers;\n\tdev->mode_config.preferred_depth = 24;\n\tdev->mode_config.async_page_flip = true;\n\tdev->mode_config.normalize_zpos = true;\n\n\tret = vc4_ctm_obj_init(vc4);\n\tif (ret)\n\t\treturn ret;\n\n\tret = vc4_load_tracker_obj_init(vc4);\n\tif (ret)\n\t\treturn ret;\n\n\tret = vc4_hvs_channels_obj_init(vc4);\n\tif (ret)\n\t\treturn ret;\n\n\tdrm_mode_config_reset(dev);\n\n\tdrm_kms_helper_poll_init(dev);\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}