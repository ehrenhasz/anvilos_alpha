{
  "module_name": "vc4_validate_shaders.c",
  "hash_id": "522da6bb30ffe7e198ca6c9f97dd6b5b8769be338ca4ca7ce1545cda5fb306b7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/vc4/vc4_validate_shaders.c",
  "human_readable_source": " \n\n \n\n#include \"vc4_drv.h\"\n#include \"vc4_qpu_defines.h\"\n\n#define LIVE_REG_COUNT (32 + 32 + 4)\n\nstruct vc4_shader_validation_state {\n\t \n\tuint32_t ip;\n\n\t \n\tuint32_t max_ip;\n\n\tuint64_t *shader;\n\n\tstruct vc4_texture_sample_info tmu_setup[2];\n\tint tmu_write_count[2];\n\n\t \n\tuint32_t live_min_clamp_offsets[LIVE_REG_COUNT];\n\tbool live_max_clamp_regs[LIVE_REG_COUNT];\n\tuint32_t live_immediates[LIVE_REG_COUNT];\n\n\t \n\tunsigned long *branch_targets;\n\n\t \n\tbool needs_uniform_address_update;\n\n\t \n\tbool needs_uniform_address_for_loop;\n\n\t \n\tbool all_registers_used;\n};\n\nstatic uint32_t\nwaddr_to_live_reg_index(uint32_t waddr, bool is_b)\n{\n\tif (waddr < 32) {\n\t\tif (is_b)\n\t\t\treturn 32 + waddr;\n\t\telse\n\t\t\treturn waddr;\n\t} else if (waddr <= QPU_W_ACC3) {\n\t\treturn 64 + waddr - QPU_W_ACC0;\n\t} else {\n\t\treturn ~0;\n\t}\n}\n\nstatic uint32_t\nraddr_add_a_to_live_reg_index(uint64_t inst)\n{\n\tuint32_t sig = QPU_GET_FIELD(inst, QPU_SIG);\n\tuint32_t add_a = QPU_GET_FIELD(inst, QPU_ADD_A);\n\tuint32_t raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);\n\tuint32_t raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);\n\n\tif (add_a == QPU_MUX_A)\n\t\treturn raddr_a;\n\telse if (add_a == QPU_MUX_B && sig != QPU_SIG_SMALL_IMM)\n\t\treturn 32 + raddr_b;\n\telse if (add_a <= QPU_MUX_R3)\n\t\treturn 64 + add_a;\n\telse\n\t\treturn ~0;\n}\n\nstatic bool\nlive_reg_is_upper_half(uint32_t lri)\n{\n\treturn\t(lri >= 16 && lri < 32) ||\n\t\t(lri >= 32 + 16 && lri < 32 + 32);\n}\n\nstatic bool\nis_tmu_submit(uint32_t waddr)\n{\n\treturn (waddr == QPU_W_TMU0_S ||\n\t\twaddr == QPU_W_TMU1_S);\n}\n\nstatic bool\nis_tmu_write(uint32_t waddr)\n{\n\treturn (waddr >= QPU_W_TMU0_S &&\n\t\twaddr <= QPU_W_TMU1_B);\n}\n\nstatic bool\nrecord_texture_sample(struct vc4_validated_shader_info *validated_shader,\n\t\t      struct vc4_shader_validation_state *validation_state,\n\t\t      int tmu)\n{\n\tuint32_t s = validated_shader->num_texture_samples;\n\tint i;\n\tstruct vc4_texture_sample_info *temp_samples;\n\n\ttemp_samples = krealloc(validated_shader->texture_samples,\n\t\t\t\t(s + 1) * sizeof(*temp_samples),\n\t\t\t\tGFP_KERNEL);\n\tif (!temp_samples)\n\t\treturn false;\n\n\tmemcpy(&temp_samples[s],\n\t       &validation_state->tmu_setup[tmu],\n\t       sizeof(*temp_samples));\n\n\tvalidated_shader->num_texture_samples = s + 1;\n\tvalidated_shader->texture_samples = temp_samples;\n\n\tfor (i = 0; i < 4; i++)\n\t\tvalidation_state->tmu_setup[tmu].p_offset[i] = ~0;\n\n\treturn true;\n}\n\nstatic bool\ncheck_tmu_write(struct vc4_validated_shader_info *validated_shader,\n\t\tstruct vc4_shader_validation_state *validation_state,\n\t\tbool is_mul)\n{\n\tuint64_t inst = validation_state->shader[validation_state->ip];\n\tuint32_t waddr = (is_mul ?\n\t\t\t  QPU_GET_FIELD(inst, QPU_WADDR_MUL) :\n\t\t\t  QPU_GET_FIELD(inst, QPU_WADDR_ADD));\n\tuint32_t raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);\n\tuint32_t raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);\n\tint tmu = waddr > QPU_W_TMU0_B;\n\tbool submit = is_tmu_submit(waddr);\n\tbool is_direct = submit && validation_state->tmu_write_count[tmu] == 0;\n\tuint32_t sig = QPU_GET_FIELD(inst, QPU_SIG);\n\n\tif (is_direct) {\n\t\tuint32_t add_b = QPU_GET_FIELD(inst, QPU_ADD_B);\n\t\tuint32_t clamp_reg, clamp_offset;\n\n\t\tif (sig == QPU_SIG_SMALL_IMM) {\n\t\t\tDRM_DEBUG(\"direct TMU read used small immediate\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\t \n\t\tif (is_mul ||\n\t\t    QPU_GET_FIELD(inst, QPU_OP_ADD) != QPU_A_ADD) {\n\t\t\tDRM_DEBUG(\"direct TMU load wasn't an add\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\t \n\t\tclamp_reg = raddr_add_a_to_live_reg_index(inst);\n\t\tif (clamp_reg == ~0) {\n\t\t\tDRM_DEBUG(\"direct TMU load wasn't clamped\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tclamp_offset = validation_state->live_min_clamp_offsets[clamp_reg];\n\t\tif (clamp_offset == ~0) {\n\t\t\tDRM_DEBUG(\"direct TMU load wasn't clamped\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\t \n\t\tvalidation_state->tmu_setup[tmu].p_offset[1] =\n\t\t\tclamp_offset;\n\n\t\tif (!(add_b == QPU_MUX_A && raddr_a == QPU_R_UNIF) &&\n\t\t    !(add_b == QPU_MUX_B && raddr_b == QPU_R_UNIF)) {\n\t\t\tDRM_DEBUG(\"direct TMU load didn't add to a uniform\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tvalidation_state->tmu_setup[tmu].is_direct = true;\n\t} else {\n\t\tif (raddr_a == QPU_R_UNIF || (sig != QPU_SIG_SMALL_IMM &&\n\t\t\t\t\t      raddr_b == QPU_R_UNIF)) {\n\t\t\tDRM_DEBUG(\"uniform read in the same instruction as \"\n\t\t\t\t  \"texture setup.\\n\");\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tif (validation_state->tmu_write_count[tmu] >= 4) {\n\t\tDRM_DEBUG(\"TMU%d got too many parameters before dispatch\\n\",\n\t\t\t  tmu);\n\t\treturn false;\n\t}\n\tvalidation_state->tmu_setup[tmu].p_offset[validation_state->tmu_write_count[tmu]] =\n\t\tvalidated_shader->uniforms_size;\n\tvalidation_state->tmu_write_count[tmu]++;\n\t \n\tif (!is_direct) {\n\t\tif (validation_state->needs_uniform_address_update) {\n\t\t\tDRM_DEBUG(\"Texturing with undefined uniform address\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tvalidated_shader->uniforms_size += 4;\n\t}\n\n\tif (submit) {\n\t\tif (!record_texture_sample(validated_shader,\n\t\t\t\t\t   validation_state, tmu)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tvalidation_state->tmu_write_count[tmu] = 0;\n\t}\n\n\treturn true;\n}\n\nstatic bool require_uniform_address_uniform(struct vc4_validated_shader_info *validated_shader)\n{\n\tuint32_t o = validated_shader->num_uniform_addr_offsets;\n\tuint32_t num_uniforms = validated_shader->uniforms_size / 4;\n\n\tvalidated_shader->uniform_addr_offsets =\n\t\tkrealloc(validated_shader->uniform_addr_offsets,\n\t\t\t (o + 1) *\n\t\t\t sizeof(*validated_shader->uniform_addr_offsets),\n\t\t\t GFP_KERNEL);\n\tif (!validated_shader->uniform_addr_offsets)\n\t\treturn false;\n\n\tvalidated_shader->uniform_addr_offsets[o] = num_uniforms;\n\tvalidated_shader->num_uniform_addr_offsets++;\n\n\treturn true;\n}\n\nstatic bool\nvalidate_uniform_address_write(struct vc4_validated_shader_info *validated_shader,\n\t\t\t       struct vc4_shader_validation_state *validation_state,\n\t\t\t       bool is_mul)\n{\n\tuint64_t inst = validation_state->shader[validation_state->ip];\n\tu32 add_b = QPU_GET_FIELD(inst, QPU_ADD_B);\n\tu32 raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);\n\tu32 raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);\n\tu32 add_lri = raddr_add_a_to_live_reg_index(inst);\n\t \n\tu32 expected_offset = validated_shader->uniforms_size + 4;\n\n\t \n\tswitch (QPU_GET_FIELD(inst, QPU_SIG)) {\n\tcase QPU_SIG_NONE:\n\tcase QPU_SIG_SCOREBOARD_UNLOCK:\n\tcase QPU_SIG_COLOR_LOAD:\n\tcase QPU_SIG_LOAD_TMU0:\n\tcase QPU_SIG_LOAD_TMU1:\n\t\tbreak;\n\tdefault:\n\t\tDRM_DEBUG(\"uniforms address change must be \"\n\t\t\t  \"normal math\\n\");\n\t\treturn false;\n\t}\n\n\tif (is_mul || QPU_GET_FIELD(inst, QPU_OP_ADD) != QPU_A_ADD) {\n\t\tDRM_DEBUG(\"Uniform address reset must be an ADD.\\n\");\n\t\treturn false;\n\t}\n\n\tif (QPU_GET_FIELD(inst, QPU_COND_ADD) != QPU_COND_ALWAYS) {\n\t\tDRM_DEBUG(\"Uniform address reset must be unconditional.\\n\");\n\t\treturn false;\n\t}\n\n\tif (QPU_GET_FIELD(inst, QPU_PACK) != QPU_PACK_A_NOP &&\n\t    !(inst & QPU_PM)) {\n\t\tDRM_DEBUG(\"No packing allowed on uniforms reset\\n\");\n\t\treturn false;\n\t}\n\n\tif (add_lri == -1) {\n\t\tDRM_DEBUG(\"First argument of uniform address write must be \"\n\t\t\t  \"an immediate value.\\n\");\n\t\treturn false;\n\t}\n\n\tif (validation_state->live_immediates[add_lri] != expected_offset) {\n\t\tDRM_DEBUG(\"Resetting uniforms with offset %db instead of %db\\n\",\n\t\t\t  validation_state->live_immediates[add_lri],\n\t\t\t  expected_offset);\n\t\treturn false;\n\t}\n\n\tif (!(add_b == QPU_MUX_A && raddr_a == QPU_R_UNIF) &&\n\t    !(add_b == QPU_MUX_B && raddr_b == QPU_R_UNIF)) {\n\t\tDRM_DEBUG(\"Second argument of uniform address write must be \"\n\t\t\t  \"a uniform.\\n\");\n\t\treturn false;\n\t}\n\n\tvalidation_state->needs_uniform_address_update = false;\n\tvalidation_state->needs_uniform_address_for_loop = false;\n\treturn require_uniform_address_uniform(validated_shader);\n}\n\nstatic bool\ncheck_reg_write(struct vc4_validated_shader_info *validated_shader,\n\t\tstruct vc4_shader_validation_state *validation_state,\n\t\tbool is_mul)\n{\n\tuint64_t inst = validation_state->shader[validation_state->ip];\n\tuint32_t waddr = (is_mul ?\n\t\t\t  QPU_GET_FIELD(inst, QPU_WADDR_MUL) :\n\t\t\t  QPU_GET_FIELD(inst, QPU_WADDR_ADD));\n\tuint32_t sig = QPU_GET_FIELD(inst, QPU_SIG);\n\tbool ws = inst & QPU_WS;\n\tbool is_b = is_mul ^ ws;\n\tu32 lri = waddr_to_live_reg_index(waddr, is_b);\n\n\tif (lri != -1) {\n\t\tuint32_t cond_add = QPU_GET_FIELD(inst, QPU_COND_ADD);\n\t\tuint32_t cond_mul = QPU_GET_FIELD(inst, QPU_COND_MUL);\n\n\t\tif (sig == QPU_SIG_LOAD_IMM &&\n\t\t    QPU_GET_FIELD(inst, QPU_PACK) == QPU_PACK_A_NOP &&\n\t\t    ((is_mul && cond_mul == QPU_COND_ALWAYS) ||\n\t\t     (!is_mul && cond_add == QPU_COND_ALWAYS))) {\n\t\t\tvalidation_state->live_immediates[lri] =\n\t\t\t\tQPU_GET_FIELD(inst, QPU_LOAD_IMM);\n\t\t} else {\n\t\t\tvalidation_state->live_immediates[lri] = ~0;\n\t\t}\n\n\t\tif (live_reg_is_upper_half(lri))\n\t\t\tvalidation_state->all_registers_used = true;\n\t}\n\n\tswitch (waddr) {\n\tcase QPU_W_UNIFORMS_ADDRESS:\n\t\tif (is_b) {\n\t\t\tDRM_DEBUG(\"relative uniforms address change \"\n\t\t\t\t  \"unsupported\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\treturn validate_uniform_address_write(validated_shader,\n\t\t\t\t\t\t      validation_state,\n\t\t\t\t\t\t      is_mul);\n\n\tcase QPU_W_TLB_COLOR_MS:\n\tcase QPU_W_TLB_COLOR_ALL:\n\tcase QPU_W_TLB_Z:\n\t\t \n\t\treturn true;\n\n\tcase QPU_W_TMU0_S:\n\tcase QPU_W_TMU0_T:\n\tcase QPU_W_TMU0_R:\n\tcase QPU_W_TMU0_B:\n\tcase QPU_W_TMU1_S:\n\tcase QPU_W_TMU1_T:\n\tcase QPU_W_TMU1_R:\n\tcase QPU_W_TMU1_B:\n\t\treturn check_tmu_write(validated_shader, validation_state,\n\t\t\t\t       is_mul);\n\n\tcase QPU_W_HOST_INT:\n\tcase QPU_W_TMU_NOSWAP:\n\tcase QPU_W_TLB_ALPHA_MASK:\n\tcase QPU_W_MUTEX_RELEASE:\n\t\t \n\t\tDRM_DEBUG(\"Unsupported waddr %d\\n\", waddr);\n\t\treturn false;\n\n\tcase QPU_W_VPM_ADDR:\n\t\tDRM_DEBUG(\"General VPM DMA unsupported\\n\");\n\t\treturn false;\n\n\tcase QPU_W_VPM:\n\tcase QPU_W_VPMVCD_SETUP:\n\t\t \n\t\treturn true;\n\n\tcase QPU_W_TLB_STENCIL_SETUP:\n\t\treturn true;\n\t}\n\n\treturn true;\n}\n\nstatic void\ntrack_live_clamps(struct vc4_validated_shader_info *validated_shader,\n\t\t  struct vc4_shader_validation_state *validation_state)\n{\n\tuint64_t inst = validation_state->shader[validation_state->ip];\n\tuint32_t op_add = QPU_GET_FIELD(inst, QPU_OP_ADD);\n\tuint32_t waddr_add = QPU_GET_FIELD(inst, QPU_WADDR_ADD);\n\tuint32_t waddr_mul = QPU_GET_FIELD(inst, QPU_WADDR_MUL);\n\tuint32_t cond_add = QPU_GET_FIELD(inst, QPU_COND_ADD);\n\tuint32_t add_a = QPU_GET_FIELD(inst, QPU_ADD_A);\n\tuint32_t add_b = QPU_GET_FIELD(inst, QPU_ADD_B);\n\tuint32_t raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);\n\tuint32_t raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);\n\tuint32_t sig = QPU_GET_FIELD(inst, QPU_SIG);\n\tbool ws = inst & QPU_WS;\n\tuint32_t lri_add_a, lri_add, lri_mul;\n\tbool add_a_is_min_0;\n\n\t \n\tlri_add_a = raddr_add_a_to_live_reg_index(inst);\n\tadd_a_is_min_0 = (lri_add_a != ~0 &&\n\t\t\t  validation_state->live_max_clamp_regs[lri_add_a]);\n\n\t \n\tlri_add = waddr_to_live_reg_index(waddr_add, ws);\n\tlri_mul = waddr_to_live_reg_index(waddr_mul, !ws);\n\tif (lri_mul != ~0) {\n\t\tvalidation_state->live_max_clamp_regs[lri_mul] = false;\n\t\tvalidation_state->live_min_clamp_offsets[lri_mul] = ~0;\n\t}\n\tif (lri_add != ~0) {\n\t\tvalidation_state->live_max_clamp_regs[lri_add] = false;\n\t\tvalidation_state->live_min_clamp_offsets[lri_add] = ~0;\n\t} else {\n\t\t \n\t\treturn;\n\t}\n\n\t \n\n\tif (cond_add != QPU_COND_ALWAYS)\n\t\treturn;\n\n\tif (op_add == QPU_A_MAX) {\n\t\t \n\t\tif (sig != QPU_SIG_SMALL_IMM || raddr_b != 0 ||\n\t\t    (add_a != QPU_MUX_B && add_b != QPU_MUX_B)) {\n\t\t\treturn;\n\t\t}\n\n\t\tvalidation_state->live_max_clamp_regs[lri_add] = true;\n\t} else if (op_add == QPU_A_MIN) {\n\t\t \n\t\tif (!add_a_is_min_0)\n\t\t\treturn;\n\n\t\tif (!(add_b == QPU_MUX_A && raddr_a == QPU_R_UNIF) &&\n\t\t    !(add_b == QPU_MUX_B && raddr_b == QPU_R_UNIF &&\n\t\t      sig != QPU_SIG_SMALL_IMM)) {\n\t\t\treturn;\n\t\t}\n\n\t\tvalidation_state->live_min_clamp_offsets[lri_add] =\n\t\t\tvalidated_shader->uniforms_size;\n\t}\n}\n\nstatic bool\ncheck_instruction_writes(struct vc4_validated_shader_info *validated_shader,\n\t\t\t struct vc4_shader_validation_state *validation_state)\n{\n\tuint64_t inst = validation_state->shader[validation_state->ip];\n\tuint32_t waddr_add = QPU_GET_FIELD(inst, QPU_WADDR_ADD);\n\tuint32_t waddr_mul = QPU_GET_FIELD(inst, QPU_WADDR_MUL);\n\tbool ok;\n\n\tif (is_tmu_write(waddr_add) && is_tmu_write(waddr_mul)) {\n\t\tDRM_DEBUG(\"ADD and MUL both set up textures\\n\");\n\t\treturn false;\n\t}\n\n\tok = (check_reg_write(validated_shader, validation_state, false) &&\n\t      check_reg_write(validated_shader, validation_state, true));\n\n\ttrack_live_clamps(validated_shader, validation_state);\n\n\treturn ok;\n}\n\nstatic bool\ncheck_branch(uint64_t inst,\n\t     struct vc4_validated_shader_info *validated_shader,\n\t     struct vc4_shader_validation_state *validation_state,\n\t     int ip)\n{\n\tint32_t branch_imm = QPU_GET_FIELD(inst, QPU_BRANCH_TARGET);\n\tuint32_t waddr_add = QPU_GET_FIELD(inst, QPU_WADDR_ADD);\n\tuint32_t waddr_mul = QPU_GET_FIELD(inst, QPU_WADDR_MUL);\n\n\tif ((int)branch_imm < 0)\n\t\tvalidation_state->needs_uniform_address_for_loop = true;\n\n\t \n\tif (waddr_add != QPU_W_NOP || waddr_mul != QPU_W_NOP) {\n\t\tDRM_DEBUG(\"branch instruction at %d wrote a register.\\n\",\n\t\t\t  validation_state->ip);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool\ncheck_instruction_reads(struct vc4_validated_shader_info *validated_shader,\n\t\t\tstruct vc4_shader_validation_state *validation_state)\n{\n\tuint64_t inst = validation_state->shader[validation_state->ip];\n\tuint32_t raddr_a = QPU_GET_FIELD(inst, QPU_RADDR_A);\n\tuint32_t raddr_b = QPU_GET_FIELD(inst, QPU_RADDR_B);\n\tuint32_t sig = QPU_GET_FIELD(inst, QPU_SIG);\n\n\tif (raddr_a == QPU_R_UNIF ||\n\t    (raddr_b == QPU_R_UNIF && sig != QPU_SIG_SMALL_IMM)) {\n\t\t \n\t\tvalidated_shader->uniforms_size += 4;\n\n\t\tif (validation_state->needs_uniform_address_update) {\n\t\t\tDRM_DEBUG(\"Uniform read with undefined uniform \"\n\t\t\t\t  \"address\\n\");\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tif ((raddr_a >= 16 && raddr_a < 32) ||\n\t    (raddr_b >= 16 && raddr_b < 32 && sig != QPU_SIG_SMALL_IMM)) {\n\t\tvalidation_state->all_registers_used = true;\n\t}\n\n\treturn true;\n}\n\n \nstatic bool\nvc4_validate_branches(struct vc4_shader_validation_state *validation_state)\n{\n\tuint32_t max_branch_target = 0;\n\tint ip;\n\tint last_branch = -2;\n\n\tfor (ip = 0; ip < validation_state->max_ip; ip++) {\n\t\tuint64_t inst = validation_state->shader[ip];\n\t\tint32_t branch_imm = QPU_GET_FIELD(inst, QPU_BRANCH_TARGET);\n\t\tuint32_t sig = QPU_GET_FIELD(inst, QPU_SIG);\n\t\tuint32_t after_delay_ip = ip + 4;\n\t\tuint32_t branch_target_ip;\n\n\t\tif (sig == QPU_SIG_PROG_END) {\n\t\t\t \n\t\t\tvalidation_state->max_ip = ip + 3;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (sig != QPU_SIG_BRANCH)\n\t\t\tcontinue;\n\n\t\tif (ip - last_branch < 4) {\n\t\t\tDRM_DEBUG(\"Branch at %d during delay slots\\n\", ip);\n\t\t\treturn false;\n\t\t}\n\t\tlast_branch = ip;\n\n\t\tif (inst & QPU_BRANCH_REG) {\n\t\t\tDRM_DEBUG(\"branching from register relative \"\n\t\t\t\t  \"not supported\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tif (!(inst & QPU_BRANCH_REL)) {\n\t\t\tDRM_DEBUG(\"relative branching required\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\t \n\t\tif (branch_imm % sizeof(inst) != 0) {\n\t\t\tDRM_DEBUG(\"branch target not aligned\\n\");\n\t\t\treturn false;\n\t\t}\n\n\t\tbranch_target_ip = after_delay_ip + (branch_imm >> 3);\n\t\tif (branch_target_ip >= validation_state->max_ip) {\n\t\t\tDRM_DEBUG(\"Branch at %d outside of shader (ip %d/%d)\\n\",\n\t\t\t\t  ip, branch_target_ip,\n\t\t\t\t  validation_state->max_ip);\n\t\t\treturn false;\n\t\t}\n\t\tset_bit(branch_target_ip, validation_state->branch_targets);\n\n\t\t \n\t\tif (after_delay_ip >= validation_state->max_ip) {\n\t\t\tDRM_DEBUG(\"Branch at %d continues past shader end \"\n\t\t\t\t  \"(%d/%d)\\n\",\n\t\t\t\t  ip, after_delay_ip, validation_state->max_ip);\n\t\t\treturn false;\n\t\t}\n\t\tset_bit(after_delay_ip, validation_state->branch_targets);\n\t\tmax_branch_target = max(max_branch_target, after_delay_ip);\n\t}\n\n\tif (max_branch_target > validation_state->max_ip - 3) {\n\t\tDRM_DEBUG(\"Branch landed after QPU_SIG_PROG_END\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic void\nreset_validation_state(struct vc4_shader_validation_state *validation_state)\n{\n\tint i;\n\n\tfor (i = 0; i < 8; i++)\n\t\tvalidation_state->tmu_setup[i / 4].p_offset[i % 4] = ~0;\n\n\tfor (i = 0; i < LIVE_REG_COUNT; i++) {\n\t\tvalidation_state->live_min_clamp_offsets[i] = ~0;\n\t\tvalidation_state->live_max_clamp_regs[i] = false;\n\t\tvalidation_state->live_immediates[i] = ~0;\n\t}\n}\n\nstatic bool\ntexturing_in_progress(struct vc4_shader_validation_state *validation_state)\n{\n\treturn (validation_state->tmu_write_count[0] != 0 ||\n\t\tvalidation_state->tmu_write_count[1] != 0);\n}\n\nstatic bool\nvc4_handle_branch_target(struct vc4_shader_validation_state *validation_state)\n{\n\tuint32_t ip = validation_state->ip;\n\n\tif (!test_bit(ip, validation_state->branch_targets))\n\t\treturn true;\n\n\tif (texturing_in_progress(validation_state)) {\n\t\tDRM_DEBUG(\"Branch target landed during TMU setup\\n\");\n\t\treturn false;\n\t}\n\n\t \n\treset_validation_state(validation_state);\n\n\t \n\tvalidation_state->needs_uniform_address_update = true;\n\n\treturn true;\n}\n\nstruct vc4_validated_shader_info *\nvc4_validate_shader(struct drm_gem_dma_object *shader_obj)\n{\n\tstruct vc4_dev *vc4 = to_vc4_dev(shader_obj->base.dev);\n\tbool found_shader_end = false;\n\tint shader_end_ip = 0;\n\tuint32_t last_thread_switch_ip = -3;\n\tuint32_t ip;\n\tstruct vc4_validated_shader_info *validated_shader = NULL;\n\tstruct vc4_shader_validation_state validation_state;\n\n\tif (WARN_ON_ONCE(vc4->is_vc5))\n\t\treturn NULL;\n\n\tmemset(&validation_state, 0, sizeof(validation_state));\n\tvalidation_state.shader = shader_obj->vaddr;\n\tvalidation_state.max_ip = shader_obj->base.size / sizeof(uint64_t);\n\n\treset_validation_state(&validation_state);\n\n\tvalidation_state.branch_targets =\n\t\tkcalloc(BITS_TO_LONGS(validation_state.max_ip),\n\t\t\tsizeof(unsigned long), GFP_KERNEL);\n\tif (!validation_state.branch_targets)\n\t\tgoto fail;\n\n\tvalidated_shader = kcalloc(1, sizeof(*validated_shader), GFP_KERNEL);\n\tif (!validated_shader)\n\t\tgoto fail;\n\n\tif (!vc4_validate_branches(&validation_state))\n\t\tgoto fail;\n\n\tfor (ip = 0; ip < validation_state.max_ip; ip++) {\n\t\tuint64_t inst = validation_state.shader[ip];\n\t\tuint32_t sig = QPU_GET_FIELD(inst, QPU_SIG);\n\n\t\tvalidation_state.ip = ip;\n\n\t\tif (!vc4_handle_branch_target(&validation_state))\n\t\t\tgoto fail;\n\n\t\tif (ip == last_thread_switch_ip + 3) {\n\t\t\t \n\t\t\tint i;\n\n\t\t\tfor (i = 64; i < LIVE_REG_COUNT; i++) {\n\t\t\t\tvalidation_state.live_min_clamp_offsets[i] = ~0;\n\t\t\t\tvalidation_state.live_max_clamp_regs[i] = false;\n\t\t\t\tvalidation_state.live_immediates[i] = ~0;\n\t\t\t}\n\t\t}\n\n\t\tswitch (sig) {\n\t\tcase QPU_SIG_NONE:\n\t\tcase QPU_SIG_WAIT_FOR_SCOREBOARD:\n\t\tcase QPU_SIG_SCOREBOARD_UNLOCK:\n\t\tcase QPU_SIG_COLOR_LOAD:\n\t\tcase QPU_SIG_LOAD_TMU0:\n\t\tcase QPU_SIG_LOAD_TMU1:\n\t\tcase QPU_SIG_PROG_END:\n\t\tcase QPU_SIG_SMALL_IMM:\n\t\tcase QPU_SIG_THREAD_SWITCH:\n\t\tcase QPU_SIG_LAST_THREAD_SWITCH:\n\t\t\tif (!check_instruction_writes(validated_shader,\n\t\t\t\t\t\t      &validation_state)) {\n\t\t\t\tDRM_DEBUG(\"Bad write at ip %d\\n\", ip);\n\t\t\t\tgoto fail;\n\t\t\t}\n\n\t\t\tif (!check_instruction_reads(validated_shader,\n\t\t\t\t\t\t     &validation_state))\n\t\t\t\tgoto fail;\n\n\t\t\tif (sig == QPU_SIG_PROG_END) {\n\t\t\t\tfound_shader_end = true;\n\t\t\t\tshader_end_ip = ip;\n\t\t\t}\n\n\t\t\tif (sig == QPU_SIG_THREAD_SWITCH ||\n\t\t\t    sig == QPU_SIG_LAST_THREAD_SWITCH) {\n\t\t\t\tvalidated_shader->is_threaded = true;\n\n\t\t\t\tif (ip < last_thread_switch_ip + 3) {\n\t\t\t\t\tDRM_DEBUG(\"Thread switch too soon after \"\n\t\t\t\t\t\t  \"last switch at ip %d\\n\", ip);\n\t\t\t\t\tgoto fail;\n\t\t\t\t}\n\t\t\t\tlast_thread_switch_ip = ip;\n\t\t\t}\n\n\t\t\tbreak;\n\n\t\tcase QPU_SIG_LOAD_IMM:\n\t\t\tif (!check_instruction_writes(validated_shader,\n\t\t\t\t\t\t      &validation_state)) {\n\t\t\t\tDRM_DEBUG(\"Bad LOAD_IMM write at ip %d\\n\", ip);\n\t\t\t\tgoto fail;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase QPU_SIG_BRANCH:\n\t\t\tif (!check_branch(inst, validated_shader,\n\t\t\t\t\t  &validation_state, ip))\n\t\t\t\tgoto fail;\n\n\t\t\tif (ip < last_thread_switch_ip + 3) {\n\t\t\t\tDRM_DEBUG(\"Branch in thread switch at ip %d\",\n\t\t\t\t\t  ip);\n\t\t\t\tgoto fail;\n\t\t\t}\n\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDRM_DEBUG(\"Unsupported QPU signal %d at \"\n\t\t\t\t  \"instruction %d\\n\", sig, ip);\n\t\t\tgoto fail;\n\t\t}\n\n\t\t \n\t\tif (found_shader_end && ip == shader_end_ip + 2)\n\t\t\tbreak;\n\t}\n\n\tif (ip == validation_state.max_ip) {\n\t\tDRM_DEBUG(\"shader failed to terminate before \"\n\t\t\t  \"shader BO end at %zd\\n\",\n\t\t\t  shader_obj->base.size);\n\t\tgoto fail;\n\t}\n\n\t \n\tif (validated_shader->is_threaded &&\n\t    validation_state.all_registers_used) {\n\t\tDRM_DEBUG(\"Shader uses threading, but uses the upper \"\n\t\t\t  \"half of the registers, too\\n\");\n\t\tgoto fail;\n\t}\n\n\t \n\tif (validation_state.needs_uniform_address_for_loop) {\n\t\tif (!require_uniform_address_uniform(validated_shader))\n\t\t\tgoto fail;\n\t\tvalidated_shader->uniforms_size += 4;\n\t}\n\n\t \n\tvalidated_shader->uniforms_src_size =\n\t\t(validated_shader->uniforms_size +\n\t\t 4 * validated_shader->num_texture_samples);\n\n\tkfree(validation_state.branch_targets);\n\n\treturn validated_shader;\n\nfail:\n\tkfree(validation_state.branch_targets);\n\tif (validated_shader) {\n\t\tkfree(validated_shader->uniform_addr_offsets);\n\t\tkfree(validated_shader->texture_samples);\n\t\tkfree(validated_shader);\n\t}\n\treturn NULL;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}