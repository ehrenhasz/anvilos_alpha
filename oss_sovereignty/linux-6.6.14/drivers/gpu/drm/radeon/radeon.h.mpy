{
  "module_name": "radeon.h",
  "hash_id": "63578a6d099f16eb16634f48a20fdbf11d3d3ce23cd3ceb36be19ec710d8aac5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/radeon/radeon.h",
  "human_readable_source": " \n#ifndef __RADEON_H__\n#define __RADEON_H__\n\n \n\n \n\n#include <linux/agp_backend.h>\n#include <linux/atomic.h>\n#include <linux/wait.h>\n#include <linux/list.h>\n#include <linux/kref.h>\n#include <linux/interval_tree.h>\n#include <linux/hashtable.h>\n#include <linux/dma-fence.h>\n\n#ifdef CONFIG_MMU_NOTIFIER\n#include <linux/mmu_notifier.h>\n#endif\n\n#include <drm/ttm/ttm_bo.h>\n#include <drm/ttm/ttm_placement.h>\n#include <drm/ttm/ttm_execbuf_util.h>\n\n#include <drm/drm_gem.h>\n#include <drm/drm_audio_component.h>\n#include <drm/drm_suballoc.h>\n\n#include \"radeon_family.h\"\n#include \"radeon_mode.h\"\n#include \"radeon_reg.h\"\n\n \nextern int radeon_no_wb;\nextern int radeon_modeset;\nextern int radeon_dynclks;\nextern int radeon_r4xx_atom;\nextern int radeon_agpmode;\nextern int radeon_vram_limit;\nextern int radeon_gart_size;\nextern int radeon_benchmarking;\nextern int radeon_testing;\nextern int radeon_connector_table;\nextern int radeon_tv;\nextern int radeon_audio;\nextern int radeon_disp_priority;\nextern int radeon_hw_i2c;\nextern int radeon_pcie_gen2;\nextern int radeon_msi;\nextern int radeon_lockup_timeout;\nextern int radeon_fastfb;\nextern int radeon_dpm;\nextern int radeon_aspm;\nextern int radeon_runtime_pm;\nextern int radeon_hard_reset;\nextern int radeon_vm_size;\nextern int radeon_vm_block_size;\nextern int radeon_deep_color;\nextern int radeon_use_pflipirq;\nextern int radeon_bapm;\nextern int radeon_backlight;\nextern int radeon_auxch;\nextern int radeon_uvd;\nextern int radeon_vce;\nextern int radeon_si_support;\nextern int radeon_cik_support;\n\n \n#define RADEON_MAX_USEC_TIMEOUT\t\t\t100000\t \n#define RADEON_FENCE_JIFFIES_TIMEOUT\t\t(HZ / 2)\n#define RADEON_USEC_IB_TEST_TIMEOUT\t\t1000000  \n \n#define RADEON_IB_POOL_SIZE\t\t\t16\n#define RADEON_DEBUGFS_MAX_COMPONENTS\t\t32\n#define RADEONFB_CONN_LIMIT\t\t\t4\n#define RADEON_BIOS_NUM_SCRATCH\t\t\t8\n\n \n \n#define RADEON_RING_TYPE_GFX_INDEX\t\t0\n\n \n#define CAYMAN_RING_TYPE_CP1_INDEX\t\t1\n#define CAYMAN_RING_TYPE_CP2_INDEX\t\t2\n\n \n#define R600_RING_TYPE_DMA_INDEX\t\t3\n \n#define CAYMAN_RING_TYPE_DMA1_INDEX\t\t4\n\n \n#define R600_RING_TYPE_UVD_INDEX\t\t5\n\n \n#define TN_RING_TYPE_VCE1_INDEX\t\t\t6\n#define TN_RING_TYPE_VCE2_INDEX\t\t\t7\n\n \n#define RADEON_NUM_RINGS\t\t\t8\n\n \n#define RADEON_NUM_SYNCS\t\t\t4\n\n \n#define RADEON_VA_IB_OFFSET\t\t\t(1 << 20)\n#define RADEON_VA_RESERVED_SIZE\t\t\t(8 << 20)\n#define RADEON_IB_VM_MAX_SIZE\t\t\t(64 << 10)\n\n \n#define RADEON_ASIC_RESET_DATA                  0x39d5e86b\n\n \n#define RADEON_RESET_GFX\t\t\t(1 << 0)\n#define RADEON_RESET_COMPUTE\t\t\t(1 << 1)\n#define RADEON_RESET_DMA\t\t\t(1 << 2)\n#define RADEON_RESET_CP\t\t\t\t(1 << 3)\n#define RADEON_RESET_GRBM\t\t\t(1 << 4)\n#define RADEON_RESET_DMA1\t\t\t(1 << 5)\n#define RADEON_RESET_RLC\t\t\t(1 << 6)\n#define RADEON_RESET_SEM\t\t\t(1 << 7)\n#define RADEON_RESET_IH\t\t\t\t(1 << 8)\n#define RADEON_RESET_VMC\t\t\t(1 << 9)\n#define RADEON_RESET_MC\t\t\t\t(1 << 10)\n#define RADEON_RESET_DISPLAY\t\t\t(1 << 11)\n\n \n#define RADEON_CG_BLOCK_GFX\t\t\t(1 << 0)\n#define RADEON_CG_BLOCK_MC\t\t\t(1 << 1)\n#define RADEON_CG_BLOCK_SDMA\t\t\t(1 << 2)\n#define RADEON_CG_BLOCK_UVD\t\t\t(1 << 3)\n#define RADEON_CG_BLOCK_VCE\t\t\t(1 << 4)\n#define RADEON_CG_BLOCK_HDP\t\t\t(1 << 5)\n#define RADEON_CG_BLOCK_BIF\t\t\t(1 << 6)\n\n \n#define RADEON_CG_SUPPORT_GFX_MGCG\t\t(1 << 0)\n#define RADEON_CG_SUPPORT_GFX_MGLS\t\t(1 << 1)\n#define RADEON_CG_SUPPORT_GFX_CGCG\t\t(1 << 2)\n#define RADEON_CG_SUPPORT_GFX_CGLS\t\t(1 << 3)\n#define RADEON_CG_SUPPORT_GFX_CGTS\t\t(1 << 4)\n#define RADEON_CG_SUPPORT_GFX_CGTS_LS\t\t(1 << 5)\n#define RADEON_CG_SUPPORT_GFX_CP_LS\t\t(1 << 6)\n#define RADEON_CG_SUPPORT_GFX_RLC_LS\t\t(1 << 7)\n#define RADEON_CG_SUPPORT_MC_LS\t\t\t(1 << 8)\n#define RADEON_CG_SUPPORT_MC_MGCG\t\t(1 << 9)\n#define RADEON_CG_SUPPORT_SDMA_LS\t\t(1 << 10)\n#define RADEON_CG_SUPPORT_SDMA_MGCG\t\t(1 << 11)\n#define RADEON_CG_SUPPORT_BIF_LS\t\t(1 << 12)\n#define RADEON_CG_SUPPORT_UVD_MGCG\t\t(1 << 13)\n#define RADEON_CG_SUPPORT_VCE_MGCG\t\t(1 << 14)\n#define RADEON_CG_SUPPORT_HDP_LS\t\t(1 << 15)\n#define RADEON_CG_SUPPORT_HDP_MGCG\t\t(1 << 16)\n\n \n#define RADEON_PG_SUPPORT_GFX_PG\t\t(1 << 0)\n#define RADEON_PG_SUPPORT_GFX_SMG\t\t(1 << 1)\n#define RADEON_PG_SUPPORT_GFX_DMG\t\t(1 << 2)\n#define RADEON_PG_SUPPORT_UVD\t\t\t(1 << 3)\n#define RADEON_PG_SUPPORT_VCE\t\t\t(1 << 4)\n#define RADEON_PG_SUPPORT_CP\t\t\t(1 << 5)\n#define RADEON_PG_SUPPORT_GDS\t\t\t(1 << 6)\n#define RADEON_PG_SUPPORT_RLC_SMU_HS\t\t(1 << 7)\n#define RADEON_PG_SUPPORT_SDMA\t\t\t(1 << 8)\n#define RADEON_PG_SUPPORT_ACP\t\t\t(1 << 9)\n#define RADEON_PG_SUPPORT_SAMU\t\t\t(1 << 10)\n\n \n#define CURSOR_WIDTH 64\n#define CURSOR_HEIGHT 64\n\n#define CIK_CURSOR_WIDTH 128\n#define CIK_CURSOR_HEIGHT 128\n\n \nenum radeon_pll_errata {\n\tCHIP_ERRATA_R300_CG             = 0x00000001,\n\tCHIP_ERRATA_PLL_DUMMYREADS      = 0x00000002,\n\tCHIP_ERRATA_PLL_DELAY           = 0x00000004\n};\n\n\nstruct radeon_device;\n\n\n \nbool radeon_get_bios(struct radeon_device *rdev);\n\n \nstruct radeon_dummy_page {\n\tuint64_t\tentry;\n\tstruct page\t*page;\n\tdma_addr_t\taddr;\n};\nint radeon_dummy_page_init(struct radeon_device *rdev);\nvoid radeon_dummy_page_fini(struct radeon_device *rdev);\n\n\n \nstruct radeon_clock {\n\tstruct radeon_pll p1pll;\n\tstruct radeon_pll p2pll;\n\tstruct radeon_pll dcpll;\n\tstruct radeon_pll spll;\n\tstruct radeon_pll mpll;\n\t \n\tuint32_t default_mclk;\n\tuint32_t default_sclk;\n\tuint32_t default_dispclk;\n\tuint32_t current_dispclk;\n\tuint32_t dp_extclk;\n\tuint32_t max_pixel_clock;\n\tuint32_t vco_freq;\n};\n\n \nint radeon_pm_init(struct radeon_device *rdev);\nint radeon_pm_late_init(struct radeon_device *rdev);\nvoid radeon_pm_fini(struct radeon_device *rdev);\nvoid radeon_pm_compute_clocks(struct radeon_device *rdev);\nvoid radeon_pm_suspend(struct radeon_device *rdev);\nvoid radeon_pm_resume(struct radeon_device *rdev);\nvoid radeon_combios_get_power_modes(struct radeon_device *rdev);\nvoid radeon_atombios_get_power_modes(struct radeon_device *rdev);\nint radeon_atom_get_clock_dividers(struct radeon_device *rdev,\n\t\t\t\t   u8 clock_type,\n\t\t\t\t   u32 clock,\n\t\t\t\t   bool strobe_mode,\n\t\t\t\t   struct atom_clock_dividers *dividers);\nint radeon_atom_get_memory_pll_dividers(struct radeon_device *rdev,\n\t\t\t\t\tu32 clock,\n\t\t\t\t\tbool strobe_mode,\n\t\t\t\t\tstruct atom_mpll_param *mpll_param);\nvoid radeon_atom_set_voltage(struct radeon_device *rdev, u16 voltage_level, u8 voltage_type);\nint radeon_atom_get_voltage_gpio_settings(struct radeon_device *rdev,\n\t\t\t\t\t  u16 voltage_level, u8 voltage_type,\n\t\t\t\t\t  u32 *gpio_value, u32 *gpio_mask);\nvoid radeon_atom_set_engine_dram_timings(struct radeon_device *rdev,\n\t\t\t\t\t u32 eng_clock, u32 mem_clock);\nint radeon_atom_get_voltage_step(struct radeon_device *rdev,\n\t\t\t\t u8 voltage_type, u16 *voltage_step);\nint radeon_atom_get_max_vddc(struct radeon_device *rdev, u8 voltage_type,\n\t\t\t     u16 voltage_id, u16 *voltage);\nint radeon_atom_get_leakage_vddc_based_on_leakage_idx(struct radeon_device *rdev,\n\t\t\t\t\t\t      u16 *voltage,\n\t\t\t\t\t\t      u16 leakage_idx);\nint radeon_atom_get_leakage_id_from_vbios(struct radeon_device *rdev,\n\t\t\t\t\t  u16 *leakage_id);\nint radeon_atom_get_leakage_vddc_based_on_leakage_params(struct radeon_device *rdev,\n\t\t\t\t\t\t\t u16 *vddc, u16 *vddci,\n\t\t\t\t\t\t\t u16 virtual_voltage_id,\n\t\t\t\t\t\t\t u16 vbios_voltage_id);\nint radeon_atom_get_voltage_evv(struct radeon_device *rdev,\n\t\t\t\tu16 virtual_voltage_id,\n\t\t\t\tu16 *voltage);\nint radeon_atom_round_to_true_voltage(struct radeon_device *rdev,\n\t\t\t\t      u8 voltage_type,\n\t\t\t\t      u16 nominal_voltage,\n\t\t\t\t      u16 *true_voltage);\nint radeon_atom_get_min_voltage(struct radeon_device *rdev,\n\t\t\t\tu8 voltage_type, u16 *min_voltage);\nint radeon_atom_get_max_voltage(struct radeon_device *rdev,\n\t\t\t\tu8 voltage_type, u16 *max_voltage);\nint radeon_atom_get_voltage_table(struct radeon_device *rdev,\n\t\t\t\t  u8 voltage_type, u8 voltage_mode,\n\t\t\t\t  struct atom_voltage_table *voltage_table);\nbool radeon_atom_is_voltage_gpio(struct radeon_device *rdev,\n\t\t\t\t u8 voltage_type, u8 voltage_mode);\nint radeon_atom_get_svi2_info(struct radeon_device *rdev,\n\t\t\t      u8 voltage_type,\n\t\t\t      u8 *svd_gpio_id, u8 *svc_gpio_id);\nvoid radeon_atom_update_memory_dll(struct radeon_device *rdev,\n\t\t\t\t   u32 mem_clock);\nvoid radeon_atom_set_ac_timing(struct radeon_device *rdev,\n\t\t\t       u32 mem_clock);\nint radeon_atom_init_mc_reg_table(struct radeon_device *rdev,\n\t\t\t\t  u8 module_index,\n\t\t\t\t  struct atom_mc_reg_table *reg_table);\nint radeon_atom_get_memory_info(struct radeon_device *rdev,\n\t\t\t\tu8 module_index, struct atom_memory_info *mem_info);\nint radeon_atom_get_mclk_range_table(struct radeon_device *rdev,\n\t\t\t\t     bool gddr5, u8 module_index,\n\t\t\t\t     struct atom_memory_clock_range_table *mclk_range_table);\nint radeon_atom_get_max_vddc(struct radeon_device *rdev, u8 voltage_type,\n\t\t\t     u16 voltage_id, u16 *voltage);\nvoid rs690_pm_info(struct radeon_device *rdev);\nextern void evergreen_tiling_fields(unsigned tiling_flags, unsigned *bankw,\n\t\t\t\t    unsigned *bankh, unsigned *mtaspect,\n\t\t\t\t    unsigned *tile_split);\n\n \nstruct radeon_fence_driver {\n\tstruct radeon_device\t\t*rdev;\n\tuint32_t\t\t\tscratch_reg;\n\tuint64_t\t\t\tgpu_addr;\n\tvolatile uint32_t\t\t*cpu_addr;\n\t \n\tuint64_t\t\t\tsync_seq[RADEON_NUM_RINGS];\n\tatomic64_t\t\t\tlast_seq;\n\tbool\t\t\t\tinitialized, delayed_irq;\n\tstruct delayed_work\t\tlockup_work;\n};\n\nstruct radeon_fence {\n\tstruct dma_fence\t\tbase;\n\n\tstruct radeon_device\t*rdev;\n\tuint64_t\t\tseq;\n\t \n\tunsigned\t\tring;\n\tbool\t\t\tis_vm_update;\n\n\twait_queue_entry_t\t\tfence_wake;\n};\n\nint radeon_fence_driver_start_ring(struct radeon_device *rdev, int ring);\nvoid radeon_fence_driver_init(struct radeon_device *rdev);\nvoid radeon_fence_driver_fini(struct radeon_device *rdev);\nvoid radeon_fence_driver_force_completion(struct radeon_device *rdev, int ring);\nint radeon_fence_emit(struct radeon_device *rdev, struct radeon_fence **fence, int ring);\nvoid radeon_fence_process(struct radeon_device *rdev, int ring);\nbool radeon_fence_signaled(struct radeon_fence *fence);\nlong radeon_fence_wait_timeout(struct radeon_fence *fence, bool interruptible, long timeout);\nint radeon_fence_wait(struct radeon_fence *fence, bool interruptible);\nint radeon_fence_wait_next(struct radeon_device *rdev, int ring);\nint radeon_fence_wait_empty(struct radeon_device *rdev, int ring);\nint radeon_fence_wait_any(struct radeon_device *rdev,\n\t\t\t  struct radeon_fence **fences,\n\t\t\t  bool intr);\nstruct radeon_fence *radeon_fence_ref(struct radeon_fence *fence);\nvoid radeon_fence_unref(struct radeon_fence **fence);\nunsigned radeon_fence_count_emitted(struct radeon_device *rdev, int ring);\nbool radeon_fence_need_sync(struct radeon_fence *fence, int ring);\nvoid radeon_fence_note_sync(struct radeon_fence *fence, int ring);\nstatic inline struct radeon_fence *radeon_fence_later(struct radeon_fence *a,\n\t\t\t\t\t\t      struct radeon_fence *b)\n{\n\tif (!a) {\n\t\treturn b;\n\t}\n\n\tif (!b) {\n\t\treturn a;\n\t}\n\n\tBUG_ON(a->ring != b->ring);\n\n\tif (a->seq > b->seq) {\n\t\treturn a;\n\t} else {\n\t\treturn b;\n\t}\n}\n\nstatic inline bool radeon_fence_is_earlier(struct radeon_fence *a,\n\t\t\t\t\t   struct radeon_fence *b)\n{\n\tif (!a) {\n\t\treturn false;\n\t}\n\n\tif (!b) {\n\t\treturn true;\n\t}\n\n\tBUG_ON(a->ring != b->ring);\n\n\treturn a->seq < b->seq;\n}\n\n \nstruct radeon_surface_reg {\n\tstruct radeon_bo *bo;\n};\n\n#define RADEON_GEM_MAX_SURFACES 8\n\n \nstruct radeon_mman {\n\tstruct ttm_device\t\tbdev;\n\tbool\t\t\t\tinitialized;\n};\n\nstruct radeon_bo_list {\n\tstruct radeon_bo\t\t*robj;\n\tstruct ttm_validate_buffer\ttv;\n\tuint64_t\t\t\tgpu_offset;\n\tunsigned\t\t\tpreferred_domains;\n\tunsigned\t\t\tallowed_domains;\n\tuint32_t\t\t\ttiling_flags;\n};\n\n \nstruct radeon_bo_va {\n\t \n\tstruct list_head\t\tbo_list;\n\tuint32_t\t\t\tflags;\n\tstruct radeon_fence\t\t*last_pt_update;\n\tunsigned\t\t\tref_count;\n\n\t \n\tstruct interval_tree_node\tit;\n\tstruct list_head\t\tvm_status;\n\n\t \n\tstruct radeon_vm\t\t*vm;\n\tstruct radeon_bo\t\t*bo;\n};\n\nstruct radeon_bo {\n\t \n\tstruct list_head\t\tlist;\n\t \n\tu32\t\t\t\tinitial_domain;\n\tstruct ttm_place\t\tplacements[4];\n\tstruct ttm_placement\t\tplacement;\n\tstruct ttm_buffer_object\ttbo;\n\tstruct ttm_bo_kmap_obj\t\tkmap;\n\tu32\t\t\t\tflags;\n\tvoid\t\t\t\t*kptr;\n\tu32\t\t\t\ttiling_flags;\n\tu32\t\t\t\tpitch;\n\tint\t\t\t\tsurface_reg;\n\tunsigned\t\t\tprime_shared_count;\n\t \n\tstruct list_head\t\tva;\n\t \n\tstruct radeon_device\t\t*rdev;\n\n\tpid_t\t\t\t\tpid;\n\n#ifdef CONFIG_MMU_NOTIFIER\n\tstruct mmu_interval_notifier\tnotifier;\n#endif\n};\n#define gem_to_radeon_bo(gobj) container_of((gobj), struct radeon_bo, tbo.base)\n\nstruct radeon_sa_manager {\n\tstruct drm_suballoc_manager\tbase;\n\tstruct radeon_bo\t\t*bo;\n\tuint64_t\t\t\tgpu_addr;\n\tvoid\t\t\t\t*cpu_ptr;\n\tu32 domain;\n};\n\n \nstruct radeon_gem {\n\tstruct mutex\t\tmutex;\n\tstruct list_head\tobjects;\n};\n\nextern const struct drm_gem_object_funcs radeon_gem_object_funcs;\n\nint radeon_align_pitch(struct radeon_device *rdev, int width, int cpp, bool tiled);\n\nint radeon_gem_init(struct radeon_device *rdev);\nvoid radeon_gem_fini(struct radeon_device *rdev);\nint radeon_gem_object_create(struct radeon_device *rdev, unsigned long size,\n\t\t\t\tint alignment, int initial_domain,\n\t\t\t\tu32 flags, bool kernel,\n\t\t\t\tstruct drm_gem_object **obj);\n\nint radeon_mode_dumb_create(struct drm_file *file_priv,\n\t\t\t    struct drm_device *dev,\n\t\t\t    struct drm_mode_create_dumb *args);\nint radeon_mode_dumb_mmap(struct drm_file *filp,\n\t\t\t  struct drm_device *dev,\n\t\t\t  uint32_t handle, uint64_t *offset_p);\n\n \nstruct radeon_semaphore {\n\tstruct drm_suballoc\t*sa_bo;\n\tsigned\t\t\twaiters;\n\tuint64_t\t\tgpu_addr;\n};\n\nint radeon_semaphore_create(struct radeon_device *rdev,\n\t\t\t    struct radeon_semaphore **semaphore);\nbool radeon_semaphore_emit_signal(struct radeon_device *rdev, int ring,\n\t\t\t\t  struct radeon_semaphore *semaphore);\nbool radeon_semaphore_emit_wait(struct radeon_device *rdev, int ring,\n\t\t\t\tstruct radeon_semaphore *semaphore);\nvoid radeon_semaphore_free(struct radeon_device *rdev,\n\t\t\t   struct radeon_semaphore **semaphore,\n\t\t\t   struct radeon_fence *fence);\n\n \nstruct radeon_sync {\n\tstruct radeon_semaphore *semaphores[RADEON_NUM_SYNCS];\n\tstruct radeon_fence\t*sync_to[RADEON_NUM_RINGS];\n\tstruct radeon_fence\t*last_vm_update;\n};\n\nvoid radeon_sync_create(struct radeon_sync *sync);\nvoid radeon_sync_fence(struct radeon_sync *sync,\n\t\t       struct radeon_fence *fence);\nint radeon_sync_resv(struct radeon_device *rdev,\n\t\t     struct radeon_sync *sync,\n\t\t     struct dma_resv *resv,\n\t\t     bool shared);\nint radeon_sync_rings(struct radeon_device *rdev,\n\t\t      struct radeon_sync *sync,\n\t\t      int waiting_ring);\nvoid radeon_sync_free(struct radeon_device *rdev, struct radeon_sync *sync,\n\t\t      struct radeon_fence *fence);\n\n \nstruct radeon_mc;\n\n#define RADEON_GPU_PAGE_SIZE 4096\n#define RADEON_GPU_PAGE_MASK (RADEON_GPU_PAGE_SIZE - 1)\n#define RADEON_GPU_PAGE_SHIFT 12\n#define RADEON_GPU_PAGE_ALIGN(a) (((a) + RADEON_GPU_PAGE_MASK) & ~RADEON_GPU_PAGE_MASK)\n\n#define RADEON_GART_PAGE_DUMMY  0\n#define RADEON_GART_PAGE_VALID\t(1 << 0)\n#define RADEON_GART_PAGE_READ\t(1 << 1)\n#define RADEON_GART_PAGE_WRITE\t(1 << 2)\n#define RADEON_GART_PAGE_SNOOP\t(1 << 3)\n\nstruct radeon_gart {\n\tdma_addr_t\t\t\ttable_addr;\n\tstruct radeon_bo\t\t*robj;\n\tvoid\t\t\t\t*ptr;\n\tunsigned\t\t\tnum_gpu_pages;\n\tunsigned\t\t\tnum_cpu_pages;\n\tunsigned\t\t\ttable_size;\n\tstruct page\t\t\t**pages;\n\tuint64_t\t\t\t*pages_entry;\n\tbool\t\t\t\tready;\n};\n\nint radeon_gart_table_ram_alloc(struct radeon_device *rdev);\nvoid radeon_gart_table_ram_free(struct radeon_device *rdev);\nint radeon_gart_table_vram_alloc(struct radeon_device *rdev);\nvoid radeon_gart_table_vram_free(struct radeon_device *rdev);\nint radeon_gart_table_vram_pin(struct radeon_device *rdev);\nvoid radeon_gart_table_vram_unpin(struct radeon_device *rdev);\nint radeon_gart_init(struct radeon_device *rdev);\nvoid radeon_gart_fini(struct radeon_device *rdev);\nvoid radeon_gart_unbind(struct radeon_device *rdev, unsigned offset,\n\t\t\tint pages);\nint radeon_gart_bind(struct radeon_device *rdev, unsigned offset,\n\t\t     int pages, struct page **pagelist,\n\t\t     dma_addr_t *dma_addr, uint32_t flags);\n\n\n \nstruct radeon_mc {\n\tresource_size_t\t\taper_size;\n\tresource_size_t\t\taper_base;\n\tresource_size_t\t\tagp_base;\n\t \n\tu64\t\t\tmc_vram_size;\n\tu64\t\t\tvisible_vram_size;\n\tu64\t\t\tgtt_size;\n\tu64\t\t\tgtt_start;\n\tu64\t\t\tgtt_end;\n\tu64\t\t\tvram_start;\n\tu64\t\t\tvram_end;\n\tunsigned\t\tvram_width;\n\tu64\t\t\treal_vram_size;\n\tint\t\t\tvram_mtrr;\n\tbool\t\t\tvram_is_ddr;\n\tbool\t\t\tigp_sideport_enabled;\n\tu64                     gtt_base_align;\n\tu64                     mc_mask;\n};\n\nbool radeon_combios_sideport_present(struct radeon_device *rdev);\nbool radeon_atombios_sideport_present(struct radeon_device *rdev);\n\n \nstruct radeon_scratch {\n\tunsigned\t\tnum_reg;\n\tuint32_t                reg_base;\n\tbool\t\t\tfree[32];\n\tuint32_t\t\treg[32];\n};\n\nint radeon_scratch_get(struct radeon_device *rdev, uint32_t *reg);\nvoid radeon_scratch_free(struct radeon_device *rdev, uint32_t reg);\n\n \n#define RADEON_MAX_DOORBELLS 1024\t \n\nstruct radeon_doorbell {\n\t \n\tresource_size_t\t\tbase;\n\tresource_size_t\t\tsize;\n\tu32 __iomem\t\t*ptr;\n\tu32\t\t\tnum_doorbells;\t \n\tDECLARE_BITMAP(used, RADEON_MAX_DOORBELLS);\n};\n\nint radeon_doorbell_get(struct radeon_device *rdev, u32 *page);\nvoid radeon_doorbell_free(struct radeon_device *rdev, u32 doorbell);\n\n \n\nstruct radeon_flip_work {\n\tstruct work_struct\t\tflip_work;\n\tstruct work_struct\t\tunpin_work;\n\tstruct radeon_device\t\t*rdev;\n\tint\t\t\t\tcrtc_id;\n\tu32\t\t\t\ttarget_vblank;\n\tuint64_t\t\t\tbase;\n\tstruct drm_pending_vblank_event *event;\n\tstruct radeon_bo\t\t*old_rbo;\n\tstruct dma_fence\t\t*fence;\n\tbool\t\t\t\tasync;\n};\n\nstruct r500_irq_stat_regs {\n\tu32 disp_int;\n\tu32 hdmi0_status;\n};\n\nstruct r600_irq_stat_regs {\n\tu32 disp_int;\n\tu32 disp_int_cont;\n\tu32 disp_int_cont2;\n\tu32 d1grph_int;\n\tu32 d2grph_int;\n\tu32 hdmi0_status;\n\tu32 hdmi1_status;\n};\n\nstruct evergreen_irq_stat_regs {\n\tu32 disp_int[6];\n\tu32 grph_int[6];\n\tu32 afmt_status[6];\n};\n\nstruct cik_irq_stat_regs {\n\tu32 disp_int;\n\tu32 disp_int_cont;\n\tu32 disp_int_cont2;\n\tu32 disp_int_cont3;\n\tu32 disp_int_cont4;\n\tu32 disp_int_cont5;\n\tu32 disp_int_cont6;\n\tu32 d1grph_int;\n\tu32 d2grph_int;\n\tu32 d3grph_int;\n\tu32 d4grph_int;\n\tu32 d5grph_int;\n\tu32 d6grph_int;\n};\n\nunion radeon_irq_stat_regs {\n\tstruct r500_irq_stat_regs r500;\n\tstruct r600_irq_stat_regs r600;\n\tstruct evergreen_irq_stat_regs evergreen;\n\tstruct cik_irq_stat_regs cik;\n};\n\nstruct radeon_irq {\n\tbool\t\t\t\tinstalled;\n\tspinlock_t\t\t\tlock;\n\tatomic_t\t\t\tring_int[RADEON_NUM_RINGS];\n\tbool\t\t\t\tcrtc_vblank_int[RADEON_MAX_CRTCS];\n\tatomic_t\t\t\tpflip[RADEON_MAX_CRTCS];\n\twait_queue_head_t\t\tvblank_queue;\n\tbool\t\t\t\thpd[RADEON_MAX_HPD_PINS];\n\tbool\t\t\t\tafmt[RADEON_MAX_AFMT_BLOCKS];\n\tunion radeon_irq_stat_regs\tstat_regs;\n\tbool\t\t\t\tdpm_thermal;\n};\n\nint radeon_irq_kms_init(struct radeon_device *rdev);\nvoid radeon_irq_kms_fini(struct radeon_device *rdev);\nvoid radeon_irq_kms_sw_irq_get(struct radeon_device *rdev, int ring);\nbool radeon_irq_kms_sw_irq_get_delayed(struct radeon_device *rdev, int ring);\nvoid radeon_irq_kms_sw_irq_put(struct radeon_device *rdev, int ring);\nvoid radeon_irq_kms_pflip_irq_get(struct radeon_device *rdev, int crtc);\nvoid radeon_irq_kms_pflip_irq_put(struct radeon_device *rdev, int crtc);\nvoid radeon_irq_kms_enable_afmt(struct radeon_device *rdev, int block);\nvoid radeon_irq_kms_disable_afmt(struct radeon_device *rdev, int block);\nvoid radeon_irq_kms_enable_hpd(struct radeon_device *rdev, unsigned hpd_mask);\nvoid radeon_irq_kms_disable_hpd(struct radeon_device *rdev, unsigned hpd_mask);\n\n \n\nstruct radeon_ib {\n\tstruct drm_suballoc\t\t*sa_bo;\n\tuint32_t\t\t\tlength_dw;\n\tuint64_t\t\t\tgpu_addr;\n\tuint32_t\t\t\t*ptr;\n\tint\t\t\t\tring;\n\tstruct radeon_fence\t\t*fence;\n\tstruct radeon_vm\t\t*vm;\n\tbool\t\t\t\tis_const_ib;\n\tstruct radeon_sync\t\tsync;\n};\n\nstruct radeon_ring {\n\tstruct radeon_device\t*rdev;\n\tstruct radeon_bo\t*ring_obj;\n\tvolatile uint32_t\t*ring;\n\tunsigned\t\trptr_offs;\n\tunsigned\t\trptr_save_reg;\n\tu64\t\t\tnext_rptr_gpu_addr;\n\tvolatile u32\t\t*next_rptr_cpu_addr;\n\tunsigned\t\twptr;\n\tunsigned\t\twptr_old;\n\tunsigned\t\tring_size;\n\tunsigned\t\tring_free_dw;\n\tint\t\t\tcount_dw;\n\tatomic_t\t\tlast_rptr;\n\tatomic64_t\t\tlast_activity;\n\tuint64_t\t\tgpu_addr;\n\tuint32_t\t\talign_mask;\n\tuint32_t\t\tptr_mask;\n\tbool\t\t\tready;\n\tu32\t\t\tnop;\n\tu32\t\t\tidx;\n\tu64\t\t\tlast_semaphore_signal_addr;\n\tu64\t\t\tlast_semaphore_wait_addr;\n\t \n\tu32 me;\n\tu32 pipe;\n\tu32 queue;\n\tstruct radeon_bo\t*mqd_obj;\n\tu32 doorbell_index;\n\tunsigned\t\twptr_offs;\n};\n\nstruct radeon_mec {\n\tstruct radeon_bo\t*hpd_eop_obj;\n\tu64\t\t\thpd_eop_gpu_addr;\n\tu32 num_pipe;\n\tu32 num_mec;\n\tu32 num_queue;\n};\n\n \n\n \n#define RADEON_NUM_VM\t16\n\n \n#define RADEON_VM_PTE_COUNT (1 << radeon_vm_block_size)\n\n \n#define RADEON_VM_PTB_ALIGN_SIZE   32768\n#define RADEON_VM_PTB_ALIGN_MASK (RADEON_VM_PTB_ALIGN_SIZE - 1)\n#define RADEON_VM_PTB_ALIGN(a) (((a) + RADEON_VM_PTB_ALIGN_MASK) & ~RADEON_VM_PTB_ALIGN_MASK)\n\n#define R600_PTE_VALID\t\t(1 << 0)\n#define R600_PTE_SYSTEM\t\t(1 << 1)\n#define R600_PTE_SNOOPED\t(1 << 2)\n#define R600_PTE_READABLE\t(1 << 5)\n#define R600_PTE_WRITEABLE\t(1 << 6)\n\n \n#define R600_PTE_FRAG_4KB\t(0 << 7)\n#define R600_PTE_FRAG_64KB\t(4 << 7)\n#define R600_PTE_FRAG_256KB\t(6 << 7)\n\n \n#define R600_PTE_GART_MASK\t( R600_PTE_READABLE | R600_PTE_WRITEABLE | \\\n\t\t\t\t  R600_PTE_SYSTEM | R600_PTE_VALID )\n\nstruct radeon_vm_pt {\n\tstruct radeon_bo\t\t*bo;\n\tuint64_t\t\t\taddr;\n};\n\nstruct radeon_vm_id {\n\tunsigned\t\tid;\n\tuint64_t\t\tpd_gpu_addr;\n\t \n\tstruct radeon_fence\t*flushed_updates;\n\t \n\tstruct radeon_fence\t*last_id_use;\n};\n\nstruct radeon_vm {\n\tstruct mutex\t\tmutex;\n\n\tstruct rb_root_cached\tva;\n\n\t \n\tspinlock_t\t\tstatus_lock;\n\n\t \n\tstruct list_head\tinvalidated;\n\n\t \n\tstruct list_head\tfreed;\n\n\t \n\tstruct list_head\tcleared;\n\n\t \n\tstruct radeon_bo\t*page_directory;\n\tunsigned\t\tmax_pde_used;\n\n\t \n\tstruct radeon_vm_pt\t*page_tables;\n\n\tstruct radeon_bo_va\t*ib_bo_va;\n\n\t \n\tstruct radeon_vm_id\tids[RADEON_NUM_RINGS];\n};\n\nstruct radeon_vm_manager {\n\tstruct radeon_fence\t\t*active[RADEON_NUM_VM];\n\tuint32_t\t\t\tmax_pfn;\n\t \n\tunsigned\t\t\tnvm;\n\t \n\tu64\t\t\t\tvram_base_offset;\n\t \n\tbool\t\t\t\tenabled;\n\t \n\tuint32_t\t\t\tsaved_table_addr[RADEON_NUM_VM];\n};\n\n \nstruct radeon_fpriv {\n\tstruct radeon_vm\t\tvm;\n};\n\n \nstruct r600_ih {\n\tstruct radeon_bo\t*ring_obj;\n\tvolatile uint32_t\t*ring;\n\tunsigned\t\trptr;\n\tunsigned\t\tring_size;\n\tuint64_t\t\tgpu_addr;\n\tuint32_t\t\tptr_mask;\n\tatomic_t\t\tlock;\n\tbool                    enabled;\n};\n\n \n#include \"clearstate_defs.h\"\n\nstruct radeon_rlc {\n\t \n\tstruct radeon_bo\t*save_restore_obj;\n\tuint64_t\t\tsave_restore_gpu_addr;\n\tvolatile uint32_t\t*sr_ptr;\n\tconst u32               *reg_list;\n\tu32                     reg_list_size;\n\t \n\tstruct radeon_bo\t*clear_state_obj;\n\tuint64_t\t\tclear_state_gpu_addr;\n\tvolatile uint32_t\t*cs_ptr;\n\tconst struct cs_section_def   *cs_data;\n\tu32                     clear_state_size;\n\t \n\tstruct radeon_bo\t*cp_table_obj;\n\tuint64_t\t\tcp_table_gpu_addr;\n\tvolatile uint32_t\t*cp_table_ptr;\n\tu32                     cp_table_size;\n};\n\nint radeon_ib_get(struct radeon_device *rdev, int ring,\n\t\t  struct radeon_ib *ib, struct radeon_vm *vm,\n\t\t  unsigned size);\nvoid radeon_ib_free(struct radeon_device *rdev, struct radeon_ib *ib);\nint radeon_ib_schedule(struct radeon_device *rdev, struct radeon_ib *ib,\n\t\t       struct radeon_ib *const_ib, bool hdp_flush);\nint radeon_ib_pool_init(struct radeon_device *rdev);\nvoid radeon_ib_pool_fini(struct radeon_device *rdev);\nint radeon_ib_ring_tests(struct radeon_device *rdev);\n \nbool radeon_ring_supports_scratch_reg(struct radeon_device *rdev,\n\t\t\t\t      struct radeon_ring *ring);\nvoid radeon_ring_free_size(struct radeon_device *rdev, struct radeon_ring *cp);\nint radeon_ring_alloc(struct radeon_device *rdev, struct radeon_ring *cp, unsigned ndw);\nint radeon_ring_lock(struct radeon_device *rdev, struct radeon_ring *cp, unsigned ndw);\nvoid radeon_ring_commit(struct radeon_device *rdev, struct radeon_ring *cp,\n\t\t\tbool hdp_flush);\nvoid radeon_ring_unlock_commit(struct radeon_device *rdev, struct radeon_ring *cp,\n\t\t\t       bool hdp_flush);\nvoid radeon_ring_undo(struct radeon_ring *ring);\nvoid radeon_ring_unlock_undo(struct radeon_device *rdev, struct radeon_ring *cp);\nint radeon_ring_test(struct radeon_device *rdev, struct radeon_ring *cp);\nvoid radeon_ring_lockup_update(struct radeon_device *rdev,\n\t\t\t       struct radeon_ring *ring);\nbool radeon_ring_test_lockup(struct radeon_device *rdev, struct radeon_ring *ring);\nunsigned radeon_ring_backup(struct radeon_device *rdev, struct radeon_ring *ring,\n\t\t\t    uint32_t **data);\nint radeon_ring_restore(struct radeon_device *rdev, struct radeon_ring *ring,\n\t\t\tunsigned size, uint32_t *data);\nint radeon_ring_init(struct radeon_device *rdev, struct radeon_ring *cp, unsigned ring_size,\n\t\t     unsigned rptr_offs, u32 nop);\nvoid radeon_ring_fini(struct radeon_device *rdev, struct radeon_ring *cp);\n\n\n \nvoid r600_dma_stop(struct radeon_device *rdev);\nint r600_dma_resume(struct radeon_device *rdev);\nvoid r600_dma_fini(struct radeon_device *rdev);\n\nvoid cayman_dma_stop(struct radeon_device *rdev);\nint cayman_dma_resume(struct radeon_device *rdev);\nvoid cayman_dma_fini(struct radeon_device *rdev);\n\n \nstruct radeon_cs_chunk {\n\tuint32_t\t\tlength_dw;\n\tuint32_t\t\t*kdata;\n\tvoid __user\t\t*user_ptr;\n};\n\nstruct radeon_cs_parser {\n\tstruct device\t\t*dev;\n\tstruct radeon_device\t*rdev;\n\tstruct drm_file\t\t*filp;\n\t \n\tunsigned\t\tnchunks;\n\tstruct radeon_cs_chunk\t*chunks;\n\tuint64_t\t\t*chunks_array;\n\t \n\tunsigned\t\tidx;\n\t \n\tunsigned\t\tnrelocs;\n\tstruct radeon_bo_list\t*relocs;\n\tstruct radeon_bo_list\t*vm_bos;\n\tstruct list_head\tvalidated;\n\tunsigned\t\tdma_reloc_idx;\n\t \n\tstruct radeon_cs_chunk  *chunk_ib;\n\tstruct radeon_cs_chunk  *chunk_relocs;\n\tstruct radeon_cs_chunk  *chunk_flags;\n\tstruct radeon_cs_chunk  *chunk_const_ib;\n\tstruct radeon_ib\tib;\n\tstruct radeon_ib\tconst_ib;\n\tvoid\t\t\t*track;\n\tunsigned\t\tfamily;\n\tint\t\t\tparser_error;\n\tu32\t\t\tcs_flags;\n\tu32\t\t\tring;\n\ts32\t\t\tpriority;\n\tstruct ww_acquire_ctx\tticket;\n};\n\nstatic inline u32 radeon_get_ib_value(struct radeon_cs_parser *p, int idx)\n{\n\tstruct radeon_cs_chunk *ibc = p->chunk_ib;\n\n\tif (ibc->kdata)\n\t\treturn ibc->kdata[idx];\n\treturn p->ib.ptr[idx];\n}\n\n\nstruct radeon_cs_packet {\n\tunsigned\tidx;\n\tunsigned\ttype;\n\tunsigned\treg;\n\tunsigned\topcode;\n\tint\t\tcount;\n\tunsigned\tone_reg_wr;\n};\n\ntypedef int (*radeon_packet0_check_t)(struct radeon_cs_parser *p,\n\t\t\t\t      struct radeon_cs_packet *pkt,\n\t\t\t\t      unsigned idx, unsigned reg);\n\n \n\nstruct radeon_agp_mode {\n\tunsigned long mode;\t \n};\n\nstruct radeon_agp_info {\n\tint agp_version_major;\n\tint agp_version_minor;\n\tunsigned long mode;\n\tunsigned long aperture_base;\t \n\tunsigned long aperture_size;\t \n\tunsigned long memory_allowed;\t \n\tunsigned long memory_used;\n\n\t \n\tunsigned short id_vendor;\n\tunsigned short id_device;\n};\n\nstruct radeon_agp_head {\n\tstruct agp_kern_info agp_info;\n\tstruct list_head memory;\n\tunsigned long mode;\n\tstruct agp_bridge_data *bridge;\n\tint enabled;\n\tint acquired;\n\tunsigned long base;\n\tint agp_mtrr;\n\tint cant_use_aperture;\n\tunsigned long page_mask;\n};\n\n#if IS_ENABLED(CONFIG_AGP)\nstruct radeon_agp_head *radeon_agp_head_init(struct drm_device *dev);\n#else\nstatic inline struct radeon_agp_head *radeon_agp_head_init(struct drm_device *dev)\n{\n\treturn NULL;\n}\n#endif\nint radeon_agp_init(struct radeon_device *rdev);\nvoid radeon_agp_resume(struct radeon_device *rdev);\nvoid radeon_agp_suspend(struct radeon_device *rdev);\nvoid radeon_agp_fini(struct radeon_device *rdev);\n\n\n \nstruct radeon_wb {\n\tstruct radeon_bo\t*wb_obj;\n\tvolatile uint32_t\t*wb;\n\tuint64_t\t\tgpu_addr;\n\tbool                    enabled;\n\tbool                    use_event;\n};\n\n#define RADEON_WB_SCRATCH_OFFSET 0\n#define RADEON_WB_RING0_NEXT_RPTR 256\n#define RADEON_WB_CP_RPTR_OFFSET 1024\n#define RADEON_WB_CP1_RPTR_OFFSET 1280\n#define RADEON_WB_CP2_RPTR_OFFSET 1536\n#define R600_WB_DMA_RPTR_OFFSET   1792\n#define R600_WB_IH_WPTR_OFFSET   2048\n#define CAYMAN_WB_DMA1_RPTR_OFFSET   2304\n#define R600_WB_EVENT_OFFSET     3072\n#define CIK_WB_CP1_WPTR_OFFSET     3328\n#define CIK_WB_CP2_WPTR_OFFSET     3584\n#define R600_WB_DMA_RING_TEST_OFFSET 3588\n#define CAYMAN_WB_DMA1_RING_TEST_OFFSET 3592\n\n \n\nenum radeon_pm_method {\n\tPM_METHOD_PROFILE,\n\tPM_METHOD_DYNPM,\n\tPM_METHOD_DPM,\n};\n\nenum radeon_dynpm_state {\n\tDYNPM_STATE_DISABLED,\n\tDYNPM_STATE_MINIMUM,\n\tDYNPM_STATE_PAUSED,\n\tDYNPM_STATE_ACTIVE,\n\tDYNPM_STATE_SUSPENDED,\n};\nenum radeon_dynpm_action {\n\tDYNPM_ACTION_NONE,\n\tDYNPM_ACTION_MINIMUM,\n\tDYNPM_ACTION_DOWNCLOCK,\n\tDYNPM_ACTION_UPCLOCK,\n\tDYNPM_ACTION_DEFAULT\n};\n\nenum radeon_voltage_type {\n\tVOLTAGE_NONE = 0,\n\tVOLTAGE_GPIO,\n\tVOLTAGE_VDDC,\n\tVOLTAGE_SW\n};\n\nenum radeon_pm_state_type {\n\t \n\tPOWER_STATE_TYPE_DEFAULT,\n\tPOWER_STATE_TYPE_POWERSAVE,\n\t \n\tPOWER_STATE_TYPE_BATTERY,\n\tPOWER_STATE_TYPE_BALANCED,\n\tPOWER_STATE_TYPE_PERFORMANCE,\n\t \n\tPOWER_STATE_TYPE_INTERNAL_UVD,\n\tPOWER_STATE_TYPE_INTERNAL_UVD_SD,\n\tPOWER_STATE_TYPE_INTERNAL_UVD_HD,\n\tPOWER_STATE_TYPE_INTERNAL_UVD_HD2,\n\tPOWER_STATE_TYPE_INTERNAL_UVD_MVC,\n\tPOWER_STATE_TYPE_INTERNAL_BOOT,\n\tPOWER_STATE_TYPE_INTERNAL_THERMAL,\n\tPOWER_STATE_TYPE_INTERNAL_ACPI,\n\tPOWER_STATE_TYPE_INTERNAL_ULV,\n\tPOWER_STATE_TYPE_INTERNAL_3DPERF,\n};\n\nenum radeon_pm_profile_type {\n\tPM_PROFILE_DEFAULT,\n\tPM_PROFILE_AUTO,\n\tPM_PROFILE_LOW,\n\tPM_PROFILE_MID,\n\tPM_PROFILE_HIGH,\n};\n\n#define PM_PROFILE_DEFAULT_IDX 0\n#define PM_PROFILE_LOW_SH_IDX  1\n#define PM_PROFILE_MID_SH_IDX  2\n#define PM_PROFILE_HIGH_SH_IDX 3\n#define PM_PROFILE_LOW_MH_IDX  4\n#define PM_PROFILE_MID_MH_IDX  5\n#define PM_PROFILE_HIGH_MH_IDX 6\n#define PM_PROFILE_MAX         7\n\nstruct radeon_pm_profile {\n\tint dpms_off_ps_idx;\n\tint dpms_on_ps_idx;\n\tint dpms_off_cm_idx;\n\tint dpms_on_cm_idx;\n};\n\nenum radeon_int_thermal_type {\n\tTHERMAL_TYPE_NONE,\n\tTHERMAL_TYPE_EXTERNAL,\n\tTHERMAL_TYPE_EXTERNAL_GPIO,\n\tTHERMAL_TYPE_RV6XX,\n\tTHERMAL_TYPE_RV770,\n\tTHERMAL_TYPE_ADT7473_WITH_INTERNAL,\n\tTHERMAL_TYPE_EVERGREEN,\n\tTHERMAL_TYPE_SUMO,\n\tTHERMAL_TYPE_NI,\n\tTHERMAL_TYPE_SI,\n\tTHERMAL_TYPE_EMC2103_WITH_INTERNAL,\n\tTHERMAL_TYPE_CI,\n\tTHERMAL_TYPE_KV,\n};\n\nstruct radeon_voltage {\n\tenum radeon_voltage_type type;\n\t \n\tstruct radeon_gpio_rec gpio;\n\tu32 delay;  \n\tbool active_high;  \n\t \n\tu8 vddc_id;  \n\tu8 vddci_id;  \n\tbool vddci_enabled;\n\t \n\tu16 voltage;\n\t \n\tu16 vddci;\n};\n\n \n#define RADEON_PM_MODE_NO_DISPLAY          (1 << 0)\n\nstruct radeon_pm_clock_info {\n\t \n\tu32 mclk;\n\t \n\tu32 sclk;\n\t \n\tstruct radeon_voltage voltage;\n\t \n\tu32 flags;\n};\n\n \n#define RADEON_PM_STATE_SINGLE_DISPLAY_ONLY (1 << 0)\n\nstruct radeon_power_state {\n\tenum radeon_pm_state_type type;\n\tstruct radeon_pm_clock_info *clock_info;\n\t \n\tint num_clock_modes;\n\tstruct radeon_pm_clock_info *default_clock_mode;\n\t \n\tu32 flags;\n\tu32 misc;  \n\tu32 misc2;  \n\tint pcie_lanes;  \n};\n\n \n#define RADEON_MODE_OVERCLOCK_MARGIN 500  \n\nenum radeon_dpm_auto_throttle_src {\n\tRADEON_DPM_AUTO_THROTTLE_SRC_THERMAL,\n\tRADEON_DPM_AUTO_THROTTLE_SRC_EXTERNAL\n};\n\nenum radeon_dpm_event_src {\n\tRADEON_DPM_EVENT_SRC_ANALOG = 0,\n\tRADEON_DPM_EVENT_SRC_EXTERNAL = 1,\n\tRADEON_DPM_EVENT_SRC_DIGITAL = 2,\n\tRADEON_DPM_EVENT_SRC_ANALOG_OR_EXTERNAL = 3,\n\tRADEON_DPM_EVENT_SRC_DIGIAL_OR_EXTERNAL = 4\n};\n\n#define RADEON_MAX_VCE_LEVELS 6\n\nenum radeon_vce_level {\n\tRADEON_VCE_LEVEL_AC_ALL = 0,      \n\tRADEON_VCE_LEVEL_DC_EE = 1,       \n\tRADEON_VCE_LEVEL_DC_LL_LOW = 2,   \n\tRADEON_VCE_LEVEL_DC_LL_HIGH = 3,  \n\tRADEON_VCE_LEVEL_DC_GP_LOW = 4,   \n\tRADEON_VCE_LEVEL_DC_GP_HIGH = 5,  \n};\n\nstruct radeon_ps {\n\tu32 caps;  \n\tu32 class;  \n\tu32 class2;  \n\t \n\tu32 vclk;\n\tu32 dclk;\n\t \n\tu32 evclk;\n\tu32 ecclk;\n\tbool vce_active;\n\tenum radeon_vce_level vce_level;\n\t \n\tvoid *ps_priv;\n};\n\nstruct radeon_dpm_thermal {\n\t \n\tstruct work_struct work;\n\t \n\tint                min_temp;\n\t \n\tint                max_temp;\n\t \n\tbool               high_to_low;\n};\n\nenum radeon_clk_action\n{\n\tRADEON_SCLK_UP = 1,\n\tRADEON_SCLK_DOWN\n};\n\nstruct radeon_blacklist_clocks\n{\n\tu32 sclk;\n\tu32 mclk;\n\tenum radeon_clk_action action;\n};\n\nstruct radeon_clock_and_voltage_limits {\n\tu32 sclk;\n\tu32 mclk;\n\tu16 vddc;\n\tu16 vddci;\n};\n\nstruct radeon_clock_array {\n\tu32 count;\n\tu32 *values;\n};\n\nstruct radeon_clock_voltage_dependency_entry {\n\tu32 clk;\n\tu16 v;\n};\n\nstruct radeon_clock_voltage_dependency_table {\n\tu32 count;\n\tstruct radeon_clock_voltage_dependency_entry *entries;\n};\n\nunion radeon_cac_leakage_entry {\n\tstruct {\n\t\tu16 vddc;\n\t\tu32 leakage;\n\t};\n\tstruct {\n\t\tu16 vddc1;\n\t\tu16 vddc2;\n\t\tu16 vddc3;\n\t};\n};\n\nstruct radeon_cac_leakage_table {\n\tu32 count;\n\tunion radeon_cac_leakage_entry *entries;\n};\n\nstruct radeon_phase_shedding_limits_entry {\n\tu16 voltage;\n\tu32 sclk;\n\tu32 mclk;\n};\n\nstruct radeon_phase_shedding_limits_table {\n\tu32 count;\n\tstruct radeon_phase_shedding_limits_entry *entries;\n};\n\nstruct radeon_uvd_clock_voltage_dependency_entry {\n\tu32 vclk;\n\tu32 dclk;\n\tu16 v;\n};\n\nstruct radeon_uvd_clock_voltage_dependency_table {\n\tu8 count;\n\tstruct radeon_uvd_clock_voltage_dependency_entry *entries;\n};\n\nstruct radeon_vce_clock_voltage_dependency_entry {\n\tu32 ecclk;\n\tu32 evclk;\n\tu16 v;\n};\n\nstruct radeon_vce_clock_voltage_dependency_table {\n\tu8 count;\n\tstruct radeon_vce_clock_voltage_dependency_entry *entries;\n};\n\nstruct radeon_ppm_table {\n\tu8 ppm_design;\n\tu16 cpu_core_number;\n\tu32 platform_tdp;\n\tu32 small_ac_platform_tdp;\n\tu32 platform_tdc;\n\tu32 small_ac_platform_tdc;\n\tu32 apu_tdp;\n\tu32 dgpu_tdp;\n\tu32 dgpu_ulv_power;\n\tu32 tj_max;\n};\n\nstruct radeon_cac_tdp_table {\n\tu16 tdp;\n\tu16 configurable_tdp;\n\tu16 tdc;\n\tu16 battery_power_limit;\n\tu16 small_power_limit;\n\tu16 low_cac_leakage;\n\tu16 high_cac_leakage;\n\tu16 maximum_power_delivery_limit;\n};\n\nstruct radeon_dpm_dynamic_state {\n\tstruct radeon_clock_voltage_dependency_table vddc_dependency_on_sclk;\n\tstruct radeon_clock_voltage_dependency_table vddci_dependency_on_mclk;\n\tstruct radeon_clock_voltage_dependency_table vddc_dependency_on_mclk;\n\tstruct radeon_clock_voltage_dependency_table mvdd_dependency_on_mclk;\n\tstruct radeon_clock_voltage_dependency_table vddc_dependency_on_dispclk;\n\tstruct radeon_uvd_clock_voltage_dependency_table uvd_clock_voltage_dependency_table;\n\tstruct radeon_vce_clock_voltage_dependency_table vce_clock_voltage_dependency_table;\n\tstruct radeon_clock_voltage_dependency_table samu_clock_voltage_dependency_table;\n\tstruct radeon_clock_voltage_dependency_table acp_clock_voltage_dependency_table;\n\tstruct radeon_clock_array valid_sclk_values;\n\tstruct radeon_clock_array valid_mclk_values;\n\tstruct radeon_clock_and_voltage_limits max_clock_voltage_on_dc;\n\tstruct radeon_clock_and_voltage_limits max_clock_voltage_on_ac;\n\tu32 mclk_sclk_ratio;\n\tu32 sclk_mclk_delta;\n\tu16 vddc_vddci_delta;\n\tu16 min_vddc_for_pcie_gen2;\n\tstruct radeon_cac_leakage_table cac_leakage_table;\n\tstruct radeon_phase_shedding_limits_table phase_shedding_limits_table;\n\tstruct radeon_ppm_table *ppm_table;\n\tstruct radeon_cac_tdp_table *cac_tdp_table;\n};\n\nstruct radeon_dpm_fan {\n\tu16 t_min;\n\tu16 t_med;\n\tu16 t_high;\n\tu16 pwm_min;\n\tu16 pwm_med;\n\tu16 pwm_high;\n\tu8 t_hyst;\n\tu32 cycle_delay;\n\tu16 t_max;\n\tu8 control_mode;\n\tu16 default_max_fan_pwm;\n\tu16 default_fan_output_sensitivity;\n\tu16 fan_output_sensitivity;\n\tbool ucode_fan_control;\n};\n\nenum radeon_pcie_gen {\n\tRADEON_PCIE_GEN1 = 0,\n\tRADEON_PCIE_GEN2 = 1,\n\tRADEON_PCIE_GEN3 = 2,\n\tRADEON_PCIE_GEN_INVALID = 0xffff\n};\n\nenum radeon_dpm_forced_level {\n\tRADEON_DPM_FORCED_LEVEL_AUTO = 0,\n\tRADEON_DPM_FORCED_LEVEL_LOW = 1,\n\tRADEON_DPM_FORCED_LEVEL_HIGH = 2,\n};\n\nstruct radeon_vce_state {\n\t \n\tu32 evclk;\n\tu32 ecclk;\n\t \n\tu32 sclk;\n\tu32 mclk;\n\tu8 clk_idx;\n\tu8 pstate;\n};\n\nstruct radeon_dpm {\n\tstruct radeon_ps        *ps;\n\t \n\tint                     num_ps;\n\t \n\tstruct radeon_ps        *current_ps;\n\t \n\tstruct radeon_ps        *requested_ps;\n\t \n\tstruct radeon_ps        *boot_ps;\n\t \n\tstruct radeon_ps        *uvd_ps;\n\t \n\tstruct radeon_vce_state vce_states[RADEON_MAX_VCE_LEVELS];\n\tenum radeon_vce_level vce_level;\n\tenum radeon_pm_state_type state;\n\tenum radeon_pm_state_type user_state;\n\tu32                     platform_caps;\n\tu32                     voltage_response_time;\n\tu32                     backbias_response_time;\n\tvoid                    *priv;\n\tu32\t\t\tnew_active_crtcs;\n\tint\t\t\tnew_active_crtc_count;\n\tint\t\t\thigh_pixelclock_count;\n\tu32\t\t\tcurrent_active_crtcs;\n\tint\t\t\tcurrent_active_crtc_count;\n\tbool single_display;\n\tstruct radeon_dpm_dynamic_state dyn_state;\n\tstruct radeon_dpm_fan fan;\n\tu32 tdp_limit;\n\tu32 near_tdp_limit;\n\tu32 near_tdp_limit_adjusted;\n\tu32 sq_ramping_threshold;\n\tu32 cac_leakage;\n\tu16 tdp_od_limit;\n\tu32 tdp_adjustment;\n\tu16 load_line_slope;\n\tbool power_control;\n\tbool ac_power;\n\t \n\tbool                    thermal_active;\n\tbool                    uvd_active;\n\tbool                    vce_active;\n\t \n\tstruct radeon_dpm_thermal thermal;\n\t \n\tenum radeon_dpm_forced_level forced_level;\n\t \n\tunsigned sd;\n\tunsigned hd;\n};\n\nvoid radeon_dpm_enable_uvd(struct radeon_device *rdev, bool enable);\nvoid radeon_dpm_enable_vce(struct radeon_device *rdev, bool enable);\n\nstruct radeon_pm {\n\tstruct mutex\t\tmutex;\n\t \n\tstruct rw_semaphore\tmclk_lock;\n\tu32\t\t\tactive_crtcs;\n\tint\t\t\tactive_crtc_count;\n\tint\t\t\treq_vblank;\n\tbool\t\t\tvblank_sync;\n\tfixed20_12\t\tmax_bandwidth;\n\tfixed20_12\t\tigp_sideport_mclk;\n\tfixed20_12\t\tigp_system_mclk;\n\tfixed20_12\t\tigp_ht_link_clk;\n\tfixed20_12\t\tigp_ht_link_width;\n\tfixed20_12\t\tk8_bandwidth;\n\tfixed20_12\t\tsideport_bandwidth;\n\tfixed20_12\t\tht_bandwidth;\n\tfixed20_12\t\tcore_bandwidth;\n\tfixed20_12\t\tsclk;\n\tfixed20_12\t\tmclk;\n\tfixed20_12\t\tneeded_bandwidth;\n\tstruct radeon_power_state *power_state;\n\t \n\tint                     num_power_states;\n\tint                     current_power_state_index;\n\tint                     current_clock_mode_index;\n\tint                     requested_power_state_index;\n\tint                     requested_clock_mode_index;\n\tint                     default_power_state_index;\n\tu32                     current_sclk;\n\tu32                     current_mclk;\n\tu16                     current_vddc;\n\tu16                     current_vddci;\n\tu32                     default_sclk;\n\tu32                     default_mclk;\n\tu16                     default_vddc;\n\tu16                     default_vddci;\n\tstruct radeon_i2c_chan *i2c_bus;\n\t \n\tenum radeon_pm_method     pm_method;\n\t \n\tstruct delayed_work\tdynpm_idle_work;\n\tenum radeon_dynpm_state\tdynpm_state;\n\tenum radeon_dynpm_action\tdynpm_planned_action;\n\tunsigned long\t\tdynpm_action_timeout;\n\tbool                    dynpm_can_upclock;\n\tbool                    dynpm_can_downclock;\n\t \n\tenum radeon_pm_profile_type profile;\n\tint                     profile_index;\n\tstruct radeon_pm_profile profiles[PM_PROFILE_MAX];\n\t \n\tenum radeon_int_thermal_type int_thermal_type;\n\tstruct device\t        *int_hwmon_dev;\n\t \n\tbool                    no_fan;\n\tu8                      fan_pulses_per_revolution;\n\tu8                      fan_min_rpm;\n\tu8                      fan_max_rpm;\n\t \n\tbool                    dpm_enabled;\n\tbool                    sysfs_initialized;\n\tstruct radeon_dpm       dpm;\n};\n\n#define RADEON_PCIE_SPEED_25 1\n#define RADEON_PCIE_SPEED_50 2\n#define RADEON_PCIE_SPEED_80 4\n\nint radeon_pm_get_type_index(struct radeon_device *rdev,\n\t\t\t     enum radeon_pm_state_type ps_type,\n\t\t\t     int instance);\n \n#define RADEON_DEFAULT_UVD_HANDLES\t10\n#define RADEON_MAX_UVD_HANDLES\t\t30\n#define RADEON_UVD_STACK_SIZE\t\t(200*1024)\n#define RADEON_UVD_HEAP_SIZE\t\t(256*1024)\n#define RADEON_UVD_SESSION_SIZE\t\t(50*1024)\n\nstruct radeon_uvd {\n\tbool\t\t\tfw_header_present;\n\tstruct radeon_bo\t*vcpu_bo;\n\tvoid\t\t\t*cpu_addr;\n\tuint64_t\t\tgpu_addr;\n\tunsigned\t\tmax_handles;\n\tatomic_t\t\thandles[RADEON_MAX_UVD_HANDLES];\n\tstruct drm_file\t\t*filp[RADEON_MAX_UVD_HANDLES];\n\tunsigned\t\timg_size[RADEON_MAX_UVD_HANDLES];\n\tstruct delayed_work\tidle_work;\n};\n\nint radeon_uvd_init(struct radeon_device *rdev);\nvoid radeon_uvd_fini(struct radeon_device *rdev);\nint radeon_uvd_suspend(struct radeon_device *rdev);\nint radeon_uvd_resume(struct radeon_device *rdev);\nint radeon_uvd_get_create_msg(struct radeon_device *rdev, int ring,\n\t\t\t      uint32_t handle, struct radeon_fence **fence);\nint radeon_uvd_get_destroy_msg(struct radeon_device *rdev, int ring,\n\t\t\t       uint32_t handle, struct radeon_fence **fence);\nvoid radeon_uvd_force_into_uvd_segment(struct radeon_bo *rbo,\n\t\t\t\t       uint32_t allowed_domains);\nvoid radeon_uvd_free_handles(struct radeon_device *rdev,\n\t\t\t     struct drm_file *filp);\nint radeon_uvd_cs_parse(struct radeon_cs_parser *parser);\nvoid radeon_uvd_note_usage(struct radeon_device *rdev);\nint radeon_uvd_calc_upll_dividers(struct radeon_device *rdev,\n\t\t\t\t  unsigned vclk, unsigned dclk,\n\t\t\t\t  unsigned vco_min, unsigned vco_max,\n\t\t\t\t  unsigned fb_factor, unsigned fb_mask,\n\t\t\t\t  unsigned pd_min, unsigned pd_max,\n\t\t\t\t  unsigned pd_even,\n\t\t\t\t  unsigned *optimal_fb_div,\n\t\t\t\t  unsigned *optimal_vclk_div,\n\t\t\t\t  unsigned *optimal_dclk_div);\nint radeon_uvd_send_upll_ctlreq(struct radeon_device *rdev,\n                                unsigned cg_upll_func_cntl);\n\n \n#define RADEON_MAX_VCE_HANDLES\t16\n\nstruct radeon_vce {\n\tstruct radeon_bo\t*vcpu_bo;\n\tuint64_t\t\tgpu_addr;\n\tunsigned\t\tfw_version;\n\tunsigned\t\tfb_version;\n\tatomic_t\t\thandles[RADEON_MAX_VCE_HANDLES];\n\tstruct drm_file\t\t*filp[RADEON_MAX_VCE_HANDLES];\n\tunsigned\t\timg_size[RADEON_MAX_VCE_HANDLES];\n\tstruct delayed_work\tidle_work;\n\tuint32_t\t\tkeyselect;\n};\n\nint radeon_vce_init(struct radeon_device *rdev);\nvoid radeon_vce_fini(struct radeon_device *rdev);\nint radeon_vce_suspend(struct radeon_device *rdev);\nint radeon_vce_resume(struct radeon_device *rdev);\nint radeon_vce_get_create_msg(struct radeon_device *rdev, int ring,\n\t\t\t      uint32_t handle, struct radeon_fence **fence);\nint radeon_vce_get_destroy_msg(struct radeon_device *rdev, int ring,\n\t\t\t       uint32_t handle, struct radeon_fence **fence);\nvoid radeon_vce_free_handles(struct radeon_device *rdev, struct drm_file *filp);\nvoid radeon_vce_note_usage(struct radeon_device *rdev);\nint radeon_vce_cs_reloc(struct radeon_cs_parser *p, int lo, int hi, unsigned size);\nint radeon_vce_cs_parse(struct radeon_cs_parser *p);\nbool radeon_vce_semaphore_emit(struct radeon_device *rdev,\n\t\t\t       struct radeon_ring *ring,\n\t\t\t       struct radeon_semaphore *semaphore,\n\t\t\t       bool emit_wait);\nvoid radeon_vce_ib_execute(struct radeon_device *rdev, struct radeon_ib *ib);\nvoid radeon_vce_fence_emit(struct radeon_device *rdev,\n\t\t\t   struct radeon_fence *fence);\nint radeon_vce_ring_test(struct radeon_device *rdev, struct radeon_ring *ring);\nint radeon_vce_ib_test(struct radeon_device *rdev, struct radeon_ring *ring);\n\nstruct r600_audio_pin {\n\tint\t\t\tchannels;\n\tint\t\t\trate;\n\tint\t\t\tbits_per_sample;\n\tu8\t\t\tstatus_bits;\n\tu8\t\t\tcategory_code;\n\tu32\t\t\toffset;\n\tbool\t\t\tconnected;\n\tu32\t\t\tid;\n};\n\nstruct r600_audio {\n\tbool enabled;\n\tstruct r600_audio_pin pin[RADEON_MAX_AFMT_BLOCKS];\n\tint num_pins;\n\tstruct radeon_audio_funcs *hdmi_funcs;\n\tstruct radeon_audio_funcs *dp_funcs;\n\tstruct radeon_audio_basic_funcs *funcs;\n\tstruct drm_audio_component *component;\n\tbool component_registered;\n\tstruct mutex component_mutex;\n};\n\n \nvoid radeon_benchmark(struct radeon_device *rdev, int test_number);\n\n\n \nvoid radeon_test_moves(struct radeon_device *rdev);\nvoid radeon_test_ring_sync(struct radeon_device *rdev,\n\t\t\t   struct radeon_ring *cpA,\n\t\t\t   struct radeon_ring *cpB);\nvoid radeon_test_syncing(struct radeon_device *rdev);\n\n \n#if defined(CONFIG_MMU_NOTIFIER)\nint radeon_mn_register(struct radeon_bo *bo, unsigned long addr);\nvoid radeon_mn_unregister(struct radeon_bo *bo);\n#else\nstatic inline int radeon_mn_register(struct radeon_bo *bo, unsigned long addr)\n{\n\treturn -ENODEV;\n}\nstatic inline void radeon_mn_unregister(struct radeon_bo *bo) {}\n#endif\n\n \nvoid radeon_debugfs_fence_init(struct radeon_device *rdev);\nvoid radeon_gem_debugfs_init(struct radeon_device *rdev);\n\n \nstruct radeon_asic_ring {\n\t \n\tu32 (*get_rptr)(struct radeon_device *rdev, struct radeon_ring *ring);\n\tu32 (*get_wptr)(struct radeon_device *rdev, struct radeon_ring *ring);\n\tvoid (*set_wptr)(struct radeon_device *rdev, struct radeon_ring *ring);\n\n\t \n\tint (*ib_parse)(struct radeon_device *rdev, struct radeon_ib *ib);\n\tint (*cs_parse)(struct radeon_cs_parser *p);\n\n\t \n\tvoid (*ib_execute)(struct radeon_device *rdev, struct radeon_ib *ib);\n\tvoid (*emit_fence)(struct radeon_device *rdev, struct radeon_fence *fence);\n\tvoid (*hdp_flush)(struct radeon_device *rdev, struct radeon_ring *ring);\n\tbool (*emit_semaphore)(struct radeon_device *rdev, struct radeon_ring *cp,\n\t\t\t       struct radeon_semaphore *semaphore, bool emit_wait);\n\tvoid (*vm_flush)(struct radeon_device *rdev, struct radeon_ring *ring,\n\t\t\t unsigned vm_id, uint64_t pd_addr);\n\n\t \n\tint (*ring_test)(struct radeon_device *rdev, struct radeon_ring *cp);\n\tint (*ib_test)(struct radeon_device *rdev, struct radeon_ring *cp);\n\tbool (*is_lockup)(struct radeon_device *rdev, struct radeon_ring *cp);\n\n\t \n\tvoid (*ring_start)(struct radeon_device *rdev, struct radeon_ring *cp);\n};\n\n \nstruct radeon_asic {\n\tint (*init)(struct radeon_device *rdev);\n\tvoid (*fini)(struct radeon_device *rdev);\n\tint (*resume)(struct radeon_device *rdev);\n\tint (*suspend)(struct radeon_device *rdev);\n\tvoid (*vga_set_state)(struct radeon_device *rdev, bool state);\n\tint (*asic_reset)(struct radeon_device *rdev, bool hard);\n\t \n\tvoid (*mmio_hdp_flush)(struct radeon_device *rdev);\n\t \n\tbool (*gui_idle)(struct radeon_device *rdev);\n\t \n\tint (*mc_wait_for_idle)(struct radeon_device *rdev);\n\t \n\tu32 (*get_xclk)(struct radeon_device *rdev);\n\t \n\tuint64_t (*get_gpu_clock_counter)(struct radeon_device *rdev);\n\t \n\tint (*get_allowed_info_register)(struct radeon_device *rdev, u32 reg, u32 *val);\n\t \n\tstruct {\n\t\tvoid (*tlb_flush)(struct radeon_device *rdev);\n\t\tuint64_t (*get_page_entry)(uint64_t addr, uint32_t flags);\n\t\tvoid (*set_page)(struct radeon_device *rdev, unsigned i,\n\t\t\t\t uint64_t entry);\n\t} gart;\n\tstruct {\n\t\tint (*init)(struct radeon_device *rdev);\n\t\tvoid (*fini)(struct radeon_device *rdev);\n\t\tvoid (*copy_pages)(struct radeon_device *rdev,\n\t\t\t\t   struct radeon_ib *ib,\n\t\t\t\t   uint64_t pe, uint64_t src,\n\t\t\t\t   unsigned count);\n\t\tvoid (*write_pages)(struct radeon_device *rdev,\n\t\t\t\t    struct radeon_ib *ib,\n\t\t\t\t    uint64_t pe,\n\t\t\t\t    uint64_t addr, unsigned count,\n\t\t\t\t    uint32_t incr, uint32_t flags);\n\t\tvoid (*set_pages)(struct radeon_device *rdev,\n\t\t\t\t  struct radeon_ib *ib,\n\t\t\t\t  uint64_t pe,\n\t\t\t\t  uint64_t addr, unsigned count,\n\t\t\t\t  uint32_t incr, uint32_t flags);\n\t\tvoid (*pad_ib)(struct radeon_ib *ib);\n\t} vm;\n\t \n\tconst struct radeon_asic_ring *ring[RADEON_NUM_RINGS];\n\t \n\tstruct {\n\t\tint (*set)(struct radeon_device *rdev);\n\t\tint (*process)(struct radeon_device *rdev);\n\t} irq;\n\t \n\tstruct {\n\t\t \n\t\tvoid (*bandwidth_update)(struct radeon_device *rdev);\n\t\t \n\t\tu32 (*get_vblank_counter)(struct radeon_device *rdev, int crtc);\n\t\t \n\t\tvoid (*wait_for_vblank)(struct radeon_device *rdev, int crtc);\n\t\t \n\t\tvoid (*set_backlight_level)(struct radeon_encoder *radeon_encoder, u8 level);\n\t\t \n\t\tu8 (*get_backlight_level)(struct radeon_encoder *radeon_encoder);\n\t\t \n\t\tvoid (*hdmi_enable)(struct drm_encoder *encoder, bool enable);\n\t\tvoid (*hdmi_setmode)(struct drm_encoder *encoder, struct drm_display_mode *mode);\n\t} display;\n\t \n\tstruct {\n\t\tstruct radeon_fence *(*blit)(struct radeon_device *rdev,\n\t\t\t\t\t     uint64_t src_offset,\n\t\t\t\t\t     uint64_t dst_offset,\n\t\t\t\t\t     unsigned num_gpu_pages,\n\t\t\t\t\t     struct dma_resv *resv);\n\t\tu32 blit_ring_index;\n\t\tstruct radeon_fence *(*dma)(struct radeon_device *rdev,\n\t\t\t\t\t    uint64_t src_offset,\n\t\t\t\t\t    uint64_t dst_offset,\n\t\t\t\t\t    unsigned num_gpu_pages,\n\t\t\t\t\t    struct dma_resv *resv);\n\t\tu32 dma_ring_index;\n\t\t \n\t\tstruct radeon_fence *(*copy)(struct radeon_device *rdev,\n\t\t\t\t\t     uint64_t src_offset,\n\t\t\t\t\t     uint64_t dst_offset,\n\t\t\t\t\t     unsigned num_gpu_pages,\n\t\t\t\t\t     struct dma_resv *resv);\n\t\t \n\t\tu32 copy_ring_index;\n\t} copy;\n\t \n\tstruct {\n\t\tint (*set_reg)(struct radeon_device *rdev, int reg,\n\t\t\t\t       uint32_t tiling_flags, uint32_t pitch,\n\t\t\t\t       uint32_t offset, uint32_t obj_size);\n\t\tvoid (*clear_reg)(struct radeon_device *rdev, int reg);\n\t} surface;\n\t \n\tstruct {\n\t\tvoid (*init)(struct radeon_device *rdev);\n\t\tvoid (*fini)(struct radeon_device *rdev);\n\t\tbool (*sense)(struct radeon_device *rdev, enum radeon_hpd_id hpd);\n\t\tvoid (*set_polarity)(struct radeon_device *rdev, enum radeon_hpd_id hpd);\n\t} hpd;\n\t \n\tstruct {\n\t\tvoid (*misc)(struct radeon_device *rdev);\n\t\tvoid (*prepare)(struct radeon_device *rdev);\n\t\tvoid (*finish)(struct radeon_device *rdev);\n\t\tvoid (*init_profile)(struct radeon_device *rdev);\n\t\tvoid (*get_dynpm_state)(struct radeon_device *rdev);\n\t\tuint32_t (*get_engine_clock)(struct radeon_device *rdev);\n\t\tvoid (*set_engine_clock)(struct radeon_device *rdev, uint32_t eng_clock);\n\t\tuint32_t (*get_memory_clock)(struct radeon_device *rdev);\n\t\tvoid (*set_memory_clock)(struct radeon_device *rdev, uint32_t mem_clock);\n\t\tint (*get_pcie_lanes)(struct radeon_device *rdev);\n\t\tvoid (*set_pcie_lanes)(struct radeon_device *rdev, int lanes);\n\t\tvoid (*set_clock_gating)(struct radeon_device *rdev, int enable);\n\t\tint (*set_uvd_clocks)(struct radeon_device *rdev, u32 vclk, u32 dclk);\n\t\tint (*set_vce_clocks)(struct radeon_device *rdev, u32 evclk, u32 ecclk);\n\t\tint (*get_temperature)(struct radeon_device *rdev);\n\t} pm;\n\t \n\tstruct {\n\t\tint (*init)(struct radeon_device *rdev);\n\t\tvoid (*setup_asic)(struct radeon_device *rdev);\n\t\tint (*enable)(struct radeon_device *rdev);\n\t\tint (*late_enable)(struct radeon_device *rdev);\n\t\tvoid (*disable)(struct radeon_device *rdev);\n\t\tint (*pre_set_power_state)(struct radeon_device *rdev);\n\t\tint (*set_power_state)(struct radeon_device *rdev);\n\t\tvoid (*post_set_power_state)(struct radeon_device *rdev);\n\t\tvoid (*display_configuration_changed)(struct radeon_device *rdev);\n\t\tvoid (*fini)(struct radeon_device *rdev);\n\t\tu32 (*get_sclk)(struct radeon_device *rdev, bool low);\n\t\tu32 (*get_mclk)(struct radeon_device *rdev, bool low);\n\t\tvoid (*print_power_state)(struct radeon_device *rdev, struct radeon_ps *ps);\n\t\tvoid (*debugfs_print_current_performance_level)(struct radeon_device *rdev, struct seq_file *m);\n\t\tint (*force_performance_level)(struct radeon_device *rdev, enum radeon_dpm_forced_level level);\n\t\tbool (*vblank_too_short)(struct radeon_device *rdev);\n\t\tvoid (*powergate_uvd)(struct radeon_device *rdev, bool gate);\n\t\tvoid (*enable_bapm)(struct radeon_device *rdev, bool enable);\n\t\tvoid (*fan_ctrl_set_mode)(struct radeon_device *rdev, u32 mode);\n\t\tu32 (*fan_ctrl_get_mode)(struct radeon_device *rdev);\n\t\tint (*set_fan_speed_percent)(struct radeon_device *rdev, u32 speed);\n\t\tint (*get_fan_speed_percent)(struct radeon_device *rdev, u32 *speed);\n\t\tu32 (*get_current_sclk)(struct radeon_device *rdev);\n\t\tu32 (*get_current_mclk)(struct radeon_device *rdev);\n\t\tu16 (*get_current_vddc)(struct radeon_device *rdev);\n\t} dpm;\n\t \n\tstruct {\n\t\tvoid (*page_flip)(struct radeon_device *rdev, int crtc, u64 crtc_base, bool async);\n\t\tbool (*page_flip_pending)(struct radeon_device *rdev, int crtc);\n\t} pflip;\n};\n\n \nstruct r100_asic {\n\tconst unsigned\t\t*reg_safe_bm;\n\tunsigned\t\treg_safe_bm_size;\n\tu32\t\t\thdp_cntl;\n};\n\nstruct r300_asic {\n\tconst unsigned\t\t*reg_safe_bm;\n\tunsigned\t\treg_safe_bm_size;\n\tu32\t\t\tresync_scratch;\n\tu32\t\t\thdp_cntl;\n};\n\nstruct r600_asic {\n\tunsigned\t\tmax_pipes;\n\tunsigned\t\tmax_tile_pipes;\n\tunsigned\t\tmax_simds;\n\tunsigned\t\tmax_backends;\n\tunsigned\t\tmax_gprs;\n\tunsigned\t\tmax_threads;\n\tunsigned\t\tmax_stack_entries;\n\tunsigned\t\tmax_hw_contexts;\n\tunsigned\t\tmax_gs_threads;\n\tunsigned\t\tsx_max_export_size;\n\tunsigned\t\tsx_max_export_pos_size;\n\tunsigned\t\tsx_max_export_smx_size;\n\tunsigned\t\tsq_num_cf_insts;\n\tunsigned\t\ttiling_nbanks;\n\tunsigned\t\ttiling_npipes;\n\tunsigned\t\ttiling_group_size;\n\tunsigned\t\ttile_config;\n\tunsigned\t\tbackend_map;\n\tunsigned\t\tactive_simds;\n};\n\nstruct rv770_asic {\n\tunsigned\t\tmax_pipes;\n\tunsigned\t\tmax_tile_pipes;\n\tunsigned\t\tmax_simds;\n\tunsigned\t\tmax_backends;\n\tunsigned\t\tmax_gprs;\n\tunsigned\t\tmax_threads;\n\tunsigned\t\tmax_stack_entries;\n\tunsigned\t\tmax_hw_contexts;\n\tunsigned\t\tmax_gs_threads;\n\tunsigned\t\tsx_max_export_size;\n\tunsigned\t\tsx_max_export_pos_size;\n\tunsigned\t\tsx_max_export_smx_size;\n\tunsigned\t\tsq_num_cf_insts;\n\tunsigned\t\tsx_num_of_sets;\n\tunsigned\t\tsc_prim_fifo_size;\n\tunsigned\t\tsc_hiz_tile_fifo_size;\n\tunsigned\t\tsc_earlyz_tile_fifo_fize;\n\tunsigned\t\ttiling_nbanks;\n\tunsigned\t\ttiling_npipes;\n\tunsigned\t\ttiling_group_size;\n\tunsigned\t\ttile_config;\n\tunsigned\t\tbackend_map;\n\tunsigned\t\tactive_simds;\n};\n\nstruct evergreen_asic {\n\tunsigned num_ses;\n\tunsigned max_pipes;\n\tunsigned max_tile_pipes;\n\tunsigned max_simds;\n\tunsigned max_backends;\n\tunsigned max_gprs;\n\tunsigned max_threads;\n\tunsigned max_stack_entries;\n\tunsigned max_hw_contexts;\n\tunsigned max_gs_threads;\n\tunsigned sx_max_export_size;\n\tunsigned sx_max_export_pos_size;\n\tunsigned sx_max_export_smx_size;\n\tunsigned sq_num_cf_insts;\n\tunsigned sx_num_of_sets;\n\tunsigned sc_prim_fifo_size;\n\tunsigned sc_hiz_tile_fifo_size;\n\tunsigned sc_earlyz_tile_fifo_size;\n\tunsigned tiling_nbanks;\n\tunsigned tiling_npipes;\n\tunsigned tiling_group_size;\n\tunsigned tile_config;\n\tunsigned backend_map;\n\tunsigned active_simds;\n};\n\nstruct cayman_asic {\n\tunsigned max_shader_engines;\n\tunsigned max_pipes_per_simd;\n\tunsigned max_tile_pipes;\n\tunsigned max_simds_per_se;\n\tunsigned max_backends_per_se;\n\tunsigned max_texture_channel_caches;\n\tunsigned max_gprs;\n\tunsigned max_threads;\n\tunsigned max_gs_threads;\n\tunsigned max_stack_entries;\n\tunsigned sx_num_of_sets;\n\tunsigned sx_max_export_size;\n\tunsigned sx_max_export_pos_size;\n\tunsigned sx_max_export_smx_size;\n\tunsigned max_hw_contexts;\n\tunsigned sq_num_cf_insts;\n\tunsigned sc_prim_fifo_size;\n\tunsigned sc_hiz_tile_fifo_size;\n\tunsigned sc_earlyz_tile_fifo_size;\n\n\tunsigned num_shader_engines;\n\tunsigned num_shader_pipes_per_simd;\n\tunsigned num_tile_pipes;\n\tunsigned num_simds_per_se;\n\tunsigned num_backends_per_se;\n\tunsigned backend_disable_mask_per_asic;\n\tunsigned backend_map;\n\tunsigned num_texture_channel_caches;\n\tunsigned mem_max_burst_length_bytes;\n\tunsigned mem_row_size_in_kb;\n\tunsigned shader_engine_tile_size;\n\tunsigned num_gpus;\n\tunsigned multi_gpu_tile_size;\n\n\tunsigned tile_config;\n\tunsigned active_simds;\n};\n\nstruct si_asic {\n\tunsigned max_shader_engines;\n\tunsigned max_tile_pipes;\n\tunsigned max_cu_per_sh;\n\tunsigned max_sh_per_se;\n\tunsigned max_backends_per_se;\n\tunsigned max_texture_channel_caches;\n\tunsigned max_gprs;\n\tunsigned max_gs_threads;\n\tunsigned max_hw_contexts;\n\tunsigned sc_prim_fifo_size_frontend;\n\tunsigned sc_prim_fifo_size_backend;\n\tunsigned sc_hiz_tile_fifo_size;\n\tunsigned sc_earlyz_tile_fifo_size;\n\n\tunsigned num_tile_pipes;\n\tunsigned backend_enable_mask;\n\tunsigned backend_disable_mask_per_asic;\n\tunsigned backend_map;\n\tunsigned num_texture_channel_caches;\n\tunsigned mem_max_burst_length_bytes;\n\tunsigned mem_row_size_in_kb;\n\tunsigned shader_engine_tile_size;\n\tunsigned num_gpus;\n\tunsigned multi_gpu_tile_size;\n\n\tunsigned tile_config;\n\tuint32_t tile_mode_array[32];\n\tuint32_t active_cus;\n};\n\nstruct cik_asic {\n\tunsigned max_shader_engines;\n\tunsigned max_tile_pipes;\n\tunsigned max_cu_per_sh;\n\tunsigned max_sh_per_se;\n\tunsigned max_backends_per_se;\n\tunsigned max_texture_channel_caches;\n\tunsigned max_gprs;\n\tunsigned max_gs_threads;\n\tunsigned max_hw_contexts;\n\tunsigned sc_prim_fifo_size_frontend;\n\tunsigned sc_prim_fifo_size_backend;\n\tunsigned sc_hiz_tile_fifo_size;\n\tunsigned sc_earlyz_tile_fifo_size;\n\n\tunsigned num_tile_pipes;\n\tunsigned backend_enable_mask;\n\tunsigned backend_disable_mask_per_asic;\n\tunsigned backend_map;\n\tunsigned num_texture_channel_caches;\n\tunsigned mem_max_burst_length_bytes;\n\tunsigned mem_row_size_in_kb;\n\tunsigned shader_engine_tile_size;\n\tunsigned num_gpus;\n\tunsigned multi_gpu_tile_size;\n\n\tunsigned tile_config;\n\tuint32_t tile_mode_array[32];\n\tuint32_t macrotile_mode_array[16];\n\tuint32_t active_cus;\n};\n\nunion radeon_asic_config {\n\tstruct r300_asic\tr300;\n\tstruct r100_asic\tr100;\n\tstruct r600_asic\tr600;\n\tstruct rv770_asic\trv770;\n\tstruct evergreen_asic\tevergreen;\n\tstruct cayman_asic\tcayman;\n\tstruct si_asic\t\tsi;\n\tstruct cik_asic\t\tcik;\n};\n\n \nvoid radeon_agp_disable(struct radeon_device *rdev);\nint radeon_asic_init(struct radeon_device *rdev);\n\n\n \nint radeon_gem_info_ioctl(struct drm_device *dev, void *data,\n\t\t\t  struct drm_file *filp);\nint radeon_gem_create_ioctl(struct drm_device *dev, void *data,\n\t\t\t    struct drm_file *filp);\nint radeon_gem_userptr_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *filp);\nint radeon_gem_pin_ioctl(struct drm_device *dev, void *data,\n\t\t\t struct drm_file *file_priv);\nint radeon_gem_unpin_ioctl(struct drm_device *dev, void *data,\n\t\t\t   struct drm_file *file_priv);\nint radeon_gem_set_domain_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *filp);\nint radeon_gem_mmap_ioctl(struct drm_device *dev, void *data,\n\t\t\t  struct drm_file *filp);\nint radeon_gem_busy_ioctl(struct drm_device *dev, void *data,\n\t\t\t  struct drm_file *filp);\nint radeon_gem_wait_idle_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *filp);\nint radeon_gem_va_ioctl(struct drm_device *dev, void *data,\n\t\t\t  struct drm_file *filp);\nint radeon_gem_op_ioctl(struct drm_device *dev, void *data,\n\t\t\tstruct drm_file *filp);\nint radeon_cs_ioctl(struct drm_device *dev, void *data, struct drm_file *filp);\nint radeon_gem_set_tiling_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *filp);\nint radeon_gem_get_tiling_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *filp);\nint radeon_info_ioctl(struct drm_device *dev, void *data, struct drm_file *filp);\n\n \nstruct r600_vram_scratch {\n\tstruct radeon_bo\t\t*robj;\n\tvolatile uint32_t\t\t*ptr;\n\tu64\t\t\t\tgpu_addr;\n};\n\n \nstruct radeon_atif_notification_cfg {\n\tbool enabled;\n\tint command_code;\n};\n\nstruct radeon_atif_notifications {\n\tbool display_switch;\n\tbool expansion_mode_change;\n\tbool thermal_state;\n\tbool forced_power_state;\n\tbool system_power_state;\n\tbool display_conf_change;\n\tbool px_gfx_switch;\n\tbool brightness_change;\n\tbool dgpu_display_event;\n};\n\nstruct radeon_atif_functions {\n\tbool system_params;\n\tbool sbios_requests;\n\tbool select_active_disp;\n\tbool lid_state;\n\tbool get_tv_standard;\n\tbool set_tv_standard;\n\tbool get_panel_expansion_mode;\n\tbool set_panel_expansion_mode;\n\tbool temperature_change;\n\tbool graphics_device_types;\n};\n\nstruct radeon_atif {\n\tstruct radeon_atif_notifications notifications;\n\tstruct radeon_atif_functions functions;\n\tstruct radeon_atif_notification_cfg notification_cfg;\n\tstruct radeon_encoder *encoder_for_bl;\n};\n\nstruct radeon_atcs_functions {\n\tbool get_ext_state;\n\tbool pcie_perf_req;\n\tbool pcie_dev_rdy;\n\tbool pcie_bus_width;\n};\n\nstruct radeon_atcs {\n\tstruct radeon_atcs_functions functions;\n};\n\n \ntypedef uint32_t (*radeon_rreg_t)(struct radeon_device*, uint32_t);\ntypedef void (*radeon_wreg_t)(struct radeon_device*, uint32_t, uint32_t);\n\nstruct radeon_device {\n\tstruct device\t\t\t*dev;\n\tstruct drm_device\t\t*ddev;\n\tstruct pci_dev\t\t\t*pdev;\n#ifdef __alpha__\n\tstruct pci_controller\t\t*hose;\n#endif\n\tstruct radeon_agp_head\t\t*agp;\n\tstruct rw_semaphore\t\texclusive_lock;\n\t \n\tunion radeon_asic_config\tconfig;\n\tenum radeon_family\t\tfamily;\n\tunsigned long\t\t\tflags;\n\tint\t\t\t\tusec_timeout;\n\tenum radeon_pll_errata\t\tpll_errata;\n\tint\t\t\t\tnum_gb_pipes;\n\tint\t\t\t\tnum_z_pipes;\n\tint\t\t\t\tdisp_priority;\n\t \n\tuint8_t\t\t\t\t*bios;\n\tbool\t\t\t\tis_atom_bios;\n\tuint16_t\t\t\tbios_header_start;\n\tstruct radeon_bo\t\t*stolen_vga_memory;\n\t \n\tresource_size_t\t\t\trmmio_base;\n\tresource_size_t\t\t\trmmio_size;\n\t \n\tspinlock_t mmio_idx_lock;\n\t \n\tspinlock_t smc_idx_lock;\n\t \n\tspinlock_t pll_idx_lock;\n\t \n\tspinlock_t mc_idx_lock;\n\t \n\tspinlock_t pcie_idx_lock;\n\t \n\tspinlock_t pciep_idx_lock;\n\t \n\tspinlock_t pif_idx_lock;\n\t \n\tspinlock_t cg_idx_lock;\n\t \n\tspinlock_t uvd_idx_lock;\n\t \n\tspinlock_t rcu_idx_lock;\n\t \n\tspinlock_t didt_idx_lock;\n\t \n\tspinlock_t end_idx_lock;\n\tvoid __iomem\t\t\t*rmmio;\n\tradeon_rreg_t\t\t\tmc_rreg;\n\tradeon_wreg_t\t\t\tmc_wreg;\n\tradeon_rreg_t\t\t\tpll_rreg;\n\tradeon_wreg_t\t\t\tpll_wreg;\n\tuint32_t                        pcie_reg_mask;\n\tradeon_rreg_t\t\t\tpciep_rreg;\n\tradeon_wreg_t\t\t\tpciep_wreg;\n\t \n\tvoid __iomem                    *rio_mem;\n\tresource_size_t\t\t\trio_mem_size;\n\tstruct radeon_clock             clock;\n\tstruct radeon_mc\t\tmc;\n\tstruct radeon_gart\t\tgart;\n\tstruct radeon_mode_info\t\tmode_info;\n\tstruct radeon_scratch\t\tscratch;\n\tstruct radeon_doorbell\t\tdoorbell;\n\tstruct radeon_mman\t\tmman;\n\tstruct radeon_fence_driver\tfence_drv[RADEON_NUM_RINGS];\n\twait_queue_head_t\t\tfence_queue;\n\tu64\t\t\t\tfence_context;\n\tstruct mutex\t\t\tring_lock;\n\tstruct radeon_ring\t\tring[RADEON_NUM_RINGS];\n\tbool\t\t\t\tib_pool_ready;\n\tstruct radeon_sa_manager\tring_tmp_bo;\n\tstruct radeon_irq\t\tirq;\n\tstruct radeon_asic\t\t*asic;\n\tstruct radeon_gem\t\tgem;\n\tstruct radeon_pm\t\tpm;\n\tstruct radeon_uvd\t\tuvd;\n\tstruct radeon_vce\t\tvce;\n\tuint32_t\t\t\tbios_scratch[RADEON_BIOS_NUM_SCRATCH];\n\tstruct radeon_wb\t\twb;\n\tstruct radeon_dummy_page\tdummy_page;\n\tbool\t\t\t\tshutdown;\n\tbool\t\t\t\tneed_swiotlb;\n\tbool\t\t\t\taccel_working;\n\tbool\t\t\t\tfastfb_working;  \n\tbool\t\t\t\tneeds_reset, in_reset;\n\tstruct radeon_surface_reg surface_regs[RADEON_GEM_MAX_SURFACES];\n\tconst struct firmware *me_fw;\t \n\tconst struct firmware *pfp_fw;\t \n\tconst struct firmware *rlc_fw;\t \n\tconst struct firmware *mc_fw;\t \n\tconst struct firmware *ce_fw;\t \n\tconst struct firmware *mec_fw;\t \n\tconst struct firmware *mec2_fw;\t \n\tconst struct firmware *sdma_fw;\t \n\tconst struct firmware *smc_fw;\t \n\tconst struct firmware *uvd_fw;\t \n\tconst struct firmware *vce_fw;\t \n\tbool new_fw;\n\tstruct r600_vram_scratch vram_scratch;\n\tint msi_enabled;  \n\tstruct r600_ih ih;  \n\tstruct radeon_rlc rlc;\n\tstruct radeon_mec mec;\n\tstruct delayed_work hotplug_work;\n\tstruct work_struct dp_work;\n\tstruct work_struct audio_work;\n\tint num_crtc;  \n\tstruct mutex dc_hw_i2c_mutex;  \n\tbool has_uvd;\n\tbool has_vce;\n\tstruct r600_audio audio;  \n\tstruct notifier_block acpi_nb;\n\t \n\tstruct drm_file *hyperz_filp;\n\tstruct drm_file *cmask_filp;\n\t \n\tstruct radeon_i2c_chan *i2c_bus[RADEON_MAX_I2C_BUS];\n\t \n\tstruct radeon_vm_manager\tvm_manager;\n\tstruct mutex\t\t\tgpu_clock_mutex;\n\t \n\tatomic64_t\t\t\tnum_bytes_moved;\n\tatomic_t\t\t\tgpu_reset_counter;\n\t \n\tstruct radeon_atif\t\tatif;\n\tstruct radeon_atcs\t\tatcs;\n\t \n\tstruct mutex\t\t\tsrbm_mutex;\n\t \n\tu32 cg_flags;\n\tu32 pg_flags;\n\n\tstruct dev_pm_domain vga_pm_domain;\n\tbool have_disp_power_ref;\n\tu32 px_quirk_flags;\n\n\t \n\tu64 vram_pin_size;\n\tu64 gart_pin_size;\n};\n\nbool radeon_is_px(struct drm_device *dev);\nint radeon_device_init(struct radeon_device *rdev,\n\t\t       struct drm_device *ddev,\n\t\t       struct pci_dev *pdev,\n\t\t       uint32_t flags);\nvoid radeon_device_fini(struct radeon_device *rdev);\nint radeon_gpu_wait_for_idle(struct radeon_device *rdev);\n\n#define RADEON_MIN_MMIO_SIZE 0x10000\n\nuint32_t r100_mm_rreg_slow(struct radeon_device *rdev, uint32_t reg);\nvoid r100_mm_wreg_slow(struct radeon_device *rdev, uint32_t reg, uint32_t v);\nstatic inline uint32_t r100_mm_rreg(struct radeon_device *rdev, uint32_t reg,\n\t\t\t\t    bool always_indirect)\n{\n\t \n\tif ((reg < rdev->rmmio_size || reg < RADEON_MIN_MMIO_SIZE) && !always_indirect)\n\t\treturn readl(((void __iomem *)rdev->rmmio) + reg);\n\telse\n\t\treturn r100_mm_rreg_slow(rdev, reg);\n}\nstatic inline void r100_mm_wreg(struct radeon_device *rdev, uint32_t reg, uint32_t v,\n\t\t\t\tbool always_indirect)\n{\n\tif ((reg < rdev->rmmio_size || reg < RADEON_MIN_MMIO_SIZE) && !always_indirect)\n\t\twritel(v, ((void __iomem *)rdev->rmmio) + reg);\n\telse\n\t\tr100_mm_wreg_slow(rdev, reg, v);\n}\n\nu32 r100_io_rreg(struct radeon_device *rdev, u32 reg);\nvoid r100_io_wreg(struct radeon_device *rdev, u32 reg, u32 v);\n\nu32 cik_mm_rdoorbell(struct radeon_device *rdev, u32 index);\nvoid cik_mm_wdoorbell(struct radeon_device *rdev, u32 index, u32 v);\n\n \nextern const struct dma_fence_ops radeon_fence_ops;\n\nstatic inline struct radeon_fence *to_radeon_fence(struct dma_fence *f)\n{\n\tstruct radeon_fence *__f = container_of(f, struct radeon_fence, base);\n\n\tif (__f->base.ops == &radeon_fence_ops)\n\t\treturn __f;\n\n\treturn NULL;\n}\n\n \n#define RREG8(reg) readb((rdev->rmmio) + (reg))\n#define WREG8(reg, v) writeb(v, (rdev->rmmio) + (reg))\n#define RREG16(reg) readw((rdev->rmmio) + (reg))\n#define WREG16(reg, v) writew(v, (rdev->rmmio) + (reg))\n#define RREG32(reg) r100_mm_rreg(rdev, (reg), false)\n#define RREG32_IDX(reg) r100_mm_rreg(rdev, (reg), true)\n#define DREG32(reg) pr_info(\"REGISTER: \" #reg \" : 0x%08X\\n\",\t\\\n\t\t\t    r100_mm_rreg(rdev, (reg), false))\n#define WREG32(reg, v) r100_mm_wreg(rdev, (reg), (v), false)\n#define WREG32_IDX(reg, v) r100_mm_wreg(rdev, (reg), (v), true)\n#define REG_SET(FIELD, v) (((v) << FIELD##_SHIFT) & FIELD##_MASK)\n#define REG_GET(FIELD, v) (((v) << FIELD##_SHIFT) & FIELD##_MASK)\n#define RREG32_PLL(reg) rdev->pll_rreg(rdev, (reg))\n#define WREG32_PLL(reg, v) rdev->pll_wreg(rdev, (reg), (v))\n#define RREG32_MC(reg) rdev->mc_rreg(rdev, (reg))\n#define WREG32_MC(reg, v) rdev->mc_wreg(rdev, (reg), (v))\n#define RREG32_PCIE(reg) rv370_pcie_rreg(rdev, (reg))\n#define WREG32_PCIE(reg, v) rv370_pcie_wreg(rdev, (reg), (v))\n#define RREG32_PCIE_PORT(reg) rdev->pciep_rreg(rdev, (reg))\n#define WREG32_PCIE_PORT(reg, v) rdev->pciep_wreg(rdev, (reg), (v))\n#define RREG32_SMC(reg) tn_smc_rreg(rdev, (reg))\n#define WREG32_SMC(reg, v) tn_smc_wreg(rdev, (reg), (v))\n#define RREG32_RCU(reg) r600_rcu_rreg(rdev, (reg))\n#define WREG32_RCU(reg, v) r600_rcu_wreg(rdev, (reg), (v))\n#define RREG32_CG(reg) eg_cg_rreg(rdev, (reg))\n#define WREG32_CG(reg, v) eg_cg_wreg(rdev, (reg), (v))\n#define RREG32_PIF_PHY0(reg) eg_pif_phy0_rreg(rdev, (reg))\n#define WREG32_PIF_PHY0(reg, v) eg_pif_phy0_wreg(rdev, (reg), (v))\n#define RREG32_PIF_PHY1(reg) eg_pif_phy1_rreg(rdev, (reg))\n#define WREG32_PIF_PHY1(reg, v) eg_pif_phy1_wreg(rdev, (reg), (v))\n#define RREG32_UVD_CTX(reg) r600_uvd_ctx_rreg(rdev, (reg))\n#define WREG32_UVD_CTX(reg, v) r600_uvd_ctx_wreg(rdev, (reg), (v))\n#define RREG32_DIDT(reg) cik_didt_rreg(rdev, (reg))\n#define WREG32_DIDT(reg, v) cik_didt_wreg(rdev, (reg), (v))\n#define WREG32_P(reg, val, mask)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tuint32_t tmp_ = RREG32(reg);\t\t\t\\\n\t\ttmp_ &= (mask);\t\t\t\t\t\\\n\t\ttmp_ |= ((val) & ~(mask));\t\t\t\\\n\t\tWREG32(reg, tmp_);\t\t\t\t\\\n\t} while (0)\n#define WREG32_AND(reg, and) WREG32_P(reg, 0, and)\n#define WREG32_OR(reg, or) WREG32_P(reg, or, ~(or))\n#define WREG32_PLL_P(reg, val, mask)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tuint32_t tmp_ = RREG32_PLL(reg);\t\t\\\n\t\ttmp_ &= (mask);\t\t\t\t\t\\\n\t\ttmp_ |= ((val) & ~(mask));\t\t\t\\\n\t\tWREG32_PLL(reg, tmp_);\t\t\t\t\\\n\t} while (0)\n#define WREG32_SMC_P(reg, val, mask)\t\t\t\t\\\n\tdo {\t\t\t\t\t\t\t\\\n\t\tuint32_t tmp_ = RREG32_SMC(reg);\t\t\\\n\t\ttmp_ &= (mask);\t\t\t\t\t\\\n\t\ttmp_ |= ((val) & ~(mask));\t\t\t\\\n\t\tWREG32_SMC(reg, tmp_);\t\t\t\t\\\n\t} while (0)\n#define DREG32_SYS(sqf, rdev, reg) seq_printf((sqf), #reg \" : 0x%08X\\n\", r100_mm_rreg((rdev), (reg), false))\n#define RREG32_IO(reg) r100_io_rreg(rdev, (reg))\n#define WREG32_IO(reg, v) r100_io_wreg(rdev, (reg), (v))\n\n#define RDOORBELL32(index) cik_mm_rdoorbell(rdev, (index))\n#define WDOORBELL32(index, v) cik_mm_wdoorbell(rdev, (index), (v))\n\n \nuint32_t rv370_pcie_rreg(struct radeon_device *rdev, uint32_t reg);\nvoid rv370_pcie_wreg(struct radeon_device *rdev, uint32_t reg, uint32_t v);\nu32 tn_smc_rreg(struct radeon_device *rdev, u32 reg);\nvoid tn_smc_wreg(struct radeon_device *rdev, u32 reg, u32 v);\nu32 r600_rcu_rreg(struct radeon_device *rdev, u32 reg);\nvoid r600_rcu_wreg(struct radeon_device *rdev, u32 reg, u32 v);\nu32 eg_cg_rreg(struct radeon_device *rdev, u32 reg);\nvoid eg_cg_wreg(struct radeon_device *rdev, u32 reg, u32 v);\nu32 eg_pif_phy0_rreg(struct radeon_device *rdev, u32 reg);\nvoid eg_pif_phy0_wreg(struct radeon_device *rdev, u32 reg, u32 v);\nu32 eg_pif_phy1_rreg(struct radeon_device *rdev, u32 reg);\nvoid eg_pif_phy1_wreg(struct radeon_device *rdev, u32 reg, u32 v);\nu32 r600_uvd_ctx_rreg(struct radeon_device *rdev, u32 reg);\nvoid r600_uvd_ctx_wreg(struct radeon_device *rdev, u32 reg, u32 v);\nu32 cik_didt_rreg(struct radeon_device *rdev, u32 reg);\nvoid cik_didt_wreg(struct radeon_device *rdev, u32 reg, u32 v);\n\nvoid r100_pll_errata_after_index(struct radeon_device *rdev);\n\n\n \n#define ASIC_IS_RN50(rdev) ((rdev->pdev->device == 0x515e) || \\\n\t\t\t    (rdev->pdev->device == 0x5969))\n#define ASIC_IS_RV100(rdev) ((rdev->family == CHIP_RV100) || \\\n\t\t(rdev->family == CHIP_RV200) || \\\n\t\t(rdev->family == CHIP_RS100) || \\\n\t\t(rdev->family == CHIP_RS200) || \\\n\t\t(rdev->family == CHIP_RV250) || \\\n\t\t(rdev->family == CHIP_RV280) || \\\n\t\t(rdev->family == CHIP_RS300))\n#define ASIC_IS_R300(rdev) ((rdev->family == CHIP_R300)  ||\t\\\n\t\t(rdev->family == CHIP_RV350) ||\t\t\t\\\n\t\t(rdev->family == CHIP_R350)  ||\t\t\t\\\n\t\t(rdev->family == CHIP_RV380) ||\t\t\t\\\n\t\t(rdev->family == CHIP_R420)  ||\t\t\t\\\n\t\t(rdev->family == CHIP_R423)  ||\t\t\t\\\n\t\t(rdev->family == CHIP_RV410) ||\t\t\t\\\n\t\t(rdev->family == CHIP_RS400) ||\t\t\t\\\n\t\t(rdev->family == CHIP_RS480))\n#define ASIC_IS_X2(rdev) ((rdev->pdev->device == 0x9441) || \\\n\t\t(rdev->pdev->device == 0x9443) || \\\n\t\t(rdev->pdev->device == 0x944B) || \\\n\t\t(rdev->pdev->device == 0x9506) || \\\n\t\t(rdev->pdev->device == 0x9509) || \\\n\t\t(rdev->pdev->device == 0x950F) || \\\n\t\t(rdev->pdev->device == 0x689C) || \\\n\t\t(rdev->pdev->device == 0x689D))\n#define ASIC_IS_AVIVO(rdev) ((rdev->family >= CHIP_RS600))\n#define ASIC_IS_DCE2(rdev) ((rdev->family == CHIP_RS600)  ||\t\\\n\t\t\t    (rdev->family == CHIP_RS690)  ||\t\\\n\t\t\t    (rdev->family == CHIP_RS740)  ||\t\\\n\t\t\t    (rdev->family >= CHIP_R600))\n#define ASIC_IS_DCE3(rdev) ((rdev->family >= CHIP_RV620))\n#define ASIC_IS_DCE32(rdev) ((rdev->family >= CHIP_RV730))\n#define ASIC_IS_DCE4(rdev) ((rdev->family >= CHIP_CEDAR))\n#define ASIC_IS_DCE41(rdev) ((rdev->family >= CHIP_PALM) && \\\n\t\t\t     (rdev->flags & RADEON_IS_IGP))\n#define ASIC_IS_DCE5(rdev) ((rdev->family >= CHIP_BARTS))\n#define ASIC_IS_DCE6(rdev) ((rdev->family >= CHIP_ARUBA))\n#define ASIC_IS_DCE61(rdev) ((rdev->family >= CHIP_ARUBA) && \\\n\t\t\t     (rdev->flags & RADEON_IS_IGP))\n#define ASIC_IS_DCE64(rdev) ((rdev->family == CHIP_OLAND))\n#define ASIC_IS_NODCE(rdev) ((rdev->family == CHIP_HAINAN))\n#define ASIC_IS_DCE8(rdev) ((rdev->family >= CHIP_BONAIRE))\n#define ASIC_IS_DCE81(rdev) ((rdev->family == CHIP_KAVERI))\n#define ASIC_IS_DCE82(rdev) ((rdev->family == CHIP_BONAIRE))\n#define ASIC_IS_DCE83(rdev) ((rdev->family == CHIP_KABINI) || \\\n\t\t\t     (rdev->family == CHIP_MULLINS))\n\n#define ASIC_IS_LOMBOK(rdev) ((rdev->pdev->device == 0x6849) || \\\n\t\t\t      (rdev->pdev->device == 0x6850) || \\\n\t\t\t      (rdev->pdev->device == 0x6858) || \\\n\t\t\t      (rdev->pdev->device == 0x6859) || \\\n\t\t\t      (rdev->pdev->device == 0x6840) || \\\n\t\t\t      (rdev->pdev->device == 0x6841) || \\\n\t\t\t      (rdev->pdev->device == 0x6842) || \\\n\t\t\t      (rdev->pdev->device == 0x6843))\n\n \n#define RBIOS8(i) (rdev->bios[i])\n#define RBIOS16(i) (RBIOS8(i) | (RBIOS8((i)+1) << 8))\n#define RBIOS32(i) ((RBIOS16(i)) | (RBIOS16((i)+2) << 16))\n\nint radeon_combios_init(struct radeon_device *rdev);\nvoid radeon_combios_fini(struct radeon_device *rdev);\nint radeon_atombios_init(struct radeon_device *rdev);\nvoid radeon_atombios_fini(struct radeon_device *rdev);\n\n\n \n\n \nstatic inline void radeon_ring_write(struct radeon_ring *ring, uint32_t v)\n{\n\tif (ring->count_dw <= 0)\n\t\tDRM_ERROR(\"radeon: writing more dwords to the ring than expected!\\n\");\n\n\tring->ring[ring->wptr++] = v;\n\tring->wptr &= ring->ptr_mask;\n\tring->count_dw--;\n\tring->ring_free_dw--;\n}\n\n \n#define radeon_init(rdev) (rdev)->asic->init((rdev))\n#define radeon_fini(rdev) (rdev)->asic->fini((rdev))\n#define radeon_resume(rdev) (rdev)->asic->resume((rdev))\n#define radeon_suspend(rdev) (rdev)->asic->suspend((rdev))\n#define radeon_cs_parse(rdev, r, p) (rdev)->asic->ring[(r)]->cs_parse((p))\n#define radeon_vga_set_state(rdev, state) (rdev)->asic->vga_set_state((rdev), (state))\n#define radeon_asic_reset(rdev) (rdev)->asic->asic_reset((rdev), false)\n#define radeon_gart_tlb_flush(rdev) (rdev)->asic->gart.tlb_flush((rdev))\n#define radeon_gart_get_page_entry(a, f) (rdev)->asic->gart.get_page_entry((a), (f))\n#define radeon_gart_set_page(rdev, i, e) (rdev)->asic->gart.set_page((rdev), (i), (e))\n#define radeon_asic_vm_init(rdev) (rdev)->asic->vm.init((rdev))\n#define radeon_asic_vm_fini(rdev) (rdev)->asic->vm.fini((rdev))\n#define radeon_asic_vm_copy_pages(rdev, ib, pe, src, count) ((rdev)->asic->vm.copy_pages((rdev), (ib), (pe), (src), (count)))\n#define radeon_asic_vm_write_pages(rdev, ib, pe, addr, count, incr, flags) ((rdev)->asic->vm.write_pages((rdev), (ib), (pe), (addr), (count), (incr), (flags)))\n#define radeon_asic_vm_set_pages(rdev, ib, pe, addr, count, incr, flags) ((rdev)->asic->vm.set_pages((rdev), (ib), (pe), (addr), (count), (incr), (flags)))\n#define radeon_asic_vm_pad_ib(rdev, ib) ((rdev)->asic->vm.pad_ib((ib)))\n#define radeon_ring_start(rdev, r, cp) (rdev)->asic->ring[(r)]->ring_start((rdev), (cp))\n#define radeon_ring_test(rdev, r, cp) (rdev)->asic->ring[(r)]->ring_test((rdev), (cp))\n#define radeon_ib_test(rdev, r, cp) (rdev)->asic->ring[(r)]->ib_test((rdev), (cp))\n#define radeon_ring_ib_execute(rdev, r, ib) (rdev)->asic->ring[(r)]->ib_execute((rdev), (ib))\n#define radeon_ring_ib_parse(rdev, r, ib) (rdev)->asic->ring[(r)]->ib_parse((rdev), (ib))\n#define radeon_ring_is_lockup(rdev, r, cp) (rdev)->asic->ring[(r)]->is_lockup((rdev), (cp))\n#define radeon_ring_vm_flush(rdev, r, vm_id, pd_addr) (rdev)->asic->ring[(r)->idx]->vm_flush((rdev), (r), (vm_id), (pd_addr))\n#define radeon_ring_get_rptr(rdev, r) (rdev)->asic->ring[(r)->idx]->get_rptr((rdev), (r))\n#define radeon_ring_get_wptr(rdev, r) (rdev)->asic->ring[(r)->idx]->get_wptr((rdev), (r))\n#define radeon_ring_set_wptr(rdev, r) (rdev)->asic->ring[(r)->idx]->set_wptr((rdev), (r))\n#define radeon_irq_set(rdev) (rdev)->asic->irq.set((rdev))\n#define radeon_irq_process(rdev) (rdev)->asic->irq.process((rdev))\n#define radeon_get_vblank_counter(rdev, crtc) (rdev)->asic->display.get_vblank_counter((rdev), (crtc))\n#define radeon_set_backlight_level(rdev, e, l) (rdev)->asic->display.set_backlight_level((e), (l))\n#define radeon_get_backlight_level(rdev, e) (rdev)->asic->display.get_backlight_level((e))\n#define radeon_hdmi_enable(rdev, e, b) (rdev)->asic->display.hdmi_enable((e), (b))\n#define radeon_hdmi_setmode(rdev, e, m) (rdev)->asic->display.hdmi_setmode((e), (m))\n#define radeon_fence_ring_emit(rdev, r, fence) (rdev)->asic->ring[(r)]->emit_fence((rdev), (fence))\n#define radeon_semaphore_ring_emit(rdev, r, cp, semaphore, emit_wait) (rdev)->asic->ring[(r)]->emit_semaphore((rdev), (cp), (semaphore), (emit_wait))\n#define radeon_copy_blit(rdev, s, d, np, resv) (rdev)->asic->copy.blit((rdev), (s), (d), (np), (resv))\n#define radeon_copy_dma(rdev, s, d, np, resv) (rdev)->asic->copy.dma((rdev), (s), (d), (np), (resv))\n#define radeon_copy(rdev, s, d, np, resv) (rdev)->asic->copy.copy((rdev), (s), (d), (np), (resv))\n#define radeon_copy_blit_ring_index(rdev) (rdev)->asic->copy.blit_ring_index\n#define radeon_copy_dma_ring_index(rdev) (rdev)->asic->copy.dma_ring_index\n#define radeon_copy_ring_index(rdev) (rdev)->asic->copy.copy_ring_index\n#define radeon_get_engine_clock(rdev) (rdev)->asic->pm.get_engine_clock((rdev))\n#define radeon_set_engine_clock(rdev, e) (rdev)->asic->pm.set_engine_clock((rdev), (e))\n#define radeon_get_memory_clock(rdev) (rdev)->asic->pm.get_memory_clock((rdev))\n#define radeon_set_memory_clock(rdev, e) (rdev)->asic->pm.set_memory_clock((rdev), (e))\n#define radeon_get_pcie_lanes(rdev) (rdev)->asic->pm.get_pcie_lanes((rdev))\n#define radeon_set_pcie_lanes(rdev, l) (rdev)->asic->pm.set_pcie_lanes((rdev), (l))\n#define radeon_set_clock_gating(rdev, e) (rdev)->asic->pm.set_clock_gating((rdev), (e))\n#define radeon_set_uvd_clocks(rdev, v, d) (rdev)->asic->pm.set_uvd_clocks((rdev), (v), (d))\n#define radeon_set_vce_clocks(rdev, ev, ec) (rdev)->asic->pm.set_vce_clocks((rdev), (ev), (ec))\n#define radeon_get_temperature(rdev) (rdev)->asic->pm.get_temperature((rdev))\n#define radeon_set_surface_reg(rdev, r, f, p, o, s) ((rdev)->asic->surface.set_reg((rdev), (r), (f), (p), (o), (s)))\n#define radeon_clear_surface_reg(rdev, r) ((rdev)->asic->surface.clear_reg((rdev), (r)))\n#define radeon_bandwidth_update(rdev) (rdev)->asic->display.bandwidth_update((rdev))\n#define radeon_hpd_init(rdev) (rdev)->asic->hpd.init((rdev))\n#define radeon_hpd_fini(rdev) (rdev)->asic->hpd.fini((rdev))\n#define radeon_hpd_sense(rdev, h) (rdev)->asic->hpd.sense((rdev), (h))\n#define radeon_hpd_set_polarity(rdev, h) (rdev)->asic->hpd.set_polarity((rdev), (h))\n#define radeon_gui_idle(rdev) (rdev)->asic->gui_idle((rdev))\n#define radeon_pm_misc(rdev) (rdev)->asic->pm.misc((rdev))\n#define radeon_pm_prepare(rdev) (rdev)->asic->pm.prepare((rdev))\n#define radeon_pm_finish(rdev) (rdev)->asic->pm.finish((rdev))\n#define radeon_pm_init_profile(rdev) (rdev)->asic->pm.init_profile((rdev))\n#define radeon_pm_get_dynpm_state(rdev) (rdev)->asic->pm.get_dynpm_state((rdev))\n#define radeon_page_flip(rdev, crtc, base, async) (rdev)->asic->pflip.page_flip((rdev), (crtc), (base), (async))\n#define radeon_page_flip_pending(rdev, crtc) (rdev)->asic->pflip.page_flip_pending((rdev), (crtc))\n#define radeon_wait_for_vblank(rdev, crtc) (rdev)->asic->display.wait_for_vblank((rdev), (crtc))\n#define radeon_mc_wait_for_idle(rdev) (rdev)->asic->mc_wait_for_idle((rdev))\n#define radeon_get_xclk(rdev) (rdev)->asic->get_xclk((rdev))\n#define radeon_get_gpu_clock_counter(rdev) (rdev)->asic->get_gpu_clock_counter((rdev))\n#define radeon_get_allowed_info_register(rdev, r, v) (rdev)->asic->get_allowed_info_register((rdev), (r), (v))\n#define radeon_dpm_init(rdev) rdev->asic->dpm.init((rdev))\n#define radeon_dpm_setup_asic(rdev) rdev->asic->dpm.setup_asic((rdev))\n#define radeon_dpm_enable(rdev) rdev->asic->dpm.enable((rdev))\n#define radeon_dpm_late_enable(rdev) rdev->asic->dpm.late_enable((rdev))\n#define radeon_dpm_disable(rdev) rdev->asic->dpm.disable((rdev))\n#define radeon_dpm_pre_set_power_state(rdev) rdev->asic->dpm.pre_set_power_state((rdev))\n#define radeon_dpm_set_power_state(rdev) rdev->asic->dpm.set_power_state((rdev))\n#define radeon_dpm_post_set_power_state(rdev) rdev->asic->dpm.post_set_power_state((rdev))\n#define radeon_dpm_display_configuration_changed(rdev) rdev->asic->dpm.display_configuration_changed((rdev))\n#define radeon_dpm_fini(rdev) rdev->asic->dpm.fini((rdev))\n#define radeon_dpm_get_sclk(rdev, l) rdev->asic->dpm.get_sclk((rdev), (l))\n#define radeon_dpm_get_mclk(rdev, l) rdev->asic->dpm.get_mclk((rdev), (l))\n#define radeon_dpm_print_power_state(rdev, ps) rdev->asic->dpm.print_power_state((rdev), (ps))\n#define radeon_dpm_debugfs_print_current_performance_level(rdev, m) rdev->asic->dpm.debugfs_print_current_performance_level((rdev), (m))\n#define radeon_dpm_force_performance_level(rdev, l) rdev->asic->dpm.force_performance_level((rdev), (l))\n#define radeon_dpm_vblank_too_short(rdev) rdev->asic->dpm.vblank_too_short((rdev))\n#define radeon_dpm_powergate_uvd(rdev, g) rdev->asic->dpm.powergate_uvd((rdev), (g))\n#define radeon_dpm_enable_bapm(rdev, e) rdev->asic->dpm.enable_bapm((rdev), (e))\n#define radeon_dpm_get_current_sclk(rdev) rdev->asic->dpm.get_current_sclk((rdev))\n#define radeon_dpm_get_current_mclk(rdev) rdev->asic->dpm.get_current_mclk((rdev))\n\n \n \nextern int radeon_gpu_reset(struct radeon_device *rdev);\nextern void radeon_pci_config_reset(struct radeon_device *rdev);\nextern void r600_set_bios_scratch_engine_hung(struct radeon_device *rdev, bool hung);\nextern void radeon_agp_disable(struct radeon_device *rdev);\nextern int radeon_modeset_init(struct radeon_device *rdev);\nextern void radeon_modeset_fini(struct radeon_device *rdev);\nextern bool radeon_card_posted(struct radeon_device *rdev);\nextern void radeon_update_bandwidth_info(struct radeon_device *rdev);\nextern void radeon_update_display_priority(struct radeon_device *rdev);\nextern bool radeon_boot_test_post_card(struct radeon_device *rdev);\nextern void radeon_scratch_init(struct radeon_device *rdev);\nextern void radeon_wb_fini(struct radeon_device *rdev);\nextern int radeon_wb_init(struct radeon_device *rdev);\nextern void radeon_wb_disable(struct radeon_device *rdev);\nextern void radeon_surface_init(struct radeon_device *rdev);\nextern int radeon_cs_parser_init(struct radeon_cs_parser *p, void *data);\nextern void radeon_legacy_set_clock_gating(struct radeon_device *rdev, int enable);\nextern void radeon_atom_set_clock_gating(struct radeon_device *rdev, int enable);\nextern void radeon_ttm_placement_from_domain(struct radeon_bo *rbo, u32 domain);\nextern bool radeon_ttm_bo_is_radeon_bo(struct ttm_buffer_object *bo);\nextern int radeon_ttm_tt_set_userptr(struct radeon_device *rdev,\n\t\t\t\t     struct ttm_tt *ttm, uint64_t addr,\n\t\t\t\t     uint32_t flags);\nextern bool radeon_ttm_tt_has_userptr(struct radeon_device *rdev, struct ttm_tt *ttm);\nextern bool radeon_ttm_tt_is_readonly(struct radeon_device *rdev, struct ttm_tt *ttm);\nbool radeon_ttm_tt_is_bound(struct ttm_device *bdev, struct ttm_tt *ttm);\nextern void radeon_vram_location(struct radeon_device *rdev, struct radeon_mc *mc, u64 base);\nextern void radeon_gtt_location(struct radeon_device *rdev, struct radeon_mc *mc);\nextern int radeon_resume_kms(struct drm_device *dev, bool resume, bool fbcon);\nextern int radeon_suspend_kms(struct drm_device *dev, bool suspend,\n\t\t\t      bool fbcon, bool freeze);\nextern void radeon_ttm_set_active_vram_size(struct radeon_device *rdev, u64 size);\nextern void radeon_program_register_sequence(struct radeon_device *rdev,\n\t\t\t\t\t     const u32 *registers,\n\t\t\t\t\t     const u32 array_size);\nstruct radeon_device *radeon_get_rdev(struct ttm_device *bdev);\n\n \n\nu32 radeon_get_vblank_counter_kms(struct drm_crtc *crtc);\nint radeon_enable_vblank_kms(struct drm_crtc *crtc);\nvoid radeon_disable_vblank_kms(struct drm_crtc *crtc);\n\n \nint radeon_vm_manager_init(struct radeon_device *rdev);\nvoid radeon_vm_manager_fini(struct radeon_device *rdev);\nint radeon_vm_init(struct radeon_device *rdev, struct radeon_vm *vm);\nvoid radeon_vm_fini(struct radeon_device *rdev, struct radeon_vm *vm);\nstruct radeon_bo_list *radeon_vm_get_bos(struct radeon_device *rdev,\n\t\t\t\t\t  struct radeon_vm *vm,\n                                          struct list_head *head);\nstruct radeon_fence *radeon_vm_grab_id(struct radeon_device *rdev,\n\t\t\t\t       struct radeon_vm *vm, int ring);\nvoid radeon_vm_flush(struct radeon_device *rdev,\n                     struct radeon_vm *vm,\n\t\t     int ring, struct radeon_fence *fence);\nvoid radeon_vm_fence(struct radeon_device *rdev,\n\t\t     struct radeon_vm *vm,\n\t\t     struct radeon_fence *fence);\nuint64_t radeon_vm_map_gart(struct radeon_device *rdev, uint64_t addr);\nint radeon_vm_update_page_directory(struct radeon_device *rdev,\n\t\t\t\t    struct radeon_vm *vm);\nint radeon_vm_clear_freed(struct radeon_device *rdev,\n\t\t\t  struct radeon_vm *vm);\nint radeon_vm_clear_invalids(struct radeon_device *rdev,\n\t\t\t     struct radeon_vm *vm);\nint radeon_vm_bo_update(struct radeon_device *rdev,\n\t\t\tstruct radeon_bo_va *bo_va,\n\t\t\tstruct ttm_resource *mem);\nvoid radeon_vm_bo_invalidate(struct radeon_device *rdev,\n\t\t\t     struct radeon_bo *bo);\nstruct radeon_bo_va *radeon_vm_bo_find(struct radeon_vm *vm,\n\t\t\t\t       struct radeon_bo *bo);\nstruct radeon_bo_va *radeon_vm_bo_add(struct radeon_device *rdev,\n\t\t\t\t      struct radeon_vm *vm,\n\t\t\t\t      struct radeon_bo *bo);\nint radeon_vm_bo_set_addr(struct radeon_device *rdev,\n\t\t\t  struct radeon_bo_va *bo_va,\n\t\t\t  uint64_t offset,\n\t\t\t  uint32_t flags);\nvoid radeon_vm_bo_rmv(struct radeon_device *rdev,\n\t\t      struct radeon_bo_va *bo_va);\n\n \nvoid r600_audio_update_hdmi(struct work_struct *work);\nstruct r600_audio_pin *r600_audio_get_pin(struct radeon_device *rdev);\nstruct r600_audio_pin *dce6_audio_get_pin(struct radeon_device *rdev);\nvoid r600_audio_enable(struct radeon_device *rdev,\n\t\t       struct r600_audio_pin *pin,\n\t\t       u8 enable_mask);\nvoid dce6_audio_enable(struct radeon_device *rdev,\n\t\t       struct r600_audio_pin *pin,\n\t\t       u8 enable_mask);\n\n \nint r600_vram_scratch_init(struct radeon_device *rdev);\nvoid r600_vram_scratch_fini(struct radeon_device *rdev);\n\n \nunsigned r600_mip_minify(unsigned size, unsigned level);\nbool r600_fmt_is_valid_color(u32 format);\nbool r600_fmt_is_valid_texture(u32 format, enum radeon_family family);\nint r600_fmt_get_blocksize(u32 format);\nint r600_fmt_get_nblocksx(u32 format, u32 w);\nint r600_fmt_get_nblocksy(u32 format, u32 h);\n\n \nstruct radeon_hdmi_acr {\n\tu32 clock;\n\n\tint n_32khz;\n\tint cts_32khz;\n\n\tint n_44_1khz;\n\tint cts_44_1khz;\n\n\tint n_48khz;\n\tint cts_48khz;\n\n};\n\nextern u32 r6xx_remap_render_backend(struct radeon_device *rdev,\n\t\t\t\t     u32 tiling_pipe_num,\n\t\t\t\t     u32 max_rb_num,\n\t\t\t\t     u32 total_max_rb_num,\n\t\t\t\t     u32 enabled_rb_mask);\n\n \n\nextern int ni_init_microcode(struct radeon_device *rdev);\nextern int ni_mc_load_microcode(struct radeon_device *rdev);\n\n \n#if defined(CONFIG_ACPI)\nextern int radeon_acpi_init(struct radeon_device *rdev);\nextern void radeon_acpi_fini(struct radeon_device *rdev);\nextern bool radeon_acpi_is_pcie_performance_request_supported(struct radeon_device *rdev);\nextern int radeon_acpi_pcie_performance_request(struct radeon_device *rdev,\n\t\t\t\t\t\tu8 perf_req, bool advertise);\nextern int radeon_acpi_pcie_notify_device_ready(struct radeon_device *rdev);\n#else\nstatic inline int radeon_acpi_init(struct radeon_device *rdev) { return 0; }\nstatic inline void radeon_acpi_fini(struct radeon_device *rdev) { }\n#endif\n\nint radeon_cs_packet_parse(struct radeon_cs_parser *p,\n\t\t\t   struct radeon_cs_packet *pkt,\n\t\t\t   unsigned idx);\nbool radeon_cs_packet_next_is_pkt3_nop(struct radeon_cs_parser *p);\nvoid radeon_cs_dump_packet(struct radeon_cs_parser *p,\n\t\t\t   struct radeon_cs_packet *pkt);\nint radeon_cs_packet_next_reloc(struct radeon_cs_parser *p,\n\t\t\t\tstruct radeon_bo_list **cs_reloc,\n\t\t\t\tint nomm);\nint r600_cs_common_vline_parse(struct radeon_cs_parser *p,\n\t\t\t       uint32_t *vline_start_end,\n\t\t\t       uint32_t *vline_status);\n\n \nvoid radeon_irq_kms_set_irq_n_enabled(struct radeon_device *rdev,\n\t\t\t\t      u32 reg, u32 mask,\n\t\t\t\t      bool enable, const char *name,\n\t\t\t\t      unsigned n);\n\n \nvoid radeon_audio_component_init(struct radeon_device *rdev);\nvoid radeon_audio_component_fini(struct radeon_device *rdev);\n\n#include \"radeon_object.h\"\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}