{
  "module_name": "r600_dpm.c",
  "hash_id": "797d27b6983edd963da2e4fea12f973447a2a97ac35cc18adf69149eaf61d965",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/radeon/r600_dpm.c",
  "human_readable_source": " \n\n#include \"radeon.h\"\n#include \"radeon_asic.h\"\n#include \"r600d.h\"\n#include \"r600_dpm.h\"\n#include \"atom.h\"\n\nconst u32 r600_utc[R600_PM_NUMBER_OF_TC] =\n{\n\tR600_UTC_DFLT_00,\n\tR600_UTC_DFLT_01,\n\tR600_UTC_DFLT_02,\n\tR600_UTC_DFLT_03,\n\tR600_UTC_DFLT_04,\n\tR600_UTC_DFLT_05,\n\tR600_UTC_DFLT_06,\n\tR600_UTC_DFLT_07,\n\tR600_UTC_DFLT_08,\n\tR600_UTC_DFLT_09,\n\tR600_UTC_DFLT_10,\n\tR600_UTC_DFLT_11,\n\tR600_UTC_DFLT_12,\n\tR600_UTC_DFLT_13,\n\tR600_UTC_DFLT_14,\n};\n\nconst u32 r600_dtc[R600_PM_NUMBER_OF_TC] =\n{\n\tR600_DTC_DFLT_00,\n\tR600_DTC_DFLT_01,\n\tR600_DTC_DFLT_02,\n\tR600_DTC_DFLT_03,\n\tR600_DTC_DFLT_04,\n\tR600_DTC_DFLT_05,\n\tR600_DTC_DFLT_06,\n\tR600_DTC_DFLT_07,\n\tR600_DTC_DFLT_08,\n\tR600_DTC_DFLT_09,\n\tR600_DTC_DFLT_10,\n\tR600_DTC_DFLT_11,\n\tR600_DTC_DFLT_12,\n\tR600_DTC_DFLT_13,\n\tR600_DTC_DFLT_14,\n};\n\nvoid r600_dpm_print_class_info(u32 class, u32 class2)\n{\n\tconst char *s;\n\n\tswitch (class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) {\n\tcase ATOM_PPLIB_CLASSIFICATION_UI_NONE:\n\tdefault:\n\t\ts = \"none\";\n\t\tbreak;\n\tcase ATOM_PPLIB_CLASSIFICATION_UI_BATTERY:\n\t\ts = \"battery\";\n\t\tbreak;\n\tcase ATOM_PPLIB_CLASSIFICATION_UI_BALANCED:\n\t\ts = \"balanced\";\n\t\tbreak;\n\tcase ATOM_PPLIB_CLASSIFICATION_UI_PERFORMANCE:\n\t\ts = \"performance\";\n\t\tbreak;\n\t}\n\tprintk(\"\\tui class: %s\\n\", s);\n\n\tprintk(\"\\tinternal class:\");\n\tif (((class & ~ATOM_PPLIB_CLASSIFICATION_UI_MASK) == 0) &&\n\t    (class2 == 0))\n\t\tpr_cont(\" none\");\n\telse {\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_BOOT)\n\t\t\tpr_cont(\" boot\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_THERMAL)\n\t\t\tpr_cont(\" thermal\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_LIMITEDPOWERSOURCE)\n\t\t\tpr_cont(\" limited_pwr\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_REST)\n\t\t\tpr_cont(\" rest\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_FORCED)\n\t\t\tpr_cont(\" forced\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_3DPERFORMANCE)\n\t\t\tpr_cont(\" 3d_perf\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_OVERDRIVETEMPLATE)\n\t\t\tpr_cont(\" ovrdrv\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_UVDSTATE)\n\t\t\tpr_cont(\" uvd\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_3DLOW)\n\t\t\tpr_cont(\" 3d_low\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_ACPI)\n\t\t\tpr_cont(\" acpi\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_HD2STATE)\n\t\t\tpr_cont(\" uvd_hd2\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_HDSTATE)\n\t\t\tpr_cont(\" uvd_hd\");\n\t\tif (class & ATOM_PPLIB_CLASSIFICATION_SDSTATE)\n\t\t\tpr_cont(\" uvd_sd\");\n\t\tif (class2 & ATOM_PPLIB_CLASSIFICATION2_LIMITEDPOWERSOURCE_2)\n\t\t\tpr_cont(\" limited_pwr2\");\n\t\tif (class2 & ATOM_PPLIB_CLASSIFICATION2_ULV)\n\t\t\tpr_cont(\" ulv\");\n\t\tif (class2 & ATOM_PPLIB_CLASSIFICATION2_MVC)\n\t\t\tpr_cont(\" uvd_mvc\");\n\t}\n\tpr_cont(\"\\n\");\n}\n\nvoid r600_dpm_print_cap_info(u32 caps)\n{\n\tprintk(\"\\tcaps:\");\n\tif (caps & ATOM_PPLIB_SINGLE_DISPLAY_ONLY)\n\t\tpr_cont(\" single_disp\");\n\tif (caps & ATOM_PPLIB_SUPPORTS_VIDEO_PLAYBACK)\n\t\tpr_cont(\" video\");\n\tif (caps & ATOM_PPLIB_DISALLOW_ON_DC)\n\t\tpr_cont(\" no_dc\");\n\tpr_cont(\"\\n\");\n}\n\nvoid r600_dpm_print_ps_status(struct radeon_device *rdev,\n\t\t\t      struct radeon_ps *rps)\n{\n\tprintk(\"\\tstatus:\");\n\tif (rps == rdev->pm.dpm.current_ps)\n\t\tpr_cont(\" c\");\n\tif (rps == rdev->pm.dpm.requested_ps)\n\t\tpr_cont(\" r\");\n\tif (rps == rdev->pm.dpm.boot_ps)\n\t\tpr_cont(\" b\");\n\tpr_cont(\"\\n\");\n}\n\nu32 r600_dpm_get_vblank_time(struct radeon_device *rdev)\n{\n\tstruct drm_device *dev = rdev->ddev;\n\tstruct drm_crtc *crtc;\n\tstruct radeon_crtc *radeon_crtc;\n\tu32 vblank_in_pixels;\n\tu32 vblank_time_us = 0xffffffff;  \n\n\tif (rdev->num_crtc && rdev->mode_info.mode_config_initialized) {\n\t\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\t\tradeon_crtc = to_radeon_crtc(crtc);\n\t\t\tif (crtc->enabled && radeon_crtc->enabled && radeon_crtc->hw_mode.clock) {\n\t\t\t\tvblank_in_pixels =\n\t\t\t\t\tradeon_crtc->hw_mode.crtc_htotal *\n\t\t\t\t\t(radeon_crtc->hw_mode.crtc_vblank_end -\n\t\t\t\t\t radeon_crtc->hw_mode.crtc_vdisplay +\n\t\t\t\t\t (radeon_crtc->v_border * 2));\n\n\t\t\t\tvblank_time_us = vblank_in_pixels * 1000 / radeon_crtc->hw_mode.clock;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn vblank_time_us;\n}\n\nu32 r600_dpm_get_vrefresh(struct radeon_device *rdev)\n{\n\tstruct drm_device *dev = rdev->ddev;\n\tstruct drm_crtc *crtc;\n\tstruct radeon_crtc *radeon_crtc;\n\tu32 vrefresh = 0;\n\n\tif (rdev->num_crtc && rdev->mode_info.mode_config_initialized) {\n\t\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\t\tradeon_crtc = to_radeon_crtc(crtc);\n\t\t\tif (crtc->enabled && radeon_crtc->enabled && radeon_crtc->hw_mode.clock) {\n\t\t\t\tvrefresh = drm_mode_vrefresh(&radeon_crtc->hw_mode);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn vrefresh;\n}\n\nvoid r600_calculate_u_and_p(u32 i, u32 r_c, u32 p_b,\n\t\t\t    u32 *p, u32 *u)\n{\n\tu32 b_c = 0;\n\tu32 i_c;\n\tu32 tmp;\n\n\ti_c = (i * r_c) / 100;\n\ttmp = i_c >> p_b;\n\n\twhile (tmp) {\n\t\tb_c++;\n\t\ttmp >>= 1;\n\t}\n\n\t*u = (b_c + 1) / 2;\n\t*p = i_c / (1 << (2 * (*u)));\n}\n\nint r600_calculate_at(u32 t, u32 h, u32 fh, u32 fl, u32 *tl, u32 *th)\n{\n\tu32 k, a, ah, al;\n\tu32 t1;\n\n\tif ((fl == 0) || (fh == 0) || (fl > fh))\n\t\treturn -EINVAL;\n\n\tk = (100 * fh) / fl;\n\tt1 = (t * (k - 100));\n\ta = (1000 * (100 * h + t1)) / (10000 + (t1 / 100));\n\ta = (a + 5) / 10;\n\tah = ((a * t) + 5000) / 10000;\n\tal = a - ah;\n\n\t*th = t - ah;\n\t*tl = t + al;\n\n\treturn 0;\n}\n\nvoid r600_gfx_clockgating_enable(struct radeon_device *rdev, bool enable)\n{\n\tint i;\n\n\tif (enable) {\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, DYN_GFX_CLK_OFF_EN, ~DYN_GFX_CLK_OFF_EN);\n\t} else {\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, 0, ~DYN_GFX_CLK_OFF_EN);\n\n\t\tWREG32(CG_RLC_REQ_AND_RSP, 0x2);\n\n\t\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\t\tif (((RREG32(CG_RLC_REQ_AND_RSP) & CG_RLC_RSP_TYPE_MASK) >> CG_RLC_RSP_TYPE_SHIFT) == 1)\n\t\t\t\tbreak;\n\t\t\tudelay(1);\n\t\t}\n\n\t\tWREG32(CG_RLC_REQ_AND_RSP, 0x0);\n\n\t\tWREG32(GRBM_PWR_CNTL, 0x1);\n\t\tRREG32(GRBM_PWR_CNTL);\n\t}\n}\n\nvoid r600_dynamicpm_enable(struct radeon_device *rdev, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(GENERAL_PWRMGT, GLOBAL_PWRMGT_EN, ~GLOBAL_PWRMGT_EN);\n\telse\n\t\tWREG32_P(GENERAL_PWRMGT, 0, ~GLOBAL_PWRMGT_EN);\n}\n\nvoid r600_enable_thermal_protection(struct radeon_device *rdev, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(GENERAL_PWRMGT, 0, ~THERMAL_PROTECTION_DIS);\n\telse\n\t\tWREG32_P(GENERAL_PWRMGT, THERMAL_PROTECTION_DIS, ~THERMAL_PROTECTION_DIS);\n}\n\nvoid r600_enable_acpi_pm(struct radeon_device *rdev)\n{\n\tWREG32_P(GENERAL_PWRMGT, STATIC_PM_EN, ~STATIC_PM_EN);\n}\n\nvoid r600_enable_dynamic_pcie_gen2(struct radeon_device *rdev, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(GENERAL_PWRMGT, ENABLE_GEN2PCIE, ~ENABLE_GEN2PCIE);\n\telse\n\t\tWREG32_P(GENERAL_PWRMGT, 0, ~ENABLE_GEN2PCIE);\n}\n\nbool r600_dynamicpm_enabled(struct radeon_device *rdev)\n{\n\tif (RREG32(GENERAL_PWRMGT) & GLOBAL_PWRMGT_EN)\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nvoid r600_enable_sclk_control(struct radeon_device *rdev, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, 0, ~SCLK_PWRMGT_OFF);\n\telse\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, SCLK_PWRMGT_OFF, ~SCLK_PWRMGT_OFF);\n}\n\nvoid r600_enable_mclk_control(struct radeon_device *rdev, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(MCLK_PWRMGT_CNTL, 0, ~MPLL_PWRMGT_OFF);\n\telse\n\t\tWREG32_P(MCLK_PWRMGT_CNTL, MPLL_PWRMGT_OFF, ~MPLL_PWRMGT_OFF);\n}\n\nvoid r600_enable_spll_bypass(struct radeon_device *rdev, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(CG_SPLL_FUNC_CNTL, SPLL_BYPASS_EN, ~SPLL_BYPASS_EN);\n\telse\n\t\tWREG32_P(CG_SPLL_FUNC_CNTL, 0, ~SPLL_BYPASS_EN);\n}\n\nvoid r600_wait_for_spll_change(struct radeon_device *rdev)\n{\n\tint i;\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (RREG32(CG_SPLL_FUNC_CNTL) & SPLL_CHG_STATUS)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n}\n\nvoid r600_set_bsp(struct radeon_device *rdev, u32 u, u32 p)\n{\n\tWREG32(CG_BSP, BSP(p) | BSU(u));\n}\n\nvoid r600_set_at(struct radeon_device *rdev,\n\t\t u32 l_to_m, u32 m_to_h,\n\t\t u32 h_to_m, u32 m_to_l)\n{\n\tWREG32(CG_RT, FLS(l_to_m) | FMS(m_to_h));\n\tWREG32(CG_LT, FHS(h_to_m) | FMS(m_to_l));\n}\n\nvoid r600_set_tc(struct radeon_device *rdev,\n\t\t u32 index, u32 u_t, u32 d_t)\n{\n\tWREG32(CG_FFCT_0 + (index * 4), UTC_0(u_t) | DTC_0(d_t));\n}\n\nvoid r600_select_td(struct radeon_device *rdev,\n\t\t    enum r600_td td)\n{\n\tif (td == R600_TD_AUTO)\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, 0, ~FIR_FORCE_TREND_SEL);\n\telse\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, FIR_FORCE_TREND_SEL, ~FIR_FORCE_TREND_SEL);\n\tif (td == R600_TD_UP)\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, 0, ~FIR_TREND_MODE);\n\tif (td == R600_TD_DOWN)\n\t\tWREG32_P(SCLK_PWRMGT_CNTL, FIR_TREND_MODE, ~FIR_TREND_MODE);\n}\n\nvoid r600_set_vrc(struct radeon_device *rdev, u32 vrv)\n{\n\tWREG32(CG_FTV, vrv);\n}\n\nvoid r600_set_tpu(struct radeon_device *rdev, u32 u)\n{\n\tWREG32_P(CG_TPC, TPU(u), ~TPU_MASK);\n}\n\nvoid r600_set_tpc(struct radeon_device *rdev, u32 c)\n{\n\tWREG32_P(CG_TPC, TPCC(c), ~TPCC_MASK);\n}\n\nvoid r600_set_sstu(struct radeon_device *rdev, u32 u)\n{\n\tWREG32_P(CG_SSP, CG_SSTU(u), ~CG_SSTU_MASK);\n}\n\nvoid r600_set_sst(struct radeon_device *rdev, u32 t)\n{\n\tWREG32_P(CG_SSP, CG_SST(t), ~CG_SST_MASK);\n}\n\nvoid r600_set_git(struct radeon_device *rdev, u32 t)\n{\n\tWREG32_P(CG_GIT, CG_GICST(t), ~CG_GICST_MASK);\n}\n\nvoid r600_set_fctu(struct radeon_device *rdev, u32 u)\n{\n\tWREG32_P(CG_FC_T, FC_TU(u), ~FC_TU_MASK);\n}\n\nvoid r600_set_fct(struct radeon_device *rdev, u32 t)\n{\n\tWREG32_P(CG_FC_T, FC_T(t), ~FC_T_MASK);\n}\n\nvoid r600_set_ctxcgtt3d_rphc(struct radeon_device *rdev, u32 p)\n{\n\tWREG32_P(CG_CTX_CGTT3D_R, PHC(p), ~PHC_MASK);\n}\n\nvoid r600_set_ctxcgtt3d_rsdc(struct radeon_device *rdev, u32 s)\n{\n\tWREG32_P(CG_CTX_CGTT3D_R, SDC(s), ~SDC_MASK);\n}\n\nvoid r600_set_vddc3d_oorsu(struct radeon_device *rdev, u32 u)\n{\n\tWREG32_P(CG_VDDC3D_OOR, SU(u), ~SU_MASK);\n}\n\nvoid r600_set_vddc3d_oorphc(struct radeon_device *rdev, u32 p)\n{\n\tWREG32_P(CG_VDDC3D_OOR, PHC(p), ~PHC_MASK);\n}\n\nvoid r600_set_vddc3d_oorsdc(struct radeon_device *rdev, u32 s)\n{\n\tWREG32_P(CG_VDDC3D_OOR, SDC(s), ~SDC_MASK);\n}\n\nvoid r600_set_mpll_lock_time(struct radeon_device *rdev, u32 lock_time)\n{\n\tWREG32_P(MPLL_TIME, MPLL_LOCK_TIME(lock_time), ~MPLL_LOCK_TIME_MASK);\n}\n\nvoid r600_set_mpll_reset_time(struct radeon_device *rdev, u32 reset_time)\n{\n\tWREG32_P(MPLL_TIME, MPLL_RESET_TIME(reset_time), ~MPLL_RESET_TIME_MASK);\n}\n\nvoid r600_engine_clock_entry_enable(struct radeon_device *rdev,\n\t\t\t\t    u32 index, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART2 + (index * 4 * 2),\n\t\t\t STEP_0_SPLL_ENTRY_VALID, ~STEP_0_SPLL_ENTRY_VALID);\n\telse\n\t\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART2 + (index * 4 * 2),\n\t\t\t 0, ~STEP_0_SPLL_ENTRY_VALID);\n}\n\nvoid r600_engine_clock_entry_enable_pulse_skipping(struct radeon_device *rdev,\n\t\t\t\t\t\t   u32 index, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART2 + (index * 4 * 2),\n\t\t\t STEP_0_SPLL_STEP_ENABLE, ~STEP_0_SPLL_STEP_ENABLE);\n\telse\n\t\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART2 + (index * 4 * 2),\n\t\t\t 0, ~STEP_0_SPLL_STEP_ENABLE);\n}\n\nvoid r600_engine_clock_entry_enable_post_divider(struct radeon_device *rdev,\n\t\t\t\t\t\t u32 index, bool enable)\n{\n\tif (enable)\n\t\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART2 + (index * 4 * 2),\n\t\t\t STEP_0_POST_DIV_EN, ~STEP_0_POST_DIV_EN);\n\telse\n\t\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART2 + (index * 4 * 2),\n\t\t\t 0, ~STEP_0_POST_DIV_EN);\n}\n\nvoid r600_engine_clock_entry_set_post_divider(struct radeon_device *rdev,\n\t\t\t\t\t      u32 index, u32 divider)\n{\n\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART1 + (index * 4 * 2),\n\t\t STEP_0_SPLL_POST_DIV(divider), ~STEP_0_SPLL_POST_DIV_MASK);\n}\n\nvoid r600_engine_clock_entry_set_reference_divider(struct radeon_device *rdev,\n\t\t\t\t\t\t   u32 index, u32 divider)\n{\n\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART1 + (index * 4 * 2),\n\t\t STEP_0_SPLL_REF_DIV(divider), ~STEP_0_SPLL_REF_DIV_MASK);\n}\n\nvoid r600_engine_clock_entry_set_feedback_divider(struct radeon_device *rdev,\n\t\t\t\t\t\t  u32 index, u32 divider)\n{\n\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART1 + (index * 4 * 2),\n\t\t STEP_0_SPLL_FB_DIV(divider), ~STEP_0_SPLL_FB_DIV_MASK);\n}\n\nvoid r600_engine_clock_entry_set_step_time(struct radeon_device *rdev,\n\t\t\t\t\t   u32 index, u32 step_time)\n{\n\tWREG32_P(SCLK_FREQ_SETTING_STEP_0_PART1 + (index * 4 * 2),\n\t\t STEP_0_SPLL_STEP_TIME(step_time), ~STEP_0_SPLL_STEP_TIME_MASK);\n}\n\nvoid r600_vid_rt_set_ssu(struct radeon_device *rdev, u32 u)\n{\n\tWREG32_P(VID_RT, SSTU(u), ~SSTU_MASK);\n}\n\nvoid r600_vid_rt_set_vru(struct radeon_device *rdev, u32 u)\n{\n\tWREG32_P(VID_RT, VID_CRTU(u), ~VID_CRTU_MASK);\n}\n\nvoid r600_vid_rt_set_vrt(struct radeon_device *rdev, u32 rt)\n{\n\tWREG32_P(VID_RT, VID_CRT(rt), ~VID_CRT_MASK);\n}\n\nvoid r600_voltage_control_enable_pins(struct radeon_device *rdev,\n\t\t\t\t      u64 mask)\n{\n\tWREG32(LOWER_GPIO_ENABLE, mask & 0xffffffff);\n\tWREG32(UPPER_GPIO_ENABLE, upper_32_bits(mask));\n}\n\n\nvoid r600_voltage_control_program_voltages(struct radeon_device *rdev,\n\t\t\t\t\t   enum r600_power_level index, u64 pins)\n{\n\tu32 tmp, mask;\n\tu32 ix = 3 - (3 & index);\n\n\tWREG32(CTXSW_VID_LOWER_GPIO_CNTL + (ix * 4), pins & 0xffffffff);\n\n\tmask = 7 << (3 * ix);\n\ttmp = RREG32(VID_UPPER_GPIO_CNTL);\n\ttmp = (tmp & ~mask) | ((pins >> (32 - (3 * ix))) & mask);\n\tWREG32(VID_UPPER_GPIO_CNTL, tmp);\n}\n\nvoid r600_voltage_control_deactivate_static_control(struct radeon_device *rdev,\n\t\t\t\t\t\t    u64 mask)\n{\n\tu32 gpio;\n\n\tgpio = RREG32(GPIOPAD_MASK);\n\tgpio &= ~mask;\n\tWREG32(GPIOPAD_MASK, gpio);\n\n\tgpio = RREG32(GPIOPAD_EN);\n\tgpio &= ~mask;\n\tWREG32(GPIOPAD_EN, gpio);\n\n\tgpio = RREG32(GPIOPAD_A);\n\tgpio &= ~mask;\n\tWREG32(GPIOPAD_A, gpio);\n}\n\nvoid r600_power_level_enable(struct radeon_device *rdev,\n\t\t\t     enum r600_power_level index, bool enable)\n{\n\tu32 ix = 3 - (3 & index);\n\n\tif (enable)\n\t\tWREG32_P(CTXSW_PROFILE_INDEX + (ix * 4), CTXSW_FREQ_STATE_ENABLE,\n\t\t\t ~CTXSW_FREQ_STATE_ENABLE);\n\telse\n\t\tWREG32_P(CTXSW_PROFILE_INDEX + (ix * 4), 0,\n\t\t\t ~CTXSW_FREQ_STATE_ENABLE);\n}\n\nvoid r600_power_level_set_voltage_index(struct radeon_device *rdev,\n\t\t\t\t\tenum r600_power_level index, u32 voltage_index)\n{\n\tu32 ix = 3 - (3 & index);\n\n\tWREG32_P(CTXSW_PROFILE_INDEX + (ix * 4),\n\t\t CTXSW_FREQ_VIDS_CFG_INDEX(voltage_index), ~CTXSW_FREQ_VIDS_CFG_INDEX_MASK);\n}\n\nvoid r600_power_level_set_mem_clock_index(struct radeon_device *rdev,\n\t\t\t\t\t  enum r600_power_level index, u32 mem_clock_index)\n{\n\tu32 ix = 3 - (3 & index);\n\n\tWREG32_P(CTXSW_PROFILE_INDEX + (ix * 4),\n\t\t CTXSW_FREQ_MCLK_CFG_INDEX(mem_clock_index), ~CTXSW_FREQ_MCLK_CFG_INDEX_MASK);\n}\n\nvoid r600_power_level_set_eng_clock_index(struct radeon_device *rdev,\n\t\t\t\t\t  enum r600_power_level index, u32 eng_clock_index)\n{\n\tu32 ix = 3 - (3 & index);\n\n\tWREG32_P(CTXSW_PROFILE_INDEX + (ix * 4),\n\t\t CTXSW_FREQ_SCLK_CFG_INDEX(eng_clock_index), ~CTXSW_FREQ_SCLK_CFG_INDEX_MASK);\n}\n\nvoid r600_power_level_set_watermark_id(struct radeon_device *rdev,\n\t\t\t\t       enum r600_power_level index,\n\t\t\t\t       enum r600_display_watermark watermark_id)\n{\n\tu32 ix = 3 - (3 & index);\n\tu32 tmp = 0;\n\n\tif (watermark_id == R600_DISPLAY_WATERMARK_HIGH)\n\t\ttmp = CTXSW_FREQ_DISPLAY_WATERMARK;\n\tWREG32_P(CTXSW_PROFILE_INDEX + (ix * 4), tmp, ~CTXSW_FREQ_DISPLAY_WATERMARK);\n}\n\nvoid r600_power_level_set_pcie_gen2(struct radeon_device *rdev,\n\t\t\t\t    enum r600_power_level index, bool compatible)\n{\n\tu32 ix = 3 - (3 & index);\n\tu32 tmp = 0;\n\n\tif (compatible)\n\t\ttmp = CTXSW_FREQ_GEN2PCIE_VOLT;\n\tWREG32_P(CTXSW_PROFILE_INDEX + (ix * 4), tmp, ~CTXSW_FREQ_GEN2PCIE_VOLT);\n}\n\nenum r600_power_level r600_power_level_get_current_index(struct radeon_device *rdev)\n{\n\tu32 tmp;\n\n\ttmp = RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_PROFILE_INDEX_MASK;\n\ttmp >>= CURRENT_PROFILE_INDEX_SHIFT;\n\treturn tmp;\n}\n\nenum r600_power_level r600_power_level_get_target_index(struct radeon_device *rdev)\n{\n\tu32 tmp;\n\n\ttmp = RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & TARGET_PROFILE_INDEX_MASK;\n\ttmp >>= TARGET_PROFILE_INDEX_SHIFT;\n\treturn tmp;\n}\n\nvoid r600_power_level_set_enter_index(struct radeon_device *rdev,\n\t\t\t\t      enum r600_power_level index)\n{\n\tWREG32_P(TARGET_AND_CURRENT_PROFILE_INDEX, DYN_PWR_ENTER_INDEX(index),\n\t\t ~DYN_PWR_ENTER_INDEX_MASK);\n}\n\nvoid r600_wait_for_power_level_unequal(struct radeon_device *rdev,\n\t\t\t\t       enum r600_power_level index)\n{\n\tint i;\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (r600_power_level_get_target_index(rdev) != index)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (r600_power_level_get_current_index(rdev) != index)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n}\n\nvoid r600_wait_for_power_level(struct radeon_device *rdev,\n\t\t\t       enum r600_power_level index)\n{\n\tint i;\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (r600_power_level_get_target_index(rdev) == index)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (r600_power_level_get_current_index(rdev) == index)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n}\n\nvoid r600_start_dpm(struct radeon_device *rdev)\n{\n\tr600_enable_sclk_control(rdev, false);\n\tr600_enable_mclk_control(rdev, false);\n\n\tr600_dynamicpm_enable(rdev, true);\n\n\tradeon_wait_for_vblank(rdev, 0);\n\tradeon_wait_for_vblank(rdev, 1);\n\n\tr600_enable_spll_bypass(rdev, true);\n\tr600_wait_for_spll_change(rdev);\n\tr600_enable_spll_bypass(rdev, false);\n\tr600_wait_for_spll_change(rdev);\n\n\tr600_enable_spll_bypass(rdev, true);\n\tr600_wait_for_spll_change(rdev);\n\tr600_enable_spll_bypass(rdev, false);\n\tr600_wait_for_spll_change(rdev);\n\n\tr600_enable_sclk_control(rdev, true);\n\tr600_enable_mclk_control(rdev, true);\n}\n\nvoid r600_stop_dpm(struct radeon_device *rdev)\n{\n\tr600_dynamicpm_enable(rdev, false);\n}\n\nint r600_dpm_pre_set_power_state(struct radeon_device *rdev)\n{\n\treturn 0;\n}\n\nvoid r600_dpm_post_set_power_state(struct radeon_device *rdev)\n{\n\n}\n\nbool r600_is_uvd_state(u32 class, u32 class2)\n{\n\tif (class & ATOM_PPLIB_CLASSIFICATION_UVDSTATE)\n\t\treturn true;\n\tif (class & ATOM_PPLIB_CLASSIFICATION_HD2STATE)\n\t\treturn true;\n\tif (class & ATOM_PPLIB_CLASSIFICATION_HDSTATE)\n\t\treturn true;\n\tif (class & ATOM_PPLIB_CLASSIFICATION_SDSTATE)\n\t\treturn true;\n\tif (class2 & ATOM_PPLIB_CLASSIFICATION2_MVC)\n\t\treturn true;\n\treturn false;\n}\n\nstatic int r600_set_thermal_temperature_range(struct radeon_device *rdev,\n\t\t\t\t\t      int min_temp, int max_temp)\n{\n\tint low_temp = 0 * 1000;\n\tint high_temp = 255 * 1000;\n\n\tif (low_temp < min_temp)\n\t\tlow_temp = min_temp;\n\tif (high_temp > max_temp)\n\t\thigh_temp = max_temp;\n\tif (high_temp < low_temp) {\n\t\tDRM_ERROR(\"invalid thermal range: %d - %d\\n\", low_temp, high_temp);\n\t\treturn -EINVAL;\n\t}\n\n\tWREG32_P(CG_THERMAL_INT, DIG_THERM_INTH(high_temp / 1000), ~DIG_THERM_INTH_MASK);\n\tWREG32_P(CG_THERMAL_INT, DIG_THERM_INTL(low_temp / 1000), ~DIG_THERM_INTL_MASK);\n\tWREG32_P(CG_THERMAL_CTRL, DIG_THERM_DPM(high_temp / 1000), ~DIG_THERM_DPM_MASK);\n\n\trdev->pm.dpm.thermal.min_temp = low_temp;\n\trdev->pm.dpm.thermal.max_temp = high_temp;\n\n\treturn 0;\n}\n\nbool r600_is_internal_thermal_sensor(enum radeon_int_thermal_type sensor)\n{\n\tswitch (sensor) {\n\tcase THERMAL_TYPE_RV6XX:\n\tcase THERMAL_TYPE_RV770:\n\tcase THERMAL_TYPE_EVERGREEN:\n\tcase THERMAL_TYPE_SUMO:\n\tcase THERMAL_TYPE_NI:\n\tcase THERMAL_TYPE_SI:\n\tcase THERMAL_TYPE_CI:\n\tcase THERMAL_TYPE_KV:\n\t\treturn true;\n\tcase THERMAL_TYPE_ADT7473_WITH_INTERNAL:\n\tcase THERMAL_TYPE_EMC2103_WITH_INTERNAL:\n\t\treturn false;  \n\tcase THERMAL_TYPE_NONE:\n\tcase THERMAL_TYPE_EXTERNAL:\n\tcase THERMAL_TYPE_EXTERNAL_GPIO:\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nint r600_dpm_late_enable(struct radeon_device *rdev)\n{\n\tint ret;\n\n\tif (rdev->irq.installed &&\n\t    r600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {\n\t\tret = r600_set_thermal_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\trdev->irq.dpm_thermal = true;\n\t\tradeon_irq_set(rdev);\n\t}\n\n\treturn 0;\n}\n\nunion power_info {\n\tstruct _ATOM_POWERPLAY_INFO info;\n\tstruct _ATOM_POWERPLAY_INFO_V2 info_2;\n\tstruct _ATOM_POWERPLAY_INFO_V3 info_3;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE pplib;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE2 pplib2;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE3 pplib3;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE4 pplib4;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE5 pplib5;\n};\n\nunion fan_info {\n\tstruct _ATOM_PPLIB_FANTABLE fan;\n\tstruct _ATOM_PPLIB_FANTABLE2 fan2;\n\tstruct _ATOM_PPLIB_FANTABLE3 fan3;\n};\n\nstatic int r600_parse_clk_voltage_dep_table(struct radeon_clock_voltage_dependency_table *radeon_table,\n\t\t\t\t\t    ATOM_PPLIB_Clock_Voltage_Dependency_Table *atom_table)\n{\n\tint i;\n\tATOM_PPLIB_Clock_Voltage_Dependency_Record *entry;\n\n\tradeon_table->entries = kcalloc(atom_table->ucNumEntries,\n\t\t\t\t\tsizeof(struct radeon_clock_voltage_dependency_entry),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!radeon_table->entries)\n\t\treturn -ENOMEM;\n\n\tentry = &atom_table->entries[0];\n\tfor (i = 0; i < atom_table->ucNumEntries; i++) {\n\t\tradeon_table->entries[i].clk = le16_to_cpu(entry->usClockLow) |\n\t\t\t(entry->ucClockHigh << 16);\n\t\tradeon_table->entries[i].v = le16_to_cpu(entry->usVoltage);\n\t\tentry = (ATOM_PPLIB_Clock_Voltage_Dependency_Record *)\n\t\t\t((u8 *)entry + sizeof(ATOM_PPLIB_Clock_Voltage_Dependency_Record));\n\t}\n\tradeon_table->count = atom_table->ucNumEntries;\n\n\treturn 0;\n}\n\nint r600_get_platform_caps(struct radeon_device *rdev)\n{\n\tstruct radeon_mode_info *mode_info = &rdev->mode_info;\n\tunion power_info *power_info;\n\tint index = GetIndexIntoMasterTable(DATA, PowerPlayInfo);\n\tu16 data_offset;\n\tu8 frev, crev;\n\n\tif (!atom_parse_data_header(mode_info->atom_context, index, NULL,\n\t\t\t\t   &frev, &crev, &data_offset))\n\t\treturn -EINVAL;\n\tpower_info = (union power_info *)(mode_info->atom_context->bios + data_offset);\n\n\trdev->pm.dpm.platform_caps = le32_to_cpu(power_info->pplib.ulPlatformCaps);\n\trdev->pm.dpm.backbias_response_time = le16_to_cpu(power_info->pplib.usBackbiasTime);\n\trdev->pm.dpm.voltage_response_time = le16_to_cpu(power_info->pplib.usVoltageTime);\n\n\treturn 0;\n}\n\n \n#define SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V2 12\n#define SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V3 14\n#define SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V4 16\n#define SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V5 18\n#define SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V6 20\n#define SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V7 22\n\nint r600_parse_extended_power_table(struct radeon_device *rdev)\n{\n\tstruct radeon_mode_info *mode_info = &rdev->mode_info;\n\tunion power_info *power_info;\n\tunion fan_info *fan_info;\n\tATOM_PPLIB_Clock_Voltage_Dependency_Table *dep_table;\n\tint index = GetIndexIntoMasterTable(DATA, PowerPlayInfo);\n\tu16 data_offset;\n\tu8 frev, crev;\n\tint ret, i;\n\n\tif (!atom_parse_data_header(mode_info->atom_context, index, NULL,\n\t\t\t\t   &frev, &crev, &data_offset))\n\t\treturn -EINVAL;\n\tpower_info = (union power_info *)(mode_info->atom_context->bios + data_offset);\n\n\t \n\tif (le16_to_cpu(power_info->pplib.usTableSize) >=\n\t    sizeof(struct _ATOM_PPLIB_POWERPLAYTABLE3)) {\n\t\tif (power_info->pplib3.usFanTableOffset) {\n\t\t\tfan_info = (union fan_info *)(mode_info->atom_context->bios + data_offset +\n\t\t\t\t\t\t      le16_to_cpu(power_info->pplib3.usFanTableOffset));\n\t\t\trdev->pm.dpm.fan.t_hyst = fan_info->fan.ucTHyst;\n\t\t\trdev->pm.dpm.fan.t_min = le16_to_cpu(fan_info->fan.usTMin);\n\t\t\trdev->pm.dpm.fan.t_med = le16_to_cpu(fan_info->fan.usTMed);\n\t\t\trdev->pm.dpm.fan.t_high = le16_to_cpu(fan_info->fan.usTHigh);\n\t\t\trdev->pm.dpm.fan.pwm_min = le16_to_cpu(fan_info->fan.usPWMMin);\n\t\t\trdev->pm.dpm.fan.pwm_med = le16_to_cpu(fan_info->fan.usPWMMed);\n\t\t\trdev->pm.dpm.fan.pwm_high = le16_to_cpu(fan_info->fan.usPWMHigh);\n\t\t\tif (fan_info->fan.ucFanTableFormat >= 2)\n\t\t\t\trdev->pm.dpm.fan.t_max = le16_to_cpu(fan_info->fan2.usTMax);\n\t\t\telse\n\t\t\t\trdev->pm.dpm.fan.t_max = 10900;\n\t\t\trdev->pm.dpm.fan.cycle_delay = 100000;\n\t\t\tif (fan_info->fan.ucFanTableFormat >= 3) {\n\t\t\t\trdev->pm.dpm.fan.control_mode = fan_info->fan3.ucFanControlMode;\n\t\t\t\trdev->pm.dpm.fan.default_max_fan_pwm =\n\t\t\t\t\tle16_to_cpu(fan_info->fan3.usFanPWMMax);\n\t\t\t\trdev->pm.dpm.fan.default_fan_output_sensitivity = 4836;\n\t\t\t\trdev->pm.dpm.fan.fan_output_sensitivity =\n\t\t\t\t\tle16_to_cpu(fan_info->fan3.usFanOutputSensitivity);\n\t\t\t}\n\t\t\trdev->pm.dpm.fan.ucode_fan_control = true;\n\t\t}\n\t}\n\n\t \n\tif (le16_to_cpu(power_info->pplib.usTableSize) >=\n\t    sizeof(struct _ATOM_PPLIB_POWERPLAYTABLE4)) {\n\t\tif (power_info->pplib4.usVddcDependencyOnSCLKOffset) {\n\t\t\tdep_table = (ATOM_PPLIB_Clock_Voltage_Dependency_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(power_info->pplib4.usVddcDependencyOnSCLKOffset));\n\t\t\tret = r600_parse_clk_voltage_dep_table(&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk,\n\t\t\t\t\t\t\t       dep_table);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\t\tif (power_info->pplib4.usVddciDependencyOnMCLKOffset) {\n\t\t\tdep_table = (ATOM_PPLIB_Clock_Voltage_Dependency_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(power_info->pplib4.usVddciDependencyOnMCLKOffset));\n\t\t\tret = r600_parse_clk_voltage_dep_table(&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk,\n\t\t\t\t\t\t\t       dep_table);\n\t\t\tif (ret) {\n\t\t\t\tkfree(rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t\tif (power_info->pplib4.usVddcDependencyOnMCLKOffset) {\n\t\t\tdep_table = (ATOM_PPLIB_Clock_Voltage_Dependency_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(power_info->pplib4.usVddcDependencyOnMCLKOffset));\n\t\t\tret = r600_parse_clk_voltage_dep_table(&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk,\n\t\t\t\t\t\t\t       dep_table);\n\t\t\tif (ret) {\n\t\t\t\tkfree(rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries);\n\t\t\t\tkfree(rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk.entries);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t\tif (power_info->pplib4.usMvddDependencyOnMCLKOffset) {\n\t\t\tdep_table = (ATOM_PPLIB_Clock_Voltage_Dependency_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(power_info->pplib4.usMvddDependencyOnMCLKOffset));\n\t\t\tret = r600_parse_clk_voltage_dep_table(&rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk,\n\t\t\t\t\t\t\t       dep_table);\n\t\t\tif (ret) {\n\t\t\t\tkfree(rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries);\n\t\t\t\tkfree(rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk.entries);\n\t\t\t\tkfree(rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk.entries);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t\tif (power_info->pplib4.usMaxClockVoltageOnDCOffset) {\n\t\t\tATOM_PPLIB_Clock_Voltage_Limit_Table *clk_v =\n\t\t\t\t(ATOM_PPLIB_Clock_Voltage_Limit_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(power_info->pplib4.usMaxClockVoltageOnDCOffset));\n\t\t\tif (clk_v->ucNumEntries) {\n\t\t\t\trdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.sclk =\n\t\t\t\t\tle16_to_cpu(clk_v->entries[0].usSclkLow) |\n\t\t\t\t\t(clk_v->entries[0].ucSclkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.mclk =\n\t\t\t\t\tle16_to_cpu(clk_v->entries[0].usMclkLow) |\n\t\t\t\t\t(clk_v->entries[0].ucMclkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.vddc =\n\t\t\t\t\tle16_to_cpu(clk_v->entries[0].usVddc);\n\t\t\t\trdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.vddci =\n\t\t\t\t\tle16_to_cpu(clk_v->entries[0].usVddci);\n\t\t\t}\n\t\t}\n\t\tif (power_info->pplib4.usVddcPhaseShedLimitsTableOffset) {\n\t\t\tATOM_PPLIB_PhaseSheddingLimits_Table *psl =\n\t\t\t\t(ATOM_PPLIB_PhaseSheddingLimits_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(power_info->pplib4.usVddcPhaseShedLimitsTableOffset));\n\t\t\tATOM_PPLIB_PhaseSheddingLimits_Record *entry;\n\n\t\t\trdev->pm.dpm.dyn_state.phase_shedding_limits_table.entries =\n\t\t\t\tkcalloc(psl->ucNumEntries,\n\t\t\t\t\tsizeof(struct radeon_phase_shedding_limits_entry),\n\t\t\t\t\tGFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.phase_shedding_limits_table.entries) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\tentry = &psl->entries[0];\n\t\t\tfor (i = 0; i < psl->ucNumEntries; i++) {\n\t\t\t\trdev->pm.dpm.dyn_state.phase_shedding_limits_table.entries[i].sclk =\n\t\t\t\t\tle16_to_cpu(entry->usSclkLow) | (entry->ucSclkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.phase_shedding_limits_table.entries[i].mclk =\n\t\t\t\t\tle16_to_cpu(entry->usMclkLow) | (entry->ucMclkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.phase_shedding_limits_table.entries[i].voltage =\n\t\t\t\t\tle16_to_cpu(entry->usVoltage);\n\t\t\t\tentry = (ATOM_PPLIB_PhaseSheddingLimits_Record *)\n\t\t\t\t\t((u8 *)entry + sizeof(ATOM_PPLIB_PhaseSheddingLimits_Record));\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.phase_shedding_limits_table.count =\n\t\t\t\tpsl->ucNumEntries;\n\t\t}\n\t}\n\n\t \n\tif (le16_to_cpu(power_info->pplib.usTableSize) >=\n\t    sizeof(struct _ATOM_PPLIB_POWERPLAYTABLE5)) {\n\t\trdev->pm.dpm.tdp_limit = le32_to_cpu(power_info->pplib5.ulTDPLimit);\n\t\trdev->pm.dpm.near_tdp_limit = le32_to_cpu(power_info->pplib5.ulNearTDPLimit);\n\t\trdev->pm.dpm.near_tdp_limit_adjusted = rdev->pm.dpm.near_tdp_limit;\n\t\trdev->pm.dpm.tdp_od_limit = le16_to_cpu(power_info->pplib5.usTDPODLimit);\n\t\tif (rdev->pm.dpm.tdp_od_limit)\n\t\t\trdev->pm.dpm.power_control = true;\n\t\telse\n\t\t\trdev->pm.dpm.power_control = false;\n\t\trdev->pm.dpm.tdp_adjustment = 0;\n\t\trdev->pm.dpm.sq_ramping_threshold = le32_to_cpu(power_info->pplib5.ulSQRampingThreshold);\n\t\trdev->pm.dpm.cac_leakage = le32_to_cpu(power_info->pplib5.ulCACLeakage);\n\t\trdev->pm.dpm.load_line_slope = le16_to_cpu(power_info->pplib5.usLoadLineSlope);\n\t\tif (power_info->pplib5.usCACLeakageTableOffset) {\n\t\t\tATOM_PPLIB_CAC_Leakage_Table *cac_table =\n\t\t\t\t(ATOM_PPLIB_CAC_Leakage_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(power_info->pplib5.usCACLeakageTableOffset));\n\t\t\tATOM_PPLIB_CAC_Leakage_Record *entry;\n\t\t\tu32 size = cac_table->ucNumEntries * sizeof(struct radeon_cac_leakage_table);\n\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries = kzalloc(size, GFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.cac_leakage_table.entries) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tentry = &cac_table->entries[0];\n\t\t\tfor (i = 0; i < cac_table->ucNumEntries; i++) {\n\t\t\t\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_EVV) {\n\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc1 =\n\t\t\t\t\t\tle16_to_cpu(entry->usVddc1);\n\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc2 =\n\t\t\t\t\t\tle16_to_cpu(entry->usVddc2);\n\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc3 =\n\t\t\t\t\t\tle16_to_cpu(entry->usVddc3);\n\t\t\t\t} else {\n\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc =\n\t\t\t\t\t\tle16_to_cpu(entry->usVddc);\n\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].leakage =\n\t\t\t\t\t\tle32_to_cpu(entry->ulLeakageValue);\n\t\t\t\t}\n\t\t\t\tentry = (ATOM_PPLIB_CAC_Leakage_Record *)\n\t\t\t\t\t((u8 *)entry + sizeof(ATOM_PPLIB_CAC_Leakage_Record));\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.count = cac_table->ucNumEntries;\n\t\t}\n\t}\n\n\t \n\tif (le16_to_cpu(power_info->pplib.usTableSize) >=\n\t    sizeof(struct _ATOM_PPLIB_POWERPLAYTABLE3)) {\n\t\tATOM_PPLIB_EXTENDEDHEADER *ext_hdr = (ATOM_PPLIB_EXTENDEDHEADER *)\n\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t le16_to_cpu(power_info->pplib3.usExtendendedHeaderOffset));\n\t\tif ((le16_to_cpu(ext_hdr->usSize) >= SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V2) &&\n\t\t\text_hdr->usVCETableOffset) {\n\t\t\tVCEClockInfoArray *array = (VCEClockInfoArray *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usVCETableOffset) + 1);\n\t\t\tATOM_PPLIB_VCE_Clock_Voltage_Limit_Table *limits =\n\t\t\t\t(ATOM_PPLIB_VCE_Clock_Voltage_Limit_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usVCETableOffset) + 1 +\n\t\t\t\t 1 + array->ucNumEntries * sizeof(VCEClockInfo));\n\t\t\tATOM_PPLIB_VCE_State_Table *states =\n\t\t\t\t(ATOM_PPLIB_VCE_State_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usVCETableOffset) + 1 +\n\t\t\t\t 1 + (array->ucNumEntries * sizeof (VCEClockInfo)) +\n\t\t\t\t 1 + (limits->numEntries * sizeof(ATOM_PPLIB_VCE_Clock_Voltage_Limit_Record)));\n\t\t\tATOM_PPLIB_VCE_Clock_Voltage_Limit_Record *entry;\n\t\t\tATOM_PPLIB_VCE_State_Record *state_entry;\n\t\t\tVCEClockInfo *vce_clk;\n\t\t\tu32 size = limits->numEntries *\n\t\t\t\tsizeof(struct radeon_vce_clock_voltage_dependency_entry);\n\t\t\trdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries =\n\t\t\t\tkzalloc(size, GFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.count =\n\t\t\t\tlimits->numEntries;\n\t\t\tentry = &limits->entries[0];\n\t\t\tstate_entry = &states->entries[0];\n\t\t\tfor (i = 0; i < limits->numEntries; i++) {\n\t\t\t\tvce_clk = (VCEClockInfo *)\n\t\t\t\t\t((u8 *)&array->entries[0] +\n\t\t\t\t\t (entry->ucVCEClockInfoIndex * sizeof(VCEClockInfo)));\n\t\t\t\trdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries[i].evclk =\n\t\t\t\t\tle16_to_cpu(vce_clk->usEVClkLow) | (vce_clk->ucEVClkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries[i].ecclk =\n\t\t\t\t\tle16_to_cpu(vce_clk->usECClkLow) | (vce_clk->ucECClkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries[i].v =\n\t\t\t\t\tle16_to_cpu(entry->usVoltage);\n\t\t\t\tentry = (ATOM_PPLIB_VCE_Clock_Voltage_Limit_Record *)\n\t\t\t\t\t((u8 *)entry + sizeof(ATOM_PPLIB_VCE_Clock_Voltage_Limit_Record));\n\t\t\t}\n\t\t\tfor (i = 0; i < states->numEntries; i++) {\n\t\t\t\tif (i >= RADEON_MAX_VCE_LEVELS)\n\t\t\t\t\tbreak;\n\t\t\t\tvce_clk = (VCEClockInfo *)\n\t\t\t\t\t((u8 *)&array->entries[0] +\n\t\t\t\t\t (state_entry->ucVCEClockInfoIndex * sizeof(VCEClockInfo)));\n\t\t\t\trdev->pm.dpm.vce_states[i].evclk =\n\t\t\t\t\tle16_to_cpu(vce_clk->usEVClkLow) | (vce_clk->ucEVClkHigh << 16);\n\t\t\t\trdev->pm.dpm.vce_states[i].ecclk =\n\t\t\t\t\tle16_to_cpu(vce_clk->usECClkLow) | (vce_clk->ucECClkHigh << 16);\n\t\t\t\trdev->pm.dpm.vce_states[i].clk_idx =\n\t\t\t\t\tstate_entry->ucClockInfoIndex & 0x3f;\n\t\t\t\trdev->pm.dpm.vce_states[i].pstate =\n\t\t\t\t\t(state_entry->ucClockInfoIndex & 0xc0) >> 6;\n\t\t\t\tstate_entry = (ATOM_PPLIB_VCE_State_Record *)\n\t\t\t\t\t((u8 *)state_entry + sizeof(ATOM_PPLIB_VCE_State_Record));\n\t\t\t}\n\t\t}\n\t\tif ((le16_to_cpu(ext_hdr->usSize) >= SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V3) &&\n\t\t\text_hdr->usUVDTableOffset) {\n\t\t\tUVDClockInfoArray *array = (UVDClockInfoArray *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usUVDTableOffset) + 1);\n\t\t\tATOM_PPLIB_UVD_Clock_Voltage_Limit_Table *limits =\n\t\t\t\t(ATOM_PPLIB_UVD_Clock_Voltage_Limit_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usUVDTableOffset) + 1 +\n\t\t\t\t 1 + (array->ucNumEntries * sizeof (UVDClockInfo)));\n\t\t\tATOM_PPLIB_UVD_Clock_Voltage_Limit_Record *entry;\n\t\t\tu32 size = limits->numEntries *\n\t\t\t\tsizeof(struct radeon_uvd_clock_voltage_dependency_entry);\n\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries =\n\t\t\t\tkzalloc(size, GFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.count =\n\t\t\t\tlimits->numEntries;\n\t\t\tentry = &limits->entries[0];\n\t\t\tfor (i = 0; i < limits->numEntries; i++) {\n\t\t\t\tUVDClockInfo *uvd_clk = (UVDClockInfo *)\n\t\t\t\t\t((u8 *)&array->entries[0] +\n\t\t\t\t\t (entry->ucUVDClockInfoIndex * sizeof(UVDClockInfo)));\n\t\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries[i].vclk =\n\t\t\t\t\tle16_to_cpu(uvd_clk->usVClkLow) | (uvd_clk->ucVClkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries[i].dclk =\n\t\t\t\t\tle16_to_cpu(uvd_clk->usDClkLow) | (uvd_clk->ucDClkHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries[i].v =\n\t\t\t\t\tle16_to_cpu(entry->usVoltage);\n\t\t\t\tentry = (ATOM_PPLIB_UVD_Clock_Voltage_Limit_Record *)\n\t\t\t\t\t((u8 *)entry + sizeof(ATOM_PPLIB_UVD_Clock_Voltage_Limit_Record));\n\t\t\t}\n\t\t}\n\t\tif ((le16_to_cpu(ext_hdr->usSize) >= SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V4) &&\n\t\t\text_hdr->usSAMUTableOffset) {\n\t\t\tATOM_PPLIB_SAMClk_Voltage_Limit_Table *limits =\n\t\t\t\t(ATOM_PPLIB_SAMClk_Voltage_Limit_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usSAMUTableOffset) + 1);\n\t\t\tATOM_PPLIB_SAMClk_Voltage_Limit_Record *entry;\n\t\t\tu32 size = limits->numEntries *\n\t\t\t\tsizeof(struct radeon_clock_voltage_dependency_entry);\n\t\t\trdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.entries =\n\t\t\t\tkzalloc(size, GFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.entries) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.count =\n\t\t\t\tlimits->numEntries;\n\t\t\tentry = &limits->entries[0];\n\t\t\tfor (i = 0; i < limits->numEntries; i++) {\n\t\t\t\trdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.entries[i].clk =\n\t\t\t\t\tle16_to_cpu(entry->usSAMClockLow) | (entry->ucSAMClockHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.entries[i].v =\n\t\t\t\t\tle16_to_cpu(entry->usVoltage);\n\t\t\t\tentry = (ATOM_PPLIB_SAMClk_Voltage_Limit_Record *)\n\t\t\t\t\t((u8 *)entry + sizeof(ATOM_PPLIB_SAMClk_Voltage_Limit_Record));\n\t\t\t}\n\t\t}\n\t\tif ((le16_to_cpu(ext_hdr->usSize) >= SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V5) &&\n\t\t    ext_hdr->usPPMTableOffset) {\n\t\t\tATOM_PPLIB_PPM_Table *ppm = (ATOM_PPLIB_PPM_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usPPMTableOffset));\n\t\t\trdev->pm.dpm.dyn_state.ppm_table =\n\t\t\t\tkzalloc(sizeof(struct radeon_ppm_table), GFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.ppm_table) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->ppm_design = ppm->ucPpmDesign;\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->cpu_core_number =\n\t\t\t\tle16_to_cpu(ppm->usCpuCoreNumber);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->platform_tdp =\n\t\t\t\tle32_to_cpu(ppm->ulPlatformTDP);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->small_ac_platform_tdp =\n\t\t\t\tle32_to_cpu(ppm->ulSmallACPlatformTDP);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->platform_tdc =\n\t\t\t\tle32_to_cpu(ppm->ulPlatformTDC);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->small_ac_platform_tdc =\n\t\t\t\tle32_to_cpu(ppm->ulSmallACPlatformTDC);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->apu_tdp =\n\t\t\t\tle32_to_cpu(ppm->ulApuTDP);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->dgpu_tdp =\n\t\t\t\tle32_to_cpu(ppm->ulDGpuTDP);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->dgpu_ulv_power =\n\t\t\t\tle32_to_cpu(ppm->ulDGpuUlvPower);\n\t\t\trdev->pm.dpm.dyn_state.ppm_table->tj_max =\n\t\t\t\tle32_to_cpu(ppm->ulTjmax);\n\t\t}\n\t\tif ((le16_to_cpu(ext_hdr->usSize) >= SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V6) &&\n\t\t\text_hdr->usACPTableOffset) {\n\t\t\tATOM_PPLIB_ACPClk_Voltage_Limit_Table *limits =\n\t\t\t\t(ATOM_PPLIB_ACPClk_Voltage_Limit_Table *)\n\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t le16_to_cpu(ext_hdr->usACPTableOffset) + 1);\n\t\t\tATOM_PPLIB_ACPClk_Voltage_Limit_Record *entry;\n\t\t\tu32 size = limits->numEntries *\n\t\t\t\tsizeof(struct radeon_clock_voltage_dependency_entry);\n\t\t\trdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.entries =\n\t\t\t\tkzalloc(size, GFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.entries) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.count =\n\t\t\t\tlimits->numEntries;\n\t\t\tentry = &limits->entries[0];\n\t\t\tfor (i = 0; i < limits->numEntries; i++) {\n\t\t\t\trdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.entries[i].clk =\n\t\t\t\t\tle16_to_cpu(entry->usACPClockLow) | (entry->ucACPClockHigh << 16);\n\t\t\t\trdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.entries[i].v =\n\t\t\t\t\tle16_to_cpu(entry->usVoltage);\n\t\t\t\tentry = (ATOM_PPLIB_ACPClk_Voltage_Limit_Record *)\n\t\t\t\t\t((u8 *)entry + sizeof(ATOM_PPLIB_ACPClk_Voltage_Limit_Record));\n\t\t\t}\n\t\t}\n\t\tif ((le16_to_cpu(ext_hdr->usSize) >= SIZE_OF_ATOM_PPLIB_EXTENDEDHEADER_V7) &&\n\t\t\text_hdr->usPowerTuneTableOffset) {\n\t\t\tu8 rev = *(u8 *)(mode_info->atom_context->bios + data_offset +\n\t\t\t\t\t le16_to_cpu(ext_hdr->usPowerTuneTableOffset));\n\t\t\tATOM_PowerTune_Table *pt;\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table =\n\t\t\t\tkzalloc(sizeof(struct radeon_cac_tdp_table), GFP_KERNEL);\n\t\t\tif (!rdev->pm.dpm.dyn_state.cac_tdp_table) {\n\t\t\t\tr600_free_extended_power_table(rdev);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tif (rev > 0) {\n\t\t\t\tATOM_PPLIB_POWERTUNE_Table_V1 *ppt = (ATOM_PPLIB_POWERTUNE_Table_V1 *)\n\t\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t\t le16_to_cpu(ext_hdr->usPowerTuneTableOffset));\n\t\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->maximum_power_delivery_limit =\n\t\t\t\t\tle16_to_cpu(ppt->usMaximumPowerDeliveryLimit);\n\t\t\t\tpt = &ppt->power_tune_table;\n\t\t\t} else {\n\t\t\t\tATOM_PPLIB_POWERTUNE_Table *ppt = (ATOM_PPLIB_POWERTUNE_Table *)\n\t\t\t\t\t(mode_info->atom_context->bios + data_offset +\n\t\t\t\t\t le16_to_cpu(ext_hdr->usPowerTuneTableOffset));\n\t\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->maximum_power_delivery_limit = 255;\n\t\t\t\tpt = &ppt->power_tune_table;\n\t\t\t}\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->tdp = le16_to_cpu(pt->usTDP);\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->configurable_tdp =\n\t\t\t\tle16_to_cpu(pt->usConfigurableTDP);\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->tdc = le16_to_cpu(pt->usTDC);\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->battery_power_limit =\n\t\t\t\tle16_to_cpu(pt->usBatteryPowerLimit);\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->small_power_limit =\n\t\t\t\tle16_to_cpu(pt->usSmallPowerLimit);\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->low_cac_leakage =\n\t\t\t\tle16_to_cpu(pt->usLowCACLeakage);\n\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table->high_cac_leakage =\n\t\t\t\tle16_to_cpu(pt->usHighCACLeakage);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nvoid r600_free_extended_power_table(struct radeon_device *rdev)\n{\n\tstruct radeon_dpm_dynamic_state *dyn_state = &rdev->pm.dpm.dyn_state;\n\n\tkfree(dyn_state->vddc_dependency_on_sclk.entries);\n\tkfree(dyn_state->vddci_dependency_on_mclk.entries);\n\tkfree(dyn_state->vddc_dependency_on_mclk.entries);\n\tkfree(dyn_state->mvdd_dependency_on_mclk.entries);\n\tkfree(dyn_state->cac_leakage_table.entries);\n\tkfree(dyn_state->phase_shedding_limits_table.entries);\n\tkfree(dyn_state->ppm_table);\n\tkfree(dyn_state->cac_tdp_table);\n\tkfree(dyn_state->vce_clock_voltage_dependency_table.entries);\n\tkfree(dyn_state->uvd_clock_voltage_dependency_table.entries);\n\tkfree(dyn_state->samu_clock_voltage_dependency_table.entries);\n\tkfree(dyn_state->acp_clock_voltage_dependency_table.entries);\n}\n\nenum radeon_pcie_gen r600_get_pcie_gen_support(struct radeon_device *rdev,\n\t\t\t\t\t       u32 sys_mask,\n\t\t\t\t\t       enum radeon_pcie_gen asic_gen,\n\t\t\t\t\t       enum radeon_pcie_gen default_gen)\n{\n\tswitch (asic_gen) {\n\tcase RADEON_PCIE_GEN1:\n\t\treturn RADEON_PCIE_GEN1;\n\tcase RADEON_PCIE_GEN2:\n\t\treturn RADEON_PCIE_GEN2;\n\tcase RADEON_PCIE_GEN3:\n\t\treturn RADEON_PCIE_GEN3;\n\tdefault:\n\t\tif ((sys_mask & RADEON_PCIE_SPEED_80) && (default_gen == RADEON_PCIE_GEN3))\n\t\t\treturn RADEON_PCIE_GEN3;\n\t\telse if ((sys_mask & RADEON_PCIE_SPEED_50) && (default_gen == RADEON_PCIE_GEN2))\n\t\t\treturn RADEON_PCIE_GEN2;\n\t\telse\n\t\t\treturn RADEON_PCIE_GEN1;\n\t}\n\treturn RADEON_PCIE_GEN1;\n}\n\nu16 r600_get_pcie_lane_support(struct radeon_device *rdev,\n\t\t\t       u16 asic_lanes,\n\t\t\t       u16 default_lanes)\n{\n\tswitch (asic_lanes) {\n\tcase 0:\n\tdefault:\n\t\treturn default_lanes;\n\tcase 1:\n\t\treturn 1;\n\tcase 2:\n\t\treturn 2;\n\tcase 4:\n\t\treturn 4;\n\tcase 8:\n\t\treturn 8;\n\tcase 12:\n\t\treturn 12;\n\tcase 16:\n\t\treturn 16;\n\t}\n}\n\nu8 r600_encode_pci_lane_width(u32 lanes)\n{\n\tstatic const u8 encoded_lanes[] = {\n\t\t0, 1, 2, 0, 3, 0, 0, 0, 4, 0, 0, 0, 5, 0, 0, 0, 6\n\t};\n\n\tif (lanes > 16)\n\t\treturn 0;\n\n\treturn encoded_lanes[lanes];\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}