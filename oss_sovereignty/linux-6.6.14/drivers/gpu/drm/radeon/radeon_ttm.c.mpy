{
  "module_name": "radeon_ttm.c",
  "hash_id": "595eae1bd0a47870c5b7e80de474240c685ec04d29e39833862ba06538c5c6db",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/radeon/radeon_ttm.c",
  "human_readable_source": " \n \n\n#include <linux/dma-mapping.h>\n#include <linux/pagemap.h>\n#include <linux/pci.h>\n#include <linux/seq_file.h>\n#include <linux/slab.h>\n#include <linux/swap.h>\n\n#include <drm/drm_device.h>\n#include <drm/drm_file.h>\n#include <drm/drm_prime.h>\n#include <drm/radeon_drm.h>\n#include <drm/ttm/ttm_bo.h>\n#include <drm/ttm/ttm_placement.h>\n#include <drm/ttm/ttm_range_manager.h>\n#include <drm/ttm/ttm_tt.h>\n\n#include \"radeon_reg.h\"\n#include \"radeon.h\"\n#include \"radeon_ttm.h\"\n\nstatic void radeon_ttm_debugfs_init(struct radeon_device *rdev);\n\nstatic int radeon_ttm_tt_bind(struct ttm_device *bdev, struct ttm_tt *ttm,\n\t\t\t      struct ttm_resource *bo_mem);\nstatic void radeon_ttm_tt_unbind(struct ttm_device *bdev, struct ttm_tt *ttm);\n\nstruct radeon_device *radeon_get_rdev(struct ttm_device *bdev)\n{\n\tstruct radeon_mman *mman;\n\tstruct radeon_device *rdev;\n\n\tmman = container_of(bdev, struct radeon_mman, bdev);\n\trdev = container_of(mman, struct radeon_device, mman);\n\treturn rdev;\n}\n\nstatic int radeon_ttm_init_vram(struct radeon_device *rdev)\n{\n\treturn ttm_range_man_init(&rdev->mman.bdev, TTM_PL_VRAM,\n\t\t\t\t  false, rdev->mc.real_vram_size >> PAGE_SHIFT);\n}\n\nstatic int radeon_ttm_init_gtt(struct radeon_device *rdev)\n{\n\treturn ttm_range_man_init(&rdev->mman.bdev, TTM_PL_TT,\n\t\t\t\t  true, rdev->mc.gtt_size >> PAGE_SHIFT);\n}\n\nstatic void radeon_evict_flags(struct ttm_buffer_object *bo,\n\t\t\t\tstruct ttm_placement *placement)\n{\n\tstatic const struct ttm_place placements = {\n\t\t.fpfn = 0,\n\t\t.lpfn = 0,\n\t\t.mem_type = TTM_PL_SYSTEM,\n\t\t.flags = 0\n\t};\n\n\tstruct radeon_bo *rbo;\n\n\tif (!radeon_ttm_bo_is_radeon_bo(bo)) {\n\t\tplacement->placement = &placements;\n\t\tplacement->busy_placement = &placements;\n\t\tplacement->num_placement = 1;\n\t\tplacement->num_busy_placement = 1;\n\t\treturn;\n\t}\n\trbo = container_of(bo, struct radeon_bo, tbo);\n\tswitch (bo->resource->mem_type) {\n\tcase TTM_PL_VRAM:\n\t\tif (rbo->rdev->ring[radeon_copy_ring_index(rbo->rdev)].ready == false)\n\t\t\tradeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_CPU);\n\t\telse if (rbo->rdev->mc.visible_vram_size < rbo->rdev->mc.real_vram_size &&\n\t\t\t bo->resource->start < (rbo->rdev->mc.visible_vram_size >> PAGE_SHIFT)) {\n\t\t\tunsigned fpfn = rbo->rdev->mc.visible_vram_size >> PAGE_SHIFT;\n\t\t\tint i;\n\n\t\t\t \n\t\t\tradeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_VRAM |\n\t\t\t\t\t\t\t RADEON_GEM_DOMAIN_GTT);\n\t\t\trbo->placement.num_busy_placement = 0;\n\t\t\tfor (i = 0; i < rbo->placement.num_placement; i++) {\n\t\t\t\tif (rbo->placements[i].mem_type == TTM_PL_VRAM) {\n\t\t\t\t\tif (rbo->placements[i].fpfn < fpfn)\n\t\t\t\t\t\trbo->placements[i].fpfn = fpfn;\n\t\t\t\t} else {\n\t\t\t\t\trbo->placement.busy_placement =\n\t\t\t\t\t\t&rbo->placements[i];\n\t\t\t\t\trbo->placement.num_busy_placement = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t} else\n\t\t\tradeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_GTT);\n\t\tbreak;\n\tcase TTM_PL_TT:\n\tdefault:\n\t\tradeon_ttm_placement_from_domain(rbo, RADEON_GEM_DOMAIN_CPU);\n\t}\n\t*placement = rbo->placement;\n}\n\nstatic int radeon_move_blit(struct ttm_buffer_object *bo,\n\t\t\tbool evict,\n\t\t\tstruct ttm_resource *new_mem,\n\t\t\tstruct ttm_resource *old_mem)\n{\n\tstruct radeon_device *rdev;\n\tuint64_t old_start, new_start;\n\tstruct radeon_fence *fence;\n\tunsigned num_pages;\n\tint r, ridx;\n\n\trdev = radeon_get_rdev(bo->bdev);\n\tridx = radeon_copy_ring_index(rdev);\n\told_start = (u64)old_mem->start << PAGE_SHIFT;\n\tnew_start = (u64)new_mem->start << PAGE_SHIFT;\n\n\tswitch (old_mem->mem_type) {\n\tcase TTM_PL_VRAM:\n\t\told_start += rdev->mc.vram_start;\n\t\tbreak;\n\tcase TTM_PL_TT:\n\t\told_start += rdev->mc.gtt_start;\n\t\tbreak;\n\tdefault:\n\t\tDRM_ERROR(\"Unknown placement %d\\n\", old_mem->mem_type);\n\t\treturn -EINVAL;\n\t}\n\tswitch (new_mem->mem_type) {\n\tcase TTM_PL_VRAM:\n\t\tnew_start += rdev->mc.vram_start;\n\t\tbreak;\n\tcase TTM_PL_TT:\n\t\tnew_start += rdev->mc.gtt_start;\n\t\tbreak;\n\tdefault:\n\t\tDRM_ERROR(\"Unknown placement %d\\n\", old_mem->mem_type);\n\t\treturn -EINVAL;\n\t}\n\tif (!rdev->ring[ridx].ready) {\n\t\tDRM_ERROR(\"Trying to move memory with ring turned off.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tBUILD_BUG_ON((PAGE_SIZE % RADEON_GPU_PAGE_SIZE) != 0);\n\n\tnum_pages = PFN_UP(new_mem->size) * (PAGE_SIZE / RADEON_GPU_PAGE_SIZE);\n\tfence = radeon_copy(rdev, old_start, new_start, num_pages, bo->base.resv);\n\tif (IS_ERR(fence))\n\t\treturn PTR_ERR(fence);\n\n\tr = ttm_bo_move_accel_cleanup(bo, &fence->base, evict, false, new_mem);\n\tradeon_fence_unref(&fence);\n\treturn r;\n}\n\nstatic int radeon_bo_move(struct ttm_buffer_object *bo, bool evict,\n\t\t\t  struct ttm_operation_ctx *ctx,\n\t\t\t  struct ttm_resource *new_mem,\n\t\t\t  struct ttm_place *hop)\n{\n\tstruct ttm_resource *old_mem = bo->resource;\n\tstruct radeon_device *rdev;\n\tstruct radeon_bo *rbo;\n\tint r;\n\n\tif (new_mem->mem_type == TTM_PL_TT) {\n\t\tr = radeon_ttm_tt_bind(bo->bdev, bo->ttm, new_mem);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tr = ttm_bo_wait_ctx(bo, ctx);\n\tif (r)\n\t\treturn r;\n\n\trbo = container_of(bo, struct radeon_bo, tbo);\n\trdev = radeon_get_rdev(bo->bdev);\n\tif (!old_mem || (old_mem->mem_type == TTM_PL_SYSTEM &&\n\t\t\t bo->ttm == NULL)) {\n\t\tttm_bo_move_null(bo, new_mem);\n\t\tgoto out;\n\t}\n\tif (old_mem->mem_type == TTM_PL_SYSTEM &&\n\t    new_mem->mem_type == TTM_PL_TT) {\n\t\tttm_bo_move_null(bo, new_mem);\n\t\tgoto out;\n\t}\n\n\tif (old_mem->mem_type == TTM_PL_TT &&\n\t    new_mem->mem_type == TTM_PL_SYSTEM) {\n\t\tradeon_ttm_tt_unbind(bo->bdev, bo->ttm);\n\t\tttm_resource_free(bo, &bo->resource);\n\t\tttm_bo_assign_mem(bo, new_mem);\n\t\tgoto out;\n\t}\n\tif (rdev->ring[radeon_copy_ring_index(rdev)].ready &&\n\t    rdev->asic->copy.copy != NULL) {\n\t\tif ((old_mem->mem_type == TTM_PL_SYSTEM &&\n\t\t     new_mem->mem_type == TTM_PL_VRAM) ||\n\t\t    (old_mem->mem_type == TTM_PL_VRAM &&\n\t\t     new_mem->mem_type == TTM_PL_SYSTEM)) {\n\t\t\thop->fpfn = 0;\n\t\t\thop->lpfn = 0;\n\t\t\thop->mem_type = TTM_PL_TT;\n\t\t\thop->flags = 0;\n\t\t\treturn -EMULTIHOP;\n\t\t}\n\n\t\tr = radeon_move_blit(bo, evict, new_mem, old_mem);\n\t} else {\n\t\tr = -ENODEV;\n\t}\n\n\tif (r) {\n\t\tr = ttm_bo_move_memcpy(bo, ctx, new_mem);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\nout:\n\t \n\tatomic64_add(bo->base.size, &rdev->num_bytes_moved);\n\tradeon_bo_move_notify(bo);\n\treturn 0;\n}\n\nstatic int radeon_ttm_io_mem_reserve(struct ttm_device *bdev, struct ttm_resource *mem)\n{\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\tsize_t bus_size = (size_t)mem->size;\n\n\tswitch (mem->mem_type) {\n\tcase TTM_PL_SYSTEM:\n\t\t \n\t\treturn 0;\n\tcase TTM_PL_TT:\n#if IS_ENABLED(CONFIG_AGP)\n\t\tif (rdev->flags & RADEON_IS_AGP) {\n\t\t\t \n\t\t\tmem->bus.offset = (mem->start << PAGE_SHIFT) +\n\t\t\t\trdev->mc.agp_base;\n\t\t\tmem->bus.is_iomem = !rdev->agp->cant_use_aperture;\n\t\t\tmem->bus.caching = ttm_write_combined;\n\t\t}\n#endif\n\t\tbreak;\n\tcase TTM_PL_VRAM:\n\t\tmem->bus.offset = mem->start << PAGE_SHIFT;\n\t\t \n\t\tif ((mem->bus.offset + bus_size) > rdev->mc.visible_vram_size)\n\t\t\treturn -EINVAL;\n\t\tmem->bus.offset += rdev->mc.aper_base;\n\t\tmem->bus.is_iomem = true;\n\t\tmem->bus.caching = ttm_write_combined;\n#ifdef __alpha__\n\t\t \n\t\tmem->bus.addr = ioremap_wc(mem->bus.offset, bus_size);\n\t\tif (!mem->bus.addr)\n\t\t\treturn -ENOMEM;\n\n\t\t \n\t\tmem->bus.offset = (mem->bus.offset & 0x0ffffffffUL) +\n\t\t\trdev->hose->dense_mem_base;\n#endif\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n \nstruct radeon_ttm_tt {\n\tstruct ttm_tt\t\tttm;\n\tu64\t\t\t\toffset;\n\n\tuint64_t\t\t\tuserptr;\n\tstruct mm_struct\t\t*usermm;\n\tuint32_t\t\t\tuserflags;\n\tbool bound;\n};\n\n \nstatic int radeon_ttm_tt_pin_userptr(struct ttm_device *bdev, struct ttm_tt *ttm)\n{\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\tstruct radeon_ttm_tt *gtt = (void *)ttm;\n\tunsigned pinned = 0;\n\tint r;\n\n\tint write = !(gtt->userflags & RADEON_GEM_USERPTR_READONLY);\n\tenum dma_data_direction direction = write ?\n\t\tDMA_BIDIRECTIONAL : DMA_TO_DEVICE;\n\n\tif (current->mm != gtt->usermm)\n\t\treturn -EPERM;\n\n\tif (gtt->userflags & RADEON_GEM_USERPTR_ANONONLY) {\n\t\t \n\t\tunsigned long end = gtt->userptr + (u64)ttm->num_pages * PAGE_SIZE;\n\t\tstruct vm_area_struct *vma;\n\t\tvma = find_vma(gtt->usermm, gtt->userptr);\n\t\tif (!vma || vma->vm_file || vma->vm_end < end)\n\t\t\treturn -EPERM;\n\t}\n\n\tdo {\n\t\tunsigned num_pages = ttm->num_pages - pinned;\n\t\tuint64_t userptr = gtt->userptr + pinned * PAGE_SIZE;\n\t\tstruct page **pages = ttm->pages + pinned;\n\n\t\tr = get_user_pages(userptr, num_pages, write ? FOLL_WRITE : 0,\n\t\t\t\t   pages);\n\t\tif (r < 0)\n\t\t\tgoto release_pages;\n\n\t\tpinned += r;\n\n\t} while (pinned < ttm->num_pages);\n\n\tr = sg_alloc_table_from_pages(ttm->sg, ttm->pages, ttm->num_pages, 0,\n\t\t\t\t      (u64)ttm->num_pages << PAGE_SHIFT,\n\t\t\t\t      GFP_KERNEL);\n\tif (r)\n\t\tgoto release_sg;\n\n\tr = dma_map_sgtable(rdev->dev, ttm->sg, direction, 0);\n\tif (r)\n\t\tgoto release_sg;\n\n\tdrm_prime_sg_to_dma_addr_array(ttm->sg, gtt->ttm.dma_address,\n\t\t\t\t       ttm->num_pages);\n\n\treturn 0;\n\nrelease_sg:\n\tkfree(ttm->sg);\n\nrelease_pages:\n\trelease_pages(ttm->pages, pinned);\n\treturn r;\n}\n\nstatic void radeon_ttm_tt_unpin_userptr(struct ttm_device *bdev, struct ttm_tt *ttm)\n{\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\tstruct radeon_ttm_tt *gtt = (void *)ttm;\n\tstruct sg_page_iter sg_iter;\n\n\tint write = !(gtt->userflags & RADEON_GEM_USERPTR_READONLY);\n\tenum dma_data_direction direction = write ?\n\t\tDMA_BIDIRECTIONAL : DMA_TO_DEVICE;\n\n\t \n\tif (!ttm->sg || !ttm->sg->sgl)\n\t\treturn;\n\n\t \n\tdma_unmap_sgtable(rdev->dev, ttm->sg, direction, 0);\n\n\tfor_each_sgtable_page(ttm->sg, &sg_iter, 0) {\n\t\tstruct page *page = sg_page_iter_page(&sg_iter);\n\t\tif (!(gtt->userflags & RADEON_GEM_USERPTR_READONLY))\n\t\t\tset_page_dirty(page);\n\n\t\tmark_page_accessed(page);\n\t\tput_page(page);\n\t}\n\n\tsg_free_table(ttm->sg);\n}\n\nstatic bool radeon_ttm_backend_is_bound(struct ttm_tt *ttm)\n{\n\tstruct radeon_ttm_tt *gtt = (void*)ttm;\n\n\treturn (gtt->bound);\n}\n\nstatic int radeon_ttm_backend_bind(struct ttm_device *bdev,\n\t\t\t\t   struct ttm_tt *ttm,\n\t\t\t\t   struct ttm_resource *bo_mem)\n{\n\tstruct radeon_ttm_tt *gtt = (void*)ttm;\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\tuint32_t flags = RADEON_GART_PAGE_VALID | RADEON_GART_PAGE_READ |\n\t\tRADEON_GART_PAGE_WRITE;\n\tint r;\n\n\tif (gtt->bound)\n\t\treturn 0;\n\n\tif (gtt->userptr) {\n\t\tradeon_ttm_tt_pin_userptr(bdev, ttm);\n\t\tflags &= ~RADEON_GART_PAGE_WRITE;\n\t}\n\n\tgtt->offset = (unsigned long)(bo_mem->start << PAGE_SHIFT);\n\tif (!ttm->num_pages) {\n\t\tWARN(1, \"nothing to bind %u pages for mreg %p back %p!\\n\",\n\t\t     ttm->num_pages, bo_mem, ttm);\n\t}\n\tif (ttm->caching == ttm_cached)\n\t\tflags |= RADEON_GART_PAGE_SNOOP;\n\tr = radeon_gart_bind(rdev, gtt->offset, ttm->num_pages,\n\t\t\t     ttm->pages, gtt->ttm.dma_address, flags);\n\tif (r) {\n\t\tDRM_ERROR(\"failed to bind %u pages at 0x%08X\\n\",\n\t\t\t  ttm->num_pages, (unsigned)gtt->offset);\n\t\treturn r;\n\t}\n\tgtt->bound = true;\n\treturn 0;\n}\n\nstatic void radeon_ttm_backend_unbind(struct ttm_device *bdev, struct ttm_tt *ttm)\n{\n\tstruct radeon_ttm_tt *gtt = (void *)ttm;\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\n\tif (gtt->userptr)\n\t\tradeon_ttm_tt_unpin_userptr(bdev, ttm);\n\n\tif (!gtt->bound)\n\t\treturn;\n\n\tradeon_gart_unbind(rdev, gtt->offset, ttm->num_pages);\n\n\tgtt->bound = false;\n}\n\nstatic void radeon_ttm_backend_destroy(struct ttm_device *bdev, struct ttm_tt *ttm)\n{\n\tstruct radeon_ttm_tt *gtt = (void *)ttm;\n\n\tttm_tt_fini(&gtt->ttm);\n\tkfree(gtt);\n}\n\nstatic struct ttm_tt *radeon_ttm_tt_create(struct ttm_buffer_object *bo,\n\t\t\t\t\t   uint32_t page_flags)\n{\n\tstruct radeon_ttm_tt *gtt;\n\tenum ttm_caching caching;\n\tstruct radeon_bo *rbo;\n#if IS_ENABLED(CONFIG_AGP)\n\tstruct radeon_device *rdev = radeon_get_rdev(bo->bdev);\n\n\tif (rdev->flags & RADEON_IS_AGP) {\n\t\treturn ttm_agp_tt_create(bo, rdev->agp->bridge, page_flags);\n\t}\n#endif\n\trbo = container_of(bo, struct radeon_bo, tbo);\n\n\tgtt = kzalloc(sizeof(struct radeon_ttm_tt), GFP_KERNEL);\n\tif (gtt == NULL) {\n\t\treturn NULL;\n\t}\n\n\tif (rbo->flags & RADEON_GEM_GTT_UC)\n\t\tcaching = ttm_uncached;\n\telse if (rbo->flags & RADEON_GEM_GTT_WC)\n\t\tcaching = ttm_write_combined;\n\telse\n\t\tcaching = ttm_cached;\n\n\tif (ttm_sg_tt_init(&gtt->ttm, bo, page_flags, caching)) {\n\t\tkfree(gtt);\n\t\treturn NULL;\n\t}\n\treturn &gtt->ttm;\n}\n\nstatic struct radeon_ttm_tt *radeon_ttm_tt_to_gtt(struct radeon_device *rdev,\n\t\t\t\t\t\t  struct ttm_tt *ttm)\n{\n#if IS_ENABLED(CONFIG_AGP)\n\tif (rdev->flags & RADEON_IS_AGP)\n\t\treturn NULL;\n#endif\n\n\tif (!ttm)\n\t\treturn NULL;\n\treturn container_of(ttm, struct radeon_ttm_tt, ttm);\n}\n\nstatic int radeon_ttm_tt_populate(struct ttm_device *bdev,\n\t\t\t\t  struct ttm_tt *ttm,\n\t\t\t\t  struct ttm_operation_ctx *ctx)\n{\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\tstruct radeon_ttm_tt *gtt = radeon_ttm_tt_to_gtt(rdev, ttm);\n\tbool slave = !!(ttm->page_flags & TTM_TT_FLAG_EXTERNAL);\n\n\tif (gtt && gtt->userptr) {\n\t\tttm->sg = kzalloc(sizeof(struct sg_table), GFP_KERNEL);\n\t\tif (!ttm->sg)\n\t\t\treturn -ENOMEM;\n\n\t\tttm->page_flags |= TTM_TT_FLAG_EXTERNAL;\n\t\treturn 0;\n\t}\n\n\tif (slave && ttm->sg) {\n\t\tdrm_prime_sg_to_dma_addr_array(ttm->sg, gtt->ttm.dma_address,\n\t\t\t\t\t       ttm->num_pages);\n\t\treturn 0;\n\t}\n\n\treturn ttm_pool_alloc(&rdev->mman.bdev.pool, ttm, ctx);\n}\n\nstatic void radeon_ttm_tt_unpopulate(struct ttm_device *bdev, struct ttm_tt *ttm)\n{\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\tstruct radeon_ttm_tt *gtt = radeon_ttm_tt_to_gtt(rdev, ttm);\n\tbool slave = !!(ttm->page_flags & TTM_TT_FLAG_EXTERNAL);\n\n\tradeon_ttm_tt_unbind(bdev, ttm);\n\n\tif (gtt && gtt->userptr) {\n\t\tkfree(ttm->sg);\n\t\tttm->page_flags &= ~TTM_TT_FLAG_EXTERNAL;\n\t\treturn;\n\t}\n\n\tif (slave)\n\t\treturn;\n\n\treturn ttm_pool_free(&rdev->mman.bdev.pool, ttm);\n}\n\nint radeon_ttm_tt_set_userptr(struct radeon_device *rdev,\n\t\t\t      struct ttm_tt *ttm, uint64_t addr,\n\t\t\t      uint32_t flags)\n{\n\tstruct radeon_ttm_tt *gtt = radeon_ttm_tt_to_gtt(rdev, ttm);\n\n\tif (gtt == NULL)\n\t\treturn -EINVAL;\n\n\tgtt->userptr = addr;\n\tgtt->usermm = current->mm;\n\tgtt->userflags = flags;\n\treturn 0;\n}\n\nbool radeon_ttm_tt_is_bound(struct ttm_device *bdev,\n\t\t\t    struct ttm_tt *ttm)\n{\n#if IS_ENABLED(CONFIG_AGP)\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\tif (rdev->flags & RADEON_IS_AGP)\n\t\treturn ttm_agp_is_bound(ttm);\n#endif\n\treturn radeon_ttm_backend_is_bound(ttm);\n}\n\nstatic int radeon_ttm_tt_bind(struct ttm_device *bdev,\n\t\t\t      struct ttm_tt *ttm,\n\t\t\t      struct ttm_resource *bo_mem)\n{\n#if IS_ENABLED(CONFIG_AGP)\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n#endif\n\n\tif (!bo_mem)\n\t\treturn -EINVAL;\n#if IS_ENABLED(CONFIG_AGP)\n\tif (rdev->flags & RADEON_IS_AGP)\n\t\treturn ttm_agp_bind(ttm, bo_mem);\n#endif\n\n\treturn radeon_ttm_backend_bind(bdev, ttm, bo_mem);\n}\n\nstatic void radeon_ttm_tt_unbind(struct ttm_device *bdev,\n\t\t\t\t struct ttm_tt *ttm)\n{\n#if IS_ENABLED(CONFIG_AGP)\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\n\tif (rdev->flags & RADEON_IS_AGP) {\n\t\tttm_agp_unbind(ttm);\n\t\treturn;\n\t}\n#endif\n\tradeon_ttm_backend_unbind(bdev, ttm);\n}\n\nstatic void radeon_ttm_tt_destroy(struct ttm_device *bdev,\n\t\t\t\t  struct ttm_tt *ttm)\n{\n#if IS_ENABLED(CONFIG_AGP)\n\tstruct radeon_device *rdev = radeon_get_rdev(bdev);\n\n\tif (rdev->flags & RADEON_IS_AGP) {\n\t\tttm_agp_destroy(ttm);\n\t\treturn;\n\t}\n#endif\n\tradeon_ttm_backend_destroy(bdev, ttm);\n}\n\nbool radeon_ttm_tt_has_userptr(struct radeon_device *rdev,\n\t\t\t       struct ttm_tt *ttm)\n{\n\tstruct radeon_ttm_tt *gtt = radeon_ttm_tt_to_gtt(rdev, ttm);\n\n\tif (gtt == NULL)\n\t\treturn false;\n\n\treturn !!gtt->userptr;\n}\n\nbool radeon_ttm_tt_is_readonly(struct radeon_device *rdev,\n\t\t\t       struct ttm_tt *ttm)\n{\n\tstruct radeon_ttm_tt *gtt = radeon_ttm_tt_to_gtt(rdev, ttm);\n\n\tif (gtt == NULL)\n\t\treturn false;\n\n\treturn !!(gtt->userflags & RADEON_GEM_USERPTR_READONLY);\n}\n\nstatic struct ttm_device_funcs radeon_bo_driver = {\n\t.ttm_tt_create = &radeon_ttm_tt_create,\n\t.ttm_tt_populate = &radeon_ttm_tt_populate,\n\t.ttm_tt_unpopulate = &radeon_ttm_tt_unpopulate,\n\t.ttm_tt_destroy = &radeon_ttm_tt_destroy,\n\t.eviction_valuable = ttm_bo_eviction_valuable,\n\t.evict_flags = &radeon_evict_flags,\n\t.move = &radeon_bo_move,\n\t.io_mem_reserve = &radeon_ttm_io_mem_reserve,\n};\n\nint radeon_ttm_init(struct radeon_device *rdev)\n{\n\tint r;\n\n\t \n\tr = ttm_device_init(&rdev->mman.bdev, &radeon_bo_driver, rdev->dev,\n\t\t\t       rdev->ddev->anon_inode->i_mapping,\n\t\t\t       rdev->ddev->vma_offset_manager,\n\t\t\t       rdev->need_swiotlb,\n\t\t\t       dma_addressing_limited(&rdev->pdev->dev));\n\tif (r) {\n\t\tDRM_ERROR(\"failed initializing buffer object driver(%d).\\n\", r);\n\t\treturn r;\n\t}\n\trdev->mman.initialized = true;\n\n\tr = radeon_ttm_init_vram(rdev);\n\tif (r) {\n\t\tDRM_ERROR(\"Failed initializing VRAM heap.\\n\");\n\t\treturn r;\n\t}\n\t \n\tradeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);\n\n\tr = radeon_bo_create(rdev, 256 * 1024, PAGE_SIZE, true,\n\t\t\t     RADEON_GEM_DOMAIN_VRAM, 0, NULL,\n\t\t\t     NULL, &rdev->stolen_vga_memory);\n\tif (r) {\n\t\treturn r;\n\t}\n\tr = radeon_bo_reserve(rdev->stolen_vga_memory, false);\n\tif (r)\n\t\treturn r;\n\tr = radeon_bo_pin(rdev->stolen_vga_memory, RADEON_GEM_DOMAIN_VRAM, NULL);\n\tradeon_bo_unreserve(rdev->stolen_vga_memory);\n\tif (r) {\n\t\tradeon_bo_unref(&rdev->stolen_vga_memory);\n\t\treturn r;\n\t}\n\tDRM_INFO(\"radeon: %uM of VRAM memory ready\\n\",\n\t\t (unsigned) (rdev->mc.real_vram_size / (1024 * 1024)));\n\n\tr = radeon_ttm_init_gtt(rdev);\n\tif (r) {\n\t\tDRM_ERROR(\"Failed initializing GTT heap.\\n\");\n\t\treturn r;\n\t}\n\tDRM_INFO(\"radeon: %uM of GTT memory ready.\\n\",\n\t\t (unsigned)(rdev->mc.gtt_size / (1024 * 1024)));\n\n\tradeon_ttm_debugfs_init(rdev);\n\n\treturn 0;\n}\n\nvoid radeon_ttm_fini(struct radeon_device *rdev)\n{\n\tint r;\n\n\tif (!rdev->mman.initialized)\n\t\treturn;\n\n\tif (rdev->stolen_vga_memory) {\n\t\tr = radeon_bo_reserve(rdev->stolen_vga_memory, false);\n\t\tif (r == 0) {\n\t\t\tradeon_bo_unpin(rdev->stolen_vga_memory);\n\t\t\tradeon_bo_unreserve(rdev->stolen_vga_memory);\n\t\t}\n\t\tradeon_bo_unref(&rdev->stolen_vga_memory);\n\t}\n\tttm_range_man_fini(&rdev->mman.bdev, TTM_PL_VRAM);\n\tttm_range_man_fini(&rdev->mman.bdev, TTM_PL_TT);\n\tttm_device_fini(&rdev->mman.bdev);\n\tradeon_gart_fini(rdev);\n\trdev->mman.initialized = false;\n\tDRM_INFO(\"radeon: ttm finalized\\n\");\n}\n\n \nvoid radeon_ttm_set_active_vram_size(struct radeon_device *rdev, u64 size)\n{\n\tstruct ttm_resource_manager *man;\n\n\tif (!rdev->mman.initialized)\n\t\treturn;\n\n\tman = ttm_manager_type(&rdev->mman.bdev, TTM_PL_VRAM);\n\t \n\tman->size = size >> PAGE_SHIFT;\n}\n\n#if defined(CONFIG_DEBUG_FS)\n\nstatic int radeon_ttm_page_pool_show(struct seq_file *m, void *data)\n{\n\tstruct radeon_device *rdev = m->private;\n\n\treturn ttm_pool_debugfs(&rdev->mman.bdev.pool, m);\n}\n\nDEFINE_SHOW_ATTRIBUTE(radeon_ttm_page_pool);\n\nstatic int radeon_ttm_vram_open(struct inode *inode, struct file *filep)\n{\n\tstruct radeon_device *rdev = inode->i_private;\n\ti_size_write(inode, rdev->mc.mc_vram_size);\n\tfilep->private_data = inode->i_private;\n\treturn 0;\n}\n\nstatic ssize_t radeon_ttm_vram_read(struct file *f, char __user *buf,\n\t\t\t\t    size_t size, loff_t *pos)\n{\n\tstruct radeon_device *rdev = f->private_data;\n\tssize_t result = 0;\n\tint r;\n\n\tif (size & 0x3 || *pos & 0x3)\n\t\treturn -EINVAL;\n\n\twhile (size) {\n\t\tunsigned long flags;\n\t\tuint32_t value;\n\n\t\tif (*pos >= rdev->mc.mc_vram_size)\n\t\t\treturn result;\n\n\t\tspin_lock_irqsave(&rdev->mmio_idx_lock, flags);\n\t\tWREG32(RADEON_MM_INDEX, ((uint32_t)*pos) | 0x80000000);\n\t\tif (rdev->family >= CHIP_CEDAR)\n\t\t\tWREG32(EVERGREEN_MM_INDEX_HI, *pos >> 31);\n\t\tvalue = RREG32(RADEON_MM_DATA);\n\t\tspin_unlock_irqrestore(&rdev->mmio_idx_lock, flags);\n\n\t\tr = put_user(value, (uint32_t __user *)buf);\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tresult += 4;\n\t\tbuf += 4;\n\t\t*pos += 4;\n\t\tsize -= 4;\n\t}\n\n\treturn result;\n}\n\nstatic const struct file_operations radeon_ttm_vram_fops = {\n\t.owner = THIS_MODULE,\n\t.open = radeon_ttm_vram_open,\n\t.read = radeon_ttm_vram_read,\n\t.llseek = default_llseek\n};\n\nstatic int radeon_ttm_gtt_open(struct inode *inode, struct file *filep)\n{\n\tstruct radeon_device *rdev = inode->i_private;\n\ti_size_write(inode, rdev->mc.gtt_size);\n\tfilep->private_data = inode->i_private;\n\treturn 0;\n}\n\nstatic ssize_t radeon_ttm_gtt_read(struct file *f, char __user *buf,\n\t\t\t\t   size_t size, loff_t *pos)\n{\n\tstruct radeon_device *rdev = f->private_data;\n\tssize_t result = 0;\n\tint r;\n\n\twhile (size) {\n\t\tloff_t p = *pos / PAGE_SIZE;\n\t\tunsigned off = *pos & ~PAGE_MASK;\n\t\tsize_t cur_size = min_t(size_t, size, PAGE_SIZE - off);\n\t\tstruct page *page;\n\t\tvoid *ptr;\n\n\t\tif (p >= rdev->gart.num_cpu_pages)\n\t\t\treturn result;\n\n\t\tpage = rdev->gart.pages[p];\n\t\tif (page) {\n\t\t\tptr = kmap_local_page(page);\n\t\t\tptr += off;\n\n\t\t\tr = copy_to_user(buf, ptr, cur_size);\n\t\t\tkunmap_local(ptr);\n\t\t} else\n\t\t\tr = clear_user(buf, cur_size);\n\n\t\tif (r)\n\t\t\treturn -EFAULT;\n\n\t\tresult += cur_size;\n\t\tbuf += cur_size;\n\t\t*pos += cur_size;\n\t\tsize -= cur_size;\n\t}\n\n\treturn result;\n}\n\nstatic const struct file_operations radeon_ttm_gtt_fops = {\n\t.owner = THIS_MODULE,\n\t.open = radeon_ttm_gtt_open,\n\t.read = radeon_ttm_gtt_read,\n\t.llseek = default_llseek\n};\n\n#endif\n\nstatic void radeon_ttm_debugfs_init(struct radeon_device *rdev)\n{\n#if defined(CONFIG_DEBUG_FS)\n\tstruct drm_minor *minor = rdev->ddev->primary;\n\tstruct dentry *root = minor->debugfs_root;\n\n\tdebugfs_create_file(\"radeon_vram\", 0444, root, rdev,\n\t\t\t    &radeon_ttm_vram_fops);\n\tdebugfs_create_file(\"radeon_gtt\", 0444, root, rdev,\n\t\t\t    &radeon_ttm_gtt_fops);\n\tdebugfs_create_file(\"ttm_page_pool\", 0444, root, rdev,\n\t\t\t    &radeon_ttm_page_pool_fops);\n\tttm_resource_manager_create_debugfs(ttm_manager_type(&rdev->mman.bdev,\n\t\t\t\t\t\t\t     TTM_PL_VRAM),\n\t\t\t\t\t    root, \"radeon_vram_mm\");\n\tttm_resource_manager_create_debugfs(ttm_manager_type(&rdev->mman.bdev,\n\t\t\t\t\t\t\t     TTM_PL_TT),\n\t\t\t\t\t    root, \"radeon_gtt_mm\");\n#endif\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}