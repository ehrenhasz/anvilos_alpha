{
  "module_name": "ci_dpm.c",
  "hash_id": "532f9847119dee0b3abfacf60a134e601dc7753f239360454bf9b728926b63f1",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/radeon/ci_dpm.c",
  "human_readable_source": " \n\n#include <linux/firmware.h>\n#include <linux/pci.h>\n#include <linux/seq_file.h>\n\n#include \"atom.h\"\n#include \"ci_dpm.h\"\n#include \"cik.h\"\n#include \"cikd.h\"\n#include \"r600_dpm.h\"\n#include \"radeon.h\"\n#include \"radeon_asic.h\"\n#include \"radeon_ucode.h\"\n#include \"si_dpm.h\"\n\n#define MC_CG_ARB_FREQ_F0           0x0a\n#define MC_CG_ARB_FREQ_F1           0x0b\n#define MC_CG_ARB_FREQ_F2           0x0c\n#define MC_CG_ARB_FREQ_F3           0x0d\n\n#define SMC_RAM_END 0x40000\n\n#define VOLTAGE_SCALE               4\n#define VOLTAGE_VID_OFFSET_SCALE1    625\n#define VOLTAGE_VID_OFFSET_SCALE2    100\n\nstatic const struct ci_pt_defaults defaults_hawaii_xt =\n{\n\t1, 0xF, 0xFD, 0x19, 5, 0x14, 0, 0xB0000,\n\t{ 0x2E,  0x00,  0x00,  0x88,  0x00,  0x00,  0x72,  0x60,  0x51,  0xA7,  0x79,  0x6B,  0x90,  0xBD,  0x79  },\n\t{ 0x217, 0x217, 0x217, 0x242, 0x242, 0x242, 0x269, 0x269, 0x269, 0x2A1, 0x2A1, 0x2A1, 0x2C9, 0x2C9, 0x2C9 }\n};\n\nstatic const struct ci_pt_defaults defaults_hawaii_pro =\n{\n\t1, 0xF, 0xFD, 0x19, 5, 0x14, 0, 0x65062,\n\t{ 0x2E,  0x00,  0x00,  0x88,  0x00,  0x00,  0x72,  0x60,  0x51,  0xA7,  0x79,  0x6B,  0x90,  0xBD,  0x79  },\n\t{ 0x217, 0x217, 0x217, 0x242, 0x242, 0x242, 0x269, 0x269, 0x269, 0x2A1, 0x2A1, 0x2A1, 0x2C9, 0x2C9, 0x2C9 }\n};\n\nstatic const struct ci_pt_defaults defaults_bonaire_xt =\n{\n\t1, 0xF, 0xFD, 0x19, 5, 45, 0, 0xB0000,\n\t{ 0x79,  0x253, 0x25D, 0xAE,  0x72,  0x80,  0x83,  0x86,  0x6F,  0xC8,  0xC9,  0xC9,  0x2F,  0x4D,  0x61  },\n\t{ 0x17C, 0x172, 0x180, 0x1BC, 0x1B3, 0x1BD, 0x206, 0x200, 0x203, 0x25D, 0x25A, 0x255, 0x2C3, 0x2C5, 0x2B4 }\n};\n\nstatic const struct ci_pt_defaults defaults_saturn_xt =\n{\n\t1, 0xF, 0xFD, 0x19, 5, 55, 0, 0x70000,\n\t{ 0x8C,  0x247, 0x249, 0xA6,  0x80,  0x81,  0x8B,  0x89,  0x86,  0xC9,  0xCA,  0xC9,  0x4D,  0x4D,  0x4D  },\n\t{ 0x187, 0x187, 0x187, 0x1C7, 0x1C7, 0x1C7, 0x210, 0x210, 0x210, 0x266, 0x266, 0x266, 0x2C9, 0x2C9, 0x2C9 }\n};\n\nstatic const struct ci_pt_config_reg didt_config_ci[] =\n{\n\t{ 0x10, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x10, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x10, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x10, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x11, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x12, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x2, 0x00003fff, 0, 0x4, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x2, 0x03ff0000, 16, 0x80, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x2, 0x78000000, 27, 0x3, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x1, 0x0000ffff, 0, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x1, 0xffff0000, 16, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x0, 0x00000001, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x30, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x31, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x32, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x22, 0x00003fff, 0, 0x4, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x22, 0x03ff0000, 16, 0x80, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x22, 0x78000000, 27, 0x3, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x21, 0x0000ffff, 0, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x21, 0xffff0000, 16, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x20, 0x00000001, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x50, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x51, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x52, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x42, 0x00003fff, 0, 0x4, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x42, 0x03ff0000, 16, 0x80, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x42, 0x78000000, 27, 0x3, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x41, 0x0000ffff, 0, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x41, 0xffff0000, 16, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x40, 0x00000001, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x70, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x71, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0x000000ff, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0x0000ff00, 8, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0x00ff0000, 16, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x72, 0xff000000, 24, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x62, 0x00003fff, 0, 0x4, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x62, 0x03ff0000, 16, 0x80, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x62, 0x78000000, 27, 0x3, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x61, 0x0000ffff, 0, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x61, 0xffff0000, 16, 0x3FFF, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0x60, 0x00000001, 0, 0x0, CISLANDS_CONFIGREG_DIDT_IND },\n\t{ 0xFFFFFFFF }\n};\n\nextern u8 rv770_get_memory_module_index(struct radeon_device *rdev);\nextern int ni_copy_and_switch_arb_sets(struct radeon_device *rdev,\n\t\t\t\t       u32 arb_freq_src, u32 arb_freq_dest);\nstatic int ci_get_std_voltage_value_sidd(struct radeon_device *rdev,\n\t\t\t\t\t struct atom_voltage_table_entry *voltage_table,\n\t\t\t\t\t u16 *std_voltage_hi_sidd, u16 *std_voltage_lo_sidd);\nstatic int ci_set_power_limit(struct radeon_device *rdev, u32 n);\nstatic int ci_set_overdrive_target_tdp(struct radeon_device *rdev,\n\t\t\t\t       u32 target_tdp);\nstatic int ci_update_uvd_dpm(struct radeon_device *rdev, bool gate);\n\nstatic PPSMC_Result ci_send_msg_to_smc(struct radeon_device *rdev, PPSMC_Msg msg);\nstatic PPSMC_Result ci_send_msg_to_smc_with_parameter(struct radeon_device *rdev,\n\t\t\t\t\t\t      PPSMC_Msg msg, u32 parameter);\n\nstatic void ci_thermal_start_smc_fan_control(struct radeon_device *rdev);\nstatic void ci_fan_ctrl_set_default_mode(struct radeon_device *rdev);\n\nstatic struct ci_power_info *ci_get_pi(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = rdev->pm.dpm.priv;\n\n\treturn pi;\n}\n\nstatic struct ci_ps *ci_get_ps(struct radeon_ps *rps)\n{\n\tstruct ci_ps *ps = rps->ps_priv;\n\n\treturn ps;\n}\n\nstatic void ci_initialize_powertune_defaults(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tswitch (rdev->pdev->device) {\n\tcase 0x6649:\n\tcase 0x6650:\n\tcase 0x6651:\n\tcase 0x6658:\n\tcase 0x665C:\n\tcase 0x665D:\n\tdefault:\n\t\tpi->powertune_defaults = &defaults_bonaire_xt;\n\t\tbreak;\n\tcase 0x6640:\n\tcase 0x6641:\n\tcase 0x6646:\n\tcase 0x6647:\n\t\tpi->powertune_defaults = &defaults_saturn_xt;\n\t\tbreak;\n\tcase 0x67B8:\n\tcase 0x67B0:\n\t\tpi->powertune_defaults = &defaults_hawaii_xt;\n\t\tbreak;\n\tcase 0x67BA:\n\tcase 0x67B1:\n\t\tpi->powertune_defaults = &defaults_hawaii_pro;\n\t\tbreak;\n\tcase 0x67A0:\n\tcase 0x67A1:\n\tcase 0x67A2:\n\tcase 0x67A8:\n\tcase 0x67A9:\n\tcase 0x67AA:\n\tcase 0x67B9:\n\tcase 0x67BE:\n\t\tpi->powertune_defaults = &defaults_bonaire_xt;\n\t\tbreak;\n\t}\n\n\tpi->dte_tj_offset = 0;\n\n\tpi->caps_power_containment = true;\n\tpi->caps_cac = false;\n\tpi->caps_sq_ramping = false;\n\tpi->caps_db_ramping = false;\n\tpi->caps_td_ramping = false;\n\tpi->caps_tcp_ramping = false;\n\n\tif (pi->caps_power_containment) {\n\t\tpi->caps_cac = true;\n\t\tif (rdev->family == CHIP_HAWAII)\n\t\t\tpi->enable_bapm_feature = false;\n\t\telse\n\t\t\tpi->enable_bapm_feature = true;\n\t\tpi->enable_tdc_limit_feature = true;\n\t\tpi->enable_pkg_pwr_tracking_feature = true;\n\t}\n}\n\nstatic u8 ci_convert_to_vid(u16 vddc)\n{\n\treturn (6200 - (vddc * VOLTAGE_SCALE)) / 25;\n}\n\nstatic int ci_populate_bapm_vddc_vid_sidd(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu8 *hi_vid = pi->smc_powertune_table.BapmVddCVidHiSidd;\n\tu8 *lo_vid = pi->smc_powertune_table.BapmVddCVidLoSidd;\n\tu8 *hi2_vid = pi->smc_powertune_table.BapmVddCVidHiSidd2;\n\tu32 i;\n\n\tif (rdev->pm.dpm.dyn_state.cac_leakage_table.entries == NULL)\n\t\treturn -EINVAL;\n\tif (rdev->pm.dpm.dyn_state.cac_leakage_table.count > 8)\n\t\treturn -EINVAL;\n\tif (rdev->pm.dpm.dyn_state.cac_leakage_table.count !=\n\t    rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < rdev->pm.dpm.dyn_state.cac_leakage_table.count; i++) {\n\t\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_EVV) {\n\t\t\tlo_vid[i] = ci_convert_to_vid(rdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc1);\n\t\t\thi_vid[i] = ci_convert_to_vid(rdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc2);\n\t\t\thi2_vid[i] = ci_convert_to_vid(rdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc3);\n\t\t} else {\n\t\t\tlo_vid[i] = ci_convert_to_vid(rdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].vddc);\n\t\t\thi_vid[i] = ci_convert_to_vid((u16)rdev->pm.dpm.dyn_state.cac_leakage_table.entries[i].leakage);\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int ci_populate_vddc_vid(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu8 *vid = pi->smc_powertune_table.VddCVid;\n\tu32 i;\n\n\tif (pi->vddc_voltage_table.count > 8)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < pi->vddc_voltage_table.count; i++)\n\t\tvid[i] = ci_convert_to_vid(pi->vddc_voltage_table.entries[i].value);\n\n\treturn 0;\n}\n\nstatic int ci_populate_svi_load_line(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct ci_pt_defaults *pt_defaults = pi->powertune_defaults;\n\n\tpi->smc_powertune_table.SviLoadLineEn = pt_defaults->svi_load_line_en;\n\tpi->smc_powertune_table.SviLoadLineVddC = pt_defaults->svi_load_line_vddc;\n\tpi->smc_powertune_table.SviLoadLineTrimVddC = 3;\n\tpi->smc_powertune_table.SviLoadLineOffsetVddC = 0;\n\n\treturn 0;\n}\n\nstatic int ci_populate_tdc_limit(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct ci_pt_defaults *pt_defaults = pi->powertune_defaults;\n\tu16 tdc_limit;\n\n\ttdc_limit = rdev->pm.dpm.dyn_state.cac_tdp_table->tdc * 256;\n\tpi->smc_powertune_table.TDC_VDDC_PkgLimit = cpu_to_be16(tdc_limit);\n\tpi->smc_powertune_table.TDC_VDDC_ThrottleReleaseLimitPerc =\n\t\tpt_defaults->tdc_vddc_throttle_release_limit_perc;\n\tpi->smc_powertune_table.TDC_MAWt = pt_defaults->tdc_mawt;\n\n\treturn 0;\n}\n\nstatic int ci_populate_dw8(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct ci_pt_defaults *pt_defaults = pi->powertune_defaults;\n\tint ret;\n\n\tret = ci_read_smc_sram_dword(rdev,\n\t\t\t\t     SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, PmFuseTable) +\n\t\t\t\t     offsetof(SMU7_Discrete_PmFuses, TdcWaterfallCtl),\n\t\t\t\t     (u32 *)&pi->smc_powertune_table.TdcWaterfallCtl,\n\t\t\t\t     pi->sram_end);\n\tif (ret)\n\t\treturn -EINVAL;\n\telse\n\t\tpi->smc_powertune_table.TdcWaterfallCtl = pt_defaults->tdc_waterfall_ctl;\n\n\treturn 0;\n}\n\nstatic int ci_populate_fuzzy_fan(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif ((rdev->pm.dpm.fan.fan_output_sensitivity & (1 << 15)) ||\n\t    (rdev->pm.dpm.fan.fan_output_sensitivity == 0))\n\t\trdev->pm.dpm.fan.fan_output_sensitivity =\n\t\t\trdev->pm.dpm.fan.default_fan_output_sensitivity;\n\n\tpi->smc_powertune_table.FuzzyFan_PwmSetDelta =\n\t\tcpu_to_be16(rdev->pm.dpm.fan.fan_output_sensitivity);\n\n\treturn 0;\n}\n\nstatic int ci_min_max_v_gnbl_pm_lid_from_bapm_vddc(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu8 *hi_vid = pi->smc_powertune_table.BapmVddCVidHiSidd;\n\tu8 *lo_vid = pi->smc_powertune_table.BapmVddCVidLoSidd;\n\tint i, min, max;\n\n\tmin = max = hi_vid[0];\n\tfor (i = 0; i < 8; i++) {\n\t\tif (0 != hi_vid[i]) {\n\t\t\tif (min > hi_vid[i])\n\t\t\t\tmin = hi_vid[i];\n\t\t\tif (max < hi_vid[i])\n\t\t\t\tmax = hi_vid[i];\n\t\t}\n\n\t\tif (0 != lo_vid[i]) {\n\t\t\tif (min > lo_vid[i])\n\t\t\t\tmin = lo_vid[i];\n\t\t\tif (max < lo_vid[i])\n\t\t\t\tmax = lo_vid[i];\n\t\t}\n\t}\n\n\tif ((min == 0) || (max == 0))\n\t\treturn -EINVAL;\n\tpi->smc_powertune_table.GnbLPMLMaxVid = (u8)max;\n\tpi->smc_powertune_table.GnbLPMLMinVid = (u8)min;\n\n\treturn 0;\n}\n\nstatic int ci_populate_bapm_vddc_base_leakage_sidd(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu16 hi_sidd, lo_sidd;\n\tstruct radeon_cac_tdp_table *cac_tdp_table =\n\t\trdev->pm.dpm.dyn_state.cac_tdp_table;\n\n\thi_sidd = cac_tdp_table->high_cac_leakage / 100 * 256;\n\tlo_sidd = cac_tdp_table->low_cac_leakage / 100 * 256;\n\n\tpi->smc_powertune_table.BapmVddCBaseLeakageHiSidd = cpu_to_be16(hi_sidd);\n\tpi->smc_powertune_table.BapmVddCBaseLeakageLoSidd = cpu_to_be16(lo_sidd);\n\n\treturn 0;\n}\n\nstatic int ci_populate_bapm_parameters_in_dpm_table(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct ci_pt_defaults *pt_defaults = pi->powertune_defaults;\n\tSMU7_Discrete_DpmTable  *dpm_table = &pi->smc_state_table;\n\tstruct radeon_cac_tdp_table *cac_tdp_table =\n\t\trdev->pm.dpm.dyn_state.cac_tdp_table;\n\tstruct radeon_ppm_table *ppm = rdev->pm.dpm.dyn_state.ppm_table;\n\tint i, j, k;\n\tconst u16 *def1;\n\tconst u16 *def2;\n\n\tdpm_table->DefaultTdp = cac_tdp_table->tdp * 256;\n\tdpm_table->TargetTdp = cac_tdp_table->configurable_tdp * 256;\n\n\tdpm_table->DTETjOffset = (u8)pi->dte_tj_offset;\n\tdpm_table->GpuTjMax =\n\t\t(u8)(pi->thermal_temp_setting.temperature_high / 1000);\n\tdpm_table->GpuTjHyst = 8;\n\n\tdpm_table->DTEAmbientTempBase = pt_defaults->dte_ambient_temp_base;\n\n\tif (ppm) {\n\t\tdpm_table->PPM_PkgPwrLimit = cpu_to_be16((u16)ppm->dgpu_tdp * 256 / 1000);\n\t\tdpm_table->PPM_TemperatureLimit = cpu_to_be16((u16)ppm->tj_max * 256);\n\t} else {\n\t\tdpm_table->PPM_PkgPwrLimit = cpu_to_be16(0);\n\t\tdpm_table->PPM_TemperatureLimit = cpu_to_be16(0);\n\t}\n\n\tdpm_table->BAPM_TEMP_GRADIENT = cpu_to_be32(pt_defaults->bapm_temp_gradient);\n\tdef1 = pt_defaults->bapmti_r;\n\tdef2 = pt_defaults->bapmti_rc;\n\n\tfor (i = 0; i < SMU7_DTE_ITERATIONS; i++) {\n\t\tfor (j = 0; j < SMU7_DTE_SOURCES; j++) {\n\t\t\tfor (k = 0; k < SMU7_DTE_SINKS; k++) {\n\t\t\t\tdpm_table->BAPMTI_R[i][j][k] = cpu_to_be16(*def1);\n\t\t\t\tdpm_table->BAPMTI_RC[i][j][k] = cpu_to_be16(*def2);\n\t\t\t\tdef1++;\n\t\t\t\tdef2++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_populate_pm_base(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 pm_fuse_table_offset;\n\tint ret;\n\n\tif (pi->caps_power_containment) {\n\t\tret = ci_read_smc_sram_dword(rdev,\n\t\t\t\t\t     SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t\t     offsetof(SMU7_Firmware_Header, PmFuseTable),\n\t\t\t\t\t     &pm_fuse_table_offset, pi->sram_end);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_populate_bapm_vddc_vid_sidd(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_populate_vddc_vid(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_populate_svi_load_line(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_populate_tdc_limit(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_populate_dw8(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_populate_fuzzy_fan(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_min_max_v_gnbl_pm_lid_from_bapm_vddc(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_populate_bapm_vddc_base_leakage_sidd(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = ci_copy_bytes_to_smc(rdev, pm_fuse_table_offset,\n\t\t\t\t\t   (u8 *)&pi->smc_powertune_table,\n\t\t\t\t\t   sizeof(SMU7_Discrete_PmFuses), pi->sram_end);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void ci_do_enable_didt(struct radeon_device *rdev, const bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 data;\n\n\tif (pi->caps_sq_ramping) {\n\t\tdata = RREG32_DIDT(DIDT_SQ_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_CTRL_EN;\n\t\telse\n\t\t\tdata &= ~DIDT_CTRL_EN;\n\t\tWREG32_DIDT(DIDT_SQ_CTRL0, data);\n\t}\n\n\tif (pi->caps_db_ramping) {\n\t\tdata = RREG32_DIDT(DIDT_DB_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_CTRL_EN;\n\t\telse\n\t\t\tdata &= ~DIDT_CTRL_EN;\n\t\tWREG32_DIDT(DIDT_DB_CTRL0, data);\n\t}\n\n\tif (pi->caps_td_ramping) {\n\t\tdata = RREG32_DIDT(DIDT_TD_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_CTRL_EN;\n\t\telse\n\t\t\tdata &= ~DIDT_CTRL_EN;\n\t\tWREG32_DIDT(DIDT_TD_CTRL0, data);\n\t}\n\n\tif (pi->caps_tcp_ramping) {\n\t\tdata = RREG32_DIDT(DIDT_TCP_CTRL0);\n\t\tif (enable)\n\t\t\tdata |= DIDT_CTRL_EN;\n\t\telse\n\t\t\tdata &= ~DIDT_CTRL_EN;\n\t\tWREG32_DIDT(DIDT_TCP_CTRL0, data);\n\t}\n}\n\nstatic int ci_program_pt_config_registers(struct radeon_device *rdev,\n\t\t\t\t\t  const struct ci_pt_config_reg *cac_config_regs)\n{\n\tconst struct ci_pt_config_reg *config_regs = cac_config_regs;\n\tu32 data;\n\tu32 cache = 0;\n\n\tif (config_regs == NULL)\n\t\treturn -EINVAL;\n\n\twhile (config_regs->offset != 0xFFFFFFFF) {\n\t\tif (config_regs->type == CISLANDS_CONFIGREG_CACHE) {\n\t\t\tcache |= ((config_regs->value << config_regs->shift) & config_regs->mask);\n\t\t} else {\n\t\t\tswitch (config_regs->type) {\n\t\t\tcase CISLANDS_CONFIGREG_SMC_IND:\n\t\t\t\tdata = RREG32_SMC(config_regs->offset);\n\t\t\t\tbreak;\n\t\t\tcase CISLANDS_CONFIGREG_DIDT_IND:\n\t\t\t\tdata = RREG32_DIDT(config_regs->offset);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tdata = RREG32(config_regs->offset << 2);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tdata &= ~config_regs->mask;\n\t\t\tdata |= ((config_regs->value << config_regs->shift) & config_regs->mask);\n\t\t\tdata |= cache;\n\n\t\t\tswitch (config_regs->type) {\n\t\t\tcase CISLANDS_CONFIGREG_SMC_IND:\n\t\t\t\tWREG32_SMC(config_regs->offset, data);\n\t\t\t\tbreak;\n\t\t\tcase CISLANDS_CONFIGREG_DIDT_IND:\n\t\t\t\tWREG32_DIDT(config_regs->offset, data);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tWREG32(config_regs->offset << 2, data);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcache = 0;\n\t\t}\n\t\tconfig_regs++;\n\t}\n\treturn 0;\n}\n\nstatic int ci_enable_didt(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret;\n\n\tif (pi->caps_sq_ramping || pi->caps_db_ramping ||\n\t    pi->caps_td_ramping || pi->caps_tcp_ramping) {\n\t\tcik_enter_rlc_safe_mode(rdev);\n\n\t\tif (enable) {\n\t\t\tret = ci_program_pt_config_registers(rdev, didt_config_ci);\n\t\t\tif (ret) {\n\t\t\t\tcik_exit_rlc_safe_mode(rdev);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\tci_do_enable_didt(rdev, enable);\n\n\t\tcik_exit_rlc_safe_mode(rdev);\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_enable_power_containment(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result;\n\tint ret = 0;\n\n\tif (enable) {\n\t\tpi->power_containment_features = 0;\n\t\tif (pi->caps_power_containment) {\n\t\t\tif (pi->enable_bapm_feature) {\n\t\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_EnableDTE);\n\t\t\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\telse\n\t\t\t\t\tpi->power_containment_features |= POWERCONTAINMENT_FEATURE_BAPM;\n\t\t\t}\n\n\t\t\tif (pi->enable_tdc_limit_feature) {\n\t\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_TDCLimitEnable);\n\t\t\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\telse\n\t\t\t\t\tpi->power_containment_features |= POWERCONTAINMENT_FEATURE_TDCLimit;\n\t\t\t}\n\n\t\t\tif (pi->enable_pkg_pwr_tracking_feature) {\n\t\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_PkgPwrLimitEnable);\n\t\t\t\tif (smc_result != PPSMC_Result_OK) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t} else {\n\t\t\t\t\tstruct radeon_cac_tdp_table *cac_tdp_table =\n\t\t\t\t\t\trdev->pm.dpm.dyn_state.cac_tdp_table;\n\t\t\t\t\tu32 default_pwr_limit =\n\t\t\t\t\t\t(u32)(cac_tdp_table->maximum_power_delivery_limit * 256);\n\n\t\t\t\t\tpi->power_containment_features |= POWERCONTAINMENT_FEATURE_PkgPwrLimit;\n\n\t\t\t\t\tci_set_power_limit(rdev, default_pwr_limit);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (pi->caps_power_containment && pi->power_containment_features) {\n\t\t\tif (pi->power_containment_features & POWERCONTAINMENT_FEATURE_TDCLimit)\n\t\t\t\tci_send_msg_to_smc(rdev, PPSMC_MSG_TDCLimitDisable);\n\n\t\t\tif (pi->power_containment_features & POWERCONTAINMENT_FEATURE_BAPM)\n\t\t\t\tci_send_msg_to_smc(rdev, PPSMC_MSG_DisableDTE);\n\n\t\t\tif (pi->power_containment_features & POWERCONTAINMENT_FEATURE_PkgPwrLimit)\n\t\t\t\tci_send_msg_to_smc(rdev, PPSMC_MSG_PkgPwrLimitDisable);\n\t\t\tpi->power_containment_features = 0;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int ci_enable_smc_cac(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result;\n\tint ret = 0;\n\n\tif (pi->caps_cac) {\n\t\tif (enable) {\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_EnableCac);\n\t\t\tif (smc_result != PPSMC_Result_OK) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tpi->cac_enabled = false;\n\t\t\t} else {\n\t\t\t\tpi->cac_enabled = true;\n\t\t\t}\n\t\t} else if (pi->cac_enabled) {\n\t\t\tci_send_msg_to_smc(rdev, PPSMC_MSG_DisableCac);\n\t\t\tpi->cac_enabled = false;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int ci_enable_thermal_based_sclk_dpm(struct radeon_device *rdev,\n\t\t\t\t\t    bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result = PPSMC_Result_OK;\n\n\tif (pi->thermal_sclk_dpm_enabled) {\n\t\tif (enable)\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_ENABLE_THERMAL_DPM);\n\t\telse\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_DISABLE_THERMAL_DPM);\n\t}\n\n\tif (smc_result == PPSMC_Result_OK)\n\t\treturn 0;\n\telse\n\t\treturn -EINVAL;\n}\n\nstatic int ci_power_control_set_level(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_cac_tdp_table *cac_tdp_table =\n\t\trdev->pm.dpm.dyn_state.cac_tdp_table;\n\ts32 adjust_percent;\n\ts32 target_tdp;\n\tint ret = 0;\n\tbool adjust_polarity = false;  \n\n\tif (pi->caps_power_containment) {\n\t\tadjust_percent = adjust_polarity ?\n\t\t\trdev->pm.dpm.tdp_adjustment : (-1 * rdev->pm.dpm.tdp_adjustment);\n\t\ttarget_tdp = ((100 + adjust_percent) *\n\t\t\t      (s32)cac_tdp_table->configurable_tdp) / 100;\n\n\t\tret = ci_set_overdrive_target_tdp(rdev, (u32)target_tdp);\n\t}\n\n\treturn ret;\n}\n\nvoid ci_dpm_powergate_uvd(struct radeon_device *rdev, bool gate)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (pi->uvd_power_gated == gate)\n\t\treturn;\n\n\tpi->uvd_power_gated = gate;\n\n\tci_update_uvd_dpm(rdev, gate);\n}\n\nbool ci_dpm_vblank_too_short(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 vblank_time = r600_dpm_get_vblank_time(rdev);\n\tu32 switch_limit = pi->mem_gddr5 ? 450 : 300;\n\n\t \n\tif (r600_dpm_get_vrefresh(rdev) > 120)\n\t\treturn true;\n\n\tif (vblank_time < switch_limit)\n\t\treturn true;\n\telse\n\t\treturn false;\n\n}\n\nstatic void ci_apply_state_adjust_rules(struct radeon_device *rdev,\n\t\t\t\t\tstruct radeon_ps *rps)\n{\n\tstruct ci_ps *ps = ci_get_ps(rps);\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_clock_and_voltage_limits *max_limits;\n\tbool disable_mclk_switching;\n\tu32 sclk, mclk;\n\tint i;\n\n\tif (rps->vce_active) {\n\t\trps->evclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].evclk;\n\t\trps->ecclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].ecclk;\n\t} else {\n\t\trps->evclk = 0;\n\t\trps->ecclk = 0;\n\t}\n\n\tif ((rdev->pm.dpm.new_active_crtc_count > 1) ||\n\t    ci_dpm_vblank_too_short(rdev))\n\t\tdisable_mclk_switching = true;\n\telse\n\t\tdisable_mclk_switching = false;\n\n\tif ((rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) == ATOM_PPLIB_CLASSIFICATION_UI_BATTERY)\n\t\tpi->battery_state = true;\n\telse\n\t\tpi->battery_state = false;\n\n\tif (rdev->pm.dpm.ac_power)\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\telse\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc;\n\n\tif (rdev->pm.dpm.ac_power == false) {\n\t\tfor (i = 0; i < ps->performance_level_count; i++) {\n\t\t\tif (ps->performance_levels[i].mclk > max_limits->mclk)\n\t\t\t\tps->performance_levels[i].mclk = max_limits->mclk;\n\t\t\tif (ps->performance_levels[i].sclk > max_limits->sclk)\n\t\t\t\tps->performance_levels[i].sclk = max_limits->sclk;\n\t\t}\n\t}\n\n\t \n\n\tif (disable_mclk_switching) {\n\t\tmclk  = ps->performance_levels[ps->performance_level_count - 1].mclk;\n\t\tsclk = ps->performance_levels[0].sclk;\n\t} else {\n\t\tmclk = ps->performance_levels[0].mclk;\n\t\tsclk = ps->performance_levels[0].sclk;\n\t}\n\n\tif (rps->vce_active) {\n\t\tif (sclk < rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].sclk)\n\t\t\tsclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].sclk;\n\t\tif (mclk < rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].mclk)\n\t\t\tmclk = rdev->pm.dpm.vce_states[rdev->pm.dpm.vce_level].mclk;\n\t}\n\n\tps->performance_levels[0].sclk = sclk;\n\tps->performance_levels[0].mclk = mclk;\n\n\tif (ps->performance_levels[1].sclk < ps->performance_levels[0].sclk)\n\t\tps->performance_levels[1].sclk = ps->performance_levels[0].sclk;\n\n\tif (disable_mclk_switching) {\n\t\tif (ps->performance_levels[0].mclk < ps->performance_levels[1].mclk)\n\t\t\tps->performance_levels[0].mclk = ps->performance_levels[1].mclk;\n\t} else {\n\t\tif (ps->performance_levels[1].mclk < ps->performance_levels[0].mclk)\n\t\t\tps->performance_levels[1].mclk = ps->performance_levels[0].mclk;\n\t}\n}\n\nstatic int ci_thermal_set_temperature_range(struct radeon_device *rdev,\n\t\t\t\t\t    int min_temp, int max_temp)\n{\n\tint low_temp = 0 * 1000;\n\tint high_temp = 255 * 1000;\n\tu32 tmp;\n\n\tif (low_temp < min_temp)\n\t\tlow_temp = min_temp;\n\tif (high_temp > max_temp)\n\t\thigh_temp = max_temp;\n\tif (high_temp < low_temp) {\n\t\tDRM_ERROR(\"invalid thermal range: %d - %d\\n\", low_temp, high_temp);\n\t\treturn -EINVAL;\n\t}\n\n\ttmp = RREG32_SMC(CG_THERMAL_INT);\n\ttmp &= ~(CI_DIG_THERM_INTH_MASK | CI_DIG_THERM_INTL_MASK);\n\ttmp |= CI_DIG_THERM_INTH(high_temp / 1000) |\n\t\tCI_DIG_THERM_INTL(low_temp / 1000);\n\tWREG32_SMC(CG_THERMAL_INT, tmp);\n\n#if 0\n\t \n\ttmp = RREG32_SMC(CG_THERMAL_CTRL);\n\ttmp &= DIG_THERM_DPM_MASK;\n\ttmp |= DIG_THERM_DPM(high_temp / 1000);\n\tWREG32_SMC(CG_THERMAL_CTRL, tmp);\n#endif\n\n\trdev->pm.dpm.thermal.min_temp = low_temp;\n\trdev->pm.dpm.thermal.max_temp = high_temp;\n\n\treturn 0;\n}\n\nstatic int ci_thermal_enable_alert(struct radeon_device *rdev,\n\t\t\t\t   bool enable)\n{\n\tu32 thermal_int = RREG32_SMC(CG_THERMAL_INT);\n\tPPSMC_Result result;\n\n\tif (enable) {\n\t\tthermal_int &= ~(THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW);\n\t\tWREG32_SMC(CG_THERMAL_INT, thermal_int);\n\t\trdev->irq.dpm_thermal = false;\n\t\tresult = ci_send_msg_to_smc(rdev, PPSMC_MSG_Thermal_Cntl_Enable);\n\t\tif (result != PPSMC_Result_OK) {\n\t\t\tDRM_DEBUG_KMS(\"Could not enable thermal interrupts.\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tthermal_int |= THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW;\n\t\tWREG32_SMC(CG_THERMAL_INT, thermal_int);\n\t\trdev->irq.dpm_thermal = true;\n\t\tresult = ci_send_msg_to_smc(rdev, PPSMC_MSG_Thermal_Cntl_Disable);\n\t\tif (result != PPSMC_Result_OK) {\n\t\t\tDRM_DEBUG_KMS(\"Could not disable thermal interrupts.\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void ci_fan_ctrl_set_static_mode(struct radeon_device *rdev, u32 mode)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\n\tif (pi->fan_ctrl_is_in_default_mode) {\n\t\ttmp = (RREG32_SMC(CG_FDO_CTRL2) & FDO_PWM_MODE_MASK) >> FDO_PWM_MODE_SHIFT;\n\t\tpi->fan_ctrl_default_mode = tmp;\n\t\ttmp = (RREG32_SMC(CG_FDO_CTRL2) & TMIN_MASK) >> TMIN_SHIFT;\n\t\tpi->t_min = tmp;\n\t\tpi->fan_ctrl_is_in_default_mode = false;\n\t}\n\n\ttmp = RREG32_SMC(CG_FDO_CTRL2) & ~TMIN_MASK;\n\ttmp |= TMIN(0);\n\tWREG32_SMC(CG_FDO_CTRL2, tmp);\n\n\ttmp = RREG32_SMC(CG_FDO_CTRL2) & ~FDO_PWM_MODE_MASK;\n\ttmp |= FDO_PWM_MODE(mode);\n\tWREG32_SMC(CG_FDO_CTRL2, tmp);\n}\n\nstatic int ci_thermal_setup_fan_table(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tSMU7_Discrete_FanTable fan_table = { FDO_MODE_HARDWARE };\n\tu32 duty100;\n\tu32 t_diff1, t_diff2, pwm_diff1, pwm_diff2;\n\tu16 fdo_min, slope1, slope2;\n\tu32 reference_clock, tmp;\n\tint ret;\n\tu64 tmp64;\n\n\tif (!pi->fan_table_start) {\n\t\trdev->pm.dpm.fan.ucode_fan_control = false;\n\t\treturn 0;\n\t}\n\n\tduty100 = (RREG32_SMC(CG_FDO_CTRL1) & FMAX_DUTY100_MASK) >> FMAX_DUTY100_SHIFT;\n\n\tif (duty100 == 0) {\n\t\trdev->pm.dpm.fan.ucode_fan_control = false;\n\t\treturn 0;\n\t}\n\n\ttmp64 = (u64)rdev->pm.dpm.fan.pwm_min * duty100;\n\tdo_div(tmp64, 10000);\n\tfdo_min = (u16)tmp64;\n\n\tt_diff1 = rdev->pm.dpm.fan.t_med - rdev->pm.dpm.fan.t_min;\n\tt_diff2 = rdev->pm.dpm.fan.t_high - rdev->pm.dpm.fan.t_med;\n\n\tpwm_diff1 = rdev->pm.dpm.fan.pwm_med - rdev->pm.dpm.fan.pwm_min;\n\tpwm_diff2 = rdev->pm.dpm.fan.pwm_high - rdev->pm.dpm.fan.pwm_med;\n\n\tslope1 = (u16)((50 + ((16 * duty100 * pwm_diff1) / t_diff1)) / 100);\n\tslope2 = (u16)((50 + ((16 * duty100 * pwm_diff2) / t_diff2)) / 100);\n\n\tfan_table.TempMin = cpu_to_be16((50 + rdev->pm.dpm.fan.t_min) / 100);\n\tfan_table.TempMed = cpu_to_be16((50 + rdev->pm.dpm.fan.t_med) / 100);\n\tfan_table.TempMax = cpu_to_be16((50 + rdev->pm.dpm.fan.t_max) / 100);\n\n\tfan_table.Slope1 = cpu_to_be16(slope1);\n\tfan_table.Slope2 = cpu_to_be16(slope2);\n\n\tfan_table.FdoMin = cpu_to_be16(fdo_min);\n\n\tfan_table.HystDown = cpu_to_be16(rdev->pm.dpm.fan.t_hyst);\n\n\tfan_table.HystUp = cpu_to_be16(1);\n\n\tfan_table.HystSlope = cpu_to_be16(1);\n\n\tfan_table.TempRespLim = cpu_to_be16(5);\n\n\treference_clock = radeon_get_xclk(rdev);\n\n\tfan_table.RefreshPeriod = cpu_to_be32((rdev->pm.dpm.fan.cycle_delay *\n\t\t\t\t\t       reference_clock) / 1600);\n\n\tfan_table.FdoMax = cpu_to_be16((u16)duty100);\n\n\ttmp = (RREG32_SMC(CG_MULT_THERMAL_CTRL) & TEMP_SEL_MASK) >> TEMP_SEL_SHIFT;\n\tfan_table.TempSrc = (uint8_t)tmp;\n\n\tret = ci_copy_bytes_to_smc(rdev,\n\t\t\t\t   pi->fan_table_start,\n\t\t\t\t   (u8 *)(&fan_table),\n\t\t\t\t   sizeof(fan_table),\n\t\t\t\t   pi->sram_end);\n\n\tif (ret) {\n\t\tDRM_ERROR(\"Failed to load fan table to the SMC.\");\n\t\trdev->pm.dpm.fan.ucode_fan_control = false;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_fan_ctrl_start_smc_fan_control(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result ret;\n\n\tif (pi->caps_od_fuzzy_fan_control_support) {\n\t\tret = ci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\tPPSMC_StartFanControl,\n\t\t\t\t\t\t\tFAN_CONTROL_FUZZY);\n\t\tif (ret != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t\tret = ci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\tPPSMC_MSG_SetFanPwmMax,\n\t\t\t\t\t\t\trdev->pm.dpm.fan.default_max_fan_pwm);\n\t\tif (ret != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tret = ci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\tPPSMC_StartFanControl,\n\t\t\t\t\t\t\tFAN_CONTROL_TABLE);\n\t\tif (ret != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\tpi->fan_is_controlled_by_smc = true;\n\treturn 0;\n}\n\nstatic int ci_fan_ctrl_stop_smc_fan_control(struct radeon_device *rdev)\n{\n\tPPSMC_Result ret;\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tret = ci_send_msg_to_smc(rdev, PPSMC_StopFanControl);\n\tif (ret == PPSMC_Result_OK) {\n\t\tpi->fan_is_controlled_by_smc = false;\n\t\treturn 0;\n\t} else\n\t\treturn -EINVAL;\n}\n\nint ci_fan_ctrl_get_fan_speed_percent(struct radeon_device *rdev,\n\t\t\t\t\t     u32 *speed)\n{\n\tu32 duty, duty100;\n\tu64 tmp64;\n\n\tif (rdev->pm.no_fan)\n\t\treturn -ENOENT;\n\n\tduty100 = (RREG32_SMC(CG_FDO_CTRL1) & FMAX_DUTY100_MASK) >> FMAX_DUTY100_SHIFT;\n\tduty = (RREG32_SMC(CG_THERMAL_STATUS) & FDO_PWM_DUTY_MASK) >> FDO_PWM_DUTY_SHIFT;\n\n\tif (duty100 == 0)\n\t\treturn -EINVAL;\n\n\ttmp64 = (u64)duty * 100;\n\tdo_div(tmp64, duty100);\n\t*speed = (u32)tmp64;\n\n\tif (*speed > 100)\n\t\t*speed = 100;\n\n\treturn 0;\n}\n\nint ci_fan_ctrl_set_fan_speed_percent(struct radeon_device *rdev,\n\t\t\t\t\t     u32 speed)\n{\n\tu32 tmp;\n\tu32 duty, duty100;\n\tu64 tmp64;\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (rdev->pm.no_fan)\n\t\treturn -ENOENT;\n\n\tif (pi->fan_is_controlled_by_smc)\n\t\treturn -EINVAL;\n\n\tif (speed > 100)\n\t\treturn -EINVAL;\n\n\tduty100 = (RREG32_SMC(CG_FDO_CTRL1) & FMAX_DUTY100_MASK) >> FMAX_DUTY100_SHIFT;\n\n\tif (duty100 == 0)\n\t\treturn -EINVAL;\n\n\ttmp64 = (u64)speed * duty100;\n\tdo_div(tmp64, 100);\n\tduty = (u32)tmp64;\n\n\ttmp = RREG32_SMC(CG_FDO_CTRL0) & ~FDO_STATIC_DUTY_MASK;\n\ttmp |= FDO_STATIC_DUTY(duty);\n\tWREG32_SMC(CG_FDO_CTRL0, tmp);\n\n\treturn 0;\n}\n\nvoid ci_fan_ctrl_set_mode(struct radeon_device *rdev, u32 mode)\n{\n\tif (mode) {\n\t\t \n\t\tif (rdev->pm.dpm.fan.ucode_fan_control)\n\t\t\tci_fan_ctrl_stop_smc_fan_control(rdev);\n\t\tci_fan_ctrl_set_static_mode(rdev, mode);\n\t} else {\n\t\t \n\t\tif (rdev->pm.dpm.fan.ucode_fan_control)\n\t\t\tci_thermal_start_smc_fan_control(rdev);\n\t\telse\n\t\t\tci_fan_ctrl_set_default_mode(rdev);\n\t}\n}\n\nu32 ci_fan_ctrl_get_mode(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\n\tif (pi->fan_is_controlled_by_smc)\n\t\treturn 0;\n\n\ttmp = RREG32_SMC(CG_FDO_CTRL2) & FDO_PWM_MODE_MASK;\n\treturn (tmp >> FDO_PWM_MODE_SHIFT);\n}\n\n#if 0\nstatic int ci_fan_ctrl_get_fan_speed_rpm(struct radeon_device *rdev,\n\t\t\t\t\t u32 *speed)\n{\n\tu32 tach_period;\n\tu32 xclk = radeon_get_xclk(rdev);\n\n\tif (rdev->pm.no_fan)\n\t\treturn -ENOENT;\n\n\tif (rdev->pm.fan_pulses_per_revolution == 0)\n\t\treturn -ENOENT;\n\n\ttach_period = (RREG32_SMC(CG_TACH_STATUS) & TACH_PERIOD_MASK) >> TACH_PERIOD_SHIFT;\n\tif (tach_period == 0)\n\t\treturn -ENOENT;\n\n\t*speed = 60 * xclk * 10000 / tach_period;\n\n\treturn 0;\n}\n\nstatic int ci_fan_ctrl_set_fan_speed_rpm(struct radeon_device *rdev,\n\t\t\t\t\t u32 speed)\n{\n\tu32 tach_period, tmp;\n\tu32 xclk = radeon_get_xclk(rdev);\n\n\tif (rdev->pm.no_fan)\n\t\treturn -ENOENT;\n\n\tif (rdev->pm.fan_pulses_per_revolution == 0)\n\t\treturn -ENOENT;\n\n\tif ((speed < rdev->pm.fan_min_rpm) ||\n\t    (speed > rdev->pm.fan_max_rpm))\n\t\treturn -EINVAL;\n\n\tif (rdev->pm.dpm.fan.ucode_fan_control)\n\t\tci_fan_ctrl_stop_smc_fan_control(rdev);\n\n\ttach_period = 60 * xclk * 10000 / (8 * speed);\n\ttmp = RREG32_SMC(CG_TACH_CTRL) & ~TARGET_PERIOD_MASK;\n\ttmp |= TARGET_PERIOD(tach_period);\n\tWREG32_SMC(CG_TACH_CTRL, tmp);\n\n\tci_fan_ctrl_set_static_mode(rdev, FDO_PWM_MODE_STATIC_RPM);\n\n\treturn 0;\n}\n#endif\n\nstatic void ci_fan_ctrl_set_default_mode(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\n\tif (!pi->fan_ctrl_is_in_default_mode) {\n\t\ttmp = RREG32_SMC(CG_FDO_CTRL2) & ~FDO_PWM_MODE_MASK;\n\t\ttmp |= FDO_PWM_MODE(pi->fan_ctrl_default_mode);\n\t\tWREG32_SMC(CG_FDO_CTRL2, tmp);\n\n\t\ttmp = RREG32_SMC(CG_FDO_CTRL2) & ~TMIN_MASK;\n\t\ttmp |= TMIN(pi->t_min);\n\t\tWREG32_SMC(CG_FDO_CTRL2, tmp);\n\t\tpi->fan_ctrl_is_in_default_mode = true;\n\t}\n}\n\nstatic void ci_thermal_start_smc_fan_control(struct radeon_device *rdev)\n{\n\tif (rdev->pm.dpm.fan.ucode_fan_control) {\n\t\tci_fan_ctrl_start_smc_fan_control(rdev);\n\t\tci_fan_ctrl_set_static_mode(rdev, FDO_PWM_MODE_STATIC);\n\t}\n}\n\nstatic void ci_thermal_initialize(struct radeon_device *rdev)\n{\n\tu32 tmp;\n\n\tif (rdev->pm.fan_pulses_per_revolution) {\n\t\ttmp = RREG32_SMC(CG_TACH_CTRL) & ~EDGE_PER_REV_MASK;\n\t\ttmp |= EDGE_PER_REV(rdev->pm.fan_pulses_per_revolution -1);\n\t\tWREG32_SMC(CG_TACH_CTRL, tmp);\n\t}\n\n\ttmp = RREG32_SMC(CG_FDO_CTRL2) & ~TACH_PWM_RESP_RATE_MASK;\n\ttmp |= TACH_PWM_RESP_RATE(0x28);\n\tWREG32_SMC(CG_FDO_CTRL2, tmp);\n}\n\nstatic int ci_thermal_start_thermal_controller(struct radeon_device *rdev)\n{\n\tint ret;\n\n\tci_thermal_initialize(rdev);\n\tret = ci_thermal_set_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);\n\tif (ret)\n\t\treturn ret;\n\tret = ci_thermal_enable_alert(rdev, true);\n\tif (ret)\n\t\treturn ret;\n\tif (rdev->pm.dpm.fan.ucode_fan_control) {\n\t\tret = ci_thermal_setup_fan_table(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tci_thermal_start_smc_fan_control(rdev);\n\t}\n\n\treturn 0;\n}\n\nstatic void ci_thermal_stop_thermal_controller(struct radeon_device *rdev)\n{\n\tif (!rdev->pm.no_fan)\n\t\tci_fan_ctrl_set_default_mode(rdev);\n}\n\n#if 0\nstatic int ci_read_smc_soft_register(struct radeon_device *rdev,\n\t\t\t\t     u16 reg_offset, u32 *value)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\treturn ci_read_smc_sram_dword(rdev,\n\t\t\t\t      pi->soft_regs_start + reg_offset,\n\t\t\t\t      value, pi->sram_end);\n}\n#endif\n\nstatic int ci_write_smc_soft_register(struct radeon_device *rdev,\n\t\t\t\t      u16 reg_offset, u32 value)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\treturn ci_write_smc_sram_dword(rdev,\n\t\t\t\t       pi->soft_regs_start + reg_offset,\n\t\t\t\t       value, pi->sram_end);\n}\n\nstatic void ci_init_fps_limits(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tSMU7_Discrete_DpmTable *table = &pi->smc_state_table;\n\n\tif (pi->caps_fps) {\n\t\tu16 tmp;\n\n\t\ttmp = 45;\n\t\ttable->FpsHighT = cpu_to_be16(tmp);\n\n\t\ttmp = 30;\n\t\ttable->FpsLowT = cpu_to_be16(tmp);\n\t}\n}\n\nstatic int ci_update_sclk_t(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret = 0;\n\tu32 low_sclk_interrupt_t = 0;\n\n\tif (pi->caps_sclk_throttle_low_notification) {\n\t\tlow_sclk_interrupt_t = cpu_to_be32(pi->low_sclk_interrupt_t);\n\n\t\tret = ci_copy_bytes_to_smc(rdev,\n\t\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t\t   offsetof(SMU7_Discrete_DpmTable, LowSclkInterruptT),\n\t\t\t\t\t   (u8 *)&low_sclk_interrupt_t,\n\t\t\t\t\t   sizeof(u32), pi->sram_end);\n\n\t}\n\n\treturn ret;\n}\n\nstatic void ci_get_leakage_voltages(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu16 leakage_id, virtual_voltage_id;\n\tu16 vddc, vddci;\n\tint i;\n\n\tpi->vddc_leakage.count = 0;\n\tpi->vddci_leakage.count = 0;\n\n\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_EVV) {\n\t\tfor (i = 0; i < CISLANDS_MAX_LEAKAGE_COUNT; i++) {\n\t\t\tvirtual_voltage_id = ATOM_VIRTUAL_VOLTAGE_ID0 + i;\n\t\t\tif (radeon_atom_get_voltage_evv(rdev, virtual_voltage_id, &vddc) != 0)\n\t\t\t\tcontinue;\n\t\t\tif (vddc != 0 && vddc != virtual_voltage_id) {\n\t\t\t\tpi->vddc_leakage.actual_voltage[pi->vddc_leakage.count] = vddc;\n\t\t\t\tpi->vddc_leakage.leakage_id[pi->vddc_leakage.count] = virtual_voltage_id;\n\t\t\t\tpi->vddc_leakage.count++;\n\t\t\t}\n\t\t}\n\t} else if (radeon_atom_get_leakage_id_from_vbios(rdev, &leakage_id) == 0) {\n\t\tfor (i = 0; i < CISLANDS_MAX_LEAKAGE_COUNT; i++) {\n\t\t\tvirtual_voltage_id = ATOM_VIRTUAL_VOLTAGE_ID0 + i;\n\t\t\tif (radeon_atom_get_leakage_vddc_based_on_leakage_params(rdev, &vddc, &vddci,\n\t\t\t\t\t\t\t\t\t\t virtual_voltage_id,\n\t\t\t\t\t\t\t\t\t\t leakage_id) == 0) {\n\t\t\t\tif (vddc != 0 && vddc != virtual_voltage_id) {\n\t\t\t\t\tpi->vddc_leakage.actual_voltage[pi->vddc_leakage.count] = vddc;\n\t\t\t\t\tpi->vddc_leakage.leakage_id[pi->vddc_leakage.count] = virtual_voltage_id;\n\t\t\t\t\tpi->vddc_leakage.count++;\n\t\t\t\t}\n\t\t\t\tif (vddci != 0 && vddci != virtual_voltage_id) {\n\t\t\t\t\tpi->vddci_leakage.actual_voltage[pi->vddci_leakage.count] = vddci;\n\t\t\t\t\tpi->vddci_leakage.leakage_id[pi->vddci_leakage.count] = virtual_voltage_id;\n\t\t\t\t\tpi->vddci_leakage.count++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void ci_set_dpm_event_sources(struct radeon_device *rdev, u32 sources)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tbool want_thermal_protection;\n\tu32 tmp;\n\n\tswitch (sources) {\n\tcase 0:\n\tdefault:\n\t\twant_thermal_protection = false;\n\t\tbreak;\n\tcase (1 << RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL):\n\t\twant_thermal_protection = true;\n\t\tbreak;\n\tcase (1 << RADEON_DPM_AUTO_THROTTLE_SRC_EXTERNAL):\n\t\twant_thermal_protection = true;\n\t\tbreak;\n\tcase ((1 << RADEON_DPM_AUTO_THROTTLE_SRC_EXTERNAL) |\n\t      (1 << RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL)):\n\t\twant_thermal_protection = true;\n\t\tbreak;\n\t}\n\n\tif (want_thermal_protection) {\n\t\ttmp = RREG32_SMC(GENERAL_PWRMGT);\n\t\tif (pi->thermal_protection)\n\t\t\ttmp &= ~THERMAL_PROTECTION_DIS;\n\t\telse\n\t\t\ttmp |= THERMAL_PROTECTION_DIS;\n\t\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n\t} else {\n\t\ttmp = RREG32_SMC(GENERAL_PWRMGT);\n\t\ttmp |= THERMAL_PROTECTION_DIS;\n\t\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n\t}\n}\n\nstatic void ci_enable_auto_throttle_source(struct radeon_device *rdev,\n\t\t\t\t\t   enum radeon_dpm_auto_throttle_src source,\n\t\t\t\t\t   bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (enable) {\n\t\tif (!(pi->active_auto_throttle_sources & (1 << source))) {\n\t\t\tpi->active_auto_throttle_sources |= 1 << source;\n\t\t\tci_set_dpm_event_sources(rdev, pi->active_auto_throttle_sources);\n\t\t}\n\t} else {\n\t\tif (pi->active_auto_throttle_sources & (1 << source)) {\n\t\t\tpi->active_auto_throttle_sources &= ~(1 << source);\n\t\t\tci_set_dpm_event_sources(rdev, pi->active_auto_throttle_sources);\n\t\t}\n\t}\n}\n\nstatic void ci_enable_vr_hot_gpio_interrupt(struct radeon_device *rdev)\n{\n\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_REGULATOR_HOT)\n\t\tci_send_msg_to_smc(rdev, PPSMC_MSG_EnableVRHotGPIOInterrupt);\n}\n\nstatic int ci_unfreeze_sclk_mclk_dpm(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result;\n\n\tif (!pi->need_update_smu7_dpm_table)\n\t\treturn 0;\n\n\tif ((!pi->sclk_dpm_key_disabled) &&\n\t    (pi->need_update_smu7_dpm_table & (DPMTABLE_OD_UPDATE_SCLK | DPMTABLE_UPDATE_SCLK))) {\n\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_SCLKDPM_UnfreezeLevel);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif ((!pi->mclk_dpm_key_disabled) &&\n\t    (pi->need_update_smu7_dpm_table & DPMTABLE_OD_UPDATE_MCLK)) {\n\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_MCLKDPM_UnfreezeLevel);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\tpi->need_update_smu7_dpm_table = 0;\n\treturn 0;\n}\n\nstatic int ci_enable_sclk_mclk_dpm(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result;\n\n\tif (enable) {\n\t\tif (!pi->sclk_dpm_key_disabled) {\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_DPM_Enable);\n\t\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!pi->mclk_dpm_key_disabled) {\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_MCLKDPM_Enable);\n\t\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\n\t\t\tWREG32_P(MC_SEQ_CNTL_3, CAC_EN, ~CAC_EN);\n\n\t\t\tWREG32_SMC(LCAC_MC0_CNTL, 0x05);\n\t\t\tWREG32_SMC(LCAC_MC1_CNTL, 0x05);\n\t\t\tWREG32_SMC(LCAC_CPL_CNTL, 0x100005);\n\n\t\t\tudelay(10);\n\n\t\t\tWREG32_SMC(LCAC_MC0_CNTL, 0x400005);\n\t\t\tWREG32_SMC(LCAC_MC1_CNTL, 0x400005);\n\t\t\tWREG32_SMC(LCAC_CPL_CNTL, 0x500005);\n\t\t}\n\t} else {\n\t\tif (!pi->sclk_dpm_key_disabled) {\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_DPM_Disable);\n\t\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (!pi->mclk_dpm_key_disabled) {\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_MCLKDPM_Disable);\n\t\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_start_dpm(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result;\n\tint ret;\n\tu32 tmp;\n\n\ttmp = RREG32_SMC(GENERAL_PWRMGT);\n\ttmp |= GLOBAL_PWRMGT_EN;\n\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n\n\ttmp = RREG32_SMC(SCLK_PWRMGT_CNTL);\n\ttmp |= DYNAMIC_PM_EN;\n\tWREG32_SMC(SCLK_PWRMGT_CNTL, tmp);\n\n\tci_write_smc_soft_register(rdev, offsetof(SMU7_SoftRegisters, VoltageChangeTimeout), 0x1000);\n\n\tWREG32_P(BIF_LNCNT_RESET, 0, ~RESET_LNCNT_EN);\n\n\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_Voltage_Cntl_Enable);\n\tif (smc_result != PPSMC_Result_OK)\n\t\treturn -EINVAL;\n\n\tret = ci_enable_sclk_mclk_dpm(rdev, true);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!pi->pcie_dpm_key_disabled) {\n\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_PCIeDPM_Enable);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_freeze_sclk_mclk_dpm(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result;\n\n\tif (!pi->need_update_smu7_dpm_table)\n\t\treturn 0;\n\n\tif ((!pi->sclk_dpm_key_disabled) &&\n\t    (pi->need_update_smu7_dpm_table & (DPMTABLE_OD_UPDATE_SCLK | DPMTABLE_UPDATE_SCLK))) {\n\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_SCLKDPM_FreezeLevel);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif ((!pi->mclk_dpm_key_disabled) &&\n\t    (pi->need_update_smu7_dpm_table & DPMTABLE_OD_UPDATE_MCLK)) {\n\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_MCLKDPM_FreezeLevel);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_stop_dpm(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result smc_result;\n\tint ret;\n\tu32 tmp;\n\n\ttmp = RREG32_SMC(GENERAL_PWRMGT);\n\ttmp &= ~GLOBAL_PWRMGT_EN;\n\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n\n\ttmp = RREG32_SMC(SCLK_PWRMGT_CNTL);\n\ttmp &= ~DYNAMIC_PM_EN;\n\tWREG32_SMC(SCLK_PWRMGT_CNTL, tmp);\n\n\tif (!pi->pcie_dpm_key_disabled) {\n\t\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_PCIeDPM_Disable);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\tret = ci_enable_sclk_mclk_dpm(rdev, false);\n\tif (ret)\n\t\treturn ret;\n\n\tsmc_result = ci_send_msg_to_smc(rdev, PPSMC_MSG_Voltage_Cntl_Disable);\n\tif (smc_result != PPSMC_Result_OK)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic void ci_enable_sclk_control(struct radeon_device *rdev, bool enable)\n{\n\tu32 tmp = RREG32_SMC(SCLK_PWRMGT_CNTL);\n\n\tif (enable)\n\t\ttmp &= ~SCLK_PWRMGT_OFF;\n\telse\n\t\ttmp |= SCLK_PWRMGT_OFF;\n\tWREG32_SMC(SCLK_PWRMGT_CNTL, tmp);\n}\n\n#if 0\nstatic int ci_notify_hw_of_power_source(struct radeon_device *rdev,\n\t\t\t\t\tbool ac_power)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_cac_tdp_table *cac_tdp_table =\n\t\trdev->pm.dpm.dyn_state.cac_tdp_table;\n\tu32 power_limit;\n\n\tif (ac_power)\n\t\tpower_limit = (u32)(cac_tdp_table->maximum_power_delivery_limit * 256);\n\telse\n\t\tpower_limit = (u32)(cac_tdp_table->battery_power_limit * 256);\n\n\tci_set_power_limit(rdev, power_limit);\n\n\tif (pi->caps_automatic_dc_transition) {\n\t\tif (ac_power)\n\t\t\tci_send_msg_to_smc(rdev, PPSMC_MSG_RunningOnAC);\n\t\telse\n\t\t\tci_send_msg_to_smc(rdev, PPSMC_MSG_Remove_DC_Clamp);\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic PPSMC_Result ci_send_msg_to_smc(struct radeon_device *rdev, PPSMC_Msg msg)\n{\n\tu32 tmp;\n\tint i;\n\n\tif (!ci_is_smc_running(rdev))\n\t\treturn PPSMC_Result_Failed;\n\n\tWREG32(SMC_MESSAGE_0, msg);\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\ttmp = RREG32(SMC_RESP_0);\n\t\tif (tmp != 0)\n\t\t\tbreak;\n\t\tudelay(1);\n\t}\n\ttmp = RREG32(SMC_RESP_0);\n\n\treturn (PPSMC_Result)tmp;\n}\n\nstatic PPSMC_Result ci_send_msg_to_smc_with_parameter(struct radeon_device *rdev,\n\t\t\t\t\t\t      PPSMC_Msg msg, u32 parameter)\n{\n\tWREG32(SMC_MSG_ARG_0, parameter);\n\treturn ci_send_msg_to_smc(rdev, msg);\n}\n\nstatic PPSMC_Result ci_send_msg_to_smc_return_parameter(struct radeon_device *rdev,\n\t\t\t\t\t\t\tPPSMC_Msg msg, u32 *parameter)\n{\n\tPPSMC_Result smc_result;\n\n\tsmc_result = ci_send_msg_to_smc(rdev, msg);\n\n\tif ((smc_result == PPSMC_Result_OK) && parameter)\n\t\t*parameter = RREG32(SMC_MSG_ARG_0);\n\n\treturn smc_result;\n}\n\nstatic int ci_dpm_force_state_sclk(struct radeon_device *rdev, u32 n)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (!pi->sclk_dpm_key_disabled) {\n\t\tPPSMC_Result smc_result =\n\t\t\tci_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SCLKDPM_SetEnabledMask, 1 << n);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_dpm_force_state_mclk(struct radeon_device *rdev, u32 n)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (!pi->mclk_dpm_key_disabled) {\n\t\tPPSMC_Result smc_result =\n\t\t\tci_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_MCLKDPM_SetEnabledMask, 1 << n);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_dpm_force_state_pcie(struct radeon_device *rdev, u32 n)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (!pi->pcie_dpm_key_disabled) {\n\t\tPPSMC_Result smc_result =\n\t\t\tci_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_PCIeDPM_ForceLevel, n);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_set_power_limit(struct radeon_device *rdev, u32 n)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (pi->power_containment_features & POWERCONTAINMENT_FEATURE_PkgPwrLimit) {\n\t\tPPSMC_Result smc_result =\n\t\t\tci_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_PkgPwrSetLimit, n);\n\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_set_overdrive_target_tdp(struct radeon_device *rdev,\n\t\t\t\t       u32 target_tdp)\n{\n\tPPSMC_Result smc_result =\n\t\tci_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_OverDriveSetTargetTdp, target_tdp);\n\tif (smc_result != PPSMC_Result_OK)\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\n#if 0\nstatic int ci_set_boot_state(struct radeon_device *rdev)\n{\n\treturn ci_enable_sclk_mclk_dpm(rdev, false);\n}\n#endif\n\nstatic u32 ci_get_average_sclk_freq(struct radeon_device *rdev)\n{\n\tu32 sclk_freq;\n\tPPSMC_Result smc_result =\n\t\tci_send_msg_to_smc_return_parameter(rdev,\n\t\t\t\t\t\t    PPSMC_MSG_API_GetSclkFrequency,\n\t\t\t\t\t\t    &sclk_freq);\n\tif (smc_result != PPSMC_Result_OK)\n\t\tsclk_freq = 0;\n\n\treturn sclk_freq;\n}\n\nstatic u32 ci_get_average_mclk_freq(struct radeon_device *rdev)\n{\n\tu32 mclk_freq;\n\tPPSMC_Result smc_result =\n\t\tci_send_msg_to_smc_return_parameter(rdev,\n\t\t\t\t\t\t    PPSMC_MSG_API_GetMclkFrequency,\n\t\t\t\t\t\t    &mclk_freq);\n\tif (smc_result != PPSMC_Result_OK)\n\t\tmclk_freq = 0;\n\n\treturn mclk_freq;\n}\n\nstatic void ci_dpm_start_smc(struct radeon_device *rdev)\n{\n\tint i;\n\n\tci_program_jump_on_start(rdev);\n\tci_start_smc_clock(rdev);\n\tci_start_smc(rdev);\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (RREG32_SMC(FIRMWARE_FLAGS) & INTERRUPTS_ENABLED)\n\t\t\tbreak;\n\t}\n}\n\nstatic void ci_dpm_stop_smc(struct radeon_device *rdev)\n{\n\tci_reset_smc(rdev);\n\tci_stop_smc_clock(rdev);\n}\n\nstatic int ci_process_firmware_header(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\tint ret;\n\n\tret = ci_read_smc_sram_dword(rdev,\n\t\t\t\t     SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, DpmTable),\n\t\t\t\t     &tmp, pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->dpm_table_start = tmp;\n\n\tret = ci_read_smc_sram_dword(rdev,\n\t\t\t\t     SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, SoftRegisters),\n\t\t\t\t     &tmp, pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->soft_regs_start = tmp;\n\n\tret = ci_read_smc_sram_dword(rdev,\n\t\t\t\t     SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, mcRegisterTable),\n\t\t\t\t     &tmp, pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->mc_reg_table_start = tmp;\n\n\tret = ci_read_smc_sram_dword(rdev,\n\t\t\t\t     SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, FanTable),\n\t\t\t\t     &tmp, pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->fan_table_start = tmp;\n\n\tret = ci_read_smc_sram_dword(rdev,\n\t\t\t\t     SMU7_FIRMWARE_HEADER_LOCATION +\n\t\t\t\t     offsetof(SMU7_Firmware_Header, mcArbDramTimingTable),\n\t\t\t\t     &tmp, pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->arb_table_start = tmp;\n\n\treturn 0;\n}\n\nstatic void ci_read_clock_registers(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tpi->clock_registers.cg_spll_func_cntl =\n\t\tRREG32_SMC(CG_SPLL_FUNC_CNTL);\n\tpi->clock_registers.cg_spll_func_cntl_2 =\n\t\tRREG32_SMC(CG_SPLL_FUNC_CNTL_2);\n\tpi->clock_registers.cg_spll_func_cntl_3 =\n\t\tRREG32_SMC(CG_SPLL_FUNC_CNTL_3);\n\tpi->clock_registers.cg_spll_func_cntl_4 =\n\t\tRREG32_SMC(CG_SPLL_FUNC_CNTL_4);\n\tpi->clock_registers.cg_spll_spread_spectrum =\n\t\tRREG32_SMC(CG_SPLL_SPREAD_SPECTRUM);\n\tpi->clock_registers.cg_spll_spread_spectrum_2 =\n\t\tRREG32_SMC(CG_SPLL_SPREAD_SPECTRUM_2);\n\tpi->clock_registers.dll_cntl = RREG32(DLL_CNTL);\n\tpi->clock_registers.mclk_pwrmgt_cntl = RREG32(MCLK_PWRMGT_CNTL);\n\tpi->clock_registers.mpll_ad_func_cntl = RREG32(MPLL_AD_FUNC_CNTL);\n\tpi->clock_registers.mpll_dq_func_cntl = RREG32(MPLL_DQ_FUNC_CNTL);\n\tpi->clock_registers.mpll_func_cntl = RREG32(MPLL_FUNC_CNTL);\n\tpi->clock_registers.mpll_func_cntl_1 = RREG32(MPLL_FUNC_CNTL_1);\n\tpi->clock_registers.mpll_func_cntl_2 = RREG32(MPLL_FUNC_CNTL_2);\n\tpi->clock_registers.mpll_ss1 = RREG32(MPLL_SS1);\n\tpi->clock_registers.mpll_ss2 = RREG32(MPLL_SS2);\n}\n\nstatic void ci_init_sclk_t(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tpi->low_sclk_interrupt_t = 0;\n}\n\nstatic void ci_enable_thermal_protection(struct radeon_device *rdev,\n\t\t\t\t\t bool enable)\n{\n\tu32 tmp = RREG32_SMC(GENERAL_PWRMGT);\n\n\tif (enable)\n\t\ttmp &= ~THERMAL_PROTECTION_DIS;\n\telse\n\t\ttmp |= THERMAL_PROTECTION_DIS;\n\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n}\n\nstatic void ci_enable_acpi_power_management(struct radeon_device *rdev)\n{\n\tu32 tmp = RREG32_SMC(GENERAL_PWRMGT);\n\n\ttmp |= STATIC_PM_EN;\n\n\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n}\n\n#if 0\nstatic int ci_enter_ulp_state(struct radeon_device *rdev)\n{\n\n\tWREG32(SMC_MESSAGE_0, PPSMC_MSG_SwitchToMinimumPower);\n\n\tudelay(25000);\n\n\treturn 0;\n}\n\nstatic int ci_exit_ulp_state(struct radeon_device *rdev)\n{\n\tint i;\n\n\tWREG32(SMC_MESSAGE_0, PPSMC_MSG_ResumeFromMinimumPower);\n\n\tudelay(7000);\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (RREG32(SMC_RESP_0) == 1)\n\t\t\tbreak;\n\t\tudelay(1000);\n\t}\n\n\treturn 0;\n}\n#endif\n\nstatic int ci_notify_smc_display_change(struct radeon_device *rdev,\n\t\t\t\t\tbool has_display)\n{\n\tPPSMC_Msg msg = has_display ? PPSMC_MSG_HasDisplay : PPSMC_MSG_NoDisplay;\n\n\treturn (ci_send_msg_to_smc(rdev, msg) == PPSMC_Result_OK) ?  0 : -EINVAL;\n}\n\nstatic int ci_enable_ds_master_switch(struct radeon_device *rdev,\n\t\t\t\t      bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (enable) {\n\t\tif (pi->caps_sclk_ds) {\n\t\t\tif (ci_send_msg_to_smc(rdev, PPSMC_MSG_MASTER_DeepSleep_ON) != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t} else {\n\t\t\tif (ci_send_msg_to_smc(rdev, PPSMC_MSG_MASTER_DeepSleep_OFF) != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tif (pi->caps_sclk_ds) {\n\t\t\tif (ci_send_msg_to_smc(rdev, PPSMC_MSG_MASTER_DeepSleep_OFF) != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void ci_program_display_gap(struct radeon_device *rdev)\n{\n\tu32 tmp = RREG32_SMC(CG_DISPLAY_GAP_CNTL);\n\tu32 pre_vbi_time_in_us;\n\tu32 frame_time_in_us;\n\tu32 ref_clock = rdev->clock.spll.reference_freq;\n\tu32 refresh_rate = r600_dpm_get_vrefresh(rdev);\n\tu32 vblank_time = r600_dpm_get_vblank_time(rdev);\n\n\ttmp &= ~DISP_GAP_MASK;\n\tif (rdev->pm.dpm.new_active_crtc_count > 0)\n\t\ttmp |= DISP_GAP(R600_PM_DISPLAY_GAP_VBLANK_OR_WM);\n\telse\n\t\ttmp |= DISP_GAP(R600_PM_DISPLAY_GAP_IGNORE);\n\tWREG32_SMC(CG_DISPLAY_GAP_CNTL, tmp);\n\n\tif (refresh_rate == 0)\n\t\trefresh_rate = 60;\n\tif (vblank_time == 0xffffffff)\n\t\tvblank_time = 500;\n\tframe_time_in_us = 1000000 / refresh_rate;\n\tpre_vbi_time_in_us =\n\t\tframe_time_in_us - 200 - vblank_time;\n\ttmp = pre_vbi_time_in_us * (ref_clock / 100);\n\n\tWREG32_SMC(CG_DISPLAY_GAP_CNTL2, tmp);\n\tci_write_smc_soft_register(rdev, offsetof(SMU7_SoftRegisters, PreVBlankGap), 0x64);\n\tci_write_smc_soft_register(rdev, offsetof(SMU7_SoftRegisters, VBlankTimeout), (frame_time_in_us - pre_vbi_time_in_us));\n\n\n\tci_notify_smc_display_change(rdev, (rdev->pm.dpm.new_active_crtc_count == 1));\n\n}\n\nstatic void ci_enable_spread_spectrum(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\n\tif (enable) {\n\t\tif (pi->caps_sclk_ss_support) {\n\t\t\ttmp = RREG32_SMC(GENERAL_PWRMGT);\n\t\t\ttmp |= DYN_SPREAD_SPECTRUM_EN;\n\t\t\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n\t\t}\n\t} else {\n\t\ttmp = RREG32_SMC(CG_SPLL_SPREAD_SPECTRUM);\n\t\ttmp &= ~SSEN;\n\t\tWREG32_SMC(CG_SPLL_SPREAD_SPECTRUM, tmp);\n\n\t\ttmp = RREG32_SMC(GENERAL_PWRMGT);\n\t\ttmp &= ~DYN_SPREAD_SPECTRUM_EN;\n\t\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n\t}\n}\n\nstatic void ci_program_sstp(struct radeon_device *rdev)\n{\n\tWREG32_SMC(CG_SSP, (SSTU(R600_SSTU_DFLT) | SST(R600_SST_DFLT)));\n}\n\nstatic void ci_enable_display_gap(struct radeon_device *rdev)\n{\n\tu32 tmp = RREG32_SMC(CG_DISPLAY_GAP_CNTL);\n\n\ttmp &= ~(DISP_GAP_MASK | DISP_GAP_MCHG_MASK);\n\ttmp |= (DISP_GAP(R600_PM_DISPLAY_GAP_IGNORE) |\n\t\tDISP_GAP_MCHG(R600_PM_DISPLAY_GAP_VBLANK));\n\n\tWREG32_SMC(CG_DISPLAY_GAP_CNTL, tmp);\n}\n\nstatic void ci_program_vc(struct radeon_device *rdev)\n{\n\tu32 tmp;\n\n\ttmp = RREG32_SMC(SCLK_PWRMGT_CNTL);\n\ttmp &= ~(RESET_SCLK_CNT | RESET_BUSY_CNT);\n\tWREG32_SMC(SCLK_PWRMGT_CNTL, tmp);\n\n\tWREG32_SMC(CG_FTV_0, CISLANDS_VRC_DFLT0);\n\tWREG32_SMC(CG_FTV_1, CISLANDS_VRC_DFLT1);\n\tWREG32_SMC(CG_FTV_2, CISLANDS_VRC_DFLT2);\n\tWREG32_SMC(CG_FTV_3, CISLANDS_VRC_DFLT3);\n\tWREG32_SMC(CG_FTV_4, CISLANDS_VRC_DFLT4);\n\tWREG32_SMC(CG_FTV_5, CISLANDS_VRC_DFLT5);\n\tWREG32_SMC(CG_FTV_6, CISLANDS_VRC_DFLT6);\n\tWREG32_SMC(CG_FTV_7, CISLANDS_VRC_DFLT7);\n}\n\nstatic void ci_clear_vc(struct radeon_device *rdev)\n{\n\tu32 tmp;\n\n\ttmp = RREG32_SMC(SCLK_PWRMGT_CNTL);\n\ttmp |= (RESET_SCLK_CNT | RESET_BUSY_CNT);\n\tWREG32_SMC(SCLK_PWRMGT_CNTL, tmp);\n\n\tWREG32_SMC(CG_FTV_0, 0);\n\tWREG32_SMC(CG_FTV_1, 0);\n\tWREG32_SMC(CG_FTV_2, 0);\n\tWREG32_SMC(CG_FTV_3, 0);\n\tWREG32_SMC(CG_FTV_4, 0);\n\tWREG32_SMC(CG_FTV_5, 0);\n\tWREG32_SMC(CG_FTV_6, 0);\n\tWREG32_SMC(CG_FTV_7, 0);\n}\n\nstatic int ci_upload_firmware(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint i;\n\n\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\tif (RREG32_SMC(RCU_UC_EVENTS) & BOOT_SEQ_DONE)\n\t\t\tbreak;\n\t}\n\tWREG32_SMC(SMC_SYSCON_MISC_CNTL, 1);\n\n\tci_stop_smc_clock(rdev);\n\tci_reset_smc(rdev);\n\n\treturn ci_load_smc_ucode(rdev, pi->sram_end);\n\n}\n\nstatic int ci_get_svi2_voltage_table(struct radeon_device *rdev,\n\t\t\t\t     struct radeon_clock_voltage_dependency_table *voltage_dependency_table,\n\t\t\t\t     struct atom_voltage_table *voltage_table)\n{\n\tu32 i;\n\n\tif (voltage_dependency_table == NULL)\n\t\treturn -EINVAL;\n\n\tvoltage_table->mask_low = 0;\n\tvoltage_table->phase_delay = 0;\n\n\tvoltage_table->count = voltage_dependency_table->count;\n\tfor (i = 0; i < voltage_table->count; i++) {\n\t\tvoltage_table->entries[i].value = voltage_dependency_table->entries[i].v;\n\t\tvoltage_table->entries[i].smio_low = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_construct_voltage_tables(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret;\n\n\tif (pi->voltage_control == CISLANDS_VOLTAGE_CONTROL_BY_GPIO) {\n\t\tret = radeon_atom_get_voltage_table(rdev, VOLTAGE_TYPE_VDDC,\n\t\t\t\t\t\t    VOLTAGE_OBJ_GPIO_LUT,\n\t\t\t\t\t\t    &pi->vddc_voltage_table);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (pi->voltage_control == CISLANDS_VOLTAGE_CONTROL_BY_SVID2) {\n\t\tret = ci_get_svi2_voltage_table(rdev,\n\t\t\t\t\t\t&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk,\n\t\t\t\t\t\t&pi->vddc_voltage_table);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (pi->vddc_voltage_table.count > SMU7_MAX_LEVELS_VDDC)\n\t\tsi_trim_voltage_table_to_fit_state_table(rdev, SMU7_MAX_LEVELS_VDDC,\n\t\t\t\t\t\t\t &pi->vddc_voltage_table);\n\n\tif (pi->vddci_control == CISLANDS_VOLTAGE_CONTROL_BY_GPIO) {\n\t\tret = radeon_atom_get_voltage_table(rdev, VOLTAGE_TYPE_VDDCI,\n\t\t\t\t\t\t    VOLTAGE_OBJ_GPIO_LUT,\n\t\t\t\t\t\t    &pi->vddci_voltage_table);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (pi->vddci_control == CISLANDS_VOLTAGE_CONTROL_BY_SVID2) {\n\t\tret = ci_get_svi2_voltage_table(rdev,\n\t\t\t\t\t\t&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk,\n\t\t\t\t\t\t&pi->vddci_voltage_table);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (pi->vddci_voltage_table.count > SMU7_MAX_LEVELS_VDDCI)\n\t\tsi_trim_voltage_table_to_fit_state_table(rdev, SMU7_MAX_LEVELS_VDDCI,\n\t\t\t\t\t\t\t &pi->vddci_voltage_table);\n\n\tif (pi->mvdd_control == CISLANDS_VOLTAGE_CONTROL_BY_GPIO) {\n\t\tret = radeon_atom_get_voltage_table(rdev, VOLTAGE_TYPE_MVDDC,\n\t\t\t\t\t\t    VOLTAGE_OBJ_GPIO_LUT,\n\t\t\t\t\t\t    &pi->mvdd_voltage_table);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (pi->mvdd_control == CISLANDS_VOLTAGE_CONTROL_BY_SVID2) {\n\t\tret = ci_get_svi2_voltage_table(rdev,\n\t\t\t\t\t\t&rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk,\n\t\t\t\t\t\t&pi->mvdd_voltage_table);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (pi->mvdd_voltage_table.count > SMU7_MAX_LEVELS_MVDD)\n\t\tsi_trim_voltage_table_to_fit_state_table(rdev, SMU7_MAX_LEVELS_MVDD,\n\t\t\t\t\t\t\t &pi->mvdd_voltage_table);\n\n\treturn 0;\n}\n\nstatic void ci_populate_smc_voltage_table(struct radeon_device *rdev,\n\t\t\t\t\t  struct atom_voltage_table_entry *voltage_table,\n\t\t\t\t\t  SMU7_Discrete_VoltageLevel *smc_voltage_table)\n{\n\tint ret;\n\n\tret = ci_get_std_voltage_value_sidd(rdev, voltage_table,\n\t\t\t\t\t    &smc_voltage_table->StdVoltageHiSidd,\n\t\t\t\t\t    &smc_voltage_table->StdVoltageLoSidd);\n\n\tif (ret) {\n\t\tsmc_voltage_table->StdVoltageHiSidd = voltage_table->value * VOLTAGE_SCALE;\n\t\tsmc_voltage_table->StdVoltageLoSidd = voltage_table->value * VOLTAGE_SCALE;\n\t}\n\n\tsmc_voltage_table->Voltage = cpu_to_be16(voltage_table->value * VOLTAGE_SCALE);\n\tsmc_voltage_table->StdVoltageHiSidd =\n\t\tcpu_to_be16(smc_voltage_table->StdVoltageHiSidd);\n\tsmc_voltage_table->StdVoltageLoSidd =\n\t\tcpu_to_be16(smc_voltage_table->StdVoltageLoSidd);\n}\n\nstatic int ci_populate_smc_vddc_table(struct radeon_device *rdev,\n\t\t\t\t      SMU7_Discrete_DpmTable *table)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tunsigned int count;\n\n\ttable->VddcLevelCount = pi->vddc_voltage_table.count;\n\tfor (count = 0; count < table->VddcLevelCount; count++) {\n\t\tci_populate_smc_voltage_table(rdev,\n\t\t\t\t\t      &pi->vddc_voltage_table.entries[count],\n\t\t\t\t\t      &table->VddcLevel[count]);\n\n\t\tif (pi->voltage_control == CISLANDS_VOLTAGE_CONTROL_BY_GPIO)\n\t\t\ttable->VddcLevel[count].Smio |=\n\t\t\t\tpi->vddc_voltage_table.entries[count].smio_low;\n\t\telse\n\t\t\ttable->VddcLevel[count].Smio = 0;\n\t}\n\ttable->VddcLevelCount = cpu_to_be32(table->VddcLevelCount);\n\n\treturn 0;\n}\n\nstatic int ci_populate_smc_vddci_table(struct radeon_device *rdev,\n\t\t\t\t       SMU7_Discrete_DpmTable *table)\n{\n\tunsigned int count;\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\ttable->VddciLevelCount = pi->vddci_voltage_table.count;\n\tfor (count = 0; count < table->VddciLevelCount; count++) {\n\t\tci_populate_smc_voltage_table(rdev,\n\t\t\t\t\t      &pi->vddci_voltage_table.entries[count],\n\t\t\t\t\t      &table->VddciLevel[count]);\n\n\t\tif (pi->vddci_control == CISLANDS_VOLTAGE_CONTROL_BY_GPIO)\n\t\t\ttable->VddciLevel[count].Smio |=\n\t\t\t\tpi->vddci_voltage_table.entries[count].smio_low;\n\t\telse\n\t\t\ttable->VddciLevel[count].Smio = 0;\n\t}\n\ttable->VddciLevelCount = cpu_to_be32(table->VddciLevelCount);\n\n\treturn 0;\n}\n\nstatic int ci_populate_smc_mvdd_table(struct radeon_device *rdev,\n\t\t\t\t      SMU7_Discrete_DpmTable *table)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tunsigned int count;\n\n\ttable->MvddLevelCount = pi->mvdd_voltage_table.count;\n\tfor (count = 0; count < table->MvddLevelCount; count++) {\n\t\tci_populate_smc_voltage_table(rdev,\n\t\t\t\t\t      &pi->mvdd_voltage_table.entries[count],\n\t\t\t\t\t      &table->MvddLevel[count]);\n\n\t\tif (pi->mvdd_control == CISLANDS_VOLTAGE_CONTROL_BY_GPIO)\n\t\t\ttable->MvddLevel[count].Smio |=\n\t\t\t\tpi->mvdd_voltage_table.entries[count].smio_low;\n\t\telse\n\t\t\ttable->MvddLevel[count].Smio = 0;\n\t}\n\ttable->MvddLevelCount = cpu_to_be32(table->MvddLevelCount);\n\n\treturn 0;\n}\n\nstatic int ci_populate_smc_voltage_tables(struct radeon_device *rdev,\n\t\t\t\t\t  SMU7_Discrete_DpmTable *table)\n{\n\tint ret;\n\n\tret = ci_populate_smc_vddc_table(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_populate_smc_vddci_table(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_populate_smc_mvdd_table(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int ci_populate_mvdd_value(struct radeon_device *rdev, u32 mclk,\n\t\t\t\t  SMU7_Discrete_VoltageLevel *voltage)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 i = 0;\n\n\tif (pi->mvdd_control != CISLANDS_VOLTAGE_CONTROL_NONE) {\n\t\tfor (i = 0; i < rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk.count; i++) {\n\t\t\tif (mclk <= rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk.entries[i].clk) {\n\t\t\t\tvoltage->Voltage = pi->mvdd_voltage_table.entries[i].value;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (i >= rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk.count)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int ci_get_std_voltage_value_sidd(struct radeon_device *rdev,\n\t\t\t\t\t struct atom_voltage_table_entry *voltage_table,\n\t\t\t\t\t u16 *std_voltage_hi_sidd, u16 *std_voltage_lo_sidd)\n{\n\tu16 v_index, idx;\n\tbool voltage_found = false;\n\t*std_voltage_hi_sidd = voltage_table->value * VOLTAGE_SCALE;\n\t*std_voltage_lo_sidd = voltage_table->value * VOLTAGE_SCALE;\n\n\tif (rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries == NULL)\n\t\treturn -EINVAL;\n\n\tif (rdev->pm.dpm.dyn_state.cac_leakage_table.entries) {\n\t\tfor (v_index = 0; (u32)v_index < rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count; v_index++) {\n\t\t\tif (voltage_table->value ==\n\t\t\t    rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[v_index].v) {\n\t\t\t\tvoltage_found = true;\n\t\t\t\tif ((u32)v_index < rdev->pm.dpm.dyn_state.cac_leakage_table.count)\n\t\t\t\t\tidx = v_index;\n\t\t\t\telse\n\t\t\t\t\tidx = rdev->pm.dpm.dyn_state.cac_leakage_table.count - 1;\n\t\t\t\t*std_voltage_lo_sidd =\n\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[idx].vddc * VOLTAGE_SCALE;\n\t\t\t\t*std_voltage_hi_sidd =\n\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[idx].leakage * VOLTAGE_SCALE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!voltage_found) {\n\t\t\tfor (v_index = 0; (u32)v_index < rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count; v_index++) {\n\t\t\t\tif (voltage_table->value <=\n\t\t\t\t    rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[v_index].v) {\n\t\t\t\t\tvoltage_found = true;\n\t\t\t\t\tif ((u32)v_index < rdev->pm.dpm.dyn_state.cac_leakage_table.count)\n\t\t\t\t\t\tidx = v_index;\n\t\t\t\t\telse\n\t\t\t\t\t\tidx = rdev->pm.dpm.dyn_state.cac_leakage_table.count - 1;\n\t\t\t\t\t*std_voltage_lo_sidd =\n\t\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[idx].vddc * VOLTAGE_SCALE;\n\t\t\t\t\t*std_voltage_hi_sidd =\n\t\t\t\t\t\trdev->pm.dpm.dyn_state.cac_leakage_table.entries[idx].leakage * VOLTAGE_SCALE;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void ci_populate_phase_value_based_on_sclk(struct radeon_device *rdev,\n\t\t\t\t\t\t  const struct radeon_phase_shedding_limits_table *limits,\n\t\t\t\t\t\t  u32 sclk,\n\t\t\t\t\t\t  u32 *phase_shedding)\n{\n\tunsigned int i;\n\n\t*phase_shedding = 1;\n\n\tfor (i = 0; i < limits->count; i++) {\n\t\tif (sclk < limits->entries[i].sclk) {\n\t\t\t*phase_shedding = i;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void ci_populate_phase_value_based_on_mclk(struct radeon_device *rdev,\n\t\t\t\t\t\t  const struct radeon_phase_shedding_limits_table *limits,\n\t\t\t\t\t\t  u32 mclk,\n\t\t\t\t\t\t  u32 *phase_shedding)\n{\n\tunsigned int i;\n\n\t*phase_shedding = 1;\n\n\tfor (i = 0; i < limits->count; i++) {\n\t\tif (mclk < limits->entries[i].mclk) {\n\t\t\t*phase_shedding = i;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic int ci_init_arb_table_index(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\tint ret;\n\n\tret = ci_read_smc_sram_dword(rdev, pi->arb_table_start,\n\t\t\t\t     &tmp, pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\ttmp &= 0x00FFFFFF;\n\ttmp |= MC_CG_ARB_FREQ_F1 << 24;\n\n\treturn ci_write_smc_sram_dword(rdev, pi->arb_table_start,\n\t\t\t\t       tmp, pi->sram_end);\n}\n\nstatic int ci_get_dependency_volt_by_clk(struct radeon_device *rdev,\n\t\t\t\t\t struct radeon_clock_voltage_dependency_table *allowed_clock_voltage_table,\n\t\t\t\t\t u32 clock, u32 *voltage)\n{\n\tu32 i = 0;\n\n\tif (allowed_clock_voltage_table->count == 0)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < allowed_clock_voltage_table->count; i++) {\n\t\tif (allowed_clock_voltage_table->entries[i].clk >= clock) {\n\t\t\t*voltage = allowed_clock_voltage_table->entries[i].v;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t*voltage = allowed_clock_voltage_table->entries[i-1].v;\n\n\treturn 0;\n}\n\nstatic u8 ci_get_sleep_divider_id_from_clock(struct radeon_device *rdev,\n\t\t\t\t\t     u32 sclk, u32 min_sclk_in_sr)\n{\n\tu32 i;\n\tu32 tmp;\n\tu32 min = (min_sclk_in_sr > CISLAND_MINIMUM_ENGINE_CLOCK) ?\n\t\tmin_sclk_in_sr : CISLAND_MINIMUM_ENGINE_CLOCK;\n\n\tif (sclk < min)\n\t\treturn 0;\n\n\tfor (i = CISLAND_MAX_DEEPSLEEP_DIVIDER_ID;  ; i--) {\n\t\ttmp = sclk / (1 << i);\n\t\tif (tmp >= min || i == 0)\n\t\t\tbreak;\n\t}\n\n\treturn (u8)i;\n}\n\nstatic int ci_initial_switch_from_arb_f0_to_f1(struct radeon_device *rdev)\n{\n\treturn ni_copy_and_switch_arb_sets(rdev, MC_CG_ARB_FREQ_F0, MC_CG_ARB_FREQ_F1);\n}\n\nstatic int ci_reset_to_default(struct radeon_device *rdev)\n{\n\treturn (ci_send_msg_to_smc(rdev, PPSMC_MSG_ResetToDefaults) == PPSMC_Result_OK) ?\n\t\t0 : -EINVAL;\n}\n\nstatic int ci_force_switch_to_arb_f0(struct radeon_device *rdev)\n{\n\tu32 tmp;\n\n\ttmp = (RREG32_SMC(SMC_SCRATCH9) & 0x0000ff00) >> 8;\n\n\tif (tmp == MC_CG_ARB_FREQ_F0)\n\t\treturn 0;\n\n\treturn ni_copy_and_switch_arb_sets(rdev, tmp, MC_CG_ARB_FREQ_F0);\n}\n\nstatic void ci_register_patching_mc_arb(struct radeon_device *rdev,\n\t\t\t\t\tconst u32 engine_clock,\n\t\t\t\t\tconst u32 memory_clock,\n\t\t\t\t\tu32 *dram_timimg2)\n{\n\tbool patch;\n\tu32 tmp, tmp2;\n\n\ttmp = RREG32(MC_SEQ_MISC0);\n\tpatch = ((tmp & 0x0000f00) == 0x300) ? true : false;\n\n\tif (patch &&\n\t    ((rdev->pdev->device == 0x67B0) ||\n\t     (rdev->pdev->device == 0x67B1))) {\n\t\tif ((memory_clock > 100000) && (memory_clock <= 125000)) {\n\t\t\ttmp2 = (((0x31 * engine_clock) / 125000) - 1) & 0xff;\n\t\t\t*dram_timimg2 &= ~0x00ff0000;\n\t\t\t*dram_timimg2 |= tmp2 << 16;\n\t\t} else if ((memory_clock > 125000) && (memory_clock <= 137500)) {\n\t\t\ttmp2 = (((0x36 * engine_clock) / 137500) - 1) & 0xff;\n\t\t\t*dram_timimg2 &= ~0x00ff0000;\n\t\t\t*dram_timimg2 |= tmp2 << 16;\n\t\t}\n\t}\n}\n\n\nstatic int ci_populate_memory_timing_parameters(struct radeon_device *rdev,\n\t\t\t\t\t\tu32 sclk,\n\t\t\t\t\t\tu32 mclk,\n\t\t\t\t\t\tSMU7_Discrete_MCArbDramTimingTableEntry *arb_regs)\n{\n\tu32 dram_timing;\n\tu32 dram_timing2;\n\tu32 burst_time;\n\n\tradeon_atom_set_engine_dram_timings(rdev, sclk, mclk);\n\n\tdram_timing  = RREG32(MC_ARB_DRAM_TIMING);\n\tdram_timing2 = RREG32(MC_ARB_DRAM_TIMING2);\n\tburst_time = RREG32(MC_ARB_BURST_TIME) & STATE0_MASK;\n\n\tci_register_patching_mc_arb(rdev, sclk, mclk, &dram_timing2);\n\n\tarb_regs->McArbDramTiming  = cpu_to_be32(dram_timing);\n\tarb_regs->McArbDramTiming2 = cpu_to_be32(dram_timing2);\n\tarb_regs->McArbBurstTime = (u8)burst_time;\n\n\treturn 0;\n}\n\nstatic int ci_do_program_memory_timing_parameters(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tSMU7_Discrete_MCArbDramTimingTable arb_regs;\n\tu32 i, j;\n\tint ret =  0;\n\n\tmemset(&arb_regs, 0, sizeof(SMU7_Discrete_MCArbDramTimingTable));\n\n\tfor (i = 0; i < pi->dpm_table.sclk_table.count; i++) {\n\t\tfor (j = 0; j < pi->dpm_table.mclk_table.count; j++) {\n\t\t\tret = ci_populate_memory_timing_parameters(rdev,\n\t\t\t\t\t\t\t\t   pi->dpm_table.sclk_table.dpm_levels[i].value,\n\t\t\t\t\t\t\t\t   pi->dpm_table.mclk_table.dpm_levels[j].value,\n\t\t\t\t\t\t\t\t   &arb_regs.entries[i][j]);\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (ret == 0)\n\t\tret = ci_copy_bytes_to_smc(rdev,\n\t\t\t\t\t   pi->arb_table_start,\n\t\t\t\t\t   (u8 *)&arb_regs,\n\t\t\t\t\t   sizeof(SMU7_Discrete_MCArbDramTimingTable),\n\t\t\t\t\t   pi->sram_end);\n\n\treturn ret;\n}\n\nstatic int ci_program_memory_timing_parameters(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (pi->need_update_smu7_dpm_table == 0)\n\t\treturn 0;\n\n\treturn ci_do_program_memory_timing_parameters(rdev);\n}\n\nstatic void ci_populate_smc_initial_state(struct radeon_device *rdev,\n\t\t\t\t\t  struct radeon_ps *radeon_boot_state)\n{\n\tstruct ci_ps *boot_state = ci_get_ps(radeon_boot_state);\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 level = 0;\n\n\tfor (level = 0; level < rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.count; level++) {\n\t\tif (rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[level].clk >=\n\t\t    boot_state->performance_levels[0].sclk) {\n\t\t\tpi->smc_state_table.GraphicsBootLevel = level;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tfor (level = 0; level < rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk.count; level++) {\n\t\tif (rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk.entries[level].clk >=\n\t\t    boot_state->performance_levels[0].mclk) {\n\t\t\tpi->smc_state_table.MemoryBootLevel = level;\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic u32 ci_get_dpm_level_enable_mask_value(struct ci_single_dpm_table *dpm_table)\n{\n\tu32 i;\n\tu32 mask_value = 0;\n\n\tfor (i = dpm_table->count; i > 0; i--) {\n\t\tmask_value = mask_value << 1;\n\t\tif (dpm_table->dpm_levels[i-1].enabled)\n\t\t\tmask_value |= 0x1;\n\t\telse\n\t\t\tmask_value &= 0xFFFFFFFE;\n\t}\n\n\treturn mask_value;\n}\n\nstatic void ci_populate_smc_link_level(struct radeon_device *rdev,\n\t\t\t\t       SMU7_Discrete_DpmTable *table)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_dpm_table *dpm_table = &pi->dpm_table;\n\tu32 i;\n\n\tfor (i = 0; i < dpm_table->pcie_speed_table.count; i++) {\n\t\ttable->LinkLevel[i].PcieGenSpeed =\n\t\t\t(u8)dpm_table->pcie_speed_table.dpm_levels[i].value;\n\t\ttable->LinkLevel[i].PcieLaneCount =\n\t\t\tr600_encode_pci_lane_width(dpm_table->pcie_speed_table.dpm_levels[i].param1);\n\t\ttable->LinkLevel[i].EnabledForActivity = 1;\n\t\ttable->LinkLevel[i].DownT = cpu_to_be32(5);\n\t\ttable->LinkLevel[i].UpT = cpu_to_be32(30);\n\t}\n\n\tpi->smc_state_table.LinkLevelCount = (u8)dpm_table->pcie_speed_table.count;\n\tpi->dpm_level_enable_mask.pcie_dpm_enable_mask =\n\t\tci_get_dpm_level_enable_mask_value(&dpm_table->pcie_speed_table);\n}\n\nstatic int ci_populate_smc_uvd_level(struct radeon_device *rdev,\n\t\t\t\t     SMU7_Discrete_DpmTable *table)\n{\n\tu32 count;\n\tstruct atom_clock_dividers dividers;\n\tint ret = -EINVAL;\n\n\ttable->UvdLevelCount =\n\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.count;\n\n\tfor (count = 0; count < table->UvdLevelCount; count++) {\n\t\ttable->UvdLevel[count].VclkFrequency =\n\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries[count].vclk;\n\t\ttable->UvdLevel[count].DclkFrequency =\n\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries[count].dclk;\n\t\ttable->UvdLevel[count].MinVddc =\n\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries[count].v * VOLTAGE_SCALE;\n\t\ttable->UvdLevel[count].MinVddcPhases = 1;\n\n\t\tret = radeon_atom_get_clock_dividers(rdev,\n\t\t\t\t\t\t     COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\n\t\t\t\t\t\t     table->UvdLevel[count].VclkFrequency, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\ttable->UvdLevel[count].VclkDivider = (u8)dividers.post_divider;\n\n\t\tret = radeon_atom_get_clock_dividers(rdev,\n\t\t\t\t\t\t     COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\n\t\t\t\t\t\t     table->UvdLevel[count].DclkFrequency, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\ttable->UvdLevel[count].DclkDivider = (u8)dividers.post_divider;\n\n\t\ttable->UvdLevel[count].VclkFrequency = cpu_to_be32(table->UvdLevel[count].VclkFrequency);\n\t\ttable->UvdLevel[count].DclkFrequency = cpu_to_be32(table->UvdLevel[count].DclkFrequency);\n\t\ttable->UvdLevel[count].MinVddc = cpu_to_be16(table->UvdLevel[count].MinVddc);\n\t}\n\n\treturn ret;\n}\n\nstatic int ci_populate_smc_vce_level(struct radeon_device *rdev,\n\t\t\t\t     SMU7_Discrete_DpmTable *table)\n{\n\tu32 count;\n\tstruct atom_clock_dividers dividers;\n\tint ret = -EINVAL;\n\n\ttable->VceLevelCount =\n\t\trdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.count;\n\n\tfor (count = 0; count < table->VceLevelCount; count++) {\n\t\ttable->VceLevel[count].Frequency =\n\t\t\trdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries[count].evclk;\n\t\ttable->VceLevel[count].MinVoltage =\n\t\t\t(u16)rdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries[count].v * VOLTAGE_SCALE;\n\t\ttable->VceLevel[count].MinPhases = 1;\n\n\t\tret = radeon_atom_get_clock_dividers(rdev,\n\t\t\t\t\t\t     COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\n\t\t\t\t\t\t     table->VceLevel[count].Frequency, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\ttable->VceLevel[count].Divider = (u8)dividers.post_divider;\n\n\t\ttable->VceLevel[count].Frequency = cpu_to_be32(table->VceLevel[count].Frequency);\n\t\ttable->VceLevel[count].MinVoltage = cpu_to_be16(table->VceLevel[count].MinVoltage);\n\t}\n\n\treturn ret;\n\n}\n\nstatic int ci_populate_smc_acp_level(struct radeon_device *rdev,\n\t\t\t\t     SMU7_Discrete_DpmTable *table)\n{\n\tu32 count;\n\tstruct atom_clock_dividers dividers;\n\tint ret = -EINVAL;\n\n\ttable->AcpLevelCount = (u8)\n\t\t(rdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.count);\n\n\tfor (count = 0; count < table->AcpLevelCount; count++) {\n\t\ttable->AcpLevel[count].Frequency =\n\t\t\trdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.entries[count].clk;\n\t\ttable->AcpLevel[count].MinVoltage =\n\t\t\trdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.entries[count].v;\n\t\ttable->AcpLevel[count].MinPhases = 1;\n\n\t\tret = radeon_atom_get_clock_dividers(rdev,\n\t\t\t\t\t\t     COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\n\t\t\t\t\t\t     table->AcpLevel[count].Frequency, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\ttable->AcpLevel[count].Divider = (u8)dividers.post_divider;\n\n\t\ttable->AcpLevel[count].Frequency = cpu_to_be32(table->AcpLevel[count].Frequency);\n\t\ttable->AcpLevel[count].MinVoltage = cpu_to_be16(table->AcpLevel[count].MinVoltage);\n\t}\n\n\treturn ret;\n}\n\nstatic int ci_populate_smc_samu_level(struct radeon_device *rdev,\n\t\t\t\t      SMU7_Discrete_DpmTable *table)\n{\n\tu32 count;\n\tstruct atom_clock_dividers dividers;\n\tint ret = -EINVAL;\n\n\ttable->SamuLevelCount =\n\t\trdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.count;\n\n\tfor (count = 0; count < table->SamuLevelCount; count++) {\n\t\ttable->SamuLevel[count].Frequency =\n\t\t\trdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.entries[count].clk;\n\t\ttable->SamuLevel[count].MinVoltage =\n\t\t\trdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.entries[count].v * VOLTAGE_SCALE;\n\t\ttable->SamuLevel[count].MinPhases = 1;\n\n\t\tret = radeon_atom_get_clock_dividers(rdev,\n\t\t\t\t\t\t     COMPUTE_GPUCLK_INPUT_FLAG_DEFAULT_GPUCLK,\n\t\t\t\t\t\t     table->SamuLevel[count].Frequency, false, &dividers);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\ttable->SamuLevel[count].Divider = (u8)dividers.post_divider;\n\n\t\ttable->SamuLevel[count].Frequency = cpu_to_be32(table->SamuLevel[count].Frequency);\n\t\ttable->SamuLevel[count].MinVoltage = cpu_to_be16(table->SamuLevel[count].MinVoltage);\n\t}\n\n\treturn ret;\n}\n\nstatic int ci_calculate_mclk_params(struct radeon_device *rdev,\n\t\t\t\t    u32 memory_clock,\n\t\t\t\t    SMU7_Discrete_MemoryLevel *mclk,\n\t\t\t\t    bool strobe_mode,\n\t\t\t\t    bool dll_state_on)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32  dll_cntl = pi->clock_registers.dll_cntl;\n\tu32  mclk_pwrmgt_cntl = pi->clock_registers.mclk_pwrmgt_cntl;\n\tu32  mpll_ad_func_cntl = pi->clock_registers.mpll_ad_func_cntl;\n\tu32  mpll_dq_func_cntl = pi->clock_registers.mpll_dq_func_cntl;\n\tu32  mpll_func_cntl = pi->clock_registers.mpll_func_cntl;\n\tu32  mpll_func_cntl_1 = pi->clock_registers.mpll_func_cntl_1;\n\tu32  mpll_func_cntl_2 = pi->clock_registers.mpll_func_cntl_2;\n\tu32  mpll_ss1 = pi->clock_registers.mpll_ss1;\n\tu32  mpll_ss2 = pi->clock_registers.mpll_ss2;\n\tstruct atom_mpll_param mpll_param;\n\tint ret;\n\n\tret = radeon_atom_get_memory_pll_dividers(rdev, memory_clock, strobe_mode, &mpll_param);\n\tif (ret)\n\t\treturn ret;\n\n\tmpll_func_cntl &= ~BWCTRL_MASK;\n\tmpll_func_cntl |= BWCTRL(mpll_param.bwcntl);\n\n\tmpll_func_cntl_1 &= ~(CLKF_MASK | CLKFRAC_MASK | VCO_MODE_MASK);\n\tmpll_func_cntl_1 |= CLKF(mpll_param.clkf) |\n\t\tCLKFRAC(mpll_param.clkfrac) | VCO_MODE(mpll_param.vco_mode);\n\n\tmpll_ad_func_cntl &= ~YCLK_POST_DIV_MASK;\n\tmpll_ad_func_cntl |= YCLK_POST_DIV(mpll_param.post_div);\n\n\tif (pi->mem_gddr5) {\n\t\tmpll_dq_func_cntl &= ~(YCLK_SEL_MASK | YCLK_POST_DIV_MASK);\n\t\tmpll_dq_func_cntl |= YCLK_SEL(mpll_param.yclk_sel) |\n\t\t\tYCLK_POST_DIV(mpll_param.post_div);\n\t}\n\n\tif (pi->caps_mclk_ss_support) {\n\t\tstruct radeon_atom_ss ss;\n\t\tu32 freq_nom;\n\t\tu32 tmp;\n\t\tu32 reference_clock = rdev->clock.mpll.reference_freq;\n\n\t\tif (mpll_param.qdr == 1)\n\t\t\tfreq_nom = memory_clock * 4 * (1 << mpll_param.post_div);\n\t\telse\n\t\t\tfreq_nom = memory_clock * 2 * (1 << mpll_param.post_div);\n\n\t\ttmp = (freq_nom / reference_clock);\n\t\ttmp = tmp * tmp;\n\t\tif (radeon_atombios_get_asic_ss_info(rdev, &ss,\n\t\t\t\t\t\t     ASIC_INTERNAL_MEMORY_SS, freq_nom)) {\n\t\t\tu32 clks = reference_clock * 5 / ss.rate;\n\t\t\tu32 clkv = (u32)((((131 * ss.percentage * ss.rate) / 100) * tmp) / freq_nom);\n\n\t\t\tmpll_ss1 &= ~CLKV_MASK;\n\t\t\tmpll_ss1 |= CLKV(clkv);\n\n\t\t\tmpll_ss2 &= ~CLKS_MASK;\n\t\t\tmpll_ss2 |= CLKS(clks);\n\t\t}\n\t}\n\n\tmclk_pwrmgt_cntl &= ~DLL_SPEED_MASK;\n\tmclk_pwrmgt_cntl |= DLL_SPEED(mpll_param.dll_speed);\n\n\tif (dll_state_on)\n\t\tmclk_pwrmgt_cntl |= MRDCK0_PDNB | MRDCK1_PDNB;\n\telse\n\t\tmclk_pwrmgt_cntl &= ~(MRDCK0_PDNB | MRDCK1_PDNB);\n\n\tmclk->MclkFrequency = memory_clock;\n\tmclk->MpllFuncCntl = mpll_func_cntl;\n\tmclk->MpllFuncCntl_1 = mpll_func_cntl_1;\n\tmclk->MpllFuncCntl_2 = mpll_func_cntl_2;\n\tmclk->MpllAdFuncCntl = mpll_ad_func_cntl;\n\tmclk->MpllDqFuncCntl = mpll_dq_func_cntl;\n\tmclk->MclkPwrmgtCntl = mclk_pwrmgt_cntl;\n\tmclk->DllCntl = dll_cntl;\n\tmclk->MpllSs1 = mpll_ss1;\n\tmclk->MpllSs2 = mpll_ss2;\n\n\treturn 0;\n}\n\nstatic int ci_populate_single_memory_level(struct radeon_device *rdev,\n\t\t\t\t\t   u32 memory_clock,\n\t\t\t\t\t   SMU7_Discrete_MemoryLevel *memory_level)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret;\n\tbool dll_state_on;\n\n\tif (rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk.entries) {\n\t\tret = ci_get_dependency_volt_by_clk(rdev,\n\t\t\t\t\t\t    &rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk,\n\t\t\t\t\t\t    memory_clock, &memory_level->MinVddc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk.entries) {\n\t\tret = ci_get_dependency_volt_by_clk(rdev,\n\t\t\t\t\t\t    &rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk,\n\t\t\t\t\t\t    memory_clock, &memory_level->MinVddci);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk.entries) {\n\t\tret = ci_get_dependency_volt_by_clk(rdev,\n\t\t\t\t\t\t    &rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk,\n\t\t\t\t\t\t    memory_clock, &memory_level->MinMvdd);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tmemory_level->MinVddcPhases = 1;\n\n\tif (pi->vddc_phase_shed_control)\n\t\tci_populate_phase_value_based_on_mclk(rdev,\n\t\t\t\t\t\t      &rdev->pm.dpm.dyn_state.phase_shedding_limits_table,\n\t\t\t\t\t\t      memory_clock,\n\t\t\t\t\t\t      &memory_level->MinVddcPhases);\n\n\tmemory_level->EnabledForThrottle = 1;\n\tmemory_level->UpH = 0;\n\tmemory_level->DownH = 100;\n\tmemory_level->VoltageDownH = 0;\n\tmemory_level->ActivityLevel = (u16)pi->mclk_activity_target;\n\n\tmemory_level->StutterEnable = false;\n\tmemory_level->StrobeEnable = false;\n\tmemory_level->EdcReadEnable = false;\n\tmemory_level->EdcWriteEnable = false;\n\tmemory_level->RttEnable = false;\n\n\tmemory_level->DisplayWatermark = PPSMC_DISPLAY_WATERMARK_LOW;\n\n\tif (pi->mclk_stutter_mode_threshold &&\n\t    (memory_clock <= pi->mclk_stutter_mode_threshold) &&\n\t    (pi->uvd_enabled == false) &&\n\t    (RREG32(DPG_PIPE_STUTTER_CONTROL) & STUTTER_ENABLE) &&\n\t    (rdev->pm.dpm.new_active_crtc_count <= 2))\n\t\tmemory_level->StutterEnable = true;\n\n\tif (pi->mclk_strobe_mode_threshold &&\n\t    (memory_clock <= pi->mclk_strobe_mode_threshold))\n\t\tmemory_level->StrobeEnable = 1;\n\n\tif (pi->mem_gddr5) {\n\t\tmemory_level->StrobeRatio =\n\t\t\tsi_get_mclk_frequency_ratio(memory_clock, memory_level->StrobeEnable);\n\t\tif (pi->mclk_edc_enable_threshold &&\n\t\t    (memory_clock > pi->mclk_edc_enable_threshold))\n\t\t\tmemory_level->EdcReadEnable = true;\n\n\t\tif (pi->mclk_edc_wr_enable_threshold &&\n\t\t    (memory_clock > pi->mclk_edc_wr_enable_threshold))\n\t\t\tmemory_level->EdcWriteEnable = true;\n\n\t\tif (memory_level->StrobeEnable) {\n\t\t\tif (si_get_mclk_frequency_ratio(memory_clock, true) >=\n\t\t\t    ((RREG32(MC_SEQ_MISC7) >> 16) & 0xf))\n\t\t\t\tdll_state_on = ((RREG32(MC_SEQ_MISC5) >> 1) & 0x1) ? true : false;\n\t\t\telse\n\t\t\t\tdll_state_on = ((RREG32(MC_SEQ_MISC6) >> 1) & 0x1) ? true : false;\n\t\t} else {\n\t\t\tdll_state_on = pi->dll_default_on;\n\t\t}\n\t} else {\n\t\tmemory_level->StrobeRatio = si_get_ddr3_mclk_frequency_ratio(memory_clock);\n\t\tdll_state_on = ((RREG32(MC_SEQ_MISC5) >> 1) & 0x1) ? true : false;\n\t}\n\n\tret = ci_calculate_mclk_params(rdev, memory_clock, memory_level, memory_level->StrobeEnable, dll_state_on);\n\tif (ret)\n\t\treturn ret;\n\n\tmemory_level->MinVddc = cpu_to_be32(memory_level->MinVddc * VOLTAGE_SCALE);\n\tmemory_level->MinVddcPhases = cpu_to_be32(memory_level->MinVddcPhases);\n\tmemory_level->MinVddci = cpu_to_be32(memory_level->MinVddci * VOLTAGE_SCALE);\n\tmemory_level->MinMvdd = cpu_to_be32(memory_level->MinMvdd * VOLTAGE_SCALE);\n\n\tmemory_level->MclkFrequency = cpu_to_be32(memory_level->MclkFrequency);\n\tmemory_level->ActivityLevel = cpu_to_be16(memory_level->ActivityLevel);\n\tmemory_level->MpllFuncCntl = cpu_to_be32(memory_level->MpllFuncCntl);\n\tmemory_level->MpllFuncCntl_1 = cpu_to_be32(memory_level->MpllFuncCntl_1);\n\tmemory_level->MpllFuncCntl_2 = cpu_to_be32(memory_level->MpllFuncCntl_2);\n\tmemory_level->MpllAdFuncCntl = cpu_to_be32(memory_level->MpllAdFuncCntl);\n\tmemory_level->MpllDqFuncCntl = cpu_to_be32(memory_level->MpllDqFuncCntl);\n\tmemory_level->MclkPwrmgtCntl = cpu_to_be32(memory_level->MclkPwrmgtCntl);\n\tmemory_level->DllCntl = cpu_to_be32(memory_level->DllCntl);\n\tmemory_level->MpllSs1 = cpu_to_be32(memory_level->MpllSs1);\n\tmemory_level->MpllSs2 = cpu_to_be32(memory_level->MpllSs2);\n\n\treturn 0;\n}\n\nstatic int ci_populate_smc_acpi_level(struct radeon_device *rdev,\n\t\t\t\t      SMU7_Discrete_DpmTable *table)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct atom_clock_dividers dividers;\n\tSMU7_Discrete_VoltageLevel voltage_level;\n\tu32 spll_func_cntl = pi->clock_registers.cg_spll_func_cntl;\n\tu32 spll_func_cntl_2 = pi->clock_registers.cg_spll_func_cntl_2;\n\tu32 dll_cntl = pi->clock_registers.dll_cntl;\n\tu32 mclk_pwrmgt_cntl = pi->clock_registers.mclk_pwrmgt_cntl;\n\tint ret;\n\n\ttable->ACPILevel.Flags &= ~PPSMC_SWSTATE_FLAG_DC;\n\n\tif (pi->acpi_vddc)\n\t\ttable->ACPILevel.MinVddc = cpu_to_be32(pi->acpi_vddc * VOLTAGE_SCALE);\n\telse\n\t\ttable->ACPILevel.MinVddc = cpu_to_be32(pi->min_vddc_in_pp_table * VOLTAGE_SCALE);\n\n\ttable->ACPILevel.MinVddcPhases = pi->vddc_phase_shed_control ? 0 : 1;\n\n\ttable->ACPILevel.SclkFrequency = rdev->clock.spll.reference_freq;\n\n\tret = radeon_atom_get_clock_dividers(rdev,\n\t\t\t\t\t     COMPUTE_GPUCLK_INPUT_FLAG_SCLK,\n\t\t\t\t\t     table->ACPILevel.SclkFrequency, false, &dividers);\n\tif (ret)\n\t\treturn ret;\n\n\ttable->ACPILevel.SclkDid = (u8)dividers.post_divider;\n\ttable->ACPILevel.DisplayWatermark = PPSMC_DISPLAY_WATERMARK_LOW;\n\ttable->ACPILevel.DeepSleepDivId = 0;\n\n\tspll_func_cntl &= ~SPLL_PWRON;\n\tspll_func_cntl |= SPLL_RESET;\n\n\tspll_func_cntl_2 &= ~SCLK_MUX_SEL_MASK;\n\tspll_func_cntl_2 |= SCLK_MUX_SEL(4);\n\n\ttable->ACPILevel.CgSpllFuncCntl = spll_func_cntl;\n\ttable->ACPILevel.CgSpllFuncCntl2 = spll_func_cntl_2;\n\ttable->ACPILevel.CgSpllFuncCntl3 = pi->clock_registers.cg_spll_func_cntl_3;\n\ttable->ACPILevel.CgSpllFuncCntl4 = pi->clock_registers.cg_spll_func_cntl_4;\n\ttable->ACPILevel.SpllSpreadSpectrum = pi->clock_registers.cg_spll_spread_spectrum;\n\ttable->ACPILevel.SpllSpreadSpectrum2 = pi->clock_registers.cg_spll_spread_spectrum_2;\n\ttable->ACPILevel.CcPwrDynRm = 0;\n\ttable->ACPILevel.CcPwrDynRm1 = 0;\n\n\ttable->ACPILevel.Flags = cpu_to_be32(table->ACPILevel.Flags);\n\ttable->ACPILevel.MinVddcPhases = cpu_to_be32(table->ACPILevel.MinVddcPhases);\n\ttable->ACPILevel.SclkFrequency = cpu_to_be32(table->ACPILevel.SclkFrequency);\n\ttable->ACPILevel.CgSpllFuncCntl = cpu_to_be32(table->ACPILevel.CgSpllFuncCntl);\n\ttable->ACPILevel.CgSpllFuncCntl2 = cpu_to_be32(table->ACPILevel.CgSpllFuncCntl2);\n\ttable->ACPILevel.CgSpllFuncCntl3 = cpu_to_be32(table->ACPILevel.CgSpllFuncCntl3);\n\ttable->ACPILevel.CgSpllFuncCntl4 = cpu_to_be32(table->ACPILevel.CgSpllFuncCntl4);\n\ttable->ACPILevel.SpllSpreadSpectrum = cpu_to_be32(table->ACPILevel.SpllSpreadSpectrum);\n\ttable->ACPILevel.SpllSpreadSpectrum2 = cpu_to_be32(table->ACPILevel.SpllSpreadSpectrum2);\n\ttable->ACPILevel.CcPwrDynRm = cpu_to_be32(table->ACPILevel.CcPwrDynRm);\n\ttable->ACPILevel.CcPwrDynRm1 = cpu_to_be32(table->ACPILevel.CcPwrDynRm1);\n\n\ttable->MemoryACPILevel.MinVddc = table->ACPILevel.MinVddc;\n\ttable->MemoryACPILevel.MinVddcPhases = table->ACPILevel.MinVddcPhases;\n\n\tif (pi->vddci_control != CISLANDS_VOLTAGE_CONTROL_NONE) {\n\t\tif (pi->acpi_vddci)\n\t\t\ttable->MemoryACPILevel.MinVddci =\n\t\t\t\tcpu_to_be32(pi->acpi_vddci * VOLTAGE_SCALE);\n\t\telse\n\t\t\ttable->MemoryACPILevel.MinVddci =\n\t\t\t\tcpu_to_be32(pi->min_vddci_in_pp_table * VOLTAGE_SCALE);\n\t}\n\n\tif (ci_populate_mvdd_value(rdev, 0, &voltage_level))\n\t\ttable->MemoryACPILevel.MinMvdd = 0;\n\telse\n\t\ttable->MemoryACPILevel.MinMvdd =\n\t\t\tcpu_to_be32(voltage_level.Voltage * VOLTAGE_SCALE);\n\n\tmclk_pwrmgt_cntl |= MRDCK0_RESET | MRDCK1_RESET;\n\tmclk_pwrmgt_cntl &= ~(MRDCK0_PDNB | MRDCK1_PDNB);\n\n\tdll_cntl &= ~(MRDCK0_BYPASS | MRDCK1_BYPASS);\n\n\ttable->MemoryACPILevel.DllCntl = cpu_to_be32(dll_cntl);\n\ttable->MemoryACPILevel.MclkPwrmgtCntl = cpu_to_be32(mclk_pwrmgt_cntl);\n\ttable->MemoryACPILevel.MpllAdFuncCntl =\n\t\tcpu_to_be32(pi->clock_registers.mpll_ad_func_cntl);\n\ttable->MemoryACPILevel.MpllDqFuncCntl =\n\t\tcpu_to_be32(pi->clock_registers.mpll_dq_func_cntl);\n\ttable->MemoryACPILevel.MpllFuncCntl =\n\t\tcpu_to_be32(pi->clock_registers.mpll_func_cntl);\n\ttable->MemoryACPILevel.MpllFuncCntl_1 =\n\t\tcpu_to_be32(pi->clock_registers.mpll_func_cntl_1);\n\ttable->MemoryACPILevel.MpllFuncCntl_2 =\n\t\tcpu_to_be32(pi->clock_registers.mpll_func_cntl_2);\n\ttable->MemoryACPILevel.MpllSs1 = cpu_to_be32(pi->clock_registers.mpll_ss1);\n\ttable->MemoryACPILevel.MpllSs2 = cpu_to_be32(pi->clock_registers.mpll_ss2);\n\n\ttable->MemoryACPILevel.EnabledForThrottle = 0;\n\ttable->MemoryACPILevel.EnabledForActivity = 0;\n\ttable->MemoryACPILevel.UpH = 0;\n\ttable->MemoryACPILevel.DownH = 100;\n\ttable->MemoryACPILevel.VoltageDownH = 0;\n\ttable->MemoryACPILevel.ActivityLevel =\n\t\tcpu_to_be16((u16)pi->mclk_activity_target);\n\n\ttable->MemoryACPILevel.StutterEnable = false;\n\ttable->MemoryACPILevel.StrobeEnable = false;\n\ttable->MemoryACPILevel.EdcReadEnable = false;\n\ttable->MemoryACPILevel.EdcWriteEnable = false;\n\ttable->MemoryACPILevel.RttEnable = false;\n\n\treturn 0;\n}\n\n\nstatic int ci_enable_ulv(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_ulv_parm *ulv = &pi->ulv;\n\n\tif (ulv->supported) {\n\t\tif (enable)\n\t\t\treturn (ci_send_msg_to_smc(rdev, PPSMC_MSG_EnableULV) == PPSMC_Result_OK) ?\n\t\t\t\t0 : -EINVAL;\n\t\telse\n\t\t\treturn (ci_send_msg_to_smc(rdev, PPSMC_MSG_DisableULV) == PPSMC_Result_OK) ?\n\t\t\t\t0 : -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_populate_ulv_level(struct radeon_device *rdev,\n\t\t\t\t SMU7_Discrete_Ulv *state)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu16 ulv_voltage = rdev->pm.dpm.backbias_response_time;\n\n\tstate->CcPwrDynRm = 0;\n\tstate->CcPwrDynRm1 = 0;\n\n\tif (ulv_voltage == 0) {\n\t\tpi->ulv.supported = false;\n\t\treturn 0;\n\t}\n\n\tif (pi->voltage_control != CISLANDS_VOLTAGE_CONTROL_BY_SVID2) {\n\t\tif (ulv_voltage > rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[0].v)\n\t\t\tstate->VddcOffset = 0;\n\t\telse\n\t\t\tstate->VddcOffset =\n\t\t\t\trdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[0].v - ulv_voltage;\n\t} else {\n\t\tif (ulv_voltage > rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[0].v)\n\t\t\tstate->VddcOffsetVid = 0;\n\t\telse\n\t\t\tstate->VddcOffsetVid = (u8)\n\t\t\t\t((rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk.entries[0].v - ulv_voltage) *\n\t\t\t\t VOLTAGE_VID_OFFSET_SCALE2 / VOLTAGE_VID_OFFSET_SCALE1);\n\t}\n\tstate->VddcPhase = pi->vddc_phase_shed_control ? 0 : 1;\n\n\tstate->CcPwrDynRm = cpu_to_be32(state->CcPwrDynRm);\n\tstate->CcPwrDynRm1 = cpu_to_be32(state->CcPwrDynRm1);\n\tstate->VddcOffset = cpu_to_be16(state->VddcOffset);\n\n\treturn 0;\n}\n\nstatic int ci_calculate_sclk_params(struct radeon_device *rdev,\n\t\t\t\t    u32 engine_clock,\n\t\t\t\t    SMU7_Discrete_GraphicsLevel *sclk)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct atom_clock_dividers dividers;\n\tu32 spll_func_cntl_3 = pi->clock_registers.cg_spll_func_cntl_3;\n\tu32 spll_func_cntl_4 = pi->clock_registers.cg_spll_func_cntl_4;\n\tu32 cg_spll_spread_spectrum = pi->clock_registers.cg_spll_spread_spectrum;\n\tu32 cg_spll_spread_spectrum_2 = pi->clock_registers.cg_spll_spread_spectrum_2;\n\tu32 reference_clock = rdev->clock.spll.reference_freq;\n\tu32 reference_divider;\n\tu32 fbdiv;\n\tint ret;\n\n\tret = radeon_atom_get_clock_dividers(rdev,\n\t\t\t\t\t     COMPUTE_GPUCLK_INPUT_FLAG_SCLK,\n\t\t\t\t\t     engine_clock, false, &dividers);\n\tif (ret)\n\t\treturn ret;\n\n\treference_divider = 1 + dividers.ref_div;\n\tfbdiv = dividers.fb_div & 0x3FFFFFF;\n\n\tspll_func_cntl_3 &= ~SPLL_FB_DIV_MASK;\n\tspll_func_cntl_3 |= SPLL_FB_DIV(fbdiv);\n\tspll_func_cntl_3 |= SPLL_DITHEN;\n\n\tif (pi->caps_sclk_ss_support) {\n\t\tstruct radeon_atom_ss ss;\n\t\tu32 vco_freq = engine_clock * dividers.post_div;\n\n\t\tif (radeon_atombios_get_asic_ss_info(rdev, &ss,\n\t\t\t\t\t\t     ASIC_INTERNAL_ENGINE_SS, vco_freq)) {\n\t\t\tu32 clk_s = reference_clock * 5 / (reference_divider * ss.rate);\n\t\t\tu32 clk_v = 4 * ss.percentage * fbdiv / (clk_s * 10000);\n\n\t\t\tcg_spll_spread_spectrum &= ~CLK_S_MASK;\n\t\t\tcg_spll_spread_spectrum |= CLK_S(clk_s);\n\t\t\tcg_spll_spread_spectrum |= SSEN;\n\n\t\t\tcg_spll_spread_spectrum_2 &= ~CLK_V_MASK;\n\t\t\tcg_spll_spread_spectrum_2 |= CLK_V(clk_v);\n\t\t}\n\t}\n\n\tsclk->SclkFrequency = engine_clock;\n\tsclk->CgSpllFuncCntl3 = spll_func_cntl_3;\n\tsclk->CgSpllFuncCntl4 = spll_func_cntl_4;\n\tsclk->SpllSpreadSpectrum = cg_spll_spread_spectrum;\n\tsclk->SpllSpreadSpectrum2  = cg_spll_spread_spectrum_2;\n\tsclk->SclkDid = (u8)dividers.post_divider;\n\n\treturn 0;\n}\n\nstatic int ci_populate_single_graphic_level(struct radeon_device *rdev,\n\t\t\t\t\t    u32 engine_clock,\n\t\t\t\t\t    u16 sclk_activity_level_t,\n\t\t\t\t\t    SMU7_Discrete_GraphicsLevel *graphic_level)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret;\n\n\tret = ci_calculate_sclk_params(rdev, engine_clock, graphic_level);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_get_dependency_volt_by_clk(rdev,\n\t\t\t\t\t    &rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk,\n\t\t\t\t\t    engine_clock, &graphic_level->MinVddc);\n\tif (ret)\n\t\treturn ret;\n\n\tgraphic_level->SclkFrequency = engine_clock;\n\n\tgraphic_level->Flags =  0;\n\tgraphic_level->MinVddcPhases = 1;\n\n\tif (pi->vddc_phase_shed_control)\n\t\tci_populate_phase_value_based_on_sclk(rdev,\n\t\t\t\t\t\t      &rdev->pm.dpm.dyn_state.phase_shedding_limits_table,\n\t\t\t\t\t\t      engine_clock,\n\t\t\t\t\t\t      &graphic_level->MinVddcPhases);\n\n\tgraphic_level->ActivityLevel = sclk_activity_level_t;\n\n\tgraphic_level->CcPwrDynRm = 0;\n\tgraphic_level->CcPwrDynRm1 = 0;\n\tgraphic_level->EnabledForThrottle = 1;\n\tgraphic_level->UpH = 0;\n\tgraphic_level->DownH = 0;\n\tgraphic_level->VoltageDownH = 0;\n\tgraphic_level->PowerThrottle = 0;\n\n\tif (pi->caps_sclk_ds)\n\t\tgraphic_level->DeepSleepDivId = ci_get_sleep_divider_id_from_clock(rdev,\n\t\t\t\t\t\t\t\t\t\t   engine_clock,\n\t\t\t\t\t\t\t\t\t\t   CISLAND_MINIMUM_ENGINE_CLOCK);\n\n\tgraphic_level->DisplayWatermark = PPSMC_DISPLAY_WATERMARK_LOW;\n\n\tgraphic_level->Flags = cpu_to_be32(graphic_level->Flags);\n\tgraphic_level->MinVddc = cpu_to_be32(graphic_level->MinVddc * VOLTAGE_SCALE);\n\tgraphic_level->MinVddcPhases = cpu_to_be32(graphic_level->MinVddcPhases);\n\tgraphic_level->SclkFrequency = cpu_to_be32(graphic_level->SclkFrequency);\n\tgraphic_level->ActivityLevel = cpu_to_be16(graphic_level->ActivityLevel);\n\tgraphic_level->CgSpllFuncCntl3 = cpu_to_be32(graphic_level->CgSpllFuncCntl3);\n\tgraphic_level->CgSpllFuncCntl4 = cpu_to_be32(graphic_level->CgSpllFuncCntl4);\n\tgraphic_level->SpllSpreadSpectrum = cpu_to_be32(graphic_level->SpllSpreadSpectrum);\n\tgraphic_level->SpllSpreadSpectrum2 = cpu_to_be32(graphic_level->SpllSpreadSpectrum2);\n\tgraphic_level->CcPwrDynRm = cpu_to_be32(graphic_level->CcPwrDynRm);\n\tgraphic_level->CcPwrDynRm1 = cpu_to_be32(graphic_level->CcPwrDynRm1);\n\n\treturn 0;\n}\n\nstatic int ci_populate_all_graphic_levels(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_dpm_table *dpm_table = &pi->dpm_table;\n\tu32 level_array_address = pi->dpm_table_start +\n\t\toffsetof(SMU7_Discrete_DpmTable, GraphicsLevel);\n\tu32 level_array_size = sizeof(SMU7_Discrete_GraphicsLevel) *\n\t\tSMU7_MAX_LEVELS_GRAPHICS;\n\tSMU7_Discrete_GraphicsLevel *levels = pi->smc_state_table.GraphicsLevel;\n\tu32 i, ret;\n\n\tmemset(levels, 0, level_array_size);\n\n\tfor (i = 0; i < dpm_table->sclk_table.count; i++) {\n\t\tret = ci_populate_single_graphic_level(rdev,\n\t\t\t\t\t\t       dpm_table->sclk_table.dpm_levels[i].value,\n\t\t\t\t\t\t       (u16)pi->activity_target[i],\n\t\t\t\t\t\t       &pi->smc_state_table.GraphicsLevel[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (i > 1)\n\t\t\tpi->smc_state_table.GraphicsLevel[i].DeepSleepDivId = 0;\n\t\tif (i == (dpm_table->sclk_table.count - 1))\n\t\t\tpi->smc_state_table.GraphicsLevel[i].DisplayWatermark =\n\t\t\t\tPPSMC_DISPLAY_WATERMARK_HIGH;\n\t}\n\tpi->smc_state_table.GraphicsLevel[0].EnabledForActivity = 1;\n\n\tpi->smc_state_table.GraphicsDpmLevelCount = (u8)dpm_table->sclk_table.count;\n\tpi->dpm_level_enable_mask.sclk_dpm_enable_mask =\n\t\tci_get_dpm_level_enable_mask_value(&dpm_table->sclk_table);\n\n\tret = ci_copy_bytes_to_smc(rdev, level_array_address,\n\t\t\t\t   (u8 *)levels, level_array_size,\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int ci_populate_ulv_state(struct radeon_device *rdev,\n\t\t\t\t SMU7_Discrete_Ulv *ulv_level)\n{\n\treturn ci_populate_ulv_level(rdev, ulv_level);\n}\n\nstatic int ci_populate_all_memory_levels(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_dpm_table *dpm_table = &pi->dpm_table;\n\tu32 level_array_address = pi->dpm_table_start +\n\t\toffsetof(SMU7_Discrete_DpmTable, MemoryLevel);\n\tu32 level_array_size = sizeof(SMU7_Discrete_MemoryLevel) *\n\t\tSMU7_MAX_LEVELS_MEMORY;\n\tSMU7_Discrete_MemoryLevel *levels = pi->smc_state_table.MemoryLevel;\n\tu32 i, ret;\n\n\tmemset(levels, 0, level_array_size);\n\n\tfor (i = 0; i < dpm_table->mclk_table.count; i++) {\n\t\tif (dpm_table->mclk_table.dpm_levels[i].value == 0)\n\t\t\treturn -EINVAL;\n\t\tret = ci_populate_single_memory_level(rdev,\n\t\t\t\t\t\t      dpm_table->mclk_table.dpm_levels[i].value,\n\t\t\t\t\t\t      &pi->smc_state_table.MemoryLevel[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tpi->smc_state_table.MemoryLevel[0].EnabledForActivity = 1;\n\n\tif ((dpm_table->mclk_table.count >= 2) &&\n\t    ((rdev->pdev->device == 0x67B0) || (rdev->pdev->device == 0x67B1))) {\n\t\tpi->smc_state_table.MemoryLevel[1].MinVddc =\n\t\t\tpi->smc_state_table.MemoryLevel[0].MinVddc;\n\t\tpi->smc_state_table.MemoryLevel[1].MinVddcPhases =\n\t\t\tpi->smc_state_table.MemoryLevel[0].MinVddcPhases;\n\t}\n\n\tpi->smc_state_table.MemoryLevel[0].ActivityLevel = cpu_to_be16(0x1F);\n\n\tpi->smc_state_table.MemoryDpmLevelCount = (u8)dpm_table->mclk_table.count;\n\tpi->dpm_level_enable_mask.mclk_dpm_enable_mask =\n\t\tci_get_dpm_level_enable_mask_value(&dpm_table->mclk_table);\n\n\tpi->smc_state_table.MemoryLevel[dpm_table->mclk_table.count - 1].DisplayWatermark =\n\t\tPPSMC_DISPLAY_WATERMARK_HIGH;\n\n\tret = ci_copy_bytes_to_smc(rdev, level_array_address,\n\t\t\t\t   (u8 *)levels, level_array_size,\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void ci_reset_single_dpm_table(struct radeon_device *rdev,\n\t\t\t\t      struct ci_single_dpm_table* dpm_table,\n\t\t\t\t      u32 count)\n{\n\tu32 i;\n\n\tdpm_table->count = count;\n\tfor (i = 0; i < MAX_REGULAR_DPM_NUMBER; i++)\n\t\tdpm_table->dpm_levels[i].enabled = false;\n}\n\nstatic void ci_setup_pcie_table_entry(struct ci_single_dpm_table* dpm_table,\n\t\t\t\t      u32 index, u32 pcie_gen, u32 pcie_lanes)\n{\n\tdpm_table->dpm_levels[index].value = pcie_gen;\n\tdpm_table->dpm_levels[index].param1 = pcie_lanes;\n\tdpm_table->dpm_levels[index].enabled = true;\n}\n\nstatic int ci_setup_default_pcie_tables(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (!pi->use_pcie_performance_levels && !pi->use_pcie_powersaving_levels)\n\t\treturn -EINVAL;\n\n\tif (pi->use_pcie_performance_levels && !pi->use_pcie_powersaving_levels) {\n\t\tpi->pcie_gen_powersaving = pi->pcie_gen_performance;\n\t\tpi->pcie_lane_powersaving = pi->pcie_lane_performance;\n\t} else if (!pi->use_pcie_performance_levels && pi->use_pcie_powersaving_levels) {\n\t\tpi->pcie_gen_performance = pi->pcie_gen_powersaving;\n\t\tpi->pcie_lane_performance = pi->pcie_lane_powersaving;\n\t}\n\n\tci_reset_single_dpm_table(rdev,\n\t\t\t\t  &pi->dpm_table.pcie_speed_table,\n\t\t\t\t  SMU7_MAX_LEVELS_LINK);\n\n\tif (rdev->family == CHIP_BONAIRE)\n\t\tci_setup_pcie_table_entry(&pi->dpm_table.pcie_speed_table, 0,\n\t\t\t\t\t  pi->pcie_gen_powersaving.min,\n\t\t\t\t\t  pi->pcie_lane_powersaving.max);\n\telse\n\t\tci_setup_pcie_table_entry(&pi->dpm_table.pcie_speed_table, 0,\n\t\t\t\t\t  pi->pcie_gen_powersaving.min,\n\t\t\t\t\t  pi->pcie_lane_powersaving.min);\n\tci_setup_pcie_table_entry(&pi->dpm_table.pcie_speed_table, 1,\n\t\t\t\t  pi->pcie_gen_performance.min,\n\t\t\t\t  pi->pcie_lane_performance.min);\n\tci_setup_pcie_table_entry(&pi->dpm_table.pcie_speed_table, 2,\n\t\t\t\t  pi->pcie_gen_powersaving.min,\n\t\t\t\t  pi->pcie_lane_powersaving.max);\n\tci_setup_pcie_table_entry(&pi->dpm_table.pcie_speed_table, 3,\n\t\t\t\t  pi->pcie_gen_performance.min,\n\t\t\t\t  pi->pcie_lane_performance.max);\n\tci_setup_pcie_table_entry(&pi->dpm_table.pcie_speed_table, 4,\n\t\t\t\t  pi->pcie_gen_powersaving.max,\n\t\t\t\t  pi->pcie_lane_powersaving.max);\n\tci_setup_pcie_table_entry(&pi->dpm_table.pcie_speed_table, 5,\n\t\t\t\t  pi->pcie_gen_performance.max,\n\t\t\t\t  pi->pcie_lane_performance.max);\n\n\tpi->dpm_table.pcie_speed_table.count = 6;\n\n\treturn 0;\n}\n\nstatic int ci_setup_default_dpm_tables(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_clock_voltage_dependency_table *allowed_sclk_vddc_table =\n\t\t&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\tstruct radeon_clock_voltage_dependency_table *allowed_mclk_table =\n\t\t&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk;\n\tstruct radeon_cac_leakage_table *std_voltage_table =\n\t\t&rdev->pm.dpm.dyn_state.cac_leakage_table;\n\tu32 i;\n\n\tif (allowed_sclk_vddc_table == NULL)\n\t\treturn -EINVAL;\n\tif (allowed_sclk_vddc_table->count < 1)\n\t\treturn -EINVAL;\n\tif (allowed_mclk_table == NULL)\n\t\treturn -EINVAL;\n\tif (allowed_mclk_table->count < 1)\n\t\treturn -EINVAL;\n\n\tmemset(&pi->dpm_table, 0, sizeof(struct ci_dpm_table));\n\n\tci_reset_single_dpm_table(rdev,\n\t\t\t\t  &pi->dpm_table.sclk_table,\n\t\t\t\t  SMU7_MAX_LEVELS_GRAPHICS);\n\tci_reset_single_dpm_table(rdev,\n\t\t\t\t  &pi->dpm_table.mclk_table,\n\t\t\t\t  SMU7_MAX_LEVELS_MEMORY);\n\tci_reset_single_dpm_table(rdev,\n\t\t\t\t  &pi->dpm_table.vddc_table,\n\t\t\t\t  SMU7_MAX_LEVELS_VDDC);\n\tci_reset_single_dpm_table(rdev,\n\t\t\t\t  &pi->dpm_table.vddci_table,\n\t\t\t\t  SMU7_MAX_LEVELS_VDDCI);\n\tci_reset_single_dpm_table(rdev,\n\t\t\t\t  &pi->dpm_table.mvdd_table,\n\t\t\t\t  SMU7_MAX_LEVELS_MVDD);\n\n\tpi->dpm_table.sclk_table.count = 0;\n\tfor (i = 0; i < allowed_sclk_vddc_table->count; i++) {\n\t\tif ((i == 0) ||\n\t\t    (pi->dpm_table.sclk_table.dpm_levels[pi->dpm_table.sclk_table.count-1].value !=\n\t\t     allowed_sclk_vddc_table->entries[i].clk)) {\n\t\t\tpi->dpm_table.sclk_table.dpm_levels[pi->dpm_table.sclk_table.count].value =\n\t\t\t\tallowed_sclk_vddc_table->entries[i].clk;\n\t\t\tpi->dpm_table.sclk_table.dpm_levels[pi->dpm_table.sclk_table.count].enabled =\n\t\t\t\t(i == 0) ? true : false;\n\t\t\tpi->dpm_table.sclk_table.count++;\n\t\t}\n\t}\n\n\tpi->dpm_table.mclk_table.count = 0;\n\tfor (i = 0; i < allowed_mclk_table->count; i++) {\n\t\tif ((i == 0) ||\n\t\t    (pi->dpm_table.mclk_table.dpm_levels[pi->dpm_table.mclk_table.count-1].value !=\n\t\t     allowed_mclk_table->entries[i].clk)) {\n\t\t\tpi->dpm_table.mclk_table.dpm_levels[pi->dpm_table.mclk_table.count].value =\n\t\t\t\tallowed_mclk_table->entries[i].clk;\n\t\t\tpi->dpm_table.mclk_table.dpm_levels[pi->dpm_table.mclk_table.count].enabled =\n\t\t\t\t(i == 0) ? true : false;\n\t\t\tpi->dpm_table.mclk_table.count++;\n\t\t}\n\t}\n\n\tfor (i = 0; i < allowed_sclk_vddc_table->count; i++) {\n\t\tpi->dpm_table.vddc_table.dpm_levels[i].value =\n\t\t\tallowed_sclk_vddc_table->entries[i].v;\n\t\tpi->dpm_table.vddc_table.dpm_levels[i].param1 =\n\t\t\tstd_voltage_table->entries[i].leakage;\n\t\tpi->dpm_table.vddc_table.dpm_levels[i].enabled = true;\n\t}\n\tpi->dpm_table.vddc_table.count = allowed_sclk_vddc_table->count;\n\n\tallowed_mclk_table = &rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk;\n\tif (allowed_mclk_table) {\n\t\tfor (i = 0; i < allowed_mclk_table->count; i++) {\n\t\t\tpi->dpm_table.vddci_table.dpm_levels[i].value =\n\t\t\t\tallowed_mclk_table->entries[i].v;\n\t\t\tpi->dpm_table.vddci_table.dpm_levels[i].enabled = true;\n\t\t}\n\t\tpi->dpm_table.vddci_table.count = allowed_mclk_table->count;\n\t}\n\n\tallowed_mclk_table = &rdev->pm.dpm.dyn_state.mvdd_dependency_on_mclk;\n\tif (allowed_mclk_table) {\n\t\tfor (i = 0; i < allowed_mclk_table->count; i++) {\n\t\t\tpi->dpm_table.mvdd_table.dpm_levels[i].value =\n\t\t\t\tallowed_mclk_table->entries[i].v;\n\t\t\tpi->dpm_table.mvdd_table.dpm_levels[i].enabled = true;\n\t\t}\n\t\tpi->dpm_table.mvdd_table.count = allowed_mclk_table->count;\n\t}\n\n\tci_setup_default_pcie_tables(rdev);\n\n\treturn 0;\n}\n\nstatic int ci_find_boot_level(struct ci_single_dpm_table *table,\n\t\t\t      u32 value, u32 *boot_level)\n{\n\tu32 i;\n\tint ret = -EINVAL;\n\n\tfor(i = 0; i < table->count; i++) {\n\t\tif (value == table->dpm_levels[i].value) {\n\t\t\t*boot_level = i;\n\t\t\tret = 0;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int ci_init_smc_table(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_ulv_parm *ulv = &pi->ulv;\n\tstruct radeon_ps *radeon_boot_state = rdev->pm.dpm.boot_ps;\n\tSMU7_Discrete_DpmTable *table = &pi->smc_state_table;\n\tint ret;\n\n\tret = ci_setup_default_dpm_tables(rdev);\n\tif (ret)\n\t\treturn ret;\n\n\tif (pi->voltage_control != CISLANDS_VOLTAGE_CONTROL_NONE)\n\t\tci_populate_smc_voltage_tables(rdev, table);\n\n\tci_init_fps_limits(rdev);\n\n\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_HARDWAREDC)\n\t\ttable->SystemFlags |= PPSMC_SYSTEMFLAG_GPIO_DC;\n\n\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_STEPVDDC)\n\t\ttable->SystemFlags |= PPSMC_SYSTEMFLAG_STEPVDDC;\n\n\tif (pi->mem_gddr5)\n\t\ttable->SystemFlags |= PPSMC_SYSTEMFLAG_GDDR5;\n\n\tif (ulv->supported) {\n\t\tret = ci_populate_ulv_state(rdev, &pi->smc_state_table.Ulv);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tWREG32_SMC(CG_ULV_PARAMETER, ulv->cg_ulv_parameter);\n\t}\n\n\tret = ci_populate_all_graphic_levels(rdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_populate_all_memory_levels(rdev);\n\tif (ret)\n\t\treturn ret;\n\n\tci_populate_smc_link_level(rdev, table);\n\n\tret = ci_populate_smc_acpi_level(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_populate_smc_vce_level(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_populate_smc_acp_level(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_populate_smc_samu_level(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_do_program_memory_timing_parameters(rdev);\n\tif (ret)\n\t\treturn ret;\n\n\tret = ci_populate_smc_uvd_level(rdev, table);\n\tif (ret)\n\t\treturn ret;\n\n\ttable->UvdBootLevel  = 0;\n\ttable->VceBootLevel  = 0;\n\ttable->AcpBootLevel  = 0;\n\ttable->SamuBootLevel  = 0;\n\ttable->GraphicsBootLevel  = 0;\n\ttable->MemoryBootLevel  = 0;\n\n\tret = ci_find_boot_level(&pi->dpm_table.sclk_table,\n\t\t\t\t pi->vbios_boot_state.sclk_bootup_value,\n\t\t\t\t (u32 *)&pi->smc_state_table.GraphicsBootLevel);\n\n\tret = ci_find_boot_level(&pi->dpm_table.mclk_table,\n\t\t\t\t pi->vbios_boot_state.mclk_bootup_value,\n\t\t\t\t (u32 *)&pi->smc_state_table.MemoryBootLevel);\n\n\ttable->BootVddc = pi->vbios_boot_state.vddc_bootup_value;\n\ttable->BootVddci = pi->vbios_boot_state.vddci_bootup_value;\n\ttable->BootMVdd = pi->vbios_boot_state.mvdd_bootup_value;\n\n\tci_populate_smc_initial_state(rdev, radeon_boot_state);\n\n\tret = ci_populate_bapm_parameters_in_dpm_table(rdev);\n\tif (ret)\n\t\treturn ret;\n\n\ttable->UVDInterval = 1;\n\ttable->VCEInterval = 1;\n\ttable->ACPInterval = 1;\n\ttable->SAMUInterval = 1;\n\ttable->GraphicsVoltageChangeEnable = 1;\n\ttable->GraphicsThermThrottleEnable = 1;\n\ttable->GraphicsInterval = 1;\n\ttable->VoltageInterval = 1;\n\ttable->ThermalInterval = 1;\n\ttable->TemperatureLimitHigh = (u16)((pi->thermal_temp_setting.temperature_high *\n\t\t\t\t\t     CISLANDS_Q88_FORMAT_CONVERSION_UNIT) / 1000);\n\ttable->TemperatureLimitLow = (u16)((pi->thermal_temp_setting.temperature_low *\n\t\t\t\t\t    CISLANDS_Q88_FORMAT_CONVERSION_UNIT) / 1000);\n\ttable->MemoryVoltageChangeEnable = 1;\n\ttable->MemoryInterval = 1;\n\ttable->VoltageResponseTime = 0;\n\ttable->VddcVddciDelta = 4000;\n\ttable->PhaseResponseTime = 0;\n\ttable->MemoryThermThrottleEnable = 1;\n\ttable->PCIeBootLinkLevel = pi->dpm_table.pcie_speed_table.count - 1;\n\ttable->PCIeGenInterval = 1;\n\tif (pi->voltage_control == CISLANDS_VOLTAGE_CONTROL_BY_SVID2)\n\t\ttable->SVI2Enable  = 1;\n\telse\n\t\ttable->SVI2Enable  = 0;\n\n\ttable->ThermGpio = 17;\n\ttable->SclkStepSize = 0x4000;\n\n\ttable->SystemFlags = cpu_to_be32(table->SystemFlags);\n\ttable->SmioMaskVddcVid = cpu_to_be32(table->SmioMaskVddcVid);\n\ttable->SmioMaskVddcPhase = cpu_to_be32(table->SmioMaskVddcPhase);\n\ttable->SmioMaskVddciVid = cpu_to_be32(table->SmioMaskVddciVid);\n\ttable->SmioMaskMvddVid = cpu_to_be32(table->SmioMaskMvddVid);\n\ttable->SclkStepSize = cpu_to_be32(table->SclkStepSize);\n\ttable->TemperatureLimitHigh = cpu_to_be16(table->TemperatureLimitHigh);\n\ttable->TemperatureLimitLow = cpu_to_be16(table->TemperatureLimitLow);\n\ttable->VddcVddciDelta = cpu_to_be16(table->VddcVddciDelta);\n\ttable->VoltageResponseTime = cpu_to_be16(table->VoltageResponseTime);\n\ttable->PhaseResponseTime = cpu_to_be16(table->PhaseResponseTime);\n\ttable->BootVddc = cpu_to_be16(table->BootVddc * VOLTAGE_SCALE);\n\ttable->BootVddci = cpu_to_be16(table->BootVddci * VOLTAGE_SCALE);\n\ttable->BootMVdd = cpu_to_be16(table->BootMVdd * VOLTAGE_SCALE);\n\n\tret = ci_copy_bytes_to_smc(rdev,\n\t\t\t\t   pi->dpm_table_start +\n\t\t\t\t   offsetof(SMU7_Discrete_DpmTable, SystemFlags),\n\t\t\t\t   (u8 *)&table->SystemFlags,\n\t\t\t\t   sizeof(SMU7_Discrete_DpmTable) - 3 * sizeof(SMU7_PIDController),\n\t\t\t\t   pi->sram_end);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void ci_trim_single_dpm_states(struct radeon_device *rdev,\n\t\t\t\t      struct ci_single_dpm_table *dpm_table,\n\t\t\t\t      u32 low_limit, u32 high_limit)\n{\n\tu32 i;\n\n\tfor (i = 0; i < dpm_table->count; i++) {\n\t\tif ((dpm_table->dpm_levels[i].value < low_limit) ||\n\t\t    (dpm_table->dpm_levels[i].value > high_limit))\n\t\t\tdpm_table->dpm_levels[i].enabled = false;\n\t\telse\n\t\t\tdpm_table->dpm_levels[i].enabled = true;\n\t}\n}\n\nstatic void ci_trim_pcie_dpm_states(struct radeon_device *rdev,\n\t\t\t\t    u32 speed_low, u32 lanes_low,\n\t\t\t\t    u32 speed_high, u32 lanes_high)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_single_dpm_table *pcie_table = &pi->dpm_table.pcie_speed_table;\n\tu32 i, j;\n\n\tfor (i = 0; i < pcie_table->count; i++) {\n\t\tif ((pcie_table->dpm_levels[i].value < speed_low) ||\n\t\t    (pcie_table->dpm_levels[i].param1 < lanes_low) ||\n\t\t    (pcie_table->dpm_levels[i].value > speed_high) ||\n\t\t    (pcie_table->dpm_levels[i].param1 > lanes_high))\n\t\t\tpcie_table->dpm_levels[i].enabled = false;\n\t\telse\n\t\t\tpcie_table->dpm_levels[i].enabled = true;\n\t}\n\n\tfor (i = 0; i < pcie_table->count; i++) {\n\t\tif (pcie_table->dpm_levels[i].enabled) {\n\t\t\tfor (j = i + 1; j < pcie_table->count; j++) {\n\t\t\t\tif (pcie_table->dpm_levels[j].enabled) {\n\t\t\t\t\tif ((pcie_table->dpm_levels[i].value == pcie_table->dpm_levels[j].value) &&\n\t\t\t\t\t    (pcie_table->dpm_levels[i].param1 == pcie_table->dpm_levels[j].param1))\n\t\t\t\t\t\tpcie_table->dpm_levels[j].enabled = false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic int ci_trim_dpm_states(struct radeon_device *rdev,\n\t\t\t      struct radeon_ps *radeon_state)\n{\n\tstruct ci_ps *state = ci_get_ps(radeon_state);\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 high_limit_count;\n\n\tif (state->performance_level_count < 1)\n\t\treturn -EINVAL;\n\n\tif (state->performance_level_count == 1)\n\t\thigh_limit_count = 0;\n\telse\n\t\thigh_limit_count = 1;\n\n\tci_trim_single_dpm_states(rdev,\n\t\t\t\t  &pi->dpm_table.sclk_table,\n\t\t\t\t  state->performance_levels[0].sclk,\n\t\t\t\t  state->performance_levels[high_limit_count].sclk);\n\n\tci_trim_single_dpm_states(rdev,\n\t\t\t\t  &pi->dpm_table.mclk_table,\n\t\t\t\t  state->performance_levels[0].mclk,\n\t\t\t\t  state->performance_levels[high_limit_count].mclk);\n\n\tci_trim_pcie_dpm_states(rdev,\n\t\t\t\tstate->performance_levels[0].pcie_gen,\n\t\t\t\tstate->performance_levels[0].pcie_lane,\n\t\t\t\tstate->performance_levels[high_limit_count].pcie_gen,\n\t\t\t\tstate->performance_levels[high_limit_count].pcie_lane);\n\n\treturn 0;\n}\n\nstatic int ci_apply_disp_minimum_voltage_request(struct radeon_device *rdev)\n{\n\tstruct radeon_clock_voltage_dependency_table *disp_voltage_table =\n\t\t&rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk;\n\tstruct radeon_clock_voltage_dependency_table *vddc_table =\n\t\t&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\tu32 requested_voltage = 0;\n\tu32 i;\n\n\tif (disp_voltage_table == NULL)\n\t\treturn -EINVAL;\n\tif (!disp_voltage_table->count)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < disp_voltage_table->count; i++) {\n\t\tif (rdev->clock.current_dispclk == disp_voltage_table->entries[i].clk)\n\t\t\trequested_voltage = disp_voltage_table->entries[i].v;\n\t}\n\n\tfor (i = 0; i < vddc_table->count; i++) {\n\t\tif (requested_voltage <= vddc_table->entries[i].v) {\n\t\t\trequested_voltage = vddc_table->entries[i].v;\n\t\t\treturn (ci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\t\t  PPSMC_MSG_VddC_Request,\n\t\t\t\t\t\t\t\t  requested_voltage * VOLTAGE_SCALE) == PPSMC_Result_OK) ?\n\t\t\t\t0 : -EINVAL;\n\t\t}\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int ci_upload_dpm_level_enable_mask(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tPPSMC_Result result;\n\n\tci_apply_disp_minimum_voltage_request(rdev);\n\n\tif (!pi->sclk_dpm_key_disabled) {\n\t\tif (pi->dpm_level_enable_mask.sclk_dpm_enable_mask) {\n\t\t\tresult = ci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\t\t   PPSMC_MSG_SCLKDPM_SetEnabledMask,\n\t\t\t\t\t\t\t\t   pi->dpm_level_enable_mask.sclk_dpm_enable_mask);\n\t\t\tif (result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!pi->mclk_dpm_key_disabled) {\n\t\tif (pi->dpm_level_enable_mask.mclk_dpm_enable_mask) {\n\t\t\tresult = ci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\t\t   PPSMC_MSG_MCLKDPM_SetEnabledMask,\n\t\t\t\t\t\t\t\t   pi->dpm_level_enable_mask.mclk_dpm_enable_mask);\n\t\t\tif (result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n#if 0\n\tif (!pi->pcie_dpm_key_disabled) {\n\t\tif (pi->dpm_level_enable_mask.pcie_dpm_enable_mask) {\n\t\t\tresult = ci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\t\t   PPSMC_MSG_PCIeDPM_SetEnabledMask,\n\t\t\t\t\t\t\t\t   pi->dpm_level_enable_mask.pcie_dpm_enable_mask);\n\t\t\tif (result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t}\n#endif\n\treturn 0;\n}\n\nstatic void ci_find_dpm_states_clocks_in_dpm_table(struct radeon_device *rdev,\n\t\t\t\t\t\t   struct radeon_ps *radeon_state)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_ps *state = ci_get_ps(radeon_state);\n\tstruct ci_single_dpm_table *sclk_table = &pi->dpm_table.sclk_table;\n\tu32 sclk = state->performance_levels[state->performance_level_count-1].sclk;\n\tstruct ci_single_dpm_table *mclk_table = &pi->dpm_table.mclk_table;\n\tu32 mclk = state->performance_levels[state->performance_level_count-1].mclk;\n\tu32 i;\n\n\tpi->need_update_smu7_dpm_table = 0;\n\n\tfor (i = 0; i < sclk_table->count; i++) {\n\t\tif (sclk == sclk_table->dpm_levels[i].value)\n\t\t\tbreak;\n\t}\n\n\tif (i >= sclk_table->count) {\n\t\tpi->need_update_smu7_dpm_table |= DPMTABLE_OD_UPDATE_SCLK;\n\t} else {\n\t\t \n\t\tif (CISLAND_MINIMUM_ENGINE_CLOCK != CISLAND_MINIMUM_ENGINE_CLOCK)\n\t\t\tpi->need_update_smu7_dpm_table |= DPMTABLE_UPDATE_SCLK;\n\t}\n\n\tfor (i = 0; i < mclk_table->count; i++) {\n\t\tif (mclk == mclk_table->dpm_levels[i].value)\n\t\t\tbreak;\n\t}\n\n\tif (i >= mclk_table->count)\n\t\tpi->need_update_smu7_dpm_table |= DPMTABLE_OD_UPDATE_MCLK;\n\n\tif (rdev->pm.dpm.current_active_crtc_count !=\n\t    rdev->pm.dpm.new_active_crtc_count)\n\t\tpi->need_update_smu7_dpm_table |= DPMTABLE_UPDATE_MCLK;\n}\n\nstatic int ci_populate_and_upload_sclk_mclk_dpm_levels(struct radeon_device *rdev,\n\t\t\t\t\t\t       struct radeon_ps *radeon_state)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_ps *state = ci_get_ps(radeon_state);\n\tu32 sclk = state->performance_levels[state->performance_level_count-1].sclk;\n\tu32 mclk = state->performance_levels[state->performance_level_count-1].mclk;\n\tstruct ci_dpm_table *dpm_table = &pi->dpm_table;\n\tint ret;\n\n\tif (!pi->need_update_smu7_dpm_table)\n\t\treturn 0;\n\n\tif (pi->need_update_smu7_dpm_table & DPMTABLE_OD_UPDATE_SCLK)\n\t\tdpm_table->sclk_table.dpm_levels[dpm_table->sclk_table.count-1].value = sclk;\n\n\tif (pi->need_update_smu7_dpm_table & DPMTABLE_OD_UPDATE_MCLK)\n\t\tdpm_table->mclk_table.dpm_levels[dpm_table->mclk_table.count-1].value = mclk;\n\n\tif (pi->need_update_smu7_dpm_table & (DPMTABLE_OD_UPDATE_SCLK | DPMTABLE_UPDATE_SCLK)) {\n\t\tret = ci_populate_all_graphic_levels(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (pi->need_update_smu7_dpm_table & (DPMTABLE_OD_UPDATE_MCLK | DPMTABLE_UPDATE_MCLK)) {\n\t\tret = ci_populate_all_memory_levels(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_enable_uvd_dpm(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct radeon_clock_and_voltage_limits *max_limits;\n\tint i;\n\n\tif (rdev->pm.dpm.ac_power)\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\telse\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc;\n\n\tif (enable) {\n\t\tpi->dpm_level_enable_mask.uvd_dpm_enable_mask = 0;\n\n\t\tfor (i = rdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.count - 1; i >= 0; i--) {\n\t\t\tif (rdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.entries[i].v <= max_limits->vddc) {\n\t\t\t\tpi->dpm_level_enable_mask.uvd_dpm_enable_mask |= 1 << i;\n\n\t\t\t\tif (!pi->caps_uvd_dpm)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t  PPSMC_MSG_UVDDPM_SetEnabledMask,\n\t\t\t\t\t\t  pi->dpm_level_enable_mask.uvd_dpm_enable_mask);\n\n\t\tif (pi->last_mclk_dpm_enable_mask & 0x1) {\n\t\t\tpi->uvd_enabled = true;\n\t\t\tpi->dpm_level_enable_mask.mclk_dpm_enable_mask &= 0xFFFFFFFE;\n\t\t\tci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\t  PPSMC_MSG_MCLKDPM_SetEnabledMask,\n\t\t\t\t\t\t\t  pi->dpm_level_enable_mask.mclk_dpm_enable_mask);\n\t\t}\n\t} else {\n\t\tif (pi->last_mclk_dpm_enable_mask & 0x1) {\n\t\t\tpi->uvd_enabled = false;\n\t\t\tpi->dpm_level_enable_mask.mclk_dpm_enable_mask |= 1;\n\t\t\tci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t\t  PPSMC_MSG_MCLKDPM_SetEnabledMask,\n\t\t\t\t\t\t\t  pi->dpm_level_enable_mask.mclk_dpm_enable_mask);\n\t\t}\n\t}\n\n\treturn (ci_send_msg_to_smc(rdev, enable ?\n\t\t\t\t   PPSMC_MSG_UVDDPM_Enable : PPSMC_MSG_UVDDPM_Disable) == PPSMC_Result_OK) ?\n\t\t0 : -EINVAL;\n}\n\nstatic int ci_enable_vce_dpm(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct radeon_clock_and_voltage_limits *max_limits;\n\tint i;\n\n\tif (rdev->pm.dpm.ac_power)\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\telse\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc;\n\n\tif (enable) {\n\t\tpi->dpm_level_enable_mask.vce_dpm_enable_mask = 0;\n\t\tfor (i = rdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.count - 1; i >= 0; i--) {\n\t\t\tif (rdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table.entries[i].v <= max_limits->vddc) {\n\t\t\t\tpi->dpm_level_enable_mask.vce_dpm_enable_mask |= 1 << i;\n\n\t\t\t\tif (!pi->caps_vce_dpm)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t  PPSMC_MSG_VCEDPM_SetEnabledMask,\n\t\t\t\t\t\t  pi->dpm_level_enable_mask.vce_dpm_enable_mask);\n\t}\n\n\treturn (ci_send_msg_to_smc(rdev, enable ?\n\t\t\t\t   PPSMC_MSG_VCEDPM_Enable : PPSMC_MSG_VCEDPM_Disable) == PPSMC_Result_OK) ?\n\t\t0 : -EINVAL;\n}\n\n#if 0\nstatic int ci_enable_samu_dpm(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct radeon_clock_and_voltage_limits *max_limits;\n\tint i;\n\n\tif (rdev->pm.dpm.ac_power)\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\telse\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc;\n\n\tif (enable) {\n\t\tpi->dpm_level_enable_mask.samu_dpm_enable_mask = 0;\n\t\tfor (i = rdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.count - 1; i >= 0; i--) {\n\t\t\tif (rdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table.entries[i].v <= max_limits->vddc) {\n\t\t\t\tpi->dpm_level_enable_mask.samu_dpm_enable_mask |= 1 << i;\n\n\t\t\t\tif (!pi->caps_samu_dpm)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t  PPSMC_MSG_SAMUDPM_SetEnabledMask,\n\t\t\t\t\t\t  pi->dpm_level_enable_mask.samu_dpm_enable_mask);\n\t}\n\treturn (ci_send_msg_to_smc(rdev, enable ?\n\t\t\t\t   PPSMC_MSG_SAMUDPM_Enable : PPSMC_MSG_SAMUDPM_Disable) == PPSMC_Result_OK) ?\n\t\t0 : -EINVAL;\n}\n\nstatic int ci_enable_acp_dpm(struct radeon_device *rdev, bool enable)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tconst struct radeon_clock_and_voltage_limits *max_limits;\n\tint i;\n\n\tif (rdev->pm.dpm.ac_power)\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\telse\n\t\tmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc;\n\n\tif (enable) {\n\t\tpi->dpm_level_enable_mask.acp_dpm_enable_mask = 0;\n\t\tfor (i = rdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.count - 1; i >= 0; i--) {\n\t\t\tif (rdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table.entries[i].v <= max_limits->vddc) {\n\t\t\t\tpi->dpm_level_enable_mask.acp_dpm_enable_mask |= 1 << i;\n\n\t\t\t\tif (!pi->caps_acp_dpm)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tci_send_msg_to_smc_with_parameter(rdev,\n\t\t\t\t\t\t  PPSMC_MSG_ACPDPM_SetEnabledMask,\n\t\t\t\t\t\t  pi->dpm_level_enable_mask.acp_dpm_enable_mask);\n\t}\n\n\treturn (ci_send_msg_to_smc(rdev, enable ?\n\t\t\t\t   PPSMC_MSG_ACPDPM_Enable : PPSMC_MSG_ACPDPM_Disable) == PPSMC_Result_OK) ?\n\t\t0 : -EINVAL;\n}\n#endif\n\nstatic int ci_update_uvd_dpm(struct radeon_device *rdev, bool gate)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\n\tif (!gate) {\n\t\tif (pi->caps_uvd_dpm ||\n\t\t    (rdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.count <= 0))\n\t\t\tpi->smc_state_table.UvdBootLevel = 0;\n\t\telse\n\t\t\tpi->smc_state_table.UvdBootLevel =\n\t\t\t\trdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table.count - 1;\n\n\t\ttmp = RREG32_SMC(DPM_TABLE_475);\n\t\ttmp &= ~UvdBootLevel_MASK;\n\t\ttmp |= UvdBootLevel(pi->smc_state_table.UvdBootLevel);\n\t\tWREG32_SMC(DPM_TABLE_475, tmp);\n\t}\n\n\treturn ci_enable_uvd_dpm(rdev, !gate);\n}\n\nstatic u8 ci_get_vce_boot_level(struct radeon_device *rdev)\n{\n\tu8 i;\n\tu32 min_evclk = 30000;  \n\tstruct radeon_vce_clock_voltage_dependency_table *table =\n\t\t&rdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table;\n\n\tfor (i = 0; i < table->count; i++) {\n\t\tif (table->entries[i].evclk >= min_evclk)\n\t\t\treturn i;\n\t}\n\n\treturn table->count - 1;\n}\n\nstatic int ci_update_vce_dpm(struct radeon_device *rdev,\n\t\t\t     struct radeon_ps *radeon_new_state,\n\t\t\t     struct radeon_ps *radeon_current_state)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret = 0;\n\tu32 tmp;\n\n\tif (radeon_current_state->evclk != radeon_new_state->evclk) {\n\t\tif (radeon_new_state->evclk) {\n\t\t\t \n\t\t\tcik_update_cg(rdev, RADEON_CG_BLOCK_VCE, false);\n\n\t\t\tpi->smc_state_table.VceBootLevel = ci_get_vce_boot_level(rdev);\n\t\t\ttmp = RREG32_SMC(DPM_TABLE_475);\n\t\t\ttmp &= ~VceBootLevel_MASK;\n\t\t\ttmp |= VceBootLevel(pi->smc_state_table.VceBootLevel);\n\t\t\tWREG32_SMC(DPM_TABLE_475, tmp);\n\n\t\t\tret = ci_enable_vce_dpm(rdev, true);\n\t\t} else {\n\t\t\t \n\t\t\tcik_update_cg(rdev, RADEON_CG_BLOCK_VCE, true);\n\n\t\t\tret = ci_enable_vce_dpm(rdev, false);\n\t\t}\n\t}\n\treturn ret;\n}\n\n#if 0\nstatic int ci_update_samu_dpm(struct radeon_device *rdev, bool gate)\n{\n\treturn ci_enable_samu_dpm(rdev, gate);\n}\n\nstatic int ci_update_acp_dpm(struct radeon_device *rdev, bool gate)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\n\tif (!gate) {\n\t\tpi->smc_state_table.AcpBootLevel = 0;\n\n\t\ttmp = RREG32_SMC(DPM_TABLE_475);\n\t\ttmp &= ~AcpBootLevel_MASK;\n\t\ttmp |= AcpBootLevel(pi->smc_state_table.AcpBootLevel);\n\t\tWREG32_SMC(DPM_TABLE_475, tmp);\n\t}\n\n\treturn ci_enable_acp_dpm(rdev, !gate);\n}\n#endif\n\nstatic int ci_generate_dpm_level_enable_mask(struct radeon_device *rdev,\n\t\t\t\t\t     struct radeon_ps *radeon_state)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret;\n\n\tret = ci_trim_dpm_states(rdev, radeon_state);\n\tif (ret)\n\t\treturn ret;\n\n\tpi->dpm_level_enable_mask.sclk_dpm_enable_mask =\n\t\tci_get_dpm_level_enable_mask_value(&pi->dpm_table.sclk_table);\n\tpi->dpm_level_enable_mask.mclk_dpm_enable_mask =\n\t\tci_get_dpm_level_enable_mask_value(&pi->dpm_table.mclk_table);\n\tpi->last_mclk_dpm_enable_mask =\n\t\tpi->dpm_level_enable_mask.mclk_dpm_enable_mask;\n\tif (pi->uvd_enabled) {\n\t\tif (pi->dpm_level_enable_mask.mclk_dpm_enable_mask & 1)\n\t\t\tpi->dpm_level_enable_mask.mclk_dpm_enable_mask &= 0xFFFFFFFE;\n\t}\n\tpi->dpm_level_enable_mask.pcie_dpm_enable_mask =\n\t\tci_get_dpm_level_enable_mask_value(&pi->dpm_table.pcie_speed_table);\n\n\treturn 0;\n}\n\nstatic u32 ci_get_lowest_enabled_level(struct radeon_device *rdev,\n\t\t\t\t       u32 level_mask)\n{\n\tu32 level = 0;\n\n\twhile ((level_mask & (1 << level)) == 0)\n\t\tlevel++;\n\n\treturn level;\n}\n\n\nint ci_dpm_force_performance_level(struct radeon_device *rdev,\n\t\t\t\t   enum radeon_dpm_forced_level level)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp, levels, i;\n\tint ret;\n\n\tif (level == RADEON_DPM_FORCED_LEVEL_HIGH) {\n\t\tif ((!pi->pcie_dpm_key_disabled) &&\n\t\t    pi->dpm_level_enable_mask.pcie_dpm_enable_mask) {\n\t\t\tlevels = 0;\n\t\t\ttmp = pi->dpm_level_enable_mask.pcie_dpm_enable_mask;\n\t\t\twhile (tmp >>= 1)\n\t\t\t\tlevels++;\n\t\t\tif (levels) {\n\t\t\t\tret = ci_dpm_force_state_pcie(rdev, level);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\t\t\t\ttmp = (RREG32_SMC(TARGET_AND_CURRENT_PROFILE_INDEX_1) &\n\t\t\t\t\t       CURR_PCIE_INDEX_MASK) >> CURR_PCIE_INDEX_SHIFT;\n\t\t\t\t\tif (tmp == levels)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tudelay(1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif ((!pi->sclk_dpm_key_disabled) &&\n\t\t    pi->dpm_level_enable_mask.sclk_dpm_enable_mask) {\n\t\t\tlevels = 0;\n\t\t\ttmp = pi->dpm_level_enable_mask.sclk_dpm_enable_mask;\n\t\t\twhile (tmp >>= 1)\n\t\t\t\tlevels++;\n\t\t\tif (levels) {\n\t\t\t\tret = ci_dpm_force_state_sclk(rdev, levels);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\t\t\t\ttmp = (RREG32_SMC(TARGET_AND_CURRENT_PROFILE_INDEX) &\n\t\t\t\t\t       CURR_SCLK_INDEX_MASK) >> CURR_SCLK_INDEX_SHIFT;\n\t\t\t\t\tif (tmp == levels)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tudelay(1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif ((!pi->mclk_dpm_key_disabled) &&\n\t\t    pi->dpm_level_enable_mask.mclk_dpm_enable_mask) {\n\t\t\tlevels = 0;\n\t\t\ttmp = pi->dpm_level_enable_mask.mclk_dpm_enable_mask;\n\t\t\twhile (tmp >>= 1)\n\t\t\t\tlevels++;\n\t\t\tif (levels) {\n\t\t\t\tret = ci_dpm_force_state_mclk(rdev, levels);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\t\t\t\ttmp = (RREG32_SMC(TARGET_AND_CURRENT_PROFILE_INDEX) &\n\t\t\t\t\t       CURR_MCLK_INDEX_MASK) >> CURR_MCLK_INDEX_SHIFT;\n\t\t\t\t\tif (tmp == levels)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tudelay(1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (level == RADEON_DPM_FORCED_LEVEL_LOW) {\n\t\tif ((!pi->sclk_dpm_key_disabled) &&\n\t\t    pi->dpm_level_enable_mask.sclk_dpm_enable_mask) {\n\t\t\tlevels = ci_get_lowest_enabled_level(rdev,\n\t\t\t\t\t\t\t     pi->dpm_level_enable_mask.sclk_dpm_enable_mask);\n\t\t\tret = ci_dpm_force_state_sclk(rdev, levels);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\t\t\ttmp = (RREG32_SMC(TARGET_AND_CURRENT_PROFILE_INDEX) &\n\t\t\t\t       CURR_SCLK_INDEX_MASK) >> CURR_SCLK_INDEX_SHIFT;\n\t\t\t\tif (tmp == levels)\n\t\t\t\t\tbreak;\n\t\t\t\tudelay(1);\n\t\t\t}\n\t\t}\n\t\tif ((!pi->mclk_dpm_key_disabled) &&\n\t\t    pi->dpm_level_enable_mask.mclk_dpm_enable_mask) {\n\t\t\tlevels = ci_get_lowest_enabled_level(rdev,\n\t\t\t\t\t\t\t     pi->dpm_level_enable_mask.mclk_dpm_enable_mask);\n\t\t\tret = ci_dpm_force_state_mclk(rdev, levels);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\t\t\ttmp = (RREG32_SMC(TARGET_AND_CURRENT_PROFILE_INDEX) &\n\t\t\t\t       CURR_MCLK_INDEX_MASK) >> CURR_MCLK_INDEX_SHIFT;\n\t\t\t\tif (tmp == levels)\n\t\t\t\t\tbreak;\n\t\t\t\tudelay(1);\n\t\t\t}\n\t\t}\n\t\tif ((!pi->pcie_dpm_key_disabled) &&\n\t\t    pi->dpm_level_enable_mask.pcie_dpm_enable_mask) {\n\t\t\tlevels = ci_get_lowest_enabled_level(rdev,\n\t\t\t\t\t\t\t     pi->dpm_level_enable_mask.pcie_dpm_enable_mask);\n\t\t\tret = ci_dpm_force_state_pcie(rdev, levels);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t\tfor (i = 0; i < rdev->usec_timeout; i++) {\n\t\t\t\ttmp = (RREG32_SMC(TARGET_AND_CURRENT_PROFILE_INDEX_1) &\n\t\t\t\t       CURR_PCIE_INDEX_MASK) >> CURR_PCIE_INDEX_SHIFT;\n\t\t\t\tif (tmp == levels)\n\t\t\t\t\tbreak;\n\t\t\t\tudelay(1);\n\t\t\t}\n\t\t}\n\t} else if (level == RADEON_DPM_FORCED_LEVEL_AUTO) {\n\t\tif (!pi->pcie_dpm_key_disabled) {\n\t\t\tPPSMC_Result smc_result;\n\n\t\t\tsmc_result = ci_send_msg_to_smc(rdev,\n\t\t\t\t\t\t\tPPSMC_MSG_PCIeDPM_UnForceLevel);\n\t\t\tif (smc_result != PPSMC_Result_OK)\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\tret = ci_upload_dpm_level_enable_mask(rdev);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\trdev->pm.dpm.forced_level = level;\n\n\treturn 0;\n}\n\nstatic int ci_set_mc_special_registers(struct radeon_device *rdev,\n\t\t\t\t       struct ci_mc_reg_table *table)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu8 i, j, k;\n\tu32 temp_reg;\n\n\tfor (i = 0, j = table->last; i < table->last; i++) {\n\t\tif (j >= SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\t\treturn -EINVAL;\n\t\tswitch(table->mc_reg_address[i].s1 << 2) {\n\t\tcase MC_SEQ_MISC1:\n\t\t\ttemp_reg = RREG32(MC_PMG_CMD_EMRS);\n\t\t\ttable->mc_reg_address[j].s1 = MC_PMG_CMD_EMRS >> 2;\n\t\t\ttable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_EMRS_LP >> 2;\n\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\ttable->mc_reg_table_entry[k].mc_data[j] =\n\t\t\t\t\t((temp_reg & 0xffff0000)) | ((table->mc_reg_table_entry[k].mc_data[i] & 0xffff0000) >> 16);\n\t\t\t}\n\t\t\tj++;\n\t\t\tif (j >= SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\n\t\t\ttemp_reg = RREG32(MC_PMG_CMD_MRS);\n\t\t\ttable->mc_reg_address[j].s1 = MC_PMG_CMD_MRS >> 2;\n\t\t\ttable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_MRS_LP >> 2;\n\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\ttable->mc_reg_table_entry[k].mc_data[j] =\n\t\t\t\t\t(temp_reg & 0xffff0000) | (table->mc_reg_table_entry[k].mc_data[i] & 0x0000ffff);\n\t\t\t\tif (!pi->mem_gddr5)\n\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[j] |= 0x100;\n\t\t\t}\n\t\t\tj++;\n\t\t\tif (j >= SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\n\t\t\tif (!pi->mem_gddr5) {\n\t\t\t\ttable->mc_reg_address[j].s1 = MC_PMG_AUTO_CMD >> 2;\n\t\t\t\ttable->mc_reg_address[j].s0 = MC_PMG_AUTO_CMD >> 2;\n\t\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[j] =\n\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xffff0000) >> 16;\n\t\t\t\t}\n\t\t\t\tj++;\n\t\t\t\tif (j > SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase MC_SEQ_RESERVE_M:\n\t\t\ttemp_reg = RREG32(MC_PMG_CMD_MRS1);\n\t\t\ttable->mc_reg_address[j].s1 = MC_PMG_CMD_MRS1 >> 2;\n\t\t\ttable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_MRS1_LP >> 2;\n\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\ttable->mc_reg_table_entry[k].mc_data[j] =\n\t\t\t\t\t(temp_reg & 0xffff0000) | (table->mc_reg_table_entry[k].mc_data[i] & 0x0000ffff);\n\t\t\t}\n\t\t\tj++;\n\t\t\tif (j > SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t}\n\n\ttable->last = j;\n\n\treturn 0;\n}\n\nstatic bool ci_check_s0_mc_reg_index(u16 in_reg, u16 *out_reg)\n{\n\tbool result = true;\n\n\tswitch(in_reg) {\n\tcase MC_SEQ_RAS_TIMING >> 2:\n\t\t*out_reg = MC_SEQ_RAS_TIMING_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_DLL_STBY >> 2:\n\t\t*out_reg = MC_SEQ_DLL_STBY_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_G5PDX_CMD0 >> 2:\n\t\t*out_reg = MC_SEQ_G5PDX_CMD0_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_G5PDX_CMD1 >> 2:\n\t\t*out_reg = MC_SEQ_G5PDX_CMD1_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_G5PDX_CTRL >> 2:\n\t\t*out_reg = MC_SEQ_G5PDX_CTRL_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_CAS_TIMING >> 2:\n\t\t*out_reg = MC_SEQ_CAS_TIMING_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_MISC_TIMING >> 2:\n\t\t*out_reg = MC_SEQ_MISC_TIMING_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_MISC_TIMING2 >> 2:\n\t\t*out_reg = MC_SEQ_MISC_TIMING2_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_PMG_DVS_CMD >> 2:\n\t\t*out_reg = MC_SEQ_PMG_DVS_CMD_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_PMG_DVS_CTL >> 2:\n\t\t*out_reg = MC_SEQ_PMG_DVS_CTL_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_RD_CTL_D0 >> 2:\n\t\t*out_reg = MC_SEQ_RD_CTL_D0_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_RD_CTL_D1 >> 2:\n\t\t*out_reg = MC_SEQ_RD_CTL_D1_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_WR_CTL_D0 >> 2:\n\t\t*out_reg = MC_SEQ_WR_CTL_D0_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_WR_CTL_D1 >> 2:\n\t\t*out_reg = MC_SEQ_WR_CTL_D1_LP >> 2;\n\t\tbreak;\n\tcase MC_PMG_CMD_EMRS >> 2:\n\t\t*out_reg = MC_SEQ_PMG_CMD_EMRS_LP >> 2;\n\t\tbreak;\n\tcase MC_PMG_CMD_MRS >> 2:\n\t\t*out_reg = MC_SEQ_PMG_CMD_MRS_LP >> 2;\n\t\tbreak;\n\tcase MC_PMG_CMD_MRS1 >> 2:\n\t\t*out_reg = MC_SEQ_PMG_CMD_MRS1_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_PMG_TIMING >> 2:\n\t\t*out_reg = MC_SEQ_PMG_TIMING_LP >> 2;\n\t\tbreak;\n\tcase MC_PMG_CMD_MRS2 >> 2:\n\t\t*out_reg = MC_SEQ_PMG_CMD_MRS2_LP >> 2;\n\t\tbreak;\n\tcase MC_SEQ_WR_CTL_2 >> 2:\n\t\t*out_reg = MC_SEQ_WR_CTL_2_LP >> 2;\n\t\tbreak;\n\tdefault:\n\t\tresult = false;\n\t\tbreak;\n\t}\n\n\treturn result;\n}\n\nstatic void ci_set_valid_flag(struct ci_mc_reg_table *table)\n{\n\tu8 i, j;\n\n\tfor (i = 0; i < table->last; i++) {\n\t\tfor (j = 1; j < table->num_entries; j++) {\n\t\t\tif (table->mc_reg_table_entry[j-1].mc_data[i] !=\n\t\t\t    table->mc_reg_table_entry[j].mc_data[i]) {\n\t\t\t\ttable->valid_flag |= 1 << i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void ci_set_s0_mc_reg_index(struct ci_mc_reg_table *table)\n{\n\tu32 i;\n\tu16 address;\n\n\tfor (i = 0; i < table->last; i++) {\n\t\ttable->mc_reg_address[i].s0 =\n\t\t\tci_check_s0_mc_reg_index(table->mc_reg_address[i].s1, &address) ?\n\t\t\taddress : table->mc_reg_address[i].s1;\n\t}\n}\n\nstatic int ci_copy_vbios_mc_reg_table(const struct atom_mc_reg_table *table,\n\t\t\t\t      struct ci_mc_reg_table *ci_table)\n{\n\tu8 i, j;\n\n\tif (table->last > SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\treturn -EINVAL;\n\tif (table->num_entries > MAX_AC_TIMING_ENTRIES)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < table->last; i++)\n\t\tci_table->mc_reg_address[i].s1 = table->mc_reg_address[i].s1;\n\n\tci_table->last = table->last;\n\n\tfor (i = 0; i < table->num_entries; i++) {\n\t\tci_table->mc_reg_table_entry[i].mclk_max =\n\t\t\ttable->mc_reg_table_entry[i].mclk_max;\n\t\tfor (j = 0; j < table->last; j++)\n\t\t\tci_table->mc_reg_table_entry[i].mc_data[j] =\n\t\t\t\ttable->mc_reg_table_entry[i].mc_data[j];\n\t}\n\tci_table->num_entries = table->num_entries;\n\n\treturn 0;\n}\n\nstatic int ci_register_patching_mc_seq(struct radeon_device *rdev,\n\t\t\t\t       struct ci_mc_reg_table *table)\n{\n\tu8 i, k;\n\tu32 tmp;\n\tbool patch;\n\n\ttmp = RREG32(MC_SEQ_MISC0);\n\tpatch = ((tmp & 0x0000f00) == 0x300) ? true : false;\n\n\tif (patch &&\n\t    ((rdev->pdev->device == 0x67B0) ||\n\t     (rdev->pdev->device == 0x67B1))) {\n\t\tfor (i = 0; i < table->last; i++) {\n\t\t\tif (table->last >= SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tswitch(table->mc_reg_address[i].s1 >> 2) {\n\t\t\tcase MC_SEQ_MISC1:\n\t\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\t\tif ((table->mc_reg_table_entry[k].mclk_max == 125000) ||\n\t\t\t\t\t    (table->mc_reg_table_entry[k].mclk_max == 137500))\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] =\n\t\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xFFFFFFF8) |\n\t\t\t\t\t\t\t0x00000007;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase MC_SEQ_WR_CTL_D0:\n\t\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\t\tif ((table->mc_reg_table_entry[k].mclk_max == 125000) ||\n\t\t\t\t\t    (table->mc_reg_table_entry[k].mclk_max == 137500))\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] =\n\t\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xFFFF0F00) |\n\t\t\t\t\t\t\t0x0000D0DD;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase MC_SEQ_WR_CTL_D1:\n\t\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\t\tif ((table->mc_reg_table_entry[k].mclk_max == 125000) ||\n\t\t\t\t\t    (table->mc_reg_table_entry[k].mclk_max == 137500))\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] =\n\t\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xFFFF0F00) |\n\t\t\t\t\t\t\t0x0000D0DD;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase MC_SEQ_WR_CTL_2:\n\t\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\t\tif ((table->mc_reg_table_entry[k].mclk_max == 125000) ||\n\t\t\t\t\t    (table->mc_reg_table_entry[k].mclk_max == 137500))\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] = 0;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase MC_SEQ_CAS_TIMING:\n\t\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\t\tif (table->mc_reg_table_entry[k].mclk_max == 125000)\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] =\n\t\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xFFE0FE0F) |\n\t\t\t\t\t\t\t0x000C0140;\n\t\t\t\t\telse if (table->mc_reg_table_entry[k].mclk_max == 137500)\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] =\n\t\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xFFE0FE0F) |\n\t\t\t\t\t\t\t0x000C0150;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase MC_SEQ_MISC_TIMING:\n\t\t\t\tfor (k = 0; k < table->num_entries; k++) {\n\t\t\t\t\tif (table->mc_reg_table_entry[k].mclk_max == 125000)\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] =\n\t\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xFFFFFFE0) |\n\t\t\t\t\t\t\t0x00000030;\n\t\t\t\t\telse if (table->mc_reg_table_entry[k].mclk_max == 137500)\n\t\t\t\t\t\ttable->mc_reg_table_entry[k].mc_data[i] =\n\t\t\t\t\t\t\t(table->mc_reg_table_entry[k].mc_data[i] & 0xFFFFFFE0) |\n\t\t\t\t\t\t\t0x00000035;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tWREG32(MC_SEQ_IO_DEBUG_INDEX, 3);\n\t\ttmp = RREG32(MC_SEQ_IO_DEBUG_DATA);\n\t\ttmp = (tmp & 0xFFF8FFFF) | (1 << 16);\n\t\tWREG32(MC_SEQ_IO_DEBUG_INDEX, 3);\n\t\tWREG32(MC_SEQ_IO_DEBUG_DATA, tmp);\n\t}\n\n\treturn 0;\n}\n\nstatic int ci_initialize_mc_reg_table(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct atom_mc_reg_table *table;\n\tstruct ci_mc_reg_table *ci_table = &pi->mc_reg_table;\n\tu8 module_index = rv770_get_memory_module_index(rdev);\n\tint ret;\n\n\ttable = kzalloc(sizeof(struct atom_mc_reg_table), GFP_KERNEL);\n\tif (!table)\n\t\treturn -ENOMEM;\n\n\tWREG32(MC_SEQ_RAS_TIMING_LP, RREG32(MC_SEQ_RAS_TIMING));\n\tWREG32(MC_SEQ_CAS_TIMING_LP, RREG32(MC_SEQ_CAS_TIMING));\n\tWREG32(MC_SEQ_DLL_STBY_LP, RREG32(MC_SEQ_DLL_STBY));\n\tWREG32(MC_SEQ_G5PDX_CMD0_LP, RREG32(MC_SEQ_G5PDX_CMD0));\n\tWREG32(MC_SEQ_G5PDX_CMD1_LP, RREG32(MC_SEQ_G5PDX_CMD1));\n\tWREG32(MC_SEQ_G5PDX_CTRL_LP, RREG32(MC_SEQ_G5PDX_CTRL));\n\tWREG32(MC_SEQ_PMG_DVS_CMD_LP, RREG32(MC_SEQ_PMG_DVS_CMD));\n\tWREG32(MC_SEQ_PMG_DVS_CTL_LP, RREG32(MC_SEQ_PMG_DVS_CTL));\n\tWREG32(MC_SEQ_MISC_TIMING_LP, RREG32(MC_SEQ_MISC_TIMING));\n\tWREG32(MC_SEQ_MISC_TIMING2_LP, RREG32(MC_SEQ_MISC_TIMING2));\n\tWREG32(MC_SEQ_PMG_CMD_EMRS_LP, RREG32(MC_PMG_CMD_EMRS));\n\tWREG32(MC_SEQ_PMG_CMD_MRS_LP, RREG32(MC_PMG_CMD_MRS));\n\tWREG32(MC_SEQ_PMG_CMD_MRS1_LP, RREG32(MC_PMG_CMD_MRS1));\n\tWREG32(MC_SEQ_WR_CTL_D0_LP, RREG32(MC_SEQ_WR_CTL_D0));\n\tWREG32(MC_SEQ_WR_CTL_D1_LP, RREG32(MC_SEQ_WR_CTL_D1));\n\tWREG32(MC_SEQ_RD_CTL_D0_LP, RREG32(MC_SEQ_RD_CTL_D0));\n\tWREG32(MC_SEQ_RD_CTL_D1_LP, RREG32(MC_SEQ_RD_CTL_D1));\n\tWREG32(MC_SEQ_PMG_TIMING_LP, RREG32(MC_SEQ_PMG_TIMING));\n\tWREG32(MC_SEQ_PMG_CMD_MRS2_LP, RREG32(MC_PMG_CMD_MRS2));\n\tWREG32(MC_SEQ_WR_CTL_2_LP, RREG32(MC_SEQ_WR_CTL_2));\n\n\tret = radeon_atom_init_mc_reg_table(rdev, module_index, table);\n\tif (ret)\n\t\tgoto init_mc_done;\n\n\tret = ci_copy_vbios_mc_reg_table(table, ci_table);\n\tif (ret)\n\t\tgoto init_mc_done;\n\n\tci_set_s0_mc_reg_index(ci_table);\n\n\tret = ci_register_patching_mc_seq(rdev, ci_table);\n\tif (ret)\n\t\tgoto init_mc_done;\n\n\tret = ci_set_mc_special_registers(rdev, ci_table);\n\tif (ret)\n\t\tgoto init_mc_done;\n\n\tci_set_valid_flag(ci_table);\n\ninit_mc_done:\n\tkfree(table);\n\n\treturn ret;\n}\n\nstatic int ci_populate_mc_reg_addresses(struct radeon_device *rdev,\n\t\t\t\t\tSMU7_Discrete_MCRegisters *mc_reg_table)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 i, j;\n\n\tfor (i = 0, j = 0; j < pi->mc_reg_table.last; j++) {\n\t\tif (pi->mc_reg_table.valid_flag & (1 << j)) {\n\t\t\tif (i >= SMU7_DISCRETE_MC_REGISTER_ARRAY_SIZE)\n\t\t\t\treturn -EINVAL;\n\t\t\tmc_reg_table->address[i].s0 = cpu_to_be16(pi->mc_reg_table.mc_reg_address[j].s0);\n\t\t\tmc_reg_table->address[i].s1 = cpu_to_be16(pi->mc_reg_table.mc_reg_address[j].s1);\n\t\t\ti++;\n\t\t}\n\t}\n\n\tmc_reg_table->last = (u8)i;\n\n\treturn 0;\n}\n\nstatic void ci_convert_mc_registers(const struct ci_mc_reg_entry *entry,\n\t\t\t\t    SMU7_Discrete_MCRegisterSet *data,\n\t\t\t\t    u32 num_entries, u32 valid_flag)\n{\n\tu32 i, j;\n\n\tfor (i = 0, j = 0; j < num_entries; j++) {\n\t\tif (valid_flag & (1 << j)) {\n\t\t\tdata->value[i] = cpu_to_be32(entry->mc_data[j]);\n\t\t\ti++;\n\t\t}\n\t}\n}\n\nstatic void ci_convert_mc_reg_table_entry_to_smc(struct radeon_device *rdev,\n\t\t\t\t\t\t const u32 memory_clock,\n\t\t\t\t\t\t SMU7_Discrete_MCRegisterSet *mc_reg_table_data)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 i = 0;\n\n\tfor(i = 0; i < pi->mc_reg_table.num_entries; i++) {\n\t\tif (memory_clock <= pi->mc_reg_table.mc_reg_table_entry[i].mclk_max)\n\t\t\tbreak;\n\t}\n\n\tif ((i == pi->mc_reg_table.num_entries) && (i > 0))\n\t\t--i;\n\n\tci_convert_mc_registers(&pi->mc_reg_table.mc_reg_table_entry[i],\n\t\t\t\tmc_reg_table_data, pi->mc_reg_table.last,\n\t\t\t\tpi->mc_reg_table.valid_flag);\n}\n\nstatic void ci_convert_mc_reg_table_to_smc(struct radeon_device *rdev,\n\t\t\t\t\t   SMU7_Discrete_MCRegisters *mc_reg_table)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 i;\n\n\tfor (i = 0; i < pi->dpm_table.mclk_table.count; i++)\n\t\tci_convert_mc_reg_table_entry_to_smc(rdev,\n\t\t\t\t\t\t     pi->dpm_table.mclk_table.dpm_levels[i].value,\n\t\t\t\t\t\t     &mc_reg_table->data[i]);\n}\n\nstatic int ci_populate_initial_mc_reg_table(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tint ret;\n\n\tmemset(&pi->smc_mc_reg_table, 0, sizeof(SMU7_Discrete_MCRegisters));\n\n\tret = ci_populate_mc_reg_addresses(rdev, &pi->smc_mc_reg_table);\n\tif (ret)\n\t\treturn ret;\n\tci_convert_mc_reg_table_to_smc(rdev, &pi->smc_mc_reg_table);\n\n\treturn ci_copy_bytes_to_smc(rdev,\n\t\t\t\t    pi->mc_reg_table_start,\n\t\t\t\t    (u8 *)&pi->smc_mc_reg_table,\n\t\t\t\t    sizeof(SMU7_Discrete_MCRegisters),\n\t\t\t\t    pi->sram_end);\n}\n\nstatic int ci_update_and_upload_mc_reg_table(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tif (!(pi->need_update_smu7_dpm_table & DPMTABLE_OD_UPDATE_MCLK))\n\t\treturn 0;\n\n\tmemset(&pi->smc_mc_reg_table, 0, sizeof(SMU7_Discrete_MCRegisters));\n\n\tci_convert_mc_reg_table_to_smc(rdev, &pi->smc_mc_reg_table);\n\n\treturn ci_copy_bytes_to_smc(rdev,\n\t\t\t\t    pi->mc_reg_table_start +\n\t\t\t\t    offsetof(SMU7_Discrete_MCRegisters, data[0]),\n\t\t\t\t    (u8 *)&pi->smc_mc_reg_table.data[0],\n\t\t\t\t    sizeof(SMU7_Discrete_MCRegisterSet) *\n\t\t\t\t    pi->dpm_table.mclk_table.count,\n\t\t\t\t    pi->sram_end);\n}\n\nstatic void ci_enable_voltage_control(struct radeon_device *rdev)\n{\n\tu32 tmp = RREG32_SMC(GENERAL_PWRMGT);\n\n\ttmp |= VOLT_PWRMGT_EN;\n\tWREG32_SMC(GENERAL_PWRMGT, tmp);\n}\n\nstatic enum radeon_pcie_gen ci_get_maximum_link_speed(struct radeon_device *rdev,\n\t\t\t\t\t\t      struct radeon_ps *radeon_state)\n{\n\tstruct ci_ps *state = ci_get_ps(radeon_state);\n\tint i;\n\tu16 pcie_speed, max_speed = 0;\n\n\tfor (i = 0; i < state->performance_level_count; i++) {\n\t\tpcie_speed = state->performance_levels[i].pcie_gen;\n\t\tif (max_speed < pcie_speed)\n\t\t\tmax_speed = pcie_speed;\n\t}\n\n\treturn max_speed;\n}\n\nstatic u16 ci_get_current_pcie_speed(struct radeon_device *rdev)\n{\n\tu32 speed_cntl = 0;\n\n\tspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL) & LC_CURRENT_DATA_RATE_MASK;\n\tspeed_cntl >>= LC_CURRENT_DATA_RATE_SHIFT;\n\n\treturn (u16)speed_cntl;\n}\n\nstatic int ci_get_current_pcie_lane_number(struct radeon_device *rdev)\n{\n\tu32 link_width = 0;\n\n\tlink_width = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL) & LC_LINK_WIDTH_RD_MASK;\n\tlink_width >>= LC_LINK_WIDTH_RD_SHIFT;\n\n\tswitch (link_width) {\n\tcase RADEON_PCIE_LC_LINK_WIDTH_X1:\n\t\treturn 1;\n\tcase RADEON_PCIE_LC_LINK_WIDTH_X2:\n\t\treturn 2;\n\tcase RADEON_PCIE_LC_LINK_WIDTH_X4:\n\t\treturn 4;\n\tcase RADEON_PCIE_LC_LINK_WIDTH_X8:\n\t\treturn 8;\n\tcase RADEON_PCIE_LC_LINK_WIDTH_X12:\n\t\t \n\t\treturn 12;\n\tcase RADEON_PCIE_LC_LINK_WIDTH_X0:\n\tcase RADEON_PCIE_LC_LINK_WIDTH_X16:\n\tdefault:\n\t\treturn 16;\n\t}\n}\n\nstatic void ci_request_link_speed_change_before_state_change(struct radeon_device *rdev,\n\t\t\t\t\t\t\t     struct radeon_ps *radeon_new_state,\n\t\t\t\t\t\t\t     struct radeon_ps *radeon_current_state)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tenum radeon_pcie_gen target_link_speed =\n\t\tci_get_maximum_link_speed(rdev, radeon_new_state);\n\tenum radeon_pcie_gen current_link_speed;\n\n\tif (pi->force_pcie_gen == RADEON_PCIE_GEN_INVALID)\n\t\tcurrent_link_speed = ci_get_maximum_link_speed(rdev, radeon_current_state);\n\telse\n\t\tcurrent_link_speed = pi->force_pcie_gen;\n\n\tpi->force_pcie_gen = RADEON_PCIE_GEN_INVALID;\n\tpi->pspp_notify_required = false;\n\tif (target_link_speed > current_link_speed) {\n\t\tswitch (target_link_speed) {\n#ifdef CONFIG_ACPI\n\t\tcase RADEON_PCIE_GEN3:\n\t\t\tif (radeon_acpi_pcie_performance_request(rdev, PCIE_PERF_REQ_PECI_GEN3, false) == 0)\n\t\t\t\tbreak;\n\t\t\tpi->force_pcie_gen = RADEON_PCIE_GEN2;\n\t\t\tif (current_link_speed == RADEON_PCIE_GEN2)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n\t\tcase RADEON_PCIE_GEN2:\n\t\t\tif (radeon_acpi_pcie_performance_request(rdev, PCIE_PERF_REQ_PECI_GEN2, false) == 0)\n\t\t\t\tbreak;\n\t\t\tfallthrough;\n#endif\n\t\tdefault:\n\t\t\tpi->force_pcie_gen = ci_get_current_pcie_speed(rdev);\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tif (target_link_speed < current_link_speed)\n\t\t\tpi->pspp_notify_required = true;\n\t}\n}\n\nstatic void ci_notify_link_speed_change_after_state_change(struct radeon_device *rdev,\n\t\t\t\t\t\t\t   struct radeon_ps *radeon_new_state,\n\t\t\t\t\t\t\t   struct radeon_ps *radeon_current_state)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tenum radeon_pcie_gen target_link_speed =\n\t\tci_get_maximum_link_speed(rdev, radeon_new_state);\n\tu8 request;\n\n\tif (pi->pspp_notify_required) {\n\t\tif (target_link_speed == RADEON_PCIE_GEN3)\n\t\t\trequest = PCIE_PERF_REQ_PECI_GEN3;\n\t\telse if (target_link_speed == RADEON_PCIE_GEN2)\n\t\t\trequest = PCIE_PERF_REQ_PECI_GEN2;\n\t\telse\n\t\t\trequest = PCIE_PERF_REQ_PECI_GEN1;\n\n\t\tif ((request == PCIE_PERF_REQ_PECI_GEN1) &&\n\t\t    (ci_get_current_pcie_speed(rdev) > 0))\n\t\t\treturn;\n\n#ifdef CONFIG_ACPI\n\t\tradeon_acpi_pcie_performance_request(rdev, request, false);\n#endif\n\t}\n}\n\nstatic int ci_set_private_data_variables_based_on_pptable(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_clock_voltage_dependency_table *allowed_sclk_vddc_table =\n\t\t&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk;\n\tstruct radeon_clock_voltage_dependency_table *allowed_mclk_vddc_table =\n\t\t&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk;\n\tstruct radeon_clock_voltage_dependency_table *allowed_mclk_vddci_table =\n\t\t&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk;\n\n\tif (allowed_sclk_vddc_table == NULL)\n\t\treturn -EINVAL;\n\tif (allowed_sclk_vddc_table->count < 1)\n\t\treturn -EINVAL;\n\tif (allowed_mclk_vddc_table == NULL)\n\t\treturn -EINVAL;\n\tif (allowed_mclk_vddc_table->count < 1)\n\t\treturn -EINVAL;\n\tif (allowed_mclk_vddci_table == NULL)\n\t\treturn -EINVAL;\n\tif (allowed_mclk_vddci_table->count < 1)\n\t\treturn -EINVAL;\n\n\tpi->min_vddc_in_pp_table = allowed_sclk_vddc_table->entries[0].v;\n\tpi->max_vddc_in_pp_table =\n\t\tallowed_sclk_vddc_table->entries[allowed_sclk_vddc_table->count - 1].v;\n\n\tpi->min_vddci_in_pp_table = allowed_mclk_vddci_table->entries[0].v;\n\tpi->max_vddci_in_pp_table =\n\t\tallowed_mclk_vddci_table->entries[allowed_mclk_vddci_table->count - 1].v;\n\n\trdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk =\n\t\tallowed_sclk_vddc_table->entries[allowed_sclk_vddc_table->count - 1].clk;\n\trdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.mclk =\n\t\tallowed_mclk_vddc_table->entries[allowed_sclk_vddc_table->count - 1].clk;\n\trdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddc =\n\t\tallowed_sclk_vddc_table->entries[allowed_sclk_vddc_table->count - 1].v;\n\trdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddci =\n\t\tallowed_mclk_vddci_table->entries[allowed_mclk_vddci_table->count - 1].v;\n\n\treturn 0;\n}\n\nstatic void ci_patch_with_vddc_leakage(struct radeon_device *rdev, u16 *vddc)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_leakage_voltage *leakage_table = &pi->vddc_leakage;\n\tu32 leakage_index;\n\n\tfor (leakage_index = 0; leakage_index < leakage_table->count; leakage_index++) {\n\t\tif (leakage_table->leakage_id[leakage_index] == *vddc) {\n\t\t\t*vddc = leakage_table->actual_voltage[leakage_index];\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void ci_patch_with_vddci_leakage(struct radeon_device *rdev, u16 *vddci)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_leakage_voltage *leakage_table = &pi->vddci_leakage;\n\tu32 leakage_index;\n\n\tfor (leakage_index = 0; leakage_index < leakage_table->count; leakage_index++) {\n\t\tif (leakage_table->leakage_id[leakage_index] == *vddci) {\n\t\t\t*vddci = leakage_table->actual_voltage[leakage_index];\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void ci_patch_clock_voltage_dependency_table_with_vddc_leakage(struct radeon_device *rdev,\n\t\t\t\t\t\t\t\t      struct radeon_clock_voltage_dependency_table *table)\n{\n\tu32 i;\n\n\tif (table) {\n\t\tfor (i = 0; i < table->count; i++)\n\t\t\tci_patch_with_vddc_leakage(rdev, &table->entries[i].v);\n\t}\n}\n\nstatic void ci_patch_clock_voltage_dependency_table_with_vddci_leakage(struct radeon_device *rdev,\n\t\t\t\t\t\t\t\t       struct radeon_clock_voltage_dependency_table *table)\n{\n\tu32 i;\n\n\tif (table) {\n\t\tfor (i = 0; i < table->count; i++)\n\t\t\tci_patch_with_vddci_leakage(rdev, &table->entries[i].v);\n\t}\n}\n\nstatic void ci_patch_vce_clock_voltage_dependency_table_with_vddc_leakage(struct radeon_device *rdev,\n\t\t\t\t\t\t\t\t\t  struct radeon_vce_clock_voltage_dependency_table *table)\n{\n\tu32 i;\n\n\tif (table) {\n\t\tfor (i = 0; i < table->count; i++)\n\t\t\tci_patch_with_vddc_leakage(rdev, &table->entries[i].v);\n\t}\n}\n\nstatic void ci_patch_uvd_clock_voltage_dependency_table_with_vddc_leakage(struct radeon_device *rdev,\n\t\t\t\t\t\t\t\t\t  struct radeon_uvd_clock_voltage_dependency_table *table)\n{\n\tu32 i;\n\n\tif (table) {\n\t\tfor (i = 0; i < table->count; i++)\n\t\t\tci_patch_with_vddc_leakage(rdev, &table->entries[i].v);\n\t}\n}\n\nstatic void ci_patch_vddc_phase_shed_limit_table_with_vddc_leakage(struct radeon_device *rdev,\n\t\t\t\t\t\t\t\t   struct radeon_phase_shedding_limits_table *table)\n{\n\tu32 i;\n\n\tif (table) {\n\t\tfor (i = 0; i < table->count; i++)\n\t\t\tci_patch_with_vddc_leakage(rdev, &table->entries[i].voltage);\n\t}\n}\n\nstatic void ci_patch_clock_voltage_limits_with_vddc_leakage(struct radeon_device *rdev,\n\t\t\t\t\t\t\t    struct radeon_clock_and_voltage_limits *table)\n{\n\tif (table) {\n\t\tci_patch_with_vddc_leakage(rdev, (u16 *)&table->vddc);\n\t\tci_patch_with_vddci_leakage(rdev, (u16 *)&table->vddci);\n\t}\n}\n\nstatic void ci_patch_cac_leakage_table_with_vddc_leakage(struct radeon_device *rdev,\n\t\t\t\t\t\t\t struct radeon_cac_leakage_table *table)\n{\n\tu32 i;\n\n\tif (table) {\n\t\tfor (i = 0; i < table->count; i++)\n\t\t\tci_patch_with_vddc_leakage(rdev, &table->entries[i].vddc);\n\t}\n}\n\nstatic void ci_patch_dependency_tables_with_leakage(struct radeon_device *rdev)\n{\n\n\tci_patch_clock_voltage_dependency_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t\t  &rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk);\n\tci_patch_clock_voltage_dependency_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t\t  &rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk);\n\tci_patch_clock_voltage_dependency_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t\t  &rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk);\n\tci_patch_clock_voltage_dependency_table_with_vddci_leakage(rdev,\n\t\t\t\t\t\t\t\t   &rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk);\n\tci_patch_vce_clock_voltage_dependency_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t\t      &rdev->pm.dpm.dyn_state.vce_clock_voltage_dependency_table);\n\tci_patch_uvd_clock_voltage_dependency_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t\t      &rdev->pm.dpm.dyn_state.uvd_clock_voltage_dependency_table);\n\tci_patch_clock_voltage_dependency_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t\t  &rdev->pm.dpm.dyn_state.samu_clock_voltage_dependency_table);\n\tci_patch_clock_voltage_dependency_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t\t  &rdev->pm.dpm.dyn_state.acp_clock_voltage_dependency_table);\n\tci_patch_vddc_phase_shed_limit_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t       &rdev->pm.dpm.dyn_state.phase_shedding_limits_table);\n\tci_patch_clock_voltage_limits_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t&rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac);\n\tci_patch_clock_voltage_limits_with_vddc_leakage(rdev,\n\t\t\t\t\t\t\t&rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc);\n\tci_patch_cac_leakage_table_with_vddc_leakage(rdev,\n\t\t\t\t\t\t     &rdev->pm.dpm.dyn_state.cac_leakage_table);\n\n}\n\nstatic void ci_get_memory_type(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tu32 tmp;\n\n\ttmp = RREG32(MC_SEQ_MISC0);\n\n\tif (((tmp & MC_SEQ_MISC0_GDDR5_MASK) >> MC_SEQ_MISC0_GDDR5_SHIFT) ==\n\t    MC_SEQ_MISC0_GDDR5_VALUE)\n\t\tpi->mem_gddr5 = true;\n\telse\n\t\tpi->mem_gddr5 = false;\n\n}\n\nstatic void ci_update_current_ps(struct radeon_device *rdev,\n\t\t\t\t struct radeon_ps *rps)\n{\n\tstruct ci_ps *new_ps = ci_get_ps(rps);\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tpi->current_rps = *rps;\n\tpi->current_ps = *new_ps;\n\tpi->current_rps.ps_priv = &pi->current_ps;\n}\n\nstatic void ci_update_requested_ps(struct radeon_device *rdev,\n\t\t\t\t   struct radeon_ps *rps)\n{\n\tstruct ci_ps *new_ps = ci_get_ps(rps);\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\n\tpi->requested_rps = *rps;\n\tpi->requested_ps = *new_ps;\n\tpi->requested_rps.ps_priv = &pi->requested_ps;\n}\n\nint ci_dpm_pre_set_power_state(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_ps requested_ps = *rdev->pm.dpm.requested_ps;\n\tstruct radeon_ps *new_ps = &requested_ps;\n\n\tci_update_requested_ps(rdev, new_ps);\n\n\tci_apply_state_adjust_rules(rdev, &pi->requested_rps);\n\n\treturn 0;\n}\n\nvoid ci_dpm_post_set_power_state(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_ps *new_ps = &pi->requested_rps;\n\n\tci_update_current_ps(rdev, new_ps);\n}\n\n\nvoid ci_dpm_setup_asic(struct radeon_device *rdev)\n{\n\tint r;\n\n\tr = ci_mc_load_microcode(rdev);\n\tif (r)\n\t\tDRM_ERROR(\"Failed to load MC firmware!\\n\");\n\tci_read_clock_registers(rdev);\n\tci_get_memory_type(rdev);\n\tci_enable_acpi_power_management(rdev);\n\tci_init_sclk_t(rdev);\n}\n\nint ci_dpm_enable(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;\n\tint ret;\n\n\tif (ci_is_smc_running(rdev))\n\t\treturn -EINVAL;\n\tif (pi->voltage_control != CISLANDS_VOLTAGE_CONTROL_NONE) {\n\t\tci_enable_voltage_control(rdev);\n\t\tret = ci_construct_voltage_tables(rdev);\n\t\tif (ret) {\n\t\t\tDRM_ERROR(\"ci_construct_voltage_tables failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\tif (pi->caps_dynamic_ac_timing) {\n\t\tret = ci_initialize_mc_reg_table(rdev);\n\t\tif (ret)\n\t\t\tpi->caps_dynamic_ac_timing = false;\n\t}\n\tif (pi->dynamic_ss)\n\t\tci_enable_spread_spectrum(rdev, true);\n\tif (pi->thermal_protection)\n\t\tci_enable_thermal_protection(rdev, true);\n\tci_program_sstp(rdev);\n\tci_enable_display_gap(rdev);\n\tci_program_vc(rdev);\n\tret = ci_upload_firmware(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_upload_firmware failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_process_firmware_header(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_process_firmware_header failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_initial_switch_from_arb_f0_to_f1(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_initial_switch_from_arb_f0_to_f1 failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_init_smc_table(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_init_smc_table failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_init_arb_table_index(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_init_arb_table_index failed\\n\");\n\t\treturn ret;\n\t}\n\tif (pi->caps_dynamic_ac_timing) {\n\t\tret = ci_populate_initial_mc_reg_table(rdev);\n\t\tif (ret) {\n\t\t\tDRM_ERROR(\"ci_populate_initial_mc_reg_table failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\tret = ci_populate_pm_base(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_populate_pm_base failed\\n\");\n\t\treturn ret;\n\t}\n\tci_dpm_start_smc(rdev);\n\tci_enable_vr_hot_gpio_interrupt(rdev);\n\tret = ci_notify_smc_display_change(rdev, false);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_notify_smc_display_change failed\\n\");\n\t\treturn ret;\n\t}\n\tci_enable_sclk_control(rdev, true);\n\tret = ci_enable_ulv(rdev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_enable_ulv failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_enable_ds_master_switch(rdev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_enable_ds_master_switch failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_start_dpm(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_start_dpm failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_enable_didt(rdev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_enable_didt failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_enable_smc_cac(rdev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_enable_smc_cac failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_enable_power_containment(rdev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_enable_power_containment failed\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ci_power_control_set_level(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_power_control_set_level failed\\n\");\n\t\treturn ret;\n\t}\n\n\tci_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);\n\n\tret = ci_enable_thermal_based_sclk_dpm(rdev, true);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_enable_thermal_based_sclk_dpm failed\\n\");\n\t\treturn ret;\n\t}\n\n\tci_thermal_start_thermal_controller(rdev);\n\n\tci_update_current_ps(rdev, boot_ps);\n\n\treturn 0;\n}\n\nstatic int ci_set_temperature_range(struct radeon_device *rdev)\n{\n\tint ret;\n\n\tret = ci_thermal_enable_alert(rdev, false);\n\tif (ret)\n\t\treturn ret;\n\tret = ci_thermal_set_temperature_range(rdev, R600_TEMP_RANGE_MIN, R600_TEMP_RANGE_MAX);\n\tif (ret)\n\t\treturn ret;\n\tret = ci_thermal_enable_alert(rdev, true);\n\tif (ret)\n\t\treturn ret;\n\n\treturn ret;\n}\n\nint ci_dpm_late_enable(struct radeon_device *rdev)\n{\n\tint ret;\n\n\tret = ci_set_temperature_range(rdev);\n\tif (ret)\n\t\treturn ret;\n\n\tci_dpm_powergate_uvd(rdev, true);\n\n\treturn 0;\n}\n\nvoid ci_dpm_disable(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;\n\n\tci_dpm_powergate_uvd(rdev, false);\n\n\tif (!ci_is_smc_running(rdev))\n\t\treturn;\n\n\tci_thermal_stop_thermal_controller(rdev);\n\n\tif (pi->thermal_protection)\n\t\tci_enable_thermal_protection(rdev, false);\n\tci_enable_power_containment(rdev, false);\n\tci_enable_smc_cac(rdev, false);\n\tci_enable_didt(rdev, false);\n\tci_enable_spread_spectrum(rdev, false);\n\tci_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, false);\n\tci_stop_dpm(rdev);\n\tci_enable_ds_master_switch(rdev, false);\n\tci_enable_ulv(rdev, false);\n\tci_clear_vc(rdev);\n\tci_reset_to_default(rdev);\n\tci_dpm_stop_smc(rdev);\n\tci_force_switch_to_arb_f0(rdev);\n\tci_enable_thermal_based_sclk_dpm(rdev, false);\n\n\tci_update_current_ps(rdev, boot_ps);\n}\n\nint ci_dpm_set_power_state(struct radeon_device *rdev)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_ps *new_ps = &pi->requested_rps;\n\tstruct radeon_ps *old_ps = &pi->current_rps;\n\tint ret;\n\n\tci_find_dpm_states_clocks_in_dpm_table(rdev, new_ps);\n\tif (pi->pcie_performance_request)\n\t\tci_request_link_speed_change_before_state_change(rdev, new_ps, old_ps);\n\tret = ci_freeze_sclk_mclk_dpm(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_freeze_sclk_mclk_dpm failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_populate_and_upload_sclk_mclk_dpm_levels(rdev, new_ps);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_populate_and_upload_sclk_mclk_dpm_levels failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_generate_dpm_level_enable_mask(rdev, new_ps);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_generate_dpm_level_enable_mask failed\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ci_update_vce_dpm(rdev, new_ps, old_ps);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_update_vce_dpm failed\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ci_update_sclk_t(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_update_sclk_t failed\\n\");\n\t\treturn ret;\n\t}\n\tif (pi->caps_dynamic_ac_timing) {\n\t\tret = ci_update_and_upload_mc_reg_table(rdev);\n\t\tif (ret) {\n\t\t\tDRM_ERROR(\"ci_update_and_upload_mc_reg_table failed\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\tret = ci_program_memory_timing_parameters(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_program_memory_timing_parameters failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_unfreeze_sclk_mclk_dpm(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_unfreeze_sclk_mclk_dpm failed\\n\");\n\t\treturn ret;\n\t}\n\tret = ci_upload_dpm_level_enable_mask(rdev);\n\tif (ret) {\n\t\tDRM_ERROR(\"ci_upload_dpm_level_enable_mask failed\\n\");\n\t\treturn ret;\n\t}\n\tif (pi->pcie_performance_request)\n\t\tci_notify_link_speed_change_after_state_change(rdev, new_ps, old_ps);\n\n\treturn 0;\n}\n\n#if 0\nvoid ci_dpm_reset_asic(struct radeon_device *rdev)\n{\n\tci_set_boot_state(rdev);\n}\n#endif\n\nvoid ci_dpm_display_configuration_changed(struct radeon_device *rdev)\n{\n\tci_program_display_gap(rdev);\n}\n\nunion power_info {\n\tstruct _ATOM_POWERPLAY_INFO info;\n\tstruct _ATOM_POWERPLAY_INFO_V2 info_2;\n\tstruct _ATOM_POWERPLAY_INFO_V3 info_3;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE pplib;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE2 pplib2;\n\tstruct _ATOM_PPLIB_POWERPLAYTABLE3 pplib3;\n};\n\nunion pplib_clock_info {\n\tstruct _ATOM_PPLIB_R600_CLOCK_INFO r600;\n\tstruct _ATOM_PPLIB_RS780_CLOCK_INFO rs780;\n\tstruct _ATOM_PPLIB_EVERGREEN_CLOCK_INFO evergreen;\n\tstruct _ATOM_PPLIB_SUMO_CLOCK_INFO sumo;\n\tstruct _ATOM_PPLIB_SI_CLOCK_INFO si;\n\tstruct _ATOM_PPLIB_CI_CLOCK_INFO ci;\n};\n\nunion pplib_power_state {\n\tstruct _ATOM_PPLIB_STATE v1;\n\tstruct _ATOM_PPLIB_STATE_V2 v2;\n};\n\nstatic void ci_parse_pplib_non_clock_info(struct radeon_device *rdev,\n\t\t\t\t\t  struct radeon_ps *rps,\n\t\t\t\t\t  struct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info,\n\t\t\t\t\t  u8 table_rev)\n{\n\trps->caps = le32_to_cpu(non_clock_info->ulCapsAndSettings);\n\trps->class = le16_to_cpu(non_clock_info->usClassification);\n\trps->class2 = le16_to_cpu(non_clock_info->usClassification2);\n\n\tif (ATOM_PPLIB_NONCLOCKINFO_VER1 < table_rev) {\n\t\trps->vclk = le32_to_cpu(non_clock_info->ulVCLK);\n\t\trps->dclk = le32_to_cpu(non_clock_info->ulDCLK);\n\t} else {\n\t\trps->vclk = 0;\n\t\trps->dclk = 0;\n\t}\n\n\tif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT)\n\t\trdev->pm.dpm.boot_ps = rps;\n\tif (rps->class & ATOM_PPLIB_CLASSIFICATION_UVDSTATE)\n\t\trdev->pm.dpm.uvd_ps = rps;\n}\n\nstatic void ci_parse_pplib_clock_info(struct radeon_device *rdev,\n\t\t\t\t      struct radeon_ps *rps, int index,\n\t\t\t\t      union pplib_clock_info *clock_info)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_ps *ps = ci_get_ps(rps);\n\tstruct ci_pl *pl = &ps->performance_levels[index];\n\n\tps->performance_level_count = index + 1;\n\n\tpl->sclk = le16_to_cpu(clock_info->ci.usEngineClockLow);\n\tpl->sclk |= clock_info->ci.ucEngineClockHigh << 16;\n\tpl->mclk = le16_to_cpu(clock_info->ci.usMemoryClockLow);\n\tpl->mclk |= clock_info->ci.ucMemoryClockHigh << 16;\n\n\tpl->pcie_gen = r600_get_pcie_gen_support(rdev,\n\t\t\t\t\t\t pi->sys_pcie_mask,\n\t\t\t\t\t\t pi->vbios_boot_state.pcie_gen_bootup_value,\n\t\t\t\t\t\t clock_info->ci.ucPCIEGen);\n\tpl->pcie_lane = r600_get_pcie_lane_support(rdev,\n\t\t\t\t\t\t   pi->vbios_boot_state.pcie_lane_bootup_value,\n\t\t\t\t\t\t   le16_to_cpu(clock_info->ci.usPCIELane));\n\n\tif (rps->class & ATOM_PPLIB_CLASSIFICATION_ACPI) {\n\t\tpi->acpi_pcie_gen = pl->pcie_gen;\n\t}\n\n\tif (rps->class2 & ATOM_PPLIB_CLASSIFICATION2_ULV) {\n\t\tpi->ulv.supported = true;\n\t\tpi->ulv.pl = *pl;\n\t\tpi->ulv.cg_ulv_parameter = CISLANDS_CGULVPARAMETER_DFLT;\n\t}\n\n\t \n\tif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT) {\n\t\tpl->mclk = pi->vbios_boot_state.mclk_bootup_value;\n\t\tpl->sclk = pi->vbios_boot_state.sclk_bootup_value;\n\t\tpl->pcie_gen = pi->vbios_boot_state.pcie_gen_bootup_value;\n\t\tpl->pcie_lane = pi->vbios_boot_state.pcie_lane_bootup_value;\n\t}\n\n\tswitch (rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) {\n\tcase ATOM_PPLIB_CLASSIFICATION_UI_BATTERY:\n\t\tpi->use_pcie_powersaving_levels = true;\n\t\tif (pi->pcie_gen_powersaving.max < pl->pcie_gen)\n\t\t\tpi->pcie_gen_powersaving.max = pl->pcie_gen;\n\t\tif (pi->pcie_gen_powersaving.min > pl->pcie_gen)\n\t\t\tpi->pcie_gen_powersaving.min = pl->pcie_gen;\n\t\tif (pi->pcie_lane_powersaving.max < pl->pcie_lane)\n\t\t\tpi->pcie_lane_powersaving.max = pl->pcie_lane;\n\t\tif (pi->pcie_lane_powersaving.min > pl->pcie_lane)\n\t\t\tpi->pcie_lane_powersaving.min = pl->pcie_lane;\n\t\tbreak;\n\tcase ATOM_PPLIB_CLASSIFICATION_UI_PERFORMANCE:\n\t\tpi->use_pcie_performance_levels = true;\n\t\tif (pi->pcie_gen_performance.max < pl->pcie_gen)\n\t\t\tpi->pcie_gen_performance.max = pl->pcie_gen;\n\t\tif (pi->pcie_gen_performance.min > pl->pcie_gen)\n\t\t\tpi->pcie_gen_performance.min = pl->pcie_gen;\n\t\tif (pi->pcie_lane_performance.max < pl->pcie_lane)\n\t\t\tpi->pcie_lane_performance.max = pl->pcie_lane;\n\t\tif (pi->pcie_lane_performance.min > pl->pcie_lane)\n\t\t\tpi->pcie_lane_performance.min = pl->pcie_lane;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic int ci_parse_power_table(struct radeon_device *rdev)\n{\n\tstruct radeon_mode_info *mode_info = &rdev->mode_info;\n\tstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info;\n\tunion pplib_power_state *power_state;\n\tint i, j, k, non_clock_array_index, clock_array_index;\n\tunion pplib_clock_info *clock_info;\n\tstruct _StateArray *state_array;\n\tstruct _ClockInfoArray *clock_info_array;\n\tstruct _NonClockInfoArray *non_clock_info_array;\n\tunion power_info *power_info;\n\tint index = GetIndexIntoMasterTable(DATA, PowerPlayInfo);\n\tu16 data_offset;\n\tu8 frev, crev;\n\tu8 *power_state_offset;\n\tstruct ci_ps *ps;\n\tint ret;\n\n\tif (!atom_parse_data_header(mode_info->atom_context, index, NULL,\n\t\t\t\t   &frev, &crev, &data_offset))\n\t\treturn -EINVAL;\n\tpower_info = (union power_info *)(mode_info->atom_context->bios + data_offset);\n\n\tstate_array = (struct _StateArray *)\n\t\t(mode_info->atom_context->bios + data_offset +\n\t\t le16_to_cpu(power_info->pplib.usStateArrayOffset));\n\tclock_info_array = (struct _ClockInfoArray *)\n\t\t(mode_info->atom_context->bios + data_offset +\n\t\t le16_to_cpu(power_info->pplib.usClockInfoArrayOffset));\n\tnon_clock_info_array = (struct _NonClockInfoArray *)\n\t\t(mode_info->atom_context->bios + data_offset +\n\t\t le16_to_cpu(power_info->pplib.usNonClockInfoArrayOffset));\n\n\trdev->pm.dpm.ps = kcalloc(state_array->ucNumEntries,\n\t\t\t\t  sizeof(struct radeon_ps),\n\t\t\t\t  GFP_KERNEL);\n\tif (!rdev->pm.dpm.ps)\n\t\treturn -ENOMEM;\n\tpower_state_offset = (u8 *)state_array->states;\n\trdev->pm.dpm.num_ps = 0;\n\tfor (i = 0; i < state_array->ucNumEntries; i++) {\n\t\tu8 *idx;\n\t\tpower_state = (union pplib_power_state *)power_state_offset;\n\t\tnon_clock_array_index = power_state->v2.nonClockInfoIndex;\n\t\tnon_clock_info = (struct _ATOM_PPLIB_NONCLOCK_INFO *)\n\t\t\t&non_clock_info_array->nonClockInfo[non_clock_array_index];\n\t\tif (!rdev->pm.power_state[i].clock_info) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_free_ps;\n\t\t}\n\t\tps = kzalloc(sizeof(struct ci_ps), GFP_KERNEL);\n\t\tif (ps == NULL) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free_ps;\n\t\t}\n\t\trdev->pm.dpm.ps[i].ps_priv = ps;\n\t\tci_parse_pplib_non_clock_info(rdev, &rdev->pm.dpm.ps[i],\n\t\t\t\t\t      non_clock_info,\n\t\t\t\t\t      non_clock_info_array->ucEntrySize);\n\t\tk = 0;\n\t\tidx = (u8 *)&power_state->v2.clockInfoIndex[0];\n\t\tfor (j = 0; j < power_state->v2.ucNumDPMLevels; j++) {\n\t\t\tclock_array_index = idx[j];\n\t\t\tif (clock_array_index >= clock_info_array->ucNumEntries)\n\t\t\t\tcontinue;\n\t\t\tif (k >= CISLANDS_MAX_HARDWARE_POWERLEVELS)\n\t\t\t\tbreak;\n\t\t\tclock_info = (union pplib_clock_info *)\n\t\t\t\t((u8 *)&clock_info_array->clockInfo[0] +\n\t\t\t\t (clock_array_index * clock_info_array->ucEntrySize));\n\t\t\tci_parse_pplib_clock_info(rdev,\n\t\t\t\t\t\t  &rdev->pm.dpm.ps[i], k,\n\t\t\t\t\t\t  clock_info);\n\t\t\tk++;\n\t\t}\n\t\tpower_state_offset += 2 + power_state->v2.ucNumDPMLevels;\n\t\trdev->pm.dpm.num_ps = i + 1;\n\t}\n\n\t \n\tfor (i = 0; i < RADEON_MAX_VCE_LEVELS; i++) {\n\t\tu32 sclk, mclk;\n\t\tclock_array_index = rdev->pm.dpm.vce_states[i].clk_idx;\n\t\tclock_info = (union pplib_clock_info *)\n\t\t\t&clock_info_array->clockInfo[clock_array_index * clock_info_array->ucEntrySize];\n\t\tsclk = le16_to_cpu(clock_info->ci.usEngineClockLow);\n\t\tsclk |= clock_info->ci.ucEngineClockHigh << 16;\n\t\tmclk = le16_to_cpu(clock_info->ci.usMemoryClockLow);\n\t\tmclk |= clock_info->ci.ucMemoryClockHigh << 16;\n\t\trdev->pm.dpm.vce_states[i].sclk = sclk;\n\t\trdev->pm.dpm.vce_states[i].mclk = mclk;\n\t}\n\n\treturn 0;\n\nerr_free_ps:\n\tfor (i = 0; i < rdev->pm.dpm.num_ps; i++)\n\t\tkfree(rdev->pm.dpm.ps[i].ps_priv);\n\tkfree(rdev->pm.dpm.ps);\n\treturn ret;\n}\n\nstatic int ci_get_vbios_boot_values(struct radeon_device *rdev,\n\t\t\t\t    struct ci_vbios_boot_state *boot_state)\n{\n\tstruct radeon_mode_info *mode_info = &rdev->mode_info;\n\tint index = GetIndexIntoMasterTable(DATA, FirmwareInfo);\n\tATOM_FIRMWARE_INFO_V2_2 *firmware_info;\n\tu8 frev, crev;\n\tu16 data_offset;\n\n\tif (atom_parse_data_header(mode_info->atom_context, index, NULL,\n\t\t\t\t   &frev, &crev, &data_offset)) {\n\t\tfirmware_info =\n\t\t\t(ATOM_FIRMWARE_INFO_V2_2 *)(mode_info->atom_context->bios +\n\t\t\t\t\t\t    data_offset);\n\t\tboot_state->mvdd_bootup_value = le16_to_cpu(firmware_info->usBootUpMVDDCVoltage);\n\t\tboot_state->vddc_bootup_value = le16_to_cpu(firmware_info->usBootUpVDDCVoltage);\n\t\tboot_state->vddci_bootup_value = le16_to_cpu(firmware_info->usBootUpVDDCIVoltage);\n\t\tboot_state->pcie_gen_bootup_value = ci_get_current_pcie_speed(rdev);\n\t\tboot_state->pcie_lane_bootup_value = ci_get_current_pcie_lane_number(rdev);\n\t\tboot_state->sclk_bootup_value = le32_to_cpu(firmware_info->ulDefaultEngineClock);\n\t\tboot_state->mclk_bootup_value = le32_to_cpu(firmware_info->ulDefaultMemoryClock);\n\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}\n\nvoid ci_dpm_fini(struct radeon_device *rdev)\n{\n\tint i;\n\n\tfor (i = 0; i < rdev->pm.dpm.num_ps; i++) {\n\t\tkfree(rdev->pm.dpm.ps[i].ps_priv);\n\t}\n\tkfree(rdev->pm.dpm.ps);\n\tkfree(rdev->pm.dpm.priv);\n\tkfree(rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries);\n\tr600_free_extended_power_table(rdev);\n}\n\nint ci_dpm_init(struct radeon_device *rdev)\n{\n\tint index = GetIndexIntoMasterTable(DATA, ASIC_InternalSS_Info);\n\tSMU7_Discrete_DpmTable  *dpm_table;\n\tstruct radeon_gpio_rec gpio;\n\tu16 data_offset, size;\n\tu8 frev, crev;\n\tstruct ci_power_info *pi;\n\tenum pci_bus_speed speed_cap = PCI_SPEED_UNKNOWN;\n\tstruct pci_dev *root = rdev->pdev->bus->self;\n\tint ret;\n\n\tpi = kzalloc(sizeof(struct ci_power_info), GFP_KERNEL);\n\tif (pi == NULL)\n\t\treturn -ENOMEM;\n\trdev->pm.dpm.priv = pi;\n\n\tif (!pci_is_root_bus(rdev->pdev->bus))\n\t\tspeed_cap = pcie_get_speed_cap(root);\n\tif (speed_cap == PCI_SPEED_UNKNOWN) {\n\t\tpi->sys_pcie_mask = 0;\n\t} else {\n\t\tif (speed_cap == PCIE_SPEED_8_0GT)\n\t\t\tpi->sys_pcie_mask = RADEON_PCIE_SPEED_25 |\n\t\t\t\tRADEON_PCIE_SPEED_50 |\n\t\t\t\tRADEON_PCIE_SPEED_80;\n\t\telse if (speed_cap == PCIE_SPEED_5_0GT)\n\t\t\tpi->sys_pcie_mask = RADEON_PCIE_SPEED_25 |\n\t\t\t\tRADEON_PCIE_SPEED_50;\n\t\telse\n\t\t\tpi->sys_pcie_mask = RADEON_PCIE_SPEED_25;\n\t}\n\tpi->force_pcie_gen = RADEON_PCIE_GEN_INVALID;\n\n\tpi->pcie_gen_performance.max = RADEON_PCIE_GEN1;\n\tpi->pcie_gen_performance.min = RADEON_PCIE_GEN3;\n\tpi->pcie_gen_powersaving.max = RADEON_PCIE_GEN1;\n\tpi->pcie_gen_powersaving.min = RADEON_PCIE_GEN3;\n\n\tpi->pcie_lane_performance.max = 0;\n\tpi->pcie_lane_performance.min = 16;\n\tpi->pcie_lane_powersaving.max = 0;\n\tpi->pcie_lane_powersaving.min = 16;\n\n\tret = ci_get_vbios_boot_values(rdev, &pi->vbios_boot_state);\n\tif (ret) {\n\t\tkfree(rdev->pm.dpm.priv);\n\t\treturn ret;\n\t}\n\n\tret = r600_get_platform_caps(rdev);\n\tif (ret) {\n\t\tkfree(rdev->pm.dpm.priv);\n\t\treturn ret;\n\t}\n\n\tret = r600_parse_extended_power_table(rdev);\n\tif (ret) {\n\t\tkfree(rdev->pm.dpm.priv);\n\t\treturn ret;\n\t}\n\n\tret = ci_parse_power_table(rdev);\n\tif (ret) {\n\t\tkfree(rdev->pm.dpm.priv);\n\t\tr600_free_extended_power_table(rdev);\n\t\treturn ret;\n\t}\n\n\tpi->dll_default_on = false;\n\tpi->sram_end = SMC_RAM_END;\n\n\tpi->activity_target[0] = CISLAND_TARGETACTIVITY_DFLT;\n\tpi->activity_target[1] = CISLAND_TARGETACTIVITY_DFLT;\n\tpi->activity_target[2] = CISLAND_TARGETACTIVITY_DFLT;\n\tpi->activity_target[3] = CISLAND_TARGETACTIVITY_DFLT;\n\tpi->activity_target[4] = CISLAND_TARGETACTIVITY_DFLT;\n\tpi->activity_target[5] = CISLAND_TARGETACTIVITY_DFLT;\n\tpi->activity_target[6] = CISLAND_TARGETACTIVITY_DFLT;\n\tpi->activity_target[7] = CISLAND_TARGETACTIVITY_DFLT;\n\n\tpi->mclk_activity_target = CISLAND_MCLK_TARGETACTIVITY_DFLT;\n\n\tpi->sclk_dpm_key_disabled = 0;\n\tpi->mclk_dpm_key_disabled = 0;\n\tpi->pcie_dpm_key_disabled = 0;\n\tpi->thermal_sclk_dpm_enabled = 0;\n\n\t \n\tif ((rdev->pdev->device == 0x6658) &&\n\t    (rdev->mc_fw->size == (BONAIRE_MC_UCODE_SIZE * 4))) {\n\t\tpi->mclk_dpm_key_disabled = 1;\n\t}\n\n\tpi->caps_sclk_ds = true;\n\n\tpi->mclk_strobe_mode_threshold = 40000;\n\tpi->mclk_stutter_mode_threshold = 40000;\n\tpi->mclk_edc_enable_threshold = 40000;\n\tpi->mclk_edc_wr_enable_threshold = 40000;\n\n\tci_initialize_powertune_defaults(rdev);\n\n\tpi->caps_fps = false;\n\n\tpi->caps_sclk_throttle_low_notification = false;\n\n\tpi->caps_uvd_dpm = true;\n\tpi->caps_vce_dpm = true;\n\n\tci_get_leakage_voltages(rdev);\n\tci_patch_dependency_tables_with_leakage(rdev);\n\tci_set_private_data_variables_based_on_pptable(rdev);\n\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries =\n\t\tkcalloc(4,\n\t\t\tsizeof(struct radeon_clock_voltage_dependency_entry),\n\t\t\tGFP_KERNEL);\n\tif (!rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries) {\n\t\tci_dpm_fini(rdev);\n\t\treturn -ENOMEM;\n\t}\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.count = 4;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[0].clk = 0;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[0].v = 0;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[1].clk = 36000;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[1].v = 720;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[2].clk = 54000;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[2].v = 810;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[3].clk = 72000;\n\trdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[3].v = 900;\n\n\trdev->pm.dpm.dyn_state.mclk_sclk_ratio = 4;\n\trdev->pm.dpm.dyn_state.sclk_mclk_delta = 15000;\n\trdev->pm.dpm.dyn_state.vddc_vddci_delta = 200;\n\n\trdev->pm.dpm.dyn_state.valid_sclk_values.count = 0;\n\trdev->pm.dpm.dyn_state.valid_sclk_values.values = NULL;\n\trdev->pm.dpm.dyn_state.valid_mclk_values.count = 0;\n\trdev->pm.dpm.dyn_state.valid_mclk_values.values = NULL;\n\n\tif (rdev->family == CHIP_HAWAII) {\n\t\tpi->thermal_temp_setting.temperature_low = 94500;\n\t\tpi->thermal_temp_setting.temperature_high = 95000;\n\t\tpi->thermal_temp_setting.temperature_shutdown = 104000;\n\t} else {\n\t\tpi->thermal_temp_setting.temperature_low = 99500;\n\t\tpi->thermal_temp_setting.temperature_high = 100000;\n\t\tpi->thermal_temp_setting.temperature_shutdown = 104000;\n\t}\n\n\tpi->uvd_enabled = false;\n\n\tdpm_table = &pi->smc_state_table;\n\n\tgpio = radeon_atombios_lookup_gpio(rdev, VDDC_VRHOT_GPIO_PINID);\n\tif (gpio.valid) {\n\t\tdpm_table->VRHotGpio = gpio.shift;\n\t\trdev->pm.dpm.platform_caps |= ATOM_PP_PLATFORM_CAP_REGULATOR_HOT;\n\t} else {\n\t\tdpm_table->VRHotGpio = CISLANDS_UNUSED_GPIO_PIN;\n\t\trdev->pm.dpm.platform_caps &= ~ATOM_PP_PLATFORM_CAP_REGULATOR_HOT;\n\t}\n\n\tgpio = radeon_atombios_lookup_gpio(rdev, PP_AC_DC_SWITCH_GPIO_PINID);\n\tif (gpio.valid) {\n\t\tdpm_table->AcDcGpio = gpio.shift;\n\t\trdev->pm.dpm.platform_caps |= ATOM_PP_PLATFORM_CAP_HARDWAREDC;\n\t} else {\n\t\tdpm_table->AcDcGpio = CISLANDS_UNUSED_GPIO_PIN;\n\t\trdev->pm.dpm.platform_caps &= ~ATOM_PP_PLATFORM_CAP_HARDWAREDC;\n\t}\n\n\tgpio = radeon_atombios_lookup_gpio(rdev, VDDC_PCC_GPIO_PINID);\n\tif (gpio.valid) {\n\t\tu32 tmp = RREG32_SMC(CNB_PWRMGT_CNTL);\n\n\t\tswitch (gpio.shift) {\n\t\tcase 0:\n\t\t\ttmp &= ~GNB_SLOW_MODE_MASK;\n\t\t\ttmp |= GNB_SLOW_MODE(1);\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttmp &= ~GNB_SLOW_MODE_MASK;\n\t\t\ttmp |= GNB_SLOW_MODE(2);\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttmp |= GNB_SLOW;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttmp |= FORCE_NB_PS1;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\ttmp |= DPM_ENABLED;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tDRM_DEBUG(\"Invalid PCC GPIO: %u!\\n\", gpio.shift);\n\t\t\tbreak;\n\t\t}\n\t\tWREG32_SMC(CNB_PWRMGT_CNTL, tmp);\n\t}\n\n\tpi->voltage_control = CISLANDS_VOLTAGE_CONTROL_NONE;\n\tpi->vddci_control = CISLANDS_VOLTAGE_CONTROL_NONE;\n\tpi->mvdd_control = CISLANDS_VOLTAGE_CONTROL_NONE;\n\tif (radeon_atom_is_voltage_gpio(rdev, VOLTAGE_TYPE_VDDC, VOLTAGE_OBJ_GPIO_LUT))\n\t\tpi->voltage_control = CISLANDS_VOLTAGE_CONTROL_BY_GPIO;\n\telse if (radeon_atom_is_voltage_gpio(rdev, VOLTAGE_TYPE_VDDC, VOLTAGE_OBJ_SVID2))\n\t\tpi->voltage_control = CISLANDS_VOLTAGE_CONTROL_BY_SVID2;\n\n\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_VDDCI_CONTROL) {\n\t\tif (radeon_atom_is_voltage_gpio(rdev, VOLTAGE_TYPE_VDDCI, VOLTAGE_OBJ_GPIO_LUT))\n\t\t\tpi->vddci_control = CISLANDS_VOLTAGE_CONTROL_BY_GPIO;\n\t\telse if (radeon_atom_is_voltage_gpio(rdev, VOLTAGE_TYPE_VDDCI, VOLTAGE_OBJ_SVID2))\n\t\t\tpi->vddci_control = CISLANDS_VOLTAGE_CONTROL_BY_SVID2;\n\t\telse\n\t\t\trdev->pm.dpm.platform_caps &= ~ATOM_PP_PLATFORM_CAP_VDDCI_CONTROL;\n\t}\n\n\tif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_MVDDCONTROL) {\n\t\tif (radeon_atom_is_voltage_gpio(rdev, VOLTAGE_TYPE_MVDDC, VOLTAGE_OBJ_GPIO_LUT))\n\t\t\tpi->mvdd_control = CISLANDS_VOLTAGE_CONTROL_BY_GPIO;\n\t\telse if (radeon_atom_is_voltage_gpio(rdev, VOLTAGE_TYPE_MVDDC, VOLTAGE_OBJ_SVID2))\n\t\t\tpi->mvdd_control = CISLANDS_VOLTAGE_CONTROL_BY_SVID2;\n\t\telse\n\t\t\trdev->pm.dpm.platform_caps &= ~ATOM_PP_PLATFORM_CAP_MVDDCONTROL;\n\t}\n\n\tpi->vddc_phase_shed_control = true;\n\n#if defined(CONFIG_ACPI)\n\tpi->pcie_performance_request =\n\t\tradeon_acpi_is_pcie_performance_request_supported(rdev);\n#else\n\tpi->pcie_performance_request = false;\n#endif\n\n\tif (atom_parse_data_header(rdev->mode_info.atom_context, index, &size,\n\t\t\t\t   &frev, &crev, &data_offset)) {\n\t\tpi->caps_sclk_ss_support = true;\n\t\tpi->caps_mclk_ss_support = true;\n\t\tpi->dynamic_ss = true;\n\t} else {\n\t\tpi->caps_sclk_ss_support = false;\n\t\tpi->caps_mclk_ss_support = false;\n\t\tpi->dynamic_ss = true;\n\t}\n\n\tif (rdev->pm.int_thermal_type != THERMAL_TYPE_NONE)\n\t\tpi->thermal_protection = true;\n\telse\n\t\tpi->thermal_protection = false;\n\n\tpi->caps_dynamic_ac_timing = true;\n\n\tpi->uvd_power_gated = false;\n\n\t \n\tif ((rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.sclk == 0) ||\n\t    (rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.mclk == 0))\n\t\trdev->pm.dpm.dyn_state.max_clock_voltage_on_dc =\n\t\t\trdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\n\n\tpi->fan_ctrl_is_in_default_mode = true;\n\n\treturn 0;\n}\n\nvoid ci_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,\n\t\t\t\t\t\t    struct seq_file *m)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct radeon_ps *rps = &pi->current_rps;\n\tu32 sclk = ci_get_average_sclk_freq(rdev);\n\tu32 mclk = ci_get_average_mclk_freq(rdev);\n\n\tseq_printf(m, \"uvd    %sabled\\n\", pi->uvd_enabled ? \"en\" : \"dis\");\n\tseq_printf(m, \"vce    %sabled\\n\", rps->vce_active ? \"en\" : \"dis\");\n\tseq_printf(m, \"power level avg    sclk: %u mclk: %u\\n\",\n\t\t   sclk, mclk);\n}\n\nvoid ci_dpm_print_power_state(struct radeon_device *rdev,\n\t\t\t      struct radeon_ps *rps)\n{\n\tstruct ci_ps *ps = ci_get_ps(rps);\n\tstruct ci_pl *pl;\n\tint i;\n\n\tr600_dpm_print_class_info(rps->class, rps->class2);\n\tr600_dpm_print_cap_info(rps->caps);\n\tprintk(\"\\tuvd    vclk: %d dclk: %d\\n\", rps->vclk, rps->dclk);\n\tfor (i = 0; i < ps->performance_level_count; i++) {\n\t\tpl = &ps->performance_levels[i];\n\t\tprintk(\"\\t\\tpower level %d    sclk: %u mclk: %u pcie gen: %u pcie lanes: %u\\n\",\n\t\t       i, pl->sclk, pl->mclk, pl->pcie_gen + 1, pl->pcie_lane);\n\t}\n\tr600_dpm_print_ps_status(rdev, rps);\n}\n\nu32 ci_dpm_get_current_sclk(struct radeon_device *rdev)\n{\n\tu32 sclk = ci_get_average_sclk_freq(rdev);\n\n\treturn sclk;\n}\n\nu32 ci_dpm_get_current_mclk(struct radeon_device *rdev)\n{\n\tu32 mclk = ci_get_average_mclk_freq(rdev);\n\n\treturn mclk;\n}\n\nu32 ci_dpm_get_sclk(struct radeon_device *rdev, bool low)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_ps *requested_state = ci_get_ps(&pi->requested_rps);\n\n\tif (low)\n\t\treturn requested_state->performance_levels[0].sclk;\n\telse\n\t\treturn requested_state->performance_levels[requested_state->performance_level_count - 1].sclk;\n}\n\nu32 ci_dpm_get_mclk(struct radeon_device *rdev, bool low)\n{\n\tstruct ci_power_info *pi = ci_get_pi(rdev);\n\tstruct ci_ps *requested_state = ci_get_ps(&pi->requested_rps);\n\n\tif (low)\n\t\treturn requested_state->performance_levels[0].mclk;\n\telse\n\t\treturn requested_state->performance_levels[requested_state->performance_level_count - 1].mclk;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}