{
  "module_name": "radeon_device.c",
  "hash_id": "8619552bbc7e28c8119ff9153fc16c497c89805553ebbd1e4633cc50c09b4aaa",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/radeon/radeon_device.c",
  "human_readable_source": " \n\n#include <linux/console.h>\n#include <linux/efi.h>\n#include <linux/pci.h>\n#include <linux/pm_runtime.h>\n#include <linux/slab.h>\n#include <linux/vga_switcheroo.h>\n#include <linux/vgaarb.h>\n\n#include <drm/drm_cache.h>\n#include <drm/drm_crtc_helper.h>\n#include <drm/drm_device.h>\n#include <drm/drm_file.h>\n#include <drm/drm_framebuffer.h>\n#include <drm/drm_probe_helper.h>\n#include <drm/radeon_drm.h>\n\n#include \"radeon_device.h\"\n#include \"radeon_reg.h\"\n#include \"radeon.h\"\n#include \"atom.h\"\n\nstatic const char radeon_family_name[][16] = {\n\t\"R100\",\n\t\"RV100\",\n\t\"RS100\",\n\t\"RV200\",\n\t\"RS200\",\n\t\"R200\",\n\t\"RV250\",\n\t\"RS300\",\n\t\"RV280\",\n\t\"R300\",\n\t\"R350\",\n\t\"RV350\",\n\t\"RV380\",\n\t\"R420\",\n\t\"R423\",\n\t\"RV410\",\n\t\"RS400\",\n\t\"RS480\",\n\t\"RS600\",\n\t\"RS690\",\n\t\"RS740\",\n\t\"RV515\",\n\t\"R520\",\n\t\"RV530\",\n\t\"RV560\",\n\t\"RV570\",\n\t\"R580\",\n\t\"R600\",\n\t\"RV610\",\n\t\"RV630\",\n\t\"RV670\",\n\t\"RV620\",\n\t\"RV635\",\n\t\"RS780\",\n\t\"RS880\",\n\t\"RV770\",\n\t\"RV730\",\n\t\"RV710\",\n\t\"RV740\",\n\t\"CEDAR\",\n\t\"REDWOOD\",\n\t\"JUNIPER\",\n\t\"CYPRESS\",\n\t\"HEMLOCK\",\n\t\"PALM\",\n\t\"SUMO\",\n\t\"SUMO2\",\n\t\"BARTS\",\n\t\"TURKS\",\n\t\"CAICOS\",\n\t\"CAYMAN\",\n\t\"ARUBA\",\n\t\"TAHITI\",\n\t\"PITCAIRN\",\n\t\"VERDE\",\n\t\"OLAND\",\n\t\"HAINAN\",\n\t\"BONAIRE\",\n\t\"KAVERI\",\n\t\"KABINI\",\n\t\"HAWAII\",\n\t\"MULLINS\",\n\t\"LAST\",\n};\n\n#if defined(CONFIG_VGA_SWITCHEROO)\nbool radeon_has_atpx_dgpu_power_cntl(void);\nbool radeon_is_atpx_hybrid(void);\n#else\nstatic inline bool radeon_has_atpx_dgpu_power_cntl(void) { return false; }\nstatic inline bool radeon_is_atpx_hybrid(void) { return false; }\n#endif\n\n#define RADEON_PX_QUIRK_DISABLE_PX  (1 << 0)\n\nstruct radeon_px_quirk {\n\tu32 chip_vendor;\n\tu32 chip_device;\n\tu32 subsys_vendor;\n\tu32 subsys_device;\n\tu32 px_quirk_flags;\n};\n\nstatic struct radeon_px_quirk radeon_px_quirk_list[] = {\n\t \n\t{ PCI_VENDOR_ID_ATI, 0x6760, 0x1025, 0x0672, RADEON_PX_QUIRK_DISABLE_PX },\n\t \n\t{ PCI_VENDOR_ID_ATI, 0x6741, 0x1043, 0x108c, RADEON_PX_QUIRK_DISABLE_PX },\n\t \n\t{ PCI_VENDOR_ID_ATI, 0x6840, 0x1043, 0x2122, RADEON_PX_QUIRK_DISABLE_PX },\n\t \n\t{ PCI_VENDOR_ID_ATI, 0x6741, 0x1043, 0x2122, RADEON_PX_QUIRK_DISABLE_PX },\n\t \n\t{ PCI_VENDOR_ID_ATI, 0x6840, 0x1043, 0x2123, RADEON_PX_QUIRK_DISABLE_PX },\n\t{ 0, 0, 0, 0, 0 },\n};\n\nbool radeon_is_px(struct drm_device *dev)\n{\n\tstruct radeon_device *rdev = dev->dev_private;\n\n\tif (rdev->flags & RADEON_IS_PX)\n\t\treturn true;\n\treturn false;\n}\n\nstatic void radeon_device_handle_px_quirks(struct radeon_device *rdev)\n{\n\tstruct radeon_px_quirk *p = radeon_px_quirk_list;\n\n\t \n\twhile (p && p->chip_device != 0) {\n\t\tif (rdev->pdev->vendor == p->chip_vendor &&\n\t\t    rdev->pdev->device == p->chip_device &&\n\t\t    rdev->pdev->subsystem_vendor == p->subsys_vendor &&\n\t\t    rdev->pdev->subsystem_device == p->subsys_device) {\n\t\t\trdev->px_quirk_flags = p->px_quirk_flags;\n\t\t\tbreak;\n\t\t}\n\t\t++p;\n\t}\n\n\tif (rdev->px_quirk_flags & RADEON_PX_QUIRK_DISABLE_PX)\n\t\trdev->flags &= ~RADEON_IS_PX;\n\n\t \n\tif (!radeon_is_atpx_hybrid() &&\n\t    !radeon_has_atpx_dgpu_power_cntl())\n\t\trdev->flags &= ~RADEON_IS_PX;\n}\n\n \nvoid radeon_program_register_sequence(struct radeon_device *rdev,\n\t\t\t\t      const u32 *registers,\n\t\t\t\t      const u32 array_size)\n{\n\tu32 tmp, reg, and_mask, or_mask;\n\tint i;\n\n\tif (array_size % 3)\n\t\treturn;\n\n\tfor (i = 0; i < array_size; i +=3) {\n\t\treg = registers[i + 0];\n\t\tand_mask = registers[i + 1];\n\t\tor_mask = registers[i + 2];\n\n\t\tif (and_mask == 0xffffffff) {\n\t\t\ttmp = or_mask;\n\t\t} else {\n\t\t\ttmp = RREG32(reg);\n\t\t\ttmp &= ~and_mask;\n\t\t\ttmp |= or_mask;\n\t\t}\n\t\tWREG32(reg, tmp);\n\t}\n}\n\nvoid radeon_pci_config_reset(struct radeon_device *rdev)\n{\n\tpci_write_config_dword(rdev->pdev, 0x7c, RADEON_ASIC_RESET_DATA);\n}\n\n \nvoid radeon_surface_init(struct radeon_device *rdev)\n{\n\t \n\tif (rdev->family < CHIP_R600) {\n\t\tint i;\n\n\t\tfor (i = 0; i < RADEON_GEM_MAX_SURFACES; i++) {\n\t\t\tif (rdev->surface_regs[i].bo)\n\t\t\t\tradeon_bo_get_surface_reg(rdev->surface_regs[i].bo);\n\t\t\telse\n\t\t\t\tradeon_clear_surface_reg(rdev, i);\n\t\t}\n\t\t \n\t\tWREG32(RADEON_SURFACE_CNTL, 0);\n\t}\n}\n\n \n \nvoid radeon_scratch_init(struct radeon_device *rdev)\n{\n\tint i;\n\n\t \n\tif (rdev->family < CHIP_R300) {\n\t\trdev->scratch.num_reg = 5;\n\t} else {\n\t\trdev->scratch.num_reg = 7;\n\t}\n\trdev->scratch.reg_base = RADEON_SCRATCH_REG0;\n\tfor (i = 0; i < rdev->scratch.num_reg; i++) {\n\t\trdev->scratch.free[i] = true;\n\t\trdev->scratch.reg[i] = rdev->scratch.reg_base + (i * 4);\n\t}\n}\n\n \nint radeon_scratch_get(struct radeon_device *rdev, uint32_t *reg)\n{\n\tint i;\n\n\tfor (i = 0; i < rdev->scratch.num_reg; i++) {\n\t\tif (rdev->scratch.free[i]) {\n\t\t\trdev->scratch.free[i] = false;\n\t\t\t*reg = rdev->scratch.reg[i];\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}\n\n \nvoid radeon_scratch_free(struct radeon_device *rdev, uint32_t reg)\n{\n\tint i;\n\n\tfor (i = 0; i < rdev->scratch.num_reg; i++) {\n\t\tif (rdev->scratch.reg[i] == reg) {\n\t\t\trdev->scratch.free[i] = true;\n\t\t\treturn;\n\t\t}\n\t}\n}\n\n \n \nstatic int radeon_doorbell_init(struct radeon_device *rdev)\n{\n\t \n\trdev->doorbell.base = pci_resource_start(rdev->pdev, 2);\n\trdev->doorbell.size = pci_resource_len(rdev->pdev, 2);\n\n\trdev->doorbell.num_doorbells = min_t(u32, rdev->doorbell.size / sizeof(u32), RADEON_MAX_DOORBELLS);\n\tif (rdev->doorbell.num_doorbells == 0)\n\t\treturn -EINVAL;\n\n\trdev->doorbell.ptr = ioremap(rdev->doorbell.base, rdev->doorbell.num_doorbells * sizeof(u32));\n\tif (rdev->doorbell.ptr == NULL) {\n\t\treturn -ENOMEM;\n\t}\n\tDRM_INFO(\"doorbell mmio base: 0x%08X\\n\", (uint32_t)rdev->doorbell.base);\n\tDRM_INFO(\"doorbell mmio size: %u\\n\", (unsigned)rdev->doorbell.size);\n\n\tmemset(&rdev->doorbell.used, 0, sizeof(rdev->doorbell.used));\n\n\treturn 0;\n}\n\n \nstatic void radeon_doorbell_fini(struct radeon_device *rdev)\n{\n\tiounmap(rdev->doorbell.ptr);\n\trdev->doorbell.ptr = NULL;\n}\n\n \nint radeon_doorbell_get(struct radeon_device *rdev, u32 *doorbell)\n{\n\tunsigned long offset = find_first_zero_bit(rdev->doorbell.used, rdev->doorbell.num_doorbells);\n\tif (offset < rdev->doorbell.num_doorbells) {\n\t\t__set_bit(offset, rdev->doorbell.used);\n\t\t*doorbell = offset;\n\t\treturn 0;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n}\n\n \nvoid radeon_doorbell_free(struct radeon_device *rdev, u32 doorbell)\n{\n\tif (doorbell < rdev->doorbell.num_doorbells)\n\t\t__clear_bit(doorbell, rdev->doorbell.used);\n}\n\n \n\n \nvoid radeon_wb_disable(struct radeon_device *rdev)\n{\n\trdev->wb.enabled = false;\n}\n\n \nvoid radeon_wb_fini(struct radeon_device *rdev)\n{\n\tradeon_wb_disable(rdev);\n\tif (rdev->wb.wb_obj) {\n\t\tif (!radeon_bo_reserve(rdev->wb.wb_obj, false)) {\n\t\t\tradeon_bo_kunmap(rdev->wb.wb_obj);\n\t\t\tradeon_bo_unpin(rdev->wb.wb_obj);\n\t\t\tradeon_bo_unreserve(rdev->wb.wb_obj);\n\t\t}\n\t\tradeon_bo_unref(&rdev->wb.wb_obj);\n\t\trdev->wb.wb = NULL;\n\t\trdev->wb.wb_obj = NULL;\n\t}\n}\n\n \nint radeon_wb_init(struct radeon_device *rdev)\n{\n\tint r;\n\n\tif (rdev->wb.wb_obj == NULL) {\n\t\tr = radeon_bo_create(rdev, RADEON_GPU_PAGE_SIZE, PAGE_SIZE, true,\n\t\t\t\t     RADEON_GEM_DOMAIN_GTT, 0, NULL, NULL,\n\t\t\t\t     &rdev->wb.wb_obj);\n\t\tif (r) {\n\t\t\tdev_warn(rdev->dev, \"(%d) create WB bo failed\\n\", r);\n\t\t\treturn r;\n\t\t}\n\t\tr = radeon_bo_reserve(rdev->wb.wb_obj, false);\n\t\tif (unlikely(r != 0)) {\n\t\t\tradeon_wb_fini(rdev);\n\t\t\treturn r;\n\t\t}\n\t\tr = radeon_bo_pin(rdev->wb.wb_obj, RADEON_GEM_DOMAIN_GTT,\n\t\t\t\t&rdev->wb.gpu_addr);\n\t\tif (r) {\n\t\t\tradeon_bo_unreserve(rdev->wb.wb_obj);\n\t\t\tdev_warn(rdev->dev, \"(%d) pin WB bo failed\\n\", r);\n\t\t\tradeon_wb_fini(rdev);\n\t\t\treturn r;\n\t\t}\n\t\tr = radeon_bo_kmap(rdev->wb.wb_obj, (void **)&rdev->wb.wb);\n\t\tradeon_bo_unreserve(rdev->wb.wb_obj);\n\t\tif (r) {\n\t\t\tdev_warn(rdev->dev, \"(%d) map WB bo failed\\n\", r);\n\t\t\tradeon_wb_fini(rdev);\n\t\t\treturn r;\n\t\t}\n\t}\n\n\t \n\tmemset((char *)rdev->wb.wb, 0, RADEON_GPU_PAGE_SIZE);\n\t \n\trdev->wb.use_event = false;\n\t \n\tif (radeon_no_wb == 1) {\n\t\trdev->wb.enabled = false;\n\t} else {\n\t\tif (rdev->flags & RADEON_IS_AGP) {\n\t\t\t \n\t\t\trdev->wb.enabled = false;\n\t\t} else if (rdev->family < CHIP_R300) {\n\t\t\t \n\t\t\trdev->wb.enabled = false;\n\t\t} else {\n\t\t\trdev->wb.enabled = true;\n\t\t\t \n\t\t\tif (rdev->family >= CHIP_R600) {\n\t\t\t\trdev->wb.use_event = true;\n\t\t\t}\n\t\t}\n\t}\n\t \n\tif (rdev->family >= CHIP_PALM) {\n\t\trdev->wb.enabled = true;\n\t\trdev->wb.use_event = true;\n\t}\n\n\tdev_info(rdev->dev, \"WB %sabled\\n\", rdev->wb.enabled ? \"en\" : \"dis\");\n\n\treturn 0;\n}\n\n \nvoid radeon_vram_location(struct radeon_device *rdev, struct radeon_mc *mc, u64 base)\n{\n\tuint64_t limit = (uint64_t)radeon_vram_limit << 20;\n\n\tmc->vram_start = base;\n\tif (mc->mc_vram_size > (rdev->mc.mc_mask - base + 1)) {\n\t\tdev_warn(rdev->dev, \"limiting VRAM to PCI aperture size\\n\");\n\t\tmc->real_vram_size = mc->aper_size;\n\t\tmc->mc_vram_size = mc->aper_size;\n\t}\n\tmc->vram_end = mc->vram_start + mc->mc_vram_size - 1;\n\tif (rdev->flags & RADEON_IS_AGP && mc->vram_end > mc->gtt_start && mc->vram_start <= mc->gtt_end) {\n\t\tdev_warn(rdev->dev, \"limiting VRAM to PCI aperture size\\n\");\n\t\tmc->real_vram_size = mc->aper_size;\n\t\tmc->mc_vram_size = mc->aper_size;\n\t}\n\tmc->vram_end = mc->vram_start + mc->mc_vram_size - 1;\n\tif (limit && limit < mc->real_vram_size)\n\t\tmc->real_vram_size = limit;\n\tdev_info(rdev->dev, \"VRAM: %lluM 0x%016llX - 0x%016llX (%lluM used)\\n\",\n\t\t\tmc->mc_vram_size >> 20, mc->vram_start,\n\t\t\tmc->vram_end, mc->real_vram_size >> 20);\n}\n\n \nvoid radeon_gtt_location(struct radeon_device *rdev, struct radeon_mc *mc)\n{\n\tu64 size_af, size_bf;\n\n\tsize_af = ((rdev->mc.mc_mask - mc->vram_end) + mc->gtt_base_align) & ~mc->gtt_base_align;\n\tsize_bf = mc->vram_start & ~mc->gtt_base_align;\n\tif (size_bf > size_af) {\n\t\tif (mc->gtt_size > size_bf) {\n\t\t\tdev_warn(rdev->dev, \"limiting GTT\\n\");\n\t\t\tmc->gtt_size = size_bf;\n\t\t}\n\t\tmc->gtt_start = (mc->vram_start & ~mc->gtt_base_align) - mc->gtt_size;\n\t} else {\n\t\tif (mc->gtt_size > size_af) {\n\t\t\tdev_warn(rdev->dev, \"limiting GTT\\n\");\n\t\t\tmc->gtt_size = size_af;\n\t\t}\n\t\tmc->gtt_start = (mc->vram_end + 1 + mc->gtt_base_align) & ~mc->gtt_base_align;\n\t}\n\tmc->gtt_end = mc->gtt_start + mc->gtt_size - 1;\n\tdev_info(rdev->dev, \"GTT: %lluM 0x%016llX - 0x%016llX\\n\",\n\t\t\tmc->gtt_size >> 20, mc->gtt_start, mc->gtt_end);\n}\n\n \n\n \nbool radeon_device_is_virtual(void)\n{\n#ifdef CONFIG_X86\n\treturn boot_cpu_has(X86_FEATURE_HYPERVISOR);\n#else\n\treturn false;\n#endif\n}\n\n \nbool radeon_card_posted(struct radeon_device *rdev)\n{\n\tuint32_t reg;\n\n\t \n\tif (rdev->family >= CHIP_BONAIRE &&\n\t    radeon_device_is_virtual())\n\t\treturn false;\n\n\t \n\tif (efi_enabled(EFI_BOOT) &&\n\t    (rdev->pdev->subsystem_vendor == PCI_VENDOR_ID_APPLE) &&\n\t    (rdev->family < CHIP_R600))\n\t\treturn false;\n\n\tif (ASIC_IS_NODCE(rdev))\n\t\tgoto check_memsize;\n\n\t \n\tif (ASIC_IS_DCE4(rdev)) {\n\t\treg = RREG32(EVERGREEN_CRTC_CONTROL + EVERGREEN_CRTC0_REGISTER_OFFSET) |\n\t\t\tRREG32(EVERGREEN_CRTC_CONTROL + EVERGREEN_CRTC1_REGISTER_OFFSET);\n\t\t\tif (rdev->num_crtc >= 4) {\n\t\t\t\treg |= RREG32(EVERGREEN_CRTC_CONTROL + EVERGREEN_CRTC2_REGISTER_OFFSET) |\n\t\t\t\t\tRREG32(EVERGREEN_CRTC_CONTROL + EVERGREEN_CRTC3_REGISTER_OFFSET);\n\t\t\t}\n\t\t\tif (rdev->num_crtc >= 6) {\n\t\t\t\treg |= RREG32(EVERGREEN_CRTC_CONTROL + EVERGREEN_CRTC4_REGISTER_OFFSET) |\n\t\t\t\t\tRREG32(EVERGREEN_CRTC_CONTROL + EVERGREEN_CRTC5_REGISTER_OFFSET);\n\t\t\t}\n\t\tif (reg & EVERGREEN_CRTC_MASTER_EN)\n\t\t\treturn true;\n\t} else if (ASIC_IS_AVIVO(rdev)) {\n\t\treg = RREG32(AVIVO_D1CRTC_CONTROL) |\n\t\t      RREG32(AVIVO_D2CRTC_CONTROL);\n\t\tif (reg & AVIVO_CRTC_EN) {\n\t\t\treturn true;\n\t\t}\n\t} else {\n\t\treg = RREG32(RADEON_CRTC_GEN_CNTL) |\n\t\t      RREG32(RADEON_CRTC2_GEN_CNTL);\n\t\tif (reg & RADEON_CRTC_EN) {\n\t\t\treturn true;\n\t\t}\n\t}\n\ncheck_memsize:\n\t \n\tif (rdev->family >= CHIP_R600)\n\t\treg = RREG32(R600_CONFIG_MEMSIZE);\n\telse\n\t\treg = RREG32(RADEON_CONFIG_MEMSIZE);\n\n\tif (reg)\n\t\treturn true;\n\n\treturn false;\n\n}\n\n \nvoid radeon_update_bandwidth_info(struct radeon_device *rdev)\n{\n\tfixed20_12 a;\n\tu32 sclk = rdev->pm.current_sclk;\n\tu32 mclk = rdev->pm.current_mclk;\n\n\t \n\ta.full = dfixed_const(100);\n\trdev->pm.sclk.full = dfixed_const(sclk);\n\trdev->pm.sclk.full = dfixed_div(rdev->pm.sclk, a);\n\trdev->pm.mclk.full = dfixed_const(mclk);\n\trdev->pm.mclk.full = dfixed_div(rdev->pm.mclk, a);\n\n\tif (rdev->flags & RADEON_IS_IGP) {\n\t\ta.full = dfixed_const(16);\n\t\t \n\t\trdev->pm.core_bandwidth.full = dfixed_div(rdev->pm.sclk, a);\n\t}\n}\n\n \nbool radeon_boot_test_post_card(struct radeon_device *rdev)\n{\n\tif (radeon_card_posted(rdev))\n\t\treturn true;\n\n\tif (rdev->bios) {\n\t\tDRM_INFO(\"GPU not posted. posting now...\\n\");\n\t\tif (rdev->is_atom_bios)\n\t\t\tatom_asic_init(rdev->mode_info.atom_context);\n\t\telse\n\t\t\tradeon_combios_asic_init(rdev->ddev);\n\t\treturn true;\n\t} else {\n\t\tdev_err(rdev->dev, \"Card not posted and no BIOS - ignoring\\n\");\n\t\treturn false;\n\t}\n}\n\n \nint radeon_dummy_page_init(struct radeon_device *rdev)\n{\n\tif (rdev->dummy_page.page)\n\t\treturn 0;\n\trdev->dummy_page.page = alloc_page(GFP_DMA32 | GFP_KERNEL | __GFP_ZERO);\n\tif (rdev->dummy_page.page == NULL)\n\t\treturn -ENOMEM;\n\trdev->dummy_page.addr = dma_map_page(&rdev->pdev->dev, rdev->dummy_page.page,\n\t\t\t\t\t0, PAGE_SIZE, DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(&rdev->pdev->dev, rdev->dummy_page.addr)) {\n\t\tdev_err(&rdev->pdev->dev, \"Failed to DMA MAP the dummy page\\n\");\n\t\t__free_page(rdev->dummy_page.page);\n\t\trdev->dummy_page.page = NULL;\n\t\treturn -ENOMEM;\n\t}\n\trdev->dummy_page.entry = radeon_gart_get_page_entry(rdev->dummy_page.addr,\n\t\t\t\t\t\t\t    RADEON_GART_PAGE_DUMMY);\n\treturn 0;\n}\n\n \nvoid radeon_dummy_page_fini(struct radeon_device *rdev)\n{\n\tif (rdev->dummy_page.page == NULL)\n\t\treturn;\n\tdma_unmap_page(&rdev->pdev->dev, rdev->dummy_page.addr, PAGE_SIZE,\n\t\t       DMA_BIDIRECTIONAL);\n\t__free_page(rdev->dummy_page.page);\n\trdev->dummy_page.page = NULL;\n}\n\n\n \n \n\n \nstatic uint32_t cail_pll_read(struct card_info *info, uint32_t reg)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\tuint32_t r;\n\n\tr = rdev->pll_rreg(rdev, reg);\n\treturn r;\n}\n\n \nstatic void cail_pll_write(struct card_info *info, uint32_t reg, uint32_t val)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\n\trdev->pll_wreg(rdev, reg, val);\n}\n\n \nstatic uint32_t cail_mc_read(struct card_info *info, uint32_t reg)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\tuint32_t r;\n\n\tr = rdev->mc_rreg(rdev, reg);\n\treturn r;\n}\n\n \nstatic void cail_mc_write(struct card_info *info, uint32_t reg, uint32_t val)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\n\trdev->mc_wreg(rdev, reg, val);\n}\n\n \nstatic void cail_reg_write(struct card_info *info, uint32_t reg, uint32_t val)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\n\tWREG32(reg*4, val);\n}\n\n \nstatic uint32_t cail_reg_read(struct card_info *info, uint32_t reg)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\tuint32_t r;\n\n\tr = RREG32(reg*4);\n\treturn r;\n}\n\n \nstatic void cail_ioreg_write(struct card_info *info, uint32_t reg, uint32_t val)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\n\tWREG32_IO(reg*4, val);\n}\n\n \nstatic uint32_t cail_ioreg_read(struct card_info *info, uint32_t reg)\n{\n\tstruct radeon_device *rdev = info->dev->dev_private;\n\tuint32_t r;\n\n\tr = RREG32_IO(reg*4);\n\treturn r;\n}\n\n \nint radeon_atombios_init(struct radeon_device *rdev)\n{\n\tstruct card_info *atom_card_info =\n\t    kzalloc(sizeof(struct card_info), GFP_KERNEL);\n\n\tif (!atom_card_info)\n\t\treturn -ENOMEM;\n\n\trdev->mode_info.atom_card_info = atom_card_info;\n\tatom_card_info->dev = rdev->ddev;\n\tatom_card_info->reg_read = cail_reg_read;\n\tatom_card_info->reg_write = cail_reg_write;\n\t \n\tif (rdev->rio_mem) {\n\t\tatom_card_info->ioreg_read = cail_ioreg_read;\n\t\tatom_card_info->ioreg_write = cail_ioreg_write;\n\t} else {\n\t\tDRM_ERROR(\"Unable to find PCI I/O BAR; using MMIO for ATOM IIO\\n\");\n\t\tatom_card_info->ioreg_read = cail_reg_read;\n\t\tatom_card_info->ioreg_write = cail_reg_write;\n\t}\n\tatom_card_info->mc_read = cail_mc_read;\n\tatom_card_info->mc_write = cail_mc_write;\n\tatom_card_info->pll_read = cail_pll_read;\n\tatom_card_info->pll_write = cail_pll_write;\n\n\trdev->mode_info.atom_context = atom_parse(atom_card_info, rdev->bios);\n\tif (!rdev->mode_info.atom_context) {\n\t\tradeon_atombios_fini(rdev);\n\t\treturn -ENOMEM;\n\t}\n\n\tmutex_init(&rdev->mode_info.atom_context->mutex);\n\tmutex_init(&rdev->mode_info.atom_context->scratch_mutex);\n\tradeon_atom_initialize_bios_scratch_regs(rdev->ddev);\n\tatom_allocate_fb_scratch(rdev->mode_info.atom_context);\n\treturn 0;\n}\n\n \nvoid radeon_atombios_fini(struct radeon_device *rdev)\n{\n\tif (rdev->mode_info.atom_context) {\n\t\tkfree(rdev->mode_info.atom_context->scratch);\n\t\tkfree(rdev->mode_info.atom_context->iio);\n\t}\n\tkfree(rdev->mode_info.atom_context);\n\trdev->mode_info.atom_context = NULL;\n\tkfree(rdev->mode_info.atom_card_info);\n\trdev->mode_info.atom_card_info = NULL;\n}\n\n \n \n\n \nint radeon_combios_init(struct radeon_device *rdev)\n{\n\tradeon_combios_initialize_bios_scratch_regs(rdev->ddev);\n\treturn 0;\n}\n\n \nvoid radeon_combios_fini(struct radeon_device *rdev)\n{\n}\n\n \n \nstatic unsigned int radeon_vga_set_decode(struct pci_dev *pdev, bool state)\n{\n\tstruct drm_device *dev = pci_get_drvdata(pdev);\n\tstruct radeon_device *rdev = dev->dev_private;\n\tradeon_vga_set_state(rdev, state);\n\tif (state)\n\t\treturn VGA_RSRC_LEGACY_IO | VGA_RSRC_LEGACY_MEM |\n\t\t       VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM;\n\telse\n\t\treturn VGA_RSRC_NORMAL_IO | VGA_RSRC_NORMAL_MEM;\n}\n\n \nstatic int radeon_gart_size_auto(enum radeon_family family)\n{\n\t \n\tif (family >= CHIP_TAHITI)\n\t\treturn 2048;\n\telse if (family >= CHIP_RV770)\n\t\treturn 1024;\n\telse\n\t\treturn 512;\n}\n\n \nstatic void radeon_check_arguments(struct radeon_device *rdev)\n{\n\t \n\tif (radeon_vram_limit != 0 && !is_power_of_2(radeon_vram_limit)) {\n\t\tdev_warn(rdev->dev, \"vram limit (%d) must be a power of 2\\n\",\n\t\t\t\tradeon_vram_limit);\n\t\tradeon_vram_limit = 0;\n\t}\n\n\tif (radeon_gart_size == -1) {\n\t\tradeon_gart_size = radeon_gart_size_auto(rdev->family);\n\t}\n\t \n\tif (radeon_gart_size < 32) {\n\t\tdev_warn(rdev->dev, \"gart size (%d) too small\\n\",\n\t\t\t\tradeon_gart_size);\n\t\tradeon_gart_size = radeon_gart_size_auto(rdev->family);\n\t} else if (!is_power_of_2(radeon_gart_size)) {\n\t\tdev_warn(rdev->dev, \"gart size (%d) must be a power of 2\\n\",\n\t\t\t\tradeon_gart_size);\n\t\tradeon_gart_size = radeon_gart_size_auto(rdev->family);\n\t}\n\trdev->mc.gtt_size = (uint64_t)radeon_gart_size << 20;\n\n\t \n\tswitch (radeon_agpmode) {\n\tcase -1:\n\tcase 0:\n\tcase 1:\n\tcase 2:\n\tcase 4:\n\tcase 8:\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(rdev->dev, \"invalid AGP mode %d (valid mode: \"\n\t\t\t\t\"-1, 0, 1, 2, 4, 8)\\n\", radeon_agpmode);\n\t\tradeon_agpmode = 0;\n\t\tbreak;\n\t}\n\n\tif (!is_power_of_2(radeon_vm_size)) {\n\t\tdev_warn(rdev->dev, \"VM size (%d) must be a power of 2\\n\",\n\t\t\t radeon_vm_size);\n\t\tradeon_vm_size = 4;\n\t}\n\n\tif (radeon_vm_size < 1) {\n\t\tdev_warn(rdev->dev, \"VM size (%d) too small, min is 1GB\\n\",\n\t\t\t radeon_vm_size);\n\t\tradeon_vm_size = 4;\n\t}\n\n\t \n\tif (radeon_vm_size > 1024) {\n\t\tdev_warn(rdev->dev, \"VM size (%d) too large, max is 1TB\\n\",\n\t\t\t radeon_vm_size);\n\t\tradeon_vm_size = 4;\n\t}\n\n\t \n\tif (radeon_vm_block_size == -1) {\n\n\t\t \n\t\tunsigned bits = ilog2(radeon_vm_size) + 18;\n\n\t\t \n\t\tif (radeon_vm_size <= 8)\n\t\t\tradeon_vm_block_size = bits - 9;\n\t\telse\n\t\t\tradeon_vm_block_size = (bits + 3) / 2;\n\n\t} else if (radeon_vm_block_size < 9) {\n\t\tdev_warn(rdev->dev, \"VM page table size (%d) too small\\n\",\n\t\t\t radeon_vm_block_size);\n\t\tradeon_vm_block_size = 9;\n\t}\n\n\tif (radeon_vm_block_size > 24 ||\n\t    (radeon_vm_size * 1024) < (1ull << radeon_vm_block_size)) {\n\t\tdev_warn(rdev->dev, \"VM page table size (%d) too large\\n\",\n\t\t\t radeon_vm_block_size);\n\t\tradeon_vm_block_size = 9;\n\t}\n}\n\n \nstatic void radeon_switcheroo_set_state(struct pci_dev *pdev, enum vga_switcheroo_state state)\n{\n\tstruct drm_device *dev = pci_get_drvdata(pdev);\n\n\tif (radeon_is_px(dev) && state == VGA_SWITCHEROO_OFF)\n\t\treturn;\n\n\tif (state == VGA_SWITCHEROO_ON) {\n\t\tpr_info(\"radeon: switched on\\n\");\n\t\t \n\t\tdev->switch_power_state = DRM_SWITCH_POWER_CHANGING;\n\n\t\tradeon_resume_kms(dev, true, true);\n\n\t\tdev->switch_power_state = DRM_SWITCH_POWER_ON;\n\t\tdrm_kms_helper_poll_enable(dev);\n\t} else {\n\t\tpr_info(\"radeon: switched off\\n\");\n\t\tdrm_kms_helper_poll_disable(dev);\n\t\tdev->switch_power_state = DRM_SWITCH_POWER_CHANGING;\n\t\tradeon_suspend_kms(dev, true, true, false);\n\t\tdev->switch_power_state = DRM_SWITCH_POWER_OFF;\n\t}\n}\n\n \nstatic bool radeon_switcheroo_can_switch(struct pci_dev *pdev)\n{\n\tstruct drm_device *dev = pci_get_drvdata(pdev);\n\n\t \n\treturn atomic_read(&dev->open_count) == 0;\n}\n\nstatic const struct vga_switcheroo_client_ops radeon_switcheroo_ops = {\n\t.set_gpu_state = radeon_switcheroo_set_state,\n\t.reprobe = NULL,\n\t.can_switch = radeon_switcheroo_can_switch,\n};\n\n \nint radeon_device_init(struct radeon_device *rdev,\n\t\t       struct drm_device *ddev,\n\t\t       struct pci_dev *pdev,\n\t\t       uint32_t flags)\n{\n\tint r, i;\n\tint dma_bits;\n\tbool runtime = false;\n\n\trdev->shutdown = false;\n\trdev->dev = &pdev->dev;\n\trdev->ddev = ddev;\n\trdev->pdev = pdev;\n\trdev->flags = flags;\n\trdev->family = flags & RADEON_FAMILY_MASK;\n\trdev->is_atom_bios = false;\n\trdev->usec_timeout = RADEON_MAX_USEC_TIMEOUT;\n\trdev->mc.gtt_size = 512 * 1024 * 1024;\n\trdev->accel_working = false;\n\t \n\tfor (i = 0; i < RADEON_NUM_RINGS; i++) {\n\t\trdev->ring[i].idx = i;\n\t}\n\trdev->fence_context = dma_fence_context_alloc(RADEON_NUM_RINGS);\n\n\tDRM_INFO(\"initializing kernel modesetting (%s 0x%04X:0x%04X 0x%04X:0x%04X 0x%02X).\\n\",\n\t\t radeon_family_name[rdev->family], pdev->vendor, pdev->device,\n\t\t pdev->subsystem_vendor, pdev->subsystem_device, pdev->revision);\n\n\t \n\tmutex_init(&rdev->ring_lock);\n\tmutex_init(&rdev->dc_hw_i2c_mutex);\n\tatomic_set(&rdev->ih.lock, 0);\n\tmutex_init(&rdev->gem.mutex);\n\tmutex_init(&rdev->pm.mutex);\n\tmutex_init(&rdev->gpu_clock_mutex);\n\tmutex_init(&rdev->srbm_mutex);\n\tmutex_init(&rdev->audio.component_mutex);\n\tinit_rwsem(&rdev->pm.mclk_lock);\n\tinit_rwsem(&rdev->exclusive_lock);\n\tinit_waitqueue_head(&rdev->irq.vblank_queue);\n\tr = radeon_gem_init(rdev);\n\tif (r)\n\t\treturn r;\n\n\tradeon_check_arguments(rdev);\n\t \n\trdev->vm_manager.max_pfn = radeon_vm_size << 18;\n\n\t \n\tr = radeon_asic_init(rdev);\n\tif (r)\n\t\treturn r;\n\n\t \n\tif ((rdev->family >= CHIP_RS400) &&\n\t    (rdev->flags & RADEON_IS_IGP)) {\n\t\trdev->flags &= ~RADEON_IS_AGP;\n\t}\n\n\tif (rdev->flags & RADEON_IS_AGP && radeon_agpmode == -1) {\n\t\tradeon_agp_disable(rdev);\n\t}\n\n\t \n\tif (rdev->family >= CHIP_CAYMAN)\n\t\trdev->mc.mc_mask = 0xffffffffffULL;  \n\telse if (rdev->family >= CHIP_CEDAR)\n\t\trdev->mc.mc_mask = 0xfffffffffULL;  \n\telse\n\t\trdev->mc.mc_mask = 0xffffffffULL;  \n\n\t \n\tdma_bits = 40;\n\tif (rdev->flags & RADEON_IS_AGP)\n\t\tdma_bits = 32;\n\tif ((rdev->flags & RADEON_IS_PCI) &&\n\t    (rdev->family <= CHIP_RS740))\n\t\tdma_bits = 32;\n#ifdef CONFIG_PPC64\n\tif (rdev->family == CHIP_CEDAR)\n\t\tdma_bits = 32;\n#endif\n\n\tr = dma_set_mask_and_coherent(&rdev->pdev->dev, DMA_BIT_MASK(dma_bits));\n\tif (r) {\n\t\tpr_warn(\"radeon: No suitable DMA available\\n\");\n\t\treturn r;\n\t}\n\trdev->need_swiotlb = drm_need_swiotlb(dma_bits);\n\n\t \n\t \n\tspin_lock_init(&rdev->mmio_idx_lock);\n\tspin_lock_init(&rdev->smc_idx_lock);\n\tspin_lock_init(&rdev->pll_idx_lock);\n\tspin_lock_init(&rdev->mc_idx_lock);\n\tspin_lock_init(&rdev->pcie_idx_lock);\n\tspin_lock_init(&rdev->pciep_idx_lock);\n\tspin_lock_init(&rdev->pif_idx_lock);\n\tspin_lock_init(&rdev->cg_idx_lock);\n\tspin_lock_init(&rdev->uvd_idx_lock);\n\tspin_lock_init(&rdev->rcu_idx_lock);\n\tspin_lock_init(&rdev->didt_idx_lock);\n\tspin_lock_init(&rdev->end_idx_lock);\n\tif (rdev->family >= CHIP_BONAIRE) {\n\t\trdev->rmmio_base = pci_resource_start(rdev->pdev, 5);\n\t\trdev->rmmio_size = pci_resource_len(rdev->pdev, 5);\n\t} else {\n\t\trdev->rmmio_base = pci_resource_start(rdev->pdev, 2);\n\t\trdev->rmmio_size = pci_resource_len(rdev->pdev, 2);\n\t}\n\trdev->rmmio = ioremap(rdev->rmmio_base, rdev->rmmio_size);\n\tif (rdev->rmmio == NULL)\n\t\treturn -ENOMEM;\n\n\t \n\tif (rdev->family >= CHIP_BONAIRE)\n\t\tradeon_doorbell_init(rdev);\n\n\t \n\tfor (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {\n\t\tif (pci_resource_flags(rdev->pdev, i) & IORESOURCE_IO) {\n\t\t\trdev->rio_mem_size = pci_resource_len(rdev->pdev, i);\n\t\t\trdev->rio_mem = pci_iomap(rdev->pdev, i, rdev->rio_mem_size);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (rdev->rio_mem == NULL)\n\t\tDRM_ERROR(\"Unable to find PCI I/O BAR\\n\");\n\n\tif (rdev->flags & RADEON_IS_PX)\n\t\tradeon_device_handle_px_quirks(rdev);\n\n\t \n\t \n\tvga_client_register(rdev->pdev, radeon_vga_set_decode);\n\n\tif (rdev->flags & RADEON_IS_PX)\n\t\truntime = true;\n\tif (!pci_is_thunderbolt_attached(rdev->pdev))\n\t\tvga_switcheroo_register_client(rdev->pdev,\n\t\t\t\t\t       &radeon_switcheroo_ops, runtime);\n\tif (runtime)\n\t\tvga_switcheroo_init_domain_pm_ops(rdev->dev, &rdev->vga_pm_domain);\n\n\tr = radeon_init(rdev);\n\tif (r)\n\t\tgoto failed;\n\n\tradeon_gem_debugfs_init(rdev);\n\n\tif (rdev->flags & RADEON_IS_AGP && !rdev->accel_working) {\n\t\t \n\t\tradeon_asic_reset(rdev);\n\t\tradeon_fini(rdev);\n\t\tradeon_agp_disable(rdev);\n\t\tr = radeon_init(rdev);\n\t\tif (r)\n\t\t\tgoto failed;\n\t}\n\n\tradeon_audio_component_init(rdev);\n\n\tr = radeon_ib_ring_tests(rdev);\n\tif (r)\n\t\tDRM_ERROR(\"ib ring test failed (%d).\\n\", r);\n\n\t \n\tif (rdev->pm.dpm_enabled &&\n\t    (rdev->pm.pm_method == PM_METHOD_DPM) &&\n\t    (rdev->family == CHIP_TURKS) &&\n\t    (rdev->flags & RADEON_IS_MOBILITY)) {\n\t\tmutex_lock(&rdev->pm.mutex);\n\t\tradeon_dpm_disable(rdev);\n\t\tradeon_dpm_enable(rdev);\n\t\tmutex_unlock(&rdev->pm.mutex);\n\t}\n\n\tif ((radeon_testing & 1)) {\n\t\tif (rdev->accel_working)\n\t\t\tradeon_test_moves(rdev);\n\t\telse\n\t\t\tDRM_INFO(\"radeon: acceleration disabled, skipping move tests\\n\");\n\t}\n\tif ((radeon_testing & 2)) {\n\t\tif (rdev->accel_working)\n\t\t\tradeon_test_syncing(rdev);\n\t\telse\n\t\t\tDRM_INFO(\"radeon: acceleration disabled, skipping sync tests\\n\");\n\t}\n\tif (radeon_benchmarking) {\n\t\tif (rdev->accel_working)\n\t\t\tradeon_benchmark(rdev, radeon_benchmarking);\n\t\telse\n\t\t\tDRM_INFO(\"radeon: acceleration disabled, skipping benchmarks\\n\");\n\t}\n\treturn 0;\n\nfailed:\n\t \n\tif (radeon_is_px(ddev))\n\t\tpm_runtime_put_noidle(ddev->dev);\n\tif (runtime)\n\t\tvga_switcheroo_fini_domain_pm_ops(rdev->dev);\n\treturn r;\n}\n\n \nvoid radeon_device_fini(struct radeon_device *rdev)\n{\n\tDRM_INFO(\"radeon: finishing device.\\n\");\n\trdev->shutdown = true;\n\t \n\tradeon_bo_evict_vram(rdev);\n\tradeon_audio_component_fini(rdev);\n\tradeon_fini(rdev);\n\tif (!pci_is_thunderbolt_attached(rdev->pdev))\n\t\tvga_switcheroo_unregister_client(rdev->pdev);\n\tif (rdev->flags & RADEON_IS_PX)\n\t\tvga_switcheroo_fini_domain_pm_ops(rdev->dev);\n\tvga_client_unregister(rdev->pdev);\n\tif (rdev->rio_mem)\n\t\tpci_iounmap(rdev->pdev, rdev->rio_mem);\n\trdev->rio_mem = NULL;\n\tiounmap(rdev->rmmio);\n\trdev->rmmio = NULL;\n\tif (rdev->family >= CHIP_BONAIRE)\n\t\tradeon_doorbell_fini(rdev);\n}\n\n\n \n \nint radeon_suspend_kms(struct drm_device *dev, bool suspend,\n\t\t       bool fbcon, bool freeze)\n{\n\tstruct radeon_device *rdev;\n\tstruct pci_dev *pdev;\n\tstruct drm_crtc *crtc;\n\tstruct drm_connector *connector;\n\tint i, r;\n\n\tif (dev == NULL || dev->dev_private == NULL) {\n\t\treturn -ENODEV;\n\t}\n\n\trdev = dev->dev_private;\n\tpdev = to_pci_dev(dev->dev);\n\n\tif (dev->switch_power_state == DRM_SWITCH_POWER_OFF)\n\t\treturn 0;\n\n\tdrm_kms_helper_poll_disable(dev);\n\n\tdrm_modeset_lock_all(dev);\n\t \n\tlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\n\t\tdrm_helper_connector_dpms(connector, DRM_MODE_DPMS_OFF);\n\t}\n\tdrm_modeset_unlock_all(dev);\n\n\t \n\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\tstruct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);\n\t\tstruct drm_framebuffer *fb = crtc->primary->fb;\n\t\tstruct radeon_bo *robj;\n\n\t\tif (radeon_crtc->cursor_bo) {\n\t\t\tstruct radeon_bo *robj = gem_to_radeon_bo(radeon_crtc->cursor_bo);\n\t\t\tr = radeon_bo_reserve(robj, false);\n\t\t\tif (r == 0) {\n\t\t\t\tradeon_bo_unpin(robj);\n\t\t\t\tradeon_bo_unreserve(robj);\n\t\t\t}\n\t\t}\n\n\t\tif (fb == NULL || fb->obj[0] == NULL) {\n\t\t\tcontinue;\n\t\t}\n\t\trobj = gem_to_radeon_bo(fb->obj[0]);\n\t\t \n\t\tif (!radeon_fbdev_robj_is_fb(rdev, robj)) {\n\t\t\tr = radeon_bo_reserve(robj, false);\n\t\t\tif (r == 0) {\n\t\t\t\tradeon_bo_unpin(robj);\n\t\t\t\tradeon_bo_unreserve(robj);\n\t\t\t}\n\t\t}\n\t}\n\t \n\tradeon_bo_evict_vram(rdev);\n\n\t \n\tfor (i = 0; i < RADEON_NUM_RINGS; i++) {\n\t\tr = radeon_fence_wait_empty(rdev, i);\n\t\tif (r) {\n\t\t\t \n\t\t\tradeon_fence_driver_force_completion(rdev, i);\n\t\t} else {\n\t\t\t \n\t\t\tflush_delayed_work(&rdev->fence_drv[i].lockup_work);\n\t\t}\n\t}\n\n\tradeon_save_bios_scratch_regs(rdev);\n\n\tradeon_suspend(rdev);\n\tradeon_hpd_fini(rdev);\n\t \n\tradeon_bo_evict_vram(rdev);\n\n\tradeon_agp_suspend(rdev);\n\n\tpci_save_state(pdev);\n\tif (freeze && rdev->family >= CHIP_CEDAR && !(rdev->flags & RADEON_IS_IGP)) {\n\t\trdev->asic->asic_reset(rdev, true);\n\t\tpci_restore_state(pdev);\n\t} else if (suspend) {\n\t\t \n\t\tpci_disable_device(pdev);\n\t\tpci_set_power_state(pdev, PCI_D3hot);\n\t}\n\n\tif (fbcon) {\n\t\tconsole_lock();\n\t\tradeon_fbdev_set_suspend(rdev, 1);\n\t\tconsole_unlock();\n\t}\n\treturn 0;\n}\n\n \nint radeon_resume_kms(struct drm_device *dev, bool resume, bool fbcon)\n{\n\tstruct drm_connector *connector;\n\tstruct radeon_device *rdev = dev->dev_private;\n\tstruct pci_dev *pdev = to_pci_dev(dev->dev);\n\tstruct drm_crtc *crtc;\n\tint r;\n\n\tif (dev->switch_power_state == DRM_SWITCH_POWER_OFF)\n\t\treturn 0;\n\n\tif (fbcon) {\n\t\tconsole_lock();\n\t}\n\tif (resume) {\n\t\tpci_set_power_state(pdev, PCI_D0);\n\t\tpci_restore_state(pdev);\n\t\tif (pci_enable_device(pdev)) {\n\t\t\tif (fbcon)\n\t\t\t\tconsole_unlock();\n\t\t\treturn -1;\n\t\t}\n\t}\n\t \n\tradeon_agp_resume(rdev);\n\tradeon_resume(rdev);\n\n\tr = radeon_ib_ring_tests(rdev);\n\tif (r)\n\t\tDRM_ERROR(\"ib ring test failed (%d).\\n\", r);\n\n\tif ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled) {\n\t\t \n\t\tr = radeon_pm_late_init(rdev);\n\t\tif (r) {\n\t\t\trdev->pm.dpm_enabled = false;\n\t\t\tDRM_ERROR(\"radeon_pm_late_init failed, disabling dpm\\n\");\n\t\t}\n\t} else {\n\t\t \n\t\tradeon_pm_resume(rdev);\n\t}\n\n\tradeon_restore_bios_scratch_regs(rdev);\n\n\t \n\tlist_for_each_entry(crtc, &dev->mode_config.crtc_list, head) {\n\t\tstruct radeon_crtc *radeon_crtc = to_radeon_crtc(crtc);\n\n\t\tif (radeon_crtc->cursor_bo) {\n\t\t\tstruct radeon_bo *robj = gem_to_radeon_bo(radeon_crtc->cursor_bo);\n\t\t\tr = radeon_bo_reserve(robj, false);\n\t\t\tif (r == 0) {\n\t\t\t\t \n\t\t\t\tr = radeon_bo_pin_restricted(robj,\n\t\t\t\t\t\t\t     RADEON_GEM_DOMAIN_VRAM,\n\t\t\t\t\t\t\t     ASIC_IS_AVIVO(rdev) ?\n\t\t\t\t\t\t\t     0 : 1 << 27,\n\t\t\t\t\t\t\t     &radeon_crtc->cursor_addr);\n\t\t\t\tif (r != 0)\n\t\t\t\t\tDRM_ERROR(\"Failed to pin cursor BO (%d)\\n\", r);\n\t\t\t\tradeon_bo_unreserve(robj);\n\t\t\t}\n\t\t}\n\t}\n\n\t \n\tif (rdev->is_atom_bios) {\n\t\tradeon_atom_encoder_init(rdev);\n\t\tradeon_atom_disp_eng_pll_init(rdev);\n\t\t \n\t\tif (rdev->mode_info.bl_encoder) {\n\t\t\tu8 bl_level = radeon_get_backlight_level(rdev,\n\t\t\t\t\t\t\t\t rdev->mode_info.bl_encoder);\n\t\t\tradeon_set_backlight_level(rdev, rdev->mode_info.bl_encoder,\n\t\t\t\t\t\t   bl_level);\n\t\t}\n\t}\n\t \n\tradeon_hpd_init(rdev);\n\t \n\tif (fbcon) {\n\t\tdrm_helper_resume_force_mode(dev);\n\t\t \n\t\tdrm_modeset_lock_all(dev);\n\t\tlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\n\t\t\tdrm_helper_connector_dpms(connector, DRM_MODE_DPMS_ON);\n\t\t}\n\t\tdrm_modeset_unlock_all(dev);\n\t}\n\n\tdrm_kms_helper_poll_enable(dev);\n\n\t \n\tif ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled)\n\t\tradeon_pm_compute_clocks(rdev);\n\n\tif (fbcon) {\n\t\tradeon_fbdev_set_suspend(rdev, 0);\n\t\tconsole_unlock();\n\t}\n\n\treturn 0;\n}\n\n \nint radeon_gpu_reset(struct radeon_device *rdev)\n{\n\tunsigned ring_sizes[RADEON_NUM_RINGS];\n\tuint32_t *ring_data[RADEON_NUM_RINGS];\n\n\tbool saved = false;\n\n\tint i, r;\n\n\tdown_write(&rdev->exclusive_lock);\n\n\tif (!rdev->needs_reset) {\n\t\tup_write(&rdev->exclusive_lock);\n\t\treturn 0;\n\t}\n\n\tatomic_inc(&rdev->gpu_reset_counter);\n\n\tradeon_save_bios_scratch_regs(rdev);\n\tradeon_suspend(rdev);\n\tradeon_hpd_fini(rdev);\n\n\tfor (i = 0; i < RADEON_NUM_RINGS; ++i) {\n\t\tring_sizes[i] = radeon_ring_backup(rdev, &rdev->ring[i],\n\t\t\t\t\t\t   &ring_data[i]);\n\t\tif (ring_sizes[i]) {\n\t\t\tsaved = true;\n\t\t\tdev_info(rdev->dev, \"Saved %d dwords of commands \"\n\t\t\t\t \"on ring %d.\\n\", ring_sizes[i], i);\n\t\t}\n\t}\n\n\tr = radeon_asic_reset(rdev);\n\tif (!r) {\n\t\tdev_info(rdev->dev, \"GPU reset succeeded, trying to resume\\n\");\n\t\tradeon_resume(rdev);\n\t}\n\n\tradeon_restore_bios_scratch_regs(rdev);\n\n\tfor (i = 0; i < RADEON_NUM_RINGS; ++i) {\n\t\tif (!r && ring_data[i]) {\n\t\t\tradeon_ring_restore(rdev, &rdev->ring[i],\n\t\t\t\t\t    ring_sizes[i], ring_data[i]);\n\t\t} else {\n\t\t\tradeon_fence_driver_force_completion(rdev, i);\n\t\t\tkfree(ring_data[i]);\n\t\t}\n\t}\n\n\tif ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled) {\n\t\t \n\t\tr = radeon_pm_late_init(rdev);\n\t\tif (r) {\n\t\t\trdev->pm.dpm_enabled = false;\n\t\t\tDRM_ERROR(\"radeon_pm_late_init failed, disabling dpm\\n\");\n\t\t}\n\t} else {\n\t\t \n\t\tradeon_pm_resume(rdev);\n\t}\n\n\t \n\tif (rdev->is_atom_bios) {\n\t\tradeon_atom_encoder_init(rdev);\n\t\tradeon_atom_disp_eng_pll_init(rdev);\n\t\t \n\t\tif (rdev->mode_info.bl_encoder) {\n\t\t\tu8 bl_level = radeon_get_backlight_level(rdev,\n\t\t\t\t\t\t\t\t rdev->mode_info.bl_encoder);\n\t\t\tradeon_set_backlight_level(rdev, rdev->mode_info.bl_encoder,\n\t\t\t\t\t\t   bl_level);\n\t\t}\n\t}\n\t \n\tradeon_hpd_init(rdev);\n\n\trdev->in_reset = true;\n\trdev->needs_reset = false;\n\n\tdowngrade_write(&rdev->exclusive_lock);\n\n\tdrm_helper_resume_force_mode(rdev->ddev);\n\n\t \n\tif ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled)\n\t\tradeon_pm_compute_clocks(rdev);\n\n\tif (!r) {\n\t\tr = radeon_ib_ring_tests(rdev);\n\t\tif (r && saved)\n\t\t\tr = -EAGAIN;\n\t} else {\n\t\t \n\t\tdev_info(rdev->dev, \"GPU reset failed\\n\");\n\t}\n\n\trdev->needs_reset = r == -EAGAIN;\n\trdev->in_reset = false;\n\n\tup_read(&rdev->exclusive_lock);\n\treturn r;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}