{
  "module_name": "xen_drm_front.c",
  "hash_id": "03cfdd3c18a0f734688dfd9459c7021db5c53b588e710bbd2e94c8f0f48105b4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/xen/xen_drm_front.c",
  "human_readable_source": "\n\n \n\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/module.h>\n\n#include <drm/drm_atomic_helper.h>\n#include <drm/drm_drv.h>\n#include <drm/drm_ioctl.h>\n#include <drm/drm_probe_helper.h>\n#include <drm/drm_file.h>\n#include <drm/drm_gem.h>\n\n#include <xen/platform_pci.h>\n#include <xen/xen.h>\n#include <xen/xenbus.h>\n\n#include <xen/xen-front-pgdir-shbuf.h>\n#include <xen/interface/io/displif.h>\n\n#include \"xen_drm_front.h\"\n#include \"xen_drm_front_cfg.h\"\n#include \"xen_drm_front_evtchnl.h\"\n#include \"xen_drm_front_gem.h\"\n#include \"xen_drm_front_kms.h\"\n\nstruct xen_drm_front_dbuf {\n\tstruct list_head list;\n\tu64 dbuf_cookie;\n\tu64 fb_cookie;\n\n\tstruct xen_front_pgdir_shbuf shbuf;\n};\n\nstatic void dbuf_add_to_list(struct xen_drm_front_info *front_info,\n\t\t\t     struct xen_drm_front_dbuf *dbuf, u64 dbuf_cookie)\n{\n\tdbuf->dbuf_cookie = dbuf_cookie;\n\tlist_add(&dbuf->list, &front_info->dbuf_list);\n}\n\nstatic struct xen_drm_front_dbuf *dbuf_get(struct list_head *dbuf_list,\n\t\t\t\t\t   u64 dbuf_cookie)\n{\n\tstruct xen_drm_front_dbuf *buf, *q;\n\n\tlist_for_each_entry_safe(buf, q, dbuf_list, list)\n\t\tif (buf->dbuf_cookie == dbuf_cookie)\n\t\t\treturn buf;\n\n\treturn NULL;\n}\n\nstatic void dbuf_free(struct list_head *dbuf_list, u64 dbuf_cookie)\n{\n\tstruct xen_drm_front_dbuf *buf, *q;\n\n\tlist_for_each_entry_safe(buf, q, dbuf_list, list)\n\t\tif (buf->dbuf_cookie == dbuf_cookie) {\n\t\t\tlist_del(&buf->list);\n\t\t\txen_front_pgdir_shbuf_unmap(&buf->shbuf);\n\t\t\txen_front_pgdir_shbuf_free(&buf->shbuf);\n\t\t\tkfree(buf);\n\t\t\tbreak;\n\t\t}\n}\n\nstatic void dbuf_free_all(struct list_head *dbuf_list)\n{\n\tstruct xen_drm_front_dbuf *buf, *q;\n\n\tlist_for_each_entry_safe(buf, q, dbuf_list, list) {\n\t\tlist_del(&buf->list);\n\t\txen_front_pgdir_shbuf_unmap(&buf->shbuf);\n\t\txen_front_pgdir_shbuf_free(&buf->shbuf);\n\t\tkfree(buf);\n\t}\n}\n\nstatic struct xendispl_req *\nbe_prepare_req(struct xen_drm_front_evtchnl *evtchnl, u8 operation)\n{\n\tstruct xendispl_req *req;\n\n\treq = RING_GET_REQUEST(&evtchnl->u.req.ring,\n\t\t\t       evtchnl->u.req.ring.req_prod_pvt);\n\treq->operation = operation;\n\treq->id = evtchnl->evt_next_id++;\n\tevtchnl->evt_id = req->id;\n\treturn req;\n}\n\nstatic int be_stream_do_io(struct xen_drm_front_evtchnl *evtchnl,\n\t\t\t   struct xendispl_req *req)\n{\n\treinit_completion(&evtchnl->u.req.completion);\n\tif (unlikely(evtchnl->state != EVTCHNL_STATE_CONNECTED))\n\t\treturn -EIO;\n\n\txen_drm_front_evtchnl_flush(evtchnl);\n\treturn 0;\n}\n\nstatic int be_stream_wait_io(struct xen_drm_front_evtchnl *evtchnl)\n{\n\tif (wait_for_completion_timeout(&evtchnl->u.req.completion,\n\t\t\tmsecs_to_jiffies(XEN_DRM_FRONT_WAIT_BACK_MS)) <= 0)\n\t\treturn -ETIMEDOUT;\n\n\treturn evtchnl->u.req.resp_status;\n}\n\nint xen_drm_front_mode_set(struct xen_drm_front_drm_pipeline *pipeline,\n\t\t\t   u32 x, u32 y, u32 width, u32 height,\n\t\t\t   u32 bpp, u64 fb_cookie)\n{\n\tstruct xen_drm_front_evtchnl *evtchnl;\n\tstruct xen_drm_front_info *front_info;\n\tstruct xendispl_req *req;\n\tunsigned long flags;\n\tint ret;\n\n\tfront_info = pipeline->drm_info->front_info;\n\tevtchnl = &front_info->evt_pairs[pipeline->index].req;\n\tif (unlikely(!evtchnl))\n\t\treturn -EIO;\n\n\tmutex_lock(&evtchnl->u.req.req_io_lock);\n\n\tspin_lock_irqsave(&front_info->io_lock, flags);\n\treq = be_prepare_req(evtchnl, XENDISPL_OP_SET_CONFIG);\n\treq->op.set_config.x = x;\n\treq->op.set_config.y = y;\n\treq->op.set_config.width = width;\n\treq->op.set_config.height = height;\n\treq->op.set_config.bpp = bpp;\n\treq->op.set_config.fb_cookie = fb_cookie;\n\n\tret = be_stream_do_io(evtchnl, req);\n\tspin_unlock_irqrestore(&front_info->io_lock, flags);\n\n\tif (ret == 0)\n\t\tret = be_stream_wait_io(evtchnl);\n\n\tmutex_unlock(&evtchnl->u.req.req_io_lock);\n\treturn ret;\n}\n\nint xen_drm_front_dbuf_create(struct xen_drm_front_info *front_info,\n\t\t\t      u64 dbuf_cookie, u32 width, u32 height,\n\t\t\t      u32 bpp, u64 size, u32 offset,\n\t\t\t      struct page **pages)\n{\n\tstruct xen_drm_front_evtchnl *evtchnl;\n\tstruct xen_drm_front_dbuf *dbuf;\n\tstruct xendispl_req *req;\n\tstruct xen_front_pgdir_shbuf_cfg buf_cfg;\n\tunsigned long flags;\n\tint ret;\n\n\tevtchnl = &front_info->evt_pairs[GENERIC_OP_EVT_CHNL].req;\n\tif (unlikely(!evtchnl))\n\t\treturn -EIO;\n\n\tdbuf = kzalloc(sizeof(*dbuf), GFP_KERNEL);\n\tif (!dbuf)\n\t\treturn -ENOMEM;\n\n\tdbuf_add_to_list(front_info, dbuf, dbuf_cookie);\n\n\tmemset(&buf_cfg, 0, sizeof(buf_cfg));\n\tbuf_cfg.xb_dev = front_info->xb_dev;\n\tbuf_cfg.num_pages = DIV_ROUND_UP(size, PAGE_SIZE);\n\tbuf_cfg.pages = pages;\n\tbuf_cfg.pgdir = &dbuf->shbuf;\n\tbuf_cfg.be_alloc = front_info->cfg.be_alloc;\n\n\tret = xen_front_pgdir_shbuf_alloc(&buf_cfg);\n\tif (ret < 0)\n\t\tgoto fail_shbuf_alloc;\n\n\tmutex_lock(&evtchnl->u.req.req_io_lock);\n\n\tspin_lock_irqsave(&front_info->io_lock, flags);\n\treq = be_prepare_req(evtchnl, XENDISPL_OP_DBUF_CREATE);\n\treq->op.dbuf_create.gref_directory =\n\t\t\txen_front_pgdir_shbuf_get_dir_start(&dbuf->shbuf);\n\treq->op.dbuf_create.buffer_sz = size;\n\treq->op.dbuf_create.data_ofs = offset;\n\treq->op.dbuf_create.dbuf_cookie = dbuf_cookie;\n\treq->op.dbuf_create.width = width;\n\treq->op.dbuf_create.height = height;\n\treq->op.dbuf_create.bpp = bpp;\n\tif (buf_cfg.be_alloc)\n\t\treq->op.dbuf_create.flags |= XENDISPL_DBUF_FLG_REQ_ALLOC;\n\n\tret = be_stream_do_io(evtchnl, req);\n\tspin_unlock_irqrestore(&front_info->io_lock, flags);\n\n\tif (ret < 0)\n\t\tgoto fail;\n\n\tret = be_stream_wait_io(evtchnl);\n\tif (ret < 0)\n\t\tgoto fail;\n\n\tret = xen_front_pgdir_shbuf_map(&dbuf->shbuf);\n\tif (ret < 0)\n\t\tgoto fail;\n\n\tmutex_unlock(&evtchnl->u.req.req_io_lock);\n\treturn 0;\n\nfail:\n\tmutex_unlock(&evtchnl->u.req.req_io_lock);\nfail_shbuf_alloc:\n\tdbuf_free(&front_info->dbuf_list, dbuf_cookie);\n\treturn ret;\n}\n\nstatic int xen_drm_front_dbuf_destroy(struct xen_drm_front_info *front_info,\n\t\t\t\t      u64 dbuf_cookie)\n{\n\tstruct xen_drm_front_evtchnl *evtchnl;\n\tstruct xendispl_req *req;\n\tunsigned long flags;\n\tbool be_alloc;\n\tint ret;\n\n\tevtchnl = &front_info->evt_pairs[GENERIC_OP_EVT_CHNL].req;\n\tif (unlikely(!evtchnl))\n\t\treturn -EIO;\n\n\tbe_alloc = front_info->cfg.be_alloc;\n\n\t \n\tif (be_alloc)\n\t\tdbuf_free(&front_info->dbuf_list, dbuf_cookie);\n\n\tmutex_lock(&evtchnl->u.req.req_io_lock);\n\n\tspin_lock_irqsave(&front_info->io_lock, flags);\n\treq = be_prepare_req(evtchnl, XENDISPL_OP_DBUF_DESTROY);\n\treq->op.dbuf_destroy.dbuf_cookie = dbuf_cookie;\n\n\tret = be_stream_do_io(evtchnl, req);\n\tspin_unlock_irqrestore(&front_info->io_lock, flags);\n\n\tif (ret == 0)\n\t\tret = be_stream_wait_io(evtchnl);\n\n\t \n\tif (!be_alloc)\n\t\tdbuf_free(&front_info->dbuf_list, dbuf_cookie);\n\n\tmutex_unlock(&evtchnl->u.req.req_io_lock);\n\treturn ret;\n}\n\nint xen_drm_front_fb_attach(struct xen_drm_front_info *front_info,\n\t\t\t    u64 dbuf_cookie, u64 fb_cookie, u32 width,\n\t\t\t    u32 height, u32 pixel_format)\n{\n\tstruct xen_drm_front_evtchnl *evtchnl;\n\tstruct xen_drm_front_dbuf *buf;\n\tstruct xendispl_req *req;\n\tunsigned long flags;\n\tint ret;\n\n\tevtchnl = &front_info->evt_pairs[GENERIC_OP_EVT_CHNL].req;\n\tif (unlikely(!evtchnl))\n\t\treturn -EIO;\n\n\tbuf = dbuf_get(&front_info->dbuf_list, dbuf_cookie);\n\tif (!buf)\n\t\treturn -EINVAL;\n\n\tbuf->fb_cookie = fb_cookie;\n\n\tmutex_lock(&evtchnl->u.req.req_io_lock);\n\n\tspin_lock_irqsave(&front_info->io_lock, flags);\n\treq = be_prepare_req(evtchnl, XENDISPL_OP_FB_ATTACH);\n\treq->op.fb_attach.dbuf_cookie = dbuf_cookie;\n\treq->op.fb_attach.fb_cookie = fb_cookie;\n\treq->op.fb_attach.width = width;\n\treq->op.fb_attach.height = height;\n\treq->op.fb_attach.pixel_format = pixel_format;\n\n\tret = be_stream_do_io(evtchnl, req);\n\tspin_unlock_irqrestore(&front_info->io_lock, flags);\n\n\tif (ret == 0)\n\t\tret = be_stream_wait_io(evtchnl);\n\n\tmutex_unlock(&evtchnl->u.req.req_io_lock);\n\treturn ret;\n}\n\nint xen_drm_front_fb_detach(struct xen_drm_front_info *front_info,\n\t\t\t    u64 fb_cookie)\n{\n\tstruct xen_drm_front_evtchnl *evtchnl;\n\tstruct xendispl_req *req;\n\tunsigned long flags;\n\tint ret;\n\n\tevtchnl = &front_info->evt_pairs[GENERIC_OP_EVT_CHNL].req;\n\tif (unlikely(!evtchnl))\n\t\treturn -EIO;\n\n\tmutex_lock(&evtchnl->u.req.req_io_lock);\n\n\tspin_lock_irqsave(&front_info->io_lock, flags);\n\treq = be_prepare_req(evtchnl, XENDISPL_OP_FB_DETACH);\n\treq->op.fb_detach.fb_cookie = fb_cookie;\n\n\tret = be_stream_do_io(evtchnl, req);\n\tspin_unlock_irqrestore(&front_info->io_lock, flags);\n\n\tif (ret == 0)\n\t\tret = be_stream_wait_io(evtchnl);\n\n\tmutex_unlock(&evtchnl->u.req.req_io_lock);\n\treturn ret;\n}\n\nint xen_drm_front_page_flip(struct xen_drm_front_info *front_info,\n\t\t\t    int conn_idx, u64 fb_cookie)\n{\n\tstruct xen_drm_front_evtchnl *evtchnl;\n\tstruct xendispl_req *req;\n\tunsigned long flags;\n\tint ret;\n\n\tif (unlikely(conn_idx >= front_info->num_evt_pairs))\n\t\treturn -EINVAL;\n\n\tevtchnl = &front_info->evt_pairs[conn_idx].req;\n\n\tmutex_lock(&evtchnl->u.req.req_io_lock);\n\n\tspin_lock_irqsave(&front_info->io_lock, flags);\n\treq = be_prepare_req(evtchnl, XENDISPL_OP_PG_FLIP);\n\treq->op.pg_flip.fb_cookie = fb_cookie;\n\n\tret = be_stream_do_io(evtchnl, req);\n\tspin_unlock_irqrestore(&front_info->io_lock, flags);\n\n\tif (ret == 0)\n\t\tret = be_stream_wait_io(evtchnl);\n\n\tmutex_unlock(&evtchnl->u.req.req_io_lock);\n\treturn ret;\n}\n\nvoid xen_drm_front_on_frame_done(struct xen_drm_front_info *front_info,\n\t\t\t\t int conn_idx, u64 fb_cookie)\n{\n\tstruct xen_drm_front_drm_info *drm_info = front_info->drm_info;\n\n\tif (unlikely(conn_idx >= front_info->cfg.num_connectors))\n\t\treturn;\n\n\txen_drm_front_kms_on_frame_done(&drm_info->pipeline[conn_idx],\n\t\t\t\t\tfb_cookie);\n}\n\nvoid xen_drm_front_gem_object_free(struct drm_gem_object *obj)\n{\n\tstruct xen_drm_front_drm_info *drm_info = obj->dev->dev_private;\n\tint idx;\n\n\tif (drm_dev_enter(obj->dev, &idx)) {\n\t\txen_drm_front_dbuf_destroy(drm_info->front_info,\n\t\t\t\t\t   xen_drm_front_dbuf_to_cookie(obj));\n\t\tdrm_dev_exit(idx);\n\t} else {\n\t\tdbuf_free(&drm_info->front_info->dbuf_list,\n\t\t\t  xen_drm_front_dbuf_to_cookie(obj));\n\t}\n\n\txen_drm_front_gem_free_object_unlocked(obj);\n}\n\nstatic int xen_drm_drv_dumb_create(struct drm_file *filp,\n\t\t\t\t   struct drm_device *dev,\n\t\t\t\t   struct drm_mode_create_dumb *args)\n{\n\tstruct xen_drm_front_drm_info *drm_info = dev->dev_private;\n\tstruct drm_gem_object *obj;\n\tint ret;\n\n\t \n\targs->pitch = DIV_ROUND_UP(args->width * args->bpp, 8);\n\targs->size = args->pitch * args->height;\n\n\tobj = xen_drm_front_gem_create(dev, args->size);\n\tif (IS_ERR(obj)) {\n\t\tret = PTR_ERR(obj);\n\t\tgoto fail;\n\t}\n\n\tret = xen_drm_front_dbuf_create(drm_info->front_info,\n\t\t\t\t\txen_drm_front_dbuf_to_cookie(obj),\n\t\t\t\t\targs->width, args->height, args->bpp,\n\t\t\t\t\targs->size, 0,\n\t\t\t\t\txen_drm_front_gem_get_pages(obj));\n\tif (ret)\n\t\tgoto fail_backend;\n\n\t \n\tret = drm_gem_handle_create(filp, obj, &args->handle);\n\tif (ret)\n\t\tgoto fail_handle;\n\n\t \n\tdrm_gem_object_put(obj);\n\treturn 0;\n\nfail_handle:\n\txen_drm_front_dbuf_destroy(drm_info->front_info,\n\t\t\t\t   xen_drm_front_dbuf_to_cookie(obj));\nfail_backend:\n\t \n\tdrm_gem_object_put(obj);\nfail:\n\tDRM_ERROR(\"Failed to create dumb buffer: %d\\n\", ret);\n\treturn ret;\n}\n\nstatic void xen_drm_drv_release(struct drm_device *dev)\n{\n\tstruct xen_drm_front_drm_info *drm_info = dev->dev_private;\n\tstruct xen_drm_front_info *front_info = drm_info->front_info;\n\n\txen_drm_front_kms_fini(drm_info);\n\n\tdrm_atomic_helper_shutdown(dev);\n\tdrm_mode_config_cleanup(dev);\n\n\tif (front_info->cfg.be_alloc)\n\t\txenbus_switch_state(front_info->xb_dev,\n\t\t\t\t    XenbusStateInitialising);\n\n\tkfree(drm_info);\n}\n\nDEFINE_DRM_GEM_FOPS(xen_drm_dev_fops);\n\nstatic const struct drm_driver xen_drm_driver = {\n\t.driver_features           = DRIVER_GEM | DRIVER_MODESET | DRIVER_ATOMIC,\n\t.release                   = xen_drm_drv_release,\n\t.gem_prime_import_sg_table = xen_drm_front_gem_import_sg_table,\n\t.dumb_create               = xen_drm_drv_dumb_create,\n\t.fops                      = &xen_drm_dev_fops,\n\t.name                      = \"xendrm-du\",\n\t.desc                      = \"Xen PV DRM Display Unit\",\n\t.date                      = \"20180221\",\n\t.major                     = 1,\n\t.minor                     = 0,\n\n};\n\nstatic int xen_drm_drv_init(struct xen_drm_front_info *front_info)\n{\n\tstruct device *dev = &front_info->xb_dev->dev;\n\tstruct xen_drm_front_drm_info *drm_info;\n\tstruct drm_device *drm_dev;\n\tint ret;\n\n\tif (drm_firmware_drivers_only())\n\t\treturn -ENODEV;\n\n\tDRM_INFO(\"Creating %s\\n\", xen_drm_driver.desc);\n\n\tdrm_info = kzalloc(sizeof(*drm_info), GFP_KERNEL);\n\tif (!drm_info) {\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\tdrm_info->front_info = front_info;\n\tfront_info->drm_info = drm_info;\n\n\tdrm_dev = drm_dev_alloc(&xen_drm_driver, dev);\n\tif (IS_ERR(drm_dev)) {\n\t\tret = PTR_ERR(drm_dev);\n\t\tgoto fail_dev;\n\t}\n\n\tdrm_info->drm_dev = drm_dev;\n\n\tdrm_dev->dev_private = drm_info;\n\n\tret = xen_drm_front_kms_init(drm_info);\n\tif (ret) {\n\t\tDRM_ERROR(\"Failed to initialize DRM/KMS, ret %d\\n\", ret);\n\t\tgoto fail_modeset;\n\t}\n\n\tret = drm_dev_register(drm_dev, 0);\n\tif (ret)\n\t\tgoto fail_register;\n\n\tDRM_INFO(\"Initialized %s %d.%d.%d %s on minor %d\\n\",\n\t\t xen_drm_driver.name, xen_drm_driver.major,\n\t\t xen_drm_driver.minor, xen_drm_driver.patchlevel,\n\t\t xen_drm_driver.date, drm_dev->primary->index);\n\n\treturn 0;\n\nfail_register:\n\tdrm_dev_unregister(drm_dev);\nfail_modeset:\n\tdrm_kms_helper_poll_fini(drm_dev);\n\tdrm_mode_config_cleanup(drm_dev);\n\tdrm_dev_put(drm_dev);\nfail_dev:\n\tkfree(drm_info);\n\tfront_info->drm_info = NULL;\nfail:\n\treturn ret;\n}\n\nstatic void xen_drm_drv_fini(struct xen_drm_front_info *front_info)\n{\n\tstruct xen_drm_front_drm_info *drm_info = front_info->drm_info;\n\tstruct drm_device *dev;\n\n\tif (!drm_info)\n\t\treturn;\n\n\tdev = drm_info->drm_dev;\n\tif (!dev)\n\t\treturn;\n\n\t \n\tif (drm_dev_is_unplugged(dev))\n\t\treturn;\n\n\tdrm_kms_helper_poll_fini(dev);\n\tdrm_dev_unplug(dev);\n\tdrm_dev_put(dev);\n\n\tfront_info->drm_info = NULL;\n\n\txen_drm_front_evtchnl_free_all(front_info);\n\tdbuf_free_all(&front_info->dbuf_list);\n\n\t \n\tif (!front_info->cfg.be_alloc)\n\t\txenbus_switch_state(front_info->xb_dev,\n\t\t\t\t    XenbusStateInitialising);\n}\n\nstatic int displback_initwait(struct xen_drm_front_info *front_info)\n{\n\tstruct xen_drm_front_cfg *cfg = &front_info->cfg;\n\tint ret;\n\n\tcfg->front_info = front_info;\n\tret = xen_drm_front_cfg_card(front_info, cfg);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tDRM_INFO(\"Have %d connector(s)\\n\", cfg->num_connectors);\n\t \n\tret = xen_drm_front_evtchnl_create_all(front_info);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn xen_drm_front_evtchnl_publish_all(front_info);\n}\n\nstatic int displback_connect(struct xen_drm_front_info *front_info)\n{\n\txen_drm_front_evtchnl_set_state(front_info, EVTCHNL_STATE_CONNECTED);\n\treturn xen_drm_drv_init(front_info);\n}\n\nstatic void displback_disconnect(struct xen_drm_front_info *front_info)\n{\n\tif (!front_info->drm_info)\n\t\treturn;\n\n\t \n\txenbus_switch_state(front_info->xb_dev, XenbusStateReconfiguring);\n\n\txen_drm_drv_fini(front_info);\n}\n\nstatic void displback_changed(struct xenbus_device *xb_dev,\n\t\t\t      enum xenbus_state backend_state)\n{\n\tstruct xen_drm_front_info *front_info = dev_get_drvdata(&xb_dev->dev);\n\tint ret;\n\n\tDRM_DEBUG(\"Backend state is %s, front is %s\\n\",\n\t\t  xenbus_strstate(backend_state),\n\t\t  xenbus_strstate(xb_dev->state));\n\n\tswitch (backend_state) {\n\tcase XenbusStateReconfiguring:\n\tcase XenbusStateReconfigured:\n\tcase XenbusStateInitialised:\n\t\tbreak;\n\n\tcase XenbusStateInitialising:\n\t\tif (xb_dev->state == XenbusStateReconfiguring)\n\t\t\tbreak;\n\n\t\t \n\t\tdisplback_disconnect(front_info);\n\t\tbreak;\n\n\tcase XenbusStateInitWait:\n\t\tif (xb_dev->state == XenbusStateReconfiguring)\n\t\t\tbreak;\n\n\t\t \n\t\tdisplback_disconnect(front_info);\n\t\tif (xb_dev->state != XenbusStateInitialising)\n\t\t\tbreak;\n\n\t\tret = displback_initwait(front_info);\n\t\tif (ret < 0)\n\t\t\txenbus_dev_fatal(xb_dev, ret, \"initializing frontend\");\n\t\telse\n\t\t\txenbus_switch_state(xb_dev, XenbusStateInitialised);\n\t\tbreak;\n\n\tcase XenbusStateConnected:\n\t\tif (xb_dev->state != XenbusStateInitialised)\n\t\t\tbreak;\n\n\t\tret = displback_connect(front_info);\n\t\tif (ret < 0) {\n\t\t\tdisplback_disconnect(front_info);\n\t\t\txenbus_dev_fatal(xb_dev, ret, \"connecting backend\");\n\t\t} else {\n\t\t\txenbus_switch_state(xb_dev, XenbusStateConnected);\n\t\t}\n\t\tbreak;\n\n\tcase XenbusStateClosing:\n\t\t \n\t\tbreak;\n\n\tcase XenbusStateUnknown:\n\tcase XenbusStateClosed:\n\t\tif (xb_dev->state == XenbusStateClosed)\n\t\t\tbreak;\n\n\t\tdisplback_disconnect(front_info);\n\t\tbreak;\n\t}\n}\n\nstatic int xen_drv_probe(struct xenbus_device *xb_dev,\n\t\t\t const struct xenbus_device_id *id)\n{\n\tstruct xen_drm_front_info *front_info;\n\tstruct device *dev = &xb_dev->dev;\n\tint ret;\n\n\tret = dma_coerce_mask_and_coherent(dev, DMA_BIT_MASK(64));\n\tif (ret < 0) {\n\t\tDRM_ERROR(\"Cannot setup DMA mask, ret %d\", ret);\n\t\treturn ret;\n\t}\n\n\tfront_info = devm_kzalloc(&xb_dev->dev,\n\t\t\t\t  sizeof(*front_info), GFP_KERNEL);\n\tif (!front_info)\n\t\treturn -ENOMEM;\n\n\tfront_info->xb_dev = xb_dev;\n\tspin_lock_init(&front_info->io_lock);\n\tINIT_LIST_HEAD(&front_info->dbuf_list);\n\tdev_set_drvdata(&xb_dev->dev, front_info);\n\n\treturn xenbus_switch_state(xb_dev, XenbusStateInitialising);\n}\n\nstatic void xen_drv_remove(struct xenbus_device *dev)\n{\n\tstruct xen_drm_front_info *front_info = dev_get_drvdata(&dev->dev);\n\tint to = 100;\n\n\txenbus_switch_state(dev, XenbusStateClosing);\n\n\t \n\twhile ((xenbus_read_unsigned(front_info->xb_dev->otherend, \"state\",\n\t\t\t\t     XenbusStateUnknown) != XenbusStateInitWait) &&\n\t\t\t\t     --to)\n\t\tmsleep(10);\n\n\tif (!to) {\n\t\tunsigned int state;\n\n\t\tstate = xenbus_read_unsigned(front_info->xb_dev->otherend,\n\t\t\t\t\t     \"state\", XenbusStateUnknown);\n\t\tDRM_ERROR(\"Backend state is %s while removing driver\\n\",\n\t\t\t  xenbus_strstate(state));\n\t}\n\n\txen_drm_drv_fini(front_info);\n\txenbus_frontend_closed(dev);\n}\n\nstatic const struct xenbus_device_id xen_driver_ids[] = {\n\t{ XENDISPL_DRIVER_NAME },\n\t{ \"\" }\n};\n\nstatic struct xenbus_driver xen_driver = {\n\t.ids = xen_driver_ids,\n\t.probe = xen_drv_probe,\n\t.remove = xen_drv_remove,\n\t.otherend_changed = displback_changed,\n\t.not_essential = true,\n};\n\nstatic int __init xen_drv_init(void)\n{\n\t \n\tif (XEN_PAGE_SIZE != PAGE_SIZE) {\n\t\tDRM_ERROR(XENDISPL_DRIVER_NAME \": different kernel and Xen page sizes are not supported: XEN_PAGE_SIZE (%lu) != PAGE_SIZE (%lu)\\n\",\n\t\t\t  XEN_PAGE_SIZE, PAGE_SIZE);\n\t\treturn -ENODEV;\n\t}\n\n\tif (!xen_domain())\n\t\treturn -ENODEV;\n\n\tif (!xen_has_pv_devices())\n\t\treturn -ENODEV;\n\n\tDRM_INFO(\"Registering XEN PV \" XENDISPL_DRIVER_NAME \"\\n\");\n\treturn xenbus_register_frontend(&xen_driver);\n}\n\nstatic void __exit xen_drv_fini(void)\n{\n\tDRM_INFO(\"Unregistering XEN PV \" XENDISPL_DRIVER_NAME \"\\n\");\n\txenbus_unregister_driver(&xen_driver);\n}\n\nmodule_init(xen_drv_init);\nmodule_exit(xen_drv_fini);\n\nMODULE_DESCRIPTION(\"Xen para-virtualized display device frontend\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS(\"xen:\" XENDISPL_DRIVER_NAME);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}