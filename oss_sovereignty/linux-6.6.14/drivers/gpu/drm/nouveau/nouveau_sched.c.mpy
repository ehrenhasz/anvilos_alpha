{
  "module_name": "nouveau_sched.c",
  "hash_id": "7d0bc94a796d83f6abc0ca61202699ca1a3145601d1da65e261a7aa36f4a8564",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/nouveau/nouveau_sched.c",
  "human_readable_source": "\n\n#include <linux/slab.h>\n#include <drm/gpu_scheduler.h>\n#include <drm/drm_syncobj.h>\n\n#include \"nouveau_drv.h\"\n#include \"nouveau_gem.h\"\n#include \"nouveau_mem.h\"\n#include \"nouveau_dma.h\"\n#include \"nouveau_exec.h\"\n#include \"nouveau_abi16.h\"\n#include \"nouveau_sched.h\"\n\n \n#define NOUVEAU_SCHED_HW_SUBMISSIONS\t\t16\n#define NOUVEAU_SCHED_JOB_TIMEOUT_MS\t\t10000\n\nint\nnouveau_job_init(struct nouveau_job *job,\n\t\t struct nouveau_job_args *args)\n{\n\tstruct nouveau_sched_entity *entity = args->sched_entity;\n\tint ret;\n\n\tjob->file_priv = args->file_priv;\n\tjob->cli = nouveau_cli(args->file_priv);\n\tjob->entity = entity;\n\n\tjob->sync = args->sync;\n\tjob->resv_usage = args->resv_usage;\n\n\tjob->ops = args->ops;\n\n\tjob->in_sync.count = args->in_sync.count;\n\tif (job->in_sync.count) {\n\t\tif (job->sync)\n\t\t\treturn -EINVAL;\n\n\t\tjob->in_sync.data = kmemdup(args->in_sync.s,\n\t\t\t\t\t sizeof(*args->in_sync.s) *\n\t\t\t\t\t args->in_sync.count,\n\t\t\t\t\t GFP_KERNEL);\n\t\tif (!job->in_sync.data)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tjob->out_sync.count = args->out_sync.count;\n\tif (job->out_sync.count) {\n\t\tif (job->sync) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_free_in_sync;\n\t\t}\n\n\t\tjob->out_sync.data = kmemdup(args->out_sync.s,\n\t\t\t\t\t  sizeof(*args->out_sync.s) *\n\t\t\t\t\t  args->out_sync.count,\n\t\t\t\t\t  GFP_KERNEL);\n\t\tif (!job->out_sync.data) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free_in_sync;\n\t\t}\n\n\t\tjob->out_sync.objs = kcalloc(job->out_sync.count,\n\t\t\t\t\t     sizeof(*job->out_sync.objs),\n\t\t\t\t\t     GFP_KERNEL);\n\t\tif (!job->out_sync.objs) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free_out_sync;\n\t\t}\n\n\t\tjob->out_sync.chains = kcalloc(job->out_sync.count,\n\t\t\t\t\t       sizeof(*job->out_sync.chains),\n\t\t\t\t\t       GFP_KERNEL);\n\t\tif (!job->out_sync.chains) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free_objs;\n\t\t}\n\n\t}\n\n\tret = drm_sched_job_init(&job->base, &entity->base, NULL);\n\tif (ret)\n\t\tgoto err_free_chains;\n\n\tjob->state = NOUVEAU_JOB_INITIALIZED;\n\n\treturn 0;\n\nerr_free_chains:\n\tkfree(job->out_sync.chains);\nerr_free_objs:\n\tkfree(job->out_sync.objs);\nerr_free_out_sync:\n\tkfree(job->out_sync.data);\nerr_free_in_sync:\n\tkfree(job->in_sync.data);\nreturn ret;\n}\n\nvoid\nnouveau_job_free(struct nouveau_job *job)\n{\n\tkfree(job->in_sync.data);\n\tkfree(job->out_sync.data);\n\tkfree(job->out_sync.objs);\n\tkfree(job->out_sync.chains);\n}\n\nvoid nouveau_job_fini(struct nouveau_job *job)\n{\n\tdma_fence_put(job->done_fence);\n\tdrm_sched_job_cleanup(&job->base);\n\tjob->ops->free(job);\n}\n\nstatic int\nsync_find_fence(struct nouveau_job *job,\n\t\tstruct drm_nouveau_sync *sync,\n\t\tstruct dma_fence **fence)\n{\n\tu32 stype = sync->flags & DRM_NOUVEAU_SYNC_TYPE_MASK;\n\tu64 point = 0;\n\tint ret;\n\n\tif (stype != DRM_NOUVEAU_SYNC_SYNCOBJ &&\n\t    stype != DRM_NOUVEAU_SYNC_TIMELINE_SYNCOBJ)\n\t\treturn -EOPNOTSUPP;\n\n\tif (stype == DRM_NOUVEAU_SYNC_TIMELINE_SYNCOBJ)\n\t\tpoint = sync->timeline_value;\n\n\tret = drm_syncobj_find_fence(job->file_priv,\n\t\t\t\t     sync->handle, point,\n\t\t\t\t     0  , fence);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int\nnouveau_job_add_deps(struct nouveau_job *job)\n{\n\tstruct dma_fence *in_fence = NULL;\n\tint ret, i;\n\n\tfor (i = 0; i < job->in_sync.count; i++) {\n\t\tstruct drm_nouveau_sync *sync = &job->in_sync.data[i];\n\n\t\tret = sync_find_fence(job, sync, &in_fence);\n\t\tif (ret) {\n\t\t\tNV_PRINTK(warn, job->cli,\n\t\t\t\t  \"Failed to find syncobj (-> in): handle=%d\\n\",\n\t\t\t\t  sync->handle);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = drm_sched_job_add_dependency(&job->base, in_fence);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void\nnouveau_job_fence_attach_cleanup(struct nouveau_job *job)\n{\n\tint i;\n\n\tfor (i = 0; i < job->out_sync.count; i++) {\n\t\tstruct drm_syncobj *obj = job->out_sync.objs[i];\n\t\tstruct dma_fence_chain *chain = job->out_sync.chains[i];\n\n\t\tif (obj)\n\t\t\tdrm_syncobj_put(obj);\n\n\t\tif (chain)\n\t\t\tdma_fence_chain_free(chain);\n\t}\n}\n\nstatic int\nnouveau_job_fence_attach_prepare(struct nouveau_job *job)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < job->out_sync.count; i++) {\n\t\tstruct drm_nouveau_sync *sync = &job->out_sync.data[i];\n\t\tstruct drm_syncobj **pobj = &job->out_sync.objs[i];\n\t\tstruct dma_fence_chain **pchain = &job->out_sync.chains[i];\n\t\tu32 stype = sync->flags & DRM_NOUVEAU_SYNC_TYPE_MASK;\n\n\t\tif (stype != DRM_NOUVEAU_SYNC_SYNCOBJ &&\n\t\t    stype != DRM_NOUVEAU_SYNC_TIMELINE_SYNCOBJ) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto err_sync_cleanup;\n\t\t}\n\n\t\t*pobj = drm_syncobj_find(job->file_priv, sync->handle);\n\t\tif (!*pobj) {\n\t\t\tNV_PRINTK(warn, job->cli,\n\t\t\t\t  \"Failed to find syncobj (-> out): handle=%d\\n\",\n\t\t\t\t  sync->handle);\n\t\t\tret = -ENOENT;\n\t\t\tgoto err_sync_cleanup;\n\t\t}\n\n\t\tif (stype == DRM_NOUVEAU_SYNC_TIMELINE_SYNCOBJ) {\n\t\t\t*pchain = dma_fence_chain_alloc();\n\t\t\tif (!*pchain) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto err_sync_cleanup;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_sync_cleanup:\n\tnouveau_job_fence_attach_cleanup(job);\n\treturn ret;\n}\n\nstatic void\nnouveau_job_fence_attach(struct nouveau_job *job)\n{\n\tstruct dma_fence *fence = job->done_fence;\n\tint i;\n\n\tfor (i = 0; i < job->out_sync.count; i++) {\n\t\tstruct drm_nouveau_sync *sync = &job->out_sync.data[i];\n\t\tstruct drm_syncobj **pobj = &job->out_sync.objs[i];\n\t\tstruct dma_fence_chain **pchain = &job->out_sync.chains[i];\n\t\tu32 stype = sync->flags & DRM_NOUVEAU_SYNC_TYPE_MASK;\n\n\t\tif (stype == DRM_NOUVEAU_SYNC_TIMELINE_SYNCOBJ) {\n\t\t\tdrm_syncobj_add_point(*pobj, *pchain, fence,\n\t\t\t\t\t      sync->timeline_value);\n\t\t} else {\n\t\t\tdrm_syncobj_replace_fence(*pobj, fence);\n\t\t}\n\n\t\tdrm_syncobj_put(*pobj);\n\t\t*pobj = NULL;\n\t\t*pchain = NULL;\n\t}\n}\n\nint\nnouveau_job_submit(struct nouveau_job *job)\n{\n\tstruct nouveau_sched_entity *entity = to_nouveau_sched_entity(job->base.entity);\n\tstruct dma_fence *done_fence = NULL;\n\tint ret;\n\n\tret = nouveau_job_add_deps(job);\n\tif (ret)\n\t\tgoto err;\n\n\tret = nouveau_job_fence_attach_prepare(job);\n\tif (ret)\n\t\tgoto err;\n\n\t \n\tmutex_lock(&entity->mutex);\n\n\t \n\tif (job->ops->submit) {\n\t\tret = job->ops->submit(job);\n\t\tif (ret)\n\t\t\tgoto err_cleanup;\n\t}\n\n\tdrm_sched_job_arm(&job->base);\n\tjob->done_fence = dma_fence_get(&job->base.s_fence->finished);\n\tif (job->sync)\n\t\tdone_fence = dma_fence_get(job->done_fence);\n\n\t \n\tset_bit(DRM_SCHED_FENCE_DONT_PIPELINE, &job->done_fence->flags);\n\n\tif (job->ops->armed_submit)\n\t\tjob->ops->armed_submit(job);\n\n\tnouveau_job_fence_attach(job);\n\n\t \n\tjob->state = NOUVEAU_JOB_SUBMIT_SUCCESS;\n\n\tdrm_sched_entity_push_job(&job->base);\n\n\tmutex_unlock(&entity->mutex);\n\n\tif (done_fence) {\n\t\tdma_fence_wait(done_fence, true);\n\t\tdma_fence_put(done_fence);\n\t}\n\n\treturn 0;\n\nerr_cleanup:\n\tmutex_unlock(&entity->mutex);\n\tnouveau_job_fence_attach_cleanup(job);\nerr:\n\tjob->state = NOUVEAU_JOB_SUBMIT_FAILED;\n\treturn ret;\n}\n\nbool\nnouveau_sched_entity_qwork(struct nouveau_sched_entity *entity,\n\t\t\t   struct work_struct *work)\n{\n\treturn queue_work(entity->sched_wq, work);\n}\n\nstatic struct dma_fence *\nnouveau_job_run(struct nouveau_job *job)\n{\n\tstruct dma_fence *fence;\n\n\tfence = job->ops->run(job);\n\tif (IS_ERR(fence))\n\t\tjob->state = NOUVEAU_JOB_RUN_FAILED;\n\telse\n\t\tjob->state = NOUVEAU_JOB_RUN_SUCCESS;\n\n\treturn fence;\n}\n\nstatic struct dma_fence *\nnouveau_sched_run_job(struct drm_sched_job *sched_job)\n{\n\tstruct nouveau_job *job = to_nouveau_job(sched_job);\n\n\treturn nouveau_job_run(job);\n}\n\nstatic enum drm_gpu_sched_stat\nnouveau_sched_timedout_job(struct drm_sched_job *sched_job)\n{\n\tstruct drm_gpu_scheduler *sched = sched_job->sched;\n\tstruct nouveau_job *job = to_nouveau_job(sched_job);\n\tenum drm_gpu_sched_stat stat = DRM_GPU_SCHED_STAT_NOMINAL;\n\n\tdrm_sched_stop(sched, sched_job);\n\n\tif (job->ops->timeout)\n\t\tstat = job->ops->timeout(job);\n\telse\n\t\tNV_PRINTK(warn, job->cli, \"Generic job timeout.\\n\");\n\n\tdrm_sched_start(sched, true);\n\n\treturn stat;\n}\n\nstatic void\nnouveau_sched_free_job(struct drm_sched_job *sched_job)\n{\n\tstruct nouveau_job *job = to_nouveau_job(sched_job);\n\n\tnouveau_job_fini(job);\n}\n\nint nouveau_sched_entity_init(struct nouveau_sched_entity *entity,\n\t\t\t      struct drm_gpu_scheduler *sched,\n\t\t\t      struct workqueue_struct *sched_wq)\n{\n\tmutex_init(&entity->mutex);\n\tspin_lock_init(&entity->job.list.lock);\n\tINIT_LIST_HEAD(&entity->job.list.head);\n\tinit_waitqueue_head(&entity->job.wq);\n\n\tentity->sched_wq = sched_wq;\n\treturn drm_sched_entity_init(&entity->base,\n\t\t\t\t     DRM_SCHED_PRIORITY_NORMAL,\n\t\t\t\t     &sched, 1, NULL);\n}\n\nvoid\nnouveau_sched_entity_fini(struct nouveau_sched_entity *entity)\n{\n\tdrm_sched_entity_destroy(&entity->base);\n}\n\nstatic const struct drm_sched_backend_ops nouveau_sched_ops = {\n\t.run_job = nouveau_sched_run_job,\n\t.timedout_job = nouveau_sched_timedout_job,\n\t.free_job = nouveau_sched_free_job,\n};\n\nint nouveau_sched_init(struct nouveau_drm *drm)\n{\n\tstruct drm_gpu_scheduler *sched = &drm->sched;\n\tlong job_hang_limit = msecs_to_jiffies(NOUVEAU_SCHED_JOB_TIMEOUT_MS);\n\n\tdrm->sched_wq = create_singlethread_workqueue(\"nouveau_sched_wq\");\n\tif (!drm->sched_wq)\n\t\treturn -ENOMEM;\n\n\treturn drm_sched_init(sched, &nouveau_sched_ops,\n\t\t\t      NOUVEAU_SCHED_HW_SUBMISSIONS, 0, job_hang_limit,\n\t\t\t      NULL, NULL, \"nouveau_sched\", drm->dev->dev);\n}\n\nvoid nouveau_sched_fini(struct nouveau_drm *drm)\n{\n\tdestroy_workqueue(drm->sched_wq);\n\tdrm_sched_fini(&drm->sched);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}