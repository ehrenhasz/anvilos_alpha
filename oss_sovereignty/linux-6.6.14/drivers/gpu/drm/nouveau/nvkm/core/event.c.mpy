{
  "module_name": "event.c",
  "hash_id": "7f45212fcec476013a82d376035f8510f7a094569095b912f5f930f67f53a8ba",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/nouveau/nvkm/core/event.c",
  "human_readable_source": " \n#include <core/event.h>\n#include <core/subdev.h>\n\nstatic void\nnvkm_event_put(struct nvkm_event *event, u32 types, int index)\n{\n\tassert_spin_locked(&event->refs_lock);\n\n\tnvkm_trace(event->subdev, \"event: decr %08x on %d\\n\", types, index);\n\n\twhile (types) {\n\t\tint type = __ffs(types); types &= ~(1 << type);\n\t\tif (--event->refs[index * event->types_nr + type] == 0) {\n\t\t\tnvkm_trace(event->subdev, \"event: blocking %d on %d\\n\", type, index);\n\t\t\tif (event->func->fini)\n\t\t\t\tevent->func->fini(event, 1 << type, index);\n\t\t}\n\t}\n}\n\nstatic void\nnvkm_event_get(struct nvkm_event *event, u32 types, int index)\n{\n\tassert_spin_locked(&event->refs_lock);\n\n\tnvkm_trace(event->subdev, \"event: incr %08x on %d\\n\", types, index);\n\n\twhile (types) {\n\t\tint type = __ffs(types); types &= ~(1 << type);\n\t\tif (++event->refs[index * event->types_nr + type] == 1) {\n\t\t\tnvkm_trace(event->subdev, \"event: allowing %d on %d\\n\", type, index);\n\t\t\tif (event->func->init)\n\t\t\t\tevent->func->init(event, 1 << type, index);\n\t\t}\n\t}\n}\n\nstatic void\nnvkm_event_ntfy_state(struct nvkm_event_ntfy *ntfy)\n{\n\tstruct nvkm_event *event = ntfy->event;\n\tunsigned long flags;\n\n\tnvkm_trace(event->subdev, \"event: ntfy state changed\\n\");\n\tspin_lock_irqsave(&event->refs_lock, flags);\n\n\tif (atomic_read(&ntfy->allowed) != ntfy->running) {\n\t\tif (ntfy->running) {\n\t\t\tnvkm_event_put(ntfy->event, ntfy->bits, ntfy->id);\n\t\t\tntfy->running = false;\n\t\t} else {\n\t\t\tnvkm_event_get(ntfy->event, ntfy->bits, ntfy->id);\n\t\t\tntfy->running = true;\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&event->refs_lock, flags);\n}\n\nstatic void\nnvkm_event_ntfy_remove(struct nvkm_event_ntfy *ntfy)\n{\n\twrite_lock_irq(&ntfy->event->list_lock);\n\tlist_del_init(&ntfy->head);\n\twrite_unlock_irq(&ntfy->event->list_lock);\n}\n\nstatic void\nnvkm_event_ntfy_insert(struct nvkm_event_ntfy *ntfy)\n{\n\twrite_lock_irq(&ntfy->event->list_lock);\n\tlist_add_tail(&ntfy->head, &ntfy->event->ntfy);\n\twrite_unlock_irq(&ntfy->event->list_lock);\n}\n\nstatic void\nnvkm_event_ntfy_block_(struct nvkm_event_ntfy *ntfy, bool wait)\n{\n\tstruct nvkm_subdev *subdev = ntfy->event->subdev;\n\n\tnvkm_trace(subdev, \"event: ntfy block %08x on %d wait:%d\\n\", ntfy->bits, ntfy->id, wait);\n\n\tif (atomic_xchg(&ntfy->allowed, 0) == 1) {\n\t\tnvkm_event_ntfy_state(ntfy);\n\t\tif (wait)\n\t\t\tnvkm_event_ntfy_remove(ntfy);\n\t}\n}\n\nvoid\nnvkm_event_ntfy_block(struct nvkm_event_ntfy *ntfy)\n{\n\tif (ntfy->event)\n\t\tnvkm_event_ntfy_block_(ntfy, ntfy->wait);\n}\n\nvoid\nnvkm_event_ntfy_allow(struct nvkm_event_ntfy *ntfy)\n{\n\tnvkm_trace(ntfy->event->subdev, \"event: ntfy allow %08x on %d\\n\", ntfy->bits, ntfy->id);\n\n\tif (atomic_xchg(&ntfy->allowed, 1) == 0) {\n\t\tnvkm_event_ntfy_state(ntfy);\n\t\tif (ntfy->wait)\n\t\t\tnvkm_event_ntfy_insert(ntfy);\n\t}\n}\n\nvoid\nnvkm_event_ntfy_del(struct nvkm_event_ntfy *ntfy)\n{\n\tstruct nvkm_event *event = ntfy->event;\n\n\tif (!event)\n\t\treturn;\n\n\tnvkm_trace(event->subdev, \"event: ntfy del %08x on %d\\n\", ntfy->bits, ntfy->id);\n\n\tnvkm_event_ntfy_block_(ntfy, false);\n\tnvkm_event_ntfy_remove(ntfy);\n\tntfy->event = NULL;\n}\n\nvoid\nnvkm_event_ntfy_add(struct nvkm_event *event, int id, u32 bits, bool wait, nvkm_event_func func,\n\t\t    struct nvkm_event_ntfy *ntfy)\n{\n\tnvkm_trace(event->subdev, \"event: ntfy add %08x on %d wait:%d\\n\", id, bits, wait);\n\n\tntfy->event = event;\n\tntfy->id = id;\n\tntfy->bits = bits;\n\tntfy->wait = wait;\n\tntfy->func = func;\n\tatomic_set(&ntfy->allowed, 0);\n\tntfy->running = false;\n\tINIT_LIST_HEAD(&ntfy->head);\n\tif (!ntfy->wait)\n\t\tnvkm_event_ntfy_insert(ntfy);\n}\n\nbool\nnvkm_event_ntfy_valid(struct nvkm_event *event, int id, u32 bits)\n{\n\treturn true;\n}\n\nvoid\nnvkm_event_ntfy(struct nvkm_event *event, int id, u32 bits)\n{\n\tstruct nvkm_event_ntfy *ntfy, *ntmp;\n\tunsigned long flags;\n\n\tif (!event->refs || WARN_ON(id >= event->index_nr))\n\t\treturn;\n\n\tnvkm_trace(event->subdev, \"event: ntfy %08x on %d\\n\", bits, id);\n\tread_lock_irqsave(&event->list_lock, flags);\n\n\tlist_for_each_entry_safe(ntfy, ntmp, &event->ntfy, head) {\n\t\tif (ntfy->id == id && ntfy->bits & bits) {\n\t\t\tif (atomic_read(&ntfy->allowed))\n\t\t\t\tntfy->func(ntfy, ntfy->bits & bits);\n\t\t}\n\t}\n\n\tread_unlock_irqrestore(&event->list_lock, flags);\n}\n\nvoid\nnvkm_event_fini(struct nvkm_event *event)\n{\n\tif (event->refs) {\n\t\tkfree(event->refs);\n\t\tevent->refs = NULL;\n\t}\n}\n\nint\n__nvkm_event_init(const struct nvkm_event_func *func, struct nvkm_subdev *subdev,\n\t\t  int types_nr, int index_nr, struct nvkm_event *event)\n{\n\tevent->refs = kzalloc(array3_size(index_nr, types_nr, sizeof(*event->refs)), GFP_KERNEL);\n\tif (!event->refs)\n\t\treturn -ENOMEM;\n\n\tevent->func = func;\n\tevent->subdev = subdev;\n\tevent->types_nr = types_nr;\n\tevent->index_nr = index_nr;\n\tINIT_LIST_HEAD(&event->ntfy);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}