{
  "module_name": "vmmnv44.c",
  "hash_id": "c28819e5e70155bd190d78a9162dc74075b2f557ed53fd047ac3e7cafa5363f7",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/nouveau/nvkm/subdev/mmu/vmmnv44.c",
  "human_readable_source": " \n#include \"vmm.h\"\n\n#include <subdev/timer.h>\n\nstatic void\nnv44_vmm_pgt_fill(struct nvkm_vmm *vmm, struct nvkm_mmu_pt *pt,\n\t\t  dma_addr_t *list, u32 ptei, u32 ptes)\n{\n\tu32 pteo = (ptei << 2) & ~0x0000000f;\n\tu32 tmp[4];\n\n\ttmp[0] = nvkm_ro32(pt->memory, pteo + 0x0);\n\ttmp[1] = nvkm_ro32(pt->memory, pteo + 0x4);\n\ttmp[2] = nvkm_ro32(pt->memory, pteo + 0x8);\n\ttmp[3] = nvkm_ro32(pt->memory, pteo + 0xc);\n\n\twhile (ptes--) {\n\t\tu32 addr = (list ? *list++ : vmm->null) >> 12;\n\t\tswitch (ptei++ & 0x3) {\n\t\tcase 0:\n\t\t\ttmp[0] &= ~0x07ffffff;\n\t\t\ttmp[0] |= addr;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\ttmp[0] &= ~0xf8000000;\n\t\t\ttmp[0] |= addr << 27;\n\t\t\ttmp[1] &= ~0x003fffff;\n\t\t\ttmp[1] |= addr >> 5;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\ttmp[1] &= ~0xffc00000;\n\t\t\ttmp[1] |= addr << 22;\n\t\t\ttmp[2] &= ~0x0001ffff;\n\t\t\ttmp[2] |= addr >> 10;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\ttmp[2] &= ~0xfffe0000;\n\t\t\ttmp[2] |= addr << 17;\n\t\t\ttmp[3] &= ~0x00000fff;\n\t\t\ttmp[3] |= addr >> 15;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tVMM_WO032(pt, vmm, pteo + 0x0, tmp[0]);\n\tVMM_WO032(pt, vmm, pteo + 0x4, tmp[1]);\n\tVMM_WO032(pt, vmm, pteo + 0x8, tmp[2]);\n\tVMM_WO032(pt, vmm, pteo + 0xc, tmp[3] | 0x40000000);\n}\n\nstatic void\nnv44_vmm_pgt_pte(struct nvkm_vmm *vmm, struct nvkm_mmu_pt *pt,\n\t\t u32 ptei, u32 ptes, struct nvkm_vmm_map *map, u64 addr)\n{\n\tdma_addr_t tmp[4], i;\n\n\tif (ptei & 3) {\n\t\tconst u32 pten = min(ptes, 4 - (ptei & 3));\n\t\tfor (i = 0; i < pten; i++, addr += 0x1000)\n\t\t\ttmp[i] = addr;\n\t\tnv44_vmm_pgt_fill(vmm, pt, tmp, ptei, pten);\n\t\tptei += pten;\n\t\tptes -= pten;\n\t}\n\n\twhile (ptes >= 4) {\n\t\tfor (i = 0; i < 4; i++, addr += 0x1000)\n\t\t\ttmp[i] = addr >> 12;\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[0] >>  0 | tmp[1] << 27);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[1] >>  5 | tmp[2] << 22);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[2] >> 10 | tmp[3] << 17);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[3] >> 15 | 0x40000000);\n\t\tptes -= 4;\n\t}\n\n\tif (ptes) {\n\t\tfor (i = 0; i < ptes; i++, addr += 0x1000)\n\t\t\ttmp[i] = addr;\n\t\tnv44_vmm_pgt_fill(vmm, pt, tmp, ptei, ptes);\n\t}\n}\n\nstatic void\nnv44_vmm_pgt_sgl(struct nvkm_vmm *vmm, struct nvkm_mmu_pt *pt,\n\t\t u32 ptei, u32 ptes, struct nvkm_vmm_map *map)\n{\n\tVMM_MAP_ITER_SGL(vmm, pt, ptei, ptes, map, nv44_vmm_pgt_pte);\n}\n\nstatic void\nnv44_vmm_pgt_dma(struct nvkm_vmm *vmm, struct nvkm_mmu_pt *pt,\n\t\t u32 ptei, u32 ptes, struct nvkm_vmm_map *map)\n{\n#if PAGE_SHIFT == 12\n\tnvkm_kmap(pt->memory);\n\tif (ptei & 3) {\n\t\tconst u32 pten = min(ptes, 4 - (ptei & 3));\n\t\tnv44_vmm_pgt_fill(vmm, pt, map->dma, ptei, pten);\n\t\tptei += pten;\n\t\tptes -= pten;\n\t\tmap->dma += pten;\n\t}\n\n\twhile (ptes >= 4) {\n\t\tu32 tmp[4], i;\n\t\tfor (i = 0; i < 4; i++)\n\t\t\ttmp[i] = *map->dma++ >> 12;\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[0] >>  0 | tmp[1] << 27);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[1] >>  5 | tmp[2] << 22);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[2] >> 10 | tmp[3] << 17);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, tmp[3] >> 15 | 0x40000000);\n\t\tptes -= 4;\n\t}\n\n\tif (ptes) {\n\t\tnv44_vmm_pgt_fill(vmm, pt, map->dma, ptei, ptes);\n\t\tmap->dma += ptes;\n\t}\n\tnvkm_done(pt->memory);\n#else\n\tVMM_MAP_ITER_DMA(vmm, pt, ptei, ptes, map, nv44_vmm_pgt_pte);\n#endif\n}\n\nstatic void\nnv44_vmm_pgt_unmap(struct nvkm_vmm *vmm,\n\t\t   struct nvkm_mmu_pt *pt, u32 ptei, u32 ptes)\n{\n\tnvkm_kmap(pt->memory);\n\tif (ptei & 3) {\n\t\tconst u32 pten = min(ptes, 4 - (ptei & 3));\n\t\tnv44_vmm_pgt_fill(vmm, pt, NULL, ptei, pten);\n\t\tptei += pten;\n\t\tptes -= pten;\n\t}\n\n\twhile (ptes > 4) {\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, 0x00000000);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, 0x00000000);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, 0x00000000);\n\t\tVMM_WO032(pt, vmm, ptei++ * 4, 0x00000000);\n\t\tptes -= 4;\n\t}\n\n\tif (ptes)\n\t\tnv44_vmm_pgt_fill(vmm, pt, NULL, ptei, ptes);\n\tnvkm_done(pt->memory);\n}\n\nstatic const struct nvkm_vmm_desc_func\nnv44_vmm_desc_pgt = {\n\t.unmap = nv44_vmm_pgt_unmap,\n\t.dma = nv44_vmm_pgt_dma,\n\t.sgl = nv44_vmm_pgt_sgl,\n};\n\nstatic const struct nvkm_vmm_desc\nnv44_vmm_desc_12[] = {\n\t{ PGT, 17, 4, 0x80000, &nv44_vmm_desc_pgt },\n\t{}\n};\n\nstatic void\nnv44_vmm_flush(struct nvkm_vmm *vmm, int level)\n{\n\tstruct nvkm_device *device = vmm->mmu->subdev.device;\n\tnvkm_wr32(device, 0x100814, vmm->limit - 4096);\n\tnvkm_wr32(device, 0x100808, 0x000000020);\n\tnvkm_msec(device, 2000,\n\t\tif (nvkm_rd32(device, 0x100808) & 0x00000001)\n\t\t\tbreak;\n\t);\n\tnvkm_wr32(device, 0x100808, 0x00000000);\n}\n\nstatic const struct nvkm_vmm_func\nnv44_vmm = {\n\t.valid = nv04_vmm_valid,\n\t.flush = nv44_vmm_flush,\n\t.page = {\n\t\t{ 12, &nv44_vmm_desc_12[0], NVKM_VMM_PAGE_HOST },\n\t\t{}\n\t}\n};\n\nint\nnv44_vmm_new(struct nvkm_mmu *mmu, bool managed, u64 addr, u64 size,\n\t     void *argv, u32 argc, struct lock_class_key *key, const char *name,\n\t     struct nvkm_vmm **pvmm)\n{\n\tstruct nvkm_subdev *subdev = &mmu->subdev;\n\tstruct nvkm_vmm *vmm;\n\tint ret;\n\n\tret = nv04_vmm_new_(&nv44_vmm, mmu, 0, managed, addr, size,\n\t\t\t    argv, argc, key, name, &vmm);\n\t*pvmm = vmm;\n\tif (ret)\n\t\treturn ret;\n\n\tvmm->nullp = dma_alloc_coherent(subdev->device->dev, 16 * 1024,\n\t\t\t\t\t&vmm->null, GFP_KERNEL);\n\tif (!vmm->nullp) {\n\t\tnvkm_warn(subdev, \"unable to allocate dummy pages\\n\");\n\t\tvmm->null = 0;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}