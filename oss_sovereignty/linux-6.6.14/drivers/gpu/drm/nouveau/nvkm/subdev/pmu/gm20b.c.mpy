{
  "module_name": "gm20b.c",
  "hash_id": "16824828931085f1bc93af7240fd515470fcd6ac8451811f5679296c6372b26a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/nouveau/nvkm/subdev/pmu/gm20b.c",
  "human_readable_source": " \n#include \"priv.h\"\n\n#include <core/memory.h>\n#include <subdev/acr.h>\n\n#include <nvfw/flcn.h>\n#include <nvfw/pmu.h>\n\nstatic int\ngm20b_pmu_acr_bootstrap_falcon_cb(void *priv, struct nvfw_falcon_msg *hdr)\n{\n\tstruct nv_pmu_acr_bootstrap_falcon_msg *msg =\n\t\tcontainer_of(hdr, typeof(*msg), msg.hdr);\n\treturn msg->falcon_id;\n}\n\nint\ngm20b_pmu_acr_bootstrap_falcon(struct nvkm_falcon *falcon,\n\t\t\t       enum nvkm_acr_lsf_id id)\n{\n\tstruct nvkm_pmu *pmu = container_of(falcon, typeof(*pmu), falcon);\n\tstruct nv_pmu_acr_bootstrap_falcon_cmd cmd = {\n\t\t.cmd.hdr.unit_id = NV_PMU_UNIT_ACR,\n\t\t.cmd.hdr.size = sizeof(cmd),\n\t\t.cmd.cmd_type = NV_PMU_ACR_CMD_BOOTSTRAP_FALCON,\n\t\t.flags = NV_PMU_ACR_BOOTSTRAP_FALCON_FLAGS_RESET_YES,\n\t\t.falcon_id = id,\n\t};\n\tint ret;\n\n\tret = nvkm_falcon_cmdq_send(pmu->hpq, &cmd.cmd.hdr,\n\t\t\t\t    gm20b_pmu_acr_bootstrap_falcon_cb,\n\t\t\t\t    &pmu->subdev, msecs_to_jiffies(1000));\n\tif (ret >= 0) {\n\t\tif (ret != cmd.falcon_id)\n\t\t\tret = -EIO;\n\t\telse\n\t\t\tret = 0;\n\t}\n\n\treturn ret;\n}\n\nvoid\ngm20b_pmu_acr_bld_patch(struct nvkm_acr *acr, u32 bld, s64 adjust)\n{\n\tstruct loader_config hdr;\n\tu64 addr;\n\n\tnvkm_robj(acr->wpr, bld, &hdr, sizeof(hdr));\n\taddr = ((u64)hdr.code_dma_base1 << 40 | hdr.code_dma_base << 8);\n\thdr.code_dma_base  = lower_32_bits((addr + adjust) >> 8);\n\thdr.code_dma_base1 = upper_32_bits((addr + adjust) >> 8);\n\taddr = ((u64)hdr.data_dma_base1 << 40 | hdr.data_dma_base << 8);\n\thdr.data_dma_base  = lower_32_bits((addr + adjust) >> 8);\n\thdr.data_dma_base1 = upper_32_bits((addr + adjust) >> 8);\n\taddr = ((u64)hdr.overlay_dma_base1 << 40 | hdr.overlay_dma_base << 8);\n\thdr.overlay_dma_base  = lower_32_bits((addr + adjust) << 8);\n\thdr.overlay_dma_base1 = upper_32_bits((addr + adjust) << 8);\n\tnvkm_wobj(acr->wpr, bld, &hdr, sizeof(hdr));\n\n\tloader_config_dump(&acr->subdev, &hdr);\n}\n\nvoid\ngm20b_pmu_acr_bld_write(struct nvkm_acr *acr, u32 bld,\n\t\t\tstruct nvkm_acr_lsfw *lsfw)\n{\n\tconst u64 base = lsfw->offset.img + lsfw->app_start_offset;\n\tconst u64 code = (base + lsfw->app_resident_code_offset) >> 8;\n\tconst u64 data = (base + lsfw->app_resident_data_offset) >> 8;\n\tconst struct loader_config hdr = {\n\t\t.dma_idx = FALCON_DMAIDX_UCODE,\n\t\t.code_dma_base = lower_32_bits(code),\n\t\t.code_size_total = lsfw->app_size,\n\t\t.code_size_to_load = lsfw->app_resident_code_size,\n\t\t.code_entry_point = lsfw->app_imem_entry,\n\t\t.data_dma_base = lower_32_bits(data),\n\t\t.data_size = lsfw->app_resident_data_size,\n\t\t.overlay_dma_base = lower_32_bits(code),\n\t\t.argc = 1,\n\t\t.argv = lsfw->falcon->data.limit - sizeof(struct nv_pmu_args),\n\t\t.code_dma_base1 = upper_32_bits(code),\n\t\t.data_dma_base1 = upper_32_bits(data),\n\t\t.overlay_dma_base1 = upper_32_bits(code),\n\t};\n\n\tnvkm_wobj(acr->wpr, bld, &hdr, sizeof(hdr));\n}\n\nstatic const struct nvkm_acr_lsf_func\ngm20b_pmu_acr = {\n\t.flags = NVKM_ACR_LSF_DMACTL_REQ_CTX,\n\t.bld_size = sizeof(struct loader_config),\n\t.bld_write = gm20b_pmu_acr_bld_write,\n\t.bld_patch = gm20b_pmu_acr_bld_patch,\n\t.bootstrap_falcons = BIT_ULL(NVKM_ACR_LSF_PMU) |\n\t\t\t     BIT_ULL(NVKM_ACR_LSF_FECS) |\n\t\t\t     BIT_ULL(NVKM_ACR_LSF_GPCCS),\n\t.bootstrap_falcon = gm20b_pmu_acr_bootstrap_falcon,\n};\n\nstatic int\ngm20b_pmu_acr_init_wpr_callback(void *priv, struct nvfw_falcon_msg *hdr)\n{\n\tstruct nv_pmu_acr_init_wpr_region_msg *msg =\n\t\tcontainer_of(hdr, typeof(*msg), msg.hdr);\n\tstruct nvkm_pmu *pmu = priv;\n\tstruct nvkm_subdev *subdev = &pmu->subdev;\n\n\tif (msg->error_code) {\n\t\tnvkm_error(subdev, \"ACR WPR init failure: %d\\n\",\n\t\t\t   msg->error_code);\n\t\treturn -EINVAL;\n\t}\n\n\tnvkm_debug(subdev, \"ACR WPR init complete\\n\");\n\tcomplete_all(&pmu->wpr_ready);\n\treturn 0;\n}\n\nstatic int\ngm20b_pmu_acr_init_wpr(struct nvkm_pmu *pmu)\n{\n\tstruct nv_pmu_acr_init_wpr_region_cmd cmd = {\n\t\t.cmd.hdr.unit_id = NV_PMU_UNIT_ACR,\n\t\t.cmd.hdr.size = sizeof(cmd),\n\t\t.cmd.cmd_type = NV_PMU_ACR_CMD_INIT_WPR_REGION,\n\t\t.region_id = 1,\n\t\t.wpr_offset = 0,\n\t};\n\n\treturn nvkm_falcon_cmdq_send(pmu->hpq, &cmd.cmd.hdr,\n\t\t\t\t     gm20b_pmu_acr_init_wpr_callback, pmu, 0);\n}\n\nstatic int\ngm20b_pmu_initmsg(struct nvkm_pmu *pmu)\n{\n\tstruct nv_pmu_init_msg msg;\n\tint ret;\n\n\tret = nvkm_falcon_msgq_recv_initmsg(pmu->msgq, &msg, sizeof(msg));\n\tif (ret)\n\t\treturn ret;\n\n\tif (msg.hdr.unit_id != NV_PMU_UNIT_INIT ||\n\t    msg.msg_type != NV_PMU_INIT_MSG_INIT)\n\t\treturn -EINVAL;\n\n\tnvkm_falcon_cmdq_init(pmu->hpq, msg.queue_info[0].index,\n\t\t\t\t\tmsg.queue_info[0].offset,\n\t\t\t\t\tmsg.queue_info[0].size);\n\tnvkm_falcon_cmdq_init(pmu->lpq, msg.queue_info[1].index,\n\t\t\t\t\tmsg.queue_info[1].offset,\n\t\t\t\t\tmsg.queue_info[1].size);\n\tnvkm_falcon_msgq_init(pmu->msgq, msg.queue_info[4].index,\n\t\t\t\t\t msg.queue_info[4].offset,\n\t\t\t\t\t msg.queue_info[4].size);\n\treturn gm20b_pmu_acr_init_wpr(pmu);\n}\n\nstatic void\ngm20b_pmu_recv(struct nvkm_pmu *pmu)\n{\n\tif (!pmu->initmsg_received) {\n\t\tint ret = pmu->func->initmsg(pmu);\n\t\tif (ret) {\n\t\t\tnvkm_error(&pmu->subdev, \"error parsing init message: %d\\n\", ret);\n\t\t\treturn;\n\t\t}\n\n\t\tpmu->initmsg_received = true;\n\t}\n\n\tnvkm_falcon_msgq_recv(pmu->msgq);\n}\n\nstatic void\ngm20b_pmu_fini(struct nvkm_pmu *pmu)\n{\n\t \n\n\tflush_work(&pmu->recv.work);\n\tnvkm_falcon_cmdq_fini(pmu->lpq);\n\tnvkm_falcon_cmdq_fini(pmu->hpq);\n\n\treinit_completion(&pmu->wpr_ready);\n\n\tnvkm_falcon_put(&pmu->falcon, &pmu->subdev);\n}\n\nstatic int\ngm20b_pmu_init(struct nvkm_pmu *pmu)\n{\n\tstruct nvkm_falcon *falcon = &pmu->falcon;\n\tstruct nv_pmu_args args = { .secure_mode = true };\n\tu32 addr_args = falcon->data.limit - sizeof(args);\n\tint ret;\n\n\tret = nvkm_falcon_get(&pmu->falcon, &pmu->subdev);\n\tif (ret)\n\t\treturn ret;\n\n\tpmu->initmsg_received = false;\n\n\tnvkm_falcon_pio_wr(falcon, (u8 *)&args, 0, 0, DMEM, addr_args, sizeof(args), 0, false);\n\tnvkm_falcon_start(falcon);\n\treturn 0;\n}\n\nconst struct nvkm_pmu_func\ngm20b_pmu = {\n\t.flcn = &gm200_pmu_flcn,\n\t.init = gm20b_pmu_init,\n\t.fini = gm20b_pmu_fini,\n\t.intr = gt215_pmu_intr,\n\t.recv = gm20b_pmu_recv,\n\t.initmsg = gm20b_pmu_initmsg,\n\t.reset = gf100_pmu_reset,\n};\n\n#if IS_ENABLED(CONFIG_ARCH_TEGRA_210_SOC)\nMODULE_FIRMWARE(\"nvidia/gm20b/pmu/desc.bin\");\nMODULE_FIRMWARE(\"nvidia/gm20b/pmu/image.bin\");\nMODULE_FIRMWARE(\"nvidia/gm20b/pmu/sig.bin\");\n#endif\n\nint\ngm20b_pmu_load(struct nvkm_pmu *pmu, int ver, const struct nvkm_pmu_fwif *fwif)\n{\n\treturn nvkm_acr_lsfw_load_sig_image_desc(&pmu->subdev, &pmu->falcon,\n\t\t\t\t\t\t NVKM_ACR_LSF_PMU, \"pmu/\",\n\t\t\t\t\t\t ver, fwif->acr);\n}\n\nstatic const struct nvkm_pmu_fwif\ngm20b_pmu_fwif[] = {\n\t{  0, gm20b_pmu_load, &gm20b_pmu, &gm20b_pmu_acr },\n\t{ -1, gm200_pmu_nofw, &gm20b_pmu },\n\t{}\n};\n\nint\ngm20b_pmu_new(struct nvkm_device *device, enum nvkm_subdev_type type, int inst,\n\t      struct nvkm_pmu **ppmu)\n{\n\treturn nvkm_pmu_new_(gm20b_pmu_fwif, device, type, inst, ppmu);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}