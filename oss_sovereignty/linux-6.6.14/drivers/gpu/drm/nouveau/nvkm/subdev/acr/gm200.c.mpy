{
  "module_name": "gm200.c",
  "hash_id": "a379148389ecb44faa3241ce3a4d3ea0f5e4e0a7571dd404d45c5c207e3af895",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/nouveau/nvkm/subdev/acr/gm200.c",
  "human_readable_source": " \n#include \"priv.h\"\n\n#include <core/falcon.h>\n#include <core/firmware.h>\n#include <core/memory.h>\n#include <subdev/mc.h>\n#include <subdev/mmu.h>\n#include <subdev/pmu.h>\n#include <subdev/timer.h>\n\n#include <nvfw/acr.h>\n#include <nvfw/flcn.h>\n\nconst struct nvkm_acr_func\ngm200_acr = {\n};\n\nint\ngm200_acr_nofw(struct nvkm_acr *acr, int ver, const struct nvkm_acr_fwif *fwif)\n{\n\tnvkm_warn(&acr->subdev, \"firmware unavailable\\n\");\n\treturn 0;\n}\n\nint\ngm200_acr_init(struct nvkm_acr *acr)\n{\n\treturn nvkm_acr_hsfw_boot(acr, \"load\");\n}\n\nvoid\ngm200_acr_wpr_check(struct nvkm_acr *acr, u64 *start, u64 *limit)\n{\n\tstruct nvkm_device *device = acr->subdev.device;\n\n\tnvkm_wr32(device, 0x100cd4, 2);\n\t*start = (u64)(nvkm_rd32(device, 0x100cd4) & 0xffffff00) << 8;\n\tnvkm_wr32(device, 0x100cd4, 3);\n\t*limit = (u64)(nvkm_rd32(device, 0x100cd4) & 0xffffff00) << 8;\n\t*limit = *limit + 0x20000;\n}\n\nint\ngm200_acr_wpr_patch(struct nvkm_acr *acr, s64 adjust)\n{\n\tstruct nvkm_subdev *subdev = &acr->subdev;\n\tstruct wpr_header hdr;\n\tstruct lsb_header lsb;\n\tstruct nvkm_acr_lsf *lsfw;\n\tu32 offset = 0;\n\n\tdo {\n\t\tnvkm_robj(acr->wpr, offset, &hdr, sizeof(hdr));\n\t\twpr_header_dump(subdev, &hdr);\n\n\t\tlist_for_each_entry(lsfw, &acr->lsfw, head) {\n\t\t\tif (lsfw->id != hdr.falcon_id)\n\t\t\t\tcontinue;\n\n\t\t\tnvkm_robj(acr->wpr, hdr.lsb_offset, &lsb, sizeof(lsb));\n\t\t\tlsb_header_dump(subdev, &lsb);\n\n\t\t\tlsfw->func->bld_patch(acr, lsb.tail.bl_data_off, adjust);\n\t\t\tbreak;\n\t\t}\n\t\toffset += sizeof(hdr);\n\t} while (hdr.falcon_id != WPR_HEADER_V0_FALCON_ID_INVALID);\n\n\treturn 0;\n}\n\nvoid\ngm200_acr_wpr_build_lsb_tail(struct nvkm_acr_lsfw *lsfw,\n\t\t\t     struct lsb_header_tail *hdr)\n{\n\thdr->ucode_off = lsfw->offset.img;\n\thdr->ucode_size = lsfw->ucode_size;\n\thdr->data_size = lsfw->data_size;\n\thdr->bl_code_size = lsfw->bootloader_size;\n\thdr->bl_imem_off = lsfw->bootloader_imem_offset;\n\thdr->bl_data_off = lsfw->offset.bld;\n\thdr->bl_data_size = lsfw->bl_data_size;\n\thdr->app_code_off = lsfw->app_start_offset +\n\t\t\t   lsfw->app_resident_code_offset;\n\thdr->app_code_size = lsfw->app_resident_code_size;\n\thdr->app_data_off = lsfw->app_start_offset +\n\t\t\t   lsfw->app_resident_data_offset;\n\thdr->app_data_size = lsfw->app_resident_data_size;\n\thdr->flags = lsfw->func->flags;\n}\n\nstatic int\ngm200_acr_wpr_build_lsb(struct nvkm_acr *acr, struct nvkm_acr_lsfw *lsfw)\n{\n\tstruct lsb_header hdr;\n\n\tif (WARN_ON(lsfw->sig->size != sizeof(hdr.signature)))\n\t\treturn -EINVAL;\n\n\tmemcpy(&hdr.signature, lsfw->sig->data, lsfw->sig->size);\n\tgm200_acr_wpr_build_lsb_tail(lsfw, &hdr.tail);\n\n\tnvkm_wobj(acr->wpr, lsfw->offset.lsb, &hdr, sizeof(hdr));\n\treturn 0;\n}\n\nint\ngm200_acr_wpr_build(struct nvkm_acr *acr, struct nvkm_acr_lsf *rtos)\n{\n\tstruct nvkm_acr_lsfw *lsfw;\n\tu32 offset = 0;\n\tint ret;\n\n\t \n\tlist_for_each_entry(lsfw, &acr->lsfw, head) {\n\t\tstruct wpr_header hdr = {\n\t\t\t.falcon_id = lsfw->id,\n\t\t\t.lsb_offset = lsfw->offset.lsb,\n\t\t\t.bootstrap_owner = NVKM_ACR_LSF_PMU,\n\t\t\t.lazy_bootstrap = rtos && lsfw->id != rtos->id,\n\t\t\t.status = WPR_HEADER_V0_STATUS_COPY,\n\t\t};\n\n\t\t \n\t\tnvkm_wobj(acr->wpr, offset, &hdr, sizeof(hdr));\n\t\toffset += sizeof(hdr);\n\n\t\t \n\t\tret = gm200_acr_wpr_build_lsb(acr, lsfw);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t \n\t\tnvkm_wobj(acr->wpr, lsfw->offset.img,\n\t\t\t\t    lsfw->img.data,\n\t\t\t\t    lsfw->img.size);\n\n\t\t \n\t\tlsfw->func->bld_write(acr, lsfw->offset.bld, lsfw);\n\t}\n\n\t \n\tnvkm_wo32(acr->wpr, offset, WPR_HEADER_V0_FALCON_ID_INVALID);\n\treturn 0;\n}\n\nstatic int\ngm200_acr_wpr_alloc(struct nvkm_acr *acr, u32 wpr_size)\n{\n\tint ret = nvkm_memory_new(acr->subdev.device, NVKM_MEM_TARGET_INST,\n\t\t\t\t  ALIGN(wpr_size, 0x40000), 0x40000, true,\n\t\t\t\t  &acr->wpr);\n\tif (ret)\n\t\treturn ret;\n\n\tacr->wpr_start = nvkm_memory_addr(acr->wpr);\n\tacr->wpr_end = acr->wpr_start + nvkm_memory_size(acr->wpr);\n\treturn 0;\n}\n\nu32\ngm200_acr_wpr_layout(struct nvkm_acr *acr)\n{\n\tstruct nvkm_acr_lsfw *lsfw;\n\tu32 wpr = 0;\n\n\twpr += 11   * sizeof(struct wpr_header);\n\n\tlist_for_each_entry(lsfw, &acr->lsfw, head) {\n\t\twpr  = ALIGN(wpr, 256);\n\t\tlsfw->offset.lsb = wpr;\n\t\twpr += sizeof(struct lsb_header);\n\n\t\twpr  = ALIGN(wpr, 4096);\n\t\tlsfw->offset.img = wpr;\n\t\twpr += lsfw->img.size;\n\n\t\twpr  = ALIGN(wpr, 256);\n\t\tlsfw->offset.bld = wpr;\n\t\tlsfw->bl_data_size = ALIGN(lsfw->func->bld_size, 256);\n\t\twpr += lsfw->bl_data_size;\n\t}\n\n\treturn wpr;\n}\n\nint\ngm200_acr_wpr_parse(struct nvkm_acr *acr)\n{\n\tconst struct wpr_header *hdr = (void *)acr->wpr_fw->data;\n\tstruct nvkm_acr_lsfw *lsfw;\n\n\twhile (hdr->falcon_id != WPR_HEADER_V0_FALCON_ID_INVALID) {\n\t\twpr_header_dump(&acr->subdev, hdr);\n\t\tlsfw = nvkm_acr_lsfw_add(NULL, acr, NULL, (hdr++)->falcon_id);\n\t\tif (IS_ERR(lsfw))\n\t\t\treturn PTR_ERR(lsfw);\n\t}\n\n\treturn 0;\n}\n\nint\ngm200_acr_hsfw_load_bld(struct nvkm_falcon_fw *fw)\n{\n\tstruct flcn_bl_dmem_desc_v1 hsdesc = {\n\t\t.ctx_dma = FALCON_DMAIDX_VIRT,\n\t\t.code_dma_base = fw->vma->addr,\n\t\t.non_sec_code_off = fw->nmem_base,\n\t\t.non_sec_code_size = fw->nmem_size,\n\t\t.sec_code_off = fw->imem_base,\n\t\t.sec_code_size = fw->imem_size,\n\t\t.code_entry_point = 0,\n\t\t.data_dma_base = fw->vma->addr + fw->dmem_base_img,\n\t\t.data_size = fw->dmem_size,\n\t};\n\n\tflcn_bl_dmem_desc_v1_dump(fw->falcon->user, &hsdesc);\n\n\treturn nvkm_falcon_pio_wr(fw->falcon, (u8 *)&hsdesc, 0, 0, DMEM, 0, sizeof(hsdesc), 0, 0);\n}\n\nint\ngm200_acr_hsfw_ctor(struct nvkm_acr *acr, const char *bl, const char *fw, const char *name, int ver,\n\t\t    const struct nvkm_acr_hsf_fwif *fwif)\n{\n\tstruct nvkm_acr_hsfw *hsfw;\n\n\tif (!(hsfw = kzalloc(sizeof(*hsfw), GFP_KERNEL)))\n\t\treturn -ENOMEM;\n\n\thsfw->falcon_id = fwif->falcon_id;\n\thsfw->boot_mbox0 = fwif->boot_mbox0;\n\thsfw->intr_clear = fwif->intr_clear;\n\tlist_add_tail(&hsfw->head, &acr->hsfw);\n\n\treturn nvkm_falcon_fw_ctor_hs(fwif->func, name, &acr->subdev, bl, fw, ver, NULL, &hsfw->fw);\n}\n\nconst struct nvkm_falcon_fw_func\ngm200_acr_unload_0 = {\n\t.signature = gm200_flcn_fw_signature,\n\t.reset = gm200_flcn_fw_reset,\n\t.load = gm200_flcn_fw_load,\n\t.load_bld = gm200_acr_hsfw_load_bld,\n\t.boot = gm200_flcn_fw_boot,\n};\n\nMODULE_FIRMWARE(\"nvidia/gm200/acr/ucode_unload.bin\");\nMODULE_FIRMWARE(\"nvidia/gm204/acr/ucode_unload.bin\");\nMODULE_FIRMWARE(\"nvidia/gm206/acr/ucode_unload.bin\");\nMODULE_FIRMWARE(\"nvidia/gp100/acr/ucode_unload.bin\");\n\nstatic const struct nvkm_acr_hsf_fwif\ngm200_acr_unload_fwif[] = {\n\t{ 0, gm200_acr_hsfw_ctor, &gm200_acr_unload_0, NVKM_ACR_HSF_PMU, 0, 0x00000010 },\n\t{}\n};\n\nstatic int\ngm200_acr_load_setup(struct nvkm_falcon_fw *fw)\n{\n\tstruct flcn_acr_desc *desc = (void *)&fw->fw.img[fw->dmem_base_img];\n\tstruct nvkm_acr *acr = fw->falcon->owner->device->acr;\n\n\tdesc->wpr_region_id = 1;\n\tdesc->regions.no_regions = 2;\n\tdesc->regions.region_props[0].start_addr = acr->wpr_start >> 8;\n\tdesc->regions.region_props[0].end_addr = acr->wpr_end >> 8;\n\tdesc->regions.region_props[0].region_id = 1;\n\tdesc->regions.region_props[0].read_mask = 0xf;\n\tdesc->regions.region_props[0].write_mask = 0xc;\n\tdesc->regions.region_props[0].client_mask = 0x2;\n\tflcn_acr_desc_dump(&acr->subdev, desc);\n\treturn 0;\n}\n\nstatic const struct nvkm_falcon_fw_func\ngm200_acr_load_0 = {\n\t.signature = gm200_flcn_fw_signature,\n\t.reset = gm200_flcn_fw_reset,\n\t.setup = gm200_acr_load_setup,\n\t.load = gm200_flcn_fw_load,\n\t.load_bld = gm200_acr_hsfw_load_bld,\n\t.boot = gm200_flcn_fw_boot,\n};\n\nMODULE_FIRMWARE(\"nvidia/gm200/acr/bl.bin\");\nMODULE_FIRMWARE(\"nvidia/gm200/acr/ucode_load.bin\");\n\nMODULE_FIRMWARE(\"nvidia/gm204/acr/bl.bin\");\nMODULE_FIRMWARE(\"nvidia/gm204/acr/ucode_load.bin\");\n\nMODULE_FIRMWARE(\"nvidia/gm206/acr/bl.bin\");\nMODULE_FIRMWARE(\"nvidia/gm206/acr/ucode_load.bin\");\n\nMODULE_FIRMWARE(\"nvidia/gp100/acr/bl.bin\");\nMODULE_FIRMWARE(\"nvidia/gp100/acr/ucode_load.bin\");\n\nstatic const struct nvkm_acr_hsf_fwif\ngm200_acr_load_fwif[] = {\n\t{ 0, gm200_acr_hsfw_ctor, &gm200_acr_load_0, NVKM_ACR_HSF_PMU, 0, 0x00000010 },\n\t{}\n};\n\nstatic const struct nvkm_acr_func\ngm200_acr_0 = {\n\t.load = gm200_acr_load_fwif,\n\t.unload = gm200_acr_unload_fwif,\n\t.wpr_parse = gm200_acr_wpr_parse,\n\t.wpr_layout = gm200_acr_wpr_layout,\n\t.wpr_alloc = gm200_acr_wpr_alloc,\n\t.wpr_build = gm200_acr_wpr_build,\n\t.wpr_patch = gm200_acr_wpr_patch,\n\t.wpr_check = gm200_acr_wpr_check,\n\t.init = gm200_acr_init,\n\t.bootstrap_falcons = BIT_ULL(NVKM_ACR_LSF_FECS) |\n\t\t\t     BIT_ULL(NVKM_ACR_LSF_GPCCS),\n};\n\nstatic int\ngm200_acr_load(struct nvkm_acr *acr, int ver, const struct nvkm_acr_fwif *fwif)\n{\n\tstruct nvkm_subdev *subdev = &acr->subdev;\n\tconst struct nvkm_acr_hsf_fwif *hsfwif;\n\n\thsfwif = nvkm_firmware_load(subdev, fwif->func->load, \"AcrLoad\",\n\t\t\t\t    acr, \"acr/bl\", \"acr/ucode_load\", \"load\");\n\tif (IS_ERR(hsfwif))\n\t\treturn PTR_ERR(hsfwif);\n\n\thsfwif = nvkm_firmware_load(subdev, fwif->func->unload, \"AcrUnload\",\n\t\t\t\t    acr, \"acr/bl\", \"acr/ucode_unload\",\n\t\t\t\t    \"unload\");\n\tif (IS_ERR(hsfwif))\n\t\treturn PTR_ERR(hsfwif);\n\n\treturn 0;\n}\n\nstatic const struct nvkm_acr_fwif\ngm200_acr_fwif[] = {\n\t{  0, gm200_acr_load, &gm200_acr_0 },\n\t{ -1, gm200_acr_nofw, &gm200_acr },\n\t{}\n};\n\nint\ngm200_acr_new(struct nvkm_device *device, enum nvkm_subdev_type type, int inst,\n\t      struct nvkm_acr **pacr)\n{\n\treturn nvkm_acr_new_(gm200_acr_fwif, device, type, inst, pacr);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}