{
  "module_name": "gp102.c",
  "hash_id": "b307d8bd4c19c99b7696f6cee3a2117a24269c3fe8d6102a4603fc400e5c62bd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/nouveau/nvkm/engine/sec2/gp102.c",
  "human_readable_source": " \n#include \"priv.h\"\n\n#include <core/memory.h>\n#include <subdev/acr.h>\n#include <subdev/timer.h>\n\n#include <nvfw/flcn.h>\n#include <nvfw/sec2.h>\n\nint\ngp102_sec2_nofw(struct nvkm_sec2 *sec2, int ver,\n\t\tconst struct nvkm_sec2_fwif *fwif)\n{\n\tnvkm_warn(&sec2->engine.subdev, \"firmware unavailable\\n\");\n\treturn 0;\n}\n\nstatic int\ngp102_sec2_acr_bootstrap_falcon_callback(void *priv, struct nvfw_falcon_msg *hdr)\n{\n\tstruct nv_sec2_acr_bootstrap_falcon_msg *msg =\n\t\tcontainer_of(hdr, typeof(*msg), msg.hdr);\n\tstruct nvkm_subdev *subdev = priv;\n\tconst char *name = nvkm_acr_lsf_id(msg->falcon_id);\n\n\tif (msg->error_code) {\n\t\tnvkm_error(subdev, \"ACR_BOOTSTRAP_FALCON failed for \"\n\t\t\t\t   \"falcon %d [%s]: %08x\\n\",\n\t\t\t   msg->falcon_id, name, msg->error_code);\n\t\treturn -EINVAL;\n\t}\n\n\tnvkm_debug(subdev, \"%s booted\\n\", name);\n\treturn 0;\n}\n\nstatic int\ngp102_sec2_acr_bootstrap_falcon(struct nvkm_falcon *falcon,\n\t\t\t        enum nvkm_acr_lsf_id id)\n{\n\tstruct nvkm_sec2 *sec2 = container_of(falcon, typeof(*sec2), falcon);\n\tstruct nv_sec2_acr_bootstrap_falcon_cmd cmd = {\n\t\t.cmd.hdr.unit_id = sec2->func->unit_acr,\n\t\t.cmd.hdr.size = sizeof(cmd),\n\t\t.cmd.cmd_type = NV_SEC2_ACR_CMD_BOOTSTRAP_FALCON,\n\t\t.flags = NV_SEC2_ACR_BOOTSTRAP_FALCON_FLAGS_RESET_YES,\n\t\t.falcon_id = id,\n\t};\n\n\treturn nvkm_falcon_cmdq_send(sec2->cmdq, &cmd.cmd.hdr,\n\t\t\t\t     gp102_sec2_acr_bootstrap_falcon_callback,\n\t\t\t\t     &sec2->engine.subdev,\n\t\t\t\t     msecs_to_jiffies(1000));\n}\n\nstatic void\ngp102_sec2_acr_bld_patch(struct nvkm_acr *acr, u32 bld, s64 adjust)\n{\n\tstruct loader_config_v1 hdr;\n\tnvkm_robj(acr->wpr, bld, &hdr, sizeof(hdr));\n\thdr.code_dma_base = hdr.code_dma_base + adjust;\n\thdr.data_dma_base = hdr.data_dma_base + adjust;\n\thdr.overlay_dma_base = hdr.overlay_dma_base + adjust;\n\tnvkm_wobj(acr->wpr, bld, &hdr, sizeof(hdr));\n\tloader_config_v1_dump(&acr->subdev, &hdr);\n}\n\nstatic void\ngp102_sec2_acr_bld_write(struct nvkm_acr *acr, u32 bld,\n\t\t\t struct nvkm_acr_lsfw *lsfw)\n{\n\tconst struct loader_config_v1 hdr = {\n\t\t.dma_idx = FALCON_SEC2_DMAIDX_UCODE,\n\t\t.code_dma_base = lsfw->offset.img + lsfw->app_start_offset,\n\t\t.code_size_total = lsfw->app_size,\n\t\t.code_size_to_load = lsfw->app_resident_code_size,\n\t\t.code_entry_point = lsfw->app_imem_entry,\n\t\t.data_dma_base = lsfw->offset.img + lsfw->app_start_offset +\n\t\t\t\t lsfw->app_resident_data_offset,\n\t\t.data_size = lsfw->app_resident_data_size,\n\t\t.overlay_dma_base = lsfw->offset.img + lsfw->app_start_offset,\n\t\t.argc = 1,\n\t\t.argv = lsfw->falcon->func->emem_addr,\n\t};\n\n\tnvkm_wobj(acr->wpr, bld, &hdr, sizeof(hdr));\n}\n\nstatic const struct nvkm_acr_lsf_func\ngp102_sec2_acr_0 = {\n\t.bld_size = sizeof(struct loader_config_v1),\n\t.bld_write = gp102_sec2_acr_bld_write,\n\t.bld_patch = gp102_sec2_acr_bld_patch,\n\t.bootstrap_falcons = BIT_ULL(NVKM_ACR_LSF_FECS) |\n\t\t\t     BIT_ULL(NVKM_ACR_LSF_GPCCS) |\n\t\t\t     BIT_ULL(NVKM_ACR_LSF_SEC2),\n\t.bootstrap_falcon = gp102_sec2_acr_bootstrap_falcon,\n};\n\nint\ngp102_sec2_initmsg(struct nvkm_sec2 *sec2)\n{\n\tstruct nv_sec2_init_msg msg;\n\tint ret, i;\n\n\tret = nvkm_falcon_msgq_recv_initmsg(sec2->msgq, &msg, sizeof(msg));\n\tif (ret)\n\t\treturn ret;\n\n\tif (msg.hdr.unit_id != NV_SEC2_UNIT_INIT ||\n\t    msg.msg_type != NV_SEC2_INIT_MSG_INIT)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < ARRAY_SIZE(msg.queue_info); i++) {\n\t\tif (msg.queue_info[i].id == NV_SEC2_INIT_MSG_QUEUE_ID_MSGQ) {\n\t\t\tnvkm_falcon_msgq_init(sec2->msgq,\n\t\t\t\t\t      msg.queue_info[i].index,\n\t\t\t\t\t      msg.queue_info[i].offset,\n\t\t\t\t\t      msg.queue_info[i].size);\n\t\t} else {\n\t\t\tnvkm_falcon_cmdq_init(sec2->cmdq,\n\t\t\t\t\t      msg.queue_info[i].index,\n\t\t\t\t\t      msg.queue_info[i].offset,\n\t\t\t\t\t      msg.queue_info[i].size);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nirqreturn_t\ngp102_sec2_intr(struct nvkm_inth *inth)\n{\n\tstruct nvkm_sec2 *sec2 = container_of(inth, typeof(*sec2), engine.subdev.inth);\n\tstruct nvkm_subdev *subdev = &sec2->engine.subdev;\n\tstruct nvkm_falcon *falcon = &sec2->falcon;\n\tu32 disp = nvkm_falcon_rd32(falcon, 0x01c);\n\tu32 intr = nvkm_falcon_rd32(falcon, 0x008) & disp & ~(disp >> 16);\n\n\tif (intr & 0x00000040) {\n\t\tif (unlikely(atomic_read(&sec2->initmsg) == 0)) {\n\t\t\tint ret = sec2->func->initmsg(sec2);\n\n\t\t\tif (ret)\n\t\t\t\tnvkm_error(subdev, \"error parsing init message: %d\\n\", ret);\n\n\t\t\tatomic_set(&sec2->initmsg, ret ?: 1);\n\t\t}\n\n\t\tif (atomic_read(&sec2->initmsg) > 0) {\n\t\t\tif (!nvkm_falcon_msgq_empty(sec2->msgq))\n\t\t\t\tnvkm_falcon_msgq_recv(sec2->msgq);\n\t\t}\n\n\t\tnvkm_falcon_wr32(falcon, 0x004, 0x00000040);\n\t\tintr &= ~0x00000040;\n\t}\n\n\tif (intr & 0x00000010) {\n\t\tif (atomic_read(&sec2->running)) {\n\t\t\tFLCN_ERR(falcon, \"halted\");\n\t\t\tgm200_flcn_tracepc(falcon);\n\t\t}\n\n\t\tnvkm_falcon_wr32(falcon, 0x004, 0x00000010);\n\t\tintr &= ~0x00000010;\n\t}\n\n\tif (intr) {\n\t\tnvkm_error(subdev, \"unhandled intr %08x\\n\", intr);\n\t\tnvkm_falcon_wr32(falcon, 0x004, intr);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic const struct nvkm_falcon_func\ngp102_sec2_flcn = {\n\t.disable = gm200_flcn_disable,\n\t.enable = gm200_flcn_enable,\n\t.reset_pmc = true,\n\t.reset_eng = gp102_flcn_reset_eng,\n\t.reset_wait_mem_scrubbing = gm200_flcn_reset_wait_mem_scrubbing,\n\t.debug = 0x408,\n\t.bind_inst = gm200_flcn_bind_inst,\n\t.bind_stat = gm200_flcn_bind_stat,\n\t.bind_intr = true,\n\t.imem_pio = &gm200_flcn_imem_pio,\n\t.dmem_pio = &gm200_flcn_dmem_pio,\n\t.emem_addr = 0x01000000,\n\t.emem_pio = &gp102_flcn_emem_pio,\n\t.start = nvkm_falcon_v1_start,\n\t.cmdq = { 0xa00, 0xa04, 8 },\n\t.msgq = { 0xa30, 0xa34, 8 },\n};\n\nconst struct nvkm_sec2_func\ngp102_sec2 = {\n\t.flcn = &gp102_sec2_flcn,\n\t.unit_unload = NV_SEC2_UNIT_UNLOAD,\n\t.unit_acr = NV_SEC2_UNIT_ACR,\n\t.intr = gp102_sec2_intr,\n\t.initmsg = gp102_sec2_initmsg,\n};\n\nMODULE_FIRMWARE(\"nvidia/gp102/sec2/desc.bin\");\nMODULE_FIRMWARE(\"nvidia/gp102/sec2/image.bin\");\nMODULE_FIRMWARE(\"nvidia/gp102/sec2/sig.bin\");\nMODULE_FIRMWARE(\"nvidia/gp104/sec2/desc.bin\");\nMODULE_FIRMWARE(\"nvidia/gp104/sec2/image.bin\");\nMODULE_FIRMWARE(\"nvidia/gp104/sec2/sig.bin\");\nMODULE_FIRMWARE(\"nvidia/gp106/sec2/desc.bin\");\nMODULE_FIRMWARE(\"nvidia/gp106/sec2/image.bin\");\nMODULE_FIRMWARE(\"nvidia/gp106/sec2/sig.bin\");\nMODULE_FIRMWARE(\"nvidia/gp107/sec2/desc.bin\");\nMODULE_FIRMWARE(\"nvidia/gp107/sec2/image.bin\");\nMODULE_FIRMWARE(\"nvidia/gp107/sec2/sig.bin\");\n\nvoid\ngp102_sec2_acr_bld_patch_1(struct nvkm_acr *acr, u32 bld, s64 adjust)\n{\n\tstruct flcn_bl_dmem_desc_v2 hdr;\n\tnvkm_robj(acr->wpr, bld, &hdr, sizeof(hdr));\n\thdr.code_dma_base = hdr.code_dma_base + adjust;\n\thdr.data_dma_base = hdr.data_dma_base + adjust;\n\tnvkm_wobj(acr->wpr, bld, &hdr, sizeof(hdr));\n\tflcn_bl_dmem_desc_v2_dump(&acr->subdev, &hdr);\n}\n\nvoid\ngp102_sec2_acr_bld_write_1(struct nvkm_acr *acr, u32 bld,\n\t\t\t   struct nvkm_acr_lsfw *lsfw)\n{\n\tconst struct flcn_bl_dmem_desc_v2 hdr = {\n\t\t.ctx_dma = FALCON_SEC2_DMAIDX_UCODE,\n\t\t.code_dma_base = lsfw->offset.img + lsfw->app_start_offset,\n\t\t.non_sec_code_off = lsfw->app_resident_code_offset,\n\t\t.non_sec_code_size = lsfw->app_resident_code_size,\n\t\t.code_entry_point = lsfw->app_imem_entry,\n\t\t.data_dma_base = lsfw->offset.img + lsfw->app_start_offset +\n\t\t\t\t lsfw->app_resident_data_offset,\n\t\t.data_size = lsfw->app_resident_data_size,\n\t\t.argc = 1,\n\t\t.argv = lsfw->falcon->func->emem_addr,\n\t};\n\n\tnvkm_wobj(acr->wpr, bld, &hdr, sizeof(hdr));\n}\n\nconst struct nvkm_acr_lsf_func\ngp102_sec2_acr_1 = {\n\t.bld_size = sizeof(struct flcn_bl_dmem_desc_v2),\n\t.bld_write = gp102_sec2_acr_bld_write_1,\n\t.bld_patch = gp102_sec2_acr_bld_patch_1,\n\t.bootstrap_falcons = BIT_ULL(NVKM_ACR_LSF_FECS) |\n\t\t\t     BIT_ULL(NVKM_ACR_LSF_GPCCS) |\n\t\t\t     BIT_ULL(NVKM_ACR_LSF_SEC2),\n\t.bootstrap_falcon = gp102_sec2_acr_bootstrap_falcon,\n};\n\nint\ngp102_sec2_load(struct nvkm_sec2 *sec2, int ver,\n\t\tconst struct nvkm_sec2_fwif *fwif)\n{\n\treturn nvkm_acr_lsfw_load_sig_image_desc_v1(&sec2->engine.subdev,\n\t\t\t\t\t\t    &sec2->falcon,\n\t\t\t\t\t\t    NVKM_ACR_LSF_SEC2, \"sec2/\",\n\t\t\t\t\t\t    ver, fwif->acr);\n}\n\nMODULE_FIRMWARE(\"nvidia/gp102/sec2/desc-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp102/sec2/image-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp102/sec2/sig-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp104/sec2/desc-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp104/sec2/image-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp104/sec2/sig-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp106/sec2/desc-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp106/sec2/image-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp106/sec2/sig-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp107/sec2/desc-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp107/sec2/image-1.bin\");\nMODULE_FIRMWARE(\"nvidia/gp107/sec2/sig-1.bin\");\n\nstatic const struct nvkm_sec2_fwif\ngp102_sec2_fwif[] = {\n\t{  1, gp102_sec2_load, &gp102_sec2, &gp102_sec2_acr_1 },\n\t{  0, gp102_sec2_load, &gp102_sec2, &gp102_sec2_acr_0 },\n\t{ -1, gp102_sec2_nofw, &gp102_sec2 },\n\t{}\n};\n\nint\ngp102_sec2_new(struct nvkm_device *device, enum nvkm_subdev_type type, int inst,\n\t       struct nvkm_sec2 **psec2)\n{\n\treturn nvkm_sec2_new_(gp102_sec2_fwif, device, type, inst, 0, psec2);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}