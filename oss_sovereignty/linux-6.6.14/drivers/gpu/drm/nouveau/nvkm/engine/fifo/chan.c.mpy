{
  "module_name": "chan.c",
  "hash_id": "1b9476eb23fd474d72d618e5eb9de1af59e6e9e0034ebc343c13195b33ba9dad",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/nouveau/nvkm/engine/fifo/chan.c",
  "human_readable_source": " \n#include \"chan.h\"\n#include \"chid.h\"\n#include \"cgrp.h\"\n#include \"chid.h\"\n#include \"runl.h\"\n#include \"priv.h\"\n\n#include <core/ramht.h>\n#include <subdev/mmu.h>\n#include <engine/dma.h>\n\n#include <nvif/if0020.h>\n\nconst struct nvkm_event_func\nnvkm_chan_event = {\n};\n\nvoid\nnvkm_chan_cctx_bind(struct nvkm_chan *chan, struct nvkm_engn *engn, struct nvkm_cctx *cctx)\n{\n\tstruct nvkm_cgrp *cgrp = chan->cgrp;\n\tstruct nvkm_runl *runl = cgrp->runl;\n\tstruct nvkm_engine *engine = engn->engine;\n\n\tif (!engn->func->bind)\n\t\treturn;\n\n\tCHAN_TRACE(chan, \"%sbind cctx %d[%s]\", cctx ? \"\" : \"un\", engn->id, engine->subdev.name);\n\n\t \n\tif (cgrp->hw)\n\t\tnvkm_runl_block(runl);\n\telse\n\t\tnvkm_chan_block(chan);\n\tnvkm_chan_preempt(chan, true);\n\n\t \n\tengn->func->bind(engn, cctx, chan);\n\n\t \n\tif (cgrp->hw)\n\t\tnvkm_runl_allow(runl);\n\telse\n\t\tnvkm_chan_allow(chan);\n}\n\nvoid\nnvkm_chan_cctx_put(struct nvkm_chan *chan, struct nvkm_cctx **pcctx)\n{\n\tstruct nvkm_cctx *cctx = *pcctx;\n\n\tif (cctx) {\n\t\tstruct nvkm_engn *engn = cctx->vctx->ectx->engn;\n\n\t\tif (refcount_dec_and_mutex_lock(&cctx->refs, &chan->cgrp->mutex)) {\n\t\t\tCHAN_TRACE(chan, \"dtor cctx %d[%s]\", engn->id, engn->engine->subdev.name);\n\t\t\tnvkm_cgrp_vctx_put(chan->cgrp, &cctx->vctx);\n\t\t\tlist_del(&cctx->head);\n\t\t\tkfree(cctx);\n\t\t\tmutex_unlock(&chan->cgrp->mutex);\n\t\t}\n\n\t\t*pcctx = NULL;\n\t}\n}\n\nint\nnvkm_chan_cctx_get(struct nvkm_chan *chan, struct nvkm_engn *engn, struct nvkm_cctx **pcctx,\n\t\t   struct nvkm_client *client)\n{\n\tstruct nvkm_cgrp *cgrp = chan->cgrp;\n\tstruct nvkm_vctx *vctx;\n\tstruct nvkm_cctx *cctx;\n\tint ret;\n\n\t \n\tmutex_lock(&cgrp->mutex);\n\tcctx = nvkm_list_find(cctx, &chan->cctxs, head,\n\t\t\t      cctx->vctx->ectx->engn == engn && cctx->vctx->vmm == chan->vmm);\n\tif (cctx) {\n\t\trefcount_inc(&cctx->refs);\n\t\t*pcctx = cctx;\n\t\tmutex_unlock(&chan->cgrp->mutex);\n\t\treturn 0;\n\t}\n\n\t \n\tret = nvkm_cgrp_vctx_get(cgrp, engn, chan, &vctx, client);\n\tif (ret) {\n\t\tCHAN_ERROR(chan, \"vctx %d[%s]: %d\", engn->id, engn->engine->subdev.name, ret);\n\t\tgoto done;\n\t}\n\n\t \n\tCHAN_TRACE(chan, \"ctor cctx %d[%s]\", engn->id, engn->engine->subdev.name);\n\tif (!(cctx = *pcctx = kzalloc(sizeof(*cctx), GFP_KERNEL))) {\n\t\tnvkm_cgrp_vctx_put(cgrp, &vctx);\n\t\tret = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\tcctx->vctx = vctx;\n\trefcount_set(&cctx->refs, 1);\n\trefcount_set(&cctx->uses, 0);\n\tlist_add_tail(&cctx->head, &chan->cctxs);\ndone:\n\tmutex_unlock(&cgrp->mutex);\n\treturn ret;\n}\n\nint\nnvkm_chan_preempt_locked(struct nvkm_chan *chan, bool wait)\n{\n\tstruct nvkm_runl *runl = chan->cgrp->runl;\n\n\tCHAN_TRACE(chan, \"preempt\");\n\tchan->func->preempt(chan);\n\tif (!wait)\n\t\treturn 0;\n\n\treturn nvkm_runl_preempt_wait(runl);\n}\n\nint\nnvkm_chan_preempt(struct nvkm_chan *chan, bool wait)\n{\n\tint ret;\n\n\tif (!chan->func->preempt)\n\t\treturn 0;\n\n\tmutex_lock(&chan->cgrp->runl->mutex);\n\tret = nvkm_chan_preempt_locked(chan, wait);\n\tmutex_unlock(&chan->cgrp->runl->mutex);\n\treturn ret;\n}\n\nvoid\nnvkm_chan_remove_locked(struct nvkm_chan *chan)\n{\n\tstruct nvkm_cgrp *cgrp = chan->cgrp;\n\tstruct nvkm_runl *runl = cgrp->runl;\n\n\tif (list_empty(&chan->head))\n\t\treturn;\n\n\tCHAN_TRACE(chan, \"remove\");\n\tif (!--cgrp->chan_nr) {\n\t\trunl->cgrp_nr--;\n\t\tlist_del(&cgrp->head);\n\t}\n\trunl->chan_nr--;\n\tlist_del_init(&chan->head);\n\tatomic_set(&runl->changed, 1);\n}\n\nvoid\nnvkm_chan_remove(struct nvkm_chan *chan, bool preempt)\n{\n\tstruct nvkm_runl *runl = chan->cgrp->runl;\n\n\tmutex_lock(&runl->mutex);\n\tif (preempt && chan->func->preempt)\n\t\tnvkm_chan_preempt_locked(chan, true);\n\tnvkm_chan_remove_locked(chan);\n\tnvkm_runl_update_locked(runl, true);\n\tmutex_unlock(&runl->mutex);\n}\n\nvoid\nnvkm_chan_insert(struct nvkm_chan *chan)\n{\n\tstruct nvkm_cgrp *cgrp = chan->cgrp;\n\tstruct nvkm_runl *runl = cgrp->runl;\n\n\tmutex_lock(&runl->mutex);\n\tif (WARN_ON(!list_empty(&chan->head))) {\n\t\tmutex_unlock(&runl->mutex);\n\t\treturn;\n\t}\n\n\tCHAN_TRACE(chan, \"insert\");\n\tlist_add_tail(&chan->head, &cgrp->chans);\n\trunl->chan_nr++;\n\tif (!cgrp->chan_nr++) {\n\t\tlist_add_tail(&cgrp->head, &cgrp->runl->cgrps);\n\t\trunl->cgrp_nr++;\n\t}\n\tatomic_set(&runl->changed, 1);\n\tnvkm_runl_update_locked(runl, true);\n\tmutex_unlock(&runl->mutex);\n}\n\nstatic void\nnvkm_chan_block_locked(struct nvkm_chan *chan)\n{\n\tCHAN_TRACE(chan, \"block %d\", atomic_read(&chan->blocked));\n\tif (atomic_inc_return(&chan->blocked) == 1)\n\t\tchan->func->stop(chan);\n}\n\nvoid\nnvkm_chan_error(struct nvkm_chan *chan, bool preempt)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&chan->lock, flags);\n\tif (atomic_inc_return(&chan->errored) == 1) {\n\t\tCHAN_ERROR(chan, \"errored - disabling channel\");\n\t\tnvkm_chan_block_locked(chan);\n\t\tif (preempt)\n\t\t\tchan->func->preempt(chan);\n\t\tnvkm_event_ntfy(&chan->cgrp->runl->chid->event, chan->id, NVKM_CHAN_EVENT_ERRORED);\n\t}\n\tspin_unlock_irqrestore(&chan->lock, flags);\n}\n\nvoid\nnvkm_chan_block(struct nvkm_chan *chan)\n{\n\tspin_lock_irq(&chan->lock);\n\tnvkm_chan_block_locked(chan);\n\tspin_unlock_irq(&chan->lock);\n}\n\nvoid\nnvkm_chan_allow(struct nvkm_chan *chan)\n{\n\tspin_lock_irq(&chan->lock);\n\tCHAN_TRACE(chan, \"allow %d\", atomic_read(&chan->blocked));\n\tif (atomic_dec_and_test(&chan->blocked))\n\t\tchan->func->start(chan);\n\tspin_unlock_irq(&chan->lock);\n}\n\nvoid\nnvkm_chan_del(struct nvkm_chan **pchan)\n{\n\tstruct nvkm_chan *chan = *pchan;\n\n\tif (!chan)\n\t\treturn;\n\n\tif (chan->func->ramfc->clear)\n\t\tchan->func->ramfc->clear(chan);\n\n\tnvkm_ramht_del(&chan->ramht);\n\tnvkm_gpuobj_del(&chan->pgd);\n\tnvkm_gpuobj_del(&chan->eng);\n\tnvkm_gpuobj_del(&chan->cache);\n\tnvkm_gpuobj_del(&chan->ramfc);\n\n\tnvkm_memory_unref(&chan->userd.mem);\n\n\tif (chan->cgrp) {\n\t\tnvkm_chid_put(chan->cgrp->runl->chid, chan->id, &chan->cgrp->lock);\n\t\tnvkm_cgrp_unref(&chan->cgrp);\n\t}\n\n\tif (chan->vmm) {\n\t\tnvkm_vmm_part(chan->vmm, chan->inst->memory);\n\t\tnvkm_vmm_unref(&chan->vmm);\n\t}\n\n\tnvkm_gpuobj_del(&chan->push);\n\tnvkm_gpuobj_del(&chan->inst);\n\tkfree(chan);\n}\n\nvoid\nnvkm_chan_put(struct nvkm_chan **pchan, unsigned long irqflags)\n{\n\tstruct nvkm_chan *chan = *pchan;\n\n\tif (!chan)\n\t\treturn;\n\n\t*pchan = NULL;\n\tspin_unlock_irqrestore(&chan->cgrp->lock, irqflags);\n}\n\nstruct nvkm_chan *\nnvkm_chan_get_inst(struct nvkm_engine *engine, u64 inst, unsigned long *pirqflags)\n{\n\tstruct nvkm_fifo *fifo = engine->subdev.device->fifo;\n\tstruct nvkm_runl *runl;\n\tstruct nvkm_engn *engn;\n\tstruct nvkm_chan *chan;\n\n\tnvkm_runl_foreach(runl, fifo) {\n\t\tnvkm_runl_foreach_engn(engn, runl) {\n\t\t\tif (engine == &fifo->engine || engn->engine == engine) {\n\t\t\t\tchan = nvkm_runl_chan_get_inst(runl, inst, pirqflags);\n\t\t\t\tif (chan || engn->engine == engine)\n\t\t\t\t\treturn chan;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstruct nvkm_chan *\nnvkm_chan_get_chid(struct nvkm_engine *engine, int id, unsigned long *pirqflags)\n{\n\tstruct nvkm_fifo *fifo = engine->subdev.device->fifo;\n\tstruct nvkm_runl *runl;\n\tstruct nvkm_engn *engn;\n\n\tnvkm_runl_foreach(runl, fifo) {\n\t\tnvkm_runl_foreach_engn(engn, runl) {\n\t\t\tif (fifo->chid || engn->engine == engine)\n\t\t\t\treturn nvkm_runl_chan_get_chid(runl, id, pirqflags);\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nint\nnvkm_chan_new_(const struct nvkm_chan_func *func, struct nvkm_runl *runl, int runq,\n\t       struct nvkm_cgrp *cgrp, const char *name, bool priv, u32 devm, struct nvkm_vmm *vmm,\n\t       struct nvkm_dmaobj *dmaobj, u64 offset, u64 length,\n\t       struct nvkm_memory *userd, u64 ouserd, struct nvkm_chan **pchan)\n{\n\tstruct nvkm_fifo *fifo = runl->fifo;\n\tstruct nvkm_device *device = fifo->engine.subdev.device;\n\tstruct nvkm_chan *chan;\n\tint ret;\n\n\t \n\tif ((runq && runq >= runl->func->runqs) ||\n\t    (!func->inst->vmm != !vmm) ||\n\t    ((func->userd->bar < 0) == !userd) ||\n\t    (!func->ramfc->ctxdma != !dmaobj) ||\n\t    ((func->ramfc->devm < devm) && devm != BIT(0)) ||\n\t    (!func->ramfc->priv && priv)) {\n\t\tRUNL_DEBUG(runl, \"args runq:%d:%d vmm:%d:%p userd:%d:%p \"\n\t\t\t\t \"push:%d:%p devm:%08x:%08x priv:%d:%d\",\n\t\t\t   runl->func->runqs, runq, func->inst->vmm, vmm,\n\t\t\t   func->userd->bar < 0, userd, func->ramfc->ctxdma, dmaobj,\n\t\t\t   func->ramfc->devm, devm, func->ramfc->priv, priv);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!(chan = *pchan = kzalloc(sizeof(*chan), GFP_KERNEL)))\n\t\treturn -ENOMEM;\n\n\tchan->func = func;\n\tstrscpy(chan->name, name, sizeof(chan->name));\n\tchan->runq = runq;\n\tchan->id = -1;\n\tspin_lock_init(&chan->lock);\n\tatomic_set(&chan->blocked, 1);\n\tatomic_set(&chan->errored, 0);\n\tINIT_LIST_HEAD(&chan->cctxs);\n\tINIT_LIST_HEAD(&chan->head);\n\n\t \n\tif (!cgrp) {\n\t\tret = nvkm_cgrp_new(runl, chan->name, vmm, fifo->func->cgrp.force, &chan->cgrp);\n\t\tif (ret) {\n\t\t\tRUNL_DEBUG(runl, \"cgrp %d\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tcgrp = chan->cgrp;\n\t} else {\n\t\tif (cgrp->runl != runl || cgrp->vmm != vmm) {\n\t\t\tRUNL_DEBUG(runl, \"cgrp %d %d\", cgrp->runl != runl, cgrp->vmm != vmm);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tchan->cgrp = nvkm_cgrp_ref(cgrp);\n\t}\n\n\t \n\tret = nvkm_gpuobj_new(device, func->inst->size, 0x1000, func->inst->zero, NULL,\n\t\t\t      &chan->inst);\n\tif (ret) {\n\t\tRUNL_DEBUG(runl, \"inst %d\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tif (func->inst->vmm) {\n\t\tif (WARN_ON(vmm->mmu != device->mmu))\n\t\t\treturn -EINVAL;\n\n\t\tret = nvkm_vmm_join(vmm, chan->inst->memory);\n\t\tif (ret) {\n\t\t\tRUNL_DEBUG(runl, \"vmm %d\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tchan->vmm = nvkm_vmm_ref(vmm);\n\t}\n\n\t \n\tif (func->ramfc->ctxdma) {\n\t\tret = nvkm_object_bind(&dmaobj->object, chan->inst, -16, &chan->push);\n\t\tif (ret) {\n\t\t\tRUNL_DEBUG(runl, \"bind %d\", ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tchan->id = nvkm_chid_get(runl->chid, chan);\n\tif (chan->id < 0) {\n\t\tRUNL_ERROR(runl, \"!chids\");\n\t\treturn -ENOSPC;\n\t}\n\n\tif (cgrp->id < 0)\n\t\tcgrp->id = chan->id;\n\n\t \n\tif (func->userd->bar < 0) {\n\t\tif (ouserd + chan->func->userd->size >= nvkm_memory_size(userd)) {\n\t\t\tRUNL_DEBUG(runl, \"ouserd %llx\", ouserd);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = nvkm_memory_kmap(userd, &chan->userd.mem);\n\t\tif (ret) {\n\t\t\tRUNL_DEBUG(runl, \"userd %d\", ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tchan->userd.base = ouserd;\n\t} else {\n\t\tchan->userd.mem = nvkm_memory_ref(fifo->userd.mem);\n\t\tchan->userd.base = chan->id * chan->func->userd->size;\n\t}\n\n\tif (chan->func->userd->clear)\n\t\tchan->func->userd->clear(chan);\n\n\t \n\tret = chan->func->ramfc->write(chan, offset, length, devm, priv);\n\tif (ret) {\n\t\tRUNL_DEBUG(runl, \"ramfc %d\", ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}