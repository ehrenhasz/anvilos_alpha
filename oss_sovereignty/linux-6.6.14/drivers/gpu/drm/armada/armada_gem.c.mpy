{
  "module_name": "armada_gem.c",
  "hash_id": "43d236ab301078316ead039af0251abbdbd197b236fbfb357343ffdfa023aac9",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/armada/armada_gem.c",
  "human_readable_source": "\n \n\n#include <linux/dma-buf.h>\n#include <linux/dma-mapping.h>\n#include <linux/mman.h>\n#include <linux/shmem_fs.h>\n\n#include <drm/armada_drm.h>\n#include <drm/drm_prime.h>\n\n#include \"armada_drm.h\"\n#include \"armada_gem.h\"\n#include \"armada_ioctlP.h\"\n\nMODULE_IMPORT_NS(DMA_BUF);\n\nstatic vm_fault_t armada_gem_vm_fault(struct vm_fault *vmf)\n{\n\tstruct drm_gem_object *gobj = vmf->vma->vm_private_data;\n\tstruct armada_gem_object *obj = drm_to_armada_gem(gobj);\n\tunsigned long pfn = obj->phys_addr >> PAGE_SHIFT;\n\n\tpfn += (vmf->address - vmf->vma->vm_start) >> PAGE_SHIFT;\n\treturn vmf_insert_pfn(vmf->vma, vmf->address, pfn);\n}\n\nstatic const struct vm_operations_struct armada_gem_vm_ops = {\n\t.fault\t= armada_gem_vm_fault,\n\t.open\t= drm_gem_vm_open,\n\t.close\t= drm_gem_vm_close,\n};\n\nstatic size_t roundup_gem_size(size_t size)\n{\n\treturn roundup(size, PAGE_SIZE);\n}\n\nvoid armada_gem_free_object(struct drm_gem_object *obj)\n{\n\tstruct armada_gem_object *dobj = drm_to_armada_gem(obj);\n\tstruct armada_private *priv = drm_to_armada_dev(obj->dev);\n\n\tDRM_DEBUG_DRIVER(\"release obj %p\\n\", dobj);\n\n\tdrm_gem_free_mmap_offset(&dobj->obj);\n\n\tmight_lock(&priv->linear_lock);\n\n\tif (dobj->page) {\n\t\t \n\t\tunsigned int order = get_order(dobj->obj.size);\n\t\t__free_pages(dobj->page, order);\n\t} else if (dobj->linear) {\n\t\t \n\t\tmutex_lock(&priv->linear_lock);\n\t\tdrm_mm_remove_node(dobj->linear);\n\t\tmutex_unlock(&priv->linear_lock);\n\t\tkfree(dobj->linear);\n\t\tif (dobj->addr)\n\t\t\tiounmap(dobj->addr);\n\t}\n\n\tif (dobj->obj.import_attach) {\n\t\t \n\t\tif (dobj->sgt)\n\t\t\tdma_buf_unmap_attachment_unlocked(dobj->obj.import_attach,\n\t\t\t\t\t\t\t  dobj->sgt, DMA_TO_DEVICE);\n\t\tdrm_prime_gem_destroy(&dobj->obj, NULL);\n\t}\n\n\tdrm_gem_object_release(&dobj->obj);\n\n\tkfree(dobj);\n}\n\nint\narmada_gem_linear_back(struct drm_device *dev, struct armada_gem_object *obj)\n{\n\tstruct armada_private *priv = drm_to_armada_dev(dev);\n\tsize_t size = obj->obj.size;\n\n\tif (obj->page || obj->linear)\n\t\treturn 0;\n\n\t \n\tif (size <= 8192) {\n\t\tunsigned int order = get_order(size);\n\t\tstruct page *p = alloc_pages(GFP_KERNEL, order);\n\n\t\tif (p) {\n\t\t\tobj->addr = page_address(p);\n\t\t\tobj->phys_addr = page_to_phys(p);\n\t\t\tobj->page = p;\n\n\t\t\tmemset(obj->addr, 0, PAGE_ALIGN(size));\n\t\t}\n\t}\n\n\t \n\n\t \n\tif (!obj->page) {\n\t\tstruct drm_mm_node *node;\n\t\tunsigned align = min_t(unsigned, size, SZ_2M);\n\t\tvoid __iomem *ptr;\n\t\tint ret;\n\n\t\tnode = kzalloc(sizeof(*node), GFP_KERNEL);\n\t\tif (!node)\n\t\t\treturn -ENOSPC;\n\n\t\tmutex_lock(&priv->linear_lock);\n\t\tret = drm_mm_insert_node_generic(&priv->linear, node,\n\t\t\t\t\t\t size, align, 0, 0);\n\t\tmutex_unlock(&priv->linear_lock);\n\t\tif (ret) {\n\t\t\tkfree(node);\n\t\t\treturn ret;\n\t\t}\n\n\t\tobj->linear = node;\n\n\t\t \n\t\tptr = ioremap_wc(obj->linear->start, size);\n\t\tif (!ptr) {\n\t\t\tmutex_lock(&priv->linear_lock);\n\t\t\tdrm_mm_remove_node(obj->linear);\n\t\t\tmutex_unlock(&priv->linear_lock);\n\t\t\tkfree(obj->linear);\n\t\t\tobj->linear = NULL;\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tmemset_io(ptr, 0, size);\n\t\tiounmap(ptr);\n\n\t\tobj->phys_addr = obj->linear->start;\n\t\tobj->dev_addr = obj->linear->start;\n\t\tobj->mapped = true;\n\t}\n\n\tDRM_DEBUG_DRIVER(\"obj %p phys %#llx dev %#llx\\n\", obj,\n\t\t\t (unsigned long long)obj->phys_addr,\n\t\t\t (unsigned long long)obj->dev_addr);\n\n\treturn 0;\n}\n\nvoid *\narmada_gem_map_object(struct drm_device *dev, struct armada_gem_object *dobj)\n{\n\t \n\tif (!dobj->addr && dobj->linear)\n\t\tdobj->addr = ioremap_wc(dobj->phys_addr, dobj->obj.size);\n\treturn dobj->addr;\n}\n\nstatic const struct drm_gem_object_funcs armada_gem_object_funcs = {\n\t.free = armada_gem_free_object,\n\t.export = armada_gem_prime_export,\n\t.vm_ops = &armada_gem_vm_ops,\n};\n\nstruct armada_gem_object *\narmada_gem_alloc_private_object(struct drm_device *dev, size_t size)\n{\n\tstruct armada_gem_object *obj;\n\n\tsize = roundup_gem_size(size);\n\n\tobj = kzalloc(sizeof(*obj), GFP_KERNEL);\n\tif (!obj)\n\t\treturn NULL;\n\n\tobj->obj.funcs = &armada_gem_object_funcs;\n\n\tdrm_gem_private_object_init(dev, &obj->obj, size);\n\n\tDRM_DEBUG_DRIVER(\"alloc private obj %p size %zu\\n\", obj, size);\n\n\treturn obj;\n}\n\nstatic struct armada_gem_object *armada_gem_alloc_object(struct drm_device *dev,\n\tsize_t size)\n{\n\tstruct armada_gem_object *obj;\n\tstruct address_space *mapping;\n\n\tsize = roundup_gem_size(size);\n\n\tobj = kzalloc(sizeof(*obj), GFP_KERNEL);\n\tif (!obj)\n\t\treturn NULL;\n\n\tobj->obj.funcs = &armada_gem_object_funcs;\n\n\tif (drm_gem_object_init(dev, &obj->obj, size)) {\n\t\tkfree(obj);\n\t\treturn NULL;\n\t}\n\n\tmapping = obj->obj.filp->f_mapping;\n\tmapping_set_gfp_mask(mapping, GFP_HIGHUSER | __GFP_RECLAIMABLE);\n\n\tDRM_DEBUG_DRIVER(\"alloc obj %p size %zu\\n\", obj, size);\n\n\treturn obj;\n}\n\n \nint armada_gem_dumb_create(struct drm_file *file, struct drm_device *dev,\n\tstruct drm_mode_create_dumb *args)\n{\n\tstruct armada_gem_object *dobj;\n\tu32 handle;\n\tsize_t size;\n\tint ret;\n\n\targs->pitch = armada_pitch(args->width, args->bpp);\n\targs->size = size = args->pitch * args->height;\n\n\tdobj = armada_gem_alloc_private_object(dev, size);\n\tif (dobj == NULL)\n\t\treturn -ENOMEM;\n\n\tret = armada_gem_linear_back(dev, dobj);\n\tif (ret)\n\t\tgoto err;\n\n\tret = drm_gem_handle_create(file, &dobj->obj, &handle);\n\tif (ret)\n\t\tgoto err;\n\n\targs->handle = handle;\n\n\t \n\tDRM_DEBUG_DRIVER(\"obj %p size %zu handle %#x\\n\", dobj, size, handle);\n err:\n\tdrm_gem_object_put(&dobj->obj);\n\treturn ret;\n}\n\n \nint armada_gem_create_ioctl(struct drm_device *dev, void *data,\n\tstruct drm_file *file)\n{\n\tstruct drm_armada_gem_create *args = data;\n\tstruct armada_gem_object *dobj;\n\tsize_t size;\n\tu32 handle;\n\tint ret;\n\n\tif (args->size == 0)\n\t\treturn -ENOMEM;\n\n\tsize = args->size;\n\n\tdobj = armada_gem_alloc_object(dev, size);\n\tif (dobj == NULL)\n\t\treturn -ENOMEM;\n\n\tret = drm_gem_handle_create(file, &dobj->obj, &handle);\n\tif (ret)\n\t\tgoto err;\n\n\targs->handle = handle;\n\n\t \n\tDRM_DEBUG_DRIVER(\"obj %p size %zu handle %#x\\n\", dobj, size, handle);\n err:\n\tdrm_gem_object_put(&dobj->obj);\n\treturn ret;\n}\n\n \nint armada_gem_mmap_ioctl(struct drm_device *dev, void *data,\n\tstruct drm_file *file)\n{\n\tstruct drm_armada_gem_mmap *args = data;\n\tstruct armada_gem_object *dobj;\n\tunsigned long addr;\n\n\tdobj = armada_gem_object_lookup(file, args->handle);\n\tif (dobj == NULL)\n\t\treturn -ENOENT;\n\n\tif (!dobj->obj.filp) {\n\t\tdrm_gem_object_put(&dobj->obj);\n\t\treturn -EINVAL;\n\t}\n\n\taddr = vm_mmap(dobj->obj.filp, 0, args->size, PROT_READ | PROT_WRITE,\n\t\t       MAP_SHARED, args->offset);\n\tdrm_gem_object_put(&dobj->obj);\n\tif (IS_ERR_VALUE(addr))\n\t\treturn addr;\n\n\targs->addr = addr;\n\n\treturn 0;\n}\n\nint armada_gem_pwrite_ioctl(struct drm_device *dev, void *data,\n\tstruct drm_file *file)\n{\n\tstruct drm_armada_gem_pwrite *args = data;\n\tstruct armada_gem_object *dobj;\n\tchar __user *ptr;\n\tint ret = 0;\n\n\tDRM_DEBUG_DRIVER(\"handle %u off %u size %u ptr 0x%llx\\n\",\n\t\targs->handle, args->offset, args->size, args->ptr);\n\n\tif (args->size == 0)\n\t\treturn 0;\n\n\tptr = (char __user *)(uintptr_t)args->ptr;\n\n\tif (!access_ok(ptr, args->size))\n\t\treturn -EFAULT;\n\n\tif (fault_in_readable(ptr, args->size))\n\t\treturn -EFAULT;\n\n\tdobj = armada_gem_object_lookup(file, args->handle);\n\tif (dobj == NULL)\n\t\treturn -ENOENT;\n\n\t \n\tif (!dobj->addr)\n\t\treturn -EINVAL;\n\n\tif (args->offset > dobj->obj.size ||\n\t    args->size > dobj->obj.size - args->offset) {\n\t\tDRM_ERROR(\"invalid size: object size %u\\n\", dobj->obj.size);\n\t\tret = -EINVAL;\n\t\tgoto unref;\n\t}\n\n\tif (copy_from_user(dobj->addr + args->offset, ptr, args->size)) {\n\t\tret = -EFAULT;\n\t} else if (dobj->update) {\n\t\tdobj->update(dobj->update_data);\n\t\tret = 0;\n\t}\n\n unref:\n\tdrm_gem_object_put(&dobj->obj);\n\treturn ret;\n}\n\n \nstatic struct sg_table *\narmada_gem_prime_map_dma_buf(struct dma_buf_attachment *attach,\n\tenum dma_data_direction dir)\n{\n\tstruct drm_gem_object *obj = attach->dmabuf->priv;\n\tstruct armada_gem_object *dobj = drm_to_armada_gem(obj);\n\tstruct scatterlist *sg;\n\tstruct sg_table *sgt;\n\tint i;\n\n\tsgt = kmalloc(sizeof(*sgt), GFP_KERNEL);\n\tif (!sgt)\n\t\treturn NULL;\n\n\tif (dobj->obj.filp) {\n\t\tstruct address_space *mapping;\n\t\tint count;\n\n\t\tcount = dobj->obj.size / PAGE_SIZE;\n\t\tif (sg_alloc_table(sgt, count, GFP_KERNEL))\n\t\t\tgoto free_sgt;\n\n\t\tmapping = dobj->obj.filp->f_mapping;\n\n\t\tfor_each_sgtable_sg(sgt, sg, i) {\n\t\t\tstruct page *page;\n\n\t\t\tpage = shmem_read_mapping_page(mapping, i);\n\t\t\tif (IS_ERR(page))\n\t\t\t\tgoto release;\n\n\t\t\tsg_set_page(sg, page, PAGE_SIZE, 0);\n\t\t}\n\n\t\tif (dma_map_sgtable(attach->dev, sgt, dir, 0))\n\t\t\tgoto release;\n\t} else if (dobj->page) {\n\t\t \n\t\tif (sg_alloc_table(sgt, 1, GFP_KERNEL))\n\t\t\tgoto free_sgt;\n\n\t\tsg_set_page(sgt->sgl, dobj->page, dobj->obj.size, 0);\n\n\t\tif (dma_map_sgtable(attach->dev, sgt, dir, 0))\n\t\t\tgoto free_table;\n\t} else if (dobj->linear) {\n\t\t \n\t\tif (sg_alloc_table(sgt, 1, GFP_KERNEL))\n\t\t\tgoto free_sgt;\n\t\tsg_dma_address(sgt->sgl) = dobj->dev_addr;\n\t\tsg_dma_len(sgt->sgl) = dobj->obj.size;\n\t} else {\n\t\tgoto free_sgt;\n\t}\n\treturn sgt;\n\n release:\n\tfor_each_sgtable_sg(sgt, sg, i)\n\t\tif (sg_page(sg))\n\t\t\tput_page(sg_page(sg));\n free_table:\n\tsg_free_table(sgt);\n free_sgt:\n\tkfree(sgt);\n\treturn NULL;\n}\n\nstatic void armada_gem_prime_unmap_dma_buf(struct dma_buf_attachment *attach,\n\tstruct sg_table *sgt, enum dma_data_direction dir)\n{\n\tstruct drm_gem_object *obj = attach->dmabuf->priv;\n\tstruct armada_gem_object *dobj = drm_to_armada_gem(obj);\n\tint i;\n\n\tif (!dobj->linear)\n\t\tdma_unmap_sgtable(attach->dev, sgt, dir, 0);\n\n\tif (dobj->obj.filp) {\n\t\tstruct scatterlist *sg;\n\n\t\tfor_each_sgtable_sg(sgt, sg, i)\n\t\t\tput_page(sg_page(sg));\n\t}\n\n\tsg_free_table(sgt);\n\tkfree(sgt);\n}\n\nstatic int\narmada_gem_dmabuf_mmap(struct dma_buf *buf, struct vm_area_struct *vma)\n{\n\treturn -EINVAL;\n}\n\nstatic const struct dma_buf_ops armada_gem_prime_dmabuf_ops = {\n\t.map_dma_buf\t= armada_gem_prime_map_dma_buf,\n\t.unmap_dma_buf\t= armada_gem_prime_unmap_dma_buf,\n\t.release\t= drm_gem_dmabuf_release,\n\t.mmap\t\t= armada_gem_dmabuf_mmap,\n};\n\nstruct dma_buf *\narmada_gem_prime_export(struct drm_gem_object *obj, int flags)\n{\n\tDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\n\n\texp_info.ops = &armada_gem_prime_dmabuf_ops;\n\texp_info.size = obj->size;\n\texp_info.flags = O_RDWR;\n\texp_info.priv = obj;\n\n\treturn drm_gem_dmabuf_export(obj->dev, &exp_info);\n}\n\nstruct drm_gem_object *\narmada_gem_prime_import(struct drm_device *dev, struct dma_buf *buf)\n{\n\tstruct dma_buf_attachment *attach;\n\tstruct armada_gem_object *dobj;\n\n\tif (buf->ops == &armada_gem_prime_dmabuf_ops) {\n\t\tstruct drm_gem_object *obj = buf->priv;\n\t\tif (obj->dev == dev) {\n\t\t\t \n\t\t\tdrm_gem_object_get(obj);\n\t\t\treturn obj;\n\t\t}\n\t}\n\n\tattach = dma_buf_attach(buf, dev->dev);\n\tif (IS_ERR(attach))\n\t\treturn ERR_CAST(attach);\n\n\tdobj = armada_gem_alloc_private_object(dev, buf->size);\n\tif (!dobj) {\n\t\tdma_buf_detach(buf, attach);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tdobj->obj.import_attach = attach;\n\tget_dma_buf(buf);\n\n\t \n\treturn &dobj->obj;\n}\n\nint armada_gem_map_import(struct armada_gem_object *dobj)\n{\n\tint ret;\n\n\tdobj->sgt = dma_buf_map_attachment_unlocked(dobj->obj.import_attach,\n\t\t\t\t\t\t    DMA_TO_DEVICE);\n\tif (IS_ERR(dobj->sgt)) {\n\t\tret = PTR_ERR(dobj->sgt);\n\t\tdobj->sgt = NULL;\n\t\tDRM_ERROR(\"dma_buf_map_attachment() error: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\tif (dobj->sgt->nents > 1) {\n\t\tDRM_ERROR(\"dma_buf_map_attachment() returned an (unsupported) scattered list\\n\");\n\t\treturn -EINVAL;\n\t}\n\tif (sg_dma_len(dobj->sgt->sgl) < dobj->obj.size) {\n\t\tDRM_ERROR(\"dma_buf_map_attachment() returned a small buffer\\n\");\n\t\treturn -EINVAL;\n\t}\n\tdobj->dev_addr = sg_dma_address(dobj->sgt->sgl);\n\tdobj->mapped = true;\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}