{
  "module_name": "drm_cache.c",
  "hash_id": "438b572c477a0a86923839cf76eaf9dfb4354e1a14862479590bf71f87de3b8c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/gpu/drm/drm_cache.c",
  "human_readable_source": " \n \n#include <linux/cc_platform.h>\n#include <linux/export.h>\n#include <linux/highmem.h>\n#include <linux/ioport.h>\n#include <linux/iosys-map.h>\n#include <xen/xen.h>\n\n#include <drm/drm_cache.h>\n\n \n#define MEMCPY_BOUNCE_SIZE 128\n\n#if defined(CONFIG_X86)\n#include <asm/smp.h>\n\n \nstatic void\ndrm_clflush_page(struct page *page)\n{\n\tuint8_t *page_virtual;\n\tunsigned int i;\n\tconst int size = boot_cpu_data.x86_clflush_size;\n\n\tif (unlikely(page == NULL))\n\t\treturn;\n\n\tpage_virtual = kmap_atomic(page);\n\tfor (i = 0; i < PAGE_SIZE; i += size)\n\t\tclflushopt(page_virtual + i);\n\tkunmap_atomic(page_virtual);\n}\n\nstatic void drm_cache_flush_clflush(struct page *pages[],\n\t\t\t\t    unsigned long num_pages)\n{\n\tunsigned long i;\n\n\tmb();  \n\tfor (i = 0; i < num_pages; i++)\n\t\tdrm_clflush_page(*pages++);\n\tmb();  \n}\n#endif\n\n \nvoid\ndrm_clflush_pages(struct page *pages[], unsigned long num_pages)\n{\n\n#if defined(CONFIG_X86)\n\tif (static_cpu_has(X86_FEATURE_CLFLUSH)) {\n\t\tdrm_cache_flush_clflush(pages, num_pages);\n\t\treturn;\n\t}\n\n\tif (wbinvd_on_all_cpus())\n\t\tpr_err(\"Timed out waiting for cache flush\\n\");\n\n#elif defined(__powerpc__)\n\tunsigned long i;\n\n\tfor (i = 0; i < num_pages; i++) {\n\t\tstruct page *page = pages[i];\n\t\tvoid *page_virtual;\n\n\t\tif (unlikely(page == NULL))\n\t\t\tcontinue;\n\n\t\tpage_virtual = kmap_atomic(page);\n\t\tflush_dcache_range((unsigned long)page_virtual,\n\t\t\t\t   (unsigned long)page_virtual + PAGE_SIZE);\n\t\tkunmap_atomic(page_virtual);\n\t}\n#else\n\tWARN_ONCE(1, \"Architecture has no drm_cache.c support\\n\");\n#endif\n}\nEXPORT_SYMBOL(drm_clflush_pages);\n\n \nvoid\ndrm_clflush_sg(struct sg_table *st)\n{\n#if defined(CONFIG_X86)\n\tif (static_cpu_has(X86_FEATURE_CLFLUSH)) {\n\t\tstruct sg_page_iter sg_iter;\n\n\t\tmb();  \n\t\tfor_each_sgtable_page(st, &sg_iter, 0)\n\t\t\tdrm_clflush_page(sg_page_iter_page(&sg_iter));\n\t\tmb();  \n\n\t\treturn;\n\t}\n\n\tif (wbinvd_on_all_cpus())\n\t\tpr_err(\"Timed out waiting for cache flush\\n\");\n#else\n\tWARN_ONCE(1, \"Architecture has no drm_cache.c support\\n\");\n#endif\n}\nEXPORT_SYMBOL(drm_clflush_sg);\n\n \nvoid\ndrm_clflush_virt_range(void *addr, unsigned long length)\n{\n#if defined(CONFIG_X86)\n\tif (static_cpu_has(X86_FEATURE_CLFLUSH)) {\n\t\tconst int size = boot_cpu_data.x86_clflush_size;\n\t\tvoid *end = addr + length;\n\n\t\taddr = (void *)(((unsigned long)addr) & -size);\n\t\tmb();  \n\t\tfor (; addr < end; addr += size)\n\t\t\tclflushopt(addr);\n\t\tclflushopt(end - 1);  \n\t\tmb();  \n\t\treturn;\n\t}\n\n\tif (wbinvd_on_all_cpus())\n\t\tpr_err(\"Timed out waiting for cache flush\\n\");\n#else\n\tWARN_ONCE(1, \"Architecture has no drm_cache.c support\\n\");\n#endif\n}\nEXPORT_SYMBOL(drm_clflush_virt_range);\n\nbool drm_need_swiotlb(int dma_bits)\n{\n\tstruct resource *tmp;\n\tresource_size_t max_iomem = 0;\n\n\t \n\tif (xen_pv_domain())\n\t\treturn true;\n\n\t \n\tif (cc_platform_has(CC_ATTR_MEM_ENCRYPT))\n\t\treturn true;\n\n\tfor (tmp = iomem_resource.child; tmp; tmp = tmp->sibling)\n\t\tmax_iomem = max(max_iomem,  tmp->end);\n\n\treturn max_iomem > ((u64)1 << dma_bits);\n}\nEXPORT_SYMBOL(drm_need_swiotlb);\n\nstatic void memcpy_fallback(struct iosys_map *dst,\n\t\t\t    const struct iosys_map *src,\n\t\t\t    unsigned long len)\n{\n\tif (!dst->is_iomem && !src->is_iomem) {\n\t\tmemcpy(dst->vaddr, src->vaddr, len);\n\t} else if (!src->is_iomem) {\n\t\tiosys_map_memcpy_to(dst, 0, src->vaddr, len);\n\t} else if (!dst->is_iomem) {\n\t\tmemcpy_fromio(dst->vaddr, src->vaddr_iomem, len);\n\t} else {\n\t\t \n\t\tchar bounce[MEMCPY_BOUNCE_SIZE];\n\t\tvoid __iomem *_src = src->vaddr_iomem;\n\t\tvoid __iomem *_dst = dst->vaddr_iomem;\n\n\t\twhile (len >= MEMCPY_BOUNCE_SIZE) {\n\t\t\tmemcpy_fromio(bounce, _src, MEMCPY_BOUNCE_SIZE);\n\t\t\tmemcpy_toio(_dst, bounce, MEMCPY_BOUNCE_SIZE);\n\t\t\t_src += MEMCPY_BOUNCE_SIZE;\n\t\t\t_dst += MEMCPY_BOUNCE_SIZE;\n\t\t\tlen -= MEMCPY_BOUNCE_SIZE;\n\t\t}\n\t\tif (len) {\n\t\t\tmemcpy_fromio(bounce, _src, MEMCPY_BOUNCE_SIZE);\n\t\t\tmemcpy_toio(_dst, bounce, MEMCPY_BOUNCE_SIZE);\n\t\t}\n\t}\n}\n\n#ifdef CONFIG_X86\n\nstatic DEFINE_STATIC_KEY_FALSE(has_movntdqa);\n\nstatic void __memcpy_ntdqa(void *dst, const void *src, unsigned long len)\n{\n\tkernel_fpu_begin();\n\n\twhile (len >= 4) {\n\t\tasm(\"movntdqa\t(%0), %%xmm0\\n\"\n\t\t    \"movntdqa 16(%0), %%xmm1\\n\"\n\t\t    \"movntdqa 32(%0), %%xmm2\\n\"\n\t\t    \"movntdqa 48(%0), %%xmm3\\n\"\n\t\t    \"movaps %%xmm0,   (%1)\\n\"\n\t\t    \"movaps %%xmm1, 16(%1)\\n\"\n\t\t    \"movaps %%xmm2, 32(%1)\\n\"\n\t\t    \"movaps %%xmm3, 48(%1)\\n\"\n\t\t    :: \"r\" (src), \"r\" (dst) : \"memory\");\n\t\tsrc += 64;\n\t\tdst += 64;\n\t\tlen -= 4;\n\t}\n\twhile (len--) {\n\t\tasm(\"movntdqa (%0), %%xmm0\\n\"\n\t\t    \"movaps %%xmm0, (%1)\\n\"\n\t\t    :: \"r\" (src), \"r\" (dst) : \"memory\");\n\t\tsrc += 16;\n\t\tdst += 16;\n\t}\n\n\tkernel_fpu_end();\n}\n\n \nstatic void __drm_memcpy_from_wc(void *dst, const void *src, unsigned long len)\n{\n\tif (unlikely(((unsigned long)dst | (unsigned long)src | len) & 15))\n\t\tmemcpy(dst, src, len);\n\telse if (likely(len))\n\t\t__memcpy_ntdqa(dst, src, len >> 4);\n}\n\n \nvoid drm_memcpy_from_wc(struct iosys_map *dst,\n\t\t\tconst struct iosys_map *src,\n\t\t\tunsigned long len)\n{\n\tif (WARN_ON(in_interrupt())) {\n\t\tmemcpy_fallback(dst, src, len);\n\t\treturn;\n\t}\n\n\tif (static_branch_likely(&has_movntdqa)) {\n\t\t__drm_memcpy_from_wc(dst->is_iomem ?\n\t\t\t\t     (void __force *)dst->vaddr_iomem :\n\t\t\t\t     dst->vaddr,\n\t\t\t\t     src->is_iomem ?\n\t\t\t\t     (void const __force *)src->vaddr_iomem :\n\t\t\t\t     src->vaddr,\n\t\t\t\t     len);\n\t\treturn;\n\t}\n\n\tmemcpy_fallback(dst, src, len);\n}\nEXPORT_SYMBOL(drm_memcpy_from_wc);\n\n \nvoid drm_memcpy_init_early(void)\n{\n\t \n\tif (static_cpu_has(X86_FEATURE_XMM4_1) &&\n\t    !boot_cpu_has(X86_FEATURE_HYPERVISOR))\n\t\tstatic_branch_enable(&has_movntdqa);\n}\n#else\nvoid drm_memcpy_from_wc(struct iosys_map *dst,\n\t\t\tconst struct iosys_map *src,\n\t\t\tunsigned long len)\n{\n\tWARN_ON(in_interrupt());\n\n\tmemcpy_fallback(dst, src, len);\n}\nEXPORT_SYMBOL(drm_memcpy_from_wc);\n\nvoid drm_memcpy_init_early(void)\n{\n}\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}