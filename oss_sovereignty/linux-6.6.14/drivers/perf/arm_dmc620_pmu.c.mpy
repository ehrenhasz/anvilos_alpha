{
  "module_name": "arm_dmc620_pmu.c",
  "hash_id": "d3995ba3725352e58845e6273f2d110600c11d1aca392e1ec5795f5ace46ff0d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/perf/arm_dmc620_pmu.c",
  "human_readable_source": "\n \n\n#define DMC620_PMUNAME\t\t\"arm_dmc620\"\n#define DMC620_DRVNAME\t\tDMC620_PMUNAME \"_pmu\"\n#define pr_fmt(fmt)\t\tDMC620_DRVNAME \": \" fmt\n\n#include <linux/acpi.h>\n#include <linux/bitfield.h>\n#include <linux/bitops.h>\n#include <linux/cpuhotplug.h>\n#include <linux/cpumask.h>\n#include <linux/device.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n#include <linux/kernel.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/perf_event.h>\n#include <linux/platform_device.h>\n#include <linux/printk.h>\n#include <linux/rculist.h>\n#include <linux/refcount.h>\n\n#define DMC620_PA_SHIFT\t\t\t\t\t12\n#define DMC620_CNT_INIT\t\t\t\t\t0x80000000\n#define DMC620_CNT_MAX_PERIOD\t\t\t\t0xffffffff\n#define DMC620_PMU_CLKDIV2_MAX_COUNTERS\t\t\t8\n#define DMC620_PMU_CLK_MAX_COUNTERS\t\t\t2\n#define DMC620_PMU_MAX_COUNTERS\t\t\t\t\\\n\t(DMC620_PMU_CLKDIV2_MAX_COUNTERS + DMC620_PMU_CLK_MAX_COUNTERS)\n\n \n#define DMC620_PMU_OVERFLOW_STATUS_CLKDIV2\t\t0x8\n#define  DMC620_PMU_OVERFLOW_STATUS_CLKDIV2_MASK\t\\\n\t\t(DMC620_PMU_CLKDIV2_MAX_COUNTERS - 1)\n#define DMC620_PMU_OVERFLOW_STATUS_CLK\t\t\t0xC\n#define  DMC620_PMU_OVERFLOW_STATUS_CLK_MASK\t\t\\\n\t\t(DMC620_PMU_CLK_MAX_COUNTERS - 1)\n#define DMC620_PMU_COUNTERS_BASE\t\t\t0x10\n#define DMC620_PMU_COUNTERn_MASK_31_00\t\t\t0x0\n#define DMC620_PMU_COUNTERn_MASK_63_32\t\t\t0x4\n#define DMC620_PMU_COUNTERn_MATCH_31_00\t\t\t0x8\n#define DMC620_PMU_COUNTERn_MATCH_63_32\t\t\t0xC\n#define DMC620_PMU_COUNTERn_CONTROL\t\t\t0x10\n#define  DMC620_PMU_COUNTERn_CONTROL_ENABLE\t\tBIT(0)\n#define  DMC620_PMU_COUNTERn_CONTROL_INVERT\t\tBIT(1)\n#define  DMC620_PMU_COUNTERn_CONTROL_EVENT_MUX\t\tGENMASK(6, 2)\n#define  DMC620_PMU_COUNTERn_CONTROL_INCR_MUX\t\tGENMASK(8, 7)\n#define DMC620_PMU_COUNTERn_VALUE\t\t\t0x20\n \n#define DMC620_PMU_COUNTERn_OFFSET(n) \\\n\t(DMC620_PMU_COUNTERS_BASE + 0x28 * (n))\n\n \nstatic DEFINE_MUTEX(dmc620_pmu_irqs_lock);\nstatic DEFINE_MUTEX(dmc620_pmu_node_lock);\nstatic LIST_HEAD(dmc620_pmu_irqs);\n\nstruct dmc620_pmu_irq {\n\tstruct hlist_node node;\n\tstruct list_head pmus_node;\n\tstruct list_head irqs_node;\n\trefcount_t refcount;\n\tunsigned int irq_num;\n\tunsigned int cpu;\n};\n\nstruct dmc620_pmu {\n\tstruct pmu pmu;\n\n\tvoid __iomem *base;\n\tstruct dmc620_pmu_irq *irq;\n\tstruct list_head pmus_node;\n\n\t \n\tDECLARE_BITMAP(used_mask, DMC620_PMU_MAX_COUNTERS);\n\tstruct perf_event *events[DMC620_PMU_MAX_COUNTERS];\n};\n\n#define to_dmc620_pmu(p) (container_of(p, struct dmc620_pmu, pmu))\n\nstatic int cpuhp_state_num;\n\nstruct dmc620_pmu_event_attr {\n\tstruct device_attribute attr;\n\tu8 clkdiv2;\n\tu8 eventid;\n};\n\nstatic ssize_t\ndmc620_pmu_event_show(struct device *dev,\n\t\t\t   struct device_attribute *attr, char *page)\n{\n\tstruct dmc620_pmu_event_attr *eattr;\n\n\teattr = container_of(attr, typeof(*eattr), attr);\n\n\treturn sysfs_emit(page, \"event=0x%x,clkdiv2=0x%x\\n\", eattr->eventid, eattr->clkdiv2);\n}\n\n#define DMC620_PMU_EVENT_ATTR(_name, _eventid, _clkdiv2)\t\t\\\n\t(&((struct dmc620_pmu_event_attr[]) {{\t\t\t\t\\\n\t\t.attr = __ATTR(_name, 0444, dmc620_pmu_event_show, NULL),\t\\\n\t\t.clkdiv2 = _clkdiv2,\t\t\t\t\t\t\\\n\t\t.eventid = _eventid,\t\t\t\t\t\\\n\t}})[0].attr.attr)\n\nstatic struct attribute *dmc620_pmu_events_attrs[] = {\n\t \n\tDMC620_PMU_EVENT_ATTR(clkdiv2_cycle_count, 0x0, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_allocate, 0x1, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_queue_depth, 0x2, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_waiting_for_wr_data, 0x3, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_read_backlog, 0x4, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_waiting_for_mi, 0x5, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_hazard_resolution, 0x6, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_enqueue, 0x7, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_arbitrate, 0x8, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_lrank_turnaround_activate, 0x9, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_prank_turnaround_activate, 0xa, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_read_depth, 0xb, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_write_depth, 0xc, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_highigh_qos_depth, 0xd, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_high_qos_depth, 0xe, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_medium_qos_depth, 0xf, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_low_qos_depth, 0x10, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_activate, 0x11, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_rdwr, 0x12, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_refresh, 0x13, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_training_request, 0x14, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_t_mac_tracker, 0x15, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_bk_fsm_tracker, 0x16, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_bk_open_tracker, 0x17, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_ranks_in_pwr_down, 0x18, 1),\n\tDMC620_PMU_EVENT_ATTR(clkdiv2_ranks_in_sref, 0x19, 1),\n\n\t \n\tDMC620_PMU_EVENT_ATTR(clk_cycle_count, 0x0, 0),\n\tDMC620_PMU_EVENT_ATTR(clk_request, 0x1, 0),\n\tDMC620_PMU_EVENT_ATTR(clk_upload_stall, 0x2, 0),\n\tNULL,\n};\n\nstatic const struct attribute_group dmc620_pmu_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = dmc620_pmu_events_attrs,\n};\n\n \n#define ATTR_CFG_FLD_mask_CFG\t\tconfig\n#define ATTR_CFG_FLD_mask_LO\t\t0\n#define ATTR_CFG_FLD_mask_HI\t\t44\n#define ATTR_CFG_FLD_match_CFG\t\tconfig1\n#define ATTR_CFG_FLD_match_LO\t\t0\n#define ATTR_CFG_FLD_match_HI\t\t44\n#define ATTR_CFG_FLD_invert_CFG\t\tconfig2\n#define ATTR_CFG_FLD_invert_LO\t\t0\n#define ATTR_CFG_FLD_invert_HI\t\t0\n#define ATTR_CFG_FLD_incr_CFG\t\tconfig2\n#define ATTR_CFG_FLD_incr_LO\t\t1\n#define ATTR_CFG_FLD_incr_HI\t\t2\n#define ATTR_CFG_FLD_event_CFG\t\tconfig2\n#define ATTR_CFG_FLD_event_LO\t\t3\n#define ATTR_CFG_FLD_event_HI\t\t8\n#define ATTR_CFG_FLD_clkdiv2_CFG\tconfig2\n#define ATTR_CFG_FLD_clkdiv2_LO\t\t9\n#define ATTR_CFG_FLD_clkdiv2_HI\t\t9\n\n#define __GEN_PMU_FORMAT_ATTR(cfg, lo, hi)\t\t\t\\\n\t(lo) == (hi) ? #cfg \":\" #lo \"\\n\" : #cfg \":\" #lo \"-\" #hi\n\n#define _GEN_PMU_FORMAT_ATTR(cfg, lo, hi)\t\t\t\\\n\t__GEN_PMU_FORMAT_ATTR(cfg, lo, hi)\n\n#define GEN_PMU_FORMAT_ATTR(name)\t\t\t\t\\\n\tPMU_FORMAT_ATTR(name,\t\t\t\t\t\\\n\t_GEN_PMU_FORMAT_ATTR(ATTR_CFG_FLD_##name##_CFG,\t\t\\\n\t\t\t     ATTR_CFG_FLD_##name##_LO,\t\t\\\n\t\t\t     ATTR_CFG_FLD_##name##_HI))\n\n#define _ATTR_CFG_GET_FLD(attr, cfg, lo, hi)\t\t\t\\\n\t((((attr)->cfg) >> lo) & GENMASK_ULL(hi - lo, 0))\n\n#define ATTR_CFG_GET_FLD(attr, name)\t\t\t\t\\\n\t_ATTR_CFG_GET_FLD(attr,\t\t\t\t\t\\\n\t\t\t  ATTR_CFG_FLD_##name##_CFG,\t\t\\\n\t\t\t  ATTR_CFG_FLD_##name##_LO,\t\t\\\n\t\t\t  ATTR_CFG_FLD_##name##_HI)\n\nGEN_PMU_FORMAT_ATTR(mask);\nGEN_PMU_FORMAT_ATTR(match);\nGEN_PMU_FORMAT_ATTR(invert);\nGEN_PMU_FORMAT_ATTR(incr);\nGEN_PMU_FORMAT_ATTR(event);\nGEN_PMU_FORMAT_ATTR(clkdiv2);\n\nstatic struct attribute *dmc620_pmu_formats_attrs[] = {\n\t&format_attr_mask.attr,\n\t&format_attr_match.attr,\n\t&format_attr_invert.attr,\n\t&format_attr_incr.attr,\n\t&format_attr_event.attr,\n\t&format_attr_clkdiv2.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group dmc620_pmu_format_attr_group = {\n\t.name\t= \"format\",\n\t.attrs\t= dmc620_pmu_formats_attrs,\n};\n\nstatic ssize_t dmc620_pmu_cpumask_show(struct device *dev,\n\t\t\t\t       struct device_attribute *attr, char *buf)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(dev_get_drvdata(dev));\n\n\treturn cpumap_print_to_pagebuf(true, buf,\n\t\t\t\t       cpumask_of(dmc620_pmu->irq->cpu));\n}\n\nstatic struct device_attribute dmc620_pmu_cpumask_attr =\n\t__ATTR(cpumask, 0444, dmc620_pmu_cpumask_show, NULL);\n\nstatic struct attribute *dmc620_pmu_cpumask_attrs[] = {\n\t&dmc620_pmu_cpumask_attr.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group dmc620_pmu_cpumask_attr_group = {\n\t.attrs = dmc620_pmu_cpumask_attrs,\n};\n\nstatic const struct attribute_group *dmc620_pmu_attr_groups[] = {\n\t&dmc620_pmu_events_attr_group,\n\t&dmc620_pmu_format_attr_group,\n\t&dmc620_pmu_cpumask_attr_group,\n\tNULL,\n};\n\nstatic inline\nu32 dmc620_pmu_creg_read(struct dmc620_pmu *dmc620_pmu,\n\t\t\tunsigned int idx, unsigned int reg)\n{\n\treturn readl(dmc620_pmu->base + DMC620_PMU_COUNTERn_OFFSET(idx) + reg);\n}\n\nstatic inline\nvoid dmc620_pmu_creg_write(struct dmc620_pmu *dmc620_pmu,\n\t\t\tunsigned int idx, unsigned int reg, u32 val)\n{\n\twritel(val, dmc620_pmu->base + DMC620_PMU_COUNTERn_OFFSET(idx) + reg);\n}\n\nstatic\nunsigned int dmc620_event_to_counter_control(struct perf_event *event)\n{\n\tstruct perf_event_attr *attr = &event->attr;\n\tunsigned int reg = 0;\n\n\treg |= FIELD_PREP(DMC620_PMU_COUNTERn_CONTROL_INVERT,\n\t\t\tATTR_CFG_GET_FLD(attr, invert));\n\treg |= FIELD_PREP(DMC620_PMU_COUNTERn_CONTROL_EVENT_MUX,\n\t\t\tATTR_CFG_GET_FLD(attr, event));\n\treg |= FIELD_PREP(DMC620_PMU_COUNTERn_CONTROL_INCR_MUX,\n\t\t\tATTR_CFG_GET_FLD(attr, incr));\n\n\treturn reg;\n}\n\nstatic int dmc620_get_event_idx(struct perf_event *event)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\tint idx, start_idx, end_idx;\n\n\tif (ATTR_CFG_GET_FLD(&event->attr, clkdiv2)) {\n\t\tstart_idx = 0;\n\t\tend_idx = DMC620_PMU_CLKDIV2_MAX_COUNTERS;\n\t} else {\n\t\tstart_idx = DMC620_PMU_CLKDIV2_MAX_COUNTERS;\n\t\tend_idx = DMC620_PMU_MAX_COUNTERS;\n\t}\n\n\tfor (idx = start_idx; idx < end_idx; ++idx) {\n\t\tif (!test_and_set_bit(idx, dmc620_pmu->used_mask))\n\t\t\treturn idx;\n\t}\n\n\t \n\treturn -EAGAIN;\n}\n\nstatic inline\nu64 dmc620_pmu_read_counter(struct perf_event *event)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\n\treturn dmc620_pmu_creg_read(dmc620_pmu,\n\t\t\t\t    event->hw.idx, DMC620_PMU_COUNTERn_VALUE);\n}\n\nstatic void dmc620_pmu_event_update(struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tu64 delta, prev_count, new_count;\n\n\tdo {\n\t\t \n\t\tprev_count = local64_read(&hwc->prev_count);\n\t\tnew_count = dmc620_pmu_read_counter(event);\n\t} while (local64_cmpxchg(&hwc->prev_count,\n\t\t\tprev_count, new_count) != prev_count);\n\tdelta = (new_count - prev_count) & DMC620_CNT_MAX_PERIOD;\n\tlocal64_add(delta, &event->count);\n}\n\nstatic void dmc620_pmu_event_set_period(struct perf_event *event)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\n\tlocal64_set(&event->hw.prev_count, DMC620_CNT_INIT);\n\tdmc620_pmu_creg_write(dmc620_pmu,\n\t\t\t      event->hw.idx, DMC620_PMU_COUNTERn_VALUE, DMC620_CNT_INIT);\n}\n\nstatic void dmc620_pmu_enable_counter(struct perf_event *event)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\tu32 reg;\n\n\treg = dmc620_event_to_counter_control(event) | DMC620_PMU_COUNTERn_CONTROL_ENABLE;\n\tdmc620_pmu_creg_write(dmc620_pmu,\n\t\t\t      event->hw.idx, DMC620_PMU_COUNTERn_CONTROL, reg);\n}\n\nstatic void dmc620_pmu_disable_counter(struct perf_event *event)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\n\tdmc620_pmu_creg_write(dmc620_pmu,\n\t\t\t      event->hw.idx, DMC620_PMU_COUNTERn_CONTROL, 0);\n}\n\nstatic irqreturn_t dmc620_pmu_handle_irq(int irq_num, void *data)\n{\n\tstruct dmc620_pmu_irq *irq = data;\n\tstruct dmc620_pmu *dmc620_pmu;\n\tirqreturn_t ret = IRQ_NONE;\n\n\trcu_read_lock();\n\tlist_for_each_entry_rcu(dmc620_pmu, &irq->pmus_node, pmus_node) {\n\t\tunsigned long status;\n\t\tstruct perf_event *event;\n\t\tunsigned int idx;\n\n\t\t \n\t\tfor (idx = 0; idx < DMC620_PMU_MAX_COUNTERS; idx++) {\n\t\t\tevent = dmc620_pmu->events[idx];\n\t\t\tif (!event)\n\t\t\t\tcontinue;\n\t\t\tdmc620_pmu_disable_counter(event);\n\t\t}\n\n\t\tstatus = readl(dmc620_pmu->base + DMC620_PMU_OVERFLOW_STATUS_CLKDIV2);\n\t\tstatus |= (readl(dmc620_pmu->base + DMC620_PMU_OVERFLOW_STATUS_CLK) <<\n\t\t\t\tDMC620_PMU_CLKDIV2_MAX_COUNTERS);\n\t\tif (status) {\n\t\t\tfor_each_set_bit(idx, &status,\n\t\t\t\t\tDMC620_PMU_MAX_COUNTERS) {\n\t\t\t\tevent = dmc620_pmu->events[idx];\n\t\t\t\tif (WARN_ON_ONCE(!event))\n\t\t\t\t\tcontinue;\n\t\t\t\tdmc620_pmu_event_update(event);\n\t\t\t\tdmc620_pmu_event_set_period(event);\n\t\t\t}\n\n\t\t\tif (status & DMC620_PMU_OVERFLOW_STATUS_CLKDIV2_MASK)\n\t\t\t\twritel(0, dmc620_pmu->base + DMC620_PMU_OVERFLOW_STATUS_CLKDIV2);\n\n\t\t\tif ((status >> DMC620_PMU_CLKDIV2_MAX_COUNTERS) &\n\t\t\t\tDMC620_PMU_OVERFLOW_STATUS_CLK_MASK)\n\t\t\t\twritel(0, dmc620_pmu->base + DMC620_PMU_OVERFLOW_STATUS_CLK);\n\t\t}\n\n\t\tfor (idx = 0; idx < DMC620_PMU_MAX_COUNTERS; idx++) {\n\t\t\tevent = dmc620_pmu->events[idx];\n\t\t\tif (!event)\n\t\t\t\tcontinue;\n\t\t\tif (!(event->hw.state & PERF_HES_STOPPED))\n\t\t\t\tdmc620_pmu_enable_counter(event);\n\t\t}\n\n\t\tret = IRQ_HANDLED;\n\t}\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nstatic struct dmc620_pmu_irq *__dmc620_pmu_get_irq(int irq_num)\n{\n\tstruct dmc620_pmu_irq *irq;\n\tint ret;\n\n\tlist_for_each_entry(irq, &dmc620_pmu_irqs, irqs_node)\n\t\tif (irq->irq_num == irq_num && refcount_inc_not_zero(&irq->refcount))\n\t\t\treturn irq;\n\n\tirq = kzalloc(sizeof(*irq), GFP_KERNEL);\n\tif (!irq)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tINIT_LIST_HEAD(&irq->pmus_node);\n\n\t \n\tirq->cpu = raw_smp_processor_id();\n\trefcount_set(&irq->refcount, 1);\n\n\tret = request_irq(irq_num, dmc620_pmu_handle_irq,\n\t\t\t  IRQF_NOBALANCING | IRQF_NO_THREAD,\n\t\t\t  \"dmc620-pmu\", irq);\n\tif (ret)\n\t\tgoto out_free_aff;\n\n\tret = irq_set_affinity(irq_num, cpumask_of(irq->cpu));\n\tif (ret)\n\t\tgoto out_free_irq;\n\n\tret = cpuhp_state_add_instance_nocalls(cpuhp_state_num, &irq->node);\n\tif (ret)\n\t\tgoto out_free_irq;\n\n\tirq->irq_num = irq_num;\n\tlist_add(&irq->irqs_node, &dmc620_pmu_irqs);\n\n\treturn irq;\n\nout_free_irq:\n\tfree_irq(irq_num, irq);\nout_free_aff:\n\tkfree(irq);\n\treturn ERR_PTR(ret);\n}\n\nstatic int dmc620_pmu_get_irq(struct dmc620_pmu *dmc620_pmu, int irq_num)\n{\n\tstruct dmc620_pmu_irq *irq;\n\n\tmutex_lock(&dmc620_pmu_irqs_lock);\n\tirq = __dmc620_pmu_get_irq(irq_num);\n\tmutex_unlock(&dmc620_pmu_irqs_lock);\n\n\tif (IS_ERR(irq))\n\t\treturn PTR_ERR(irq);\n\n\tdmc620_pmu->irq = irq;\n\tmutex_lock(&dmc620_pmu_node_lock);\n\tlist_add_rcu(&dmc620_pmu->pmus_node, &irq->pmus_node);\n\tmutex_unlock(&dmc620_pmu_node_lock);\n\n\treturn 0;\n}\n\nstatic void dmc620_pmu_put_irq(struct dmc620_pmu *dmc620_pmu)\n{\n\tstruct dmc620_pmu_irq *irq = dmc620_pmu->irq;\n\n\tmutex_lock(&dmc620_pmu_node_lock);\n\tlist_del_rcu(&dmc620_pmu->pmus_node);\n\tmutex_unlock(&dmc620_pmu_node_lock);\n\n\tmutex_lock(&dmc620_pmu_irqs_lock);\n\tif (!refcount_dec_and_test(&irq->refcount)) {\n\t\tmutex_unlock(&dmc620_pmu_irqs_lock);\n\t\treturn;\n\t}\n\n\tlist_del(&irq->irqs_node);\n\tmutex_unlock(&dmc620_pmu_irqs_lock);\n\n\tfree_irq(irq->irq_num, irq);\n\tcpuhp_state_remove_instance_nocalls(cpuhp_state_num, &irq->node);\n\tkfree(irq);\n}\n\nstatic int dmc620_pmu_event_init(struct perf_event *event)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct perf_event *sibling;\n\n\tif (event->attr.type != event->pmu->type)\n\t\treturn -ENOENT;\n\n\t \n\tif (is_sampling_event(event) ||\n\t\tevent->attach_state & PERF_ATTACH_TASK) {\n\t\tdev_dbg(dmc620_pmu->pmu.dev,\n\t\t\t\"Can't support per-task counters\\n\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\t \n\tevent->cpu = dmc620_pmu->irq->cpu;\n\tif (event->cpu < 0)\n\t\treturn -EINVAL;\n\n\t \n\tif (event->group_leader != event &&\n\t\t\t!is_software_event(event->group_leader))\n\t\treturn -EINVAL;\n\n\tfor_each_sibling_event(sibling, event->group_leader) {\n\t\tif (sibling != event &&\n\t\t\t\t!is_software_event(sibling))\n\t\t\treturn -EINVAL;\n\t}\n\n\thwc->idx = -1;\n\treturn 0;\n}\n\nstatic void dmc620_pmu_read(struct perf_event *event)\n{\n\tdmc620_pmu_event_update(event);\n}\n\nstatic void dmc620_pmu_start(struct perf_event *event, int flags)\n{\n\tevent->hw.state = 0;\n\tdmc620_pmu_event_set_period(event);\n\tdmc620_pmu_enable_counter(event);\n}\n\nstatic void dmc620_pmu_stop(struct perf_event *event, int flags)\n{\n\tif (event->hw.state & PERF_HES_STOPPED)\n\t\treturn;\n\n\tdmc620_pmu_disable_counter(event);\n\tdmc620_pmu_event_update(event);\n\tevent->hw.state |= PERF_HES_STOPPED | PERF_HES_UPTODATE;\n}\n\nstatic int dmc620_pmu_add(struct perf_event *event, int flags)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\tstruct perf_event_attr *attr = &event->attr;\n\tstruct hw_perf_event *hwc = &event->hw;\n\tint idx;\n\tu64 reg;\n\n\tidx = dmc620_get_event_idx(event);\n\tif (idx < 0)\n\t\treturn idx;\n\n\thwc->idx = idx;\n\tdmc620_pmu->events[idx] = event;\n\thwc->state = PERF_HES_STOPPED | PERF_HES_UPTODATE;\n\n\treg = ATTR_CFG_GET_FLD(attr, mask);\n\tdmc620_pmu_creg_write(dmc620_pmu,\n\t\t\t      idx, DMC620_PMU_COUNTERn_MASK_31_00, lower_32_bits(reg));\n\tdmc620_pmu_creg_write(dmc620_pmu,\n\t\t\t      idx, DMC620_PMU_COUNTERn_MASK_63_32, upper_32_bits(reg));\n\n\treg = ATTR_CFG_GET_FLD(attr, match);\n\tdmc620_pmu_creg_write(dmc620_pmu,\n\t\t\t      idx, DMC620_PMU_COUNTERn_MATCH_31_00, lower_32_bits(reg));\n\tdmc620_pmu_creg_write(dmc620_pmu,\n\t\t\t      idx, DMC620_PMU_COUNTERn_MATCH_63_32, upper_32_bits(reg));\n\n\tif (flags & PERF_EF_START)\n\t\tdmc620_pmu_start(event, PERF_EF_RELOAD);\n\n\tperf_event_update_userpage(event);\n\treturn 0;\n}\n\nstatic void dmc620_pmu_del(struct perf_event *event, int flags)\n{\n\tstruct dmc620_pmu *dmc620_pmu = to_dmc620_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\tint idx = hwc->idx;\n\n\tdmc620_pmu_stop(event, PERF_EF_UPDATE);\n\tdmc620_pmu->events[idx] = NULL;\n\tclear_bit(idx, dmc620_pmu->used_mask);\n\tperf_event_update_userpage(event);\n}\n\nstatic int dmc620_pmu_cpu_teardown(unsigned int cpu,\n\t\t\t\t   struct hlist_node *node)\n{\n\tstruct dmc620_pmu_irq *irq;\n\tstruct dmc620_pmu *dmc620_pmu;\n\tunsigned int target;\n\n\tirq = hlist_entry_safe(node, struct dmc620_pmu_irq, node);\n\tif (cpu != irq->cpu)\n\t\treturn 0;\n\n\ttarget = cpumask_any_but(cpu_online_mask, cpu);\n\tif (target >= nr_cpu_ids)\n\t\treturn 0;\n\n\t \n\tmutex_lock(&dmc620_pmu_node_lock);\n\tlist_for_each_entry(dmc620_pmu, &irq->pmus_node, pmus_node)\n\t\tperf_pmu_migrate_context(&dmc620_pmu->pmu, irq->cpu, target);\n\tmutex_unlock(&dmc620_pmu_node_lock);\n\n\tWARN_ON(irq_set_affinity(irq->irq_num, cpumask_of(target)));\n\tirq->cpu = target;\n\n\treturn 0;\n}\n\nstatic int dmc620_pmu_device_probe(struct platform_device *pdev)\n{\n\tstruct dmc620_pmu *dmc620_pmu;\n\tstruct resource *res;\n\tchar *name;\n\tint irq_num;\n\tint i, ret;\n\n\tdmc620_pmu = devm_kzalloc(&pdev->dev,\n\t\t\tsizeof(struct dmc620_pmu), GFP_KERNEL);\n\tif (!dmc620_pmu)\n\t\treturn -ENOMEM;\n\n\tplatform_set_drvdata(pdev, dmc620_pmu);\n\n\tdmc620_pmu->pmu = (struct pmu) {\n\t\t.module = THIS_MODULE,\n\t\t.capabilities\t= PERF_PMU_CAP_NO_EXCLUDE,\n\t\t.task_ctx_nr\t= perf_invalid_context,\n\t\t.event_init\t= dmc620_pmu_event_init,\n\t\t.add\t\t= dmc620_pmu_add,\n\t\t.del\t\t= dmc620_pmu_del,\n\t\t.start\t\t= dmc620_pmu_start,\n\t\t.stop\t\t= dmc620_pmu_stop,\n\t\t.read\t\t= dmc620_pmu_read,\n\t\t.attr_groups\t= dmc620_pmu_attr_groups,\n\t};\n\n\tdmc620_pmu->base = devm_platform_get_and_ioremap_resource(pdev, 0, &res);\n\tif (IS_ERR(dmc620_pmu->base))\n\t\treturn PTR_ERR(dmc620_pmu->base);\n\n\t \n\tfor (i = 0; i < DMC620_PMU_MAX_COUNTERS; i++)\n\t\tdmc620_pmu_creg_write(dmc620_pmu, i, DMC620_PMU_COUNTERn_CONTROL, 0);\n\twritel(0, dmc620_pmu->base + DMC620_PMU_OVERFLOW_STATUS_CLKDIV2);\n\twritel(0, dmc620_pmu->base + DMC620_PMU_OVERFLOW_STATUS_CLK);\n\n\tirq_num = platform_get_irq(pdev, 0);\n\tif (irq_num < 0)\n\t\treturn irq_num;\n\n\tret = dmc620_pmu_get_irq(dmc620_pmu, irq_num);\n\tif (ret)\n\t\treturn ret;\n\n\tname = devm_kasprintf(&pdev->dev, GFP_KERNEL,\n\t\t\t\t  \"%s_%llx\", DMC620_PMUNAME,\n\t\t\t\t  (u64)(res->start >> DMC620_PA_SHIFT));\n\tif (!name) {\n\t\tdev_err(&pdev->dev,\n\t\t\t  \"Create name failed, PMU @%pa\\n\", &res->start);\n\t\tret = -ENOMEM;\n\t\tgoto out_teardown_dev;\n\t}\n\n\tret = perf_pmu_register(&dmc620_pmu->pmu, name, -1);\n\tif (ret)\n\t\tgoto out_teardown_dev;\n\n\treturn 0;\n\nout_teardown_dev:\n\tdmc620_pmu_put_irq(dmc620_pmu);\n\tsynchronize_rcu();\n\treturn ret;\n}\n\nstatic int dmc620_pmu_device_remove(struct platform_device *pdev)\n{\n\tstruct dmc620_pmu *dmc620_pmu = platform_get_drvdata(pdev);\n\n\tdmc620_pmu_put_irq(dmc620_pmu);\n\n\t \n\tperf_pmu_unregister(&dmc620_pmu->pmu);\n\n\treturn 0;\n}\n\nstatic const struct acpi_device_id dmc620_acpi_match[] = {\n\t{ \"ARMHD620\", 0},\n\t{},\n};\nMODULE_DEVICE_TABLE(acpi, dmc620_acpi_match);\nstatic struct platform_driver dmc620_pmu_driver = {\n\t.driver\t= {\n\t\t.name\t\t= DMC620_DRVNAME,\n\t\t.acpi_match_table = dmc620_acpi_match,\n\t\t.suppress_bind_attrs = true,\n\t},\n\t.probe\t= dmc620_pmu_device_probe,\n\t.remove\t= dmc620_pmu_device_remove,\n};\n\nstatic int __init dmc620_pmu_init(void)\n{\n\tint ret;\n\n\tcpuhp_state_num = cpuhp_setup_state_multi(CPUHP_AP_ONLINE_DYN,\n\t\t\t\t      DMC620_DRVNAME,\n\t\t\t\t      NULL,\n\t\t\t\t      dmc620_pmu_cpu_teardown);\n\tif (cpuhp_state_num < 0)\n\t\treturn cpuhp_state_num;\n\n\tret = platform_driver_register(&dmc620_pmu_driver);\n\tif (ret)\n\t\tcpuhp_remove_multi_state(cpuhp_state_num);\n\n\treturn ret;\n}\n\nstatic void __exit dmc620_pmu_exit(void)\n{\n\tplatform_driver_unregister(&dmc620_pmu_driver);\n\tcpuhp_remove_multi_state(cpuhp_state_num);\n}\n\nmodule_init(dmc620_pmu_init);\nmodule_exit(dmc620_pmu_exit);\n\nMODULE_DESCRIPTION(\"Perf driver for the ARM DMC-620 memory controller\");\nMODULE_AUTHOR(\"Tuan Phan <tuanphan@os.amperecomputing.com\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}