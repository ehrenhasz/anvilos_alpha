{
  "module_name": "xgene_pmu.c",
  "hash_id": "e7c793f349b09b5905b688223586eb1dfe5473f02c256a8d79c75bcc20133b26",
  "original_prompt": "Ingested from linux-6.6.14/drivers/perf/xgene_pmu.c",
  "human_readable_source": "\n \n\n#include <linux/acpi.h>\n#include <linux/clk.h>\n#include <linux/cpuhotplug.h>\n#include <linux/cpumask.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/mfd/syscon.h>\n#include <linux/module.h>\n#include <linux/of_address.h>\n#include <linux/of_fdt.h>\n#include <linux/of_irq.h>\n#include <linux/of_platform.h>\n#include <linux/perf_event.h>\n#include <linux/platform_device.h>\n#include <linux/regmap.h>\n#include <linux/slab.h>\n\n#define CSW_CSWCR                       0x0000\n#define  CSW_CSWCR_DUALMCB_MASK         BIT(0)\n#define  CSW_CSWCR_MCB0_ROUTING(x)\t(((x) & 0x0C) >> 2)\n#define  CSW_CSWCR_MCB1_ROUTING(x)\t(((x) & 0x30) >> 4)\n#define MCBADDRMR                       0x0000\n#define  MCBADDRMR_DUALMCU_MODE_MASK    BIT(2)\n\n#define PCPPMU_INTSTATUS_REG\t0x000\n#define PCPPMU_INTMASK_REG\t0x004\n#define  PCPPMU_INTMASK\t\t0x0000000F\n#define  PCPPMU_INTENMASK\t0xFFFFFFFF\n#define  PCPPMU_INTCLRMASK\t0xFFFFFFF0\n#define  PCPPMU_INT_MCU\t\tBIT(0)\n#define  PCPPMU_INT_MCB\t\tBIT(1)\n#define  PCPPMU_INT_L3C\t\tBIT(2)\n#define  PCPPMU_INT_IOB\t\tBIT(3)\n\n#define  PCPPMU_V3_INTMASK\t0x00FF33FF\n#define  PCPPMU_V3_INTENMASK\t0xFFFFFFFF\n#define  PCPPMU_V3_INTCLRMASK\t0xFF00CC00\n#define  PCPPMU_V3_INT_MCU\t0x000000FF\n#define  PCPPMU_V3_INT_MCB\t0x00000300\n#define  PCPPMU_V3_INT_L3C\t0x00FF0000\n#define  PCPPMU_V3_INT_IOB\t0x00003000\n\n#define PMU_MAX_COUNTERS\t4\n#define PMU_CNT_MAX_PERIOD\t0xFFFFFFFFULL\n#define PMU_V3_CNT_MAX_PERIOD\t0xFFFFFFFFFFFFFFFFULL\n#define PMU_OVERFLOW_MASK\t0xF\n#define PMU_PMCR_E\t\tBIT(0)\n#define PMU_PMCR_P\t\tBIT(1)\n\n#define PMU_PMEVCNTR0\t\t0x000\n#define PMU_PMEVCNTR1\t\t0x004\n#define PMU_PMEVCNTR2\t\t0x008\n#define PMU_PMEVCNTR3\t\t0x00C\n#define PMU_PMEVTYPER0\t\t0x400\n#define PMU_PMEVTYPER1\t\t0x404\n#define PMU_PMEVTYPER2\t\t0x408\n#define PMU_PMEVTYPER3\t\t0x40C\n#define PMU_PMAMR0\t\t0xA00\n#define PMU_PMAMR1\t\t0xA04\n#define PMU_PMCNTENSET\t\t0xC00\n#define PMU_PMCNTENCLR\t\t0xC20\n#define PMU_PMINTENSET\t\t0xC40\n#define PMU_PMINTENCLR\t\t0xC60\n#define PMU_PMOVSR\t\t0xC80\n#define PMU_PMCR\t\t0xE04\n\n \n#define PMU_PMOVSCLR\t\t0xC80\n#define PMU_PMOVSSET\t\t0xCC0\n\n#define to_pmu_dev(p)     container_of(p, struct xgene_pmu_dev, pmu)\n#define GET_CNTR(ev)      (ev->hw.idx)\n#define GET_EVENTID(ev)   (ev->hw.config & 0xFFULL)\n#define GET_AGENTID(ev)   (ev->hw.config_base & 0xFFFFFFFFUL)\n#define GET_AGENT1ID(ev)  ((ev->hw.config_base >> 32) & 0xFFFFFFFFUL)\n\nstruct hw_pmu_info {\n\tu32 type;\n\tu32 enable_mask;\n\tvoid __iomem *csr;\n};\n\nstruct xgene_pmu_dev {\n\tstruct hw_pmu_info *inf;\n\tstruct xgene_pmu *parent;\n\tstruct pmu pmu;\n\tu8 max_counters;\n\tDECLARE_BITMAP(cntr_assign_mask, PMU_MAX_COUNTERS);\n\tu64 max_period;\n\tconst struct attribute_group **attr_groups;\n\tstruct perf_event *pmu_counter_event[PMU_MAX_COUNTERS];\n};\n\nstruct xgene_pmu_ops {\n\tvoid (*mask_int)(struct xgene_pmu *pmu);\n\tvoid (*unmask_int)(struct xgene_pmu *pmu);\n\tu64 (*read_counter)(struct xgene_pmu_dev *pmu, int idx);\n\tvoid (*write_counter)(struct xgene_pmu_dev *pmu, int idx, u64 val);\n\tvoid (*write_evttype)(struct xgene_pmu_dev *pmu_dev, int idx, u32 val);\n\tvoid (*write_agentmsk)(struct xgene_pmu_dev *pmu_dev, u32 val);\n\tvoid (*write_agent1msk)(struct xgene_pmu_dev *pmu_dev, u32 val);\n\tvoid (*enable_counter)(struct xgene_pmu_dev *pmu_dev, int idx);\n\tvoid (*disable_counter)(struct xgene_pmu_dev *pmu_dev, int idx);\n\tvoid (*enable_counter_int)(struct xgene_pmu_dev *pmu_dev, int idx);\n\tvoid (*disable_counter_int)(struct xgene_pmu_dev *pmu_dev, int idx);\n\tvoid (*reset_counters)(struct xgene_pmu_dev *pmu_dev);\n\tvoid (*start_counters)(struct xgene_pmu_dev *pmu_dev);\n\tvoid (*stop_counters)(struct xgene_pmu_dev *pmu_dev);\n};\n\nstruct xgene_pmu {\n\tstruct device *dev;\n\tstruct hlist_node node;\n\tint version;\n\tvoid __iomem *pcppmu_csr;\n\tu32 mcb_active_mask;\n\tu32 mc_active_mask;\n\tu32 l3c_active_mask;\n\tcpumask_t cpu;\n\tint irq;\n\traw_spinlock_t lock;\n\tconst struct xgene_pmu_ops *ops;\n\tstruct list_head l3cpmus;\n\tstruct list_head iobpmus;\n\tstruct list_head mcbpmus;\n\tstruct list_head mcpmus;\n};\n\nstruct xgene_pmu_dev_ctx {\n\tchar *name;\n\tstruct list_head next;\n\tstruct xgene_pmu_dev *pmu_dev;\n\tstruct hw_pmu_info inf;\n};\n\nstruct xgene_pmu_data {\n\tint id;\n\tu32 data;\n};\n\nenum xgene_pmu_version {\n\tPCP_PMU_V1 = 1,\n\tPCP_PMU_V2,\n\tPCP_PMU_V3,\n};\n\nenum xgene_pmu_dev_type {\n\tPMU_TYPE_L3C = 0,\n\tPMU_TYPE_IOB,\n\tPMU_TYPE_IOB_SLOW,\n\tPMU_TYPE_MCB,\n\tPMU_TYPE_MC,\n};\n\n \nstatic ssize_t xgene_pmu_format_show(struct device *dev,\n\t\t\t\t     struct device_attribute *attr, char *buf)\n{\n\tstruct dev_ext_attribute *eattr;\n\n\teattr = container_of(attr, struct dev_ext_attribute, attr);\n\treturn sysfs_emit(buf, \"%s\\n\", (char *) eattr->var);\n}\n\n#define XGENE_PMU_FORMAT_ATTR(_name, _config)\t\t\\\n\t(&((struct dev_ext_attribute[]) {\t\t\\\n\t\t{ .attr = __ATTR(_name, S_IRUGO, xgene_pmu_format_show, NULL), \\\n\t\t  .var = (void *) _config, }\t\t\\\n\t})[0].attr.attr)\n\nstatic struct attribute *l3c_pmu_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(l3c_eventid, \"config:0-7\"),\n\tXGENE_PMU_FORMAT_ATTR(l3c_agentid, \"config1:0-9\"),\n\tNULL,\n};\n\nstatic struct attribute *iob_pmu_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(iob_eventid, \"config:0-7\"),\n\tXGENE_PMU_FORMAT_ATTR(iob_agentid, \"config1:0-63\"),\n\tNULL,\n};\n\nstatic struct attribute *mcb_pmu_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(mcb_eventid, \"config:0-5\"),\n\tXGENE_PMU_FORMAT_ATTR(mcb_agentid, \"config1:0-9\"),\n\tNULL,\n};\n\nstatic struct attribute *mc_pmu_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(mc_eventid, \"config:0-28\"),\n\tNULL,\n};\n\nstatic const struct attribute_group l3c_pmu_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = l3c_pmu_format_attrs,\n};\n\nstatic const struct attribute_group iob_pmu_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = iob_pmu_format_attrs,\n};\n\nstatic const struct attribute_group mcb_pmu_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = mcb_pmu_format_attrs,\n};\n\nstatic const struct attribute_group mc_pmu_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = mc_pmu_format_attrs,\n};\n\nstatic struct attribute *l3c_pmu_v3_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(l3c_eventid, \"config:0-39\"),\n\tNULL,\n};\n\nstatic struct attribute *iob_pmu_v3_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(iob_eventid, \"config:0-47\"),\n\tNULL,\n};\n\nstatic struct attribute *iob_slow_pmu_v3_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(iob_slow_eventid, \"config:0-16\"),\n\tNULL,\n};\n\nstatic struct attribute *mcb_pmu_v3_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(mcb_eventid, \"config:0-35\"),\n\tNULL,\n};\n\nstatic struct attribute *mc_pmu_v3_format_attrs[] = {\n\tXGENE_PMU_FORMAT_ATTR(mc_eventid, \"config:0-44\"),\n\tNULL,\n};\n\nstatic const struct attribute_group l3c_pmu_v3_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = l3c_pmu_v3_format_attrs,\n};\n\nstatic const struct attribute_group iob_pmu_v3_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = iob_pmu_v3_format_attrs,\n};\n\nstatic const struct attribute_group iob_slow_pmu_v3_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = iob_slow_pmu_v3_format_attrs,\n};\n\nstatic const struct attribute_group mcb_pmu_v3_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = mcb_pmu_v3_format_attrs,\n};\n\nstatic const struct attribute_group mc_pmu_v3_format_attr_group = {\n\t.name = \"format\",\n\t.attrs = mc_pmu_v3_format_attrs,\n};\n\n \nstatic ssize_t xgene_pmu_event_show(struct device *dev,\n\t\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct perf_pmu_events_attr *pmu_attr =\n\t\tcontainer_of(attr, struct perf_pmu_events_attr, attr);\n\n\treturn sysfs_emit(buf, \"config=0x%llx\\n\", pmu_attr->id);\n}\n\n#define XGENE_PMU_EVENT_ATTR(_name, _config)\t\t\\\n\tPMU_EVENT_ATTR_ID(_name, xgene_pmu_event_show, _config)\n\nstatic struct attribute *l3c_pmu_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(cycle-count-div-64,\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(read-hit,\t\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(read-miss,\t\t\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(write-need-replacement,\t\t0x06),\n\tXGENE_PMU_EVENT_ATTR(write-not-need-replacement,\t0x07),\n\tXGENE_PMU_EVENT_ATTR(tq-full,\t\t\t\t0x08),\n\tXGENE_PMU_EVENT_ATTR(ackq-full,\t\t\t\t0x09),\n\tXGENE_PMU_EVENT_ATTR(wdb-full,\t\t\t\t0x0a),\n\tXGENE_PMU_EVENT_ATTR(bank-fifo-full,\t\t\t0x0b),\n\tXGENE_PMU_EVENT_ATTR(odb-full,\t\t\t\t0x0c),\n\tXGENE_PMU_EVENT_ATTR(wbq-full,\t\t\t\t0x0d),\n\tXGENE_PMU_EVENT_ATTR(bank-conflict-fifo-issue,\t\t0x0e),\n\tXGENE_PMU_EVENT_ATTR(bank-fifo-issue,\t\t\t0x0f),\n\tNULL,\n};\n\nstatic struct attribute *iob_pmu_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(cycle-count-div-64,\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(axi0-read,\t\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(axi0-read-partial,\t\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(axi1-read,\t\t\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(axi1-read-partial,\t\t\t0x05),\n\tXGENE_PMU_EVENT_ATTR(csw-read-block,\t\t\t0x06),\n\tXGENE_PMU_EVENT_ATTR(csw-read-partial,\t\t\t0x07),\n\tXGENE_PMU_EVENT_ATTR(axi0-write,\t\t\t0x10),\n\tXGENE_PMU_EVENT_ATTR(axi0-write-partial,\t\t0x11),\n\tXGENE_PMU_EVENT_ATTR(axi1-write,\t\t\t0x13),\n\tXGENE_PMU_EVENT_ATTR(axi1-write-partial,\t\t0x14),\n\tXGENE_PMU_EVENT_ATTR(csw-inbound-dirty,\t\t\t0x16),\n\tNULL,\n};\n\nstatic struct attribute *mcb_pmu_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(cycle-count-div-64,\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(csw-read,\t\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(csw-write-request,\t\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(mcb-csw-stall,\t\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(cancel-read-gack,\t\t\t0x05),\n\tNULL,\n};\n\nstatic struct attribute *mc_pmu_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(cycle-count-div-64,\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(act-cmd-sent,\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(pre-cmd-sent,\t\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(rd-cmd-sent,\t\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(rda-cmd-sent,\t\t\t0x05),\n\tXGENE_PMU_EVENT_ATTR(wr-cmd-sent,\t\t\t0x06),\n\tXGENE_PMU_EVENT_ATTR(wra-cmd-sent,\t\t\t0x07),\n\tXGENE_PMU_EVENT_ATTR(pde-cmd-sent,\t\t\t0x08),\n\tXGENE_PMU_EVENT_ATTR(sre-cmd-sent,\t\t\t0x09),\n\tXGENE_PMU_EVENT_ATTR(prea-cmd-sent,\t\t\t0x0a),\n\tXGENE_PMU_EVENT_ATTR(ref-cmd-sent,\t\t\t0x0b),\n\tXGENE_PMU_EVENT_ATTR(rd-rda-cmd-sent,\t\t\t0x0c),\n\tXGENE_PMU_EVENT_ATTR(wr-wra-cmd-sent,\t\t\t0x0d),\n\tXGENE_PMU_EVENT_ATTR(in-rd-collision,\t\t\t0x0e),\n\tXGENE_PMU_EVENT_ATTR(in-wr-collision,\t\t\t0x0f),\n\tXGENE_PMU_EVENT_ATTR(collision-queue-not-empty,\t\t0x10),\n\tXGENE_PMU_EVENT_ATTR(collision-queue-full,\t\t0x11),\n\tXGENE_PMU_EVENT_ATTR(mcu-request,\t\t\t0x12),\n\tXGENE_PMU_EVENT_ATTR(mcu-rd-request,\t\t\t0x13),\n\tXGENE_PMU_EVENT_ATTR(mcu-hp-rd-request,\t\t\t0x14),\n\tXGENE_PMU_EVENT_ATTR(mcu-wr-request,\t\t\t0x15),\n\tXGENE_PMU_EVENT_ATTR(mcu-rd-proceed-all,\t\t0x16),\n\tXGENE_PMU_EVENT_ATTR(mcu-rd-proceed-cancel,\t\t0x17),\n\tXGENE_PMU_EVENT_ATTR(mcu-rd-response,\t\t\t0x18),\n\tXGENE_PMU_EVENT_ATTR(mcu-rd-proceed-speculative-all,\t0x19),\n\tXGENE_PMU_EVENT_ATTR(mcu-rd-proceed-speculative-cancel,\t0x1a),\n\tXGENE_PMU_EVENT_ATTR(mcu-wr-proceed-all,\t\t0x1b),\n\tXGENE_PMU_EVENT_ATTR(mcu-wr-proceed-cancel,\t\t0x1c),\n\tNULL,\n};\n\nstatic const struct attribute_group l3c_pmu_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = l3c_pmu_events_attrs,\n};\n\nstatic const struct attribute_group iob_pmu_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = iob_pmu_events_attrs,\n};\n\nstatic const struct attribute_group mcb_pmu_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = mcb_pmu_events_attrs,\n};\n\nstatic const struct attribute_group mc_pmu_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = mc_pmu_events_attrs,\n};\n\nstatic struct attribute *l3c_pmu_v3_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(read-hit,\t\t\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(read-miss,\t\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(index-flush-eviction,\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(write-caused-replacement,\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(write-not-caused-replacement,\t0x05),\n\tXGENE_PMU_EVENT_ATTR(clean-eviction,\t\t\t0x06),\n\tXGENE_PMU_EVENT_ATTR(dirty-eviction,\t\t\t0x07),\n\tXGENE_PMU_EVENT_ATTR(read,\t\t\t\t0x08),\n\tXGENE_PMU_EVENT_ATTR(write,\t\t\t\t0x09),\n\tXGENE_PMU_EVENT_ATTR(request,\t\t\t\t0x0a),\n\tXGENE_PMU_EVENT_ATTR(tq-bank-conflict-issue-stall,\t0x0b),\n\tXGENE_PMU_EVENT_ATTR(tq-full,\t\t\t\t0x0c),\n\tXGENE_PMU_EVENT_ATTR(ackq-full,\t\t\t\t0x0d),\n\tXGENE_PMU_EVENT_ATTR(wdb-full,\t\t\t\t0x0e),\n\tXGENE_PMU_EVENT_ATTR(odb-full,\t\t\t\t0x10),\n\tXGENE_PMU_EVENT_ATTR(wbq-full,\t\t\t\t0x11),\n\tXGENE_PMU_EVENT_ATTR(input-req-async-fifo-stall,\t0x12),\n\tXGENE_PMU_EVENT_ATTR(output-req-async-fifo-stall,\t0x13),\n\tXGENE_PMU_EVENT_ATTR(output-data-async-fifo-stall,\t0x14),\n\tXGENE_PMU_EVENT_ATTR(total-insertion,\t\t\t0x15),\n\tXGENE_PMU_EVENT_ATTR(sip-insertions-r-set,\t\t0x16),\n\tXGENE_PMU_EVENT_ATTR(sip-insertions-r-clear,\t\t0x17),\n\tXGENE_PMU_EVENT_ATTR(dip-insertions-r-set,\t\t0x18),\n\tXGENE_PMU_EVENT_ATTR(dip-insertions-r-clear,\t\t0x19),\n\tXGENE_PMU_EVENT_ATTR(dip-insertions-force-r-set,\t0x1a),\n\tXGENE_PMU_EVENT_ATTR(egression,\t\t\t\t0x1b),\n\tXGENE_PMU_EVENT_ATTR(replacement,\t\t\t0x1c),\n\tXGENE_PMU_EVENT_ATTR(old-replacement,\t\t\t0x1d),\n\tXGENE_PMU_EVENT_ATTR(young-replacement,\t\t\t0x1e),\n\tXGENE_PMU_EVENT_ATTR(r-set-replacement,\t\t\t0x1f),\n\tXGENE_PMU_EVENT_ATTR(r-clear-replacement,\t\t0x20),\n\tXGENE_PMU_EVENT_ATTR(old-r-replacement,\t\t\t0x21),\n\tXGENE_PMU_EVENT_ATTR(old-nr-replacement,\t\t0x22),\n\tXGENE_PMU_EVENT_ATTR(young-r-replacement,\t\t0x23),\n\tXGENE_PMU_EVENT_ATTR(young-nr-replacement,\t\t0x24),\n\tXGENE_PMU_EVENT_ATTR(bloomfilter-clearing,\t\t0x25),\n\tXGENE_PMU_EVENT_ATTR(generation-flip,\t\t\t0x26),\n\tXGENE_PMU_EVENT_ATTR(vcc-droop-detected,\t\t0x27),\n\tNULL,\n};\n\nstatic struct attribute *iob_fast_pmu_v3_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(pa-req-buf-alloc-all,\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(pa-req-buf-alloc-rd,\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(pa-req-buf-alloc-wr,\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(pa-all-cp-req,\t\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(pa-cp-blk-req,\t\t\t0x05),\n\tXGENE_PMU_EVENT_ATTR(pa-cp-ptl-req,\t\t\t0x06),\n\tXGENE_PMU_EVENT_ATTR(pa-cp-rd-req,\t\t\t0x07),\n\tXGENE_PMU_EVENT_ATTR(pa-cp-wr-req,\t\t\t0x08),\n\tXGENE_PMU_EVENT_ATTR(ba-all-req,\t\t\t0x09),\n\tXGENE_PMU_EVENT_ATTR(ba-rd-req,\t\t\t\t0x0a),\n\tXGENE_PMU_EVENT_ATTR(ba-wr-req,\t\t\t\t0x0b),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-shared-req-issued,\t\t0x10),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-exclusive-req-issued,\t0x11),\n\tXGENE_PMU_EVENT_ATTR(pa-wr-invalidate-req-issued-stashable, 0x12),\n\tXGENE_PMU_EVENT_ATTR(pa-wr-invalidate-req-issued-nonstashable, 0x13),\n\tXGENE_PMU_EVENT_ATTR(pa-wr-back-req-issued-stashable,\t0x14),\n\tXGENE_PMU_EVENT_ATTR(pa-wr-back-req-issued-nonstashable, 0x15),\n\tXGENE_PMU_EVENT_ATTR(pa-ptl-wr-req,\t\t\t0x16),\n\tXGENE_PMU_EVENT_ATTR(pa-ptl-rd-req,\t\t\t0x17),\n\tXGENE_PMU_EVENT_ATTR(pa-wr-back-clean-data,\t\t0x18),\n\tXGENE_PMU_EVENT_ATTR(pa-wr-back-cancelled-on-SS,\t0x1b),\n\tXGENE_PMU_EVENT_ATTR(pa-barrier-occurrence,\t\t0x1c),\n\tXGENE_PMU_EVENT_ATTR(pa-barrier-cycles,\t\t\t0x1d),\n\tXGENE_PMU_EVENT_ATTR(pa-total-cp-snoops,\t\t0x20),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-shared-snoop,\t\t0x21),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-shared-snoop-hit,\t\t0x22),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-exclusive-snoop,\t\t0x23),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-exclusive-snoop-hit,\t\t0x24),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-wr-invalid-snoop,\t\t0x25),\n\tXGENE_PMU_EVENT_ATTR(pa-rd-wr-invalid-snoop-hit,\t0x26),\n\tXGENE_PMU_EVENT_ATTR(pa-req-buffer-full,\t\t0x28),\n\tXGENE_PMU_EVENT_ATTR(cswlf-outbound-req-fifo-full,\t0x29),\n\tXGENE_PMU_EVENT_ATTR(cswlf-inbound-snoop-fifo-backpressure, 0x2a),\n\tXGENE_PMU_EVENT_ATTR(cswlf-outbound-lack-fifo-full,\t0x2b),\n\tXGENE_PMU_EVENT_ATTR(cswlf-inbound-gack-fifo-backpressure, 0x2c),\n\tXGENE_PMU_EVENT_ATTR(cswlf-outbound-data-fifo-full,\t0x2d),\n\tXGENE_PMU_EVENT_ATTR(cswlf-inbound-data-fifo-backpressure, 0x2e),\n\tXGENE_PMU_EVENT_ATTR(cswlf-inbound-req-backpressure,\t0x2f),\n\tNULL,\n};\n\nstatic struct attribute *iob_slow_pmu_v3_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(pa-axi0-rd-req,\t\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(pa-axi0-wr-req,\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(pa-axi1-rd-req,\t\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(pa-axi1-wr-req,\t\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(ba-all-axi-req,\t\t\t0x07),\n\tXGENE_PMU_EVENT_ATTR(ba-axi-rd-req,\t\t\t0x08),\n\tXGENE_PMU_EVENT_ATTR(ba-axi-wr-req,\t\t\t0x09),\n\tXGENE_PMU_EVENT_ATTR(ba-free-list-empty,\t\t0x10),\n\tNULL,\n};\n\nstatic struct attribute *mcb_pmu_v3_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(req-receive,\t\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(rd-req-recv,\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(rd-req-recv-2,\t\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(wr-req-recv,\t\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(wr-req-recv-2,\t\t\t0x05),\n\tXGENE_PMU_EVENT_ATTR(rd-req-sent-to-mcu,\t\t0x06),\n\tXGENE_PMU_EVENT_ATTR(rd-req-sent-to-mcu-2,\t\t0x07),\n\tXGENE_PMU_EVENT_ATTR(rd-req-sent-to-spec-mcu,\t\t0x08),\n\tXGENE_PMU_EVENT_ATTR(rd-req-sent-to-spec-mcu-2,\t\t0x09),\n\tXGENE_PMU_EVENT_ATTR(glbl-ack-recv-for-rd-sent-to-spec-mcu, 0x0a),\n\tXGENE_PMU_EVENT_ATTR(glbl-ack-go-recv-for-rd-sent-to-spec-mcu, 0x0b),\n\tXGENE_PMU_EVENT_ATTR(glbl-ack-nogo-recv-for-rd-sent-to-spec-mcu, 0x0c),\n\tXGENE_PMU_EVENT_ATTR(glbl-ack-go-recv-any-rd-req,\t0x0d),\n\tXGENE_PMU_EVENT_ATTR(glbl-ack-go-recv-any-rd-req-2,\t0x0e),\n\tXGENE_PMU_EVENT_ATTR(wr-req-sent-to-mcu,\t\t0x0f),\n\tXGENE_PMU_EVENT_ATTR(gack-recv,\t\t\t\t0x10),\n\tXGENE_PMU_EVENT_ATTR(rd-gack-recv,\t\t\t0x11),\n\tXGENE_PMU_EVENT_ATTR(wr-gack-recv,\t\t\t0x12),\n\tXGENE_PMU_EVENT_ATTR(cancel-rd-gack,\t\t\t0x13),\n\tXGENE_PMU_EVENT_ATTR(cancel-wr-gack,\t\t\t0x14),\n\tXGENE_PMU_EVENT_ATTR(mcb-csw-req-stall,\t\t\t0x15),\n\tXGENE_PMU_EVENT_ATTR(mcu-req-intf-blocked,\t\t0x16),\n\tXGENE_PMU_EVENT_ATTR(mcb-mcu-rd-intf-stall,\t\t0x17),\n\tXGENE_PMU_EVENT_ATTR(csw-rd-intf-blocked,\t\t0x18),\n\tXGENE_PMU_EVENT_ATTR(csw-local-ack-intf-blocked,\t0x19),\n\tXGENE_PMU_EVENT_ATTR(mcu-req-table-full,\t\t0x1a),\n\tXGENE_PMU_EVENT_ATTR(mcu-stat-table-full,\t\t0x1b),\n\tXGENE_PMU_EVENT_ATTR(mcu-wr-table-full,\t\t\t0x1c),\n\tXGENE_PMU_EVENT_ATTR(mcu-rdreceipt-resp,\t\t0x1d),\n\tXGENE_PMU_EVENT_ATTR(mcu-wrcomplete-resp,\t\t0x1e),\n\tXGENE_PMU_EVENT_ATTR(mcu-retryack-resp,\t\t\t0x1f),\n\tXGENE_PMU_EVENT_ATTR(mcu-pcrdgrant-resp,\t\t0x20),\n\tXGENE_PMU_EVENT_ATTR(mcu-req-from-lastload,\t\t0x21),\n\tXGENE_PMU_EVENT_ATTR(mcu-req-from-bypass,\t\t0x22),\n\tXGENE_PMU_EVENT_ATTR(volt-droop-detect,\t\t\t0x23),\n\tNULL,\n};\n\nstatic struct attribute *mc_pmu_v3_events_attrs[] = {\n\tXGENE_PMU_EVENT_ATTR(cycle-count,\t\t\t0x00),\n\tXGENE_PMU_EVENT_ATTR(act-sent,\t\t\t\t0x01),\n\tXGENE_PMU_EVENT_ATTR(pre-sent,\t\t\t\t0x02),\n\tXGENE_PMU_EVENT_ATTR(rd-sent,\t\t\t\t0x03),\n\tXGENE_PMU_EVENT_ATTR(rda-sent,\t\t\t\t0x04),\n\tXGENE_PMU_EVENT_ATTR(wr-sent,\t\t\t\t0x05),\n\tXGENE_PMU_EVENT_ATTR(wra-sent,\t\t\t\t0x06),\n\tXGENE_PMU_EVENT_ATTR(pd-entry-vld,\t\t\t0x07),\n\tXGENE_PMU_EVENT_ATTR(sref-entry-vld,\t\t\t0x08),\n\tXGENE_PMU_EVENT_ATTR(prea-sent,\t\t\t\t0x09),\n\tXGENE_PMU_EVENT_ATTR(ref-sent,\t\t\t\t0x0a),\n\tXGENE_PMU_EVENT_ATTR(rd-rda-sent,\t\t\t0x0b),\n\tXGENE_PMU_EVENT_ATTR(wr-wra-sent,\t\t\t0x0c),\n\tXGENE_PMU_EVENT_ATTR(raw-hazard,\t\t\t0x0d),\n\tXGENE_PMU_EVENT_ATTR(war-hazard,\t\t\t0x0e),\n\tXGENE_PMU_EVENT_ATTR(waw-hazard,\t\t\t0x0f),\n\tXGENE_PMU_EVENT_ATTR(rar-hazard,\t\t\t0x10),\n\tXGENE_PMU_EVENT_ATTR(raw-war-waw-hazard,\t\t0x11),\n\tXGENE_PMU_EVENT_ATTR(hprd-lprd-wr-req-vld,\t\t0x12),\n\tXGENE_PMU_EVENT_ATTR(lprd-req-vld,\t\t\t0x13),\n\tXGENE_PMU_EVENT_ATTR(hprd-req-vld,\t\t\t0x14),\n\tXGENE_PMU_EVENT_ATTR(hprd-lprd-req-vld,\t\t\t0x15),\n\tXGENE_PMU_EVENT_ATTR(wr-req-vld,\t\t\t0x16),\n\tXGENE_PMU_EVENT_ATTR(partial-wr-req-vld,\t\t0x17),\n\tXGENE_PMU_EVENT_ATTR(rd-retry,\t\t\t\t0x18),\n\tXGENE_PMU_EVENT_ATTR(wr-retry,\t\t\t\t0x19),\n\tXGENE_PMU_EVENT_ATTR(retry-gnt,\t\t\t\t0x1a),\n\tXGENE_PMU_EVENT_ATTR(rank-change,\t\t\t0x1b),\n\tXGENE_PMU_EVENT_ATTR(dir-change,\t\t\t0x1c),\n\tXGENE_PMU_EVENT_ATTR(rank-dir-change,\t\t\t0x1d),\n\tXGENE_PMU_EVENT_ATTR(rank-active,\t\t\t0x1e),\n\tXGENE_PMU_EVENT_ATTR(rank-idle,\t\t\t\t0x1f),\n\tXGENE_PMU_EVENT_ATTR(rank-pd,\t\t\t\t0x20),\n\tXGENE_PMU_EVENT_ATTR(rank-sref,\t\t\t\t0x21),\n\tXGENE_PMU_EVENT_ATTR(queue-fill-gt-thresh,\t\t0x22),\n\tXGENE_PMU_EVENT_ATTR(queue-rds-gt-thresh,\t\t0x23),\n\tXGENE_PMU_EVENT_ATTR(queue-wrs-gt-thresh,\t\t0x24),\n\tXGENE_PMU_EVENT_ATTR(phy-updt-complt,\t\t\t0x25),\n\tXGENE_PMU_EVENT_ATTR(tz-fail,\t\t\t\t0x26),\n\tXGENE_PMU_EVENT_ATTR(dram-errc,\t\t\t\t0x27),\n\tXGENE_PMU_EVENT_ATTR(dram-errd,\t\t\t\t0x28),\n\tXGENE_PMU_EVENT_ATTR(rd-enq,\t\t\t\t0x29),\n\tXGENE_PMU_EVENT_ATTR(wr-enq,\t\t\t\t0x2a),\n\tXGENE_PMU_EVENT_ATTR(tmac-limit-reached,\t\t0x2b),\n\tXGENE_PMU_EVENT_ATTR(tmaw-tracker-full,\t\t\t0x2c),\n\tNULL,\n};\n\nstatic const struct attribute_group l3c_pmu_v3_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = l3c_pmu_v3_events_attrs,\n};\n\nstatic const struct attribute_group iob_fast_pmu_v3_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = iob_fast_pmu_v3_events_attrs,\n};\n\nstatic const struct attribute_group iob_slow_pmu_v3_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = iob_slow_pmu_v3_events_attrs,\n};\n\nstatic const struct attribute_group mcb_pmu_v3_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = mcb_pmu_v3_events_attrs,\n};\n\nstatic const struct attribute_group mc_pmu_v3_events_attr_group = {\n\t.name = \"events\",\n\t.attrs = mc_pmu_v3_events_attrs,\n};\n\n \nstatic ssize_t cpumask_show(struct device *dev,\n\t\t\t    struct device_attribute *attr, char *buf)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(dev_get_drvdata(dev));\n\n\treturn cpumap_print_to_pagebuf(true, buf, &pmu_dev->parent->cpu);\n}\n\nstatic DEVICE_ATTR_RO(cpumask);\n\nstatic struct attribute *xgene_pmu_cpumask_attrs[] = {\n\t&dev_attr_cpumask.attr,\n\tNULL,\n};\n\nstatic const struct attribute_group pmu_cpumask_attr_group = {\n\t.attrs = xgene_pmu_cpumask_attrs,\n};\n\n \nstatic const struct attribute_group *l3c_pmu_attr_groups[] = {\n\t&l3c_pmu_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&l3c_pmu_events_attr_group,\n\tNULL\n};\n\nstatic const struct attribute_group *iob_pmu_attr_groups[] = {\n\t&iob_pmu_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&iob_pmu_events_attr_group,\n\tNULL\n};\n\nstatic const struct attribute_group *mcb_pmu_attr_groups[] = {\n\t&mcb_pmu_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&mcb_pmu_events_attr_group,\n\tNULL\n};\n\nstatic const struct attribute_group *mc_pmu_attr_groups[] = {\n\t&mc_pmu_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&mc_pmu_events_attr_group,\n\tNULL\n};\n\n \nstatic const struct attribute_group *l3c_pmu_v3_attr_groups[] = {\n\t&l3c_pmu_v3_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&l3c_pmu_v3_events_attr_group,\n\tNULL\n};\n\nstatic const struct attribute_group *iob_fast_pmu_v3_attr_groups[] = {\n\t&iob_pmu_v3_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&iob_fast_pmu_v3_events_attr_group,\n\tNULL\n};\n\nstatic const struct attribute_group *iob_slow_pmu_v3_attr_groups[] = {\n\t&iob_slow_pmu_v3_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&iob_slow_pmu_v3_events_attr_group,\n\tNULL\n};\n\nstatic const struct attribute_group *mcb_pmu_v3_attr_groups[] = {\n\t&mcb_pmu_v3_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&mcb_pmu_v3_events_attr_group,\n\tNULL\n};\n\nstatic const struct attribute_group *mc_pmu_v3_attr_groups[] = {\n\t&mc_pmu_v3_format_attr_group,\n\t&pmu_cpumask_attr_group,\n\t&mc_pmu_v3_events_attr_group,\n\tNULL\n};\n\nstatic int get_next_avail_cntr(struct xgene_pmu_dev *pmu_dev)\n{\n\tint cntr;\n\n\tcntr = find_first_zero_bit(pmu_dev->cntr_assign_mask,\n\t\t\t\tpmu_dev->max_counters);\n\tif (cntr == pmu_dev->max_counters)\n\t\treturn -ENOSPC;\n\tset_bit(cntr, pmu_dev->cntr_assign_mask);\n\n\treturn cntr;\n}\n\nstatic void clear_avail_cntr(struct xgene_pmu_dev *pmu_dev, int cntr)\n{\n\tclear_bit(cntr, pmu_dev->cntr_assign_mask);\n}\n\nstatic inline void xgene_pmu_mask_int(struct xgene_pmu *xgene_pmu)\n{\n\twritel(PCPPMU_INTENMASK, xgene_pmu->pcppmu_csr + PCPPMU_INTMASK_REG);\n}\n\nstatic inline void xgene_pmu_v3_mask_int(struct xgene_pmu *xgene_pmu)\n{\n\twritel(PCPPMU_V3_INTENMASK, xgene_pmu->pcppmu_csr + PCPPMU_INTMASK_REG);\n}\n\nstatic inline void xgene_pmu_unmask_int(struct xgene_pmu *xgene_pmu)\n{\n\twritel(PCPPMU_INTCLRMASK, xgene_pmu->pcppmu_csr + PCPPMU_INTMASK_REG);\n}\n\nstatic inline void xgene_pmu_v3_unmask_int(struct xgene_pmu *xgene_pmu)\n{\n\twritel(PCPPMU_V3_INTCLRMASK,\n\t       xgene_pmu->pcppmu_csr + PCPPMU_INTMASK_REG);\n}\n\nstatic inline u64 xgene_pmu_read_counter32(struct xgene_pmu_dev *pmu_dev,\n\t\t\t\t\t   int idx)\n{\n\treturn readl(pmu_dev->inf->csr + PMU_PMEVCNTR0 + (4 * idx));\n}\n\nstatic inline u64 xgene_pmu_read_counter64(struct xgene_pmu_dev *pmu_dev,\n\t\t\t\t\t   int idx)\n{\n\tu32 lo, hi;\n\n\t \n\tdo {\n\t\thi = xgene_pmu_read_counter32(pmu_dev, 2 * idx + 1);\n\t\tlo = xgene_pmu_read_counter32(pmu_dev, 2 * idx);\n\t} while (hi != xgene_pmu_read_counter32(pmu_dev, 2 * idx + 1));\n\n\treturn (((u64)hi << 32) | lo);\n}\n\nstatic inline void\nxgene_pmu_write_counter32(struct xgene_pmu_dev *pmu_dev, int idx, u64 val)\n{\n\twritel(val, pmu_dev->inf->csr + PMU_PMEVCNTR0 + (4 * idx));\n}\n\nstatic inline void\nxgene_pmu_write_counter64(struct xgene_pmu_dev *pmu_dev, int idx, u64 val)\n{\n\tu32 cnt_lo, cnt_hi;\n\n\tcnt_hi = upper_32_bits(val);\n\tcnt_lo = lower_32_bits(val);\n\n\t \n\txgene_pmu_write_counter32(pmu_dev, 2 * idx, cnt_lo);\n\txgene_pmu_write_counter32(pmu_dev, 2 * idx + 1, cnt_hi);\n}\n\nstatic inline void\nxgene_pmu_write_evttype(struct xgene_pmu_dev *pmu_dev, int idx, u32 val)\n{\n\twritel(val, pmu_dev->inf->csr + PMU_PMEVTYPER0 + (4 * idx));\n}\n\nstatic inline void\nxgene_pmu_write_agentmsk(struct xgene_pmu_dev *pmu_dev, u32 val)\n{\n\twritel(val, pmu_dev->inf->csr + PMU_PMAMR0);\n}\n\nstatic inline void\nxgene_pmu_v3_write_agentmsk(struct xgene_pmu_dev *pmu_dev, u32 val) { }\n\nstatic inline void\nxgene_pmu_write_agent1msk(struct xgene_pmu_dev *pmu_dev, u32 val)\n{\n\twritel(val, pmu_dev->inf->csr + PMU_PMAMR1);\n}\n\nstatic inline void\nxgene_pmu_v3_write_agent1msk(struct xgene_pmu_dev *pmu_dev, u32 val) { }\n\nstatic inline void\nxgene_pmu_enable_counter(struct xgene_pmu_dev *pmu_dev, int idx)\n{\n\tu32 val;\n\n\tval = readl(pmu_dev->inf->csr + PMU_PMCNTENSET);\n\tval |= 1 << idx;\n\twritel(val, pmu_dev->inf->csr + PMU_PMCNTENSET);\n}\n\nstatic inline void\nxgene_pmu_disable_counter(struct xgene_pmu_dev *pmu_dev, int idx)\n{\n\tu32 val;\n\n\tval = readl(pmu_dev->inf->csr + PMU_PMCNTENCLR);\n\tval |= 1 << idx;\n\twritel(val, pmu_dev->inf->csr + PMU_PMCNTENCLR);\n}\n\nstatic inline void\nxgene_pmu_enable_counter_int(struct xgene_pmu_dev *pmu_dev, int idx)\n{\n\tu32 val;\n\n\tval = readl(pmu_dev->inf->csr + PMU_PMINTENSET);\n\tval |= 1 << idx;\n\twritel(val, pmu_dev->inf->csr + PMU_PMINTENSET);\n}\n\nstatic inline void\nxgene_pmu_disable_counter_int(struct xgene_pmu_dev *pmu_dev, int idx)\n{\n\tu32 val;\n\n\tval = readl(pmu_dev->inf->csr + PMU_PMINTENCLR);\n\tval |= 1 << idx;\n\twritel(val, pmu_dev->inf->csr + PMU_PMINTENCLR);\n}\n\nstatic inline void xgene_pmu_reset_counters(struct xgene_pmu_dev *pmu_dev)\n{\n\tu32 val;\n\n\tval = readl(pmu_dev->inf->csr + PMU_PMCR);\n\tval |= PMU_PMCR_P;\n\twritel(val, pmu_dev->inf->csr + PMU_PMCR);\n}\n\nstatic inline void xgene_pmu_start_counters(struct xgene_pmu_dev *pmu_dev)\n{\n\tu32 val;\n\n\tval = readl(pmu_dev->inf->csr + PMU_PMCR);\n\tval |= PMU_PMCR_E;\n\twritel(val, pmu_dev->inf->csr + PMU_PMCR);\n}\n\nstatic inline void xgene_pmu_stop_counters(struct xgene_pmu_dev *pmu_dev)\n{\n\tu32 val;\n\n\tval = readl(pmu_dev->inf->csr + PMU_PMCR);\n\tval &= ~PMU_PMCR_E;\n\twritel(val, pmu_dev->inf->csr + PMU_PMCR);\n}\n\nstatic void xgene_perf_pmu_enable(struct pmu *pmu)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(pmu);\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\tbool enabled = !bitmap_empty(pmu_dev->cntr_assign_mask,\n\t\t\tpmu_dev->max_counters);\n\n\tif (!enabled)\n\t\treturn;\n\n\txgene_pmu->ops->start_counters(pmu_dev);\n}\n\nstatic void xgene_perf_pmu_disable(struct pmu *pmu)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(pmu);\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\n\txgene_pmu->ops->stop_counters(pmu_dev);\n}\n\nstatic int xgene_perf_event_init(struct perf_event *event)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct hw_perf_event *hw = &event->hw;\n\tstruct perf_event *sibling;\n\n\t \n\tif (event->attr.type != event->pmu->type)\n\t\treturn -ENOENT;\n\n\t \n\tif (is_sampling_event(event) || event->attach_state & PERF_ATTACH_TASK)\n\t\treturn -EINVAL;\n\n\tif (event->cpu < 0)\n\t\treturn -EINVAL;\n\t \n\tevent->cpu = cpumask_first(&pmu_dev->parent->cpu);\n\n\thw->config = event->attr.config;\n\t \n\thw->config_base = event->attr.config1;\n\n\t \n\tif (event->group_leader->pmu != event->pmu &&\n\t\t\t!is_software_event(event->group_leader))\n\t\treturn -EINVAL;\n\n\tfor_each_sibling_event(sibling, event->group_leader) {\n\t\tif (sibling->pmu != event->pmu &&\n\t\t\t\t!is_software_event(sibling))\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic void xgene_perf_enable_event(struct perf_event *event)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\n\txgene_pmu->ops->write_evttype(pmu_dev, GET_CNTR(event),\n\t\t\t\t      GET_EVENTID(event));\n\txgene_pmu->ops->write_agentmsk(pmu_dev, ~((u32)GET_AGENTID(event)));\n\tif (pmu_dev->inf->type == PMU_TYPE_IOB)\n\t\txgene_pmu->ops->write_agent1msk(pmu_dev,\n\t\t\t\t\t\t~((u32)GET_AGENT1ID(event)));\n\n\txgene_pmu->ops->enable_counter(pmu_dev, GET_CNTR(event));\n\txgene_pmu->ops->enable_counter_int(pmu_dev, GET_CNTR(event));\n}\n\nstatic void xgene_perf_disable_event(struct perf_event *event)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\n\txgene_pmu->ops->disable_counter(pmu_dev, GET_CNTR(event));\n\txgene_pmu->ops->disable_counter_int(pmu_dev, GET_CNTR(event));\n}\n\nstatic void xgene_perf_event_set_period(struct perf_event *event)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\tstruct hw_perf_event *hw = &event->hw;\n\t \n\tu64 val = 1ULL << 31;\n\n\tlocal64_set(&hw->prev_count, val);\n\txgene_pmu->ops->write_counter(pmu_dev, hw->idx, val);\n}\n\nstatic void xgene_perf_event_update(struct perf_event *event)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\tstruct hw_perf_event *hw = &event->hw;\n\tu64 delta, prev_raw_count, new_raw_count;\n\nagain:\n\tprev_raw_count = local64_read(&hw->prev_count);\n\tnew_raw_count = xgene_pmu->ops->read_counter(pmu_dev, GET_CNTR(event));\n\n\tif (local64_cmpxchg(&hw->prev_count, prev_raw_count,\n\t\t\t    new_raw_count) != prev_raw_count)\n\t\tgoto again;\n\n\tdelta = (new_raw_count - prev_raw_count) & pmu_dev->max_period;\n\n\tlocal64_add(delta, &event->count);\n}\n\nstatic void xgene_perf_read(struct perf_event *event)\n{\n\txgene_perf_event_update(event);\n}\n\nstatic void xgene_perf_start(struct perf_event *event, int flags)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\tstruct hw_perf_event *hw = &event->hw;\n\n\tif (WARN_ON_ONCE(!(hw->state & PERF_HES_STOPPED)))\n\t\treturn;\n\n\tWARN_ON_ONCE(!(hw->state & PERF_HES_UPTODATE));\n\thw->state = 0;\n\n\txgene_perf_event_set_period(event);\n\n\tif (flags & PERF_EF_RELOAD) {\n\t\tu64 prev_raw_count =  local64_read(&hw->prev_count);\n\n\t\txgene_pmu->ops->write_counter(pmu_dev, GET_CNTR(event),\n\t\t\t\t\t      prev_raw_count);\n\t}\n\n\txgene_perf_enable_event(event);\n\tperf_event_update_userpage(event);\n}\n\nstatic void xgene_perf_stop(struct perf_event *event, int flags)\n{\n\tstruct hw_perf_event *hw = &event->hw;\n\n\tif (hw->state & PERF_HES_UPTODATE)\n\t\treturn;\n\n\txgene_perf_disable_event(event);\n\tWARN_ON_ONCE(hw->state & PERF_HES_STOPPED);\n\thw->state |= PERF_HES_STOPPED;\n\n\tif (hw->state & PERF_HES_UPTODATE)\n\t\treturn;\n\n\txgene_perf_read(event);\n\thw->state |= PERF_HES_UPTODATE;\n}\n\nstatic int xgene_perf_add(struct perf_event *event, int flags)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct hw_perf_event *hw = &event->hw;\n\n\thw->state = PERF_HES_UPTODATE | PERF_HES_STOPPED;\n\n\t \n\thw->idx = get_next_avail_cntr(pmu_dev);\n\tif (hw->idx < 0)\n\t\treturn -EAGAIN;\n\n\t \n\tpmu_dev->pmu_counter_event[hw->idx] = event;\n\n\tif (flags & PERF_EF_START)\n\t\txgene_perf_start(event, PERF_EF_RELOAD);\n\n\treturn 0;\n}\n\nstatic void xgene_perf_del(struct perf_event *event, int flags)\n{\n\tstruct xgene_pmu_dev *pmu_dev = to_pmu_dev(event->pmu);\n\tstruct hw_perf_event *hw = &event->hw;\n\n\txgene_perf_stop(event, PERF_EF_UPDATE);\n\n\t \n\tclear_avail_cntr(pmu_dev, GET_CNTR(event));\n\n\tperf_event_update_userpage(event);\n\tpmu_dev->pmu_counter_event[hw->idx] = NULL;\n}\n\nstatic int xgene_init_perf(struct xgene_pmu_dev *pmu_dev, char *name)\n{\n\tstruct xgene_pmu *xgene_pmu;\n\n\tif (pmu_dev->parent->version == PCP_PMU_V3)\n\t\tpmu_dev->max_period = PMU_V3_CNT_MAX_PERIOD;\n\telse\n\t\tpmu_dev->max_period = PMU_CNT_MAX_PERIOD;\n\t \n\txgene_pmu = pmu_dev->parent;\n\tif (xgene_pmu->version == PCP_PMU_V1)\n\t\tpmu_dev->max_counters = 1;\n\telse\n\t\tpmu_dev->max_counters = PMU_MAX_COUNTERS;\n\n\t \n\tpmu_dev->pmu = (struct pmu) {\n\t\t.attr_groups\t= pmu_dev->attr_groups,\n\t\t.task_ctx_nr\t= perf_invalid_context,\n\t\t.pmu_enable\t= xgene_perf_pmu_enable,\n\t\t.pmu_disable\t= xgene_perf_pmu_disable,\n\t\t.event_init\t= xgene_perf_event_init,\n\t\t.add\t\t= xgene_perf_add,\n\t\t.del\t\t= xgene_perf_del,\n\t\t.start\t\t= xgene_perf_start,\n\t\t.stop\t\t= xgene_perf_stop,\n\t\t.read\t\t= xgene_perf_read,\n\t\t.capabilities\t= PERF_PMU_CAP_NO_EXCLUDE,\n\t};\n\n\t \n\txgene_pmu->ops->stop_counters(pmu_dev);\n\txgene_pmu->ops->reset_counters(pmu_dev);\n\n\treturn perf_pmu_register(&pmu_dev->pmu, name, -1);\n}\n\nstatic int\nxgene_pmu_dev_add(struct xgene_pmu *xgene_pmu, struct xgene_pmu_dev_ctx *ctx)\n{\n\tstruct device *dev = xgene_pmu->dev;\n\tstruct xgene_pmu_dev *pmu;\n\n\tpmu = devm_kzalloc(dev, sizeof(*pmu), GFP_KERNEL);\n\tif (!pmu)\n\t\treturn -ENOMEM;\n\tpmu->parent = xgene_pmu;\n\tpmu->inf = &ctx->inf;\n\tctx->pmu_dev = pmu;\n\n\tswitch (pmu->inf->type) {\n\tcase PMU_TYPE_L3C:\n\t\tif (!(xgene_pmu->l3c_active_mask & pmu->inf->enable_mask))\n\t\t\treturn -ENODEV;\n\t\tif (xgene_pmu->version == PCP_PMU_V3)\n\t\t\tpmu->attr_groups = l3c_pmu_v3_attr_groups;\n\t\telse\n\t\t\tpmu->attr_groups = l3c_pmu_attr_groups;\n\t\tbreak;\n\tcase PMU_TYPE_IOB:\n\t\tif (xgene_pmu->version == PCP_PMU_V3)\n\t\t\tpmu->attr_groups = iob_fast_pmu_v3_attr_groups;\n\t\telse\n\t\t\tpmu->attr_groups = iob_pmu_attr_groups;\n\t\tbreak;\n\tcase PMU_TYPE_IOB_SLOW:\n\t\tif (xgene_pmu->version == PCP_PMU_V3)\n\t\t\tpmu->attr_groups = iob_slow_pmu_v3_attr_groups;\n\t\tbreak;\n\tcase PMU_TYPE_MCB:\n\t\tif (!(xgene_pmu->mcb_active_mask & pmu->inf->enable_mask))\n\t\t\treturn -ENODEV;\n\t\tif (xgene_pmu->version == PCP_PMU_V3)\n\t\t\tpmu->attr_groups = mcb_pmu_v3_attr_groups;\n\t\telse\n\t\t\tpmu->attr_groups = mcb_pmu_attr_groups;\n\t\tbreak;\n\tcase PMU_TYPE_MC:\n\t\tif (!(xgene_pmu->mc_active_mask & pmu->inf->enable_mask))\n\t\t\treturn -ENODEV;\n\t\tif (xgene_pmu->version == PCP_PMU_V3)\n\t\t\tpmu->attr_groups = mc_pmu_v3_attr_groups;\n\t\telse\n\t\t\tpmu->attr_groups = mc_pmu_attr_groups;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (xgene_init_perf(pmu, ctx->name)) {\n\t\tdev_err(dev, \"%s PMU: Failed to init perf driver\\n\", ctx->name);\n\t\treturn -ENODEV;\n\t}\n\n\tdev_info(dev, \"%s PMU registered\\n\", ctx->name);\n\n\treturn 0;\n}\n\nstatic void _xgene_pmu_isr(int irq, struct xgene_pmu_dev *pmu_dev)\n{\n\tstruct xgene_pmu *xgene_pmu = pmu_dev->parent;\n\tvoid __iomem *csr = pmu_dev->inf->csr;\n\tu32 pmovsr;\n\tint idx;\n\n\txgene_pmu->ops->stop_counters(pmu_dev);\n\n\tif (xgene_pmu->version == PCP_PMU_V3)\n\t\tpmovsr = readl(csr + PMU_PMOVSSET) & PMU_OVERFLOW_MASK;\n\telse\n\t\tpmovsr = readl(csr + PMU_PMOVSR) & PMU_OVERFLOW_MASK;\n\n\tif (!pmovsr)\n\t\tgoto out;\n\n\t \n\tif (xgene_pmu->version == PCP_PMU_V1)\n\t\twritel(0x0, csr + PMU_PMOVSR);\n\telse if (xgene_pmu->version == PCP_PMU_V2)\n\t\twritel(pmovsr, csr + PMU_PMOVSR);\n\telse\n\t\twritel(pmovsr, csr + PMU_PMOVSCLR);\n\n\tfor (idx = 0; idx < PMU_MAX_COUNTERS; idx++) {\n\t\tstruct perf_event *event = pmu_dev->pmu_counter_event[idx];\n\t\tint overflowed = pmovsr & BIT(idx);\n\n\t\t \n\t\tif (!event || !overflowed)\n\t\t\tcontinue;\n\t\txgene_perf_event_update(event);\n\t\txgene_perf_event_set_period(event);\n\t}\n\nout:\n\txgene_pmu->ops->start_counters(pmu_dev);\n}\n\nstatic irqreturn_t xgene_pmu_isr(int irq, void *dev_id)\n{\n\tu32 intr_mcu, intr_mcb, intr_l3c, intr_iob;\n\tstruct xgene_pmu_dev_ctx *ctx;\n\tstruct xgene_pmu *xgene_pmu = dev_id;\n\tu32 val;\n\n\traw_spin_lock(&xgene_pmu->lock);\n\n\t \n\tval = readl(xgene_pmu->pcppmu_csr + PCPPMU_INTSTATUS_REG);\n\tif (xgene_pmu->version == PCP_PMU_V3) {\n\t\tintr_mcu = PCPPMU_V3_INT_MCU;\n\t\tintr_mcb = PCPPMU_V3_INT_MCB;\n\t\tintr_l3c = PCPPMU_V3_INT_L3C;\n\t\tintr_iob = PCPPMU_V3_INT_IOB;\n\t} else {\n\t\tintr_mcu = PCPPMU_INT_MCU;\n\t\tintr_mcb = PCPPMU_INT_MCB;\n\t\tintr_l3c = PCPPMU_INT_L3C;\n\t\tintr_iob = PCPPMU_INT_IOB;\n\t}\n\tif (val & intr_mcu) {\n\t\tlist_for_each_entry(ctx, &xgene_pmu->mcpmus, next) {\n\t\t\t_xgene_pmu_isr(irq, ctx->pmu_dev);\n\t\t}\n\t}\n\tif (val & intr_mcb) {\n\t\tlist_for_each_entry(ctx, &xgene_pmu->mcbpmus, next) {\n\t\t\t_xgene_pmu_isr(irq, ctx->pmu_dev);\n\t\t}\n\t}\n\tif (val & intr_l3c) {\n\t\tlist_for_each_entry(ctx, &xgene_pmu->l3cpmus, next) {\n\t\t\t_xgene_pmu_isr(irq, ctx->pmu_dev);\n\t\t}\n\t}\n\tif (val & intr_iob) {\n\t\tlist_for_each_entry(ctx, &xgene_pmu->iobpmus, next) {\n\t\t\t_xgene_pmu_isr(irq, ctx->pmu_dev);\n\t\t}\n\t}\n\n\traw_spin_unlock(&xgene_pmu->lock);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int acpi_pmu_probe_active_mcb_mcu_l3c(struct xgene_pmu *xgene_pmu,\n\t\t\t\t\t     struct platform_device *pdev)\n{\n\tvoid __iomem *csw_csr, *mcba_csr, *mcbb_csr;\n\tunsigned int reg;\n\n\tcsw_csr = devm_platform_ioremap_resource(pdev, 1);\n\tif (IS_ERR(csw_csr)) {\n\t\tdev_err(&pdev->dev, \"ioremap failed for CSW CSR resource\\n\");\n\t\treturn PTR_ERR(csw_csr);\n\t}\n\n\tmcba_csr = devm_platform_ioremap_resource(pdev, 2);\n\tif (IS_ERR(mcba_csr)) {\n\t\tdev_err(&pdev->dev, \"ioremap failed for MCBA CSR resource\\n\");\n\t\treturn PTR_ERR(mcba_csr);\n\t}\n\n\tmcbb_csr = devm_platform_ioremap_resource(pdev, 3);\n\tif (IS_ERR(mcbb_csr)) {\n\t\tdev_err(&pdev->dev, \"ioremap failed for MCBB CSR resource\\n\");\n\t\treturn PTR_ERR(mcbb_csr);\n\t}\n\n\txgene_pmu->l3c_active_mask = 0x1;\n\n\treg = readl(csw_csr + CSW_CSWCR);\n\tif (reg & CSW_CSWCR_DUALMCB_MASK) {\n\t\t \n\t\txgene_pmu->mcb_active_mask = 0x3;\n\t\t \n\t\treg = readl(mcbb_csr + CSW_CSWCR);\n\t\txgene_pmu->mc_active_mask =\n\t\t\t(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0xF : 0x5;\n\t} else {\n\t\t \n\t\txgene_pmu->mcb_active_mask = 0x1;\n\t\t \n\t\treg = readl(mcba_csr + CSW_CSWCR);\n\t\txgene_pmu->mc_active_mask =\n\t\t\t(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0x3 : 0x1;\n\t}\n\n\treturn 0;\n}\n\nstatic int acpi_pmu_v3_probe_active_mcb_mcu_l3c(struct xgene_pmu *xgene_pmu,\n\t\t\t\t\t\tstruct platform_device *pdev)\n{\n\tvoid __iomem *csw_csr;\n\tunsigned int reg;\n\tu32 mcb0routing;\n\tu32 mcb1routing;\n\n\tcsw_csr = devm_platform_ioremap_resource(pdev, 1);\n\tif (IS_ERR(csw_csr)) {\n\t\tdev_err(&pdev->dev, \"ioremap failed for CSW CSR resource\\n\");\n\t\treturn PTR_ERR(csw_csr);\n\t}\n\n\treg = readl(csw_csr + CSW_CSWCR);\n\tmcb0routing = CSW_CSWCR_MCB0_ROUTING(reg);\n\tmcb1routing = CSW_CSWCR_MCB1_ROUTING(reg);\n\tif (reg & CSW_CSWCR_DUALMCB_MASK) {\n\t\t \n\t\txgene_pmu->mcb_active_mask = 0x3;\n\t\t \n\t\txgene_pmu->l3c_active_mask = 0xFF;\n\t\t \n\t\tif ((mcb0routing == 0x2) && (mcb1routing == 0x2))\n\t\t\txgene_pmu->mc_active_mask = 0xFF;\n\t\telse if ((mcb0routing == 0x1) && (mcb1routing == 0x1))\n\t\t\txgene_pmu->mc_active_mask =  0x33;\n\t\telse\n\t\t\txgene_pmu->mc_active_mask =  0x11;\n\t} else {\n\t\t \n\t\txgene_pmu->mcb_active_mask = 0x1;\n\t\t \n\t\txgene_pmu->l3c_active_mask = 0x0F;\n\t\t \n\t\tif (mcb0routing == 0x2)\n\t\t\txgene_pmu->mc_active_mask = 0x0F;\n\t\telse if (mcb0routing == 0x1)\n\t\t\txgene_pmu->mc_active_mask =  0x03;\n\t\telse\n\t\t\txgene_pmu->mc_active_mask =  0x01;\n\t}\n\n\treturn 0;\n}\n\nstatic int fdt_pmu_probe_active_mcb_mcu_l3c(struct xgene_pmu *xgene_pmu,\n\t\t\t\t\t    struct platform_device *pdev)\n{\n\tstruct regmap *csw_map, *mcba_map, *mcbb_map;\n\tstruct device_node *np = pdev->dev.of_node;\n\tunsigned int reg;\n\n\tcsw_map = syscon_regmap_lookup_by_phandle(np, \"regmap-csw\");\n\tif (IS_ERR(csw_map)) {\n\t\tdev_err(&pdev->dev, \"unable to get syscon regmap csw\\n\");\n\t\treturn PTR_ERR(csw_map);\n\t}\n\n\tmcba_map = syscon_regmap_lookup_by_phandle(np, \"regmap-mcba\");\n\tif (IS_ERR(mcba_map)) {\n\t\tdev_err(&pdev->dev, \"unable to get syscon regmap mcba\\n\");\n\t\treturn PTR_ERR(mcba_map);\n\t}\n\n\tmcbb_map = syscon_regmap_lookup_by_phandle(np, \"regmap-mcbb\");\n\tif (IS_ERR(mcbb_map)) {\n\t\tdev_err(&pdev->dev, \"unable to get syscon regmap mcbb\\n\");\n\t\treturn PTR_ERR(mcbb_map);\n\t}\n\n\txgene_pmu->l3c_active_mask = 0x1;\n\tif (regmap_read(csw_map, CSW_CSWCR, &reg))\n\t\treturn -EINVAL;\n\n\tif (reg & CSW_CSWCR_DUALMCB_MASK) {\n\t\t \n\t\txgene_pmu->mcb_active_mask = 0x3;\n\t\t \n\t\tif (regmap_read(mcbb_map, MCBADDRMR, &reg))\n\t\t\treturn 0;\n\t\txgene_pmu->mc_active_mask =\n\t\t\t(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0xF : 0x5;\n\t} else {\n\t\t \n\t\txgene_pmu->mcb_active_mask = 0x1;\n\t\t \n\t\tif (regmap_read(mcba_map, MCBADDRMR, &reg))\n\t\t\treturn 0;\n\t\txgene_pmu->mc_active_mask =\n\t\t\t(reg & MCBADDRMR_DUALMCU_MODE_MASK) ? 0x3 : 0x1;\n\t}\n\n\treturn 0;\n}\n\nstatic int xgene_pmu_probe_active_mcb_mcu_l3c(struct xgene_pmu *xgene_pmu,\n\t\t\t\t\t      struct platform_device *pdev)\n{\n\tif (has_acpi_companion(&pdev->dev)) {\n\t\tif (xgene_pmu->version == PCP_PMU_V3)\n\t\t\treturn acpi_pmu_v3_probe_active_mcb_mcu_l3c(xgene_pmu,\n\t\t\t\t\t\t\t\t    pdev);\n\t\telse\n\t\t\treturn acpi_pmu_probe_active_mcb_mcu_l3c(xgene_pmu,\n\t\t\t\t\t\t\t\t pdev);\n\t}\n\treturn fdt_pmu_probe_active_mcb_mcu_l3c(xgene_pmu, pdev);\n}\n\nstatic char *xgene_pmu_dev_name(struct device *dev, u32 type, int id)\n{\n\tswitch (type) {\n\tcase PMU_TYPE_L3C:\n\t\treturn devm_kasprintf(dev, GFP_KERNEL, \"l3c%d\", id);\n\tcase PMU_TYPE_IOB:\n\t\treturn devm_kasprintf(dev, GFP_KERNEL, \"iob%d\", id);\n\tcase PMU_TYPE_IOB_SLOW:\n\t\treturn devm_kasprintf(dev, GFP_KERNEL, \"iob_slow%d\", id);\n\tcase PMU_TYPE_MCB:\n\t\treturn devm_kasprintf(dev, GFP_KERNEL, \"mcb%d\", id);\n\tcase PMU_TYPE_MC:\n\t\treturn devm_kasprintf(dev, GFP_KERNEL, \"mc%d\", id);\n\tdefault:\n\t\treturn devm_kasprintf(dev, GFP_KERNEL, \"unknown\");\n\t}\n}\n\n#if defined(CONFIG_ACPI)\nstatic struct\nxgene_pmu_dev_ctx *acpi_get_pmu_hw_inf(struct xgene_pmu *xgene_pmu,\n\t\t\t\t       struct acpi_device *adev, u32 type)\n{\n\tstruct device *dev = xgene_pmu->dev;\n\tstruct list_head resource_list;\n\tstruct xgene_pmu_dev_ctx *ctx;\n\tconst union acpi_object *obj;\n\tstruct hw_pmu_info *inf;\n\tvoid __iomem *dev_csr;\n\tstruct resource res;\n\tstruct resource_entry *rentry;\n\tint enable_bit;\n\tint rc;\n\n\tctx = devm_kzalloc(dev, sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&resource_list);\n\trc = acpi_dev_get_resources(adev, &resource_list, NULL, NULL);\n\tif (rc <= 0) {\n\t\tdev_err(dev, \"PMU type %d: No resources found\\n\", type);\n\t\treturn NULL;\n\t}\n\n\tlist_for_each_entry(rentry, &resource_list, node) {\n\t\tif (resource_type(rentry->res) == IORESOURCE_MEM) {\n\t\t\tres = *rentry->res;\n\t\t\trentry = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\tacpi_dev_free_resource_list(&resource_list);\n\n\tif (rentry) {\n\t\tdev_err(dev, \"PMU type %d: No memory resource found\\n\", type);\n\t\treturn NULL;\n\t}\n\n\tdev_csr = devm_ioremap_resource(dev, &res);\n\tif (IS_ERR(dev_csr)) {\n\t\tdev_err(dev, \"PMU type %d: Fail to map resource\\n\", type);\n\t\treturn NULL;\n\t}\n\n\t \n\trc = acpi_dev_get_property(adev, \"enable-bit-index\",\n\t\t\t\t   ACPI_TYPE_INTEGER, &obj);\n\tif (rc < 0)\n\t\tenable_bit = 0;\n\telse\n\t\tenable_bit = (int) obj->integer.value;\n\n\tctx->name = xgene_pmu_dev_name(dev, type, enable_bit);\n\tif (!ctx->name) {\n\t\tdev_err(dev, \"PMU type %d: Fail to get device name\\n\", type);\n\t\treturn NULL;\n\t}\n\tinf = &ctx->inf;\n\tinf->type = type;\n\tinf->csr = dev_csr;\n\tinf->enable_mask = 1 << enable_bit;\n\n\treturn ctx;\n}\n\nstatic const struct acpi_device_id xgene_pmu_acpi_type_match[] = {\n\t{\"APMC0D5D\", PMU_TYPE_L3C},\n\t{\"APMC0D5E\", PMU_TYPE_IOB},\n\t{\"APMC0D5F\", PMU_TYPE_MCB},\n\t{\"APMC0D60\", PMU_TYPE_MC},\n\t{\"APMC0D84\", PMU_TYPE_L3C},\n\t{\"APMC0D85\", PMU_TYPE_IOB},\n\t{\"APMC0D86\", PMU_TYPE_IOB_SLOW},\n\t{\"APMC0D87\", PMU_TYPE_MCB},\n\t{\"APMC0D88\", PMU_TYPE_MC},\n\t{},\n};\n\nstatic const struct acpi_device_id *xgene_pmu_acpi_match_type(\n\t\t\t\t\tconst struct acpi_device_id *ids,\n\t\t\t\t\tstruct acpi_device *adev)\n{\n\tconst struct acpi_device_id *match_id = NULL;\n\tconst struct acpi_device_id *id;\n\n\tfor (id = ids; id->id[0] || id->cls; id++) {\n\t\tif (!acpi_match_device_ids(adev, id))\n\t\t\tmatch_id = id;\n\t\telse if (match_id)\n\t\t\tbreak;\n\t}\n\n\treturn match_id;\n}\n\nstatic acpi_status acpi_pmu_dev_add(acpi_handle handle, u32 level,\n\t\t\t\t    void *data, void **return_value)\n{\n\tstruct acpi_device *adev = acpi_fetch_acpi_dev(handle);\n\tconst struct acpi_device_id *acpi_id;\n\tstruct xgene_pmu *xgene_pmu = data;\n\tstruct xgene_pmu_dev_ctx *ctx;\n\n\tif (!adev || acpi_bus_get_status(adev) || !adev->status.present)\n\t\treturn AE_OK;\n\n\tacpi_id = xgene_pmu_acpi_match_type(xgene_pmu_acpi_type_match, adev);\n\tif (!acpi_id)\n\t\treturn AE_OK;\n\n\tctx = acpi_get_pmu_hw_inf(xgene_pmu, adev, (u32)acpi_id->driver_data);\n\tif (!ctx)\n\t\treturn AE_OK;\n\n\tif (xgene_pmu_dev_add(xgene_pmu, ctx)) {\n\t\t \n\t\tdevm_kfree(xgene_pmu->dev, ctx);\n\t\treturn AE_OK;\n\t}\n\n\tswitch (ctx->inf.type) {\n\tcase PMU_TYPE_L3C:\n\t\tlist_add(&ctx->next, &xgene_pmu->l3cpmus);\n\t\tbreak;\n\tcase PMU_TYPE_IOB:\n\t\tlist_add(&ctx->next, &xgene_pmu->iobpmus);\n\t\tbreak;\n\tcase PMU_TYPE_IOB_SLOW:\n\t\tlist_add(&ctx->next, &xgene_pmu->iobpmus);\n\t\tbreak;\n\tcase PMU_TYPE_MCB:\n\t\tlist_add(&ctx->next, &xgene_pmu->mcbpmus);\n\t\tbreak;\n\tcase PMU_TYPE_MC:\n\t\tlist_add(&ctx->next, &xgene_pmu->mcpmus);\n\t\tbreak;\n\t}\n\treturn AE_OK;\n}\n\nstatic int acpi_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\n\t\t\t\t  struct platform_device *pdev)\n{\n\tstruct device *dev = xgene_pmu->dev;\n\tacpi_handle handle;\n\tacpi_status status;\n\n\thandle = ACPI_HANDLE(dev);\n\tif (!handle)\n\t\treturn -EINVAL;\n\n\tstatus = acpi_walk_namespace(ACPI_TYPE_DEVICE, handle, 1,\n\t\t\t\t     acpi_pmu_dev_add, NULL, xgene_pmu, NULL);\n\tif (ACPI_FAILURE(status)) {\n\t\tdev_err(dev, \"failed to probe PMU devices\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n#else\nstatic int acpi_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\n\t\t\t\t  struct platform_device *pdev)\n{\n\treturn 0;\n}\n#endif\n\nstatic struct\nxgene_pmu_dev_ctx *fdt_get_pmu_hw_inf(struct xgene_pmu *xgene_pmu,\n\t\t\t\t      struct device_node *np, u32 type)\n{\n\tstruct device *dev = xgene_pmu->dev;\n\tstruct xgene_pmu_dev_ctx *ctx;\n\tstruct hw_pmu_info *inf;\n\tvoid __iomem *dev_csr;\n\tstruct resource res;\n\tint enable_bit;\n\n\tctx = devm_kzalloc(dev, sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn NULL;\n\n\tif (of_address_to_resource(np, 0, &res) < 0) {\n\t\tdev_err(dev, \"PMU type %d: No resource address found\\n\", type);\n\t\treturn NULL;\n\t}\n\n\tdev_csr = devm_ioremap_resource(dev, &res);\n\tif (IS_ERR(dev_csr)) {\n\t\tdev_err(dev, \"PMU type %d: Fail to map resource\\n\", type);\n\t\treturn NULL;\n\t}\n\n\t \n\tif (of_property_read_u32(np, \"enable-bit-index\", &enable_bit))\n\t\tenable_bit = 0;\n\n\tctx->name = xgene_pmu_dev_name(dev, type, enable_bit);\n\tif (!ctx->name) {\n\t\tdev_err(dev, \"PMU type %d: Fail to get device name\\n\", type);\n\t\treturn NULL;\n\t}\n\n\tinf = &ctx->inf;\n\tinf->type = type;\n\tinf->csr = dev_csr;\n\tinf->enable_mask = 1 << enable_bit;\n\n\treturn ctx;\n}\n\nstatic int fdt_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\n\t\t\t\t struct platform_device *pdev)\n{\n\tstruct xgene_pmu_dev_ctx *ctx;\n\tstruct device_node *np;\n\n\tfor_each_child_of_node(pdev->dev.of_node, np) {\n\t\tif (!of_device_is_available(np))\n\t\t\tcontinue;\n\n\t\tif (of_device_is_compatible(np, \"apm,xgene-pmu-l3c\"))\n\t\t\tctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_L3C);\n\t\telse if (of_device_is_compatible(np, \"apm,xgene-pmu-iob\"))\n\t\t\tctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_IOB);\n\t\telse if (of_device_is_compatible(np, \"apm,xgene-pmu-mcb\"))\n\t\t\tctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_MCB);\n\t\telse if (of_device_is_compatible(np, \"apm,xgene-pmu-mc\"))\n\t\t\tctx = fdt_get_pmu_hw_inf(xgene_pmu, np, PMU_TYPE_MC);\n\t\telse\n\t\t\tctx = NULL;\n\n\t\tif (!ctx)\n\t\t\tcontinue;\n\n\t\tif (xgene_pmu_dev_add(xgene_pmu, ctx)) {\n\t\t\t \n\t\t\tdevm_kfree(xgene_pmu->dev, ctx);\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (ctx->inf.type) {\n\t\tcase PMU_TYPE_L3C:\n\t\t\tlist_add(&ctx->next, &xgene_pmu->l3cpmus);\n\t\t\tbreak;\n\t\tcase PMU_TYPE_IOB:\n\t\t\tlist_add(&ctx->next, &xgene_pmu->iobpmus);\n\t\t\tbreak;\n\t\tcase PMU_TYPE_IOB_SLOW:\n\t\t\tlist_add(&ctx->next, &xgene_pmu->iobpmus);\n\t\t\tbreak;\n\t\tcase PMU_TYPE_MCB:\n\t\t\tlist_add(&ctx->next, &xgene_pmu->mcbpmus);\n\t\t\tbreak;\n\t\tcase PMU_TYPE_MC:\n\t\t\tlist_add(&ctx->next, &xgene_pmu->mcpmus);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int xgene_pmu_probe_pmu_dev(struct xgene_pmu *xgene_pmu,\n\t\t\t\t   struct platform_device *pdev)\n{\n\tif (has_acpi_companion(&pdev->dev))\n\t\treturn acpi_pmu_probe_pmu_dev(xgene_pmu, pdev);\n\treturn fdt_pmu_probe_pmu_dev(xgene_pmu, pdev);\n}\n\nstatic const struct xgene_pmu_data xgene_pmu_data = {\n\t.id   = PCP_PMU_V1,\n};\n\nstatic const struct xgene_pmu_data xgene_pmu_v2_data = {\n\t.id   = PCP_PMU_V2,\n};\n\nstatic const struct xgene_pmu_ops xgene_pmu_ops = {\n\t.mask_int = xgene_pmu_mask_int,\n\t.unmask_int = xgene_pmu_unmask_int,\n\t.read_counter = xgene_pmu_read_counter32,\n\t.write_counter = xgene_pmu_write_counter32,\n\t.write_evttype = xgene_pmu_write_evttype,\n\t.write_agentmsk = xgene_pmu_write_agentmsk,\n\t.write_agent1msk = xgene_pmu_write_agent1msk,\n\t.enable_counter = xgene_pmu_enable_counter,\n\t.disable_counter = xgene_pmu_disable_counter,\n\t.enable_counter_int = xgene_pmu_enable_counter_int,\n\t.disable_counter_int = xgene_pmu_disable_counter_int,\n\t.reset_counters = xgene_pmu_reset_counters,\n\t.start_counters = xgene_pmu_start_counters,\n\t.stop_counters = xgene_pmu_stop_counters,\n};\n\nstatic const struct xgene_pmu_ops xgene_pmu_v3_ops = {\n\t.mask_int = xgene_pmu_v3_mask_int,\n\t.unmask_int = xgene_pmu_v3_unmask_int,\n\t.read_counter = xgene_pmu_read_counter64,\n\t.write_counter = xgene_pmu_write_counter64,\n\t.write_evttype = xgene_pmu_write_evttype,\n\t.write_agentmsk = xgene_pmu_v3_write_agentmsk,\n\t.write_agent1msk = xgene_pmu_v3_write_agent1msk,\n\t.enable_counter = xgene_pmu_enable_counter,\n\t.disable_counter = xgene_pmu_disable_counter,\n\t.enable_counter_int = xgene_pmu_enable_counter_int,\n\t.disable_counter_int = xgene_pmu_disable_counter_int,\n\t.reset_counters = xgene_pmu_reset_counters,\n\t.start_counters = xgene_pmu_start_counters,\n\t.stop_counters = xgene_pmu_stop_counters,\n};\n\nstatic const struct of_device_id xgene_pmu_of_match[] = {\n\t{ .compatible\t= \"apm,xgene-pmu\",\t.data = &xgene_pmu_data },\n\t{ .compatible\t= \"apm,xgene-pmu-v2\",\t.data = &xgene_pmu_v2_data },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, xgene_pmu_of_match);\n#ifdef CONFIG_ACPI\nstatic const struct acpi_device_id xgene_pmu_acpi_match[] = {\n\t{\"APMC0D5B\", PCP_PMU_V1},\n\t{\"APMC0D5C\", PCP_PMU_V2},\n\t{\"APMC0D83\", PCP_PMU_V3},\n\t{},\n};\nMODULE_DEVICE_TABLE(acpi, xgene_pmu_acpi_match);\n#endif\n\nstatic int xgene_pmu_online_cpu(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct xgene_pmu *xgene_pmu = hlist_entry_safe(node, struct xgene_pmu,\n\t\t\t\t\t\t       node);\n\n\tif (cpumask_empty(&xgene_pmu->cpu))\n\t\tcpumask_set_cpu(cpu, &xgene_pmu->cpu);\n\n\t \n\tWARN_ON(irq_set_affinity(xgene_pmu->irq, &xgene_pmu->cpu));\n\n\treturn 0;\n}\n\nstatic int xgene_pmu_offline_cpu(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct xgene_pmu *xgene_pmu = hlist_entry_safe(node, struct xgene_pmu,\n\t\t\t\t\t\t       node);\n\tstruct xgene_pmu_dev_ctx *ctx;\n\tunsigned int target;\n\n\tif (!cpumask_test_and_clear_cpu(cpu, &xgene_pmu->cpu))\n\t\treturn 0;\n\ttarget = cpumask_any_but(cpu_online_mask, cpu);\n\tif (target >= nr_cpu_ids)\n\t\treturn 0;\n\n\tlist_for_each_entry(ctx, &xgene_pmu->mcpmus, next) {\n\t\tperf_pmu_migrate_context(&ctx->pmu_dev->pmu, cpu, target);\n\t}\n\tlist_for_each_entry(ctx, &xgene_pmu->mcbpmus, next) {\n\t\tperf_pmu_migrate_context(&ctx->pmu_dev->pmu, cpu, target);\n\t}\n\tlist_for_each_entry(ctx, &xgene_pmu->l3cpmus, next) {\n\t\tperf_pmu_migrate_context(&ctx->pmu_dev->pmu, cpu, target);\n\t}\n\tlist_for_each_entry(ctx, &xgene_pmu->iobpmus, next) {\n\t\tperf_pmu_migrate_context(&ctx->pmu_dev->pmu, cpu, target);\n\t}\n\n\tcpumask_set_cpu(target, &xgene_pmu->cpu);\n\t \n\tWARN_ON(irq_set_affinity(xgene_pmu->irq, &xgene_pmu->cpu));\n\n\treturn 0;\n}\n\nstatic int xgene_pmu_probe(struct platform_device *pdev)\n{\n\tconst struct xgene_pmu_data *dev_data;\n\tconst struct of_device_id *of_id;\n\tstruct xgene_pmu *xgene_pmu;\n\tint irq, rc;\n\tint version;\n\n\t \n\trc = cpuhp_setup_state_multi(CPUHP_AP_PERF_ARM_APM_XGENE_ONLINE,\n\t\t\t\t      \"CPUHP_AP_PERF_ARM_APM_XGENE_ONLINE\",\n\t\t\t\t      xgene_pmu_online_cpu,\n\t\t\t\t      xgene_pmu_offline_cpu);\n\tif (rc)\n\t\treturn rc;\n\n\txgene_pmu = devm_kzalloc(&pdev->dev, sizeof(*xgene_pmu), GFP_KERNEL);\n\tif (!xgene_pmu)\n\t\treturn -ENOMEM;\n\txgene_pmu->dev = &pdev->dev;\n\tplatform_set_drvdata(pdev, xgene_pmu);\n\n\tversion = -EINVAL;\n\tof_id = of_match_device(xgene_pmu_of_match, &pdev->dev);\n\tif (of_id) {\n\t\tdev_data = (const struct xgene_pmu_data *) of_id->data;\n\t\tversion = dev_data->id;\n\t}\n\n#ifdef CONFIG_ACPI\n\tif (ACPI_COMPANION(&pdev->dev)) {\n\t\tconst struct acpi_device_id *acpi_id;\n\n\t\tacpi_id = acpi_match_device(xgene_pmu_acpi_match, &pdev->dev);\n\t\tif (acpi_id)\n\t\t\tversion = (int) acpi_id->driver_data;\n\t}\n#endif\n\tif (version < 0)\n\t\treturn -ENODEV;\n\n\tif (version == PCP_PMU_V3)\n\t\txgene_pmu->ops = &xgene_pmu_v3_ops;\n\telse\n\t\txgene_pmu->ops = &xgene_pmu_ops;\n\n\tINIT_LIST_HEAD(&xgene_pmu->l3cpmus);\n\tINIT_LIST_HEAD(&xgene_pmu->iobpmus);\n\tINIT_LIST_HEAD(&xgene_pmu->mcbpmus);\n\tINIT_LIST_HEAD(&xgene_pmu->mcpmus);\n\n\txgene_pmu->version = version;\n\tdev_info(&pdev->dev, \"X-Gene PMU version %d\\n\", xgene_pmu->version);\n\n\txgene_pmu->pcppmu_csr = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(xgene_pmu->pcppmu_csr)) {\n\t\tdev_err(&pdev->dev, \"ioremap failed for PCP PMU resource\\n\");\n\t\treturn PTR_ERR(xgene_pmu->pcppmu_csr);\n\t}\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn -EINVAL;\n\n\trc = devm_request_irq(&pdev->dev, irq, xgene_pmu_isr,\n\t\t\t\tIRQF_NOBALANCING | IRQF_NO_THREAD,\n\t\t\t\tdev_name(&pdev->dev), xgene_pmu);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Could not request IRQ %d\\n\", irq);\n\t\treturn rc;\n\t}\n\n\txgene_pmu->irq = irq;\n\n\traw_spin_lock_init(&xgene_pmu->lock);\n\n\t \n\trc = xgene_pmu_probe_active_mcb_mcu_l3c(xgene_pmu, pdev);\n\tif (rc) {\n\t\tdev_warn(&pdev->dev, \"Unknown MCB/MCU active status\\n\");\n\t\txgene_pmu->mcb_active_mask = 0x1;\n\t\txgene_pmu->mc_active_mask = 0x1;\n\t}\n\n\t \n\trc = cpuhp_state_add_instance(CPUHP_AP_PERF_ARM_APM_XGENE_ONLINE,\n\t\t\t\t      &xgene_pmu->node);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"Error %d registering hotplug\", rc);\n\t\treturn rc;\n\t}\n\n\t \n\trc = xgene_pmu_probe_pmu_dev(xgene_pmu, pdev);\n\tif (rc) {\n\t\tdev_err(&pdev->dev, \"No PMU perf devices found!\\n\");\n\t\tgoto out_unregister;\n\t}\n\n\t \n\txgene_pmu->ops->unmask_int(xgene_pmu);\n\n\treturn 0;\n\nout_unregister:\n\tcpuhp_state_remove_instance(CPUHP_AP_PERF_ARM_APM_XGENE_ONLINE,\n\t\t\t\t    &xgene_pmu->node);\n\treturn rc;\n}\n\nstatic void\nxgene_pmu_dev_cleanup(struct xgene_pmu *xgene_pmu, struct list_head *pmus)\n{\n\tstruct xgene_pmu_dev_ctx *ctx;\n\n\tlist_for_each_entry(ctx, pmus, next) {\n\t\tperf_pmu_unregister(&ctx->pmu_dev->pmu);\n\t}\n}\n\nstatic int xgene_pmu_remove(struct platform_device *pdev)\n{\n\tstruct xgene_pmu *xgene_pmu = dev_get_drvdata(&pdev->dev);\n\n\txgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->l3cpmus);\n\txgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->iobpmus);\n\txgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->mcbpmus);\n\txgene_pmu_dev_cleanup(xgene_pmu, &xgene_pmu->mcpmus);\n\tcpuhp_state_remove_instance(CPUHP_AP_PERF_ARM_APM_XGENE_ONLINE,\n\t\t\t\t    &xgene_pmu->node);\n\n\treturn 0;\n}\n\nstatic struct platform_driver xgene_pmu_driver = {\n\t.probe = xgene_pmu_probe,\n\t.remove = xgene_pmu_remove,\n\t.driver = {\n\t\t.name\t\t= \"xgene-pmu\",\n\t\t.of_match_table = xgene_pmu_of_match,\n\t\t.acpi_match_table = ACPI_PTR(xgene_pmu_acpi_match),\n\t\t.suppress_bind_attrs = true,\n\t},\n};\n\nbuiltin_platform_driver(xgene_pmu_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}