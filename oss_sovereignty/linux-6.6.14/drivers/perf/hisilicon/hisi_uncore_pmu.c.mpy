{
  "module_name": "hisi_uncore_pmu.c",
  "hash_id": "839b998e93af4db30e060e6ee67c998be505566949e3edba0fd9fe10071376ec",
  "original_prompt": "Ingested from linux-6.6.14/drivers/perf/hisilicon/hisi_uncore_pmu.c",
  "human_readable_source": "\n \n#include <linux/bitmap.h>\n#include <linux/bitops.h>\n#include <linux/bug.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/interrupt.h>\n\n#include <asm/cputype.h>\n#include <asm/local64.h>\n\n#include \"hisi_uncore_pmu.h\"\n\n#define HISI_MAX_PERIOD(nr) (GENMASK_ULL((nr) - 1, 0))\n\n \nssize_t hisi_format_sysfs_show(struct device *dev,\n\t\t\t       struct device_attribute *attr, char *buf)\n{\n\tstruct dev_ext_attribute *eattr;\n\n\teattr = container_of(attr, struct dev_ext_attribute, attr);\n\n\treturn sysfs_emit(buf, \"%s\\n\", (char *)eattr->var);\n}\nEXPORT_SYMBOL_GPL(hisi_format_sysfs_show);\n\n \nssize_t hisi_event_sysfs_show(struct device *dev,\n\t\t\t      struct device_attribute *attr, char *page)\n{\n\tstruct dev_ext_attribute *eattr;\n\n\teattr = container_of(attr, struct dev_ext_attribute, attr);\n\n\treturn sysfs_emit(page, \"config=0x%lx\\n\", (unsigned long)eattr->var);\n}\nEXPORT_SYMBOL_GPL(hisi_event_sysfs_show);\n\n \nssize_t hisi_cpumask_sysfs_show(struct device *dev,\n\t\t\t\tstruct device_attribute *attr, char *buf)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(dev_get_drvdata(dev));\n\n\treturn sysfs_emit(buf, \"%d\\n\", hisi_pmu->on_cpu);\n}\nEXPORT_SYMBOL_GPL(hisi_cpumask_sysfs_show);\n\nstatic bool hisi_validate_event_group(struct perf_event *event)\n{\n\tstruct perf_event *sibling, *leader = event->group_leader;\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\t \n\tint counters = 1;\n\n\tif (!is_software_event(leader)) {\n\t\t \n\t\tif (leader->pmu != event->pmu)\n\t\t\treturn false;\n\n\t\t \n\t\tif (leader != event)\n\t\t\tcounters++;\n\t}\n\n\tfor_each_sibling_event(sibling, event->group_leader) {\n\t\tif (is_software_event(sibling))\n\t\t\tcontinue;\n\t\tif (sibling->pmu != event->pmu)\n\t\t\treturn false;\n\t\t \n\t\tcounters++;\n\t}\n\n\t \n\treturn counters <= hisi_pmu->num_counters;\n}\n\nint hisi_uncore_pmu_get_event_idx(struct perf_event *event)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tunsigned long *used_mask = hisi_pmu->pmu_events.used_mask;\n\tu32 num_counters = hisi_pmu->num_counters;\n\tint idx;\n\n\tidx = find_first_zero_bit(used_mask, num_counters);\n\tif (idx == num_counters)\n\t\treturn -EAGAIN;\n\n\tset_bit(idx, used_mask);\n\n\treturn idx;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_get_event_idx);\n\nssize_t hisi_uncore_pmu_identifier_attr_show(struct device *dev,\n\t\t\t\t\t     struct device_attribute *attr,\n\t\t\t\t\t     char *page)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(dev_get_drvdata(dev));\n\n\treturn sysfs_emit(page, \"0x%08x\\n\", hisi_pmu->identifier);\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_identifier_attr_show);\n\nstatic void hisi_uncore_pmu_clear_event_idx(struct hisi_pmu *hisi_pmu, int idx)\n{\n\tclear_bit(idx, hisi_pmu->pmu_events.used_mask);\n}\n\nstatic irqreturn_t hisi_uncore_pmu_isr(int irq, void *data)\n{\n\tstruct hisi_pmu *hisi_pmu = data;\n\tstruct perf_event *event;\n\tunsigned long overflown;\n\tint idx;\n\n\toverflown = hisi_pmu->ops->get_int_status(hisi_pmu);\n\tif (!overflown)\n\t\treturn IRQ_NONE;\n\n\t \n\tfor_each_set_bit(idx, &overflown, hisi_pmu->num_counters) {\n\t\t \n\t\thisi_pmu->ops->clear_int_status(hisi_pmu, idx);\n\t\t \n\t\tevent = hisi_pmu->pmu_events.hw_events[idx];\n\t\tif (!event)\n\t\t\tcontinue;\n\n\t\thisi_uncore_pmu_event_update(event);\n\t\thisi_uncore_pmu_set_event_period(event);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nint hisi_uncore_pmu_init_irq(struct hisi_pmu *hisi_pmu,\n\t\t\t     struct platform_device *pdev)\n{\n\tint irq, ret;\n\n\tirq = platform_get_irq(pdev, 0);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tret = devm_request_irq(&pdev->dev, irq, hisi_uncore_pmu_isr,\n\t\t\t       IRQF_NOBALANCING | IRQF_NO_THREAD,\n\t\t\t       dev_name(&pdev->dev), hisi_pmu);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Fail to request IRQ: %d ret: %d.\\n\", irq, ret);\n\t\treturn ret;\n\t}\n\n\thisi_pmu->irq = irq;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_init_irq);\n\nint hisi_uncore_pmu_event_init(struct perf_event *event)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\tstruct hisi_pmu *hisi_pmu;\n\n\tif (event->attr.type != event->pmu->type)\n\t\treturn -ENOENT;\n\n\t \n\tif (is_sampling_event(event) || event->attach_state & PERF_ATTACH_TASK)\n\t\treturn -EOPNOTSUPP;\n\n\t \n\tif (event->cpu < 0)\n\t\treturn -EINVAL;\n\n\t \n\tif (!hisi_validate_event_group(event))\n\t\treturn -EINVAL;\n\n\thisi_pmu = to_hisi_pmu(event->pmu);\n\tif (event->attr.config > hisi_pmu->check_event)\n\t\treturn -EINVAL;\n\n\tif (hisi_pmu->on_cpu == -1)\n\t\treturn -EINVAL;\n\t \n\thwc->idx\t\t= -1;\n\thwc->config_base\t= event->attr.config;\n\n\tif (hisi_pmu->ops->check_filter && hisi_pmu->ops->check_filter(event))\n\t\treturn -EINVAL;\n\n\t \n\tevent->cpu = hisi_pmu->on_cpu;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_event_init);\n\n \nstatic void hisi_uncore_pmu_enable_event(struct perf_event *event)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\thisi_pmu->ops->write_evtype(hisi_pmu, hwc->idx,\n\t\t\t\t    HISI_GET_EVENTID(event));\n\n\tif (hisi_pmu->ops->enable_filter)\n\t\thisi_pmu->ops->enable_filter(event);\n\n\thisi_pmu->ops->enable_counter_int(hisi_pmu, hwc);\n\thisi_pmu->ops->enable_counter(hisi_pmu, hwc);\n}\n\n \nstatic void hisi_uncore_pmu_disable_event(struct perf_event *event)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\thisi_pmu->ops->disable_counter(hisi_pmu, hwc);\n\thisi_pmu->ops->disable_counter_int(hisi_pmu, hwc);\n\n\tif (hisi_pmu->ops->disable_filter)\n\t\thisi_pmu->ops->disable_filter(event);\n}\n\nvoid hisi_uncore_pmu_set_event_period(struct perf_event *event)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\t \n\tu64 val = BIT_ULL(hisi_pmu->counter_bits - 1);\n\n\tlocal64_set(&hwc->prev_count, val);\n\t \n\thisi_pmu->ops->write_counter(hisi_pmu, hwc, val);\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_set_event_period);\n\nvoid hisi_uncore_pmu_event_update(struct perf_event *event)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\tu64 delta, prev_raw_count, new_raw_count;\n\n\tdo {\n\t\t \n\t\tnew_raw_count = hisi_pmu->ops->read_counter(hisi_pmu, hwc);\n\t\tprev_raw_count = local64_read(&hwc->prev_count);\n\t} while (local64_cmpxchg(&hwc->prev_count, prev_raw_count,\n\t\t\t\t new_raw_count) != prev_raw_count);\n\t \n\tdelta = (new_raw_count - prev_raw_count) &\n\t\tHISI_MAX_PERIOD(hisi_pmu->counter_bits);\n\tlocal64_add(delta, &event->count);\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_event_update);\n\nvoid hisi_uncore_pmu_start(struct perf_event *event, int flags)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (WARN_ON_ONCE(!(hwc->state & PERF_HES_STOPPED)))\n\t\treturn;\n\n\tWARN_ON_ONCE(!(hwc->state & PERF_HES_UPTODATE));\n\thwc->state = 0;\n\thisi_uncore_pmu_set_event_period(event);\n\n\tif (flags & PERF_EF_RELOAD) {\n\t\tu64 prev_raw_count =  local64_read(&hwc->prev_count);\n\n\t\thisi_pmu->ops->write_counter(hisi_pmu, hwc, prev_raw_count);\n\t}\n\n\thisi_uncore_pmu_enable_event(event);\n\tperf_event_update_userpage(event);\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_start);\n\nvoid hisi_uncore_pmu_stop(struct perf_event *event, int flags)\n{\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\thisi_uncore_pmu_disable_event(event);\n\tWARN_ON_ONCE(hwc->state & PERF_HES_STOPPED);\n\thwc->state |= PERF_HES_STOPPED;\n\n\tif (hwc->state & PERF_HES_UPTODATE)\n\t\treturn;\n\n\t \n\thisi_uncore_pmu_event_update(event);\n\thwc->state |= PERF_HES_UPTODATE;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_stop);\n\nint hisi_uncore_pmu_add(struct perf_event *event, int flags)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\tint idx;\n\n\thwc->state = PERF_HES_STOPPED | PERF_HES_UPTODATE;\n\n\t \n\tidx = hisi_pmu->ops->get_event_idx(event);\n\tif (idx < 0)\n\t\treturn idx;\n\n\tevent->hw.idx = idx;\n\thisi_pmu->pmu_events.hw_events[idx] = event;\n\n\tif (flags & PERF_EF_START)\n\t\thisi_uncore_pmu_start(event, PERF_EF_RELOAD);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_add);\n\nvoid hisi_uncore_pmu_del(struct perf_event *event, int flags)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(event->pmu);\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\thisi_uncore_pmu_stop(event, PERF_EF_UPDATE);\n\thisi_uncore_pmu_clear_event_idx(hisi_pmu, hwc->idx);\n\tperf_event_update_userpage(event);\n\thisi_pmu->pmu_events.hw_events[hwc->idx] = NULL;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_del);\n\nvoid hisi_uncore_pmu_read(struct perf_event *event)\n{\n\t \n\thisi_uncore_pmu_event_update(event);\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_read);\n\nvoid hisi_uncore_pmu_enable(struct pmu *pmu)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(pmu);\n\tbool enabled = !bitmap_empty(hisi_pmu->pmu_events.used_mask,\n\t\t\t\t    hisi_pmu->num_counters);\n\n\tif (!enabled)\n\t\treturn;\n\n\thisi_pmu->ops->start_counters(hisi_pmu);\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_enable);\n\nvoid hisi_uncore_pmu_disable(struct pmu *pmu)\n{\n\tstruct hisi_pmu *hisi_pmu = to_hisi_pmu(pmu);\n\n\thisi_pmu->ops->stop_counters(hisi_pmu);\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_disable);\n\n\n \nstatic void hisi_read_sccl_and_ccl_id(int *scclp, int *cclp)\n{\n\tu64 mpidr = read_cpuid_mpidr();\n\tint aff3 = MPIDR_AFFINITY_LEVEL(mpidr, 3);\n\tint aff2 = MPIDR_AFFINITY_LEVEL(mpidr, 2);\n\tint aff1 = MPIDR_AFFINITY_LEVEL(mpidr, 1);\n\tbool mt = mpidr & MPIDR_MT_BITMASK;\n\tint sccl, ccl;\n\n\tif (mt && read_cpuid_part_number() == HISI_CPU_PART_TSV110) {\n\t\tsccl = aff2 >> 3;\n\t\tccl = aff2 & 0x7;\n\t} else if (mt) {\n\t\tsccl = aff3;\n\t\tccl = aff2;\n\t} else {\n\t\tsccl = aff2;\n\t\tccl = aff1;\n\t}\n\n\tif (scclp)\n\t\t*scclp = sccl;\n\tif (cclp)\n\t\t*cclp = ccl;\n}\n\n \nstatic bool hisi_pmu_cpu_is_associated_pmu(struct hisi_pmu *hisi_pmu)\n{\n\tint sccl_id, ccl_id;\n\n\t \n\tif (hisi_pmu->sccl_id == -1)\n\t\treturn true;\n\n\tif (hisi_pmu->ccl_id == -1) {\n\t\t \n\t\thisi_read_sccl_and_ccl_id(&sccl_id, NULL);\n\n\t\treturn sccl_id == hisi_pmu->sccl_id;\n\t}\n\n\thisi_read_sccl_and_ccl_id(&sccl_id, &ccl_id);\n\n\treturn sccl_id == hisi_pmu->sccl_id && ccl_id == hisi_pmu->ccl_id;\n}\n\nint hisi_uncore_pmu_online_cpu(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct hisi_pmu *hisi_pmu = hlist_entry_safe(node, struct hisi_pmu,\n\t\t\t\t\t\t     node);\n\n\tif (!hisi_pmu_cpu_is_associated_pmu(hisi_pmu))\n\t\treturn 0;\n\n\tcpumask_set_cpu(cpu, &hisi_pmu->associated_cpus);\n\n\t \n\tif (hisi_pmu->on_cpu != -1)\n\t\treturn 0;\n\n\t \n\thisi_pmu->on_cpu = cpu;\n\n\t \n\tWARN_ON(irq_set_affinity(hisi_pmu->irq, cpumask_of(cpu)));\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_online_cpu);\n\nint hisi_uncore_pmu_offline_cpu(unsigned int cpu, struct hlist_node *node)\n{\n\tstruct hisi_pmu *hisi_pmu = hlist_entry_safe(node, struct hisi_pmu,\n\t\t\t\t\t\t     node);\n\tcpumask_t pmu_online_cpus;\n\tunsigned int target;\n\n\tif (!cpumask_test_and_clear_cpu(cpu, &hisi_pmu->associated_cpus))\n\t\treturn 0;\n\n\t \n\tif (hisi_pmu->on_cpu != cpu)\n\t\treturn 0;\n\n\t \n\thisi_pmu->on_cpu = -1;\n\n\t \n\tcpumask_and(&pmu_online_cpus, &hisi_pmu->associated_cpus,\n\t\t    cpu_online_mask);\n\ttarget = cpumask_any_but(&pmu_online_cpus, cpu);\n\tif (target >= nr_cpu_ids)\n\t\treturn 0;\n\n\tperf_pmu_migrate_context(&hisi_pmu->pmu, cpu, target);\n\t \n\thisi_pmu->on_cpu = target;\n\tWARN_ON(irq_set_affinity(hisi_pmu->irq, cpumask_of(target)));\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hisi_uncore_pmu_offline_cpu);\n\nvoid hisi_pmu_init(struct hisi_pmu *hisi_pmu, struct module *module)\n{\n\tstruct pmu *pmu = &hisi_pmu->pmu;\n\n\tpmu->module             = module;\n\tpmu->task_ctx_nr        = perf_invalid_context;\n\tpmu->event_init         = hisi_uncore_pmu_event_init;\n\tpmu->pmu_enable         = hisi_uncore_pmu_enable;\n\tpmu->pmu_disable        = hisi_uncore_pmu_disable;\n\tpmu->add                = hisi_uncore_pmu_add;\n\tpmu->del                = hisi_uncore_pmu_del;\n\tpmu->start              = hisi_uncore_pmu_start;\n\tpmu->stop               = hisi_uncore_pmu_stop;\n\tpmu->read               = hisi_uncore_pmu_read;\n\tpmu->attr_groups        = hisi_pmu->pmu_events.attr_groups;\n\tpmu->capabilities       = PERF_PMU_CAP_NO_EXCLUDE;\n}\nEXPORT_SYMBOL_GPL(hisi_pmu_init);\n\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}