{
  "module_name": "hwspinlock_core.c",
  "hash_id": "91d73ec6e03c50163c9a8d366584cc891fe6232c1fa5d714c614bd8b1ba30037",
  "original_prompt": "Ingested from linux-6.6.14/drivers/hwspinlock/hwspinlock_core.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt)    \"%s: \" fmt, __func__\n\n#include <linux/delay.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/spinlock.h>\n#include <linux/types.h>\n#include <linux/err.h>\n#include <linux/jiffies.h>\n#include <linux/radix-tree.h>\n#include <linux/hwspinlock.h>\n#include <linux/pm_runtime.h>\n#include <linux/mutex.h>\n#include <linux/of.h>\n\n#include \"hwspinlock_internal.h\"\n\n \n#define HWSPINLOCK_RETRY_DELAY_US\t100\n\n \n#define HWSPINLOCK_UNUSED\t(0)  \n\n \nstatic RADIX_TREE(hwspinlock_tree, GFP_KERNEL);\n\n \nstatic DEFINE_MUTEX(hwspinlock_tree_lock);\n\n\n \nint __hwspin_trylock(struct hwspinlock *hwlock, int mode, unsigned long *flags)\n{\n\tint ret;\n\n\tif (WARN_ON(!hwlock || (!flags && mode == HWLOCK_IRQSTATE)))\n\t\treturn -EINVAL;\n\n\t \n\tswitch (mode) {\n\tcase HWLOCK_IRQSTATE:\n\t\tret = spin_trylock_irqsave(&hwlock->lock, *flags);\n\t\tbreak;\n\tcase HWLOCK_IRQ:\n\t\tret = spin_trylock_irq(&hwlock->lock);\n\t\tbreak;\n\tcase HWLOCK_RAW:\n\tcase HWLOCK_IN_ATOMIC:\n\t\tret = 1;\n\t\tbreak;\n\tdefault:\n\t\tret = spin_trylock(&hwlock->lock);\n\t\tbreak;\n\t}\n\n\t \n\tif (!ret)\n\t\treturn -EBUSY;\n\n\t \n\tret = hwlock->bank->ops->trylock(hwlock);\n\n\t \n\tif (!ret) {\n\t\tswitch (mode) {\n\t\tcase HWLOCK_IRQSTATE:\n\t\t\tspin_unlock_irqrestore(&hwlock->lock, *flags);\n\t\t\tbreak;\n\t\tcase HWLOCK_IRQ:\n\t\t\tspin_unlock_irq(&hwlock->lock);\n\t\t\tbreak;\n\t\tcase HWLOCK_RAW:\n\t\tcase HWLOCK_IN_ATOMIC:\n\t\t\t \n\t\t\tbreak;\n\t\tdefault:\n\t\t\tspin_unlock(&hwlock->lock);\n\t\t\tbreak;\n\t\t}\n\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tmb();\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(__hwspin_trylock);\n\n \nint __hwspin_lock_timeout(struct hwspinlock *hwlock, unsigned int to,\n\t\t\t\t\tint mode, unsigned long *flags)\n{\n\tint ret;\n\tunsigned long expire, atomic_delay = 0;\n\n\texpire = msecs_to_jiffies(to) + jiffies;\n\n\tfor (;;) {\n\t\t \n\t\tret = __hwspin_trylock(hwlock, mode, flags);\n\t\tif (ret != -EBUSY)\n\t\t\tbreak;\n\n\t\t \n\t\tif (mode == HWLOCK_IN_ATOMIC) {\n\t\t\tudelay(HWSPINLOCK_RETRY_DELAY_US);\n\t\t\tatomic_delay += HWSPINLOCK_RETRY_DELAY_US;\n\t\t\tif (atomic_delay > to * 1000)\n\t\t\t\treturn -ETIMEDOUT;\n\t\t} else {\n\t\t\tif (time_is_before_eq_jiffies(expire))\n\t\t\t\treturn -ETIMEDOUT;\n\t\t}\n\n\t\t \n\t\tif (hwlock->bank->ops->relax)\n\t\t\thwlock->bank->ops->relax(hwlock);\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(__hwspin_lock_timeout);\n\n \nvoid __hwspin_unlock(struct hwspinlock *hwlock, int mode, unsigned long *flags)\n{\n\tif (WARN_ON(!hwlock || (!flags && mode == HWLOCK_IRQSTATE)))\n\t\treturn;\n\n\t \n\tmb();\n\n\thwlock->bank->ops->unlock(hwlock);\n\n\t \n\tswitch (mode) {\n\tcase HWLOCK_IRQSTATE:\n\t\tspin_unlock_irqrestore(&hwlock->lock, *flags);\n\t\tbreak;\n\tcase HWLOCK_IRQ:\n\t\tspin_unlock_irq(&hwlock->lock);\n\t\tbreak;\n\tcase HWLOCK_RAW:\n\tcase HWLOCK_IN_ATOMIC:\n\t\t \n\t\tbreak;\n\tdefault:\n\t\tspin_unlock(&hwlock->lock);\n\t\tbreak;\n\t}\n}\nEXPORT_SYMBOL_GPL(__hwspin_unlock);\n\n \nstatic inline int\nof_hwspin_lock_simple_xlate(const struct of_phandle_args *hwlock_spec)\n{\n\tif (WARN_ON(hwlock_spec->args_count != 1))\n\t\treturn -EINVAL;\n\n\treturn hwlock_spec->args[0];\n}\n\n \nint of_hwspin_lock_get_id(struct device_node *np, int index)\n{\n\tstruct of_phandle_args args;\n\tstruct hwspinlock *hwlock;\n\tstruct radix_tree_iter iter;\n\tvoid **slot;\n\tint id;\n\tint ret;\n\n\tret = of_parse_phandle_with_args(np, \"hwlocks\", \"#hwlock-cells\", index,\n\t\t\t\t\t &args);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!of_device_is_available(args.np)) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\t \n\tret = -EPROBE_DEFER;\n\trcu_read_lock();\n\tradix_tree_for_each_slot(slot, &hwspinlock_tree, &iter, 0) {\n\t\thwlock = radix_tree_deref_slot(slot);\n\t\tif (unlikely(!hwlock))\n\t\t\tcontinue;\n\t\tif (radix_tree_deref_retry(hwlock)) {\n\t\t\tslot = radix_tree_iter_retry(&iter);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (device_match_of_node(hwlock->bank->dev, args.np)) {\n\t\t\tret = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\tif (ret < 0)\n\t\tgoto out;\n\n\tid = of_hwspin_lock_simple_xlate(&args);\n\tif (id < 0 || id >= hwlock->bank->num_locks) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tid += hwlock->bank->base_id;\n\nout:\n\tof_node_put(args.np);\n\treturn ret ? ret : id;\n}\nEXPORT_SYMBOL_GPL(of_hwspin_lock_get_id);\n\n \nint of_hwspin_lock_get_id_byname(struct device_node *np, const char *name)\n{\n\tint index;\n\n\tif (!name)\n\t\treturn -EINVAL;\n\n\tindex = of_property_match_string(np, \"hwlock-names\", name);\n\tif (index < 0)\n\t\treturn index;\n\n\treturn of_hwspin_lock_get_id(np, index);\n}\nEXPORT_SYMBOL_GPL(of_hwspin_lock_get_id_byname);\n\nstatic int hwspin_lock_register_single(struct hwspinlock *hwlock, int id)\n{\n\tstruct hwspinlock *tmp;\n\tint ret;\n\n\tmutex_lock(&hwspinlock_tree_lock);\n\n\tret = radix_tree_insert(&hwspinlock_tree, id, hwlock);\n\tif (ret) {\n\t\tif (ret == -EEXIST)\n\t\t\tpr_err(\"hwspinlock id %d already exists!\\n\", id);\n\t\tgoto out;\n\t}\n\n\t \n\ttmp = radix_tree_tag_set(&hwspinlock_tree, id, HWSPINLOCK_UNUSED);\n\n\t \n\tWARN_ON(tmp != hwlock);\n\nout:\n\tmutex_unlock(&hwspinlock_tree_lock);\n\treturn 0;\n}\n\nstatic struct hwspinlock *hwspin_lock_unregister_single(unsigned int id)\n{\n\tstruct hwspinlock *hwlock = NULL;\n\tint ret;\n\n\tmutex_lock(&hwspinlock_tree_lock);\n\n\t \n\tret = radix_tree_tag_get(&hwspinlock_tree, id, HWSPINLOCK_UNUSED);\n\tif (ret == 0) {\n\t\tpr_err(\"hwspinlock %d still in use (or not present)\\n\", id);\n\t\tgoto out;\n\t}\n\n\thwlock = radix_tree_delete(&hwspinlock_tree, id);\n\tif (!hwlock) {\n\t\tpr_err(\"failed to delete hwspinlock %d\\n\", id);\n\t\tgoto out;\n\t}\n\nout:\n\tmutex_unlock(&hwspinlock_tree_lock);\n\treturn hwlock;\n}\n\n \nint hwspin_lock_register(struct hwspinlock_device *bank, struct device *dev,\n\t\tconst struct hwspinlock_ops *ops, int base_id, int num_locks)\n{\n\tstruct hwspinlock *hwlock;\n\tint ret = 0, i;\n\n\tif (!bank || !ops || !dev || !num_locks || !ops->trylock ||\n\t\t\t\t\t\t\t!ops->unlock) {\n\t\tpr_err(\"invalid parameters\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tbank->dev = dev;\n\tbank->ops = ops;\n\tbank->base_id = base_id;\n\tbank->num_locks = num_locks;\n\n\tfor (i = 0; i < num_locks; i++) {\n\t\thwlock = &bank->lock[i];\n\n\t\tspin_lock_init(&hwlock->lock);\n\t\thwlock->bank = bank;\n\n\t\tret = hwspin_lock_register_single(hwlock, base_id + i);\n\t\tif (ret)\n\t\t\tgoto reg_failed;\n\t}\n\n\treturn 0;\n\nreg_failed:\n\twhile (--i >= 0)\n\t\thwspin_lock_unregister_single(base_id + i);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(hwspin_lock_register);\n\n \nint hwspin_lock_unregister(struct hwspinlock_device *bank)\n{\n\tstruct hwspinlock *hwlock, *tmp;\n\tint i;\n\n\tfor (i = 0; i < bank->num_locks; i++) {\n\t\thwlock = &bank->lock[i];\n\n\t\ttmp = hwspin_lock_unregister_single(bank->base_id + i);\n\t\tif (!tmp)\n\t\t\treturn -EBUSY;\n\n\t\t \n\t\tWARN_ON(tmp != hwlock);\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(hwspin_lock_unregister);\n\nstatic void devm_hwspin_lock_unreg(struct device *dev, void *res)\n{\n\thwspin_lock_unregister(*(struct hwspinlock_device **)res);\n}\n\nstatic int devm_hwspin_lock_device_match(struct device *dev, void *res,\n\t\t\t\t\t void *data)\n{\n\tstruct hwspinlock_device **bank = res;\n\n\tif (WARN_ON(!bank || !*bank))\n\t\treturn 0;\n\n\treturn *bank == data;\n}\n\n \nint devm_hwspin_lock_unregister(struct device *dev,\n\t\t\t\tstruct hwspinlock_device *bank)\n{\n\tint ret;\n\n\tret = devres_release(dev, devm_hwspin_lock_unreg,\n\t\t\t     devm_hwspin_lock_device_match, bank);\n\tWARN_ON(ret);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(devm_hwspin_lock_unregister);\n\n \nint devm_hwspin_lock_register(struct device *dev,\n\t\t\t      struct hwspinlock_device *bank,\n\t\t\t      const struct hwspinlock_ops *ops,\n\t\t\t      int base_id, int num_locks)\n{\n\tstruct hwspinlock_device **ptr;\n\tint ret;\n\n\tptr = devres_alloc(devm_hwspin_lock_unreg, sizeof(*ptr), GFP_KERNEL);\n\tif (!ptr)\n\t\treturn -ENOMEM;\n\n\tret = hwspin_lock_register(bank, dev, ops, base_id, num_locks);\n\tif (!ret) {\n\t\t*ptr = bank;\n\t\tdevres_add(dev, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(devm_hwspin_lock_register);\n\n \nstatic int __hwspin_lock_request(struct hwspinlock *hwlock)\n{\n\tstruct device *dev = hwlock->bank->dev;\n\tstruct hwspinlock *tmp;\n\tint ret;\n\n\t \n\tif (!try_module_get(dev->driver->owner)) {\n\t\tdev_err(dev, \"%s: can't get owner\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tret = pm_runtime_get_sync(dev);\n\tif (ret < 0 && ret != -EACCES) {\n\t\tdev_err(dev, \"%s: can't power on device\\n\", __func__);\n\t\tpm_runtime_put_noidle(dev);\n\t\tmodule_put(dev->driver->owner);\n\t\treturn ret;\n\t}\n\n\tret = 0;\n\n\t \n\ttmp = radix_tree_tag_clear(&hwspinlock_tree, hwlock_to_id(hwlock),\n\t\t\t\t\t\t\tHWSPINLOCK_UNUSED);\n\n\t \n\tWARN_ON(tmp != hwlock);\n\n\treturn ret;\n}\n\n \nint hwspin_lock_get_id(struct hwspinlock *hwlock)\n{\n\tif (!hwlock) {\n\t\tpr_err(\"invalid hwlock\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn hwlock_to_id(hwlock);\n}\nEXPORT_SYMBOL_GPL(hwspin_lock_get_id);\n\n \nstruct hwspinlock *hwspin_lock_request(void)\n{\n\tstruct hwspinlock *hwlock;\n\tint ret;\n\n\tmutex_lock(&hwspinlock_tree_lock);\n\n\t \n\tret = radix_tree_gang_lookup_tag(&hwspinlock_tree, (void **)&hwlock,\n\t\t\t\t\t\t0, 1, HWSPINLOCK_UNUSED);\n\tif (ret == 0) {\n\t\tpr_warn(\"a free hwspinlock is not available\\n\");\n\t\thwlock = NULL;\n\t\tgoto out;\n\t}\n\n\t \n\tWARN_ON(ret > 1);\n\n\t \n\tret = __hwspin_lock_request(hwlock);\n\tif (ret < 0)\n\t\thwlock = NULL;\n\nout:\n\tmutex_unlock(&hwspinlock_tree_lock);\n\treturn hwlock;\n}\nEXPORT_SYMBOL_GPL(hwspin_lock_request);\n\n \nstruct hwspinlock *hwspin_lock_request_specific(unsigned int id)\n{\n\tstruct hwspinlock *hwlock;\n\tint ret;\n\n\tmutex_lock(&hwspinlock_tree_lock);\n\n\t \n\thwlock = radix_tree_lookup(&hwspinlock_tree, id);\n\tif (!hwlock) {\n\t\tpr_warn(\"hwspinlock %u does not exist\\n\", id);\n\t\tgoto out;\n\t}\n\n\t \n\tWARN_ON(hwlock_to_id(hwlock) != id);\n\n\t \n\tret = radix_tree_tag_get(&hwspinlock_tree, id, HWSPINLOCK_UNUSED);\n\tif (ret == 0) {\n\t\tpr_warn(\"hwspinlock %u is already in use\\n\", id);\n\t\thwlock = NULL;\n\t\tgoto out;\n\t}\n\n\t \n\tret = __hwspin_lock_request(hwlock);\n\tif (ret < 0)\n\t\thwlock = NULL;\n\nout:\n\tmutex_unlock(&hwspinlock_tree_lock);\n\treturn hwlock;\n}\nEXPORT_SYMBOL_GPL(hwspin_lock_request_specific);\n\n \nint hwspin_lock_free(struct hwspinlock *hwlock)\n{\n\tstruct device *dev;\n\tstruct hwspinlock *tmp;\n\tint ret;\n\n\tif (!hwlock) {\n\t\tpr_err(\"invalid hwlock\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = hwlock->bank->dev;\n\tmutex_lock(&hwspinlock_tree_lock);\n\n\t \n\tret = radix_tree_tag_get(&hwspinlock_tree, hwlock_to_id(hwlock),\n\t\t\t\t\t\t\tHWSPINLOCK_UNUSED);\n\tif (ret == 1) {\n\t\tdev_err(dev, \"%s: hwlock is already free\\n\", __func__);\n\t\tdump_stack();\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t \n\tpm_runtime_put(dev);\n\n\t \n\ttmp = radix_tree_tag_set(&hwspinlock_tree, hwlock_to_id(hwlock),\n\t\t\t\t\t\t\tHWSPINLOCK_UNUSED);\n\n\t \n\tWARN_ON(tmp != hwlock);\n\n\tmodule_put(dev->driver->owner);\n\nout:\n\tmutex_unlock(&hwspinlock_tree_lock);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(hwspin_lock_free);\n\nstatic int devm_hwspin_lock_match(struct device *dev, void *res, void *data)\n{\n\tstruct hwspinlock **hwlock = res;\n\n\tif (WARN_ON(!hwlock || !*hwlock))\n\t\treturn 0;\n\n\treturn *hwlock == data;\n}\n\nstatic void devm_hwspin_lock_release(struct device *dev, void *res)\n{\n\thwspin_lock_free(*(struct hwspinlock **)res);\n}\n\n \nint devm_hwspin_lock_free(struct device *dev, struct hwspinlock *hwlock)\n{\n\tint ret;\n\n\tret = devres_release(dev, devm_hwspin_lock_release,\n\t\t\t     devm_hwspin_lock_match, hwlock);\n\tWARN_ON(ret);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(devm_hwspin_lock_free);\n\n \nstruct hwspinlock *devm_hwspin_lock_request(struct device *dev)\n{\n\tstruct hwspinlock **ptr, *hwlock;\n\n\tptr = devres_alloc(devm_hwspin_lock_release, sizeof(*ptr), GFP_KERNEL);\n\tif (!ptr)\n\t\treturn NULL;\n\n\thwlock = hwspin_lock_request();\n\tif (hwlock) {\n\t\t*ptr = hwlock;\n\t\tdevres_add(dev, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn hwlock;\n}\nEXPORT_SYMBOL_GPL(devm_hwspin_lock_request);\n\n \nstruct hwspinlock *devm_hwspin_lock_request_specific(struct device *dev,\n\t\t\t\t\t\t     unsigned int id)\n{\n\tstruct hwspinlock **ptr, *hwlock;\n\n\tptr = devres_alloc(devm_hwspin_lock_release, sizeof(*ptr), GFP_KERNEL);\n\tif (!ptr)\n\t\treturn NULL;\n\n\thwlock = hwspin_lock_request_specific(id);\n\tif (hwlock) {\n\t\t*ptr = hwlock;\n\t\tdevres_add(dev, ptr);\n\t} else {\n\t\tdevres_free(ptr);\n\t}\n\n\treturn hwlock;\n}\nEXPORT_SYMBOL_GPL(devm_hwspin_lock_request_specific);\n\nMODULE_DESCRIPTION(\"Hardware spinlock interface\");\nMODULE_AUTHOR(\"Ohad Ben-Cohen <ohad@wizery.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}