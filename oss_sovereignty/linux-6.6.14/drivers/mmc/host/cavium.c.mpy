{
  "module_name": "cavium.c",
  "hash_id": "0761c49903c724959cd9c156293e31c00b4dac5c54f8dbc4596857ca619a1920",
  "original_prompt": "Ingested from linux-6.6.14/drivers/mmc/host/cavium.c",
  "human_readable_source": " \n#include <linux/bitfield.h>\n#include <linux/delay.h>\n#include <linux/dma-direction.h>\n#include <linux/dma-mapping.h>\n#include <linux/gpio/consumer.h>\n#include <linux/interrupt.h>\n#include <linux/mmc/mmc.h>\n#include <linux/mmc/slot-gpio.h>\n#include <linux/module.h>\n#include <linux/regulator/consumer.h>\n#include <linux/scatterlist.h>\n#include <linux/time.h>\n\n#include \"cavium.h\"\n\nconst char *cvm_mmc_irq_names[] = {\n\t\"MMC Buffer\",\n\t\"MMC Command\",\n\t\"MMC DMA\",\n\t\"MMC Command Error\",\n\t\"MMC DMA Error\",\n\t\"MMC Switch\",\n\t\"MMC Switch Error\",\n\t\"MMC DMA int Fifo\",\n\t\"MMC DMA int\",\n};\n\n \nstatic struct cvm_mmc_cr_type cvm_mmc_cr_types[] = {\n\t{0, 0},\t\t \n\t{0, 3},\t\t \n\t{0, 2},\t\t \n\t{0, 1},\t\t \n\t{0, 0},\t\t \n\t{0, 1},\t\t \n\t{0, 1},\t\t \n\t{0, 1},\t\t \n\t{1, 1},\t\t \n\t{0, 2},\t\t \n\t{0, 2},\t\t \n\t{1, 1},\t\t \n\t{0, 1},\t\t \n\t{0, 1},\t\t \n\t{1, 1},\t\t \n\t{0, 0},\t\t \n\t{0, 1},\t\t \n\t{1, 1},\t\t \n\t{1, 1},\t\t \n\t{3, 1},\t\t \n\t{2, 1},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 1},\t\t \n\t{2, 1},\t\t \n\t{2, 1},\t\t \n\t{2, 1},\t\t \n\t{2, 1},\t\t \n\t{0, 1},\t\t \n\t{0, 1},\t\t \n\t{1, 1},\t\t \n\t{1, 1},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 1},\t\t \n\t{0, 1},\t\t \n\t{0, 0},\t\t \n\t{0, 1},\t\t \n\t{0, 4},\t\t \n\t{0, 5},\t\t \n\t{0, 0},\t\t \n\t{2, 1},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 1},\t\t \n\t{0xff, 0xff},\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0},\t\t \n\t{0, 0}\t\t \n};\n\nstatic struct cvm_mmc_cr_mods cvm_mmc_get_cr_mods(struct mmc_command *cmd)\n{\n\tstruct cvm_mmc_cr_type *cr;\n\tu8 hardware_ctype, hardware_rtype;\n\tu8 desired_ctype = 0, desired_rtype = 0;\n\tstruct cvm_mmc_cr_mods r;\n\n\tcr = cvm_mmc_cr_types + (cmd->opcode & 0x3f);\n\thardware_ctype = cr->ctype;\n\thardware_rtype = cr->rtype;\n\tif (cmd->opcode == MMC_GEN_CMD)\n\t\thardware_ctype = (cmd->arg & 1) ? 1 : 2;\n\n\tswitch (mmc_cmd_type(cmd)) {\n\tcase MMC_CMD_ADTC:\n\t\tdesired_ctype = (cmd->data->flags & MMC_DATA_WRITE) ? 2 : 1;\n\t\tbreak;\n\tcase MMC_CMD_AC:\n\tcase MMC_CMD_BC:\n\tcase MMC_CMD_BCR:\n\t\tdesired_ctype = 0;\n\t\tbreak;\n\t}\n\n\tswitch (mmc_resp_type(cmd)) {\n\tcase MMC_RSP_NONE:\n\t\tdesired_rtype = 0;\n\t\tbreak;\n\tcase MMC_RSP_R1: \n\tcase MMC_RSP_R1B:\n\t\tdesired_rtype = 1;\n\t\tbreak;\n\tcase MMC_RSP_R2:\n\t\tdesired_rtype = 2;\n\t\tbreak;\n\tcase MMC_RSP_R3:  \n\t\tdesired_rtype = 3;\n\t\tbreak;\n\t}\n\tr.ctype_xor = desired_ctype ^ hardware_ctype;\n\tr.rtype_xor = desired_rtype ^ hardware_rtype;\n\treturn r;\n}\n\nstatic void check_switch_errors(struct cvm_mmc_host *host)\n{\n\tu64 emm_switch;\n\n\temm_switch = readq(host->base + MIO_EMM_SWITCH(host));\n\tif (emm_switch & MIO_EMM_SWITCH_ERR0)\n\t\tdev_err(host->dev, \"Switch power class error\\n\");\n\tif (emm_switch & MIO_EMM_SWITCH_ERR1)\n\t\tdev_err(host->dev, \"Switch hs timing error\\n\");\n\tif (emm_switch & MIO_EMM_SWITCH_ERR2)\n\t\tdev_err(host->dev, \"Switch bus width error\\n\");\n}\n\nstatic void clear_bus_id(u64 *reg)\n{\n\tu64 bus_id_mask = GENMASK_ULL(61, 60);\n\n\t*reg &= ~bus_id_mask;\n}\n\nstatic void set_bus_id(u64 *reg, int bus_id)\n{\n\tclear_bus_id(reg);\n\t*reg |= FIELD_PREP(GENMASK(61, 60), bus_id);\n}\n\nstatic int get_bus_id(u64 reg)\n{\n\treturn FIELD_GET(GENMASK_ULL(61, 60), reg);\n}\n\n \nstatic void do_switch(struct cvm_mmc_host *host, u64 emm_switch)\n{\n\tint retries = 100;\n\tu64 rsp_sts;\n\tint bus_id;\n\n\t \n\tbus_id = get_bus_id(emm_switch);\n\tclear_bus_id(&emm_switch);\n\twriteq(emm_switch, host->base + MIO_EMM_SWITCH(host));\n\n\tset_bus_id(&emm_switch, bus_id);\n\twriteq(emm_switch, host->base + MIO_EMM_SWITCH(host));\n\n\t \n\tdo {\n\t\trsp_sts = readq(host->base + MIO_EMM_RSP_STS(host));\n\t\tif (!(rsp_sts & MIO_EMM_RSP_STS_SWITCH_VAL))\n\t\t\tbreak;\n\t\tudelay(10);\n\t} while (--retries);\n\n\tcheck_switch_errors(host);\n}\n\nstatic bool switch_val_changed(struct cvm_mmc_slot *slot, u64 new_val)\n{\n\t \n\tu64 match = 0x3001070fffffffffull;\n\n\treturn (slot->cached_switch & match) != (new_val & match);\n}\n\nstatic void set_wdog(struct cvm_mmc_slot *slot, unsigned int ns)\n{\n\tu64 timeout;\n\n\tif (!slot->clock)\n\t\treturn;\n\n\tif (ns)\n\t\ttimeout = (slot->clock * ns) / NSEC_PER_SEC;\n\telse\n\t\ttimeout = (slot->clock * 850ull) / 1000ull;\n\twriteq(timeout, slot->host->base + MIO_EMM_WDOG(slot->host));\n}\n\nstatic void cvm_mmc_reset_bus(struct cvm_mmc_slot *slot)\n{\n\tstruct cvm_mmc_host *host = slot->host;\n\tu64 emm_switch, wdog;\n\n\temm_switch = readq(slot->host->base + MIO_EMM_SWITCH(host));\n\temm_switch &= ~(MIO_EMM_SWITCH_EXE | MIO_EMM_SWITCH_ERR0 |\n\t\t\tMIO_EMM_SWITCH_ERR1 | MIO_EMM_SWITCH_ERR2);\n\tset_bus_id(&emm_switch, slot->bus_id);\n\n\twdog = readq(slot->host->base + MIO_EMM_WDOG(host));\n\tdo_switch(slot->host, emm_switch);\n\n\tslot->cached_switch = emm_switch;\n\n\tmsleep(20);\n\n\twriteq(wdog, slot->host->base + MIO_EMM_WDOG(host));\n}\n\n \nstatic void cvm_mmc_switch_to(struct cvm_mmc_slot *slot)\n{\n\tstruct cvm_mmc_host *host = slot->host;\n\tstruct cvm_mmc_slot *old_slot;\n\tu64 emm_sample, emm_switch;\n\n\tif (slot->bus_id == host->last_slot)\n\t\treturn;\n\n\tif (host->last_slot >= 0 && host->slot[host->last_slot]) {\n\t\told_slot = host->slot[host->last_slot];\n\t\told_slot->cached_switch = readq(host->base + MIO_EMM_SWITCH(host));\n\t\told_slot->cached_rca = readq(host->base + MIO_EMM_RCA(host));\n\t}\n\n\twriteq(slot->cached_rca, host->base + MIO_EMM_RCA(host));\n\temm_switch = slot->cached_switch;\n\tset_bus_id(&emm_switch, slot->bus_id);\n\tdo_switch(host, emm_switch);\n\n\temm_sample = FIELD_PREP(MIO_EMM_SAMPLE_CMD_CNT, slot->cmd_cnt) |\n\t\t     FIELD_PREP(MIO_EMM_SAMPLE_DAT_CNT, slot->dat_cnt);\n\twriteq(emm_sample, host->base + MIO_EMM_SAMPLE(host));\n\n\thost->last_slot = slot->bus_id;\n}\n\nstatic void do_read(struct cvm_mmc_host *host, struct mmc_request *req,\n\t\t    u64 dbuf)\n{\n\tstruct sg_mapping_iter *smi = &host->smi;\n\tint data_len = req->data->blocks * req->data->blksz;\n\tint bytes_xfered, shift = -1;\n\tu64 dat = 0;\n\n\t \n\twriteq((0x10000 | (dbuf << 6)), host->base + MIO_EMM_BUF_IDX(host));\n\n\tfor (bytes_xfered = 0; bytes_xfered < data_len;) {\n\t\tif (smi->consumed >= smi->length) {\n\t\t\tif (!sg_miter_next(smi))\n\t\t\t\tbreak;\n\t\t\tsmi->consumed = 0;\n\t\t}\n\n\t\tif (shift < 0) {\n\t\t\tdat = readq(host->base + MIO_EMM_BUF_DAT(host));\n\t\t\tshift = 56;\n\t\t}\n\n\t\twhile (smi->consumed < smi->length && shift >= 0) {\n\t\t\t((u8 *)smi->addr)[smi->consumed] = (dat >> shift) & 0xff;\n\t\t\tbytes_xfered++;\n\t\t\tsmi->consumed++;\n\t\t\tshift -= 8;\n\t\t}\n\t}\n\n\tsg_miter_stop(smi);\n\treq->data->bytes_xfered = bytes_xfered;\n\treq->data->error = 0;\n}\n\nstatic void do_write(struct mmc_request *req)\n{\n\treq->data->bytes_xfered = req->data->blocks * req->data->blksz;\n\treq->data->error = 0;\n}\n\nstatic void set_cmd_response(struct cvm_mmc_host *host, struct mmc_request *req,\n\t\t\t     u64 rsp_sts)\n{\n\tu64 rsp_hi, rsp_lo;\n\n\tif (!(rsp_sts & MIO_EMM_RSP_STS_RSP_VAL))\n\t\treturn;\n\n\trsp_lo = readq(host->base + MIO_EMM_RSP_LO(host));\n\n\tswitch (FIELD_GET(MIO_EMM_RSP_STS_RSP_TYPE, rsp_sts)) {\n\tcase 1:\n\tcase 3:\n\t\treq->cmd->resp[0] = (rsp_lo >> 8) & 0xffffffff;\n\t\treq->cmd->resp[1] = 0;\n\t\treq->cmd->resp[2] = 0;\n\t\treq->cmd->resp[3] = 0;\n\t\tbreak;\n\tcase 2:\n\t\treq->cmd->resp[3] = rsp_lo & 0xffffffff;\n\t\treq->cmd->resp[2] = (rsp_lo >> 32) & 0xffffffff;\n\t\trsp_hi = readq(host->base + MIO_EMM_RSP_HI(host));\n\t\treq->cmd->resp[1] = rsp_hi & 0xffffffff;\n\t\treq->cmd->resp[0] = (rsp_hi >> 32) & 0xffffffff;\n\t\tbreak;\n\t}\n}\n\nstatic int get_dma_dir(struct mmc_data *data)\n{\n\treturn (data->flags & MMC_DATA_WRITE) ? DMA_TO_DEVICE : DMA_FROM_DEVICE;\n}\n\nstatic int finish_dma_single(struct cvm_mmc_host *host, struct mmc_data *data)\n{\n\tdata->bytes_xfered = data->blocks * data->blksz;\n\tdata->error = 0;\n\tdma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));\n\treturn 1;\n}\n\nstatic int finish_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)\n{\n\tu64 fifo_cfg;\n\tint count;\n\n\t \n\tfifo_cfg = readq(host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));\n\tcount = FIELD_GET(MIO_EMM_DMA_FIFO_CFG_COUNT, fifo_cfg);\n\tif (count)\n\t\tdev_err(host->dev, \"%u requests still pending\\n\", count);\n\n\tdata->bytes_xfered = data->blocks * data->blksz;\n\tdata->error = 0;\n\n\t \n\twriteq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));\n\tdma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));\n\treturn 1;\n}\n\nstatic int finish_dma(struct cvm_mmc_host *host, struct mmc_data *data)\n{\n\tif (host->use_sg && data->sg_len > 1)\n\t\treturn finish_dma_sg(host, data);\n\telse\n\t\treturn finish_dma_single(host, data);\n}\n\nstatic int check_status(u64 rsp_sts)\n{\n\tif (rsp_sts & MIO_EMM_RSP_STS_RSP_BAD_STS ||\n\t    rsp_sts & MIO_EMM_RSP_STS_RSP_CRC_ERR ||\n\t    rsp_sts & MIO_EMM_RSP_STS_BLK_CRC_ERR)\n\t\treturn -EILSEQ;\n\tif (rsp_sts & MIO_EMM_RSP_STS_RSP_TIMEOUT ||\n\t    rsp_sts & MIO_EMM_RSP_STS_BLK_TIMEOUT)\n\t\treturn -ETIMEDOUT;\n\tif (rsp_sts & MIO_EMM_RSP_STS_DBUF_ERR)\n\t\treturn -EIO;\n\treturn 0;\n}\n\n \nstatic void cleanup_dma(struct cvm_mmc_host *host, u64 rsp_sts)\n{\n\tu64 emm_dma;\n\n\temm_dma = readq(host->base + MIO_EMM_DMA(host));\n\temm_dma |= FIELD_PREP(MIO_EMM_DMA_VAL, 1) |\n\t\t   FIELD_PREP(MIO_EMM_DMA_DAT_NULL, 1);\n\tset_bus_id(&emm_dma, get_bus_id(rsp_sts));\n\twriteq(emm_dma, host->base + MIO_EMM_DMA(host));\n}\n\nirqreturn_t cvm_mmc_interrupt(int irq, void *dev_id)\n{\n\tstruct cvm_mmc_host *host = dev_id;\n\tstruct mmc_request *req;\n\tu64 emm_int, rsp_sts;\n\tbool host_done;\n\n\tif (host->need_irq_handler_lock)\n\t\tspin_lock(&host->irq_handler_lock);\n\telse\n\t\t__acquire(&host->irq_handler_lock);\n\n\t \n\temm_int = readq(host->base + MIO_EMM_INT(host));\n\twriteq(emm_int, host->base + MIO_EMM_INT(host));\n\n\tif (emm_int & MIO_EMM_INT_SWITCH_ERR)\n\t\tcheck_switch_errors(host);\n\n\treq = host->current_req;\n\tif (!req)\n\t\tgoto out;\n\n\trsp_sts = readq(host->base + MIO_EMM_RSP_STS(host));\n\t \n\tif ((rsp_sts & MIO_EMM_RSP_STS_DMA_VAL) && host->dma_active)\n\t\tgoto out;\n\n\tif (!host->dma_active && req->data &&\n\t    (emm_int & MIO_EMM_INT_BUF_DONE)) {\n\t\tunsigned int type = (rsp_sts >> 7) & 3;\n\n\t\tif (type == 1)\n\t\t\tdo_read(host, req, rsp_sts & MIO_EMM_RSP_STS_DBUF);\n\t\telse if (type == 2)\n\t\t\tdo_write(req);\n\t}\n\n\thost_done = emm_int & MIO_EMM_INT_CMD_DONE ||\n\t\t    emm_int & MIO_EMM_INT_DMA_DONE ||\n\t\t    emm_int & MIO_EMM_INT_CMD_ERR  ||\n\t\t    emm_int & MIO_EMM_INT_DMA_ERR;\n\n\tif (!(host_done && req->done))\n\t\tgoto no_req_done;\n\n\treq->cmd->error = check_status(rsp_sts);\n\n\tif (host->dma_active && req->data)\n\t\tif (!finish_dma(host, req->data))\n\t\t\tgoto no_req_done;\n\n\tset_cmd_response(host, req, rsp_sts);\n\tif ((emm_int & MIO_EMM_INT_DMA_ERR) &&\n\t    (rsp_sts & MIO_EMM_RSP_STS_DMA_PEND))\n\t\tcleanup_dma(host, rsp_sts);\n\n\thost->current_req = NULL;\n\treq->done(req);\n\nno_req_done:\n\tif (host->dmar_fixup_done)\n\t\thost->dmar_fixup_done(host);\n\tif (host_done)\n\t\thost->release_bus(host);\nout:\n\tif (host->need_irq_handler_lock)\n\t\tspin_unlock(&host->irq_handler_lock);\n\telse\n\t\t__release(&host->irq_handler_lock);\n\treturn IRQ_RETVAL(emm_int != 0);\n}\n\n \nstatic u64 prepare_dma_single(struct cvm_mmc_host *host, struct mmc_data *data)\n{\n\tu64 dma_cfg, addr;\n\tint count, rw;\n\n\tcount = dma_map_sg(host->dev, data->sg, data->sg_len,\n\t\t\t   get_dma_dir(data));\n\tif (!count)\n\t\treturn 0;\n\n\trw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;\n\tdma_cfg = FIELD_PREP(MIO_EMM_DMA_CFG_EN, 1) |\n\t\t  FIELD_PREP(MIO_EMM_DMA_CFG_RW, rw);\n#ifdef __LITTLE_ENDIAN\n\tdma_cfg |= FIELD_PREP(MIO_EMM_DMA_CFG_ENDIAN, 1);\n#endif\n\tdma_cfg |= FIELD_PREP(MIO_EMM_DMA_CFG_SIZE,\n\t\t\t      (sg_dma_len(&data->sg[0]) / 8) - 1);\n\n\taddr = sg_dma_address(&data->sg[0]);\n\tif (!host->big_dma_addr)\n\t\tdma_cfg |= FIELD_PREP(MIO_EMM_DMA_CFG_ADR, addr);\n\twriteq(dma_cfg, host->dma_base + MIO_EMM_DMA_CFG(host));\n\n\tpr_debug(\"[%s] sg_dma_len: %u  total sg_elem: %d\\n\",\n\t\t (rw) ? \"W\" : \"R\", sg_dma_len(&data->sg[0]), count);\n\n\tif (host->big_dma_addr)\n\t\twriteq(addr, host->dma_base + MIO_EMM_DMA_ADR(host));\n\treturn addr;\n}\n\n \nstatic u64 prepare_dma_sg(struct cvm_mmc_host *host, struct mmc_data *data)\n{\n\tstruct scatterlist *sg;\n\tu64 fifo_cmd, addr;\n\tint count, i, rw;\n\n\tcount = dma_map_sg(host->dev, data->sg, data->sg_len,\n\t\t\t   get_dma_dir(data));\n\tif (!count)\n\t\treturn 0;\n\tif (count > 16)\n\t\tgoto error;\n\n\t \n\twriteq(0, host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));\n\n\tfor_each_sg(data->sg, sg, count, i) {\n\t\t \n\t\taddr = sg_dma_address(sg);\n\t\tif (addr & 7)\n\t\t\tgoto error;\n\t\twriteq(addr, host->dma_base + MIO_EMM_DMA_FIFO_ADR(host));\n\n\t\t \n\t\trw = (data->flags & MMC_DATA_WRITE) ? 1 : 0;\n\t\tfifo_cmd = FIELD_PREP(MIO_EMM_DMA_FIFO_CMD_RW, rw);\n\n\t\t \n\t\tfifo_cmd |= FIELD_PREP(MIO_EMM_DMA_FIFO_CMD_INTDIS,\n\t\t\t\t       (i + 1 == count) ? 0 : 1);\n\n#ifdef __LITTLE_ENDIAN\n\t\tfifo_cmd |= FIELD_PREP(MIO_EMM_DMA_FIFO_CMD_ENDIAN, 1);\n#endif\n\t\tfifo_cmd |= FIELD_PREP(MIO_EMM_DMA_FIFO_CMD_SIZE,\n\t\t\t\t       sg_dma_len(sg) / 8 - 1);\n\t\t \n\t\twriteq(fifo_cmd, host->dma_base + MIO_EMM_DMA_FIFO_CMD(host));\n\t\tpr_debug(\"[%s] sg_dma_len: %u  sg_elem: %d/%d\\n\",\n\t\t\t (rw) ? \"W\" : \"R\", sg_dma_len(sg), i, count);\n\t}\n\n\t \n\treturn 1;\n\nerror:\n\tWARN_ON_ONCE(1);\n\tdma_unmap_sg(host->dev, data->sg, data->sg_len, get_dma_dir(data));\n\t \n\twriteq(BIT_ULL(16), host->dma_base + MIO_EMM_DMA_FIFO_CFG(host));\n\treturn 0;\n}\n\nstatic u64 prepare_dma(struct cvm_mmc_host *host, struct mmc_data *data)\n{\n\tif (host->use_sg && data->sg_len > 1)\n\t\treturn prepare_dma_sg(host, data);\n\telse\n\t\treturn prepare_dma_single(host, data);\n}\n\nstatic u64 prepare_ext_dma(struct mmc_host *mmc, struct mmc_request *mrq)\n{\n\tstruct cvm_mmc_slot *slot = mmc_priv(mmc);\n\tu64 emm_dma;\n\n\temm_dma = FIELD_PREP(MIO_EMM_DMA_VAL, 1) |\n\t\t  FIELD_PREP(MIO_EMM_DMA_SECTOR,\n\t\t\t     mmc_card_is_blockaddr(mmc->card) ? 1 : 0) |\n\t\t  FIELD_PREP(MIO_EMM_DMA_RW,\n\t\t\t     (mrq->data->flags & MMC_DATA_WRITE) ? 1 : 0) |\n\t\t  FIELD_PREP(MIO_EMM_DMA_BLOCK_CNT, mrq->data->blocks) |\n\t\t  FIELD_PREP(MIO_EMM_DMA_CARD_ADDR, mrq->cmd->arg);\n\tset_bus_id(&emm_dma, slot->bus_id);\n\n\tif (mmc_card_mmc(mmc->card) || (mmc_card_sd(mmc->card) &&\n\t    (mmc->card->scr.cmds & SD_SCR_CMD23_SUPPORT)))\n\t\temm_dma |= FIELD_PREP(MIO_EMM_DMA_MULTI, 1);\n\n\tpr_debug(\"[%s] blocks: %u  multi: %d\\n\",\n\t\t(emm_dma & MIO_EMM_DMA_RW) ? \"W\" : \"R\",\n\t\t mrq->data->blocks, (emm_dma & MIO_EMM_DMA_MULTI) ? 1 : 0);\n\treturn emm_dma;\n}\n\nstatic void cvm_mmc_dma_request(struct mmc_host *mmc,\n\t\t\t\tstruct mmc_request *mrq)\n{\n\tstruct cvm_mmc_slot *slot = mmc_priv(mmc);\n\tstruct cvm_mmc_host *host = slot->host;\n\tstruct mmc_data *data;\n\tu64 emm_dma, addr;\n\n\tif (!mrq->data || !mrq->data->sg || !mrq->data->sg_len ||\n\t    !mrq->stop || mrq->stop->opcode != MMC_STOP_TRANSMISSION) {\n\t\tdev_err(&mmc->card->dev, \"Error: %s no data\\n\", __func__);\n\t\tgoto error;\n\t}\n\n\tcvm_mmc_switch_to(slot);\n\n\tdata = mrq->data;\n\tpr_debug(\"DMA request  blocks: %d  block_size: %d  total_size: %d\\n\",\n\t\t data->blocks, data->blksz, data->blocks * data->blksz);\n\tif (data->timeout_ns)\n\t\tset_wdog(slot, data->timeout_ns);\n\n\tWARN_ON(host->current_req);\n\thost->current_req = mrq;\n\n\temm_dma = prepare_ext_dma(mmc, mrq);\n\taddr = prepare_dma(host, data);\n\tif (!addr) {\n\t\tdev_err(host->dev, \"prepare_dma failed\\n\");\n\t\tgoto error;\n\t}\n\n\thost->dma_active = true;\n\thost->int_enable(host, MIO_EMM_INT_CMD_ERR | MIO_EMM_INT_DMA_DONE |\n\t\t\t MIO_EMM_INT_DMA_ERR);\n\n\tif (host->dmar_fixup)\n\t\thost->dmar_fixup(host, mrq->cmd, data, addr);\n\n\t \n\tif (mmc_card_sd(mmc->card))\n\t\twriteq(0x00b00000ull, host->base + MIO_EMM_STS_MASK(host));\n\telse\n\t\twriteq(0xe4390080ull, host->base + MIO_EMM_STS_MASK(host));\n\twriteq(emm_dma, host->base + MIO_EMM_DMA(host));\n\treturn;\n\nerror:\n\tmrq->cmd->error = -EINVAL;\n\tif (mrq->done)\n\t\tmrq->done(mrq);\n\thost->release_bus(host);\n}\n\nstatic void do_read_request(struct cvm_mmc_host *host, struct mmc_request *mrq)\n{\n\tsg_miter_start(&host->smi, mrq->data->sg, mrq->data->sg_len,\n\t\t       SG_MITER_ATOMIC | SG_MITER_TO_SG);\n}\n\nstatic void do_write_request(struct cvm_mmc_host *host, struct mmc_request *mrq)\n{\n\tunsigned int data_len = mrq->data->blocks * mrq->data->blksz;\n\tstruct sg_mapping_iter *smi = &host->smi;\n\tunsigned int bytes_xfered;\n\tint shift = 56;\n\tu64 dat = 0;\n\n\t \n\tsg_miter_start(smi, mrq->data->sg, mrq->data->sg_len, SG_MITER_FROM_SG);\n\n\t \n\twriteq(0x10000ull, host->base + MIO_EMM_BUF_IDX(host));\n\n\tfor (bytes_xfered = 0; bytes_xfered < data_len;) {\n\t\tif (smi->consumed >= smi->length) {\n\t\t\tif (!sg_miter_next(smi))\n\t\t\t\tbreak;\n\t\t\tsmi->consumed = 0;\n\t\t}\n\n\t\twhile (smi->consumed < smi->length && shift >= 0) {\n\t\t\tdat |= (u64)((u8 *)smi->addr)[smi->consumed] << shift;\n\t\t\tbytes_xfered++;\n\t\t\tsmi->consumed++;\n\t\t\tshift -= 8;\n\t\t}\n\n\t\tif (shift < 0) {\n\t\t\twriteq(dat, host->base + MIO_EMM_BUF_DAT(host));\n\t\t\tshift = 56;\n\t\t\tdat = 0;\n\t\t}\n\t}\n\tsg_miter_stop(smi);\n}\n\nstatic void cvm_mmc_request(struct mmc_host *mmc, struct mmc_request *mrq)\n{\n\tstruct cvm_mmc_slot *slot = mmc_priv(mmc);\n\tstruct cvm_mmc_host *host = slot->host;\n\tstruct mmc_command *cmd = mrq->cmd;\n\tstruct cvm_mmc_cr_mods mods;\n\tu64 emm_cmd, rsp_sts;\n\tint retries = 100;\n\n\t \n\thost->acquire_bus(host);\n\n\tif (cmd->opcode == MMC_READ_MULTIPLE_BLOCK ||\n\t    cmd->opcode == MMC_WRITE_MULTIPLE_BLOCK)\n\t\treturn cvm_mmc_dma_request(mmc, mrq);\n\n\tcvm_mmc_switch_to(slot);\n\n\tmods = cvm_mmc_get_cr_mods(cmd);\n\n\tWARN_ON(host->current_req);\n\thost->current_req = mrq;\n\n\tif (cmd->data) {\n\t\tif (cmd->data->flags & MMC_DATA_READ)\n\t\t\tdo_read_request(host, mrq);\n\t\telse\n\t\t\tdo_write_request(host, mrq);\n\n\t\tif (cmd->data->timeout_ns)\n\t\t\tset_wdog(slot, cmd->data->timeout_ns);\n\t} else\n\t\tset_wdog(slot, 0);\n\n\thost->dma_active = false;\n\thost->int_enable(host, MIO_EMM_INT_CMD_DONE | MIO_EMM_INT_CMD_ERR);\n\n\temm_cmd = FIELD_PREP(MIO_EMM_CMD_VAL, 1) |\n\t\t  FIELD_PREP(MIO_EMM_CMD_CTYPE_XOR, mods.ctype_xor) |\n\t\t  FIELD_PREP(MIO_EMM_CMD_RTYPE_XOR, mods.rtype_xor) |\n\t\t  FIELD_PREP(MIO_EMM_CMD_IDX, cmd->opcode) |\n\t\t  FIELD_PREP(MIO_EMM_CMD_ARG, cmd->arg);\n\tset_bus_id(&emm_cmd, slot->bus_id);\n\tif (cmd->data && mmc_cmd_type(cmd) == MMC_CMD_ADTC)\n\t\temm_cmd |= FIELD_PREP(MIO_EMM_CMD_OFFSET,\n\t\t\t\t64 - ((cmd->data->blocks * cmd->data->blksz) / 8));\n\n\twriteq(0, host->base + MIO_EMM_STS_MASK(host));\n\nretry:\n\trsp_sts = readq(host->base + MIO_EMM_RSP_STS(host));\n\tif (rsp_sts & MIO_EMM_RSP_STS_DMA_VAL ||\n\t    rsp_sts & MIO_EMM_RSP_STS_CMD_VAL ||\n\t    rsp_sts & MIO_EMM_RSP_STS_SWITCH_VAL ||\n\t    rsp_sts & MIO_EMM_RSP_STS_DMA_PEND) {\n\t\tudelay(10);\n\t\tif (--retries)\n\t\t\tgoto retry;\n\t}\n\tif (!retries)\n\t\tdev_err(host->dev, \"Bad status: %llx before command write\\n\", rsp_sts);\n\twriteq(emm_cmd, host->base + MIO_EMM_CMD(host));\n}\n\nstatic void cvm_mmc_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)\n{\n\tstruct cvm_mmc_slot *slot = mmc_priv(mmc);\n\tstruct cvm_mmc_host *host = slot->host;\n\tint clk_period = 0, power_class = 10, bus_width = 0;\n\tu64 clock, emm_switch;\n\n\thost->acquire_bus(host);\n\tcvm_mmc_switch_to(slot);\n\n\t \n\tswitch (ios->power_mode) {\n\tcase MMC_POWER_ON:\n\t\tbreak;\n\n\tcase MMC_POWER_OFF:\n\t\tcvm_mmc_reset_bus(slot);\n\t\tif (host->global_pwr_gpiod)\n\t\t\thost->set_shared_power(host, 0);\n\t\telse if (!IS_ERR(mmc->supply.vmmc))\n\t\t\tmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);\n\t\tbreak;\n\n\tcase MMC_POWER_UP:\n\t\tif (host->global_pwr_gpiod)\n\t\t\thost->set_shared_power(host, 1);\n\t\telse if (!IS_ERR(mmc->supply.vmmc))\n\t\t\tmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, ios->vdd);\n\t\tbreak;\n\t}\n\n\t \n\tswitch (ios->bus_width) {\n\tcase MMC_BUS_WIDTH_8:\n\t\tbus_width = 2;\n\t\tbreak;\n\tcase MMC_BUS_WIDTH_4:\n\t\tbus_width = 1;\n\t\tbreak;\n\tcase MMC_BUS_WIDTH_1:\n\t\tbus_width = 0;\n\t\tbreak;\n\t}\n\n\t \n\tif (ios->bus_width && ios->timing == MMC_TIMING_MMC_DDR52)\n\t\tbus_width |= 4;\n\n\t \n\tclock = ios->clock;\n\tif (clock > 52000000)\n\t\tclock = 52000000;\n\tslot->clock = clock;\n\n\tif (clock)\n\t\tclk_period = (host->sys_freq + clock - 1) / (2 * clock);\n\n\temm_switch = FIELD_PREP(MIO_EMM_SWITCH_HS_TIMING,\n\t\t\t\t(ios->timing == MMC_TIMING_MMC_HS)) |\n\t\t     FIELD_PREP(MIO_EMM_SWITCH_BUS_WIDTH, bus_width) |\n\t\t     FIELD_PREP(MIO_EMM_SWITCH_POWER_CLASS, power_class) |\n\t\t     FIELD_PREP(MIO_EMM_SWITCH_CLK_HI, clk_period) |\n\t\t     FIELD_PREP(MIO_EMM_SWITCH_CLK_LO, clk_period);\n\tset_bus_id(&emm_switch, slot->bus_id);\n\n\tif (!switch_val_changed(slot, emm_switch))\n\t\tgoto out;\n\n\tset_wdog(slot, 0);\n\tdo_switch(host, emm_switch);\n\tslot->cached_switch = emm_switch;\nout:\n\thost->release_bus(host);\n}\n\nstatic const struct mmc_host_ops cvm_mmc_ops = {\n\t.request        = cvm_mmc_request,\n\t.set_ios        = cvm_mmc_set_ios,\n\t.get_ro\t\t= mmc_gpio_get_ro,\n\t.get_cd\t\t= mmc_gpio_get_cd,\n};\n\nstatic void cvm_mmc_set_clock(struct cvm_mmc_slot *slot, unsigned int clock)\n{\n\tstruct mmc_host *mmc = slot->mmc;\n\n\tclock = min(clock, mmc->f_max);\n\tclock = max(clock, mmc->f_min);\n\tslot->clock = clock;\n}\n\nstatic int cvm_mmc_init_lowlevel(struct cvm_mmc_slot *slot)\n{\n\tstruct cvm_mmc_host *host = slot->host;\n\tu64 emm_switch;\n\n\t \n\thost->emm_cfg |= (1ull << slot->bus_id);\n\twriteq(host->emm_cfg, slot->host->base + MIO_EMM_CFG(host));\n\tudelay(10);\n\n\t \n\tcvm_mmc_set_clock(slot, slot->mmc->f_min);\n\temm_switch = FIELD_PREP(MIO_EMM_SWITCH_POWER_CLASS, 10);\n\temm_switch |= FIELD_PREP(MIO_EMM_SWITCH_CLK_HI,\n\t\t\t\t (host->sys_freq / slot->clock) / 2);\n\temm_switch |= FIELD_PREP(MIO_EMM_SWITCH_CLK_LO,\n\t\t\t\t (host->sys_freq / slot->clock) / 2);\n\n\t \n\tset_bus_id(&emm_switch, slot->bus_id);\n\tdo_switch(host, emm_switch);\n\n\tslot->cached_switch = emm_switch;\n\n\t \n\tset_wdog(slot, 0);\n\twriteq(0xe4390080ull, host->base + MIO_EMM_STS_MASK(host));\n\twriteq(1, host->base + MIO_EMM_RCA(host));\n\treturn 0;\n}\n\nstatic int cvm_mmc_of_parse(struct device *dev, struct cvm_mmc_slot *slot)\n{\n\tu32 id, cmd_skew = 0, dat_skew = 0, bus_width = 0;\n\tstruct device_node *node = dev->of_node;\n\tstruct mmc_host *mmc = slot->mmc;\n\tu64 clock_period;\n\tint ret;\n\n\tret = of_property_read_u32(node, \"reg\", &id);\n\tif (ret) {\n\t\tdev_err(dev, \"Missing or invalid reg property on %pOF\\n\", node);\n\t\treturn ret;\n\t}\n\n\tif (id >= CAVIUM_MAX_MMC || slot->host->slot[id]) {\n\t\tdev_err(dev, \"Invalid reg property on %pOF\\n\", node);\n\t\treturn -EINVAL;\n\t}\n\n\tret = mmc_regulator_get_supply(mmc);\n\tif (ret)\n\t\treturn ret;\n\t \n\tif (IS_ERR(mmc->supply.vmmc))\n\t\tmmc->ocr_avail = MMC_VDD_32_33 | MMC_VDD_33_34;\n\n\t \n\tret = mmc_of_parse(mmc);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (!(mmc->caps & (MMC_CAP_8_BIT_DATA | MMC_CAP_4_BIT_DATA))) {\n\t\tof_property_read_u32(node, \"cavium,bus-max-width\", &bus_width);\n\t\tif (bus_width == 8)\n\t\t\tmmc->caps |= MMC_CAP_8_BIT_DATA | MMC_CAP_4_BIT_DATA;\n\t\telse if (bus_width == 4)\n\t\t\tmmc->caps |= MMC_CAP_4_BIT_DATA;\n\t}\n\n\t \n\tif (!mmc->f_max)\n\t\tof_property_read_u32(node, \"spi-max-frequency\", &mmc->f_max);\n\tif (!mmc->f_max || mmc->f_max > 52000000)\n\t\tmmc->f_max = 52000000;\n\tmmc->f_min = 400000;\n\n\t \n\tclock_period = 1000000000000ull / slot->host->sys_freq;\n\tof_property_read_u32(node, \"cavium,cmd-clk-skew\", &cmd_skew);\n\tof_property_read_u32(node, \"cavium,dat-clk-skew\", &dat_skew);\n\tslot->cmd_cnt = (cmd_skew + clock_period / 2) / clock_period;\n\tslot->dat_cnt = (dat_skew + clock_period / 2) / clock_period;\n\n\treturn id;\n}\n\nint cvm_mmc_of_slot_probe(struct device *dev, struct cvm_mmc_host *host)\n{\n\tstruct cvm_mmc_slot *slot;\n\tstruct mmc_host *mmc;\n\tint ret, id;\n\n\tmmc = mmc_alloc_host(sizeof(struct cvm_mmc_slot), dev);\n\tif (!mmc)\n\t\treturn -ENOMEM;\n\n\tslot = mmc_priv(mmc);\n\tslot->mmc = mmc;\n\tslot->host = host;\n\n\tret = cvm_mmc_of_parse(dev, slot);\n\tif (ret < 0)\n\t\tgoto error;\n\tid = ret;\n\n\t \n\tmmc->ops = &cvm_mmc_ops;\n\n\t \n\tmmc->caps |= MMC_CAP_MMC_HIGHSPEED | MMC_CAP_SD_HIGHSPEED |\n\t\t     MMC_CAP_CMD23 | MMC_CAP_POWER_OFF_CARD | MMC_CAP_3_3V_DDR;\n\n\tif (host->use_sg)\n\t\tmmc->max_segs = 16;\n\telse\n\t\tmmc->max_segs = 1;\n\n\t \n\tmmc->max_seg_size = min_t(unsigned int, 8 * 1024 * 1024,\n\t\t\t\t  dma_get_max_seg_size(host->dev));\n\tmmc->max_req_size = mmc->max_seg_size;\n\t \n\tmmc->max_blk_size = 512;\n\t \n\tmmc->max_blk_count = 32767;\n\n\tslot->clock = mmc->f_min;\n\tslot->bus_id = id;\n\tslot->cached_rca = 1;\n\n\thost->acquire_bus(host);\n\thost->slot[id] = slot;\n\tcvm_mmc_switch_to(slot);\n\tcvm_mmc_init_lowlevel(slot);\n\thost->release_bus(host);\n\n\tret = mmc_add_host(mmc);\n\tif (ret) {\n\t\tdev_err(dev, \"mmc_add_host() returned %d\\n\", ret);\n\t\tslot->host->slot[id] = NULL;\n\t\tgoto error;\n\t}\n\treturn 0;\n\nerror:\n\tmmc_free_host(slot->mmc);\n\treturn ret;\n}\n\nint cvm_mmc_of_slot_remove(struct cvm_mmc_slot *slot)\n{\n\tmmc_remove_host(slot->mmc);\n\tslot->host->slot[slot->bus_id] = NULL;\n\tmmc_free_host(slot->mmc);\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}