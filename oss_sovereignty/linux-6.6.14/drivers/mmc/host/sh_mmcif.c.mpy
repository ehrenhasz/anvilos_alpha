{
  "module_name": "sh_mmcif.c",
  "hash_id": "b7e0dc768104eebe3d62a5abc39737e8ba1dc6a7980c9357f5af806f1ae896d9",
  "original_prompt": "Ingested from linux-6.6.14/drivers/mmc/host/sh_mmcif.c",
  "human_readable_source": "\n \n\n \n\n#include <linux/bitops.h>\n#include <linux/clk.h>\n#include <linux/completion.h>\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmaengine.h>\n#include <linux/mmc/card.h>\n#include <linux/mmc/core.h>\n#include <linux/mmc/host.h>\n#include <linux/mmc/mmc.h>\n#include <linux/mmc/sdio.h>\n#include <linux/mmc/slot-gpio.h>\n#include <linux/mod_devicetable.h>\n#include <linux/mutex.h>\n#include <linux/pagemap.h>\n#include <linux/platform_data/sh_mmcif.h>\n#include <linux/platform_device.h>\n#include <linux/pm_qos.h>\n#include <linux/pm_runtime.h>\n#include <linux/sh_dma.h>\n#include <linux/spinlock.h>\n#include <linux/module.h>\n\n#define DRIVER_NAME\t\"sh_mmcif\"\n\n \n#define CMD_MASK\t\t0x3f000000\n#define CMD_SET_RTYP_NO\t\t((0 << 23) | (0 << 22))\n#define CMD_SET_RTYP_6B\t\t((0 << 23) | (1 << 22))  \n#define CMD_SET_RTYP_17B\t((1 << 23) | (0 << 22))  \n#define CMD_SET_RBSY\t\t(1 << 21)  \n#define CMD_SET_CCSEN\t\t(1 << 20)\n#define CMD_SET_WDAT\t\t(1 << 19)  \n#define CMD_SET_DWEN\t\t(1 << 18)  \n#define CMD_SET_CMLTE\t\t(1 << 17)  \n#define CMD_SET_CMD12EN\t\t(1 << 16)  \n#define CMD_SET_RIDXC_INDEX\t((0 << 15) | (0 << 14))  \n#define CMD_SET_RIDXC_BITS\t((0 << 15) | (1 << 14))  \n#define CMD_SET_RIDXC_NO\t((1 << 15) | (0 << 14))  \n#define CMD_SET_CRC7C\t\t((0 << 13) | (0 << 12))  \n#define CMD_SET_CRC7C_BITS\t((0 << 13) | (1 << 12))  \n#define CMD_SET_CRC7C_INTERNAL\t((1 << 13) | (0 << 12))  \n#define CMD_SET_CRC16C\t\t(1 << 10)  \n#define CMD_SET_CRCSTE\t\t(1 << 8)  \n#define CMD_SET_TBIT\t\t(1 << 7)  \n#define CMD_SET_OPDM\t\t(1 << 6)  \n#define CMD_SET_CCSH\t\t(1 << 5)\n#define CMD_SET_DARS\t\t(1 << 2)  \n#define CMD_SET_DATW_1\t\t((0 << 1) | (0 << 0))  \n#define CMD_SET_DATW_4\t\t((0 << 1) | (1 << 0))  \n#define CMD_SET_DATW_8\t\t((1 << 1) | (0 << 0))  \n\n \n#define CMD_CTRL_BREAK\t\t(1 << 0)\n\n \n#define BLOCK_SIZE_MASK\t\t0x0000ffff\n\n \n#define INT_CCSDE\t\t(1 << 29)\n#define INT_CMD12DRE\t\t(1 << 26)\n#define INT_CMD12RBE\t\t(1 << 25)\n#define INT_CMD12CRE\t\t(1 << 24)\n#define INT_DTRANE\t\t(1 << 23)\n#define INT_BUFRE\t\t(1 << 22)\n#define INT_BUFWEN\t\t(1 << 21)\n#define INT_BUFREN\t\t(1 << 20)\n#define INT_CCSRCV\t\t(1 << 19)\n#define INT_RBSYE\t\t(1 << 17)\n#define INT_CRSPE\t\t(1 << 16)\n#define INT_CMDVIO\t\t(1 << 15)\n#define INT_BUFVIO\t\t(1 << 14)\n#define INT_WDATERR\t\t(1 << 11)\n#define INT_RDATERR\t\t(1 << 10)\n#define INT_RIDXERR\t\t(1 << 9)\n#define INT_RSPERR\t\t(1 << 8)\n#define INT_CCSTO\t\t(1 << 5)\n#define INT_CRCSTO\t\t(1 << 4)\n#define INT_WDATTO\t\t(1 << 3)\n#define INT_RDATTO\t\t(1 << 2)\n#define INT_RBSYTO\t\t(1 << 1)\n#define INT_RSPTO\t\t(1 << 0)\n#define INT_ERR_STS\t\t(INT_CMDVIO | INT_BUFVIO | INT_WDATERR |  \\\n\t\t\t\t INT_RDATERR | INT_RIDXERR | INT_RSPERR | \\\n\t\t\t\t INT_CCSTO | INT_CRCSTO | INT_WDATTO |\t  \\\n\t\t\t\t INT_RDATTO | INT_RBSYTO | INT_RSPTO)\n\n#define INT_ALL\t\t\t(INT_RBSYE | INT_CRSPE | INT_BUFREN |\t \\\n\t\t\t\t INT_BUFWEN | INT_CMD12DRE | INT_BUFRE | \\\n\t\t\t\t INT_DTRANE | INT_CMD12RBE | INT_CMD12CRE)\n\n#define INT_CCS\t\t\t(INT_CCSTO | INT_CCSRCV | INT_CCSDE)\n\n \n#define MASK_ALL\t\t0x00000000\n#define MASK_MCCSDE\t\t(1 << 29)\n#define MASK_MCMD12DRE\t\t(1 << 26)\n#define MASK_MCMD12RBE\t\t(1 << 25)\n#define MASK_MCMD12CRE\t\t(1 << 24)\n#define MASK_MDTRANE\t\t(1 << 23)\n#define MASK_MBUFRE\t\t(1 << 22)\n#define MASK_MBUFWEN\t\t(1 << 21)\n#define MASK_MBUFREN\t\t(1 << 20)\n#define MASK_MCCSRCV\t\t(1 << 19)\n#define MASK_MRBSYE\t\t(1 << 17)\n#define MASK_MCRSPE\t\t(1 << 16)\n#define MASK_MCMDVIO\t\t(1 << 15)\n#define MASK_MBUFVIO\t\t(1 << 14)\n#define MASK_MWDATERR\t\t(1 << 11)\n#define MASK_MRDATERR\t\t(1 << 10)\n#define MASK_MRIDXERR\t\t(1 << 9)\n#define MASK_MRSPERR\t\t(1 << 8)\n#define MASK_MCCSTO\t\t(1 << 5)\n#define MASK_MCRCSTO\t\t(1 << 4)\n#define MASK_MWDATTO\t\t(1 << 3)\n#define MASK_MRDATTO\t\t(1 << 2)\n#define MASK_MRBSYTO\t\t(1 << 1)\n#define MASK_MRSPTO\t\t(1 << 0)\n\n#define MASK_START_CMD\t\t(MASK_MCMDVIO | MASK_MBUFVIO | MASK_MWDATERR | \\\n\t\t\t\t MASK_MRDATERR | MASK_MRIDXERR | MASK_MRSPERR | \\\n\t\t\t\t MASK_MCRCSTO | MASK_MWDATTO | \\\n\t\t\t\t MASK_MRDATTO | MASK_MRBSYTO | MASK_MRSPTO)\n\n#define MASK_CLEAN\t\t(INT_ERR_STS | MASK_MRBSYE | MASK_MCRSPE |\t\\\n\t\t\t\t MASK_MBUFREN | MASK_MBUFWEN |\t\t\t\\\n\t\t\t\t MASK_MCMD12DRE | MASK_MBUFRE | MASK_MDTRANE |\t\\\n\t\t\t\t MASK_MCMD12RBE | MASK_MCMD12CRE)\n\n \n#define STS1_CMDSEQ\t\t(1 << 31)\n\n \n#define STS2_CRCSTE\t\t(1 << 31)\n#define STS2_CRC16E\t\t(1 << 30)\n#define STS2_AC12CRCE\t\t(1 << 29)\n#define STS2_RSPCRC7E\t\t(1 << 28)\n#define STS2_CRCSTEBE\t\t(1 << 27)\n#define STS2_RDATEBE\t\t(1 << 26)\n#define STS2_AC12REBE\t\t(1 << 25)\n#define STS2_RSPEBE\t\t(1 << 24)\n#define STS2_AC12IDXE\t\t(1 << 23)\n#define STS2_RSPIDXE\t\t(1 << 22)\n#define STS2_CCSTO\t\t(1 << 15)\n#define STS2_RDATTO\t\t(1 << 14)\n#define STS2_DATBSYTO\t\t(1 << 13)\n#define STS2_CRCSTTO\t\t(1 << 12)\n#define STS2_AC12BSYTO\t\t(1 << 11)\n#define STS2_RSPBSYTO\t\t(1 << 10)\n#define STS2_AC12RSPTO\t\t(1 << 9)\n#define STS2_RSPTO\t\t(1 << 8)\n#define STS2_CRC_ERR\t\t(STS2_CRCSTE | STS2_CRC16E |\t\t\\\n\t\t\t\t STS2_AC12CRCE | STS2_RSPCRC7E | STS2_CRCSTEBE)\n#define STS2_TIMEOUT_ERR\t(STS2_CCSTO | STS2_RDATTO |\t\t\\\n\t\t\t\t STS2_DATBSYTO | STS2_CRCSTTO |\t\t\\\n\t\t\t\t STS2_AC12BSYTO | STS2_RSPBSYTO |\t\\\n\t\t\t\t STS2_AC12RSPTO | STS2_RSPTO)\n\n#define CLKDEV_EMMC_DATA\t52000000  \n#define CLKDEV_MMC_DATA\t\t20000000  \n#define CLKDEV_INIT\t\t400000    \n\nenum sh_mmcif_state {\n\tSTATE_IDLE,\n\tSTATE_REQUEST,\n\tSTATE_IOS,\n\tSTATE_TIMEOUT,\n};\n\nenum sh_mmcif_wait_for {\n\tMMCIF_WAIT_FOR_REQUEST,\n\tMMCIF_WAIT_FOR_CMD,\n\tMMCIF_WAIT_FOR_MREAD,\n\tMMCIF_WAIT_FOR_MWRITE,\n\tMMCIF_WAIT_FOR_READ,\n\tMMCIF_WAIT_FOR_WRITE,\n\tMMCIF_WAIT_FOR_READ_END,\n\tMMCIF_WAIT_FOR_WRITE_END,\n\tMMCIF_WAIT_FOR_STOP,\n};\n\n \nstruct sh_mmcif_host {\n\tstruct mmc_host *mmc;\n\tstruct mmc_request *mrq;\n\tstruct platform_device *pd;\n\tstruct clk *clk;\n\tint bus_width;\n\tunsigned char timing;\n\tbool sd_error;\n\tbool dying;\n\tlong timeout;\n\tvoid __iomem *addr;\n\tu32 *pio_ptr;\n\tspinlock_t lock;\t\t \n\tenum sh_mmcif_state state;\n\tenum sh_mmcif_wait_for wait_for;\n\tstruct delayed_work timeout_work;\n\tsize_t blocksize;\n\tint sg_idx;\n\tint sg_blkidx;\n\tbool power;\n\tbool ccs_enable;\t\t \n\tbool clk_ctrl2_enable;\n\tstruct mutex thread_lock;\n\tu32 clkdiv_map;          \n\n\t \n\tstruct dma_chan\t\t*chan_rx;\n\tstruct dma_chan\t\t*chan_tx;\n\tstruct completion\tdma_complete;\n\tbool\t\t\tdma_active;\n};\n\nstatic const struct of_device_id sh_mmcif_of_match[] = {\n\t{ .compatible = \"renesas,sh-mmcif\" },\n\t{ }\n};\nMODULE_DEVICE_TABLE(of, sh_mmcif_of_match);\n\n#define sh_mmcif_host_to_dev(host) (&host->pd->dev)\n\nstatic inline void sh_mmcif_bitset(struct sh_mmcif_host *host,\n\t\t\t\t\tunsigned int reg, u32 val)\n{\n\twritel(val | readl(host->addr + reg), host->addr + reg);\n}\n\nstatic inline void sh_mmcif_bitclr(struct sh_mmcif_host *host,\n\t\t\t\t\tunsigned int reg, u32 val)\n{\n\twritel(~val & readl(host->addr + reg), host->addr + reg);\n}\n\nstatic void sh_mmcif_dma_complete(void *arg)\n{\n\tstruct sh_mmcif_host *host = arg;\n\tstruct mmc_request *mrq = host->mrq;\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\n\tdev_dbg(dev, \"Command completed\\n\");\n\n\tif (WARN(!mrq || !mrq->data, \"%s: NULL data in DMA completion!\\n\",\n\t\t dev_name(dev)))\n\t\treturn;\n\n\tcomplete(&host->dma_complete);\n}\n\nstatic void sh_mmcif_start_dma_rx(struct sh_mmcif_host *host)\n{\n\tstruct mmc_data *data = host->mrq->data;\n\tstruct scatterlist *sg = data->sg;\n\tstruct dma_async_tx_descriptor *desc = NULL;\n\tstruct dma_chan *chan = host->chan_rx;\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tdma_cookie_t cookie = -EINVAL;\n\tint ret;\n\n\tret = dma_map_sg(chan->device->dev, sg, data->sg_len,\n\t\t\t DMA_FROM_DEVICE);\n\tif (ret > 0) {\n\t\thost->dma_active = true;\n\t\tdesc = dmaengine_prep_slave_sg(chan, sg, ret,\n\t\t\tDMA_DEV_TO_MEM, DMA_PREP_INTERRUPT | DMA_CTRL_ACK);\n\t}\n\n\tif (desc) {\n\t\tdesc->callback = sh_mmcif_dma_complete;\n\t\tdesc->callback_param = host;\n\t\tcookie = dmaengine_submit(desc);\n\t\tsh_mmcif_bitset(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN);\n\t\tdma_async_issue_pending(chan);\n\t}\n\tdev_dbg(dev, \"%s(): mapped %d -> %d, cookie %d\\n\",\n\t\t__func__, data->sg_len, ret, cookie);\n\n\tif (!desc) {\n\t\t \n\t\tif (ret >= 0)\n\t\t\tret = -EIO;\n\t\thost->chan_rx = NULL;\n\t\thost->dma_active = false;\n\t\tdma_release_channel(chan);\n\t\t \n\t\tchan = host->chan_tx;\n\t\tif (chan) {\n\t\t\thost->chan_tx = NULL;\n\t\t\tdma_release_channel(chan);\n\t\t}\n\t\tdev_warn(dev,\n\t\t\t \"DMA failed: %d, falling back to PIO\\n\", ret);\n\t\tsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN | BUF_ACC_DMAWEN);\n\t}\n\n\tdev_dbg(dev, \"%s(): desc %p, cookie %d, sg[%d]\\n\", __func__,\n\t\tdesc, cookie, data->sg_len);\n}\n\nstatic void sh_mmcif_start_dma_tx(struct sh_mmcif_host *host)\n{\n\tstruct mmc_data *data = host->mrq->data;\n\tstruct scatterlist *sg = data->sg;\n\tstruct dma_async_tx_descriptor *desc = NULL;\n\tstruct dma_chan *chan = host->chan_tx;\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tdma_cookie_t cookie = -EINVAL;\n\tint ret;\n\n\tret = dma_map_sg(chan->device->dev, sg, data->sg_len,\n\t\t\t DMA_TO_DEVICE);\n\tif (ret > 0) {\n\t\thost->dma_active = true;\n\t\tdesc = dmaengine_prep_slave_sg(chan, sg, ret,\n\t\t\tDMA_MEM_TO_DEV, DMA_PREP_INTERRUPT | DMA_CTRL_ACK);\n\t}\n\n\tif (desc) {\n\t\tdesc->callback = sh_mmcif_dma_complete;\n\t\tdesc->callback_param = host;\n\t\tcookie = dmaengine_submit(desc);\n\t\tsh_mmcif_bitset(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAWEN);\n\t\tdma_async_issue_pending(chan);\n\t}\n\tdev_dbg(dev, \"%s(): mapped %d -> %d, cookie %d\\n\",\n\t\t__func__, data->sg_len, ret, cookie);\n\n\tif (!desc) {\n\t\t \n\t\tif (ret >= 0)\n\t\t\tret = -EIO;\n\t\thost->chan_tx = NULL;\n\t\thost->dma_active = false;\n\t\tdma_release_channel(chan);\n\t\t \n\t\tchan = host->chan_rx;\n\t\tif (chan) {\n\t\t\thost->chan_rx = NULL;\n\t\t\tdma_release_channel(chan);\n\t\t}\n\t\tdev_warn(dev,\n\t\t\t \"DMA failed: %d, falling back to PIO\\n\", ret);\n\t\tsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN | BUF_ACC_DMAWEN);\n\t}\n\n\tdev_dbg(dev, \"%s(): desc %p, cookie %d\\n\", __func__,\n\t\tdesc, cookie);\n}\n\nstatic struct dma_chan *\nsh_mmcif_request_dma_pdata(struct sh_mmcif_host *host, uintptr_t slave_id)\n{\n\tdma_cap_mask_t mask;\n\n\tdma_cap_zero(mask);\n\tdma_cap_set(DMA_SLAVE, mask);\n\tif (slave_id <= 0)\n\t\treturn NULL;\n\n\treturn dma_request_channel(mask, shdma_chan_filter, (void *)slave_id);\n}\n\nstatic int sh_mmcif_dma_slave_config(struct sh_mmcif_host *host,\n\t\t\t\t     struct dma_chan *chan,\n\t\t\t\t     enum dma_transfer_direction direction)\n{\n\tstruct resource *res;\n\tstruct dma_slave_config cfg = { 0, };\n\n\tres = platform_get_resource(host->pd, IORESOURCE_MEM, 0);\n\tif (!res)\n\t\treturn -EINVAL;\n\n\tcfg.direction = direction;\n\n\tif (direction == DMA_DEV_TO_MEM) {\n\t\tcfg.src_addr = res->start + MMCIF_CE_DATA;\n\t\tcfg.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\t} else {\n\t\tcfg.dst_addr = res->start + MMCIF_CE_DATA;\n\t\tcfg.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\t}\n\n\treturn dmaengine_slave_config(chan, &cfg);\n}\n\nstatic void sh_mmcif_request_dma(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\thost->dma_active = false;\n\n\t \n\tif (IS_ENABLED(CONFIG_SUPERH) && dev->platform_data) {\n\t\tstruct sh_mmcif_plat_data *pdata = dev->platform_data;\n\n\t\thost->chan_tx = sh_mmcif_request_dma_pdata(host,\n\t\t\t\t\t\t\tpdata->slave_id_tx);\n\t\thost->chan_rx = sh_mmcif_request_dma_pdata(host,\n\t\t\t\t\t\t\tpdata->slave_id_rx);\n\t} else {\n\t\thost->chan_tx = dma_request_chan(dev, \"tx\");\n\t\tif (IS_ERR(host->chan_tx))\n\t\t\thost->chan_tx = NULL;\n\t\thost->chan_rx = dma_request_chan(dev, \"rx\");\n\t\tif (IS_ERR(host->chan_rx))\n\t\t\thost->chan_rx = NULL;\n\t}\n\tdev_dbg(dev, \"%s: got channel TX %p RX %p\\n\", __func__, host->chan_tx,\n\t\thost->chan_rx);\n\n\tif (!host->chan_tx || !host->chan_rx ||\n\t    sh_mmcif_dma_slave_config(host, host->chan_tx, DMA_MEM_TO_DEV) ||\n\t    sh_mmcif_dma_slave_config(host, host->chan_rx, DMA_DEV_TO_MEM))\n\t\tgoto error;\n\n\treturn;\n\nerror:\n\tif (host->chan_tx)\n\t\tdma_release_channel(host->chan_tx);\n\tif (host->chan_rx)\n\t\tdma_release_channel(host->chan_rx);\n\thost->chan_tx = host->chan_rx = NULL;\n}\n\nstatic void sh_mmcif_release_dma(struct sh_mmcif_host *host)\n{\n\tsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN | BUF_ACC_DMAWEN);\n\t \n\tif (host->chan_tx) {\n\t\tstruct dma_chan *chan = host->chan_tx;\n\t\thost->chan_tx = NULL;\n\t\tdma_release_channel(chan);\n\t}\n\tif (host->chan_rx) {\n\t\tstruct dma_chan *chan = host->chan_rx;\n\t\thost->chan_rx = NULL;\n\t\tdma_release_channel(chan);\n\t}\n\n\thost->dma_active = false;\n}\n\nstatic void sh_mmcif_clock_control(struct sh_mmcif_host *host, unsigned int clk)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tstruct sh_mmcif_plat_data *p = dev->platform_data;\n\tbool sup_pclk = p ? p->sup_pclk : false;\n\tunsigned int current_clk = clk_get_rate(host->clk);\n\tunsigned int clkdiv;\n\n\tsh_mmcif_bitclr(host, MMCIF_CE_CLK_CTRL, CLK_ENABLE);\n\tsh_mmcif_bitclr(host, MMCIF_CE_CLK_CTRL, CLK_CLEAR);\n\n\tif (!clk)\n\t\treturn;\n\n\tif (host->clkdiv_map) {\n\t\tunsigned int freq, best_freq, myclk, div, diff_min, diff;\n\t\tint i;\n\n\t\tclkdiv = 0;\n\t\tdiff_min = ~0;\n\t\tbest_freq = 0;\n\t\tfor (i = 31; i >= 0; i--) {\n\t\t\tif (!((1 << i) & host->clkdiv_map))\n\t\t\t\tcontinue;\n\n\t\t\t \n\n\t\t\tdiv = 1 << (i + 1);\n\t\t\tfreq = clk_round_rate(host->clk, clk * div);\n\t\t\tmyclk = freq / div;\n\t\t\tdiff = (myclk > clk) ? myclk - clk : clk - myclk;\n\n\t\t\tif (diff <= diff_min) {\n\t\t\t\tbest_freq = freq;\n\t\t\t\tclkdiv = i;\n\t\t\t\tdiff_min = diff;\n\t\t\t}\n\t\t}\n\n\t\tdev_dbg(dev, \"clk %u/%u (%u, 0x%x)\\n\",\n\t\t\t(best_freq >> (clkdiv + 1)), clk, best_freq, clkdiv);\n\n\t\tclk_set_rate(host->clk, best_freq);\n\t\tclkdiv = clkdiv << 16;\n\t} else if (sup_pclk && clk == current_clk) {\n\t\tclkdiv = CLK_SUP_PCLK;\n\t} else {\n\t\tclkdiv = (fls(DIV_ROUND_UP(current_clk, clk) - 1) - 1) << 16;\n\t}\n\n\tsh_mmcif_bitset(host, MMCIF_CE_CLK_CTRL, CLK_CLEAR & clkdiv);\n\tsh_mmcif_bitset(host, MMCIF_CE_CLK_CTRL, CLK_ENABLE);\n}\n\nstatic void sh_mmcif_sync_reset(struct sh_mmcif_host *host)\n{\n\tu32 tmp;\n\n\ttmp = 0x010f0000 & sh_mmcif_readl(host->addr, MMCIF_CE_CLK_CTRL);\n\n\tsh_mmcif_writel(host->addr, MMCIF_CE_VERSION, SOFT_RST_ON);\n\tsh_mmcif_writel(host->addr, MMCIF_CE_VERSION, SOFT_RST_OFF);\n\tif (host->ccs_enable)\n\t\ttmp |= SCCSTO_29;\n\tif (host->clk_ctrl2_enable)\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_CLK_CTRL2, 0x0F0F0000);\n\tsh_mmcif_bitset(host, MMCIF_CE_CLK_CTRL, tmp |\n\t\tSRSPTO_256 | SRBSYTO_29 | SRWDTO_29);\n\t \n\tsh_mmcif_bitset(host, MMCIF_CE_BUF_ACC, BUF_ACC_ATYP);\n}\n\nstatic int sh_mmcif_error_manage(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tu32 state1, state2;\n\tint ret, timeout;\n\n\thost->sd_error = false;\n\n\tstate1 = sh_mmcif_readl(host->addr, MMCIF_CE_HOST_STS1);\n\tstate2 = sh_mmcif_readl(host->addr, MMCIF_CE_HOST_STS2);\n\tdev_dbg(dev, \"ERR HOST_STS1 = %08x\\n\", state1);\n\tdev_dbg(dev, \"ERR HOST_STS2 = %08x\\n\", state2);\n\n\tif (state1 & STS1_CMDSEQ) {\n\t\tsh_mmcif_bitset(host, MMCIF_CE_CMD_CTRL, CMD_CTRL_BREAK);\n\t\tsh_mmcif_bitset(host, MMCIF_CE_CMD_CTRL, ~CMD_CTRL_BREAK);\n\t\tfor (timeout = 10000; timeout; timeout--) {\n\t\t\tif (!(sh_mmcif_readl(host->addr, MMCIF_CE_HOST_STS1)\n\t\t\t      & STS1_CMDSEQ))\n\t\t\t\tbreak;\n\t\t\tmdelay(1);\n\t\t}\n\t\tif (!timeout) {\n\t\t\tdev_err(dev,\n\t\t\t\t\"Forced end of command sequence timeout err\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tsh_mmcif_sync_reset(host);\n\t\tdev_dbg(dev, \"Forced end of command sequence\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (state2 & STS2_CRC_ERR) {\n\t\tdev_err(dev, \" CRC error: state %u, wait %u\\n\",\n\t\t\thost->state, host->wait_for);\n\t\tret = -EIO;\n\t} else if (state2 & STS2_TIMEOUT_ERR) {\n\t\tdev_err(dev, \" Timeout: state %u, wait %u\\n\",\n\t\t\thost->state, host->wait_for);\n\t\tret = -ETIMEDOUT;\n\t} else {\n\t\tdev_dbg(dev, \" End/Index error: state %u, wait %u\\n\",\n\t\t\thost->state, host->wait_for);\n\t\tret = -EIO;\n\t}\n\treturn ret;\n}\n\nstatic bool sh_mmcif_next_block(struct sh_mmcif_host *host, u32 *p)\n{\n\tstruct mmc_data *data = host->mrq->data;\n\n\thost->sg_blkidx += host->blocksize;\n\n\t \n\tBUG_ON(host->sg_blkidx > data->sg->length);\n\n\tif (host->sg_blkidx == data->sg->length) {\n\t\thost->sg_blkidx = 0;\n\t\tif (++host->sg_idx < data->sg_len)\n\t\t\thost->pio_ptr = sg_virt(++data->sg);\n\t} else {\n\t\thost->pio_ptr = p;\n\t}\n\n\treturn host->sg_idx != data->sg_len;\n}\n\nstatic void sh_mmcif_single_read(struct sh_mmcif_host *host,\n\t\t\t\t struct mmc_request *mrq)\n{\n\thost->blocksize = (sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\n\t\t\t   BLOCK_SIZE_MASK) + 3;\n\n\thost->wait_for = MMCIF_WAIT_FOR_READ;\n\n\t \n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFREN);\n}\n\nstatic bool sh_mmcif_read_block(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tstruct mmc_data *data = host->mrq->data;\n\tu32 *p = sg_virt(data->sg);\n\tint i;\n\n\tif (host->sd_error) {\n\t\tdata->error = sh_mmcif_error_manage(host);\n\t\tdev_dbg(dev, \"%s(): %d\\n\", __func__, data->error);\n\t\treturn false;\n\t}\n\n\tfor (i = 0; i < host->blocksize / 4; i++)\n\t\t*p++ = sh_mmcif_readl(host->addr, MMCIF_CE_DATA);\n\n\t \n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFRE);\n\thost->wait_for = MMCIF_WAIT_FOR_READ_END;\n\n\treturn true;\n}\n\nstatic void sh_mmcif_multi_read(struct sh_mmcif_host *host,\n\t\t\t\tstruct mmc_request *mrq)\n{\n\tstruct mmc_data *data = mrq->data;\n\n\tif (!data->sg_len || !data->sg->length)\n\t\treturn;\n\n\thost->blocksize = sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\n\t\tBLOCK_SIZE_MASK;\n\n\thost->wait_for = MMCIF_WAIT_FOR_MREAD;\n\thost->sg_idx = 0;\n\thost->sg_blkidx = 0;\n\thost->pio_ptr = sg_virt(data->sg);\n\n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFREN);\n}\n\nstatic bool sh_mmcif_mread_block(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tstruct mmc_data *data = host->mrq->data;\n\tu32 *p = host->pio_ptr;\n\tint i;\n\n\tif (host->sd_error) {\n\t\tdata->error = sh_mmcif_error_manage(host);\n\t\tdev_dbg(dev, \"%s(): %d\\n\", __func__, data->error);\n\t\treturn false;\n\t}\n\n\tBUG_ON(!data->sg->length);\n\n\tfor (i = 0; i < host->blocksize / 4; i++)\n\t\t*p++ = sh_mmcif_readl(host->addr, MMCIF_CE_DATA);\n\n\tif (!sh_mmcif_next_block(host, p))\n\t\treturn false;\n\n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFREN);\n\n\treturn true;\n}\n\nstatic void sh_mmcif_single_write(struct sh_mmcif_host *host,\n\t\t\t\t\tstruct mmc_request *mrq)\n{\n\thost->blocksize = (sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\n\t\t\t   BLOCK_SIZE_MASK) + 3;\n\n\thost->wait_for = MMCIF_WAIT_FOR_WRITE;\n\n\t \n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFWEN);\n}\n\nstatic bool sh_mmcif_write_block(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tstruct mmc_data *data = host->mrq->data;\n\tu32 *p = sg_virt(data->sg);\n\tint i;\n\n\tif (host->sd_error) {\n\t\tdata->error = sh_mmcif_error_manage(host);\n\t\tdev_dbg(dev, \"%s(): %d\\n\", __func__, data->error);\n\t\treturn false;\n\t}\n\n\tfor (i = 0; i < host->blocksize / 4; i++)\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_DATA, *p++);\n\n\t \n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MDTRANE);\n\thost->wait_for = MMCIF_WAIT_FOR_WRITE_END;\n\n\treturn true;\n}\n\nstatic void sh_mmcif_multi_write(struct sh_mmcif_host *host,\n\t\t\t\tstruct mmc_request *mrq)\n{\n\tstruct mmc_data *data = mrq->data;\n\n\tif (!data->sg_len || !data->sg->length)\n\t\treturn;\n\n\thost->blocksize = sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\n\t\tBLOCK_SIZE_MASK;\n\n\thost->wait_for = MMCIF_WAIT_FOR_MWRITE;\n\thost->sg_idx = 0;\n\thost->sg_blkidx = 0;\n\thost->pio_ptr = sg_virt(data->sg);\n\n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFWEN);\n}\n\nstatic bool sh_mmcif_mwrite_block(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tstruct mmc_data *data = host->mrq->data;\n\tu32 *p = host->pio_ptr;\n\tint i;\n\n\tif (host->sd_error) {\n\t\tdata->error = sh_mmcif_error_manage(host);\n\t\tdev_dbg(dev, \"%s(): %d\\n\", __func__, data->error);\n\t\treturn false;\n\t}\n\n\tBUG_ON(!data->sg->length);\n\n\tfor (i = 0; i < host->blocksize / 4; i++)\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_DATA, *p++);\n\n\tif (!sh_mmcif_next_block(host, p))\n\t\treturn false;\n\n\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFWEN);\n\n\treturn true;\n}\n\nstatic void sh_mmcif_get_response(struct sh_mmcif_host *host,\n\t\t\t\t\t\tstruct mmc_command *cmd)\n{\n\tif (cmd->flags & MMC_RSP_136) {\n\t\tcmd->resp[0] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP3);\n\t\tcmd->resp[1] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP2);\n\t\tcmd->resp[2] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP1);\n\t\tcmd->resp[3] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP0);\n\t} else\n\t\tcmd->resp[0] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP0);\n}\n\nstatic void sh_mmcif_get_cmd12response(struct sh_mmcif_host *host,\n\t\t\t\t\t\tstruct mmc_command *cmd)\n{\n\tcmd->resp[0] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP_CMD12);\n}\n\nstatic u32 sh_mmcif_set_cmd(struct sh_mmcif_host *host,\n\t\t\t    struct mmc_request *mrq)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tstruct mmc_data *data = mrq->data;\n\tstruct mmc_command *cmd = mrq->cmd;\n\tu32 opc = cmd->opcode;\n\tu32 tmp = 0;\n\n\t \n\tswitch (mmc_resp_type(cmd)) {\n\tcase MMC_RSP_NONE:\n\t\ttmp |= CMD_SET_RTYP_NO;\n\t\tbreak;\n\tcase MMC_RSP_R1:\n\tcase MMC_RSP_R3:\n\t\ttmp |= CMD_SET_RTYP_6B;\n\t\tbreak;\n\tcase MMC_RSP_R1B:\n\t\ttmp |= CMD_SET_RBSY | CMD_SET_RTYP_6B;\n\t\tbreak;\n\tcase MMC_RSP_R2:\n\t\ttmp |= CMD_SET_RTYP_17B;\n\t\tbreak;\n\tdefault:\n\t\tdev_err(dev, \"Unsupported response type.\\n\");\n\t\tbreak;\n\t}\n\n\t \n\tif (data) {\n\t\ttmp |= CMD_SET_WDAT;\n\t\tswitch (host->bus_width) {\n\t\tcase MMC_BUS_WIDTH_1:\n\t\t\ttmp |= CMD_SET_DATW_1;\n\t\t\tbreak;\n\t\tcase MMC_BUS_WIDTH_4:\n\t\t\ttmp |= CMD_SET_DATW_4;\n\t\t\tbreak;\n\t\tcase MMC_BUS_WIDTH_8:\n\t\t\ttmp |= CMD_SET_DATW_8;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdev_err(dev, \"Unsupported bus width.\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tswitch (host->timing) {\n\t\tcase MMC_TIMING_MMC_DDR52:\n\t\t\t \n\t\t\ttmp |= CMD_SET_DARS;\n\t\t\tbreak;\n\t\t}\n\t}\n\t \n\tif (opc == MMC_WRITE_BLOCK || opc == MMC_WRITE_MULTIPLE_BLOCK)\n\t\ttmp |= CMD_SET_DWEN;\n\t \n\tif (opc == MMC_READ_MULTIPLE_BLOCK || opc == MMC_WRITE_MULTIPLE_BLOCK) {\n\t\ttmp |= CMD_SET_CMLTE | CMD_SET_CMD12EN;\n\t\tsh_mmcif_bitset(host, MMCIF_CE_BLOCK_SET,\n\t\t\t\tdata->blocks << 16);\n\t}\n\t \n\tif (opc == MMC_SEND_OP_COND || opc == MMC_ALL_SEND_CID ||\n\t    opc == MMC_SEND_CSD || opc == MMC_SEND_CID)\n\t\ttmp |= CMD_SET_RIDXC_BITS;\n\t \n\tif (opc == MMC_SEND_OP_COND)\n\t\ttmp |= CMD_SET_CRC7C_BITS;\n\t \n\tif (opc == MMC_ALL_SEND_CID ||\n\t\topc == MMC_SEND_CSD || opc == MMC_SEND_CID)\n\t\ttmp |= CMD_SET_CRC7C_INTERNAL;\n\n\treturn (opc << 24) | tmp;\n}\n\nstatic int sh_mmcif_data_trans(struct sh_mmcif_host *host,\n\t\t\t       struct mmc_request *mrq, u32 opc)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\n\tswitch (opc) {\n\tcase MMC_READ_MULTIPLE_BLOCK:\n\t\tsh_mmcif_multi_read(host, mrq);\n\t\treturn 0;\n\tcase MMC_WRITE_MULTIPLE_BLOCK:\n\t\tsh_mmcif_multi_write(host, mrq);\n\t\treturn 0;\n\tcase MMC_WRITE_BLOCK:\n\t\tsh_mmcif_single_write(host, mrq);\n\t\treturn 0;\n\tcase MMC_READ_SINGLE_BLOCK:\n\tcase MMC_SEND_EXT_CSD:\n\t\tsh_mmcif_single_read(host, mrq);\n\t\treturn 0;\n\tdefault:\n\t\tdev_err(dev, \"Unsupported CMD%d\\n\", opc);\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void sh_mmcif_start_cmd(struct sh_mmcif_host *host,\n\t\t\t       struct mmc_request *mrq)\n{\n\tstruct mmc_command *cmd = mrq->cmd;\n\tu32 opc;\n\tu32 mask = 0;\n\tunsigned long flags;\n\n\tif (cmd->flags & MMC_RSP_BUSY)\n\t\tmask = MASK_START_CMD | MASK_MRBSYE;\n\telse\n\t\tmask = MASK_START_CMD | MASK_MCRSPE;\n\n\tif (host->ccs_enable)\n\t\tmask |= MASK_MCCSTO;\n\n\tif (mrq->data) {\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_BLOCK_SET, 0);\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_BLOCK_SET,\n\t\t\t\tmrq->data->blksz);\n\t}\n\topc = sh_mmcif_set_cmd(host, mrq);\n\n\tif (host->ccs_enable)\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_INT, 0xD80430C0);\n\telse\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_INT, 0xD80430C0 | INT_CCS);\n\tsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, mask);\n\t \n\tsh_mmcif_writel(host->addr, MMCIF_CE_ARG, cmd->arg);\n\t \n\tspin_lock_irqsave(&host->lock, flags);\n\tsh_mmcif_writel(host->addr, MMCIF_CE_CMD_SET, opc);\n\n\thost->wait_for = MMCIF_WAIT_FOR_CMD;\n\tschedule_delayed_work(&host->timeout_work, host->timeout);\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\n\nstatic void sh_mmcif_stop_cmd(struct sh_mmcif_host *host,\n\t\t\t      struct mmc_request *mrq)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\n\tswitch (mrq->cmd->opcode) {\n\tcase MMC_READ_MULTIPLE_BLOCK:\n\t\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MCMD12DRE);\n\t\tbreak;\n\tcase MMC_WRITE_MULTIPLE_BLOCK:\n\t\tsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MCMD12RBE);\n\t\tbreak;\n\tdefault:\n\t\tdev_err(dev, \"unsupported stop cmd\\n\");\n\t\tmrq->stop->error = sh_mmcif_error_manage(host);\n\t\treturn;\n\t}\n\n\thost->wait_for = MMCIF_WAIT_FOR_STOP;\n}\n\nstatic void sh_mmcif_request(struct mmc_host *mmc, struct mmc_request *mrq)\n{\n\tstruct sh_mmcif_host *host = mmc_priv(mmc);\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\tif (host->state != STATE_IDLE) {\n\t\tdev_dbg(dev, \"%s() rejected, state %u\\n\",\n\t\t\t__func__, host->state);\n\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\tmrq->cmd->error = -EAGAIN;\n\t\tmmc_request_done(mmc, mrq);\n\t\treturn;\n\t}\n\n\thost->state = STATE_REQUEST;\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\thost->mrq = mrq;\n\n\tsh_mmcif_start_cmd(host, mrq);\n}\n\nstatic void sh_mmcif_clk_setup(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\n\tif (host->mmc->f_max) {\n\t\tunsigned int f_max, f_min = 0, f_min_old;\n\n\t\tf_max = host->mmc->f_max;\n\t\tfor (f_min_old = f_max; f_min_old > 2;) {\n\t\t\tf_min = clk_round_rate(host->clk, f_min_old / 2);\n\t\t\tif (f_min == f_min_old)\n\t\t\t\tbreak;\n\t\t\tf_min_old = f_min;\n\t\t}\n\n\t\t \n\t\thost->clkdiv_map = 0x3ff;\n\n\t\thost->mmc->f_max = f_max >> ffs(host->clkdiv_map);\n\t\thost->mmc->f_min = f_min >> fls(host->clkdiv_map);\n\t} else {\n\t\tunsigned int clk = clk_get_rate(host->clk);\n\n\t\thost->mmc->f_max = clk / 2;\n\t\thost->mmc->f_min = clk / 512;\n\t}\n\n\tdev_dbg(dev, \"clk max/min = %d/%d\\n\",\n\t\thost->mmc->f_max, host->mmc->f_min);\n}\n\nstatic void sh_mmcif_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)\n{\n\tstruct sh_mmcif_host *host = mmc_priv(mmc);\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\tif (host->state != STATE_IDLE) {\n\t\tdev_dbg(dev, \"%s() rejected, state %u\\n\",\n\t\t\t__func__, host->state);\n\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\treturn;\n\t}\n\n\thost->state = STATE_IOS;\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\tswitch (ios->power_mode) {\n\tcase MMC_POWER_UP:\n\t\tif (!IS_ERR(mmc->supply.vmmc))\n\t\t\tmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, ios->vdd);\n\t\tif (!host->power) {\n\t\t\tclk_prepare_enable(host->clk);\n\t\t\tpm_runtime_get_sync(dev);\n\t\t\tsh_mmcif_sync_reset(host);\n\t\t\tsh_mmcif_request_dma(host);\n\t\t\thost->power = true;\n\t\t}\n\t\tbreak;\n\tcase MMC_POWER_OFF:\n\t\tif (!IS_ERR(mmc->supply.vmmc))\n\t\t\tmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);\n\t\tif (host->power) {\n\t\t\tsh_mmcif_clock_control(host, 0);\n\t\t\tsh_mmcif_release_dma(host);\n\t\t\tpm_runtime_put(dev);\n\t\t\tclk_disable_unprepare(host->clk);\n\t\t\thost->power = false;\n\t\t}\n\t\tbreak;\n\tcase MMC_POWER_ON:\n\t\tsh_mmcif_clock_control(host, ios->clock);\n\t\tbreak;\n\t}\n\n\thost->timing = ios->timing;\n\thost->bus_width = ios->bus_width;\n\thost->state = STATE_IDLE;\n}\n\nstatic const struct mmc_host_ops sh_mmcif_ops = {\n\t.request\t= sh_mmcif_request,\n\t.set_ios\t= sh_mmcif_set_ios,\n\t.get_cd\t\t= mmc_gpio_get_cd,\n};\n\nstatic bool sh_mmcif_end_cmd(struct sh_mmcif_host *host)\n{\n\tstruct mmc_command *cmd = host->mrq->cmd;\n\tstruct mmc_data *data = host->mrq->data;\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tlong time;\n\n\tif (host->sd_error) {\n\t\tswitch (cmd->opcode) {\n\t\tcase MMC_ALL_SEND_CID:\n\t\tcase MMC_SELECT_CARD:\n\t\tcase MMC_APP_CMD:\n\t\t\tcmd->error = -ETIMEDOUT;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tcmd->error = sh_mmcif_error_manage(host);\n\t\t\tbreak;\n\t\t}\n\t\tdev_dbg(dev, \"CMD%d error %d\\n\",\n\t\t\tcmd->opcode, cmd->error);\n\t\thost->sd_error = false;\n\t\treturn false;\n\t}\n\tif (!(cmd->flags & MMC_RSP_PRESENT)) {\n\t\tcmd->error = 0;\n\t\treturn false;\n\t}\n\n\tsh_mmcif_get_response(host, cmd);\n\n\tif (!data)\n\t\treturn false;\n\n\t \n\tinit_completion(&host->dma_complete);\n\n\tif (data->flags & MMC_DATA_READ) {\n\t\tif (host->chan_rx)\n\t\t\tsh_mmcif_start_dma_rx(host);\n\t} else {\n\t\tif (host->chan_tx)\n\t\t\tsh_mmcif_start_dma_tx(host);\n\t}\n\n\tif (!host->dma_active) {\n\t\tdata->error = sh_mmcif_data_trans(host, host->mrq, cmd->opcode);\n\t\treturn !data->error;\n\t}\n\n\t \n\ttime = wait_for_completion_interruptible_timeout(&host->dma_complete,\n\t\t\t\t\t\t\t host->timeout);\n\n\tif (data->flags & MMC_DATA_READ)\n\t\tdma_unmap_sg(host->chan_rx->device->dev,\n\t\t\t     data->sg, data->sg_len,\n\t\t\t     DMA_FROM_DEVICE);\n\telse\n\t\tdma_unmap_sg(host->chan_tx->device->dev,\n\t\t\t     data->sg, data->sg_len,\n\t\t\t     DMA_TO_DEVICE);\n\n\tif (host->sd_error) {\n\t\tdev_err(host->mmc->parent,\n\t\t\t\"Error IRQ while waiting for DMA completion!\\n\");\n\t\t \n\t\tdata->error = sh_mmcif_error_manage(host);\n\t} else if (!time) {\n\t\tdev_err(host->mmc->parent, \"DMA timeout!\\n\");\n\t\tdata->error = -ETIMEDOUT;\n\t} else if (time < 0) {\n\t\tdev_err(host->mmc->parent,\n\t\t\t\"wait_for_completion_...() error %ld!\\n\", time);\n\t\tdata->error = time;\n\t}\n\tsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC,\n\t\t\tBUF_ACC_DMAREN | BUF_ACC_DMAWEN);\n\thost->dma_active = false;\n\n\tif (data->error) {\n\t\tdata->bytes_xfered = 0;\n\t\t \n\t\tif (data->flags & MMC_DATA_READ)\n\t\t\tdmaengine_terminate_sync(host->chan_rx);\n\t\telse\n\t\t\tdmaengine_terminate_sync(host->chan_tx);\n\t}\n\n\treturn false;\n}\n\nstatic irqreturn_t sh_mmcif_irqt(int irq, void *dev_id)\n{\n\tstruct sh_mmcif_host *host = dev_id;\n\tstruct mmc_request *mrq;\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tbool wait = false;\n\tunsigned long flags;\n\tint wait_work;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\twait_work = host->wait_for;\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\tcancel_delayed_work_sync(&host->timeout_work);\n\n\tmutex_lock(&host->thread_lock);\n\n\tmrq = host->mrq;\n\tif (!mrq) {\n\t\tdev_dbg(dev, \"IRQ thread state %u, wait %u: NULL mrq!\\n\",\n\t\t\thost->state, host->wait_for);\n\t\tmutex_unlock(&host->thread_lock);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\t \n\tswitch (wait_work) {\n\tcase MMCIF_WAIT_FOR_REQUEST:\n\t\t \n\t\tmutex_unlock(&host->thread_lock);\n\t\treturn IRQ_HANDLED;\n\tcase MMCIF_WAIT_FOR_CMD:\n\t\t \n\t\twait = sh_mmcif_end_cmd(host);\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_MREAD:\n\t\t \n\t\twait = sh_mmcif_mread_block(host);\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_READ:\n\t\t \n\t\twait = sh_mmcif_read_block(host);\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_MWRITE:\n\t\t \n\t\twait = sh_mmcif_mwrite_block(host);\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_WRITE:\n\t\t \n\t\twait = sh_mmcif_write_block(host);\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_STOP:\n\t\tif (host->sd_error) {\n\t\t\tmrq->stop->error = sh_mmcif_error_manage(host);\n\t\t\tdev_dbg(dev, \"%s(): %d\\n\", __func__, mrq->stop->error);\n\t\t\tbreak;\n\t\t}\n\t\tsh_mmcif_get_cmd12response(host, mrq->stop);\n\t\tmrq->stop->error = 0;\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_READ_END:\n\tcase MMCIF_WAIT_FOR_WRITE_END:\n\t\tif (host->sd_error) {\n\t\t\tmrq->data->error = sh_mmcif_error_manage(host);\n\t\t\tdev_dbg(dev, \"%s(): %d\\n\", __func__, mrq->data->error);\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tif (wait) {\n\t\tschedule_delayed_work(&host->timeout_work, host->timeout);\n\t\t \n\t\tmutex_unlock(&host->thread_lock);\n\t\treturn IRQ_HANDLED;\n\t}\n\n\tif (host->wait_for != MMCIF_WAIT_FOR_STOP) {\n\t\tstruct mmc_data *data = mrq->data;\n\t\tif (!mrq->cmd->error && data && !data->error)\n\t\t\tdata->bytes_xfered =\n\t\t\t\tdata->blocks * data->blksz;\n\n\t\tif (mrq->stop && !mrq->cmd->error && (!data || !data->error)) {\n\t\t\tsh_mmcif_stop_cmd(host, mrq);\n\t\t\tif (!mrq->stop->error) {\n\t\t\t\tschedule_delayed_work(&host->timeout_work, host->timeout);\n\t\t\t\tmutex_unlock(&host->thread_lock);\n\t\t\t\treturn IRQ_HANDLED;\n\t\t\t}\n\t\t}\n\t}\n\n\thost->wait_for = MMCIF_WAIT_FOR_REQUEST;\n\thost->state = STATE_IDLE;\n\thost->mrq = NULL;\n\tmmc_request_done(host->mmc, mrq);\n\n\tmutex_unlock(&host->thread_lock);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t sh_mmcif_intr(int irq, void *dev_id)\n{\n\tstruct sh_mmcif_host *host = dev_id;\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tu32 state, mask;\n\n\tstate = sh_mmcif_readl(host->addr, MMCIF_CE_INT);\n\tmask = sh_mmcif_readl(host->addr, MMCIF_CE_INT_MASK);\n\tif (host->ccs_enable)\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~(state & mask));\n\telse\n\t\tsh_mmcif_writel(host->addr, MMCIF_CE_INT, INT_CCS | ~(state & mask));\n\tsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, state & MASK_CLEAN);\n\n\tif (state & ~MASK_CLEAN)\n\t\tdev_dbg(dev, \"IRQ state = 0x%08x incompletely cleared\\n\",\n\t\t\tstate);\n\n\tif (state & INT_ERR_STS || state & ~INT_ALL) {\n\t\thost->sd_error = true;\n\t\tdev_dbg(dev, \"int err state = 0x%08x\\n\", state);\n\t}\n\tif (state & ~(INT_CMD12RBE | INT_CMD12CRE)) {\n\t\tif (!host->mrq)\n\t\t\tdev_dbg(dev, \"NULL IRQ state = 0x%08x\\n\", state);\n\t\tif (!host->dma_active)\n\t\t\treturn IRQ_WAKE_THREAD;\n\t\telse if (host->sd_error)\n\t\t\tsh_mmcif_dma_complete(host);\n\t} else {\n\t\tdev_dbg(dev, \"Unexpected IRQ 0x%x\\n\", state);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void sh_mmcif_timeout_work(struct work_struct *work)\n{\n\tstruct delayed_work *d = to_delayed_work(work);\n\tstruct sh_mmcif_host *host = container_of(d, struct sh_mmcif_host, timeout_work);\n\tstruct mmc_request *mrq = host->mrq;\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tunsigned long flags;\n\n\tif (host->dying)\n\t\t \n\t\treturn;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\tif (host->state == STATE_IDLE) {\n\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\treturn;\n\t}\n\n\tdev_err(dev, \"Timeout waiting for %u on CMD%u\\n\",\n\t\thost->wait_for, mrq->cmd->opcode);\n\n\thost->state = STATE_TIMEOUT;\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\t \n\tswitch (host->wait_for) {\n\tcase MMCIF_WAIT_FOR_CMD:\n\t\tmrq->cmd->error = sh_mmcif_error_manage(host);\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_STOP:\n\t\tmrq->stop->error = sh_mmcif_error_manage(host);\n\t\tbreak;\n\tcase MMCIF_WAIT_FOR_MREAD:\n\tcase MMCIF_WAIT_FOR_MWRITE:\n\tcase MMCIF_WAIT_FOR_READ:\n\tcase MMCIF_WAIT_FOR_WRITE:\n\tcase MMCIF_WAIT_FOR_READ_END:\n\tcase MMCIF_WAIT_FOR_WRITE_END:\n\t\tmrq->data->error = sh_mmcif_error_manage(host);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\thost->state = STATE_IDLE;\n\thost->wait_for = MMCIF_WAIT_FOR_REQUEST;\n\thost->mrq = NULL;\n\tmmc_request_done(host->mmc, mrq);\n}\n\nstatic void sh_mmcif_init_ocr(struct sh_mmcif_host *host)\n{\n\tstruct device *dev = sh_mmcif_host_to_dev(host);\n\tstruct sh_mmcif_plat_data *pd = dev->platform_data;\n\tstruct mmc_host *mmc = host->mmc;\n\n\tmmc_regulator_get_supply(mmc);\n\n\tif (!pd)\n\t\treturn;\n\n\tif (!mmc->ocr_avail)\n\t\tmmc->ocr_avail = pd->ocr;\n\telse if (pd->ocr)\n\t\tdev_warn(mmc_dev(mmc), \"Platform OCR mask is ignored\\n\");\n}\n\nstatic int sh_mmcif_probe(struct platform_device *pdev)\n{\n\tint ret = 0, irq[2];\n\tstruct mmc_host *mmc;\n\tstruct sh_mmcif_host *host;\n\tstruct device *dev = &pdev->dev;\n\tstruct sh_mmcif_plat_data *pd = dev->platform_data;\n\tvoid __iomem *reg;\n\tconst char *name;\n\n\tirq[0] = platform_get_irq(pdev, 0);\n\tirq[1] = platform_get_irq_optional(pdev, 1);\n\tif (irq[0] < 0)\n\t\treturn irq[0];\n\n\treg = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(reg))\n\t\treturn PTR_ERR(reg);\n\n\tmmc = mmc_alloc_host(sizeof(struct sh_mmcif_host), dev);\n\tif (!mmc)\n\t\treturn -ENOMEM;\n\n\tret = mmc_of_parse(mmc);\n\tif (ret < 0)\n\t\tgoto err_host;\n\n\thost\t\t= mmc_priv(mmc);\n\thost->mmc\t= mmc;\n\thost->addr\t= reg;\n\thost->timeout\t= msecs_to_jiffies(10000);\n\thost->ccs_enable = true;\n\thost->clk_ctrl2_enable = false;\n\n\thost->pd = pdev;\n\n\tspin_lock_init(&host->lock);\n\n\tmmc->ops = &sh_mmcif_ops;\n\tsh_mmcif_init_ocr(host);\n\n\tmmc->caps |= MMC_CAP_MMC_HIGHSPEED | MMC_CAP_WAIT_WHILE_BUSY;\n\tmmc->caps2 |= MMC_CAP2_NO_SD | MMC_CAP2_NO_SDIO;\n\tmmc->max_busy_timeout = 10000;\n\n\tif (pd && pd->caps)\n\t\tmmc->caps |= pd->caps;\n\tmmc->max_segs = 32;\n\tmmc->max_blk_size = 512;\n\tmmc->max_req_size = PAGE_SIZE * mmc->max_segs;\n\tmmc->max_blk_count = mmc->max_req_size / mmc->max_blk_size;\n\tmmc->max_seg_size = mmc->max_req_size;\n\n\tplatform_set_drvdata(pdev, host);\n\n\thost->clk = devm_clk_get(dev, NULL);\n\tif (IS_ERR(host->clk)) {\n\t\tret = PTR_ERR(host->clk);\n\t\tdev_err(dev, \"cannot get clock: %d\\n\", ret);\n\t\tgoto err_host;\n\t}\n\n\tret = clk_prepare_enable(host->clk);\n\tif (ret < 0)\n\t\tgoto err_host;\n\n\tsh_mmcif_clk_setup(host);\n\n\tpm_runtime_enable(dev);\n\thost->power = false;\n\n\tret = pm_runtime_get_sync(dev);\n\tif (ret < 0)\n\t\tgoto err_clk;\n\n\tINIT_DELAYED_WORK(&host->timeout_work, sh_mmcif_timeout_work);\n\n\tsh_mmcif_sync_reset(host);\n\tsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, MASK_ALL);\n\n\tname = irq[1] < 0 ? dev_name(dev) : \"sh_mmc:error\";\n\tret = devm_request_threaded_irq(dev, irq[0], sh_mmcif_intr,\n\t\t\t\t\tsh_mmcif_irqt, 0, name, host);\n\tif (ret) {\n\t\tdev_err(dev, \"request_irq error (%s)\\n\", name);\n\t\tgoto err_clk;\n\t}\n\tif (irq[1] >= 0) {\n\t\tret = devm_request_threaded_irq(dev, irq[1],\n\t\t\t\t\t\tsh_mmcif_intr, sh_mmcif_irqt,\n\t\t\t\t\t\t0, \"sh_mmc:int\", host);\n\t\tif (ret) {\n\t\t\tdev_err(dev, \"request_irq error (sh_mmc:int)\\n\");\n\t\t\tgoto err_clk;\n\t\t}\n\t}\n\n\tmutex_init(&host->thread_lock);\n\n\tret = mmc_add_host(mmc);\n\tif (ret < 0)\n\t\tgoto err_clk;\n\n\tdev_pm_qos_expose_latency_limit(dev, 100);\n\n\tdev_info(dev, \"Chip version 0x%04x, clock rate %luMHz\\n\",\n\t\t sh_mmcif_readl(host->addr, MMCIF_CE_VERSION) & 0xffff,\n\t\t clk_get_rate(host->clk) / 1000000UL);\n\n\tpm_runtime_put(dev);\n\tclk_disable_unprepare(host->clk);\n\treturn ret;\n\nerr_clk:\n\tclk_disable_unprepare(host->clk);\n\tpm_runtime_put_sync(dev);\n\tpm_runtime_disable(dev);\nerr_host:\n\tmmc_free_host(mmc);\n\treturn ret;\n}\n\nstatic void sh_mmcif_remove(struct platform_device *pdev)\n{\n\tstruct sh_mmcif_host *host = platform_get_drvdata(pdev);\n\n\thost->dying = true;\n\tclk_prepare_enable(host->clk);\n\tpm_runtime_get_sync(&pdev->dev);\n\n\tdev_pm_qos_hide_latency_limit(&pdev->dev);\n\n\tmmc_remove_host(host->mmc);\n\tsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, MASK_ALL);\n\n\t \n\tcancel_delayed_work_sync(&host->timeout_work);\n\n\tclk_disable_unprepare(host->clk);\n\tmmc_free_host(host->mmc);\n\tpm_runtime_put_sync(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int sh_mmcif_suspend(struct device *dev)\n{\n\tstruct sh_mmcif_host *host = dev_get_drvdata(dev);\n\n\tpm_runtime_get_sync(dev);\n\tsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, MASK_ALL);\n\tpm_runtime_put(dev);\n\n\treturn 0;\n}\n\nstatic int sh_mmcif_resume(struct device *dev)\n{\n\treturn 0;\n}\n#endif\n\nstatic const struct dev_pm_ops sh_mmcif_dev_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(sh_mmcif_suspend, sh_mmcif_resume)\n};\n\nstatic struct platform_driver sh_mmcif_driver = {\n\t.probe\t\t= sh_mmcif_probe,\n\t.remove_new\t= sh_mmcif_remove,\n\t.driver\t\t= {\n\t\t.name\t= DRIVER_NAME,\n\t\t.probe_type = PROBE_PREFER_ASYNCHRONOUS,\n\t\t.pm\t= &sh_mmcif_dev_pm_ops,\n\t\t.of_match_table = sh_mmcif_of_match,\n\t},\n};\n\nmodule_platform_driver(sh_mmcif_driver);\n\nMODULE_DESCRIPTION(\"SuperH on-chip MMC/eMMC interface driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS(\"platform:\" DRIVER_NAME);\nMODULE_AUTHOR(\"Yusuke Goda <yusuke.goda.sx@renesas.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}