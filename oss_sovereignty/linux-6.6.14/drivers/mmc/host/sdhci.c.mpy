{
  "module_name": "sdhci.c",
  "hash_id": "9a0fd95d54b96c6a99ca3bcd687b30fecab79de849cc60996ec3c1beb2705a85",
  "original_prompt": "Ingested from linux-6.6.14/drivers/mmc/host/sdhci.c",
  "human_readable_source": "\n \n\n#include <linux/bitfield.h>\n#include <linux/delay.h>\n#include <linux/dmaengine.h>\n#include <linux/ktime.h>\n#include <linux/highmem.h>\n#include <linux/io.h>\n#include <linux/module.h>\n#include <linux/dma-mapping.h>\n#include <linux/slab.h>\n#include <linux/scatterlist.h>\n#include <linux/sizes.h>\n#include <linux/regulator/consumer.h>\n#include <linux/pm_runtime.h>\n#include <linux/of.h>\n\n#include <linux/leds.h>\n\n#include <linux/mmc/mmc.h>\n#include <linux/mmc/host.h>\n#include <linux/mmc/card.h>\n#include <linux/mmc/sdio.h>\n#include <linux/mmc/slot-gpio.h>\n\n#include \"sdhci.h\"\n\n#define DRIVER_NAME \"sdhci\"\n\n#define DBG(f, x...) \\\n\tpr_debug(\"%s: \" DRIVER_NAME \": \" f, mmc_hostname(host->mmc), ## x)\n\n#define SDHCI_DUMP(f, x...) \\\n\tpr_err(\"%s: \" DRIVER_NAME \": \" f, mmc_hostname(host->mmc), ## x)\n\n#define MAX_TUNING_LOOP 40\n\nstatic unsigned int debug_quirks = 0;\nstatic unsigned int debug_quirks2;\n\nstatic void sdhci_enable_preset_value(struct sdhci_host *host, bool enable);\n\nstatic bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd);\n\nvoid sdhci_dumpregs(struct sdhci_host *host)\n{\n\tSDHCI_DUMP(\"============ SDHCI REGISTER DUMP ===========\\n\");\n\n\tSDHCI_DUMP(\"Sys addr:  0x%08x | Version:  0x%08x\\n\",\n\t\t   sdhci_readl(host, SDHCI_DMA_ADDRESS),\n\t\t   sdhci_readw(host, SDHCI_HOST_VERSION));\n\tSDHCI_DUMP(\"Blk size:  0x%08x | Blk cnt:  0x%08x\\n\",\n\t\t   sdhci_readw(host, SDHCI_BLOCK_SIZE),\n\t\t   sdhci_readw(host, SDHCI_BLOCK_COUNT));\n\tSDHCI_DUMP(\"Argument:  0x%08x | Trn mode: 0x%08x\\n\",\n\t\t   sdhci_readl(host, SDHCI_ARGUMENT),\n\t\t   sdhci_readw(host, SDHCI_TRANSFER_MODE));\n\tSDHCI_DUMP(\"Present:   0x%08x | Host ctl: 0x%08x\\n\",\n\t\t   sdhci_readl(host, SDHCI_PRESENT_STATE),\n\t\t   sdhci_readb(host, SDHCI_HOST_CONTROL));\n\tSDHCI_DUMP(\"Power:     0x%08x | Blk gap:  0x%08x\\n\",\n\t\t   sdhci_readb(host, SDHCI_POWER_CONTROL),\n\t\t   sdhci_readb(host, SDHCI_BLOCK_GAP_CONTROL));\n\tSDHCI_DUMP(\"Wake-up:   0x%08x | Clock:    0x%08x\\n\",\n\t\t   sdhci_readb(host, SDHCI_WAKE_UP_CONTROL),\n\t\t   sdhci_readw(host, SDHCI_CLOCK_CONTROL));\n\tSDHCI_DUMP(\"Timeout:   0x%08x | Int stat: 0x%08x\\n\",\n\t\t   sdhci_readb(host, SDHCI_TIMEOUT_CONTROL),\n\t\t   sdhci_readl(host, SDHCI_INT_STATUS));\n\tSDHCI_DUMP(\"Int enab:  0x%08x | Sig enab: 0x%08x\\n\",\n\t\t   sdhci_readl(host, SDHCI_INT_ENABLE),\n\t\t   sdhci_readl(host, SDHCI_SIGNAL_ENABLE));\n\tSDHCI_DUMP(\"ACmd stat: 0x%08x | Slot int: 0x%08x\\n\",\n\t\t   sdhci_readw(host, SDHCI_AUTO_CMD_STATUS),\n\t\t   sdhci_readw(host, SDHCI_SLOT_INT_STATUS));\n\tSDHCI_DUMP(\"Caps:      0x%08x | Caps_1:   0x%08x\\n\",\n\t\t   sdhci_readl(host, SDHCI_CAPABILITIES),\n\t\t   sdhci_readl(host, SDHCI_CAPABILITIES_1));\n\tSDHCI_DUMP(\"Cmd:       0x%08x | Max curr: 0x%08x\\n\",\n\t\t   sdhci_readw(host, SDHCI_COMMAND),\n\t\t   sdhci_readl(host, SDHCI_MAX_CURRENT));\n\tSDHCI_DUMP(\"Resp[0]:   0x%08x | Resp[1]:  0x%08x\\n\",\n\t\t   sdhci_readl(host, SDHCI_RESPONSE),\n\t\t   sdhci_readl(host, SDHCI_RESPONSE + 4));\n\tSDHCI_DUMP(\"Resp[2]:   0x%08x | Resp[3]:  0x%08x\\n\",\n\t\t   sdhci_readl(host, SDHCI_RESPONSE + 8),\n\t\t   sdhci_readl(host, SDHCI_RESPONSE + 12));\n\tSDHCI_DUMP(\"Host ctl2: 0x%08x\\n\",\n\t\t   sdhci_readw(host, SDHCI_HOST_CONTROL2));\n\n\tif (host->flags & SDHCI_USE_ADMA) {\n\t\tif (host->flags & SDHCI_USE_64_BIT_DMA) {\n\t\t\tSDHCI_DUMP(\"ADMA Err:  0x%08x | ADMA Ptr: 0x%08x%08x\\n\",\n\t\t\t\t   sdhci_readl(host, SDHCI_ADMA_ERROR),\n\t\t\t\t   sdhci_readl(host, SDHCI_ADMA_ADDRESS_HI),\n\t\t\t\t   sdhci_readl(host, SDHCI_ADMA_ADDRESS));\n\t\t} else {\n\t\t\tSDHCI_DUMP(\"ADMA Err:  0x%08x | ADMA Ptr: 0x%08x\\n\",\n\t\t\t\t   sdhci_readl(host, SDHCI_ADMA_ERROR),\n\t\t\t\t   sdhci_readl(host, SDHCI_ADMA_ADDRESS));\n\t\t}\n\t}\n\n\tif (host->ops->dump_vendor_regs)\n\t\thost->ops->dump_vendor_regs(host);\n\n\tSDHCI_DUMP(\"============================================\\n\");\n}\nEXPORT_SYMBOL_GPL(sdhci_dumpregs);\n\n \n\nstatic void sdhci_do_enable_v4_mode(struct sdhci_host *host)\n{\n\tu16 ctrl2;\n\n\tctrl2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\tif (ctrl2 & SDHCI_CTRL_V4_MODE)\n\t\treturn;\n\n\tctrl2 |= SDHCI_CTRL_V4_MODE;\n\tsdhci_writew(host, ctrl2, SDHCI_HOST_CONTROL2);\n}\n\n \nvoid sdhci_enable_v4_mode(struct sdhci_host *host)\n{\n\thost->v4_mode = true;\n\tsdhci_do_enable_v4_mode(host);\n}\nEXPORT_SYMBOL_GPL(sdhci_enable_v4_mode);\n\nstatic inline bool sdhci_data_line_cmd(struct mmc_command *cmd)\n{\n\treturn cmd->data || cmd->flags & MMC_RSP_BUSY;\n}\n\nstatic void sdhci_set_card_detection(struct sdhci_host *host, bool enable)\n{\n\tu32 present;\n\n\tif ((host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) ||\n\t    !mmc_card_is_removable(host->mmc) || mmc_can_gpio_cd(host->mmc))\n\t\treturn;\n\n\tif (enable) {\n\t\tpresent = sdhci_readl(host, SDHCI_PRESENT_STATE) &\n\t\t\t\t      SDHCI_CARD_PRESENT;\n\n\t\thost->ier |= present ? SDHCI_INT_CARD_REMOVE :\n\t\t\t\t       SDHCI_INT_CARD_INSERT;\n\t} else {\n\t\thost->ier &= ~(SDHCI_INT_CARD_REMOVE | SDHCI_INT_CARD_INSERT);\n\t}\n\n\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n}\n\nstatic void sdhci_enable_card_detection(struct sdhci_host *host)\n{\n\tsdhci_set_card_detection(host, true);\n}\n\nstatic void sdhci_disable_card_detection(struct sdhci_host *host)\n{\n\tsdhci_set_card_detection(host, false);\n}\n\nstatic void sdhci_runtime_pm_bus_on(struct sdhci_host *host)\n{\n\tif (host->bus_on)\n\t\treturn;\n\thost->bus_on = true;\n\tpm_runtime_get_noresume(mmc_dev(host->mmc));\n}\n\nstatic void sdhci_runtime_pm_bus_off(struct sdhci_host *host)\n{\n\tif (!host->bus_on)\n\t\treturn;\n\thost->bus_on = false;\n\tpm_runtime_put_noidle(mmc_dev(host->mmc));\n}\n\nvoid sdhci_reset(struct sdhci_host *host, u8 mask)\n{\n\tktime_t timeout;\n\n\tsdhci_writeb(host, mask, SDHCI_SOFTWARE_RESET);\n\n\tif (mask & SDHCI_RESET_ALL) {\n\t\thost->clock = 0;\n\t\t \n\t\tif (host->quirks2 & SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON)\n\t\t\tsdhci_runtime_pm_bus_off(host);\n\t}\n\n\t \n\ttimeout = ktime_add_ms(ktime_get(), 100);\n\n\t \n\twhile (1) {\n\t\tbool timedout = ktime_after(ktime_get(), timeout);\n\n\t\tif (!(sdhci_readb(host, SDHCI_SOFTWARE_RESET) & mask))\n\t\t\tbreak;\n\t\tif (timedout) {\n\t\t\tpr_err(\"%s: Reset 0x%x never completed.\\n\",\n\t\t\t\tmmc_hostname(host->mmc), (int)mask);\n\t\t\tsdhci_err_stats_inc(host, CTRL_TIMEOUT);\n\t\t\tsdhci_dumpregs(host);\n\t\t\treturn;\n\t\t}\n\t\tudelay(10);\n\t}\n}\nEXPORT_SYMBOL_GPL(sdhci_reset);\n\nstatic bool sdhci_do_reset(struct sdhci_host *host, u8 mask)\n{\n\tif (host->quirks & SDHCI_QUIRK_NO_CARD_NO_RESET) {\n\t\tstruct mmc_host *mmc = host->mmc;\n\n\t\tif (!mmc->ops->get_cd(mmc))\n\t\t\treturn false;\n\t}\n\n\thost->ops->reset(host, mask);\n\n\treturn true;\n}\n\nstatic void sdhci_reset_for_all(struct sdhci_host *host)\n{\n\tif (sdhci_do_reset(host, SDHCI_RESET_ALL)) {\n\t\tif (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {\n\t\t\tif (host->ops->enable_dma)\n\t\t\t\thost->ops->enable_dma(host);\n\t\t}\n\t\t \n\t\thost->preset_enabled = false;\n\t}\n}\n\nenum sdhci_reset_reason {\n\tSDHCI_RESET_FOR_INIT,\n\tSDHCI_RESET_FOR_REQUEST_ERROR,\n\tSDHCI_RESET_FOR_REQUEST_ERROR_DATA_ONLY,\n\tSDHCI_RESET_FOR_TUNING_ABORT,\n\tSDHCI_RESET_FOR_CARD_REMOVED,\n\tSDHCI_RESET_FOR_CQE_RECOVERY,\n};\n\nstatic void sdhci_reset_for_reason(struct sdhci_host *host, enum sdhci_reset_reason reason)\n{\n\tif (host->quirks2 & SDHCI_QUIRK2_ISSUE_CMD_DAT_RESET_TOGETHER) {\n\t\tsdhci_do_reset(host, SDHCI_RESET_CMD | SDHCI_RESET_DATA);\n\t\treturn;\n\t}\n\n\tswitch (reason) {\n\tcase SDHCI_RESET_FOR_INIT:\n\t\tsdhci_do_reset(host, SDHCI_RESET_CMD | SDHCI_RESET_DATA);\n\t\tbreak;\n\tcase SDHCI_RESET_FOR_REQUEST_ERROR:\n\tcase SDHCI_RESET_FOR_TUNING_ABORT:\n\tcase SDHCI_RESET_FOR_CARD_REMOVED:\n\tcase SDHCI_RESET_FOR_CQE_RECOVERY:\n\t\tsdhci_do_reset(host, SDHCI_RESET_CMD);\n\t\tsdhci_do_reset(host, SDHCI_RESET_DATA);\n\t\tbreak;\n\tcase SDHCI_RESET_FOR_REQUEST_ERROR_DATA_ONLY:\n\t\tsdhci_do_reset(host, SDHCI_RESET_DATA);\n\t\tbreak;\n\t}\n}\n\n#define sdhci_reset_for(h, r) sdhci_reset_for_reason((h), SDHCI_RESET_FOR_##r)\n\nstatic void sdhci_set_default_irqs(struct sdhci_host *host)\n{\n\thost->ier = SDHCI_INT_BUS_POWER | SDHCI_INT_DATA_END_BIT |\n\t\t    SDHCI_INT_DATA_CRC | SDHCI_INT_DATA_TIMEOUT |\n\t\t    SDHCI_INT_INDEX | SDHCI_INT_END_BIT | SDHCI_INT_CRC |\n\t\t    SDHCI_INT_TIMEOUT | SDHCI_INT_DATA_END |\n\t\t    SDHCI_INT_RESPONSE;\n\n\tif (host->tuning_mode == SDHCI_TUNING_MODE_2 ||\n\t    host->tuning_mode == SDHCI_TUNING_MODE_3)\n\t\thost->ier |= SDHCI_INT_RETUNE;\n\n\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n}\n\nstatic void sdhci_config_dma(struct sdhci_host *host)\n{\n\tu8 ctrl;\n\tu16 ctrl2;\n\n\tif (host->version < SDHCI_SPEC_200)\n\t\treturn;\n\n\tctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);\n\n\t \n\tctrl &= ~SDHCI_CTRL_DMA_MASK;\n\tif (!(host->flags & SDHCI_REQ_USE_DMA))\n\t\tgoto out;\n\n\t \n\tif (host->flags & SDHCI_USE_ADMA)\n\t\tctrl |= SDHCI_CTRL_ADMA32;\n\n\tif (host->flags & SDHCI_USE_64_BIT_DMA) {\n\t\t \n\t\tif (host->v4_mode) {\n\t\t\tctrl2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\t\t\tctrl2 |= SDHCI_CTRL_64BIT_ADDR;\n\t\t\tsdhci_writew(host, ctrl2, SDHCI_HOST_CONTROL2);\n\t\t} else if (host->flags & SDHCI_USE_ADMA) {\n\t\t\t \n\t\t\tctrl |= SDHCI_CTRL_ADMA64;\n\t\t}\n\t}\n\nout:\n\tsdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);\n}\n\nstatic void sdhci_init(struct sdhci_host *host, int soft)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\tunsigned long flags;\n\n\tif (soft)\n\t\tsdhci_reset_for(host, INIT);\n\telse\n\t\tsdhci_reset_for_all(host);\n\n\tif (host->v4_mode)\n\t\tsdhci_do_enable_v4_mode(host);\n\n\tspin_lock_irqsave(&host->lock, flags);\n\tsdhci_set_default_irqs(host);\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\thost->cqe_on = false;\n\n\tif (soft) {\n\t\t \n\t\thost->clock = 0;\n\t\thost->reinit_uhs = true;\n\t\tmmc->ops->set_ios(mmc, &mmc->ios);\n\t}\n}\n\nstatic void sdhci_reinit(struct sdhci_host *host)\n{\n\tu32 cd = host->ier & (SDHCI_INT_CARD_REMOVE | SDHCI_INT_CARD_INSERT);\n\n\tsdhci_init(host, 0);\n\tsdhci_enable_card_detection(host);\n\n\t \n\tif (cd != (host->ier & (SDHCI_INT_CARD_REMOVE | SDHCI_INT_CARD_INSERT)))\n\t\tmmc_detect_change(host->mmc, msecs_to_jiffies(200));\n}\n\nstatic void __sdhci_led_activate(struct sdhci_host *host)\n{\n\tu8 ctrl;\n\n\tif (host->quirks & SDHCI_QUIRK_NO_LED)\n\t\treturn;\n\n\tctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);\n\tctrl |= SDHCI_CTRL_LED;\n\tsdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);\n}\n\nstatic void __sdhci_led_deactivate(struct sdhci_host *host)\n{\n\tu8 ctrl;\n\n\tif (host->quirks & SDHCI_QUIRK_NO_LED)\n\t\treturn;\n\n\tctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);\n\tctrl &= ~SDHCI_CTRL_LED;\n\tsdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);\n}\n\n#if IS_REACHABLE(CONFIG_LEDS_CLASS)\nstatic void sdhci_led_control(struct led_classdev *led,\n\t\t\t      enum led_brightness brightness)\n{\n\tstruct sdhci_host *host = container_of(led, struct sdhci_host, led);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tif (host->runtime_suspended)\n\t\tgoto out;\n\n\tif (brightness == LED_OFF)\n\t\t__sdhci_led_deactivate(host);\n\telse\n\t\t__sdhci_led_activate(host);\nout:\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\n\nstatic int sdhci_led_register(struct sdhci_host *host)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\n\tif (host->quirks & SDHCI_QUIRK_NO_LED)\n\t\treturn 0;\n\n\tsnprintf(host->led_name, sizeof(host->led_name),\n\t\t \"%s::\", mmc_hostname(mmc));\n\n\thost->led.name = host->led_name;\n\thost->led.brightness = LED_OFF;\n\thost->led.default_trigger = mmc_hostname(mmc);\n\thost->led.brightness_set = sdhci_led_control;\n\n\treturn led_classdev_register(mmc_dev(mmc), &host->led);\n}\n\nstatic void sdhci_led_unregister(struct sdhci_host *host)\n{\n\tif (host->quirks & SDHCI_QUIRK_NO_LED)\n\t\treturn;\n\n\tled_classdev_unregister(&host->led);\n}\n\nstatic inline void sdhci_led_activate(struct sdhci_host *host)\n{\n}\n\nstatic inline void sdhci_led_deactivate(struct sdhci_host *host)\n{\n}\n\n#else\n\nstatic inline int sdhci_led_register(struct sdhci_host *host)\n{\n\treturn 0;\n}\n\nstatic inline void sdhci_led_unregister(struct sdhci_host *host)\n{\n}\n\nstatic inline void sdhci_led_activate(struct sdhci_host *host)\n{\n\t__sdhci_led_activate(host);\n}\n\nstatic inline void sdhci_led_deactivate(struct sdhci_host *host)\n{\n\t__sdhci_led_deactivate(host);\n}\n\n#endif\n\nstatic void sdhci_mod_timer(struct sdhci_host *host, struct mmc_request *mrq,\n\t\t\t    unsigned long timeout)\n{\n\tif (sdhci_data_line_cmd(mrq->cmd))\n\t\tmod_timer(&host->data_timer, timeout);\n\telse\n\t\tmod_timer(&host->timer, timeout);\n}\n\nstatic void sdhci_del_timer(struct sdhci_host *host, struct mmc_request *mrq)\n{\n\tif (sdhci_data_line_cmd(mrq->cmd))\n\t\tdel_timer(&host->data_timer);\n\telse\n\t\tdel_timer(&host->timer);\n}\n\nstatic inline bool sdhci_has_requests(struct sdhci_host *host)\n{\n\treturn host->cmd || host->data_cmd;\n}\n\n \n\nstatic void sdhci_read_block_pio(struct sdhci_host *host)\n{\n\tsize_t blksize, len, chunk;\n\tu32 scratch;\n\tu8 *buf;\n\n\tDBG(\"PIO reading\\n\");\n\n\tblksize = host->data->blksz;\n\tchunk = 0;\n\n\twhile (blksize) {\n\t\tBUG_ON(!sg_miter_next(&host->sg_miter));\n\n\t\tlen = min(host->sg_miter.length, blksize);\n\n\t\tblksize -= len;\n\t\thost->sg_miter.consumed = len;\n\n\t\tbuf = host->sg_miter.addr;\n\n\t\twhile (len) {\n\t\t\tif (chunk == 0) {\n\t\t\t\tscratch = sdhci_readl(host, SDHCI_BUFFER);\n\t\t\t\tchunk = 4;\n\t\t\t}\n\n\t\t\t*buf = scratch & 0xFF;\n\n\t\t\tbuf++;\n\t\t\tscratch >>= 8;\n\t\t\tchunk--;\n\t\t\tlen--;\n\t\t}\n\t}\n\n\tsg_miter_stop(&host->sg_miter);\n}\n\nstatic void sdhci_write_block_pio(struct sdhci_host *host)\n{\n\tsize_t blksize, len, chunk;\n\tu32 scratch;\n\tu8 *buf;\n\n\tDBG(\"PIO writing\\n\");\n\n\tblksize = host->data->blksz;\n\tchunk = 0;\n\tscratch = 0;\n\n\twhile (blksize) {\n\t\tBUG_ON(!sg_miter_next(&host->sg_miter));\n\n\t\tlen = min(host->sg_miter.length, blksize);\n\n\t\tblksize -= len;\n\t\thost->sg_miter.consumed = len;\n\n\t\tbuf = host->sg_miter.addr;\n\n\t\twhile (len) {\n\t\t\tscratch |= (u32)*buf << (chunk * 8);\n\n\t\t\tbuf++;\n\t\t\tchunk++;\n\t\t\tlen--;\n\n\t\t\tif ((chunk == 4) || ((len == 0) && (blksize == 0))) {\n\t\t\t\tsdhci_writel(host, scratch, SDHCI_BUFFER);\n\t\t\t\tchunk = 0;\n\t\t\t\tscratch = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tsg_miter_stop(&host->sg_miter);\n}\n\nstatic void sdhci_transfer_pio(struct sdhci_host *host)\n{\n\tu32 mask;\n\n\tif (host->blocks == 0)\n\t\treturn;\n\n\tif (host->data->flags & MMC_DATA_READ)\n\t\tmask = SDHCI_DATA_AVAILABLE;\n\telse\n\t\tmask = SDHCI_SPACE_AVAILABLE;\n\n\t \n\tif ((host->quirks & SDHCI_QUIRK_BROKEN_SMALL_PIO) &&\n\t\t(host->data->blocks == 1))\n\t\tmask = ~0;\n\n\twhile (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask) {\n\t\tif (host->quirks & SDHCI_QUIRK_PIO_NEEDS_DELAY)\n\t\t\tudelay(100);\n\n\t\tif (host->data->flags & MMC_DATA_READ)\n\t\t\tsdhci_read_block_pio(host);\n\t\telse\n\t\t\tsdhci_write_block_pio(host);\n\n\t\thost->blocks--;\n\t\tif (host->blocks == 0)\n\t\t\tbreak;\n\t}\n\n\tDBG(\"PIO transfer complete.\\n\");\n}\n\nstatic int sdhci_pre_dma_transfer(struct sdhci_host *host,\n\t\t\t\t  struct mmc_data *data, int cookie)\n{\n\tint sg_count;\n\n\t \n\tif (data->host_cookie == COOKIE_PRE_MAPPED)\n\t\treturn data->sg_count;\n\n\t \n\tif (host->bounce_buffer) {\n\t\tunsigned int length = data->blksz * data->blocks;\n\n\t\tif (length > host->bounce_buffer_size) {\n\t\t\tpr_err(\"%s: asked for transfer of %u bytes exceeds bounce buffer %u bytes\\n\",\n\t\t\t       mmc_hostname(host->mmc), length,\n\t\t\t       host->bounce_buffer_size);\n\t\t\treturn -EIO;\n\t\t}\n\t\tif (mmc_get_dma_dir(data) == DMA_TO_DEVICE) {\n\t\t\t \n\t\t\tif (host->ops->copy_to_bounce_buffer) {\n\t\t\t\thost->ops->copy_to_bounce_buffer(host,\n\t\t\t\t\t\t\t\t data, length);\n\t\t\t} else {\n\t\t\t\tsg_copy_to_buffer(data->sg, data->sg_len,\n\t\t\t\t\t\t  host->bounce_buffer, length);\n\t\t\t}\n\t\t}\n\t\t \n\t\tdma_sync_single_for_device(mmc_dev(host->mmc),\n\t\t\t\t\t   host->bounce_addr,\n\t\t\t\t\t   host->bounce_buffer_size,\n\t\t\t\t\t   mmc_get_dma_dir(data));\n\t\t \n\t\tsg_count = 1;\n\t} else {\n\t\t \n\t\tsg_count = dma_map_sg(mmc_dev(host->mmc),\n\t\t\t\t      data->sg, data->sg_len,\n\t\t\t\t      mmc_get_dma_dir(data));\n\t}\n\n\tif (sg_count == 0)\n\t\treturn -ENOSPC;\n\n\tdata->sg_count = sg_count;\n\tdata->host_cookie = cookie;\n\n\treturn sg_count;\n}\n\nstatic char *sdhci_kmap_atomic(struct scatterlist *sg)\n{\n\treturn kmap_local_page(sg_page(sg)) + sg->offset;\n}\n\nstatic void sdhci_kunmap_atomic(void *buffer)\n{\n\tkunmap_local(buffer);\n}\n\nvoid sdhci_adma_write_desc(struct sdhci_host *host, void **desc,\n\t\t\t   dma_addr_t addr, int len, unsigned int cmd)\n{\n\tstruct sdhci_adma2_64_desc *dma_desc = *desc;\n\n\t \n\tdma_desc->cmd = cpu_to_le16(cmd);\n\tdma_desc->len = cpu_to_le16(len);\n\tdma_desc->addr_lo = cpu_to_le32(lower_32_bits(addr));\n\n\tif (host->flags & SDHCI_USE_64_BIT_DMA)\n\t\tdma_desc->addr_hi = cpu_to_le32(upper_32_bits(addr));\n\n\t*desc += host->desc_sz;\n}\nEXPORT_SYMBOL_GPL(sdhci_adma_write_desc);\n\nstatic inline void __sdhci_adma_write_desc(struct sdhci_host *host,\n\t\t\t\t\t   void **desc, dma_addr_t addr,\n\t\t\t\t\t   int len, unsigned int cmd)\n{\n\tif (host->ops->adma_write_desc)\n\t\thost->ops->adma_write_desc(host, desc, addr, len, cmd);\n\telse\n\t\tsdhci_adma_write_desc(host, desc, addr, len, cmd);\n}\n\nstatic void sdhci_adma_mark_end(void *desc)\n{\n\tstruct sdhci_adma2_64_desc *dma_desc = desc;\n\n\t \n\tdma_desc->cmd |= cpu_to_le16(ADMA2_END);\n}\n\nstatic void sdhci_adma_table_pre(struct sdhci_host *host,\n\tstruct mmc_data *data, int sg_count)\n{\n\tstruct scatterlist *sg;\n\tdma_addr_t addr, align_addr;\n\tvoid *desc, *align;\n\tchar *buffer;\n\tint len, offset, i;\n\n\t \n\n\thost->sg_count = sg_count;\n\n\tdesc = host->adma_table;\n\talign = host->align_buffer;\n\n\talign_addr = host->align_addr;\n\n\tfor_each_sg(data->sg, sg, host->sg_count, i) {\n\t\taddr = sg_dma_address(sg);\n\t\tlen = sg_dma_len(sg);\n\n\t\t \n\t\toffset = (SDHCI_ADMA2_ALIGN - (addr & SDHCI_ADMA2_MASK)) &\n\t\t\t SDHCI_ADMA2_MASK;\n\t\tif (offset) {\n\t\t\tif (data->flags & MMC_DATA_WRITE) {\n\t\t\t\tbuffer = sdhci_kmap_atomic(sg);\n\t\t\t\tmemcpy(align, buffer, offset);\n\t\t\t\tsdhci_kunmap_atomic(buffer);\n\t\t\t}\n\n\t\t\t \n\t\t\t__sdhci_adma_write_desc(host, &desc, align_addr,\n\t\t\t\t\t\toffset, ADMA2_TRAN_VALID);\n\n\t\t\tBUG_ON(offset > 65536);\n\n\t\t\talign += SDHCI_ADMA2_ALIGN;\n\t\t\talign_addr += SDHCI_ADMA2_ALIGN;\n\n\t\t\taddr += offset;\n\t\t\tlen -= offset;\n\t\t}\n\n\t\t \n\t\twhile (len > host->max_adma) {\n\t\t\tint n = 32 * 1024;  \n\n\t\t\t__sdhci_adma_write_desc(host, &desc, addr, n, ADMA2_TRAN_VALID);\n\t\t\taddr += n;\n\t\t\tlen -= n;\n\t\t}\n\n\t\t \n\t\tif (len)\n\t\t\t__sdhci_adma_write_desc(host, &desc, addr, len,\n\t\t\t\t\t\tADMA2_TRAN_VALID);\n\n\t\t \n\t\tWARN_ON((desc - host->adma_table) >= host->adma_table_sz);\n\t}\n\n\tif (host->quirks & SDHCI_QUIRK_NO_ENDATTR_IN_NOPDESC) {\n\t\t \n\t\tif (desc != host->adma_table) {\n\t\t\tdesc -= host->desc_sz;\n\t\t\tsdhci_adma_mark_end(desc);\n\t\t}\n\t} else {\n\t\t \n\t\t__sdhci_adma_write_desc(host, &desc, 0, 0, ADMA2_NOP_END_VALID);\n\t}\n}\n\nstatic void sdhci_adma_table_post(struct sdhci_host *host,\n\tstruct mmc_data *data)\n{\n\tstruct scatterlist *sg;\n\tint i, size;\n\tvoid *align;\n\tchar *buffer;\n\n\tif (data->flags & MMC_DATA_READ) {\n\t\tbool has_unaligned = false;\n\n\t\t \n\t\tfor_each_sg(data->sg, sg, host->sg_count, i)\n\t\t\tif (sg_dma_address(sg) & SDHCI_ADMA2_MASK) {\n\t\t\t\thas_unaligned = true;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tif (has_unaligned) {\n\t\t\tdma_sync_sg_for_cpu(mmc_dev(host->mmc), data->sg,\n\t\t\t\t\t    data->sg_len, DMA_FROM_DEVICE);\n\n\t\t\talign = host->align_buffer;\n\n\t\t\tfor_each_sg(data->sg, sg, host->sg_count, i) {\n\t\t\t\tif (sg_dma_address(sg) & SDHCI_ADMA2_MASK) {\n\t\t\t\t\tsize = SDHCI_ADMA2_ALIGN -\n\t\t\t\t\t       (sg_dma_address(sg) & SDHCI_ADMA2_MASK);\n\n\t\t\t\t\tbuffer = sdhci_kmap_atomic(sg);\n\t\t\t\t\tmemcpy(buffer, align, size);\n\t\t\t\t\tsdhci_kunmap_atomic(buffer);\n\n\t\t\t\t\talign += SDHCI_ADMA2_ALIGN;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void sdhci_set_adma_addr(struct sdhci_host *host, dma_addr_t addr)\n{\n\tsdhci_writel(host, lower_32_bits(addr), SDHCI_ADMA_ADDRESS);\n\tif (host->flags & SDHCI_USE_64_BIT_DMA)\n\t\tsdhci_writel(host, upper_32_bits(addr), SDHCI_ADMA_ADDRESS_HI);\n}\n\nstatic dma_addr_t sdhci_sdma_address(struct sdhci_host *host)\n{\n\tif (host->bounce_buffer)\n\t\treturn host->bounce_addr;\n\telse\n\t\treturn sg_dma_address(host->data->sg);\n}\n\nstatic void sdhci_set_sdma_addr(struct sdhci_host *host, dma_addr_t addr)\n{\n\tif (host->v4_mode)\n\t\tsdhci_set_adma_addr(host, addr);\n\telse\n\t\tsdhci_writel(host, addr, SDHCI_DMA_ADDRESS);\n}\n\nstatic unsigned int sdhci_target_timeout(struct sdhci_host *host,\n\t\t\t\t\t struct mmc_command *cmd,\n\t\t\t\t\t struct mmc_data *data)\n{\n\tunsigned int target_timeout;\n\n\t \n\tif (!data) {\n\t\ttarget_timeout = cmd->busy_timeout * 1000;\n\t} else {\n\t\ttarget_timeout = DIV_ROUND_UP(data->timeout_ns, 1000);\n\t\tif (host->clock && data->timeout_clks) {\n\t\t\tunsigned long long val;\n\n\t\t\t \n\t\t\tval = 1000000ULL * data->timeout_clks;\n\t\t\tif (do_div(val, host->clock))\n\t\t\t\ttarget_timeout++;\n\t\t\ttarget_timeout += val;\n\t\t}\n\t}\n\n\treturn target_timeout;\n}\n\nstatic void sdhci_calc_sw_timeout(struct sdhci_host *host,\n\t\t\t\t  struct mmc_command *cmd)\n{\n\tstruct mmc_data *data = cmd->data;\n\tstruct mmc_host *mmc = host->mmc;\n\tstruct mmc_ios *ios = &mmc->ios;\n\tunsigned char bus_width = 1 << ios->bus_width;\n\tunsigned int blksz;\n\tunsigned int freq;\n\tu64 target_timeout;\n\tu64 transfer_time;\n\n\ttarget_timeout = sdhci_target_timeout(host, cmd, data);\n\ttarget_timeout *= NSEC_PER_USEC;\n\n\tif (data) {\n\t\tblksz = data->blksz;\n\t\tfreq = mmc->actual_clock ? : host->clock;\n\t\ttransfer_time = (u64)blksz * NSEC_PER_SEC * (8 / bus_width);\n\t\tdo_div(transfer_time, freq);\n\t\t \n\t\ttransfer_time = transfer_time * 2;\n\t\t \n\t\thost->data_timeout = data->blocks * target_timeout +\n\t\t\t\t     transfer_time;\n\t} else {\n\t\thost->data_timeout = target_timeout;\n\t}\n\n\tif (host->data_timeout)\n\t\thost->data_timeout += MMC_CMD_TRANSFER_TIME;\n}\n\nstatic u8 sdhci_calc_timeout(struct sdhci_host *host, struct mmc_command *cmd,\n\t\t\t     bool *too_big)\n{\n\tu8 count;\n\tstruct mmc_data *data;\n\tunsigned target_timeout, current_timeout;\n\n\t*too_big = false;\n\n\t \n\tif (host->quirks & SDHCI_QUIRK_BROKEN_TIMEOUT_VAL)\n\t\treturn host->max_timeout_count;\n\n\t \n\tif (cmd == NULL)\n\t\treturn host->max_timeout_count;\n\n\tdata = cmd->data;\n\t \n\tif (!data && !cmd->busy_timeout)\n\t\treturn host->max_timeout_count;\n\n\t \n\ttarget_timeout = sdhci_target_timeout(host, cmd, data);\n\n\t \n\tcount = 0;\n\tcurrent_timeout = (1 << 13) * 1000 / host->timeout_clk;\n\twhile (current_timeout < target_timeout) {\n\t\tcount++;\n\t\tcurrent_timeout <<= 1;\n\t\tif (count > host->max_timeout_count) {\n\t\t\tif (!(host->quirks2 & SDHCI_QUIRK2_DISABLE_HW_TIMEOUT))\n\t\t\t\tDBG(\"Too large timeout 0x%x requested for CMD%d!\\n\",\n\t\t\t\t    count, cmd->opcode);\n\t\t\tcount = host->max_timeout_count;\n\t\t\t*too_big = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn count;\n}\n\nstatic void sdhci_set_transfer_irqs(struct sdhci_host *host)\n{\n\tu32 pio_irqs = SDHCI_INT_DATA_AVAIL | SDHCI_INT_SPACE_AVAIL;\n\tu32 dma_irqs = SDHCI_INT_DMA_END | SDHCI_INT_ADMA_ERROR;\n\n\tif (host->flags & SDHCI_REQ_USE_DMA)\n\t\thost->ier = (host->ier & ~pio_irqs) | dma_irqs;\n\telse\n\t\thost->ier = (host->ier & ~dma_irqs) | pio_irqs;\n\n\tif (host->flags & (SDHCI_AUTO_CMD23 | SDHCI_AUTO_CMD12))\n\t\thost->ier |= SDHCI_INT_AUTO_CMD_ERR;\n\telse\n\t\thost->ier &= ~SDHCI_INT_AUTO_CMD_ERR;\n\n\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n}\n\nvoid sdhci_set_data_timeout_irq(struct sdhci_host *host, bool enable)\n{\n\tif (enable)\n\t\thost->ier |= SDHCI_INT_DATA_TIMEOUT;\n\telse\n\t\thost->ier &= ~SDHCI_INT_DATA_TIMEOUT;\n\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n}\nEXPORT_SYMBOL_GPL(sdhci_set_data_timeout_irq);\n\nvoid __sdhci_set_timeout(struct sdhci_host *host, struct mmc_command *cmd)\n{\n\tbool too_big = false;\n\tu8 count = sdhci_calc_timeout(host, cmd, &too_big);\n\n\tif (too_big &&\n\t    host->quirks2 & SDHCI_QUIRK2_DISABLE_HW_TIMEOUT) {\n\t\tsdhci_calc_sw_timeout(host, cmd);\n\t\tsdhci_set_data_timeout_irq(host, false);\n\t} else if (!(host->ier & SDHCI_INT_DATA_TIMEOUT)) {\n\t\tsdhci_set_data_timeout_irq(host, true);\n\t}\n\n\tsdhci_writeb(host, count, SDHCI_TIMEOUT_CONTROL);\n}\nEXPORT_SYMBOL_GPL(__sdhci_set_timeout);\n\nstatic void sdhci_set_timeout(struct sdhci_host *host, struct mmc_command *cmd)\n{\n\tif (host->ops->set_timeout)\n\t\thost->ops->set_timeout(host, cmd);\n\telse\n\t\t__sdhci_set_timeout(host, cmd);\n}\n\nstatic void sdhci_initialize_data(struct sdhci_host *host,\n\t\t\t\t  struct mmc_data *data)\n{\n\tWARN_ON(host->data);\n\n\t \n\tBUG_ON(data->blksz * data->blocks > 524288);\n\tBUG_ON(data->blksz > host->mmc->max_blk_size);\n\tBUG_ON(data->blocks > 65535);\n\n\thost->data = data;\n\thost->data_early = 0;\n\thost->data->bytes_xfered = 0;\n}\n\nstatic inline void sdhci_set_block_info(struct sdhci_host *host,\n\t\t\t\t\tstruct mmc_data *data)\n{\n\t \n\tsdhci_writew(host,\n\t\t     SDHCI_MAKE_BLKSZ(host->sdma_boundary, data->blksz),\n\t\t     SDHCI_BLOCK_SIZE);\n\t \n\tif (host->version >= SDHCI_SPEC_410 && host->v4_mode &&\n\t    (host->quirks2 & SDHCI_QUIRK2_USE_32BIT_BLK_CNT)) {\n\t\tif (sdhci_readw(host, SDHCI_BLOCK_COUNT))\n\t\t\tsdhci_writew(host, 0, SDHCI_BLOCK_COUNT);\n\t\tsdhci_writew(host, data->blocks, SDHCI_32BIT_BLK_CNT);\n\t} else {\n\t\tsdhci_writew(host, data->blocks, SDHCI_BLOCK_COUNT);\n\t}\n}\n\nstatic void sdhci_prepare_data(struct sdhci_host *host, struct mmc_command *cmd)\n{\n\tstruct mmc_data *data = cmd->data;\n\n\tsdhci_initialize_data(host, data);\n\n\tif (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {\n\t\tstruct scatterlist *sg;\n\t\tunsigned int length_mask, offset_mask;\n\t\tint i;\n\n\t\thost->flags |= SDHCI_REQ_USE_DMA;\n\n\t\t \n\t\tlength_mask = 0;\n\t\toffset_mask = 0;\n\t\tif (host->flags & SDHCI_USE_ADMA) {\n\t\t\tif (host->quirks & SDHCI_QUIRK_32BIT_ADMA_SIZE) {\n\t\t\t\tlength_mask = 3;\n\t\t\t\t \n\t\t\t\toffset_mask = 3;\n\t\t\t}\n\t\t} else {\n\t\t\tif (host->quirks & SDHCI_QUIRK_32BIT_DMA_SIZE)\n\t\t\t\tlength_mask = 3;\n\t\t\tif (host->quirks & SDHCI_QUIRK_32BIT_DMA_ADDR)\n\t\t\t\toffset_mask = 3;\n\t\t}\n\n\t\tif (unlikely(length_mask | offset_mask)) {\n\t\t\tfor_each_sg(data->sg, sg, data->sg_len, i) {\n\t\t\t\tif (sg->length & length_mask) {\n\t\t\t\t\tDBG(\"Reverting to PIO because of transfer size (%d)\\n\",\n\t\t\t\t\t    sg->length);\n\t\t\t\t\thost->flags &= ~SDHCI_REQ_USE_DMA;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (sg->offset & offset_mask) {\n\t\t\t\t\tDBG(\"Reverting to PIO because of bad alignment\\n\");\n\t\t\t\t\thost->flags &= ~SDHCI_REQ_USE_DMA;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tsdhci_config_dma(host);\n\n\tif (host->flags & SDHCI_REQ_USE_DMA) {\n\t\tint sg_cnt = sdhci_pre_dma_transfer(host, data, COOKIE_MAPPED);\n\n\t\tif (sg_cnt <= 0) {\n\t\t\t \n\t\t\tWARN_ON(1);\n\t\t\thost->flags &= ~SDHCI_REQ_USE_DMA;\n\t\t} else if (host->flags & SDHCI_USE_ADMA) {\n\t\t\tsdhci_adma_table_pre(host, data, sg_cnt);\n\t\t\tsdhci_set_adma_addr(host, host->adma_addr);\n\t\t} else {\n\t\t\tWARN_ON(sg_cnt != 1);\n\t\t\tsdhci_set_sdma_addr(host, sdhci_sdma_address(host));\n\t\t}\n\t}\n\n\tif (!(host->flags & SDHCI_REQ_USE_DMA)) {\n\t\tint flags;\n\n\t\tflags = SG_MITER_ATOMIC;\n\t\tif (host->data->flags & MMC_DATA_READ)\n\t\t\tflags |= SG_MITER_TO_SG;\n\t\telse\n\t\t\tflags |= SG_MITER_FROM_SG;\n\t\tsg_miter_start(&host->sg_miter, data->sg, data->sg_len, flags);\n\t\thost->blocks = data->blocks;\n\t}\n\n\tsdhci_set_transfer_irqs(host);\n\n\tsdhci_set_block_info(host, data);\n}\n\n#if IS_ENABLED(CONFIG_MMC_SDHCI_EXTERNAL_DMA)\n\nstatic int sdhci_external_dma_init(struct sdhci_host *host)\n{\n\tint ret = 0;\n\tstruct mmc_host *mmc = host->mmc;\n\n\thost->tx_chan = dma_request_chan(mmc_dev(mmc), \"tx\");\n\tif (IS_ERR(host->tx_chan)) {\n\t\tret = PTR_ERR(host->tx_chan);\n\t\tif (ret != -EPROBE_DEFER)\n\t\t\tpr_warn(\"Failed to request TX DMA channel.\\n\");\n\t\thost->tx_chan = NULL;\n\t\treturn ret;\n\t}\n\n\thost->rx_chan = dma_request_chan(mmc_dev(mmc), \"rx\");\n\tif (IS_ERR(host->rx_chan)) {\n\t\tif (host->tx_chan) {\n\t\t\tdma_release_channel(host->tx_chan);\n\t\t\thost->tx_chan = NULL;\n\t\t}\n\n\t\tret = PTR_ERR(host->rx_chan);\n\t\tif (ret != -EPROBE_DEFER)\n\t\t\tpr_warn(\"Failed to request RX DMA channel.\\n\");\n\t\thost->rx_chan = NULL;\n\t}\n\n\treturn ret;\n}\n\nstatic struct dma_chan *sdhci_external_dma_channel(struct sdhci_host *host,\n\t\t\t\t\t\t   struct mmc_data *data)\n{\n\treturn data->flags & MMC_DATA_WRITE ? host->tx_chan : host->rx_chan;\n}\n\nstatic int sdhci_external_dma_setup(struct sdhci_host *host,\n\t\t\t\t    struct mmc_command *cmd)\n{\n\tint ret, i;\n\tenum dma_transfer_direction dir;\n\tstruct dma_async_tx_descriptor *desc;\n\tstruct mmc_data *data = cmd->data;\n\tstruct dma_chan *chan;\n\tstruct dma_slave_config cfg;\n\tdma_cookie_t cookie;\n\tint sg_cnt;\n\n\tif (!host->mapbase)\n\t\treturn -EINVAL;\n\n\tmemset(&cfg, 0, sizeof(cfg));\n\tcfg.src_addr = host->mapbase + SDHCI_BUFFER;\n\tcfg.dst_addr = host->mapbase + SDHCI_BUFFER;\n\tcfg.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\tcfg.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\n\tcfg.src_maxburst = data->blksz / 4;\n\tcfg.dst_maxburst = data->blksz / 4;\n\n\t \n\tfor (i = 0; i < data->sg_len; i++) {\n\t\tif ((data->sg + i)->length % data->blksz)\n\t\t\treturn -EINVAL;\n\t}\n\n\tchan = sdhci_external_dma_channel(host, data);\n\n\tret = dmaengine_slave_config(chan, &cfg);\n\tif (ret)\n\t\treturn ret;\n\n\tsg_cnt = sdhci_pre_dma_transfer(host, data, COOKIE_MAPPED);\n\tif (sg_cnt <= 0)\n\t\treturn -EINVAL;\n\n\tdir = data->flags & MMC_DATA_WRITE ? DMA_MEM_TO_DEV : DMA_DEV_TO_MEM;\n\tdesc = dmaengine_prep_slave_sg(chan, data->sg, data->sg_len, dir,\n\t\t\t\t       DMA_PREP_INTERRUPT | DMA_CTRL_ACK);\n\tif (!desc)\n\t\treturn -EINVAL;\n\n\tdesc->callback = NULL;\n\tdesc->callback_param = NULL;\n\n\tcookie = dmaengine_submit(desc);\n\tif (dma_submit_error(cookie))\n\t\tret = cookie;\n\n\treturn ret;\n}\n\nstatic void sdhci_external_dma_release(struct sdhci_host *host)\n{\n\tif (host->tx_chan) {\n\t\tdma_release_channel(host->tx_chan);\n\t\thost->tx_chan = NULL;\n\t}\n\n\tif (host->rx_chan) {\n\t\tdma_release_channel(host->rx_chan);\n\t\thost->rx_chan = NULL;\n\t}\n\n\tsdhci_switch_external_dma(host, false);\n}\n\nstatic void __sdhci_external_dma_prepare_data(struct sdhci_host *host,\n\t\t\t\t\t      struct mmc_command *cmd)\n{\n\tstruct mmc_data *data = cmd->data;\n\n\tsdhci_initialize_data(host, data);\n\n\thost->flags |= SDHCI_REQ_USE_DMA;\n\tsdhci_set_transfer_irqs(host);\n\n\tsdhci_set_block_info(host, data);\n}\n\nstatic void sdhci_external_dma_prepare_data(struct sdhci_host *host,\n\t\t\t\t\t    struct mmc_command *cmd)\n{\n\tif (!sdhci_external_dma_setup(host, cmd)) {\n\t\t__sdhci_external_dma_prepare_data(host, cmd);\n\t} else {\n\t\tsdhci_external_dma_release(host);\n\t\tpr_err(\"%s: Cannot use external DMA, switch to the DMA/PIO which standard SDHCI provides.\\n\",\n\t\t       mmc_hostname(host->mmc));\n\t\tsdhci_prepare_data(host, cmd);\n\t}\n}\n\nstatic void sdhci_external_dma_pre_transfer(struct sdhci_host *host,\n\t\t\t\t\t    struct mmc_command *cmd)\n{\n\tstruct dma_chan *chan;\n\n\tif (!cmd->data)\n\t\treturn;\n\n\tchan = sdhci_external_dma_channel(host, cmd->data);\n\tif (chan)\n\t\tdma_async_issue_pending(chan);\n}\n\n#else\n\nstatic inline int sdhci_external_dma_init(struct sdhci_host *host)\n{\n\treturn -EOPNOTSUPP;\n}\n\nstatic inline void sdhci_external_dma_release(struct sdhci_host *host)\n{\n}\n\nstatic inline void sdhci_external_dma_prepare_data(struct sdhci_host *host,\n\t\t\t\t\t\t   struct mmc_command *cmd)\n{\n\t \n\tWARN_ON_ONCE(1);\n}\n\nstatic inline void sdhci_external_dma_pre_transfer(struct sdhci_host *host,\n\t\t\t\t\t\t   struct mmc_command *cmd)\n{\n}\n\nstatic inline struct dma_chan *sdhci_external_dma_channel(struct sdhci_host *host,\n\t\t\t\t\t\t\t  struct mmc_data *data)\n{\n\treturn NULL;\n}\n\n#endif\n\nvoid sdhci_switch_external_dma(struct sdhci_host *host, bool en)\n{\n\thost->use_external_dma = en;\n}\nEXPORT_SYMBOL_GPL(sdhci_switch_external_dma);\n\nstatic inline bool sdhci_auto_cmd12(struct sdhci_host *host,\n\t\t\t\t    struct mmc_request *mrq)\n{\n\treturn !mrq->sbc && (host->flags & SDHCI_AUTO_CMD12) &&\n\t       !mrq->cap_cmd_during_tfr;\n}\n\nstatic inline bool sdhci_auto_cmd23(struct sdhci_host *host,\n\t\t\t\t    struct mmc_request *mrq)\n{\n\treturn mrq->sbc && (host->flags & SDHCI_AUTO_CMD23);\n}\n\nstatic inline bool sdhci_manual_cmd23(struct sdhci_host *host,\n\t\t\t\t      struct mmc_request *mrq)\n{\n\treturn mrq->sbc && !(host->flags & SDHCI_AUTO_CMD23);\n}\n\nstatic inline void sdhci_auto_cmd_select(struct sdhci_host *host,\n\t\t\t\t\t struct mmc_command *cmd,\n\t\t\t\t\t u16 *mode)\n{\n\tbool use_cmd12 = sdhci_auto_cmd12(host, cmd->mrq) &&\n\t\t\t (cmd->opcode != SD_IO_RW_EXTENDED);\n\tbool use_cmd23 = sdhci_auto_cmd23(host, cmd->mrq);\n\tu16 ctrl2;\n\n\t \n\tif (host->version >= SDHCI_SPEC_410 && host->v4_mode &&\n\t    (use_cmd12 || use_cmd23)) {\n\t\t*mode |= SDHCI_TRNS_AUTO_SEL;\n\n\t\tctrl2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\t\tif (use_cmd23)\n\t\t\tctrl2 |= SDHCI_CMD23_ENABLE;\n\t\telse\n\t\t\tctrl2 &= ~SDHCI_CMD23_ENABLE;\n\t\tsdhci_writew(host, ctrl2, SDHCI_HOST_CONTROL2);\n\n\t\treturn;\n\t}\n\n\t \n\tif (use_cmd12)\n\t\t*mode |= SDHCI_TRNS_AUTO_CMD12;\n\telse if (use_cmd23)\n\t\t*mode |= SDHCI_TRNS_AUTO_CMD23;\n}\n\nstatic void sdhci_set_transfer_mode(struct sdhci_host *host,\n\tstruct mmc_command *cmd)\n{\n\tu16 mode = 0;\n\tstruct mmc_data *data = cmd->data;\n\n\tif (data == NULL) {\n\t\tif (host->quirks2 &\n\t\t\tSDHCI_QUIRK2_CLEAR_TRANSFERMODE_REG_BEFORE_CMD) {\n\t\t\t \n\t\t\tif (!mmc_op_tuning(cmd->opcode))\n\t\t\t\tsdhci_writew(host, 0x0, SDHCI_TRANSFER_MODE);\n\t\t} else {\n\t\t \n\t\t\tmode = sdhci_readw(host, SDHCI_TRANSFER_MODE);\n\t\t\tsdhci_writew(host, mode & ~(SDHCI_TRNS_AUTO_CMD12 |\n\t\t\t\tSDHCI_TRNS_AUTO_CMD23), SDHCI_TRANSFER_MODE);\n\t\t}\n\t\treturn;\n\t}\n\n\tWARN_ON(!host->data);\n\n\tif (!(host->quirks2 & SDHCI_QUIRK2_SUPPORT_SINGLE))\n\t\tmode = SDHCI_TRNS_BLK_CNT_EN;\n\n\tif (mmc_op_multi(cmd->opcode) || data->blocks > 1) {\n\t\tmode = SDHCI_TRNS_BLK_CNT_EN | SDHCI_TRNS_MULTI;\n\t\tsdhci_auto_cmd_select(host, cmd, &mode);\n\t\tif (sdhci_auto_cmd23(host, cmd->mrq))\n\t\t\tsdhci_writel(host, cmd->mrq->sbc->arg, SDHCI_ARGUMENT2);\n\t}\n\n\tif (data->flags & MMC_DATA_READ)\n\t\tmode |= SDHCI_TRNS_READ;\n\tif (host->flags & SDHCI_REQ_USE_DMA)\n\t\tmode |= SDHCI_TRNS_DMA;\n\n\tsdhci_writew(host, mode, SDHCI_TRANSFER_MODE);\n}\n\nstatic bool sdhci_needs_reset(struct sdhci_host *host, struct mmc_request *mrq)\n{\n\treturn (!(host->flags & SDHCI_DEVICE_DEAD) &&\n\t\t((mrq->cmd && mrq->cmd->error) ||\n\t\t (mrq->sbc && mrq->sbc->error) ||\n\t\t (mrq->data && mrq->data->stop && mrq->data->stop->error) ||\n\t\t (host->quirks & SDHCI_QUIRK_RESET_AFTER_REQUEST)));\n}\n\nstatic void sdhci_set_mrq_done(struct sdhci_host *host, struct mmc_request *mrq)\n{\n\tint i;\n\n\tfor (i = 0; i < SDHCI_MAX_MRQS; i++) {\n\t\tif (host->mrqs_done[i] == mrq) {\n\t\t\tWARN_ON(1);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tfor (i = 0; i < SDHCI_MAX_MRQS; i++) {\n\t\tif (!host->mrqs_done[i]) {\n\t\t\thost->mrqs_done[i] = mrq;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tWARN_ON(i >= SDHCI_MAX_MRQS);\n}\n\nstatic void __sdhci_finish_mrq(struct sdhci_host *host, struct mmc_request *mrq)\n{\n\tif (host->cmd && host->cmd->mrq == mrq)\n\t\thost->cmd = NULL;\n\n\tif (host->data_cmd && host->data_cmd->mrq == mrq)\n\t\thost->data_cmd = NULL;\n\n\tif (host->deferred_cmd && host->deferred_cmd->mrq == mrq)\n\t\thost->deferred_cmd = NULL;\n\n\tif (host->data && host->data->mrq == mrq)\n\t\thost->data = NULL;\n\n\tif (sdhci_needs_reset(host, mrq))\n\t\thost->pending_reset = true;\n\n\tsdhci_set_mrq_done(host, mrq);\n\n\tsdhci_del_timer(host, mrq);\n\n\tif (!sdhci_has_requests(host))\n\t\tsdhci_led_deactivate(host);\n}\n\nstatic void sdhci_finish_mrq(struct sdhci_host *host, struct mmc_request *mrq)\n{\n\t__sdhci_finish_mrq(host, mrq);\n\n\tqueue_work(host->complete_wq, &host->complete_work);\n}\n\nstatic void __sdhci_finish_data(struct sdhci_host *host, bool sw_data_timeout)\n{\n\tstruct mmc_command *data_cmd = host->data_cmd;\n\tstruct mmc_data *data = host->data;\n\n\thost->data = NULL;\n\thost->data_cmd = NULL;\n\n\t \n\tif (data->error) {\n\t\tif (!host->cmd || host->cmd == data_cmd)\n\t\t\tsdhci_reset_for(host, REQUEST_ERROR);\n\t\telse\n\t\t\tsdhci_reset_for(host, REQUEST_ERROR_DATA_ONLY);\n\t}\n\n\tif ((host->flags & (SDHCI_REQ_USE_DMA | SDHCI_USE_ADMA)) ==\n\t    (SDHCI_REQ_USE_DMA | SDHCI_USE_ADMA))\n\t\tsdhci_adma_table_post(host, data);\n\n\t \n\tif (data->error)\n\t\tdata->bytes_xfered = 0;\n\telse\n\t\tdata->bytes_xfered = data->blksz * data->blocks;\n\n\t \n\tif (data->stop &&\n\t    ((!data->mrq->sbc && !sdhci_auto_cmd12(host, data->mrq)) ||\n\t     data->error)) {\n\t\t \n\t\tif (data->mrq->cap_cmd_during_tfr) {\n\t\t\t__sdhci_finish_mrq(host, data->mrq);\n\t\t} else {\n\t\t\t \n\t\t\thost->cmd = NULL;\n\t\t\tif (!sdhci_send_command(host, data->stop)) {\n\t\t\t\tif (sw_data_timeout) {\n\t\t\t\t\t \n\t\t\t\t\tdata->stop->error = -EIO;\n\t\t\t\t\t__sdhci_finish_mrq(host, data->mrq);\n\t\t\t\t} else {\n\t\t\t\t\tWARN_ON(host->deferred_cmd);\n\t\t\t\t\thost->deferred_cmd = data->stop;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\t__sdhci_finish_mrq(host, data->mrq);\n\t}\n}\n\nstatic void sdhci_finish_data(struct sdhci_host *host)\n{\n\t__sdhci_finish_data(host, false);\n}\n\nstatic bool sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)\n{\n\tint flags;\n\tu32 mask;\n\tunsigned long timeout;\n\n\tWARN_ON(host->cmd);\n\n\t \n\tcmd->error = 0;\n\n\tif ((host->quirks2 & SDHCI_QUIRK2_STOP_WITH_TC) &&\n\t    cmd->opcode == MMC_STOP_TRANSMISSION)\n\t\tcmd->flags |= MMC_RSP_BUSY;\n\n\tmask = SDHCI_CMD_INHIBIT;\n\tif (sdhci_data_line_cmd(cmd))\n\t\tmask |= SDHCI_DATA_INHIBIT;\n\n\t \n\tif (cmd->mrq->data && (cmd == cmd->mrq->data->stop))\n\t\tmask &= ~SDHCI_DATA_INHIBIT;\n\n\tif (sdhci_readl(host, SDHCI_PRESENT_STATE) & mask)\n\t\treturn false;\n\n\thost->cmd = cmd;\n\thost->data_timeout = 0;\n\tif (sdhci_data_line_cmd(cmd)) {\n\t\tWARN_ON(host->data_cmd);\n\t\thost->data_cmd = cmd;\n\t\tsdhci_set_timeout(host, cmd);\n\t}\n\n\tif (cmd->data) {\n\t\tif (host->use_external_dma)\n\t\t\tsdhci_external_dma_prepare_data(host, cmd);\n\t\telse\n\t\t\tsdhci_prepare_data(host, cmd);\n\t}\n\n\tsdhci_writel(host, cmd->arg, SDHCI_ARGUMENT);\n\n\tsdhci_set_transfer_mode(host, cmd);\n\n\tif ((cmd->flags & MMC_RSP_136) && (cmd->flags & MMC_RSP_BUSY)) {\n\t\tWARN_ONCE(1, \"Unsupported response type!\\n\");\n\t\t \n\t\tcmd->flags &= ~MMC_RSP_BUSY;\n\t}\n\n\tif (!(cmd->flags & MMC_RSP_PRESENT))\n\t\tflags = SDHCI_CMD_RESP_NONE;\n\telse if (cmd->flags & MMC_RSP_136)\n\t\tflags = SDHCI_CMD_RESP_LONG;\n\telse if (cmd->flags & MMC_RSP_BUSY)\n\t\tflags = SDHCI_CMD_RESP_SHORT_BUSY;\n\telse\n\t\tflags = SDHCI_CMD_RESP_SHORT;\n\n\tif (cmd->flags & MMC_RSP_CRC)\n\t\tflags |= SDHCI_CMD_CRC;\n\tif (cmd->flags & MMC_RSP_OPCODE)\n\t\tflags |= SDHCI_CMD_INDEX;\n\n\t \n\tif (cmd->data || mmc_op_tuning(cmd->opcode))\n\t\tflags |= SDHCI_CMD_DATA;\n\n\ttimeout = jiffies;\n\tif (host->data_timeout)\n\t\ttimeout += nsecs_to_jiffies(host->data_timeout);\n\telse if (!cmd->data && cmd->busy_timeout > 9000)\n\t\ttimeout += DIV_ROUND_UP(cmd->busy_timeout, 1000) * HZ + HZ;\n\telse\n\t\ttimeout += 10 * HZ;\n\tsdhci_mod_timer(host, cmd->mrq, timeout);\n\n\tif (host->use_external_dma)\n\t\tsdhci_external_dma_pre_transfer(host, cmd);\n\n\tsdhci_writew(host, SDHCI_MAKE_CMD(cmd->opcode, flags), SDHCI_COMMAND);\n\n\treturn true;\n}\n\nstatic bool sdhci_present_error(struct sdhci_host *host,\n\t\t\t\tstruct mmc_command *cmd, bool present)\n{\n\tif (!present || host->flags & SDHCI_DEVICE_DEAD) {\n\t\tcmd->error = -ENOMEDIUM;\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic bool sdhci_send_command_retry(struct sdhci_host *host,\n\t\t\t\t     struct mmc_command *cmd,\n\t\t\t\t     unsigned long flags)\n\t__releases(host->lock)\n\t__acquires(host->lock)\n{\n\tstruct mmc_command *deferred_cmd = host->deferred_cmd;\n\tint timeout = 10;  \n\tbool present;\n\n\twhile (!sdhci_send_command(host, cmd)) {\n\t\tif (!timeout--) {\n\t\t\tpr_err(\"%s: Controller never released inhibit bit(s).\\n\",\n\t\t\t       mmc_hostname(host->mmc));\n\t\t\tsdhci_err_stats_inc(host, CTRL_TIMEOUT);\n\t\t\tsdhci_dumpregs(host);\n\t\t\tcmd->error = -EIO;\n\t\t\treturn false;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&host->lock, flags);\n\n\t\tusleep_range(1000, 1250);\n\n\t\tpresent = host->mmc->ops->get_cd(host->mmc);\n\n\t\tspin_lock_irqsave(&host->lock, flags);\n\n\t\t \n\t\tif (cmd == deferred_cmd && cmd != host->deferred_cmd)\n\t\t\treturn true;\n\n\t\tif (sdhci_present_error(host, cmd, present))\n\t\t\treturn false;\n\t}\n\n\tif (cmd == host->deferred_cmd)\n\t\thost->deferred_cmd = NULL;\n\n\treturn true;\n}\n\nstatic void sdhci_read_rsp_136(struct sdhci_host *host, struct mmc_command *cmd)\n{\n\tint i, reg;\n\n\tfor (i = 0; i < 4; i++) {\n\t\treg = SDHCI_RESPONSE + (3 - i) * 4;\n\t\tcmd->resp[i] = sdhci_readl(host, reg);\n\t}\n\n\tif (host->quirks2 & SDHCI_QUIRK2_RSP_136_HAS_CRC)\n\t\treturn;\n\n\t \n\tfor (i = 0; i < 4; i++) {\n\t\tcmd->resp[i] <<= 8;\n\t\tif (i != 3)\n\t\t\tcmd->resp[i] |= cmd->resp[i + 1] >> 24;\n\t}\n}\n\nstatic void sdhci_finish_command(struct sdhci_host *host)\n{\n\tstruct mmc_command *cmd = host->cmd;\n\n\thost->cmd = NULL;\n\n\tif (cmd->flags & MMC_RSP_PRESENT) {\n\t\tif (cmd->flags & MMC_RSP_136) {\n\t\t\tsdhci_read_rsp_136(host, cmd);\n\t\t} else {\n\t\t\tcmd->resp[0] = sdhci_readl(host, SDHCI_RESPONSE);\n\t\t}\n\t}\n\n\tif (cmd->mrq->cap_cmd_during_tfr && cmd == cmd->mrq->cmd)\n\t\tmmc_command_done(host->mmc, cmd->mrq);\n\n\t \n\tif (cmd->flags & MMC_RSP_BUSY) {\n\t\tif (cmd->data) {\n\t\t\tDBG(\"Cannot wait for busy signal when also doing a data transfer\");\n\t\t} else if (!(host->quirks & SDHCI_QUIRK_NO_BUSY_IRQ) &&\n\t\t\t   cmd == host->data_cmd) {\n\t\t\t \n\t\t\treturn;\n\t\t}\n\t}\n\n\t \n\tif (cmd == cmd->mrq->sbc) {\n\t\tif (!sdhci_send_command(host, cmd->mrq->cmd)) {\n\t\t\tWARN_ON(host->deferred_cmd);\n\t\t\thost->deferred_cmd = cmd->mrq->cmd;\n\t\t}\n\t} else {\n\n\t\t \n\t\tif (host->data && host->data_early)\n\t\t\tsdhci_finish_data(host);\n\n\t\tif (!cmd->data)\n\t\t\t__sdhci_finish_mrq(host, cmd->mrq);\n\t}\n}\n\nstatic u16 sdhci_get_preset_value(struct sdhci_host *host)\n{\n\tu16 preset = 0;\n\n\tswitch (host->timing) {\n\tcase MMC_TIMING_MMC_HS:\n\tcase MMC_TIMING_SD_HS:\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_HIGH_SPEED);\n\t\tbreak;\n\tcase MMC_TIMING_UHS_SDR12:\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR12);\n\t\tbreak;\n\tcase MMC_TIMING_UHS_SDR25:\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR25);\n\t\tbreak;\n\tcase MMC_TIMING_UHS_SDR50:\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR50);\n\t\tbreak;\n\tcase MMC_TIMING_UHS_SDR104:\n\tcase MMC_TIMING_MMC_HS200:\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR104);\n\t\tbreak;\n\tcase MMC_TIMING_UHS_DDR50:\n\tcase MMC_TIMING_MMC_DDR52:\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_DDR50);\n\t\tbreak;\n\tcase MMC_TIMING_MMC_HS400:\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_HS400);\n\t\tbreak;\n\tdefault:\n\t\tpr_warn(\"%s: Invalid UHS-I mode selected\\n\",\n\t\t\tmmc_hostname(host->mmc));\n\t\tpreset = sdhci_readw(host, SDHCI_PRESET_FOR_SDR12);\n\t\tbreak;\n\t}\n\treturn preset;\n}\n\nu16 sdhci_calc_clk(struct sdhci_host *host, unsigned int clock,\n\t\t   unsigned int *actual_clock)\n{\n\tint div = 0;  \n\tint real_div = div, clk_mul = 1;\n\tu16 clk = 0;\n\tbool switch_base_clk = false;\n\n\tif (host->version >= SDHCI_SPEC_300) {\n\t\tif (host->preset_enabled) {\n\t\t\tu16 pre_val;\n\n\t\t\tclk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);\n\t\t\tpre_val = sdhci_get_preset_value(host);\n\t\t\tdiv = FIELD_GET(SDHCI_PRESET_SDCLK_FREQ_MASK, pre_val);\n\t\t\tif (host->clk_mul &&\n\t\t\t\t(pre_val & SDHCI_PRESET_CLKGEN_SEL)) {\n\t\t\t\tclk = SDHCI_PROG_CLOCK_MODE;\n\t\t\t\treal_div = div + 1;\n\t\t\t\tclk_mul = host->clk_mul;\n\t\t\t} else {\n\t\t\t\treal_div = max_t(int, 1, div << 1);\n\t\t\t}\n\t\t\tgoto clock_set;\n\t\t}\n\n\t\t \n\t\tif (host->clk_mul) {\n\t\t\tfor (div = 1; div <= 1024; div++) {\n\t\t\t\tif ((host->max_clk * host->clk_mul / div)\n\t\t\t\t\t<= clock)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((host->max_clk * host->clk_mul / div) <= clock) {\n\t\t\t\t \n\t\t\t\tclk = SDHCI_PROG_CLOCK_MODE;\n\t\t\t\treal_div = div;\n\t\t\t\tclk_mul = host->clk_mul;\n\t\t\t\tdiv--;\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tswitch_base_clk = true;\n\t\t\t}\n\t\t}\n\n\t\tif (!host->clk_mul || switch_base_clk) {\n\t\t\t \n\t\t\tif (host->max_clk <= clock)\n\t\t\t\tdiv = 1;\n\t\t\telse {\n\t\t\t\tfor (div = 2; div < SDHCI_MAX_DIV_SPEC_300;\n\t\t\t\t     div += 2) {\n\t\t\t\t\tif ((host->max_clk / div) <= clock)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\treal_div = div;\n\t\t\tdiv >>= 1;\n\t\t\tif ((host->quirks2 & SDHCI_QUIRK2_CLOCK_DIV_ZERO_BROKEN)\n\t\t\t\t&& !div && host->max_clk <= 25000000)\n\t\t\t\tdiv = 1;\n\t\t}\n\t} else {\n\t\t \n\t\tfor (div = 1; div < SDHCI_MAX_DIV_SPEC_200; div *= 2) {\n\t\t\tif ((host->max_clk / div) <= clock)\n\t\t\t\tbreak;\n\t\t}\n\t\treal_div = div;\n\t\tdiv >>= 1;\n\t}\n\nclock_set:\n\tif (real_div)\n\t\t*actual_clock = (host->max_clk * clk_mul) / real_div;\n\tclk |= (div & SDHCI_DIV_MASK) << SDHCI_DIVIDER_SHIFT;\n\tclk |= ((div & SDHCI_DIV_HI_MASK) >> SDHCI_DIV_MASK_LEN)\n\t\t<< SDHCI_DIVIDER_HI_SHIFT;\n\n\treturn clk;\n}\nEXPORT_SYMBOL_GPL(sdhci_calc_clk);\n\nvoid sdhci_enable_clk(struct sdhci_host *host, u16 clk)\n{\n\tktime_t timeout;\n\n\tclk |= SDHCI_CLOCK_INT_EN;\n\tsdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);\n\n\t \n\ttimeout = ktime_add_ms(ktime_get(), 150);\n\twhile (1) {\n\t\tbool timedout = ktime_after(ktime_get(), timeout);\n\n\t\tclk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);\n\t\tif (clk & SDHCI_CLOCK_INT_STABLE)\n\t\t\tbreak;\n\t\tif (timedout) {\n\t\t\tpr_err(\"%s: Internal clock never stabilised.\\n\",\n\t\t\t       mmc_hostname(host->mmc));\n\t\t\tsdhci_err_stats_inc(host, CTRL_TIMEOUT);\n\t\t\tsdhci_dumpregs(host);\n\t\t\treturn;\n\t\t}\n\t\tudelay(10);\n\t}\n\n\tif (host->version >= SDHCI_SPEC_410 && host->v4_mode) {\n\t\tclk |= SDHCI_CLOCK_PLL_EN;\n\t\tclk &= ~SDHCI_CLOCK_INT_STABLE;\n\t\tsdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);\n\n\t\t \n\t\ttimeout = ktime_add_ms(ktime_get(), 150);\n\t\twhile (1) {\n\t\t\tbool timedout = ktime_after(ktime_get(), timeout);\n\n\t\t\tclk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);\n\t\t\tif (clk & SDHCI_CLOCK_INT_STABLE)\n\t\t\t\tbreak;\n\t\t\tif (timedout) {\n\t\t\t\tpr_err(\"%s: PLL clock never stabilised.\\n\",\n\t\t\t\t       mmc_hostname(host->mmc));\n\t\t\t\tsdhci_err_stats_inc(host, CTRL_TIMEOUT);\n\t\t\t\tsdhci_dumpregs(host);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tudelay(10);\n\t\t}\n\t}\n\n\tclk |= SDHCI_CLOCK_CARD_EN;\n\tsdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);\n}\nEXPORT_SYMBOL_GPL(sdhci_enable_clk);\n\nvoid sdhci_set_clock(struct sdhci_host *host, unsigned int clock)\n{\n\tu16 clk;\n\n\thost->mmc->actual_clock = 0;\n\n\tsdhci_writew(host, 0, SDHCI_CLOCK_CONTROL);\n\n\tif (clock == 0)\n\t\treturn;\n\n\tclk = sdhci_calc_clk(host, clock, &host->mmc->actual_clock);\n\tsdhci_enable_clk(host, clk);\n}\nEXPORT_SYMBOL_GPL(sdhci_set_clock);\n\nstatic void sdhci_set_power_reg(struct sdhci_host *host, unsigned char mode,\n\t\t\t\tunsigned short vdd)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\n\tmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, vdd);\n\n\tif (mode != MMC_POWER_OFF)\n\t\tsdhci_writeb(host, SDHCI_POWER_ON, SDHCI_POWER_CONTROL);\n\telse\n\t\tsdhci_writeb(host, 0, SDHCI_POWER_CONTROL);\n}\n\nvoid sdhci_set_power_noreg(struct sdhci_host *host, unsigned char mode,\n\t\t\t   unsigned short vdd)\n{\n\tu8 pwr = 0;\n\n\tif (mode != MMC_POWER_OFF) {\n\t\tswitch (1 << vdd) {\n\t\tcase MMC_VDD_165_195:\n\t\t \n\t\tcase MMC_VDD_20_21:\n\t\t\tpwr = SDHCI_POWER_180;\n\t\t\tbreak;\n\t\tcase MMC_VDD_29_30:\n\t\tcase MMC_VDD_30_31:\n\t\t\tpwr = SDHCI_POWER_300;\n\t\t\tbreak;\n\t\tcase MMC_VDD_32_33:\n\t\tcase MMC_VDD_33_34:\n\t\t \n\t\tcase MMC_VDD_34_35:\n\t\tcase MMC_VDD_35_36:\n\t\t\tpwr = SDHCI_POWER_330;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tWARN(1, \"%s: Invalid vdd %#x\\n\",\n\t\t\t     mmc_hostname(host->mmc), vdd);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (host->pwr == pwr)\n\t\treturn;\n\n\thost->pwr = pwr;\n\n\tif (pwr == 0) {\n\t\tsdhci_writeb(host, 0, SDHCI_POWER_CONTROL);\n\t\tif (host->quirks2 & SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON)\n\t\t\tsdhci_runtime_pm_bus_off(host);\n\t} else {\n\t\t \n\t\tif (!(host->quirks & SDHCI_QUIRK_SINGLE_POWER_WRITE))\n\t\t\tsdhci_writeb(host, 0, SDHCI_POWER_CONTROL);\n\n\t\t \n\t\tif (host->quirks & SDHCI_QUIRK_NO_SIMULT_VDD_AND_POWER)\n\t\t\tsdhci_writeb(host, pwr, SDHCI_POWER_CONTROL);\n\n\t\tpwr |= SDHCI_POWER_ON;\n\n\t\tsdhci_writeb(host, pwr, SDHCI_POWER_CONTROL);\n\n\t\tif (host->quirks2 & SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON)\n\t\t\tsdhci_runtime_pm_bus_on(host);\n\n\t\t \n\t\tif (host->quirks & SDHCI_QUIRK_DELAY_AFTER_POWER)\n\t\t\tmdelay(10);\n\t}\n}\nEXPORT_SYMBOL_GPL(sdhci_set_power_noreg);\n\nvoid sdhci_set_power(struct sdhci_host *host, unsigned char mode,\n\t\t     unsigned short vdd)\n{\n\tif (IS_ERR(host->mmc->supply.vmmc))\n\t\tsdhci_set_power_noreg(host, mode, vdd);\n\telse\n\t\tsdhci_set_power_reg(host, mode, vdd);\n}\nEXPORT_SYMBOL_GPL(sdhci_set_power);\n\n \nvoid sdhci_set_power_and_bus_voltage(struct sdhci_host *host,\n\t\t\t\t     unsigned char mode,\n\t\t\t\t     unsigned short vdd)\n{\n\tif (!IS_ERR(host->mmc->supply.vmmc)) {\n\t\tstruct mmc_host *mmc = host->mmc;\n\n\t\tmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, vdd);\n\t}\n\tsdhci_set_power_noreg(host, mode, vdd);\n}\nEXPORT_SYMBOL_GPL(sdhci_set_power_and_bus_voltage);\n\n \n\nvoid sdhci_request(struct mmc_host *mmc, struct mmc_request *mrq)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tstruct mmc_command *cmd;\n\tunsigned long flags;\n\tbool present;\n\n\t \n\tpresent = mmc->ops->get_cd(mmc);\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tsdhci_led_activate(host);\n\n\tif (sdhci_present_error(host, mrq->cmd, present))\n\t\tgoto out_finish;\n\n\tcmd = sdhci_manual_cmd23(host, mrq) ? mrq->sbc : mrq->cmd;\n\n\tif (!sdhci_send_command_retry(host, cmd, flags))\n\t\tgoto out_finish;\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\treturn;\n\nout_finish:\n\tsdhci_finish_mrq(host, mrq);\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\nEXPORT_SYMBOL_GPL(sdhci_request);\n\nint sdhci_request_atomic(struct mmc_host *mmc, struct mmc_request *mrq)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tstruct mmc_command *cmd;\n\tunsigned long flags;\n\tint ret = 0;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tif (sdhci_present_error(host, mrq->cmd, true)) {\n\t\tsdhci_finish_mrq(host, mrq);\n\t\tgoto out_finish;\n\t}\n\n\tcmd = sdhci_manual_cmd23(host, mrq) ? mrq->sbc : mrq->cmd;\n\n\t \n\tif (!sdhci_send_command(host, cmd))\n\t\tret = -EBUSY;\n\telse\n\t\tsdhci_led_activate(host);\n\nout_finish:\n\tspin_unlock_irqrestore(&host->lock, flags);\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(sdhci_request_atomic);\n\nvoid sdhci_set_bus_width(struct sdhci_host *host, int width)\n{\n\tu8 ctrl;\n\n\tctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);\n\tif (width == MMC_BUS_WIDTH_8) {\n\t\tctrl &= ~SDHCI_CTRL_4BITBUS;\n\t\tctrl |= SDHCI_CTRL_8BITBUS;\n\t} else {\n\t\tif (host->mmc->caps & MMC_CAP_8_BIT_DATA)\n\t\t\tctrl &= ~SDHCI_CTRL_8BITBUS;\n\t\tif (width == MMC_BUS_WIDTH_4)\n\t\t\tctrl |= SDHCI_CTRL_4BITBUS;\n\t\telse\n\t\t\tctrl &= ~SDHCI_CTRL_4BITBUS;\n\t}\n\tsdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);\n}\nEXPORT_SYMBOL_GPL(sdhci_set_bus_width);\n\nvoid sdhci_set_uhs_signaling(struct sdhci_host *host, unsigned timing)\n{\n\tu16 ctrl_2;\n\n\tctrl_2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\t \n\tctrl_2 &= ~SDHCI_CTRL_UHS_MASK;\n\tif ((timing == MMC_TIMING_MMC_HS200) ||\n\t    (timing == MMC_TIMING_UHS_SDR104))\n\t\tctrl_2 |= SDHCI_CTRL_UHS_SDR104;\n\telse if (timing == MMC_TIMING_UHS_SDR12)\n\t\tctrl_2 |= SDHCI_CTRL_UHS_SDR12;\n\telse if (timing == MMC_TIMING_UHS_SDR25)\n\t\tctrl_2 |= SDHCI_CTRL_UHS_SDR25;\n\telse if (timing == MMC_TIMING_UHS_SDR50)\n\t\tctrl_2 |= SDHCI_CTRL_UHS_SDR50;\n\telse if ((timing == MMC_TIMING_UHS_DDR50) ||\n\t\t (timing == MMC_TIMING_MMC_DDR52))\n\t\tctrl_2 |= SDHCI_CTRL_UHS_DDR50;\n\telse if (timing == MMC_TIMING_MMC_HS400)\n\t\tctrl_2 |= SDHCI_CTRL_HS400;  \n\tsdhci_writew(host, ctrl_2, SDHCI_HOST_CONTROL2);\n}\nEXPORT_SYMBOL_GPL(sdhci_set_uhs_signaling);\n\nstatic bool sdhci_timing_has_preset(unsigned char timing)\n{\n\tswitch (timing) {\n\tcase MMC_TIMING_UHS_SDR12:\n\tcase MMC_TIMING_UHS_SDR25:\n\tcase MMC_TIMING_UHS_SDR50:\n\tcase MMC_TIMING_UHS_SDR104:\n\tcase MMC_TIMING_UHS_DDR50:\n\tcase MMC_TIMING_MMC_DDR52:\n\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic bool sdhci_preset_needed(struct sdhci_host *host, unsigned char timing)\n{\n\treturn !(host->quirks2 & SDHCI_QUIRK2_PRESET_VALUE_BROKEN) &&\n\t       sdhci_timing_has_preset(timing);\n}\n\nstatic bool sdhci_presetable_values_change(struct sdhci_host *host, struct mmc_ios *ios)\n{\n\t \n\treturn !host->preset_enabled &&\n\t       (sdhci_preset_needed(host, ios->timing) || host->drv_type != ios->drv_type);\n}\n\nvoid sdhci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tbool reinit_uhs = host->reinit_uhs;\n\tbool turning_on_clk = false;\n\tu8 ctrl;\n\n\thost->reinit_uhs = false;\n\n\tif (ios->power_mode == MMC_POWER_UNDEFINED)\n\t\treturn;\n\n\tif (host->flags & SDHCI_DEVICE_DEAD) {\n\t\tif (!IS_ERR(mmc->supply.vmmc) &&\n\t\t    ios->power_mode == MMC_POWER_OFF)\n\t\t\tmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);\n\t\treturn;\n\t}\n\n\t \n\tif (ios->power_mode == MMC_POWER_OFF) {\n\t\tsdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);\n\t\tsdhci_reinit(host);\n\t}\n\n\tif (host->version >= SDHCI_SPEC_300 &&\n\t\t(ios->power_mode == MMC_POWER_UP) &&\n\t\t!(host->quirks2 & SDHCI_QUIRK2_PRESET_VALUE_BROKEN))\n\t\tsdhci_enable_preset_value(host, false);\n\n\tif (!ios->clock || ios->clock != host->clock) {\n\t\tturning_on_clk = ios->clock && !host->clock;\n\n\t\thost->ops->set_clock(host, ios->clock);\n\t\thost->clock = ios->clock;\n\n\t\tif (host->quirks & SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK &&\n\t\t    host->clock) {\n\t\t\thost->timeout_clk = mmc->actual_clock ?\n\t\t\t\t\t\tmmc->actual_clock / 1000 :\n\t\t\t\t\t\thost->clock / 1000;\n\t\t\tmmc->max_busy_timeout =\n\t\t\t\thost->ops->get_max_timeout_count ?\n\t\t\t\thost->ops->get_max_timeout_count(host) :\n\t\t\t\t1 << 27;\n\t\t\tmmc->max_busy_timeout /= host->timeout_clk;\n\t\t}\n\t}\n\n\tif (host->ops->set_power)\n\t\thost->ops->set_power(host, ios->power_mode, ios->vdd);\n\telse\n\t\tsdhci_set_power(host, ios->power_mode, ios->vdd);\n\n\tif (host->ops->platform_send_init_74_clocks)\n\t\thost->ops->platform_send_init_74_clocks(host, ios->power_mode);\n\n\thost->ops->set_bus_width(host, ios->bus_width);\n\n\t \n\tif (!reinit_uhs &&\n\t    turning_on_clk &&\n\t    host->timing == ios->timing &&\n\t    host->version >= SDHCI_SPEC_300 &&\n\t    !sdhci_presetable_values_change(host, ios))\n\t\treturn;\n\n\tctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);\n\n\tif (!(host->quirks & SDHCI_QUIRK_NO_HISPD_BIT)) {\n\t\tif (ios->timing == MMC_TIMING_SD_HS ||\n\t\t     ios->timing == MMC_TIMING_MMC_HS ||\n\t\t     ios->timing == MMC_TIMING_MMC_HS400 ||\n\t\t     ios->timing == MMC_TIMING_MMC_HS200 ||\n\t\t     ios->timing == MMC_TIMING_MMC_DDR52 ||\n\t\t     ios->timing == MMC_TIMING_UHS_SDR50 ||\n\t\t     ios->timing == MMC_TIMING_UHS_SDR104 ||\n\t\t     ios->timing == MMC_TIMING_UHS_DDR50 ||\n\t\t     ios->timing == MMC_TIMING_UHS_SDR25)\n\t\t\tctrl |= SDHCI_CTRL_HISPD;\n\t\telse\n\t\t\tctrl &= ~SDHCI_CTRL_HISPD;\n\t}\n\n\tif (host->version >= SDHCI_SPEC_300) {\n\t\tu16 clk, ctrl_2;\n\n\t\t \n\t\tclk = sdhci_readw(host, SDHCI_CLOCK_CONTROL);\n\t\tif (clk & SDHCI_CLOCK_CARD_EN) {\n\t\t\tclk &= ~SDHCI_CLOCK_CARD_EN;\n\t\t\tsdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);\n\t\t}\n\n\t\tsdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);\n\n\t\tif (!host->preset_enabled) {\n\t\t\t \n\t\t\tctrl_2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\t\t\tctrl_2 &= ~SDHCI_CTRL_DRV_TYPE_MASK;\n\t\t\tif (ios->drv_type == MMC_SET_DRIVER_TYPE_A)\n\t\t\t\tctrl_2 |= SDHCI_CTRL_DRV_TYPE_A;\n\t\t\telse if (ios->drv_type == MMC_SET_DRIVER_TYPE_B)\n\t\t\t\tctrl_2 |= SDHCI_CTRL_DRV_TYPE_B;\n\t\t\telse if (ios->drv_type == MMC_SET_DRIVER_TYPE_C)\n\t\t\t\tctrl_2 |= SDHCI_CTRL_DRV_TYPE_C;\n\t\t\telse if (ios->drv_type == MMC_SET_DRIVER_TYPE_D)\n\t\t\t\tctrl_2 |= SDHCI_CTRL_DRV_TYPE_D;\n\t\t\telse {\n\t\t\t\tpr_warn(\"%s: invalid driver type, default to driver type B\\n\",\n\t\t\t\t\tmmc_hostname(mmc));\n\t\t\t\tctrl_2 |= SDHCI_CTRL_DRV_TYPE_B;\n\t\t\t}\n\n\t\t\tsdhci_writew(host, ctrl_2, SDHCI_HOST_CONTROL2);\n\t\t\thost->drv_type = ios->drv_type;\n\t\t}\n\n\t\thost->ops->set_uhs_signaling(host, ios->timing);\n\t\thost->timing = ios->timing;\n\n\t\tif (sdhci_preset_needed(host, ios->timing)) {\n\t\t\tu16 preset;\n\n\t\t\tsdhci_enable_preset_value(host, true);\n\t\t\tpreset = sdhci_get_preset_value(host);\n\t\t\tios->drv_type = FIELD_GET(SDHCI_PRESET_DRV_MASK,\n\t\t\t\t\t\t  preset);\n\t\t\thost->drv_type = ios->drv_type;\n\t\t}\n\n\t\t \n\t\thost->ops->set_clock(host, host->clock);\n\t} else\n\t\tsdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);\n}\nEXPORT_SYMBOL_GPL(sdhci_set_ios);\n\nstatic int sdhci_get_cd(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tint gpio_cd = mmc_gpio_get_cd(mmc);\n\n\tif (host->flags & SDHCI_DEVICE_DEAD)\n\t\treturn 0;\n\n\t \n\tif (!mmc_card_is_removable(mmc))\n\t\treturn 1;\n\n\t \n\tif (gpio_cd >= 0)\n\t\treturn !!gpio_cd;\n\n\t \n\tif (host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION)\n\t\treturn 1;\n\n\t \n\treturn !!(sdhci_readl(host, SDHCI_PRESENT_STATE) & SDHCI_CARD_PRESENT);\n}\n\nint sdhci_get_cd_nogpio(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tunsigned long flags;\n\tint ret = 0;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tif (host->flags & SDHCI_DEVICE_DEAD)\n\t\tgoto out;\n\n\tret = !!(sdhci_readl(host, SDHCI_PRESENT_STATE) & SDHCI_CARD_PRESENT);\nout:\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(sdhci_get_cd_nogpio);\n\nstatic int sdhci_check_ro(struct sdhci_host *host)\n{\n\tunsigned long flags;\n\tint is_readonly;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tif (host->flags & SDHCI_DEVICE_DEAD)\n\t\tis_readonly = 0;\n\telse if (host->ops->get_ro)\n\t\tis_readonly = host->ops->get_ro(host);\n\telse if (mmc_can_gpio_ro(host->mmc))\n\t\tis_readonly = mmc_gpio_get_ro(host->mmc);\n\telse\n\t\tis_readonly = !(sdhci_readl(host, SDHCI_PRESENT_STATE)\n\t\t\t\t& SDHCI_WRITE_PROTECT);\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\t \n\treturn host->quirks & SDHCI_QUIRK_INVERTED_WRITE_PROTECT ?\n\t\t!is_readonly : is_readonly;\n}\n\n#define SAMPLE_COUNT\t5\n\nstatic int sdhci_get_ro(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tint i, ro_count;\n\n\tif (!(host->quirks & SDHCI_QUIRK_UNSTABLE_RO_DETECT))\n\t\treturn sdhci_check_ro(host);\n\n\tro_count = 0;\n\tfor (i = 0; i < SAMPLE_COUNT; i++) {\n\t\tif (sdhci_check_ro(host)) {\n\t\t\tif (++ro_count > SAMPLE_COUNT / 2)\n\t\t\t\treturn 1;\n\t\t}\n\t\tmsleep(30);\n\t}\n\treturn 0;\n}\n\nstatic void sdhci_hw_reset(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\n\tif (host->ops && host->ops->hw_reset)\n\t\thost->ops->hw_reset(host);\n}\n\nstatic void sdhci_enable_sdio_irq_nolock(struct sdhci_host *host, int enable)\n{\n\tif (!(host->flags & SDHCI_DEVICE_DEAD)) {\n\t\tif (enable)\n\t\t\thost->ier |= SDHCI_INT_CARD_INT;\n\t\telse\n\t\t\thost->ier &= ~SDHCI_INT_CARD_INT;\n\n\t\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\t\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n\t}\n}\n\nvoid sdhci_enable_sdio_irq(struct mmc_host *mmc, int enable)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tunsigned long flags;\n\n\tif (enable)\n\t\tpm_runtime_get_noresume(mmc_dev(mmc));\n\n\tspin_lock_irqsave(&host->lock, flags);\n\tsdhci_enable_sdio_irq_nolock(host, enable);\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\tif (!enable)\n\t\tpm_runtime_put_noidle(mmc_dev(mmc));\n}\nEXPORT_SYMBOL_GPL(sdhci_enable_sdio_irq);\n\nstatic void sdhci_ack_sdio_irq(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\tsdhci_enable_sdio_irq_nolock(host, true);\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\n\nint sdhci_start_signal_voltage_switch(struct mmc_host *mmc,\n\t\t\t\t      struct mmc_ios *ios)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tu16 ctrl;\n\tint ret;\n\n\t \n\tif (host->version < SDHCI_SPEC_300)\n\t\treturn 0;\n\n\tctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\n\tswitch (ios->signal_voltage) {\n\tcase MMC_SIGNAL_VOLTAGE_330:\n\t\tif (!(host->flags & SDHCI_SIGNALING_330))\n\t\t\treturn -EINVAL;\n\t\t \n\t\tctrl &= ~SDHCI_CTRL_VDD_180;\n\t\tsdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);\n\n\t\tif (!IS_ERR(mmc->supply.vqmmc)) {\n\t\t\tret = mmc_regulator_set_vqmmc(mmc, ios);\n\t\t\tif (ret < 0) {\n\t\t\t\tpr_warn(\"%s: Switching to 3.3V signalling voltage failed\\n\",\n\t\t\t\t\tmmc_hostname(mmc));\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t\t \n\t\tusleep_range(5000, 5500);\n\n\t\t \n\t\tctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\t\tif (!(ctrl & SDHCI_CTRL_VDD_180))\n\t\t\treturn 0;\n\n\t\tpr_warn(\"%s: 3.3V regulator output did not become stable\\n\",\n\t\t\tmmc_hostname(mmc));\n\n\t\treturn -EAGAIN;\n\tcase MMC_SIGNAL_VOLTAGE_180:\n\t\tif (!(host->flags & SDHCI_SIGNALING_180))\n\t\t\treturn -EINVAL;\n\t\tif (!IS_ERR(mmc->supply.vqmmc)) {\n\t\t\tret = mmc_regulator_set_vqmmc(mmc, ios);\n\t\t\tif (ret < 0) {\n\t\t\t\tpr_warn(\"%s: Switching to 1.8V signalling voltage failed\\n\",\n\t\t\t\t\tmmc_hostname(mmc));\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tctrl |= SDHCI_CTRL_VDD_180;\n\t\tsdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);\n\n\t\t \n\t\tif (host->ops->voltage_switch)\n\t\t\thost->ops->voltage_switch(host);\n\n\t\t \n\t\tctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\t\tif (ctrl & SDHCI_CTRL_VDD_180)\n\t\t\treturn 0;\n\n\t\tpr_warn(\"%s: 1.8V regulator output did not become stable\\n\",\n\t\t\tmmc_hostname(mmc));\n\n\t\treturn -EAGAIN;\n\tcase MMC_SIGNAL_VOLTAGE_120:\n\t\tif (!(host->flags & SDHCI_SIGNALING_120))\n\t\t\treturn -EINVAL;\n\t\tif (!IS_ERR(mmc->supply.vqmmc)) {\n\t\t\tret = mmc_regulator_set_vqmmc(mmc, ios);\n\t\t\tif (ret < 0) {\n\t\t\t\tpr_warn(\"%s: Switching to 1.2V signalling voltage failed\\n\",\n\t\t\t\t\tmmc_hostname(mmc));\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\tdefault:\n\t\t \n\t\treturn 0;\n\t}\n}\nEXPORT_SYMBOL_GPL(sdhci_start_signal_voltage_switch);\n\nstatic int sdhci_card_busy(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tu32 present_state;\n\n\t \n\tpresent_state = sdhci_readl(host, SDHCI_PRESENT_STATE);\n\n\treturn !(present_state & SDHCI_DATA_0_LVL_MASK);\n}\n\nstatic int sdhci_prepare_hs400_tuning(struct mmc_host *mmc, struct mmc_ios *ios)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\thost->flags |= SDHCI_HS400_TUNING;\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\treturn 0;\n}\n\nvoid sdhci_start_tuning(struct sdhci_host *host)\n{\n\tu16 ctrl;\n\n\tctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\tctrl |= SDHCI_CTRL_EXEC_TUNING;\n\tif (host->quirks2 & SDHCI_QUIRK2_TUNING_WORK_AROUND)\n\t\tctrl |= SDHCI_CTRL_TUNED_CLK;\n\tsdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);\n\n\t \n\tsdhci_writel(host, SDHCI_INT_DATA_AVAIL, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, SDHCI_INT_DATA_AVAIL, SDHCI_SIGNAL_ENABLE);\n}\nEXPORT_SYMBOL_GPL(sdhci_start_tuning);\n\nvoid sdhci_end_tuning(struct sdhci_host *host)\n{\n\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n}\nEXPORT_SYMBOL_GPL(sdhci_end_tuning);\n\nvoid sdhci_reset_tuning(struct sdhci_host *host)\n{\n\tu16 ctrl;\n\n\tctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\tctrl &= ~SDHCI_CTRL_TUNED_CLK;\n\tctrl &= ~SDHCI_CTRL_EXEC_TUNING;\n\tsdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);\n}\nEXPORT_SYMBOL_GPL(sdhci_reset_tuning);\n\nvoid sdhci_abort_tuning(struct sdhci_host *host, u32 opcode)\n{\n\tsdhci_reset_tuning(host);\n\n\tsdhci_reset_for(host, TUNING_ABORT);\n\n\tsdhci_end_tuning(host);\n\n\tmmc_send_abort_tuning(host->mmc, opcode);\n}\nEXPORT_SYMBOL_GPL(sdhci_abort_tuning);\n\n \nvoid sdhci_send_tuning(struct sdhci_host *host, u32 opcode)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\tstruct mmc_command cmd = {};\n\tstruct mmc_request mrq = {};\n\tunsigned long flags;\n\tu32 b = host->sdma_boundary;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tcmd.opcode = opcode;\n\tcmd.flags = MMC_RSP_R1 | MMC_CMD_ADTC;\n\tcmd.mrq = &mrq;\n\n\tmrq.cmd = &cmd;\n\t \n\tif (cmd.opcode == MMC_SEND_TUNING_BLOCK_HS200 &&\n\t    mmc->ios.bus_width == MMC_BUS_WIDTH_8)\n\t\tsdhci_writew(host, SDHCI_MAKE_BLKSZ(b, 128), SDHCI_BLOCK_SIZE);\n\telse\n\t\tsdhci_writew(host, SDHCI_MAKE_BLKSZ(b, 64), SDHCI_BLOCK_SIZE);\n\n\t \n\tsdhci_writew(host, SDHCI_TRNS_READ, SDHCI_TRANSFER_MODE);\n\n\tif (!sdhci_send_command_retry(host, &cmd, flags)) {\n\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\thost->tuning_done = 0;\n\t\treturn;\n\t}\n\n\thost->cmd = NULL;\n\n\tsdhci_del_timer(host, &mrq);\n\n\thost->tuning_done = 0;\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\t \n\twait_event_timeout(host->buf_ready_int, (host->tuning_done == 1),\n\t\t\t   msecs_to_jiffies(50));\n\n}\nEXPORT_SYMBOL_GPL(sdhci_send_tuning);\n\nstatic int __sdhci_execute_tuning(struct sdhci_host *host, u32 opcode)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < host->tuning_loop_count; i++) {\n\t\tu16 ctrl;\n\n\t\tsdhci_send_tuning(host, opcode);\n\n\t\tif (!host->tuning_done) {\n\t\t\tpr_debug(\"%s: Tuning timeout, falling back to fixed sampling clock\\n\",\n\t\t\t\t mmc_hostname(host->mmc));\n\t\t\tsdhci_abort_tuning(host, opcode);\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\n\t\t \n\t\tif (host->tuning_delay > 0)\n\t\t\tmdelay(host->tuning_delay);\n\n\t\tctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\t\tif (!(ctrl & SDHCI_CTRL_EXEC_TUNING)) {\n\t\t\tif (ctrl & SDHCI_CTRL_TUNED_CLK)\n\t\t\t\treturn 0;  \n\t\t\tbreak;\n\t\t}\n\n\t}\n\n\tpr_info(\"%s: Tuning failed, falling back to fixed sampling clock\\n\",\n\t\tmmc_hostname(host->mmc));\n\tsdhci_reset_tuning(host);\n\treturn -EAGAIN;\n}\n\nint sdhci_execute_tuning(struct mmc_host *mmc, u32 opcode)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tint err = 0;\n\tunsigned int tuning_count = 0;\n\tbool hs400_tuning;\n\n\ths400_tuning = host->flags & SDHCI_HS400_TUNING;\n\n\tif (host->tuning_mode == SDHCI_TUNING_MODE_1)\n\t\ttuning_count = host->tuning_count;\n\n\t \n\tswitch (host->timing) {\n\t \n\tcase MMC_TIMING_MMC_HS400:\n\t\terr = -EINVAL;\n\t\tgoto out;\n\n\tcase MMC_TIMING_MMC_HS200:\n\t\t \n\t\tif (hs400_tuning)\n\t\t\ttuning_count = 0;\n\t\tbreak;\n\n\tcase MMC_TIMING_UHS_SDR104:\n\tcase MMC_TIMING_UHS_DDR50:\n\t\tbreak;\n\n\tcase MMC_TIMING_UHS_SDR50:\n\t\tif (host->flags & SDHCI_SDR50_NEEDS_TUNING)\n\t\t\tbreak;\n\t\tfallthrough;\n\n\tdefault:\n\t\tgoto out;\n\t}\n\n\tif (host->ops->platform_execute_tuning) {\n\t\terr = host->ops->platform_execute_tuning(host, opcode);\n\t\tgoto out;\n\t}\n\n\tmmc->retune_period = tuning_count;\n\n\tif (host->tuning_delay < 0)\n\t\thost->tuning_delay = opcode == MMC_SEND_TUNING_BLOCK;\n\n\tsdhci_start_tuning(host);\n\n\thost->tuning_err = __sdhci_execute_tuning(host, opcode);\n\n\tsdhci_end_tuning(host);\nout:\n\thost->flags &= ~SDHCI_HS400_TUNING;\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(sdhci_execute_tuning);\n\nstatic void sdhci_enable_preset_value(struct sdhci_host *host, bool enable)\n{\n\t \n\tif (host->version < SDHCI_SPEC_300)\n\t\treturn;\n\n\t \n\tif (host->preset_enabled != enable) {\n\t\tu16 ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);\n\n\t\tif (enable)\n\t\t\tctrl |= SDHCI_CTRL_PRESET_VAL_ENABLE;\n\t\telse\n\t\t\tctrl &= ~SDHCI_CTRL_PRESET_VAL_ENABLE;\n\n\t\tsdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);\n\n\t\tif (enable)\n\t\t\thost->flags |= SDHCI_PV_ENABLED;\n\t\telse\n\t\t\thost->flags &= ~SDHCI_PV_ENABLED;\n\n\t\thost->preset_enabled = enable;\n\t}\n}\n\nstatic void sdhci_post_req(struct mmc_host *mmc, struct mmc_request *mrq,\n\t\t\t\tint err)\n{\n\tstruct mmc_data *data = mrq->data;\n\n\tif (data->host_cookie != COOKIE_UNMAPPED)\n\t\tdma_unmap_sg(mmc_dev(mmc), data->sg, data->sg_len,\n\t\t\t     mmc_get_dma_dir(data));\n\n\tdata->host_cookie = COOKIE_UNMAPPED;\n}\n\nstatic void sdhci_pre_req(struct mmc_host *mmc, struct mmc_request *mrq)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\n\tmrq->data->host_cookie = COOKIE_UNMAPPED;\n\n\t \n\tif (host->flags & SDHCI_REQ_USE_DMA && !host->bounce_buffer)\n\t\tsdhci_pre_dma_transfer(host, mrq->data, COOKIE_PRE_MAPPED);\n}\n\nstatic void sdhci_error_out_mrqs(struct sdhci_host *host, int err)\n{\n\tif (host->data_cmd) {\n\t\thost->data_cmd->error = err;\n\t\tsdhci_finish_mrq(host, host->data_cmd->mrq);\n\t}\n\n\tif (host->cmd) {\n\t\thost->cmd->error = err;\n\t\tsdhci_finish_mrq(host, host->cmd->mrq);\n\t}\n}\n\nstatic void sdhci_card_event(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tunsigned long flags;\n\tint present;\n\n\t \n\tif (host->ops->card_event)\n\t\thost->ops->card_event(host);\n\n\tpresent = mmc->ops->get_cd(mmc);\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\t \n\tif (sdhci_has_requests(host) && !present) {\n\t\tpr_err(\"%s: Card removed during transfer!\\n\",\n\t\t\tmmc_hostname(mmc));\n\t\tpr_err(\"%s: Resetting controller.\\n\",\n\t\t\tmmc_hostname(mmc));\n\n\t\tsdhci_reset_for(host, CARD_REMOVED);\n\n\t\tsdhci_error_out_mrqs(host, -ENOMEDIUM);\n\t}\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\n\nstatic const struct mmc_host_ops sdhci_ops = {\n\t.request\t= sdhci_request,\n\t.post_req\t= sdhci_post_req,\n\t.pre_req\t= sdhci_pre_req,\n\t.set_ios\t= sdhci_set_ios,\n\t.get_cd\t\t= sdhci_get_cd,\n\t.get_ro\t\t= sdhci_get_ro,\n\t.card_hw_reset\t= sdhci_hw_reset,\n\t.enable_sdio_irq = sdhci_enable_sdio_irq,\n\t.ack_sdio_irq    = sdhci_ack_sdio_irq,\n\t.start_signal_voltage_switch\t= sdhci_start_signal_voltage_switch,\n\t.prepare_hs400_tuning\t\t= sdhci_prepare_hs400_tuning,\n\t.execute_tuning\t\t\t= sdhci_execute_tuning,\n\t.card_event\t\t\t= sdhci_card_event,\n\t.card_busy\t= sdhci_card_busy,\n};\n\n \n\nstatic bool sdhci_request_done(struct sdhci_host *host)\n{\n\tunsigned long flags;\n\tstruct mmc_request *mrq;\n\tint i;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tfor (i = 0; i < SDHCI_MAX_MRQS; i++) {\n\t\tmrq = host->mrqs_done[i];\n\t\tif (mrq)\n\t\t\tbreak;\n\t}\n\n\tif (!mrq) {\n\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\treturn true;\n\t}\n\n\t \n\tif (sdhci_needs_reset(host, mrq)) {\n\t\t \n\t\tif (host->cmd || host->data_cmd) {\n\t\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\t\treturn true;\n\t\t}\n\n\t\t \n\t\tif (host->quirks & SDHCI_QUIRK_CLOCK_BEFORE_RESET)\n\t\t\t \n\t\t\thost->ops->set_clock(host, host->clock);\n\n\t\tsdhci_reset_for(host, REQUEST_ERROR);\n\n\t\thost->pending_reset = false;\n\t}\n\n\t \n\tif (host->flags & SDHCI_REQ_USE_DMA) {\n\t\tstruct mmc_data *data = mrq->data;\n\n\t\tif (host->use_external_dma && data &&\n\t\t    (mrq->cmd->error || data->error)) {\n\t\t\tstruct dma_chan *chan = sdhci_external_dma_channel(host, data);\n\n\t\t\thost->mrqs_done[i] = NULL;\n\t\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\t\tdmaengine_terminate_sync(chan);\n\t\t\tspin_lock_irqsave(&host->lock, flags);\n\t\t\tsdhci_set_mrq_done(host, mrq);\n\t\t}\n\n\t\tif (data && data->host_cookie == COOKIE_MAPPED) {\n\t\t\tif (host->bounce_buffer) {\n\t\t\t\t \n\t\t\t\tif (mmc_get_dma_dir(data) == DMA_FROM_DEVICE) {\n\t\t\t\t\tunsigned int length = data->bytes_xfered;\n\n\t\t\t\t\tif (length > host->bounce_buffer_size) {\n\t\t\t\t\t\tpr_err(\"%s: bounce buffer is %u bytes but DMA claims to have transferred %u bytes\\n\",\n\t\t\t\t\t\t       mmc_hostname(host->mmc),\n\t\t\t\t\t\t       host->bounce_buffer_size,\n\t\t\t\t\t\t       data->bytes_xfered);\n\t\t\t\t\t\t \n\t\t\t\t\t\tlength = host->bounce_buffer_size;\n\t\t\t\t\t}\n\t\t\t\t\tdma_sync_single_for_cpu(\n\t\t\t\t\t\tmmc_dev(host->mmc),\n\t\t\t\t\t\thost->bounce_addr,\n\t\t\t\t\t\thost->bounce_buffer_size,\n\t\t\t\t\t\tDMA_FROM_DEVICE);\n\t\t\t\t\tsg_copy_from_buffer(data->sg,\n\t\t\t\t\t\tdata->sg_len,\n\t\t\t\t\t\thost->bounce_buffer,\n\t\t\t\t\t\tlength);\n\t\t\t\t} else {\n\t\t\t\t\t \n\t\t\t\t\tdma_sync_single_for_cpu(\n\t\t\t\t\t\tmmc_dev(host->mmc),\n\t\t\t\t\t\thost->bounce_addr,\n\t\t\t\t\t\thost->bounce_buffer_size,\n\t\t\t\t\t\tmmc_get_dma_dir(data));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t \n\t\t\t\tdma_unmap_sg(mmc_dev(host->mmc), data->sg,\n\t\t\t\t\t     data->sg_len,\n\t\t\t\t\t     mmc_get_dma_dir(data));\n\t\t\t}\n\t\t\tdata->host_cookie = COOKIE_UNMAPPED;\n\t\t}\n\t}\n\n\thost->mrqs_done[i] = NULL;\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\tif (host->ops->request_done)\n\t\thost->ops->request_done(host, mrq);\n\telse\n\t\tmmc_request_done(host->mmc, mrq);\n\n\treturn false;\n}\n\nstatic void sdhci_complete_work(struct work_struct *work)\n{\n\tstruct sdhci_host *host = container_of(work, struct sdhci_host,\n\t\t\t\t\t       complete_work);\n\n\twhile (!sdhci_request_done(host))\n\t\t;\n}\n\nstatic void sdhci_timeout_timer(struct timer_list *t)\n{\n\tstruct sdhci_host *host;\n\tunsigned long flags;\n\n\thost = from_timer(host, t, timer);\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tif (host->cmd && !sdhci_data_line_cmd(host->cmd)) {\n\t\tpr_err(\"%s: Timeout waiting for hardware cmd interrupt.\\n\",\n\t\t       mmc_hostname(host->mmc));\n\t\tsdhci_err_stats_inc(host, REQ_TIMEOUT);\n\t\tsdhci_dumpregs(host);\n\n\t\thost->cmd->error = -ETIMEDOUT;\n\t\tsdhci_finish_mrq(host, host->cmd->mrq);\n\t}\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\n\nstatic void sdhci_timeout_data_timer(struct timer_list *t)\n{\n\tstruct sdhci_host *host;\n\tunsigned long flags;\n\n\thost = from_timer(host, t, data_timer);\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tif (host->data || host->data_cmd ||\n\t    (host->cmd && sdhci_data_line_cmd(host->cmd))) {\n\t\tpr_err(\"%s: Timeout waiting for hardware interrupt.\\n\",\n\t\t       mmc_hostname(host->mmc));\n\t\tsdhci_err_stats_inc(host, REQ_TIMEOUT);\n\t\tsdhci_dumpregs(host);\n\n\t\tif (host->data) {\n\t\t\thost->data->error = -ETIMEDOUT;\n\t\t\t__sdhci_finish_data(host, true);\n\t\t\tqueue_work(host->complete_wq, &host->complete_work);\n\t\t} else if (host->data_cmd) {\n\t\t\thost->data_cmd->error = -ETIMEDOUT;\n\t\t\tsdhci_finish_mrq(host, host->data_cmd->mrq);\n\t\t} else {\n\t\t\thost->cmd->error = -ETIMEDOUT;\n\t\t\tsdhci_finish_mrq(host, host->cmd->mrq);\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\n\n \n\nstatic void sdhci_cmd_irq(struct sdhci_host *host, u32 intmask, u32 *intmask_p)\n{\n\t \n\tif (intmask & SDHCI_INT_AUTO_CMD_ERR && host->data_cmd) {\n\t\tstruct mmc_request *mrq = host->data_cmd->mrq;\n\t\tu16 auto_cmd_status = sdhci_readw(host, SDHCI_AUTO_CMD_STATUS);\n\t\tint data_err_bit = (auto_cmd_status & SDHCI_AUTO_CMD_TIMEOUT) ?\n\t\t\t\t   SDHCI_INT_DATA_TIMEOUT :\n\t\t\t\t   SDHCI_INT_DATA_CRC;\n\n\t\t \n\t\tif (!mrq->sbc && (host->flags & SDHCI_AUTO_CMD12)) {\n\t\t\t*intmask_p |= data_err_bit;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!host->cmd) {\n\t\t \n\t\tif (host->pending_reset)\n\t\t\treturn;\n\t\tpr_err(\"%s: Got command interrupt 0x%08x even though no command operation was in progress.\\n\",\n\t\t       mmc_hostname(host->mmc), (unsigned)intmask);\n\t\tsdhci_err_stats_inc(host, UNEXPECTED_IRQ);\n\t\tsdhci_dumpregs(host);\n\t\treturn;\n\t}\n\n\tif (intmask & (SDHCI_INT_TIMEOUT | SDHCI_INT_CRC |\n\t\t       SDHCI_INT_END_BIT | SDHCI_INT_INDEX)) {\n\t\tif (intmask & SDHCI_INT_TIMEOUT) {\n\t\t\thost->cmd->error = -ETIMEDOUT;\n\t\t\tsdhci_err_stats_inc(host, CMD_TIMEOUT);\n\t\t} else {\n\t\t\thost->cmd->error = -EILSEQ;\n\t\t\tif (!mmc_op_tuning(host->cmd->opcode))\n\t\t\t\tsdhci_err_stats_inc(host, CMD_CRC);\n\t\t}\n\t\t \n\t\tif (host->cmd->data &&\n\t\t    (intmask & (SDHCI_INT_CRC | SDHCI_INT_TIMEOUT)) ==\n\t\t     SDHCI_INT_CRC) {\n\t\t\thost->cmd = NULL;\n\t\t\t*intmask_p |= SDHCI_INT_DATA_CRC;\n\t\t\treturn;\n\t\t}\n\n\t\t__sdhci_finish_mrq(host, host->cmd->mrq);\n\t\treturn;\n\t}\n\n\t \n\tif (intmask & SDHCI_INT_AUTO_CMD_ERR) {\n\t\tstruct mmc_request *mrq = host->cmd->mrq;\n\t\tu16 auto_cmd_status = sdhci_readw(host, SDHCI_AUTO_CMD_STATUS);\n\t\tint err = (auto_cmd_status & SDHCI_AUTO_CMD_TIMEOUT) ?\n\t\t\t  -ETIMEDOUT :\n\t\t\t  -EILSEQ;\n\n\t\tsdhci_err_stats_inc(host, AUTO_CMD);\n\n\t\tif (sdhci_auto_cmd23(host, mrq)) {\n\t\t\tmrq->sbc->error = err;\n\t\t\t__sdhci_finish_mrq(host, mrq);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (intmask & SDHCI_INT_RESPONSE)\n\t\tsdhci_finish_command(host);\n}\n\nstatic void sdhci_adma_show_error(struct sdhci_host *host)\n{\n\tvoid *desc = host->adma_table;\n\tdma_addr_t dma = host->adma_addr;\n\n\tsdhci_dumpregs(host);\n\n\twhile (true) {\n\t\tstruct sdhci_adma2_64_desc *dma_desc = desc;\n\n\t\tif (host->flags & SDHCI_USE_64_BIT_DMA)\n\t\t\tSDHCI_DUMP(\"%08llx: DMA 0x%08x%08x, LEN 0x%04x, Attr=0x%02x\\n\",\n\t\t\t    (unsigned long long)dma,\n\t\t\t    le32_to_cpu(dma_desc->addr_hi),\n\t\t\t    le32_to_cpu(dma_desc->addr_lo),\n\t\t\t    le16_to_cpu(dma_desc->len),\n\t\t\t    le16_to_cpu(dma_desc->cmd));\n\t\telse\n\t\t\tSDHCI_DUMP(\"%08llx: DMA 0x%08x, LEN 0x%04x, Attr=0x%02x\\n\",\n\t\t\t    (unsigned long long)dma,\n\t\t\t    le32_to_cpu(dma_desc->addr_lo),\n\t\t\t    le16_to_cpu(dma_desc->len),\n\t\t\t    le16_to_cpu(dma_desc->cmd));\n\n\t\tdesc += host->desc_sz;\n\t\tdma += host->desc_sz;\n\n\t\tif (dma_desc->cmd & cpu_to_le16(ADMA2_END))\n\t\t\tbreak;\n\t}\n}\n\nstatic void sdhci_data_irq(struct sdhci_host *host, u32 intmask)\n{\n\t \n\tif (intmask & SDHCI_INT_DATA_AVAIL && !host->data) {\n\t\tif (mmc_op_tuning(SDHCI_GET_CMD(sdhci_readw(host, SDHCI_COMMAND)))) {\n\t\t\thost->tuning_done = 1;\n\t\t\twake_up(&host->buf_ready_int);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!host->data) {\n\t\tstruct mmc_command *data_cmd = host->data_cmd;\n\n\t\t \n\t\tif (data_cmd && (data_cmd->flags & MMC_RSP_BUSY)) {\n\t\t\tif (intmask & SDHCI_INT_DATA_TIMEOUT) {\n\t\t\t\thost->data_cmd = NULL;\n\t\t\t\tdata_cmd->error = -ETIMEDOUT;\n\t\t\t\tsdhci_err_stats_inc(host, CMD_TIMEOUT);\n\t\t\t\t__sdhci_finish_mrq(host, data_cmd->mrq);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (intmask & SDHCI_INT_DATA_END) {\n\t\t\t\thost->data_cmd = NULL;\n\t\t\t\t \n\t\t\t\tif (host->cmd == data_cmd)\n\t\t\t\t\treturn;\n\n\t\t\t\t__sdhci_finish_mrq(host, data_cmd->mrq);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (host->pending_reset)\n\t\t\treturn;\n\n\t\tpr_err(\"%s: Got data interrupt 0x%08x even though no data operation was in progress.\\n\",\n\t\t       mmc_hostname(host->mmc), (unsigned)intmask);\n\t\tsdhci_err_stats_inc(host, UNEXPECTED_IRQ);\n\t\tsdhci_dumpregs(host);\n\n\t\treturn;\n\t}\n\n\tif (intmask & SDHCI_INT_DATA_TIMEOUT) {\n\t\thost->data->error = -ETIMEDOUT;\n\t\tsdhci_err_stats_inc(host, DAT_TIMEOUT);\n\t} else if (intmask & SDHCI_INT_DATA_END_BIT) {\n\t\thost->data->error = -EILSEQ;\n\t\tif (!mmc_op_tuning(SDHCI_GET_CMD(sdhci_readw(host, SDHCI_COMMAND))))\n\t\t\tsdhci_err_stats_inc(host, DAT_CRC);\n\t} else if ((intmask & SDHCI_INT_DATA_CRC) &&\n\t\tSDHCI_GET_CMD(sdhci_readw(host, SDHCI_COMMAND))\n\t\t\t!= MMC_BUS_TEST_R) {\n\t\thost->data->error = -EILSEQ;\n\t\tif (!mmc_op_tuning(SDHCI_GET_CMD(sdhci_readw(host, SDHCI_COMMAND))))\n\t\t\tsdhci_err_stats_inc(host, DAT_CRC);\n\t} else if (intmask & SDHCI_INT_ADMA_ERROR) {\n\t\tpr_err(\"%s: ADMA error: 0x%08x\\n\", mmc_hostname(host->mmc),\n\t\t       intmask);\n\t\tsdhci_adma_show_error(host);\n\t\tsdhci_err_stats_inc(host, ADMA);\n\t\thost->data->error = -EIO;\n\t\tif (host->ops->adma_workaround)\n\t\t\thost->ops->adma_workaround(host, intmask);\n\t}\n\n\tif (host->data->error)\n\t\tsdhci_finish_data(host);\n\telse {\n\t\tif (intmask & (SDHCI_INT_DATA_AVAIL | SDHCI_INT_SPACE_AVAIL))\n\t\t\tsdhci_transfer_pio(host);\n\n\t\t \n\t\tif (intmask & SDHCI_INT_DMA_END) {\n\t\t\tdma_addr_t dmastart, dmanow;\n\n\t\t\tdmastart = sdhci_sdma_address(host);\n\t\t\tdmanow = dmastart + host->data->bytes_xfered;\n\t\t\t \n\t\t\tdmanow = (dmanow &\n\t\t\t\t~((dma_addr_t)SDHCI_DEFAULT_BOUNDARY_SIZE - 1)) +\n\t\t\t\tSDHCI_DEFAULT_BOUNDARY_SIZE;\n\t\t\thost->data->bytes_xfered = dmanow - dmastart;\n\t\t\tDBG(\"DMA base %pad, transferred 0x%06x bytes, next %pad\\n\",\n\t\t\t    &dmastart, host->data->bytes_xfered, &dmanow);\n\t\t\tsdhci_set_sdma_addr(host, dmanow);\n\t\t}\n\n\t\tif (intmask & SDHCI_INT_DATA_END) {\n\t\t\tif (host->cmd == host->data_cmd) {\n\t\t\t\t \n\t\t\t\thost->data_early = 1;\n\t\t\t} else {\n\t\t\t\tsdhci_finish_data(host);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic inline bool sdhci_defer_done(struct sdhci_host *host,\n\t\t\t\t    struct mmc_request *mrq)\n{\n\tstruct mmc_data *data = mrq->data;\n\n\treturn host->pending_reset || host->always_defer_done ||\n\t       ((host->flags & SDHCI_REQ_USE_DMA) && data &&\n\t\tdata->host_cookie == COOKIE_MAPPED);\n}\n\nstatic irqreturn_t sdhci_irq(int irq, void *dev_id)\n{\n\tstruct mmc_request *mrqs_done[SDHCI_MAX_MRQS] = {0};\n\tirqreturn_t result = IRQ_NONE;\n\tstruct sdhci_host *host = dev_id;\n\tu32 intmask, mask, unexpected = 0;\n\tint max_loops = 16;\n\tint i;\n\n\tspin_lock(&host->lock);\n\n\tif (host->runtime_suspended) {\n\t\tspin_unlock(&host->lock);\n\t\treturn IRQ_NONE;\n\t}\n\n\tintmask = sdhci_readl(host, SDHCI_INT_STATUS);\n\tif (!intmask || intmask == 0xffffffff) {\n\t\tresult = IRQ_NONE;\n\t\tgoto out;\n\t}\n\n\tdo {\n\t\tDBG(\"IRQ status 0x%08x\\n\", intmask);\n\n\t\tif (host->ops->irq) {\n\t\t\tintmask = host->ops->irq(host, intmask);\n\t\t\tif (!intmask)\n\t\t\t\tgoto cont;\n\t\t}\n\n\t\t \n\t\tmask = intmask & (SDHCI_INT_CMD_MASK | SDHCI_INT_DATA_MASK |\n\t\t\t\t  SDHCI_INT_BUS_POWER);\n\t\tsdhci_writel(host, mask, SDHCI_INT_STATUS);\n\n\t\tif (intmask & (SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE)) {\n\t\t\tu32 present = sdhci_readl(host, SDHCI_PRESENT_STATE) &\n\t\t\t\t      SDHCI_CARD_PRESENT;\n\n\t\t\t \n\t\t\thost->ier &= ~(SDHCI_INT_CARD_INSERT |\n\t\t\t\t       SDHCI_INT_CARD_REMOVE);\n\t\t\thost->ier |= present ? SDHCI_INT_CARD_REMOVE :\n\t\t\t\t\t       SDHCI_INT_CARD_INSERT;\n\t\t\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\t\t\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n\n\t\t\tsdhci_writel(host, intmask & (SDHCI_INT_CARD_INSERT |\n\t\t\t\t     SDHCI_INT_CARD_REMOVE), SDHCI_INT_STATUS);\n\n\t\t\thost->thread_isr |= intmask & (SDHCI_INT_CARD_INSERT |\n\t\t\t\t\t\t       SDHCI_INT_CARD_REMOVE);\n\t\t\tresult = IRQ_WAKE_THREAD;\n\t\t}\n\n\t\tif (intmask & SDHCI_INT_CMD_MASK)\n\t\t\tsdhci_cmd_irq(host, intmask & SDHCI_INT_CMD_MASK, &intmask);\n\n\t\tif (intmask & SDHCI_INT_DATA_MASK)\n\t\t\tsdhci_data_irq(host, intmask & SDHCI_INT_DATA_MASK);\n\n\t\tif (intmask & SDHCI_INT_BUS_POWER)\n\t\t\tpr_err(\"%s: Card is consuming too much power!\\n\",\n\t\t\t\tmmc_hostname(host->mmc));\n\n\t\tif (intmask & SDHCI_INT_RETUNE)\n\t\t\tmmc_retune_needed(host->mmc);\n\n\t\tif ((intmask & SDHCI_INT_CARD_INT) &&\n\t\t    (host->ier & SDHCI_INT_CARD_INT)) {\n\t\t\tsdhci_enable_sdio_irq_nolock(host, false);\n\t\t\tsdio_signal_irq(host->mmc);\n\t\t}\n\n\t\tintmask &= ~(SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE |\n\t\t\t     SDHCI_INT_CMD_MASK | SDHCI_INT_DATA_MASK |\n\t\t\t     SDHCI_INT_ERROR | SDHCI_INT_BUS_POWER |\n\t\t\t     SDHCI_INT_RETUNE | SDHCI_INT_CARD_INT);\n\n\t\tif (intmask) {\n\t\t\tunexpected |= intmask;\n\t\t\tsdhci_writel(host, intmask, SDHCI_INT_STATUS);\n\t\t}\ncont:\n\t\tif (result == IRQ_NONE)\n\t\t\tresult = IRQ_HANDLED;\n\n\t\tintmask = sdhci_readl(host, SDHCI_INT_STATUS);\n\t} while (intmask && --max_loops);\n\n\t \n\tfor (i = 0; i < SDHCI_MAX_MRQS; i++) {\n\t\tstruct mmc_request *mrq = host->mrqs_done[i];\n\n\t\tif (!mrq)\n\t\t\tcontinue;\n\n\t\tif (sdhci_defer_done(host, mrq)) {\n\t\t\tresult = IRQ_WAKE_THREAD;\n\t\t} else {\n\t\t\tmrqs_done[i] = mrq;\n\t\t\thost->mrqs_done[i] = NULL;\n\t\t}\n\t}\nout:\n\tif (host->deferred_cmd)\n\t\tresult = IRQ_WAKE_THREAD;\n\n\tspin_unlock(&host->lock);\n\n\t \n\tfor (i = 0; i < SDHCI_MAX_MRQS; i++) {\n\t\tif (!mrqs_done[i])\n\t\t\tcontinue;\n\n\t\tif (host->ops->request_done)\n\t\t\thost->ops->request_done(host, mrqs_done[i]);\n\t\telse\n\t\t\tmmc_request_done(host->mmc, mrqs_done[i]);\n\t}\n\n\tif (unexpected) {\n\t\tpr_err(\"%s: Unexpected interrupt 0x%08x.\\n\",\n\t\t\t   mmc_hostname(host->mmc), unexpected);\n\t\tsdhci_err_stats_inc(host, UNEXPECTED_IRQ);\n\t\tsdhci_dumpregs(host);\n\t}\n\n\treturn result;\n}\n\nstatic irqreturn_t sdhci_thread_irq(int irq, void *dev_id)\n{\n\tstruct sdhci_host *host = dev_id;\n\tstruct mmc_command *cmd;\n\tunsigned long flags;\n\tu32 isr;\n\n\twhile (!sdhci_request_done(host))\n\t\t;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tisr = host->thread_isr;\n\thost->thread_isr = 0;\n\n\tcmd = host->deferred_cmd;\n\tif (cmd && !sdhci_send_command_retry(host, cmd, flags))\n\t\tsdhci_finish_mrq(host, cmd->mrq);\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\tif (isr & (SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE)) {\n\t\tstruct mmc_host *mmc = host->mmc;\n\n\t\tmmc->ops->card_event(mmc);\n\t\tmmc_detect_change(mmc, msecs_to_jiffies(200));\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n \n\n#ifdef CONFIG_PM\n\nstatic bool sdhci_cd_irq_can_wakeup(struct sdhci_host *host)\n{\n\treturn mmc_card_is_removable(host->mmc) &&\n\t       !(host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) &&\n\t       !mmc_can_gpio_cd(host->mmc);\n}\n\n \nstatic bool sdhci_enable_irq_wakeups(struct sdhci_host *host)\n{\n\tu8 mask = SDHCI_WAKE_ON_INSERT | SDHCI_WAKE_ON_REMOVE |\n\t\t  SDHCI_WAKE_ON_INT;\n\tu32 irq_val = 0;\n\tu8 wake_val = 0;\n\tu8 val;\n\n\tif (sdhci_cd_irq_can_wakeup(host)) {\n\t\twake_val |= SDHCI_WAKE_ON_INSERT | SDHCI_WAKE_ON_REMOVE;\n\t\tirq_val |= SDHCI_INT_CARD_INSERT | SDHCI_INT_CARD_REMOVE;\n\t}\n\n\tif (mmc_card_wake_sdio_irq(host->mmc)) {\n\t\twake_val |= SDHCI_WAKE_ON_INT;\n\t\tirq_val |= SDHCI_INT_CARD_INT;\n\t}\n\n\tif (!irq_val)\n\t\treturn false;\n\n\tval = sdhci_readb(host, SDHCI_WAKE_UP_CONTROL);\n\tval &= ~mask;\n\tval |= wake_val;\n\tsdhci_writeb(host, val, SDHCI_WAKE_UP_CONTROL);\n\n\tsdhci_writel(host, irq_val, SDHCI_INT_ENABLE);\n\n\thost->irq_wake_enabled = !enable_irq_wake(host->irq);\n\n\treturn host->irq_wake_enabled;\n}\n\nstatic void sdhci_disable_irq_wakeups(struct sdhci_host *host)\n{\n\tu8 val;\n\tu8 mask = SDHCI_WAKE_ON_INSERT | SDHCI_WAKE_ON_REMOVE\n\t\t\t| SDHCI_WAKE_ON_INT;\n\n\tval = sdhci_readb(host, SDHCI_WAKE_UP_CONTROL);\n\tval &= ~mask;\n\tsdhci_writeb(host, val, SDHCI_WAKE_UP_CONTROL);\n\n\tdisable_irq_wake(host->irq);\n\n\thost->irq_wake_enabled = false;\n}\n\nint sdhci_suspend_host(struct sdhci_host *host)\n{\n\tsdhci_disable_card_detection(host);\n\n\tmmc_retune_timer_stop(host->mmc);\n\n\tif (!device_may_wakeup(mmc_dev(host->mmc)) ||\n\t    !sdhci_enable_irq_wakeups(host)) {\n\t\thost->ier = 0;\n\t\tsdhci_writel(host, 0, SDHCI_INT_ENABLE);\n\t\tsdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);\n\t\tfree_irq(host->irq, host);\n\t}\n\n\treturn 0;\n}\n\nEXPORT_SYMBOL_GPL(sdhci_suspend_host);\n\nint sdhci_resume_host(struct sdhci_host *host)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\tint ret = 0;\n\n\tif (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {\n\t\tif (host->ops->enable_dma)\n\t\t\thost->ops->enable_dma(host);\n\t}\n\n\tif ((mmc->pm_flags & MMC_PM_KEEP_POWER) &&\n\t    (host->quirks2 & SDHCI_QUIRK2_HOST_OFF_CARD_ON)) {\n\t\t \n\t\tsdhci_init(host, 0);\n\t\thost->pwr = 0;\n\t\thost->clock = 0;\n\t\thost->reinit_uhs = true;\n\t\tmmc->ops->set_ios(mmc, &mmc->ios);\n\t} else {\n\t\tsdhci_init(host, (mmc->pm_flags & MMC_PM_KEEP_POWER));\n\t}\n\n\tif (host->irq_wake_enabled) {\n\t\tsdhci_disable_irq_wakeups(host);\n\t} else {\n\t\tret = request_threaded_irq(host->irq, sdhci_irq,\n\t\t\t\t\t   sdhci_thread_irq, IRQF_SHARED,\n\t\t\t\t\t   mmc_hostname(mmc), host);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tsdhci_enable_card_detection(host);\n\n\treturn ret;\n}\n\nEXPORT_SYMBOL_GPL(sdhci_resume_host);\n\nint sdhci_runtime_suspend_host(struct sdhci_host *host)\n{\n\tunsigned long flags;\n\n\tmmc_retune_timer_stop(host->mmc);\n\n\tspin_lock_irqsave(&host->lock, flags);\n\thost->ier &= SDHCI_INT_CARD_INT;\n\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\tsynchronize_hardirq(host->irq);\n\n\tspin_lock_irqsave(&host->lock, flags);\n\thost->runtime_suspended = true;\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(sdhci_runtime_suspend_host);\n\nint sdhci_runtime_resume_host(struct sdhci_host *host, int soft_reset)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\tunsigned long flags;\n\tint host_flags = host->flags;\n\n\tif (host_flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {\n\t\tif (host->ops->enable_dma)\n\t\t\thost->ops->enable_dma(host);\n\t}\n\n\tsdhci_init(host, soft_reset);\n\n\tif (mmc->ios.power_mode != MMC_POWER_UNDEFINED &&\n\t    mmc->ios.power_mode != MMC_POWER_OFF) {\n\t\t \n\t\thost->pwr = 0;\n\t\thost->clock = 0;\n\t\thost->reinit_uhs = true;\n\t\tmmc->ops->start_signal_voltage_switch(mmc, &mmc->ios);\n\t\tmmc->ops->set_ios(mmc, &mmc->ios);\n\n\t\tif ((host_flags & SDHCI_PV_ENABLED) &&\n\t\t    !(host->quirks2 & SDHCI_QUIRK2_PRESET_VALUE_BROKEN)) {\n\t\t\tspin_lock_irqsave(&host->lock, flags);\n\t\t\tsdhci_enable_preset_value(host, true);\n\t\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t\t}\n\n\t\tif ((mmc->caps2 & MMC_CAP2_HS400_ES) &&\n\t\t    mmc->ops->hs400_enhanced_strobe)\n\t\t\tmmc->ops->hs400_enhanced_strobe(mmc, &mmc->ios);\n\t}\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\thost->runtime_suspended = false;\n\n\t \n\tif (sdio_irq_claimed(mmc))\n\t\tsdhci_enable_sdio_irq_nolock(host, true);\n\n\t \n\tsdhci_enable_card_detection(host);\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(sdhci_runtime_resume_host);\n\n#endif  \n\n \n\nvoid sdhci_cqe_enable(struct mmc_host *mmc)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tunsigned long flags;\n\tu8 ctrl;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tctrl = sdhci_readb(host, SDHCI_HOST_CONTROL);\n\tctrl &= ~SDHCI_CTRL_DMA_MASK;\n\t \n\tif (host->v4_mode && (host->caps1 & SDHCI_CAN_DO_ADMA3))\n\t\tctrl |= SDHCI_CTRL_ADMA3;\n\telse if (host->flags & SDHCI_USE_64_BIT_DMA)\n\t\tctrl |= SDHCI_CTRL_ADMA64;\n\telse\n\t\tctrl |= SDHCI_CTRL_ADMA32;\n\tsdhci_writeb(host, ctrl, SDHCI_HOST_CONTROL);\n\n\tsdhci_writew(host, SDHCI_MAKE_BLKSZ(host->sdma_boundary, 512),\n\t\t     SDHCI_BLOCK_SIZE);\n\n\t \n\tsdhci_set_timeout(host, NULL);\n\n\thost->ier = host->cqe_ier;\n\n\tsdhci_writel(host, host->ier, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, host->ier, SDHCI_SIGNAL_ENABLE);\n\n\thost->cqe_on = true;\n\n\tpr_debug(\"%s: sdhci: CQE on, IRQ mask %#x, IRQ status %#x\\n\",\n\t\t mmc_hostname(mmc), host->ier,\n\t\t sdhci_readl(host, SDHCI_INT_STATUS));\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\nEXPORT_SYMBOL_GPL(sdhci_cqe_enable);\n\nvoid sdhci_cqe_disable(struct mmc_host *mmc, bool recovery)\n{\n\tstruct sdhci_host *host = mmc_priv(mmc);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&host->lock, flags);\n\n\tsdhci_set_default_irqs(host);\n\n\thost->cqe_on = false;\n\n\tif (recovery)\n\t\tsdhci_reset_for(host, CQE_RECOVERY);\n\n\tpr_debug(\"%s: sdhci: CQE off, IRQ mask %#x, IRQ status %#x\\n\",\n\t\t mmc_hostname(mmc), host->ier,\n\t\t sdhci_readl(host, SDHCI_INT_STATUS));\n\n\tspin_unlock_irqrestore(&host->lock, flags);\n}\nEXPORT_SYMBOL_GPL(sdhci_cqe_disable);\n\nbool sdhci_cqe_irq(struct sdhci_host *host, u32 intmask, int *cmd_error,\n\t\t   int *data_error)\n{\n\tu32 mask;\n\n\tif (!host->cqe_on)\n\t\treturn false;\n\n\tif (intmask & (SDHCI_INT_INDEX | SDHCI_INT_END_BIT | SDHCI_INT_CRC)) {\n\t\t*cmd_error = -EILSEQ;\n\t\tif (!mmc_op_tuning(SDHCI_GET_CMD(sdhci_readw(host, SDHCI_COMMAND))))\n\t\t\tsdhci_err_stats_inc(host, CMD_CRC);\n\t} else if (intmask & SDHCI_INT_TIMEOUT) {\n\t\t*cmd_error = -ETIMEDOUT;\n\t\tsdhci_err_stats_inc(host, CMD_TIMEOUT);\n\t} else\n\t\t*cmd_error = 0;\n\n\tif (intmask & (SDHCI_INT_DATA_END_BIT | SDHCI_INT_DATA_CRC)) {\n\t\t*data_error = -EILSEQ;\n\t\tif (!mmc_op_tuning(SDHCI_GET_CMD(sdhci_readw(host, SDHCI_COMMAND))))\n\t\t\tsdhci_err_stats_inc(host, DAT_CRC);\n\t} else if (intmask & SDHCI_INT_DATA_TIMEOUT) {\n\t\t*data_error = -ETIMEDOUT;\n\t\tsdhci_err_stats_inc(host, DAT_TIMEOUT);\n\t} else if (intmask & SDHCI_INT_ADMA_ERROR) {\n\t\t*data_error = -EIO;\n\t\tsdhci_err_stats_inc(host, ADMA);\n\t} else\n\t\t*data_error = 0;\n\n\t \n\tmask = intmask & host->cqe_ier;\n\tsdhci_writel(host, mask, SDHCI_INT_STATUS);\n\n\tif (intmask & SDHCI_INT_BUS_POWER)\n\t\tpr_err(\"%s: Card is consuming too much power!\\n\",\n\t\t       mmc_hostname(host->mmc));\n\n\tintmask &= ~(host->cqe_ier | SDHCI_INT_ERROR);\n\tif (intmask) {\n\t\tsdhci_writel(host, intmask, SDHCI_INT_STATUS);\n\t\tpr_err(\"%s: CQE: Unexpected interrupt 0x%08x.\\n\",\n\t\t       mmc_hostname(host->mmc), intmask);\n\t\tsdhci_err_stats_inc(host, UNEXPECTED_IRQ);\n\t\tsdhci_dumpregs(host);\n\t}\n\n\treturn true;\n}\nEXPORT_SYMBOL_GPL(sdhci_cqe_irq);\n\n \n\nstruct sdhci_host *sdhci_alloc_host(struct device *dev,\n\tsize_t priv_size)\n{\n\tstruct mmc_host *mmc;\n\tstruct sdhci_host *host;\n\n\tWARN_ON(dev == NULL);\n\n\tmmc = mmc_alloc_host(sizeof(struct sdhci_host) + priv_size, dev);\n\tif (!mmc)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\thost = mmc_priv(mmc);\n\thost->mmc = mmc;\n\thost->mmc_host_ops = sdhci_ops;\n\tmmc->ops = &host->mmc_host_ops;\n\n\thost->flags = SDHCI_SIGNALING_330;\n\n\thost->cqe_ier     = SDHCI_CQE_INT_MASK;\n\thost->cqe_err_ier = SDHCI_CQE_INT_ERR_MASK;\n\n\thost->tuning_delay = -1;\n\thost->tuning_loop_count = MAX_TUNING_LOOP;\n\n\thost->sdma_boundary = SDHCI_DEFAULT_BOUNDARY_ARG;\n\n\t \n\thost->adma_table_cnt = SDHCI_MAX_SEGS * 2 + 1;\n\thost->max_adma = 65536;\n\n\thost->max_timeout_count = 0xE;\n\n\treturn host;\n}\n\nEXPORT_SYMBOL_GPL(sdhci_alloc_host);\n\nstatic int sdhci_set_dma_mask(struct sdhci_host *host)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\tstruct device *dev = mmc_dev(mmc);\n\tint ret = -EINVAL;\n\n\tif (host->quirks2 & SDHCI_QUIRK2_BROKEN_64_BIT_DMA)\n\t\thost->flags &= ~SDHCI_USE_64_BIT_DMA;\n\n\t \n\tif (host->flags & SDHCI_USE_64_BIT_DMA) {\n\t\tret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(64));\n\t\tif (ret) {\n\t\t\tpr_warn(\"%s: Failed to set 64-bit DMA mask.\\n\",\n\t\t\t\tmmc_hostname(mmc));\n\t\t\thost->flags &= ~SDHCI_USE_64_BIT_DMA;\n\t\t}\n\t}\n\n\t \n\tif (ret) {\n\t\tret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));\n\t\tif (ret)\n\t\t\tpr_warn(\"%s: Failed to set 32-bit DMA mask.\\n\",\n\t\t\t\tmmc_hostname(mmc));\n\t}\n\n\treturn ret;\n}\n\nvoid __sdhci_read_caps(struct sdhci_host *host, const u16 *ver,\n\t\t       const u32 *caps, const u32 *caps1)\n{\n\tu16 v;\n\tu64 dt_caps_mask = 0;\n\tu64 dt_caps = 0;\n\n\tif (host->read_caps)\n\t\treturn;\n\n\thost->read_caps = true;\n\n\tif (debug_quirks)\n\t\thost->quirks = debug_quirks;\n\n\tif (debug_quirks2)\n\t\thost->quirks2 = debug_quirks2;\n\n\tsdhci_reset_for_all(host);\n\n\tif (host->v4_mode)\n\t\tsdhci_do_enable_v4_mode(host);\n\n\tdevice_property_read_u64(mmc_dev(host->mmc),\n\t\t\t\t \"sdhci-caps-mask\", &dt_caps_mask);\n\tdevice_property_read_u64(mmc_dev(host->mmc),\n\t\t\t\t \"sdhci-caps\", &dt_caps);\n\n\tv = ver ? *ver : sdhci_readw(host, SDHCI_HOST_VERSION);\n\thost->version = (v & SDHCI_SPEC_VER_MASK) >> SDHCI_SPEC_VER_SHIFT;\n\n\tif (caps) {\n\t\thost->caps = *caps;\n\t} else {\n\t\thost->caps = sdhci_readl(host, SDHCI_CAPABILITIES);\n\t\thost->caps &= ~lower_32_bits(dt_caps_mask);\n\t\thost->caps |= lower_32_bits(dt_caps);\n\t}\n\n\tif (host->version < SDHCI_SPEC_300)\n\t\treturn;\n\n\tif (caps1) {\n\t\thost->caps1 = *caps1;\n\t} else {\n\t\thost->caps1 = sdhci_readl(host, SDHCI_CAPABILITIES_1);\n\t\thost->caps1 &= ~upper_32_bits(dt_caps_mask);\n\t\thost->caps1 |= upper_32_bits(dt_caps);\n\t}\n}\nEXPORT_SYMBOL_GPL(__sdhci_read_caps);\n\nstatic void sdhci_allocate_bounce_buffer(struct sdhci_host *host)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\tunsigned int max_blocks;\n\tunsigned int bounce_size;\n\tint ret;\n\n\t \n\tbounce_size = SZ_64K;\n\t \n\tif (mmc->max_req_size < bounce_size)\n\t\tbounce_size = mmc->max_req_size;\n\tmax_blocks = bounce_size / 512;\n\n\t \n\thost->bounce_buffer = devm_kmalloc(mmc_dev(mmc),\n\t\t\t\t\t   bounce_size,\n\t\t\t\t\t   GFP_KERNEL);\n\tif (!host->bounce_buffer) {\n\t\tpr_err(\"%s: failed to allocate %u bytes for bounce buffer, falling back to single segments\\n\",\n\t\t       mmc_hostname(mmc),\n\t\t       bounce_size);\n\t\t \n\t\treturn;\n\t}\n\n\thost->bounce_addr = dma_map_single(mmc_dev(mmc),\n\t\t\t\t\t   host->bounce_buffer,\n\t\t\t\t\t   bounce_size,\n\t\t\t\t\t   DMA_BIDIRECTIONAL);\n\tret = dma_mapping_error(mmc_dev(mmc), host->bounce_addr);\n\tif (ret) {\n\t\tdevm_kfree(mmc_dev(mmc), host->bounce_buffer);\n\t\thost->bounce_buffer = NULL;\n\t\t \n\t\treturn;\n\t}\n\n\thost->bounce_buffer_size = bounce_size;\n\n\t \n\tmmc->max_segs = max_blocks;\n\tmmc->max_seg_size = bounce_size;\n\tmmc->max_req_size = bounce_size;\n\n\tpr_info(\"%s bounce up to %u segments into one, max segment size %u bytes\\n\",\n\t\tmmc_hostname(mmc), max_blocks, bounce_size);\n}\n\nstatic inline bool sdhci_can_64bit_dma(struct sdhci_host *host)\n{\n\t \n\tif (host->version >= SDHCI_SPEC_410 && host->v4_mode)\n\t\treturn host->caps & SDHCI_CAN_64BIT_V4;\n\n\treturn host->caps & SDHCI_CAN_64BIT;\n}\n\nint sdhci_setup_host(struct sdhci_host *host)\n{\n\tstruct mmc_host *mmc;\n\tu32 max_current_caps;\n\tunsigned int ocr_avail;\n\tunsigned int override_timeout_clk;\n\tu32 max_clk;\n\tint ret = 0;\n\tbool enable_vqmmc = false;\n\n\tWARN_ON(host == NULL);\n\tif (host == NULL)\n\t\treturn -EINVAL;\n\n\tmmc = host->mmc;\n\n\t \n\tif (!mmc->supply.vqmmc) {\n\t\tret = mmc_regulator_get_supply(mmc);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tenable_vqmmc  = true;\n\t}\n\n\tDBG(\"Version:   0x%08x | Present:  0x%08x\\n\",\n\t    sdhci_readw(host, SDHCI_HOST_VERSION),\n\t    sdhci_readl(host, SDHCI_PRESENT_STATE));\n\tDBG(\"Caps:      0x%08x | Caps_1:   0x%08x\\n\",\n\t    sdhci_readl(host, SDHCI_CAPABILITIES),\n\t    sdhci_readl(host, SDHCI_CAPABILITIES_1));\n\n\tsdhci_read_caps(host);\n\n\toverride_timeout_clk = host->timeout_clk;\n\n\tif (host->version > SDHCI_SPEC_420) {\n\t\tpr_err(\"%s: Unknown controller version (%d). You may experience problems.\\n\",\n\t\t       mmc_hostname(mmc), host->version);\n\t}\n\n\tif (host->quirks & SDHCI_QUIRK_FORCE_DMA)\n\t\thost->flags |= SDHCI_USE_SDMA;\n\telse if (!(host->caps & SDHCI_CAN_DO_SDMA))\n\t\tDBG(\"Controller doesn't have SDMA capability\\n\");\n\telse\n\t\thost->flags |= SDHCI_USE_SDMA;\n\n\tif ((host->quirks & SDHCI_QUIRK_BROKEN_DMA) &&\n\t\t(host->flags & SDHCI_USE_SDMA)) {\n\t\tDBG(\"Disabling DMA as it is marked broken\\n\");\n\t\thost->flags &= ~SDHCI_USE_SDMA;\n\t}\n\n\tif ((host->version >= SDHCI_SPEC_200) &&\n\t\t(host->caps & SDHCI_CAN_DO_ADMA2))\n\t\thost->flags |= SDHCI_USE_ADMA;\n\n\tif ((host->quirks & SDHCI_QUIRK_BROKEN_ADMA) &&\n\t\t(host->flags & SDHCI_USE_ADMA)) {\n\t\tDBG(\"Disabling ADMA as it is marked broken\\n\");\n\t\thost->flags &= ~SDHCI_USE_ADMA;\n\t}\n\n\tif (sdhci_can_64bit_dma(host))\n\t\thost->flags |= SDHCI_USE_64_BIT_DMA;\n\n\tif (host->use_external_dma) {\n\t\tret = sdhci_external_dma_init(host);\n\t\tif (ret == -EPROBE_DEFER)\n\t\t\tgoto unreg;\n\t\t \n\t\telse if (ret)\n\t\t\tsdhci_switch_external_dma(host, false);\n\t\t \n\t\telse\n\t\t\thost->flags &= ~(SDHCI_USE_SDMA | SDHCI_USE_ADMA);\n\t}\n\n\tif (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {\n\t\tif (host->ops->set_dma_mask)\n\t\t\tret = host->ops->set_dma_mask(host);\n\t\telse\n\t\t\tret = sdhci_set_dma_mask(host);\n\n\t\tif (!ret && host->ops->enable_dma)\n\t\t\tret = host->ops->enable_dma(host);\n\n\t\tif (ret) {\n\t\t\tpr_warn(\"%s: No suitable DMA available - falling back to PIO\\n\",\n\t\t\t\tmmc_hostname(mmc));\n\t\t\thost->flags &= ~(SDHCI_USE_SDMA | SDHCI_USE_ADMA);\n\n\t\t\tret = 0;\n\t\t}\n\t}\n\n\t \n\tif ((host->flags & SDHCI_USE_64_BIT_DMA) && !host->v4_mode)\n\t\thost->flags &= ~SDHCI_USE_SDMA;\n\n\tif (host->flags & SDHCI_USE_ADMA) {\n\t\tdma_addr_t dma;\n\t\tvoid *buf;\n\n\t\tif (!(host->flags & SDHCI_USE_64_BIT_DMA))\n\t\t\thost->alloc_desc_sz = SDHCI_ADMA2_32_DESC_SZ;\n\t\telse if (!host->alloc_desc_sz)\n\t\t\thost->alloc_desc_sz = SDHCI_ADMA2_64_DESC_SZ(host);\n\n\t\thost->desc_sz = host->alloc_desc_sz;\n\t\thost->adma_table_sz = host->adma_table_cnt * host->desc_sz;\n\n\t\thost->align_buffer_sz = SDHCI_MAX_SEGS * SDHCI_ADMA2_ALIGN;\n\t\t \n\t\tbuf = dma_alloc_coherent(mmc_dev(mmc),\n\t\t\t\t\t host->align_buffer_sz + host->adma_table_sz,\n\t\t\t\t\t &dma, GFP_KERNEL);\n\t\tif (!buf) {\n\t\t\tpr_warn(\"%s: Unable to allocate ADMA buffers - falling back to standard DMA\\n\",\n\t\t\t\tmmc_hostname(mmc));\n\t\t\thost->flags &= ~SDHCI_USE_ADMA;\n\t\t} else if ((dma + host->align_buffer_sz) &\n\t\t\t   (SDHCI_ADMA2_DESC_ALIGN - 1)) {\n\t\t\tpr_warn(\"%s: unable to allocate aligned ADMA descriptor\\n\",\n\t\t\t\tmmc_hostname(mmc));\n\t\t\thost->flags &= ~SDHCI_USE_ADMA;\n\t\t\tdma_free_coherent(mmc_dev(mmc), host->align_buffer_sz +\n\t\t\t\t\t  host->adma_table_sz, buf, dma);\n\t\t} else {\n\t\t\thost->align_buffer = buf;\n\t\t\thost->align_addr = dma;\n\n\t\t\thost->adma_table = buf + host->align_buffer_sz;\n\t\t\thost->adma_addr = dma + host->align_buffer_sz;\n\t\t}\n\t}\n\n\t \n\tif (!(host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA))) {\n\t\thost->dma_mask = DMA_BIT_MASK(64);\n\t\tmmc_dev(mmc)->dma_mask = &host->dma_mask;\n\t}\n\n\tif (host->version >= SDHCI_SPEC_300)\n\t\thost->max_clk = FIELD_GET(SDHCI_CLOCK_V3_BASE_MASK, host->caps);\n\telse\n\t\thost->max_clk = FIELD_GET(SDHCI_CLOCK_BASE_MASK, host->caps);\n\n\thost->max_clk *= 1000000;\n\tif (host->max_clk == 0 || host->quirks &\n\t\t\tSDHCI_QUIRK_CAP_CLOCK_BASE_BROKEN) {\n\t\tif (!host->ops->get_max_clock) {\n\t\t\tpr_err(\"%s: Hardware doesn't specify base clock frequency.\\n\",\n\t\t\t       mmc_hostname(mmc));\n\t\t\tret = -ENODEV;\n\t\t\tgoto undma;\n\t\t}\n\t\thost->max_clk = host->ops->get_max_clock(host);\n\t}\n\n\t \n\thost->clk_mul = FIELD_GET(SDHCI_CLOCK_MUL_MASK, host->caps1);\n\n\t \n\tif (host->clk_mul)\n\t\thost->clk_mul += 1;\n\n\t \n\tmax_clk = host->max_clk;\n\n\tif (host->ops->get_min_clock)\n\t\tmmc->f_min = host->ops->get_min_clock(host);\n\telse if (host->version >= SDHCI_SPEC_300) {\n\t\tif (host->clk_mul)\n\t\t\tmax_clk = host->max_clk * host->clk_mul;\n\t\t \n\t\tmmc->f_min = host->max_clk / SDHCI_MAX_DIV_SPEC_300;\n\t} else\n\t\tmmc->f_min = host->max_clk / SDHCI_MAX_DIV_SPEC_200;\n\n\tif (!mmc->f_max || mmc->f_max > max_clk)\n\t\tmmc->f_max = max_clk;\n\n\tif (!(host->quirks & SDHCI_QUIRK_DATA_TIMEOUT_USES_SDCLK)) {\n\t\thost->timeout_clk = FIELD_GET(SDHCI_TIMEOUT_CLK_MASK, host->caps);\n\n\t\tif (host->caps & SDHCI_TIMEOUT_CLK_UNIT)\n\t\t\thost->timeout_clk *= 1000;\n\n\t\tif (host->timeout_clk == 0) {\n\t\t\tif (!host->ops->get_timeout_clock) {\n\t\t\t\tpr_err(\"%s: Hardware doesn't specify timeout clock frequency.\\n\",\n\t\t\t\t\tmmc_hostname(mmc));\n\t\t\t\tret = -ENODEV;\n\t\t\t\tgoto undma;\n\t\t\t}\n\n\t\t\thost->timeout_clk =\n\t\t\t\tDIV_ROUND_UP(host->ops->get_timeout_clock(host),\n\t\t\t\t\t     1000);\n\t\t}\n\n\t\tif (override_timeout_clk)\n\t\t\thost->timeout_clk = override_timeout_clk;\n\n\t\tmmc->max_busy_timeout = host->ops->get_max_timeout_count ?\n\t\t\thost->ops->get_max_timeout_count(host) : 1 << 27;\n\t\tmmc->max_busy_timeout /= host->timeout_clk;\n\t}\n\n\tif (host->quirks2 & SDHCI_QUIRK2_DISABLE_HW_TIMEOUT &&\n\t    !host->ops->get_max_timeout_count)\n\t\tmmc->max_busy_timeout = 0;\n\n\tmmc->caps |= MMC_CAP_SDIO_IRQ | MMC_CAP_CMD23;\n\tmmc->caps2 |= MMC_CAP2_SDIO_IRQ_NOTHREAD;\n\n\tif (host->quirks & SDHCI_QUIRK_MULTIBLOCK_READ_ACMD12)\n\t\thost->flags |= SDHCI_AUTO_CMD12;\n\n\t \n\tif ((host->version >= SDHCI_SPEC_300) &&\n\t    ((host->flags & SDHCI_USE_ADMA) ||\n\t     !(host->flags & SDHCI_USE_SDMA) || host->v4_mode) &&\n\t     !(host->quirks2 & SDHCI_QUIRK2_ACMD23_BROKEN)) {\n\t\thost->flags |= SDHCI_AUTO_CMD23;\n\t\tDBG(\"Auto-CMD23 available\\n\");\n\t} else {\n\t\tDBG(\"Auto-CMD23 unavailable\\n\");\n\t}\n\n\t \n\tif (!(host->quirks & SDHCI_QUIRK_FORCE_1_BIT_DATA))\n\t\tmmc->caps |= MMC_CAP_4_BIT_DATA;\n\n\tif (host->quirks2 & SDHCI_QUIRK2_HOST_NO_CMD23)\n\t\tmmc->caps &= ~MMC_CAP_CMD23;\n\n\tif (host->caps & SDHCI_CAN_DO_HISPD)\n\t\tmmc->caps |= MMC_CAP_SD_HIGHSPEED | MMC_CAP_MMC_HIGHSPEED;\n\n\tif ((host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) &&\n\t    mmc_card_is_removable(mmc) &&\n\t    mmc_gpio_get_cd(mmc) < 0)\n\t\tmmc->caps |= MMC_CAP_NEEDS_POLL;\n\n\tif (!IS_ERR(mmc->supply.vqmmc)) {\n\t\tif (enable_vqmmc) {\n\t\t\tret = regulator_enable(mmc->supply.vqmmc);\n\t\t\thost->sdhci_core_to_disable_vqmmc = !ret;\n\t\t}\n\n\t\t \n\t\tif (!regulator_is_supported_voltage(mmc->supply.vqmmc, 1700000,\n\t\t\t\t\t\t    1950000))\n\t\t\thost->caps1 &= ~(SDHCI_SUPPORT_SDR104 |\n\t\t\t\t\t SDHCI_SUPPORT_SDR50 |\n\t\t\t\t\t SDHCI_SUPPORT_DDR50);\n\n\t\t \n\t\tif (!regulator_is_supported_voltage(mmc->supply.vqmmc, 2700000,\n\t\t\t\t\t\t    3600000))\n\t\t\thost->flags &= ~SDHCI_SIGNALING_330;\n\n\t\tif (ret) {\n\t\t\tpr_warn(\"%s: Failed to enable vqmmc regulator: %d\\n\",\n\t\t\t\tmmc_hostname(mmc), ret);\n\t\t\tmmc->supply.vqmmc = ERR_PTR(-EINVAL);\n\t\t}\n\n\t}\n\n\tif (host->quirks2 & SDHCI_QUIRK2_NO_1_8_V) {\n\t\thost->caps1 &= ~(SDHCI_SUPPORT_SDR104 | SDHCI_SUPPORT_SDR50 |\n\t\t\t\t SDHCI_SUPPORT_DDR50);\n\t\t \n\t\tmmc->caps2 &= ~(MMC_CAP2_HSX00_1_8V | MMC_CAP2_HS400_ES);\n\t\tmmc->caps &= ~(MMC_CAP_1_8V_DDR | MMC_CAP_UHS);\n\t}\n\n\t \n\tif (host->caps1 & (SDHCI_SUPPORT_SDR104 | SDHCI_SUPPORT_SDR50 |\n\t\t\t   SDHCI_SUPPORT_DDR50))\n\t\tmmc->caps |= MMC_CAP_UHS_SDR12 | MMC_CAP_UHS_SDR25;\n\n\t \n\tif (host->caps1 & SDHCI_SUPPORT_SDR104) {\n\t\tmmc->caps |= MMC_CAP_UHS_SDR104 | MMC_CAP_UHS_SDR50;\n\t\t \n\t\tif (!(host->quirks2 & SDHCI_QUIRK2_BROKEN_HS200))\n\t\t\tmmc->caps2 |= MMC_CAP2_HS200;\n\t} else if (host->caps1 & SDHCI_SUPPORT_SDR50) {\n\t\tmmc->caps |= MMC_CAP_UHS_SDR50;\n\t}\n\n\tif (host->quirks2 & SDHCI_QUIRK2_CAPS_BIT63_FOR_HS400 &&\n\t    (host->caps1 & SDHCI_SUPPORT_HS400))\n\t\tmmc->caps2 |= MMC_CAP2_HS400;\n\n\tif ((mmc->caps2 & MMC_CAP2_HSX00_1_2V) &&\n\t    (IS_ERR(mmc->supply.vqmmc) ||\n\t     !regulator_is_supported_voltage(mmc->supply.vqmmc, 1100000,\n\t\t\t\t\t     1300000)))\n\t\tmmc->caps2 &= ~MMC_CAP2_HSX00_1_2V;\n\n\tif ((host->caps1 & SDHCI_SUPPORT_DDR50) &&\n\t    !(host->quirks2 & SDHCI_QUIRK2_BROKEN_DDR50))\n\t\tmmc->caps |= MMC_CAP_UHS_DDR50;\n\n\t \n\tif (host->caps1 & SDHCI_USE_SDR50_TUNING)\n\t\thost->flags |= SDHCI_SDR50_NEEDS_TUNING;\n\n\t \n\tif (host->caps1 & SDHCI_DRIVER_TYPE_A)\n\t\tmmc->caps |= MMC_CAP_DRIVER_TYPE_A;\n\tif (host->caps1 & SDHCI_DRIVER_TYPE_C)\n\t\tmmc->caps |= MMC_CAP_DRIVER_TYPE_C;\n\tif (host->caps1 & SDHCI_DRIVER_TYPE_D)\n\t\tmmc->caps |= MMC_CAP_DRIVER_TYPE_D;\n\n\t \n\thost->tuning_count = FIELD_GET(SDHCI_RETUNING_TIMER_COUNT_MASK,\n\t\t\t\t       host->caps1);\n\n\t \n\tif (host->tuning_count)\n\t\thost->tuning_count = 1 << (host->tuning_count - 1);\n\n\t \n\thost->tuning_mode = FIELD_GET(SDHCI_RETUNING_MODE_MASK, host->caps1);\n\n\tocr_avail = 0;\n\n\t \n\tmax_current_caps = sdhci_readl(host, SDHCI_MAX_CURRENT);\n\tif (!max_current_caps && !IS_ERR(mmc->supply.vmmc)) {\n\t\tint curr = regulator_get_current_limit(mmc->supply.vmmc);\n\t\tif (curr > 0) {\n\n\t\t\t \n\t\t\tcurr = curr/1000;   \n\t\t\tcurr = curr/SDHCI_MAX_CURRENT_MULTIPLIER;\n\n\t\t\tcurr = min_t(u32, curr, SDHCI_MAX_CURRENT_LIMIT);\n\t\t\tmax_current_caps =\n\t\t\t\tFIELD_PREP(SDHCI_MAX_CURRENT_330_MASK, curr) |\n\t\t\t\tFIELD_PREP(SDHCI_MAX_CURRENT_300_MASK, curr) |\n\t\t\t\tFIELD_PREP(SDHCI_MAX_CURRENT_180_MASK, curr);\n\t\t}\n\t}\n\n\tif (host->caps & SDHCI_CAN_VDD_330) {\n\t\tocr_avail |= MMC_VDD_32_33 | MMC_VDD_33_34;\n\n\t\tmmc->max_current_330 = FIELD_GET(SDHCI_MAX_CURRENT_330_MASK,\n\t\t\t\t\t\t max_current_caps) *\n\t\t\t\t\t\tSDHCI_MAX_CURRENT_MULTIPLIER;\n\t}\n\tif (host->caps & SDHCI_CAN_VDD_300) {\n\t\tocr_avail |= MMC_VDD_29_30 | MMC_VDD_30_31;\n\n\t\tmmc->max_current_300 = FIELD_GET(SDHCI_MAX_CURRENT_300_MASK,\n\t\t\t\t\t\t max_current_caps) *\n\t\t\t\t\t\tSDHCI_MAX_CURRENT_MULTIPLIER;\n\t}\n\tif (host->caps & SDHCI_CAN_VDD_180) {\n\t\tocr_avail |= MMC_VDD_165_195;\n\n\t\tmmc->max_current_180 = FIELD_GET(SDHCI_MAX_CURRENT_180_MASK,\n\t\t\t\t\t\t max_current_caps) *\n\t\t\t\t\t\tSDHCI_MAX_CURRENT_MULTIPLIER;\n\t}\n\n\t \n\tif (host->ocr_mask)\n\t\tocr_avail = host->ocr_mask;\n\n\t \n\tif (mmc->ocr_avail)\n\t\tocr_avail = mmc->ocr_avail;\n\n\tmmc->ocr_avail = ocr_avail;\n\tmmc->ocr_avail_sdio = ocr_avail;\n\tif (host->ocr_avail_sdio)\n\t\tmmc->ocr_avail_sdio &= host->ocr_avail_sdio;\n\tmmc->ocr_avail_sd = ocr_avail;\n\tif (host->ocr_avail_sd)\n\t\tmmc->ocr_avail_sd &= host->ocr_avail_sd;\n\telse  \n\t\tmmc->ocr_avail_sd &= ~MMC_VDD_165_195;\n\tmmc->ocr_avail_mmc = ocr_avail;\n\tif (host->ocr_avail_mmc)\n\t\tmmc->ocr_avail_mmc &= host->ocr_avail_mmc;\n\n\tif (mmc->ocr_avail == 0) {\n\t\tpr_err(\"%s: Hardware doesn't report any support voltages.\\n\",\n\t\t       mmc_hostname(mmc));\n\t\tret = -ENODEV;\n\t\tgoto unreg;\n\t}\n\n\tif ((mmc->caps & (MMC_CAP_UHS_SDR12 | MMC_CAP_UHS_SDR25 |\n\t\t\t  MMC_CAP_UHS_SDR50 | MMC_CAP_UHS_SDR104 |\n\t\t\t  MMC_CAP_UHS_DDR50 | MMC_CAP_1_8V_DDR)) ||\n\t    (mmc->caps2 & (MMC_CAP2_HS200_1_8V_SDR | MMC_CAP2_HS400_1_8V)))\n\t\thost->flags |= SDHCI_SIGNALING_180;\n\n\tif (mmc->caps2 & MMC_CAP2_HSX00_1_2V)\n\t\thost->flags |= SDHCI_SIGNALING_120;\n\n\tspin_lock_init(&host->lock);\n\n\t \n\tmmc->max_req_size = 524288;\n\n\t \n\tif (host->flags & SDHCI_USE_ADMA) {\n\t\tmmc->max_segs = SDHCI_MAX_SEGS;\n\t} else if (host->flags & SDHCI_USE_SDMA) {\n\t\tmmc->max_segs = 1;\n\t\tmmc->max_req_size = min_t(size_t, mmc->max_req_size,\n\t\t\t\t\t  dma_max_mapping_size(mmc_dev(mmc)));\n\t} else {  \n\t\tmmc->max_segs = SDHCI_MAX_SEGS;\n\t}\n\n\t \n\tif (host->flags & SDHCI_USE_ADMA) {\n\t\tif (host->quirks & SDHCI_QUIRK_BROKEN_ADMA_ZEROLEN_DESC) {\n\t\t\thost->max_adma = 65532;  \n\t\t\tmmc->max_seg_size = 65535;\n\t\t} else {\n\t\t\tmmc->max_seg_size = 65536;\n\t\t}\n\t} else {\n\t\tmmc->max_seg_size = mmc->max_req_size;\n\t}\n\n\t \n\tif (host->quirks & SDHCI_QUIRK_FORCE_BLK_SZ_2048) {\n\t\tmmc->max_blk_size = 2;\n\t} else {\n\t\tmmc->max_blk_size = (host->caps & SDHCI_MAX_BLOCK_MASK) >>\n\t\t\t\tSDHCI_MAX_BLOCK_SHIFT;\n\t\tif (mmc->max_blk_size >= 3) {\n\t\t\tpr_warn(\"%s: Invalid maximum block size, assuming 512 bytes\\n\",\n\t\t\t\tmmc_hostname(mmc));\n\t\t\tmmc->max_blk_size = 0;\n\t\t}\n\t}\n\n\tmmc->max_blk_size = 512 << mmc->max_blk_size;\n\n\t \n\tmmc->max_blk_count = (host->quirks & SDHCI_QUIRK_NO_MULTIBLOCK) ? 1 : 65535;\n\n\tif (mmc->max_segs == 1)\n\t\t \n\t\tsdhci_allocate_bounce_buffer(host);\n\n\treturn 0;\n\nunreg:\n\tif (host->sdhci_core_to_disable_vqmmc)\n\t\tregulator_disable(mmc->supply.vqmmc);\nundma:\n\tif (host->align_buffer)\n\t\tdma_free_coherent(mmc_dev(mmc), host->align_buffer_sz +\n\t\t\t\t  host->adma_table_sz, host->align_buffer,\n\t\t\t\t  host->align_addr);\n\thost->adma_table = NULL;\n\thost->align_buffer = NULL;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(sdhci_setup_host);\n\nvoid sdhci_cleanup_host(struct sdhci_host *host)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\n\tif (host->sdhci_core_to_disable_vqmmc)\n\t\tregulator_disable(mmc->supply.vqmmc);\n\n\tif (host->align_buffer)\n\t\tdma_free_coherent(mmc_dev(mmc), host->align_buffer_sz +\n\t\t\t\t  host->adma_table_sz, host->align_buffer,\n\t\t\t\t  host->align_addr);\n\n\tif (host->use_external_dma)\n\t\tsdhci_external_dma_release(host);\n\n\thost->adma_table = NULL;\n\thost->align_buffer = NULL;\n}\nEXPORT_SYMBOL_GPL(sdhci_cleanup_host);\n\nint __sdhci_add_host(struct sdhci_host *host)\n{\n\tunsigned int flags = WQ_UNBOUND | WQ_MEM_RECLAIM | WQ_HIGHPRI;\n\tstruct mmc_host *mmc = host->mmc;\n\tint ret;\n\n\tif ((mmc->caps2 & MMC_CAP2_CQE) &&\n\t    (host->quirks & SDHCI_QUIRK_BROKEN_CQE)) {\n\t\tmmc->caps2 &= ~MMC_CAP2_CQE;\n\t\tmmc->cqe_ops = NULL;\n\t}\n\n\thost->complete_wq = alloc_workqueue(\"sdhci\", flags, 0);\n\tif (!host->complete_wq)\n\t\treturn -ENOMEM;\n\n\tINIT_WORK(&host->complete_work, sdhci_complete_work);\n\n\ttimer_setup(&host->timer, sdhci_timeout_timer, 0);\n\ttimer_setup(&host->data_timer, sdhci_timeout_data_timer, 0);\n\n\tinit_waitqueue_head(&host->buf_ready_int);\n\n\tsdhci_init(host, 0);\n\n\tret = request_threaded_irq(host->irq, sdhci_irq, sdhci_thread_irq,\n\t\t\t\t   IRQF_SHARED,\tmmc_hostname(mmc), host);\n\tif (ret) {\n\t\tpr_err(\"%s: Failed to request IRQ %d: %d\\n\",\n\t\t       mmc_hostname(mmc), host->irq, ret);\n\t\tgoto unwq;\n\t}\n\n\tret = sdhci_led_register(host);\n\tif (ret) {\n\t\tpr_err(\"%s: Failed to register LED device: %d\\n\",\n\t\t       mmc_hostname(mmc), ret);\n\t\tgoto unirq;\n\t}\n\n\tret = mmc_add_host(mmc);\n\tif (ret)\n\t\tgoto unled;\n\n\tpr_info(\"%s: SDHCI controller on %s [%s] using %s\\n\",\n\t\tmmc_hostname(mmc), host->hw_name, dev_name(mmc_dev(mmc)),\n\t\thost->use_external_dma ? \"External DMA\" :\n\t\t(host->flags & SDHCI_USE_ADMA) ?\n\t\t(host->flags & SDHCI_USE_64_BIT_DMA) ? \"ADMA 64-bit\" : \"ADMA\" :\n\t\t(host->flags & SDHCI_USE_SDMA) ? \"DMA\" : \"PIO\");\n\n\tsdhci_enable_card_detection(host);\n\n\treturn 0;\n\nunled:\n\tsdhci_led_unregister(host);\nunirq:\n\tsdhci_reset_for_all(host);\n\tsdhci_writel(host, 0, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);\n\tfree_irq(host->irq, host);\nunwq:\n\tdestroy_workqueue(host->complete_wq);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(__sdhci_add_host);\n\nint sdhci_add_host(struct sdhci_host *host)\n{\n\tint ret;\n\n\tret = sdhci_setup_host(host);\n\tif (ret)\n\t\treturn ret;\n\n\tret = __sdhci_add_host(host);\n\tif (ret)\n\t\tgoto cleanup;\n\n\treturn 0;\n\ncleanup:\n\tsdhci_cleanup_host(host);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(sdhci_add_host);\n\nvoid sdhci_remove_host(struct sdhci_host *host, int dead)\n{\n\tstruct mmc_host *mmc = host->mmc;\n\tunsigned long flags;\n\n\tif (dead) {\n\t\tspin_lock_irqsave(&host->lock, flags);\n\n\t\thost->flags |= SDHCI_DEVICE_DEAD;\n\n\t\tif (sdhci_has_requests(host)) {\n\t\t\tpr_err(\"%s: Controller removed during \"\n\t\t\t\t\" transfer!\\n\", mmc_hostname(mmc));\n\t\t\tsdhci_error_out_mrqs(host, -ENOMEDIUM);\n\t\t}\n\n\t\tspin_unlock_irqrestore(&host->lock, flags);\n\t}\n\n\tsdhci_disable_card_detection(host);\n\n\tmmc_remove_host(mmc);\n\n\tsdhci_led_unregister(host);\n\n\tif (!dead)\n\t\tsdhci_reset_for_all(host);\n\n\tsdhci_writel(host, 0, SDHCI_INT_ENABLE);\n\tsdhci_writel(host, 0, SDHCI_SIGNAL_ENABLE);\n\tfree_irq(host->irq, host);\n\n\tdel_timer_sync(&host->timer);\n\tdel_timer_sync(&host->data_timer);\n\n\tdestroy_workqueue(host->complete_wq);\n\n\tif (host->sdhci_core_to_disable_vqmmc)\n\t\tregulator_disable(mmc->supply.vqmmc);\n\n\tif (host->align_buffer)\n\t\tdma_free_coherent(mmc_dev(mmc), host->align_buffer_sz +\n\t\t\t\t  host->adma_table_sz, host->align_buffer,\n\t\t\t\t  host->align_addr);\n\n\tif (host->use_external_dma)\n\t\tsdhci_external_dma_release(host);\n\n\thost->adma_table = NULL;\n\thost->align_buffer = NULL;\n}\n\nEXPORT_SYMBOL_GPL(sdhci_remove_host);\n\nvoid sdhci_free_host(struct sdhci_host *host)\n{\n\tmmc_free_host(host->mmc);\n}\n\nEXPORT_SYMBOL_GPL(sdhci_free_host);\n\n \n\nstatic int __init sdhci_drv_init(void)\n{\n\tpr_info(DRIVER_NAME\n\t\t\": Secure Digital Host Controller Interface driver\\n\");\n\tpr_info(DRIVER_NAME \": Copyright(c) Pierre Ossman\\n\");\n\n\treturn 0;\n}\n\nstatic void __exit sdhci_drv_exit(void)\n{\n}\n\nmodule_init(sdhci_drv_init);\nmodule_exit(sdhci_drv_exit);\n\nmodule_param(debug_quirks, uint, 0444);\nmodule_param(debug_quirks2, uint, 0444);\n\nMODULE_AUTHOR(\"Pierre Ossman <pierre@ossman.eu>\");\nMODULE_DESCRIPTION(\"Secure Digital Host Controller Interface core driver\");\nMODULE_LICENSE(\"GPL\");\n\nMODULE_PARM_DESC(debug_quirks, \"Force certain quirks.\");\nMODULE_PARM_DESC(debug_quirks2, \"Force certain other quirks.\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}