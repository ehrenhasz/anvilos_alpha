{
  "module_name": "qaic.h",
  "hash_id": "fc14ea3e885543664ccb2d9140b2a263962a33fce717b4df39bf3412abbdef27",
  "original_prompt": "Ingested from linux-6.6.14/drivers/accel/qaic/qaic.h",
  "human_readable_source": " \n\n#ifndef _QAIC_H_\n#define _QAIC_H_\n\n#include <linux/interrupt.h>\n#include <linux/kref.h>\n#include <linux/mhi.h>\n#include <linux/mutex.h>\n#include <linux/pci.h>\n#include <linux/spinlock.h>\n#include <linux/srcu.h>\n#include <linux/wait.h>\n#include <linux/workqueue.h>\n#include <drm/drm_device.h>\n#include <drm/drm_gem.h>\n\n#define QAIC_DBC_BASE\t\tSZ_128K\n#define QAIC_DBC_SIZE\t\tSZ_4K\n\n#define QAIC_NO_PARTITION\t-1\n\n#define QAIC_DBC_OFF(i)\t\t((i) * QAIC_DBC_SIZE + QAIC_DBC_BASE)\n\n#define to_qaic_bo(obj) container_of(obj, struct qaic_bo, base)\n\nextern bool datapath_polling;\n\nstruct qaic_user {\n\t \n\tint\t\t\thandle;\n\tstruct kref\t\tref_count;\n\t \n\tstruct qaic_drm_device\t*qddev;\n\t \n\tstruct list_head\tnode;\n\t \n\tstruct srcu_struct\tqddev_lock;\n\tatomic_t\t\tchunk_id;\n};\n\nstruct dma_bridge_chan {\n\t \n\tstruct qaic_device\t*qdev;\n\t \n\tunsigned int\t\tid;\n\t \n\tspinlock_t\t\txfer_lock;\n\t \n\tvoid\t\t\t*req_q_base;\n\t \n\tvoid\t\t\t*rsp_q_base;\n\t \n\tdma_addr_t\t\tdma_addr;\n\t \n\tu32\t\t\ttotal_size;\n\t \n\tu32\t\t\tnelem;\n\t \n\tstruct qaic_user\t*usr;\n\t \n\tu16\t\t\tnext_req_id;\n\t \n\tbool\t\t\tin_use;\n\t \n\tvoid __iomem\t\t*dbc_base;\n\t \n\tstruct list_head\txfer_list;\n\t \n\tstruct srcu_struct\tch_lock;\n\t \n\twait_queue_head_t\tdbc_release;\n\t \n\tstruct list_head\tbo_lists;\n\t \n\tunsigned int\t\tirq;\n\t \n\tstruct work_struct\tpoll_work;\n};\n\nstruct qaic_device {\n\t \n\tstruct pci_dev\t\t*pdev;\n\t \n\tu32\t\t\tnext_seq_num;\n\t \n\tvoid __iomem\t\t*bar_0;\n\t \n\tvoid __iomem\t\t*bar_2;\n\t \n\tstruct mhi_controller\t*mhi_cntrl;\n\t \n\tstruct mhi_device\t*cntl_ch;\n\t \n\tstruct list_head\tcntl_xfer_list;\n\t \n\tstruct mutex\t\tcntl_mutex;\n\t \n\tstruct dma_bridge_chan\t*dbc;\n\t \n\tstruct workqueue_struct\t*cntl_wq;\n\t \n\tstruct srcu_struct\tdev_lock;\n\t \n\tbool\t\t\tin_reset;\n\t \n\tbool\t\t\tcntl_lost_buf;\n\t \n\tu32\t\t\tnum_dbc;\n\t \n\tstruct qaic_drm_device\t*qddev;\n\t \n\tu32 (*gen_crc)(void *msg);\n\t \n\tbool (*valid_crc)(void *msg);\n};\n\nstruct qaic_drm_device {\n\t \n\tstruct qaic_device\t*qdev;\n\t \n\ts32\t\t\tpartition_id;\n\t \n\tstruct drm_device\t*ddev;\n\t \n\tstruct list_head\tusers;\n\t \n\tstruct mutex\t\tusers_mutex;\n};\n\nstruct qaic_bo {\n\tstruct drm_gem_object\tbase;\n\t \n\tstruct sg_table\t\t*sgt;\n\t \n\tu64\t\t\tsize;\n\t \n\tstruct list_head\tslices;\n\t \n\tint\t\t\ttotal_slice_nents;\n\t \n\tint\t\t\tdir;\n\t \n\tstruct dma_bridge_chan\t*dbc;\n\t \n\tu32\t\t\tnr_slice;\n\t \n\tu32\t\t\tnr_slice_xfer_done;\n\t \n\tbool\t\t\tqueued;\n\t \n\tbool\t\t\tsliced;\n\t \n\tu16\t\t\treq_id;\n\t \n\tu32\t\t\thandle;\n\t \n\tstruct completion\txfer_done;\n\t \n\tstruct list_head\txfer_list;\n\t \n\tstruct list_head\tbo_list;\n\tstruct {\n\t\t \n\t\tu64\t\treq_received_ts;\n\t\t \n\t\tu64\t\treq_submit_ts;\n\t\t \n\t\tu64\t\treq_processed_ts;\n\t\t \n\t\tu32\t\tqueue_level_before;\n\t} perf_stats;\n\n};\n\nstruct bo_slice {\n\t \n\tstruct sg_table\t\t*sgt;\n\t \n\tint\t\t\tnents;\n\t \n\tint\t\t\tdir;\n\t \n\tstruct dbc_req\t\t*reqs;\n\tstruct kref\t\tref_count;\n\t \n\tbool\t\t\tno_xfer;\n\t \n\tstruct qaic_bo\t\t*bo;\n\t \n\tstruct list_head\tslice;\n\t \n\tu64\t\t\tsize;\n\t \n\tu64\t\t\toffset;\n};\n\nint get_dbc_req_elem_size(void);\nint get_dbc_rsp_elem_size(void);\nint get_cntl_version(struct qaic_device *qdev, struct qaic_user *usr, u16 *major, u16 *minor);\nint qaic_manage_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nvoid qaic_mhi_ul_xfer_cb(struct mhi_device *mhi_dev, struct mhi_result *mhi_result);\n\nvoid qaic_mhi_dl_xfer_cb(struct mhi_device *mhi_dev, struct mhi_result *mhi_result);\n\nint qaic_control_open(struct qaic_device *qdev);\nvoid qaic_control_close(struct qaic_device *qdev);\nvoid qaic_release_usr(struct qaic_device *qdev, struct qaic_user *usr);\n\nirqreturn_t dbc_irq_threaded_fn(int irq, void *data);\nirqreturn_t dbc_irq_handler(int irq, void *data);\nint disable_dbc(struct qaic_device *qdev, u32 dbc_id, struct qaic_user *usr);\nvoid enable_dbc(struct qaic_device *qdev, u32 dbc_id, struct qaic_user *usr);\nvoid wakeup_dbc(struct qaic_device *qdev, u32 dbc_id);\nvoid release_dbc(struct qaic_device *qdev, u32 dbc_id);\n\nvoid wake_all_cntl(struct qaic_device *qdev);\nvoid qaic_dev_reset_clean_local_state(struct qaic_device *qdev, bool exit_reset);\n\nstruct drm_gem_object *qaic_gem_prime_import(struct drm_device *dev, struct dma_buf *dma_buf);\n\nint qaic_create_bo_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nint qaic_mmap_bo_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nint qaic_attach_slice_bo_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nint qaic_execute_bo_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nint qaic_partial_execute_bo_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nint qaic_wait_bo_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nint qaic_perf_stats_bo_ioctl(struct drm_device *dev, void *data, struct drm_file *file_priv);\nvoid irq_polling_work(struct work_struct *work);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}