{
  "module_name": "mmu_v2_hr.c",
  "hash_id": "6cd1f5e0b1f1d19139bbaae62f846546ba0a52b43ab8c1ef943a2745de802a31",
  "original_prompt": "Ingested from linux-6.6.14/drivers/accel/habanalabs/common/mmu/mmu_v2_hr.c",
  "human_readable_source": "\n\n \n\n#include \"../habanalabs.h\"\n#include \"../../include/hw_ip/mmu/mmu_general.h\"\n\n#include <linux/slab.h>\n\nstatic struct pgt_info *hl_mmu_v2_hr_get_pgt_info(struct hl_ctx *ctx, u64 phys_hop_addr)\n{\n\tstruct pgt_info *pgt_info = NULL;\n\n\thash_for_each_possible(ctx->hr_mmu_phys_hash, pgt_info, node,\n\t\t\t\t(unsigned long) phys_hop_addr)\n\t\tif (phys_hop_addr == pgt_info->phys_addr)\n\t\t\tbreak;\n\n\treturn pgt_info;\n}\n\nstatic void hl_mmu_v2_hr_add_pgt_info(struct hl_ctx *ctx, struct pgt_info *pgt_info,\n\t\t\t\t\tdma_addr_t phys_addr)\n{\n\thash_add(ctx->hr_mmu_phys_hash, &pgt_info->node, phys_addr);\n}\n\nstatic struct pgt_info *hl_mmu_v2_hr_get_hop0_pgt_info(struct hl_ctx *ctx)\n{\n\treturn &ctx->hdev->mmu_priv.hr.mmu_asid_hop0[ctx->asid];\n}\n\n \nstatic inline int hl_mmu_v2_hr_init(struct hl_device *hdev)\n{\n\tstruct asic_fixed_properties *prop = &hdev->asic_prop;\n\n\treturn hl_mmu_hr_init(hdev, &hdev->mmu_priv.hr, prop->mmu_hop_table_size,\n\t\t\t\tprop->mmu_pgt_size);\n}\n\n \nstatic inline void hl_mmu_v2_hr_fini(struct hl_device *hdev)\n{\n\tstruct asic_fixed_properties *prop = &hdev->asic_prop;\n\n\thl_mmu_hr_fini(hdev, &hdev->mmu_priv.hr, prop->mmu_hop_table_size);\n}\n\n \nstatic int hl_mmu_v2_hr_ctx_init(struct hl_ctx *ctx)\n{\n\thash_init(ctx->hr_mmu_phys_hash);\n\treturn 0;\n}\n\n \nstatic void hl_mmu_v2_hr_ctx_fini(struct hl_ctx *ctx)\n{\n\tstruct hl_device *hdev = ctx->hdev;\n\tstruct pgt_info *pgt_info;\n\tstruct hlist_node *tmp;\n\tint i;\n\n\tif (!hash_empty(ctx->hr_mmu_phys_hash))\n\t\tdev_err(hdev->dev, \"ctx %d is freed while it has pgts in use\\n\",\n\t\t\tctx->asid);\n\n\thash_for_each_safe(ctx->hr_mmu_phys_hash, i, tmp, pgt_info, node) {\n\t\tdev_err_ratelimited(hdev->dev,\n\t\t\t\"pgt_info of addr 0x%llx of asid %d was not destroyed, num_ptes: %d\\n\",\n\t\t\tpgt_info->phys_addr, ctx->asid, pgt_info->num_of_ptes);\n\t\thl_mmu_hr_free_hop_remove_pgt(pgt_info, &ctx->hdev->mmu_priv.hr,\n\t\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size);\n\t}\n}\n\nstatic int _hl_mmu_v2_hr_unmap(struct hl_ctx *ctx,\n\t\t\t\tu64 virt_addr, bool is_dram_addr)\n{\n\tu64 curr_pte, scrambled_virt_addr, hop_pte_phys_addr[MMU_ARCH_6_HOPS] = { 0 };\n\tstruct pgt_info *hops_pgt_info[MMU_ARCH_6_HOPS] = { NULL };\n\tstruct hl_device *hdev = ctx->hdev;\n\tstruct asic_fixed_properties *prop;\n\tstruct hl_mmu_properties *mmu_prop;\n\tbool is_huge = false;\n\tint i, hop_last;\n\n\tprop = &hdev->asic_prop;\n\n\t \n\tmmu_prop = is_dram_addr ? &prop->dmmu : &prop->pmmu;\n\thop_last = mmu_prop->num_hops - 1;\n\n\tscrambled_virt_addr = hdev->asic_funcs->scramble_addr(hdev, virt_addr);\n\tcurr_pte = 0;\n\n\tfor (i = 0 ; i < mmu_prop->num_hops ; i++) {\n\t\t \n\t\tif (i == 0)\n\t\t\thops_pgt_info[i] = hl_mmu_v2_hr_get_hop0_pgt_info(ctx);\n\t\telse\n\t\t\thops_pgt_info[i] = hl_mmu_hr_get_next_hop_pgt_info(ctx,\n\t\t\t\t\t&ctx->hdev->mmu_func[MMU_HR_PGT].hr_funcs, curr_pte);\n\t\tif (!hops_pgt_info[i])\n\t\t\tgoto not_mapped;\n\n\t\thop_pte_phys_addr[i] = hl_mmu_get_hop_pte_phys_addr(ctx, mmu_prop, i,\n\t\t\t\t\t\t\t\t\thops_pgt_info[i]->phys_addr,\n\t\t\t\t\t\t\t\t\tscrambled_virt_addr);\n\t\tif (hop_pte_phys_addr[i] == U64_MAX)\n\t\t\treturn -EFAULT;\n\n\t\tcurr_pte = *(u64 *) (uintptr_t) hl_mmu_hr_pte_phys_to_virt(ctx, hops_pgt_info[i],\n\t\t\t\t\t\t\thop_pte_phys_addr[i],\n\t\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size);\n\n\t\tif ((i < hop_last) && (curr_pte & mmu_prop->last_mask)) {\n\t\t\thop_last = i;\n\t\t\tis_huge = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (is_dram_addr && !is_huge) {\n\t\tdev_err(hdev->dev, \"DRAM unmapping should use huge pages only\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tif (!(curr_pte & PAGE_PRESENT_MASK))\n\t\tgoto not_mapped;\n\n\tfor (i = hop_last ; i > 0 ; i--) {\n\t\thl_mmu_hr_clear_pte(ctx, hops_pgt_info[i], hop_pte_phys_addr[i],\n\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size);\n\n\t\tif (hl_mmu_hr_put_pte(ctx, hops_pgt_info[i], &ctx->hdev->mmu_priv.hr,\n\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size))\n\t\t\tgoto mapped;\n\t}\n\thl_mmu_hr_clear_pte(ctx, hops_pgt_info[0], hop_pte_phys_addr[0],\n\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size);\n\nmapped:\n\treturn 0;\n\nnot_mapped:\n\tdev_err(hdev->dev, \"virt addr 0x%llx is not mapped to phys addr\\n\", virt_addr);\n\n\treturn -EINVAL;\n}\n\nstatic int hl_mmu_v2_get_last_hop(struct hl_mmu_properties *mmu_prop, u32 page_size)\n{\n\tint hop;\n\n\tfor (hop = (mmu_prop->num_hops - 1); hop; hop--) {\n\t\tif (mmu_prop->hop_shifts[hop] == 0)\n\t\t\tcontinue;\n\n\t\tif (page_size <= (1 << mmu_prop->hop_shifts[hop]))\n\t\t\tbreak;\n\t}\n\n\treturn hop;\n}\n\nstatic int _hl_mmu_v2_hr_map(struct hl_ctx *ctx,\n\t\t\tu64 virt_addr, u64 phys_addr,\n\t\t\tu32 page_size, bool is_dram_addr)\n{\n\tu64 hop_pte_phys_addr[MMU_ARCH_6_HOPS] = { 0 },\n\t\tcurr_pte = 0, scrambled_virt_addr, scrambled_phys_addr;\n\tstruct pgt_info *hops_pgt_info[MMU_ARCH_6_HOPS] = { NULL };\n\tbool hop_new[MMU_ARCH_6_HOPS] = { false };\n\tstruct hl_device *hdev = ctx->hdev;\n\tstruct asic_fixed_properties *prop = &hdev->asic_prop;\n\tstruct hl_mmu_properties *mmu_prop;\n\tint i, hop_last, rc = -ENOMEM;\n\n\t \n\tif (is_dram_addr)\n\t\tmmu_prop = &prop->dmmu;\n\telse if (page_size == prop->pmmu_huge.page_size)\n\t\tmmu_prop = &prop->pmmu_huge;\n\telse\n\t\tmmu_prop = &prop->pmmu;\n\n\thop_last = hl_mmu_v2_get_last_hop(mmu_prop, page_size);\n\tif (hop_last <= 0) {\n\t\tdev_err(ctx->hdev->dev, \"Invalid last HOP %d\\n\", hop_last);\n\t\treturn -EFAULT;\n\t}\n\n\tscrambled_virt_addr = hdev->asic_funcs->scramble_addr(hdev, virt_addr);\n\tscrambled_phys_addr = hdev->asic_funcs->scramble_addr(hdev, phys_addr);\n\n\tfor (i = 0 ; i <= hop_last ; i++) {\n\n\t\tif (i == 0)\n\t\t\thops_pgt_info[i] = hl_mmu_v2_hr_get_hop0_pgt_info(ctx);\n\t\telse\n\t\t\thops_pgt_info[i] = hl_mmu_hr_get_alloc_next_hop(ctx,\n\t\t\t\t\t\t\t&ctx->hdev->mmu_priv.hr,\n\t\t\t\t\t\t\t&ctx->hdev->mmu_func[MMU_HR_PGT].hr_funcs,\n\t\t\t\t\t\t\tmmu_prop, curr_pte, &hop_new[i]);\n\t\tif (!hops_pgt_info[i])\n\t\t\tgoto err;\n\n\t\thop_pte_phys_addr[i] = hl_mmu_get_hop_pte_phys_addr(ctx, mmu_prop, i,\n\t\t\t\t\t\t\t\t\thops_pgt_info[i]->phys_addr,\n\t\t\t\t\t\t\t\t\tscrambled_virt_addr);\n\t\tcurr_pte = *(u64 *) (uintptr_t) hl_mmu_hr_pte_phys_to_virt(ctx, hops_pgt_info[i],\n\t\t\t\t\t\t\thop_pte_phys_addr[i],\n\t\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size);\n\t}\n\n\tif (curr_pte & PAGE_PRESENT_MASK) {\n\t\tdev_err(hdev->dev, \"mapping already exists for virt_addr 0x%llx\\n\",\n\t\t\t\t\t\t\t\t\tscrambled_virt_addr);\n\n\t\tfor (i = 0 ; i <= hop_last ; i++)\n\t\t\tdev_dbg(hdev->dev, \"hop%d pte: 0x%llx (0x%llx)\\n\",\n\t\t\t\t\ti,\n\t\t\t\t\t*(u64 *) (uintptr_t)\n\t\t\t\t\thl_mmu_hr_pte_phys_to_virt(ctx, hops_pgt_info[i],\n\t\t\t\t\t\t\thop_pte_phys_addr[i],\n\t\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size),\n\t\t\t\t\thop_pte_phys_addr[i]);\n\t\trc = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tcurr_pte = (scrambled_phys_addr & HOP_PHYS_ADDR_MASK) | mmu_prop->last_mask\n\t\t\t| PAGE_PRESENT_MASK;\n\n\t \n\thl_mmu_hr_write_pte(ctx, hops_pgt_info[hop_last], hop_pte_phys_addr[hop_last], curr_pte,\n\t\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size);\n\n\t \n\tfor (i = 1 ; i <= hop_last ; i++) {\n\t\tif (hop_new[i]) {\n\t\t\tcurr_pte = (hops_pgt_info[i]->phys_addr & HOP_PHYS_ADDR_MASK) |\n\t\t\t\t\t\t\tPAGE_PRESENT_MASK;\n\t\t\thl_mmu_hr_write_pte(ctx, hops_pgt_info[i - 1], hop_pte_phys_addr[i - 1],\n\t\t\t\t\t\tcurr_pte, ctx->hdev->asic_prop.mmu_hop_table_size);\n\t\t\tif (i - 1)\n\t\t\t\thl_mmu_hr_get_pte(ctx, &ctx->hdev->mmu_func[MMU_HR_PGT].hr_funcs,\n\t\t\t\t\t\t\t\thops_pgt_info[i - 1]->phys_addr);\n\t\t}\n\t}\n\n\thl_mmu_hr_get_pte(ctx, &ctx->hdev->mmu_func[MMU_HR_PGT].hr_funcs,\n\t\t\t\t\t\thops_pgt_info[hop_last]->phys_addr);\n\n\treturn 0;\n\nerr:\n\tfor (i = 1 ; i <= hop_last ; i++)\n\t\tif (hop_new[i] && hops_pgt_info[i])\n\t\t\thl_mmu_hr_free_hop_remove_pgt(hops_pgt_info[i], &ctx->hdev->mmu_priv.hr,\n\t\t\t\t\t\t\tctx->hdev->asic_prop.mmu_hop_table_size);\n\n\treturn rc;\n}\n\n \nstatic void hl_mmu_v2_hr_swap_out(struct hl_ctx *ctx)\n{\n\n}\n\n \nstatic void hl_mmu_v2_hr_swap_in(struct hl_ctx *ctx)\n{\n\n}\n\nstatic int hl_mmu_v2_hr_get_tlb_mapping_params(struct hl_device *hdev,\n\t\t\t\t\t\t\tstruct hl_mmu_properties **mmu_prop,\n\t\t\t\t\t\t\tstruct hl_mmu_hop_info *hops,\n\t\t\t\t\t\t\tu64 virt_addr, bool *is_huge)\n{\n\tstruct asic_fixed_properties *prop = &hdev->asic_prop;\n\tbool is_dram_addr, is_pmmu_addr, is_pmmu_h_addr;\n\n\tis_dram_addr = hl_mem_area_inside_range(virt_addr, prop->dmmu.page_size,\n\t\t\t\t\t\tprop->dmmu.start_addr,\n\t\t\t\t\t\tprop->dmmu.end_addr);\n\tis_pmmu_addr = hl_mem_area_inside_range(virt_addr, prop->pmmu.page_size,\n\t\t\t\t\t\tprop->pmmu.start_addr,\n\t\t\t\t\t\tprop->pmmu.end_addr);\n\tis_pmmu_h_addr = hl_mem_area_inside_range(virt_addr,\n\t\t\t\t\t\tprop->pmmu_huge.page_size,\n\t\t\t\t\t\tprop->pmmu_huge.start_addr,\n\t\t\t\t\t\tprop->pmmu_huge.end_addr);\n\tif (is_dram_addr) {\n\t\t*mmu_prop = &prop->dmmu;\n\t\t*is_huge = true;\n\t\thops->range_type = HL_VA_RANGE_TYPE_DRAM;\n\t} else if (is_pmmu_addr) {\n\t\t*mmu_prop = &prop->pmmu;\n\t\t*is_huge = false;\n\t\thops->range_type = HL_VA_RANGE_TYPE_HOST;\n\t} else if (is_pmmu_h_addr) {\n\t\t*mmu_prop = &prop->pmmu_huge;\n\t\t*is_huge = true;\n\t\thops->range_type = HL_VA_RANGE_TYPE_HOST_HUGE;\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int hl_mmu_v2_hr_get_tlb_info(struct hl_ctx *ctx, u64 virt_addr,\n\t\t\t\t\tstruct hl_mmu_hop_info *hops)\n{\n\treturn hl_mmu_hr_get_tlb_info(ctx, virt_addr, hops,\n\t\t\t\t\t&ctx->hdev->mmu_func[MMU_HR_PGT].hr_funcs);\n}\n\n \nvoid hl_mmu_v2_hr_set_funcs(struct hl_device *hdev, struct hl_mmu_funcs *mmu)\n{\n\tmmu->init = hl_mmu_v2_hr_init;\n\tmmu->fini = hl_mmu_v2_hr_fini;\n\tmmu->ctx_init = hl_mmu_v2_hr_ctx_init;\n\tmmu->ctx_fini = hl_mmu_v2_hr_ctx_fini;\n\tmmu->map = _hl_mmu_v2_hr_map;\n\tmmu->unmap = _hl_mmu_v2_hr_unmap;\n\tmmu->flush = hl_mmu_hr_flush;\n\tmmu->swap_out = hl_mmu_v2_hr_swap_out;\n\tmmu->swap_in = hl_mmu_v2_hr_swap_in;\n\tmmu->get_tlb_info = hl_mmu_v2_hr_get_tlb_info;\n\tmmu->hr_funcs.get_hop0_pgt_info = hl_mmu_v2_hr_get_hop0_pgt_info;\n\tmmu->hr_funcs.get_pgt_info = hl_mmu_v2_hr_get_pgt_info;\n\tmmu->hr_funcs.add_pgt_info = hl_mmu_v2_hr_add_pgt_info;\n\tmmu->hr_funcs.get_tlb_mapping_params = hl_mmu_v2_hr_get_tlb_mapping_params;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}