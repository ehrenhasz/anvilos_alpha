{
  "module_name": "ivpu_ipc.c",
  "hash_id": "110565d8f7c60c8aa0df30a84512a91d9cd08ce3e5557c0dfaacc607e5d9118a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/accel/ivpu/ivpu_ipc.c",
  "human_readable_source": "\n \n\n#include <linux/genalloc.h>\n#include <linux/highmem.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n\n#include \"ivpu_drv.h\"\n#include \"ivpu_gem.h\"\n#include \"ivpu_hw.h\"\n#include \"ivpu_hw_reg_io.h\"\n#include \"ivpu_ipc.h\"\n#include \"ivpu_jsm_msg.h\"\n#include \"ivpu_pm.h\"\n\n#define IPC_MAX_RX_MSG\t128\n#define IS_KTHREAD()\t(get_current()->flags & PF_KTHREAD)\n\nstruct ivpu_ipc_tx_buf {\n\tstruct ivpu_ipc_hdr ipc;\n\tstruct vpu_jsm_msg jsm;\n};\n\nstruct ivpu_ipc_rx_msg {\n\tstruct list_head link;\n\tstruct ivpu_ipc_hdr *ipc_hdr;\n\tstruct vpu_jsm_msg *jsm_msg;\n};\n\nstatic void ivpu_ipc_msg_dump(struct ivpu_device *vdev, char *c,\n\t\t\t      struct ivpu_ipc_hdr *ipc_hdr, u32 vpu_addr)\n{\n\tivpu_dbg(vdev, IPC,\n\t\t \"%s: vpu:0x%x (data_addr:0x%08x, data_size:0x%x, channel:0x%x, src_node:0x%x, dst_node:0x%x, status:0x%x)\",\n\t\t c, vpu_addr, ipc_hdr->data_addr, ipc_hdr->data_size, ipc_hdr->channel,\n\t\t ipc_hdr->src_node, ipc_hdr->dst_node, ipc_hdr->status);\n}\n\nstatic void ivpu_jsm_msg_dump(struct ivpu_device *vdev, char *c,\n\t\t\t      struct vpu_jsm_msg *jsm_msg, u32 vpu_addr)\n{\n\tu32 *payload = (u32 *)&jsm_msg->payload;\n\n\tivpu_dbg(vdev, JSM,\n\t\t \"%s: vpu:0x%08x (type:0x%x, status:0x%x, id: 0x%x, result: 0x%x, payload:0x%x 0x%x 0x%x 0x%x 0x%x)\\n\",\n\t\t c, vpu_addr, jsm_msg->type, jsm_msg->status, jsm_msg->request_id, jsm_msg->result,\n\t\t payload[0], payload[1], payload[2], payload[3], payload[4]);\n}\n\nstatic void\nivpu_ipc_rx_mark_free(struct ivpu_device *vdev, struct ivpu_ipc_hdr *ipc_hdr,\n\t\t      struct vpu_jsm_msg *jsm_msg)\n{\n\tipc_hdr->status = IVPU_IPC_HDR_FREE;\n\tif (jsm_msg)\n\t\tjsm_msg->status = VPU_JSM_MSG_FREE;\n\twmb();  \n}\n\nstatic void ivpu_ipc_mem_fini(struct ivpu_device *vdev)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\n\tivpu_bo_free_internal(ipc->mem_rx);\n\tivpu_bo_free_internal(ipc->mem_tx);\n}\n\nstatic int\nivpu_ipc_tx_prepare(struct ivpu_device *vdev, struct ivpu_ipc_consumer *cons,\n\t\t    struct vpu_jsm_msg *req)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tstruct ivpu_ipc_tx_buf *tx_buf;\n\tu32 tx_buf_vpu_addr;\n\tu32 jsm_vpu_addr;\n\n\ttx_buf_vpu_addr = gen_pool_alloc(ipc->mm_tx, sizeof(*tx_buf));\n\tif (!tx_buf_vpu_addr) {\n\t\tivpu_err(vdev, \"Failed to reserve IPC buffer, size %ld\\n\",\n\t\t\t sizeof(*tx_buf));\n\t\treturn -ENOMEM;\n\t}\n\n\ttx_buf = ivpu_to_cpu_addr(ipc->mem_tx, tx_buf_vpu_addr);\n\tif (drm_WARN_ON(&vdev->drm, !tx_buf)) {\n\t\tgen_pool_free(ipc->mm_tx, tx_buf_vpu_addr, sizeof(*tx_buf));\n\t\treturn -EIO;\n\t}\n\n\tjsm_vpu_addr = tx_buf_vpu_addr + offsetof(struct ivpu_ipc_tx_buf, jsm);\n\n\tif (tx_buf->ipc.status != IVPU_IPC_HDR_FREE)\n\t\tivpu_warn(vdev, \"IPC message vpu:0x%x not released by firmware\\n\",\n\t\t\t  tx_buf_vpu_addr);\n\n\tif (tx_buf->jsm.status != VPU_JSM_MSG_FREE)\n\t\tivpu_warn(vdev, \"JSM message vpu:0x%x not released by firmware\\n\",\n\t\t\t  jsm_vpu_addr);\n\n\tmemset(tx_buf, 0, sizeof(*tx_buf));\n\ttx_buf->ipc.data_addr = jsm_vpu_addr;\n\t \n\ttx_buf->ipc.data_size = sizeof(*req);\n\ttx_buf->ipc.channel = cons->channel;\n\ttx_buf->ipc.src_node = 0;\n\ttx_buf->ipc.dst_node = 1;\n\ttx_buf->ipc.status = IVPU_IPC_HDR_ALLOCATED;\n\ttx_buf->jsm.type = req->type;\n\ttx_buf->jsm.status = VPU_JSM_MSG_ALLOCATED;\n\ttx_buf->jsm.payload = req->payload;\n\n\treq->request_id = atomic_inc_return(&ipc->request_id);\n\ttx_buf->jsm.request_id = req->request_id;\n\tcons->request_id = req->request_id;\n\twmb();  \n\n\tcons->tx_vpu_addr = tx_buf_vpu_addr;\n\n\tivpu_jsm_msg_dump(vdev, \"TX\", &tx_buf->jsm, jsm_vpu_addr);\n\tivpu_ipc_msg_dump(vdev, \"TX\", &tx_buf->ipc, tx_buf_vpu_addr);\n\n\treturn 0;\n}\n\nstatic void ivpu_ipc_tx_release(struct ivpu_device *vdev, u32 vpu_addr)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\n\tif (vpu_addr)\n\t\tgen_pool_free(ipc->mm_tx, vpu_addr, sizeof(struct ivpu_ipc_tx_buf));\n}\n\nstatic void ivpu_ipc_tx(struct ivpu_device *vdev, u32 vpu_addr)\n{\n\tivpu_hw_reg_ipc_tx_set(vdev, vpu_addr);\n}\n\nvoid\nivpu_ipc_consumer_add(struct ivpu_device *vdev, struct ivpu_ipc_consumer *cons, u32 channel)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\n\tINIT_LIST_HEAD(&cons->link);\n\tcons->channel = channel;\n\tcons->tx_vpu_addr = 0;\n\tcons->request_id = 0;\n\tspin_lock_init(&cons->rx_msg_lock);\n\tINIT_LIST_HEAD(&cons->rx_msg_list);\n\tinit_waitqueue_head(&cons->rx_msg_wq);\n\n\tspin_lock_irq(&ipc->cons_list_lock);\n\tlist_add_tail(&cons->link, &ipc->cons_list);\n\tspin_unlock_irq(&ipc->cons_list_lock);\n}\n\nvoid ivpu_ipc_consumer_del(struct ivpu_device *vdev, struct ivpu_ipc_consumer *cons)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tstruct ivpu_ipc_rx_msg *rx_msg, *r;\n\n\tspin_lock_irq(&ipc->cons_list_lock);\n\tlist_del(&cons->link);\n\tspin_unlock_irq(&ipc->cons_list_lock);\n\n\tspin_lock_irq(&cons->rx_msg_lock);\n\tlist_for_each_entry_safe(rx_msg, r, &cons->rx_msg_list, link) {\n\t\tlist_del(&rx_msg->link);\n\t\tivpu_ipc_rx_mark_free(vdev, rx_msg->ipc_hdr, rx_msg->jsm_msg);\n\t\tatomic_dec(&ipc->rx_msg_count);\n\t\tkfree(rx_msg);\n\t}\n\tspin_unlock_irq(&cons->rx_msg_lock);\n\n\tivpu_ipc_tx_release(vdev, cons->tx_vpu_addr);\n}\n\nstatic int\nivpu_ipc_send(struct ivpu_device *vdev, struct ivpu_ipc_consumer *cons, struct vpu_jsm_msg *req)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tint ret;\n\n\tmutex_lock(&ipc->lock);\n\n\tif (!ipc->on) {\n\t\tret = -EAGAIN;\n\t\tgoto unlock;\n\t}\n\n\tret = ivpu_ipc_tx_prepare(vdev, cons, req);\n\tif (ret)\n\t\tgoto unlock;\n\n\tivpu_ipc_tx(vdev, cons->tx_vpu_addr);\n\nunlock:\n\tmutex_unlock(&ipc->lock);\n\treturn ret;\n}\n\nint ivpu_ipc_receive(struct ivpu_device *vdev, struct ivpu_ipc_consumer *cons,\n\t\t     struct ivpu_ipc_hdr *ipc_buf,\n\t\t     struct vpu_jsm_msg *ipc_payload, unsigned long timeout_ms)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tstruct ivpu_ipc_rx_msg *rx_msg;\n\tint wait_ret, ret = 0;\n\n\twait_ret = wait_event_timeout(cons->rx_msg_wq,\n\t\t\t\t      (IS_KTHREAD() && kthread_should_stop()) ||\n\t\t\t\t      !list_empty(&cons->rx_msg_list),\n\t\t\t\t      msecs_to_jiffies(timeout_ms));\n\n\tif (IS_KTHREAD() && kthread_should_stop())\n\t\treturn -EINTR;\n\n\tif (wait_ret == 0)\n\t\treturn -ETIMEDOUT;\n\n\tspin_lock_irq(&cons->rx_msg_lock);\n\trx_msg = list_first_entry_or_null(&cons->rx_msg_list, struct ivpu_ipc_rx_msg, link);\n\tif (!rx_msg) {\n\t\tspin_unlock_irq(&cons->rx_msg_lock);\n\t\treturn -EAGAIN;\n\t}\n\tlist_del(&rx_msg->link);\n\tspin_unlock_irq(&cons->rx_msg_lock);\n\n\tif (ipc_buf)\n\t\tmemcpy(ipc_buf, rx_msg->ipc_hdr, sizeof(*ipc_buf));\n\tif (rx_msg->jsm_msg) {\n\t\tu32 size = min_t(int, rx_msg->ipc_hdr->data_size, sizeof(*ipc_payload));\n\n\t\tif (rx_msg->jsm_msg->result != VPU_JSM_STATUS_SUCCESS) {\n\t\t\tivpu_dbg(vdev, IPC, \"IPC resp result error: %d\\n\", rx_msg->jsm_msg->result);\n\t\t\tret = -EBADMSG;\n\t\t}\n\n\t\tif (ipc_payload)\n\t\t\tmemcpy(ipc_payload, rx_msg->jsm_msg, size);\n\t}\n\n\tivpu_ipc_rx_mark_free(vdev, rx_msg->ipc_hdr, rx_msg->jsm_msg);\n\tatomic_dec(&ipc->rx_msg_count);\n\tkfree(rx_msg);\n\n\treturn ret;\n}\n\nstatic int\nivpu_ipc_send_receive_internal(struct ivpu_device *vdev, struct vpu_jsm_msg *req,\n\t\t\t       enum vpu_ipc_msg_type expected_resp_type,\n\t\t\t       struct vpu_jsm_msg *resp, u32 channel,\n\t\t\t       unsigned long timeout_ms)\n{\n\tstruct ivpu_ipc_consumer cons;\n\tint ret;\n\n\tivpu_ipc_consumer_add(vdev, &cons, channel);\n\n\tret = ivpu_ipc_send(vdev, &cons, req);\n\tif (ret) {\n\t\tivpu_warn(vdev, \"IPC send failed: %d\\n\", ret);\n\t\tgoto consumer_del;\n\t}\n\n\tret = ivpu_ipc_receive(vdev, &cons, NULL, resp, timeout_ms);\n\tif (ret) {\n\t\tivpu_warn(vdev, \"IPC receive failed: type 0x%x, ret %d\\n\", req->type, ret);\n\t\tgoto consumer_del;\n\t}\n\n\tif (resp->type != expected_resp_type) {\n\t\tivpu_warn(vdev, \"Invalid JSM response type: 0x%x\\n\", resp->type);\n\t\tret = -EBADE;\n\t}\n\nconsumer_del:\n\tivpu_ipc_consumer_del(vdev, &cons);\n\treturn ret;\n}\n\nint ivpu_ipc_send_receive(struct ivpu_device *vdev, struct vpu_jsm_msg *req,\n\t\t\t  enum vpu_ipc_msg_type expected_resp_type,\n\t\t\t  struct vpu_jsm_msg *resp, u32 channel,\n\t\t\t  unsigned long timeout_ms)\n{\n\tstruct vpu_jsm_msg hb_req = { .type = VPU_JSM_MSG_QUERY_ENGINE_HB };\n\tstruct vpu_jsm_msg hb_resp;\n\tint ret, hb_ret;\n\n\tret = ivpu_rpm_get(vdev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = ivpu_ipc_send_receive_internal(vdev, req, expected_resp_type, resp,\n\t\t\t\t\t     channel, timeout_ms);\n\tif (ret != -ETIMEDOUT)\n\t\tgoto rpm_put;\n\n\thb_ret = ivpu_ipc_send_receive_internal(vdev, &hb_req, VPU_JSM_MSG_QUERY_ENGINE_HB_DONE,\n\t\t\t\t\t\t&hb_resp, VPU_IPC_CHAN_ASYNC_CMD,\n\t\t\t\t\t\tvdev->timeout.jsm);\n\tif (hb_ret == -ETIMEDOUT) {\n\t\tivpu_hw_diagnose_failure(vdev);\n\t\tivpu_pm_schedule_recovery(vdev);\n\t}\n\nrpm_put:\n\tivpu_rpm_put(vdev);\n\treturn ret;\n}\n\nstatic bool\nivpu_ipc_match_consumer(struct ivpu_device *vdev, struct ivpu_ipc_consumer *cons,\n\t\t\tstruct ivpu_ipc_hdr *ipc_hdr, struct vpu_jsm_msg *jsm_msg)\n{\n\tif (cons->channel != ipc_hdr->channel)\n\t\treturn false;\n\n\tif (!jsm_msg || jsm_msg->request_id == cons->request_id)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void\nivpu_ipc_dispatch(struct ivpu_device *vdev, struct ivpu_ipc_consumer *cons,\n\t\t  struct ivpu_ipc_hdr *ipc_hdr, struct vpu_jsm_msg *jsm_msg)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tstruct ivpu_ipc_rx_msg *rx_msg;\n\tunsigned long flags;\n\n\tlockdep_assert_held(&ipc->cons_list_lock);\n\n\trx_msg = kzalloc(sizeof(*rx_msg), GFP_ATOMIC);\n\tif (!rx_msg) {\n\t\tivpu_ipc_rx_mark_free(vdev, ipc_hdr, jsm_msg);\n\t\treturn;\n\t}\n\n\tatomic_inc(&ipc->rx_msg_count);\n\n\trx_msg->ipc_hdr = ipc_hdr;\n\trx_msg->jsm_msg = jsm_msg;\n\n\tspin_lock_irqsave(&cons->rx_msg_lock, flags);\n\tlist_add_tail(&rx_msg->link, &cons->rx_msg_list);\n\tspin_unlock_irqrestore(&cons->rx_msg_lock, flags);\n\n\twake_up(&cons->rx_msg_wq);\n}\n\nint ivpu_ipc_irq_handler(struct ivpu_device *vdev)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tstruct ivpu_ipc_consumer *cons;\n\tstruct ivpu_ipc_hdr *ipc_hdr;\n\tstruct vpu_jsm_msg *jsm_msg;\n\tunsigned long flags;\n\tbool dispatched;\n\tu32 vpu_addr;\n\n\t \n\twhile (ivpu_hw_reg_ipc_rx_count_get(vdev)) {\n\t\tvpu_addr = ivpu_hw_reg_ipc_rx_addr_get(vdev);\n\t\tif (vpu_addr == REG_IO_ERROR) {\n\t\t\tivpu_err(vdev, \"Failed to read IPC rx addr register\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tipc_hdr = ivpu_to_cpu_addr(ipc->mem_rx, vpu_addr);\n\t\tif (!ipc_hdr) {\n\t\t\tivpu_warn(vdev, \"IPC msg 0x%x out of range\\n\", vpu_addr);\n\t\t\tcontinue;\n\t\t}\n\t\tivpu_ipc_msg_dump(vdev, \"RX\", ipc_hdr, vpu_addr);\n\n\t\tjsm_msg = NULL;\n\t\tif (ipc_hdr->channel != IVPU_IPC_CHAN_BOOT_MSG) {\n\t\t\tjsm_msg = ivpu_to_cpu_addr(ipc->mem_rx, ipc_hdr->data_addr);\n\t\t\tif (!jsm_msg) {\n\t\t\t\tivpu_warn(vdev, \"JSM msg 0x%x out of range\\n\", ipc_hdr->data_addr);\n\t\t\t\tivpu_ipc_rx_mark_free(vdev, ipc_hdr, NULL);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tivpu_jsm_msg_dump(vdev, \"RX\", jsm_msg, ipc_hdr->data_addr);\n\t\t}\n\n\t\tif (atomic_read(&ipc->rx_msg_count) > IPC_MAX_RX_MSG) {\n\t\t\tivpu_warn(vdev, \"IPC RX msg dropped, msg count %d\\n\", IPC_MAX_RX_MSG);\n\t\t\tivpu_ipc_rx_mark_free(vdev, ipc_hdr, jsm_msg);\n\t\t\tcontinue;\n\t\t}\n\n\t\tdispatched = false;\n\t\tspin_lock_irqsave(&ipc->cons_list_lock, flags);\n\t\tlist_for_each_entry(cons, &ipc->cons_list, link) {\n\t\t\tif (ivpu_ipc_match_consumer(vdev, cons, ipc_hdr, jsm_msg)) {\n\t\t\t\tivpu_ipc_dispatch(vdev, cons, ipc_hdr, jsm_msg);\n\t\t\t\tdispatched = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&ipc->cons_list_lock, flags);\n\n\t\tif (!dispatched) {\n\t\t\tivpu_dbg(vdev, IPC, \"IPC RX msg 0x%x dropped (no consumer)\\n\", vpu_addr);\n\t\t\tivpu_ipc_rx_mark_free(vdev, ipc_hdr, jsm_msg);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint ivpu_ipc_init(struct ivpu_device *vdev)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tint ret = -ENOMEM;\n\n\tipc->mem_tx = ivpu_bo_alloc_internal(vdev, 0, SZ_16K, DRM_IVPU_BO_WC);\n\tif (!ipc->mem_tx)\n\t\treturn ret;\n\n\tipc->mem_rx = ivpu_bo_alloc_internal(vdev, 0, SZ_16K, DRM_IVPU_BO_WC);\n\tif (!ipc->mem_rx)\n\t\tgoto err_free_tx;\n\n\tipc->mm_tx = devm_gen_pool_create(vdev->drm.dev, __ffs(IVPU_IPC_ALIGNMENT),\n\t\t\t\t\t  -1, \"TX_IPC_JSM\");\n\tif (IS_ERR(ipc->mm_tx)) {\n\t\tret = PTR_ERR(ipc->mm_tx);\n\t\tivpu_err(vdev, \"Failed to create gen pool, %pe\\n\", ipc->mm_tx);\n\t\tgoto err_free_rx;\n\t}\n\n\tret = gen_pool_add(ipc->mm_tx, ipc->mem_tx->vpu_addr, ipc->mem_tx->base.size, -1);\n\tif (ret) {\n\t\tivpu_err(vdev, \"gen_pool_add failed, ret %d\\n\", ret);\n\t\tgoto err_free_rx;\n\t}\n\n\tINIT_LIST_HEAD(&ipc->cons_list);\n\tspin_lock_init(&ipc->cons_list_lock);\n\tdrmm_mutex_init(&vdev->drm, &ipc->lock);\n\n\tivpu_ipc_reset(vdev);\n\treturn 0;\n\nerr_free_rx:\n\tivpu_bo_free_internal(ipc->mem_rx);\nerr_free_tx:\n\tivpu_bo_free_internal(ipc->mem_tx);\n\treturn ret;\n}\n\nvoid ivpu_ipc_fini(struct ivpu_device *vdev)\n{\n\tivpu_ipc_mem_fini(vdev);\n}\n\nvoid ivpu_ipc_enable(struct ivpu_device *vdev)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\n\tmutex_lock(&ipc->lock);\n\tipc->on = true;\n\tmutex_unlock(&ipc->lock);\n}\n\nvoid ivpu_ipc_disable(struct ivpu_device *vdev)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\tstruct ivpu_ipc_consumer *cons, *c;\n\tunsigned long flags;\n\n\tmutex_lock(&ipc->lock);\n\tipc->on = false;\n\tmutex_unlock(&ipc->lock);\n\n\tspin_lock_irqsave(&ipc->cons_list_lock, flags);\n\tlist_for_each_entry_safe(cons, c, &ipc->cons_list, link)\n\t\twake_up(&cons->rx_msg_wq);\n\tspin_unlock_irqrestore(&ipc->cons_list_lock, flags);\n}\n\nvoid ivpu_ipc_reset(struct ivpu_device *vdev)\n{\n\tstruct ivpu_ipc_info *ipc = vdev->ipc;\n\n\tmutex_lock(&ipc->lock);\n\n\tmemset(ipc->mem_tx->kvaddr, 0, ipc->mem_tx->base.size);\n\tmemset(ipc->mem_rx->kvaddr, 0, ipc->mem_rx->base.size);\n\twmb();  \n\n\tmutex_unlock(&ipc->lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}