{
  "module_name": "ivpu_drv.c",
  "hash_id": "cadcdeddc72c7ca6d98f370c2e2cc1feb4a5ed192c0d769a8019b95d767e4c0d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/accel/ivpu/ivpu_drv.c",
  "human_readable_source": "\n \n\n#include <linux/firmware.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n\n#include <drm/drm_accel.h>\n#include <drm/drm_file.h>\n#include <drm/drm_gem.h>\n#include <drm/drm_ioctl.h>\n#include <drm/drm_prime.h>\n\n#include \"vpu_boot_api.h\"\n#include \"ivpu_debugfs.h\"\n#include \"ivpu_drv.h\"\n#include \"ivpu_fw.h\"\n#include \"ivpu_gem.h\"\n#include \"ivpu_hw.h\"\n#include \"ivpu_ipc.h\"\n#include \"ivpu_job.h\"\n#include \"ivpu_jsm_msg.h\"\n#include \"ivpu_mmu.h\"\n#include \"ivpu_mmu_context.h\"\n#include \"ivpu_pm.h\"\n\n#ifndef DRIVER_VERSION_STR\n#define DRIVER_VERSION_STR __stringify(DRM_IVPU_DRIVER_MAJOR) \".\" \\\n\t\t\t   __stringify(DRM_IVPU_DRIVER_MINOR) \".\"\n#endif\n\nstatic const struct drm_driver driver;\n\nstatic struct lock_class_key submitted_jobs_xa_lock_class_key;\n\nint ivpu_dbg_mask;\nmodule_param_named(dbg_mask, ivpu_dbg_mask, int, 0644);\nMODULE_PARM_DESC(dbg_mask, \"Driver debug mask. See IVPU_DBG_* macros.\");\n\nint ivpu_test_mode;\nmodule_param_named_unsafe(test_mode, ivpu_test_mode, int, 0644);\nMODULE_PARM_DESC(test_mode, \"Test mode: 0 - normal operation, 1 - fw unit test, 2 - null hw\");\n\nu8 ivpu_pll_min_ratio;\nmodule_param_named(pll_min_ratio, ivpu_pll_min_ratio, byte, 0644);\nMODULE_PARM_DESC(pll_min_ratio, \"Minimum PLL ratio used to set VPU frequency\");\n\nu8 ivpu_pll_max_ratio = U8_MAX;\nmodule_param_named(pll_max_ratio, ivpu_pll_max_ratio, byte, 0644);\nMODULE_PARM_DESC(pll_max_ratio, \"Maximum PLL ratio used to set VPU frequency\");\n\nbool ivpu_disable_mmu_cont_pages;\nmodule_param_named(disable_mmu_cont_pages, ivpu_disable_mmu_cont_pages, bool, 0644);\nMODULE_PARM_DESC(disable_mmu_cont_pages, \"Disable MMU contiguous pages optimization\");\n\nstruct ivpu_file_priv *ivpu_file_priv_get(struct ivpu_file_priv *file_priv)\n{\n\tstruct ivpu_device *vdev = file_priv->vdev;\n\n\tkref_get(&file_priv->ref);\n\n\tivpu_dbg(vdev, KREF, \"file_priv get: ctx %u refcount %u\\n\",\n\t\t file_priv->ctx.id, kref_read(&file_priv->ref));\n\n\treturn file_priv;\n}\n\nstruct ivpu_file_priv *ivpu_file_priv_get_by_ctx_id(struct ivpu_device *vdev, unsigned long id)\n{\n\tstruct ivpu_file_priv *file_priv;\n\n\txa_lock_irq(&vdev->context_xa);\n\tfile_priv = xa_load(&vdev->context_xa, id);\n\t \n\tif (file_priv && !kref_get_unless_zero(&file_priv->ref))\n\t\tfile_priv = NULL;\n\txa_unlock_irq(&vdev->context_xa);\n\n\tif (file_priv)\n\t\tivpu_dbg(vdev, KREF, \"file_priv get by id: ctx %u refcount %u\\n\",\n\t\t\t file_priv->ctx.id, kref_read(&file_priv->ref));\n\n\treturn file_priv;\n}\n\nstatic void file_priv_release(struct kref *ref)\n{\n\tstruct ivpu_file_priv *file_priv = container_of(ref, struct ivpu_file_priv, ref);\n\tstruct ivpu_device *vdev = file_priv->vdev;\n\n\tivpu_dbg(vdev, FILE, \"file_priv release: ctx %u\\n\", file_priv->ctx.id);\n\n\tivpu_cmdq_release_all(file_priv);\n\tivpu_bo_remove_all_bos_from_context(&file_priv->ctx);\n\tivpu_jsm_context_release(vdev, file_priv->ctx.id);\n\tivpu_mmu_user_context_fini(vdev, &file_priv->ctx);\n\tdrm_WARN_ON(&vdev->drm, xa_erase_irq(&vdev->context_xa, file_priv->ctx.id) != file_priv);\n\tmutex_destroy(&file_priv->lock);\n\tkfree(file_priv);\n}\n\nvoid ivpu_file_priv_put(struct ivpu_file_priv **link)\n{\n\tstruct ivpu_file_priv *file_priv = *link;\n\tstruct ivpu_device *vdev = file_priv->vdev;\n\n\tdrm_WARN_ON(&vdev->drm, !file_priv);\n\n\tivpu_dbg(vdev, KREF, \"file_priv put: ctx %u refcount %u\\n\",\n\t\t file_priv->ctx.id, kref_read(&file_priv->ref));\n\n\t*link = NULL;\n\tkref_put(&file_priv->ref, file_priv_release);\n}\n\nstatic int ivpu_get_capabilities(struct ivpu_device *vdev, struct drm_ivpu_param *args)\n{\n\tswitch (args->index) {\n\tcase DRM_IVPU_CAP_METRIC_STREAMER:\n\t\targs->value = 0;\n\t\tbreak;\n\tcase DRM_IVPU_CAP_DMA_MEMORY_RANGE:\n\t\targs->value = 1;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic int ivpu_get_param_ioctl(struct drm_device *dev, void *data, struct drm_file *file)\n{\n\tstruct ivpu_file_priv *file_priv = file->driver_priv;\n\tstruct ivpu_device *vdev = file_priv->vdev;\n\tstruct pci_dev *pdev = to_pci_dev(vdev->drm.dev);\n\tstruct drm_ivpu_param *args = data;\n\tint ret = 0;\n\tint idx;\n\n\tif (!drm_dev_enter(dev, &idx))\n\t\treturn -ENODEV;\n\n\tswitch (args->param) {\n\tcase DRM_IVPU_PARAM_DEVICE_ID:\n\t\targs->value = pdev->device;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_DEVICE_REVISION:\n\t\targs->value = pdev->revision;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_PLATFORM_TYPE:\n\t\targs->value = vdev->platform;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_CORE_CLOCK_RATE:\n\t\targs->value = ivpu_hw_reg_pll_freq_get(vdev);\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_NUM_CONTEXTS:\n\t\targs->value = ivpu_get_context_count(vdev);\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_CONTEXT_BASE_ADDRESS:\n\t\targs->value = vdev->hw->ranges.user.start;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_CONTEXT_PRIORITY:\n\t\targs->value = file_priv->priority;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_CONTEXT_ID:\n\t\targs->value = file_priv->ctx.id;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_FW_API_VERSION:\n\t\tif (args->index < VPU_FW_API_VER_NUM) {\n\t\t\tstruct vpu_firmware_header *fw_hdr;\n\n\t\t\tfw_hdr = (struct vpu_firmware_header *)vdev->fw->file->data;\n\t\t\targs->value = fw_hdr->api_version[args->index];\n\t\t} else {\n\t\t\tret = -EINVAL;\n\t\t}\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_ENGINE_HEARTBEAT:\n\t\tret = ivpu_jsm_get_heartbeat(vdev, args->index, &args->value);\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_UNIQUE_INFERENCE_ID:\n\t\targs->value = (u64)atomic64_inc_return(&vdev->unique_id_counter);\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_TILE_CONFIG:\n\t\targs->value = vdev->hw->tile_fuse;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_SKU:\n\t\targs->value = vdev->hw->sku;\n\t\tbreak;\n\tcase DRM_IVPU_PARAM_CAPABILITIES:\n\t\tret = ivpu_get_capabilities(vdev, args);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\tdrm_dev_exit(idx);\n\treturn ret;\n}\n\nstatic int ivpu_set_param_ioctl(struct drm_device *dev, void *data, struct drm_file *file)\n{\n\tstruct ivpu_file_priv *file_priv = file->driver_priv;\n\tstruct drm_ivpu_param *args = data;\n\tint ret = 0;\n\n\tswitch (args->param) {\n\tcase DRM_IVPU_PARAM_CONTEXT_PRIORITY:\n\t\tif (args->value <= DRM_IVPU_CONTEXT_PRIORITY_REALTIME)\n\t\t\tfile_priv->priority = args->value;\n\t\telse\n\t\t\tret = -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int ivpu_open(struct drm_device *dev, struct drm_file *file)\n{\n\tstruct ivpu_device *vdev = to_ivpu_device(dev);\n\tstruct ivpu_file_priv *file_priv;\n\tu32 ctx_id;\n\tvoid *old;\n\tint ret;\n\n\tret = xa_alloc_irq(&vdev->context_xa, &ctx_id, NULL, vdev->context_xa_limit, GFP_KERNEL);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to allocate context id: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tfile_priv = kzalloc(sizeof(*file_priv), GFP_KERNEL);\n\tif (!file_priv) {\n\t\tret = -ENOMEM;\n\t\tgoto err_xa_erase;\n\t}\n\n\tfile_priv->vdev = vdev;\n\tfile_priv->priority = DRM_IVPU_CONTEXT_PRIORITY_NORMAL;\n\tkref_init(&file_priv->ref);\n\tmutex_init(&file_priv->lock);\n\n\tret = ivpu_mmu_user_context_init(vdev, &file_priv->ctx, ctx_id);\n\tif (ret)\n\t\tgoto err_mutex_destroy;\n\n\told = xa_store_irq(&vdev->context_xa, ctx_id, file_priv, GFP_KERNEL);\n\tif (xa_is_err(old)) {\n\t\tret = xa_err(old);\n\t\tivpu_err(vdev, \"Failed to store context %u: %d\\n\", ctx_id, ret);\n\t\tgoto err_ctx_fini;\n\t}\n\n\tivpu_dbg(vdev, FILE, \"file_priv create: ctx %u process %s pid %d\\n\",\n\t\t ctx_id, current->comm, task_pid_nr(current));\n\n\tfile->driver_priv = file_priv;\n\treturn 0;\n\nerr_ctx_fini:\n\tivpu_mmu_user_context_fini(vdev, &file_priv->ctx);\nerr_mutex_destroy:\n\tmutex_destroy(&file_priv->lock);\n\tkfree(file_priv);\nerr_xa_erase:\n\txa_erase_irq(&vdev->context_xa, ctx_id);\n\treturn ret;\n}\n\nstatic void ivpu_postclose(struct drm_device *dev, struct drm_file *file)\n{\n\tstruct ivpu_file_priv *file_priv = file->driver_priv;\n\tstruct ivpu_device *vdev = to_ivpu_device(dev);\n\n\tivpu_dbg(vdev, FILE, \"file_priv close: ctx %u process %s pid %d\\n\",\n\t\t file_priv->ctx.id, current->comm, task_pid_nr(current));\n\n\tivpu_file_priv_put(&file_priv);\n}\n\nstatic const struct drm_ioctl_desc ivpu_drm_ioctls[] = {\n\tDRM_IOCTL_DEF_DRV(IVPU_GET_PARAM, ivpu_get_param_ioctl, 0),\n\tDRM_IOCTL_DEF_DRV(IVPU_SET_PARAM, ivpu_set_param_ioctl, 0),\n\tDRM_IOCTL_DEF_DRV(IVPU_BO_CREATE, ivpu_bo_create_ioctl, 0),\n\tDRM_IOCTL_DEF_DRV(IVPU_BO_INFO, ivpu_bo_info_ioctl, 0),\n\tDRM_IOCTL_DEF_DRV(IVPU_SUBMIT, ivpu_submit_ioctl, 0),\n\tDRM_IOCTL_DEF_DRV(IVPU_BO_WAIT, ivpu_bo_wait_ioctl, 0),\n};\n\nstatic int ivpu_wait_for_ready(struct ivpu_device *vdev)\n{\n\tstruct ivpu_ipc_consumer cons;\n\tstruct ivpu_ipc_hdr ipc_hdr;\n\tunsigned long timeout;\n\tint ret;\n\n\tif (ivpu_test_mode == IVPU_TEST_MODE_FW_TEST)\n\t\treturn 0;\n\n\tivpu_ipc_consumer_add(vdev, &cons, IVPU_IPC_CHAN_BOOT_MSG);\n\n\ttimeout = jiffies + msecs_to_jiffies(vdev->timeout.boot);\n\twhile (1) {\n\t\tret = ivpu_ipc_irq_handler(vdev);\n\t\tif (ret)\n\t\t\tbreak;\n\t\tret = ivpu_ipc_receive(vdev, &cons, &ipc_hdr, NULL, 0);\n\t\tif (ret != -ETIMEDOUT || time_after_eq(jiffies, timeout))\n\t\t\tbreak;\n\n\t\tcond_resched();\n\t}\n\n\tivpu_ipc_consumer_del(vdev, &cons);\n\n\tif (!ret && ipc_hdr.data_addr != IVPU_IPC_BOOT_MSG_DATA_ADDR) {\n\t\tivpu_err(vdev, \"Invalid VPU ready message: 0x%x\\n\",\n\t\t\t ipc_hdr.data_addr);\n\t\treturn -EIO;\n\t}\n\n\tif (!ret)\n\t\tivpu_dbg(vdev, PM, \"VPU ready message received successfully\\n\");\n\telse\n\t\tivpu_hw_diagnose_failure(vdev);\n\n\treturn ret;\n}\n\n \nint ivpu_boot(struct ivpu_device *vdev)\n{\n\tint ret;\n\n\t \n\tivpu_fw_boot_params_setup(vdev, vdev->fw->mem->kvaddr);\n\n\tret = ivpu_hw_boot_fw(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to start the firmware: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = ivpu_wait_for_ready(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to boot the firmware: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tivpu_hw_irq_clear(vdev);\n\tenable_irq(vdev->irq);\n\tivpu_hw_irq_enable(vdev);\n\tivpu_ipc_enable(vdev);\n\treturn 0;\n}\n\nvoid ivpu_prepare_for_reset(struct ivpu_device *vdev)\n{\n\tivpu_hw_irq_disable(vdev);\n\tdisable_irq(vdev->irq);\n\tivpu_ipc_disable(vdev);\n\tivpu_mmu_disable(vdev);\n}\n\nint ivpu_shutdown(struct ivpu_device *vdev)\n{\n\tint ret;\n\n\tivpu_prepare_for_reset(vdev);\n\n\tret = ivpu_hw_power_down(vdev);\n\tif (ret)\n\t\tivpu_warn(vdev, \"Failed to power down HW: %d\\n\", ret);\n\n\treturn ret;\n}\n\nstatic const struct file_operations ivpu_fops = {\n\t.owner\t\t= THIS_MODULE,\n\tDRM_ACCEL_FOPS,\n};\n\nstatic const struct drm_driver driver = {\n\t.driver_features = DRIVER_GEM | DRIVER_COMPUTE_ACCEL,\n\n\t.open = ivpu_open,\n\t.postclose = ivpu_postclose,\n\t.gem_prime_import = ivpu_gem_prime_import,\n\n#if defined(CONFIG_DEBUG_FS)\n\t.debugfs_init = ivpu_debugfs_init,\n#endif\n\n\t.ioctls = ivpu_drm_ioctls,\n\t.num_ioctls = ARRAY_SIZE(ivpu_drm_ioctls),\n\t.fops = &ivpu_fops,\n\n\t.name = DRIVER_NAME,\n\t.desc = DRIVER_DESC,\n\t.date = DRIVER_DATE,\n\t.major = DRM_IVPU_DRIVER_MAJOR,\n\t.minor = DRM_IVPU_DRIVER_MINOR,\n};\n\nstatic int ivpu_irq_init(struct ivpu_device *vdev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(vdev->drm.dev);\n\tint ret;\n\n\tret = pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_MSI | PCI_IRQ_MSIX);\n\tif (ret < 0) {\n\t\tivpu_err(vdev, \"Failed to allocate a MSI IRQ: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tvdev->irq = pci_irq_vector(pdev, 0);\n\n\tret = devm_request_irq(vdev->drm.dev, vdev->irq, vdev->hw->ops->irq_handler,\n\t\t\t       IRQF_NO_AUTOEN, DRIVER_NAME, vdev);\n\tif (ret)\n\t\tivpu_err(vdev, \"Failed to request an IRQ %d\\n\", ret);\n\n\treturn ret;\n}\n\nstatic int ivpu_pci_init(struct ivpu_device *vdev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(vdev->drm.dev);\n\tstruct resource *bar0 = &pdev->resource[0];\n\tstruct resource *bar4 = &pdev->resource[4];\n\tint ret;\n\n\tivpu_dbg(vdev, MISC, \"Mapping BAR0 (RegV) %pR\\n\", bar0);\n\tvdev->regv = devm_ioremap_resource(vdev->drm.dev, bar0);\n\tif (IS_ERR(vdev->regv)) {\n\t\tivpu_err(vdev, \"Failed to map bar 0: %pe\\n\", vdev->regv);\n\t\treturn PTR_ERR(vdev->regv);\n\t}\n\n\tivpu_dbg(vdev, MISC, \"Mapping BAR4 (RegB) %pR\\n\", bar4);\n\tvdev->regb = devm_ioremap_resource(vdev->drm.dev, bar4);\n\tif (IS_ERR(vdev->regb)) {\n\t\tivpu_err(vdev, \"Failed to map bar 4: %pe\\n\", vdev->regb);\n\t\treturn PTR_ERR(vdev->regb);\n\t}\n\n\tret = dma_set_mask_and_coherent(vdev->drm.dev, DMA_BIT_MASK(vdev->hw->dma_bits));\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to set DMA mask: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\tdma_set_max_seg_size(vdev->drm.dev, UINT_MAX);\n\n\t \n\tpcie_capability_clear_word(pdev, PCI_EXP_DEVSTA, 0x3f);\n\n\t \n\tif (ivpu_hw_gen(vdev) == IVPU_HW_37XX)\n\t\tpdev->d3hot_delay = 0;\n\n\tret = pcim_enable_device(pdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to enable PCI device: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tpci_set_master(pdev);\n\n\treturn 0;\n}\n\nstatic int ivpu_dev_init(struct ivpu_device *vdev)\n{\n\tint ret;\n\n\tvdev->hw = drmm_kzalloc(&vdev->drm, sizeof(*vdev->hw), GFP_KERNEL);\n\tif (!vdev->hw)\n\t\treturn -ENOMEM;\n\n\tvdev->mmu = drmm_kzalloc(&vdev->drm, sizeof(*vdev->mmu), GFP_KERNEL);\n\tif (!vdev->mmu)\n\t\treturn -ENOMEM;\n\n\tvdev->fw = drmm_kzalloc(&vdev->drm, sizeof(*vdev->fw), GFP_KERNEL);\n\tif (!vdev->fw)\n\t\treturn -ENOMEM;\n\n\tvdev->ipc = drmm_kzalloc(&vdev->drm, sizeof(*vdev->ipc), GFP_KERNEL);\n\tif (!vdev->ipc)\n\t\treturn -ENOMEM;\n\n\tvdev->pm = drmm_kzalloc(&vdev->drm, sizeof(*vdev->pm), GFP_KERNEL);\n\tif (!vdev->pm)\n\t\treturn -ENOMEM;\n\n\tif (ivpu_hw_gen(vdev) >= IVPU_HW_40XX) {\n\t\tvdev->hw->ops = &ivpu_hw_40xx_ops;\n\t\tvdev->hw->dma_bits = 48;\n\t} else {\n\t\tvdev->hw->ops = &ivpu_hw_37xx_ops;\n\t\tvdev->hw->dma_bits = 38;\n\t}\n\n\tvdev->platform = IVPU_PLATFORM_INVALID;\n\tvdev->context_xa_limit.min = IVPU_USER_CONTEXT_MIN_SSID;\n\tvdev->context_xa_limit.max = IVPU_USER_CONTEXT_MAX_SSID;\n\tatomic64_set(&vdev->unique_id_counter, 0);\n\txa_init_flags(&vdev->context_xa, XA_FLAGS_ALLOC);\n\txa_init_flags(&vdev->submitted_jobs_xa, XA_FLAGS_ALLOC1);\n\tlockdep_set_class(&vdev->submitted_jobs_xa.xa_lock, &submitted_jobs_xa_lock_class_key);\n\n\tret = ivpu_pci_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize PCI device: %d\\n\", ret);\n\t\tgoto err_xa_destroy;\n\t}\n\n\tret = ivpu_irq_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize IRQs: %d\\n\", ret);\n\t\tgoto err_xa_destroy;\n\t}\n\n\t \n\tret = ivpu_hw_info_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize HW info: %d\\n\", ret);\n\t\tgoto err_xa_destroy;\n\t}\n\n\t \n\tret = ivpu_hw_power_up(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to power up HW: %d\\n\", ret);\n\t\tgoto err_xa_destroy;\n\t}\n\n\tret = ivpu_mmu_global_context_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize global MMU context: %d\\n\", ret);\n\t\tgoto err_power_down;\n\t}\n\n\tret = ivpu_mmu_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize MMU device: %d\\n\", ret);\n\t\tgoto err_mmu_gctx_fini;\n\t}\n\n\tret = ivpu_fw_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize firmware: %d\\n\", ret);\n\t\tgoto err_mmu_gctx_fini;\n\t}\n\n\tret = ivpu_ipc_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize IPC: %d\\n\", ret);\n\t\tgoto err_fw_fini;\n\t}\n\n\tret = ivpu_pm_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize PM: %d\\n\", ret);\n\t\tgoto err_ipc_fini;\n\t}\n\n\tret = ivpu_job_done_thread_init(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to initialize job done thread: %d\\n\", ret);\n\t\tgoto err_ipc_fini;\n\t}\n\n\tret = ivpu_fw_load(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to load firmware: %d\\n\", ret);\n\t\tgoto err_job_done_thread_fini;\n\t}\n\n\tret = ivpu_boot(vdev);\n\tif (ret) {\n\t\tivpu_err(vdev, \"Failed to boot: %d\\n\", ret);\n\t\tgoto err_job_done_thread_fini;\n\t}\n\n\tivpu_pm_enable(vdev);\n\n\treturn 0;\n\nerr_job_done_thread_fini:\n\tivpu_job_done_thread_fini(vdev);\nerr_ipc_fini:\n\tivpu_ipc_fini(vdev);\nerr_fw_fini:\n\tivpu_fw_fini(vdev);\nerr_mmu_gctx_fini:\n\tivpu_mmu_global_context_fini(vdev);\nerr_power_down:\n\tivpu_hw_power_down(vdev);\n\tif (IVPU_WA(d3hot_after_power_off))\n\t\tpci_set_power_state(to_pci_dev(vdev->drm.dev), PCI_D3hot);\nerr_xa_destroy:\n\txa_destroy(&vdev->submitted_jobs_xa);\n\txa_destroy(&vdev->context_xa);\n\treturn ret;\n}\n\nstatic void ivpu_dev_fini(struct ivpu_device *vdev)\n{\n\tivpu_pm_disable(vdev);\n\tivpu_shutdown(vdev);\n\tif (IVPU_WA(d3hot_after_power_off))\n\t\tpci_set_power_state(to_pci_dev(vdev->drm.dev), PCI_D3hot);\n\tivpu_job_done_thread_fini(vdev);\n\tivpu_pm_cancel_recovery(vdev);\n\n\tivpu_ipc_fini(vdev);\n\tivpu_fw_fini(vdev);\n\tivpu_mmu_global_context_fini(vdev);\n\n\tdrm_WARN_ON(&vdev->drm, !xa_empty(&vdev->submitted_jobs_xa));\n\txa_destroy(&vdev->submitted_jobs_xa);\n\tdrm_WARN_ON(&vdev->drm, !xa_empty(&vdev->context_xa));\n\txa_destroy(&vdev->context_xa);\n}\n\nstatic struct pci_device_id ivpu_pci_ids[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_MTL) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_ARL) },\n\t{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_LNL) },\n\t{ }\n};\nMODULE_DEVICE_TABLE(pci, ivpu_pci_ids);\n\nstatic int ivpu_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tstruct ivpu_device *vdev;\n\tint ret;\n\n\tvdev = devm_drm_dev_alloc(&pdev->dev, &driver, struct ivpu_device, drm);\n\tif (IS_ERR(vdev))\n\t\treturn PTR_ERR(vdev);\n\n\tpci_set_drvdata(pdev, vdev);\n\n\tret = ivpu_dev_init(vdev);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to initialize VPU device: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = drm_dev_register(&vdev->drm, 0);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to register DRM device: %d\\n\", ret);\n\t\tivpu_dev_fini(vdev);\n\t}\n\n\treturn ret;\n}\n\nstatic void ivpu_remove(struct pci_dev *pdev)\n{\n\tstruct ivpu_device *vdev = pci_get_drvdata(pdev);\n\n\tdrm_dev_unplug(&vdev->drm);\n\tivpu_dev_fini(vdev);\n}\n\nstatic const struct dev_pm_ops ivpu_drv_pci_pm = {\n\tSET_SYSTEM_SLEEP_PM_OPS(ivpu_pm_suspend_cb, ivpu_pm_resume_cb)\n\tSET_RUNTIME_PM_OPS(ivpu_pm_runtime_suspend_cb, ivpu_pm_runtime_resume_cb, NULL)\n};\n\nstatic const struct pci_error_handlers ivpu_drv_pci_err = {\n\t.reset_prepare = ivpu_pm_reset_prepare_cb,\n\t.reset_done = ivpu_pm_reset_done_cb,\n};\n\nstatic struct pci_driver ivpu_pci_driver = {\n\t.name = KBUILD_MODNAME,\n\t.id_table = ivpu_pci_ids,\n\t.probe = ivpu_probe,\n\t.remove = ivpu_remove,\n\t.driver = {\n\t\t.pm = &ivpu_drv_pci_pm,\n\t},\n\t.err_handler = &ivpu_drv_pci_err,\n};\n\nmodule_pci_driver(ivpu_pci_driver);\n\nMODULE_AUTHOR(\"Intel Corporation\");\nMODULE_DESCRIPTION(DRIVER_DESC);\nMODULE_LICENSE(\"GPL and additional rights\");\nMODULE_VERSION(DRIVER_VERSION_STR);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}