{
  "module_name": "iommu-helpers.h",
  "hash_id": "0f1e13ea6cf26d1d45aaddfae3fb9c7b03aaf867f3602f71fae809902cd71d40",
  "original_prompt": "Ingested from linux-6.6.14/drivers/parisc/iommu-helpers.h",
  "human_readable_source": " \n#include <linux/prefetch.h>\n\n  \nstatic inline unsigned int\niommu_fill_pdir(struct ioc *ioc, struct scatterlist *startsg, int nents, \n\t\tunsigned long hint,\n\t\tvoid (*iommu_io_pdir_entry)(__le64 *, space_t, unsigned long,\n\t\t\t\t\t    unsigned long))\n{\n\tstruct scatterlist *dma_sg = startsg;\t \n\tunsigned int n_mappings = 0;\n\tunsigned long dma_offset = 0, dma_len = 0;\n\t__le64 *pdirp = NULL;\n\n\t \n\t dma_sg--;\n\n\twhile (nents-- > 0) {\n\t\tunsigned long vaddr;\n\t\tlong size;\n\n\t\tDBG_RUN_SG(\" %d : %08lx %p/%05x\\n\", nents,\n\t\t\t   (unsigned long)sg_dma_address(startsg),\n\t\t\t   sg_virt(startsg), startsg->length\n\t\t);\n\n\n\t\t \n\t\t\n\t\tif (sg_dma_address(startsg) & PIDE_FLAG) {\n\t\t\tu32 pide = sg_dma_address(startsg) & ~PIDE_FLAG;\n\n\t\t\tBUG_ON(pdirp && (dma_len != sg_dma_len(dma_sg)));\n\n\t\t\tdma_sg++;\n\n\t\t\tdma_len = sg_dma_len(startsg);\n\t\t\tsg_dma_len(startsg) = 0;\n\t\t\tdma_offset = (unsigned long) pide & ~IOVP_MASK;\n\t\t\tn_mappings++;\n#if defined(ZX1_SUPPORT)\n\t\t\t \n\t\t\tsg_dma_address(dma_sg) = pide | ioc->ibase;\n#else\n\t\t\t \n\t\t\tsg_dma_address(dma_sg) = pide;\n#endif\n\t\t\tpdirp = &(ioc->pdir_base[pide >> IOVP_SHIFT]);\n\t\t\tprefetchw(pdirp);\n\t\t}\n\t\t\n\t\tBUG_ON(pdirp == NULL);\n\t\t\n\t\tvaddr = (unsigned long)sg_virt(startsg);\n\t\tsg_dma_len(dma_sg) += startsg->length;\n\t\tsize = startsg->length + dma_offset;\n\t\tdma_offset = 0;\n#ifdef IOMMU_MAP_STATS\n\t\tioc->msg_pages += startsg->length >> IOVP_SHIFT;\n#endif\n\t\tdo {\n\t\t\tiommu_io_pdir_entry(pdirp, KERNEL_SPACE, \n\t\t\t\t\t    vaddr, hint);\n\t\t\tvaddr += IOVP_SIZE;\n\t\t\tsize -= IOVP_SIZE;\n\t\t\tpdirp++;\n\t\t} while(unlikely(size > 0));\n\t\tstartsg++;\n\t}\n\treturn(n_mappings);\n}\n\n\n \n\nstatic inline unsigned int\niommu_coalesce_chunks(struct ioc *ioc, struct device *dev,\n\t\tstruct scatterlist *startsg, int nents,\n\t\tint (*iommu_alloc_range)(struct ioc *, struct device *, size_t))\n{\n\tstruct scatterlist *contig_sg;\t    \n\tunsigned long dma_offset, dma_len;  \n\tunsigned int n_mappings = 0;\n\tunsigned int max_seg_size = min(dma_get_max_seg_size(dev),\n\t\t\t\t\t(unsigned)DMA_CHUNK_SIZE);\n\tunsigned int max_seg_boundary = dma_get_seg_boundary(dev) + 1;\n\tif (max_seg_boundary)\t \n\t\tmax_seg_size = min(max_seg_size, max_seg_boundary);\n\n\twhile (nents > 0) {\n\n\t\t \n\t\tcontig_sg = startsg;\n\t\tdma_len = startsg->length;\n\t\tdma_offset = startsg->offset;\n\n\t\t \n\t\tsg_dma_address(startsg) = 0;\n\t\tsg_dma_len(startsg) = 0;\n\n\t\t \n\t\twhile(--nents > 0) {\n\t\t\tunsigned long prev_end, sg_start;\n\n\t\t\tprev_end = (unsigned long)sg_virt(startsg) +\n\t\t\t\t\t\t\tstartsg->length;\n\n\t\t\tstartsg++;\n\t\t\tsg_start = (unsigned long)sg_virt(startsg);\n\n\t\t\t \n\t\t\tsg_dma_address(startsg) = 0;\n\t\t\tsg_dma_len(startsg) = 0;\n\n\t\t\t    \n\t\t\tif (unlikely(ALIGN(dma_len + dma_offset + startsg->length, IOVP_SIZE) >\n\t\t\t\t     max_seg_size))\n\t\t\t\tbreak;\n\n\t\t\t \n\t\t\tif (unlikely((prev_end != sg_start) ||\n\t\t\t\t((prev_end | sg_start) & ~PAGE_MASK)))\n\t\t\t\tbreak;\n\t\t\t\n\t\t\tdma_len += startsg->length;\n\t\t}\n\n\t\t \n\t\tsg_dma_len(contig_sg) = dma_len;\n\t\tdma_len = ALIGN(dma_len + dma_offset, IOVP_SIZE);\n\t\tsg_dma_address(contig_sg) =\n\t\t\tPIDE_FLAG \n\t\t\t| (iommu_alloc_range(ioc, dev, dma_len) << IOVP_SHIFT)\n\t\t\t| dma_offset;\n\t\tn_mappings++;\n\t}\n\n\treturn n_mappings;\n}\n\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}