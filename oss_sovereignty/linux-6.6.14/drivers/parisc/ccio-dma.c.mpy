{
  "module_name": "ccio-dma.c",
  "hash_id": "f34546e4007fb91eff9616f4164cb331b309b549b162c6819e183f7f1c5b4d17",
  "original_prompt": "Ingested from linux-6.6.14/drivers/parisc/ccio-dma.c",
  "human_readable_source": "\n \n\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/mm.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/pci.h>\n#include <linux/reboot.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/dma-map-ops.h>\n#include <linux/scatterlist.h>\n#include <linux/iommu-helper.h>\n#include <linux/export.h>\n\n#include <asm/byteorder.h>\n#include <asm/cache.h>\t\t \n#include <linux/uaccess.h>\n#include <asm/page.h>\n#include <asm/dma.h>\n#include <asm/io.h>\n#include <asm/hardware.h>        \n#include <asm/parisc-device.h>\n\n#include \"iommu.h\"\n\n \n#define MODULE_NAME \"ccio\"\n\n#undef DEBUG_CCIO_RES\n#undef DEBUG_CCIO_RUN\n#undef DEBUG_CCIO_INIT\n#undef DEBUG_CCIO_RUN_SG\n\n#ifdef CONFIG_PROC_FS\n \n#undef CCIO_COLLECT_STATS\n#endif\n\n#ifdef DEBUG_CCIO_INIT\n#define DBG_INIT(x...)  printk(x)\n#else\n#define DBG_INIT(x...)\n#endif\n\n#ifdef DEBUG_CCIO_RUN\n#define DBG_RUN(x...)   printk(x)\n#else\n#define DBG_RUN(x...)\n#endif\n\n#ifdef DEBUG_CCIO_RES\n#define DBG_RES(x...)   printk(x)\n#else\n#define DBG_RES(x...)\n#endif\n\n#ifdef DEBUG_CCIO_RUN_SG\n#define DBG_RUN_SG(x...) printk(x)\n#else\n#define DBG_RUN_SG(x...)\n#endif\n\n#define WRITE_U32(value, addr) __raw_writel(value, addr)\n#define READ_U32(addr) __raw_readl(addr)\n\n#define U2_IOA_RUNWAY 0x580\n#define U2_BC_GSC     0x501\n#define UTURN_IOA_RUNWAY 0x581\n#define UTURN_BC_GSC     0x502\n\n#define IOA_NORMAL_MODE      0x00020080  \n#define CMD_TLB_DIRECT_WRITE 35          \n#define CMD_TLB_PURGE        33          \n\nstruct ioa_registers {\n\t \n\tint32_t    unused1[12];\n\tuint32_t   io_command;              \n\tuint32_t   io_status;               \n\tuint32_t   io_control;              \n\tint32_t    unused2[1];\n\n\t \n\tuint32_t   io_err_resp;             \n\tuint32_t   io_err_info;             \n\tuint32_t   io_err_req;              \n\tuint32_t   io_err_resp_hi;          \n\tuint32_t   io_tlb_entry_m;          \n\tuint32_t   io_tlb_entry_l;          \n\tuint32_t   unused3[1];\n\tuint32_t   io_pdir_base;            \n\tuint32_t   io_io_low_hv;            \n\tuint32_t   io_io_high_hv;           \n\tuint32_t   unused4[1];\n\tuint32_t   io_chain_id_mask;        \n\tuint32_t   unused5[2];\n\tuint32_t   io_io_low;               \n\tuint32_t   io_io_high;              \n};\n\n \n\nstruct ioc {\n\tstruct ioa_registers __iomem *ioc_regs;   \n\tu8  *res_map;\t                 \n\t__le64 *pdir_base;\t\t \n\tu32 pdir_size;\t\t\t \n\tu32 res_hint;\t\t\t \n\tu32 res_size;\t\t\t \n\tspinlock_t res_lock;\n\n#ifdef CCIO_COLLECT_STATS\n#define CCIO_SEARCH_SAMPLE 0x100\n\tunsigned long avg_search[CCIO_SEARCH_SAMPLE];\n\tunsigned long avg_idx;\t\t   \n\tunsigned long used_pages;\n\tunsigned long msingle_calls;\n\tunsigned long msingle_pages;\n\tunsigned long msg_calls;\n\tunsigned long msg_pages;\n\tunsigned long usingle_calls;\n\tunsigned long usingle_pages;\n\tunsigned long usg_calls;\n\tunsigned long usg_pages;\n#endif\n\tunsigned short cujo20_bug;\n\n\t \n\tu32 chainid_shift;\t\t \n\tstruct ioc *next;\t\t \n\tconst char *name;\t\t \n\tunsigned int hw_path;            \n\tstruct pci_dev *fake_pci_dev;    \n\tstruct resource mmio_region[2];  \n};\n\nstatic struct ioc *ioc_list;\nstatic int ioc_count;\n\n \n#define IOVP_SIZE PAGE_SIZE\n#define IOVP_SHIFT PAGE_SHIFT\n#define IOVP_MASK PAGE_MASK\n\n \n#define CCIO_IOVA(iovp,offset) ((iovp) | (offset))\n#define CCIO_IOVP(iova) ((iova) & IOVP_MASK)\n\n#define PDIR_INDEX(iovp)    ((iovp)>>IOVP_SHIFT)\n#define MKIOVP(pdir_idx)    ((long)(pdir_idx) << IOVP_SHIFT)\n#define MKIOVA(iovp,offset) (dma_addr_t)((long)iovp | (long)offset)\n\n \n#define CCIO_SEARCH_LOOP(ioc, res_idx, mask, size)  \\\n\tfor (; res_ptr < res_end; ++res_ptr) { \\\n\t\tint ret;\\\n\t\tunsigned int idx;\\\n\t\tidx = (unsigned int)((unsigned long)res_ptr - (unsigned long)ioc->res_map); \\\n\t\tret = iommu_is_span_boundary(idx << 3, pages_needed, 0, boundary_size);\\\n\t\tif ((0 == (*res_ptr & mask)) && !ret) { \\\n\t\t\t*res_ptr |= mask; \\\n\t\t\tres_idx = idx;\\\n\t\t\tioc->res_hint = res_idx + (size >> 3); \\\n\t\t\tgoto resource_found; \\\n\t\t} \\\n\t}\n\n#define CCIO_FIND_FREE_MAPPING(ioa, res_idx, mask, size) \\\n       u##size *res_ptr = (u##size *)&((ioc)->res_map[ioa->res_hint & ~((size >> 3) - 1)]); \\\n       u##size *res_end = (u##size *)&(ioc)->res_map[ioa->res_size]; \\\n\tCCIO_SEARCH_LOOP(ioc, res_idx, mask, size); \\\n\tres_ptr = (u##size *)&(ioc)->res_map[0]; \\\n\tCCIO_SEARCH_LOOP(ioa, res_idx, mask, size);\n\n \n\n \nstatic int\nccio_alloc_range(struct ioc *ioc, struct device *dev, size_t size)\n{\n\tunsigned int pages_needed = size >> IOVP_SHIFT;\n\tunsigned int res_idx;\n\tunsigned long boundary_size;\n#ifdef CCIO_COLLECT_STATS\n\tunsigned long cr_start = mfctl(16);\n#endif\n\t\n\tBUG_ON(pages_needed == 0);\n\tBUG_ON((pages_needed * IOVP_SIZE) > DMA_CHUNK_SIZE);\n\n\tDBG_RES(\"%s() size: %zu pages_needed %d\\n\",\n\t\t\t__func__, size, pages_needed);\n\n\t \n\n\tboundary_size = dma_get_seg_boundary_nr_pages(dev, IOVP_SHIFT);\n\n\tif (pages_needed <= 8) {\n\t\t \n#if 0\n\t\t \n\t\tunsigned long mask = ~(~0UL >> pages_needed);\n\t\tCCIO_FIND_FREE_MAPPING(ioc, res_idx, mask, 8);\n#else\n\t\tCCIO_FIND_FREE_MAPPING(ioc, res_idx, 0xff, 8);\n#endif\n\t} else if (pages_needed <= 16) {\n\t\tCCIO_FIND_FREE_MAPPING(ioc, res_idx, 0xffff, 16);\n\t} else if (pages_needed <= 32) {\n\t\tCCIO_FIND_FREE_MAPPING(ioc, res_idx, ~(unsigned int)0, 32);\n#ifdef __LP64__\n\t} else if (pages_needed <= 64) {\n\t\tCCIO_FIND_FREE_MAPPING(ioc, res_idx, ~0UL, 64);\n#endif\n\t} else {\n\t\tpanic(\"%s: %s() Too many pages to map. pages_needed: %u\\n\",\n\t\t       __FILE__,  __func__, pages_needed);\n\t}\n\n\tpanic(\"%s: %s() I/O MMU is out of mapping resources.\\n\", __FILE__,\n\t      __func__);\n\t\nresource_found:\n\t\n\tDBG_RES(\"%s() res_idx %d res_hint: %d\\n\",\n\t\t__func__, res_idx, ioc->res_hint);\n\n#ifdef CCIO_COLLECT_STATS\n\t{\n\t\tunsigned long cr_end = mfctl(16);\n\t\tunsigned long tmp = cr_end - cr_start;\n\t\t \n\t\tcr_start = (cr_end < cr_start) ?  -(tmp) : (tmp);\n\t}\n\tioc->avg_search[ioc->avg_idx++] = cr_start;\n\tioc->avg_idx &= CCIO_SEARCH_SAMPLE - 1;\n\tioc->used_pages += pages_needed;\n#endif\n\t \n\treturn res_idx << 3;\n}\n\n#define CCIO_FREE_MAPPINGS(ioc, res_idx, mask, size) \\\n        u##size *res_ptr = (u##size *)&((ioc)->res_map[res_idx]); \\\n        BUG_ON((*res_ptr & mask) != mask); \\\n\t*res_ptr &= ~(mask);\n\n \nstatic void\nccio_free_range(struct ioc *ioc, dma_addr_t iova, unsigned long pages_mapped)\n{\n\tunsigned long iovp = CCIO_IOVP(iova);\n\tunsigned int res_idx = PDIR_INDEX(iovp) >> 3;\n\n\tBUG_ON(pages_mapped == 0);\n\tBUG_ON((pages_mapped * IOVP_SIZE) > DMA_CHUNK_SIZE);\n\tBUG_ON(pages_mapped > BITS_PER_LONG);\n\n\tDBG_RES(\"%s():  res_idx: %d pages_mapped %lu\\n\",\n\t\t__func__, res_idx, pages_mapped);\n\n#ifdef CCIO_COLLECT_STATS\n\tioc->used_pages -= pages_mapped;\n#endif\n\n\tif(pages_mapped <= 8) {\n#if 0\n\t\t \n\t\tunsigned long mask = ~(~0UL >> pages_mapped);\n\t\tCCIO_FREE_MAPPINGS(ioc, res_idx, mask, 8);\n#else\n\t\tCCIO_FREE_MAPPINGS(ioc, res_idx, 0xffUL, 8);\n#endif\n\t} else if(pages_mapped <= 16) {\n\t\tCCIO_FREE_MAPPINGS(ioc, res_idx, 0xffffUL, 16);\n\t} else if(pages_mapped <= 32) {\n\t\tCCIO_FREE_MAPPINGS(ioc, res_idx, ~(unsigned int)0, 32);\n#ifdef __LP64__\n\t} else if(pages_mapped <= 64) {\n\t\tCCIO_FREE_MAPPINGS(ioc, res_idx, ~0UL, 64);\n#endif\n\t} else {\n\t\tpanic(\"%s:%s() Too many pages to unmap.\\n\", __FILE__,\n\t\t      __func__);\n\t}\n}\n\n \n\ntypedef unsigned long space_t;\n#define KERNEL_SPACE 0\n\n \n#define IOPDIR_VALID    0x01UL\n#define HINT_SAFE_DMA   0x02UL\t \n#ifdef CONFIG_EISA\n#define HINT_STOP_MOST  0x04UL\t \n#else\n#define HINT_STOP_MOST  0x00UL\t \n#endif\n#define HINT_UDPATE_ENB 0x08UL   \n#define HINT_PREFETCH   0x10UL\t \n\n\n \nstatic u32 hint_lookup[] = {\n\t[DMA_BIDIRECTIONAL]\t= HINT_STOP_MOST | HINT_SAFE_DMA | IOPDIR_VALID,\n\t[DMA_TO_DEVICE]\t\t= HINT_STOP_MOST | HINT_PREFETCH | IOPDIR_VALID,\n\t[DMA_FROM_DEVICE]\t= HINT_STOP_MOST | IOPDIR_VALID,\n};\n\n  \nstatic void\nccio_io_pdir_entry(__le64 *pdir_ptr, space_t sid, unsigned long vba,\n\t\t   unsigned long hints)\n{\n\tregister unsigned long pa;\n\tregister unsigned long ci;  \n\n\t \n\tBUG_ON(sid != KERNEL_SPACE);\n\n\t \n\tpa = lpa(vba);\n\tasm volatile(\"depw  %1,31,12,%0\" : \"+r\" (pa) : \"r\" (hints));\n\t((u32 *)pdir_ptr)[1] = (u32) pa;\n\n\t \n\n#ifdef __LP64__\n\t \n\tasm volatile (\"extrd,u %1,15,4,%0\" : \"=r\" (ci) : \"r\" (pa));\n\tasm volatile (\"extrd,u %1,31,16,%0\" : \"+r\" (pa) : \"r\" (pa));\n\tasm volatile (\"depd  %1,35,4,%0\" : \"+r\" (pa) : \"r\" (ci));\n#else\n\tpa = 0;\n#endif\n\t \n\tasm volatile (\"lci %%r0(%1), %0\" : \"=r\" (ci) : \"r\" (vba));\n\tasm volatile (\"extru %1,19,12,%0\" : \"+r\" (ci) : \"r\" (ci));\n\tasm volatile (\"depw  %1,15,12,%0\" : \"+r\" (pa) : \"r\" (ci));\n\n\t((u32 *)pdir_ptr)[0] = (u32) pa;\n\n\n\t \n\tasm_io_fdc(pdir_ptr);\n\tasm_io_sync();\n}\n\n \nstatic void\nccio_clear_io_tlb(struct ioc *ioc, dma_addr_t iovp, size_t byte_cnt)\n{\n\tu32 chain_size = 1 << ioc->chainid_shift;\n\n\tiovp &= IOVP_MASK;\t \n\tbyte_cnt += chain_size;\n\n\twhile(byte_cnt > chain_size) {\n\t\tWRITE_U32(CMD_TLB_PURGE | iovp, &ioc->ioc_regs->io_command);\n\t\tiovp += chain_size;\n\t\tbyte_cnt -= chain_size;\n\t}\n}\n\n  \nstatic void\nccio_mark_invalid(struct ioc *ioc, dma_addr_t iova, size_t byte_cnt)\n{\n\tu32 iovp = (u32)CCIO_IOVP(iova);\n\tsize_t saved_byte_cnt;\n\n\t \n\tsaved_byte_cnt = byte_cnt = ALIGN(byte_cnt, IOVP_SIZE);\n\n\twhile(byte_cnt > 0) {\n\t\t \n\t\tunsigned int idx = PDIR_INDEX(iovp);\n\t\tchar *pdir_ptr = (char *) &(ioc->pdir_base[idx]);\n\n\t\tBUG_ON(idx >= (ioc->pdir_size / sizeof(u64)));\n\t\tpdir_ptr[7] = 0;\t  \n\t\t \n\t\tasm_io_fdc(pdir_ptr);\n\n\t\tiovp     += IOVP_SIZE;\n\t\tbyte_cnt -= IOVP_SIZE;\n\t}\n\n\tasm_io_sync();\n\tccio_clear_io_tlb(ioc, CCIO_IOVP(iova), saved_byte_cnt);\n}\n\n \n\n \nstatic int \nccio_dma_supported(struct device *dev, u64 mask)\n{\n\tif(dev == NULL) {\n\t\tprintk(KERN_ERR MODULE_NAME \": EISA/ISA/et al not supported\\n\");\n\t\tBUG();\n\t\treturn 0;\n\t}\n\n\t \n\treturn (int)(mask >= 0xffffffffUL);\n}\n\n \nstatic dma_addr_t \nccio_map_single(struct device *dev, void *addr, size_t size,\n\t\tenum dma_data_direction direction)\n{\n\tint idx;\n\tstruct ioc *ioc;\n\tunsigned long flags;\n\tdma_addr_t iovp;\n\tdma_addr_t offset;\n\t__le64 *pdir_start;\n\tunsigned long hint = hint_lookup[(int)direction];\n\n\tBUG_ON(!dev);\n\tioc = GET_IOC(dev);\n\tif (!ioc)\n\t\treturn DMA_MAPPING_ERROR;\n\n\tBUG_ON(size <= 0);\n\n\t \n\toffset = ((unsigned long) addr) & ~IOVP_MASK;\n\n\t \n\tsize = ALIGN(size + offset, IOVP_SIZE);\n\tspin_lock_irqsave(&ioc->res_lock, flags);\n\n#ifdef CCIO_COLLECT_STATS\n\tioc->msingle_calls++;\n\tioc->msingle_pages += size >> IOVP_SHIFT;\n#endif\n\n\tidx = ccio_alloc_range(ioc, dev, size);\n\tiovp = (dma_addr_t)MKIOVP(idx);\n\n\tpdir_start = &(ioc->pdir_base[idx]);\n\n\tDBG_RUN(\"%s() %px -> %#lx size: %zu\\n\",\n\t\t__func__, addr, (long)(iovp | offset), size);\n\n\t \n\tif((size % L1_CACHE_BYTES) || ((unsigned long)addr % L1_CACHE_BYTES))\n\t\thint |= HINT_SAFE_DMA;\n\n\twhile(size > 0) {\n\t\tccio_io_pdir_entry(pdir_start, KERNEL_SPACE, (unsigned long)addr, hint);\n\n\t\tDBG_RUN(\" pdir %p %08x%08x\\n\",\n\t\t\tpdir_start,\n\t\t\t(u32) (((u32 *) pdir_start)[0]),\n\t\t\t(u32) (((u32 *) pdir_start)[1]));\n\t\t++pdir_start;\n\t\taddr += IOVP_SIZE;\n\t\tsize -= IOVP_SIZE;\n\t}\n\n\tspin_unlock_irqrestore(&ioc->res_lock, flags);\n\n\t \n\treturn CCIO_IOVA(iovp, offset);\n}\n\n\nstatic dma_addr_t\nccio_map_page(struct device *dev, struct page *page, unsigned long offset,\n\t\tsize_t size, enum dma_data_direction direction,\n\t\tunsigned long attrs)\n{\n\treturn ccio_map_single(dev, page_address(page) + offset, size,\n\t\t\tdirection);\n}\n\n\n \nstatic void \nccio_unmap_page(struct device *dev, dma_addr_t iova, size_t size,\n\t\tenum dma_data_direction direction, unsigned long attrs)\n{\n\tstruct ioc *ioc;\n\tunsigned long flags; \n\tdma_addr_t offset = iova & ~IOVP_MASK;\n\t\n\tBUG_ON(!dev);\n\tioc = GET_IOC(dev);\n\tif (!ioc) {\n\t\tWARN_ON(!ioc);\n\t\treturn;\n\t}\n\n\tDBG_RUN(\"%s() iovp %#lx/%zx\\n\",\n\t\t__func__, (long)iova, size);\n\n\tiova ^= offset;         \n\tsize += offset;\n\tsize = ALIGN(size, IOVP_SIZE);\n\n\tspin_lock_irqsave(&ioc->res_lock, flags);\n\n#ifdef CCIO_COLLECT_STATS\n\tioc->usingle_calls++;\n\tioc->usingle_pages += size >> IOVP_SHIFT;\n#endif\n\n\tccio_mark_invalid(ioc, iova, size);\n\tccio_free_range(ioc, iova, (size >> IOVP_SHIFT));\n\tspin_unlock_irqrestore(&ioc->res_lock, flags);\n}\n\n \nstatic void * \nccio_alloc(struct device *dev, size_t size, dma_addr_t *dma_handle, gfp_t flag,\n\t\tunsigned long attrs)\n{\n\tvoid *ret;\n#if 0\n \n\tif(!hwdev) {\n\t\t \n\t\t*dma_handle = 0;\n\t\treturn 0;\n\t}\n#endif\n\tret = (void *) __get_free_pages(flag, get_order(size));\n\n\tif (ret) {\n\t\tmemset(ret, 0, size);\n\t\t*dma_handle = ccio_map_single(dev, ret, size, DMA_BIDIRECTIONAL);\n\t}\n\n\treturn ret;\n}\n\n \nstatic void \nccio_free(struct device *dev, size_t size, void *cpu_addr,\n\t\tdma_addr_t dma_handle, unsigned long attrs)\n{\n\tccio_unmap_page(dev, dma_handle, size, 0, 0);\n\tfree_pages((unsigned long)cpu_addr, get_order(size));\n}\n\n \n#define PIDE_FLAG 0x80000000UL\n\n#ifdef CCIO_COLLECT_STATS\n#define IOMMU_MAP_STATS\n#endif\n#include \"iommu-helpers.h\"\n\n \nstatic int\nccio_map_sg(struct device *dev, struct scatterlist *sglist, int nents, \n\t    enum dma_data_direction direction, unsigned long attrs)\n{\n\tstruct ioc *ioc;\n\tint coalesced, filled = 0;\n\tunsigned long flags;\n\tunsigned long hint = hint_lookup[(int)direction];\n\tunsigned long prev_len = 0, current_len = 0;\n\tint i;\n\t\n\tBUG_ON(!dev);\n\tioc = GET_IOC(dev);\n\tif (!ioc)\n\t\treturn -EINVAL;\n\t\n\tDBG_RUN_SG(\"%s() START %d entries\\n\", __func__, nents);\n\n\t \n\tif (nents == 1) {\n\t\tsg_dma_address(sglist) = ccio_map_single(dev,\n\t\t\t\tsg_virt(sglist), sglist->length,\n\t\t\t\tdirection);\n\t\tsg_dma_len(sglist) = sglist->length;\n\t\treturn 1;\n\t}\n\n\tfor(i = 0; i < nents; i++)\n\t\tprev_len += sglist[i].length;\n\t\n\tspin_lock_irqsave(&ioc->res_lock, flags);\n\n#ifdef CCIO_COLLECT_STATS\n\tioc->msg_calls++;\n#endif\n\n\t \n\tcoalesced = iommu_coalesce_chunks(ioc, dev, sglist, nents, ccio_alloc_range);\n\n\t \n\tfilled = iommu_fill_pdir(ioc, sglist, nents, hint, ccio_io_pdir_entry);\n\n\tspin_unlock_irqrestore(&ioc->res_lock, flags);\n\n\tBUG_ON(coalesced != filled);\n\n\tDBG_RUN_SG(\"%s() DONE %d mappings\\n\", __func__, filled);\n\n\tfor (i = 0; i < filled; i++)\n\t\tcurrent_len += sg_dma_len(sglist + i);\n\n\tBUG_ON(current_len != prev_len);\n\n\treturn filled;\n}\n\n \nstatic void \nccio_unmap_sg(struct device *dev, struct scatterlist *sglist, int nents, \n\t      enum dma_data_direction direction, unsigned long attrs)\n{\n\tstruct ioc *ioc;\n\n\tBUG_ON(!dev);\n\tioc = GET_IOC(dev);\n\tif (!ioc) {\n\t\tWARN_ON(!ioc);\n\t\treturn;\n\t}\n\n\tDBG_RUN_SG(\"%s() START %d entries, %p,%x\\n\",\n\t\t__func__, nents, sg_virt(sglist), sglist->length);\n\n#ifdef CCIO_COLLECT_STATS\n\tioc->usg_calls++;\n#endif\n\n\twhile (nents && sg_dma_len(sglist)) {\n\n#ifdef CCIO_COLLECT_STATS\n\t\tioc->usg_pages += sg_dma_len(sglist) >> PAGE_SHIFT;\n#endif\n\t\tccio_unmap_page(dev, sg_dma_address(sglist),\n\t\t\t\t  sg_dma_len(sglist), direction, 0);\n\t\t++sglist;\n\t\tnents--;\n\t}\n\n\tDBG_RUN_SG(\"%s() DONE (nents %d)\\n\", __func__, nents);\n}\n\nstatic const struct dma_map_ops ccio_ops = {\n\t.dma_supported =\tccio_dma_supported,\n\t.alloc =\t\tccio_alloc,\n\t.free =\t\t\tccio_free,\n\t.map_page =\t\tccio_map_page,\n\t.unmap_page =\t\tccio_unmap_page,\n\t.map_sg =\t\tccio_map_sg,\n\t.unmap_sg =\t\tccio_unmap_sg,\n\t.get_sgtable =\t\tdma_common_get_sgtable,\n\t.alloc_pages =\t\tdma_common_alloc_pages,\n\t.free_pages =\t\tdma_common_free_pages,\n};\n\n#ifdef CONFIG_PROC_FS\nstatic int ccio_proc_info(struct seq_file *m, void *p)\n{\n\tstruct ioc *ioc = ioc_list;\n\n\twhile (ioc != NULL) {\n\t\tunsigned int total_pages = ioc->res_size << 3;\n#ifdef CCIO_COLLECT_STATS\n\t\tunsigned long avg = 0, min, max;\n\t\tint j;\n#endif\n\n\t\tseq_printf(m, \"%s\\n\", ioc->name);\n\t\t\n\t\tseq_printf(m, \"Cujo 2.0 bug    : %s\\n\",\n\t\t\t   (ioc->cujo20_bug ? \"yes\" : \"no\"));\n\t\t\n\t\tseq_printf(m, \"IO PDIR size    : %d bytes (%d entries)\\n\",\n\t\t\t   total_pages * 8, total_pages);\n\n#ifdef CCIO_COLLECT_STATS\n\t\tseq_printf(m, \"IO PDIR entries : %ld free  %ld used (%d%%)\\n\",\n\t\t\t   total_pages - ioc->used_pages, ioc->used_pages,\n\t\t\t   (int)(ioc->used_pages * 100 / total_pages));\n#endif\n\n\t\tseq_printf(m, \"Resource bitmap : %d bytes (%d pages)\\n\",\n\t\t\t   ioc->res_size, total_pages);\n\n#ifdef CCIO_COLLECT_STATS\n\t\tmin = max = ioc->avg_search[0];\n\t\tfor(j = 0; j < CCIO_SEARCH_SAMPLE; ++j) {\n\t\t\tavg += ioc->avg_search[j];\n\t\t\tif(ioc->avg_search[j] > max) \n\t\t\t\tmax = ioc->avg_search[j];\n\t\t\tif(ioc->avg_search[j] < min) \n\t\t\t\tmin = ioc->avg_search[j];\n\t\t}\n\t\tavg /= CCIO_SEARCH_SAMPLE;\n\t\tseq_printf(m, \"  Bitmap search : %ld/%ld/%ld (min/avg/max CPU Cycles)\\n\",\n\t\t\t   min, avg, max);\n\n\t\tseq_printf(m, \"pci_map_single(): %8ld calls  %8ld pages (avg %d/1000)\\n\",\n\t\t\t   ioc->msingle_calls, ioc->msingle_pages,\n\t\t\t   (int)((ioc->msingle_pages * 1000)/ioc->msingle_calls));\n\n\t\t \n\t\tmin = ioc->usingle_calls - ioc->usg_calls;\n\t\tmax = ioc->usingle_pages - ioc->usg_pages;\n\t\tseq_printf(m, \"pci_unmap_single: %8ld calls  %8ld pages (avg %d/1000)\\n\",\n\t\t\t   min, max, (int)((max * 1000)/min));\n\n\t\tseq_printf(m, \"pci_map_sg()    : %8ld calls  %8ld pages (avg %d/1000)\\n\",\n\t\t\t   ioc->msg_calls, ioc->msg_pages,\n\t\t\t   (int)((ioc->msg_pages * 1000)/ioc->msg_calls));\n\n\t\tseq_printf(m, \"pci_unmap_sg()  : %8ld calls  %8ld pages (avg %d/1000)\\n\\n\\n\",\n\t\t\t   ioc->usg_calls, ioc->usg_pages,\n\t\t\t   (int)((ioc->usg_pages * 1000)/ioc->usg_calls));\n#endif\t \n\n\t\tioc = ioc->next;\n\t}\n\n\treturn 0;\n}\n\nstatic int ccio_proc_bitmap_info(struct seq_file *m, void *p)\n{\n\tstruct ioc *ioc = ioc_list;\n\n\twhile (ioc != NULL) {\n\t\tseq_hex_dump(m, \"   \", DUMP_PREFIX_NONE, 32, 4, ioc->res_map,\n\t\t\t     ioc->res_size, false);\n\t\tseq_putc(m, '\\n');\n\t\tioc = ioc->next;\n\t\tbreak;  \n\t}\n\n\treturn 0;\n}\n#endif  \n\n \nstatic struct ioc * ccio_find_ioc(int hw_path)\n{\n\tint i;\n\tstruct ioc *ioc;\n\n\tioc = ioc_list;\n\tfor (i = 0; i < ioc_count; i++) {\n\t\tif (ioc->hw_path == hw_path)\n\t\t\treturn ioc;\n\n\t\tioc = ioc->next;\n\t}\n\n\treturn NULL;\n}\n\n \nvoid * ccio_get_iommu(const struct parisc_device *dev)\n{\n\tdev = find_pa_parent_type(dev, HPHW_IOA);\n\tif (!dev)\n\t\treturn NULL;\n\n\treturn ccio_find_ioc(dev->hw_path);\n}\n\n#define CUJO_20_STEP       0x10000000\t \n\n \nvoid __init ccio_cujo20_fixup(struct parisc_device *cujo, u32 iovp)\n{\n\tunsigned int idx;\n\tstruct parisc_device *dev = parisc_parent(cujo);\n\tstruct ioc *ioc = ccio_get_iommu(dev);\n\tu8 *res_ptr;\n\n\tioc->cujo20_bug = 1;\n\tres_ptr = ioc->res_map;\n\tidx = PDIR_INDEX(iovp) >> 3;\n\n\twhile (idx < ioc->res_size) {\n\t\tres_ptr[idx] |= 0xff;\n\t\tidx += PDIR_INDEX(CUJO_20_STEP) >> 3;\n\t}\n}\n\n#if 0\n \n\n \nstatic int\nccio_get_iotlb_size(struct parisc_device *dev)\n{\n\tif (dev->spa_shift == 0) {\n\t\tpanic(\"%s() : Can't determine I/O TLB size.\\n\", __func__);\n\t}\n\treturn (1 << dev->spa_shift);\n}\n#else\n\n \n#define CCIO_CHAINID_SHIFT\t8\n#define CCIO_CHAINID_MASK\t0xff\n#endif  \n\n \nstatic const struct parisc_device_id ccio_tbl[] __initconst = {\n\t{ HPHW_IOA, HVERSION_REV_ANY_ID, U2_IOA_RUNWAY, 0xb },  \n\t{ HPHW_IOA, HVERSION_REV_ANY_ID, UTURN_IOA_RUNWAY, 0xb },  \n\t{ 0, }\n};\n\nstatic int ccio_probe(struct parisc_device *dev);\n\nstatic struct parisc_driver ccio_driver __refdata = {\n\t.name =\t\t\"ccio\",\n\t.id_table =\tccio_tbl,\n\t.probe =\tccio_probe,\n};\n\n \nstatic void __init\nccio_ioc_init(struct ioc *ioc)\n{\n\tint i;\n\tunsigned int iov_order;\n\tu32 iova_space_size;\n\n\t \n\n\tiova_space_size = (u32) (totalram_pages() / count_parisc_driver(&ccio_driver));\n\n\t \n\n\tif (iova_space_size < (1 << (20 - PAGE_SHIFT))) {\n\t\tiova_space_size =  1 << (20 - PAGE_SHIFT);\n#ifdef __LP64__\n\t} else if (iova_space_size > (1 << (30 - PAGE_SHIFT))) {\n\t\tiova_space_size =  1 << (30 - PAGE_SHIFT);\n#endif\n\t}\n\n\t \n\n\t \n\n\tiov_order = get_order(iova_space_size << PAGE_SHIFT);\n\n\t \n\tiova_space_size = 1 << (iov_order + PAGE_SHIFT);\n\n\tioc->pdir_size = (iova_space_size / IOVP_SIZE) * sizeof(u64);\n\n\tBUG_ON(ioc->pdir_size > 8 * 1024 * 1024);    \n\n\t \n\tBUG_ON((1 << get_order(ioc->pdir_size)) != (ioc->pdir_size >> PAGE_SHIFT));\n\n\tDBG_INIT(\"%s() hpa 0x%p mem %luMB IOV %dMB (%d bits)\\n\",\n\t\t\t__func__, ioc->ioc_regs,\n\t\t\t(unsigned long) totalram_pages() >> (20 - PAGE_SHIFT),\n\t\t\tiova_space_size>>20,\n\t\t\tiov_order + PAGE_SHIFT);\n\n\tioc->pdir_base = (__le64 *)__get_free_pages(GFP_KERNEL,\n\t\t\t\t\t\t get_order(ioc->pdir_size));\n\tif(NULL == ioc->pdir_base) {\n\t\tpanic(\"%s() could not allocate I/O Page Table\\n\", __func__);\n\t}\n\tmemset(ioc->pdir_base, 0, ioc->pdir_size);\n\n\tBUG_ON((((unsigned long)ioc->pdir_base) & PAGE_MASK) != (unsigned long)ioc->pdir_base);\n\tDBG_INIT(\" base %p\\n\", ioc->pdir_base);\n\n\t \n\tioc->res_size = (ioc->pdir_size / sizeof(u64)) >> 3;\n\tDBG_INIT(\"%s() res_size 0x%x\\n\", __func__, ioc->res_size);\n\t\n\tioc->res_map = (u8 *)__get_free_pages(GFP_KERNEL, \n\t\t\t\t\t      get_order(ioc->res_size));\n\tif(NULL == ioc->res_map) {\n\t\tpanic(\"%s() could not allocate resource map\\n\", __func__);\n\t}\n\tmemset(ioc->res_map, 0, ioc->res_size);\n\n\t \n\tioc->res_hint = 16;\n\n\t \n\tspin_lock_init(&ioc->res_lock);\n\n\t \n\tioc->chainid_shift = get_order(iova_space_size) + PAGE_SHIFT - CCIO_CHAINID_SHIFT;\n\tDBG_INIT(\" chainid_shift 0x%x\\n\", ioc->chainid_shift);\n\n\t \n\tWRITE_U32(CCIO_CHAINID_MASK << ioc->chainid_shift, \n\t\t  &ioc->ioc_regs->io_chain_id_mask);\n\n\tWRITE_U32(virt_to_phys(ioc->pdir_base), \n\t\t  &ioc->ioc_regs->io_pdir_base);\n\n\t \n\tWRITE_U32(IOA_NORMAL_MODE, &ioc->ioc_regs->io_control);\n\n\t \n\tWRITE_U32(0, &ioc->ioc_regs->io_tlb_entry_m);\n\tWRITE_U32(0, &ioc->ioc_regs->io_tlb_entry_l);\n\n\tfor(i = 1 << CCIO_CHAINID_SHIFT; i ; i--) {\n\t\tWRITE_U32((CMD_TLB_DIRECT_WRITE | (i << ioc->chainid_shift)),\n\t\t\t  &ioc->ioc_regs->io_command);\n\t}\n}\n\nstatic void __init\nccio_init_resource(struct resource *res, char *name, void __iomem *ioaddr)\n{\n\tint result;\n\n\tres->parent = NULL;\n\tres->flags = IORESOURCE_MEM;\n\t \n\tres->start = (unsigned long)((signed) READ_U32(ioaddr) << 16);\n\tres->end = (unsigned long)((signed) (READ_U32(ioaddr + 4) << 16) - 1);\n\tres->name = name;\n\t \n\tif (res->end + 1 == res->start)\n\t\treturn;\n\n\t \n\tresult = insert_resource(&iomem_resource, res);\n\tif (result < 0) {\n\t\tprintk(KERN_ERR \"%s() failed to claim CCIO bus address space (%08lx,%08lx)\\n\", \n\t\t\t__func__, (unsigned long)res->start, (unsigned long)res->end);\n\t}\n}\n\nstatic int __init ccio_init_resources(struct ioc *ioc)\n{\n\tstruct resource *res = ioc->mmio_region;\n\tchar *name = kmalloc(14, GFP_KERNEL);\n\tif (unlikely(!name))\n\t\treturn -ENOMEM;\n\tsnprintf(name, 14, \"GSC Bus [%d/]\", ioc->hw_path);\n\n\tccio_init_resource(res, name, &ioc->ioc_regs->io_io_low);\n\tccio_init_resource(res + 1, name, &ioc->ioc_regs->io_io_low_hv);\n\treturn 0;\n}\n\nstatic int new_ioc_area(struct resource *res, unsigned long size,\n\t\tunsigned long min, unsigned long max, unsigned long align)\n{\n\tif (max <= min)\n\t\treturn -EBUSY;\n\n\tres->start = (max - size + 1) &~ (align - 1);\n\tres->end = res->start + size;\n\t\n\t \n\tif (!insert_resource(&iomem_resource, res))\n\t\treturn 0;\n\n\treturn new_ioc_area(res, size, min, max - size, align);\n}\n\nstatic int expand_ioc_area(struct resource *res, unsigned long size,\n\t\tunsigned long min, unsigned long max, unsigned long align)\n{\n\tunsigned long start, len;\n\n\tif (!res->parent)\n\t\treturn new_ioc_area(res, size, min, max, align);\n\n\tstart = (res->start - size) &~ (align - 1);\n\tlen = res->end - start + 1;\n\tif (start >= min) {\n\t\tif (!adjust_resource(res, start, len))\n\t\t\treturn 0;\n\t}\n\n\tstart = res->start;\n\tlen = ((size + res->end + align) &~ (align - 1)) - start;\n\tif (start + len <= max) {\n\t\tif (!adjust_resource(res, start, len))\n\t\t\treturn 0;\n\t}\n\n\treturn -EBUSY;\n}\n\n \nint ccio_allocate_resource(const struct parisc_device *dev,\n\t\tstruct resource *res, unsigned long size,\n\t\tunsigned long min, unsigned long max, unsigned long align)\n{\n\tstruct resource *parent = &iomem_resource;\n\tstruct ioc *ioc = ccio_get_iommu(dev);\n\tif (!ioc)\n\t\tgoto out;\n\n\tparent = ioc->mmio_region;\n\tif (parent->parent &&\n\t    !allocate_resource(parent, res, size, min, max, align, NULL, NULL))\n\t\treturn 0;\n\n\tif ((parent + 1)->parent &&\n\t    !allocate_resource(parent + 1, res, size, min, max, align,\n\t\t\t\tNULL, NULL))\n\t\treturn 0;\n\n\tif (!expand_ioc_area(parent, size, min, max, align)) {\n\t\t__raw_writel(((parent->start)>>16) | 0xffff0000,\n\t\t\t     &ioc->ioc_regs->io_io_low);\n\t\t__raw_writel(((parent->end)>>16) | 0xffff0000,\n\t\t\t     &ioc->ioc_regs->io_io_high);\n\t} else if (!expand_ioc_area(parent + 1, size, min, max, align)) {\n\t\tparent++;\n\t\t__raw_writel(((parent->start)>>16) | 0xffff0000,\n\t\t\t     &ioc->ioc_regs->io_io_low_hv);\n\t\t__raw_writel(((parent->end)>>16) | 0xffff0000,\n\t\t\t     &ioc->ioc_regs->io_io_high_hv);\n\t} else {\n\t\treturn -EBUSY;\n\t}\n\n out:\n\treturn allocate_resource(parent, res, size, min, max, align, NULL,NULL);\n}\n\nint ccio_request_resource(const struct parisc_device *dev,\n\t\tstruct resource *res)\n{\n\tstruct resource *parent;\n\tstruct ioc *ioc = ccio_get_iommu(dev);\n\n\tif (!ioc) {\n\t\tparent = &iomem_resource;\n\t} else if ((ioc->mmio_region->start <= res->start) &&\n\t\t\t(res->end <= ioc->mmio_region->end)) {\n\t\tparent = ioc->mmio_region;\n\t} else if (((ioc->mmio_region + 1)->start <= res->start) &&\n\t\t\t(res->end <= (ioc->mmio_region + 1)->end)) {\n\t\tparent = ioc->mmio_region + 1;\n\t} else {\n\t\treturn -EBUSY;\n\t}\n\n\t \n\treturn insert_resource(parent, res);\n}\n\n \nstatic int __init ccio_probe(struct parisc_device *dev)\n{\n\tint i;\n\tstruct ioc *ioc, **ioc_p = &ioc_list;\n\tstruct pci_hba_data *hba;\n\n\tioc = kzalloc(sizeof(struct ioc), GFP_KERNEL);\n\tif (ioc == NULL) {\n\t\tprintk(KERN_ERR MODULE_NAME \": memory allocation failure\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tioc->name = dev->id.hversion == U2_IOA_RUNWAY ? \"U2\" : \"UTurn\";\n\n\tprintk(KERN_INFO \"Found %s at 0x%lx\\n\", ioc->name,\n\t\t(unsigned long)dev->hpa.start);\n\n\tfor (i = 0; i < ioc_count; i++) {\n\t\tioc_p = &(*ioc_p)->next;\n\t}\n\t*ioc_p = ioc;\n\n\tioc->hw_path = dev->hw_path;\n\tioc->ioc_regs = ioremap(dev->hpa.start, 4096);\n\tif (!ioc->ioc_regs) {\n\t\tkfree(ioc);\n\t\treturn -ENOMEM;\n\t}\n\tccio_ioc_init(ioc);\n\tif (ccio_init_resources(ioc)) {\n\t\tiounmap(ioc->ioc_regs);\n\t\tkfree(ioc);\n\t\treturn -ENOMEM;\n\t}\n\thppa_dma_ops = &ccio_ops;\n\n\thba = kzalloc(sizeof(*hba), GFP_KERNEL);\n\t \n\tBUG_ON(hba == NULL);\n\n\thba->iommu = ioc;\n\tdev->dev.platform_data = hba;\n\n#ifdef CONFIG_PROC_FS\n\tif (ioc_count == 0) {\n\t\tstruct proc_dir_entry *runway;\n\n\t\trunway = proc_mkdir(\"bus/runway\", NULL);\n\t\tif (runway) {\n\t\t\tproc_create_single(MODULE_NAME, 0, runway,\n\t\t\t\tccio_proc_info);\n\t\t\tproc_create_single(MODULE_NAME\"-bitmap\", 0, runway,\n\t\t\t\tccio_proc_bitmap_info);\n\t\t}\n\t}\n#endif\n\tioc_count++;\n\treturn 0;\n}\n\n \nstatic int __init ccio_init(void)\n{\n\treturn register_parisc_driver(&ccio_driver);\n}\narch_initcall(ccio_init);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}