{
  "module_name": "knav_dma.c",
  "hash_id": "f2fcc2d266a44cb75ba371bde243d0616d2ff0884125ebb9781a265b75a6240c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/soc/ti/knav_dma.c",
  "human_readable_source": "\n \n\n#include <linux/io.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n#include <linux/dma-direction.h>\n#include <linux/interrupt.h>\n#include <linux/pm_runtime.h>\n#include <linux/of_dma.h>\n#include <linux/of_address.h>\n#include <linux/platform_device.h>\n#include <linux/soc/ti/knav_dma.h>\n#include <linux/debugfs.h>\n#include <linux/seq_file.h>\n\n#define REG_MASK\t\t0xffffffff\n\n#define DMA_LOOPBACK\t\tBIT(31)\n#define DMA_ENABLE\t\tBIT(31)\n#define DMA_TEARDOWN\t\tBIT(30)\n\n#define DMA_TX_FILT_PSWORDS\tBIT(29)\n#define DMA_TX_FILT_EINFO\tBIT(30)\n#define DMA_TX_PRIO_SHIFT\t0\n#define DMA_RX_PRIO_SHIFT\t16\n#define DMA_PRIO_MASK\t\tGENMASK(3, 0)\n#define DMA_PRIO_DEFAULT\t0\n#define DMA_RX_TIMEOUT_DEFAULT\t17500  \n#define DMA_RX_TIMEOUT_MASK\tGENMASK(16, 0)\n#define DMA_RX_TIMEOUT_SHIFT\t0\n\n#define CHAN_HAS_EPIB\t\tBIT(30)\n#define CHAN_HAS_PSINFO\t\tBIT(29)\n#define CHAN_ERR_RETRY\t\tBIT(28)\n#define CHAN_PSINFO_AT_SOP\tBIT(25)\n#define CHAN_SOP_OFF_SHIFT\t16\n#define CHAN_SOP_OFF_MASK\tGENMASK(9, 0)\n#define DESC_TYPE_SHIFT\t\t26\n#define DESC_TYPE_MASK\t\tGENMASK(2, 0)\n\n \n#define CHAN_QNUM_MASK\t\tGENMASK(14, 0)\n#define DMA_MAX_QMS\t\t4\n#define DMA_TIMEOUT\t\t1\t \n#define DMA_INVALID_ID\t\t0xffff\n\nstruct reg_global {\n\tu32\trevision;\n\tu32\tperf_control;\n\tu32\temulation_control;\n\tu32\tpriority_control;\n\tu32\tqm_base_address[DMA_MAX_QMS];\n};\n\nstruct reg_chan {\n\tu32\tcontrol;\n\tu32\tmode;\n\tu32\t__rsvd[6];\n};\n\nstruct reg_tx_sched {\n\tu32\tprio;\n};\n\nstruct reg_rx_flow {\n\tu32\tcontrol;\n\tu32\ttags;\n\tu32\ttag_sel;\n\tu32\tfdq_sel[2];\n\tu32\tthresh[3];\n};\n\nstruct knav_dma_pool_device {\n\tstruct device\t\t\t*dev;\n\tstruct list_head\t\tlist;\n};\n\nstruct knav_dma_device {\n\tbool\t\t\t\tloopback, enable_all;\n\tunsigned\t\t\ttx_priority, rx_priority, rx_timeout;\n\tunsigned\t\t\tlogical_queue_managers;\n\tunsigned\t\t\tqm_base_address[DMA_MAX_QMS];\n\tstruct reg_global __iomem\t*reg_global;\n\tstruct reg_chan __iomem\t\t*reg_tx_chan;\n\tstruct reg_rx_flow __iomem\t*reg_rx_flow;\n\tstruct reg_chan __iomem\t\t*reg_rx_chan;\n\tstruct reg_tx_sched __iomem\t*reg_tx_sched;\n\tunsigned\t\t\tmax_rx_chan, max_tx_chan;\n\tunsigned\t\t\tmax_rx_flow;\n\tchar\t\t\t\tname[32];\n\tatomic_t\t\t\tref_count;\n\tstruct list_head\t\tlist;\n\tstruct list_head\t\tchan_list;\n\tspinlock_t\t\t\tlock;\n};\n\nstruct knav_dma_chan {\n\tenum dma_transfer_direction\tdirection;\n\tstruct knav_dma_device\t\t*dma;\n\tatomic_t\t\t\tref_count;\n\n\t \n\tstruct reg_chan __iomem\t\t*reg_chan;\n\tstruct reg_tx_sched __iomem\t*reg_tx_sched;\n\tstruct reg_rx_flow __iomem\t*reg_rx_flow;\n\n\t \n\tunsigned\t\t\tchannel, flow;\n\tstruct knav_dma_cfg\t\tcfg;\n\tstruct list_head\t\tlist;\n\tspinlock_t\t\t\tlock;\n};\n\n#define chan_number(ch)\t((ch->direction == DMA_MEM_TO_DEV) ? \\\n\t\t\tch->channel : ch->flow)\n\nstatic struct knav_dma_pool_device *kdev;\n\nstatic bool device_ready;\nbool knav_dma_device_ready(void)\n{\n\treturn device_ready;\n}\nEXPORT_SYMBOL_GPL(knav_dma_device_ready);\n\nstatic bool check_config(struct knav_dma_chan *chan, struct knav_dma_cfg *cfg)\n{\n\tif (!memcmp(&chan->cfg, cfg, sizeof(*cfg)))\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\nstatic int chan_start(struct knav_dma_chan *chan,\n\t\t\tstruct knav_dma_cfg *cfg)\n{\n\tu32 v = 0;\n\n\tspin_lock(&chan->lock);\n\tif ((chan->direction == DMA_MEM_TO_DEV) && chan->reg_chan) {\n\t\tif (cfg->u.tx.filt_pswords)\n\t\t\tv |= DMA_TX_FILT_PSWORDS;\n\t\tif (cfg->u.tx.filt_einfo)\n\t\t\tv |= DMA_TX_FILT_EINFO;\n\t\twritel_relaxed(v, &chan->reg_chan->mode);\n\t\twritel_relaxed(DMA_ENABLE, &chan->reg_chan->control);\n\t}\n\n\tif (chan->reg_tx_sched)\n\t\twritel_relaxed(cfg->u.tx.priority, &chan->reg_tx_sched->prio);\n\n\tif (chan->reg_rx_flow) {\n\t\tv = 0;\n\n\t\tif (cfg->u.rx.einfo_present)\n\t\t\tv |= CHAN_HAS_EPIB;\n\t\tif (cfg->u.rx.psinfo_present)\n\t\t\tv |= CHAN_HAS_PSINFO;\n\t\tif (cfg->u.rx.err_mode == DMA_RETRY)\n\t\t\tv |= CHAN_ERR_RETRY;\n\t\tv |= (cfg->u.rx.desc_type & DESC_TYPE_MASK) << DESC_TYPE_SHIFT;\n\t\tif (cfg->u.rx.psinfo_at_sop)\n\t\t\tv |= CHAN_PSINFO_AT_SOP;\n\t\tv |= (cfg->u.rx.sop_offset & CHAN_SOP_OFF_MASK)\n\t\t\t<< CHAN_SOP_OFF_SHIFT;\n\t\tv |= cfg->u.rx.dst_q & CHAN_QNUM_MASK;\n\n\t\twritel_relaxed(v, &chan->reg_rx_flow->control);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->tags);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->tag_sel);\n\n\t\tv =  cfg->u.rx.fdq[0] << 16;\n\t\tv |=  cfg->u.rx.fdq[1] & CHAN_QNUM_MASK;\n\t\twritel_relaxed(v, &chan->reg_rx_flow->fdq_sel[0]);\n\n\t\tv =  cfg->u.rx.fdq[2] << 16;\n\t\tv |=  cfg->u.rx.fdq[3] & CHAN_QNUM_MASK;\n\t\twritel_relaxed(v, &chan->reg_rx_flow->fdq_sel[1]);\n\n\t\twritel_relaxed(0, &chan->reg_rx_flow->thresh[0]);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->thresh[1]);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->thresh[2]);\n\t}\n\n\t \n\tmemcpy(&chan->cfg, cfg, sizeof(*cfg));\n\tspin_unlock(&chan->lock);\n\n\treturn 0;\n}\n\nstatic int chan_teardown(struct knav_dma_chan *chan)\n{\n\tunsigned long end, value;\n\n\tif (!chan->reg_chan)\n\t\treturn 0;\n\n\t \n\twritel_relaxed(DMA_TEARDOWN, &chan->reg_chan->control);\n\n\t \n\tend = jiffies + msecs_to_jiffies(DMA_TIMEOUT);\n\tdo {\n\t\tvalue = readl_relaxed(&chan->reg_chan->control);\n\t\tif ((value & DMA_ENABLE) == 0)\n\t\t\tbreak;\n\t} while (time_after(end, jiffies));\n\n\tif (readl_relaxed(&chan->reg_chan->control) & DMA_ENABLE) {\n\t\tdev_err(kdev->dev, \"timeout waiting for teardown\\n\");\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\nstatic void chan_stop(struct knav_dma_chan *chan)\n{\n\tspin_lock(&chan->lock);\n\tif (chan->reg_rx_flow) {\n\t\t \n\t\twritel_relaxed(0, &chan->reg_rx_flow->fdq_sel[0]);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->fdq_sel[1]);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->thresh[0]);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->thresh[1]);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->thresh[2]);\n\t}\n\n\t \n\tchan_teardown(chan);\n\n\t \n\tif (chan->reg_rx_flow) {\n\t\twritel_relaxed(0, &chan->reg_rx_flow->control);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->tags);\n\t\twritel_relaxed(0, &chan->reg_rx_flow->tag_sel);\n\t}\n\n\tmemset(&chan->cfg, 0, sizeof(struct knav_dma_cfg));\n\tspin_unlock(&chan->lock);\n\n\tdev_dbg(kdev->dev, \"channel stopped\\n\");\n}\n\nstatic void dma_hw_enable_all(struct knav_dma_device *dma)\n{\n\tint i;\n\n\tfor (i = 0; i < dma->max_tx_chan; i++) {\n\t\twritel_relaxed(0, &dma->reg_tx_chan[i].mode);\n\t\twritel_relaxed(DMA_ENABLE, &dma->reg_tx_chan[i].control);\n\t}\n}\n\n\nstatic void knav_dma_hw_init(struct knav_dma_device *dma)\n{\n\tunsigned v;\n\tint i;\n\n\tspin_lock(&dma->lock);\n\tv  = dma->loopback ? DMA_LOOPBACK : 0;\n\twritel_relaxed(v, &dma->reg_global->emulation_control);\n\n\tv = readl_relaxed(&dma->reg_global->perf_control);\n\tv |= ((dma->rx_timeout & DMA_RX_TIMEOUT_MASK) << DMA_RX_TIMEOUT_SHIFT);\n\twritel_relaxed(v, &dma->reg_global->perf_control);\n\n\tv = ((dma->tx_priority << DMA_TX_PRIO_SHIFT) |\n\t     (dma->rx_priority << DMA_RX_PRIO_SHIFT));\n\n\twritel_relaxed(v, &dma->reg_global->priority_control);\n\n\t \n\tfor (i = 0; i < dma->max_rx_chan; i++)\n\t\twritel_relaxed(DMA_ENABLE, &dma->reg_rx_chan[i].control);\n\n\tfor (i = 0; i < dma->logical_queue_managers; i++)\n\t\twritel_relaxed(dma->qm_base_address[i],\n\t\t\t       &dma->reg_global->qm_base_address[i]);\n\tspin_unlock(&dma->lock);\n}\n\nstatic void knav_dma_hw_destroy(struct knav_dma_device *dma)\n{\n\tint i;\n\tunsigned v;\n\n\tspin_lock(&dma->lock);\n\tv = ~DMA_ENABLE & REG_MASK;\n\n\tfor (i = 0; i < dma->max_rx_chan; i++)\n\t\twritel_relaxed(v, &dma->reg_rx_chan[i].control);\n\n\tfor (i = 0; i < dma->max_tx_chan; i++)\n\t\twritel_relaxed(v, &dma->reg_tx_chan[i].control);\n\tspin_unlock(&dma->lock);\n}\n\nstatic void dma_debug_show_channels(struct seq_file *s,\n\t\t\t\t\tstruct knav_dma_chan *chan)\n{\n\tint i;\n\n\tseq_printf(s, \"\\t%s %d:\\t\",\n\t\t((chan->direction == DMA_MEM_TO_DEV) ? \"tx chan\" : \"rx flow\"),\n\t\tchan_number(chan));\n\n\tif (chan->direction == DMA_MEM_TO_DEV) {\n\t\tseq_printf(s, \"einfo - %d, pswords - %d, priority - %d\\n\",\n\t\t\tchan->cfg.u.tx.filt_einfo,\n\t\t\tchan->cfg.u.tx.filt_pswords,\n\t\t\tchan->cfg.u.tx.priority);\n\t} else {\n\t\tseq_printf(s, \"einfo - %d, psinfo - %d, desc_type - %d\\n\",\n\t\t\tchan->cfg.u.rx.einfo_present,\n\t\t\tchan->cfg.u.rx.psinfo_present,\n\t\t\tchan->cfg.u.rx.desc_type);\n\t\tseq_printf(s, \"\\t\\t\\tdst_q: [%d], thresh: %d fdq: \",\n\t\t\tchan->cfg.u.rx.dst_q,\n\t\t\tchan->cfg.u.rx.thresh);\n\t\tfor (i = 0; i < KNAV_DMA_FDQ_PER_CHAN; i++)\n\t\t\tseq_printf(s, \"[%d]\", chan->cfg.u.rx.fdq[i]);\n\t\tseq_printf(s, \"\\n\");\n\t}\n}\n\nstatic void dma_debug_show_devices(struct seq_file *s,\n\t\t\t\t\tstruct knav_dma_device *dma)\n{\n\tstruct knav_dma_chan *chan;\n\n\tlist_for_each_entry(chan, &dma->chan_list, list) {\n\t\tif (atomic_read(&chan->ref_count))\n\t\t\tdma_debug_show_channels(s, chan);\n\t}\n}\n\nstatic int knav_dma_debug_show(struct seq_file *s, void *v)\n{\n\tstruct knav_dma_device *dma;\n\n\tlist_for_each_entry(dma, &kdev->list, list) {\n\t\tif (atomic_read(&dma->ref_count)) {\n\t\t\tseq_printf(s, \"%s : max_tx_chan: (%d), max_rx_flows: (%d)\\n\",\n\t\t\tdma->name, dma->max_tx_chan, dma->max_rx_flow);\n\t\t\tdma_debug_show_devices(s, dma);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nDEFINE_SHOW_ATTRIBUTE(knav_dma_debug);\n\nstatic int of_channel_match_helper(struct device_node *np, const char *name,\n\t\t\t\t\tconst char **dma_instance)\n{\n\tstruct of_phandle_args args;\n\tstruct device_node *dma_node;\n\tint index;\n\n\tdma_node = of_parse_phandle(np, \"ti,navigator-dmas\", 0);\n\tif (!dma_node)\n\t\treturn -ENODEV;\n\n\t*dma_instance = dma_node->name;\n\tindex = of_property_match_string(np, \"ti,navigator-dma-names\", name);\n\tif (index < 0) {\n\t\tdev_err(kdev->dev, \"No 'ti,navigator-dma-names' property\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (of_parse_phandle_with_fixed_args(np, \"ti,navigator-dmas\",\n\t\t\t\t\t1, index, &args)) {\n\t\tdev_err(kdev->dev, \"Missing the phandle args name %s\\n\", name);\n\t\treturn -ENODEV;\n\t}\n\n\tif (args.args[0] < 0) {\n\t\tdev_err(kdev->dev, \"Missing args for %s\\n\", name);\n\t\treturn -ENODEV;\n\t}\n\n\treturn args.args[0];\n}\n\n \nvoid *knav_dma_open_channel(struct device *dev, const char *name,\n\t\t\t\t\tstruct knav_dma_cfg *config)\n{\n\tstruct knav_dma_device *dma = NULL, *iter1;\n\tstruct knav_dma_chan *chan = NULL, *iter2;\n\tint chan_num = -1;\n\tconst char *instance;\n\n\tif (!kdev) {\n\t\tpr_err(\"keystone-navigator-dma driver not registered\\n\");\n\t\treturn (void *)-EINVAL;\n\t}\n\n\tchan_num = of_channel_match_helper(dev->of_node, name, &instance);\n\tif (chan_num < 0) {\n\t\tdev_err(kdev->dev, \"No DMA instance with name %s\\n\", name);\n\t\treturn (void *)-EINVAL;\n\t}\n\n\tdev_dbg(kdev->dev, \"initializing %s channel %d from DMA %s\\n\",\n\t\t  config->direction == DMA_MEM_TO_DEV ? \"transmit\" :\n\t\t  config->direction == DMA_DEV_TO_MEM ? \"receive\"  :\n\t\t  \"unknown\", chan_num, instance);\n\n\tif (config->direction != DMA_MEM_TO_DEV &&\n\t    config->direction != DMA_DEV_TO_MEM) {\n\t\tdev_err(kdev->dev, \"bad direction\\n\");\n\t\treturn (void *)-EINVAL;\n\t}\n\n\t \n\tlist_for_each_entry(iter1, &kdev->list, list) {\n\t\tif (!strcmp(iter1->name, instance)) {\n\t\t\tdma = iter1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!dma) {\n\t\tdev_err(kdev->dev, \"No DMA instance with name %s\\n\", instance);\n\t\treturn (void *)-EINVAL;\n\t}\n\n\t \n\tlist_for_each_entry(iter2, &dma->chan_list, list) {\n\t\tif (config->direction == DMA_MEM_TO_DEV) {\n\t\t\tif (iter2->channel == chan_num) {\n\t\t\t\tchan = iter2;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tif (iter2->flow == chan_num) {\n\t\t\t\tchan = iter2;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (!chan) {\n\t\tdev_err(kdev->dev, \"channel %d is not in DMA %s\\n\",\n\t\t\t\tchan_num, instance);\n\t\treturn (void *)-EINVAL;\n\t}\n\n\tif (atomic_read(&chan->ref_count) >= 1) {\n\t\tif (!check_config(chan, config)) {\n\t\t\tdev_err(kdev->dev, \"channel %d config miss-match\\n\",\n\t\t\t\tchan_num);\n\t\t\treturn (void *)-EINVAL;\n\t\t}\n\t}\n\n\tif (atomic_inc_return(&chan->dma->ref_count) <= 1)\n\t\tknav_dma_hw_init(chan->dma);\n\n\tif (atomic_inc_return(&chan->ref_count) <= 1)\n\t\tchan_start(chan, config);\n\n\tdev_dbg(kdev->dev, \"channel %d opened from DMA %s\\n\",\n\t\t\t\tchan_num, instance);\n\n\treturn chan;\n}\nEXPORT_SYMBOL_GPL(knav_dma_open_channel);\n\n \nvoid knav_dma_close_channel(void *channel)\n{\n\tstruct knav_dma_chan *chan = channel;\n\n\tif (!kdev) {\n\t\tpr_err(\"keystone-navigator-dma driver not registered\\n\");\n\t\treturn;\n\t}\n\n\tif (atomic_dec_return(&chan->ref_count) <= 0)\n\t\tchan_stop(chan);\n\n\tif (atomic_dec_return(&chan->dma->ref_count) <= 0)\n\t\tknav_dma_hw_destroy(chan->dma);\n\n\tdev_dbg(kdev->dev, \"channel %d or flow %d closed from DMA %s\\n\",\n\t\t\tchan->channel, chan->flow, chan->dma->name);\n}\nEXPORT_SYMBOL_GPL(knav_dma_close_channel);\n\nstatic void __iomem *pktdma_get_regs(struct knav_dma_device *dma,\n\t\t\t\tstruct device_node *node,\n\t\t\t\tunsigned index, resource_size_t *_size)\n{\n\tstruct device *dev = kdev->dev;\n\tstruct resource res;\n\tvoid __iomem *regs;\n\tint ret;\n\n\tret = of_address_to_resource(node, index, &res);\n\tif (ret) {\n\t\tdev_err(dev, \"Can't translate of node(%pOFn) address for index(%d)\\n\",\n\t\t\tnode, index);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\tregs = devm_ioremap_resource(kdev->dev, &res);\n\tif (IS_ERR(regs))\n\t\tdev_err(dev, \"Failed to map register base for index(%d) node(%pOFn)\\n\",\n\t\t\tindex, node);\n\tif (_size)\n\t\t*_size = resource_size(&res);\n\n\treturn regs;\n}\n\nstatic int pktdma_init_rx_chan(struct knav_dma_chan *chan, u32 flow)\n{\n\tstruct knav_dma_device *dma = chan->dma;\n\n\tchan->flow = flow;\n\tchan->reg_rx_flow = dma->reg_rx_flow + flow;\n\tchan->channel = DMA_INVALID_ID;\n\tdev_dbg(kdev->dev, \"rx flow(%d) (%p)\\n\", chan->flow, chan->reg_rx_flow);\n\n\treturn 0;\n}\n\nstatic int pktdma_init_tx_chan(struct knav_dma_chan *chan, u32 channel)\n{\n\tstruct knav_dma_device *dma = chan->dma;\n\n\tchan->channel = channel;\n\tchan->reg_chan = dma->reg_tx_chan + channel;\n\tchan->reg_tx_sched = dma->reg_tx_sched + channel;\n\tchan->flow = DMA_INVALID_ID;\n\tdev_dbg(kdev->dev, \"tx channel(%d) (%p)\\n\", chan->channel, chan->reg_chan);\n\n\treturn 0;\n}\n\nstatic int pktdma_init_chan(struct knav_dma_device *dma,\n\t\t\t\tenum dma_transfer_direction dir,\n\t\t\t\tunsigned chan_num)\n{\n\tstruct device *dev = kdev->dev;\n\tstruct knav_dma_chan *chan;\n\tint ret = -EINVAL;\n\n\tchan = devm_kzalloc(dev, sizeof(*chan), GFP_KERNEL);\n\tif (!chan)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&chan->list);\n\tchan->dma\t= dma;\n\tchan->direction\t= DMA_TRANS_NONE;\n\tatomic_set(&chan->ref_count, 0);\n\tspin_lock_init(&chan->lock);\n\n\tif (dir == DMA_MEM_TO_DEV) {\n\t\tchan->direction = dir;\n\t\tret = pktdma_init_tx_chan(chan, chan_num);\n\t} else if (dir == DMA_DEV_TO_MEM) {\n\t\tchan->direction = dir;\n\t\tret = pktdma_init_rx_chan(chan, chan_num);\n\t} else {\n\t\tdev_err(dev, \"channel(%d) direction unknown\\n\", chan_num);\n\t}\n\n\tlist_add_tail(&chan->list, &dma->chan_list);\n\n\treturn ret;\n}\n\nstatic int dma_init(struct device_node *cloud, struct device_node *dma_node)\n{\n\tunsigned max_tx_chan, max_rx_chan, max_rx_flow, max_tx_sched;\n\tstruct device_node *node = dma_node;\n\tstruct knav_dma_device *dma;\n\tint ret, len, num_chan = 0;\n\tresource_size_t size;\n\tu32 timeout;\n\tu32 i;\n\n\tdma = devm_kzalloc(kdev->dev, sizeof(*dma), GFP_KERNEL);\n\tif (!dma) {\n\t\tdev_err(kdev->dev, \"could not allocate driver mem\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tINIT_LIST_HEAD(&dma->list);\n\tINIT_LIST_HEAD(&dma->chan_list);\n\n\tif (!of_find_property(cloud, \"ti,navigator-cloud-address\", &len)) {\n\t\tdev_err(kdev->dev, \"unspecified navigator cloud addresses\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tdma->logical_queue_managers = len / sizeof(u32);\n\tif (dma->logical_queue_managers > DMA_MAX_QMS) {\n\t\tdev_warn(kdev->dev, \"too many queue mgrs(>%d) rest ignored\\n\",\n\t\t\t dma->logical_queue_managers);\n\t\tdma->logical_queue_managers = DMA_MAX_QMS;\n\t}\n\n\tret = of_property_read_u32_array(cloud, \"ti,navigator-cloud-address\",\n\t\t\t\t\tdma->qm_base_address,\n\t\t\t\t\tdma->logical_queue_managers);\n\tif (ret) {\n\t\tdev_err(kdev->dev, \"invalid navigator cloud addresses\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tdma->reg_global\t = pktdma_get_regs(dma, node, 0, &size);\n\tif (IS_ERR(dma->reg_global))\n\t\treturn PTR_ERR(dma->reg_global);\n\tif (size < sizeof(struct reg_global)) {\n\t\tdev_err(kdev->dev, \"bad size %pa for global regs\\n\", &size);\n\t\treturn -ENODEV;\n\t}\n\n\tdma->reg_tx_chan = pktdma_get_regs(dma, node, 1, &size);\n\tif (IS_ERR(dma->reg_tx_chan))\n\t\treturn PTR_ERR(dma->reg_tx_chan);\n\n\tmax_tx_chan = size / sizeof(struct reg_chan);\n\tdma->reg_rx_chan = pktdma_get_regs(dma, node, 2, &size);\n\tif (IS_ERR(dma->reg_rx_chan))\n\t\treturn PTR_ERR(dma->reg_rx_chan);\n\n\tmax_rx_chan = size / sizeof(struct reg_chan);\n\tdma->reg_tx_sched = pktdma_get_regs(dma, node, 3, &size);\n\tif (IS_ERR(dma->reg_tx_sched))\n\t\treturn PTR_ERR(dma->reg_tx_sched);\n\n\tmax_tx_sched = size / sizeof(struct reg_tx_sched);\n\tdma->reg_rx_flow = pktdma_get_regs(dma, node, 4, &size);\n\tif (IS_ERR(dma->reg_rx_flow))\n\t\treturn PTR_ERR(dma->reg_rx_flow);\n\n\tmax_rx_flow = size / sizeof(struct reg_rx_flow);\n\tdma->rx_priority = DMA_PRIO_DEFAULT;\n\tdma->tx_priority = DMA_PRIO_DEFAULT;\n\n\tdma->enable_all\t= of_property_read_bool(node, \"ti,enable-all\");\n\tdma->loopback\t= of_property_read_bool(node, \"ti,loop-back\");\n\n\tret = of_property_read_u32(node, \"ti,rx-retry-timeout\", &timeout);\n\tif (ret < 0) {\n\t\tdev_dbg(kdev->dev, \"unspecified rx timeout using value %d\\n\",\n\t\t\tDMA_RX_TIMEOUT_DEFAULT);\n\t\ttimeout = DMA_RX_TIMEOUT_DEFAULT;\n\t}\n\n\tdma->rx_timeout = timeout;\n\tdma->max_rx_chan = max_rx_chan;\n\tdma->max_rx_flow = max_rx_flow;\n\tdma->max_tx_chan = min(max_tx_chan, max_tx_sched);\n\tatomic_set(&dma->ref_count, 0);\n\tstrcpy(dma->name, node->name);\n\tspin_lock_init(&dma->lock);\n\n\tfor (i = 0; i < dma->max_tx_chan; i++) {\n\t\tif (pktdma_init_chan(dma, DMA_MEM_TO_DEV, i) >= 0)\n\t\t\tnum_chan++;\n\t}\n\n\tfor (i = 0; i < dma->max_rx_flow; i++) {\n\t\tif (pktdma_init_chan(dma, DMA_DEV_TO_MEM, i) >= 0)\n\t\t\tnum_chan++;\n\t}\n\n\tlist_add_tail(&dma->list, &kdev->list);\n\n\t \n\tif (dma->enable_all) {\n\t\tatomic_inc(&dma->ref_count);\n\t\tknav_dma_hw_init(dma);\n\t\tdma_hw_enable_all(dma);\n\t}\n\n\tdev_info(kdev->dev, \"DMA %s registered %d logical channels, flows %d, tx chans: %d, rx chans: %d%s\\n\",\n\t\tdma->name, num_chan, dma->max_rx_flow,\n\t\tdma->max_tx_chan, dma->max_rx_chan,\n\t\tdma->loopback ? \", loopback\" : \"\");\n\n\treturn 0;\n}\n\nstatic int knav_dma_probe(struct platform_device *pdev)\n{\n\tstruct device *dev = &pdev->dev;\n\tstruct device_node *node = pdev->dev.of_node;\n\tstruct device_node *child;\n\tint ret = 0;\n\n\tif (!node) {\n\t\tdev_err(&pdev->dev, \"could not find device info\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tkdev = devm_kzalloc(dev,\n\t\t\tsizeof(struct knav_dma_pool_device), GFP_KERNEL);\n\tif (!kdev) {\n\t\tdev_err(dev, \"could not allocate driver mem\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tkdev->dev = dev;\n\tINIT_LIST_HEAD(&kdev->list);\n\n\tpm_runtime_enable(kdev->dev);\n\tret = pm_runtime_resume_and_get(kdev->dev);\n\tif (ret < 0) {\n\t\tdev_err(kdev->dev, \"unable to enable pktdma, err %d\\n\", ret);\n\t\tgoto err_pm_disable;\n\t}\n\n\t \n\tfor_each_child_of_node(node, child) {\n\t\tret = dma_init(node, child);\n\t\tif (ret) {\n\t\t\tof_node_put(child);\n\t\t\tdev_err(&pdev->dev, \"init failed with %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (list_empty(&kdev->list)) {\n\t\tdev_err(dev, \"no valid dma instance\\n\");\n\t\tret = -ENODEV;\n\t\tgoto err_put_sync;\n\t}\n\n\tdebugfs_create_file(\"knav_dma\", S_IFREG | S_IRUGO, NULL, NULL,\n\t\t\t    &knav_dma_debug_fops);\n\n\tdevice_ready = true;\n\treturn ret;\n\nerr_put_sync:\n\tpm_runtime_put_sync(kdev->dev);\nerr_pm_disable:\n\tpm_runtime_disable(kdev->dev);\n\n\treturn ret;\n}\n\nstatic int knav_dma_remove(struct platform_device *pdev)\n{\n\tstruct knav_dma_device *dma;\n\n\tlist_for_each_entry(dma, &kdev->list, list) {\n\t\tif (atomic_dec_return(&dma->ref_count) == 0)\n\t\t\tknav_dma_hw_destroy(dma);\n\t}\n\n\tpm_runtime_put_sync(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\n\treturn 0;\n}\n\nstatic struct of_device_id of_match[] = {\n\t{ .compatible = \"ti,keystone-navigator-dma\", },\n\t{},\n};\n\nMODULE_DEVICE_TABLE(of, of_match);\n\nstatic struct platform_driver knav_dma_driver = {\n\t.probe\t= knav_dma_probe,\n\t.remove\t= knav_dma_remove,\n\t.driver = {\n\t\t.name\t\t= \"keystone-navigator-dma\",\n\t\t.of_match_table\t= of_match,\n\t},\n};\nmodule_platform_driver(knav_dma_driver);\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_DESCRIPTION(\"TI Keystone Navigator Packet DMA driver\");\nMODULE_AUTHOR(\"Sandeep Nair <sandeep_n@ti.com>\");\nMODULE_AUTHOR(\"Santosh Shilimkar <santosh.shilimkar@ti.com>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}