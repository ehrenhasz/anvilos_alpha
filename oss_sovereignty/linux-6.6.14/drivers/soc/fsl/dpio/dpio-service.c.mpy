{
  "module_name": "dpio-service.c",
  "hash_id": "02c31d2f0049a93bdeb98f5bbb4ecc09a5b518d22ef7a6ced2d0c309c92fa9e4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/soc/fsl/dpio/dpio-service.c",
  "human_readable_source": "\n \n#include <linux/types.h>\n#include <linux/fsl/mc.h>\n#include <soc/fsl/dpaa2-io.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/platform_device.h>\n#include <linux/interrupt.h>\n#include <linux/dma-mapping.h>\n#include <linux/dim.h>\n#include <linux/slab.h>\n\n#include \"dpio.h\"\n#include \"qbman-portal.h\"\n\nstruct dpaa2_io {\n\tstruct dpaa2_io_desc dpio_desc;\n\tstruct qbman_swp_desc swp_desc;\n\tstruct qbman_swp *swp;\n\tstruct list_head node;\n\t \n\tspinlock_t lock_mgmt_cmd;\n\t \n\tspinlock_t lock_notifications;\n\tstruct list_head notifications;\n\tstruct device *dev;\n\n\t \n\tstruct dim rx_dim;\n\t \n\tspinlock_t dim_lock;\n\tu16 event_ctr;\n\tu64 bytes;\n\tu64 frames;\n};\n\nstruct dpaa2_io_store {\n\tunsigned int max;\n\tdma_addr_t paddr;\n\tstruct dpaa2_dq *vaddr;\n\tvoid *alloced_addr;     \n\tunsigned int idx;       \n\tstruct qbman_swp *swp;  \n\tstruct device *dev;     \n};\n\n \nstatic struct dpaa2_io *dpio_by_cpu[NR_CPUS];\nstatic struct list_head dpio_list = LIST_HEAD_INIT(dpio_list);\nstatic DEFINE_SPINLOCK(dpio_list_lock);\n\nstatic inline struct dpaa2_io *service_select_by_cpu(struct dpaa2_io *d,\n\t\t\t\t\t\t     int cpu)\n{\n\tif (d)\n\t\treturn d;\n\n\tif (cpu != DPAA2_IO_ANY_CPU && cpu >= num_possible_cpus())\n\t\treturn NULL;\n\n\t \n\tif (cpu < 0)\n\t\tcpu = raw_smp_processor_id();\n\n\t \n\treturn dpio_by_cpu[cpu];\n}\n\nstatic inline struct dpaa2_io *service_select(struct dpaa2_io *d)\n{\n\tif (d)\n\t\treturn d;\n\n\td = service_select_by_cpu(d, -1);\n\tif (d)\n\t\treturn d;\n\n\tspin_lock(&dpio_list_lock);\n\td = list_entry(dpio_list.next, struct dpaa2_io, node);\n\tlist_del(&d->node);\n\tlist_add_tail(&d->node, &dpio_list);\n\tspin_unlock(&dpio_list_lock);\n\n\treturn d;\n}\n\n \nstruct dpaa2_io *dpaa2_io_service_select(int cpu)\n{\n\tif (cpu == DPAA2_IO_ANY_CPU)\n\t\treturn service_select(NULL);\n\n\treturn service_select_by_cpu(NULL, cpu);\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_select);\n\nstatic void dpaa2_io_dim_work(struct work_struct *w)\n{\n\tstruct dim *dim = container_of(w, struct dim, work);\n\tstruct dim_cq_moder moder =\n\t\tnet_dim_get_rx_moderation(dim->mode, dim->profile_ix);\n\tstruct dpaa2_io *d = container_of(dim, struct dpaa2_io, rx_dim);\n\n\tdpaa2_io_set_irq_coalescing(d, moder.usec);\n\tdim->state = DIM_START_MEASURE;\n}\n\n \nstruct dpaa2_io *dpaa2_io_create(const struct dpaa2_io_desc *desc,\n\t\t\t\t struct device *dev)\n{\n\tstruct dpaa2_io *obj = kmalloc(sizeof(*obj), GFP_KERNEL);\n\tu32 qman_256_cycles_per_ns;\n\n\tif (!obj)\n\t\treturn NULL;\n\n\t \n\tif (desc->cpu != DPAA2_IO_ANY_CPU && desc->cpu >= num_possible_cpus()) {\n\t\tkfree(obj);\n\t\treturn NULL;\n\t}\n\n\tobj->dpio_desc = *desc;\n\tobj->swp_desc.cena_bar = obj->dpio_desc.regs_cena;\n\tobj->swp_desc.cinh_bar = obj->dpio_desc.regs_cinh;\n\tobj->swp_desc.qman_clk = obj->dpio_desc.qman_clk;\n\tobj->swp_desc.qman_version = obj->dpio_desc.qman_version;\n\n\t \n\tqman_256_cycles_per_ns = 256000 / (obj->swp_desc.qman_clk / 1000000);\n\tobj->swp_desc.qman_256_cycles_per_ns = qman_256_cycles_per_ns;\n\tobj->swp = qbman_swp_init(&obj->swp_desc);\n\n\tif (!obj->swp) {\n\t\tkfree(obj);\n\t\treturn NULL;\n\t}\n\n\tINIT_LIST_HEAD(&obj->node);\n\tspin_lock_init(&obj->lock_mgmt_cmd);\n\tspin_lock_init(&obj->lock_notifications);\n\tspin_lock_init(&obj->dim_lock);\n\tINIT_LIST_HEAD(&obj->notifications);\n\n\t \n\tqbman_swp_interrupt_set_trigger(obj->swp,\n\t\t\t\t\tQBMAN_SWP_INTERRUPT_DQRI);\n\tqbman_swp_interrupt_clear_status(obj->swp, 0xffffffff);\n\tif (obj->dpio_desc.receives_notifications)\n\t\tqbman_swp_push_set(obj->swp, 0, 1);\n\n\tspin_lock(&dpio_list_lock);\n\tlist_add_tail(&obj->node, &dpio_list);\n\tif (desc->cpu >= 0 && !dpio_by_cpu[desc->cpu])\n\t\tdpio_by_cpu[desc->cpu] = obj;\n\tspin_unlock(&dpio_list_lock);\n\n\tobj->dev = dev;\n\n\tmemset(&obj->rx_dim, 0, sizeof(obj->rx_dim));\n\tINIT_WORK(&obj->rx_dim.work, dpaa2_io_dim_work);\n\tobj->event_ctr = 0;\n\tobj->bytes = 0;\n\tobj->frames = 0;\n\n\treturn obj;\n}\n\n \nvoid dpaa2_io_down(struct dpaa2_io *d)\n{\n\tspin_lock(&dpio_list_lock);\n\tdpio_by_cpu[d->dpio_desc.cpu] = NULL;\n\tlist_del(&d->node);\n\tspin_unlock(&dpio_list_lock);\n\n\tkfree(d);\n}\n\n#define DPAA_POLL_MAX 32\n\n \nirqreturn_t dpaa2_io_irq(struct dpaa2_io *obj)\n{\n\tconst struct dpaa2_dq *dq;\n\tint max = 0;\n\tstruct qbman_swp *swp;\n\tu32 status;\n\n\tobj->event_ctr++;\n\n\tswp = obj->swp;\n\tstatus = qbman_swp_interrupt_read_status(swp);\n\tif (!status)\n\t\treturn IRQ_NONE;\n\n\tdq = qbman_swp_dqrr_next(swp);\n\twhile (dq) {\n\t\tif (qbman_result_is_SCN(dq)) {\n\t\t\tstruct dpaa2_io_notification_ctx *ctx;\n\t\t\tu64 q64;\n\n\t\t\tq64 = qbman_result_SCN_ctx(dq);\n\t\t\tctx = (void *)(uintptr_t)q64;\n\t\t\tctx->cb(ctx);\n\t\t} else {\n\t\t\tpr_crit(\"fsl-mc-dpio: Unrecognised/ignored DQRR entry\\n\");\n\t\t}\n\t\tqbman_swp_dqrr_consume(swp, dq);\n\t\t++max;\n\t\tif (max > DPAA_POLL_MAX)\n\t\t\tgoto done;\n\t\tdq = qbman_swp_dqrr_next(swp);\n\t}\ndone:\n\tqbman_swp_interrupt_clear_status(swp, status);\n\tqbman_swp_interrupt_set_inhibit(swp, 0);\n\treturn IRQ_HANDLED;\n}\n\n \nint dpaa2_io_get_cpu(struct dpaa2_io *d)\n{\n\treturn d->dpio_desc.cpu;\n}\nEXPORT_SYMBOL(dpaa2_io_get_cpu);\n\n \nint dpaa2_io_service_register(struct dpaa2_io *d,\n\t\t\t      struct dpaa2_io_notification_ctx *ctx,\n\t\t\t      struct device *dev)\n{\n\tstruct device_link *link;\n\tunsigned long irqflags;\n\n\td = service_select_by_cpu(d, ctx->desired_cpu);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tlink = device_link_add(dev, d->dev, DL_FLAG_AUTOREMOVE_CONSUMER);\n\tif (!link)\n\t\treturn -EINVAL;\n\n\tctx->dpio_id = d->dpio_desc.dpio_id;\n\tctx->qman64 = (u64)(uintptr_t)ctx;\n\tctx->dpio_private = d;\n\tspin_lock_irqsave(&d->lock_notifications, irqflags);\n\tlist_add(&ctx->node, &d->notifications);\n\tspin_unlock_irqrestore(&d->lock_notifications, irqflags);\n\n\t \n\tif (ctx->is_cdan)\n\t\treturn qbman_swp_CDAN_set_context_enable(d->swp,\n\t\t\t\t\t\t\t (u16)ctx->id,\n\t\t\t\t\t\t\t ctx->qman64);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_register);\n\n \nvoid dpaa2_io_service_deregister(struct dpaa2_io *service,\n\t\t\t\t struct dpaa2_io_notification_ctx *ctx,\n\t\t\t\t struct device *dev)\n{\n\tstruct dpaa2_io *d = ctx->dpio_private;\n\tunsigned long irqflags;\n\n\tif (ctx->is_cdan)\n\t\tqbman_swp_CDAN_disable(d->swp, (u16)ctx->id);\n\n\tspin_lock_irqsave(&d->lock_notifications, irqflags);\n\tlist_del(&ctx->node);\n\tspin_unlock_irqrestore(&d->lock_notifications, irqflags);\n\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_deregister);\n\n \nint dpaa2_io_service_rearm(struct dpaa2_io *d,\n\t\t\t   struct dpaa2_io_notification_ctx *ctx)\n{\n\tunsigned long irqflags;\n\tint err;\n\n\td = service_select_by_cpu(d, ctx->desired_cpu);\n\tif (!unlikely(d))\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&d->lock_mgmt_cmd, irqflags);\n\tif (ctx->is_cdan)\n\t\terr = qbman_swp_CDAN_enable(d->swp, (u16)ctx->id);\n\telse\n\t\terr = qbman_swp_fq_schedule(d->swp, ctx->id);\n\tspin_unlock_irqrestore(&d->lock_mgmt_cmd, irqflags);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_rearm);\n\n \nint dpaa2_io_service_pull_fq(struct dpaa2_io *d, u32 fqid,\n\t\t\t     struct dpaa2_io_store *s)\n{\n\tstruct qbman_pull_desc pd;\n\tint err;\n\n\tqbman_pull_desc_clear(&pd);\n\tqbman_pull_desc_set_storage(&pd, s->vaddr, s->paddr, 1);\n\tqbman_pull_desc_set_numframes(&pd, (u8)s->max);\n\tqbman_pull_desc_set_fq(&pd, fqid);\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\ts->swp = d->swp;\n\terr = qbman_swp_pull(d->swp, &pd);\n\tif (err)\n\t\ts->swp = NULL;\n\n\treturn err;\n}\nEXPORT_SYMBOL(dpaa2_io_service_pull_fq);\n\n \nint dpaa2_io_service_pull_channel(struct dpaa2_io *d, u32 channelid,\n\t\t\t\t  struct dpaa2_io_store *s)\n{\n\tstruct qbman_pull_desc pd;\n\tint err;\n\n\tqbman_pull_desc_clear(&pd);\n\tqbman_pull_desc_set_storage(&pd, s->vaddr, s->paddr, 1);\n\tqbman_pull_desc_set_numframes(&pd, (u8)s->max);\n\tqbman_pull_desc_set_channel(&pd, channelid, qbman_pull_type_prio);\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\ts->swp = d->swp;\n\terr = qbman_swp_pull(d->swp, &pd);\n\tif (err)\n\t\ts->swp = NULL;\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_pull_channel);\n\n \nint dpaa2_io_service_enqueue_fq(struct dpaa2_io *d,\n\t\t\t\tu32 fqid,\n\t\t\t\tconst struct dpaa2_fd *fd)\n{\n\tstruct qbman_eq_desc ed;\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tqbman_eq_desc_clear(&ed);\n\tqbman_eq_desc_set_no_orp(&ed, 0);\n\tqbman_eq_desc_set_fq(&ed, fqid);\n\n\treturn qbman_swp_enqueue(d->swp, &ed, fd);\n}\nEXPORT_SYMBOL(dpaa2_io_service_enqueue_fq);\n\n \nint dpaa2_io_service_enqueue_multiple_fq(struct dpaa2_io *d,\n\t\t\t\tu32 fqid,\n\t\t\t\tconst struct dpaa2_fd *fd,\n\t\t\t\tint nb)\n{\n\tstruct qbman_eq_desc ed;\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tqbman_eq_desc_clear(&ed);\n\tqbman_eq_desc_set_no_orp(&ed, 0);\n\tqbman_eq_desc_set_fq(&ed, fqid);\n\n\treturn qbman_swp_enqueue_multiple(d->swp, &ed, fd, NULL, nb);\n}\nEXPORT_SYMBOL(dpaa2_io_service_enqueue_multiple_fq);\n\n \nint dpaa2_io_service_enqueue_multiple_desc_fq(struct dpaa2_io *d,\n\t\t\t\tu32 *fqid,\n\t\t\t\tconst struct dpaa2_fd *fd,\n\t\t\t\tint nb)\n{\n\tstruct qbman_eq_desc *ed;\n\tint i, ret;\n\n\ted = kcalloc(sizeof(struct qbman_eq_desc), 32, GFP_KERNEL);\n\tif (!ed)\n\t\treturn -ENOMEM;\n\n\td = service_select(d);\n\tif (!d) {\n\t\tret = -ENODEV;\n\t\tgoto out;\n\t}\n\n\tfor (i = 0; i < nb; i++) {\n\t\tqbman_eq_desc_clear(&ed[i]);\n\t\tqbman_eq_desc_set_no_orp(&ed[i], 0);\n\t\tqbman_eq_desc_set_fq(&ed[i], fqid[i]);\n\t}\n\n\tret = qbman_swp_enqueue_multiple_desc(d->swp, &ed[0], fd, nb);\nout:\n\tkfree(ed);\n\treturn ret;\n}\nEXPORT_SYMBOL(dpaa2_io_service_enqueue_multiple_desc_fq);\n\n \nint dpaa2_io_service_enqueue_qd(struct dpaa2_io *d,\n\t\t\t\tu32 qdid, u8 prio, u16 qdbin,\n\t\t\t\tconst struct dpaa2_fd *fd)\n{\n\tstruct qbman_eq_desc ed;\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tqbman_eq_desc_clear(&ed);\n\tqbman_eq_desc_set_no_orp(&ed, 0);\n\tqbman_eq_desc_set_qd(&ed, qdid, qdbin, prio);\n\n\treturn qbman_swp_enqueue(d->swp, &ed, fd);\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_enqueue_qd);\n\n \nint dpaa2_io_service_release(struct dpaa2_io *d,\n\t\t\t     u16 bpid,\n\t\t\t     const u64 *buffers,\n\t\t\t     unsigned int num_buffers)\n{\n\tstruct qbman_release_desc rd;\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tqbman_release_desc_clear(&rd);\n\tqbman_release_desc_set_bpid(&rd, bpid);\n\n\treturn qbman_swp_release(d->swp, &rd, buffers, num_buffers);\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_release);\n\n \nint dpaa2_io_service_acquire(struct dpaa2_io *d,\n\t\t\t     u16 bpid,\n\t\t\t     u64 *buffers,\n\t\t\t     unsigned int num_buffers)\n{\n\tunsigned long irqflags;\n\tint err;\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tspin_lock_irqsave(&d->lock_mgmt_cmd, irqflags);\n\terr = qbman_swp_acquire(d->swp, bpid, buffers, num_buffers);\n\tspin_unlock_irqrestore(&d->lock_mgmt_cmd, irqflags);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_service_acquire);\n\n \n\n \nstruct dpaa2_io_store *dpaa2_io_store_create(unsigned int max_frames,\n\t\t\t\t\t     struct device *dev)\n{\n\tstruct dpaa2_io_store *ret;\n\tsize_t size;\n\n\tif (!max_frames || (max_frames > 32))\n\t\treturn NULL;\n\n\tret = kmalloc(sizeof(*ret), GFP_KERNEL);\n\tif (!ret)\n\t\treturn NULL;\n\n\tret->max = max_frames;\n\tsize = max_frames * sizeof(struct dpaa2_dq) + 64;\n\tret->alloced_addr = kzalloc(size, GFP_KERNEL);\n\tif (!ret->alloced_addr) {\n\t\tkfree(ret);\n\t\treturn NULL;\n\t}\n\n\tret->vaddr = PTR_ALIGN(ret->alloced_addr, 64);\n\tret->paddr = dma_map_single(dev, ret->vaddr,\n\t\t\t\t    sizeof(struct dpaa2_dq) * max_frames,\n\t\t\t\t    DMA_FROM_DEVICE);\n\tif (dma_mapping_error(dev, ret->paddr)) {\n\t\tkfree(ret->alloced_addr);\n\t\tkfree(ret);\n\t\treturn NULL;\n\t}\n\n\tret->idx = 0;\n\tret->dev = dev;\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_store_create);\n\n \nvoid dpaa2_io_store_destroy(struct dpaa2_io_store *s)\n{\n\tdma_unmap_single(s->dev, s->paddr, sizeof(struct dpaa2_dq) * s->max,\n\t\t\t DMA_FROM_DEVICE);\n\tkfree(s->alloced_addr);\n\tkfree(s);\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_store_destroy);\n\n \nstruct dpaa2_dq *dpaa2_io_store_next(struct dpaa2_io_store *s, int *is_last)\n{\n\tint match;\n\tstruct dpaa2_dq *ret = &s->vaddr[s->idx];\n\n\tmatch = qbman_result_has_new_result(s->swp, ret);\n\tif (!match) {\n\t\t*is_last = 0;\n\t\treturn NULL;\n\t}\n\n\ts->idx++;\n\n\tif (dpaa2_dq_is_pull_complete(ret)) {\n\t\t*is_last = 1;\n\t\ts->idx = 0;\n\t\t \n\t\tif (!(dpaa2_dq_flags(ret) & DPAA2_DQ_STAT_VALIDFRAME))\n\t\t\tret = NULL;\n\t} else {\n\t\tprefetch(&s->vaddr[s->idx]);\n\t\t*is_last = 0;\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_store_next);\n\n \nint dpaa2_io_query_fq_count(struct dpaa2_io *d, u32 fqid,\n\t\t\t    u32 *fcnt, u32 *bcnt)\n{\n\tstruct qbman_fq_query_np_rslt state;\n\tstruct qbman_swp *swp;\n\tunsigned long irqflags;\n\tint ret;\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tswp = d->swp;\n\tspin_lock_irqsave(&d->lock_mgmt_cmd, irqflags);\n\tret = qbman_fq_query_state(swp, fqid, &state);\n\tspin_unlock_irqrestore(&d->lock_mgmt_cmd, irqflags);\n\tif (ret)\n\t\treturn ret;\n\t*fcnt = qbman_fq_state_frame_count(&state);\n\t*bcnt = qbman_fq_state_byte_count(&state);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_query_fq_count);\n\n \nint dpaa2_io_query_bp_count(struct dpaa2_io *d, u16 bpid, u32 *num)\n{\n\tstruct qbman_bp_query_rslt state;\n\tstruct qbman_swp *swp;\n\tunsigned long irqflags;\n\tint ret;\n\n\td = service_select(d);\n\tif (!d)\n\t\treturn -ENODEV;\n\n\tswp = d->swp;\n\tspin_lock_irqsave(&d->lock_mgmt_cmd, irqflags);\n\tret = qbman_bp_query(swp, bpid, &state);\n\tspin_unlock_irqrestore(&d->lock_mgmt_cmd, irqflags);\n\tif (ret)\n\t\treturn ret;\n\t*num = qbman_bp_info_num_free_bufs(&state);\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(dpaa2_io_query_bp_count);\n\n \nint dpaa2_io_set_irq_coalescing(struct dpaa2_io *d, u32 irq_holdoff)\n{\n\tstruct qbman_swp *swp = d->swp;\n\n\treturn qbman_swp_set_irq_coalescing(swp, swp->dqrr.dqrr_size - 1,\n\t\t\t\t\t    irq_holdoff);\n}\nEXPORT_SYMBOL(dpaa2_io_set_irq_coalescing);\n\n \nvoid dpaa2_io_get_irq_coalescing(struct dpaa2_io *d, u32 *irq_holdoff)\n{\n\tstruct qbman_swp *swp = d->swp;\n\n\tqbman_swp_get_irq_coalescing(swp, NULL, irq_holdoff);\n}\nEXPORT_SYMBOL(dpaa2_io_get_irq_coalescing);\n\n \nvoid dpaa2_io_set_adaptive_coalescing(struct dpaa2_io *d,\n\t\t\t\t      int use_adaptive_rx_coalesce)\n{\n\td->swp->use_adaptive_rx_coalesce = use_adaptive_rx_coalesce;\n}\nEXPORT_SYMBOL(dpaa2_io_set_adaptive_coalescing);\n\n \nint dpaa2_io_get_adaptive_coalescing(struct dpaa2_io *d)\n{\n\treturn d->swp->use_adaptive_rx_coalesce;\n}\nEXPORT_SYMBOL(dpaa2_io_get_adaptive_coalescing);\n\n \nvoid dpaa2_io_update_net_dim(struct dpaa2_io *d, __u64 frames, __u64 bytes)\n{\n\tstruct dim_sample dim_sample = {};\n\n\tif (!d->swp->use_adaptive_rx_coalesce)\n\t\treturn;\n\n\tspin_lock(&d->dim_lock);\n\n\td->bytes += bytes;\n\td->frames += frames;\n\n\tdim_update_sample(d->event_ctr, d->frames, d->bytes, &dim_sample);\n\tnet_dim(&d->rx_dim, dim_sample);\n\n\tspin_unlock(&d->dim_lock);\n}\nEXPORT_SYMBOL(dpaa2_io_update_net_dim);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}