{
  "module_name": "qman.c",
  "hash_id": "5662a5b5d30179fe85677b446bd43df7d68cd5517c0e98a474368e5909b508d3",
  "original_prompt": "Ingested from linux-6.6.14/drivers/soc/fsl/qbman/qman.c",
  "human_readable_source": " \n\n#include \"qman_priv.h\"\n\n#define DQRR_MAXFILL\t15\n#define EQCR_ITHRESH\t4\t \n#define IRQNAME\t\t\"QMan portal %d\"\n#define MAX_IRQNAME\t16\t \n#define QMAN_POLL_LIMIT 32\n#define QMAN_PIRQ_DQRR_ITHRESH 12\n#define QMAN_DQRR_IT_MAX 15\n#define QMAN_ITP_MAX 0xFFF\n#define QMAN_PIRQ_MR_ITHRESH 4\n#define QMAN_PIRQ_IPERIOD 100\n\n \n\n#if defined(CONFIG_ARM) || defined(CONFIG_ARM64)\n \n#define QM_REG_EQCR_PI_CINH\t0x3000\n#define QM_REG_EQCR_CI_CINH\t0x3040\n#define QM_REG_EQCR_ITR\t\t0x3080\n#define QM_REG_DQRR_PI_CINH\t0x3100\n#define QM_REG_DQRR_CI_CINH\t0x3140\n#define QM_REG_DQRR_ITR\t\t0x3180\n#define QM_REG_DQRR_DCAP\t0x31C0\n#define QM_REG_DQRR_SDQCR\t0x3200\n#define QM_REG_DQRR_VDQCR\t0x3240\n#define QM_REG_DQRR_PDQCR\t0x3280\n#define QM_REG_MR_PI_CINH\t0x3300\n#define QM_REG_MR_CI_CINH\t0x3340\n#define QM_REG_MR_ITR\t\t0x3380\n#define QM_REG_CFG\t\t0x3500\n#define QM_REG_ISR\t\t0x3600\n#define QM_REG_IER\t\t0x3640\n#define QM_REG_ISDR\t\t0x3680\n#define QM_REG_IIR\t\t0x36C0\n#define QM_REG_ITPR\t\t0x3740\n\n \n#define QM_CL_EQCR\t\t0x0000\n#define QM_CL_DQRR\t\t0x1000\n#define QM_CL_MR\t\t0x2000\n#define QM_CL_EQCR_PI_CENA\t0x3000\n#define QM_CL_EQCR_CI_CENA\t0x3040\n#define QM_CL_DQRR_PI_CENA\t0x3100\n#define QM_CL_DQRR_CI_CENA\t0x3140\n#define QM_CL_MR_PI_CENA\t0x3300\n#define QM_CL_MR_CI_CENA\t0x3340\n#define QM_CL_CR\t\t0x3800\n#define QM_CL_RR0\t\t0x3900\n#define QM_CL_RR1\t\t0x3940\n\n#else\n \n#define QM_REG_EQCR_PI_CINH\t0x0000\n#define QM_REG_EQCR_CI_CINH\t0x0004\n#define QM_REG_EQCR_ITR\t\t0x0008\n#define QM_REG_DQRR_PI_CINH\t0x0040\n#define QM_REG_DQRR_CI_CINH\t0x0044\n#define QM_REG_DQRR_ITR\t\t0x0048\n#define QM_REG_DQRR_DCAP\t0x0050\n#define QM_REG_DQRR_SDQCR\t0x0054\n#define QM_REG_DQRR_VDQCR\t0x0058\n#define QM_REG_DQRR_PDQCR\t0x005c\n#define QM_REG_MR_PI_CINH\t0x0080\n#define QM_REG_MR_CI_CINH\t0x0084\n#define QM_REG_MR_ITR\t\t0x0088\n#define QM_REG_CFG\t\t0x0100\n#define QM_REG_ISR\t\t0x0e00\n#define QM_REG_IER\t\t0x0e04\n#define QM_REG_ISDR\t\t0x0e08\n#define QM_REG_IIR\t\t0x0e0c\n#define QM_REG_ITPR\t\t0x0e14\n\n \n#define QM_CL_EQCR\t\t0x0000\n#define QM_CL_DQRR\t\t0x1000\n#define QM_CL_MR\t\t0x2000\n#define QM_CL_EQCR_PI_CENA\t0x3000\n#define QM_CL_EQCR_CI_CENA\t0x3100\n#define QM_CL_DQRR_PI_CENA\t0x3200\n#define QM_CL_DQRR_CI_CENA\t0x3300\n#define QM_CL_MR_PI_CENA\t0x3400\n#define QM_CL_MR_CI_CENA\t0x3500\n#define QM_CL_CR\t\t0x3800\n#define QM_CL_RR0\t\t0x3900\n#define QM_CL_RR1\t\t0x3940\n#endif\n\n \n\n \n#define qm_cl(base, idx)\t((void *)base + ((idx) << 6))\n\n \nenum qm_eqcr_pmode {\t\t \n\tqm_eqcr_pci = 0,\t \n\tqm_eqcr_pce = 1,\t \n\tqm_eqcr_pvb = 2\t\t \n};\nenum qm_dqrr_dmode {\t\t \n\tqm_dqrr_dpush = 0,\t \n\tqm_dqrr_dpull = 1\t \n};\nenum qm_dqrr_pmode {\t\t \n\tqm_dqrr_pci,\t\t \n\tqm_dqrr_pce,\t\t \n\tqm_dqrr_pvb\t\t \n};\nenum qm_dqrr_cmode {\t\t \n\tqm_dqrr_cci = 0,\t \n\tqm_dqrr_cce = 1,\t \n\tqm_dqrr_cdc = 2\t\t \n};\nenum qm_mr_pmode {\t\t \n\tqm_mr_pci,\t\t \n\tqm_mr_pce,\t\t \n\tqm_mr_pvb\t\t \n};\nenum qm_mr_cmode {\t\t \n\tqm_mr_cci = 0,\t\t \n\tqm_mr_cce = 1\t\t \n};\n\n \n\n#define QM_EQCR_SIZE\t\t8\n#define QM_DQRR_SIZE\t\t16\n#define QM_MR_SIZE\t\t8\n\n \nstruct qm_eqcr_entry {\n\tu8 _ncw_verb;  \n\tu8 dca;\n\t__be16 seqnum;\n\tu8 __reserved[4];\n\t__be32 fqid;\t \n\t__be32 tag;\n\tstruct qm_fd fd;\n\tu8 __reserved3[32];\n} __packed __aligned(8);\n#define QM_EQCR_VERB_VBIT\t\t0x80\n#define QM_EQCR_VERB_CMD_MASK\t\t0x61\t \n#define QM_EQCR_VERB_CMD_ENQUEUE\t0x01\n#define QM_EQCR_SEQNUM_NESN\t\t0x8000\t \n#define QM_EQCR_SEQNUM_NLIS\t\t0x4000\t \n#define QM_EQCR_SEQNUM_SEQMASK\t\t0x3fff\t \n\nstruct qm_eqcr {\n\tstruct qm_eqcr_entry *ring, *cursor;\n\tu8 ci, available, ithresh, vbit;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tu32 busy;\n\tenum qm_eqcr_pmode pmode;\n#endif\n};\n\nstruct qm_dqrr {\n\tconst struct qm_dqrr_entry *ring, *cursor;\n\tu8 pi, ci, fill, ithresh, vbit;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tenum qm_dqrr_dmode dmode;\n\tenum qm_dqrr_pmode pmode;\n\tenum qm_dqrr_cmode cmode;\n#endif\n};\n\nstruct qm_mr {\n\tunion qm_mr_entry *ring, *cursor;\n\tu8 pi, ci, fill, ithresh, vbit;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tenum qm_mr_pmode pmode;\n\tenum qm_mr_cmode cmode;\n#endif\n};\n\n \n \nstruct qm_mcc_fq {\n\tu8 _ncw_verb;\n\tu8 __reserved1[3];\n\t__be32 fqid;\t \n\tu8 __reserved2[56];\n} __packed;\n\n \nstruct qm_mcc_cgr {\n\tu8 _ncw_verb;\n\tu8 __reserved1[30];\n\tu8 cgid;\n\tu8 __reserved2[32];\n};\n\n#define QM_MCC_VERB_VBIT\t\t0x80\n#define QM_MCC_VERB_MASK\t\t0x7f\t \n#define QM_MCC_VERB_INITFQ_PARKED\t0x40\n#define QM_MCC_VERB_INITFQ_SCHED\t0x41\n#define QM_MCC_VERB_QUERYFQ\t\t0x44\n#define QM_MCC_VERB_QUERYFQ_NP\t\t0x45\t \n#define QM_MCC_VERB_QUERYWQ\t\t0x46\n#define QM_MCC_VERB_QUERYWQ_DEDICATED\t0x47\n#define QM_MCC_VERB_ALTER_SCHED\t\t0x48\t \n#define QM_MCC_VERB_ALTER_FE\t\t0x49\t \n#define QM_MCC_VERB_ALTER_RETIRE\t0x4a\t \n#define QM_MCC_VERB_ALTER_OOS\t\t0x4b\t \n#define QM_MCC_VERB_ALTER_FQXON\t\t0x4d\t \n#define QM_MCC_VERB_ALTER_FQXOFF\t0x4e\t \n#define QM_MCC_VERB_INITCGR\t\t0x50\n#define QM_MCC_VERB_MODIFYCGR\t\t0x51\n#define QM_MCC_VERB_CGRTESTWRITE\t0x52\n#define QM_MCC_VERB_QUERYCGR\t\t0x58\n#define QM_MCC_VERB_QUERYCONGESTION\t0x59\nunion qm_mc_command {\n\tstruct {\n\t\tu8 _ncw_verb;  \n\t\tu8 __reserved[63];\n\t};\n\tstruct qm_mcc_initfq initfq;\n\tstruct qm_mcc_initcgr initcgr;\n\tstruct qm_mcc_fq fq;\n\tstruct qm_mcc_cgr cgr;\n};\n\n \n \nstruct qm_mcr_queryfq {\n\tu8 verb;\n\tu8 result;\n\tu8 __reserved1[8];\n\tstruct qm_fqd fqd;\t \n\tu8 __reserved2[30];\n} __packed;\n\n \nstruct qm_mcr_alterfq {\n\tu8 verb;\n\tu8 result;\n\tu8 fqs;\t\t \n\tu8 __reserved1[61];\n};\n#define QM_MCR_VERB_RRID\t\t0x80\n#define QM_MCR_VERB_MASK\t\tQM_MCC_VERB_MASK\n#define QM_MCR_VERB_INITFQ_PARKED\tQM_MCC_VERB_INITFQ_PARKED\n#define QM_MCR_VERB_INITFQ_SCHED\tQM_MCC_VERB_INITFQ_SCHED\n#define QM_MCR_VERB_QUERYFQ\t\tQM_MCC_VERB_QUERYFQ\n#define QM_MCR_VERB_QUERYFQ_NP\t\tQM_MCC_VERB_QUERYFQ_NP\n#define QM_MCR_VERB_QUERYWQ\t\tQM_MCC_VERB_QUERYWQ\n#define QM_MCR_VERB_QUERYWQ_DEDICATED\tQM_MCC_VERB_QUERYWQ_DEDICATED\n#define QM_MCR_VERB_ALTER_SCHED\t\tQM_MCC_VERB_ALTER_SCHED\n#define QM_MCR_VERB_ALTER_FE\t\tQM_MCC_VERB_ALTER_FE\n#define QM_MCR_VERB_ALTER_RETIRE\tQM_MCC_VERB_ALTER_RETIRE\n#define QM_MCR_VERB_ALTER_OOS\t\tQM_MCC_VERB_ALTER_OOS\n#define QM_MCR_RESULT_NULL\t\t0x00\n#define QM_MCR_RESULT_OK\t\t0xf0\n#define QM_MCR_RESULT_ERR_FQID\t\t0xf1\n#define QM_MCR_RESULT_ERR_FQSTATE\t0xf2\n#define QM_MCR_RESULT_ERR_NOTEMPTY\t0xf3\t \n#define QM_MCR_RESULT_ERR_BADCHANNEL\t0xf4\n#define QM_MCR_RESULT_PENDING\t\t0xf8\n#define QM_MCR_RESULT_ERR_BADCOMMAND\t0xff\n#define QM_MCR_FQS_ORLPRESENT\t\t0x02\t \n#define QM_MCR_FQS_NOTEMPTY\t\t0x01\t \n#define QM_MCR_TIMEOUT\t\t\t10000\t \nunion qm_mc_result {\n\tstruct {\n\t\tu8 verb;\n\t\tu8 result;\n\t\tu8 __reserved1[62];\n\t};\n\tstruct qm_mcr_queryfq queryfq;\n\tstruct qm_mcr_alterfq alterfq;\n\tstruct qm_mcr_querycgr querycgr;\n\tstruct qm_mcr_querycongestion querycongestion;\n\tstruct qm_mcr_querywq querywq;\n\tstruct qm_mcr_queryfq_np queryfq_np;\n};\n\nstruct qm_mc {\n\tunion qm_mc_command *cr;\n\tunion qm_mc_result *rr;\n\tu8 rridx, vbit;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tenum {\n\t\t \n\t\tqman_mc_idle,\n\t\t \n\t\tqman_mc_user,\n\t\t \n\t\tqman_mc_hw\n\t} state;\n#endif\n};\n\nstruct qm_addr {\n\tvoid *ce;\t\t \n\t__be32 *ce_be;\t\t \n\tvoid __iomem *ci;\t \n};\n\nstruct qm_portal {\n\t \n\tstruct qm_addr addr;\n\tstruct qm_eqcr eqcr;\n\tstruct qm_dqrr dqrr;\n\tstruct qm_mr mr;\n\tstruct qm_mc mc;\n} ____cacheline_aligned;\n\n \nstatic inline u32 qm_in(struct qm_portal *p, u32 offset)\n{\n\treturn ioread32be(p->addr.ci + offset);\n}\n\nstatic inline void qm_out(struct qm_portal *p, u32 offset, u32 val)\n{\n\tiowrite32be(val, p->addr.ci + offset);\n}\n\n \nstatic inline void qm_cl_invalidate(struct qm_portal *p, u32 offset)\n{\n\tdpaa_invalidate(p->addr.ce + offset);\n}\n\nstatic inline void qm_cl_touch_ro(struct qm_portal *p, u32 offset)\n{\n\tdpaa_touch_ro(p->addr.ce + offset);\n}\n\nstatic inline u32 qm_ce_in(struct qm_portal *p, u32 offset)\n{\n\treturn be32_to_cpu(*(p->addr.ce_be + (offset/4)));\n}\n\n \n\n#define EQCR_SHIFT\tilog2(sizeof(struct qm_eqcr_entry))\n#define EQCR_CARRY\t(uintptr_t)(QM_EQCR_SIZE << EQCR_SHIFT)\n\n \nstatic struct qm_eqcr_entry *eqcr_carryclear(struct qm_eqcr_entry *p)\n{\n\tuintptr_t addr = (uintptr_t)p;\n\n\taddr &= ~EQCR_CARRY;\n\n\treturn (struct qm_eqcr_entry *)addr;\n}\n\n \nstatic int eqcr_ptr2idx(struct qm_eqcr_entry *e)\n{\n\treturn ((uintptr_t)e >> EQCR_SHIFT) & (QM_EQCR_SIZE - 1);\n}\n\n \nstatic inline void eqcr_inc(struct qm_eqcr *eqcr)\n{\n\t \n\tstruct qm_eqcr_entry *partial = eqcr->cursor + 1;\n\n\teqcr->cursor = eqcr_carryclear(partial);\n\tif (partial != eqcr->cursor)\n\t\teqcr->vbit ^= QM_EQCR_VERB_VBIT;\n}\n\nstatic inline int qm_eqcr_init(struct qm_portal *portal,\n\t\t\t\tenum qm_eqcr_pmode pmode,\n\t\t\t\tunsigned int eq_stash_thresh,\n\t\t\t\tint eq_stash_prio)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\tu32 cfg;\n\tu8 pi;\n\n\teqcr->ring = portal->addr.ce + QM_CL_EQCR;\n\teqcr->ci = qm_in(portal, QM_REG_EQCR_CI_CINH) & (QM_EQCR_SIZE - 1);\n\tqm_cl_invalidate(portal, QM_CL_EQCR_CI_CENA);\n\tpi = qm_in(portal, QM_REG_EQCR_PI_CINH) & (QM_EQCR_SIZE - 1);\n\teqcr->cursor = eqcr->ring + pi;\n\teqcr->vbit = (qm_in(portal, QM_REG_EQCR_PI_CINH) & QM_EQCR_SIZE) ?\n\t\t     QM_EQCR_VERB_VBIT : 0;\n\teqcr->available = QM_EQCR_SIZE - 1 -\n\t\t\t  dpaa_cyc_diff(QM_EQCR_SIZE, eqcr->ci, pi);\n\teqcr->ithresh = qm_in(portal, QM_REG_EQCR_ITR);\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\teqcr->busy = 0;\n\teqcr->pmode = pmode;\n#endif\n\tcfg = (qm_in(portal, QM_REG_CFG) & 0x00ffffff) |\n\t      (eq_stash_thresh << 28) |  \n\t      (eq_stash_prio << 26) |  \n\t      ((pmode & 0x3) << 24);  \n\tqm_out(portal, QM_REG_CFG, cfg);\n\treturn 0;\n}\n\nstatic inline void qm_eqcr_finish(struct qm_portal *portal)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\tu8 pi = qm_in(portal, QM_REG_EQCR_PI_CINH) & (QM_EQCR_SIZE - 1);\n\tu8 ci = qm_in(portal, QM_REG_EQCR_CI_CINH) & (QM_EQCR_SIZE - 1);\n\n\tDPAA_ASSERT(!eqcr->busy);\n\tif (pi != eqcr_ptr2idx(eqcr->cursor))\n\t\tpr_crit(\"losing uncommitted EQCR entries\\n\");\n\tif (ci != eqcr->ci)\n\t\tpr_crit(\"missing existing EQCR completions\\n\");\n\tif (eqcr->ci != eqcr_ptr2idx(eqcr->cursor))\n\t\tpr_crit(\"EQCR destroyed unquiesced\\n\");\n}\n\nstatic inline struct qm_eqcr_entry *qm_eqcr_start_no_stash(struct qm_portal\n\t\t\t\t\t\t\t\t *portal)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\n\tDPAA_ASSERT(!eqcr->busy);\n\tif (!eqcr->available)\n\t\treturn NULL;\n\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\teqcr->busy = 1;\n#endif\n\tdpaa_zero(eqcr->cursor);\n\treturn eqcr->cursor;\n}\n\nstatic inline struct qm_eqcr_entry *qm_eqcr_start_stash(struct qm_portal\n\t\t\t\t\t\t\t\t*portal)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\tu8 diff, old_ci;\n\n\tDPAA_ASSERT(!eqcr->busy);\n\tif (!eqcr->available) {\n\t\told_ci = eqcr->ci;\n\t\teqcr->ci = qm_ce_in(portal, QM_CL_EQCR_CI_CENA) &\n\t\t\t   (QM_EQCR_SIZE - 1);\n\t\tdiff = dpaa_cyc_diff(QM_EQCR_SIZE, old_ci, eqcr->ci);\n\t\teqcr->available += diff;\n\t\tif (!diff)\n\t\t\treturn NULL;\n\t}\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\teqcr->busy = 1;\n#endif\n\tdpaa_zero(eqcr->cursor);\n\treturn eqcr->cursor;\n}\n\nstatic inline void eqcr_commit_checks(struct qm_eqcr *eqcr)\n{\n\tDPAA_ASSERT(eqcr->busy);\n\tDPAA_ASSERT(!(be32_to_cpu(eqcr->cursor->fqid) & ~QM_FQID_MASK));\n\tDPAA_ASSERT(eqcr->available >= 1);\n}\n\nstatic inline void qm_eqcr_pvb_commit(struct qm_portal *portal, u8 myverb)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\tstruct qm_eqcr_entry *eqcursor;\n\n\teqcr_commit_checks(eqcr);\n\tDPAA_ASSERT(eqcr->pmode == qm_eqcr_pvb);\n\tdma_wmb();\n\teqcursor = eqcr->cursor;\n\teqcursor->_ncw_verb = myverb | eqcr->vbit;\n\tdpaa_flush(eqcursor);\n\teqcr_inc(eqcr);\n\teqcr->available--;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\teqcr->busy = 0;\n#endif\n}\n\nstatic inline void qm_eqcr_cce_prefetch(struct qm_portal *portal)\n{\n\tqm_cl_touch_ro(portal, QM_CL_EQCR_CI_CENA);\n}\n\nstatic inline u8 qm_eqcr_cce_update(struct qm_portal *portal)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\tu8 diff, old_ci = eqcr->ci;\n\n\teqcr->ci = qm_ce_in(portal, QM_CL_EQCR_CI_CENA) & (QM_EQCR_SIZE - 1);\n\tqm_cl_invalidate(portal, QM_CL_EQCR_CI_CENA);\n\tdiff = dpaa_cyc_diff(QM_EQCR_SIZE, old_ci, eqcr->ci);\n\teqcr->available += diff;\n\treturn diff;\n}\n\nstatic inline void qm_eqcr_set_ithresh(struct qm_portal *portal, u8 ithresh)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\n\teqcr->ithresh = ithresh;\n\tqm_out(portal, QM_REG_EQCR_ITR, ithresh);\n}\n\nstatic inline u8 qm_eqcr_get_avail(struct qm_portal *portal)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\n\treturn eqcr->available;\n}\n\nstatic inline u8 qm_eqcr_get_fill(struct qm_portal *portal)\n{\n\tstruct qm_eqcr *eqcr = &portal->eqcr;\n\n\treturn QM_EQCR_SIZE - 1 - eqcr->available;\n}\n\n \n\n#define DQRR_SHIFT\tilog2(sizeof(struct qm_dqrr_entry))\n#define DQRR_CARRY\t(uintptr_t)(QM_DQRR_SIZE << DQRR_SHIFT)\n\nstatic const struct qm_dqrr_entry *dqrr_carryclear(\n\t\t\t\t\tconst struct qm_dqrr_entry *p)\n{\n\tuintptr_t addr = (uintptr_t)p;\n\n\taddr &= ~DQRR_CARRY;\n\n\treturn (const struct qm_dqrr_entry *)addr;\n}\n\nstatic inline int dqrr_ptr2idx(const struct qm_dqrr_entry *e)\n{\n\treturn ((uintptr_t)e >> DQRR_SHIFT) & (QM_DQRR_SIZE - 1);\n}\n\nstatic const struct qm_dqrr_entry *dqrr_inc(const struct qm_dqrr_entry *e)\n{\n\treturn dqrr_carryclear(e + 1);\n}\n\nstatic inline void qm_dqrr_set_maxfill(struct qm_portal *portal, u8 mf)\n{\n\tqm_out(portal, QM_REG_CFG, (qm_in(portal, QM_REG_CFG) & 0xff0fffff) |\n\t\t\t\t   ((mf & (QM_DQRR_SIZE - 1)) << 20));\n}\n\nstatic inline int qm_dqrr_init(struct qm_portal *portal,\n\t\t\t       const struct qm_portal_config *config,\n\t\t\t       enum qm_dqrr_dmode dmode,\n\t\t\t       enum qm_dqrr_pmode pmode,\n\t\t\t       enum qm_dqrr_cmode cmode, u8 max_fill)\n{\n\tstruct qm_dqrr *dqrr = &portal->dqrr;\n\tu32 cfg;\n\n\t \n\tqm_out(portal, QM_REG_DQRR_SDQCR, 0);\n\tqm_out(portal, QM_REG_DQRR_VDQCR, 0);\n\tqm_out(portal, QM_REG_DQRR_PDQCR, 0);\n\tdqrr->ring = portal->addr.ce + QM_CL_DQRR;\n\tdqrr->pi = qm_in(portal, QM_REG_DQRR_PI_CINH) & (QM_DQRR_SIZE - 1);\n\tdqrr->ci = qm_in(portal, QM_REG_DQRR_CI_CINH) & (QM_DQRR_SIZE - 1);\n\tdqrr->cursor = dqrr->ring + dqrr->ci;\n\tdqrr->fill = dpaa_cyc_diff(QM_DQRR_SIZE, dqrr->ci, dqrr->pi);\n\tdqrr->vbit = (qm_in(portal, QM_REG_DQRR_PI_CINH) & QM_DQRR_SIZE) ?\n\t\t\tQM_DQRR_VERB_VBIT : 0;\n\tdqrr->ithresh = qm_in(portal, QM_REG_DQRR_ITR);\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tdqrr->dmode = dmode;\n\tdqrr->pmode = pmode;\n\tdqrr->cmode = cmode;\n#endif\n\t \n\tfor (cfg = 0; cfg < QM_DQRR_SIZE; cfg++)\n\t\tdpaa_invalidate(qm_cl(dqrr->ring, cfg));\n\tcfg = (qm_in(portal, QM_REG_CFG) & 0xff000f00) |\n\t\t((max_fill & (QM_DQRR_SIZE - 1)) << 20) |  \n\t\t((dmode & 1) << 18) |\t\t\t \n\t\t((cmode & 3) << 16) |\t\t\t \n\t\t0xa0 |\t\t\t\t\t \n\t\t(0 ? 0x40 : 0) |\t\t\t \n\t\t(0 ? 0x10 : 0);\t\t\t\t \n\tqm_out(portal, QM_REG_CFG, cfg);\n\tqm_dqrr_set_maxfill(portal, max_fill);\n\treturn 0;\n}\n\nstatic inline void qm_dqrr_finish(struct qm_portal *portal)\n{\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tstruct qm_dqrr *dqrr = &portal->dqrr;\n\n\tif (dqrr->cmode != qm_dqrr_cdc &&\n\t    dqrr->ci != dqrr_ptr2idx(dqrr->cursor))\n\t\tpr_crit(\"Ignoring completed DQRR entries\\n\");\n#endif\n}\n\nstatic inline const struct qm_dqrr_entry *qm_dqrr_current(\n\t\t\t\t\t\tstruct qm_portal *portal)\n{\n\tstruct qm_dqrr *dqrr = &portal->dqrr;\n\n\tif (!dqrr->fill)\n\t\treturn NULL;\n\treturn dqrr->cursor;\n}\n\nstatic inline u8 qm_dqrr_next(struct qm_portal *portal)\n{\n\tstruct qm_dqrr *dqrr = &portal->dqrr;\n\n\tDPAA_ASSERT(dqrr->fill);\n\tdqrr->cursor = dqrr_inc(dqrr->cursor);\n\treturn --dqrr->fill;\n}\n\nstatic inline void qm_dqrr_pvb_update(struct qm_portal *portal)\n{\n\tstruct qm_dqrr *dqrr = &portal->dqrr;\n\tstruct qm_dqrr_entry *res = qm_cl(dqrr->ring, dqrr->pi);\n\n\tDPAA_ASSERT(dqrr->pmode == qm_dqrr_pvb);\n#ifndef CONFIG_FSL_PAMU\n\t \n\tdpaa_invalidate_touch_ro(res);\n#endif\n\tif ((res->verb & QM_DQRR_VERB_VBIT) == dqrr->vbit) {\n\t\tdqrr->pi = (dqrr->pi + 1) & (QM_DQRR_SIZE - 1);\n\t\tif (!dqrr->pi)\n\t\t\tdqrr->vbit ^= QM_DQRR_VERB_VBIT;\n\t\tdqrr->fill++;\n\t}\n}\n\nstatic inline void qm_dqrr_cdc_consume_1ptr(struct qm_portal *portal,\n\t\t\t\t\tconst struct qm_dqrr_entry *dq,\n\t\t\t\t\tint park)\n{\n\t__maybe_unused struct qm_dqrr *dqrr = &portal->dqrr;\n\tint idx = dqrr_ptr2idx(dq);\n\n\tDPAA_ASSERT(dqrr->cmode == qm_dqrr_cdc);\n\tDPAA_ASSERT((dqrr->ring + idx) == dq);\n\tDPAA_ASSERT(idx < QM_DQRR_SIZE);\n\tqm_out(portal, QM_REG_DQRR_DCAP, (0 << 8) |  \n\t       ((park ? 1 : 0) << 6) |\t\t     \n\t       idx);\t\t\t\t     \n}\n\nstatic inline void qm_dqrr_cdc_consume_n(struct qm_portal *portal, u32 bitmask)\n{\n\t__maybe_unused struct qm_dqrr *dqrr = &portal->dqrr;\n\n\tDPAA_ASSERT(dqrr->cmode == qm_dqrr_cdc);\n\tqm_out(portal, QM_REG_DQRR_DCAP, (1 << 8) |  \n\t       (bitmask << 16));\t\t     \n}\n\nstatic inline void qm_dqrr_sdqcr_set(struct qm_portal *portal, u32 sdqcr)\n{\n\tqm_out(portal, QM_REG_DQRR_SDQCR, sdqcr);\n}\n\nstatic inline void qm_dqrr_vdqcr_set(struct qm_portal *portal, u32 vdqcr)\n{\n\tqm_out(portal, QM_REG_DQRR_VDQCR, vdqcr);\n}\n\nstatic inline int qm_dqrr_set_ithresh(struct qm_portal *portal, u8 ithresh)\n{\n\n\tif (ithresh > QMAN_DQRR_IT_MAX)\n\t\treturn -EINVAL;\n\n\tqm_out(portal, QM_REG_DQRR_ITR, ithresh);\n\n\treturn 0;\n}\n\n \n\n#define MR_SHIFT\tilog2(sizeof(union qm_mr_entry))\n#define MR_CARRY\t(uintptr_t)(QM_MR_SIZE << MR_SHIFT)\n\nstatic union qm_mr_entry *mr_carryclear(union qm_mr_entry *p)\n{\n\tuintptr_t addr = (uintptr_t)p;\n\n\taddr &= ~MR_CARRY;\n\n\treturn (union qm_mr_entry *)addr;\n}\n\nstatic inline int mr_ptr2idx(const union qm_mr_entry *e)\n{\n\treturn ((uintptr_t)e >> MR_SHIFT) & (QM_MR_SIZE - 1);\n}\n\nstatic inline union qm_mr_entry *mr_inc(union qm_mr_entry *e)\n{\n\treturn mr_carryclear(e + 1);\n}\n\nstatic inline int qm_mr_init(struct qm_portal *portal, enum qm_mr_pmode pmode,\n\t\t\t     enum qm_mr_cmode cmode)\n{\n\tstruct qm_mr *mr = &portal->mr;\n\tu32 cfg;\n\n\tmr->ring = portal->addr.ce + QM_CL_MR;\n\tmr->pi = qm_in(portal, QM_REG_MR_PI_CINH) & (QM_MR_SIZE - 1);\n\tmr->ci = qm_in(portal, QM_REG_MR_CI_CINH) & (QM_MR_SIZE - 1);\n\tmr->cursor = mr->ring + mr->ci;\n\tmr->fill = dpaa_cyc_diff(QM_MR_SIZE, mr->ci, mr->pi);\n\tmr->vbit = (qm_in(portal, QM_REG_MR_PI_CINH) & QM_MR_SIZE)\n\t\t? QM_MR_VERB_VBIT : 0;\n\tmr->ithresh = qm_in(portal, QM_REG_MR_ITR);\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tmr->pmode = pmode;\n\tmr->cmode = cmode;\n#endif\n\tcfg = (qm_in(portal, QM_REG_CFG) & 0xfffff0ff) |\n\t      ((cmode & 1) << 8);\t \n\tqm_out(portal, QM_REG_CFG, cfg);\n\treturn 0;\n}\n\nstatic inline void qm_mr_finish(struct qm_portal *portal)\n{\n\tstruct qm_mr *mr = &portal->mr;\n\n\tif (mr->ci != mr_ptr2idx(mr->cursor))\n\t\tpr_crit(\"Ignoring completed MR entries\\n\");\n}\n\nstatic inline const union qm_mr_entry *qm_mr_current(struct qm_portal *portal)\n{\n\tstruct qm_mr *mr = &portal->mr;\n\n\tif (!mr->fill)\n\t\treturn NULL;\n\treturn mr->cursor;\n}\n\nstatic inline int qm_mr_next(struct qm_portal *portal)\n{\n\tstruct qm_mr *mr = &portal->mr;\n\n\tDPAA_ASSERT(mr->fill);\n\tmr->cursor = mr_inc(mr->cursor);\n\treturn --mr->fill;\n}\n\nstatic inline void qm_mr_pvb_update(struct qm_portal *portal)\n{\n\tstruct qm_mr *mr = &portal->mr;\n\tunion qm_mr_entry *res = qm_cl(mr->ring, mr->pi);\n\n\tDPAA_ASSERT(mr->pmode == qm_mr_pvb);\n\n\tif ((res->verb & QM_MR_VERB_VBIT) == mr->vbit) {\n\t\tmr->pi = (mr->pi + 1) & (QM_MR_SIZE - 1);\n\t\tif (!mr->pi)\n\t\t\tmr->vbit ^= QM_MR_VERB_VBIT;\n\t\tmr->fill++;\n\t\tres = mr_inc(res);\n\t}\n\tdpaa_invalidate_touch_ro(res);\n}\n\nstatic inline void qm_mr_cci_consume(struct qm_portal *portal, u8 num)\n{\n\tstruct qm_mr *mr = &portal->mr;\n\n\tDPAA_ASSERT(mr->cmode == qm_mr_cci);\n\tmr->ci = (mr->ci + num) & (QM_MR_SIZE - 1);\n\tqm_out(portal, QM_REG_MR_CI_CINH, mr->ci);\n}\n\nstatic inline void qm_mr_cci_consume_to_current(struct qm_portal *portal)\n{\n\tstruct qm_mr *mr = &portal->mr;\n\n\tDPAA_ASSERT(mr->cmode == qm_mr_cci);\n\tmr->ci = mr_ptr2idx(mr->cursor);\n\tqm_out(portal, QM_REG_MR_CI_CINH, mr->ci);\n}\n\nstatic inline void qm_mr_set_ithresh(struct qm_portal *portal, u8 ithresh)\n{\n\tqm_out(portal, QM_REG_MR_ITR, ithresh);\n}\n\n \n\nstatic inline int qm_mc_init(struct qm_portal *portal)\n{\n\tu8 rr0, rr1;\n\tstruct qm_mc *mc = &portal->mc;\n\n\tmc->cr = portal->addr.ce + QM_CL_CR;\n\tmc->rr = portal->addr.ce + QM_CL_RR0;\n\t \n\trr0 = mc->rr->verb;\n\trr1 = (mc->rr+1)->verb;\n\tif ((rr0 == 0 && rr1 == 0) || rr0 != 0)\n\t\tmc->rridx = 1;\n\telse\n\t\tmc->rridx = 0;\n\tmc->vbit = mc->rridx ? QM_MCC_VERB_VBIT : 0;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tmc->state = qman_mc_idle;\n#endif\n\treturn 0;\n}\n\nstatic inline void qm_mc_finish(struct qm_portal *portal)\n{\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tstruct qm_mc *mc = &portal->mc;\n\n\tDPAA_ASSERT(mc->state == qman_mc_idle);\n\tif (mc->state != qman_mc_idle)\n\t\tpr_crit(\"Losing incomplete MC command\\n\");\n#endif\n}\n\nstatic inline union qm_mc_command *qm_mc_start(struct qm_portal *portal)\n{\n\tstruct qm_mc *mc = &portal->mc;\n\n\tDPAA_ASSERT(mc->state == qman_mc_idle);\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tmc->state = qman_mc_user;\n#endif\n\tdpaa_zero(mc->cr);\n\treturn mc->cr;\n}\n\nstatic inline void qm_mc_commit(struct qm_portal *portal, u8 myverb)\n{\n\tstruct qm_mc *mc = &portal->mc;\n\tunion qm_mc_result *rr = mc->rr + mc->rridx;\n\n\tDPAA_ASSERT(mc->state == qman_mc_user);\n\tdma_wmb();\n\tmc->cr->_ncw_verb = myverb | mc->vbit;\n\tdpaa_flush(mc->cr);\n\tdpaa_invalidate_touch_ro(rr);\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tmc->state = qman_mc_hw;\n#endif\n}\n\nstatic inline union qm_mc_result *qm_mc_result(struct qm_portal *portal)\n{\n\tstruct qm_mc *mc = &portal->mc;\n\tunion qm_mc_result *rr = mc->rr + mc->rridx;\n\n\tDPAA_ASSERT(mc->state == qman_mc_hw);\n\t \n\tif (!rr->verb) {\n\t\tdpaa_invalidate_touch_ro(rr);\n\t\treturn NULL;\n\t}\n\tmc->rridx ^= 1;\n\tmc->vbit ^= QM_MCC_VERB_VBIT;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tmc->state = qman_mc_idle;\n#endif\n\treturn rr;\n}\n\nstatic inline int qm_mc_result_timeout(struct qm_portal *portal,\n\t\t\t\t       union qm_mc_result **mcr)\n{\n\tint timeout = QM_MCR_TIMEOUT;\n\n\tdo {\n\t\t*mcr = qm_mc_result(portal);\n\t\tif (*mcr)\n\t\t\tbreak;\n\t\tudelay(1);\n\t} while (--timeout);\n\n\treturn timeout;\n}\n\nstatic inline void fq_set(struct qman_fq *fq, u32 mask)\n{\n\tfq->flags |= mask;\n}\n\nstatic inline void fq_clear(struct qman_fq *fq, u32 mask)\n{\n\tfq->flags &= ~mask;\n}\n\nstatic inline int fq_isset(struct qman_fq *fq, u32 mask)\n{\n\treturn fq->flags & mask;\n}\n\nstatic inline int fq_isclear(struct qman_fq *fq, u32 mask)\n{\n\treturn !(fq->flags & mask);\n}\n\nstruct qman_portal {\n\tstruct qm_portal p;\n\t \n\tunsigned long bits;\n\t \n\tunsigned long irq_sources;\n\tu32 use_eqcr_ci_stashing;\n\t \n\tstruct qman_fq *vdqcr_owned;\n\tu32 sdqcr;\n\t \n\tconst struct qm_portal_config *config;\n\t \n\tstruct qman_cgrs *cgrs;\n\t \n\tstruct list_head cgr_cbs;\n\t \n\tspinlock_t cgr_lock;\n\tstruct work_struct congestion_work;\n\tstruct work_struct mr_work;\n\tchar irqname[MAX_IRQNAME];\n};\n\nstatic cpumask_t affine_mask;\nstatic DEFINE_SPINLOCK(affine_mask_lock);\nstatic u16 affine_channels[NR_CPUS];\nstatic DEFINE_PER_CPU(struct qman_portal, qman_affine_portal);\nstruct qman_portal *affine_portals[NR_CPUS];\n\nstatic inline struct qman_portal *get_affine_portal(void)\n{\n\treturn &get_cpu_var(qman_affine_portal);\n}\n\nstatic inline void put_affine_portal(void)\n{\n\tput_cpu_var(qman_affine_portal);\n}\n\n\nstatic inline struct qman_portal *get_portal_for_channel(u16 channel)\n{\n\tint i;\n\n\tfor (i = 0; i < num_possible_cpus(); i++) {\n\t\tif (affine_portals[i] &&\n\t\t    affine_portals[i]->config->channel == channel)\n\t\t\treturn affine_portals[i];\n\t}\n\n\treturn NULL;\n}\n\nstatic struct workqueue_struct *qm_portal_wq;\n\nint qman_dqrr_set_ithresh(struct qman_portal *portal, u8 ithresh)\n{\n\tint res;\n\n\tif (!portal)\n\t\treturn -EINVAL;\n\n\tres = qm_dqrr_set_ithresh(&portal->p, ithresh);\n\tif (res)\n\t\treturn res;\n\n\tportal->p.dqrr.ithresh = ithresh;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_dqrr_set_ithresh);\n\nvoid qman_dqrr_get_ithresh(struct qman_portal *portal, u8 *ithresh)\n{\n\tif (portal && ithresh)\n\t\t*ithresh = qm_in(&portal->p, QM_REG_DQRR_ITR);\n}\nEXPORT_SYMBOL(qman_dqrr_get_ithresh);\n\nvoid qman_portal_get_iperiod(struct qman_portal *portal, u32 *iperiod)\n{\n\tif (portal && iperiod)\n\t\t*iperiod = qm_in(&portal->p, QM_REG_ITPR);\n}\nEXPORT_SYMBOL(qman_portal_get_iperiod);\n\nint qman_portal_set_iperiod(struct qman_portal *portal, u32 iperiod)\n{\n\tif (!portal || iperiod > QMAN_ITP_MAX)\n\t\treturn -EINVAL;\n\n\tqm_out(&portal->p, QM_REG_ITPR, iperiod);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_portal_set_iperiod);\n\nint qman_wq_alloc(void)\n{\n\tqm_portal_wq = alloc_workqueue(\"qman_portal_wq\", 0, 1);\n\tif (!qm_portal_wq)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\n\nvoid qman_enable_irqs(void)\n{\n\tint i;\n\n\tfor (i = 0; i < num_possible_cpus(); i++) {\n\t\tif (affine_portals[i]) {\n\t\t\tqm_out(&affine_portals[i]->p, QM_REG_ISR, 0xffffffff);\n\t\t\tqm_out(&affine_portals[i]->p, QM_REG_IIR, 0);\n\t\t}\n\n\t}\n}\n\n \nstatic DECLARE_WAIT_QUEUE_HEAD(affine_queue);\n\nstatic struct qman_fq **fq_table;\nstatic u32 num_fqids;\n\nint qman_alloc_fq_table(u32 _num_fqids)\n{\n\tnum_fqids = _num_fqids;\n\n\tfq_table = vzalloc(array3_size(sizeof(struct qman_fq *),\n\t\t\t\t       num_fqids, 2));\n\tif (!fq_table)\n\t\treturn -ENOMEM;\n\n\tpr_debug(\"Allocated fq lookup table at %p, entry count %u\\n\",\n\t\t fq_table, num_fqids * 2);\n\treturn 0;\n}\n\nstatic struct qman_fq *idx_to_fq(u32 idx)\n{\n\tstruct qman_fq *fq;\n\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tif (WARN_ON(idx >= num_fqids * 2))\n\t\treturn NULL;\n#endif\n\tfq = fq_table[idx];\n\tDPAA_ASSERT(!fq || idx == fq->idx);\n\n\treturn fq;\n}\n\n \nstatic struct qman_fq *fqid_to_fq(u32 fqid)\n{\n\treturn idx_to_fq(fqid * 2);\n}\n\nstatic struct qman_fq *tag_to_fq(u32 tag)\n{\n#if BITS_PER_LONG == 64\n\treturn idx_to_fq(tag);\n#else\n\treturn (struct qman_fq *)tag;\n#endif\n}\n\nstatic u32 fq_to_tag(struct qman_fq *fq)\n{\n#if BITS_PER_LONG == 64\n\treturn fq->idx;\n#else\n\treturn (u32)fq;\n#endif\n}\n\nstatic u32 __poll_portal_slow(struct qman_portal *p, u32 is);\nstatic inline unsigned int __poll_portal_fast(struct qman_portal *p,\n\t\t\t\t\tunsigned int poll_limit, bool sched_napi);\nstatic void qm_congestion_task(struct work_struct *work);\nstatic void qm_mr_process_task(struct work_struct *work);\n\nstatic irqreturn_t portal_isr(int irq, void *ptr)\n{\n\tstruct qman_portal *p = ptr;\n\tu32 is = qm_in(&p->p, QM_REG_ISR) & p->irq_sources;\n\tu32 clear = 0;\n\n\tif (unlikely(!is))\n\t\treturn IRQ_NONE;\n\n\t \n\tif (is & QM_PIRQ_DQRI) {\n\t\t__poll_portal_fast(p, QMAN_POLL_LIMIT, true);\n\t\tclear = QM_DQAVAIL_MASK | QM_PIRQ_DQRI;\n\t}\n\t \n\tclear |= __poll_portal_slow(p, is) & QM_PIRQ_SLOW;\n\tqm_out(&p->p, QM_REG_ISR, clear);\n\treturn IRQ_HANDLED;\n}\n\nstatic int drain_mr_fqrni(struct qm_portal *p)\n{\n\tconst union qm_mr_entry *msg;\nloop:\n\tqm_mr_pvb_update(p);\n\tmsg = qm_mr_current(p);\n\tif (!msg) {\n\t\t \n\t\tmdelay(1);\n\t\tqm_mr_pvb_update(p);\n\t\tmsg = qm_mr_current(p);\n\t\tif (!msg)\n\t\t\treturn 0;\n\t}\n\tif ((msg->verb & QM_MR_VERB_TYPE_MASK) != QM_MR_VERB_FQRNI) {\n\t\t \n\t\tpr_err(\"Found verb 0x%x in MR\\n\", msg->verb);\n\t\treturn -1;\n\t}\n\tqm_mr_next(p);\n\tqm_mr_cci_consume(p, 1);\n\tgoto loop;\n}\n\nstatic int qman_create_portal(struct qman_portal *portal,\n\t\t\t      const struct qm_portal_config *c,\n\t\t\t      const struct qman_cgrs *cgrs)\n{\n\tstruct qm_portal *p;\n\tint ret;\n\tu32 isdr;\n\n\tp = &portal->p;\n\n#ifdef CONFIG_FSL_PAMU\n\t \n\tportal->use_eqcr_ci_stashing = ((qman_ip_rev >= QMAN_REV30) ? 1 : 0);\n#else\n\tportal->use_eqcr_ci_stashing = 0;\n#endif\n\t \n\tp->addr.ce = c->addr_virt_ce;\n\tp->addr.ce_be = c->addr_virt_ce;\n\tp->addr.ci = c->addr_virt_ci;\n\t \n\tif (qm_eqcr_init(p, qm_eqcr_pvb,\n\t\t\tportal->use_eqcr_ci_stashing ? 3 : 0, 1)) {\n\t\tdev_err(c->dev, \"EQCR initialisation failed\\n\");\n\t\tgoto fail_eqcr;\n\t}\n\tif (qm_dqrr_init(p, c, qm_dqrr_dpush, qm_dqrr_pvb,\n\t\t\tqm_dqrr_cdc, DQRR_MAXFILL)) {\n\t\tdev_err(c->dev, \"DQRR initialisation failed\\n\");\n\t\tgoto fail_dqrr;\n\t}\n\tif (qm_mr_init(p, qm_mr_pvb, qm_mr_cci)) {\n\t\tdev_err(c->dev, \"MR initialisation failed\\n\");\n\t\tgoto fail_mr;\n\t}\n\tif (qm_mc_init(p)) {\n\t\tdev_err(c->dev, \"MC initialisation failed\\n\");\n\t\tgoto fail_mc;\n\t}\n\t \n\tqm_dqrr_set_ithresh(p, QMAN_PIRQ_DQRR_ITHRESH);\n\tqm_mr_set_ithresh(p, QMAN_PIRQ_MR_ITHRESH);\n\tqm_out(p, QM_REG_ITPR, QMAN_PIRQ_IPERIOD);\n\tportal->cgrs = kmalloc_array(2, sizeof(*cgrs), GFP_KERNEL);\n\tif (!portal->cgrs)\n\t\tgoto fail_cgrs;\n\t \n\tqman_cgrs_init(&portal->cgrs[1]);\n\tif (cgrs)\n\t\tportal->cgrs[0] = *cgrs;\n\telse\n\t\t \n\t\tqman_cgrs_fill(&portal->cgrs[0]);\n\tINIT_LIST_HEAD(&portal->cgr_cbs);\n\tspin_lock_init(&portal->cgr_lock);\n\tINIT_WORK(&portal->congestion_work, qm_congestion_task);\n\tINIT_WORK(&portal->mr_work, qm_mr_process_task);\n\tportal->bits = 0;\n\tportal->sdqcr = QM_SDQCR_SOURCE_CHANNELS | QM_SDQCR_COUNT_UPTO3 |\n\t\t\tQM_SDQCR_DEDICATED_PRECEDENCE | QM_SDQCR_TYPE_PRIO_QOS |\n\t\t\tQM_SDQCR_TOKEN_SET(0xab) | QM_SDQCR_CHANNELS_DEDICATED;\n\tisdr = 0xffffffff;\n\tqm_out(p, QM_REG_ISDR, isdr);\n\tportal->irq_sources = 0;\n\tqm_out(p, QM_REG_IER, 0);\n\tsnprintf(portal->irqname, MAX_IRQNAME, IRQNAME, c->cpu);\n\tqm_out(p, QM_REG_IIR, 1);\n\tif (request_irq(c->irq, portal_isr, 0, portal->irqname,\tportal)) {\n\t\tdev_err(c->dev, \"request_irq() failed\\n\");\n\t\tgoto fail_irq;\n\t}\n\n\tif (dpaa_set_portal_irq_affinity(c->dev, c->irq, c->cpu))\n\t\tgoto fail_affinity;\n\n\t \n\tisdr &= ~QM_PIRQ_EQCI;\n\tqm_out(p, QM_REG_ISDR, isdr);\n\tret = qm_eqcr_get_fill(p);\n\tif (ret) {\n\t\tdev_err(c->dev, \"EQCR unclean\\n\");\n\t\tgoto fail_eqcr_empty;\n\t}\n\tisdr &= ~(QM_PIRQ_DQRI | QM_PIRQ_MRI);\n\tqm_out(p, QM_REG_ISDR, isdr);\n\tif (qm_dqrr_current(p)) {\n\t\tdev_dbg(c->dev, \"DQRR unclean\\n\");\n\t\tqm_dqrr_cdc_consume_n(p, 0xffff);\n\t}\n\tif (qm_mr_current(p) && drain_mr_fqrni(p)) {\n\t\t \n\t\tconst union qm_mr_entry *e = qm_mr_current(p);\n\n\t\tdev_err(c->dev, \"MR dirty, VB 0x%x, rc 0x%x, addr 0x%llx\\n\",\n\t\t\te->verb, e->ern.rc, qm_fd_addr_get64(&e->ern.fd));\n\t\tgoto fail_dqrr_mr_empty;\n\t}\n\t \n\tportal->config = c;\n\tqm_out(p, QM_REG_ISR, 0xffffffff);\n\tqm_out(p, QM_REG_ISDR, 0);\n\tif (!qman_requires_cleanup())\n\t\tqm_out(p, QM_REG_IIR, 0);\n\t \n\tqm_dqrr_sdqcr_set(p, portal->sdqcr);\n\treturn 0;\n\nfail_dqrr_mr_empty:\nfail_eqcr_empty:\nfail_affinity:\n\tfree_irq(c->irq, portal);\nfail_irq:\n\tkfree(portal->cgrs);\nfail_cgrs:\n\tqm_mc_finish(p);\nfail_mc:\n\tqm_mr_finish(p);\nfail_mr:\n\tqm_dqrr_finish(p);\nfail_dqrr:\n\tqm_eqcr_finish(p);\nfail_eqcr:\n\treturn -EIO;\n}\n\nstruct qman_portal *qman_create_affine_portal(const struct qm_portal_config *c,\n\t\t\t\t\t      const struct qman_cgrs *cgrs)\n{\n\tstruct qman_portal *portal;\n\tint err;\n\n\tportal = &per_cpu(qman_affine_portal, c->cpu);\n\terr = qman_create_portal(portal, c, cgrs);\n\tif (err)\n\t\treturn NULL;\n\n\tspin_lock(&affine_mask_lock);\n\tcpumask_set_cpu(c->cpu, &affine_mask);\n\taffine_channels[c->cpu] = c->channel;\n\taffine_portals[c->cpu] = portal;\n\tspin_unlock(&affine_mask_lock);\n\n\treturn portal;\n}\n\nstatic void qman_destroy_portal(struct qman_portal *qm)\n{\n\tconst struct qm_portal_config *pcfg;\n\n\t \n\tqm_dqrr_sdqcr_set(&qm->p, 0);\n\n\t \n\tqm_eqcr_cce_update(&qm->p);\n\tqm_eqcr_cce_update(&qm->p);\n\tpcfg = qm->config;\n\n\tfree_irq(pcfg->irq, qm);\n\n\tkfree(qm->cgrs);\n\tqm_mc_finish(&qm->p);\n\tqm_mr_finish(&qm->p);\n\tqm_dqrr_finish(&qm->p);\n\tqm_eqcr_finish(&qm->p);\n\n\tqm->config = NULL;\n}\n\nconst struct qm_portal_config *qman_destroy_affine_portal(void)\n{\n\tstruct qman_portal *qm = get_affine_portal();\n\tconst struct qm_portal_config *pcfg;\n\tint cpu;\n\n\tpcfg = qm->config;\n\tcpu = pcfg->cpu;\n\n\tqman_destroy_portal(qm);\n\n\tspin_lock(&affine_mask_lock);\n\tcpumask_clear_cpu(cpu, &affine_mask);\n\tspin_unlock(&affine_mask_lock);\n\tput_affine_portal();\n\treturn pcfg;\n}\n\n \nstatic inline void fq_state_change(struct qman_portal *p, struct qman_fq *fq,\n\t\t\t\t   const union qm_mr_entry *msg, u8 verb)\n{\n\tswitch (verb) {\n\tcase QM_MR_VERB_FQRL:\n\t\tDPAA_ASSERT(fq_isset(fq, QMAN_FQ_STATE_ORL));\n\t\tfq_clear(fq, QMAN_FQ_STATE_ORL);\n\t\tbreak;\n\tcase QM_MR_VERB_FQRN:\n\t\tDPAA_ASSERT(fq->state == qman_fq_state_parked ||\n\t\t\t    fq->state == qman_fq_state_sched);\n\t\tDPAA_ASSERT(fq_isset(fq, QMAN_FQ_STATE_CHANGING));\n\t\tfq_clear(fq, QMAN_FQ_STATE_CHANGING);\n\t\tif (msg->fq.fqs & QM_MR_FQS_NOTEMPTY)\n\t\t\tfq_set(fq, QMAN_FQ_STATE_NE);\n\t\tif (msg->fq.fqs & QM_MR_FQS_ORLPRESENT)\n\t\t\tfq_set(fq, QMAN_FQ_STATE_ORL);\n\t\tfq->state = qman_fq_state_retired;\n\t\tbreak;\n\tcase QM_MR_VERB_FQPN:\n\t\tDPAA_ASSERT(fq->state == qman_fq_state_sched);\n\t\tDPAA_ASSERT(fq_isclear(fq, QMAN_FQ_STATE_CHANGING));\n\t\tfq->state = qman_fq_state_parked;\n\t}\n}\n\nstatic void qm_congestion_task(struct work_struct *work)\n{\n\tstruct qman_portal *p = container_of(work, struct qman_portal,\n\t\t\t\t\t     congestion_work);\n\tstruct qman_cgrs rr, c;\n\tunion qm_mc_result *mcr;\n\tstruct qman_cgr *cgr;\n\n\tspin_lock(&p->cgr_lock);\n\tqm_mc_start(&p->p);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_QUERYCONGESTION);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tspin_unlock(&p->cgr_lock);\n\t\tdev_crit(p->config->dev, \"QUERYCONGESTION timeout\\n\");\n\t\tqman_p_irqsource_add(p, QM_PIRQ_CSCI);\n\t\treturn;\n\t}\n\t \n\tqman_cgrs_and(&rr, (struct qman_cgrs *)&mcr->querycongestion.state,\n\t\t      &p->cgrs[0]);\n\t \n\tqman_cgrs_xor(&c, &rr, &p->cgrs[1]);\n\t \n\tqman_cgrs_cp(&p->cgrs[1], &rr);\n\t \n\tlist_for_each_entry(cgr, &p->cgr_cbs, node)\n\t\tif (cgr->cb && qman_cgrs_get(&c, cgr->cgrid))\n\t\t\tcgr->cb(p, cgr, qman_cgrs_get(&rr, cgr->cgrid));\n\tspin_unlock(&p->cgr_lock);\n\tqman_p_irqsource_add(p, QM_PIRQ_CSCI);\n}\n\nstatic void qm_mr_process_task(struct work_struct *work)\n{\n\tstruct qman_portal *p = container_of(work, struct qman_portal,\n\t\t\t\t\t     mr_work);\n\tconst union qm_mr_entry *msg;\n\tstruct qman_fq *fq;\n\tu8 verb, num = 0;\n\n\tpreempt_disable();\n\n\twhile (1) {\n\t\tqm_mr_pvb_update(&p->p);\n\t\tmsg = qm_mr_current(&p->p);\n\t\tif (!msg)\n\t\t\tbreak;\n\n\t\tverb = msg->verb & QM_MR_VERB_TYPE_MASK;\n\t\t \n\t\tif (verb & 0x20) {\n\t\t\tswitch (verb) {\n\t\t\tcase QM_MR_VERB_FQRNI:\n\t\t\t\t \n\t\t\t\tbreak;\n\t\t\tcase QM_MR_VERB_FQRN:\n\t\t\tcase QM_MR_VERB_FQRL:\n\t\t\t\t \n\t\t\t\tfq = fqid_to_fq(qm_fqid_get(&msg->fq));\n\t\t\t\tif (WARN_ON(!fq))\n\t\t\t\t\tbreak;\n\t\t\t\tfq_state_change(p, fq, msg, verb);\n\t\t\t\tif (fq->cb.fqs)\n\t\t\t\t\tfq->cb.fqs(p, fq, msg);\n\t\t\t\tbreak;\n\t\t\tcase QM_MR_VERB_FQPN:\n\t\t\t\t \n\t\t\t\tfq = tag_to_fq(be32_to_cpu(msg->fq.context_b));\n\t\t\t\tfq_state_change(p, fq, msg, verb);\n\t\t\t\tif (fq->cb.fqs)\n\t\t\t\t\tfq->cb.fqs(p, fq, msg);\n\t\t\t\tbreak;\n\t\t\tcase QM_MR_VERB_DC_ERN:\n\t\t\t\t \n\t\t\t\tpr_crit_once(\"Leaking DCP ERNs!\\n\");\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tpr_crit(\"Invalid MR verb 0x%02x\\n\", verb);\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tfq = tag_to_fq(be32_to_cpu(msg->ern.tag));\n\t\t\tfq->cb.ern(p, fq, msg);\n\t\t}\n\t\tnum++;\n\t\tqm_mr_next(&p->p);\n\t}\n\n\tqm_mr_cci_consume(&p->p, num);\n\tqman_p_irqsource_add(p, QM_PIRQ_MRI);\n\tpreempt_enable();\n}\n\nstatic u32 __poll_portal_slow(struct qman_portal *p, u32 is)\n{\n\tif (is & QM_PIRQ_CSCI) {\n\t\tqman_p_irqsource_remove(p, QM_PIRQ_CSCI);\n\t\tqueue_work_on(smp_processor_id(), qm_portal_wq,\n\t\t\t      &p->congestion_work);\n\t}\n\n\tif (is & QM_PIRQ_EQRI) {\n\t\tqm_eqcr_cce_update(&p->p);\n\t\tqm_eqcr_set_ithresh(&p->p, 0);\n\t\twake_up(&affine_queue);\n\t}\n\n\tif (is & QM_PIRQ_MRI) {\n\t\tqman_p_irqsource_remove(p, QM_PIRQ_MRI);\n\t\tqueue_work_on(smp_processor_id(), qm_portal_wq,\n\t\t\t      &p->mr_work);\n\t}\n\n\treturn is;\n}\n\n \nstatic noinline void clear_vdqcr(struct qman_portal *p, struct qman_fq *fq)\n{\n\tp->vdqcr_owned = NULL;\n\tfq_clear(fq, QMAN_FQ_STATE_VDQCR);\n\twake_up(&affine_queue);\n}\n\n \nstatic inline unsigned int __poll_portal_fast(struct qman_portal *p,\n\t\t\t\t\tunsigned int poll_limit, bool sched_napi)\n{\n\tconst struct qm_dqrr_entry *dq;\n\tstruct qman_fq *fq;\n\tenum qman_cb_dqrr_result res;\n\tunsigned int limit = 0;\n\n\tdo {\n\t\tqm_dqrr_pvb_update(&p->p);\n\t\tdq = qm_dqrr_current(&p->p);\n\t\tif (!dq)\n\t\t\tbreak;\n\n\t\tif (dq->stat & QM_DQRR_STAT_UNSCHEDULED) {\n\t\t\t \n\t\t\tfq = p->vdqcr_owned;\n\t\t\t \n\t\t\tif (dq->stat & QM_DQRR_STAT_FQ_EMPTY)\n\t\t\t\tfq_clear(fq, QMAN_FQ_STATE_NE);\n\t\t\t \n\t\t\tres = fq->cb.dqrr(p, fq, dq, sched_napi);\n\t\t\tif (res == qman_cb_dqrr_stop)\n\t\t\t\tbreak;\n\t\t\t \n\t\t\tif (dq->stat & QM_DQRR_STAT_DQCR_EXPIRED)\n\t\t\t\tclear_vdqcr(p, fq);\n\t\t} else {\n\t\t\t \n\t\t\tfq = tag_to_fq(be32_to_cpu(dq->context_b));\n\t\t\t \n\t\t\tres = fq->cb.dqrr(p, fq, dq, sched_napi);\n\t\t\t \n\t\t\tif (res == qman_cb_dqrr_stop)\n\t\t\t\tbreak;\n\t\t}\n\t\t \n\t\t \n\t\tDPAA_ASSERT((dq->stat & QM_DQRR_STAT_FQ_HELDACTIVE) ||\n\t\t\t    (res != qman_cb_dqrr_park));\n\t\t \n\t\tif (res != qman_cb_dqrr_defer)\n\t\t\tqm_dqrr_cdc_consume_1ptr(&p->p, dq,\n\t\t\t\t\t\t res == qman_cb_dqrr_park);\n\t\t \n\t\tqm_dqrr_next(&p->p);\n\t\t \n\t} while (++limit < poll_limit && res != qman_cb_dqrr_consume_stop);\n\n\treturn limit;\n}\n\nvoid qman_p_irqsource_add(struct qman_portal *p, u32 bits)\n{\n\tunsigned long irqflags;\n\n\tlocal_irq_save(irqflags);\n\tp->irq_sources |= bits & QM_PIRQ_VISIBLE;\n\tqm_out(&p->p, QM_REG_IER, p->irq_sources);\n\tlocal_irq_restore(irqflags);\n}\nEXPORT_SYMBOL(qman_p_irqsource_add);\n\nvoid qman_p_irqsource_remove(struct qman_portal *p, u32 bits)\n{\n\tunsigned long irqflags;\n\tu32 ier;\n\n\t \n\tlocal_irq_save(irqflags);\n\tbits &= QM_PIRQ_VISIBLE;\n\tp->irq_sources &= ~bits;\n\tqm_out(&p->p, QM_REG_IER, p->irq_sources);\n\tier = qm_in(&p->p, QM_REG_IER);\n\t \n\tqm_out(&p->p, QM_REG_ISR, ~ier);\n\tlocal_irq_restore(irqflags);\n}\nEXPORT_SYMBOL(qman_p_irqsource_remove);\n\nconst cpumask_t *qman_affine_cpus(void)\n{\n\treturn &affine_mask;\n}\nEXPORT_SYMBOL(qman_affine_cpus);\n\nu16 qman_affine_channel(int cpu)\n{\n\tif (cpu < 0) {\n\t\tstruct qman_portal *portal = get_affine_portal();\n\n\t\tcpu = portal->config->cpu;\n\t\tput_affine_portal();\n\t}\n\tWARN_ON(!cpumask_test_cpu(cpu, &affine_mask));\n\treturn affine_channels[cpu];\n}\nEXPORT_SYMBOL(qman_affine_channel);\n\nstruct qman_portal *qman_get_affine_portal(int cpu)\n{\n\treturn affine_portals[cpu];\n}\nEXPORT_SYMBOL(qman_get_affine_portal);\n\nint qman_start_using_portal(struct qman_portal *p, struct device *dev)\n{\n\treturn (!device_link_add(dev, p->config->dev,\n\t\t\t\t DL_FLAG_AUTOREMOVE_CONSUMER)) ? -EINVAL : 0;\n}\nEXPORT_SYMBOL(qman_start_using_portal);\n\nint qman_p_poll_dqrr(struct qman_portal *p, unsigned int limit)\n{\n\treturn __poll_portal_fast(p, limit, false);\n}\nEXPORT_SYMBOL(qman_p_poll_dqrr);\n\nvoid qman_p_static_dequeue_add(struct qman_portal *p, u32 pools)\n{\n\tunsigned long irqflags;\n\n\tlocal_irq_save(irqflags);\n\tpools &= p->config->pools;\n\tp->sdqcr |= pools;\n\tqm_dqrr_sdqcr_set(&p->p, p->sdqcr);\n\tlocal_irq_restore(irqflags);\n}\nEXPORT_SYMBOL(qman_p_static_dequeue_add);\n\n \n\nstatic const char *mcr_result_str(u8 result)\n{\n\tswitch (result) {\n\tcase QM_MCR_RESULT_NULL:\n\t\treturn \"QM_MCR_RESULT_NULL\";\n\tcase QM_MCR_RESULT_OK:\n\t\treturn \"QM_MCR_RESULT_OK\";\n\tcase QM_MCR_RESULT_ERR_FQID:\n\t\treturn \"QM_MCR_RESULT_ERR_FQID\";\n\tcase QM_MCR_RESULT_ERR_FQSTATE:\n\t\treturn \"QM_MCR_RESULT_ERR_FQSTATE\";\n\tcase QM_MCR_RESULT_ERR_NOTEMPTY:\n\t\treturn \"QM_MCR_RESULT_ERR_NOTEMPTY\";\n\tcase QM_MCR_RESULT_PENDING:\n\t\treturn \"QM_MCR_RESULT_PENDING\";\n\tcase QM_MCR_RESULT_ERR_BADCOMMAND:\n\t\treturn \"QM_MCR_RESULT_ERR_BADCOMMAND\";\n\t}\n\treturn \"<unknown MCR result>\";\n}\n\nint qman_create_fq(u32 fqid, u32 flags, struct qman_fq *fq)\n{\n\tif (flags & QMAN_FQ_FLAG_DYNAMIC_FQID) {\n\t\tint ret = qman_alloc_fqid(&fqid);\n\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\tfq->fqid = fqid;\n\tfq->flags = flags;\n\tfq->state = qman_fq_state_oos;\n\tfq->cgr_groupid = 0;\n\n\t \n\tif (fqid == 0 || fqid >= num_fqids) {\n\t\tWARN(1, \"bad fqid %d\\n\", fqid);\n\t\treturn -EINVAL;\n\t}\n\n\tfq->idx = fqid * 2;\n\tif (flags & QMAN_FQ_FLAG_NO_MODIFY)\n\t\tfq->idx++;\n\n\tWARN_ON(fq_table[fq->idx]);\n\tfq_table[fq->idx] = fq;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_create_fq);\n\nvoid qman_destroy_fq(struct qman_fq *fq)\n{\n\t \n\tswitch (fq->state) {\n\tcase qman_fq_state_parked:\n\tcase qman_fq_state_oos:\n\t\tif (fq_isset(fq, QMAN_FQ_FLAG_DYNAMIC_FQID))\n\t\t\tqman_release_fqid(fq->fqid);\n\n\t\tDPAA_ASSERT(fq_table[fq->idx]);\n\t\tfq_table[fq->idx] = NULL;\n\t\treturn;\n\tdefault:\n\t\tbreak;\n\t}\n\tDPAA_ASSERT(NULL == \"qman_free_fq() on unquiesced FQ!\");\n}\nEXPORT_SYMBOL(qman_destroy_fq);\n\nu32 qman_fq_fqid(struct qman_fq *fq)\n{\n\treturn fq->fqid;\n}\nEXPORT_SYMBOL(qman_fq_fqid);\n\nint qman_init_fq(struct qman_fq *fq, u32 flags, struct qm_mcc_initfq *opts)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p;\n\tu8 res, myverb;\n\tint ret = 0;\n\n\tmyverb = (flags & QMAN_INITFQ_FLAG_SCHED)\n\t\t? QM_MCC_VERB_INITFQ_SCHED : QM_MCC_VERB_INITFQ_PARKED;\n\n\tif (fq->state != qman_fq_state_oos &&\n\t    fq->state != qman_fq_state_parked)\n\t\treturn -EINVAL;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\n\t\treturn -EINVAL;\n#endif\n\tif (opts && (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_OAC)) {\n\t\t \n\t\tif (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_TDTHRESH)\n\t\t\treturn -EINVAL;\n\t}\n\t \n\tp = get_affine_portal();\n\tif (fq_isset(fq, QMAN_FQ_STATE_CHANGING) ||\n\t    (fq->state != qman_fq_state_oos &&\n\t     fq->state != qman_fq_state_parked)) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\tmcc = qm_mc_start(&p->p);\n\tif (opts)\n\t\tmcc->initfq = *opts;\n\tqm_fqid_set(&mcc->fq, fq->fqid);\n\tmcc->initfq.count = 0;\n\t \n\tif (fq_isclear(fq, QMAN_FQ_FLAG_TO_DCPORTAL)) {\n\t\tdma_addr_t phys_fq;\n\n\t\tmcc->initfq.we_mask |= cpu_to_be16(QM_INITFQ_WE_CONTEXTB);\n\t\tmcc->initfq.fqd.context_b = cpu_to_be32(fq_to_tag(fq));\n\t\t \n\t\tif (!(be16_to_cpu(mcc->initfq.we_mask) &\n\t\t\t\t  QM_INITFQ_WE_CONTEXTA)) {\n\t\t\tmcc->initfq.we_mask |=\n\t\t\t\tcpu_to_be16(QM_INITFQ_WE_CONTEXTA);\n\t\t\tmemset(&mcc->initfq.fqd.context_a, 0,\n\t\t\t\tsizeof(mcc->initfq.fqd.context_a));\n\t\t} else {\n\t\t\tstruct qman_portal *p = qman_dma_portal;\n\n\t\t\tphys_fq = dma_map_single(p->config->dev, fq,\n\t\t\t\t\t\t sizeof(*fq), DMA_TO_DEVICE);\n\t\t\tif (dma_mapping_error(p->config->dev, phys_fq)) {\n\t\t\t\tdev_err(p->config->dev, \"dma_mapping failed\\n\");\n\t\t\t\tret = -EIO;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tqm_fqd_stashing_set64(&mcc->initfq.fqd, phys_fq);\n\t\t}\n\t}\n\tif (flags & QMAN_INITFQ_FLAG_LOCAL) {\n\t\tint wq = 0;\n\n\t\tif (!(be16_to_cpu(mcc->initfq.we_mask) &\n\t\t\t\t  QM_INITFQ_WE_DESTWQ)) {\n\t\t\tmcc->initfq.we_mask |=\n\t\t\t\tcpu_to_be16(QM_INITFQ_WE_DESTWQ);\n\t\t\twq = 4;\n\t\t}\n\t\tqm_fqd_set_destwq(&mcc->initfq.fqd, p->config->channel, wq);\n\t}\n\tqm_mc_commit(&p->p, myverb);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tdev_err(p->config->dev, \"MCR timeout\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == myverb);\n\tres = mcr->result;\n\tif (res != QM_MCR_RESULT_OK) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tif (opts) {\n\t\tif (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_FQCTRL) {\n\t\t\tif (be16_to_cpu(opts->fqd.fq_ctrl) & QM_FQCTRL_CGE)\n\t\t\t\tfq_set(fq, QMAN_FQ_STATE_CGR_EN);\n\t\t\telse\n\t\t\t\tfq_clear(fq, QMAN_FQ_STATE_CGR_EN);\n\t\t}\n\t\tif (be16_to_cpu(opts->we_mask) & QM_INITFQ_WE_CGID)\n\t\t\tfq->cgr_groupid = opts->fqd.cgid;\n\t}\n\tfq->state = (flags & QMAN_INITFQ_FLAG_SCHED) ?\n\t\tqman_fq_state_sched : qman_fq_state_parked;\n\nout:\n\tput_affine_portal();\n\treturn ret;\n}\nEXPORT_SYMBOL(qman_init_fq);\n\nint qman_schedule_fq(struct qman_fq *fq)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p;\n\tint ret = 0;\n\n\tif (fq->state != qman_fq_state_parked)\n\t\treturn -EINVAL;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\n\t\treturn -EINVAL;\n#endif\n\t \n\tp = get_affine_portal();\n\tif (fq_isset(fq, QMAN_FQ_STATE_CHANGING) ||\n\t    fq->state != qman_fq_state_parked) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\tmcc = qm_mc_start(&p->p);\n\tqm_fqid_set(&mcc->fq, fq->fqid);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_SCHED);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tdev_err(p->config->dev, \"ALTER_SCHED timeout\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_ALTER_SCHED);\n\tif (mcr->result != QM_MCR_RESULT_OK) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tfq->state = qman_fq_state_sched;\nout:\n\tput_affine_portal();\n\treturn ret;\n}\nEXPORT_SYMBOL(qman_schedule_fq);\n\nint qman_retire_fq(struct qman_fq *fq, u32 *flags)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p;\n\tint ret;\n\tu8 res;\n\n\tif (fq->state != qman_fq_state_parked &&\n\t    fq->state != qman_fq_state_sched)\n\t\treturn -EINVAL;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\n\t\treturn -EINVAL;\n#endif\n\tp = get_affine_portal();\n\tif (fq_isset(fq, QMAN_FQ_STATE_CHANGING) ||\n\t    fq->state == qman_fq_state_retired ||\n\t    fq->state == qman_fq_state_oos) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\tmcc = qm_mc_start(&p->p);\n\tqm_fqid_set(&mcc->fq, fq->fqid);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_RETIRE);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tdev_crit(p->config->dev, \"ALTER_RETIRE timeout\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_ALTER_RETIRE);\n\tres = mcr->result;\n\t \n\tif (res == QM_MCR_RESULT_OK) {\n\t\tret = 0;\n\t\t \n\t\tif (mcr->alterfq.fqs & QM_MCR_FQS_NOTEMPTY)\n\t\t\tfq_set(fq, QMAN_FQ_STATE_NE);\n\t\tif (mcr->alterfq.fqs & QM_MCR_FQS_ORLPRESENT)\n\t\t\tfq_set(fq, QMAN_FQ_STATE_ORL);\n\t\tif (flags)\n\t\t\t*flags = fq->flags;\n\t\tfq->state = qman_fq_state_retired;\n\t\tif (fq->cb.fqs) {\n\t\t\t \n\t\t\tunion qm_mr_entry msg;\n\n\t\t\tmsg.verb = QM_MR_VERB_FQRNI;\n\t\t\tmsg.fq.fqs = mcr->alterfq.fqs;\n\t\t\tqm_fqid_set(&msg.fq, fq->fqid);\n\t\t\tmsg.fq.context_b = cpu_to_be32(fq_to_tag(fq));\n\t\t\tfq->cb.fqs(p, fq, &msg);\n\t\t}\n\t} else if (res == QM_MCR_RESULT_PENDING) {\n\t\tret = 1;\n\t\tfq_set(fq, QMAN_FQ_STATE_CHANGING);\n\t} else {\n\t\tret = -EIO;\n\t}\nout:\n\tput_affine_portal();\n\treturn ret;\n}\nEXPORT_SYMBOL(qman_retire_fq);\n\nint qman_oos_fq(struct qman_fq *fq)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p;\n\tint ret = 0;\n\n\tif (fq->state != qman_fq_state_retired)\n\t\treturn -EINVAL;\n#ifdef CONFIG_FSL_DPAA_CHECKING\n\tif (fq_isset(fq, QMAN_FQ_FLAG_NO_MODIFY))\n\t\treturn -EINVAL;\n#endif\n\tp = get_affine_portal();\n\tif (fq_isset(fq, QMAN_FQ_STATE_BLOCKOOS) ||\n\t    fq->state != qman_fq_state_retired) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\tmcc = qm_mc_start(&p->p);\n\tqm_fqid_set(&mcc->fq, fq->fqid);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_OOS);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_ALTER_OOS);\n\tif (mcr->result != QM_MCR_RESULT_OK) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\tfq->state = qman_fq_state_oos;\nout:\n\tput_affine_portal();\n\treturn ret;\n}\nEXPORT_SYMBOL(qman_oos_fq);\n\nint qman_query_fq(struct qman_fq *fq, struct qm_fqd *fqd)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p = get_affine_portal();\n\tint ret = 0;\n\n\tmcc = qm_mc_start(&p->p);\n\tqm_fqid_set(&mcc->fq, fq->fqid);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ);\n\tif (mcr->result == QM_MCR_RESULT_OK)\n\t\t*fqd = mcr->queryfq.fqd;\n\telse\n\t\tret = -EIO;\nout:\n\tput_affine_portal();\n\treturn ret;\n}\n\nint qman_query_fq_np(struct qman_fq *fq, struct qm_mcr_queryfq_np *np)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p = get_affine_portal();\n\tint ret = 0;\n\n\tmcc = qm_mc_start(&p->p);\n\tqm_fqid_set(&mcc->fq, fq->fqid);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ_NP);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ_NP);\n\tif (mcr->result == QM_MCR_RESULT_OK)\n\t\t*np = mcr->queryfq_np;\n\telse if (mcr->result == QM_MCR_RESULT_ERR_FQID)\n\t\tret = -ERANGE;\n\telse\n\t\tret = -EIO;\nout:\n\tput_affine_portal();\n\treturn ret;\n}\nEXPORT_SYMBOL(qman_query_fq_np);\n\nstatic int qman_query_cgr(struct qman_cgr *cgr,\n\t\t\t  struct qm_mcr_querycgr *cgrd)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p = get_affine_portal();\n\tint ret = 0;\n\n\tmcc = qm_mc_start(&p->p);\n\tmcc->cgr.cgid = cgr->cgrid;\n\tqm_mc_commit(&p->p, QM_MCC_VERB_QUERYCGR);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCC_VERB_QUERYCGR);\n\tif (mcr->result == QM_MCR_RESULT_OK)\n\t\t*cgrd = mcr->querycgr;\n\telse {\n\t\tdev_err(p->config->dev, \"QUERY_CGR failed: %s\\n\",\n\t\t\tmcr_result_str(mcr->result));\n\t\tret = -EIO;\n\t}\nout:\n\tput_affine_portal();\n\treturn ret;\n}\n\nint qman_query_cgr_congested(struct qman_cgr *cgr, bool *result)\n{\n\tstruct qm_mcr_querycgr query_cgr;\n\tint err;\n\n\terr = qman_query_cgr(cgr, &query_cgr);\n\tif (err)\n\t\treturn err;\n\n\t*result = !!query_cgr.cgr.cs;\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_query_cgr_congested);\n\n \nstatic int set_p_vdqcr(struct qman_portal *p, struct qman_fq *fq, u32 vdqcr)\n{\n\tunsigned long irqflags;\n\tint ret = -EBUSY;\n\n\tlocal_irq_save(irqflags);\n\tif (p->vdqcr_owned)\n\t\tgoto out;\n\tif (fq_isset(fq, QMAN_FQ_STATE_VDQCR))\n\t\tgoto out;\n\n\tfq_set(fq, QMAN_FQ_STATE_VDQCR);\n\tp->vdqcr_owned = fq;\n\tqm_dqrr_vdqcr_set(&p->p, vdqcr);\n\tret = 0;\nout:\n\tlocal_irq_restore(irqflags);\n\treturn ret;\n}\n\nstatic int set_vdqcr(struct qman_portal **p, struct qman_fq *fq, u32 vdqcr)\n{\n\tint ret;\n\n\t*p = get_affine_portal();\n\tret = set_p_vdqcr(*p, fq, vdqcr);\n\tput_affine_portal();\n\treturn ret;\n}\n\nstatic int wait_vdqcr_start(struct qman_portal **p, struct qman_fq *fq,\n\t\t\t\tu32 vdqcr, u32 flags)\n{\n\tint ret = 0;\n\n\tif (flags & QMAN_VOLATILE_FLAG_WAIT_INT)\n\t\tret = wait_event_interruptible(affine_queue,\n\t\t\t\t!set_vdqcr(p, fq, vdqcr));\n\telse\n\t\twait_event(affine_queue, !set_vdqcr(p, fq, vdqcr));\n\treturn ret;\n}\n\nint qman_volatile_dequeue(struct qman_fq *fq, u32 flags, u32 vdqcr)\n{\n\tstruct qman_portal *p;\n\tint ret;\n\n\tif (fq->state != qman_fq_state_parked &&\n\t    fq->state != qman_fq_state_retired)\n\t\treturn -EINVAL;\n\tif (vdqcr & QM_VDQCR_FQID_MASK)\n\t\treturn -EINVAL;\n\tif (fq_isset(fq, QMAN_FQ_STATE_VDQCR))\n\t\treturn -EBUSY;\n\tvdqcr = (vdqcr & ~QM_VDQCR_FQID_MASK) | fq->fqid;\n\tif (flags & QMAN_VOLATILE_FLAG_WAIT)\n\t\tret = wait_vdqcr_start(&p, fq, vdqcr, flags);\n\telse\n\t\tret = set_vdqcr(&p, fq, vdqcr);\n\tif (ret)\n\t\treturn ret;\n\t \n\tif (flags & QMAN_VOLATILE_FLAG_FINISH) {\n\t\tif (flags & QMAN_VOLATILE_FLAG_WAIT_INT)\n\t\t\t \n\t\t\twait_event_interruptible(affine_queue,\n\t\t\t\t!fq_isset(fq, QMAN_FQ_STATE_VDQCR));\n\t\telse\n\t\t\twait_event(affine_queue,\n\t\t\t\t!fq_isset(fq, QMAN_FQ_STATE_VDQCR));\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_volatile_dequeue);\n\nstatic void update_eqcr_ci(struct qman_portal *p, u8 avail)\n{\n\tif (avail)\n\t\tqm_eqcr_cce_prefetch(&p->p);\n\telse\n\t\tqm_eqcr_cce_update(&p->p);\n}\n\nint qman_enqueue(struct qman_fq *fq, const struct qm_fd *fd)\n{\n\tstruct qman_portal *p;\n\tstruct qm_eqcr_entry *eq;\n\tunsigned long irqflags;\n\tu8 avail;\n\n\tp = get_affine_portal();\n\tlocal_irq_save(irqflags);\n\n\tif (p->use_eqcr_ci_stashing) {\n\t\t \n\t\teq = qm_eqcr_start_stash(&p->p);\n\t} else {\n\t\t \n\t\tavail = qm_eqcr_get_avail(&p->p);\n\t\tif (avail < 2)\n\t\t\tupdate_eqcr_ci(p, avail);\n\t\teq = qm_eqcr_start_no_stash(&p->p);\n\t}\n\n\tif (unlikely(!eq))\n\t\tgoto out;\n\n\tqm_fqid_set(eq, fq->fqid);\n\teq->tag = cpu_to_be32(fq_to_tag(fq));\n\teq->fd = *fd;\n\n\tqm_eqcr_pvb_commit(&p->p, QM_EQCR_VERB_CMD_ENQUEUE);\nout:\n\tlocal_irq_restore(irqflags);\n\tput_affine_portal();\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_enqueue);\n\nstatic int qm_modify_cgr(struct qman_cgr *cgr, u32 flags,\n\t\t\t struct qm_mcc_initcgr *opts)\n{\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tstruct qman_portal *p = get_affine_portal();\n\tu8 verb = QM_MCC_VERB_MODIFYCGR;\n\tint ret = 0;\n\n\tmcc = qm_mc_start(&p->p);\n\tif (opts)\n\t\tmcc->initcgr = *opts;\n\tmcc->initcgr.cgid = cgr->cgrid;\n\tif (flags & QMAN_CGR_FLAG_USE_INIT)\n\t\tverb = QM_MCC_VERB_INITCGR;\n\tqm_mc_commit(&p->p, verb);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == verb);\n\tif (mcr->result != QM_MCR_RESULT_OK)\n\t\tret = -EIO;\n\nout:\n\tput_affine_portal();\n\treturn ret;\n}\n\n#define PORTAL_IDX(n)\t(n->config->channel - QM_CHANNEL_SWPORTAL0)\n\n \nstatic void qm_cgr_cscn_targ_set(struct __qm_mc_cgr *cgr, int pi, u32 val)\n{\n\tif (qman_ip_rev >= QMAN_REV30)\n\t\tcgr->cscn_targ_upd_ctrl = cpu_to_be16(pi |\n\t\t\t\t\tQM_CGR_TARG_UDP_CTRL_WRITE_BIT);\n\telse\n\t\tcgr->cscn_targ = cpu_to_be32(val | QM_CGR_TARG_PORTAL(pi));\n}\n\nstatic void qm_cgr_cscn_targ_clear(struct __qm_mc_cgr *cgr, int pi, u32 val)\n{\n\tif (qman_ip_rev >= QMAN_REV30)\n\t\tcgr->cscn_targ_upd_ctrl = cpu_to_be16(pi);\n\telse\n\t\tcgr->cscn_targ = cpu_to_be32(val & ~QM_CGR_TARG_PORTAL(pi));\n}\n\nstatic u8 qman_cgr_cpus[CGR_NUM];\n\nvoid qman_init_cgr_all(void)\n{\n\tstruct qman_cgr cgr;\n\tint err_cnt = 0;\n\n\tfor (cgr.cgrid = 0; cgr.cgrid < CGR_NUM; cgr.cgrid++) {\n\t\tif (qm_modify_cgr(&cgr, QMAN_CGR_FLAG_USE_INIT, NULL))\n\t\t\terr_cnt++;\n\t}\n\n\tif (err_cnt)\n\t\tpr_err(\"Warning: %d error%s while initialising CGR h/w\\n\",\n\t\t       err_cnt, (err_cnt > 1) ? \"s\" : \"\");\n}\n\nint qman_create_cgr(struct qman_cgr *cgr, u32 flags,\n\t\t    struct qm_mcc_initcgr *opts)\n{\n\tstruct qm_mcr_querycgr cgr_state;\n\tint ret;\n\tstruct qman_portal *p;\n\n\t \n\tif (cgr->cgrid >= CGR_NUM)\n\t\treturn -EINVAL;\n\n\tpreempt_disable();\n\tp = get_affine_portal();\n\tqman_cgr_cpus[cgr->cgrid] = smp_processor_id();\n\tpreempt_enable();\n\n\tcgr->chan = p->config->channel;\n\tspin_lock(&p->cgr_lock);\n\n\tif (opts) {\n\t\tstruct qm_mcc_initcgr local_opts = *opts;\n\n\t\tret = qman_query_cgr(cgr, &cgr_state);\n\t\tif (ret)\n\t\t\tgoto out;\n\n\t\tqm_cgr_cscn_targ_set(&local_opts.cgr, PORTAL_IDX(p),\n\t\t\t\t     be32_to_cpu(cgr_state.cgr.cscn_targ));\n\t\tlocal_opts.we_mask |= cpu_to_be16(QM_CGR_WE_CSCN_TARG);\n\n\t\t \n\t\tif (flags & QMAN_CGR_FLAG_USE_INIT)\n\t\t\tret = qm_modify_cgr(cgr, QMAN_CGR_FLAG_USE_INIT,\n\t\t\t\t\t    &local_opts);\n\t\telse\n\t\t\tret = qm_modify_cgr(cgr, 0, &local_opts);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tlist_add(&cgr->node, &p->cgr_cbs);\n\n\t \n\tret = qman_query_cgr(cgr, &cgr_state);\n\tif (ret) {\n\t\t \n\t\tdev_err(p->config->dev, \"CGR HW state partially modified\\n\");\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\tif (cgr->cb && cgr_state.cgr.cscn_en &&\n\t    qman_cgrs_get(&p->cgrs[1], cgr->cgrid))\n\t\tcgr->cb(p, cgr, 1);\nout:\n\tspin_unlock(&p->cgr_lock);\n\tput_affine_portal();\n\treturn ret;\n}\nEXPORT_SYMBOL(qman_create_cgr);\n\nstatic struct qman_portal *qman_cgr_get_affine_portal(struct qman_cgr *cgr)\n{\n\tstruct qman_portal *p = get_affine_portal();\n\n\tif (cgr->chan != p->config->channel) {\n\t\t \n\t\tdev_err(p->config->dev, \"CGR not owned by current portal\");\n\t\tdev_dbg(p->config->dev, \" create 0x%x, delete 0x%x\\n\",\n\t\t\tcgr->chan, p->config->channel);\n\t\tput_affine_portal();\n\t\treturn NULL;\n\t}\n\n\treturn p;\n}\n\nint qman_delete_cgr(struct qman_cgr *cgr)\n{\n\tunsigned long irqflags;\n\tstruct qm_mcr_querycgr cgr_state;\n\tstruct qm_mcc_initcgr local_opts;\n\tint ret = 0;\n\tstruct qman_cgr *i;\n\tstruct qman_portal *p = qman_cgr_get_affine_portal(cgr);\n\n\tif (!p)\n\t\treturn -EINVAL;\n\n\tmemset(&local_opts, 0, sizeof(struct qm_mcc_initcgr));\n\tspin_lock_irqsave(&p->cgr_lock, irqflags);\n\tlist_del(&cgr->node);\n\t \n\tlist_for_each_entry(i, &p->cgr_cbs, node)\n\t\tif (i->cgrid == cgr->cgrid && i->cb)\n\t\t\tgoto release_lock;\n\tret = qman_query_cgr(cgr, &cgr_state);\n\tif (ret)  {\n\t\t \n\t\tlist_add(&cgr->node, &p->cgr_cbs);\n\t\tgoto release_lock;\n\t}\n\n\tlocal_opts.we_mask = cpu_to_be16(QM_CGR_WE_CSCN_TARG);\n\tqm_cgr_cscn_targ_clear(&local_opts.cgr, PORTAL_IDX(p),\n\t\t\t       be32_to_cpu(cgr_state.cgr.cscn_targ));\n\n\tret = qm_modify_cgr(cgr, 0, &local_opts);\n\tif (ret)\n\t\t \n\t\tlist_add(&cgr->node, &p->cgr_cbs);\nrelease_lock:\n\tspin_unlock_irqrestore(&p->cgr_lock, irqflags);\n\tput_affine_portal();\n\treturn ret;\n}\nEXPORT_SYMBOL(qman_delete_cgr);\n\nstruct cgr_comp {\n\tstruct qman_cgr *cgr;\n\tstruct completion completion;\n};\n\nstatic void qman_delete_cgr_smp_call(void *p)\n{\n\tqman_delete_cgr((struct qman_cgr *)p);\n}\n\nvoid qman_delete_cgr_safe(struct qman_cgr *cgr)\n{\n\tpreempt_disable();\n\tif (qman_cgr_cpus[cgr->cgrid] != smp_processor_id()) {\n\t\tsmp_call_function_single(qman_cgr_cpus[cgr->cgrid],\n\t\t\t\t\t qman_delete_cgr_smp_call, cgr, true);\n\t\tpreempt_enable();\n\t\treturn;\n\t}\n\n\tqman_delete_cgr(cgr);\n\tpreempt_enable();\n}\nEXPORT_SYMBOL(qman_delete_cgr_safe);\n\nstatic int qman_update_cgr(struct qman_cgr *cgr, struct qm_mcc_initcgr *opts)\n{\n\tint ret;\n\tunsigned long irqflags;\n\tstruct qman_portal *p = qman_cgr_get_affine_portal(cgr);\n\n\tif (!p)\n\t\treturn -EINVAL;\n\n\tspin_lock_irqsave(&p->cgr_lock, irqflags);\n\tret = qm_modify_cgr(cgr, 0, opts);\n\tspin_unlock_irqrestore(&p->cgr_lock, irqflags);\n\tput_affine_portal();\n\treturn ret;\n}\n\nstruct update_cgr_params {\n\tstruct qman_cgr *cgr;\n\tstruct qm_mcc_initcgr *opts;\n\tint ret;\n};\n\nstatic void qman_update_cgr_smp_call(void *p)\n{\n\tstruct update_cgr_params *params = p;\n\n\tparams->ret = qman_update_cgr(params->cgr, params->opts);\n}\n\nint qman_update_cgr_safe(struct qman_cgr *cgr, struct qm_mcc_initcgr *opts)\n{\n\tstruct update_cgr_params params = {\n\t\t.cgr = cgr,\n\t\t.opts = opts,\n\t};\n\n\tpreempt_disable();\n\tif (qman_cgr_cpus[cgr->cgrid] != smp_processor_id())\n\t\tsmp_call_function_single(qman_cgr_cpus[cgr->cgrid],\n\t\t\t\t\t qman_update_cgr_smp_call, &params,\n\t\t\t\t\t true);\n\telse\n\t\tparams.ret = qman_update_cgr(cgr, opts);\n\tpreempt_enable();\n\treturn params.ret;\n}\nEXPORT_SYMBOL(qman_update_cgr_safe);\n\n \n\nstatic int _qm_mr_consume_and_match_verb(struct qm_portal *p, int v)\n{\n\tconst union qm_mr_entry *msg;\n\tint found = 0;\n\n\tqm_mr_pvb_update(p);\n\tmsg = qm_mr_current(p);\n\twhile (msg) {\n\t\tif ((msg->verb & QM_MR_VERB_TYPE_MASK) == v)\n\t\t\tfound = 1;\n\t\tqm_mr_next(p);\n\t\tqm_mr_cci_consume_to_current(p);\n\t\tqm_mr_pvb_update(p);\n\t\tmsg = qm_mr_current(p);\n\t}\n\treturn found;\n}\n\nstatic int _qm_dqrr_consume_and_match(struct qm_portal *p, u32 fqid, int s,\n\t\t\t\t      bool wait)\n{\n\tconst struct qm_dqrr_entry *dqrr;\n\tint found = 0;\n\n\tdo {\n\t\tqm_dqrr_pvb_update(p);\n\t\tdqrr = qm_dqrr_current(p);\n\t\tif (!dqrr)\n\t\t\tcpu_relax();\n\t} while (wait && !dqrr);\n\n\twhile (dqrr) {\n\t\tif (qm_fqid_get(dqrr) == fqid && (dqrr->stat & s))\n\t\t\tfound = 1;\n\t\tqm_dqrr_cdc_consume_1ptr(p, dqrr, 0);\n\t\tqm_dqrr_pvb_update(p);\n\t\tqm_dqrr_next(p);\n\t\tdqrr = qm_dqrr_current(p);\n\t}\n\treturn found;\n}\n\n#define qm_mr_drain(p, V) \\\n\t_qm_mr_consume_and_match_verb(p, QM_MR_VERB_##V)\n\n#define qm_dqrr_drain(p, f, S) \\\n\t_qm_dqrr_consume_and_match(p, f, QM_DQRR_STAT_##S, false)\n\n#define qm_dqrr_drain_wait(p, f, S) \\\n\t_qm_dqrr_consume_and_match(p, f, QM_DQRR_STAT_##S, true)\n\n#define qm_dqrr_drain_nomatch(p) \\\n\t_qm_dqrr_consume_and_match(p, 0, 0, false)\n\nint qman_shutdown_fq(u32 fqid)\n{\n\tstruct qman_portal *p, *channel_portal;\n\tstruct device *dev;\n\tunion qm_mc_command *mcc;\n\tunion qm_mc_result *mcr;\n\tint orl_empty, drain = 0, ret = 0;\n\tu32 channel, res;\n\tu8 state;\n\n\tp = get_affine_portal();\n\tdev = p->config->dev;\n\t \n\tmcc = qm_mc_start(&p->p);\n\tqm_fqid_set(&mcc->fq, fqid);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ_NP);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tdev_err(dev, \"QUERYFQ_NP timeout\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ_NP);\n\tstate = mcr->queryfq_np.state & QM_MCR_NP_STATE_MASK;\n\tif (state == QM_MCR_NP_STATE_OOS)\n\t\tgoto out;  \n\n\t \n\tmcc = qm_mc_start(&p->p);\n\tqm_fqid_set(&mcc->fq, fqid);\n\tqm_mc_commit(&p->p, QM_MCC_VERB_QUERYFQ);\n\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\tdev_err(dev, \"QUERYFQ timeout\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto out;\n\t}\n\n\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) == QM_MCR_VERB_QUERYFQ);\n\t \n\tchannel = qm_fqd_get_chan(&mcr->queryfq.fqd);\n\tqm_fqd_get_wq(&mcr->queryfq.fqd);\n\n\tif (channel < qm_channel_pool1) {\n\t\tchannel_portal = get_portal_for_channel(channel);\n\t\tif (channel_portal == NULL) {\n\t\t\tdev_err(dev, \"Can't find portal for dedicated channel 0x%x\\n\",\n\t\t\t\tchannel);\n\t\t\tret = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t} else\n\t\tchannel_portal = p;\n\n\tswitch (state) {\n\tcase QM_MCR_NP_STATE_TEN_SCHED:\n\tcase QM_MCR_NP_STATE_TRU_SCHED:\n\tcase QM_MCR_NP_STATE_ACTIVE:\n\tcase QM_MCR_NP_STATE_PARKED:\n\t\torl_empty = 0;\n\t\tmcc = qm_mc_start(&channel_portal->p);\n\t\tqm_fqid_set(&mcc->fq, fqid);\n\t\tqm_mc_commit(&channel_portal->p, QM_MCC_VERB_ALTER_RETIRE);\n\t\tif (!qm_mc_result_timeout(&channel_portal->p, &mcr)) {\n\t\t\tdev_err(dev, \"ALTER_RETIRE timeout\\n\");\n\t\t\tret = -ETIMEDOUT;\n\t\t\tgoto out;\n\t\t}\n\t\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) ==\n\t\t\t    QM_MCR_VERB_ALTER_RETIRE);\n\t\tres = mcr->result;  \n\n\t\tif (res == QM_MCR_RESULT_OK)\n\t\t\tdrain_mr_fqrni(&channel_portal->p);\n\n\t\tif (res == QM_MCR_RESULT_PENDING) {\n\t\t\t \n\t\t\tint found_fqrn = 0;\n\n\t\t\t \n\t\t\tdrain = 1;\n\n\t\t\tif (channel >= qm_channel_pool1 &&\n\t\t\t    channel < qm_channel_pool1 + 15) {\n\t\t\t\t \n\t\t\t} else if (channel < qm_channel_pool1) {\n\t\t\t\t \n\t\t\t} else {\n\t\t\t\tdev_err(dev, \"Can't recover FQ 0x%x, ch: 0x%x\",\n\t\t\t\t\tfqid, channel);\n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\t \n\t\t\tif (channel < qm_channel_pool1)\n\t\t\t\tqm_dqrr_sdqcr_set(&channel_portal->p,\n\t\t\t\t\t\t  QM_SDQCR_TYPE_ACTIVE |\n\t\t\t\t\t\t  QM_SDQCR_CHANNELS_DEDICATED);\n\t\t\telse\n\t\t\t\tqm_dqrr_sdqcr_set(&channel_portal->p,\n\t\t\t\t\t\t  QM_SDQCR_TYPE_ACTIVE |\n\t\t\t\t\t\t  QM_SDQCR_CHANNELS_POOL_CONV\n\t\t\t\t\t\t  (channel));\n\t\t\tdo {\n\t\t\t\t \n\t\t\t\tqm_dqrr_drain_nomatch(&channel_portal->p);\n\t\t\t\t \n\t\t\t\tfound_fqrn = qm_mr_drain(&channel_portal->p,\n\t\t\t\t\t\t\t FQRN);\n\t\t\t\tcpu_relax();\n\t\t\t} while (!found_fqrn);\n\t\t\t \n\t\t\tqm_dqrr_sdqcr_set(&channel_portal->p,\n\t\t\t\t\t  channel_portal->sdqcr);\n\n\t\t}\n\t\tif (res != QM_MCR_RESULT_OK &&\n\t\t    res != QM_MCR_RESULT_PENDING) {\n\t\t\tdev_err(dev, \"retire_fq failed: FQ 0x%x, res=0x%x\\n\",\n\t\t\t\tfqid, res);\n\t\t\tret = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tif (!(mcr->alterfq.fqs & QM_MCR_FQS_ORLPRESENT)) {\n\t\t\t \n\t\t\torl_empty = 1;\n\t\t}\n\t\t \n\t\tif (drain || mcr->alterfq.fqs & QM_MCR_FQS_NOTEMPTY) {\n\t\t\t \n\t\t\tdo {\n\t\t\t\tu32 vdqcr = fqid | QM_VDQCR_NUMFRAMES_SET(3);\n\n\t\t\t\tqm_dqrr_vdqcr_set(&p->p, vdqcr);\n\t\t\t\t \n\t\t\t} while (!qm_dqrr_drain_wait(&p->p, fqid, FQ_EMPTY));\n\t\t}\n\n\t\twhile (!orl_empty) {\n\t\t\t \n\t\t\torl_empty = qm_mr_drain(&p->p, FQRL);\n\t\t\tcpu_relax();\n\t\t}\n\t\tmcc = qm_mc_start(&p->p);\n\t\tqm_fqid_set(&mcc->fq, fqid);\n\t\tqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_OOS);\n\t\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\t\tret = -ETIMEDOUT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) ==\n\t\t\t    QM_MCR_VERB_ALTER_OOS);\n\t\tif (mcr->result != QM_MCR_RESULT_OK) {\n\t\t\tdev_err(dev, \"OOS after drain fail: FQ 0x%x (0x%x)\\n\",\n\t\t\t\tfqid, mcr->result);\n\t\t\tret = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\n\tcase QM_MCR_NP_STATE_RETIRED:\n\t\t \n\t\tmcc = qm_mc_start(&p->p);\n\t\tqm_fqid_set(&mcc->fq, fqid);\n\t\tqm_mc_commit(&p->p, QM_MCC_VERB_ALTER_OOS);\n\t\tif (!qm_mc_result_timeout(&p->p, &mcr)) {\n\t\t\tret = -ETIMEDOUT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tDPAA_ASSERT((mcr->verb & QM_MCR_VERB_MASK) ==\n\t\t\t    QM_MCR_VERB_ALTER_OOS);\n\t\tif (mcr->result != QM_MCR_RESULT_OK) {\n\t\t\tdev_err(dev, \"OOS fail: FQ 0x%x (0x%x)\\n\",\n\t\t\t\tfqid, mcr->result);\n\t\t\tret = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\n\tcase QM_MCR_NP_STATE_OOS:\n\t\t \n\t\tbreak;\n\n\tdefault:\n\t\tret = -EIO;\n\t}\n\nout:\n\tput_affine_portal();\n\treturn ret;\n}\n\nconst struct qm_portal_config *qman_get_qm_portal_config(\n\t\t\t\t\t\tstruct qman_portal *portal)\n{\n\treturn portal->config;\n}\nEXPORT_SYMBOL(qman_get_qm_portal_config);\n\nstruct gen_pool *qm_fqalloc;  \nstruct gen_pool *qm_qpalloc;  \nstruct gen_pool *qm_cgralloc;  \n\nstatic int qman_alloc_range(struct gen_pool *p, u32 *result, u32 cnt)\n{\n\tunsigned long addr;\n\n\tif (!p)\n\t\treturn -ENODEV;\n\n\taddr = gen_pool_alloc(p, cnt);\n\tif (!addr)\n\t\treturn -ENOMEM;\n\n\t*result = addr & ~DPAA_GENALLOC_OFF;\n\n\treturn 0;\n}\n\nint qman_alloc_fqid_range(u32 *result, u32 count)\n{\n\treturn qman_alloc_range(qm_fqalloc, result, count);\n}\nEXPORT_SYMBOL(qman_alloc_fqid_range);\n\nint qman_alloc_pool_range(u32 *result, u32 count)\n{\n\treturn qman_alloc_range(qm_qpalloc, result, count);\n}\nEXPORT_SYMBOL(qman_alloc_pool_range);\n\nint qman_alloc_cgrid_range(u32 *result, u32 count)\n{\n\treturn qman_alloc_range(qm_cgralloc, result, count);\n}\nEXPORT_SYMBOL(qman_alloc_cgrid_range);\n\nint qman_release_fqid(u32 fqid)\n{\n\tint ret = qman_shutdown_fq(fqid);\n\n\tif (ret) {\n\t\tpr_debug(\"FQID %d leaked\\n\", fqid);\n\t\treturn ret;\n\t}\n\n\tgen_pool_free(qm_fqalloc, fqid | DPAA_GENALLOC_OFF, 1);\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_release_fqid);\n\nstatic int qpool_cleanup(u32 qp)\n{\n\t \n\tstruct qman_fq fq = {\n\t\t.fqid = QM_FQID_RANGE_START\n\t};\n\tint err;\n\n\tdo {\n\t\tstruct qm_mcr_queryfq_np np;\n\n\t\terr = qman_query_fq_np(&fq, &np);\n\t\tif (err == -ERANGE)\n\t\t\t \n\t\t\treturn 0;\n\t\telse if (WARN_ON(err))\n\t\t\treturn err;\n\n\t\tif ((np.state & QM_MCR_NP_STATE_MASK) != QM_MCR_NP_STATE_OOS) {\n\t\t\tstruct qm_fqd fqd;\n\n\t\t\terr = qman_query_fq(&fq, &fqd);\n\t\t\tif (WARN_ON(err))\n\t\t\t\treturn err;\n\t\t\tif (qm_fqd_get_chan(&fqd) == qp) {\n\t\t\t\t \n\t\t\t\terr = qman_shutdown_fq(fq.fqid);\n\t\t\t\tif (err)\n\t\t\t\t\t \n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t\t \n\t\tfq.fqid++;\n\t} while (1);\n}\n\nint qman_release_pool(u32 qp)\n{\n\tint ret;\n\n\tret = qpool_cleanup(qp);\n\tif (ret) {\n\t\tpr_debug(\"CHID %d leaked\\n\", qp);\n\t\treturn ret;\n\t}\n\n\tgen_pool_free(qm_qpalloc, qp | DPAA_GENALLOC_OFF, 1);\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_release_pool);\n\nstatic int cgr_cleanup(u32 cgrid)\n{\n\t \n\tstruct qman_fq fq = {\n\t\t.fqid = QM_FQID_RANGE_START\n\t};\n\tint err;\n\n\tdo {\n\t\tstruct qm_mcr_queryfq_np np;\n\n\t\terr = qman_query_fq_np(&fq, &np);\n\t\tif (err == -ERANGE)\n\t\t\t \n\t\t\treturn 0;\n\t\telse if (WARN_ON(err))\n\t\t\treturn err;\n\n\t\tif ((np.state & QM_MCR_NP_STATE_MASK) != QM_MCR_NP_STATE_OOS) {\n\t\t\tstruct qm_fqd fqd;\n\n\t\t\terr = qman_query_fq(&fq, &fqd);\n\t\t\tif (WARN_ON(err))\n\t\t\t\treturn err;\n\t\t\tif (be16_to_cpu(fqd.fq_ctrl) & QM_FQCTRL_CGE &&\n\t\t\t    fqd.cgid == cgrid) {\n\t\t\t\tpr_err(\"CRGID 0x%x is being used by FQID 0x%x, CGR will be leaked\\n\",\n\t\t\t\t       cgrid, fq.fqid);\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\t\t \n\t\tfq.fqid++;\n\t} while (1);\n}\n\nint qman_release_cgrid(u32 cgrid)\n{\n\tint ret;\n\n\tret = cgr_cleanup(cgrid);\n\tif (ret) {\n\t\tpr_debug(\"CGRID %d leaked\\n\", cgrid);\n\t\treturn ret;\n\t}\n\n\tgen_pool_free(qm_cgralloc, cgrid | DPAA_GENALLOC_OFF, 1);\n\treturn 0;\n}\nEXPORT_SYMBOL(qman_release_cgrid);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}