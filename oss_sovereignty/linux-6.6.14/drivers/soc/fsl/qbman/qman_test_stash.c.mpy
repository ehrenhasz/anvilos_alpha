{
  "module_name": "qman_test_stash.c",
  "hash_id": "e81b7ab26309c55b2a99186bf2267e11fe27ba931895ba8766606624da7d3b26",
  "original_prompt": "Ingested from linux-6.6.14/drivers/soc/fsl/qbman/qman_test_stash.c",
  "human_readable_source": " \n\n#include \"qman_test.h\"\n\n#include <linux/dma-mapping.h>\n#include <linux/delay.h>\n\n \n\n \nstruct bstrap {\n\tint (*fn)(void);\n\tatomic_t started;\n};\nstatic int bstrap_fn(void *bs)\n{\n\tstruct bstrap *bstrap = bs;\n\tint err;\n\n\tatomic_inc(&bstrap->started);\n\terr = bstrap->fn();\n\tif (err)\n\t\treturn err;\n\twhile (!kthread_should_stop())\n\t\tmsleep(20);\n\treturn 0;\n}\nstatic int on_all_cpus(int (*fn)(void))\n{\n\tint cpu;\n\n\tfor_each_cpu(cpu, cpu_online_mask) {\n\t\tstruct bstrap bstrap = {\n\t\t\t.fn = fn,\n\t\t\t.started = ATOMIC_INIT(0)\n\t\t};\n\t\tstruct task_struct *k = kthread_create(bstrap_fn, &bstrap,\n\t\t\t\"hotpotato%d\", cpu);\n\t\tint ret;\n\n\t\tif (IS_ERR(k))\n\t\t\treturn -ENOMEM;\n\t\tkthread_bind(k, cpu);\n\t\twake_up_process(k);\n\t\t \n\t\twhile (!atomic_read(&bstrap.started))\n\t\t\tmsleep(20);\n\t\tret = kthread_stop(k);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstruct hp_handler {\n\n\t \n\t \n\t \n\tstruct qman_fq rx;\n\t \n\tstruct qman_fq tx;\n\t \n\tu32 rx_mixer;\n\t \n\tu32 tx_mixer;\n\t \n\tdma_addr_t addr;\n\tu32 *frame_ptr;\n\n\t \n\t \n\tu32 fqid_rx, fqid_tx;\n\t \n\tstruct list_head node;\n\t \n\tunsigned int processor_id;\n} ____cacheline_aligned;\n\nstruct hp_cpu {\n\t \n\tunsigned int processor_id;\n\t \n\tstruct list_head handlers;\n\t \n\tstruct list_head node;\n\t \n\tstruct hp_handler *iterator;\n};\n\n \nstatic DEFINE_PER_CPU(struct hp_cpu, hp_cpus);\n\n \nstatic LIST_HEAD(hp_cpu_list);\nstatic DEFINE_SPINLOCK(hp_lock);\n\nstatic unsigned int hp_cpu_list_length;\n\n \nstatic struct hp_handler *special_handler;\nstatic int loop_counter;\n\n \nstatic struct kmem_cache *hp_handler_slab;\n\n \nstatic void *__frame_ptr;\nstatic u32 *frame_ptr;\nstatic dma_addr_t frame_dma;\n\n \nstatic const struct qm_portal_config *pcfg;\n\n \nstatic DECLARE_WAIT_QUEUE_HEAD(queue);\n\n#define HP_PER_CPU\t2\n#define HP_LOOPS\t8\n \n#define HP_NUM_WORDS\t80\n \n#define HP_FIRST_WORD\t0xabbaf00d\n\nstatic inline u32 do_lfsr(u32 prev)\n{\n\treturn (prev >> 1) ^ (-(prev & 1u) & 0xd0000001u);\n}\n\nstatic int allocate_frame_data(void)\n{\n\tu32 lfsr = HP_FIRST_WORD;\n\tint loop;\n\n\tif (!qman_dma_portal) {\n\t\tpr_crit(\"portal not available\\n\");\n\t\treturn -EIO;\n\t}\n\n\tpcfg = qman_get_qm_portal_config(qman_dma_portal);\n\n\t__frame_ptr = kmalloc(4 * HP_NUM_WORDS, GFP_KERNEL);\n\tif (!__frame_ptr)\n\t\treturn -ENOMEM;\n\n\tframe_ptr = PTR_ALIGN(__frame_ptr, 64);\n\tfor (loop = 0; loop < HP_NUM_WORDS; loop++) {\n\t\tframe_ptr[loop] = lfsr;\n\t\tlfsr = do_lfsr(lfsr);\n\t}\n\n\tframe_dma = dma_map_single(pcfg->dev, frame_ptr, 4 * HP_NUM_WORDS,\n\t\t\t\t   DMA_BIDIRECTIONAL);\n\tif (dma_mapping_error(pcfg->dev, frame_dma)) {\n\t\tpr_crit(\"dma mapping failure\\n\");\n\t\tkfree(__frame_ptr);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic void deallocate_frame_data(void)\n{\n\tdma_unmap_single(pcfg->dev, frame_dma, 4 * HP_NUM_WORDS,\n\t\t\t DMA_BIDIRECTIONAL);\n\tkfree(__frame_ptr);\n}\n\nstatic inline int process_frame_data(struct hp_handler *handler,\n\t\t\t\t     const struct qm_fd *fd)\n{\n\tu32 *p = handler->frame_ptr;\n\tu32 lfsr = HP_FIRST_WORD;\n\tint loop;\n\n\tif (qm_fd_addr_get64(fd) != handler->addr) {\n\t\tpr_crit(\"bad frame address, [%llX != %llX]\\n\",\n\t\t\tqm_fd_addr_get64(fd), handler->addr);\n\t\treturn -EIO;\n\t}\n\tfor (loop = 0; loop < HP_NUM_WORDS; loop++, p++) {\n\t\t*p ^= handler->rx_mixer;\n\t\tif (*p != lfsr) {\n\t\t\tpr_crit(\"corrupt frame data\");\n\t\t\treturn -EIO;\n\t\t}\n\t\t*p ^= handler->tx_mixer;\n\t\tlfsr = do_lfsr(lfsr);\n\t}\n\treturn 0;\n}\n\nstatic enum qman_cb_dqrr_result normal_dqrr(struct qman_portal *portal,\n\t\t\t\t\t    struct qman_fq *fq,\n\t\t\t\t\t    const struct qm_dqrr_entry *dqrr,\n\t\t\t\t\t    bool sched_napi)\n{\n\tstruct hp_handler *handler = (struct hp_handler *)fq;\n\n\tif (process_frame_data(handler, &dqrr->fd)) {\n\t\tWARN_ON(1);\n\t\tgoto skip;\n\t}\n\tif (qman_enqueue(&handler->tx, &dqrr->fd)) {\n\t\tpr_crit(\"qman_enqueue() failed\");\n\t\tWARN_ON(1);\n\t}\nskip:\n\treturn qman_cb_dqrr_consume;\n}\n\nstatic enum qman_cb_dqrr_result special_dqrr(struct qman_portal *portal,\n\t\t\t\t\t     struct qman_fq *fq,\n\t\t\t\t\t     const struct qm_dqrr_entry *dqrr,\n\t\t\t\t\t     bool sched_napi)\n{\n\tstruct hp_handler *handler = (struct hp_handler *)fq;\n\n\tprocess_frame_data(handler, &dqrr->fd);\n\tif (++loop_counter < HP_LOOPS) {\n\t\tif (qman_enqueue(&handler->tx, &dqrr->fd)) {\n\t\t\tpr_crit(\"qman_enqueue() failed\");\n\t\t\tWARN_ON(1);\n\t\t\tgoto skip;\n\t\t}\n\t} else {\n\t\tpr_info(\"Received final (%dth) frame\\n\", loop_counter);\n\t\twake_up(&queue);\n\t}\nskip:\n\treturn qman_cb_dqrr_consume;\n}\n\nstatic int create_per_cpu_handlers(void)\n{\n\tstruct hp_handler *handler;\n\tint loop;\n\tstruct hp_cpu *hp_cpu = this_cpu_ptr(&hp_cpus);\n\n\thp_cpu->processor_id = smp_processor_id();\n\tspin_lock(&hp_lock);\n\tlist_add_tail(&hp_cpu->node, &hp_cpu_list);\n\thp_cpu_list_length++;\n\tspin_unlock(&hp_lock);\n\tINIT_LIST_HEAD(&hp_cpu->handlers);\n\tfor (loop = 0; loop < HP_PER_CPU; loop++) {\n\t\thandler = kmem_cache_alloc(hp_handler_slab, GFP_KERNEL);\n\t\tif (!handler) {\n\t\t\tpr_crit(\"kmem_cache_alloc() failed\");\n\t\t\tWARN_ON(1);\n\t\t\treturn -EIO;\n\t\t}\n\t\thandler->processor_id = hp_cpu->processor_id;\n\t\thandler->addr = frame_dma;\n\t\thandler->frame_ptr = frame_ptr;\n\t\tlist_add_tail(&handler->node, &hp_cpu->handlers);\n\t}\n\treturn 0;\n}\n\nstatic int destroy_per_cpu_handlers(void)\n{\n\tstruct list_head *loop, *tmp;\n\tstruct hp_cpu *hp_cpu = this_cpu_ptr(&hp_cpus);\n\n\tspin_lock(&hp_lock);\n\tlist_del(&hp_cpu->node);\n\tspin_unlock(&hp_lock);\n\tlist_for_each_safe(loop, tmp, &hp_cpu->handlers) {\n\t\tu32 flags = 0;\n\t\tstruct hp_handler *handler = list_entry(loop, struct hp_handler,\n\t\t\t\t\t\t\tnode);\n\t\tif (qman_retire_fq(&handler->rx, &flags) ||\n\t\t    (flags & QMAN_FQ_STATE_BLOCKOOS)) {\n\t\t\tpr_crit(\"qman_retire_fq(rx) failed, flags: %x\", flags);\n\t\t\tWARN_ON(1);\n\t\t\treturn -EIO;\n\t\t}\n\t\tif (qman_oos_fq(&handler->rx)) {\n\t\t\tpr_crit(\"qman_oos_fq(rx) failed\");\n\t\t\tWARN_ON(1);\n\t\t\treturn -EIO;\n\t\t}\n\t\tqman_destroy_fq(&handler->rx);\n\t\tqman_destroy_fq(&handler->tx);\n\t\tqman_release_fqid(handler->fqid_rx);\n\t\tlist_del(&handler->node);\n\t\tkmem_cache_free(hp_handler_slab, handler);\n\t}\n\treturn 0;\n}\n\nstatic inline u8 num_cachelines(u32 offset)\n{\n\tu8 res = (offset + (L1_CACHE_BYTES - 1))\n\t\t\t / (L1_CACHE_BYTES);\n\tif (res > 3)\n\t\treturn 3;\n\treturn res;\n}\n#define STASH_DATA_CL \\\n\tnum_cachelines(HP_NUM_WORDS * 4)\n#define STASH_CTX_CL \\\n\tnum_cachelines(offsetof(struct hp_handler, fqid_rx))\n\nstatic int init_handler(void *h)\n{\n\tstruct qm_mcc_initfq opts;\n\tstruct hp_handler *handler = h;\n\tint err;\n\n\tif (handler->processor_id != smp_processor_id()) {\n\t\terr = -EIO;\n\t\tgoto failed;\n\t}\n\t \n\tmemset(&handler->rx, 0, sizeof(handler->rx));\n\tif (handler == special_handler)\n\t\thandler->rx.cb.dqrr = special_dqrr;\n\telse\n\t\thandler->rx.cb.dqrr = normal_dqrr;\n\terr = qman_create_fq(handler->fqid_rx, 0, &handler->rx);\n\tif (err) {\n\t\tpr_crit(\"qman_create_fq(rx) failed\");\n\t\tgoto failed;\n\t}\n\tmemset(&opts, 0, sizeof(opts));\n\topts.we_mask = cpu_to_be16(QM_INITFQ_WE_FQCTRL |\n\t\t\t\t   QM_INITFQ_WE_CONTEXTA);\n\topts.fqd.fq_ctrl = cpu_to_be16(QM_FQCTRL_CTXASTASHING);\n\tqm_fqd_set_stashing(&opts.fqd, 0, STASH_DATA_CL, STASH_CTX_CL);\n\terr = qman_init_fq(&handler->rx, QMAN_INITFQ_FLAG_SCHED |\n\t\t\t   QMAN_INITFQ_FLAG_LOCAL, &opts);\n\tif (err) {\n\t\tpr_crit(\"qman_init_fq(rx) failed\");\n\t\tgoto failed;\n\t}\n\t \n\tmemset(&handler->tx, 0, sizeof(handler->tx));\n\terr = qman_create_fq(handler->fqid_tx, QMAN_FQ_FLAG_NO_MODIFY,\n\t\t\t     &handler->tx);\n\tif (err) {\n\t\tpr_crit(\"qman_create_fq(tx) failed\");\n\t\tgoto failed;\n\t}\n\n\treturn 0;\nfailed:\n\treturn err;\n}\n\nstatic void init_handler_cb(void *h)\n{\n\tif (init_handler(h))\n\t\tWARN_ON(1);\n}\n\nstatic int init_phase2(void)\n{\n\tint loop;\n\tu32 fqid = 0;\n\tu32 lfsr = 0xdeadbeef;\n\tstruct hp_cpu *hp_cpu;\n\tstruct hp_handler *handler;\n\n\tfor (loop = 0; loop < HP_PER_CPU; loop++) {\n\t\tlist_for_each_entry(hp_cpu, &hp_cpu_list, node) {\n\t\t\tint err;\n\n\t\t\tif (!loop)\n\t\t\t\thp_cpu->iterator = list_first_entry(\n\t\t\t\t\t\t&hp_cpu->handlers,\n\t\t\t\t\t\tstruct hp_handler, node);\n\t\t\telse\n\t\t\t\thp_cpu->iterator = list_entry(\n\t\t\t\t\t\thp_cpu->iterator->node.next,\n\t\t\t\t\t\tstruct hp_handler, node);\n\t\t\t \n\t\t\thp_cpu->iterator->fqid_rx = fqid;\n\t\t\t \n\t\t\terr = qman_alloc_fqid(&fqid);\n\t\t\tif (err) {\n\t\t\t\tpr_crit(\"qman_alloc_fqid() failed\");\n\t\t\t\treturn err;\n\t\t\t}\n\t\t\thp_cpu->iterator->fqid_tx = fqid;\n\t\t\t \n\t\t\thp_cpu->iterator->rx_mixer = lfsr;\n\t\t\t \n\t\t\tlfsr = do_lfsr(lfsr);\n\t\t\thp_cpu->iterator->tx_mixer = lfsr;\n\t\t}\n\t}\n\t \n\thp_cpu = list_first_entry(&hp_cpu_list, struct hp_cpu, node);\n\thandler = list_first_entry(&hp_cpu->handlers, struct hp_handler, node);\n\tif (handler->fqid_rx != 0 || handler->rx_mixer != 0xdeadbeef)\n\t\treturn 1;\n\thandler->fqid_rx = fqid;\n\thandler->rx_mixer = lfsr;\n\t \n\tspecial_handler = handler;\n\treturn 0;\n}\n\nstatic int init_phase3(void)\n{\n\tint loop, err;\n\tstruct hp_cpu *hp_cpu;\n\n\tfor (loop = 0; loop < HP_PER_CPU; loop++) {\n\t\tlist_for_each_entry(hp_cpu, &hp_cpu_list, node) {\n\t\t\tif (!loop)\n\t\t\t\thp_cpu->iterator = list_first_entry(\n\t\t\t\t\t\t&hp_cpu->handlers,\n\t\t\t\t\t\tstruct hp_handler, node);\n\t\t\telse\n\t\t\t\thp_cpu->iterator = list_entry(\n\t\t\t\t\t\thp_cpu->iterator->node.next,\n\t\t\t\t\t\tstruct hp_handler, node);\n\t\t\tpreempt_disable();\n\t\t\tif (hp_cpu->processor_id == smp_processor_id()) {\n\t\t\t\terr = init_handler(hp_cpu->iterator);\n\t\t\t\tif (err)\n\t\t\t\t\treturn err;\n\t\t\t} else {\n\t\t\t\tsmp_call_function_single(hp_cpu->processor_id,\n\t\t\t\t\tinit_handler_cb, hp_cpu->iterator, 1);\n\t\t\t}\n\t\t\tpreempt_enable();\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int send_first_frame(void *ignore)\n{\n\tu32 *p = special_handler->frame_ptr;\n\tu32 lfsr = HP_FIRST_WORD;\n\tint loop, err;\n\tstruct qm_fd fd;\n\n\tif (special_handler->processor_id != smp_processor_id()) {\n\t\terr = -EIO;\n\t\tgoto failed;\n\t}\n\tmemset(&fd, 0, sizeof(fd));\n\tqm_fd_addr_set64(&fd, special_handler->addr);\n\tqm_fd_set_contig_big(&fd, HP_NUM_WORDS * 4);\n\tfor (loop = 0; loop < HP_NUM_WORDS; loop++, p++) {\n\t\tif (*p != lfsr) {\n\t\t\terr = -EIO;\n\t\t\tpr_crit(\"corrupt frame data\");\n\t\t\tgoto failed;\n\t\t}\n\t\t*p ^= special_handler->tx_mixer;\n\t\tlfsr = do_lfsr(lfsr);\n\t}\n\tpr_info(\"Sending first frame\\n\");\n\terr = qman_enqueue(&special_handler->tx, &fd);\n\tif (err) {\n\t\tpr_crit(\"qman_enqueue() failed\");\n\t\tgoto failed;\n\t}\n\n\treturn 0;\nfailed:\n\treturn err;\n}\n\nstatic void send_first_frame_cb(void *ignore)\n{\n\tif (send_first_frame(NULL))\n\t\tWARN_ON(1);\n}\n\nint qman_test_stash(void)\n{\n\tint err;\n\n\tif (cpumask_weight(cpu_online_mask) < 2) {\n\t\tpr_info(\"%s(): skip - only 1 CPU\\n\", __func__);\n\t\treturn 0;\n\t}\n\n\tpr_info(\"%s(): Starting\\n\", __func__);\n\n\thp_cpu_list_length = 0;\n\tloop_counter = 0;\n\thp_handler_slab = kmem_cache_create(\"hp_handler_slab\",\n\t\t\tsizeof(struct hp_handler), L1_CACHE_BYTES,\n\t\t\tSLAB_HWCACHE_ALIGN, NULL);\n\tif (!hp_handler_slab) {\n\t\terr = -EIO;\n\t\tpr_crit(\"kmem_cache_create() failed\");\n\t\tgoto failed;\n\t}\n\n\terr = allocate_frame_data();\n\tif (err)\n\t\tgoto failed;\n\n\t \n\tpr_info(\"Creating %d handlers per cpu...\\n\", HP_PER_CPU);\n\tif (on_all_cpus(create_per_cpu_handlers)) {\n\t\terr = -EIO;\n\t\tpr_crit(\"on_each_cpu() failed\");\n\t\tgoto failed;\n\t}\n\tpr_info(\"Number of cpus: %d, total of %d handlers\\n\",\n\t\thp_cpu_list_length, hp_cpu_list_length * HP_PER_CPU);\n\n\terr = init_phase2();\n\tif (err)\n\t\tgoto failed;\n\n\terr = init_phase3();\n\tif (err)\n\t\tgoto failed;\n\n\tpreempt_disable();\n\tif (special_handler->processor_id == smp_processor_id()) {\n\t\terr = send_first_frame(NULL);\n\t\tif (err)\n\t\t\tgoto failed;\n\t} else {\n\t\tsmp_call_function_single(special_handler->processor_id,\n\t\t\t\t\t send_first_frame_cb, NULL, 1);\n\t}\n\tpreempt_enable();\n\n\twait_event(queue, loop_counter == HP_LOOPS);\n\tdeallocate_frame_data();\n\tif (on_all_cpus(destroy_per_cpu_handlers)) {\n\t\terr = -EIO;\n\t\tpr_crit(\"on_each_cpu() failed\");\n\t\tgoto failed;\n\t}\n\tkmem_cache_destroy(hp_handler_slab);\n\tpr_info(\"%s(): Finished\\n\", __func__);\n\n\treturn 0;\nfailed:\n\tWARN_ON(1);\n\treturn err;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}