{
  "module_name": "hwmtm.c",
  "hash_id": "799573e005fcc0bd5ce01fbcbac3082f676b653cab1c0fb50b3e8080b477a78d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/fddi/skfp/hwmtm.c",
  "human_readable_source": "\n \n\n#define\tHWMTM\n\n#ifndef FDDI\n#define\tFDDI\n#endif\n\n#include \"h/types.h\"\n#include \"h/fddi.h\"\n#include \"h/smc.h\"\n#include \"h/supern_2.h\"\n#include \"h/skfbiinc.h\"\n\n \n \n#ifdef COMMON_MB_POOL\nstatic\tSMbuf *mb_start;\nstatic\tSMbuf *mb_free;\nstatic\tint mb_init = FALSE ;\nstatic\tint call_count;\n#endif\n\n \n\n#ifdef\tDEBUG\n#ifndef\tDEBUG_BRD\nextern\tstruct smt_debug\tdebug ;\n#endif\n#endif\n\n#ifdef\tNDIS_OS2\nextern\tu_char\toffDepth ;\nextern\tu_char\tforce_irq_pending ;\n#endif\n\n \n\nstatic void queue_llc_rx(struct s_smc *smc, SMbuf *mb);\nstatic void smt_to_llc(struct s_smc *smc, SMbuf *mb);\nstatic void init_txd_ring(struct s_smc *smc);\nstatic void init_rxd_ring(struct s_smc *smc);\nstatic void queue_txd_mb(struct s_smc *smc, SMbuf *mb);\nstatic u_long init_descr_ring(struct s_smc *smc, union s_fp_descr volatile *start,\n\t\t\t      int count);\nstatic u_long repair_txd_ring(struct s_smc *smc, struct s_smt_tx_queue *queue);\nstatic u_long repair_rxd_ring(struct s_smc *smc, struct s_smt_rx_queue *queue);\nstatic SMbuf* get_llc_rx(struct s_smc *smc);\nstatic SMbuf* get_txd_mb(struct s_smc *smc);\nstatic void mac_drv_clear_txd(struct s_smc *smc);\n\n \n \n\nextern void* mac_drv_get_space(struct s_smc *smc, unsigned int size);\nextern void* mac_drv_get_desc_mem(struct s_smc *smc, unsigned int size);\nextern void mac_drv_fill_rxd(struct s_smc *smc);\nextern void mac_drv_tx_complete(struct s_smc *smc,\n\t\t\t\tvolatile struct s_smt_fp_txd *txd);\nextern void mac_drv_rx_complete(struct s_smc *smc,\n\t\t\t\tvolatile struct s_smt_fp_rxd *rxd,\n\t\t\t\tint frag_count, int len);\nextern void mac_drv_requeue_rxd(struct s_smc *smc, \n\t\t\t\tvolatile struct s_smt_fp_rxd *rxd,\n\t\t\t\tint frag_count);\nextern void mac_drv_clear_rxd(struct s_smc *smc,\n\t\t\t      volatile struct s_smt_fp_rxd *rxd, int frag_count);\n\n#ifdef\tUSE_OS_CPY\nextern void hwm_cpy_rxd2mb(void);\nextern void hwm_cpy_txd2mb(void);\n#endif\n\n#ifdef\tALL_RX_COMPLETE\nextern void mac_drv_all_receives_complete(void);\n#endif\n\nextern u_long mac_drv_virt2phys(struct s_smc *smc, void *virt);\nextern u_long dma_master(struct s_smc *smc, void *virt, int len, int flag);\n\n#ifdef\tNDIS_OS2\nextern void post_proc(void);\n#else\nextern void dma_complete(struct s_smc *smc, volatile union s_fp_descr *descr,\n\t\t\t int flag);\n#endif\n\nextern int mac_drv_rx_init(struct s_smc *smc, int len, int fc, char *look_ahead,\n\t\t\t   int la_len);\n\n \nvoid process_receive(struct s_smc *smc);\nvoid fddi_isr(struct s_smc *smc);\nvoid smt_free_mbuf(struct s_smc *smc, SMbuf *mb);\nvoid init_driver_fplus(struct s_smc *smc);\nvoid mac_drv_rx_mode(struct s_smc *smc, int mode);\nvoid init_fddi_driver(struct s_smc *smc, u_char *mac_addr);\nvoid mac_drv_clear_tx_queue(struct s_smc *smc);\nvoid mac_drv_clear_rx_queue(struct s_smc *smc);\nvoid hwm_tx_frag(struct s_smc *smc, char far *virt, u_long phys, int len,\n\t\t int frame_status);\nvoid hwm_rx_frag(struct s_smc *smc, char far *virt, u_long phys, int len,\n\t\t int frame_status);\n\nint mac_drv_init(struct s_smc *smc);\nint hwm_tx_init(struct s_smc *smc, u_char fc, int frag_count, int frame_len,\n\t\tint frame_status);\n\nu_int mac_drv_check_space(void);\n\nSMbuf* smt_get_mbuf(struct s_smc *smc);\n\n#ifdef DEBUG\n\tvoid mac_drv_debug_lev(struct s_smc *smc, int flag, int lev);\n#endif\n\n \n#ifndef\tUNUSED\n#ifdef\tlint\n#define UNUSED(x)\t(x) = (x)\n#else\n#define UNUSED(x)\n#endif\n#endif\n\n#ifdef\tUSE_CAN_ADDR\n#define MA\t\tsmc->hw.fddi_canon_addr.a\n#define\tGROUP_ADDR_BIT\t0x01\n#else\n#define\tMA\t\tsmc->hw.fddi_home_addr.a\n#define\tGROUP_ADDR_BIT\t0x80\n#endif\n\n#define RXD_TXD_COUNT\t(HWM_ASYNC_TXD_COUNT+HWM_SYNC_TXD_COUNT+\\\n\t\t\tSMT_R1_RXD_COUNT+SMT_R2_RXD_COUNT)\n\n#ifdef\tMB_OUTSIDE_SMC\n#define\tEXT_VIRT_MEM\t((RXD_TXD_COUNT+1)*sizeof(struct s_smt_fp_txd) +\\\n\t\t\tMAX_MBUF*sizeof(SMbuf))\n#define\tEXT_VIRT_MEM_2\t((RXD_TXD_COUNT+1)*sizeof(struct s_smt_fp_txd))\n#else\n#define\tEXT_VIRT_MEM\t((RXD_TXD_COUNT+1)*sizeof(struct s_smt_fp_txd))\n#endif\n\n\t \n#if\tdefined(NDIS_OS2) || defined(ODI2)\n#define CR_READ(var)\t((var) & 0xffff0000 | ((var) & 0xffff))\n#else\n#define CR_READ(var)\t(__le32)(var)\n#endif\n\n#define IMASK_SLOW\t(IS_PLINT1 | IS_PLINT2 | IS_TIMINT | IS_TOKEN | \\\n\t\t\t IS_MINTR1 | IS_MINTR2 | IS_MINTR3 | IS_R1_P | \\\n\t\t\t IS_R1_C | IS_XA_C | IS_XS_C)\n\n \n\n\n \nu_int mac_drv_check_space(void)\n{\n#ifdef\tMB_OUTSIDE_SMC\n#ifdef\tCOMMON_MB_POOL\n\tcall_count++ ;\n\tif (call_count == 1) {\n\t\treturn EXT_VIRT_MEM;\n\t}\n\telse {\n\t\treturn EXT_VIRT_MEM_2;\n\t}\n#else\n\treturn EXT_VIRT_MEM;\n#endif\n#else\n\treturn 0;\n#endif\n}\n\n \nint mac_drv_init(struct s_smc *smc)\n{\n\tif (sizeof(struct s_smt_fp_rxd) % 16) {\n\t\tSMT_PANIC(smc,HWM_E0001,HWM_E0001_MSG) ;\n\t}\n\tif (sizeof(struct s_smt_fp_txd) % 16) {\n\t\tSMT_PANIC(smc,HWM_E0002,HWM_E0002_MSG) ;\n\t}\n\n\t \n\tif (!(smc->os.hwm.descr_p = (union s_fp_descr volatile *)\n\t\tmac_drv_get_desc_mem(smc,(u_int)\n\t\t(RXD_TXD_COUNT+1)*sizeof(struct s_smt_fp_txd)))) {\n\t\treturn 1;\t \n\t}\n\n\t \n#ifndef\tMB_OUTSIDE_SMC\n\tsmc->os.hwm.mbuf_pool.mb_start=(SMbuf *)(&smc->os.hwm.mbuf_pool.mb[0]) ;\n#else\n#ifndef\tCOMMON_MB_POOL\n\tif (!(smc->os.hwm.mbuf_pool.mb_start = (SMbuf *) mac_drv_get_space(smc,\n\t\tMAX_MBUF*sizeof(SMbuf)))) {\n\t\treturn 1;\t \n\t}\n#else\n\tif (!mb_start) {\n\t\tif (!(mb_start = (SMbuf *) mac_drv_get_space(smc,\n\t\t\tMAX_MBUF*sizeof(SMbuf)))) {\n\t\t\treturn 1;\t \n\t\t}\n\t}\n#endif\n#endif\n\treturn 0;\n}\n\n \nvoid init_driver_fplus(struct s_smc *smc)\n{\n\tsmc->hw.fp.mdr2init = FM_LSB | FM_BMMODE | FM_ENNPRQ | FM_ENHSRQ | 3 ;\n\n#ifdef\tPCI\n\tsmc->hw.fp.mdr2init |= FM_CHKPAR | FM_PARITY ;\n#endif\n\tsmc->hw.fp.mdr3init = FM_MENRQAUNLCK | FM_MENRS ;\n\n#ifdef\tUSE_CAN_ADDR\n\t \n\tsmc->hw.fp.frselreg_init = FM_ENXMTADSWAP | FM_ENRCVADSWAP ;\n#endif\n}\n\nstatic u_long init_descr_ring(struct s_smc *smc,\n\t\t\t      union s_fp_descr volatile *start,\n\t\t\t      int count)\n{\n\tint i ;\n\tunion s_fp_descr volatile *d1 ;\n\tunion s_fp_descr volatile *d2 ;\n\tu_long\tphys ;\n\n\tDB_GEN(3, \"descr ring starts at = %p\", start);\n\tfor (i=count-1, d1=start; i ; i--) {\n\t\td2 = d1 ;\n\t\td1++ ;\t\t \n\t\td2->r.rxd_rbctrl = cpu_to_le32(BMU_CHECK) ;\n\t\td2->r.rxd_next = &d1->r ;\n\t\tphys = mac_drv_virt2phys(smc,(void *)d1) ;\n\t\td2->r.rxd_nrdadr = cpu_to_le32(phys) ;\n\t}\n\tDB_GEN(3, \"descr ring ends at = %p\", d1);\n\td1->r.rxd_rbctrl = cpu_to_le32(BMU_CHECK) ;\n\td1->r.rxd_next = &start->r ;\n\tphys = mac_drv_virt2phys(smc,(void *)start) ;\n\td1->r.rxd_nrdadr = cpu_to_le32(phys) ;\n\n\tfor (i=count, d1=start; i ; i--) {\n\t\tDRV_BUF_FLUSH(&d1->r,DDI_DMA_SYNC_FORDEV) ;\n\t\td1++;\n\t}\n\treturn phys;\n}\n\nstatic void init_txd_ring(struct s_smc *smc)\n{\n\tstruct s_smt_fp_txd volatile *ds ;\n\tstruct s_smt_tx_queue *queue ;\n\tu_long\tphys ;\n\n\t \n\tds = (struct s_smt_fp_txd volatile *) ((char *)smc->os.hwm.descr_p +\n\t\tSMT_R1_RXD_COUNT*sizeof(struct s_smt_fp_rxd)) ;\n\tqueue = smc->hw.fp.tx[QUEUE_A0] ;\n\tDB_GEN(3, \"Init async TxD ring, %d TxDs\", HWM_ASYNC_TXD_COUNT);\n\t(void)init_descr_ring(smc,(union s_fp_descr volatile *)ds,\n\t\tHWM_ASYNC_TXD_COUNT) ;\n\tphys = le32_to_cpu(ds->txd_ntdadr) ;\n\tds++ ;\n\tqueue->tx_curr_put = queue->tx_curr_get = ds ;\n\tds-- ;\n\tqueue->tx_free = HWM_ASYNC_TXD_COUNT ;\n\tqueue->tx_used = 0 ;\n\toutpd(ADDR(B5_XA_DA),phys) ;\n\n\tds = (struct s_smt_fp_txd volatile *) ((char *)ds +\n\t\tHWM_ASYNC_TXD_COUNT*sizeof(struct s_smt_fp_txd)) ;\n\tqueue = smc->hw.fp.tx[QUEUE_S] ;\n\tDB_GEN(3, \"Init sync TxD ring, %d TxDs\", HWM_SYNC_TXD_COUNT);\n\t(void)init_descr_ring(smc,(union s_fp_descr volatile *)ds,\n\t\tHWM_SYNC_TXD_COUNT) ;\n\tphys = le32_to_cpu(ds->txd_ntdadr) ;\n\tds++ ;\n\tqueue->tx_curr_put = queue->tx_curr_get = ds ;\n\tqueue->tx_free = HWM_SYNC_TXD_COUNT ;\n\tqueue->tx_used = 0 ;\n\toutpd(ADDR(B5_XS_DA),phys) ;\n}\n\nstatic void init_rxd_ring(struct s_smc *smc)\n{\n\tstruct s_smt_fp_rxd volatile *ds ;\n\tstruct s_smt_rx_queue *queue ;\n\tu_long\tphys ;\n\n\t \n\tds = (struct s_smt_fp_rxd volatile *) smc->os.hwm.descr_p ;\n\tqueue = smc->hw.fp.rx[QUEUE_R1] ;\n\tDB_GEN(3, \"Init RxD ring, %d RxDs\", SMT_R1_RXD_COUNT);\n\t(void)init_descr_ring(smc,(union s_fp_descr volatile *)ds,\n\t\tSMT_R1_RXD_COUNT) ;\n\tphys = le32_to_cpu(ds->rxd_nrdadr) ;\n\tds++ ;\n\tqueue->rx_curr_put = queue->rx_curr_get = ds ;\n\tqueue->rx_free = SMT_R1_RXD_COUNT ;\n\tqueue->rx_used = 0 ;\n\toutpd(ADDR(B4_R1_DA),phys) ;\n}\n\n \nvoid init_fddi_driver(struct s_smc *smc, u_char *mac_addr)\n{\n\tSMbuf\t*mb ;\n\tint\ti ;\n\n\tinit_board(smc,mac_addr) ;\n\t(void)init_fplus(smc) ;\n\n\t \n#ifndef\tCOMMON_MB_POOL\n\tmb = smc->os.hwm.mbuf_pool.mb_start ;\n\tsmc->os.hwm.mbuf_pool.mb_free = (SMbuf *)NULL ;\n\tfor (i = 0; i < MAX_MBUF; i++) {\n\t\tmb->sm_use_count = 1 ;\n\t\tsmt_free_mbuf(smc,mb)\t;\n\t\tmb++ ;\n\t}\n#else\n\tmb = mb_start ;\n\tif (!mb_init) {\n\t\tmb_free = 0 ;\n\t\tfor (i = 0; i < MAX_MBUF; i++) {\n\t\t\tmb->sm_use_count = 1 ;\n\t\t\tsmt_free_mbuf(smc,mb)\t;\n\t\t\tmb++ ;\n\t\t}\n\t\tmb_init = TRUE ;\n\t}\n#endif\n\n\t \n\tsmc->os.hwm.llc_rx_pipe = smc->os.hwm.llc_rx_tail = (SMbuf *)NULL ;\n\tsmc->os.hwm.txd_tx_pipe = smc->os.hwm.txd_tx_tail = NULL ;\n\tsmc->os.hwm.pass_SMT = smc->os.hwm.pass_NSA = smc->os.hwm.pass_DB = 0 ;\n\tsmc->os.hwm.pass_llc_promisc = TRUE ;\n\tsmc->os.hwm.queued_rx_frames = smc->os.hwm.queued_txd_mb = 0 ;\n\tsmc->os.hwm.detec_count = 0 ;\n\tsmc->os.hwm.rx_break = 0 ;\n\tsmc->os.hwm.rx_len_error = 0 ;\n\tsmc->os.hwm.isr_flag = FALSE ;\n\n\t \n\ti = 16 - ((long)smc->os.hwm.descr_p & 0xf) ;\n\tif (i != 16) {\n\t\tDB_GEN(3, \"i = %d\", i);\n\t\tsmc->os.hwm.descr_p = (union s_fp_descr volatile *)\n\t\t\t((char *)smc->os.hwm.descr_p+i) ;\n\t}\n\tDB_GEN(3, \"pt to descr area = %p\", smc->os.hwm.descr_p);\n\n\tinit_txd_ring(smc) ;\n\tinit_rxd_ring(smc) ;\n\tmac_drv_fill_rxd(smc) ;\n\n\tinit_plc(smc) ;\n}\n\n\nSMbuf *smt_get_mbuf(struct s_smc *smc)\n{\n\tregister SMbuf\t*mb ;\n\n#ifndef\tCOMMON_MB_POOL\n\tmb = smc->os.hwm.mbuf_pool.mb_free ;\n#else\n\tmb = mb_free ;\n#endif\n\tif (mb) {\n#ifndef\tCOMMON_MB_POOL\n\t\tsmc->os.hwm.mbuf_pool.mb_free = mb->sm_next ;\n#else\n\t\tmb_free = mb->sm_next ;\n#endif\n\t\tmb->sm_off = 8 ;\n\t\tmb->sm_use_count = 1 ;\n\t}\n\tDB_GEN(3, \"get SMbuf: mb = %p\", mb);\n\treturn mb;\t \n}\n\nvoid smt_free_mbuf(struct s_smc *smc, SMbuf *mb)\n{\n\n\tif (mb) {\n\t\tmb->sm_use_count-- ;\n\t\tDB_GEN(3, \"free_mbuf: sm_use_count = %d\", mb->sm_use_count);\n\t\t \n\t\tif (!mb->sm_use_count) {\n\t\t\tDB_GEN(3, \"free SMbuf: mb = %p\", mb);\n#ifndef\tCOMMON_MB_POOL\n\t\t\tmb->sm_next = smc->os.hwm.mbuf_pool.mb_free ;\n\t\t\tsmc->os.hwm.mbuf_pool.mb_free = mb ;\n#else\n\t\t\tmb->sm_next = mb_free ;\n\t\t\tmb_free = mb ;\n#endif\n\t\t}\n\t}\n\telse\n\t\tSMT_PANIC(smc,HWM_E0003,HWM_E0003_MSG) ;\n}\n\n\n \nvoid mac_drv_repair_descr(struct s_smc *smc)\n{\n\tu_long\tphys ;\n\n\tif (smc->hw.hw_state != STOPPED) {\n\t\tSK_BREAK() ;\n\t\tSMT_PANIC(smc,HWM_E0013,HWM_E0013_MSG) ;\n\t\treturn ;\n\t}\n\n\t \n\tphys = repair_txd_ring(smc,smc->hw.fp.tx[QUEUE_A0]) ;\n\toutpd(ADDR(B5_XA_DA),phys) ;\n\tif (smc->hw.fp.tx_q[QUEUE_A0].tx_used) {\n\t\toutpd(ADDR(B0_XA_CSR),CSR_START) ;\n\t}\n\tphys = repair_txd_ring(smc,smc->hw.fp.tx[QUEUE_S]) ;\n\toutpd(ADDR(B5_XS_DA),phys) ;\n\tif (smc->hw.fp.tx_q[QUEUE_S].tx_used) {\n\t\toutpd(ADDR(B0_XS_CSR),CSR_START) ;\n\t}\n\n\t \n\tphys = repair_rxd_ring(smc,smc->hw.fp.rx[QUEUE_R1]) ;\n\toutpd(ADDR(B4_R1_DA),phys) ;\n\toutpd(ADDR(B0_R1_CSR),CSR_START) ;\n}\n\nstatic u_long repair_txd_ring(struct s_smc *smc, struct s_smt_tx_queue *queue)\n{\n\tint i ;\n\tint tx_used ;\n\tu_long phys ;\n\tu_long tbctrl ;\n\tstruct s_smt_fp_txd volatile *t ;\n\n\tSK_UNUSED(smc) ;\n\n\tt = queue->tx_curr_get ;\n\ttx_used = queue->tx_used ;\n\tfor (i = tx_used+queue->tx_free-1 ; i ; i-- ) {\n\t\tt = t->txd_next ;\n\t}\n\tphys = le32_to_cpu(t->txd_ntdadr) ;\n\n\tt = queue->tx_curr_get ;\n\twhile (tx_used) {\n\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORCPU) ;\n\t\ttbctrl = le32_to_cpu(t->txd_tbctrl) ;\n\n\t\tif (tbctrl & BMU_OWN) {\n\t\t\tif (tbctrl & BMU_STF) {\n\t\t\t\tbreak ;\t\t \n\t\t\t}\n\t\t\telse {\n\t\t\t\t \n\t\t\t\tt->txd_tbctrl &= ~cpu_to_le32(BMU_OWN) ;\n\t\t\t}\n\t\t}\n\t\tphys = le32_to_cpu(t->txd_ntdadr) ;\n\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\n\t\tt = t->txd_next ;\n\t\ttx_used-- ;\n\t}\n\treturn phys;\n}\n\n \nstatic u_long repair_rxd_ring(struct s_smc *smc, struct s_smt_rx_queue *queue)\n{\n\tint i ;\n\tint rx_used ;\n\tu_long phys ;\n\tu_long rbctrl ;\n\tstruct s_smt_fp_rxd volatile *r ;\n\n\tSK_UNUSED(smc) ;\n\n\tr = queue->rx_curr_get ;\n\trx_used = queue->rx_used ;\n\tfor (i = SMT_R1_RXD_COUNT-1 ; i ; i-- ) {\n\t\tr = r->rxd_next ;\n\t}\n\tphys = le32_to_cpu(r->rxd_nrdadr) ;\n\n\tr = queue->rx_curr_get ;\n\twhile (rx_used) {\n\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\n\t\trbctrl = le32_to_cpu(r->rxd_rbctrl) ;\n\n\t\tif (rbctrl & BMU_OWN) {\n\t\t\tif (rbctrl & BMU_STF) {\n\t\t\t\tbreak ;\t\t \n\t\t\t}\n\t\t\telse {\n\t\t\t\t \n\t\t\t\tr->rxd_rbctrl &= ~cpu_to_le32(BMU_OWN) ;\n\t\t\t}\n\t\t}\n\t\tphys = le32_to_cpu(r->rxd_nrdadr) ;\n\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\n\t\tr = r->rxd_next ;\n\t\trx_used-- ;\n\t}\n\treturn phys;\n}\n\n\n \n\n \nvoid fddi_isr(struct s_smc *smc)\n{\n\tu_long\t\tis ;\t\t \n\tu_short\t\tstu, stl ;\n\tSMbuf\t\t*mb ;\n\n#ifdef\tUSE_BREAK_ISR\n\tint\tforce_irq ;\n#endif\n\n#ifdef\tODI2\n\tif (smc->os.hwm.rx_break) {\n\t\tmac_drv_fill_rxd(smc) ;\n\t\tif (smc->hw.fp.rx_q[QUEUE_R1].rx_used > 0) {\n\t\t\tsmc->os.hwm.rx_break = 0 ;\n\t\t\tprocess_receive(smc) ;\n\t\t}\n\t\telse {\n\t\t\tsmc->os.hwm.detec_count = 0 ;\n\t\t\tsmt_force_irq(smc) ;\n\t\t}\n\t}\n#endif\n\tsmc->os.hwm.isr_flag = TRUE ;\n\n#ifdef\tUSE_BREAK_ISR\n\tforce_irq = TRUE ;\n\tif (smc->os.hwm.leave_isr) {\n\t\tsmc->os.hwm.leave_isr = FALSE ;\n\t\tprocess_receive(smc) ;\n\t}\n#endif\n\n\twhile ((is = GET_ISR() & ISR_MASK)) {\n\t\tNDD_TRACE(\"CH0B\",is,0,0) ;\n\t\tDB_GEN(7, \"ISA = 0x%lx\", is);\n\n\t\tif (is & IMASK_SLOW) {\n\t\t\tNDD_TRACE(\"CH1b\",is,0,0) ;\n\t\t\tif (is & IS_PLINT1) {\t \n\t\t\t\tplc1_irq(smc) ;\n\t\t\t}\n\t\t\tif (is & IS_PLINT2) {\t \n\t\t\t\tplc2_irq(smc) ;\n\t\t\t}\n\t\t\tif (is & IS_MINTR1) {\t \n\t\t\t\tstu = inpw(FM_A(FM_ST1U)) ;\n\t\t\t\tstl = inpw(FM_A(FM_ST1L)) ;\n\t\t\t\tDB_GEN(6, \"Slow transmit complete\");\n\t\t\t\tmac1_irq(smc,stu,stl) ;\n\t\t\t}\n\t\t\tif (is & IS_MINTR2) {\t \n\t\t\t\tstu= inpw(FM_A(FM_ST2U)) ;\n\t\t\t\tstl= inpw(FM_A(FM_ST2L)) ;\n\t\t\t\tDB_GEN(6, \"Slow receive complete\");\n\t\t\t\tDB_GEN(7, \"stl = %x : stu = %x\", stl, stu);\n\t\t\t\tmac2_irq(smc,stu,stl) ;\n\t\t\t}\n\t\t\tif (is & IS_MINTR3) {\t \n\t\t\t\tstu= inpw(FM_A(FM_ST3U)) ;\n\t\t\t\tstl= inpw(FM_A(FM_ST3L)) ;\n\t\t\t\tDB_GEN(6, \"FORMAC Mode Register 3\");\n\t\t\t\tmac3_irq(smc,stu,stl) ;\n\t\t\t}\n\t\t\tif (is & IS_TIMINT) {\t \n\t\t\t\ttimer_irq(smc) ;\n#ifdef\tNDIS_OS2\n\t\t\t\tforce_irq_pending = 0 ;\n#endif\n\t\t\t\t \n\t\t\t\tif (++smc->os.hwm.detec_count > 4) {\n\t\t\t\t\t \n\t\t\t\t\t process_receive(smc) ;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (is & IS_TOKEN) {\t \n\t\t\t\trtm_irq(smc) ;\n\t\t\t}\n\t\t\tif (is & IS_R1_P) {\t \n\t\t\t\t \n\t\t\t\toutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_P) ;\n\t\t\t\tSMT_PANIC(smc,HWM_E0004,HWM_E0004_MSG) ;\n\t\t\t}\n\t\t\tif (is & IS_R1_C) {\t \n\t\t\t\t \n\t\t\t\toutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_C) ;\n\t\t\t\tSMT_PANIC(smc,HWM_E0005,HWM_E0005_MSG) ;\n\t\t\t}\n\t\t\tif (is & IS_XA_C) {\t \n\t\t\t\t \n\t\t\t\toutpd(ADDR(B5_XA_CSR),CSR_IRQ_CL_C) ;\n\t\t\t\tSMT_PANIC(smc,HWM_E0006,HWM_E0006_MSG) ;\n\t\t\t}\n\t\t\tif (is & IS_XS_C) {\t \n\t\t\t\t \n\t\t\t\toutpd(ADDR(B5_XS_CSR),CSR_IRQ_CL_C) ;\n\t\t\t\tSMT_PANIC(smc,HWM_E0007,HWM_E0007_MSG) ;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (is & (IS_XS_F|IS_XA_F)) {\n\t\t\tDB_GEN(6, \"Fast tx complete queue\");\n\t\t\t \n\t\t\toutpd(ADDR(B5_XS_CSR),CSR_IRQ_CL_F) ;\n\t\t\toutpd(ADDR(B5_XA_CSR),CSR_IRQ_CL_F) ;\n\t\t\tmac_drv_clear_txd(smc) ;\n\t\t\tllc_restart_tx(smc) ;\n\t\t}\n\n\t\t \n\t\tif (is & IS_R1_F) {\n\t\t\tDB_GEN(6, \"Fast receive complete\");\n\t\t\t \n#ifndef USE_BREAK_ISR\n\t\t\toutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_F) ;\n\t\t\tprocess_receive(smc) ;\n#else\n\t\t\tprocess_receive(smc) ;\n\t\t\tif (smc->os.hwm.leave_isr) {\n\t\t\t\tforce_irq = FALSE ;\n\t\t\t} else {\n\t\t\t\toutpd(ADDR(B4_R1_CSR),CSR_IRQ_CL_F) ;\n\t\t\t\tprocess_receive(smc) ;\n\t\t\t}\n#endif\n\t\t}\n\n#ifndef\tNDIS_OS2\n\t\twhile ((mb = get_llc_rx(smc))) {\n\t\t\tsmt_to_llc(smc,mb) ;\n\t\t}\n#else\n\t\tif (offDepth)\n\t\t\tpost_proc() ;\n\n\t\twhile (!offDepth && (mb = get_llc_rx(smc))) {\n\t\t\tsmt_to_llc(smc,mb) ;\n\t\t}\n\n\t\tif (!offDepth && smc->os.hwm.rx_break) {\n\t\t\tprocess_receive(smc) ;\n\t\t}\n#endif\n\t\tif (smc->q.ev_get != smc->q.ev_put) {\n\t\t\tNDD_TRACE(\"CH2a\",0,0,0) ;\n\t\t\tev_dispatcher(smc) ;\n\t\t}\n#ifdef\tNDIS_OS2\n\t\tpost_proc() ;\n\t\tif (offDepth) {\t\t \n\t\t\tbreak ;\t\t \n\t\t}\n#endif\n#ifdef\tUSE_BREAK_ISR\n\t\tif (smc->os.hwm.leave_isr) {\n\t\t\tbreak ;\t\t \n\t\t}\n#endif\n\n\t\t \n\t}\t \n\n#ifdef\tUSE_BREAK_ISR\n\tif (smc->os.hwm.leave_isr && force_irq) {\n\t\tsmt_force_irq(smc) ;\n\t}\n#endif\n\tsmc->os.hwm.isr_flag = FALSE ;\n\tNDD_TRACE(\"CH0E\",0,0,0) ;\n}\n\n\n \n\n#ifndef\tNDIS_OS2\n \nvoid mac_drv_rx_mode(struct s_smc *smc, int mode)\n{\n\tswitch(mode) {\n\tcase RX_ENABLE_PASS_SMT:\n\t\tsmc->os.hwm.pass_SMT = TRUE ;\n\t\tbreak ;\n\tcase RX_DISABLE_PASS_SMT:\n\t\tsmc->os.hwm.pass_SMT = FALSE ;\n\t\tbreak ;\n\tcase RX_ENABLE_PASS_NSA:\n\t\tsmc->os.hwm.pass_NSA = TRUE ;\n\t\tbreak ;\n\tcase RX_DISABLE_PASS_NSA:\n\t\tsmc->os.hwm.pass_NSA = FALSE ;\n\t\tbreak ;\n\tcase RX_ENABLE_PASS_DB:\n\t\tsmc->os.hwm.pass_DB = TRUE ;\n\t\tbreak ;\n\tcase RX_DISABLE_PASS_DB:\n\t\tsmc->os.hwm.pass_DB = FALSE ;\n\t\tbreak ;\n\tcase RX_DISABLE_PASS_ALL:\n\t\tsmc->os.hwm.pass_SMT = smc->os.hwm.pass_NSA = FALSE ;\n\t\tsmc->os.hwm.pass_DB = FALSE ;\n\t\tsmc->os.hwm.pass_llc_promisc = TRUE ;\n\t\tmac_set_rx_mode(smc,RX_DISABLE_NSA) ;\n\t\tbreak ;\n\tcase RX_DISABLE_LLC_PROMISC:\n\t\tsmc->os.hwm.pass_llc_promisc = FALSE ;\n\t\tbreak ;\n\tcase RX_ENABLE_LLC_PROMISC:\n\t\tsmc->os.hwm.pass_llc_promisc = TRUE ;\n\t\tbreak ;\n\tcase RX_ENABLE_ALLMULTI:\n\tcase RX_DISABLE_ALLMULTI:\n\tcase RX_ENABLE_PROMISC:\n\tcase RX_DISABLE_PROMISC:\n\tcase RX_ENABLE_NSA:\n\tcase RX_DISABLE_NSA:\n\tdefault:\n\t\tmac_set_rx_mode(smc,mode) ;\n\t\tbreak ;\n\t}\n}\n#endif\t \n\n \nvoid process_receive(struct s_smc *smc)\n{\n\tint i ;\n\tint n ;\n\tint frag_count ;\t\t \n\tint used_frags ;\t\t \n\tstruct s_smt_rx_queue *queue ;\t \n\tstruct s_smt_fp_rxd volatile *r ;\t \n\tstruct s_smt_fp_rxd volatile *rxd ;\t \n\tu_long rbctrl ;\t\t\t \n\tu_long rfsw ;\t\t\t \n\tu_short rx_used ;\n\tu_char far *virt ;\n\tchar far *data ;\n\tSMbuf *mb ;\n\tu_char fc ;\t\t\t \n\tint len ;\t\t\t \n\n\tsmc->os.hwm.detec_count = 0 ;\n\tqueue = smc->hw.fp.rx[QUEUE_R1] ;\n\tNDD_TRACE(\"RHxB\",0,0,0) ;\n\tfor ( ; ; ) {\n\t\tr = queue->rx_curr_get ;\n\t\trx_used = queue->rx_used ;\n\t\tfrag_count = 0 ;\n\n#ifdef\tUSE_BREAK_ISR\n\t\tif (smc->os.hwm.leave_isr) {\n\t\t\tgoto rx_end ;\n\t\t}\n#endif\n#ifdef\tNDIS_OS2\n\t\tif (offDepth) {\n\t\t\tsmc->os.hwm.rx_break = 1 ;\n\t\t\tgoto rx_end ;\n\t\t}\n\t\tsmc->os.hwm.rx_break = 0 ;\n#endif\n#ifdef\tODI2\n\t\tif (smc->os.hwm.rx_break) {\n\t\t\tgoto rx_end ;\n\t\t}\n#endif\n\t\tn = 0 ;\n\t\tdo {\n\t\t\tDB_RX(5, \"Check RxD %p for OWN and EOF\", r);\n\t\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\n\t\t\trbctrl = le32_to_cpu(CR_READ(r->rxd_rbctrl));\n\n\t\t\tif (rbctrl & BMU_OWN) {\n\t\t\t\tNDD_TRACE(\"RHxE\",r,rfsw,rbctrl) ;\n\t\t\t\tDB_RX(4, \"End of RxDs\");\n\t\t\t\tgoto rx_end ;\n\t\t\t}\n\t\t\t \n\t\t\tif (!rx_used) {\n\t\t\t\tSK_BREAK() ;\n\t\t\t\tSMT_PANIC(smc,HWM_E0009,HWM_E0009_MSG) ;\n\t\t\t\t \n\t\t\t\tsmc->hw.hw_state = STOPPED ;\n\t\t\t\tmac_drv_clear_rx_queue(smc) ;\n\t\t\t\tsmc->hw.hw_state = STARTED ;\n\t\t\t\tmac_drv_fill_rxd(smc) ;\n\t\t\t\tsmc->os.hwm.detec_count = 0 ;\n\t\t\t\tgoto rx_end ;\n\t\t\t}\n\t\t\trfsw = le32_to_cpu(r->rxd_rfsw) ;\n\t\t\tif ((rbctrl & BMU_STF) != ((rbctrl & BMU_ST_BUF) <<5)) {\n\t\t\t\t \n\t\t\t\tSK_BREAK() ;\n\t\t\t\trfsw = 0 ;\n\t\t\t\tif (frag_count) {\n\t\t\t\t\tbreak ;\n\t\t\t\t}\n\t\t\t}\n\t\t\tn += rbctrl & 0xffff ;\n\t\t\tr = r->rxd_next ;\n\t\t\tfrag_count++ ;\n\t\t\trx_used-- ;\n\t\t} while (!(rbctrl & BMU_EOF)) ;\n\t\tused_frags = frag_count ;\n\t\tDB_RX(5, \"EOF set in RxD, used_frags = %d\", used_frags);\n\n\t\t \n\t\t \n\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\n\t\twhile (rx_used && !(r->rxd_rbctrl & cpu_to_le32(BMU_ST_BUF))) {\n\t\t\tDB_RX(5, \"Check STF bit in %p\", r);\n\t\t\tr = r->rxd_next ;\n\t\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\n\t\t\tfrag_count++ ;\n\t\t\trx_used-- ;\n\t\t}\n\t\tDB_RX(5, \"STF bit found\");\n\n\t\t \n\t\trxd = queue->rx_curr_get ;\n\t\tqueue->rx_curr_get = r ;\n\t\tqueue->rx_free += frag_count ;\n\t\tqueue->rx_used = rx_used ;\n\n\t\t \n\t\trxd->rxd_rbctrl &= cpu_to_le32(~BMU_STF) ;\n\n\t\tfor (r=rxd, i=frag_count ; i ; r=r->rxd_next, i--){\n\t\t\tDB_RX(5, \"dma_complete for RxD %p\", r);\n\t\t\tdma_complete(smc,(union s_fp_descr volatile *)r,DMA_WR);\n\t\t}\n\t\tsmc->hw.fp.err_stats.err_valid++ ;\n\t\tsmc->mib.m[MAC0].fddiMACCopied_Ct++ ;\n\n\t\t \n\t\tlen = (rfsw & RD_LENGTH) - 4 ;\n\n\t\tDB_RX(4, \"frame length = %d\", len);\n\t\t \n\t\tif (rfsw & (RX_MSRABT|RX_FS_E|RX_FS_CRC|RX_FS_IMPL)){\n\t\t\tif (rfsw & RD_S_MSRABT) {\n\t\t\t\tDB_RX(2, \"Frame aborted by the FORMAC\");\n\t\t\t\tsmc->hw.fp.err_stats.err_abort++ ;\n\t\t\t}\n\t\t\t \n\t\t\tif (rfsw & RD_S_SEAC2) {\n\t\t\t\tDB_RX(2, \"E-Indicator set\");\n\t\t\t\tsmc->hw.fp.err_stats.err_e_indicator++ ;\n\t\t\t}\n\t\t\tif (rfsw & RD_S_SFRMERR) {\n\t\t\t\tDB_RX(2, \"CRC error\");\n\t\t\t\tsmc->hw.fp.err_stats.err_crc++ ;\n\t\t\t}\n\t\t\tif (rfsw & RX_FS_IMPL) {\n\t\t\t\tDB_RX(2, \"Implementer frame\");\n\t\t\t\tsmc->hw.fp.err_stats.err_imp_frame++ ;\n\t\t\t}\n\t\t\tgoto abort_frame ;\n\t\t}\n\t\tif (len > FDDI_RAW_MTU-4) {\n\t\t\tDB_RX(2, \"Frame too long error\");\n\t\t\tsmc->hw.fp.err_stats.err_too_long++ ;\n\t\t\tgoto abort_frame ;\n\t\t}\n\t\t \n\t\tif (len <= 4) {\n\t\t\tDB_RX(2, \"Frame length = 0\");\n\t\t\tgoto abort_frame ;\n\t\t}\n\n\t\tif (len != (n-4)) {\n\t\t\tDB_RX(4, \"BMU: rx len differs: [%d:%d]\", len, n);\n\t\t\tsmc->os.hwm.rx_len_error++ ;\n\t\t\tgoto abort_frame ;\n\t\t}\n\n\t\t \n\t\tvirt = (u_char far *) rxd->rxd_virt ;\n\t\tDB_RX(2, \"FC = %x\", *virt);\n\t\tif (virt[12] == MA[5] &&\n\t\t    virt[11] == MA[4] &&\n\t\t    virt[10] == MA[3] &&\n\t\t    virt[9] == MA[2] &&\n\t\t    virt[8] == MA[1] &&\n\t\t    (virt[7] & ~GROUP_ADDR_BIT) == MA[0]) {\n\t\t\tgoto abort_frame ;\n\t\t}\n\n\t\t \n\t\tif (rfsw & RX_FS_LLC) {\n\t\t\t \n\t\t\tif (!smc->os.hwm.pass_llc_promisc) {\n\t\t\t\tif(!(virt[1] & GROUP_ADDR_BIT)) {\n\t\t\t\t\tif (virt[6] != MA[5] ||\n\t\t\t\t\t    virt[5] != MA[4] ||\n\t\t\t\t\t    virt[4] != MA[3] ||\n\t\t\t\t\t    virt[3] != MA[2] ||\n\t\t\t\t\t    virt[2] != MA[1] ||\n\t\t\t\t\t    virt[1] != MA[0]) {\n\t\t\t\t\t\tDB_RX(2, \"DA != MA and not multi- or broadcast\");\n\t\t\t\t\t\tgoto abort_frame ;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t \n\t\t\tDB_RX(4, \"LLC - receive\");\n\t\t\tmac_drv_rx_complete(smc,rxd,frag_count,len) ;\n\t\t}\n\t\telse {\n\t\t\tif (!(mb = smt_get_mbuf(smc))) {\n\t\t\t\tsmc->hw.fp.err_stats.err_no_buf++ ;\n\t\t\t\tDB_RX(4, \"No SMbuf; receive terminated\");\n\t\t\t\tgoto abort_frame ;\n\t\t\t}\n\t\t\tdata = smtod(mb,char *) - 1 ;\n\n\t\t\t \n#ifdef USE_OS_CPY\n\t\t\thwm_cpy_rxd2mb(rxd,data,len) ;\n#else\n\t\t\tfor (r=rxd, i=used_frags ; i ; r=r->rxd_next, i--){\n\t\t\t\tn = le32_to_cpu(r->rxd_rbctrl) & RD_LENGTH ;\n\t\t\t\tDB_RX(6, \"cp SMT frame to mb: len = %d\", n);\n\t\t\t\tmemcpy(data,r->rxd_virt,n) ;\n\t\t\t\tdata += n ;\n\t\t\t}\n\t\t\tdata = smtod(mb,char *) - 1 ;\n#endif\n\t\t\tfc = *(char *)mb->sm_data = *data ;\n\t\t\tmb->sm_len = len - 1 ;\t\t \n\t\t\tdata++ ;\n\n\t\t\t \n\t\t\tswitch(fc) {\n\t\t\tcase FC_SMT_INFO :\n\t\t\t\tsmc->hw.fp.err_stats.err_smt_frame++ ;\n\t\t\t\tDB_RX(5, \"SMT frame received\");\n\n\t\t\t\tif (smc->os.hwm.pass_SMT) {\n\t\t\t\t\tDB_RX(5, \"pass SMT frame\");\n\t\t\t\t\tmac_drv_rx_complete(smc, rxd,\n\t\t\t\t\t\tfrag_count,len) ;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tDB_RX(5, \"requeue RxD\");\n\t\t\t\t\tmac_drv_requeue_rxd(smc,rxd,frag_count);\n\t\t\t\t}\n\n\t\t\t\tsmt_received_pack(smc,mb,(int)(rfsw>>25)) ;\n\t\t\t\tbreak ;\n\t\t\tcase FC_SMT_NSA :\n\t\t\t\tsmc->hw.fp.err_stats.err_smt_frame++ ;\n\t\t\t\tDB_RX(5, \"SMT frame received\");\n\n\t\t\t\t \n\t\t\t\t \n\t\t\t\t \n\t\t\t\tif (smc->os.hwm.pass_NSA ||\n\t\t\t\t\t(smc->os.hwm.pass_SMT &&\n\t\t\t\t\t!(rfsw & A_INDIC))) {\n\t\t\t\t\tDB_RX(5, \"pass SMT frame\");\n\t\t\t\t\tmac_drv_rx_complete(smc, rxd,\n\t\t\t\t\t\tfrag_count,len) ;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tDB_RX(5, \"requeue RxD\");\n\t\t\t\t\tmac_drv_requeue_rxd(smc,rxd,frag_count);\n\t\t\t\t}\n\n\t\t\t\tsmt_received_pack(smc,mb,(int)(rfsw>>25)) ;\n\t\t\t\tbreak ;\n\t\t\tcase FC_BEACON :\n\t\t\t\tif (smc->os.hwm.pass_DB) {\n\t\t\t\t\tDB_RX(5, \"pass DB frame\");\n\t\t\t\t\tmac_drv_rx_complete(smc, rxd,\n\t\t\t\t\t\tfrag_count,len) ;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tDB_RX(5, \"requeue RxD\");\n\t\t\t\t\tmac_drv_requeue_rxd(smc,rxd,frag_count);\n\t\t\t\t}\n\t\t\t\tsmt_free_mbuf(smc,mb) ;\n\t\t\t\tbreak ;\n\t\t\tdefault :\n\t\t\t\t \n\t\t\t\tDB_RX(2, \"unknown FC error\");\n\t\t\t\tsmt_free_mbuf(smc,mb) ;\n\t\t\t\tDB_RX(5, \"requeue RxD\");\n\t\t\t\tmac_drv_requeue_rxd(smc,rxd,frag_count) ;\n\t\t\t\tif ((fc & 0xf0) == FC_MAC)\n\t\t\t\t\tsmc->hw.fp.err_stats.err_mac_frame++ ;\n\t\t\t\telse\n\t\t\t\t\tsmc->hw.fp.err_stats.err_imp_frame++ ;\n\n\t\t\t\tbreak ;\n\t\t\t}\n\t\t}\n\n\t\tDB_RX(3, \"next RxD is %p\", queue->rx_curr_get);\n\t\tNDD_TRACE(\"RHx1\",queue->rx_curr_get,0,0) ;\n\n\t\tcontinue ;\n\t \nabort_frame:\n\t\tDB_RX(5, \"requeue RxD\");\n\t\tmac_drv_requeue_rxd(smc,rxd,frag_count) ;\n\n\t\tDB_RX(3, \"next RxD is %p\", queue->rx_curr_get);\n\t\tNDD_TRACE(\"RHx2\",queue->rx_curr_get,0,0) ;\n\t}\nrx_end:\n#ifdef\tALL_RX_COMPLETE\n\tmac_drv_all_receives_complete(smc) ;\n#endif\n\treturn ;\t \n}\n\nstatic void smt_to_llc(struct s_smc *smc, SMbuf *mb)\n{\n\tu_char\tfc ;\n\n\tDB_RX(4, \"send a queued frame to the llc layer\");\n\tsmc->os.hwm.r.len = mb->sm_len ;\n\tsmc->os.hwm.r.mb_pos = smtod(mb,char *) ;\n\tfc = *smc->os.hwm.r.mb_pos ;\n\t(void)mac_drv_rx_init(smc,(int)mb->sm_len,(int)fc,\n\t\tsmc->os.hwm.r.mb_pos,(int)mb->sm_len) ;\n\tsmt_free_mbuf(smc,mb) ;\n}\n\n \nvoid hwm_rx_frag(struct s_smc *smc, char far *virt, u_long phys, int len,\n\t\t int frame_status)\n{\n\tstruct s_smt_fp_rxd volatile *r ;\n\t__le32\trbctrl;\n\n\tNDD_TRACE(\"RHfB\",virt,len,frame_status) ;\n\tDB_RX(2, \"hwm_rx_frag: len = %d, frame_status = %x\", len, frame_status);\n\tr = smc->hw.fp.rx_q[QUEUE_R1].rx_curr_put ;\n\tr->rxd_virt = virt ;\n\tr->rxd_rbadr = cpu_to_le32(phys) ;\n\trbctrl = cpu_to_le32( (((__u32)frame_status &\n\t\t(FIRST_FRAG|LAST_FRAG))<<26) |\n\t\t(((u_long) frame_status & FIRST_FRAG) << 21) |\n\t\tBMU_OWN | BMU_CHECK | BMU_EN_IRQ_EOF | len) ;\n\tr->rxd_rbctrl = rbctrl ;\n\n\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\n\toutpd(ADDR(B0_R1_CSR),CSR_START) ;\n\tsmc->hw.fp.rx_q[QUEUE_R1].rx_free-- ;\n\tsmc->hw.fp.rx_q[QUEUE_R1].rx_used++ ;\n\tsmc->hw.fp.rx_q[QUEUE_R1].rx_curr_put = r->rxd_next ;\n\tNDD_TRACE(\"RHfE\",r,le32_to_cpu(r->rxd_rbadr),0) ;\n}\n\n \nvoid mac_drv_clear_rx_queue(struct s_smc *smc)\n{\n\tstruct s_smt_fp_rxd volatile *r ;\n\tstruct s_smt_fp_rxd volatile *next_rxd ;\n\tstruct s_smt_rx_queue *queue ;\n\tint frag_count ;\n\tint i ;\n\n\tif (smc->hw.hw_state != STOPPED) {\n\t\tSK_BREAK() ;\n\t\tSMT_PANIC(smc,HWM_E0012,HWM_E0012_MSG) ;\n\t\treturn ;\n\t}\n\n\tqueue = smc->hw.fp.rx[QUEUE_R1] ;\n\tDB_RX(5, \"clear_rx_queue\");\n\n\t \n\tr = queue->rx_curr_get ;\n\twhile (queue->rx_used) {\n\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\n\t\tDB_RX(5, \"switch OWN bit of RxD 0x%p\", r);\n\t\tr->rxd_rbctrl &= ~cpu_to_le32(BMU_OWN) ;\n\t\tfrag_count = 1 ;\n\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\n\t\tr = r->rxd_next ;\n\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\n\t\twhile (r != queue->rx_curr_put &&\n\t\t\t!(r->rxd_rbctrl & cpu_to_le32(BMU_ST_BUF))) {\n\t\t\tDB_RX(5, \"Check STF bit in %p\", r);\n\t\t\tr->rxd_rbctrl &= ~cpu_to_le32(BMU_OWN) ;\n\t\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORDEV) ;\n\t\t\tr = r->rxd_next ;\n\t\t\tDRV_BUF_FLUSH(r,DDI_DMA_SYNC_FORCPU) ;\n\t\t\tfrag_count++ ;\n\t\t}\n\t\tDB_RX(5, \"STF bit found\");\n\t\tnext_rxd = r ;\n\n\t\tfor (r=queue->rx_curr_get,i=frag_count; i ; r=r->rxd_next,i--){\n\t\t\tDB_RX(5, \"dma_complete for RxD %p\", r);\n\t\t\tdma_complete(smc,(union s_fp_descr volatile *)r,DMA_WR);\n\t\t}\n\n\t\tDB_RX(5, \"mac_drv_clear_rxd: RxD %p frag_count %d\",\n\t\t      queue->rx_curr_get, frag_count);\n\t\tmac_drv_clear_rxd(smc,queue->rx_curr_get,frag_count) ;\n\n\t\tqueue->rx_curr_get = next_rxd ;\n\t\tqueue->rx_used -= frag_count ;\n\t\tqueue->rx_free += frag_count ;\n\t}\n}\n\n\n \n\n \nint hwm_tx_init(struct s_smc *smc, u_char fc, int frag_count, int frame_len,\n\t\tint frame_status)\n{\n\tNDD_TRACE(\"THiB\",fc,frag_count,frame_len) ;\n\tsmc->os.hwm.tx_p = smc->hw.fp.tx[frame_status & QUEUE_A0] ;\n\tsmc->os.hwm.tx_descr = TX_DESCRIPTOR | (((u_long)(frame_len-1)&3)<<27) ;\n\tsmc->os.hwm.tx_len = frame_len ;\n\tDB_TX(3, \"hwm_tx_init: fc = %x, len = %d\", fc, frame_len);\n\tif ((fc & ~(FC_SYNC_BIT|FC_LLC_PRIOR)) == FC_ASYNC_LLC) {\n\t\tframe_status |= LAN_TX ;\n\t}\n\telse {\n\t\tswitch (fc) {\n\t\tcase FC_SMT_INFO :\n\t\tcase FC_SMT_NSA :\n\t\t\tframe_status |= LAN_TX ;\n\t\t\tbreak ;\n\t\tcase FC_SMT_LOC :\n\t\t\tframe_status |= LOC_TX ;\n\t\t\tbreak ;\n\t\tcase FC_SMT_LAN_LOC :\n\t\t\tframe_status |= LAN_TX | LOC_TX ;\n\t\t\tbreak ;\n\t\tdefault :\n\t\t\tSMT_PANIC(smc,HWM_E0010,HWM_E0010_MSG) ;\n\t\t}\n\t}\n\tif (!smc->hw.mac_ring_is_up) {\n\t\tframe_status &= ~LAN_TX ;\n\t\tframe_status |= RING_DOWN ;\n\t\tDB_TX(2, \"Ring is down: terminate LAN_TX\");\n\t}\n\tif (frag_count > smc->os.hwm.tx_p->tx_free) {\n#ifndef\tNDIS_OS2\n\t\tmac_drv_clear_txd(smc) ;\n\t\tif (frag_count > smc->os.hwm.tx_p->tx_free) {\n\t\t\tDB_TX(2, \"Out of TxDs, terminate LAN_TX\");\n\t\t\tframe_status &= ~LAN_TX ;\n\t\t\tframe_status |= OUT_OF_TXD ;\n\t\t}\n#else\n\t\tDB_TX(2, \"Out of TxDs, terminate LAN_TX\");\n\t\tframe_status &= ~LAN_TX ;\n\t\tframe_status |= OUT_OF_TXD ;\n#endif\n\t}\n\tDB_TX(3, \"frame_status = %x\", frame_status);\n\tNDD_TRACE(\"THiE\",frame_status,smc->os.hwm.tx_p->tx_free,0) ;\n\treturn frame_status;\n}\n\n \nvoid hwm_tx_frag(struct s_smc *smc, char far *virt, u_long phys, int len,\n\t\t int frame_status)\n{\n\tstruct s_smt_fp_txd volatile *t ;\n\tstruct s_smt_tx_queue *queue ;\n\t__le32\ttbctrl ;\n\n\tqueue = smc->os.hwm.tx_p ;\n\n\tNDD_TRACE(\"THfB\",virt,len,frame_status) ;\n\t \n\tt = queue->tx_curr_put ;\n\n\tDB_TX(2, \"hwm_tx_frag: len = %d, frame_status = %x\", len, frame_status);\n\tif (frame_status & LAN_TX) {\n\t\t \n\t\tDB_TX(3, \"LAN_TX: TxD = %p, virt = %p\", t, virt);\n\t\tt->txd_virt = virt ;\n\t\tt->txd_txdscr = cpu_to_le32(smc->os.hwm.tx_descr) ;\n\t\tt->txd_tbadr = cpu_to_le32(phys) ;\n\t\ttbctrl = cpu_to_le32((((__u32)frame_status &\n\t\t\t(FIRST_FRAG|LAST_FRAG|EN_IRQ_EOF))<< 26) |\n\t\t\tBMU_OWN|BMU_CHECK |len) ;\n\t\tt->txd_tbctrl = tbctrl ;\n\n#ifndef\tAIX\n\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\n\t\toutpd(queue->tx_bmu_ctl,CSR_START) ;\n#else\t \n\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\n\t\tif (frame_status & QUEUE_A0) {\n\t\t\toutpd(ADDR(B0_XA_CSR),CSR_START) ;\n\t\t}\n\t\telse {\n\t\t\toutpd(ADDR(B0_XS_CSR),CSR_START) ;\n\t\t}\n#endif\n\t\tqueue->tx_free-- ;\n\t\tqueue->tx_used++ ;\n\t\tqueue->tx_curr_put = t->txd_next ;\n\t\tif (frame_status & LAST_FRAG) {\n\t\t\tsmc->mib.m[MAC0].fddiMACTransmit_Ct++ ;\n\t\t}\n\t}\n\tif (frame_status & LOC_TX) {\n\t\tDB_TX(3, \"LOC_TX:\");\n\t\tif (frame_status & FIRST_FRAG) {\n\t\t\tif(!(smc->os.hwm.tx_mb = smt_get_mbuf(smc))) {\n\t\t\t\tsmc->hw.fp.err_stats.err_no_buf++ ;\n\t\t\t\tDB_TX(4, \"No SMbuf; transmit terminated\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tsmc->os.hwm.tx_data =\n\t\t\t\t\tsmtod(smc->os.hwm.tx_mb,char *) - 1 ;\n#ifdef USE_OS_CPY\n#ifdef PASS_1ST_TXD_2_TX_COMP\n\t\t\t\thwm_cpy_txd2mb(t,smc->os.hwm.tx_data,\n\t\t\t\t\tsmc->os.hwm.tx_len) ;\n#endif\n#endif\n\t\t\t}\n\t\t}\n\t\tif (smc->os.hwm.tx_mb) {\n#ifndef\tUSE_OS_CPY\n\t\t\tDB_TX(3, \"copy fragment into MBuf\");\n\t\t\tmemcpy(smc->os.hwm.tx_data,virt,len) ;\n\t\t\tsmc->os.hwm.tx_data += len ;\n#endif\n\t\t\tif (frame_status & LAST_FRAG) {\n#ifdef\tUSE_OS_CPY\n#ifndef PASS_1ST_TXD_2_TX_COMP\n\t\t\t\t  \n\t\t\t\thwm_cpy_txd2mb(t,smc->os.hwm.tx_data,\n\t\t\t\t\tsmc->os.hwm.tx_len) ;\n#endif\t \n#endif\t \n\t\t\t\tsmc->os.hwm.tx_data =\n\t\t\t\t\tsmtod(smc->os.hwm.tx_mb,char *) - 1 ;\n\t\t\t\t*(char *)smc->os.hwm.tx_mb->sm_data =\n\t\t\t\t\t*smc->os.hwm.tx_data ;\n\t\t\t\tsmc->os.hwm.tx_data++ ;\n\t\t\t\tsmc->os.hwm.tx_mb->sm_len =\n\t\t\t\t\tsmc->os.hwm.tx_len - 1 ;\n\t\t\t\tDB_TX(3, \"pass LLC frame to SMT\");\n\t\t\t\tsmt_received_pack(smc,smc->os.hwm.tx_mb,\n\t\t\t\t\t\tRD_FS_LOCAL) ;\n\t\t\t}\n\t\t}\n\t}\n\tNDD_TRACE(\"THfE\",t,queue->tx_free,0) ;\n}\n\n\n \nstatic void queue_llc_rx(struct s_smc *smc, SMbuf *mb)\n{\n\tDB_GEN(4, \"queue_llc_rx: mb = %p\", mb);\n\tsmc->os.hwm.queued_rx_frames++ ;\n\tmb->sm_next = (SMbuf *)NULL ;\n\tif (smc->os.hwm.llc_rx_pipe == NULL) {\n\t\tsmc->os.hwm.llc_rx_pipe = mb ;\n\t}\n\telse {\n\t\tsmc->os.hwm.llc_rx_tail->sm_next = mb ;\n\t}\n\tsmc->os.hwm.llc_rx_tail = mb ;\n\n\t \n\tif (!smc->os.hwm.isr_flag) {\n\t\tsmt_force_irq(smc) ;\n\t}\n}\n\n \nstatic SMbuf *get_llc_rx(struct s_smc *smc)\n{\n\tSMbuf\t*mb ;\n\n\tif ((mb = smc->os.hwm.llc_rx_pipe)) {\n\t\tsmc->os.hwm.queued_rx_frames-- ;\n\t\tsmc->os.hwm.llc_rx_pipe = mb->sm_next ;\n\t}\n\tDB_GEN(4, \"get_llc_rx: mb = 0x%p\", mb);\n\treturn mb;\n}\n\n \nstatic void queue_txd_mb(struct s_smc *smc, SMbuf *mb)\n{\n\tDB_GEN(4, \"_rx: queue_txd_mb = %p\", mb);\n\tsmc->os.hwm.queued_txd_mb++ ;\n\tmb->sm_next = (SMbuf *)NULL ;\n\tif (smc->os.hwm.txd_tx_pipe == NULL) {\n\t\tsmc->os.hwm.txd_tx_pipe = mb ;\n\t}\n\telse {\n\t\tsmc->os.hwm.txd_tx_tail->sm_next = mb ;\n\t}\n\tsmc->os.hwm.txd_tx_tail = mb ;\n}\n\n \nstatic SMbuf *get_txd_mb(struct s_smc *smc)\n{\n\tSMbuf *mb ;\n\n\tif ((mb = smc->os.hwm.txd_tx_pipe)) {\n\t\tsmc->os.hwm.queued_txd_mb-- ;\n\t\tsmc->os.hwm.txd_tx_pipe = mb->sm_next ;\n\t}\n\tDB_GEN(4, \"get_txd_mb: mb = 0x%p\", mb);\n\treturn mb;\n}\n\n \nvoid smt_send_mbuf(struct s_smc *smc, SMbuf *mb, int fc)\n{\n\tchar far *data ;\n\tint\tlen ;\n\tint\tn ;\n\tint\ti ;\n\tint\tfrag_count ;\n\tint\tframe_status ;\n\tSK_LOC_DECL(char far,*virt[3]) ;\n\tint\tfrag_len[3] ;\n\tstruct s_smt_tx_queue *queue ;\n\tstruct s_smt_fp_txd volatile *t ;\n\tu_long\tphys ;\n\t__le32\ttbctrl;\n\n\tNDD_TRACE(\"THSB\",mb,fc,0) ;\n\tDB_TX(4, \"smt_send_mbuf: mb = 0x%p, fc = 0x%x\", mb, fc);\n\n\tmb->sm_off-- ;\t \n\tmb->sm_len++ ;\t \n\tdata = smtod(mb,char *) ;\n\t*data = fc ;\n\tif (fc == FC_SMT_LOC)\n\t\t*data = FC_SMT_INFO ;\n\n\t \n\tfrag_count = 0 ;\n\tlen = mb->sm_len ;\n\twhile (len) {\n\t\tn = SMT_PAGESIZE - ((long)data & (SMT_PAGESIZE-1)) ;\n\t\tif (n >= len) {\n\t\t\tn = len ;\n\t\t}\n\t\tDB_TX(5, \"frag: virt/len = 0x%p/%d\", data, n);\n\t\tvirt[frag_count] = data ;\n\t\tfrag_len[frag_count] = n ;\n\t\tfrag_count++ ;\n\t\tlen -= n ;\n\t\tdata += n ;\n\t}\n\n\t \n\tqueue = smc->hw.fp.tx[QUEUE_A0] ;\n\tif (fc == FC_BEACON || fc == FC_SMT_LOC) {\n\t\tframe_status = LOC_TX ;\n\t}\n\telse {\n\t\tframe_status = LAN_TX ;\n\t\tif ((smc->os.hwm.pass_NSA &&(fc == FC_SMT_NSA)) ||\n\t\t   (smc->os.hwm.pass_SMT &&(fc == FC_SMT_INFO)))\n\t\t\tframe_status |= LOC_TX ;\n\t}\n\n\tif (!smc->hw.mac_ring_is_up || frag_count > queue->tx_free) {\n\t\tframe_status &= ~LAN_TX;\n\t\tif (frame_status) {\n\t\t\tDB_TX(2, \"Ring is down: terminate LAN_TX\");\n\t\t}\n\t\telse {\n\t\t\tDB_TX(2, \"Ring is down: terminate transmission\");\n\t\t\tsmt_free_mbuf(smc,mb) ;\n\t\t\treturn ;\n\t\t}\n\t}\n\tDB_TX(5, \"frame_status = 0x%x\", frame_status);\n\n\tif ((frame_status & LAN_TX) && (frame_status & LOC_TX)) {\n\t\tmb->sm_use_count = 2 ;\n\t}\n\n\tif (frame_status & LAN_TX) {\n\t\tt = queue->tx_curr_put ;\n\t\tframe_status |= FIRST_FRAG ;\n\t\tfor (i = 0; i < frag_count; i++) {\n\t\t\tDB_TX(5, \"init TxD = 0x%p\", t);\n\t\t\tif (i == frag_count-1) {\n\t\t\t\tframe_status |= LAST_FRAG ;\n\t\t\t\tt->txd_txdscr = cpu_to_le32(TX_DESCRIPTOR |\n\t\t\t\t\t(((__u32)(mb->sm_len-1)&3) << 27)) ;\n\t\t\t}\n\t\t\tt->txd_virt = virt[i] ;\n\t\t\tphys = dma_master(smc, (void far *)virt[i],\n\t\t\t\tfrag_len[i], DMA_RD|SMT_BUF) ;\n\t\t\tt->txd_tbadr = cpu_to_le32(phys) ;\n\t\t\ttbctrl = cpu_to_le32((((__u32)frame_status &\n\t\t\t\t(FIRST_FRAG|LAST_FRAG)) << 26) |\n\t\t\t\tBMU_OWN | BMU_CHECK | BMU_SMT_TX |frag_len[i]) ;\n\t\t\tt->txd_tbctrl = tbctrl ;\n#ifndef\tAIX\n\t\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\n\t\t\toutpd(queue->tx_bmu_ctl,CSR_START) ;\n#else\n\t\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\n\t\t\toutpd(ADDR(B0_XA_CSR),CSR_START) ;\n#endif\n\t\t\tframe_status &= ~FIRST_FRAG ;\n\t\t\tqueue->tx_curr_put = t = t->txd_next ;\n\t\t\tqueue->tx_free-- ;\n\t\t\tqueue->tx_used++ ;\n\t\t}\n\t\tsmc->mib.m[MAC0].fddiMACTransmit_Ct++ ;\n\t\tqueue_txd_mb(smc,mb) ;\n\t}\n\n\tif (frame_status & LOC_TX) {\n\t\tDB_TX(5, \"pass Mbuf to LLC queue\");\n\t\tqueue_llc_rx(smc,mb) ;\n\t}\n\n\t \n\tmac_drv_clear_txd(smc) ;\n\tNDD_TRACE(\"THSE\",t,queue->tx_free,frag_count) ;\n}\n\n \nstatic void mac_drv_clear_txd(struct s_smc *smc)\n{\n\tstruct s_smt_tx_queue *queue ;\n\tstruct s_smt_fp_txd volatile *t1 ;\n\tstruct s_smt_fp_txd volatile *t2 = NULL ;\n\tSMbuf *mb ;\n\tu_long\ttbctrl ;\n\tint i ;\n\tint frag_count ;\n\tint n ;\n\n\tNDD_TRACE(\"THcB\",0,0,0) ;\n\tfor (i = QUEUE_S; i <= QUEUE_A0; i++) {\n\t\tqueue = smc->hw.fp.tx[i] ;\n\t\tt1 = queue->tx_curr_get ;\n\t\tDB_TX(5, \"clear_txd: QUEUE = %d (0=sync/1=async)\", i);\n\n\t\tfor ( ; ; ) {\n\t\t\tfrag_count = 0 ;\n\n\t\t\tdo {\n\t\t\t\tDRV_BUF_FLUSH(t1,DDI_DMA_SYNC_FORCPU) ;\n\t\t\t\tDB_TX(5, \"check OWN/EOF bit of TxD 0x%p\", t1);\n\t\t\t\ttbctrl = le32_to_cpu(CR_READ(t1->txd_tbctrl));\n\n\t\t\t\tif (tbctrl & BMU_OWN || !queue->tx_used){\n\t\t\t\t\tDB_TX(4, \"End of TxDs queue %d\", i);\n\t\t\t\t\tgoto free_next_queue ;\t \n\t\t\t\t}\n\t\t\t\tt1 = t1->txd_next ;\n\t\t\t\tfrag_count++ ;\n\t\t\t} while (!(tbctrl & BMU_EOF)) ;\n\n\t\t\tt1 = queue->tx_curr_get ;\n\t\t\tfor (n = frag_count; n; n--) {\n\t\t\t\ttbctrl = le32_to_cpu(t1->txd_tbctrl) ;\n\t\t\t\tdma_complete(smc,\n\t\t\t\t\t(union s_fp_descr volatile *) t1,\n\t\t\t\t\t(int) (DMA_RD |\n\t\t\t\t\t((tbctrl & BMU_SMT_TX) >> 18))) ;\n\t\t\t\tt2 = t1 ;\n\t\t\t\tt1 = t1->txd_next ;\n\t\t\t}\n\n\t\t\tif (tbctrl & BMU_SMT_TX) {\n\t\t\t\tmb = get_txd_mb(smc) ;\n\t\t\t\tsmt_free_mbuf(smc,mb) ;\n\t\t\t}\n\t\t\telse {\n#ifndef PASS_1ST_TXD_2_TX_COMP\n\t\t\t\tDB_TX(4, \"mac_drv_tx_comp for TxD 0x%p\", t2);\n\t\t\t\tmac_drv_tx_complete(smc,t2) ;\n#else\n\t\t\t\tDB_TX(4, \"mac_drv_tx_comp for TxD 0x%x\",\n\t\t\t\t      queue->tx_curr_get);\n\t\t\t\tmac_drv_tx_complete(smc,queue->tx_curr_get) ;\n#endif\n\t\t\t}\n\t\t\tqueue->tx_curr_get = t1 ;\n\t\t\tqueue->tx_free += frag_count ;\n\t\t\tqueue->tx_used -= frag_count ;\n\t\t}\nfree_next_queue: ;\n\t}\n\tNDD_TRACE(\"THcE\",0,0,0) ;\n}\n\n \nvoid mac_drv_clear_tx_queue(struct s_smc *smc)\n{\n\tstruct s_smt_fp_txd volatile *t ;\n\tstruct s_smt_tx_queue *queue ;\n\tint tx_used ;\n\tint i ;\n\n\tif (smc->hw.hw_state != STOPPED) {\n\t\tSK_BREAK() ;\n\t\tSMT_PANIC(smc,HWM_E0011,HWM_E0011_MSG) ;\n\t\treturn ;\n\t}\n\n\tfor (i = QUEUE_S; i <= QUEUE_A0; i++) {\n\t\tqueue = smc->hw.fp.tx[i] ;\n\t\tDB_TX(5, \"clear_tx_queue: QUEUE = %d (0=sync/1=async)\", i);\n\n\t\t \n\t\tt = queue->tx_curr_get ;\n\t\ttx_used = queue->tx_used ;\n\t\twhile (tx_used) {\n\t\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORCPU) ;\n\t\t\tDB_TX(5, \"switch OWN bit of TxD 0x%p\", t);\n\t\t\tt->txd_tbctrl &= ~cpu_to_le32(BMU_OWN) ;\n\t\t\tDRV_BUF_FLUSH(t,DDI_DMA_SYNC_FORDEV) ;\n\t\t\tt = t->txd_next ;\n\t\t\ttx_used-- ;\n\t\t}\n\t}\n\n\t \n\tmac_drv_clear_txd(smc) ;\n\n\tfor (i = QUEUE_S; i <= QUEUE_A0; i++) {\n\t\tqueue = smc->hw.fp.tx[i] ;\n\t\tt = queue->tx_curr_get ;\n\n\t\t \n\t\tif (i == QUEUE_S) {\n\t\t\toutpd(ADDR(B5_XS_DA),le32_to_cpu(t->txd_ntdadr)) ;\n\t\t}\n\t\telse {\n\t\t\toutpd(ADDR(B5_XA_DA),le32_to_cpu(t->txd_ntdadr)) ;\n\t\t}\n\n\t\tqueue->tx_curr_put = queue->tx_curr_get->txd_next ;\n\t\tqueue->tx_curr_get = queue->tx_curr_put ;\n\t}\n}\n\n\n \n\n#ifdef\tDEBUG\n \nvoid mac_drv_debug_lev(struct s_smc *smc, int flag, int lev)\n{\n\tswitch(flag) {\n\tcase (int)NULL:\n\t\tDB_P.d_smtf = DB_P.d_smt = DB_P.d_ecm = DB_P.d_rmt = 0 ;\n\t\tDB_P.d_cfm = 0 ;\n\t\tDB_P.d_os.hwm_rx = DB_P.d_os.hwm_tx = DB_P.d_os.hwm_gen = 0 ;\n#ifdef\tSBA\n\t\tDB_P.d_sba = 0 ;\n#endif\n#ifdef\tESS\n\t\tDB_P.d_ess = 0 ;\n#endif\n\t\tbreak ;\n\tcase DEBUG_SMTF:\n\t\tDB_P.d_smtf = lev ;\n\t\tbreak ;\n\tcase DEBUG_SMT:\n\t\tDB_P.d_smt = lev ;\n\t\tbreak ;\n\tcase DEBUG_ECM:\n\t\tDB_P.d_ecm = lev ;\n\t\tbreak ;\n\tcase DEBUG_RMT:\n\t\tDB_P.d_rmt = lev ;\n\t\tbreak ;\n\tcase DEBUG_CFM:\n\t\tDB_P.d_cfm = lev ;\n\t\tbreak ;\n\tcase DEBUG_PCM:\n\t\tDB_P.d_pcm = lev ;\n\t\tbreak ;\n\tcase DEBUG_SBA:\n#ifdef\tSBA\n\t\tDB_P.d_sba = lev ;\n#endif\n\t\tbreak ;\n\tcase DEBUG_ESS:\n#ifdef\tESS\n\t\tDB_P.d_ess = lev ;\n#endif\n\t\tbreak ;\n\tcase DB_HWM_RX:\n\t\tDB_P.d_os.hwm_rx = lev ;\n\t\tbreak ;\n\tcase DB_HWM_TX:\n\t\tDB_P.d_os.hwm_tx = lev ;\n\t\tbreak ;\n\tcase DB_HWM_GEN:\n\t\tDB_P.d_os.hwm_gen = lev ;\n\t\tbreak ;\n\tdefault:\n\t\tbreak ;\n\t}\n}\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}