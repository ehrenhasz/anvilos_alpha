{
  "module_name": "bcm_sf2_cfp.c",
  "hash_id": "c72094e6929d52ece5430398f7e356c2868b198ef26e4c6b91bdbc676cafe00a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/dsa/bcm_sf2_cfp.c",
  "human_readable_source": "\n \n\n#include <linux/list.h>\n#include <linux/ethtool.h>\n#include <linux/if_ether.h>\n#include <linux/in.h>\n#include <linux/netdevice.h>\n#include <net/dsa.h>\n#include <linux/bitmap.h>\n#include <net/flow_offload.h>\n#include <net/switchdev.h>\n#include <uapi/linux/if_bridge.h>\n\n#include \"bcm_sf2.h\"\n#include \"bcm_sf2_regs.h\"\n\nstruct cfp_rule {\n\tint port;\n\tstruct ethtool_rx_flow_spec fs;\n\tstruct list_head next;\n};\n\nstruct cfp_udf_slice_layout {\n\tu8 slices[UDFS_PER_SLICE];\n\tu32 mask_value;\n\tu32 base_offset;\n};\n\nstruct cfp_udf_layout {\n\tstruct cfp_udf_slice_layout udfs[UDF_NUM_SLICES];\n};\n\nstatic const u8 zero_slice[UDFS_PER_SLICE] = { };\n\n \nstatic const struct cfp_udf_layout udf_tcpip4_layout = {\n\t.udfs = {\n\t\t[1] = {\n\t\t\t.slices = {\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 6,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 7,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 8,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 9,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL3 | 0,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL3 | 1,\n\t\t\t\t0, 0, 0\n\t\t\t},\n\t\t\t.mask_value = L3_FRAMING_MASK | IPPROTO_MASK | IP_FRAG,\n\t\t\t.base_offset = CORE_UDF_0_A_0_8_PORT_0 + UDF_SLICE_OFFSET,\n\t\t},\n\t},\n};\n\n \nstatic const struct cfp_udf_layout udf_tcpip6_layout = {\n\t.udfs = {\n\t\t[0] = {\n\t\t\t.slices = {\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 4,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 5,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 6,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 7,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 8,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 9,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 10,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 11,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL3 | 0,\n\t\t\t},\n\t\t\t.mask_value = L3_FRAMING_MASK | IPPROTO_MASK | IP_FRAG,\n\t\t\t.base_offset = CORE_UDF_0_B_0_8_PORT_0,\n\t\t},\n\t\t[3] = {\n\t\t\t.slices = {\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 12,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 13,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 14,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 15,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 16,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 17,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 18,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL2 | 19,\n\t\t\t\t \n\t\t\t\tCFG_UDF_EOL3 | 1,\n\t\t\t},\n\t\t\t.mask_value = L3_FRAMING_MASK | IPPROTO_MASK | IP_FRAG,\n\t\t\t.base_offset = CORE_UDF_0_D_0_11_PORT_0,\n\t\t},\n\t},\n};\n\nstatic inline unsigned int bcm_sf2_get_num_udf_slices(const u8 *layout)\n{\n\tunsigned int i, count = 0;\n\n\tfor (i = 0; i < UDFS_PER_SLICE; i++) {\n\t\tif (layout[i] != 0)\n\t\t\tcount++;\n\t}\n\n\treturn count;\n}\n\nstatic inline u32 udf_upper_bits(int num_udf)\n{\n\treturn GENMASK(num_udf - 1, 0) >> (UDFS_PER_SLICE - 1);\n}\n\nstatic inline u32 udf_lower_bits(int num_udf)\n{\n\treturn (u8)GENMASK(num_udf - 1, 0);\n}\n\nstatic unsigned int bcm_sf2_get_slice_number(const struct cfp_udf_layout *l,\n\t\t\t\t\t     unsigned int start)\n{\n\tconst struct cfp_udf_slice_layout *slice_layout;\n\tunsigned int slice_idx;\n\n\tfor (slice_idx = start; slice_idx < UDF_NUM_SLICES; slice_idx++) {\n\t\tslice_layout = &l->udfs[slice_idx];\n\t\tif (memcmp(slice_layout->slices, zero_slice,\n\t\t\t   sizeof(zero_slice)))\n\t\t\tbreak;\n\t}\n\n\treturn slice_idx;\n}\n\nstatic void bcm_sf2_cfp_udf_set(struct bcm_sf2_priv *priv,\n\t\t\t\tconst struct cfp_udf_layout *layout,\n\t\t\t\tunsigned int slice_num)\n{\n\tu32 offset = layout->udfs[slice_num].base_offset;\n\tunsigned int i;\n\n\tfor (i = 0; i < UDFS_PER_SLICE; i++)\n\t\tcore_writel(priv, layout->udfs[slice_num].slices[i],\n\t\t\t    offset + i * 4);\n}\n\nstatic int bcm_sf2_cfp_op(struct bcm_sf2_priv *priv, unsigned int op)\n{\n\tunsigned int timeout = 1000;\n\tu32 reg;\n\n\treg = core_readl(priv, CORE_CFP_ACC);\n\treg &= ~(OP_SEL_MASK | RAM_SEL_MASK);\n\treg |= OP_STR_DONE | op;\n\tcore_writel(priv, reg, CORE_CFP_ACC);\n\n\tdo {\n\t\treg = core_readl(priv, CORE_CFP_ACC);\n\t\tif (!(reg & OP_STR_DONE))\n\t\t\tbreak;\n\n\t\tcpu_relax();\n\t} while (timeout--);\n\n\tif (!timeout)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nstatic inline void bcm_sf2_cfp_rule_addr_set(struct bcm_sf2_priv *priv,\n\t\t\t\t\t     unsigned int addr)\n{\n\tu32 reg;\n\n\tWARN_ON(addr >= priv->num_cfp_rules);\n\n\treg = core_readl(priv, CORE_CFP_ACC);\n\treg &= ~(XCESS_ADDR_MASK << XCESS_ADDR_SHIFT);\n\treg |= addr << XCESS_ADDR_SHIFT;\n\tcore_writel(priv, reg, CORE_CFP_ACC);\n}\n\nstatic inline unsigned int bcm_sf2_cfp_rule_size(struct bcm_sf2_priv *priv)\n{\n\t \n\treturn priv->num_cfp_rules - 1;\n}\n\nstatic int bcm_sf2_cfp_act_pol_set(struct bcm_sf2_priv *priv,\n\t\t\t\t   unsigned int rule_index,\n\t\t\t\t   int src_port,\n\t\t\t\t   unsigned int port_num,\n\t\t\t\t   unsigned int queue_num,\n\t\t\t\t   bool fwd_map_change)\n{\n\tint ret;\n\tu32 reg;\n\n\t \n\tif (fwd_map_change)\n\t\treg = CHANGE_FWRD_MAP_IB_REP_ARL |\n\t\t      BIT(port_num + DST_MAP_IB_SHIFT) |\n\t\t      CHANGE_TC | queue_num << NEW_TC_SHIFT;\n\telse\n\t\treg = 0;\n\n\t \n\tif (src_port == port_num)\n\t\treg |= LOOP_BK_EN;\n\n\tcore_writel(priv, reg, CORE_ACT_POL_DATA0);\n\n\t \n\tcore_writel(priv, rule_index << CHAIN_ID_SHIFT, CORE_ACT_POL_DATA1);\n\n\tcore_writel(priv, 0, CORE_ACT_POL_DATA2);\n\n\t \n\tret = bcm_sf2_cfp_op(priv, OP_SEL_WRITE | ACT_POL_RAM);\n\tif (ret) {\n\t\tpr_err(\"Policer entry at %d failed\\n\", rule_index);\n\t\treturn ret;\n\t}\n\n\t \n\tcore_writel(priv, POLICER_MODE_DISABLE, CORE_RATE_METER0);\n\n\t \n\tret = bcm_sf2_cfp_op(priv, OP_SEL_WRITE | RATE_METER_RAM);\n\tif (ret) {\n\t\tpr_err(\"Meter entry at %d failed\\n\", rule_index);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void bcm_sf2_cfp_slice_ipv4(struct bcm_sf2_priv *priv,\n\t\t\t\t   struct flow_dissector_key_ipv4_addrs *addrs,\n\t\t\t\t   struct flow_dissector_key_ports *ports,\n\t\t\t\t   const __be16 vlan_tci,\n\t\t\t\t   unsigned int slice_num, u8 num_udf,\n\t\t\t\t   bool mask)\n{\n\tu32 reg, offset;\n\n\t \n\treg = udf_lower_bits(num_udf) << 24 | be16_to_cpu(vlan_tci) >> 8;\n\tif (mask)\n\t\tcore_writel(priv, reg, CORE_CFP_MASK_PORT(5));\n\telse\n\t\tcore_writel(priv, reg, CORE_CFP_DATA_PORT(5));\n\n\t \n\treg = (u32)(be16_to_cpu(vlan_tci) & 0xff) << 24;\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(4);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(4);\n\tcore_writel(priv, reg, offset);\n\n\t \n\treg = be16_to_cpu(ports->dst) >> 8;\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(3);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(3);\n\tcore_writel(priv, reg, offset);\n\n\t \n\treg = (be16_to_cpu(ports->dst) & 0xff) << 24 |\n\t      (u32)be16_to_cpu(ports->src) << 8 |\n\t      (be32_to_cpu(addrs->dst) & 0x0000ff00) >> 8;\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(2);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(2);\n\tcore_writel(priv, reg, offset);\n\n\t \n\treg = (u32)(be32_to_cpu(addrs->dst) & 0xff) << 24 |\n\t      (u32)(be32_to_cpu(addrs->dst) >> 16) << 8 |\n\t      (be32_to_cpu(addrs->src) & 0x0000ff00) >> 8;\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(1);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(1);\n\tcore_writel(priv, reg, offset);\n\n\t \n\treg = (u32)(be32_to_cpu(addrs->src) & 0xff) << 24 |\n\t      (u32)(be32_to_cpu(addrs->src) >> 16) << 8 |\n\t      SLICE_NUM(slice_num) | SLICE_VALID;\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(0);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(0);\n\tcore_writel(priv, reg, offset);\n}\n\nstatic int bcm_sf2_cfp_ipv4_rule_set(struct bcm_sf2_priv *priv, int port,\n\t\t\t\t     unsigned int port_num,\n\t\t\t\t     unsigned int queue_num,\n\t\t\t\t     struct ethtool_rx_flow_spec *fs)\n{\n\t__be16 vlan_tci = 0, vlan_m_tci = htons(0xffff);\n\tstruct ethtool_rx_flow_spec_input input = {};\n\tconst struct cfp_udf_layout *layout;\n\tunsigned int slice_num, rule_index;\n\tstruct ethtool_rx_flow_rule *flow;\n\tstruct flow_match_ipv4_addrs ipv4;\n\tstruct flow_match_ports ports;\n\tstruct flow_match_ip ip;\n\tu8 ip_proto, ip_frag;\n\tu8 num_udf;\n\tu32 reg;\n\tint ret;\n\n\tswitch (fs->flow_type & ~FLOW_EXT) {\n\tcase TCP_V4_FLOW:\n\t\tip_proto = IPPROTO_TCP;\n\t\tbreak;\n\tcase UDP_V4_FLOW:\n\t\tip_proto = IPPROTO_UDP;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tip_frag = !!(be32_to_cpu(fs->h_ext.data[0]) & 1);\n\n\t \n\tif (fs->flow_type & FLOW_EXT) {\n\t\tvlan_tci = fs->h_ext.vlan_tci;\n\t\tvlan_m_tci = fs->m_ext.vlan_tci;\n\t}\n\n\t \n\tif (fs->location == RX_CLS_LOC_ANY)\n\t\trule_index = find_first_zero_bit(priv->cfp.used,\n\t\t\t\t\t\t priv->num_cfp_rules);\n\telse\n\t\trule_index = fs->location;\n\n\tif (rule_index > bcm_sf2_cfp_rule_size(priv))\n\t\treturn -ENOSPC;\n\n\tinput.fs = fs;\n\tflow = ethtool_rx_flow_rule_create(&input);\n\tif (IS_ERR(flow))\n\t\treturn PTR_ERR(flow);\n\n\tflow_rule_match_ipv4_addrs(flow->rule, &ipv4);\n\tflow_rule_match_ports(flow->rule, &ports);\n\tflow_rule_match_ip(flow->rule, &ip);\n\n\tlayout = &udf_tcpip4_layout;\n\t \n\tslice_num = bcm_sf2_get_slice_number(layout, 0);\n\tif (slice_num == UDF_NUM_SLICES) {\n\t\tret = -EINVAL;\n\t\tgoto out_err_flow_rule;\n\t}\n\n\tnum_udf = bcm_sf2_get_num_udf_slices(layout->udfs[slice_num].slices);\n\n\t \n\tbcm_sf2_cfp_udf_set(priv, layout, slice_num);\n\n\t \n\tcore_writel(priv, BIT(port), CORE_CFP_DATA_PORT(7));\n\n\t \n\tcore_writel(priv, 0xff, CORE_CFP_MASK_PORT(7));\n\n\t \n\tcore_writel(priv, ip.key->tos << IPTOS_SHIFT |\n\t\t    ip_proto << IPPROTO_SHIFT | ip_frag << IP_FRAG_SHIFT |\n\t\t    udf_upper_bits(num_udf),\n\t\t    CORE_CFP_DATA_PORT(6));\n\n\t \n\tcore_writel(priv, layout->udfs[slice_num].mask_value |\n\t\t    udf_upper_bits(num_udf), CORE_CFP_MASK_PORT(6));\n\n\t \n\tbcm_sf2_cfp_slice_ipv4(priv, ipv4.key, ports.key, vlan_tci,\n\t\t\t       slice_num, num_udf, false);\n\tbcm_sf2_cfp_slice_ipv4(priv, ipv4.mask, ports.mask, vlan_m_tci,\n\t\t\t       SLICE_NUM_MASK, num_udf, true);\n\n\t \n\tbcm_sf2_cfp_rule_addr_set(priv, rule_index);\n\n\tret = bcm_sf2_cfp_op(priv, OP_SEL_WRITE | TCAM_SEL);\n\tif (ret) {\n\t\tpr_err(\"TCAM entry at addr %d failed\\n\", rule_index);\n\t\tgoto out_err_flow_rule;\n\t}\n\n\t \n\tret = bcm_sf2_cfp_act_pol_set(priv, rule_index, port, port_num,\n\t\t\t\t      queue_num, true);\n\tif (ret)\n\t\tgoto out_err_flow_rule;\n\n\t \n\treg = core_readl(priv, CORE_CFP_CTL_REG);\n\treg |= BIT(port);\n\tcore_writel(priv, reg, CORE_CFP_CTL_REG);\n\n\t \n\tset_bit(rule_index, priv->cfp.used);\n\tset_bit(rule_index, priv->cfp.unique);\n\tfs->location = rule_index;\n\n\treturn 0;\n\nout_err_flow_rule:\n\tethtool_rx_flow_rule_destroy(flow);\n\treturn ret;\n}\n\nstatic void bcm_sf2_cfp_slice_ipv6(struct bcm_sf2_priv *priv,\n\t\t\t\t   const __be32 *ip6_addr, const __be16 port,\n\t\t\t\t   const __be16 vlan_tci,\n\t\t\t\t   unsigned int slice_num, u32 udf_bits,\n\t\t\t\t   bool mask)\n{\n\tu32 reg, tmp, val, offset;\n\n\t \n\treg = udf_bits << 24 | be16_to_cpu(vlan_tci) >> 8;\n\tif (mask)\n\t\tcore_writel(priv, reg, CORE_CFP_MASK_PORT(5));\n\telse\n\t\tcore_writel(priv, reg, CORE_CFP_DATA_PORT(5));\n\n\t \n\treg = be32_to_cpu(ip6_addr[3]);\n\tval = (u32)be16_to_cpu(port) << 8 | ((reg >> 8) & 0xff);\n\tval |= (u32)(be16_to_cpu(vlan_tci) & 0xff) << 24;\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(4);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(4);\n\tcore_writel(priv, val, offset);\n\n\t \n\ttmp = be32_to_cpu(ip6_addr[2]);\n\tval = (u32)(reg & 0xff) << 24 | (u32)(reg >> 16) << 8 |\n\t      ((tmp >> 8) & 0xff);\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(3);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(3);\n\tcore_writel(priv, val, offset);\n\n\t \n\treg = be32_to_cpu(ip6_addr[1]);\n\tval = (u32)(tmp & 0xff) << 24 | (u32)(tmp >> 16) << 8 |\n\t      ((reg >> 8) & 0xff);\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(2);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(2);\n\tcore_writel(priv, val, offset);\n\n\t \n\ttmp = be32_to_cpu(ip6_addr[0]);\n\tval = (u32)(reg & 0xff) << 24 | (u32)(reg >> 16) << 8 |\n\t      ((tmp >> 8) & 0xff);\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(1);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(1);\n\tcore_writel(priv, val, offset);\n\n\t \n\treg = (u32)(tmp & 0xff) << 24 | (u32)(tmp >> 16) << 8 |\n\t       SLICE_NUM(slice_num) | SLICE_VALID;\n\tif (mask)\n\t\toffset = CORE_CFP_MASK_PORT(0);\n\telse\n\t\toffset = CORE_CFP_DATA_PORT(0);\n\tcore_writel(priv, reg, offset);\n}\n\nstatic struct cfp_rule *bcm_sf2_cfp_rule_find(struct bcm_sf2_priv *priv,\n\t\t\t\t\t      int port, u32 location)\n{\n\tstruct cfp_rule *rule;\n\n\tlist_for_each_entry(rule, &priv->cfp.rules_list, next) {\n\t\tif (rule->port == port && rule->fs.location == location)\n\t\t\treturn rule;\n\t}\n\n\treturn NULL;\n}\n\nstatic int bcm_sf2_cfp_rule_cmp(struct bcm_sf2_priv *priv, int port,\n\t\t\t\tstruct ethtool_rx_flow_spec *fs)\n{\n\tstruct cfp_rule *rule = NULL;\n\tsize_t fs_size = 0;\n\tint ret = 1;\n\n\tif (list_empty(&priv->cfp.rules_list))\n\t\treturn ret;\n\n\tlist_for_each_entry(rule, &priv->cfp.rules_list, next) {\n\t\tret = 1;\n\t\tif (rule->port != port)\n\t\t\tcontinue;\n\n\t\tif (rule->fs.flow_type != fs->flow_type ||\n\t\t    rule->fs.ring_cookie != fs->ring_cookie ||\n\t\t    rule->fs.h_ext.data[0] != fs->h_ext.data[0])\n\t\t\tcontinue;\n\n\t\tswitch (fs->flow_type & ~FLOW_EXT) {\n\t\tcase TCP_V6_FLOW:\n\t\tcase UDP_V6_FLOW:\n\t\t\tfs_size = sizeof(struct ethtool_tcpip6_spec);\n\t\t\tbreak;\n\t\tcase TCP_V4_FLOW:\n\t\tcase UDP_V4_FLOW:\n\t\t\tfs_size = sizeof(struct ethtool_tcpip4_spec);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = memcmp(&rule->fs.h_u, &fs->h_u, fs_size);\n\t\tret |= memcmp(&rule->fs.m_u, &fs->m_u, fs_size);\n\t\t \n\t\tif (rule->fs.flow_type & FLOW_EXT) {\n\t\t\tret |= rule->fs.h_ext.vlan_tci != fs->h_ext.vlan_tci;\n\t\t\tret |= rule->fs.m_ext.vlan_tci != fs->m_ext.vlan_tci;\n\t\t}\n\t\tif (ret == 0)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int bcm_sf2_cfp_ipv6_rule_set(struct bcm_sf2_priv *priv, int port,\n\t\t\t\t     unsigned int port_num,\n\t\t\t\t     unsigned int queue_num,\n\t\t\t\t     struct ethtool_rx_flow_spec *fs)\n{\n\t__be16 vlan_tci = 0, vlan_m_tci = htons(0xffff);\n\tstruct ethtool_rx_flow_spec_input input = {};\n\tunsigned int slice_num, rule_index[2];\n\tconst struct cfp_udf_layout *layout;\n\tstruct ethtool_rx_flow_rule *flow;\n\tstruct flow_match_ipv6_addrs ipv6;\n\tstruct flow_match_ports ports;\n\tu8 ip_proto, ip_frag;\n\tint ret = 0;\n\tu8 num_udf;\n\tu32 reg;\n\n\tswitch (fs->flow_type & ~FLOW_EXT) {\n\tcase TCP_V6_FLOW:\n\t\tip_proto = IPPROTO_TCP;\n\t\tbreak;\n\tcase UDP_V6_FLOW:\n\t\tip_proto = IPPROTO_UDP;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tip_frag = !!(be32_to_cpu(fs->h_ext.data[0]) & 1);\n\n\t \n\tif (fs->flow_type & FLOW_EXT) {\n\t\tvlan_tci = fs->h_ext.vlan_tci;\n\t\tvlan_m_tci = fs->m_ext.vlan_tci;\n\t}\n\n\tlayout = &udf_tcpip6_layout;\n\tslice_num = bcm_sf2_get_slice_number(layout, 0);\n\tif (slice_num == UDF_NUM_SLICES)\n\t\treturn -EINVAL;\n\n\tnum_udf = bcm_sf2_get_num_udf_slices(layout->udfs[slice_num].slices);\n\n\t \n\tif (fs->location == RX_CLS_LOC_ANY)\n\t\trule_index[1] = find_first_zero_bit(priv->cfp.used,\n\t\t\t\t\t\t    priv->num_cfp_rules);\n\telse\n\t\trule_index[1] = fs->location;\n\tif (rule_index[1] > bcm_sf2_cfp_rule_size(priv))\n\t\treturn -ENOSPC;\n\n\t \n\tset_bit(rule_index[1], priv->cfp.used);\n\n\trule_index[0] = find_first_zero_bit(priv->cfp.used,\n\t\t\t\t\t    priv->num_cfp_rules);\n\tif (rule_index[0] > bcm_sf2_cfp_rule_size(priv)) {\n\t\tret = -ENOSPC;\n\t\tgoto out_err;\n\t}\n\n\tinput.fs = fs;\n\tflow = ethtool_rx_flow_rule_create(&input);\n\tif (IS_ERR(flow)) {\n\t\tret = PTR_ERR(flow);\n\t\tgoto out_err;\n\t}\n\tflow_rule_match_ipv6_addrs(flow->rule, &ipv6);\n\tflow_rule_match_ports(flow->rule, &ports);\n\n\t \n\tbcm_sf2_cfp_udf_set(priv, layout, slice_num);\n\n\t \n\tcore_writel(priv, BIT(port), CORE_CFP_DATA_PORT(7));\n\n\t \n\tcore_writel(priv, 0xff, CORE_CFP_MASK_PORT(7));\n\n\t \n\treg = 1 << L3_FRAMING_SHIFT | ip_proto << IPPROTO_SHIFT |\n\t\tip_frag << IP_FRAG_SHIFT | udf_upper_bits(num_udf);\n\tcore_writel(priv, reg, CORE_CFP_DATA_PORT(6));\n\n\t \n\treg = layout->udfs[slice_num].mask_value | udf_upper_bits(num_udf);\n\tcore_writel(priv, reg, CORE_CFP_MASK_PORT(6));\n\n\t \n\tbcm_sf2_cfp_slice_ipv6(priv, ipv6.key->src.in6_u.u6_addr32,\n\t\t\t       ports.key->src, vlan_tci, slice_num,\n\t\t\t       udf_lower_bits(num_udf), false);\n\tbcm_sf2_cfp_slice_ipv6(priv, ipv6.mask->src.in6_u.u6_addr32,\n\t\t\t       ports.mask->src, vlan_m_tci, SLICE_NUM_MASK,\n\t\t\t       udf_lower_bits(num_udf), true);\n\n\t \n\tbcm_sf2_cfp_rule_addr_set(priv, rule_index[0]);\n\n\tret = bcm_sf2_cfp_op(priv, OP_SEL_WRITE | TCAM_SEL);\n\tif (ret) {\n\t\tpr_err(\"TCAM entry at addr %d failed\\n\", rule_index[0]);\n\t\tgoto out_err_flow_rule;\n\t}\n\n\t \n\tret = bcm_sf2_cfp_act_pol_set(priv, rule_index[0], port, port_num,\n\t\t\t\t      queue_num, false);\n\tif (ret)\n\t\tgoto out_err_flow_rule;\n\n\t \n\tslice_num = bcm_sf2_get_slice_number(layout, slice_num + 1);\n\tif (slice_num == UDF_NUM_SLICES) {\n\t\tret = -EINVAL;\n\t\tgoto out_err_flow_rule;\n\t}\n\n\tnum_udf = bcm_sf2_get_num_udf_slices(layout->udfs[slice_num].slices);\n\n\t \n\tbcm_sf2_cfp_udf_set(priv, layout, slice_num);\n\n\t \n\tcore_writel(priv, 0, CORE_CFP_DATA_PORT(7));\n\tcore_writel(priv, 0, CORE_CFP_MASK_PORT(7));\n\n\t \n\treg = rule_index[0] << 24 | udf_upper_bits(num_udf) << 16 |\n\t\tudf_lower_bits(num_udf) << 8;\n\tcore_writel(priv, reg, CORE_CFP_DATA_PORT(6));\n\n\t \n\treg = XCESS_ADDR_MASK << 24 | udf_upper_bits(num_udf) << 16 |\n\t\tudf_lower_bits(num_udf) << 8;\n\tcore_writel(priv, reg, CORE_CFP_MASK_PORT(6));\n\n\tbcm_sf2_cfp_slice_ipv6(priv, ipv6.key->dst.in6_u.u6_addr32,\n\t\t\t       ports.key->dst, 0, slice_num,\n\t\t\t       0, false);\n\tbcm_sf2_cfp_slice_ipv6(priv, ipv6.mask->dst.in6_u.u6_addr32,\n\t\t\t       ports.key->dst, 0, SLICE_NUM_MASK,\n\t\t\t       0, true);\n\n\t \n\tbcm_sf2_cfp_rule_addr_set(priv, rule_index[1]);\n\n\tret = bcm_sf2_cfp_op(priv, OP_SEL_WRITE | TCAM_SEL);\n\tif (ret) {\n\t\tpr_err(\"TCAM entry at addr %d failed\\n\", rule_index[1]);\n\t\tgoto out_err_flow_rule;\n\t}\n\n\t \n\tret = bcm_sf2_cfp_act_pol_set(priv, rule_index[1], port, port_num,\n\t\t\t\t      queue_num, true);\n\tif (ret)\n\t\tgoto out_err_flow_rule;\n\n\t \n\treg = core_readl(priv, CORE_CFP_CTL_REG);\n\treg |= BIT(port);\n\tcore_writel(priv, reg, CORE_CFP_CTL_REG);\n\n\t \n\tset_bit(rule_index[0], priv->cfp.used);\n\tset_bit(rule_index[1], priv->cfp.unique);\n\tfs->location = rule_index[1];\n\n\treturn ret;\n\nout_err_flow_rule:\n\tethtool_rx_flow_rule_destroy(flow);\nout_err:\n\tclear_bit(rule_index[1], priv->cfp.used);\n\treturn ret;\n}\n\nstatic int bcm_sf2_cfp_rule_insert(struct dsa_switch *ds, int port,\n\t\t\t\t   struct ethtool_rx_flow_spec *fs)\n{\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\ts8 cpu_port = dsa_to_port(ds, port)->cpu_dp->index;\n\t__u64 ring_cookie = fs->ring_cookie;\n\tstruct switchdev_obj_port_vlan vlan;\n\tunsigned int queue_num, port_num;\n\tu16 vid;\n\tint ret;\n\n\t \n\tif (ring_cookie == RX_CLS_FLOW_WAKE)\n\t\tring_cookie = cpu_port * SF2_NUM_EGRESS_QUEUES;\n\n\t \n\tport_num = ring_cookie / SF2_NUM_EGRESS_QUEUES;\n\n\tif (ring_cookie == RX_CLS_FLOW_DISC ||\n\t    !(dsa_is_user_port(ds, port_num) ||\n\t      dsa_is_cpu_port(ds, port_num)) ||\n\t    port_num >= priv->hw_params.num_ports)\n\t\treturn -EINVAL;\n\n\t \n\tif (fs->flow_type & FLOW_EXT) {\n\t\t \n\t\tif ((be16_to_cpu(fs->m_ext.vlan_tci) & VLAN_VID_MASK) !=\n\t\t    VLAN_VID_MASK)\n\t\t\treturn -EINVAL;\n\n\t\tvid = be16_to_cpu(fs->h_ext.vlan_tci) & VLAN_VID_MASK;\n\t\tvlan.vid = vid;\n\t\tif (be32_to_cpu(fs->h_ext.data[1]) & 1)\n\t\t\tvlan.flags = BRIDGE_VLAN_INFO_UNTAGGED;\n\t\telse\n\t\t\tvlan.flags = 0;\n\n\t\tret = ds->ops->port_vlan_add(ds, port_num, &vlan, NULL);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t \n\tqueue_num = ring_cookie % SF2_NUM_EGRESS_QUEUES;\n\tif (port_num >= 7)\n\t\tport_num -= 1;\n\n\tswitch (fs->flow_type & ~FLOW_EXT) {\n\tcase TCP_V4_FLOW:\n\tcase UDP_V4_FLOW:\n\t\tret = bcm_sf2_cfp_ipv4_rule_set(priv, port, port_num,\n\t\t\t\t\t\tqueue_num, fs);\n\t\tbreak;\n\tcase TCP_V6_FLOW:\n\tcase UDP_V6_FLOW:\n\t\tret = bcm_sf2_cfp_ipv6_rule_set(priv, port, port_num,\n\t\t\t\t\t\tqueue_num, fs);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic int bcm_sf2_cfp_rule_set(struct dsa_switch *ds, int port,\n\t\t\t\tstruct ethtool_rx_flow_spec *fs)\n{\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\tstruct cfp_rule *rule = NULL;\n\tint ret = -EINVAL;\n\n\t \n\tif (fs->flow_type & FLOW_MAC_EXT)\n\t\treturn -EINVAL;\n\n\tif (fs->location != RX_CLS_LOC_ANY &&\n\t    fs->location > bcm_sf2_cfp_rule_size(priv))\n\t\treturn -EINVAL;\n\n\tif ((fs->flow_type & FLOW_EXT) &&\n\t    !(ds->ops->port_vlan_add || ds->ops->port_vlan_del))\n\t\treturn -EOPNOTSUPP;\n\n\tif (fs->location != RX_CLS_LOC_ANY &&\n\t    test_bit(fs->location, priv->cfp.used))\n\t\treturn -EBUSY;\n\n\tret = bcm_sf2_cfp_rule_cmp(priv, port, fs);\n\tif (ret == 0)\n\t\treturn -EEXIST;\n\n\trule = kzalloc(sizeof(*rule), GFP_KERNEL);\n\tif (!rule)\n\t\treturn -ENOMEM;\n\n\tret = bcm_sf2_cfp_rule_insert(ds, port, fs);\n\tif (ret) {\n\t\tkfree(rule);\n\t\treturn ret;\n\t}\n\n\trule->port = port;\n\tmemcpy(&rule->fs, fs, sizeof(*fs));\n\tlist_add_tail(&rule->next, &priv->cfp.rules_list);\n\n\treturn ret;\n}\n\nstatic int bcm_sf2_cfp_rule_del_one(struct bcm_sf2_priv *priv, int port,\n\t\t\t\t    u32 loc, u32 *next_loc)\n{\n\tint ret;\n\tu32 reg;\n\n\t \n\tbcm_sf2_cfp_rule_addr_set(priv, loc);\n\n\tret =  bcm_sf2_cfp_op(priv, OP_SEL_READ | TCAM_SEL);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\treg = core_readl(priv, CORE_CFP_DATA_PORT(6));\n\tif (next_loc)\n\t\t*next_loc = (reg >> 24) & CHAIN_ID_MASK;\n\n\t \n\treg = core_readl(priv, CORE_CFP_DATA_PORT(0));\n\treg &= ~SLICE_VALID;\n\tcore_writel(priv, reg, CORE_CFP_DATA_PORT(0));\n\n\t \n\tret = bcm_sf2_cfp_op(priv, OP_SEL_WRITE | TCAM_SEL);\n\tif (ret)\n\t\treturn ret;\n\n\tclear_bit(loc, priv->cfp.used);\n\tclear_bit(loc, priv->cfp.unique);\n\n\treturn 0;\n}\n\nstatic int bcm_sf2_cfp_rule_remove(struct bcm_sf2_priv *priv, int port,\n\t\t\t\t   u32 loc)\n{\n\tu32 next_loc = 0;\n\tint ret;\n\n\tret = bcm_sf2_cfp_rule_del_one(priv, port, loc, &next_loc);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (next_loc)\n\t\tret = bcm_sf2_cfp_rule_del_one(priv, port, next_loc, NULL);\n\n\treturn ret;\n}\n\nstatic int bcm_sf2_cfp_rule_del(struct bcm_sf2_priv *priv, int port, u32 loc)\n{\n\tstruct cfp_rule *rule;\n\tint ret;\n\n\tif (loc > bcm_sf2_cfp_rule_size(priv))\n\t\treturn -EINVAL;\n\n\t \n\tif (!test_bit(loc, priv->cfp.unique) || loc == 0)\n\t\treturn -EINVAL;\n\n\trule = bcm_sf2_cfp_rule_find(priv, port, loc);\n\tif (!rule)\n\t\treturn -EINVAL;\n\n\tret = bcm_sf2_cfp_rule_remove(priv, port, loc);\n\n\tlist_del(&rule->next);\n\tkfree(rule);\n\n\treturn ret;\n}\n\nstatic void bcm_sf2_invert_masks(struct ethtool_rx_flow_spec *flow)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < sizeof(flow->m_u); i++)\n\t\tflow->m_u.hdata[i] ^= 0xff;\n\n\tflow->m_ext.vlan_etype ^= cpu_to_be16(~0);\n\tflow->m_ext.vlan_tci ^= cpu_to_be16(~0);\n\tflow->m_ext.data[0] ^= cpu_to_be32(~0);\n\tflow->m_ext.data[1] ^= cpu_to_be32(~0);\n}\n\nstatic int bcm_sf2_cfp_rule_get(struct bcm_sf2_priv *priv, int port,\n\t\t\t\tstruct ethtool_rxnfc *nfc)\n{\n\tstruct cfp_rule *rule;\n\n\trule = bcm_sf2_cfp_rule_find(priv, port, nfc->fs.location);\n\tif (!rule)\n\t\treturn -EINVAL;\n\n\tmemcpy(&nfc->fs, &rule->fs, sizeof(rule->fs));\n\n\tbcm_sf2_invert_masks(&nfc->fs);\n\n\t \n\tnfc->data = bcm_sf2_cfp_rule_size(priv);\n\n\treturn 0;\n}\n\n \nstatic int bcm_sf2_cfp_rule_get_all(struct bcm_sf2_priv *priv,\n\t\t\t\t    int port, struct ethtool_rxnfc *nfc,\n\t\t\t\t    u32 *rule_locs)\n{\n\tunsigned int index = 1, rules_cnt = 0;\n\n\tfor_each_set_bit_from(index, priv->cfp.unique, priv->num_cfp_rules) {\n\t\trule_locs[rules_cnt] = index;\n\t\trules_cnt++;\n\t}\n\n\t \n\tnfc->data = bcm_sf2_cfp_rule_size(priv);\n\tnfc->rule_cnt = rules_cnt;\n\n\treturn 0;\n}\n\nint bcm_sf2_get_rxnfc(struct dsa_switch *ds, int port,\n\t\t      struct ethtool_rxnfc *nfc, u32 *rule_locs)\n{\n\tstruct net_device *p = dsa_port_to_master(dsa_to_port(ds, port));\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\tint ret = 0;\n\n\tmutex_lock(&priv->cfp.lock);\n\n\tswitch (nfc->cmd) {\n\tcase ETHTOOL_GRXCLSRLCNT:\n\t\t \n\t\tnfc->rule_cnt = bitmap_weight(priv->cfp.unique,\n\t\t\t\t\t      priv->num_cfp_rules) - 1;\n\t\t \n\t\tnfc->data |= RX_CLS_LOC_SPECIAL;\n\t\tbreak;\n\tcase ETHTOOL_GRXCLSRULE:\n\t\tret = bcm_sf2_cfp_rule_get(priv, port, nfc);\n\t\tbreak;\n\tcase ETHTOOL_GRXCLSRLALL:\n\t\tret = bcm_sf2_cfp_rule_get_all(priv, port, nfc, rule_locs);\n\t\tbreak;\n\tdefault:\n\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\n\tmutex_unlock(&priv->cfp.lock);\n\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (p->ethtool_ops->get_rxnfc) {\n\t\tret = p->ethtool_ops->get_rxnfc(p, nfc, rule_locs);\n\t\tif (ret == -EOPNOTSUPP)\n\t\t\tret = 0;\n\t}\n\n\treturn ret;\n}\n\nint bcm_sf2_set_rxnfc(struct dsa_switch *ds, int port,\n\t\t      struct ethtool_rxnfc *nfc)\n{\n\tstruct net_device *p = dsa_port_to_master(dsa_to_port(ds, port));\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\tint ret = 0;\n\n\tmutex_lock(&priv->cfp.lock);\n\n\tswitch (nfc->cmd) {\n\tcase ETHTOOL_SRXCLSRLINS:\n\t\tret = bcm_sf2_cfp_rule_set(ds, port, &nfc->fs);\n\t\tbreak;\n\n\tcase ETHTOOL_SRXCLSRLDEL:\n\t\tret = bcm_sf2_cfp_rule_del(priv, port, nfc->fs.location);\n\t\tbreak;\n\tdefault:\n\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\t}\n\n\tmutex_unlock(&priv->cfp.lock);\n\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tif (p->ethtool_ops->set_rxnfc) {\n\t\tret = p->ethtool_ops->set_rxnfc(p, nfc);\n\t\tif (ret && ret != -EOPNOTSUPP) {\n\t\t\tmutex_lock(&priv->cfp.lock);\n\t\t\tbcm_sf2_cfp_rule_del(priv, port, nfc->fs.location);\n\t\t\tmutex_unlock(&priv->cfp.lock);\n\t\t} else {\n\t\t\tret = 0;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nint bcm_sf2_cfp_rst(struct bcm_sf2_priv *priv)\n{\n\tunsigned int timeout = 1000;\n\tu32 reg;\n\n\treg = core_readl(priv, CORE_CFP_ACC);\n\treg |= TCAM_RESET;\n\tcore_writel(priv, reg, CORE_CFP_ACC);\n\n\tdo {\n\t\treg = core_readl(priv, CORE_CFP_ACC);\n\t\tif (!(reg & TCAM_RESET))\n\t\t\tbreak;\n\n\t\tcpu_relax();\n\t} while (timeout--);\n\n\tif (!timeout)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nvoid bcm_sf2_cfp_exit(struct dsa_switch *ds)\n{\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\tstruct cfp_rule *rule, *n;\n\n\tif (list_empty(&priv->cfp.rules_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe_reverse(rule, n, &priv->cfp.rules_list, next)\n\t\tbcm_sf2_cfp_rule_del(priv, rule->port, rule->fs.location);\n}\n\nint bcm_sf2_cfp_resume(struct dsa_switch *ds)\n{\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\tstruct cfp_rule *rule;\n\tint ret = 0;\n\tu32 reg;\n\n\tif (list_empty(&priv->cfp.rules_list))\n\t\treturn ret;\n\n\treg = core_readl(priv, CORE_CFP_CTL_REG);\n\treg &= ~CFP_EN_MAP_MASK;\n\tcore_writel(priv, reg, CORE_CFP_CTL_REG);\n\n\tret = bcm_sf2_cfp_rst(priv);\n\tif (ret)\n\t\treturn ret;\n\n\tlist_for_each_entry(rule, &priv->cfp.rules_list, next) {\n\t\tret = bcm_sf2_cfp_rule_remove(priv, rule->port,\n\t\t\t\t\t      rule->fs.location);\n\t\tif (ret) {\n\t\t\tdev_err(ds->dev, \"failed to remove rule\\n\");\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = bcm_sf2_cfp_rule_insert(ds, rule->port, &rule->fs);\n\t\tif (ret) {\n\t\t\tdev_err(ds->dev, \"failed to restore rule\\n\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic const struct bcm_sf2_cfp_stat {\n\tunsigned int offset;\n\tunsigned int ram_loc;\n\tconst char *name;\n} bcm_sf2_cfp_stats[] = {\n\t{\n\t\t.offset = CORE_STAT_GREEN_CNTR,\n\t\t.ram_loc = GREEN_STAT_RAM,\n\t\t.name = \"Green\"\n\t},\n\t{\n\t\t.offset = CORE_STAT_YELLOW_CNTR,\n\t\t.ram_loc = YELLOW_STAT_RAM,\n\t\t.name = \"Yellow\"\n\t},\n\t{\n\t\t.offset = CORE_STAT_RED_CNTR,\n\t\t.ram_loc = RED_STAT_RAM,\n\t\t.name = \"Red\"\n\t},\n};\n\nvoid bcm_sf2_cfp_get_strings(struct dsa_switch *ds, int port,\n\t\t\t     u32 stringset, uint8_t *data)\n{\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\tunsigned int s = ARRAY_SIZE(bcm_sf2_cfp_stats);\n\tchar buf[ETH_GSTRING_LEN];\n\tunsigned int i, j, iter;\n\n\tif (stringset != ETH_SS_STATS)\n\t\treturn;\n\n\tfor (i = 1; i < priv->num_cfp_rules; i++) {\n\t\tfor (j = 0; j < s; j++) {\n\t\t\tsnprintf(buf, sizeof(buf),\n\t\t\t\t \"CFP%03d_%sCntr\",\n\t\t\t\t i, bcm_sf2_cfp_stats[j].name);\n\t\t\titer = (i - 1) * s + j;\n\t\t\tstrscpy(data + iter * ETH_GSTRING_LEN,\n\t\t\t\tbuf, ETH_GSTRING_LEN);\n\t\t}\n\t}\n}\n\nvoid bcm_sf2_cfp_get_ethtool_stats(struct dsa_switch *ds, int port,\n\t\t\t\t   uint64_t *data)\n{\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\tunsigned int s = ARRAY_SIZE(bcm_sf2_cfp_stats);\n\tconst struct bcm_sf2_cfp_stat *stat;\n\tunsigned int i, j, iter;\n\tstruct cfp_rule *rule;\n\tint ret;\n\n\tmutex_lock(&priv->cfp.lock);\n\tfor (i = 1; i < priv->num_cfp_rules; i++) {\n\t\trule = bcm_sf2_cfp_rule_find(priv, port, i);\n\t\tif (!rule)\n\t\t\tcontinue;\n\n\t\tfor (j = 0; j < s; j++) {\n\t\t\tstat = &bcm_sf2_cfp_stats[j];\n\n\t\t\tbcm_sf2_cfp_rule_addr_set(priv, i);\n\t\t\tret = bcm_sf2_cfp_op(priv, stat->ram_loc | OP_SEL_READ);\n\t\t\tif (ret)\n\t\t\t\tcontinue;\n\n\t\t\titer = (i - 1) * s + j;\n\t\t\tdata[iter] = core_readl(priv, stat->offset);\n\t\t}\n\n\t}\n\tmutex_unlock(&priv->cfp.lock);\n}\n\nint bcm_sf2_cfp_get_sset_count(struct dsa_switch *ds, int port, int sset)\n{\n\tstruct bcm_sf2_priv *priv = bcm_sf2_to_priv(ds);\n\n\tif (sset != ETH_SS_STATS)\n\t\treturn 0;\n\n\t \n\treturn (priv->num_cfp_rules - 1) * ARRAY_SIZE(bcm_sf2_cfp_stats);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}