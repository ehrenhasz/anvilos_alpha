{
  "module_name": "vrf.c",
  "hash_id": "702a5fa73c91489c8c86146aa452c82206f3ce2506d7358351832303f2105282",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/vrf.c",
  "human_readable_source": "\n \n\n#include <linux/ethtool.h>\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ip.h>\n#include <linux/init.h>\n#include <linux/moduleparam.h>\n#include <linux/netfilter.h>\n#include <linux/rtnetlink.h>\n#include <net/rtnetlink.h>\n#include <linux/u64_stats_sync.h>\n#include <linux/hashtable.h>\n#include <linux/spinlock_types.h>\n\n#include <linux/inetdevice.h>\n#include <net/arp.h>\n#include <net/ip.h>\n#include <net/ip_fib.h>\n#include <net/ip6_fib.h>\n#include <net/ip6_route.h>\n#include <net/route.h>\n#include <net/addrconf.h>\n#include <net/l3mdev.h>\n#include <net/fib_rules.h>\n#include <net/sch_generic.h>\n#include <net/netns/generic.h>\n#include <net/netfilter/nf_conntrack.h>\n\n#define DRV_NAME\t\"vrf\"\n#define DRV_VERSION\t\"1.1\"\n\n#define FIB_RULE_PREF  1000        \n\n#define HT_MAP_BITS\t4\n#define HASH_INITVAL\t((u32)0xcafef00d)\n\nstruct  vrf_map {\n\tDECLARE_HASHTABLE(ht, HT_MAP_BITS);\n\tspinlock_t vmap_lock;\n\n\t \n\tu32 shared_tables;\n\n\tbool strict_mode;\n};\n\nstruct vrf_map_elem {\n\tstruct hlist_node hnode;\n\tstruct list_head vrf_list;   \n\n\tu32 table_id;\n\tint users;\n\tint ifindex;\n};\n\nstatic unsigned int vrf_net_id;\n\n \nstruct netns_vrf {\n\t \n\tbool add_fib_rules;\n\n\tstruct vrf_map vmap;\n\tstruct ctl_table_header\t*ctl_hdr;\n};\n\nstruct net_vrf {\n\tstruct rtable __rcu\t*rth;\n\tstruct rt6_info\t__rcu\t*rt6;\n#if IS_ENABLED(CONFIG_IPV6)\n\tstruct fib6_table\t*fib6_table;\n#endif\n\tu32                     tb_id;\n\n\tstruct list_head\tme_list;    \n\tint\t\t\tifindex;\n};\n\nstatic void vrf_rx_stats(struct net_device *dev, int len)\n{\n\tstruct pcpu_dstats *dstats = this_cpu_ptr(dev->dstats);\n\n\tu64_stats_update_begin(&dstats->syncp);\n\tdstats->rx_packets++;\n\tdstats->rx_bytes += len;\n\tu64_stats_update_end(&dstats->syncp);\n}\n\nstatic void vrf_tx_error(struct net_device *vrf_dev, struct sk_buff *skb)\n{\n\tvrf_dev->stats.tx_errors++;\n\tkfree_skb(skb);\n}\n\nstatic void vrf_get_stats64(struct net_device *dev,\n\t\t\t    struct rtnl_link_stats64 *stats)\n{\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tconst struct pcpu_dstats *dstats;\n\t\tu64 tbytes, tpkts, tdrops, rbytes, rpkts;\n\t\tunsigned int start;\n\n\t\tdstats = per_cpu_ptr(dev->dstats, i);\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&dstats->syncp);\n\t\t\ttbytes = dstats->tx_bytes;\n\t\t\ttpkts = dstats->tx_packets;\n\t\t\ttdrops = dstats->tx_drops;\n\t\t\trbytes = dstats->rx_bytes;\n\t\t\trpkts = dstats->rx_packets;\n\t\t} while (u64_stats_fetch_retry(&dstats->syncp, start));\n\t\tstats->tx_bytes += tbytes;\n\t\tstats->tx_packets += tpkts;\n\t\tstats->tx_dropped += tdrops;\n\t\tstats->rx_bytes += rbytes;\n\t\tstats->rx_packets += rpkts;\n\t}\n}\n\nstatic struct vrf_map *netns_vrf_map(struct net *net)\n{\n\tstruct netns_vrf *nn_vrf = net_generic(net, vrf_net_id);\n\n\treturn &nn_vrf->vmap;\n}\n\nstatic struct vrf_map *netns_vrf_map_by_dev(struct net_device *dev)\n{\n\treturn netns_vrf_map(dev_net(dev));\n}\n\nstatic int vrf_map_elem_get_vrf_ifindex(struct vrf_map_elem *me)\n{\n\tstruct list_head *me_head = &me->vrf_list;\n\tstruct net_vrf *vrf;\n\n\tif (list_empty(me_head))\n\t\treturn -ENODEV;\n\n\tvrf = list_first_entry(me_head, struct net_vrf, me_list);\n\n\treturn vrf->ifindex;\n}\n\nstatic struct vrf_map_elem *vrf_map_elem_alloc(gfp_t flags)\n{\n\tstruct vrf_map_elem *me;\n\n\tme = kmalloc(sizeof(*me), flags);\n\tif (!me)\n\t\treturn NULL;\n\n\treturn me;\n}\n\nstatic void vrf_map_elem_free(struct vrf_map_elem *me)\n{\n\tkfree(me);\n}\n\nstatic void vrf_map_elem_init(struct vrf_map_elem *me, int table_id,\n\t\t\t      int ifindex, int users)\n{\n\tme->table_id = table_id;\n\tme->ifindex = ifindex;\n\tme->users = users;\n\tINIT_LIST_HEAD(&me->vrf_list);\n}\n\nstatic struct vrf_map_elem *vrf_map_lookup_elem(struct vrf_map *vmap,\n\t\t\t\t\t\tu32 table_id)\n{\n\tstruct vrf_map_elem *me;\n\tu32 key;\n\n\tkey = jhash_1word(table_id, HASH_INITVAL);\n\thash_for_each_possible(vmap->ht, me, hnode, key) {\n\t\tif (me->table_id == table_id)\n\t\t\treturn me;\n\t}\n\n\treturn NULL;\n}\n\nstatic void vrf_map_add_elem(struct vrf_map *vmap, struct vrf_map_elem *me)\n{\n\tu32 table_id = me->table_id;\n\tu32 key;\n\n\tkey = jhash_1word(table_id, HASH_INITVAL);\n\thash_add(vmap->ht, &me->hnode, key);\n}\n\nstatic void vrf_map_del_elem(struct vrf_map_elem *me)\n{\n\thash_del(&me->hnode);\n}\n\nstatic void vrf_map_lock(struct vrf_map *vmap) __acquires(&vmap->vmap_lock)\n{\n\tspin_lock(&vmap->vmap_lock);\n}\n\nstatic void vrf_map_unlock(struct vrf_map *vmap) __releases(&vmap->vmap_lock)\n{\n\tspin_unlock(&vmap->vmap_lock);\n}\n\n \nstatic int\nvrf_map_register_dev(struct net_device *dev, struct netlink_ext_ack *extack)\n{\n\tstruct vrf_map *vmap = netns_vrf_map_by_dev(dev);\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\tstruct vrf_map_elem *new_me, *me;\n\tu32 table_id = vrf->tb_id;\n\tbool free_new_me = false;\n\tint users;\n\tint res;\n\n\t \n\tnew_me = vrf_map_elem_alloc(GFP_KERNEL);\n\tif (!new_me)\n\t\treturn -ENOMEM;\n\n\tvrf_map_elem_init(new_me, table_id, dev->ifindex, 0);\n\n\tvrf_map_lock(vmap);\n\n\tme = vrf_map_lookup_elem(vmap, table_id);\n\tif (!me) {\n\t\tme = new_me;\n\t\tvrf_map_add_elem(vmap, me);\n\t\tgoto link_vrf;\n\t}\n\n\t \n\tfree_new_me = true;\n\tif (vmap->strict_mode) {\n\t\t \n\t\tNL_SET_ERR_MSG(extack, \"Table is used by another VRF\");\n\t\tres = -EBUSY;\n\t\tgoto unlock;\n\t}\n\nlink_vrf:\n\tusers = ++me->users;\n\tif (users == 2)\n\t\t++vmap->shared_tables;\n\n\tlist_add(&vrf->me_list, &me->vrf_list);\n\n\tres = 0;\n\nunlock:\n\tvrf_map_unlock(vmap);\n\n\t \n\tif (free_new_me)\n\t\tvrf_map_elem_free(new_me);\n\n\treturn res;\n}\n\n \nstatic void vrf_map_unregister_dev(struct net_device *dev)\n{\n\tstruct vrf_map *vmap = netns_vrf_map_by_dev(dev);\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\tu32 table_id = vrf->tb_id;\n\tstruct vrf_map_elem *me;\n\tint users;\n\n\tvrf_map_lock(vmap);\n\n\tme = vrf_map_lookup_elem(vmap, table_id);\n\tif (!me)\n\t\tgoto unlock;\n\n\tlist_del(&vrf->me_list);\n\n\tusers = --me->users;\n\tif (users == 1) {\n\t\t--vmap->shared_tables;\n\t} else if (users == 0) {\n\t\tvrf_map_del_elem(me);\n\n\t\t \n\t\tvrf_map_elem_free(me);\n\t}\n\nunlock:\n\tvrf_map_unlock(vmap);\n}\n\n \nstatic int vrf_ifindex_lookup_by_table_id(struct net *net, u32 table_id)\n{\n\tstruct vrf_map *vmap = netns_vrf_map(net);\n\tstruct vrf_map_elem *me;\n\tint ifindex;\n\n\tvrf_map_lock(vmap);\n\n\tif (!vmap->strict_mode) {\n\t\tifindex = -EPERM;\n\t\tgoto unlock;\n\t}\n\n\tme = vrf_map_lookup_elem(vmap, table_id);\n\tif (!me) {\n\t\tifindex = -ENODEV;\n\t\tgoto unlock;\n\t}\n\n\tifindex = vrf_map_elem_get_vrf_ifindex(me);\n\nunlock:\n\tvrf_map_unlock(vmap);\n\n\treturn ifindex;\n}\n\n \nstatic bool qdisc_tx_is_default(const struct net_device *dev)\n{\n\tstruct netdev_queue *txq;\n\tstruct Qdisc *qdisc;\n\n\tif (dev->num_tx_queues > 1)\n\t\treturn false;\n\n\ttxq = netdev_get_tx_queue(dev, 0);\n\tqdisc = rcu_access_pointer(txq->qdisc);\n\n\treturn !qdisc->enqueue;\n}\n\n \nstatic int vrf_local_xmit(struct sk_buff *skb, struct net_device *dev,\n\t\t\t  struct dst_entry *dst)\n{\n\tint len = skb->len;\n\n\tskb_orphan(skb);\n\n\tskb_dst_set(skb, dst);\n\n\t \n\tskb->pkt_type = PACKET_LOOPBACK;\n\n\tskb->protocol = eth_type_trans(skb, dev);\n\n\tif (likely(__netif_rx(skb) == NET_RX_SUCCESS))\n\t\tvrf_rx_stats(dev, len);\n\telse\n\t\tthis_cpu_inc(dev->dstats->rx_drops);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void vrf_nf_set_untracked(struct sk_buff *skb)\n{\n\tif (skb_get_nfct(skb) == 0)\n\t\tnf_ct_set(skb, NULL, IP_CT_UNTRACKED);\n}\n\nstatic void vrf_nf_reset_ct(struct sk_buff *skb)\n{\n\tif (skb_get_nfct(skb) == IP_CT_UNTRACKED)\n\t\tnf_reset_ct(skb);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\nstatic int vrf_ip6_local_out(struct net *net, struct sock *sk,\n\t\t\t     struct sk_buff *skb)\n{\n\tint err;\n\n\tvrf_nf_reset_ct(skb);\n\n\terr = nf_hook(NFPROTO_IPV6, NF_INET_LOCAL_OUT, net,\n\t\t      sk, skb, NULL, skb_dst(skb)->dev, dst_output);\n\n\tif (likely(err == 1))\n\t\terr = dst_output(net, sk, skb);\n\n\treturn err;\n}\n\nstatic netdev_tx_t vrf_process_v6_outbound(struct sk_buff *skb,\n\t\t\t\t\t   struct net_device *dev)\n{\n\tconst struct ipv6hdr *iph;\n\tstruct net *net = dev_net(skb->dev);\n\tstruct flowi6 fl6;\n\tint ret = NET_XMIT_DROP;\n\tstruct dst_entry *dst;\n\tstruct dst_entry *dst_null = &net->ipv6.ip6_null_entry->dst;\n\n\tif (!pskb_may_pull(skb, ETH_HLEN + sizeof(struct ipv6hdr)))\n\t\tgoto err;\n\n\tiph = ipv6_hdr(skb);\n\n\tmemset(&fl6, 0, sizeof(fl6));\n\t \n\tfl6.flowi6_l3mdev = dev->ifindex;\n\tfl6.flowi6_iif = LOOPBACK_IFINDEX;\n\tfl6.daddr = iph->daddr;\n\tfl6.saddr = iph->saddr;\n\tfl6.flowlabel = ip6_flowinfo(iph);\n\tfl6.flowi6_mark = skb->mark;\n\tfl6.flowi6_proto = iph->nexthdr;\n\n\tdst = ip6_dst_lookup_flow(net, NULL, &fl6, NULL);\n\tif (IS_ERR(dst) || dst == dst_null)\n\t\tgoto err;\n\n\tskb_dst_drop(skb);\n\n\t \n\tif (dst->dev == dev)\n\t\treturn vrf_local_xmit(skb, dev, dst);\n\n\tskb_dst_set(skb, dst);\n\n\t \n\t__skb_pull(skb, skb_network_offset(skb));\n\n\tmemset(IP6CB(skb), 0, sizeof(*IP6CB(skb)));\n\tret = vrf_ip6_local_out(net, skb->sk, skb);\n\tif (unlikely(net_xmit_eval(ret)))\n\t\tdev->stats.tx_errors++;\n\telse\n\t\tret = NET_XMIT_SUCCESS;\n\n\treturn ret;\nerr:\n\tvrf_tx_error(dev, skb);\n\treturn NET_XMIT_DROP;\n}\n#else\nstatic netdev_tx_t vrf_process_v6_outbound(struct sk_buff *skb,\n\t\t\t\t\t   struct net_device *dev)\n{\n\tvrf_tx_error(dev, skb);\n\treturn NET_XMIT_DROP;\n}\n#endif\n\n \nstatic int vrf_ip_local_out(struct net *net, struct sock *sk,\n\t\t\t    struct sk_buff *skb)\n{\n\tint err;\n\n\tvrf_nf_reset_ct(skb);\n\n\terr = nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT, net, sk,\n\t\t      skb, NULL, skb_dst(skb)->dev, dst_output);\n\tif (likely(err == 1))\n\t\terr = dst_output(net, sk, skb);\n\n\treturn err;\n}\n\nstatic netdev_tx_t vrf_process_v4_outbound(struct sk_buff *skb,\n\t\t\t\t\t   struct net_device *vrf_dev)\n{\n\tstruct iphdr *ip4h;\n\tint ret = NET_XMIT_DROP;\n\tstruct flowi4 fl4;\n\tstruct net *net = dev_net(vrf_dev);\n\tstruct rtable *rt;\n\n\tif (!pskb_may_pull(skb, ETH_HLEN + sizeof(struct iphdr)))\n\t\tgoto err;\n\n\tip4h = ip_hdr(skb);\n\n\tmemset(&fl4, 0, sizeof(fl4));\n\t \n\tfl4.flowi4_l3mdev = vrf_dev->ifindex;\n\tfl4.flowi4_iif = LOOPBACK_IFINDEX;\n\tfl4.flowi4_tos = RT_TOS(ip4h->tos);\n\tfl4.flowi4_flags = FLOWI_FLAG_ANYSRC;\n\tfl4.flowi4_proto = ip4h->protocol;\n\tfl4.daddr = ip4h->daddr;\n\tfl4.saddr = ip4h->saddr;\n\n\trt = ip_route_output_flow(net, &fl4, NULL);\n\tif (IS_ERR(rt))\n\t\tgoto err;\n\n\tskb_dst_drop(skb);\n\n\t \n\tif (rt->dst.dev == vrf_dev)\n\t\treturn vrf_local_xmit(skb, vrf_dev, &rt->dst);\n\n\tskb_dst_set(skb, &rt->dst);\n\n\t \n\t__skb_pull(skb, skb_network_offset(skb));\n\n\tif (!ip4h->saddr) {\n\t\tip4h->saddr = inet_select_addr(skb_dst(skb)->dev, 0,\n\t\t\t\t\t       RT_SCOPE_LINK);\n\t}\n\n\tmemset(IPCB(skb), 0, sizeof(*IPCB(skb)));\n\tret = vrf_ip_local_out(dev_net(skb_dst(skb)->dev), skb->sk, skb);\n\tif (unlikely(net_xmit_eval(ret)))\n\t\tvrf_dev->stats.tx_errors++;\n\telse\n\t\tret = NET_XMIT_SUCCESS;\n\nout:\n\treturn ret;\nerr:\n\tvrf_tx_error(vrf_dev, skb);\n\tgoto out;\n}\n\nstatic netdev_tx_t is_ip_tx_frame(struct sk_buff *skb, struct net_device *dev)\n{\n\tswitch (skb->protocol) {\n\tcase htons(ETH_P_IP):\n\t\treturn vrf_process_v4_outbound(skb, dev);\n\tcase htons(ETH_P_IPV6):\n\t\treturn vrf_process_v6_outbound(skb, dev);\n\tdefault:\n\t\tvrf_tx_error(dev, skb);\n\t\treturn NET_XMIT_DROP;\n\t}\n}\n\nstatic netdev_tx_t vrf_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tint len = skb->len;\n\tnetdev_tx_t ret = is_ip_tx_frame(skb, dev);\n\n\tif (likely(ret == NET_XMIT_SUCCESS || ret == NET_XMIT_CN)) {\n\t\tstruct pcpu_dstats *dstats = this_cpu_ptr(dev->dstats);\n\n\t\tu64_stats_update_begin(&dstats->syncp);\n\t\tdstats->tx_packets++;\n\t\tdstats->tx_bytes += len;\n\t\tu64_stats_update_end(&dstats->syncp);\n\t} else {\n\t\tthis_cpu_inc(dev->dstats->tx_drops);\n\t}\n\n\treturn ret;\n}\n\nstatic void vrf_finish_direct(struct sk_buff *skb)\n{\n\tstruct net_device *vrf_dev = skb->dev;\n\n\tif (!list_empty(&vrf_dev->ptype_all) &&\n\t    likely(skb_headroom(skb) >= ETH_HLEN)) {\n\t\tstruct ethhdr *eth = skb_push(skb, ETH_HLEN);\n\n\t\tether_addr_copy(eth->h_source, vrf_dev->dev_addr);\n\t\teth_zero_addr(eth->h_dest);\n\t\teth->h_proto = skb->protocol;\n\n\t\tdev_queue_xmit_nit(skb, vrf_dev);\n\n\t\tskb_pull(skb, ETH_HLEN);\n\t}\n\n\tvrf_nf_reset_ct(skb);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\n \nstatic int vrf_finish_output6(struct net *net, struct sock *sk,\n\t\t\t      struct sk_buff *skb)\n{\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct net_device *dev = dst->dev;\n\tconst struct in6_addr *nexthop;\n\tstruct neighbour *neigh;\n\tint ret;\n\n\tvrf_nf_reset_ct(skb);\n\n\tskb->protocol = htons(ETH_P_IPV6);\n\tskb->dev = dev;\n\n\trcu_read_lock();\n\tnexthop = rt6_nexthop((struct rt6_info *)dst, &ipv6_hdr(skb)->daddr);\n\tneigh = __ipv6_neigh_lookup_noref(dst->dev, nexthop);\n\tif (unlikely(!neigh))\n\t\tneigh = __neigh_create(&nd_tbl, nexthop, dst->dev, false);\n\tif (!IS_ERR(neigh)) {\n\t\tsock_confirm_neigh(skb, neigh);\n\t\tret = neigh_output(neigh, skb, false);\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\trcu_read_unlock();\n\n\tIP6_INC_STATS(dev_net(dst->dev),\n\t\t      ip6_dst_idev(dst), IPSTATS_MIB_OUTNOROUTES);\n\tkfree_skb(skb);\n\treturn -EINVAL;\n}\n\n \nstatic int vrf_output6(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\treturn NF_HOOK_COND(NFPROTO_IPV6, NF_INET_POST_ROUTING,\n\t\t\t    net, sk, skb, NULL, skb_dst(skb)->dev,\n\t\t\t    vrf_finish_output6,\n\t\t\t    !(IP6CB(skb)->flags & IP6SKB_REROUTED));\n}\n\n \nstatic struct sk_buff *vrf_ip6_out_redirect(struct net_device *vrf_dev,\n\t\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct net_vrf *vrf = netdev_priv(vrf_dev);\n\tstruct dst_entry *dst = NULL;\n\tstruct rt6_info *rt6;\n\n\trcu_read_lock();\n\n\trt6 = rcu_dereference(vrf->rt6);\n\tif (likely(rt6)) {\n\t\tdst = &rt6->dst;\n\t\tdst_hold(dst);\n\t}\n\n\trcu_read_unlock();\n\n\tif (unlikely(!dst)) {\n\t\tvrf_tx_error(vrf_dev, skb);\n\t\treturn NULL;\n\t}\n\n\tskb_dst_drop(skb);\n\tskb_dst_set(skb, dst);\n\n\treturn skb;\n}\n\nstatic int vrf_output6_direct_finish(struct net *net, struct sock *sk,\n\t\t\t\t     struct sk_buff *skb)\n{\n\tvrf_finish_direct(skb);\n\n\treturn vrf_ip6_local_out(net, sk, skb);\n}\n\nstatic int vrf_output6_direct(struct net *net, struct sock *sk,\n\t\t\t      struct sk_buff *skb)\n{\n\tint err = 1;\n\n\tskb->protocol = htons(ETH_P_IPV6);\n\n\tif (!(IPCB(skb)->flags & IPSKB_REROUTED))\n\t\terr = nf_hook(NFPROTO_IPV6, NF_INET_POST_ROUTING, net, sk, skb,\n\t\t\t      NULL, skb->dev, vrf_output6_direct_finish);\n\n\tif (likely(err == 1))\n\t\tvrf_finish_direct(skb);\n\n\treturn err;\n}\n\nstatic int vrf_ip6_out_direct_finish(struct net *net, struct sock *sk,\n\t\t\t\t     struct sk_buff *skb)\n{\n\tint err;\n\n\terr = vrf_output6_direct(net, sk, skb);\n\tif (likely(err == 1))\n\t\terr = vrf_ip6_local_out(net, sk, skb);\n\n\treturn err;\n}\n\nstatic struct sk_buff *vrf_ip6_out_direct(struct net_device *vrf_dev,\n\t\t\t\t\t  struct sock *sk,\n\t\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct net *net = dev_net(vrf_dev);\n\tint err;\n\n\tskb->dev = vrf_dev;\n\n\terr = nf_hook(NFPROTO_IPV6, NF_INET_LOCAL_OUT, net, sk,\n\t\t      skb, NULL, vrf_dev, vrf_ip6_out_direct_finish);\n\n\tif (likely(err == 1))\n\t\terr = vrf_output6_direct(net, sk, skb);\n\n\tif (likely(err == 1))\n\t\treturn skb;\n\n\treturn NULL;\n}\n\nstatic struct sk_buff *vrf_ip6_out(struct net_device *vrf_dev,\n\t\t\t\t   struct sock *sk,\n\t\t\t\t   struct sk_buff *skb)\n{\n\t \n\tif (rt6_need_strict(&ipv6_hdr(skb)->daddr))\n\t\treturn skb;\n\n\tvrf_nf_set_untracked(skb);\n\n\tif (qdisc_tx_is_default(vrf_dev) ||\n\t    IP6CB(skb)->flags & IP6SKB_XFRM_TRANSFORMED)\n\t\treturn vrf_ip6_out_direct(vrf_dev, sk, skb);\n\n\treturn vrf_ip6_out_redirect(vrf_dev, skb);\n}\n\n \nstatic void vrf_rt6_release(struct net_device *dev, struct net_vrf *vrf)\n{\n\tstruct rt6_info *rt6 = rtnl_dereference(vrf->rt6);\n\tstruct net *net = dev_net(dev);\n\tstruct dst_entry *dst;\n\n\tRCU_INIT_POINTER(vrf->rt6, NULL);\n\tsynchronize_rcu();\n\n\t \n\tif (rt6) {\n\t\tdst = &rt6->dst;\n\t\tnetdev_ref_replace(dst->dev, net->loopback_dev,\n\t\t\t\t   &dst->dev_tracker, GFP_KERNEL);\n\t\tdst->dev = net->loopback_dev;\n\t\tdst_release(dst);\n\t}\n}\n\nstatic int vrf_rt6_create(struct net_device *dev)\n{\n\tint flags = DST_NOPOLICY | DST_NOXFRM;\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\tstruct net *net = dev_net(dev);\n\tstruct rt6_info *rt6;\n\tint rc = -ENOMEM;\n\n\t \n\tif (!ipv6_mod_enabled())\n\t\treturn 0;\n\n\tvrf->fib6_table = fib6_new_table(net, vrf->tb_id);\n\tif (!vrf->fib6_table)\n\t\tgoto out;\n\n\t \n\trt6 = ip6_dst_alloc(net, dev, flags);\n\tif (!rt6)\n\t\tgoto out;\n\n\trt6->dst.output\t= vrf_output6;\n\n\trcu_assign_pointer(vrf->rt6, rt6);\n\n\trc = 0;\nout:\n\treturn rc;\n}\n#else\nstatic struct sk_buff *vrf_ip6_out(struct net_device *vrf_dev,\n\t\t\t\t   struct sock *sk,\n\t\t\t\t   struct sk_buff *skb)\n{\n\treturn skb;\n}\n\nstatic void vrf_rt6_release(struct net_device *dev, struct net_vrf *vrf)\n{\n}\n\nstatic int vrf_rt6_create(struct net_device *dev)\n{\n\treturn 0;\n}\n#endif\n\n \nstatic int vrf_finish_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct dst_entry *dst = skb_dst(skb);\n\tstruct rtable *rt = (struct rtable *)dst;\n\tstruct net_device *dev = dst->dev;\n\tunsigned int hh_len = LL_RESERVED_SPACE(dev);\n\tstruct neighbour *neigh;\n\tbool is_v6gw = false;\n\n\tvrf_nf_reset_ct(skb);\n\n\t \n\tif (unlikely(skb_headroom(skb) < hh_len && dev->header_ops)) {\n\t\tskb = skb_expand_head(skb, hh_len);\n\t\tif (!skb) {\n\t\t\tdev->stats.tx_errors++;\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\trcu_read_lock();\n\n\tneigh = ip_neigh_for_gw(rt, skb, &is_v6gw);\n\tif (!IS_ERR(neigh)) {\n\t\tint ret;\n\n\t\tsock_confirm_neigh(skb, neigh);\n\t\t \n\t\tret = neigh_output(neigh, skb, is_v6gw);\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\n\trcu_read_unlock();\n\tvrf_tx_error(skb->dev, skb);\n\treturn -EINVAL;\n}\n\nstatic int vrf_output(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tstruct net_device *dev = skb_dst(skb)->dev;\n\n\tIP_UPD_PO_STATS(net, IPSTATS_MIB_OUT, skb->len);\n\n\tskb->dev = dev;\n\tskb->protocol = htons(ETH_P_IP);\n\n\treturn NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING,\n\t\t\t    net, sk, skb, NULL, dev,\n\t\t\t    vrf_finish_output,\n\t\t\t    !(IPCB(skb)->flags & IPSKB_REROUTED));\n}\n\n \nstatic struct sk_buff *vrf_ip_out_redirect(struct net_device *vrf_dev,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct net_vrf *vrf = netdev_priv(vrf_dev);\n\tstruct dst_entry *dst = NULL;\n\tstruct rtable *rth;\n\n\trcu_read_lock();\n\n\trth = rcu_dereference(vrf->rth);\n\tif (likely(rth)) {\n\t\tdst = &rth->dst;\n\t\tdst_hold(dst);\n\t}\n\n\trcu_read_unlock();\n\n\tif (unlikely(!dst)) {\n\t\tvrf_tx_error(vrf_dev, skb);\n\t\treturn NULL;\n\t}\n\n\tskb_dst_drop(skb);\n\tskb_dst_set(skb, dst);\n\n\treturn skb;\n}\n\nstatic int vrf_output_direct_finish(struct net *net, struct sock *sk,\n\t\t\t\t    struct sk_buff *skb)\n{\n\tvrf_finish_direct(skb);\n\n\treturn vrf_ip_local_out(net, sk, skb);\n}\n\nstatic int vrf_output_direct(struct net *net, struct sock *sk,\n\t\t\t     struct sk_buff *skb)\n{\n\tint err = 1;\n\n\tskb->protocol = htons(ETH_P_IP);\n\n\tif (!(IPCB(skb)->flags & IPSKB_REROUTED))\n\t\terr = nf_hook(NFPROTO_IPV4, NF_INET_POST_ROUTING, net, sk, skb,\n\t\t\t      NULL, skb->dev, vrf_output_direct_finish);\n\n\tif (likely(err == 1))\n\t\tvrf_finish_direct(skb);\n\n\treturn err;\n}\n\nstatic int vrf_ip_out_direct_finish(struct net *net, struct sock *sk,\n\t\t\t\t    struct sk_buff *skb)\n{\n\tint err;\n\n\terr = vrf_output_direct(net, sk, skb);\n\tif (likely(err == 1))\n\t\terr = vrf_ip_local_out(net, sk, skb);\n\n\treturn err;\n}\n\nstatic struct sk_buff *vrf_ip_out_direct(struct net_device *vrf_dev,\n\t\t\t\t\t struct sock *sk,\n\t\t\t\t\t struct sk_buff *skb)\n{\n\tstruct net *net = dev_net(vrf_dev);\n\tint err;\n\n\tskb->dev = vrf_dev;\n\n\terr = nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT, net, sk,\n\t\t      skb, NULL, vrf_dev, vrf_ip_out_direct_finish);\n\n\tif (likely(err == 1))\n\t\terr = vrf_output_direct(net, sk, skb);\n\n\tif (likely(err == 1))\n\t\treturn skb;\n\n\treturn NULL;\n}\n\nstatic struct sk_buff *vrf_ip_out(struct net_device *vrf_dev,\n\t\t\t\t  struct sock *sk,\n\t\t\t\t  struct sk_buff *skb)\n{\n\t \n\tif (ipv4_is_multicast(ip_hdr(skb)->daddr) ||\n\t    ipv4_is_lbcast(ip_hdr(skb)->daddr))\n\t\treturn skb;\n\n\tvrf_nf_set_untracked(skb);\n\n\tif (qdisc_tx_is_default(vrf_dev) ||\n\t    IPCB(skb)->flags & IPSKB_XFRM_TRANSFORMED)\n\t\treturn vrf_ip_out_direct(vrf_dev, sk, skb);\n\n\treturn vrf_ip_out_redirect(vrf_dev, skb);\n}\n\n \nstatic struct sk_buff *vrf_l3_out(struct net_device *vrf_dev,\n\t\t\t\t  struct sock *sk,\n\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t  u16 proto)\n{\n\tswitch (proto) {\n\tcase AF_INET:\n\t\treturn vrf_ip_out(vrf_dev, sk, skb);\n\tcase AF_INET6:\n\t\treturn vrf_ip6_out(vrf_dev, sk, skb);\n\t}\n\n\treturn skb;\n}\n\n \nstatic void vrf_rtable_release(struct net_device *dev, struct net_vrf *vrf)\n{\n\tstruct rtable *rth = rtnl_dereference(vrf->rth);\n\tstruct net *net = dev_net(dev);\n\tstruct dst_entry *dst;\n\n\tRCU_INIT_POINTER(vrf->rth, NULL);\n\tsynchronize_rcu();\n\n\t \n\tif (rth) {\n\t\tdst = &rth->dst;\n\t\tnetdev_ref_replace(dst->dev, net->loopback_dev,\n\t\t\t\t   &dst->dev_tracker, GFP_KERNEL);\n\t\tdst->dev = net->loopback_dev;\n\t\tdst_release(dst);\n\t}\n}\n\nstatic int vrf_rtable_create(struct net_device *dev)\n{\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\tstruct rtable *rth;\n\n\tif (!fib_new_table(dev_net(dev), vrf->tb_id))\n\t\treturn -ENOMEM;\n\n\t \n\trth = rt_dst_alloc(dev, 0, RTN_UNICAST, 1);\n\tif (!rth)\n\t\treturn -ENOMEM;\n\n\trth->dst.output\t= vrf_output;\n\n\trcu_assign_pointer(vrf->rth, rth);\n\n\treturn 0;\n}\n\n \n\n \nstatic void cycle_netdev(struct net_device *dev,\n\t\t\t struct netlink_ext_ack *extack)\n{\n\tunsigned int flags = dev->flags;\n\tint ret;\n\n\tif (!netif_running(dev))\n\t\treturn;\n\n\tret = dev_change_flags(dev, flags & ~IFF_UP, extack);\n\tif (ret >= 0)\n\t\tret = dev_change_flags(dev, flags, extack);\n\n\tif (ret < 0) {\n\t\tnetdev_err(dev,\n\t\t\t   \"Failed to cycle device %s; route tables might be wrong!\\n\",\n\t\t\t   dev->name);\n\t}\n}\n\nstatic int do_vrf_add_slave(struct net_device *dev, struct net_device *port_dev,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tint ret;\n\n\t \n\tif (port_dev == dev_net(dev)->loopback_dev) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Can not enslave loopback device to a VRF\");\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tport_dev->priv_flags |= IFF_L3MDEV_SLAVE;\n\tret = netdev_master_upper_dev_link(port_dev, dev, NULL, NULL, extack);\n\tif (ret < 0)\n\t\tgoto err;\n\n\tcycle_netdev(port_dev, extack);\n\n\treturn 0;\n\nerr:\n\tport_dev->priv_flags &= ~IFF_L3MDEV_SLAVE;\n\treturn ret;\n}\n\nstatic int vrf_add_slave(struct net_device *dev, struct net_device *port_dev,\n\t\t\t struct netlink_ext_ack *extack)\n{\n\tif (netif_is_l3_master(port_dev)) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"Can not enslave an L3 master device to a VRF\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (netif_is_l3_slave(port_dev))\n\t\treturn -EINVAL;\n\n\treturn do_vrf_add_slave(dev, port_dev, extack);\n}\n\n \nstatic int do_vrf_del_slave(struct net_device *dev, struct net_device *port_dev)\n{\n\tnetdev_upper_dev_unlink(port_dev, dev);\n\tport_dev->priv_flags &= ~IFF_L3MDEV_SLAVE;\n\n\tcycle_netdev(port_dev, NULL);\n\n\treturn 0;\n}\n\nstatic int vrf_del_slave(struct net_device *dev, struct net_device *port_dev)\n{\n\treturn do_vrf_del_slave(dev, port_dev);\n}\n\nstatic void vrf_dev_uninit(struct net_device *dev)\n{\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\n\tvrf_rtable_release(dev, vrf);\n\tvrf_rt6_release(dev, vrf);\n}\n\nstatic int vrf_dev_init(struct net_device *dev)\n{\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\n\t \n\tif (vrf_rtable_create(dev) != 0)\n\t\tgoto out_nomem;\n\n\tif (vrf_rt6_create(dev) != 0)\n\t\tgoto out_rth;\n\n\tdev->flags = IFF_MASTER | IFF_NOARP;\n\n\t \n\tdev->operstate = IF_OPER_UP;\n\tnetdev_lockdep_set_classes(dev);\n\treturn 0;\n\nout_rth:\n\tvrf_rtable_release(dev, vrf);\nout_nomem:\n\treturn -ENOMEM;\n}\n\nstatic const struct net_device_ops vrf_netdev_ops = {\n\t.ndo_init\t\t= vrf_dev_init,\n\t.ndo_uninit\t\t= vrf_dev_uninit,\n\t.ndo_start_xmit\t\t= vrf_xmit,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n\t.ndo_get_stats64\t= vrf_get_stats64,\n\t.ndo_add_slave\t\t= vrf_add_slave,\n\t.ndo_del_slave\t\t= vrf_del_slave,\n};\n\nstatic u32 vrf_fib_table(const struct net_device *dev)\n{\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\n\treturn vrf->tb_id;\n}\n\nstatic int vrf_rcv_finish(struct net *net, struct sock *sk, struct sk_buff *skb)\n{\n\tkfree_skb(skb);\n\treturn 0;\n}\n\nstatic struct sk_buff *vrf_rcv_nfhook(u8 pf, unsigned int hook,\n\t\t\t\t      struct sk_buff *skb,\n\t\t\t\t      struct net_device *dev)\n{\n\tstruct net *net = dev_net(dev);\n\n\tif (nf_hook(pf, hook, net, NULL, skb, dev, NULL, vrf_rcv_finish) != 1)\n\t\tskb = NULL;     \n\n\treturn skb;\n}\n\nstatic int vrf_prepare_mac_header(struct sk_buff *skb,\n\t\t\t\t  struct net_device *vrf_dev, u16 proto)\n{\n\tstruct ethhdr *eth;\n\tint err;\n\n\t \n\terr = skb_cow_head(skb, LL_RESERVED_SPACE(vrf_dev));\n\tif (unlikely(err))\n\t\t \n\t\treturn -ENOBUFS;\n\n\t__skb_push(skb, ETH_HLEN);\n\teth = (struct ethhdr *)skb->data;\n\n\tskb_reset_mac_header(skb);\n\tskb_reset_mac_len(skb);\n\n\t \n\tether_addr_copy(eth->h_dest, vrf_dev->dev_addr);\n\tether_addr_copy(eth->h_source, vrf_dev->dev_addr);\n\teth->h_proto = htons(proto);\n\n\t \n\tskb->protocol = eth->h_proto;\n\tskb->pkt_type = PACKET_HOST;\n\n\tskb_postpush_rcsum(skb, skb->data, ETH_HLEN);\n\n\tskb_pull_inline(skb, ETH_HLEN);\n\n\treturn 0;\n}\n\n \nstatic int vrf_add_mac_header_if_unset(struct sk_buff *skb,\n\t\t\t\t       struct net_device *vrf_dev,\n\t\t\t\t       u16 proto, struct net_device *orig_dev)\n{\n\tif (skb_mac_header_was_set(skb) && dev_has_header(orig_dev))\n\t\treturn 0;\n\n\treturn vrf_prepare_mac_header(skb, vrf_dev, proto);\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\n \nstatic bool ipv6_ndisc_frame(const struct sk_buff *skb)\n{\n\tconst struct ipv6hdr *iph = ipv6_hdr(skb);\n\tbool rc = false;\n\n\tif (iph->nexthdr == NEXTHDR_ICMP) {\n\t\tconst struct icmp6hdr *icmph;\n\t\tstruct icmp6hdr _icmph;\n\n\t\ticmph = skb_header_pointer(skb, sizeof(*iph),\n\t\t\t\t\t   sizeof(_icmph), &_icmph);\n\t\tif (!icmph)\n\t\t\tgoto out;\n\n\t\tswitch (icmph->icmp6_type) {\n\t\tcase NDISC_ROUTER_SOLICITATION:\n\t\tcase NDISC_ROUTER_ADVERTISEMENT:\n\t\tcase NDISC_NEIGHBOUR_SOLICITATION:\n\t\tcase NDISC_NEIGHBOUR_ADVERTISEMENT:\n\t\tcase NDISC_REDIRECT:\n\t\t\trc = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\nout:\n\treturn rc;\n}\n\nstatic struct rt6_info *vrf_ip6_route_lookup(struct net *net,\n\t\t\t\t\t     const struct net_device *dev,\n\t\t\t\t\t     struct flowi6 *fl6,\n\t\t\t\t\t     int ifindex,\n\t\t\t\t\t     const struct sk_buff *skb,\n\t\t\t\t\t     int flags)\n{\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\n\treturn ip6_pol_route(net, vrf->fib6_table, ifindex, fl6, skb, flags);\n}\n\nstatic void vrf_ip6_input_dst(struct sk_buff *skb, struct net_device *vrf_dev,\n\t\t\t      int ifindex)\n{\n\tconst struct ipv6hdr *iph = ipv6_hdr(skb);\n\tstruct flowi6 fl6 = {\n\t\t.flowi6_iif     = ifindex,\n\t\t.flowi6_mark    = skb->mark,\n\t\t.flowi6_proto   = iph->nexthdr,\n\t\t.daddr          = iph->daddr,\n\t\t.saddr          = iph->saddr,\n\t\t.flowlabel      = ip6_flowinfo(iph),\n\t};\n\tstruct net *net = dev_net(vrf_dev);\n\tstruct rt6_info *rt6;\n\n\trt6 = vrf_ip6_route_lookup(net, vrf_dev, &fl6, ifindex, skb,\n\t\t\t\t   RT6_LOOKUP_F_HAS_SADDR | RT6_LOOKUP_F_IFACE);\n\tif (unlikely(!rt6))\n\t\treturn;\n\n\tif (unlikely(&rt6->dst == &net->ipv6.ip6_null_entry->dst))\n\t\treturn;\n\n\tskb_dst_set(skb, &rt6->dst);\n}\n\nstatic struct sk_buff *vrf_ip6_rcv(struct net_device *vrf_dev,\n\t\t\t\t   struct sk_buff *skb)\n{\n\tint orig_iif = skb->skb_iif;\n\tbool need_strict = rt6_need_strict(&ipv6_hdr(skb)->daddr);\n\tbool is_ndisc = ipv6_ndisc_frame(skb);\n\n\t \n\tif (skb->pkt_type == PACKET_LOOPBACK || (need_strict && !is_ndisc)) {\n\t\tskb->dev = vrf_dev;\n\t\tskb->skb_iif = vrf_dev->ifindex;\n\t\tIP6CB(skb)->flags |= IP6SKB_L3SLAVE;\n\n\t\tif (skb->pkt_type == PACKET_LOOPBACK)\n\t\t\tskb->pkt_type = PACKET_HOST;\n\t\telse\n\t\t\tvrf_ip6_input_dst(skb, vrf_dev, orig_iif);\n\n\t\tgoto out;\n\t}\n\n\t \n\tif (!is_ndisc) {\n\t\tstruct net_device *orig_dev = skb->dev;\n\n\t\tvrf_rx_stats(vrf_dev, skb->len);\n\t\tskb->dev = vrf_dev;\n\t\tskb->skb_iif = vrf_dev->ifindex;\n\n\t\tif (!list_empty(&vrf_dev->ptype_all)) {\n\t\t\tint err;\n\n\t\t\terr = vrf_add_mac_header_if_unset(skb, vrf_dev,\n\t\t\t\t\t\t\t  ETH_P_IPV6,\n\t\t\t\t\t\t\t  orig_dev);\n\t\t\tif (likely(!err)) {\n\t\t\t\tskb_push(skb, skb->mac_len);\n\t\t\t\tdev_queue_xmit_nit(skb, vrf_dev);\n\t\t\t\tskb_pull(skb, skb->mac_len);\n\t\t\t}\n\t\t}\n\n\t\tIP6CB(skb)->flags |= IP6SKB_L3SLAVE;\n\t}\n\n\tif (need_strict)\n\t\tvrf_ip6_input_dst(skb, vrf_dev, orig_iif);\n\n\tskb = vrf_rcv_nfhook(NFPROTO_IPV6, NF_INET_PRE_ROUTING, skb, vrf_dev);\nout:\n\treturn skb;\n}\n\n#else\nstatic struct sk_buff *vrf_ip6_rcv(struct net_device *vrf_dev,\n\t\t\t\t   struct sk_buff *skb)\n{\n\treturn skb;\n}\n#endif\n\nstatic struct sk_buff *vrf_ip_rcv(struct net_device *vrf_dev,\n\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct net_device *orig_dev = skb->dev;\n\n\tskb->dev = vrf_dev;\n\tskb->skb_iif = vrf_dev->ifindex;\n\tIPCB(skb)->flags |= IPSKB_L3SLAVE;\n\n\tif (ipv4_is_multicast(ip_hdr(skb)->daddr))\n\t\tgoto out;\n\n\t \n\tif (skb->pkt_type == PACKET_LOOPBACK) {\n\t\tskb->pkt_type = PACKET_HOST;\n\t\tgoto out;\n\t}\n\n\tvrf_rx_stats(vrf_dev, skb->len);\n\n\tif (!list_empty(&vrf_dev->ptype_all)) {\n\t\tint err;\n\n\t\terr = vrf_add_mac_header_if_unset(skb, vrf_dev, ETH_P_IP,\n\t\t\t\t\t\t  orig_dev);\n\t\tif (likely(!err)) {\n\t\t\tskb_push(skb, skb->mac_len);\n\t\t\tdev_queue_xmit_nit(skb, vrf_dev);\n\t\t\tskb_pull(skb, skb->mac_len);\n\t\t}\n\t}\n\n\tskb = vrf_rcv_nfhook(NFPROTO_IPV4, NF_INET_PRE_ROUTING, skb, vrf_dev);\nout:\n\treturn skb;\n}\n\n \nstatic struct sk_buff *vrf_l3_rcv(struct net_device *vrf_dev,\n\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t  u16 proto)\n{\n\tswitch (proto) {\n\tcase AF_INET:\n\t\treturn vrf_ip_rcv(vrf_dev, skb);\n\tcase AF_INET6:\n\t\treturn vrf_ip6_rcv(vrf_dev, skb);\n\t}\n\n\treturn skb;\n}\n\n#if IS_ENABLED(CONFIG_IPV6)\n \nstatic struct dst_entry *vrf_link_scope_lookup(const struct net_device *dev,\n\t\t\t\t\t      struct flowi6 *fl6)\n{\n\tstruct net *net = dev_net(dev);\n\tint flags = RT6_LOOKUP_F_IFACE | RT6_LOOKUP_F_DST_NOREF;\n\tstruct dst_entry *dst = NULL;\n\tstruct rt6_info *rt;\n\n\t \n\tif (fl6->flowi6_oif == dev->ifindex) {\n\t\tdst = &net->ipv6.ip6_null_entry->dst;\n\t\treturn dst;\n\t}\n\n\tif (!ipv6_addr_any(&fl6->saddr))\n\t\tflags |= RT6_LOOKUP_F_HAS_SADDR;\n\n\trt = vrf_ip6_route_lookup(net, dev, fl6, fl6->flowi6_oif, NULL, flags);\n\tif (rt)\n\t\tdst = &rt->dst;\n\n\treturn dst;\n}\n#endif\n\nstatic const struct l3mdev_ops vrf_l3mdev_ops = {\n\t.l3mdev_fib_table\t= vrf_fib_table,\n\t.l3mdev_l3_rcv\t\t= vrf_l3_rcv,\n\t.l3mdev_l3_out\t\t= vrf_l3_out,\n#if IS_ENABLED(CONFIG_IPV6)\n\t.l3mdev_link_scope_lookup = vrf_link_scope_lookup,\n#endif\n};\n\nstatic void vrf_get_drvinfo(struct net_device *dev,\n\t\t\t    struct ethtool_drvinfo *info)\n{\n\tstrscpy(info->driver, DRV_NAME, sizeof(info->driver));\n\tstrscpy(info->version, DRV_VERSION, sizeof(info->version));\n}\n\nstatic const struct ethtool_ops vrf_ethtool_ops = {\n\t.get_drvinfo\t= vrf_get_drvinfo,\n};\n\nstatic inline size_t vrf_fib_rule_nl_size(void)\n{\n\tsize_t sz;\n\n\tsz  = NLMSG_ALIGN(sizeof(struct fib_rule_hdr));\n\tsz += nla_total_size(sizeof(u8));\t \n\tsz += nla_total_size(sizeof(u32));\t \n\tsz += nla_total_size(sizeof(u8));        \n\n\treturn sz;\n}\n\nstatic int vrf_fib_rule(const struct net_device *dev, __u8 family, bool add_it)\n{\n\tstruct fib_rule_hdr *frh;\n\tstruct nlmsghdr *nlh;\n\tstruct sk_buff *skb;\n\tint err;\n\n\tif ((family == AF_INET6 || family == RTNL_FAMILY_IP6MR) &&\n\t    !ipv6_mod_enabled())\n\t\treturn 0;\n\n\tskb = nlmsg_new(vrf_fib_rule_nl_size(), GFP_KERNEL);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tnlh = nlmsg_put(skb, 0, 0, 0, sizeof(*frh), 0);\n\tif (!nlh)\n\t\tgoto nla_put_failure;\n\n\t \n\tnlh->nlmsg_flags |= NLM_F_EXCL;\n\n\tfrh = nlmsg_data(nlh);\n\tmemset(frh, 0, sizeof(*frh));\n\tfrh->family = family;\n\tfrh->action = FR_ACT_TO_TBL;\n\n\tif (nla_put_u8(skb, FRA_PROTOCOL, RTPROT_KERNEL))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u8(skb, FRA_L3MDEV, 1))\n\t\tgoto nla_put_failure;\n\n\tif (nla_put_u32(skb, FRA_PRIORITY, FIB_RULE_PREF))\n\t\tgoto nla_put_failure;\n\n\tnlmsg_end(skb, nlh);\n\n\t \n\tskb->sk = dev_net(dev)->rtnl;\n\tif (add_it) {\n\t\terr = fib_nl_newrule(skb, nlh, NULL);\n\t\tif (err == -EEXIST)\n\t\t\terr = 0;\n\t} else {\n\t\terr = fib_nl_delrule(skb, nlh, NULL);\n\t\tif (err == -ENOENT)\n\t\t\terr = 0;\n\t}\n\tnlmsg_free(skb);\n\n\treturn err;\n\nnla_put_failure:\n\tnlmsg_free(skb);\n\n\treturn -EMSGSIZE;\n}\n\nstatic int vrf_add_fib_rules(const struct net_device *dev)\n{\n\tint err;\n\n\terr = vrf_fib_rule(dev, AF_INET,  true);\n\tif (err < 0)\n\t\tgoto out_err;\n\n\terr = vrf_fib_rule(dev, AF_INET6, true);\n\tif (err < 0)\n\t\tgoto ipv6_err;\n\n#if IS_ENABLED(CONFIG_IP_MROUTE_MULTIPLE_TABLES)\n\terr = vrf_fib_rule(dev, RTNL_FAMILY_IPMR, true);\n\tif (err < 0)\n\t\tgoto ipmr_err;\n#endif\n\n#if IS_ENABLED(CONFIG_IPV6_MROUTE_MULTIPLE_TABLES)\n\terr = vrf_fib_rule(dev, RTNL_FAMILY_IP6MR, true);\n\tif (err < 0)\n\t\tgoto ip6mr_err;\n#endif\n\n\treturn 0;\n\n#if IS_ENABLED(CONFIG_IPV6_MROUTE_MULTIPLE_TABLES)\nip6mr_err:\n\tvrf_fib_rule(dev, RTNL_FAMILY_IPMR,  false);\n#endif\n\n#if IS_ENABLED(CONFIG_IP_MROUTE_MULTIPLE_TABLES)\nipmr_err:\n\tvrf_fib_rule(dev, AF_INET6,  false);\n#endif\n\nipv6_err:\n\tvrf_fib_rule(dev, AF_INET,  false);\n\nout_err:\n\tnetdev_err(dev, \"Failed to add FIB rules.\\n\");\n\treturn err;\n}\n\nstatic void vrf_setup(struct net_device *dev)\n{\n\tether_setup(dev);\n\n\t \n\tdev->netdev_ops = &vrf_netdev_ops;\n\tdev->l3mdev_ops = &vrf_l3mdev_ops;\n\tdev->ethtool_ops = &vrf_ethtool_ops;\n\tdev->needs_free_netdev = true;\n\n\t \n\teth_hw_addr_random(dev);\n\n\t \n\tdev->features |= NETIF_F_LLTX;\n\n\t \n\tdev->features |= NETIF_F_NETNS_LOCAL;\n\n\t \n\tdev->features   |= NETIF_F_VLAN_CHALLENGED;\n\n\t \n\tdev->features   |= NETIF_F_GSO_SOFTWARE;\n\tdev->features   |= NETIF_F_RXCSUM | NETIF_F_HW_CSUM | NETIF_F_SCTP_CRC;\n\tdev->features   |= NETIF_F_SG | NETIF_F_FRAGLIST | NETIF_F_HIGHDMA;\n\n\tdev->hw_features = dev->features;\n\tdev->hw_enc_features = dev->features;\n\n\t \n\tdev->priv_flags |= IFF_NO_QUEUE;\n\tdev->priv_flags |= IFF_NO_RX_HANDLER;\n\tdev->priv_flags |= IFF_LIVE_ADDR_CHANGE;\n\n\t \n\tdev->min_mtu = IPV6_MIN_MTU;\n\tdev->max_mtu = IP6_MAX_MTU;\n\tdev->mtu = dev->max_mtu;\n\n\tdev->pcpu_stat_type = NETDEV_PCPU_STAT_DSTATS;\n}\n\nstatic int vrf_validate(struct nlattr *tb[], struct nlattr *data[],\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tif (tb[IFLA_ADDRESS]) {\n\t\tif (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid hardware address\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS]))) {\n\t\t\tNL_SET_ERR_MSG(extack, \"Invalid hardware address\");\n\t\t\treturn -EADDRNOTAVAIL;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void vrf_dellink(struct net_device *dev, struct list_head *head)\n{\n\tstruct net_device *port_dev;\n\tstruct list_head *iter;\n\n\tnetdev_for_each_lower_dev(dev, port_dev, iter)\n\t\tvrf_del_slave(dev, port_dev);\n\n\tvrf_map_unregister_dev(dev);\n\n\tunregister_netdevice_queue(dev, head);\n}\n\nstatic int vrf_newlink(struct net *src_net, struct net_device *dev,\n\t\t       struct nlattr *tb[], struct nlattr *data[],\n\t\t       struct netlink_ext_ack *extack)\n{\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\tstruct netns_vrf *nn_vrf;\n\tbool *add_fib_rules;\n\tstruct net *net;\n\tint err;\n\n\tif (!data || !data[IFLA_VRF_TABLE]) {\n\t\tNL_SET_ERR_MSG(extack, \"VRF table id is missing\");\n\t\treturn -EINVAL;\n\t}\n\n\tvrf->tb_id = nla_get_u32(data[IFLA_VRF_TABLE]);\n\tif (vrf->tb_id == RT_TABLE_UNSPEC) {\n\t\tNL_SET_ERR_MSG_ATTR(extack, data[IFLA_VRF_TABLE],\n\t\t\t\t    \"Invalid VRF table id\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev->priv_flags |= IFF_L3MDEV_MASTER;\n\n\terr = register_netdevice(dev);\n\tif (err)\n\t\tgoto out;\n\n\t \n\tvrf->ifindex = dev->ifindex;\n\n\terr = vrf_map_register_dev(dev, extack);\n\tif (err) {\n\t\tunregister_netdevice(dev);\n\t\tgoto out;\n\t}\n\n\tnet = dev_net(dev);\n\tnn_vrf = net_generic(net, vrf_net_id);\n\n\tadd_fib_rules = &nn_vrf->add_fib_rules;\n\tif (*add_fib_rules) {\n\t\terr = vrf_add_fib_rules(dev);\n\t\tif (err) {\n\t\t\tvrf_map_unregister_dev(dev);\n\t\t\tunregister_netdevice(dev);\n\t\t\tgoto out;\n\t\t}\n\t\t*add_fib_rules = false;\n\t}\n\nout:\n\treturn err;\n}\n\nstatic size_t vrf_nl_getsize(const struct net_device *dev)\n{\n\treturn nla_total_size(sizeof(u32));   \n}\n\nstatic int vrf_fillinfo(struct sk_buff *skb,\n\t\t\tconst struct net_device *dev)\n{\n\tstruct net_vrf *vrf = netdev_priv(dev);\n\n\treturn nla_put_u32(skb, IFLA_VRF_TABLE, vrf->tb_id);\n}\n\nstatic size_t vrf_get_slave_size(const struct net_device *bond_dev,\n\t\t\t\t const struct net_device *slave_dev)\n{\n\treturn nla_total_size(sizeof(u32));   \n}\n\nstatic int vrf_fill_slave_info(struct sk_buff *skb,\n\t\t\t       const struct net_device *vrf_dev,\n\t\t\t       const struct net_device *slave_dev)\n{\n\tstruct net_vrf *vrf = netdev_priv(vrf_dev);\n\n\tif (nla_put_u32(skb, IFLA_VRF_PORT_TABLE, vrf->tb_id))\n\t\treturn -EMSGSIZE;\n\n\treturn 0;\n}\n\nstatic const struct nla_policy vrf_nl_policy[IFLA_VRF_MAX + 1] = {\n\t[IFLA_VRF_TABLE] = { .type = NLA_U32 },\n};\n\nstatic struct rtnl_link_ops vrf_link_ops __read_mostly = {\n\t.kind\t\t= DRV_NAME,\n\t.priv_size\t= sizeof(struct net_vrf),\n\n\t.get_size\t= vrf_nl_getsize,\n\t.policy\t\t= vrf_nl_policy,\n\t.validate\t= vrf_validate,\n\t.fill_info\t= vrf_fillinfo,\n\n\t.get_slave_size  = vrf_get_slave_size,\n\t.fill_slave_info = vrf_fill_slave_info,\n\n\t.newlink\t= vrf_newlink,\n\t.dellink\t= vrf_dellink,\n\t.setup\t\t= vrf_setup,\n\t.maxtype\t= IFLA_VRF_MAX,\n};\n\nstatic int vrf_device_event(struct notifier_block *unused,\n\t\t\t    unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\n\t \n\tif (event == NETDEV_UNREGISTER) {\n\t\tstruct net_device *vrf_dev;\n\n\t\tif (!netif_is_l3_slave(dev))\n\t\t\tgoto out;\n\n\t\tvrf_dev = netdev_master_upper_dev_get(dev);\n\t\tvrf_del_slave(vrf_dev, dev);\n\t}\nout:\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block vrf_notifier_block __read_mostly = {\n\t.notifier_call = vrf_device_event,\n};\n\nstatic int vrf_map_init(struct vrf_map *vmap)\n{\n\tspin_lock_init(&vmap->vmap_lock);\n\thash_init(vmap->ht);\n\n\tvmap->strict_mode = false;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_SYSCTL\nstatic bool vrf_strict_mode(struct vrf_map *vmap)\n{\n\tbool strict_mode;\n\n\tvrf_map_lock(vmap);\n\tstrict_mode = vmap->strict_mode;\n\tvrf_map_unlock(vmap);\n\n\treturn strict_mode;\n}\n\nstatic int vrf_strict_mode_change(struct vrf_map *vmap, bool new_mode)\n{\n\tbool *cur_mode;\n\tint res = 0;\n\n\tvrf_map_lock(vmap);\n\n\tcur_mode = &vmap->strict_mode;\n\tif (*cur_mode == new_mode)\n\t\tgoto unlock;\n\n\tif (*cur_mode) {\n\t\t \n\t\t*cur_mode = false;\n\t} else {\n\t\tif (vmap->shared_tables) {\n\t\t\t \n\t\t\tres = -EBUSY;\n\t\t\tgoto unlock;\n\t\t}\n\n\t\t \n\t\t*cur_mode = true;\n\t}\n\nunlock:\n\tvrf_map_unlock(vmap);\n\n\treturn res;\n}\n\nstatic int vrf_shared_table_handler(struct ctl_table *table, int write,\n\t\t\t\t    void *buffer, size_t *lenp, loff_t *ppos)\n{\n\tstruct net *net = (struct net *)table->extra1;\n\tstruct vrf_map *vmap = netns_vrf_map(net);\n\tint proc_strict_mode = 0;\n\tstruct ctl_table tmp = {\n\t\t.procname\t= table->procname,\n\t\t.data\t\t= &proc_strict_mode,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= table->mode,\n\t\t.extra1\t\t= SYSCTL_ZERO,\n\t\t.extra2\t\t= SYSCTL_ONE,\n\t};\n\tint ret;\n\n\tif (!write)\n\t\tproc_strict_mode = vrf_strict_mode(vmap);\n\n\tret = proc_dointvec_minmax(&tmp, write, buffer, lenp, ppos);\n\n\tif (write && ret == 0)\n\t\tret = vrf_strict_mode_change(vmap, (bool)proc_strict_mode);\n\n\treturn ret;\n}\n\nstatic const struct ctl_table vrf_table[] = {\n\t{\n\t\t.procname\t= \"strict_mode\",\n\t\t.data\t\t= NULL,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= vrf_shared_table_handler,\n\t\t \n\t\t.extra1\t\t= NULL,\n\t},\n\t{ },\n};\n\nstatic int vrf_netns_init_sysctl(struct net *net, struct netns_vrf *nn_vrf)\n{\n\tstruct ctl_table *table;\n\n\ttable = kmemdup(vrf_table, sizeof(vrf_table), GFP_KERNEL);\n\tif (!table)\n\t\treturn -ENOMEM;\n\n\t \n\ttable[0].extra1 = net;\n\n\tnn_vrf->ctl_hdr = register_net_sysctl_sz(net, \"net/vrf\", table,\n\t\t\t\t\t\t ARRAY_SIZE(vrf_table));\n\tif (!nn_vrf->ctl_hdr) {\n\t\tkfree(table);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstatic void vrf_netns_exit_sysctl(struct net *net)\n{\n\tstruct netns_vrf *nn_vrf = net_generic(net, vrf_net_id);\n\tstruct ctl_table *table;\n\n\ttable = nn_vrf->ctl_hdr->ctl_table_arg;\n\tunregister_net_sysctl_table(nn_vrf->ctl_hdr);\n\tkfree(table);\n}\n#else\nstatic int vrf_netns_init_sysctl(struct net *net, struct netns_vrf *nn_vrf)\n{\n\treturn 0;\n}\n\nstatic void vrf_netns_exit_sysctl(struct net *net)\n{\n}\n#endif\n\n \nstatic int __net_init vrf_netns_init(struct net *net)\n{\n\tstruct netns_vrf *nn_vrf = net_generic(net, vrf_net_id);\n\n\tnn_vrf->add_fib_rules = true;\n\tvrf_map_init(&nn_vrf->vmap);\n\n\treturn vrf_netns_init_sysctl(net, nn_vrf);\n}\n\nstatic void __net_exit vrf_netns_exit(struct net *net)\n{\n\tvrf_netns_exit_sysctl(net);\n}\n\nstatic struct pernet_operations vrf_net_ops __net_initdata = {\n\t.init = vrf_netns_init,\n\t.exit = vrf_netns_exit,\n\t.id   = &vrf_net_id,\n\t.size = sizeof(struct netns_vrf),\n};\n\nstatic int __init vrf_init_module(void)\n{\n\tint rc;\n\n\tregister_netdevice_notifier(&vrf_notifier_block);\n\n\trc = register_pernet_subsys(&vrf_net_ops);\n\tif (rc < 0)\n\t\tgoto error;\n\n\trc = l3mdev_table_lookup_register(L3MDEV_TYPE_VRF,\n\t\t\t\t\t  vrf_ifindex_lookup_by_table_id);\n\tif (rc < 0)\n\t\tgoto unreg_pernet;\n\n\trc = rtnl_link_register(&vrf_link_ops);\n\tif (rc < 0)\n\t\tgoto table_lookup_unreg;\n\n\treturn 0;\n\ntable_lookup_unreg:\n\tl3mdev_table_lookup_unregister(L3MDEV_TYPE_VRF,\n\t\t\t\t       vrf_ifindex_lookup_by_table_id);\n\nunreg_pernet:\n\tunregister_pernet_subsys(&vrf_net_ops);\n\nerror:\n\tunregister_netdevice_notifier(&vrf_notifier_block);\n\treturn rc;\n}\n\nmodule_init(vrf_init_module);\nMODULE_AUTHOR(\"Shrijeet Mukherjee, David Ahern\");\nMODULE_DESCRIPTION(\"Device driver to instantiate VRF domains\");\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_RTNL_LINK(DRV_NAME);\nMODULE_VERSION(DRV_VERSION);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}