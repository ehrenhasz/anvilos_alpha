{
  "module_name": "sdio.c",
  "hash_id": "723b116dcdd786e587ca05a455e73d7368f928f4195b2be27cf9480ce7220b5c",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/mediatek/mt76/sdio.c",
  "human_readable_source": "\n \n\n#include <linux/iopoll.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/mmc/sdio_func.h>\n#include <linux/mmc/card.h>\n#include <linux/mmc/host.h>\n#include <linux/sched.h>\n#include <linux/kthread.h>\n\n#include \"mt76.h\"\n#include \"sdio.h\"\n\nstatic u32 mt76s_read_whisr(struct mt76_dev *dev)\n{\n\treturn sdio_readl(dev->sdio.func, MCR_WHISR, NULL);\n}\n\nu32 mt76s_read_pcr(struct mt76_dev *dev)\n{\n\tstruct mt76_sdio *sdio = &dev->sdio;\n\n\treturn sdio_readl(sdio->func, MCR_WHLPCR, NULL);\n}\nEXPORT_SYMBOL_GPL(mt76s_read_pcr);\n\nstatic u32 mt76s_read_mailbox(struct mt76_dev *dev, u32 offset)\n{\n\tstruct sdio_func *func = dev->sdio.func;\n\tu32 val = ~0, status;\n\tint err;\n\n\tsdio_claim_host(func);\n\n\tsdio_writel(func, offset, MCR_H2DSM0R, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed setting address [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\tsdio_writel(func, H2D_SW_INT_READ, MCR_WSICR, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed setting read mode [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\terr = readx_poll_timeout(mt76s_read_whisr, dev, status,\n\t\t\t\t status & H2D_SW_INT_READ, 0, 1000000);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"query whisr timeout\\n\");\n\t\tgoto out;\n\t}\n\n\tsdio_writel(func, H2D_SW_INT_READ, MCR_WHISR, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed setting read mode [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\tval = sdio_readl(func, MCR_H2DSM0R, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed reading h2dsm0r [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\tif (val != offset) {\n\t\tdev_err(dev->dev, \"register mismatch\\n\");\n\t\tval = ~0;\n\t\tgoto out;\n\t}\n\n\tval = sdio_readl(func, MCR_D2HRM1R, &err);\n\tif (err < 0)\n\t\tdev_err(dev->dev, \"failed reading d2hrm1r [err=%d]\\n\", err);\n\nout:\n\tsdio_release_host(func);\n\n\treturn val;\n}\n\nstatic void mt76s_write_mailbox(struct mt76_dev *dev, u32 offset, u32 val)\n{\n\tstruct sdio_func *func = dev->sdio.func;\n\tu32 status;\n\tint err;\n\n\tsdio_claim_host(func);\n\n\tsdio_writel(func, offset, MCR_H2DSM0R, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed setting address [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\tsdio_writel(func, val, MCR_H2DSM1R, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev,\n\t\t\t\"failed setting write value [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\tsdio_writel(func, H2D_SW_INT_WRITE, MCR_WSICR, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed setting write mode [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\terr = readx_poll_timeout(mt76s_read_whisr, dev, status,\n\t\t\t\t status & H2D_SW_INT_WRITE, 0, 1000000);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"query whisr timeout\\n\");\n\t\tgoto out;\n\t}\n\n\tsdio_writel(func, H2D_SW_INT_WRITE, MCR_WHISR, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed setting write mode [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\tval = sdio_readl(func, MCR_H2DSM0R, &err);\n\tif (err < 0) {\n\t\tdev_err(dev->dev, \"failed reading h2dsm0r [err=%d]\\n\", err);\n\t\tgoto out;\n\t}\n\n\tif (val != offset)\n\t\tdev_err(dev->dev, \"register mismatch\\n\");\n\nout:\n\tsdio_release_host(func);\n}\n\nu32 mt76s_rr(struct mt76_dev *dev, u32 offset)\n{\n\tif (test_bit(MT76_STATE_MCU_RUNNING, &dev->phy.state))\n\t\treturn dev->mcu_ops->mcu_rr(dev, offset);\n\telse\n\t\treturn mt76s_read_mailbox(dev, offset);\n}\nEXPORT_SYMBOL_GPL(mt76s_rr);\n\nvoid mt76s_wr(struct mt76_dev *dev, u32 offset, u32 val)\n{\n\tif (test_bit(MT76_STATE_MCU_RUNNING, &dev->phy.state))\n\t\tdev->mcu_ops->mcu_wr(dev, offset, val);\n\telse\n\t\tmt76s_write_mailbox(dev, offset, val);\n}\nEXPORT_SYMBOL_GPL(mt76s_wr);\n\nu32 mt76s_rmw(struct mt76_dev *dev, u32 offset, u32 mask, u32 val)\n{\n\tval |= mt76s_rr(dev, offset) & ~mask;\n\tmt76s_wr(dev, offset, val);\n\n\treturn val;\n}\nEXPORT_SYMBOL_GPL(mt76s_rmw);\n\nvoid mt76s_write_copy(struct mt76_dev *dev, u32 offset,\n\t\t      const void *data, int len)\n{\n\tconst u32 *val = data;\n\tint i;\n\n\tfor (i = 0; i < len / sizeof(u32); i++) {\n\t\tmt76s_wr(dev, offset, val[i]);\n\t\toffset += sizeof(u32);\n\t}\n}\nEXPORT_SYMBOL_GPL(mt76s_write_copy);\n\nvoid mt76s_read_copy(struct mt76_dev *dev, u32 offset,\n\t\t     void *data, int len)\n{\n\tu32 *val = data;\n\tint i;\n\n\tfor (i = 0; i < len / sizeof(u32); i++) {\n\t\tval[i] = mt76s_rr(dev, offset);\n\t\toffset += sizeof(u32);\n\t}\n}\nEXPORT_SYMBOL_GPL(mt76s_read_copy);\n\nint mt76s_wr_rp(struct mt76_dev *dev, u32 base,\n\t\tconst struct mt76_reg_pair *data,\n\t\tint len)\n{\n\tint i;\n\n\tfor (i = 0; i < len; i++) {\n\t\tmt76s_wr(dev, data->reg, data->value);\n\t\tdata++;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mt76s_wr_rp);\n\nint mt76s_rd_rp(struct mt76_dev *dev, u32 base,\n\t\tstruct mt76_reg_pair *data, int len)\n{\n\tint i;\n\n\tfor (i = 0; i < len; i++) {\n\t\tdata->value = mt76s_rr(dev, data->reg);\n\t\tdata++;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mt76s_rd_rp);\n\nint mt76s_hw_init(struct mt76_dev *dev, struct sdio_func *func, int hw_ver)\n{\n\tu32 status, ctrl;\n\tint ret;\n\n\tdev->sdio.hw_ver = hw_ver;\n\n\tsdio_claim_host(func);\n\n\tret = sdio_enable_func(func);\n\tif (ret < 0)\n\t\tgoto release;\n\n\t \n\tsdio_writel(func, WHLPCR_INT_EN_CLR | WHLPCR_FW_OWN_REQ_CLR,\n\t\t    MCR_WHLPCR, &ret);\n\tif (ret < 0)\n\t\tgoto disable_func;\n\n\tret = readx_poll_timeout(mt76s_read_pcr, dev, status,\n\t\t\t\t status & WHLPCR_IS_DRIVER_OWN, 2000, 1000000);\n\tif (ret < 0) {\n\t\tdev_err(dev->dev, \"Cannot get ownership from device\");\n\t\tgoto disable_func;\n\t}\n\n\tret = sdio_set_block_size(func, 512);\n\tif (ret < 0)\n\t\tgoto disable_func;\n\n\t \n\tsdio_writel(func, WHLPCR_INT_EN_SET, MCR_WHLPCR, &ret);\n\tif (ret < 0)\n\t\tgoto disable_func;\n\n\tctrl = WHIER_RX0_DONE_INT_EN | WHIER_TX_DONE_INT_EN;\n\tif (hw_ver == MT76_CONNAC2_SDIO)\n\t\tctrl |= WHIER_RX1_DONE_INT_EN;\n\tsdio_writel(func, ctrl, MCR_WHIER, &ret);\n\tif (ret < 0)\n\t\tgoto disable_func;\n\n\tswitch (hw_ver) {\n\tcase MT76_CONNAC_SDIO:\n\t\t \n\t\tctrl = FIELD_PREP(MAX_HIF_RX_LEN_NUM, 16);\n\t\tbreak;\n\tdefault:\n\t\tctrl = sdio_readl(func, MCR_WHCR, &ret);\n\t\tif (ret < 0)\n\t\t\tgoto disable_func;\n\t\tctrl &= ~MAX_HIF_RX_LEN_NUM_CONNAC2;\n\t\tctrl &= ~W_INT_CLR_CTRL;  \n\t\tctrl |= FIELD_PREP(MAX_HIF_RX_LEN_NUM_CONNAC2, 0);\n\t\tbreak;\n\t}\n\n\tsdio_writel(func, ctrl, MCR_WHCR, &ret);\n\tif (ret < 0)\n\t\tgoto disable_func;\n\n\tret = sdio_claim_irq(func, mt76s_sdio_irq);\n\tif (ret < 0)\n\t\tgoto disable_func;\n\n\tsdio_release_host(func);\n\n\treturn 0;\n\ndisable_func:\n\tsdio_disable_func(func);\nrelease:\n\tsdio_release_host(func);\n\n\treturn ret;\n}\nEXPORT_SYMBOL_GPL(mt76s_hw_init);\n\nint mt76s_alloc_rx_queue(struct mt76_dev *dev, enum mt76_rxq_id qid)\n{\n\tstruct mt76_queue *q = &dev->q_rx[qid];\n\n\tspin_lock_init(&q->lock);\n\tq->entry = devm_kcalloc(dev->dev,\n\t\t\t\tMT76S_NUM_RX_ENTRIES, sizeof(*q->entry),\n\t\t\t\tGFP_KERNEL);\n\tif (!q->entry)\n\t\treturn -ENOMEM;\n\n\tq->ndesc = MT76S_NUM_RX_ENTRIES;\n\tq->head = q->tail = 0;\n\tq->queued = 0;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mt76s_alloc_rx_queue);\n\nstatic struct mt76_queue *mt76s_alloc_tx_queue(struct mt76_dev *dev)\n{\n\tstruct mt76_queue *q;\n\n\tq = devm_kzalloc(dev->dev, sizeof(*q), GFP_KERNEL);\n\tif (!q)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tspin_lock_init(&q->lock);\n\tq->entry = devm_kcalloc(dev->dev,\n\t\t\t\tMT76S_NUM_TX_ENTRIES, sizeof(*q->entry),\n\t\t\t\tGFP_KERNEL);\n\tif (!q->entry)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tq->ndesc = MT76S_NUM_TX_ENTRIES;\n\n\treturn q;\n}\n\nint mt76s_alloc_tx(struct mt76_dev *dev)\n{\n\tstruct mt76_queue *q;\n\tint i;\n\n\tfor (i = 0; i <= MT_TXQ_PSD; i++) {\n\t\tq = mt76s_alloc_tx_queue(dev);\n\t\tif (IS_ERR(q))\n\t\t\treturn PTR_ERR(q);\n\n\t\tdev->phy.q_tx[i] = q;\n\t}\n\n\tq = mt76s_alloc_tx_queue(dev);\n\tif (IS_ERR(q))\n\t\treturn PTR_ERR(q);\n\n\tdev->q_mcu[MT_MCUQ_WM] = q;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(mt76s_alloc_tx);\n\nstatic struct mt76_queue_entry *\nmt76s_get_next_rx_entry(struct mt76_queue *q)\n{\n\tstruct mt76_queue_entry *e = NULL;\n\n\tspin_lock_bh(&q->lock);\n\tif (q->queued > 0) {\n\t\te = &q->entry[q->tail];\n\t\tq->tail = (q->tail + 1) % q->ndesc;\n\t\tq->queued--;\n\t}\n\tspin_unlock_bh(&q->lock);\n\n\treturn e;\n}\n\nstatic int\nmt76s_process_rx_queue(struct mt76_dev *dev, struct mt76_queue *q)\n{\n\tint qid = q - &dev->q_rx[MT_RXQ_MAIN];\n\tint nframes = 0;\n\n\twhile (true) {\n\t\tstruct mt76_queue_entry *e;\n\n\t\tif (!test_bit(MT76_STATE_INITIALIZED, &dev->phy.state))\n\t\t\tbreak;\n\n\t\te = mt76s_get_next_rx_entry(q);\n\t\tif (!e || !e->skb)\n\t\t\tbreak;\n\n\t\tdev->drv->rx_skb(dev, MT_RXQ_MAIN, e->skb, NULL);\n\t\te->skb = NULL;\n\t\tnframes++;\n\t}\n\tif (qid == MT_RXQ_MAIN)\n\t\tmt76_rx_poll_complete(dev, MT_RXQ_MAIN, NULL);\n\n\treturn nframes;\n}\n\nstatic void mt76s_net_worker(struct mt76_worker *w)\n{\n\tstruct mt76_sdio *sdio = container_of(w, struct mt76_sdio,\n\t\t\t\t\t      net_worker);\n\tstruct mt76_dev *dev = container_of(sdio, struct mt76_dev, sdio);\n\tint i, nframes;\n\n\tdo {\n\t\tnframes = 0;\n\n\t\tlocal_bh_disable();\n\t\trcu_read_lock();\n\n\t\tmt76_for_each_q_rx(dev, i)\n\t\t\tnframes += mt76s_process_rx_queue(dev, &dev->q_rx[i]);\n\n\t\trcu_read_unlock();\n\t\tlocal_bh_enable();\n\t} while (nframes > 0);\n}\n\nstatic int mt76s_process_tx_queue(struct mt76_dev *dev, struct mt76_queue *q)\n{\n\tstruct mt76_queue_entry entry;\n\tint nframes = 0;\n\tbool mcu;\n\n\tif (!q)\n\t\treturn 0;\n\n\tmcu = q == dev->q_mcu[MT_MCUQ_WM];\n\twhile (q->queued > 0) {\n\t\tif (!q->entry[q->tail].done)\n\t\t\tbreak;\n\n\t\tentry = q->entry[q->tail];\n\t\tq->entry[q->tail].done = false;\n\n\t\tif (mcu) {\n\t\t\tdev_kfree_skb(entry.skb);\n\t\t\tentry.skb = NULL;\n\t\t}\n\n\t\tmt76_queue_tx_complete(dev, q, &entry);\n\t\tnframes++;\n\t}\n\n\tif (!q->queued)\n\t\twake_up(&dev->tx_wait);\n\n\treturn nframes;\n}\n\nstatic void mt76s_status_worker(struct mt76_worker *w)\n{\n\tstruct mt76_sdio *sdio = container_of(w, struct mt76_sdio,\n\t\t\t\t\t      status_worker);\n\tstruct mt76_dev *dev = container_of(sdio, struct mt76_dev, sdio);\n\tbool resched = false;\n\tint i, nframes;\n\n\tdo {\n\t\tint ndata_frames = 0;\n\n\t\tnframes = mt76s_process_tx_queue(dev, dev->q_mcu[MT_MCUQ_WM]);\n\n\t\tfor (i = 0; i <= MT_TXQ_PSD; i++)\n\t\t\tndata_frames += mt76s_process_tx_queue(dev,\n\t\t\t\t\t\t\t       dev->phy.q_tx[i]);\n\t\tnframes += ndata_frames;\n\t\tif (ndata_frames > 0)\n\t\t\tresched = true;\n\n\t\tif (dev->drv->tx_status_data && ndata_frames > 0 &&\n\t\t    !test_and_set_bit(MT76_READING_STATS, &dev->phy.state) &&\n\t\t    !test_bit(MT76_STATE_SUSPEND, &dev->phy.state))\n\t\t\tmt76_worker_schedule(&sdio->stat_worker);\n\t} while (nframes > 0);\n\n\tif (resched)\n\t\tmt76_worker_schedule(&dev->tx_worker);\n}\n\nstatic void mt76s_tx_status_data(struct mt76_worker *worker)\n{\n\tstruct mt76_sdio *sdio;\n\tstruct mt76_dev *dev;\n\tu8 update = 1;\n\tu16 count = 0;\n\n\tsdio = container_of(worker, struct mt76_sdio, stat_worker);\n\tdev = container_of(sdio, struct mt76_dev, sdio);\n\n\twhile (true) {\n\t\tif (test_bit(MT76_REMOVED, &dev->phy.state))\n\t\t\tbreak;\n\n\t\tif (!dev->drv->tx_status_data(dev, &update))\n\t\t\tbreak;\n\t\tcount++;\n\t}\n\n\tif (count && test_bit(MT76_STATE_RUNNING, &dev->phy.state))\n\t\tmt76_worker_schedule(&sdio->status_worker);\n\telse\n\t\tclear_bit(MT76_READING_STATS, &dev->phy.state);\n}\n\nstatic int\nmt76s_tx_queue_skb(struct mt76_dev *dev, struct mt76_queue *q,\n\t\t   enum mt76_txq_id qid, struct sk_buff *skb,\n\t\t   struct mt76_wcid *wcid, struct ieee80211_sta *sta)\n{\n\tstruct mt76_tx_info tx_info = {\n\t\t.skb = skb,\n\t};\n\tint err, len = skb->len;\n\tu16 idx = q->head;\n\n\tif (q->queued == q->ndesc)\n\t\treturn -ENOSPC;\n\n\tskb->prev = skb->next = NULL;\n\terr = dev->drv->tx_prepare_skb(dev, NULL, qid, wcid, sta, &tx_info);\n\tif (err < 0)\n\t\treturn err;\n\n\tq->entry[q->head].skb = tx_info.skb;\n\tq->entry[q->head].buf_sz = len;\n\tq->entry[q->head].wcid = 0xffff;\n\n\tsmp_wmb();\n\n\tq->head = (q->head + 1) % q->ndesc;\n\tq->queued++;\n\n\treturn idx;\n}\n\nstatic int\nmt76s_tx_queue_skb_raw(struct mt76_dev *dev, struct mt76_queue *q,\n\t\t       struct sk_buff *skb, u32 tx_info)\n{\n\tint ret = -ENOSPC, len = skb->len, pad;\n\n\tif (q->queued == q->ndesc)\n\t\tgoto error;\n\n\tpad = round_up(skb->len, 4) - skb->len;\n\tret = mt76_skb_adjust_pad(skb, pad);\n\tif (ret)\n\t\tgoto error;\n\n\tspin_lock_bh(&q->lock);\n\n\tq->entry[q->head].buf_sz = len;\n\tq->entry[q->head].skb = skb;\n\n\t \n\tsmp_wmb();\n\n\tq->head = (q->head + 1) % q->ndesc;\n\tq->queued++;\n\n\tspin_unlock_bh(&q->lock);\n\n\treturn 0;\n\nerror:\n\tdev_kfree_skb(skb);\n\n\treturn ret;\n}\n\nstatic void mt76s_tx_kick(struct mt76_dev *dev, struct mt76_queue *q)\n{\n\tstruct mt76_sdio *sdio = &dev->sdio;\n\n\tmt76_worker_schedule(&sdio->txrx_worker);\n}\n\nstatic const struct mt76_queue_ops sdio_queue_ops = {\n\t.tx_queue_skb = mt76s_tx_queue_skb,\n\t.kick = mt76s_tx_kick,\n\t.tx_queue_skb_raw = mt76s_tx_queue_skb_raw,\n};\n\nvoid mt76s_deinit(struct mt76_dev *dev)\n{\n\tstruct mt76_sdio *sdio = &dev->sdio;\n\tint i;\n\n\tmt76_worker_teardown(&sdio->txrx_worker);\n\tmt76_worker_teardown(&sdio->status_worker);\n\tmt76_worker_teardown(&sdio->net_worker);\n\tmt76_worker_teardown(&sdio->stat_worker);\n\n\tclear_bit(MT76_READING_STATS, &dev->phy.state);\n\n\tmt76_tx_status_check(dev, true);\n\n\tsdio_claim_host(sdio->func);\n\tsdio_release_irq(sdio->func);\n\tsdio_release_host(sdio->func);\n\n\tmt76_for_each_q_rx(dev, i) {\n\t\tstruct mt76_queue *q = &dev->q_rx[i];\n\t\tint j;\n\n\t\tfor (j = 0; j < q->ndesc; j++) {\n\t\t\tstruct mt76_queue_entry *e = &q->entry[j];\n\n\t\t\tif (!e->skb)\n\t\t\t\tcontinue;\n\n\t\t\tdev_kfree_skb(e->skb);\n\t\t\te->skb = NULL;\n\t\t}\n\t}\n}\nEXPORT_SYMBOL_GPL(mt76s_deinit);\n\nint mt76s_init(struct mt76_dev *dev, struct sdio_func *func,\n\t       const struct mt76_bus_ops *bus_ops)\n{\n\tstruct mt76_sdio *sdio = &dev->sdio;\n\tu32 host_max_cap;\n\tint err;\n\n\terr = mt76_worker_setup(dev->hw, &sdio->status_worker,\n\t\t\t\tmt76s_status_worker, \"sdio-status\");\n\tif (err)\n\t\treturn err;\n\n\terr = mt76_worker_setup(dev->hw, &sdio->net_worker, mt76s_net_worker,\n\t\t\t\t\"sdio-net\");\n\tif (err)\n\t\treturn err;\n\n\terr = mt76_worker_setup(dev->hw, &sdio->stat_worker, mt76s_tx_status_data,\n\t\t\t\t\"sdio-sta\");\n\tif (err)\n\t\treturn err;\n\n\tsched_set_fifo_low(sdio->status_worker.task);\n\tsched_set_fifo_low(sdio->net_worker.task);\n\tsched_set_fifo_low(sdio->stat_worker.task);\n\n\tdev->queue_ops = &sdio_queue_ops;\n\tdev->bus = bus_ops;\n\tdev->sdio.func = func;\n\n\thost_max_cap = min_t(u32, func->card->host->max_req_size,\n\t\t\t     func->cur_blksize *\n\t\t\t     func->card->host->max_blk_count);\n\tdev->sdio.xmit_buf_sz = min_t(u32, host_max_cap, MT76S_XMIT_BUF_SZ);\n\tdev->sdio.xmit_buf = devm_kmalloc(dev->dev, dev->sdio.xmit_buf_sz,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!dev->sdio.xmit_buf)\n\t\terr = -ENOMEM;\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(mt76s_init);\n\nMODULE_AUTHOR(\"Sean Wang <sean.wang@mediatek.com>\");\nMODULE_AUTHOR(\"Lorenzo Bianconi <lorenzo@kernel.org>\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}