{
  "module_name": "mt76.h",
  "hash_id": "32dc0f7e411d3ae6177b0f8c09be021e0869e08006b0d66efefcb3ab961f1207",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/mediatek/mt76/mt76.h",
  "human_readable_source": " \n \n\n#ifndef __MT76_H\n#define __MT76_H\n\n#include <linux/kernel.h>\n#include <linux/io.h>\n#include <linux/spinlock.h>\n#include <linux/skbuff.h>\n#include <linux/leds.h>\n#include <linux/usb.h>\n#include <linux/average.h>\n#include <linux/soc/mediatek/mtk_wed.h>\n#include <net/mac80211.h>\n#include <net/page_pool/helpers.h>\n#include \"util.h\"\n#include \"testmode.h\"\n\n#define MT_MCU_RING_SIZE\t32\n#define MT_RX_BUF_SIZE\t\t2048\n#define MT_SKB_HEAD_LEN\t\t256\n\n#define MT_MAX_NON_AQL_PKT\t16\n#define MT_TXQ_FREE_THR\t\t32\n\n#define MT76_TOKEN_FREE_THR\t64\n\n#define MT_QFLAG_WED_RING\tGENMASK(1, 0)\n#define MT_QFLAG_WED_TYPE\tGENMASK(3, 2)\n#define MT_QFLAG_WED\t\tBIT(4)\n\n#define __MT_WED_Q(_type, _n)\t(MT_QFLAG_WED | \\\n\t\t\t\t FIELD_PREP(MT_QFLAG_WED_TYPE, _type) | \\\n\t\t\t\t FIELD_PREP(MT_QFLAG_WED_RING, _n))\n#define MT_WED_Q_TX(_n)\t\t__MT_WED_Q(MT76_WED_Q_TX, _n)\n#define MT_WED_Q_RX(_n)\t\t__MT_WED_Q(MT76_WED_Q_RX, _n)\n#define MT_WED_Q_TXFREE\t\t__MT_WED_Q(MT76_WED_Q_TXFREE, 0)\n\nstruct mt76_dev;\nstruct mt76_phy;\nstruct mt76_wcid;\nstruct mt76s_intr;\n\nstruct mt76_reg_pair {\n\tu32 reg;\n\tu32 value;\n};\n\nenum mt76_bus_type {\n\tMT76_BUS_MMIO,\n\tMT76_BUS_USB,\n\tMT76_BUS_SDIO,\n};\n\nenum mt76_wed_type {\n\tMT76_WED_Q_TX,\n\tMT76_WED_Q_TXFREE,\n\tMT76_WED_Q_RX,\n};\n\nstruct mt76_bus_ops {\n\tu32 (*rr)(struct mt76_dev *dev, u32 offset);\n\tvoid (*wr)(struct mt76_dev *dev, u32 offset, u32 val);\n\tu32 (*rmw)(struct mt76_dev *dev, u32 offset, u32 mask, u32 val);\n\tvoid (*write_copy)(struct mt76_dev *dev, u32 offset, const void *data,\n\t\t\t   int len);\n\tvoid (*read_copy)(struct mt76_dev *dev, u32 offset, void *data,\n\t\t\t  int len);\n\tint (*wr_rp)(struct mt76_dev *dev, u32 base,\n\t\t     const struct mt76_reg_pair *rp, int len);\n\tint (*rd_rp)(struct mt76_dev *dev, u32 base,\n\t\t     struct mt76_reg_pair *rp, int len);\n\tenum mt76_bus_type type;\n};\n\n#define mt76_is_usb(dev) ((dev)->bus->type == MT76_BUS_USB)\n#define mt76_is_mmio(dev) ((dev)->bus->type == MT76_BUS_MMIO)\n#define mt76_is_sdio(dev) ((dev)->bus->type == MT76_BUS_SDIO)\n\nenum mt76_txq_id {\n\tMT_TXQ_VO = IEEE80211_AC_VO,\n\tMT_TXQ_VI = IEEE80211_AC_VI,\n\tMT_TXQ_BE = IEEE80211_AC_BE,\n\tMT_TXQ_BK = IEEE80211_AC_BK,\n\tMT_TXQ_PSD,\n\tMT_TXQ_BEACON,\n\tMT_TXQ_CAB,\n\t__MT_TXQ_MAX\n};\n\nenum mt76_mcuq_id {\n\tMT_MCUQ_WM,\n\tMT_MCUQ_WA,\n\tMT_MCUQ_FWDL,\n\t__MT_MCUQ_MAX\n};\n\nenum mt76_rxq_id {\n\tMT_RXQ_MAIN,\n\tMT_RXQ_MCU,\n\tMT_RXQ_MCU_WA,\n\tMT_RXQ_BAND1,\n\tMT_RXQ_BAND1_WA,\n\tMT_RXQ_MAIN_WA,\n\tMT_RXQ_BAND2,\n\tMT_RXQ_BAND2_WA,\n\t__MT_RXQ_MAX\n};\n\nenum mt76_band_id {\n\tMT_BAND0,\n\tMT_BAND1,\n\tMT_BAND2,\n\t__MT_MAX_BAND\n};\n\nenum mt76_cipher_type {\n\tMT_CIPHER_NONE,\n\tMT_CIPHER_WEP40,\n\tMT_CIPHER_TKIP,\n\tMT_CIPHER_TKIP_NO_MIC,\n\tMT_CIPHER_AES_CCMP,\n\tMT_CIPHER_WEP104,\n\tMT_CIPHER_BIP_CMAC_128,\n\tMT_CIPHER_WEP128,\n\tMT_CIPHER_WAPI,\n\tMT_CIPHER_CCMP_CCX,\n\tMT_CIPHER_CCMP_256,\n\tMT_CIPHER_GCMP,\n\tMT_CIPHER_GCMP_256,\n};\n\nenum mt76_dfs_state {\n\tMT_DFS_STATE_UNKNOWN,\n\tMT_DFS_STATE_DISABLED,\n\tMT_DFS_STATE_CAC,\n\tMT_DFS_STATE_ACTIVE,\n};\n\nstruct mt76_queue_buf {\n\tdma_addr_t addr;\n\tu16 len;\n\tbool skip_unmap;\n};\n\nstruct mt76_tx_info {\n\tstruct mt76_queue_buf buf[32];\n\tstruct sk_buff *skb;\n\tint nbuf;\n\tu32 info;\n};\n\nstruct mt76_queue_entry {\n\tunion {\n\t\tvoid *buf;\n\t\tstruct sk_buff *skb;\n\t};\n\tunion {\n\t\tstruct mt76_txwi_cache *txwi;\n\t\tstruct urb *urb;\n\t\tint buf_sz;\n\t};\n\tu32 dma_addr[2];\n\tu16 dma_len[2];\n\tu16 wcid;\n\tbool skip_buf0:1;\n\tbool skip_buf1:1;\n\tbool done:1;\n};\n\nstruct mt76_queue_regs {\n\tu32 desc_base;\n\tu32 ring_size;\n\tu32 cpu_idx;\n\tu32 dma_idx;\n} __packed __aligned(4);\n\nstruct mt76_queue {\n\tstruct mt76_queue_regs __iomem *regs;\n\n\tspinlock_t lock;\n\tspinlock_t cleanup_lock;\n\tstruct mt76_queue_entry *entry;\n\tstruct mt76_desc *desc;\n\n\tu16 first;\n\tu16 head;\n\tu16 tail;\n\tint ndesc;\n\tint queued;\n\tint buf_size;\n\tbool stopped;\n\tbool blocked;\n\n\tu8 buf_offset;\n\tu8 hw_idx;\n\tu8 flags;\n\n\tu32 wed_regs;\n\n\tdma_addr_t desc_dma;\n\tstruct sk_buff *rx_head;\n\tstruct page_pool *page_pool;\n};\n\nstruct mt76_mcu_ops {\n\tu32 headroom;\n\tu32 tailroom;\n\n\tint (*mcu_send_msg)(struct mt76_dev *dev, int cmd, const void *data,\n\t\t\t    int len, bool wait_resp);\n\tint (*mcu_skb_send_msg)(struct mt76_dev *dev, struct sk_buff *skb,\n\t\t\t\tint cmd, int *seq);\n\tint (*mcu_parse_response)(struct mt76_dev *dev, int cmd,\n\t\t\t\t  struct sk_buff *skb, int seq);\n\tu32 (*mcu_rr)(struct mt76_dev *dev, u32 offset);\n\tvoid (*mcu_wr)(struct mt76_dev *dev, u32 offset, u32 val);\n\tint (*mcu_wr_rp)(struct mt76_dev *dev, u32 base,\n\t\t\t const struct mt76_reg_pair *rp, int len);\n\tint (*mcu_rd_rp)(struct mt76_dev *dev, u32 base,\n\t\t\t struct mt76_reg_pair *rp, int len);\n\tint (*mcu_restart)(struct mt76_dev *dev);\n};\n\nstruct mt76_queue_ops {\n\tint (*init)(struct mt76_dev *dev,\n\t\t    int (*poll)(struct napi_struct *napi, int budget));\n\n\tint (*alloc)(struct mt76_dev *dev, struct mt76_queue *q,\n\t\t     int idx, int n_desc, int bufsize,\n\t\t     u32 ring_base);\n\n\tint (*tx_queue_skb)(struct mt76_dev *dev, struct mt76_queue *q,\n\t\t\t    enum mt76_txq_id qid, struct sk_buff *skb,\n\t\t\t    struct mt76_wcid *wcid, struct ieee80211_sta *sta);\n\n\tint (*tx_queue_skb_raw)(struct mt76_dev *dev, struct mt76_queue *q,\n\t\t\t\tstruct sk_buff *skb, u32 tx_info);\n\n\tvoid *(*dequeue)(struct mt76_dev *dev, struct mt76_queue *q, bool flush,\n\t\t\t int *len, u32 *info, bool *more);\n\n\tvoid (*rx_reset)(struct mt76_dev *dev, enum mt76_rxq_id qid);\n\n\tvoid (*tx_cleanup)(struct mt76_dev *dev, struct mt76_queue *q,\n\t\t\t   bool flush);\n\n\tvoid (*rx_cleanup)(struct mt76_dev *dev, struct mt76_queue *q);\n\n\tvoid (*kick)(struct mt76_dev *dev, struct mt76_queue *q);\n\n\tvoid (*reset_q)(struct mt76_dev *dev, struct mt76_queue *q);\n};\n\nenum mt76_phy_type {\n\tMT_PHY_TYPE_CCK,\n\tMT_PHY_TYPE_OFDM,\n\tMT_PHY_TYPE_HT,\n\tMT_PHY_TYPE_HT_GF,\n\tMT_PHY_TYPE_VHT,\n\tMT_PHY_TYPE_HE_SU = 8,\n\tMT_PHY_TYPE_HE_EXT_SU,\n\tMT_PHY_TYPE_HE_TB,\n\tMT_PHY_TYPE_HE_MU,\n\tMT_PHY_TYPE_EHT_SU = 13,\n\tMT_PHY_TYPE_EHT_TRIG,\n\tMT_PHY_TYPE_EHT_MU,\n\t__MT_PHY_TYPE_MAX,\n};\n\nstruct mt76_sta_stats {\n\tu64 tx_mode[__MT_PHY_TYPE_MAX];\n\tu64 tx_bw[5];\t\t \n\tu64 tx_nss[4];\t\t \n\tu64 tx_mcs[16];\t\t \n\tu64 tx_bytes;\n\t \n\tu32 tx_packets;\t\t \n\tu32 tx_retries;\n\tu32 tx_failed;\n\t \n\tu64 rx_bytes;\n\tu32 rx_packets;\n\tu32 rx_errors;\n\tu32 rx_drops;\n};\n\nenum mt76_wcid_flags {\n\tMT_WCID_FLAG_CHECK_PS,\n\tMT_WCID_FLAG_PS,\n\tMT_WCID_FLAG_4ADDR,\n\tMT_WCID_FLAG_HDR_TRANS,\n};\n\n#define MT76_N_WCIDS 1088\n\n \n#define MT_TX_HW_QUEUE_PHY\t\tGENMASK(3, 2)\n\nDECLARE_EWMA(signal, 10, 8);\n\n#define MT_WCID_TX_INFO_RATE\t\tGENMASK(15, 0)\n#define MT_WCID_TX_INFO_NSS\t\tGENMASK(17, 16)\n#define MT_WCID_TX_INFO_TXPWR_ADJ\tGENMASK(25, 18)\n#define MT_WCID_TX_INFO_SET\t\tBIT(31)\n\nstruct mt76_wcid {\n\tstruct mt76_rx_tid __rcu *aggr[IEEE80211_NUM_TIDS];\n\n\tatomic_t non_aql_packets;\n\tunsigned long flags;\n\n\tstruct ewma_signal rssi;\n\tint inactive_count;\n\n\tstruct rate_info rate;\n\tunsigned long ampdu_state;\n\n\tu16 idx;\n\tu8 hw_key_idx;\n\tu8 hw_key_idx2;\n\n\tu8 sta:1;\n\tu8 amsdu:1;\n\tu8 phy_idx:2;\n\n\tu8 rx_check_pn;\n\tu8 rx_key_pn[IEEE80211_NUM_TIDS + 1][6];\n\tu16 cipher;\n\n\tu32 tx_info;\n\tbool sw_iv;\n\n\tstruct list_head list;\n\tstruct idr pktid;\n\n\tstruct mt76_sta_stats stats;\n\n\tstruct list_head poll_list;\n};\n\nstruct mt76_txq {\n\tu16 wcid;\n\n\tu16 agg_ssn;\n\tbool send_bar;\n\tbool aggr;\n};\n\nstruct mt76_txwi_cache {\n\tstruct list_head list;\n\tdma_addr_t dma_addr;\n\n\tunion {\n\t\tstruct sk_buff *skb;\n\t\tvoid *ptr;\n\t};\n};\n\nstruct mt76_rx_tid {\n\tstruct rcu_head rcu_head;\n\n\tstruct mt76_dev *dev;\n\n\tspinlock_t lock;\n\tstruct delayed_work reorder_work;\n\n\tu16 head;\n\tu16 size;\n\tu16 nframes;\n\n\tu8 num;\n\n\tu8 started:1, stopped:1, timer_pending:1;\n\n\tstruct sk_buff *reorder_buf[];\n};\n\n#define MT_TX_CB_DMA_DONE\t\tBIT(0)\n#define MT_TX_CB_TXS_DONE\t\tBIT(1)\n#define MT_TX_CB_TXS_FAILED\t\tBIT(2)\n\n#define MT_PACKET_ID_MASK\t\tGENMASK(6, 0)\n#define MT_PACKET_ID_NO_ACK\t\t0\n#define MT_PACKET_ID_NO_SKB\t\t1\n#define MT_PACKET_ID_WED\t\t2\n#define MT_PACKET_ID_FIRST\t\t3\n#define MT_PACKET_ID_HAS_RATE\t\tBIT(7)\n \n#define MT_TX_STATUS_SKB_TIMEOUT\t(HZ / 4)\n\nstruct mt76_tx_cb {\n\tunsigned long jiffies;\n\tu16 wcid;\n\tu8 pktid;\n\tu8 flags;\n};\n\nenum {\n\tMT76_STATE_INITIALIZED,\n\tMT76_STATE_REGISTERED,\n\tMT76_STATE_RUNNING,\n\tMT76_STATE_MCU_RUNNING,\n\tMT76_SCANNING,\n\tMT76_HW_SCANNING,\n\tMT76_HW_SCHED_SCANNING,\n\tMT76_RESTART,\n\tMT76_RESET,\n\tMT76_MCU_RESET,\n\tMT76_REMOVED,\n\tMT76_READING_STATS,\n\tMT76_STATE_POWER_OFF,\n\tMT76_STATE_SUSPEND,\n\tMT76_STATE_ROC,\n\tMT76_STATE_PM,\n\tMT76_STATE_WED_RESET,\n};\n\nstruct mt76_hw_cap {\n\tbool has_2ghz;\n\tbool has_5ghz;\n\tbool has_6ghz;\n};\n\n#define MT_DRV_TXWI_NO_FREE\t\tBIT(0)\n#define MT_DRV_TX_ALIGNED4_SKBS\t\tBIT(1)\n#define MT_DRV_SW_RX_AIRTIME\t\tBIT(2)\n#define MT_DRV_RX_DMA_HDR\t\tBIT(3)\n#define MT_DRV_HW_MGMT_TXQ\t\tBIT(4)\n#define MT_DRV_AMSDU_OFFLOAD\t\tBIT(5)\n\nstruct mt76_driver_ops {\n\tu32 drv_flags;\n\tu32 survey_flags;\n\tu16 txwi_size;\n\tu16 token_size;\n\tu8 mcs_rates;\n\n\tvoid (*update_survey)(struct mt76_phy *phy);\n\n\tint (*tx_prepare_skb)(struct mt76_dev *dev, void *txwi_ptr,\n\t\t\t      enum mt76_txq_id qid, struct mt76_wcid *wcid,\n\t\t\t      struct ieee80211_sta *sta,\n\t\t\t      struct mt76_tx_info *tx_info);\n\n\tvoid (*tx_complete_skb)(struct mt76_dev *dev,\n\t\t\t\tstruct mt76_queue_entry *e);\n\n\tbool (*tx_status_data)(struct mt76_dev *dev, u8 *update);\n\n\tbool (*rx_check)(struct mt76_dev *dev, void *data, int len);\n\n\tvoid (*rx_skb)(struct mt76_dev *dev, enum mt76_rxq_id q,\n\t\t       struct sk_buff *skb, u32 *info);\n\n\tvoid (*rx_poll_complete)(struct mt76_dev *dev, enum mt76_rxq_id q);\n\n\tvoid (*sta_ps)(struct mt76_dev *dev, struct ieee80211_sta *sta,\n\t\t       bool ps);\n\n\tint (*sta_add)(struct mt76_dev *dev, struct ieee80211_vif *vif,\n\t\t       struct ieee80211_sta *sta);\n\n\tvoid (*sta_assoc)(struct mt76_dev *dev, struct ieee80211_vif *vif,\n\t\t\t  struct ieee80211_sta *sta);\n\n\tvoid (*sta_remove)(struct mt76_dev *dev, struct ieee80211_vif *vif,\n\t\t\t   struct ieee80211_sta *sta);\n};\n\nstruct mt76_channel_state {\n\tu64 cc_active;\n\tu64 cc_busy;\n\tu64 cc_rx;\n\tu64 cc_bss_rx;\n\tu64 cc_tx;\n\n\ts8 noise;\n};\n\nstruct mt76_sband {\n\tstruct ieee80211_supported_band sband;\n\tstruct mt76_channel_state *chan;\n};\n\n \n#define MT_VEND_TYPE_EEPROM\tBIT(31)\n#define MT_VEND_TYPE_CFG\tBIT(30)\n#define MT_VEND_TYPE_MASK\t(MT_VEND_TYPE_EEPROM | MT_VEND_TYPE_CFG)\n\n#define MT_VEND_ADDR(type, n)\t(MT_VEND_TYPE_##type | (n))\nenum mt_vendor_req {\n\tMT_VEND_DEV_MODE =\t0x1,\n\tMT_VEND_WRITE =\t\t0x2,\n\tMT_VEND_POWER_ON =\t0x4,\n\tMT_VEND_MULTI_WRITE =\t0x6,\n\tMT_VEND_MULTI_READ =\t0x7,\n\tMT_VEND_READ_EEPROM =\t0x9,\n\tMT_VEND_WRITE_FCE =\t0x42,\n\tMT_VEND_WRITE_CFG =\t0x46,\n\tMT_VEND_READ_CFG =\t0x47,\n\tMT_VEND_READ_EXT =\t0x63,\n\tMT_VEND_WRITE_EXT =\t0x66,\n\tMT_VEND_FEATURE_SET =\t0x91,\n};\n\nenum mt76u_in_ep {\n\tMT_EP_IN_PKT_RX,\n\tMT_EP_IN_CMD_RESP,\n\t__MT_EP_IN_MAX,\n};\n\nenum mt76u_out_ep {\n\tMT_EP_OUT_INBAND_CMD,\n\tMT_EP_OUT_AC_BE,\n\tMT_EP_OUT_AC_BK,\n\tMT_EP_OUT_AC_VI,\n\tMT_EP_OUT_AC_VO,\n\tMT_EP_OUT_HCCA,\n\t__MT_EP_OUT_MAX,\n};\n\nstruct mt76_mcu {\n\tstruct mutex mutex;\n\tu32 msg_seq;\n\tint timeout;\n\n\tstruct sk_buff_head res_q;\n\twait_queue_head_t wait;\n};\n\n#define MT_TX_SG_MAX_SIZE\t8\n#define MT_RX_SG_MAX_SIZE\t4\n#define MT_NUM_TX_ENTRIES\t256\n#define MT_NUM_RX_ENTRIES\t128\n#define MCU_RESP_URB_SIZE\t1024\nstruct mt76_usb {\n\tstruct mutex usb_ctrl_mtx;\n\tu8 *data;\n\tu16 data_len;\n\n\tstruct mt76_worker status_worker;\n\tstruct mt76_worker rx_worker;\n\n\tstruct work_struct stat_work;\n\n\tu8 out_ep[__MT_EP_OUT_MAX];\n\tu8 in_ep[__MT_EP_IN_MAX];\n\tbool sg_en;\n\n\tstruct mt76u_mcu {\n\t\tu8 *data;\n\t\t \n\t\tstruct mt76_reg_pair *rp;\n\t\tint rp_len;\n\t\tu32 base;\n\t} mcu;\n};\n\n#define MT76S_XMIT_BUF_SZ\t0x3fe00\n#define MT76S_NUM_TX_ENTRIES\t256\n#define MT76S_NUM_RX_ENTRIES\t512\nstruct mt76_sdio {\n\tstruct mt76_worker txrx_worker;\n\tstruct mt76_worker status_worker;\n\tstruct mt76_worker net_worker;\n\tstruct mt76_worker stat_worker;\n\n\tu8 *xmit_buf;\n\tu32 xmit_buf_sz;\n\n\tstruct sdio_func *func;\n\tvoid *intr_data;\n\tu8 hw_ver;\n\twait_queue_head_t wait;\n\n\tstruct {\n\t\tint pse_data_quota;\n\t\tint ple_data_quota;\n\t\tint pse_mcu_quota;\n\t\tint pse_page_size;\n\t\tint deficit;\n\t} sched;\n\n\tint (*parse_irq)(struct mt76_dev *dev, struct mt76s_intr *intr);\n};\n\nstruct mt76_mmio {\n\tvoid __iomem *regs;\n\tspinlock_t irq_lock;\n\tu32 irqmask;\n\n\tstruct mtk_wed_device wed;\n\tstruct completion wed_reset;\n\tstruct completion wed_reset_complete;\n};\n\nstruct mt76_rx_status {\n\tunion {\n\t\tstruct mt76_wcid *wcid;\n\t\tu16 wcid_idx;\n\t};\n\n\tu32 reorder_time;\n\n\tu32 ampdu_ref;\n\tu32 timestamp;\n\n\tu8 iv[6];\n\n\tu8 phy_idx:2;\n\tu8 aggr:1;\n\tu8 qos_ctl;\n\tu16 seqno;\n\n\tu16 freq;\n\tu32 flag;\n\tu8 enc_flags;\n\tu8 encoding:3, bw:4;\n\tunion {\n\t\tstruct {\n\t\t\tu8 he_ru:3;\n\t\t\tu8 he_gi:2;\n\t\t\tu8 he_dcm:1;\n\t\t};\n\t\tstruct {\n\t\t\tu8 ru:4;\n\t\t\tu8 gi:2;\n\t\t} eht;\n\t};\n\n\tu8 amsdu:1, first_amsdu:1, last_amsdu:1;\n\tu8 rate_idx;\n\tu8 nss:5, band:3;\n\ts8 signal;\n\tu8 chains;\n\ts8 chain_signal[IEEE80211_MAX_CHAINS];\n};\n\nstruct mt76_freq_range_power {\n\tconst struct cfg80211_sar_freq_ranges *range;\n\ts8 power;\n};\n\nstruct mt76_testmode_ops {\n\tint (*set_state)(struct mt76_phy *phy, enum mt76_testmode_state state);\n\tint (*set_params)(struct mt76_phy *phy, struct nlattr **tb,\n\t\t\t  enum mt76_testmode_state new_state);\n\tint (*dump_stats)(struct mt76_phy *phy, struct sk_buff *msg);\n};\n\nstruct mt76_testmode_data {\n\tenum mt76_testmode_state state;\n\n\tu32 param_set[DIV_ROUND_UP(NUM_MT76_TM_ATTRS, 32)];\n\tstruct sk_buff *tx_skb;\n\n\tu32 tx_count;\n\tu16 tx_mpdu_len;\n\n\tu8 tx_rate_mode;\n\tu8 tx_rate_idx;\n\tu8 tx_rate_nss;\n\tu8 tx_rate_sgi;\n\tu8 tx_rate_ldpc;\n\tu8 tx_rate_stbc;\n\tu8 tx_ltf;\n\n\tu8 tx_antenna_mask;\n\tu8 tx_spe_idx;\n\n\tu8 tx_duty_cycle;\n\tu32 tx_time;\n\tu32 tx_ipg;\n\n\tu32 freq_offset;\n\n\tu8 tx_power[4];\n\tu8 tx_power_control;\n\n\tu8 addr[3][ETH_ALEN];\n\n\tu32 tx_pending;\n\tu32 tx_queued;\n\tu16 tx_queued_limit;\n\tu32 tx_done;\n\tstruct {\n\t\tu64 packets[__MT_RXQ_MAX];\n\t\tu64 fcs_error[__MT_RXQ_MAX];\n\t} rx_stats;\n};\n\nstruct mt76_vif {\n\tu8 idx;\n\tu8 omac_idx;\n\tu8 band_idx;\n\tu8 wmm_idx;\n\tu8 scan_seq_num;\n\tu8 cipher;\n\tu8 basic_rates_idx;\n\tu8 mcast_rates_idx;\n\tu8 beacon_rates_idx;\n\tstruct ieee80211_chanctx_conf *ctx;\n};\n\nstruct mt76_phy {\n\tstruct ieee80211_hw *hw;\n\tstruct mt76_dev *dev;\n\tvoid *priv;\n\n\tunsigned long state;\n\tu8 band_idx;\n\n\tstruct mt76_queue *q_tx[__MT_TXQ_MAX];\n\n\tstruct cfg80211_chan_def chandef;\n\tstruct ieee80211_channel *main_chan;\n\n\tstruct mt76_channel_state *chan_state;\n\tenum mt76_dfs_state dfs_state;\n\tktime_t survey_time;\n\n\tu32 aggr_stats[32];\n\n\tstruct mt76_hw_cap cap;\n\tstruct mt76_sband sband_2g;\n\tstruct mt76_sband sband_5g;\n\tstruct mt76_sband sband_6g;\n\n\tu8 macaddr[ETH_ALEN];\n\n\tint txpower_cur;\n\tu8 antenna_mask;\n\tu16 chainmask;\n\n#ifdef CONFIG_NL80211_TESTMODE\n\tstruct mt76_testmode_data test;\n#endif\n\n\tstruct delayed_work mac_work;\n\tu8 mac_work_count;\n\n\tstruct {\n\t\tstruct sk_buff *head;\n\t\tstruct sk_buff **tail;\n\t\tu16 seqno;\n\t} rx_amsdu[__MT_RXQ_MAX];\n\n\tstruct mt76_freq_range_power *frp;\n\n\tstruct {\n\t\tstruct led_classdev cdev;\n\t\tchar name[32];\n\t\tbool al;\n\t\tu8 pin;\n\t} leds;\n};\n\nstruct mt76_dev {\n\tstruct mt76_phy phy;  \n\tstruct mt76_phy *phys[__MT_MAX_BAND];\n\n\tstruct ieee80211_hw *hw;\n\n\tspinlock_t wed_lock;\n\tspinlock_t lock;\n\tspinlock_t cc_lock;\n\n\tu32 cur_cc_bss_rx;\n\n\tstruct mt76_rx_status rx_ampdu_status;\n\tu32 rx_ampdu_len;\n\tu32 rx_ampdu_ref;\n\n\tstruct mutex mutex;\n\n\tconst struct mt76_bus_ops *bus;\n\tconst struct mt76_driver_ops *drv;\n\tconst struct mt76_mcu_ops *mcu_ops;\n\tstruct device *dev;\n\tstruct device *dma_dev;\n\n\tstruct mt76_mcu mcu;\n\n\tstruct net_device napi_dev;\n\tstruct net_device tx_napi_dev;\n\tspinlock_t rx_lock;\n\tstruct napi_struct napi[__MT_RXQ_MAX];\n\tstruct sk_buff_head rx_skb[__MT_RXQ_MAX];\n\tstruct tasklet_struct irq_tasklet;\n\n\tstruct list_head txwi_cache;\n\tstruct list_head rxwi_cache;\n\tstruct mt76_queue *q_mcu[__MT_MCUQ_MAX];\n\tstruct mt76_queue q_rx[__MT_RXQ_MAX];\n\tconst struct mt76_queue_ops *queue_ops;\n\tint tx_dma_idx[4];\n\n\tstruct mt76_worker tx_worker;\n\tstruct napi_struct tx_napi;\n\n\tspinlock_t token_lock;\n\tstruct idr token;\n\tu16 wed_token_count;\n\tu16 token_count;\n\tu16 token_size;\n\n\tspinlock_t rx_token_lock;\n\tstruct idr rx_token;\n\tu16 rx_token_size;\n\n\twait_queue_head_t tx_wait;\n\t \n\tspinlock_t status_lock;\n\n\tu32 wcid_mask[DIV_ROUND_UP(MT76_N_WCIDS, 32)];\n\tu32 wcid_phy_mask[DIV_ROUND_UP(MT76_N_WCIDS, 32)];\n\n\tu64 vif_mask;\n\n\tstruct mt76_wcid global_wcid;\n\tstruct mt76_wcid __rcu *wcid[MT76_N_WCIDS];\n\tstruct list_head wcid_list;\n\n\tstruct list_head sta_poll_list;\n\tspinlock_t sta_poll_lock;\n\n\tu32 rev;\n\n\tstruct tasklet_struct pre_tbtt_tasklet;\n\tint beacon_int;\n\tu8 beacon_mask;\n\n\tstruct debugfs_blob_wrapper eeprom;\n\tstruct debugfs_blob_wrapper otp;\n\n\tchar alpha2[3];\n\tenum nl80211_dfs_regions region;\n\n\tu32 debugfs_reg;\n\n\tu8 csa_complete;\n\n\tu32 rxfilter;\n\n#ifdef CONFIG_NL80211_TESTMODE\n\tconst struct mt76_testmode_ops *test_ops;\n\tstruct {\n\t\tconst char *name;\n\t\tu32 offset;\n\t} test_mtd;\n#endif\n\tstruct workqueue_struct *wq;\n\n\tunion {\n\t\tstruct mt76_mmio mmio;\n\t\tstruct mt76_usb usb;\n\t\tstruct mt76_sdio sdio;\n\t};\n};\n\n \nstruct mt76_mib_stats {\n\tu32 ack_fail_cnt;\n\tu32 fcs_err_cnt;\n\tu32 rts_cnt;\n\tu32 rts_retries_cnt;\n\tu32 ba_miss_cnt;\n\tu32 tx_bf_cnt;\n\tu32 tx_mu_bf_cnt;\n\tu32 tx_mu_mpdu_cnt;\n\tu32 tx_mu_acked_mpdu_cnt;\n\tu32 tx_su_acked_mpdu_cnt;\n\tu32 tx_bf_ibf_ppdu_cnt;\n\tu32 tx_bf_ebf_ppdu_cnt;\n\n\tu32 tx_bf_rx_fb_all_cnt;\n\tu32 tx_bf_rx_fb_eht_cnt;\n\tu32 tx_bf_rx_fb_he_cnt;\n\tu32 tx_bf_rx_fb_vht_cnt;\n\tu32 tx_bf_rx_fb_ht_cnt;\n\n\tu32 tx_bf_rx_fb_bw;  \n\tu32 tx_bf_rx_fb_nc_cnt;\n\tu32 tx_bf_rx_fb_nr_cnt;\n\tu32 tx_bf_fb_cpl_cnt;\n\tu32 tx_bf_fb_trig_cnt;\n\n\tu32 tx_ampdu_cnt;\n\tu32 tx_stop_q_empty_cnt;\n\tu32 tx_mpdu_attempts_cnt;\n\tu32 tx_mpdu_success_cnt;\n\tu32 tx_pkt_ebf_cnt;\n\tu32 tx_pkt_ibf_cnt;\n\n\tu32 tx_rwp_fail_cnt;\n\tu32 tx_rwp_need_cnt;\n\n\t \n\tu32 rx_fifo_full_cnt;\n\tu32 channel_idle_cnt;\n\tu32 primary_cca_busy_time;\n\tu32 secondary_cca_busy_time;\n\tu32 primary_energy_detect_time;\n\tu32 cck_mdrdy_time;\n\tu32 ofdm_mdrdy_time;\n\tu32 green_mdrdy_time;\n\tu32 rx_vector_mismatch_cnt;\n\tu32 rx_delimiter_fail_cnt;\n\tu32 rx_mrdy_cnt;\n\tu32 rx_len_mismatch_cnt;\n\tu32 rx_mpdu_cnt;\n\tu32 rx_ampdu_cnt;\n\tu32 rx_ampdu_bytes_cnt;\n\tu32 rx_ampdu_valid_subframe_cnt;\n\tu32 rx_ampdu_valid_subframe_bytes_cnt;\n\tu32 rx_pfdrop_cnt;\n\tu32 rx_vec_queue_overflow_drop_cnt;\n\tu32 rx_ba_cnt;\n\n\tu32 tx_amsdu[8];\n\tu32 tx_amsdu_cnt;\n\n\t \n\tu32 dl_cck_cnt;\n\tu32 dl_ofdm_cnt;\n\tu32 dl_htmix_cnt;\n\tu32 dl_htgf_cnt;\n\tu32 dl_vht_su_cnt;\n\tu32 dl_vht_2mu_cnt;\n\tu32 dl_vht_3mu_cnt;\n\tu32 dl_vht_4mu_cnt;\n\tu32 dl_he_su_cnt;\n\tu32 dl_he_ext_su_cnt;\n\tu32 dl_he_2ru_cnt;\n\tu32 dl_he_2mu_cnt;\n\tu32 dl_he_3ru_cnt;\n\tu32 dl_he_3mu_cnt;\n\tu32 dl_he_4ru_cnt;\n\tu32 dl_he_4mu_cnt;\n\tu32 dl_he_5to8ru_cnt;\n\tu32 dl_he_9to16ru_cnt;\n\tu32 dl_he_gtr16ru_cnt;\n\n\tu32 ul_hetrig_su_cnt;\n\tu32 ul_hetrig_2ru_cnt;\n\tu32 ul_hetrig_3ru_cnt;\n\tu32 ul_hetrig_4ru_cnt;\n\tu32 ul_hetrig_5to8ru_cnt;\n\tu32 ul_hetrig_9to16ru_cnt;\n\tu32 ul_hetrig_gtr16ru_cnt;\n\tu32 ul_hetrig_2mu_cnt;\n\tu32 ul_hetrig_3mu_cnt;\n\tu32 ul_hetrig_4mu_cnt;\n};\n\nstruct mt76_power_limits {\n\ts8 cck[4];\n\ts8 ofdm[8];\n\ts8 mcs[4][10];\n\ts8 ru[7][12];\n};\n\nstruct mt76_ethtool_worker_info {\n\tu64 *data;\n\tint idx;\n\tint initial_stat_idx;\n\tint worker_stat_count;\n\tint sta_count;\n};\n\n#define CCK_RATE(_idx, _rate) {\t\t\t\t\t\\\n\t.bitrate = _rate,\t\t\t\t\t\\\n\t.flags = IEEE80211_RATE_SHORT_PREAMBLE,\t\t\t\\\n\t.hw_value = (MT_PHY_TYPE_CCK << 8) | (_idx),\t\t\\\n\t.hw_value_short = (MT_PHY_TYPE_CCK << 8) | (4 + _idx),\t\\\n}\n\n#define OFDM_RATE(_idx, _rate) {\t\t\t\t\\\n\t.bitrate = _rate,\t\t\t\t\t\\\n\t.hw_value = (MT_PHY_TYPE_OFDM << 8) | (_idx),\t\t\\\n\t.hw_value_short = (MT_PHY_TYPE_OFDM << 8) | (_idx),\t\\\n}\n\nextern struct ieee80211_rate mt76_rates[12];\n\n#define __mt76_rr(dev, ...)\t(dev)->bus->rr((dev), __VA_ARGS__)\n#define __mt76_wr(dev, ...)\t(dev)->bus->wr((dev), __VA_ARGS__)\n#define __mt76_rmw(dev, ...)\t(dev)->bus->rmw((dev), __VA_ARGS__)\n#define __mt76_wr_copy(dev, ...)\t(dev)->bus->write_copy((dev), __VA_ARGS__)\n#define __mt76_rr_copy(dev, ...)\t(dev)->bus->read_copy((dev), __VA_ARGS__)\n\n#define __mt76_set(dev, offset, val)\t__mt76_rmw(dev, offset, 0, val)\n#define __mt76_clear(dev, offset, val)\t__mt76_rmw(dev, offset, val, 0)\n\n#define mt76_rr(dev, ...)\t(dev)->mt76.bus->rr(&((dev)->mt76), __VA_ARGS__)\n#define mt76_wr(dev, ...)\t(dev)->mt76.bus->wr(&((dev)->mt76), __VA_ARGS__)\n#define mt76_rmw(dev, ...)\t(dev)->mt76.bus->rmw(&((dev)->mt76), __VA_ARGS__)\n#define mt76_wr_copy(dev, ...)\t(dev)->mt76.bus->write_copy(&((dev)->mt76), __VA_ARGS__)\n#define mt76_rr_copy(dev, ...)\t(dev)->mt76.bus->read_copy(&((dev)->mt76), __VA_ARGS__)\n#define mt76_wr_rp(dev, ...)\t(dev)->mt76.bus->wr_rp(&((dev)->mt76), __VA_ARGS__)\n#define mt76_rd_rp(dev, ...)\t(dev)->mt76.bus->rd_rp(&((dev)->mt76), __VA_ARGS__)\n\n\n#define mt76_mcu_restart(dev, ...)\t(dev)->mt76.mcu_ops->mcu_restart(&((dev)->mt76))\n\n#define mt76_set(dev, offset, val)\tmt76_rmw(dev, offset, 0, val)\n#define mt76_clear(dev, offset, val)\tmt76_rmw(dev, offset, val, 0)\n\n#define mt76_get_field(_dev, _reg, _field)\t\t\\\n\tFIELD_GET(_field, mt76_rr(dev, _reg))\n\n#define mt76_rmw_field(_dev, _reg, _field, _val)\t\\\n\tmt76_rmw(_dev, _reg, _field, FIELD_PREP(_field, _val))\n\n#define __mt76_rmw_field(_dev, _reg, _field, _val)\t\\\n\t__mt76_rmw(_dev, _reg, _field, FIELD_PREP(_field, _val))\n\n#define mt76_hw(dev) (dev)->mphy.hw\n\nbool __mt76_poll(struct mt76_dev *dev, u32 offset, u32 mask, u32 val,\n\t\t int timeout);\n\n#define mt76_poll(dev, ...) __mt76_poll(&((dev)->mt76), __VA_ARGS__)\n\nbool ____mt76_poll_msec(struct mt76_dev *dev, u32 offset, u32 mask, u32 val,\n\t\t\tint timeout, int kick);\n#define __mt76_poll_msec(...)         ____mt76_poll_msec(__VA_ARGS__, 10)\n#define mt76_poll_msec(dev, ...)      ____mt76_poll_msec(&((dev)->mt76), __VA_ARGS__, 10)\n#define mt76_poll_msec_tick(dev, ...) ____mt76_poll_msec(&((dev)->mt76), __VA_ARGS__)\n\nvoid mt76_mmio_init(struct mt76_dev *dev, void __iomem *regs);\nvoid mt76_pci_disable_aspm(struct pci_dev *pdev);\n\nstatic inline u16 mt76_chip(struct mt76_dev *dev)\n{\n\treturn dev->rev >> 16;\n}\n\nstatic inline u16 mt76_rev(struct mt76_dev *dev)\n{\n\treturn dev->rev & 0xffff;\n}\n\n#define mt76xx_chip(dev) mt76_chip(&((dev)->mt76))\n#define mt76xx_rev(dev) mt76_rev(&((dev)->mt76))\n\n#define mt76_init_queues(dev, ...)\t\t(dev)->mt76.queue_ops->init(&((dev)->mt76), __VA_ARGS__)\n#define mt76_queue_alloc(dev, ...)\t(dev)->mt76.queue_ops->alloc(&((dev)->mt76), __VA_ARGS__)\n#define mt76_tx_queue_skb_raw(dev, ...)\t(dev)->mt76.queue_ops->tx_queue_skb_raw(&((dev)->mt76), __VA_ARGS__)\n#define mt76_tx_queue_skb(dev, ...)\t(dev)->mt76.queue_ops->tx_queue_skb(&((dev)->mt76), __VA_ARGS__)\n#define mt76_queue_rx_reset(dev, ...)\t(dev)->mt76.queue_ops->rx_reset(&((dev)->mt76), __VA_ARGS__)\n#define mt76_queue_tx_cleanup(dev, ...)\t(dev)->mt76.queue_ops->tx_cleanup(&((dev)->mt76), __VA_ARGS__)\n#define mt76_queue_rx_cleanup(dev, ...)\t(dev)->mt76.queue_ops->rx_cleanup(&((dev)->mt76), __VA_ARGS__)\n#define mt76_queue_kick(dev, ...)\t(dev)->mt76.queue_ops->kick(&((dev)->mt76), __VA_ARGS__)\n#define mt76_queue_reset(dev, ...)\t(dev)->mt76.queue_ops->reset_q(&((dev)->mt76), __VA_ARGS__)\n\n#define mt76_for_each_q_rx(dev, i)\t\\\n\tfor (i = 0; i < ARRAY_SIZE((dev)->q_rx); i++)\t\\\n\t\tif ((dev)->q_rx[i].ndesc)\n\nstruct mt76_dev *mt76_alloc_device(struct device *pdev, unsigned int size,\n\t\t\t\t   const struct ieee80211_ops *ops,\n\t\t\t\t   const struct mt76_driver_ops *drv_ops);\nint mt76_register_device(struct mt76_dev *dev, bool vht,\n\t\t\t struct ieee80211_rate *rates, int n_rates);\nvoid mt76_unregister_device(struct mt76_dev *dev);\nvoid mt76_free_device(struct mt76_dev *dev);\nvoid mt76_unregister_phy(struct mt76_phy *phy);\n\nstruct mt76_phy *mt76_alloc_phy(struct mt76_dev *dev, unsigned int size,\n\t\t\t\tconst struct ieee80211_ops *ops,\n\t\t\t\tu8 band_idx);\nint mt76_register_phy(struct mt76_phy *phy, bool vht,\n\t\t      struct ieee80211_rate *rates, int n_rates);\n\nstruct dentry *mt76_register_debugfs_fops(struct mt76_phy *phy,\n\t\t\t\t\t  const struct file_operations *ops);\nstatic inline struct dentry *mt76_register_debugfs(struct mt76_dev *dev)\n{\n\treturn mt76_register_debugfs_fops(&dev->phy, NULL);\n}\n\nint mt76_queues_read(struct seq_file *s, void *data);\nvoid mt76_seq_puts_array(struct seq_file *file, const char *str,\n\t\t\t s8 *val, int len);\n\nint mt76_eeprom_init(struct mt76_dev *dev, int len);\nvoid mt76_eeprom_override(struct mt76_phy *phy);\nint mt76_get_of_eeprom(struct mt76_dev *dev, void *data, int offset, int len);\n\nstruct mt76_queue *\nmt76_init_queue(struct mt76_dev *dev, int qid, int idx, int n_desc,\n\t\tint ring_base, u32 flags);\nu16 mt76_calculate_default_rate(struct mt76_phy *phy,\n\t\t\t\tstruct ieee80211_vif *vif, int rateidx);\nstatic inline int mt76_init_tx_queue(struct mt76_phy *phy, int qid, int idx,\n\t\t\t\t     int n_desc, int ring_base, u32 flags)\n{\n\tstruct mt76_queue *q;\n\n\tq = mt76_init_queue(phy->dev, qid, idx, n_desc, ring_base, flags);\n\tif (IS_ERR(q))\n\t\treturn PTR_ERR(q);\n\n\tphy->q_tx[qid] = q;\n\n\treturn 0;\n}\n\nstatic inline int mt76_init_mcu_queue(struct mt76_dev *dev, int qid, int idx,\n\t\t\t\t      int n_desc, int ring_base)\n{\n\tstruct mt76_queue *q;\n\n\tq = mt76_init_queue(dev, qid, idx, n_desc, ring_base, 0);\n\tif (IS_ERR(q))\n\t\treturn PTR_ERR(q);\n\n\tdev->q_mcu[qid] = q;\n\n\treturn 0;\n}\n\nstatic inline struct mt76_phy *\nmt76_dev_phy(struct mt76_dev *dev, u8 phy_idx)\n{\n\tif ((phy_idx == MT_BAND1 && dev->phys[phy_idx]) ||\n\t    (phy_idx == MT_BAND2 && dev->phys[phy_idx]))\n\t\treturn dev->phys[phy_idx];\n\n\treturn &dev->phy;\n}\n\nstatic inline struct ieee80211_hw *\nmt76_phy_hw(struct mt76_dev *dev, u8 phy_idx)\n{\n\treturn mt76_dev_phy(dev, phy_idx)->hw;\n}\n\nstatic inline u8 *\nmt76_get_txwi_ptr(struct mt76_dev *dev, struct mt76_txwi_cache *t)\n{\n\treturn (u8 *)t - dev->drv->txwi_size;\n}\n\n \nstatic inline int mt76_incr(int val, int size)\n{\n\treturn (val + 1) & (size - 1);\n}\n\n \nstatic inline int mt76_decr(int val, int size)\n{\n\treturn (val - 1) & (size - 1);\n}\n\nu8 mt76_ac_to_hwq(u8 ac);\n\nstatic inline struct ieee80211_txq *\nmtxq_to_txq(struct mt76_txq *mtxq)\n{\n\tvoid *ptr = mtxq;\n\n\treturn container_of(ptr, struct ieee80211_txq, drv_priv);\n}\n\nstatic inline struct ieee80211_sta *\nwcid_to_sta(struct mt76_wcid *wcid)\n{\n\tvoid *ptr = wcid;\n\n\tif (!wcid || !wcid->sta)\n\t\treturn NULL;\n\n\treturn container_of(ptr, struct ieee80211_sta, drv_priv);\n}\n\nstatic inline struct mt76_tx_cb *mt76_tx_skb_cb(struct sk_buff *skb)\n{\n\tBUILD_BUG_ON(sizeof(struct mt76_tx_cb) >\n\t\t     sizeof(IEEE80211_SKB_CB(skb)->status.status_driver_data));\n\treturn ((void *)IEEE80211_SKB_CB(skb)->status.status_driver_data);\n}\n\nstatic inline void *mt76_skb_get_hdr(struct sk_buff *skb)\n{\n\tstruct mt76_rx_status mstat;\n\tu8 *data = skb->data;\n\n\t \n\tBUILD_BUG_ON(sizeof(struct ieee80211_radiotap_he) % 4);\n\tBUILD_BUG_ON(sizeof(struct ieee80211_radiotap_he_mu) % 4);\n\n\tmstat = *((struct mt76_rx_status *)skb->cb);\n\n\tif (mstat.flag & RX_FLAG_RADIOTAP_HE)\n\t\tdata += sizeof(struct ieee80211_radiotap_he);\n\tif (mstat.flag & RX_FLAG_RADIOTAP_HE_MU)\n\t\tdata += sizeof(struct ieee80211_radiotap_he_mu);\n\n\treturn data;\n}\n\nstatic inline void mt76_insert_hdr_pad(struct sk_buff *skb)\n{\n\tint len = ieee80211_get_hdrlen_from_skb(skb);\n\n\tif (len % 4 == 0)\n\t\treturn;\n\n\tskb_push(skb, 2);\n\tmemmove(skb->data, skb->data + 2, len);\n\n\tskb->data[len] = 0;\n\tskb->data[len + 1] = 0;\n}\n\nstatic inline bool mt76_is_skb_pktid(u8 pktid)\n{\n\tif (pktid & MT_PACKET_ID_HAS_RATE)\n\t\treturn false;\n\n\treturn pktid >= MT_PACKET_ID_FIRST;\n}\n\nstatic inline u8 mt76_tx_power_nss_delta(u8 nss)\n{\n\tstatic const u8 nss_delta[4] = { 0, 6, 9, 12 };\n\tu8 idx = nss - 1;\n\n\treturn (idx < ARRAY_SIZE(nss_delta)) ? nss_delta[idx] : 0;\n}\n\nstatic inline bool mt76_testmode_enabled(struct mt76_phy *phy)\n{\n#ifdef CONFIG_NL80211_TESTMODE\n\treturn phy->test.state != MT76_TM_STATE_OFF;\n#else\n\treturn false;\n#endif\n}\n\nstatic inline bool mt76_is_testmode_skb(struct mt76_dev *dev,\n\t\t\t\t\tstruct sk_buff *skb,\n\t\t\t\t\tstruct ieee80211_hw **hw)\n{\n#ifdef CONFIG_NL80211_TESTMODE\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(dev->phys); i++) {\n\t\tstruct mt76_phy *phy = dev->phys[i];\n\n\t\tif (phy && skb == phy->test.tx_skb) {\n\t\t\t*hw = dev->phys[i]->hw;\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n#else\n\treturn false;\n#endif\n}\n\nvoid mt76_rx(struct mt76_dev *dev, enum mt76_rxq_id q, struct sk_buff *skb);\nvoid mt76_tx(struct mt76_phy *dev, struct ieee80211_sta *sta,\n\t     struct mt76_wcid *wcid, struct sk_buff *skb);\nvoid mt76_wake_tx_queue(struct ieee80211_hw *hw, struct ieee80211_txq *txq);\nvoid mt76_stop_tx_queues(struct mt76_phy *phy, struct ieee80211_sta *sta,\n\t\t\t bool send_bar);\nvoid mt76_tx_check_agg_ssn(struct ieee80211_sta *sta, struct sk_buff *skb);\nvoid mt76_txq_schedule(struct mt76_phy *phy, enum mt76_txq_id qid);\nvoid mt76_txq_schedule_all(struct mt76_phy *phy);\nvoid mt76_tx_worker_run(struct mt76_dev *dev);\nvoid mt76_tx_worker(struct mt76_worker *w);\nvoid mt76_release_buffered_frames(struct ieee80211_hw *hw,\n\t\t\t\t  struct ieee80211_sta *sta,\n\t\t\t\t  u16 tids, int nframes,\n\t\t\t\t  enum ieee80211_frame_release_type reason,\n\t\t\t\t  bool more_data);\nbool mt76_has_tx_pending(struct mt76_phy *phy);\nvoid mt76_set_channel(struct mt76_phy *phy);\nvoid mt76_update_survey(struct mt76_phy *phy);\nvoid mt76_update_survey_active_time(struct mt76_phy *phy, ktime_t time);\nint mt76_get_survey(struct ieee80211_hw *hw, int idx,\n\t\t    struct survey_info *survey);\nint mt76_rx_signal(u8 chain_mask, s8 *chain_signal);\nvoid mt76_set_stream_caps(struct mt76_phy *phy, bool vht);\n\nint mt76_rx_aggr_start(struct mt76_dev *dev, struct mt76_wcid *wcid, u8 tid,\n\t\t       u16 ssn, u16 size);\nvoid mt76_rx_aggr_stop(struct mt76_dev *dev, struct mt76_wcid *wcid, u8 tid);\n\nvoid mt76_wcid_key_setup(struct mt76_dev *dev, struct mt76_wcid *wcid,\n\t\t\t struct ieee80211_key_conf *key);\n\nvoid mt76_tx_status_lock(struct mt76_dev *dev, struct sk_buff_head *list)\n\t\t\t __acquires(&dev->status_lock);\nvoid mt76_tx_status_unlock(struct mt76_dev *dev, struct sk_buff_head *list)\n\t\t\t   __releases(&dev->status_lock);\n\nint mt76_tx_status_skb_add(struct mt76_dev *dev, struct mt76_wcid *wcid,\n\t\t\t   struct sk_buff *skb);\nstruct sk_buff *mt76_tx_status_skb_get(struct mt76_dev *dev,\n\t\t\t\t       struct mt76_wcid *wcid, int pktid,\n\t\t\t\t       struct sk_buff_head *list);\nvoid mt76_tx_status_skb_done(struct mt76_dev *dev, struct sk_buff *skb,\n\t\t\t     struct sk_buff_head *list);\nvoid __mt76_tx_complete_skb(struct mt76_dev *dev, u16 wcid, struct sk_buff *skb,\n\t\t\t    struct list_head *free_list);\nstatic inline void\nmt76_tx_complete_skb(struct mt76_dev *dev, u16 wcid, struct sk_buff *skb)\n{\n    __mt76_tx_complete_skb(dev, wcid, skb, NULL);\n}\n\nvoid mt76_tx_status_check(struct mt76_dev *dev, bool flush);\nint mt76_sta_state(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\n\t\t   struct ieee80211_sta *sta,\n\t\t   enum ieee80211_sta_state old_state,\n\t\t   enum ieee80211_sta_state new_state);\nvoid __mt76_sta_remove(struct mt76_dev *dev, struct ieee80211_vif *vif,\n\t\t       struct ieee80211_sta *sta);\nvoid mt76_sta_pre_rcu_remove(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\n\t\t\t     struct ieee80211_sta *sta);\n\nint mt76_get_min_avg_rssi(struct mt76_dev *dev, bool ext_phy);\n\nint mt76_get_txpower(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\n\t\t     int *dbm);\nint mt76_init_sar_power(struct ieee80211_hw *hw,\n\t\t\tconst struct cfg80211_sar_specs *sar);\nint mt76_get_sar_power(struct mt76_phy *phy,\n\t\t       struct ieee80211_channel *chan,\n\t\t       int power);\n\nvoid mt76_csa_check(struct mt76_dev *dev);\nvoid mt76_csa_finish(struct mt76_dev *dev);\n\nint mt76_get_antenna(struct ieee80211_hw *hw, u32 *tx_ant, u32 *rx_ant);\nint mt76_set_tim(struct ieee80211_hw *hw, struct ieee80211_sta *sta, bool set);\nvoid mt76_insert_ccmp_hdr(struct sk_buff *skb, u8 key_id);\nint mt76_get_rate(struct mt76_dev *dev,\n\t\t  struct ieee80211_supported_band *sband,\n\t\t  int idx, bool cck);\nvoid mt76_sw_scan(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\n\t\t  const u8 *mac);\nvoid mt76_sw_scan_complete(struct ieee80211_hw *hw,\n\t\t\t   struct ieee80211_vif *vif);\nenum mt76_dfs_state mt76_phy_dfs_state(struct mt76_phy *phy);\nint mt76_testmode_cmd(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\n\t\t      void *data, int len);\nint mt76_testmode_dump(struct ieee80211_hw *hw, struct sk_buff *skb,\n\t\t       struct netlink_callback *cb, void *data, int len);\nint mt76_testmode_set_state(struct mt76_phy *phy, enum mt76_testmode_state state);\nint mt76_testmode_alloc_skb(struct mt76_phy *phy, u32 len);\n\nstatic inline void mt76_testmode_reset(struct mt76_phy *phy, bool disable)\n{\n#ifdef CONFIG_NL80211_TESTMODE\n\tenum mt76_testmode_state state = MT76_TM_STATE_IDLE;\n\n\tif (disable || phy->test.state == MT76_TM_STATE_OFF)\n\t\tstate = MT76_TM_STATE_OFF;\n\n\tmt76_testmode_set_state(phy, state);\n#endif\n}\n\n\n \nstatic inline struct ieee80211_hw *\nmt76_tx_status_get_hw(struct mt76_dev *dev, struct sk_buff *skb)\n{\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tu8 phy_idx = (info->hw_queue & MT_TX_HW_QUEUE_PHY) >> 2;\n\tstruct ieee80211_hw *hw = mt76_phy_hw(dev, phy_idx);\n\n\tinfo->hw_queue &= ~MT_TX_HW_QUEUE_PHY;\n\n\treturn hw;\n}\n\nvoid mt76_put_txwi(struct mt76_dev *dev, struct mt76_txwi_cache *t);\nvoid mt76_put_rxwi(struct mt76_dev *dev, struct mt76_txwi_cache *t);\nstruct mt76_txwi_cache *mt76_get_rxwi(struct mt76_dev *dev);\nvoid mt76_free_pending_rxwi(struct mt76_dev *dev);\nvoid mt76_rx_complete(struct mt76_dev *dev, struct sk_buff_head *frames,\n\t\t      struct napi_struct *napi);\nvoid mt76_rx_poll_complete(struct mt76_dev *dev, enum mt76_rxq_id q,\n\t\t\t   struct napi_struct *napi);\nvoid mt76_rx_aggr_reorder(struct sk_buff *skb, struct sk_buff_head *frames);\nvoid mt76_testmode_tx_pending(struct mt76_phy *phy);\nvoid mt76_queue_tx_complete(struct mt76_dev *dev, struct mt76_queue *q,\n\t\t\t    struct mt76_queue_entry *e);\n\n \nstatic inline bool mt76u_urb_error(struct urb *urb)\n{\n\treturn urb->status &&\n\t       urb->status != -ECONNRESET &&\n\t       urb->status != -ESHUTDOWN &&\n\t       urb->status != -ENOENT;\n}\n\n \nstatic inline u8 q2ep(u8 qid)\n{\n\t \n\treturn qid + 1;\n}\n\nstatic inline int\nmt76u_bulk_msg(struct mt76_dev *dev, void *data, int len, int *actual_len,\n\t       int timeout, int ep)\n{\n\tstruct usb_interface *uintf = to_usb_interface(dev->dev);\n\tstruct usb_device *udev = interface_to_usbdev(uintf);\n\tstruct mt76_usb *usb = &dev->usb;\n\tunsigned int pipe;\n\n\tif (actual_len)\n\t\tpipe = usb_rcvbulkpipe(udev, usb->in_ep[ep]);\n\telse\n\t\tpipe = usb_sndbulkpipe(udev, usb->out_ep[ep]);\n\n\treturn usb_bulk_msg(udev, pipe, data, len, actual_len, timeout);\n}\n\nvoid mt76_ethtool_page_pool_stats(struct mt76_dev *dev, u64 *data, int *index);\nvoid mt76_ethtool_worker(struct mt76_ethtool_worker_info *wi,\n\t\t\t struct mt76_sta_stats *stats, bool eht);\nint mt76_skb_adjust_pad(struct sk_buff *skb, int pad);\nint __mt76u_vendor_request(struct mt76_dev *dev, u8 req, u8 req_type,\n\t\t\t   u16 val, u16 offset, void *buf, size_t len);\nint mt76u_vendor_request(struct mt76_dev *dev, u8 req,\n\t\t\t u8 req_type, u16 val, u16 offset,\n\t\t\t void *buf, size_t len);\nvoid mt76u_single_wr(struct mt76_dev *dev, const u8 req,\n\t\t     const u16 offset, const u32 val);\nvoid mt76u_read_copy(struct mt76_dev *dev, u32 offset,\n\t\t     void *data, int len);\nu32 ___mt76u_rr(struct mt76_dev *dev, u8 req, u8 req_type, u32 addr);\nvoid ___mt76u_wr(struct mt76_dev *dev, u8 req, u8 req_type,\n\t\t u32 addr, u32 val);\nint __mt76u_init(struct mt76_dev *dev, struct usb_interface *intf,\n\t\t struct mt76_bus_ops *ops);\nint mt76u_init(struct mt76_dev *dev, struct usb_interface *intf);\nint mt76u_alloc_mcu_queue(struct mt76_dev *dev);\nint mt76u_alloc_queues(struct mt76_dev *dev);\nvoid mt76u_stop_tx(struct mt76_dev *dev);\nvoid mt76u_stop_rx(struct mt76_dev *dev);\nint mt76u_resume_rx(struct mt76_dev *dev);\nvoid mt76u_queues_deinit(struct mt76_dev *dev);\n\nint mt76s_init(struct mt76_dev *dev, struct sdio_func *func,\n\t       const struct mt76_bus_ops *bus_ops);\nint mt76s_alloc_rx_queue(struct mt76_dev *dev, enum mt76_rxq_id qid);\nint mt76s_alloc_tx(struct mt76_dev *dev);\nvoid mt76s_deinit(struct mt76_dev *dev);\nvoid mt76s_sdio_irq(struct sdio_func *func);\nvoid mt76s_txrx_worker(struct mt76_sdio *sdio);\nbool mt76s_txqs_empty(struct mt76_dev *dev);\nint mt76s_hw_init(struct mt76_dev *dev, struct sdio_func *func,\n\t\t  int hw_ver);\nu32 mt76s_rr(struct mt76_dev *dev, u32 offset);\nvoid mt76s_wr(struct mt76_dev *dev, u32 offset, u32 val);\nu32 mt76s_rmw(struct mt76_dev *dev, u32 offset, u32 mask, u32 val);\nu32 mt76s_read_pcr(struct mt76_dev *dev);\nvoid mt76s_write_copy(struct mt76_dev *dev, u32 offset,\n\t\t      const void *data, int len);\nvoid mt76s_read_copy(struct mt76_dev *dev, u32 offset,\n\t\t     void *data, int len);\nint mt76s_wr_rp(struct mt76_dev *dev, u32 base,\n\t\tconst struct mt76_reg_pair *data,\n\t\tint len);\nint mt76s_rd_rp(struct mt76_dev *dev, u32 base,\n\t\tstruct mt76_reg_pair *data, int len);\n\nstruct sk_buff *\n__mt76_mcu_msg_alloc(struct mt76_dev *dev, const void *data,\n\t\t     int len, int data_len, gfp_t gfp);\nstatic inline struct sk_buff *\nmt76_mcu_msg_alloc(struct mt76_dev *dev, const void *data,\n\t\t   int data_len)\n{\n\treturn __mt76_mcu_msg_alloc(dev, data, data_len, data_len, GFP_KERNEL);\n}\n\nvoid mt76_mcu_rx_event(struct mt76_dev *dev, struct sk_buff *skb);\nstruct sk_buff *mt76_mcu_get_response(struct mt76_dev *dev,\n\t\t\t\t      unsigned long expires);\nint mt76_mcu_send_and_get_msg(struct mt76_dev *dev, int cmd, const void *data,\n\t\t\t      int len, bool wait_resp, struct sk_buff **ret);\nint mt76_mcu_skb_send_and_get_msg(struct mt76_dev *dev, struct sk_buff *skb,\n\t\t\t\t  int cmd, bool wait_resp, struct sk_buff **ret);\nint __mt76_mcu_send_firmware(struct mt76_dev *dev, int cmd, const void *data,\n\t\t\t     int len, int max_len);\nstatic inline int\nmt76_mcu_send_firmware(struct mt76_dev *dev, int cmd, const void *data,\n\t\t       int len)\n{\n\tint max_len = 4096 - dev->mcu_ops->headroom;\n\n\treturn __mt76_mcu_send_firmware(dev, cmd, data, len, max_len);\n}\n\nstatic inline int\nmt76_mcu_send_msg(struct mt76_dev *dev, int cmd, const void *data, int len,\n\t\t  bool wait_resp)\n{\n\treturn mt76_mcu_send_and_get_msg(dev, cmd, data, len, wait_resp, NULL);\n}\n\nstatic inline int\nmt76_mcu_skb_send_msg(struct mt76_dev *dev, struct sk_buff *skb, int cmd,\n\t\t      bool wait_resp)\n{\n\treturn mt76_mcu_skb_send_and_get_msg(dev, skb, cmd, wait_resp, NULL);\n}\n\nvoid mt76_set_irq_mask(struct mt76_dev *dev, u32 addr, u32 clear, u32 set);\n\ns8 mt76_get_rate_power_limits(struct mt76_phy *phy,\n\t\t\t      struct ieee80211_channel *chan,\n\t\t\t      struct mt76_power_limits *dest,\n\t\t\t      s8 target_power);\n\nstatic inline bool mt76_queue_is_wed_rx(struct mt76_queue *q)\n{\n\treturn (q->flags & MT_QFLAG_WED) &&\n\t       FIELD_GET(MT_QFLAG_WED_TYPE, q->flags) == MT76_WED_Q_RX;\n}\n\nstruct mt76_txwi_cache *\nmt76_token_release(struct mt76_dev *dev, int token, bool *wake);\nint mt76_token_consume(struct mt76_dev *dev, struct mt76_txwi_cache **ptxwi);\nvoid __mt76_set_tx_blocked(struct mt76_dev *dev, bool blocked);\nstruct mt76_txwi_cache *mt76_rx_token_release(struct mt76_dev *dev, int token);\nint mt76_rx_token_consume(struct mt76_dev *dev, void *ptr,\n\t\t\t  struct mt76_txwi_cache *r, dma_addr_t phys);\nint mt76_create_page_pool(struct mt76_dev *dev, struct mt76_queue *q);\nstatic inline void mt76_put_page_pool_buf(void *buf, bool allow_direct)\n{\n\tstruct page *page = virt_to_head_page(buf);\n\n\tpage_pool_put_full_page(page->pp, page, allow_direct);\n}\n\nstatic inline void *\nmt76_get_page_pool_buf(struct mt76_queue *q, u32 *offset, u32 size)\n{\n\tstruct page *page;\n\n\tpage = page_pool_dev_alloc_frag(q->page_pool, offset, size);\n\tif (!page)\n\t\treturn NULL;\n\n\treturn page_address(page) + *offset;\n}\n\nstatic inline void mt76_set_tx_blocked(struct mt76_dev *dev, bool blocked)\n{\n\tspin_lock_bh(&dev->token_lock);\n\t__mt76_set_tx_blocked(dev, blocked);\n\tspin_unlock_bh(&dev->token_lock);\n}\n\nstatic inline int\nmt76_token_get(struct mt76_dev *dev, struct mt76_txwi_cache **ptxwi)\n{\n\tint token;\n\n\tspin_lock_bh(&dev->token_lock);\n\ttoken = idr_alloc(&dev->token, *ptxwi, 0, dev->token_size, GFP_ATOMIC);\n\tspin_unlock_bh(&dev->token_lock);\n\n\treturn token;\n}\n\nstatic inline struct mt76_txwi_cache *\nmt76_token_put(struct mt76_dev *dev, int token)\n{\n\tstruct mt76_txwi_cache *txwi;\n\n\tspin_lock_bh(&dev->token_lock);\n\ttxwi = idr_remove(&dev->token, token);\n\tspin_unlock_bh(&dev->token_lock);\n\n\treturn txwi;\n}\n\nstatic inline void mt76_packet_id_init(struct mt76_wcid *wcid)\n{\n\tINIT_LIST_HEAD(&wcid->list);\n\tidr_init(&wcid->pktid);\n}\n\nstatic inline void\nmt76_packet_id_flush(struct mt76_dev *dev, struct mt76_wcid *wcid)\n{\n\tstruct sk_buff_head list;\n\n\tmt76_tx_status_lock(dev, &list);\n\tmt76_tx_status_skb_get(dev, wcid, -1, &list);\n\tmt76_tx_status_unlock(dev, &list);\n\n\tidr_destroy(&wcid->pktid);\n}\n\n#endif\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}