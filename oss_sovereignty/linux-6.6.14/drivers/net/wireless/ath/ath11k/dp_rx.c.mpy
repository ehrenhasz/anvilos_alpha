{
  "module_name": "dp_rx.c",
  "hash_id": "bfde3ac422c30972ecb4d99619d12fb13f729137b9559f992cb5cf069865736d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ath/ath11k/dp_rx.c",
  "human_readable_source": "\n \n\n#include <linux/ieee80211.h>\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <crypto/hash.h>\n#include \"core.h\"\n#include \"debug.h\"\n#include \"debugfs_htt_stats.h\"\n#include \"debugfs_sta.h\"\n#include \"hal_desc.h\"\n#include \"hw.h\"\n#include \"dp_rx.h\"\n#include \"hal_rx.h\"\n#include \"dp_tx.h\"\n#include \"peer.h\"\n\n#define ATH11K_DP_RX_FRAGMENT_TIMEOUT_MS (2 * HZ)\n\nstatic inline\nu8 *ath11k_dp_rx_h_80211_hdr(struct ath11k_base *ab, struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_hdr_status(desc);\n}\n\nstatic inline\nenum hal_encrypt_type ath11k_dp_rx_h_mpdu_start_enctype(struct ath11k_base *ab,\n\t\t\t\t\t\t\tstruct hal_rx_desc *desc)\n{\n\tif (!ab->hw_params.hw_ops->rx_desc_encrypt_valid(desc))\n\t\treturn HAL_ENCRYPT_TYPE_OPEN;\n\n\treturn ab->hw_params.hw_ops->rx_desc_get_encrypt_type(desc);\n}\n\nstatic inline u8 ath11k_dp_rx_h_msdu_start_decap_type(struct ath11k_base *ab,\n\t\t\t\t\t\t      struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_decap_type(desc);\n}\n\nstatic inline\nbool ath11k_dp_rx_h_msdu_start_ldpc_support(struct ath11k_base *ab,\n\t\t\t\t\t    struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_ldpc_support(desc);\n}\n\nstatic inline\nu8 ath11k_dp_rx_h_msdu_start_mesh_ctl_present(struct ath11k_base *ab,\n\t\t\t\t\t      struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_mesh_ctl(desc);\n}\n\nstatic inline\nbool ath11k_dp_rx_h_mpdu_start_seq_ctrl_valid(struct ath11k_base *ab,\n\t\t\t\t\t      struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_mpdu_seq_ctl_vld(desc);\n}\n\nstatic inline bool ath11k_dp_rx_h_mpdu_start_fc_valid(struct ath11k_base *ab,\n\t\t\t\t\t\t      struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_mpdu_fc_valid(desc);\n}\n\nstatic inline bool ath11k_dp_rx_h_mpdu_start_more_frags(struct ath11k_base *ab,\n\t\t\t\t\t\t\tstruct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr;\n\n\thdr = (struct ieee80211_hdr *)(skb->data + ab->hw_params.hal_desc_sz);\n\treturn ieee80211_has_morefrags(hdr->frame_control);\n}\n\nstatic inline u16 ath11k_dp_rx_h_mpdu_start_frag_no(struct ath11k_base *ab,\n\t\t\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr;\n\n\thdr = (struct ieee80211_hdr *)(skb->data + ab->hw_params.hal_desc_sz);\n\treturn le16_to_cpu(hdr->seq_ctrl) & IEEE80211_SCTL_FRAG;\n}\n\nstatic inline u16 ath11k_dp_rx_h_mpdu_start_seq_no(struct ath11k_base *ab,\n\t\t\t\t\t\t   struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_mpdu_start_seq_no(desc);\n}\n\nstatic inline void *ath11k_dp_rx_get_attention(struct ath11k_base *ab,\n\t\t\t\t\t       struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_attention(desc);\n}\n\nstatic inline bool ath11k_dp_rx_h_attn_msdu_done(struct rx_attention *attn)\n{\n\treturn !!FIELD_GET(RX_ATTENTION_INFO2_MSDU_DONE,\n\t\t\t   __le32_to_cpu(attn->info2));\n}\n\nstatic inline bool ath11k_dp_rx_h_attn_l4_cksum_fail(struct rx_attention *attn)\n{\n\treturn !!FIELD_GET(RX_ATTENTION_INFO1_TCP_UDP_CKSUM_FAIL,\n\t\t\t   __le32_to_cpu(attn->info1));\n}\n\nstatic inline bool ath11k_dp_rx_h_attn_ip_cksum_fail(struct rx_attention *attn)\n{\n\treturn !!FIELD_GET(RX_ATTENTION_INFO1_IP_CKSUM_FAIL,\n\t\t\t   __le32_to_cpu(attn->info1));\n}\n\nstatic inline bool ath11k_dp_rx_h_attn_is_decrypted(struct rx_attention *attn)\n{\n\treturn (FIELD_GET(RX_ATTENTION_INFO2_DCRYPT_STATUS_CODE,\n\t\t\t  __le32_to_cpu(attn->info2)) ==\n\t\tRX_DESC_DECRYPT_STATUS_CODE_OK);\n}\n\nstatic u32 ath11k_dp_rx_h_attn_mpdu_err(struct rx_attention *attn)\n{\n\tu32 info = __le32_to_cpu(attn->info1);\n\tu32 errmap = 0;\n\n\tif (info & RX_ATTENTION_INFO1_FCS_ERR)\n\t\terrmap |= DP_RX_MPDU_ERR_FCS;\n\n\tif (info & RX_ATTENTION_INFO1_DECRYPT_ERR)\n\t\terrmap |= DP_RX_MPDU_ERR_DECRYPT;\n\n\tif (info & RX_ATTENTION_INFO1_TKIP_MIC_ERR)\n\t\terrmap |= DP_RX_MPDU_ERR_TKIP_MIC;\n\n\tif (info & RX_ATTENTION_INFO1_A_MSDU_ERROR)\n\t\terrmap |= DP_RX_MPDU_ERR_AMSDU_ERR;\n\n\tif (info & RX_ATTENTION_INFO1_OVERFLOW_ERR)\n\t\terrmap |= DP_RX_MPDU_ERR_OVERFLOW;\n\n\tif (info & RX_ATTENTION_INFO1_MSDU_LEN_ERR)\n\t\terrmap |= DP_RX_MPDU_ERR_MSDU_LEN;\n\n\tif (info & RX_ATTENTION_INFO1_MPDU_LEN_ERR)\n\t\terrmap |= DP_RX_MPDU_ERR_MPDU_LEN;\n\n\treturn errmap;\n}\n\nstatic bool ath11k_dp_rx_h_attn_msdu_len_err(struct ath11k_base *ab,\n\t\t\t\t\t     struct hal_rx_desc *desc)\n{\n\tstruct rx_attention *rx_attention;\n\tu32 errmap;\n\n\trx_attention = ath11k_dp_rx_get_attention(ab, desc);\n\terrmap = ath11k_dp_rx_h_attn_mpdu_err(rx_attention);\n\n\treturn errmap & DP_RX_MPDU_ERR_MSDU_LEN;\n}\n\nstatic inline u16 ath11k_dp_rx_h_msdu_start_msdu_len(struct ath11k_base *ab,\n\t\t\t\t\t\t     struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_msdu_len(desc);\n}\n\nstatic inline u8 ath11k_dp_rx_h_msdu_start_sgi(struct ath11k_base *ab,\n\t\t\t\t\t       struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_msdu_sgi(desc);\n}\n\nstatic inline u8 ath11k_dp_rx_h_msdu_start_rate_mcs(struct ath11k_base *ab,\n\t\t\t\t\t\t    struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_msdu_rate_mcs(desc);\n}\n\nstatic inline u8 ath11k_dp_rx_h_msdu_start_rx_bw(struct ath11k_base *ab,\n\t\t\t\t\t\t struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_msdu_rx_bw(desc);\n}\n\nstatic inline u32 ath11k_dp_rx_h_msdu_start_freq(struct ath11k_base *ab,\n\t\t\t\t\t\t struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_msdu_freq(desc);\n}\n\nstatic inline u8 ath11k_dp_rx_h_msdu_start_pkt_type(struct ath11k_base *ab,\n\t\t\t\t\t\t    struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_msdu_pkt_type(desc);\n}\n\nstatic inline u8 ath11k_dp_rx_h_msdu_start_nss(struct ath11k_base *ab,\n\t\t\t\t\t       struct hal_rx_desc *desc)\n{\n\treturn hweight8(ab->hw_params.hw_ops->rx_desc_get_msdu_nss(desc));\n}\n\nstatic inline u8 ath11k_dp_rx_h_mpdu_start_tid(struct ath11k_base *ab,\n\t\t\t\t\t       struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_mpdu_tid(desc);\n}\n\nstatic inline u16 ath11k_dp_rx_h_mpdu_start_peer_id(struct ath11k_base *ab,\n\t\t\t\t\t\t    struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_mpdu_peer_id(desc);\n}\n\nstatic inline u8 ath11k_dp_rx_h_msdu_end_l3pad(struct ath11k_base *ab,\n\t\t\t\t\t       struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_l3_pad_bytes(desc);\n}\n\nstatic inline bool ath11k_dp_rx_h_msdu_end_first_msdu(struct ath11k_base *ab,\n\t\t\t\t\t\t      struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_first_msdu(desc);\n}\n\nstatic bool ath11k_dp_rx_h_msdu_end_last_msdu(struct ath11k_base *ab,\n\t\t\t\t\t      struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_last_msdu(desc);\n}\n\nstatic void ath11k_dp_rx_desc_end_tlv_copy(struct ath11k_base *ab,\n\t\t\t\t\t   struct hal_rx_desc *fdesc,\n\t\t\t\t\t   struct hal_rx_desc *ldesc)\n{\n\tab->hw_params.hw_ops->rx_desc_copy_attn_end_tlv(fdesc, ldesc);\n}\n\nstatic inline u32 ath11k_dp_rxdesc_get_mpdulen_err(struct rx_attention *attn)\n{\n\treturn FIELD_GET(RX_ATTENTION_INFO1_MPDU_LEN_ERR,\n\t\t\t __le32_to_cpu(attn->info1));\n}\n\nstatic inline u8 *ath11k_dp_rxdesc_get_80211hdr(struct ath11k_base *ab,\n\t\t\t\t\t\tstruct hal_rx_desc *rx_desc)\n{\n\tu8 *rx_pkt_hdr;\n\n\trx_pkt_hdr = ab->hw_params.hw_ops->rx_desc_get_msdu_payload(rx_desc);\n\n\treturn rx_pkt_hdr;\n}\n\nstatic inline bool ath11k_dp_rxdesc_mpdu_valid(struct ath11k_base *ab,\n\t\t\t\t\t       struct hal_rx_desc *rx_desc)\n{\n\tu32 tlv_tag;\n\n\ttlv_tag = ab->hw_params.hw_ops->rx_desc_get_mpdu_start_tag(rx_desc);\n\n\treturn tlv_tag == HAL_RX_MPDU_START;\n}\n\nstatic inline u32 ath11k_dp_rxdesc_get_ppduid(struct ath11k_base *ab,\n\t\t\t\t\t      struct hal_rx_desc *rx_desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_get_mpdu_ppdu_id(rx_desc);\n}\n\nstatic inline void ath11k_dp_rxdesc_set_msdu_len(struct ath11k_base *ab,\n\t\t\t\t\t\t struct hal_rx_desc *desc,\n\t\t\t\t\t\t u16 len)\n{\n\tab->hw_params.hw_ops->rx_desc_set_msdu_len(desc, len);\n}\n\nstatic bool ath11k_dp_rx_h_attn_is_mcbc(struct ath11k_base *ab,\n\t\t\t\t\tstruct hal_rx_desc *desc)\n{\n\tstruct rx_attention *attn = ath11k_dp_rx_get_attention(ab, desc);\n\n\treturn ath11k_dp_rx_h_msdu_end_first_msdu(ab, desc) &&\n\t\t(!!FIELD_GET(RX_ATTENTION_INFO1_MCAST_BCAST,\n\t\t __le32_to_cpu(attn->info1)));\n}\n\nstatic bool ath11k_dp_rxdesc_mac_addr2_valid(struct ath11k_base *ab,\n\t\t\t\t\t     struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_mac_addr2_valid(desc);\n}\n\nstatic u8 *ath11k_dp_rxdesc_mpdu_start_addr2(struct ath11k_base *ab,\n\t\t\t\t\t     struct hal_rx_desc *desc)\n{\n\treturn ab->hw_params.hw_ops->rx_desc_mpdu_start_addr2(desc);\n}\n\nstatic void ath11k_dp_service_mon_ring(struct timer_list *t)\n{\n\tstruct ath11k_base *ab = from_timer(ab, t, mon_reap_timer);\n\tint i;\n\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++)\n\t\tath11k_dp_rx_process_mon_rings(ab, i, NULL, DP_MON_SERVICE_BUDGET);\n\n\tmod_timer(&ab->mon_reap_timer, jiffies +\n\t\t  msecs_to_jiffies(ATH11K_MON_TIMER_INTERVAL));\n}\n\nstatic int ath11k_dp_purge_mon_ring(struct ath11k_base *ab)\n{\n\tint i, reaped = 0;\n\tunsigned long timeout = jiffies + msecs_to_jiffies(DP_MON_PURGE_TIMEOUT_MS);\n\n\tdo {\n\t\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++)\n\t\t\treaped += ath11k_dp_rx_process_mon_rings(ab, i,\n\t\t\t\t\t\t\t\t NULL,\n\t\t\t\t\t\t\t\t DP_MON_SERVICE_BUDGET);\n\n\t\t \n\t\tif (reaped < DP_MON_SERVICE_BUDGET)\n\t\t\treturn 0;\n\n\t} while (time_before(jiffies, timeout));\n\n\tath11k_warn(ab, \"dp mon ring purge timeout\");\n\n\treturn -ETIMEDOUT;\n}\n\n \nint ath11k_dp_rxbufs_replenish(struct ath11k_base *ab, int mac_id,\n\t\t\t       struct dp_rxdma_ring *rx_ring,\n\t\t\t       int req_entries,\n\t\t\t       enum hal_rx_buf_return_buf_manager mgr)\n{\n\tstruct hal_srng *srng;\n\tu32 *desc;\n\tstruct sk_buff *skb;\n\tint num_free;\n\tint num_remain;\n\tint buf_id;\n\tu32 cookie;\n\tdma_addr_t paddr;\n\n\treq_entries = min(req_entries, rx_ring->bufs_max);\n\n\tsrng = &ab->hal.srng_list[rx_ring->refill_buf_ring.ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\tnum_free = ath11k_hal_srng_src_num_free(ab, srng, true);\n\tif (!req_entries && (num_free > (rx_ring->bufs_max * 3) / 4))\n\t\treq_entries = num_free;\n\n\treq_entries = min(num_free, req_entries);\n\tnum_remain = req_entries;\n\n\twhile (num_remain > 0) {\n\t\tskb = dev_alloc_skb(DP_RX_BUFFER_SIZE +\n\t\t\t\t    DP_RX_BUFFER_ALIGN_SIZE);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tif (!IS_ALIGNED((unsigned long)skb->data,\n\t\t\t\tDP_RX_BUFFER_ALIGN_SIZE)) {\n\t\t\tskb_pull(skb,\n\t\t\t\t PTR_ALIGN(skb->data, DP_RX_BUFFER_ALIGN_SIZE) -\n\t\t\t\t skb->data);\n\t\t}\n\n\t\tpaddr = dma_map_single(ab->dev, skb->data,\n\t\t\t\t       skb->len + skb_tailroom(skb),\n\t\t\t\t       DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(ab->dev, paddr))\n\t\t\tgoto fail_free_skb;\n\n\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\tbuf_id = idr_alloc(&rx_ring->bufs_idr, skb, 1,\n\t\t\t\t   (rx_ring->bufs_max * 3) + 1, GFP_ATOMIC);\n\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\tif (buf_id <= 0)\n\t\t\tgoto fail_dma_unmap;\n\n\t\tdesc = ath11k_hal_srng_src_get_next_entry(ab, srng);\n\t\tif (!desc)\n\t\t\tgoto fail_idr_remove;\n\n\t\tATH11K_SKB_RXCB(skb)->paddr = paddr;\n\n\t\tcookie = FIELD_PREP(DP_RXDMA_BUF_COOKIE_PDEV_ID, mac_id) |\n\t\t\t FIELD_PREP(DP_RXDMA_BUF_COOKIE_BUF_ID, buf_id);\n\n\t\tnum_remain--;\n\n\t\tath11k_hal_rx_buf_addr_info_set(desc, paddr, cookie, mgr);\n\t}\n\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\treturn req_entries - num_remain;\n\nfail_idr_remove:\n\tspin_lock_bh(&rx_ring->idr_lock);\n\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\tspin_unlock_bh(&rx_ring->idr_lock);\nfail_dma_unmap:\n\tdma_unmap_single(ab->dev, paddr, skb->len + skb_tailroom(skb),\n\t\t\t DMA_FROM_DEVICE);\nfail_free_skb:\n\tdev_kfree_skb_any(skb);\n\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\treturn req_entries - num_remain;\n}\n\nstatic int ath11k_dp_rxdma_buf_ring_free(struct ath11k *ar,\n\t\t\t\t\t struct dp_rxdma_ring *rx_ring)\n{\n\tstruct sk_buff *skb;\n\tint buf_id;\n\n\tspin_lock_bh(&rx_ring->idr_lock);\n\tidr_for_each_entry(&rx_ring->bufs_idr, skb, buf_id) {\n\t\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\t\t \n\t\tdma_unmap_single(ar->ab->dev, ATH11K_SKB_RXCB(skb)->paddr,\n\t\t\t\t skb->len + skb_tailroom(skb), DMA_FROM_DEVICE);\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\tidr_destroy(&rx_ring->bufs_idr);\n\tspin_unlock_bh(&rx_ring->idr_lock);\n\n\treturn 0;\n}\n\nstatic int ath11k_dp_rxdma_pdev_buf_free(struct ath11k *ar)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct dp_rxdma_ring *rx_ring = &dp->rx_refill_buf_ring;\n\tint i;\n\n\tath11k_dp_rxdma_buf_ring_free(ar, rx_ring);\n\n\trx_ring = &dp->rxdma_mon_buf_ring;\n\tath11k_dp_rxdma_buf_ring_free(ar, rx_ring);\n\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\trx_ring = &dp->rx_mon_status_refill_ring[i];\n\t\tath11k_dp_rxdma_buf_ring_free(ar, rx_ring);\n\t}\n\n\treturn 0;\n}\n\nstatic int ath11k_dp_rxdma_ring_buf_setup(struct ath11k *ar,\n\t\t\t\t\t  struct dp_rxdma_ring *rx_ring,\n\t\t\t\t\t  u32 ringtype)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tint num_entries;\n\n\tnum_entries = rx_ring->refill_buf_ring.size /\n\t\tath11k_hal_srng_get_entrysize(ar->ab, ringtype);\n\n\trx_ring->bufs_max = num_entries;\n\tath11k_dp_rxbufs_replenish(ar->ab, dp->mac_id, rx_ring, num_entries,\n\t\t\t\t   ar->ab->hw_params.hal_params->rx_buf_rbm);\n\treturn 0;\n}\n\nstatic int ath11k_dp_rxdma_pdev_buf_setup(struct ath11k *ar)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct dp_rxdma_ring *rx_ring = &dp->rx_refill_buf_ring;\n\tint i;\n\n\tath11k_dp_rxdma_ring_buf_setup(ar, rx_ring, HAL_RXDMA_BUF);\n\n\tif (ar->ab->hw_params.rxdma1_enable) {\n\t\trx_ring = &dp->rxdma_mon_buf_ring;\n\t\tath11k_dp_rxdma_ring_buf_setup(ar, rx_ring, HAL_RXDMA_MONITOR_BUF);\n\t}\n\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\trx_ring = &dp->rx_mon_status_refill_ring[i];\n\t\tath11k_dp_rxdma_ring_buf_setup(ar, rx_ring, HAL_RXDMA_MONITOR_STATUS);\n\t}\n\n\treturn 0;\n}\n\nstatic void ath11k_dp_rx_pdev_srng_free(struct ath11k *ar)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_base *ab = ar->ab;\n\tint i;\n\n\tath11k_dp_srng_cleanup(ab, &dp->rx_refill_buf_ring.refill_buf_ring);\n\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\tif (ab->hw_params.rx_mac_buf_ring)\n\t\t\tath11k_dp_srng_cleanup(ab, &dp->rx_mac_buf_ring[i]);\n\n\t\tath11k_dp_srng_cleanup(ab, &dp->rxdma_err_dst_ring[i]);\n\t\tath11k_dp_srng_cleanup(ab,\n\t\t\t\t       &dp->rx_mon_status_refill_ring[i].refill_buf_ring);\n\t}\n\n\tath11k_dp_srng_cleanup(ab, &dp->rxdma_mon_buf_ring.refill_buf_ring);\n}\n\nvoid ath11k_dp_pdev_reo_cleanup(struct ath11k_base *ab)\n{\n\tstruct ath11k_dp *dp = &ab->dp;\n\tint i;\n\n\tfor (i = 0; i < DP_REO_DST_RING_MAX; i++)\n\t\tath11k_dp_srng_cleanup(ab, &dp->reo_dst_ring[i]);\n}\n\nint ath11k_dp_pdev_reo_setup(struct ath11k_base *ab)\n{\n\tstruct ath11k_dp *dp = &ab->dp;\n\tint ret;\n\tint i;\n\n\tfor (i = 0; i < DP_REO_DST_RING_MAX; i++) {\n\t\tret = ath11k_dp_srng_setup(ab, &dp->reo_dst_ring[i],\n\t\t\t\t\t   HAL_REO_DST, i, 0,\n\t\t\t\t\t   DP_REO_DST_RING_SIZE);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab, \"failed to setup reo_dst_ring\\n\");\n\t\t\tgoto err_reo_cleanup;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_reo_cleanup:\n\tath11k_dp_pdev_reo_cleanup(ab);\n\n\treturn ret;\n}\n\nstatic int ath11k_dp_rx_pdev_srng_alloc(struct ath11k *ar)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct dp_srng *srng = NULL;\n\tint i;\n\tint ret;\n\n\tret = ath11k_dp_srng_setup(ar->ab,\n\t\t\t\t   &dp->rx_refill_buf_ring.refill_buf_ring,\n\t\t\t\t   HAL_RXDMA_BUF, 0,\n\t\t\t\t   dp->mac_id, DP_RXDMA_BUF_RING_SIZE);\n\tif (ret) {\n\t\tath11k_warn(ar->ab, \"failed to setup rx_refill_buf_ring\\n\");\n\t\treturn ret;\n\t}\n\n\tif (ar->ab->hw_params.rx_mac_buf_ring) {\n\t\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\t\tret = ath11k_dp_srng_setup(ar->ab,\n\t\t\t\t\t\t   &dp->rx_mac_buf_ring[i],\n\t\t\t\t\t\t   HAL_RXDMA_BUF, 1,\n\t\t\t\t\t\t   dp->mac_id + i, 1024);\n\t\t\tif (ret) {\n\t\t\t\tath11k_warn(ar->ab, \"failed to setup rx_mac_buf_ring %d\\n\",\n\t\t\t\t\t    i);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\tret = ath11k_dp_srng_setup(ar->ab, &dp->rxdma_err_dst_ring[i],\n\t\t\t\t\t   HAL_RXDMA_DST, 0, dp->mac_id + i,\n\t\t\t\t\t   DP_RXDMA_ERR_DST_RING_SIZE);\n\t\tif (ret) {\n\t\t\tath11k_warn(ar->ab, \"failed to setup rxdma_err_dst_ring %d\\n\", i);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\tsrng = &dp->rx_mon_status_refill_ring[i].refill_buf_ring;\n\t\tret = ath11k_dp_srng_setup(ar->ab,\n\t\t\t\t\t   srng,\n\t\t\t\t\t   HAL_RXDMA_MONITOR_STATUS, 0, dp->mac_id + i,\n\t\t\t\t\t   DP_RXDMA_MON_STATUS_RING_SIZE);\n\t\tif (ret) {\n\t\t\tath11k_warn(ar->ab,\n\t\t\t\t    \"failed to setup rx_mon_status_refill_ring %d\\n\", i);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tif (!ar->ab->hw_params.rxdma1_enable) {\n\t\t \n\t\ttimer_setup(&ar->ab->mon_reap_timer,\n\t\t\t    ath11k_dp_service_mon_ring, 0);\n\t\treturn 0;\n\t}\n\n\tret = ath11k_dp_srng_setup(ar->ab,\n\t\t\t\t   &dp->rxdma_mon_buf_ring.refill_buf_ring,\n\t\t\t\t   HAL_RXDMA_MONITOR_BUF, 0, dp->mac_id,\n\t\t\t\t   DP_RXDMA_MONITOR_BUF_RING_SIZE);\n\tif (ret) {\n\t\tath11k_warn(ar->ab,\n\t\t\t    \"failed to setup HAL_RXDMA_MONITOR_BUF\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ath11k_dp_srng_setup(ar->ab, &dp->rxdma_mon_dst_ring,\n\t\t\t\t   HAL_RXDMA_MONITOR_DST, 0, dp->mac_id,\n\t\t\t\t   DP_RXDMA_MONITOR_DST_RING_SIZE);\n\tif (ret) {\n\t\tath11k_warn(ar->ab,\n\t\t\t    \"failed to setup HAL_RXDMA_MONITOR_DST\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ath11k_dp_srng_setup(ar->ab, &dp->rxdma_mon_desc_ring,\n\t\t\t\t   HAL_RXDMA_MONITOR_DESC, 0, dp->mac_id,\n\t\t\t\t   DP_RXDMA_MONITOR_DESC_RING_SIZE);\n\tif (ret) {\n\t\tath11k_warn(ar->ab,\n\t\t\t    \"failed to setup HAL_RXDMA_MONITOR_DESC\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nvoid ath11k_dp_reo_cmd_list_cleanup(struct ath11k_base *ab)\n{\n\tstruct ath11k_dp *dp = &ab->dp;\n\tstruct dp_reo_cmd *cmd, *tmp;\n\tstruct dp_reo_cache_flush_elem *cmd_cache, *tmp_cache;\n\tstruct dp_rx_tid *rx_tid;\n\n\tspin_lock_bh(&dp->reo_cmd_lock);\n\tlist_for_each_entry_safe(cmd, tmp, &dp->reo_cmd_list, list) {\n\t\tlist_del(&cmd->list);\n\t\trx_tid = &cmd->data;\n\t\tif (rx_tid->vaddr) {\n\t\t\tdma_unmap_single(ab->dev, rx_tid->paddr,\n\t\t\t\t\t rx_tid->size, DMA_BIDIRECTIONAL);\n\t\t\tkfree(rx_tid->vaddr);\n\t\t\trx_tid->vaddr = NULL;\n\t\t}\n\t\tkfree(cmd);\n\t}\n\n\tlist_for_each_entry_safe(cmd_cache, tmp_cache,\n\t\t\t\t &dp->reo_cmd_cache_flush_list, list) {\n\t\tlist_del(&cmd_cache->list);\n\t\tdp->reo_cmd_cache_flush_count--;\n\t\trx_tid = &cmd_cache->data;\n\t\tif (rx_tid->vaddr) {\n\t\t\tdma_unmap_single(ab->dev, rx_tid->paddr,\n\t\t\t\t\t rx_tid->size, DMA_BIDIRECTIONAL);\n\t\t\tkfree(rx_tid->vaddr);\n\t\t\trx_tid->vaddr = NULL;\n\t\t}\n\t\tkfree(cmd_cache);\n\t}\n\tspin_unlock_bh(&dp->reo_cmd_lock);\n}\n\nstatic void ath11k_dp_reo_cmd_free(struct ath11k_dp *dp, void *ctx,\n\t\t\t\t   enum hal_reo_cmd_status status)\n{\n\tstruct dp_rx_tid *rx_tid = ctx;\n\n\tif (status != HAL_REO_CMD_SUCCESS)\n\t\tath11k_warn(dp->ab, \"failed to flush rx tid hw desc, tid %d status %d\\n\",\n\t\t\t    rx_tid->tid, status);\n\tif (rx_tid->vaddr) {\n\t\tdma_unmap_single(dp->ab->dev, rx_tid->paddr, rx_tid->size,\n\t\t\t\t DMA_BIDIRECTIONAL);\n\t\tkfree(rx_tid->vaddr);\n\t\trx_tid->vaddr = NULL;\n\t}\n}\n\nstatic void ath11k_dp_reo_cache_flush(struct ath11k_base *ab,\n\t\t\t\t      struct dp_rx_tid *rx_tid)\n{\n\tstruct ath11k_hal_reo_cmd cmd = {0};\n\tunsigned long tot_desc_sz, desc_sz;\n\tint ret;\n\n\ttot_desc_sz = rx_tid->size;\n\tdesc_sz = ath11k_hal_reo_qdesc_size(0, HAL_DESC_REO_NON_QOS_TID);\n\n\twhile (tot_desc_sz > desc_sz) {\n\t\ttot_desc_sz -= desc_sz;\n\t\tcmd.addr_lo = lower_32_bits(rx_tid->paddr + tot_desc_sz);\n\t\tcmd.addr_hi = upper_32_bits(rx_tid->paddr);\n\t\tret = ath11k_dp_tx_send_reo_cmd(ab, rx_tid,\n\t\t\t\t\t\tHAL_REO_CMD_FLUSH_CACHE, &cmd,\n\t\t\t\t\t\tNULL);\n\t\tif (ret)\n\t\t\tath11k_warn(ab,\n\t\t\t\t    \"failed to send HAL_REO_CMD_FLUSH_CACHE, tid %d (%d)\\n\",\n\t\t\t\t    rx_tid->tid, ret);\n\t}\n\n\tmemset(&cmd, 0, sizeof(cmd));\n\tcmd.addr_lo = lower_32_bits(rx_tid->paddr);\n\tcmd.addr_hi = upper_32_bits(rx_tid->paddr);\n\tcmd.flag |= HAL_REO_CMD_FLG_NEED_STATUS;\n\tret = ath11k_dp_tx_send_reo_cmd(ab, rx_tid,\n\t\t\t\t\tHAL_REO_CMD_FLUSH_CACHE,\n\t\t\t\t\t&cmd, ath11k_dp_reo_cmd_free);\n\tif (ret) {\n\t\tath11k_err(ab, \"failed to send HAL_REO_CMD_FLUSH_CACHE cmd, tid %d (%d)\\n\",\n\t\t\t   rx_tid->tid, ret);\n\t\tdma_unmap_single(ab->dev, rx_tid->paddr, rx_tid->size,\n\t\t\t\t DMA_BIDIRECTIONAL);\n\t\tkfree(rx_tid->vaddr);\n\t\trx_tid->vaddr = NULL;\n\t}\n}\n\nstatic void ath11k_dp_rx_tid_del_func(struct ath11k_dp *dp, void *ctx,\n\t\t\t\t      enum hal_reo_cmd_status status)\n{\n\tstruct ath11k_base *ab = dp->ab;\n\tstruct dp_rx_tid *rx_tid = ctx;\n\tstruct dp_reo_cache_flush_elem *elem, *tmp;\n\n\tif (status == HAL_REO_CMD_DRAIN) {\n\t\tgoto free_desc;\n\t} else if (status != HAL_REO_CMD_SUCCESS) {\n\t\t \n\t\tath11k_warn(ab, \"failed to delete rx tid %d hw descriptor %d\\n\",\n\t\t\t    rx_tid->tid, status);\n\t\treturn;\n\t}\n\n\telem = kzalloc(sizeof(*elem), GFP_ATOMIC);\n\tif (!elem)\n\t\tgoto free_desc;\n\n\telem->ts = jiffies;\n\tmemcpy(&elem->data, rx_tid, sizeof(*rx_tid));\n\n\tspin_lock_bh(&dp->reo_cmd_lock);\n\tlist_add_tail(&elem->list, &dp->reo_cmd_cache_flush_list);\n\tdp->reo_cmd_cache_flush_count++;\n\n\t \n\tlist_for_each_entry_safe(elem, tmp, &dp->reo_cmd_cache_flush_list,\n\t\t\t\t list) {\n\t\tif (dp->reo_cmd_cache_flush_count > DP_REO_DESC_FREE_THRESHOLD ||\n\t\t    time_after(jiffies, elem->ts +\n\t\t\t       msecs_to_jiffies(DP_REO_DESC_FREE_TIMEOUT_MS))) {\n\t\t\tlist_del(&elem->list);\n\t\t\tdp->reo_cmd_cache_flush_count--;\n\t\t\tspin_unlock_bh(&dp->reo_cmd_lock);\n\n\t\t\tath11k_dp_reo_cache_flush(ab, &elem->data);\n\t\t\tkfree(elem);\n\t\t\tspin_lock_bh(&dp->reo_cmd_lock);\n\t\t}\n\t}\n\tspin_unlock_bh(&dp->reo_cmd_lock);\n\n\treturn;\nfree_desc:\n\tdma_unmap_single(ab->dev, rx_tid->paddr, rx_tid->size,\n\t\t\t DMA_BIDIRECTIONAL);\n\tkfree(rx_tid->vaddr);\n\trx_tid->vaddr = NULL;\n}\n\nvoid ath11k_peer_rx_tid_delete(struct ath11k *ar,\n\t\t\t       struct ath11k_peer *peer, u8 tid)\n{\n\tstruct ath11k_hal_reo_cmd cmd = {0};\n\tstruct dp_rx_tid *rx_tid = &peer->rx_tid[tid];\n\tint ret;\n\n\tif (!rx_tid->active)\n\t\treturn;\n\n\trx_tid->active = false;\n\n\tcmd.flag = HAL_REO_CMD_FLG_NEED_STATUS;\n\tcmd.addr_lo = lower_32_bits(rx_tid->paddr);\n\tcmd.addr_hi = upper_32_bits(rx_tid->paddr);\n\tcmd.upd0 |= HAL_REO_CMD_UPD0_VLD;\n\tret = ath11k_dp_tx_send_reo_cmd(ar->ab, rx_tid,\n\t\t\t\t\tHAL_REO_CMD_UPDATE_RX_QUEUE, &cmd,\n\t\t\t\t\tath11k_dp_rx_tid_del_func);\n\tif (ret) {\n\t\tif (ret != -ESHUTDOWN)\n\t\t\tath11k_err(ar->ab, \"failed to send HAL_REO_CMD_UPDATE_RX_QUEUE cmd, tid %d (%d)\\n\",\n\t\t\t\t   tid, ret);\n\t\tdma_unmap_single(ar->ab->dev, rx_tid->paddr, rx_tid->size,\n\t\t\t\t DMA_BIDIRECTIONAL);\n\t\tkfree(rx_tid->vaddr);\n\t\trx_tid->vaddr = NULL;\n\t}\n\n\trx_tid->paddr = 0;\n\trx_tid->size = 0;\n}\n\nstatic int ath11k_dp_rx_link_desc_return(struct ath11k_base *ab,\n\t\t\t\t\t u32 *link_desc,\n\t\t\t\t\t enum hal_wbm_rel_bm_act action)\n{\n\tstruct ath11k_dp *dp = &ab->dp;\n\tstruct hal_srng *srng;\n\tu32 *desc;\n\tint ret = 0;\n\n\tsrng = &ab->hal.srng_list[dp->wbm_desc_rel_ring.ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\tdesc = ath11k_hal_srng_src_get_next_entry(ab, srng);\n\tif (!desc) {\n\t\tret = -ENOBUFS;\n\t\tgoto exit;\n\t}\n\n\tath11k_hal_rx_msdu_link_desc_set(ab, (void *)desc, (void *)link_desc,\n\t\t\t\t\t action);\n\nexit:\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\treturn ret;\n}\n\nstatic void ath11k_dp_rx_frags_cleanup(struct dp_rx_tid *rx_tid, bool rel_link_desc)\n{\n\tstruct ath11k_base *ab = rx_tid->ab;\n\n\tlockdep_assert_held(&ab->base_lock);\n\n\tif (rx_tid->dst_ring_desc) {\n\t\tif (rel_link_desc)\n\t\t\tath11k_dp_rx_link_desc_return(ab, (u32 *)rx_tid->dst_ring_desc,\n\t\t\t\t\t\t      HAL_WBM_REL_BM_ACT_PUT_IN_IDLE);\n\t\tkfree(rx_tid->dst_ring_desc);\n\t\trx_tid->dst_ring_desc = NULL;\n\t}\n\n\trx_tid->cur_sn = 0;\n\trx_tid->last_frag_no = 0;\n\trx_tid->rx_frag_bitmap = 0;\n\t__skb_queue_purge(&rx_tid->rx_frags);\n}\n\nvoid ath11k_peer_frags_flush(struct ath11k *ar, struct ath11k_peer *peer)\n{\n\tstruct dp_rx_tid *rx_tid;\n\tint i;\n\n\tlockdep_assert_held(&ar->ab->base_lock);\n\n\tfor (i = 0; i <= IEEE80211_NUM_TIDS; i++) {\n\t\trx_tid = &peer->rx_tid[i];\n\n\t\tspin_unlock_bh(&ar->ab->base_lock);\n\t\tdel_timer_sync(&rx_tid->frag_timer);\n\t\tspin_lock_bh(&ar->ab->base_lock);\n\n\t\tath11k_dp_rx_frags_cleanup(rx_tid, true);\n\t}\n}\n\nvoid ath11k_peer_rx_tid_cleanup(struct ath11k *ar, struct ath11k_peer *peer)\n{\n\tstruct dp_rx_tid *rx_tid;\n\tint i;\n\n\tlockdep_assert_held(&ar->ab->base_lock);\n\n\tfor (i = 0; i <= IEEE80211_NUM_TIDS; i++) {\n\t\trx_tid = &peer->rx_tid[i];\n\n\t\tath11k_peer_rx_tid_delete(ar, peer, i);\n\t\tath11k_dp_rx_frags_cleanup(rx_tid, true);\n\n\t\tspin_unlock_bh(&ar->ab->base_lock);\n\t\tdel_timer_sync(&rx_tid->frag_timer);\n\t\tspin_lock_bh(&ar->ab->base_lock);\n\t}\n}\n\nstatic int ath11k_peer_rx_tid_reo_update(struct ath11k *ar,\n\t\t\t\t\t struct ath11k_peer *peer,\n\t\t\t\t\t struct dp_rx_tid *rx_tid,\n\t\t\t\t\t u32 ba_win_sz, u16 ssn,\n\t\t\t\t\t bool update_ssn)\n{\n\tstruct ath11k_hal_reo_cmd cmd = {0};\n\tint ret;\n\n\tcmd.addr_lo = lower_32_bits(rx_tid->paddr);\n\tcmd.addr_hi = upper_32_bits(rx_tid->paddr);\n\tcmd.flag = HAL_REO_CMD_FLG_NEED_STATUS;\n\tcmd.upd0 = HAL_REO_CMD_UPD0_BA_WINDOW_SIZE;\n\tcmd.ba_window_size = ba_win_sz;\n\n\tif (update_ssn) {\n\t\tcmd.upd0 |= HAL_REO_CMD_UPD0_SSN;\n\t\tcmd.upd2 = FIELD_PREP(HAL_REO_CMD_UPD2_SSN, ssn);\n\t}\n\n\tret = ath11k_dp_tx_send_reo_cmd(ar->ab, rx_tid,\n\t\t\t\t\tHAL_REO_CMD_UPDATE_RX_QUEUE, &cmd,\n\t\t\t\t\tNULL);\n\tif (ret) {\n\t\tath11k_warn(ar->ab, \"failed to update rx tid queue, tid %d (%d)\\n\",\n\t\t\t    rx_tid->tid, ret);\n\t\treturn ret;\n\t}\n\n\trx_tid->ba_win_sz = ba_win_sz;\n\n\treturn 0;\n}\n\nstatic void ath11k_dp_rx_tid_mem_free(struct ath11k_base *ab,\n\t\t\t\t      const u8 *peer_mac, int vdev_id, u8 tid)\n{\n\tstruct ath11k_peer *peer;\n\tstruct dp_rx_tid *rx_tid;\n\n\tspin_lock_bh(&ab->base_lock);\n\n\tpeer = ath11k_peer_find(ab, vdev_id, peer_mac);\n\tif (!peer) {\n\t\tath11k_warn(ab, \"failed to find the peer to free up rx tid mem\\n\");\n\t\tgoto unlock_exit;\n\t}\n\n\trx_tid = &peer->rx_tid[tid];\n\tif (!rx_tid->active)\n\t\tgoto unlock_exit;\n\n\tdma_unmap_single(ab->dev, rx_tid->paddr, rx_tid->size,\n\t\t\t DMA_BIDIRECTIONAL);\n\tkfree(rx_tid->vaddr);\n\trx_tid->vaddr = NULL;\n\n\trx_tid->active = false;\n\nunlock_exit:\n\tspin_unlock_bh(&ab->base_lock);\n}\n\nint ath11k_peer_rx_tid_setup(struct ath11k *ar, const u8 *peer_mac, int vdev_id,\n\t\t\t     u8 tid, u32 ba_win_sz, u16 ssn,\n\t\t\t     enum hal_pn_type pn_type)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct ath11k_peer *peer;\n\tstruct dp_rx_tid *rx_tid;\n\tu32 hw_desc_sz;\n\tu32 *addr_aligned;\n\tvoid *vaddr;\n\tdma_addr_t paddr;\n\tint ret;\n\n\tspin_lock_bh(&ab->base_lock);\n\n\tpeer = ath11k_peer_find(ab, vdev_id, peer_mac);\n\tif (!peer) {\n\t\tath11k_warn(ab, \"failed to find the peer %pM to set up rx tid\\n\",\n\t\t\t    peer_mac);\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\treturn -ENOENT;\n\t}\n\n\trx_tid = &peer->rx_tid[tid];\n\t \n\tif (rx_tid->active) {\n\t\tpaddr = rx_tid->paddr;\n\t\tret = ath11k_peer_rx_tid_reo_update(ar, peer, rx_tid,\n\t\t\t\t\t\t    ba_win_sz, ssn, true);\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab, \"failed to update reo for peer %pM rx tid %d\\n: %d\",\n\t\t\t\t    peer_mac, tid, ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\tret = ath11k_wmi_peer_rx_reorder_queue_setup(ar, vdev_id,\n\t\t\t\t\t\t\t     peer_mac, paddr,\n\t\t\t\t\t\t\t     tid, 1, ba_win_sz);\n\t\tif (ret)\n\t\t\tath11k_warn(ab, \"failed to send wmi rx reorder queue for peer %pM tid %d: %d\\n\",\n\t\t\t\t    peer_mac, tid, ret);\n\t\treturn ret;\n\t}\n\n\trx_tid->tid = tid;\n\n\trx_tid->ba_win_sz = ba_win_sz;\n\n\t \n\tif (tid == HAL_DESC_REO_NON_QOS_TID)\n\t\thw_desc_sz = ath11k_hal_reo_qdesc_size(ba_win_sz, tid);\n\telse\n\t\thw_desc_sz = ath11k_hal_reo_qdesc_size(DP_BA_WIN_SZ_MAX, tid);\n\n\tvaddr = kzalloc(hw_desc_sz + HAL_LINK_DESC_ALIGN - 1, GFP_ATOMIC);\n\tif (!vaddr) {\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\treturn -ENOMEM;\n\t}\n\n\taddr_aligned = PTR_ALIGN(vaddr, HAL_LINK_DESC_ALIGN);\n\n\tath11k_hal_reo_qdesc_setup(addr_aligned, tid, ba_win_sz,\n\t\t\t\t   ssn, pn_type);\n\n\tpaddr = dma_map_single(ab->dev, addr_aligned, hw_desc_sz,\n\t\t\t       DMA_BIDIRECTIONAL);\n\n\tret = dma_mapping_error(ab->dev, paddr);\n\tif (ret) {\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\tath11k_warn(ab, \"failed to setup dma map for peer %pM rx tid %d: %d\\n\",\n\t\t\t    peer_mac, tid, ret);\n\t\tgoto err_mem_free;\n\t}\n\n\trx_tid->vaddr = vaddr;\n\trx_tid->paddr = paddr;\n\trx_tid->size = hw_desc_sz;\n\trx_tid->active = true;\n\n\tspin_unlock_bh(&ab->base_lock);\n\n\tret = ath11k_wmi_peer_rx_reorder_queue_setup(ar, vdev_id, peer_mac,\n\t\t\t\t\t\t     paddr, tid, 1, ba_win_sz);\n\tif (ret) {\n\t\tath11k_warn(ar->ab, \"failed to setup rx reorder queue for peer %pM tid %d: %d\\n\",\n\t\t\t    peer_mac, tid, ret);\n\t\tath11k_dp_rx_tid_mem_free(ab, peer_mac, vdev_id, tid);\n\t}\n\n\treturn ret;\n\nerr_mem_free:\n\tkfree(rx_tid->vaddr);\n\trx_tid->vaddr = NULL;\n\n\treturn ret;\n}\n\nint ath11k_dp_rx_ampdu_start(struct ath11k *ar,\n\t\t\t     struct ieee80211_ampdu_params *params)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct ath11k_sta *arsta = (void *)params->sta->drv_priv;\n\tint vdev_id = arsta->arvif->vdev_id;\n\tint ret;\n\n\tret = ath11k_peer_rx_tid_setup(ar, params->sta->addr, vdev_id,\n\t\t\t\t       params->tid, params->buf_size,\n\t\t\t\t       params->ssn, arsta->pn_type);\n\tif (ret)\n\t\tath11k_warn(ab, \"failed to setup rx tid %d\\n\", ret);\n\n\treturn ret;\n}\n\nint ath11k_dp_rx_ampdu_stop(struct ath11k *ar,\n\t\t\t    struct ieee80211_ampdu_params *params)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct ath11k_peer *peer;\n\tstruct ath11k_sta *arsta = (void *)params->sta->drv_priv;\n\tint vdev_id = arsta->arvif->vdev_id;\n\tdma_addr_t paddr;\n\tbool active;\n\tint ret;\n\n\tspin_lock_bh(&ab->base_lock);\n\n\tpeer = ath11k_peer_find(ab, vdev_id, params->sta->addr);\n\tif (!peer) {\n\t\tath11k_warn(ab, \"failed to find the peer to stop rx aggregation\\n\");\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\treturn -ENOENT;\n\t}\n\n\tpaddr = peer->rx_tid[params->tid].paddr;\n\tactive = peer->rx_tid[params->tid].active;\n\n\tif (!active) {\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\treturn 0;\n\t}\n\n\tret = ath11k_peer_rx_tid_reo_update(ar, peer, peer->rx_tid, 1, 0, false);\n\tspin_unlock_bh(&ab->base_lock);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to update reo for rx tid %d: %d\\n\",\n\t\t\t    params->tid, ret);\n\t\treturn ret;\n\t}\n\n\tret = ath11k_wmi_peer_rx_reorder_queue_setup(ar, vdev_id,\n\t\t\t\t\t\t     params->sta->addr, paddr,\n\t\t\t\t\t\t     params->tid, 1, 1);\n\tif (ret)\n\t\tath11k_warn(ab, \"failed to send wmi to delete rx tid %d\\n\",\n\t\t\t    ret);\n\n\treturn ret;\n}\n\nint ath11k_dp_peer_rx_pn_replay_config(struct ath11k_vif *arvif,\n\t\t\t\t       const u8 *peer_addr,\n\t\t\t\t       enum set_key_cmd key_cmd,\n\t\t\t\t       struct ieee80211_key_conf *key)\n{\n\tstruct ath11k *ar = arvif->ar;\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct ath11k_hal_reo_cmd cmd = {0};\n\tstruct ath11k_peer *peer;\n\tstruct dp_rx_tid *rx_tid;\n\tu8 tid;\n\tint ret = 0;\n\n\t \n\tif (!(key->flags & IEEE80211_KEY_FLAG_PAIRWISE))\n\t\treturn 0;\n\n\tcmd.flag |= HAL_REO_CMD_FLG_NEED_STATUS;\n\tcmd.upd0 |= HAL_REO_CMD_UPD0_PN |\n\t\t    HAL_REO_CMD_UPD0_PN_SIZE |\n\t\t    HAL_REO_CMD_UPD0_PN_VALID |\n\t\t    HAL_REO_CMD_UPD0_PN_CHECK |\n\t\t    HAL_REO_CMD_UPD0_SVLD;\n\n\tswitch (key->cipher) {\n\tcase WLAN_CIPHER_SUITE_TKIP:\n\tcase WLAN_CIPHER_SUITE_CCMP:\n\tcase WLAN_CIPHER_SUITE_CCMP_256:\n\tcase WLAN_CIPHER_SUITE_GCMP:\n\tcase WLAN_CIPHER_SUITE_GCMP_256:\n\t\tif (key_cmd == SET_KEY) {\n\t\t\tcmd.upd1 |= HAL_REO_CMD_UPD1_PN_CHECK;\n\t\t\tcmd.pn_size = 48;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tspin_lock_bh(&ab->base_lock);\n\n\tpeer = ath11k_peer_find(ab, arvif->vdev_id, peer_addr);\n\tif (!peer) {\n\t\tath11k_warn(ab, \"failed to find the peer to configure pn replay detection\\n\");\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\treturn -ENOENT;\n\t}\n\n\tfor (tid = 0; tid <= IEEE80211_NUM_TIDS; tid++) {\n\t\trx_tid = &peer->rx_tid[tid];\n\t\tif (!rx_tid->active)\n\t\t\tcontinue;\n\t\tcmd.addr_lo = lower_32_bits(rx_tid->paddr);\n\t\tcmd.addr_hi = upper_32_bits(rx_tid->paddr);\n\t\tret = ath11k_dp_tx_send_reo_cmd(ab, rx_tid,\n\t\t\t\t\t\tHAL_REO_CMD_UPDATE_RX_QUEUE,\n\t\t\t\t\t\t&cmd, NULL);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab, \"failed to configure rx tid %d queue for pn replay detection %d\\n\",\n\t\t\t\t    tid, ret);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tspin_unlock_bh(&ab->base_lock);\n\n\treturn ret;\n}\n\nstatic inline int ath11k_get_ppdu_user_index(struct htt_ppdu_stats *ppdu_stats,\n\t\t\t\t\t     u16 peer_id)\n{\n\tint i;\n\n\tfor (i = 0; i < HTT_PPDU_STATS_MAX_USERS - 1; i++) {\n\t\tif (ppdu_stats->user_stats[i].is_valid_peer_id) {\n\t\t\tif (peer_id == ppdu_stats->user_stats[i].peer_id)\n\t\t\t\treturn i;\n\t\t} else {\n\t\t\treturn i;\n\t\t}\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int ath11k_htt_tlv_ppdu_stats_parse(struct ath11k_base *ab,\n\t\t\t\t\t   u16 tag, u16 len, const void *ptr,\n\t\t\t\t\t   void *data)\n{\n\tstruct htt_ppdu_stats_info *ppdu_info;\n\tstruct htt_ppdu_user_stats *user_stats;\n\tint cur_user;\n\tu16 peer_id;\n\n\tppdu_info = (struct htt_ppdu_stats_info *)data;\n\n\tswitch (tag) {\n\tcase HTT_PPDU_STATS_TAG_COMMON:\n\t\tif (len < sizeof(struct htt_ppdu_stats_common)) {\n\t\t\tath11k_warn(ab, \"Invalid len %d for the tag 0x%x\\n\",\n\t\t\t\t    len, tag);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tmemcpy((void *)&ppdu_info->ppdu_stats.common, ptr,\n\t\t       sizeof(struct htt_ppdu_stats_common));\n\t\tbreak;\n\tcase HTT_PPDU_STATS_TAG_USR_RATE:\n\t\tif (len < sizeof(struct htt_ppdu_stats_user_rate)) {\n\t\t\tath11k_warn(ab, \"Invalid len %d for the tag 0x%x\\n\",\n\t\t\t\t    len, tag);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tpeer_id = ((struct htt_ppdu_stats_user_rate *)ptr)->sw_peer_id;\n\t\tcur_user = ath11k_get_ppdu_user_index(&ppdu_info->ppdu_stats,\n\t\t\t\t\t\t      peer_id);\n\t\tif (cur_user < 0)\n\t\t\treturn -EINVAL;\n\t\tuser_stats = &ppdu_info->ppdu_stats.user_stats[cur_user];\n\t\tuser_stats->peer_id = peer_id;\n\t\tuser_stats->is_valid_peer_id = true;\n\t\tmemcpy((void *)&user_stats->rate, ptr,\n\t\t       sizeof(struct htt_ppdu_stats_user_rate));\n\t\tuser_stats->tlv_flags |= BIT(tag);\n\t\tbreak;\n\tcase HTT_PPDU_STATS_TAG_USR_COMPLTN_COMMON:\n\t\tif (len < sizeof(struct htt_ppdu_stats_usr_cmpltn_cmn)) {\n\t\t\tath11k_warn(ab, \"Invalid len %d for the tag 0x%x\\n\",\n\t\t\t\t    len, tag);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tpeer_id = ((struct htt_ppdu_stats_usr_cmpltn_cmn *)ptr)->sw_peer_id;\n\t\tcur_user = ath11k_get_ppdu_user_index(&ppdu_info->ppdu_stats,\n\t\t\t\t\t\t      peer_id);\n\t\tif (cur_user < 0)\n\t\t\treturn -EINVAL;\n\t\tuser_stats = &ppdu_info->ppdu_stats.user_stats[cur_user];\n\t\tuser_stats->peer_id = peer_id;\n\t\tuser_stats->is_valid_peer_id = true;\n\t\tmemcpy((void *)&user_stats->cmpltn_cmn, ptr,\n\t\t       sizeof(struct htt_ppdu_stats_usr_cmpltn_cmn));\n\t\tuser_stats->tlv_flags |= BIT(tag);\n\t\tbreak;\n\tcase HTT_PPDU_STATS_TAG_USR_COMPLTN_ACK_BA_STATUS:\n\t\tif (len <\n\t\t    sizeof(struct htt_ppdu_stats_usr_cmpltn_ack_ba_status)) {\n\t\t\tath11k_warn(ab, \"Invalid len %d for the tag 0x%x\\n\",\n\t\t\t\t    len, tag);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tpeer_id =\n\t\t((struct htt_ppdu_stats_usr_cmpltn_ack_ba_status *)ptr)->sw_peer_id;\n\t\tcur_user = ath11k_get_ppdu_user_index(&ppdu_info->ppdu_stats,\n\t\t\t\t\t\t      peer_id);\n\t\tif (cur_user < 0)\n\t\t\treturn -EINVAL;\n\t\tuser_stats = &ppdu_info->ppdu_stats.user_stats[cur_user];\n\t\tuser_stats->peer_id = peer_id;\n\t\tuser_stats->is_valid_peer_id = true;\n\t\tmemcpy((void *)&user_stats->ack_ba, ptr,\n\t\t       sizeof(struct htt_ppdu_stats_usr_cmpltn_ack_ba_status));\n\t\tuser_stats->tlv_flags |= BIT(tag);\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nint ath11k_dp_htt_tlv_iter(struct ath11k_base *ab, const void *ptr, size_t len,\n\t\t\t   int (*iter)(struct ath11k_base *ar, u16 tag, u16 len,\n\t\t\t\t       const void *ptr, void *data),\n\t\t\t   void *data)\n{\n\tconst struct htt_tlv *tlv;\n\tconst void *begin = ptr;\n\tu16 tlv_tag, tlv_len;\n\tint ret = -EINVAL;\n\n\twhile (len > 0) {\n\t\tif (len < sizeof(*tlv)) {\n\t\t\tath11k_err(ab, \"htt tlv parse failure at byte %zd (%zu bytes left, %zu expected)\\n\",\n\t\t\t\t   ptr - begin, len, sizeof(*tlv));\n\t\t\treturn -EINVAL;\n\t\t}\n\t\ttlv = (struct htt_tlv *)ptr;\n\t\ttlv_tag = FIELD_GET(HTT_TLV_TAG, tlv->header);\n\t\ttlv_len = FIELD_GET(HTT_TLV_LEN, tlv->header);\n\t\tptr += sizeof(*tlv);\n\t\tlen -= sizeof(*tlv);\n\n\t\tif (tlv_len > len) {\n\t\t\tath11k_err(ab, \"htt tlv parse failure of tag %u at byte %zd (%zu bytes left, %u expected)\\n\",\n\t\t\t\t   tlv_tag, ptr - begin, len, tlv_len);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tret = iter(ab, tlv_tag, tlv_len, ptr, data);\n\t\tif (ret == -ENOMEM)\n\t\t\treturn ret;\n\n\t\tptr += tlv_len;\n\t\tlen -= tlv_len;\n\t}\n\treturn 0;\n}\n\nstatic void\nath11k_update_per_peer_tx_stats(struct ath11k *ar,\n\t\t\t\tstruct htt_ppdu_stats *ppdu_stats, u8 user)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct ath11k_peer *peer;\n\tstruct ieee80211_sta *sta;\n\tstruct ath11k_sta *arsta;\n\tstruct htt_ppdu_stats_user_rate *user_rate;\n\tstruct ath11k_per_peer_tx_stats *peer_stats = &ar->peer_tx_stats;\n\tstruct htt_ppdu_user_stats *usr_stats = &ppdu_stats->user_stats[user];\n\tstruct htt_ppdu_stats_common *common = &ppdu_stats->common;\n\tint ret;\n\tu8 flags, mcs, nss, bw, sgi, dcm, rate_idx = 0;\n\tu32 succ_bytes = 0;\n\tu16 rate = 0, succ_pkts = 0;\n\tu32 tx_duration = 0;\n\tu8 tid = HTT_PPDU_STATS_NON_QOS_TID;\n\tbool is_ampdu = false;\n\n\tif (!usr_stats)\n\t\treturn;\n\n\tif (!(usr_stats->tlv_flags & BIT(HTT_PPDU_STATS_TAG_USR_RATE)))\n\t\treturn;\n\n\tif (usr_stats->tlv_flags & BIT(HTT_PPDU_STATS_TAG_USR_COMPLTN_COMMON))\n\t\tis_ampdu =\n\t\t\tHTT_USR_CMPLTN_IS_AMPDU(usr_stats->cmpltn_cmn.flags);\n\n\tif (usr_stats->tlv_flags &\n\t    BIT(HTT_PPDU_STATS_TAG_USR_COMPLTN_ACK_BA_STATUS)) {\n\t\tsucc_bytes = usr_stats->ack_ba.success_bytes;\n\t\tsucc_pkts = FIELD_GET(HTT_PPDU_STATS_ACK_BA_INFO_NUM_MSDU_M,\n\t\t\t\t      usr_stats->ack_ba.info);\n\t\ttid = FIELD_GET(HTT_PPDU_STATS_ACK_BA_INFO_TID_NUM,\n\t\t\t\tusr_stats->ack_ba.info);\n\t}\n\n\tif (common->fes_duration_us)\n\t\ttx_duration = common->fes_duration_us;\n\n\tuser_rate = &usr_stats->rate;\n\tflags = HTT_USR_RATE_PREAMBLE(user_rate->rate_flags);\n\tbw = HTT_USR_RATE_BW(user_rate->rate_flags) - 2;\n\tnss = HTT_USR_RATE_NSS(user_rate->rate_flags) + 1;\n\tmcs = HTT_USR_RATE_MCS(user_rate->rate_flags);\n\tsgi = HTT_USR_RATE_GI(user_rate->rate_flags);\n\tdcm = HTT_USR_RATE_DCM(user_rate->rate_flags);\n\n\t \n\n\tif (flags == WMI_RATE_PREAMBLE_HE && mcs > ATH11K_HE_MCS_MAX) {\n\t\tath11k_warn(ab, \"Invalid HE mcs %d peer stats\",  mcs);\n\t\treturn;\n\t}\n\n\tif (flags == WMI_RATE_PREAMBLE_VHT && mcs > ATH11K_VHT_MCS_MAX) {\n\t\tath11k_warn(ab, \"Invalid VHT mcs %d peer stats\",  mcs);\n\t\treturn;\n\t}\n\n\tif (flags == WMI_RATE_PREAMBLE_HT && (mcs > ATH11K_HT_MCS_MAX || nss < 1)) {\n\t\tath11k_warn(ab, \"Invalid HT mcs %d nss %d peer stats\",\n\t\t\t    mcs, nss);\n\t\treturn;\n\t}\n\n\tif (flags == WMI_RATE_PREAMBLE_CCK || flags == WMI_RATE_PREAMBLE_OFDM) {\n\t\tret = ath11k_mac_hw_ratecode_to_legacy_rate(mcs,\n\t\t\t\t\t\t\t    flags,\n\t\t\t\t\t\t\t    &rate_idx,\n\t\t\t\t\t\t\t    &rate);\n\t\tif (ret < 0)\n\t\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tspin_lock_bh(&ab->base_lock);\n\tpeer = ath11k_peer_find_by_id(ab, usr_stats->peer_id);\n\n\tif (!peer || !peer->sta) {\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tsta = peer->sta;\n\tarsta = (struct ath11k_sta *)sta->drv_priv;\n\n\tmemset(&arsta->txrate, 0, sizeof(arsta->txrate));\n\n\tswitch (flags) {\n\tcase WMI_RATE_PREAMBLE_OFDM:\n\t\tarsta->txrate.legacy = rate;\n\t\tbreak;\n\tcase WMI_RATE_PREAMBLE_CCK:\n\t\tarsta->txrate.legacy = rate;\n\t\tbreak;\n\tcase WMI_RATE_PREAMBLE_HT:\n\t\tarsta->txrate.mcs = mcs + 8 * (nss - 1);\n\t\tarsta->txrate.flags = RATE_INFO_FLAGS_MCS;\n\t\tif (sgi)\n\t\t\tarsta->txrate.flags |= RATE_INFO_FLAGS_SHORT_GI;\n\t\tbreak;\n\tcase WMI_RATE_PREAMBLE_VHT:\n\t\tarsta->txrate.mcs = mcs;\n\t\tarsta->txrate.flags = RATE_INFO_FLAGS_VHT_MCS;\n\t\tif (sgi)\n\t\t\tarsta->txrate.flags |= RATE_INFO_FLAGS_SHORT_GI;\n\t\tbreak;\n\tcase WMI_RATE_PREAMBLE_HE:\n\t\tarsta->txrate.mcs = mcs;\n\t\tarsta->txrate.flags = RATE_INFO_FLAGS_HE_MCS;\n\t\tarsta->txrate.he_dcm = dcm;\n\t\tarsta->txrate.he_gi = ath11k_mac_he_gi_to_nl80211_he_gi(sgi);\n\t\tarsta->txrate.he_ru_alloc = ath11k_mac_phy_he_ru_to_nl80211_he_ru_alloc\n\t\t\t\t\t\t((user_rate->ru_end -\n\t\t\t\t\t\t user_rate->ru_start) + 1);\n\t\tbreak;\n\t}\n\n\tarsta->txrate.nss = nss;\n\n\tarsta->txrate.bw = ath11k_mac_bw_to_mac80211_bw(bw);\n\tarsta->tx_duration += tx_duration;\n\tmemcpy(&arsta->last_txrate, &arsta->txrate, sizeof(struct rate_info));\n\n\t \n\tif (tid < HTT_PPDU_STATS_NON_QOS_TID) {\n\t\tmemset(peer_stats, 0, sizeof(*peer_stats));\n\t\tpeer_stats->succ_pkts = succ_pkts;\n\t\tpeer_stats->succ_bytes = succ_bytes;\n\t\tpeer_stats->is_ampdu = is_ampdu;\n\t\tpeer_stats->duration = tx_duration;\n\t\tpeer_stats->ba_fails =\n\t\t\tHTT_USR_CMPLTN_LONG_RETRY(usr_stats->cmpltn_cmn.flags) +\n\t\t\tHTT_USR_CMPLTN_SHORT_RETRY(usr_stats->cmpltn_cmn.flags);\n\n\t\tif (ath11k_debugfs_is_extd_tx_stats_enabled(ar))\n\t\t\tath11k_debugfs_sta_add_tx_stats(arsta, peer_stats, rate_idx);\n\t}\n\n\tspin_unlock_bh(&ab->base_lock);\n\trcu_read_unlock();\n}\n\nstatic void ath11k_htt_update_ppdu_stats(struct ath11k *ar,\n\t\t\t\t\t struct htt_ppdu_stats *ppdu_stats)\n{\n\tu8 user;\n\n\tfor (user = 0; user < HTT_PPDU_STATS_MAX_USERS - 1; user++)\n\t\tath11k_update_per_peer_tx_stats(ar, ppdu_stats, user);\n}\n\nstatic\nstruct htt_ppdu_stats_info *ath11k_dp_htt_get_ppdu_desc(struct ath11k *ar,\n\t\t\t\t\t\t\tu32 ppdu_id)\n{\n\tstruct htt_ppdu_stats_info *ppdu_info;\n\n\tlockdep_assert_held(&ar->data_lock);\n\n\tif (!list_empty(&ar->ppdu_stats_info)) {\n\t\tlist_for_each_entry(ppdu_info, &ar->ppdu_stats_info, list) {\n\t\t\tif (ppdu_info->ppdu_id == ppdu_id)\n\t\t\t\treturn ppdu_info;\n\t\t}\n\n\t\tif (ar->ppdu_stat_list_depth > HTT_PPDU_DESC_MAX_DEPTH) {\n\t\t\tppdu_info = list_first_entry(&ar->ppdu_stats_info,\n\t\t\t\t\t\t     typeof(*ppdu_info), list);\n\t\t\tlist_del(&ppdu_info->list);\n\t\t\tar->ppdu_stat_list_depth--;\n\t\t\tath11k_htt_update_ppdu_stats(ar, &ppdu_info->ppdu_stats);\n\t\t\tkfree(ppdu_info);\n\t\t}\n\t}\n\n\tppdu_info = kzalloc(sizeof(*ppdu_info), GFP_ATOMIC);\n\tif (!ppdu_info)\n\t\treturn NULL;\n\n\tlist_add_tail(&ppdu_info->list, &ar->ppdu_stats_info);\n\tar->ppdu_stat_list_depth++;\n\n\treturn ppdu_info;\n}\n\nstatic int ath11k_htt_pull_ppdu_stats(struct ath11k_base *ab,\n\t\t\t\t      struct sk_buff *skb)\n{\n\tstruct ath11k_htt_ppdu_stats_msg *msg;\n\tstruct htt_ppdu_stats_info *ppdu_info;\n\tstruct ath11k *ar;\n\tint ret;\n\tu8 pdev_id;\n\tu32 ppdu_id, len;\n\n\tmsg = (struct ath11k_htt_ppdu_stats_msg *)skb->data;\n\tlen = FIELD_GET(HTT_T2H_PPDU_STATS_INFO_PAYLOAD_SIZE, msg->info);\n\tpdev_id = FIELD_GET(HTT_T2H_PPDU_STATS_INFO_PDEV_ID, msg->info);\n\tppdu_id = msg->ppdu_id;\n\n\trcu_read_lock();\n\tar = ath11k_mac_get_ar_by_pdev_id(ab, pdev_id);\n\tif (!ar) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (ath11k_debugfs_is_pktlog_lite_mode_enabled(ar))\n\t\ttrace_ath11k_htt_ppdu_stats(ar, skb->data, len);\n\n\tspin_lock_bh(&ar->data_lock);\n\tppdu_info = ath11k_dp_htt_get_ppdu_desc(ar, ppdu_id);\n\tif (!ppdu_info) {\n\t\tret = -EINVAL;\n\t\tgoto out_unlock_data;\n\t}\n\n\tppdu_info->ppdu_id = ppdu_id;\n\tret = ath11k_dp_htt_tlv_iter(ab, msg->data, len,\n\t\t\t\t     ath11k_htt_tlv_ppdu_stats_parse,\n\t\t\t\t     (void *)ppdu_info);\n\tif (ret) {\n\t\tath11k_warn(ab, \"Failed to parse tlv %d\\n\", ret);\n\t\tgoto out_unlock_data;\n\t}\n\nout_unlock_data:\n\tspin_unlock_bh(&ar->data_lock);\n\nout:\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nstatic void ath11k_htt_pktlog(struct ath11k_base *ab, struct sk_buff *skb)\n{\n\tstruct htt_pktlog_msg *data = (struct htt_pktlog_msg *)skb->data;\n\tstruct ath_pktlog_hdr *hdr = (struct ath_pktlog_hdr *)data;\n\tstruct ath11k *ar;\n\tu8 pdev_id;\n\n\tpdev_id = FIELD_GET(HTT_T2H_PPDU_STATS_INFO_PDEV_ID, data->hdr);\n\n\trcu_read_lock();\n\n\tar = ath11k_mac_get_ar_by_pdev_id(ab, pdev_id);\n\tif (!ar) {\n\t\tath11k_warn(ab, \"invalid pdev id %d on htt pktlog\\n\", pdev_id);\n\t\tgoto out;\n\t}\n\n\ttrace_ath11k_htt_pktlog(ar, data->payload, hdr->size,\n\t\t\t\tar->ab->pktlog_defs_checksum);\n\nout:\n\trcu_read_unlock();\n}\n\nstatic void ath11k_htt_backpressure_event_handler(struct ath11k_base *ab,\n\t\t\t\t\t\t  struct sk_buff *skb)\n{\n\tu32 *data = (u32 *)skb->data;\n\tu8 pdev_id, ring_type, ring_id, pdev_idx;\n\tu16 hp, tp;\n\tu32 backpressure_time;\n\tstruct ath11k_bp_stats *bp_stats;\n\n\tpdev_id = FIELD_GET(HTT_BACKPRESSURE_EVENT_PDEV_ID_M, *data);\n\tring_type = FIELD_GET(HTT_BACKPRESSURE_EVENT_RING_TYPE_M, *data);\n\tring_id = FIELD_GET(HTT_BACKPRESSURE_EVENT_RING_ID_M, *data);\n\t++data;\n\n\thp = FIELD_GET(HTT_BACKPRESSURE_EVENT_HP_M, *data);\n\ttp = FIELD_GET(HTT_BACKPRESSURE_EVENT_TP_M, *data);\n\t++data;\n\n\tbackpressure_time = *data;\n\n\tath11k_dbg(ab, ATH11K_DBG_DP_HTT, \"backpressure event, pdev %d, ring type %d,ring id %d, hp %d tp %d, backpressure time %d\\n\",\n\t\t   pdev_id, ring_type, ring_id, hp, tp, backpressure_time);\n\n\tif (ring_type == HTT_BACKPRESSURE_UMAC_RING_TYPE) {\n\t\tif (ring_id >= HTT_SW_UMAC_RING_IDX_MAX)\n\t\t\treturn;\n\n\t\tbp_stats = &ab->soc_stats.bp_stats.umac_ring_bp_stats[ring_id];\n\t} else if (ring_type == HTT_BACKPRESSURE_LMAC_RING_TYPE) {\n\t\tpdev_idx = DP_HW2SW_MACID(pdev_id);\n\n\t\tif (ring_id >= HTT_SW_LMAC_RING_IDX_MAX || pdev_idx >= MAX_RADIOS)\n\t\t\treturn;\n\n\t\tbp_stats = &ab->soc_stats.bp_stats.lmac_ring_bp_stats[ring_id][pdev_idx];\n\t} else {\n\t\tath11k_warn(ab, \"unknown ring type received in htt bp event %d\\n\",\n\t\t\t    ring_type);\n\t\treturn;\n\t}\n\n\tspin_lock_bh(&ab->base_lock);\n\tbp_stats->hp = hp;\n\tbp_stats->tp = tp;\n\tbp_stats->count++;\n\tbp_stats->jiffies = jiffies;\n\tspin_unlock_bh(&ab->base_lock);\n}\n\nvoid ath11k_dp_htt_htc_t2h_msg_handler(struct ath11k_base *ab,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct ath11k_dp *dp = &ab->dp;\n\tstruct htt_resp_msg *resp = (struct htt_resp_msg *)skb->data;\n\tenum htt_t2h_msg_type type = FIELD_GET(HTT_T2H_MSG_TYPE, *(u32 *)resp);\n\tu16 peer_id;\n\tu8 vdev_id;\n\tu8 mac_addr[ETH_ALEN];\n\tu16 peer_mac_h16;\n\tu16 ast_hash;\n\tu16 hw_peer_id;\n\n\tath11k_dbg(ab, ATH11K_DBG_DP_HTT, \"dp_htt rx msg type :0x%0x\\n\", type);\n\n\tswitch (type) {\n\tcase HTT_T2H_MSG_TYPE_VERSION_CONF:\n\t\tdp->htt_tgt_ver_major = FIELD_GET(HTT_T2H_VERSION_CONF_MAJOR,\n\t\t\t\t\t\t  resp->version_msg.version);\n\t\tdp->htt_tgt_ver_minor = FIELD_GET(HTT_T2H_VERSION_CONF_MINOR,\n\t\t\t\t\t\t  resp->version_msg.version);\n\t\tcomplete(&dp->htt_tgt_version_received);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PEER_MAP:\n\t\tvdev_id = FIELD_GET(HTT_T2H_PEER_MAP_INFO_VDEV_ID,\n\t\t\t\t    resp->peer_map_ev.info);\n\t\tpeer_id = FIELD_GET(HTT_T2H_PEER_MAP_INFO_PEER_ID,\n\t\t\t\t    resp->peer_map_ev.info);\n\t\tpeer_mac_h16 = FIELD_GET(HTT_T2H_PEER_MAP_INFO1_MAC_ADDR_H16,\n\t\t\t\t\t resp->peer_map_ev.info1);\n\t\tath11k_dp_get_mac_addr(resp->peer_map_ev.mac_addr_l32,\n\t\t\t\t       peer_mac_h16, mac_addr);\n\t\tath11k_peer_map_event(ab, vdev_id, peer_id, mac_addr, 0, 0);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PEER_MAP2:\n\t\tvdev_id = FIELD_GET(HTT_T2H_PEER_MAP_INFO_VDEV_ID,\n\t\t\t\t    resp->peer_map_ev.info);\n\t\tpeer_id = FIELD_GET(HTT_T2H_PEER_MAP_INFO_PEER_ID,\n\t\t\t\t    resp->peer_map_ev.info);\n\t\tpeer_mac_h16 = FIELD_GET(HTT_T2H_PEER_MAP_INFO1_MAC_ADDR_H16,\n\t\t\t\t\t resp->peer_map_ev.info1);\n\t\tath11k_dp_get_mac_addr(resp->peer_map_ev.mac_addr_l32,\n\t\t\t\t       peer_mac_h16, mac_addr);\n\t\tast_hash = FIELD_GET(HTT_T2H_PEER_MAP_INFO2_AST_HASH_VAL,\n\t\t\t\t     resp->peer_map_ev.info2);\n\t\thw_peer_id = FIELD_GET(HTT_T2H_PEER_MAP_INFO1_HW_PEER_ID,\n\t\t\t\t       resp->peer_map_ev.info1);\n\t\tath11k_peer_map_event(ab, vdev_id, peer_id, mac_addr, ast_hash,\n\t\t\t\t      hw_peer_id);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PEER_UNMAP:\n\tcase HTT_T2H_MSG_TYPE_PEER_UNMAP2:\n\t\tpeer_id = FIELD_GET(HTT_T2H_PEER_UNMAP_INFO_PEER_ID,\n\t\t\t\t    resp->peer_unmap_ev.info);\n\t\tath11k_peer_unmap_event(ab, peer_id);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PPDU_STATS_IND:\n\t\tath11k_htt_pull_ppdu_stats(ab, skb);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_EXT_STATS_CONF:\n\t\tath11k_debugfs_htt_ext_stats_handler(ab, skb);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PKTLOG:\n\t\tath11k_htt_pktlog(ab, skb);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_BKPRESSURE_EVENT_IND:\n\t\tath11k_htt_backpressure_event_handler(ab, skb);\n\t\tbreak;\n\tdefault:\n\t\tath11k_warn(ab, \"htt event %d not handled\\n\", type);\n\t\tbreak;\n\t}\n\n\tdev_kfree_skb_any(skb);\n}\n\nstatic int ath11k_dp_rx_msdu_coalesce(struct ath11k *ar,\n\t\t\t\t      struct sk_buff_head *msdu_list,\n\t\t\t\t      struct sk_buff *first, struct sk_buff *last,\n\t\t\t\t      u8 l3pad_bytes, int msdu_len)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct sk_buff *skb;\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(first);\n\tint buf_first_hdr_len, buf_first_len;\n\tstruct hal_rx_desc *ldesc;\n\tint space_extra, rem_len, buf_len;\n\tu32 hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\t \n\tbuf_first_hdr_len = hal_rx_desc_sz + l3pad_bytes;\n\tbuf_first_len = DP_RX_BUFFER_SIZE - buf_first_hdr_len;\n\n\tif (WARN_ON_ONCE(msdu_len <= buf_first_len)) {\n\t\tskb_put(first, buf_first_hdr_len + msdu_len);\n\t\tskb_pull(first, buf_first_hdr_len);\n\t\treturn 0;\n\t}\n\n\tldesc = (struct hal_rx_desc *)last->data;\n\trxcb->is_first_msdu = ath11k_dp_rx_h_msdu_end_first_msdu(ab, ldesc);\n\trxcb->is_last_msdu = ath11k_dp_rx_h_msdu_end_last_msdu(ab, ldesc);\n\n\t \n\tskb_put(first, DP_RX_BUFFER_SIZE);\n\tskb_pull(first, buf_first_hdr_len);\n\n\t \n\tath11k_dp_rx_desc_end_tlv_copy(ab, rxcb->rx_desc, ldesc);\n\n\tspace_extra = msdu_len - (buf_first_len + skb_tailroom(first));\n\tif (space_extra > 0 &&\n\t    (pskb_expand_head(first, 0, space_extra, GFP_ATOMIC) < 0)) {\n\t\t \n\t\twhile ((skb = __skb_dequeue(msdu_list)) != NULL) {\n\t\t\trxcb = ATH11K_SKB_RXCB(skb);\n\t\t\tif (!rxcb->is_continuation) {\n\t\t\t\tdev_kfree_skb_any(skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdev_kfree_skb_any(skb);\n\t\t}\n\t\treturn -ENOMEM;\n\t}\n\n\trem_len = msdu_len - buf_first_len;\n\twhile ((skb = __skb_dequeue(msdu_list)) != NULL && rem_len > 0) {\n\t\trxcb = ATH11K_SKB_RXCB(skb);\n\t\tif (rxcb->is_continuation)\n\t\t\tbuf_len = DP_RX_BUFFER_SIZE - hal_rx_desc_sz;\n\t\telse\n\t\t\tbuf_len = rem_len;\n\n\t\tif (buf_len > (DP_RX_BUFFER_SIZE - hal_rx_desc_sz)) {\n\t\t\tWARN_ON_ONCE(1);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tskb_put(skb, buf_len + hal_rx_desc_sz);\n\t\tskb_pull(skb, hal_rx_desc_sz);\n\t\tskb_copy_from_linear_data(skb, skb_put(first, buf_len),\n\t\t\t\t\t  buf_len);\n\t\tdev_kfree_skb_any(skb);\n\n\t\trem_len -= buf_len;\n\t\tif (!rxcb->is_continuation)\n\t\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic struct sk_buff *ath11k_dp_rx_get_msdu_last_buf(struct sk_buff_head *msdu_list,\n\t\t\t\t\t\t      struct sk_buff *first)\n{\n\tstruct sk_buff *skb;\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(first);\n\n\tif (!rxcb->is_continuation)\n\t\treturn first;\n\n\tskb_queue_walk(msdu_list, skb) {\n\t\trxcb = ATH11K_SKB_RXCB(skb);\n\t\tif (!rxcb->is_continuation)\n\t\t\treturn skb;\n\t}\n\n\treturn NULL;\n}\n\nstatic void ath11k_dp_rx_h_csum_offload(struct ath11k *ar, struct sk_buff *msdu)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tstruct rx_attention *rx_attention;\n\tbool ip_csum_fail, l4_csum_fail;\n\n\trx_attention = ath11k_dp_rx_get_attention(ar->ab, rxcb->rx_desc);\n\tip_csum_fail = ath11k_dp_rx_h_attn_ip_cksum_fail(rx_attention);\n\tl4_csum_fail = ath11k_dp_rx_h_attn_l4_cksum_fail(rx_attention);\n\n\tmsdu->ip_summed = (ip_csum_fail || l4_csum_fail) ?\n\t\t\t  CHECKSUM_NONE : CHECKSUM_UNNECESSARY;\n}\n\nstatic int ath11k_dp_rx_crypto_mic_len(struct ath11k *ar,\n\t\t\t\t       enum hal_encrypt_type enctype)\n{\n\tswitch (enctype) {\n\tcase HAL_ENCRYPT_TYPE_OPEN:\n\tcase HAL_ENCRYPT_TYPE_TKIP_NO_MIC:\n\tcase HAL_ENCRYPT_TYPE_TKIP_MIC:\n\t\treturn 0;\n\tcase HAL_ENCRYPT_TYPE_CCMP_128:\n\t\treturn IEEE80211_CCMP_MIC_LEN;\n\tcase HAL_ENCRYPT_TYPE_CCMP_256:\n\t\treturn IEEE80211_CCMP_256_MIC_LEN;\n\tcase HAL_ENCRYPT_TYPE_GCMP_128:\n\tcase HAL_ENCRYPT_TYPE_AES_GCMP_256:\n\t\treturn IEEE80211_GCMP_MIC_LEN;\n\tcase HAL_ENCRYPT_TYPE_WEP_40:\n\tcase HAL_ENCRYPT_TYPE_WEP_104:\n\tcase HAL_ENCRYPT_TYPE_WEP_128:\n\tcase HAL_ENCRYPT_TYPE_WAPI_GCM_SM4:\n\tcase HAL_ENCRYPT_TYPE_WAPI:\n\t\tbreak;\n\t}\n\n\tath11k_warn(ar->ab, \"unsupported encryption type %d for mic len\\n\", enctype);\n\treturn 0;\n}\n\nstatic int ath11k_dp_rx_crypto_param_len(struct ath11k *ar,\n\t\t\t\t\t enum hal_encrypt_type enctype)\n{\n\tswitch (enctype) {\n\tcase HAL_ENCRYPT_TYPE_OPEN:\n\t\treturn 0;\n\tcase HAL_ENCRYPT_TYPE_TKIP_NO_MIC:\n\tcase HAL_ENCRYPT_TYPE_TKIP_MIC:\n\t\treturn IEEE80211_TKIP_IV_LEN;\n\tcase HAL_ENCRYPT_TYPE_CCMP_128:\n\t\treturn IEEE80211_CCMP_HDR_LEN;\n\tcase HAL_ENCRYPT_TYPE_CCMP_256:\n\t\treturn IEEE80211_CCMP_256_HDR_LEN;\n\tcase HAL_ENCRYPT_TYPE_GCMP_128:\n\tcase HAL_ENCRYPT_TYPE_AES_GCMP_256:\n\t\treturn IEEE80211_GCMP_HDR_LEN;\n\tcase HAL_ENCRYPT_TYPE_WEP_40:\n\tcase HAL_ENCRYPT_TYPE_WEP_104:\n\tcase HAL_ENCRYPT_TYPE_WEP_128:\n\tcase HAL_ENCRYPT_TYPE_WAPI_GCM_SM4:\n\tcase HAL_ENCRYPT_TYPE_WAPI:\n\t\tbreak;\n\t}\n\n\tath11k_warn(ar->ab, \"unsupported encryption type %d\\n\", enctype);\n\treturn 0;\n}\n\nstatic int ath11k_dp_rx_crypto_icv_len(struct ath11k *ar,\n\t\t\t\t       enum hal_encrypt_type enctype)\n{\n\tswitch (enctype) {\n\tcase HAL_ENCRYPT_TYPE_OPEN:\n\tcase HAL_ENCRYPT_TYPE_CCMP_128:\n\tcase HAL_ENCRYPT_TYPE_CCMP_256:\n\tcase HAL_ENCRYPT_TYPE_GCMP_128:\n\tcase HAL_ENCRYPT_TYPE_AES_GCMP_256:\n\t\treturn 0;\n\tcase HAL_ENCRYPT_TYPE_TKIP_NO_MIC:\n\tcase HAL_ENCRYPT_TYPE_TKIP_MIC:\n\t\treturn IEEE80211_TKIP_ICV_LEN;\n\tcase HAL_ENCRYPT_TYPE_WEP_40:\n\tcase HAL_ENCRYPT_TYPE_WEP_104:\n\tcase HAL_ENCRYPT_TYPE_WEP_128:\n\tcase HAL_ENCRYPT_TYPE_WAPI_GCM_SM4:\n\tcase HAL_ENCRYPT_TYPE_WAPI:\n\t\tbreak;\n\t}\n\n\tath11k_warn(ar->ab, \"unsupported encryption type %d\\n\", enctype);\n\treturn 0;\n}\n\nstatic void ath11k_dp_rx_h_undecap_nwifi(struct ath11k *ar,\n\t\t\t\t\t struct sk_buff *msdu,\n\t\t\t\t\t u8 *first_hdr,\n\t\t\t\t\t enum hal_encrypt_type enctype,\n\t\t\t\t\t struct ieee80211_rx_status *status)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tu8 decap_hdr[DP_MAX_NWIFI_HDR_LEN];\n\tstruct ieee80211_hdr *hdr;\n\tsize_t hdr_len;\n\tu8 da[ETH_ALEN];\n\tu8 sa[ETH_ALEN];\n\tu16 qos_ctl = 0;\n\tu8 *qos;\n\n\t \n\thdr = (struct ieee80211_hdr *)msdu->data;\n\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\tether_addr_copy(da, ieee80211_get_DA(hdr));\n\tether_addr_copy(sa, ieee80211_get_SA(hdr));\n\tskb_pull(msdu, ieee80211_hdrlen(hdr->frame_control));\n\n\tif (rxcb->is_first_msdu) {\n\t\t \n\t\thdr = (struct ieee80211_hdr *)first_hdr;\n\t\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\n\t\t \n\t\tif (ieee80211_is_data_qos(hdr->frame_control)) {\n\t\t\tqos = ieee80211_get_qos_ctl(hdr);\n\t\t\tqos[0] &= ~IEEE80211_QOS_CTL_A_MSDU_PRESENT;\n\t\t}\n\t} else {\n\t\t \n\t\thdr->frame_control |= __cpu_to_le16(IEEE80211_STYPE_QOS_DATA);\n\n\t\t \n\t\thdr->frame_control &= ~(__cpu_to_le16(IEEE80211_FCTL_ORDER));\n\n\t\tqos_ctl = rxcb->tid;\n\n\t\tif (ath11k_dp_rx_h_msdu_start_mesh_ctl_present(ar->ab, rxcb->rx_desc))\n\t\t\tqos_ctl |= IEEE80211_QOS_CTL_MESH_CONTROL_PRESENT;\n\n\t\t \n\n\t\t \n\t\tmemcpy(decap_hdr, (uint8_t *)hdr, hdr_len);\n\t}\n\n\tif (!(status->flag & RX_FLAG_IV_STRIPPED)) {\n\t\tmemcpy(skb_push(msdu,\n\t\t\t\tath11k_dp_rx_crypto_param_len(ar, enctype)),\n\t\t       (void *)hdr + hdr_len,\n\t\t       ath11k_dp_rx_crypto_param_len(ar, enctype));\n\t}\n\n\tif (!rxcb->is_first_msdu) {\n\t\tmemcpy(skb_push(msdu,\n\t\t\t\tIEEE80211_QOS_CTL_LEN), &qos_ctl,\n\t\t\t\tIEEE80211_QOS_CTL_LEN);\n\t\tmemcpy(skb_push(msdu, hdr_len), decap_hdr, hdr_len);\n\t\treturn;\n\t}\n\n\tmemcpy(skb_push(msdu, hdr_len), hdr, hdr_len);\n\n\t \n\thdr = (struct ieee80211_hdr *)msdu->data;\n\tether_addr_copy(ieee80211_get_DA(hdr), da);\n\tether_addr_copy(ieee80211_get_SA(hdr), sa);\n}\n\nstatic void ath11k_dp_rx_h_undecap_raw(struct ath11k *ar, struct sk_buff *msdu,\n\t\t\t\t       enum hal_encrypt_type enctype,\n\t\t\t\t       struct ieee80211_rx_status *status,\n\t\t\t\t       bool decrypted)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tstruct ieee80211_hdr *hdr;\n\tsize_t hdr_len;\n\tsize_t crypto_len;\n\n\tif (!rxcb->is_first_msdu ||\n\t    !(rxcb->is_first_msdu && rxcb->is_last_msdu)) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn;\n\t}\n\n\tskb_trim(msdu, msdu->len - FCS_LEN);\n\n\tif (!decrypted)\n\t\treturn;\n\n\thdr = (void *)msdu->data;\n\n\t \n\tif (status->flag & RX_FLAG_IV_STRIPPED) {\n\t\tskb_trim(msdu, msdu->len -\n\t\t\t ath11k_dp_rx_crypto_mic_len(ar, enctype));\n\n\t\tskb_trim(msdu, msdu->len -\n\t\t\t ath11k_dp_rx_crypto_icv_len(ar, enctype));\n\t} else {\n\t\t \n\t\tif (status->flag & RX_FLAG_MIC_STRIPPED)\n\t\t\tskb_trim(msdu, msdu->len -\n\t\t\t\t ath11k_dp_rx_crypto_mic_len(ar, enctype));\n\n\t\t \n\t\tif (status->flag & RX_FLAG_ICV_STRIPPED)\n\t\t\tskb_trim(msdu, msdu->len -\n\t\t\t\t ath11k_dp_rx_crypto_icv_len(ar, enctype));\n\t}\n\n\t \n\tif ((status->flag & RX_FLAG_MMIC_STRIPPED) &&\n\t    !ieee80211_has_morefrags(hdr->frame_control) &&\n\t    enctype == HAL_ENCRYPT_TYPE_TKIP_MIC)\n\t\tskb_trim(msdu, msdu->len - IEEE80211_CCMP_MIC_LEN);\n\n\t \n\tif (status->flag & RX_FLAG_IV_STRIPPED) {\n\t\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\t\tcrypto_len = ath11k_dp_rx_crypto_param_len(ar, enctype);\n\n\t\tmemmove((void *)msdu->data + crypto_len,\n\t\t\t(void *)msdu->data, hdr_len);\n\t\tskb_pull(msdu, crypto_len);\n\t}\n}\n\nstatic void *ath11k_dp_rx_h_find_rfc1042(struct ath11k *ar,\n\t\t\t\t\t struct sk_buff *msdu,\n\t\t\t\t\t enum hal_encrypt_type enctype)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tstruct ieee80211_hdr *hdr;\n\tsize_t hdr_len, crypto_len;\n\tvoid *rfc1042;\n\tbool is_amsdu;\n\n\tis_amsdu = !(rxcb->is_first_msdu && rxcb->is_last_msdu);\n\thdr = (struct ieee80211_hdr *)ath11k_dp_rx_h_80211_hdr(ar->ab, rxcb->rx_desc);\n\trfc1042 = hdr;\n\n\tif (rxcb->is_first_msdu) {\n\t\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\t\tcrypto_len = ath11k_dp_rx_crypto_param_len(ar, enctype);\n\n\t\trfc1042 += hdr_len + crypto_len;\n\t}\n\n\tif (is_amsdu)\n\t\trfc1042 += sizeof(struct ath11k_dp_amsdu_subframe_hdr);\n\n\treturn rfc1042;\n}\n\nstatic void ath11k_dp_rx_h_undecap_eth(struct ath11k *ar,\n\t\t\t\t       struct sk_buff *msdu,\n\t\t\t\t       u8 *first_hdr,\n\t\t\t\t       enum hal_encrypt_type enctype,\n\t\t\t\t       struct ieee80211_rx_status *status)\n{\n\tstruct ieee80211_hdr *hdr;\n\tstruct ethhdr *eth;\n\tsize_t hdr_len;\n\tu8 da[ETH_ALEN];\n\tu8 sa[ETH_ALEN];\n\tvoid *rfc1042;\n\n\trfc1042 = ath11k_dp_rx_h_find_rfc1042(ar, msdu, enctype);\n\tif (WARN_ON_ONCE(!rfc1042))\n\t\treturn;\n\n\t \n\teth = (struct ethhdr *)msdu->data;\n\tether_addr_copy(da, eth->h_dest);\n\tether_addr_copy(sa, eth->h_source);\n\tskb_pull(msdu, sizeof(struct ethhdr));\n\n\t \n\tmemcpy(skb_push(msdu, sizeof(struct ath11k_dp_rfc1042_hdr)), rfc1042,\n\t       sizeof(struct ath11k_dp_rfc1042_hdr));\n\n\t \n\thdr = (struct ieee80211_hdr *)first_hdr;\n\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\n\tif (!(status->flag & RX_FLAG_IV_STRIPPED)) {\n\t\tmemcpy(skb_push(msdu,\n\t\t\t\tath11k_dp_rx_crypto_param_len(ar, enctype)),\n\t\t       (void *)hdr + hdr_len,\n\t\t       ath11k_dp_rx_crypto_param_len(ar, enctype));\n\t}\n\n\tmemcpy(skb_push(msdu, hdr_len), hdr, hdr_len);\n\n\t \n\thdr = (struct ieee80211_hdr *)msdu->data;\n\tether_addr_copy(ieee80211_get_DA(hdr), da);\n\tether_addr_copy(ieee80211_get_SA(hdr), sa);\n}\n\nstatic void ath11k_dp_rx_h_undecap(struct ath11k *ar, struct sk_buff *msdu,\n\t\t\t\t   struct hal_rx_desc *rx_desc,\n\t\t\t\t   enum hal_encrypt_type enctype,\n\t\t\t\t   struct ieee80211_rx_status *status,\n\t\t\t\t   bool decrypted)\n{\n\tu8 *first_hdr;\n\tu8 decap;\n\tstruct ethhdr *ehdr;\n\n\tfirst_hdr = ath11k_dp_rx_h_80211_hdr(ar->ab, rx_desc);\n\tdecap = ath11k_dp_rx_h_msdu_start_decap_type(ar->ab, rx_desc);\n\n\tswitch (decap) {\n\tcase DP_RX_DECAP_TYPE_NATIVE_WIFI:\n\t\tath11k_dp_rx_h_undecap_nwifi(ar, msdu, first_hdr,\n\t\t\t\t\t     enctype, status);\n\t\tbreak;\n\tcase DP_RX_DECAP_TYPE_RAW:\n\t\tath11k_dp_rx_h_undecap_raw(ar, msdu, enctype, status,\n\t\t\t\t\t   decrypted);\n\t\tbreak;\n\tcase DP_RX_DECAP_TYPE_ETHERNET2_DIX:\n\t\tehdr = (struct ethhdr *)msdu->data;\n\n\t\t \n\t\tif (ehdr->h_proto == cpu_to_be16(ETH_P_PAE)) {\n\t\t\tATH11K_SKB_RXCB(msdu)->is_eapol = true;\n\t\t\tath11k_dp_rx_h_undecap_eth(ar, msdu, first_hdr,\n\t\t\t\t\t\t   enctype, status);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (ATH11K_SKB_RXCB(msdu)->is_mcbc && decrypted)\n\t\t\tath11k_dp_rx_h_undecap_eth(ar, msdu, first_hdr,\n\t\t\t\t\t\t   enctype, status);\n\t\tbreak;\n\tcase DP_RX_DECAP_TYPE_8023:\n\t\t \n\t\tbreak;\n\t}\n}\n\nstatic struct ath11k_peer *\nath11k_dp_rx_h_find_peer(struct ath11k_base *ab, struct sk_buff *msdu)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tstruct hal_rx_desc *rx_desc = rxcb->rx_desc;\n\tstruct ath11k_peer *peer = NULL;\n\n\tlockdep_assert_held(&ab->base_lock);\n\n\tif (rxcb->peer_id)\n\t\tpeer = ath11k_peer_find_by_id(ab, rxcb->peer_id);\n\n\tif (peer)\n\t\treturn peer;\n\n\tif (!rx_desc || !(ath11k_dp_rxdesc_mac_addr2_valid(ab, rx_desc)))\n\t\treturn NULL;\n\n\tpeer = ath11k_peer_find_by_addr(ab,\n\t\t\t\t\tath11k_dp_rxdesc_mpdu_start_addr2(ab, rx_desc));\n\treturn peer;\n}\n\nstatic void ath11k_dp_rx_h_mpdu(struct ath11k *ar,\n\t\t\t\tstruct sk_buff *msdu,\n\t\t\t\tstruct hal_rx_desc *rx_desc,\n\t\t\t\tstruct ieee80211_rx_status *rx_status)\n{\n\tbool  fill_crypto_hdr;\n\tenum hal_encrypt_type enctype;\n\tbool is_decrypted = false;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tstruct ieee80211_hdr *hdr;\n\tstruct ath11k_peer *peer;\n\tstruct rx_attention *rx_attention;\n\tu32 err_bitmap;\n\n\t \n\trxcb = ATH11K_SKB_RXCB(msdu);\n\tfill_crypto_hdr = ath11k_dp_rx_h_attn_is_mcbc(ar->ab, rx_desc);\n\trxcb->is_mcbc = fill_crypto_hdr;\n\n\tif (rxcb->is_mcbc) {\n\t\trxcb->peer_id = ath11k_dp_rx_h_mpdu_start_peer_id(ar->ab, rx_desc);\n\t\trxcb->seq_no = ath11k_dp_rx_h_mpdu_start_seq_no(ar->ab, rx_desc);\n\t}\n\n\tspin_lock_bh(&ar->ab->base_lock);\n\tpeer = ath11k_dp_rx_h_find_peer(ar->ab, msdu);\n\tif (peer) {\n\t\tif (rxcb->is_mcbc)\n\t\t\tenctype = peer->sec_type_grp;\n\t\telse\n\t\t\tenctype = peer->sec_type;\n\t} else {\n\t\tenctype = ath11k_dp_rx_h_mpdu_start_enctype(ar->ab, rx_desc);\n\t}\n\tspin_unlock_bh(&ar->ab->base_lock);\n\n\trx_attention = ath11k_dp_rx_get_attention(ar->ab, rx_desc);\n\terr_bitmap = ath11k_dp_rx_h_attn_mpdu_err(rx_attention);\n\tif (enctype != HAL_ENCRYPT_TYPE_OPEN && !err_bitmap)\n\t\tis_decrypted = ath11k_dp_rx_h_attn_is_decrypted(rx_attention);\n\n\t \n\trx_status->flag &= ~(RX_FLAG_FAILED_FCS_CRC |\n\t\t\t     RX_FLAG_MMIC_ERROR |\n\t\t\t     RX_FLAG_DECRYPTED |\n\t\t\t     RX_FLAG_IV_STRIPPED |\n\t\t\t     RX_FLAG_MMIC_STRIPPED);\n\n\tif (err_bitmap & DP_RX_MPDU_ERR_FCS)\n\t\trx_status->flag |= RX_FLAG_FAILED_FCS_CRC;\n\tif (err_bitmap & DP_RX_MPDU_ERR_TKIP_MIC)\n\t\trx_status->flag |= RX_FLAG_MMIC_ERROR;\n\n\tif (is_decrypted) {\n\t\trx_status->flag |= RX_FLAG_DECRYPTED | RX_FLAG_MMIC_STRIPPED;\n\n\t\tif (fill_crypto_hdr)\n\t\t\trx_status->flag |= RX_FLAG_MIC_STRIPPED |\n\t\t\t\t\tRX_FLAG_ICV_STRIPPED;\n\t\telse\n\t\t\trx_status->flag |= RX_FLAG_IV_STRIPPED |\n\t\t\t\t\t   RX_FLAG_PN_VALIDATED;\n\t}\n\n\tath11k_dp_rx_h_csum_offload(ar, msdu);\n\tath11k_dp_rx_h_undecap(ar, msdu, rx_desc,\n\t\t\t       enctype, rx_status, is_decrypted);\n\n\tif (!is_decrypted || fill_crypto_hdr)\n\t\treturn;\n\n\tif (ath11k_dp_rx_h_msdu_start_decap_type(ar->ab, rx_desc) !=\n\t    DP_RX_DECAP_TYPE_ETHERNET2_DIX) {\n\t\thdr = (void *)msdu->data;\n\t\thdr->frame_control &= ~__cpu_to_le16(IEEE80211_FCTL_PROTECTED);\n\t}\n}\n\nstatic void ath11k_dp_rx_h_rate(struct ath11k *ar, struct hal_rx_desc *rx_desc,\n\t\t\t\tstruct ieee80211_rx_status *rx_status)\n{\n\tstruct ieee80211_supported_band *sband;\n\tenum rx_msdu_start_pkt_type pkt_type;\n\tu8 bw;\n\tu8 rate_mcs, nss;\n\tu8 sgi;\n\tbool is_cck, is_ldpc;\n\n\tpkt_type = ath11k_dp_rx_h_msdu_start_pkt_type(ar->ab, rx_desc);\n\tbw = ath11k_dp_rx_h_msdu_start_rx_bw(ar->ab, rx_desc);\n\trate_mcs = ath11k_dp_rx_h_msdu_start_rate_mcs(ar->ab, rx_desc);\n\tnss = ath11k_dp_rx_h_msdu_start_nss(ar->ab, rx_desc);\n\tsgi = ath11k_dp_rx_h_msdu_start_sgi(ar->ab, rx_desc);\n\n\tswitch (pkt_type) {\n\tcase RX_MSDU_START_PKT_TYPE_11A:\n\tcase RX_MSDU_START_PKT_TYPE_11B:\n\t\tis_cck = (pkt_type == RX_MSDU_START_PKT_TYPE_11B);\n\t\tsband = &ar->mac.sbands[rx_status->band];\n\t\trx_status->rate_idx = ath11k_mac_hw_rate_to_idx(sband, rate_mcs,\n\t\t\t\t\t\t\t\tis_cck);\n\t\tbreak;\n\tcase RX_MSDU_START_PKT_TYPE_11N:\n\t\trx_status->encoding = RX_ENC_HT;\n\t\tif (rate_mcs > ATH11K_HT_MCS_MAX) {\n\t\t\tath11k_warn(ar->ab,\n\t\t\t\t    \"Received with invalid mcs in HT mode %d\\n\",\n\t\t\t\t     rate_mcs);\n\t\t\tbreak;\n\t\t}\n\t\trx_status->rate_idx = rate_mcs + (8 * (nss - 1));\n\t\tif (sgi)\n\t\t\trx_status->enc_flags |= RX_ENC_FLAG_SHORT_GI;\n\t\trx_status->bw = ath11k_mac_bw_to_mac80211_bw(bw);\n\t\tbreak;\n\tcase RX_MSDU_START_PKT_TYPE_11AC:\n\t\trx_status->encoding = RX_ENC_VHT;\n\t\trx_status->rate_idx = rate_mcs;\n\t\tif (rate_mcs > ATH11K_VHT_MCS_MAX) {\n\t\t\tath11k_warn(ar->ab,\n\t\t\t\t    \"Received with invalid mcs in VHT mode %d\\n\",\n\t\t\t\t     rate_mcs);\n\t\t\tbreak;\n\t\t}\n\t\trx_status->nss = nss;\n\t\tif (sgi)\n\t\t\trx_status->enc_flags |= RX_ENC_FLAG_SHORT_GI;\n\t\trx_status->bw = ath11k_mac_bw_to_mac80211_bw(bw);\n\t\tis_ldpc = ath11k_dp_rx_h_msdu_start_ldpc_support(ar->ab, rx_desc);\n\t\tif (is_ldpc)\n\t\t\trx_status->enc_flags |= RX_ENC_FLAG_LDPC;\n\t\tbreak;\n\tcase RX_MSDU_START_PKT_TYPE_11AX:\n\t\trx_status->rate_idx = rate_mcs;\n\t\tif (rate_mcs > ATH11K_HE_MCS_MAX) {\n\t\t\tath11k_warn(ar->ab,\n\t\t\t\t    \"Received with invalid mcs in HE mode %d\\n\",\n\t\t\t\t    rate_mcs);\n\t\t\tbreak;\n\t\t}\n\t\trx_status->encoding = RX_ENC_HE;\n\t\trx_status->nss = nss;\n\t\trx_status->he_gi = ath11k_mac_he_gi_to_nl80211_he_gi(sgi);\n\t\trx_status->bw = ath11k_mac_bw_to_mac80211_bw(bw);\n\t\tbreak;\n\t}\n}\n\nstatic void ath11k_dp_rx_h_ppdu(struct ath11k *ar, struct hal_rx_desc *rx_desc,\n\t\t\t\tstruct ieee80211_rx_status *rx_status)\n{\n\tu8 channel_num;\n\tu32 center_freq, meta_data;\n\tstruct ieee80211_channel *channel;\n\n\trx_status->freq = 0;\n\trx_status->rate_idx = 0;\n\trx_status->nss = 0;\n\trx_status->encoding = RX_ENC_LEGACY;\n\trx_status->bw = RATE_INFO_BW_20;\n\n\trx_status->flag |= RX_FLAG_NO_SIGNAL_VAL;\n\n\tmeta_data = ath11k_dp_rx_h_msdu_start_freq(ar->ab, rx_desc);\n\tchannel_num = meta_data;\n\tcenter_freq = meta_data >> 16;\n\n\tif (center_freq >= ATH11K_MIN_6G_FREQ &&\n\t    center_freq <= ATH11K_MAX_6G_FREQ) {\n\t\trx_status->band = NL80211_BAND_6GHZ;\n\t\trx_status->freq = center_freq;\n\t} else if (channel_num >= 1 && channel_num <= 14) {\n\t\trx_status->band = NL80211_BAND_2GHZ;\n\t} else if (channel_num >= 36 && channel_num <= 177) {\n\t\trx_status->band = NL80211_BAND_5GHZ;\n\t} else {\n\t\tspin_lock_bh(&ar->data_lock);\n\t\tchannel = ar->rx_channel;\n\t\tif (channel) {\n\t\t\trx_status->band = channel->band;\n\t\t\tchannel_num =\n\t\t\t\tieee80211_frequency_to_channel(channel->center_freq);\n\t\t}\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\tath11k_dbg_dump(ar->ab, ATH11K_DBG_DATA, NULL, \"rx_desc: \",\n\t\t\t\trx_desc, sizeof(struct hal_rx_desc));\n\t}\n\n\tif (rx_status->band != NL80211_BAND_6GHZ)\n\t\trx_status->freq = ieee80211_channel_to_frequency(channel_num,\n\t\t\t\t\t\t\t\t rx_status->band);\n\n\tath11k_dp_rx_h_rate(ar, rx_desc, rx_status);\n}\n\nstatic void ath11k_dp_rx_deliver_msdu(struct ath11k *ar, struct napi_struct *napi,\n\t\t\t\t      struct sk_buff *msdu,\n\t\t\t\t      struct ieee80211_rx_status *status)\n{\n\tstatic const struct ieee80211_radiotap_he known = {\n\t\t.data1 = cpu_to_le16(IEEE80211_RADIOTAP_HE_DATA1_DATA_MCS_KNOWN |\n\t\t\t\t     IEEE80211_RADIOTAP_HE_DATA1_BW_RU_ALLOC_KNOWN),\n\t\t.data2 = cpu_to_le16(IEEE80211_RADIOTAP_HE_DATA2_GI_KNOWN),\n\t};\n\tstruct ieee80211_rx_status *rx_status;\n\tstruct ieee80211_radiotap_he *he = NULL;\n\tstruct ieee80211_sta *pubsta = NULL;\n\tstruct ath11k_peer *peer;\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tu8 decap = DP_RX_DECAP_TYPE_RAW;\n\tbool is_mcbc = rxcb->is_mcbc;\n\tbool is_eapol = rxcb->is_eapol;\n\n\tif (status->encoding == RX_ENC_HE &&\n\t    !(status->flag & RX_FLAG_RADIOTAP_HE) &&\n\t    !(status->flag & RX_FLAG_SKIP_MONITOR)) {\n\t\the = skb_push(msdu, sizeof(known));\n\t\tmemcpy(he, &known, sizeof(known));\n\t\tstatus->flag |= RX_FLAG_RADIOTAP_HE;\n\t}\n\n\tif (!(status->flag & RX_FLAG_ONLY_MONITOR))\n\t\tdecap = ath11k_dp_rx_h_msdu_start_decap_type(ar->ab, rxcb->rx_desc);\n\n\tspin_lock_bh(&ar->ab->base_lock);\n\tpeer = ath11k_dp_rx_h_find_peer(ar->ab, msdu);\n\tif (peer && peer->sta)\n\t\tpubsta = peer->sta;\n\tspin_unlock_bh(&ar->ab->base_lock);\n\n\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t   \"rx skb %p len %u peer %pM %d %s sn %u %s%s%s%s%s%s%s %srate_idx %u vht_nss %u freq %u band %u flag 0x%x fcs-err %i mic-err %i amsdu-more %i\\n\",\n\t\t   msdu,\n\t\t   msdu->len,\n\t\t   peer ? peer->addr : NULL,\n\t\t   rxcb->tid,\n\t\t   is_mcbc ? \"mcast\" : \"ucast\",\n\t\t   rxcb->seq_no,\n\t\t   (status->encoding == RX_ENC_LEGACY) ? \"legacy\" : \"\",\n\t\t   (status->encoding == RX_ENC_HT) ? \"ht\" : \"\",\n\t\t   (status->encoding == RX_ENC_VHT) ? \"vht\" : \"\",\n\t\t   (status->encoding == RX_ENC_HE) ? \"he\" : \"\",\n\t\t   (status->bw == RATE_INFO_BW_40) ? \"40\" : \"\",\n\t\t   (status->bw == RATE_INFO_BW_80) ? \"80\" : \"\",\n\t\t   (status->bw == RATE_INFO_BW_160) ? \"160\" : \"\",\n\t\t   status->enc_flags & RX_ENC_FLAG_SHORT_GI ? \"sgi \" : \"\",\n\t\t   status->rate_idx,\n\t\t   status->nss,\n\t\t   status->freq,\n\t\t   status->band, status->flag,\n\t\t   !!(status->flag & RX_FLAG_FAILED_FCS_CRC),\n\t\t   !!(status->flag & RX_FLAG_MMIC_ERROR),\n\t\t   !!(status->flag & RX_FLAG_AMSDU_MORE));\n\n\tath11k_dbg_dump(ar->ab, ATH11K_DBG_DP_RX, NULL, \"dp rx msdu: \",\n\t\t\tmsdu->data, msdu->len);\n\n\trx_status = IEEE80211_SKB_RXCB(msdu);\n\t*rx_status = *status;\n\n\t \n\n\t \n\tif (decap == DP_RX_DECAP_TYPE_ETHERNET2_DIX && !is_eapol &&\n\t    !(is_mcbc && rx_status->flag & RX_FLAG_DECRYPTED))\n\t\trx_status->flag |= RX_FLAG_8023;\n\n\tieee80211_rx_napi(ar->hw, pubsta, msdu, napi);\n}\n\nstatic int ath11k_dp_rx_process_msdu(struct ath11k *ar,\n\t\t\t\t     struct sk_buff *msdu,\n\t\t\t\t     struct sk_buff_head *msdu_list,\n\t\t\t\t     struct ieee80211_rx_status *rx_status)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct hal_rx_desc *rx_desc, *lrx_desc;\n\tstruct rx_attention *rx_attention;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tstruct sk_buff *last_buf;\n\tu8 l3_pad_bytes;\n\tu8 *hdr_status;\n\tu16 msdu_len;\n\tint ret;\n\tu32 hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\tlast_buf = ath11k_dp_rx_get_msdu_last_buf(msdu_list, msdu);\n\tif (!last_buf) {\n\t\tath11k_warn(ab,\n\t\t\t    \"No valid Rx buffer to access Atten/MSDU_END/MPDU_END tlvs\\n\");\n\t\tret = -EIO;\n\t\tgoto free_out;\n\t}\n\n\trx_desc = (struct hal_rx_desc *)msdu->data;\n\tif (ath11k_dp_rx_h_attn_msdu_len_err(ab, rx_desc)) {\n\t\tath11k_warn(ar->ab, \"msdu len not valid\\n\");\n\t\tret = -EIO;\n\t\tgoto free_out;\n\t}\n\n\tlrx_desc = (struct hal_rx_desc *)last_buf->data;\n\trx_attention = ath11k_dp_rx_get_attention(ab, lrx_desc);\n\tif (!ath11k_dp_rx_h_attn_msdu_done(rx_attention)) {\n\t\tath11k_warn(ab, \"msdu_done bit in attention is not set\\n\");\n\t\tret = -EIO;\n\t\tgoto free_out;\n\t}\n\n\trxcb = ATH11K_SKB_RXCB(msdu);\n\trxcb->rx_desc = rx_desc;\n\tmsdu_len = ath11k_dp_rx_h_msdu_start_msdu_len(ab, rx_desc);\n\tl3_pad_bytes = ath11k_dp_rx_h_msdu_end_l3pad(ab, lrx_desc);\n\n\tif (rxcb->is_frag) {\n\t\tskb_pull(msdu, hal_rx_desc_sz);\n\t} else if (!rxcb->is_continuation) {\n\t\tif ((msdu_len + hal_rx_desc_sz) > DP_RX_BUFFER_SIZE) {\n\t\t\thdr_status = ath11k_dp_rx_h_80211_hdr(ab, rx_desc);\n\t\t\tret = -EINVAL;\n\t\t\tath11k_warn(ab, \"invalid msdu len %u\\n\", msdu_len);\n\t\t\tath11k_dbg_dump(ab, ATH11K_DBG_DATA, NULL, \"\", hdr_status,\n\t\t\t\t\tsizeof(struct ieee80211_hdr));\n\t\t\tath11k_dbg_dump(ab, ATH11K_DBG_DATA, NULL, \"\", rx_desc,\n\t\t\t\t\tsizeof(struct hal_rx_desc));\n\t\t\tgoto free_out;\n\t\t}\n\t\tskb_put(msdu, hal_rx_desc_sz + l3_pad_bytes + msdu_len);\n\t\tskb_pull(msdu, hal_rx_desc_sz + l3_pad_bytes);\n\t} else {\n\t\tret = ath11k_dp_rx_msdu_coalesce(ar, msdu_list,\n\t\t\t\t\t\t msdu, last_buf,\n\t\t\t\t\t\t l3_pad_bytes, msdu_len);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab,\n\t\t\t\t    \"failed to coalesce msdu rx buffer%d\\n\", ret);\n\t\t\tgoto free_out;\n\t\t}\n\t}\n\n\tath11k_dp_rx_h_ppdu(ar, rx_desc, rx_status);\n\tath11k_dp_rx_h_mpdu(ar, msdu, rx_desc, rx_status);\n\n\trx_status->flag |= RX_FLAG_SKIP_MONITOR | RX_FLAG_DUP_VALIDATED;\n\n\treturn 0;\n\nfree_out:\n\treturn ret;\n}\n\nstatic void ath11k_dp_rx_process_received_packets(struct ath11k_base *ab,\n\t\t\t\t\t\t  struct napi_struct *napi,\n\t\t\t\t\t\t  struct sk_buff_head *msdu_list,\n\t\t\t\t\t\t  int mac_id)\n{\n\tstruct sk_buff *msdu;\n\tstruct ath11k *ar;\n\tstruct ieee80211_rx_status rx_status = {0};\n\tint ret;\n\n\tif (skb_queue_empty(msdu_list))\n\t\treturn;\n\n\tif (unlikely(!rcu_access_pointer(ab->pdevs_active[mac_id]))) {\n\t\t__skb_queue_purge(msdu_list);\n\t\treturn;\n\t}\n\n\tar = ab->pdevs[mac_id].ar;\n\tif (unlikely(test_bit(ATH11K_CAC_RUNNING, &ar->dev_flags))) {\n\t\t__skb_queue_purge(msdu_list);\n\t\treturn;\n\t}\n\n\twhile ((msdu = __skb_dequeue(msdu_list))) {\n\t\tret = ath11k_dp_rx_process_msdu(ar, msdu, msdu_list, &rx_status);\n\t\tif (unlikely(ret)) {\n\t\t\tath11k_dbg(ab, ATH11K_DBG_DATA,\n\t\t\t\t   \"Unable to process msdu %d\", ret);\n\t\t\tdev_kfree_skb_any(msdu);\n\t\t\tcontinue;\n\t\t}\n\n\t\tath11k_dp_rx_deliver_msdu(ar, napi, msdu, &rx_status);\n\t}\n}\n\nint ath11k_dp_process_rx(struct ath11k_base *ab, int ring_id,\n\t\t\t struct napi_struct *napi, int budget)\n{\n\tstruct ath11k_dp *dp = &ab->dp;\n\tstruct dp_rxdma_ring *rx_ring;\n\tint num_buffs_reaped[MAX_RADIOS] = {0};\n\tstruct sk_buff_head msdu_list[MAX_RADIOS];\n\tstruct ath11k_skb_rxcb *rxcb;\n\tint total_msdu_reaped = 0;\n\tstruct hal_srng *srng;\n\tstruct sk_buff *msdu;\n\tbool done = false;\n\tint buf_id, mac_id;\n\tstruct ath11k *ar;\n\tstruct hal_reo_dest_ring *desc;\n\tenum hal_reo_dest_ring_push_reason push_reason;\n\tu32 cookie;\n\tint i;\n\n\tfor (i = 0; i < MAX_RADIOS; i++)\n\t\t__skb_queue_head_init(&msdu_list[i]);\n\n\tsrng = &ab->hal.srng_list[dp->reo_dst_ring[ring_id].ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\ntry_again:\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\twhile (likely(desc =\n\t      (struct hal_reo_dest_ring *)ath11k_hal_srng_dst_get_next_entry(ab,\n\t\t\t\t\t\t\t\t\t     srng))) {\n\t\tcookie = FIELD_GET(BUFFER_ADDR_INFO1_SW_COOKIE,\n\t\t\t\t   desc->buf_addr_info.info1);\n\t\tbuf_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_BUF_ID,\n\t\t\t\t   cookie);\n\t\tmac_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_PDEV_ID, cookie);\n\n\t\tif (unlikely(buf_id == 0))\n\t\t\tcontinue;\n\n\t\tar = ab->pdevs[mac_id].ar;\n\t\trx_ring = &ar->dp.rx_refill_buf_ring;\n\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\tmsdu = idr_find(&rx_ring->bufs_idr, buf_id);\n\t\tif (unlikely(!msdu)) {\n\t\t\tath11k_warn(ab, \"frame rx with invalid buf_id %d\\n\",\n\t\t\t\t    buf_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\n\t\trxcb = ATH11K_SKB_RXCB(msdu);\n\t\tdma_unmap_single(ab->dev, rxcb->paddr,\n\t\t\t\t msdu->len + skb_tailroom(msdu),\n\t\t\t\t DMA_FROM_DEVICE);\n\n\t\tnum_buffs_reaped[mac_id]++;\n\n\t\tpush_reason = FIELD_GET(HAL_REO_DEST_RING_INFO0_PUSH_REASON,\n\t\t\t\t\tdesc->info0);\n\t\tif (unlikely(push_reason !=\n\t\t\t     HAL_REO_DEST_RING_PUSH_REASON_ROUTING_INSTRUCTION)) {\n\t\t\tdev_kfree_skb_any(msdu);\n\t\t\tab->soc_stats.hal_reo_error[dp->reo_dst_ring[ring_id].ring_id]++;\n\t\t\tcontinue;\n\t\t}\n\n\t\trxcb->is_first_msdu = !!(desc->rx_msdu_info.info0 &\n\t\t\t\t\t RX_MSDU_DESC_INFO0_FIRST_MSDU_IN_MPDU);\n\t\trxcb->is_last_msdu = !!(desc->rx_msdu_info.info0 &\n\t\t\t\t\tRX_MSDU_DESC_INFO0_LAST_MSDU_IN_MPDU);\n\t\trxcb->is_continuation = !!(desc->rx_msdu_info.info0 &\n\t\t\t\t\t   RX_MSDU_DESC_INFO0_MSDU_CONTINUATION);\n\t\trxcb->peer_id = FIELD_GET(RX_MPDU_DESC_META_DATA_PEER_ID,\n\t\t\t\t\t  desc->rx_mpdu_info.meta_data);\n\t\trxcb->seq_no = FIELD_GET(RX_MPDU_DESC_INFO0_SEQ_NUM,\n\t\t\t\t\t desc->rx_mpdu_info.info0);\n\t\trxcb->tid = FIELD_GET(HAL_REO_DEST_RING_INFO0_RX_QUEUE_NUM,\n\t\t\t\t      desc->info0);\n\n\t\trxcb->mac_id = mac_id;\n\t\t__skb_queue_tail(&msdu_list[mac_id], msdu);\n\n\t\tif (rxcb->is_continuation) {\n\t\t\tdone = false;\n\t\t} else {\n\t\t\ttotal_msdu_reaped++;\n\t\t\tdone = true;\n\t\t}\n\n\t\tif (total_msdu_reaped >= budget)\n\t\t\tbreak;\n\t}\n\n\t \n\tif (unlikely(!done && ath11k_hal_srng_dst_num_free(ab, srng, true))) {\n\t\tath11k_hal_srng_access_end(ab, srng);\n\t\tgoto try_again;\n\t}\n\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\tif (unlikely(!total_msdu_reaped))\n\t\tgoto exit;\n\n\tfor (i = 0; i < ab->num_radios; i++) {\n\t\tif (!num_buffs_reaped[i])\n\t\t\tcontinue;\n\n\t\tath11k_dp_rx_process_received_packets(ab, napi, &msdu_list[i], i);\n\n\t\tar = ab->pdevs[i].ar;\n\t\trx_ring = &ar->dp.rx_refill_buf_ring;\n\n\t\tath11k_dp_rxbufs_replenish(ab, i, rx_ring, num_buffs_reaped[i],\n\t\t\t\t\t   ab->hw_params.hal_params->rx_buf_rbm);\n\t}\nexit:\n\treturn total_msdu_reaped;\n}\n\nstatic void ath11k_dp_rx_update_peer_stats(struct ath11k_sta *arsta,\n\t\t\t\t\t   struct hal_rx_mon_ppdu_info *ppdu_info)\n{\n\tstruct ath11k_rx_peer_stats *rx_stats = arsta->rx_stats;\n\tu32 num_msdu;\n\tint i;\n\n\tif (!rx_stats)\n\t\treturn;\n\n\tarsta->rssi_comb = ppdu_info->rssi_comb;\n\tewma_avg_rssi_add(&arsta->avg_rssi, ppdu_info->rssi_comb);\n\n\tnum_msdu = ppdu_info->tcp_msdu_count + ppdu_info->tcp_ack_msdu_count +\n\t\t   ppdu_info->udp_msdu_count + ppdu_info->other_msdu_count;\n\n\trx_stats->num_msdu += num_msdu;\n\trx_stats->tcp_msdu_count += ppdu_info->tcp_msdu_count +\n\t\t\t\t    ppdu_info->tcp_ack_msdu_count;\n\trx_stats->udp_msdu_count += ppdu_info->udp_msdu_count;\n\trx_stats->other_msdu_count += ppdu_info->other_msdu_count;\n\n\tif (ppdu_info->preamble_type == HAL_RX_PREAMBLE_11A ||\n\t    ppdu_info->preamble_type == HAL_RX_PREAMBLE_11B) {\n\t\tppdu_info->nss = 1;\n\t\tppdu_info->mcs = HAL_RX_MAX_MCS;\n\t\tppdu_info->tid = IEEE80211_NUM_TIDS;\n\t}\n\n\tif (ppdu_info->nss > 0 && ppdu_info->nss <= HAL_RX_MAX_NSS)\n\t\trx_stats->nss_count[ppdu_info->nss - 1] += num_msdu;\n\n\tif (ppdu_info->mcs <= HAL_RX_MAX_MCS)\n\t\trx_stats->mcs_count[ppdu_info->mcs] += num_msdu;\n\n\tif (ppdu_info->gi < HAL_RX_GI_MAX)\n\t\trx_stats->gi_count[ppdu_info->gi] += num_msdu;\n\n\tif (ppdu_info->bw < HAL_RX_BW_MAX)\n\t\trx_stats->bw_count[ppdu_info->bw] += num_msdu;\n\n\tif (ppdu_info->ldpc < HAL_RX_SU_MU_CODING_MAX)\n\t\trx_stats->coding_count[ppdu_info->ldpc] += num_msdu;\n\n\tif (ppdu_info->tid <= IEEE80211_NUM_TIDS)\n\t\trx_stats->tid_count[ppdu_info->tid] += num_msdu;\n\n\tif (ppdu_info->preamble_type < HAL_RX_PREAMBLE_MAX)\n\t\trx_stats->pream_cnt[ppdu_info->preamble_type] += num_msdu;\n\n\tif (ppdu_info->reception_type < HAL_RX_RECEPTION_TYPE_MAX)\n\t\trx_stats->reception_type[ppdu_info->reception_type] += num_msdu;\n\n\tif (ppdu_info->is_stbc)\n\t\trx_stats->stbc_count += num_msdu;\n\n\tif (ppdu_info->beamformed)\n\t\trx_stats->beamformed_count += num_msdu;\n\n\tif (ppdu_info->num_mpdu_fcs_ok > 1)\n\t\trx_stats->ampdu_msdu_count += num_msdu;\n\telse\n\t\trx_stats->non_ampdu_msdu_count += num_msdu;\n\n\trx_stats->num_mpdu_fcs_ok += ppdu_info->num_mpdu_fcs_ok;\n\trx_stats->num_mpdu_fcs_err += ppdu_info->num_mpdu_fcs_err;\n\trx_stats->dcm_count += ppdu_info->dcm;\n\trx_stats->ru_alloc_cnt[ppdu_info->ru_alloc] += num_msdu;\n\n\tarsta->rssi_comb = ppdu_info->rssi_comb;\n\n\tBUILD_BUG_ON(ARRAY_SIZE(arsta->chain_signal) >\n\t\t\t     ARRAY_SIZE(ppdu_info->rssi_chain_pri20));\n\n\tfor (i = 0; i < ARRAY_SIZE(arsta->chain_signal); i++)\n\t\tarsta->chain_signal[i] = ppdu_info->rssi_chain_pri20[i];\n\n\trx_stats->rx_duration += ppdu_info->rx_duration;\n\tarsta->rx_duration = rx_stats->rx_duration;\n}\n\nstatic struct sk_buff *ath11k_dp_rx_alloc_mon_status_buf(struct ath11k_base *ab,\n\t\t\t\t\t\t\t struct dp_rxdma_ring *rx_ring,\n\t\t\t\t\t\t\t int *buf_id)\n{\n\tstruct sk_buff *skb;\n\tdma_addr_t paddr;\n\n\tskb = dev_alloc_skb(DP_RX_BUFFER_SIZE +\n\t\t\t    DP_RX_BUFFER_ALIGN_SIZE);\n\n\tif (!skb)\n\t\tgoto fail_alloc_skb;\n\n\tif (!IS_ALIGNED((unsigned long)skb->data,\n\t\t\tDP_RX_BUFFER_ALIGN_SIZE)) {\n\t\tskb_pull(skb, PTR_ALIGN(skb->data, DP_RX_BUFFER_ALIGN_SIZE) -\n\t\t\t skb->data);\n\t}\n\n\tpaddr = dma_map_single(ab->dev, skb->data,\n\t\t\t       skb->len + skb_tailroom(skb),\n\t\t\t       DMA_FROM_DEVICE);\n\tif (unlikely(dma_mapping_error(ab->dev, paddr)))\n\t\tgoto fail_free_skb;\n\n\tspin_lock_bh(&rx_ring->idr_lock);\n\t*buf_id = idr_alloc(&rx_ring->bufs_idr, skb, 0,\n\t\t\t    rx_ring->bufs_max, GFP_ATOMIC);\n\tspin_unlock_bh(&rx_ring->idr_lock);\n\tif (*buf_id < 0)\n\t\tgoto fail_dma_unmap;\n\n\tATH11K_SKB_RXCB(skb)->paddr = paddr;\n\treturn skb;\n\nfail_dma_unmap:\n\tdma_unmap_single(ab->dev, paddr, skb->len + skb_tailroom(skb),\n\t\t\t DMA_FROM_DEVICE);\nfail_free_skb:\n\tdev_kfree_skb_any(skb);\nfail_alloc_skb:\n\treturn NULL;\n}\n\nint ath11k_dp_rx_mon_status_bufs_replenish(struct ath11k_base *ab, int mac_id,\n\t\t\t\t\t   struct dp_rxdma_ring *rx_ring,\n\t\t\t\t\t   int req_entries,\n\t\t\t\t\t   enum hal_rx_buf_return_buf_manager mgr)\n{\n\tstruct hal_srng *srng;\n\tu32 *desc;\n\tstruct sk_buff *skb;\n\tint num_free;\n\tint num_remain;\n\tint buf_id;\n\tu32 cookie;\n\tdma_addr_t paddr;\n\n\treq_entries = min(req_entries, rx_ring->bufs_max);\n\n\tsrng = &ab->hal.srng_list[rx_ring->refill_buf_ring.ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\tnum_free = ath11k_hal_srng_src_num_free(ab, srng, true);\n\n\treq_entries = min(num_free, req_entries);\n\tnum_remain = req_entries;\n\n\twhile (num_remain > 0) {\n\t\tskb = ath11k_dp_rx_alloc_mon_status_buf(ab, rx_ring,\n\t\t\t\t\t\t\t&buf_id);\n\t\tif (!skb)\n\t\t\tbreak;\n\t\tpaddr = ATH11K_SKB_RXCB(skb)->paddr;\n\n\t\tdesc = ath11k_hal_srng_src_get_next_entry(ab, srng);\n\t\tif (!desc)\n\t\t\tgoto fail_desc_get;\n\n\t\tcookie = FIELD_PREP(DP_RXDMA_BUF_COOKIE_PDEV_ID, mac_id) |\n\t\t\t FIELD_PREP(DP_RXDMA_BUF_COOKIE_BUF_ID, buf_id);\n\n\t\tnum_remain--;\n\n\t\tath11k_hal_rx_buf_addr_info_set(desc, paddr, cookie, mgr);\n\t}\n\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\treturn req_entries - num_remain;\n\nfail_desc_get:\n\tspin_lock_bh(&rx_ring->idr_lock);\n\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\tspin_unlock_bh(&rx_ring->idr_lock);\n\tdma_unmap_single(ab->dev, paddr, skb->len + skb_tailroom(skb),\n\t\t\t DMA_FROM_DEVICE);\n\tdev_kfree_skb_any(skb);\n\tath11k_hal_srng_access_end(ab, srng);\n\tspin_unlock_bh(&srng->lock);\n\n\treturn req_entries - num_remain;\n}\n\n#define ATH11K_DP_RX_FULL_MON_PPDU_ID_WRAP 32535\n\nstatic void\nath11k_dp_rx_mon_update_status_buf_state(struct ath11k_mon_data *pmon,\n\t\t\t\t\t struct hal_tlv_hdr *tlv)\n{\n\tstruct hal_rx_ppdu_start *ppdu_start;\n\tu16 ppdu_id_diff, ppdu_id, tlv_len;\n\tu8 *ptr;\n\n\t \n\ttlv_len = FIELD_GET(HAL_TLV_HDR_LEN, tlv->tl);\n\tptr = (u8 *)tlv;\n\tptr += sizeof(*tlv) + tlv_len;\n\ttlv = (struct hal_tlv_hdr *)ptr;\n\n\tif (FIELD_GET(HAL_TLV_HDR_TAG, tlv->tl) != HAL_RX_PPDU_START)\n\t\treturn;\n\n\tptr += sizeof(*tlv);\n\tppdu_start = (struct hal_rx_ppdu_start *)ptr;\n\tppdu_id = FIELD_GET(HAL_RX_PPDU_START_INFO0_PPDU_ID,\n\t\t\t    __le32_to_cpu(ppdu_start->info0));\n\n\tif (pmon->sw_mon_entries.ppdu_id < ppdu_id) {\n\t\tpmon->buf_state = DP_MON_STATUS_LEAD;\n\t\tppdu_id_diff = ppdu_id - pmon->sw_mon_entries.ppdu_id;\n\t\tif (ppdu_id_diff > ATH11K_DP_RX_FULL_MON_PPDU_ID_WRAP)\n\t\t\tpmon->buf_state = DP_MON_STATUS_LAG;\n\t} else if (pmon->sw_mon_entries.ppdu_id > ppdu_id) {\n\t\tpmon->buf_state = DP_MON_STATUS_LAG;\n\t\tppdu_id_diff = pmon->sw_mon_entries.ppdu_id - ppdu_id;\n\t\tif (ppdu_id_diff > ATH11K_DP_RX_FULL_MON_PPDU_ID_WRAP)\n\t\t\tpmon->buf_state = DP_MON_STATUS_LEAD;\n\t}\n}\n\nstatic int ath11k_dp_rx_reap_mon_status_ring(struct ath11k_base *ab, int mac_id,\n\t\t\t\t\t     int *budget, struct sk_buff_head *skb_list)\n{\n\tstruct ath11k *ar;\n\tconst struct ath11k_hw_hal_params *hal_params;\n\tstruct ath11k_pdev_dp *dp;\n\tstruct dp_rxdma_ring *rx_ring;\n\tstruct ath11k_mon_data *pmon;\n\tstruct hal_srng *srng;\n\tvoid *rx_mon_status_desc;\n\tstruct sk_buff *skb;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tstruct hal_tlv_hdr *tlv;\n\tu32 cookie;\n\tint buf_id, srng_id;\n\tdma_addr_t paddr;\n\tu8 rbm;\n\tint num_buffs_reaped = 0;\n\n\tar = ab->pdevs[ath11k_hw_mac_id_to_pdev_id(&ab->hw_params, mac_id)].ar;\n\tdp = &ar->dp;\n\tpmon = &dp->mon_data;\n\tsrng_id = ath11k_hw_mac_id_to_srng_id(&ab->hw_params, mac_id);\n\trx_ring = &dp->rx_mon_status_refill_ring[srng_id];\n\n\tsrng = &ab->hal.srng_list[rx_ring->refill_buf_ring.ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\twhile (*budget) {\n\t\t*budget -= 1;\n\t\trx_mon_status_desc =\n\t\t\tath11k_hal_srng_src_peek(ab, srng);\n\t\tif (!rx_mon_status_desc) {\n\t\t\tpmon->buf_state = DP_MON_STATUS_REPLINISH;\n\t\t\tbreak;\n\t\t}\n\n\t\tath11k_hal_rx_buf_addr_info_get(rx_mon_status_desc, &paddr,\n\t\t\t\t\t\t&cookie, &rbm);\n\t\tif (paddr) {\n\t\t\tbuf_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_BUF_ID, cookie);\n\n\t\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\t\tskb = idr_find(&rx_ring->bufs_idr, buf_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\n\t\t\tif (!skb) {\n\t\t\t\tath11k_warn(ab, \"rx monitor status with invalid buf_id %d\\n\",\n\t\t\t\t\t    buf_id);\n\t\t\t\tpmon->buf_state = DP_MON_STATUS_REPLINISH;\n\t\t\t\tgoto move_next;\n\t\t\t}\n\n\t\t\trxcb = ATH11K_SKB_RXCB(skb);\n\n\t\t\tdma_sync_single_for_cpu(ab->dev, rxcb->paddr,\n\t\t\t\t\t\tskb->len + skb_tailroom(skb),\n\t\t\t\t\t\tDMA_FROM_DEVICE);\n\n\t\t\ttlv = (struct hal_tlv_hdr *)skb->data;\n\t\t\tif (FIELD_GET(HAL_TLV_HDR_TAG, tlv->tl) !=\n\t\t\t\t\tHAL_RX_STATUS_BUFFER_DONE) {\n\t\t\t\tath11k_warn(ab, \"mon status DONE not set %lx, buf_id %d\\n\",\n\t\t\t\t\t    FIELD_GET(HAL_TLV_HDR_TAG,\n\t\t\t\t\t\t      tlv->tl), buf_id);\n\t\t\t\t \n\t\t\t\tpmon->buf_state = DP_MON_STATUS_NO_DMA;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\t\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\t\tif (ab->hw_params.full_monitor_mode) {\n\t\t\t\tath11k_dp_rx_mon_update_status_buf_state(pmon, tlv);\n\t\t\t\tif (paddr == pmon->mon_status_paddr)\n\t\t\t\t\tpmon->buf_state = DP_MON_STATUS_MATCH;\n\t\t\t}\n\n\t\t\tdma_unmap_single(ab->dev, rxcb->paddr,\n\t\t\t\t\t skb->len + skb_tailroom(skb),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\n\t\t\t__skb_queue_tail(skb_list, skb);\n\t\t} else {\n\t\t\tpmon->buf_state = DP_MON_STATUS_REPLINISH;\n\t\t}\nmove_next:\n\t\tskb = ath11k_dp_rx_alloc_mon_status_buf(ab, rx_ring,\n\t\t\t\t\t\t\t&buf_id);\n\n\t\tif (!skb) {\n\t\t\thal_params = ab->hw_params.hal_params;\n\t\t\tath11k_hal_rx_buf_addr_info_set(rx_mon_status_desc, 0, 0,\n\t\t\t\t\t\t\thal_params->rx_buf_rbm);\n\t\t\tnum_buffs_reaped++;\n\t\t\tbreak;\n\t\t}\n\t\trxcb = ATH11K_SKB_RXCB(skb);\n\n\t\tcookie = FIELD_PREP(DP_RXDMA_BUF_COOKIE_PDEV_ID, mac_id) |\n\t\t\t FIELD_PREP(DP_RXDMA_BUF_COOKIE_BUF_ID, buf_id);\n\n\t\tath11k_hal_rx_buf_addr_info_set(rx_mon_status_desc, rxcb->paddr,\n\t\t\t\t\t\tcookie,\n\t\t\t\t\t\tab->hw_params.hal_params->rx_buf_rbm);\n\t\tath11k_hal_srng_src_get_next_entry(ab, srng);\n\t\tnum_buffs_reaped++;\n\t}\n\tath11k_hal_srng_access_end(ab, srng);\n\tspin_unlock_bh(&srng->lock);\n\n\treturn num_buffs_reaped;\n}\n\nstatic void ath11k_dp_rx_frag_timer(struct timer_list *timer)\n{\n\tstruct dp_rx_tid *rx_tid = from_timer(rx_tid, timer, frag_timer);\n\n\tspin_lock_bh(&rx_tid->ab->base_lock);\n\tif (rx_tid->last_frag_no &&\n\t    rx_tid->rx_frag_bitmap == GENMASK(rx_tid->last_frag_no, 0)) {\n\t\tspin_unlock_bh(&rx_tid->ab->base_lock);\n\t\treturn;\n\t}\n\tath11k_dp_rx_frags_cleanup(rx_tid, true);\n\tspin_unlock_bh(&rx_tid->ab->base_lock);\n}\n\nint ath11k_peer_rx_frag_setup(struct ath11k *ar, const u8 *peer_mac, int vdev_id)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct crypto_shash *tfm;\n\tstruct ath11k_peer *peer;\n\tstruct dp_rx_tid *rx_tid;\n\tint i;\n\n\ttfm = crypto_alloc_shash(\"michael_mic\", 0, 0);\n\tif (IS_ERR(tfm)) {\n\t\tath11k_warn(ab, \"failed to allocate michael_mic shash: %ld\\n\",\n\t\t\t    PTR_ERR(tfm));\n\t\treturn PTR_ERR(tfm);\n\t}\n\n\tspin_lock_bh(&ab->base_lock);\n\n\tpeer = ath11k_peer_find(ab, vdev_id, peer_mac);\n\tif (!peer) {\n\t\tath11k_warn(ab, \"failed to find the peer to set up fragment info\\n\");\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\tcrypto_free_shash(tfm);\n\t\treturn -ENOENT;\n\t}\n\n\tfor (i = 0; i <= IEEE80211_NUM_TIDS; i++) {\n\t\trx_tid = &peer->rx_tid[i];\n\t\trx_tid->ab = ab;\n\t\ttimer_setup(&rx_tid->frag_timer, ath11k_dp_rx_frag_timer, 0);\n\t\tskb_queue_head_init(&rx_tid->rx_frags);\n\t}\n\n\tpeer->tfm_mmic = tfm;\n\tpeer->dp_setup_done = true;\n\tspin_unlock_bh(&ab->base_lock);\n\n\treturn 0;\n}\n\nstatic int ath11k_dp_rx_h_michael_mic(struct crypto_shash *tfm, u8 *key,\n\t\t\t\t      struct ieee80211_hdr *hdr, u8 *data,\n\t\t\t\t      size_t data_len, u8 *mic)\n{\n\tSHASH_DESC_ON_STACK(desc, tfm);\n\tu8 mic_hdr[16] = {0};\n\tu8 tid = 0;\n\tint ret;\n\n\tif (!tfm)\n\t\treturn -EINVAL;\n\n\tdesc->tfm = tfm;\n\n\tret = crypto_shash_setkey(tfm, key, 8);\n\tif (ret)\n\t\tgoto out;\n\n\tret = crypto_shash_init(desc);\n\tif (ret)\n\t\tgoto out;\n\n\t \n\tmemcpy(mic_hdr, ieee80211_get_DA(hdr), ETH_ALEN);\n\tmemcpy(mic_hdr + ETH_ALEN, ieee80211_get_SA(hdr), ETH_ALEN);\n\tif (ieee80211_is_data_qos(hdr->frame_control))\n\t\ttid = ieee80211_get_tid(hdr);\n\tmic_hdr[12] = tid;\n\n\tret = crypto_shash_update(desc, mic_hdr, 16);\n\tif (ret)\n\t\tgoto out;\n\tret = crypto_shash_update(desc, data, data_len);\n\tif (ret)\n\t\tgoto out;\n\tret = crypto_shash_final(desc, mic);\nout:\n\tshash_desc_zero(desc);\n\treturn ret;\n}\n\nstatic int ath11k_dp_rx_h_verify_tkip_mic(struct ath11k *ar, struct ath11k_peer *peer,\n\t\t\t\t\t  struct sk_buff *msdu)\n{\n\tstruct hal_rx_desc *rx_desc = (struct hal_rx_desc *)msdu->data;\n\tstruct ieee80211_rx_status *rxs = IEEE80211_SKB_RXCB(msdu);\n\tstruct ieee80211_key_conf *key_conf;\n\tstruct ieee80211_hdr *hdr;\n\tu8 mic[IEEE80211_CCMP_MIC_LEN];\n\tint head_len, tail_len, ret;\n\tsize_t data_len;\n\tu32 hdr_len, hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\tu8 *key, *data;\n\tu8 key_idx;\n\n\tif (ath11k_dp_rx_h_mpdu_start_enctype(ar->ab, rx_desc) !=\n\t    HAL_ENCRYPT_TYPE_TKIP_MIC)\n\t\treturn 0;\n\n\thdr = (struct ieee80211_hdr *)(msdu->data + hal_rx_desc_sz);\n\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\thead_len = hdr_len + hal_rx_desc_sz + IEEE80211_TKIP_IV_LEN;\n\ttail_len = IEEE80211_CCMP_MIC_LEN + IEEE80211_TKIP_ICV_LEN + FCS_LEN;\n\n\tif (!is_multicast_ether_addr(hdr->addr1))\n\t\tkey_idx = peer->ucast_keyidx;\n\telse\n\t\tkey_idx = peer->mcast_keyidx;\n\n\tkey_conf = peer->keys[key_idx];\n\n\tdata = msdu->data + head_len;\n\tdata_len = msdu->len - head_len - tail_len;\n\tkey = &key_conf->key[NL80211_TKIP_DATA_OFFSET_RX_MIC_KEY];\n\n\tret = ath11k_dp_rx_h_michael_mic(peer->tfm_mmic, key, hdr, data, data_len, mic);\n\tif (ret || memcmp(mic, data + data_len, IEEE80211_CCMP_MIC_LEN))\n\t\tgoto mic_fail;\n\n\treturn 0;\n\nmic_fail:\n\t(ATH11K_SKB_RXCB(msdu))->is_first_msdu = true;\n\t(ATH11K_SKB_RXCB(msdu))->is_last_msdu = true;\n\n\trxs->flag |= RX_FLAG_MMIC_ERROR | RX_FLAG_MMIC_STRIPPED |\n\t\t    RX_FLAG_IV_STRIPPED | RX_FLAG_DECRYPTED;\n\tskb_pull(msdu, hal_rx_desc_sz);\n\n\tath11k_dp_rx_h_ppdu(ar, rx_desc, rxs);\n\tath11k_dp_rx_h_undecap(ar, msdu, rx_desc,\n\t\t\t       HAL_ENCRYPT_TYPE_TKIP_MIC, rxs, true);\n\tieee80211_rx(ar->hw, msdu);\n\treturn -EINVAL;\n}\n\nstatic void ath11k_dp_rx_h_undecap_frag(struct ath11k *ar, struct sk_buff *msdu,\n\t\t\t\t\tenum hal_encrypt_type enctype, u32 flags)\n{\n\tstruct ieee80211_hdr *hdr;\n\tsize_t hdr_len;\n\tsize_t crypto_len;\n\tu32 hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\tif (!flags)\n\t\treturn;\n\n\thdr = (struct ieee80211_hdr *)(msdu->data + hal_rx_desc_sz);\n\n\tif (flags & RX_FLAG_MIC_STRIPPED)\n\t\tskb_trim(msdu, msdu->len -\n\t\t\t ath11k_dp_rx_crypto_mic_len(ar, enctype));\n\n\tif (flags & RX_FLAG_ICV_STRIPPED)\n\t\tskb_trim(msdu, msdu->len -\n\t\t\t ath11k_dp_rx_crypto_icv_len(ar, enctype));\n\n\tif (flags & RX_FLAG_IV_STRIPPED) {\n\t\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\t\tcrypto_len = ath11k_dp_rx_crypto_param_len(ar, enctype);\n\n\t\tmemmove((void *)msdu->data + hal_rx_desc_sz + crypto_len,\n\t\t\t(void *)msdu->data + hal_rx_desc_sz, hdr_len);\n\t\tskb_pull(msdu, crypto_len);\n\t}\n}\n\nstatic int ath11k_dp_rx_h_defrag(struct ath11k *ar,\n\t\t\t\t struct ath11k_peer *peer,\n\t\t\t\t struct dp_rx_tid *rx_tid,\n\t\t\t\t struct sk_buff **defrag_skb)\n{\n\tstruct hal_rx_desc *rx_desc;\n\tstruct sk_buff *skb, *first_frag, *last_frag;\n\tstruct ieee80211_hdr *hdr;\n\tstruct rx_attention *rx_attention;\n\tenum hal_encrypt_type enctype;\n\tbool is_decrypted = false;\n\tint msdu_len = 0;\n\tint extra_space;\n\tu32 flags, hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\tfirst_frag = skb_peek(&rx_tid->rx_frags);\n\tlast_frag = skb_peek_tail(&rx_tid->rx_frags);\n\n\tskb_queue_walk(&rx_tid->rx_frags, skb) {\n\t\tflags = 0;\n\t\trx_desc = (struct hal_rx_desc *)skb->data;\n\t\thdr = (struct ieee80211_hdr *)(skb->data + hal_rx_desc_sz);\n\n\t\tenctype = ath11k_dp_rx_h_mpdu_start_enctype(ar->ab, rx_desc);\n\t\tif (enctype != HAL_ENCRYPT_TYPE_OPEN) {\n\t\t\trx_attention = ath11k_dp_rx_get_attention(ar->ab, rx_desc);\n\t\t\tis_decrypted = ath11k_dp_rx_h_attn_is_decrypted(rx_attention);\n\t\t}\n\n\t\tif (is_decrypted) {\n\t\t\tif (skb != first_frag)\n\t\t\t\tflags |=  RX_FLAG_IV_STRIPPED;\n\t\t\tif (skb != last_frag)\n\t\t\t\tflags |= RX_FLAG_ICV_STRIPPED |\n\t\t\t\t\t RX_FLAG_MIC_STRIPPED;\n\t\t}\n\n\t\t \n\t\tif (skb != last_frag)\n\t\t\tskb_trim(skb, skb->len - FCS_LEN);\n\t\tath11k_dp_rx_h_undecap_frag(ar, skb, enctype, flags);\n\n\t\tif (skb != first_frag)\n\t\t\tskb_pull(skb, hal_rx_desc_sz +\n\t\t\t\t      ieee80211_hdrlen(hdr->frame_control));\n\t\tmsdu_len += skb->len;\n\t}\n\n\textra_space = msdu_len - (DP_RX_BUFFER_SIZE + skb_tailroom(first_frag));\n\tif (extra_space > 0 &&\n\t    (pskb_expand_head(first_frag, 0, extra_space, GFP_ATOMIC) < 0))\n\t\treturn -ENOMEM;\n\n\t__skb_unlink(first_frag, &rx_tid->rx_frags);\n\twhile ((skb = __skb_dequeue(&rx_tid->rx_frags))) {\n\t\tskb_put_data(first_frag, skb->data, skb->len);\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\thdr = (struct ieee80211_hdr *)(first_frag->data + hal_rx_desc_sz);\n\thdr->frame_control &= ~__cpu_to_le16(IEEE80211_FCTL_MOREFRAGS);\n\tATH11K_SKB_RXCB(first_frag)->is_frag = 1;\n\n\tif (ath11k_dp_rx_h_verify_tkip_mic(ar, peer, first_frag))\n\t\tfirst_frag = NULL;\n\n\t*defrag_skb = first_frag;\n\treturn 0;\n}\n\nstatic int ath11k_dp_rx_h_defrag_reo_reinject(struct ath11k *ar, struct dp_rx_tid *rx_tid,\n\t\t\t\t\t      struct sk_buff *defrag_skb)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct dp_rxdma_ring *rx_refill_ring = &dp->rx_refill_buf_ring;\n\tstruct hal_rx_desc *rx_desc = (struct hal_rx_desc *)defrag_skb->data;\n\tstruct hal_reo_entrance_ring *reo_ent_ring;\n\tstruct hal_reo_dest_ring *reo_dest_ring;\n\tstruct dp_link_desc_bank *link_desc_banks;\n\tstruct hal_rx_msdu_link *msdu_link;\n\tstruct hal_rx_msdu_details *msdu0;\n\tstruct hal_srng *srng;\n\tdma_addr_t paddr;\n\tu32 desc_bank, msdu_info, mpdu_info;\n\tu32 dst_idx, cookie, hal_rx_desc_sz;\n\tint ret, buf_id;\n\n\thal_rx_desc_sz = ab->hw_params.hal_desc_sz;\n\tlink_desc_banks = ab->dp.link_desc_banks;\n\treo_dest_ring = rx_tid->dst_ring_desc;\n\n\tath11k_hal_rx_reo_ent_paddr_get(ab, reo_dest_ring, &paddr, &desc_bank);\n\tmsdu_link = (struct hal_rx_msdu_link *)(link_desc_banks[desc_bank].vaddr +\n\t\t\t(paddr - link_desc_banks[desc_bank].paddr));\n\tmsdu0 = &msdu_link->msdu_link[0];\n\tdst_idx = FIELD_GET(RX_MSDU_DESC_INFO0_REO_DEST_IND, msdu0->rx_msdu_info.info0);\n\tmemset(msdu0, 0, sizeof(*msdu0));\n\n\tmsdu_info = FIELD_PREP(RX_MSDU_DESC_INFO0_FIRST_MSDU_IN_MPDU, 1) |\n\t\t    FIELD_PREP(RX_MSDU_DESC_INFO0_LAST_MSDU_IN_MPDU, 1) |\n\t\t    FIELD_PREP(RX_MSDU_DESC_INFO0_MSDU_CONTINUATION, 0) |\n\t\t    FIELD_PREP(RX_MSDU_DESC_INFO0_MSDU_LENGTH,\n\t\t\t       defrag_skb->len - hal_rx_desc_sz) |\n\t\t    FIELD_PREP(RX_MSDU_DESC_INFO0_REO_DEST_IND, dst_idx) |\n\t\t    FIELD_PREP(RX_MSDU_DESC_INFO0_VALID_SA, 1) |\n\t\t    FIELD_PREP(RX_MSDU_DESC_INFO0_VALID_DA, 1);\n\tmsdu0->rx_msdu_info.info0 = msdu_info;\n\n\t \n\tath11k_dp_rxdesc_set_msdu_len(ab, rx_desc, defrag_skb->len - hal_rx_desc_sz);\n\n\tpaddr = dma_map_single(ab->dev, defrag_skb->data,\n\t\t\t       defrag_skb->len + skb_tailroom(defrag_skb),\n\t\t\t       DMA_TO_DEVICE);\n\tif (dma_mapping_error(ab->dev, paddr))\n\t\treturn -ENOMEM;\n\n\tspin_lock_bh(&rx_refill_ring->idr_lock);\n\tbuf_id = idr_alloc(&rx_refill_ring->bufs_idr, defrag_skb, 0,\n\t\t\t   rx_refill_ring->bufs_max * 3, GFP_ATOMIC);\n\tspin_unlock_bh(&rx_refill_ring->idr_lock);\n\tif (buf_id < 0) {\n\t\tret = -ENOMEM;\n\t\tgoto err_unmap_dma;\n\t}\n\n\tATH11K_SKB_RXCB(defrag_skb)->paddr = paddr;\n\tcookie = FIELD_PREP(DP_RXDMA_BUF_COOKIE_PDEV_ID, dp->mac_id) |\n\t\t FIELD_PREP(DP_RXDMA_BUF_COOKIE_BUF_ID, buf_id);\n\n\tath11k_hal_rx_buf_addr_info_set(msdu0, paddr, cookie,\n\t\t\t\t\tab->hw_params.hal_params->rx_buf_rbm);\n\n\t \n\tsrng = &ab->hal.srng_list[ab->dp.reo_reinject_ring.ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\treo_ent_ring = (struct hal_reo_entrance_ring *)\n\t\t\tath11k_hal_srng_src_get_next_entry(ab, srng);\n\tif (!reo_ent_ring) {\n\t\tath11k_hal_srng_access_end(ab, srng);\n\t\tspin_unlock_bh(&srng->lock);\n\t\tret = -ENOSPC;\n\t\tgoto err_free_idr;\n\t}\n\tmemset(reo_ent_ring, 0, sizeof(*reo_ent_ring));\n\n\tath11k_hal_rx_reo_ent_paddr_get(ab, reo_dest_ring, &paddr, &desc_bank);\n\tath11k_hal_rx_buf_addr_info_set(reo_ent_ring, paddr, desc_bank,\n\t\t\t\t\tHAL_RX_BUF_RBM_WBM_IDLE_DESC_LIST);\n\n\tmpdu_info = FIELD_PREP(RX_MPDU_DESC_INFO0_MSDU_COUNT, 1) |\n\t\t    FIELD_PREP(RX_MPDU_DESC_INFO0_SEQ_NUM, rx_tid->cur_sn) |\n\t\t    FIELD_PREP(RX_MPDU_DESC_INFO0_FRAG_FLAG, 0) |\n\t\t    FIELD_PREP(RX_MPDU_DESC_INFO0_VALID_SA, 1) |\n\t\t    FIELD_PREP(RX_MPDU_DESC_INFO0_VALID_DA, 1) |\n\t\t    FIELD_PREP(RX_MPDU_DESC_INFO0_RAW_MPDU, 1) |\n\t\t    FIELD_PREP(RX_MPDU_DESC_INFO0_VALID_PN, 1);\n\n\treo_ent_ring->rx_mpdu_info.info0 = mpdu_info;\n\treo_ent_ring->rx_mpdu_info.meta_data = reo_dest_ring->rx_mpdu_info.meta_data;\n\treo_ent_ring->queue_addr_lo = reo_dest_ring->queue_addr_lo;\n\treo_ent_ring->info0 = FIELD_PREP(HAL_REO_ENTR_RING_INFO0_QUEUE_ADDR_HI,\n\t\t\t\t\t FIELD_GET(HAL_REO_DEST_RING_INFO0_QUEUE_ADDR_HI,\n\t\t\t\t\t\t   reo_dest_ring->info0)) |\n\t\t\t      FIELD_PREP(HAL_REO_ENTR_RING_INFO0_DEST_IND, dst_idx);\n\tath11k_hal_srng_access_end(ab, srng);\n\tspin_unlock_bh(&srng->lock);\n\n\treturn 0;\n\nerr_free_idr:\n\tspin_lock_bh(&rx_refill_ring->idr_lock);\n\tidr_remove(&rx_refill_ring->bufs_idr, buf_id);\n\tspin_unlock_bh(&rx_refill_ring->idr_lock);\nerr_unmap_dma:\n\tdma_unmap_single(ab->dev, paddr, defrag_skb->len + skb_tailroom(defrag_skb),\n\t\t\t DMA_TO_DEVICE);\n\treturn ret;\n}\n\nstatic int ath11k_dp_rx_h_cmp_frags(struct ath11k *ar,\n\t\t\t\t    struct sk_buff *a, struct sk_buff *b)\n{\n\tint frag1, frag2;\n\n\tfrag1 = ath11k_dp_rx_h_mpdu_start_frag_no(ar->ab, a);\n\tfrag2 = ath11k_dp_rx_h_mpdu_start_frag_no(ar->ab, b);\n\n\treturn frag1 - frag2;\n}\n\nstatic void ath11k_dp_rx_h_sort_frags(struct ath11k *ar,\n\t\t\t\t      struct sk_buff_head *frag_list,\n\t\t\t\t      struct sk_buff *cur_frag)\n{\n\tstruct sk_buff *skb;\n\tint cmp;\n\n\tskb_queue_walk(frag_list, skb) {\n\t\tcmp = ath11k_dp_rx_h_cmp_frags(ar, skb, cur_frag);\n\t\tif (cmp < 0)\n\t\t\tcontinue;\n\t\t__skb_queue_before(frag_list, skb, cur_frag);\n\t\treturn;\n\t}\n\t__skb_queue_tail(frag_list, cur_frag);\n}\n\nstatic u64 ath11k_dp_rx_h_get_pn(struct ath11k *ar, struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr;\n\tu64 pn = 0;\n\tu8 *ehdr;\n\tu32 hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\thdr = (struct ieee80211_hdr *)(skb->data + hal_rx_desc_sz);\n\tehdr = skb->data + hal_rx_desc_sz + ieee80211_hdrlen(hdr->frame_control);\n\n\tpn = ehdr[0];\n\tpn |= (u64)ehdr[1] << 8;\n\tpn |= (u64)ehdr[4] << 16;\n\tpn |= (u64)ehdr[5] << 24;\n\tpn |= (u64)ehdr[6] << 32;\n\tpn |= (u64)ehdr[7] << 40;\n\n\treturn pn;\n}\n\nstatic bool\nath11k_dp_rx_h_defrag_validate_incr_pn(struct ath11k *ar, struct dp_rx_tid *rx_tid)\n{\n\tenum hal_encrypt_type encrypt_type;\n\tstruct sk_buff *first_frag, *skb;\n\tstruct hal_rx_desc *desc;\n\tu64 last_pn;\n\tu64 cur_pn;\n\n\tfirst_frag = skb_peek(&rx_tid->rx_frags);\n\tdesc = (struct hal_rx_desc *)first_frag->data;\n\n\tencrypt_type = ath11k_dp_rx_h_mpdu_start_enctype(ar->ab, desc);\n\tif (encrypt_type != HAL_ENCRYPT_TYPE_CCMP_128 &&\n\t    encrypt_type != HAL_ENCRYPT_TYPE_CCMP_256 &&\n\t    encrypt_type != HAL_ENCRYPT_TYPE_GCMP_128 &&\n\t    encrypt_type != HAL_ENCRYPT_TYPE_AES_GCMP_256)\n\t\treturn true;\n\n\tlast_pn = ath11k_dp_rx_h_get_pn(ar, first_frag);\n\tskb_queue_walk(&rx_tid->rx_frags, skb) {\n\t\tif (skb == first_frag)\n\t\t\tcontinue;\n\n\t\tcur_pn = ath11k_dp_rx_h_get_pn(ar, skb);\n\t\tif (cur_pn != last_pn + 1)\n\t\t\treturn false;\n\t\tlast_pn = cur_pn;\n\t}\n\treturn true;\n}\n\nstatic int ath11k_dp_rx_frag_h_mpdu(struct ath11k *ar,\n\t\t\t\t    struct sk_buff *msdu,\n\t\t\t\t    u32 *ring_desc)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct hal_rx_desc *rx_desc;\n\tstruct ath11k_peer *peer;\n\tstruct dp_rx_tid *rx_tid;\n\tstruct sk_buff *defrag_skb = NULL;\n\tu32 peer_id;\n\tu16 seqno, frag_no;\n\tu8 tid;\n\tint ret = 0;\n\tbool more_frags;\n\tbool is_mcbc;\n\n\trx_desc = (struct hal_rx_desc *)msdu->data;\n\tpeer_id = ath11k_dp_rx_h_mpdu_start_peer_id(ar->ab, rx_desc);\n\ttid = ath11k_dp_rx_h_mpdu_start_tid(ar->ab, rx_desc);\n\tseqno = ath11k_dp_rx_h_mpdu_start_seq_no(ar->ab, rx_desc);\n\tfrag_no = ath11k_dp_rx_h_mpdu_start_frag_no(ar->ab, msdu);\n\tmore_frags = ath11k_dp_rx_h_mpdu_start_more_frags(ar->ab, msdu);\n\tis_mcbc = ath11k_dp_rx_h_attn_is_mcbc(ar->ab, rx_desc);\n\n\t \n\tif (is_mcbc)\n\t\treturn -EINVAL;\n\n\tif (!ath11k_dp_rx_h_mpdu_start_seq_ctrl_valid(ar->ab, rx_desc) ||\n\t    !ath11k_dp_rx_h_mpdu_start_fc_valid(ar->ab, rx_desc) ||\n\t    tid > IEEE80211_NUM_TIDS)\n\t\treturn -EINVAL;\n\n\t \n\tif (WARN_ON_ONCE(!frag_no && !more_frags))\n\t\treturn -EINVAL;\n\n\tspin_lock_bh(&ab->base_lock);\n\tpeer = ath11k_peer_find_by_id(ab, peer_id);\n\tif (!peer) {\n\t\tath11k_warn(ab, \"failed to find the peer to de-fragment received fragment peer_id %d\\n\",\n\t\t\t    peer_id);\n\t\tret = -ENOENT;\n\t\tgoto out_unlock;\n\t}\n\tif (!peer->dp_setup_done) {\n\t\tath11k_warn(ab, \"The peer %pM [%d] has uninitialized datapath\\n\",\n\t\t\t    peer->addr, peer_id);\n\t\tret = -ENOENT;\n\t\tgoto out_unlock;\n\t}\n\n\trx_tid = &peer->rx_tid[tid];\n\n\tif ((!skb_queue_empty(&rx_tid->rx_frags) && seqno != rx_tid->cur_sn) ||\n\t    skb_queue_empty(&rx_tid->rx_frags)) {\n\t\t \n\t\tath11k_dp_rx_frags_cleanup(rx_tid, true);\n\t\trx_tid->cur_sn = seqno;\n\t}\n\n\tif (rx_tid->rx_frag_bitmap & BIT(frag_no)) {\n\t\t \n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tif (!rx_tid->rx_frag_bitmap || (frag_no > __fls(rx_tid->rx_frag_bitmap)))\n\t\t__skb_queue_tail(&rx_tid->rx_frags, msdu);\n\telse\n\t\tath11k_dp_rx_h_sort_frags(ar, &rx_tid->rx_frags, msdu);\n\n\trx_tid->rx_frag_bitmap |= BIT(frag_no);\n\tif (!more_frags)\n\t\trx_tid->last_frag_no = frag_no;\n\n\tif (frag_no == 0) {\n\t\trx_tid->dst_ring_desc = kmemdup(ring_desc,\n\t\t\t\t\t\tsizeof(*rx_tid->dst_ring_desc),\n\t\t\t\t\t\tGFP_ATOMIC);\n\t\tif (!rx_tid->dst_ring_desc) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_unlock;\n\t\t}\n\t} else {\n\t\tath11k_dp_rx_link_desc_return(ab, ring_desc,\n\t\t\t\t\t      HAL_WBM_REL_BM_ACT_PUT_IN_IDLE);\n\t}\n\n\tif (!rx_tid->last_frag_no ||\n\t    rx_tid->rx_frag_bitmap != GENMASK(rx_tid->last_frag_no, 0)) {\n\t\tmod_timer(&rx_tid->frag_timer, jiffies +\n\t\t\t\t\t       ATH11K_DP_RX_FRAGMENT_TIMEOUT_MS);\n\t\tgoto out_unlock;\n\t}\n\n\tspin_unlock_bh(&ab->base_lock);\n\tdel_timer_sync(&rx_tid->frag_timer);\n\tspin_lock_bh(&ab->base_lock);\n\n\tpeer = ath11k_peer_find_by_id(ab, peer_id);\n\tif (!peer)\n\t\tgoto err_frags_cleanup;\n\n\tif (!ath11k_dp_rx_h_defrag_validate_incr_pn(ar, rx_tid))\n\t\tgoto err_frags_cleanup;\n\n\tif (ath11k_dp_rx_h_defrag(ar, peer, rx_tid, &defrag_skb))\n\t\tgoto err_frags_cleanup;\n\n\tif (!defrag_skb)\n\t\tgoto err_frags_cleanup;\n\n\tif (ath11k_dp_rx_h_defrag_reo_reinject(ar, rx_tid, defrag_skb))\n\t\tgoto err_frags_cleanup;\n\n\tath11k_dp_rx_frags_cleanup(rx_tid, false);\n\tgoto out_unlock;\n\nerr_frags_cleanup:\n\tdev_kfree_skb_any(defrag_skb);\n\tath11k_dp_rx_frags_cleanup(rx_tid, true);\nout_unlock:\n\tspin_unlock_bh(&ab->base_lock);\n\treturn ret;\n}\n\nstatic int\nath11k_dp_process_rx_err_buf(struct ath11k *ar, u32 *ring_desc, int buf_id, bool drop)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct dp_rxdma_ring *rx_ring = &dp->rx_refill_buf_ring;\n\tstruct sk_buff *msdu;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tstruct hal_rx_desc *rx_desc;\n\tu8 *hdr_status;\n\tu16 msdu_len;\n\tu32 hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\tspin_lock_bh(&rx_ring->idr_lock);\n\tmsdu = idr_find(&rx_ring->bufs_idr, buf_id);\n\tif (!msdu) {\n\t\tath11k_warn(ar->ab, \"rx err buf with invalid buf_id %d\\n\",\n\t\t\t    buf_id);\n\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\treturn -EINVAL;\n\t}\n\n\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\tspin_unlock_bh(&rx_ring->idr_lock);\n\n\trxcb = ATH11K_SKB_RXCB(msdu);\n\tdma_unmap_single(ar->ab->dev, rxcb->paddr,\n\t\t\t msdu->len + skb_tailroom(msdu),\n\t\t\t DMA_FROM_DEVICE);\n\n\tif (drop) {\n\t\tdev_kfree_skb_any(msdu);\n\t\treturn 0;\n\t}\n\n\trcu_read_lock();\n\tif (!rcu_dereference(ar->ab->pdevs_active[ar->pdev_idx])) {\n\t\tdev_kfree_skb_any(msdu);\n\t\tgoto exit;\n\t}\n\n\tif (test_bit(ATH11K_CAC_RUNNING, &ar->dev_flags)) {\n\t\tdev_kfree_skb_any(msdu);\n\t\tgoto exit;\n\t}\n\n\trx_desc = (struct hal_rx_desc *)msdu->data;\n\tmsdu_len = ath11k_dp_rx_h_msdu_start_msdu_len(ar->ab, rx_desc);\n\tif ((msdu_len + hal_rx_desc_sz) > DP_RX_BUFFER_SIZE) {\n\t\thdr_status = ath11k_dp_rx_h_80211_hdr(ar->ab, rx_desc);\n\t\tath11k_warn(ar->ab, \"invalid msdu leng %u\", msdu_len);\n\t\tath11k_dbg_dump(ar->ab, ATH11K_DBG_DATA, NULL, \"\", hdr_status,\n\t\t\t\tsizeof(struct ieee80211_hdr));\n\t\tath11k_dbg_dump(ar->ab, ATH11K_DBG_DATA, NULL, \"\", rx_desc,\n\t\t\t\tsizeof(struct hal_rx_desc));\n\t\tdev_kfree_skb_any(msdu);\n\t\tgoto exit;\n\t}\n\n\tskb_put(msdu, hal_rx_desc_sz + msdu_len);\n\n\tif (ath11k_dp_rx_frag_h_mpdu(ar, msdu, ring_desc)) {\n\t\tdev_kfree_skb_any(msdu);\n\t\tath11k_dp_rx_link_desc_return(ar->ab, ring_desc,\n\t\t\t\t\t      HAL_WBM_REL_BM_ACT_PUT_IN_IDLE);\n\t}\nexit:\n\trcu_read_unlock();\n\treturn 0;\n}\n\nint ath11k_dp_process_rx_err(struct ath11k_base *ab, struct napi_struct *napi,\n\t\t\t     int budget)\n{\n\tu32 msdu_cookies[HAL_NUM_RX_MSDUS_PER_LINK_DESC];\n\tstruct dp_link_desc_bank *link_desc_banks;\n\tenum hal_rx_buf_return_buf_manager rbm;\n\tint tot_n_bufs_reaped, quota, ret, i;\n\tint n_bufs_reaped[MAX_RADIOS] = {0};\n\tstruct dp_rxdma_ring *rx_ring;\n\tstruct dp_srng *reo_except;\n\tu32 desc_bank, num_msdus;\n\tstruct hal_srng *srng;\n\tstruct ath11k_dp *dp;\n\tvoid *link_desc_va;\n\tint buf_id, mac_id;\n\tstruct ath11k *ar;\n\tdma_addr_t paddr;\n\tu32 *desc;\n\tbool is_frag;\n\tu8 drop = 0;\n\n\ttot_n_bufs_reaped = 0;\n\tquota = budget;\n\n\tdp = &ab->dp;\n\treo_except = &dp->reo_except_ring;\n\tlink_desc_banks = dp->link_desc_banks;\n\n\tsrng = &ab->hal.srng_list[reo_except->ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\twhile (budget &&\n\t       (desc = ath11k_hal_srng_dst_get_next_entry(ab, srng))) {\n\t\tstruct hal_reo_dest_ring *reo_desc = (struct hal_reo_dest_ring *)desc;\n\n\t\tab->soc_stats.err_ring_pkts++;\n\t\tret = ath11k_hal_desc_reo_parse_err(ab, desc, &paddr,\n\t\t\t\t\t\t    &desc_bank);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab, \"failed to parse error reo desc %d\\n\",\n\t\t\t\t    ret);\n\t\t\tcontinue;\n\t\t}\n\t\tlink_desc_va = link_desc_banks[desc_bank].vaddr +\n\t\t\t       (paddr - link_desc_banks[desc_bank].paddr);\n\t\tath11k_hal_rx_msdu_link_info_get(link_desc_va, &num_msdus, msdu_cookies,\n\t\t\t\t\t\t &rbm);\n\t\tif (rbm != HAL_RX_BUF_RBM_WBM_IDLE_DESC_LIST &&\n\t\t    rbm != HAL_RX_BUF_RBM_SW3_BM) {\n\t\t\tab->soc_stats.invalid_rbm++;\n\t\t\tath11k_warn(ab, \"invalid return buffer manager %d\\n\", rbm);\n\t\t\tath11k_dp_rx_link_desc_return(ab, desc,\n\t\t\t\t\t\t      HAL_WBM_REL_BM_ACT_REL_MSDU);\n\t\t\tcontinue;\n\t\t}\n\n\t\tis_frag = !!(reo_desc->rx_mpdu_info.info0 & RX_MPDU_DESC_INFO0_FRAG_FLAG);\n\n\t\t \n\t\tif (!is_frag || num_msdus > 1) {\n\t\t\tdrop = 1;\n\t\t\t \n\t\t\tath11k_dp_rx_link_desc_return(ab, desc,\n\t\t\t\t\t\t      HAL_WBM_REL_BM_ACT_PUT_IN_IDLE);\n\t\t}\n\n\t\tfor (i = 0; i < num_msdus; i++) {\n\t\t\tbuf_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_BUF_ID,\n\t\t\t\t\t   msdu_cookies[i]);\n\n\t\t\tmac_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_PDEV_ID,\n\t\t\t\t\t   msdu_cookies[i]);\n\n\t\t\tar = ab->pdevs[mac_id].ar;\n\n\t\t\tif (!ath11k_dp_process_rx_err_buf(ar, desc, buf_id, drop)) {\n\t\t\t\tn_bufs_reaped[mac_id]++;\n\t\t\t\ttot_n_bufs_reaped++;\n\t\t\t}\n\t\t}\n\n\t\tif (tot_n_bufs_reaped >= quota) {\n\t\t\ttot_n_bufs_reaped = quota;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tbudget = quota - tot_n_bufs_reaped;\n\t}\n\nexit:\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\tfor (i = 0; i <  ab->num_radios; i++) {\n\t\tif (!n_bufs_reaped[i])\n\t\t\tcontinue;\n\n\t\tar = ab->pdevs[i].ar;\n\t\trx_ring = &ar->dp.rx_refill_buf_ring;\n\n\t\tath11k_dp_rxbufs_replenish(ab, i, rx_ring, n_bufs_reaped[i],\n\t\t\t\t\t   ab->hw_params.hal_params->rx_buf_rbm);\n\t}\n\n\treturn tot_n_bufs_reaped;\n}\n\nstatic void ath11k_dp_rx_null_q_desc_sg_drop(struct ath11k *ar,\n\t\t\t\t\t     int msdu_len,\n\t\t\t\t\t     struct sk_buff_head *msdu_list)\n{\n\tstruct sk_buff *skb, *tmp;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tint n_buffs;\n\n\tn_buffs = DIV_ROUND_UP(msdu_len,\n\t\t\t       (DP_RX_BUFFER_SIZE - ar->ab->hw_params.hal_desc_sz));\n\n\tskb_queue_walk_safe(msdu_list, skb, tmp) {\n\t\trxcb = ATH11K_SKB_RXCB(skb);\n\t\tif (rxcb->err_rel_src == HAL_WBM_REL_SRC_MODULE_REO &&\n\t\t    rxcb->err_code == HAL_REO_DEST_RING_ERROR_CODE_DESC_ADDR_ZERO) {\n\t\t\tif (!n_buffs)\n\t\t\t\tbreak;\n\t\t\t__skb_unlink(skb, msdu_list);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tn_buffs--;\n\t\t}\n\t}\n}\n\nstatic int ath11k_dp_rx_h_null_q_desc(struct ath11k *ar, struct sk_buff *msdu,\n\t\t\t\t      struct ieee80211_rx_status *status,\n\t\t\t\t      struct sk_buff_head *msdu_list)\n{\n\tu16 msdu_len;\n\tstruct hal_rx_desc *desc = (struct hal_rx_desc *)msdu->data;\n\tstruct rx_attention *rx_attention;\n\tu8 l3pad_bytes;\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tu32 hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\tmsdu_len = ath11k_dp_rx_h_msdu_start_msdu_len(ar->ab, desc);\n\n\tif (!rxcb->is_frag && ((msdu_len + hal_rx_desc_sz) > DP_RX_BUFFER_SIZE)) {\n\t\t \n\t\tmsdu_len = msdu_len - (DP_RX_BUFFER_SIZE - hal_rx_desc_sz);\n\t\tath11k_dp_rx_null_q_desc_sg_drop(ar, msdu_len, msdu_list);\n\t\treturn -EINVAL;\n\t}\n\n\trx_attention = ath11k_dp_rx_get_attention(ar->ab, desc);\n\tif (!ath11k_dp_rx_h_attn_msdu_done(rx_attention)) {\n\t\tath11k_warn(ar->ab,\n\t\t\t    \"msdu_done bit not set in null_q_des processing\\n\");\n\t\t__skb_queue_purge(msdu_list);\n\t\treturn -EIO;\n\t}\n\n\t \n\n\trxcb->is_first_msdu = ath11k_dp_rx_h_msdu_end_first_msdu(ar->ab, desc);\n\trxcb->is_last_msdu = ath11k_dp_rx_h_msdu_end_last_msdu(ar->ab, desc);\n\n\tif (rxcb->is_frag) {\n\t\tskb_pull(msdu, hal_rx_desc_sz);\n\t} else {\n\t\tl3pad_bytes = ath11k_dp_rx_h_msdu_end_l3pad(ar->ab, desc);\n\n\t\tif ((hal_rx_desc_sz + l3pad_bytes + msdu_len) > DP_RX_BUFFER_SIZE)\n\t\t\treturn -EINVAL;\n\n\t\tskb_put(msdu, hal_rx_desc_sz + l3pad_bytes + msdu_len);\n\t\tskb_pull(msdu, hal_rx_desc_sz + l3pad_bytes);\n\t}\n\tath11k_dp_rx_h_ppdu(ar, desc, status);\n\n\tath11k_dp_rx_h_mpdu(ar, msdu, desc, status);\n\n\trxcb->tid = ath11k_dp_rx_h_mpdu_start_tid(ar->ab, desc);\n\n\t \n\n\treturn 0;\n}\n\nstatic bool ath11k_dp_rx_h_reo_err(struct ath11k *ar, struct sk_buff *msdu,\n\t\t\t\t   struct ieee80211_rx_status *status,\n\t\t\t\t   struct sk_buff_head *msdu_list)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tbool drop = false;\n\n\tar->ab->soc_stats.reo_error[rxcb->err_code]++;\n\n\tswitch (rxcb->err_code) {\n\tcase HAL_REO_DEST_RING_ERROR_CODE_DESC_ADDR_ZERO:\n\t\tif (ath11k_dp_rx_h_null_q_desc(ar, msdu, status, msdu_list))\n\t\t\tdrop = true;\n\t\tbreak;\n\tcase HAL_REO_DEST_RING_ERROR_CODE_PN_CHECK_FAILED:\n\t\t \n\t\tfallthrough;\n\tdefault:\n\t\t \n\t\tdrop = true;\n\t\tbreak;\n\t}\n\n\treturn drop;\n}\n\nstatic void ath11k_dp_rx_h_tkip_mic_err(struct ath11k *ar, struct sk_buff *msdu,\n\t\t\t\t\tstruct ieee80211_rx_status *status)\n{\n\tu16 msdu_len;\n\tstruct hal_rx_desc *desc = (struct hal_rx_desc *)msdu->data;\n\tu8 l3pad_bytes;\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tu32 hal_rx_desc_sz = ar->ab->hw_params.hal_desc_sz;\n\n\trxcb->is_first_msdu = ath11k_dp_rx_h_msdu_end_first_msdu(ar->ab, desc);\n\trxcb->is_last_msdu = ath11k_dp_rx_h_msdu_end_last_msdu(ar->ab, desc);\n\n\tl3pad_bytes = ath11k_dp_rx_h_msdu_end_l3pad(ar->ab, desc);\n\tmsdu_len = ath11k_dp_rx_h_msdu_start_msdu_len(ar->ab, desc);\n\tskb_put(msdu, hal_rx_desc_sz + l3pad_bytes + msdu_len);\n\tskb_pull(msdu, hal_rx_desc_sz + l3pad_bytes);\n\n\tath11k_dp_rx_h_ppdu(ar, desc, status);\n\n\tstatus->flag |= (RX_FLAG_MMIC_STRIPPED | RX_FLAG_MMIC_ERROR |\n\t\t\t RX_FLAG_DECRYPTED);\n\n\tath11k_dp_rx_h_undecap(ar, msdu, desc,\n\t\t\t       HAL_ENCRYPT_TYPE_TKIP_MIC, status, false);\n}\n\nstatic bool ath11k_dp_rx_h_rxdma_err(struct ath11k *ar,  struct sk_buff *msdu,\n\t\t\t\t     struct ieee80211_rx_status *status)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tbool drop = false;\n\n\tar->ab->soc_stats.rxdma_error[rxcb->err_code]++;\n\n\tswitch (rxcb->err_code) {\n\tcase HAL_REO_ENTR_RING_RXDMA_ECODE_TKIP_MIC_ERR:\n\t\tath11k_dp_rx_h_tkip_mic_err(ar, msdu, status);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tdrop = true;\n\t\tbreak;\n\t}\n\n\treturn drop;\n}\n\nstatic void ath11k_dp_rx_wbm_err(struct ath11k *ar,\n\t\t\t\t struct napi_struct *napi,\n\t\t\t\t struct sk_buff *msdu,\n\t\t\t\t struct sk_buff_head *msdu_list)\n{\n\tstruct ath11k_skb_rxcb *rxcb = ATH11K_SKB_RXCB(msdu);\n\tstruct ieee80211_rx_status rxs = {0};\n\tbool drop = true;\n\n\tswitch (rxcb->err_rel_src) {\n\tcase HAL_WBM_REL_SRC_MODULE_REO:\n\t\tdrop = ath11k_dp_rx_h_reo_err(ar, msdu, &rxs, msdu_list);\n\t\tbreak;\n\tcase HAL_WBM_REL_SRC_MODULE_RXDMA:\n\t\tdrop = ath11k_dp_rx_h_rxdma_err(ar, msdu, &rxs);\n\t\tbreak;\n\tdefault:\n\t\t \n\t\tbreak;\n\t}\n\n\tif (drop) {\n\t\tdev_kfree_skb_any(msdu);\n\t\treturn;\n\t}\n\n\tath11k_dp_rx_deliver_msdu(ar, napi, msdu, &rxs);\n}\n\nint ath11k_dp_rx_process_wbm_err(struct ath11k_base *ab,\n\t\t\t\t struct napi_struct *napi, int budget)\n{\n\tstruct ath11k *ar;\n\tstruct ath11k_dp *dp = &ab->dp;\n\tstruct dp_rxdma_ring *rx_ring;\n\tstruct hal_rx_wbm_rel_info err_info;\n\tstruct hal_srng *srng;\n\tstruct sk_buff *msdu;\n\tstruct sk_buff_head msdu_list[MAX_RADIOS];\n\tstruct ath11k_skb_rxcb *rxcb;\n\tu32 *rx_desc;\n\tint buf_id, mac_id;\n\tint num_buffs_reaped[MAX_RADIOS] = {0};\n\tint total_num_buffs_reaped = 0;\n\tint ret, i;\n\n\tfor (i = 0; i < ab->num_radios; i++)\n\t\t__skb_queue_head_init(&msdu_list[i]);\n\n\tsrng = &ab->hal.srng_list[dp->rx_rel_ring.ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\twhile (budget) {\n\t\trx_desc = ath11k_hal_srng_dst_get_next_entry(ab, srng);\n\t\tif (!rx_desc)\n\t\t\tbreak;\n\n\t\tret = ath11k_hal_wbm_desc_parse_err(ab, rx_desc, &err_info);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab,\n\t\t\t\t    \"failed to parse rx error in wbm_rel ring desc %d\\n\",\n\t\t\t\t    ret);\n\t\t\tcontinue;\n\t\t}\n\n\t\tbuf_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_BUF_ID, err_info.cookie);\n\t\tmac_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_PDEV_ID, err_info.cookie);\n\n\t\tar = ab->pdevs[mac_id].ar;\n\t\trx_ring = &ar->dp.rx_refill_buf_ring;\n\n\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\tmsdu = idr_find(&rx_ring->bufs_idr, buf_id);\n\t\tif (!msdu) {\n\t\t\tath11k_warn(ab, \"frame rx with invalid buf_id %d pdev %d\\n\",\n\t\t\t\t    buf_id, mac_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\n\t\trxcb = ATH11K_SKB_RXCB(msdu);\n\t\tdma_unmap_single(ab->dev, rxcb->paddr,\n\t\t\t\t msdu->len + skb_tailroom(msdu),\n\t\t\t\t DMA_FROM_DEVICE);\n\n\t\tnum_buffs_reaped[mac_id]++;\n\t\ttotal_num_buffs_reaped++;\n\t\tbudget--;\n\n\t\tif (err_info.push_reason !=\n\t\t    HAL_REO_DEST_RING_PUSH_REASON_ERR_DETECTED) {\n\t\t\tdev_kfree_skb_any(msdu);\n\t\t\tcontinue;\n\t\t}\n\n\t\trxcb->err_rel_src = err_info.err_rel_src;\n\t\trxcb->err_code = err_info.err_code;\n\t\trxcb->rx_desc = (struct hal_rx_desc *)msdu->data;\n\t\t__skb_queue_tail(&msdu_list[mac_id], msdu);\n\t}\n\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\tif (!total_num_buffs_reaped)\n\t\tgoto done;\n\n\tfor (i = 0; i <  ab->num_radios; i++) {\n\t\tif (!num_buffs_reaped[i])\n\t\t\tcontinue;\n\n\t\tar = ab->pdevs[i].ar;\n\t\trx_ring = &ar->dp.rx_refill_buf_ring;\n\n\t\tath11k_dp_rxbufs_replenish(ab, i, rx_ring, num_buffs_reaped[i],\n\t\t\t\t\t   ab->hw_params.hal_params->rx_buf_rbm);\n\t}\n\n\trcu_read_lock();\n\tfor (i = 0; i <  ab->num_radios; i++) {\n\t\tif (!rcu_dereference(ab->pdevs_active[i])) {\n\t\t\t__skb_queue_purge(&msdu_list[i]);\n\t\t\tcontinue;\n\t\t}\n\n\t\tar = ab->pdevs[i].ar;\n\n\t\tif (test_bit(ATH11K_CAC_RUNNING, &ar->dev_flags)) {\n\t\t\t__skb_queue_purge(&msdu_list[i]);\n\t\t\tcontinue;\n\t\t}\n\n\t\twhile ((msdu = __skb_dequeue(&msdu_list[i])) != NULL)\n\t\t\tath11k_dp_rx_wbm_err(ar, napi, msdu, &msdu_list[i]);\n\t}\n\trcu_read_unlock();\ndone:\n\treturn total_num_buffs_reaped;\n}\n\nint ath11k_dp_process_rxdma_err(struct ath11k_base *ab, int mac_id, int budget)\n{\n\tstruct ath11k *ar;\n\tstruct dp_srng *err_ring;\n\tstruct dp_rxdma_ring *rx_ring;\n\tstruct dp_link_desc_bank *link_desc_banks = ab->dp.link_desc_banks;\n\tstruct hal_srng *srng;\n\tu32 msdu_cookies[HAL_NUM_RX_MSDUS_PER_LINK_DESC];\n\tenum hal_rx_buf_return_buf_manager rbm;\n\tenum hal_reo_entr_rxdma_ecode rxdma_err_code;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tstruct sk_buff *skb;\n\tstruct hal_reo_entrance_ring *entr_ring;\n\tvoid *desc;\n\tint num_buf_freed = 0;\n\tint quota = budget;\n\tdma_addr_t paddr;\n\tu32 desc_bank;\n\tvoid *link_desc_va;\n\tint num_msdus;\n\tint i;\n\tint buf_id;\n\n\tar = ab->pdevs[ath11k_hw_mac_id_to_pdev_id(&ab->hw_params, mac_id)].ar;\n\terr_ring = &ar->dp.rxdma_err_dst_ring[ath11k_hw_mac_id_to_srng_id(&ab->hw_params,\n\t\t\t\t\t\t\t\t\t  mac_id)];\n\trx_ring = &ar->dp.rx_refill_buf_ring;\n\n\tsrng = &ab->hal.srng_list[err_ring->ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\twhile (quota-- &&\n\t       (desc = ath11k_hal_srng_dst_get_next_entry(ab, srng))) {\n\t\tath11k_hal_rx_reo_ent_paddr_get(ab, desc, &paddr, &desc_bank);\n\n\t\tentr_ring = (struct hal_reo_entrance_ring *)desc;\n\t\trxdma_err_code =\n\t\t\tFIELD_GET(HAL_REO_ENTR_RING_INFO1_RXDMA_ERROR_CODE,\n\t\t\t\t  entr_ring->info1);\n\t\tab->soc_stats.rxdma_error[rxdma_err_code]++;\n\n\t\tlink_desc_va = link_desc_banks[desc_bank].vaddr +\n\t\t\t       (paddr - link_desc_banks[desc_bank].paddr);\n\t\tath11k_hal_rx_msdu_link_info_get(link_desc_va, &num_msdus,\n\t\t\t\t\t\t msdu_cookies, &rbm);\n\n\t\tfor (i = 0; i < num_msdus; i++) {\n\t\t\tbuf_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_BUF_ID,\n\t\t\t\t\t   msdu_cookies[i]);\n\n\t\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\t\tskb = idr_find(&rx_ring->bufs_idr, buf_id);\n\t\t\tif (!skb) {\n\t\t\t\tath11k_warn(ab, \"rxdma error with invalid buf_id %d\\n\",\n\t\t\t\t\t    buf_id);\n\t\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\n\t\t\trxcb = ATH11K_SKB_RXCB(skb);\n\t\t\tdma_unmap_single(ab->dev, rxcb->paddr,\n\t\t\t\t\t skb->len + skb_tailroom(skb),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\n\t\t\tnum_buf_freed++;\n\t\t}\n\n\t\tath11k_dp_rx_link_desc_return(ab, desc,\n\t\t\t\t\t      HAL_WBM_REL_BM_ACT_PUT_IN_IDLE);\n\t}\n\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n\n\tif (num_buf_freed)\n\t\tath11k_dp_rxbufs_replenish(ab, mac_id, rx_ring, num_buf_freed,\n\t\t\t\t\t   ab->hw_params.hal_params->rx_buf_rbm);\n\n\treturn budget - quota;\n}\n\nvoid ath11k_dp_process_reo_status(struct ath11k_base *ab)\n{\n\tstruct ath11k_dp *dp = &ab->dp;\n\tstruct hal_srng *srng;\n\tstruct dp_reo_cmd *cmd, *tmp;\n\tbool found = false;\n\tu32 *reo_desc;\n\tu16 tag;\n\tstruct hal_reo_status reo_status;\n\n\tsrng = &ab->hal.srng_list[dp->reo_status_ring.ring_id];\n\n\tmemset(&reo_status, 0, sizeof(reo_status));\n\n\tspin_lock_bh(&srng->lock);\n\n\tath11k_hal_srng_access_begin(ab, srng);\n\n\twhile ((reo_desc = ath11k_hal_srng_dst_get_next_entry(ab, srng))) {\n\t\ttag = FIELD_GET(HAL_SRNG_TLV_HDR_TAG, *reo_desc);\n\n\t\tswitch (tag) {\n\t\tcase HAL_REO_GET_QUEUE_STATS_STATUS:\n\t\t\tath11k_hal_reo_status_queue_stats(ab, reo_desc,\n\t\t\t\t\t\t\t  &reo_status);\n\t\t\tbreak;\n\t\tcase HAL_REO_FLUSH_QUEUE_STATUS:\n\t\t\tath11k_hal_reo_flush_queue_status(ab, reo_desc,\n\t\t\t\t\t\t\t  &reo_status);\n\t\t\tbreak;\n\t\tcase HAL_REO_FLUSH_CACHE_STATUS:\n\t\t\tath11k_hal_reo_flush_cache_status(ab, reo_desc,\n\t\t\t\t\t\t\t  &reo_status);\n\t\t\tbreak;\n\t\tcase HAL_REO_UNBLOCK_CACHE_STATUS:\n\t\t\tath11k_hal_reo_unblk_cache_status(ab, reo_desc,\n\t\t\t\t\t\t\t  &reo_status);\n\t\t\tbreak;\n\t\tcase HAL_REO_FLUSH_TIMEOUT_LIST_STATUS:\n\t\t\tath11k_hal_reo_flush_timeout_list_status(ab, reo_desc,\n\t\t\t\t\t\t\t\t &reo_status);\n\t\t\tbreak;\n\t\tcase HAL_REO_DESCRIPTOR_THRESHOLD_REACHED_STATUS:\n\t\t\tath11k_hal_reo_desc_thresh_reached_status(ab, reo_desc,\n\t\t\t\t\t\t\t\t  &reo_status);\n\t\t\tbreak;\n\t\tcase HAL_REO_UPDATE_RX_REO_QUEUE_STATUS:\n\t\t\tath11k_hal_reo_update_rx_reo_queue_status(ab, reo_desc,\n\t\t\t\t\t\t\t\t  &reo_status);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tath11k_warn(ab, \"Unknown reo status type %d\\n\", tag);\n\t\t\tcontinue;\n\t\t}\n\n\t\tspin_lock_bh(&dp->reo_cmd_lock);\n\t\tlist_for_each_entry_safe(cmd, tmp, &dp->reo_cmd_list, list) {\n\t\t\tif (reo_status.uniform_hdr.cmd_num == cmd->cmd_num) {\n\t\t\t\tfound = true;\n\t\t\t\tlist_del(&cmd->list);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_bh(&dp->reo_cmd_lock);\n\n\t\tif (found) {\n\t\t\tcmd->handler(dp, (void *)&cmd->data,\n\t\t\t\t     reo_status.uniform_hdr.cmd_status);\n\t\t\tkfree(cmd);\n\t\t}\n\n\t\tfound = false;\n\t}\n\n\tath11k_hal_srng_access_end(ab, srng);\n\n\tspin_unlock_bh(&srng->lock);\n}\n\nvoid ath11k_dp_rx_pdev_free(struct ath11k_base *ab, int mac_id)\n{\n\tstruct ath11k *ar = ab->pdevs[mac_id].ar;\n\n\tath11k_dp_rx_pdev_srng_free(ar);\n\tath11k_dp_rxdma_pdev_buf_free(ar);\n}\n\nint ath11k_dp_rx_pdev_alloc(struct ath11k_base *ab, int mac_id)\n{\n\tstruct ath11k *ar = ab->pdevs[mac_id].ar;\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tu32 ring_id;\n\tint i;\n\tint ret;\n\n\tret = ath11k_dp_rx_pdev_srng_alloc(ar);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to setup rx srngs\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ath11k_dp_rxdma_pdev_buf_setup(ar);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to setup rxdma ring\\n\");\n\t\treturn ret;\n\t}\n\n\tring_id = dp->rx_refill_buf_ring.refill_buf_ring.ring_id;\n\tret = ath11k_dp_tx_htt_srng_setup(ab, ring_id, mac_id, HAL_RXDMA_BUF);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to configure rx_refill_buf_ring %d\\n\",\n\t\t\t    ret);\n\t\treturn ret;\n\t}\n\n\tif (ab->hw_params.rx_mac_buf_ring) {\n\t\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\t\tring_id = dp->rx_mac_buf_ring[i].ring_id;\n\t\t\tret = ath11k_dp_tx_htt_srng_setup(ab, ring_id,\n\t\t\t\t\t\t\t  mac_id + i, HAL_RXDMA_BUF);\n\t\t\tif (ret) {\n\t\t\t\tath11k_warn(ab, \"failed to configure rx_mac_buf_ring%d %d\\n\",\n\t\t\t\t\t    i, ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\tring_id = dp->rxdma_err_dst_ring[i].ring_id;\n\t\tret = ath11k_dp_tx_htt_srng_setup(ab, ring_id,\n\t\t\t\t\t\t  mac_id + i, HAL_RXDMA_DST);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab, \"failed to configure rxdma_err_dest_ring%d %d\\n\",\n\t\t\t\t    i, ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\tif (!ab->hw_params.rxdma1_enable)\n\t\tgoto config_refill_ring;\n\n\tring_id = dp->rxdma_mon_buf_ring.refill_buf_ring.ring_id;\n\tret = ath11k_dp_tx_htt_srng_setup(ab, ring_id,\n\t\t\t\t\t  mac_id, HAL_RXDMA_MONITOR_BUF);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to configure rxdma_mon_buf_ring %d\\n\",\n\t\t\t    ret);\n\t\treturn ret;\n\t}\n\tret = ath11k_dp_tx_htt_srng_setup(ab,\n\t\t\t\t\t  dp->rxdma_mon_dst_ring.ring_id,\n\t\t\t\t\t  mac_id, HAL_RXDMA_MONITOR_DST);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to configure rxdma_mon_dst_ring %d\\n\",\n\t\t\t    ret);\n\t\treturn ret;\n\t}\n\tret = ath11k_dp_tx_htt_srng_setup(ab,\n\t\t\t\t\t  dp->rxdma_mon_desc_ring.ring_id,\n\t\t\t\t\t  mac_id, HAL_RXDMA_MONITOR_DESC);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to configure rxdma_mon_dst_ring %d\\n\",\n\t\t\t    ret);\n\t\treturn ret;\n\t}\n\nconfig_refill_ring:\n\tfor (i = 0; i < ab->hw_params.num_rxmda_per_pdev; i++) {\n\t\tring_id = dp->rx_mon_status_refill_ring[i].refill_buf_ring.ring_id;\n\t\tret = ath11k_dp_tx_htt_srng_setup(ab, ring_id, mac_id + i,\n\t\t\t\t\t\t  HAL_RXDMA_MONITOR_STATUS);\n\t\tif (ret) {\n\t\t\tath11k_warn(ab,\n\t\t\t\t    \"failed to configure mon_status_refill_ring%d %d\\n\",\n\t\t\t\t    i, ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void ath11k_dp_mon_set_frag_len(u32 *total_len, u32 *frag_len)\n{\n\tif (*total_len >= (DP_RX_BUFFER_SIZE - sizeof(struct hal_rx_desc))) {\n\t\t*frag_len = DP_RX_BUFFER_SIZE - sizeof(struct hal_rx_desc);\n\t\t*total_len -= *frag_len;\n\t} else {\n\t\t*frag_len = *total_len;\n\t\t*total_len = 0;\n\t}\n}\n\nstatic\nint ath11k_dp_rx_monitor_link_desc_return(struct ath11k *ar,\n\t\t\t\t\t  void *p_last_buf_addr_info,\n\t\t\t\t\t  u8 mac_id)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct dp_srng *dp_srng;\n\tvoid *hal_srng;\n\tvoid *src_srng_desc;\n\tint ret = 0;\n\n\tif (ar->ab->hw_params.rxdma1_enable) {\n\t\tdp_srng = &dp->rxdma_mon_desc_ring;\n\t\thal_srng = &ar->ab->hal.srng_list[dp_srng->ring_id];\n\t} else {\n\t\tdp_srng = &ar->ab->dp.wbm_desc_rel_ring;\n\t\thal_srng = &ar->ab->hal.srng_list[dp_srng->ring_id];\n\t}\n\n\tath11k_hal_srng_access_begin(ar->ab, hal_srng);\n\n\tsrc_srng_desc = ath11k_hal_srng_src_get_next_entry(ar->ab, hal_srng);\n\n\tif (src_srng_desc) {\n\t\tstruct ath11k_buffer_addr *src_desc =\n\t\t\t\t(struct ath11k_buffer_addr *)src_srng_desc;\n\n\t\t*src_desc = *((struct ath11k_buffer_addr *)p_last_buf_addr_info);\n\t} else {\n\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t   \"Monitor Link Desc Ring %d Full\", mac_id);\n\t\tret = -ENOMEM;\n\t}\n\n\tath11k_hal_srng_access_end(ar->ab, hal_srng);\n\treturn ret;\n}\n\nstatic\nvoid ath11k_dp_rx_mon_next_link_desc_get(void *rx_msdu_link_desc,\n\t\t\t\t\t dma_addr_t *paddr, u32 *sw_cookie,\n\t\t\t\t\t u8 *rbm,\n\t\t\t\t\t void **pp_buf_addr_info)\n{\n\tstruct hal_rx_msdu_link *msdu_link =\n\t\t\t(struct hal_rx_msdu_link *)rx_msdu_link_desc;\n\tstruct ath11k_buffer_addr *buf_addr_info;\n\n\tbuf_addr_info = (struct ath11k_buffer_addr *)&msdu_link->buf_addr_info;\n\n\tath11k_hal_rx_buf_addr_info_get(buf_addr_info, paddr, sw_cookie, rbm);\n\n\t*pp_buf_addr_info = (void *)buf_addr_info;\n}\n\nstatic int ath11k_dp_pkt_set_pktlen(struct sk_buff *skb, u32 len)\n{\n\tif (skb->len > len) {\n\t\tskb_trim(skb, len);\n\t} else {\n\t\tif (skb_tailroom(skb) < len - skb->len) {\n\t\t\tif ((pskb_expand_head(skb, 0,\n\t\t\t\t\t      len - skb->len - skb_tailroom(skb),\n\t\t\t\t\t      GFP_ATOMIC))) {\n\t\t\t\tdev_kfree_skb_any(skb);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t}\n\t\tskb_put(skb, (len - skb->len));\n\t}\n\treturn 0;\n}\n\nstatic void ath11k_hal_rx_msdu_list_get(struct ath11k *ar,\n\t\t\t\t\tvoid *msdu_link_desc,\n\t\t\t\t\tstruct hal_rx_msdu_list *msdu_list,\n\t\t\t\t\tu16 *num_msdus)\n{\n\tstruct hal_rx_msdu_details *msdu_details = NULL;\n\tstruct rx_msdu_desc *msdu_desc_info = NULL;\n\tstruct hal_rx_msdu_link *msdu_link = NULL;\n\tint i;\n\tu32 last = FIELD_PREP(RX_MSDU_DESC_INFO0_LAST_MSDU_IN_MPDU, 1);\n\tu32 first = FIELD_PREP(RX_MSDU_DESC_INFO0_FIRST_MSDU_IN_MPDU, 1);\n\tu8  tmp  = 0;\n\n\tmsdu_link = (struct hal_rx_msdu_link *)msdu_link_desc;\n\tmsdu_details = &msdu_link->msdu_link[0];\n\n\tfor (i = 0; i < HAL_RX_NUM_MSDU_DESC; i++) {\n\t\tif (FIELD_GET(BUFFER_ADDR_INFO0_ADDR,\n\t\t\t      msdu_details[i].buf_addr_info.info0) == 0) {\n\t\t\tmsdu_desc_info = &msdu_details[i - 1].rx_msdu_info;\n\t\t\tmsdu_desc_info->info0 |= last;\n\t\t\t;\n\t\t\tbreak;\n\t\t}\n\t\tmsdu_desc_info = &msdu_details[i].rx_msdu_info;\n\n\t\tif (!i)\n\t\t\tmsdu_desc_info->info0 |= first;\n\t\telse if (i == (HAL_RX_NUM_MSDU_DESC - 1))\n\t\t\tmsdu_desc_info->info0 |= last;\n\t\tmsdu_list->msdu_info[i].msdu_flags = msdu_desc_info->info0;\n\t\tmsdu_list->msdu_info[i].msdu_len =\n\t\t\t HAL_RX_MSDU_PKT_LENGTH_GET(msdu_desc_info->info0);\n\t\tmsdu_list->sw_cookie[i] =\n\t\t\tFIELD_GET(BUFFER_ADDR_INFO1_SW_COOKIE,\n\t\t\t\t  msdu_details[i].buf_addr_info.info1);\n\t\ttmp = FIELD_GET(BUFFER_ADDR_INFO1_RET_BUF_MGR,\n\t\t\t\tmsdu_details[i].buf_addr_info.info1);\n\t\tmsdu_list->rbm[i] = tmp;\n\t}\n\t*num_msdus = i;\n}\n\nstatic u32 ath11k_dp_rx_mon_comp_ppduid(u32 msdu_ppdu_id, u32 *ppdu_id,\n\t\t\t\t\tu32 *rx_bufs_used)\n{\n\tu32 ret = 0;\n\n\tif ((*ppdu_id < msdu_ppdu_id) &&\n\t    ((msdu_ppdu_id - *ppdu_id) < DP_NOT_PPDU_ID_WRAP_AROUND)) {\n\t\t*ppdu_id = msdu_ppdu_id;\n\t\tret = msdu_ppdu_id;\n\t} else if ((*ppdu_id > msdu_ppdu_id) &&\n\t\t((*ppdu_id - msdu_ppdu_id) > DP_NOT_PPDU_ID_WRAP_AROUND)) {\n\t\t \n\t\t*rx_bufs_used += 1;\n\t\t*ppdu_id = msdu_ppdu_id;\n\t\tret = msdu_ppdu_id;\n\t}\n\treturn ret;\n}\n\nstatic void ath11k_dp_mon_get_buf_len(struct hal_rx_msdu_desc_info *info,\n\t\t\t\t      bool *is_frag, u32 *total_len,\n\t\t\t\t      u32 *frag_len, u32 *msdu_cnt)\n{\n\tif (info->msdu_flags & RX_MSDU_DESC_INFO0_MSDU_CONTINUATION) {\n\t\tif (!*is_frag) {\n\t\t\t*total_len = info->msdu_len;\n\t\t\t*is_frag = true;\n\t\t}\n\t\tath11k_dp_mon_set_frag_len(total_len,\n\t\t\t\t\t   frag_len);\n\t} else {\n\t\tif (*is_frag) {\n\t\t\tath11k_dp_mon_set_frag_len(total_len,\n\t\t\t\t\t\t   frag_len);\n\t\t} else {\n\t\t\t*frag_len = info->msdu_len;\n\t\t}\n\t\t*is_frag = false;\n\t\t*msdu_cnt -= 1;\n\t}\n}\n\nstatic u32\nath11k_dp_rx_mon_mpdu_pop(struct ath11k *ar, int mac_id,\n\t\t\t  void *ring_entry, struct sk_buff **head_msdu,\n\t\t\t  struct sk_buff **tail_msdu, u32 *npackets,\n\t\t\t  u32 *ppdu_id)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = (struct ath11k_mon_data *)&dp->mon_data;\n\tstruct dp_rxdma_ring *rx_ring = &dp->rxdma_mon_buf_ring;\n\tstruct sk_buff *msdu = NULL, *last = NULL;\n\tstruct hal_rx_msdu_list msdu_list;\n\tvoid *p_buf_addr_info, *p_last_buf_addr_info;\n\tstruct hal_rx_desc *rx_desc;\n\tvoid *rx_msdu_link_desc;\n\tdma_addr_t paddr;\n\tu16 num_msdus = 0;\n\tu32 rx_buf_size, rx_pkt_offset, sw_cookie;\n\tu32 rx_bufs_used = 0, i = 0;\n\tu32 msdu_ppdu_id = 0, msdu_cnt = 0;\n\tu32 total_len = 0, frag_len = 0;\n\tbool is_frag, is_first_msdu;\n\tbool drop_mpdu = false;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tstruct hal_reo_entrance_ring *ent_desc =\n\t\t\t(struct hal_reo_entrance_ring *)ring_entry;\n\tint buf_id;\n\tu32 rx_link_buf_info[2];\n\tu8 rbm;\n\n\tif (!ar->ab->hw_params.rxdma1_enable)\n\t\trx_ring = &dp->rx_refill_buf_ring;\n\n\tath11k_hal_rx_reo_ent_buf_paddr_get(ring_entry, &paddr,\n\t\t\t\t\t    &sw_cookie,\n\t\t\t\t\t    &p_last_buf_addr_info, &rbm,\n\t\t\t\t\t    &msdu_cnt);\n\n\tif (FIELD_GET(HAL_REO_ENTR_RING_INFO1_RXDMA_PUSH_REASON,\n\t\t      ent_desc->info1) ==\n\t\t      HAL_REO_DEST_RING_PUSH_REASON_ERR_DETECTED) {\n\t\tu8 rxdma_err =\n\t\t\tFIELD_GET(HAL_REO_ENTR_RING_INFO1_RXDMA_ERROR_CODE,\n\t\t\t\t  ent_desc->info1);\n\t\tif (rxdma_err == HAL_REO_ENTR_RING_RXDMA_ECODE_FLUSH_REQUEST_ERR ||\n\t\t    rxdma_err == HAL_REO_ENTR_RING_RXDMA_ECODE_MPDU_LEN_ERR ||\n\t\t    rxdma_err == HAL_REO_ENTR_RING_RXDMA_ECODE_OVERFLOW_ERR) {\n\t\t\tdrop_mpdu = true;\n\t\t\tpmon->rx_mon_stats.dest_mpdu_drop++;\n\t\t}\n\t}\n\n\tis_frag = false;\n\tis_first_msdu = true;\n\n\tdo {\n\t\tif (pmon->mon_last_linkdesc_paddr == paddr) {\n\t\t\tpmon->rx_mon_stats.dup_mon_linkdesc_cnt++;\n\t\t\treturn rx_bufs_used;\n\t\t}\n\n\t\tif (ar->ab->hw_params.rxdma1_enable)\n\t\t\trx_msdu_link_desc =\n\t\t\t\t(void *)pmon->link_desc_banks[sw_cookie].vaddr +\n\t\t\t\t(paddr - pmon->link_desc_banks[sw_cookie].paddr);\n\t\telse\n\t\t\trx_msdu_link_desc =\n\t\t\t\t(void *)ar->ab->dp.link_desc_banks[sw_cookie].vaddr +\n\t\t\t\t(paddr - ar->ab->dp.link_desc_banks[sw_cookie].paddr);\n\n\t\tath11k_hal_rx_msdu_list_get(ar, rx_msdu_link_desc, &msdu_list,\n\t\t\t\t\t    &num_msdus);\n\n\t\tfor (i = 0; i < num_msdus; i++) {\n\t\t\tu32 l2_hdr_offset;\n\n\t\t\tif (pmon->mon_last_buf_cookie == msdu_list.sw_cookie[i]) {\n\t\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t\t   \"i %d last_cookie %d is same\\n\",\n\t\t\t\t\t   i, pmon->mon_last_buf_cookie);\n\t\t\t\tdrop_mpdu = true;\n\t\t\t\tpmon->rx_mon_stats.dup_mon_buf_cnt++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbuf_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_BUF_ID,\n\t\t\t\t\t   msdu_list.sw_cookie[i]);\n\n\t\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\t\tmsdu = idr_find(&rx_ring->bufs_idr, buf_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\t\tif (!msdu) {\n\t\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t\t   \"msdu_pop: invalid buf_id %d\\n\", buf_id);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\trxcb = ATH11K_SKB_RXCB(msdu);\n\t\t\tif (!rxcb->unmapped) {\n\t\t\t\tdma_unmap_single(ar->ab->dev, rxcb->paddr,\n\t\t\t\t\t\t msdu->len +\n\t\t\t\t\t\t skb_tailroom(msdu),\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\t\trxcb->unmapped = 1;\n\t\t\t}\n\t\t\tif (drop_mpdu) {\n\t\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t\t   \"i %d drop msdu %p *ppdu_id %x\\n\",\n\t\t\t\t\t   i, msdu, *ppdu_id);\n\t\t\t\tdev_kfree_skb_any(msdu);\n\t\t\t\tmsdu = NULL;\n\t\t\t\tgoto next_msdu;\n\t\t\t}\n\n\t\t\trx_desc = (struct hal_rx_desc *)msdu->data;\n\n\t\t\trx_pkt_offset = sizeof(struct hal_rx_desc);\n\t\t\tl2_hdr_offset = ath11k_dp_rx_h_msdu_end_l3pad(ar->ab, rx_desc);\n\n\t\t\tif (is_first_msdu) {\n\t\t\t\tif (!ath11k_dp_rxdesc_mpdu_valid(ar->ab, rx_desc)) {\n\t\t\t\t\tdrop_mpdu = true;\n\t\t\t\t\tdev_kfree_skb_any(msdu);\n\t\t\t\t\tmsdu = NULL;\n\t\t\t\t\tpmon->mon_last_linkdesc_paddr = paddr;\n\t\t\t\t\tgoto next_msdu;\n\t\t\t\t}\n\n\t\t\t\tmsdu_ppdu_id =\n\t\t\t\t\tath11k_dp_rxdesc_get_ppduid(ar->ab, rx_desc);\n\n\t\t\t\tif (ath11k_dp_rx_mon_comp_ppduid(msdu_ppdu_id,\n\t\t\t\t\t\t\t\t ppdu_id,\n\t\t\t\t\t\t\t\t &rx_bufs_used)) {\n\t\t\t\t\tif (rx_bufs_used) {\n\t\t\t\t\t\tdrop_mpdu = true;\n\t\t\t\t\t\tdev_kfree_skb_any(msdu);\n\t\t\t\t\t\tmsdu = NULL;\n\t\t\t\t\t\tgoto next_msdu;\n\t\t\t\t\t}\n\t\t\t\t\treturn rx_bufs_used;\n\t\t\t\t}\n\t\t\t\tpmon->mon_last_linkdesc_paddr = paddr;\n\t\t\t\tis_first_msdu = false;\n\t\t\t}\n\t\t\tath11k_dp_mon_get_buf_len(&msdu_list.msdu_info[i],\n\t\t\t\t\t\t  &is_frag, &total_len,\n\t\t\t\t\t\t  &frag_len, &msdu_cnt);\n\t\t\trx_buf_size = rx_pkt_offset + l2_hdr_offset + frag_len;\n\n\t\t\tath11k_dp_pkt_set_pktlen(msdu, rx_buf_size);\n\n\t\t\tif (!(*head_msdu))\n\t\t\t\t*head_msdu = msdu;\n\t\t\telse if (last)\n\t\t\t\tlast->next = msdu;\n\n\t\t\tlast = msdu;\nnext_msdu:\n\t\t\tpmon->mon_last_buf_cookie = msdu_list.sw_cookie[i];\n\t\t\trx_bufs_used++;\n\t\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\t\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\t}\n\n\t\tath11k_hal_rx_buf_addr_info_set(rx_link_buf_info, paddr, sw_cookie, rbm);\n\n\t\tath11k_dp_rx_mon_next_link_desc_get(rx_msdu_link_desc, &paddr,\n\t\t\t\t\t\t    &sw_cookie, &rbm,\n\t\t\t\t\t\t    &p_buf_addr_info);\n\n\t\tif (ar->ab->hw_params.rxdma1_enable) {\n\t\t\tif (ath11k_dp_rx_monitor_link_desc_return(ar,\n\t\t\t\t\t\t\t\t  p_last_buf_addr_info,\n\t\t\t\t\t\t\t\t  dp->mac_id))\n\t\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t\t   \"dp_rx_monitor_link_desc_return failed\");\n\t\t} else {\n\t\t\tath11k_dp_rx_link_desc_return(ar->ab, rx_link_buf_info,\n\t\t\t\t\t\t      HAL_WBM_REL_BM_ACT_PUT_IN_IDLE);\n\t\t}\n\n\t\tp_last_buf_addr_info = p_buf_addr_info;\n\n\t} while (paddr && msdu_cnt);\n\n\tif (last)\n\t\tlast->next = NULL;\n\n\t*tail_msdu = msdu;\n\n\tif (msdu_cnt == 0)\n\t\t*npackets = 1;\n\n\treturn rx_bufs_used;\n}\n\nstatic void ath11k_dp_rx_msdus_set_payload(struct ath11k *ar, struct sk_buff *msdu)\n{\n\tu32 rx_pkt_offset, l2_hdr_offset;\n\n\trx_pkt_offset = ar->ab->hw_params.hal_desc_sz;\n\tl2_hdr_offset = ath11k_dp_rx_h_msdu_end_l3pad(ar->ab,\n\t\t\t\t\t\t      (struct hal_rx_desc *)msdu->data);\n\tskb_pull(msdu, rx_pkt_offset + l2_hdr_offset);\n}\n\nstatic struct sk_buff *\nath11k_dp_rx_mon_merg_msdus(struct ath11k *ar,\n\t\t\t    u32 mac_id, struct sk_buff *head_msdu,\n\t\t\t    struct sk_buff *last_msdu,\n\t\t\t    struct ieee80211_rx_status *rxs, bool *fcs_err)\n{\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct sk_buff *msdu, *prev_buf;\n\tstruct hal_rx_desc *rx_desc;\n\tchar *hdr_desc;\n\tu8 *dest, decap_format;\n\tstruct ieee80211_hdr_3addr *wh;\n\tstruct rx_attention *rx_attention;\n\tu32 err_bitmap;\n\n\tif (!head_msdu)\n\t\tgoto err_merge_fail;\n\n\trx_desc = (struct hal_rx_desc *)head_msdu->data;\n\trx_attention = ath11k_dp_rx_get_attention(ab, rx_desc);\n\terr_bitmap = ath11k_dp_rx_h_attn_mpdu_err(rx_attention);\n\n\tif (err_bitmap & DP_RX_MPDU_ERR_FCS)\n\t\t*fcs_err = true;\n\n\tif (ath11k_dp_rxdesc_get_mpdulen_err(rx_attention))\n\t\treturn NULL;\n\n\tdecap_format = ath11k_dp_rx_h_msdu_start_decap_type(ab, rx_desc);\n\n\tath11k_dp_rx_h_ppdu(ar, rx_desc, rxs);\n\n\tif (decap_format == DP_RX_DECAP_TYPE_RAW) {\n\t\tath11k_dp_rx_msdus_set_payload(ar, head_msdu);\n\n\t\tprev_buf = head_msdu;\n\t\tmsdu = head_msdu->next;\n\n\t\twhile (msdu) {\n\t\t\tath11k_dp_rx_msdus_set_payload(ar, msdu);\n\n\t\t\tprev_buf = msdu;\n\t\t\tmsdu = msdu->next;\n\t\t}\n\n\t\tprev_buf->next = NULL;\n\n\t\tskb_trim(prev_buf, prev_buf->len - HAL_RX_FCS_LEN);\n\t} else if (decap_format == DP_RX_DECAP_TYPE_NATIVE_WIFI) {\n\t\tu8 qos_pkt = 0;\n\n\t\trx_desc = (struct hal_rx_desc *)head_msdu->data;\n\t\thdr_desc = ath11k_dp_rxdesc_get_80211hdr(ab, rx_desc);\n\n\t\t \n\t\twh = (struct ieee80211_hdr_3addr *)hdr_desc;\n\n\t\tif (ieee80211_is_data_qos(wh->frame_control))\n\t\t\tqos_pkt = 1;\n\n\t\tmsdu = head_msdu;\n\n\t\twhile (msdu) {\n\t\t\tath11k_dp_rx_msdus_set_payload(ar, msdu);\n\t\t\tif (qos_pkt) {\n\t\t\t\tdest = skb_push(msdu, sizeof(__le16));\n\t\t\t\tif (!dest)\n\t\t\t\t\tgoto err_merge_fail;\n\t\t\t\tmemcpy(dest, hdr_desc, sizeof(struct ieee80211_qos_hdr));\n\t\t\t}\n\t\t\tprev_buf = msdu;\n\t\t\tmsdu = msdu->next;\n\t\t}\n\t\tdest = skb_put(prev_buf, HAL_RX_FCS_LEN);\n\t\tif (!dest)\n\t\t\tgoto err_merge_fail;\n\n\t\tath11k_dbg(ab, ATH11K_DBG_DATA,\n\t\t\t   \"mpdu_buf %p mpdu_buf->len %u\",\n\t\t\t   prev_buf, prev_buf->len);\n\t} else {\n\t\tath11k_dbg(ab, ATH11K_DBG_DATA,\n\t\t\t   \"decap format %d is not supported!\\n\",\n\t\t\t   decap_format);\n\t\tgoto err_merge_fail;\n\t}\n\n\treturn head_msdu;\n\nerr_merge_fail:\n\treturn NULL;\n}\n\nstatic void\nath11k_dp_rx_update_radiotap_he(struct hal_rx_mon_ppdu_info *rx_status,\n\t\t\t\tu8 *rtap_buf)\n{\n\tu32 rtap_len = 0;\n\n\tput_unaligned_le16(rx_status->he_data1, &rtap_buf[rtap_len]);\n\trtap_len += 2;\n\n\tput_unaligned_le16(rx_status->he_data2, &rtap_buf[rtap_len]);\n\trtap_len += 2;\n\n\tput_unaligned_le16(rx_status->he_data3, &rtap_buf[rtap_len]);\n\trtap_len += 2;\n\n\tput_unaligned_le16(rx_status->he_data4, &rtap_buf[rtap_len]);\n\trtap_len += 2;\n\n\tput_unaligned_le16(rx_status->he_data5, &rtap_buf[rtap_len]);\n\trtap_len += 2;\n\n\tput_unaligned_le16(rx_status->he_data6, &rtap_buf[rtap_len]);\n}\n\nstatic void\nath11k_dp_rx_update_radiotap_he_mu(struct hal_rx_mon_ppdu_info *rx_status,\n\t\t\t\t   u8 *rtap_buf)\n{\n\tu32 rtap_len = 0;\n\n\tput_unaligned_le16(rx_status->he_flags1, &rtap_buf[rtap_len]);\n\trtap_len += 2;\n\n\tput_unaligned_le16(rx_status->he_flags2, &rtap_buf[rtap_len]);\n\trtap_len += 2;\n\n\trtap_buf[rtap_len] = rx_status->he_RU[0];\n\trtap_len += 1;\n\n\trtap_buf[rtap_len] = rx_status->he_RU[1];\n\trtap_len += 1;\n\n\trtap_buf[rtap_len] = rx_status->he_RU[2];\n\trtap_len += 1;\n\n\trtap_buf[rtap_len] = rx_status->he_RU[3];\n}\n\nstatic void ath11k_update_radiotap(struct ath11k *ar,\n\t\t\t\t   struct hal_rx_mon_ppdu_info *ppduinfo,\n\t\t\t\t   struct sk_buff *mon_skb,\n\t\t\t\t   struct ieee80211_rx_status *rxs)\n{\n\tstruct ieee80211_supported_band *sband;\n\tu8 *ptr = NULL;\n\n\trxs->flag |= RX_FLAG_MACTIME_START;\n\trxs->signal = ppduinfo->rssi_comb + ATH11K_DEFAULT_NOISE_FLOOR;\n\n\tif (ppduinfo->nss)\n\t\trxs->nss = ppduinfo->nss;\n\n\tif (ppduinfo->he_mu_flags) {\n\t\trxs->flag |= RX_FLAG_RADIOTAP_HE_MU;\n\t\trxs->encoding = RX_ENC_HE;\n\t\tptr = skb_push(mon_skb, sizeof(struct ieee80211_radiotap_he_mu));\n\t\tath11k_dp_rx_update_radiotap_he_mu(ppduinfo, ptr);\n\t} else if (ppduinfo->he_flags) {\n\t\trxs->flag |= RX_FLAG_RADIOTAP_HE;\n\t\trxs->encoding = RX_ENC_HE;\n\t\tptr = skb_push(mon_skb, sizeof(struct ieee80211_radiotap_he));\n\t\tath11k_dp_rx_update_radiotap_he(ppduinfo, ptr);\n\t\trxs->rate_idx = ppduinfo->rate;\n\t} else if (ppduinfo->vht_flags) {\n\t\trxs->encoding = RX_ENC_VHT;\n\t\trxs->rate_idx = ppduinfo->rate;\n\t} else if (ppduinfo->ht_flags) {\n\t\trxs->encoding = RX_ENC_HT;\n\t\trxs->rate_idx = ppduinfo->rate;\n\t} else {\n\t\trxs->encoding = RX_ENC_LEGACY;\n\t\tsband = &ar->mac.sbands[rxs->band];\n\t\trxs->rate_idx = ath11k_mac_hw_rate_to_idx(sband, ppduinfo->rate,\n\t\t\t\t\t\t\t  ppduinfo->cck_flag);\n\t}\n\n\trxs->mactime = ppduinfo->tsft;\n}\n\nstatic int ath11k_dp_rx_mon_deliver(struct ath11k *ar, u32 mac_id,\n\t\t\t\t    struct sk_buff *head_msdu,\n\t\t\t\t    struct hal_rx_mon_ppdu_info *ppduinfo,\n\t\t\t\t    struct sk_buff *tail_msdu,\n\t\t\t\t    struct napi_struct *napi)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct sk_buff *mon_skb, *skb_next, *header;\n\tstruct ieee80211_rx_status *rxs = &dp->rx_status;\n\tbool fcs_err = false;\n\n\tmon_skb = ath11k_dp_rx_mon_merg_msdus(ar, mac_id, head_msdu,\n\t\t\t\t\t      tail_msdu, rxs, &fcs_err);\n\n\tif (!mon_skb)\n\t\tgoto mon_deliver_fail;\n\n\theader = mon_skb;\n\n\trxs->flag = 0;\n\n\tif (fcs_err)\n\t\trxs->flag = RX_FLAG_FAILED_FCS_CRC;\n\n\tdo {\n\t\tskb_next = mon_skb->next;\n\t\tif (!skb_next)\n\t\t\trxs->flag &= ~RX_FLAG_AMSDU_MORE;\n\t\telse\n\t\t\trxs->flag |= RX_FLAG_AMSDU_MORE;\n\n\t\tif (mon_skb == header) {\n\t\t\theader = NULL;\n\t\t\trxs->flag &= ~RX_FLAG_ALLOW_SAME_PN;\n\t\t} else {\n\t\t\trxs->flag |= RX_FLAG_ALLOW_SAME_PN;\n\t\t}\n\t\trxs->flag |= RX_FLAG_ONLY_MONITOR;\n\t\tath11k_update_radiotap(ar, ppduinfo, mon_skb, rxs);\n\n\t\tath11k_dp_rx_deliver_msdu(ar, napi, mon_skb, rxs);\n\t\tmon_skb = skb_next;\n\t} while (mon_skb);\n\trxs->flag = 0;\n\n\treturn 0;\n\nmon_deliver_fail:\n\tmon_skb = head_msdu;\n\twhile (mon_skb) {\n\t\tskb_next = mon_skb->next;\n\t\tdev_kfree_skb_any(mon_skb);\n\t\tmon_skb = skb_next;\n\t}\n\treturn -EINVAL;\n}\n\n \n#define MON_DEST_RING_STUCK_MAX_CNT 16\n\nstatic void ath11k_dp_rx_mon_dest_process(struct ath11k *ar, int mac_id,\n\t\t\t\t\t  u32 quota, struct napi_struct *napi)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = (struct ath11k_mon_data *)&dp->mon_data;\n\tconst struct ath11k_hw_hal_params *hal_params;\n\tvoid *ring_entry;\n\tvoid *mon_dst_srng;\n\tu32 ppdu_id;\n\tu32 rx_bufs_used;\n\tu32 ring_id;\n\tstruct ath11k_pdev_mon_stats *rx_mon_stats;\n\tu32\t npackets = 0;\n\tu32 mpdu_rx_bufs_used;\n\n\tif (ar->ab->hw_params.rxdma1_enable)\n\t\tring_id = dp->rxdma_mon_dst_ring.ring_id;\n\telse\n\t\tring_id = dp->rxdma_err_dst_ring[mac_id].ring_id;\n\n\tmon_dst_srng = &ar->ab->hal.srng_list[ring_id];\n\n\tif (!mon_dst_srng) {\n\t\tath11k_warn(ar->ab,\n\t\t\t    \"HAL Monitor Destination Ring Init Failed -- %p\",\n\t\t\t    mon_dst_srng);\n\t\treturn;\n\t}\n\n\tspin_lock_bh(&pmon->mon_lock);\n\n\tath11k_hal_srng_access_begin(ar->ab, mon_dst_srng);\n\n\tppdu_id = pmon->mon_ppdu_info.ppdu_id;\n\trx_bufs_used = 0;\n\trx_mon_stats = &pmon->rx_mon_stats;\n\n\twhile ((ring_entry = ath11k_hal_srng_dst_peek(ar->ab, mon_dst_srng))) {\n\t\tstruct sk_buff *head_msdu, *tail_msdu;\n\n\t\thead_msdu = NULL;\n\t\ttail_msdu = NULL;\n\n\t\tmpdu_rx_bufs_used = ath11k_dp_rx_mon_mpdu_pop(ar, mac_id, ring_entry,\n\t\t\t\t\t\t\t      &head_msdu,\n\t\t\t\t\t\t\t      &tail_msdu,\n\t\t\t\t\t\t\t      &npackets, &ppdu_id);\n\n\t\trx_bufs_used += mpdu_rx_bufs_used;\n\n\t\tif (mpdu_rx_bufs_used) {\n\t\t\tdp->mon_dest_ring_stuck_cnt = 0;\n\t\t} else {\n\t\t\tdp->mon_dest_ring_stuck_cnt++;\n\t\t\trx_mon_stats->dest_mon_not_reaped++;\n\t\t}\n\n\t\tif (dp->mon_dest_ring_stuck_cnt > MON_DEST_RING_STUCK_MAX_CNT) {\n\t\t\trx_mon_stats->dest_mon_stuck++;\n\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t   \"status ring ppdu_id=%d dest ring ppdu_id=%d mon_dest_ring_stuck_cnt=%d dest_mon_not_reaped=%u dest_mon_stuck=%u\\n\",\n\t\t\t\t   pmon->mon_ppdu_info.ppdu_id, ppdu_id,\n\t\t\t\t   dp->mon_dest_ring_stuck_cnt,\n\t\t\t\t   rx_mon_stats->dest_mon_not_reaped,\n\t\t\t\t   rx_mon_stats->dest_mon_stuck);\n\t\t\tpmon->mon_ppdu_info.ppdu_id = ppdu_id;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ppdu_id != pmon->mon_ppdu_info.ppdu_id) {\n\t\t\tpmon->mon_ppdu_status = DP_PPDU_STATUS_START;\n\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t   \"dest_rx: new ppdu_id %x != status ppdu_id %x dest_mon_not_reaped = %u dest_mon_stuck = %u\\n\",\n\t\t\t\t   ppdu_id, pmon->mon_ppdu_info.ppdu_id,\n\t\t\t\t   rx_mon_stats->dest_mon_not_reaped,\n\t\t\t\t   rx_mon_stats->dest_mon_stuck);\n\t\t\tbreak;\n\t\t}\n\t\tif (head_msdu && tail_msdu) {\n\t\t\tath11k_dp_rx_mon_deliver(ar, dp->mac_id, head_msdu,\n\t\t\t\t\t\t &pmon->mon_ppdu_info,\n\t\t\t\t\t\t tail_msdu, napi);\n\t\t\trx_mon_stats->dest_mpdu_done++;\n\t\t}\n\n\t\tring_entry = ath11k_hal_srng_dst_get_next_entry(ar->ab,\n\t\t\t\t\t\t\t\tmon_dst_srng);\n\t}\n\tath11k_hal_srng_access_end(ar->ab, mon_dst_srng);\n\n\tspin_unlock_bh(&pmon->mon_lock);\n\n\tif (rx_bufs_used) {\n\t\trx_mon_stats->dest_ppdu_done++;\n\t\thal_params = ar->ab->hw_params.hal_params;\n\n\t\tif (ar->ab->hw_params.rxdma1_enable)\n\t\t\tath11k_dp_rxbufs_replenish(ar->ab, dp->mac_id,\n\t\t\t\t\t\t   &dp->rxdma_mon_buf_ring,\n\t\t\t\t\t\t   rx_bufs_used,\n\t\t\t\t\t\t   hal_params->rx_buf_rbm);\n\t\telse\n\t\t\tath11k_dp_rxbufs_replenish(ar->ab, dp->mac_id,\n\t\t\t\t\t\t   &dp->rx_refill_buf_ring,\n\t\t\t\t\t\t   rx_bufs_used,\n\t\t\t\t\t\t   hal_params->rx_buf_rbm);\n\t}\n}\n\nint ath11k_dp_rx_process_mon_status(struct ath11k_base *ab, int mac_id,\n\t\t\t\t    struct napi_struct *napi, int budget)\n{\n\tstruct ath11k *ar = ath11k_ab_to_ar(ab, mac_id);\n\tenum hal_rx_mon_status hal_status;\n\tstruct sk_buff *skb;\n\tstruct sk_buff_head skb_list;\n\tstruct ath11k_peer *peer;\n\tstruct ath11k_sta *arsta;\n\tint num_buffs_reaped = 0;\n\tu32 rx_buf_sz;\n\tu16 log_type;\n\tstruct ath11k_mon_data *pmon = (struct ath11k_mon_data *)&ar->dp.mon_data;\n\tstruct ath11k_pdev_mon_stats *rx_mon_stats = &pmon->rx_mon_stats;\n\tstruct hal_rx_mon_ppdu_info *ppdu_info = &pmon->mon_ppdu_info;\n\n\t__skb_queue_head_init(&skb_list);\n\n\tnum_buffs_reaped = ath11k_dp_rx_reap_mon_status_ring(ab, mac_id, &budget,\n\t\t\t\t\t\t\t     &skb_list);\n\tif (!num_buffs_reaped)\n\t\tgoto exit;\n\n\tmemset(ppdu_info, 0, sizeof(*ppdu_info));\n\tppdu_info->peer_id = HAL_INVALID_PEERID;\n\n\twhile ((skb = __skb_dequeue(&skb_list))) {\n\t\tif (ath11k_debugfs_is_pktlog_lite_mode_enabled(ar)) {\n\t\t\tlog_type = ATH11K_PKTLOG_TYPE_LITE_RX;\n\t\t\trx_buf_sz = DP_RX_BUFFER_SIZE_LITE;\n\t\t} else if (ath11k_debugfs_is_pktlog_rx_stats_enabled(ar)) {\n\t\t\tlog_type = ATH11K_PKTLOG_TYPE_RX_STATBUF;\n\t\t\trx_buf_sz = DP_RX_BUFFER_SIZE;\n\t\t} else {\n\t\t\tlog_type = ATH11K_PKTLOG_TYPE_INVALID;\n\t\t\trx_buf_sz = 0;\n\t\t}\n\n\t\tif (log_type != ATH11K_PKTLOG_TYPE_INVALID)\n\t\t\ttrace_ath11k_htt_rxdesc(ar, skb->data, log_type, rx_buf_sz);\n\n\t\tmemset(ppdu_info, 0, sizeof(*ppdu_info));\n\t\tppdu_info->peer_id = HAL_INVALID_PEERID;\n\t\thal_status = ath11k_hal_rx_parse_mon_status(ab, ppdu_info, skb);\n\n\t\tif (test_bit(ATH11K_FLAG_MONITOR_STARTED, &ar->monitor_flags) &&\n\t\t    pmon->mon_ppdu_status == DP_PPDU_STATUS_START &&\n\t\t    hal_status == HAL_TLV_STATUS_PPDU_DONE) {\n\t\t\trx_mon_stats->status_ppdu_done++;\n\t\t\tpmon->mon_ppdu_status = DP_PPDU_STATUS_DONE;\n\t\t\tath11k_dp_rx_mon_dest_process(ar, mac_id, budget, napi);\n\t\t\tpmon->mon_ppdu_status = DP_PPDU_STATUS_START;\n\t\t}\n\n\t\tif (ppdu_info->peer_id == HAL_INVALID_PEERID ||\n\t\t    hal_status != HAL_RX_MON_STATUS_PPDU_DONE) {\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\trcu_read_lock();\n\t\tspin_lock_bh(&ab->base_lock);\n\t\tpeer = ath11k_peer_find_by_id(ab, ppdu_info->peer_id);\n\n\t\tif (!peer || !peer->sta) {\n\t\t\tath11k_dbg(ab, ATH11K_DBG_DATA,\n\t\t\t\t   \"failed to find the peer with peer_id %d\\n\",\n\t\t\t\t   ppdu_info->peer_id);\n\t\t\tgoto next_skb;\n\t\t}\n\n\t\tarsta = (struct ath11k_sta *)peer->sta->drv_priv;\n\t\tath11k_dp_rx_update_peer_stats(arsta, ppdu_info);\n\n\t\tif (ath11k_debugfs_is_pktlog_peer_valid(ar, peer->addr))\n\t\t\ttrace_ath11k_htt_rxdesc(ar, skb->data, log_type, rx_buf_sz);\n\nnext_skb:\n\t\tspin_unlock_bh(&ab->base_lock);\n\t\trcu_read_unlock();\n\n\t\tdev_kfree_skb_any(skb);\n\t\tmemset(ppdu_info, 0, sizeof(*ppdu_info));\n\t\tppdu_info->peer_id = HAL_INVALID_PEERID;\n\t}\nexit:\n\treturn num_buffs_reaped;\n}\n\nstatic u32\nath11k_dp_rx_full_mon_mpdu_pop(struct ath11k *ar,\n\t\t\t       void *ring_entry, struct sk_buff **head_msdu,\n\t\t\t       struct sk_buff **tail_msdu,\n\t\t\t       struct hal_sw_mon_ring_entries *sw_mon_entries)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = &dp->mon_data;\n\tstruct dp_rxdma_ring *rx_ring = &dp->rxdma_mon_buf_ring;\n\tstruct sk_buff *msdu = NULL, *last = NULL;\n\tstruct hal_sw_monitor_ring *sw_desc = ring_entry;\n\tstruct hal_rx_msdu_list msdu_list;\n\tstruct hal_rx_desc *rx_desc;\n\tstruct ath11k_skb_rxcb *rxcb;\n\tvoid *rx_msdu_link_desc;\n\tvoid *p_buf_addr_info, *p_last_buf_addr_info;\n\tint buf_id, i = 0;\n\tu32 rx_buf_size, rx_pkt_offset, l2_hdr_offset;\n\tu32 rx_bufs_used = 0, msdu_cnt = 0;\n\tu32 total_len = 0, frag_len = 0, sw_cookie;\n\tu16 num_msdus = 0;\n\tu8 rxdma_err, rbm;\n\tbool is_frag, is_first_msdu;\n\tbool drop_mpdu = false;\n\n\tath11k_hal_rx_sw_mon_ring_buf_paddr_get(ring_entry, sw_mon_entries);\n\n\tsw_cookie = sw_mon_entries->mon_dst_sw_cookie;\n\tsw_mon_entries->end_of_ppdu = false;\n\tsw_mon_entries->drop_ppdu = false;\n\tp_last_buf_addr_info = sw_mon_entries->dst_buf_addr_info;\n\tmsdu_cnt = sw_mon_entries->msdu_cnt;\n\n\tsw_mon_entries->end_of_ppdu =\n\t\tFIELD_GET(HAL_SW_MON_RING_INFO0_END_OF_PPDU, sw_desc->info0);\n\tif (sw_mon_entries->end_of_ppdu)\n\t\treturn rx_bufs_used;\n\n\tif (FIELD_GET(HAL_SW_MON_RING_INFO0_RXDMA_PUSH_REASON,\n\t\t      sw_desc->info0) ==\n\t\t      HAL_REO_DEST_RING_PUSH_REASON_ERR_DETECTED) {\n\t\trxdma_err =\n\t\t\tFIELD_GET(HAL_SW_MON_RING_INFO0_RXDMA_ERROR_CODE,\n\t\t\t\t  sw_desc->info0);\n\t\tif (rxdma_err == HAL_REO_ENTR_RING_RXDMA_ECODE_FLUSH_REQUEST_ERR ||\n\t\t    rxdma_err == HAL_REO_ENTR_RING_RXDMA_ECODE_MPDU_LEN_ERR ||\n\t\t    rxdma_err == HAL_REO_ENTR_RING_RXDMA_ECODE_OVERFLOW_ERR) {\n\t\t\tpmon->rx_mon_stats.dest_mpdu_drop++;\n\t\t\tdrop_mpdu = true;\n\t\t}\n\t}\n\n\tis_frag = false;\n\tis_first_msdu = true;\n\n\tdo {\n\t\trx_msdu_link_desc =\n\t\t\t(u8 *)pmon->link_desc_banks[sw_cookie].vaddr +\n\t\t\t(sw_mon_entries->mon_dst_paddr -\n\t\t\t pmon->link_desc_banks[sw_cookie].paddr);\n\n\t\tath11k_hal_rx_msdu_list_get(ar, rx_msdu_link_desc, &msdu_list,\n\t\t\t\t\t    &num_msdus);\n\n\t\tfor (i = 0; i < num_msdus; i++) {\n\t\t\tbuf_id = FIELD_GET(DP_RXDMA_BUF_COOKIE_BUF_ID,\n\t\t\t\t\t   msdu_list.sw_cookie[i]);\n\n\t\t\tspin_lock_bh(&rx_ring->idr_lock);\n\t\t\tmsdu = idr_find(&rx_ring->bufs_idr, buf_id);\n\t\t\tif (!msdu) {\n\t\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t\t   \"full mon msdu_pop: invalid buf_id %d\\n\",\n\t\t\t\t\t    buf_id);\n\t\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tidr_remove(&rx_ring->bufs_idr, buf_id);\n\t\t\tspin_unlock_bh(&rx_ring->idr_lock);\n\n\t\t\trxcb = ATH11K_SKB_RXCB(msdu);\n\t\t\tif (!rxcb->unmapped) {\n\t\t\t\tdma_unmap_single(ar->ab->dev, rxcb->paddr,\n\t\t\t\t\t\t msdu->len +\n\t\t\t\t\t\t skb_tailroom(msdu),\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\t\trxcb->unmapped = 1;\n\t\t\t}\n\t\t\tif (drop_mpdu) {\n\t\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t\t   \"full mon: i %d drop msdu %p *ppdu_id %x\\n\",\n\t\t\t\t\t   i, msdu, sw_mon_entries->ppdu_id);\n\t\t\t\tdev_kfree_skb_any(msdu);\n\t\t\t\tmsdu_cnt--;\n\t\t\t\tgoto next_msdu;\n\t\t\t}\n\n\t\t\trx_desc = (struct hal_rx_desc *)msdu->data;\n\n\t\t\trx_pkt_offset = sizeof(struct hal_rx_desc);\n\t\t\tl2_hdr_offset = ath11k_dp_rx_h_msdu_end_l3pad(ar->ab, rx_desc);\n\n\t\t\tif (is_first_msdu) {\n\t\t\t\tif (!ath11k_dp_rxdesc_mpdu_valid(ar->ab, rx_desc)) {\n\t\t\t\t\tdrop_mpdu = true;\n\t\t\t\t\tdev_kfree_skb_any(msdu);\n\t\t\t\t\tmsdu = NULL;\n\t\t\t\t\tgoto next_msdu;\n\t\t\t\t}\n\t\t\t\tis_first_msdu = false;\n\t\t\t}\n\n\t\t\tath11k_dp_mon_get_buf_len(&msdu_list.msdu_info[i],\n\t\t\t\t\t\t  &is_frag, &total_len,\n\t\t\t\t\t\t  &frag_len, &msdu_cnt);\n\n\t\t\trx_buf_size = rx_pkt_offset + l2_hdr_offset + frag_len;\n\n\t\t\tath11k_dp_pkt_set_pktlen(msdu, rx_buf_size);\n\n\t\t\tif (!(*head_msdu))\n\t\t\t\t*head_msdu = msdu;\n\t\t\telse if (last)\n\t\t\t\tlast->next = msdu;\n\n\t\t\tlast = msdu;\nnext_msdu:\n\t\t\trx_bufs_used++;\n\t\t}\n\n\t\tath11k_dp_rx_mon_next_link_desc_get(rx_msdu_link_desc,\n\t\t\t\t\t\t    &sw_mon_entries->mon_dst_paddr,\n\t\t\t\t\t\t    &sw_mon_entries->mon_dst_sw_cookie,\n\t\t\t\t\t\t    &rbm,\n\t\t\t\t\t\t    &p_buf_addr_info);\n\n\t\tif (ath11k_dp_rx_monitor_link_desc_return(ar,\n\t\t\t\t\t\t\t  p_last_buf_addr_info,\n\t\t\t\t\t\t\t  dp->mac_id))\n\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA,\n\t\t\t\t   \"full mon: dp_rx_monitor_link_desc_return failed\\n\");\n\n\t\tp_last_buf_addr_info = p_buf_addr_info;\n\n\t} while (sw_mon_entries->mon_dst_paddr && msdu_cnt);\n\n\tif (last)\n\t\tlast->next = NULL;\n\n\t*tail_msdu = msdu;\n\n\treturn rx_bufs_used;\n}\n\nstatic int ath11k_dp_rx_full_mon_prepare_mpdu(struct ath11k_dp *dp,\n\t\t\t\t\t      struct dp_full_mon_mpdu *mon_mpdu,\n\t\t\t\t\t      struct sk_buff *head,\n\t\t\t\t\t      struct sk_buff *tail)\n{\n\tmon_mpdu = kzalloc(sizeof(*mon_mpdu), GFP_ATOMIC);\n\tif (!mon_mpdu)\n\t\treturn -ENOMEM;\n\n\tlist_add_tail(&mon_mpdu->list, &dp->dp_full_mon_mpdu_list);\n\tmon_mpdu->head = head;\n\tmon_mpdu->tail = tail;\n\n\treturn 0;\n}\n\nstatic void ath11k_dp_rx_full_mon_drop_ppdu(struct ath11k_dp *dp,\n\t\t\t\t\t    struct dp_full_mon_mpdu *mon_mpdu)\n{\n\tstruct dp_full_mon_mpdu *tmp;\n\tstruct sk_buff *tmp_msdu, *skb_next;\n\n\tif (list_empty(&dp->dp_full_mon_mpdu_list))\n\t\treturn;\n\n\tlist_for_each_entry_safe(mon_mpdu, tmp, &dp->dp_full_mon_mpdu_list, list) {\n\t\tlist_del(&mon_mpdu->list);\n\n\t\ttmp_msdu = mon_mpdu->head;\n\t\twhile (tmp_msdu) {\n\t\t\tskb_next = tmp_msdu->next;\n\t\t\tdev_kfree_skb_any(tmp_msdu);\n\t\t\ttmp_msdu = skb_next;\n\t\t}\n\n\t\tkfree(mon_mpdu);\n\t}\n}\n\nstatic int ath11k_dp_rx_full_mon_deliver_ppdu(struct ath11k *ar,\n\t\t\t\t\t      int mac_id,\n\t\t\t\t\t      struct ath11k_mon_data *pmon,\n\t\t\t\t\t      struct napi_struct *napi)\n{\n\tstruct ath11k_pdev_mon_stats *rx_mon_stats;\n\tstruct dp_full_mon_mpdu *tmp;\n\tstruct dp_full_mon_mpdu *mon_mpdu = pmon->mon_mpdu;\n\tstruct sk_buff *head_msdu, *tail_msdu;\n\tstruct ath11k_base *ab = ar->ab;\n\tstruct ath11k_dp *dp = &ab->dp;\n\tint ret;\n\n\trx_mon_stats = &pmon->rx_mon_stats;\n\n\tlist_for_each_entry_safe(mon_mpdu, tmp, &dp->dp_full_mon_mpdu_list, list) {\n\t\tlist_del(&mon_mpdu->list);\n\t\thead_msdu = mon_mpdu->head;\n\t\ttail_msdu = mon_mpdu->tail;\n\t\tif (head_msdu && tail_msdu) {\n\t\t\tret = ath11k_dp_rx_mon_deliver(ar, mac_id, head_msdu,\n\t\t\t\t\t\t       &pmon->mon_ppdu_info,\n\t\t\t\t\t\t       tail_msdu, napi);\n\t\t\trx_mon_stats->dest_mpdu_done++;\n\t\t\tath11k_dbg(ar->ab, ATH11K_DBG_DATA, \"full mon: deliver ppdu\\n\");\n\t\t}\n\t\tkfree(mon_mpdu);\n\t}\n\n\treturn ret;\n}\n\nstatic int\nath11k_dp_rx_process_full_mon_status_ring(struct ath11k_base *ab, int mac_id,\n\t\t\t\t\t  struct napi_struct *napi, int budget)\n{\n\tstruct ath11k *ar = ab->pdevs[mac_id].ar;\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = &dp->mon_data;\n\tstruct hal_sw_mon_ring_entries *sw_mon_entries;\n\tint quota = 0, work = 0, count;\n\n\tsw_mon_entries = &pmon->sw_mon_entries;\n\n\twhile (pmon->hold_mon_dst_ring) {\n\t\tquota = ath11k_dp_rx_process_mon_status(ab, mac_id,\n\t\t\t\t\t\t\tnapi, 1);\n\t\tif (pmon->buf_state == DP_MON_STATUS_MATCH) {\n\t\t\tcount = sw_mon_entries->status_buf_count;\n\t\t\tif (count > 1) {\n\t\t\t\tquota += ath11k_dp_rx_process_mon_status(ab, mac_id,\n\t\t\t\t\t\t\t\t\t napi, count);\n\t\t\t}\n\n\t\t\tath11k_dp_rx_full_mon_deliver_ppdu(ar, dp->mac_id,\n\t\t\t\t\t\t\t   pmon, napi);\n\t\t\tpmon->hold_mon_dst_ring = false;\n\t\t} else if (!pmon->mon_status_paddr ||\n\t\t\t   pmon->buf_state == DP_MON_STATUS_LEAD) {\n\t\t\tsw_mon_entries->drop_ppdu = true;\n\t\t\tpmon->hold_mon_dst_ring = false;\n\t\t}\n\n\t\tif (!quota)\n\t\t\tbreak;\n\n\t\twork += quota;\n\t}\n\n\tif (sw_mon_entries->drop_ppdu)\n\t\tath11k_dp_rx_full_mon_drop_ppdu(&ab->dp, pmon->mon_mpdu);\n\n\treturn work;\n}\n\nstatic int ath11k_dp_full_mon_process_rx(struct ath11k_base *ab, int mac_id,\n\t\t\t\t\t struct napi_struct *napi, int budget)\n{\n\tstruct ath11k *ar = ab->pdevs[mac_id].ar;\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = &dp->mon_data;\n\tstruct hal_sw_mon_ring_entries *sw_mon_entries;\n\tstruct ath11k_pdev_mon_stats *rx_mon_stats;\n\tstruct sk_buff *head_msdu, *tail_msdu;\n\tvoid *mon_dst_srng = &ar->ab->hal.srng_list[dp->rxdma_mon_dst_ring.ring_id];\n\tvoid *ring_entry;\n\tu32 rx_bufs_used = 0, mpdu_rx_bufs_used;\n\tint quota = 0, ret;\n\tbool break_dst_ring = false;\n\n\tspin_lock_bh(&pmon->mon_lock);\n\n\tsw_mon_entries = &pmon->sw_mon_entries;\n\trx_mon_stats = &pmon->rx_mon_stats;\n\n\tif (pmon->hold_mon_dst_ring) {\n\t\tspin_unlock_bh(&pmon->mon_lock);\n\t\tgoto reap_status_ring;\n\t}\n\n\tath11k_hal_srng_access_begin(ar->ab, mon_dst_srng);\n\twhile ((ring_entry = ath11k_hal_srng_dst_peek(ar->ab, mon_dst_srng))) {\n\t\thead_msdu = NULL;\n\t\ttail_msdu = NULL;\n\n\t\tmpdu_rx_bufs_used = ath11k_dp_rx_full_mon_mpdu_pop(ar, ring_entry,\n\t\t\t\t\t\t\t\t   &head_msdu,\n\t\t\t\t\t\t\t\t   &tail_msdu,\n\t\t\t\t\t\t\t\t   sw_mon_entries);\n\t\trx_bufs_used += mpdu_rx_bufs_used;\n\n\t\tif (!sw_mon_entries->end_of_ppdu) {\n\t\t\tif (head_msdu) {\n\t\t\t\tret = ath11k_dp_rx_full_mon_prepare_mpdu(&ab->dp,\n\t\t\t\t\t\t\t\t\t pmon->mon_mpdu,\n\t\t\t\t\t\t\t\t\t head_msdu,\n\t\t\t\t\t\t\t\t\t tail_msdu);\n\t\t\t\tif (ret)\n\t\t\t\t\tbreak_dst_ring = true;\n\t\t\t}\n\n\t\t\tgoto next_entry;\n\t\t} else {\n\t\t\tif (!sw_mon_entries->ppdu_id &&\n\t\t\t    !sw_mon_entries->mon_status_paddr) {\n\t\t\t\tbreak_dst_ring = true;\n\t\t\t\tgoto next_entry;\n\t\t\t}\n\t\t}\n\n\t\trx_mon_stats->dest_ppdu_done++;\n\t\tpmon->mon_ppdu_status = DP_PPDU_STATUS_START;\n\t\tpmon->buf_state = DP_MON_STATUS_LAG;\n\t\tpmon->mon_status_paddr = sw_mon_entries->mon_status_paddr;\n\t\tpmon->hold_mon_dst_ring = true;\nnext_entry:\n\t\tring_entry = ath11k_hal_srng_dst_get_next_entry(ar->ab,\n\t\t\t\t\t\t\t\tmon_dst_srng);\n\t\tif (break_dst_ring)\n\t\t\tbreak;\n\t}\n\n\tath11k_hal_srng_access_end(ar->ab, mon_dst_srng);\n\tspin_unlock_bh(&pmon->mon_lock);\n\n\tif (rx_bufs_used) {\n\t\tath11k_dp_rxbufs_replenish(ar->ab, dp->mac_id,\n\t\t\t\t\t   &dp->rxdma_mon_buf_ring,\n\t\t\t\t\t   rx_bufs_used,\n\t\t\t\t\t   HAL_RX_BUF_RBM_SW3_BM);\n\t}\n\nreap_status_ring:\n\tquota = ath11k_dp_rx_process_full_mon_status_ring(ab, mac_id,\n\t\t\t\t\t\t\t  napi, budget);\n\n\treturn quota;\n}\n\nint ath11k_dp_rx_process_mon_rings(struct ath11k_base *ab, int mac_id,\n\t\t\t\t   struct napi_struct *napi, int budget)\n{\n\tstruct ath11k *ar = ath11k_ab_to_ar(ab, mac_id);\n\tint ret = 0;\n\n\tif (test_bit(ATH11K_FLAG_MONITOR_STARTED, &ar->monitor_flags) &&\n\t    ab->hw_params.full_monitor_mode)\n\t\tret = ath11k_dp_full_mon_process_rx(ab, mac_id, napi, budget);\n\telse\n\t\tret = ath11k_dp_rx_process_mon_status(ab, mac_id, napi, budget);\n\n\treturn ret;\n}\n\nstatic int ath11k_dp_rx_pdev_mon_status_attach(struct ath11k *ar)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = (struct ath11k_mon_data *)&dp->mon_data;\n\n\tskb_queue_head_init(&pmon->rx_status_q);\n\n\tpmon->mon_ppdu_status = DP_PPDU_STATUS_START;\n\n\tmemset(&pmon->rx_mon_stats, 0,\n\t       sizeof(pmon->rx_mon_stats));\n\treturn 0;\n}\n\nint ath11k_dp_rx_pdev_mon_attach(struct ath11k *ar)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = &dp->mon_data;\n\tstruct hal_srng *mon_desc_srng = NULL;\n\tstruct dp_srng *dp_srng;\n\tint ret = 0;\n\tu32 n_link_desc = 0;\n\n\tret = ath11k_dp_rx_pdev_mon_status_attach(ar);\n\tif (ret) {\n\t\tath11k_warn(ar->ab, \"pdev_mon_status_attach() failed\");\n\t\treturn ret;\n\t}\n\n\t \n\tif (!ar->ab->hw_params.rxdma1_enable)\n\t\treturn 0;\n\n\tdp_srng = &dp->rxdma_mon_desc_ring;\n\tn_link_desc = dp_srng->size /\n\t\tath11k_hal_srng_get_entrysize(ar->ab, HAL_RXDMA_MONITOR_DESC);\n\tmon_desc_srng =\n\t\t&ar->ab->hal.srng_list[dp->rxdma_mon_desc_ring.ring_id];\n\n\tret = ath11k_dp_link_desc_setup(ar->ab, pmon->link_desc_banks,\n\t\t\t\t\tHAL_RXDMA_MONITOR_DESC, mon_desc_srng,\n\t\t\t\t\tn_link_desc);\n\tif (ret) {\n\t\tath11k_warn(ar->ab, \"mon_link_desc_pool_setup() failed\");\n\t\treturn ret;\n\t}\n\tpmon->mon_last_linkdesc_paddr = 0;\n\tpmon->mon_last_buf_cookie = DP_RX_DESC_COOKIE_MAX + 1;\n\tspin_lock_init(&pmon->mon_lock);\n\n\treturn 0;\n}\n\nstatic int ath11k_dp_mon_link_free(struct ath11k *ar)\n{\n\tstruct ath11k_pdev_dp *dp = &ar->dp;\n\tstruct ath11k_mon_data *pmon = &dp->mon_data;\n\n\tath11k_dp_link_desc_cleanup(ar->ab, pmon->link_desc_banks,\n\t\t\t\t    HAL_RXDMA_MONITOR_DESC,\n\t\t\t\t    &dp->rxdma_mon_desc_ring);\n\treturn 0;\n}\n\nint ath11k_dp_rx_pdev_mon_detach(struct ath11k *ar)\n{\n\tath11k_dp_mon_link_free(ar);\n\treturn 0;\n}\n\nint ath11k_dp_rx_pktlog_start(struct ath11k_base *ab)\n{\n\t \n\tmod_timer(&ab->mon_reap_timer,\n\t\t  jiffies + msecs_to_jiffies(ATH11K_MON_TIMER_INTERVAL));\n\n\treturn 0;\n}\n\nint ath11k_dp_rx_pktlog_stop(struct ath11k_base *ab, bool stop_timer)\n{\n\tint ret;\n\n\tif (stop_timer)\n\t\tdel_timer_sync(&ab->mon_reap_timer);\n\n\t \n\tret = ath11k_dp_purge_mon_ring(ab);\n\tif (ret) {\n\t\tath11k_warn(ab, \"failed to purge dp mon ring: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}