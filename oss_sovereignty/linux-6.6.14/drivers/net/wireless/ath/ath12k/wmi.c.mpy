{
  "module_name": "wmi.c",
  "hash_id": "a856aad05d74678bf18829f2bfa22cea9d1dadb176900f85741baeacf32c9cfd",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ath/ath12k/wmi.c",
  "human_readable_source": "\n \n#include <linux/skbuff.h>\n#include <linux/ctype.h>\n#include <net/mac80211.h>\n#include <net/cfg80211.h>\n#include <linux/completion.h>\n#include <linux/if_ether.h>\n#include <linux/types.h>\n#include <linux/pci.h>\n#include <linux/uuid.h>\n#include <linux/time.h>\n#include <linux/of.h>\n#include \"core.h\"\n#include \"debug.h\"\n#include \"mac.h\"\n#include \"hw.h\"\n#include \"peer.h\"\n\nstruct ath12k_wmi_svc_ready_parse {\n\tbool wmi_svc_bitmap_done;\n};\n\nstruct ath12k_wmi_dma_ring_caps_parse {\n\tstruct ath12k_wmi_dma_ring_caps_params *dma_ring_caps;\n\tu32 n_dma_ring_caps;\n};\n\nstruct ath12k_wmi_service_ext_arg {\n\tu32 default_conc_scan_config_bits;\n\tu32 default_fw_config_bits;\n\tstruct ath12k_wmi_ppe_threshold_arg ppet;\n\tu32 he_cap_info;\n\tu32 mpdu_density;\n\tu32 max_bssid_rx_filters;\n\tu32 num_hw_modes;\n\tu32 num_phy;\n};\n\nstruct ath12k_wmi_svc_rdy_ext_parse {\n\tstruct ath12k_wmi_service_ext_arg arg;\n\tconst struct ath12k_wmi_soc_mac_phy_hw_mode_caps_params *hw_caps;\n\tconst struct ath12k_wmi_hw_mode_cap_params *hw_mode_caps;\n\tu32 n_hw_mode_caps;\n\tu32 tot_phy_id;\n\tstruct ath12k_wmi_hw_mode_cap_params pref_hw_mode_caps;\n\tstruct ath12k_wmi_mac_phy_caps_params *mac_phy_caps;\n\tu32 n_mac_phy_caps;\n\tconst struct ath12k_wmi_soc_hal_reg_caps_params *soc_hal_reg_caps;\n\tconst struct ath12k_wmi_hal_reg_caps_ext_params *ext_hal_reg_caps;\n\tu32 n_ext_hal_reg_caps;\n\tstruct ath12k_wmi_dma_ring_caps_parse dma_caps_parse;\n\tbool hw_mode_done;\n\tbool mac_phy_done;\n\tbool ext_hal_reg_done;\n\tbool mac_phy_chainmask_combo_done;\n\tbool mac_phy_chainmask_cap_done;\n\tbool oem_dma_ring_cap_done;\n\tbool dma_ring_cap_done;\n};\n\nstruct ath12k_wmi_svc_rdy_ext2_arg {\n\tu32 reg_db_version;\n\tu32 hw_min_max_tx_power_2ghz;\n\tu32 hw_min_max_tx_power_5ghz;\n\tu32 chwidth_num_peer_caps;\n\tu32 preamble_puncture_bw;\n\tu32 max_user_per_ppdu_ofdma;\n\tu32 max_user_per_ppdu_mumimo;\n\tu32 target_cap_flags;\n\tu32 eht_cap_mac_info[WMI_MAX_EHTCAP_MAC_SIZE];\n\tu32 max_num_linkview_peers;\n\tu32 max_num_msduq_supported_per_tid;\n\tu32 default_num_msduq_supported_per_tid;\n};\n\nstruct ath12k_wmi_svc_rdy_ext2_parse {\n\tstruct ath12k_wmi_svc_rdy_ext2_arg arg;\n\tstruct ath12k_wmi_dma_ring_caps_parse dma_caps_parse;\n\tbool dma_ring_cap_done;\n\tbool spectral_bin_scaling_done;\n\tbool mac_phy_caps_ext_done;\n};\n\nstruct ath12k_wmi_rdy_parse {\n\tu32 num_extra_mac_addr;\n};\n\nstruct ath12k_wmi_dma_buf_release_arg {\n\tstruct ath12k_wmi_dma_buf_release_fixed_params fixed;\n\tconst struct ath12k_wmi_dma_buf_release_entry_params *buf_entry;\n\tconst struct ath12k_wmi_dma_buf_release_meta_data_params *meta_data;\n\tu32 num_buf_entry;\n\tu32 num_meta;\n\tbool buf_entry_done;\n\tbool meta_data_done;\n};\n\nstruct ath12k_wmi_tlv_policy {\n\tsize_t min_len;\n};\n\nstruct wmi_tlv_mgmt_rx_parse {\n\tconst struct ath12k_wmi_mgmt_rx_params *fixed;\n\tconst u8 *frame_buf;\n\tbool frame_buf_done;\n};\n\nstatic const struct ath12k_wmi_tlv_policy ath12k_wmi_tlv_policies[] = {\n\t[WMI_TAG_ARRAY_BYTE] = { .min_len = 0 },\n\t[WMI_TAG_ARRAY_UINT32] = { .min_len = 0 },\n\t[WMI_TAG_SERVICE_READY_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_service_ready_event) },\n\t[WMI_TAG_SERVICE_READY_EXT_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_service_ready_ext_event) },\n\t[WMI_TAG_SOC_MAC_PHY_HW_MODE_CAPS] = {\n\t\t.min_len = sizeof(struct ath12k_wmi_soc_mac_phy_hw_mode_caps_params) },\n\t[WMI_TAG_SOC_HAL_REG_CAPABILITIES] = {\n\t\t.min_len = sizeof(struct ath12k_wmi_soc_hal_reg_caps_params) },\n\t[WMI_TAG_VDEV_START_RESPONSE_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_vdev_start_resp_event) },\n\t[WMI_TAG_PEER_DELETE_RESP_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_peer_delete_resp_event) },\n\t[WMI_TAG_OFFLOAD_BCN_TX_STATUS_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_bcn_tx_status_event) },\n\t[WMI_TAG_VDEV_STOPPED_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_vdev_stopped_event) },\n\t[WMI_TAG_REG_CHAN_LIST_CC_EXT_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_reg_chan_list_cc_ext_event) },\n\t[WMI_TAG_MGMT_RX_HDR] = {\n\t\t.min_len = sizeof(struct ath12k_wmi_mgmt_rx_params) },\n\t[WMI_TAG_MGMT_TX_COMPL_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_mgmt_tx_compl_event) },\n\t[WMI_TAG_SCAN_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_scan_event) },\n\t[WMI_TAG_PEER_STA_KICKOUT_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_peer_sta_kickout_event) },\n\t[WMI_TAG_ROAM_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_roam_event) },\n\t[WMI_TAG_CHAN_INFO_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_chan_info_event) },\n\t[WMI_TAG_PDEV_BSS_CHAN_INFO_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_pdev_bss_chan_info_event) },\n\t[WMI_TAG_VDEV_INSTALL_KEY_COMPLETE_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_vdev_install_key_compl_event) },\n\t[WMI_TAG_READY_EVENT] = {\n\t\t.min_len = sizeof(struct ath12k_wmi_ready_event_min_params) },\n\t[WMI_TAG_SERVICE_AVAILABLE_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_service_available_event) },\n\t[WMI_TAG_PEER_ASSOC_CONF_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_peer_assoc_conf_event) },\n\t[WMI_TAG_PDEV_CTL_FAILSAFE_CHECK_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_pdev_ctl_failsafe_chk_event) },\n\t[WMI_TAG_HOST_SWFDA_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_fils_discovery_event) },\n\t[WMI_TAG_OFFLOAD_PRB_RSP_TX_STATUS_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_probe_resp_tx_status_event) },\n\t[WMI_TAG_VDEV_DELETE_RESP_EVENT] = {\n\t\t.min_len = sizeof(struct wmi_vdev_delete_resp_event) },\n};\n\nstatic __le32 ath12k_wmi_tlv_hdr(u32 cmd, u32 len)\n{\n\treturn le32_encode_bits(cmd, WMI_TLV_TAG) |\n\t\tle32_encode_bits(len, WMI_TLV_LEN);\n}\n\nstatic __le32 ath12k_wmi_tlv_cmd_hdr(u32 cmd, u32 len)\n{\n\treturn ath12k_wmi_tlv_hdr(cmd, len - TLV_HDR_SIZE);\n}\n\nvoid ath12k_wmi_init_qcn9274(struct ath12k_base *ab,\n\t\t\t     struct ath12k_wmi_resource_config_arg *config)\n{\n\tconfig->num_vdevs = ab->num_radios * TARGET_NUM_VDEVS;\n\n\tif (ab->num_radios == 2) {\n\t\tconfig->num_peers = TARGET_NUM_PEERS(DBS);\n\t\tconfig->num_tids = TARGET_NUM_TIDS(DBS);\n\t} else if (ab->num_radios == 3) {\n\t\tconfig->num_peers = TARGET_NUM_PEERS(DBS_SBS);\n\t\tconfig->num_tids = TARGET_NUM_TIDS(DBS_SBS);\n\t} else {\n\t\t \n\t\tconfig->num_peers = TARGET_NUM_PEERS(SINGLE);\n\t\tconfig->num_tids = TARGET_NUM_TIDS(SINGLE);\n\t}\n\tconfig->num_offload_peers = TARGET_NUM_OFFLD_PEERS;\n\tconfig->num_offload_reorder_buffs = TARGET_NUM_OFFLD_REORDER_BUFFS;\n\tconfig->num_peer_keys = TARGET_NUM_PEER_KEYS;\n\tconfig->ast_skid_limit = TARGET_AST_SKID_LIMIT;\n\tconfig->tx_chain_mask = (1 << ab->target_caps.num_rf_chains) - 1;\n\tconfig->rx_chain_mask = (1 << ab->target_caps.num_rf_chains) - 1;\n\tconfig->rx_timeout_pri[0] = TARGET_RX_TIMEOUT_LO_PRI;\n\tconfig->rx_timeout_pri[1] = TARGET_RX_TIMEOUT_LO_PRI;\n\tconfig->rx_timeout_pri[2] = TARGET_RX_TIMEOUT_LO_PRI;\n\tconfig->rx_timeout_pri[3] = TARGET_RX_TIMEOUT_HI_PRI;\n\n\tif (test_bit(ATH12K_FLAG_RAW_MODE, &ab->dev_flags))\n\t\tconfig->rx_decap_mode = TARGET_DECAP_MODE_RAW;\n\telse\n\t\tconfig->rx_decap_mode = TARGET_DECAP_MODE_NATIVE_WIFI;\n\n\tconfig->scan_max_pending_req = TARGET_SCAN_MAX_PENDING_REQS;\n\tconfig->bmiss_offload_max_vdev = TARGET_BMISS_OFFLOAD_MAX_VDEV;\n\tconfig->roam_offload_max_vdev = TARGET_ROAM_OFFLOAD_MAX_VDEV;\n\tconfig->roam_offload_max_ap_profiles = TARGET_ROAM_OFFLOAD_MAX_AP_PROFILES;\n\tconfig->num_mcast_groups = TARGET_NUM_MCAST_GROUPS;\n\tconfig->num_mcast_table_elems = TARGET_NUM_MCAST_TABLE_ELEMS;\n\tconfig->mcast2ucast_mode = TARGET_MCAST2UCAST_MODE;\n\tconfig->tx_dbg_log_size = TARGET_TX_DBG_LOG_SIZE;\n\tconfig->num_wds_entries = TARGET_NUM_WDS_ENTRIES;\n\tconfig->dma_burst_size = TARGET_DMA_BURST_SIZE;\n\tconfig->rx_skip_defrag_timeout_dup_detection_check =\n\t\tTARGET_RX_SKIP_DEFRAG_TIMEOUT_DUP_DETECTION_CHECK;\n\tconfig->vow_config = TARGET_VOW_CONFIG;\n\tconfig->gtk_offload_max_vdev = TARGET_GTK_OFFLOAD_MAX_VDEV;\n\tconfig->num_msdu_desc = TARGET_NUM_MSDU_DESC;\n\tconfig->beacon_tx_offload_max_vdev = ab->num_radios * TARGET_MAX_BCN_OFFLD;\n\tconfig->rx_batchmode = TARGET_RX_BATCHMODE;\n\t \n\tconfig->peer_map_unmap_version = 0x32;\n\tconfig->twt_ap_pdev_count = ab->num_radios;\n\tconfig->twt_ap_sta_count = 1000;\n}\n\nvoid ath12k_wmi_init_wcn7850(struct ath12k_base *ab,\n\t\t\t     struct ath12k_wmi_resource_config_arg *config)\n{\n\tconfig->num_vdevs = 4;\n\tconfig->num_peers = 16;\n\tconfig->num_tids = 32;\n\n\tconfig->num_offload_peers = 3;\n\tconfig->num_offload_reorder_buffs = 3;\n\tconfig->num_peer_keys = TARGET_NUM_PEER_KEYS;\n\tconfig->ast_skid_limit = TARGET_AST_SKID_LIMIT;\n\tconfig->tx_chain_mask = (1 << ab->target_caps.num_rf_chains) - 1;\n\tconfig->rx_chain_mask = (1 << ab->target_caps.num_rf_chains) - 1;\n\tconfig->rx_timeout_pri[0] = TARGET_RX_TIMEOUT_LO_PRI;\n\tconfig->rx_timeout_pri[1] = TARGET_RX_TIMEOUT_LO_PRI;\n\tconfig->rx_timeout_pri[2] = TARGET_RX_TIMEOUT_LO_PRI;\n\tconfig->rx_timeout_pri[3] = TARGET_RX_TIMEOUT_HI_PRI;\n\tconfig->rx_decap_mode = TARGET_DECAP_MODE_NATIVE_WIFI;\n\tconfig->scan_max_pending_req = TARGET_SCAN_MAX_PENDING_REQS;\n\tconfig->bmiss_offload_max_vdev = TARGET_BMISS_OFFLOAD_MAX_VDEV;\n\tconfig->roam_offload_max_vdev = TARGET_ROAM_OFFLOAD_MAX_VDEV;\n\tconfig->roam_offload_max_ap_profiles = TARGET_ROAM_OFFLOAD_MAX_AP_PROFILES;\n\tconfig->num_mcast_groups = 0;\n\tconfig->num_mcast_table_elems = 0;\n\tconfig->mcast2ucast_mode = 0;\n\tconfig->tx_dbg_log_size = TARGET_TX_DBG_LOG_SIZE;\n\tconfig->num_wds_entries = 0;\n\tconfig->dma_burst_size = 0;\n\tconfig->rx_skip_defrag_timeout_dup_detection_check = 0;\n\tconfig->vow_config = TARGET_VOW_CONFIG;\n\tconfig->gtk_offload_max_vdev = 2;\n\tconfig->num_msdu_desc = 0x400;\n\tconfig->beacon_tx_offload_max_vdev = 2;\n\tconfig->rx_batchmode = TARGET_RX_BATCHMODE;\n\n\tconfig->peer_map_unmap_version = 0x1;\n\tconfig->use_pdev_id = 1;\n\tconfig->max_frag_entries = 0xa;\n\tconfig->num_tdls_vdevs = 0x1;\n\tconfig->num_tdls_conn_table_entries = 8;\n\tconfig->beacon_tx_offload_max_vdev = 0x2;\n\tconfig->num_multicast_filter_entries = 0x20;\n\tconfig->num_wow_filters = 0x16;\n\tconfig->num_keep_alive_pattern = 0;\n}\n\n#define PRIMAP(_hw_mode_) \\\n\t[_hw_mode_] = _hw_mode_##_PRI\n\nstatic const int ath12k_hw_mode_pri_map[] = {\n\tPRIMAP(WMI_HOST_HW_MODE_SINGLE),\n\tPRIMAP(WMI_HOST_HW_MODE_DBS),\n\tPRIMAP(WMI_HOST_HW_MODE_SBS_PASSIVE),\n\tPRIMAP(WMI_HOST_HW_MODE_SBS),\n\tPRIMAP(WMI_HOST_HW_MODE_DBS_SBS),\n\tPRIMAP(WMI_HOST_HW_MODE_DBS_OR_SBS),\n\t \n\tPRIMAP(WMI_HOST_HW_MODE_MAX),\n};\n\nstatic int\nath12k_wmi_tlv_iter(struct ath12k_base *ab, const void *ptr, size_t len,\n\t\t    int (*iter)(struct ath12k_base *ab, u16 tag, u16 len,\n\t\t\t\tconst void *ptr, void *data),\n\t\t    void *data)\n{\n\tconst void *begin = ptr;\n\tconst struct wmi_tlv *tlv;\n\tu16 tlv_tag, tlv_len;\n\tint ret;\n\n\twhile (len > 0) {\n\t\tif (len < sizeof(*tlv)) {\n\t\t\tath12k_err(ab, \"wmi tlv parse failure at byte %zd (%zu bytes left, %zu expected)\\n\",\n\t\t\t\t   ptr - begin, len, sizeof(*tlv));\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\ttlv = ptr;\n\t\ttlv_tag = le32_get_bits(tlv->header, WMI_TLV_TAG);\n\t\ttlv_len = le32_get_bits(tlv->header, WMI_TLV_LEN);\n\t\tptr += sizeof(*tlv);\n\t\tlen -= sizeof(*tlv);\n\n\t\tif (tlv_len > len) {\n\t\t\tath12k_err(ab, \"wmi tlv parse failure of tag %u at byte %zd (%zu bytes left, %u expected)\\n\",\n\t\t\t\t   tlv_tag, ptr - begin, len, tlv_len);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (tlv_tag < ARRAY_SIZE(ath12k_wmi_tlv_policies) &&\n\t\t    ath12k_wmi_tlv_policies[tlv_tag].min_len &&\n\t\t    ath12k_wmi_tlv_policies[tlv_tag].min_len > tlv_len) {\n\t\t\tath12k_err(ab, \"wmi tlv parse failure of tag %u at byte %zd (%u bytes is less than min length %zu)\\n\",\n\t\t\t\t   tlv_tag, ptr - begin, tlv_len,\n\t\t\t\t   ath12k_wmi_tlv_policies[tlv_tag].min_len);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tret = iter(ab, tlv_tag, tlv_len, ptr, data);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tptr += tlv_len;\n\t\tlen -= tlv_len;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_tlv_iter_parse(struct ath12k_base *ab, u16 tag, u16 len,\n\t\t\t\t     const void *ptr, void *data)\n{\n\tconst void **tb = data;\n\n\tif (tag < WMI_TAG_MAX)\n\t\ttb[tag] = ptr;\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_tlv_parse(struct ath12k_base *ar, const void **tb,\n\t\t\t\tconst void *ptr, size_t len)\n{\n\treturn ath12k_wmi_tlv_iter(ar, ptr, len, ath12k_wmi_tlv_iter_parse,\n\t\t\t\t   (void *)tb);\n}\n\nstatic const void **\nath12k_wmi_tlv_parse_alloc(struct ath12k_base *ab, const void *ptr,\n\t\t\t   size_t len, gfp_t gfp)\n{\n\tconst void **tb;\n\tint ret;\n\n\ttb = kcalloc(WMI_TAG_MAX, sizeof(*tb), gfp);\n\tif (!tb)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tret = ath12k_wmi_tlv_parse(ab, tb, ptr, len);\n\tif (ret) {\n\t\tkfree(tb);\n\t\treturn ERR_PTR(ret);\n\t}\n\n\treturn tb;\n}\n\nstatic int ath12k_wmi_cmd_send_nowait(struct ath12k_wmi_pdev *wmi, struct sk_buff *skb,\n\t\t\t\t      u32 cmd_id)\n{\n\tstruct ath12k_skb_cb *skb_cb = ATH12K_SKB_CB(skb);\n\tstruct ath12k_base *ab = wmi->wmi_ab->ab;\n\tstruct wmi_cmd_hdr *cmd_hdr;\n\tint ret;\n\n\tif (!skb_push(skb, sizeof(struct wmi_cmd_hdr)))\n\t\treturn -ENOMEM;\n\n\tcmd_hdr = (struct wmi_cmd_hdr *)skb->data;\n\tcmd_hdr->cmd_id = le32_encode_bits(cmd_id, WMI_CMD_HDR_CMD_ID);\n\n\tmemset(skb_cb, 0, sizeof(*skb_cb));\n\tret = ath12k_htc_send(&ab->htc, wmi->eid, skb);\n\n\tif (ret)\n\t\tgoto err_pull;\n\n\treturn 0;\n\nerr_pull:\n\tskb_pull(skb, sizeof(struct wmi_cmd_hdr));\n\treturn ret;\n}\n\nint ath12k_wmi_cmd_send(struct ath12k_wmi_pdev *wmi, struct sk_buff *skb,\n\t\t\tu32 cmd_id)\n{\n\tstruct ath12k_wmi_base *wmi_sc = wmi->wmi_ab;\n\tint ret = -EOPNOTSUPP;\n\n\tmight_sleep();\n\n\twait_event_timeout(wmi_sc->tx_credits_wq, ({\n\t\tret = ath12k_wmi_cmd_send_nowait(wmi, skb, cmd_id);\n\n\t\tif (ret && test_bit(ATH12K_FLAG_CRASH_FLUSH, &wmi_sc->ab->dev_flags))\n\t\t\tret = -ESHUTDOWN;\n\n\t\t(ret != -EAGAIN);\n\t}), WMI_SEND_TIMEOUT_HZ);\n\n\tif (ret == -EAGAIN)\n\t\tath12k_warn(wmi_sc->ab, \"wmi command %d timeout\\n\", cmd_id);\n\n\treturn ret;\n}\n\nstatic int ath12k_pull_svc_ready_ext(struct ath12k_wmi_pdev *wmi_handle,\n\t\t\t\t     const void *ptr,\n\t\t\t\t     struct ath12k_wmi_service_ext_arg *arg)\n{\n\tconst struct wmi_service_ready_ext_event *ev = ptr;\n\tint i;\n\n\tif (!ev)\n\t\treturn -EINVAL;\n\n\t \n\targ->default_conc_scan_config_bits =\n\t\tle32_to_cpu(ev->default_conc_scan_config_bits);\n\targ->default_fw_config_bits = le32_to_cpu(ev->default_fw_config_bits);\n\targ->he_cap_info = le32_to_cpu(ev->he_cap_info);\n\targ->mpdu_density = le32_to_cpu(ev->mpdu_density);\n\targ->max_bssid_rx_filters = le32_to_cpu(ev->max_bssid_rx_filters);\n\targ->ppet.numss_m1 = le32_to_cpu(ev->ppet.numss_m1);\n\targ->ppet.ru_bit_mask = le32_to_cpu(ev->ppet.ru_info);\n\n\tfor (i = 0; i < WMI_MAX_NUM_SS; i++)\n\t\targ->ppet.ppet16_ppet8_ru3_ru0[i] =\n\t\t\tle32_to_cpu(ev->ppet.ppet16_ppet8_ru3_ru0[i]);\n\n\treturn 0;\n}\n\nstatic int\nath12k_pull_mac_phy_cap_svc_ready_ext(struct ath12k_wmi_pdev *wmi_handle,\n\t\t\t\t      struct ath12k_wmi_svc_rdy_ext_parse *svc,\n\t\t\t\t      u8 hw_mode_id, u8 phy_id,\n\t\t\t\t      struct ath12k_pdev *pdev)\n{\n\tconst struct ath12k_wmi_mac_phy_caps_params *mac_caps;\n\tconst struct ath12k_wmi_soc_mac_phy_hw_mode_caps_params *hw_caps = svc->hw_caps;\n\tconst struct ath12k_wmi_hw_mode_cap_params *wmi_hw_mode_caps = svc->hw_mode_caps;\n\tconst struct ath12k_wmi_mac_phy_caps_params *wmi_mac_phy_caps = svc->mac_phy_caps;\n\tstruct ath12k_base *ab = wmi_handle->wmi_ab->ab;\n\tstruct ath12k_band_cap *cap_band;\n\tstruct ath12k_pdev_cap *pdev_cap = &pdev->cap;\n\tstruct ath12k_fw_pdev *fw_pdev;\n\tu32 phy_map;\n\tu32 hw_idx, phy_idx = 0;\n\tint i;\n\n\tif (!hw_caps || !wmi_hw_mode_caps || !svc->soc_hal_reg_caps)\n\t\treturn -EINVAL;\n\n\tfor (hw_idx = 0; hw_idx < le32_to_cpu(hw_caps->num_hw_modes); hw_idx++) {\n\t\tif (hw_mode_id == le32_to_cpu(wmi_hw_mode_caps[hw_idx].hw_mode_id))\n\t\t\tbreak;\n\n\t\tphy_map = le32_to_cpu(wmi_hw_mode_caps[hw_idx].phy_id_map);\n\t\tphy_idx = fls(phy_map);\n\t}\n\n\tif (hw_idx == le32_to_cpu(hw_caps->num_hw_modes))\n\t\treturn -EINVAL;\n\n\tphy_idx += phy_id;\n\tif (phy_id >= le32_to_cpu(svc->soc_hal_reg_caps->num_phy))\n\t\treturn -EINVAL;\n\n\tmac_caps = wmi_mac_phy_caps + phy_idx;\n\n\tpdev->pdev_id = le32_to_cpu(mac_caps->pdev_id);\n\tpdev_cap->supported_bands |= le32_to_cpu(mac_caps->supported_bands);\n\tpdev_cap->ampdu_density = le32_to_cpu(mac_caps->ampdu_density);\n\n\tfw_pdev = &ab->fw_pdev[ab->fw_pdev_count];\n\tfw_pdev->supported_bands = le32_to_cpu(mac_caps->supported_bands);\n\tfw_pdev->pdev_id = le32_to_cpu(mac_caps->pdev_id);\n\tfw_pdev->phy_id = le32_to_cpu(mac_caps->phy_id);\n\tab->fw_pdev_count++;\n\n\t \n\tif (le32_to_cpu(mac_caps->supported_bands) & WMI_HOST_WLAN_2G_CAP) {\n\t\tpdev_cap->tx_chain_mask = le32_to_cpu(mac_caps->tx_chain_mask_2g);\n\t\tpdev_cap->rx_chain_mask = le32_to_cpu(mac_caps->rx_chain_mask_2g);\n\t} else if (le32_to_cpu(mac_caps->supported_bands) & WMI_HOST_WLAN_5G_CAP) {\n\t\tpdev_cap->vht_cap = le32_to_cpu(mac_caps->vht_cap_info_5g);\n\t\tpdev_cap->vht_mcs = le32_to_cpu(mac_caps->vht_supp_mcs_5g);\n\t\tpdev_cap->he_mcs = le32_to_cpu(mac_caps->he_supp_mcs_5g);\n\t\tpdev_cap->tx_chain_mask = le32_to_cpu(mac_caps->tx_chain_mask_5g);\n\t\tpdev_cap->rx_chain_mask = le32_to_cpu(mac_caps->rx_chain_mask_5g);\n\t} else {\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tpdev_cap->tx_chain_mask_shift =\n\t\t\tfind_first_bit((unsigned long *)&pdev_cap->tx_chain_mask, 32);\n\tpdev_cap->rx_chain_mask_shift =\n\t\t\tfind_first_bit((unsigned long *)&pdev_cap->rx_chain_mask, 32);\n\n\tif (le32_to_cpu(mac_caps->supported_bands) & WMI_HOST_WLAN_2G_CAP) {\n\t\tcap_band = &pdev_cap->band[NL80211_BAND_2GHZ];\n\t\tcap_band->phy_id = le32_to_cpu(mac_caps->phy_id);\n\t\tcap_band->max_bw_supported = le32_to_cpu(mac_caps->max_bw_supported_2g);\n\t\tcap_band->ht_cap_info = le32_to_cpu(mac_caps->ht_cap_info_2g);\n\t\tcap_band->he_cap_info[0] = le32_to_cpu(mac_caps->he_cap_info_2g);\n\t\tcap_band->he_cap_info[1] = le32_to_cpu(mac_caps->he_cap_info_2g_ext);\n\t\tcap_band->he_mcs = le32_to_cpu(mac_caps->he_supp_mcs_2g);\n\t\tfor (i = 0; i < WMI_MAX_HECAP_PHY_SIZE; i++)\n\t\t\tcap_band->he_cap_phy_info[i] =\n\t\t\t\tle32_to_cpu(mac_caps->he_cap_phy_info_2g[i]);\n\n\t\tcap_band->he_ppet.numss_m1 = le32_to_cpu(mac_caps->he_ppet2g.numss_m1);\n\t\tcap_band->he_ppet.ru_bit_mask = le32_to_cpu(mac_caps->he_ppet2g.ru_info);\n\n\t\tfor (i = 0; i < WMI_MAX_NUM_SS; i++)\n\t\t\tcap_band->he_ppet.ppet16_ppet8_ru3_ru0[i] =\n\t\t\t\tle32_to_cpu(mac_caps->he_ppet2g.ppet16_ppet8_ru3_ru0[i]);\n\t}\n\n\tif (le32_to_cpu(mac_caps->supported_bands) & WMI_HOST_WLAN_5G_CAP) {\n\t\tcap_band = &pdev_cap->band[NL80211_BAND_5GHZ];\n\t\tcap_band->phy_id = le32_to_cpu(mac_caps->phy_id);\n\t\tcap_band->max_bw_supported =\n\t\t\tle32_to_cpu(mac_caps->max_bw_supported_5g);\n\t\tcap_band->ht_cap_info = le32_to_cpu(mac_caps->ht_cap_info_5g);\n\t\tcap_band->he_cap_info[0] = le32_to_cpu(mac_caps->he_cap_info_5g);\n\t\tcap_band->he_cap_info[1] = le32_to_cpu(mac_caps->he_cap_info_5g_ext);\n\t\tcap_band->he_mcs = le32_to_cpu(mac_caps->he_supp_mcs_5g);\n\t\tfor (i = 0; i < WMI_MAX_HECAP_PHY_SIZE; i++)\n\t\t\tcap_band->he_cap_phy_info[i] =\n\t\t\t\tle32_to_cpu(mac_caps->he_cap_phy_info_5g[i]);\n\n\t\tcap_band->he_ppet.numss_m1 = le32_to_cpu(mac_caps->he_ppet5g.numss_m1);\n\t\tcap_band->he_ppet.ru_bit_mask = le32_to_cpu(mac_caps->he_ppet5g.ru_info);\n\n\t\tfor (i = 0; i < WMI_MAX_NUM_SS; i++)\n\t\t\tcap_band->he_ppet.ppet16_ppet8_ru3_ru0[i] =\n\t\t\t\tle32_to_cpu(mac_caps->he_ppet5g.ppet16_ppet8_ru3_ru0[i]);\n\n\t\tcap_band = &pdev_cap->band[NL80211_BAND_6GHZ];\n\t\tcap_band->max_bw_supported =\n\t\t\tle32_to_cpu(mac_caps->max_bw_supported_5g);\n\t\tcap_band->ht_cap_info = le32_to_cpu(mac_caps->ht_cap_info_5g);\n\t\tcap_band->he_cap_info[0] = le32_to_cpu(mac_caps->he_cap_info_5g);\n\t\tcap_band->he_cap_info[1] = le32_to_cpu(mac_caps->he_cap_info_5g_ext);\n\t\tcap_band->he_mcs = le32_to_cpu(mac_caps->he_supp_mcs_5g);\n\t\tfor (i = 0; i < WMI_MAX_HECAP_PHY_SIZE; i++)\n\t\t\tcap_band->he_cap_phy_info[i] =\n\t\t\t\tle32_to_cpu(mac_caps->he_cap_phy_info_5g[i]);\n\n\t\tcap_band->he_ppet.numss_m1 = le32_to_cpu(mac_caps->he_ppet5g.numss_m1);\n\t\tcap_band->he_ppet.ru_bit_mask = le32_to_cpu(mac_caps->he_ppet5g.ru_info);\n\n\t\tfor (i = 0; i < WMI_MAX_NUM_SS; i++)\n\t\t\tcap_band->he_ppet.ppet16_ppet8_ru3_ru0[i] =\n\t\t\t\tle32_to_cpu(mac_caps->he_ppet5g.ppet16_ppet8_ru3_ru0[i]);\n\t}\n\n\treturn 0;\n}\n\nstatic int\nath12k_pull_reg_cap_svc_rdy_ext(struct ath12k_wmi_pdev *wmi_handle,\n\t\t\t\tconst struct ath12k_wmi_soc_hal_reg_caps_params *reg_caps,\n\t\t\t\tconst struct ath12k_wmi_hal_reg_caps_ext_params *ext_caps,\n\t\t\t\tu8 phy_idx,\n\t\t\t\tstruct ath12k_wmi_hal_reg_capabilities_ext_arg *param)\n{\n\tconst struct ath12k_wmi_hal_reg_caps_ext_params *ext_reg_cap;\n\n\tif (!reg_caps || !ext_caps)\n\t\treturn -EINVAL;\n\n\tif (phy_idx >= le32_to_cpu(reg_caps->num_phy))\n\t\treturn -EINVAL;\n\n\text_reg_cap = &ext_caps[phy_idx];\n\n\tparam->phy_id = le32_to_cpu(ext_reg_cap->phy_id);\n\tparam->eeprom_reg_domain = le32_to_cpu(ext_reg_cap->eeprom_reg_domain);\n\tparam->eeprom_reg_domain_ext =\n\t\tle32_to_cpu(ext_reg_cap->eeprom_reg_domain_ext);\n\tparam->regcap1 = le32_to_cpu(ext_reg_cap->regcap1);\n\tparam->regcap2 = le32_to_cpu(ext_reg_cap->regcap2);\n\t \n\tparam->low_2ghz_chan = le32_to_cpu(ext_reg_cap->low_2ghz_chan);\n\tparam->high_2ghz_chan = le32_to_cpu(ext_reg_cap->high_2ghz_chan);\n\tparam->low_5ghz_chan = le32_to_cpu(ext_reg_cap->low_5ghz_chan);\n\tparam->high_5ghz_chan = le32_to_cpu(ext_reg_cap->high_5ghz_chan);\n\n\treturn 0;\n}\n\nstatic int ath12k_pull_service_ready_tlv(struct ath12k_base *ab,\n\t\t\t\t\t const void *evt_buf,\n\t\t\t\t\t struct ath12k_wmi_target_cap_arg *cap)\n{\n\tconst struct wmi_service_ready_event *ev = evt_buf;\n\n\tif (!ev) {\n\t\tath12k_err(ab, \"%s: failed by NULL param\\n\",\n\t\t\t   __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tcap->phy_capability = le32_to_cpu(ev->phy_capability);\n\tcap->max_frag_entry = le32_to_cpu(ev->max_frag_entry);\n\tcap->num_rf_chains = le32_to_cpu(ev->num_rf_chains);\n\tcap->ht_cap_info = le32_to_cpu(ev->ht_cap_info);\n\tcap->vht_cap_info = le32_to_cpu(ev->vht_cap_info);\n\tcap->vht_supp_mcs = le32_to_cpu(ev->vht_supp_mcs);\n\tcap->hw_min_tx_power = le32_to_cpu(ev->hw_min_tx_power);\n\tcap->hw_max_tx_power = le32_to_cpu(ev->hw_max_tx_power);\n\tcap->sys_cap_info = le32_to_cpu(ev->sys_cap_info);\n\tcap->min_pkt_size_enable = le32_to_cpu(ev->min_pkt_size_enable);\n\tcap->max_bcn_ie_size = le32_to_cpu(ev->max_bcn_ie_size);\n\tcap->max_num_scan_channels = le32_to_cpu(ev->max_num_scan_channels);\n\tcap->max_supported_macs = le32_to_cpu(ev->max_supported_macs);\n\tcap->wmi_fw_sub_feat_caps = le32_to_cpu(ev->wmi_fw_sub_feat_caps);\n\tcap->txrx_chainmask = le32_to_cpu(ev->txrx_chainmask);\n\tcap->default_dbs_hw_mode_index = le32_to_cpu(ev->default_dbs_hw_mode_index);\n\tcap->num_msdu_desc = le32_to_cpu(ev->num_msdu_desc);\n\n\treturn 0;\n}\n\n \nstatic void ath12k_wmi_service_bitmap_copy(struct ath12k_wmi_pdev *wmi,\n\t\t\t\t\t   const u32 *wmi_svc_bm)\n{\n\tint i, j;\n\n\tfor (i = 0, j = 0; i < WMI_SERVICE_BM_SIZE && j < WMI_MAX_SERVICE; i++) {\n\t\tdo {\n\t\t\tif (wmi_svc_bm[i] & BIT(j % WMI_SERVICE_BITS_IN_SIZE32))\n\t\t\t\tset_bit(j, wmi->wmi_ab->svc_map);\n\t\t} while (++j % WMI_SERVICE_BITS_IN_SIZE32);\n\t}\n}\n\nstatic int ath12k_wmi_svc_rdy_parse(struct ath12k_base *ab, u16 tag, u16 len,\n\t\t\t\t    const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_svc_ready_parse *svc_ready = data;\n\tstruct ath12k_wmi_pdev *wmi_handle = &ab->wmi_ab.wmi[0];\n\tu16 expect_len;\n\n\tswitch (tag) {\n\tcase WMI_TAG_SERVICE_READY_EVENT:\n\t\tif (ath12k_pull_service_ready_tlv(ab, ptr, &ab->target_caps))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\n\tcase WMI_TAG_ARRAY_UINT32:\n\t\tif (!svc_ready->wmi_svc_bitmap_done) {\n\t\t\texpect_len = WMI_SERVICE_BM_SIZE * sizeof(u32);\n\t\t\tif (len < expect_len) {\n\t\t\t\tath12k_warn(ab, \"invalid len %d for the tag 0x%x\\n\",\n\t\t\t\t\t    len, tag);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\tath12k_wmi_service_bitmap_copy(wmi_handle, ptr);\n\n\t\t\tsvc_ready->wmi_svc_bitmap_done = true;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath12k_service_ready_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct ath12k_wmi_svc_ready_parse svc_ready = { };\n\tint ret;\n\n\tret = ath12k_wmi_tlv_iter(ab, skb->data, skb->len,\n\t\t\t\t  ath12k_wmi_svc_rdy_parse,\n\t\t\t\t  &svc_ready);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to parse tlv %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstruct sk_buff *ath12k_wmi_alloc_skb(struct ath12k_wmi_base *wmi_sc, u32 len)\n{\n\tstruct sk_buff *skb;\n\tstruct ath12k_base *ab = wmi_sc->ab;\n\tu32 round_len = roundup(len, 4);\n\n\tskb = ath12k_htc_alloc_skb(ab, WMI_SKB_HEADROOM + round_len);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, WMI_SKB_HEADROOM);\n\tif (!IS_ALIGNED((unsigned long)skb->data, 4))\n\t\tath12k_warn(ab, \"unaligned WMI skb data\\n\");\n\n\tskb_put(skb, round_len);\n\tmemset(skb->data, 0, round_len);\n\n\treturn skb;\n}\n\nint ath12k_wmi_mgmt_send(struct ath12k *ar, u32 vdev_id, u32 buf_id,\n\t\t\t struct sk_buff *frame)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_mgmt_send_cmd *cmd;\n\tstruct wmi_tlv *frame_tlv;\n\tstruct sk_buff *skb;\n\tu32 buf_len;\n\tint ret, len;\n\n\tbuf_len = min_t(int, frame->len, WMI_MGMT_SEND_DOWNLD_LEN);\n\n\tlen = sizeof(*cmd) + sizeof(*frame_tlv) + roundup(buf_len, 4);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_mgmt_send_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_MGMT_TX_SEND_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->desc_id = cpu_to_le32(buf_id);\n\tcmd->chanfreq = 0;\n\tcmd->paddr_lo = cpu_to_le32(lower_32_bits(ATH12K_SKB_CB(frame)->paddr));\n\tcmd->paddr_hi = cpu_to_le32(upper_32_bits(ATH12K_SKB_CB(frame)->paddr));\n\tcmd->frame_len = cpu_to_le32(frame->len);\n\tcmd->buf_len = cpu_to_le32(buf_len);\n\tcmd->tx_params_valid = 0;\n\n\tframe_tlv = (struct wmi_tlv *)(skb->data + sizeof(*cmd));\n\tframe_tlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, buf_len);\n\n\tmemcpy(frame_tlv->value, frame->data, buf_len);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_MGMT_TX_SEND_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to submit WMI_MGMT_TX_SEND_CMDID cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_create(struct ath12k *ar, u8 *macaddr,\n\t\t\t   struct ath12k_wmi_vdev_create_arg *args)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_create_cmd *cmd;\n\tstruct sk_buff *skb;\n\tstruct ath12k_wmi_vdev_txrx_streams_params *txrx_streams;\n\tstruct wmi_tlv *tlv;\n\tint ret, len;\n\tvoid *ptr;\n\n\t \n\tlen = sizeof(*cmd) + TLV_HDR_SIZE +\n\t\t(WMI_NUM_SUPPORTED_BAND_MAX * sizeof(*txrx_streams));\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_create_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_CREATE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(args->if_id);\n\tcmd->vdev_type = cpu_to_le32(args->type);\n\tcmd->vdev_subtype = cpu_to_le32(args->subtype);\n\tcmd->num_cfg_txrx_streams = cpu_to_le32(WMI_NUM_SUPPORTED_BAND_MAX);\n\tcmd->pdev_id = cpu_to_le32(args->pdev_id);\n\tcmd->vdev_stats_id = cpu_to_le32(args->if_stats_id);\n\tether_addr_copy(cmd->vdev_macaddr.addr, macaddr);\n\n\tptr = skb->data + sizeof(*cmd);\n\tlen = WMI_NUM_SUPPORTED_BAND_MAX * sizeof(*txrx_streams);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, len);\n\n\tptr += TLV_HDR_SIZE;\n\ttxrx_streams = ptr;\n\tlen = sizeof(*txrx_streams);\n\ttxrx_streams->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_TXRX_STREAMS,\n\t\t\t\t\t\t\t  len);\n\ttxrx_streams->band = WMI_TPC_CHAINMASK_CONFIG_BAND_2G;\n\ttxrx_streams->supported_tx_streams =\n\t\t\t\t args->chains[NL80211_BAND_2GHZ].tx;\n\ttxrx_streams->supported_rx_streams =\n\t\t\t\t args->chains[NL80211_BAND_2GHZ].rx;\n\n\ttxrx_streams++;\n\ttxrx_streams->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_TXRX_STREAMS,\n\t\t\t\t\t\t\t  len);\n\ttxrx_streams->band = WMI_TPC_CHAINMASK_CONFIG_BAND_5G;\n\ttxrx_streams->supported_tx_streams =\n\t\t\t\t args->chains[NL80211_BAND_5GHZ].tx;\n\ttxrx_streams->supported_rx_streams =\n\t\t\t\t args->chains[NL80211_BAND_5GHZ].rx;\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev create: id %d type %d subtype %d macaddr %pM pdevid %d\\n\",\n\t\t   args->if_id, args->type, args->subtype,\n\t\t   macaddr, args->pdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_VDEV_CREATE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to submit WMI_VDEV_CREATE_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_delete(struct ath12k *ar, u8 vdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_delete_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_delete_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_DELETE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI, \"WMI vdev delete id %d\\n\", vdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_VDEV_DELETE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to submit WMI_VDEV_DELETE_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_stop(struct ath12k *ar, u8 vdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_stop_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_stop_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_STOP_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI, \"WMI vdev stop id 0x%x\\n\", vdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_VDEV_STOP_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to submit WMI_VDEV_STOP cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_down(struct ath12k *ar, u8 vdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_down_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_down_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_DOWN_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI, \"WMI vdev down id 0x%x\\n\", vdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_VDEV_DOWN_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to submit WMI_VDEV_DOWN cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nstatic void ath12k_wmi_put_wmi_channel(struct ath12k_wmi_channel_params *chan,\n\t\t\t\t       struct wmi_vdev_start_req_arg *arg)\n{\n\tmemset(chan, 0, sizeof(*chan));\n\n\tchan->mhz = cpu_to_le32(arg->freq);\n\tchan->band_center_freq1 = cpu_to_le32(arg->band_center_freq1);\n\tif (arg->mode == MODE_11AC_VHT80_80)\n\t\tchan->band_center_freq2 = cpu_to_le32(arg->band_center_freq2);\n\telse\n\t\tchan->band_center_freq2 = 0;\n\n\tchan->info |= le32_encode_bits(arg->mode, WMI_CHAN_INFO_MODE);\n\tif (arg->passive)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_PASSIVE);\n\tif (arg->allow_ibss)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_ADHOC_ALLOWED);\n\tif (arg->allow_ht)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_ALLOW_HT);\n\tif (arg->allow_vht)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_ALLOW_VHT);\n\tif (arg->allow_he)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_ALLOW_HE);\n\tif (arg->ht40plus)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_HT40_PLUS);\n\tif (arg->chan_radar)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_DFS);\n\tif (arg->freq2_radar)\n\t\tchan->info |= cpu_to_le32(WMI_CHAN_INFO_DFS_FREQ2);\n\n\tchan->reg_info_1 = le32_encode_bits(arg->max_power,\n\t\t\t\t\t    WMI_CHAN_REG_INFO1_MAX_PWR) |\n\t\tle32_encode_bits(arg->max_reg_power,\n\t\t\t\t WMI_CHAN_REG_INFO1_MAX_REG_PWR);\n\n\tchan->reg_info_2 = le32_encode_bits(arg->max_antenna_gain,\n\t\t\t\t\t    WMI_CHAN_REG_INFO2_ANT_MAX) |\n\t\tle32_encode_bits(arg->max_power, WMI_CHAN_REG_INFO2_MAX_TX_PWR);\n}\n\nint ath12k_wmi_vdev_start(struct ath12k *ar, struct wmi_vdev_start_req_arg *arg,\n\t\t\t  bool restart)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_start_request_cmd *cmd;\n\tstruct sk_buff *skb;\n\tstruct ath12k_wmi_channel_params *chan;\n\tstruct wmi_tlv *tlv;\n\tvoid *ptr;\n\tint ret, len;\n\n\tif (WARN_ON(arg->ssid_len > sizeof(cmd->ssid.ssid)))\n\t\treturn -EINVAL;\n\n\tlen = sizeof(*cmd) + sizeof(*chan) + TLV_HDR_SIZE;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_start_request_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_START_REQUEST_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\tcmd->beacon_interval = cpu_to_le32(arg->bcn_intval);\n\tcmd->bcn_tx_rate = cpu_to_le32(arg->bcn_tx_rate);\n\tcmd->dtim_period = cpu_to_le32(arg->dtim_period);\n\tcmd->num_noa_descriptors = cpu_to_le32(arg->num_noa_descriptors);\n\tcmd->preferred_rx_streams = cpu_to_le32(arg->pref_rx_streams);\n\tcmd->preferred_tx_streams = cpu_to_le32(arg->pref_tx_streams);\n\tcmd->cac_duration_ms = cpu_to_le32(arg->cac_duration_ms);\n\tcmd->regdomain = cpu_to_le32(arg->regdomain);\n\tcmd->he_ops = cpu_to_le32(arg->he_ops);\n\tcmd->punct_bitmap = cpu_to_le32(arg->punct_bitmap);\n\n\tif (!restart) {\n\t\tif (arg->ssid) {\n\t\t\tcmd->ssid.ssid_len = cpu_to_le32(arg->ssid_len);\n\t\t\tmemcpy(cmd->ssid.ssid, arg->ssid, arg->ssid_len);\n\t\t}\n\t\tif (arg->hidden_ssid)\n\t\t\tcmd->flags |= cpu_to_le32(WMI_VDEV_START_HIDDEN_SSID);\n\t\tif (arg->pmf_enabled)\n\t\t\tcmd->flags |= cpu_to_le32(WMI_VDEV_START_PMF_ENABLED);\n\t}\n\n\tcmd->flags |= cpu_to_le32(WMI_VDEV_START_LDPC_RX_ENABLED);\n\n\tptr = skb->data + sizeof(*cmd);\n\tchan = ptr;\n\n\tath12k_wmi_put_wmi_channel(chan, arg);\n\n\tchan->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_CHANNEL,\n\t\t\t\t\t\t  sizeof(*chan));\n\tptr += sizeof(*chan);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, 0);\n\n\t \n\n\tptr += sizeof(*tlv);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI, \"vdev %s id 0x%x freq 0x%x mode 0x%x\\n\",\n\t\t   restart ? \"restart\" : \"start\", arg->vdev_id,\n\t\t   arg->freq, arg->mode);\n\n\tif (restart)\n\t\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t\t  WMI_VDEV_RESTART_REQUEST_CMDID);\n\telse\n\t\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t\t  WMI_VDEV_START_REQUEST_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to submit vdev_%s cmd\\n\",\n\t\t\t    restart ? \"restart\" : \"start\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_up(struct ath12k *ar, u32 vdev_id, u32 aid, const u8 *bssid)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_up_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_up_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_UP_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->vdev_assoc_id = cpu_to_le32(aid);\n\n\tether_addr_copy(cmd->vdev_bssid.addr, bssid);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI mgmt vdev up id 0x%x assoc id %d bssid %pM\\n\",\n\t\t   vdev_id, aid, bssid);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_VDEV_UP_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to submit WMI_VDEV_UP cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_peer_create_cmd(struct ath12k *ar,\n\t\t\t\t    struct ath12k_wmi_peer_create_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_peer_create_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_peer_create_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PEER_CREATE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tether_addr_copy(cmd->peer_macaddr.addr, arg->peer_addr);\n\tcmd->peer_type = cpu_to_le32(arg->peer_type);\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI peer create vdev_id %d peer_addr %pM\\n\",\n\t\t   arg->vdev_id, arg->peer_addr);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PEER_CREATE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to submit WMI_PEER_CREATE cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_peer_delete_cmd(struct ath12k *ar,\n\t\t\t\t    const u8 *peer_addr, u8 vdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_peer_delete_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_peer_delete_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PEER_DELETE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tether_addr_copy(cmd->peer_macaddr.addr, peer_addr);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI peer delete vdev_id %d peer_addr %pM\\n\",\n\t\t   vdev_id,  peer_addr);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PEER_DELETE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_PEER_DELETE cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_pdev_set_regdomain(struct ath12k *ar,\n\t\t\t\t       struct ath12k_wmi_pdev_set_regdomain_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_pdev_set_regdomain_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_pdev_set_regdomain_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_SET_REGDOMAIN_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->reg_domain = cpu_to_le32(arg->current_rd_in_use);\n\tcmd->reg_domain_2g = cpu_to_le32(arg->current_rd_2g);\n\tcmd->reg_domain_5g = cpu_to_le32(arg->current_rd_5g);\n\tcmd->conformance_test_limit_2g = cpu_to_le32(arg->ctl_2g);\n\tcmd->conformance_test_limit_5g = cpu_to_le32(arg->ctl_5g);\n\tcmd->dfs_domain = cpu_to_le32(arg->dfs_domain);\n\tcmd->pdev_id = cpu_to_le32(arg->pdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI pdev regd rd %d rd2g %d rd5g %d domain %d pdev id %d\\n\",\n\t\t   arg->current_rd_in_use, arg->current_rd_2g,\n\t\t   arg->current_rd_5g, arg->dfs_domain, arg->pdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PDEV_SET_REGDOMAIN_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_PDEV_SET_REGDOMAIN cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_set_peer_param(struct ath12k *ar, const u8 *peer_addr,\n\t\t\t      u32 vdev_id, u32 param_id, u32 param_val)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_peer_set_param_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_peer_set_param_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PEER_SET_PARAM_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tether_addr_copy(cmd->peer_macaddr.addr, peer_addr);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->param_id = cpu_to_le32(param_id);\n\tcmd->param_value = cpu_to_le32(param_val);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev %d peer 0x%pM set param %d value %d\\n\",\n\t\t   vdev_id, peer_addr, param_id, param_val);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PEER_SET_PARAM_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_PEER_SET_PARAM cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_peer_flush_tids_cmd(struct ath12k *ar,\n\t\t\t\t\tu8 peer_addr[ETH_ALEN],\n\t\t\t\t\tu32 peer_tid_bitmap,\n\t\t\t\t\tu8 vdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_peer_flush_tids_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_peer_flush_tids_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PEER_FLUSH_TIDS_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tether_addr_copy(cmd->peer_macaddr.addr, peer_addr);\n\tcmd->peer_tid_bitmap = cpu_to_le32(peer_tid_bitmap);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI peer flush vdev_id %d peer_addr %pM tids %08x\\n\",\n\t\t   vdev_id, peer_addr, peer_tid_bitmap);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PEER_FLUSH_TIDS_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_PEER_FLUSH_TIDS cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_peer_rx_reorder_queue_setup(struct ath12k *ar,\n\t\t\t\t\t   int vdev_id, const u8 *addr,\n\t\t\t\t\t   dma_addr_t paddr, u8 tid,\n\t\t\t\t\t   u8 ba_window_size_valid,\n\t\t\t\t\t   u32 ba_window_size)\n{\n\tstruct wmi_peer_reorder_queue_setup_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_peer_reorder_queue_setup_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_REORDER_QUEUE_SETUP_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tether_addr_copy(cmd->peer_macaddr.addr, addr);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->tid = cpu_to_le32(tid);\n\tcmd->queue_ptr_lo = cpu_to_le32(lower_32_bits(paddr));\n\tcmd->queue_ptr_hi = cpu_to_le32(upper_32_bits(paddr));\n\tcmd->queue_no = cpu_to_le32(tid);\n\tcmd->ba_window_size_valid = cpu_to_le32(ba_window_size_valid);\n\tcmd->ba_window_size = cpu_to_le32(ba_window_size);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi rx reorder queue setup addr %pM vdev_id %d tid %d\\n\",\n\t\t   addr, vdev_id, tid);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb,\n\t\t\t\t  WMI_PEER_REORDER_QUEUE_SETUP_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_PEER_REORDER_QUEUE_SETUP\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint\nath12k_wmi_rx_reord_queue_remove(struct ath12k *ar,\n\t\t\t\t struct ath12k_wmi_rx_reorder_queue_remove_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_peer_reorder_queue_remove_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_peer_reorder_queue_remove_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_REORDER_QUEUE_REMOVE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tether_addr_copy(cmd->peer_macaddr.addr, arg->peer_macaddr);\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\tcmd->tid_mask = cpu_to_le32(arg->peer_tid_bitmap);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"%s: peer_macaddr %pM vdev_id %d, tid_map %d\", __func__,\n\t\t   arg->peer_macaddr, arg->vdev_id, arg->peer_tid_bitmap);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_PEER_REORDER_QUEUE_REMOVE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_PEER_REORDER_QUEUE_REMOVE_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_pdev_set_param(struct ath12k *ar, u32 param_id,\n\t\t\t      u32 param_value, u8 pdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_pdev_set_param_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_pdev_set_param_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_SET_PARAM_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->pdev_id = cpu_to_le32(pdev_id);\n\tcmd->param_id = cpu_to_le32(param_id);\n\tcmd->param_value = cpu_to_le32(param_value);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI pdev set param %d pdev id %d value %d\\n\",\n\t\t   param_id, pdev_id, param_value);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PDEV_SET_PARAM_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_PDEV_SET_PARAM cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_pdev_set_ps_mode(struct ath12k *ar, int vdev_id, u32 enable)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_pdev_set_ps_mode_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_pdev_set_ps_mode_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_STA_POWERSAVE_MODE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->sta_ps_mode = cpu_to_le32(enable);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev set psmode %d vdev id %d\\n\",\n\t\t   enable, vdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_STA_POWERSAVE_MODE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_PDEV_SET_PARAM cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_pdev_suspend(struct ath12k *ar, u32 suspend_opt,\n\t\t\t    u32 pdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_pdev_suspend_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_pdev_suspend_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_SUSPEND_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->suspend_opt = cpu_to_le32(suspend_opt);\n\tcmd->pdev_id = cpu_to_le32(pdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI pdev suspend pdev_id %d\\n\", pdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PDEV_SUSPEND_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_PDEV_SUSPEND cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_pdev_resume(struct ath12k *ar, u32 pdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_pdev_resume_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_pdev_resume_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_RESUME_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->pdev_id = cpu_to_le32(pdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI pdev resume pdev id %d\\n\", pdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PDEV_RESUME_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_PDEV_RESUME cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\n \nint ath12k_wmi_pdev_bss_chan_info_request(struct ath12k *ar,\n\t\t\t\t\t  enum wmi_bss_chan_info_req_type type)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_pdev_bss_chan_info_req_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_pdev_bss_chan_info_req_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_BSS_CHAN_INFO_REQUEST,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->req_type = cpu_to_le32(type);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI bss chan info req type %d\\n\", type);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_PDEV_BSS_CHAN_INFO_REQUEST_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_PDEV_BSS_CHAN_INFO_REQUEST cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_set_ap_ps_param_cmd(struct ath12k *ar, u8 *peer_addr,\n\t\t\t\t\tstruct ath12k_wmi_ap_ps_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_ap_ps_peer_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_ap_ps_peer_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_AP_PS_PEER_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\tether_addr_copy(cmd->peer_macaddr.addr, peer_addr);\n\tcmd->param = cpu_to_le32(arg->param);\n\tcmd->value = cpu_to_le32(arg->value);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI set ap ps vdev id %d peer %pM param %d value %d\\n\",\n\t\t   arg->vdev_id, peer_addr, arg->param, arg->value);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_AP_PS_PEER_PARAM_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_AP_PS_PEER_PARAM_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_set_sta_ps_param(struct ath12k *ar, u32 vdev_id,\n\t\t\t\tu32 param, u32 param_value)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_sta_powersave_param_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_sta_powersave_param_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_STA_POWERSAVE_PARAM_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->param = cpu_to_le32(param);\n\tcmd->value = cpu_to_le32(param_value);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI set sta ps vdev_id %d param %d value %d\\n\",\n\t\t   vdev_id, param, param_value);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_STA_POWERSAVE_PARAM_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_STA_POWERSAVE_PARAM_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_force_fw_hang_cmd(struct ath12k *ar, u32 type, u32 delay_time_ms)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_force_fw_hang_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret, len;\n\n\tlen = sizeof(*cmd);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_force_fw_hang_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_FORCE_FW_HANG_CMD,\n\t\t\t\t\t\t len);\n\n\tcmd->type = cpu_to_le32(type);\n\tcmd->delay_time_ms = cpu_to_le32(delay_time_ms);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_FORCE_FW_HANG_CMDID);\n\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"Failed to send WMI_FORCE_FW_HANG_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_set_param_cmd(struct ath12k *ar, u32 vdev_id,\n\t\t\t\t  u32 param_id, u32 param_value)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_set_param_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_set_param_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_SET_PARAM_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->param_id = cpu_to_le32(param_id);\n\tcmd->param_value = cpu_to_le32(param_value);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev id 0x%x set param %d value %d\\n\",\n\t\t   vdev_id, param_id, param_value);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_VDEV_SET_PARAM_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_VDEV_SET_PARAM_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_pdev_temperature_cmd(struct ath12k *ar)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_get_pdev_temperature_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_get_pdev_temperature_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_GET_TEMPERATURE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->pdev_id = cpu_to_le32(ar->pdev->pdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI pdev get temperature for pdev_id %d\\n\", ar->pdev->pdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PDEV_GET_TEMPERATURE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_PDEV_GET_TEMPERATURE cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_bcn_offload_control_cmd(struct ath12k *ar,\n\t\t\t\t\t    u32 vdev_id, u32 bcn_ctrl_op)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_bcn_offload_ctrl_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_bcn_offload_ctrl_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_BCN_OFFLOAD_CTRL_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->bcn_ctrl_op = cpu_to_le32(bcn_ctrl_op);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI bcn ctrl offload vdev id %d ctrl_op %d\\n\",\n\t\t   vdev_id, bcn_ctrl_op);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_BCN_OFFLOAD_CTRL_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_BCN_OFFLOAD_CTRL_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_bcn_tmpl(struct ath12k *ar, u32 vdev_id,\n\t\t\tstruct ieee80211_mutable_offsets *offs,\n\t\t\tstruct sk_buff *bcn)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_bcn_tmpl_cmd *cmd;\n\tstruct ath12k_wmi_bcn_prb_info_params *bcn_prb_info;\n\tstruct wmi_tlv *tlv;\n\tstruct sk_buff *skb;\n\tvoid *ptr;\n\tint ret, len;\n\tsize_t aligned_len = roundup(bcn->len, 4);\n\n\tlen = sizeof(*cmd) + sizeof(*bcn_prb_info) + TLV_HDR_SIZE + aligned_len;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_bcn_tmpl_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_BCN_TMPL_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->tim_ie_offset = cpu_to_le32(offs->tim_offset);\n\tcmd->csa_switch_count_offset = cpu_to_le32(offs->cntdwn_counter_offs[0]);\n\tcmd->ext_csa_switch_count_offset = cpu_to_le32(offs->cntdwn_counter_offs[1]);\n\tcmd->buf_len = cpu_to_le32(bcn->len);\n\n\tptr = skb->data + sizeof(*cmd);\n\n\tbcn_prb_info = ptr;\n\tlen = sizeof(*bcn_prb_info);\n\tbcn_prb_info->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_BCN_PRB_INFO,\n\t\t\t\t\t\t\t  len);\n\tbcn_prb_info->caps = 0;\n\tbcn_prb_info->erp = 0;\n\n\tptr += sizeof(*bcn_prb_info);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, aligned_len);\n\tmemcpy(tlv->value, bcn->data, bcn->len);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_BCN_TMPL_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_BCN_TMPL_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_install_key(struct ath12k *ar,\n\t\t\t\tstruct wmi_vdev_install_key_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_install_key_cmd *cmd;\n\tstruct wmi_tlv *tlv;\n\tstruct sk_buff *skb;\n\tint ret, len, key_len_aligned;\n\n\t \n\tkey_len_aligned = roundup(arg->key_len, 4);\n\n\tlen = sizeof(*cmd) + TLV_HDR_SIZE + key_len_aligned;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_install_key_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_INSTALL_KEY_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\tether_addr_copy(cmd->peer_macaddr.addr, arg->macaddr);\n\tcmd->key_idx = cpu_to_le32(arg->key_idx);\n\tcmd->key_flags = cpu_to_le32(arg->key_flags);\n\tcmd->key_cipher = cpu_to_le32(arg->key_cipher);\n\tcmd->key_len = cpu_to_le32(arg->key_len);\n\tcmd->key_txmic_len = cpu_to_le32(arg->key_txmic_len);\n\tcmd->key_rxmic_len = cpu_to_le32(arg->key_rxmic_len);\n\n\tif (arg->key_rsc_counter)\n\t\tcmd->key_rsc_counter = cpu_to_le64(arg->key_rsc_counter);\n\n\ttlv = (struct wmi_tlv *)(skb->data + sizeof(*cmd));\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, key_len_aligned);\n\tmemcpy(tlv->value, arg->key_data, arg->key_len);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev install key idx %d cipher %d len %d\\n\",\n\t\t   arg->key_idx, arg->key_cipher, arg->key_len);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_VDEV_INSTALL_KEY_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_VDEV_INSTALL_KEY cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nstatic void ath12k_wmi_copy_peer_flags(struct wmi_peer_assoc_complete_cmd *cmd,\n\t\t\t\t       struct ath12k_wmi_peer_assoc_arg *arg,\n\t\t\t\t       bool hw_crypto_disabled)\n{\n\tcmd->peer_flags = 0;\n\tcmd->peer_flags_ext = 0;\n\n\tif (arg->is_wme_set) {\n\t\tif (arg->qos_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_QOS);\n\t\tif (arg->apsd_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_APSD);\n\t\tif (arg->ht_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_HT);\n\t\tif (arg->bw_40)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_40MHZ);\n\t\tif (arg->bw_80)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_80MHZ);\n\t\tif (arg->bw_160)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_160MHZ);\n\t\tif (arg->bw_320)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_EXT_320MHZ);\n\n\t\t \n\t\tif (arg->stbc_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_STBC);\n\n\t\t \n\t\tif (arg->ldpc_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_LDPC);\n\n\t\tif (arg->static_mimops_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_STATIC_MIMOPS);\n\t\tif (arg->dynamic_mimops_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_DYN_MIMOPS);\n\t\tif (arg->spatial_mux_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_SPATIAL_MUX);\n\t\tif (arg->vht_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_VHT);\n\t\tif (arg->he_flag)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_HE);\n\t\tif (arg->twt_requester)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_TWT_REQ);\n\t\tif (arg->twt_responder)\n\t\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_TWT_RESP);\n\t\tif (arg->eht_flag)\n\t\t\tcmd->peer_flags_ext |= cpu_to_le32(WMI_PEER_EXT_EHT);\n\t}\n\n\t \n\tif (arg->auth_flag)\n\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_AUTH);\n\tif (arg->need_ptk_4_way) {\n\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_NEED_PTK_4_WAY);\n\t\tif (!hw_crypto_disabled)\n\t\t\tcmd->peer_flags &= cpu_to_le32(~WMI_PEER_AUTH);\n\t}\n\tif (arg->need_gtk_2_way)\n\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_NEED_GTK_2_WAY);\n\t \n\tif (arg->safe_mode_enabled)\n\t\tcmd->peer_flags &= cpu_to_le32(~(WMI_PEER_NEED_PTK_4_WAY |\n\t\t\t\t\t\t WMI_PEER_NEED_GTK_2_WAY));\n\n\tif (arg->is_pmf_enabled)\n\t\tcmd->peer_flags |= cpu_to_le32(WMI_PEER_PMF);\n\n\t \n\t \n\n\t \n\tif (arg->peer_ht_rates.num_rates == 0)\n\t\tcmd->peer_flags &= cpu_to_le32(~WMI_PEER_HT);\n}\n\nint ath12k_wmi_send_peer_assoc_cmd(struct ath12k *ar,\n\t\t\t\t   struct ath12k_wmi_peer_assoc_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_peer_assoc_complete_cmd *cmd;\n\tstruct ath12k_wmi_vht_rate_set_params *mcs;\n\tstruct ath12k_wmi_he_rate_set_params *he_mcs;\n\tstruct ath12k_wmi_eht_rate_set_params *eht_mcs;\n\tstruct sk_buff *skb;\n\tstruct wmi_tlv *tlv;\n\tvoid *ptr;\n\tu32 peer_legacy_rates_align;\n\tu32 peer_ht_rates_align;\n\tint i, ret, len;\n\n\tpeer_legacy_rates_align = roundup(arg->peer_legacy_rates.num_rates,\n\t\t\t\t\t  sizeof(u32));\n\tpeer_ht_rates_align = roundup(arg->peer_ht_rates.num_rates,\n\t\t\t\t      sizeof(u32));\n\n\tlen = sizeof(*cmd) +\n\t      TLV_HDR_SIZE + (peer_legacy_rates_align * sizeof(u8)) +\n\t      TLV_HDR_SIZE + (peer_ht_rates_align * sizeof(u8)) +\n\t      sizeof(*mcs) + TLV_HDR_SIZE +\n\t      (sizeof(*he_mcs) * arg->peer_he_mcs_count) +\n\t      TLV_HDR_SIZE + (sizeof(*eht_mcs) * arg->peer_eht_mcs_count) +\n\t      TLV_HDR_SIZE + TLV_HDR_SIZE;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tptr = skb->data;\n\n\tcmd = ptr;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PEER_ASSOC_COMPLETE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\n\tcmd->peer_new_assoc = cpu_to_le32(arg->peer_new_assoc);\n\tcmd->peer_associd = cpu_to_le32(arg->peer_associd);\n\tcmd->punct_bitmap = cpu_to_le32(arg->punct_bitmap);\n\n\tath12k_wmi_copy_peer_flags(cmd, arg,\n\t\t\t\t   test_bit(ATH12K_FLAG_HW_CRYPTO_DISABLED,\n\t\t\t\t\t    &ar->ab->dev_flags));\n\n\tether_addr_copy(cmd->peer_macaddr.addr, arg->peer_mac);\n\n\tcmd->peer_rate_caps = cpu_to_le32(arg->peer_rate_caps);\n\tcmd->peer_caps = cpu_to_le32(arg->peer_caps);\n\tcmd->peer_listen_intval = cpu_to_le32(arg->peer_listen_intval);\n\tcmd->peer_ht_caps = cpu_to_le32(arg->peer_ht_caps);\n\tcmd->peer_max_mpdu = cpu_to_le32(arg->peer_max_mpdu);\n\tcmd->peer_mpdu_density = cpu_to_le32(arg->peer_mpdu_density);\n\tcmd->peer_vht_caps = cpu_to_le32(arg->peer_vht_caps);\n\tcmd->peer_phymode = cpu_to_le32(arg->peer_phymode);\n\n\t \n\tcmd->peer_he_cap_info = cpu_to_le32(arg->peer_he_cap_macinfo[0]);\n\tcmd->peer_he_cap_info_ext = cpu_to_le32(arg->peer_he_cap_macinfo[1]);\n\tcmd->peer_he_cap_info_internal = cpu_to_le32(arg->peer_he_cap_macinfo_internal);\n\tcmd->peer_he_caps_6ghz = cpu_to_le32(arg->peer_he_caps_6ghz);\n\tcmd->peer_he_ops = cpu_to_le32(arg->peer_he_ops);\n\tfor (i = 0; i < WMI_MAX_HECAP_PHY_SIZE; i++)\n\t\tcmd->peer_he_cap_phy[i] =\n\t\t\tcpu_to_le32(arg->peer_he_cap_phyinfo[i]);\n\tcmd->peer_ppet.numss_m1 = cpu_to_le32(arg->peer_ppet.numss_m1);\n\tcmd->peer_ppet.ru_info = cpu_to_le32(arg->peer_ppet.ru_bit_mask);\n\tfor (i = 0; i < WMI_MAX_NUM_SS; i++)\n\t\tcmd->peer_ppet.ppet16_ppet8_ru3_ru0[i] =\n\t\t\tcpu_to_le32(arg->peer_ppet.ppet16_ppet8_ru3_ru0[i]);\n\n\t \n\tmemcpy_and_pad(cmd->peer_eht_cap_mac, sizeof(cmd->peer_eht_cap_mac),\n\t\t       arg->peer_eht_cap_mac, sizeof(arg->peer_eht_cap_mac),\n\t\t       0);\n\tmemcpy_and_pad(cmd->peer_eht_cap_phy, sizeof(cmd->peer_eht_cap_phy),\n\t\t       arg->peer_eht_cap_phy, sizeof(arg->peer_eht_cap_phy),\n\t\t       0);\n\tmemcpy_and_pad(&cmd->peer_eht_ppet, sizeof(cmd->peer_eht_ppet),\n\t\t       &arg->peer_eht_ppet, sizeof(arg->peer_eht_ppet), 0);\n\n\t \n\tptr += sizeof(*cmd);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, peer_legacy_rates_align);\n\n\tptr += TLV_HDR_SIZE;\n\n\tcmd->num_peer_legacy_rates = cpu_to_le32(arg->peer_legacy_rates.num_rates);\n\tmemcpy(ptr, arg->peer_legacy_rates.rates,\n\t       arg->peer_legacy_rates.num_rates);\n\n\t \n\tptr += peer_legacy_rates_align;\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, peer_ht_rates_align);\n\tptr += TLV_HDR_SIZE;\n\tcmd->num_peer_ht_rates = cpu_to_le32(arg->peer_ht_rates.num_rates);\n\tmemcpy(ptr, arg->peer_ht_rates.rates,\n\t       arg->peer_ht_rates.num_rates);\n\n\t \n\tptr += peer_ht_rates_align;\n\n\tmcs = ptr;\n\n\tmcs->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VHT_RATE_SET,\n\t\t\t\t\t\t sizeof(*mcs));\n\n\tcmd->peer_nss = cpu_to_le32(arg->peer_nss);\n\n\t \n\tcmd->peer_bw_rxnss_override = 0;\n\tcmd->peer_bw_rxnss_override |= cpu_to_le32(arg->peer_bw_rxnss_override);\n\n\tif (arg->vht_capable) {\n\t\tmcs->rx_max_rate = cpu_to_le32(arg->rx_max_rate);\n\t\tmcs->rx_mcs_set = cpu_to_le32(arg->rx_mcs_set);\n\t\tmcs->tx_max_rate = cpu_to_le32(arg->tx_max_rate);\n\t\tmcs->tx_mcs_set = cpu_to_le32(arg->tx_mcs_set);\n\t}\n\n\t \n\tcmd->peer_he_mcs = cpu_to_le32(arg->peer_he_mcs_count);\n\tcmd->min_data_rate = cpu_to_le32(arg->min_data_rate);\n\n\tptr += sizeof(*mcs);\n\n\tlen = arg->peer_he_mcs_count * sizeof(*he_mcs);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, len);\n\tptr += TLV_HDR_SIZE;\n\n\t \n\tfor (i = 0; i < arg->peer_he_mcs_count; i++) {\n\t\the_mcs = ptr;\n\t\the_mcs->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_HE_RATE_SET,\n\t\t\t\t\t\t\t    sizeof(*he_mcs));\n\n\t\the_mcs->rx_mcs_set = cpu_to_le32(arg->peer_he_rx_mcs_set[i]);\n\t\the_mcs->tx_mcs_set = cpu_to_le32(arg->peer_he_tx_mcs_set[i]);\n\t\tptr += sizeof(*he_mcs);\n\t}\n\n\t \n\tlen = 0;\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, len);\n\tptr += TLV_HDR_SIZE;\n\n\t \n\tlen = arg->peer_eht_mcs_count * sizeof(*eht_mcs);\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, len);\n\tptr += TLV_HDR_SIZE;\n\n\tfor (i = 0; i < arg->peer_eht_mcs_count; i++) {\n\t\teht_mcs = ptr;\n\t\teht_mcs->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_HE_RATE_SET,\n\t\t\t\t\t\t\t     sizeof(*eht_mcs));\n\n\t\teht_mcs->rx_mcs_set = cpu_to_le32(arg->peer_eht_rx_mcs_set[i]);\n\t\teht_mcs->tx_mcs_set = cpu_to_le32(arg->peer_eht_tx_mcs_set[i]);\n\t\tptr += sizeof(*eht_mcs);\n\t}\n\n\t \n\tlen = 0;\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, len);\n\tptr += TLV_HDR_SIZE;\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi peer assoc vdev id %d assoc id %d peer mac %pM peer_flags %x rate_caps %x peer_caps %x listen_intval %d ht_caps %x max_mpdu %d nss %d phymode %d peer_mpdu_density %d vht_caps %x he cap_info %x he ops %x he cap_info_ext %x he phy %x %x %x peer_bw_rxnss_override %x peer_flags_ext %x eht mac_cap %x %x eht phy_cap %x %x %x\\n\",\n\t\t   cmd->vdev_id, cmd->peer_associd, arg->peer_mac,\n\t\t   cmd->peer_flags, cmd->peer_rate_caps, cmd->peer_caps,\n\t\t   cmd->peer_listen_intval, cmd->peer_ht_caps,\n\t\t   cmd->peer_max_mpdu, cmd->peer_nss, cmd->peer_phymode,\n\t\t   cmd->peer_mpdu_density,\n\t\t   cmd->peer_vht_caps, cmd->peer_he_cap_info,\n\t\t   cmd->peer_he_ops, cmd->peer_he_cap_info_ext,\n\t\t   cmd->peer_he_cap_phy[0], cmd->peer_he_cap_phy[1],\n\t\t   cmd->peer_he_cap_phy[2],\n\t\t   cmd->peer_bw_rxnss_override, cmd->peer_flags_ext,\n\t\t   cmd->peer_eht_cap_mac[0], cmd->peer_eht_cap_mac[1],\n\t\t   cmd->peer_eht_cap_phy[0], cmd->peer_eht_cap_phy[1],\n\t\t   cmd->peer_eht_cap_phy[2]);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_PEER_ASSOC_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_PEER_ASSOC_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nvoid ath12k_wmi_start_scan_init(struct ath12k *ar,\n\t\t\t\tstruct ath12k_wmi_scan_req_arg *arg)\n{\n\t \n\targ->scan_req_id = 1;\n\targ->scan_priority = WMI_SCAN_PRIORITY_LOW;\n\targ->dwell_time_active = 50;\n\targ->dwell_time_active_2g = 0;\n\targ->dwell_time_passive = 150;\n\targ->dwell_time_active_6g = 40;\n\targ->dwell_time_passive_6g = 30;\n\targ->min_rest_time = 50;\n\targ->max_rest_time = 500;\n\targ->repeat_probe_time = 0;\n\targ->probe_spacing_time = 0;\n\targ->idle_time = 0;\n\targ->max_scan_time = 20000;\n\targ->probe_delay = 5;\n\targ->notify_scan_events = WMI_SCAN_EVENT_STARTED |\n\t\t\t\t  WMI_SCAN_EVENT_COMPLETED |\n\t\t\t\t  WMI_SCAN_EVENT_BSS_CHANNEL |\n\t\t\t\t  WMI_SCAN_EVENT_FOREIGN_CHAN |\n\t\t\t\t  WMI_SCAN_EVENT_DEQUEUED;\n\targ->scan_flags |= WMI_SCAN_CHAN_STAT_EVENT;\n\targ->num_bssid = 1;\n\n\t \n\teth_broadcast_addr(arg->bssid_list[0].addr);\n}\n\nstatic void ath12k_wmi_copy_scan_event_cntrl_flags(struct wmi_start_scan_cmd *cmd,\n\t\t\t\t\t\t   struct ath12k_wmi_scan_req_arg *arg)\n{\n\t \n\tif (arg->scan_ev_started)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_STARTED);\n\tif (arg->scan_ev_completed)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_COMPLETED);\n\tif (arg->scan_ev_bss_chan)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_BSS_CHANNEL);\n\tif (arg->scan_ev_foreign_chan)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_FOREIGN_CHAN);\n\tif (arg->scan_ev_dequeued)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_DEQUEUED);\n\tif (arg->scan_ev_preempted)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_PREEMPTED);\n\tif (arg->scan_ev_start_failed)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_START_FAILED);\n\tif (arg->scan_ev_restarted)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_RESTARTED);\n\tif (arg->scan_ev_foreign_chn_exit)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_FOREIGN_CHAN_EXIT);\n\tif (arg->scan_ev_suspended)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_SUSPENDED);\n\tif (arg->scan_ev_resumed)\n\t\tcmd->notify_scan_events |= cpu_to_le32(WMI_SCAN_EVENT_RESUMED);\n\n\t \n\tcmd->scan_ctrl_flags = 0;\n\tif (arg->scan_f_passive)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_FLAG_PASSIVE);\n\tif (arg->scan_f_strict_passive_pch)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_FLAG_STRICT_PASSIVE_ON_PCHN);\n\tif (arg->scan_f_promisc_mode)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_FILTER_PROMISCUOS);\n\tif (arg->scan_f_capture_phy_err)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_CAPTURE_PHY_ERROR);\n\tif (arg->scan_f_half_rate)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_FLAG_HALF_RATE_SUPPORT);\n\tif (arg->scan_f_quarter_rate)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_FLAG_QUARTER_RATE_SUPPORT);\n\tif (arg->scan_f_cck_rates)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_ADD_CCK_RATES);\n\tif (arg->scan_f_ofdm_rates)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_ADD_OFDM_RATES);\n\tif (arg->scan_f_chan_stat_evnt)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_CHAN_STAT_EVENT);\n\tif (arg->scan_f_filter_prb_req)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_FILTER_PROBE_REQ);\n\tif (arg->scan_f_bcast_probe)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_ADD_BCAST_PROBE_REQ);\n\tif (arg->scan_f_offchan_mgmt_tx)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_OFFCHAN_MGMT_TX);\n\tif (arg->scan_f_offchan_data_tx)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_OFFCHAN_DATA_TX);\n\tif (arg->scan_f_force_active_dfs_chn)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_FLAG_FORCE_ACTIVE_ON_DFS);\n\tif (arg->scan_f_add_tpc_ie_in_probe)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_ADD_TPC_IE_IN_PROBE_REQ);\n\tif (arg->scan_f_add_ds_ie_in_probe)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_ADD_DS_IE_IN_PROBE_REQ);\n\tif (arg->scan_f_add_spoofed_mac_in_probe)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_ADD_SPOOF_MAC_IN_PROBE_REQ);\n\tif (arg->scan_f_add_rand_seq_in_probe)\n\t\tcmd->scan_ctrl_flags |= cpu_to_le32(WMI_SCAN_RANDOM_SEQ_NO_IN_PROBE_REQ);\n\tif (arg->scan_f_en_ie_whitelist_in_probe)\n\t\tcmd->scan_ctrl_flags |=\n\t\t\tcpu_to_le32(WMI_SCAN_ENABLE_IE_WHTELIST_IN_PROBE_REQ);\n\n\tcmd->scan_ctrl_flags |= le32_encode_bits(arg->adaptive_dwell_time_mode,\n\t\t\t\t\t\t WMI_SCAN_DWELL_MODE_MASK);\n}\n\nint ath12k_wmi_send_scan_start_cmd(struct ath12k *ar,\n\t\t\t\t   struct ath12k_wmi_scan_req_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_start_scan_cmd *cmd;\n\tstruct ath12k_wmi_ssid_params *ssid = NULL;\n\tstruct ath12k_wmi_mac_addr_params *bssid;\n\tstruct sk_buff *skb;\n\tstruct wmi_tlv *tlv;\n\tvoid *ptr;\n\tint i, ret, len;\n\tu32 *tmp_ptr, extraie_len_with_pad = 0;\n\tstruct ath12k_wmi_hint_short_ssid_arg *s_ssid = NULL;\n\tstruct ath12k_wmi_hint_bssid_arg *hint_bssid = NULL;\n\n\tlen = sizeof(*cmd);\n\n\tlen += TLV_HDR_SIZE;\n\tif (arg->num_chan)\n\t\tlen += arg->num_chan * sizeof(u32);\n\n\tlen += TLV_HDR_SIZE;\n\tif (arg->num_ssids)\n\t\tlen += arg->num_ssids * sizeof(*ssid);\n\n\tlen += TLV_HDR_SIZE;\n\tif (arg->num_bssid)\n\t\tlen += sizeof(*bssid) * arg->num_bssid;\n\n\tif (arg->num_hint_bssid)\n\t\tlen += TLV_HDR_SIZE +\n\t\t       arg->num_hint_bssid * sizeof(*hint_bssid);\n\n\tif (arg->num_hint_s_ssid)\n\t\tlen += TLV_HDR_SIZE +\n\t\t       arg->num_hint_s_ssid * sizeof(*s_ssid);\n\n\tlen += TLV_HDR_SIZE;\n\tif (arg->extraie.len)\n\t\textraie_len_with_pad =\n\t\t\troundup(arg->extraie.len, sizeof(u32));\n\tif (extraie_len_with_pad <= (wmi->wmi_ab->max_msg_len[ar->pdev_idx] - len)) {\n\t\tlen += extraie_len_with_pad;\n\t} else {\n\t\tath12k_warn(ar->ab, \"discard large size %d bytes extraie for scan start\\n\",\n\t\t\t    arg->extraie.len);\n\t\textraie_len_with_pad = 0;\n\t}\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tptr = skb->data;\n\n\tcmd = ptr;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_START_SCAN_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->scan_id = cpu_to_le32(arg->scan_id);\n\tcmd->scan_req_id = cpu_to_le32(arg->scan_req_id);\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\tcmd->scan_priority = cpu_to_le32(arg->scan_priority);\n\tcmd->notify_scan_events = cpu_to_le32(arg->notify_scan_events);\n\n\tath12k_wmi_copy_scan_event_cntrl_flags(cmd, arg);\n\n\tcmd->dwell_time_active = cpu_to_le32(arg->dwell_time_active);\n\tcmd->dwell_time_active_2g = cpu_to_le32(arg->dwell_time_active_2g);\n\tcmd->dwell_time_passive = cpu_to_le32(arg->dwell_time_passive);\n\tcmd->dwell_time_active_6g = cpu_to_le32(arg->dwell_time_active_6g);\n\tcmd->dwell_time_passive_6g = cpu_to_le32(arg->dwell_time_passive_6g);\n\tcmd->min_rest_time = cpu_to_le32(arg->min_rest_time);\n\tcmd->max_rest_time = cpu_to_le32(arg->max_rest_time);\n\tcmd->repeat_probe_time = cpu_to_le32(arg->repeat_probe_time);\n\tcmd->probe_spacing_time = cpu_to_le32(arg->probe_spacing_time);\n\tcmd->idle_time = cpu_to_le32(arg->idle_time);\n\tcmd->max_scan_time = cpu_to_le32(arg->max_scan_time);\n\tcmd->probe_delay = cpu_to_le32(arg->probe_delay);\n\tcmd->burst_duration = cpu_to_le32(arg->burst_duration);\n\tcmd->num_chan = cpu_to_le32(arg->num_chan);\n\tcmd->num_bssid = cpu_to_le32(arg->num_bssid);\n\tcmd->num_ssids = cpu_to_le32(arg->num_ssids);\n\tcmd->ie_len = cpu_to_le32(arg->extraie.len);\n\tcmd->n_probes = cpu_to_le32(arg->n_probes);\n\n\tptr += sizeof(*cmd);\n\n\tlen = arg->num_chan * sizeof(u32);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_UINT32, len);\n\tptr += TLV_HDR_SIZE;\n\ttmp_ptr = (u32 *)ptr;\n\n\tmemcpy(tmp_ptr, arg->chan_list, arg->num_chan * 4);\n\n\tptr += len;\n\n\tlen = arg->num_ssids * sizeof(*ssid);\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_FIXED_STRUCT, len);\n\n\tptr += TLV_HDR_SIZE;\n\n\tif (arg->num_ssids) {\n\t\tssid = ptr;\n\t\tfor (i = 0; i < arg->num_ssids; ++i) {\n\t\t\tssid->ssid_len = cpu_to_le32(arg->ssid[i].ssid_len);\n\t\t\tmemcpy(ssid->ssid, arg->ssid[i].ssid,\n\t\t\t       arg->ssid[i].ssid_len);\n\t\t\tssid++;\n\t\t}\n\t}\n\n\tptr += (arg->num_ssids * sizeof(*ssid));\n\tlen = arg->num_bssid * sizeof(*bssid);\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_FIXED_STRUCT, len);\n\n\tptr += TLV_HDR_SIZE;\n\tbssid = ptr;\n\n\tif (arg->num_bssid) {\n\t\tfor (i = 0; i < arg->num_bssid; ++i) {\n\t\t\tether_addr_copy(bssid->addr,\n\t\t\t\t\targ->bssid_list[i].addr);\n\t\t\tbssid++;\n\t\t}\n\t}\n\n\tptr += arg->num_bssid * sizeof(*bssid);\n\n\tlen = extraie_len_with_pad;\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, len);\n\tptr += TLV_HDR_SIZE;\n\n\tif (extraie_len_with_pad)\n\t\tmemcpy(ptr, arg->extraie.ptr,\n\t\t       arg->extraie.len);\n\n\tptr += extraie_len_with_pad;\n\n\tif (arg->num_hint_s_ssid) {\n\t\tlen = arg->num_hint_s_ssid * sizeof(*s_ssid);\n\t\ttlv = ptr;\n\t\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_FIXED_STRUCT, len);\n\t\tptr += TLV_HDR_SIZE;\n\t\ts_ssid = ptr;\n\t\tfor (i = 0; i < arg->num_hint_s_ssid; ++i) {\n\t\t\ts_ssid->freq_flags = arg->hint_s_ssid[i].freq_flags;\n\t\t\ts_ssid->short_ssid = arg->hint_s_ssid[i].short_ssid;\n\t\t\ts_ssid++;\n\t\t}\n\t\tptr += len;\n\t}\n\n\tif (arg->num_hint_bssid) {\n\t\tlen = arg->num_hint_bssid * sizeof(struct ath12k_wmi_hint_bssid_arg);\n\t\ttlv = ptr;\n\t\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_FIXED_STRUCT, len);\n\t\tptr += TLV_HDR_SIZE;\n\t\thint_bssid = ptr;\n\t\tfor (i = 0; i < arg->num_hint_bssid; ++i) {\n\t\t\thint_bssid->freq_flags =\n\t\t\t\targ->hint_bssid[i].freq_flags;\n\t\t\tether_addr_copy(&arg->hint_bssid[i].bssid.addr[0],\n\t\t\t\t\t&hint_bssid->bssid.addr[0]);\n\t\t\thint_bssid++;\n\t\t}\n\t}\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_START_SCAN_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_START_SCAN_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_scan_stop_cmd(struct ath12k *ar,\n\t\t\t\t  struct ath12k_wmi_scan_cancel_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_stop_scan_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_stop_scan_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_STOP_SCAN_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\tcmd->requestor = cpu_to_le32(arg->requester);\n\tcmd->scan_id = cpu_to_le32(arg->scan_id);\n\tcmd->pdev_id = cpu_to_le32(arg->pdev_id);\n\t \n\tif (arg->req_type == WLAN_SCAN_CANCEL_PDEV_ALL) {\n\t\t \n\t\tcmd->req_type = cpu_to_le32(WMI_SCAN_STOP_ALL);\n\t} else if (arg->req_type == WLAN_SCAN_CANCEL_VDEV_ALL) {\n\t\t \n\t\tcmd->req_type = cpu_to_le32(WMI_SCAN_STOP_VAP_ALL);\n\t} else if (arg->req_type == WLAN_SCAN_CANCEL_SINGLE) {\n\t\t \n\t\tcmd->req_type = WMI_SCAN_STOP_ONE;\n\t} else {\n\t\tath12k_warn(ar->ab, \"invalid scan cancel req_type %d\",\n\t\t\t    arg->req_type);\n\t\tdev_kfree_skb(skb);\n\t\treturn -EINVAL;\n\t}\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_STOP_SCAN_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_STOP_SCAN_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_scan_chan_list_cmd(struct ath12k *ar,\n\t\t\t\t       struct ath12k_wmi_scan_chan_list_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_scan_chan_list_cmd *cmd;\n\tstruct sk_buff *skb;\n\tstruct ath12k_wmi_channel_params *chan_info;\n\tstruct ath12k_wmi_channel_arg *channel_arg;\n\tstruct wmi_tlv *tlv;\n\tvoid *ptr;\n\tint i, ret, len;\n\tu16 num_send_chans, num_sends = 0, max_chan_limit = 0;\n\t__le32 *reg1, *reg2;\n\n\tchannel_arg = &arg->channel[0];\n\twhile (arg->nallchans) {\n\t\tlen = sizeof(*cmd) + TLV_HDR_SIZE;\n\t\tmax_chan_limit = (wmi->wmi_ab->max_msg_len[ar->pdev_idx] - len) /\n\t\t\tsizeof(*chan_info);\n\n\t\tnum_send_chans = min(arg->nallchans, max_chan_limit);\n\n\t\targ->nallchans -= num_send_chans;\n\t\tlen += sizeof(*chan_info) * num_send_chans;\n\n\t\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\t\tif (!skb)\n\t\t\treturn -ENOMEM;\n\n\t\tcmd = (struct wmi_scan_chan_list_cmd *)skb->data;\n\t\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_SCAN_CHAN_LIST_CMD,\n\t\t\t\t\t\t\t sizeof(*cmd));\n\t\tcmd->pdev_id = cpu_to_le32(arg->pdev_id);\n\t\tcmd->num_scan_chans = cpu_to_le32(num_send_chans);\n\t\tif (num_sends)\n\t\t\tcmd->flags |= cpu_to_le32(WMI_APPEND_TO_EXISTING_CHAN_LIST_FLAG);\n\n\t\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t\t   \"WMI no.of chan = %d len = %d pdev_id = %d num_sends = %d\\n\",\n\t\t\t   num_send_chans, len, cmd->pdev_id, num_sends);\n\n\t\tptr = skb->data + sizeof(*cmd);\n\n\t\tlen = sizeof(*chan_info) * num_send_chans;\n\t\ttlv = ptr;\n\t\ttlv->header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_ARRAY_STRUCT,\n\t\t\t\t\t\t     len);\n\t\tptr += TLV_HDR_SIZE;\n\n\t\tfor (i = 0; i < num_send_chans; ++i) {\n\t\t\tchan_info = ptr;\n\t\t\tmemset(chan_info, 0, sizeof(*chan_info));\n\t\t\tlen = sizeof(*chan_info);\n\t\t\tchan_info->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_CHANNEL,\n\t\t\t\t\t\t\t\t       len);\n\n\t\t\treg1 = &chan_info->reg_info_1;\n\t\t\treg2 = &chan_info->reg_info_2;\n\t\t\tchan_info->mhz = cpu_to_le32(channel_arg->mhz);\n\t\t\tchan_info->band_center_freq1 = cpu_to_le32(channel_arg->cfreq1);\n\t\t\tchan_info->band_center_freq2 = cpu_to_le32(channel_arg->cfreq2);\n\n\t\t\tif (channel_arg->is_chan_passive)\n\t\t\t\tchan_info->info |= cpu_to_le32(WMI_CHAN_INFO_PASSIVE);\n\t\t\tif (channel_arg->allow_he)\n\t\t\t\tchan_info->info |= cpu_to_le32(WMI_CHAN_INFO_ALLOW_HE);\n\t\t\telse if (channel_arg->allow_vht)\n\t\t\t\tchan_info->info |= cpu_to_le32(WMI_CHAN_INFO_ALLOW_VHT);\n\t\t\telse if (channel_arg->allow_ht)\n\t\t\t\tchan_info->info |= cpu_to_le32(WMI_CHAN_INFO_ALLOW_HT);\n\t\t\tif (channel_arg->half_rate)\n\t\t\t\tchan_info->info |= cpu_to_le32(WMI_CHAN_INFO_HALF_RATE);\n\t\t\tif (channel_arg->quarter_rate)\n\t\t\t\tchan_info->info |=\n\t\t\t\t\tcpu_to_le32(WMI_CHAN_INFO_QUARTER_RATE);\n\n\t\t\tif (channel_arg->psc_channel)\n\t\t\t\tchan_info->info |= cpu_to_le32(WMI_CHAN_INFO_PSC);\n\n\t\t\tif (channel_arg->dfs_set)\n\t\t\t\tchan_info->info |= cpu_to_le32(WMI_CHAN_INFO_DFS);\n\n\t\t\tchan_info->info |= le32_encode_bits(channel_arg->phy_mode,\n\t\t\t\t\t\t\t    WMI_CHAN_INFO_MODE);\n\t\t\t*reg1 |= le32_encode_bits(channel_arg->minpower,\n\t\t\t\t\t\t  WMI_CHAN_REG_INFO1_MIN_PWR);\n\t\t\t*reg1 |= le32_encode_bits(channel_arg->maxpower,\n\t\t\t\t\t\t  WMI_CHAN_REG_INFO1_MAX_PWR);\n\t\t\t*reg1 |= le32_encode_bits(channel_arg->maxregpower,\n\t\t\t\t\t\t  WMI_CHAN_REG_INFO1_MAX_REG_PWR);\n\t\t\t*reg1 |= le32_encode_bits(channel_arg->reg_class_id,\n\t\t\t\t\t\t  WMI_CHAN_REG_INFO1_REG_CLS);\n\t\t\t*reg2 |= le32_encode_bits(channel_arg->antennamax,\n\t\t\t\t\t\t  WMI_CHAN_REG_INFO2_ANT_MAX);\n\n\t\t\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t\t\t   \"WMI chan scan list chan[%d] = %u, chan_info->info %8x\\n\",\n\t\t\t\t   i, chan_info->mhz, chan_info->info);\n\n\t\t\tptr += sizeof(*chan_info);\n\n\t\t\tchannel_arg++;\n\t\t}\n\n\t\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_SCAN_CHAN_LIST_CMDID);\n\t\tif (ret) {\n\t\t\tath12k_warn(ar->ab, \"failed to send WMI_SCAN_CHAN_LIST cmd\\n\");\n\t\t\tdev_kfree_skb(skb);\n\t\t\treturn ret;\n\t\t}\n\n\t\tnum_sends++;\n\t}\n\n\treturn 0;\n}\n\nint ath12k_wmi_send_wmm_update_cmd(struct ath12k *ar, u32 vdev_id,\n\t\t\t\t   struct wmi_wmm_params_all_arg *param)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_vdev_set_wmm_params_cmd *cmd;\n\tstruct wmi_wmm_params *wmm_param;\n\tstruct wmi_wmm_params_arg *wmi_wmm_arg;\n\tstruct sk_buff *skb;\n\tint ret, ac;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_vdev_set_wmm_params_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_SET_WMM_PARAMS_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->wmm_param_type = 0;\n\n\tfor (ac = 0; ac < WME_NUM_AC; ac++) {\n\t\tswitch (ac) {\n\t\tcase WME_AC_BE:\n\t\t\twmi_wmm_arg = &param->ac_be;\n\t\t\tbreak;\n\t\tcase WME_AC_BK:\n\t\t\twmi_wmm_arg = &param->ac_bk;\n\t\t\tbreak;\n\t\tcase WME_AC_VI:\n\t\t\twmi_wmm_arg = &param->ac_vi;\n\t\t\tbreak;\n\t\tcase WME_AC_VO:\n\t\t\twmi_wmm_arg = &param->ac_vo;\n\t\t\tbreak;\n\t\t}\n\n\t\twmm_param = (struct wmi_wmm_params *)&cmd->wmm_params[ac];\n\t\twmm_param->tlv_header =\n\t\t\tath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_SET_WMM_PARAMS_CMD,\n\t\t\t\t\t       sizeof(*wmm_param));\n\n\t\twmm_param->aifs = cpu_to_le32(wmi_wmm_arg->aifs);\n\t\twmm_param->cwmin = cpu_to_le32(wmi_wmm_arg->cwmin);\n\t\twmm_param->cwmax = cpu_to_le32(wmi_wmm_arg->cwmax);\n\t\twmm_param->txoplimit = cpu_to_le32(wmi_wmm_arg->txop);\n\t\twmm_param->acm = cpu_to_le32(wmi_wmm_arg->acm);\n\t\twmm_param->no_ack = cpu_to_le32(wmi_wmm_arg->no_ack);\n\n\t\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t\t   \"wmi wmm set ac %d aifs %d cwmin %d cwmax %d txop %d acm %d no_ack %d\\n\",\n\t\t\t   ac, wmm_param->aifs, wmm_param->cwmin,\n\t\t\t   wmm_param->cwmax, wmm_param->txoplimit,\n\t\t\t   wmm_param->acm, wmm_param->no_ack);\n\t}\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_VDEV_SET_WMM_PARAMS_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_VDEV_SET_WMM_PARAMS_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_dfs_phyerr_offload_enable_cmd(struct ath12k *ar,\n\t\t\t\t\t\t  u32 pdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_dfs_phyerr_offload_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_dfs_phyerr_offload_cmd *)skb->data;\n\tcmd->tlv_header =\n\t\tath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_DFS_PHYERR_OFFLOAD_ENABLE_CMD,\n\t\t\t\t       sizeof(*cmd));\n\n\tcmd->pdev_id = cpu_to_le32(pdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI dfs phy err offload enable pdev id %d\\n\", pdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_PDEV_DFS_PHYERR_OFFLOAD_ENABLE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_PDEV_DFS_PHYERR_OFFLOAD_ENABLE cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_delba_send(struct ath12k *ar, u32 vdev_id, const u8 *mac,\n\t\t\t  u32 tid, u32 initiator, u32 reason)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_delba_send_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_delba_send_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_DELBA_SEND_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tether_addr_copy(cmd->peer_macaddr.addr, mac);\n\tcmd->tid = cpu_to_le32(tid);\n\tcmd->initiator = cpu_to_le32(initiator);\n\tcmd->reasoncode = cpu_to_le32(reason);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi delba send vdev_id 0x%X mac_addr %pM tid %u initiator %u reason %u\\n\",\n\t\t   vdev_id, mac, tid, initiator, reason);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_DELBA_SEND_CMDID);\n\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_DELBA_SEND_CMDID cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_addba_set_resp(struct ath12k *ar, u32 vdev_id, const u8 *mac,\n\t\t\t      u32 tid, u32 status)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_addba_setresponse_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_addba_setresponse_cmd *)skb->data;\n\tcmd->tlv_header =\n\t\tath12k_wmi_tlv_cmd_hdr(WMI_TAG_ADDBA_SETRESPONSE_CMD,\n\t\t\t\t       sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tether_addr_copy(cmd->peer_macaddr.addr, mac);\n\tcmd->tid = cpu_to_le32(tid);\n\tcmd->statuscode = cpu_to_le32(status);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi addba set resp vdev_id 0x%X mac_addr %pM tid %u status %u\\n\",\n\t\t   vdev_id, mac, tid, status);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_ADDBA_SET_RESP_CMDID);\n\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_ADDBA_SET_RESP_CMDID cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_addba_send(struct ath12k *ar, u32 vdev_id, const u8 *mac,\n\t\t\t  u32 tid, u32 buf_size)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_addba_send_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_addba_send_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_ADDBA_SEND_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tether_addr_copy(cmd->peer_macaddr.addr, mac);\n\tcmd->tid = cpu_to_le32(tid);\n\tcmd->buffersize = cpu_to_le32(buf_size);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi addba send vdev_id 0x%X mac_addr %pM tid %u bufsize %u\\n\",\n\t\t   vdev_id, mac, tid, buf_size);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_ADDBA_SEND_CMDID);\n\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_ADDBA_SEND_CMDID cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_addba_clear_resp(struct ath12k *ar, u32 vdev_id, const u8 *mac)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_addba_clear_resp_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_addba_clear_resp_cmd *)skb->data;\n\tcmd->tlv_header =\n\t\tath12k_wmi_tlv_cmd_hdr(WMI_TAG_ADDBA_CLEAR_RESP_CMD,\n\t\t\t\t       sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tether_addr_copy(cmd->peer_macaddr.addr, mac);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi addba clear resp vdev_id 0x%X mac_addr %pM\\n\",\n\t\t   vdev_id, mac);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_ADDBA_CLEAR_RESP_CMDID);\n\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_ADDBA_CLEAR_RESP_CMDID cmd\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_send_init_country_cmd(struct ath12k *ar,\n\t\t\t\t     struct ath12k_wmi_init_country_arg *arg)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_init_country_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_init_country_cmd *)skb->data;\n\tcmd->tlv_header =\n\t\tath12k_wmi_tlv_cmd_hdr(WMI_TAG_SET_INIT_COUNTRY_CMD,\n\t\t\t\t       sizeof(*cmd));\n\n\tcmd->pdev_id = cpu_to_le32(ar->pdev->pdev_id);\n\n\tswitch (arg->flags) {\n\tcase ALPHA_IS_SET:\n\t\tcmd->init_cc_type = WMI_COUNTRY_INFO_TYPE_ALPHA;\n\t\tmemcpy(&cmd->cc_info.alpha2, arg->cc_info.alpha2, 3);\n\t\tbreak;\n\tcase CC_IS_SET:\n\t\tcmd->init_cc_type = cpu_to_le32(WMI_COUNTRY_INFO_TYPE_COUNTRY_CODE);\n\t\tcmd->cc_info.country_code =\n\t\t\tcpu_to_le32(arg->cc_info.country_code);\n\t\tbreak;\n\tcase REGDMN_IS_SET:\n\t\tcmd->init_cc_type = cpu_to_le32(WMI_COUNTRY_INFO_TYPE_REGDOMAIN);\n\t\tcmd->cc_info.regdom_id = cpu_to_le32(arg->cc_info.regdom_id);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_SET_INIT_COUNTRY_CMDID);\n\nout:\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send WMI_SET_INIT_COUNTRY CMD :%d\\n\",\n\t\t\t    ret);\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint\nath12k_wmi_send_twt_enable_cmd(struct ath12k *ar, u32 pdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct ath12k_base *ab = wmi->wmi_ab->ab;\n\tstruct wmi_twt_enable_params_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret, len;\n\n\tlen = sizeof(*cmd);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_twt_enable_params_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_TWT_ENABLE_CMD,\n\t\t\t\t\t\t len);\n\tcmd->pdev_id = cpu_to_le32(pdev_id);\n\tcmd->sta_cong_timer_ms = cpu_to_le32(ATH12K_TWT_DEF_STA_CONG_TIMER_MS);\n\tcmd->default_slot_size = cpu_to_le32(ATH12K_TWT_DEF_DEFAULT_SLOT_SIZE);\n\tcmd->congestion_thresh_setup =\n\t\tcpu_to_le32(ATH12K_TWT_DEF_CONGESTION_THRESH_SETUP);\n\tcmd->congestion_thresh_teardown =\n\t\tcpu_to_le32(ATH12K_TWT_DEF_CONGESTION_THRESH_TEARDOWN);\n\tcmd->congestion_thresh_critical =\n\t\tcpu_to_le32(ATH12K_TWT_DEF_CONGESTION_THRESH_CRITICAL);\n\tcmd->interference_thresh_teardown =\n\t\tcpu_to_le32(ATH12K_TWT_DEF_INTERFERENCE_THRESH_TEARDOWN);\n\tcmd->interference_thresh_setup =\n\t\tcpu_to_le32(ATH12K_TWT_DEF_INTERFERENCE_THRESH_SETUP);\n\tcmd->min_no_sta_setup = cpu_to_le32(ATH12K_TWT_DEF_MIN_NO_STA_SETUP);\n\tcmd->min_no_sta_teardown = cpu_to_le32(ATH12K_TWT_DEF_MIN_NO_STA_TEARDOWN);\n\tcmd->no_of_bcast_mcast_slots =\n\t\tcpu_to_le32(ATH12K_TWT_DEF_NO_OF_BCAST_MCAST_SLOTS);\n\tcmd->min_no_twt_slots = cpu_to_le32(ATH12K_TWT_DEF_MIN_NO_TWT_SLOTS);\n\tcmd->max_no_sta_twt = cpu_to_le32(ATH12K_TWT_DEF_MAX_NO_STA_TWT);\n\tcmd->mode_check_interval = cpu_to_le32(ATH12K_TWT_DEF_MODE_CHECK_INTERVAL);\n\tcmd->add_sta_slot_interval = cpu_to_le32(ATH12K_TWT_DEF_ADD_STA_SLOT_INTERVAL);\n\tcmd->remove_sta_slot_interval =\n\t\tcpu_to_le32(ATH12K_TWT_DEF_REMOVE_STA_SLOT_INTERVAL);\n\t \n\tcmd->mbss_support = 0;\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_TWT_ENABLE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ab, \"Failed to send WMI_TWT_ENABLE_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint\nath12k_wmi_send_twt_disable_cmd(struct ath12k *ar, u32 pdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct ath12k_base *ab = wmi->wmi_ab->ab;\n\tstruct wmi_twt_disable_params_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret, len;\n\n\tlen = sizeof(*cmd);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_twt_disable_params_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_TWT_DISABLE_CMD,\n\t\t\t\t\t\t len);\n\tcmd->pdev_id = cpu_to_le32(pdev_id);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_TWT_DISABLE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ab, \"Failed to send WMI_TWT_DISABLE_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint\nath12k_wmi_send_obss_spr_cmd(struct ath12k *ar, u32 vdev_id,\n\t\t\t     struct ieee80211_he_obss_pd *he_obss_pd)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct ath12k_base *ab = wmi->wmi_ab->ab;\n\tstruct wmi_obss_spatial_reuse_params_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret, len;\n\n\tlen = sizeof(*cmd);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_obss_spatial_reuse_params_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_OBSS_SPATIAL_REUSE_SET_CMD,\n\t\t\t\t\t\t len);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->enable = cpu_to_le32(he_obss_pd->enable);\n\tcmd->obss_min = a_cpu_to_sle32(he_obss_pd->min_offset);\n\tcmd->obss_max = a_cpu_to_sle32(he_obss_pd->max_offset);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_PDEV_OBSS_PD_SPATIAL_REUSE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ab,\n\t\t\t    \"Failed to send WMI_PDEV_OBSS_PD_SPATIAL_REUSE_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint ath12k_wmi_obss_color_cfg_cmd(struct ath12k *ar, u32 vdev_id,\n\t\t\t\t  u8 bss_color, u32 period,\n\t\t\t\t  bool enable)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct ath12k_base *ab = wmi->wmi_ab->ab;\n\tstruct wmi_obss_color_collision_cfg_params_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret, len;\n\n\tlen = sizeof(*cmd);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_obss_color_collision_cfg_params_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_OBSS_COLOR_COLLISION_DET_CONFIG,\n\t\t\t\t\t\t len);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->evt_type = enable ? cpu_to_le32(ATH12K_OBSS_COLOR_COLLISION_DETECTION) :\n\t\tcpu_to_le32(ATH12K_OBSS_COLOR_COLLISION_DETECTION_DISABLE);\n\tcmd->current_bss_color = cpu_to_le32(bss_color);\n\tcmd->detection_period_ms = cpu_to_le32(period);\n\tcmd->scan_period_ms = cpu_to_le32(ATH12K_BSS_COLOR_COLLISION_SCAN_PERIOD_MS);\n\tcmd->free_slot_expiry_time_ms = 0;\n\tcmd->flags = 0;\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi_send_obss_color_collision_cfg id %d type %d bss_color %d detect_period %d scan_period %d\\n\",\n\t\t   cmd->vdev_id, cmd->evt_type, cmd->current_bss_color,\n\t\t   cmd->detection_period_ms, cmd->scan_period_ms);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_OBSS_COLOR_COLLISION_DET_CONFIG_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ab, \"Failed to send WMI_OBSS_COLOR_COLLISION_DET_CONFIG_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint ath12k_wmi_send_bss_color_change_enable_cmd(struct ath12k *ar, u32 vdev_id,\n\t\t\t\t\t\tbool enable)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct ath12k_base *ab = wmi->wmi_ab->ab;\n\tstruct wmi_bss_color_change_enable_params_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret, len;\n\n\tlen = sizeof(*cmd);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_bss_color_change_enable_params_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_BSS_COLOR_CHANGE_ENABLE,\n\t\t\t\t\t\t len);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->enable = enable ? cpu_to_le32(1) : 0;\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"wmi_send_bss_color_change_enable id %d enable %d\\n\",\n\t\t   cmd->vdev_id, cmd->enable);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb,\n\t\t\t\t  WMI_BSS_COLOR_CHANGE_ENABLE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ab, \"Failed to send WMI_BSS_COLOR_CHANGE_ENABLE_CMDID\");\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint ath12k_wmi_fils_discovery_tmpl(struct ath12k *ar, u32 vdev_id,\n\t\t\t\t   struct sk_buff *tmpl)\n{\n\tstruct wmi_tlv *tlv;\n\tstruct sk_buff *skb;\n\tvoid *ptr;\n\tint ret, len;\n\tsize_t aligned_len;\n\tstruct wmi_fils_discovery_tmpl_cmd *cmd;\n\n\taligned_len = roundup(tmpl->len, 4);\n\tlen = sizeof(*cmd) + TLV_HDR_SIZE + aligned_len;\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev %i set FILS discovery template\\n\", vdev_id);\n\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_fils_discovery_tmpl_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_FILS_DISCOVERY_TMPL_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->buf_len = cpu_to_le32(tmpl->len);\n\tptr = skb->data + sizeof(*cmd);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, aligned_len);\n\tmemcpy(tlv->value, tmpl->data, tmpl->len);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb, WMI_FILS_DISCOVERY_TMPL_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"WMI vdev %i failed to send FILS discovery template command\\n\",\n\t\t\t    vdev_id);\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint ath12k_wmi_probe_resp_tmpl(struct ath12k *ar, u32 vdev_id,\n\t\t\t       struct sk_buff *tmpl)\n{\n\tstruct wmi_probe_tmpl_cmd *cmd;\n\tstruct ath12k_wmi_bcn_prb_info_params *probe_info;\n\tstruct wmi_tlv *tlv;\n\tstruct sk_buff *skb;\n\tvoid *ptr;\n\tint ret, len;\n\tsize_t aligned_len = roundup(tmpl->len, 4);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev %i set probe response template\\n\", vdev_id);\n\n\tlen = sizeof(*cmd) + sizeof(*probe_info) + TLV_HDR_SIZE + aligned_len;\n\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_probe_tmpl_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PRB_TMPL_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->buf_len = cpu_to_le32(tmpl->len);\n\n\tptr = skb->data + sizeof(*cmd);\n\n\tprobe_info = ptr;\n\tlen = sizeof(*probe_info);\n\tprobe_info->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_BCN_PRB_INFO,\n\t\t\t\t\t\t\tlen);\n\tprobe_info->caps = 0;\n\tprobe_info->erp = 0;\n\n\tptr += sizeof(*probe_info);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_BYTE, aligned_len);\n\tmemcpy(tlv->value, tmpl->data, tmpl->len);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb, WMI_PRB_TMPL_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"WMI vdev %i failed to send probe response template command\\n\",\n\t\t\t    vdev_id);\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nint ath12k_wmi_fils_discovery(struct ath12k *ar, u32 vdev_id, u32 interval,\n\t\t\t      bool unsol_bcast_probe_resp_enabled)\n{\n\tstruct sk_buff *skb;\n\tint ret, len;\n\tstruct wmi_fils_discovery_cmd *cmd;\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI vdev %i set %s interval to %u TU\\n\",\n\t\t   vdev_id, unsol_bcast_probe_resp_enabled ?\n\t\t   \"unsolicited broadcast probe response\" : \"FILS discovery\",\n\t\t   interval);\n\n\tlen = sizeof(*cmd);\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_fils_discovery_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_ENABLE_FILS_CMD,\n\t\t\t\t\t\t len);\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->interval = cpu_to_le32(interval);\n\tcmd->config = cpu_to_le32(unsol_bcast_probe_resp_enabled);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb, WMI_ENABLE_FILS_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"WMI vdev %i failed to send FILS discovery enable/disable command\\n\",\n\t\t\t    vdev_id);\n\t\tdev_kfree_skb(skb);\n\t}\n\treturn ret;\n}\n\nstatic void\nath12k_fill_band_to_mac_param(struct ath12k_base  *soc,\n\t\t\t      struct ath12k_wmi_pdev_band_arg *arg)\n{\n\tu8 i;\n\tstruct ath12k_wmi_hal_reg_capabilities_ext_arg *hal_reg_cap;\n\tstruct ath12k_pdev *pdev;\n\n\tfor (i = 0; i < soc->num_radios; i++) {\n\t\tpdev = &soc->pdevs[i];\n\t\thal_reg_cap = &soc->hal_reg_cap[i];\n\t\targ[i].pdev_id = pdev->pdev_id;\n\n\t\tswitch (pdev->cap.supported_bands) {\n\t\tcase WMI_HOST_WLAN_2G_5G_CAP:\n\t\t\targ[i].start_freq = hal_reg_cap->low_2ghz_chan;\n\t\t\targ[i].end_freq = hal_reg_cap->high_5ghz_chan;\n\t\t\tbreak;\n\t\tcase WMI_HOST_WLAN_2G_CAP:\n\t\t\targ[i].start_freq = hal_reg_cap->low_2ghz_chan;\n\t\t\targ[i].end_freq = hal_reg_cap->high_2ghz_chan;\n\t\t\tbreak;\n\t\tcase WMI_HOST_WLAN_5G_CAP:\n\t\t\targ[i].start_freq = hal_reg_cap->low_5ghz_chan;\n\t\t\targ[i].end_freq = hal_reg_cap->high_5ghz_chan;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic void\nath12k_wmi_copy_resource_config(struct ath12k_wmi_resource_config_params *wmi_cfg,\n\t\t\t\tstruct ath12k_wmi_resource_config_arg *tg_cfg)\n{\n\twmi_cfg->num_vdevs = cpu_to_le32(tg_cfg->num_vdevs);\n\twmi_cfg->num_peers = cpu_to_le32(tg_cfg->num_peers);\n\twmi_cfg->num_offload_peers = cpu_to_le32(tg_cfg->num_offload_peers);\n\twmi_cfg->num_offload_reorder_buffs =\n\t\tcpu_to_le32(tg_cfg->num_offload_reorder_buffs);\n\twmi_cfg->num_peer_keys = cpu_to_le32(tg_cfg->num_peer_keys);\n\twmi_cfg->num_tids = cpu_to_le32(tg_cfg->num_tids);\n\twmi_cfg->ast_skid_limit = cpu_to_le32(tg_cfg->ast_skid_limit);\n\twmi_cfg->tx_chain_mask = cpu_to_le32(tg_cfg->tx_chain_mask);\n\twmi_cfg->rx_chain_mask = cpu_to_le32(tg_cfg->rx_chain_mask);\n\twmi_cfg->rx_timeout_pri[0] = cpu_to_le32(tg_cfg->rx_timeout_pri[0]);\n\twmi_cfg->rx_timeout_pri[1] = cpu_to_le32(tg_cfg->rx_timeout_pri[1]);\n\twmi_cfg->rx_timeout_pri[2] = cpu_to_le32(tg_cfg->rx_timeout_pri[2]);\n\twmi_cfg->rx_timeout_pri[3] = cpu_to_le32(tg_cfg->rx_timeout_pri[3]);\n\twmi_cfg->rx_decap_mode = cpu_to_le32(tg_cfg->rx_decap_mode);\n\twmi_cfg->scan_max_pending_req = cpu_to_le32(tg_cfg->scan_max_pending_req);\n\twmi_cfg->bmiss_offload_max_vdev = cpu_to_le32(tg_cfg->bmiss_offload_max_vdev);\n\twmi_cfg->roam_offload_max_vdev = cpu_to_le32(tg_cfg->roam_offload_max_vdev);\n\twmi_cfg->roam_offload_max_ap_profiles =\n\t\tcpu_to_le32(tg_cfg->roam_offload_max_ap_profiles);\n\twmi_cfg->num_mcast_groups = cpu_to_le32(tg_cfg->num_mcast_groups);\n\twmi_cfg->num_mcast_table_elems = cpu_to_le32(tg_cfg->num_mcast_table_elems);\n\twmi_cfg->mcast2ucast_mode = cpu_to_le32(tg_cfg->mcast2ucast_mode);\n\twmi_cfg->tx_dbg_log_size = cpu_to_le32(tg_cfg->tx_dbg_log_size);\n\twmi_cfg->num_wds_entries = cpu_to_le32(tg_cfg->num_wds_entries);\n\twmi_cfg->dma_burst_size = cpu_to_le32(tg_cfg->dma_burst_size);\n\twmi_cfg->mac_aggr_delim = cpu_to_le32(tg_cfg->mac_aggr_delim);\n\twmi_cfg->rx_skip_defrag_timeout_dup_detection_check =\n\t\tcpu_to_le32(tg_cfg->rx_skip_defrag_timeout_dup_detection_check);\n\twmi_cfg->vow_config = cpu_to_le32(tg_cfg->vow_config);\n\twmi_cfg->gtk_offload_max_vdev = cpu_to_le32(tg_cfg->gtk_offload_max_vdev);\n\twmi_cfg->num_msdu_desc = cpu_to_le32(tg_cfg->num_msdu_desc);\n\twmi_cfg->max_frag_entries = cpu_to_le32(tg_cfg->max_frag_entries);\n\twmi_cfg->num_tdls_vdevs = cpu_to_le32(tg_cfg->num_tdls_vdevs);\n\twmi_cfg->num_tdls_conn_table_entries =\n\t\tcpu_to_le32(tg_cfg->num_tdls_conn_table_entries);\n\twmi_cfg->beacon_tx_offload_max_vdev =\n\t\tcpu_to_le32(tg_cfg->beacon_tx_offload_max_vdev);\n\twmi_cfg->num_multicast_filter_entries =\n\t\tcpu_to_le32(tg_cfg->num_multicast_filter_entries);\n\twmi_cfg->num_wow_filters = cpu_to_le32(tg_cfg->num_wow_filters);\n\twmi_cfg->num_keep_alive_pattern = cpu_to_le32(tg_cfg->num_keep_alive_pattern);\n\twmi_cfg->keep_alive_pattern_size = cpu_to_le32(tg_cfg->keep_alive_pattern_size);\n\twmi_cfg->max_tdls_concurrent_sleep_sta =\n\t\tcpu_to_le32(tg_cfg->max_tdls_concurrent_sleep_sta);\n\twmi_cfg->max_tdls_concurrent_buffer_sta =\n\t\tcpu_to_le32(tg_cfg->max_tdls_concurrent_buffer_sta);\n\twmi_cfg->wmi_send_separate = cpu_to_le32(tg_cfg->wmi_send_separate);\n\twmi_cfg->num_ocb_vdevs = cpu_to_le32(tg_cfg->num_ocb_vdevs);\n\twmi_cfg->num_ocb_channels = cpu_to_le32(tg_cfg->num_ocb_channels);\n\twmi_cfg->num_ocb_schedules = cpu_to_le32(tg_cfg->num_ocb_schedules);\n\twmi_cfg->bpf_instruction_size = cpu_to_le32(tg_cfg->bpf_instruction_size);\n\twmi_cfg->max_bssid_rx_filters = cpu_to_le32(tg_cfg->max_bssid_rx_filters);\n\twmi_cfg->use_pdev_id = cpu_to_le32(tg_cfg->use_pdev_id);\n\twmi_cfg->flag1 = cpu_to_le32(tg_cfg->atf_config);\n\twmi_cfg->peer_map_unmap_version = cpu_to_le32(tg_cfg->peer_map_unmap_version);\n\twmi_cfg->sched_params = cpu_to_le32(tg_cfg->sched_params);\n\twmi_cfg->twt_ap_pdev_count = cpu_to_le32(tg_cfg->twt_ap_pdev_count);\n\twmi_cfg->twt_ap_sta_count = cpu_to_le32(tg_cfg->twt_ap_sta_count);\n\twmi_cfg->host_service_flags = cpu_to_le32(tg_cfg->is_reg_cc_ext_event_supported <<\n\t\t\t\tWMI_RSRC_CFG_HOST_SVC_FLAG_REG_CC_EXT_SUPPORT_BIT);\n}\n\nstatic int ath12k_init_cmd_send(struct ath12k_wmi_pdev *wmi,\n\t\t\t\tstruct ath12k_wmi_init_cmd_arg *arg)\n{\n\tstruct ath12k_base *ab = wmi->wmi_ab->ab;\n\tstruct sk_buff *skb;\n\tstruct wmi_init_cmd *cmd;\n\tstruct ath12k_wmi_resource_config_params *cfg;\n\tstruct ath12k_wmi_pdev_set_hw_mode_cmd *hw_mode;\n\tstruct ath12k_wmi_pdev_band_to_mac_params *band_to_mac;\n\tstruct ath12k_wmi_host_mem_chunk_params *host_mem_chunks;\n\tstruct wmi_tlv *tlv;\n\tsize_t ret, len;\n\tvoid *ptr;\n\tu32 hw_mode_len = 0;\n\tu16 idx;\n\n\tif (arg->hw_mode_id != WMI_HOST_HW_MODE_MAX)\n\t\thw_mode_len = sizeof(*hw_mode) + TLV_HDR_SIZE +\n\t\t\t      (arg->num_band_to_mac * sizeof(*band_to_mac));\n\n\tlen = sizeof(*cmd) + TLV_HDR_SIZE + sizeof(*cfg) + hw_mode_len +\n\t      (arg->num_mem_chunks ? (sizeof(*host_mem_chunks) * WMI_MAX_MEM_REQS) : 0);\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_init_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_INIT_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tptr = skb->data + sizeof(*cmd);\n\tcfg = ptr;\n\n\tath12k_wmi_copy_resource_config(cfg, &arg->res_cfg);\n\n\tcfg->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_RESOURCE_CONFIG,\n\t\t\t\t\t\t sizeof(*cfg));\n\n\tptr += sizeof(*cfg);\n\thost_mem_chunks = ptr + TLV_HDR_SIZE;\n\tlen = sizeof(struct ath12k_wmi_host_mem_chunk_params);\n\n\tfor (idx = 0; idx < arg->num_mem_chunks; ++idx) {\n\t\thost_mem_chunks[idx].tlv_header =\n\t\t\tath12k_wmi_tlv_hdr(WMI_TAG_WLAN_HOST_MEMORY_CHUNK,\n\t\t\t\t\t   len);\n\n\t\thost_mem_chunks[idx].ptr = cpu_to_le32(arg->mem_chunks[idx].paddr);\n\t\thost_mem_chunks[idx].size = cpu_to_le32(arg->mem_chunks[idx].len);\n\t\thost_mem_chunks[idx].req_id = cpu_to_le32(arg->mem_chunks[idx].req_id);\n\n\t\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t\t   \"WMI host mem chunk req_id %d paddr 0x%llx len %d\\n\",\n\t\t\t   arg->mem_chunks[idx].req_id,\n\t\t\t   (u64)arg->mem_chunks[idx].paddr,\n\t\t\t   arg->mem_chunks[idx].len);\n\t}\n\tcmd->num_host_mem_chunks = cpu_to_le32(arg->num_mem_chunks);\n\tlen = sizeof(struct ath12k_wmi_host_mem_chunk_params) * arg->num_mem_chunks;\n\n\t \n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, len);\n\tptr += TLV_HDR_SIZE + len;\n\n\tif (arg->hw_mode_id != WMI_HOST_HW_MODE_MAX) {\n\t\thw_mode = (struct ath12k_wmi_pdev_set_hw_mode_cmd *)ptr;\n\t\thw_mode->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_SET_HW_MODE_CMD,\n\t\t\t\t\t\t\t     sizeof(*hw_mode));\n\n\t\thw_mode->hw_mode_index = cpu_to_le32(arg->hw_mode_id);\n\t\thw_mode->num_band_to_mac = cpu_to_le32(arg->num_band_to_mac);\n\n\t\tptr += sizeof(*hw_mode);\n\n\t\tlen = arg->num_band_to_mac * sizeof(*band_to_mac);\n\t\ttlv = ptr;\n\t\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_STRUCT, len);\n\n\t\tptr += TLV_HDR_SIZE;\n\t\tlen = sizeof(*band_to_mac);\n\n\t\tfor (idx = 0; idx < arg->num_band_to_mac; idx++) {\n\t\t\tband_to_mac = (void *)ptr;\n\n\t\t\tband_to_mac->tlv_header =\n\t\t\t\tath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_BAND_TO_MAC,\n\t\t\t\t\t\t       len);\n\t\t\tband_to_mac->pdev_id = cpu_to_le32(arg->band_to_mac[idx].pdev_id);\n\t\t\tband_to_mac->start_freq =\n\t\t\t\tcpu_to_le32(arg->band_to_mac[idx].start_freq);\n\t\t\tband_to_mac->end_freq =\n\t\t\t\tcpu_to_le32(arg->band_to_mac[idx].end_freq);\n\t\t\tptr += sizeof(*band_to_mac);\n\t\t}\n\t}\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_INIT_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to send WMI_INIT_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_pdev_lro_cfg(struct ath12k *ar,\n\t\t\t    int pdev_id)\n{\n\tstruct ath12k_wmi_pdev_lro_config_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct ath12k_wmi_pdev_lro_config_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_LRO_INFO_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tget_random_bytes(cmd->th_4, sizeof(cmd->th_4));\n\tget_random_bytes(cmd->th_6, sizeof(cmd->th_6));\n\n\tcmd->pdev_id = cpu_to_le32(pdev_id);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI lro cfg cmd pdev_id 0x%x\\n\", pdev_id);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb, WMI_LRO_CONFIG_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send lro cfg req wmi cmd\\n\");\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tdev_kfree_skb(skb);\n\treturn ret;\n}\n\nint ath12k_wmi_wait_for_service_ready(struct ath12k_base *ab)\n{\n\tunsigned long time_left;\n\n\ttime_left = wait_for_completion_timeout(&ab->wmi_ab.service_ready,\n\t\t\t\t\t\tWMI_SERVICE_READY_TIMEOUT_HZ);\n\tif (!time_left)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nint ath12k_wmi_wait_for_unified_ready(struct ath12k_base *ab)\n{\n\tunsigned long time_left;\n\n\ttime_left = wait_for_completion_timeout(&ab->wmi_ab.unified_ready,\n\t\t\t\t\t\tWMI_SERVICE_READY_TIMEOUT_HZ);\n\tif (!time_left)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nint ath12k_wmi_set_hw_mode(struct ath12k_base *ab,\n\t\t\t   enum wmi_host_hw_mode_config_type mode)\n{\n\tstruct ath12k_wmi_pdev_set_hw_mode_cmd *cmd;\n\tstruct sk_buff *skb;\n\tstruct ath12k_wmi_base *wmi_ab = &ab->wmi_ab;\n\tint len;\n\tint ret;\n\n\tlen = sizeof(*cmd);\n\n\tskb = ath12k_wmi_alloc_skb(wmi_ab, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct ath12k_wmi_pdev_set_hw_mode_cmd *)skb->data;\n\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_PDEV_SET_HW_MODE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->pdev_id = WMI_PDEV_ID_SOC;\n\tcmd->hw_mode_index = cpu_to_le32(mode);\n\n\tret = ath12k_wmi_cmd_send(&wmi_ab->wmi[0], skb, WMI_PDEV_SET_HW_MODE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to send WMI_PDEV_SET_HW_MODE_CMDID\\n\");\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_cmd_init(struct ath12k_base *ab)\n{\n\tstruct ath12k_wmi_base *wmi_sc = &ab->wmi_ab;\n\tstruct ath12k_wmi_init_cmd_arg arg = {};\n\n\tif (test_bit(WMI_TLV_SERVICE_REG_CC_EXT_EVENT_SUPPORT,\n\t\t     ab->wmi_ab.svc_map))\n\t\targ.res_cfg.is_reg_cc_ext_event_supported = true;\n\n\tab->hw_params->wmi_init(ab, &arg.res_cfg);\n\n\targ.num_mem_chunks = wmi_sc->num_mem_chunks;\n\targ.hw_mode_id = wmi_sc->preferred_hw_mode;\n\targ.mem_chunks = wmi_sc->mem_chunks;\n\n\tif (ab->hw_params->single_pdev_only)\n\t\targ.hw_mode_id = WMI_HOST_HW_MODE_MAX;\n\n\targ.num_band_to_mac = ab->num_radios;\n\tath12k_fill_band_to_mac_param(ab, arg.band_to_mac);\n\n\treturn ath12k_init_cmd_send(&wmi_sc->wmi[0], &arg);\n}\n\nint ath12k_wmi_vdev_spectral_conf(struct ath12k *ar,\n\t\t\t\t  struct ath12k_wmi_vdev_spectral_conf_arg *arg)\n{\n\tstruct ath12k_wmi_vdev_spectral_conf_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct ath12k_wmi_vdev_spectral_conf_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_SPECTRAL_CONFIGURE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\tcmd->vdev_id = cpu_to_le32(arg->vdev_id);\n\tcmd->scan_count = cpu_to_le32(arg->scan_count);\n\tcmd->scan_period = cpu_to_le32(arg->scan_period);\n\tcmd->scan_priority = cpu_to_le32(arg->scan_priority);\n\tcmd->scan_fft_size = cpu_to_le32(arg->scan_fft_size);\n\tcmd->scan_gc_ena = cpu_to_le32(arg->scan_gc_ena);\n\tcmd->scan_restart_ena = cpu_to_le32(arg->scan_restart_ena);\n\tcmd->scan_noise_floor_ref = cpu_to_le32(arg->scan_noise_floor_ref);\n\tcmd->scan_init_delay = cpu_to_le32(arg->scan_init_delay);\n\tcmd->scan_nb_tone_thr = cpu_to_le32(arg->scan_nb_tone_thr);\n\tcmd->scan_str_bin_thr = cpu_to_le32(arg->scan_str_bin_thr);\n\tcmd->scan_wb_rpt_mode = cpu_to_le32(arg->scan_wb_rpt_mode);\n\tcmd->scan_rssi_rpt_mode = cpu_to_le32(arg->scan_rssi_rpt_mode);\n\tcmd->scan_rssi_thr = cpu_to_le32(arg->scan_rssi_thr);\n\tcmd->scan_pwr_format = cpu_to_le32(arg->scan_pwr_format);\n\tcmd->scan_rpt_mode = cpu_to_le32(arg->scan_rpt_mode);\n\tcmd->scan_bin_scale = cpu_to_le32(arg->scan_bin_scale);\n\tcmd->scan_dbm_adj = cpu_to_le32(arg->scan_dbm_adj);\n\tcmd->scan_chn_mask = cpu_to_le32(arg->scan_chn_mask);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI spectral scan config cmd vdev_id 0x%x\\n\",\n\t\t   arg->vdev_id);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb,\n\t\t\t\t  WMI_VDEV_SPECTRAL_SCAN_CONFIGURE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send spectral scan config wmi cmd\\n\");\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tdev_kfree_skb(skb);\n\treturn ret;\n}\n\nint ath12k_wmi_vdev_spectral_enable(struct ath12k *ar, u32 vdev_id,\n\t\t\t\t    u32 trigger, u32 enable)\n{\n\tstruct ath12k_wmi_vdev_spectral_enable_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct ath12k_wmi_vdev_spectral_enable_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_VDEV_SPECTRAL_ENABLE_CMD,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->vdev_id = cpu_to_le32(vdev_id);\n\tcmd->trigger_cmd = cpu_to_le32(trigger);\n\tcmd->enable_cmd = cpu_to_le32(enable);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI spectral enable cmd vdev id 0x%x\\n\",\n\t\t   vdev_id);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb,\n\t\t\t\t  WMI_VDEV_SPECTRAL_SCAN_ENABLE_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send spectral enable wmi cmd\\n\");\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tdev_kfree_skb(skb);\n\treturn ret;\n}\n\nint ath12k_wmi_pdev_dma_ring_cfg(struct ath12k *ar,\n\t\t\t\t struct ath12k_wmi_pdev_dma_ring_cfg_arg *arg)\n{\n\tstruct ath12k_wmi_pdev_dma_ring_cfg_req_cmd *cmd;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tskb = ath12k_wmi_alloc_skb(ar->wmi->wmi_ab, sizeof(*cmd));\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct ath12k_wmi_pdev_dma_ring_cfg_req_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_DMA_RING_CFG_REQ,\n\t\t\t\t\t\t sizeof(*cmd));\n\n\tcmd->pdev_id = cpu_to_le32(DP_SW2HW_MACID(arg->pdev_id));\n\tcmd->module_id = cpu_to_le32(arg->module_id);\n\tcmd->base_paddr_lo = cpu_to_le32(arg->base_paddr_lo);\n\tcmd->base_paddr_hi = cpu_to_le32(arg->base_paddr_hi);\n\tcmd->head_idx_paddr_lo = cpu_to_le32(arg->head_idx_paddr_lo);\n\tcmd->head_idx_paddr_hi = cpu_to_le32(arg->head_idx_paddr_hi);\n\tcmd->tail_idx_paddr_lo = cpu_to_le32(arg->tail_idx_paddr_lo);\n\tcmd->tail_idx_paddr_hi = cpu_to_le32(arg->tail_idx_paddr_hi);\n\tcmd->num_elems = cpu_to_le32(arg->num_elems);\n\tcmd->buf_size = cpu_to_le32(arg->buf_size);\n\tcmd->num_resp_per_event = cpu_to_le32(arg->num_resp_per_event);\n\tcmd->event_timeout_ms = cpu_to_le32(arg->event_timeout_ms);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI DMA ring cfg req cmd pdev_id 0x%x\\n\",\n\t\t   arg->pdev_id);\n\n\tret = ath12k_wmi_cmd_send(ar->wmi, skb,\n\t\t\t\t  WMI_PDEV_DMA_RING_CFG_REQ_CMDID);\n\tif (ret) {\n\t\tath12k_warn(ar->ab,\n\t\t\t    \"failed to send dma ring cfg req wmi cmd\\n\");\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tdev_kfree_skb(skb);\n\treturn ret;\n}\n\nstatic int ath12k_wmi_dma_buf_entry_parse(struct ath12k_base *soc,\n\t\t\t\t\t  u16 tag, u16 len,\n\t\t\t\t\t  const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_dma_buf_release_arg *arg = data;\n\n\tif (tag != WMI_TAG_DMA_BUF_RELEASE_ENTRY)\n\t\treturn -EPROTO;\n\n\tif (arg->num_buf_entry >= le32_to_cpu(arg->fixed.num_buf_release_entry))\n\t\treturn -ENOBUFS;\n\n\targ->num_buf_entry++;\n\treturn 0;\n}\n\nstatic int ath12k_wmi_dma_buf_meta_parse(struct ath12k_base *soc,\n\t\t\t\t\t u16 tag, u16 len,\n\t\t\t\t\t const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_dma_buf_release_arg *arg = data;\n\n\tif (tag != WMI_TAG_DMA_BUF_RELEASE_SPECTRAL_META_DATA)\n\t\treturn -EPROTO;\n\n\tif (arg->num_meta >= le32_to_cpu(arg->fixed.num_meta_data_entry))\n\t\treturn -ENOBUFS;\n\n\targ->num_meta++;\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_dma_buf_parse(struct ath12k_base *ab,\n\t\t\t\t    u16 tag, u16 len,\n\t\t\t\t    const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_dma_buf_release_arg *arg = data;\n\tconst struct ath12k_wmi_dma_buf_release_fixed_params *fixed;\n\tu32 pdev_id;\n\tint ret;\n\n\tswitch (tag) {\n\tcase WMI_TAG_DMA_BUF_RELEASE:\n\t\tfixed = ptr;\n\t\targ->fixed = *fixed;\n\t\tpdev_id = DP_HW2SW_MACID(le32_to_cpu(fixed->pdev_id));\n\t\targ->fixed.pdev_id = cpu_to_le32(pdev_id);\n\t\tbreak;\n\tcase WMI_TAG_ARRAY_STRUCT:\n\t\tif (!arg->buf_entry_done) {\n\t\t\targ->num_buf_entry = 0;\n\t\t\targ->buf_entry = ptr;\n\n\t\t\tret = ath12k_wmi_tlv_iter(ab, ptr, len,\n\t\t\t\t\t\t  ath12k_wmi_dma_buf_entry_parse,\n\t\t\t\t\t\t  arg);\n\t\t\tif (ret) {\n\t\t\t\tath12k_warn(ab, \"failed to parse dma buf entry tlv %d\\n\",\n\t\t\t\t\t    ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\targ->buf_entry_done = true;\n\t\t} else if (!arg->meta_data_done) {\n\t\t\targ->num_meta = 0;\n\t\t\targ->meta_data = ptr;\n\n\t\t\tret = ath12k_wmi_tlv_iter(ab, ptr, len,\n\t\t\t\t\t\t  ath12k_wmi_dma_buf_meta_parse,\n\t\t\t\t\t\t  arg);\n\t\t\tif (ret) {\n\t\t\t\tath12k_warn(ab, \"failed to parse dma buf meta tlv %d\\n\",\n\t\t\t\t\t    ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\targ->meta_data_done = true;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void ath12k_wmi_pdev_dma_ring_buf_release_event(struct ath12k_base *ab,\n\t\t\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct ath12k_wmi_dma_buf_release_arg arg = {};\n\tstruct ath12k_dbring_buf_release_event param;\n\tint ret;\n\n\tret = ath12k_wmi_tlv_iter(ab, skb->data, skb->len,\n\t\t\t\t  ath12k_wmi_dma_buf_parse,\n\t\t\t\t  &arg);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to parse dma buf release tlv %d\\n\", ret);\n\t\treturn;\n\t}\n\n\tparam.fixed = arg.fixed;\n\tparam.buf_entry = arg.buf_entry;\n\tparam.num_buf_entry = arg.num_buf_entry;\n\tparam.meta_data = arg.meta_data;\n\tparam.num_meta = arg.num_meta;\n\n\tret = ath12k_dbring_buffer_release_event(ab, &param);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to handle dma buf release event %d\\n\", ret);\n\t\treturn;\n\t}\n}\n\nstatic int ath12k_wmi_hw_mode_caps_parse(struct ath12k_base *soc,\n\t\t\t\t\t u16 tag, u16 len,\n\t\t\t\t\t const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_svc_rdy_ext_parse *svc_rdy_ext = data;\n\tstruct ath12k_wmi_hw_mode_cap_params *hw_mode_cap;\n\tu32 phy_map = 0;\n\n\tif (tag != WMI_TAG_HW_MODE_CAPABILITIES)\n\t\treturn -EPROTO;\n\n\tif (svc_rdy_ext->n_hw_mode_caps >= svc_rdy_ext->arg.num_hw_modes)\n\t\treturn -ENOBUFS;\n\n\thw_mode_cap = container_of(ptr, struct ath12k_wmi_hw_mode_cap_params,\n\t\t\t\t   hw_mode_id);\n\tsvc_rdy_ext->n_hw_mode_caps++;\n\n\tphy_map = le32_to_cpu(hw_mode_cap->phy_id_map);\n\tsvc_rdy_ext->tot_phy_id += fls(phy_map);\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_hw_mode_caps(struct ath12k_base *soc,\n\t\t\t\t   u16 len, const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_svc_rdy_ext_parse *svc_rdy_ext = data;\n\tconst struct ath12k_wmi_hw_mode_cap_params *hw_mode_caps;\n\tenum wmi_host_hw_mode_config_type mode, pref;\n\tu32 i;\n\tint ret;\n\n\tsvc_rdy_ext->n_hw_mode_caps = 0;\n\tsvc_rdy_ext->hw_mode_caps = ptr;\n\n\tret = ath12k_wmi_tlv_iter(soc, ptr, len,\n\t\t\t\t  ath12k_wmi_hw_mode_caps_parse,\n\t\t\t\t  svc_rdy_ext);\n\tif (ret) {\n\t\tath12k_warn(soc, \"failed to parse tlv %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0 ; i < svc_rdy_ext->n_hw_mode_caps; i++) {\n\t\thw_mode_caps = &svc_rdy_ext->hw_mode_caps[i];\n\t\tmode = le32_to_cpu(hw_mode_caps->hw_mode_id);\n\n\t\tif (mode >= WMI_HOST_HW_MODE_MAX)\n\t\t\tcontinue;\n\n\t\tpref = soc->wmi_ab.preferred_hw_mode;\n\n\t\tif (ath12k_hw_mode_pri_map[mode] < ath12k_hw_mode_pri_map[pref]) {\n\t\t\tsvc_rdy_ext->pref_hw_mode_caps = *hw_mode_caps;\n\t\t\tsoc->wmi_ab.preferred_hw_mode = mode;\n\t\t}\n\t}\n\n\tath12k_dbg(soc, ATH12K_DBG_WMI, \"preferred_hw_mode:%d\\n\",\n\t\t   soc->wmi_ab.preferred_hw_mode);\n\tif (soc->wmi_ab.preferred_hw_mode == WMI_HOST_HW_MODE_MAX)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_mac_phy_caps_parse(struct ath12k_base *soc,\n\t\t\t\t\t u16 tag, u16 len,\n\t\t\t\t\t const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_svc_rdy_ext_parse *svc_rdy_ext = data;\n\n\tif (tag != WMI_TAG_MAC_PHY_CAPABILITIES)\n\t\treturn -EPROTO;\n\n\tif (svc_rdy_ext->n_mac_phy_caps >= svc_rdy_ext->tot_phy_id)\n\t\treturn -ENOBUFS;\n\n\tlen = min_t(u16, len, sizeof(struct ath12k_wmi_mac_phy_caps_params));\n\tif (!svc_rdy_ext->n_mac_phy_caps) {\n\t\tsvc_rdy_ext->mac_phy_caps = kzalloc((svc_rdy_ext->tot_phy_id) * len,\n\t\t\t\t\t\t    GFP_ATOMIC);\n\t\tif (!svc_rdy_ext->mac_phy_caps)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tmemcpy(svc_rdy_ext->mac_phy_caps + svc_rdy_ext->n_mac_phy_caps, ptr, len);\n\tsvc_rdy_ext->n_mac_phy_caps++;\n\treturn 0;\n}\n\nstatic int ath12k_wmi_ext_hal_reg_caps_parse(struct ath12k_base *soc,\n\t\t\t\t\t     u16 tag, u16 len,\n\t\t\t\t\t     const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_svc_rdy_ext_parse *svc_rdy_ext = data;\n\n\tif (tag != WMI_TAG_HAL_REG_CAPABILITIES_EXT)\n\t\treturn -EPROTO;\n\n\tif (svc_rdy_ext->n_ext_hal_reg_caps >= svc_rdy_ext->arg.num_phy)\n\t\treturn -ENOBUFS;\n\n\tsvc_rdy_ext->n_ext_hal_reg_caps++;\n\treturn 0;\n}\n\nstatic int ath12k_wmi_ext_hal_reg_caps(struct ath12k_base *soc,\n\t\t\t\t       u16 len, const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_pdev *wmi_handle = &soc->wmi_ab.wmi[0];\n\tstruct ath12k_wmi_svc_rdy_ext_parse *svc_rdy_ext = data;\n\tstruct ath12k_wmi_hal_reg_capabilities_ext_arg reg_cap;\n\tint ret;\n\tu32 i;\n\n\tsvc_rdy_ext->n_ext_hal_reg_caps = 0;\n\tsvc_rdy_ext->ext_hal_reg_caps = ptr;\n\tret = ath12k_wmi_tlv_iter(soc, ptr, len,\n\t\t\t\t  ath12k_wmi_ext_hal_reg_caps_parse,\n\t\t\t\t  svc_rdy_ext);\n\tif (ret) {\n\t\tath12k_warn(soc, \"failed to parse tlv %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tfor (i = 0; i < svc_rdy_ext->arg.num_phy; i++) {\n\t\tret = ath12k_pull_reg_cap_svc_rdy_ext(wmi_handle,\n\t\t\t\t\t\t      svc_rdy_ext->soc_hal_reg_caps,\n\t\t\t\t\t\t      svc_rdy_ext->ext_hal_reg_caps, i,\n\t\t\t\t\t\t      &reg_cap);\n\t\tif (ret) {\n\t\t\tath12k_warn(soc, \"failed to extract reg cap %d\\n\", i);\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (reg_cap.phy_id >= MAX_RADIOS) {\n\t\t\tath12k_warn(soc, \"unexpected phy id %u\\n\", reg_cap.phy_id);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tsoc->hal_reg_cap[reg_cap.phy_id] = reg_cap;\n\t}\n\treturn 0;\n}\n\nstatic int ath12k_wmi_ext_soc_hal_reg_caps_parse(struct ath12k_base *soc,\n\t\t\t\t\t\t u16 len, const void *ptr,\n\t\t\t\t\t\t void *data)\n{\n\tstruct ath12k_wmi_pdev *wmi_handle = &soc->wmi_ab.wmi[0];\n\tstruct ath12k_wmi_svc_rdy_ext_parse *svc_rdy_ext = data;\n\tu8 hw_mode_id = le32_to_cpu(svc_rdy_ext->pref_hw_mode_caps.hw_mode_id);\n\tu32 phy_id_map;\n\tint pdev_index = 0;\n\tint ret;\n\n\tsvc_rdy_ext->soc_hal_reg_caps = ptr;\n\tsvc_rdy_ext->arg.num_phy = le32_to_cpu(svc_rdy_ext->soc_hal_reg_caps->num_phy);\n\n\tsoc->num_radios = 0;\n\tphy_id_map = le32_to_cpu(svc_rdy_ext->pref_hw_mode_caps.phy_id_map);\n\tsoc->fw_pdev_count = 0;\n\n\twhile (phy_id_map && soc->num_radios < MAX_RADIOS) {\n\t\tret = ath12k_pull_mac_phy_cap_svc_ready_ext(wmi_handle,\n\t\t\t\t\t\t\t    svc_rdy_ext,\n\t\t\t\t\t\t\t    hw_mode_id, soc->num_radios,\n\t\t\t\t\t\t\t    &soc->pdevs[pdev_index]);\n\t\tif (ret) {\n\t\t\tath12k_warn(soc, \"failed to extract mac caps, idx :%d\\n\",\n\t\t\t\t    soc->num_radios);\n\t\t\treturn ret;\n\t\t}\n\n\t\tsoc->num_radios++;\n\n\t\t \n\t\tif (soc->hw_params->single_pdev_only)\n\t\t\tpdev_index = 0;\n\t\telse\n\t\t\tpdev_index = soc->num_radios;\n\n\t\t \n\t\tphy_id_map >>= 1;\n\t}\n\n\tif (soc->hw_params->single_pdev_only) {\n\t\tsoc->num_radios = 1;\n\t\tsoc->pdevs[0].pdev_id = 0;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_dma_ring_caps_parse(struct ath12k_base *soc,\n\t\t\t\t\t  u16 tag, u16 len,\n\t\t\t\t\t  const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_dma_ring_caps_parse *parse = data;\n\n\tif (tag != WMI_TAG_DMA_RING_CAPABILITIES)\n\t\treturn -EPROTO;\n\n\tparse->n_dma_ring_caps++;\n\treturn 0;\n}\n\nstatic int ath12k_wmi_alloc_dbring_caps(struct ath12k_base *ab,\n\t\t\t\t\tu32 num_cap)\n{\n\tsize_t sz;\n\tvoid *ptr;\n\n\tsz = num_cap * sizeof(struct ath12k_dbring_cap);\n\tptr = kzalloc(sz, GFP_ATOMIC);\n\tif (!ptr)\n\t\treturn -ENOMEM;\n\n\tab->db_caps = ptr;\n\tab->num_db_cap = num_cap;\n\n\treturn 0;\n}\n\nstatic void ath12k_wmi_free_dbring_caps(struct ath12k_base *ab)\n{\n\tkfree(ab->db_caps);\n\tab->db_caps = NULL;\n}\n\nstatic int ath12k_wmi_dma_ring_caps(struct ath12k_base *ab,\n\t\t\t\t    u16 len, const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_dma_ring_caps_parse *dma_caps_parse = data;\n\tstruct ath12k_wmi_dma_ring_caps_params *dma_caps;\n\tstruct ath12k_dbring_cap *dir_buff_caps;\n\tint ret;\n\tu32 i;\n\n\tdma_caps_parse->n_dma_ring_caps = 0;\n\tdma_caps = (struct ath12k_wmi_dma_ring_caps_params *)ptr;\n\tret = ath12k_wmi_tlv_iter(ab, ptr, len,\n\t\t\t\t  ath12k_wmi_dma_ring_caps_parse,\n\t\t\t\t  dma_caps_parse);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to parse dma ring caps tlv %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (!dma_caps_parse->n_dma_ring_caps)\n\t\treturn 0;\n\n\tif (ab->num_db_cap) {\n\t\tath12k_warn(ab, \"Already processed, so ignoring dma ring caps\\n\");\n\t\treturn 0;\n\t}\n\n\tret = ath12k_wmi_alloc_dbring_caps(ab, dma_caps_parse->n_dma_ring_caps);\n\tif (ret)\n\t\treturn ret;\n\n\tdir_buff_caps = ab->db_caps;\n\tfor (i = 0; i < dma_caps_parse->n_dma_ring_caps; i++) {\n\t\tif (le32_to_cpu(dma_caps[i].module_id) >= WMI_DIRECT_BUF_MAX) {\n\t\t\tath12k_warn(ab, \"Invalid module id %d\\n\",\n\t\t\t\t    le32_to_cpu(dma_caps[i].module_id));\n\t\t\tret = -EINVAL;\n\t\t\tgoto free_dir_buff;\n\t\t}\n\n\t\tdir_buff_caps[i].id = le32_to_cpu(dma_caps[i].module_id);\n\t\tdir_buff_caps[i].pdev_id =\n\t\t\tDP_HW2SW_MACID(le32_to_cpu(dma_caps[i].pdev_id));\n\t\tdir_buff_caps[i].min_elem = le32_to_cpu(dma_caps[i].min_elem);\n\t\tdir_buff_caps[i].min_buf_sz = le32_to_cpu(dma_caps[i].min_buf_sz);\n\t\tdir_buff_caps[i].min_buf_align = le32_to_cpu(dma_caps[i].min_buf_align);\n\t}\n\n\treturn 0;\n\nfree_dir_buff:\n\tath12k_wmi_free_dbring_caps(ab);\n\treturn ret;\n}\n\nstatic int ath12k_wmi_svc_rdy_ext_parse(struct ath12k_base *ab,\n\t\t\t\t\tu16 tag, u16 len,\n\t\t\t\t\tconst void *ptr, void *data)\n{\n\tstruct ath12k_wmi_pdev *wmi_handle = &ab->wmi_ab.wmi[0];\n\tstruct ath12k_wmi_svc_rdy_ext_parse *svc_rdy_ext = data;\n\tint ret;\n\n\tswitch (tag) {\n\tcase WMI_TAG_SERVICE_READY_EXT_EVENT:\n\t\tret = ath12k_pull_svc_ready_ext(wmi_handle, ptr,\n\t\t\t\t\t\t&svc_rdy_ext->arg);\n\t\tif (ret) {\n\t\t\tath12k_warn(ab, \"unable to extract ext params\\n\");\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\n\tcase WMI_TAG_SOC_MAC_PHY_HW_MODE_CAPS:\n\t\tsvc_rdy_ext->hw_caps = ptr;\n\t\tsvc_rdy_ext->arg.num_hw_modes =\n\t\t\tle32_to_cpu(svc_rdy_ext->hw_caps->num_hw_modes);\n\t\tbreak;\n\n\tcase WMI_TAG_SOC_HAL_REG_CAPABILITIES:\n\t\tret = ath12k_wmi_ext_soc_hal_reg_caps_parse(ab, len, ptr,\n\t\t\t\t\t\t\t    svc_rdy_ext);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tbreak;\n\n\tcase WMI_TAG_ARRAY_STRUCT:\n\t\tif (!svc_rdy_ext->hw_mode_done) {\n\t\t\tret = ath12k_wmi_hw_mode_caps(ab, len, ptr, svc_rdy_ext);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tsvc_rdy_ext->hw_mode_done = true;\n\t\t} else if (!svc_rdy_ext->mac_phy_done) {\n\t\t\tsvc_rdy_ext->n_mac_phy_caps = 0;\n\t\t\tret = ath12k_wmi_tlv_iter(ab, ptr, len,\n\t\t\t\t\t\t  ath12k_wmi_mac_phy_caps_parse,\n\t\t\t\t\t\t  svc_rdy_ext);\n\t\t\tif (ret) {\n\t\t\t\tath12k_warn(ab, \"failed to parse tlv %d\\n\", ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tsvc_rdy_ext->mac_phy_done = true;\n\t\t} else if (!svc_rdy_ext->ext_hal_reg_done) {\n\t\t\tret = ath12k_wmi_ext_hal_reg_caps(ab, len, ptr, svc_rdy_ext);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tsvc_rdy_ext->ext_hal_reg_done = true;\n\t\t} else if (!svc_rdy_ext->mac_phy_chainmask_combo_done) {\n\t\t\tsvc_rdy_ext->mac_phy_chainmask_combo_done = true;\n\t\t} else if (!svc_rdy_ext->mac_phy_chainmask_cap_done) {\n\t\t\tsvc_rdy_ext->mac_phy_chainmask_cap_done = true;\n\t\t} else if (!svc_rdy_ext->oem_dma_ring_cap_done) {\n\t\t\tsvc_rdy_ext->oem_dma_ring_cap_done = true;\n\t\t} else if (!svc_rdy_ext->dma_ring_cap_done) {\n\t\t\tret = ath12k_wmi_dma_ring_caps(ab, len, ptr,\n\t\t\t\t\t\t       &svc_rdy_ext->dma_caps_parse);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tsvc_rdy_ext->dma_ring_cap_done = true;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int ath12k_service_ready_ext_event(struct ath12k_base *ab,\n\t\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct ath12k_wmi_svc_rdy_ext_parse svc_rdy_ext = { };\n\tint ret;\n\n\tret = ath12k_wmi_tlv_iter(ab, skb->data, skb->len,\n\t\t\t\t  ath12k_wmi_svc_rdy_ext_parse,\n\t\t\t\t  &svc_rdy_ext);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to parse tlv %d\\n\", ret);\n\t\tgoto err;\n\t}\n\n\tif (!test_bit(WMI_TLV_SERVICE_EXT2_MSG, ab->wmi_ab.svc_map))\n\t\tcomplete(&ab->wmi_ab.service_ready);\n\n\tkfree(svc_rdy_ext.mac_phy_caps);\n\treturn 0;\n\nerr:\n\tath12k_wmi_free_dbring_caps(ab);\n\treturn ret;\n}\n\nstatic int ath12k_pull_svc_ready_ext2(struct ath12k_wmi_pdev *wmi_handle,\n\t\t\t\t      const void *ptr,\n\t\t\t\t      struct ath12k_wmi_svc_rdy_ext2_arg *arg)\n{\n\tconst struct wmi_service_ready_ext2_event *ev = ptr;\n\n\tif (!ev)\n\t\treturn -EINVAL;\n\n\targ->reg_db_version = le32_to_cpu(ev->reg_db_version);\n\targ->hw_min_max_tx_power_2ghz = le32_to_cpu(ev->hw_min_max_tx_power_2ghz);\n\targ->hw_min_max_tx_power_5ghz = le32_to_cpu(ev->hw_min_max_tx_power_5ghz);\n\targ->chwidth_num_peer_caps = le32_to_cpu(ev->chwidth_num_peer_caps);\n\targ->preamble_puncture_bw = le32_to_cpu(ev->preamble_puncture_bw);\n\targ->max_user_per_ppdu_ofdma = le32_to_cpu(ev->max_user_per_ppdu_ofdma);\n\targ->max_user_per_ppdu_mumimo = le32_to_cpu(ev->max_user_per_ppdu_mumimo);\n\targ->target_cap_flags = le32_to_cpu(ev->target_cap_flags);\n\treturn 0;\n}\n\nstatic void ath12k_wmi_eht_caps_parse(struct ath12k_pdev *pdev, u32 band,\n\t\t\t\t      const __le32 cap_mac_info[],\n\t\t\t\t      const __le32 cap_phy_info[],\n\t\t\t\t      const __le32 supp_mcs[],\n\t\t\t\t      const struct ath12k_wmi_ppe_threshold_params *ppet,\n\t\t\t\t       __le32 cap_info_internal)\n{\n\tstruct ath12k_band_cap *cap_band = &pdev->cap.band[band];\n\tu8 i;\n\n\tfor (i = 0; i < WMI_MAX_EHTCAP_MAC_SIZE; i++)\n\t\tcap_band->eht_cap_mac_info[i] = le32_to_cpu(cap_mac_info[i]);\n\n\tfor (i = 0; i < WMI_MAX_EHTCAP_PHY_SIZE; i++)\n\t\tcap_band->eht_cap_phy_info[i] = le32_to_cpu(cap_phy_info[i]);\n\n\tcap_band->eht_mcs_20_only = le32_to_cpu(supp_mcs[0]);\n\tcap_band->eht_mcs_80 = le32_to_cpu(supp_mcs[1]);\n\tif (band != NL80211_BAND_2GHZ) {\n\t\tcap_band->eht_mcs_160 = le32_to_cpu(supp_mcs[2]);\n\t\tcap_band->eht_mcs_320 = le32_to_cpu(supp_mcs[3]);\n\t}\n\n\tcap_band->eht_ppet.numss_m1 = le32_to_cpu(ppet->numss_m1);\n\tcap_band->eht_ppet.ru_bit_mask = le32_to_cpu(ppet->ru_info);\n\tfor (i = 0; i < WMI_MAX_NUM_SS; i++)\n\t\tcap_band->eht_ppet.ppet16_ppet8_ru3_ru0[i] =\n\t\t\tle32_to_cpu(ppet->ppet16_ppet8_ru3_ru0[i]);\n\n\tcap_band->eht_cap_info_internal = le32_to_cpu(cap_info_internal);\n}\n\nstatic int\nath12k_wmi_tlv_mac_phy_caps_ext_parse(struct ath12k_base *ab,\n\t\t\t\t      const struct ath12k_wmi_caps_ext_params *caps,\n\t\t\t\t      struct ath12k_pdev *pdev)\n{\n\tu32 bands;\n\tint i;\n\n\tif (ab->hw_params->single_pdev_only) {\n\t\tfor (i = 0; i < ab->fw_pdev_count; i++) {\n\t\t\tstruct ath12k_fw_pdev *fw_pdev = &ab->fw_pdev[i];\n\n\t\t\tif (fw_pdev->pdev_id == le32_to_cpu(caps->pdev_id) &&\n\t\t\t    fw_pdev->phy_id == le32_to_cpu(caps->phy_id)) {\n\t\t\t\tbands = fw_pdev->supported_bands;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (i == ab->fw_pdev_count)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tbands = pdev->cap.supported_bands;\n\t}\n\n\tif (bands & WMI_HOST_WLAN_2G_CAP) {\n\t\tath12k_wmi_eht_caps_parse(pdev, NL80211_BAND_2GHZ,\n\t\t\t\t\t  caps->eht_cap_mac_info_2ghz,\n\t\t\t\t\t  caps->eht_cap_phy_info_2ghz,\n\t\t\t\t\t  caps->eht_supp_mcs_ext_2ghz,\n\t\t\t\t\t  &caps->eht_ppet_2ghz,\n\t\t\t\t\t  caps->eht_cap_info_internal);\n\t}\n\n\tif (bands & WMI_HOST_WLAN_5G_CAP) {\n\t\tath12k_wmi_eht_caps_parse(pdev, NL80211_BAND_5GHZ,\n\t\t\t\t\t  caps->eht_cap_mac_info_5ghz,\n\t\t\t\t\t  caps->eht_cap_phy_info_5ghz,\n\t\t\t\t\t  caps->eht_supp_mcs_ext_5ghz,\n\t\t\t\t\t  &caps->eht_ppet_5ghz,\n\t\t\t\t\t  caps->eht_cap_info_internal);\n\n\t\tath12k_wmi_eht_caps_parse(pdev, NL80211_BAND_6GHZ,\n\t\t\t\t\t  caps->eht_cap_mac_info_5ghz,\n\t\t\t\t\t  caps->eht_cap_phy_info_5ghz,\n\t\t\t\t\t  caps->eht_supp_mcs_ext_5ghz,\n\t\t\t\t\t  &caps->eht_ppet_5ghz,\n\t\t\t\t\t  caps->eht_cap_info_internal);\n\t}\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_tlv_mac_phy_caps_ext(struct ath12k_base *ab, u16 tag,\n\t\t\t\t\t   u16 len, const void *ptr,\n\t\t\t\t\t   void *data)\n{\n\tconst struct ath12k_wmi_caps_ext_params *caps = ptr;\n\tint i = 0, ret;\n\n\tif (tag != WMI_TAG_MAC_PHY_CAPABILITIES_EXT)\n\t\treturn -EPROTO;\n\n\tif (ab->hw_params->single_pdev_only) {\n\t\tif (ab->wmi_ab.preferred_hw_mode != le32_to_cpu(caps->hw_mode_id))\n\t\t\treturn 0;\n\t} else {\n\t\tfor (i = 0; i < ab->num_radios; i++) {\n\t\t\tif (ab->pdevs[i].pdev_id == le32_to_cpu(caps->pdev_id))\n\t\t\t\tbreak;\n\t\t}\n\n\t\tif (i == ab->num_radios)\n\t\t\treturn -EINVAL;\n\t}\n\n\tret = ath12k_wmi_tlv_mac_phy_caps_ext_parse(ab, caps, &ab->pdevs[i]);\n\tif (ret) {\n\t\tath12k_warn(ab,\n\t\t\t    \"failed to parse extended MAC PHY capabilities for pdev %d: %d\\n\",\n\t\t\t    ret, ab->pdevs[i].pdev_id);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath12k_wmi_svc_rdy_ext2_parse(struct ath12k_base *ab,\n\t\t\t\t\t u16 tag, u16 len,\n\t\t\t\t\t const void *ptr, void *data)\n{\n\tstruct ath12k_wmi_pdev *wmi_handle = &ab->wmi_ab.wmi[0];\n\tstruct ath12k_wmi_svc_rdy_ext2_parse *parse = data;\n\tint ret;\n\n\tswitch (tag) {\n\tcase WMI_TAG_SERVICE_READY_EXT2_EVENT:\n\t\tret = ath12k_pull_svc_ready_ext2(wmi_handle, ptr,\n\t\t\t\t\t\t &parse->arg);\n\t\tif (ret) {\n\t\t\tath12k_warn(ab,\n\t\t\t\t    \"failed to extract wmi service ready ext2 parameters: %d\\n\",\n\t\t\t\t    ret);\n\t\t\treturn ret;\n\t\t}\n\t\tbreak;\n\n\tcase WMI_TAG_ARRAY_STRUCT:\n\t\tif (!parse->dma_ring_cap_done) {\n\t\t\tret = ath12k_wmi_dma_ring_caps(ab, len, ptr,\n\t\t\t\t\t\t       &parse->dma_caps_parse);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tparse->dma_ring_cap_done = true;\n\t\t} else if (!parse->spectral_bin_scaling_done) {\n\t\t\t \n\t\t\tparse->spectral_bin_scaling_done = true;\n\t\t} else if (!parse->mac_phy_caps_ext_done) {\n\t\t\tret = ath12k_wmi_tlv_iter(ab, ptr, len,\n\t\t\t\t\t\t  ath12k_wmi_tlv_mac_phy_caps_ext,\n\t\t\t\t\t\t  parse);\n\t\t\tif (ret) {\n\t\t\t\tath12k_warn(ab, \"failed to parse extended MAC PHY capabilities WMI TLV: %d\\n\",\n\t\t\t\t\t    ret);\n\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tparse->mac_phy_caps_ext_done = true;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath12k_service_ready_ext2_event(struct ath12k_base *ab,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n\tstruct ath12k_wmi_svc_rdy_ext2_parse svc_rdy_ext2 = { };\n\tint ret;\n\n\tret = ath12k_wmi_tlv_iter(ab, skb->data, skb->len,\n\t\t\t\t  ath12k_wmi_svc_rdy_ext2_parse,\n\t\t\t\t  &svc_rdy_ext2);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to parse ext2 event tlv %d\\n\", ret);\n\t\tgoto err;\n\t}\n\n\tcomplete(&ab->wmi_ab.service_ready);\n\n\treturn 0;\n\nerr:\n\tath12k_wmi_free_dbring_caps(ab);\n\treturn ret;\n}\n\nstatic int ath12k_pull_vdev_start_resp_tlv(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t\t\t   struct wmi_vdev_start_resp_event *vdev_rsp)\n{\n\tconst void **tb;\n\tconst struct wmi_vdev_start_resp_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_VDEV_START_RESPONSE_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch vdev start resp ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\t*vdev_rsp = *ev;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic struct ath12k_reg_rule\n*create_ext_reg_rules_from_wmi(u32 num_reg_rules,\n\t\t\t       struct ath12k_wmi_reg_rule_ext_params *wmi_reg_rule)\n{\n\tstruct ath12k_reg_rule *reg_rule_ptr;\n\tu32 count;\n\n\treg_rule_ptr = kzalloc((num_reg_rules * sizeof(*reg_rule_ptr)),\n\t\t\t       GFP_ATOMIC);\n\n\tif (!reg_rule_ptr)\n\t\treturn NULL;\n\n\tfor (count = 0; count < num_reg_rules; count++) {\n\t\treg_rule_ptr[count].start_freq =\n\t\t\tle32_get_bits(wmi_reg_rule[count].freq_info,\n\t\t\t\t      REG_RULE_START_FREQ);\n\t\treg_rule_ptr[count].end_freq =\n\t\t\tle32_get_bits(wmi_reg_rule[count].freq_info,\n\t\t\t\t      REG_RULE_END_FREQ);\n\t\treg_rule_ptr[count].max_bw =\n\t\t\tle32_get_bits(wmi_reg_rule[count].bw_pwr_info,\n\t\t\t\t      REG_RULE_MAX_BW);\n\t\treg_rule_ptr[count].reg_power =\n\t\t\tle32_get_bits(wmi_reg_rule[count].bw_pwr_info,\n\t\t\t\t      REG_RULE_REG_PWR);\n\t\treg_rule_ptr[count].ant_gain =\n\t\t\tle32_get_bits(wmi_reg_rule[count].bw_pwr_info,\n\t\t\t\t      REG_RULE_ANT_GAIN);\n\t\treg_rule_ptr[count].flags =\n\t\t\tle32_get_bits(wmi_reg_rule[count].flag_info,\n\t\t\t\t      REG_RULE_FLAGS);\n\t\treg_rule_ptr[count].psd_flag =\n\t\t\tle32_get_bits(wmi_reg_rule[count].psd_power_info,\n\t\t\t\t      REG_RULE_PSD_INFO);\n\t\treg_rule_ptr[count].psd_eirp =\n\t\t\tle32_get_bits(wmi_reg_rule[count].psd_power_info,\n\t\t\t\t      REG_RULE_PSD_EIRP);\n\t}\n\n\treturn reg_rule_ptr;\n}\n\nstatic int ath12k_pull_reg_chan_list_ext_update_ev(struct ath12k_base *ab,\n\t\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t\t   struct ath12k_reg_info *reg_info)\n{\n\tconst void **tb;\n\tconst struct wmi_reg_chan_list_cc_ext_event *ev;\n\tstruct ath12k_wmi_reg_rule_ext_params *ext_wmi_reg_rule;\n\tu32 num_2g_reg_rules, num_5g_reg_rules;\n\tu32 num_6g_reg_rules_ap[WMI_REG_CURRENT_MAX_AP_TYPE];\n\tu32 num_6g_reg_rules_cl[WMI_REG_CURRENT_MAX_AP_TYPE][WMI_REG_MAX_CLIENT_TYPE];\n\tu32 total_reg_rules = 0;\n\tint ret, i, j;\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"processing regulatory ext channel list\\n\");\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_REG_CHAN_LIST_CC_EXT_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch reg chan list ext update ev\\n\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\treg_info->num_2g_reg_rules = le32_to_cpu(ev->num_2g_reg_rules);\n\treg_info->num_5g_reg_rules = le32_to_cpu(ev->num_5g_reg_rules);\n\treg_info->num_6g_reg_rules_ap[WMI_REG_INDOOR_AP] =\n\t\tle32_to_cpu(ev->num_6g_reg_rules_ap_lpi);\n\treg_info->num_6g_reg_rules_ap[WMI_REG_STD_POWER_AP] =\n\t\tle32_to_cpu(ev->num_6g_reg_rules_ap_sp);\n\treg_info->num_6g_reg_rules_ap[WMI_REG_VLP_AP] =\n\t\tle32_to_cpu(ev->num_6g_reg_rules_ap_vlp);\n\n\tfor (i = 0; i < WMI_REG_MAX_CLIENT_TYPE; i++) {\n\t\treg_info->num_6g_reg_rules_cl[WMI_REG_INDOOR_AP][i] =\n\t\t\tle32_to_cpu(ev->num_6g_reg_rules_cl_lpi[i]);\n\t\treg_info->num_6g_reg_rules_cl[WMI_REG_STD_POWER_AP][i] =\n\t\t\tle32_to_cpu(ev->num_6g_reg_rules_cl_sp[i]);\n\t\treg_info->num_6g_reg_rules_cl[WMI_REG_VLP_AP][i] =\n\t\t\tle32_to_cpu(ev->num_6g_reg_rules_cl_vlp[i]);\n\t}\n\n\tnum_2g_reg_rules = reg_info->num_2g_reg_rules;\n\ttotal_reg_rules += num_2g_reg_rules;\n\tnum_5g_reg_rules = reg_info->num_5g_reg_rules;\n\ttotal_reg_rules += num_5g_reg_rules;\n\n\tif (num_2g_reg_rules > MAX_REG_RULES || num_5g_reg_rules > MAX_REG_RULES) {\n\t\tath12k_warn(ab, \"Num reg rules for 2G/5G exceeds max limit (num_2g_reg_rules: %d num_5g_reg_rules: %d max_rules: %d)\\n\",\n\t\t\t    num_2g_reg_rules, num_5g_reg_rules, MAX_REG_RULES);\n\t\tkfree(tb);\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < WMI_REG_CURRENT_MAX_AP_TYPE; i++) {\n\t\tnum_6g_reg_rules_ap[i] = reg_info->num_6g_reg_rules_ap[i];\n\n\t\tif (num_6g_reg_rules_ap[i] > MAX_6G_REG_RULES) {\n\t\t\tath12k_warn(ab, \"Num 6G reg rules for AP mode(%d) exceeds max limit (num_6g_reg_rules_ap: %d, max_rules: %d)\\n\",\n\t\t\t\t    i, num_6g_reg_rules_ap[i], MAX_6G_REG_RULES);\n\t\t\tkfree(tb);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\ttotal_reg_rules += num_6g_reg_rules_ap[i];\n\t}\n\n\tfor (i = 0; i < WMI_REG_MAX_CLIENT_TYPE; i++) {\n\t\tnum_6g_reg_rules_cl[WMI_REG_INDOOR_AP][i] =\n\t\t\t\treg_info->num_6g_reg_rules_cl[WMI_REG_INDOOR_AP][i];\n\t\ttotal_reg_rules += num_6g_reg_rules_cl[WMI_REG_INDOOR_AP][i];\n\n\t\tnum_6g_reg_rules_cl[WMI_REG_STD_POWER_AP][i] =\n\t\t\t\treg_info->num_6g_reg_rules_cl[WMI_REG_STD_POWER_AP][i];\n\t\ttotal_reg_rules += num_6g_reg_rules_cl[WMI_REG_STD_POWER_AP][i];\n\n\t\tnum_6g_reg_rules_cl[WMI_REG_VLP_AP][i] =\n\t\t\t\treg_info->num_6g_reg_rules_cl[WMI_REG_VLP_AP][i];\n\t\ttotal_reg_rules += num_6g_reg_rules_cl[WMI_REG_VLP_AP][i];\n\n\t\tif (num_6g_reg_rules_cl[WMI_REG_INDOOR_AP][i] > MAX_6G_REG_RULES ||\n\t\t    num_6g_reg_rules_cl[WMI_REG_STD_POWER_AP][i] > MAX_6G_REG_RULES ||\n\t\t    num_6g_reg_rules_cl[WMI_REG_VLP_AP][i] >  MAX_6G_REG_RULES) {\n\t\t\tath12k_warn(ab, \"Num 6g client reg rules exceeds max limit, for client(type: %d)\\n\",\n\t\t\t\t    i);\n\t\t\tkfree(tb);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!total_reg_rules) {\n\t\tath12k_warn(ab, \"No reg rules available\\n\");\n\t\tkfree(tb);\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(reg_info->alpha2, &ev->alpha2, REG_ALPHA2_LEN);\n\n\t \n\tif (memcmp(reg_info->alpha2, \"US\", 2) == 0) {\n\t\treg_info->num_5g_reg_rules = REG_US_5G_NUM_REG_RULES;\n\t\tnum_5g_reg_rules = reg_info->num_5g_reg_rules;\n\t}\n\n\treg_info->dfs_region = le32_to_cpu(ev->dfs_region);\n\treg_info->phybitmap = le32_to_cpu(ev->phybitmap);\n\treg_info->num_phy = le32_to_cpu(ev->num_phy);\n\treg_info->phy_id = le32_to_cpu(ev->phy_id);\n\treg_info->ctry_code = le32_to_cpu(ev->country_id);\n\treg_info->reg_dmn_pair = le32_to_cpu(ev->domain_code);\n\n\tswitch (le32_to_cpu(ev->status_code)) {\n\tcase WMI_REG_SET_CC_STATUS_PASS:\n\t\treg_info->status_code = REG_SET_CC_STATUS_PASS;\n\t\tbreak;\n\tcase WMI_REG_CURRENT_ALPHA2_NOT_FOUND:\n\t\treg_info->status_code = REG_CURRENT_ALPHA2_NOT_FOUND;\n\t\tbreak;\n\tcase WMI_REG_INIT_ALPHA2_NOT_FOUND:\n\t\treg_info->status_code = REG_INIT_ALPHA2_NOT_FOUND;\n\t\tbreak;\n\tcase WMI_REG_SET_CC_CHANGE_NOT_ALLOWED:\n\t\treg_info->status_code = REG_SET_CC_CHANGE_NOT_ALLOWED;\n\t\tbreak;\n\tcase WMI_REG_SET_CC_STATUS_NO_MEMORY:\n\t\treg_info->status_code = REG_SET_CC_STATUS_NO_MEMORY;\n\t\tbreak;\n\tcase WMI_REG_SET_CC_STATUS_FAIL:\n\t\treg_info->status_code = REG_SET_CC_STATUS_FAIL;\n\t\tbreak;\n\t}\n\n\treg_info->is_ext_reg_event = true;\n\n\treg_info->min_bw_2g = le32_to_cpu(ev->min_bw_2g);\n\treg_info->max_bw_2g = le32_to_cpu(ev->max_bw_2g);\n\treg_info->min_bw_5g = le32_to_cpu(ev->min_bw_5g);\n\treg_info->max_bw_5g = le32_to_cpu(ev->max_bw_5g);\n\treg_info->min_bw_6g_ap[WMI_REG_INDOOR_AP] = le32_to_cpu(ev->min_bw_6g_ap_lpi);\n\treg_info->max_bw_6g_ap[WMI_REG_INDOOR_AP] = le32_to_cpu(ev->max_bw_6g_ap_lpi);\n\treg_info->min_bw_6g_ap[WMI_REG_STD_POWER_AP] = le32_to_cpu(ev->min_bw_6g_ap_sp);\n\treg_info->max_bw_6g_ap[WMI_REG_STD_POWER_AP] = le32_to_cpu(ev->max_bw_6g_ap_sp);\n\treg_info->min_bw_6g_ap[WMI_REG_VLP_AP] = le32_to_cpu(ev->min_bw_6g_ap_vlp);\n\treg_info->max_bw_6g_ap[WMI_REG_VLP_AP] = le32_to_cpu(ev->max_bw_6g_ap_vlp);\n\n\tfor (i = 0; i < WMI_REG_MAX_CLIENT_TYPE; i++) {\n\t\treg_info->min_bw_6g_client[WMI_REG_INDOOR_AP][i] =\n\t\t\tle32_to_cpu(ev->min_bw_6g_client_lpi[i]);\n\t\treg_info->max_bw_6g_client[WMI_REG_INDOOR_AP][i] =\n\t\t\tle32_to_cpu(ev->max_bw_6g_client_lpi[i]);\n\t\treg_info->min_bw_6g_client[WMI_REG_STD_POWER_AP][i] =\n\t\t\tle32_to_cpu(ev->min_bw_6g_client_sp[i]);\n\t\treg_info->max_bw_6g_client[WMI_REG_STD_POWER_AP][i] =\n\t\t\tle32_to_cpu(ev->max_bw_6g_client_sp[i]);\n\t\treg_info->min_bw_6g_client[WMI_REG_VLP_AP][i] =\n\t\t\tle32_to_cpu(ev->min_bw_6g_client_vlp[i]);\n\t\treg_info->max_bw_6g_client[WMI_REG_VLP_AP][i] =\n\t\t\tle32_to_cpu(ev->max_bw_6g_client_vlp[i]);\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"%s:cc_ext %s dsf %d BW: min_2g %d max_2g %d min_5g %d max_5g %d\",\n\t\t   __func__, reg_info->alpha2, reg_info->dfs_region,\n\t\t   reg_info->min_bw_2g, reg_info->max_bw_2g,\n\t\t   reg_info->min_bw_5g, reg_info->max_bw_5g);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"num_2g_reg_rules %d num_5g_reg_rules %d\",\n\t\t   num_2g_reg_rules, num_5g_reg_rules);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"num_6g_reg_rules_ap_lpi: %d num_6g_reg_rules_ap_sp: %d num_6g_reg_rules_ap_vlp: %d\",\n\t\t   num_6g_reg_rules_ap[WMI_REG_INDOOR_AP],\n\t\t   num_6g_reg_rules_ap[WMI_REG_STD_POWER_AP],\n\t\t   num_6g_reg_rules_ap[WMI_REG_VLP_AP]);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"6g Regular client: num_6g_reg_rules_lpi: %d num_6g_reg_rules_sp: %d num_6g_reg_rules_vlp: %d\",\n\t\t   num_6g_reg_rules_cl[WMI_REG_INDOOR_AP][WMI_REG_DEFAULT_CLIENT],\n\t\t   num_6g_reg_rules_cl[WMI_REG_STD_POWER_AP][WMI_REG_DEFAULT_CLIENT],\n\t\t   num_6g_reg_rules_cl[WMI_REG_VLP_AP][WMI_REG_DEFAULT_CLIENT]);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"6g Subordinate client: num_6g_reg_rules_lpi: %d num_6g_reg_rules_sp: %d num_6g_reg_rules_vlp: %d\",\n\t\t   num_6g_reg_rules_cl[WMI_REG_INDOOR_AP][WMI_REG_SUBORDINATE_CLIENT],\n\t\t   num_6g_reg_rules_cl[WMI_REG_STD_POWER_AP][WMI_REG_SUBORDINATE_CLIENT],\n\t\t   num_6g_reg_rules_cl[WMI_REG_VLP_AP][WMI_REG_SUBORDINATE_CLIENT]);\n\n\text_wmi_reg_rule =\n\t\t(struct ath12k_wmi_reg_rule_ext_params *)((u8 *)ev\n\t\t\t+ sizeof(*ev)\n\t\t\t+ sizeof(struct wmi_tlv));\n\n\tif (num_2g_reg_rules) {\n\t\treg_info->reg_rules_2g_ptr =\n\t\t\tcreate_ext_reg_rules_from_wmi(num_2g_reg_rules,\n\t\t\t\t\t\t      ext_wmi_reg_rule);\n\n\t\tif (!reg_info->reg_rules_2g_ptr) {\n\t\t\tkfree(tb);\n\t\t\tath12k_warn(ab, \"Unable to Allocate memory for 2g rules\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tif (num_5g_reg_rules) {\n\t\text_wmi_reg_rule += num_2g_reg_rules;\n\t\treg_info->reg_rules_5g_ptr =\n\t\t\tcreate_ext_reg_rules_from_wmi(num_5g_reg_rules,\n\t\t\t\t\t\t      ext_wmi_reg_rule);\n\n\t\tif (!reg_info->reg_rules_5g_ptr) {\n\t\t\tkfree(tb);\n\t\t\tath12k_warn(ab, \"Unable to Allocate memory for 5g rules\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\text_wmi_reg_rule += num_5g_reg_rules;\n\n\tfor (i = 0; i < WMI_REG_CURRENT_MAX_AP_TYPE; i++) {\n\t\treg_info->reg_rules_6g_ap_ptr[i] =\n\t\t\tcreate_ext_reg_rules_from_wmi(num_6g_reg_rules_ap[i],\n\t\t\t\t\t\t      ext_wmi_reg_rule);\n\n\t\tif (!reg_info->reg_rules_6g_ap_ptr[i]) {\n\t\t\tkfree(tb);\n\t\t\tath12k_warn(ab, \"Unable to Allocate memory for 6g ap rules\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\text_wmi_reg_rule += num_6g_reg_rules_ap[i];\n\t}\n\n\tfor (j = 0; j < WMI_REG_CURRENT_MAX_AP_TYPE; j++) {\n\t\tfor (i = 0; i < WMI_REG_MAX_CLIENT_TYPE; i++) {\n\t\t\treg_info->reg_rules_6g_client_ptr[j][i] =\n\t\t\t\tcreate_ext_reg_rules_from_wmi(num_6g_reg_rules_cl[j][i],\n\t\t\t\t\t\t\t      ext_wmi_reg_rule);\n\n\t\t\tif (!reg_info->reg_rules_6g_client_ptr[j][i]) {\n\t\t\t\tkfree(tb);\n\t\t\t\tath12k_warn(ab, \"Unable to Allocate memory for 6g client rules\\n\");\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\text_wmi_reg_rule += num_6g_reg_rules_cl[j][i];\n\t\t}\n\t}\n\n\treg_info->client_type = le32_to_cpu(ev->client_type);\n\treg_info->rnr_tpe_usable = ev->rnr_tpe_usable;\n\treg_info->unspecified_ap_usable = ev->unspecified_ap_usable;\n\treg_info->domain_code_6g_ap[WMI_REG_INDOOR_AP] =\n\t\tle32_to_cpu(ev->domain_code_6g_ap_lpi);\n\treg_info->domain_code_6g_ap[WMI_REG_STD_POWER_AP] =\n\t\tle32_to_cpu(ev->domain_code_6g_ap_sp);\n\treg_info->domain_code_6g_ap[WMI_REG_VLP_AP] =\n\t\tle32_to_cpu(ev->domain_code_6g_ap_vlp);\n\n\tfor (i = 0; i < WMI_REG_MAX_CLIENT_TYPE; i++) {\n\t\treg_info->domain_code_6g_client[WMI_REG_INDOOR_AP][i] =\n\t\t\tle32_to_cpu(ev->domain_code_6g_client_lpi[i]);\n\t\treg_info->domain_code_6g_client[WMI_REG_STD_POWER_AP][i] =\n\t\t\tle32_to_cpu(ev->domain_code_6g_client_sp[i]);\n\t\treg_info->domain_code_6g_client[WMI_REG_VLP_AP][i] =\n\t\t\tle32_to_cpu(ev->domain_code_6g_client_vlp[i]);\n\t}\n\n\treg_info->domain_code_6g_super_id = le32_to_cpu(ev->domain_code_6g_super_id);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"6g client_type: %d domain_code_6g_super_id: %d\",\n\t\t   reg_info->client_type, reg_info->domain_code_6g_super_id);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"processed regulatory ext channel list\\n\");\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_pull_peer_del_resp_ev(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t\t\tstruct wmi_peer_delete_resp_event *peer_del_resp)\n{\n\tconst void **tb;\n\tconst struct wmi_peer_delete_resp_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_PEER_DELETE_RESP_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch peer delete resp ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\tmemset(peer_del_resp, 0, sizeof(*peer_del_resp));\n\n\tpeer_del_resp->vdev_id = ev->vdev_id;\n\tether_addr_copy(peer_del_resp->peer_macaddr.addr,\n\t\t\tev->peer_macaddr.addr);\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_pull_vdev_del_resp_ev(struct ath12k_base *ab,\n\t\t\t\t\tstruct sk_buff *skb,\n\t\t\t\t\tu32 *vdev_id)\n{\n\tconst void **tb;\n\tconst struct wmi_vdev_delete_resp_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_VDEV_DELETE_RESP_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch vdev delete resp ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\t*vdev_id = le32_to_cpu(ev->vdev_id);\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_pull_bcn_tx_status_ev(struct ath12k_base *ab, void *evt_buf,\n\t\t\t\t\tu32 len, u32 *vdev_id,\n\t\t\t\t\tu32 *tx_status)\n{\n\tconst void **tb;\n\tconst struct wmi_bcn_tx_status_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, evt_buf, len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_OFFLOAD_BCN_TX_STATUS_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch bcn tx status ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\t*vdev_id = le32_to_cpu(ev->vdev_id);\n\t*tx_status = le32_to_cpu(ev->tx_status);\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_pull_vdev_stopped_param_tlv(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t\t\t      u32 *vdev_id)\n{\n\tconst void **tb;\n\tconst struct wmi_vdev_stopped_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_VDEV_STOPPED_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch vdev stop ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\t*vdev_id = le32_to_cpu(ev->vdev_id);\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_wmi_tlv_mgmt_rx_parse(struct ath12k_base *ab,\n\t\t\t\t\tu16 tag, u16 len,\n\t\t\t\t\tconst void *ptr, void *data)\n{\n\tstruct wmi_tlv_mgmt_rx_parse *parse = data;\n\n\tswitch (tag) {\n\tcase WMI_TAG_MGMT_RX_HDR:\n\t\tparse->fixed = ptr;\n\t\tbreak;\n\tcase WMI_TAG_ARRAY_BYTE:\n\t\tif (!parse->frame_buf_done) {\n\t\t\tparse->frame_buf = ptr;\n\t\t\tparse->frame_buf_done = true;\n\t\t}\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int ath12k_pull_mgmt_rx_params_tlv(struct ath12k_base *ab,\n\t\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t\t  struct ath12k_wmi_mgmt_rx_arg *hdr)\n{\n\tstruct wmi_tlv_mgmt_rx_parse parse = { };\n\tconst struct ath12k_wmi_mgmt_rx_params *ev;\n\tconst u8 *frame;\n\tint i, ret;\n\n\tret = ath12k_wmi_tlv_iter(ab, skb->data, skb->len,\n\t\t\t\t  ath12k_wmi_tlv_mgmt_rx_parse,\n\t\t\t\t  &parse);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to parse mgmt rx tlv %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = parse.fixed;\n\tframe = parse.frame_buf;\n\n\tif (!ev || !frame) {\n\t\tath12k_warn(ab, \"failed to fetch mgmt rx hdr\");\n\t\treturn -EPROTO;\n\t}\n\n\thdr->pdev_id = le32_to_cpu(ev->pdev_id);\n\thdr->chan_freq = le32_to_cpu(ev->chan_freq);\n\thdr->channel = le32_to_cpu(ev->channel);\n\thdr->snr = le32_to_cpu(ev->snr);\n\thdr->rate = le32_to_cpu(ev->rate);\n\thdr->phy_mode = le32_to_cpu(ev->phy_mode);\n\thdr->buf_len = le32_to_cpu(ev->buf_len);\n\thdr->status = le32_to_cpu(ev->status);\n\thdr->flags = le32_to_cpu(ev->flags);\n\thdr->rssi = a_sle32_to_cpu(ev->rssi);\n\thdr->tsf_delta = le32_to_cpu(ev->tsf_delta);\n\n\tfor (i = 0; i < ATH_MAX_ANTENNA; i++)\n\t\thdr->rssi_ctl[i] = le32_to_cpu(ev->rssi_ctl[i]);\n\n\tif (skb->len < (frame - skb->data) + hdr->buf_len) {\n\t\tath12k_warn(ab, \"invalid length in mgmt rx hdr ev\");\n\t\treturn -EPROTO;\n\t}\n\n\t \n\tskb_trim(skb, 0);\n\tskb_put(skb, frame - skb->data);\n\tskb_pull(skb, frame - skb->data);\n\tskb_put(skb, hdr->buf_len);\n\n\treturn 0;\n}\n\nstatic int wmi_process_mgmt_tx_comp(struct ath12k *ar, u32 desc_id,\n\t\t\t\t    u32 status)\n{\n\tstruct sk_buff *msdu;\n\tstruct ieee80211_tx_info *info;\n\tstruct ath12k_skb_cb *skb_cb;\n\tint num_mgmt;\n\n\tspin_lock_bh(&ar->txmgmt_idr_lock);\n\tmsdu = idr_find(&ar->txmgmt_idr, desc_id);\n\n\tif (!msdu) {\n\t\tath12k_warn(ar->ab, \"received mgmt tx compl for invalid msdu_id: %d\\n\",\n\t\t\t    desc_id);\n\t\tspin_unlock_bh(&ar->txmgmt_idr_lock);\n\t\treturn -ENOENT;\n\t}\n\n\tidr_remove(&ar->txmgmt_idr, desc_id);\n\tspin_unlock_bh(&ar->txmgmt_idr_lock);\n\n\tskb_cb = ATH12K_SKB_CB(msdu);\n\tdma_unmap_single(ar->ab->dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);\n\n\tinfo = IEEE80211_SKB_CB(msdu);\n\tif ((!(info->flags & IEEE80211_TX_CTL_NO_ACK)) && !status)\n\t\tinfo->flags |= IEEE80211_TX_STAT_ACK;\n\n\tieee80211_tx_status_irqsafe(ar->hw, msdu);\n\n\tnum_mgmt = atomic_dec_if_positive(&ar->num_pending_mgmt_tx);\n\n\t \n\tif (num_mgmt < 0)\n\t\tWARN_ON_ONCE(1);\n\n\tif (!num_mgmt)\n\t\twake_up(&ar->txmgmt_empty_waitq);\n\n\treturn 0;\n}\n\nstatic int ath12k_pull_mgmt_tx_compl_param_tlv(struct ath12k_base *ab,\n\t\t\t\t\t       struct sk_buff *skb,\n\t\t\t\t\t       struct wmi_mgmt_tx_compl_event *param)\n{\n\tconst void **tb;\n\tconst struct wmi_mgmt_tx_compl_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_MGMT_TX_COMPL_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch mgmt tx compl ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\tparam->pdev_id = ev->pdev_id;\n\tparam->desc_id = ev->desc_id;\n\tparam->status = ev->status;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic void ath12k_wmi_event_scan_started(struct ath12k *ar)\n{\n\tlockdep_assert_held(&ar->data_lock);\n\n\tswitch (ar->scan.state) {\n\tcase ATH12K_SCAN_IDLE:\n\tcase ATH12K_SCAN_RUNNING:\n\tcase ATH12K_SCAN_ABORTING:\n\t\tath12k_warn(ar->ab, \"received scan started event in an invalid scan state: %s (%d)\\n\",\n\t\t\t    ath12k_scan_state_str(ar->scan.state),\n\t\t\t    ar->scan.state);\n\t\tbreak;\n\tcase ATH12K_SCAN_STARTING:\n\t\tar->scan.state = ATH12K_SCAN_RUNNING;\n\t\tcomplete(&ar->scan.started);\n\t\tbreak;\n\t}\n}\n\nstatic void ath12k_wmi_event_scan_start_failed(struct ath12k *ar)\n{\n\tlockdep_assert_held(&ar->data_lock);\n\n\tswitch (ar->scan.state) {\n\tcase ATH12K_SCAN_IDLE:\n\tcase ATH12K_SCAN_RUNNING:\n\tcase ATH12K_SCAN_ABORTING:\n\t\tath12k_warn(ar->ab, \"received scan start failed event in an invalid scan state: %s (%d)\\n\",\n\t\t\t    ath12k_scan_state_str(ar->scan.state),\n\t\t\t    ar->scan.state);\n\t\tbreak;\n\tcase ATH12K_SCAN_STARTING:\n\t\tcomplete(&ar->scan.started);\n\t\t__ath12k_mac_scan_finish(ar);\n\t\tbreak;\n\t}\n}\n\nstatic void ath12k_wmi_event_scan_completed(struct ath12k *ar)\n{\n\tlockdep_assert_held(&ar->data_lock);\n\n\tswitch (ar->scan.state) {\n\tcase ATH12K_SCAN_IDLE:\n\tcase ATH12K_SCAN_STARTING:\n\t\t \n\t\tath12k_warn(ar->ab, \"received scan completed event in an invalid scan state: %s (%d)\\n\",\n\t\t\t    ath12k_scan_state_str(ar->scan.state),\n\t\t\t    ar->scan.state);\n\t\tbreak;\n\tcase ATH12K_SCAN_RUNNING:\n\tcase ATH12K_SCAN_ABORTING:\n\t\t__ath12k_mac_scan_finish(ar);\n\t\tbreak;\n\t}\n}\n\nstatic void ath12k_wmi_event_scan_bss_chan(struct ath12k *ar)\n{\n\tlockdep_assert_held(&ar->data_lock);\n\n\tswitch (ar->scan.state) {\n\tcase ATH12K_SCAN_IDLE:\n\tcase ATH12K_SCAN_STARTING:\n\t\tath12k_warn(ar->ab, \"received scan bss chan event in an invalid scan state: %s (%d)\\n\",\n\t\t\t    ath12k_scan_state_str(ar->scan.state),\n\t\t\t    ar->scan.state);\n\t\tbreak;\n\tcase ATH12K_SCAN_RUNNING:\n\tcase ATH12K_SCAN_ABORTING:\n\t\tar->scan_channel = NULL;\n\t\tbreak;\n\t}\n}\n\nstatic void ath12k_wmi_event_scan_foreign_chan(struct ath12k *ar, u32 freq)\n{\n\tlockdep_assert_held(&ar->data_lock);\n\n\tswitch (ar->scan.state) {\n\tcase ATH12K_SCAN_IDLE:\n\tcase ATH12K_SCAN_STARTING:\n\t\tath12k_warn(ar->ab, \"received scan foreign chan event in an invalid scan state: %s (%d)\\n\",\n\t\t\t    ath12k_scan_state_str(ar->scan.state),\n\t\t\t    ar->scan.state);\n\t\tbreak;\n\tcase ATH12K_SCAN_RUNNING:\n\tcase ATH12K_SCAN_ABORTING:\n\t\tar->scan_channel = ieee80211_get_channel(ar->hw->wiphy, freq);\n\t\tbreak;\n\t}\n}\n\nstatic const char *\nath12k_wmi_event_scan_type_str(enum wmi_scan_event_type type,\n\t\t\t       enum wmi_scan_completion_reason reason)\n{\n\tswitch (type) {\n\tcase WMI_SCAN_EVENT_STARTED:\n\t\treturn \"started\";\n\tcase WMI_SCAN_EVENT_COMPLETED:\n\t\tswitch (reason) {\n\t\tcase WMI_SCAN_REASON_COMPLETED:\n\t\t\treturn \"completed\";\n\t\tcase WMI_SCAN_REASON_CANCELLED:\n\t\t\treturn \"completed [cancelled]\";\n\t\tcase WMI_SCAN_REASON_PREEMPTED:\n\t\t\treturn \"completed [preempted]\";\n\t\tcase WMI_SCAN_REASON_TIMEDOUT:\n\t\t\treturn \"completed [timedout]\";\n\t\tcase WMI_SCAN_REASON_INTERNAL_FAILURE:\n\t\t\treturn \"completed [internal err]\";\n\t\tcase WMI_SCAN_REASON_MAX:\n\t\t\tbreak;\n\t\t}\n\t\treturn \"completed [unknown]\";\n\tcase WMI_SCAN_EVENT_BSS_CHANNEL:\n\t\treturn \"bss channel\";\n\tcase WMI_SCAN_EVENT_FOREIGN_CHAN:\n\t\treturn \"foreign channel\";\n\tcase WMI_SCAN_EVENT_DEQUEUED:\n\t\treturn \"dequeued\";\n\tcase WMI_SCAN_EVENT_PREEMPTED:\n\t\treturn \"preempted\";\n\tcase WMI_SCAN_EVENT_START_FAILED:\n\t\treturn \"start failed\";\n\tcase WMI_SCAN_EVENT_RESTARTED:\n\t\treturn \"restarted\";\n\tcase WMI_SCAN_EVENT_FOREIGN_CHAN_EXIT:\n\t\treturn \"foreign channel exit\";\n\tdefault:\n\t\treturn \"unknown\";\n\t}\n}\n\nstatic int ath12k_pull_scan_ev(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t       struct wmi_scan_event *scan_evt_param)\n{\n\tconst void **tb;\n\tconst struct wmi_scan_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_SCAN_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch scan ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\tscan_evt_param->event_type = ev->event_type;\n\tscan_evt_param->reason = ev->reason;\n\tscan_evt_param->channel_freq = ev->channel_freq;\n\tscan_evt_param->scan_req_id = ev->scan_req_id;\n\tscan_evt_param->scan_id = ev->scan_id;\n\tscan_evt_param->vdev_id = ev->vdev_id;\n\tscan_evt_param->tsf_timestamp = ev->tsf_timestamp;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_pull_peer_sta_kickout_ev(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t\t\t   struct wmi_peer_sta_kickout_arg *arg)\n{\n\tconst void **tb;\n\tconst struct wmi_peer_sta_kickout_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_PEER_STA_KICKOUT_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch peer sta kickout ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\targ->mac_addr = ev->peer_macaddr.addr;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_pull_roam_ev(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t       struct wmi_roam_event *roam_ev)\n{\n\tconst void **tb;\n\tconst struct wmi_roam_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_ROAM_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch roam ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\troam_ev->vdev_id = ev->vdev_id;\n\troam_ev->reason = ev->reason;\n\troam_ev->rssi = ev->rssi;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int freq_to_idx(struct ath12k *ar, int freq)\n{\n\tstruct ieee80211_supported_band *sband;\n\tint band, ch, idx = 0;\n\n\tfor (band = NL80211_BAND_2GHZ; band < NUM_NL80211_BANDS; band++) {\n\t\tif (!ar->mac.sbands[band].channels)\n\t\t\tcontinue;\n\n\t\tsband = ar->hw->wiphy->bands[band];\n\t\tif (!sband)\n\t\t\tcontinue;\n\n\t\tfor (ch = 0; ch < sband->n_channels; ch++, idx++)\n\t\t\tif (sband->channels[ch].center_freq == freq)\n\t\t\t\tgoto exit;\n\t}\n\nexit:\n\treturn idx;\n}\n\nstatic int ath12k_pull_chan_info_ev(struct ath12k_base *ab, u8 *evt_buf,\n\t\t\t\t    u32 len, struct wmi_chan_info_event *ch_info_ev)\n{\n\tconst void **tb;\n\tconst struct wmi_chan_info_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, evt_buf, len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_CHAN_INFO_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch chan info ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\tch_info_ev->err_code = ev->err_code;\n\tch_info_ev->freq = ev->freq;\n\tch_info_ev->cmd_flags = ev->cmd_flags;\n\tch_info_ev->noise_floor = ev->noise_floor;\n\tch_info_ev->rx_clear_count = ev->rx_clear_count;\n\tch_info_ev->cycle_count = ev->cycle_count;\n\tch_info_ev->chan_tx_pwr_range = ev->chan_tx_pwr_range;\n\tch_info_ev->chan_tx_pwr_tp = ev->chan_tx_pwr_tp;\n\tch_info_ev->rx_frame_count = ev->rx_frame_count;\n\tch_info_ev->tx_frame_cnt = ev->tx_frame_cnt;\n\tch_info_ev->mac_clk_mhz = ev->mac_clk_mhz;\n\tch_info_ev->vdev_id = ev->vdev_id;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int\nath12k_pull_pdev_bss_chan_info_ev(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t\t  struct wmi_pdev_bss_chan_info_event *bss_ch_info_ev)\n{\n\tconst void **tb;\n\tconst struct wmi_pdev_bss_chan_info_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_PDEV_BSS_CHAN_INFO_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch pdev bss chan info ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\tbss_ch_info_ev->pdev_id = ev->pdev_id;\n\tbss_ch_info_ev->freq = ev->freq;\n\tbss_ch_info_ev->noise_floor = ev->noise_floor;\n\tbss_ch_info_ev->rx_clear_count_low = ev->rx_clear_count_low;\n\tbss_ch_info_ev->rx_clear_count_high = ev->rx_clear_count_high;\n\tbss_ch_info_ev->cycle_count_low = ev->cycle_count_low;\n\tbss_ch_info_ev->cycle_count_high = ev->cycle_count_high;\n\tbss_ch_info_ev->tx_cycle_count_low = ev->tx_cycle_count_low;\n\tbss_ch_info_ev->tx_cycle_count_high = ev->tx_cycle_count_high;\n\tbss_ch_info_ev->rx_cycle_count_low = ev->rx_cycle_count_low;\n\tbss_ch_info_ev->rx_cycle_count_high = ev->rx_cycle_count_high;\n\tbss_ch_info_ev->rx_bss_cycle_count_low = ev->rx_bss_cycle_count_low;\n\tbss_ch_info_ev->rx_bss_cycle_count_high = ev->rx_bss_cycle_count_high;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int\nath12k_pull_vdev_install_key_compl_ev(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t\t      struct wmi_vdev_install_key_complete_arg *arg)\n{\n\tconst void **tb;\n\tconst struct wmi_vdev_install_key_compl_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_VDEV_INSTALL_KEY_COMPLETE_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch vdev install key compl ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\targ->vdev_id = le32_to_cpu(ev->vdev_id);\n\targ->macaddr = ev->peer_macaddr.addr;\n\targ->key_idx = le32_to_cpu(ev->key_idx);\n\targ->key_flags = le32_to_cpu(ev->key_flags);\n\targ->status = le32_to_cpu(ev->status);\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int ath12k_pull_peer_assoc_conf_ev(struct ath12k_base *ab, struct sk_buff *skb,\n\t\t\t\t\t  struct wmi_peer_assoc_conf_arg *peer_assoc_conf)\n{\n\tconst void **tb;\n\tconst struct wmi_peer_assoc_conf_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_PEER_ASSOC_CONF_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch peer assoc conf ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\tpeer_assoc_conf->vdev_id = le32_to_cpu(ev->vdev_id);\n\tpeer_assoc_conf->macaddr = ev->peer_macaddr.addr;\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic int\nath12k_pull_pdev_temp_ev(struct ath12k_base *ab, u8 *evt_buf,\n\t\t\t u32 len, const struct wmi_pdev_temperature_event *ev)\n{\n\tconst void **tb;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, evt_buf, len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tev = tb[WMI_TAG_PDEV_TEMPERATURE_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch pdev temp ev\");\n\t\tkfree(tb);\n\t\treturn -EPROTO;\n\t}\n\n\tkfree(tb);\n\treturn 0;\n}\n\nstatic void ath12k_wmi_op_ep_tx_credits(struct ath12k_base *ab)\n{\n\t \n\twake_up(&ab->wmi_ab.tx_credits_wq);\n}\n\nstatic void ath12k_wmi_htc_tx_complete(struct ath12k_base *ab,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tdev_kfree_skb(skb);\n}\n\nstatic bool ath12k_reg_is_world_alpha(char *alpha)\n{\n\treturn alpha[0] == '0' && alpha[1] == '0';\n}\n\nstatic int ath12k_reg_chan_list_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct ath12k_reg_info *reg_info = NULL;\n\tstruct ieee80211_regdomain *regd = NULL;\n\tbool intersect = false;\n\tint ret = 0, pdev_idx, i, j;\n\tstruct ath12k *ar;\n\n\treg_info = kzalloc(sizeof(*reg_info), GFP_ATOMIC);\n\tif (!reg_info) {\n\t\tret = -ENOMEM;\n\t\tgoto fallback;\n\t}\n\n\tret = ath12k_pull_reg_chan_list_ext_update_ev(ab, skb, reg_info);\n\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to extract regulatory info from received event\\n\");\n\t\tgoto fallback;\n\t}\n\n\tif (reg_info->status_code != REG_SET_CC_STATUS_PASS) {\n\t\t \n\t\tath12k_warn(ab, \"Failed to set the requested Country regulatory setting\\n\");\n\t\tgoto mem_free;\n\t}\n\n\tpdev_idx = reg_info->phy_id;\n\n\tif (pdev_idx >= ab->num_radios) {\n\t\t \n\t\tif (ab->hw_params->single_pdev_only &&\n\t\t    pdev_idx < ab->hw_params->num_rxmda_per_pdev)\n\t\t\tgoto mem_free;\n\t\telse\n\t\t\tgoto fallback;\n\t}\n\n\t \n\tif (ab->default_regd[pdev_idx] && !ab->new_regd[pdev_idx] &&\n\t    !memcmp(ab->default_regd[pdev_idx]->alpha2,\n\t\t    reg_info->alpha2, 2))\n\t\tgoto mem_free;\n\n\t \n\tif (ab->default_regd[pdev_idx] &&\n\t    !ath12k_reg_is_world_alpha((char *)\n\t\tab->default_regd[pdev_idx]->alpha2) &&\n\t    !ath12k_reg_is_world_alpha((char *)reg_info->alpha2))\n\t\tintersect = true;\n\n\tregd = ath12k_reg_build_regd(ab, reg_info, intersect);\n\tif (!regd) {\n\t\tath12k_warn(ab, \"failed to build regd from reg_info\\n\");\n\t\tgoto fallback;\n\t}\n\n\tspin_lock(&ab->base_lock);\n\tif (test_bit(ATH12K_FLAG_REGISTERED, &ab->dev_flags)) {\n\t\t \n\t\tar = ab->pdevs[pdev_idx].ar;\n\t\tkfree(ab->new_regd[pdev_idx]);\n\t\tab->new_regd[pdev_idx] = regd;\n\t\tqueue_work(ab->workqueue, &ar->regd_update_work);\n\t} else {\n\t\t \n\t\tkfree(ab->default_regd[pdev_idx]);\n\t\t \n\t\tab->default_regd[pdev_idx] = regd;\n\t}\n\tab->dfs_region = reg_info->dfs_region;\n\tspin_unlock(&ab->base_lock);\n\n\tgoto mem_free;\n\nfallback:\n\t \n\t \n\tWARN_ON(1);\nmem_free:\n\tif (reg_info) {\n\t\tkfree(reg_info->reg_rules_2g_ptr);\n\t\tkfree(reg_info->reg_rules_5g_ptr);\n\t\tif (reg_info->is_ext_reg_event) {\n\t\t\tfor (i = 0; i < WMI_REG_CURRENT_MAX_AP_TYPE; i++)\n\t\t\t\tkfree(reg_info->reg_rules_6g_ap_ptr[i]);\n\n\t\t\tfor (j = 0; j < WMI_REG_CURRENT_MAX_AP_TYPE; j++)\n\t\t\t\tfor (i = 0; i < WMI_REG_MAX_CLIENT_TYPE; i++)\n\t\t\t\t\tkfree(reg_info->reg_rules_6g_client_ptr[j][i]);\n\t\t}\n\t\tkfree(reg_info);\n\t}\n\treturn ret;\n}\n\nstatic int ath12k_wmi_rdy_parse(struct ath12k_base *ab, u16 tag, u16 len,\n\t\t\t\tconst void *ptr, void *data)\n{\n\tstruct ath12k_wmi_rdy_parse *rdy_parse = data;\n\tstruct wmi_ready_event fixed_param;\n\tstruct ath12k_wmi_mac_addr_params *addr_list;\n\tstruct ath12k_pdev *pdev;\n\tu32 num_mac_addr;\n\tint i;\n\n\tswitch (tag) {\n\tcase WMI_TAG_READY_EVENT:\n\t\tmemset(&fixed_param, 0, sizeof(fixed_param));\n\t\tmemcpy(&fixed_param, (struct wmi_ready_event *)ptr,\n\t\t       min_t(u16, sizeof(fixed_param), len));\n\t\tab->wlan_init_status = le32_to_cpu(fixed_param.ready_event_min.status);\n\t\trdy_parse->num_extra_mac_addr =\n\t\t\tle32_to_cpu(fixed_param.ready_event_min.num_extra_mac_addr);\n\n\t\tether_addr_copy(ab->mac_addr,\n\t\t\t\tfixed_param.ready_event_min.mac_addr.addr);\n\t\tab->pktlog_defs_checksum = le32_to_cpu(fixed_param.pktlog_defs_checksum);\n\t\tab->wmi_ready = true;\n\t\tbreak;\n\tcase WMI_TAG_ARRAY_FIXED_STRUCT:\n\t\taddr_list = (struct ath12k_wmi_mac_addr_params *)ptr;\n\t\tnum_mac_addr = rdy_parse->num_extra_mac_addr;\n\n\t\tif (!(ab->num_radios > 1 && num_mac_addr >= ab->num_radios))\n\t\t\tbreak;\n\n\t\tfor (i = 0; i < ab->num_radios; i++) {\n\t\t\tpdev = &ab->pdevs[i];\n\t\t\tether_addr_copy(pdev->mac_addr, addr_list[i].addr);\n\t\t}\n\t\tab->pdevs_macaddr_valid = true;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath12k_ready_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct ath12k_wmi_rdy_parse rdy_parse = { };\n\tint ret;\n\n\tret = ath12k_wmi_tlv_iter(ab, skb->data, skb->len,\n\t\t\t\t  ath12k_wmi_rdy_parse, &rdy_parse);\n\tif (ret) {\n\t\tath12k_warn(ab, \"failed to parse tlv %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tcomplete(&ab->wmi_ab.unified_ready);\n\treturn 0;\n}\n\nstatic void ath12k_peer_delete_resp_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_peer_delete_resp_event peer_del_resp;\n\tstruct ath12k *ar;\n\n\tif (ath12k_pull_peer_del_resp_ev(ab, skb, &peer_del_resp) != 0) {\n\t\tath12k_warn(ab, \"failed to extract peer delete resp\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, le32_to_cpu(peer_del_resp.vdev_id));\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in peer delete resp ev %d\",\n\t\t\t    peer_del_resp.vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tcomplete(&ar->peer_delete_done);\n\trcu_read_unlock();\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"peer delete resp for vdev id %d addr %pM\\n\",\n\t\t   peer_del_resp.vdev_id, peer_del_resp.peer_macaddr.addr);\n}\n\nstatic void ath12k_vdev_delete_resp_event(struct ath12k_base *ab,\n\t\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct ath12k *ar;\n\tu32 vdev_id = 0;\n\n\tif (ath12k_pull_vdev_del_resp_ev(ab, skb, &vdev_id) != 0) {\n\t\tath12k_warn(ab, \"failed to extract vdev delete resp\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, vdev_id);\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in vdev delete resp ev %d\",\n\t\t\t    vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tcomplete(&ar->vdev_delete_done);\n\n\trcu_read_unlock();\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"vdev delete resp for vdev id %d\\n\",\n\t\t   vdev_id);\n}\n\nstatic const char *ath12k_wmi_vdev_resp_print(u32 vdev_resp_status)\n{\n\tswitch (vdev_resp_status) {\n\tcase WMI_VDEV_START_RESPONSE_INVALID_VDEVID:\n\t\treturn \"invalid vdev id\";\n\tcase WMI_VDEV_START_RESPONSE_NOT_SUPPORTED:\n\t\treturn \"not supported\";\n\tcase WMI_VDEV_START_RESPONSE_DFS_VIOLATION:\n\t\treturn \"dfs violation\";\n\tcase WMI_VDEV_START_RESPONSE_INVALID_REGDOMAIN:\n\t\treturn \"invalid regdomain\";\n\tdefault:\n\t\treturn \"unknown\";\n\t}\n}\n\nstatic void ath12k_vdev_start_resp_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_vdev_start_resp_event vdev_start_resp;\n\tstruct ath12k *ar;\n\tu32 status;\n\n\tif (ath12k_pull_vdev_start_resp_tlv(ab, skb, &vdev_start_resp) != 0) {\n\t\tath12k_warn(ab, \"failed to extract vdev start resp\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, le32_to_cpu(vdev_start_resp.vdev_id));\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in vdev start resp ev %d\",\n\t\t\t    vdev_start_resp.vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tar->last_wmi_vdev_start_status = 0;\n\n\tstatus = le32_to_cpu(vdev_start_resp.status);\n\n\tif (WARN_ON_ONCE(status)) {\n\t\tath12k_warn(ab, \"vdev start resp error status %d (%s)\\n\",\n\t\t\t    status, ath12k_wmi_vdev_resp_print(status));\n\t\tar->last_wmi_vdev_start_status = status;\n\t}\n\n\tcomplete(&ar->vdev_setup_done);\n\n\trcu_read_unlock();\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"vdev start resp for vdev id %d\",\n\t\t   vdev_start_resp.vdev_id);\n}\n\nstatic void ath12k_bcn_tx_status_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tu32 vdev_id, tx_status;\n\n\tif (ath12k_pull_bcn_tx_status_ev(ab, skb->data, skb->len,\n\t\t\t\t\t &vdev_id, &tx_status) != 0) {\n\t\tath12k_warn(ab, \"failed to extract bcn tx status\");\n\t\treturn;\n\t}\n}\n\nstatic void ath12k_vdev_stopped_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct ath12k *ar;\n\tu32 vdev_id = 0;\n\n\tif (ath12k_pull_vdev_stopped_param_tlv(ab, skb, &vdev_id) != 0) {\n\t\tath12k_warn(ab, \"failed to extract vdev stopped event\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, vdev_id);\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in vdev stopped ev %d\",\n\t\t\t    vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tcomplete(&ar->vdev_setup_done);\n\n\trcu_read_unlock();\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"vdev stopped for vdev id %d\", vdev_id);\n}\n\nstatic void ath12k_mgmt_rx_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct ath12k_wmi_mgmt_rx_arg rx_ev = {0};\n\tstruct ath12k *ar;\n\tstruct ieee80211_rx_status *status = IEEE80211_SKB_RXCB(skb);\n\tstruct ieee80211_hdr *hdr;\n\tu16 fc;\n\tstruct ieee80211_supported_band *sband;\n\n\tif (ath12k_pull_mgmt_rx_params_tlv(ab, skb, &rx_ev) != 0) {\n\t\tath12k_warn(ab, \"failed to extract mgmt rx event\");\n\t\tdev_kfree_skb(skb);\n\t\treturn;\n\t}\n\n\tmemset(status, 0, sizeof(*status));\n\n\tath12k_dbg(ab, ATH12K_DBG_MGMT, \"mgmt rx event status %08x\\n\",\n\t\t   rx_ev.status);\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_pdev_id(ab, rx_ev.pdev_id);\n\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid pdev_id %d in mgmt_rx_event\\n\",\n\t\t\t    rx_ev.pdev_id);\n\t\tdev_kfree_skb(skb);\n\t\tgoto exit;\n\t}\n\n\tif ((test_bit(ATH12K_CAC_RUNNING, &ar->dev_flags)) ||\n\t    (rx_ev.status & (WMI_RX_STATUS_ERR_DECRYPT |\n\t\t\t     WMI_RX_STATUS_ERR_KEY_CACHE_MISS |\n\t\t\t     WMI_RX_STATUS_ERR_CRC))) {\n\t\tdev_kfree_skb(skb);\n\t\tgoto exit;\n\t}\n\n\tif (rx_ev.status & WMI_RX_STATUS_ERR_MIC)\n\t\tstatus->flag |= RX_FLAG_MMIC_ERROR;\n\n\tif (rx_ev.chan_freq >= ATH12K_MIN_6G_FREQ) {\n\t\tstatus->band = NL80211_BAND_6GHZ;\n\t} else if (rx_ev.channel >= 1 && rx_ev.channel <= 14) {\n\t\tstatus->band = NL80211_BAND_2GHZ;\n\t} else if (rx_ev.channel >= 36 && rx_ev.channel <= ATH12K_MAX_5G_CHAN) {\n\t\tstatus->band = NL80211_BAND_5GHZ;\n\t} else {\n\t\t \n\t\tWARN_ON_ONCE(1);\n\t\tdev_kfree_skb(skb);\n\t\tgoto exit;\n\t}\n\n\tif (rx_ev.phy_mode == MODE_11B &&\n\t    (status->band == NL80211_BAND_5GHZ || status->band == NL80211_BAND_6GHZ))\n\t\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t\t   \"wmi mgmt rx 11b (CCK) on 5/6GHz, band = %d\\n\", status->band);\n\n\tsband = &ar->mac.sbands[status->band];\n\n\tstatus->freq = ieee80211_channel_to_frequency(rx_ev.channel,\n\t\t\t\t\t\t      status->band);\n\tstatus->signal = rx_ev.snr + ATH12K_DEFAULT_NOISE_FLOOR;\n\tstatus->rate_idx = ath12k_mac_bitrate_to_idx(sband, rx_ev.rate / 100);\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\tfc = le16_to_cpu(hdr->frame_control);\n\n\t \n\tstatus->flag |= RX_FLAG_SKIP_MONITOR;\n\n\t \n\tif (ieee80211_has_protected(hdr->frame_control)) {\n\t\tstatus->flag |= RX_FLAG_DECRYPTED;\n\n\t\tif (!ieee80211_is_robust_mgmt_frame(skb)) {\n\t\t\tstatus->flag |= RX_FLAG_IV_STRIPPED |\n\t\t\t\t\tRX_FLAG_MMIC_STRIPPED;\n\t\t\thdr->frame_control = __cpu_to_le16(fc &\n\t\t\t\t\t     ~IEEE80211_FCTL_PROTECTED);\n\t\t}\n\t}\n\n\t \n\n\tath12k_dbg(ab, ATH12K_DBG_MGMT,\n\t\t   \"event mgmt rx skb %pK len %d ftype %02x stype %02x\\n\",\n\t\t   skb, skb->len,\n\t\t   fc & IEEE80211_FCTL_FTYPE, fc & IEEE80211_FCTL_STYPE);\n\n\tath12k_dbg(ab, ATH12K_DBG_MGMT,\n\t\t   \"event mgmt rx freq %d band %d snr %d, rate_idx %d\\n\",\n\t\t   status->freq, status->band, status->signal,\n\t\t   status->rate_idx);\n\n\tieee80211_rx_ni(ar->hw, skb);\n\nexit:\n\trcu_read_unlock();\n}\n\nstatic void ath12k_mgmt_tx_compl_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_mgmt_tx_compl_event tx_compl_param = {0};\n\tstruct ath12k *ar;\n\n\tif (ath12k_pull_mgmt_tx_compl_param_tlv(ab, skb, &tx_compl_param) != 0) {\n\t\tath12k_warn(ab, \"failed to extract mgmt tx compl event\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_pdev_id(ab, le32_to_cpu(tx_compl_param.pdev_id));\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid pdev id %d in mgmt_tx_compl_event\\n\",\n\t\t\t    tx_compl_param.pdev_id);\n\t\tgoto exit;\n\t}\n\n\twmi_process_mgmt_tx_comp(ar, le32_to_cpu(tx_compl_param.desc_id),\n\t\t\t\t le32_to_cpu(tx_compl_param.status));\n\n\tath12k_dbg(ab, ATH12K_DBG_MGMT,\n\t\t   \"mgmt tx compl ev pdev_id %d, desc_id %d, status %d\",\n\t\t   tx_compl_param.pdev_id, tx_compl_param.desc_id,\n\t\t   tx_compl_param.status);\n\nexit:\n\trcu_read_unlock();\n}\n\nstatic struct ath12k *ath12k_get_ar_on_scan_abort(struct ath12k_base *ab,\n\t\t\t\t\t\t  u32 vdev_id)\n{\n\tint i;\n\tstruct ath12k_pdev *pdev;\n\tstruct ath12k *ar;\n\n\tfor (i = 0; i < ab->num_radios; i++) {\n\t\tpdev = rcu_dereference(ab->pdevs_active[i]);\n\t\tif (pdev && pdev->ar) {\n\t\t\tar = pdev->ar;\n\n\t\t\tspin_lock_bh(&ar->data_lock);\n\t\t\tif (ar->scan.state == ATH12K_SCAN_ABORTING &&\n\t\t\t    ar->scan.vdev_id == vdev_id) {\n\t\t\t\tspin_unlock_bh(&ar->data_lock);\n\t\t\t\treturn ar;\n\t\t\t}\n\t\t\tspin_unlock_bh(&ar->data_lock);\n\t\t}\n\t}\n\treturn NULL;\n}\n\nstatic void ath12k_scan_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct ath12k *ar;\n\tstruct wmi_scan_event scan_ev = {0};\n\n\tif (ath12k_pull_scan_ev(ab, skb, &scan_ev) != 0) {\n\t\tath12k_warn(ab, \"failed to extract scan event\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\n\t \n\tif (le32_to_cpu(scan_ev.event_type) == WMI_SCAN_EVENT_COMPLETED &&\n\t    le32_to_cpu(scan_ev.reason) == WMI_SCAN_REASON_CANCELLED)\n\t\tar = ath12k_get_ar_on_scan_abort(ab, le32_to_cpu(scan_ev.vdev_id));\n\telse\n\t\tar = ath12k_mac_get_ar_by_vdev_id(ab, le32_to_cpu(scan_ev.vdev_id));\n\n\tif (!ar) {\n\t\tath12k_warn(ab, \"Received scan event for unknown vdev\");\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tspin_lock_bh(&ar->data_lock);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"scan event %s type %d reason %d freq %d req_id %d scan_id %d vdev_id %d state %s (%d)\\n\",\n\t\t   ath12k_wmi_event_scan_type_str(le32_to_cpu(scan_ev.event_type),\n\t\t\t\t\t\t  le32_to_cpu(scan_ev.reason)),\n\t\t   le32_to_cpu(scan_ev.event_type),\n\t\t   le32_to_cpu(scan_ev.reason),\n\t\t   le32_to_cpu(scan_ev.channel_freq),\n\t\t   le32_to_cpu(scan_ev.scan_req_id),\n\t\t   le32_to_cpu(scan_ev.scan_id),\n\t\t   le32_to_cpu(scan_ev.vdev_id),\n\t\t   ath12k_scan_state_str(ar->scan.state), ar->scan.state);\n\n\tswitch (le32_to_cpu(scan_ev.event_type)) {\n\tcase WMI_SCAN_EVENT_STARTED:\n\t\tath12k_wmi_event_scan_started(ar);\n\t\tbreak;\n\tcase WMI_SCAN_EVENT_COMPLETED:\n\t\tath12k_wmi_event_scan_completed(ar);\n\t\tbreak;\n\tcase WMI_SCAN_EVENT_BSS_CHANNEL:\n\t\tath12k_wmi_event_scan_bss_chan(ar);\n\t\tbreak;\n\tcase WMI_SCAN_EVENT_FOREIGN_CHAN:\n\t\tath12k_wmi_event_scan_foreign_chan(ar, le32_to_cpu(scan_ev.channel_freq));\n\t\tbreak;\n\tcase WMI_SCAN_EVENT_START_FAILED:\n\t\tath12k_warn(ab, \"received scan start failure event\\n\");\n\t\tath12k_wmi_event_scan_start_failed(ar);\n\t\tbreak;\n\tcase WMI_SCAN_EVENT_DEQUEUED:\n\t\t__ath12k_mac_scan_finish(ar);\n\t\tbreak;\n\tcase WMI_SCAN_EVENT_PREEMPTED:\n\tcase WMI_SCAN_EVENT_RESTARTED:\n\tcase WMI_SCAN_EVENT_FOREIGN_CHAN_EXIT:\n\tdefault:\n\t\tbreak;\n\t}\n\n\tspin_unlock_bh(&ar->data_lock);\n\n\trcu_read_unlock();\n}\n\nstatic void ath12k_peer_sta_kickout_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_peer_sta_kickout_arg arg = {};\n\tstruct ieee80211_sta *sta;\n\tstruct ath12k_peer *peer;\n\tstruct ath12k *ar;\n\n\tif (ath12k_pull_peer_sta_kickout_ev(ab, skb, &arg) != 0) {\n\t\tath12k_warn(ab, \"failed to extract peer sta kickout event\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\n\tspin_lock_bh(&ab->base_lock);\n\n\tpeer = ath12k_peer_find_by_addr(ab, arg.mac_addr);\n\n\tif (!peer) {\n\t\tath12k_warn(ab, \"peer not found %pM\\n\",\n\t\t\t    arg.mac_addr);\n\t\tgoto exit;\n\t}\n\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, peer->vdev_id);\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in peer sta kickout ev %d\",\n\t\t\t    peer->vdev_id);\n\t\tgoto exit;\n\t}\n\n\tsta = ieee80211_find_sta_by_ifaddr(ar->hw,\n\t\t\t\t\t   arg.mac_addr, NULL);\n\tif (!sta) {\n\t\tath12k_warn(ab, \"Spurious quick kickout for STA %pM\\n\",\n\t\t\t    arg.mac_addr);\n\t\tgoto exit;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI, \"peer sta kickout event %pM\",\n\t\t   arg.mac_addr);\n\n\tieee80211_report_low_ack(sta, 10);\n\nexit:\n\tspin_unlock_bh(&ab->base_lock);\n\trcu_read_unlock();\n}\n\nstatic void ath12k_roam_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_roam_event roam_ev = {};\n\tstruct ath12k *ar;\n\n\tif (ath12k_pull_roam_ev(ab, skb, &roam_ev) != 0) {\n\t\tath12k_warn(ab, \"failed to extract roam event\");\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"wmi roam event vdev %u reason 0x%08x rssi %d\\n\",\n\t\t   roam_ev.vdev_id, roam_ev.reason, roam_ev.rssi);\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, le32_to_cpu(roam_ev.vdev_id));\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in roam ev %d\",\n\t\t\t    roam_ev.vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tif (le32_to_cpu(roam_ev.reason) >= WMI_ROAM_REASON_MAX)\n\t\tath12k_warn(ab, \"ignoring unknown roam event reason %d on vdev %i\\n\",\n\t\t\t    roam_ev.reason, roam_ev.vdev_id);\n\n\tswitch (le32_to_cpu(roam_ev.reason)) {\n\tcase WMI_ROAM_REASON_BEACON_MISS:\n\t\t \n\t\tbreak;\n\tcase WMI_ROAM_REASON_BETTER_AP:\n\tcase WMI_ROAM_REASON_LOW_RSSI:\n\tcase WMI_ROAM_REASON_SUITABLE_AP_FOUND:\n\tcase WMI_ROAM_REASON_HO_FAILED:\n\t\tath12k_warn(ab, \"ignoring not implemented roam event reason %d on vdev %i\\n\",\n\t\t\t    roam_ev.reason, roam_ev.vdev_id);\n\t\tbreak;\n\t}\n\n\trcu_read_unlock();\n}\n\nstatic void ath12k_chan_info_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_chan_info_event ch_info_ev = {0};\n\tstruct ath12k *ar;\n\tstruct survey_info *survey;\n\tint idx;\n\t \n\tu32 cc_freq_hz = ab->cc_freq_hz;\n\n\tif (ath12k_pull_chan_info_ev(ab, skb->data, skb->len, &ch_info_ev) != 0) {\n\t\tath12k_warn(ab, \"failed to extract chan info event\");\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"chan info vdev_id %d err_code %d freq %d cmd_flags %d noise_floor %d rx_clear_count %d cycle_count %d mac_clk_mhz %d\\n\",\n\t\t   ch_info_ev.vdev_id, ch_info_ev.err_code, ch_info_ev.freq,\n\t\t   ch_info_ev.cmd_flags, ch_info_ev.noise_floor,\n\t\t   ch_info_ev.rx_clear_count, ch_info_ev.cycle_count,\n\t\t   ch_info_ev.mac_clk_mhz);\n\n\tif (le32_to_cpu(ch_info_ev.cmd_flags) == WMI_CHAN_INFO_END_RESP) {\n\t\tath12k_dbg(ab, ATH12K_DBG_WMI, \"chan info report completed\\n\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, le32_to_cpu(ch_info_ev.vdev_id));\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in chan info ev %d\",\n\t\t\t    ch_info_ev.vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tspin_lock_bh(&ar->data_lock);\n\n\tswitch (ar->scan.state) {\n\tcase ATH12K_SCAN_IDLE:\n\tcase ATH12K_SCAN_STARTING:\n\t\tath12k_warn(ab, \"received chan info event without a scan request, ignoring\\n\");\n\t\tgoto exit;\n\tcase ATH12K_SCAN_RUNNING:\n\tcase ATH12K_SCAN_ABORTING:\n\t\tbreak;\n\t}\n\n\tidx = freq_to_idx(ar, le32_to_cpu(ch_info_ev.freq));\n\tif (idx >= ARRAY_SIZE(ar->survey)) {\n\t\tath12k_warn(ab, \"chan info: invalid frequency %d (idx %d out of bounds)\\n\",\n\t\t\t    ch_info_ev.freq, idx);\n\t\tgoto exit;\n\t}\n\n\t \n\tif (ch_info_ev.mac_clk_mhz)\n\t\tcc_freq_hz = (le32_to_cpu(ch_info_ev.mac_clk_mhz) * 1000);\n\n\tif (ch_info_ev.cmd_flags == WMI_CHAN_INFO_START_RESP) {\n\t\tsurvey = &ar->survey[idx];\n\t\tmemset(survey, 0, sizeof(*survey));\n\t\tsurvey->noise = le32_to_cpu(ch_info_ev.noise_floor);\n\t\tsurvey->filled = SURVEY_INFO_NOISE_DBM | SURVEY_INFO_TIME |\n\t\t\t\t SURVEY_INFO_TIME_BUSY;\n\t\tsurvey->time = div_u64(le32_to_cpu(ch_info_ev.cycle_count), cc_freq_hz);\n\t\tsurvey->time_busy = div_u64(le32_to_cpu(ch_info_ev.rx_clear_count),\n\t\t\t\t\t    cc_freq_hz);\n\t}\nexit:\n\tspin_unlock_bh(&ar->data_lock);\n\trcu_read_unlock();\n}\n\nstatic void\nath12k_pdev_bss_chan_info_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_pdev_bss_chan_info_event bss_ch_info_ev = {};\n\tstruct survey_info *survey;\n\tstruct ath12k *ar;\n\tu32 cc_freq_hz = ab->cc_freq_hz;\n\tu64 busy, total, tx, rx, rx_bss;\n\tint idx;\n\n\tif (ath12k_pull_pdev_bss_chan_info_ev(ab, skb, &bss_ch_info_ev) != 0) {\n\t\tath12k_warn(ab, \"failed to extract pdev bss chan info event\");\n\t\treturn;\n\t}\n\n\tbusy = (u64)(le32_to_cpu(bss_ch_info_ev.rx_clear_count_high)) << 32 |\n\t\tle32_to_cpu(bss_ch_info_ev.rx_clear_count_low);\n\n\ttotal = (u64)(le32_to_cpu(bss_ch_info_ev.cycle_count_high)) << 32 |\n\t\tle32_to_cpu(bss_ch_info_ev.cycle_count_low);\n\n\ttx = (u64)(le32_to_cpu(bss_ch_info_ev.tx_cycle_count_high)) << 32 |\n\t\tle32_to_cpu(bss_ch_info_ev.tx_cycle_count_low);\n\n\trx = (u64)(le32_to_cpu(bss_ch_info_ev.rx_cycle_count_high)) << 32 |\n\t\tle32_to_cpu(bss_ch_info_ev.rx_cycle_count_low);\n\n\trx_bss = (u64)(le32_to_cpu(bss_ch_info_ev.rx_bss_cycle_count_high)) << 32 |\n\t\tle32_to_cpu(bss_ch_info_ev.rx_bss_cycle_count_low);\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"pdev bss chan info:\\n pdev_id: %d freq: %d noise: %d cycle: busy %llu total %llu tx %llu rx %llu rx_bss %llu\\n\",\n\t\t   bss_ch_info_ev.pdev_id, bss_ch_info_ev.freq,\n\t\t   bss_ch_info_ev.noise_floor, busy, total,\n\t\t   tx, rx, rx_bss);\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_pdev_id(ab, le32_to_cpu(bss_ch_info_ev.pdev_id));\n\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid pdev id %d in bss_chan_info event\\n\",\n\t\t\t    bss_ch_info_ev.pdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tspin_lock_bh(&ar->data_lock);\n\tidx = freq_to_idx(ar, le32_to_cpu(bss_ch_info_ev.freq));\n\tif (idx >= ARRAY_SIZE(ar->survey)) {\n\t\tath12k_warn(ab, \"bss chan info: invalid frequency %d (idx %d out of bounds)\\n\",\n\t\t\t    bss_ch_info_ev.freq, idx);\n\t\tgoto exit;\n\t}\n\n\tsurvey = &ar->survey[idx];\n\n\tsurvey->noise     = le32_to_cpu(bss_ch_info_ev.noise_floor);\n\tsurvey->time      = div_u64(total, cc_freq_hz);\n\tsurvey->time_busy = div_u64(busy, cc_freq_hz);\n\tsurvey->time_rx   = div_u64(rx_bss, cc_freq_hz);\n\tsurvey->time_tx   = div_u64(tx, cc_freq_hz);\n\tsurvey->filled   |= (SURVEY_INFO_NOISE_DBM |\n\t\t\t     SURVEY_INFO_TIME |\n\t\t\t     SURVEY_INFO_TIME_BUSY |\n\t\t\t     SURVEY_INFO_TIME_RX |\n\t\t\t     SURVEY_INFO_TIME_TX);\nexit:\n\tspin_unlock_bh(&ar->data_lock);\n\tcomplete(&ar->bss_survey_done);\n\n\trcu_read_unlock();\n}\n\nstatic void ath12k_vdev_install_key_compl_event(struct ath12k_base *ab,\n\t\t\t\t\t\tstruct sk_buff *skb)\n{\n\tstruct wmi_vdev_install_key_complete_arg install_key_compl = {0};\n\tstruct ath12k *ar;\n\n\tif (ath12k_pull_vdev_install_key_compl_ev(ab, skb, &install_key_compl) != 0) {\n\t\tath12k_warn(ab, \"failed to extract install key compl event\");\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"vdev install key ev idx %d flags %08x macaddr %pM status %d\\n\",\n\t\t   install_key_compl.key_idx, install_key_compl.key_flags,\n\t\t   install_key_compl.macaddr, install_key_compl.status);\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, install_key_compl.vdev_id);\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in install key compl ev %d\",\n\t\t\t    install_key_compl.vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tar->install_key_status = 0;\n\n\tif (install_key_compl.status != WMI_VDEV_INSTALL_KEY_COMPL_STATUS_SUCCESS) {\n\t\tath12k_warn(ab, \"install key failed for %pM status %d\\n\",\n\t\t\t    install_key_compl.macaddr, install_key_compl.status);\n\t\tar->install_key_status = install_key_compl.status;\n\t}\n\n\tcomplete(&ar->install_key_done);\n\trcu_read_unlock();\n}\n\nstatic int ath12k_wmi_tlv_services_parser(struct ath12k_base *ab,\n\t\t\t\t\t  u16 tag, u16 len,\n\t\t\t\t\t  const void *ptr,\n\t\t\t\t\t  void *data)\n{\n\tconst struct wmi_service_available_event *ev;\n\tu32 *wmi_ext2_service_bitmap;\n\tint i, j;\n\tu16 expected_len;\n\n\texpected_len = WMI_SERVICE_SEGMENT_BM_SIZE32 * sizeof(u32);\n\tif (len < expected_len) {\n\t\tath12k_warn(ab, \"invalid length %d for the WMI services available tag 0x%x\\n\",\n\t\t\t    len, tag);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (tag) {\n\tcase WMI_TAG_SERVICE_AVAILABLE_EVENT:\n\t\tev = (struct wmi_service_available_event *)ptr;\n\t\tfor (i = 0, j = WMI_MAX_SERVICE;\n\t\t     i < WMI_SERVICE_SEGMENT_BM_SIZE32 && j < WMI_MAX_EXT_SERVICE;\n\t\t     i++) {\n\t\t\tdo {\n\t\t\t\tif (le32_to_cpu(ev->wmi_service_segment_bitmap[i]) &\n\t\t\t\t    BIT(j % WMI_AVAIL_SERVICE_BITS_IN_SIZE32))\n\t\t\t\t\tset_bit(j, ab->wmi_ab.svc_map);\n\t\t\t} while (++j % WMI_AVAIL_SERVICE_BITS_IN_SIZE32);\n\t\t}\n\n\t\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t\t   \"wmi_ext_service_bitmap 0x%x 0x%x 0x%x 0x%x\",\n\t\t\t   ev->wmi_service_segment_bitmap[0],\n\t\t\t   ev->wmi_service_segment_bitmap[1],\n\t\t\t   ev->wmi_service_segment_bitmap[2],\n\t\t\t   ev->wmi_service_segment_bitmap[3]);\n\t\tbreak;\n\tcase WMI_TAG_ARRAY_UINT32:\n\t\twmi_ext2_service_bitmap = (u32 *)ptr;\n\t\tfor (i = 0, j = WMI_MAX_EXT_SERVICE;\n\t\t     i < WMI_SERVICE_SEGMENT_BM_SIZE32 && j < WMI_MAX_EXT2_SERVICE;\n\t\t     i++) {\n\t\t\tdo {\n\t\t\t\tif (wmi_ext2_service_bitmap[i] &\n\t\t\t\t    BIT(j % WMI_AVAIL_SERVICE_BITS_IN_SIZE32))\n\t\t\t\t\tset_bit(j, ab->wmi_ab.svc_map);\n\t\t\t} while (++j % WMI_AVAIL_SERVICE_BITS_IN_SIZE32);\n\t\t}\n\n\t\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t\t   \"wmi_ext2_service_bitmap 0x%04x 0x%04x 0x%04x 0x%04x\",\n\t\t\t   wmi_ext2_service_bitmap[0], wmi_ext2_service_bitmap[1],\n\t\t\t   wmi_ext2_service_bitmap[2], wmi_ext2_service_bitmap[3]);\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic int ath12k_service_available_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tint ret;\n\n\tret = ath12k_wmi_tlv_iter(ab, skb->data, skb->len,\n\t\t\t\t  ath12k_wmi_tlv_services_parser,\n\t\t\t\t  NULL);\n\treturn ret;\n}\n\nstatic void ath12k_peer_assoc_conf_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_peer_assoc_conf_arg peer_assoc_conf = {0};\n\tstruct ath12k *ar;\n\n\tif (ath12k_pull_peer_assoc_conf_ev(ab, skb, &peer_assoc_conf) != 0) {\n\t\tath12k_warn(ab, \"failed to extract peer assoc conf event\");\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"peer assoc conf ev vdev id %d macaddr %pM\\n\",\n\t\t   peer_assoc_conf.vdev_id, peer_assoc_conf.macaddr);\n\n\trcu_read_lock();\n\tar = ath12k_mac_get_ar_by_vdev_id(ab, peer_assoc_conf.vdev_id);\n\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid vdev id in peer assoc conf ev %d\",\n\t\t\t    peer_assoc_conf.vdev_id);\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tcomplete(&ar->peer_assoc_done);\n\trcu_read_unlock();\n}\n\nstatic void ath12k_update_stats_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n}\n\n \nstatic void ath12k_pdev_ctl_failsafe_check_event(struct ath12k_base *ab,\n\t\t\t\t\t\t struct sk_buff *skb)\n{\n\tconst void **tb;\n\tconst struct wmi_pdev_ctl_failsafe_chk_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn;\n\t}\n\n\tev = tb[WMI_TAG_PDEV_CTL_FAILSAFE_CHECK_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch pdev ctl failsafe check ev\");\n\t\tkfree(tb);\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"pdev ctl failsafe check ev status %d\\n\",\n\t\t   ev->ctl_failsafe_status);\n\n\t \n\tif (ev->ctl_failsafe_status != 0)\n\t\tath12k_warn(ab, \"pdev ctl failsafe failure status %d\",\n\t\t\t    ev->ctl_failsafe_status);\n\n\tkfree(tb);\n}\n\nstatic void\nath12k_wmi_process_csa_switch_count_event(struct ath12k_base *ab,\n\t\t\t\t\t  const struct ath12k_wmi_pdev_csa_event *ev,\n\t\t\t\t\t  const u32 *vdev_ids)\n{\n\tint i;\n\tstruct ath12k_vif *arvif;\n\n\t \n\tif (ev->current_switch_count)\n\t\treturn;\n\n\trcu_read_lock();\n\tfor (i = 0; i < le32_to_cpu(ev->num_vdevs); i++) {\n\t\tarvif = ath12k_mac_get_arvif_by_vdev_id(ab, vdev_ids[i]);\n\n\t\tif (!arvif) {\n\t\t\tath12k_warn(ab, \"Recvd csa status for unknown vdev %d\",\n\t\t\t\t    vdev_ids[i]);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (arvif->is_up && arvif->vif->bss_conf.csa_active)\n\t\t\tieee80211_csa_finish(arvif->vif);\n\t}\n\trcu_read_unlock();\n}\n\nstatic void\nath12k_wmi_pdev_csa_switch_count_status_event(struct ath12k_base *ab,\n\t\t\t\t\t      struct sk_buff *skb)\n{\n\tconst void **tb;\n\tconst struct ath12k_wmi_pdev_csa_event *ev;\n\tconst u32 *vdev_ids;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn;\n\t}\n\n\tev = tb[WMI_TAG_PDEV_CSA_SWITCH_COUNT_STATUS_EVENT];\n\tvdev_ids = tb[WMI_TAG_ARRAY_UINT32];\n\n\tif (!ev || !vdev_ids) {\n\t\tath12k_warn(ab, \"failed to fetch pdev csa switch count ev\");\n\t\tkfree(tb);\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"pdev csa switch count %d for pdev %d, num_vdevs %d\",\n\t\t   ev->current_switch_count, ev->pdev_id,\n\t\t   ev->num_vdevs);\n\n\tath12k_wmi_process_csa_switch_count_event(ab, ev, vdev_ids);\n\n\tkfree(tb);\n}\n\nstatic void\nath12k_wmi_pdev_dfs_radar_detected_event(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tconst void **tb;\n\tconst struct ath12k_wmi_pdev_radar_event *ev;\n\tstruct ath12k *ar;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab, \"failed to parse tlv: %d\\n\", ret);\n\t\treturn;\n\t}\n\n\tev = tb[WMI_TAG_PDEV_DFS_RADAR_DETECTION_EVENT];\n\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch pdev dfs radar detected ev\");\n\t\tkfree(tb);\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"pdev dfs radar detected on pdev %d, detection mode %d, chan freq %d, chan_width %d, detector id %d, seg id %d, timestamp %d, chirp %d, freq offset %d, sidx %d\",\n\t\t   ev->pdev_id, ev->detection_mode, ev->chan_freq, ev->chan_width,\n\t\t   ev->detector_id, ev->segment_id, ev->timestamp, ev->is_chirp,\n\t\t   ev->freq_offset, ev->sidx);\n\n\trcu_read_lock();\n\n\tar = ath12k_mac_get_ar_by_pdev_id(ab, le32_to_cpu(ev->pdev_id));\n\n\tif (!ar) {\n\t\tath12k_warn(ab, \"radar detected in invalid pdev %d\\n\",\n\t\t\t    ev->pdev_id);\n\t\tgoto exit;\n\t}\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_REG, \"DFS Radar Detected in pdev %d\\n\",\n\t\t   ev->pdev_id);\n\n\tif (ar->dfs_block_radar_events)\n\t\tath12k_info(ab, \"DFS Radar detected, but ignored as requested\\n\");\n\telse\n\t\tieee80211_radar_detected(ar->hw);\n\nexit:\n\trcu_read_unlock();\n\n\tkfree(tb);\n}\n\nstatic void\nath12k_wmi_pdev_temperature_event(struct ath12k_base *ab,\n\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct ath12k *ar;\n\tstruct wmi_pdev_temperature_event ev = {0};\n\n\tif (ath12k_pull_pdev_temp_ev(ab, skb->data, skb->len, &ev) != 0) {\n\t\tath12k_warn(ab, \"failed to extract pdev temperature event\");\n\t\treturn;\n\t}\n\n\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t   \"pdev temperature ev temp %d pdev_id %d\\n\", ev.temp, ev.pdev_id);\n\n\trcu_read_lock();\n\n\tar = ath12k_mac_get_ar_by_pdev_id(ab, le32_to_cpu(ev.pdev_id));\n\tif (!ar) {\n\t\tath12k_warn(ab, \"invalid pdev id in pdev temperature ev %d\", ev.pdev_id);\n\t\tgoto exit;\n\t}\n\nexit:\n\trcu_read_unlock();\n}\n\nstatic void ath12k_fils_discovery_event(struct ath12k_base *ab,\n\t\t\t\t\tstruct sk_buff *skb)\n{\n\tconst void **tb;\n\tconst struct wmi_fils_discovery_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab,\n\t\t\t    \"failed to parse FILS discovery event tlv %d\\n\",\n\t\t\t    ret);\n\t\treturn;\n\t}\n\n\tev = tb[WMI_TAG_HOST_SWFDA_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab, \"failed to fetch FILS discovery event\\n\");\n\t\tkfree(tb);\n\t\treturn;\n\t}\n\n\tath12k_warn(ab,\n\t\t    \"FILS discovery frame expected from host for vdev_id: %u, transmission scheduled at %u, next TBTT: %u\\n\",\n\t\t    ev->vdev_id, ev->fils_tt, ev->tbtt);\n\n\tkfree(tb);\n}\n\nstatic void ath12k_probe_resp_tx_status_event(struct ath12k_base *ab,\n\t\t\t\t\t      struct sk_buff *skb)\n{\n\tconst void **tb;\n\tconst struct wmi_probe_resp_tx_status_event *ev;\n\tint ret;\n\n\ttb = ath12k_wmi_tlv_parse_alloc(ab, skb->data, skb->len, GFP_ATOMIC);\n\tif (IS_ERR(tb)) {\n\t\tret = PTR_ERR(tb);\n\t\tath12k_warn(ab,\n\t\t\t    \"failed to parse probe response transmission status event tlv: %d\\n\",\n\t\t\t    ret);\n\t\treturn;\n\t}\n\n\tev = tb[WMI_TAG_OFFLOAD_PRB_RSP_TX_STATUS_EVENT];\n\tif (!ev) {\n\t\tath12k_warn(ab,\n\t\t\t    \"failed to fetch probe response transmission status event\");\n\t\tkfree(tb);\n\t\treturn;\n\t}\n\n\tif (ev->tx_status)\n\t\tath12k_warn(ab,\n\t\t\t    \"Probe response transmission failed for vdev_id %u, status %u\\n\",\n\t\t\t    ev->vdev_id, ev->tx_status);\n\n\tkfree(tb);\n}\n\nstatic void ath12k_wmi_op_rx(struct ath12k_base *ab, struct sk_buff *skb)\n{\n\tstruct wmi_cmd_hdr *cmd_hdr;\n\tenum wmi_tlv_event_id id;\n\n\tcmd_hdr = (struct wmi_cmd_hdr *)skb->data;\n\tid = le32_get_bits(cmd_hdr->cmd_id, WMI_CMD_HDR_CMD_ID);\n\n\tif (!skb_pull(skb, sizeof(struct wmi_cmd_hdr)))\n\t\tgoto out;\n\n\tswitch (id) {\n\t\t \n\tcase WMI_SERVICE_READY_EVENTID:\n\t\tath12k_service_ready_event(ab, skb);\n\t\tbreak;\n\tcase WMI_SERVICE_READY_EXT_EVENTID:\n\t\tath12k_service_ready_ext_event(ab, skb);\n\t\tbreak;\n\tcase WMI_SERVICE_READY_EXT2_EVENTID:\n\t\tath12k_service_ready_ext2_event(ab, skb);\n\t\tbreak;\n\tcase WMI_REG_CHAN_LIST_CC_EXT_EVENTID:\n\t\tath12k_reg_chan_list_event(ab, skb);\n\t\tbreak;\n\tcase WMI_READY_EVENTID:\n\t\tath12k_ready_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PEER_DELETE_RESP_EVENTID:\n\t\tath12k_peer_delete_resp_event(ab, skb);\n\t\tbreak;\n\tcase WMI_VDEV_START_RESP_EVENTID:\n\t\tath12k_vdev_start_resp_event(ab, skb);\n\t\tbreak;\n\tcase WMI_OFFLOAD_BCN_TX_STATUS_EVENTID:\n\t\tath12k_bcn_tx_status_event(ab, skb);\n\t\tbreak;\n\tcase WMI_VDEV_STOPPED_EVENTID:\n\t\tath12k_vdev_stopped_event(ab, skb);\n\t\tbreak;\n\tcase WMI_MGMT_RX_EVENTID:\n\t\tath12k_mgmt_rx_event(ab, skb);\n\t\t \n\t\treturn;\n\tcase WMI_MGMT_TX_COMPLETION_EVENTID:\n\t\tath12k_mgmt_tx_compl_event(ab, skb);\n\t\tbreak;\n\tcase WMI_SCAN_EVENTID:\n\t\tath12k_scan_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PEER_STA_KICKOUT_EVENTID:\n\t\tath12k_peer_sta_kickout_event(ab, skb);\n\t\tbreak;\n\tcase WMI_ROAM_EVENTID:\n\t\tath12k_roam_event(ab, skb);\n\t\tbreak;\n\tcase WMI_CHAN_INFO_EVENTID:\n\t\tath12k_chan_info_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PDEV_BSS_CHAN_INFO_EVENTID:\n\t\tath12k_pdev_bss_chan_info_event(ab, skb);\n\t\tbreak;\n\tcase WMI_VDEV_INSTALL_KEY_COMPLETE_EVENTID:\n\t\tath12k_vdev_install_key_compl_event(ab, skb);\n\t\tbreak;\n\tcase WMI_SERVICE_AVAILABLE_EVENTID:\n\t\tath12k_service_available_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PEER_ASSOC_CONF_EVENTID:\n\t\tath12k_peer_assoc_conf_event(ab, skb);\n\t\tbreak;\n\tcase WMI_UPDATE_STATS_EVENTID:\n\t\tath12k_update_stats_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PDEV_CTL_FAILSAFE_CHECK_EVENTID:\n\t\tath12k_pdev_ctl_failsafe_check_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PDEV_CSA_SWITCH_COUNT_STATUS_EVENTID:\n\t\tath12k_wmi_pdev_csa_switch_count_status_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PDEV_TEMPERATURE_EVENTID:\n\t\tath12k_wmi_pdev_temperature_event(ab, skb);\n\t\tbreak;\n\tcase WMI_PDEV_DMA_RING_BUF_RELEASE_EVENTID:\n\t\tath12k_wmi_pdev_dma_ring_buf_release_event(ab, skb);\n\t\tbreak;\n\tcase WMI_HOST_FILS_DISCOVERY_EVENTID:\n\t\tath12k_fils_discovery_event(ab, skb);\n\t\tbreak;\n\tcase WMI_OFFLOAD_PROB_RESP_TX_STATUS_EVENTID:\n\t\tath12k_probe_resp_tx_status_event(ab, skb);\n\t\tbreak;\n\t \n\tcase WMI_TBTTOFFSET_EXT_UPDATE_EVENTID:\n\tcase WMI_PEER_OPER_MODE_CHANGE_EVENTID:\n\tcase WMI_TWT_ENABLE_EVENTID:\n\tcase WMI_TWT_DISABLE_EVENTID:\n\tcase WMI_PDEV_DMA_RING_CFG_RSP_EVENTID:\n\t\tath12k_dbg(ab, ATH12K_DBG_WMI,\n\t\t\t   \"ignoring unsupported event 0x%x\\n\", id);\n\t\tbreak;\n\tcase WMI_PDEV_DFS_RADAR_DETECTION_EVENTID:\n\t\tath12k_wmi_pdev_dfs_radar_detected_event(ab, skb);\n\t\tbreak;\n\tcase WMI_VDEV_DELETE_RESP_EVENTID:\n\t\tath12k_vdev_delete_resp_event(ab, skb);\n\t\tbreak;\n\t \n\tdefault:\n\t\tath12k_dbg(ab, ATH12K_DBG_WMI, \"Unknown eventid: 0x%x\\n\", id);\n\t\tbreak;\n\t}\n\nout:\n\tdev_kfree_skb(skb);\n}\n\nstatic int ath12k_connect_pdev_htc_service(struct ath12k_base *ab,\n\t\t\t\t\t   u32 pdev_idx)\n{\n\tint status;\n\tu32 svc_id[] = { ATH12K_HTC_SVC_ID_WMI_CONTROL,\n\t\t\t ATH12K_HTC_SVC_ID_WMI_CONTROL_MAC1,\n\t\t\t ATH12K_HTC_SVC_ID_WMI_CONTROL_MAC2 };\n\tstruct ath12k_htc_svc_conn_req conn_req = {};\n\tstruct ath12k_htc_svc_conn_resp conn_resp = {};\n\n\t \n\tconn_req.ep_ops.ep_tx_complete = ath12k_wmi_htc_tx_complete;\n\tconn_req.ep_ops.ep_rx_complete = ath12k_wmi_op_rx;\n\tconn_req.ep_ops.ep_tx_credits = ath12k_wmi_op_ep_tx_credits;\n\n\t \n\tconn_req.service_id = svc_id[pdev_idx];\n\n\tstatus = ath12k_htc_connect_service(&ab->htc, &conn_req, &conn_resp);\n\tif (status) {\n\t\tath12k_warn(ab, \"failed to connect to WMI CONTROL service status: %d\\n\",\n\t\t\t    status);\n\t\treturn status;\n\t}\n\n\tab->wmi_ab.wmi_endpoint_id[pdev_idx] = conn_resp.eid;\n\tab->wmi_ab.wmi[pdev_idx].eid = conn_resp.eid;\n\tab->wmi_ab.max_msg_len[pdev_idx] = conn_resp.max_msg_len;\n\n\treturn 0;\n}\n\nstatic int\nath12k_wmi_send_unit_test_cmd(struct ath12k *ar,\n\t\t\t      struct wmi_unit_test_cmd ut_cmd,\n\t\t\t      u32 *test_args)\n{\n\tstruct ath12k_wmi_pdev *wmi = ar->wmi;\n\tstruct wmi_unit_test_cmd *cmd;\n\tstruct sk_buff *skb;\n\tstruct wmi_tlv *tlv;\n\tvoid *ptr;\n\tu32 *ut_cmd_args;\n\tint buf_len, arg_len;\n\tint ret;\n\tint i;\n\n\targ_len = sizeof(u32) * le32_to_cpu(ut_cmd.num_args);\n\tbuf_len = sizeof(ut_cmd) + arg_len + TLV_HDR_SIZE;\n\n\tskb = ath12k_wmi_alloc_skb(wmi->wmi_ab, buf_len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcmd = (struct wmi_unit_test_cmd *)skb->data;\n\tcmd->tlv_header = ath12k_wmi_tlv_cmd_hdr(WMI_TAG_UNIT_TEST_CMD,\n\t\t\t\t\t\t sizeof(ut_cmd));\n\n\tcmd->vdev_id = ut_cmd.vdev_id;\n\tcmd->module_id = ut_cmd.module_id;\n\tcmd->num_args = ut_cmd.num_args;\n\tcmd->diag_token = ut_cmd.diag_token;\n\n\tptr = skb->data + sizeof(ut_cmd);\n\n\ttlv = ptr;\n\ttlv->header = ath12k_wmi_tlv_hdr(WMI_TAG_ARRAY_UINT32, arg_len);\n\n\tptr += TLV_HDR_SIZE;\n\n\tut_cmd_args = ptr;\n\tfor (i = 0; i < le32_to_cpu(ut_cmd.num_args); i++)\n\t\tut_cmd_args[i] = test_args[i];\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_WMI,\n\t\t   \"WMI unit test : module %d vdev %d n_args %d token %d\\n\",\n\t\t   cmd->module_id, cmd->vdev_id, cmd->num_args,\n\t\t   cmd->diag_token);\n\n\tret = ath12k_wmi_cmd_send(wmi, skb, WMI_UNIT_TEST_CMDID);\n\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to send WMI_UNIT_TEST CMD :%d\\n\",\n\t\t\t    ret);\n\t\tdev_kfree_skb(skb);\n\t}\n\n\treturn ret;\n}\n\nint ath12k_wmi_simulate_radar(struct ath12k *ar)\n{\n\tstruct ath12k_vif *arvif;\n\tu32 dfs_args[DFS_MAX_TEST_ARGS];\n\tstruct wmi_unit_test_cmd wmi_ut;\n\tbool arvif_found = false;\n\n\tlist_for_each_entry(arvif, &ar->arvifs, list) {\n\t\tif (arvif->is_started && arvif->vdev_type == WMI_VDEV_TYPE_AP) {\n\t\t\tarvif_found = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!arvif_found)\n\t\treturn -EINVAL;\n\n\tdfs_args[DFS_TEST_CMDID] = 0;\n\tdfs_args[DFS_TEST_PDEV_ID] = ar->pdev->pdev_id;\n\t \n\tdfs_args[DFS_TEST_RADAR_PARAM] = 0;\n\n\twmi_ut.vdev_id = cpu_to_le32(arvif->vdev_id);\n\twmi_ut.module_id = cpu_to_le32(DFS_UNIT_TEST_MODULE);\n\twmi_ut.num_args = cpu_to_le32(DFS_MAX_TEST_ARGS);\n\twmi_ut.diag_token = cpu_to_le32(DFS_UNIT_TEST_TOKEN);\n\n\tath12k_dbg(ar->ab, ATH12K_DBG_REG, \"Triggering Radar Simulation\\n\");\n\n\treturn ath12k_wmi_send_unit_test_cmd(ar, wmi_ut, dfs_args);\n}\n\nint ath12k_wmi_connect(struct ath12k_base *ab)\n{\n\tu32 i;\n\tu8 wmi_ep_count;\n\n\twmi_ep_count = ab->htc.wmi_ep_count;\n\tif (wmi_ep_count > ab->hw_params->max_radios)\n\t\treturn -1;\n\n\tfor (i = 0; i < wmi_ep_count; i++)\n\t\tath12k_connect_pdev_htc_service(ab, i);\n\n\treturn 0;\n}\n\nstatic void ath12k_wmi_pdev_detach(struct ath12k_base *ab, u8 pdev_id)\n{\n\tif (WARN_ON(pdev_id >= MAX_RADIOS))\n\t\treturn;\n\n\t \n}\n\nint ath12k_wmi_pdev_attach(struct ath12k_base *ab,\n\t\t\t   u8 pdev_id)\n{\n\tstruct ath12k_wmi_pdev *wmi_handle;\n\n\tif (pdev_id >= ab->hw_params->max_radios)\n\t\treturn -EINVAL;\n\n\twmi_handle = &ab->wmi_ab.wmi[pdev_id];\n\n\twmi_handle->wmi_ab = &ab->wmi_ab;\n\n\tab->wmi_ab.ab = ab;\n\t \n\n\treturn 0;\n}\n\nint ath12k_wmi_attach(struct ath12k_base *ab)\n{\n\tint ret;\n\n\tret = ath12k_wmi_pdev_attach(ab, 0);\n\tif (ret)\n\t\treturn ret;\n\n\tab->wmi_ab.ab = ab;\n\tab->wmi_ab.preferred_hw_mode = WMI_HOST_HW_MODE_MAX;\n\n\t \n\tif (ab->hw_params->single_pdev_only)\n\t\tab->wmi_ab.preferred_hw_mode = WMI_HOST_HW_MODE_SINGLE;\n\n\t \n\tinit_completion(&ab->wmi_ab.service_ready);\n\tinit_completion(&ab->wmi_ab.unified_ready);\n\n\treturn 0;\n}\n\nvoid ath12k_wmi_detach(struct ath12k_base *ab)\n{\n\tint i;\n\n\t \n\n\tfor (i = 0; i < ab->htc.wmi_ep_count; i++)\n\t\tath12k_wmi_pdev_detach(ab, i);\n\n\tath12k_wmi_free_dbring_caps(ab);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}