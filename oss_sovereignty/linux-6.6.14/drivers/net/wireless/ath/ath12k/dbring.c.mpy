{
  "module_name": "dbring.c",
  "hash_id": "0b654c4fc400304f0faa60a2ea848053a4a621c15aed614a1087a84365ec8c15",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ath/ath12k/dbring.c",
  "human_readable_source": "\n \n\n#include \"core.h\"\n#include \"debug.h\"\n\nstatic int ath12k_dbring_bufs_replenish(struct ath12k *ar,\n\t\t\t\t\tstruct ath12k_dbring *ring,\n\t\t\t\t\tstruct ath12k_dbring_element *buff,\n\t\t\t\t\tgfp_t gfp)\n{\n\tstruct ath12k_base *ab = ar->ab;\n\tstruct hal_srng *srng;\n\tdma_addr_t paddr;\n\tvoid *ptr_aligned, *ptr_unaligned, *desc;\n\tint ret;\n\tint buf_id;\n\tu32 cookie;\n\n\tsrng = &ab->hal.srng_list[ring->refill_srng.ring_id];\n\n\tlockdep_assert_held(&srng->lock);\n\n\tath12k_hal_srng_access_begin(ab, srng);\n\n\tptr_unaligned = buff->payload;\n\tptr_aligned = PTR_ALIGN(ptr_unaligned, ring->buf_align);\n\tpaddr = dma_map_single(ab->dev, ptr_aligned, ring->buf_sz,\n\t\t\t       DMA_FROM_DEVICE);\n\n\tret = dma_mapping_error(ab->dev, paddr);\n\tif (ret)\n\t\tgoto err;\n\n\tspin_lock_bh(&ring->idr_lock);\n\tbuf_id = idr_alloc(&ring->bufs_idr, buff, 0, ring->bufs_max, gfp);\n\tspin_unlock_bh(&ring->idr_lock);\n\tif (buf_id < 0) {\n\t\tret = -ENOBUFS;\n\t\tgoto err_dma_unmap;\n\t}\n\n\tdesc = ath12k_hal_srng_src_get_next_entry(ab, srng);\n\tif (!desc) {\n\t\tret = -ENOENT;\n\t\tgoto err_idr_remove;\n\t}\n\n\tbuff->paddr = paddr;\n\n\tcookie = u32_encode_bits(ar->pdev_idx, DP_RXDMA_BUF_COOKIE_PDEV_ID) |\n\t\t u32_encode_bits(buf_id, DP_RXDMA_BUF_COOKIE_BUF_ID);\n\n\tath12k_hal_rx_buf_addr_info_set(desc, paddr, cookie, 0);\n\n\tath12k_hal_srng_access_end(ab, srng);\n\n\treturn 0;\n\nerr_idr_remove:\n\tspin_lock_bh(&ring->idr_lock);\n\tidr_remove(&ring->bufs_idr, buf_id);\n\tspin_unlock_bh(&ring->idr_lock);\nerr_dma_unmap:\n\tdma_unmap_single(ab->dev, paddr, ring->buf_sz,\n\t\t\t DMA_FROM_DEVICE);\nerr:\n\tath12k_hal_srng_access_end(ab, srng);\n\treturn ret;\n}\n\nstatic int ath12k_dbring_fill_bufs(struct ath12k *ar,\n\t\t\t\t   struct ath12k_dbring *ring,\n\t\t\t\t   gfp_t gfp)\n{\n\tstruct ath12k_dbring_element *buff;\n\tstruct hal_srng *srng;\n\tstruct ath12k_base *ab = ar->ab;\n\tint num_remain, req_entries, num_free;\n\tu32 align;\n\tint size, ret;\n\n\tsrng = &ab->hal.srng_list[ring->refill_srng.ring_id];\n\n\tspin_lock_bh(&srng->lock);\n\n\tnum_free = ath12k_hal_srng_src_num_free(ab, srng, true);\n\treq_entries = min(num_free, ring->bufs_max);\n\tnum_remain = req_entries;\n\talign = ring->buf_align;\n\tsize = sizeof(*buff) + ring->buf_sz + align - 1;\n\n\twhile (num_remain > 0) {\n\t\tbuff = kzalloc(size, gfp);\n\t\tif (!buff)\n\t\t\tbreak;\n\n\t\tret = ath12k_dbring_bufs_replenish(ar, ring, buff, gfp);\n\t\tif (ret) {\n\t\t\tath12k_warn(ab, \"failed to replenish db ring num_remain %d req_ent %d\\n\",\n\t\t\t\t    num_remain, req_entries);\n\t\t\tkfree(buff);\n\t\t\tbreak;\n\t\t}\n\t\tnum_remain--;\n\t}\n\n\tspin_unlock_bh(&srng->lock);\n\n\treturn num_remain;\n}\n\nint ath12k_dbring_wmi_cfg_setup(struct ath12k *ar,\n\t\t\t\tstruct ath12k_dbring *ring,\n\t\t\t\tenum wmi_direct_buffer_module id)\n{\n\tstruct ath12k_wmi_pdev_dma_ring_cfg_arg arg = {0};\n\tint ret;\n\n\tif (id >= WMI_DIRECT_BUF_MAX)\n\t\treturn -EINVAL;\n\n\targ.pdev_id = DP_SW2HW_MACID(ring->pdev_id);\n\targ.module_id = id;\n\targ.base_paddr_lo = lower_32_bits(ring->refill_srng.paddr);\n\targ.base_paddr_hi = upper_32_bits(ring->refill_srng.paddr);\n\targ.head_idx_paddr_lo = lower_32_bits(ring->hp_addr);\n\targ.head_idx_paddr_hi = upper_32_bits(ring->hp_addr);\n\targ.tail_idx_paddr_lo = lower_32_bits(ring->tp_addr);\n\targ.tail_idx_paddr_hi = upper_32_bits(ring->tp_addr);\n\targ.num_elems = ring->bufs_max;\n\targ.buf_size = ring->buf_sz;\n\targ.num_resp_per_event = ring->num_resp_per_event;\n\targ.event_timeout_ms = ring->event_timeout_ms;\n\n\tret = ath12k_wmi_pdev_dma_ring_cfg(ar, &arg);\n\tif (ret) {\n\t\tath12k_warn(ar->ab, \"failed to setup db ring cfg\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint ath12k_dbring_set_cfg(struct ath12k *ar, struct ath12k_dbring *ring,\n\t\t\t  u32 num_resp_per_event, u32 event_timeout_ms,\n\t\t\t  int (*handler)(struct ath12k *,\n\t\t\t\t\t struct ath12k_dbring_data *))\n{\n\tif (WARN_ON(!ring))\n\t\treturn -EINVAL;\n\n\tring->num_resp_per_event = num_resp_per_event;\n\tring->event_timeout_ms = event_timeout_ms;\n\tring->handler = handler;\n\n\treturn 0;\n}\n\nint ath12k_dbring_buf_setup(struct ath12k *ar,\n\t\t\t    struct ath12k_dbring *ring,\n\t\t\t    struct ath12k_dbring_cap *db_cap)\n{\n\tstruct ath12k_base *ab = ar->ab;\n\tstruct hal_srng *srng;\n\tint ret;\n\n\tsrng = &ab->hal.srng_list[ring->refill_srng.ring_id];\n\tring->bufs_max = ring->refill_srng.size /\n\t\tath12k_hal_srng_get_entrysize(ab, HAL_RXDMA_DIR_BUF);\n\n\tring->buf_sz = db_cap->min_buf_sz;\n\tring->buf_align = db_cap->min_buf_align;\n\tring->pdev_id = db_cap->pdev_id;\n\tring->hp_addr = ath12k_hal_srng_get_hp_addr(ab, srng);\n\tring->tp_addr = ath12k_hal_srng_get_tp_addr(ab, srng);\n\n\tret = ath12k_dbring_fill_bufs(ar, ring, GFP_KERNEL);\n\n\treturn ret;\n}\n\nint ath12k_dbring_srng_setup(struct ath12k *ar, struct ath12k_dbring *ring,\n\t\t\t     int ring_num, int num_entries)\n{\n\tint ret;\n\n\tret = ath12k_dp_srng_setup(ar->ab, &ring->refill_srng, HAL_RXDMA_DIR_BUF,\n\t\t\t\t   ring_num, ar->pdev_idx, num_entries);\n\tif (ret < 0) {\n\t\tath12k_warn(ar->ab, \"failed to setup srng: %d ring_id %d\\n\",\n\t\t\t    ret, ring_num);\n\t\tgoto err;\n\t}\n\n\treturn 0;\nerr:\n\tath12k_dp_srng_cleanup(ar->ab, &ring->refill_srng);\n\treturn ret;\n}\n\nint ath12k_dbring_get_cap(struct ath12k_base *ab,\n\t\t\t  u8 pdev_idx,\n\t\t\t  enum wmi_direct_buffer_module id,\n\t\t\t  struct ath12k_dbring_cap *db_cap)\n{\n\tint i;\n\n\tif (!ab->num_db_cap || !ab->db_caps)\n\t\treturn -ENOENT;\n\n\tif (id >= WMI_DIRECT_BUF_MAX)\n\t\treturn -EINVAL;\n\n\tfor (i = 0; i < ab->num_db_cap; i++) {\n\t\tif (pdev_idx == ab->db_caps[i].pdev_id &&\n\t\t    id == ab->db_caps[i].id) {\n\t\t\t*db_cap = ab->db_caps[i];\n\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn -ENOENT;\n}\n\nint ath12k_dbring_buffer_release_event(struct ath12k_base *ab,\n\t\t\t\t       struct ath12k_dbring_buf_release_event *ev)\n{\n\tstruct ath12k_dbring *ring = NULL;\n\tstruct hal_srng *srng;\n\tstruct ath12k *ar;\n\tstruct ath12k_dbring_element *buff;\n\tstruct ath12k_dbring_data handler_data;\n\tstruct ath12k_buffer_addr desc;\n\tu8 *vaddr_unalign;\n\tu32 num_entry, num_buff_reaped;\n\tu8 pdev_idx, rbm;\n\tu32 cookie;\n\tint buf_id;\n\tint size;\n\tdma_addr_t paddr;\n\tint ret = 0;\n\n\tpdev_idx = le32_to_cpu(ev->fixed.pdev_id);\n\n\tif (pdev_idx >= ab->num_radios) {\n\t\tath12k_warn(ab, \"Invalid pdev id %d\\n\", pdev_idx);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ev->fixed.num_buf_release_entry !=\n\t    ev->fixed.num_meta_data_entry) {\n\t\tath12k_warn(ab, \"Buffer entry %d mismatch meta entry %d\\n\",\n\t\t\t    ev->fixed.num_buf_release_entry,\n\t\t\t    ev->fixed.num_meta_data_entry);\n\t\treturn -EINVAL;\n\t}\n\n\tar = ab->pdevs[pdev_idx].ar;\n\n\trcu_read_lock();\n\tif (!rcu_dereference(ab->pdevs_active[pdev_idx])) {\n\t\tret = -EINVAL;\n\t\tgoto rcu_unlock;\n\t}\n\n\tswitch (ev->fixed.module_id) {\n\tcase WMI_DIRECT_BUF_SPECTRAL:\n\t\tbreak;\n\tdefault:\n\t\tring = NULL;\n\t\tath12k_warn(ab, \"Recv dma buffer release ev on unsupp module %d\\n\",\n\t\t\t    ev->fixed.module_id);\n\t\tbreak;\n\t}\n\n\tif (!ring) {\n\t\tret = -EINVAL;\n\t\tgoto rcu_unlock;\n\t}\n\n\tsrng = &ab->hal.srng_list[ring->refill_srng.ring_id];\n\tnum_entry = le32_to_cpu(ev->fixed.num_buf_release_entry);\n\tsize = sizeof(*buff) + ring->buf_sz + ring->buf_align - 1;\n\tnum_buff_reaped = 0;\n\n\tspin_lock_bh(&srng->lock);\n\n\twhile (num_buff_reaped < num_entry) {\n\t\tdesc.info0 = ev->buf_entry[num_buff_reaped].paddr_lo;\n\t\tdesc.info1 = ev->buf_entry[num_buff_reaped].paddr_hi;\n\t\thandler_data.meta = ev->meta_data[num_buff_reaped];\n\n\t\tnum_buff_reaped++;\n\n\t\tath12k_hal_rx_buf_addr_info_get(&desc, &paddr, &cookie, &rbm);\n\n\t\tbuf_id = u32_get_bits(cookie, DP_RXDMA_BUF_COOKIE_BUF_ID);\n\n\t\tspin_lock_bh(&ring->idr_lock);\n\t\tbuff = idr_find(&ring->bufs_idr, buf_id);\n\t\tif (!buff) {\n\t\t\tspin_unlock_bh(&ring->idr_lock);\n\t\t\tcontinue;\n\t\t}\n\t\tidr_remove(&ring->bufs_idr, buf_id);\n\t\tspin_unlock_bh(&ring->idr_lock);\n\n\t\tdma_unmap_single(ab->dev, buff->paddr, ring->buf_sz,\n\t\t\t\t DMA_FROM_DEVICE);\n\n\t\tif (ring->handler) {\n\t\t\tvaddr_unalign = buff->payload;\n\t\t\thandler_data.data = PTR_ALIGN(vaddr_unalign,\n\t\t\t\t\t\t      ring->buf_align);\n\t\t\thandler_data.data_sz = ring->buf_sz;\n\n\t\t\tring->handler(ar, &handler_data);\n\t\t}\n\n\t\tmemset(buff, 0, size);\n\t\tath12k_dbring_bufs_replenish(ar, ring, buff, GFP_ATOMIC);\n\t}\n\n\tspin_unlock_bh(&srng->lock);\n\nrcu_unlock:\n\trcu_read_unlock();\n\n\treturn ret;\n}\n\nvoid ath12k_dbring_srng_cleanup(struct ath12k *ar, struct ath12k_dbring *ring)\n{\n\tath12k_dp_srng_cleanup(ar->ab, &ring->refill_srng);\n}\n\nvoid ath12k_dbring_buf_cleanup(struct ath12k *ar, struct ath12k_dbring *ring)\n{\n\tstruct ath12k_dbring_element *buff;\n\tint buf_id;\n\n\tspin_lock_bh(&ring->idr_lock);\n\tidr_for_each_entry(&ring->bufs_idr, buff, buf_id) {\n\t\tidr_remove(&ring->bufs_idr, buf_id);\n\t\tdma_unmap_single(ar->ab->dev, buff->paddr,\n\t\t\t\t ring->buf_sz, DMA_FROM_DEVICE);\n\t\tkfree(buff);\n\t}\n\n\tidr_destroy(&ring->bufs_idr);\n\tspin_unlock_bh(&ring->idr_lock);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}