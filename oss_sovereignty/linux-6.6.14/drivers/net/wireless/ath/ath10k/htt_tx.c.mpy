{
  "module_name": "htt_tx.c",
  "hash_id": "4294cb730f3b21c5e436c3db547f78e7b00cc01dbe7765910983f6cd2356463a",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ath/ath10k/htt_tx.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include \"htt.h\"\n#include \"mac.h\"\n#include \"hif.h\"\n#include \"txrx.h\"\n#include \"debug.h\"\n\nstatic u8 ath10k_htt_tx_txq_calc_size(size_t count)\n{\n\tint exp;\n\tint factor;\n\n\texp = 0;\n\tfactor = count >> 7;\n\n\twhile (factor >= 64 && exp < 4) {\n\t\tfactor >>= 3;\n\t\texp++;\n\t}\n\n\tif (exp == 4)\n\t\treturn 0xff;\n\n\tif (count > 0)\n\t\tfactor = max(1, factor);\n\n\treturn SM(exp, HTT_TX_Q_STATE_ENTRY_EXP) |\n\t       SM(factor, HTT_TX_Q_STATE_ENTRY_FACTOR);\n}\n\nstatic void __ath10k_htt_tx_txq_recalc(struct ieee80211_hw *hw,\n\t\t\t\t       struct ieee80211_txq *txq)\n{\n\tstruct ath10k *ar = hw->priv;\n\tstruct ath10k_sta *arsta;\n\tstruct ath10k_vif *arvif = (void *)txq->vif->drv_priv;\n\tunsigned long frame_cnt;\n\tunsigned long byte_cnt;\n\tint idx;\n\tu32 bit;\n\tu16 peer_id;\n\tu8 tid;\n\tu8 count;\n\n\tlockdep_assert_held(&ar->htt.tx_lock);\n\n\tif (!ar->htt.tx_q_state.enabled)\n\t\treturn;\n\n\tif (ar->htt.tx_q_state.mode != HTT_TX_MODE_SWITCH_PUSH_PULL)\n\t\treturn;\n\n\tif (txq->sta) {\n\t\tarsta = (void *)txq->sta->drv_priv;\n\t\tpeer_id = arsta->peer_id;\n\t} else {\n\t\tpeer_id = arvif->peer_id;\n\t}\n\n\ttid = txq->tid;\n\tbit = BIT(peer_id % 32);\n\tidx = peer_id / 32;\n\n\tieee80211_txq_get_depth(txq, &frame_cnt, &byte_cnt);\n\tcount = ath10k_htt_tx_txq_calc_size(byte_cnt);\n\n\tif (unlikely(peer_id >= ar->htt.tx_q_state.num_peers) ||\n\t    unlikely(tid >= ar->htt.tx_q_state.num_tids)) {\n\t\tath10k_warn(ar, \"refusing to update txq for peer_id %u tid %u due to out of bounds\\n\",\n\t\t\t    peer_id, tid);\n\t\treturn;\n\t}\n\n\tar->htt.tx_q_state.vaddr->count[tid][peer_id] = count;\n\tar->htt.tx_q_state.vaddr->map[tid][idx] &= ~bit;\n\tar->htt.tx_q_state.vaddr->map[tid][idx] |= count ? bit : 0;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt tx txq state update peer_id %u tid %u count %u\\n\",\n\t\t   peer_id, tid, count);\n}\n\nstatic void __ath10k_htt_tx_txq_sync(struct ath10k *ar)\n{\n\tu32 seq;\n\tsize_t size;\n\n\tlockdep_assert_held(&ar->htt.tx_lock);\n\n\tif (!ar->htt.tx_q_state.enabled)\n\t\treturn;\n\n\tif (ar->htt.tx_q_state.mode != HTT_TX_MODE_SWITCH_PUSH_PULL)\n\t\treturn;\n\n\tseq = le32_to_cpu(ar->htt.tx_q_state.vaddr->seq);\n\tseq++;\n\tar->htt.tx_q_state.vaddr->seq = cpu_to_le32(seq);\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt tx txq state update commit seq %u\\n\",\n\t\t   seq);\n\n\tsize = sizeof(*ar->htt.tx_q_state.vaddr);\n\tdma_sync_single_for_device(ar->dev,\n\t\t\t\t   ar->htt.tx_q_state.paddr,\n\t\t\t\t   size,\n\t\t\t\t   DMA_TO_DEVICE);\n}\n\nvoid ath10k_htt_tx_txq_recalc(struct ieee80211_hw *hw,\n\t\t\t      struct ieee80211_txq *txq)\n{\n\tstruct ath10k *ar = hw->priv;\n\n\tspin_lock_bh(&ar->htt.tx_lock);\n\t__ath10k_htt_tx_txq_recalc(hw, txq);\n\tspin_unlock_bh(&ar->htt.tx_lock);\n}\n\nvoid ath10k_htt_tx_txq_sync(struct ath10k *ar)\n{\n\tspin_lock_bh(&ar->htt.tx_lock);\n\t__ath10k_htt_tx_txq_sync(ar);\n\tspin_unlock_bh(&ar->htt.tx_lock);\n}\n\nvoid ath10k_htt_tx_txq_update(struct ieee80211_hw *hw,\n\t\t\t      struct ieee80211_txq *txq)\n{\n\tstruct ath10k *ar = hw->priv;\n\n\tspin_lock_bh(&ar->htt.tx_lock);\n\t__ath10k_htt_tx_txq_recalc(hw, txq);\n\t__ath10k_htt_tx_txq_sync(ar);\n\tspin_unlock_bh(&ar->htt.tx_lock);\n}\n\nvoid ath10k_htt_tx_dec_pending(struct ath10k_htt *htt)\n{\n\tlockdep_assert_held(&htt->tx_lock);\n\n\thtt->num_pending_tx--;\n\tif (htt->num_pending_tx == htt->max_num_pending_tx - 1)\n\t\tath10k_mac_tx_unlock(htt->ar, ATH10K_TX_PAUSE_Q_FULL);\n\n\tif (htt->num_pending_tx == 0)\n\t\twake_up(&htt->empty_tx_wq);\n}\n\nint ath10k_htt_tx_inc_pending(struct ath10k_htt *htt)\n{\n\tlockdep_assert_held(&htt->tx_lock);\n\n\tif (htt->num_pending_tx >= htt->max_num_pending_tx)\n\t\treturn -EBUSY;\n\n\thtt->num_pending_tx++;\n\tif (htt->num_pending_tx == htt->max_num_pending_tx)\n\t\tath10k_mac_tx_lock(htt->ar, ATH10K_TX_PAUSE_Q_FULL);\n\n\treturn 0;\n}\n\nint ath10k_htt_tx_mgmt_inc_pending(struct ath10k_htt *htt, bool is_mgmt,\n\t\t\t\t   bool is_presp)\n{\n\tstruct ath10k *ar = htt->ar;\n\n\tlockdep_assert_held(&htt->tx_lock);\n\n\tif (!is_mgmt || !ar->hw_params.max_probe_resp_desc_thres)\n\t\treturn 0;\n\n\tif (is_presp &&\n\t    ar->hw_params.max_probe_resp_desc_thres < htt->num_pending_mgmt_tx)\n\t\treturn -EBUSY;\n\n\thtt->num_pending_mgmt_tx++;\n\n\treturn 0;\n}\n\nvoid ath10k_htt_tx_mgmt_dec_pending(struct ath10k_htt *htt)\n{\n\tlockdep_assert_held(&htt->tx_lock);\n\n\tif (!htt->ar->hw_params.max_probe_resp_desc_thres)\n\t\treturn;\n\n\thtt->num_pending_mgmt_tx--;\n}\n\nint ath10k_htt_tx_alloc_msdu_id(struct ath10k_htt *htt, struct sk_buff *skb)\n{\n\tstruct ath10k *ar = htt->ar;\n\tint ret;\n\n\tspin_lock_bh(&htt->tx_lock);\n\tret = idr_alloc(&htt->pending_tx, skb, 0,\n\t\t\thtt->max_num_pending_tx, GFP_ATOMIC);\n\tspin_unlock_bh(&htt->tx_lock);\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt tx alloc msdu_id %d\\n\", ret);\n\n\treturn ret;\n}\n\nvoid ath10k_htt_tx_free_msdu_id(struct ath10k_htt *htt, u16 msdu_id)\n{\n\tstruct ath10k *ar = htt->ar;\n\n\tlockdep_assert_held(&htt->tx_lock);\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt tx free msdu_id %u\\n\", msdu_id);\n\n\tidr_remove(&htt->pending_tx, msdu_id);\n}\n\nstatic void ath10k_htt_tx_free_cont_txbuf_32(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\n\tif (!htt->txbuf.vaddr_txbuff_32)\n\t\treturn;\n\n\tsize = htt->txbuf.size;\n\tdma_free_coherent(ar->dev, size, htt->txbuf.vaddr_txbuff_32,\n\t\t\t  htt->txbuf.paddr);\n\thtt->txbuf.vaddr_txbuff_32 = NULL;\n}\n\nstatic int ath10k_htt_tx_alloc_cont_txbuf_32(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\n\tsize = htt->max_num_pending_tx *\n\t\t\tsizeof(struct ath10k_htt_txbuf_32);\n\n\thtt->txbuf.vaddr_txbuff_32 = dma_alloc_coherent(ar->dev, size,\n\t\t\t\t\t\t\t&htt->txbuf.paddr,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\tif (!htt->txbuf.vaddr_txbuff_32)\n\t\treturn -ENOMEM;\n\n\thtt->txbuf.size = size;\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_tx_free_cont_txbuf_64(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\n\tif (!htt->txbuf.vaddr_txbuff_64)\n\t\treturn;\n\n\tsize = htt->txbuf.size;\n\tdma_free_coherent(ar->dev, size, htt->txbuf.vaddr_txbuff_64,\n\t\t\t  htt->txbuf.paddr);\n\thtt->txbuf.vaddr_txbuff_64 = NULL;\n}\n\nstatic int ath10k_htt_tx_alloc_cont_txbuf_64(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\n\tsize = htt->max_num_pending_tx *\n\t\t\tsizeof(struct ath10k_htt_txbuf_64);\n\n\thtt->txbuf.vaddr_txbuff_64 = dma_alloc_coherent(ar->dev, size,\n\t\t\t\t\t\t\t&htt->txbuf.paddr,\n\t\t\t\t\t\t\tGFP_KERNEL);\n\tif (!htt->txbuf.vaddr_txbuff_64)\n\t\treturn -ENOMEM;\n\n\thtt->txbuf.size = size;\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_tx_free_cont_frag_desc_32(struct ath10k_htt *htt)\n{\n\tsize_t size;\n\n\tif (!htt->frag_desc.vaddr_desc_32)\n\t\treturn;\n\n\tsize = htt->max_num_pending_tx *\n\t\t\tsizeof(struct htt_msdu_ext_desc);\n\n\tdma_free_coherent(htt->ar->dev,\n\t\t\t  size,\n\t\t\t  htt->frag_desc.vaddr_desc_32,\n\t\t\t  htt->frag_desc.paddr);\n\n\thtt->frag_desc.vaddr_desc_32 = NULL;\n}\n\nstatic int ath10k_htt_tx_alloc_cont_frag_desc_32(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\n\tif (!ar->hw_params.continuous_frag_desc)\n\t\treturn 0;\n\n\tsize = htt->max_num_pending_tx *\n\t\t\tsizeof(struct htt_msdu_ext_desc);\n\thtt->frag_desc.vaddr_desc_32 = dma_alloc_coherent(ar->dev, size,\n\t\t\t\t\t\t\t  &htt->frag_desc.paddr,\n\t\t\t\t\t\t\t  GFP_KERNEL);\n\tif (!htt->frag_desc.vaddr_desc_32) {\n\t\tath10k_err(ar, \"failed to alloc fragment desc memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\thtt->frag_desc.size = size;\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_tx_free_cont_frag_desc_64(struct ath10k_htt *htt)\n{\n\tsize_t size;\n\n\tif (!htt->frag_desc.vaddr_desc_64)\n\t\treturn;\n\n\tsize = htt->max_num_pending_tx *\n\t\t\tsizeof(struct htt_msdu_ext_desc_64);\n\n\tdma_free_coherent(htt->ar->dev,\n\t\t\t  size,\n\t\t\t  htt->frag_desc.vaddr_desc_64,\n\t\t\t  htt->frag_desc.paddr);\n\n\thtt->frag_desc.vaddr_desc_64 = NULL;\n}\n\nstatic int ath10k_htt_tx_alloc_cont_frag_desc_64(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\n\tif (!ar->hw_params.continuous_frag_desc)\n\t\treturn 0;\n\n\tsize = htt->max_num_pending_tx *\n\t\t\tsizeof(struct htt_msdu_ext_desc_64);\n\n\thtt->frag_desc.vaddr_desc_64 = dma_alloc_coherent(ar->dev, size,\n\t\t\t\t\t\t\t  &htt->frag_desc.paddr,\n\t\t\t\t\t\t\t  GFP_KERNEL);\n\tif (!htt->frag_desc.vaddr_desc_64) {\n\t\tath10k_err(ar, \"failed to alloc fragment desc memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\thtt->frag_desc.size = size;\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_tx_free_txq(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\n\tif (!test_bit(ATH10K_FW_FEATURE_PEER_FLOW_CONTROL,\n\t\t      ar->running_fw->fw_file.fw_features))\n\t\treturn;\n\n\tsize = sizeof(*htt->tx_q_state.vaddr);\n\n\tdma_unmap_single(ar->dev, htt->tx_q_state.paddr, size, DMA_TO_DEVICE);\n\tkfree(htt->tx_q_state.vaddr);\n}\n\nstatic int ath10k_htt_tx_alloc_txq(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tsize_t size;\n\tint ret;\n\n\tif (!test_bit(ATH10K_FW_FEATURE_PEER_FLOW_CONTROL,\n\t\t      ar->running_fw->fw_file.fw_features))\n\t\treturn 0;\n\n\thtt->tx_q_state.num_peers = HTT_TX_Q_STATE_NUM_PEERS;\n\thtt->tx_q_state.num_tids = HTT_TX_Q_STATE_NUM_TIDS;\n\thtt->tx_q_state.type = HTT_Q_DEPTH_TYPE_BYTES;\n\n\tsize = sizeof(*htt->tx_q_state.vaddr);\n\thtt->tx_q_state.vaddr = kzalloc(size, GFP_KERNEL);\n\tif (!htt->tx_q_state.vaddr)\n\t\treturn -ENOMEM;\n\n\thtt->tx_q_state.paddr = dma_map_single(ar->dev, htt->tx_q_state.vaddr,\n\t\t\t\t\t       size, DMA_TO_DEVICE);\n\tret = dma_mapping_error(ar->dev, htt->tx_q_state.paddr);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to dma map tx_q_state: %d\\n\", ret);\n\t\tkfree(htt->tx_q_state.vaddr);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_tx_free_txdone_fifo(struct ath10k_htt *htt)\n{\n\tWARN_ON(!kfifo_is_empty(&htt->txdone_fifo));\n\tkfifo_free(&htt->txdone_fifo);\n}\n\nstatic int ath10k_htt_tx_alloc_txdone_fifo(struct ath10k_htt *htt)\n{\n\tint ret;\n\tsize_t size;\n\n\tsize = roundup_pow_of_two(htt->max_num_pending_tx);\n\tret = kfifo_alloc(&htt->txdone_fifo, size, GFP_KERNEL);\n\treturn ret;\n}\n\nstatic int ath10k_htt_tx_alloc_buf(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tint ret;\n\n\tret = ath10k_htt_alloc_txbuff(htt);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to alloc cont tx buffer: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_htt_alloc_frag_desc(htt);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to alloc cont frag desc: %d\\n\", ret);\n\t\tgoto free_txbuf;\n\t}\n\n\tret = ath10k_htt_tx_alloc_txq(htt);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to alloc txq: %d\\n\", ret);\n\t\tgoto free_frag_desc;\n\t}\n\n\tret = ath10k_htt_tx_alloc_txdone_fifo(htt);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to alloc txdone fifo: %d\\n\", ret);\n\t\tgoto free_txq;\n\t}\n\n\treturn 0;\n\nfree_txq:\n\tath10k_htt_tx_free_txq(htt);\n\nfree_frag_desc:\n\tath10k_htt_free_frag_desc(htt);\n\nfree_txbuf:\n\tath10k_htt_free_txbuff(htt);\n\n\treturn ret;\n}\n\nint ath10k_htt_tx_start(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tint ret;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"htt tx max num pending tx %d\\n\",\n\t\t   htt->max_num_pending_tx);\n\n\tspin_lock_init(&htt->tx_lock);\n\tidr_init(&htt->pending_tx);\n\n\tif (htt->tx_mem_allocated)\n\t\treturn 0;\n\n\tif (ar->bus_param.dev_type == ATH10K_DEV_TYPE_HL)\n\t\treturn 0;\n\n\tret = ath10k_htt_tx_alloc_buf(htt);\n\tif (ret)\n\t\tgoto free_idr_pending_tx;\n\n\thtt->tx_mem_allocated = true;\n\n\treturn 0;\n\nfree_idr_pending_tx:\n\tidr_destroy(&htt->pending_tx);\n\n\treturn ret;\n}\n\nstatic int ath10k_htt_tx_clean_up_pending(int msdu_id, void *skb, void *ctx)\n{\n\tstruct ath10k *ar = ctx;\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct htt_tx_done tx_done = {0};\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"force cleanup msdu_id %u\\n\", msdu_id);\n\n\ttx_done.msdu_id = msdu_id;\n\ttx_done.status = HTT_TX_COMPL_STATE_DISCARD;\n\n\tath10k_txrx_tx_unref(htt, &tx_done);\n\n\treturn 0;\n}\n\nvoid ath10k_htt_tx_destroy(struct ath10k_htt *htt)\n{\n\tif (!htt->tx_mem_allocated)\n\t\treturn;\n\n\tath10k_htt_free_txbuff(htt);\n\tath10k_htt_tx_free_txq(htt);\n\tath10k_htt_free_frag_desc(htt);\n\tath10k_htt_tx_free_txdone_fifo(htt);\n\thtt->tx_mem_allocated = false;\n}\n\nstatic void ath10k_htt_flush_tx_queue(struct ath10k_htt *htt)\n{\n\tath10k_htc_stop_hl(htt->ar);\n\tidr_for_each(&htt->pending_tx, ath10k_htt_tx_clean_up_pending, htt->ar);\n}\n\nvoid ath10k_htt_tx_stop(struct ath10k_htt *htt)\n{\n\tath10k_htt_flush_tx_queue(htt);\n\tidr_destroy(&htt->pending_tx);\n}\n\nvoid ath10k_htt_tx_free(struct ath10k_htt *htt)\n{\n\tath10k_htt_tx_stop(htt);\n\tath10k_htt_tx_destroy(htt);\n}\n\nvoid ath10k_htt_op_ep_tx_credits(struct ath10k *ar)\n{\n\tqueue_work(ar->workqueue, &ar->bundle_tx_work);\n}\n\nvoid ath10k_htt_htc_tx_complete(struct ath10k *ar, struct sk_buff *skb)\n{\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct htt_tx_done tx_done = {0};\n\tstruct htt_cmd_hdr *htt_hdr;\n\tstruct htt_data_tx_desc *desc_hdr = NULL;\n\tu16 flags1 = 0;\n\tu8 msg_type = 0;\n\n\tif (htt->disable_tx_comp) {\n\t\thtt_hdr = (struct htt_cmd_hdr *)skb->data;\n\t\tmsg_type = htt_hdr->msg_type;\n\n\t\tif (msg_type == HTT_H2T_MSG_TYPE_TX_FRM) {\n\t\t\tdesc_hdr = (struct htt_data_tx_desc *)\n\t\t\t\t(skb->data + sizeof(*htt_hdr));\n\t\t\tflags1 = __le16_to_cpu(desc_hdr->flags1);\n\t\t\tskb_pull(skb, sizeof(struct htt_cmd_hdr));\n\t\t\tskb_pull(skb, sizeof(struct htt_data_tx_desc));\n\t\t}\n\t}\n\n\tdev_kfree_skb_any(skb);\n\n\tif ((!htt->disable_tx_comp) || (msg_type != HTT_H2T_MSG_TYPE_TX_FRM))\n\t\treturn;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt tx complete msdu id:%u ,flags1:%x\\n\",\n\t\t   __le16_to_cpu(desc_hdr->id), flags1);\n\n\tif (flags1 & HTT_DATA_TX_DESC_FLAGS1_TX_COMPLETE)\n\t\treturn;\n\n\ttx_done.status = HTT_TX_COMPL_STATE_ACK;\n\ttx_done.msdu_id = __le16_to_cpu(desc_hdr->id);\n\tath10k_txrx_tx_unref(&ar->htt, &tx_done);\n}\n\nvoid ath10k_htt_hif_tx_complete(struct ath10k *ar, struct sk_buff *skb)\n{\n\tdev_kfree_skb_any(skb);\n}\nEXPORT_SYMBOL(ath10k_htt_hif_tx_complete);\n\nint ath10k_htt_h2t_ver_req_msg(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tint len = 0;\n\tint ret;\n\n\tlen += sizeof(cmd->hdr);\n\tlen += sizeof(cmd->ver_req);\n\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\tcmd = (struct htt_cmd *)skb->data;\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_VERSION_REQ;\n\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint ath10k_htt_h2t_stats_req(struct ath10k_htt *htt, u32 mask, u32 reset_mask,\n\t\t\t     u64 cookie)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct htt_stats_req *req;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tint len = 0, ret;\n\n\tlen += sizeof(cmd->hdr);\n\tlen += sizeof(cmd->stats_req);\n\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\tcmd = (struct htt_cmd *)skb->data;\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_STATS_REQ;\n\n\treq = &cmd->stats_req;\n\n\tmemset(req, 0, sizeof(*req));\n\n\t \n\tmemcpy(req->upload_types, &mask, 3);\n\tmemcpy(req->reset_types, &reset_mask, 3);\n\treq->stat_type = HTT_STATS_REQ_CFG_STAT_TYPE_INVALID;\n\treq->cookie_lsb = cpu_to_le32(cookie & 0xffffffff);\n\treq->cookie_msb = cpu_to_le32((cookie & 0xffffffff00000000ULL) >> 32);\n\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to send htt type stats request: %d\",\n\t\t\t    ret);\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_htt_send_frag_desc_bank_cfg_32(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tstruct htt_frag_desc_bank_cfg32 *cfg;\n\tint ret, size;\n\tu8 info;\n\n\tif (!ar->hw_params.continuous_frag_desc)\n\t\treturn 0;\n\n\tif (!htt->frag_desc.paddr) {\n\t\tath10k_warn(ar, \"invalid frag desc memory\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tsize = sizeof(cmd->hdr) + sizeof(cmd->frag_desc_bank_cfg32);\n\tskb = ath10k_htc_alloc_skb(ar, size);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, size);\n\tcmd = (struct htt_cmd *)skb->data;\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_FRAG_DESC_BANK_CFG;\n\n\tinfo = 0;\n\tinfo |= SM(htt->tx_q_state.type,\n\t\t   HTT_FRAG_DESC_BANK_CFG_INFO_Q_STATE_DEPTH_TYPE);\n\n\tif (test_bit(ATH10K_FW_FEATURE_PEER_FLOW_CONTROL,\n\t\t     ar->running_fw->fw_file.fw_features))\n\t\tinfo |= HTT_FRAG_DESC_BANK_CFG_INFO_Q_STATE_VALID;\n\n\tcfg = &cmd->frag_desc_bank_cfg32;\n\tcfg->info = info;\n\tcfg->num_banks = 1;\n\tcfg->desc_size = sizeof(struct htt_msdu_ext_desc);\n\tcfg->bank_base_addrs[0] = __cpu_to_le32(htt->frag_desc.paddr);\n\tcfg->bank_id[0].bank_min_id = 0;\n\tcfg->bank_id[0].bank_max_id = __cpu_to_le16(htt->max_num_pending_tx -\n\t\t\t\t\t\t    1);\n\n\tcfg->q_state.paddr = cpu_to_le32(htt->tx_q_state.paddr);\n\tcfg->q_state.num_peers = cpu_to_le16(htt->tx_q_state.num_peers);\n\tcfg->q_state.num_tids = cpu_to_le16(htt->tx_q_state.num_tids);\n\tcfg->q_state.record_size = HTT_TX_Q_STATE_ENTRY_SIZE;\n\tcfg->q_state.record_multiplier = HTT_TX_Q_STATE_ENTRY_MULTIPLIER;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt frag desc bank cmd\\n\");\n\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to send frag desc bank cfg request: %d\\n\",\n\t\t\t    ret);\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_htt_send_frag_desc_bank_cfg_64(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tstruct htt_frag_desc_bank_cfg64 *cfg;\n\tint ret, size;\n\tu8 info;\n\n\tif (!ar->hw_params.continuous_frag_desc)\n\t\treturn 0;\n\n\tif (!htt->frag_desc.paddr) {\n\t\tath10k_warn(ar, \"invalid frag desc memory\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tsize = sizeof(cmd->hdr) + sizeof(cmd->frag_desc_bank_cfg64);\n\tskb = ath10k_htc_alloc_skb(ar, size);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, size);\n\tcmd = (struct htt_cmd *)skb->data;\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_FRAG_DESC_BANK_CFG;\n\n\tinfo = 0;\n\tinfo |= SM(htt->tx_q_state.type,\n\t\t   HTT_FRAG_DESC_BANK_CFG_INFO_Q_STATE_DEPTH_TYPE);\n\n\tif (test_bit(ATH10K_FW_FEATURE_PEER_FLOW_CONTROL,\n\t\t     ar->running_fw->fw_file.fw_features))\n\t\tinfo |= HTT_FRAG_DESC_BANK_CFG_INFO_Q_STATE_VALID;\n\n\tcfg = &cmd->frag_desc_bank_cfg64;\n\tcfg->info = info;\n\tcfg->num_banks = 1;\n\tcfg->desc_size = sizeof(struct htt_msdu_ext_desc_64);\n\tcfg->bank_base_addrs[0] =  __cpu_to_le64(htt->frag_desc.paddr);\n\tcfg->bank_id[0].bank_min_id = 0;\n\tcfg->bank_id[0].bank_max_id = __cpu_to_le16(htt->max_num_pending_tx -\n\t\t\t\t\t\t    1);\n\n\tcfg->q_state.paddr = cpu_to_le32(htt->tx_q_state.paddr);\n\tcfg->q_state.num_peers = cpu_to_le16(htt->tx_q_state.num_peers);\n\tcfg->q_state.num_tids = cpu_to_le16(htt->tx_q_state.num_tids);\n\tcfg->q_state.record_size = HTT_TX_Q_STATE_ENTRY_SIZE;\n\tcfg->q_state.record_multiplier = HTT_TX_Q_STATE_ENTRY_MULTIPLIER;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt frag desc bank cmd\\n\");\n\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to send frag desc bank cfg request: %d\\n\",\n\t\t\t    ret);\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_fill_rx_desc_offset_32(struct ath10k_hw_params *hw, void *rx_ring)\n{\n\tstruct htt_rx_ring_setup_ring32 *ring =\n\t\t\t(struct htt_rx_ring_setup_ring32 *)rx_ring;\n\n\tath10k_htt_rx_desc_get_offsets(hw, &ring->offsets);\n}\n\nstatic void ath10k_htt_fill_rx_desc_offset_64(struct ath10k_hw_params *hw, void *rx_ring)\n{\n\tstruct htt_rx_ring_setup_ring64 *ring =\n\t\t\t(struct htt_rx_ring_setup_ring64 *)rx_ring;\n\n\tath10k_htt_rx_desc_get_offsets(hw, &ring->offsets);\n}\n\nstatic int ath10k_htt_send_rx_ring_cfg_32(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tstruct htt_rx_ring_setup_ring32 *ring;\n\tconst int num_rx_ring = 1;\n\tu16 flags;\n\tu32 fw_idx;\n\tint len;\n\tint ret;\n\n\t \n\tBUILD_BUG_ON(!IS_ALIGNED(HTT_RX_BUF_SIZE, 4));\n\tBUILD_BUG_ON((HTT_RX_BUF_SIZE & HTT_MAX_CACHE_LINE_SIZE_MASK) != 0);\n\n\tlen = sizeof(cmd->hdr) + sizeof(cmd->rx_setup_32.hdr)\n\t    + (sizeof(*ring) * num_rx_ring);\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\n\tcmd = (struct htt_cmd *)skb->data;\n\tring = &cmd->rx_setup_32.rings[0];\n\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_RX_RING_CFG;\n\tcmd->rx_setup_32.hdr.num_rings = 1;\n\n\t \n\tflags = 0;\n\tflags |= HTT_RX_RING_FLAGS_MAC80211_HDR;\n\tflags |= HTT_RX_RING_FLAGS_MSDU_PAYLOAD;\n\tflags |= HTT_RX_RING_FLAGS_PPDU_START;\n\tflags |= HTT_RX_RING_FLAGS_PPDU_END;\n\tflags |= HTT_RX_RING_FLAGS_MPDU_START;\n\tflags |= HTT_RX_RING_FLAGS_MPDU_END;\n\tflags |= HTT_RX_RING_FLAGS_MSDU_START;\n\tflags |= HTT_RX_RING_FLAGS_MSDU_END;\n\tflags |= HTT_RX_RING_FLAGS_RX_ATTENTION;\n\tflags |= HTT_RX_RING_FLAGS_FRAG_INFO;\n\tflags |= HTT_RX_RING_FLAGS_UNICAST_RX;\n\tflags |= HTT_RX_RING_FLAGS_MULTICAST_RX;\n\tflags |= HTT_RX_RING_FLAGS_CTRL_RX;\n\tflags |= HTT_RX_RING_FLAGS_MGMT_RX;\n\tflags |= HTT_RX_RING_FLAGS_NULL_RX;\n\tflags |= HTT_RX_RING_FLAGS_PHY_DATA_RX;\n\n\tfw_idx = __le32_to_cpu(*htt->rx_ring.alloc_idx.vaddr);\n\n\tring->fw_idx_shadow_reg_paddr =\n\t\t__cpu_to_le32(htt->rx_ring.alloc_idx.paddr);\n\tring->rx_ring_base_paddr = __cpu_to_le32(htt->rx_ring.base_paddr);\n\tring->rx_ring_len = __cpu_to_le16(htt->rx_ring.size);\n\tring->rx_ring_bufsize = __cpu_to_le16(HTT_RX_BUF_SIZE);\n\tring->flags = __cpu_to_le16(flags);\n\tring->fw_idx_init_val = __cpu_to_le16(fw_idx);\n\n\tath10k_htt_fill_rx_desc_offset_32(hw, ring);\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_htt_send_rx_ring_cfg_64(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tstruct htt_rx_ring_setup_ring64 *ring;\n\tconst int num_rx_ring = 1;\n\tu16 flags;\n\tu32 fw_idx;\n\tint len;\n\tint ret;\n\n\t \n\tBUILD_BUG_ON(!IS_ALIGNED(HTT_RX_BUF_SIZE, 4));\n\tBUILD_BUG_ON((HTT_RX_BUF_SIZE & HTT_MAX_CACHE_LINE_SIZE_MASK) != 0);\n\n\tlen = sizeof(cmd->hdr) + sizeof(cmd->rx_setup_64.hdr)\n\t    + (sizeof(*ring) * num_rx_ring);\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\n\tcmd = (struct htt_cmd *)skb->data;\n\tring = &cmd->rx_setup_64.rings[0];\n\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_RX_RING_CFG;\n\tcmd->rx_setup_64.hdr.num_rings = 1;\n\n\tflags = 0;\n\tflags |= HTT_RX_RING_FLAGS_MAC80211_HDR;\n\tflags |= HTT_RX_RING_FLAGS_MSDU_PAYLOAD;\n\tflags |= HTT_RX_RING_FLAGS_PPDU_START;\n\tflags |= HTT_RX_RING_FLAGS_PPDU_END;\n\tflags |= HTT_RX_RING_FLAGS_MPDU_START;\n\tflags |= HTT_RX_RING_FLAGS_MPDU_END;\n\tflags |= HTT_RX_RING_FLAGS_MSDU_START;\n\tflags |= HTT_RX_RING_FLAGS_MSDU_END;\n\tflags |= HTT_RX_RING_FLAGS_RX_ATTENTION;\n\tflags |= HTT_RX_RING_FLAGS_FRAG_INFO;\n\tflags |= HTT_RX_RING_FLAGS_UNICAST_RX;\n\tflags |= HTT_RX_RING_FLAGS_MULTICAST_RX;\n\tflags |= HTT_RX_RING_FLAGS_CTRL_RX;\n\tflags |= HTT_RX_RING_FLAGS_MGMT_RX;\n\tflags |= HTT_RX_RING_FLAGS_NULL_RX;\n\tflags |= HTT_RX_RING_FLAGS_PHY_DATA_RX;\n\n\tfw_idx = __le32_to_cpu(*htt->rx_ring.alloc_idx.vaddr);\n\n\tring->fw_idx_shadow_reg_paddr = __cpu_to_le64(htt->rx_ring.alloc_idx.paddr);\n\tring->rx_ring_base_paddr = __cpu_to_le64(htt->rx_ring.base_paddr);\n\tring->rx_ring_len = __cpu_to_le16(htt->rx_ring.size);\n\tring->rx_ring_bufsize = __cpu_to_le16(HTT_RX_BUF_SIZE);\n\tring->flags = __cpu_to_le16(flags);\n\tring->fw_idx_init_val = __cpu_to_le16(fw_idx);\n\n\tath10k_htt_fill_rx_desc_offset_64(hw, ring);\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_htt_send_rx_ring_cfg_hl(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tstruct htt_rx_ring_setup_ring32 *ring;\n\tconst int num_rx_ring = 1;\n\tu16 flags;\n\tint len;\n\tint ret;\n\n\t \n\tBUILD_BUG_ON(!IS_ALIGNED(HTT_RX_BUF_SIZE, 4));\n\tBUILD_BUG_ON((HTT_RX_BUF_SIZE & HTT_MAX_CACHE_LINE_SIZE_MASK) != 0);\n\n\tlen = sizeof(cmd->hdr) + sizeof(cmd->rx_setup_32.hdr)\n\t    + (sizeof(*ring) * num_rx_ring);\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\n\tcmd = (struct htt_cmd *)skb->data;\n\tring = &cmd->rx_setup_32.rings[0];\n\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_RX_RING_CFG;\n\tcmd->rx_setup_32.hdr.num_rings = 1;\n\n\tflags = 0;\n\tflags |= HTT_RX_RING_FLAGS_MSDU_PAYLOAD;\n\tflags |= HTT_RX_RING_FLAGS_UNICAST_RX;\n\tflags |= HTT_RX_RING_FLAGS_MULTICAST_RX;\n\n\tmemset(ring, 0, sizeof(*ring));\n\tring->rx_ring_len = __cpu_to_le16(HTT_RX_RING_SIZE_MIN);\n\tring->rx_ring_bufsize = __cpu_to_le16(HTT_RX_BUF_SIZE);\n\tring->flags = __cpu_to_le16(flags);\n\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_htt_h2t_aggr_cfg_msg_32(struct ath10k_htt *htt,\n\t\t\t\t\t  u8 max_subfrms_ampdu,\n\t\t\t\t\t  u8 max_subfrms_amsdu)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct htt_aggr_conf *aggr_conf;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tint len;\n\tint ret;\n\n\t \n\n\tif (max_subfrms_ampdu == 0 || max_subfrms_ampdu > 64)\n\t\treturn -EINVAL;\n\n\tif (max_subfrms_amsdu == 0 || max_subfrms_amsdu > 31)\n\t\treturn -EINVAL;\n\n\tlen = sizeof(cmd->hdr);\n\tlen += sizeof(cmd->aggr_conf);\n\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\tcmd = (struct htt_cmd *)skb->data;\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_AGGR_CFG;\n\n\taggr_conf = &cmd->aggr_conf;\n\taggr_conf->max_num_ampdu_subframes = max_subfrms_ampdu;\n\taggr_conf->max_num_amsdu_subframes = max_subfrms_amsdu;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt h2t aggr cfg msg amsdu %d ampdu %d\",\n\t\t   aggr_conf->max_num_amsdu_subframes,\n\t\t   aggr_conf->max_num_ampdu_subframes);\n\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_htt_h2t_aggr_cfg_msg_v2(struct ath10k_htt *htt,\n\t\t\t\t\t  u8 max_subfrms_ampdu,\n\t\t\t\t\t  u8 max_subfrms_amsdu)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct htt_aggr_conf_v2 *aggr_conf;\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tint len;\n\tint ret;\n\n\t \n\n\tif (max_subfrms_ampdu == 0 || max_subfrms_ampdu > 64)\n\t\treturn -EINVAL;\n\n\tif (max_subfrms_amsdu == 0 || max_subfrms_amsdu > 31)\n\t\treturn -EINVAL;\n\n\tlen = sizeof(cmd->hdr);\n\tlen += sizeof(cmd->aggr_conf_v2);\n\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\tcmd = (struct htt_cmd *)skb->data;\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_AGGR_CFG;\n\n\taggr_conf = &cmd->aggr_conf_v2;\n\taggr_conf->max_num_ampdu_subframes = max_subfrms_ampdu;\n\taggr_conf->max_num_amsdu_subframes = max_subfrms_amsdu;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt h2t aggr cfg msg amsdu %d ampdu %d\",\n\t\t   aggr_conf->max_num_amsdu_subframes,\n\t\t   aggr_conf->max_num_ampdu_subframes);\n\n\tret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\n\tif (ret) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint ath10k_htt_tx_fetch_resp(struct ath10k *ar,\n\t\t\t     __le32 token,\n\t\t\t     __le16 fetch_seq_num,\n\t\t\t     struct htt_tx_fetch_record *records,\n\t\t\t     size_t num_records)\n{\n\tstruct sk_buff *skb;\n\tstruct htt_cmd *cmd;\n\tconst u16 resp_id = 0;\n\tint len = 0;\n\tint ret;\n\n\t \n\n\tlen += sizeof(cmd->hdr);\n\tlen += sizeof(cmd->tx_fetch_resp);\n\tlen += sizeof(cmd->tx_fetch_resp.records[0]) * num_records;\n\n\tskb = ath10k_htc_alloc_skb(ar, len);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tskb_put(skb, len);\n\tcmd = (struct htt_cmd *)skb->data;\n\tcmd->hdr.msg_type = HTT_H2T_MSG_TYPE_TX_FETCH_RESP;\n\tcmd->tx_fetch_resp.resp_id = cpu_to_le16(resp_id);\n\tcmd->tx_fetch_resp.fetch_seq_num = fetch_seq_num;\n\tcmd->tx_fetch_resp.num_records = cpu_to_le16(num_records);\n\tcmd->tx_fetch_resp.token = token;\n\n\tmemcpy(cmd->tx_fetch_resp.records, records,\n\t       sizeof(records[0]) * num_records);\n\n\tret = ath10k_htc_send(&ar->htc, ar->htt.eid, skb);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to submit htc command: %d\\n\", ret);\n\t\tgoto err_free_skb;\n\t}\n\n\treturn 0;\n\nerr_free_skb:\n\tdev_kfree_skb_any(skb);\n\n\treturn ret;\n}\n\nstatic u8 ath10k_htt_tx_get_vdev_id(struct ath10k *ar, struct sk_buff *skb)\n{\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct ath10k_skb_cb *cb = ATH10K_SKB_CB(skb);\n\tstruct ath10k_vif *arvif;\n\n\tif (info->flags & IEEE80211_TX_CTL_TX_OFFCHAN) {\n\t\treturn ar->scan.vdev_id;\n\t} else if (cb->vif) {\n\t\tarvif = (void *)cb->vif->drv_priv;\n\t\treturn arvif->vdev_id;\n\t} else if (ar->monitor_started) {\n\t\treturn ar->monitor_vdev_id;\n\t} else {\n\t\treturn 0;\n\t}\n}\n\nstatic u8 ath10k_htt_tx_get_tid(struct sk_buff *skb, bool is_eth)\n{\n\tstruct ieee80211_hdr *hdr = (void *)skb->data;\n\tstruct ath10k_skb_cb *cb = ATH10K_SKB_CB(skb);\n\n\tif (!is_eth && ieee80211_is_mgmt(hdr->frame_control))\n\t\treturn HTT_DATA_TX_EXT_TID_MGMT;\n\telse if (cb->flags & ATH10K_SKB_F_QOS)\n\t\treturn skb->priority & IEEE80211_QOS_CTL_TID_MASK;\n\telse\n\t\treturn HTT_DATA_TX_EXT_TID_NON_QOS_MCAST_BCAST;\n}\n\nint ath10k_htt_mgmt_tx(struct ath10k_htt *htt, struct sk_buff *msdu)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct device *dev = ar->dev;\n\tstruct sk_buff *txdesc = NULL;\n\tstruct htt_cmd *cmd;\n\tstruct ath10k_skb_cb *skb_cb = ATH10K_SKB_CB(msdu);\n\tu8 vdev_id = ath10k_htt_tx_get_vdev_id(ar, msdu);\n\tint len = 0;\n\tint msdu_id = -1;\n\tint res;\n\tconst u8 *peer_addr;\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)msdu->data;\n\n\tlen += sizeof(cmd->hdr);\n\tlen += sizeof(cmd->mgmt_tx);\n\n\tres = ath10k_htt_tx_alloc_msdu_id(htt, msdu);\n\tif (res < 0)\n\t\tgoto err;\n\n\tmsdu_id = res;\n\n\tif ((ieee80211_is_action(hdr->frame_control) ||\n\t     ieee80211_is_deauth(hdr->frame_control) ||\n\t     ieee80211_is_disassoc(hdr->frame_control)) &&\n\t     ieee80211_has_protected(hdr->frame_control)) {\n\t\tpeer_addr = hdr->addr1;\n\t\tif (is_multicast_ether_addr(peer_addr)) {\n\t\t\tskb_put(msdu, sizeof(struct ieee80211_mmie_16));\n\t\t} else {\n\t\t\tif (skb_cb->ucast_cipher == WLAN_CIPHER_SUITE_GCMP ||\n\t\t\t    skb_cb->ucast_cipher == WLAN_CIPHER_SUITE_GCMP_256)\n\t\t\t\tskb_put(msdu, IEEE80211_GCMP_MIC_LEN);\n\t\t\telse\n\t\t\t\tskb_put(msdu, IEEE80211_CCMP_MIC_LEN);\n\t\t}\n\t}\n\n\ttxdesc = ath10k_htc_alloc_skb(ar, len);\n\tif (!txdesc) {\n\t\tres = -ENOMEM;\n\t\tgoto err_free_msdu_id;\n\t}\n\n\tskb_cb->paddr = dma_map_single(dev, msdu->data, msdu->len,\n\t\t\t\t       DMA_TO_DEVICE);\n\tres = dma_mapping_error(dev, skb_cb->paddr);\n\tif (res) {\n\t\tres = -EIO;\n\t\tgoto err_free_txdesc;\n\t}\n\n\tskb_put(txdesc, len);\n\tcmd = (struct htt_cmd *)txdesc->data;\n\tmemset(cmd, 0, len);\n\n\tcmd->hdr.msg_type         = HTT_H2T_MSG_TYPE_MGMT_TX;\n\tcmd->mgmt_tx.msdu_paddr = __cpu_to_le32(ATH10K_SKB_CB(msdu)->paddr);\n\tcmd->mgmt_tx.len        = __cpu_to_le32(msdu->len);\n\tcmd->mgmt_tx.desc_id    = __cpu_to_le32(msdu_id);\n\tcmd->mgmt_tx.vdev_id    = __cpu_to_le32(vdev_id);\n\tmemcpy(cmd->mgmt_tx.hdr, msdu->data,\n\t       min_t(int, msdu->len, HTT_MGMT_FRM_HDR_DOWNLOAD_LEN));\n\n\tres = ath10k_htc_send(&htt->ar->htc, htt->eid, txdesc);\n\tif (res)\n\t\tgoto err_unmap_msdu;\n\n\treturn 0;\n\nerr_unmap_msdu:\n\tif (ar->bus_param.dev_type != ATH10K_DEV_TYPE_HL)\n\t\tdma_unmap_single(dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);\nerr_free_txdesc:\n\tdev_kfree_skb_any(txdesc);\nerr_free_msdu_id:\n\tspin_lock_bh(&htt->tx_lock);\n\tath10k_htt_tx_free_msdu_id(htt, msdu_id);\n\tspin_unlock_bh(&htt->tx_lock);\nerr:\n\treturn res;\n}\n\n#define HTT_TX_HL_NEEDED_HEADROOM \\\n\t(unsigned int)(sizeof(struct htt_cmd_hdr) + \\\n\tsizeof(struct htt_data_tx_desc) + \\\n\tsizeof(struct ath10k_htc_hdr))\n\nstatic int ath10k_htt_tx_hl(struct ath10k_htt *htt, enum ath10k_hw_txrx_mode txmode,\n\t\t\t    struct sk_buff *msdu)\n{\n\tstruct ath10k *ar = htt->ar;\n\tint res, data_len;\n\tstruct htt_cmd_hdr *cmd_hdr;\n\tstruct htt_data_tx_desc *tx_desc;\n\tstruct ath10k_skb_cb *skb_cb = ATH10K_SKB_CB(msdu);\n\tstruct sk_buff *tmp_skb;\n\tbool is_eth = (txmode == ATH10K_HW_TXRX_ETHERNET);\n\tu8 vdev_id = ath10k_htt_tx_get_vdev_id(ar, msdu);\n\tu8 tid = ath10k_htt_tx_get_tid(msdu, is_eth);\n\tu8 flags0 = 0;\n\tu16 flags1 = 0;\n\tu16 msdu_id = 0;\n\n\tif (!is_eth) {\n\t\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)msdu->data;\n\n\t\tif ((ieee80211_is_action(hdr->frame_control) ||\n\t\t     ieee80211_is_deauth(hdr->frame_control) ||\n\t\t     ieee80211_is_disassoc(hdr->frame_control)) &&\n\t\t     ieee80211_has_protected(hdr->frame_control)) {\n\t\t\tskb_put(msdu, IEEE80211_CCMP_MIC_LEN);\n\t\t}\n\t}\n\n\tdata_len = msdu->len;\n\n\tswitch (txmode) {\n\tcase ATH10K_HW_TXRX_RAW:\n\tcase ATH10K_HW_TXRX_NATIVE_WIFI:\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_MAC_HDR_PRESENT;\n\t\tfallthrough;\n\tcase ATH10K_HW_TXRX_ETHERNET:\n\t\tflags0 |= SM(txmode, HTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\n\t\tbreak;\n\tcase ATH10K_HW_TXRX_MGMT:\n\t\tflags0 |= SM(ATH10K_HW_TXRX_MGMT,\n\t\t\t     HTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_MAC_HDR_PRESENT;\n\n\t\tif (htt->disable_tx_comp)\n\t\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_TX_COMPLETE;\n\t\tbreak;\n\t}\n\n\tif (skb_cb->flags & ATH10K_SKB_F_NO_HWCRYPT)\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_NO_ENCRYPT;\n\n\tflags1 |= SM((u16)vdev_id, HTT_DATA_TX_DESC_FLAGS1_VDEV_ID);\n\tflags1 |= SM((u16)tid, HTT_DATA_TX_DESC_FLAGS1_EXT_TID);\n\tif (msdu->ip_summed == CHECKSUM_PARTIAL &&\n\t    !test_bit(ATH10K_FLAG_RAW_MODE, &ar->dev_flags)) {\n\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L3_OFFLOAD;\n\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L4_OFFLOAD;\n\t}\n\n\t \n\tif (skb_headroom(msdu) < HTT_TX_HL_NEEDED_HEADROOM) {\n\t\ttmp_skb = msdu;\n\n\t\tath10k_dbg(htt->ar, ATH10K_DBG_HTT,\n\t\t\t   \"Not enough headroom in skb. Current headroom: %u, needed: %u. Reallocating...\\n\",\n\t\t\t   skb_headroom(msdu), HTT_TX_HL_NEEDED_HEADROOM);\n\t\tmsdu = skb_realloc_headroom(msdu, HTT_TX_HL_NEEDED_HEADROOM);\n\t\tkfree_skb(tmp_skb);\n\t\tif (!msdu) {\n\t\t\tath10k_warn(htt->ar, \"htt hl tx: Unable to realloc skb!\\n\");\n\t\t\tres = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (ar->bus_param.hl_msdu_ids) {\n\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_POSTPONED;\n\t\tres = ath10k_htt_tx_alloc_msdu_id(htt, msdu);\n\t\tif (res < 0) {\n\t\t\tath10k_err(ar, \"msdu_id allocation failed %d\\n\", res);\n\t\t\tgoto out;\n\t\t}\n\t\tmsdu_id = res;\n\t}\n\n\t \n\tskb_get(msdu);\n\n\tskb_push(msdu, sizeof(*cmd_hdr));\n\tskb_push(msdu, sizeof(*tx_desc));\n\tcmd_hdr = (struct htt_cmd_hdr *)msdu->data;\n\ttx_desc = (struct htt_data_tx_desc *)(msdu->data + sizeof(*cmd_hdr));\n\n\tcmd_hdr->msg_type = HTT_H2T_MSG_TYPE_TX_FRM;\n\ttx_desc->flags0 = flags0;\n\ttx_desc->flags1 = __cpu_to_le16(flags1);\n\ttx_desc->len = __cpu_to_le16(data_len);\n\ttx_desc->id = __cpu_to_le16(msdu_id);\n\ttx_desc->frags_paddr = 0;  \n\t \n\ttx_desc->peerid = __cpu_to_le32(HTT_INVALID_PEERID);\n\n\tres = ath10k_htc_send_hl(&htt->ar->htc, htt->eid, msdu);\n\nout:\n\treturn res;\n}\n\nstatic int ath10k_htt_tx_32(struct ath10k_htt *htt,\n\t\t\t    enum ath10k_hw_txrx_mode txmode,\n\t\t\t    struct sk_buff *msdu)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct device *dev = ar->dev;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(msdu);\n\tstruct ath10k_skb_cb *skb_cb = ATH10K_SKB_CB(msdu);\n\tstruct ath10k_hif_sg_item sg_items[2];\n\tstruct ath10k_htt_txbuf_32 *txbuf;\n\tstruct htt_data_tx_desc_frag *frags;\n\tbool is_eth = (txmode == ATH10K_HW_TXRX_ETHERNET);\n\tu8 vdev_id = ath10k_htt_tx_get_vdev_id(ar, msdu);\n\tu8 tid = ath10k_htt_tx_get_tid(msdu, is_eth);\n\tint prefetch_len;\n\tint res;\n\tu8 flags0 = 0;\n\tu16 msdu_id, flags1 = 0;\n\tu16 freq = 0;\n\tu32 frags_paddr = 0;\n\tu32 txbuf_paddr;\n\tstruct htt_msdu_ext_desc *ext_desc = NULL;\n\tstruct htt_msdu_ext_desc *ext_desc_t = NULL;\n\n\tres = ath10k_htt_tx_alloc_msdu_id(htt, msdu);\n\tif (res < 0)\n\t\tgoto err;\n\n\tmsdu_id = res;\n\n\tprefetch_len = min(htt->prefetch_len, msdu->len);\n\tprefetch_len = roundup(prefetch_len, 4);\n\n\ttxbuf = htt->txbuf.vaddr_txbuff_32 + msdu_id;\n\ttxbuf_paddr = htt->txbuf.paddr +\n\t\t      (sizeof(struct ath10k_htt_txbuf_32) * msdu_id);\n\n\tif (!is_eth) {\n\t\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)msdu->data;\n\n\t\tif ((ieee80211_is_action(hdr->frame_control) ||\n\t\t     ieee80211_is_deauth(hdr->frame_control) ||\n\t\t     ieee80211_is_disassoc(hdr->frame_control)) &&\n\t\t     ieee80211_has_protected(hdr->frame_control)) {\n\t\t\tskb_put(msdu, IEEE80211_CCMP_MIC_LEN);\n\t\t} else if (!(skb_cb->flags & ATH10K_SKB_F_NO_HWCRYPT) &&\n\t\t\t   txmode == ATH10K_HW_TXRX_RAW &&\n\t\t\t   ieee80211_has_protected(hdr->frame_control)) {\n\t\t\tskb_put(msdu, IEEE80211_CCMP_MIC_LEN);\n\t\t}\n\t}\n\n\tskb_cb->paddr = dma_map_single(dev, msdu->data, msdu->len,\n\t\t\t\t       DMA_TO_DEVICE);\n\tres = dma_mapping_error(dev, skb_cb->paddr);\n\tif (res) {\n\t\tres = -EIO;\n\t\tgoto err_free_msdu_id;\n\t}\n\n\tif (unlikely(info->flags & IEEE80211_TX_CTL_TX_OFFCHAN))\n\t\tfreq = ar->scan.roc_freq;\n\n\tswitch (txmode) {\n\tcase ATH10K_HW_TXRX_RAW:\n\tcase ATH10K_HW_TXRX_NATIVE_WIFI:\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_MAC_HDR_PRESENT;\n\t\tfallthrough;\n\tcase ATH10K_HW_TXRX_ETHERNET:\n\t\tif (ar->hw_params.continuous_frag_desc) {\n\t\t\text_desc_t = htt->frag_desc.vaddr_desc_32;\n\t\t\tmemset(&ext_desc_t[msdu_id], 0,\n\t\t\t       sizeof(struct htt_msdu_ext_desc));\n\t\t\tfrags = (struct htt_data_tx_desc_frag *)\n\t\t\t\t&ext_desc_t[msdu_id].frags;\n\t\t\text_desc = &ext_desc_t[msdu_id];\n\t\t\tfrags[0].tword_addr.paddr_lo =\n\t\t\t\t__cpu_to_le32(skb_cb->paddr);\n\t\t\tfrags[0].tword_addr.paddr_hi = 0;\n\t\t\tfrags[0].tword_addr.len_16 = __cpu_to_le16(msdu->len);\n\n\t\t\tfrags_paddr =  htt->frag_desc.paddr +\n\t\t\t\t(sizeof(struct htt_msdu_ext_desc) * msdu_id);\n\t\t} else {\n\t\t\tfrags = txbuf->frags;\n\t\t\tfrags[0].dword_addr.paddr =\n\t\t\t\t__cpu_to_le32(skb_cb->paddr);\n\t\t\tfrags[0].dword_addr.len = __cpu_to_le32(msdu->len);\n\t\t\tfrags[1].dword_addr.paddr = 0;\n\t\t\tfrags[1].dword_addr.len = 0;\n\n\t\t\tfrags_paddr = txbuf_paddr;\n\t\t}\n\t\tflags0 |= SM(txmode, HTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\n\t\tbreak;\n\tcase ATH10K_HW_TXRX_MGMT:\n\t\tflags0 |= SM(ATH10K_HW_TXRX_MGMT,\n\t\t\t     HTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_MAC_HDR_PRESENT;\n\n\t\tfrags_paddr = skb_cb->paddr;\n\t\tbreak;\n\t}\n\n\t \n\n\ttxbuf->htc_hdr.eid = htt->eid;\n\ttxbuf->htc_hdr.len = __cpu_to_le16(sizeof(txbuf->cmd_hdr) +\n\t\t\t\t\t   sizeof(txbuf->cmd_tx) +\n\t\t\t\t\t   prefetch_len);\n\ttxbuf->htc_hdr.flags = 0;\n\n\tif (skb_cb->flags & ATH10K_SKB_F_NO_HWCRYPT)\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_NO_ENCRYPT;\n\n\tflags1 |= SM((u16)vdev_id, HTT_DATA_TX_DESC_FLAGS1_VDEV_ID);\n\tflags1 |= SM((u16)tid, HTT_DATA_TX_DESC_FLAGS1_EXT_TID);\n\tif (msdu->ip_summed == CHECKSUM_PARTIAL &&\n\t    !test_bit(ATH10K_FLAG_RAW_MODE, &ar->dev_flags)) {\n\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L3_OFFLOAD;\n\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L4_OFFLOAD;\n\t\tif (ar->hw_params.continuous_frag_desc)\n\t\t\text_desc->flags |= HTT_MSDU_CHECKSUM_ENABLE;\n\t}\n\n\t \n\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_POSTPONED;\n\n\ttxbuf->cmd_hdr.msg_type = HTT_H2T_MSG_TYPE_TX_FRM;\n\ttxbuf->cmd_tx.flags0 = flags0;\n\ttxbuf->cmd_tx.flags1 = __cpu_to_le16(flags1);\n\ttxbuf->cmd_tx.len = __cpu_to_le16(msdu->len);\n\ttxbuf->cmd_tx.id = __cpu_to_le16(msdu_id);\n\ttxbuf->cmd_tx.frags_paddr = __cpu_to_le32(frags_paddr);\n\tif (ath10k_mac_tx_frm_has_freq(ar)) {\n\t\ttxbuf->cmd_tx.offchan_tx.peerid =\n\t\t\t\t__cpu_to_le16(HTT_INVALID_PEERID);\n\t\ttxbuf->cmd_tx.offchan_tx.freq =\n\t\t\t\t__cpu_to_le16(freq);\n\t} else {\n\t\ttxbuf->cmd_tx.peerid =\n\t\t\t\t__cpu_to_le32(HTT_INVALID_PEERID);\n\t}\n\n\ttrace_ath10k_htt_tx(ar, msdu_id, msdu->len, vdev_id, tid);\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt tx flags0 %u flags1 %u len %d id %u frags_paddr %pad, msdu_paddr %pad vdev %u tid %u freq %u\\n\",\n\t\t   flags0, flags1, msdu->len, msdu_id, &frags_paddr,\n\t\t   &skb_cb->paddr, vdev_id, tid, freq);\n\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"htt tx msdu: \",\n\t\t\tmsdu->data, msdu->len);\n\ttrace_ath10k_tx_hdr(ar, msdu->data, msdu->len);\n\ttrace_ath10k_tx_payload(ar, msdu->data, msdu->len);\n\n\tsg_items[0].transfer_id = 0;\n\tsg_items[0].transfer_context = NULL;\n\tsg_items[0].vaddr = &txbuf->htc_hdr;\n\tsg_items[0].paddr = txbuf_paddr +\n\t\t\t    sizeof(txbuf->frags);\n\tsg_items[0].len = sizeof(txbuf->htc_hdr) +\n\t\t\t  sizeof(txbuf->cmd_hdr) +\n\t\t\t  sizeof(txbuf->cmd_tx);\n\n\tsg_items[1].transfer_id = 0;\n\tsg_items[1].transfer_context = NULL;\n\tsg_items[1].vaddr = msdu->data;\n\tsg_items[1].paddr = skb_cb->paddr;\n\tsg_items[1].len = prefetch_len;\n\n\tres = ath10k_hif_tx_sg(htt->ar,\n\t\t\t       htt->ar->htc.endpoint[htt->eid].ul_pipe_id,\n\t\t\t       sg_items, ARRAY_SIZE(sg_items));\n\tif (res)\n\t\tgoto err_unmap_msdu;\n\n\treturn 0;\n\nerr_unmap_msdu:\n\tdma_unmap_single(dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);\nerr_free_msdu_id:\n\tspin_lock_bh(&htt->tx_lock);\n\tath10k_htt_tx_free_msdu_id(htt, msdu_id);\n\tspin_unlock_bh(&htt->tx_lock);\nerr:\n\treturn res;\n}\n\nstatic int ath10k_htt_tx_64(struct ath10k_htt *htt,\n\t\t\t    enum ath10k_hw_txrx_mode txmode,\n\t\t\t    struct sk_buff *msdu)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct device *dev = ar->dev;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(msdu);\n\tstruct ath10k_skb_cb *skb_cb = ATH10K_SKB_CB(msdu);\n\tstruct ath10k_hif_sg_item sg_items[2];\n\tstruct ath10k_htt_txbuf_64 *txbuf;\n\tstruct htt_data_tx_desc_frag *frags;\n\tbool is_eth = (txmode == ATH10K_HW_TXRX_ETHERNET);\n\tu8 vdev_id = ath10k_htt_tx_get_vdev_id(ar, msdu);\n\tu8 tid = ath10k_htt_tx_get_tid(msdu, is_eth);\n\tint prefetch_len;\n\tint res;\n\tu8 flags0 = 0;\n\tu16 msdu_id, flags1 = 0;\n\tu16 freq = 0;\n\tdma_addr_t frags_paddr = 0;\n\tdma_addr_t txbuf_paddr;\n\tstruct htt_msdu_ext_desc_64 *ext_desc = NULL;\n\tstruct htt_msdu_ext_desc_64 *ext_desc_t = NULL;\n\n\tres = ath10k_htt_tx_alloc_msdu_id(htt, msdu);\n\tif (res < 0)\n\t\tgoto err;\n\n\tmsdu_id = res;\n\n\tprefetch_len = min(htt->prefetch_len, msdu->len);\n\tprefetch_len = roundup(prefetch_len, 4);\n\n\ttxbuf = htt->txbuf.vaddr_txbuff_64 + msdu_id;\n\ttxbuf_paddr = htt->txbuf.paddr +\n\t\t      (sizeof(struct ath10k_htt_txbuf_64) * msdu_id);\n\n\tif (!is_eth) {\n\t\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)msdu->data;\n\n\t\tif ((ieee80211_is_action(hdr->frame_control) ||\n\t\t     ieee80211_is_deauth(hdr->frame_control) ||\n\t\t     ieee80211_is_disassoc(hdr->frame_control)) &&\n\t\t     ieee80211_has_protected(hdr->frame_control)) {\n\t\t\tskb_put(msdu, IEEE80211_CCMP_MIC_LEN);\n\t\t} else if (!(skb_cb->flags & ATH10K_SKB_F_NO_HWCRYPT) &&\n\t\t\t   txmode == ATH10K_HW_TXRX_RAW &&\n\t\t\t   ieee80211_has_protected(hdr->frame_control)) {\n\t\t\tskb_put(msdu, IEEE80211_CCMP_MIC_LEN);\n\t\t}\n\t}\n\n\tskb_cb->paddr = dma_map_single(dev, msdu->data, msdu->len,\n\t\t\t\t       DMA_TO_DEVICE);\n\tres = dma_mapping_error(dev, skb_cb->paddr);\n\tif (res) {\n\t\tres = -EIO;\n\t\tgoto err_free_msdu_id;\n\t}\n\n\tif (unlikely(info->flags & IEEE80211_TX_CTL_TX_OFFCHAN))\n\t\tfreq = ar->scan.roc_freq;\n\n\tswitch (txmode) {\n\tcase ATH10K_HW_TXRX_RAW:\n\tcase ATH10K_HW_TXRX_NATIVE_WIFI:\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_MAC_HDR_PRESENT;\n\t\tfallthrough;\n\tcase ATH10K_HW_TXRX_ETHERNET:\n\t\tif (ar->hw_params.continuous_frag_desc) {\n\t\t\text_desc_t = htt->frag_desc.vaddr_desc_64;\n\t\t\tmemset(&ext_desc_t[msdu_id], 0,\n\t\t\t       sizeof(struct htt_msdu_ext_desc_64));\n\t\t\tfrags = (struct htt_data_tx_desc_frag *)\n\t\t\t\t&ext_desc_t[msdu_id].frags;\n\t\t\text_desc = &ext_desc_t[msdu_id];\n\t\t\tfrags[0].tword_addr.paddr_lo =\n\t\t\t\t__cpu_to_le32(skb_cb->paddr);\n\t\t\tfrags[0].tword_addr.paddr_hi =\n\t\t\t\t__cpu_to_le16(upper_32_bits(skb_cb->paddr));\n\t\t\tfrags[0].tword_addr.len_16 = __cpu_to_le16(msdu->len);\n\n\t\t\tfrags_paddr =  htt->frag_desc.paddr +\n\t\t\t   (sizeof(struct htt_msdu_ext_desc_64) * msdu_id);\n\t\t} else {\n\t\t\tfrags = txbuf->frags;\n\t\t\tfrags[0].tword_addr.paddr_lo =\n\t\t\t\t\t\t__cpu_to_le32(skb_cb->paddr);\n\t\t\tfrags[0].tword_addr.paddr_hi =\n\t\t\t\t__cpu_to_le16(upper_32_bits(skb_cb->paddr));\n\t\t\tfrags[0].tword_addr.len_16 = __cpu_to_le16(msdu->len);\n\t\t\tfrags[1].tword_addr.paddr_lo = 0;\n\t\t\tfrags[1].tword_addr.paddr_hi = 0;\n\t\t\tfrags[1].tword_addr.len_16 = 0;\n\t\t}\n\t\tflags0 |= SM(txmode, HTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\n\t\tbreak;\n\tcase ATH10K_HW_TXRX_MGMT:\n\t\tflags0 |= SM(ATH10K_HW_TXRX_MGMT,\n\t\t\t     HTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_MAC_HDR_PRESENT;\n\n\t\tfrags_paddr = skb_cb->paddr;\n\t\tbreak;\n\t}\n\n\t \n\n\ttxbuf->htc_hdr.eid = htt->eid;\n\ttxbuf->htc_hdr.len = __cpu_to_le16(sizeof(txbuf->cmd_hdr) +\n\t\t\t\t\t   sizeof(txbuf->cmd_tx) +\n\t\t\t\t\t   prefetch_len);\n\ttxbuf->htc_hdr.flags = 0;\n\n\tif (skb_cb->flags & ATH10K_SKB_F_NO_HWCRYPT)\n\t\tflags0 |= HTT_DATA_TX_DESC_FLAGS0_NO_ENCRYPT;\n\n\tflags1 |= SM((u16)vdev_id, HTT_DATA_TX_DESC_FLAGS1_VDEV_ID);\n\tflags1 |= SM((u16)tid, HTT_DATA_TX_DESC_FLAGS1_EXT_TID);\n\tif (msdu->ip_summed == CHECKSUM_PARTIAL &&\n\t    !test_bit(ATH10K_FLAG_RAW_MODE, &ar->dev_flags)) {\n\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L3_OFFLOAD;\n\t\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L4_OFFLOAD;\n\t\tif (ar->hw_params.continuous_frag_desc) {\n\t\t\tmemset(ext_desc->tso_flag, 0, sizeof(ext_desc->tso_flag));\n\t\t\text_desc->tso_flag[3] |=\n\t\t\t\t__cpu_to_le32(HTT_MSDU_CHECKSUM_ENABLE_64);\n\t\t}\n\t}\n\n\t \n\tflags1 |= HTT_DATA_TX_DESC_FLAGS1_POSTPONED;\n\n\ttxbuf->cmd_hdr.msg_type = HTT_H2T_MSG_TYPE_TX_FRM;\n\ttxbuf->cmd_tx.flags0 = flags0;\n\ttxbuf->cmd_tx.flags1 = __cpu_to_le16(flags1);\n\ttxbuf->cmd_tx.len = __cpu_to_le16(msdu->len);\n\ttxbuf->cmd_tx.id = __cpu_to_le16(msdu_id);\n\n\t \n\ttxbuf->cmd_tx.frags_paddr = __cpu_to_le64(frags_paddr);\n\tif (ath10k_mac_tx_frm_has_freq(ar)) {\n\t\ttxbuf->cmd_tx.offchan_tx.peerid =\n\t\t\t\t__cpu_to_le16(HTT_INVALID_PEERID);\n\t\ttxbuf->cmd_tx.offchan_tx.freq =\n\t\t\t\t__cpu_to_le16(freq);\n\t} else {\n\t\ttxbuf->cmd_tx.peerid =\n\t\t\t\t__cpu_to_le32(HTT_INVALID_PEERID);\n\t}\n\n\ttrace_ath10k_htt_tx(ar, msdu_id, msdu->len, vdev_id, tid);\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt tx flags0 %u flags1 %u len %d id %u frags_paddr %pad, msdu_paddr %pad vdev %u tid %u freq %u\\n\",\n\t\t   flags0, flags1, msdu->len, msdu_id, &frags_paddr,\n\t\t   &skb_cb->paddr, vdev_id, tid, freq);\n\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"htt tx msdu: \",\n\t\t\tmsdu->data, msdu->len);\n\ttrace_ath10k_tx_hdr(ar, msdu->data, msdu->len);\n\ttrace_ath10k_tx_payload(ar, msdu->data, msdu->len);\n\n\tsg_items[0].transfer_id = 0;\n\tsg_items[0].transfer_context = NULL;\n\tsg_items[0].vaddr = &txbuf->htc_hdr;\n\tsg_items[0].paddr = txbuf_paddr +\n\t\t\t    sizeof(txbuf->frags);\n\tsg_items[0].len = sizeof(txbuf->htc_hdr) +\n\t\t\t  sizeof(txbuf->cmd_hdr) +\n\t\t\t  sizeof(txbuf->cmd_tx);\n\n\tsg_items[1].transfer_id = 0;\n\tsg_items[1].transfer_context = NULL;\n\tsg_items[1].vaddr = msdu->data;\n\tsg_items[1].paddr = skb_cb->paddr;\n\tsg_items[1].len = prefetch_len;\n\n\tres = ath10k_hif_tx_sg(htt->ar,\n\t\t\t       htt->ar->htc.endpoint[htt->eid].ul_pipe_id,\n\t\t\t       sg_items, ARRAY_SIZE(sg_items));\n\tif (res)\n\t\tgoto err_unmap_msdu;\n\n\treturn 0;\n\nerr_unmap_msdu:\n\tdma_unmap_single(dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);\nerr_free_msdu_id:\n\tspin_lock_bh(&htt->tx_lock);\n\tath10k_htt_tx_free_msdu_id(htt, msdu_id);\n\tspin_unlock_bh(&htt->tx_lock);\nerr:\n\treturn res;\n}\n\nstatic const struct ath10k_htt_tx_ops htt_tx_ops_32 = {\n\t.htt_send_rx_ring_cfg = ath10k_htt_send_rx_ring_cfg_32,\n\t.htt_send_frag_desc_bank_cfg = ath10k_htt_send_frag_desc_bank_cfg_32,\n\t.htt_alloc_frag_desc = ath10k_htt_tx_alloc_cont_frag_desc_32,\n\t.htt_free_frag_desc = ath10k_htt_tx_free_cont_frag_desc_32,\n\t.htt_tx = ath10k_htt_tx_32,\n\t.htt_alloc_txbuff = ath10k_htt_tx_alloc_cont_txbuf_32,\n\t.htt_free_txbuff = ath10k_htt_tx_free_cont_txbuf_32,\n\t.htt_h2t_aggr_cfg_msg = ath10k_htt_h2t_aggr_cfg_msg_32,\n};\n\nstatic const struct ath10k_htt_tx_ops htt_tx_ops_64 = {\n\t.htt_send_rx_ring_cfg = ath10k_htt_send_rx_ring_cfg_64,\n\t.htt_send_frag_desc_bank_cfg = ath10k_htt_send_frag_desc_bank_cfg_64,\n\t.htt_alloc_frag_desc = ath10k_htt_tx_alloc_cont_frag_desc_64,\n\t.htt_free_frag_desc = ath10k_htt_tx_free_cont_frag_desc_64,\n\t.htt_tx = ath10k_htt_tx_64,\n\t.htt_alloc_txbuff = ath10k_htt_tx_alloc_cont_txbuf_64,\n\t.htt_free_txbuff = ath10k_htt_tx_free_cont_txbuf_64,\n\t.htt_h2t_aggr_cfg_msg = ath10k_htt_h2t_aggr_cfg_msg_v2,\n};\n\nstatic const struct ath10k_htt_tx_ops htt_tx_ops_hl = {\n\t.htt_send_rx_ring_cfg = ath10k_htt_send_rx_ring_cfg_hl,\n\t.htt_send_frag_desc_bank_cfg = ath10k_htt_send_frag_desc_bank_cfg_32,\n\t.htt_tx = ath10k_htt_tx_hl,\n\t.htt_h2t_aggr_cfg_msg = ath10k_htt_h2t_aggr_cfg_msg_32,\n\t.htt_flush_tx = ath10k_htt_flush_tx_queue,\n};\n\nvoid ath10k_htt_set_tx_ops(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\n\tif (ar->bus_param.dev_type == ATH10K_DEV_TYPE_HL)\n\t\thtt->tx_ops = &htt_tx_ops_hl;\n\telse if (ar->hw_params.target_64bit)\n\t\thtt->tx_ops = &htt_tx_ops_64;\n\telse\n\t\thtt->tx_ops = &htt_tx_ops_32;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}