{
  "module_name": "pci.c",
  "hash_id": "3ce61f2d798e2c2c003f1f7f558633e8eb796725e19390eea998670394020638",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ath/ath10k/pci.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/bitops.h>\n\n#include \"core.h\"\n#include \"debug.h\"\n#include \"coredump.h\"\n\n#include \"targaddrs.h\"\n#include \"bmi.h\"\n\n#include \"hif.h\"\n#include \"htc.h\"\n\n#include \"ce.h\"\n#include \"pci.h\"\n\nenum ath10k_pci_reset_mode {\n\tATH10K_PCI_RESET_AUTO = 0,\n\tATH10K_PCI_RESET_WARM_ONLY = 1,\n};\n\nstatic unsigned int ath10k_pci_irq_mode = ATH10K_PCI_IRQ_AUTO;\nstatic unsigned int ath10k_pci_reset_mode = ATH10K_PCI_RESET_AUTO;\n\nmodule_param_named(irq_mode, ath10k_pci_irq_mode, uint, 0644);\nMODULE_PARM_DESC(irq_mode, \"0: auto, 1: legacy, 2: msi (default: 0)\");\n\nmodule_param_named(reset_mode, ath10k_pci_reset_mode, uint, 0644);\nMODULE_PARM_DESC(reset_mode, \"0: auto, 1: warm only (default: 0)\");\n\n \n#define ATH10K_PCI_TARGET_WAIT 3000\n#define ATH10K_PCI_NUM_WARM_RESET_ATTEMPTS 3\n\n \n#define ATH10K_DIAG_TRANSFER_LIMIT\t0x5000\n\n#define QCA99X0_PCIE_BAR0_START_REG    0x81030\n#define QCA99X0_CPU_MEM_ADDR_REG       0x4d00c\n#define QCA99X0_CPU_MEM_DATA_REG       0x4d010\n\nstatic const struct pci_device_id ath10k_pci_id_table[] = {\n\t \n\t{ PCI_VDEVICE(UBIQUITI, QCA988X_2_0_DEVICE_ID_UBNT) },\n\n\t{ PCI_VDEVICE(ATHEROS, QCA988X_2_0_DEVICE_ID) },  \n\t{ PCI_VDEVICE(ATHEROS, QCA6164_2_1_DEVICE_ID) },  \n\t{ PCI_VDEVICE(ATHEROS, QCA6174_2_1_DEVICE_ID) },  \n\t{ PCI_VDEVICE(ATHEROS, QCA99X0_2_0_DEVICE_ID) },  \n\t{ PCI_VDEVICE(ATHEROS, QCA9888_2_0_DEVICE_ID) },  \n\t{ PCI_VDEVICE(ATHEROS, QCA9984_1_0_DEVICE_ID) },  \n\t{ PCI_VDEVICE(ATHEROS, QCA9377_1_0_DEVICE_ID) },  \n\t{ PCI_VDEVICE(ATHEROS, QCA9887_1_0_DEVICE_ID) },  \n\t{0}\n};\n\nstatic const struct ath10k_pci_supp_chip ath10k_pci_supp_chips[] = {\n\t \n\t{ QCA988X_2_0_DEVICE_ID_UBNT, QCA988X_HW_2_0_CHIP_ID_REV },\n\t{ QCA988X_2_0_DEVICE_ID, QCA988X_HW_2_0_CHIP_ID_REV },\n\n\t{ QCA6164_2_1_DEVICE_ID, QCA6174_HW_2_1_CHIP_ID_REV },\n\t{ QCA6164_2_1_DEVICE_ID, QCA6174_HW_2_2_CHIP_ID_REV },\n\t{ QCA6164_2_1_DEVICE_ID, QCA6174_HW_3_0_CHIP_ID_REV },\n\t{ QCA6164_2_1_DEVICE_ID, QCA6174_HW_3_1_CHIP_ID_REV },\n\t{ QCA6164_2_1_DEVICE_ID, QCA6174_HW_3_2_CHIP_ID_REV },\n\n\t{ QCA6174_2_1_DEVICE_ID, QCA6174_HW_2_1_CHIP_ID_REV },\n\t{ QCA6174_2_1_DEVICE_ID, QCA6174_HW_2_2_CHIP_ID_REV },\n\t{ QCA6174_2_1_DEVICE_ID, QCA6174_HW_3_0_CHIP_ID_REV },\n\t{ QCA6174_2_1_DEVICE_ID, QCA6174_HW_3_1_CHIP_ID_REV },\n\t{ QCA6174_2_1_DEVICE_ID, QCA6174_HW_3_2_CHIP_ID_REV },\n\n\t{ QCA99X0_2_0_DEVICE_ID, QCA99X0_HW_2_0_CHIP_ID_REV },\n\n\t{ QCA9984_1_0_DEVICE_ID, QCA9984_HW_1_0_CHIP_ID_REV },\n\n\t{ QCA9888_2_0_DEVICE_ID, QCA9888_HW_2_0_CHIP_ID_REV },\n\n\t{ QCA9377_1_0_DEVICE_ID, QCA9377_HW_1_0_CHIP_ID_REV },\n\t{ QCA9377_1_0_DEVICE_ID, QCA9377_HW_1_1_CHIP_ID_REV },\n\n\t{ QCA9887_1_0_DEVICE_ID, QCA9887_HW_1_0_CHIP_ID_REV },\n};\n\nstatic void ath10k_pci_buffer_cleanup(struct ath10k *ar);\nstatic int ath10k_pci_cold_reset(struct ath10k *ar);\nstatic int ath10k_pci_safe_chip_reset(struct ath10k *ar);\nstatic int ath10k_pci_init_irq(struct ath10k *ar);\nstatic int ath10k_pci_deinit_irq(struct ath10k *ar);\nstatic int ath10k_pci_request_irq(struct ath10k *ar);\nstatic void ath10k_pci_free_irq(struct ath10k *ar);\nstatic int ath10k_pci_bmi_wait(struct ath10k *ar,\n\t\t\t       struct ath10k_ce_pipe *tx_pipe,\n\t\t\t       struct ath10k_ce_pipe *rx_pipe,\n\t\t\t       struct bmi_xfer *xfer);\nstatic int ath10k_pci_qca99x0_chip_reset(struct ath10k *ar);\nstatic void ath10k_pci_htc_tx_cb(struct ath10k_ce_pipe *ce_state);\nstatic void ath10k_pci_htc_rx_cb(struct ath10k_ce_pipe *ce_state);\nstatic void ath10k_pci_htt_tx_cb(struct ath10k_ce_pipe *ce_state);\nstatic void ath10k_pci_htt_rx_cb(struct ath10k_ce_pipe *ce_state);\nstatic void ath10k_pci_htt_htc_rx_cb(struct ath10k_ce_pipe *ce_state);\nstatic void ath10k_pci_pktlog_rx_cb(struct ath10k_ce_pipe *ce_state);\n\nstatic const struct ce_attr pci_host_ce_config_wlan[] = {\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 16,\n\t\t.src_sz_max = 256,\n\t\t.dest_nentries = 0,\n\t\t.send_cb = ath10k_pci_htc_tx_cb,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 2048,\n\t\t.dest_nentries = 512,\n\t\t.recv_cb = ath10k_pci_htt_htc_rx_cb,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 2048,\n\t\t.dest_nentries = 128,\n\t\t.recv_cb = ath10k_pci_htc_rx_cb,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 32,\n\t\t.src_sz_max = 2048,\n\t\t.dest_nentries = 0,\n\t\t.send_cb = ath10k_pci_htc_tx_cb,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS | CE_ATTR_DIS_INTR,\n\t\t.src_nentries = CE_HTT_H2T_MSG_SRC_NENTRIES,\n\t\t.src_sz_max = 256,\n\t\t.dest_nentries = 0,\n\t\t.send_cb = ath10k_pci_htt_tx_cb,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 512,\n\t\t.dest_nentries = 512,\n\t\t.recv_cb = ath10k_pci_htt_rx_cb,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 0,\n\t\t.dest_nentries = 0,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS | CE_ATTR_POLL,\n\t\t.src_nentries = 2,\n\t\t.src_sz_max = DIAG_TRANSFER_LIMIT,\n\t\t.dest_nentries = 2,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 2048,\n\t\t.dest_nentries = 128,\n\t\t.recv_cb = ath10k_pci_pktlog_rx_cb,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 0,\n\t\t.dest_nentries = 0,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 0,\n\t\t.dest_nentries = 0,\n\t},\n\n\t \n\t{\n\t\t.flags = CE_ATTR_FLAGS,\n\t\t.src_nentries = 0,\n\t\t.src_sz_max = 0,\n\t\t.dest_nentries = 0,\n\t},\n};\n\n \nstatic const struct ce_pipe_config pci_target_ce_config_wlan[] = {\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(0),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_OUT),\n\t\t.nentries = __cpu_to_le32(32),\n\t\t.nbytes_max = __cpu_to_le32(256),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(1),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_IN),\n\t\t.nentries = __cpu_to_le32(32),\n\t\t.nbytes_max = __cpu_to_le32(2048),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(2),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_IN),\n\t\t.nentries = __cpu_to_le32(64),\n\t\t.nbytes_max = __cpu_to_le32(2048),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(3),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_OUT),\n\t\t.nentries = __cpu_to_le32(32),\n\t\t.nbytes_max = __cpu_to_le32(2048),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(4),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_OUT),\n\t\t.nentries = __cpu_to_le32(256),\n\t\t.nbytes_max = __cpu_to_le32(256),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(5),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_IN),\n\t\t.nentries = __cpu_to_le32(32),\n\t\t.nbytes_max = __cpu_to_le32(512),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(6),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_INOUT),\n\t\t.nentries = __cpu_to_le32(32),\n\t\t.nbytes_max = __cpu_to_le32(4096),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(7),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_INOUT),\n\t\t.nentries = __cpu_to_le32(0),\n\t\t.nbytes_max = __cpu_to_le32(0),\n\t\t.flags = __cpu_to_le32(0),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(8),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_IN),\n\t\t.nentries = __cpu_to_le32(64),\n\t\t.nbytes_max = __cpu_to_le32(2048),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS | CE_ATTR_DIS_INTR),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n\t{\n\t\t.pipenum = __cpu_to_le32(9),\n\t\t.pipedir = __cpu_to_le32(PIPEDIR_INOUT),\n\t\t.nentries = __cpu_to_le32(32),\n\t\t.nbytes_max = __cpu_to_le32(2048),\n\t\t.flags = __cpu_to_le32(CE_ATTR_FLAGS | CE_ATTR_DIS_INTR),\n\t\t.reserved = __cpu_to_le32(0),\n\t},\n\n\t \n};\n\n \nstatic const struct ce_service_to_pipe pci_target_service_to_ce_map_wlan[] = {\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_VO),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(3),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_VO),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(2),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_BK),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(3),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_BK),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(2),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_BE),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(3),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_BE),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(2),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_VI),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(3),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_DATA_VI),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(2),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_CONTROL),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(3),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_WMI_CONTROL),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(2),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_RSVD_CTRL),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(0),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_RSVD_CTRL),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(1),\n\t},\n\t{  \n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_TEST_RAW_STREAMS),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(0),\n\t},\n\t{  \n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_TEST_RAW_STREAMS),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(1),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_HTT_DATA_MSG),\n\t\t__cpu_to_le32(PIPEDIR_OUT),\t \n\t\t__cpu_to_le32(4),\n\t},\n\t{\n\t\t__cpu_to_le32(ATH10K_HTC_SVC_ID_HTT_DATA_MSG),\n\t\t__cpu_to_le32(PIPEDIR_IN),\t \n\t\t__cpu_to_le32(5),\n\t},\n\n\t \n\n\t{  \n\t\t__cpu_to_le32(0),\n\t\t__cpu_to_le32(0),\n\t\t__cpu_to_le32(0),\n\t},\n};\n\nstatic bool ath10k_pci_is_awake(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tu32 val = ioread32(ar_pci->mem + PCIE_LOCAL_BASE_ADDRESS +\n\t\t\t   RTC_STATE_ADDRESS);\n\n\treturn RTC_STATE_V_GET(val) == RTC_STATE_V_ON;\n}\n\nstatic void __ath10k_pci_wake(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tlockdep_assert_held(&ar_pci->ps_lock);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI_PS, \"pci ps wake reg refcount %lu awake %d\\n\",\n\t\t   ar_pci->ps_wake_refcount, ar_pci->ps_awake);\n\n\tiowrite32(PCIE_SOC_WAKE_V_MASK,\n\t\t  ar_pci->mem + PCIE_LOCAL_BASE_ADDRESS +\n\t\t  PCIE_SOC_WAKE_ADDRESS);\n}\n\nstatic void __ath10k_pci_sleep(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tlockdep_assert_held(&ar_pci->ps_lock);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI_PS, \"pci ps sleep reg refcount %lu awake %d\\n\",\n\t\t   ar_pci->ps_wake_refcount, ar_pci->ps_awake);\n\n\tiowrite32(PCIE_SOC_WAKE_RESET,\n\t\t  ar_pci->mem + PCIE_LOCAL_BASE_ADDRESS +\n\t\t  PCIE_SOC_WAKE_ADDRESS);\n\tar_pci->ps_awake = false;\n}\n\nstatic int ath10k_pci_wake_wait(struct ath10k *ar)\n{\n\tint tot_delay = 0;\n\tint curr_delay = 5;\n\n\twhile (tot_delay < PCIE_WAKE_TIMEOUT) {\n\t\tif (ath10k_pci_is_awake(ar)) {\n\t\t\tif (tot_delay > PCIE_WAKE_LATE_US)\n\t\t\t\tath10k_warn(ar, \"device wakeup took %d ms which is unusually long, otherwise it works normally.\\n\",\n\t\t\t\t\t    tot_delay / 1000);\n\t\t\treturn 0;\n\t\t}\n\n\t\tudelay(curr_delay);\n\t\ttot_delay += curr_delay;\n\n\t\tif (curr_delay < 50)\n\t\t\tcurr_delay += 5;\n\t}\n\n\treturn -ETIMEDOUT;\n}\n\nstatic int ath10k_pci_force_wake(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (ar_pci->pci_ps)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&ar_pci->ps_lock, flags);\n\n\tif (!ar_pci->ps_awake) {\n\t\tiowrite32(PCIE_SOC_WAKE_V_MASK,\n\t\t\t  ar_pci->mem + PCIE_LOCAL_BASE_ADDRESS +\n\t\t\t  PCIE_SOC_WAKE_ADDRESS);\n\n\t\tret = ath10k_pci_wake_wait(ar);\n\t\tif (ret == 0)\n\t\t\tar_pci->ps_awake = true;\n\t}\n\n\tspin_unlock_irqrestore(&ar_pci->ps_lock, flags);\n\n\treturn ret;\n}\n\nstatic void ath10k_pci_force_sleep(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ar_pci->ps_lock, flags);\n\n\tiowrite32(PCIE_SOC_WAKE_RESET,\n\t\t  ar_pci->mem + PCIE_LOCAL_BASE_ADDRESS +\n\t\t  PCIE_SOC_WAKE_ADDRESS);\n\tar_pci->ps_awake = false;\n\n\tspin_unlock_irqrestore(&ar_pci->ps_lock, flags);\n}\n\nstatic int ath10k_pci_wake(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tunsigned long flags;\n\tint ret = 0;\n\n\tif (ar_pci->pci_ps == 0)\n\t\treturn ret;\n\n\tspin_lock_irqsave(&ar_pci->ps_lock, flags);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI_PS, \"pci ps wake refcount %lu awake %d\\n\",\n\t\t   ar_pci->ps_wake_refcount, ar_pci->ps_awake);\n\n\t \n\tif (!ar_pci->ps_awake) {\n\t\t__ath10k_pci_wake(ar);\n\n\t\tret = ath10k_pci_wake_wait(ar);\n\t\tif (ret == 0)\n\t\t\tar_pci->ps_awake = true;\n\t}\n\n\tif (ret == 0) {\n\t\tar_pci->ps_wake_refcount++;\n\t\tWARN_ON(ar_pci->ps_wake_refcount == 0);\n\t}\n\n\tspin_unlock_irqrestore(&ar_pci->ps_lock, flags);\n\n\treturn ret;\n}\n\nstatic void ath10k_pci_sleep(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tunsigned long flags;\n\n\tif (ar_pci->pci_ps == 0)\n\t\treturn;\n\n\tspin_lock_irqsave(&ar_pci->ps_lock, flags);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI_PS, \"pci ps sleep refcount %lu awake %d\\n\",\n\t\t   ar_pci->ps_wake_refcount, ar_pci->ps_awake);\n\n\tif (WARN_ON(ar_pci->ps_wake_refcount == 0))\n\t\tgoto skip;\n\n\tar_pci->ps_wake_refcount--;\n\n\tmod_timer(&ar_pci->ps_timer, jiffies +\n\t\t  msecs_to_jiffies(ATH10K_PCI_SLEEP_GRACE_PERIOD_MSEC));\n\nskip:\n\tspin_unlock_irqrestore(&ar_pci->ps_lock, flags);\n}\n\nstatic void ath10k_pci_ps_timer(struct timer_list *t)\n{\n\tstruct ath10k_pci *ar_pci = from_timer(ar_pci, t, ps_timer);\n\tstruct ath10k *ar = ar_pci->ar;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ar_pci->ps_lock, flags);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI_PS, \"pci ps timer refcount %lu awake %d\\n\",\n\t\t   ar_pci->ps_wake_refcount, ar_pci->ps_awake);\n\n\tif (ar_pci->ps_wake_refcount > 0)\n\t\tgoto skip;\n\n\t__ath10k_pci_sleep(ar);\n\nskip:\n\tspin_unlock_irqrestore(&ar_pci->ps_lock, flags);\n}\n\nstatic void ath10k_pci_sleep_sync(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tunsigned long flags;\n\n\tif (ar_pci->pci_ps == 0) {\n\t\tath10k_pci_force_sleep(ar);\n\t\treturn;\n\t}\n\n\tdel_timer_sync(&ar_pci->ps_timer);\n\n\tspin_lock_irqsave(&ar_pci->ps_lock, flags);\n\tWARN_ON(ar_pci->ps_wake_refcount > 0);\n\t__ath10k_pci_sleep(ar);\n\tspin_unlock_irqrestore(&ar_pci->ps_lock, flags);\n}\n\nstatic void ath10k_bus_pci_write32(struct ath10k *ar, u32 offset, u32 value)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret;\n\n\tif (unlikely(offset + sizeof(value) > ar_pci->mem_len)) {\n\t\tath10k_warn(ar, \"refusing to write mmio out of bounds at 0x%08x - 0x%08zx (max 0x%08zx)\\n\",\n\t\t\t    offset, offset + sizeof(value), ar_pci->mem_len);\n\t\treturn;\n\t}\n\n\tret = ath10k_pci_wake(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wake target for write32 of 0x%08x at 0x%08x: %d\\n\",\n\t\t\t    value, offset, ret);\n\t\treturn;\n\t}\n\n\tiowrite32(value, ar_pci->mem + offset);\n\tath10k_pci_sleep(ar);\n}\n\nstatic u32 ath10k_bus_pci_read32(struct ath10k *ar, u32 offset)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tu32 val;\n\tint ret;\n\n\tif (unlikely(offset + sizeof(val) > ar_pci->mem_len)) {\n\t\tath10k_warn(ar, \"refusing to read mmio out of bounds at 0x%08x - 0x%08zx (max 0x%08zx)\\n\",\n\t\t\t    offset, offset + sizeof(val), ar_pci->mem_len);\n\t\treturn 0;\n\t}\n\n\tret = ath10k_pci_wake(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wake target for read32 at 0x%08x: %d\\n\",\n\t\t\t    offset, ret);\n\t\treturn 0xffffffff;\n\t}\n\n\tval = ioread32(ar_pci->mem + offset);\n\tath10k_pci_sleep(ar);\n\n\treturn val;\n}\n\ninline void ath10k_pci_write32(struct ath10k *ar, u32 offset, u32 value)\n{\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\n\tce->bus_ops->write32(ar, offset, value);\n}\n\ninline u32 ath10k_pci_read32(struct ath10k *ar, u32 offset)\n{\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\n\treturn ce->bus_ops->read32(ar, offset);\n}\n\nu32 ath10k_pci_soc_read32(struct ath10k *ar, u32 addr)\n{\n\treturn ath10k_pci_read32(ar, RTC_SOC_BASE_ADDRESS + addr);\n}\n\nvoid ath10k_pci_soc_write32(struct ath10k *ar, u32 addr, u32 val)\n{\n\tath10k_pci_write32(ar, RTC_SOC_BASE_ADDRESS + addr, val);\n}\n\nu32 ath10k_pci_reg_read32(struct ath10k *ar, u32 addr)\n{\n\treturn ath10k_pci_read32(ar, PCIE_LOCAL_BASE_ADDRESS + addr);\n}\n\nvoid ath10k_pci_reg_write32(struct ath10k *ar, u32 addr, u32 val)\n{\n\tath10k_pci_write32(ar, PCIE_LOCAL_BASE_ADDRESS + addr, val);\n}\n\nbool ath10k_pci_irq_pending(struct ath10k *ar)\n{\n\tu32 cause;\n\n\t \n\tcause = ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\t  PCIE_INTR_CAUSE_ADDRESS);\n\tif (cause & (PCIE_INTR_FIRMWARE_MASK | PCIE_INTR_CE_MASK_ALL))\n\t\treturn true;\n\n\treturn false;\n}\n\nvoid ath10k_pci_disable_and_clear_legacy_irq(struct ath10k *ar)\n{\n\t \n\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS + PCIE_INTR_ENABLE_ADDRESS,\n\t\t\t   0);\n\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS + PCIE_INTR_CLR_ADDRESS,\n\t\t\t   PCIE_INTR_FIRMWARE_MASK | PCIE_INTR_CE_MASK_ALL);\n\n\t \n\t(void)ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\tPCIE_INTR_ENABLE_ADDRESS);\n}\n\nvoid ath10k_pci_enable_legacy_irq(struct ath10k *ar)\n{\n\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t   PCIE_INTR_ENABLE_ADDRESS,\n\t\t\t   PCIE_INTR_FIRMWARE_MASK | PCIE_INTR_CE_MASK_ALL);\n\n\t \n\t(void)ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\tPCIE_INTR_ENABLE_ADDRESS);\n}\n\nstatic inline const char *ath10k_pci_get_irq_method(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tif (ar_pci->oper_irq_mode == ATH10K_PCI_IRQ_MSI)\n\t\treturn \"msi\";\n\n\treturn \"legacy\";\n}\n\nstatic int __ath10k_pci_rx_post_buf(struct ath10k_pci_pipe *pipe)\n{\n\tstruct ath10k *ar = pipe->hif_ce_state;\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\tstruct ath10k_ce_pipe *ce_pipe = pipe->ce_hdl;\n\tstruct sk_buff *skb;\n\tdma_addr_t paddr;\n\tint ret;\n\n\tskb = dev_alloc_skb(pipe->buf_sz);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tWARN_ONCE((unsigned long)skb->data & 3, \"unaligned skb\");\n\n\tpaddr = dma_map_single(ar->dev, skb->data,\n\t\t\t       skb->len + skb_tailroom(skb),\n\t\t\t       DMA_FROM_DEVICE);\n\tif (unlikely(dma_mapping_error(ar->dev, paddr))) {\n\t\tath10k_warn(ar, \"failed to dma map pci rx buf\\n\");\n\t\tdev_kfree_skb_any(skb);\n\t\treturn -EIO;\n\t}\n\n\tATH10K_SKB_RXCB(skb)->paddr = paddr;\n\n\tspin_lock_bh(&ce->ce_lock);\n\tret = ce_pipe->ops->ce_rx_post_buf(ce_pipe, skb, paddr);\n\tspin_unlock_bh(&ce->ce_lock);\n\tif (ret) {\n\t\tdma_unmap_single(ar->dev, paddr, skb->len + skb_tailroom(skb),\n\t\t\t\t DMA_FROM_DEVICE);\n\t\tdev_kfree_skb_any(skb);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void ath10k_pci_rx_post_pipe(struct ath10k_pci_pipe *pipe)\n{\n\tstruct ath10k *ar = pipe->hif_ce_state;\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\tstruct ath10k_ce_pipe *ce_pipe = pipe->ce_hdl;\n\tint ret, num;\n\n\tif (pipe->buf_sz == 0)\n\t\treturn;\n\n\tif (!ce_pipe->dest_ring)\n\t\treturn;\n\n\tspin_lock_bh(&ce->ce_lock);\n\tnum = __ath10k_ce_rx_num_free_bufs(ce_pipe);\n\tspin_unlock_bh(&ce->ce_lock);\n\n\twhile (num >= 0) {\n\t\tret = __ath10k_pci_rx_post_buf(pipe);\n\t\tif (ret) {\n\t\t\tif (ret == -ENOSPC)\n\t\t\t\tbreak;\n\t\t\tath10k_warn(ar, \"failed to post pci rx buf: %d\\n\", ret);\n\t\t\tmod_timer(&ar_pci->rx_post_retry, jiffies +\n\t\t\t\t  ATH10K_PCI_RX_POST_RETRY_MS);\n\t\t\tbreak;\n\t\t}\n\t\tnum--;\n\t}\n}\n\nvoid ath10k_pci_rx_post(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint i;\n\n\tfor (i = 0; i < CE_COUNT; i++)\n\t\tath10k_pci_rx_post_pipe(&ar_pci->pipe_info[i]);\n}\n\nvoid ath10k_pci_rx_replenish_retry(struct timer_list *t)\n{\n\tstruct ath10k_pci *ar_pci = from_timer(ar_pci, t, rx_post_retry);\n\tstruct ath10k *ar = ar_pci->ar;\n\n\tath10k_pci_rx_post(ar);\n}\n\nstatic u32 ath10k_pci_qca988x_targ_cpu_to_ce_addr(struct ath10k *ar, u32 addr)\n{\n\tu32 val = 0, region = addr & 0xfffff;\n\n\tval = (ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS + CORE_CTRL_ADDRESS)\n\t\t\t\t & 0x7ff) << 21;\n\tval |= 0x100000 | region;\n\treturn val;\n}\n\n \nstatic u32 ath10k_pci_qca6174_targ_cpu_to_ce_addr(struct ath10k *ar, u32 addr)\n{\n\tu32 val = 0, region = addr & 0xfffff;\n\n\tval = (ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS + CORE_CTRL_ADDRESS)\n\t\t\t\t & 0x7ff) << 21;\n\tval |= ((addr >= 0x100000) ? 0x100000 : 0) | region;\n\treturn val;\n}\n\nstatic u32 ath10k_pci_qca99x0_targ_cpu_to_ce_addr(struct ath10k *ar, u32 addr)\n{\n\tu32 val = 0, region = addr & 0xfffff;\n\n\tval = ath10k_pci_read32(ar, PCIE_BAR_REG_ADDRESS);\n\tval |= 0x100000 | region;\n\treturn val;\n}\n\nstatic u32 ath10k_pci_targ_cpu_to_ce_addr(struct ath10k *ar, u32 addr)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tif (WARN_ON_ONCE(!ar_pci->targ_cpu_to_ce_addr))\n\t\treturn -ENOTSUPP;\n\n\treturn ar_pci->targ_cpu_to_ce_addr(ar, addr);\n}\n\n \nstatic int ath10k_pci_diag_read_mem(struct ath10k *ar, u32 address, void *data,\n\t\t\t\t    int nbytes)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret = 0;\n\tu32 *buf;\n\tunsigned int completed_nbytes, alloc_nbytes, remaining_bytes;\n\tstruct ath10k_ce_pipe *ce_diag;\n\t \n\tu32 ce_data;\n\tdma_addr_t ce_data_base = 0;\n\tvoid *data_buf;\n\tint i;\n\n\tmutex_lock(&ar_pci->ce_diag_mutex);\n\tce_diag = ar_pci->ce_diag;\n\n\t \n\talloc_nbytes = min_t(unsigned int, nbytes, DIAG_TRANSFER_LIMIT);\n\n\tdata_buf = dma_alloc_coherent(ar->dev, alloc_nbytes, &ce_data_base,\n\t\t\t\t      GFP_ATOMIC);\n\tif (!data_buf) {\n\t\tret = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\t \n\taddress = ath10k_pci_targ_cpu_to_ce_addr(ar, address);\n\n\tremaining_bytes = nbytes;\n\tce_data = ce_data_base;\n\twhile (remaining_bytes) {\n\t\tnbytes = min_t(unsigned int, remaining_bytes,\n\t\t\t       DIAG_TRANSFER_LIMIT);\n\n\t\tret = ath10k_ce_rx_post_buf(ce_diag, &ce_data, ce_data);\n\t\tif (ret != 0)\n\t\t\tgoto done;\n\n\t\t \n\t\tret = ath10k_ce_send(ce_diag, NULL, (u32)address, nbytes, 0, 0);\n\t\tif (ret)\n\t\t\tgoto done;\n\n\t\ti = 0;\n\t\twhile (ath10k_ce_completed_send_next(ce_diag, NULL) != 0) {\n\t\t\tudelay(DIAG_ACCESS_CE_WAIT_US);\n\t\t\ti += DIAG_ACCESS_CE_WAIT_US;\n\n\t\t\tif (i > DIAG_ACCESS_CE_TIMEOUT_US) {\n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\n\t\ti = 0;\n\t\twhile (ath10k_ce_completed_recv_next(ce_diag, (void **)&buf,\n\t\t\t\t\t\t     &completed_nbytes) != 0) {\n\t\t\tudelay(DIAG_ACCESS_CE_WAIT_US);\n\t\t\ti += DIAG_ACCESS_CE_WAIT_US;\n\n\t\t\tif (i > DIAG_ACCESS_CE_TIMEOUT_US) {\n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\n\t\tif (nbytes != completed_nbytes) {\n\t\t\tret = -EIO;\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (*buf != ce_data) {\n\t\t\tret = -EIO;\n\t\t\tgoto done;\n\t\t}\n\n\t\tremaining_bytes -= nbytes;\n\t\tmemcpy(data, data_buf, nbytes);\n\n\t\taddress += nbytes;\n\t\tdata += nbytes;\n\t}\n\ndone:\n\n\tif (data_buf)\n\t\tdma_free_coherent(ar->dev, alloc_nbytes, data_buf,\n\t\t\t\t  ce_data_base);\n\n\tmutex_unlock(&ar_pci->ce_diag_mutex);\n\n\treturn ret;\n}\n\nstatic int ath10k_pci_diag_read32(struct ath10k *ar, u32 address, u32 *value)\n{\n\t__le32 val = 0;\n\tint ret;\n\n\tret = ath10k_pci_diag_read_mem(ar, address, &val, sizeof(val));\n\t*value = __le32_to_cpu(val);\n\n\treturn ret;\n}\n\nstatic int __ath10k_pci_diag_read_hi(struct ath10k *ar, void *dest,\n\t\t\t\t     u32 src, u32 len)\n{\n\tu32 host_addr, addr;\n\tint ret;\n\n\thost_addr = host_interest_item_address(src);\n\n\tret = ath10k_pci_diag_read32(ar, host_addr, &addr);\n\tif (ret != 0) {\n\t\tath10k_warn(ar, \"failed to get memcpy hi address for firmware address %d: %d\\n\",\n\t\t\t    src, ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_diag_read_mem(ar, addr, dest, len);\n\tif (ret != 0) {\n\t\tath10k_warn(ar, \"failed to memcpy firmware memory from %d (%d B): %d\\n\",\n\t\t\t    addr, len, ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\n#define ath10k_pci_diag_read_hi(ar, dest, src, len)\t\t\\\n\t__ath10k_pci_diag_read_hi(ar, dest, HI_ITEM(src), len)\n\nint ath10k_pci_diag_write_mem(struct ath10k *ar, u32 address,\n\t\t\t      const void *data, int nbytes)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret = 0;\n\tu32 *buf;\n\tunsigned int completed_nbytes, alloc_nbytes, remaining_bytes;\n\tstruct ath10k_ce_pipe *ce_diag;\n\tvoid *data_buf;\n\tdma_addr_t ce_data_base = 0;\n\tint i;\n\n\tmutex_lock(&ar_pci->ce_diag_mutex);\n\tce_diag = ar_pci->ce_diag;\n\n\t \n\talloc_nbytes = min_t(unsigned int, nbytes, DIAG_TRANSFER_LIMIT);\n\n\tdata_buf = dma_alloc_coherent(ar->dev, alloc_nbytes, &ce_data_base,\n\t\t\t\t      GFP_ATOMIC);\n\tif (!data_buf) {\n\t\tret = -ENOMEM;\n\t\tgoto done;\n\t}\n\n\t \n\taddress = ath10k_pci_targ_cpu_to_ce_addr(ar, address);\n\n\tremaining_bytes = nbytes;\n\twhile (remaining_bytes) {\n\t\t \n\t\tnbytes = min_t(int, remaining_bytes, DIAG_TRANSFER_LIMIT);\n\n\t\t \n\t\tmemcpy(data_buf, data, nbytes);\n\n\t\t \n\t\tret = ath10k_ce_rx_post_buf(ce_diag, &address, address);\n\t\tif (ret != 0)\n\t\t\tgoto done;\n\n\t\t \n\t\tret = ath10k_ce_send(ce_diag, NULL, ce_data_base, nbytes, 0, 0);\n\t\tif (ret != 0)\n\t\t\tgoto done;\n\n\t\ti = 0;\n\t\twhile (ath10k_ce_completed_send_next(ce_diag, NULL) != 0) {\n\t\t\tudelay(DIAG_ACCESS_CE_WAIT_US);\n\t\t\ti += DIAG_ACCESS_CE_WAIT_US;\n\n\t\t\tif (i > DIAG_ACCESS_CE_TIMEOUT_US) {\n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\n\t\ti = 0;\n\t\twhile (ath10k_ce_completed_recv_next(ce_diag, (void **)&buf,\n\t\t\t\t\t\t     &completed_nbytes) != 0) {\n\t\t\tudelay(DIAG_ACCESS_CE_WAIT_US);\n\t\t\ti += DIAG_ACCESS_CE_WAIT_US;\n\n\t\t\tif (i > DIAG_ACCESS_CE_TIMEOUT_US) {\n\t\t\t\tret = -EBUSY;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\n\t\tif (nbytes != completed_nbytes) {\n\t\t\tret = -EIO;\n\t\t\tgoto done;\n\t\t}\n\n\t\tif (*buf != address) {\n\t\t\tret = -EIO;\n\t\t\tgoto done;\n\t\t}\n\n\t\tremaining_bytes -= nbytes;\n\t\taddress += nbytes;\n\t\tdata += nbytes;\n\t}\n\ndone:\n\tif (data_buf) {\n\t\tdma_free_coherent(ar->dev, alloc_nbytes, data_buf,\n\t\t\t\t  ce_data_base);\n\t}\n\n\tif (ret != 0)\n\t\tath10k_warn(ar, \"failed to write diag value at 0x%x: %d\\n\",\n\t\t\t    address, ret);\n\n\tmutex_unlock(&ar_pci->ce_diag_mutex);\n\n\treturn ret;\n}\n\nstatic int ath10k_pci_diag_write32(struct ath10k *ar, u32 address, u32 value)\n{\n\t__le32 val = __cpu_to_le32(value);\n\n\treturn ath10k_pci_diag_write_mem(ar, address, &val, sizeof(val));\n}\n\n \nstatic void ath10k_pci_htc_tx_cb(struct ath10k_ce_pipe *ce_state)\n{\n\tstruct ath10k *ar = ce_state->ar;\n\tstruct sk_buff_head list;\n\tstruct sk_buff *skb;\n\n\t__skb_queue_head_init(&list);\n\twhile (ath10k_ce_completed_send_next(ce_state, (void **)&skb) == 0) {\n\t\t \n\t\tif (skb == NULL)\n\t\t\tcontinue;\n\n\t\t__skb_queue_tail(&list, skb);\n\t}\n\n\twhile ((skb = __skb_dequeue(&list)))\n\t\tath10k_htc_tx_completion_handler(ar, skb);\n}\n\nstatic void ath10k_pci_process_rx_cb(struct ath10k_ce_pipe *ce_state,\n\t\t\t\t     void (*callback)(struct ath10k *ar,\n\t\t\t\t\t\t      struct sk_buff *skb))\n{\n\tstruct ath10k *ar = ce_state->ar;\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct ath10k_pci_pipe *pipe_info =  &ar_pci->pipe_info[ce_state->id];\n\tstruct sk_buff *skb;\n\tstruct sk_buff_head list;\n\tvoid *transfer_context;\n\tunsigned int nbytes, max_nbytes;\n\n\t__skb_queue_head_init(&list);\n\twhile (ath10k_ce_completed_recv_next(ce_state, &transfer_context,\n\t\t\t\t\t     &nbytes) == 0) {\n\t\tskb = transfer_context;\n\t\tmax_nbytes = skb->len + skb_tailroom(skb);\n\t\tdma_unmap_single(ar->dev, ATH10K_SKB_RXCB(skb)->paddr,\n\t\t\t\t max_nbytes, DMA_FROM_DEVICE);\n\n\t\tif (unlikely(max_nbytes < nbytes)) {\n\t\t\tath10k_warn(ar, \"rxed more than expected (nbytes %d, max %d)\",\n\t\t\t\t    nbytes, max_nbytes);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tskb_put(skb, nbytes);\n\t\t__skb_queue_tail(&list, skb);\n\t}\n\n\twhile ((skb = __skb_dequeue(&list))) {\n\t\tath10k_dbg(ar, ATH10K_DBG_PCI, \"pci rx ce pipe %d len %d\\n\",\n\t\t\t   ce_state->id, skb->len);\n\t\tath10k_dbg_dump(ar, ATH10K_DBG_PCI_DUMP, NULL, \"pci rx: \",\n\t\t\t\tskb->data, skb->len);\n\n\t\tcallback(ar, skb);\n\t}\n\n\tath10k_pci_rx_post_pipe(pipe_info);\n}\n\nstatic void ath10k_pci_process_htt_rx_cb(struct ath10k_ce_pipe *ce_state,\n\t\t\t\t\t void (*callback)(struct ath10k *ar,\n\t\t\t\t\t\t\t  struct sk_buff *skb))\n{\n\tstruct ath10k *ar = ce_state->ar;\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct ath10k_pci_pipe *pipe_info =  &ar_pci->pipe_info[ce_state->id];\n\tstruct ath10k_ce_pipe *ce_pipe = pipe_info->ce_hdl;\n\tstruct sk_buff *skb;\n\tstruct sk_buff_head list;\n\tvoid *transfer_context;\n\tunsigned int nbytes, max_nbytes, nentries;\n\tint orig_len;\n\n\t \n\t__skb_queue_head_init(&list);\n\twhile (ath10k_ce_completed_recv_next_nolock(ce_state, &transfer_context,\n\t\t\t\t\t\t    &nbytes) == 0) {\n\t\tskb = transfer_context;\n\t\tmax_nbytes = skb->len + skb_tailroom(skb);\n\n\t\tif (unlikely(max_nbytes < nbytes)) {\n\t\t\tath10k_warn(ar, \"rxed more than expected (nbytes %d, max %d)\",\n\t\t\t\t    nbytes, max_nbytes);\n\t\t\tcontinue;\n\t\t}\n\n\t\tdma_sync_single_for_cpu(ar->dev, ATH10K_SKB_RXCB(skb)->paddr,\n\t\t\t\t\tmax_nbytes, DMA_FROM_DEVICE);\n\t\tskb_put(skb, nbytes);\n\t\t__skb_queue_tail(&list, skb);\n\t}\n\n\tnentries = skb_queue_len(&list);\n\twhile ((skb = __skb_dequeue(&list))) {\n\t\tath10k_dbg(ar, ATH10K_DBG_PCI, \"pci rx ce pipe %d len %d\\n\",\n\t\t\t   ce_state->id, skb->len);\n\t\tath10k_dbg_dump(ar, ATH10K_DBG_PCI_DUMP, NULL, \"pci rx: \",\n\t\t\t\tskb->data, skb->len);\n\n\t\torig_len = skb->len;\n\t\tcallback(ar, skb);\n\t\tskb_push(skb, orig_len - skb->len);\n\t\tskb_reset_tail_pointer(skb);\n\t\tskb_trim(skb, 0);\n\n\t\t \n\t\tdma_sync_single_for_device(ar->dev, ATH10K_SKB_RXCB(skb)->paddr,\n\t\t\t\t\t   skb->len + skb_tailroom(skb),\n\t\t\t\t\t   DMA_FROM_DEVICE);\n\t}\n\tath10k_ce_rx_update_write_idx(ce_pipe, nentries);\n}\n\n \nstatic void ath10k_pci_htc_rx_cb(struct ath10k_ce_pipe *ce_state)\n{\n\tath10k_pci_process_rx_cb(ce_state, ath10k_htc_rx_completion_handler);\n}\n\nstatic void ath10k_pci_htt_htc_rx_cb(struct ath10k_ce_pipe *ce_state)\n{\n\t \n\tath10k_ce_per_engine_service(ce_state->ar, 4);\n\n\tath10k_pci_process_rx_cb(ce_state, ath10k_htc_rx_completion_handler);\n}\n\n \nstatic void ath10k_pci_pktlog_rx_cb(struct ath10k_ce_pipe *ce_state)\n{\n\tath10k_pci_process_rx_cb(ce_state,\n\t\t\t\t ath10k_htt_rx_pktlog_completion_handler);\n}\n\n \nstatic void ath10k_pci_htt_tx_cb(struct ath10k_ce_pipe *ce_state)\n{\n\tstruct ath10k *ar = ce_state->ar;\n\tstruct sk_buff *skb;\n\n\twhile (ath10k_ce_completed_send_next(ce_state, (void **)&skb) == 0) {\n\t\t \n\t\tif (!skb)\n\t\t\tcontinue;\n\n\t\tdma_unmap_single(ar->dev, ATH10K_SKB_CB(skb)->paddr,\n\t\t\t\t skb->len, DMA_TO_DEVICE);\n\t\tath10k_htt_hif_tx_complete(ar, skb);\n\t}\n}\n\nstatic void ath10k_pci_htt_rx_deliver(struct ath10k *ar, struct sk_buff *skb)\n{\n\tskb_pull(skb, sizeof(struct ath10k_htc_hdr));\n\tath10k_htt_t2h_msg_handler(ar, skb);\n}\n\n \nstatic void ath10k_pci_htt_rx_cb(struct ath10k_ce_pipe *ce_state)\n{\n\t \n\tath10k_ce_per_engine_service(ce_state->ar, 4);\n\n\tath10k_pci_process_htt_rx_cb(ce_state, ath10k_pci_htt_rx_deliver);\n}\n\nint ath10k_pci_hif_tx_sg(struct ath10k *ar, u8 pipe_id,\n\t\t\t struct ath10k_hif_sg_item *items, int n_items)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\tstruct ath10k_pci_pipe *pci_pipe = &ar_pci->pipe_info[pipe_id];\n\tstruct ath10k_ce_pipe *ce_pipe = pci_pipe->ce_hdl;\n\tstruct ath10k_ce_ring *src_ring = ce_pipe->src_ring;\n\tunsigned int nentries_mask;\n\tunsigned int sw_index;\n\tunsigned int write_index;\n\tint err, i = 0;\n\n\tspin_lock_bh(&ce->ce_lock);\n\n\tnentries_mask = src_ring->nentries_mask;\n\tsw_index = src_ring->sw_index;\n\twrite_index = src_ring->write_index;\n\n\tif (unlikely(CE_RING_DELTA(nentries_mask,\n\t\t\t\t   write_index, sw_index - 1) < n_items)) {\n\t\terr = -ENOBUFS;\n\t\tgoto err;\n\t}\n\n\tfor (i = 0; i < n_items - 1; i++) {\n\t\tath10k_dbg(ar, ATH10K_DBG_PCI,\n\t\t\t   \"pci tx item %d paddr %pad len %d n_items %d\\n\",\n\t\t\t   i, &items[i].paddr, items[i].len, n_items);\n\t\tath10k_dbg_dump(ar, ATH10K_DBG_PCI_DUMP, NULL, \"pci tx data: \",\n\t\t\t\titems[i].vaddr, items[i].len);\n\n\t\terr = ath10k_ce_send_nolock(ce_pipe,\n\t\t\t\t\t    items[i].transfer_context,\n\t\t\t\t\t    items[i].paddr,\n\t\t\t\t\t    items[i].len,\n\t\t\t\t\t    items[i].transfer_id,\n\t\t\t\t\t    CE_SEND_FLAG_GATHER);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\t \n\n\tath10k_dbg(ar, ATH10K_DBG_PCI,\n\t\t   \"pci tx item %d paddr %pad len %d n_items %d\\n\",\n\t\t   i, &items[i].paddr, items[i].len, n_items);\n\tath10k_dbg_dump(ar, ATH10K_DBG_PCI_DUMP, NULL, \"pci tx data: \",\n\t\t\titems[i].vaddr, items[i].len);\n\n\terr = ath10k_ce_send_nolock(ce_pipe,\n\t\t\t\t    items[i].transfer_context,\n\t\t\t\t    items[i].paddr,\n\t\t\t\t    items[i].len,\n\t\t\t\t    items[i].transfer_id,\n\t\t\t\t    0);\n\tif (err)\n\t\tgoto err;\n\n\tspin_unlock_bh(&ce->ce_lock);\n\treturn 0;\n\nerr:\n\tfor (; i > 0; i--)\n\t\t__ath10k_ce_send_revert(ce_pipe);\n\n\tspin_unlock_bh(&ce->ce_lock);\n\treturn err;\n}\n\nint ath10k_pci_hif_diag_read(struct ath10k *ar, u32 address, void *buf,\n\t\t\t     size_t buf_len)\n{\n\treturn ath10k_pci_diag_read_mem(ar, address, buf, buf_len);\n}\n\nu16 ath10k_pci_hif_get_free_queue_number(struct ath10k *ar, u8 pipe)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI, \"pci hif get free queue number\\n\");\n\n\treturn ath10k_ce_num_free_src_entries(ar_pci->pipe_info[pipe].ce_hdl);\n}\n\nstatic void ath10k_pci_dump_registers(struct ath10k *ar,\n\t\t\t\t      struct ath10k_fw_crash_data *crash_data)\n{\n\t__le32 reg_dump_values[REG_DUMP_COUNT_QCA988X] = {};\n\tint i, ret;\n\n\tlockdep_assert_held(&ar->dump_mutex);\n\n\tret = ath10k_pci_diag_read_hi(ar, &reg_dump_values[0],\n\t\t\t\t      hi_failure_state,\n\t\t\t\t      REG_DUMP_COUNT_QCA988X * sizeof(__le32));\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to read firmware dump area: %d\\n\", ret);\n\t\treturn;\n\t}\n\n\tBUILD_BUG_ON(REG_DUMP_COUNT_QCA988X % 4);\n\n\tath10k_err(ar, \"firmware register dump:\\n\");\n\tfor (i = 0; i < REG_DUMP_COUNT_QCA988X; i += 4)\n\t\tath10k_err(ar, \"[%02d]: 0x%08X 0x%08X 0x%08X 0x%08X\\n\",\n\t\t\t   i,\n\t\t\t   __le32_to_cpu(reg_dump_values[i]),\n\t\t\t   __le32_to_cpu(reg_dump_values[i + 1]),\n\t\t\t   __le32_to_cpu(reg_dump_values[i + 2]),\n\t\t\t   __le32_to_cpu(reg_dump_values[i + 3]));\n\n\tif (!crash_data)\n\t\treturn;\n\n\tfor (i = 0; i < REG_DUMP_COUNT_QCA988X; i++)\n\t\tcrash_data->registers[i] = reg_dump_values[i];\n}\n\nstatic int ath10k_pci_dump_memory_section(struct ath10k *ar,\n\t\t\t\t\t  const struct ath10k_mem_region *mem_region,\n\t\t\t\t\t  u8 *buf, size_t buf_len)\n{\n\tconst struct ath10k_mem_section *cur_section, *next_section;\n\tunsigned int count, section_size, skip_size;\n\tint ret, i, j;\n\n\tif (!mem_region || !buf)\n\t\treturn 0;\n\n\tcur_section = &mem_region->section_table.sections[0];\n\n\tif (mem_region->start > cur_section->start) {\n\t\tath10k_warn(ar, \"incorrect memdump region 0x%x with section start address 0x%x.\\n\",\n\t\t\t    mem_region->start, cur_section->start);\n\t\treturn 0;\n\t}\n\n\tskip_size = cur_section->start - mem_region->start;\n\n\t \n\tfor (i = 0; i < skip_size; i++) {\n\t\t*buf = ATH10K_MAGIC_NOT_COPIED;\n\t\tbuf++;\n\t}\n\n\tcount = 0;\n\n\tfor (i = 0; cur_section != NULL; i++) {\n\t\tsection_size = cur_section->end - cur_section->start;\n\n\t\tif (section_size <= 0) {\n\t\t\tath10k_warn(ar, \"incorrect ramdump format with start address 0x%x and stop address 0x%x\\n\",\n\t\t\t\t    cur_section->start,\n\t\t\t\t    cur_section->end);\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((i + 1) == mem_region->section_table.size) {\n\t\t\t \n\t\t\tnext_section = NULL;\n\t\t\tskip_size = 0;\n\t\t} else {\n\t\t\tnext_section = cur_section + 1;\n\n\t\t\tif (cur_section->end > next_section->start) {\n\t\t\t\tath10k_warn(ar, \"next ramdump section 0x%x is smaller than current end address 0x%x\\n\",\n\t\t\t\t\t    next_section->start,\n\t\t\t\t\t    cur_section->end);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tskip_size = next_section->start - cur_section->end;\n\t\t}\n\n\t\tif (buf_len < (skip_size + section_size)) {\n\t\t\tath10k_warn(ar, \"ramdump buffer is too small: %zu\\n\", buf_len);\n\t\t\tbreak;\n\t\t}\n\n\t\tbuf_len -= skip_size + section_size;\n\n\t\t \n\t\tret = ath10k_pci_diag_read_mem(ar, cur_section->start,\n\t\t\t\t\t       buf, section_size);\n\t\tif (ret) {\n\t\t\tath10k_warn(ar, \"failed to read ramdump from section 0x%x: %d\\n\",\n\t\t\t\t    cur_section->start, ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tbuf += section_size;\n\t\tcount += section_size;\n\n\t\t \n\t\tfor (j = 0; j < skip_size; j++) {\n\t\t\t*buf = ATH10K_MAGIC_NOT_COPIED;\n\t\t\tbuf++;\n\t\t}\n\n\t\tcount += skip_size;\n\n\t\tif (!next_section)\n\t\t\t \n\t\t\tbreak;\n\n\t\tcur_section = next_section;\n\t}\n\n\treturn count;\n}\n\nstatic int ath10k_pci_set_ram_config(struct ath10k *ar, u32 config)\n{\n\tu32 val;\n\n\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t   FW_RAM_CONFIG_ADDRESS, config);\n\n\tval = ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\tFW_RAM_CONFIG_ADDRESS);\n\tif (val != config) {\n\t\tath10k_warn(ar, \"failed to set RAM config from 0x%x to 0x%x\\n\",\n\t\t\t    val, config);\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int ath10k_pci_dump_memory_sram(struct ath10k *ar,\n\t\t\t\t       const struct ath10k_mem_region *region,\n\t\t\t\t       u8 *buf)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tu32 base_addr, i;\n\n\tbase_addr = ioread32(ar_pci->mem + QCA99X0_PCIE_BAR0_START_REG);\n\tbase_addr += region->start;\n\n\tfor (i = 0; i < region->len; i += 4) {\n\t\tiowrite32(base_addr + i, ar_pci->mem + QCA99X0_CPU_MEM_ADDR_REG);\n\t\t*(u32 *)(buf + i) = ioread32(ar_pci->mem + QCA99X0_CPU_MEM_DATA_REG);\n\t}\n\n\treturn region->len;\n}\n\n \nstatic int ath10k_pci_dump_memory_reg(struct ath10k *ar,\n\t\t\t\t      const struct ath10k_mem_region *region,\n\t\t\t\t      u8 *buf)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tu32 i;\n\tint ret;\n\n\tmutex_lock(&ar->conf_mutex);\n\tif (ar->state != ATH10K_STATE_ON) {\n\t\tath10k_warn(ar, \"Skipping pci_dump_memory_reg invalid state\\n\");\n\t\tret = -EIO;\n\t\tgoto done;\n\t}\n\n\tfor (i = 0; i < region->len; i += 4)\n\t\t*(u32 *)(buf + i) = ioread32(ar_pci->mem + region->start + i);\n\n\tret = region->len;\ndone:\n\tmutex_unlock(&ar->conf_mutex);\n\treturn ret;\n}\n\n \nstatic int ath10k_pci_dump_memory_generic(struct ath10k *ar,\n\t\t\t\t\t  const struct ath10k_mem_region *current_region,\n\t\t\t\t\t  u8 *buf)\n{\n\tint ret;\n\n\tif (current_region->section_table.size > 0)\n\t\t \n\t\treturn ath10k_pci_dump_memory_section(ar,\n\t\t\t\t\t\t      current_region,\n\t\t\t\t\t\t      buf,\n\t\t\t\t\t\t      current_region->len);\n\n\t \n\tret = ath10k_pci_diag_read_mem(ar,\n\t\t\t\t       current_region->start,\n\t\t\t\t       buf,\n\t\t\t\t       current_region->len);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to copy ramdump region %s: %d\\n\",\n\t\t\t    current_region->name, ret);\n\t\treturn ret;\n\t}\n\n\treturn current_region->len;\n}\n\nstatic void ath10k_pci_dump_memory(struct ath10k *ar,\n\t\t\t\t   struct ath10k_fw_crash_data *crash_data)\n{\n\tconst struct ath10k_hw_mem_layout *mem_layout;\n\tconst struct ath10k_mem_region *current_region;\n\tstruct ath10k_dump_ram_data_hdr *hdr;\n\tu32 count, shift;\n\tsize_t buf_len;\n\tint ret, i;\n\tu8 *buf;\n\n\tlockdep_assert_held(&ar->dump_mutex);\n\n\tif (!crash_data)\n\t\treturn;\n\n\tmem_layout = ath10k_coredump_get_mem_layout(ar);\n\tif (!mem_layout)\n\t\treturn;\n\n\tcurrent_region = &mem_layout->region_table.regions[0];\n\n\tbuf = crash_data->ramdump_buf;\n\tbuf_len = crash_data->ramdump_buf_len;\n\n\tmemset(buf, 0, buf_len);\n\n\tfor (i = 0; i < mem_layout->region_table.size; i++) {\n\t\tcount = 0;\n\n\t\tif (current_region->len > buf_len) {\n\t\t\tath10k_warn(ar, \"memory region %s size %d is larger that remaining ramdump buffer size %zu\\n\",\n\t\t\t\t    current_region->name,\n\t\t\t\t    current_region->len,\n\t\t\t\t    buf_len);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (current_region->type == ATH10K_MEM_REGION_TYPE_IRAM1 ||\n\t\t    current_region->type == ATH10K_MEM_REGION_TYPE_IRAM2) {\n\t\t\tshift = current_region->start >> 20;\n\n\t\t\tret = ath10k_pci_set_ram_config(ar, shift);\n\t\t\tif (ret) {\n\t\t\t\tath10k_warn(ar, \"failed to switch ram config to IRAM for section %s: %d\\n\",\n\t\t\t\t\t    current_region->name, ret);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\thdr = (void *)buf;\n\t\tbuf += sizeof(*hdr);\n\t\tbuf_len -= sizeof(*hdr);\n\n\t\tswitch (current_region->type) {\n\t\tcase ATH10K_MEM_REGION_TYPE_IOSRAM:\n\t\t\tcount = ath10k_pci_dump_memory_sram(ar, current_region, buf);\n\t\t\tbreak;\n\t\tcase ATH10K_MEM_REGION_TYPE_IOREG:\n\t\t\tret = ath10k_pci_dump_memory_reg(ar, current_region, buf);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\n\t\t\tcount = ret;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tret = ath10k_pci_dump_memory_generic(ar, current_region, buf);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\n\t\t\tcount = ret;\n\t\t\tbreak;\n\t\t}\n\n\t\thdr->region_type = cpu_to_le32(current_region->type);\n\t\thdr->start = cpu_to_le32(current_region->start);\n\t\thdr->length = cpu_to_le32(count);\n\n\t\tif (count == 0)\n\t\t\t \n\t\t\tbreak;\n\n\t\tbuf += count;\n\t\tbuf_len -= count;\n\n\t\tcurrent_region++;\n\t}\n}\n\nstatic void ath10k_pci_fw_dump_work(struct work_struct *work)\n{\n\tstruct ath10k_pci *ar_pci = container_of(work, struct ath10k_pci,\n\t\t\t\t\t\t dump_work);\n\tstruct ath10k_fw_crash_data *crash_data;\n\tstruct ath10k *ar = ar_pci->ar;\n\tchar guid[UUID_STRING_LEN + 1];\n\n\tmutex_lock(&ar->dump_mutex);\n\n\tspin_lock_bh(&ar->data_lock);\n\tar->stats.fw_crash_counter++;\n\tspin_unlock_bh(&ar->data_lock);\n\n\tcrash_data = ath10k_coredump_new(ar);\n\n\tif (crash_data)\n\t\tscnprintf(guid, sizeof(guid), \"%pUl\", &crash_data->guid);\n\telse\n\t\tscnprintf(guid, sizeof(guid), \"n/a\");\n\n\tath10k_err(ar, \"firmware crashed! (guid %s)\\n\", guid);\n\tath10k_print_driver_info(ar);\n\tath10k_pci_dump_registers(ar, crash_data);\n\tath10k_ce_dump_registers(ar, crash_data);\n\tath10k_pci_dump_memory(ar, crash_data);\n\n\tmutex_unlock(&ar->dump_mutex);\n\n\tath10k_core_start_recovery(ar);\n}\n\nstatic void ath10k_pci_fw_crashed_dump(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tqueue_work(ar->workqueue, &ar_pci->dump_work);\n}\n\nvoid ath10k_pci_hif_send_complete_check(struct ath10k *ar, u8 pipe,\n\t\t\t\t\tint force)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI, \"pci hif send complete check\\n\");\n\n\tif (!force) {\n\t\tint resources;\n\t\t \n\t\tresources = ath10k_pci_hif_get_free_queue_number(ar, pipe);\n\n\t\t \n\t\tif (resources > (ar_pci->attr[pipe].src_nentries >> 1))\n\t\t\treturn;\n\t}\n\tath10k_ce_per_engine_service(ar, pipe);\n}\n\nstatic void ath10k_pci_rx_retry_sync(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tdel_timer_sync(&ar_pci->rx_post_retry);\n}\n\nint ath10k_pci_hif_map_service_to_pipe(struct ath10k *ar, u16 service_id,\n\t\t\t\t       u8 *ul_pipe, u8 *dl_pipe)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tconst struct ce_service_to_pipe *entry;\n\tbool ul_set = false, dl_set = false;\n\tint i;\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI, \"pci hif map service\\n\");\n\n\tfor (i = 0; i < ARRAY_SIZE(pci_target_service_to_ce_map_wlan); i++) {\n\t\tentry = &ar_pci->serv_to_pipe[i];\n\n\t\tif (__le32_to_cpu(entry->service_id) != service_id)\n\t\t\tcontinue;\n\n\t\tswitch (__le32_to_cpu(entry->pipedir)) {\n\t\tcase PIPEDIR_NONE:\n\t\t\tbreak;\n\t\tcase PIPEDIR_IN:\n\t\t\tWARN_ON(dl_set);\n\t\t\t*dl_pipe = __le32_to_cpu(entry->pipenum);\n\t\t\tdl_set = true;\n\t\t\tbreak;\n\t\tcase PIPEDIR_OUT:\n\t\t\tWARN_ON(ul_set);\n\t\t\t*ul_pipe = __le32_to_cpu(entry->pipenum);\n\t\t\tul_set = true;\n\t\t\tbreak;\n\t\tcase PIPEDIR_INOUT:\n\t\t\tWARN_ON(dl_set);\n\t\t\tWARN_ON(ul_set);\n\t\t\t*dl_pipe = __le32_to_cpu(entry->pipenum);\n\t\t\t*ul_pipe = __le32_to_cpu(entry->pipenum);\n\t\t\tdl_set = true;\n\t\t\tul_set = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!ul_set || !dl_set)\n\t\treturn -ENOENT;\n\n\treturn 0;\n}\n\nvoid ath10k_pci_hif_get_default_pipe(struct ath10k *ar,\n\t\t\t\t     u8 *ul_pipe, u8 *dl_pipe)\n{\n\tath10k_dbg(ar, ATH10K_DBG_PCI, \"pci hif get default pipe\\n\");\n\n\t(void)ath10k_pci_hif_map_service_to_pipe(ar,\n\t\t\t\t\t\t ATH10K_HTC_SVC_ID_RSVD_CTRL,\n\t\t\t\t\t\t ul_pipe, dl_pipe);\n}\n\nvoid ath10k_pci_irq_msi_fw_mask(struct ath10k *ar)\n{\n\tu32 val;\n\n\tswitch (ar->hw_rev) {\n\tcase ATH10K_HW_QCA988X:\n\tcase ATH10K_HW_QCA9887:\n\tcase ATH10K_HW_QCA6174:\n\tcase ATH10K_HW_QCA9377:\n\t\tval = ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\t\tCORE_CTRL_ADDRESS);\n\t\tval &= ~CORE_CTRL_PCIE_REG_31_MASK;\n\t\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\t   CORE_CTRL_ADDRESS, val);\n\t\tbreak;\n\tcase ATH10K_HW_QCA99X0:\n\tcase ATH10K_HW_QCA9984:\n\tcase ATH10K_HW_QCA9888:\n\tcase ATH10K_HW_QCA4019:\n\t\t \n\t\tbreak;\n\tcase ATH10K_HW_WCN3990:\n\t\tbreak;\n\t}\n}\n\nstatic void ath10k_pci_irq_msi_fw_unmask(struct ath10k *ar)\n{\n\tu32 val;\n\n\tswitch (ar->hw_rev) {\n\tcase ATH10K_HW_QCA988X:\n\tcase ATH10K_HW_QCA9887:\n\tcase ATH10K_HW_QCA6174:\n\tcase ATH10K_HW_QCA9377:\n\t\tval = ath10k_pci_read32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\t\tCORE_CTRL_ADDRESS);\n\t\tval |= CORE_CTRL_PCIE_REG_31_MASK;\n\t\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS +\n\t\t\t\t   CORE_CTRL_ADDRESS, val);\n\t\tbreak;\n\tcase ATH10K_HW_QCA99X0:\n\tcase ATH10K_HW_QCA9984:\n\tcase ATH10K_HW_QCA9888:\n\tcase ATH10K_HW_QCA4019:\n\t\t \n\t\tbreak;\n\tcase ATH10K_HW_WCN3990:\n\t\tbreak;\n\t}\n}\n\nstatic void ath10k_pci_irq_disable(struct ath10k *ar)\n{\n\tath10k_ce_disable_interrupts(ar);\n\tath10k_pci_disable_and_clear_legacy_irq(ar);\n\tath10k_pci_irq_msi_fw_mask(ar);\n}\n\nstatic void ath10k_pci_irq_sync(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tsynchronize_irq(ar_pci->pdev->irq);\n}\n\nstatic void ath10k_pci_irq_enable(struct ath10k *ar)\n{\n\tath10k_ce_enable_interrupts(ar);\n\tath10k_pci_enable_legacy_irq(ar);\n\tath10k_pci_irq_msi_fw_unmask(ar);\n}\n\nstatic int ath10k_pci_hif_start(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot hif start\\n\");\n\n\tath10k_core_napi_enable(ar);\n\n\tath10k_pci_irq_enable(ar);\n\tath10k_pci_rx_post(ar);\n\n\tpcie_capability_clear_and_set_word(ar_pci->pdev, PCI_EXP_LNKCTL,\n\t\t\t\t\t   PCI_EXP_LNKCTL_ASPMC,\n\t\t\t\t\t   ar_pci->link_ctl & PCI_EXP_LNKCTL_ASPMC);\n\n\treturn 0;\n}\n\nstatic void ath10k_pci_rx_pipe_cleanup(struct ath10k_pci_pipe *pci_pipe)\n{\n\tstruct ath10k *ar;\n\tstruct ath10k_ce_pipe *ce_pipe;\n\tstruct ath10k_ce_ring *ce_ring;\n\tstruct sk_buff *skb;\n\tint i;\n\n\tar = pci_pipe->hif_ce_state;\n\tce_pipe = pci_pipe->ce_hdl;\n\tce_ring = ce_pipe->dest_ring;\n\n\tif (!ce_ring)\n\t\treturn;\n\n\tif (!pci_pipe->buf_sz)\n\t\treturn;\n\n\tfor (i = 0; i < ce_ring->nentries; i++) {\n\t\tskb = ce_ring->per_transfer_context[i];\n\t\tif (!skb)\n\t\t\tcontinue;\n\n\t\tce_ring->per_transfer_context[i] = NULL;\n\n\t\tdma_unmap_single(ar->dev, ATH10K_SKB_RXCB(skb)->paddr,\n\t\t\t\t skb->len + skb_tailroom(skb),\n\t\t\t\t DMA_FROM_DEVICE);\n\t\tdev_kfree_skb_any(skb);\n\t}\n}\n\nstatic void ath10k_pci_tx_pipe_cleanup(struct ath10k_pci_pipe *pci_pipe)\n{\n\tstruct ath10k *ar;\n\tstruct ath10k_ce_pipe *ce_pipe;\n\tstruct ath10k_ce_ring *ce_ring;\n\tstruct sk_buff *skb;\n\tint i;\n\n\tar = pci_pipe->hif_ce_state;\n\tce_pipe = pci_pipe->ce_hdl;\n\tce_ring = ce_pipe->src_ring;\n\n\tif (!ce_ring)\n\t\treturn;\n\n\tif (!pci_pipe->buf_sz)\n\t\treturn;\n\n\tfor (i = 0; i < ce_ring->nentries; i++) {\n\t\tskb = ce_ring->per_transfer_context[i];\n\t\tif (!skb)\n\t\t\tcontinue;\n\n\t\tce_ring->per_transfer_context[i] = NULL;\n\n\t\tath10k_htc_tx_completion_handler(ar, skb);\n\t}\n}\n\n \nstatic void ath10k_pci_buffer_cleanup(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint pipe_num;\n\n\tfor (pipe_num = 0; pipe_num < CE_COUNT; pipe_num++) {\n\t\tstruct ath10k_pci_pipe *pipe_info;\n\n\t\tpipe_info = &ar_pci->pipe_info[pipe_num];\n\t\tath10k_pci_rx_pipe_cleanup(pipe_info);\n\t\tath10k_pci_tx_pipe_cleanup(pipe_info);\n\t}\n}\n\nvoid ath10k_pci_ce_deinit(struct ath10k *ar)\n{\n\tint i;\n\n\tfor (i = 0; i < CE_COUNT; i++)\n\t\tath10k_ce_deinit_pipe(ar, i);\n}\n\nvoid ath10k_pci_flush(struct ath10k *ar)\n{\n\tath10k_pci_rx_retry_sync(ar);\n\tath10k_pci_buffer_cleanup(ar);\n}\n\nstatic void ath10k_pci_hif_stop(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tunsigned long flags;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot hif stop\\n\");\n\n\tath10k_pci_irq_disable(ar);\n\tath10k_pci_irq_sync(ar);\n\n\tath10k_core_napi_sync_disable(ar);\n\n\tcancel_work_sync(&ar_pci->dump_work);\n\n\t \n\tath10k_pci_safe_chip_reset(ar);\n\n\tath10k_pci_flush(ar);\n\n\tspin_lock_irqsave(&ar_pci->ps_lock, flags);\n\tWARN_ON(ar_pci->ps_wake_refcount > 0);\n\tspin_unlock_irqrestore(&ar_pci->ps_lock, flags);\n}\n\nint ath10k_pci_hif_exchange_bmi_msg(struct ath10k *ar,\n\t\t\t\t    void *req, u32 req_len,\n\t\t\t\t    void *resp, u32 *resp_len)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct ath10k_pci_pipe *pci_tx = &ar_pci->pipe_info[BMI_CE_NUM_TO_TARG];\n\tstruct ath10k_pci_pipe *pci_rx = &ar_pci->pipe_info[BMI_CE_NUM_TO_HOST];\n\tstruct ath10k_ce_pipe *ce_tx = pci_tx->ce_hdl;\n\tstruct ath10k_ce_pipe *ce_rx = pci_rx->ce_hdl;\n\tdma_addr_t req_paddr = 0;\n\tdma_addr_t resp_paddr = 0;\n\tstruct bmi_xfer xfer = {};\n\tvoid *treq, *tresp = NULL;\n\tint ret = 0;\n\n\tmight_sleep();\n\n\tif (resp && !resp_len)\n\t\treturn -EINVAL;\n\n\tif (resp && resp_len && *resp_len == 0)\n\t\treturn -EINVAL;\n\n\ttreq = kmemdup(req, req_len, GFP_KERNEL);\n\tif (!treq)\n\t\treturn -ENOMEM;\n\n\treq_paddr = dma_map_single(ar->dev, treq, req_len, DMA_TO_DEVICE);\n\tret = dma_mapping_error(ar->dev, req_paddr);\n\tif (ret) {\n\t\tret = -EIO;\n\t\tgoto err_dma;\n\t}\n\n\tif (resp && resp_len) {\n\t\ttresp = kzalloc(*resp_len, GFP_KERNEL);\n\t\tif (!tresp) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_req;\n\t\t}\n\n\t\tresp_paddr = dma_map_single(ar->dev, tresp, *resp_len,\n\t\t\t\t\t    DMA_FROM_DEVICE);\n\t\tret = dma_mapping_error(ar->dev, resp_paddr);\n\t\tif (ret) {\n\t\t\tret = -EIO;\n\t\t\tgoto err_req;\n\t\t}\n\n\t\txfer.wait_for_resp = true;\n\t\txfer.resp_len = 0;\n\n\t\tath10k_ce_rx_post_buf(ce_rx, &xfer, resp_paddr);\n\t}\n\n\tret = ath10k_ce_send(ce_tx, &xfer, req_paddr, req_len, -1, 0);\n\tif (ret)\n\t\tgoto err_resp;\n\n\tret = ath10k_pci_bmi_wait(ar, ce_tx, ce_rx, &xfer);\n\tif (ret) {\n\t\tdma_addr_t unused_buffer;\n\t\tunsigned int unused_nbytes;\n\t\tunsigned int unused_id;\n\n\t\tath10k_ce_cancel_send_next(ce_tx, NULL, &unused_buffer,\n\t\t\t\t\t   &unused_nbytes, &unused_id);\n\t} else {\n\t\t \n\t\tret = 0;\n\t}\n\nerr_resp:\n\tif (resp) {\n\t\tdma_addr_t unused_buffer;\n\n\t\tath10k_ce_revoke_recv_next(ce_rx, NULL, &unused_buffer);\n\t\tdma_unmap_single(ar->dev, resp_paddr,\n\t\t\t\t *resp_len, DMA_FROM_DEVICE);\n\t}\nerr_req:\n\tdma_unmap_single(ar->dev, req_paddr, req_len, DMA_TO_DEVICE);\n\n\tif (ret == 0 && resp_len) {\n\t\t*resp_len = min(*resp_len, xfer.resp_len);\n\t\tmemcpy(resp, tresp, *resp_len);\n\t}\nerr_dma:\n\tkfree(treq);\n\tkfree(tresp);\n\n\treturn ret;\n}\n\nstatic void ath10k_pci_bmi_send_done(struct ath10k_ce_pipe *ce_state)\n{\n\tstruct bmi_xfer *xfer;\n\n\tif (ath10k_ce_completed_send_next(ce_state, (void **)&xfer))\n\t\treturn;\n\n\txfer->tx_done = true;\n}\n\nstatic void ath10k_pci_bmi_recv_data(struct ath10k_ce_pipe *ce_state)\n{\n\tstruct ath10k *ar = ce_state->ar;\n\tstruct bmi_xfer *xfer;\n\tunsigned int nbytes;\n\n\tif (ath10k_ce_completed_recv_next(ce_state, (void **)&xfer,\n\t\t\t\t\t  &nbytes))\n\t\treturn;\n\n\tif (WARN_ON_ONCE(!xfer))\n\t\treturn;\n\n\tif (!xfer->wait_for_resp) {\n\t\tath10k_warn(ar, \"unexpected: BMI data received; ignoring\\n\");\n\t\treturn;\n\t}\n\n\txfer->resp_len = nbytes;\n\txfer->rx_done = true;\n}\n\nstatic int ath10k_pci_bmi_wait(struct ath10k *ar,\n\t\t\t       struct ath10k_ce_pipe *tx_pipe,\n\t\t\t       struct ath10k_ce_pipe *rx_pipe,\n\t\t\t       struct bmi_xfer *xfer)\n{\n\tunsigned long timeout = jiffies + BMI_COMMUNICATION_TIMEOUT_HZ;\n\tunsigned long started = jiffies;\n\tunsigned long dur;\n\tint ret;\n\n\twhile (time_before_eq(jiffies, timeout)) {\n\t\tath10k_pci_bmi_send_done(tx_pipe);\n\t\tath10k_pci_bmi_recv_data(rx_pipe);\n\n\t\tif (xfer->tx_done && (xfer->rx_done == xfer->wait_for_resp)) {\n\t\t\tret = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\tschedule();\n\t}\n\n\tret = -ETIMEDOUT;\n\nout:\n\tdur = jiffies - started;\n\tif (dur > HZ)\n\t\tath10k_dbg(ar, ATH10K_DBG_BMI,\n\t\t\t   \"bmi cmd took %lu jiffies hz %d ret %d\\n\",\n\t\t\t   dur, HZ, ret);\n\treturn ret;\n}\n\n \nstatic int ath10k_pci_wake_target_cpu(struct ath10k *ar)\n{\n\tu32 addr, val;\n\n\taddr = SOC_CORE_BASE_ADDRESS + CORE_CTRL_ADDRESS;\n\tval = ath10k_pci_read32(ar, addr);\n\tval |= CORE_CTRL_CPU_INTR_MASK;\n\tath10k_pci_write32(ar, addr, val);\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_get_num_banks(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tswitch (ar_pci->pdev->device) {\n\tcase QCA988X_2_0_DEVICE_ID_UBNT:\n\tcase QCA988X_2_0_DEVICE_ID:\n\tcase QCA99X0_2_0_DEVICE_ID:\n\tcase QCA9888_2_0_DEVICE_ID:\n\tcase QCA9984_1_0_DEVICE_ID:\n\tcase QCA9887_1_0_DEVICE_ID:\n\t\treturn 1;\n\tcase QCA6164_2_1_DEVICE_ID:\n\tcase QCA6174_2_1_DEVICE_ID:\n\t\tswitch (MS(ar->bus_param.chip_id, SOC_CHIP_ID_REV)) {\n\t\tcase QCA6174_HW_1_0_CHIP_ID_REV:\n\t\tcase QCA6174_HW_1_1_CHIP_ID_REV:\n\t\tcase QCA6174_HW_2_1_CHIP_ID_REV:\n\t\tcase QCA6174_HW_2_2_CHIP_ID_REV:\n\t\t\treturn 3;\n\t\tcase QCA6174_HW_1_3_CHIP_ID_REV:\n\t\t\treturn 2;\n\t\tcase QCA6174_HW_3_0_CHIP_ID_REV:\n\t\tcase QCA6174_HW_3_1_CHIP_ID_REV:\n\t\tcase QCA6174_HW_3_2_CHIP_ID_REV:\n\t\t\treturn 9;\n\t\t}\n\t\tbreak;\n\tcase QCA9377_1_0_DEVICE_ID:\n\t\treturn 9;\n\t}\n\n\tath10k_warn(ar, \"unknown number of banks, assuming 1\\n\");\n\treturn 1;\n}\n\nstatic int ath10k_bus_get_num_banks(struct ath10k *ar)\n{\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\n\treturn ce->bus_ops->get_num_banks(ar);\n}\n\nint ath10k_pci_init_config(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tu32 interconnect_targ_addr;\n\tu32 pcie_state_targ_addr = 0;\n\tu32 pipe_cfg_targ_addr = 0;\n\tu32 svc_to_pipe_map = 0;\n\tu32 pcie_config_flags = 0;\n\tu32 ealloc_value;\n\tu32 ealloc_targ_addr;\n\tu32 flag2_value;\n\tu32 flag2_targ_addr;\n\tint ret = 0;\n\n\t \n\tinterconnect_targ_addr =\n\t\thost_interest_item_address(HI_ITEM(hi_interconnect_state));\n\n\t \n\tret = ath10k_pci_diag_read32(ar, interconnect_targ_addr,\n\t\t\t\t     &pcie_state_targ_addr);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to get pcie state addr: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (pcie_state_targ_addr == 0) {\n\t\tret = -EIO;\n\t\tath10k_err(ar, \"Invalid pcie state addr\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_diag_read32(ar, (pcie_state_targ_addr +\n\t\t\t\t\t  offsetof(struct pcie_state,\n\t\t\t\t\t\t   pipe_cfg_addr)),\n\t\t\t\t     &pipe_cfg_targ_addr);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to get pipe cfg addr: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (pipe_cfg_targ_addr == 0) {\n\t\tret = -EIO;\n\t\tath10k_err(ar, \"Invalid pipe cfg addr\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_diag_write_mem(ar, pipe_cfg_targ_addr,\n\t\t\t\t\tar_pci->pipe_config,\n\t\t\t\t\tsizeof(struct ce_pipe_config) *\n\t\t\t\t\tNUM_TARGET_CE_CONFIG_WLAN);\n\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to write pipe cfg: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_diag_read32(ar, (pcie_state_targ_addr +\n\t\t\t\t\t  offsetof(struct pcie_state,\n\t\t\t\t\t\t   svc_to_pipe_map)),\n\t\t\t\t     &svc_to_pipe_map);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to get svc/pipe map: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tif (svc_to_pipe_map == 0) {\n\t\tret = -EIO;\n\t\tath10k_err(ar, \"Invalid svc_to_pipe map\\n\");\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_diag_write_mem(ar, svc_to_pipe_map,\n\t\t\t\t\tar_pci->serv_to_pipe,\n\t\t\t\t\tsizeof(pci_target_service_to_ce_map_wlan));\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to write svc/pipe map: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_diag_read32(ar, (pcie_state_targ_addr +\n\t\t\t\t\t  offsetof(struct pcie_state,\n\t\t\t\t\t\t   config_flags)),\n\t\t\t\t     &pcie_config_flags);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to get pcie config_flags: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tpcie_config_flags &= ~PCIE_CONFIG_FLAG_ENABLE_L1;\n\n\tret = ath10k_pci_diag_write32(ar, (pcie_state_targ_addr +\n\t\t\t\t\t   offsetof(struct pcie_state,\n\t\t\t\t\t\t    config_flags)),\n\t\t\t\t      pcie_config_flags);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to write pcie config_flags: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tealloc_targ_addr = host_interest_item_address(HI_ITEM(hi_early_alloc));\n\n\tret = ath10k_pci_diag_read32(ar, ealloc_targ_addr, &ealloc_value);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to get early alloc val: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tealloc_value |= ((HI_EARLY_ALLOC_MAGIC << HI_EARLY_ALLOC_MAGIC_SHIFT) &\n\t\t\t HI_EARLY_ALLOC_MAGIC_MASK);\n\tealloc_value |= ((ath10k_bus_get_num_banks(ar) <<\n\t\t\t  HI_EARLY_ALLOC_IRAM_BANKS_SHIFT) &\n\t\t\t HI_EARLY_ALLOC_IRAM_BANKS_MASK);\n\n\tret = ath10k_pci_diag_write32(ar, ealloc_targ_addr, ealloc_value);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to set early alloc val: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tflag2_targ_addr = host_interest_item_address(HI_ITEM(hi_option_flag2));\n\n\tret = ath10k_pci_diag_read32(ar, flag2_targ_addr, &flag2_value);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to get option val: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tflag2_value |= HI_OPTION_EARLY_CFG_DONE;\n\n\tret = ath10k_pci_diag_write32(ar, flag2_targ_addr, flag2_value);\n\tif (ret != 0) {\n\t\tath10k_err(ar, \"Failed to set option val: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic void ath10k_pci_override_ce_config(struct ath10k *ar)\n{\n\tstruct ce_attr *attr;\n\tstruct ce_pipe_config *config;\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\t \n\n\t \n\tattr = &ar_pci->attr[5];\n\tattr->src_sz_max = 0;\n\tattr->dest_nentries = 0;\n\n\t \n\tconfig = &ar_pci->pipe_config[5];\n\tconfig->pipedir = __cpu_to_le32(PIPEDIR_OUT);\n\tconfig->nbytes_max = __cpu_to_le32(2048);\n\n\t \n\tar_pci->serv_to_pipe[15].pipenum = __cpu_to_le32(1);\n}\n\nint ath10k_pci_alloc_pipes(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct ath10k_pci_pipe *pipe;\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\tint i, ret;\n\n\tfor (i = 0; i < CE_COUNT; i++) {\n\t\tpipe = &ar_pci->pipe_info[i];\n\t\tpipe->ce_hdl = &ce->ce_states[i];\n\t\tpipe->pipe_num = i;\n\t\tpipe->hif_ce_state = ar;\n\n\t\tret = ath10k_ce_alloc_pipe(ar, i, &ar_pci->attr[i]);\n\t\tif (ret) {\n\t\t\tath10k_err(ar, \"failed to allocate copy engine pipe %d: %d\\n\",\n\t\t\t\t   i, ret);\n\t\t\treturn ret;\n\t\t}\n\n\t\t \n\t\tif (i == CE_DIAG_PIPE) {\n\t\t\tar_pci->ce_diag = pipe->ce_hdl;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpipe->buf_sz = (size_t)(ar_pci->attr[i].src_sz_max);\n\t}\n\n\treturn 0;\n}\n\nvoid ath10k_pci_free_pipes(struct ath10k *ar)\n{\n\tint i;\n\n\tfor (i = 0; i < CE_COUNT; i++)\n\t\tath10k_ce_free_pipe(ar, i);\n}\n\nint ath10k_pci_init_pipes(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint i, ret;\n\n\tfor (i = 0; i < CE_COUNT; i++) {\n\t\tret = ath10k_ce_init_pipe(ar, i, &ar_pci->attr[i]);\n\t\tif (ret) {\n\t\t\tath10k_err(ar, \"failed to initialize copy engine pipe %d: %d\\n\",\n\t\t\t\t   i, ret);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic bool ath10k_pci_has_fw_crashed(struct ath10k *ar)\n{\n\treturn ath10k_pci_read32(ar, FW_INDICATOR_ADDRESS) &\n\t       FW_IND_EVENT_PENDING;\n}\n\nstatic void ath10k_pci_fw_crashed_clear(struct ath10k *ar)\n{\n\tu32 val;\n\n\tval = ath10k_pci_read32(ar, FW_INDICATOR_ADDRESS);\n\tval &= ~FW_IND_EVENT_PENDING;\n\tath10k_pci_write32(ar, FW_INDICATOR_ADDRESS, val);\n}\n\nstatic bool ath10k_pci_has_device_gone(struct ath10k *ar)\n{\n\tu32 val;\n\n\tval = ath10k_pci_read32(ar, FW_INDICATOR_ADDRESS);\n\treturn (val == 0xffffffff);\n}\n\n \nstatic void ath10k_pci_warm_reset_si0(struct ath10k *ar)\n{\n\tu32 val;\n\n\tval = ath10k_pci_soc_read32(ar, SOC_RESET_CONTROL_ADDRESS);\n\tath10k_pci_soc_write32(ar, SOC_RESET_CONTROL_ADDRESS,\n\t\t\t       val | SOC_RESET_CONTROL_SI0_RST_MASK);\n\tval = ath10k_pci_soc_read32(ar, SOC_RESET_CONTROL_ADDRESS);\n\n\tmsleep(10);\n\n\tval = ath10k_pci_soc_read32(ar, SOC_RESET_CONTROL_ADDRESS);\n\tath10k_pci_soc_write32(ar, SOC_RESET_CONTROL_ADDRESS,\n\t\t\t       val & ~SOC_RESET_CONTROL_SI0_RST_MASK);\n\tval = ath10k_pci_soc_read32(ar, SOC_RESET_CONTROL_ADDRESS);\n\n\tmsleep(10);\n}\n\nstatic void ath10k_pci_warm_reset_cpu(struct ath10k *ar)\n{\n\tu32 val;\n\n\tath10k_pci_write32(ar, FW_INDICATOR_ADDRESS, 0);\n\n\tval = ath10k_pci_soc_read32(ar, SOC_RESET_CONTROL_ADDRESS);\n\tath10k_pci_soc_write32(ar, SOC_RESET_CONTROL_ADDRESS,\n\t\t\t       val | SOC_RESET_CONTROL_CPU_WARM_RST_MASK);\n}\n\nstatic void ath10k_pci_warm_reset_ce(struct ath10k *ar)\n{\n\tu32 val;\n\n\tval = ath10k_pci_soc_read32(ar, SOC_RESET_CONTROL_ADDRESS);\n\n\tath10k_pci_soc_write32(ar, SOC_RESET_CONTROL_ADDRESS,\n\t\t\t       val | SOC_RESET_CONTROL_CE_RST_MASK);\n\tmsleep(10);\n\tath10k_pci_soc_write32(ar, SOC_RESET_CONTROL_ADDRESS,\n\t\t\t       val & ~SOC_RESET_CONTROL_CE_RST_MASK);\n}\n\nstatic void ath10k_pci_warm_reset_clear_lf(struct ath10k *ar)\n{\n\tu32 val;\n\n\tval = ath10k_pci_soc_read32(ar, SOC_LF_TIMER_CONTROL0_ADDRESS);\n\tath10k_pci_soc_write32(ar, SOC_LF_TIMER_CONTROL0_ADDRESS,\n\t\t\t       val & ~SOC_LF_TIMER_CONTROL0_ENABLE_MASK);\n}\n\nstatic int ath10k_pci_warm_reset(struct ath10k *ar)\n{\n\tint ret;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot warm reset\\n\");\n\n\tspin_lock_bh(&ar->data_lock);\n\tar->stats.fw_warm_reset_counter++;\n\tspin_unlock_bh(&ar->data_lock);\n\n\tath10k_pci_irq_disable(ar);\n\n\t \n\tath10k_pci_warm_reset_si0(ar);\n\tath10k_pci_warm_reset_cpu(ar);\n\tath10k_pci_init_pipes(ar);\n\tath10k_pci_wait_for_target_init(ar);\n\n\tath10k_pci_warm_reset_clear_lf(ar);\n\tath10k_pci_warm_reset_ce(ar);\n\tath10k_pci_warm_reset_cpu(ar);\n\tath10k_pci_init_pipes(ar);\n\n\tret = ath10k_pci_wait_for_target_init(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wait for target init: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot warm reset complete\\n\");\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_qca99x0_soft_chip_reset(struct ath10k *ar)\n{\n\tath10k_pci_irq_disable(ar);\n\treturn ath10k_pci_qca99x0_chip_reset(ar);\n}\n\nstatic int ath10k_pci_safe_chip_reset(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tif (!ar_pci->pci_soft_reset)\n\t\treturn -ENOTSUPP;\n\n\treturn ar_pci->pci_soft_reset(ar);\n}\n\nstatic int ath10k_pci_qca988x_chip_reset(struct ath10k *ar)\n{\n\tint i, ret;\n\tu32 val;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot 988x chip reset\\n\");\n\n\t \n\tfor (i = 0; i < ATH10K_PCI_NUM_WARM_RESET_ATTEMPTS; i++) {\n\t\tret = ath10k_pci_warm_reset(ar);\n\t\tif (ret) {\n\t\t\tath10k_warn(ar, \"failed to warm reset attempt %d of %d: %d\\n\",\n\t\t\t\t    i + 1, ATH10K_PCI_NUM_WARM_RESET_ATTEMPTS,\n\t\t\t\t    ret);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tret = ath10k_pci_init_pipes(ar);\n\t\tif (ret) {\n\t\t\tath10k_warn(ar, \"failed to init copy engine: %d\\n\",\n\t\t\t\t    ret);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = ath10k_pci_diag_read32(ar, QCA988X_HOST_INTEREST_ADDRESS,\n\t\t\t\t\t     &val);\n\t\tif (ret) {\n\t\t\tath10k_warn(ar, \"failed to poke copy engine: %d\\n\",\n\t\t\t\t    ret);\n\t\t\tcontinue;\n\t\t}\n\n\t\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot chip reset complete (warm)\\n\");\n\t\treturn 0;\n\t}\n\n\tif (ath10k_pci_reset_mode == ATH10K_PCI_RESET_WARM_ONLY) {\n\t\tath10k_warn(ar, \"refusing cold reset as requested\\n\");\n\t\treturn -EPERM;\n\t}\n\n\tret = ath10k_pci_cold_reset(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to cold reset: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_wait_for_target_init(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wait for target after cold reset: %d\\n\",\n\t\t\t    ret);\n\t\treturn ret;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot qca988x chip reset complete (cold)\\n\");\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_qca6174_chip_reset(struct ath10k *ar)\n{\n\tint ret;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot qca6174 chip reset\\n\");\n\n\t \n\n\tret = ath10k_pci_cold_reset(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to cold reset: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_wait_for_target_init(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wait for target after cold reset: %d\\n\",\n\t\t\t    ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_warm_reset(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to warm reset: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot qca6174 chip reset complete (cold)\\n\");\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_qca99x0_chip_reset(struct ath10k *ar)\n{\n\tint ret;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot qca99x0 chip reset\\n\");\n\n\tret = ath10k_pci_cold_reset(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to cold reset: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = ath10k_pci_wait_for_target_init(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wait for target after cold reset: %d\\n\",\n\t\t\t    ret);\n\t\treturn ret;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot qca99x0 chip reset complete (cold)\\n\");\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_chip_reset(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tif (WARN_ON(!ar_pci->pci_hard_reset))\n\t\treturn -ENOTSUPP;\n\n\treturn ar_pci->pci_hard_reset(ar);\n}\n\nstatic int ath10k_pci_hif_power_up(struct ath10k *ar,\n\t\t\t\t   enum ath10k_firmware_mode fw_mode)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot hif power up\\n\");\n\n\tpcie_capability_read_word(ar_pci->pdev, PCI_EXP_LNKCTL,\n\t\t\t\t  &ar_pci->link_ctl);\n\tpcie_capability_clear_word(ar_pci->pdev, PCI_EXP_LNKCTL,\n\t\t\t\t   PCI_EXP_LNKCTL_ASPMC);\n\n\t \n\tret = ath10k_pci_chip_reset(ar);\n\tif (ret) {\n\t\tif (ath10k_pci_has_fw_crashed(ar)) {\n\t\t\tath10k_warn(ar, \"firmware crashed during chip reset\\n\");\n\t\t\tath10k_pci_fw_crashed_clear(ar);\n\t\t\tath10k_pci_fw_crashed_dump(ar);\n\t\t}\n\n\t\tath10k_err(ar, \"failed to reset chip: %d\\n\", ret);\n\t\tgoto err_sleep;\n\t}\n\n\tret = ath10k_pci_init_pipes(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to initialize CE: %d\\n\", ret);\n\t\tgoto err_sleep;\n\t}\n\n\tret = ath10k_pci_init_config(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to setup init config: %d\\n\", ret);\n\t\tgoto err_ce;\n\t}\n\n\tret = ath10k_pci_wake_target_cpu(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"could not wake up target CPU: %d\\n\", ret);\n\t\tgoto err_ce;\n\t}\n\n\treturn 0;\n\nerr_ce:\n\tath10k_pci_ce_deinit(ar);\n\nerr_sleep:\n\treturn ret;\n}\n\nvoid ath10k_pci_hif_power_down(struct ath10k *ar)\n{\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot hif power down\\n\");\n\n\t \n}\n\nstatic int ath10k_pci_hif_suspend(struct ath10k *ar)\n{\n\t \n\treturn 0;\n}\n\nstatic int ath10k_pci_suspend(struct ath10k *ar)\n{\n\t \n\tath10k_pci_sleep_sync(ar);\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_hif_resume(struct ath10k *ar)\n{\n\t \n\treturn 0;\n}\n\nstatic int ath10k_pci_resume(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct pci_dev *pdev = ar_pci->pdev;\n\tu32 val;\n\tint ret = 0;\n\n\tret = ath10k_pci_force_wake(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to wake up target: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\t \n\tpci_read_config_dword(pdev, 0x40, &val);\n\tif ((val & 0x0000ff00) != 0)\n\t\tpci_write_config_dword(pdev, 0x40, val & 0xffff00ff);\n\n\treturn ret;\n}\n\nstatic bool ath10k_pci_validate_cal(void *data, size_t size)\n{\n\t__le16 *cal_words = data;\n\tu16 checksum = 0;\n\tsize_t i;\n\n\tif (size % 2 != 0)\n\t\treturn false;\n\n\tfor (i = 0; i < size / 2; i++)\n\t\tchecksum ^= le16_to_cpu(cal_words[i]);\n\n\treturn checksum == 0xffff;\n}\n\nstatic void ath10k_pci_enable_eeprom(struct ath10k *ar)\n{\n\t \n\tath10k_pci_soc_write32(ar, CLOCK_CONTROL_OFFSET, 0x0);\n\n\t \n\tath10k_pci_write32(ar,\n\t\t\t   GPIO_BASE_ADDRESS + GPIO_PIN0_OFFSET +\n\t\t\t   4 * QCA9887_1_0_I2C_SDA_GPIO_PIN,\n\t\t\t   SM(QCA9887_1_0_I2C_SDA_PIN_CONFIG,\n\t\t\t      GPIO_PIN0_CONFIG) |\n\t\t\t   SM(1, GPIO_PIN0_PAD_PULL));\n\n\tath10k_pci_write32(ar,\n\t\t\t   GPIO_BASE_ADDRESS + GPIO_PIN0_OFFSET +\n\t\t\t   4 * QCA9887_1_0_SI_CLK_GPIO_PIN,\n\t\t\t   SM(QCA9887_1_0_SI_CLK_PIN_CONFIG, GPIO_PIN0_CONFIG) |\n\t\t\t   SM(1, GPIO_PIN0_PAD_PULL));\n\n\tath10k_pci_write32(ar,\n\t\t\t   GPIO_BASE_ADDRESS +\n\t\t\t   QCA9887_1_0_GPIO_ENABLE_W1TS_LOW_ADDRESS,\n\t\t\t   1u << QCA9887_1_0_SI_CLK_GPIO_PIN);\n\n\t \n\tath10k_pci_write32(ar,\n\t\t\t   SI_BASE_ADDRESS + SI_CONFIG_OFFSET,\n\t\t\t   SM(1, SI_CONFIG_ERR_INT) |\n\t\t\t   SM(1, SI_CONFIG_BIDIR_OD_DATA) |\n\t\t\t   SM(1, SI_CONFIG_I2C) |\n\t\t\t   SM(1, SI_CONFIG_POS_SAMPLE) |\n\t\t\t   SM(1, SI_CONFIG_INACTIVE_DATA) |\n\t\t\t   SM(1, SI_CONFIG_INACTIVE_CLK) |\n\t\t\t   SM(8, SI_CONFIG_DIVIDER));\n}\n\nstatic int ath10k_pci_read_eeprom(struct ath10k *ar, u16 addr, u8 *out)\n{\n\tu32 reg;\n\tint wait_limit;\n\n\t \n\treg = QCA9887_EEPROM_SELECT_READ |\n\t      SM(addr, QCA9887_EEPROM_ADDR_LO) |\n\t      SM(addr >> 8, QCA9887_EEPROM_ADDR_HI);\n\tath10k_pci_write32(ar, SI_BASE_ADDRESS + SI_TX_DATA0_OFFSET, reg);\n\n\t \n\tath10k_pci_write32(ar, SI_BASE_ADDRESS + SI_CS_OFFSET,\n\t\t\t   SM(1, SI_CS_START) | SM(1, SI_CS_RX_CNT) |\n\t\t\t   SM(4, SI_CS_TX_CNT));\n\n\t \n\twait_limit = 100000;\n\n\t \n\tdo {\n\t\treg = ath10k_pci_read32(ar, SI_BASE_ADDRESS + SI_CS_OFFSET);\n\t\tif (MS(reg, SI_CS_DONE_INT))\n\t\t\tbreak;\n\n\t\twait_limit--;\n\t\tudelay(10);\n\t} while (wait_limit > 0);\n\n\tif (!MS(reg, SI_CS_DONE_INT)) {\n\t\tath10k_err(ar, \"timeout while reading device EEPROM at %04x\\n\",\n\t\t\t   addr);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\t \n\tath10k_pci_write32(ar, SI_BASE_ADDRESS + SI_CS_OFFSET, reg);\n\n\tif (MS(reg, SI_CS_DONE_ERR)) {\n\t\tath10k_err(ar, \"failed to read device EEPROM at %04x\\n\", addr);\n\t\treturn -EIO;\n\t}\n\n\t \n\treg = ath10k_pci_read32(ar, SI_BASE_ADDRESS + SI_RX_DATA0_OFFSET);\n\t*out = reg;\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_hif_fetch_cal_eeprom(struct ath10k *ar, void **data,\n\t\t\t\t\t   size_t *data_len)\n{\n\tu8 *caldata = NULL;\n\tsize_t calsize, i;\n\tint ret;\n\n\tif (!QCA_REV_9887(ar))\n\t\treturn -EOPNOTSUPP;\n\n\tcalsize = ar->hw_params.cal_data_len;\n\tcaldata = kmalloc(calsize, GFP_KERNEL);\n\tif (!caldata)\n\t\treturn -ENOMEM;\n\n\tath10k_pci_enable_eeprom(ar);\n\n\tfor (i = 0; i < calsize; i++) {\n\t\tret = ath10k_pci_read_eeprom(ar, i, &caldata[i]);\n\t\tif (ret)\n\t\t\tgoto err_free;\n\t}\n\n\tif (!ath10k_pci_validate_cal(caldata, calsize))\n\t\tgoto err_free;\n\n\t*data = caldata;\n\t*data_len = calsize;\n\n\treturn 0;\n\nerr_free:\n\tkfree(caldata);\n\n\treturn -EINVAL;\n}\n\nstatic const struct ath10k_hif_ops ath10k_pci_hif_ops = {\n\t.tx_sg\t\t\t= ath10k_pci_hif_tx_sg,\n\t.diag_read\t\t= ath10k_pci_hif_diag_read,\n\t.diag_write\t\t= ath10k_pci_diag_write_mem,\n\t.exchange_bmi_msg\t= ath10k_pci_hif_exchange_bmi_msg,\n\t.start\t\t\t= ath10k_pci_hif_start,\n\t.stop\t\t\t= ath10k_pci_hif_stop,\n\t.map_service_to_pipe\t= ath10k_pci_hif_map_service_to_pipe,\n\t.get_default_pipe\t= ath10k_pci_hif_get_default_pipe,\n\t.send_complete_check\t= ath10k_pci_hif_send_complete_check,\n\t.get_free_queue_number\t= ath10k_pci_hif_get_free_queue_number,\n\t.power_up\t\t= ath10k_pci_hif_power_up,\n\t.power_down\t\t= ath10k_pci_hif_power_down,\n\t.read32\t\t\t= ath10k_pci_read32,\n\t.write32\t\t= ath10k_pci_write32,\n\t.suspend\t\t= ath10k_pci_hif_suspend,\n\t.resume\t\t\t= ath10k_pci_hif_resume,\n\t.fetch_cal_eeprom\t= ath10k_pci_hif_fetch_cal_eeprom,\n};\n\n \nstatic irqreturn_t ath10k_pci_interrupt_handler(int irq, void *arg)\n{\n\tstruct ath10k *ar = arg;\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret;\n\n\tif (ath10k_pci_has_device_gone(ar))\n\t\treturn IRQ_NONE;\n\n\tret = ath10k_pci_force_wake(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wake device up on irq: %d\\n\", ret);\n\t\treturn IRQ_NONE;\n\t}\n\n\tif ((ar_pci->oper_irq_mode == ATH10K_PCI_IRQ_LEGACY) &&\n\t    !ath10k_pci_irq_pending(ar))\n\t\treturn IRQ_NONE;\n\n\tath10k_pci_disable_and_clear_legacy_irq(ar);\n\tath10k_pci_irq_msi_fw_mask(ar);\n\tnapi_schedule(&ar->napi);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int ath10k_pci_napi_poll(struct napi_struct *ctx, int budget)\n{\n\tstruct ath10k *ar = container_of(ctx, struct ath10k, napi);\n\tint done = 0;\n\n\tif (ath10k_pci_has_fw_crashed(ar)) {\n\t\tath10k_pci_fw_crashed_clear(ar);\n\t\tath10k_pci_fw_crashed_dump(ar);\n\t\tnapi_complete(ctx);\n\t\treturn done;\n\t}\n\n\tath10k_ce_per_engine_service_any(ar);\n\n\tdone = ath10k_htt_txrx_compl_task(ar, budget);\n\n\tif (done < budget) {\n\t\tnapi_complete_done(ctx, done);\n\t\t \n\t\tif (ath10k_ce_interrupt_summary(ar)) {\n\t\t\tnapi_reschedule(ctx);\n\t\t\tgoto out;\n\t\t}\n\t\tath10k_pci_enable_legacy_irq(ar);\n\t\tath10k_pci_irq_msi_fw_unmask(ar);\n\t}\n\nout:\n\treturn done;\n}\n\nstatic int ath10k_pci_request_irq_msi(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret;\n\n\tret = request_irq(ar_pci->pdev->irq,\n\t\t\t  ath10k_pci_interrupt_handler,\n\t\t\t  IRQF_SHARED, \"ath10k_pci\", ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to request MSI irq %d: %d\\n\",\n\t\t\t    ar_pci->pdev->irq, ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_request_irq_legacy(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret;\n\n\tret = request_irq(ar_pci->pdev->irq,\n\t\t\t  ath10k_pci_interrupt_handler,\n\t\t\t  IRQF_SHARED, \"ath10k_pci\", ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to request legacy irq %d: %d\\n\",\n\t\t\t    ar_pci->pdev->irq, ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_request_irq(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tswitch (ar_pci->oper_irq_mode) {\n\tcase ATH10K_PCI_IRQ_LEGACY:\n\t\treturn ath10k_pci_request_irq_legacy(ar);\n\tcase ATH10K_PCI_IRQ_MSI:\n\t\treturn ath10k_pci_request_irq_msi(ar);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void ath10k_pci_free_irq(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tfree_irq(ar_pci->pdev->irq, ar);\n}\n\nvoid ath10k_pci_init_napi(struct ath10k *ar)\n{\n\tnetif_napi_add(&ar->napi_dev, &ar->napi, ath10k_pci_napi_poll);\n}\n\nstatic int ath10k_pci_init_irq(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tint ret;\n\n\tath10k_pci_init_napi(ar);\n\n\tif (ath10k_pci_irq_mode != ATH10K_PCI_IRQ_AUTO)\n\t\tath10k_info(ar, \"limiting irq mode to: %d\\n\",\n\t\t\t    ath10k_pci_irq_mode);\n\n\t \n\tif (ath10k_pci_irq_mode != ATH10K_PCI_IRQ_LEGACY) {\n\t\tar_pci->oper_irq_mode = ATH10K_PCI_IRQ_MSI;\n\t\tret = pci_enable_msi(ar_pci->pdev);\n\t\tif (ret == 0)\n\t\t\treturn 0;\n\n\t\t \n\t}\n\n\t \n\tar_pci->oper_irq_mode = ATH10K_PCI_IRQ_LEGACY;\n\n\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS + PCIE_INTR_ENABLE_ADDRESS,\n\t\t\t   PCIE_INTR_FIRMWARE_MASK | PCIE_INTR_CE_MASK_ALL);\n\n\treturn 0;\n}\n\nstatic void ath10k_pci_deinit_irq_legacy(struct ath10k *ar)\n{\n\tath10k_pci_write32(ar, SOC_CORE_BASE_ADDRESS + PCIE_INTR_ENABLE_ADDRESS,\n\t\t\t   0);\n}\n\nstatic int ath10k_pci_deinit_irq(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tswitch (ar_pci->oper_irq_mode) {\n\tcase ATH10K_PCI_IRQ_LEGACY:\n\t\tath10k_pci_deinit_irq_legacy(ar);\n\t\tbreak;\n\tdefault:\n\t\tpci_disable_msi(ar_pci->pdev);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nint ath10k_pci_wait_for_target_init(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tunsigned long timeout;\n\tu32 val;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot waiting target to initialise\\n\");\n\n\ttimeout = jiffies + msecs_to_jiffies(ATH10K_PCI_TARGET_WAIT);\n\n\tdo {\n\t\tval = ath10k_pci_read32(ar, FW_INDICATOR_ADDRESS);\n\n\t\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot target indicator %x\\n\",\n\t\t\t   val);\n\n\t\t \n\t\tif (val == 0xffffffff)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (val & FW_IND_EVENT_PENDING)\n\t\t\tbreak;\n\n\t\tif (val & FW_IND_INITIALIZED)\n\t\t\tbreak;\n\n\t\tif (ar_pci->oper_irq_mode == ATH10K_PCI_IRQ_LEGACY)\n\t\t\t \n\t\t\tath10k_pci_enable_legacy_irq(ar);\n\n\t\tmdelay(10);\n\t} while (time_before(jiffies, timeout));\n\n\tath10k_pci_disable_and_clear_legacy_irq(ar);\n\tath10k_pci_irq_msi_fw_mask(ar);\n\n\tif (val == 0xffffffff) {\n\t\tath10k_err(ar, \"failed to read device register, device is gone\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (val & FW_IND_EVENT_PENDING) {\n\t\tath10k_warn(ar, \"device has crashed during init\\n\");\n\t\treturn -ECOMM;\n\t}\n\n\tif (!(val & FW_IND_INITIALIZED)) {\n\t\tath10k_err(ar, \"failed to receive initialized event from target: %08x\\n\",\n\t\t\t   val);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot target initialised\\n\");\n\treturn 0;\n}\n\nstatic int ath10k_pci_cold_reset(struct ath10k *ar)\n{\n\tu32 val;\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot cold reset\\n\");\n\n\tspin_lock_bh(&ar->data_lock);\n\n\tar->stats.fw_cold_reset_counter++;\n\n\tspin_unlock_bh(&ar->data_lock);\n\n\t \n\tval = ath10k_pci_reg_read32(ar, SOC_GLOBAL_RESET_ADDRESS);\n\tval |= 1;\n\tath10k_pci_reg_write32(ar, SOC_GLOBAL_RESET_ADDRESS, val);\n\n\t \n\tmsleep(20);\n\n\t \n\tval &= ~1;\n\tath10k_pci_reg_write32(ar, SOC_GLOBAL_RESET_ADDRESS, val);\n\n\tmsleep(20);\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot cold reset complete\\n\");\n\n\treturn 0;\n}\n\nstatic int ath10k_pci_claim(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct pci_dev *pdev = ar_pci->pdev;\n\tint ret;\n\n\tpci_set_drvdata(pdev, ar);\n\n\tret = pci_enable_device(pdev);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to enable pci device: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = pci_request_region(pdev, BAR_NUM, \"ath\");\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to request region BAR%d: %d\\n\", BAR_NUM,\n\t\t\t   ret);\n\t\tgoto err_device;\n\t}\n\n\t \n\tret = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to set dma mask to 32-bit: %d\\n\", ret);\n\t\tgoto err_region;\n\t}\n\n\tpci_set_master(pdev);\n\n\t \n\tar_pci->mem_len = pci_resource_len(pdev, BAR_NUM);\n\tar_pci->mem = pci_iomap(pdev, BAR_NUM, 0);\n\tif (!ar_pci->mem) {\n\t\tath10k_err(ar, \"failed to iomap BAR%d\\n\", BAR_NUM);\n\t\tret = -EIO;\n\t\tgoto err_region;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"boot pci_mem 0x%pK\\n\", ar_pci->mem);\n\treturn 0;\n\nerr_region:\n\tpci_release_region(pdev, BAR_NUM);\n\nerr_device:\n\tpci_disable_device(pdev);\n\n\treturn ret;\n}\n\nstatic void ath10k_pci_release(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct pci_dev *pdev = ar_pci->pdev;\n\n\tpci_iounmap(pdev, ar_pci->mem);\n\tpci_release_region(pdev, BAR_NUM);\n\tpci_disable_device(pdev);\n}\n\nstatic bool ath10k_pci_chip_is_supported(u32 dev_id, u32 chip_id)\n{\n\tconst struct ath10k_pci_supp_chip *supp_chip;\n\tint i;\n\tu32 rev_id = MS(chip_id, SOC_CHIP_ID_REV);\n\n\tfor (i = 0; i < ARRAY_SIZE(ath10k_pci_supp_chips); i++) {\n\t\tsupp_chip = &ath10k_pci_supp_chips[i];\n\n\t\tif (supp_chip->dev_id == dev_id &&\n\t\t    supp_chip->rev_id == rev_id)\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nint ath10k_pci_setup_resource(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\tstruct ath10k_ce *ce = ath10k_ce_priv(ar);\n\tint ret;\n\n\tspin_lock_init(&ce->ce_lock);\n\tspin_lock_init(&ar_pci->ps_lock);\n\tmutex_init(&ar_pci->ce_diag_mutex);\n\n\tINIT_WORK(&ar_pci->dump_work, ath10k_pci_fw_dump_work);\n\n\ttimer_setup(&ar_pci->rx_post_retry, ath10k_pci_rx_replenish_retry, 0);\n\n\tar_pci->attr = kmemdup(pci_host_ce_config_wlan,\n\t\t\t       sizeof(pci_host_ce_config_wlan),\n\t\t\t       GFP_KERNEL);\n\tif (!ar_pci->attr)\n\t\treturn -ENOMEM;\n\n\tar_pci->pipe_config = kmemdup(pci_target_ce_config_wlan,\n\t\t\t\t      sizeof(pci_target_ce_config_wlan),\n\t\t\t\t      GFP_KERNEL);\n\tif (!ar_pci->pipe_config) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_attr;\n\t}\n\n\tar_pci->serv_to_pipe = kmemdup(pci_target_service_to_ce_map_wlan,\n\t\t\t\t       sizeof(pci_target_service_to_ce_map_wlan),\n\t\t\t\t       GFP_KERNEL);\n\tif (!ar_pci->serv_to_pipe) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_pipe_config;\n\t}\n\n\tif (QCA_REV_6174(ar) || QCA_REV_9377(ar))\n\t\tath10k_pci_override_ce_config(ar);\n\n\tret = ath10k_pci_alloc_pipes(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to allocate copy engine pipes: %d\\n\",\n\t\t\t   ret);\n\t\tgoto err_free_serv_to_pipe;\n\t}\n\n\treturn 0;\n\nerr_free_serv_to_pipe:\n\tkfree(ar_pci->serv_to_pipe);\nerr_free_pipe_config:\n\tkfree(ar_pci->pipe_config);\nerr_free_attr:\n\tkfree(ar_pci->attr);\n\treturn ret;\n}\n\nvoid ath10k_pci_release_resource(struct ath10k *ar)\n{\n\tstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\n\n\tath10k_pci_rx_retry_sync(ar);\n\tnetif_napi_del(&ar->napi);\n\tath10k_pci_ce_deinit(ar);\n\tath10k_pci_free_pipes(ar);\n\tkfree(ar_pci->attr);\n\tkfree(ar_pci->pipe_config);\n\tkfree(ar_pci->serv_to_pipe);\n}\n\nstatic const struct ath10k_bus_ops ath10k_pci_bus_ops = {\n\t.read32\t\t= ath10k_bus_pci_read32,\n\t.write32\t= ath10k_bus_pci_write32,\n\t.get_num_banks\t= ath10k_pci_get_num_banks,\n};\n\nstatic int ath10k_pci_probe(struct pci_dev *pdev,\n\t\t\t    const struct pci_device_id *pci_dev)\n{\n\tint ret = 0;\n\tstruct ath10k *ar;\n\tstruct ath10k_pci *ar_pci;\n\tenum ath10k_hw_rev hw_rev;\n\tstruct ath10k_bus_params bus_params = {};\n\tbool pci_ps, is_qca988x = false;\n\tint (*pci_soft_reset)(struct ath10k *ar);\n\tint (*pci_hard_reset)(struct ath10k *ar);\n\tu32 (*targ_cpu_to_ce_addr)(struct ath10k *ar, u32 addr);\n\n\tswitch (pci_dev->device) {\n\tcase QCA988X_2_0_DEVICE_ID_UBNT:\n\tcase QCA988X_2_0_DEVICE_ID:\n\t\thw_rev = ATH10K_HW_QCA988X;\n\t\tpci_ps = false;\n\t\tis_qca988x = true;\n\t\tpci_soft_reset = ath10k_pci_warm_reset;\n\t\tpci_hard_reset = ath10k_pci_qca988x_chip_reset;\n\t\ttarg_cpu_to_ce_addr = ath10k_pci_qca988x_targ_cpu_to_ce_addr;\n\t\tbreak;\n\tcase QCA9887_1_0_DEVICE_ID:\n\t\thw_rev = ATH10K_HW_QCA9887;\n\t\tpci_ps = false;\n\t\tpci_soft_reset = ath10k_pci_warm_reset;\n\t\tpci_hard_reset = ath10k_pci_qca988x_chip_reset;\n\t\ttarg_cpu_to_ce_addr = ath10k_pci_qca988x_targ_cpu_to_ce_addr;\n\t\tbreak;\n\tcase QCA6164_2_1_DEVICE_ID:\n\tcase QCA6174_2_1_DEVICE_ID:\n\t\thw_rev = ATH10K_HW_QCA6174;\n\t\tpci_ps = true;\n\t\tpci_soft_reset = ath10k_pci_warm_reset;\n\t\tpci_hard_reset = ath10k_pci_qca6174_chip_reset;\n\t\ttarg_cpu_to_ce_addr = ath10k_pci_qca6174_targ_cpu_to_ce_addr;\n\t\tbreak;\n\tcase QCA99X0_2_0_DEVICE_ID:\n\t\thw_rev = ATH10K_HW_QCA99X0;\n\t\tpci_ps = false;\n\t\tpci_soft_reset = ath10k_pci_qca99x0_soft_chip_reset;\n\t\tpci_hard_reset = ath10k_pci_qca99x0_chip_reset;\n\t\ttarg_cpu_to_ce_addr = ath10k_pci_qca99x0_targ_cpu_to_ce_addr;\n\t\tbreak;\n\tcase QCA9984_1_0_DEVICE_ID:\n\t\thw_rev = ATH10K_HW_QCA9984;\n\t\tpci_ps = false;\n\t\tpci_soft_reset = ath10k_pci_qca99x0_soft_chip_reset;\n\t\tpci_hard_reset = ath10k_pci_qca99x0_chip_reset;\n\t\ttarg_cpu_to_ce_addr = ath10k_pci_qca99x0_targ_cpu_to_ce_addr;\n\t\tbreak;\n\tcase QCA9888_2_0_DEVICE_ID:\n\t\thw_rev = ATH10K_HW_QCA9888;\n\t\tpci_ps = false;\n\t\tpci_soft_reset = ath10k_pci_qca99x0_soft_chip_reset;\n\t\tpci_hard_reset = ath10k_pci_qca99x0_chip_reset;\n\t\ttarg_cpu_to_ce_addr = ath10k_pci_qca99x0_targ_cpu_to_ce_addr;\n\t\tbreak;\n\tcase QCA9377_1_0_DEVICE_ID:\n\t\thw_rev = ATH10K_HW_QCA9377;\n\t\tpci_ps = true;\n\t\tpci_soft_reset = ath10k_pci_warm_reset;\n\t\tpci_hard_reset = ath10k_pci_qca6174_chip_reset;\n\t\ttarg_cpu_to_ce_addr = ath10k_pci_qca6174_targ_cpu_to_ce_addr;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t\treturn -ENOTSUPP;\n\t}\n\n\tar = ath10k_core_create(sizeof(*ar_pci), &pdev->dev, ATH10K_BUS_PCI,\n\t\t\t\thw_rev, &ath10k_pci_hif_ops);\n\tif (!ar) {\n\t\tdev_err(&pdev->dev, \"failed to allocate core\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"pci probe %04x:%04x %04x:%04x\\n\",\n\t\t   pdev->vendor, pdev->device,\n\t\t   pdev->subsystem_vendor, pdev->subsystem_device);\n\n\tar_pci = ath10k_pci_priv(ar);\n\tar_pci->pdev = pdev;\n\tar_pci->dev = &pdev->dev;\n\tar_pci->ar = ar;\n\tar->dev_id = pci_dev->device;\n\tar_pci->pci_ps = pci_ps;\n\tar_pci->ce.bus_ops = &ath10k_pci_bus_ops;\n\tar_pci->pci_soft_reset = pci_soft_reset;\n\tar_pci->pci_hard_reset = pci_hard_reset;\n\tar_pci->targ_cpu_to_ce_addr = targ_cpu_to_ce_addr;\n\tar->ce_priv = &ar_pci->ce;\n\n\tar->id.vendor = pdev->vendor;\n\tar->id.device = pdev->device;\n\tar->id.subsystem_vendor = pdev->subsystem_vendor;\n\tar->id.subsystem_device = pdev->subsystem_device;\n\n\ttimer_setup(&ar_pci->ps_timer, ath10k_pci_ps_timer, 0);\n\n\tret = ath10k_pci_setup_resource(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to setup resource: %d\\n\", ret);\n\t\tgoto err_core_destroy;\n\t}\n\n\tret = ath10k_pci_claim(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to claim device: %d\\n\", ret);\n\t\tgoto err_free_pipes;\n\t}\n\n\tret = ath10k_pci_force_wake(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to wake up device : %d\\n\", ret);\n\t\tgoto err_sleep;\n\t}\n\n\tath10k_pci_ce_deinit(ar);\n\tath10k_pci_irq_disable(ar);\n\n\tret = ath10k_pci_init_irq(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to init irqs: %d\\n\", ret);\n\t\tgoto err_sleep;\n\t}\n\n\tath10k_info(ar, \"pci irq %s oper_irq_mode %d irq_mode %d reset_mode %d\\n\",\n\t\t    ath10k_pci_get_irq_method(ar), ar_pci->oper_irq_mode,\n\t\t    ath10k_pci_irq_mode, ath10k_pci_reset_mode);\n\n\tret = ath10k_pci_request_irq(ar);\n\tif (ret) {\n\t\tath10k_warn(ar, \"failed to request irqs: %d\\n\", ret);\n\t\tgoto err_deinit_irq;\n\t}\n\n\tbus_params.dev_type = ATH10K_DEV_TYPE_LL;\n\tbus_params.link_can_suspend = true;\n\t \n\tif (is_qca988x) {\n\t\tbus_params.chip_id =\n\t\t\tath10k_pci_soc_read32(ar, SOC_CHIP_ID_ADDRESS);\n\t\tif (bus_params.chip_id != 0xffffffff) {\n\t\t\tif (!ath10k_pci_chip_is_supported(pdev->device,\n\t\t\t\t\t\t\t  bus_params.chip_id)) {\n\t\t\t\tret = -ENODEV;\n\t\t\t\tgoto err_unsupported;\n\t\t\t}\n\t\t}\n\t}\n\n\tret = ath10k_pci_chip_reset(ar);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to reset chip: %d\\n\", ret);\n\t\tgoto err_free_irq;\n\t}\n\n\tbus_params.chip_id = ath10k_pci_soc_read32(ar, SOC_CHIP_ID_ADDRESS);\n\tif (bus_params.chip_id == 0xffffffff) {\n\t\tret = -ENODEV;\n\t\tgoto err_unsupported;\n\t}\n\n\tif (!ath10k_pci_chip_is_supported(pdev->device, bus_params.chip_id)) {\n\t\tret = -ENODEV;\n\t\tgoto err_unsupported;\n\t}\n\n\tret = ath10k_core_register(ar, &bus_params);\n\tif (ret) {\n\t\tath10k_err(ar, \"failed to register driver core: %d\\n\", ret);\n\t\tgoto err_free_irq;\n\t}\n\n\treturn 0;\n\nerr_unsupported:\n\tath10k_err(ar, \"device %04x with chip_id %08x isn't supported\\n\",\n\t\t   pdev->device, bus_params.chip_id);\n\nerr_free_irq:\n\tath10k_pci_free_irq(ar);\n\nerr_deinit_irq:\n\tath10k_pci_release_resource(ar);\n\nerr_sleep:\n\tath10k_pci_sleep_sync(ar);\n\tath10k_pci_release(ar);\n\nerr_free_pipes:\n\tath10k_pci_free_pipes(ar);\n\nerr_core_destroy:\n\tath10k_core_destroy(ar);\n\n\treturn ret;\n}\n\nstatic void ath10k_pci_remove(struct pci_dev *pdev)\n{\n\tstruct ath10k *ar = pci_get_drvdata(pdev);\n\n\tath10k_dbg(ar, ATH10K_DBG_PCI, \"pci remove\\n\");\n\n\tif (!ar)\n\t\treturn;\n\n\tath10k_core_unregister(ar);\n\tath10k_pci_free_irq(ar);\n\tath10k_pci_deinit_irq(ar);\n\tath10k_pci_release_resource(ar);\n\tath10k_pci_sleep_sync(ar);\n\tath10k_pci_release(ar);\n\tath10k_core_destroy(ar);\n}\n\nMODULE_DEVICE_TABLE(pci, ath10k_pci_id_table);\n\nstatic __maybe_unused int ath10k_pci_pm_suspend(struct device *dev)\n{\n\tstruct ath10k *ar = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = ath10k_pci_suspend(ar);\n\tif (ret)\n\t\tath10k_warn(ar, \"failed to suspend hif: %d\\n\", ret);\n\n\treturn ret;\n}\n\nstatic __maybe_unused int ath10k_pci_pm_resume(struct device *dev)\n{\n\tstruct ath10k *ar = dev_get_drvdata(dev);\n\tint ret;\n\n\tret = ath10k_pci_resume(ar);\n\tif (ret)\n\t\tath10k_warn(ar, \"failed to resume hif: %d\\n\", ret);\n\n\treturn ret;\n}\n\nstatic SIMPLE_DEV_PM_OPS(ath10k_pci_pm_ops,\n\t\t\t ath10k_pci_pm_suspend,\n\t\t\t ath10k_pci_pm_resume);\n\nstatic struct pci_driver ath10k_pci_driver = {\n\t.name = \"ath10k_pci\",\n\t.id_table = ath10k_pci_id_table,\n\t.probe = ath10k_pci_probe,\n\t.remove = ath10k_pci_remove,\n#ifdef CONFIG_PM\n\t.driver.pm = &ath10k_pci_pm_ops,\n#endif\n};\n\nstatic int __init ath10k_pci_init(void)\n{\n\tint ret1, ret2;\n\n\tret1 = pci_register_driver(&ath10k_pci_driver);\n\tif (ret1)\n\t\tprintk(KERN_ERR \"failed to register ath10k pci driver: %d\\n\",\n\t\t       ret1);\n\n\tret2 = ath10k_ahb_init();\n\tif (ret2)\n\t\tprintk(KERN_ERR \"ahb init failed: %d\\n\", ret2);\n\n\tif (ret1 && ret2)\n\t\treturn ret1;\n\n\t \n\treturn 0;\n}\nmodule_init(ath10k_pci_init);\n\nstatic void __exit ath10k_pci_exit(void)\n{\n\tpci_unregister_driver(&ath10k_pci_driver);\n\tath10k_ahb_exit();\n}\n\nmodule_exit(ath10k_pci_exit);\n\nMODULE_AUTHOR(\"Qualcomm Atheros\");\nMODULE_DESCRIPTION(\"Driver support for Qualcomm Atheros PCIe/AHB 802.11ac WLAN devices\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n\n \nMODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR \"/\" ATH10K_FW_API2_FILE);\nMODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR \"/\" ATH10K_FW_API3_FILE);\nMODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR \"/\" ATH10K_FW_API4_FILE);\nMODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR \"/\" ATH10K_FW_API5_FILE);\nMODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR \"/\" QCA988X_HW_2_0_BOARD_DATA_FILE);\nMODULE_FIRMWARE(QCA988X_HW_2_0_FW_DIR \"/\" ATH10K_BOARD_API2_FILE);\n\n \nMODULE_FIRMWARE(QCA9887_HW_1_0_FW_DIR \"/\" ATH10K_FW_API5_FILE);\nMODULE_FIRMWARE(QCA9887_HW_1_0_FW_DIR \"/\" QCA9887_HW_1_0_BOARD_DATA_FILE);\nMODULE_FIRMWARE(QCA9887_HW_1_0_FW_DIR \"/\" ATH10K_BOARD_API2_FILE);\n\n \nMODULE_FIRMWARE(QCA6174_HW_2_1_FW_DIR \"/\" ATH10K_FW_API4_FILE);\nMODULE_FIRMWARE(QCA6174_HW_2_1_FW_DIR \"/\" ATH10K_FW_API5_FILE);\nMODULE_FIRMWARE(QCA6174_HW_2_1_FW_DIR \"/\" QCA6174_HW_2_1_BOARD_DATA_FILE);\nMODULE_FIRMWARE(QCA6174_HW_2_1_FW_DIR \"/\" ATH10K_BOARD_API2_FILE);\n\n \nMODULE_FIRMWARE(QCA6174_HW_3_0_FW_DIR \"/\" ATH10K_FW_API4_FILE);\nMODULE_FIRMWARE(QCA6174_HW_3_0_FW_DIR \"/\" ATH10K_FW_API5_FILE);\nMODULE_FIRMWARE(QCA6174_HW_3_0_FW_DIR \"/\" ATH10K_FW_API6_FILE);\nMODULE_FIRMWARE(QCA6174_HW_3_0_FW_DIR \"/\" QCA6174_HW_3_0_BOARD_DATA_FILE);\nMODULE_FIRMWARE(QCA6174_HW_3_0_FW_DIR \"/\" ATH10K_BOARD_API2_FILE);\n\n \nMODULE_FIRMWARE(QCA9377_HW_1_0_FW_DIR \"/\" ATH10K_FW_API6_FILE);\nMODULE_FIRMWARE(QCA9377_HW_1_0_FW_DIR \"/\" ATH10K_FW_API5_FILE);\nMODULE_FIRMWARE(QCA9377_HW_1_0_FW_DIR \"/\" QCA9377_HW_1_0_BOARD_DATA_FILE);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}