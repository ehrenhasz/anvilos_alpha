{
  "module_name": "htt_rx.c",
  "hash_id": "ed0662f6e682efb2679c34a04e76d38986ca70745d6301f8c771e787f2057ccc",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ath/ath10k/htt_rx.c",
  "human_readable_source": "\n \n\n#include \"core.h\"\n#include \"htc.h\"\n#include \"htt.h\"\n#include \"txrx.h\"\n#include \"debug.h\"\n#include \"trace.h\"\n#include \"mac.h\"\n\n#include <linux/log2.h>\n#include <linux/bitfield.h>\n\n \n#define HTT_RX_RING_REFILL_RETRY_MS 50\n\n#define HTT_RX_RING_REFILL_RESCHED_MS 5\n\n \n#define HTT_RX_BUF_TO_RX_DESC(hw, buf) ath10k_htt_rx_desc_from_raw_buffer(hw, buf)\n\nstatic int ath10k_htt_rx_get_csum_state(struct ath10k_hw_params *hw, struct sk_buff *skb);\n\nstatic struct sk_buff *\nath10k_htt_rx_find_skb_paddr(struct ath10k *ar, u64 paddr)\n{\n\tstruct ath10k_skb_rxcb *rxcb;\n\n\thash_for_each_possible(ar->htt.rx_ring.skb_table, rxcb, hlist, paddr)\n\t\tif (rxcb->paddr == paddr)\n\t\t\treturn ATH10K_RXCB_SKB(rxcb);\n\n\tWARN_ON_ONCE(1);\n\treturn NULL;\n}\n\nstatic void ath10k_htt_rx_ring_free(struct ath10k_htt *htt)\n{\n\tstruct sk_buff *skb;\n\tstruct ath10k_skb_rxcb *rxcb;\n\tstruct hlist_node *n;\n\tint i;\n\n\tif (htt->rx_ring.in_ord_rx) {\n\t\thash_for_each_safe(htt->rx_ring.skb_table, i, n, rxcb, hlist) {\n\t\t\tskb = ATH10K_RXCB_SKB(rxcb);\n\t\t\tdma_unmap_single(htt->ar->dev, rxcb->paddr,\n\t\t\t\t\t skb->len + skb_tailroom(skb),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\thash_del(&rxcb->hlist);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < htt->rx_ring.size; i++) {\n\t\t\tskb = htt->rx_ring.netbufs_ring[i];\n\t\t\tif (!skb)\n\t\t\t\tcontinue;\n\n\t\t\trxcb = ATH10K_SKB_RXCB(skb);\n\t\t\tdma_unmap_single(htt->ar->dev, rxcb->paddr,\n\t\t\t\t\t skb->len + skb_tailroom(skb),\n\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t}\n\t}\n\n\thtt->rx_ring.fill_cnt = 0;\n\thash_init(htt->rx_ring.skb_table);\n\tmemset(htt->rx_ring.netbufs_ring, 0,\n\t       htt->rx_ring.size * sizeof(htt->rx_ring.netbufs_ring[0]));\n}\n\nstatic size_t ath10k_htt_get_rx_ring_size_32(struct ath10k_htt *htt)\n{\n\treturn htt->rx_ring.size * sizeof(htt->rx_ring.paddrs_ring_32);\n}\n\nstatic size_t ath10k_htt_get_rx_ring_size_64(struct ath10k_htt *htt)\n{\n\treturn htt->rx_ring.size * sizeof(htt->rx_ring.paddrs_ring_64);\n}\n\nstatic void ath10k_htt_config_paddrs_ring_32(struct ath10k_htt *htt,\n\t\t\t\t\t     void *vaddr)\n{\n\thtt->rx_ring.paddrs_ring_32 = vaddr;\n}\n\nstatic void ath10k_htt_config_paddrs_ring_64(struct ath10k_htt *htt,\n\t\t\t\t\t     void *vaddr)\n{\n\thtt->rx_ring.paddrs_ring_64 = vaddr;\n}\n\nstatic void ath10k_htt_set_paddrs_ring_32(struct ath10k_htt *htt,\n\t\t\t\t\t  dma_addr_t paddr, int idx)\n{\n\thtt->rx_ring.paddrs_ring_32[idx] = __cpu_to_le32(paddr);\n}\n\nstatic void ath10k_htt_set_paddrs_ring_64(struct ath10k_htt *htt,\n\t\t\t\t\t  dma_addr_t paddr, int idx)\n{\n\thtt->rx_ring.paddrs_ring_64[idx] = __cpu_to_le64(paddr);\n}\n\nstatic void ath10k_htt_reset_paddrs_ring_32(struct ath10k_htt *htt, int idx)\n{\n\thtt->rx_ring.paddrs_ring_32[idx] = 0;\n}\n\nstatic void ath10k_htt_reset_paddrs_ring_64(struct ath10k_htt *htt, int idx)\n{\n\thtt->rx_ring.paddrs_ring_64[idx] = 0;\n}\n\nstatic void *ath10k_htt_get_vaddr_ring_32(struct ath10k_htt *htt)\n{\n\treturn (void *)htt->rx_ring.paddrs_ring_32;\n}\n\nstatic void *ath10k_htt_get_vaddr_ring_64(struct ath10k_htt *htt)\n{\n\treturn (void *)htt->rx_ring.paddrs_ring_64;\n}\n\nstatic int __ath10k_htt_rx_ring_fill_n(struct ath10k_htt *htt, int num)\n{\n\tstruct ath10k_hw_params *hw = &htt->ar->hw_params;\n\tstruct htt_rx_desc *rx_desc;\n\tstruct ath10k_skb_rxcb *rxcb;\n\tstruct sk_buff *skb;\n\tdma_addr_t paddr;\n\tint ret = 0, idx;\n\n\t \n\tBUILD_BUG_ON(HTT_RX_RING_FILL_LEVEL >= HTT_RX_RING_SIZE / 2);\n\n\tidx = __le32_to_cpu(*htt->rx_ring.alloc_idx.vaddr);\n\n\tif (idx < 0 || idx >= htt->rx_ring.size) {\n\t\tath10k_err(htt->ar, \"rx ring index is not valid, firmware malfunctioning?\\n\");\n\t\tidx &= htt->rx_ring.size_mask;\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\n\twhile (num > 0) {\n\t\tskb = dev_alloc_skb(HTT_RX_BUF_SIZE + HTT_RX_DESC_ALIGN);\n\t\tif (!skb) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\tif (!IS_ALIGNED((unsigned long)skb->data, HTT_RX_DESC_ALIGN))\n\t\t\tskb_pull(skb,\n\t\t\t\t PTR_ALIGN(skb->data, HTT_RX_DESC_ALIGN) -\n\t\t\t\t skb->data);\n\n\t\t \n\t\trx_desc = HTT_RX_BUF_TO_RX_DESC(hw, skb->data);\n\t\tath10k_htt_rx_desc_get_attention(hw, rx_desc)->flags = __cpu_to_le32(0);\n\n\t\tpaddr = dma_map_single(htt->ar->dev, skb->data,\n\t\t\t\t       skb->len + skb_tailroom(skb),\n\t\t\t\t       DMA_FROM_DEVICE);\n\n\t\tif (unlikely(dma_mapping_error(htt->ar->dev, paddr))) {\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\n\t\trxcb = ATH10K_SKB_RXCB(skb);\n\t\trxcb->paddr = paddr;\n\t\thtt->rx_ring.netbufs_ring[idx] = skb;\n\t\tath10k_htt_set_paddrs_ring(htt, paddr, idx);\n\t\thtt->rx_ring.fill_cnt++;\n\n\t\tif (htt->rx_ring.in_ord_rx) {\n\t\t\thash_add(htt->rx_ring.skb_table,\n\t\t\t\t &ATH10K_SKB_RXCB(skb)->hlist,\n\t\t\t\t paddr);\n\t\t}\n\n\t\tnum--;\n\t\tidx++;\n\t\tidx &= htt->rx_ring.size_mask;\n\t}\n\nfail:\n\t \n\tmb();\n\t*htt->rx_ring.alloc_idx.vaddr = __cpu_to_le32(idx);\n\treturn ret;\n}\n\nstatic int ath10k_htt_rx_ring_fill_n(struct ath10k_htt *htt, int num)\n{\n\tlockdep_assert_held(&htt->rx_ring.lock);\n\treturn __ath10k_htt_rx_ring_fill_n(htt, num);\n}\n\nstatic void ath10k_htt_rx_msdu_buff_replenish(struct ath10k_htt *htt)\n{\n\tint ret, num_deficit, num_to_fill;\n\n\t \n\tspin_lock_bh(&htt->rx_ring.lock);\n\tnum_deficit = htt->rx_ring.fill_level - htt->rx_ring.fill_cnt;\n\tnum_to_fill = min(ATH10K_HTT_MAX_NUM_REFILL, num_deficit);\n\tnum_deficit -= num_to_fill;\n\tret = ath10k_htt_rx_ring_fill_n(htt, num_to_fill);\n\tif (ret == -ENOMEM) {\n\t\t \n\t\tmod_timer(&htt->rx_ring.refill_retry_timer, jiffies +\n\t\t\t  msecs_to_jiffies(HTT_RX_RING_REFILL_RETRY_MS));\n\t} else if (num_deficit > 0) {\n\t\tmod_timer(&htt->rx_ring.refill_retry_timer, jiffies +\n\t\t\t  msecs_to_jiffies(HTT_RX_RING_REFILL_RESCHED_MS));\n\t}\n\tspin_unlock_bh(&htt->rx_ring.lock);\n}\n\nstatic void ath10k_htt_rx_ring_refill_retry(struct timer_list *t)\n{\n\tstruct ath10k_htt *htt = from_timer(htt, t, rx_ring.refill_retry_timer);\n\n\tath10k_htt_rx_msdu_buff_replenish(htt);\n}\n\nint ath10k_htt_rx_ring_refill(struct ath10k *ar)\n{\n\tstruct ath10k_htt *htt = &ar->htt;\n\tint ret;\n\n\tif (ar->bus_param.dev_type == ATH10K_DEV_TYPE_HL)\n\t\treturn 0;\n\n\tspin_lock_bh(&htt->rx_ring.lock);\n\tret = ath10k_htt_rx_ring_fill_n(htt, (htt->rx_ring.fill_level -\n\t\t\t\t\t      htt->rx_ring.fill_cnt));\n\n\tif (ret)\n\t\tath10k_htt_rx_ring_free(htt);\n\n\tspin_unlock_bh(&htt->rx_ring.lock);\n\n\treturn ret;\n}\n\nvoid ath10k_htt_rx_free(struct ath10k_htt *htt)\n{\n\tif (htt->ar->bus_param.dev_type == ATH10K_DEV_TYPE_HL)\n\t\treturn;\n\n\tdel_timer_sync(&htt->rx_ring.refill_retry_timer);\n\n\tskb_queue_purge(&htt->rx_msdus_q);\n\tskb_queue_purge(&htt->rx_in_ord_compl_q);\n\tskb_queue_purge(&htt->tx_fetch_ind_q);\n\n\tspin_lock_bh(&htt->rx_ring.lock);\n\tath10k_htt_rx_ring_free(htt);\n\tspin_unlock_bh(&htt->rx_ring.lock);\n\n\tdma_free_coherent(htt->ar->dev,\n\t\t\t  ath10k_htt_get_rx_ring_size(htt),\n\t\t\t  ath10k_htt_get_vaddr_ring(htt),\n\t\t\t  htt->rx_ring.base_paddr);\n\n\tath10k_htt_config_paddrs_ring(htt, NULL);\n\n\tdma_free_coherent(htt->ar->dev,\n\t\t\t  sizeof(*htt->rx_ring.alloc_idx.vaddr),\n\t\t\t  htt->rx_ring.alloc_idx.vaddr,\n\t\t\t  htt->rx_ring.alloc_idx.paddr);\n\thtt->rx_ring.alloc_idx.vaddr = NULL;\n\n\tkfree(htt->rx_ring.netbufs_ring);\n\thtt->rx_ring.netbufs_ring = NULL;\n}\n\nstatic inline struct sk_buff *ath10k_htt_rx_netbuf_pop(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tint idx;\n\tstruct sk_buff *msdu;\n\n\tlockdep_assert_held(&htt->rx_ring.lock);\n\n\tif (htt->rx_ring.fill_cnt == 0) {\n\t\tath10k_warn(ar, \"tried to pop sk_buff from an empty rx ring\\n\");\n\t\treturn NULL;\n\t}\n\n\tidx = htt->rx_ring.sw_rd_idx.msdu_payld;\n\tmsdu = htt->rx_ring.netbufs_ring[idx];\n\thtt->rx_ring.netbufs_ring[idx] = NULL;\n\tath10k_htt_reset_paddrs_ring(htt, idx);\n\n\tidx++;\n\tidx &= htt->rx_ring.size_mask;\n\thtt->rx_ring.sw_rd_idx.msdu_payld = idx;\n\thtt->rx_ring.fill_cnt--;\n\n\tdma_unmap_single(htt->ar->dev,\n\t\t\t ATH10K_SKB_RXCB(msdu)->paddr,\n\t\t\t msdu->len + skb_tailroom(msdu),\n\t\t\t DMA_FROM_DEVICE);\n\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"htt rx netbuf pop: \",\n\t\t\tmsdu->data, msdu->len + skb_tailroom(msdu));\n\n\treturn msdu;\n}\n\n \nstatic int ath10k_htt_rx_amsdu_pop(struct ath10k_htt *htt,\n\t\t\t\t   struct sk_buff_head *amsdu)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tint msdu_len, msdu_chaining = 0;\n\tstruct sk_buff *msdu;\n\tstruct htt_rx_desc *rx_desc;\n\tstruct rx_attention *rx_desc_attention;\n\tstruct rx_frag_info_common *rx_desc_frag_info_common;\n\tstruct rx_msdu_start_common *rx_desc_msdu_start_common;\n\tstruct rx_msdu_end_common *rx_desc_msdu_end_common;\n\n\tlockdep_assert_held(&htt->rx_ring.lock);\n\n\tfor (;;) {\n\t\tint last_msdu, msdu_len_invalid, msdu_chained;\n\n\t\tmsdu = ath10k_htt_rx_netbuf_pop(htt);\n\t\tif (!msdu) {\n\t\t\t__skb_queue_purge(amsdu);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\t__skb_queue_tail(amsdu, msdu);\n\n\t\trx_desc = HTT_RX_BUF_TO_RX_DESC(hw, msdu->data);\n\t\trx_desc_attention = ath10k_htt_rx_desc_get_attention(hw, rx_desc);\n\t\trx_desc_msdu_start_common = ath10k_htt_rx_desc_get_msdu_start(hw,\n\t\t\t\t\t\t\t\t\t      rx_desc);\n\t\trx_desc_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rx_desc);\n\t\trx_desc_frag_info_common = ath10k_htt_rx_desc_get_frag_info(hw, rx_desc);\n\n\t\t \n\t\tskb_put(msdu, hw->rx_desc_ops->rx_desc_msdu_payload_offset);\n\t\tskb_pull(msdu, hw->rx_desc_ops->rx_desc_msdu_payload_offset);\n\n\t\t \n\t\tif (!(__le32_to_cpu(rx_desc_attention->flags)\n\t\t\t\t& RX_ATTENTION_FLAGS_MSDU_DONE)) {\n\t\t\t__skb_queue_purge(amsdu);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tmsdu_len_invalid = !!(__le32_to_cpu(rx_desc_attention->flags)\n\t\t\t\t\t& (RX_ATTENTION_FLAGS_MPDU_LENGTH_ERR |\n\t\t\t\t\t   RX_ATTENTION_FLAGS_MSDU_LENGTH_ERR));\n\t\tmsdu_len = MS(__le32_to_cpu(rx_desc_msdu_start_common->info0),\n\t\t\t      RX_MSDU_START_INFO0_MSDU_LENGTH);\n\t\tmsdu_chained = rx_desc_frag_info_common->ring2_more_count;\n\n\t\tif (msdu_len_invalid)\n\t\t\tmsdu_len = 0;\n\n\t\tskb_trim(msdu, 0);\n\t\tskb_put(msdu, min(msdu_len, ath10k_htt_rx_msdu_size(hw)));\n\t\tmsdu_len -= msdu->len;\n\n\t\t \n\t\twhile (msdu_chained--) {\n\t\t\tmsdu = ath10k_htt_rx_netbuf_pop(htt);\n\t\t\tif (!msdu) {\n\t\t\t\t__skb_queue_purge(amsdu);\n\t\t\t\treturn -ENOENT;\n\t\t\t}\n\n\t\t\t__skb_queue_tail(amsdu, msdu);\n\t\t\tskb_trim(msdu, 0);\n\t\t\tskb_put(msdu, min(msdu_len, HTT_RX_BUF_SIZE));\n\t\t\tmsdu_len -= msdu->len;\n\t\t\tmsdu_chaining = 1;\n\t\t}\n\n\t\tlast_msdu = __le32_to_cpu(rx_desc_msdu_end_common->info0) &\n\t\t\t\tRX_MSDU_END_INFO0_LAST_MSDU;\n\n\t\t \n\t\ttrace_ath10k_htt_rx_desc(ar, (void *)rx_desc + sizeof(u32),\n\t\t\t\t\t hw->rx_desc_ops->rx_desc_size - sizeof(u32));\n\n\t\tif (last_msdu)\n\t\t\tbreak;\n\t}\n\n\tif (skb_queue_empty(amsdu))\n\t\tmsdu_chaining = -1;\n\n\t \n\n\treturn msdu_chaining;\n}\n\nstatic struct sk_buff *ath10k_htt_rx_pop_paddr(struct ath10k_htt *htt,\n\t\t\t\t\t       u64 paddr)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_skb_rxcb *rxcb;\n\tstruct sk_buff *msdu;\n\n\tlockdep_assert_held(&htt->rx_ring.lock);\n\n\tmsdu = ath10k_htt_rx_find_skb_paddr(ar, paddr);\n\tif (!msdu)\n\t\treturn NULL;\n\n\trxcb = ATH10K_SKB_RXCB(msdu);\n\thash_del(&rxcb->hlist);\n\thtt->rx_ring.fill_cnt--;\n\n\tdma_unmap_single(htt->ar->dev, rxcb->paddr,\n\t\t\t msdu->len + skb_tailroom(msdu),\n\t\t\t DMA_FROM_DEVICE);\n\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"htt rx netbuf pop: \",\n\t\t\tmsdu->data, msdu->len + skb_tailroom(msdu));\n\n\treturn msdu;\n}\n\nstatic inline void ath10k_htt_append_frag_list(struct sk_buff *skb_head,\n\t\t\t\t\t       struct sk_buff *frag_list,\n\t\t\t\t\t       unsigned int frag_len)\n{\n\tskb_shinfo(skb_head)->frag_list = frag_list;\n\tskb_head->data_len = frag_len;\n\tskb_head->len += skb_head->data_len;\n}\n\nstatic int ath10k_htt_rx_handle_amsdu_mon_32(struct ath10k_htt *htt,\n\t\t\t\t\t     struct sk_buff *msdu,\n\t\t\t\t\t     struct htt_rx_in_ord_msdu_desc **msdu_desc)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tu32 paddr;\n\tstruct sk_buff *frag_buf;\n\tstruct sk_buff *prev_frag_buf;\n\tu8 last_frag;\n\tstruct htt_rx_in_ord_msdu_desc *ind_desc = *msdu_desc;\n\tstruct htt_rx_desc *rxd;\n\tint amsdu_len = __le16_to_cpu(ind_desc->msdu_len);\n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw, msdu->data);\n\ttrace_ath10k_htt_rx_desc(ar, rxd, hw->rx_desc_ops->rx_desc_size);\n\n\tskb_put(msdu, hw->rx_desc_ops->rx_desc_size);\n\tskb_pull(msdu, hw->rx_desc_ops->rx_desc_size);\n\tskb_put(msdu, min(amsdu_len, ath10k_htt_rx_msdu_size(hw)));\n\tamsdu_len -= msdu->len;\n\n\tlast_frag = ind_desc->reserved;\n\tif (last_frag) {\n\t\tif (amsdu_len) {\n\t\t\tath10k_warn(ar, \"invalid amsdu len %u, left %d\",\n\t\t\t\t    __le16_to_cpu(ind_desc->msdu_len),\n\t\t\t\t    amsdu_len);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tind_desc++;\n\tpaddr = __le32_to_cpu(ind_desc->msdu_paddr);\n\tfrag_buf = ath10k_htt_rx_pop_paddr(htt, paddr);\n\tif (!frag_buf) {\n\t\tath10k_warn(ar, \"failed to pop frag-1 paddr: 0x%x\", paddr);\n\t\treturn -ENOENT;\n\t}\n\n\tskb_put(frag_buf, min(amsdu_len, HTT_RX_BUF_SIZE));\n\tath10k_htt_append_frag_list(msdu, frag_buf, amsdu_len);\n\n\tamsdu_len -= frag_buf->len;\n\tprev_frag_buf = frag_buf;\n\tlast_frag = ind_desc->reserved;\n\twhile (!last_frag) {\n\t\tind_desc++;\n\t\tpaddr = __le32_to_cpu(ind_desc->msdu_paddr);\n\t\tfrag_buf = ath10k_htt_rx_pop_paddr(htt, paddr);\n\t\tif (!frag_buf) {\n\t\t\tath10k_warn(ar, \"failed to pop frag-n paddr: 0x%x\",\n\t\t\t\t    paddr);\n\t\t\tprev_frag_buf->next = NULL;\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tskb_put(frag_buf, min(amsdu_len, HTT_RX_BUF_SIZE));\n\t\tlast_frag = ind_desc->reserved;\n\t\tamsdu_len -= frag_buf->len;\n\n\t\tprev_frag_buf->next = frag_buf;\n\t\tprev_frag_buf = frag_buf;\n\t}\n\n\tif (amsdu_len) {\n\t\tath10k_warn(ar, \"invalid amsdu len %u, left %d\",\n\t\t\t    __le16_to_cpu(ind_desc->msdu_len), amsdu_len);\n\t}\n\n\t*msdu_desc = ind_desc;\n\n\tprev_frag_buf->next = NULL;\n\treturn 0;\n}\n\nstatic int\nath10k_htt_rx_handle_amsdu_mon_64(struct ath10k_htt *htt,\n\t\t\t\t  struct sk_buff *msdu,\n\t\t\t\t  struct htt_rx_in_ord_msdu_desc_ext **msdu_desc)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tu64 paddr;\n\tstruct sk_buff *frag_buf;\n\tstruct sk_buff *prev_frag_buf;\n\tu8 last_frag;\n\tstruct htt_rx_in_ord_msdu_desc_ext *ind_desc = *msdu_desc;\n\tstruct htt_rx_desc *rxd;\n\tint amsdu_len = __le16_to_cpu(ind_desc->msdu_len);\n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw, msdu->data);\n\ttrace_ath10k_htt_rx_desc(ar, rxd, hw->rx_desc_ops->rx_desc_size);\n\n\tskb_put(msdu, hw->rx_desc_ops->rx_desc_size);\n\tskb_pull(msdu, hw->rx_desc_ops->rx_desc_size);\n\tskb_put(msdu, min(amsdu_len, ath10k_htt_rx_msdu_size(hw)));\n\tamsdu_len -= msdu->len;\n\n\tlast_frag = ind_desc->reserved;\n\tif (last_frag) {\n\t\tif (amsdu_len) {\n\t\t\tath10k_warn(ar, \"invalid amsdu len %u, left %d\",\n\t\t\t\t    __le16_to_cpu(ind_desc->msdu_len),\n\t\t\t\t    amsdu_len);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tind_desc++;\n\tpaddr = __le64_to_cpu(ind_desc->msdu_paddr);\n\tfrag_buf = ath10k_htt_rx_pop_paddr(htt, paddr);\n\tif (!frag_buf) {\n\t\tath10k_warn(ar, \"failed to pop frag-1 paddr: 0x%llx\", paddr);\n\t\treturn -ENOENT;\n\t}\n\n\tskb_put(frag_buf, min(amsdu_len, HTT_RX_BUF_SIZE));\n\tath10k_htt_append_frag_list(msdu, frag_buf, amsdu_len);\n\n\tamsdu_len -= frag_buf->len;\n\tprev_frag_buf = frag_buf;\n\tlast_frag = ind_desc->reserved;\n\twhile (!last_frag) {\n\t\tind_desc++;\n\t\tpaddr = __le64_to_cpu(ind_desc->msdu_paddr);\n\t\tfrag_buf = ath10k_htt_rx_pop_paddr(htt, paddr);\n\t\tif (!frag_buf) {\n\t\t\tath10k_warn(ar, \"failed to pop frag-n paddr: 0x%llx\",\n\t\t\t\t    paddr);\n\t\t\tprev_frag_buf->next = NULL;\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tskb_put(frag_buf, min(amsdu_len, HTT_RX_BUF_SIZE));\n\t\tlast_frag = ind_desc->reserved;\n\t\tamsdu_len -= frag_buf->len;\n\n\t\tprev_frag_buf->next = frag_buf;\n\t\tprev_frag_buf = frag_buf;\n\t}\n\n\tif (amsdu_len) {\n\t\tath10k_warn(ar, \"invalid amsdu len %u, left %d\",\n\t\t\t    __le16_to_cpu(ind_desc->msdu_len), amsdu_len);\n\t}\n\n\t*msdu_desc = ind_desc;\n\n\tprev_frag_buf->next = NULL;\n\treturn 0;\n}\n\nstatic int ath10k_htt_rx_pop_paddr32_list(struct ath10k_htt *htt,\n\t\t\t\t\t  struct htt_rx_in_ord_ind *ev,\n\t\t\t\t\t  struct sk_buff_head *list)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_in_ord_msdu_desc *msdu_desc = ev->msdu_descs32;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_attention *rxd_attention;\n\tstruct sk_buff *msdu;\n\tint msdu_count, ret;\n\tbool is_offload;\n\tu32 paddr;\n\n\tlockdep_assert_held(&htt->rx_ring.lock);\n\n\tmsdu_count = __le16_to_cpu(ev->msdu_count);\n\tis_offload = !!(ev->info & HTT_RX_IN_ORD_IND_INFO_OFFLOAD_MASK);\n\n\twhile (msdu_count--) {\n\t\tpaddr = __le32_to_cpu(msdu_desc->msdu_paddr);\n\n\t\tmsdu = ath10k_htt_rx_pop_paddr(htt, paddr);\n\t\tif (!msdu) {\n\t\t\t__skb_queue_purge(list);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tif (!is_offload && ar->monitor_arvif) {\n\t\t\tret = ath10k_htt_rx_handle_amsdu_mon_32(htt, msdu,\n\t\t\t\t\t\t\t\t&msdu_desc);\n\t\t\tif (ret) {\n\t\t\t\t__skb_queue_purge(list);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t\t__skb_queue_tail(list, msdu);\n\t\t\tmsdu_desc++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t__skb_queue_tail(list, msdu);\n\n\t\tif (!is_offload) {\n\t\t\trxd = HTT_RX_BUF_TO_RX_DESC(hw, msdu->data);\n\t\t\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\n\t\t\ttrace_ath10k_htt_rx_desc(ar, rxd, hw->rx_desc_ops->rx_desc_size);\n\n\t\t\tskb_put(msdu, hw->rx_desc_ops->rx_desc_size);\n\t\t\tskb_pull(msdu, hw->rx_desc_ops->rx_desc_size);\n\t\t\tskb_put(msdu, __le16_to_cpu(msdu_desc->msdu_len));\n\n\t\t\tif (!(__le32_to_cpu(rxd_attention->flags) &\n\t\t\t      RX_ATTENTION_FLAGS_MSDU_DONE)) {\n\t\t\t\tath10k_warn(htt->ar, \"tried to pop an incomplete frame, oops!\\n\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tmsdu_desc++;\n\t}\n\n\treturn 0;\n}\n\nstatic int ath10k_htt_rx_pop_paddr64_list(struct ath10k_htt *htt,\n\t\t\t\t\t  struct htt_rx_in_ord_ind *ev,\n\t\t\t\t\t  struct sk_buff_head *list)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_in_ord_msdu_desc_ext *msdu_desc = ev->msdu_descs64;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_attention *rxd_attention;\n\tstruct sk_buff *msdu;\n\tint msdu_count, ret;\n\tbool is_offload;\n\tu64 paddr;\n\n\tlockdep_assert_held(&htt->rx_ring.lock);\n\n\tmsdu_count = __le16_to_cpu(ev->msdu_count);\n\tis_offload = !!(ev->info & HTT_RX_IN_ORD_IND_INFO_OFFLOAD_MASK);\n\n\twhile (msdu_count--) {\n\t\tpaddr = __le64_to_cpu(msdu_desc->msdu_paddr);\n\t\tmsdu = ath10k_htt_rx_pop_paddr(htt, paddr);\n\t\tif (!msdu) {\n\t\t\t__skb_queue_purge(list);\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\tif (!is_offload && ar->monitor_arvif) {\n\t\t\tret = ath10k_htt_rx_handle_amsdu_mon_64(htt, msdu,\n\t\t\t\t\t\t\t\t&msdu_desc);\n\t\t\tif (ret) {\n\t\t\t\t__skb_queue_purge(list);\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t\t__skb_queue_tail(list, msdu);\n\t\t\tmsdu_desc++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t__skb_queue_tail(list, msdu);\n\n\t\tif (!is_offload) {\n\t\t\trxd = HTT_RX_BUF_TO_RX_DESC(hw, msdu->data);\n\t\t\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\n\t\t\ttrace_ath10k_htt_rx_desc(ar, rxd, hw->rx_desc_ops->rx_desc_size);\n\n\t\t\tskb_put(msdu, hw->rx_desc_ops->rx_desc_size);\n\t\t\tskb_pull(msdu, hw->rx_desc_ops->rx_desc_size);\n\t\t\tskb_put(msdu, __le16_to_cpu(msdu_desc->msdu_len));\n\n\t\t\tif (!(__le32_to_cpu(rxd_attention->flags) &\n\t\t\t      RX_ATTENTION_FLAGS_MSDU_DONE)) {\n\t\t\t\tath10k_warn(htt->ar, \"tried to pop an incomplete frame, oops!\\n\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t}\n\n\t\tmsdu_desc++;\n\t}\n\n\treturn 0;\n}\n\nint ath10k_htt_rx_alloc(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tdma_addr_t paddr;\n\tvoid *vaddr, *vaddr_ring;\n\tsize_t size;\n\tstruct timer_list *timer = &htt->rx_ring.refill_retry_timer;\n\n\tif (ar->bus_param.dev_type == ATH10K_DEV_TYPE_HL)\n\t\treturn 0;\n\n\thtt->rx_confused = false;\n\n\t \n\thtt->rx_ring.size = HTT_RX_RING_SIZE;\n\thtt->rx_ring.size_mask = htt->rx_ring.size - 1;\n\thtt->rx_ring.fill_level = ar->hw_params.rx_ring_fill_level;\n\n\tif (!is_power_of_2(htt->rx_ring.size)) {\n\t\tath10k_warn(ar, \"htt rx ring size is not power of 2\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\thtt->rx_ring.netbufs_ring =\n\t\tkcalloc(htt->rx_ring.size, sizeof(struct sk_buff *),\n\t\t\tGFP_KERNEL);\n\tif (!htt->rx_ring.netbufs_ring)\n\t\tgoto err_netbuf;\n\n\tsize = ath10k_htt_get_rx_ring_size(htt);\n\n\tvaddr_ring = dma_alloc_coherent(htt->ar->dev, size, &paddr, GFP_KERNEL);\n\tif (!vaddr_ring)\n\t\tgoto err_dma_ring;\n\n\tath10k_htt_config_paddrs_ring(htt, vaddr_ring);\n\thtt->rx_ring.base_paddr = paddr;\n\n\tvaddr = dma_alloc_coherent(htt->ar->dev,\n\t\t\t\t   sizeof(*htt->rx_ring.alloc_idx.vaddr),\n\t\t\t\t   &paddr, GFP_KERNEL);\n\tif (!vaddr)\n\t\tgoto err_dma_idx;\n\n\thtt->rx_ring.alloc_idx.vaddr = vaddr;\n\thtt->rx_ring.alloc_idx.paddr = paddr;\n\thtt->rx_ring.sw_rd_idx.msdu_payld = htt->rx_ring.size_mask;\n\t*htt->rx_ring.alloc_idx.vaddr = 0;\n\n\t \n\ttimer_setup(timer, ath10k_htt_rx_ring_refill_retry, 0);\n\n\tspin_lock_init(&htt->rx_ring.lock);\n\n\thtt->rx_ring.fill_cnt = 0;\n\thtt->rx_ring.sw_rd_idx.msdu_payld = 0;\n\thash_init(htt->rx_ring.skb_table);\n\n\tskb_queue_head_init(&htt->rx_msdus_q);\n\tskb_queue_head_init(&htt->rx_in_ord_compl_q);\n\tskb_queue_head_init(&htt->tx_fetch_ind_q);\n\tatomic_set(&htt->num_mpdus_ready, 0);\n\n\tath10k_dbg(ar, ATH10K_DBG_BOOT, \"htt rx ring size %d fill_level %d\\n\",\n\t\t   htt->rx_ring.size, htt->rx_ring.fill_level);\n\treturn 0;\n\nerr_dma_idx:\n\tdma_free_coherent(htt->ar->dev,\n\t\t\t  ath10k_htt_get_rx_ring_size(htt),\n\t\t\t  vaddr_ring,\n\t\t\t  htt->rx_ring.base_paddr);\n\tath10k_htt_config_paddrs_ring(htt, NULL);\nerr_dma_ring:\n\tkfree(htt->rx_ring.netbufs_ring);\n\thtt->rx_ring.netbufs_ring = NULL;\nerr_netbuf:\n\treturn -ENOMEM;\n}\n\nstatic int ath10k_htt_rx_crypto_param_len(struct ath10k *ar,\n\t\t\t\t\t  enum htt_rx_mpdu_encrypt_type type)\n{\n\tswitch (type) {\n\tcase HTT_RX_MPDU_ENCRYPT_NONE:\n\t\treturn 0;\n\tcase HTT_RX_MPDU_ENCRYPT_WEP40:\n\tcase HTT_RX_MPDU_ENCRYPT_WEP104:\n\t\treturn IEEE80211_WEP_IV_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_TKIP_WITHOUT_MIC:\n\tcase HTT_RX_MPDU_ENCRYPT_TKIP_WPA:\n\t\treturn IEEE80211_TKIP_IV_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_AES_CCM_WPA2:\n\t\treturn IEEE80211_CCMP_HDR_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_AES_CCM256_WPA2:\n\t\treturn IEEE80211_CCMP_256_HDR_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_AES_GCMP_WPA2:\n\tcase HTT_RX_MPDU_ENCRYPT_AES_GCMP256_WPA2:\n\t\treturn IEEE80211_GCMP_HDR_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_WEP128:\n\tcase HTT_RX_MPDU_ENCRYPT_WAPI:\n\t\tbreak;\n\t}\n\n\tath10k_warn(ar, \"unsupported encryption type %d\\n\", type);\n\treturn 0;\n}\n\n#define MICHAEL_MIC_LEN 8\n\nstatic int ath10k_htt_rx_crypto_mic_len(struct ath10k *ar,\n\t\t\t\t\tenum htt_rx_mpdu_encrypt_type type)\n{\n\tswitch (type) {\n\tcase HTT_RX_MPDU_ENCRYPT_NONE:\n\tcase HTT_RX_MPDU_ENCRYPT_WEP40:\n\tcase HTT_RX_MPDU_ENCRYPT_WEP104:\n\tcase HTT_RX_MPDU_ENCRYPT_TKIP_WITHOUT_MIC:\n\tcase HTT_RX_MPDU_ENCRYPT_TKIP_WPA:\n\t\treturn 0;\n\tcase HTT_RX_MPDU_ENCRYPT_AES_CCM_WPA2:\n\t\treturn IEEE80211_CCMP_MIC_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_AES_CCM256_WPA2:\n\t\treturn IEEE80211_CCMP_256_MIC_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_AES_GCMP_WPA2:\n\tcase HTT_RX_MPDU_ENCRYPT_AES_GCMP256_WPA2:\n\t\treturn IEEE80211_GCMP_MIC_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_WEP128:\n\tcase HTT_RX_MPDU_ENCRYPT_WAPI:\n\t\tbreak;\n\t}\n\n\tath10k_warn(ar, \"unsupported encryption type %d\\n\", type);\n\treturn 0;\n}\n\nstatic int ath10k_htt_rx_crypto_icv_len(struct ath10k *ar,\n\t\t\t\t\tenum htt_rx_mpdu_encrypt_type type)\n{\n\tswitch (type) {\n\tcase HTT_RX_MPDU_ENCRYPT_NONE:\n\tcase HTT_RX_MPDU_ENCRYPT_AES_CCM_WPA2:\n\tcase HTT_RX_MPDU_ENCRYPT_AES_CCM256_WPA2:\n\tcase HTT_RX_MPDU_ENCRYPT_AES_GCMP_WPA2:\n\tcase HTT_RX_MPDU_ENCRYPT_AES_GCMP256_WPA2:\n\t\treturn 0;\n\tcase HTT_RX_MPDU_ENCRYPT_WEP40:\n\tcase HTT_RX_MPDU_ENCRYPT_WEP104:\n\t\treturn IEEE80211_WEP_ICV_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_TKIP_WITHOUT_MIC:\n\tcase HTT_RX_MPDU_ENCRYPT_TKIP_WPA:\n\t\treturn IEEE80211_TKIP_ICV_LEN;\n\tcase HTT_RX_MPDU_ENCRYPT_WEP128:\n\tcase HTT_RX_MPDU_ENCRYPT_WAPI:\n\t\tbreak;\n\t}\n\n\tath10k_warn(ar, \"unsupported encryption type %d\\n\", type);\n\treturn 0;\n}\n\nstruct amsdu_subframe_hdr {\n\tu8 dst[ETH_ALEN];\n\tu8 src[ETH_ALEN];\n\t__be16 len;\n} __packed;\n\n#define GROUP_ID_IS_SU_MIMO(x) ((x) == 0 || (x) == 63)\n\nstatic inline u8 ath10k_bw_to_mac80211_bw(u8 bw)\n{\n\tu8 ret = 0;\n\n\tswitch (bw) {\n\tcase 0:\n\t\tret = RATE_INFO_BW_20;\n\t\tbreak;\n\tcase 1:\n\t\tret = RATE_INFO_BW_40;\n\t\tbreak;\n\tcase 2:\n\t\tret = RATE_INFO_BW_80;\n\t\tbreak;\n\tcase 3:\n\t\tret = RATE_INFO_BW_160;\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\nstatic void ath10k_htt_rx_h_rates(struct ath10k *ar,\n\t\t\t\t  struct ieee80211_rx_status *status,\n\t\t\t\t  struct htt_rx_desc *rxd)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct rx_attention *rxd_attention;\n\tstruct rx_mpdu_start *rxd_mpdu_start;\n\tstruct rx_mpdu_end *rxd_mpdu_end;\n\tstruct rx_msdu_start_common *rxd_msdu_start_common;\n\tstruct rx_msdu_end_common *rxd_msdu_end_common;\n\tstruct rx_ppdu_start *rxd_ppdu_start;\n\tstruct ieee80211_supported_band *sband;\n\tu8 cck, rate, bw, sgi, mcs, nss;\n\tu8 *rxd_msdu_payload;\n\tu8 preamble = 0;\n\tu8 group_id;\n\tu32 info1, info2, info3;\n\tu32 stbc, nsts_su;\n\n\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\trxd_mpdu_start = ath10k_htt_rx_desc_get_mpdu_start(hw, rxd);\n\trxd_mpdu_end = ath10k_htt_rx_desc_get_mpdu_end(hw, rxd);\n\trxd_msdu_start_common = ath10k_htt_rx_desc_get_msdu_start(hw, rxd);\n\trxd_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rxd);\n\trxd_ppdu_start = ath10k_htt_rx_desc_get_ppdu_start(hw, rxd);\n\trxd_msdu_payload = ath10k_htt_rx_desc_get_msdu_payload(hw, rxd);\n\n\tinfo1 = __le32_to_cpu(rxd_ppdu_start->info1);\n\tinfo2 = __le32_to_cpu(rxd_ppdu_start->info2);\n\tinfo3 = __le32_to_cpu(rxd_ppdu_start->info3);\n\n\tpreamble = MS(info1, RX_PPDU_START_INFO1_PREAMBLE_TYPE);\n\n\tswitch (preamble) {\n\tcase HTT_RX_LEGACY:\n\t\t \n\t\tif (!status->freq)\n\t\t\treturn;\n\n\t\tcck = info1 & RX_PPDU_START_INFO1_L_SIG_RATE_SELECT;\n\t\trate = MS(info1, RX_PPDU_START_INFO1_L_SIG_RATE);\n\t\trate &= ~RX_PPDU_START_RATE_FLAG;\n\n\t\tsband = &ar->mac.sbands[status->band];\n\t\tstatus->rate_idx = ath10k_mac_hw_rate_to_idx(sband, rate, cck);\n\t\tbreak;\n\tcase HTT_RX_HT:\n\tcase HTT_RX_HT_WITH_TXBF:\n\t\t \n\t\tmcs = info2 & 0x1F;\n\t\tnss = mcs >> 3;\n\t\tbw = (info2 >> 7) & 1;\n\t\tsgi = (info3 >> 7) & 1;\n\n\t\tstatus->rate_idx = mcs;\n\t\tstatus->encoding = RX_ENC_HT;\n\t\tif (sgi)\n\t\t\tstatus->enc_flags |= RX_ENC_FLAG_SHORT_GI;\n\t\tif (bw)\n\t\t\tstatus->bw = RATE_INFO_BW_40;\n\t\tbreak;\n\tcase HTT_RX_VHT:\n\tcase HTT_RX_VHT_WITH_TXBF:\n\t\t \n\t\tbw = info2 & 3;\n\t\tsgi = info3 & 1;\n\t\tstbc = (info2 >> 3) & 1;\n\t\tgroup_id = (info2 >> 4) & 0x3F;\n\n\t\tif (GROUP_ID_IS_SU_MIMO(group_id)) {\n\t\t\tmcs = (info3 >> 4) & 0x0F;\n\t\t\tnsts_su = ((info2 >> 10) & 0x07);\n\t\t\tif (stbc)\n\t\t\t\tnss = (nsts_su >> 2) + 1;\n\t\t\telse\n\t\t\t\tnss = (nsts_su + 1);\n\t\t} else {\n\t\t\t \n\t\t\tmcs = 0;\n\t\t\tnss = 1;\n\t\t}\n\n\t\tif (mcs > 0x09) {\n\t\t\tath10k_warn(ar, \"invalid MCS received %u\\n\", mcs);\n\t\t\tath10k_warn(ar, \"rxd %08x mpdu start %08x %08x msdu start %08x %08x ppdu start %08x %08x %08x %08x %08x\\n\",\n\t\t\t\t    __le32_to_cpu(rxd_attention->flags),\n\t\t\t\t    __le32_to_cpu(rxd_mpdu_start->info0),\n\t\t\t\t    __le32_to_cpu(rxd_mpdu_start->info1),\n\t\t\t\t    __le32_to_cpu(rxd_msdu_start_common->info0),\n\t\t\t\t    __le32_to_cpu(rxd_msdu_start_common->info1),\n\t\t\t\t    rxd_ppdu_start->info0,\n\t\t\t\t    __le32_to_cpu(rxd_ppdu_start->info1),\n\t\t\t\t    __le32_to_cpu(rxd_ppdu_start->info2),\n\t\t\t\t    __le32_to_cpu(rxd_ppdu_start->info3),\n\t\t\t\t    __le32_to_cpu(rxd_ppdu_start->info4));\n\n\t\t\tath10k_warn(ar, \"msdu end %08x mpdu end %08x\\n\",\n\t\t\t\t    __le32_to_cpu(rxd_msdu_end_common->info0),\n\t\t\t\t    __le32_to_cpu(rxd_mpdu_end->info0));\n\n\t\t\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL,\n\t\t\t\t\t\"rx desc msdu payload: \",\n\t\t\t\t\trxd_msdu_payload, 50);\n\t\t}\n\n\t\tstatus->rate_idx = mcs;\n\t\tstatus->nss = nss;\n\n\t\tif (sgi)\n\t\t\tstatus->enc_flags |= RX_ENC_FLAG_SHORT_GI;\n\n\t\tstatus->bw = ath10k_bw_to_mac80211_bw(bw);\n\t\tstatus->encoding = RX_ENC_VHT;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic struct ieee80211_channel *\nath10k_htt_rx_h_peer_channel(struct ath10k *ar, struct htt_rx_desc *rxd)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct rx_attention *rxd_attention;\n\tstruct rx_msdu_end_common *rxd_msdu_end_common;\n\tstruct rx_mpdu_start *rxd_mpdu_start;\n\tstruct ath10k_peer *peer;\n\tstruct ath10k_vif *arvif;\n\tstruct cfg80211_chan_def def;\n\tu16 peer_id;\n\n\tlockdep_assert_held(&ar->data_lock);\n\n\tif (!rxd)\n\t\treturn NULL;\n\n\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\trxd_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rxd);\n\trxd_mpdu_start = ath10k_htt_rx_desc_get_mpdu_start(hw, rxd);\n\n\tif (rxd_attention->flags &\n\t    __cpu_to_le32(RX_ATTENTION_FLAGS_PEER_IDX_INVALID))\n\t\treturn NULL;\n\n\tif (!(rxd_msdu_end_common->info0 &\n\t      __cpu_to_le32(RX_MSDU_END_INFO0_FIRST_MSDU)))\n\t\treturn NULL;\n\n\tpeer_id = MS(__le32_to_cpu(rxd_mpdu_start->info0),\n\t\t     RX_MPDU_START_INFO0_PEER_IDX);\n\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tif (!peer)\n\t\treturn NULL;\n\n\tarvif = ath10k_get_arvif(ar, peer->vdev_id);\n\tif (WARN_ON_ONCE(!arvif))\n\t\treturn NULL;\n\n\tif (ath10k_mac_vif_chan(arvif->vif, &def))\n\t\treturn NULL;\n\n\treturn def.chan;\n}\n\nstatic struct ieee80211_channel *\nath10k_htt_rx_h_vdev_channel(struct ath10k *ar, u32 vdev_id)\n{\n\tstruct ath10k_vif *arvif;\n\tstruct cfg80211_chan_def def;\n\n\tlockdep_assert_held(&ar->data_lock);\n\n\tlist_for_each_entry(arvif, &ar->arvifs, list) {\n\t\tif (arvif->vdev_id == vdev_id &&\n\t\t    ath10k_mac_vif_chan(arvif->vif, &def) == 0)\n\t\t\treturn def.chan;\n\t}\n\n\treturn NULL;\n}\n\nstatic void\nath10k_htt_rx_h_any_chan_iter(struct ieee80211_hw *hw,\n\t\t\t      struct ieee80211_chanctx_conf *conf,\n\t\t\t      void *data)\n{\n\tstruct cfg80211_chan_def *def = data;\n\n\t*def = conf->def;\n}\n\nstatic struct ieee80211_channel *\nath10k_htt_rx_h_any_channel(struct ath10k *ar)\n{\n\tstruct cfg80211_chan_def def = {};\n\n\tieee80211_iter_chan_contexts_atomic(ar->hw,\n\t\t\t\t\t    ath10k_htt_rx_h_any_chan_iter,\n\t\t\t\t\t    &def);\n\n\treturn def.chan;\n}\n\nstatic bool ath10k_htt_rx_h_channel(struct ath10k *ar,\n\t\t\t\t    struct ieee80211_rx_status *status,\n\t\t\t\t    struct htt_rx_desc *rxd,\n\t\t\t\t    u32 vdev_id)\n{\n\tstruct ieee80211_channel *ch;\n\n\tspin_lock_bh(&ar->data_lock);\n\tch = ar->scan_channel;\n\tif (!ch)\n\t\tch = ar->rx_channel;\n\tif (!ch)\n\t\tch = ath10k_htt_rx_h_peer_channel(ar, rxd);\n\tif (!ch)\n\t\tch = ath10k_htt_rx_h_vdev_channel(ar, vdev_id);\n\tif (!ch)\n\t\tch = ath10k_htt_rx_h_any_channel(ar);\n\tif (!ch)\n\t\tch = ar->tgt_oper_chan;\n\tspin_unlock_bh(&ar->data_lock);\n\n\tif (!ch)\n\t\treturn false;\n\n\tstatus->band = ch->band;\n\tstatus->freq = ch->center_freq;\n\n\treturn true;\n}\n\nstatic void ath10k_htt_rx_h_signal(struct ath10k *ar,\n\t\t\t\t   struct ieee80211_rx_status *status,\n\t\t\t\t   struct htt_rx_desc *rxd)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct rx_ppdu_start *rxd_ppdu_start = ath10k_htt_rx_desc_get_ppdu_start(hw, rxd);\n\tint i;\n\n\tfor (i = 0; i < IEEE80211_MAX_CHAINS ; i++) {\n\t\tstatus->chains &= ~BIT(i);\n\n\t\tif (rxd_ppdu_start->rssi_chains[i].pri20_mhz != 0x80) {\n\t\t\tstatus->chain_signal[i] = ATH10K_DEFAULT_NOISE_FLOOR +\n\t\t\t\trxd_ppdu_start->rssi_chains[i].pri20_mhz;\n\n\t\t\tstatus->chains |= BIT(i);\n\t\t}\n\t}\n\n\t \n\tstatus->signal = ATH10K_DEFAULT_NOISE_FLOOR +\n\t\t\t rxd_ppdu_start->rssi_comb;\n\tstatus->flag &= ~RX_FLAG_NO_SIGNAL_VAL;\n}\n\nstatic void ath10k_htt_rx_h_mactime(struct ath10k *ar,\n\t\t\t\t    struct ieee80211_rx_status *status,\n\t\t\t\t    struct htt_rx_desc *rxd)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct rx_ppdu_end_common *rxd_ppdu_end_common;\n\n\trxd_ppdu_end_common = ath10k_htt_rx_desc_get_ppdu_end(hw, rxd);\n\n\t \n\tstatus->mactime = __le32_to_cpu(rxd_ppdu_end_common->tsf_timestamp);\n\tstatus->flag |= RX_FLAG_MACTIME_END;\n}\n\nstatic void ath10k_htt_rx_h_ppdu(struct ath10k *ar,\n\t\t\t\t struct sk_buff_head *amsdu,\n\t\t\t\t struct ieee80211_rx_status *status,\n\t\t\t\t u32 vdev_id)\n{\n\tstruct sk_buff *first;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_attention *rxd_attention;\n\tbool is_first_ppdu;\n\tbool is_last_ppdu;\n\n\tif (skb_queue_empty(amsdu))\n\t\treturn;\n\n\tfirst = skb_peek(amsdu);\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)first->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\n\tis_first_ppdu = !!(rxd_attention->flags &\n\t\t\t   __cpu_to_le32(RX_ATTENTION_FLAGS_FIRST_MPDU));\n\tis_last_ppdu = !!(rxd_attention->flags &\n\t\t\t  __cpu_to_le32(RX_ATTENTION_FLAGS_LAST_MPDU));\n\n\tif (is_first_ppdu) {\n\t\t \n\t\tstatus->freq = 0;\n\t\tstatus->rate_idx = 0;\n\t\tstatus->nss = 0;\n\t\tstatus->encoding = RX_ENC_LEGACY;\n\t\tstatus->bw = RATE_INFO_BW_20;\n\n\t\tstatus->flag &= ~RX_FLAG_MACTIME_END;\n\t\tstatus->flag |= RX_FLAG_NO_SIGNAL_VAL;\n\n\t\tstatus->flag &= ~(RX_FLAG_AMPDU_IS_LAST);\n\t\tstatus->flag |= RX_FLAG_AMPDU_DETAILS | RX_FLAG_AMPDU_LAST_KNOWN;\n\t\tstatus->ampdu_reference = ar->ampdu_reference;\n\n\t\tath10k_htt_rx_h_signal(ar, status, rxd);\n\t\tath10k_htt_rx_h_channel(ar, status, rxd, vdev_id);\n\t\tath10k_htt_rx_h_rates(ar, status, rxd);\n\t}\n\n\tif (is_last_ppdu) {\n\t\tath10k_htt_rx_h_mactime(ar, status, rxd);\n\n\t\t \n\t\tstatus->flag |= RX_FLAG_AMPDU_IS_LAST;\n\t\tar->ampdu_reference++;\n\t}\n}\n\nstatic const char * const tid_to_ac[] = {\n\t\"BE\",\n\t\"BK\",\n\t\"BK\",\n\t\"BE\",\n\t\"VI\",\n\t\"VI\",\n\t\"VO\",\n\t\"VO\",\n};\n\nstatic char *ath10k_get_tid(struct ieee80211_hdr *hdr, char *out, size_t size)\n{\n\tu8 *qc;\n\tint tid;\n\n\tif (!ieee80211_is_data_qos(hdr->frame_control))\n\t\treturn \"\";\n\n\tqc = ieee80211_get_qos_ctl(hdr);\n\ttid = *qc & IEEE80211_QOS_CTL_TID_MASK;\n\tif (tid < 8)\n\t\tsnprintf(out, size, \"tid %d (%s)\", tid, tid_to_ac[tid]);\n\telse\n\t\tsnprintf(out, size, \"tid %d\", tid);\n\n\treturn out;\n}\n\nstatic void ath10k_htt_rx_h_queue_msdu(struct ath10k *ar,\n\t\t\t\t       struct ieee80211_rx_status *rx_status,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct ieee80211_rx_status *status;\n\n\tstatus = IEEE80211_SKB_RXCB(skb);\n\t*status = *rx_status;\n\n\tskb_queue_tail(&ar->htt.rx_msdus_q, skb);\n}\n\nstatic void ath10k_process_rx(struct ath10k *ar, struct sk_buff *skb)\n{\n\tstruct ieee80211_rx_status *status;\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\tchar tid[32];\n\n\tstatus = IEEE80211_SKB_RXCB(skb);\n\n\tif (!(ar->filter_flags & FIF_FCSFAIL) &&\n\t    status->flag & RX_FLAG_FAILED_FCS_CRC) {\n\t\tar->stats.rx_crc_err_drop++;\n\t\tdev_kfree_skb_any(skb);\n\t\treturn;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_DATA,\n\t\t   \"rx skb %pK len %u peer %pM %s %s sn %u %s%s%s%s%s%s %srate_idx %u vht_nss %u freq %u band %u flag 0x%x fcs-err %i mic-err %i amsdu-more %i\\n\",\n\t\t   skb,\n\t\t   skb->len,\n\t\t   ieee80211_get_SA(hdr),\n\t\t   ath10k_get_tid(hdr, tid, sizeof(tid)),\n\t\t   is_multicast_ether_addr(ieee80211_get_DA(hdr)) ?\n\t\t\t\t\t\t\t\"mcast\" : \"ucast\",\n\t\t   IEEE80211_SEQ_TO_SN(__le16_to_cpu(hdr->seq_ctrl)),\n\t\t   (status->encoding == RX_ENC_LEGACY) ? \"legacy\" : \"\",\n\t\t   (status->encoding == RX_ENC_HT) ? \"ht\" : \"\",\n\t\t   (status->encoding == RX_ENC_VHT) ? \"vht\" : \"\",\n\t\t   (status->bw == RATE_INFO_BW_40) ? \"40\" : \"\",\n\t\t   (status->bw == RATE_INFO_BW_80) ? \"80\" : \"\",\n\t\t   (status->bw == RATE_INFO_BW_160) ? \"160\" : \"\",\n\t\t   status->enc_flags & RX_ENC_FLAG_SHORT_GI ? \"sgi \" : \"\",\n\t\t   status->rate_idx,\n\t\t   status->nss,\n\t\t   status->freq,\n\t\t   status->band, status->flag,\n\t\t   !!(status->flag & RX_FLAG_FAILED_FCS_CRC),\n\t\t   !!(status->flag & RX_FLAG_MMIC_ERROR),\n\t\t   !!(status->flag & RX_FLAG_AMSDU_MORE));\n\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"rx skb: \",\n\t\t\tskb->data, skb->len);\n\ttrace_ath10k_rx_hdr(ar, skb->data, skb->len);\n\ttrace_ath10k_rx_payload(ar, skb->data, skb->len);\n\n\tieee80211_rx_napi(ar->hw, NULL, skb, &ar->napi);\n}\n\nstatic int ath10k_htt_rx_nwifi_hdrlen(struct ath10k *ar,\n\t\t\t\t      struct ieee80211_hdr *hdr)\n{\n\tint len = ieee80211_hdrlen(hdr->frame_control);\n\n\tif (!test_bit(ATH10K_FW_FEATURE_NO_NWIFI_DECAP_4ADDR_PADDING,\n\t\t      ar->running_fw->fw_file.fw_features))\n\t\tlen = round_up(len, 4);\n\n\treturn len;\n}\n\nstatic void ath10k_htt_rx_h_undecap_raw(struct ath10k *ar,\n\t\t\t\t\tstruct sk_buff *msdu,\n\t\t\t\t\tstruct ieee80211_rx_status *status,\n\t\t\t\t\tenum htt_rx_mpdu_encrypt_type enctype,\n\t\t\t\t\tbool is_decrypted,\n\t\t\t\t\tconst u8 first_hdr[64])\n{\n\tstruct ieee80211_hdr *hdr;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_msdu_end_common *rxd_msdu_end_common;\n\tsize_t hdr_len;\n\tsize_t crypto_len;\n\tbool is_first;\n\tbool is_last;\n\tbool msdu_limit_err;\n\tint bytes_aligned = ar->hw_params.decap_align_bytes;\n\tu8 *qos;\n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)msdu->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rxd);\n\tis_first = !!(rxd_msdu_end_common->info0 &\n\t\t      __cpu_to_le32(RX_MSDU_END_INFO0_FIRST_MSDU));\n\tis_last = !!(rxd_msdu_end_common->info0 &\n\t\t     __cpu_to_le32(RX_MSDU_END_INFO0_LAST_MSDU));\n\n\t \n\n\t \n\tmsdu_limit_err = ath10k_htt_rx_desc_msdu_limit_error(hw, rxd);\n\n\t \n\t \n\tif (WARN_ON_ONCE(!is_first && !msdu_limit_err))\n\t\treturn;\n\n\t \n\tif (WARN_ON_ONCE(!(is_first && is_last) && !msdu_limit_err))\n\t\treturn;\n\n\tskb_trim(msdu, msdu->len - FCS_LEN);\n\n\t \n\tif (unlikely(msdu_limit_err)) {\n\t\thdr = (struct ieee80211_hdr *)first_hdr;\n\t\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\t\tcrypto_len = ath10k_htt_rx_crypto_param_len(ar, enctype);\n\n\t\tif (ieee80211_is_data_qos(hdr->frame_control)) {\n\t\t\tqos = ieee80211_get_qos_ctl(hdr);\n\t\t\tqos[0] |= IEEE80211_QOS_CTL_A_MSDU_PRESENT;\n\t\t}\n\n\t\tif (crypto_len)\n\t\t\tmemcpy(skb_push(msdu, crypto_len),\n\t\t\t       (void *)hdr + round_up(hdr_len, bytes_aligned),\n\t\t\t       crypto_len);\n\n\t\tmemcpy(skb_push(msdu, hdr_len), hdr, hdr_len);\n\t}\n\n\t \n\tif (!is_decrypted)\n\t\treturn;\n\n\t \n\n\thdr = (void *)msdu->data;\n\n\t \n\tif (status->flag & RX_FLAG_IV_STRIPPED) {\n\t\tskb_trim(msdu, msdu->len -\n\t\t\t ath10k_htt_rx_crypto_mic_len(ar, enctype));\n\n\t\tskb_trim(msdu, msdu->len -\n\t\t\t ath10k_htt_rx_crypto_icv_len(ar, enctype));\n\t} else {\n\t\t \n\t\tif (status->flag & RX_FLAG_MIC_STRIPPED)\n\t\t\tskb_trim(msdu, msdu->len -\n\t\t\t\t ath10k_htt_rx_crypto_mic_len(ar, enctype));\n\n\t\t \n\t\tif (status->flag & RX_FLAG_ICV_STRIPPED)\n\t\t\tskb_trim(msdu, msdu->len -\n\t\t\t\t ath10k_htt_rx_crypto_icv_len(ar, enctype));\n\t}\n\n\t \n\tif ((status->flag & RX_FLAG_MMIC_STRIPPED) &&\n\t    !ieee80211_has_morefrags(hdr->frame_control) &&\n\t    enctype == HTT_RX_MPDU_ENCRYPT_TKIP_WPA)\n\t\tskb_trim(msdu, msdu->len - MICHAEL_MIC_LEN);\n\n\t \n\tif (status->flag & RX_FLAG_IV_STRIPPED) {\n\t\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\t\tcrypto_len = ath10k_htt_rx_crypto_param_len(ar, enctype);\n\n\t\tmemmove((void *)msdu->data + crypto_len,\n\t\t\t(void *)msdu->data, hdr_len);\n\t\tskb_pull(msdu, crypto_len);\n\t}\n}\n\nstatic void ath10k_htt_rx_h_undecap_nwifi(struct ath10k *ar,\n\t\t\t\t\t  struct sk_buff *msdu,\n\t\t\t\t\t  struct ieee80211_rx_status *status,\n\t\t\t\t\t  const u8 first_hdr[64],\n\t\t\t\t\t  enum htt_rx_mpdu_encrypt_type enctype)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct ieee80211_hdr *hdr;\n\tstruct htt_rx_desc *rxd;\n\tsize_t hdr_len;\n\tu8 da[ETH_ALEN];\n\tu8 sa[ETH_ALEN];\n\tint l3_pad_bytes;\n\tint bytes_aligned = ar->hw_params.decap_align_bytes;\n\n\t \n\n\t \n\trxd = HTT_RX_BUF_TO_RX_DESC(hw, (void *)msdu->data -\n\t\t\t\t    hw->rx_desc_ops->rx_desc_size);\n\n\tl3_pad_bytes = ath10k_htt_rx_desc_get_l3_pad_bytes(&ar->hw_params, rxd);\n\tskb_put(msdu, l3_pad_bytes);\n\n\thdr = (struct ieee80211_hdr *)(msdu->data + l3_pad_bytes);\n\n\thdr_len = ath10k_htt_rx_nwifi_hdrlen(ar, hdr);\n\tether_addr_copy(da, ieee80211_get_DA(hdr));\n\tether_addr_copy(sa, ieee80211_get_SA(hdr));\n\tskb_pull(msdu, hdr_len);\n\n\t \n\thdr = (struct ieee80211_hdr *)first_hdr;\n\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\n\tif (!(status->flag & RX_FLAG_IV_STRIPPED)) {\n\t\tmemcpy(skb_push(msdu,\n\t\t\t\tath10k_htt_rx_crypto_param_len(ar, enctype)),\n\t\t       (void *)hdr + round_up(hdr_len, bytes_aligned),\n\t\t\tath10k_htt_rx_crypto_param_len(ar, enctype));\n\t}\n\n\tmemcpy(skb_push(msdu, hdr_len), hdr, hdr_len);\n\n\t \n\thdr = (struct ieee80211_hdr *)msdu->data;\n\tether_addr_copy(ieee80211_get_DA(hdr), da);\n\tether_addr_copy(ieee80211_get_SA(hdr), sa);\n}\n\nstatic void *ath10k_htt_rx_h_find_rfc1042(struct ath10k *ar,\n\t\t\t\t\t  struct sk_buff *msdu,\n\t\t\t\t\t  enum htt_rx_mpdu_encrypt_type enctype)\n{\n\tstruct ieee80211_hdr *hdr;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_msdu_end_common *rxd_msdu_end_common;\n\tu8 *rxd_rx_hdr_status;\n\tsize_t hdr_len, crypto_len;\n\tvoid *rfc1042;\n\tbool is_first, is_last, is_amsdu;\n\tint bytes_aligned = ar->hw_params.decap_align_bytes;\n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)msdu->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rxd);\n\trxd_rx_hdr_status = ath10k_htt_rx_desc_get_rx_hdr_status(hw, rxd);\n\thdr = (void *)rxd_rx_hdr_status;\n\n\tis_first = !!(rxd_msdu_end_common->info0 &\n\t\t      __cpu_to_le32(RX_MSDU_END_INFO0_FIRST_MSDU));\n\tis_last = !!(rxd_msdu_end_common->info0 &\n\t\t     __cpu_to_le32(RX_MSDU_END_INFO0_LAST_MSDU));\n\tis_amsdu = !(is_first && is_last);\n\n\trfc1042 = hdr;\n\n\tif (is_first) {\n\t\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\t\tcrypto_len = ath10k_htt_rx_crypto_param_len(ar, enctype);\n\n\t\trfc1042 += round_up(hdr_len, bytes_aligned) +\n\t\t\t   round_up(crypto_len, bytes_aligned);\n\t}\n\n\tif (is_amsdu)\n\t\trfc1042 += sizeof(struct amsdu_subframe_hdr);\n\n\treturn rfc1042;\n}\n\nstatic void ath10k_htt_rx_h_undecap_eth(struct ath10k *ar,\n\t\t\t\t\tstruct sk_buff *msdu,\n\t\t\t\t\tstruct ieee80211_rx_status *status,\n\t\t\t\t\tconst u8 first_hdr[64],\n\t\t\t\t\tenum htt_rx_mpdu_encrypt_type enctype)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct ieee80211_hdr *hdr;\n\tstruct ethhdr *eth;\n\tsize_t hdr_len;\n\tvoid *rfc1042;\n\tu8 da[ETH_ALEN];\n\tu8 sa[ETH_ALEN];\n\tint l3_pad_bytes;\n\tstruct htt_rx_desc *rxd;\n\tint bytes_aligned = ar->hw_params.decap_align_bytes;\n\n\t \n\n\trfc1042 = ath10k_htt_rx_h_find_rfc1042(ar, msdu, enctype);\n\tif (WARN_ON_ONCE(!rfc1042))\n\t\treturn;\n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)msdu->data - hw->rx_desc_ops->rx_desc_size);\n\n\tl3_pad_bytes = ath10k_htt_rx_desc_get_l3_pad_bytes(&ar->hw_params, rxd);\n\tskb_put(msdu, l3_pad_bytes);\n\tskb_pull(msdu, l3_pad_bytes);\n\n\t \n\teth = (struct ethhdr *)msdu->data;\n\tether_addr_copy(da, eth->h_dest);\n\tether_addr_copy(sa, eth->h_source);\n\tskb_pull(msdu, sizeof(struct ethhdr));\n\n\t \n\tmemcpy(skb_push(msdu, sizeof(struct rfc1042_hdr)), rfc1042,\n\t       sizeof(struct rfc1042_hdr));\n\n\t \n\thdr = (struct ieee80211_hdr *)first_hdr;\n\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\n\tif (!(status->flag & RX_FLAG_IV_STRIPPED)) {\n\t\tmemcpy(skb_push(msdu,\n\t\t\t\tath10k_htt_rx_crypto_param_len(ar, enctype)),\n\t\t       (void *)hdr + round_up(hdr_len, bytes_aligned),\n\t\t\tath10k_htt_rx_crypto_param_len(ar, enctype));\n\t}\n\n\tmemcpy(skb_push(msdu, hdr_len), hdr, hdr_len);\n\n\t \n\thdr = (struct ieee80211_hdr *)msdu->data;\n\tether_addr_copy(ieee80211_get_DA(hdr), da);\n\tether_addr_copy(ieee80211_get_SA(hdr), sa);\n}\n\nstatic void ath10k_htt_rx_h_undecap_snap(struct ath10k *ar,\n\t\t\t\t\t struct sk_buff *msdu,\n\t\t\t\t\t struct ieee80211_rx_status *status,\n\t\t\t\t\t const u8 first_hdr[64],\n\t\t\t\t\t enum htt_rx_mpdu_encrypt_type enctype)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct ieee80211_hdr *hdr;\n\tsize_t hdr_len;\n\tint l3_pad_bytes;\n\tstruct htt_rx_desc *rxd;\n\tint bytes_aligned = ar->hw_params.decap_align_bytes;\n\n\t \n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)msdu->data - hw->rx_desc_ops->rx_desc_size);\n\n\tl3_pad_bytes = ath10k_htt_rx_desc_get_l3_pad_bytes(&ar->hw_params, rxd);\n\n\tskb_put(msdu, l3_pad_bytes);\n\tskb_pull(msdu, sizeof(struct amsdu_subframe_hdr) + l3_pad_bytes);\n\n\thdr = (struct ieee80211_hdr *)first_hdr;\n\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\n\tif (!(status->flag & RX_FLAG_IV_STRIPPED)) {\n\t\tmemcpy(skb_push(msdu,\n\t\t\t\tath10k_htt_rx_crypto_param_len(ar, enctype)),\n\t\t       (void *)hdr + round_up(hdr_len, bytes_aligned),\n\t\t\tath10k_htt_rx_crypto_param_len(ar, enctype));\n\t}\n\n\tmemcpy(skb_push(msdu, hdr_len), hdr, hdr_len);\n}\n\nstatic void ath10k_htt_rx_h_undecap(struct ath10k *ar,\n\t\t\t\t    struct sk_buff *msdu,\n\t\t\t\t    struct ieee80211_rx_status *status,\n\t\t\t\t    u8 first_hdr[64],\n\t\t\t\t    enum htt_rx_mpdu_encrypt_type enctype,\n\t\t\t\t    bool is_decrypted)\n{\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_msdu_start_common *rxd_msdu_start_common;\n\tenum rx_msdu_decap_format decap;\n\n\t \n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)msdu->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_msdu_start_common = ath10k_htt_rx_desc_get_msdu_start(hw, rxd);\n\tdecap = MS(__le32_to_cpu(rxd_msdu_start_common->info1),\n\t\t   RX_MSDU_START_INFO1_DECAP_FORMAT);\n\n\tswitch (decap) {\n\tcase RX_MSDU_DECAP_RAW:\n\t\tath10k_htt_rx_h_undecap_raw(ar, msdu, status, enctype,\n\t\t\t\t\t    is_decrypted, first_hdr);\n\t\tbreak;\n\tcase RX_MSDU_DECAP_NATIVE_WIFI:\n\t\tath10k_htt_rx_h_undecap_nwifi(ar, msdu, status, first_hdr,\n\t\t\t\t\t      enctype);\n\t\tbreak;\n\tcase RX_MSDU_DECAP_ETHERNET2_DIX:\n\t\tath10k_htt_rx_h_undecap_eth(ar, msdu, status, first_hdr, enctype);\n\t\tbreak;\n\tcase RX_MSDU_DECAP_8023_SNAP_LLC:\n\t\tath10k_htt_rx_h_undecap_snap(ar, msdu, status, first_hdr,\n\t\t\t\t\t     enctype);\n\t\tbreak;\n\t}\n}\n\nstatic int ath10k_htt_rx_get_csum_state(struct ath10k_hw_params *hw, struct sk_buff *skb)\n{\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_attention *rxd_attention;\n\tstruct rx_msdu_start_common *rxd_msdu_start_common;\n\tu32 flags, info;\n\tbool is_ip4, is_ip6;\n\tbool is_tcp, is_udp;\n\tbool ip_csum_ok, tcpudp_csum_ok;\n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)skb->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\trxd_msdu_start_common = ath10k_htt_rx_desc_get_msdu_start(hw, rxd);\n\tflags = __le32_to_cpu(rxd_attention->flags);\n\tinfo = __le32_to_cpu(rxd_msdu_start_common->info1);\n\n\tis_ip4 = !!(info & RX_MSDU_START_INFO1_IPV4_PROTO);\n\tis_ip6 = !!(info & RX_MSDU_START_INFO1_IPV6_PROTO);\n\tis_tcp = !!(info & RX_MSDU_START_INFO1_TCP_PROTO);\n\tis_udp = !!(info & RX_MSDU_START_INFO1_UDP_PROTO);\n\tip_csum_ok = !(flags & RX_ATTENTION_FLAGS_IP_CHKSUM_FAIL);\n\ttcpudp_csum_ok = !(flags & RX_ATTENTION_FLAGS_TCP_UDP_CHKSUM_FAIL);\n\n\tif (!is_ip4 && !is_ip6)\n\t\treturn CHECKSUM_NONE;\n\tif (!is_tcp && !is_udp)\n\t\treturn CHECKSUM_NONE;\n\tif (!ip_csum_ok)\n\t\treturn CHECKSUM_NONE;\n\tif (!tcpudp_csum_ok)\n\t\treturn CHECKSUM_NONE;\n\n\treturn CHECKSUM_UNNECESSARY;\n}\n\nstatic void ath10k_htt_rx_h_csum_offload(struct ath10k_hw_params *hw,\n\t\t\t\t\t struct sk_buff *msdu)\n{\n\tmsdu->ip_summed = ath10k_htt_rx_get_csum_state(hw, msdu);\n}\n\nstatic u64 ath10k_htt_rx_h_get_pn(struct ath10k *ar, struct sk_buff *skb,\n\t\t\t\t  enum htt_rx_mpdu_encrypt_type enctype)\n{\n\tstruct ieee80211_hdr *hdr;\n\tu64 pn = 0;\n\tu8 *ehdr;\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\tehdr = skb->data + ieee80211_hdrlen(hdr->frame_control);\n\n\tif (enctype == HTT_RX_MPDU_ENCRYPT_AES_CCM_WPA2) {\n\t\tpn = ehdr[0];\n\t\tpn |= (u64)ehdr[1] << 8;\n\t\tpn |= (u64)ehdr[4] << 16;\n\t\tpn |= (u64)ehdr[5] << 24;\n\t\tpn |= (u64)ehdr[6] << 32;\n\t\tpn |= (u64)ehdr[7] << 40;\n\t}\n\treturn pn;\n}\n\nstatic bool ath10k_htt_rx_h_frag_multicast_check(struct ath10k *ar,\n\t\t\t\t\t\t struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr;\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\treturn !is_multicast_ether_addr(hdr->addr1);\n}\n\nstatic bool ath10k_htt_rx_h_frag_pn_check(struct ath10k *ar,\n\t\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t\t  u16 peer_id,\n\t\t\t\t\t  enum htt_rx_mpdu_encrypt_type enctype)\n{\n\tstruct ath10k_peer *peer;\n\tunion htt_rx_pn_t *last_pn, new_pn = {0};\n\tstruct ieee80211_hdr *hdr;\n\tu8 tid, frag_number;\n\tu32 seq;\n\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tif (!peer) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"invalid peer for frag pn check\\n\");\n\t\treturn false;\n\t}\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\tif (ieee80211_is_data_qos(hdr->frame_control))\n\t\ttid = ieee80211_get_tid(hdr);\n\telse\n\t\ttid = ATH10K_TXRX_NON_QOS_TID;\n\n\tlast_pn = &peer->frag_tids_last_pn[tid];\n\tnew_pn.pn48 = ath10k_htt_rx_h_get_pn(ar, skb, enctype);\n\tfrag_number = le16_to_cpu(hdr->seq_ctrl) & IEEE80211_SCTL_FRAG;\n\tseq = IEEE80211_SEQ_TO_SN(__le16_to_cpu(hdr->seq_ctrl));\n\n\tif (frag_number == 0) {\n\t\tlast_pn->pn48 = new_pn.pn48;\n\t\tpeer->frag_tids_seq[tid] = seq;\n\t} else {\n\t\tif (seq != peer->frag_tids_seq[tid])\n\t\t\treturn false;\n\n\t\tif (new_pn.pn48 != last_pn->pn48 + 1)\n\t\t\treturn false;\n\n\t\tlast_pn->pn48 = new_pn.pn48;\n\t}\n\n\treturn true;\n}\n\nstatic void ath10k_htt_rx_h_mpdu(struct ath10k *ar,\n\t\t\t\t struct sk_buff_head *amsdu,\n\t\t\t\t struct ieee80211_rx_status *status,\n\t\t\t\t bool fill_crypt_header,\n\t\t\t\t u8 *rx_hdr,\n\t\t\t\t enum ath10k_pkt_rx_err *err,\n\t\t\t\t u16 peer_id,\n\t\t\t\t bool frag)\n{\n\tstruct sk_buff *first;\n\tstruct sk_buff *last;\n\tstruct sk_buff *msdu, *temp;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_attention *rxd_attention;\n\tstruct rx_mpdu_start *rxd_mpdu_start;\n\n\tstruct ieee80211_hdr *hdr;\n\tenum htt_rx_mpdu_encrypt_type enctype;\n\tu8 first_hdr[64];\n\tu8 *qos;\n\tbool has_fcs_err;\n\tbool has_crypto_err;\n\tbool has_tkip_err;\n\tbool has_peer_idx_invalid;\n\tbool is_decrypted;\n\tbool is_mgmt;\n\tu32 attention;\n\tbool frag_pn_check = true, multicast_check = true;\n\n\tif (skb_queue_empty(amsdu))\n\t\treturn;\n\n\tfirst = skb_peek(amsdu);\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)first->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\trxd_mpdu_start = ath10k_htt_rx_desc_get_mpdu_start(hw, rxd);\n\n\tis_mgmt = !!(rxd_attention->flags &\n\t\t     __cpu_to_le32(RX_ATTENTION_FLAGS_MGMT_TYPE));\n\n\tenctype = MS(__le32_to_cpu(rxd_mpdu_start->info0),\n\t\t     RX_MPDU_START_INFO0_ENCRYPT_TYPE);\n\n\t \n\thdr = (void *)ath10k_htt_rx_desc_get_rx_hdr_status(hw, rxd);\n\tmemcpy(first_hdr, hdr, RX_HTT_HDR_STATUS_LEN);\n\n\tif (rx_hdr)\n\t\tmemcpy(rx_hdr, hdr, RX_HTT_HDR_STATUS_LEN);\n\n\t \n\thdr = (void *)first_hdr;\n\n\tif (ieee80211_is_data_qos(hdr->frame_control)) {\n\t\tqos = ieee80211_get_qos_ctl(hdr);\n\t\tqos[0] &= ~IEEE80211_QOS_CTL_A_MSDU_PRESENT;\n\t}\n\n\t \n\tlast = skb_peek_tail(amsdu);\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)last->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_attention = ath10k_htt_rx_desc_get_attention(hw, rxd);\n\tattention = __le32_to_cpu(rxd_attention->flags);\n\n\thas_fcs_err = !!(attention & RX_ATTENTION_FLAGS_FCS_ERR);\n\thas_crypto_err = !!(attention & RX_ATTENTION_FLAGS_DECRYPT_ERR);\n\thas_tkip_err = !!(attention & RX_ATTENTION_FLAGS_TKIP_MIC_ERR);\n\thas_peer_idx_invalid = !!(attention & RX_ATTENTION_FLAGS_PEER_IDX_INVALID);\n\n\t \n\tis_decrypted = (enctype != HTT_RX_MPDU_ENCRYPT_NONE &&\n\t\t\t!has_fcs_err &&\n\t\t\t!has_crypto_err &&\n\t\t\t!has_peer_idx_invalid);\n\n\t \n\tstatus->flag &= ~(RX_FLAG_FAILED_FCS_CRC |\n\t\t\t  RX_FLAG_MMIC_ERROR |\n\t\t\t  RX_FLAG_DECRYPTED |\n\t\t\t  RX_FLAG_IV_STRIPPED |\n\t\t\t  RX_FLAG_ONLY_MONITOR |\n\t\t\t  RX_FLAG_MMIC_STRIPPED);\n\n\tif (has_fcs_err)\n\t\tstatus->flag |= RX_FLAG_FAILED_FCS_CRC;\n\n\tif (has_tkip_err)\n\t\tstatus->flag |= RX_FLAG_MMIC_ERROR;\n\n\tif (err) {\n\t\tif (has_fcs_err)\n\t\t\t*err = ATH10K_PKT_RX_ERR_FCS;\n\t\telse if (has_tkip_err)\n\t\t\t*err = ATH10K_PKT_RX_ERR_TKIP;\n\t\telse if (has_crypto_err)\n\t\t\t*err = ATH10K_PKT_RX_ERR_CRYPT;\n\t\telse if (has_peer_idx_invalid)\n\t\t\t*err = ATH10K_PKT_RX_ERR_PEER_IDX_INVAL;\n\t}\n\n\t \n\tif (is_mgmt)\n\t\tstatus->flag |= RX_FLAG_ONLY_MONITOR;\n\n\tif (is_decrypted) {\n\t\tstatus->flag |= RX_FLAG_DECRYPTED;\n\n\t\tif (likely(!is_mgmt))\n\t\t\tstatus->flag |= RX_FLAG_MMIC_STRIPPED;\n\n\t\tif (fill_crypt_header)\n\t\t\tstatus->flag |= RX_FLAG_MIC_STRIPPED |\n\t\t\t\t\tRX_FLAG_ICV_STRIPPED;\n\t\telse\n\t\t\tstatus->flag |= RX_FLAG_IV_STRIPPED;\n\t}\n\n\tskb_queue_walk(amsdu, msdu) {\n\t\tif (frag && !fill_crypt_header && is_decrypted &&\n\t\t    enctype == HTT_RX_MPDU_ENCRYPT_AES_CCM_WPA2)\n\t\t\tfrag_pn_check = ath10k_htt_rx_h_frag_pn_check(ar,\n\t\t\t\t\t\t\t\t      msdu,\n\t\t\t\t\t\t\t\t      peer_id,\n\t\t\t\t\t\t\t\t      enctype);\n\n\t\tif (frag)\n\t\t\tmulticast_check = ath10k_htt_rx_h_frag_multicast_check(ar,\n\t\t\t\t\t\t\t\t\t       msdu);\n\n\t\tif (!frag_pn_check || !multicast_check) {\n\t\t\t \n\t\t\ttemp = msdu->prev;\n\t\t\t__skb_unlink(msdu, amsdu);\n\t\t\tdev_kfree_skb_any(msdu);\n\t\t\tmsdu = temp;\n\t\t\tfrag_pn_check = true;\n\t\t\tmulticast_check = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tath10k_htt_rx_h_csum_offload(&ar->hw_params, msdu);\n\n\t\tif (frag && !fill_crypt_header &&\n\t\t    enctype == HTT_RX_MPDU_ENCRYPT_TKIP_WPA)\n\t\t\tstatus->flag &= ~RX_FLAG_MMIC_STRIPPED;\n\n\t\tath10k_htt_rx_h_undecap(ar, msdu, status, first_hdr, enctype,\n\t\t\t\t\tis_decrypted);\n\n\t\t \n\t\tif (!is_decrypted)\n\t\t\tcontinue;\n\t\tif (is_mgmt)\n\t\t\tcontinue;\n\n\t\tif (fill_crypt_header)\n\t\t\tcontinue;\n\n\t\thdr = (void *)msdu->data;\n\t\thdr->frame_control &= ~__cpu_to_le16(IEEE80211_FCTL_PROTECTED);\n\n\t\tif (frag && !fill_crypt_header &&\n\t\t    enctype == HTT_RX_MPDU_ENCRYPT_TKIP_WPA)\n\t\t\tstatus->flag &= ~RX_FLAG_IV_STRIPPED &\n\t\t\t\t\t~RX_FLAG_MMIC_STRIPPED;\n\t}\n}\n\nstatic void ath10k_htt_rx_h_enqueue(struct ath10k *ar,\n\t\t\t\t    struct sk_buff_head *amsdu,\n\t\t\t\t    struct ieee80211_rx_status *status)\n{\n\tstruct sk_buff *msdu;\n\tstruct sk_buff *first_subframe;\n\n\tfirst_subframe = skb_peek(amsdu);\n\n\twhile ((msdu = __skb_dequeue(amsdu))) {\n\t\t \n\t\tif (skb_queue_empty(amsdu))\n\t\t\tstatus->flag &= ~RX_FLAG_AMSDU_MORE;\n\t\telse\n\t\t\tstatus->flag |= RX_FLAG_AMSDU_MORE;\n\n\t\tif (msdu == first_subframe) {\n\t\t\tfirst_subframe = NULL;\n\t\t\tstatus->flag &= ~RX_FLAG_ALLOW_SAME_PN;\n\t\t} else {\n\t\t\tstatus->flag |= RX_FLAG_ALLOW_SAME_PN;\n\t\t}\n\n\t\tath10k_htt_rx_h_queue_msdu(ar, status, msdu);\n\t}\n}\n\nstatic int ath10k_unchain_msdu(struct sk_buff_head *amsdu,\n\t\t\t       unsigned long *unchain_cnt)\n{\n\tstruct sk_buff *skb, *first;\n\tint space;\n\tint total_len = 0;\n\tint amsdu_len = skb_queue_len(amsdu);\n\n\t \n\n\tfirst = __skb_dequeue(amsdu);\n\n\t \n\tskb_queue_walk(amsdu, skb)\n\t\ttotal_len += skb->len;\n\n\tspace = total_len - skb_tailroom(first);\n\tif ((space > 0) &&\n\t    (pskb_expand_head(first, 0, space, GFP_ATOMIC) < 0)) {\n\t\t \n\t\t \n\t\t__skb_queue_head(amsdu, first);\n\t\treturn -1;\n\t}\n\n\t \n\twhile ((skb = __skb_dequeue(amsdu))) {\n\t\tskb_copy_from_linear_data(skb, skb_put(first, skb->len),\n\t\t\t\t\t  skb->len);\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\t__skb_queue_head(amsdu, first);\n\n\t*unchain_cnt += amsdu_len - 1;\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_rx_h_unchain(struct ath10k *ar,\n\t\t\t\t    struct sk_buff_head *amsdu,\n\t\t\t\t    unsigned long *drop_cnt,\n\t\t\t\t    unsigned long *unchain_cnt)\n{\n\tstruct sk_buff *first;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_msdu_start_common *rxd_msdu_start_common;\n\tstruct rx_frag_info_common *rxd_frag_info;\n\tenum rx_msdu_decap_format decap;\n\n\tfirst = skb_peek(amsdu);\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)first->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_msdu_start_common = ath10k_htt_rx_desc_get_msdu_start(hw, rxd);\n\trxd_frag_info = ath10k_htt_rx_desc_get_frag_info(hw, rxd);\n\tdecap = MS(__le32_to_cpu(rxd_msdu_start_common->info1),\n\t\t   RX_MSDU_START_INFO1_DECAP_FORMAT);\n\n\t \n\tif (decap != RX_MSDU_DECAP_RAW ||\n\t    skb_queue_len(amsdu) != 1 + rxd_frag_info->ring2_more_count) {\n\t\t*drop_cnt += skb_queue_len(amsdu);\n\t\t__skb_queue_purge(amsdu);\n\t\treturn;\n\t}\n\n\tath10k_unchain_msdu(amsdu, unchain_cnt);\n}\n\nstatic bool ath10k_htt_rx_validate_amsdu(struct ath10k *ar,\n\t\t\t\t\t struct sk_buff_head *amsdu)\n{\n\tu8 *subframe_hdr;\n\tstruct sk_buff *first;\n\tbool is_first, is_last;\n\tstruct ath10k_hw_params *hw = &ar->hw_params;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_msdu_end_common *rxd_msdu_end_common;\n\tstruct rx_mpdu_start *rxd_mpdu_start;\n\tstruct ieee80211_hdr *hdr;\n\tsize_t hdr_len, crypto_len;\n\tenum htt_rx_mpdu_encrypt_type enctype;\n\tint bytes_aligned = ar->hw_params.decap_align_bytes;\n\n\tfirst = skb_peek(amsdu);\n\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)first->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rxd);\n\trxd_mpdu_start = ath10k_htt_rx_desc_get_mpdu_start(hw, rxd);\n\thdr = (void *)ath10k_htt_rx_desc_get_rx_hdr_status(hw, rxd);\n\n\tis_first = !!(rxd_msdu_end_common->info0 &\n\t\t      __cpu_to_le32(RX_MSDU_END_INFO0_FIRST_MSDU));\n\tis_last = !!(rxd_msdu_end_common->info0 &\n\t\t     __cpu_to_le32(RX_MSDU_END_INFO0_LAST_MSDU));\n\n\t \n\tif (is_first && is_last)\n\t\treturn true;\n\n\t \n\tif (!is_first)\n\t\treturn false;\n\n\tenctype = MS(__le32_to_cpu(rxd_mpdu_start->info0),\n\t\t     RX_MPDU_START_INFO0_ENCRYPT_TYPE);\n\n\thdr_len = ieee80211_hdrlen(hdr->frame_control);\n\tcrypto_len = ath10k_htt_rx_crypto_param_len(ar, enctype);\n\n\tsubframe_hdr = (u8 *)hdr + round_up(hdr_len, bytes_aligned) +\n\t\t       crypto_len;\n\n\t \n\tif (ether_addr_equal(subframe_hdr, rfc1042_header))\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic bool ath10k_htt_rx_amsdu_allowed(struct ath10k *ar,\n\t\t\t\t\tstruct sk_buff_head *amsdu,\n\t\t\t\t\tstruct ieee80211_rx_status *rx_status)\n{\n\tif (!rx_status->freq) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"no channel configured; ignoring frame(s)!\\n\");\n\t\treturn false;\n\t}\n\n\tif (test_bit(ATH10K_CAC_RUNNING, &ar->dev_flags)) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx cac running\\n\");\n\t\treturn false;\n\t}\n\n\tif (!ath10k_htt_rx_validate_amsdu(ar, amsdu)) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"invalid amsdu received\\n\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void ath10k_htt_rx_h_filter(struct ath10k *ar,\n\t\t\t\t   struct sk_buff_head *amsdu,\n\t\t\t\t   struct ieee80211_rx_status *rx_status,\n\t\t\t\t   unsigned long *drop_cnt)\n{\n\tif (skb_queue_empty(amsdu))\n\t\treturn;\n\n\tif (ath10k_htt_rx_amsdu_allowed(ar, amsdu, rx_status))\n\t\treturn;\n\n\tif (drop_cnt)\n\t\t*drop_cnt += skb_queue_len(amsdu);\n\n\t__skb_queue_purge(amsdu);\n}\n\nstatic int ath10k_htt_rx_handle_amsdu(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ieee80211_rx_status *rx_status = &htt->rx_status;\n\tstruct sk_buff_head amsdu;\n\tint ret;\n\tunsigned long drop_cnt = 0;\n\tunsigned long unchain_cnt = 0;\n\tunsigned long drop_cnt_filter = 0;\n\tunsigned long msdus_to_queue, num_msdus;\n\tenum ath10k_pkt_rx_err err = ATH10K_PKT_RX_ERR_MAX;\n\tu8 first_hdr[RX_HTT_HDR_STATUS_LEN];\n\n\t__skb_queue_head_init(&amsdu);\n\n\tspin_lock_bh(&htt->rx_ring.lock);\n\tif (htt->rx_confused) {\n\t\tspin_unlock_bh(&htt->rx_ring.lock);\n\t\treturn -EIO;\n\t}\n\tret = ath10k_htt_rx_amsdu_pop(htt, &amsdu);\n\tspin_unlock_bh(&htt->rx_ring.lock);\n\n\tif (ret < 0) {\n\t\tath10k_warn(ar, \"rx ring became corrupted: %d\\n\", ret);\n\t\t__skb_queue_purge(&amsdu);\n\t\t \n\t\thtt->rx_confused = true;\n\t\treturn ret;\n\t}\n\n\tnum_msdus = skb_queue_len(&amsdu);\n\n\tath10k_htt_rx_h_ppdu(ar, &amsdu, rx_status, 0xffff);\n\n\t \n\tif (ret > 0)\n\t\tath10k_htt_rx_h_unchain(ar, &amsdu, &drop_cnt, &unchain_cnt);\n\n\tath10k_htt_rx_h_filter(ar, &amsdu, rx_status, &drop_cnt_filter);\n\tath10k_htt_rx_h_mpdu(ar, &amsdu, rx_status, true, first_hdr, &err, 0,\n\t\t\t     false);\n\tmsdus_to_queue = skb_queue_len(&amsdu);\n\tath10k_htt_rx_h_enqueue(ar, &amsdu, rx_status);\n\n\tath10k_sta_update_rx_tid_stats(ar, first_hdr, num_msdus, err,\n\t\t\t\t       unchain_cnt, drop_cnt, drop_cnt_filter,\n\t\t\t\t       msdus_to_queue);\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_rx_mpdu_desc_pn_hl(struct htt_hl_rx_desc *rx_desc,\n\t\t\t\t\t  union htt_rx_pn_t *pn,\n\t\t\t\t\t  int pn_len_bits)\n{\n\tswitch (pn_len_bits) {\n\tcase 48:\n\t\tpn->pn48 = __le32_to_cpu(rx_desc->pn_31_0) +\n\t\t\t   ((u64)(__le32_to_cpu(rx_desc->u0.pn_63_32) & 0xFFFF) << 32);\n\t\tbreak;\n\tcase 24:\n\t\tpn->pn24 = __le32_to_cpu(rx_desc->pn_31_0);\n\t\tbreak;\n\t}\n}\n\nstatic bool ath10k_htt_rx_pn_cmp48(union htt_rx_pn_t *new_pn,\n\t\t\t\t   union htt_rx_pn_t *old_pn)\n{\n\treturn ((new_pn->pn48 & 0xffffffffffffULL) <=\n\t\t(old_pn->pn48 & 0xffffffffffffULL));\n}\n\nstatic bool ath10k_htt_rx_pn_check_replay_hl(struct ath10k *ar,\n\t\t\t\t\t     struct ath10k_peer *peer,\n\t\t\t\t\t     struct htt_rx_indication_hl *rx)\n{\n\tbool last_pn_valid, pn_invalid = false;\n\tenum htt_txrx_sec_cast_type sec_index;\n\tenum htt_security_types sec_type;\n\tunion htt_rx_pn_t new_pn = {0};\n\tstruct htt_hl_rx_desc *rx_desc;\n\tunion htt_rx_pn_t *last_pn;\n\tu32 rx_desc_info, tid;\n\tint num_mpdu_ranges;\n\n\tlockdep_assert_held(&ar->data_lock);\n\n\tif (!peer)\n\t\treturn false;\n\n\tif (!(rx->fw_desc.flags & FW_RX_DESC_FLAGS_FIRST_MSDU))\n\t\treturn false;\n\n\tnum_mpdu_ranges = MS(__le32_to_cpu(rx->hdr.info1),\n\t\t\t     HTT_RX_INDICATION_INFO1_NUM_MPDU_RANGES);\n\n\trx_desc = (struct htt_hl_rx_desc *)&rx->mpdu_ranges[num_mpdu_ranges];\n\trx_desc_info = __le32_to_cpu(rx_desc->info);\n\n\tif (!MS(rx_desc_info, HTT_RX_DESC_HL_INFO_ENCRYPTED))\n\t\treturn false;\n\n\ttid = MS(rx->hdr.info0, HTT_RX_INDICATION_INFO0_EXT_TID);\n\tlast_pn_valid = peer->tids_last_pn_valid[tid];\n\tlast_pn = &peer->tids_last_pn[tid];\n\n\tif (MS(rx_desc_info, HTT_RX_DESC_HL_INFO_MCAST_BCAST))\n\t\tsec_index = HTT_TXRX_SEC_MCAST;\n\telse\n\t\tsec_index = HTT_TXRX_SEC_UCAST;\n\n\tsec_type = peer->rx_pn[sec_index].sec_type;\n\tath10k_htt_rx_mpdu_desc_pn_hl(rx_desc, &new_pn, peer->rx_pn[sec_index].pn_len);\n\n\tif (sec_type != HTT_SECURITY_AES_CCMP &&\n\t    sec_type != HTT_SECURITY_TKIP &&\n\t    sec_type != HTT_SECURITY_TKIP_NOMIC)\n\t\treturn false;\n\n\tif (last_pn_valid)\n\t\tpn_invalid = ath10k_htt_rx_pn_cmp48(&new_pn, last_pn);\n\telse\n\t\tpeer->tids_last_pn_valid[tid] = true;\n\n\tif (!pn_invalid)\n\t\tlast_pn->pn48 = new_pn.pn48;\n\n\treturn pn_invalid;\n}\n\nstatic bool ath10k_htt_rx_proc_rx_ind_hl(struct ath10k_htt *htt,\n\t\t\t\t\t struct htt_rx_indication_hl *rx,\n\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t enum htt_rx_pn_check_type check_pn_type,\n\t\t\t\t\t enum htt_rx_tkip_demic_type tkip_mic_type)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct ath10k_peer *peer;\n\tstruct htt_rx_indication_mpdu_range *mpdu_ranges;\n\tstruct fw_rx_desc_hl *fw_desc;\n\tenum htt_txrx_sec_cast_type sec_index;\n\tenum htt_security_types sec_type;\n\tunion htt_rx_pn_t new_pn = {0};\n\tstruct htt_hl_rx_desc *rx_desc;\n\tstruct ieee80211_hdr *hdr;\n\tstruct ieee80211_rx_status *rx_status;\n\tu16 peer_id;\n\tu8 rx_desc_len;\n\tint num_mpdu_ranges;\n\tsize_t tot_hdr_len;\n\tstruct ieee80211_channel *ch;\n\tbool pn_invalid, qos, first_msdu;\n\tu32 tid, rx_desc_info;\n\n\tpeer_id = __le16_to_cpu(rx->hdr.peer_id);\n\ttid = MS(rx->hdr.info0, HTT_RX_INDICATION_INFO0_EXT_TID);\n\n\tspin_lock_bh(&ar->data_lock);\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tspin_unlock_bh(&ar->data_lock);\n\tif (!peer && peer_id != HTT_INVALID_PEERID)\n\t\tath10k_warn(ar, \"Got RX ind from invalid peer: %u\\n\", peer_id);\n\n\tif (!peer)\n\t\treturn true;\n\n\tnum_mpdu_ranges = MS(__le32_to_cpu(rx->hdr.info1),\n\t\t\t     HTT_RX_INDICATION_INFO1_NUM_MPDU_RANGES);\n\tmpdu_ranges = htt_rx_ind_get_mpdu_ranges_hl(rx);\n\tfw_desc = &rx->fw_desc;\n\trx_desc_len = fw_desc->len;\n\n\tif (fw_desc->u.bits.discard) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt discard mpdu\\n\");\n\t\tgoto err;\n\t}\n\n\t \n\tif (num_mpdu_ranges > 1)\n\t\tath10k_warn(ar,\n\t\t\t    \"Unsupported number of MPDU ranges: %d, ignoring all but the first\\n\",\n\t\t\t    num_mpdu_ranges);\n\n\tif (mpdu_ranges->mpdu_range_status !=\n\t    HTT_RX_IND_MPDU_STATUS_OK &&\n\t    mpdu_ranges->mpdu_range_status !=\n\t    HTT_RX_IND_MPDU_STATUS_TKIP_MIC_ERR) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt mpdu_range_status %d\\n\",\n\t\t\t   mpdu_ranges->mpdu_range_status);\n\t\tgoto err;\n\t}\n\n\trx_desc = (struct htt_hl_rx_desc *)&rx->mpdu_ranges[num_mpdu_ranges];\n\trx_desc_info = __le32_to_cpu(rx_desc->info);\n\n\tif (MS(rx_desc_info, HTT_RX_DESC_HL_INFO_MCAST_BCAST))\n\t\tsec_index = HTT_TXRX_SEC_MCAST;\n\telse\n\t\tsec_index = HTT_TXRX_SEC_UCAST;\n\n\tsec_type = peer->rx_pn[sec_index].sec_type;\n\tfirst_msdu = rx->fw_desc.flags & FW_RX_DESC_FLAGS_FIRST_MSDU;\n\n\tath10k_htt_rx_mpdu_desc_pn_hl(rx_desc, &new_pn, peer->rx_pn[sec_index].pn_len);\n\n\tif (check_pn_type == HTT_RX_PN_CHECK && tid >= IEEE80211_NUM_TIDS) {\n\t\tspin_lock_bh(&ar->data_lock);\n\t\tpn_invalid = ath10k_htt_rx_pn_check_replay_hl(ar, peer, rx);\n\t\tspin_unlock_bh(&ar->data_lock);\n\n\t\tif (pn_invalid)\n\t\t\tgoto err;\n\t}\n\n\t \n\ttot_hdr_len = sizeof(struct htt_resp_hdr) + sizeof(rx->hdr) +\n\t\t      sizeof(rx->ppdu) + sizeof(rx->prefix) +\n\t\t      sizeof(rx->fw_desc) +\n\t\t      sizeof(*mpdu_ranges) * num_mpdu_ranges + rx_desc_len;\n\n\tskb_pull(skb, tot_hdr_len);\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\tqos = ieee80211_is_data_qos(hdr->frame_control);\n\n\trx_status = IEEE80211_SKB_RXCB(skb);\n\tmemset(rx_status, 0, sizeof(*rx_status));\n\n\tif (rx->ppdu.combined_rssi == 0) {\n\t\t \n\t\trx_status->signal = 0;\n\t\trx_status->flag |= RX_FLAG_NO_SIGNAL_VAL;\n\t} else {\n\t\trx_status->signal = ATH10K_DEFAULT_NOISE_FLOOR +\n\t\t\trx->ppdu.combined_rssi;\n\t\trx_status->flag &= ~RX_FLAG_NO_SIGNAL_VAL;\n\t}\n\n\tspin_lock_bh(&ar->data_lock);\n\tch = ar->scan_channel;\n\tif (!ch)\n\t\tch = ar->rx_channel;\n\tif (!ch)\n\t\tch = ath10k_htt_rx_h_any_channel(ar);\n\tif (!ch)\n\t\tch = ar->tgt_oper_chan;\n\tspin_unlock_bh(&ar->data_lock);\n\n\tif (ch) {\n\t\trx_status->band = ch->band;\n\t\trx_status->freq = ch->center_freq;\n\t}\n\tif (rx->fw_desc.flags & FW_RX_DESC_FLAGS_LAST_MSDU)\n\t\trx_status->flag &= ~RX_FLAG_AMSDU_MORE;\n\telse\n\t\trx_status->flag |= RX_FLAG_AMSDU_MORE;\n\n\t \n\tif (ieee80211_has_protected(hdr->frame_control)) {\n\t\thdr->frame_control &= ~__cpu_to_le16(IEEE80211_FCTL_PROTECTED);\n\t\trx_status->flag |= RX_FLAG_DECRYPTED |\n\t\t\t\t   RX_FLAG_IV_STRIPPED |\n\t\t\t\t   RX_FLAG_MMIC_STRIPPED;\n\n\t\tif (tid < IEEE80211_NUM_TIDS &&\n\t\t    first_msdu &&\n\t\t    check_pn_type == HTT_RX_PN_CHECK &&\n\t\t   (sec_type == HTT_SECURITY_AES_CCMP ||\n\t\t    sec_type == HTT_SECURITY_TKIP ||\n\t\t    sec_type == HTT_SECURITY_TKIP_NOMIC)) {\n\t\t\tu8 offset, *ivp, i;\n\t\t\ts8 keyidx = 0;\n\t\t\t__le64 pn48 = cpu_to_le64(new_pn.pn48);\n\n\t\t\thdr = (struct ieee80211_hdr *)skb->data;\n\t\t\toffset = ieee80211_hdrlen(hdr->frame_control);\n\t\t\thdr->frame_control |= __cpu_to_le16(IEEE80211_FCTL_PROTECTED);\n\t\t\trx_status->flag &= ~RX_FLAG_IV_STRIPPED;\n\n\t\t\tmemmove(skb->data - IEEE80211_CCMP_HDR_LEN,\n\t\t\t\tskb->data, offset);\n\t\t\tskb_push(skb, IEEE80211_CCMP_HDR_LEN);\n\t\t\tivp = skb->data + offset;\n\t\t\tmemset(skb->data + offset, 0, IEEE80211_CCMP_HDR_LEN);\n\t\t\t \n\t\t\tivp[IEEE80211_WEP_IV_LEN - 1] |= ATH10K_IEEE80211_EXTIV;\n\n\t\t\tfor (i = 0; i < ARRAY_SIZE(peer->keys); i++) {\n\t\t\t\tif (peer->keys[i] &&\n\t\t\t\t    peer->keys[i]->flags & IEEE80211_KEY_FLAG_PAIRWISE)\n\t\t\t\t\tkeyidx = peer->keys[i]->keyidx;\n\t\t\t}\n\n\t\t\t \n\t\t\tivp[IEEE80211_WEP_IV_LEN - 1] |= keyidx << 6;\n\n\t\t\tif (sec_type == HTT_SECURITY_AES_CCMP) {\n\t\t\t\trx_status->flag |= RX_FLAG_MIC_STRIPPED;\n\t\t\t\t \n\t\t\t\tmemcpy(skb->data + offset, &pn48, 2);\n\t\t\t\t \n\t\t\t\tmemcpy(skb->data + offset + 4, ((u8 *)&pn48) + 2, 4);\n\t\t\t} else {\n\t\t\t\trx_status->flag |= RX_FLAG_ICV_STRIPPED;\n\t\t\t\t \n\t\t\t\tmemcpy(skb->data + offset + 2, &pn48, 1);\n\t\t\t\t \n\t\t\t\tmemcpy(skb->data + offset, ((u8 *)&pn48) + 1, 1);\n\t\t\t\t \n\t\t\t\tmemcpy(skb->data + offset + 4, ((u8 *)&pn48) + 2, 4);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (tkip_mic_type == HTT_RX_TKIP_MIC)\n\t\trx_status->flag &= ~RX_FLAG_IV_STRIPPED &\n\t\t\t\t   ~RX_FLAG_MMIC_STRIPPED;\n\n\tif (mpdu_ranges->mpdu_range_status == HTT_RX_IND_MPDU_STATUS_TKIP_MIC_ERR)\n\t\trx_status->flag |= RX_FLAG_MMIC_ERROR;\n\n\tif (!qos && tid < IEEE80211_NUM_TIDS) {\n\t\tu8 offset;\n\t\t__le16 qos_ctrl = 0;\n\n\t\thdr = (struct ieee80211_hdr *)skb->data;\n\t\toffset = ieee80211_hdrlen(hdr->frame_control);\n\n\t\thdr->frame_control |= cpu_to_le16(IEEE80211_STYPE_QOS_DATA);\n\t\tmemmove(skb->data - IEEE80211_QOS_CTL_LEN, skb->data, offset);\n\t\tskb_push(skb, IEEE80211_QOS_CTL_LEN);\n\t\tqos_ctrl = cpu_to_le16(tid);\n\t\tmemcpy(skb->data + offset, &qos_ctrl, IEEE80211_QOS_CTL_LEN);\n\t}\n\n\tif (ar->napi.dev)\n\t\tieee80211_rx_napi(ar->hw, NULL, skb, &ar->napi);\n\telse\n\t\tieee80211_rx_ni(ar->hw, skb);\n\n\t \n\treturn false;\nerr:\n\t \n\treturn true;\n}\n\nstatic int ath10k_htt_rx_frag_tkip_decap_nomic(struct sk_buff *skb,\n\t\t\t\t\t       u16 head_len,\n\t\t\t\t\t       u16 hdr_len)\n{\n\tu8 *ivp, *orig_hdr;\n\n\torig_hdr = skb->data;\n\tivp = orig_hdr + hdr_len + head_len;\n\n\t \n\tif (!(ivp[IEEE80211_WEP_IV_LEN - 1] & ATH10K_IEEE80211_EXTIV))\n\t\treturn -EINVAL;\n\n\tmemmove(orig_hdr + IEEE80211_TKIP_IV_LEN, orig_hdr, head_len + hdr_len);\n\tskb_pull(skb, IEEE80211_TKIP_IV_LEN);\n\tskb_trim(skb, skb->len - ATH10K_IEEE80211_TKIP_MICLEN);\n\treturn 0;\n}\n\nstatic int ath10k_htt_rx_frag_tkip_decap_withmic(struct sk_buff *skb,\n\t\t\t\t\t\t u16 head_len,\n\t\t\t\t\t\t u16 hdr_len)\n{\n\tu8 *ivp, *orig_hdr;\n\n\torig_hdr = skb->data;\n\tivp = orig_hdr + hdr_len + head_len;\n\n\t \n\tif (!(ivp[IEEE80211_WEP_IV_LEN - 1] & ATH10K_IEEE80211_EXTIV))\n\t\treturn -EINVAL;\n\n\tmemmove(orig_hdr + IEEE80211_TKIP_IV_LEN, orig_hdr, head_len + hdr_len);\n\tskb_pull(skb, IEEE80211_TKIP_IV_LEN);\n\tskb_trim(skb, skb->len - IEEE80211_TKIP_ICV_LEN);\n\treturn 0;\n}\n\nstatic int ath10k_htt_rx_frag_ccmp_decap(struct sk_buff *skb,\n\t\t\t\t\t u16 head_len,\n\t\t\t\t\t u16 hdr_len)\n{\n\tu8 *ivp, *orig_hdr;\n\n\torig_hdr = skb->data;\n\tivp = orig_hdr + hdr_len + head_len;\n\n\t \n\tif (!(ivp[IEEE80211_WEP_IV_LEN - 1] & ATH10K_IEEE80211_EXTIV))\n\t\treturn -EINVAL;\n\n\tskb_trim(skb, skb->len - IEEE80211_CCMP_MIC_LEN);\n\tmemmove(orig_hdr + IEEE80211_CCMP_HDR_LEN, orig_hdr, head_len + hdr_len);\n\tskb_pull(skb, IEEE80211_CCMP_HDR_LEN);\n\treturn 0;\n}\n\nstatic int ath10k_htt_rx_frag_wep_decap(struct sk_buff *skb,\n\t\t\t\t\tu16 head_len,\n\t\t\t\t\tu16 hdr_len)\n{\n\tu8 *orig_hdr;\n\n\torig_hdr = skb->data;\n\n\tmemmove(orig_hdr + IEEE80211_WEP_IV_LEN,\n\t\torig_hdr, head_len + hdr_len);\n\tskb_pull(skb, IEEE80211_WEP_IV_LEN);\n\tskb_trim(skb, skb->len - IEEE80211_WEP_ICV_LEN);\n\treturn 0;\n}\n\nstatic bool ath10k_htt_rx_proc_rx_frag_ind_hl(struct ath10k_htt *htt,\n\t\t\t\t\t      struct htt_rx_fragment_indication *rx,\n\t\t\t\t\t      struct sk_buff *skb)\n{\n\tstruct ath10k *ar = htt->ar;\n\tenum htt_rx_tkip_demic_type tkip_mic = HTT_RX_NON_TKIP_MIC;\n\tenum htt_txrx_sec_cast_type sec_index;\n\tstruct htt_rx_indication_hl *rx_hl;\n\tenum htt_security_types sec_type;\n\tu32 tid, frag, seq, rx_desc_info;\n\tunion htt_rx_pn_t new_pn = {0};\n\tstruct htt_hl_rx_desc *rx_desc;\n\tu16 peer_id, sc, hdr_space;\n\tunion htt_rx_pn_t *last_pn;\n\tstruct ieee80211_hdr *hdr;\n\tint ret, num_mpdu_ranges;\n\tstruct ath10k_peer *peer;\n\tstruct htt_resp *resp;\n\tsize_t tot_hdr_len;\n\n\tresp = (struct htt_resp *)(skb->data + HTT_RX_FRAG_IND_INFO0_HEADER_LEN);\n\tskb_pull(skb, HTT_RX_FRAG_IND_INFO0_HEADER_LEN);\n\tskb_trim(skb, skb->len - FCS_LEN);\n\n\tpeer_id = __le16_to_cpu(rx->peer_id);\n\trx_hl = (struct htt_rx_indication_hl *)(&resp->rx_ind_hl);\n\n\tspin_lock_bh(&ar->data_lock);\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tif (!peer) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"invalid peer: %u\\n\", peer_id);\n\t\tgoto err;\n\t}\n\n\tnum_mpdu_ranges = MS(__le32_to_cpu(rx_hl->hdr.info1),\n\t\t\t     HTT_RX_INDICATION_INFO1_NUM_MPDU_RANGES);\n\n\ttot_hdr_len = sizeof(struct htt_resp_hdr) +\n\t\t      sizeof(rx_hl->hdr) +\n\t\t      sizeof(rx_hl->ppdu) +\n\t\t      sizeof(rx_hl->prefix) +\n\t\t      sizeof(rx_hl->fw_desc) +\n\t\t      sizeof(struct htt_rx_indication_mpdu_range) * num_mpdu_ranges;\n\n\ttid =  MS(rx_hl->hdr.info0, HTT_RX_INDICATION_INFO0_EXT_TID);\n\trx_desc = (struct htt_hl_rx_desc *)(skb->data + tot_hdr_len);\n\trx_desc_info = __le32_to_cpu(rx_desc->info);\n\n\thdr = (struct ieee80211_hdr *)((u8 *)rx_desc + rx_hl->fw_desc.len);\n\n\tif (is_multicast_ether_addr(hdr->addr1)) {\n\t\t \n\t\tgoto err;\n\t}\n\n\tif (!MS(rx_desc_info, HTT_RX_DESC_HL_INFO_ENCRYPTED)) {\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\treturn ath10k_htt_rx_proc_rx_ind_hl(htt, &resp->rx_ind_hl, skb,\n\t\t\t\t\t\t    HTT_RX_NON_PN_CHECK,\n\t\t\t\t\t\t    HTT_RX_NON_TKIP_MIC);\n\t}\n\n\tif (ieee80211_has_retry(hdr->frame_control))\n\t\tgoto err;\n\n\thdr_space = ieee80211_hdrlen(hdr->frame_control);\n\tsc = __le16_to_cpu(hdr->seq_ctrl);\n\tseq = IEEE80211_SEQ_TO_SN(sc);\n\tfrag = sc & IEEE80211_SCTL_FRAG;\n\n\tsec_index = MS(rx_desc_info, HTT_RX_DESC_HL_INFO_MCAST_BCAST) ?\n\t\t    HTT_TXRX_SEC_MCAST : HTT_TXRX_SEC_UCAST;\n\tsec_type = peer->rx_pn[sec_index].sec_type;\n\tath10k_htt_rx_mpdu_desc_pn_hl(rx_desc, &new_pn, peer->rx_pn[sec_index].pn_len);\n\n\tswitch (sec_type) {\n\tcase HTT_SECURITY_TKIP:\n\t\ttkip_mic = HTT_RX_TKIP_MIC;\n\t\tret = ath10k_htt_rx_frag_tkip_decap_withmic(skb,\n\t\t\t\t\t\t\t    tot_hdr_len +\n\t\t\t\t\t\t\t    rx_hl->fw_desc.len,\n\t\t\t\t\t\t\t    hdr_space);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbreak;\n\tcase HTT_SECURITY_TKIP_NOMIC:\n\t\tret = ath10k_htt_rx_frag_tkip_decap_nomic(skb,\n\t\t\t\t\t\t\t  tot_hdr_len +\n\t\t\t\t\t\t\t  rx_hl->fw_desc.len,\n\t\t\t\t\t\t\t  hdr_space);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbreak;\n\tcase HTT_SECURITY_AES_CCMP:\n\t\tret = ath10k_htt_rx_frag_ccmp_decap(skb,\n\t\t\t\t\t\t    tot_hdr_len + rx_hl->fw_desc.len,\n\t\t\t\t\t\t    hdr_space);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbreak;\n\tcase HTT_SECURITY_WEP128:\n\tcase HTT_SECURITY_WEP104:\n\tcase HTT_SECURITY_WEP40:\n\t\tret = ath10k_htt_rx_frag_wep_decap(skb,\n\t\t\t\t\t\t   tot_hdr_len + rx_hl->fw_desc.len,\n\t\t\t\t\t\t   hdr_space);\n\t\tif (ret)\n\t\t\tgoto err;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tresp = (struct htt_resp *)(skb->data);\n\n\tif (sec_type != HTT_SECURITY_AES_CCMP &&\n\t    sec_type != HTT_SECURITY_TKIP &&\n\t    sec_type != HTT_SECURITY_TKIP_NOMIC) {\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\treturn ath10k_htt_rx_proc_rx_ind_hl(htt, &resp->rx_ind_hl, skb,\n\t\t\t\t\t\t    HTT_RX_NON_PN_CHECK,\n\t\t\t\t\t\t    HTT_RX_NON_TKIP_MIC);\n\t}\n\n\tlast_pn = &peer->frag_tids_last_pn[tid];\n\n\tif (frag == 0) {\n\t\tif (ath10k_htt_rx_pn_check_replay_hl(ar, peer, &resp->rx_ind_hl))\n\t\t\tgoto err;\n\n\t\tlast_pn->pn48 = new_pn.pn48;\n\t\tpeer->frag_tids_seq[tid] = seq;\n\t} else if (sec_type == HTT_SECURITY_AES_CCMP) {\n\t\tif (seq != peer->frag_tids_seq[tid])\n\t\t\tgoto err;\n\n\t\tif (new_pn.pn48 != last_pn->pn48 + 1)\n\t\t\tgoto err;\n\n\t\tlast_pn->pn48 = new_pn.pn48;\n\t\tlast_pn = &peer->tids_last_pn[tid];\n\t\tlast_pn->pn48 = new_pn.pn48;\n\t}\n\n\tspin_unlock_bh(&ar->data_lock);\n\n\treturn ath10k_htt_rx_proc_rx_ind_hl(htt, &resp->rx_ind_hl, skb,\n\t\t\t\t\t    HTT_RX_NON_PN_CHECK, tkip_mic);\n\nerr:\n\tspin_unlock_bh(&ar->data_lock);\n\n\t \n\treturn true;\n}\n\nstatic void ath10k_htt_rx_proc_rx_ind_ll(struct ath10k_htt *htt,\n\t\t\t\t\t struct htt_rx_indication *rx)\n{\n\tstruct ath10k *ar = htt->ar;\n\tstruct htt_rx_indication_mpdu_range *mpdu_ranges;\n\tint num_mpdu_ranges;\n\tint i, mpdu_count = 0;\n\tu16 peer_id;\n\tu8 tid;\n\n\tnum_mpdu_ranges = MS(__le32_to_cpu(rx->hdr.info1),\n\t\t\t     HTT_RX_INDICATION_INFO1_NUM_MPDU_RANGES);\n\tpeer_id = __le16_to_cpu(rx->hdr.peer_id);\n\ttid =  MS(rx->hdr.info0, HTT_RX_INDICATION_INFO0_EXT_TID);\n\n\tmpdu_ranges = htt_rx_ind_get_mpdu_ranges(rx);\n\n\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"htt rx ind: \",\n\t\t\trx, struct_size(rx, mpdu_ranges, num_mpdu_ranges));\n\n\tfor (i = 0; i < num_mpdu_ranges; i++)\n\t\tmpdu_count += mpdu_ranges[i].mpdu_count;\n\n\tatomic_add(mpdu_count, &htt->num_mpdus_ready);\n\n\tath10k_sta_update_rx_tid_stats_ampdu(ar, peer_id, tid, mpdu_ranges,\n\t\t\t\t\t     num_mpdu_ranges);\n}\n\nstatic void ath10k_htt_rx_tx_compl_ind(struct ath10k *ar,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct htt_resp *resp = (struct htt_resp *)skb->data;\n\tstruct htt_tx_done tx_done = {};\n\tint status = MS(resp->data_tx_completion.flags, HTT_DATA_TX_STATUS);\n\t__le16 msdu_id, *msdus;\n\tbool rssi_enabled = false;\n\tu8 msdu_count = 0, num_airtime_records, tid;\n\tint i, htt_pad = 0;\n\tstruct htt_data_tx_compl_ppdu_dur *ppdu_info;\n\tstruct ath10k_peer *peer;\n\tu16 ppdu_info_offset = 0, peer_id;\n\tu32 tx_duration;\n\n\tswitch (status) {\n\tcase HTT_DATA_TX_STATUS_NO_ACK:\n\t\ttx_done.status = HTT_TX_COMPL_STATE_NOACK;\n\t\tbreak;\n\tcase HTT_DATA_TX_STATUS_OK:\n\t\ttx_done.status = HTT_TX_COMPL_STATE_ACK;\n\t\tbreak;\n\tcase HTT_DATA_TX_STATUS_DISCARD:\n\tcase HTT_DATA_TX_STATUS_POSTPONE:\n\tcase HTT_DATA_TX_STATUS_DOWNLOAD_FAIL:\n\t\ttx_done.status = HTT_TX_COMPL_STATE_DISCARD;\n\t\tbreak;\n\tdefault:\n\t\tath10k_warn(ar, \"unhandled tx completion status %d\\n\", status);\n\t\ttx_done.status = HTT_TX_COMPL_STATE_DISCARD;\n\t\tbreak;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt tx completion num_msdus %d\\n\",\n\t\t   resp->data_tx_completion.num_msdus);\n\n\tmsdu_count = resp->data_tx_completion.num_msdus;\n\tmsdus = resp->data_tx_completion.msdus;\n\trssi_enabled = ath10k_is_rssi_enable(&ar->hw_params, resp);\n\n\tif (rssi_enabled)\n\t\thtt_pad = ath10k_tx_data_rssi_get_pad_bytes(&ar->hw_params,\n\t\t\t\t\t\t\t    resp);\n\n\tfor (i = 0; i < msdu_count; i++) {\n\t\tmsdu_id = msdus[i];\n\t\ttx_done.msdu_id = __le16_to_cpu(msdu_id);\n\n\t\tif (rssi_enabled) {\n\t\t\t \n\t\t\tif (msdu_count & 0x01) {\n\t\t\t\tmsdu_id = msdus[msdu_count +  i + 1 + htt_pad];\n\t\t\t\ttx_done.ack_rssi = __le16_to_cpu(msdu_id);\n\t\t\t} else {\n\t\t\t\tmsdu_id = msdus[msdu_count +  i + htt_pad];\n\t\t\t\ttx_done.ack_rssi = __le16_to_cpu(msdu_id);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (ar->bus_param.dev_type == ATH10K_DEV_TYPE_HL) {\n\t\t\tath10k_txrx_tx_unref(htt, &tx_done);\n\t\t} else if (!kfifo_put(&htt->txdone_fifo, tx_done)) {\n\t\t\tath10k_warn(ar, \"txdone fifo overrun, msdu_id %d status %d\\n\",\n\t\t\t\t    tx_done.msdu_id, tx_done.status);\n\t\t\tath10k_txrx_tx_unref(htt, &tx_done);\n\t\t}\n\t}\n\n\tif (!(resp->data_tx_completion.flags2 & HTT_TX_CMPL_FLAG_PPDU_DURATION_PRESENT))\n\t\treturn;\n\n\tppdu_info_offset = (msdu_count & 0x01) ? msdu_count + 1 : msdu_count;\n\n\tif (rssi_enabled)\n\t\tppdu_info_offset += ppdu_info_offset;\n\n\tif (resp->data_tx_completion.flags2 &\n\t    (HTT_TX_CMPL_FLAG_PPID_PRESENT | HTT_TX_CMPL_FLAG_PA_PRESENT))\n\t\tppdu_info_offset += 2;\n\n\tppdu_info = (struct htt_data_tx_compl_ppdu_dur *)&msdus[ppdu_info_offset];\n\tnum_airtime_records = FIELD_GET(HTT_TX_COMPL_PPDU_DUR_INFO0_NUM_ENTRIES_MASK,\n\t\t\t\t\t__le32_to_cpu(ppdu_info->info0));\n\n\tfor (i = 0; i < num_airtime_records; i++) {\n\t\tstruct htt_data_tx_ppdu_dur *ppdu_dur;\n\t\tu32 info0;\n\n\t\tppdu_dur = &ppdu_info->ppdu_dur[i];\n\t\tinfo0 = __le32_to_cpu(ppdu_dur->info0);\n\n\t\tpeer_id = FIELD_GET(HTT_TX_PPDU_DUR_INFO0_PEER_ID_MASK,\n\t\t\t\t    info0);\n\t\trcu_read_lock();\n\t\tspin_lock_bh(&ar->data_lock);\n\n\t\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\t\tif (!peer || !peer->sta) {\n\t\t\tspin_unlock_bh(&ar->data_lock);\n\t\t\trcu_read_unlock();\n\t\t\tcontinue;\n\t\t}\n\n\t\ttid = FIELD_GET(HTT_TX_PPDU_DUR_INFO0_TID_MASK, info0) &\n\t\t\t\t\t\tIEEE80211_QOS_CTL_TID_MASK;\n\t\ttx_duration = __le32_to_cpu(ppdu_dur->tx_duration);\n\n\t\tieee80211_sta_register_airtime(peer->sta, tid, tx_duration, 0);\n\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\trcu_read_unlock();\n\t}\n}\n\nstatic void ath10k_htt_rx_addba(struct ath10k *ar, struct htt_resp *resp)\n{\n\tstruct htt_rx_addba *ev = &resp->rx_addba;\n\tstruct ath10k_peer *peer;\n\tstruct ath10k_vif *arvif;\n\tu16 info0, tid, peer_id;\n\n\tinfo0 = __le16_to_cpu(ev->info0);\n\ttid = MS(info0, HTT_RX_BA_INFO0_TID);\n\tpeer_id = MS(info0, HTT_RX_BA_INFO0_PEER_ID);\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt rx addba tid %u peer_id %u size %u\\n\",\n\t\t   tid, peer_id, ev->window_size);\n\n\tspin_lock_bh(&ar->data_lock);\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tif (!peer) {\n\t\tath10k_warn(ar, \"received addba event for invalid peer_id: %u\\n\",\n\t\t\t    peer_id);\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\treturn;\n\t}\n\n\tarvif = ath10k_get_arvif(ar, peer->vdev_id);\n\tif (!arvif) {\n\t\tath10k_warn(ar, \"received addba event for invalid vdev_id: %u\\n\",\n\t\t\t    peer->vdev_id);\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\treturn;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt rx start rx ba session sta %pM tid %u size %u\\n\",\n\t\t   peer->addr, tid, ev->window_size);\n\n\tieee80211_start_rx_ba_session_offl(arvif->vif, peer->addr, tid);\n\tspin_unlock_bh(&ar->data_lock);\n}\n\nstatic void ath10k_htt_rx_delba(struct ath10k *ar, struct htt_resp *resp)\n{\n\tstruct htt_rx_delba *ev = &resp->rx_delba;\n\tstruct ath10k_peer *peer;\n\tstruct ath10k_vif *arvif;\n\tu16 info0, tid, peer_id;\n\n\tinfo0 = __le16_to_cpu(ev->info0);\n\ttid = MS(info0, HTT_RX_BA_INFO0_TID);\n\tpeer_id = MS(info0, HTT_RX_BA_INFO0_PEER_ID);\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt rx delba tid %u peer_id %u\\n\",\n\t\t   tid, peer_id);\n\n\tspin_lock_bh(&ar->data_lock);\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tif (!peer) {\n\t\tath10k_warn(ar, \"received addba event for invalid peer_id: %u\\n\",\n\t\t\t    peer_id);\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\treturn;\n\t}\n\n\tarvif = ath10k_get_arvif(ar, peer->vdev_id);\n\tif (!arvif) {\n\t\tath10k_warn(ar, \"received addba event for invalid vdev_id: %u\\n\",\n\t\t\t    peer->vdev_id);\n\t\tspin_unlock_bh(&ar->data_lock);\n\t\treturn;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt rx stop rx ba session sta %pM tid %u\\n\",\n\t\t   peer->addr, tid);\n\n\tieee80211_stop_rx_ba_session_offl(arvif->vif, peer->addr, tid);\n\tspin_unlock_bh(&ar->data_lock);\n}\n\nstatic int ath10k_htt_rx_extract_amsdu(struct ath10k_hw_params *hw,\n\t\t\t\t       struct sk_buff_head *list,\n\t\t\t\t       struct sk_buff_head *amsdu)\n{\n\tstruct sk_buff *msdu;\n\tstruct htt_rx_desc *rxd;\n\tstruct rx_msdu_end_common *rxd_msdu_end_common;\n\n\tif (skb_queue_empty(list))\n\t\treturn -ENOBUFS;\n\n\tif (WARN_ON(!skb_queue_empty(amsdu)))\n\t\treturn -EINVAL;\n\n\twhile ((msdu = __skb_dequeue(list))) {\n\t\t__skb_queue_tail(amsdu, msdu);\n\n\t\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t\t    (void *)msdu->data -\n\t\t\t\t\t    hw->rx_desc_ops->rx_desc_size);\n\n\t\trxd_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rxd);\n\t\tif (rxd_msdu_end_common->info0 &\n\t\t    __cpu_to_le32(RX_MSDU_END_INFO0_LAST_MSDU))\n\t\t\tbreak;\n\t}\n\n\tmsdu = skb_peek_tail(amsdu);\n\trxd = HTT_RX_BUF_TO_RX_DESC(hw,\n\t\t\t\t    (void *)msdu->data - hw->rx_desc_ops->rx_desc_size);\n\n\trxd_msdu_end_common = ath10k_htt_rx_desc_get_msdu_end(hw, rxd);\n\tif (!(rxd_msdu_end_common->info0 &\n\t      __cpu_to_le32(RX_MSDU_END_INFO0_LAST_MSDU))) {\n\t\tskb_queue_splice_init(amsdu, list);\n\t\treturn -EAGAIN;\n\t}\n\n\treturn 0;\n}\n\nstatic void ath10k_htt_rx_h_rx_offload_prot(struct ieee80211_rx_status *status,\n\t\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\n\n\tif (!ieee80211_has_protected(hdr->frame_control))\n\t\treturn;\n\n\t \n\n\thdr->frame_control &= ~__cpu_to_le16(IEEE80211_FCTL_PROTECTED);\n\tstatus->flag |= RX_FLAG_DECRYPTED |\n\t\t\tRX_FLAG_IV_STRIPPED |\n\t\t\tRX_FLAG_MMIC_STRIPPED;\n}\n\nstatic void ath10k_htt_rx_h_rx_offload(struct ath10k *ar,\n\t\t\t\t       struct sk_buff_head *list)\n{\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct ieee80211_rx_status *status = &htt->rx_status;\n\tstruct htt_rx_offload_msdu *rx;\n\tstruct sk_buff *msdu;\n\tsize_t offset;\n\n\twhile ((msdu = __skb_dequeue(list))) {\n\t\t \n\n\t\trx = (void *)msdu->data;\n\n\t\tskb_put(msdu, sizeof(*rx));\n\t\tskb_pull(msdu, sizeof(*rx));\n\n\t\tif (skb_tailroom(msdu) < __le16_to_cpu(rx->msdu_len)) {\n\t\t\tath10k_warn(ar, \"dropping frame: offloaded rx msdu is too long!\\n\");\n\t\t\tdev_kfree_skb_any(msdu);\n\t\t\tcontinue;\n\t\t}\n\n\t\tskb_put(msdu, __le16_to_cpu(rx->msdu_len));\n\n\t\t \n\t\toffset = 4 - ((unsigned long)msdu->data & 3);\n\t\tskb_put(msdu, offset);\n\t\tmemmove(msdu->data + offset, msdu->data, msdu->len);\n\t\tskb_pull(msdu, offset);\n\n\t\t \n\n\t\tmemset(status, 0, sizeof(*status));\n\t\tstatus->flag |= RX_FLAG_NO_SIGNAL_VAL;\n\n\t\tath10k_htt_rx_h_rx_offload_prot(status, msdu);\n\t\tath10k_htt_rx_h_channel(ar, status, NULL, rx->vdev_id);\n\t\tath10k_htt_rx_h_queue_msdu(ar, status, msdu);\n\t}\n}\n\nstatic int ath10k_htt_rx_in_ord_ind(struct ath10k *ar, struct sk_buff *skb)\n{\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct htt_resp *resp = (void *)skb->data;\n\tstruct ieee80211_rx_status *status = &htt->rx_status;\n\tstruct sk_buff_head list;\n\tstruct sk_buff_head amsdu;\n\tu16 peer_id;\n\tu16 msdu_count;\n\tu8 vdev_id;\n\tu8 tid;\n\tbool offload;\n\tbool frag;\n\tint ret;\n\n\tlockdep_assert_held(&htt->rx_ring.lock);\n\n\tif (htt->rx_confused)\n\t\treturn -EIO;\n\n\tskb_pull(skb, sizeof(resp->hdr));\n\tskb_pull(skb, sizeof(resp->rx_in_ord_ind));\n\n\tpeer_id = __le16_to_cpu(resp->rx_in_ord_ind.peer_id);\n\tmsdu_count = __le16_to_cpu(resp->rx_in_ord_ind.msdu_count);\n\tvdev_id = resp->rx_in_ord_ind.vdev_id;\n\ttid = SM(resp->rx_in_ord_ind.info, HTT_RX_IN_ORD_IND_INFO_TID);\n\toffload = !!(resp->rx_in_ord_ind.info &\n\t\t\tHTT_RX_IN_ORD_IND_INFO_OFFLOAD_MASK);\n\tfrag = !!(resp->rx_in_ord_ind.info & HTT_RX_IN_ORD_IND_INFO_FRAG_MASK);\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt rx in ord vdev %i peer %i tid %i offload %i frag %i msdu count %i\\n\",\n\t\t   vdev_id, peer_id, tid, offload, frag, msdu_count);\n\n\tif (skb->len < msdu_count * sizeof(*resp->rx_in_ord_ind.msdu_descs32)) {\n\t\tath10k_warn(ar, \"dropping invalid in order rx indication\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t \n\t__skb_queue_head_init(&list);\n\tif (ar->hw_params.target_64bit)\n\t\tret = ath10k_htt_rx_pop_paddr64_list(htt, &resp->rx_in_ord_ind,\n\t\t\t\t\t\t     &list);\n\telse\n\t\tret = ath10k_htt_rx_pop_paddr32_list(htt, &resp->rx_in_ord_ind,\n\t\t\t\t\t\t     &list);\n\n\tif (ret < 0) {\n\t\tath10k_warn(ar, \"failed to pop paddr list: %d\\n\", ret);\n\t\thtt->rx_confused = true;\n\t\treturn -EIO;\n\t}\n\n\t \n\tif (offload)\n\t\tath10k_htt_rx_h_rx_offload(ar, &list);\n\n\twhile (!skb_queue_empty(&list)) {\n\t\t__skb_queue_head_init(&amsdu);\n\t\tret = ath10k_htt_rx_extract_amsdu(&ar->hw_params, &list, &amsdu);\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t \n\t\t\tath10k_htt_rx_h_ppdu(ar, &amsdu, status, vdev_id);\n\t\t\tath10k_htt_rx_h_filter(ar, &amsdu, status, NULL);\n\t\t\tath10k_htt_rx_h_mpdu(ar, &amsdu, status, false, NULL,\n\t\t\t\t\t     NULL, peer_id, frag);\n\t\t\tath10k_htt_rx_h_enqueue(ar, &amsdu, status);\n\t\t\tbreak;\n\t\tcase -EAGAIN:\n\t\t\tfallthrough;\n\t\tdefault:\n\t\t\t \n\t\t\tath10k_warn(ar, \"failed to extract amsdu: %d\\n\", ret);\n\t\t\thtt->rx_confused = true;\n\t\t\t__skb_queue_purge(&list);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic void ath10k_htt_rx_tx_fetch_resp_id_confirm(struct ath10k *ar,\n\t\t\t\t\t\t   const __le32 *resp_ids,\n\t\t\t\t\t\t   int num_resp_ids)\n{\n\tint i;\n\tu32 resp_id;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx tx fetch confirm num_resp_ids %d\\n\",\n\t\t   num_resp_ids);\n\n\tfor (i = 0; i < num_resp_ids; i++) {\n\t\tresp_id = le32_to_cpu(resp_ids[i]);\n\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx tx fetch confirm resp_id %u\\n\",\n\t\t\t   resp_id);\n\n\t\t \n\t}\n}\n\nstatic void ath10k_htt_rx_tx_fetch_ind(struct ath10k *ar, struct sk_buff *skb)\n{\n\tstruct ieee80211_hw *hw = ar->hw;\n\tstruct ieee80211_txq *txq;\n\tstruct htt_resp *resp = (struct htt_resp *)skb->data;\n\tstruct htt_tx_fetch_record *record;\n\tsize_t len;\n\tsize_t max_num_bytes;\n\tsize_t max_num_msdus;\n\tsize_t num_bytes;\n\tsize_t num_msdus;\n\tconst __le32 *resp_ids;\n\tu16 num_records;\n\tu16 num_resp_ids;\n\tu16 peer_id;\n\tu8 tid;\n\tint ret;\n\tint i;\n\tbool may_tx;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx tx fetch ind\\n\");\n\n\tlen = sizeof(resp->hdr) + sizeof(resp->tx_fetch_ind);\n\tif (unlikely(skb->len < len)) {\n\t\tath10k_warn(ar, \"received corrupted tx_fetch_ind event: buffer too short\\n\");\n\t\treturn;\n\t}\n\n\tnum_records = le16_to_cpu(resp->tx_fetch_ind.num_records);\n\tnum_resp_ids = le16_to_cpu(resp->tx_fetch_ind.num_resp_ids);\n\n\tlen += sizeof(resp->tx_fetch_ind.records[0]) * num_records;\n\tlen += sizeof(resp->tx_fetch_ind.resp_ids[0]) * num_resp_ids;\n\n\tif (unlikely(skb->len < len)) {\n\t\tath10k_warn(ar, \"received corrupted tx_fetch_ind event: too many records/resp_ids\\n\");\n\t\treturn;\n\t}\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx tx fetch ind num records %u num resps %u seq %u\\n\",\n\t\t   num_records, num_resp_ids,\n\t\t   le16_to_cpu(resp->tx_fetch_ind.fetch_seq_num));\n\n\tif (!ar->htt.tx_q_state.enabled) {\n\t\tath10k_warn(ar, \"received unexpected tx_fetch_ind event: not enabled\\n\");\n\t\treturn;\n\t}\n\n\tif (ar->htt.tx_q_state.mode == HTT_TX_MODE_SWITCH_PUSH) {\n\t\tath10k_warn(ar, \"received unexpected tx_fetch_ind event: in push mode\\n\");\n\t\treturn;\n\t}\n\n\trcu_read_lock();\n\n\tfor (i = 0; i < num_records; i++) {\n\t\trecord = &resp->tx_fetch_ind.records[i];\n\t\tpeer_id = MS(le16_to_cpu(record->info),\n\t\t\t     HTT_TX_FETCH_RECORD_INFO_PEER_ID);\n\t\ttid = MS(le16_to_cpu(record->info),\n\t\t\t HTT_TX_FETCH_RECORD_INFO_TID);\n\t\tmax_num_msdus = le16_to_cpu(record->num_msdus);\n\t\tmax_num_bytes = le32_to_cpu(record->num_bytes);\n\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx tx fetch record %i peer_id %u tid %u msdus %zu bytes %zu\\n\",\n\t\t\t   i, peer_id, tid, max_num_msdus, max_num_bytes);\n\n\t\tif (unlikely(peer_id >= ar->htt.tx_q_state.num_peers) ||\n\t\t    unlikely(tid >= ar->htt.tx_q_state.num_tids)) {\n\t\t\tath10k_warn(ar, \"received out of range peer_id %u tid %u\\n\",\n\t\t\t\t    peer_id, tid);\n\t\t\tcontinue;\n\t\t}\n\n\t\tspin_lock_bh(&ar->data_lock);\n\t\ttxq = ath10k_mac_txq_lookup(ar, peer_id, tid);\n\t\tspin_unlock_bh(&ar->data_lock);\n\n\t\t \n\n\t\tif (unlikely(!txq)) {\n\t\t\tath10k_warn(ar, \"failed to lookup txq for peer_id %u tid %u\\n\",\n\t\t\t\t    peer_id, tid);\n\t\t\tcontinue;\n\t\t}\n\n\t\tnum_msdus = 0;\n\t\tnum_bytes = 0;\n\n\t\tieee80211_txq_schedule_start(hw, txq->ac);\n\t\tmay_tx = ieee80211_txq_may_transmit(hw, txq);\n\t\twhile (num_msdus < max_num_msdus &&\n\t\t       num_bytes < max_num_bytes) {\n\t\t\tif (!may_tx)\n\t\t\t\tbreak;\n\n\t\t\tret = ath10k_mac_tx_push_txq(hw, txq);\n\t\t\tif (ret < 0)\n\t\t\t\tbreak;\n\n\t\t\tnum_msdus++;\n\t\t\tnum_bytes += ret;\n\t\t}\n\t\tieee80211_return_txq(hw, txq, false);\n\t\tieee80211_txq_schedule_end(hw, txq->ac);\n\n\t\trecord->num_msdus = cpu_to_le16(num_msdus);\n\t\trecord->num_bytes = cpu_to_le32(num_bytes);\n\n\t\tath10k_htt_tx_txq_recalc(hw, txq);\n\t}\n\n\trcu_read_unlock();\n\n\tresp_ids = ath10k_htt_get_tx_fetch_ind_resp_ids(&resp->tx_fetch_ind);\n\tath10k_htt_rx_tx_fetch_resp_id_confirm(ar, resp_ids, num_resp_ids);\n\n\tret = ath10k_htt_tx_fetch_resp(ar,\n\t\t\t\t       resp->tx_fetch_ind.token,\n\t\t\t\t       resp->tx_fetch_ind.fetch_seq_num,\n\t\t\t\t       resp->tx_fetch_ind.records,\n\t\t\t\t       num_records);\n\tif (unlikely(ret)) {\n\t\tath10k_warn(ar, \"failed to submit tx fetch resp for token 0x%08x: %d\\n\",\n\t\t\t    le32_to_cpu(resp->tx_fetch_ind.token), ret);\n\t\t \n\t}\n\n\tath10k_htt_tx_txq_sync(ar);\n}\n\nstatic void ath10k_htt_rx_tx_fetch_confirm(struct ath10k *ar,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n\tconst struct htt_resp *resp = (void *)skb->data;\n\tsize_t len;\n\tint num_resp_ids;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx tx fetch confirm\\n\");\n\n\tlen = sizeof(resp->hdr) + sizeof(resp->tx_fetch_confirm);\n\tif (unlikely(skb->len < len)) {\n\t\tath10k_warn(ar, \"received corrupted tx_fetch_confirm event: buffer too short\\n\");\n\t\treturn;\n\t}\n\n\tnum_resp_ids = le16_to_cpu(resp->tx_fetch_confirm.num_resp_ids);\n\tlen += sizeof(resp->tx_fetch_confirm.resp_ids[0]) * num_resp_ids;\n\n\tif (unlikely(skb->len < len)) {\n\t\tath10k_warn(ar, \"received corrupted tx_fetch_confirm event: resp_ids buffer overflow\\n\");\n\t\treturn;\n\t}\n\n\tath10k_htt_rx_tx_fetch_resp_id_confirm(ar,\n\t\t\t\t\t       resp->tx_fetch_confirm.resp_ids,\n\t\t\t\t\t       num_resp_ids);\n}\n\nstatic void ath10k_htt_rx_tx_mode_switch_ind(struct ath10k *ar,\n\t\t\t\t\t     struct sk_buff *skb)\n{\n\tconst struct htt_resp *resp = (void *)skb->data;\n\tconst struct htt_tx_mode_switch_record *record;\n\tstruct ieee80211_txq *txq;\n\tstruct ath10k_txq *artxq;\n\tsize_t len;\n\tsize_t num_records;\n\tenum htt_tx_mode_switch_mode mode;\n\tbool enable;\n\tu16 info0;\n\tu16 info1;\n\tu16 threshold;\n\tu16 peer_id;\n\tu8 tid;\n\tint i;\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx tx mode switch ind\\n\");\n\n\tlen = sizeof(resp->hdr) + sizeof(resp->tx_mode_switch_ind);\n\tif (unlikely(skb->len < len)) {\n\t\tath10k_warn(ar, \"received corrupted tx_mode_switch_ind event: buffer too short\\n\");\n\t\treturn;\n\t}\n\n\tinfo0 = le16_to_cpu(resp->tx_mode_switch_ind.info0);\n\tinfo1 = le16_to_cpu(resp->tx_mode_switch_ind.info1);\n\n\tenable = !!(info0 & HTT_TX_MODE_SWITCH_IND_INFO0_ENABLE);\n\tnum_records = MS(info0, HTT_TX_MODE_SWITCH_IND_INFO1_THRESHOLD);\n\tmode = MS(info1, HTT_TX_MODE_SWITCH_IND_INFO1_MODE);\n\tthreshold = MS(info1, HTT_TX_MODE_SWITCH_IND_INFO1_THRESHOLD);\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t   \"htt rx tx mode switch ind info0 0x%04x info1 0x%04x enable %d num records %zd mode %d threshold %u\\n\",\n\t\t   info0, info1, enable, num_records, mode, threshold);\n\n\tlen += sizeof(resp->tx_mode_switch_ind.records[0]) * num_records;\n\n\tif (unlikely(skb->len < len)) {\n\t\tath10k_warn(ar, \"received corrupted tx_mode_switch_mode_ind event: too many records\\n\");\n\t\treturn;\n\t}\n\n\tswitch (mode) {\n\tcase HTT_TX_MODE_SWITCH_PUSH:\n\tcase HTT_TX_MODE_SWITCH_PUSH_PULL:\n\t\tbreak;\n\tdefault:\n\t\tath10k_warn(ar, \"received invalid tx_mode_switch_mode_ind mode %d, ignoring\\n\",\n\t\t\t    mode);\n\t\treturn;\n\t}\n\n\tif (!enable)\n\t\treturn;\n\n\tar->htt.tx_q_state.enabled = enable;\n\tar->htt.tx_q_state.mode = mode;\n\tar->htt.tx_q_state.num_push_allowed = threshold;\n\n\trcu_read_lock();\n\n\tfor (i = 0; i < num_records; i++) {\n\t\trecord = &resp->tx_mode_switch_ind.records[i];\n\t\tinfo0 = le16_to_cpu(record->info0);\n\t\tpeer_id = MS(info0, HTT_TX_MODE_SWITCH_RECORD_INFO0_PEER_ID);\n\t\ttid = MS(info0, HTT_TX_MODE_SWITCH_RECORD_INFO0_TID);\n\n\t\tif (unlikely(peer_id >= ar->htt.tx_q_state.num_peers) ||\n\t\t    unlikely(tid >= ar->htt.tx_q_state.num_tids)) {\n\t\t\tath10k_warn(ar, \"received out of range peer_id %u tid %u\\n\",\n\t\t\t\t    peer_id, tid);\n\t\t\tcontinue;\n\t\t}\n\n\t\tspin_lock_bh(&ar->data_lock);\n\t\ttxq = ath10k_mac_txq_lookup(ar, peer_id, tid);\n\t\tspin_unlock_bh(&ar->data_lock);\n\n\t\t \n\n\t\tif (unlikely(!txq)) {\n\t\t\tath10k_warn(ar, \"failed to lookup txq for peer_id %u tid %u\\n\",\n\t\t\t\t    peer_id, tid);\n\t\t\tcontinue;\n\t\t}\n\n\t\tspin_lock_bh(&ar->htt.tx_lock);\n\t\tartxq = (void *)txq->drv_priv;\n\t\tartxq->num_push_allowed = le16_to_cpu(record->num_max_msdus);\n\t\tspin_unlock_bh(&ar->htt.tx_lock);\n\t}\n\n\trcu_read_unlock();\n\n\tath10k_mac_tx_push_pending(ar);\n}\n\nvoid ath10k_htt_htc_t2h_msg_handler(struct ath10k *ar, struct sk_buff *skb)\n{\n\tbool release;\n\n\trelease = ath10k_htt_t2h_msg_handler(ar, skb);\n\n\t \n\tif (release)\n\t\tdev_kfree_skb_any(skb);\n}\n\nstatic inline s8 ath10k_get_legacy_rate_idx(struct ath10k *ar, u8 rate)\n{\n\tstatic const u8 legacy_rates[] = {1, 2, 5, 11, 6, 9, 12,\n\t\t\t\t\t  18, 24, 36, 48, 54};\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(legacy_rates); i++) {\n\t\tif (rate == legacy_rates[i])\n\t\t\treturn i;\n\t}\n\n\tath10k_warn(ar, \"Invalid legacy rate %d peer stats\", rate);\n\treturn -EINVAL;\n}\n\nstatic void\nath10k_accumulate_per_peer_tx_stats(struct ath10k *ar,\n\t\t\t\t    struct ath10k_sta *arsta,\n\t\t\t\t    struct ath10k_per_peer_tx_stats *pstats,\n\t\t\t\t    s8 legacy_rate_idx)\n{\n\tstruct rate_info *txrate = &arsta->txrate;\n\tstruct ath10k_htt_tx_stats *tx_stats;\n\tint idx, ht_idx, gi, mcs, bw, nss;\n\tunsigned long flags;\n\n\tif (!arsta->tx_stats)\n\t\treturn;\n\n\ttx_stats = arsta->tx_stats;\n\tflags = txrate->flags;\n\tgi = test_bit(ATH10K_RATE_INFO_FLAGS_SGI_BIT, &flags);\n\tmcs = ATH10K_HW_MCS_RATE(pstats->ratecode);\n\tbw = txrate->bw;\n\tnss = txrate->nss;\n\tht_idx = mcs + (nss - 1) * 8;\n\tidx = mcs * 8 + 8 * 10 * (nss - 1);\n\tidx += bw * 2 + gi;\n\n#define STATS_OP_FMT(name) tx_stats->stats[ATH10K_STATS_TYPE_##name]\n\n\tif (txrate->flags & RATE_INFO_FLAGS_VHT_MCS) {\n\t\tSTATS_OP_FMT(SUCC).vht[0][mcs] += pstats->succ_bytes;\n\t\tSTATS_OP_FMT(SUCC).vht[1][mcs] += pstats->succ_pkts;\n\t\tSTATS_OP_FMT(FAIL).vht[0][mcs] += pstats->failed_bytes;\n\t\tSTATS_OP_FMT(FAIL).vht[1][mcs] += pstats->failed_pkts;\n\t\tSTATS_OP_FMT(RETRY).vht[0][mcs] += pstats->retry_bytes;\n\t\tSTATS_OP_FMT(RETRY).vht[1][mcs] += pstats->retry_pkts;\n\t} else if (txrate->flags & RATE_INFO_FLAGS_MCS) {\n\t\tSTATS_OP_FMT(SUCC).ht[0][ht_idx] += pstats->succ_bytes;\n\t\tSTATS_OP_FMT(SUCC).ht[1][ht_idx] += pstats->succ_pkts;\n\t\tSTATS_OP_FMT(FAIL).ht[0][ht_idx] += pstats->failed_bytes;\n\t\tSTATS_OP_FMT(FAIL).ht[1][ht_idx] += pstats->failed_pkts;\n\t\tSTATS_OP_FMT(RETRY).ht[0][ht_idx] += pstats->retry_bytes;\n\t\tSTATS_OP_FMT(RETRY).ht[1][ht_idx] += pstats->retry_pkts;\n\t} else {\n\t\tmcs = legacy_rate_idx;\n\n\t\tSTATS_OP_FMT(SUCC).legacy[0][mcs] += pstats->succ_bytes;\n\t\tSTATS_OP_FMT(SUCC).legacy[1][mcs] += pstats->succ_pkts;\n\t\tSTATS_OP_FMT(FAIL).legacy[0][mcs] += pstats->failed_bytes;\n\t\tSTATS_OP_FMT(FAIL).legacy[1][mcs] += pstats->failed_pkts;\n\t\tSTATS_OP_FMT(RETRY).legacy[0][mcs] += pstats->retry_bytes;\n\t\tSTATS_OP_FMT(RETRY).legacy[1][mcs] += pstats->retry_pkts;\n\t}\n\n\tif (ATH10K_HW_AMPDU(pstats->flags)) {\n\t\ttx_stats->ba_fails += ATH10K_HW_BA_FAIL(pstats->flags);\n\n\t\tif (txrate->flags & RATE_INFO_FLAGS_MCS) {\n\t\t\tSTATS_OP_FMT(AMPDU).ht[0][ht_idx] +=\n\t\t\t\tpstats->succ_bytes + pstats->retry_bytes;\n\t\t\tSTATS_OP_FMT(AMPDU).ht[1][ht_idx] +=\n\t\t\t\tpstats->succ_pkts + pstats->retry_pkts;\n\t\t} else {\n\t\t\tSTATS_OP_FMT(AMPDU).vht[0][mcs] +=\n\t\t\t\tpstats->succ_bytes + pstats->retry_bytes;\n\t\t\tSTATS_OP_FMT(AMPDU).vht[1][mcs] +=\n\t\t\t\tpstats->succ_pkts + pstats->retry_pkts;\n\t\t}\n\t\tSTATS_OP_FMT(AMPDU).bw[0][bw] +=\n\t\t\tpstats->succ_bytes + pstats->retry_bytes;\n\t\tSTATS_OP_FMT(AMPDU).nss[0][nss - 1] +=\n\t\t\tpstats->succ_bytes + pstats->retry_bytes;\n\t\tSTATS_OP_FMT(AMPDU).gi[0][gi] +=\n\t\t\tpstats->succ_bytes + pstats->retry_bytes;\n\t\tSTATS_OP_FMT(AMPDU).rate_table[0][idx] +=\n\t\t\tpstats->succ_bytes + pstats->retry_bytes;\n\t\tSTATS_OP_FMT(AMPDU).bw[1][bw] +=\n\t\t\tpstats->succ_pkts + pstats->retry_pkts;\n\t\tSTATS_OP_FMT(AMPDU).nss[1][nss - 1] +=\n\t\t\tpstats->succ_pkts + pstats->retry_pkts;\n\t\tSTATS_OP_FMT(AMPDU).gi[1][gi] +=\n\t\t\tpstats->succ_pkts + pstats->retry_pkts;\n\t\tSTATS_OP_FMT(AMPDU).rate_table[1][idx] +=\n\t\t\tpstats->succ_pkts + pstats->retry_pkts;\n\t} else {\n\t\ttx_stats->ack_fails +=\n\t\t\t\tATH10K_HW_BA_FAIL(pstats->flags);\n\t}\n\n\tSTATS_OP_FMT(SUCC).bw[0][bw] += pstats->succ_bytes;\n\tSTATS_OP_FMT(SUCC).nss[0][nss - 1] += pstats->succ_bytes;\n\tSTATS_OP_FMT(SUCC).gi[0][gi] += pstats->succ_bytes;\n\n\tSTATS_OP_FMT(SUCC).bw[1][bw] += pstats->succ_pkts;\n\tSTATS_OP_FMT(SUCC).nss[1][nss - 1] += pstats->succ_pkts;\n\tSTATS_OP_FMT(SUCC).gi[1][gi] += pstats->succ_pkts;\n\n\tSTATS_OP_FMT(FAIL).bw[0][bw] += pstats->failed_bytes;\n\tSTATS_OP_FMT(FAIL).nss[0][nss - 1] += pstats->failed_bytes;\n\tSTATS_OP_FMT(FAIL).gi[0][gi] += pstats->failed_bytes;\n\n\tSTATS_OP_FMT(FAIL).bw[1][bw] += pstats->failed_pkts;\n\tSTATS_OP_FMT(FAIL).nss[1][nss - 1] += pstats->failed_pkts;\n\tSTATS_OP_FMT(FAIL).gi[1][gi] += pstats->failed_pkts;\n\n\tSTATS_OP_FMT(RETRY).bw[0][bw] += pstats->retry_bytes;\n\tSTATS_OP_FMT(RETRY).nss[0][nss - 1] += pstats->retry_bytes;\n\tSTATS_OP_FMT(RETRY).gi[0][gi] += pstats->retry_bytes;\n\n\tSTATS_OP_FMT(RETRY).bw[1][bw] += pstats->retry_pkts;\n\tSTATS_OP_FMT(RETRY).nss[1][nss - 1] += pstats->retry_pkts;\n\tSTATS_OP_FMT(RETRY).gi[1][gi] += pstats->retry_pkts;\n\n\tif (txrate->flags >= RATE_INFO_FLAGS_MCS) {\n\t\tSTATS_OP_FMT(SUCC).rate_table[0][idx] += pstats->succ_bytes;\n\t\tSTATS_OP_FMT(SUCC).rate_table[1][idx] += pstats->succ_pkts;\n\t\tSTATS_OP_FMT(FAIL).rate_table[0][idx] += pstats->failed_bytes;\n\t\tSTATS_OP_FMT(FAIL).rate_table[1][idx] += pstats->failed_pkts;\n\t\tSTATS_OP_FMT(RETRY).rate_table[0][idx] += pstats->retry_bytes;\n\t\tSTATS_OP_FMT(RETRY).rate_table[1][idx] += pstats->retry_pkts;\n\t}\n\n\ttx_stats->tx_duration += pstats->duration;\n}\n\nstatic void\nath10k_update_per_peer_tx_stats(struct ath10k *ar,\n\t\t\t\tstruct ieee80211_sta *sta,\n\t\t\t\tstruct ath10k_per_peer_tx_stats *peer_stats)\n{\n\tstruct ath10k_sta *arsta = (struct ath10k_sta *)sta->drv_priv;\n\tstruct ieee80211_chanctx_conf *conf = NULL;\n\tu8 rate = 0, sgi;\n\ts8 rate_idx = 0;\n\tbool skip_auto_rate;\n\tstruct rate_info txrate;\n\n\tlockdep_assert_held(&ar->data_lock);\n\n\ttxrate.flags = ATH10K_HW_PREAMBLE(peer_stats->ratecode);\n\ttxrate.bw = ATH10K_HW_BW(peer_stats->flags);\n\ttxrate.nss = ATH10K_HW_NSS(peer_stats->ratecode);\n\ttxrate.mcs = ATH10K_HW_MCS_RATE(peer_stats->ratecode);\n\tsgi = ATH10K_HW_GI(peer_stats->flags);\n\tskip_auto_rate = ATH10K_FW_SKIPPED_RATE_CTRL(peer_stats->flags);\n\n\t \n\tif (skip_auto_rate)\n\t\treturn;\n\n\tif (txrate.flags == WMI_RATE_PREAMBLE_VHT && txrate.mcs > 9) {\n\t\tath10k_warn(ar, \"Invalid VHT mcs %d peer stats\",  txrate.mcs);\n\t\treturn;\n\t}\n\n\tif (txrate.flags == WMI_RATE_PREAMBLE_HT &&\n\t    (txrate.mcs > 7 || txrate.nss < 1)) {\n\t\tath10k_warn(ar, \"Invalid HT mcs %d nss %d peer stats\",\n\t\t\t    txrate.mcs, txrate.nss);\n\t\treturn;\n\t}\n\n\tmemset(&arsta->txrate, 0, sizeof(arsta->txrate));\n\tmemset(&arsta->tx_info.status, 0, sizeof(arsta->tx_info.status));\n\tif (txrate.flags == WMI_RATE_PREAMBLE_CCK ||\n\t    txrate.flags == WMI_RATE_PREAMBLE_OFDM) {\n\t\trate = ATH10K_HW_LEGACY_RATE(peer_stats->ratecode);\n\t\t \n\t\tif (rate == 6 && txrate.flags == WMI_RATE_PREAMBLE_CCK)\n\t\t\trate = 5;\n\t\trate_idx = ath10k_get_legacy_rate_idx(ar, rate);\n\t\tif (rate_idx < 0)\n\t\t\treturn;\n\t\tarsta->txrate.legacy = rate;\n\t} else if (txrate.flags == WMI_RATE_PREAMBLE_HT) {\n\t\tarsta->txrate.flags = RATE_INFO_FLAGS_MCS;\n\t\tarsta->txrate.mcs = txrate.mcs + 8 * (txrate.nss - 1);\n\t} else {\n\t\tarsta->txrate.flags = RATE_INFO_FLAGS_VHT_MCS;\n\t\tarsta->txrate.mcs = txrate.mcs;\n\t}\n\n\tswitch (txrate.flags) {\n\tcase WMI_RATE_PREAMBLE_OFDM:\n\t\tif (arsta->arvif && arsta->arvif->vif)\n\t\t\tconf = rcu_dereference(arsta->arvif->vif->bss_conf.chanctx_conf);\n\t\tif (conf && conf->def.chan->band == NL80211_BAND_5GHZ)\n\t\t\tarsta->tx_info.status.rates[0].idx = rate_idx - 4;\n\t\tbreak;\n\tcase WMI_RATE_PREAMBLE_CCK:\n\t\tarsta->tx_info.status.rates[0].idx = rate_idx;\n\t\tif (sgi)\n\t\t\tarsta->tx_info.status.rates[0].flags |=\n\t\t\t\t(IEEE80211_TX_RC_USE_SHORT_PREAMBLE |\n\t\t\t\t IEEE80211_TX_RC_SHORT_GI);\n\t\tbreak;\n\tcase WMI_RATE_PREAMBLE_HT:\n\t\tarsta->tx_info.status.rates[0].idx =\n\t\t\t\ttxrate.mcs + ((txrate.nss - 1) * 8);\n\t\tif (sgi)\n\t\t\tarsta->tx_info.status.rates[0].flags |=\n\t\t\t\t\tIEEE80211_TX_RC_SHORT_GI;\n\t\tarsta->tx_info.status.rates[0].flags |= IEEE80211_TX_RC_MCS;\n\t\tbreak;\n\tcase WMI_RATE_PREAMBLE_VHT:\n\t\tieee80211_rate_set_vht(&arsta->tx_info.status.rates[0],\n\t\t\t\t       txrate.mcs, txrate.nss);\n\t\tif (sgi)\n\t\t\tarsta->tx_info.status.rates[0].flags |=\n\t\t\t\t\t\tIEEE80211_TX_RC_SHORT_GI;\n\t\tarsta->tx_info.status.rates[0].flags |= IEEE80211_TX_RC_VHT_MCS;\n\t\tbreak;\n\t}\n\n\tarsta->txrate.nss = txrate.nss;\n\tarsta->txrate.bw = ath10k_bw_to_mac80211_bw(txrate.bw);\n\tarsta->last_tx_bitrate = cfg80211_calculate_bitrate(&arsta->txrate);\n\tif (sgi)\n\t\tarsta->txrate.flags |= RATE_INFO_FLAGS_SHORT_GI;\n\n\tswitch (arsta->txrate.bw) {\n\tcase RATE_INFO_BW_40:\n\t\tarsta->tx_info.status.rates[0].flags |=\n\t\t\t\tIEEE80211_TX_RC_40_MHZ_WIDTH;\n\t\tbreak;\n\tcase RATE_INFO_BW_80:\n\t\tarsta->tx_info.status.rates[0].flags |=\n\t\t\t\tIEEE80211_TX_RC_80_MHZ_WIDTH;\n\t\tbreak;\n\tcase RATE_INFO_BW_160:\n\t\tarsta->tx_info.status.rates[0].flags |=\n\t\t\t\tIEEE80211_TX_RC_160_MHZ_WIDTH;\n\t\tbreak;\n\t}\n\n\tif (peer_stats->succ_pkts) {\n\t\tarsta->tx_info.flags = IEEE80211_TX_STAT_ACK;\n\t\tarsta->tx_info.status.rates[0].count = 1;\n\t\tieee80211_tx_rate_update(ar->hw, sta, &arsta->tx_info);\n\t}\n\n\tif (ar->htt.disable_tx_comp) {\n\t\tarsta->tx_failed += peer_stats->failed_pkts;\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"tx failed %d\\n\",\n\t\t\t   arsta->tx_failed);\n\t}\n\n\tarsta->tx_retries += peer_stats->retry_pkts;\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt tx retries %d\", arsta->tx_retries);\n\n\tif (ath10k_debug_is_extd_tx_stats_enabled(ar))\n\t\tath10k_accumulate_per_peer_tx_stats(ar, arsta, peer_stats,\n\t\t\t\t\t\t    rate_idx);\n}\n\nstatic void ath10k_htt_fetch_peer_stats(struct ath10k *ar,\n\t\t\t\t\tstruct sk_buff *skb)\n{\n\tstruct htt_resp *resp = (struct htt_resp *)skb->data;\n\tstruct ath10k_per_peer_tx_stats *p_tx_stats = &ar->peer_tx_stats;\n\tstruct htt_per_peer_tx_stats_ind *tx_stats;\n\tstruct ieee80211_sta *sta;\n\tstruct ath10k_peer *peer;\n\tint peer_id, i;\n\tu8 ppdu_len, num_ppdu;\n\n\tnum_ppdu = resp->peer_tx_stats.num_ppdu;\n\tppdu_len = resp->peer_tx_stats.ppdu_len * sizeof(__le32);\n\n\tif (skb->len < sizeof(struct htt_resp_hdr) + num_ppdu * ppdu_len) {\n\t\tath10k_warn(ar, \"Invalid peer stats buf length %d\\n\", skb->len);\n\t\treturn;\n\t}\n\n\ttx_stats = (struct htt_per_peer_tx_stats_ind *)\n\t\t\t(resp->peer_tx_stats.payload);\n\tpeer_id = __le16_to_cpu(tx_stats->peer_id);\n\n\trcu_read_lock();\n\tspin_lock_bh(&ar->data_lock);\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tif (!peer || !peer->sta) {\n\t\tath10k_warn(ar, \"Invalid peer id %d peer stats buffer\\n\",\n\t\t\t    peer_id);\n\t\tgoto out;\n\t}\n\n\tsta = peer->sta;\n\tfor (i = 0; i < num_ppdu; i++) {\n\t\ttx_stats = (struct htt_per_peer_tx_stats_ind *)\n\t\t\t   (resp->peer_tx_stats.payload + i * ppdu_len);\n\n\t\tp_tx_stats->succ_bytes = __le32_to_cpu(tx_stats->succ_bytes);\n\t\tp_tx_stats->retry_bytes = __le32_to_cpu(tx_stats->retry_bytes);\n\t\tp_tx_stats->failed_bytes =\n\t\t\t\t__le32_to_cpu(tx_stats->failed_bytes);\n\t\tp_tx_stats->ratecode = tx_stats->ratecode;\n\t\tp_tx_stats->flags = tx_stats->flags;\n\t\tp_tx_stats->succ_pkts = __le16_to_cpu(tx_stats->succ_pkts);\n\t\tp_tx_stats->retry_pkts = __le16_to_cpu(tx_stats->retry_pkts);\n\t\tp_tx_stats->failed_pkts = __le16_to_cpu(tx_stats->failed_pkts);\n\t\tp_tx_stats->duration = __le16_to_cpu(tx_stats->tx_duration);\n\n\t\tath10k_update_per_peer_tx_stats(ar, sta, p_tx_stats);\n\t}\n\nout:\n\tspin_unlock_bh(&ar->data_lock);\n\trcu_read_unlock();\n}\n\nstatic void ath10k_fetch_10_2_tx_stats(struct ath10k *ar, u8 *data)\n{\n\tstruct ath10k_pktlog_hdr *hdr = (struct ath10k_pktlog_hdr *)data;\n\tstruct ath10k_per_peer_tx_stats *p_tx_stats = &ar->peer_tx_stats;\n\tstruct ath10k_10_2_peer_tx_stats *tx_stats;\n\tstruct ieee80211_sta *sta;\n\tstruct ath10k_peer *peer;\n\tu16 log_type = __le16_to_cpu(hdr->log_type);\n\tu32 peer_id = 0, i;\n\n\tif (log_type != ATH_PKTLOG_TYPE_TX_STAT)\n\t\treturn;\n\n\ttx_stats = (struct ath10k_10_2_peer_tx_stats *)((hdr->payload) +\n\t\t    ATH10K_10_2_TX_STATS_OFFSET);\n\n\tif (!tx_stats->tx_ppdu_cnt)\n\t\treturn;\n\n\tpeer_id = tx_stats->peer_id;\n\n\trcu_read_lock();\n\tspin_lock_bh(&ar->data_lock);\n\tpeer = ath10k_peer_find_by_id(ar, peer_id);\n\tif (!peer || !peer->sta) {\n\t\tath10k_warn(ar, \"Invalid peer id %d in peer stats buffer\\n\",\n\t\t\t    peer_id);\n\t\tgoto out;\n\t}\n\n\tsta = peer->sta;\n\tfor (i = 0; i < tx_stats->tx_ppdu_cnt; i++) {\n\t\tp_tx_stats->succ_bytes =\n\t\t\t__le16_to_cpu(tx_stats->success_bytes[i]);\n\t\tp_tx_stats->retry_bytes =\n\t\t\t__le16_to_cpu(tx_stats->retry_bytes[i]);\n\t\tp_tx_stats->failed_bytes =\n\t\t\t__le16_to_cpu(tx_stats->failed_bytes[i]);\n\t\tp_tx_stats->ratecode = tx_stats->ratecode[i];\n\t\tp_tx_stats->flags = tx_stats->flags[i];\n\t\tp_tx_stats->succ_pkts = tx_stats->success_pkts[i];\n\t\tp_tx_stats->retry_pkts = tx_stats->retry_pkts[i];\n\t\tp_tx_stats->failed_pkts = tx_stats->failed_pkts[i];\n\n\t\tath10k_update_per_peer_tx_stats(ar, sta, p_tx_stats);\n\t}\n\tspin_unlock_bh(&ar->data_lock);\n\trcu_read_unlock();\n\n\treturn;\n\nout:\n\tspin_unlock_bh(&ar->data_lock);\n\trcu_read_unlock();\n}\n\nstatic int ath10k_htt_rx_pn_len(enum htt_security_types sec_type)\n{\n\tswitch (sec_type) {\n\tcase HTT_SECURITY_TKIP:\n\tcase HTT_SECURITY_TKIP_NOMIC:\n\tcase HTT_SECURITY_AES_CCMP:\n\t\treturn 48;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\nstatic void ath10k_htt_rx_sec_ind_handler(struct ath10k *ar,\n\t\t\t\t\t  struct htt_security_indication *ev)\n{\n\tenum htt_txrx_sec_cast_type sec_index;\n\tenum htt_security_types sec_type;\n\tstruct ath10k_peer *peer;\n\n\tspin_lock_bh(&ar->data_lock);\n\n\tpeer = ath10k_peer_find_by_id(ar, __le16_to_cpu(ev->peer_id));\n\tif (!peer) {\n\t\tath10k_warn(ar, \"failed to find peer id %d for security indication\",\n\t\t\t    __le16_to_cpu(ev->peer_id));\n\t\tgoto out;\n\t}\n\n\tsec_type = MS(ev->flags, HTT_SECURITY_TYPE);\n\n\tif (ev->flags & HTT_SECURITY_IS_UNICAST)\n\t\tsec_index = HTT_TXRX_SEC_UCAST;\n\telse\n\t\tsec_index = HTT_TXRX_SEC_MCAST;\n\n\tpeer->rx_pn[sec_index].sec_type = sec_type;\n\tpeer->rx_pn[sec_index].pn_len = ath10k_htt_rx_pn_len(sec_type);\n\n\tmemset(peer->tids_last_pn_valid, 0, sizeof(peer->tids_last_pn_valid));\n\tmemset(peer->tids_last_pn, 0, sizeof(peer->tids_last_pn));\n\nout:\n\tspin_unlock_bh(&ar->data_lock);\n}\n\nbool ath10k_htt_t2h_msg_handler(struct ath10k *ar, struct sk_buff *skb)\n{\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct htt_resp *resp = (struct htt_resp *)skb->data;\n\tenum htt_t2h_msg_type type;\n\n\t \n\tif (!IS_ALIGNED((unsigned long)skb->data, 4))\n\t\tath10k_warn(ar, \"unaligned htt message, expect trouble\\n\");\n\n\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx, msg_type: 0x%0X\\n\",\n\t\t   resp->hdr.msg_type);\n\n\tif (resp->hdr.msg_type >= ar->htt.t2h_msg_types_max) {\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"htt rx, unsupported msg_type: 0x%0X\\n max: 0x%0X\",\n\t\t\t   resp->hdr.msg_type, ar->htt.t2h_msg_types_max);\n\t\treturn true;\n\t}\n\ttype = ar->htt.t2h_msg_types[resp->hdr.msg_type];\n\n\tswitch (type) {\n\tcase HTT_T2H_MSG_TYPE_VERSION_CONF: {\n\t\thtt->target_version_major = resp->ver_resp.major;\n\t\thtt->target_version_minor = resp->ver_resp.minor;\n\t\tcomplete(&htt->target_version_received);\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_RX_IND:\n\t\tif (ar->bus_param.dev_type != ATH10K_DEV_TYPE_HL) {\n\t\t\tath10k_htt_rx_proc_rx_ind_ll(htt, &resp->rx_ind);\n\t\t} else {\n\t\t\tskb_queue_tail(&htt->rx_indication_head, skb);\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PEER_MAP: {\n\t\tstruct htt_peer_map_event ev = {\n\t\t\t.vdev_id = resp->peer_map.vdev_id,\n\t\t\t.peer_id = __le16_to_cpu(resp->peer_map.peer_id),\n\t\t};\n\t\tmemcpy(ev.addr, resp->peer_map.addr, sizeof(ev.addr));\n\t\tath10k_peer_map_event(htt, &ev);\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_PEER_UNMAP: {\n\t\tstruct htt_peer_unmap_event ev = {\n\t\t\t.peer_id = __le16_to_cpu(resp->peer_unmap.peer_id),\n\t\t};\n\t\tath10k_peer_unmap_event(htt, &ev);\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_MGMT_TX_COMPLETION: {\n\t\tstruct htt_tx_done tx_done = {};\n\t\tstruct ath10k_htt *htt = &ar->htt;\n\t\tstruct ath10k_htc *htc = &ar->htc;\n\t\tstruct ath10k_htc_ep *ep = &ar->htc.endpoint[htt->eid];\n\t\tint status = __le32_to_cpu(resp->mgmt_tx_completion.status);\n\t\tint info = __le32_to_cpu(resp->mgmt_tx_completion.info);\n\n\t\ttx_done.msdu_id = __le32_to_cpu(resp->mgmt_tx_completion.desc_id);\n\n\t\tswitch (status) {\n\t\tcase HTT_MGMT_TX_STATUS_OK:\n\t\t\ttx_done.status = HTT_TX_COMPL_STATE_ACK;\n\t\t\tif (test_bit(WMI_SERVICE_HTT_MGMT_TX_COMP_VALID_FLAGS,\n\t\t\t\t     ar->wmi.svc_map) &&\n\t\t\t    (resp->mgmt_tx_completion.flags &\n\t\t\t     HTT_MGMT_TX_CMPL_FLAG_ACK_RSSI)) {\n\t\t\t\ttx_done.ack_rssi =\n\t\t\t\tFIELD_GET(HTT_MGMT_TX_CMPL_INFO_ACK_RSSI_MASK,\n\t\t\t\t\t  info);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase HTT_MGMT_TX_STATUS_RETRY:\n\t\t\ttx_done.status = HTT_TX_COMPL_STATE_NOACK;\n\t\t\tbreak;\n\t\tcase HTT_MGMT_TX_STATUS_DROP:\n\t\t\ttx_done.status = HTT_TX_COMPL_STATE_DISCARD;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (htt->disable_tx_comp) {\n\t\t\tspin_lock_bh(&htc->tx_lock);\n\t\t\tep->tx_credits++;\n\t\t\tspin_unlock_bh(&htc->tx_lock);\n\t\t}\n\n\t\tstatus = ath10k_txrx_tx_unref(htt, &tx_done);\n\t\tif (!status) {\n\t\t\tspin_lock_bh(&htt->tx_lock);\n\t\t\tath10k_htt_tx_mgmt_dec_pending(htt);\n\t\t\tspin_unlock_bh(&htt->tx_lock);\n\t\t}\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_TX_COMPL_IND:\n\t\tath10k_htt_rx_tx_compl_ind(htt->ar, skb);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_SEC_IND: {\n\t\tstruct ath10k *ar = htt->ar;\n\t\tstruct htt_security_indication *ev = &resp->security_indication;\n\n\t\tath10k_htt_rx_sec_ind_handler(ar, ev);\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t\t   \"sec ind peer_id %d unicast %d type %d\\n\",\n\t\t\t  __le16_to_cpu(ev->peer_id),\n\t\t\t  !!(ev->flags & HTT_SECURITY_IS_UNICAST),\n\t\t\t  MS(ev->flags, HTT_SECURITY_TYPE));\n\t\tcomplete(&ar->install_key_done);\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_RX_FRAG_IND: {\n\t\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"htt event: \",\n\t\t\t\tskb->data, skb->len);\n\t\tatomic_inc(&htt->num_mpdus_ready);\n\n\t\treturn ath10k_htt_rx_proc_rx_frag_ind(htt,\n\t\t\t\t\t\t      &resp->rx_frag_ind,\n\t\t\t\t\t\t      skb);\n\t}\n\tcase HTT_T2H_MSG_TYPE_TEST:\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_STATS_CONF:\n\t\ttrace_ath10k_htt_stats(ar, skb->data, skb->len);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_TX_INSPECT_IND:\n\t\t \n\t\tath10k_warn(ar, \"received an unexpected htt tx inspect event\\n\");\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_RX_ADDBA:\n\t\tath10k_htt_rx_addba(ar, resp);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_RX_DELBA:\n\t\tath10k_htt_rx_delba(ar, resp);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PKTLOG: {\n\t\ttrace_ath10k_htt_pktlog(ar, resp->pktlog_msg.payload,\n\t\t\t\t\tskb->len -\n\t\t\t\t\toffsetof(struct htt_resp,\n\t\t\t\t\t\t pktlog_msg.payload));\n\n\t\tif (ath10k_peer_stats_enabled(ar))\n\t\t\tath10k_fetch_10_2_tx_stats(ar,\n\t\t\t\t\t\t   resp->pktlog_msg.payload);\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_RX_FLUSH: {\n\t\t \n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_RX_IN_ORD_PADDR_IND: {\n\t\tskb_queue_tail(&htt->rx_in_ord_compl_q, skb);\n\t\treturn false;\n\t}\n\tcase HTT_T2H_MSG_TYPE_TX_CREDIT_UPDATE_IND: {\n\t\tstruct ath10k_htt *htt = &ar->htt;\n\t\tstruct ath10k_htc *htc = &ar->htc;\n\t\tstruct ath10k_htc_ep *ep = &ar->htc.endpoint[htt->eid];\n\t\tu32 msg_word = __le32_to_cpu(*(__le32 *)resp);\n\t\tint htt_credit_delta;\n\n\t\thtt_credit_delta = HTT_TX_CREDIT_DELTA_ABS_GET(msg_word);\n\t\tif (HTT_TX_CREDIT_SIGN_BIT_GET(msg_word))\n\t\t\thtt_credit_delta = -htt_credit_delta;\n\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t\t   \"htt credit update delta %d\\n\",\n\t\t\t   htt_credit_delta);\n\n\t\tif (htt->disable_tx_comp) {\n\t\t\tspin_lock_bh(&htc->tx_lock);\n\t\t\tep->tx_credits += htt_credit_delta;\n\t\t\tspin_unlock_bh(&htc->tx_lock);\n\t\t\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t\t\t   \"htt credit total %d\\n\",\n\t\t\t\t   ep->tx_credits);\n\t\t\tep->ep_ops.ep_tx_credits(htc->ar);\n\t\t}\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_CHAN_CHANGE: {\n\t\tu32 phymode = __le32_to_cpu(resp->chan_change.phymode);\n\t\tu32 freq = __le32_to_cpu(resp->chan_change.freq);\n\n\t\tar->tgt_oper_chan = ieee80211_get_channel(ar->hw->wiphy, freq);\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT,\n\t\t\t   \"htt chan change freq %u phymode %s\\n\",\n\t\t\t   freq, ath10k_wmi_phymode_str(phymode));\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_AGGR_CONF:\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_TX_FETCH_IND: {\n\t\tstruct sk_buff *tx_fetch_ind = skb_copy(skb, GFP_ATOMIC);\n\n\t\tif (!tx_fetch_ind) {\n\t\t\tath10k_warn(ar, \"failed to copy htt tx fetch ind\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tskb_queue_tail(&htt->tx_fetch_ind_q, tx_fetch_ind);\n\t\tbreak;\n\t}\n\tcase HTT_T2H_MSG_TYPE_TX_FETCH_CONFIRM:\n\t\tath10k_htt_rx_tx_fetch_confirm(ar, skb);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_TX_MODE_SWITCH_IND:\n\t\tath10k_htt_rx_tx_mode_switch_ind(ar, skb);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_PEER_STATS:\n\t\tath10k_htt_fetch_peer_stats(ar, skb);\n\t\tbreak;\n\tcase HTT_T2H_MSG_TYPE_EN_STATS:\n\tdefault:\n\t\tath10k_warn(ar, \"htt event (%d) not handled\\n\",\n\t\t\t    resp->hdr.msg_type);\n\t\tath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, \"htt event: \",\n\t\t\t\tskb->data, skb->len);\n\t\tbreak;\n\t}\n\treturn true;\n}\nEXPORT_SYMBOL(ath10k_htt_t2h_msg_handler);\n\nvoid ath10k_htt_rx_pktlog_completion_handler(struct ath10k *ar,\n\t\t\t\t\t     struct sk_buff *skb)\n{\n\ttrace_ath10k_htt_pktlog(ar, skb->data, skb->len);\n\tdev_kfree_skb_any(skb);\n}\nEXPORT_SYMBOL(ath10k_htt_rx_pktlog_completion_handler);\n\nstatic int ath10k_htt_rx_deliver_msdu(struct ath10k *ar, int quota, int budget)\n{\n\tstruct sk_buff *skb;\n\n\twhile (quota < budget) {\n\t\tif (skb_queue_empty(&ar->htt.rx_msdus_q))\n\t\t\tbreak;\n\n\t\tskb = skb_dequeue(&ar->htt.rx_msdus_q);\n\t\tif (!skb)\n\t\t\tbreak;\n\t\tath10k_process_rx(ar, skb);\n\t\tquota++;\n\t}\n\n\treturn quota;\n}\n\nint ath10k_htt_rx_hl_indication(struct ath10k *ar, int budget)\n{\n\tstruct htt_resp *resp;\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct sk_buff *skb;\n\tbool release;\n\tint quota;\n\n\tfor (quota = 0; quota < budget; quota++) {\n\t\tskb = skb_dequeue(&htt->rx_indication_head);\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\tresp = (struct htt_resp *)skb->data;\n\n\t\trelease = ath10k_htt_rx_proc_rx_ind_hl(htt,\n\t\t\t\t\t\t       &resp->rx_ind_hl,\n\t\t\t\t\t\t       skb,\n\t\t\t\t\t\t       HTT_RX_PN_CHECK,\n\t\t\t\t\t\t       HTT_RX_NON_TKIP_MIC);\n\n\t\tif (release)\n\t\t\tdev_kfree_skb_any(skb);\n\n\t\tath10k_dbg(ar, ATH10K_DBG_HTT, \"rx indication poll pending count:%d\\n\",\n\t\t\t   skb_queue_len(&htt->rx_indication_head));\n\t}\n\treturn quota;\n}\nEXPORT_SYMBOL(ath10k_htt_rx_hl_indication);\n\nint ath10k_htt_txrx_compl_task(struct ath10k *ar, int budget)\n{\n\tstruct ath10k_htt *htt = &ar->htt;\n\tstruct htt_tx_done tx_done = {};\n\tstruct sk_buff_head tx_ind_q;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\tint quota = 0, done, ret;\n\tbool resched_napi = false;\n\n\t__skb_queue_head_init(&tx_ind_q);\n\n\t \n\tquota = ath10k_htt_rx_deliver_msdu(ar, quota, budget);\n\tif (quota == budget) {\n\t\tresched_napi = true;\n\t\tgoto exit;\n\t}\n\n\twhile ((skb = skb_dequeue(&htt->rx_in_ord_compl_q))) {\n\t\tspin_lock_bh(&htt->rx_ring.lock);\n\t\tret = ath10k_htt_rx_in_ord_ind(ar, skb);\n\t\tspin_unlock_bh(&htt->rx_ring.lock);\n\n\t\tdev_kfree_skb_any(skb);\n\t\tif (ret == -EIO) {\n\t\t\tresched_napi = true;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\twhile (atomic_read(&htt->num_mpdus_ready)) {\n\t\tret = ath10k_htt_rx_handle_amsdu(htt);\n\t\tif (ret == -EIO) {\n\t\t\tresched_napi = true;\n\t\t\tgoto exit;\n\t\t}\n\t\tatomic_dec(&htt->num_mpdus_ready);\n\t}\n\n\t \n\tquota = ath10k_htt_rx_deliver_msdu(ar, quota, budget);\n\n\t \n\tif ((quota < budget) && !kfifo_is_empty(&htt->txdone_fifo))\n\t\tquota = budget;\n\n\t \n\twhile (kfifo_get(&htt->txdone_fifo, &tx_done))\n\t\tath10k_txrx_tx_unref(htt, &tx_done);\n\n\tath10k_mac_tx_push_pending(ar);\n\n\tspin_lock_irqsave(&htt->tx_fetch_ind_q.lock, flags);\n\tskb_queue_splice_init(&htt->tx_fetch_ind_q, &tx_ind_q);\n\tspin_unlock_irqrestore(&htt->tx_fetch_ind_q.lock, flags);\n\n\twhile ((skb = __skb_dequeue(&tx_ind_q))) {\n\t\tath10k_htt_rx_tx_fetch_ind(ar, skb);\n\t\tdev_kfree_skb_any(skb);\n\t}\n\nexit:\n\tath10k_htt_rx_msdu_buff_replenish(htt);\n\t \n\tdone = resched_napi ? budget : quota;\n\n\treturn done;\n}\nEXPORT_SYMBOL(ath10k_htt_txrx_compl_task);\n\nstatic const struct ath10k_htt_rx_ops htt_rx_ops_32 = {\n\t.htt_get_rx_ring_size = ath10k_htt_get_rx_ring_size_32,\n\t.htt_config_paddrs_ring = ath10k_htt_config_paddrs_ring_32,\n\t.htt_set_paddrs_ring = ath10k_htt_set_paddrs_ring_32,\n\t.htt_get_vaddr_ring = ath10k_htt_get_vaddr_ring_32,\n\t.htt_reset_paddrs_ring = ath10k_htt_reset_paddrs_ring_32,\n};\n\nstatic const struct ath10k_htt_rx_ops htt_rx_ops_64 = {\n\t.htt_get_rx_ring_size = ath10k_htt_get_rx_ring_size_64,\n\t.htt_config_paddrs_ring = ath10k_htt_config_paddrs_ring_64,\n\t.htt_set_paddrs_ring = ath10k_htt_set_paddrs_ring_64,\n\t.htt_get_vaddr_ring = ath10k_htt_get_vaddr_ring_64,\n\t.htt_reset_paddrs_ring = ath10k_htt_reset_paddrs_ring_64,\n};\n\nstatic const struct ath10k_htt_rx_ops htt_rx_ops_hl = {\n\t.htt_rx_proc_rx_frag_ind = ath10k_htt_rx_proc_rx_frag_ind_hl,\n};\n\nvoid ath10k_htt_set_rx_ops(struct ath10k_htt *htt)\n{\n\tstruct ath10k *ar = htt->ar;\n\n\tif (ar->bus_param.dev_type == ATH10K_DEV_TYPE_HL)\n\t\thtt->rx_ops = &htt_rx_ops_hl;\n\telse if (ar->hw_params.target_64bit)\n\t\thtt->rx_ops = &htt_rx_ops_64;\n\telse\n\t\thtt->rx_ops = &htt_rx_ops_32;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}