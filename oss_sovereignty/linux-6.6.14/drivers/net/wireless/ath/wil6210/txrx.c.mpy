{
  "module_name": "txrx.c",
  "hash_id": "5e698b9efd18b9eb57b26e8a82880e2951000a20213289124e1881ef11259d9d",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ath/wil6210/txrx.c",
  "human_readable_source": "\n \n\n#include <linux/etherdevice.h>\n#include <net/ieee80211_radiotap.h>\n#include <linux/if_arp.h>\n#include <linux/moduleparam.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/if_vlan.h>\n#include <net/ipv6.h>\n#include <linux/prefetch.h>\n\n#include \"wil6210.h\"\n#include \"wmi.h\"\n#include \"txrx.h\"\n#include \"trace.h\"\n#include \"txrx_edma.h\"\n\nbool rx_align_2;\nmodule_param(rx_align_2, bool, 0444);\nMODULE_PARM_DESC(rx_align_2, \" align Rx buffers on 4*n+2, default - no\");\n\nbool rx_large_buf;\nmodule_param(rx_large_buf, bool, 0444);\nMODULE_PARM_DESC(rx_large_buf, \" allocate 8KB RX buffers, default - no\");\n\n \nbool drop_if_ring_full;\n\nstatic inline uint wil_rx_snaplen(void)\n{\n\treturn rx_align_2 ? 6 : 0;\n}\n\n \nstatic inline int wil_ring_wmark_low(struct wil_ring *ring)\n{\n\treturn ring->size / 8;\n}\n\n \nstatic inline int wil_ring_wmark_high(struct wil_ring *ring)\n{\n\treturn ring->size / 4;\n}\n\n \nstatic inline int wil_ring_avail_low(struct wil_ring *ring)\n{\n\treturn wil_ring_avail_tx(ring) < wil_ring_wmark_low(ring);\n}\n\n \nstatic inline int wil_ring_avail_high(struct wil_ring *ring)\n{\n\treturn wil_ring_avail_tx(ring) > wil_ring_wmark_high(ring);\n}\n\n \nbool wil_is_tx_idle(struct wil6210_priv *wil)\n{\n\tint i;\n\tunsigned long data_comp_to;\n\tint min_ring_id = wil_get_min_tx_ring_id(wil);\n\n\tfor (i = min_ring_id; i < WIL6210_MAX_TX_RINGS; i++) {\n\t\tstruct wil_ring *vring = &wil->ring_tx[i];\n\t\tint vring_index = vring - wil->ring_tx;\n\t\tstruct wil_ring_tx_data *txdata =\n\t\t\t&wil->ring_tx_data[vring_index];\n\n\t\tspin_lock(&txdata->lock);\n\n\t\tif (!vring->va || !txdata->enabled) {\n\t\t\tspin_unlock(&txdata->lock);\n\t\t\tcontinue;\n\t\t}\n\n\t\tdata_comp_to = jiffies + msecs_to_jiffies(\n\t\t\t\t\tWIL_DATA_COMPLETION_TO_MS);\n\t\tif (test_bit(wil_status_napi_en, wil->status)) {\n\t\t\twhile (!wil_ring_is_empty(vring)) {\n\t\t\t\tif (time_after(jiffies, data_comp_to)) {\n\t\t\t\t\twil_dbg_pm(wil,\n\t\t\t\t\t\t   \"TO waiting for idle tx\\n\");\n\t\t\t\t\tspin_unlock(&txdata->lock);\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t\twil_dbg_ratelimited(wil,\n\t\t\t\t\t\t    \"tx vring is not empty -> NAPI\\n\");\n\t\t\t\tspin_unlock(&txdata->lock);\n\t\t\t\tnapi_synchronize(&wil->napi_tx);\n\t\t\t\tmsleep(20);\n\t\t\t\tspin_lock(&txdata->lock);\n\t\t\t\tif (!vring->va || !txdata->enabled)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tspin_unlock(&txdata->lock);\n\t}\n\n\treturn true;\n}\n\nstatic int wil_vring_alloc(struct wil6210_priv *wil, struct wil_ring *vring)\n{\n\tstruct device *dev = wil_to_dev(wil);\n\tsize_t sz = vring->size * sizeof(vring->va[0]);\n\tuint i;\n\n\twil_dbg_misc(wil, \"vring_alloc:\\n\");\n\n\tBUILD_BUG_ON(sizeof(vring->va[0]) != 32);\n\n\tvring->swhead = 0;\n\tvring->swtail = 0;\n\tvring->ctx = kcalloc(vring->size, sizeof(vring->ctx[0]), GFP_KERNEL);\n\tif (!vring->ctx) {\n\t\tvring->va = NULL;\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\tif (wil->dma_addr_size > 32)\n\t\tdma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));\n\n\tvring->va = dma_alloc_coherent(dev, sz, &vring->pa, GFP_KERNEL);\n\tif (!vring->va) {\n\t\tkfree(vring->ctx);\n\t\tvring->ctx = NULL;\n\t\treturn -ENOMEM;\n\t}\n\n\tif (wil->dma_addr_size > 32)\n\t\tdma_set_mask_and_coherent(dev,\n\t\t\t\t\t  DMA_BIT_MASK(wil->dma_addr_size));\n\n\t \n\tfor (i = 0; i < vring->size; i++) {\n\t\tvolatile struct vring_tx_desc *_d =\n\t\t\t&vring->va[i].tx.legacy;\n\n\t\t_d->dma.status = TX_DMA_STATUS_DU;\n\t}\n\n\twil_dbg_misc(wil, \"vring[%d] 0x%p:%pad 0x%p\\n\", vring->size,\n\t\t     vring->va, &vring->pa, vring->ctx);\n\n\treturn 0;\n}\n\nstatic void wil_txdesc_unmap(struct device *dev, union wil_tx_desc *desc,\n\t\t\t     struct wil_ctx *ctx)\n{\n\tstruct vring_tx_desc *d = &desc->legacy;\n\tdma_addr_t pa = wil_desc_addr(&d->dma.addr);\n\tu16 dmalen = le16_to_cpu(d->dma.length);\n\n\tswitch (ctx->mapped_as) {\n\tcase wil_mapped_as_single:\n\t\tdma_unmap_single(dev, pa, dmalen, DMA_TO_DEVICE);\n\t\tbreak;\n\tcase wil_mapped_as_page:\n\t\tdma_unmap_page(dev, pa, dmalen, DMA_TO_DEVICE);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void wil_vring_free(struct wil6210_priv *wil, struct wil_ring *vring)\n{\n\tstruct device *dev = wil_to_dev(wil);\n\tsize_t sz = vring->size * sizeof(vring->va[0]);\n\n\tlockdep_assert_held(&wil->mutex);\n\tif (!vring->is_rx) {\n\t\tint vring_index = vring - wil->ring_tx;\n\n\t\twil_dbg_misc(wil, \"free Tx vring %d [%d] 0x%p:%pad 0x%p\\n\",\n\t\t\t     vring_index, vring->size, vring->va,\n\t\t\t     &vring->pa, vring->ctx);\n\t} else {\n\t\twil_dbg_misc(wil, \"free Rx vring [%d] 0x%p:%pad 0x%p\\n\",\n\t\t\t     vring->size, vring->va,\n\t\t\t     &vring->pa, vring->ctx);\n\t}\n\n\twhile (!wil_ring_is_empty(vring)) {\n\t\tdma_addr_t pa;\n\t\tu16 dmalen;\n\t\tstruct wil_ctx *ctx;\n\n\t\tif (!vring->is_rx) {\n\t\t\tstruct vring_tx_desc dd, *d = &dd;\n\t\t\tvolatile struct vring_tx_desc *_d =\n\t\t\t\t\t&vring->va[vring->swtail].tx.legacy;\n\n\t\t\tctx = &vring->ctx[vring->swtail];\n\t\t\tif (!ctx) {\n\t\t\t\twil_dbg_txrx(wil,\n\t\t\t\t\t     \"ctx(%d) was already completed\\n\",\n\t\t\t\t\t     vring->swtail);\n\t\t\t\tvring->swtail = wil_ring_next_tail(vring);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t*d = *_d;\n\t\t\twil_txdesc_unmap(dev, (union wil_tx_desc *)d, ctx);\n\t\t\tif (ctx->skb)\n\t\t\t\tdev_kfree_skb_any(ctx->skb);\n\t\t\tvring->swtail = wil_ring_next_tail(vring);\n\t\t} else {  \n\t\t\tstruct vring_rx_desc dd, *d = &dd;\n\t\t\tvolatile struct vring_rx_desc *_d =\n\t\t\t\t&vring->va[vring->swhead].rx.legacy;\n\n\t\t\tctx = &vring->ctx[vring->swhead];\n\t\t\t*d = *_d;\n\t\t\tpa = wil_desc_addr(&d->dma.addr);\n\t\t\tdmalen = le16_to_cpu(d->dma.length);\n\t\t\tdma_unmap_single(dev, pa, dmalen, DMA_FROM_DEVICE);\n\t\t\tkfree_skb(ctx->skb);\n\t\t\twil_ring_advance_head(vring, 1);\n\t\t}\n\t}\n\tdma_free_coherent(dev, sz, (void *)vring->va, vring->pa);\n\tkfree(vring->ctx);\n\tvring->pa = 0;\n\tvring->va = NULL;\n\tvring->ctx = NULL;\n}\n\n \nstatic int wil_vring_alloc_skb(struct wil6210_priv *wil, struct wil_ring *vring,\n\t\t\t       u32 i, int headroom)\n{\n\tstruct device *dev = wil_to_dev(wil);\n\tunsigned int sz = wil->rx_buf_len + ETH_HLEN + wil_rx_snaplen();\n\tstruct vring_rx_desc dd, *d = &dd;\n\tvolatile struct vring_rx_desc *_d = &vring->va[i].rx.legacy;\n\tdma_addr_t pa;\n\tstruct sk_buff *skb = dev_alloc_skb(sz + headroom);\n\n\tif (unlikely(!skb))\n\t\treturn -ENOMEM;\n\n\tskb_reserve(skb, headroom);\n\tskb_put(skb, sz);\n\n\t \n\tskb->ip_summed = CHECKSUM_NONE;\n\n\tpa = dma_map_single(dev, skb->data, skb->len, DMA_FROM_DEVICE);\n\tif (unlikely(dma_mapping_error(dev, pa))) {\n\t\tkfree_skb(skb);\n\t\treturn -ENOMEM;\n\t}\n\n\td->dma.d0 = RX_DMA_D0_CMD_DMA_RT | RX_DMA_D0_CMD_DMA_IT;\n\twil_desc_addr_set(&d->dma.addr, pa);\n\t \n\t \n\t \n\td->dma.status = 0;  \n\td->dma.length = cpu_to_le16(sz);\n\t*_d = *d;\n\tvring->ctx[i].skb = skb;\n\n\treturn 0;\n}\n\n \nstatic void wil_rx_add_radiotap_header(struct wil6210_priv *wil,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct wil6210_rtap {\n\t\tstruct ieee80211_radiotap_header rthdr;\n\t\t \n\t\t \n\t\tu8 flags;\n\t\t \n\t\t__le16 chnl_freq __aligned(2);\n\t\t__le16 chnl_flags;\n\t\t \n\t\tu8 mcs_present;\n\t\tu8 mcs_flags;\n\t\tu8 mcs_index;\n\t} __packed;\n\tstruct vring_rx_desc *d = wil_skb_rxdesc(skb);\n\tstruct wil6210_rtap *rtap;\n\tint rtap_len = sizeof(struct wil6210_rtap);\n\tstruct ieee80211_channel *ch = wil->monitor_chandef.chan;\n\n\tif (skb_headroom(skb) < rtap_len &&\n\t    pskb_expand_head(skb, rtap_len, 0, GFP_ATOMIC)) {\n\t\twil_err(wil, \"Unable to expand headroom to %d\\n\", rtap_len);\n\t\treturn;\n\t}\n\n\trtap = skb_push(skb, rtap_len);\n\tmemset(rtap, 0, rtap_len);\n\n\trtap->rthdr.it_version = PKTHDR_RADIOTAP_VERSION;\n\trtap->rthdr.it_len = cpu_to_le16(rtap_len);\n\trtap->rthdr.it_present = cpu_to_le32((1 << IEEE80211_RADIOTAP_FLAGS) |\n\t\t\t(1 << IEEE80211_RADIOTAP_CHANNEL) |\n\t\t\t(1 << IEEE80211_RADIOTAP_MCS));\n\tif (d->dma.status & RX_DMA_STATUS_ERROR)\n\t\trtap->flags |= IEEE80211_RADIOTAP_F_BADFCS;\n\n\trtap->chnl_freq = cpu_to_le16(ch ? ch->center_freq : 58320);\n\trtap->chnl_flags = cpu_to_le16(0);\n\n\trtap->mcs_present = IEEE80211_RADIOTAP_MCS_HAVE_MCS;\n\trtap->mcs_flags = 0;\n\trtap->mcs_index = wil_rxdesc_mcs(d);\n}\n\nstatic bool wil_is_rx_idle(struct wil6210_priv *wil)\n{\n\tstruct vring_rx_desc *_d;\n\tstruct wil_ring *ring = &wil->ring_rx;\n\n\t_d = (struct vring_rx_desc *)&ring->va[ring->swhead].rx.legacy;\n\tif (_d->dma.status & RX_DMA_STATUS_DU)\n\t\treturn false;\n\n\treturn true;\n}\n\nstatic int wil_rx_get_cid_by_skb(struct wil6210_priv *wil, struct sk_buff *skb)\n{\n\tstruct vring_rx_desc *d = wil_skb_rxdesc(skb);\n\tint mid = wil_rxdesc_mid(d);\n\tstruct wil6210_vif *vif = wil->vifs[mid];\n\t \n\tint cid = wil_rxdesc_cid(d);\n\tunsigned int snaplen = wil_rx_snaplen();\n\tstruct ieee80211_hdr_3addr *hdr;\n\tint i;\n\tunsigned char *ta;\n\tu8 ftype;\n\n\t \n\tif (vif->wdev.iftype == NL80211_IFTYPE_MONITOR)\n\t\treturn cid;\n\n\tftype = wil_rxdesc_ftype(d) << 2;\n\tif (likely(ftype == IEEE80211_FTYPE_DATA)) {\n\t\tif (unlikely(skb->len < ETH_HLEN + snaplen)) {\n\t\t\twil_err_ratelimited(wil,\n\t\t\t\t\t    \"Short data frame, len = %d\\n\",\n\t\t\t\t\t    skb->len);\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tta = wil_skb_get_sa(skb);\n\t} else {\n\t\tif (unlikely(skb->len < sizeof(struct ieee80211_hdr_3addr))) {\n\t\t\twil_err_ratelimited(wil, \"Short frame, len = %d\\n\",\n\t\t\t\t\t    skb->len);\n\t\t\treturn -ENOENT;\n\t\t}\n\t\thdr = (void *)skb->data;\n\t\tta = hdr->addr2;\n\t}\n\n\tif (wil->max_assoc_sta <= WIL6210_RX_DESC_MAX_CID)\n\t\treturn cid;\n\n\t \n\tif (vif->wdev.iftype != NL80211_IFTYPE_P2P_GO &&\n\t    vif->wdev.iftype != NL80211_IFTYPE_AP)\n\t\treturn cid;\n\n\t \n\tfor (i = cid; i < wil->max_assoc_sta; i += WIL6210_RX_DESC_MAX_CID) {\n\t\tif (wil->sta[i].status != wil_sta_unused &&\n\t\t    ether_addr_equal(wil->sta[i].addr, ta)) {\n\t\t\tcid = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (i >= wil->max_assoc_sta) {\n\t\twil_err_ratelimited(wil, \"Could not find cid for frame with transmit addr = %pM, iftype = %d, frametype = %d, len = %d\\n\",\n\t\t\t\t    ta, vif->wdev.iftype, ftype, skb->len);\n\t\tcid = -ENOENT;\n\t}\n\n\treturn cid;\n}\n\n \nstatic struct sk_buff *wil_vring_reap_rx(struct wil6210_priv *wil,\n\t\t\t\t\t struct wil_ring *vring)\n{\n\tstruct device *dev = wil_to_dev(wil);\n\tstruct wil6210_vif *vif;\n\tstruct net_device *ndev;\n\tvolatile struct vring_rx_desc *_d;\n\tstruct vring_rx_desc *d;\n\tstruct sk_buff *skb;\n\tdma_addr_t pa;\n\tunsigned int snaplen = wil_rx_snaplen();\n\tunsigned int sz = wil->rx_buf_len + ETH_HLEN + snaplen;\n\tu16 dmalen;\n\tu8 ftype;\n\tint cid, mid;\n\tint i;\n\tstruct wil_net_stats *stats;\n\n\tBUILD_BUG_ON(sizeof(struct skb_rx_info) > sizeof(skb->cb));\n\nagain:\n\tif (unlikely(wil_ring_is_empty(vring)))\n\t\treturn NULL;\n\n\ti = (int)vring->swhead;\n\t_d = &vring->va[i].rx.legacy;\n\tif (unlikely(!(_d->dma.status & RX_DMA_STATUS_DU))) {\n\t\t \n\t\treturn NULL;\n\t}\n\n\tskb = vring->ctx[i].skb;\n\tvring->ctx[i].skb = NULL;\n\twil_ring_advance_head(vring, 1);\n\tif (!skb) {\n\t\twil_err(wil, \"No Rx skb at [%d]\\n\", i);\n\t\tgoto again;\n\t}\n\td = wil_skb_rxdesc(skb);\n\t*d = *_d;\n\tpa = wil_desc_addr(&d->dma.addr);\n\n\tdma_unmap_single(dev, pa, sz, DMA_FROM_DEVICE);\n\tdmalen = le16_to_cpu(d->dma.length);\n\n\ttrace_wil6210_rx(i, d);\n\twil_dbg_txrx(wil, \"Rx[%3d] : %d bytes\\n\", i, dmalen);\n\twil_hex_dump_txrx(\"RxD \", DUMP_PREFIX_NONE, 32, 4,\n\t\t\t  (const void *)d, sizeof(*d), false);\n\n\tmid = wil_rxdesc_mid(d);\n\tvif = wil->vifs[mid];\n\n\tif (unlikely(!vif)) {\n\t\twil_dbg_txrx(wil, \"skipped RX descriptor with invalid mid %d\",\n\t\t\t     mid);\n\t\tkfree_skb(skb);\n\t\tgoto again;\n\t}\n\tndev = vif_to_ndev(vif);\n\tif (unlikely(dmalen > sz)) {\n\t\twil_err_ratelimited(wil, \"Rx size too large: %d bytes!\\n\",\n\t\t\t\t    dmalen);\n\t\tkfree_skb(skb);\n\t\tgoto again;\n\t}\n\tskb_trim(skb, dmalen);\n\n\tprefetch(skb->data);\n\n\twil_hex_dump_txrx(\"Rx \", DUMP_PREFIX_OFFSET, 16, 1,\n\t\t\t  skb->data, skb_headlen(skb), false);\n\n\tcid = wil_rx_get_cid_by_skb(wil, skb);\n\tif (cid == -ENOENT) {\n\t\tkfree_skb(skb);\n\t\tgoto again;\n\t}\n\twil_skb_set_cid(skb, (u8)cid);\n\tstats = &wil->sta[cid].stats;\n\n\tstats->last_mcs_rx = wil_rxdesc_mcs(d);\n\tif (stats->last_mcs_rx < ARRAY_SIZE(stats->rx_per_mcs))\n\t\tstats->rx_per_mcs[stats->last_mcs_rx]++;\n\n\t \n\tif (ndev->type == ARPHRD_IEEE80211_RADIOTAP)\n\t\twil_rx_add_radiotap_header(wil, skb);\n\n\t \n\tif (ndev->type != ARPHRD_ETHER)\n\t\treturn skb;\n\t \n\tftype = wil_rxdesc_ftype(d) << 2;\n\tif (unlikely(ftype != IEEE80211_FTYPE_DATA)) {\n\t\tu8 fc1 = wil_rxdesc_fc1(d);\n\t\tint tid = wil_rxdesc_tid(d);\n\t\tu16 seq = wil_rxdesc_seq(d);\n\n\t\twil_dbg_txrx(wil,\n\t\t\t     \"Non-data frame FC[7:0] 0x%02x MID %d CID %d TID %d Seq 0x%03x\\n\",\n\t\t\t     fc1, mid, cid, tid, seq);\n\t\tstats->rx_non_data_frame++;\n\t\tif (wil_is_back_req(fc1)) {\n\t\t\twil_dbg_txrx(wil,\n\t\t\t\t     \"BAR: MID %d CID %d TID %d Seq 0x%03x\\n\",\n\t\t\t\t     mid, cid, tid, seq);\n\t\t\twil_rx_bar(wil, vif, cid, tid, seq);\n\t\t} else {\n\t\t\t \n\t\t\twil_dbg_txrx(wil,\n\t\t\t\t     \"Unhandled non-data frame FC[7:0] 0x%02x MID %d CID %d TID %d Seq 0x%03x\\n\",\n\t\t\t\t     fc1, mid, cid, tid, seq);\n\t\t\twil_hex_dump_txrx(\"RxD \", DUMP_PREFIX_NONE, 32, 4,\n\t\t\t\t\t  (const void *)d, sizeof(*d), false);\n\t\t\twil_hex_dump_txrx(\"Rx \", DUMP_PREFIX_OFFSET, 16, 1,\n\t\t\t\t\t  skb->data, skb_headlen(skb), false);\n\t\t}\n\t\tkfree_skb(skb);\n\t\tgoto again;\n\t}\n\n\t \n\tif (likely(d->dma.status & RX_DMA_STATUS_L4I)) {\n\t\t \n\t\tif (likely((d->dma.error & RX_DMA_ERROR_L4_ERR) == 0))\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\t \n\t\telse\n\t\t\tstats->rx_csum_err++;\n\t}\n\n\tif (snaplen) {\n\t\t \n\t\tmemmove(skb->data + snaplen, skb->data, 2 * ETH_ALEN);\n\t\tskb_pull(skb, snaplen);\n\t}\n\n\treturn skb;\n}\n\n \nstatic int wil_rx_refill(struct wil6210_priv *wil, int count)\n{\n\tstruct net_device *ndev = wil->main_ndev;\n\tstruct wil_ring *v = &wil->ring_rx;\n\tu32 next_tail;\n\tint rc = 0;\n\tint headroom = ndev->type == ARPHRD_IEEE80211_RADIOTAP ?\n\t\t\tWIL6210_RTAP_SIZE : 0;\n\n\tfor (; next_tail = wil_ring_next_tail(v),\n\t     (next_tail != v->swhead) && (count-- > 0);\n\t     v->swtail = next_tail) {\n\t\trc = wil_vring_alloc_skb(wil, v, v->swtail, headroom);\n\t\tif (unlikely(rc)) {\n\t\t\twil_err_ratelimited(wil, \"Error %d in rx refill[%d]\\n\",\n\t\t\t\t\t    rc, v->swtail);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\twmb();\n\n\twil_w(wil, v->hwtail, v->swtail);\n\n\treturn rc;\n}\n\n \nint reverse_memcmp(const void *cs, const void *ct, size_t count)\n{\n\tconst unsigned char *su1, *su2;\n\tint res = 0;\n\n\tfor (su1 = cs + count - 1, su2 = ct + count - 1; count > 0;\n\t     --su1, --su2, count--) {\n\t\tres = *su1 - *su2;\n\t\tif (res)\n\t\t\tbreak;\n\t}\n\treturn res;\n}\n\nstatic int wil_rx_crypto_check(struct wil6210_priv *wil, struct sk_buff *skb)\n{\n\tstruct vring_rx_desc *d = wil_skb_rxdesc(skb);\n\tint cid = wil_skb_get_cid(skb);\n\tint tid = wil_rxdesc_tid(d);\n\tint key_id = wil_rxdesc_key_id(d);\n\tint mc = wil_rxdesc_mcast(d);\n\tstruct wil_sta_info *s = &wil->sta[cid];\n\tstruct wil_tid_crypto_rx *c = mc ? &s->group_crypto_rx :\n\t\t\t\t      &s->tid_crypto_rx[tid];\n\tstruct wil_tid_crypto_rx_single *cc = &c->key_id[key_id];\n\tconst u8 *pn = (u8 *)&d->mac.pn;\n\n\tif (!cc->key_set) {\n\t\twil_err_ratelimited(wil,\n\t\t\t\t    \"Key missing. CID %d TID %d MCast %d KEY_ID %d\\n\",\n\t\t\t\t    cid, tid, mc, key_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (reverse_memcmp(pn, cc->pn, IEEE80211_GCMP_PN_LEN) <= 0) {\n\t\twil_err_ratelimited(wil,\n\t\t\t\t    \"Replay attack. CID %d TID %d MCast %d KEY_ID %d PN %6phN last %6phN\\n\",\n\t\t\t\t    cid, tid, mc, key_id, pn, cc->pn);\n\t\treturn -EINVAL;\n\t}\n\tmemcpy(cc->pn, pn, IEEE80211_GCMP_PN_LEN);\n\n\treturn 0;\n}\n\nstatic int wil_rx_error_check(struct wil6210_priv *wil, struct sk_buff *skb,\n\t\t\t      struct wil_net_stats *stats)\n{\n\tstruct vring_rx_desc *d = wil_skb_rxdesc(skb);\n\n\tif ((d->dma.status & RX_DMA_STATUS_ERROR) &&\n\t    (d->dma.error & RX_DMA_ERROR_MIC)) {\n\t\tstats->rx_mic_error++;\n\t\twil_dbg_txrx(wil, \"MIC error, dropping packet\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nstatic void wil_get_netif_rx_params(struct sk_buff *skb, int *cid,\n\t\t\t\t    int *security)\n{\n\tstruct vring_rx_desc *d = wil_skb_rxdesc(skb);\n\n\t*cid = wil_skb_get_cid(skb);\n\t*security = wil_rxdesc_security(d);\n}\n\n \nstatic struct wil_eapol_key *wil_is_ptk_eapol_key(struct wil6210_priv *wil,\n\t\t\t\t\t\t  struct sk_buff *skb)\n{\n\tu8 *buf;\n\tconst struct wil_1x_hdr *hdr;\n\tstruct wil_eapol_key *key;\n\tu16 key_info;\n\tint len = skb->len;\n\n\tif (!skb_mac_header_was_set(skb)) {\n\t\twil_err(wil, \"mac header was not set\\n\");\n\t\treturn NULL;\n\t}\n\n\tlen -= skb_mac_offset(skb);\n\n\tif (len < sizeof(struct ethhdr) + sizeof(struct wil_1x_hdr) +\n\t    sizeof(struct wil_eapol_key))\n\t\treturn NULL;\n\n\tbuf = skb_mac_header(skb) + sizeof(struct ethhdr);\n\n\thdr = (const struct wil_1x_hdr *)buf;\n\tif (hdr->type != WIL_1X_TYPE_EAPOL_KEY)\n\t\treturn NULL;\n\n\tkey = (struct wil_eapol_key *)(buf + sizeof(struct wil_1x_hdr));\n\tif (key->type != WIL_EAPOL_KEY_TYPE_WPA &&\n\t    key->type != WIL_EAPOL_KEY_TYPE_RSN)\n\t\treturn NULL;\n\n\tkey_info = be16_to_cpu(key->key_info);\n\tif (!(key_info & WIL_KEY_INFO_KEY_TYPE))  \n\t\treturn NULL;\n\n\treturn key;\n}\n\nstatic bool wil_skb_is_eap_3(struct wil6210_priv *wil, struct sk_buff *skb)\n{\n\tstruct wil_eapol_key *key;\n\tu16 key_info;\n\n\tkey = wil_is_ptk_eapol_key(wil, skb);\n\tif (!key)\n\t\treturn false;\n\n\tkey_info = be16_to_cpu(key->key_info);\n\tif (key_info & (WIL_KEY_INFO_MIC |\n\t\t\tWIL_KEY_INFO_ENCR_KEY_DATA)) {\n\t\t \n\t\twil_dbg_misc(wil, \"EAPOL key message 3\\n\");\n\t\treturn true;\n\t}\n\t \n\twil_dbg_misc(wil, \"EAPOL key message 1\\n\");\n\n\treturn false;\n}\n\nstatic bool wil_skb_is_eap_4(struct wil6210_priv *wil, struct sk_buff *skb)\n{\n\tstruct wil_eapol_key *key;\n\tu32 *nonce, i;\n\n\tkey = wil_is_ptk_eapol_key(wil, skb);\n\tif (!key)\n\t\treturn false;\n\n\tnonce = (u32 *)key->key_nonce;\n\tfor (i = 0; i < WIL_EAP_NONCE_LEN / sizeof(u32); i++, nonce++) {\n\t\tif (*nonce != 0) {\n\t\t\t \n\t\t\twil_dbg_misc(wil, \"EAPOL key message 2\\n\");\n\t\t\treturn false;\n\t\t}\n\t}\n\twil_dbg_misc(wil, \"EAPOL key message 4\\n\");\n\n\treturn true;\n}\n\nvoid wil_enable_tx_key_worker(struct work_struct *work)\n{\n\tstruct wil6210_vif *vif = container_of(work,\n\t\t\tstruct wil6210_vif, enable_tx_key_worker);\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tint rc, cid;\n\n\trtnl_lock();\n\tif (vif->ptk_rekey_state != WIL_REKEY_WAIT_M4_SENT) {\n\t\twil_dbg_misc(wil, \"Invalid rekey state = %d\\n\",\n\t\t\t     vif->ptk_rekey_state);\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n\n\tcid =  wil_find_cid_by_idx(wil, vif->mid, 0);\n\tif (!wil_cid_valid(wil, cid)) {\n\t\twil_err(wil, \"Invalid cid = %d\\n\", cid);\n\t\trtnl_unlock();\n\t\treturn;\n\t}\n\n\twil_dbg_misc(wil, \"Apply PTK key after eapol was sent out\\n\");\n\trc = wmi_add_cipher_key(vif, 0, wil->sta[cid].addr, 0, NULL,\n\t\t\t\tWMI_KEY_USE_APPLY_PTK);\n\n\tvif->ptk_rekey_state = WIL_REKEY_IDLE;\n\trtnl_unlock();\n\n\tif (rc)\n\t\twil_err(wil, \"Apply PTK key failed %d\\n\", rc);\n}\n\nvoid wil_tx_complete_handle_eapol(struct wil6210_vif *vif, struct sk_buff *skb)\n{\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tstruct wireless_dev *wdev = vif_to_wdev(vif);\n\tbool q = false;\n\n\tif (wdev->iftype != NL80211_IFTYPE_STATION ||\n\t    !test_bit(WMI_FW_CAPABILITY_SPLIT_REKEY, wil->fw_capabilities))\n\t\treturn;\n\n\t \n\tif (!wil_skb_is_eap_4(wil, skb))\n\t\treturn;\n\n\tspin_lock_bh(&wil->eap_lock);\n\tswitch (vif->ptk_rekey_state) {\n\tcase WIL_REKEY_IDLE:\n\t\t \n\t\tbreak;\n\tcase WIL_REKEY_M3_RECEIVED:\n\t\tvif->ptk_rekey_state = WIL_REKEY_IDLE;\n\t\tbreak;\n\tcase WIL_REKEY_WAIT_M4_SENT:\n\t\tq = true;\n\t\tbreak;\n\tdefault:\n\t\twil_err(wil, \"Unknown rekey state = %d\",\n\t\t\tvif->ptk_rekey_state);\n\t}\n\tspin_unlock_bh(&wil->eap_lock);\n\n\tif (q) {\n\t\tq = queue_work(wil->wmi_wq, &vif->enable_tx_key_worker);\n\t\twil_dbg_misc(wil, \"queue_work of enable_tx_key_worker -> %d\\n\",\n\t\t\t     q);\n\t}\n}\n\nstatic void wil_rx_handle_eapol(struct wil6210_vif *vif, struct sk_buff *skb)\n{\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tstruct wireless_dev *wdev = vif_to_wdev(vif);\n\n\tif (wdev->iftype != NL80211_IFTYPE_STATION ||\n\t    !test_bit(WMI_FW_CAPABILITY_SPLIT_REKEY, wil->fw_capabilities))\n\t\treturn;\n\n\t \n\tif (!wil_skb_is_eap_3(wil, skb))\n\t\treturn;\n\n\tif (vif->ptk_rekey_state == WIL_REKEY_IDLE)\n\t\tvif->ptk_rekey_state = WIL_REKEY_M3_RECEIVED;\n}\n\n \nvoid wil_netif_rx(struct sk_buff *skb, struct net_device *ndev, int cid,\n\t\t  struct wil_net_stats *stats, bool gro)\n{\n\tstruct wil6210_vif *vif = ndev_to_vif(ndev);\n\tstruct wil6210_priv *wil = ndev_to_wil(ndev);\n\tstruct wireless_dev *wdev = vif_to_wdev(vif);\n\tunsigned int len = skb->len;\n\tu8 *sa, *da = wil_skb_get_da(skb);\n\t \n\tint mcast = is_multicast_ether_addr(da);\n\tstruct sk_buff *xmit_skb = NULL;\n\n\tif (wdev->iftype == NL80211_IFTYPE_STATION) {\n\t\tsa = wil_skb_get_sa(skb);\n\t\tif (mcast && ether_addr_equal(sa, ndev->dev_addr)) {\n\t\t\t \n\t\t\tdev_kfree_skb(skb);\n\t\t\tndev->stats.rx_dropped++;\n\t\t\tstats->rx_dropped++;\n\t\t\twil_dbg_txrx(wil, \"Rx drop %d bytes\\n\", len);\n\t\t\treturn;\n\t\t}\n\t} else if (wdev->iftype == NL80211_IFTYPE_AP && !vif->ap_isolate) {\n\t\tif (mcast) {\n\t\t\t \n\t\t\txmit_skb = skb_copy(skb, GFP_ATOMIC);\n\t\t} else {\n\t\t\tint xmit_cid = wil_find_cid(wil, vif->mid, da);\n\n\t\t\tif (xmit_cid >= 0) {\n\t\t\t\t \n\t\t\t\txmit_skb = skb;\n\t\t\t\tskb = NULL;\n\t\t\t}\n\t\t}\n\t}\n\tif (xmit_skb) {\n\t\t \n\t\txmit_skb->dev = ndev;\n\t\txmit_skb->priority += 256;\n\t\txmit_skb->protocol = htons(ETH_P_802_3);\n\t\tskb_reset_network_header(xmit_skb);\n\t\tskb_reset_mac_header(xmit_skb);\n\t\twil_dbg_txrx(wil, \"Rx -> Tx %d bytes\\n\", len);\n\t\tdev_queue_xmit(xmit_skb);\n\t}\n\n\tif (skb) {  \n\t\tskb->protocol = eth_type_trans(skb, ndev);\n\t\tskb->dev = ndev;\n\n\t\tif (skb->protocol == cpu_to_be16(ETH_P_PAE))\n\t\t\twil_rx_handle_eapol(vif, skb);\n\n\t\tif (gro)\n\t\t\tnapi_gro_receive(&wil->napi_rx, skb);\n\t\telse\n\t\t\tnetif_rx(skb);\n\t}\n\tndev->stats.rx_packets++;\n\tstats->rx_packets++;\n\tndev->stats.rx_bytes += len;\n\tstats->rx_bytes += len;\n\tif (mcast)\n\t\tndev->stats.multicast++;\n}\n\nvoid wil_netif_rx_any(struct sk_buff *skb, struct net_device *ndev)\n{\n\tint cid, security;\n\tstruct wil6210_priv *wil = ndev_to_wil(ndev);\n\tstruct wil_net_stats *stats;\n\n\twil->txrx_ops.get_netif_rx_params(skb, &cid, &security);\n\n\tstats = &wil->sta[cid].stats;\n\n\tskb_orphan(skb);\n\n\tif (security && (wil->txrx_ops.rx_crypto_check(wil, skb) != 0)) {\n\t\twil_dbg_txrx(wil, \"Rx drop %d bytes\\n\", skb->len);\n\t\tdev_kfree_skb(skb);\n\t\tndev->stats.rx_dropped++;\n\t\tstats->rx_replay++;\n\t\tstats->rx_dropped++;\n\t\treturn;\n\t}\n\n\t \n\tif (unlikely(wil->txrx_ops.rx_error_check(wil, skb, stats))) {\n\t\tdev_kfree_skb(skb);\n\t\treturn;\n\t}\n\n\twil_netif_rx(skb, ndev, cid, stats, true);\n}\n\n \nvoid wil_rx_handle(struct wil6210_priv *wil, int *quota)\n{\n\tstruct net_device *ndev = wil->main_ndev;\n\tstruct wireless_dev *wdev = ndev->ieee80211_ptr;\n\tstruct wil_ring *v = &wil->ring_rx;\n\tstruct sk_buff *skb;\n\n\tif (unlikely(!v->va)) {\n\t\twil_err(wil, \"Rx IRQ while Rx not yet initialized\\n\");\n\t\treturn;\n\t}\n\twil_dbg_txrx(wil, \"rx_handle\\n\");\n\twhile ((*quota > 0) && (NULL != (skb = wil_vring_reap_rx(wil, v)))) {\n\t\t(*quota)--;\n\n\t\t \n\t\tif (wdev->iftype == NL80211_IFTYPE_MONITOR) {\n\t\t\tskb->dev = ndev;\n\t\t\tskb_reset_mac_header(skb);\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\t\tskb->pkt_type = PACKET_OTHERHOST;\n\t\t\tskb->protocol = htons(ETH_P_802_2);\n\t\t\twil_netif_rx_any(skb, ndev);\n\t\t} else {\n\t\t\twil_rx_reorder(wil, skb);\n\t\t}\n\t}\n\twil_rx_refill(wil, v->size);\n}\n\nstatic void wil_rx_buf_len_init(struct wil6210_priv *wil)\n{\n\twil->rx_buf_len = rx_large_buf ?\n\t\tWIL_MAX_ETH_MTU : TXRX_BUF_LEN_DEFAULT - WIL_MAX_MPDU_OVERHEAD;\n\tif (mtu_max > wil->rx_buf_len) {\n\t\t \n\t\twil_info(wil, \"Override RX buffer to mtu_max(%d)\\n\", mtu_max);\n\t\twil->rx_buf_len = mtu_max;\n\t}\n}\n\nstatic int wil_rx_init(struct wil6210_priv *wil, uint order)\n{\n\tstruct wil_ring *vring = &wil->ring_rx;\n\tint rc;\n\n\twil_dbg_misc(wil, \"rx_init\\n\");\n\n\tif (vring->va) {\n\t\twil_err(wil, \"Rx ring already allocated\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\twil_rx_buf_len_init(wil);\n\n\tvring->size = 1 << order;\n\tvring->is_rx = true;\n\trc = wil_vring_alloc(wil, vring);\n\tif (rc)\n\t\treturn rc;\n\n\trc = wmi_rx_chain_add(wil, vring);\n\tif (rc)\n\t\tgoto err_free;\n\n\trc = wil_rx_refill(wil, vring->size);\n\tif (rc)\n\t\tgoto err_free;\n\n\treturn 0;\n err_free:\n\twil_vring_free(wil, vring);\n\n\treturn rc;\n}\n\nstatic void wil_rx_fini(struct wil6210_priv *wil)\n{\n\tstruct wil_ring *vring = &wil->ring_rx;\n\n\twil_dbg_misc(wil, \"rx_fini\\n\");\n\n\tif (vring->va)\n\t\twil_vring_free(wil, vring);\n}\n\nstatic int wil_tx_desc_map(union wil_tx_desc *desc, dma_addr_t pa,\n\t\t\t   u32 len, int vring_index)\n{\n\tstruct vring_tx_desc *d = &desc->legacy;\n\n\twil_desc_addr_set(&d->dma.addr, pa);\n\td->dma.ip_length = 0;\n\t \n\td->dma.b11 = 0 ;\n\td->dma.error = 0;\n\td->dma.status = 0;  \n\td->dma.length = cpu_to_le16((u16)len);\n\td->dma.d0 = (vring_index << DMA_CFG_DESC_TX_0_QID_POS);\n\td->mac.d[0] = 0;\n\td->mac.d[1] = 0;\n\td->mac.d[2] = 0;\n\td->mac.ucode_cmd = 0;\n\t \n\td->mac.d[2] = BIT(MAC_CFG_DESC_TX_2_SNAP_HDR_INSERTION_EN_POS) |\n\t\t      (1 << MAC_CFG_DESC_TX_2_L2_TRANSLATION_TYPE_POS);\n\n\treturn 0;\n}\n\nvoid wil_tx_data_init(struct wil_ring_tx_data *txdata)\n{\n\tspin_lock_bh(&txdata->lock);\n\ttxdata->dot1x_open = false;\n\ttxdata->enabled = 0;\n\ttxdata->idle = 0;\n\ttxdata->last_idle = 0;\n\ttxdata->begin = 0;\n\ttxdata->agg_wsize = 0;\n\ttxdata->agg_timeout = 0;\n\ttxdata->agg_amsdu = 0;\n\ttxdata->addba_in_progress = false;\n\ttxdata->mid = U8_MAX;\n\tspin_unlock_bh(&txdata->lock);\n}\n\nstatic int wil_vring_init_tx(struct wil6210_vif *vif, int id, int size,\n\t\t\t     int cid, int tid)\n{\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tint rc;\n\tstruct wmi_vring_cfg_cmd cmd = {\n\t\t.action = cpu_to_le32(WMI_VRING_CMD_ADD),\n\t\t.vring_cfg = {\n\t\t\t.tx_sw_ring = {\n\t\t\t\t.max_mpdu_size =\n\t\t\t\t\tcpu_to_le16(wil_mtu2macbuf(mtu_max)),\n\t\t\t\t.ring_size = cpu_to_le16(size),\n\t\t\t},\n\t\t\t.ringid = id,\n\t\t\t.encap_trans_type = WMI_VRING_ENC_TYPE_802_3,\n\t\t\t.mac_ctrl = 0,\n\t\t\t.to_resolution = 0,\n\t\t\t.agg_max_wsize = 0,\n\t\t\t.schd_params = {\n\t\t\t\t.priority = cpu_to_le16(0),\n\t\t\t\t.timeslot_us = cpu_to_le16(0xfff),\n\t\t\t},\n\t\t},\n\t};\n\tstruct {\n\t\tstruct wmi_cmd_hdr wmi;\n\t\tstruct wmi_vring_cfg_done_event cmd;\n\t} __packed reply = {\n\t\t.cmd = {.status = WMI_FW_STATUS_FAILURE},\n\t};\n\tstruct wil_ring *vring = &wil->ring_tx[id];\n\tstruct wil_ring_tx_data *txdata = &wil->ring_tx_data[id];\n\n\tif (cid >= WIL6210_RX_DESC_MAX_CID) {\n\t\tcmd.vring_cfg.cidxtid = CIDXTID_EXTENDED_CID_TID;\n\t\tcmd.vring_cfg.cid = cid;\n\t\tcmd.vring_cfg.tid = tid;\n\t} else {\n\t\tcmd.vring_cfg.cidxtid = mk_cidxtid(cid, tid);\n\t}\n\n\twil_dbg_misc(wil, \"vring_init_tx: max_mpdu_size %d\\n\",\n\t\t     cmd.vring_cfg.tx_sw_ring.max_mpdu_size);\n\tlockdep_assert_held(&wil->mutex);\n\n\tif (vring->va) {\n\t\twil_err(wil, \"Tx ring [%d] already allocated\\n\", id);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\twil_tx_data_init(txdata);\n\tvring->is_rx = false;\n\tvring->size = size;\n\trc = wil_vring_alloc(wil, vring);\n\tif (rc)\n\t\tgoto out;\n\n\twil->ring2cid_tid[id][0] = cid;\n\twil->ring2cid_tid[id][1] = tid;\n\n\tcmd.vring_cfg.tx_sw_ring.ring_mem_base = cpu_to_le64(vring->pa);\n\n\tif (!vif->privacy)\n\t\ttxdata->dot1x_open = true;\n\trc = wmi_call(wil, WMI_VRING_CFG_CMDID, vif->mid, &cmd, sizeof(cmd),\n\t\t      WMI_VRING_CFG_DONE_EVENTID, &reply, sizeof(reply),\n\t\t      WIL_WMI_CALL_GENERAL_TO_MS);\n\tif (rc)\n\t\tgoto out_free;\n\n\tif (reply.cmd.status != WMI_FW_STATUS_SUCCESS) {\n\t\twil_err(wil, \"Tx config failed, status 0x%02x\\n\",\n\t\t\treply.cmd.status);\n\t\trc = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\tspin_lock_bh(&txdata->lock);\n\tvring->hwtail = le32_to_cpu(reply.cmd.tx_vring_tail_ptr);\n\ttxdata->mid = vif->mid;\n\ttxdata->enabled = 1;\n\tspin_unlock_bh(&txdata->lock);\n\n\tif (txdata->dot1x_open && (agg_wsize >= 0))\n\t\twil_addba_tx_request(wil, id, agg_wsize);\n\n\treturn 0;\n out_free:\n\tspin_lock_bh(&txdata->lock);\n\ttxdata->dot1x_open = false;\n\ttxdata->enabled = 0;\n\tspin_unlock_bh(&txdata->lock);\n\twil_vring_free(wil, vring);\n\twil->ring2cid_tid[id][0] = wil->max_assoc_sta;\n\twil->ring2cid_tid[id][1] = 0;\n\n out:\n\n\treturn rc;\n}\n\nstatic int wil_tx_vring_modify(struct wil6210_vif *vif, int ring_id, int cid,\n\t\t\t       int tid)\n{\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tint rc;\n\tstruct wmi_vring_cfg_cmd cmd = {\n\t\t.action = cpu_to_le32(WMI_VRING_CMD_MODIFY),\n\t\t.vring_cfg = {\n\t\t\t.tx_sw_ring = {\n\t\t\t\t.max_mpdu_size =\n\t\t\t\t\tcpu_to_le16(wil_mtu2macbuf(mtu_max)),\n\t\t\t\t.ring_size = 0,\n\t\t\t},\n\t\t\t.ringid = ring_id,\n\t\t\t.cidxtid = mk_cidxtid(cid, tid),\n\t\t\t.encap_trans_type = WMI_VRING_ENC_TYPE_802_3,\n\t\t\t.mac_ctrl = 0,\n\t\t\t.to_resolution = 0,\n\t\t\t.agg_max_wsize = 0,\n\t\t\t.schd_params = {\n\t\t\t\t.priority = cpu_to_le16(0),\n\t\t\t\t.timeslot_us = cpu_to_le16(0xfff),\n\t\t\t},\n\t\t},\n\t};\n\tstruct {\n\t\tstruct wmi_cmd_hdr wmi;\n\t\tstruct wmi_vring_cfg_done_event cmd;\n\t} __packed reply = {\n\t\t.cmd = {.status = WMI_FW_STATUS_FAILURE},\n\t};\n\tstruct wil_ring *vring = &wil->ring_tx[ring_id];\n\tstruct wil_ring_tx_data *txdata = &wil->ring_tx_data[ring_id];\n\n\twil_dbg_misc(wil, \"vring_modify: ring %d cid %d tid %d\\n\", ring_id,\n\t\t     cid, tid);\n\tlockdep_assert_held(&wil->mutex);\n\n\tif (!vring->va) {\n\t\twil_err(wil, \"Tx ring [%d] not allocated\\n\", ring_id);\n\t\treturn -EINVAL;\n\t}\n\n\tif (wil->ring2cid_tid[ring_id][0] != cid ||\n\t    wil->ring2cid_tid[ring_id][1] != tid) {\n\t\twil_err(wil, \"ring info does not match cid=%u tid=%u\\n\",\n\t\t\twil->ring2cid_tid[ring_id][0],\n\t\t\twil->ring2cid_tid[ring_id][1]);\n\t}\n\n\tcmd.vring_cfg.tx_sw_ring.ring_mem_base = cpu_to_le64(vring->pa);\n\n\trc = wmi_call(wil, WMI_VRING_CFG_CMDID, vif->mid, &cmd, sizeof(cmd),\n\t\t      WMI_VRING_CFG_DONE_EVENTID, &reply, sizeof(reply),\n\t\t      WIL_WMI_CALL_GENERAL_TO_MS);\n\tif (rc)\n\t\tgoto fail;\n\n\tif (reply.cmd.status != WMI_FW_STATUS_SUCCESS) {\n\t\twil_err(wil, \"Tx modify failed, status 0x%02x\\n\",\n\t\t\treply.cmd.status);\n\t\trc = -EINVAL;\n\t\tgoto fail;\n\t}\n\n\t \n\ttxdata->agg_wsize = 0;\n\tif (txdata->dot1x_open && agg_wsize >= 0)\n\t\twil_addba_tx_request(wil, ring_id, agg_wsize);\n\n\treturn 0;\nfail:\n\tspin_lock_bh(&txdata->lock);\n\ttxdata->dot1x_open = false;\n\ttxdata->enabled = 0;\n\tspin_unlock_bh(&txdata->lock);\n\twil->ring2cid_tid[ring_id][0] = wil->max_assoc_sta;\n\twil->ring2cid_tid[ring_id][1] = 0;\n\treturn rc;\n}\n\nint wil_vring_init_bcast(struct wil6210_vif *vif, int id, int size)\n{\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tint rc;\n\tstruct wmi_bcast_vring_cfg_cmd cmd = {\n\t\t.action = cpu_to_le32(WMI_VRING_CMD_ADD),\n\t\t.vring_cfg = {\n\t\t\t.tx_sw_ring = {\n\t\t\t\t.max_mpdu_size =\n\t\t\t\t\tcpu_to_le16(wil_mtu2macbuf(mtu_max)),\n\t\t\t\t.ring_size = cpu_to_le16(size),\n\t\t\t},\n\t\t\t.ringid = id,\n\t\t\t.encap_trans_type = WMI_VRING_ENC_TYPE_802_3,\n\t\t},\n\t};\n\tstruct {\n\t\tstruct wmi_cmd_hdr wmi;\n\t\tstruct wmi_vring_cfg_done_event cmd;\n\t} __packed reply = {\n\t\t.cmd = {.status = WMI_FW_STATUS_FAILURE},\n\t};\n\tstruct wil_ring *vring = &wil->ring_tx[id];\n\tstruct wil_ring_tx_data *txdata = &wil->ring_tx_data[id];\n\n\twil_dbg_misc(wil, \"vring_init_bcast: max_mpdu_size %d\\n\",\n\t\t     cmd.vring_cfg.tx_sw_ring.max_mpdu_size);\n\tlockdep_assert_held(&wil->mutex);\n\n\tif (vring->va) {\n\t\twil_err(wil, \"Tx ring [%d] already allocated\\n\", id);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\twil_tx_data_init(txdata);\n\tvring->is_rx = false;\n\tvring->size = size;\n\trc = wil_vring_alloc(wil, vring);\n\tif (rc)\n\t\tgoto out;\n\n\twil->ring2cid_tid[id][0] = wil->max_assoc_sta;  \n\twil->ring2cid_tid[id][1] = 0;  \n\n\tcmd.vring_cfg.tx_sw_ring.ring_mem_base = cpu_to_le64(vring->pa);\n\n\tif (!vif->privacy)\n\t\ttxdata->dot1x_open = true;\n\trc = wmi_call(wil, WMI_BCAST_VRING_CFG_CMDID, vif->mid,\n\t\t      &cmd, sizeof(cmd),\n\t\t      WMI_VRING_CFG_DONE_EVENTID, &reply, sizeof(reply),\n\t\t      WIL_WMI_CALL_GENERAL_TO_MS);\n\tif (rc)\n\t\tgoto out_free;\n\n\tif (reply.cmd.status != WMI_FW_STATUS_SUCCESS) {\n\t\twil_err(wil, \"Tx config failed, status 0x%02x\\n\",\n\t\t\treply.cmd.status);\n\t\trc = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\tspin_lock_bh(&txdata->lock);\n\tvring->hwtail = le32_to_cpu(reply.cmd.tx_vring_tail_ptr);\n\ttxdata->mid = vif->mid;\n\ttxdata->enabled = 1;\n\tspin_unlock_bh(&txdata->lock);\n\n\treturn 0;\n out_free:\n\tspin_lock_bh(&txdata->lock);\n\ttxdata->enabled = 0;\n\ttxdata->dot1x_open = false;\n\tspin_unlock_bh(&txdata->lock);\n\twil_vring_free(wil, vring);\n out:\n\n\treturn rc;\n}\n\nstatic struct wil_ring *wil_find_tx_ucast(struct wil6210_priv *wil,\n\t\t\t\t\t  struct wil6210_vif *vif,\n\t\t\t\t\t  struct sk_buff *skb)\n{\n\tint i, cid;\n\tconst u8 *da = wil_skb_get_da(skb);\n\tint min_ring_id = wil_get_min_tx_ring_id(wil);\n\n\tcid = wil_find_cid(wil, vif->mid, da);\n\n\tif (cid < 0 || cid >= wil->max_assoc_sta)\n\t\treturn NULL;\n\n\t \n\tfor (i = min_ring_id; i < ARRAY_SIZE(wil->ring2cid_tid); i++) {\n\t\tif (!wil->ring_tx_data[i].dot1x_open &&\n\t\t    skb->protocol != cpu_to_be16(ETH_P_PAE))\n\t\t\tcontinue;\n\t\tif (wil->ring2cid_tid[i][0] == cid) {\n\t\t\tstruct wil_ring *v = &wil->ring_tx[i];\n\t\t\tstruct wil_ring_tx_data *txdata = &wil->ring_tx_data[i];\n\n\t\t\twil_dbg_txrx(wil, \"find_tx_ucast: (%pM) -> [%d]\\n\",\n\t\t\t\t     da, i);\n\t\t\tif (v->va && txdata->enabled) {\n\t\t\t\treturn v;\n\t\t\t} else {\n\t\t\t\twil_dbg_txrx(wil,\n\t\t\t\t\t     \"find_tx_ucast: vring[%d] not valid\\n\",\n\t\t\t\t\t     i);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn NULL;\n}\n\nstatic int wil_tx_ring(struct wil6210_priv *wil, struct wil6210_vif *vif,\n\t\t       struct wil_ring *ring, struct sk_buff *skb);\n\nstatic struct wil_ring *wil_find_tx_ring_sta(struct wil6210_priv *wil,\n\t\t\t\t\t     struct wil6210_vif *vif,\n\t\t\t\t\t     struct sk_buff *skb)\n{\n\tstruct wil_ring *ring;\n\tint i;\n\tu8 cid;\n\tstruct wil_ring_tx_data  *txdata;\n\tint min_ring_id = wil_get_min_tx_ring_id(wil);\n\n\t \n\tfor (i = min_ring_id; i < WIL6210_MAX_TX_RINGS; i++) {\n\t\tring = &wil->ring_tx[i];\n\t\ttxdata = &wil->ring_tx_data[i];\n\t\tif (!ring->va || !txdata->enabled || txdata->mid != vif->mid)\n\t\t\tcontinue;\n\n\t\tcid = wil->ring2cid_tid[i][0];\n\t\tif (cid >= wil->max_assoc_sta)  \n\t\t\tcontinue;\n\n\t\tif (!wil->ring_tx_data[i].dot1x_open &&\n\t\t    skb->protocol != cpu_to_be16(ETH_P_PAE))\n\t\t\tcontinue;\n\n\t\twil_dbg_txrx(wil, \"Tx -> ring %d\\n\", i);\n\n\t\treturn ring;\n\t}\n\n\twil_dbg_txrx(wil, \"Tx while no rings active?\\n\");\n\n\treturn NULL;\n}\n\n \nstatic struct wil_ring *wil_find_tx_bcast_1(struct wil6210_priv *wil,\n\t\t\t\t\t    struct wil6210_vif *vif,\n\t\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct wil_ring *v;\n\tstruct wil_ring_tx_data *txdata;\n\tint i = vif->bcast_ring;\n\n\tif (i < 0)\n\t\treturn NULL;\n\tv = &wil->ring_tx[i];\n\ttxdata = &wil->ring_tx_data[i];\n\tif (!v->va || !txdata->enabled)\n\t\treturn NULL;\n\tif (!wil->ring_tx_data[i].dot1x_open &&\n\t    skb->protocol != cpu_to_be16(ETH_P_PAE))\n\t\treturn NULL;\n\n\treturn v;\n}\n\n \nstatic bool wil_check_multicast_to_unicast(struct wil6210_priv *wil,\n\t\t\t\t\t   struct sk_buff *skb)\n{\n\tconst struct ethhdr *eth = (void *)skb->data;\n\tconst struct vlan_ethhdr *ethvlan = (void *)skb->data;\n\t__be16 ethertype;\n\n\tif (!wil->multicast_to_unicast)\n\t\treturn false;\n\n\t \n\tethertype = eth->h_proto;\n\tif (ethertype == htons(ETH_P_8021Q) && skb->len >= VLAN_ETH_HLEN)\n\t\tethertype = ethvlan->h_vlan_encapsulated_proto;\n\tswitch (ethertype) {\n\tcase htons(ETH_P_ARP):\n\tcase htons(ETH_P_IP):\n\tcase htons(ETH_P_IPV6):\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic void wil_set_da_for_vring(struct wil6210_priv *wil,\n\t\t\t\t struct sk_buff *skb, int vring_index)\n{\n\tu8 *da = wil_skb_get_da(skb);\n\tint cid = wil->ring2cid_tid[vring_index][0];\n\n\tether_addr_copy(da, wil->sta[cid].addr);\n}\n\nstatic struct wil_ring *wil_find_tx_bcast_2(struct wil6210_priv *wil,\n\t\t\t\t\t    struct wil6210_vif *vif,\n\t\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct wil_ring *v, *v2;\n\tstruct sk_buff *skb2;\n\tint i;\n\tu8 cid;\n\tconst u8 *src = wil_skb_get_sa(skb);\n\tstruct wil_ring_tx_data *txdata, *txdata2;\n\tint min_ring_id = wil_get_min_tx_ring_id(wil);\n\n\t \n\tfor (i = min_ring_id; i < WIL6210_MAX_TX_RINGS; i++) {\n\t\tv = &wil->ring_tx[i];\n\t\ttxdata = &wil->ring_tx_data[i];\n\t\tif (!v->va || !txdata->enabled || txdata->mid != vif->mid)\n\t\t\tcontinue;\n\n\t\tcid = wil->ring2cid_tid[i][0];\n\t\tif (cid >= wil->max_assoc_sta)  \n\t\t\tcontinue;\n\t\tif (!wil->ring_tx_data[i].dot1x_open &&\n\t\t    skb->protocol != cpu_to_be16(ETH_P_PAE))\n\t\t\tcontinue;\n\n\t\t \n\t\tif (0 == memcmp(wil->sta[cid].addr, src, ETH_ALEN))\n\t\t\tcontinue;\n\n\t\tgoto found;\n\t}\n\n\twil_dbg_txrx(wil, \"Tx while no vrings active?\\n\");\n\n\treturn NULL;\n\nfound:\n\twil_dbg_txrx(wil, \"BCAST -> ring %d\\n\", i);\n\twil_set_da_for_vring(wil, skb, i);\n\n\t \n\tfor (i++; i < WIL6210_MAX_TX_RINGS; i++) {\n\t\tv2 = &wil->ring_tx[i];\n\t\ttxdata2 = &wil->ring_tx_data[i];\n\t\tif (!v2->va || txdata2->mid != vif->mid)\n\t\t\tcontinue;\n\t\tcid = wil->ring2cid_tid[i][0];\n\t\tif (cid >= wil->max_assoc_sta)  \n\t\t\tcontinue;\n\t\tif (!wil->ring_tx_data[i].dot1x_open &&\n\t\t    skb->protocol != cpu_to_be16(ETH_P_PAE))\n\t\t\tcontinue;\n\n\t\tif (0 == memcmp(wil->sta[cid].addr, src, ETH_ALEN))\n\t\t\tcontinue;\n\n\t\tskb2 = skb_copy(skb, GFP_ATOMIC);\n\t\tif (skb2) {\n\t\t\twil_dbg_txrx(wil, \"BCAST DUP -> ring %d\\n\", i);\n\t\t\twil_set_da_for_vring(wil, skb2, i);\n\t\t\twil_tx_ring(wil, vif, v2, skb2);\n\t\t\t \n\t\t\tdev_kfree_skb_any(skb2);\n\t\t} else {\n\t\t\twil_err(wil, \"skb_copy failed\\n\");\n\t\t}\n\t}\n\n\treturn v;\n}\n\nstatic inline\nvoid wil_tx_desc_set_nr_frags(struct vring_tx_desc *d, int nr_frags)\n{\n\td->mac.d[2] |= (nr_frags << MAC_CFG_DESC_TX_2_NUM_OF_DESCRIPTORS_POS);\n}\n\n \n\nstatic void wil_tx_desc_offload_setup_tso(struct vring_tx_desc *d,\n\t\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t\t  int tso_desc_type, bool is_ipv4,\n\t\t\t\t\t  int tcp_hdr_len, int skb_net_hdr_len)\n{\n\td->dma.b11 = ETH_HLEN;  \n\td->dma.b11 |= is_ipv4 << DMA_CFG_DESC_TX_OFFLOAD_CFG_L3T_IPV4_POS;\n\n\td->dma.d0 |= (2 << DMA_CFG_DESC_TX_0_L4_TYPE_POS);\n\t \n\td->dma.d0 |= (tcp_hdr_len & DMA_CFG_DESC_TX_0_L4_LENGTH_MSK);\n\n\t \n\td->dma.d0 |= (BIT(DMA_CFG_DESC_TX_0_TCP_SEG_EN_POS)) |\n\t\t(tso_desc_type << DMA_CFG_DESC_TX_0_SEGMENT_BUF_DETAILS_POS);\n\td->dma.d0 |= (is_ipv4 << DMA_CFG_DESC_TX_0_IPV4_CHECKSUM_EN_POS);\n\n\td->dma.ip_length = skb_net_hdr_len;\n\t \n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_TCP_UDP_CHECKSUM_EN_POS);\n\t \n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_PSEUDO_HEADER_CALC_EN_POS);\n}\n\n \n\nstatic int wil_tx_desc_offload_setup(struct vring_tx_desc *d,\n\t\t\t\t     struct sk_buff *skb){\n\tint protocol;\n\n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn 0;\n\n\td->dma.b11 = ETH_HLEN;  \n\n\tswitch (skb->protocol) {\n\tcase cpu_to_be16(ETH_P_IP):\n\t\tprotocol = ip_hdr(skb)->protocol;\n\t\td->dma.b11 |= BIT(DMA_CFG_DESC_TX_OFFLOAD_CFG_L3T_IPV4_POS);\n\t\tbreak;\n\tcase cpu_to_be16(ETH_P_IPV6):\n\t\tprotocol = ipv6_hdr(skb)->nexthdr;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (protocol) {\n\tcase IPPROTO_TCP:\n\t\td->dma.d0 |= (2 << DMA_CFG_DESC_TX_0_L4_TYPE_POS);\n\t\t \n\t\td->dma.d0 |=\n\t\t(tcp_hdrlen(skb) & DMA_CFG_DESC_TX_0_L4_LENGTH_MSK);\n\t\tbreak;\n\tcase IPPROTO_UDP:\n\t\t \n\t\td->dma.d0 |=\n\t\t(sizeof(struct udphdr) & DMA_CFG_DESC_TX_0_L4_LENGTH_MSK);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\td->dma.ip_length = skb_network_header_len(skb);\n\t \n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_TCP_UDP_CHECKSUM_EN_POS);\n\t \n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_PSEUDO_HEADER_CALC_EN_POS);\n\n\treturn 0;\n}\n\nstatic inline void wil_tx_last_desc(struct vring_tx_desc *d)\n{\n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_CMD_EOP_POS) |\n\t      BIT(DMA_CFG_DESC_TX_0_CMD_MARK_WB_POS) |\n\t      BIT(DMA_CFG_DESC_TX_0_CMD_DMA_IT_POS);\n}\n\nstatic inline void wil_set_tx_desc_last_tso(volatile struct vring_tx_desc *d)\n{\n\td->dma.d0 |= wil_tso_type_lst <<\n\t\t  DMA_CFG_DESC_TX_0_SEGMENT_BUF_DETAILS_POS;\n}\n\nstatic int __wil_tx_vring_tso(struct wil6210_priv *wil, struct wil6210_vif *vif,\n\t\t\t      struct wil_ring *vring, struct sk_buff *skb)\n{\n\tstruct device *dev = wil_to_dev(wil);\n\n\t \n\tvolatile struct vring_tx_desc *_desc = NULL, *_hdr_desc,\n\t\t\t\t      *_first_desc = NULL;\n\n\t \n\tstruct vring_tx_desc desc_mem, hdr_desc_mem, first_desc_mem,\n\t\t\t     *d = &hdr_desc_mem, *hdr_desc = &hdr_desc_mem,\n\t\t\t     *first_desc = &first_desc_mem;\n\n\t \n\tstruct wil_ctx *hdr_ctx, *first_ctx = NULL;\n\n\tint descs_used = 0;  \n\tint sg_desc_cnt = 0;  \n\n\tu32 swhead = vring->swhead;\n\tint used, avail = wil_ring_avail_tx(vring);\n\tint nr_frags = skb_shinfo(skb)->nr_frags;\n\tint min_desc_required = nr_frags + 1;\n\tint mss = skb_shinfo(skb)->gso_size;\t \n\tint f, len, hdrlen, headlen;\n\tint vring_index = vring - wil->ring_tx;\n\tstruct wil_ring_tx_data *txdata = &wil->ring_tx_data[vring_index];\n\tuint i = swhead;\n\tdma_addr_t pa;\n\tconst skb_frag_t *frag = NULL;\n\tint rem_data = mss;\n\tint lenmss;\n\tint hdr_compensation_need = true;\n\tint desc_tso_type = wil_tso_type_first;\n\tbool is_ipv4;\n\tint tcp_hdr_len;\n\tint skb_net_hdr_len;\n\tint gso_type;\n\tint rc = -EINVAL;\n\n\twil_dbg_txrx(wil, \"tx_vring_tso: %d bytes to vring %d\\n\", skb->len,\n\t\t     vring_index);\n\n\tif (unlikely(!txdata->enabled))\n\t\treturn -EINVAL;\n\n\t \n\tif (unlikely(avail < min_desc_required)) {\n\t\twil_err_ratelimited(wil,\n\t\t\t\t    \"TSO: Tx ring[%2d] full. No space for %d fragments\\n\",\n\t\t\t\t    vring_index, min_desc_required);\n\t\treturn -ENOMEM;\n\t}\n\n\t \n\thdrlen = skb_tcp_all_headers(skb);\n\n\tgso_type = skb_shinfo(skb)->gso_type & (SKB_GSO_TCPV6 | SKB_GSO_TCPV4);\n\tswitch (gso_type) {\n\tcase SKB_GSO_TCPV4:\n\t\t \n\t\tip_hdr(skb)->tot_len = 0;\n\t\tip_hdr(skb)->check = 0;\n\t\tis_ipv4 = true;\n\t\tbreak;\n\tcase SKB_GSO_TCPV6:\n\t\t \n\t\tipv6_hdr(skb)->payload_len = 0;\n\t\tis_ipv4 = false;\n\t\tbreak;\n\tdefault:\n\t\t \n\t\treturn -EINVAL;\n\t}\n\n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn -EINVAL;\n\n\t \n\ttcp_hdr_len = tcp_hdrlen(skb);\n\tskb_net_hdr_len = skb_network_header_len(skb);\n\n\t_hdr_desc = &vring->va[i].tx.legacy;\n\n\tpa = dma_map_single(dev, skb->data, hdrlen, DMA_TO_DEVICE);\n\tif (unlikely(dma_mapping_error(dev, pa))) {\n\t\twil_err(wil, \"TSO: Skb head DMA map error\\n\");\n\t\tgoto err_exit;\n\t}\n\n\twil->txrx_ops.tx_desc_map((union wil_tx_desc *)hdr_desc, pa,\n\t\t\t\t  hdrlen, vring_index);\n\twil_tx_desc_offload_setup_tso(hdr_desc, skb, wil_tso_type_hdr, is_ipv4,\n\t\t\t\t      tcp_hdr_len, skb_net_hdr_len);\n\twil_tx_last_desc(hdr_desc);\n\n\tvring->ctx[i].mapped_as = wil_mapped_as_single;\n\thdr_ctx = &vring->ctx[i];\n\n\tdescs_used++;\n\theadlen = skb_headlen(skb) - hdrlen;\n\n\tfor (f = headlen ? -1 : 0; f < nr_frags; f++)  {\n\t\tif (headlen) {\n\t\t\tlen = headlen;\n\t\t\twil_dbg_txrx(wil, \"TSO: process skb head, len %u\\n\",\n\t\t\t\t     len);\n\t\t} else {\n\t\t\tfrag = &skb_shinfo(skb)->frags[f];\n\t\t\tlen = skb_frag_size(frag);\n\t\t\twil_dbg_txrx(wil, \"TSO: frag[%d]: len %u\\n\", f, len);\n\t\t}\n\n\t\twhile (len) {\n\t\t\twil_dbg_txrx(wil,\n\t\t\t\t     \"TSO: len %d, rem_data %d, descs_used %d\\n\",\n\t\t\t\t     len, rem_data, descs_used);\n\n\t\t\tif (descs_used == avail)  {\n\t\t\t\twil_err_ratelimited(wil, \"TSO: ring overflow\\n\");\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto mem_error;\n\t\t\t}\n\n\t\t\tlenmss = min_t(int, rem_data, len);\n\t\t\ti = (swhead + descs_used) % vring->size;\n\t\t\twil_dbg_txrx(wil, \"TSO: lenmss %d, i %d\\n\", lenmss, i);\n\n\t\t\tif (!headlen) {\n\t\t\t\tpa = skb_frag_dma_map(dev, frag,\n\t\t\t\t\t\t      skb_frag_size(frag) - len,\n\t\t\t\t\t\t      lenmss, DMA_TO_DEVICE);\n\t\t\t\tvring->ctx[i].mapped_as = wil_mapped_as_page;\n\t\t\t} else {\n\t\t\t\tpa = dma_map_single(dev,\n\t\t\t\t\t\t    skb->data +\n\t\t\t\t\t\t    skb_headlen(skb) - headlen,\n\t\t\t\t\t\t    lenmss,\n\t\t\t\t\t\t    DMA_TO_DEVICE);\n\t\t\t\tvring->ctx[i].mapped_as = wil_mapped_as_single;\n\t\t\t\theadlen -= lenmss;\n\t\t\t}\n\n\t\t\tif (unlikely(dma_mapping_error(dev, pa))) {\n\t\t\t\twil_err(wil, \"TSO: DMA map page error\\n\");\n\t\t\t\tgoto mem_error;\n\t\t\t}\n\n\t\t\t_desc = &vring->va[i].tx.legacy;\n\n\t\t\tif (!_first_desc) {\n\t\t\t\t_first_desc = _desc;\n\t\t\t\tfirst_ctx = &vring->ctx[i];\n\t\t\t\td = first_desc;\n\t\t\t} else {\n\t\t\t\td = &desc_mem;\n\t\t\t}\n\n\t\t\twil->txrx_ops.tx_desc_map((union wil_tx_desc *)d,\n\t\t\t\t\t\t  pa, lenmss, vring_index);\n\t\t\twil_tx_desc_offload_setup_tso(d, skb, desc_tso_type,\n\t\t\t\t\t\t      is_ipv4, tcp_hdr_len,\n\t\t\t\t\t\t      skb_net_hdr_len);\n\n\t\t\t \n\t\t\tdesc_tso_type = wil_tso_type_mid;\n\n\t\t\tdescs_used++;   \n\t\t\tsg_desc_cnt++;  \n\t\t\tlen -= lenmss;\n\t\t\trem_data -= lenmss;\n\n\t\t\twil_dbg_txrx(wil,\n\t\t\t\t     \"TSO: len %d, rem_data %d, descs_used %d, sg_desc_cnt %d,\\n\",\n\t\t\t\t     len, rem_data, descs_used, sg_desc_cnt);\n\n\t\t\t \n\t\t\tif (rem_data == 0 || (f == nr_frags - 1 && len == 0)) {\n\t\t\t\tif (hdr_compensation_need) {\n\t\t\t\t\t \n\t\t\t\t\thdr_ctx->nr_frags = sg_desc_cnt;\n\t\t\t\t\twil_tx_desc_set_nr_frags(first_desc,\n\t\t\t\t\t\t\t\t sg_desc_cnt +\n\t\t\t\t\t\t\t\t 1);\n\t\t\t\t\thdr_compensation_need = false;\n\t\t\t\t} else {\n\t\t\t\t\twil_tx_desc_set_nr_frags(first_desc,\n\t\t\t\t\t\t\t\t sg_desc_cnt);\n\t\t\t\t}\n\t\t\t\tfirst_ctx->nr_frags = sg_desc_cnt - 1;\n\n\t\t\t\twil_tx_last_desc(d);\n\n\t\t\t\t \n\t\t\t\tif (first_desc != d)\n\t\t\t\t\t*_first_desc = *first_desc;\n\n\t\t\t\t \n\t\t\t\tif (f < nr_frags - 1 || len > 0)\n\t\t\t\t\t*_desc = *d;\n\n\t\t\t\trem_data = mss;\n\t\t\t\t_first_desc = NULL;\n\t\t\t\tsg_desc_cnt = 0;\n\t\t\t} else if (first_desc != d)  \n\t\t\t\t\t*_desc = *d;\n\t\t}\n\t}\n\n\tif (!_desc)\n\t\tgoto mem_error;\n\n\t \n\tif (_first_desc == _desc)\n\t\td = first_desc;\n\n\t \n\twil_set_tx_desc_last_tso(d);\n\t*_desc = *d;\n\n\t \n\twil_tx_desc_set_nr_frags(hdr_desc, descs_used);\n\t*_hdr_desc = *hdr_desc;\n\n\t \n\tvring->ctx[i].skb = skb_get(skb);\n\n\t \n\tused = wil_ring_used_tx(vring);\n\tif (wil_val_in_range(wil->ring_idle_trsh,\n\t\t\t     used, used + descs_used)) {\n\t\ttxdata->idle += get_cycles() - txdata->last_idle;\n\t\twil_dbg_txrx(wil,  \"Ring[%2d] not idle %d -> %d\\n\",\n\t\t\t     vring_index, used, used + descs_used);\n\t}\n\n\t \n\twmb();\n\n\t \n\twil_ring_advance_head(vring, descs_used);\n\twil_dbg_txrx(wil, \"TSO: Tx swhead %d -> %d\\n\", swhead, vring->swhead);\n\n\t \n\twmb();\n\n\tif (wil->tx_latency)\n\t\t*(ktime_t *)&skb->cb = ktime_get();\n\telse\n\t\tmemset(skb->cb, 0, sizeof(ktime_t));\n\n\twil_w(wil, vring->hwtail, vring->swhead);\n\treturn 0;\n\nmem_error:\n\twhile (descs_used > 0) {\n\t\tstruct wil_ctx *ctx;\n\n\t\ti = (swhead + descs_used - 1) % vring->size;\n\t\td = (struct vring_tx_desc *)&vring->va[i].tx.legacy;\n\t\t_desc = &vring->va[i].tx.legacy;\n\t\t*d = *_desc;\n\t\t_desc->dma.status = TX_DMA_STATUS_DU;\n\t\tctx = &vring->ctx[i];\n\t\twil_txdesc_unmap(dev, (union wil_tx_desc *)d, ctx);\n\t\tmemset(ctx, 0, sizeof(*ctx));\n\t\tdescs_used--;\n\t}\nerr_exit:\n\treturn rc;\n}\n\nstatic int __wil_tx_ring(struct wil6210_priv *wil, struct wil6210_vif *vif,\n\t\t\t struct wil_ring *ring, struct sk_buff *skb)\n{\n\tstruct device *dev = wil_to_dev(wil);\n\tstruct vring_tx_desc dd, *d = &dd;\n\tvolatile struct vring_tx_desc *_d;\n\tu32 swhead = ring->swhead;\n\tint avail = wil_ring_avail_tx(ring);\n\tint nr_frags = skb_shinfo(skb)->nr_frags;\n\tuint f = 0;\n\tint ring_index = ring - wil->ring_tx;\n\tstruct wil_ring_tx_data  *txdata = &wil->ring_tx_data[ring_index];\n\tuint i = swhead;\n\tdma_addr_t pa;\n\tint used;\n\tbool mcast = (ring_index == vif->bcast_ring);\n\tuint len = skb_headlen(skb);\n\n\twil_dbg_txrx(wil, \"tx_ring: %d bytes to ring %d, nr_frags %d\\n\",\n\t\t     skb->len, ring_index, nr_frags);\n\n\tif (unlikely(!txdata->enabled))\n\t\treturn -EINVAL;\n\n\tif (unlikely(avail < 1 + nr_frags)) {\n\t\twil_err_ratelimited(wil,\n\t\t\t\t    \"Tx ring[%2d] full. No space for %d fragments\\n\",\n\t\t\t\t    ring_index, 1 + nr_frags);\n\t\treturn -ENOMEM;\n\t}\n\t_d = &ring->va[i].tx.legacy;\n\n\tpa = dma_map_single(dev, skb->data, skb_headlen(skb), DMA_TO_DEVICE);\n\n\twil_dbg_txrx(wil, \"Tx[%2d] skb %d bytes 0x%p -> %pad\\n\", ring_index,\n\t\t     skb_headlen(skb), skb->data, &pa);\n\twil_hex_dump_txrx(\"Tx \", DUMP_PREFIX_OFFSET, 16, 1,\n\t\t\t  skb->data, skb_headlen(skb), false);\n\n\tif (unlikely(dma_mapping_error(dev, pa)))\n\t\treturn -EINVAL;\n\tring->ctx[i].mapped_as = wil_mapped_as_single;\n\t \n\twil->txrx_ops.tx_desc_map((union wil_tx_desc *)d, pa, len,\n\t\t\t\t   ring_index);\n\tif (unlikely(mcast)) {\n\t\td->mac.d[0] |= BIT(MAC_CFG_DESC_TX_0_MCS_EN_POS);  \n\t\tif (unlikely(len > WIL_BCAST_MCS0_LIMIT))  \n\t\t\td->mac.d[0] |= (1 << MAC_CFG_DESC_TX_0_MCS_INDEX_POS);\n\t}\n\t \n\tif (unlikely(wil_tx_desc_offload_setup(d, skb))) {\n\t\twil_err(wil, \"Tx[%2d] Failed to set cksum, drop packet\\n\",\n\t\t\tring_index);\n\t\tgoto dma_error;\n\t}\n\n\tring->ctx[i].nr_frags = nr_frags;\n\twil_tx_desc_set_nr_frags(d, nr_frags + 1);\n\n\t \n\tfor (; f < nr_frags; f++) {\n\t\tconst skb_frag_t *frag = &skb_shinfo(skb)->frags[f];\n\t\tint len = skb_frag_size(frag);\n\n\t\t*_d = *d;\n\t\twil_dbg_txrx(wil, \"Tx[%2d] desc[%4d]\\n\", ring_index, i);\n\t\twil_hex_dump_txrx(\"TxD \", DUMP_PREFIX_NONE, 32, 4,\n\t\t\t\t  (const void *)d, sizeof(*d), false);\n\t\ti = (swhead + f + 1) % ring->size;\n\t\t_d = &ring->va[i].tx.legacy;\n\t\tpa = skb_frag_dma_map(dev, frag, 0, skb_frag_size(frag),\n\t\t\t\t      DMA_TO_DEVICE);\n\t\tif (unlikely(dma_mapping_error(dev, pa))) {\n\t\t\twil_err(wil, \"Tx[%2d] failed to map fragment\\n\",\n\t\t\t\tring_index);\n\t\t\tgoto dma_error;\n\t\t}\n\t\tring->ctx[i].mapped_as = wil_mapped_as_page;\n\t\twil->txrx_ops.tx_desc_map((union wil_tx_desc *)d,\n\t\t\t\t\t   pa, len, ring_index);\n\t\t \n\t\twil_tx_desc_offload_setup(d, skb);\n\t}\n\t \n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_CMD_EOP_POS);\n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_CMD_MARK_WB_POS);\n\td->dma.d0 |= BIT(DMA_CFG_DESC_TX_0_CMD_DMA_IT_POS);\n\t*_d = *d;\n\twil_dbg_txrx(wil, \"Tx[%2d] desc[%4d]\\n\", ring_index, i);\n\twil_hex_dump_txrx(\"TxD \", DUMP_PREFIX_NONE, 32, 4,\n\t\t\t  (const void *)d, sizeof(*d), false);\n\n\t \n\tring->ctx[i].skb = skb_get(skb);\n\n\t \n\tused = wil_ring_used_tx(ring);\n\tif (wil_val_in_range(wil->ring_idle_trsh,\n\t\t\t     used, used + nr_frags + 1)) {\n\t\ttxdata->idle += get_cycles() - txdata->last_idle;\n\t\twil_dbg_txrx(wil,  \"Ring[%2d] not idle %d -> %d\\n\",\n\t\t\t     ring_index, used, used + nr_frags + 1);\n\t}\n\n\t \n\twmb();\n\n\t \n\twil_ring_advance_head(ring, nr_frags + 1);\n\twil_dbg_txrx(wil, \"Tx[%2d] swhead %d -> %d\\n\", ring_index, swhead,\n\t\t     ring->swhead);\n\ttrace_wil6210_tx(ring_index, swhead, skb->len, nr_frags);\n\n\t \n\twmb();\n\n\tif (wil->tx_latency)\n\t\t*(ktime_t *)&skb->cb = ktime_get();\n\telse\n\t\tmemset(skb->cb, 0, sizeof(ktime_t));\n\n\twil_w(wil, ring->hwtail, ring->swhead);\n\n\treturn 0;\n dma_error:\n\t \n\tnr_frags = f + 1;  \n\tfor (f = 0; f < nr_frags; f++) {\n\t\tstruct wil_ctx *ctx;\n\n\t\ti = (swhead + f) % ring->size;\n\t\tctx = &ring->ctx[i];\n\t\t_d = &ring->va[i].tx.legacy;\n\t\t*d = *_d;\n\t\t_d->dma.status = TX_DMA_STATUS_DU;\n\t\twil->txrx_ops.tx_desc_unmap(dev,\n\t\t\t\t\t    (union wil_tx_desc *)d,\n\t\t\t\t\t    ctx);\n\n\t\tmemset(ctx, 0, sizeof(*ctx));\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int wil_tx_ring(struct wil6210_priv *wil, struct wil6210_vif *vif,\n\t\t       struct wil_ring *ring, struct sk_buff *skb)\n{\n\tint ring_index = ring - wil->ring_tx;\n\tstruct wil_ring_tx_data *txdata = &wil->ring_tx_data[ring_index];\n\tint rc;\n\n\tspin_lock(&txdata->lock);\n\n\tif (test_bit(wil_status_suspending, wil->status) ||\n\t    test_bit(wil_status_suspended, wil->status) ||\n\t    test_bit(wil_status_resuming, wil->status)) {\n\t\twil_dbg_txrx(wil,\n\t\t\t     \"suspend/resume in progress. drop packet\\n\");\n\t\tspin_unlock(&txdata->lock);\n\t\treturn -EINVAL;\n\t}\n\n\trc = (skb_is_gso(skb) ? wil->txrx_ops.tx_ring_tso : __wil_tx_ring)\n\t     (wil, vif, ring, skb);\n\n\tspin_unlock(&txdata->lock);\n\n\treturn rc;\n}\n\n \nstatic inline void __wil_update_net_queues(struct wil6210_priv *wil,\n\t\t\t\t\t   struct wil6210_vif *vif,\n\t\t\t\t\t   struct wil_ring *ring,\n\t\t\t\t\t   bool check_stop)\n{\n\tint i;\n\tint min_ring_id = wil_get_min_tx_ring_id(wil);\n\n\tif (unlikely(!vif))\n\t\treturn;\n\n\tif (ring)\n\t\twil_dbg_txrx(wil, \"vring %d, mid %d, check_stop=%d, stopped=%d\",\n\t\t\t     (int)(ring - wil->ring_tx), vif->mid, check_stop,\n\t\t\t     vif->net_queue_stopped);\n\telse\n\t\twil_dbg_txrx(wil, \"check_stop=%d, mid=%d, stopped=%d\",\n\t\t\t     check_stop, vif->mid, vif->net_queue_stopped);\n\n\tif (ring && drop_if_ring_full)\n\t\t \n\t\treturn;\n\n\tif (check_stop == vif->net_queue_stopped)\n\t\t \n\t\treturn;\n\n\tif (check_stop) {\n\t\tif (!ring || unlikely(wil_ring_avail_low(ring))) {\n\t\t\t \n\t\t\tnetif_tx_stop_all_queues(vif_to_ndev(vif));\n\t\t\tvif->net_queue_stopped = true;\n\t\t\twil_dbg_txrx(wil, \"netif_tx_stop called\\n\");\n\t\t}\n\t\treturn;\n\t}\n\n\t \n\tif (test_bit(wil_status_suspending, wil->status) ||\n\t    test_bit(wil_status_suspended, wil->status))\n\t\treturn;\n\n\t \n\tfor (i = min_ring_id; i < WIL6210_MAX_TX_RINGS; i++) {\n\t\tstruct wil_ring *cur_ring = &wil->ring_tx[i];\n\t\tstruct wil_ring_tx_data  *txdata = &wil->ring_tx_data[i];\n\n\t\tif (txdata->mid != vif->mid || !cur_ring->va ||\n\t\t    !txdata->enabled || cur_ring == ring)\n\t\t\tcontinue;\n\n\t\tif (wil_ring_avail_low(cur_ring)) {\n\t\t\twil_dbg_txrx(wil, \"ring %d full, can't wake\\n\",\n\t\t\t\t     (int)(cur_ring - wil->ring_tx));\n\t\t\treturn;\n\t\t}\n\t}\n\n\tif (!ring || wil_ring_avail_high(ring)) {\n\t\t \n\t\twil_dbg_txrx(wil, \"calling netif_tx_wake\\n\");\n\t\tnetif_tx_wake_all_queues(vif_to_ndev(vif));\n\t\tvif->net_queue_stopped = false;\n\t}\n}\n\nvoid wil_update_net_queues(struct wil6210_priv *wil, struct wil6210_vif *vif,\n\t\t\t   struct wil_ring *ring, bool check_stop)\n{\n\tspin_lock(&wil->net_queue_lock);\n\t__wil_update_net_queues(wil, vif, ring, check_stop);\n\tspin_unlock(&wil->net_queue_lock);\n}\n\nvoid wil_update_net_queues_bh(struct wil6210_priv *wil, struct wil6210_vif *vif,\n\t\t\t      struct wil_ring *ring, bool check_stop)\n{\n\tspin_lock_bh(&wil->net_queue_lock);\n\t__wil_update_net_queues(wil, vif, ring, check_stop);\n\tspin_unlock_bh(&wil->net_queue_lock);\n}\n\nnetdev_tx_t wil_start_xmit(struct sk_buff *skb, struct net_device *ndev)\n{\n\tstruct wil6210_vif *vif = ndev_to_vif(ndev);\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tconst u8 *da = wil_skb_get_da(skb);\n\tbool bcast = is_multicast_ether_addr(da);\n\tstruct wil_ring *ring;\n\tstatic bool pr_once_fw;\n\tint rc;\n\n\twil_dbg_txrx(wil, \"start_xmit\\n\");\n\tif (unlikely(!test_bit(wil_status_fwready, wil->status))) {\n\t\tif (!pr_once_fw) {\n\t\t\twil_err(wil, \"FW not ready\\n\");\n\t\t\tpr_once_fw = true;\n\t\t}\n\t\tgoto drop;\n\t}\n\tif (unlikely(!test_bit(wil_vif_fwconnected, vif->status))) {\n\t\twil_dbg_ratelimited(wil,\n\t\t\t\t    \"VIF not connected, packet dropped\\n\");\n\t\tgoto drop;\n\t}\n\tif (unlikely(vif->wdev.iftype == NL80211_IFTYPE_MONITOR)) {\n\t\twil_err(wil, \"Xmit in monitor mode not supported\\n\");\n\t\tgoto drop;\n\t}\n\tpr_once_fw = false;\n\n\t \n\tif (vif->wdev.iftype == NL80211_IFTYPE_STATION && !vif->pbss) {\n\t\t \n\t\tring = wil_find_tx_ring_sta(wil, vif, skb);\n\t} else if (bcast) {\n\t\tif (vif->pbss || wil_check_multicast_to_unicast(wil, skb))\n\t\t\t \n\t\t\tring = wil_find_tx_bcast_2(wil, vif, skb);\n\t\telse if (vif->wdev.iftype == NL80211_IFTYPE_AP)\n\t\t\t \n\t\t\tring = wil_find_tx_bcast_1(wil, vif, skb);\n\t\telse\n\t\t\t \n\t\t\tring = wil_find_tx_bcast_2(wil, vif, skb);\n\t} else {\n\t\t \n\t\tring = wil_find_tx_ucast(wil, vif, skb);\n\t}\n\tif (unlikely(!ring)) {\n\t\twil_dbg_txrx(wil, \"No Tx RING found for %pM\\n\", da);\n\t\tgoto drop;\n\t}\n\t \n\trc = wil_tx_ring(wil, vif, ring, skb);\n\n\tswitch (rc) {\n\tcase 0:\n\t\t \n\t\twil_update_net_queues_bh(wil, vif, ring, true);\n\t\t \n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\tcase -ENOMEM:\n\t\tif (drop_if_ring_full)\n\t\t\tgoto drop;\n\t\treturn NETDEV_TX_BUSY;\n\tdefault:\n\t\tbreak;  \n\t}\n drop:\n\tndev->stats.tx_dropped++;\n\tdev_kfree_skb_any(skb);\n\n\treturn NET_XMIT_DROP;\n}\n\nvoid wil_tx_latency_calc(struct wil6210_priv *wil, struct sk_buff *skb,\n\t\t\t struct wil_sta_info *sta)\n{\n\tint skb_time_us;\n\tint bin;\n\n\tif (!wil->tx_latency)\n\t\treturn;\n\n\tif (ktime_to_ms(*(ktime_t *)&skb->cb) == 0)\n\t\treturn;\n\n\tskb_time_us = ktime_us_delta(ktime_get(), *(ktime_t *)&skb->cb);\n\tbin = skb_time_us / wil->tx_latency_res;\n\tbin = min_t(int, bin, WIL_NUM_LATENCY_BINS - 1);\n\n\twil_dbg_txrx(wil, \"skb time %dus => bin %d\\n\", skb_time_us, bin);\n\tsta->tx_latency_bins[bin]++;\n\tsta->stats.tx_latency_total_us += skb_time_us;\n\tif (skb_time_us < sta->stats.tx_latency_min_us)\n\t\tsta->stats.tx_latency_min_us = skb_time_us;\n\tif (skb_time_us > sta->stats.tx_latency_max_us)\n\t\tsta->stats.tx_latency_max_us = skb_time_us;\n}\n\n \nint wil_tx_complete(struct wil6210_vif *vif, int ringid)\n{\n\tstruct wil6210_priv *wil = vif_to_wil(vif);\n\tstruct net_device *ndev = vif_to_ndev(vif);\n\tstruct device *dev = wil_to_dev(wil);\n\tstruct wil_ring *vring = &wil->ring_tx[ringid];\n\tstruct wil_ring_tx_data *txdata = &wil->ring_tx_data[ringid];\n\tint done = 0;\n\tint cid = wil->ring2cid_tid[ringid][0];\n\tstruct wil_net_stats *stats = NULL;\n\tvolatile struct vring_tx_desc *_d;\n\tint used_before_complete;\n\tint used_new;\n\n\tif (unlikely(!vring->va)) {\n\t\twil_err(wil, \"Tx irq[%d]: vring not initialized\\n\", ringid);\n\t\treturn 0;\n\t}\n\n\tif (unlikely(!txdata->enabled)) {\n\t\twil_info(wil, \"Tx irq[%d]: vring disabled\\n\", ringid);\n\t\treturn 0;\n\t}\n\n\twil_dbg_txrx(wil, \"tx_complete: (%d)\\n\", ringid);\n\n\tused_before_complete = wil_ring_used_tx(vring);\n\n\tif (cid < wil->max_assoc_sta)\n\t\tstats = &wil->sta[cid].stats;\n\n\twhile (!wil_ring_is_empty(vring)) {\n\t\tint new_swtail;\n\t\tstruct wil_ctx *ctx = &vring->ctx[vring->swtail];\n\t\t \n\t\tint lf = (vring->swtail + ctx->nr_frags) % vring->size;\n\t\t \n\n\t\t_d = &vring->va[lf].tx.legacy;\n\t\tif (unlikely(!(_d->dma.status & TX_DMA_STATUS_DU)))\n\t\t\tbreak;\n\n\t\tnew_swtail = (lf + 1) % vring->size;\n\t\twhile (vring->swtail != new_swtail) {\n\t\t\tstruct vring_tx_desc dd, *d = &dd;\n\t\t\tu16 dmalen;\n\t\t\tstruct sk_buff *skb;\n\n\t\t\tctx = &vring->ctx[vring->swtail];\n\t\t\tskb = ctx->skb;\n\t\t\t_d = &vring->va[vring->swtail].tx.legacy;\n\n\t\t\t*d = *_d;\n\n\t\t\tdmalen = le16_to_cpu(d->dma.length);\n\t\t\ttrace_wil6210_tx_done(ringid, vring->swtail, dmalen,\n\t\t\t\t\t      d->dma.error);\n\t\t\twil_dbg_txrx(wil,\n\t\t\t\t     \"TxC[%2d][%3d] : %d bytes, status 0x%02x err 0x%02x\\n\",\n\t\t\t\t     ringid, vring->swtail, dmalen,\n\t\t\t\t     d->dma.status, d->dma.error);\n\t\t\twil_hex_dump_txrx(\"TxCD \", DUMP_PREFIX_NONE, 32, 4,\n\t\t\t\t\t  (const void *)d, sizeof(*d), false);\n\n\t\t\twil->txrx_ops.tx_desc_unmap(dev,\n\t\t\t\t\t\t    (union wil_tx_desc *)d,\n\t\t\t\t\t\t    ctx);\n\n\t\t\tif (skb) {\n\t\t\t\tif (likely(d->dma.error == 0)) {\n\t\t\t\t\tndev->stats.tx_packets++;\n\t\t\t\t\tndev->stats.tx_bytes += skb->len;\n\t\t\t\t\tif (stats) {\n\t\t\t\t\t\tstats->tx_packets++;\n\t\t\t\t\t\tstats->tx_bytes += skb->len;\n\n\t\t\t\t\t\twil_tx_latency_calc(wil, skb,\n\t\t\t\t\t\t\t&wil->sta[cid]);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tndev->stats.tx_errors++;\n\t\t\t\t\tif (stats)\n\t\t\t\t\t\tstats->tx_errors++;\n\t\t\t\t}\n\n\t\t\t\tif (skb->protocol == cpu_to_be16(ETH_P_PAE))\n\t\t\t\t\twil_tx_complete_handle_eapol(vif, skb);\n\n\t\t\t\twil_consume_skb(skb, d->dma.error == 0);\n\t\t\t}\n\t\t\tmemset(ctx, 0, sizeof(*ctx));\n\t\t\t \n\t\t\twmb();\n\t\t\t \n\t\t\tvring->swtail = wil_ring_next_tail(vring);\n\t\t\tdone++;\n\t\t}\n\t}\n\n\t \n\tused_new = wil_ring_used_tx(vring);\n\tif (wil_val_in_range(wil->ring_idle_trsh,\n\t\t\t     used_new, used_before_complete)) {\n\t\twil_dbg_txrx(wil, \"Ring[%2d] idle %d -> %d\\n\",\n\t\t\t     ringid, used_before_complete, used_new);\n\t\ttxdata->last_idle = get_cycles();\n\t}\n\n\t \n\tif (done)\n\t\twil_update_net_queues(wil, vif, vring, false);\n\n\treturn done;\n}\n\nstatic inline int wil_tx_init(struct wil6210_priv *wil)\n{\n\treturn 0;\n}\n\nstatic inline void wil_tx_fini(struct wil6210_priv *wil) {}\n\nstatic void wil_get_reorder_params(struct wil6210_priv *wil,\n\t\t\t\t   struct sk_buff *skb, int *tid, int *cid,\n\t\t\t\t   int *mid, u16 *seq, int *mcast, int *retry)\n{\n\tstruct vring_rx_desc *d = wil_skb_rxdesc(skb);\n\n\t*tid = wil_rxdesc_tid(d);\n\t*cid = wil_skb_get_cid(skb);\n\t*mid = wil_rxdesc_mid(d);\n\t*seq = wil_rxdesc_seq(d);\n\t*mcast = wil_rxdesc_mcast(d);\n\t*retry = wil_rxdesc_retry(d);\n}\n\nvoid wil_init_txrx_ops_legacy_dma(struct wil6210_priv *wil)\n{\n\twil->txrx_ops.configure_interrupt_moderation =\n\t\twil_configure_interrupt_moderation;\n\t \n\twil->txrx_ops.tx_desc_map = wil_tx_desc_map;\n\twil->txrx_ops.tx_desc_unmap = wil_txdesc_unmap;\n\twil->txrx_ops.tx_ring_tso =  __wil_tx_vring_tso;\n\twil->txrx_ops.ring_init_tx = wil_vring_init_tx;\n\twil->txrx_ops.ring_fini_tx = wil_vring_free;\n\twil->txrx_ops.ring_init_bcast = wil_vring_init_bcast;\n\twil->txrx_ops.tx_init = wil_tx_init;\n\twil->txrx_ops.tx_fini = wil_tx_fini;\n\twil->txrx_ops.tx_ring_modify = wil_tx_vring_modify;\n\t \n\twil->txrx_ops.rx_init = wil_rx_init;\n\twil->txrx_ops.wmi_addba_rx_resp = wmi_addba_rx_resp;\n\twil->txrx_ops.get_reorder_params = wil_get_reorder_params;\n\twil->txrx_ops.get_netif_rx_params =\n\t\twil_get_netif_rx_params;\n\twil->txrx_ops.rx_crypto_check = wil_rx_crypto_check;\n\twil->txrx_ops.rx_error_check = wil_rx_error_check;\n\twil->txrx_ops.is_rx_idle = wil_is_rx_idle;\n\twil->txrx_ops.rx_fini = wil_rx_fini;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}