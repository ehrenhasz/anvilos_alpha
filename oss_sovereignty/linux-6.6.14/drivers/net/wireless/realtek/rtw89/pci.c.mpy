{
  "module_name": "pci.c",
  "hash_id": "b4255b388c36ad63eb028ae7e9fee5bd938cd343d3db73e604251bedd269e022",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/realtek/rtw89/pci.c",
  "human_readable_source": "\n \n\n#include <linux/pci.h>\n\n#include \"mac.h\"\n#include \"pci.h\"\n#include \"reg.h\"\n#include \"ser.h\"\n\nstatic bool rtw89_pci_disable_clkreq;\nstatic bool rtw89_pci_disable_aspm_l1;\nstatic bool rtw89_pci_disable_l1ss;\nmodule_param_named(disable_clkreq, rtw89_pci_disable_clkreq, bool, 0644);\nmodule_param_named(disable_aspm_l1, rtw89_pci_disable_aspm_l1, bool, 0644);\nmodule_param_named(disable_aspm_l1ss, rtw89_pci_disable_l1ss, bool, 0644);\nMODULE_PARM_DESC(disable_clkreq, \"Set Y to disable PCI clkreq support\");\nMODULE_PARM_DESC(disable_aspm_l1, \"Set Y to disable PCI ASPM L1 support\");\nMODULE_PARM_DESC(disable_aspm_l1ss, \"Set Y to disable PCI L1SS support\");\n\nstatic int rtw89_pci_rst_bdram_pcie(struct rtw89_dev *rtwdev)\n{\n\tu32 val;\n\tint ret;\n\n\trtw89_write32(rtwdev, R_AX_PCIE_INIT_CFG1,\n\t\t      rtw89_read32(rtwdev, R_AX_PCIE_INIT_CFG1) | B_AX_RST_BDRAM);\n\n\tret = read_poll_timeout_atomic(rtw89_read32, val, !(val & B_AX_RST_BDRAM),\n\t\t\t\t       1, RTW89_PCI_POLL_BDRAM_RST_CNT, false,\n\t\t\t\t       rtwdev, R_AX_PCIE_INIT_CFG1);\n\n\tif (ret)\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\nstatic u32 rtw89_pci_dma_recalc(struct rtw89_dev *rtwdev,\n\t\t\t\tstruct rtw89_pci_dma_ring *bd_ring,\n\t\t\t\tu32 cur_idx, bool tx)\n{\n\tu32 cnt, cur_rp, wp, rp, len;\n\n\trp = bd_ring->rp;\n\twp = bd_ring->wp;\n\tlen = bd_ring->len;\n\n\tcur_rp = FIELD_GET(TXBD_HW_IDX_MASK, cur_idx);\n\tif (tx)\n\t\tcnt = cur_rp >= rp ? cur_rp - rp : len - (rp - cur_rp);\n\telse\n\t\tcnt = cur_rp >= wp ? cur_rp - wp : len - (wp - cur_rp);\n\n\tbd_ring->rp = cur_rp;\n\n\treturn cnt;\n}\n\nstatic u32 rtw89_pci_txbd_recalc(struct rtw89_dev *rtwdev,\n\t\t\t\t struct rtw89_pci_tx_ring *tx_ring)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &tx_ring->bd_ring;\n\tu32 addr_idx = bd_ring->addr.idx;\n\tu32 cnt, idx;\n\n\tidx = rtw89_read32(rtwdev, addr_idx);\n\tcnt = rtw89_pci_dma_recalc(rtwdev, bd_ring, idx, true);\n\n\treturn cnt;\n}\n\nstatic void rtw89_pci_release_fwcmd(struct rtw89_dev *rtwdev,\n\t\t\t\t    struct rtw89_pci *rtwpci,\n\t\t\t\t    u32 cnt, bool release_all)\n{\n\tstruct rtw89_pci_tx_data *tx_data;\n\tstruct sk_buff *skb;\n\tu32 qlen;\n\n\twhile (cnt--) {\n\t\tskb = skb_dequeue(&rtwpci->h2c_queue);\n\t\tif (!skb) {\n\t\t\trtw89_err(rtwdev, \"failed to pre-release fwcmd\\n\");\n\t\t\treturn;\n\t\t}\n\t\tskb_queue_tail(&rtwpci->h2c_release_queue, skb);\n\t}\n\n\tqlen = skb_queue_len(&rtwpci->h2c_release_queue);\n\tif (!release_all)\n\t       qlen = qlen > RTW89_PCI_MULTITAG ? qlen - RTW89_PCI_MULTITAG : 0;\n\n\twhile (qlen--) {\n\t\tskb = skb_dequeue(&rtwpci->h2c_release_queue);\n\t\tif (!skb) {\n\t\t\trtw89_err(rtwdev, \"failed to release fwcmd\\n\");\n\t\t\treturn;\n\t\t}\n\t\ttx_data = RTW89_PCI_TX_SKB_CB(skb);\n\t\tdma_unmap_single(&rtwpci->pdev->dev, tx_data->dma, skb->len,\n\t\t\t\t DMA_TO_DEVICE);\n\t\tdev_kfree_skb_any(skb);\n\t}\n}\n\nstatic void rtw89_pci_reclaim_tx_fwcmd(struct rtw89_dev *rtwdev,\n\t\t\t\t       struct rtw89_pci *rtwpci)\n{\n\tstruct rtw89_pci_tx_ring *tx_ring = &rtwpci->tx_rings[RTW89_TXCH_CH12];\n\tu32 cnt;\n\n\tcnt = rtw89_pci_txbd_recalc(rtwdev, tx_ring);\n\tif (!cnt)\n\t\treturn;\n\trtw89_pci_release_fwcmd(rtwdev, rtwpci, cnt, false);\n}\n\nstatic u32 rtw89_pci_rxbd_recalc(struct rtw89_dev *rtwdev,\n\t\t\t\t struct rtw89_pci_rx_ring *rx_ring)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &rx_ring->bd_ring;\n\tu32 addr_idx = bd_ring->addr.idx;\n\tu32 cnt, idx;\n\n\tidx = rtw89_read32(rtwdev, addr_idx);\n\tcnt = rtw89_pci_dma_recalc(rtwdev, bd_ring, idx, false);\n\n\treturn cnt;\n}\n\nstatic void rtw89_pci_sync_skb_for_cpu(struct rtw89_dev *rtwdev,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct rtw89_pci_rx_info *rx_info;\n\tdma_addr_t dma;\n\n\trx_info = RTW89_PCI_RX_SKB_CB(skb);\n\tdma = rx_info->dma;\n\tdma_sync_single_for_cpu(rtwdev->dev, dma, RTW89_PCI_RX_BUF_SIZE,\n\t\t\t\tDMA_FROM_DEVICE);\n}\n\nstatic void rtw89_pci_sync_skb_for_device(struct rtw89_dev *rtwdev,\n\t\t\t\t\t  struct sk_buff *skb)\n{\n\tstruct rtw89_pci_rx_info *rx_info;\n\tdma_addr_t dma;\n\n\trx_info = RTW89_PCI_RX_SKB_CB(skb);\n\tdma = rx_info->dma;\n\tdma_sync_single_for_device(rtwdev->dev, dma, RTW89_PCI_RX_BUF_SIZE,\n\t\t\t\t   DMA_FROM_DEVICE);\n}\n\nstatic int rtw89_pci_rxbd_info_update(struct rtw89_dev *rtwdev,\n\t\t\t\t      struct sk_buff *skb)\n{\n\tstruct rtw89_pci_rxbd_info *rxbd_info;\n\tstruct rtw89_pci_rx_info *rx_info = RTW89_PCI_RX_SKB_CB(skb);\n\n\trxbd_info = (struct rtw89_pci_rxbd_info *)skb->data;\n\trx_info->fs = le32_get_bits(rxbd_info->dword, RTW89_PCI_RXBD_FS);\n\trx_info->ls = le32_get_bits(rxbd_info->dword, RTW89_PCI_RXBD_LS);\n\trx_info->len = le32_get_bits(rxbd_info->dword, RTW89_PCI_RXBD_WRITE_SIZE);\n\trx_info->tag = le32_get_bits(rxbd_info->dword, RTW89_PCI_RXBD_TAG);\n\n\treturn 0;\n}\n\nstatic void rtw89_pci_ctrl_txdma_ch_pcie(struct rtw89_dev *rtwdev, bool enable)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tconst struct rtw89_reg_def *dma_stop1 = &info->dma_stop1;\n\tconst struct rtw89_reg_def *dma_stop2 = &info->dma_stop2;\n\n\tif (enable) {\n\t\trtw89_write32_clr(rtwdev, dma_stop1->addr, dma_stop1->mask);\n\t\tif (dma_stop2->addr)\n\t\t\trtw89_write32_clr(rtwdev, dma_stop2->addr, dma_stop2->mask);\n\t} else {\n\t\trtw89_write32_set(rtwdev, dma_stop1->addr, dma_stop1->mask);\n\t\tif (dma_stop2->addr)\n\t\t\trtw89_write32_set(rtwdev, dma_stop2->addr, dma_stop2->mask);\n\t}\n}\n\nstatic void rtw89_pci_ctrl_txdma_fw_ch_pcie(struct rtw89_dev *rtwdev, bool enable)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tconst struct rtw89_reg_def *dma_stop1 = &info->dma_stop1;\n\n\tif (enable)\n\t\trtw89_write32_clr(rtwdev, dma_stop1->addr, B_AX_STOP_CH12);\n\telse\n\t\trtw89_write32_set(rtwdev, dma_stop1->addr, B_AX_STOP_CH12);\n}\n\nstatic bool\nrtw89_skb_put_rx_data(struct rtw89_dev *rtwdev, bool fs, bool ls,\n\t\t      struct sk_buff *new,\n\t\t      const struct sk_buff *skb, u32 offset,\n\t\t      const struct rtw89_pci_rx_info *rx_info,\n\t\t      const struct rtw89_rx_desc_info *desc_info)\n{\n\tu32 copy_len = rx_info->len - offset;\n\n\tif (unlikely(skb_tailroom(new) < copy_len)) {\n\t\trtw89_debug(rtwdev, RTW89_DBG_TXRX,\n\t\t\t    \"invalid rx data length bd_len=%d desc_len=%d offset=%d (fs=%d ls=%d)\\n\",\n\t\t\t    rx_info->len, desc_info->pkt_size, offset, fs, ls);\n\t\trtw89_hex_dump(rtwdev, RTW89_DBG_TXRX, \"rx_data: \",\n\t\t\t       skb->data, rx_info->len);\n\t\t \n\t\tif (fs && ls) {\n\t\t\tcopy_len = desc_info->pkt_size;\n\t\t} else {\n\t\t\trtw89_info(rtwdev, \"drop rx data due to invalid length\\n\");\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tskb_put_data(new, skb->data + offset, copy_len);\n\n\treturn true;\n}\n\nstatic u32 rtw89_pci_rxbd_deliver_skbs(struct rtw89_dev *rtwdev,\n\t\t\t\t       struct rtw89_pci_rx_ring *rx_ring)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &rx_ring->bd_ring;\n\tstruct rtw89_pci_rx_info *rx_info;\n\tstruct rtw89_rx_desc_info *desc_info = &rx_ring->diliver_desc;\n\tstruct sk_buff *new = rx_ring->diliver_skb;\n\tstruct sk_buff *skb;\n\tu32 rxinfo_size = sizeof(struct rtw89_pci_rxbd_info);\n\tu32 offset;\n\tu32 cnt = 1;\n\tbool fs, ls;\n\tint ret;\n\n\tskb = rx_ring->buf[bd_ring->wp];\n\trtw89_pci_sync_skb_for_cpu(rtwdev, skb);\n\n\tret = rtw89_pci_rxbd_info_update(rtwdev, skb);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to update %d RXBD info: %d\\n\",\n\t\t\t  bd_ring->wp, ret);\n\t\tgoto err_sync_device;\n\t}\n\n\trx_info = RTW89_PCI_RX_SKB_CB(skb);\n\tfs = rx_info->fs;\n\tls = rx_info->ls;\n\n\tif (fs) {\n\t\tif (new) {\n\t\t\trtw89_debug(rtwdev, RTW89_DBG_UNEXP,\n\t\t\t\t    \"skb should not be ready before first segment start\\n\");\n\t\t\tgoto err_sync_device;\n\t\t}\n\t\tif (desc_info->ready) {\n\t\t\trtw89_warn(rtwdev, \"desc info should not be ready before first segment start\\n\");\n\t\t\tgoto err_sync_device;\n\t\t}\n\n\t\trtw89_chip_query_rxdesc(rtwdev, desc_info, skb->data, rxinfo_size);\n\n\t\tnew = rtw89_alloc_skb_for_rx(rtwdev, desc_info->pkt_size);\n\t\tif (!new)\n\t\t\tgoto err_sync_device;\n\n\t\trx_ring->diliver_skb = new;\n\n\t\t \n\t\toffset = desc_info->offset + desc_info->rxd_len;\n\t} else {\n\t\toffset = sizeof(struct rtw89_pci_rxbd_info);\n\t\tif (!new) {\n\t\t\trtw89_debug(rtwdev, RTW89_DBG_UNEXP, \"no last skb\\n\");\n\t\t\tgoto err_sync_device;\n\t\t}\n\t}\n\tif (!rtw89_skb_put_rx_data(rtwdev, fs, ls, new, skb, offset, rx_info, desc_info))\n\t\tgoto err_sync_device;\n\trtw89_pci_sync_skb_for_device(rtwdev, skb);\n\trtw89_pci_rxbd_increase(rx_ring, 1);\n\n\tif (!desc_info->ready) {\n\t\trtw89_warn(rtwdev, \"no rx desc information\\n\");\n\t\tgoto err_free_resource;\n\t}\n\tif (ls) {\n\t\trtw89_core_rx(rtwdev, desc_info, new);\n\t\trx_ring->diliver_skb = NULL;\n\t\tdesc_info->ready = false;\n\t}\n\n\treturn cnt;\n\nerr_sync_device:\n\trtw89_pci_sync_skb_for_device(rtwdev, skb);\n\trtw89_pci_rxbd_increase(rx_ring, 1);\nerr_free_resource:\n\tif (new)\n\t\tdev_kfree_skb_any(new);\n\trx_ring->diliver_skb = NULL;\n\tdesc_info->ready = false;\n\n\treturn cnt;\n}\n\nstatic void rtw89_pci_rxbd_deliver(struct rtw89_dev *rtwdev,\n\t\t\t\t   struct rtw89_pci_rx_ring *rx_ring,\n\t\t\t\t   u32 cnt)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &rx_ring->bd_ring;\n\tu32 rx_cnt;\n\n\twhile (cnt && rtwdev->napi_budget_countdown > 0) {\n\t\trx_cnt = rtw89_pci_rxbd_deliver_skbs(rtwdev, rx_ring);\n\t\tif (!rx_cnt) {\n\t\t\trtw89_err(rtwdev, \"failed to deliver RXBD skb\\n\");\n\n\t\t\t \n\t\t\trtw89_pci_rxbd_increase(rx_ring, cnt);\n\t\t\tbreak;\n\t\t}\n\n\t\tcnt -= rx_cnt;\n\t}\n\n\trtw89_write16(rtwdev, bd_ring->addr.idx, bd_ring->wp);\n}\n\nstatic int rtw89_pci_poll_rxq_dma(struct rtw89_dev *rtwdev,\n\t\t\t\t  struct rtw89_pci *rtwpci, int budget)\n{\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tint countdown = rtwdev->napi_budget_countdown;\n\tu32 cnt;\n\n\trx_ring = &rtwpci->rx_rings[RTW89_RXCH_RXQ];\n\n\tcnt = rtw89_pci_rxbd_recalc(rtwdev, rx_ring);\n\tif (!cnt)\n\t\treturn 0;\n\n\tcnt = min_t(u32, budget, cnt);\n\n\trtw89_pci_rxbd_deliver(rtwdev, rx_ring, cnt);\n\n\t \n\tif (rtwdev->napi_budget_countdown <= 0)\n\t\treturn budget;\n\n\treturn budget - countdown;\n}\n\nstatic void rtw89_pci_tx_status(struct rtw89_dev *rtwdev,\n\t\t\t\tstruct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\tstruct sk_buff *skb, u8 tx_status)\n{\n\tstruct rtw89_tx_skb_data *skb_data = RTW89_TX_SKB_CB(skb);\n\tstruct ieee80211_tx_info *info;\n\n\trtw89_core_tx_wait_complete(rtwdev, skb_data, tx_status == RTW89_TX_DONE);\n\n\tinfo = IEEE80211_SKB_CB(skb);\n\tieee80211_tx_info_clear_status(info);\n\n\tif (info->flags & IEEE80211_TX_CTL_NO_ACK)\n\t\tinfo->flags |= IEEE80211_TX_STAT_NOACK_TRANSMITTED;\n\tif (tx_status == RTW89_TX_DONE) {\n\t\tinfo->flags |= IEEE80211_TX_STAT_ACK;\n\t\ttx_ring->tx_acked++;\n\t} else {\n\t\tif (info->flags & IEEE80211_TX_CTL_REQ_TX_STATUS)\n\t\t\trtw89_debug(rtwdev, RTW89_DBG_FW,\n\t\t\t\t    \"failed to TX of status %x\\n\", tx_status);\n\t\tswitch (tx_status) {\n\t\tcase RTW89_TX_RETRY_LIMIT:\n\t\t\ttx_ring->tx_retry_lmt++;\n\t\t\tbreak;\n\t\tcase RTW89_TX_LIFE_TIME:\n\t\t\ttx_ring->tx_life_time++;\n\t\t\tbreak;\n\t\tcase RTW89_TX_MACID_DROP:\n\t\t\ttx_ring->tx_mac_id_drop++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\trtw89_warn(rtwdev, \"invalid TX status %x\\n\", tx_status);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tieee80211_tx_status_ni(rtwdev->hw, skb);\n}\n\nstatic void rtw89_pci_reclaim_txbd(struct rtw89_dev *rtwdev, struct rtw89_pci_tx_ring *tx_ring)\n{\n\tstruct rtw89_pci_tx_wd *txwd;\n\tu32 cnt;\n\n\tcnt = rtw89_pci_txbd_recalc(rtwdev, tx_ring);\n\twhile (cnt--) {\n\t\ttxwd = list_first_entry_or_null(&tx_ring->busy_pages, struct rtw89_pci_tx_wd, list);\n\t\tif (!txwd) {\n\t\t\trtw89_warn(rtwdev, \"No busy txwd pages available\\n\");\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_del_init(&txwd->list);\n\n\t\t \n\t\tif (skb_queue_len(&txwd->queue) == 0)\n\t\t\trtw89_pci_enqueue_txwd(tx_ring, txwd);\n\t}\n}\n\nstatic void rtw89_pci_release_busy_txwd(struct rtw89_dev *rtwdev,\n\t\t\t\t\tstruct rtw89_pci_tx_ring *tx_ring)\n{\n\tstruct rtw89_pci_tx_wd_ring *wd_ring = &tx_ring->wd_ring;\n\tstruct rtw89_pci_tx_wd *txwd;\n\tint i;\n\n\tfor (i = 0; i < wd_ring->page_num; i++) {\n\t\ttxwd = list_first_entry_or_null(&tx_ring->busy_pages, struct rtw89_pci_tx_wd, list);\n\t\tif (!txwd)\n\t\t\tbreak;\n\n\t\tlist_del_init(&txwd->list);\n\t}\n}\n\nstatic void rtw89_pci_release_txwd_skb(struct rtw89_dev *rtwdev,\n\t\t\t\t       struct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\t       struct rtw89_pci_tx_wd *txwd, u16 seq,\n\t\t\t\t       u8 tx_status)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_data *tx_data;\n\tstruct sk_buff *skb, *tmp;\n\tu8 txch = tx_ring->txch;\n\n\tif (!list_empty(&txwd->list)) {\n\t\trtw89_pci_reclaim_txbd(rtwdev, tx_ring);\n\t\t \n\t\tif (!rtwpci->low_power && !list_empty(&txwd->list))\n\t\t\trtw89_warn(rtwdev, \"queue %d txwd %d is not idle\\n\",\n\t\t\t\t   txch, seq);\n\t}\n\n\tskb_queue_walk_safe(&txwd->queue, skb, tmp) {\n\t\tskb_unlink(skb, &txwd->queue);\n\n\t\ttx_data = RTW89_PCI_TX_SKB_CB(skb);\n\t\tdma_unmap_single(&rtwpci->pdev->dev, tx_data->dma, skb->len,\n\t\t\t\t DMA_TO_DEVICE);\n\n\t\trtw89_pci_tx_status(rtwdev, tx_ring, skb, tx_status);\n\t}\n\n\tif (list_empty(&txwd->list))\n\t\trtw89_pci_enqueue_txwd(tx_ring, txwd);\n}\n\nstatic void rtw89_pci_release_rpp(struct rtw89_dev *rtwdev,\n\t\t\t\t  struct rtw89_pci_rpp_fmt *rpp)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring;\n\tstruct rtw89_pci_tx_wd_ring *wd_ring;\n\tstruct rtw89_pci_tx_wd *txwd;\n\tu16 seq;\n\tu8 qsel, tx_status, txch;\n\n\tseq = le32_get_bits(rpp->dword, RTW89_PCI_RPP_SEQ);\n\tqsel = le32_get_bits(rpp->dword, RTW89_PCI_RPP_QSEL);\n\ttx_status = le32_get_bits(rpp->dword, RTW89_PCI_RPP_TX_STATUS);\n\ttxch = rtw89_core_get_ch_dma(rtwdev, qsel);\n\n\tif (txch == RTW89_TXCH_CH12) {\n\t\trtw89_warn(rtwdev, \"should no fwcmd release report\\n\");\n\t\treturn;\n\t}\n\n\ttx_ring = &rtwpci->tx_rings[txch];\n\twd_ring = &tx_ring->wd_ring;\n\ttxwd = &wd_ring->pages[seq];\n\n\trtw89_pci_release_txwd_skb(rtwdev, tx_ring, txwd, seq, tx_status);\n}\n\nstatic void rtw89_pci_release_pending_txwd_skb(struct rtw89_dev *rtwdev,\n\t\t\t\t\t       struct rtw89_pci_tx_ring *tx_ring)\n{\n\tstruct rtw89_pci_tx_wd_ring *wd_ring = &tx_ring->wd_ring;\n\tstruct rtw89_pci_tx_wd *txwd;\n\tint i;\n\n\tfor (i = 0; i < wd_ring->page_num; i++) {\n\t\ttxwd = &wd_ring->pages[i];\n\n\t\tif (!list_empty(&txwd->list))\n\t\t\tcontinue;\n\n\t\trtw89_pci_release_txwd_skb(rtwdev, tx_ring, txwd, i, RTW89_TX_MACID_DROP);\n\t}\n}\n\nstatic u32 rtw89_pci_release_tx_skbs(struct rtw89_dev *rtwdev,\n\t\t\t\t     struct rtw89_pci_rx_ring *rx_ring,\n\t\t\t\t     u32 max_cnt)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &rx_ring->bd_ring;\n\tstruct rtw89_pci_rx_info *rx_info;\n\tstruct rtw89_pci_rpp_fmt *rpp;\n\tstruct rtw89_rx_desc_info desc_info = {};\n\tstruct sk_buff *skb;\n\tu32 cnt = 0;\n\tu32 rpp_size = sizeof(struct rtw89_pci_rpp_fmt);\n\tu32 rxinfo_size = sizeof(struct rtw89_pci_rxbd_info);\n\tu32 offset;\n\tint ret;\n\n\tskb = rx_ring->buf[bd_ring->wp];\n\trtw89_pci_sync_skb_for_cpu(rtwdev, skb);\n\n\tret = rtw89_pci_rxbd_info_update(rtwdev, skb);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to update %d RXBD info: %d\\n\",\n\t\t\t  bd_ring->wp, ret);\n\t\tgoto err_sync_device;\n\t}\n\n\trx_info = RTW89_PCI_RX_SKB_CB(skb);\n\tif (!rx_info->fs || !rx_info->ls) {\n\t\trtw89_err(rtwdev, \"cannot process RP frame not set FS/LS\\n\");\n\t\treturn cnt;\n\t}\n\n\trtw89_chip_query_rxdesc(rtwdev, &desc_info, skb->data, rxinfo_size);\n\n\t \n\toffset = desc_info.offset + desc_info.rxd_len;\n\tfor (; offset + rpp_size <= rx_info->len; offset += rpp_size) {\n\t\trpp = (struct rtw89_pci_rpp_fmt *)(skb->data + offset);\n\t\trtw89_pci_release_rpp(rtwdev, rpp);\n\t}\n\n\trtw89_pci_sync_skb_for_device(rtwdev, skb);\n\trtw89_pci_rxbd_increase(rx_ring, 1);\n\tcnt++;\n\n\treturn cnt;\n\nerr_sync_device:\n\trtw89_pci_sync_skb_for_device(rtwdev, skb);\n\treturn 0;\n}\n\nstatic void rtw89_pci_release_tx(struct rtw89_dev *rtwdev,\n\t\t\t\t struct rtw89_pci_rx_ring *rx_ring,\n\t\t\t\t u32 cnt)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &rx_ring->bd_ring;\n\tu32 release_cnt;\n\n\twhile (cnt) {\n\t\trelease_cnt = rtw89_pci_release_tx_skbs(rtwdev, rx_ring, cnt);\n\t\tif (!release_cnt) {\n\t\t\trtw89_err(rtwdev, \"failed to release TX skbs\\n\");\n\n\t\t\t \n\t\t\trtw89_pci_rxbd_increase(rx_ring, cnt);\n\t\t\tbreak;\n\t\t}\n\n\t\tcnt -= release_cnt;\n\t}\n\n\trtw89_write16(rtwdev, bd_ring->addr.idx, bd_ring->wp);\n}\n\nstatic int rtw89_pci_poll_rpq_dma(struct rtw89_dev *rtwdev,\n\t\t\t\t  struct rtw89_pci *rtwpci, int budget)\n{\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tu32 cnt;\n\tint work_done;\n\n\trx_ring = &rtwpci->rx_rings[RTW89_RXCH_RPQ];\n\n\tspin_lock_bh(&rtwpci->trx_lock);\n\n\tcnt = rtw89_pci_rxbd_recalc(rtwdev, rx_ring);\n\tif (cnt == 0)\n\t\tgoto out_unlock;\n\n\trtw89_pci_release_tx(rtwdev, rx_ring, cnt);\n\nout_unlock:\n\tspin_unlock_bh(&rtwpci->trx_lock);\n\n\t \n\twork_done = min_t(int, cnt, budget);\n\trtwdev->napi_budget_countdown -= work_done;\n\n\treturn work_done;\n}\n\nstatic void rtw89_pci_isr_rxd_unavail(struct rtw89_dev *rtwdev,\n\t\t\t\t      struct rtw89_pci *rtwpci)\n{\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tstruct rtw89_pci_dma_ring *bd_ring;\n\tu32 reg_idx;\n\tu16 hw_idx, hw_idx_next, host_idx;\n\tint i;\n\n\tfor (i = 0; i < RTW89_RXCH_NUM; i++) {\n\t\trx_ring = &rtwpci->rx_rings[i];\n\t\tbd_ring = &rx_ring->bd_ring;\n\n\t\treg_idx = rtw89_read32(rtwdev, bd_ring->addr.idx);\n\t\thw_idx = FIELD_GET(TXBD_HW_IDX_MASK, reg_idx);\n\t\thost_idx = FIELD_GET(TXBD_HOST_IDX_MASK, reg_idx);\n\t\thw_idx_next = (hw_idx + 1) % bd_ring->len;\n\n\t\tif (hw_idx_next == host_idx)\n\t\t\trtw89_debug(rtwdev, RTW89_DBG_UNEXP, \"%d RXD unavailable\\n\", i);\n\n\t\trtw89_debug(rtwdev, RTW89_DBG_TXRX,\n\t\t\t    \"%d RXD unavailable, idx=0x%08x, len=%d\\n\",\n\t\t\t    i, reg_idx, bd_ring->len);\n\t}\n}\n\nvoid rtw89_pci_recognize_intrs(struct rtw89_dev *rtwdev,\n\t\t\t       struct rtw89_pci *rtwpci,\n\t\t\t       struct rtw89_pci_isrs *isrs)\n{\n\tisrs->halt_c2h_isrs = rtw89_read32(rtwdev, R_AX_HISR0) & rtwpci->halt_c2h_intrs;\n\tisrs->isrs[0] = rtw89_read32(rtwdev, R_AX_PCIE_HISR00) & rtwpci->intrs[0];\n\tisrs->isrs[1] = rtw89_read32(rtwdev, R_AX_PCIE_HISR10) & rtwpci->intrs[1];\n\n\trtw89_write32(rtwdev, R_AX_HISR0, isrs->halt_c2h_isrs);\n\trtw89_write32(rtwdev, R_AX_PCIE_HISR00, isrs->isrs[0]);\n\trtw89_write32(rtwdev, R_AX_PCIE_HISR10, isrs->isrs[1]);\n}\nEXPORT_SYMBOL(rtw89_pci_recognize_intrs);\n\nvoid rtw89_pci_recognize_intrs_v1(struct rtw89_dev *rtwdev,\n\t\t\t\t  struct rtw89_pci *rtwpci,\n\t\t\t\t  struct rtw89_pci_isrs *isrs)\n{\n\tisrs->ind_isrs = rtw89_read32(rtwdev, R_AX_PCIE_HISR00_V1) & rtwpci->ind_intrs;\n\tisrs->halt_c2h_isrs = isrs->ind_isrs & B_AX_HS0ISR_IND_INT_EN ?\n\t\t\t      rtw89_read32(rtwdev, R_AX_HISR0) & rtwpci->halt_c2h_intrs : 0;\n\tisrs->isrs[0] = isrs->ind_isrs & B_AX_HCI_AXIDMA_INT_EN ?\n\t\t\trtw89_read32(rtwdev, R_AX_HAXI_HISR00) & rtwpci->intrs[0] : 0;\n\tisrs->isrs[1] = isrs->ind_isrs & B_AX_HS1ISR_IND_INT_EN ?\n\t\t\trtw89_read32(rtwdev, R_AX_HISR1) & rtwpci->intrs[1] : 0;\n\n\tif (isrs->halt_c2h_isrs)\n\t\trtw89_write32(rtwdev, R_AX_HISR0, isrs->halt_c2h_isrs);\n\tif (isrs->isrs[0])\n\t\trtw89_write32(rtwdev, R_AX_HAXI_HISR00, isrs->isrs[0]);\n\tif (isrs->isrs[1])\n\t\trtw89_write32(rtwdev, R_AX_HISR1, isrs->isrs[1]);\n}\nEXPORT_SYMBOL(rtw89_pci_recognize_intrs_v1);\n\nstatic void rtw89_pci_clear_isr0(struct rtw89_dev *rtwdev, u32 isr00)\n{\n\t \n\trtw89_write32(rtwdev, R_AX_PCIE_HISR00, isr00);\n}\n\nvoid rtw89_pci_enable_intr(struct rtw89_dev *rtwdev, struct rtw89_pci *rtwpci)\n{\n\trtw89_write32(rtwdev, R_AX_HIMR0, rtwpci->halt_c2h_intrs);\n\trtw89_write32(rtwdev, R_AX_PCIE_HIMR00, rtwpci->intrs[0]);\n\trtw89_write32(rtwdev, R_AX_PCIE_HIMR10, rtwpci->intrs[1]);\n}\nEXPORT_SYMBOL(rtw89_pci_enable_intr);\n\nvoid rtw89_pci_disable_intr(struct rtw89_dev *rtwdev, struct rtw89_pci *rtwpci)\n{\n\trtw89_write32(rtwdev, R_AX_HIMR0, 0);\n\trtw89_write32(rtwdev, R_AX_PCIE_HIMR00, 0);\n\trtw89_write32(rtwdev, R_AX_PCIE_HIMR10, 0);\n}\nEXPORT_SYMBOL(rtw89_pci_disable_intr);\n\nvoid rtw89_pci_enable_intr_v1(struct rtw89_dev *rtwdev, struct rtw89_pci *rtwpci)\n{\n\trtw89_write32(rtwdev, R_AX_PCIE_HIMR00_V1, rtwpci->ind_intrs);\n\trtw89_write32(rtwdev, R_AX_HIMR0, rtwpci->halt_c2h_intrs);\n\trtw89_write32(rtwdev, R_AX_HAXI_HIMR00, rtwpci->intrs[0]);\n\trtw89_write32(rtwdev, R_AX_HIMR1, rtwpci->intrs[1]);\n}\nEXPORT_SYMBOL(rtw89_pci_enable_intr_v1);\n\nvoid rtw89_pci_disable_intr_v1(struct rtw89_dev *rtwdev, struct rtw89_pci *rtwpci)\n{\n\trtw89_write32(rtwdev, R_AX_PCIE_HIMR00_V1, 0);\n}\nEXPORT_SYMBOL(rtw89_pci_disable_intr_v1);\n\nstatic void rtw89_pci_ops_recovery_start(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\trtw89_chip_disable_intr(rtwdev, rtwpci);\n\trtw89_chip_config_intr_mask(rtwdev, RTW89_PCI_INTR_MASK_RECOVERY_START);\n\trtw89_chip_enable_intr(rtwdev, rtwpci);\n\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n}\n\nstatic void rtw89_pci_ops_recovery_complete(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\trtw89_chip_disable_intr(rtwdev, rtwpci);\n\trtw89_chip_config_intr_mask(rtwdev, RTW89_PCI_INTR_MASK_RECOVERY_COMPLETE);\n\trtw89_chip_enable_intr(rtwdev, rtwpci);\n\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n}\n\nstatic void rtw89_pci_low_power_interrupt_handler(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tint budget = NAPI_POLL_WEIGHT;\n\n\t \n\trtwdev->napi_budget_countdown = budget;\n\n\trtw89_pci_poll_rpq_dma(rtwdev, rtwpci, budget);\n\trtw89_pci_poll_rxq_dma(rtwdev, rtwpci, budget);\n}\n\nstatic irqreturn_t rtw89_pci_interrupt_threadfn(int irq, void *dev)\n{\n\tstruct rtw89_dev *rtwdev = dev;\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_isrs isrs;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\trtw89_chip_recognize_intrs(rtwdev, rtwpci, &isrs);\n\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n\n\tif (unlikely(isrs.isrs[0] & B_AX_RDU_INT))\n\t\trtw89_pci_isr_rxd_unavail(rtwdev, rtwpci);\n\n\tif (unlikely(isrs.halt_c2h_isrs & B_AX_HALT_C2H_INT_EN))\n\t\trtw89_ser_notify(rtwdev, rtw89_mac_get_err_status(rtwdev));\n\n\tif (unlikely(isrs.halt_c2h_isrs & B_AX_WDT_TIMEOUT_INT_EN))\n\t\trtw89_ser_notify(rtwdev, MAC_AX_ERR_L2_ERR_WDT_TIMEOUT_INT);\n\n\tif (unlikely(rtwpci->under_recovery))\n\t\tgoto enable_intr;\n\n\tif (unlikely(rtwpci->low_power)) {\n\t\trtw89_pci_low_power_interrupt_handler(rtwdev);\n\t\tgoto enable_intr;\n\t}\n\n\tif (likely(rtwpci->running)) {\n\t\tlocal_bh_disable();\n\t\tnapi_schedule(&rtwdev->napi);\n\t\tlocal_bh_enable();\n\t}\n\n\treturn IRQ_HANDLED;\n\nenable_intr:\n\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\tif (likely(rtwpci->running))\n\t\trtw89_chip_enable_intr(rtwdev, rtwpci);\n\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t rtw89_pci_interrupt_handler(int irq, void *dev)\n{\n\tstruct rtw89_dev *rtwdev = dev;\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tunsigned long flags;\n\tirqreturn_t irqret = IRQ_WAKE_THREAD;\n\n\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\n\t \n\tif (unlikely(!rtwpci->running)) {\n\t\tirqret = IRQ_HANDLED;\n\t\tgoto exit;\n\t}\n\n\trtw89_chip_disable_intr(rtwdev, rtwpci);\nexit:\n\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n\n\treturn irqret;\n}\n\n#define DEF_TXCHADDRS_TYPE1(info, txch, v...) \\\n\t[RTW89_TXCH_##txch] = { \\\n\t\t.num = R_AX_##txch##_TXBD_NUM ##v, \\\n\t\t.idx = R_AX_##txch##_TXBD_IDX ##v, \\\n\t\t.bdram = R_AX_##txch##_BDRAM_CTRL ##v, \\\n\t\t.desa_l = R_AX_##txch##_TXBD_DESA_L ##v, \\\n\t\t.desa_h = R_AX_##txch##_TXBD_DESA_H ##v, \\\n\t}\n\n#define DEF_TXCHADDRS(info, txch, v...) \\\n\t[RTW89_TXCH_##txch] = { \\\n\t\t.num = R_AX_##txch##_TXBD_NUM, \\\n\t\t.idx = R_AX_##txch##_TXBD_IDX, \\\n\t\t.bdram = R_AX_##txch##_BDRAM_CTRL ##v, \\\n\t\t.desa_l = R_AX_##txch##_TXBD_DESA_L ##v, \\\n\t\t.desa_h = R_AX_##txch##_TXBD_DESA_H ##v, \\\n\t}\n\n#define DEF_RXCHADDRS(info, rxch, v...) \\\n\t[RTW89_RXCH_##rxch] = { \\\n\t\t.num = R_AX_##rxch##_RXBD_NUM ##v, \\\n\t\t.idx = R_AX_##rxch##_RXBD_IDX ##v, \\\n\t\t.desa_l = R_AX_##rxch##_RXBD_DESA_L ##v, \\\n\t\t.desa_h = R_AX_##rxch##_RXBD_DESA_H ##v, \\\n\t}\n\nconst struct rtw89_pci_ch_dma_addr_set rtw89_pci_ch_dma_addr_set = {\n\t.tx = {\n\t\tDEF_TXCHADDRS(info, ACH0),\n\t\tDEF_TXCHADDRS(info, ACH1),\n\t\tDEF_TXCHADDRS(info, ACH2),\n\t\tDEF_TXCHADDRS(info, ACH3),\n\t\tDEF_TXCHADDRS(info, ACH4),\n\t\tDEF_TXCHADDRS(info, ACH5),\n\t\tDEF_TXCHADDRS(info, ACH6),\n\t\tDEF_TXCHADDRS(info, ACH7),\n\t\tDEF_TXCHADDRS(info, CH8),\n\t\tDEF_TXCHADDRS(info, CH9),\n\t\tDEF_TXCHADDRS_TYPE1(info, CH10),\n\t\tDEF_TXCHADDRS_TYPE1(info, CH11),\n\t\tDEF_TXCHADDRS(info, CH12),\n\t},\n\t.rx = {\n\t\tDEF_RXCHADDRS(info, RXQ),\n\t\tDEF_RXCHADDRS(info, RPQ),\n\t},\n};\nEXPORT_SYMBOL(rtw89_pci_ch_dma_addr_set);\n\nconst struct rtw89_pci_ch_dma_addr_set rtw89_pci_ch_dma_addr_set_v1 = {\n\t.tx = {\n\t\tDEF_TXCHADDRS(info, ACH0, _V1),\n\t\tDEF_TXCHADDRS(info, ACH1, _V1),\n\t\tDEF_TXCHADDRS(info, ACH2, _V1),\n\t\tDEF_TXCHADDRS(info, ACH3, _V1),\n\t\tDEF_TXCHADDRS(info, ACH4, _V1),\n\t\tDEF_TXCHADDRS(info, ACH5, _V1),\n\t\tDEF_TXCHADDRS(info, ACH6, _V1),\n\t\tDEF_TXCHADDRS(info, ACH7, _V1),\n\t\tDEF_TXCHADDRS(info, CH8, _V1),\n\t\tDEF_TXCHADDRS(info, CH9, _V1),\n\t\tDEF_TXCHADDRS_TYPE1(info, CH10, _V1),\n\t\tDEF_TXCHADDRS_TYPE1(info, CH11, _V1),\n\t\tDEF_TXCHADDRS(info, CH12, _V1),\n\t},\n\t.rx = {\n\t\tDEF_RXCHADDRS(info, RXQ, _V1),\n\t\tDEF_RXCHADDRS(info, RPQ, _V1),\n\t},\n};\nEXPORT_SYMBOL(rtw89_pci_ch_dma_addr_set_v1);\n\n#undef DEF_TXCHADDRS_TYPE1\n#undef DEF_TXCHADDRS\n#undef DEF_RXCHADDRS\n\nstatic int rtw89_pci_get_txch_addrs(struct rtw89_dev *rtwdev,\n\t\t\t\t    enum rtw89_tx_channel txch,\n\t\t\t\t    const struct rtw89_pci_ch_dma_addr **addr)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\n\tif (txch >= RTW89_TXCH_NUM)\n\t\treturn -EINVAL;\n\n\t*addr = &info->dma_addr_set->tx[txch];\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_get_rxch_addrs(struct rtw89_dev *rtwdev,\n\t\t\t\t    enum rtw89_rx_channel rxch,\n\t\t\t\t    const struct rtw89_pci_ch_dma_addr **addr)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\n\tif (rxch >= RTW89_RXCH_NUM)\n\t\treturn -EINVAL;\n\n\t*addr = &info->dma_addr_set->rx[rxch];\n\n\treturn 0;\n}\n\nstatic u32 rtw89_pci_get_avail_txbd_num(struct rtw89_pci_tx_ring *ring)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &ring->bd_ring;\n\n\t \n\tif (bd_ring->rp > bd_ring->wp)\n\t\treturn bd_ring->rp - bd_ring->wp - 1;\n\n\treturn bd_ring->len - (bd_ring->wp - bd_ring->rp) - 1;\n}\n\nstatic\nu32 __rtw89_pci_check_and_reclaim_tx_fwcmd_resource(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring = &rtwpci->tx_rings[RTW89_TXCH_CH12];\n\tu32 cnt;\n\n\tspin_lock_bh(&rtwpci->trx_lock);\n\trtw89_pci_reclaim_tx_fwcmd(rtwdev, rtwpci);\n\tcnt = rtw89_pci_get_avail_txbd_num(tx_ring);\n\tspin_unlock_bh(&rtwpci->trx_lock);\n\n\treturn cnt;\n}\n\nstatic\nu32 __rtw89_pci_check_and_reclaim_tx_resource_noio(struct rtw89_dev *rtwdev,\n\t\t\t\t\t\t   u8 txch)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring = &rtwpci->tx_rings[txch];\n\tstruct rtw89_pci_tx_wd_ring *wd_ring = &tx_ring->wd_ring;\n\tu32 cnt;\n\n\tspin_lock_bh(&rtwpci->trx_lock);\n\tcnt = rtw89_pci_get_avail_txbd_num(tx_ring);\n\tcnt = min(cnt, wd_ring->curr_num);\n\tspin_unlock_bh(&rtwpci->trx_lock);\n\n\treturn cnt;\n}\n\nstatic u32 __rtw89_pci_check_and_reclaim_tx_resource(struct rtw89_dev *rtwdev,\n\t\t\t\t\t\t     u8 txch)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring = &rtwpci->tx_rings[txch];\n\tstruct rtw89_pci_tx_wd_ring *wd_ring = &tx_ring->wd_ring;\n\tconst struct rtw89_chip_info *chip = rtwdev->chip;\n\tu32 bd_cnt, wd_cnt, min_cnt = 0;\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tenum rtw89_debug_mask debug_mask;\n\tu32 cnt;\n\n\trx_ring = &rtwpci->rx_rings[RTW89_RXCH_RPQ];\n\n\tspin_lock_bh(&rtwpci->trx_lock);\n\tbd_cnt = rtw89_pci_get_avail_txbd_num(tx_ring);\n\twd_cnt = wd_ring->curr_num;\n\n\tif (wd_cnt == 0 || bd_cnt == 0) {\n\t\tcnt = rtw89_pci_rxbd_recalc(rtwdev, rx_ring);\n\t\tif (cnt)\n\t\t\trtw89_pci_release_tx(rtwdev, rx_ring, cnt);\n\t\telse if (wd_cnt == 0)\n\t\t\tgoto out_unlock;\n\n\t\tbd_cnt = rtw89_pci_get_avail_txbd_num(tx_ring);\n\t\tif (bd_cnt == 0)\n\t\t\trtw89_pci_reclaim_txbd(rtwdev, tx_ring);\n\t}\n\n\tbd_cnt = rtw89_pci_get_avail_txbd_num(tx_ring);\n\twd_cnt = wd_ring->curr_num;\n\tmin_cnt = min(bd_cnt, wd_cnt);\n\tif (min_cnt == 0) {\n\t\t \n\t\tif (rtwpci->low_power || chip->small_fifo_size)\n\t\t\tdebug_mask = RTW89_DBG_TXRX;\n\t\telse\n\t\t\tdebug_mask = RTW89_DBG_UNEXP;\n\n\t\trtw89_debug(rtwdev, debug_mask,\n\t\t\t    \"still no tx resource after reclaim: wd_cnt=%d bd_cnt=%d\\n\",\n\t\t\t    wd_cnt, bd_cnt);\n\t}\n\nout_unlock:\n\tspin_unlock_bh(&rtwpci->trx_lock);\n\n\treturn min_cnt;\n}\n\nstatic u32 rtw89_pci_check_and_reclaim_tx_resource(struct rtw89_dev *rtwdev,\n\t\t\t\t\t\t   u8 txch)\n{\n\tif (rtwdev->hci.paused)\n\t\treturn __rtw89_pci_check_and_reclaim_tx_resource_noio(rtwdev, txch);\n\n\tif (txch == RTW89_TXCH_CH12)\n\t\treturn __rtw89_pci_check_and_reclaim_tx_fwcmd_resource(rtwdev);\n\n\treturn __rtw89_pci_check_and_reclaim_tx_resource(rtwdev, txch);\n}\n\nstatic void __rtw89_pci_tx_kick_off(struct rtw89_dev *rtwdev, struct rtw89_pci_tx_ring *tx_ring)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_dma_ring *bd_ring = &tx_ring->bd_ring;\n\tu32 host_idx, addr;\n\n\tspin_lock_bh(&rtwpci->trx_lock);\n\n\taddr = bd_ring->addr.idx;\n\thost_idx = bd_ring->wp;\n\trtw89_write16(rtwdev, addr, host_idx);\n\n\tspin_unlock_bh(&rtwpci->trx_lock);\n}\n\nstatic void rtw89_pci_tx_bd_ring_update(struct rtw89_dev *rtwdev, struct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\t\tint n_txbd)\n{\n\tstruct rtw89_pci_dma_ring *bd_ring = &tx_ring->bd_ring;\n\tu32 host_idx, len;\n\n\tlen = bd_ring->len;\n\thost_idx = bd_ring->wp + n_txbd;\n\thost_idx = host_idx < len ? host_idx : host_idx - len;\n\n\tbd_ring->wp = host_idx;\n}\n\nstatic void rtw89_pci_ops_tx_kick_off(struct rtw89_dev *rtwdev, u8 txch)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring = &rtwpci->tx_rings[txch];\n\n\tif (rtwdev->hci.paused) {\n\t\tset_bit(txch, rtwpci->kick_map);\n\t\treturn;\n\t}\n\n\t__rtw89_pci_tx_kick_off(rtwdev, tx_ring);\n}\n\nstatic void rtw89_pci_tx_kick_off_pending(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring;\n\tint txch;\n\n\tfor (txch = 0; txch < RTW89_TXCH_NUM; txch++) {\n\t\tif (!test_and_clear_bit(txch, rtwpci->kick_map))\n\t\t\tcontinue;\n\n\t\ttx_ring = &rtwpci->tx_rings[txch];\n\t\t__rtw89_pci_tx_kick_off(rtwdev, tx_ring);\n\t}\n}\n\nstatic void __pci_flush_txch(struct rtw89_dev *rtwdev, u8 txch, bool drop)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring = &rtwpci->tx_rings[txch];\n\tstruct rtw89_pci_dma_ring *bd_ring = &tx_ring->bd_ring;\n\tu32 cur_idx, cur_rp;\n\tu8 i;\n\n\t \n\tfor (i = 0; i < 60; i++) {\n\t\tcur_idx = rtw89_read32(rtwdev, bd_ring->addr.idx);\n\t\tcur_rp = FIELD_GET(TXBD_HW_IDX_MASK, cur_idx);\n\t\tif (cur_rp == bd_ring->wp)\n\t\t\treturn;\n\n\t\tudelay(1);\n\t}\n\n\tif (!drop)\n\t\trtw89_info(rtwdev, \"timed out to flush pci txch: %d\\n\", txch);\n}\n\nstatic void __rtw89_pci_ops_flush_txchs(struct rtw89_dev *rtwdev, u32 txchs,\n\t\t\t\t\tbool drop)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tu8 i;\n\n\tfor (i = 0; i < RTW89_TXCH_NUM; i++) {\n\t\t \n\t\tif (i == RTW89_TXCH_CH12)\n\t\t\tcontinue;\n\t\tif (info->tx_dma_ch_mask & BIT(i))\n\t\t\tcontinue;\n\n\t\tif (txchs & BIT(i))\n\t\t\t__pci_flush_txch(rtwdev, i, drop);\n\t}\n}\n\nstatic void rtw89_pci_ops_flush_queues(struct rtw89_dev *rtwdev, u32 queues,\n\t\t\t\t       bool drop)\n{\n\t__rtw89_pci_ops_flush_txchs(rtwdev, BIT(RTW89_TXCH_NUM) - 1, drop);\n}\n\nu32 rtw89_pci_fill_txaddr_info(struct rtw89_dev *rtwdev,\n\t\t\t       void *txaddr_info_addr, u32 total_len,\n\t\t\t       dma_addr_t dma, u8 *add_info_nr)\n{\n\tstruct rtw89_pci_tx_addr_info_32 *txaddr_info = txaddr_info_addr;\n\n\ttxaddr_info->length = cpu_to_le16(total_len);\n\ttxaddr_info->option = cpu_to_le16(RTW89_PCI_ADDR_MSDU_LS |\n\t\t\t\t\t  RTW89_PCI_ADDR_NUM(1));\n\ttxaddr_info->dma = cpu_to_le32(dma);\n\n\t*add_info_nr = 1;\n\n\treturn sizeof(*txaddr_info);\n}\nEXPORT_SYMBOL(rtw89_pci_fill_txaddr_info);\n\nu32 rtw89_pci_fill_txaddr_info_v1(struct rtw89_dev *rtwdev,\n\t\t\t\t  void *txaddr_info_addr, u32 total_len,\n\t\t\t\t  dma_addr_t dma, u8 *add_info_nr)\n{\n\tstruct rtw89_pci_tx_addr_info_32_v1 *txaddr_info = txaddr_info_addr;\n\tu32 remain = total_len;\n\tu32 len;\n\tu16 length_option;\n\tint n;\n\n\tfor (n = 0; n < RTW89_TXADDR_INFO_NR_V1 && remain; n++) {\n\t\tlen = remain >= TXADDR_INFO_LENTHG_V1_MAX ?\n\t\t      TXADDR_INFO_LENTHG_V1_MAX : remain;\n\t\tremain -= len;\n\n\t\tlength_option = FIELD_PREP(B_PCIADDR_LEN_V1_MASK, len) |\n\t\t\t\tFIELD_PREP(B_PCIADDR_HIGH_SEL_V1_MASK, 0) |\n\t\t\t\tFIELD_PREP(B_PCIADDR_LS_V1_MASK, remain == 0);\n\t\ttxaddr_info->length_opt = cpu_to_le16(length_option);\n\t\ttxaddr_info->dma_low_lsb = cpu_to_le16(FIELD_GET(GENMASK(15, 0), dma));\n\t\ttxaddr_info->dma_low_msb = cpu_to_le16(FIELD_GET(GENMASK(31, 16), dma));\n\n\t\tdma += len;\n\t\ttxaddr_info++;\n\t}\n\n\tWARN_ONCE(remain, \"length overflow remain=%u total_len=%u\",\n\t\t  remain, total_len);\n\n\t*add_info_nr = n;\n\n\treturn n * sizeof(*txaddr_info);\n}\nEXPORT_SYMBOL(rtw89_pci_fill_txaddr_info_v1);\n\nstatic int rtw89_pci_txwd_submit(struct rtw89_dev *rtwdev,\n\t\t\t\t struct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\t struct rtw89_pci_tx_wd *txwd,\n\t\t\t\t struct rtw89_core_tx_request *tx_req)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_chip_info *chip = rtwdev->chip;\n\tstruct rtw89_tx_desc_info *desc_info = &tx_req->desc_info;\n\tstruct rtw89_txwd_info *txwd_info;\n\tstruct rtw89_pci_tx_wp_info *txwp_info;\n\tvoid *txaddr_info_addr;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\tstruct sk_buff *skb = tx_req->skb;\n\tstruct rtw89_pci_tx_data *tx_data = RTW89_PCI_TX_SKB_CB(skb);\n\tstruct rtw89_tx_skb_data *skb_data = RTW89_TX_SKB_CB(skb);\n\tbool en_wd_info = desc_info->en_wd_info;\n\tu32 txwd_len;\n\tu32 txwp_len;\n\tu32 txaddr_info_len;\n\tdma_addr_t dma;\n\tint ret;\n\n\tdma = dma_map_single(&pdev->dev, skb->data, skb->len, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&pdev->dev, dma)) {\n\t\trtw89_err(rtwdev, \"failed to map skb dma data\\n\");\n\t\tret = -EBUSY;\n\t\tgoto err;\n\t}\n\n\ttx_data->dma = dma;\n\trcu_assign_pointer(skb_data->wait, NULL);\n\n\ttxwp_len = sizeof(*txwp_info);\n\ttxwd_len = chip->txwd_body_size;\n\ttxwd_len += en_wd_info ? sizeof(*txwd_info) : 0;\n\n\ttxwp_info = txwd->vaddr + txwd_len;\n\ttxwp_info->seq0 = cpu_to_le16(txwd->seq | RTW89_PCI_TXWP_VALID);\n\ttxwp_info->seq1 = 0;\n\ttxwp_info->seq2 = 0;\n\ttxwp_info->seq3 = 0;\n\n\ttx_ring->tx_cnt++;\n\ttxaddr_info_addr = txwd->vaddr + txwd_len + txwp_len;\n\ttxaddr_info_len =\n\t\trtw89_chip_fill_txaddr_info(rtwdev, txaddr_info_addr, skb->len,\n\t\t\t\t\t    dma, &desc_info->addr_info_nr);\n\n\ttxwd->len = txwd_len + txwp_len + txaddr_info_len;\n\n\trtw89_chip_fill_txdesc(rtwdev, desc_info, txwd->vaddr);\n\n\tskb_queue_tail(&txwd->queue, skb);\n\n\treturn 0;\n\nerr:\n\treturn ret;\n}\n\nstatic int rtw89_pci_fwcmd_submit(struct rtw89_dev *rtwdev,\n\t\t\t\t  struct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\t  struct rtw89_pci_tx_bd_32 *txbd,\n\t\t\t\t  struct rtw89_core_tx_request *tx_req)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_chip_info *chip = rtwdev->chip;\n\tstruct rtw89_tx_desc_info *desc_info = &tx_req->desc_info;\n\tvoid *txdesc;\n\tint txdesc_size = chip->h2c_desc_size;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\tstruct sk_buff *skb = tx_req->skb;\n\tstruct rtw89_pci_tx_data *tx_data = RTW89_PCI_TX_SKB_CB(skb);\n\tdma_addr_t dma;\n\n\ttxdesc = skb_push(skb, txdesc_size);\n\tmemset(txdesc, 0, txdesc_size);\n\trtw89_chip_fill_txdesc_fwcmd(rtwdev, desc_info, txdesc);\n\n\tdma = dma_map_single(&pdev->dev, skb->data, skb->len, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&pdev->dev, dma)) {\n\t\trtw89_err(rtwdev, \"failed to map fwcmd dma data\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\ttx_data->dma = dma;\n\ttxbd->option = cpu_to_le16(RTW89_PCI_TXBD_OPTION_LS);\n\ttxbd->length = cpu_to_le16(skb->len);\n\ttxbd->dma = cpu_to_le32(tx_data->dma);\n\tskb_queue_tail(&rtwpci->h2c_queue, skb);\n\n\trtw89_pci_tx_bd_ring_update(rtwdev, tx_ring, 1);\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_txbd_submit(struct rtw89_dev *rtwdev,\n\t\t\t\t struct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\t struct rtw89_pci_tx_bd_32 *txbd,\n\t\t\t\t struct rtw89_core_tx_request *tx_req)\n{\n\tstruct rtw89_pci_tx_wd *txwd;\n\tint ret;\n\n\t \n\tif (tx_ring->txch == RTW89_TXCH_CH12)\n\t\treturn rtw89_pci_fwcmd_submit(rtwdev, tx_ring, txbd, tx_req);\n\n\ttxwd = rtw89_pci_dequeue_txwd(tx_ring);\n\tif (!txwd) {\n\t\trtw89_err(rtwdev, \"no available TXWD\\n\");\n\t\tret = -ENOSPC;\n\t\tgoto err;\n\t}\n\n\tret = rtw89_pci_txwd_submit(rtwdev, tx_ring, txwd, tx_req);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to submit TXWD %d\\n\", txwd->seq);\n\t\tgoto err_enqueue_wd;\n\t}\n\n\tlist_add_tail(&txwd->list, &tx_ring->busy_pages);\n\n\ttxbd->option = cpu_to_le16(RTW89_PCI_TXBD_OPTION_LS);\n\ttxbd->length = cpu_to_le16(txwd->len);\n\ttxbd->dma = cpu_to_le32(txwd->paddr);\n\n\trtw89_pci_tx_bd_ring_update(rtwdev, tx_ring, 1);\n\n\treturn 0;\n\nerr_enqueue_wd:\n\trtw89_pci_enqueue_txwd(tx_ring, txwd);\nerr:\n\treturn ret;\n}\n\nstatic int rtw89_pci_tx_write(struct rtw89_dev *rtwdev, struct rtw89_core_tx_request *tx_req,\n\t\t\t      u8 txch)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_tx_ring *tx_ring;\n\tstruct rtw89_pci_tx_bd_32 *txbd;\n\tu32 n_avail_txbd;\n\tint ret = 0;\n\n\t \n\tif ((txch == RTW89_TXCH_CH12 ||\n\t     tx_req->tx_type == RTW89_CORE_TX_TYPE_FWCMD) &&\n\t    (txch != RTW89_TXCH_CH12 ||\n\t     tx_req->tx_type != RTW89_CORE_TX_TYPE_FWCMD)) {\n\t\trtw89_err(rtwdev, \"only fw cmd uses dma channel 12\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ttx_ring = &rtwpci->tx_rings[txch];\n\tspin_lock_bh(&rtwpci->trx_lock);\n\n\tn_avail_txbd = rtw89_pci_get_avail_txbd_num(tx_ring);\n\tif (n_avail_txbd == 0) {\n\t\trtw89_err(rtwdev, \"no available TXBD\\n\");\n\t\tret = -ENOSPC;\n\t\tgoto err_unlock;\n\t}\n\n\ttxbd = rtw89_pci_get_next_txbd(tx_ring);\n\tret = rtw89_pci_txbd_submit(rtwdev, tx_ring, txbd, tx_req);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to submit TXBD\\n\");\n\t\tgoto err_unlock;\n\t}\n\n\tspin_unlock_bh(&rtwpci->trx_lock);\n\treturn 0;\n\nerr_unlock:\n\tspin_unlock_bh(&rtwpci->trx_lock);\n\treturn ret;\n}\n\nstatic int rtw89_pci_ops_tx_write(struct rtw89_dev *rtwdev, struct rtw89_core_tx_request *tx_req)\n{\n\tstruct rtw89_tx_desc_info *desc_info = &tx_req->desc_info;\n\tint ret;\n\n\tret = rtw89_pci_tx_write(rtwdev, tx_req, desc_info->ch_dma);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to TX Queue %d\\n\", desc_info->ch_dma);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nconst struct rtw89_pci_bd_ram rtw89_bd_ram_table_dual[RTW89_TXCH_NUM] = {\n\t[RTW89_TXCH_ACH0] = {.start_idx = 0,  .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH1] = {.start_idx = 5,  .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH2] = {.start_idx = 10, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH3] = {.start_idx = 15, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH4] = {.start_idx = 20, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH5] = {.start_idx = 25, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH6] = {.start_idx = 30, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH7] = {.start_idx = 35, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_CH8]  = {.start_idx = 40, .max_num = 5, .min_num = 1},\n\t[RTW89_TXCH_CH9]  = {.start_idx = 45, .max_num = 5, .min_num = 1},\n\t[RTW89_TXCH_CH10] = {.start_idx = 50, .max_num = 5, .min_num = 1},\n\t[RTW89_TXCH_CH11] = {.start_idx = 55, .max_num = 5, .min_num = 1},\n\t[RTW89_TXCH_CH12] = {.start_idx = 60, .max_num = 4, .min_num = 1},\n};\nEXPORT_SYMBOL(rtw89_bd_ram_table_dual);\n\nconst struct rtw89_pci_bd_ram rtw89_bd_ram_table_single[RTW89_TXCH_NUM] = {\n\t[RTW89_TXCH_ACH0] = {.start_idx = 0,  .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH1] = {.start_idx = 5,  .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH2] = {.start_idx = 10, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_ACH3] = {.start_idx = 15, .max_num = 5, .min_num = 2},\n\t[RTW89_TXCH_CH8]  = {.start_idx = 20, .max_num = 4, .min_num = 1},\n\t[RTW89_TXCH_CH9]  = {.start_idx = 24, .max_num = 4, .min_num = 1},\n\t[RTW89_TXCH_CH12] = {.start_idx = 28, .max_num = 4, .min_num = 1},\n};\nEXPORT_SYMBOL(rtw89_bd_ram_table_single);\n\nstatic void rtw89_pci_reset_trx_rings(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tconst struct rtw89_pci_bd_ram *bd_ram_table = *info->bd_ram_table;\n\tstruct rtw89_pci_tx_ring *tx_ring;\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tstruct rtw89_pci_dma_ring *bd_ring;\n\tconst struct rtw89_pci_bd_ram *bd_ram;\n\tu32 addr_num;\n\tu32 addr_bdram;\n\tu32 addr_desa_l;\n\tu32 val32;\n\tint i;\n\n\tfor (i = 0; i < RTW89_TXCH_NUM; i++) {\n\t\tif (info->tx_dma_ch_mask & BIT(i))\n\t\t\tcontinue;\n\n\t\ttx_ring = &rtwpci->tx_rings[i];\n\t\tbd_ring = &tx_ring->bd_ring;\n\t\tbd_ram = &bd_ram_table[i];\n\t\taddr_num = bd_ring->addr.num;\n\t\taddr_bdram = bd_ring->addr.bdram;\n\t\taddr_desa_l = bd_ring->addr.desa_l;\n\t\tbd_ring->wp = 0;\n\t\tbd_ring->rp = 0;\n\n\t\tval32 = FIELD_PREP(BDRAM_SIDX_MASK, bd_ram->start_idx) |\n\t\t\tFIELD_PREP(BDRAM_MAX_MASK, bd_ram->max_num) |\n\t\t\tFIELD_PREP(BDRAM_MIN_MASK, bd_ram->min_num);\n\n\t\trtw89_write16(rtwdev, addr_num, bd_ring->len);\n\t\trtw89_write32(rtwdev, addr_bdram, val32);\n\t\trtw89_write32(rtwdev, addr_desa_l, bd_ring->dma);\n\t}\n\n\tfor (i = 0; i < RTW89_RXCH_NUM; i++) {\n\t\trx_ring = &rtwpci->rx_rings[i];\n\t\tbd_ring = &rx_ring->bd_ring;\n\t\taddr_num = bd_ring->addr.num;\n\t\taddr_desa_l = bd_ring->addr.desa_l;\n\t\tbd_ring->wp = 0;\n\t\tbd_ring->rp = 0;\n\t\trx_ring->diliver_skb = NULL;\n\t\trx_ring->diliver_desc.ready = false;\n\n\t\trtw89_write16(rtwdev, addr_num, bd_ring->len);\n\t\trtw89_write32(rtwdev, addr_desa_l, bd_ring->dma);\n\t}\n}\n\nstatic void rtw89_pci_release_tx_ring(struct rtw89_dev *rtwdev,\n\t\t\t\t      struct rtw89_pci_tx_ring *tx_ring)\n{\n\trtw89_pci_release_busy_txwd(rtwdev, tx_ring);\n\trtw89_pci_release_pending_txwd_skb(rtwdev, tx_ring);\n}\n\nstatic void rtw89_pci_ops_reset(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tint txch;\n\n\trtw89_pci_reset_trx_rings(rtwdev);\n\n\tspin_lock_bh(&rtwpci->trx_lock);\n\tfor (txch = 0; txch < RTW89_TXCH_NUM; txch++) {\n\t\tif (info->tx_dma_ch_mask & BIT(txch))\n\t\t\tcontinue;\n\t\tif (txch == RTW89_TXCH_CH12) {\n\t\t\trtw89_pci_release_fwcmd(rtwdev, rtwpci,\n\t\t\t\t\t\tskb_queue_len(&rtwpci->h2c_queue), true);\n\t\t\tcontinue;\n\t\t}\n\t\trtw89_pci_release_tx_ring(rtwdev, &rtwpci->tx_rings[txch]);\n\t}\n\tspin_unlock_bh(&rtwpci->trx_lock);\n}\n\nstatic void rtw89_pci_enable_intr_lock(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\trtwpci->running = true;\n\trtw89_chip_enable_intr(rtwdev, rtwpci);\n\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n}\n\nstatic void rtw89_pci_disable_intr_lock(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\trtwpci->running = false;\n\trtw89_chip_disable_intr(rtwdev, rtwpci);\n\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n}\n\nstatic int rtw89_pci_ops_start(struct rtw89_dev *rtwdev)\n{\n\trtw89_core_napi_start(rtwdev);\n\trtw89_pci_enable_intr_lock(rtwdev);\n\n\treturn 0;\n}\n\nstatic void rtw89_pci_ops_stop(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\n\trtw89_pci_disable_intr_lock(rtwdev);\n\tsynchronize_irq(pdev->irq);\n\trtw89_core_napi_stop(rtwdev);\n}\n\nstatic void rtw89_pci_ops_pause(struct rtw89_dev *rtwdev, bool pause)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\n\tif (pause) {\n\t\trtw89_pci_disable_intr_lock(rtwdev);\n\t\tsynchronize_irq(pdev->irq);\n\t\tif (test_bit(RTW89_FLAG_NAPI_RUNNING, rtwdev->flags))\n\t\t\tnapi_synchronize(&rtwdev->napi);\n\t} else {\n\t\trtw89_pci_enable_intr_lock(rtwdev);\n\t\trtw89_pci_tx_kick_off_pending(rtwdev);\n\t}\n}\n\nstatic\nvoid rtw89_pci_switch_bd_idx_addr(struct rtw89_dev *rtwdev, bool low_power)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tconst struct rtw89_pci_bd_idx_addr *bd_idx_addr = info->bd_idx_addr_low_power;\n\tconst struct rtw89_pci_ch_dma_addr_set *dma_addr_set = info->dma_addr_set;\n\tstruct rtw89_pci_tx_ring *tx_ring;\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tint i;\n\n\tif (WARN(!bd_idx_addr, \"only HCI with low power mode needs this\\n\"))\n\t\treturn;\n\n\tfor (i = 0; i < RTW89_TXCH_NUM; i++) {\n\t\ttx_ring = &rtwpci->tx_rings[i];\n\t\ttx_ring->bd_ring.addr.idx = low_power ?\n\t\t\t\t\t    bd_idx_addr->tx_bd_addrs[i] :\n\t\t\t\t\t    dma_addr_set->tx[i].idx;\n\t}\n\n\tfor (i = 0; i < RTW89_RXCH_NUM; i++) {\n\t\trx_ring = &rtwpci->rx_rings[i];\n\t\trx_ring->bd_ring.addr.idx = low_power ?\n\t\t\t\t\t    bd_idx_addr->rx_bd_addrs[i] :\n\t\t\t\t\t    dma_addr_set->rx[i].idx;\n\t}\n}\n\nstatic void rtw89_pci_ops_switch_mode(struct rtw89_dev *rtwdev, bool low_power)\n{\n\tenum rtw89_pci_intr_mask_cfg cfg;\n\n\tWARN(!rtwdev->hci.paused, \"HCI isn't paused\\n\");\n\n\tcfg = low_power ? RTW89_PCI_INTR_MASK_LOW_POWER : RTW89_PCI_INTR_MASK_NORMAL;\n\trtw89_chip_config_intr_mask(rtwdev, cfg);\n\trtw89_pci_switch_bd_idx_addr(rtwdev, low_power);\n}\n\nstatic void rtw89_pci_ops_write32(struct rtw89_dev *rtwdev, u32 addr, u32 data);\n\nstatic u32 rtw89_pci_ops_read32_cmac(struct rtw89_dev *rtwdev, u32 addr)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tu32 val = readl(rtwpci->mmap + addr);\n\tint count;\n\n\tfor (count = 0; ; count++) {\n\t\tif (val != RTW89_R32_DEAD)\n\t\t\treturn val;\n\t\tif (count >= MAC_REG_POOL_COUNT) {\n\t\t\trtw89_warn(rtwdev, \"addr %#x = %#x\\n\", addr, val);\n\t\t\treturn RTW89_R32_DEAD;\n\t\t}\n\t\trtw89_pci_ops_write32(rtwdev, R_AX_CK_EN, B_AX_CMAC_ALLCKEN);\n\t\tval = readl(rtwpci->mmap + addr);\n\t}\n\n\treturn val;\n}\n\nstatic u8 rtw89_pci_ops_read8(struct rtw89_dev *rtwdev, u32 addr)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tu32 addr32, val32, shift;\n\n\tif (!ACCESS_CMAC(addr))\n\t\treturn readb(rtwpci->mmap + addr);\n\n\taddr32 = addr & ~0x3;\n\tshift = (addr & 0x3) * 8;\n\tval32 = rtw89_pci_ops_read32_cmac(rtwdev, addr32);\n\treturn val32 >> shift;\n}\n\nstatic u16 rtw89_pci_ops_read16(struct rtw89_dev *rtwdev, u32 addr)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tu32 addr32, val32, shift;\n\n\tif (!ACCESS_CMAC(addr))\n\t\treturn readw(rtwpci->mmap + addr);\n\n\taddr32 = addr & ~0x3;\n\tshift = (addr & 0x3) * 8;\n\tval32 = rtw89_pci_ops_read32_cmac(rtwdev, addr32);\n\treturn val32 >> shift;\n}\n\nstatic u32 rtw89_pci_ops_read32(struct rtw89_dev *rtwdev, u32 addr)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\tif (!ACCESS_CMAC(addr))\n\t\treturn readl(rtwpci->mmap + addr);\n\n\treturn rtw89_pci_ops_read32_cmac(rtwdev, addr);\n}\n\nstatic void rtw89_pci_ops_write8(struct rtw89_dev *rtwdev, u32 addr, u8 data)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\twriteb(data, rtwpci->mmap + addr);\n}\n\nstatic void rtw89_pci_ops_write16(struct rtw89_dev *rtwdev, u32 addr, u16 data)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\twritew(data, rtwpci->mmap + addr);\n}\n\nstatic void rtw89_pci_ops_write32(struct rtw89_dev *rtwdev, u32 addr, u32 data)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\twritel(data, rtwpci->mmap + addr);\n}\n\nstatic void rtw89_pci_ctrl_dma_trx(struct rtw89_dev *rtwdev, bool enable)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\n\tif (enable)\n\t\trtw89_write32_set(rtwdev, info->init_cfg_reg,\n\t\t\t\t  info->rxhci_en_bit | info->txhci_en_bit);\n\telse\n\t\trtw89_write32_clr(rtwdev, info->init_cfg_reg,\n\t\t\t\t  info->rxhci_en_bit | info->txhci_en_bit);\n}\n\nstatic void rtw89_pci_ctrl_dma_io(struct rtw89_dev *rtwdev, bool enable)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tu32 reg, mask;\n\n\tif (chip_id == RTL8852C) {\n\t\treg = R_AX_HAXI_INIT_CFG1;\n\t\tmask = B_AX_STOP_AXI_MST;\n\t} else {\n\t\treg = R_AX_PCIE_DMA_STOP1;\n\t\tmask = B_AX_STOP_PCIEIO;\n\t}\n\n\tif (enable)\n\t\trtw89_write32_clr(rtwdev, reg, mask);\n\telse\n\t\trtw89_write32_set(rtwdev, reg, mask);\n}\n\nstatic void rtw89_pci_ctrl_dma_all(struct rtw89_dev *rtwdev, bool enable)\n{\n\trtw89_pci_ctrl_dma_io(rtwdev, enable);\n\trtw89_pci_ctrl_dma_trx(rtwdev, enable);\n}\n\nstatic int rtw89_pci_check_mdio(struct rtw89_dev *rtwdev, u8 addr, u8 speed, u16 rw_bit)\n{\n\tu16 val;\n\n\trtw89_write8(rtwdev, R_AX_MDIO_CFG, addr & 0x1F);\n\n\tval = rtw89_read16(rtwdev, R_AX_MDIO_CFG);\n\tswitch (speed) {\n\tcase PCIE_PHY_GEN1:\n\t\tif (addr < 0x20)\n\t\t\tval = u16_replace_bits(val, MDIO_PG0_G1, B_AX_MDIO_PHY_ADDR_MASK);\n\t\telse\n\t\t\tval = u16_replace_bits(val, MDIO_PG1_G1, B_AX_MDIO_PHY_ADDR_MASK);\n\t\tbreak;\n\tcase PCIE_PHY_GEN2:\n\t\tif (addr < 0x20)\n\t\t\tval = u16_replace_bits(val, MDIO_PG0_G2, B_AX_MDIO_PHY_ADDR_MASK);\n\t\telse\n\t\t\tval = u16_replace_bits(val, MDIO_PG1_G2, B_AX_MDIO_PHY_ADDR_MASK);\n\t\tbreak;\n\tdefault:\n\t\trtw89_err(rtwdev, \"[ERR]Error Speed %d!\\n\", speed);\n\t\treturn -EINVAL;\n\t}\n\trtw89_write16(rtwdev, R_AX_MDIO_CFG, val);\n\trtw89_write16_set(rtwdev, R_AX_MDIO_CFG, rw_bit);\n\n\treturn read_poll_timeout(rtw89_read16, val, !(val & rw_bit), 10, 2000,\n\t\t\t\t false, rtwdev, R_AX_MDIO_CFG);\n}\n\nstatic int\nrtw89_read16_mdio(struct rtw89_dev *rtwdev, u8 addr, u8 speed, u16 *val)\n{\n\tint ret;\n\n\tret = rtw89_pci_check_mdio(rtwdev, addr, speed, B_AX_MDIO_RFLAG);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]MDIO R16 0x%X fail ret=%d!\\n\", addr, ret);\n\t\treturn ret;\n\t}\n\t*val = rtw89_read16(rtwdev, R_AX_MDIO_RDATA);\n\n\treturn 0;\n}\n\nstatic int\nrtw89_write16_mdio(struct rtw89_dev *rtwdev, u8 addr, u16 data, u8 speed)\n{\n\tint ret;\n\n\trtw89_write16(rtwdev, R_AX_MDIO_WDATA, data);\n\tret = rtw89_pci_check_mdio(rtwdev, addr, speed, B_AX_MDIO_WFLAG);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]MDIO W16 0x%X = %x fail ret=%d!\\n\", addr, data, ret);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int\nrtw89_write16_mdio_mask(struct rtw89_dev *rtwdev, u8 addr, u16 mask, u16 data, u8 speed)\n{\n\tu32 shift;\n\tint ret;\n\tu16 val;\n\n\tret = rtw89_read16_mdio(rtwdev, addr, speed, &val);\n\tif (ret)\n\t\treturn ret;\n\n\tshift = __ffs(mask);\n\tval &= ~mask;\n\tval |= ((data << shift) & mask);\n\n\tret = rtw89_write16_mdio(rtwdev, addr, val, speed);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int rtw89_write16_mdio_set(struct rtw89_dev *rtwdev, u8 addr, u16 mask, u8 speed)\n{\n\tint ret;\n\tu16 val;\n\n\tret = rtw89_read16_mdio(rtwdev, addr, speed, &val);\n\tif (ret)\n\t\treturn ret;\n\tret = rtw89_write16_mdio(rtwdev, addr, val | mask, speed);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int rtw89_write16_mdio_clr(struct rtw89_dev *rtwdev, u8 addr, u16 mask, u8 speed)\n{\n\tint ret;\n\tu16 val;\n\n\tret = rtw89_read16_mdio(rtwdev, addr, speed, &val);\n\tif (ret)\n\t\treturn ret;\n\tret = rtw89_write16_mdio(rtwdev, addr, val & ~mask, speed);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_write_config_byte(struct rtw89_dev *rtwdev, u16 addr,\n\t\t\t\t       u8 data)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\n\treturn pci_write_config_byte(pdev, addr, data);\n}\n\nstatic int rtw89_pci_read_config_byte(struct rtw89_dev *rtwdev, u16 addr,\n\t\t\t\t      u8 *value)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\n\treturn pci_read_config_byte(pdev, addr, value);\n}\n\nstatic int rtw89_pci_config_byte_set(struct rtw89_dev *rtwdev, u16 addr,\n\t\t\t\t     u8 bit)\n{\n\tu8 value;\n\tint ret;\n\n\tret = rtw89_pci_read_config_byte(rtwdev, addr, &value);\n\tif (ret)\n\t\treturn ret;\n\n\tvalue |= bit;\n\tret = rtw89_pci_write_config_byte(rtwdev, addr, value);\n\n\treturn ret;\n}\n\nstatic int rtw89_pci_config_byte_clr(struct rtw89_dev *rtwdev, u16 addr,\n\t\t\t\t     u8 bit)\n{\n\tu8 value;\n\tint ret;\n\n\tret = rtw89_pci_read_config_byte(rtwdev, addr, &value);\n\tif (ret)\n\t\treturn ret;\n\n\tvalue &= ~bit;\n\tret = rtw89_pci_write_config_byte(rtwdev, addr, value);\n\n\treturn ret;\n}\n\nstatic int\n__get_target(struct rtw89_dev *rtwdev, u16 *target, enum rtw89_pcie_phy phy_rate)\n{\n\tu16 val, tar;\n\tint ret;\n\n\t \n\tret = rtw89_read16_mdio(rtwdev, RAC_CTRL_PPR_V1, phy_rate, &val);\n\tif (ret)\n\t\treturn ret;\n\tret = rtw89_write16_mdio(rtwdev, RAC_CTRL_PPR_V1, val & ~B_AX_CLK_CALIB_EN,\n\t\t\t\t phy_rate);\n\tif (ret)\n\t\treturn ret;\n\tret = rtw89_write16_mdio(rtwdev, RAC_CTRL_PPR_V1, val | B_AX_CLK_CALIB_EN,\n\t\t\t\t phy_rate);\n\tif (ret)\n\t\treturn ret;\n\n\tfsleep(300);\n\n\tret = rtw89_read16_mdio(rtwdev, RAC_CTRL_PPR_V1, phy_rate, &tar);\n\tif (ret)\n\t\treturn ret;\n\tret = rtw89_write16_mdio(rtwdev, RAC_CTRL_PPR_V1, val & ~B_AX_CLK_CALIB_EN,\n\t\t\t\t phy_rate);\n\tif (ret)\n\t\treturn ret;\n\n\ttar = tar & 0x0FFF;\n\tif (tar == 0 || tar == 0x0FFF) {\n\t\trtw89_err(rtwdev, \"[ERR]Get target failed.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t*target = tar;\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_autok_x(struct rtw89_dev *rtwdev)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tint ret;\n\n\tif (chip_id != RTL8852B && chip_id != RTL8851B)\n\t\treturn 0;\n\n\tret = rtw89_write16_mdio_mask(rtwdev, RAC_REG_FLD_0, BAC_AUTOK_N_MASK,\n\t\t\t\t      PCIE_AUTOK_4, PCIE_PHY_GEN1);\n\treturn ret;\n}\n\nstatic int rtw89_pci_auto_refclk_cal(struct rtw89_dev *rtwdev, bool autook_en)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tenum rtw89_pcie_phy phy_rate;\n\tu16 val16, mgn_set, div_set, tar;\n\tu8 val8, bdr_ori;\n\tbool l1_flag = false;\n\tint ret = 0;\n\n\tif (chip_id != RTL8852B && chip_id != RTL8851B)\n\t\treturn 0;\n\n\tret = rtw89_pci_read_config_byte(rtwdev, RTW89_PCIE_PHY_RATE, &val8);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]pci config read %X\\n\",\n\t\t\t  RTW89_PCIE_PHY_RATE);\n\t\treturn ret;\n\t}\n\n\tif (FIELD_GET(RTW89_PCIE_PHY_RATE_MASK, val8) == 0x1) {\n\t\tphy_rate = PCIE_PHY_GEN1;\n\t} else if (FIELD_GET(RTW89_PCIE_PHY_RATE_MASK, val8) == 0x2) {\n\t\tphy_rate = PCIE_PHY_GEN2;\n\t} else {\n\t\trtw89_err(rtwdev, \"[ERR]PCIe PHY rate %#x not support\\n\", val8);\n\t\treturn -EOPNOTSUPP;\n\t}\n\t \n\tret = rtw89_pci_read_config_byte(rtwdev, RTW89_PCIE_L1_CTRL, &bdr_ori);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]pci config read %X\\n\", RTW89_PCIE_L1_CTRL);\n\t\treturn ret;\n\t}\n\n\tif (bdr_ori & RTW89_PCIE_BIT_L1) {\n\t\tret = rtw89_pci_write_config_byte(rtwdev, RTW89_PCIE_L1_CTRL,\n\t\t\t\t\t\t  bdr_ori & ~RTW89_PCIE_BIT_L1);\n\t\tif (ret) {\n\t\t\trtw89_err(rtwdev, \"[ERR]pci config write %X\\n\",\n\t\t\t\t  RTW89_PCIE_L1_CTRL);\n\t\t\treturn ret;\n\t\t}\n\t\tl1_flag = true;\n\t}\n\n\tret = rtw89_read16_mdio(rtwdev, RAC_CTRL_PPR_V1, phy_rate, &val16);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]mdio_r16_pcie %X\\n\", RAC_CTRL_PPR_V1);\n\t\tgoto end;\n\t}\n\n\tif (val16 & B_AX_CALIB_EN) {\n\t\tret = rtw89_write16_mdio(rtwdev, RAC_CTRL_PPR_V1,\n\t\t\t\t\t val16 & ~B_AX_CALIB_EN, phy_rate);\n\t\tif (ret) {\n\t\t\trtw89_err(rtwdev, \"[ERR]mdio_w16_pcie %X\\n\", RAC_CTRL_PPR_V1);\n\t\t\tgoto end;\n\t\t}\n\t}\n\n\tif (!autook_en)\n\t\tgoto end;\n\t \n\tret = rtw89_write16_mdio_clr(rtwdev, RAC_CTRL_PPR_V1, B_AX_DIV, phy_rate);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]mdio_w16_pcie %X\\n\", RAC_CTRL_PPR_V1);\n\t\tgoto end;\n\t}\n\n\t \n\tret = __get_target(rtwdev, &tar, phy_rate);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]1st get target fail %d\\n\", ret);\n\t\tgoto end;\n\t}\n\n\tmgn_set = tar * INTF_INTGRA_HOSTREF_V1 / INTF_INTGRA_MINREF_V1 - tar;\n\n\tif (mgn_set >= 128) {\n\t\tdiv_set = 0x0003;\n\t\tmgn_set = 0x000F;\n\t} else if (mgn_set >= 64) {\n\t\tdiv_set = 0x0003;\n\t\tmgn_set >>= 3;\n\t} else if (mgn_set >= 32) {\n\t\tdiv_set = 0x0002;\n\t\tmgn_set >>= 2;\n\t} else if (mgn_set >= 16) {\n\t\tdiv_set = 0x0001;\n\t\tmgn_set >>= 1;\n\t} else if (mgn_set == 0) {\n\t\trtw89_err(rtwdev, \"[ERR]cal mgn is 0,tar = %d\\n\", tar);\n\t\tgoto end;\n\t} else {\n\t\tdiv_set = 0x0000;\n\t}\n\n\tret = rtw89_read16_mdio(rtwdev, RAC_CTRL_PPR_V1, phy_rate, &val16);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]mdio_r16_pcie %X\\n\", RAC_CTRL_PPR_V1);\n\t\tgoto end;\n\t}\n\n\tval16 |= u16_encode_bits(div_set, B_AX_DIV);\n\n\tret = rtw89_write16_mdio(rtwdev, RAC_CTRL_PPR_V1, val16, phy_rate);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]mdio_w16_pcie %X\\n\", RAC_CTRL_PPR_V1);\n\t\tgoto end;\n\t}\n\n\tret = __get_target(rtwdev, &tar, phy_rate);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]2nd get target fail %d\\n\", ret);\n\t\tgoto end;\n\t}\n\n\trtw89_debug(rtwdev, RTW89_DBG_HCI, \"[TRACE]target = 0x%X, div = 0x%X, margin = 0x%X\\n\",\n\t\t    tar, div_set, mgn_set);\n\tret = rtw89_write16_mdio(rtwdev, RAC_SET_PPR_V1,\n\t\t\t\t (tar & 0x0FFF) | (mgn_set << 12), phy_rate);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]mdio_w16_pcie %X\\n\", RAC_SET_PPR_V1);\n\t\tgoto end;\n\t}\n\n\t \n\tret = rtw89_write16_mdio_set(rtwdev, RAC_CTRL_PPR_V1, B_AX_CALIB_EN, phy_rate);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR]mdio_w16_pcie %X\\n\", RAC_CTRL_PPR_V1);\n\t\tgoto end;\n\t}\n\n\t \n\tret = rtw89_pci_write_config_byte(rtwdev, RTW89_PCIE_CLK_CTRL,\n\t\t\t\t\t  PCIE_CLKDLY_HW_0);\n\nend:\n\t \n\tif (l1_flag) {\n\t\tret = rtw89_pci_write_config_byte(rtwdev, RTW89_PCIE_L1_CTRL,\n\t\t\t\t\t\t  bdr_ori);\n\t\tif (ret) {\n\t\t\trtw89_err(rtwdev, \"[ERR]pci config write %X\\n\",\n\t\t\t\t  RTW89_PCIE_L1_CTRL);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int rtw89_pci_deglitch_setting(struct rtw89_dev *rtwdev)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tint ret;\n\n\tif (chip_id == RTL8852A) {\n\t\tret = rtw89_write16_mdio_clr(rtwdev, RAC_ANA24, B_AX_DEGLITCH,\n\t\t\t\t\t     PCIE_PHY_GEN1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tret = rtw89_write16_mdio_clr(rtwdev, RAC_ANA24, B_AX_DEGLITCH,\n\t\t\t\t\t     PCIE_PHY_GEN2);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} else if (chip_id == RTL8852C) {\n\t\trtw89_write16_clr(rtwdev, R_RAC_DIRECT_OFFSET_G1 + RAC_ANA24 * 2,\n\t\t\t\t  B_AX_DEGLITCH);\n\t\trtw89_write16_clr(rtwdev, R_RAC_DIRECT_OFFSET_G2 + RAC_ANA24 * 2,\n\t\t\t\t  B_AX_DEGLITCH);\n\t}\n\n\treturn 0;\n}\n\nstatic void rtw89_pci_rxdma_prefth(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id != RTL8852A)\n\t\treturn;\n\n\trtw89_write32_set(rtwdev, R_AX_PCIE_INIT_CFG1, B_AX_DIS_RXDMA_PRE);\n}\n\nstatic void rtw89_pci_l1off_pwroff(struct rtw89_dev *rtwdev)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\n\tif (chip_id != RTL8852A && chip_id != RTL8852B && chip_id != RTL8851B)\n\t\treturn;\n\n\trtw89_write32_clr(rtwdev, R_AX_PCIE_PS_CTRL, B_AX_L1OFF_PWR_OFF_EN);\n}\n\nstatic u32 rtw89_pci_l2_rxen_lat(struct rtw89_dev *rtwdev)\n{\n\tint ret;\n\n\tif (rtwdev->chip->chip_id != RTL8852A)\n\t\treturn 0;\n\n\tret = rtw89_write16_mdio_clr(rtwdev, RAC_ANA26, B_AX_RXEN,\n\t\t\t\t     PCIE_PHY_GEN1);\n\tif (ret)\n\t\treturn ret;\n\n\tret = rtw89_write16_mdio_clr(rtwdev, RAC_ANA26, B_AX_RXEN,\n\t\t\t\t     PCIE_PHY_GEN2);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic void rtw89_pci_aphy_pwrcut(struct rtw89_dev *rtwdev)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\n\tif (chip_id != RTL8852A && chip_id != RTL8852B && chip_id != RTL8851B)\n\t\treturn;\n\n\trtw89_write32_clr(rtwdev, R_AX_SYS_PW_CTRL, B_AX_PSUS_OFF_CAPC_EN);\n}\n\nstatic void rtw89_pci_hci_ldo(struct rtw89_dev *rtwdev)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852B || chip_id == RTL8851B) {\n\t\trtw89_write32_set(rtwdev, R_AX_SYS_SDIO_CTRL,\n\t\t\t\t  B_AX_PCIE_DIS_L2_CTRL_LDO_HCI);\n\t\trtw89_write32_clr(rtwdev, R_AX_SYS_SDIO_CTRL,\n\t\t\t\t  B_AX_PCIE_DIS_WLSUS_AFT_PDN);\n\t} else if (rtwdev->chip->chip_id == RTL8852C) {\n\t\trtw89_write32_clr(rtwdev, R_AX_SYS_SDIO_CTRL,\n\t\t\t\t  B_AX_PCIE_DIS_L2_CTRL_LDO_HCI);\n\t}\n}\n\nstatic int rtw89_pci_dphy_delay(struct rtw89_dev *rtwdev)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\n\tif (chip_id != RTL8852B && chip_id != RTL8851B)\n\t\treturn 0;\n\n\treturn rtw89_write16_mdio_mask(rtwdev, RAC_REG_REV2, BAC_CMU_EN_DLY_MASK,\n\t\t\t\t       PCIE_DPHY_DLY_25US, PCIE_PHY_GEN1);\n}\n\nstatic void rtw89_pci_power_wake(struct rtw89_dev *rtwdev, bool pwr_up)\n{\n\tif (pwr_up)\n\t\trtw89_write32_set(rtwdev, R_AX_HCI_OPT_CTRL, BIT_WAKE_CTRL);\n\telse\n\t\trtw89_write32_clr(rtwdev, R_AX_HCI_OPT_CTRL, BIT_WAKE_CTRL);\n}\n\nstatic void rtw89_pci_autoload_hang(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id != RTL8852C)\n\t\treturn;\n\n\trtw89_write32_set(rtwdev, R_AX_PCIE_BG_CLR, B_AX_BG_CLR_ASYNC_M3);\n\trtw89_write32_clr(rtwdev, R_AX_PCIE_BG_CLR, B_AX_BG_CLR_ASYNC_M3);\n}\n\nstatic void rtw89_pci_l12_vmain(struct rtw89_dev *rtwdev)\n{\n\tif (!(rtwdev->chip->chip_id == RTL8852C && rtwdev->hal.cv == CHIP_CAV))\n\t\treturn;\n\n\trtw89_write32_set(rtwdev, R_AX_SYS_SDIO_CTRL, B_AX_PCIE_FORCE_PWR_NGAT);\n}\n\nstatic void rtw89_pci_gen2_force_ib(struct rtw89_dev *rtwdev)\n{\n\tif (!(rtwdev->chip->chip_id == RTL8852C && rtwdev->hal.cv == CHIP_CAV))\n\t\treturn;\n\n\trtw89_write32_set(rtwdev, R_AX_PMC_DBG_CTRL2,\n\t\t\t  B_AX_SYSON_DIS_PMCR_AX_WRMSK);\n\trtw89_write32_set(rtwdev, R_AX_HCI_BG_CTRL, B_AX_BG_CLR_ASYNC_M3);\n\trtw89_write32_clr(rtwdev, R_AX_PMC_DBG_CTRL2,\n\t\t\t  B_AX_SYSON_DIS_PMCR_AX_WRMSK);\n}\n\nstatic void rtw89_pci_l1_ent_lat(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id != RTL8852C)\n\t\treturn;\n\n\trtw89_write32_clr(rtwdev, R_AX_PCIE_PS_CTRL_V1, B_AX_SEL_REQ_ENTR_L1);\n}\n\nstatic void rtw89_pci_wd_exit_l1(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id != RTL8852C)\n\t\treturn;\n\n\trtw89_write32_set(rtwdev, R_AX_PCIE_PS_CTRL_V1, B_AX_DMAC0_EXIT_L1_EN);\n}\n\nstatic void rtw89_pci_set_sic(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id == RTL8852C)\n\t\treturn;\n\n\trtw89_write32_clr(rtwdev, R_AX_PCIE_EXP_CTRL,\n\t\t\t  B_AX_SIC_EN_FORCE_CLKREQ);\n}\n\nstatic void rtw89_pci_set_lbc(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tu32 lbc;\n\n\tif (rtwdev->chip->chip_id == RTL8852C)\n\t\treturn;\n\n\tlbc = rtw89_read32(rtwdev, R_AX_LBC_WATCHDOG);\n\tif (info->lbc_en == MAC_AX_PCIE_ENABLE) {\n\t\tlbc = u32_replace_bits(lbc, info->lbc_tmr, B_AX_LBC_TIMER);\n\t\tlbc |= B_AX_LBC_FLAG | B_AX_LBC_EN;\n\t\trtw89_write32(rtwdev, R_AX_LBC_WATCHDOG, lbc);\n\t} else {\n\t\tlbc &= ~B_AX_LBC_EN;\n\t}\n\trtw89_write32_set(rtwdev, R_AX_LBC_WATCHDOG, lbc);\n}\n\nstatic void rtw89_pci_set_io_rcy(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tu32 val32;\n\n\tif (rtwdev->chip->chip_id != RTL8852C)\n\t\treturn;\n\n\tif (info->io_rcy_en == MAC_AX_PCIE_ENABLE) {\n\t\tval32 = FIELD_PREP(B_AX_PCIE_WDT_TIMER_M1_MASK,\n\t\t\t\t   info->io_rcy_tmr);\n\t\trtw89_write32(rtwdev, R_AX_PCIE_WDT_TIMER_M1, val32);\n\t\trtw89_write32(rtwdev, R_AX_PCIE_WDT_TIMER_M2, val32);\n\t\trtw89_write32(rtwdev, R_AX_PCIE_WDT_TIMER_E0, val32);\n\n\t\trtw89_write32_set(rtwdev, R_AX_PCIE_IO_RCY_M1, B_AX_PCIE_IO_RCY_WDT_MODE_M1);\n\t\trtw89_write32_set(rtwdev, R_AX_PCIE_IO_RCY_M2, B_AX_PCIE_IO_RCY_WDT_MODE_M2);\n\t\trtw89_write32_set(rtwdev, R_AX_PCIE_IO_RCY_E0, B_AX_PCIE_IO_RCY_WDT_MODE_E0);\n\t} else {\n\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_IO_RCY_M1, B_AX_PCIE_IO_RCY_WDT_MODE_M1);\n\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_IO_RCY_M2, B_AX_PCIE_IO_RCY_WDT_MODE_M2);\n\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_IO_RCY_E0, B_AX_PCIE_IO_RCY_WDT_MODE_E0);\n\t}\n\n\trtw89_write32_clr(rtwdev, R_AX_PCIE_IO_RCY_S1, B_AX_PCIE_IO_RCY_WDT_MODE_S1);\n}\n\nstatic void rtw89_pci_set_dbg(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id == RTL8852C)\n\t\treturn;\n\n\trtw89_write32_set(rtwdev, R_AX_PCIE_DBG_CTRL,\n\t\t\t  B_AX_ASFF_FULL_NO_STK | B_AX_EN_STUCK_DBG);\n\n\tif (rtwdev->chip->chip_id == RTL8852A)\n\t\trtw89_write32_set(rtwdev, R_AX_PCIE_EXP_CTRL,\n\t\t\t\t  B_AX_EN_CHKDSC_NO_RX_STUCK);\n}\n\nstatic void rtw89_pci_set_keep_reg(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id == RTL8852C)\n\t\treturn;\n\n\trtw89_write32_set(rtwdev, R_AX_PCIE_INIT_CFG1,\n\t\t\t  B_AX_PCIE_TXRST_KEEP_REG | B_AX_PCIE_RXRST_KEEP_REG);\n}\n\nstatic void rtw89_pci_clr_idx_all(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tu32 val = B_AX_CLR_ACH0_IDX | B_AX_CLR_ACH1_IDX | B_AX_CLR_ACH2_IDX |\n\t\t  B_AX_CLR_ACH3_IDX | B_AX_CLR_CH8_IDX | B_AX_CLR_CH9_IDX |\n\t\t  B_AX_CLR_CH12_IDX;\n\tu32 rxbd_rwptr_clr = info->rxbd_rwptr_clr_reg;\n\tu32 txbd_rwptr_clr2 = info->txbd_rwptr_clr2_reg;\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852C)\n\t\tval |= B_AX_CLR_ACH4_IDX | B_AX_CLR_ACH5_IDX |\n\t\t       B_AX_CLR_ACH6_IDX | B_AX_CLR_ACH7_IDX;\n\t \n\trtw89_write32_set(rtwdev, R_AX_TXBD_RWPTR_CLR1, val);\n\tif (chip_id == RTL8852A || chip_id == RTL8852C)\n\t\trtw89_write32_set(rtwdev, txbd_rwptr_clr2,\n\t\t\t\t  B_AX_CLR_CH10_IDX | B_AX_CLR_CH11_IDX);\n\trtw89_write32_set(rtwdev, rxbd_rwptr_clr,\n\t\t\t  B_AX_CLR_RXQ_IDX | B_AX_CLR_RPQ_IDX);\n}\n\nstatic int rtw89_poll_txdma_ch_idle_pcie(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tu32 ret, check, dma_busy;\n\tu32 dma_busy1 = info->dma_busy1.addr;\n\tu32 dma_busy2 = info->dma_busy2_reg;\n\n\tcheck = info->dma_busy1.mask;\n\n\tret = read_poll_timeout(rtw89_read32, dma_busy, (dma_busy & check) == 0,\n\t\t\t\t10, 100, false, rtwdev, dma_busy1);\n\tif (ret)\n\t\treturn ret;\n\n\tif (!dma_busy2)\n\t\treturn 0;\n\n\tcheck = B_AX_CH10_BUSY | B_AX_CH11_BUSY;\n\n\tret = read_poll_timeout(rtw89_read32, dma_busy, (dma_busy & check) == 0,\n\t\t\t\t10, 100, false, rtwdev, dma_busy2);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int rtw89_poll_rxdma_ch_idle_pcie(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tu32 ret, check, dma_busy;\n\tu32 dma_busy3 = info->dma_busy3_reg;\n\n\tcheck = B_AX_RXQ_BUSY | B_AX_RPQ_BUSY;\n\n\tret = read_poll_timeout(rtw89_read32, dma_busy, (dma_busy & check) == 0,\n\t\t\t\t10, 100, false, rtwdev, dma_busy3);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_poll_dma_all_idle(struct rtw89_dev *rtwdev)\n{\n\tu32 ret;\n\n\tret = rtw89_poll_txdma_ch_idle_pcie(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"txdma ch busy\\n\");\n\t\treturn ret;\n\t}\n\n\tret = rtw89_poll_rxdma_ch_idle_pcie(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"rxdma ch busy\\n\");\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_mode_op(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tenum mac_ax_bd_trunc_mode txbd_trunc_mode = info->txbd_trunc_mode;\n\tenum mac_ax_bd_trunc_mode rxbd_trunc_mode = info->rxbd_trunc_mode;\n\tenum mac_ax_rxbd_mode rxbd_mode = info->rxbd_mode;\n\tenum mac_ax_tag_mode tag_mode = info->tag_mode;\n\tenum mac_ax_wd_dma_intvl wd_dma_idle_intvl = info->wd_dma_idle_intvl;\n\tenum mac_ax_wd_dma_intvl wd_dma_act_intvl = info->wd_dma_act_intvl;\n\tenum mac_ax_tx_burst tx_burst = info->tx_burst;\n\tenum mac_ax_rx_burst rx_burst = info->rx_burst;\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tu8 cv = rtwdev->hal.cv;\n\tu32 val32;\n\n\tif (txbd_trunc_mode == MAC_AX_BD_TRUNC) {\n\t\tif (chip_id == RTL8852A && cv == CHIP_CBV)\n\t\t\trtw89_write32_set(rtwdev, R_AX_PCIE_INIT_CFG1, B_AX_TX_TRUNC_MODE);\n\t} else if (txbd_trunc_mode == MAC_AX_BD_NORM) {\n\t\tif (chip_id == RTL8852A || chip_id == RTL8852B)\n\t\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_INIT_CFG1, B_AX_TX_TRUNC_MODE);\n\t}\n\n\tif (rxbd_trunc_mode == MAC_AX_BD_TRUNC) {\n\t\tif (chip_id == RTL8852A && cv == CHIP_CBV)\n\t\t\trtw89_write32_set(rtwdev, R_AX_PCIE_INIT_CFG1, B_AX_RX_TRUNC_MODE);\n\t} else if (rxbd_trunc_mode == MAC_AX_BD_NORM) {\n\t\tif (chip_id == RTL8852A || chip_id == RTL8852B)\n\t\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_INIT_CFG1, B_AX_RX_TRUNC_MODE);\n\t}\n\n\tif (rxbd_mode == MAC_AX_RXBD_PKT) {\n\t\trtw89_write32_clr(rtwdev, info->init_cfg_reg, info->rxbd_mode_bit);\n\t} else if (rxbd_mode == MAC_AX_RXBD_SEP) {\n\t\trtw89_write32_set(rtwdev, info->init_cfg_reg, info->rxbd_mode_bit);\n\n\t\tif (chip_id == RTL8852A || chip_id == RTL8852B)\n\t\t\trtw89_write32_mask(rtwdev, R_AX_PCIE_INIT_CFG2,\n\t\t\t\t\t   B_AX_PCIE_RX_APPLEN_MASK, 0);\n\t}\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852B) {\n\t\trtw89_write32_mask(rtwdev, R_AX_PCIE_INIT_CFG1, B_AX_PCIE_MAX_TXDMA_MASK, tx_burst);\n\t\trtw89_write32_mask(rtwdev, R_AX_PCIE_INIT_CFG1, B_AX_PCIE_MAX_RXDMA_MASK, rx_burst);\n\t} else if (chip_id == RTL8852C) {\n\t\trtw89_write32_mask(rtwdev, R_AX_HAXI_INIT_CFG1, B_AX_HAXI_MAX_TXDMA_MASK, tx_burst);\n\t\trtw89_write32_mask(rtwdev, R_AX_HAXI_INIT_CFG1, B_AX_HAXI_MAX_RXDMA_MASK, rx_burst);\n\t}\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852B) {\n\t\tif (tag_mode == MAC_AX_TAG_SGL) {\n\t\t\tval32 = rtw89_read32(rtwdev, R_AX_PCIE_INIT_CFG1) &\n\t\t\t\t\t    ~B_AX_LATENCY_CONTROL;\n\t\t\trtw89_write32(rtwdev, R_AX_PCIE_INIT_CFG1, val32);\n\t\t} else if (tag_mode == MAC_AX_TAG_MULTI) {\n\t\t\tval32 = rtw89_read32(rtwdev, R_AX_PCIE_INIT_CFG1) |\n\t\t\t\t\t    B_AX_LATENCY_CONTROL;\n\t\t\trtw89_write32(rtwdev, R_AX_PCIE_INIT_CFG1, val32);\n\t\t}\n\t}\n\n\trtw89_write32_mask(rtwdev, info->exp_ctrl_reg, info->max_tag_num_mask,\n\t\t\t   info->multi_tag_num);\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852B) {\n\t\trtw89_write32_mask(rtwdev, R_AX_PCIE_INIT_CFG2, B_AX_WD_ITVL_IDLE,\n\t\t\t\t   wd_dma_idle_intvl);\n\t\trtw89_write32_mask(rtwdev, R_AX_PCIE_INIT_CFG2, B_AX_WD_ITVL_ACT,\n\t\t\t\t   wd_dma_act_intvl);\n\t} else if (chip_id == RTL8852C) {\n\t\trtw89_write32_mask(rtwdev, R_AX_HAXI_INIT_CFG1, B_AX_WD_ITVL_IDLE_V1_MASK,\n\t\t\t\t   wd_dma_idle_intvl);\n\t\trtw89_write32_mask(rtwdev, R_AX_HAXI_INIT_CFG1, B_AX_WD_ITVL_ACT_V1_MASK,\n\t\t\t\t   wd_dma_act_intvl);\n\t}\n\n\tif (txbd_trunc_mode == MAC_AX_BD_TRUNC) {\n\t\trtw89_write32_set(rtwdev, R_AX_TX_ADDRESS_INFO_MODE_SETTING,\n\t\t\t\t  B_AX_HOST_ADDR_INFO_8B_SEL);\n\t\trtw89_write32_clr(rtwdev, R_AX_PKTIN_SETTING, B_AX_WD_ADDR_INFO_LENGTH);\n\t} else if (txbd_trunc_mode == MAC_AX_BD_NORM) {\n\t\trtw89_write32_clr(rtwdev, R_AX_TX_ADDRESS_INFO_MODE_SETTING,\n\t\t\t\t  B_AX_HOST_ADDR_INFO_8B_SEL);\n\t\trtw89_write32_set(rtwdev, R_AX_PKTIN_SETTING, B_AX_WD_ADDR_INFO_LENGTH);\n\t}\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_ops_deinit(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\n\tif (rtwdev->chip->chip_id == RTL8852A) {\n\t\t \n\t\trtw89_write32_set(rtwdev, R_AX_LTR_CTRL_0, B_AX_APP_LTR_IDLE);\n\t}\n\tinfo->ltr_set(rtwdev, false);\n\trtw89_pci_ctrl_dma_all(rtwdev, false);\n\trtw89_pci_clr_idx_all(rtwdev);\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_ops_mac_pre_init(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tint ret;\n\n\trtw89_pci_rxdma_prefth(rtwdev);\n\trtw89_pci_l1off_pwroff(rtwdev);\n\trtw89_pci_deglitch_setting(rtwdev);\n\tret = rtw89_pci_l2_rxen_lat(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR] pcie l2 rxen lat %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\trtw89_pci_aphy_pwrcut(rtwdev);\n\trtw89_pci_hci_ldo(rtwdev);\n\trtw89_pci_dphy_delay(rtwdev);\n\n\tret = rtw89_pci_autok_x(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR] pcie autok_x fail %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = rtw89_pci_auto_refclk_cal(rtwdev, false);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR] pcie autok fail %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\trtw89_pci_power_wake(rtwdev, true);\n\trtw89_pci_autoload_hang(rtwdev);\n\trtw89_pci_l12_vmain(rtwdev);\n\trtw89_pci_gen2_force_ib(rtwdev);\n\trtw89_pci_l1_ent_lat(rtwdev);\n\trtw89_pci_wd_exit_l1(rtwdev);\n\trtw89_pci_set_sic(rtwdev);\n\trtw89_pci_set_lbc(rtwdev);\n\trtw89_pci_set_io_rcy(rtwdev);\n\trtw89_pci_set_dbg(rtwdev);\n\trtw89_pci_set_keep_reg(rtwdev);\n\n\trtw89_write32_set(rtwdev, info->dma_stop1.addr, B_AX_STOP_WPDMA);\n\n\t \n\trtw89_pci_ctrl_dma_all(rtwdev, false);\n\n\tret = rtw89_pci_poll_dma_all_idle(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"[ERR] poll pcie dma all idle\\n\");\n\t\treturn ret;\n\t}\n\n\trtw89_pci_clr_idx_all(rtwdev);\n\trtw89_pci_mode_op(rtwdev);\n\n\t \n\trtw89_pci_ops_reset(rtwdev);\n\n\tret = rtw89_pci_rst_bdram_pcie(rtwdev);\n\tif (ret) {\n\t\trtw89_warn(rtwdev, \"reset bdram busy\\n\");\n\t\treturn ret;\n\t}\n\n\t \n\trtw89_pci_ctrl_txdma_ch_pcie(rtwdev, false);\n\trtw89_pci_ctrl_txdma_fw_ch_pcie(rtwdev, true);\n\n\t \n\trtw89_pci_ctrl_dma_all(rtwdev, true);\n\n\treturn 0;\n}\n\nint rtw89_pci_ltr_set(struct rtw89_dev *rtwdev, bool en)\n{\n\tu32 val;\n\n\tif (!en)\n\t\treturn 0;\n\n\tval = rtw89_read32(rtwdev, R_AX_LTR_CTRL_0);\n\tif (rtw89_pci_ltr_is_err_reg_val(val))\n\t\treturn -EINVAL;\n\tval = rtw89_read32(rtwdev, R_AX_LTR_CTRL_1);\n\tif (rtw89_pci_ltr_is_err_reg_val(val))\n\t\treturn -EINVAL;\n\tval = rtw89_read32(rtwdev, R_AX_LTR_IDLE_LATENCY);\n\tif (rtw89_pci_ltr_is_err_reg_val(val))\n\t\treturn -EINVAL;\n\tval = rtw89_read32(rtwdev, R_AX_LTR_ACTIVE_LATENCY);\n\tif (rtw89_pci_ltr_is_err_reg_val(val))\n\t\treturn -EINVAL;\n\n\trtw89_write32_set(rtwdev, R_AX_LTR_CTRL_0, B_AX_LTR_HW_EN | B_AX_LTR_EN |\n\t\t\t\t\t\t   B_AX_LTR_WD_NOEMP_CHK);\n\trtw89_write32_mask(rtwdev, R_AX_LTR_CTRL_0, B_AX_LTR_SPACE_IDX_MASK,\n\t\t\t   PCI_LTR_SPC_500US);\n\trtw89_write32_mask(rtwdev, R_AX_LTR_CTRL_0, B_AX_LTR_IDLE_TIMER_IDX_MASK,\n\t\t\t   PCI_LTR_IDLE_TIMER_3_2MS);\n\trtw89_write32_mask(rtwdev, R_AX_LTR_CTRL_1, B_AX_LTR_RX0_TH_MASK, 0x28);\n\trtw89_write32_mask(rtwdev, R_AX_LTR_CTRL_1, B_AX_LTR_RX1_TH_MASK, 0x28);\n\trtw89_write32(rtwdev, R_AX_LTR_IDLE_LATENCY, 0x90039003);\n\trtw89_write32(rtwdev, R_AX_LTR_ACTIVE_LATENCY, 0x880b880b);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(rtw89_pci_ltr_set);\n\nint rtw89_pci_ltr_set_v1(struct rtw89_dev *rtwdev, bool en)\n{\n\tu32 dec_ctrl;\n\tu32 val32;\n\n\tval32 = rtw89_read32(rtwdev, R_AX_LTR_CTRL_0);\n\tif (rtw89_pci_ltr_is_err_reg_val(val32))\n\t\treturn -EINVAL;\n\tval32 = rtw89_read32(rtwdev, R_AX_LTR_CTRL_1);\n\tif (rtw89_pci_ltr_is_err_reg_val(val32))\n\t\treturn -EINVAL;\n\tdec_ctrl = rtw89_read32(rtwdev, R_AX_LTR_DEC_CTRL);\n\tif (rtw89_pci_ltr_is_err_reg_val(dec_ctrl))\n\t\treturn -EINVAL;\n\tval32 = rtw89_read32(rtwdev, R_AX_LTR_LATENCY_IDX3);\n\tif (rtw89_pci_ltr_is_err_reg_val(val32))\n\t\treturn -EINVAL;\n\tval32 = rtw89_read32(rtwdev, R_AX_LTR_LATENCY_IDX0);\n\tif (rtw89_pci_ltr_is_err_reg_val(val32))\n\t\treturn -EINVAL;\n\n\tif (!en) {\n\t\tdec_ctrl &= ~(LTR_EN_BITS | B_AX_LTR_IDX_DRV_MASK | B_AX_LTR_HW_DEC_EN);\n\t\tdec_ctrl |= FIELD_PREP(B_AX_LTR_IDX_DRV_MASK, PCIE_LTR_IDX_IDLE) |\n\t\t\t    B_AX_LTR_REQ_DRV;\n\t} else {\n\t\tdec_ctrl |= B_AX_LTR_HW_DEC_EN;\n\t}\n\n\tdec_ctrl &= ~B_AX_LTR_SPACE_IDX_V1_MASK;\n\tdec_ctrl |= FIELD_PREP(B_AX_LTR_SPACE_IDX_V1_MASK, PCI_LTR_SPC_500US);\n\n\tif (en)\n\t\trtw89_write32_set(rtwdev, R_AX_LTR_CTRL_0,\n\t\t\t\t  B_AX_LTR_WD_NOEMP_CHK_V1 | B_AX_LTR_HW_EN);\n\trtw89_write32_mask(rtwdev, R_AX_LTR_CTRL_0, B_AX_LTR_IDLE_TIMER_IDX_MASK,\n\t\t\t   PCI_LTR_IDLE_TIMER_3_2MS);\n\trtw89_write32_mask(rtwdev, R_AX_LTR_CTRL_1, B_AX_LTR_RX0_TH_MASK, 0x28);\n\trtw89_write32_mask(rtwdev, R_AX_LTR_CTRL_1, B_AX_LTR_RX1_TH_MASK, 0x28);\n\trtw89_write32(rtwdev, R_AX_LTR_DEC_CTRL, dec_ctrl);\n\trtw89_write32(rtwdev, R_AX_LTR_LATENCY_IDX3, 0x90039003);\n\trtw89_write32(rtwdev, R_AX_LTR_LATENCY_IDX0, 0x880b880b);\n\n\treturn 0;\n}\nEXPORT_SYMBOL(rtw89_pci_ltr_set_v1);\n\nstatic int rtw89_pci_ops_mac_post_init(struct rtw89_dev *rtwdev)\n{\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tint ret;\n\n\tret = info->ltr_set(rtwdev, true);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"pci ltr set fail\\n\");\n\t\treturn ret;\n\t}\n\tif (chip_id == RTL8852A) {\n\t\t \n\t\trtw89_write32_set(rtwdev, R_AX_LTR_CTRL_0, B_AX_APP_LTR_ACT);\n\t}\n\tif (chip_id == RTL8852A || chip_id == RTL8852B) {\n\t\t \n\t\trtw89_write32_set(rtwdev, R_AX_TX_ADDRESS_INFO_MODE_SETTING,\n\t\t\t\t  B_AX_HOST_ADDR_INFO_8B_SEL);\n\t\trtw89_write32_clr(rtwdev, R_AX_PKTIN_SETTING, B_AX_WD_ADDR_INFO_LENGTH);\n\t}\n\n\t \n\trtw89_pci_ctrl_txdma_ch_pcie(rtwdev, true);\n\n\t \n\trtw89_write32_clr(rtwdev, info->dma_stop1.addr,\n\t\t\t  B_AX_STOP_WPDMA | B_AX_STOP_PCIEIO);\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_claim_device(struct rtw89_dev *rtwdev,\n\t\t\t\t  struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tint ret;\n\n\tret = pci_enable_device(pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to enable pci device\\n\");\n\t\treturn ret;\n\t}\n\n\tpci_set_master(pdev);\n\tpci_set_drvdata(pdev, rtwdev->hw);\n\n\trtwpci->pdev = pdev;\n\n\treturn 0;\n}\n\nstatic void rtw89_pci_declaim_device(struct rtw89_dev *rtwdev,\n\t\t\t\t     struct pci_dev *pdev)\n{\n\tpci_disable_device(pdev);\n}\n\nstatic int rtw89_pci_setup_mapping(struct rtw89_dev *rtwdev,\n\t\t\t\t   struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tunsigned long resource_len;\n\tu8 bar_id = 2;\n\tint ret;\n\n\tret = pci_request_regions(pdev, KBUILD_MODNAME);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to request pci regions\\n\");\n\t\tgoto err;\n\t}\n\n\tret = dma_set_mask(&pdev->dev, DMA_BIT_MASK(32));\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to set dma mask to 32-bit\\n\");\n\t\tgoto err_release_regions;\n\t}\n\n\tret = dma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(32));\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to set consistent dma mask to 32-bit\\n\");\n\t\tgoto err_release_regions;\n\t}\n\n\tresource_len = pci_resource_len(pdev, bar_id);\n\trtwpci->mmap = pci_iomap(pdev, bar_id, resource_len);\n\tif (!rtwpci->mmap) {\n\t\trtw89_err(rtwdev, \"failed to map pci io\\n\");\n\t\tret = -EIO;\n\t\tgoto err_release_regions;\n\t}\n\n\treturn 0;\n\nerr_release_regions:\n\tpci_release_regions(pdev);\nerr:\n\treturn ret;\n}\n\nstatic void rtw89_pci_clear_mapping(struct rtw89_dev *rtwdev,\n\t\t\t\t    struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\tif (rtwpci->mmap) {\n\t\tpci_iounmap(pdev, rtwpci->mmap);\n\t\tpci_release_regions(pdev);\n\t}\n}\n\nstatic void rtw89_pci_free_tx_wd_ring(struct rtw89_dev *rtwdev,\n\t\t\t\t      struct pci_dev *pdev,\n\t\t\t\t      struct rtw89_pci_tx_ring *tx_ring)\n{\n\tstruct rtw89_pci_tx_wd_ring *wd_ring = &tx_ring->wd_ring;\n\tu8 *head = wd_ring->head;\n\tdma_addr_t dma = wd_ring->dma;\n\tu32 page_size = wd_ring->page_size;\n\tu32 page_num = wd_ring->page_num;\n\tu32 ring_sz = page_size * page_num;\n\n\tdma_free_coherent(&pdev->dev, ring_sz, head, dma);\n\twd_ring->head = NULL;\n}\n\nstatic void rtw89_pci_free_tx_ring(struct rtw89_dev *rtwdev,\n\t\t\t\t   struct pci_dev *pdev,\n\t\t\t\t   struct rtw89_pci_tx_ring *tx_ring)\n{\n\tint ring_sz;\n\tu8 *head;\n\tdma_addr_t dma;\n\n\thead = tx_ring->bd_ring.head;\n\tdma = tx_ring->bd_ring.dma;\n\tring_sz = tx_ring->bd_ring.desc_size * tx_ring->bd_ring.len;\n\tdma_free_coherent(&pdev->dev, ring_sz, head, dma);\n\n\ttx_ring->bd_ring.head = NULL;\n}\n\nstatic void rtw89_pci_free_tx_rings(struct rtw89_dev *rtwdev,\n\t\t\t\t    struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tstruct rtw89_pci_tx_ring *tx_ring;\n\tint i;\n\n\tfor (i = 0; i < RTW89_TXCH_NUM; i++) {\n\t\tif (info->tx_dma_ch_mask & BIT(i))\n\t\t\tcontinue;\n\t\ttx_ring = &rtwpci->tx_rings[i];\n\t\trtw89_pci_free_tx_wd_ring(rtwdev, pdev, tx_ring);\n\t\trtw89_pci_free_tx_ring(rtwdev, pdev, tx_ring);\n\t}\n}\n\nstatic void rtw89_pci_free_rx_ring(struct rtw89_dev *rtwdev,\n\t\t\t\t   struct pci_dev *pdev,\n\t\t\t\t   struct rtw89_pci_rx_ring *rx_ring)\n{\n\tstruct rtw89_pci_rx_info *rx_info;\n\tstruct sk_buff *skb;\n\tdma_addr_t dma;\n\tu32 buf_sz;\n\tu8 *head;\n\tint ring_sz = rx_ring->bd_ring.desc_size * rx_ring->bd_ring.len;\n\tint i;\n\n\tbuf_sz = rx_ring->buf_sz;\n\tfor (i = 0; i < rx_ring->bd_ring.len; i++) {\n\t\tskb = rx_ring->buf[i];\n\t\tif (!skb)\n\t\t\tcontinue;\n\n\t\trx_info = RTW89_PCI_RX_SKB_CB(skb);\n\t\tdma = rx_info->dma;\n\t\tdma_unmap_single(&pdev->dev, dma, buf_sz, DMA_FROM_DEVICE);\n\t\tdev_kfree_skb(skb);\n\t\trx_ring->buf[i] = NULL;\n\t}\n\n\thead = rx_ring->bd_ring.head;\n\tdma = rx_ring->bd_ring.dma;\n\tdma_free_coherent(&pdev->dev, ring_sz, head, dma);\n\n\trx_ring->bd_ring.head = NULL;\n}\n\nstatic void rtw89_pci_free_rx_rings(struct rtw89_dev *rtwdev,\n\t\t\t\t    struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tint i;\n\n\tfor (i = 0; i < RTW89_RXCH_NUM; i++) {\n\t\trx_ring = &rtwpci->rx_rings[i];\n\t\trtw89_pci_free_rx_ring(rtwdev, pdev, rx_ring);\n\t}\n}\n\nstatic void rtw89_pci_free_trx_rings(struct rtw89_dev *rtwdev,\n\t\t\t\t     struct pci_dev *pdev)\n{\n\trtw89_pci_free_rx_rings(rtwdev, pdev);\n\trtw89_pci_free_tx_rings(rtwdev, pdev);\n}\n\nstatic int rtw89_pci_init_rx_bd(struct rtw89_dev *rtwdev, struct pci_dev *pdev,\n\t\t\t\tstruct rtw89_pci_rx_ring *rx_ring,\n\t\t\t\tstruct sk_buff *skb, int buf_sz, u32 idx)\n{\n\tstruct rtw89_pci_rx_info *rx_info;\n\tstruct rtw89_pci_rx_bd_32 *rx_bd;\n\tdma_addr_t dma;\n\n\tif (!skb)\n\t\treturn -EINVAL;\n\n\tdma = dma_map_single(&pdev->dev, skb->data, buf_sz, DMA_FROM_DEVICE);\n\tif (dma_mapping_error(&pdev->dev, dma))\n\t\treturn -EBUSY;\n\n\trx_info = RTW89_PCI_RX_SKB_CB(skb);\n\trx_bd = RTW89_PCI_RX_BD(rx_ring, idx);\n\n\tmemset(rx_bd, 0, sizeof(*rx_bd));\n\trx_bd->buf_size = cpu_to_le16(buf_sz);\n\trx_bd->dma = cpu_to_le32(dma);\n\trx_info->dma = dma;\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_alloc_tx_wd_ring(struct rtw89_dev *rtwdev,\n\t\t\t\t      struct pci_dev *pdev,\n\t\t\t\t      struct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\t      enum rtw89_tx_channel txch)\n{\n\tstruct rtw89_pci_tx_wd_ring *wd_ring = &tx_ring->wd_ring;\n\tstruct rtw89_pci_tx_wd *txwd;\n\tdma_addr_t dma;\n\tdma_addr_t cur_paddr;\n\tu8 *head;\n\tu8 *cur_vaddr;\n\tu32 page_size = RTW89_PCI_TXWD_PAGE_SIZE;\n\tu32 page_num = RTW89_PCI_TXWD_NUM_MAX;\n\tu32 ring_sz = page_size * page_num;\n\tu32 page_offset;\n\tint i;\n\n\t \n\tif (txch == RTW89_TXCH_CH12)\n\t\treturn 0;\n\n\thead = dma_alloc_coherent(&pdev->dev, ring_sz, &dma, GFP_KERNEL);\n\tif (!head)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&wd_ring->free_pages);\n\twd_ring->head = head;\n\twd_ring->dma = dma;\n\twd_ring->page_size = page_size;\n\twd_ring->page_num = page_num;\n\n\tpage_offset = 0;\n\tfor (i = 0; i < page_num; i++) {\n\t\ttxwd = &wd_ring->pages[i];\n\t\tcur_paddr = dma + page_offset;\n\t\tcur_vaddr = head + page_offset;\n\n\t\tskb_queue_head_init(&txwd->queue);\n\t\tINIT_LIST_HEAD(&txwd->list);\n\t\ttxwd->paddr = cur_paddr;\n\t\ttxwd->vaddr = cur_vaddr;\n\t\ttxwd->len = page_size;\n\t\ttxwd->seq = i;\n\t\trtw89_pci_enqueue_txwd(tx_ring, txwd);\n\n\t\tpage_offset += page_size;\n\t}\n\n\treturn 0;\n}\n\nstatic int rtw89_pci_alloc_tx_ring(struct rtw89_dev *rtwdev,\n\t\t\t\t   struct pci_dev *pdev,\n\t\t\t\t   struct rtw89_pci_tx_ring *tx_ring,\n\t\t\t\t   u32 desc_size, u32 len,\n\t\t\t\t   enum rtw89_tx_channel txch)\n{\n\tconst struct rtw89_pci_ch_dma_addr *txch_addr;\n\tint ring_sz = desc_size * len;\n\tu8 *head;\n\tdma_addr_t dma;\n\tint ret;\n\n\tret = rtw89_pci_alloc_tx_wd_ring(rtwdev, pdev, tx_ring, txch);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to alloc txwd ring of txch %d\\n\", txch);\n\t\tgoto err;\n\t}\n\n\tret = rtw89_pci_get_txch_addrs(rtwdev, txch, &txch_addr);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to get address of txch %d\", txch);\n\t\tgoto err_free_wd_ring;\n\t}\n\n\thead = dma_alloc_coherent(&pdev->dev, ring_sz, &dma, GFP_KERNEL);\n\tif (!head) {\n\t\tret = -ENOMEM;\n\t\tgoto err_free_wd_ring;\n\t}\n\n\tINIT_LIST_HEAD(&tx_ring->busy_pages);\n\ttx_ring->bd_ring.head = head;\n\ttx_ring->bd_ring.dma = dma;\n\ttx_ring->bd_ring.len = len;\n\ttx_ring->bd_ring.desc_size = desc_size;\n\ttx_ring->bd_ring.addr = *txch_addr;\n\ttx_ring->bd_ring.wp = 0;\n\ttx_ring->bd_ring.rp = 0;\n\ttx_ring->txch = txch;\n\n\treturn 0;\n\nerr_free_wd_ring:\n\trtw89_pci_free_tx_wd_ring(rtwdev, pdev, tx_ring);\nerr:\n\treturn ret;\n}\n\nstatic int rtw89_pci_alloc_tx_rings(struct rtw89_dev *rtwdev,\n\t\t\t\t    struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_pci_info *info = rtwdev->pci_info;\n\tstruct rtw89_pci_tx_ring *tx_ring;\n\tu32 desc_size;\n\tu32 len;\n\tu32 i, tx_allocated;\n\tint ret;\n\n\tfor (i = 0; i < RTW89_TXCH_NUM; i++) {\n\t\tif (info->tx_dma_ch_mask & BIT(i))\n\t\t\tcontinue;\n\t\ttx_ring = &rtwpci->tx_rings[i];\n\t\tdesc_size = sizeof(struct rtw89_pci_tx_bd_32);\n\t\tlen = RTW89_PCI_TXBD_NUM_MAX;\n\t\tret = rtw89_pci_alloc_tx_ring(rtwdev, pdev, tx_ring,\n\t\t\t\t\t      desc_size, len, i);\n\t\tif (ret) {\n\t\t\trtw89_err(rtwdev, \"failed to alloc tx ring %d\\n\", i);\n\t\t\tgoto err_free;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_free:\n\ttx_allocated = i;\n\tfor (i = 0; i < tx_allocated; i++) {\n\t\ttx_ring = &rtwpci->tx_rings[i];\n\t\trtw89_pci_free_tx_ring(rtwdev, pdev, tx_ring);\n\t}\n\n\treturn ret;\n}\n\nstatic int rtw89_pci_alloc_rx_ring(struct rtw89_dev *rtwdev,\n\t\t\t\t   struct pci_dev *pdev,\n\t\t\t\t   struct rtw89_pci_rx_ring *rx_ring,\n\t\t\t\t   u32 desc_size, u32 len, u32 rxch)\n{\n\tconst struct rtw89_pci_ch_dma_addr *rxch_addr;\n\tstruct sk_buff *skb;\n\tu8 *head;\n\tdma_addr_t dma;\n\tint ring_sz = desc_size * len;\n\tint buf_sz = RTW89_PCI_RX_BUF_SIZE;\n\tint i, allocated;\n\tint ret;\n\n\tret = rtw89_pci_get_rxch_addrs(rtwdev, rxch, &rxch_addr);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to get address of rxch %d\", rxch);\n\t\treturn ret;\n\t}\n\n\thead = dma_alloc_coherent(&pdev->dev, ring_sz, &dma, GFP_KERNEL);\n\tif (!head) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\trx_ring->bd_ring.head = head;\n\trx_ring->bd_ring.dma = dma;\n\trx_ring->bd_ring.len = len;\n\trx_ring->bd_ring.desc_size = desc_size;\n\trx_ring->bd_ring.addr = *rxch_addr;\n\trx_ring->bd_ring.wp = 0;\n\trx_ring->bd_ring.rp = 0;\n\trx_ring->buf_sz = buf_sz;\n\trx_ring->diliver_skb = NULL;\n\trx_ring->diliver_desc.ready = false;\n\n\tfor (i = 0; i < len; i++) {\n\t\tskb = dev_alloc_skb(buf_sz);\n\t\tif (!skb) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err_free;\n\t\t}\n\n\t\tmemset(skb->data, 0, buf_sz);\n\t\trx_ring->buf[i] = skb;\n\t\tret = rtw89_pci_init_rx_bd(rtwdev, pdev, rx_ring, skb,\n\t\t\t\t\t   buf_sz, i);\n\t\tif (ret) {\n\t\t\trtw89_err(rtwdev, \"failed to init rx buf %d\\n\", i);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\trx_ring->buf[i] = NULL;\n\t\t\tgoto err_free;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_free:\n\tallocated = i;\n\tfor (i = 0; i < allocated; i++) {\n\t\tskb = rx_ring->buf[i];\n\t\tif (!skb)\n\t\t\tcontinue;\n\t\tdma = *((dma_addr_t *)skb->cb);\n\t\tdma_unmap_single(&pdev->dev, dma, buf_sz, DMA_FROM_DEVICE);\n\t\tdev_kfree_skb(skb);\n\t\trx_ring->buf[i] = NULL;\n\t}\n\n\thead = rx_ring->bd_ring.head;\n\tdma = rx_ring->bd_ring.dma;\n\tdma_free_coherent(&pdev->dev, ring_sz, head, dma);\n\n\trx_ring->bd_ring.head = NULL;\nerr:\n\treturn ret;\n}\n\nstatic int rtw89_pci_alloc_rx_rings(struct rtw89_dev *rtwdev,\n\t\t\t\t    struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct rtw89_pci_rx_ring *rx_ring;\n\tu32 desc_size;\n\tu32 len;\n\tint i, rx_allocated;\n\tint ret;\n\n\tfor (i = 0; i < RTW89_RXCH_NUM; i++) {\n\t\trx_ring = &rtwpci->rx_rings[i];\n\t\tdesc_size = sizeof(struct rtw89_pci_rx_bd_32);\n\t\tlen = RTW89_PCI_RXBD_NUM_MAX;\n\t\tret = rtw89_pci_alloc_rx_ring(rtwdev, pdev, rx_ring,\n\t\t\t\t\t      desc_size, len, i);\n\t\tif (ret) {\n\t\t\trtw89_err(rtwdev, \"failed to alloc rx ring %d\\n\", i);\n\t\t\tgoto err_free;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr_free:\n\trx_allocated = i;\n\tfor (i = 0; i < rx_allocated; i++) {\n\t\trx_ring = &rtwpci->rx_rings[i];\n\t\trtw89_pci_free_rx_ring(rtwdev, pdev, rx_ring);\n\t}\n\n\treturn ret;\n}\n\nstatic int rtw89_pci_alloc_trx_rings(struct rtw89_dev *rtwdev,\n\t\t\t\t     struct pci_dev *pdev)\n{\n\tint ret;\n\n\tret = rtw89_pci_alloc_tx_rings(rtwdev, pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to alloc dma tx rings\\n\");\n\t\tgoto err;\n\t}\n\n\tret = rtw89_pci_alloc_rx_rings(rtwdev, pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to alloc dma rx rings\\n\");\n\t\tgoto err_free_tx_rings;\n\t}\n\n\treturn 0;\n\nerr_free_tx_rings:\n\trtw89_pci_free_tx_rings(rtwdev, pdev);\nerr:\n\treturn ret;\n}\n\nstatic void rtw89_pci_h2c_init(struct rtw89_dev *rtwdev,\n\t\t\t       struct rtw89_pci *rtwpci)\n{\n\tskb_queue_head_init(&rtwpci->h2c_queue);\n\tskb_queue_head_init(&rtwpci->h2c_release_queue);\n}\n\nstatic int rtw89_pci_setup_resource(struct rtw89_dev *rtwdev,\n\t\t\t\t    struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tint ret;\n\n\tret = rtw89_pci_setup_mapping(rtwdev, pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to setup pci mapping\\n\");\n\t\tgoto err;\n\t}\n\n\tret = rtw89_pci_alloc_trx_rings(rtwdev, pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to alloc pci trx rings\\n\");\n\t\tgoto err_pci_unmap;\n\t}\n\n\trtw89_pci_h2c_init(rtwdev, rtwpci);\n\n\tspin_lock_init(&rtwpci->irq_lock);\n\tspin_lock_init(&rtwpci->trx_lock);\n\n\treturn 0;\n\nerr_pci_unmap:\n\trtw89_pci_clear_mapping(rtwdev, pdev);\nerr:\n\treturn ret;\n}\n\nstatic void rtw89_pci_clear_resource(struct rtw89_dev *rtwdev,\n\t\t\t\t     struct pci_dev *pdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\trtw89_pci_free_trx_rings(rtwdev, pdev);\n\trtw89_pci_clear_mapping(rtwdev, pdev);\n\trtw89_pci_release_fwcmd(rtwdev, rtwpci,\n\t\t\t\tskb_queue_len(&rtwpci->h2c_queue), true);\n}\n\nvoid rtw89_pci_config_intr_mask(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tconst struct rtw89_chip_info *chip = rtwdev->chip;\n\tu32 hs0isr_ind_int_en = B_AX_HS0ISR_IND_INT_EN;\n\n\tif (chip->chip_id == RTL8851B)\n\t\ths0isr_ind_int_en = B_AX_HS0ISR_IND_INT_EN_WKARND;\n\n\trtwpci->halt_c2h_intrs = B_AX_HALT_C2H_INT_EN | 0;\n\n\tif (rtwpci->under_recovery) {\n\t\trtwpci->intrs[0] = hs0isr_ind_int_en;\n\t\trtwpci->intrs[1] = 0;\n\t} else {\n\t\trtwpci->intrs[0] = B_AX_TXDMA_STUCK_INT_EN |\n\t\t\t\t   B_AX_RXDMA_INT_EN |\n\t\t\t\t   B_AX_RXP1DMA_INT_EN |\n\t\t\t\t   B_AX_RPQDMA_INT_EN |\n\t\t\t\t   B_AX_RXDMA_STUCK_INT_EN |\n\t\t\t\t   B_AX_RDU_INT_EN |\n\t\t\t\t   B_AX_RPQBD_FULL_INT_EN |\n\t\t\t\t   hs0isr_ind_int_en;\n\n\t\trtwpci->intrs[1] = B_AX_HC10ISR_IND_INT_EN;\n\t}\n}\nEXPORT_SYMBOL(rtw89_pci_config_intr_mask);\n\nstatic void rtw89_pci_recovery_intr_mask_v1(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\trtwpci->ind_intrs = B_AX_HS0ISR_IND_INT_EN;\n\trtwpci->halt_c2h_intrs = B_AX_HALT_C2H_INT_EN | B_AX_WDT_TIMEOUT_INT_EN;\n\trtwpci->intrs[0] = 0;\n\trtwpci->intrs[1] = 0;\n}\n\nstatic void rtw89_pci_default_intr_mask_v1(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\trtwpci->ind_intrs = B_AX_HCI_AXIDMA_INT_EN |\n\t\t\t    B_AX_HS1ISR_IND_INT_EN |\n\t\t\t    B_AX_HS0ISR_IND_INT_EN;\n\trtwpci->halt_c2h_intrs = B_AX_HALT_C2H_INT_EN | B_AX_WDT_TIMEOUT_INT_EN;\n\trtwpci->intrs[0] = B_AX_TXDMA_STUCK_INT_EN |\n\t\t\t   B_AX_RXDMA_INT_EN |\n\t\t\t   B_AX_RXP1DMA_INT_EN |\n\t\t\t   B_AX_RPQDMA_INT_EN |\n\t\t\t   B_AX_RXDMA_STUCK_INT_EN |\n\t\t\t   B_AX_RDU_INT_EN |\n\t\t\t   B_AX_RPQBD_FULL_INT_EN;\n\trtwpci->intrs[1] = B_AX_GPIO18_INT_EN;\n}\n\nstatic void rtw89_pci_low_power_intr_mask_v1(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\trtwpci->ind_intrs = B_AX_HS1ISR_IND_INT_EN |\n\t\t\t    B_AX_HS0ISR_IND_INT_EN;\n\trtwpci->halt_c2h_intrs = B_AX_HALT_C2H_INT_EN | B_AX_WDT_TIMEOUT_INT_EN;\n\trtwpci->intrs[0] = 0;\n\trtwpci->intrs[1] = B_AX_GPIO18_INT_EN;\n}\n\nvoid rtw89_pci_config_intr_mask_v1(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\n\tif (rtwpci->under_recovery)\n\t\trtw89_pci_recovery_intr_mask_v1(rtwdev);\n\telse if (rtwpci->low_power)\n\t\trtw89_pci_low_power_intr_mask_v1(rtwdev);\n\telse\n\t\trtw89_pci_default_intr_mask_v1(rtwdev);\n}\nEXPORT_SYMBOL(rtw89_pci_config_intr_mask_v1);\n\nstatic int rtw89_pci_request_irq(struct rtw89_dev *rtwdev,\n\t\t\t\t struct pci_dev *pdev)\n{\n\tunsigned long flags = 0;\n\tint ret;\n\n\tflags |= PCI_IRQ_LEGACY | PCI_IRQ_MSI;\n\tret = pci_alloc_irq_vectors(pdev, 1, 1, flags);\n\tif (ret < 0) {\n\t\trtw89_err(rtwdev, \"failed to alloc irq vectors, ret %d\\n\", ret);\n\t\tgoto err;\n\t}\n\n\tret = devm_request_threaded_irq(rtwdev->dev, pdev->irq,\n\t\t\t\t\trtw89_pci_interrupt_handler,\n\t\t\t\t\trtw89_pci_interrupt_threadfn,\n\t\t\t\t\tIRQF_SHARED, KBUILD_MODNAME, rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to request threaded irq\\n\");\n\t\tgoto err_free_vector;\n\t}\n\n\trtw89_chip_config_intr_mask(rtwdev, RTW89_PCI_INTR_MASK_RESET);\n\n\treturn 0;\n\nerr_free_vector:\n\tpci_free_irq_vectors(pdev);\nerr:\n\treturn ret;\n}\n\nstatic void rtw89_pci_free_irq(struct rtw89_dev *rtwdev,\n\t\t\t       struct pci_dev *pdev)\n{\n\tdevm_free_irq(rtwdev->dev, pdev->irq, rtwdev);\n\tpci_free_irq_vectors(pdev);\n}\n\nstatic u16 gray_code_to_bin(u16 gray_code, u32 bit_num)\n{\n\tu16 bin = 0, gray_bit;\n\tu32 bit_idx;\n\n\tfor (bit_idx = 0; bit_idx < bit_num; bit_idx++) {\n\t\tgray_bit = (gray_code >> bit_idx) & 0x1;\n\t\tif (bit_num - bit_idx > 1)\n\t\t\tgray_bit ^= (gray_code >> (bit_idx + 1)) & 0x1;\n\t\tbin |= (gray_bit << bit_idx);\n\t}\n\n\treturn bin;\n}\n\nstatic int rtw89_pci_filter_out(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\tu16 val16, filter_out_val;\n\tu32 val, phy_offset;\n\tint ret;\n\n\tif (rtwdev->chip->chip_id != RTL8852C)\n\t\treturn 0;\n\n\tval = rtw89_read32_mask(rtwdev, R_AX_PCIE_MIX_CFG_V1, B_AX_ASPM_CTRL_MASK);\n\tif (val == B_AX_ASPM_CTRL_L1)\n\t\treturn 0;\n\n\tret = pci_read_config_dword(pdev, RTW89_PCIE_L1_STS_V1, &val);\n\tif (ret)\n\t\treturn ret;\n\n\tval = FIELD_GET(RTW89_BCFG_LINK_SPEED_MASK, val);\n\tif (val == RTW89_PCIE_GEN1_SPEED) {\n\t\tphy_offset = R_RAC_DIRECT_OFFSET_G1;\n\t} else if (val == RTW89_PCIE_GEN2_SPEED) {\n\t\tphy_offset = R_RAC_DIRECT_OFFSET_G2;\n\t\tval16 = rtw89_read16(rtwdev, phy_offset + RAC_ANA10 * RAC_MULT);\n\t\trtw89_write16_set(rtwdev, phy_offset + RAC_ANA10 * RAC_MULT,\n\t\t\t\t  val16 | B_PCIE_BIT_PINOUT_DIS);\n\t\trtw89_write16_set(rtwdev, phy_offset + RAC_ANA19 * RAC_MULT,\n\t\t\t\t  val16 & ~B_PCIE_BIT_RD_SEL);\n\n\t\tval16 = rtw89_read16_mask(rtwdev,\n\t\t\t\t\t  phy_offset + RAC_ANA1F * RAC_MULT,\n\t\t\t\t\t  FILTER_OUT_EQ_MASK);\n\t\tval16 = gray_code_to_bin(val16, hweight16(val16));\n\t\tfilter_out_val = rtw89_read16(rtwdev, phy_offset + RAC_ANA24 *\n\t\t\t\t\t      RAC_MULT);\n\t\tfilter_out_val &= ~REG_FILTER_OUT_MASK;\n\t\tfilter_out_val |= FIELD_PREP(REG_FILTER_OUT_MASK, val16);\n\n\t\trtw89_write16(rtwdev, phy_offset + RAC_ANA24 * RAC_MULT,\n\t\t\t      filter_out_val);\n\t\trtw89_write16_set(rtwdev, phy_offset + RAC_ANA0A * RAC_MULT,\n\t\t\t\t  B_BAC_EQ_SEL);\n\t\trtw89_write16_set(rtwdev,\n\t\t\t\t  R_RAC_DIRECT_OFFSET_G1 + RAC_ANA0C * RAC_MULT,\n\t\t\t\t  B_PCIE_BIT_PSAVE);\n\t} else {\n\t\treturn -EOPNOTSUPP;\n\t}\n\trtw89_write16_set(rtwdev, phy_offset + RAC_ANA0C * RAC_MULT,\n\t\t\t  B_PCIE_BIT_PSAVE);\n\n\treturn 0;\n}\n\nstatic void rtw89_pci_clkreq_set(struct rtw89_dev *rtwdev, bool enable)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tint ret;\n\n\tif (rtw89_pci_disable_clkreq)\n\t\treturn;\n\n\tret = rtw89_pci_write_config_byte(rtwdev, RTW89_PCIE_CLK_CTRL,\n\t\t\t\t\t  PCIE_CLKDLY_HW_30US);\n\tif (ret)\n\t\trtw89_err(rtwdev, \"failed to set CLKREQ Delay\\n\");\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852B || chip_id == RTL8851B) {\n\t\tif (enable)\n\t\t\tret = rtw89_pci_config_byte_set(rtwdev,\n\t\t\t\t\t\t\tRTW89_PCIE_L1_CTRL,\n\t\t\t\t\t\t\tRTW89_PCIE_BIT_CLK);\n\t\telse\n\t\t\tret = rtw89_pci_config_byte_clr(rtwdev,\n\t\t\t\t\t\t\tRTW89_PCIE_L1_CTRL,\n\t\t\t\t\t\t\tRTW89_PCIE_BIT_CLK);\n\t\tif (ret)\n\t\t\trtw89_err(rtwdev, \"failed to %s CLKREQ_L1, ret=%d\",\n\t\t\t\t  enable ? \"set\" : \"unset\", ret);\n\t} else if (chip_id == RTL8852C) {\n\t\trtw89_write32_set(rtwdev, R_AX_PCIE_LAT_CTRL,\n\t\t\t\t  B_AX_CLK_REQ_SEL_OPT | B_AX_CLK_REQ_SEL);\n\t\tif (enable)\n\t\t\trtw89_write32_set(rtwdev, R_AX_L1_CLK_CTRL,\n\t\t\t\t\t  B_AX_CLK_REQ_N);\n\t\telse\n\t\t\trtw89_write32_clr(rtwdev, R_AX_L1_CLK_CTRL,\n\t\t\t\t\t  B_AX_CLK_REQ_N);\n\t}\n}\n\nstatic void rtw89_pci_aspm_set(struct rtw89_dev *rtwdev, bool enable)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tu8 value = 0;\n\tint ret;\n\n\tif (rtw89_pci_disable_aspm_l1)\n\t\treturn;\n\n\tret = rtw89_pci_read_config_byte(rtwdev, RTW89_PCIE_ASPM_CTRL, &value);\n\tif (ret)\n\t\trtw89_err(rtwdev, \"failed to read ASPM Delay\\n\");\n\n\tvalue &= ~(RTW89_L1DLY_MASK | RTW89_L0DLY_MASK);\n\tvalue |= FIELD_PREP(RTW89_L1DLY_MASK, PCIE_L1DLY_16US) |\n\t\t FIELD_PREP(RTW89_L0DLY_MASK, PCIE_L0SDLY_4US);\n\n\tret = rtw89_pci_write_config_byte(rtwdev, RTW89_PCIE_ASPM_CTRL, value);\n\tif (ret)\n\t\trtw89_err(rtwdev, \"failed to read ASPM Delay\\n\");\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852B || chip_id == RTL8851B) {\n\t\tif (enable)\n\t\t\tret = rtw89_pci_config_byte_set(rtwdev,\n\t\t\t\t\t\t\tRTW89_PCIE_L1_CTRL,\n\t\t\t\t\t\t\tRTW89_PCIE_BIT_L1);\n\t\telse\n\t\t\tret = rtw89_pci_config_byte_clr(rtwdev,\n\t\t\t\t\t\t\tRTW89_PCIE_L1_CTRL,\n\t\t\t\t\t\t\tRTW89_PCIE_BIT_L1);\n\t} else if (chip_id == RTL8852C) {\n\t\tif (enable)\n\t\t\trtw89_write32_set(rtwdev, R_AX_PCIE_MIX_CFG_V1,\n\t\t\t\t\t  B_AX_ASPM_CTRL_L1);\n\t\telse\n\t\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_MIX_CFG_V1,\n\t\t\t\t\t  B_AX_ASPM_CTRL_L1);\n\t}\n\tif (ret)\n\t\trtw89_err(rtwdev, \"failed to %s ASPM L1, ret=%d\",\n\t\t\t  enable ? \"set\" : \"unset\", ret);\n}\n\nstatic void rtw89_pci_recalc_int_mit(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_traffic_stats *stats = &rtwdev->stats;\n\tenum rtw89_tfc_lv tx_tfc_lv = stats->tx_tfc_lv;\n\tenum rtw89_tfc_lv rx_tfc_lv = stats->rx_tfc_lv;\n\tu32 val = 0;\n\n\tif (!rtwdev->scanning &&\n\t    (tx_tfc_lv >= RTW89_TFC_HIGH || rx_tfc_lv >= RTW89_TFC_HIGH))\n\t\tval = B_AX_RXMIT_RXP2_SEL | B_AX_RXMIT_RXP1_SEL |\n\t\t      FIELD_PREP(B_AX_RXCOUNTER_MATCH_MASK, RTW89_PCI_RXBD_NUM_MAX / 2) |\n\t\t      FIELD_PREP(B_AX_RXTIMER_UNIT_MASK, AX_RXTIMER_UNIT_64US) |\n\t\t      FIELD_PREP(B_AX_RXTIMER_MATCH_MASK, 2048 / 64);\n\n\trtw89_write32(rtwdev, R_AX_INT_MIT_RX, val);\n}\n\nstatic void rtw89_pci_link_cfg(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\tu16 link_ctrl;\n\tint ret;\n\n\t \n\tret = pcie_capability_read_word(pdev, PCI_EXP_LNKCTL, &link_ctrl);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to read PCI cap, ret=%d\\n\", ret);\n\t\treturn;\n\t}\n\n\tif (link_ctrl & PCI_EXP_LNKCTL_CLKREQ_EN)\n\t\trtw89_pci_clkreq_set(rtwdev, true);\n\n\tif (link_ctrl & PCI_EXP_LNKCTL_ASPM_L1)\n\t\trtw89_pci_aspm_set(rtwdev, true);\n}\n\nstatic void rtw89_pci_l1ss_set(struct rtw89_dev *rtwdev, bool enable)\n{\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\tint ret;\n\n\tif (chip_id == RTL8852A || chip_id == RTL8852B || chip_id == RTL8851B) {\n\t\tif (enable)\n\t\t\tret = rtw89_pci_config_byte_set(rtwdev,\n\t\t\t\t\t\t\tRTW89_PCIE_TIMER_CTRL,\n\t\t\t\t\t\t\tRTW89_PCIE_BIT_L1SUB);\n\t\telse\n\t\t\tret = rtw89_pci_config_byte_clr(rtwdev,\n\t\t\t\t\t\t\tRTW89_PCIE_TIMER_CTRL,\n\t\t\t\t\t\t\tRTW89_PCIE_BIT_L1SUB);\n\t\tif (ret)\n\t\t\trtw89_err(rtwdev, \"failed to %s L1SS, ret=%d\",\n\t\t\t\t  enable ? \"set\" : \"unset\", ret);\n\t} else if (chip_id == RTL8852C) {\n\t\tret = rtw89_pci_config_byte_clr(rtwdev, RTW89_PCIE_L1SS_STS_V1,\n\t\t\t\t\t\tRTW89_PCIE_BIT_ASPM_L11 |\n\t\t\t\t\t\tRTW89_PCIE_BIT_PCI_L11);\n\t\tif (ret)\n\t\t\trtw89_warn(rtwdev, \"failed to unset ASPM L1.1, ret=%d\", ret);\n\t\tif (enable)\n\t\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_MIX_CFG_V1,\n\t\t\t\t\t  B_AX_L1SUB_DISABLE);\n\t\telse\n\t\t\trtw89_write32_set(rtwdev, R_AX_PCIE_MIX_CFG_V1,\n\t\t\t\t\t  B_AX_L1SUB_DISABLE);\n\t}\n}\n\nstatic void rtw89_pci_l1ss_cfg(struct rtw89_dev *rtwdev)\n{\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tstruct pci_dev *pdev = rtwpci->pdev;\n\tu32 l1ss_cap_ptr, l1ss_ctrl;\n\n\tif (rtw89_pci_disable_l1ss)\n\t\treturn;\n\n\tl1ss_cap_ptr = pci_find_ext_capability(pdev, PCI_EXT_CAP_ID_L1SS);\n\tif (!l1ss_cap_ptr)\n\t\treturn;\n\n\tpci_read_config_dword(pdev, l1ss_cap_ptr + PCI_L1SS_CTL1, &l1ss_ctrl);\n\n\tif (l1ss_ctrl & PCI_L1SS_CTL1_L1SS_MASK)\n\t\trtw89_pci_l1ss_set(rtwdev, true);\n}\n\nstatic int rtw89_pci_poll_io_idle(struct rtw89_dev *rtwdev)\n{\n\tint ret = 0;\n\tu32 sts;\n\tu32 busy = B_AX_PCIEIO_BUSY | B_AX_PCIEIO_TX_BUSY | B_AX_PCIEIO_RX_BUSY;\n\n\tret = read_poll_timeout_atomic(rtw89_read32, sts, (sts & busy) == 0x0,\n\t\t\t\t       10, 1000, false, rtwdev,\n\t\t\t\t       R_AX_PCIE_DMA_BUSY1);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"pci dmach busy1 0x%X\\n\",\n\t\t\t  rtw89_read32(rtwdev, R_AX_PCIE_DMA_BUSY1));\n\t\treturn -EINVAL;\n\t}\n\treturn ret;\n}\n\nstatic int rtw89_pci_lv1rst_stop_dma(struct rtw89_dev *rtwdev)\n{\n\tu32 val;\n\tint ret;\n\n\tif (rtwdev->chip->chip_id == RTL8852C)\n\t\treturn 0;\n\n\trtw89_pci_ctrl_dma_all(rtwdev, false);\n\tret = rtw89_pci_poll_io_idle(rtwdev);\n\tif (ret) {\n\t\tval = rtw89_read32(rtwdev, R_AX_DBG_ERR_FLAG);\n\t\trtw89_debug(rtwdev, RTW89_DBG_HCI,\n\t\t\t    \"[PCIe] poll_io_idle fail, before 0x%08x: 0x%08x\\n\",\n\t\t\t    R_AX_DBG_ERR_FLAG, val);\n\t\tif (val & B_AX_TX_STUCK || val & B_AX_PCIE_TXBD_LEN0)\n\t\t\trtw89_mac_ctrl_hci_dma_tx(rtwdev, false);\n\t\tif (val & B_AX_RX_STUCK)\n\t\t\trtw89_mac_ctrl_hci_dma_rx(rtwdev, false);\n\t\trtw89_mac_ctrl_hci_dma_trx(rtwdev, true);\n\t\tret = rtw89_pci_poll_io_idle(rtwdev);\n\t\tval = rtw89_read32(rtwdev, R_AX_DBG_ERR_FLAG);\n\t\trtw89_debug(rtwdev, RTW89_DBG_HCI,\n\t\t\t    \"[PCIe] poll_io_idle fail, after 0x%08x: 0x%08x\\n\",\n\t\t\t    R_AX_DBG_ERR_FLAG, val);\n\t}\n\n\treturn ret;\n}\n\n\n\nstatic int rtw89_pci_rst_bdram(struct rtw89_dev *rtwdev)\n{\n\tint ret = 0;\n\tu32 val32, sts;\n\n\tval32 = B_AX_RST_BDRAM;\n\trtw89_write32_set(rtwdev, R_AX_PCIE_INIT_CFG1, val32);\n\n\tret = read_poll_timeout_atomic(rtw89_read32, sts,\n\t\t\t\t       (sts & B_AX_RST_BDRAM) == 0x0, 1, 100,\n\t\t\t\t       true, rtwdev, R_AX_PCIE_INIT_CFG1);\n\treturn ret;\n}\n\nstatic int rtw89_pci_lv1rst_start_dma(struct rtw89_dev *rtwdev)\n{\n\tu32 ret;\n\n\tif (rtwdev->chip->chip_id == RTL8852C)\n\t\treturn 0;\n\n\trtw89_mac_ctrl_hci_dma_trx(rtwdev, false);\n\trtw89_mac_ctrl_hci_dma_trx(rtwdev, true);\n\trtw89_pci_clr_idx_all(rtwdev);\n\n\tret = rtw89_pci_rst_bdram(rtwdev);\n\tif (ret)\n\t\treturn ret;\n\n\trtw89_pci_ctrl_dma_all(rtwdev, true);\n\treturn ret;\n}\n\nstatic int rtw89_pci_ops_mac_lv1_recovery(struct rtw89_dev *rtwdev,\n\t\t\t\t\t  enum rtw89_lv1_rcvy_step step)\n{\n\tint ret;\n\n\tswitch (step) {\n\tcase RTW89_LV1_RCVY_STEP_1:\n\t\tret = rtw89_pci_lv1rst_stop_dma(rtwdev);\n\t\tif (ret)\n\t\t\trtw89_err(rtwdev, \"lv1 rcvy pci stop dma fail\\n\");\n\n\t\tbreak;\n\n\tcase RTW89_LV1_RCVY_STEP_2:\n\t\tret = rtw89_pci_lv1rst_start_dma(rtwdev);\n\t\tif (ret)\n\t\t\trtw89_err(rtwdev, \"lv1 rcvy pci start dma fail\\n\");\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic void rtw89_pci_ops_dump_err_status(struct rtw89_dev *rtwdev)\n{\n\trtw89_info(rtwdev, \"R_AX_RPQ_RXBD_IDX =0x%08x\\n\",\n\t\t   rtw89_read32(rtwdev, R_AX_RPQ_RXBD_IDX));\n\trtw89_info(rtwdev, \"R_AX_DBG_ERR_FLAG=0x%08x\\n\",\n\t\t   rtw89_read32(rtwdev, R_AX_DBG_ERR_FLAG));\n\trtw89_info(rtwdev, \"R_AX_LBC_WATCHDOG=0x%08x\\n\",\n\t\t   rtw89_read32(rtwdev, R_AX_LBC_WATCHDOG));\n}\n\nstatic int rtw89_pci_napi_poll(struct napi_struct *napi, int budget)\n{\n\tstruct rtw89_dev *rtwdev = container_of(napi, struct rtw89_dev, napi);\n\tstruct rtw89_pci *rtwpci = (struct rtw89_pci *)rtwdev->priv;\n\tunsigned long flags;\n\tint work_done;\n\n\trtwdev->napi_budget_countdown = budget;\n\n\trtw89_pci_clear_isr0(rtwdev, B_AX_RPQDMA_INT | B_AX_RPQBD_FULL_INT);\n\twork_done = rtw89_pci_poll_rpq_dma(rtwdev, rtwpci, rtwdev->napi_budget_countdown);\n\tif (work_done == budget)\n\t\treturn budget;\n\n\trtw89_pci_clear_isr0(rtwdev, B_AX_RXP1DMA_INT | B_AX_RXDMA_INT | B_AX_RDU_INT);\n\twork_done += rtw89_pci_poll_rxq_dma(rtwdev, rtwpci, rtwdev->napi_budget_countdown);\n\tif (work_done < budget && napi_complete_done(napi, work_done)) {\n\t\tspin_lock_irqsave(&rtwpci->irq_lock, flags);\n\t\tif (likely(rtwpci->running))\n\t\t\trtw89_chip_enable_intr(rtwdev, rtwpci);\n\t\tspin_unlock_irqrestore(&rtwpci->irq_lock, flags);\n\t}\n\n\treturn work_done;\n}\n\nstatic int __maybe_unused rtw89_pci_suspend(struct device *dev)\n{\n\tstruct ieee80211_hw *hw = dev_get_drvdata(dev);\n\tstruct rtw89_dev *rtwdev = hw->priv;\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\n\trtw89_write32_set(rtwdev, R_AX_RSV_CTRL, B_AX_WLOCK_1C_BIT6);\n\trtw89_write32_set(rtwdev, R_AX_RSV_CTRL, B_AX_R_DIS_PRST);\n\trtw89_write32_clr(rtwdev, R_AX_RSV_CTRL, B_AX_WLOCK_1C_BIT6);\n\tif (chip_id == RTL8852A || chip_id == RTL8852B || chip_id == RTL8851B) {\n\t\trtw89_write32_clr(rtwdev, R_AX_SYS_SDIO_CTRL,\n\t\t\t\t  B_AX_PCIE_DIS_L2_CTRL_LDO_HCI);\n\t\trtw89_write32_set(rtwdev, R_AX_PCIE_INIT_CFG1,\n\t\t\t\t  B_AX_PCIE_PERST_KEEP_REG | B_AX_PCIE_TRAIN_KEEP_REG);\n\t} else {\n\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_PS_CTRL_V1,\n\t\t\t\t  B_AX_CMAC_EXIT_L1_EN | B_AX_DMAC0_EXIT_L1_EN);\n\t}\n\n\treturn 0;\n}\n\nstatic void rtw89_pci_l2_hci_ldo(struct rtw89_dev *rtwdev)\n{\n\tif (rtwdev->chip->chip_id == RTL8852C)\n\t\treturn;\n\n\t \n\trtw89_pci_write_config_byte(rtwdev, RTW89_PCIE_RST_MSTATE,\n\t\t\t\t    RTW89_PCIE_BIT_CFG_RST_MSTATE);\n\trtw89_pci_write_config_byte(rtwdev, RTW89_PCIE_RST_MSTATE,\n\t\t\t\t    RTW89_PCIE_BIT_CFG_RST_MSTATE);\n}\n\nstatic int __maybe_unused rtw89_pci_resume(struct device *dev)\n{\n\tstruct ieee80211_hw *hw = dev_get_drvdata(dev);\n\tstruct rtw89_dev *rtwdev = hw->priv;\n\tenum rtw89_core_chip_id chip_id = rtwdev->chip->chip_id;\n\n\trtw89_write32_set(rtwdev, R_AX_RSV_CTRL, B_AX_WLOCK_1C_BIT6);\n\trtw89_write32_clr(rtwdev, R_AX_RSV_CTRL, B_AX_R_DIS_PRST);\n\trtw89_write32_clr(rtwdev, R_AX_RSV_CTRL, B_AX_WLOCK_1C_BIT6);\n\tif (chip_id == RTL8852A || chip_id == RTL8852B || chip_id == RTL8851B) {\n\t\trtw89_write32_set(rtwdev, R_AX_SYS_SDIO_CTRL,\n\t\t\t\t  B_AX_PCIE_DIS_L2_CTRL_LDO_HCI);\n\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_INIT_CFG1,\n\t\t\t\t  B_AX_PCIE_PERST_KEEP_REG | B_AX_PCIE_TRAIN_KEEP_REG);\n\t} else {\n\t\trtw89_write32_set(rtwdev, R_AX_PCIE_PS_CTRL_V1,\n\t\t\t\t  B_AX_CMAC_EXIT_L1_EN | B_AX_DMAC0_EXIT_L1_EN);\n\t\trtw89_write32_clr(rtwdev, R_AX_PCIE_PS_CTRL_V1,\n\t\t\t\t  B_AX_SEL_REQ_ENTR_L1);\n\t}\n\trtw89_pci_l2_hci_ldo(rtwdev);\n\trtw89_pci_filter_out(rtwdev);\n\trtw89_pci_link_cfg(rtwdev);\n\trtw89_pci_l1ss_cfg(rtwdev);\n\n\treturn 0;\n}\n\nSIMPLE_DEV_PM_OPS(rtw89_pm_ops, rtw89_pci_suspend, rtw89_pci_resume);\nEXPORT_SYMBOL(rtw89_pm_ops);\n\nstatic const struct rtw89_hci_ops rtw89_pci_ops = {\n\t.tx_write\t= rtw89_pci_ops_tx_write,\n\t.tx_kick_off\t= rtw89_pci_ops_tx_kick_off,\n\t.flush_queues\t= rtw89_pci_ops_flush_queues,\n\t.reset\t\t= rtw89_pci_ops_reset,\n\t.start\t\t= rtw89_pci_ops_start,\n\t.stop\t\t= rtw89_pci_ops_stop,\n\t.pause\t\t= rtw89_pci_ops_pause,\n\t.switch_mode\t= rtw89_pci_ops_switch_mode,\n\t.recalc_int_mit = rtw89_pci_recalc_int_mit,\n\n\t.read8\t\t= rtw89_pci_ops_read8,\n\t.read16\t\t= rtw89_pci_ops_read16,\n\t.read32\t\t= rtw89_pci_ops_read32,\n\t.write8\t\t= rtw89_pci_ops_write8,\n\t.write16\t= rtw89_pci_ops_write16,\n\t.write32\t= rtw89_pci_ops_write32,\n\n\t.mac_pre_init\t= rtw89_pci_ops_mac_pre_init,\n\t.mac_post_init\t= rtw89_pci_ops_mac_post_init,\n\t.deinit\t\t= rtw89_pci_ops_deinit,\n\n\t.check_and_reclaim_tx_resource = rtw89_pci_check_and_reclaim_tx_resource,\n\t.mac_lv1_rcvy\t= rtw89_pci_ops_mac_lv1_recovery,\n\t.dump_err_status = rtw89_pci_ops_dump_err_status,\n\t.napi_poll\t= rtw89_pci_napi_poll,\n\n\t.recovery_start = rtw89_pci_ops_recovery_start,\n\t.recovery_complete = rtw89_pci_ops_recovery_complete,\n\n\t.ctrl_txdma_ch\t= rtw89_pci_ctrl_txdma_ch_pcie,\n\t.ctrl_txdma_fw_ch = rtw89_pci_ctrl_txdma_fw_ch_pcie,\n\t.ctrl_trxhci\t= rtw89_pci_ctrl_dma_trx,\n\t.poll_txdma_ch\t= rtw89_poll_txdma_ch_idle_pcie,\n\t.clr_idx_all\t= rtw89_pci_clr_idx_all,\n\t.clear\t\t= rtw89_pci_clear_resource,\n\t.disable_intr\t= rtw89_pci_disable_intr_lock,\n\t.enable_intr\t= rtw89_pci_enable_intr_lock,\n\t.rst_bdram\t= rtw89_pci_rst_bdram_pcie,\n};\n\nint rtw89_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tstruct rtw89_dev *rtwdev;\n\tconst struct rtw89_driver_info *info;\n\tconst struct rtw89_pci_info *pci_info;\n\tint ret;\n\n\tinfo = (const struct rtw89_driver_info *)id->driver_data;\n\n\trtwdev = rtw89_alloc_ieee80211_hw(&pdev->dev,\n\t\t\t\t\t  sizeof(struct rtw89_pci),\n\t\t\t\t\t  info->chip);\n\tif (!rtwdev) {\n\t\tdev_err(&pdev->dev, \"failed to allocate hw\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tpci_info = info->bus.pci;\n\n\trtwdev->pci_info = info->bus.pci;\n\trtwdev->hci.ops = &rtw89_pci_ops;\n\trtwdev->hci.type = RTW89_HCI_TYPE_PCIE;\n\trtwdev->hci.rpwm_addr = pci_info->rpwm_addr;\n\trtwdev->hci.cpwm_addr = pci_info->cpwm_addr;\n\n\tSET_IEEE80211_DEV(rtwdev->hw, &pdev->dev);\n\n\tret = rtw89_core_init(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to initialise core\\n\");\n\t\tgoto err_release_hw;\n\t}\n\n\tret = rtw89_pci_claim_device(rtwdev, pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to claim pci device\\n\");\n\t\tgoto err_core_deinit;\n\t}\n\n\tret = rtw89_pci_setup_resource(rtwdev, pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to setup pci resource\\n\");\n\t\tgoto err_declaim_pci;\n\t}\n\n\tret = rtw89_chip_info_setup(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to setup chip information\\n\");\n\t\tgoto err_clear_resource;\n\t}\n\n\trtw89_pci_filter_out(rtwdev);\n\trtw89_pci_link_cfg(rtwdev);\n\trtw89_pci_l1ss_cfg(rtwdev);\n\n\trtw89_core_napi_init(rtwdev);\n\n\tret = rtw89_pci_request_irq(rtwdev, pdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to request pci irq\\n\");\n\t\tgoto err_deinit_napi;\n\t}\n\n\tret = rtw89_core_register(rtwdev);\n\tif (ret) {\n\t\trtw89_err(rtwdev, \"failed to register core\\n\");\n\t\tgoto err_free_irq;\n\t}\n\n\treturn 0;\n\nerr_free_irq:\n\trtw89_pci_free_irq(rtwdev, pdev);\nerr_deinit_napi:\n\trtw89_core_napi_deinit(rtwdev);\nerr_clear_resource:\n\trtw89_pci_clear_resource(rtwdev, pdev);\nerr_declaim_pci:\n\trtw89_pci_declaim_device(rtwdev, pdev);\nerr_core_deinit:\n\trtw89_core_deinit(rtwdev);\nerr_release_hw:\n\trtw89_free_ieee80211_hw(rtwdev);\n\n\treturn ret;\n}\nEXPORT_SYMBOL(rtw89_pci_probe);\n\nvoid rtw89_pci_remove(struct pci_dev *pdev)\n{\n\tstruct ieee80211_hw *hw = pci_get_drvdata(pdev);\n\tstruct rtw89_dev *rtwdev;\n\n\trtwdev = hw->priv;\n\n\trtw89_pci_free_irq(rtwdev, pdev);\n\trtw89_core_napi_deinit(rtwdev);\n\trtw89_core_unregister(rtwdev);\n\trtw89_pci_clear_resource(rtwdev, pdev);\n\trtw89_pci_declaim_device(rtwdev, pdev);\n\trtw89_core_deinit(rtwdev);\n\trtw89_free_ieee80211_hw(rtwdev);\n}\nEXPORT_SYMBOL(rtw89_pci_remove);\n\nMODULE_AUTHOR(\"Realtek Corporation\");\nMODULE_DESCRIPTION(\"Realtek PCI 802.11ax wireless driver\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}