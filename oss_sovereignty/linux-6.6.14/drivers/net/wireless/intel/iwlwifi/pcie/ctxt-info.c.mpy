{
  "module_name": "ctxt-info.c",
  "hash_id": "0ba83b81c34511334b7bad28e4c2913b546618e3404bbec85980dbf680547750",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/intel/iwlwifi/pcie/ctxt-info.c",
  "human_readable_source": "\n \n#include \"iwl-trans.h\"\n#include \"iwl-fh.h\"\n#include \"iwl-context-info.h\"\n#include \"internal.h\"\n#include \"iwl-prph.h\"\n\nstatic void *_iwl_pcie_ctxt_info_dma_alloc_coherent(struct iwl_trans *trans,\n\t\t\t\t\t\t    size_t size,\n\t\t\t\t\t\t    dma_addr_t *phys,\n\t\t\t\t\t\t    int depth)\n{\n\tvoid *result;\n\n\tif (WARN(depth > 2,\n\t\t \"failed to allocate DMA memory not crossing 2^32 boundary\"))\n\t\treturn NULL;\n\n\tresult = dma_alloc_coherent(trans->dev, size, phys, GFP_KERNEL);\n\n\tif (!result)\n\t\treturn NULL;\n\n\tif (unlikely(iwl_txq_crosses_4g_boundary(*phys, size))) {\n\t\tvoid *old = result;\n\t\tdma_addr_t oldphys = *phys;\n\n\t\tresult = _iwl_pcie_ctxt_info_dma_alloc_coherent(trans, size,\n\t\t\t\t\t\t\t\tphys,\n\t\t\t\t\t\t\t\tdepth + 1);\n\t\tdma_free_coherent(trans->dev, size, old, oldphys);\n\t}\n\n\treturn result;\n}\n\nvoid *iwl_pcie_ctxt_info_dma_alloc_coherent(struct iwl_trans *trans,\n\t\t\t\t\t    size_t size,\n\t\t\t\t\t    dma_addr_t *phys)\n{\n\treturn _iwl_pcie_ctxt_info_dma_alloc_coherent(trans, size, phys, 0);\n}\n\nint iwl_pcie_ctxt_info_alloc_dma(struct iwl_trans *trans,\n\t\t\t\t const void *data, u32 len,\n\t\t\t\t struct iwl_dram_data *dram)\n{\n\tdram->block = iwl_pcie_ctxt_info_dma_alloc_coherent(trans, len,\n\t\t\t\t\t\t\t    &dram->physical);\n\tif (!dram->block)\n\t\treturn -ENOMEM;\n\n\tdram->size = len;\n\tmemcpy(dram->block, data, len);\n\n\treturn 0;\n}\n\nvoid iwl_pcie_ctxt_info_free_paging(struct iwl_trans *trans)\n{\n\tstruct iwl_self_init_dram *dram = &trans->init_dram;\n\tint i;\n\n\tif (!dram->paging) {\n\t\tWARN_ON(dram->paging_cnt);\n\t\treturn;\n\t}\n\n\t \n\tfor (i = 0; i < dram->paging_cnt; i++)\n\t\tdma_free_coherent(trans->dev, dram->paging[i].size,\n\t\t\t\t  dram->paging[i].block,\n\t\t\t\t  dram->paging[i].physical);\n\n\tkfree(dram->paging);\n\tdram->paging_cnt = 0;\n\tdram->paging = NULL;\n}\n\nint iwl_pcie_init_fw_sec(struct iwl_trans *trans,\n\t\t\t const struct fw_img *fw,\n\t\t\t struct iwl_context_info_dram *ctxt_dram)\n{\n\tstruct iwl_self_init_dram *dram = &trans->init_dram;\n\tint i, ret, lmac_cnt, umac_cnt, paging_cnt;\n\n\tif (WARN(dram->paging,\n\t\t \"paging shouldn't already be initialized (%d pages)\\n\",\n\t\t dram->paging_cnt))\n\t\tiwl_pcie_ctxt_info_free_paging(trans);\n\n\tlmac_cnt = iwl_pcie_get_num_sections(fw, 0);\n\t \n\tumac_cnt = iwl_pcie_get_num_sections(fw, lmac_cnt + 1);\n\t \n\tpaging_cnt = iwl_pcie_get_num_sections(fw, lmac_cnt + umac_cnt + 2);\n\n\tdram->fw = kcalloc(umac_cnt + lmac_cnt, sizeof(*dram->fw), GFP_KERNEL);\n\tif (!dram->fw)\n\t\treturn -ENOMEM;\n\tdram->paging = kcalloc(paging_cnt, sizeof(*dram->paging), GFP_KERNEL);\n\tif (!dram->paging)\n\t\treturn -ENOMEM;\n\n\t \n\tfor (i = 0; i < lmac_cnt; i++) {\n\t\tret = iwl_pcie_ctxt_info_alloc_dma(trans, fw->sec[i].data,\n\t\t\t\t\t\t   fw->sec[i].len,\n\t\t\t\t\t\t   &dram->fw[dram->fw_cnt]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tctxt_dram->lmac_img[i] =\n\t\t\tcpu_to_le64(dram->fw[dram->fw_cnt].physical);\n\t\tdram->fw_cnt++;\n\t}\n\n\t \n\tfor (i = 0; i < umac_cnt; i++) {\n\t\t \n\t\tret = iwl_pcie_ctxt_info_alloc_dma(trans,\n\t\t\t\t\t\t   fw->sec[dram->fw_cnt + 1].data,\n\t\t\t\t\t\t   fw->sec[dram->fw_cnt + 1].len,\n\t\t\t\t\t\t   &dram->fw[dram->fw_cnt]);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tctxt_dram->umac_img[i] =\n\t\t\tcpu_to_le64(dram->fw[dram->fw_cnt].physical);\n\t\tdram->fw_cnt++;\n\t}\n\n\t \n\tfor (i = 0; i < paging_cnt; i++) {\n\t\t \n\t\tint fw_idx = dram->fw_cnt + i + 2;\n\n\t\tret = iwl_pcie_ctxt_info_alloc_dma(trans, fw->sec[fw_idx].data,\n\t\t\t\t\t\t   fw->sec[fw_idx].len,\n\t\t\t\t\t\t   &dram->paging[i]);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tctxt_dram->virtual_img[i] =\n\t\t\tcpu_to_le64(dram->paging[i].physical);\n\t\tdram->paging_cnt++;\n\t}\n\n\treturn 0;\n}\n\nint iwl_pcie_ctxt_info_init(struct iwl_trans *trans,\n\t\t\t    const struct fw_img *fw)\n{\n\tstruct iwl_trans_pcie *trans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\tstruct iwl_context_info *ctxt_info;\n\tstruct iwl_context_info_rbd_cfg *rx_cfg;\n\tu32 control_flags = 0, rb_size;\n\tdma_addr_t phys;\n\tint ret;\n\n\tctxt_info = iwl_pcie_ctxt_info_dma_alloc_coherent(trans,\n\t\t\t\t\t\t\t  sizeof(*ctxt_info),\n\t\t\t\t\t\t\t  &phys);\n\tif (!ctxt_info)\n\t\treturn -ENOMEM;\n\n\ttrans_pcie->ctxt_info_dma_addr = phys;\n\n\tctxt_info->version.version = 0;\n\tctxt_info->version.mac_id =\n\t\tcpu_to_le16((u16)iwl_read32(trans, CSR_HW_REV));\n\t \n\tctxt_info->version.size = cpu_to_le16(sizeof(*ctxt_info) / 4);\n\n\tswitch (trans_pcie->rx_buf_size) {\n\tcase IWL_AMSDU_2K:\n\t\trb_size = IWL_CTXT_INFO_RB_SIZE_2K;\n\t\tbreak;\n\tcase IWL_AMSDU_4K:\n\t\trb_size = IWL_CTXT_INFO_RB_SIZE_4K;\n\t\tbreak;\n\tcase IWL_AMSDU_8K:\n\t\trb_size = IWL_CTXT_INFO_RB_SIZE_8K;\n\t\tbreak;\n\tcase IWL_AMSDU_12K:\n\t\trb_size = IWL_CTXT_INFO_RB_SIZE_16K;\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t\trb_size = IWL_CTXT_INFO_RB_SIZE_4K;\n\t}\n\n\tWARN_ON(RX_QUEUE_CB_SIZE(trans->cfg->num_rbds) > 12);\n\tcontrol_flags = IWL_CTXT_INFO_TFD_FORMAT_LONG;\n\tcontrol_flags |=\n\t\tu32_encode_bits(RX_QUEUE_CB_SIZE(trans->cfg->num_rbds),\n\t\t\t\tIWL_CTXT_INFO_RB_CB_SIZE);\n\tcontrol_flags |= u32_encode_bits(rb_size, IWL_CTXT_INFO_RB_SIZE);\n\tctxt_info->control.control_flags = cpu_to_le32(control_flags);\n\n\t \n\trx_cfg = &ctxt_info->rbd_cfg;\n\trx_cfg->free_rbd_addr = cpu_to_le64(trans_pcie->rxq->bd_dma);\n\trx_cfg->used_rbd_addr = cpu_to_le64(trans_pcie->rxq->used_bd_dma);\n\trx_cfg->status_wr_ptr = cpu_to_le64(trans_pcie->rxq->rb_stts_dma);\n\n\t \n\tctxt_info->hcmd_cfg.cmd_queue_addr =\n\t\tcpu_to_le64(trans->txqs.txq[trans->txqs.cmd.q_id]->dma_addr);\n\tctxt_info->hcmd_cfg.cmd_queue_size =\n\t\tTFD_QUEUE_CB_SIZE(IWL_CMD_QUEUE_SIZE);\n\n\t \n\tret = iwl_pcie_init_fw_sec(trans, fw, &ctxt_info->dram);\n\tif (ret) {\n\t\tdma_free_coherent(trans->dev, sizeof(*trans_pcie->ctxt_info),\n\t\t\t\t  ctxt_info, trans_pcie->ctxt_info_dma_addr);\n\t\treturn ret;\n\t}\n\n\ttrans_pcie->ctxt_info = ctxt_info;\n\n\tiwl_enable_fw_load_int_ctx_info(trans);\n\n\t \n\tif (iwl_pcie_dbg_on(trans))\n\t\tiwl_pcie_apply_destination(trans);\n\n\t \n\tiwl_write64(trans, CSR_CTXT_INFO_BA, trans_pcie->ctxt_info_dma_addr);\n\n\t \n\n\treturn 0;\n}\n\nvoid iwl_pcie_ctxt_info_free(struct iwl_trans *trans)\n{\n\tstruct iwl_trans_pcie *trans_pcie = IWL_TRANS_GET_PCIE_TRANS(trans);\n\n\tif (!trans_pcie->ctxt_info)\n\t\treturn;\n\n\tdma_free_coherent(trans->dev, sizeof(*trans_pcie->ctxt_info),\n\t\t\t  trans_pcie->ctxt_info,\n\t\t\t  trans_pcie->ctxt_info_dma_addr);\n\ttrans_pcie->ctxt_info_dma_addr = 0;\n\ttrans_pcie->ctxt_info = NULL;\n\n\tiwl_pcie_ctxt_info_free_fw_img(trans);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}