{
  "module_name": "libipw_tx.c",
  "hash_id": "5ac5d08e1f442b185c8dfff30303ee6dac349d02cea96806b4f86d94958c7d14",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/intel/ipw2x00/libipw_tx.c",
  "human_readable_source": "\n \n#include <linux/compiler.h>\n#include <linux/errno.h>\n#include <linux/if_arp.h>\n#include <linux/in6.h>\n#include <linux/in.h>\n#include <linux/ip.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/proc_fs.h>\n#include <linux/skbuff.h>\n#include <linux/slab.h>\n#include <linux/tcp.h>\n#include <linux/types.h>\n#include <linux/wireless.h>\n#include <linux/etherdevice.h>\n#include <linux/uaccess.h>\n\n#include \"libipw.h\"\n\n \n\nstatic u8 P802_1H_OUI[P80211_OUI_LEN] = { 0x00, 0x00, 0xf8 };\nstatic u8 RFC1042_OUI[P80211_OUI_LEN] = { 0x00, 0x00, 0x00 };\n\nstatic int libipw_copy_snap(u8 * data, __be16 h_proto)\n{\n\tstruct libipw_snap_hdr *snap;\n\tu8 *oui;\n\n\tsnap = (struct libipw_snap_hdr *)data;\n\tsnap->dsap = 0xaa;\n\tsnap->ssap = 0xaa;\n\tsnap->ctrl = 0x03;\n\n\tif (h_proto == htons(ETH_P_AARP) || h_proto == htons(ETH_P_IPX))\n\t\toui = P802_1H_OUI;\n\telse\n\t\toui = RFC1042_OUI;\n\tsnap->oui[0] = oui[0];\n\tsnap->oui[1] = oui[1];\n\tsnap->oui[2] = oui[2];\n\n\tmemcpy(data + SNAP_SIZE, &h_proto, sizeof(u16));\n\n\treturn SNAP_SIZE + sizeof(u16);\n}\n\nstatic int libipw_encrypt_fragment(struct libipw_device *ieee,\n\t\t\t\t\t     struct sk_buff *frag, int hdr_len)\n{\n\tstruct lib80211_crypt_data *crypt =\n\t\tieee->crypt_info.crypt[ieee->crypt_info.tx_keyidx];\n\tint res;\n\n\tif (crypt == NULL)\n\t\treturn -1;\n\n\t \n\tatomic_inc(&crypt->refcnt);\n\tres = 0;\n\tif (crypt->ops && crypt->ops->encrypt_mpdu)\n\t\tres = crypt->ops->encrypt_mpdu(frag, hdr_len, crypt->priv);\n\n\tatomic_dec(&crypt->refcnt);\n\tif (res < 0) {\n\t\tprintk(KERN_INFO \"%s: Encryption failed: len=%d.\\n\",\n\t\t       ieee->dev->name, frag->len);\n\t\tieee->ieee_stats.tx_discards++;\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nvoid libipw_txb_free(struct libipw_txb *txb)\n{\n\tint i;\n\tif (unlikely(!txb))\n\t\treturn;\n\tfor (i = 0; i < txb->nr_frags; i++)\n\t\tif (txb->fragments[i])\n\t\t\tdev_kfree_skb_any(txb->fragments[i]);\n\tkfree(txb);\n}\n\nstatic struct libipw_txb *libipw_alloc_txb(int nr_frags, int txb_size,\n\t\t\t\t\t\t int headroom, gfp_t gfp_mask)\n{\n\tstruct libipw_txb *txb;\n\tint i;\n\n\ttxb = kmalloc(struct_size(txb, fragments, nr_frags), gfp_mask);\n\tif (!txb)\n\t\treturn NULL;\n\n\tmemset(txb, 0, sizeof(struct libipw_txb));\n\ttxb->nr_frags = nr_frags;\n\ttxb->frag_size = txb_size;\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\ttxb->fragments[i] = __dev_alloc_skb(txb_size + headroom,\n\t\t\t\t\t\t    gfp_mask);\n\t\tif (unlikely(!txb->fragments[i])) {\n\t\t\ti--;\n\t\t\tbreak;\n\t\t}\n\t\tskb_reserve(txb->fragments[i], headroom);\n\t}\n\tif (unlikely(i != nr_frags)) {\n\t\twhile (i >= 0)\n\t\t\tdev_kfree_skb_any(txb->fragments[i--]);\n\t\tkfree(txb);\n\t\treturn NULL;\n\t}\n\treturn txb;\n}\n\nstatic int libipw_classify(struct sk_buff *skb)\n{\n\tstruct ethhdr *eth;\n\tstruct iphdr *ip;\n\n\teth = (struct ethhdr *)skb->data;\n\tif (eth->h_proto != htons(ETH_P_IP))\n\t\treturn 0;\n\n\tip = ip_hdr(skb);\n\tswitch (ip->tos & 0xfc) {\n\tcase 0x20:\n\t\treturn 2;\n\tcase 0x40:\n\t\treturn 1;\n\tcase 0x60:\n\t\treturn 3;\n\tcase 0x80:\n\t\treturn 4;\n\tcase 0xa0:\n\t\treturn 5;\n\tcase 0xc0:\n\t\treturn 6;\n\tcase 0xe0:\n\t\treturn 7;\n\tdefault:\n\t\treturn 0;\n\t}\n}\n\n \nnetdev_tx_t libipw_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct libipw_device *ieee = netdev_priv(dev);\n\tstruct libipw_txb *txb = NULL;\n\tstruct libipw_hdr_3addrqos *frag_hdr;\n\tint i, bytes_per_frag, nr_frags, bytes_last_frag, frag_size,\n\t    rts_required;\n\tunsigned long flags;\n\tint encrypt, host_encrypt, host_encrypt_msdu;\n\t__be16 ether_type;\n\tint bytes, fc, hdr_len;\n\tstruct sk_buff *skb_frag;\n\tstruct libipw_hdr_3addrqos header = { \n\t\t.duration_id = 0,\n\t\t.seq_ctl = 0,\n\t\t.qos_ctl = 0\n\t};\n\tu8 dest[ETH_ALEN], src[ETH_ALEN];\n\tstruct lib80211_crypt_data *crypt;\n\tint priority = skb->priority;\n\tint snapped = 0;\n\n\tif (ieee->is_queue_full && (*ieee->is_queue_full) (dev, priority))\n\t\treturn NETDEV_TX_BUSY;\n\n\tspin_lock_irqsave(&ieee->lock, flags);\n\n\t \n\tif (!ieee->hard_start_xmit) {\n\t\tprintk(KERN_WARNING \"%s: No xmit handler.\\n\", ieee->dev->name);\n\t\tgoto success;\n\t}\n\n\tif (unlikely(skb->len < SNAP_SIZE + sizeof(u16))) {\n\t\tprintk(KERN_WARNING \"%s: skb too small (%d).\\n\",\n\t\t       ieee->dev->name, skb->len);\n\t\tgoto success;\n\t}\n\n\tether_type = ((struct ethhdr *)skb->data)->h_proto;\n\n\tcrypt = ieee->crypt_info.crypt[ieee->crypt_info.tx_keyidx];\n\n\tencrypt = !(ether_type == htons(ETH_P_PAE) && ieee->ieee802_1x) &&\n\t    ieee->sec.encrypt;\n\n\thost_encrypt = ieee->host_encrypt && encrypt && crypt;\n\thost_encrypt_msdu = ieee->host_encrypt_msdu && encrypt && crypt;\n\n\tif (!encrypt && ieee->ieee802_1x &&\n\t    ieee->drop_unencrypted && ether_type != htons(ETH_P_PAE)) {\n\t\tdev->stats.tx_dropped++;\n\t\tgoto success;\n\t}\n\n\t \n\tskb_copy_from_linear_data(skb, dest, ETH_ALEN);\n\tskb_copy_from_linear_data_offset(skb, ETH_ALEN, src, ETH_ALEN);\n\n\tif (host_encrypt)\n\t\tfc = IEEE80211_FTYPE_DATA | IEEE80211_STYPE_DATA |\n\t\t    IEEE80211_FCTL_PROTECTED;\n\telse\n\t\tfc = IEEE80211_FTYPE_DATA | IEEE80211_STYPE_DATA;\n\n\tif (ieee->iw_mode == IW_MODE_INFRA) {\n\t\tfc |= IEEE80211_FCTL_TODS;\n\t\t \n\t\tmemcpy(header.addr1, ieee->bssid, ETH_ALEN);\n\t\tmemcpy(header.addr2, src, ETH_ALEN);\n\t\tmemcpy(header.addr3, dest, ETH_ALEN);\n\t} else if (ieee->iw_mode == IW_MODE_ADHOC) {\n\t\t \n\t\tmemcpy(header.addr1, dest, ETH_ALEN);\n\t\tmemcpy(header.addr2, src, ETH_ALEN);\n\t\tmemcpy(header.addr3, ieee->bssid, ETH_ALEN);\n\t}\n\thdr_len = LIBIPW_3ADDR_LEN;\n\n\tif (ieee->is_qos_active && ieee->is_qos_active(dev, skb)) {\n\t\tfc |= IEEE80211_STYPE_QOS_DATA;\n\t\thdr_len += 2;\n\n\t\tskb->priority = libipw_classify(skb);\n\t\theader.qos_ctl |= cpu_to_le16(skb->priority & LIBIPW_QCTL_TID);\n\t}\n\theader.frame_ctl = cpu_to_le16(fc);\n\n\t \n\tskb_pull(skb, sizeof(struct ethhdr));\n\n\t \n\tbytes = skb->len + SNAP_SIZE + sizeof(u16);\n\n\t \n\tif ((host_encrypt || host_encrypt_msdu) &&\n\t    crypt && crypt->ops && crypt->ops->encrypt_msdu) {\n\t\tint res = 0;\n\t\tint len = bytes + hdr_len + crypt->ops->extra_msdu_prefix_len +\n\t\t    crypt->ops->extra_msdu_postfix_len;\n\t\tstruct sk_buff *skb_new = dev_alloc_skb(len);\n\n\t\tif (unlikely(!skb_new))\n\t\t\tgoto failed;\n\n\t\tskb_reserve(skb_new, crypt->ops->extra_msdu_prefix_len);\n\t\tskb_put_data(skb_new, &header, hdr_len);\n\t\tsnapped = 1;\n\t\tlibipw_copy_snap(skb_put(skb_new, SNAP_SIZE + sizeof(u16)),\n\t\t\t\t    ether_type);\n\t\tskb_copy_from_linear_data(skb, skb_put(skb_new, skb->len), skb->len);\n\t\tres = crypt->ops->encrypt_msdu(skb_new, hdr_len, crypt->priv);\n\t\tif (res < 0) {\n\t\t\tLIBIPW_ERROR(\"msdu encryption failed\\n\");\n\t\t\tdev_kfree_skb_any(skb_new);\n\t\t\tgoto failed;\n\t\t}\n\t\tdev_kfree_skb_any(skb);\n\t\tskb = skb_new;\n\t\tbytes += crypt->ops->extra_msdu_prefix_len +\n\t\t    crypt->ops->extra_msdu_postfix_len;\n\t\tskb_pull(skb, hdr_len);\n\t}\n\n\tif (host_encrypt || ieee->host_open_frag) {\n\t\t \n\t\tif (is_multicast_ether_addr(dest) ||\n\t\t    is_broadcast_ether_addr(dest))\n\t\t\tfrag_size = MAX_FRAG_THRESHOLD;\n\t\telse\n\t\t\tfrag_size = ieee->fts;\n\n\t\t \n\t\tbytes_per_frag = frag_size - hdr_len;\n\t\tif (ieee->config &\n\t\t    (CFG_LIBIPW_COMPUTE_FCS | CFG_LIBIPW_RESERVE_FCS))\n\t\t\tbytes_per_frag -= LIBIPW_FCS_LEN;\n\n\t\t \n\t\tif (host_encrypt && crypt && crypt->ops)\n\t\t\tbytes_per_frag -= crypt->ops->extra_mpdu_prefix_len +\n\t\t\t    crypt->ops->extra_mpdu_postfix_len;\n\n\t\t \n\t\tnr_frags = bytes / bytes_per_frag;\n\t\tbytes_last_frag = bytes % bytes_per_frag;\n\t\tif (bytes_last_frag)\n\t\t\tnr_frags++;\n\t\telse\n\t\t\tbytes_last_frag = bytes_per_frag;\n\t} else {\n\t\tnr_frags = 1;\n\t\tbytes_per_frag = bytes_last_frag = bytes;\n\t\tfrag_size = bytes + hdr_len;\n\t}\n\n\trts_required = (frag_size > ieee->rts\n\t\t\t&& ieee->config & CFG_LIBIPW_RTS);\n\tif (rts_required)\n\t\tnr_frags++;\n\n\t \n\ttxb = libipw_alloc_txb(nr_frags, frag_size,\n\t\t\t\t  ieee->tx_headroom, GFP_ATOMIC);\n\tif (unlikely(!txb)) {\n\t\tprintk(KERN_WARNING \"%s: Could not allocate TXB\\n\",\n\t\t       ieee->dev->name);\n\t\tgoto failed;\n\t}\n\ttxb->encrypted = encrypt;\n\tif (host_encrypt)\n\t\ttxb->payload_size = frag_size * (nr_frags - 1) +\n\t\t    bytes_last_frag;\n\telse\n\t\ttxb->payload_size = bytes;\n\n\tif (rts_required) {\n\t\tskb_frag = txb->fragments[0];\n\t\tfrag_hdr = skb_put(skb_frag, hdr_len);\n\n\t\t \n\t\theader.frame_ctl =\n\t\t    cpu_to_le16(IEEE80211_FTYPE_CTL | IEEE80211_STYPE_RTS);\n\t\tmemcpy(frag_hdr, &header, hdr_len);\n\n\t\t \n\t\theader.frame_ctl = cpu_to_le16(fc);\n\n\t\tif (ieee->config &\n\t\t    (CFG_LIBIPW_COMPUTE_FCS | CFG_LIBIPW_RESERVE_FCS))\n\t\t\tskb_put(skb_frag, 4);\n\n\t\ttxb->rts_included = 1;\n\t\ti = 1;\n\t} else\n\t\ti = 0;\n\n\tfor (; i < nr_frags; i++) {\n\t\tskb_frag = txb->fragments[i];\n\n\t\tif (host_encrypt)\n\t\t\tskb_reserve(skb_frag,\n\t\t\t\t    crypt->ops->extra_mpdu_prefix_len);\n\n\t\tfrag_hdr = skb_put_data(skb_frag, &header, hdr_len);\n\n\t\t \n\t\tif (i != nr_frags - 1) {\n\t\t\tfrag_hdr->frame_ctl =\n\t\t\t    cpu_to_le16(fc | IEEE80211_FCTL_MOREFRAGS);\n\t\t\tbytes = bytes_per_frag;\n\t\t} else {\n\t\t\t \n\t\t\tbytes = bytes_last_frag;\n\t\t}\n\n\t\tif (i == 0 && !snapped) {\n\t\t\tlibipw_copy_snap(skb_put\n\t\t\t\t\t    (skb_frag, SNAP_SIZE + sizeof(u16)),\n\t\t\t\t\t    ether_type);\n\t\t\tbytes -= SNAP_SIZE + sizeof(u16);\n\t\t}\n\n\t\tskb_copy_from_linear_data(skb, skb_put(skb_frag, bytes), bytes);\n\n\t\t \n\t\tskb_pull(skb, bytes);\n\n\t\t \n\t\tif (host_encrypt)\n\t\t\tlibipw_encrypt_fragment(ieee, skb_frag, hdr_len);\n\n\t\tif (ieee->config &\n\t\t    (CFG_LIBIPW_COMPUTE_FCS | CFG_LIBIPW_RESERVE_FCS))\n\t\t\tskb_put(skb_frag, 4);\n\t}\n\n      success:\n\tspin_unlock_irqrestore(&ieee->lock, flags);\n\n\tdev_kfree_skb_any(skb);\n\n\tif (txb) {\n\t\tnetdev_tx_t ret = (*ieee->hard_start_xmit)(txb, dev, priority);\n\t\tif (ret == NETDEV_TX_OK) {\n\t\t\tdev->stats.tx_packets++;\n\t\t\tdev->stats.tx_bytes += txb->payload_size;\n\t\t\treturn NETDEV_TX_OK;\n\t\t}\n\n\t\tlibipw_txb_free(txb);\n\t}\n\n\treturn NETDEV_TX_OK;\n\n      failed:\n\tspin_unlock_irqrestore(&ieee->lock, flags);\n\tnetif_stop_queue(dev);\n\tdev->stats.tx_errors++;\n\treturn NETDEV_TX_BUSY;\n}\nEXPORT_SYMBOL(libipw_xmit);\n\nEXPORT_SYMBOL(libipw_txb_free);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}