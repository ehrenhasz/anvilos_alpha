{
  "module_name": "tx.c",
  "hash_id": "2e13d2727a887601ebc7d92349cc8ebfc899227f817403883b4a86925281765e",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/ti/wlcore/tx.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/etherdevice.h>\n#include <linux/pm_runtime.h>\n#include <linux/spinlock.h>\n\n#include \"wlcore.h\"\n#include \"debug.h\"\n#include \"io.h\"\n#include \"ps.h\"\n#include \"tx.h\"\n#include \"event.h\"\n#include \"hw_ops.h\"\n\n \n#include \"../wl12xx/reg.h\"\n\nstatic int wl1271_set_default_wep_key(struct wl1271 *wl,\n\t\t\t\t      struct wl12xx_vif *wlvif, u8 id)\n{\n\tint ret;\n\tbool is_ap = (wlvif->bss_type == BSS_TYPE_AP_BSS);\n\n\tif (is_ap)\n\t\tret = wl12xx_cmd_set_default_wep_key(wl, id,\n\t\t\t\t\t\t     wlvif->ap.bcast_hlid);\n\telse\n\t\tret = wl12xx_cmd_set_default_wep_key(wl, id, wlvif->sta.hlid);\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\twl1271_debug(DEBUG_CRYPT, \"default wep key idx: %d\", (int)id);\n\treturn 0;\n}\n\nstatic int wl1271_alloc_tx_id(struct wl1271 *wl, struct sk_buff *skb)\n{\n\tint id;\n\n\tid = find_first_zero_bit(wl->tx_frames_map, wl->num_tx_desc);\n\tif (id >= wl->num_tx_desc)\n\t\treturn -EBUSY;\n\n\t__set_bit(id, wl->tx_frames_map);\n\twl->tx_frames[id] = skb;\n\twl->tx_frames_cnt++;\n\treturn id;\n}\n\nvoid wl1271_free_tx_id(struct wl1271 *wl, int id)\n{\n\tif (__test_and_clear_bit(id, wl->tx_frames_map)) {\n\t\tif (unlikely(wl->tx_frames_cnt == wl->num_tx_desc))\n\t\t\tclear_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags);\n\n\t\twl->tx_frames[id] = NULL;\n\t\twl->tx_frames_cnt--;\n\t}\n}\nEXPORT_SYMBOL(wl1271_free_tx_id);\n\nstatic void wl1271_tx_ap_update_inconnection_sta(struct wl1271 *wl,\n\t\t\t\t\t\t struct wl12xx_vif *wlvif,\n\t\t\t\t\t\t struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr;\n\n\thdr = (struct ieee80211_hdr *)(skb->data +\n\t\t\t\t       sizeof(struct wl1271_tx_hw_descr));\n\tif (!ieee80211_is_auth(hdr->frame_control))\n\t\treturn;\n\n\t \n\twl1271_acx_set_inconnection_sta(wl, wlvif, hdr->addr1);\n\n\t \n\twlcore_update_inconn_sta(wl, wlvif, NULL, true);\n\twlvif->pending_auth_reply_time = jiffies;\n\tcancel_delayed_work(&wlvif->pending_auth_complete_work);\n\tieee80211_queue_delayed_work(wl->hw,\n\t\t\t\t&wlvif->pending_auth_complete_work,\n\t\t\t\tmsecs_to_jiffies(WLCORE_PEND_AUTH_ROC_TIMEOUT));\n}\n\nstatic void wl1271_tx_regulate_link(struct wl1271 *wl,\n\t\t\t\t    struct wl12xx_vif *wlvif,\n\t\t\t\t    u8 hlid)\n{\n\tbool fw_ps;\n\tu8 tx_pkts;\n\n\tif (WARN_ON(!test_bit(hlid, wlvif->links_map)))\n\t\treturn;\n\n\tfw_ps = test_bit(hlid, &wl->ap_fw_ps_map);\n\ttx_pkts = wl->links[hlid].allocated_pkts;\n\n\t \n\tif (wl->active_link_count > (wl->ap_count*2 + 1) && fw_ps &&\n\t    tx_pkts >= WL1271_PS_STA_MAX_PACKETS)\n\t\twl12xx_ps_link_start(wl, wlvif, hlid, true);\n}\n\nbool wl12xx_is_dummy_packet(struct wl1271 *wl, struct sk_buff *skb)\n{\n\treturn wl->dummy_packet == skb;\n}\nEXPORT_SYMBOL(wl12xx_is_dummy_packet);\n\nstatic u8 wl12xx_tx_get_hlid_ap(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t\t\tstruct sk_buff *skb, struct ieee80211_sta *sta)\n{\n\tif (sta) {\n\t\tstruct wl1271_station *wl_sta;\n\n\t\twl_sta = (struct wl1271_station *)sta->drv_priv;\n\t\treturn wl_sta->hlid;\n\t} else {\n\t\tstruct ieee80211_hdr *hdr;\n\n\t\tif (!test_bit(WLVIF_FLAG_AP_STARTED, &wlvif->flags))\n\t\t\treturn wl->system_hlid;\n\n\t\thdr = (struct ieee80211_hdr *)skb->data;\n\t\tif (is_multicast_ether_addr(ieee80211_get_DA(hdr)))\n\t\t\treturn wlvif->ap.bcast_hlid;\n\t\telse\n\t\t\treturn wlvif->ap.global_hlid;\n\t}\n}\n\nu8 wl12xx_tx_get_hlid(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t      struct sk_buff *skb, struct ieee80211_sta *sta)\n{\n\tstruct ieee80211_tx_info *control;\n\n\tif (wlvif->bss_type == BSS_TYPE_AP_BSS)\n\t\treturn wl12xx_tx_get_hlid_ap(wl, wlvif, skb, sta);\n\n\tcontrol = IEEE80211_SKB_CB(skb);\n\tif (control->flags & IEEE80211_TX_CTL_TX_OFFCHAN) {\n\t\twl1271_debug(DEBUG_TX, \"tx offchannel\");\n\t\treturn wlvif->dev_hlid;\n\t}\n\n\treturn wlvif->sta.hlid;\n}\n\nunsigned int wlcore_calc_packet_alignment(struct wl1271 *wl,\n\t\t\t\t\t  unsigned int packet_length)\n{\n\tif ((wl->quirks & WLCORE_QUIRK_TX_PAD_LAST_FRAME) ||\n\t    !(wl->quirks & WLCORE_QUIRK_TX_BLOCKSIZE_ALIGN))\n\t\treturn ALIGN(packet_length, WL1271_TX_ALIGN_TO);\n\telse\n\t\treturn ALIGN(packet_length, WL12XX_BUS_BLOCK_SIZE);\n}\nEXPORT_SYMBOL(wlcore_calc_packet_alignment);\n\nstatic int wl1271_tx_allocate(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t\t      struct sk_buff *skb, u32 extra, u32 buf_offset,\n\t\t\t      u8 hlid, bool is_gem)\n{\n\tstruct wl1271_tx_hw_descr *desc;\n\tu32 total_len = skb->len + sizeof(struct wl1271_tx_hw_descr) + extra;\n\tu32 total_blocks;\n\tint id, ret = -EBUSY, ac;\n\tu32 spare_blocks;\n\n\tif (buf_offset + total_len > wl->aggr_buf_size)\n\t\treturn -EAGAIN;\n\n\tspare_blocks = wlcore_hw_get_spare_blocks(wl, is_gem);\n\n\t \n\tid = wl1271_alloc_tx_id(wl, skb);\n\tif (id < 0)\n\t\treturn id;\n\n\ttotal_blocks = wlcore_hw_calc_tx_blocks(wl, total_len, spare_blocks);\n\n\tif (total_blocks <= wl->tx_blocks_available) {\n\t\tdesc = skb_push(skb, total_len - skb->len);\n\n\t\twlcore_hw_set_tx_desc_blocks(wl, desc, total_blocks,\n\t\t\t\t\t     spare_blocks);\n\n\t\tdesc->id = id;\n\n\t\twl->tx_blocks_available -= total_blocks;\n\t\twl->tx_allocated_blocks += total_blocks;\n\n\t\t \n\t\tif (wl->tx_allocated_blocks == total_blocks ||\n\t\t    test_and_clear_bit(WL1271_FLAG_REINIT_TX_WDOG, &wl->flags))\n\t\t\twl12xx_rearm_tx_watchdog_locked(wl);\n\n\t\tac = wl1271_tx_get_queue(skb_get_queue_mapping(skb));\n\t\twl->tx_allocated_pkts[ac]++;\n\n\t\tif (test_bit(hlid, wl->links_map))\n\t\t\twl->links[hlid].allocated_pkts++;\n\n\t\tret = 0;\n\n\t\twl1271_debug(DEBUG_TX,\n\t\t\t     \"tx_allocate: size: %d, blocks: %d, id: %d\",\n\t\t\t     total_len, total_blocks, id);\n\t} else {\n\t\twl1271_free_tx_id(wl, id);\n\t}\n\n\treturn ret;\n}\n\nstatic void wl1271_tx_fill_hdr(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t\t       struct sk_buff *skb, u32 extra,\n\t\t\t       struct ieee80211_tx_info *control, u8 hlid)\n{\n\tstruct wl1271_tx_hw_descr *desc;\n\tint ac, rate_idx;\n\ts64 hosttime;\n\tu16 tx_attr = 0;\n\t__le16 frame_control;\n\tstruct ieee80211_hdr *hdr;\n\tu8 *frame_start;\n\tbool is_dummy;\n\n\tdesc = (struct wl1271_tx_hw_descr *) skb->data;\n\tframe_start = (u8 *)(desc + 1);\n\thdr = (struct ieee80211_hdr *)(frame_start + extra);\n\tframe_control = hdr->frame_control;\n\n\t \n\tif (extra) {\n\t\tint hdrlen = ieee80211_hdrlen(frame_control);\n\t\tmemmove(frame_start, hdr, hdrlen);\n\t\tskb_set_network_header(skb, skb_network_offset(skb) + extra);\n\t}\n\n\t \n\thosttime = (ktime_get_boottime_ns() >> 10);\n\tdesc->start_time = cpu_to_le32(hosttime - wl->time_offset);\n\n\tis_dummy = wl12xx_is_dummy_packet(wl, skb);\n\tif (is_dummy || !wlvif || wlvif->bss_type != BSS_TYPE_AP_BSS)\n\t\tdesc->life_time = cpu_to_le16(TX_HW_MGMT_PKT_LIFETIME_TU);\n\telse\n\t\tdesc->life_time = cpu_to_le16(TX_HW_AP_MODE_PKT_LIFETIME_TU);\n\n\t \n\tac = wl1271_tx_get_queue(skb_get_queue_mapping(skb));\n\tdesc->tid = skb->priority;\n\n\tif (is_dummy) {\n\t\t \n\t\ttx_attr = (SESSION_COUNTER_INVALID <<\n\t\t\t   TX_HW_ATTR_OFST_SESSION_COUNTER) &\n\t\t\t   TX_HW_ATTR_SESSION_COUNTER;\n\n\t\ttx_attr |= TX_HW_ATTR_TX_DUMMY_REQ;\n\t} else if (wlvif) {\n\t\tu8 session_id = wl->session_ids[hlid];\n\n\t\tif ((wl->quirks & WLCORE_QUIRK_AP_ZERO_SESSION_ID) &&\n\t\t    (wlvif->bss_type == BSS_TYPE_AP_BSS))\n\t\t\tsession_id = 0;\n\n\t\t \n\t\ttx_attr = session_id << TX_HW_ATTR_OFST_SESSION_COUNTER;\n\t}\n\n\tdesc->hlid = hlid;\n\tif (is_dummy || !wlvif)\n\t\trate_idx = 0;\n\telse if (wlvif->bss_type != BSS_TYPE_AP_BSS) {\n\t\t \n\t\tif (skb->protocol == cpu_to_be16(ETH_P_PAE))\n\t\t\trate_idx = wlvif->sta.basic_rate_idx;\n\t\telse if (control->flags & IEEE80211_TX_CTL_NO_CCK_RATE)\n\t\t\trate_idx = wlvif->sta.p2p_rate_idx;\n\t\telse if (ieee80211_is_data(frame_control))\n\t\t\trate_idx = wlvif->sta.ap_rate_idx;\n\t\telse\n\t\t\trate_idx = wlvif->sta.basic_rate_idx;\n\t} else {\n\t\tif (hlid == wlvif->ap.global_hlid)\n\t\t\trate_idx = wlvif->ap.mgmt_rate_idx;\n\t\telse if (hlid == wlvif->ap.bcast_hlid ||\n\t\t\t skb->protocol == cpu_to_be16(ETH_P_PAE) ||\n\t\t\t !ieee80211_is_data(frame_control))\n\t\t\t \n\t\t\trate_idx = wlvif->ap.bcast_rate_idx;\n\t\telse\n\t\t\trate_idx = wlvif->ap.ucast_rate_idx[ac];\n\t}\n\n\ttx_attr |= rate_idx << TX_HW_ATTR_OFST_RATE_POLICY;\n\n\t \n\tif (ieee80211_is_auth(frame_control) &&\n\t    ieee80211_has_protected(frame_control))\n\t\ttx_attr |= TX_HW_ATTR_HOST_ENCRYPT;\n\n\t \n\tif (control->control.flags & IEEE80211_TX_CTRL_PORT_CTRL_PROTO)\n\t\ttx_attr |= TX_HW_ATTR_EAPOL_FRAME;\n\n\tdesc->tx_attr = cpu_to_le16(tx_attr);\n\n\twlcore_hw_set_tx_desc_csum(wl, desc, skb);\n\twlcore_hw_set_tx_desc_data_len(wl, desc, skb);\n}\n\n \nstatic int wl1271_prepare_tx_frame(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t\t\t   struct sk_buff *skb, u32 buf_offset, u8 hlid)\n{\n\tstruct ieee80211_tx_info *info;\n\tu32 extra = 0;\n\tint ret = 0;\n\tu32 total_len;\n\tbool is_dummy;\n\tbool is_gem = false;\n\n\tif (!skb) {\n\t\twl1271_error(\"discarding null skb\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (hlid == WL12XX_INVALID_LINK_ID) {\n\t\twl1271_error(\"invalid hlid. dropping skb 0x%p\", skb);\n\t\treturn -EINVAL;\n\t}\n\n\tinfo = IEEE80211_SKB_CB(skb);\n\n\tis_dummy = wl12xx_is_dummy_packet(wl, skb);\n\n\tif ((wl->quirks & WLCORE_QUIRK_TKIP_HEADER_SPACE) &&\n\t    info->control.hw_key &&\n\t    info->control.hw_key->cipher == WLAN_CIPHER_SUITE_TKIP)\n\t\textra = WL1271_EXTRA_SPACE_TKIP;\n\n\tif (info->control.hw_key) {\n\t\tbool is_wep;\n\t\tu8 idx = info->control.hw_key->hw_key_idx;\n\t\tu32 cipher = info->control.hw_key->cipher;\n\n\t\tis_wep = (cipher == WLAN_CIPHER_SUITE_WEP40) ||\n\t\t\t (cipher == WLAN_CIPHER_SUITE_WEP104);\n\n\t\tif (WARN_ON(is_wep && wlvif && wlvif->default_key != idx)) {\n\t\t\tret = wl1271_set_default_wep_key(wl, wlvif, idx);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t\twlvif->default_key = idx;\n\t\t}\n\n\t\tis_gem = (cipher == WL1271_CIPHER_SUITE_GEM);\n\t}\n\n\tret = wl1271_tx_allocate(wl, wlvif, skb, extra, buf_offset, hlid,\n\t\t\t\t is_gem);\n\tif (ret < 0)\n\t\treturn ret;\n\n\twl1271_tx_fill_hdr(wl, wlvif, skb, extra, info, hlid);\n\n\tif (!is_dummy && wlvif && wlvif->bss_type == BSS_TYPE_AP_BSS) {\n\t\twl1271_tx_ap_update_inconnection_sta(wl, wlvif, skb);\n\t\twl1271_tx_regulate_link(wl, wlvif, hlid);\n\t}\n\n\t \n\ttotal_len = wlcore_calc_packet_alignment(wl, skb->len);\n\n\tmemcpy(wl->aggr_buf + buf_offset, skb->data, skb->len);\n\tmemset(wl->aggr_buf + buf_offset + skb->len, 0, total_len - skb->len);\n\n\t \n\tif (is_dummy)\n\t\tskb_pull(skb, sizeof(struct wl1271_tx_hw_descr));\n\n\treturn total_len;\n}\n\nu32 wl1271_tx_enabled_rates_get(struct wl1271 *wl, u32 rate_set,\n\t\t\t\tenum nl80211_band rate_band)\n{\n\tstruct ieee80211_supported_band *band;\n\tu32 enabled_rates = 0;\n\tint bit;\n\n\tband = wl->hw->wiphy->bands[rate_band];\n\tfor (bit = 0; bit < band->n_bitrates; bit++) {\n\t\tif (rate_set & 0x1)\n\t\t\tenabled_rates |= band->bitrates[bit].hw_value;\n\t\trate_set >>= 1;\n\t}\n\n\t \n\trate_set >>= HW_HT_RATES_OFFSET - band->n_bitrates;\n\n\tfor (bit = 0; bit < 16; bit++) {\n\t\tif (rate_set & 0x1)\n\t\t\tenabled_rates |= (CONF_HW_BIT_RATE_MCS_0 << bit);\n\t\trate_set >>= 1;\n\t}\n\n\treturn enabled_rates;\n}\n\nvoid wl1271_handle_tx_low_watermark(struct wl1271 *wl)\n{\n\tint i;\n\tstruct wl12xx_vif *wlvif;\n\n\twl12xx_for_each_wlvif(wl, wlvif) {\n\t\tfor (i = 0; i < NUM_TX_QUEUES; i++) {\n\t\t\tif (wlcore_is_queue_stopped_by_reason(wl, wlvif, i,\n\t\t\t\t\tWLCORE_QUEUE_STOP_REASON_WATERMARK) &&\n\t\t\t    wlvif->tx_queue_count[i] <=\n\t\t\t\t\tWL1271_TX_QUEUE_LOW_WATERMARK)\n\t\t\t\t \n\t\t\t\twlcore_wake_queue(wl, wlvif, i,\n\t\t\t\t\tWLCORE_QUEUE_STOP_REASON_WATERMARK);\n\t\t}\n\t}\n}\n\nstatic int wlcore_select_ac(struct wl1271 *wl)\n{\n\tint i, q = -1, ac;\n\tu32 min_pkts = 0xffffffff;\n\n\t \n\tfor (i = 0; i < NUM_TX_QUEUES; i++) {\n\t\tac = wl1271_tx_get_queue(i);\n\t\tif (wl->tx_queue_count[ac] &&\n\t\t    wl->tx_allocated_pkts[ac] < min_pkts) {\n\t\t\tq = ac;\n\t\t\tmin_pkts = wl->tx_allocated_pkts[q];\n\t\t}\n\t}\n\n\treturn q;\n}\n\nstatic struct sk_buff *wlcore_lnk_dequeue(struct wl1271 *wl,\n\t\t\t\t\t  struct wl1271_link *lnk, u8 q)\n{\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\n\tskb = skb_dequeue(&lnk->tx_queue[q]);\n\tif (skb) {\n\t\tspin_lock_irqsave(&wl->wl_lock, flags);\n\t\tWARN_ON_ONCE(wl->tx_queue_count[q] <= 0);\n\t\twl->tx_queue_count[q]--;\n\t\tif (lnk->wlvif) {\n\t\t\tWARN_ON_ONCE(lnk->wlvif->tx_queue_count[q] <= 0);\n\t\t\tlnk->wlvif->tx_queue_count[q]--;\n\t\t}\n\t\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n\t}\n\n\treturn skb;\n}\n\nstatic struct sk_buff *wlcore_lnk_dequeue_high_prio(struct wl1271 *wl,\n\t\t\t\t\t\t    u8 hlid, u8 ac,\n\t\t\t\t\t\t    u8 *low_prio_hlid)\n{\n\tstruct wl1271_link *lnk = &wl->links[hlid];\n\n\tif (!wlcore_hw_lnk_high_prio(wl, hlid, lnk)) {\n\t\tif (*low_prio_hlid == WL12XX_INVALID_LINK_ID &&\n\t\t    !skb_queue_empty(&lnk->tx_queue[ac]) &&\n\t\t    wlcore_hw_lnk_low_prio(wl, hlid, lnk))\n\t\t\t \n\t\t\t*low_prio_hlid = hlid;\n\n\t\treturn NULL;\n\t}\n\n\treturn wlcore_lnk_dequeue(wl, lnk, ac);\n}\n\nstatic struct sk_buff *wlcore_vif_dequeue_high_prio(struct wl1271 *wl,\n\t\t\t\t\t\t    struct wl12xx_vif *wlvif,\n\t\t\t\t\t\t    u8 ac, u8 *hlid,\n\t\t\t\t\t\t    u8 *low_prio_hlid)\n{\n\tstruct sk_buff *skb = NULL;\n\tint i, h, start_hlid;\n\n\t \n\tstart_hlid = (wlvif->last_tx_hlid + 1) % wl->num_links;\n\n\t \n\tfor (i = 0; i < wl->num_links; i++) {\n\t\th = (start_hlid + i) % wl->num_links;\n\n\t\t \n\t\tif (!test_bit(h, wlvif->links_map))\n\t\t\tcontinue;\n\n\t\tskb = wlcore_lnk_dequeue_high_prio(wl, h, ac,\n\t\t\t\t\t\t   low_prio_hlid);\n\t\tif (!skb)\n\t\t\tcontinue;\n\n\t\twlvif->last_tx_hlid = h;\n\t\tbreak;\n\t}\n\n\tif (!skb)\n\t\twlvif->last_tx_hlid = 0;\n\n\t*hlid = wlvif->last_tx_hlid;\n\treturn skb;\n}\n\nstatic struct sk_buff *wl1271_skb_dequeue(struct wl1271 *wl, u8 *hlid)\n{\n\tunsigned long flags;\n\tstruct wl12xx_vif *wlvif = wl->last_wlvif;\n\tstruct sk_buff *skb = NULL;\n\tint ac;\n\tu8 low_prio_hlid = WL12XX_INVALID_LINK_ID;\n\n\tac = wlcore_select_ac(wl);\n\tif (ac < 0)\n\t\tgoto out;\n\n\t \n\tif (wlvif) {\n\t\twl12xx_for_each_wlvif_continue(wl, wlvif) {\n\t\t\tif (!wlvif->tx_queue_count[ac])\n\t\t\t\tcontinue;\n\n\t\t\tskb = wlcore_vif_dequeue_high_prio(wl, wlvif, ac, hlid,\n\t\t\t\t\t\t\t   &low_prio_hlid);\n\t\t\tif (!skb)\n\t\t\t\tcontinue;\n\n\t\t\twl->last_wlvif = wlvif;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (!skb) {\n\t\tskb = wlcore_lnk_dequeue_high_prio(wl, wl->system_hlid,\n\t\t\t\t\t\t   ac, &low_prio_hlid);\n\t\tif (skb) {\n\t\t\t*hlid = wl->system_hlid;\n\t\t\twl->last_wlvif = NULL;\n\t\t}\n\t}\n\n\t \n\tif (!skb) {\n\t\twl12xx_for_each_wlvif(wl, wlvif) {\n\t\t\tif (!wlvif->tx_queue_count[ac])\n\t\t\t\tgoto next;\n\n\t\t\tskb = wlcore_vif_dequeue_high_prio(wl, wlvif, ac, hlid,\n\t\t\t\t\t\t\t   &low_prio_hlid);\n\t\t\tif (skb) {\n\t\t\t\twl->last_wlvif = wlvif;\n\t\t\t\tbreak;\n\t\t\t}\n\nnext:\n\t\t\tif (wlvif == wl->last_wlvif)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tif (!skb && low_prio_hlid != WL12XX_INVALID_LINK_ID) {\n\t\tstruct wl1271_link *lnk = &wl->links[low_prio_hlid];\n\t\tskb = wlcore_lnk_dequeue(wl, lnk, ac);\n\n\t\tWARN_ON(!skb);  \n\t\t*hlid = low_prio_hlid;\n\n\t\t \n\t\twl->last_wlvif = lnk->wlvif;\n\t\tif (lnk->wlvif)\n\t\t\tlnk->wlvif->last_tx_hlid = low_prio_hlid;\n\n\t}\n\nout:\n\tif (!skb &&\n\t    test_and_clear_bit(WL1271_FLAG_DUMMY_PACKET_PENDING, &wl->flags)) {\n\t\tint q;\n\n\t\tskb = wl->dummy_packet;\n\t\t*hlid = wl->system_hlid;\n\t\tq = wl1271_tx_get_queue(skb_get_queue_mapping(skb));\n\t\tspin_lock_irqsave(&wl->wl_lock, flags);\n\t\tWARN_ON_ONCE(wl->tx_queue_count[q] <= 0);\n\t\twl->tx_queue_count[q]--;\n\t\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n\t}\n\n\treturn skb;\n}\n\nstatic void wl1271_skb_queue_head(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t\t\t  struct sk_buff *skb, u8 hlid)\n{\n\tunsigned long flags;\n\tint q = wl1271_tx_get_queue(skb_get_queue_mapping(skb));\n\n\tif (wl12xx_is_dummy_packet(wl, skb)) {\n\t\tset_bit(WL1271_FLAG_DUMMY_PACKET_PENDING, &wl->flags);\n\t} else {\n\t\tskb_queue_head(&wl->links[hlid].tx_queue[q], skb);\n\n\t\t \n\t\twlvif->last_tx_hlid = (hlid + wl->num_links - 1) %\n\t\t\t\t      wl->num_links;\n\t}\n\n\tspin_lock_irqsave(&wl->wl_lock, flags);\n\twl->tx_queue_count[q]++;\n\tif (wlvif)\n\t\twlvif->tx_queue_count[q]++;\n\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n}\n\nstatic bool wl1271_tx_is_data_present(struct sk_buff *skb)\n{\n\tstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)(skb->data);\n\n\treturn ieee80211_is_data_present(hdr->frame_control);\n}\n\nvoid wl12xx_rearm_rx_streaming(struct wl1271 *wl, unsigned long *active_hlids)\n{\n\tstruct wl12xx_vif *wlvif;\n\tu32 timeout;\n\tu8 hlid;\n\n\tif (!wl->conf.rx_streaming.interval)\n\t\treturn;\n\n\tif (!wl->conf.rx_streaming.always &&\n\t    !test_bit(WL1271_FLAG_SOFT_GEMINI, &wl->flags))\n\t\treturn;\n\n\ttimeout = wl->conf.rx_streaming.duration;\n\twl12xx_for_each_wlvif_sta(wl, wlvif) {\n\t\tbool found = false;\n\t\tfor_each_set_bit(hlid, active_hlids, wl->num_links) {\n\t\t\tif (test_bit(hlid, wlvif->links_map)) {\n\t\t\t\tfound  = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!found)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (!test_bit(WLVIF_FLAG_RX_STREAMING_STARTED, &wlvif->flags))\n\t\t\tieee80211_queue_work(wl->hw,\n\t\t\t\t\t     &wlvif->rx_streaming_enable_work);\n\n\t\tmod_timer(&wlvif->rx_streaming_timer,\n\t\t\t  jiffies + msecs_to_jiffies(timeout));\n\t}\n}\n\n \nint wlcore_tx_work_locked(struct wl1271 *wl)\n{\n\tstruct wl12xx_vif *wlvif;\n\tstruct sk_buff *skb;\n\tstruct wl1271_tx_hw_descr *desc;\n\tu32 buf_offset = 0, last_len = 0;\n\tbool sent_packets = false;\n\tunsigned long active_hlids[BITS_TO_LONGS(WLCORE_MAX_LINKS)] = {0};\n\tint ret = 0;\n\tint bus_ret = 0;\n\tu8 hlid;\n\n\tif (unlikely(wl->state != WLCORE_STATE_ON))\n\t\treturn 0;\n\n\twhile ((skb = wl1271_skb_dequeue(wl, &hlid))) {\n\t\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\t\tbool has_data = false;\n\n\t\twlvif = NULL;\n\t\tif (!wl12xx_is_dummy_packet(wl, skb))\n\t\t\twlvif = wl12xx_vif_to_data(info->control.vif);\n\t\telse\n\t\t\thlid = wl->system_hlid;\n\n\t\thas_data = wlvif && wl1271_tx_is_data_present(skb);\n\t\tret = wl1271_prepare_tx_frame(wl, wlvif, skb, buf_offset,\n\t\t\t\t\t      hlid);\n\t\tif (ret == -EAGAIN) {\n\t\t\t \n\t\t\twl1271_skb_queue_head(wl, wlvif, skb, hlid);\n\n\t\t\tbuf_offset = wlcore_hw_pre_pkt_send(wl, buf_offset,\n\t\t\t\t\t\t\t    last_len);\n\t\t\tbus_ret = wlcore_write_data(wl, REG_SLV_MEM_DATA,\n\t\t\t\t\t     wl->aggr_buf, buf_offset, true);\n\t\t\tif (bus_ret < 0)\n\t\t\t\tgoto out;\n\n\t\t\tsent_packets = true;\n\t\t\tbuf_offset = 0;\n\t\t\tcontinue;\n\t\t} else if (ret == -EBUSY) {\n\t\t\t \n\t\t\twl1271_skb_queue_head(wl, wlvif, skb, hlid);\n\t\t\t \n\t\t\tset_bit(WL1271_FLAG_FW_TX_BUSY, &wl->flags);\n\t\t\tgoto out_ack;\n\t\t} else if (ret < 0) {\n\t\t\tif (wl12xx_is_dummy_packet(wl, skb))\n\t\t\t\t \n\t\t\t\twl1271_skb_queue_head(wl, wlvif, skb, hlid);\n\t\t\telse\n\t\t\t\tieee80211_free_txskb(wl->hw, skb);\n\t\t\tgoto out_ack;\n\t\t}\n\t\tlast_len = ret;\n\t\tbuf_offset += last_len;\n\t\twl->tx_packets_count++;\n\t\tif (has_data) {\n\t\t\tdesc = (struct wl1271_tx_hw_descr *) skb->data;\n\t\t\t__set_bit(desc->hlid, active_hlids);\n\t\t}\n\t}\n\nout_ack:\n\tif (buf_offset) {\n\t\tbuf_offset = wlcore_hw_pre_pkt_send(wl, buf_offset, last_len);\n\t\tbus_ret = wlcore_write_data(wl, REG_SLV_MEM_DATA, wl->aggr_buf,\n\t\t\t\t\t     buf_offset, true);\n\t\tif (bus_ret < 0)\n\t\t\tgoto out;\n\n\t\tsent_packets = true;\n\t}\n\tif (sent_packets) {\n\t\t \n\t\tif (wl->quirks & WLCORE_QUIRK_END_OF_TRANSACTION) {\n\t\t\tbus_ret = wlcore_write32(wl, WL12XX_HOST_WR_ACCESS,\n\t\t\t\t\t     wl->tx_packets_count);\n\t\t\tif (bus_ret < 0)\n\t\t\t\tgoto out;\n\t\t}\n\n\t\twl1271_handle_tx_low_watermark(wl);\n\t}\n\twl12xx_rearm_rx_streaming(wl, active_hlids);\n\nout:\n\treturn bus_ret;\n}\n\nvoid wl1271_tx_work(struct work_struct *work)\n{\n\tstruct wl1271 *wl = container_of(work, struct wl1271, tx_work);\n\tint ret;\n\n\tmutex_lock(&wl->mutex);\n\tret = pm_runtime_resume_and_get(wl->dev);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = wlcore_tx_work_locked(wl);\n\tif (ret < 0) {\n\t\tpm_runtime_put_noidle(wl->dev);\n\t\twl12xx_queue_recovery_work(wl);\n\t\tgoto out;\n\t}\n\n\tpm_runtime_mark_last_busy(wl->dev);\n\tpm_runtime_put_autosuspend(wl->dev);\nout:\n\tmutex_unlock(&wl->mutex);\n}\n\nstatic u8 wl1271_tx_get_rate_flags(u8 rate_class_index)\n{\n\tu8 flags = 0;\n\n\t \n\tif (rate_class_index <= 8)\n\t\tflags |= IEEE80211_TX_RC_MCS;\n\n\t \n\tif (rate_class_index == 0)\n\t\tflags |= IEEE80211_TX_RC_SHORT_GI;\n\n\treturn flags;\n}\n\nstatic void wl1271_tx_complete_packet(struct wl1271 *wl,\n\t\t\t\t      struct wl1271_tx_hw_res_descr *result)\n{\n\tstruct ieee80211_tx_info *info;\n\tstruct ieee80211_vif *vif;\n\tstruct wl12xx_vif *wlvif;\n\tstruct sk_buff *skb;\n\tint id = result->id;\n\tint rate = -1;\n\tu8 rate_flags = 0;\n\tu8 retries = 0;\n\n\t \n\tif (unlikely(id >= wl->num_tx_desc || wl->tx_frames[id] == NULL)) {\n\t\twl1271_warning(\"TX result illegal id: %d\", id);\n\t\treturn;\n\t}\n\n\tskb = wl->tx_frames[id];\n\tinfo = IEEE80211_SKB_CB(skb);\n\n\tif (wl12xx_is_dummy_packet(wl, skb)) {\n\t\twl1271_free_tx_id(wl, id);\n\t\treturn;\n\t}\n\n\t \n\tvif = info->control.vif;\n\twlvif = wl12xx_vif_to_data(vif);\n\n\t \n\tif (result->status == TX_SUCCESS) {\n\t\tif (!(info->flags & IEEE80211_TX_CTL_NO_ACK))\n\t\t\tinfo->flags |= IEEE80211_TX_STAT_ACK;\n\t\trate = wlcore_rate_to_idx(wl, result->rate_class_index,\n\t\t\t\t\t  wlvif->band);\n\t\trate_flags = wl1271_tx_get_rate_flags(result->rate_class_index);\n\t\tretries = result->ack_failures;\n\t} else if (result->status == TX_RETRY_EXCEEDED) {\n\t\twl->stats.excessive_retries++;\n\t\tretries = result->ack_failures;\n\t}\n\n\tinfo->status.rates[0].idx = rate;\n\tinfo->status.rates[0].count = retries;\n\tinfo->status.rates[0].flags = rate_flags;\n\tinfo->status.ack_signal = -1;\n\n\twl->stats.retry_count += result->ack_failures;\n\n\t \n\tskb_pull(skb, sizeof(struct wl1271_tx_hw_descr));\n\n\t \n\tif ((wl->quirks & WLCORE_QUIRK_TKIP_HEADER_SPACE) &&\n\t    info->control.hw_key &&\n\t    info->control.hw_key->cipher == WLAN_CIPHER_SUITE_TKIP) {\n\t\tint hdrlen = ieee80211_get_hdrlen_from_skb(skb);\n\t\tmemmove(skb->data + WL1271_EXTRA_SPACE_TKIP, skb->data,\n\t\t\thdrlen);\n\t\tskb_pull(skb, WL1271_EXTRA_SPACE_TKIP);\n\t}\n\n\twl1271_debug(DEBUG_TX, \"tx status id %u skb 0x%p failures %u rate 0x%x\"\n\t\t     \" status 0x%x\",\n\t\t     result->id, skb, result->ack_failures,\n\t\t     result->rate_class_index, result->status);\n\n\t \n\tskb_queue_tail(&wl->deferred_tx_queue, skb);\n\tqueue_work(wl->freezable_wq, &wl->netstack_work);\n\twl1271_free_tx_id(wl, result->id);\n}\n\n \nint wlcore_tx_complete(struct wl1271 *wl)\n{\n\tstruct wl1271_acx_mem_map *memmap = wl->target_mem_map;\n\tu32 count, fw_counter;\n\tu32 i;\n\tint ret;\n\n\t \n\tret = wlcore_read(wl, le32_to_cpu(memmap->tx_result),\n\t\t\t  wl->tx_res_if, sizeof(*wl->tx_res_if), false);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tfw_counter = le32_to_cpu(wl->tx_res_if->tx_result_fw_counter);\n\n\t \n\tret = wlcore_write32(wl, le32_to_cpu(memmap->tx_result) +\n\t\t\t     offsetof(struct wl1271_tx_hw_res_if,\n\t\t\t\t      tx_result_host_counter), fw_counter);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tcount = fw_counter - wl->tx_results_count;\n\twl1271_debug(DEBUG_TX, \"tx_complete received, packets: %d\", count);\n\n\t \n\tif (unlikely(count > TX_HW_RESULT_QUEUE_LEN))\n\t\twl1271_warning(\"TX result overflow from chipset: %d\", count);\n\n\t \n\tfor (i = 0; i < count; i++) {\n\t\tstruct wl1271_tx_hw_res_descr *result;\n\t\tu8 offset = wl->tx_results_count & TX_HW_RESULT_QUEUE_LEN_MASK;\n\n\t\t \n\t\tresult =  &(wl->tx_res_if->tx_results_queue[offset]);\n\t\twl1271_tx_complete_packet(wl, result);\n\n\t\twl->tx_results_count++;\n\t}\n\nout:\n\treturn ret;\n}\nEXPORT_SYMBOL(wlcore_tx_complete);\n\nvoid wl1271_tx_reset_link_queues(struct wl1271 *wl, u8 hlid)\n{\n\tstruct sk_buff *skb;\n\tint i;\n\tunsigned long flags;\n\tstruct ieee80211_tx_info *info;\n\tint total[NUM_TX_QUEUES];\n\tstruct wl1271_link *lnk = &wl->links[hlid];\n\n\tfor (i = 0; i < NUM_TX_QUEUES; i++) {\n\t\ttotal[i] = 0;\n\t\twhile ((skb = skb_dequeue(&lnk->tx_queue[i]))) {\n\t\t\twl1271_debug(DEBUG_TX, \"link freeing skb 0x%p\", skb);\n\n\t\t\tif (!wl12xx_is_dummy_packet(wl, skb)) {\n\t\t\t\tinfo = IEEE80211_SKB_CB(skb);\n\t\t\t\tinfo->status.rates[0].idx = -1;\n\t\t\t\tinfo->status.rates[0].count = 0;\n\t\t\t\tieee80211_tx_status_ni(wl->hw, skb);\n\t\t\t}\n\n\t\t\ttotal[i]++;\n\t\t}\n\t}\n\n\tspin_lock_irqsave(&wl->wl_lock, flags);\n\tfor (i = 0; i < NUM_TX_QUEUES; i++) {\n\t\twl->tx_queue_count[i] -= total[i];\n\t\tif (lnk->wlvif)\n\t\t\tlnk->wlvif->tx_queue_count[i] -= total[i];\n\t}\n\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n\n\twl1271_handle_tx_low_watermark(wl);\n}\n\n \nvoid wl12xx_tx_reset_wlvif(struct wl1271 *wl, struct wl12xx_vif *wlvif)\n{\n\tint i;\n\n\t \n\tfor_each_set_bit(i, wlvif->links_map, wl->num_links) {\n\t\tif (wlvif->bss_type == BSS_TYPE_AP_BSS &&\n\t\t    i != wlvif->ap.bcast_hlid && i != wlvif->ap.global_hlid) {\n\t\t\t \n\t\t\twl1271_free_sta(wl, wlvif, i);\n\t\t} else {\n\t\t\tu8 hlid = i;\n\t\t\twl12xx_free_link(wl, wlvif, &hlid);\n\t\t}\n\t}\n\twlvif->last_tx_hlid = 0;\n\n\tfor (i = 0; i < NUM_TX_QUEUES; i++)\n\t\twlvif->tx_queue_count[i] = 0;\n}\n \nvoid wl12xx_tx_reset(struct wl1271 *wl)\n{\n\tint i;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *info;\n\n\t \n\tif (wl1271_tx_total_queue_count(wl) != 0) {\n\t\tfor (i = 0; i < wl->num_links; i++)\n\t\t\twl1271_tx_reset_link_queues(wl, i);\n\n\t\tfor (i = 0; i < NUM_TX_QUEUES; i++)\n\t\t\twl->tx_queue_count[i] = 0;\n\t}\n\n\t \n\twl1271_handle_tx_low_watermark(wl);\n\n\tfor (i = 0; i < wl->num_tx_desc; i++) {\n\t\tif (wl->tx_frames[i] == NULL)\n\t\t\tcontinue;\n\n\t\tskb = wl->tx_frames[i];\n\t\twl1271_free_tx_id(wl, i);\n\t\twl1271_debug(DEBUG_TX, \"freeing skb 0x%p\", skb);\n\n\t\tif (!wl12xx_is_dummy_packet(wl, skb)) {\n\t\t\t \n\t\t\tinfo = IEEE80211_SKB_CB(skb);\n\t\t\tskb_pull(skb, sizeof(struct wl1271_tx_hw_descr));\n\t\t\tif ((wl->quirks & WLCORE_QUIRK_TKIP_HEADER_SPACE) &&\n\t\t\t    info->control.hw_key &&\n\t\t\t    info->control.hw_key->cipher ==\n\t\t\t    WLAN_CIPHER_SUITE_TKIP) {\n\t\t\t\tint hdrlen = ieee80211_get_hdrlen_from_skb(skb);\n\t\t\t\tmemmove(skb->data + WL1271_EXTRA_SPACE_TKIP,\n\t\t\t\t\tskb->data, hdrlen);\n\t\t\t\tskb_pull(skb, WL1271_EXTRA_SPACE_TKIP);\n\t\t\t}\n\n\t\t\tinfo->status.rates[0].idx = -1;\n\t\t\tinfo->status.rates[0].count = 0;\n\n\t\t\tieee80211_tx_status_ni(wl->hw, skb);\n\t\t}\n\t}\n}\n\n#define WL1271_TX_FLUSH_TIMEOUT 500000\n\n \nvoid wl1271_tx_flush(struct wl1271 *wl)\n{\n\tunsigned long timeout, start_time;\n\tint i;\n\tstart_time = jiffies;\n\ttimeout = start_time + usecs_to_jiffies(WL1271_TX_FLUSH_TIMEOUT);\n\n\t \n\tmutex_lock(&wl->flush_mutex);\n\n\tmutex_lock(&wl->mutex);\n\tif (wl->tx_frames_cnt == 0 && wl1271_tx_total_queue_count(wl) == 0) {\n\t\tmutex_unlock(&wl->mutex);\n\t\tgoto out;\n\t}\n\n\twlcore_stop_queues(wl, WLCORE_QUEUE_STOP_REASON_FLUSH);\n\n\twhile (!time_after(jiffies, timeout)) {\n\t\twl1271_debug(DEBUG_MAC80211, \"flushing tx buffer: %d %d\",\n\t\t\t     wl->tx_frames_cnt,\n\t\t\t     wl1271_tx_total_queue_count(wl));\n\n\t\t \n\t\tmutex_unlock(&wl->mutex);\n\t\tif (wl1271_tx_total_queue_count(wl))\n\t\t\twl1271_tx_work(&wl->tx_work);\n\t\tmsleep(20);\n\t\tmutex_lock(&wl->mutex);\n\n\t\tif ((wl->tx_frames_cnt == 0) &&\n\t\t    (wl1271_tx_total_queue_count(wl) == 0)) {\n\t\t\twl1271_debug(DEBUG_MAC80211, \"tx flush took %d ms\",\n\t\t\t\t     jiffies_to_msecs(jiffies - start_time));\n\t\t\tgoto out_wake;\n\t\t}\n\t}\n\n\twl1271_warning(\"Unable to flush all TX buffers, \"\n\t\t       \"timed out (timeout %d ms\",\n\t\t       WL1271_TX_FLUSH_TIMEOUT / 1000);\n\n\t \n\tfor (i = 0; i < wl->num_links; i++)\n\t\twl1271_tx_reset_link_queues(wl, i);\n\nout_wake:\n\twlcore_wake_queues(wl, WLCORE_QUEUE_STOP_REASON_FLUSH);\n\tmutex_unlock(&wl->mutex);\nout:\n\tmutex_unlock(&wl->flush_mutex);\n}\nEXPORT_SYMBOL_GPL(wl1271_tx_flush);\n\nu32 wl1271_tx_min_rate_get(struct wl1271 *wl, u32 rate_set)\n{\n\tif (WARN_ON(!rate_set))\n\t\treturn 0;\n\n\treturn BIT(__ffs(rate_set));\n}\nEXPORT_SYMBOL_GPL(wl1271_tx_min_rate_get);\n\nvoid wlcore_stop_queue_locked(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t\t      u8 queue, enum wlcore_queue_stop_reason reason)\n{\n\tint hwq = wlcore_tx_get_mac80211_queue(wlvif, queue);\n\tbool stopped = !!wl->queue_stop_reasons[hwq];\n\n\t \n\tWARN_ON_ONCE(test_and_set_bit(reason, &wl->queue_stop_reasons[hwq]));\n\n\tif (stopped)\n\t\treturn;\n\n\tieee80211_stop_queue(wl->hw, hwq);\n}\n\nvoid wlcore_stop_queue(struct wl1271 *wl, struct wl12xx_vif *wlvif, u8 queue,\n\t\t       enum wlcore_queue_stop_reason reason)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&wl->wl_lock, flags);\n\twlcore_stop_queue_locked(wl, wlvif, queue, reason);\n\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n}\n\nvoid wlcore_wake_queue(struct wl1271 *wl, struct wl12xx_vif *wlvif, u8 queue,\n\t\t       enum wlcore_queue_stop_reason reason)\n{\n\tunsigned long flags;\n\tint hwq = wlcore_tx_get_mac80211_queue(wlvif, queue);\n\n\tspin_lock_irqsave(&wl->wl_lock, flags);\n\n\t \n\tWARN_ON_ONCE(!test_and_clear_bit(reason, &wl->queue_stop_reasons[hwq]));\n\n\tif (wl->queue_stop_reasons[hwq])\n\t\tgoto out;\n\n\tieee80211_wake_queue(wl->hw, hwq);\n\nout:\n\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n}\n\nvoid wlcore_stop_queues(struct wl1271 *wl,\n\t\t\tenum wlcore_queue_stop_reason reason)\n{\n\tint i;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&wl->wl_lock, flags);\n\n\t \n        for (i = 0; i < WLCORE_NUM_MAC_ADDRESSES * NUM_TX_QUEUES; i++)\n                WARN_ON_ONCE(test_and_set_bit(reason,\n\t\t\t\t\t      &wl->queue_stop_reasons[i]));\n\n\t \n\tieee80211_stop_queues(wl->hw);\n\n\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n}\n\nvoid wlcore_wake_queues(struct wl1271 *wl,\n\t\t\tenum wlcore_queue_stop_reason reason)\n{\n\tint i;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&wl->wl_lock, flags);\n\n\t \n        for (i = 0; i < WLCORE_NUM_MAC_ADDRESSES * NUM_TX_QUEUES; i++)\n\t\tWARN_ON_ONCE(!test_and_clear_bit(reason,\n\t\t\t\t\t\t &wl->queue_stop_reasons[i]));\n\n\t \n\tieee80211_wake_queues(wl->hw);\n\n\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n}\n\nbool wlcore_is_queue_stopped_by_reason(struct wl1271 *wl,\n\t\t\t\t       struct wl12xx_vif *wlvif, u8 queue,\n\t\t\t\t       enum wlcore_queue_stop_reason reason)\n{\n\tunsigned long flags;\n\tbool stopped;\n\n\tspin_lock_irqsave(&wl->wl_lock, flags);\n\tstopped = wlcore_is_queue_stopped_by_reason_locked(wl, wlvif, queue,\n\t\t\t\t\t\t\t   reason);\n\tspin_unlock_irqrestore(&wl->wl_lock, flags);\n\n\treturn stopped;\n}\n\nbool wlcore_is_queue_stopped_by_reason_locked(struct wl1271 *wl,\n\t\t\t\t       struct wl12xx_vif *wlvif, u8 queue,\n\t\t\t\t       enum wlcore_queue_stop_reason reason)\n{\n\tint hwq = wlcore_tx_get_mac80211_queue(wlvif, queue);\n\n\tassert_spin_locked(&wl->wl_lock);\n\treturn test_bit(reason, &wl->queue_stop_reasons[hwq]);\n}\n\nbool wlcore_is_queue_stopped_locked(struct wl1271 *wl, struct wl12xx_vif *wlvif,\n\t\t\t\t    u8 queue)\n{\n\tint hwq = wlcore_tx_get_mac80211_queue(wlvif, queue);\n\n\tassert_spin_locked(&wl->wl_lock);\n\treturn !!wl->queue_stop_reasons[hwq];\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}