{
  "module_name": "topaz_pcie.c",
  "hash_id": "55e0ddaa912e0d560f619763d29bbaaeea8dbdbe9b46ba52f60e544e2d1c62be",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/quantenna/qtnfmac/pcie/topaz_pcie.c",
  "human_readable_source": "\n \n\n#include <linux/kernel.h>\n#include <linux/firmware.h>\n#include <linux/pci.h>\n#include <linux/vmalloc.h>\n#include <linux/delay.h>\n#include <linux/interrupt.h>\n#include <linux/sched.h>\n#include <linux/crc32.h>\n#include <linux/completion.h>\n#include <linux/spinlock.h>\n#include <linux/circ_buf.h>\n\n#include \"pcie_priv.h\"\n#include \"topaz_pcie_regs.h\"\n#include \"topaz_pcie_ipc.h\"\n#include \"qtn_hw_ids.h\"\n#include \"core.h\"\n#include \"bus.h\"\n#include \"shm_ipc.h\"\n#include \"debug.h\"\n\n#define TOPAZ_TX_BD_SIZE_DEFAULT\t128\n#define TOPAZ_RX_BD_SIZE_DEFAULT\t256\n\nstruct qtnf_topaz_tx_bd {\n\t__le32 addr;\n\t__le32 info;\n} __packed;\n\nstruct qtnf_topaz_rx_bd {\n\t__le32 addr;\n\t__le32 info;\n} __packed;\n\nstruct qtnf_extra_bd_params {\n\t__le32 param1;\n\t__le32 param2;\n\t__le32 param3;\n\t__le32 param4;\n} __packed;\n\n#define QTNF_BD_PARAM_OFFSET(n)\toffsetof(struct qtnf_extra_bd_params, param##n)\n\nstruct vmac_pkt_info {\n\t__le32 addr;\n\t__le32 info;\n};\n\nstruct qtnf_topaz_bda {\n\t__le16\tbda_len;\n\t__le16\tbda_version;\n\t__le32\tbda_bootstate;\n\t__le32\tbda_dma_mask;\n\t__le32\tbda_dma_offset;\n\t__le32\tbda_flags;\n\t__le32\tbda_img;\n\t__le32\tbda_img_size;\n\t__le32\tbda_ep2h_irqstatus;\n\t__le32\tbda_h2ep_irqstatus;\n\t__le32\tbda_msi_addr;\n\tu8\treserved1[56];\n\t__le32\tbda_flashsz;\n\tu8\tbda_boardname[PCIE_BDA_NAMELEN];\n\t__le32\tbda_pci_pre_status;\n\t__le32\tbda_pci_endian;\n\t__le32\tbda_pci_post_status;\n\t__le32\tbda_h2ep_txd_budget;\n\t__le32\tbda_ep2h_txd_budget;\n\t__le32\tbda_rc_rx_bd_base;\n\t__le32\tbda_rc_rx_bd_num;\n\t__le32\tbda_rc_tx_bd_base;\n\t__le32\tbda_rc_tx_bd_num;\n\tu8\tbda_ep_link_state;\n\tu8\tbda_rc_link_state;\n\tu8\tbda_rc_msi_enabled;\n\tu8\treserved2;\n\t__le32\tbda_ep_next_pkt;\n\tstruct vmac_pkt_info request[QTN_PCIE_RC_TX_QUEUE_LEN];\n\tstruct qtnf_shm_ipc_region bda_shm_reg1 __aligned(4096);\n\tstruct qtnf_shm_ipc_region bda_shm_reg2 __aligned(4096);\n} __packed;\n\nstruct qtnf_pcie_topaz_state {\n\tstruct qtnf_pcie_bus_priv base;\n\tstruct qtnf_topaz_bda __iomem *bda;\n\n\tdma_addr_t dma_msi_dummy;\n\tu32 dma_msi_imwr;\n\n\tstruct qtnf_topaz_tx_bd *tx_bd_vbase;\n\tstruct qtnf_topaz_rx_bd *rx_bd_vbase;\n\n\t__le32 __iomem *ep_next_rx_pkt;\n\t__le32 __iomem *txqueue_wake;\n\t__le32 __iomem *ep_pmstate;\n\n\tunsigned long rx_pkt_count;\n};\n\nstatic void qtnf_deassert_intx(struct qtnf_pcie_topaz_state *ts)\n{\n\tvoid __iomem *reg = ts->base.sysctl_bar + TOPAZ_PCIE_CFG0_OFFSET;\n\tu32 cfg;\n\n\tcfg = readl(reg);\n\tcfg &= ~TOPAZ_ASSERT_INTX;\n\tqtnf_non_posted_write(cfg, reg);\n}\n\nstatic inline int qtnf_topaz_intx_asserted(struct qtnf_pcie_topaz_state *ts)\n{\n\tvoid __iomem *reg = ts->base.sysctl_bar + TOPAZ_PCIE_CFG0_OFFSET;\n\tu32 cfg = readl(reg);\n\n\treturn !!(cfg & TOPAZ_ASSERT_INTX);\n}\n\nstatic void qtnf_topaz_reset_ep(struct qtnf_pcie_topaz_state *ts)\n{\n\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_RST_EP_IRQ),\n\t       TOPAZ_LH_IPC4_INT(ts->base.sysctl_bar));\n\tmsleep(QTN_EP_RESET_WAIT_MS);\n\tpci_restore_state(ts->base.pdev);\n}\n\nstatic void setup_rx_irqs(struct qtnf_pcie_topaz_state *ts)\n{\n\tvoid __iomem *reg = PCIE_DMA_WR_DONE_IMWR_ADDR_LOW(ts->base.dmareg_bar);\n\n\tts->dma_msi_imwr = readl(reg);\n}\n\nstatic void enable_rx_irqs(struct qtnf_pcie_topaz_state *ts)\n{\n\tvoid __iomem *reg = PCIE_DMA_WR_DONE_IMWR_ADDR_LOW(ts->base.dmareg_bar);\n\n\tqtnf_non_posted_write(ts->dma_msi_imwr, reg);\n}\n\nstatic void disable_rx_irqs(struct qtnf_pcie_topaz_state *ts)\n{\n\tvoid __iomem *reg = PCIE_DMA_WR_DONE_IMWR_ADDR_LOW(ts->base.dmareg_bar);\n\n\tqtnf_non_posted_write(QTN_HOST_LO32(ts->dma_msi_dummy), reg);\n}\n\nstatic void qtnf_topaz_ipc_gen_ep_int(void *arg)\n{\n\tstruct qtnf_pcie_topaz_state *ts = arg;\n\n\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_CTRL_IRQ),\n\t       TOPAZ_CTL_M2L_INT(ts->base.sysctl_bar));\n}\n\nstatic int qtnf_is_state(__le32 __iomem *reg, u32 state)\n{\n\tu32 s = readl(reg);\n\n\treturn (s == state);\n}\n\nstatic void qtnf_set_state(__le32 __iomem *reg, u32 state)\n{\n\tqtnf_non_posted_write(state, reg);\n}\n\nstatic int qtnf_poll_state(__le32 __iomem *reg, u32 state, u32 delay_in_ms)\n{\n\tu32 timeout = 0;\n\n\twhile ((qtnf_is_state(reg, state) == 0)) {\n\t\tusleep_range(1000, 1200);\n\t\tif (++timeout > delay_in_ms)\n\t\t\treturn -1;\n\t}\n\n\treturn 0;\n}\n\nstatic int topaz_alloc_bd_table(struct qtnf_pcie_topaz_state *ts,\n\t\t\t\tstruct qtnf_topaz_bda __iomem *bda)\n{\n\tstruct qtnf_extra_bd_params __iomem *extra_params;\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\tdma_addr_t paddr;\n\tvoid *vaddr;\n\tint len;\n\tint i;\n\n\t \n\n\tlen = priv->tx_bd_num * sizeof(struct qtnf_topaz_tx_bd) +\n\t\tpriv->rx_bd_num * sizeof(struct qtnf_topaz_rx_bd) +\n\t\t\tsizeof(struct qtnf_extra_bd_params);\n\n\tvaddr = dmam_alloc_coherent(&priv->pdev->dev, len, &paddr, GFP_KERNEL);\n\tif (!vaddr)\n\t\treturn -ENOMEM;\n\n\t \n\n\tts->tx_bd_vbase = vaddr;\n\tqtnf_non_posted_write(paddr, &bda->bda_rc_tx_bd_base);\n\n\tfor (i = 0; i < priv->tx_bd_num; i++)\n\t\tts->tx_bd_vbase[i].info |= cpu_to_le32(QTN_BD_EMPTY);\n\n\tpr_debug(\"TX descriptor table: vaddr=0x%p paddr=%pad\\n\", vaddr, &paddr);\n\n\tpriv->tx_bd_r_index = 0;\n\tpriv->tx_bd_w_index = 0;\n\n\t \n\n\tvaddr = ((struct qtnf_topaz_tx_bd *)vaddr) + priv->tx_bd_num;\n\tpaddr += priv->tx_bd_num * sizeof(struct qtnf_topaz_tx_bd);\n\n\tts->rx_bd_vbase = vaddr;\n\tqtnf_non_posted_write(paddr, &bda->bda_rc_rx_bd_base);\n\n\tpr_debug(\"RX descriptor table: vaddr=0x%p paddr=%pad\\n\", vaddr, &paddr);\n\n\t \n\n\tvaddr = ((struct qtnf_topaz_rx_bd *)vaddr) + priv->rx_bd_num;\n\tpaddr += priv->rx_bd_num * sizeof(struct qtnf_topaz_rx_bd);\n\n\textra_params = (struct qtnf_extra_bd_params __iomem *)vaddr;\n\n\tts->ep_next_rx_pkt = &extra_params->param1;\n\tqtnf_non_posted_write(paddr + QTNF_BD_PARAM_OFFSET(1),\n\t\t\t      &bda->bda_ep_next_pkt);\n\tts->txqueue_wake = &extra_params->param2;\n\tts->ep_pmstate = &extra_params->param3;\n\tts->dma_msi_dummy = paddr + QTNF_BD_PARAM_OFFSET(4);\n\n\treturn 0;\n}\n\nstatic int\ntopaz_skb2rbd_attach(struct qtnf_pcie_topaz_state *ts, u16 index, u32 wrap)\n{\n\tstruct qtnf_topaz_rx_bd *rxbd = &ts->rx_bd_vbase[index];\n\tstruct sk_buff *skb;\n\tdma_addr_t paddr;\n\n\tskb = netdev_alloc_skb_ip_align(NULL, SKB_BUF_SIZE);\n\tif (!skb) {\n\t\tts->base.rx_skb[index] = NULL;\n\t\treturn -ENOMEM;\n\t}\n\n\tts->base.rx_skb[index] = skb;\n\n\tpaddr = dma_map_single(&ts->base.pdev->dev, skb->data, SKB_BUF_SIZE,\n\t\t\t       DMA_FROM_DEVICE);\n\tif (dma_mapping_error(&ts->base.pdev->dev, paddr)) {\n\t\tpr_err(\"skb mapping error: %pad\\n\", &paddr);\n\t\treturn -ENOMEM;\n\t}\n\n\trxbd->addr = cpu_to_le32(QTN_HOST_LO32(paddr));\n\trxbd->info = cpu_to_le32(QTN_BD_EMPTY | wrap);\n\n\tts->base.rx_bd_w_index = index;\n\n\treturn 0;\n}\n\nstatic int topaz_alloc_rx_buffers(struct qtnf_pcie_topaz_state *ts)\n{\n\tu16 i;\n\tint ret = 0;\n\n\tmemset(ts->rx_bd_vbase, 0x0,\n\t       ts->base.rx_bd_num * sizeof(struct qtnf_topaz_rx_bd));\n\n\tfor (i = 0; i < ts->base.rx_bd_num; i++) {\n\t\tret = topaz_skb2rbd_attach(ts, i, 0);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tts->rx_bd_vbase[ts->base.rx_bd_num - 1].info |=\n\t\t\t\t\t\tcpu_to_le32(QTN_BD_WRAP);\n\n\treturn ret;\n}\n\n \nstatic void qtnf_topaz_free_xfer_buffers(struct qtnf_pcie_topaz_state *ts)\n{\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\tstruct qtnf_topaz_rx_bd *rxbd;\n\tstruct qtnf_topaz_tx_bd *txbd;\n\tstruct sk_buff *skb;\n\tdma_addr_t paddr;\n\tint i;\n\n\t \n\tfor (i = 0; i < priv->rx_bd_num; i++) {\n\t\tif (priv->rx_skb && priv->rx_skb[i]) {\n\t\t\trxbd = &ts->rx_bd_vbase[i];\n\t\t\tskb = priv->rx_skb[i];\n\t\t\tpaddr = QTN_HOST_ADDR(0x0, le32_to_cpu(rxbd->addr));\n\t\t\tdma_unmap_single(&priv->pdev->dev, paddr,\n\t\t\t\t\t SKB_BUF_SIZE, DMA_FROM_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tpriv->rx_skb[i] = NULL;\n\t\t\trxbd->addr = 0;\n\t\t\trxbd->info = 0;\n\t\t}\n\t}\n\n\t \n\tfor (i = 0; i < priv->tx_bd_num; i++) {\n\t\tif (priv->tx_skb && priv->tx_skb[i]) {\n\t\t\ttxbd = &ts->tx_bd_vbase[i];\n\t\t\tskb = priv->tx_skb[i];\n\t\t\tpaddr = QTN_HOST_ADDR(0x0, le32_to_cpu(txbd->addr));\n\t\t\tdma_unmap_single(&priv->pdev->dev, paddr,\n\t\t\t\t\t SKB_BUF_SIZE, DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tpriv->tx_skb[i] = NULL;\n\t\t\ttxbd->addr = 0;\n\t\t\ttxbd->info = 0;\n\t\t}\n\t}\n}\n\nstatic int qtnf_pcie_topaz_init_xfer(struct qtnf_pcie_topaz_state *ts,\n\t\t\t\t     unsigned int tx_bd_size,\n\t\t\t\t     unsigned int rx_bd_size)\n{\n\tstruct qtnf_topaz_bda __iomem *bda = ts->bda;\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\tint ret;\n\n\tif (tx_bd_size == 0)\n\t\ttx_bd_size = TOPAZ_TX_BD_SIZE_DEFAULT;\n\n\t \n\tif (tx_bd_size > QTN_PCIE_RC_TX_QUEUE_LEN) {\n\t\tpr_warn(\"TX BD queue cannot exceed %d\\n\",\n\t\t\tQTN_PCIE_RC_TX_QUEUE_LEN);\n\t\ttx_bd_size = QTN_PCIE_RC_TX_QUEUE_LEN;\n\t}\n\n\tpriv->tx_bd_num = tx_bd_size;\n\tqtnf_non_posted_write(priv->tx_bd_num, &bda->bda_rc_tx_bd_num);\n\n\tif (rx_bd_size == 0)\n\t\trx_bd_size = TOPAZ_RX_BD_SIZE_DEFAULT;\n\n\tif (rx_bd_size > TOPAZ_RX_BD_SIZE_DEFAULT) {\n\t\tpr_warn(\"RX BD queue cannot exceed %d\\n\",\n\t\t\tTOPAZ_RX_BD_SIZE_DEFAULT);\n\t\trx_bd_size = TOPAZ_RX_BD_SIZE_DEFAULT;\n\t}\n\n\tpriv->rx_bd_num = rx_bd_size;\n\tqtnf_non_posted_write(priv->rx_bd_num, &bda->bda_rc_rx_bd_num);\n\n\tpriv->rx_bd_w_index = 0;\n\tpriv->rx_bd_r_index = 0;\n\n\tret = qtnf_pcie_alloc_skb_array(priv);\n\tif (ret) {\n\t\tpr_err(\"failed to allocate skb array\\n\");\n\t\treturn ret;\n\t}\n\n\tret = topaz_alloc_bd_table(ts, bda);\n\tif (ret) {\n\t\tpr_err(\"failed to allocate bd table\\n\");\n\t\treturn ret;\n\t}\n\n\tret = topaz_alloc_rx_buffers(ts);\n\tif (ret) {\n\t\tpr_err(\"failed to allocate rx buffers\\n\");\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic void qtnf_topaz_data_tx_reclaim(struct qtnf_pcie_topaz_state *ts)\n{\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\tstruct qtnf_topaz_tx_bd *txbd;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\tdma_addr_t paddr;\n\tu32 tx_done_index;\n\tint count = 0;\n\tint i;\n\n\tspin_lock_irqsave(&priv->tx_reclaim_lock, flags);\n\n\ttx_done_index = readl(ts->ep_next_rx_pkt);\n\ti = priv->tx_bd_r_index;\n\n\tif (CIRC_CNT(priv->tx_bd_w_index, tx_done_index, priv->tx_bd_num))\n\t\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_TX_DONE_IRQ),\n\t\t       TOPAZ_LH_IPC4_INT(priv->sysctl_bar));\n\n\twhile (CIRC_CNT(tx_done_index, i, priv->tx_bd_num)) {\n\t\tskb = priv->tx_skb[i];\n\n\t\tif (likely(skb)) {\n\t\t\ttxbd = &ts->tx_bd_vbase[i];\n\t\t\tpaddr = QTN_HOST_ADDR(0x0, le32_to_cpu(txbd->addr));\n\t\t\tdma_unmap_single(&priv->pdev->dev, paddr, skb->len,\n\t\t\t\t\t DMA_TO_DEVICE);\n\n\t\t\tif (skb->dev) {\n\t\t\t\tdev_sw_netstats_tx_add(skb->dev, 1, skb->len);\n\t\t\t\tif (unlikely(priv->tx_stopped)) {\n\t\t\t\t\tqtnf_wake_all_queues(skb->dev);\n\t\t\t\t\tpriv->tx_stopped = 0;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdev_kfree_skb_any(skb);\n\t\t}\n\n\t\tpriv->tx_skb[i] = NULL;\n\t\tcount++;\n\n\t\tif (++i >= priv->tx_bd_num)\n\t\t\ti = 0;\n\t}\n\n\tpriv->tx_reclaim_done += count;\n\tpriv->tx_reclaim_req++;\n\tpriv->tx_bd_r_index = i;\n\n\tspin_unlock_irqrestore(&priv->tx_reclaim_lock, flags);\n}\n\nstatic void qtnf_try_stop_xmit(struct qtnf_bus *bus, struct net_device *ndev)\n{\n\tstruct qtnf_pcie_topaz_state *ts = (void *)get_bus_priv(bus);\n\n\tif (ndev) {\n\t\tnetif_tx_stop_all_queues(ndev);\n\t\tts->base.tx_stopped = 1;\n\t}\n\n\twritel(0x0, ts->txqueue_wake);\n\n\t \n\tdma_wmb();\n\n\t \n\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_TX_STOP_IRQ),\n\t       TOPAZ_LH_IPC4_INT(ts->base.sysctl_bar));\n\n\t \n\ttasklet_hi_schedule(&ts->base.reclaim_tq);\n}\n\nstatic void qtnf_try_wake_xmit(struct qtnf_bus *bus, struct net_device *ndev)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\tint ready;\n\n\tready = readl(ts->txqueue_wake);\n\tif (ready) {\n\t\tnetif_wake_queue(ndev);\n\t} else {\n\t\t \n\t\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_TX_STOP_IRQ),\n\t\t       TOPAZ_LH_IPC4_INT(ts->base.sysctl_bar));\n\t}\n}\n\nstatic int qtnf_tx_queue_ready(struct qtnf_pcie_topaz_state *ts)\n{\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\n\tif (!CIRC_SPACE(priv->tx_bd_w_index, priv->tx_bd_r_index,\n\t\t\tpriv->tx_bd_num)) {\n\t\tqtnf_topaz_data_tx_reclaim(ts);\n\n\t\tif (!CIRC_SPACE(priv->tx_bd_w_index, priv->tx_bd_r_index,\n\t\t\t\tpriv->tx_bd_num)) {\n\t\t\tpriv->tx_full_count++;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn 1;\n}\n\nstatic int qtnf_pcie_data_tx(struct qtnf_bus *bus, struct sk_buff *skb,\n\t\t\t     unsigned int macid, unsigned int vifid)\n{\n\tstruct qtnf_pcie_topaz_state *ts = (void *)get_bus_priv(bus);\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\tstruct qtnf_topaz_bda __iomem *bda = ts->bda;\n\tstruct qtnf_topaz_tx_bd *txbd;\n\tdma_addr_t skb_paddr;\n\tunsigned long flags;\n\tint ret = 0;\n\tint len;\n\tint i;\n\n\tspin_lock_irqsave(&priv->tx_lock, flags);\n\n\tif (!qtnf_tx_queue_ready(ts)) {\n\t\tqtnf_try_stop_xmit(bus, skb->dev);\n\t\tspin_unlock_irqrestore(&priv->tx_lock, flags);\n\t\treturn NETDEV_TX_BUSY;\n\t}\n\n\ti = priv->tx_bd_w_index;\n\tpriv->tx_skb[i] = skb;\n\tlen = skb->len;\n\n\tskb_paddr = dma_map_single(&priv->pdev->dev, skb->data, skb->len,\n\t\t\t\t   DMA_TO_DEVICE);\n\tif (dma_mapping_error(&priv->pdev->dev, skb_paddr)) {\n\t\tret = -ENOMEM;\n\t\tgoto tx_done;\n\t}\n\n\ttxbd = &ts->tx_bd_vbase[i];\n\ttxbd->addr = cpu_to_le32(QTN_HOST_LO32(skb_paddr));\n\n\twritel(QTN_HOST_LO32(skb_paddr), &bda->request[i].addr);\n\twritel(len | QTN_PCIE_TX_VALID_PKT, &bda->request[i].info);\n\n\t \n\tdma_wmb();\n\n\t \n\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_TX_DONE_IRQ),\n\t       TOPAZ_LH_IPC4_INT(priv->sysctl_bar));\n\n\tif (++i >= priv->tx_bd_num)\n\t\ti = 0;\n\n\tpriv->tx_bd_w_index = i;\n\ntx_done:\n\tif (ret) {\n\t\tif (skb->dev)\n\t\t\tskb->dev->stats.tx_dropped++;\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\tpriv->tx_done_count++;\n\tspin_unlock_irqrestore(&priv->tx_lock, flags);\n\n\tqtnf_topaz_data_tx_reclaim(ts);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic irqreturn_t qtnf_pcie_topaz_interrupt(int irq, void *data)\n{\n\tstruct qtnf_bus *bus = (struct qtnf_bus *)data;\n\tstruct qtnf_pcie_topaz_state *ts = (void *)get_bus_priv(bus);\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\n\tif (!priv->msi_enabled && !qtnf_topaz_intx_asserted(ts))\n\t\treturn IRQ_NONE;\n\n\tif (!priv->msi_enabled)\n\t\tqtnf_deassert_intx(ts);\n\n\tpriv->pcie_irq_count++;\n\n\tqtnf_shm_ipc_irq_handler(&priv->shm_ipc_ep_in);\n\tqtnf_shm_ipc_irq_handler(&priv->shm_ipc_ep_out);\n\n\tif (napi_schedule_prep(&bus->mux_napi)) {\n\t\tdisable_rx_irqs(ts);\n\t\t__napi_schedule(&bus->mux_napi);\n\t}\n\n\ttasklet_hi_schedule(&priv->reclaim_tq);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int qtnf_rx_data_ready(struct qtnf_pcie_topaz_state *ts)\n{\n\tu16 index = ts->base.rx_bd_r_index;\n\tstruct qtnf_topaz_rx_bd *rxbd;\n\tu32 descw;\n\n\trxbd = &ts->rx_bd_vbase[index];\n\tdescw = le32_to_cpu(rxbd->info);\n\n\tif (descw & QTN_BD_EMPTY)\n\t\treturn 0;\n\n\treturn 1;\n}\n\nstatic int qtnf_topaz_rx_poll(struct napi_struct *napi, int budget)\n{\n\tstruct qtnf_bus *bus = container_of(napi, struct qtnf_bus, mux_napi);\n\tstruct qtnf_pcie_topaz_state *ts = (void *)get_bus_priv(bus);\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\tstruct net_device *ndev = NULL;\n\tstruct sk_buff *skb = NULL;\n\tint processed = 0;\n\tstruct qtnf_topaz_rx_bd *rxbd;\n\tdma_addr_t skb_paddr;\n\tint consume;\n\tu32 descw;\n\tu32 poffset;\n\tu32 psize;\n\tu16 r_idx;\n\tu16 w_idx;\n\tint ret;\n\n\twhile (processed < budget) {\n\t\tif (!qtnf_rx_data_ready(ts))\n\t\t\tgoto rx_out;\n\n\t\tr_idx = priv->rx_bd_r_index;\n\t\trxbd = &ts->rx_bd_vbase[r_idx];\n\t\tdescw = le32_to_cpu(rxbd->info);\n\n\t\tskb = priv->rx_skb[r_idx];\n\t\tpoffset = QTN_GET_OFFSET(descw);\n\t\tpsize = QTN_GET_LEN(descw);\n\t\tconsume = 1;\n\n\t\tif (descw & QTN_BD_EMPTY) {\n\t\t\tpr_warn(\"skip invalid rxbd[%d]\\n\", r_idx);\n\t\t\tconsume = 0;\n\t\t}\n\n\t\tif (!skb) {\n\t\t\tpr_warn(\"skip missing rx_skb[%d]\\n\", r_idx);\n\t\t\tconsume = 0;\n\t\t}\n\n\t\tif (skb && (skb_tailroom(skb) <  psize)) {\n\t\t\tpr_err(\"skip packet with invalid length: %u > %u\\n\",\n\t\t\t       psize, skb_tailroom(skb));\n\t\t\tconsume = 0;\n\t\t}\n\n\t\tif (skb) {\n\t\t\tskb_paddr = QTN_HOST_ADDR(0x0, le32_to_cpu(rxbd->addr));\n\t\t\tdma_unmap_single(&priv->pdev->dev, skb_paddr,\n\t\t\t\t\t SKB_BUF_SIZE, DMA_FROM_DEVICE);\n\t\t}\n\n\t\tif (consume) {\n\t\t\tskb_reserve(skb, poffset);\n\t\t\tskb_put(skb, psize);\n\t\t\tndev = qtnf_classify_skb(bus, skb);\n\t\t\tif (likely(ndev)) {\n\t\t\t\tdev_sw_netstats_rx_add(ndev, skb->len);\n\t\t\t\tskb->protocol = eth_type_trans(skb, ndev);\n\t\t\t\tnetif_receive_skb(skb);\n\t\t\t} else {\n\t\t\t\tpr_debug(\"drop untagged skb\\n\");\n\t\t\t\tbus->mux_dev.stats.rx_dropped++;\n\t\t\t\tdev_kfree_skb_any(skb);\n\t\t\t}\n\t\t} else {\n\t\t\tif (skb) {\n\t\t\t\tbus->mux_dev.stats.rx_dropped++;\n\t\t\t\tdev_kfree_skb_any(skb);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (((++ts->rx_pkt_count) & RX_DONE_INTR_MSK) == 0)\n\t\t\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_RX_DONE_IRQ),\n\t\t\t       TOPAZ_LH_IPC4_INT(priv->sysctl_bar));\n\n\t\tpriv->rx_skb[r_idx] = NULL;\n\t\tif (++r_idx >= priv->rx_bd_num)\n\t\t\tr_idx = 0;\n\n\t\tpriv->rx_bd_r_index = r_idx;\n\n\t\t \n\t\tw_idx = priv->rx_bd_w_index;\n\t\twhile (CIRC_SPACE(priv->rx_bd_w_index, priv->rx_bd_r_index,\n\t\t\t\t  priv->rx_bd_num) > 0) {\n\t\t\tif (++w_idx >= priv->rx_bd_num)\n\t\t\t\tw_idx = 0;\n\n\t\t\tret = topaz_skb2rbd_attach(ts, w_idx,\n\t\t\t\t\t\t   descw & QTN_BD_WRAP);\n\t\t\tif (ret) {\n\t\t\t\tpr_err(\"failed to allocate new rx_skb[%d]\\n\",\n\t\t\t\t       w_idx);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tprocessed++;\n\t}\n\nrx_out:\n\tif (processed < budget) {\n\t\tnapi_complete(napi);\n\t\tenable_rx_irqs(ts);\n\t}\n\n\treturn processed;\n}\n\nstatic void\nqtnf_pcie_data_tx_timeout(struct qtnf_bus *bus, struct net_device *ndev)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\n\tqtnf_try_wake_xmit(bus, ndev);\n\ttasklet_hi_schedule(&ts->base.reclaim_tq);\n}\n\nstatic void qtnf_pcie_data_rx_start(struct qtnf_bus *bus)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\n\tnapi_enable(&bus->mux_napi);\n\tenable_rx_irqs(ts);\n}\n\nstatic void qtnf_pcie_data_rx_stop(struct qtnf_bus *bus)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\n\tdisable_rx_irqs(ts);\n\tnapi_disable(&bus->mux_napi);\n}\n\nstatic struct qtnf_bus_ops qtnf_pcie_topaz_bus_ops = {\n\t \n\t.control_tx\t= qtnf_pcie_control_tx,\n\n\t \n\t.data_tx\t\t= qtnf_pcie_data_tx,\n\t.data_tx_timeout\t= qtnf_pcie_data_tx_timeout,\n\t.data_rx_start\t\t= qtnf_pcie_data_rx_start,\n\t.data_rx_stop\t\t= qtnf_pcie_data_rx_stop,\n};\n\nstatic int qtnf_dbg_irq_stats(struct seq_file *s, void *data)\n{\n\tstruct qtnf_bus *bus = dev_get_drvdata(s->private);\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\n\tseq_printf(s, \"pcie_irq_count(%u)\\n\", ts->base.pcie_irq_count);\n\n\treturn 0;\n}\n\nstatic int qtnf_dbg_pkt_stats(struct seq_file *s, void *data)\n{\n\tstruct qtnf_bus *bus = dev_get_drvdata(s->private);\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\tstruct qtnf_pcie_bus_priv *priv = &ts->base;\n\tu32 tx_done_index = readl(ts->ep_next_rx_pkt);\n\n\tseq_printf(s, \"tx_full_count(%u)\\n\", priv->tx_full_count);\n\tseq_printf(s, \"tx_done_count(%u)\\n\", priv->tx_done_count);\n\tseq_printf(s, \"tx_reclaim_done(%u)\\n\", priv->tx_reclaim_done);\n\tseq_printf(s, \"tx_reclaim_req(%u)\\n\", priv->tx_reclaim_req);\n\n\tseq_printf(s, \"tx_bd_r_index(%u)\\n\", priv->tx_bd_r_index);\n\tseq_printf(s, \"tx_done_index(%u)\\n\", tx_done_index);\n\tseq_printf(s, \"tx_bd_w_index(%u)\\n\", priv->tx_bd_w_index);\n\n\tseq_printf(s, \"tx host queue len(%u)\\n\",\n\t\t   CIRC_CNT(priv->tx_bd_w_index, priv->tx_bd_r_index,\n\t\t\t    priv->tx_bd_num));\n\tseq_printf(s, \"tx reclaim queue len(%u)\\n\",\n\t\t   CIRC_CNT(tx_done_index, priv->tx_bd_r_index,\n\t\t\t    priv->tx_bd_num));\n\tseq_printf(s, \"tx card queue len(%u)\\n\",\n\t\t   CIRC_CNT(priv->tx_bd_w_index, tx_done_index,\n\t\t\t    priv->tx_bd_num));\n\n\tseq_printf(s, \"rx_bd_r_index(%u)\\n\", priv->rx_bd_r_index);\n\tseq_printf(s, \"rx_bd_w_index(%u)\\n\", priv->rx_bd_w_index);\n\tseq_printf(s, \"rx alloc queue len(%u)\\n\",\n\t\t   CIRC_SPACE(priv->rx_bd_w_index, priv->rx_bd_r_index,\n\t\t\t      priv->rx_bd_num));\n\n\treturn 0;\n}\n\nstatic void qtnf_reset_dma_offset(struct qtnf_pcie_topaz_state *ts)\n{\n\tstruct qtnf_topaz_bda __iomem *bda = ts->bda;\n\tu32 offset = readl(&bda->bda_dma_offset);\n\n\tif ((offset & PCIE_DMA_OFFSET_ERROR_MASK) != PCIE_DMA_OFFSET_ERROR)\n\t\treturn;\n\n\twritel(0x0, &bda->bda_dma_offset);\n}\n\nstatic int qtnf_pcie_endian_detect(struct qtnf_pcie_topaz_state *ts)\n{\n\tstruct qtnf_topaz_bda __iomem *bda = ts->bda;\n\tu32 timeout = 0;\n\tu32 endian;\n\tint ret = 0;\n\n\twritel(QTN_PCI_ENDIAN_DETECT_DATA, &bda->bda_pci_endian);\n\n\t \n\tdma_wmb();\n\n\twritel(QTN_PCI_ENDIAN_VALID_STATUS, &bda->bda_pci_pre_status);\n\n\twhile (readl(&bda->bda_pci_post_status) !=\n\t       QTN_PCI_ENDIAN_VALID_STATUS) {\n\t\tusleep_range(1000, 1200);\n\t\tif (++timeout > QTN_FW_DL_TIMEOUT_MS) {\n\t\t\tpr_err(\"card endianness detection timed out\\n\");\n\t\t\tret = -ETIMEDOUT;\n\t\t\tgoto endian_out;\n\t\t}\n\t}\n\n\t \n\tdma_rmb();\n\n\tendian = readl(&bda->bda_pci_endian);\n\tWARN(endian != QTN_PCI_LITTLE_ENDIAN,\n\t     \"%s: unexpected card endianness\", __func__);\n\nendian_out:\n\twritel(0, &bda->bda_pci_pre_status);\n\twritel(0, &bda->bda_pci_post_status);\n\twritel(0, &bda->bda_pci_endian);\n\n\treturn ret;\n}\n\nstatic int qtnf_pre_init_ep(struct qtnf_bus *bus)\n{\n\tstruct qtnf_pcie_topaz_state *ts = (void *)get_bus_priv(bus);\n\tstruct qtnf_topaz_bda __iomem *bda = ts->bda;\n\tu32 flags;\n\tint ret;\n\n\tret = qtnf_pcie_endian_detect(ts);\n\tif (ret < 0) {\n\t\tpr_err(\"failed to detect card endianness\\n\");\n\t\treturn ret;\n\t}\n\n\twriteb(ts->base.msi_enabled, &ts->bda->bda_rc_msi_enabled);\n\tqtnf_reset_dma_offset(ts);\n\n\t \n\tflags = readl(&bda->bda_flags) | QTN_BDA_HOST_QLINK_DRV;\n\n\tif (ts->base.flashboot)\n\t\tflags |= QTN_BDA_FLASH_BOOT;\n\telse\n\t\tflags &= ~QTN_BDA_FLASH_BOOT;\n\n\twritel(flags, &bda->bda_flags);\n\n\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_HOST_RDY);\n\tif (qtnf_poll_state(&ts->bda->bda_bootstate, QTN_BDA_FW_TARGET_RDY,\n\t\t\t    QTN_FW_DL_TIMEOUT_MS)) {\n\t\tpr_err(\"card is not ready to boot...\\n\");\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn ret;\n}\n\nstatic int qtnf_post_init_ep(struct qtnf_pcie_topaz_state *ts)\n{\n\tstruct pci_dev *pdev = ts->base.pdev;\n\n\tsetup_rx_irqs(ts);\n\tdisable_rx_irqs(ts);\n\n\tif (qtnf_poll_state(&ts->bda->bda_bootstate, QTN_BDA_FW_QLINK_DONE,\n\t\t\t    QTN_FW_QLINK_TIMEOUT_MS))\n\t\treturn -ETIMEDOUT;\n\n\tenable_irq(pdev->irq);\n\treturn 0;\n}\n\nstatic int\nqtnf_ep_fw_load(struct qtnf_pcie_topaz_state *ts, const u8 *fw, u32 fw_size)\n{\n\tstruct qtnf_topaz_bda __iomem *bda = ts->bda;\n\tstruct pci_dev *pdev = ts->base.pdev;\n\tu32 remaining = fw_size;\n\tu8 *curr = (u8 *)fw;\n\tu32 blksize;\n\tu32 nblocks;\n\tu32 offset;\n\tu32 count;\n\tu32 size;\n\tdma_addr_t paddr;\n\tvoid *data;\n\tint ret = 0;\n\n\tpr_debug(\"FW upload started: fw_addr = 0x%p, size=%d\\n\", fw, fw_size);\n\n\tblksize = ts->base.fw_blksize;\n\n\tif (blksize < PAGE_SIZE)\n\t\tblksize = PAGE_SIZE;\n\n\twhile (blksize >= PAGE_SIZE) {\n\t\tpr_debug(\"allocating %u bytes to upload FW\\n\", blksize);\n\t\tdata = dma_alloc_coherent(&pdev->dev, blksize,\n\t\t\t\t\t  &paddr, GFP_KERNEL);\n\t\tif (data)\n\t\t\tbreak;\n\t\tblksize /= 2;\n\t}\n\n\tif (!data) {\n\t\tpr_err(\"failed to allocate DMA buffer for FW upload\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fw_load_out;\n\t}\n\n\tnblocks = NBLOCKS(fw_size, blksize);\n\toffset = readl(&bda->bda_dma_offset);\n\n\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_HOST_LOAD);\n\tif (qtnf_poll_state(&ts->bda->bda_bootstate, QTN_BDA_FW_EP_RDY,\n\t\t\t    QTN_FW_DL_TIMEOUT_MS)) {\n\t\tpr_err(\"card is not ready to download FW\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto fw_load_map;\n\t}\n\n\tfor (count = 0 ; count < nblocks; count++) {\n\t\tsize = (remaining > blksize) ? blksize : remaining;\n\n\t\tmemcpy(data, curr, size);\n\t\tqtnf_non_posted_write(paddr + offset, &bda->bda_img);\n\t\tqtnf_non_posted_write(size, &bda->bda_img_size);\n\n\t\tpr_debug(\"chunk[%u] VA[0x%p] PA[%pad] sz[%u]\\n\",\n\t\t\t count, (void *)curr, &paddr, size);\n\n\t\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_BLOCK_RDY);\n\t\tif (qtnf_poll_state(&ts->bda->bda_bootstate,\n\t\t\t\t    QTN_BDA_FW_BLOCK_DONE,\n\t\t\t\t    QTN_FW_DL_TIMEOUT_MS)) {\n\t\t\tpr_err(\"confirmation for block #%d timed out\\n\", count);\n\t\t\tret = -ETIMEDOUT;\n\t\t\tgoto fw_load_map;\n\t\t}\n\n\t\tremaining = (remaining < size) ? remaining : (remaining - size);\n\t\tcurr += size;\n\t}\n\n\t \n\tqtnf_non_posted_write(0, &bda->bda_img);\n\tqtnf_non_posted_write(0, &bda->bda_img_size);\n\n\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_BLOCK_RDY);\n\tif (qtnf_poll_state(&ts->bda->bda_bootstate, QTN_BDA_FW_BLOCK_DONE,\n\t\t\t    QTN_FW_DL_TIMEOUT_MS)) {\n\t\tpr_err(\"confirmation for the last block timed out\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto fw_load_map;\n\t}\n\n\t \n\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_BLOCK_END);\n\tif (qtnf_poll_state(&ts->bda->bda_bootstate, QTN_BDA_FW_LOAD_DONE,\n\t\t\t    QTN_FW_DL_TIMEOUT_MS)) {\n\t\tpr_err(\"confirmation for FW upload completion timed out\\n\");\n\t\tret = -ETIMEDOUT;\n\t\tgoto fw_load_map;\n\t}\n\n\tpr_debug(\"FW upload completed: totally sent %d blocks\\n\", count);\n\nfw_load_map:\n\tdma_free_coherent(&pdev->dev, blksize, data, paddr);\n\nfw_load_out:\n\treturn ret;\n}\n\nstatic int qtnf_topaz_fw_upload(struct qtnf_pcie_topaz_state *ts,\n\t\t\t\tconst char *fwname)\n{\n\tconst struct firmware *fw;\n\tstruct pci_dev *pdev = ts->base.pdev;\n\tint ret;\n\n\tif (qtnf_poll_state(&ts->bda->bda_bootstate,\n\t\t\t    QTN_BDA_FW_LOAD_RDY,\n\t\t\t    QTN_FW_DL_TIMEOUT_MS)) {\n\t\tpr_err(\"%s: card is not ready\\n\", fwname);\n\t\treturn -1;\n\t}\n\n\tpr_info(\"starting firmware upload: %s\\n\", fwname);\n\n\tret = request_firmware(&fw, fwname, &pdev->dev);\n\tif (ret < 0) {\n\t\tpr_err(\"%s: request_firmware error %d\\n\", fwname, ret);\n\t\treturn -1;\n\t}\n\n\tret = qtnf_ep_fw_load(ts, fw->data, fw->size);\n\trelease_firmware(fw);\n\n\tif (ret)\n\t\tpr_err(\"%s: FW upload error\\n\", fwname);\n\n\treturn ret;\n}\n\nstatic void qtnf_topaz_fw_work_handler(struct work_struct *work)\n{\n\tstruct qtnf_bus *bus = container_of(work, struct qtnf_bus, fw_work);\n\tstruct qtnf_pcie_topaz_state *ts = (void *)get_bus_priv(bus);\n\tint bootloader_needed = readl(&ts->bda->bda_flags) & QTN_BDA_XMIT_UBOOT;\n\tstruct pci_dev *pdev = ts->base.pdev;\n\tint ret;\n\n\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_TARGET_BOOT);\n\n\tif (bootloader_needed) {\n\t\tret = qtnf_topaz_fw_upload(ts, QTN_PCI_TOPAZ_BOOTLD_NAME);\n\t\tif (ret)\n\t\t\tgoto fw_load_exit;\n\n\t\tret = qtnf_pre_init_ep(bus);\n\t\tif (ret)\n\t\t\tgoto fw_load_exit;\n\n\t\tqtnf_set_state(&ts->bda->bda_bootstate,\n\t\t\t       QTN_BDA_FW_TARGET_BOOT);\n\t}\n\n\tif (ts->base.flashboot) {\n\t\tpr_info(\"booting firmware from flash\\n\");\n\n\t\tret = qtnf_poll_state(&ts->bda->bda_bootstate,\n\t\t\t\t      QTN_BDA_FW_FLASH_BOOT,\n\t\t\t\t      QTN_FW_DL_TIMEOUT_MS);\n\t\tif (ret)\n\t\t\tgoto fw_load_exit;\n\t} else {\n\t\tret = qtnf_topaz_fw_upload(ts, QTN_PCI_TOPAZ_FW_NAME);\n\t\tif (ret)\n\t\t\tgoto fw_load_exit;\n\n\t\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_START);\n\t\tret = qtnf_poll_state(&ts->bda->bda_bootstate,\n\t\t\t\t      QTN_BDA_FW_CONFIG,\n\t\t\t\t      QTN_FW_QLINK_TIMEOUT_MS);\n\t\tif (ret) {\n\t\t\tpr_err(\"FW bringup timed out\\n\");\n\t\t\tgoto fw_load_exit;\n\t\t}\n\n\t\tqtnf_set_state(&ts->bda->bda_bootstate, QTN_BDA_FW_RUN);\n\t\tret = qtnf_poll_state(&ts->bda->bda_bootstate,\n\t\t\t\t      QTN_BDA_FW_RUNNING,\n\t\t\t\t      QTN_FW_QLINK_TIMEOUT_MS);\n\t\tif (ret) {\n\t\t\tpr_err(\"card bringup timed out\\n\");\n\t\t\tgoto fw_load_exit;\n\t\t}\n\t}\n\n\tret = qtnf_post_init_ep(ts);\n\tif (ret) {\n\t\tpr_err(\"FW runtime failure\\n\");\n\t\tgoto fw_load_exit;\n\t}\n\n\tpr_info(\"firmware is up and running\\n\");\n\n\tret = qtnf_pcie_fw_boot_done(bus);\n\tif (ret)\n\t\tgoto fw_load_exit;\n\n\tqtnf_debugfs_add_entry(bus, \"pkt_stats\", qtnf_dbg_pkt_stats);\n\tqtnf_debugfs_add_entry(bus, \"irq_stats\", qtnf_dbg_irq_stats);\n\nfw_load_exit:\n\tput_device(&pdev->dev);\n}\n\nstatic void qtnf_reclaim_tasklet_fn(struct tasklet_struct *t)\n{\n\tstruct qtnf_pcie_topaz_state *ts = from_tasklet(ts, t, base.reclaim_tq);\n\n\tqtnf_topaz_data_tx_reclaim(ts);\n}\n\nstatic u64 qtnf_topaz_dma_mask_get(void)\n{\n\treturn DMA_BIT_MASK(32);\n}\n\nstatic int qtnf_pcie_topaz_probe(struct qtnf_bus *bus,\n\t\t\t\t unsigned int tx_bd_num, unsigned int rx_bd_num)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\tstruct pci_dev *pdev = ts->base.pdev;\n\tstruct qtnf_shm_ipc_int ipc_int;\n\tunsigned long irqflags;\n\tint ret;\n\n\tbus->bus_ops = &qtnf_pcie_topaz_bus_ops;\n\tINIT_WORK(&bus->fw_work, qtnf_topaz_fw_work_handler);\n\tts->bda = ts->base.epmem_bar;\n\n\t \n\tif (ts->base.msi_enabled)\n\t\tirqflags = IRQF_NOBALANCING;\n\telse\n\t\tirqflags = IRQF_NOBALANCING | IRQF_SHARED;\n\n\tret = devm_request_irq(&pdev->dev, pdev->irq,\n\t\t\t       &qtnf_pcie_topaz_interrupt,\n\t\t\t       irqflags, \"qtnf_topaz_irq\", (void *)bus);\n\tif (ret) {\n\t\tpr_err(\"failed to request pcie irq %d\\n\", pdev->irq);\n\t\treturn ret;\n\t}\n\n\tdisable_irq(pdev->irq);\n\n\tret = qtnf_pre_init_ep(bus);\n\tif (ret) {\n\t\tpr_err(\"failed to init card\\n\");\n\t\treturn ret;\n\t}\n\n\tret = qtnf_pcie_topaz_init_xfer(ts, tx_bd_num, rx_bd_num);\n\tif (ret) {\n\t\tpr_err(\"PCIE xfer init failed\\n\");\n\t\treturn ret;\n\t}\n\n\ttasklet_setup(&ts->base.reclaim_tq, qtnf_reclaim_tasklet_fn);\n\tnetif_napi_add_weight(&bus->mux_dev, &bus->mux_napi,\n\t\t\t      qtnf_topaz_rx_poll, 10);\n\n\tipc_int.fn = qtnf_topaz_ipc_gen_ep_int;\n\tipc_int.arg = ts;\n\tqtnf_pcie_init_shm_ipc(&ts->base, &ts->bda->bda_shm_reg1,\n\t\t\t       &ts->bda->bda_shm_reg2, &ipc_int);\n\n\treturn 0;\n}\n\nstatic void qtnf_pcie_topaz_remove(struct qtnf_bus *bus)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\n\tqtnf_topaz_reset_ep(ts);\n\tqtnf_topaz_free_xfer_buffers(ts);\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic int qtnf_pcie_topaz_suspend(struct qtnf_bus *bus)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\tstruct pci_dev *pdev = ts->base.pdev;\n\n\twritel((u32 __force)PCI_D3hot, ts->ep_pmstate);\n\tdma_wmb();\n\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_PM_EP_IRQ),\n\t       TOPAZ_LH_IPC4_INT(ts->base.sysctl_bar));\n\n\tpci_save_state(pdev);\n\tpci_enable_wake(pdev, PCI_D3hot, 1);\n\tpci_set_power_state(pdev, PCI_D3hot);\n\n\treturn 0;\n}\n\nstatic int qtnf_pcie_topaz_resume(struct qtnf_bus *bus)\n{\n\tstruct qtnf_pcie_topaz_state *ts = get_bus_priv(bus);\n\tstruct pci_dev *pdev = ts->base.pdev;\n\n\tpci_set_power_state(pdev, PCI_D0);\n\tpci_restore_state(pdev);\n\tpci_enable_wake(pdev, PCI_D0, 0);\n\n\twritel((u32 __force)PCI_D0, ts->ep_pmstate);\n\tdma_wmb();\n\twritel(TOPAZ_IPC_IRQ_WORD(TOPAZ_RC_PM_EP_IRQ),\n\t       TOPAZ_LH_IPC4_INT(ts->base.sysctl_bar));\n\n\treturn 0;\n}\n#endif\n\nstruct qtnf_bus *qtnf_pcie_topaz_alloc(struct pci_dev *pdev)\n{\n\tstruct qtnf_bus *bus;\n\tstruct qtnf_pcie_topaz_state *ts;\n\n\tbus = devm_kzalloc(&pdev->dev, sizeof(*bus) + sizeof(*ts), GFP_KERNEL);\n\tif (!bus)\n\t\treturn NULL;\n\n\tts = get_bus_priv(bus);\n\tts->base.probe_cb = qtnf_pcie_topaz_probe;\n\tts->base.remove_cb = qtnf_pcie_topaz_remove;\n\tts->base.dma_mask_get_cb = qtnf_topaz_dma_mask_get;\n#ifdef CONFIG_PM_SLEEP\n\tts->base.resume_cb = qtnf_pcie_topaz_resume;\n\tts->base.suspend_cb = qtnf_pcie_topaz_suspend;\n#endif\n\n\treturn bus;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}