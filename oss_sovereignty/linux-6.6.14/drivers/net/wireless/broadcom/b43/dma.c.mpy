{
  "module_name": "dma.c",
  "hash_id": "d10f20ae3e5d691e39d0457324c4f3f611c932245d8a1ace7ed143e0a3d48e27",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/broadcom/b43/dma.c",
  "human_readable_source": "\n \n\n#include \"b43.h\"\n#include \"dma.h\"\n#include \"main.h\"\n#include \"debugfs.h\"\n#include \"xmit.h\"\n\n#include <linux/dma-mapping.h>\n#include <linux/pci.h>\n#include <linux/delay.h>\n#include <linux/skbuff.h>\n#include <linux/etherdevice.h>\n#include <linux/slab.h>\n#include <asm/div64.h>\n\n\n \n#define TX_SLOTS_PER_FRAME\t2\n\nstatic u32 b43_dma_address(struct b43_dma *dma, dma_addr_t dmaaddr,\n\t\t\t   enum b43_addrtype addrtype)\n{\n\tu32 addr;\n\n\tswitch (addrtype) {\n\tcase B43_DMA_ADDR_LOW:\n\t\taddr = lower_32_bits(dmaaddr);\n\t\tif (dma->translation_in_low) {\n\t\t\taddr &= ~SSB_DMA_TRANSLATION_MASK;\n\t\t\taddr |= dma->translation;\n\t\t}\n\t\tbreak;\n\tcase B43_DMA_ADDR_HIGH:\n\t\taddr = upper_32_bits(dmaaddr);\n\t\tif (!dma->translation_in_low) {\n\t\t\taddr &= ~SSB_DMA_TRANSLATION_MASK;\n\t\t\taddr |= dma->translation;\n\t\t}\n\t\tbreak;\n\tcase B43_DMA_ADDR_EXT:\n\t\tif (dma->translation_in_low)\n\t\t\taddr = lower_32_bits(dmaaddr);\n\t\telse\n\t\t\taddr = upper_32_bits(dmaaddr);\n\t\taddr &= SSB_DMA_TRANSLATION_MASK;\n\t\taddr >>= SSB_DMA_TRANSLATION_SHIFT;\n\t\tbreak;\n\t}\n\n\treturn addr;\n}\n\n \nstatic\nstruct b43_dmadesc_generic *op32_idx2desc(struct b43_dmaring *ring,\n\t\t\t\t\t  int slot,\n\t\t\t\t\t  struct b43_dmadesc_meta **meta)\n{\n\tstruct b43_dmadesc32 *desc;\n\n\t*meta = &(ring->meta[slot]);\n\tdesc = ring->descbase;\n\tdesc = &(desc[slot]);\n\n\treturn (struct b43_dmadesc_generic *)desc;\n}\n\nstatic void op32_fill_descriptor(struct b43_dmaring *ring,\n\t\t\t\t struct b43_dmadesc_generic *desc,\n\t\t\t\t dma_addr_t dmaaddr, u16 bufsize,\n\t\t\t\t int start, int end, int irq)\n{\n\tstruct b43_dmadesc32 *descbase = ring->descbase;\n\tint slot;\n\tu32 ctl;\n\tu32 addr;\n\tu32 addrext;\n\n\tslot = (int)(&(desc->dma32) - descbase);\n\tB43_WARN_ON(!(slot >= 0 && slot < ring->nr_slots));\n\n\taddr = b43_dma_address(&ring->dev->dma, dmaaddr, B43_DMA_ADDR_LOW);\n\taddrext = b43_dma_address(&ring->dev->dma, dmaaddr, B43_DMA_ADDR_EXT);\n\n\tctl = bufsize & B43_DMA32_DCTL_BYTECNT;\n\tif (slot == ring->nr_slots - 1)\n\t\tctl |= B43_DMA32_DCTL_DTABLEEND;\n\tif (start)\n\t\tctl |= B43_DMA32_DCTL_FRAMESTART;\n\tif (end)\n\t\tctl |= B43_DMA32_DCTL_FRAMEEND;\n\tif (irq)\n\t\tctl |= B43_DMA32_DCTL_IRQ;\n\tctl |= (addrext << B43_DMA32_DCTL_ADDREXT_SHIFT)\n\t    & B43_DMA32_DCTL_ADDREXT_MASK;\n\n\tdesc->dma32.control = cpu_to_le32(ctl);\n\tdesc->dma32.address = cpu_to_le32(addr);\n}\n\nstatic void op32_poke_tx(struct b43_dmaring *ring, int slot)\n{\n\tb43_dma_write(ring, B43_DMA32_TXINDEX,\n\t\t      (u32) (slot * sizeof(struct b43_dmadesc32)));\n}\n\nstatic void op32_tx_suspend(struct b43_dmaring *ring)\n{\n\tb43_dma_write(ring, B43_DMA32_TXCTL, b43_dma_read(ring, B43_DMA32_TXCTL)\n\t\t      | B43_DMA32_TXSUSPEND);\n}\n\nstatic void op32_tx_resume(struct b43_dmaring *ring)\n{\n\tb43_dma_write(ring, B43_DMA32_TXCTL, b43_dma_read(ring, B43_DMA32_TXCTL)\n\t\t      & ~B43_DMA32_TXSUSPEND);\n}\n\nstatic int op32_get_current_rxslot(struct b43_dmaring *ring)\n{\n\tu32 val;\n\n\tval = b43_dma_read(ring, B43_DMA32_RXSTATUS);\n\tval &= B43_DMA32_RXDPTR;\n\n\treturn (val / sizeof(struct b43_dmadesc32));\n}\n\nstatic void op32_set_current_rxslot(struct b43_dmaring *ring, int slot)\n{\n\tb43_dma_write(ring, B43_DMA32_RXINDEX,\n\t\t      (u32) (slot * sizeof(struct b43_dmadesc32)));\n}\n\nstatic const struct b43_dma_ops dma32_ops = {\n\t.idx2desc = op32_idx2desc,\n\t.fill_descriptor = op32_fill_descriptor,\n\t.poke_tx = op32_poke_tx,\n\t.tx_suspend = op32_tx_suspend,\n\t.tx_resume = op32_tx_resume,\n\t.get_current_rxslot = op32_get_current_rxslot,\n\t.set_current_rxslot = op32_set_current_rxslot,\n};\n\n \nstatic\nstruct b43_dmadesc_generic *op64_idx2desc(struct b43_dmaring *ring,\n\t\t\t\t\t  int slot,\n\t\t\t\t\t  struct b43_dmadesc_meta **meta)\n{\n\tstruct b43_dmadesc64 *desc;\n\n\t*meta = &(ring->meta[slot]);\n\tdesc = ring->descbase;\n\tdesc = &(desc[slot]);\n\n\treturn (struct b43_dmadesc_generic *)desc;\n}\n\nstatic void op64_fill_descriptor(struct b43_dmaring *ring,\n\t\t\t\t struct b43_dmadesc_generic *desc,\n\t\t\t\t dma_addr_t dmaaddr, u16 bufsize,\n\t\t\t\t int start, int end, int irq)\n{\n\tstruct b43_dmadesc64 *descbase = ring->descbase;\n\tint slot;\n\tu32 ctl0 = 0, ctl1 = 0;\n\tu32 addrlo, addrhi;\n\tu32 addrext;\n\n\tslot = (int)(&(desc->dma64) - descbase);\n\tB43_WARN_ON(!(slot >= 0 && slot < ring->nr_slots));\n\n\taddrlo = b43_dma_address(&ring->dev->dma, dmaaddr, B43_DMA_ADDR_LOW);\n\taddrhi = b43_dma_address(&ring->dev->dma, dmaaddr, B43_DMA_ADDR_HIGH);\n\taddrext = b43_dma_address(&ring->dev->dma, dmaaddr, B43_DMA_ADDR_EXT);\n\n\tif (slot == ring->nr_slots - 1)\n\t\tctl0 |= B43_DMA64_DCTL0_DTABLEEND;\n\tif (start)\n\t\tctl0 |= B43_DMA64_DCTL0_FRAMESTART;\n\tif (end)\n\t\tctl0 |= B43_DMA64_DCTL0_FRAMEEND;\n\tif (irq)\n\t\tctl0 |= B43_DMA64_DCTL0_IRQ;\n\tctl1 |= bufsize & B43_DMA64_DCTL1_BYTECNT;\n\tctl1 |= (addrext << B43_DMA64_DCTL1_ADDREXT_SHIFT)\n\t    & B43_DMA64_DCTL1_ADDREXT_MASK;\n\n\tdesc->dma64.control0 = cpu_to_le32(ctl0);\n\tdesc->dma64.control1 = cpu_to_le32(ctl1);\n\tdesc->dma64.address_low = cpu_to_le32(addrlo);\n\tdesc->dma64.address_high = cpu_to_le32(addrhi);\n}\n\nstatic void op64_poke_tx(struct b43_dmaring *ring, int slot)\n{\n\tb43_dma_write(ring, B43_DMA64_TXINDEX,\n\t\t      (u32) (slot * sizeof(struct b43_dmadesc64)));\n}\n\nstatic void op64_tx_suspend(struct b43_dmaring *ring)\n{\n\tb43_dma_write(ring, B43_DMA64_TXCTL, b43_dma_read(ring, B43_DMA64_TXCTL)\n\t\t      | B43_DMA64_TXSUSPEND);\n}\n\nstatic void op64_tx_resume(struct b43_dmaring *ring)\n{\n\tb43_dma_write(ring, B43_DMA64_TXCTL, b43_dma_read(ring, B43_DMA64_TXCTL)\n\t\t      & ~B43_DMA64_TXSUSPEND);\n}\n\nstatic int op64_get_current_rxslot(struct b43_dmaring *ring)\n{\n\tu32 val;\n\n\tval = b43_dma_read(ring, B43_DMA64_RXSTATUS);\n\tval &= B43_DMA64_RXSTATDPTR;\n\n\treturn (val / sizeof(struct b43_dmadesc64));\n}\n\nstatic void op64_set_current_rxslot(struct b43_dmaring *ring, int slot)\n{\n\tb43_dma_write(ring, B43_DMA64_RXINDEX,\n\t\t      (u32) (slot * sizeof(struct b43_dmadesc64)));\n}\n\nstatic const struct b43_dma_ops dma64_ops = {\n\t.idx2desc = op64_idx2desc,\n\t.fill_descriptor = op64_fill_descriptor,\n\t.poke_tx = op64_poke_tx,\n\t.tx_suspend = op64_tx_suspend,\n\t.tx_resume = op64_tx_resume,\n\t.get_current_rxslot = op64_get_current_rxslot,\n\t.set_current_rxslot = op64_set_current_rxslot,\n};\n\nstatic inline int free_slots(struct b43_dmaring *ring)\n{\n\treturn (ring->nr_slots - ring->used_slots);\n}\n\nstatic inline int next_slot(struct b43_dmaring *ring, int slot)\n{\n\tB43_WARN_ON(!(slot >= -1 && slot <= ring->nr_slots - 1));\n\tif (slot == ring->nr_slots - 1)\n\t\treturn 0;\n\treturn slot + 1;\n}\n\nstatic inline int prev_slot(struct b43_dmaring *ring, int slot)\n{\n\tB43_WARN_ON(!(slot >= 0 && slot <= ring->nr_slots - 1));\n\tif (slot == 0)\n\t\treturn ring->nr_slots - 1;\n\treturn slot - 1;\n}\n\n#ifdef CONFIG_B43_DEBUG\nstatic void update_max_used_slots(struct b43_dmaring *ring,\n\t\t\t\t  int current_used_slots)\n{\n\tif (current_used_slots <= ring->max_used_slots)\n\t\treturn;\n\tring->max_used_slots = current_used_slots;\n\tif (b43_debug(ring->dev, B43_DBG_DMAVERBOSE)) {\n\t\tb43dbg(ring->dev->wl,\n\t\t       \"max_used_slots increased to %d on %s ring %d\\n\",\n\t\t       ring->max_used_slots,\n\t\t       ring->tx ? \"TX\" : \"RX\", ring->index);\n\t}\n}\n#else\nstatic inline\n    void update_max_used_slots(struct b43_dmaring *ring, int current_used_slots)\n{\n}\n#endif  \n\n \nstatic inline int request_slot(struct b43_dmaring *ring)\n{\n\tint slot;\n\n\tB43_WARN_ON(!ring->tx);\n\tB43_WARN_ON(ring->stopped);\n\tB43_WARN_ON(free_slots(ring) == 0);\n\n\tslot = next_slot(ring, ring->current_slot);\n\tring->current_slot = slot;\n\tring->used_slots++;\n\n\tupdate_max_used_slots(ring, ring->used_slots);\n\n\treturn slot;\n}\n\nstatic u16 b43_dmacontroller_base(enum b43_dmatype type, int controller_idx)\n{\n\tstatic const u16 map64[] = {\n\t\tB43_MMIO_DMA64_BASE0,\n\t\tB43_MMIO_DMA64_BASE1,\n\t\tB43_MMIO_DMA64_BASE2,\n\t\tB43_MMIO_DMA64_BASE3,\n\t\tB43_MMIO_DMA64_BASE4,\n\t\tB43_MMIO_DMA64_BASE5,\n\t};\n\tstatic const u16 map32[] = {\n\t\tB43_MMIO_DMA32_BASE0,\n\t\tB43_MMIO_DMA32_BASE1,\n\t\tB43_MMIO_DMA32_BASE2,\n\t\tB43_MMIO_DMA32_BASE3,\n\t\tB43_MMIO_DMA32_BASE4,\n\t\tB43_MMIO_DMA32_BASE5,\n\t};\n\n\tif (type == B43_DMA_64BIT) {\n\t\tB43_WARN_ON(!(controller_idx >= 0 &&\n\t\t\t      controller_idx < ARRAY_SIZE(map64)));\n\t\treturn map64[controller_idx];\n\t}\n\tB43_WARN_ON(!(controller_idx >= 0 &&\n\t\t      controller_idx < ARRAY_SIZE(map32)));\n\treturn map32[controller_idx];\n}\n\nstatic inline\n    dma_addr_t map_descbuffer(struct b43_dmaring *ring,\n\t\t\t      unsigned char *buf, size_t len, int tx)\n{\n\tdma_addr_t dmaaddr;\n\n\tif (tx) {\n\t\tdmaaddr = dma_map_single(ring->dev->dev->dma_dev,\n\t\t\t\t\t buf, len, DMA_TO_DEVICE);\n\t} else {\n\t\tdmaaddr = dma_map_single(ring->dev->dev->dma_dev,\n\t\t\t\t\t buf, len, DMA_FROM_DEVICE);\n\t}\n\n\treturn dmaaddr;\n}\n\nstatic inline\n    void unmap_descbuffer(struct b43_dmaring *ring,\n\t\t\t  dma_addr_t addr, size_t len, int tx)\n{\n\tif (tx) {\n\t\tdma_unmap_single(ring->dev->dev->dma_dev,\n\t\t\t\t addr, len, DMA_TO_DEVICE);\n\t} else {\n\t\tdma_unmap_single(ring->dev->dev->dma_dev,\n\t\t\t\t addr, len, DMA_FROM_DEVICE);\n\t}\n}\n\nstatic inline\n    void sync_descbuffer_for_cpu(struct b43_dmaring *ring,\n\t\t\t\t dma_addr_t addr, size_t len)\n{\n\tB43_WARN_ON(ring->tx);\n\tdma_sync_single_for_cpu(ring->dev->dev->dma_dev,\n\t\t\t\t    addr, len, DMA_FROM_DEVICE);\n}\n\nstatic inline\n    void sync_descbuffer_for_device(struct b43_dmaring *ring,\n\t\t\t\t    dma_addr_t addr, size_t len)\n{\n\tB43_WARN_ON(ring->tx);\n\tdma_sync_single_for_device(ring->dev->dev->dma_dev,\n\t\t\t\t   addr, len, DMA_FROM_DEVICE);\n}\n\nstatic inline\n    void free_descriptor_buffer(struct b43_dmaring *ring,\n\t\t\t\tstruct b43_dmadesc_meta *meta)\n{\n\tif (meta->skb) {\n\t\tif (ring->tx)\n\t\t\tieee80211_free_txskb(ring->dev->wl->hw, meta->skb);\n\t\telse\n\t\t\tdev_kfree_skb_any(meta->skb);\n\t\tmeta->skb = NULL;\n\t}\n}\n\nstatic int alloc_ringmemory(struct b43_dmaring *ring)\n{\n\t \n\tu16 ring_mem_size = (ring->type == B43_DMA_64BIT) ?\n\t\t\t\tB43_DMA64_RINGMEMSIZE : B43_DMA32_RINGMEMSIZE;\n\n\tring->descbase = dma_alloc_coherent(ring->dev->dev->dma_dev,\n\t\t\t\t\t    ring_mem_size, &(ring->dmabase),\n\t\t\t\t\t    GFP_KERNEL);\n\tif (!ring->descbase)\n\t\treturn -ENOMEM;\n\n\treturn 0;\n}\n\nstatic void free_ringmemory(struct b43_dmaring *ring)\n{\n\tu16 ring_mem_size = (ring->type == B43_DMA_64BIT) ?\n\t\t\t\tB43_DMA64_RINGMEMSIZE : B43_DMA32_RINGMEMSIZE;\n\tdma_free_coherent(ring->dev->dev->dma_dev, ring_mem_size,\n\t\t\t  ring->descbase, ring->dmabase);\n}\n\n \nstatic int b43_dmacontroller_rx_reset(struct b43_wldev *dev, u16 mmio_base,\n\t\t\t\t      enum b43_dmatype type)\n{\n\tint i;\n\tu32 value;\n\tu16 offset;\n\n\tmight_sleep();\n\n\toffset = (type == B43_DMA_64BIT) ? B43_DMA64_RXCTL : B43_DMA32_RXCTL;\n\tb43_write32(dev, mmio_base + offset, 0);\n\tfor (i = 0; i < 10; i++) {\n\t\toffset = (type == B43_DMA_64BIT) ? B43_DMA64_RXSTATUS :\n\t\t\t\t\t\t   B43_DMA32_RXSTATUS;\n\t\tvalue = b43_read32(dev, mmio_base + offset);\n\t\tif (type == B43_DMA_64BIT) {\n\t\t\tvalue &= B43_DMA64_RXSTAT;\n\t\t\tif (value == B43_DMA64_RXSTAT_DISABLED) {\n\t\t\t\ti = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue &= B43_DMA32_RXSTATE;\n\t\t\tif (value == B43_DMA32_RXSTAT_DISABLED) {\n\t\t\t\ti = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tmsleep(1);\n\t}\n\tif (i != -1) {\n\t\tb43err(dev->wl, \"DMA RX reset timed out\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\treturn 0;\n}\n\n \nstatic int b43_dmacontroller_tx_reset(struct b43_wldev *dev, u16 mmio_base,\n\t\t\t\t      enum b43_dmatype type)\n{\n\tint i;\n\tu32 value;\n\tu16 offset;\n\n\tmight_sleep();\n\n\tfor (i = 0; i < 10; i++) {\n\t\toffset = (type == B43_DMA_64BIT) ? B43_DMA64_TXSTATUS :\n\t\t\t\t\t\t   B43_DMA32_TXSTATUS;\n\t\tvalue = b43_read32(dev, mmio_base + offset);\n\t\tif (type == B43_DMA_64BIT) {\n\t\t\tvalue &= B43_DMA64_TXSTAT;\n\t\t\tif (value == B43_DMA64_TXSTAT_DISABLED ||\n\t\t\t    value == B43_DMA64_TXSTAT_IDLEWAIT ||\n\t\t\t    value == B43_DMA64_TXSTAT_STOPPED)\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\tvalue &= B43_DMA32_TXSTATE;\n\t\t\tif (value == B43_DMA32_TXSTAT_DISABLED ||\n\t\t\t    value == B43_DMA32_TXSTAT_IDLEWAIT ||\n\t\t\t    value == B43_DMA32_TXSTAT_STOPPED)\n\t\t\t\tbreak;\n\t\t}\n\t\tmsleep(1);\n\t}\n\toffset = (type == B43_DMA_64BIT) ? B43_DMA64_TXCTL : B43_DMA32_TXCTL;\n\tb43_write32(dev, mmio_base + offset, 0);\n\tfor (i = 0; i < 10; i++) {\n\t\toffset = (type == B43_DMA_64BIT) ? B43_DMA64_TXSTATUS :\n\t\t\t\t\t\t   B43_DMA32_TXSTATUS;\n\t\tvalue = b43_read32(dev, mmio_base + offset);\n\t\tif (type == B43_DMA_64BIT) {\n\t\t\tvalue &= B43_DMA64_TXSTAT;\n\t\t\tif (value == B43_DMA64_TXSTAT_DISABLED) {\n\t\t\t\ti = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue &= B43_DMA32_TXSTATE;\n\t\t\tif (value == B43_DMA32_TXSTAT_DISABLED) {\n\t\t\t\ti = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tmsleep(1);\n\t}\n\tif (i != -1) {\n\t\tb43err(dev->wl, \"DMA TX reset timed out\\n\");\n\t\treturn -ENODEV;\n\t}\n\t \n\tmsleep(1);\n\n\treturn 0;\n}\n\n \nstatic bool b43_dma_mapping_error(struct b43_dmaring *ring,\n\t\t\t\t  dma_addr_t addr,\n\t\t\t\t  size_t buffersize, bool dma_to_device)\n{\n\tif (unlikely(dma_mapping_error(ring->dev->dev->dma_dev, addr)))\n\t\treturn true;\n\n\tswitch (ring->type) {\n\tcase B43_DMA_30BIT:\n\t\tif ((u64)addr + buffersize > (1ULL << 30))\n\t\t\tgoto address_error;\n\t\tbreak;\n\tcase B43_DMA_32BIT:\n\t\tif ((u64)addr + buffersize > (1ULL << 32))\n\t\t\tgoto address_error;\n\t\tbreak;\n\tcase B43_DMA_64BIT:\n\t\t \n\t\tbreak;\n\t}\n\n\t \n\treturn false;\n\naddress_error:\n\t \n\tunmap_descbuffer(ring, addr, buffersize, dma_to_device);\n\n\treturn true;\n}\n\nstatic bool b43_rx_buffer_is_poisoned(struct b43_dmaring *ring, struct sk_buff *skb)\n{\n\tunsigned char *f = skb->data + ring->frameoffset;\n\n\treturn ((f[0] & f[1] & f[2] & f[3] & f[4] & f[5] & f[6] & f[7]) == 0xFF);\n}\n\nstatic void b43_poison_rx_buffer(struct b43_dmaring *ring, struct sk_buff *skb)\n{\n\tstruct b43_rxhdr_fw4 *rxhdr;\n\tunsigned char *frame;\n\n\t \n\n\trxhdr = (struct b43_rxhdr_fw4 *)(skb->data);\n\trxhdr->frame_len = 0;\n\n\tB43_WARN_ON(ring->rx_buffersize < ring->frameoffset + sizeof(struct b43_plcp_hdr6) + 2);\n\tframe = skb->data + ring->frameoffset;\n\tmemset(frame, 0xFF, sizeof(struct b43_plcp_hdr6) + 2  );\n}\n\nstatic int setup_rx_descbuffer(struct b43_dmaring *ring,\n\t\t\t       struct b43_dmadesc_generic *desc,\n\t\t\t       struct b43_dmadesc_meta *meta, gfp_t gfp_flags)\n{\n\tdma_addr_t dmaaddr;\n\tstruct sk_buff *skb;\n\n\tB43_WARN_ON(ring->tx);\n\n\tskb = __dev_alloc_skb(ring->rx_buffersize, gfp_flags);\n\tif (unlikely(!skb))\n\t\treturn -ENOMEM;\n\tb43_poison_rx_buffer(ring, skb);\n\tdmaaddr = map_descbuffer(ring, skb->data, ring->rx_buffersize, 0);\n\tif (b43_dma_mapping_error(ring, dmaaddr, ring->rx_buffersize, 0)) {\n\t\t \n\t\tgfp_flags |= GFP_DMA;\n\n\t\tdev_kfree_skb_any(skb);\n\n\t\tskb = __dev_alloc_skb(ring->rx_buffersize, gfp_flags);\n\t\tif (unlikely(!skb))\n\t\t\treturn -ENOMEM;\n\t\tb43_poison_rx_buffer(ring, skb);\n\t\tdmaaddr = map_descbuffer(ring, skb->data,\n\t\t\t\t\t ring->rx_buffersize, 0);\n\t\tif (b43_dma_mapping_error(ring, dmaaddr, ring->rx_buffersize, 0)) {\n\t\t\tb43err(ring->dev->wl, \"RX DMA buffer allocation failed\\n\");\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\treturn -EIO;\n\t\t}\n\t}\n\n\tmeta->skb = skb;\n\tmeta->dmaaddr = dmaaddr;\n\tring->ops->fill_descriptor(ring, desc, dmaaddr,\n\t\t\t\t   ring->rx_buffersize, 0, 0, 0);\n\n\treturn 0;\n}\n\n \nstatic int alloc_initial_descbuffers(struct b43_dmaring *ring)\n{\n\tint i, err = -ENOMEM;\n\tstruct b43_dmadesc_generic *desc;\n\tstruct b43_dmadesc_meta *meta;\n\n\tfor (i = 0; i < ring->nr_slots; i++) {\n\t\tdesc = ring->ops->idx2desc(ring, i, &meta);\n\n\t\terr = setup_rx_descbuffer(ring, desc, meta, GFP_KERNEL);\n\t\tif (err) {\n\t\t\tb43err(ring->dev->wl,\n\t\t\t       \"Failed to allocate initial descbuffers\\n\");\n\t\t\tgoto err_unwind;\n\t\t}\n\t}\n\tmb();\n\tring->used_slots = ring->nr_slots;\n\terr = 0;\n      out:\n\treturn err;\n\n      err_unwind:\n\tfor (i--; i >= 0; i--) {\n\t\tdesc = ring->ops->idx2desc(ring, i, &meta);\n\n\t\tunmap_descbuffer(ring, meta->dmaaddr, ring->rx_buffersize, 0);\n\t\tdev_kfree_skb(meta->skb);\n\t}\n\tgoto out;\n}\n\n \nstatic int dmacontroller_setup(struct b43_dmaring *ring)\n{\n\tint err = 0;\n\tu32 value;\n\tu32 addrext;\n\tbool parity = ring->dev->dma.parity;\n\tu32 addrlo;\n\tu32 addrhi;\n\n\tif (ring->tx) {\n\t\tif (ring->type == B43_DMA_64BIT) {\n\t\t\tu64 ringbase = (u64) (ring->dmabase);\n\t\t\taddrext = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_EXT);\n\t\t\taddrlo = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_LOW);\n\t\t\taddrhi = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_HIGH);\n\n\t\t\tvalue = B43_DMA64_TXENABLE;\n\t\t\tvalue |= (addrext << B43_DMA64_TXADDREXT_SHIFT)\n\t\t\t    & B43_DMA64_TXADDREXT_MASK;\n\t\t\tif (!parity)\n\t\t\t\tvalue |= B43_DMA64_TXPARITYDISABLE;\n\t\t\tb43_dma_write(ring, B43_DMA64_TXCTL, value);\n\t\t\tb43_dma_write(ring, B43_DMA64_TXRINGLO, addrlo);\n\t\t\tb43_dma_write(ring, B43_DMA64_TXRINGHI, addrhi);\n\t\t} else {\n\t\t\tu32 ringbase = (u32) (ring->dmabase);\n\t\t\taddrext = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_EXT);\n\t\t\taddrlo = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_LOW);\n\n\t\t\tvalue = B43_DMA32_TXENABLE;\n\t\t\tvalue |= (addrext << B43_DMA32_TXADDREXT_SHIFT)\n\t\t\t    & B43_DMA32_TXADDREXT_MASK;\n\t\t\tif (!parity)\n\t\t\t\tvalue |= B43_DMA32_TXPARITYDISABLE;\n\t\t\tb43_dma_write(ring, B43_DMA32_TXCTL, value);\n\t\t\tb43_dma_write(ring, B43_DMA32_TXRING, addrlo);\n\t\t}\n\t} else {\n\t\terr = alloc_initial_descbuffers(ring);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tif (ring->type == B43_DMA_64BIT) {\n\t\t\tu64 ringbase = (u64) (ring->dmabase);\n\t\t\taddrext = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_EXT);\n\t\t\taddrlo = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_LOW);\n\t\t\taddrhi = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_HIGH);\n\n\t\t\tvalue = (ring->frameoffset << B43_DMA64_RXFROFF_SHIFT);\n\t\t\tvalue |= B43_DMA64_RXENABLE;\n\t\t\tvalue |= (addrext << B43_DMA64_RXADDREXT_SHIFT)\n\t\t\t    & B43_DMA64_RXADDREXT_MASK;\n\t\t\tif (!parity)\n\t\t\t\tvalue |= B43_DMA64_RXPARITYDISABLE;\n\t\t\tb43_dma_write(ring, B43_DMA64_RXCTL, value);\n\t\t\tb43_dma_write(ring, B43_DMA64_RXRINGLO, addrlo);\n\t\t\tb43_dma_write(ring, B43_DMA64_RXRINGHI, addrhi);\n\t\t\tb43_dma_write(ring, B43_DMA64_RXINDEX, ring->nr_slots *\n\t\t\t\t      sizeof(struct b43_dmadesc64));\n\t\t} else {\n\t\t\tu32 ringbase = (u32) (ring->dmabase);\n\t\t\taddrext = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_EXT);\n\t\t\taddrlo = b43_dma_address(&ring->dev->dma, ringbase, B43_DMA_ADDR_LOW);\n\n\t\t\tvalue = (ring->frameoffset << B43_DMA32_RXFROFF_SHIFT);\n\t\t\tvalue |= B43_DMA32_RXENABLE;\n\t\t\tvalue |= (addrext << B43_DMA32_RXADDREXT_SHIFT)\n\t\t\t    & B43_DMA32_RXADDREXT_MASK;\n\t\t\tif (!parity)\n\t\t\t\tvalue |= B43_DMA32_RXPARITYDISABLE;\n\t\t\tb43_dma_write(ring, B43_DMA32_RXCTL, value);\n\t\t\tb43_dma_write(ring, B43_DMA32_RXRING, addrlo);\n\t\t\tb43_dma_write(ring, B43_DMA32_RXINDEX, ring->nr_slots *\n\t\t\t\t      sizeof(struct b43_dmadesc32));\n\t\t}\n\t}\n\nout:\n\treturn err;\n}\n\n \nstatic void dmacontroller_cleanup(struct b43_dmaring *ring)\n{\n\tif (ring->tx) {\n\t\tb43_dmacontroller_tx_reset(ring->dev, ring->mmio_base,\n\t\t\t\t\t   ring->type);\n\t\tif (ring->type == B43_DMA_64BIT) {\n\t\t\tb43_dma_write(ring, B43_DMA64_TXRINGLO, 0);\n\t\t\tb43_dma_write(ring, B43_DMA64_TXRINGHI, 0);\n\t\t} else\n\t\t\tb43_dma_write(ring, B43_DMA32_TXRING, 0);\n\t} else {\n\t\tb43_dmacontroller_rx_reset(ring->dev, ring->mmio_base,\n\t\t\t\t\t   ring->type);\n\t\tif (ring->type == B43_DMA_64BIT) {\n\t\t\tb43_dma_write(ring, B43_DMA64_RXRINGLO, 0);\n\t\t\tb43_dma_write(ring, B43_DMA64_RXRINGHI, 0);\n\t\t} else\n\t\t\tb43_dma_write(ring, B43_DMA32_RXRING, 0);\n\t}\n}\n\nstatic void free_all_descbuffers(struct b43_dmaring *ring)\n{\n\tstruct b43_dmadesc_meta *meta;\n\tint i;\n\n\tif (!ring->used_slots)\n\t\treturn;\n\tfor (i = 0; i < ring->nr_slots; i++) {\n\t\t \n\t\tring->ops->idx2desc(ring, i, &meta);\n\n\t\tif (!meta->skb || b43_dma_ptr_is_poisoned(meta->skb)) {\n\t\t\tB43_WARN_ON(!ring->tx);\n\t\t\tcontinue;\n\t\t}\n\t\tif (ring->tx) {\n\t\t\tunmap_descbuffer(ring, meta->dmaaddr,\n\t\t\t\t\t meta->skb->len, 1);\n\t\t} else {\n\t\t\tunmap_descbuffer(ring, meta->dmaaddr,\n\t\t\t\t\t ring->rx_buffersize, 0);\n\t\t}\n\t\tfree_descriptor_buffer(ring, meta);\n\t}\n}\n\nstatic enum b43_dmatype b43_engine_type(struct b43_wldev *dev)\n{\n\tu32 tmp;\n\tu16 mmio_base;\n\n\tswitch (dev->dev->bus_type) {\n#ifdef CONFIG_B43_BCMA\n\tcase B43_BUS_BCMA:\n\t\ttmp = bcma_aread32(dev->dev->bdev, BCMA_IOST);\n\t\tif (tmp & BCMA_IOST_DMA64)\n\t\t\treturn B43_DMA_64BIT;\n\t\tbreak;\n#endif\n#ifdef CONFIG_B43_SSB\n\tcase B43_BUS_SSB:\n\t\ttmp = ssb_read32(dev->dev->sdev, SSB_TMSHIGH);\n\t\tif (tmp & SSB_TMSHIGH_DMA64)\n\t\t\treturn B43_DMA_64BIT;\n\t\tbreak;\n#endif\n\t}\n\n\tmmio_base = b43_dmacontroller_base(0, 0);\n\tb43_write32(dev, mmio_base + B43_DMA32_TXCTL, B43_DMA32_TXADDREXT_MASK);\n\ttmp = b43_read32(dev, mmio_base + B43_DMA32_TXCTL);\n\tif (tmp & B43_DMA32_TXADDREXT_MASK)\n\t\treturn B43_DMA_32BIT;\n\treturn B43_DMA_30BIT;\n}\n\n \nstatic\nstruct b43_dmaring *b43_setup_dmaring(struct b43_wldev *dev,\n\t\t\t\t      int controller_index,\n\t\t\t\t      int for_tx,\n\t\t\t\t      enum b43_dmatype type)\n{\n\tstruct b43_dmaring *ring;\n\tint i, err;\n\tdma_addr_t dma_test;\n\n\tring = kzalloc(sizeof(*ring), GFP_KERNEL);\n\tif (!ring)\n\t\tgoto out;\n\n\tring->nr_slots = B43_RXRING_SLOTS;\n\tif (for_tx)\n\t\tring->nr_slots = B43_TXRING_SLOTS;\n\n\tring->meta = kcalloc(ring->nr_slots, sizeof(struct b43_dmadesc_meta),\n\t\t\t     GFP_KERNEL);\n\tif (!ring->meta)\n\t\tgoto err_kfree_ring;\n\tfor (i = 0; i < ring->nr_slots; i++)\n\t\tring->meta->skb = B43_DMA_PTR_POISON;\n\n\tring->type = type;\n\tring->dev = dev;\n\tring->mmio_base = b43_dmacontroller_base(type, controller_index);\n\tring->index = controller_index;\n\tif (type == B43_DMA_64BIT)\n\t\tring->ops = &dma64_ops;\n\telse\n\t\tring->ops = &dma32_ops;\n\tif (for_tx) {\n\t\tring->tx = true;\n\t\tring->current_slot = -1;\n\t} else {\n\t\tif (ring->index == 0) {\n\t\t\tswitch (dev->fw.hdr_format) {\n\t\t\tcase B43_FW_HDR_598:\n\t\t\t\tring->rx_buffersize = B43_DMA0_RX_FW598_BUFSIZE;\n\t\t\t\tring->frameoffset = B43_DMA0_RX_FW598_FO;\n\t\t\t\tbreak;\n\t\t\tcase B43_FW_HDR_410:\n\t\t\tcase B43_FW_HDR_351:\n\t\t\t\tring->rx_buffersize = B43_DMA0_RX_FW351_BUFSIZE;\n\t\t\t\tring->frameoffset = B43_DMA0_RX_FW351_FO;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else\n\t\t\tB43_WARN_ON(1);\n\t}\n#ifdef CONFIG_B43_DEBUG\n\tring->last_injected_overflow = jiffies;\n#endif\n\n\tif (for_tx) {\n\t\t \n\t\tBUILD_BUG_ON(B43_TXRING_SLOTS % TX_SLOTS_PER_FRAME != 0);\n\n\t\tring->txhdr_cache = kcalloc(ring->nr_slots / TX_SLOTS_PER_FRAME,\n\t\t\t\t\t    b43_txhdr_size(dev),\n\t\t\t\t\t    GFP_KERNEL);\n\t\tif (!ring->txhdr_cache)\n\t\t\tgoto err_kfree_meta;\n\n\t\t \n\t\tdma_test = dma_map_single(dev->dev->dma_dev,\n\t\t\t\t\t  ring->txhdr_cache,\n\t\t\t\t\t  b43_txhdr_size(dev),\n\t\t\t\t\t  DMA_TO_DEVICE);\n\n\t\tif (b43_dma_mapping_error(ring, dma_test,\n\t\t\t\t\t  b43_txhdr_size(dev), 1)) {\n\t\t\t \n\t\t\tkfree(ring->txhdr_cache);\n\t\t\tring->txhdr_cache = kcalloc(ring->nr_slots / TX_SLOTS_PER_FRAME,\n\t\t\t\t\t\t    b43_txhdr_size(dev),\n\t\t\t\t\t\t    GFP_KERNEL | GFP_DMA);\n\t\t\tif (!ring->txhdr_cache)\n\t\t\t\tgoto err_kfree_meta;\n\n\t\t\tdma_test = dma_map_single(dev->dev->dma_dev,\n\t\t\t\t\t\t  ring->txhdr_cache,\n\t\t\t\t\t\t  b43_txhdr_size(dev),\n\t\t\t\t\t\t  DMA_TO_DEVICE);\n\n\t\t\tif (b43_dma_mapping_error(ring, dma_test,\n\t\t\t\t\t\t  b43_txhdr_size(dev), 1)) {\n\n\t\t\t\tb43err(dev->wl,\n\t\t\t\t       \"TXHDR DMA allocation failed\\n\");\n\t\t\t\tgoto err_kfree_txhdr_cache;\n\t\t\t}\n\t\t}\n\n\t\tdma_unmap_single(dev->dev->dma_dev,\n\t\t\t\t dma_test, b43_txhdr_size(dev),\n\t\t\t\t DMA_TO_DEVICE);\n\t}\n\n\terr = alloc_ringmemory(ring);\n\tif (err)\n\t\tgoto err_kfree_txhdr_cache;\n\terr = dmacontroller_setup(ring);\n\tif (err)\n\t\tgoto err_free_ringmemory;\n\n      out:\n\treturn ring;\n\n      err_free_ringmemory:\n\tfree_ringmemory(ring);\n      err_kfree_txhdr_cache:\n\tkfree(ring->txhdr_cache);\n      err_kfree_meta:\n\tkfree(ring->meta);\n      err_kfree_ring:\n\tkfree(ring);\n\tring = NULL;\n\tgoto out;\n}\n\n#define divide(a, b)\t({\t\\\n\ttypeof(a) __a = a;\t\\\n\tdo_div(__a, b);\t\t\\\n\t__a;\t\t\t\\\n  })\n\n#define modulo(a, b)\t({\t\\\n\ttypeof(a) __a = a;\t\\\n\tdo_div(__a, b);\t\t\\\n  })\n\n \nstatic void b43_destroy_dmaring(struct b43_dmaring *ring,\n\t\t\t\tconst char *ringname)\n{\n\tif (!ring)\n\t\treturn;\n\n#ifdef CONFIG_B43_DEBUG\n\t{\n\t\t \n\t\tu64 failed_packets = ring->nr_failed_tx_packets;\n\t\tu64 succeed_packets = ring->nr_succeed_tx_packets;\n\t\tu64 nr_packets = failed_packets + succeed_packets;\n\t\tu64 permille_failed = 0, average_tries = 0;\n\n\t\tif (nr_packets)\n\t\t\tpermille_failed = divide(failed_packets * 1000, nr_packets);\n\t\tif (nr_packets)\n\t\t\taverage_tries = divide(ring->nr_total_packet_tries * 100, nr_packets);\n\n\t\tb43dbg(ring->dev->wl, \"DMA-%u %s: \"\n\t\t       \"Used slots %d/%d, Failed frames %llu/%llu = %llu.%01llu%%, \"\n\t\t       \"Average tries %llu.%02llu\\n\",\n\t\t       (unsigned int)(ring->type), ringname,\n\t\t       ring->max_used_slots,\n\t\t       ring->nr_slots,\n\t\t       (unsigned long long)failed_packets,\n\t\t       (unsigned long long)nr_packets,\n\t\t       (unsigned long long)divide(permille_failed, 10),\n\t\t       (unsigned long long)modulo(permille_failed, 10),\n\t\t       (unsigned long long)divide(average_tries, 100),\n\t\t       (unsigned long long)modulo(average_tries, 100));\n\t}\n#endif  \n\n\t \n\tdmacontroller_cleanup(ring);\n\tfree_all_descbuffers(ring);\n\tfree_ringmemory(ring);\n\n\tkfree(ring->txhdr_cache);\n\tkfree(ring->meta);\n\tkfree(ring);\n}\n\n#define destroy_ring(dma, ring) do {\t\t\t\t\\\n\tb43_destroy_dmaring((dma)->ring, __stringify(ring));\t\\\n\t(dma)->ring = NULL;\t\t\t\t\t\\\n    } while (0)\n\nvoid b43_dma_free(struct b43_wldev *dev)\n{\n\tstruct b43_dma *dma;\n\n\tif (b43_using_pio_transfers(dev))\n\t\treturn;\n\tdma = &dev->dma;\n\n\tdestroy_ring(dma, rx_ring);\n\tdestroy_ring(dma, tx_ring_AC_BK);\n\tdestroy_ring(dma, tx_ring_AC_BE);\n\tdestroy_ring(dma, tx_ring_AC_VI);\n\tdestroy_ring(dma, tx_ring_AC_VO);\n\tdestroy_ring(dma, tx_ring_mcast);\n}\n\n \nstatic bool b43_dma_translation_in_low_word(struct b43_wldev *dev,\n\t\t\t\t\t    enum b43_dmatype type)\n{\n\tif (type != B43_DMA_64BIT)\n\t\treturn true;\n\n#ifdef CONFIG_B43_SSB\n\tif (dev->dev->bus_type == B43_BUS_SSB &&\n\t    dev->dev->sdev->bus->bustype == SSB_BUSTYPE_PCI &&\n\t    !(pci_is_pcie(dev->dev->sdev->bus->host_pci) &&\n\t      ssb_read32(dev->dev->sdev, SSB_TMSHIGH) & SSB_TMSHIGH_DMA64))\n\t\t\treturn true;\n#endif\n\treturn false;\n}\n\nint b43_dma_init(struct b43_wldev *dev)\n{\n\tstruct b43_dma *dma = &dev->dma;\n\tenum b43_dmatype type = b43_engine_type(dev);\n\tint err;\n\n\terr = dma_set_mask_and_coherent(dev->dev->dma_dev, DMA_BIT_MASK(type));\n\tif (err) {\n\t\tb43err(dev->wl, \"The machine/kernel does not support \"\n\t\t       \"the required %u-bit DMA mask\\n\", type);\n\t\treturn err;\n\t}\n\n\tswitch (dev->dev->bus_type) {\n#ifdef CONFIG_B43_BCMA\n\tcase B43_BUS_BCMA:\n\t\tdma->translation = bcma_core_dma_translation(dev->dev->bdev);\n\t\tbreak;\n#endif\n#ifdef CONFIG_B43_SSB\n\tcase B43_BUS_SSB:\n\t\tdma->translation = ssb_dma_translation(dev->dev->sdev);\n\t\tbreak;\n#endif\n\t}\n\tdma->translation_in_low = b43_dma_translation_in_low_word(dev, type);\n\n\tdma->parity = true;\n#ifdef CONFIG_B43_BCMA\n\t \n\tif (dev->dev->bus_type == B43_BUS_BCMA)\n\t\tdma->parity = false;\n#endif\n\n\terr = -ENOMEM;\n\t \n\tdma->tx_ring_AC_BK = b43_setup_dmaring(dev, 0, 1, type);\n\tif (!dma->tx_ring_AC_BK)\n\t\tgoto out;\n\n\tdma->tx_ring_AC_BE = b43_setup_dmaring(dev, 1, 1, type);\n\tif (!dma->tx_ring_AC_BE)\n\t\tgoto err_destroy_bk;\n\n\tdma->tx_ring_AC_VI = b43_setup_dmaring(dev, 2, 1, type);\n\tif (!dma->tx_ring_AC_VI)\n\t\tgoto err_destroy_be;\n\n\tdma->tx_ring_AC_VO = b43_setup_dmaring(dev, 3, 1, type);\n\tif (!dma->tx_ring_AC_VO)\n\t\tgoto err_destroy_vi;\n\n\tdma->tx_ring_mcast = b43_setup_dmaring(dev, 4, 1, type);\n\tif (!dma->tx_ring_mcast)\n\t\tgoto err_destroy_vo;\n\n\t \n\tdma->rx_ring = b43_setup_dmaring(dev, 0, 0, type);\n\tif (!dma->rx_ring)\n\t\tgoto err_destroy_mcast;\n\n\t \n\tB43_WARN_ON(dev->dev->core_rev < 5);\n\n\tb43dbg(dev->wl, \"%u-bit DMA initialized\\n\",\n\t       (unsigned int)type);\n\terr = 0;\nout:\n\treturn err;\n\nerr_destroy_mcast:\n\tdestroy_ring(dma, tx_ring_mcast);\nerr_destroy_vo:\n\tdestroy_ring(dma, tx_ring_AC_VO);\nerr_destroy_vi:\n\tdestroy_ring(dma, tx_ring_AC_VI);\nerr_destroy_be:\n\tdestroy_ring(dma, tx_ring_AC_BE);\nerr_destroy_bk:\n\tdestroy_ring(dma, tx_ring_AC_BK);\n\treturn err;\n}\n\n \nstatic u16 generate_cookie(struct b43_dmaring *ring, int slot)\n{\n\tu16 cookie;\n\n\t \n\tcookie = (((u16)ring->index + 1) << 12);\n\tB43_WARN_ON(slot & ~0x0FFF);\n\tcookie |= (u16)slot;\n\n\treturn cookie;\n}\n\n \nstatic\nstruct b43_dmaring *parse_cookie(struct b43_wldev *dev, u16 cookie, int *slot)\n{\n\tstruct b43_dma *dma = &dev->dma;\n\tstruct b43_dmaring *ring = NULL;\n\n\tswitch (cookie & 0xF000) {\n\tcase 0x1000:\n\t\tring = dma->tx_ring_AC_BK;\n\t\tbreak;\n\tcase 0x2000:\n\t\tring = dma->tx_ring_AC_BE;\n\t\tbreak;\n\tcase 0x3000:\n\t\tring = dma->tx_ring_AC_VI;\n\t\tbreak;\n\tcase 0x4000:\n\t\tring = dma->tx_ring_AC_VO;\n\t\tbreak;\n\tcase 0x5000:\n\t\tring = dma->tx_ring_mcast;\n\t\tbreak;\n\t}\n\t*slot = (cookie & 0x0FFF);\n\tif (unlikely(!ring || *slot < 0 || *slot >= ring->nr_slots)) {\n\t\tb43dbg(dev->wl, \"TX-status contains \"\n\t\t       \"invalid cookie: 0x%04X\\n\", cookie);\n\t\treturn NULL;\n\t}\n\n\treturn ring;\n}\n\nstatic int dma_tx_fragment(struct b43_dmaring *ring,\n\t\t\t   struct sk_buff *skb)\n{\n\tconst struct b43_dma_ops *ops = ring->ops;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\tstruct b43_private_tx_info *priv_info = b43_get_priv_tx_info(info);\n\tu8 *header;\n\tint slot, old_top_slot, old_used_slots;\n\tint err;\n\tstruct b43_dmadesc_generic *desc;\n\tstruct b43_dmadesc_meta *meta;\n\tstruct b43_dmadesc_meta *meta_hdr;\n\tu16 cookie;\n\tsize_t hdrsize = b43_txhdr_size(ring->dev);\n\n\t \n\n\told_top_slot = ring->current_slot;\n\told_used_slots = ring->used_slots;\n\n\t \n\tslot = request_slot(ring);\n\tdesc = ops->idx2desc(ring, slot, &meta_hdr);\n\tmemset(meta_hdr, 0, sizeof(*meta_hdr));\n\n\theader = &(ring->txhdr_cache[(slot / TX_SLOTS_PER_FRAME) * hdrsize]);\n\tcookie = generate_cookie(ring, slot);\n\terr = b43_generate_txhdr(ring->dev, header,\n\t\t\t\t skb, info, cookie);\n\tif (unlikely(err)) {\n\t\tring->current_slot = old_top_slot;\n\t\tring->used_slots = old_used_slots;\n\t\treturn err;\n\t}\n\n\tmeta_hdr->dmaaddr = map_descbuffer(ring, (unsigned char *)header,\n\t\t\t\t\t   hdrsize, 1);\n\tif (b43_dma_mapping_error(ring, meta_hdr->dmaaddr, hdrsize, 1)) {\n\t\tring->current_slot = old_top_slot;\n\t\tring->used_slots = old_used_slots;\n\t\treturn -EIO;\n\t}\n\tops->fill_descriptor(ring, desc, meta_hdr->dmaaddr,\n\t\t\t     hdrsize, 1, 0, 0);\n\n\t \n\tslot = request_slot(ring);\n\tdesc = ops->idx2desc(ring, slot, &meta);\n\tmemset(meta, 0, sizeof(*meta));\n\n\tmeta->skb = skb;\n\tmeta->is_last_fragment = true;\n\tpriv_info->bouncebuffer = NULL;\n\n\tmeta->dmaaddr = map_descbuffer(ring, skb->data, skb->len, 1);\n\t \n\tif (b43_dma_mapping_error(ring, meta->dmaaddr, skb->len, 1)) {\n\t\tpriv_info->bouncebuffer = kmemdup(skb->data, skb->len,\n\t\t\t\t\t\t  GFP_ATOMIC | GFP_DMA);\n\t\tif (!priv_info->bouncebuffer) {\n\t\t\tring->current_slot = old_top_slot;\n\t\t\tring->used_slots = old_used_slots;\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_unmap_hdr;\n\t\t}\n\n\t\tmeta->dmaaddr = map_descbuffer(ring, priv_info->bouncebuffer, skb->len, 1);\n\t\tif (b43_dma_mapping_error(ring, meta->dmaaddr, skb->len, 1)) {\n\t\t\tkfree(priv_info->bouncebuffer);\n\t\t\tpriv_info->bouncebuffer = NULL;\n\t\t\tring->current_slot = old_top_slot;\n\t\t\tring->used_slots = old_used_slots;\n\t\t\terr = -EIO;\n\t\t\tgoto out_unmap_hdr;\n\t\t}\n\t}\n\n\tops->fill_descriptor(ring, desc, meta->dmaaddr, skb->len, 0, 1, 1);\n\n\tif (info->flags & IEEE80211_TX_CTL_SEND_AFTER_DTIM) {\n\t\t \n\t\tb43_shm_write16(ring->dev, B43_SHM_SHARED,\n\t\t\t\tB43_SHM_SH_MCASTCOOKIE, cookie);\n\t}\n\t \n\twmb();\n\tops->poke_tx(ring, next_slot(ring, slot));\n\treturn 0;\n\nout_unmap_hdr:\n\tunmap_descbuffer(ring, meta_hdr->dmaaddr,\n\t\t\t hdrsize, 1);\n\treturn err;\n}\n\nstatic inline int should_inject_overflow(struct b43_dmaring *ring)\n{\n#ifdef CONFIG_B43_DEBUG\n\tif (unlikely(b43_debug(ring->dev, B43_DBG_DMAOVERFLOW))) {\n\t\t \n\t\tunsigned long next_overflow;\n\n\t\tnext_overflow = ring->last_injected_overflow + HZ;\n\t\tif (time_after(jiffies, next_overflow)) {\n\t\t\tring->last_injected_overflow = jiffies;\n\t\t\tb43dbg(ring->dev->wl,\n\t\t\t       \"Injecting TX ring overflow on \"\n\t\t\t       \"DMA controller %d\\n\", ring->index);\n\t\t\treturn 1;\n\t\t}\n\t}\n#endif  \n\treturn 0;\n}\n\n \nstatic struct b43_dmaring *select_ring_by_priority(struct b43_wldev *dev,\n\t\t\t\t\t\t   u8 queue_prio)\n{\n\tstruct b43_dmaring *ring;\n\n\tif (dev->qos_enabled) {\n\t\t \n\t\tswitch (queue_prio) {\n\t\tdefault:\n\t\t\tB43_WARN_ON(1);\n\t\t\tfallthrough;\n\t\tcase 0:\n\t\t\tring = dev->dma.tx_ring_AC_VO;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tring = dev->dma.tx_ring_AC_VI;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tring = dev->dma.tx_ring_AC_BE;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tring = dev->dma.tx_ring_AC_BK;\n\t\t\tbreak;\n\t\t}\n\t} else\n\t\tring = dev->dma.tx_ring_AC_BE;\n\n\treturn ring;\n}\n\nint b43_dma_tx(struct b43_wldev *dev, struct sk_buff *skb)\n{\n\tstruct b43_dmaring *ring;\n\tstruct ieee80211_hdr *hdr;\n\tint err = 0;\n\tstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\n\n\thdr = (struct ieee80211_hdr *)skb->data;\n\tif (info->flags & IEEE80211_TX_CTL_SEND_AFTER_DTIM) {\n\t\t \n\t\tring = dev->dma.tx_ring_mcast;\n\t\t \n\t\thdr->frame_control |= cpu_to_le16(IEEE80211_FCTL_MOREDATA);\n\t} else {\n\t\t \n\t\tring = select_ring_by_priority(\n\t\t\tdev, skb_get_queue_mapping(skb));\n\t}\n\n\tB43_WARN_ON(!ring->tx);\n\n\tif (unlikely(ring->stopped)) {\n\t\t \n\t\tif (b43_debug(dev, B43_DBG_DMAVERBOSE))\n\t\t\tb43err(dev->wl, \"Packet after queue stopped\\n\");\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\tif (WARN_ON(free_slots(ring) < TX_SLOTS_PER_FRAME)) {\n\t\t \n\t\tb43err(dev->wl, \"DMA queue overflow\\n\");\n\t\terr = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\t \n\tring->queue_prio = skb_get_queue_mapping(skb);\n\n\terr = dma_tx_fragment(ring, skb);\n\tif (unlikely(err == -ENOKEY)) {\n\t\t \n\t\tieee80211_free_txskb(dev->wl->hw, skb);\n\t\terr = 0;\n\t\tgoto out;\n\t}\n\tif (unlikely(err)) {\n\t\tb43err(dev->wl, \"DMA tx mapping failure\\n\");\n\t\tgoto out;\n\t}\n\tif ((free_slots(ring) < TX_SLOTS_PER_FRAME) ||\n\t    should_inject_overflow(ring)) {\n\t\t \n\t\tunsigned int skb_mapping = skb_get_queue_mapping(skb);\n\t\tieee80211_stop_queue(dev->wl->hw, skb_mapping);\n\t\tdev->wl->tx_queue_stopped[skb_mapping] = true;\n\t\tring->stopped = true;\n\t\tif (b43_debug(dev, B43_DBG_DMAVERBOSE)) {\n\t\t\tb43dbg(dev->wl, \"Stopped TX ring %d\\n\", ring->index);\n\t\t}\n\t}\nout:\n\n\treturn err;\n}\n\nvoid b43_dma_handle_txstatus(struct b43_wldev *dev,\n\t\t\t     const struct b43_txstatus *status)\n{\n\tconst struct b43_dma_ops *ops;\n\tstruct b43_dmaring *ring;\n\tstruct b43_dmadesc_meta *meta;\n\tstatic const struct b43_txstatus fake;  \n\tconst struct b43_txstatus *txstat;\n\tint slot, firstused;\n\tbool frame_succeed;\n\tint skip;\n\tstatic u8 err_out1;\n\n\tring = parse_cookie(dev, status->cookie, &slot);\n\tif (unlikely(!ring))\n\t\treturn;\n\tB43_WARN_ON(!ring->tx);\n\n\t \n\tfirstused = ring->current_slot - ring->used_slots + 1;\n\tif (firstused < 0)\n\t\tfirstused = ring->nr_slots + firstused;\n\n\tskip = 0;\n\tif (unlikely(slot != firstused)) {\n\t\t \n\t\tif (slot == next_slot(ring, next_slot(ring, firstused))) {\n\t\t\t \n\t\t\tslot = firstused;\n\t\t\tskip = 2;\n\t\t\tif (!err_out1) {\n\t\t\t\t \n\t\t\t\tb43dbg(dev->wl,\n\t\t\t\t       \"Skip on DMA ring %d slot %d.\\n\",\n\t\t\t\t       ring->index, slot);\n\t\t\t\terr_out1 = 1;\n\t\t\t}\n\t\t} else {\n\t\t\t \n\t\t\tb43dbg(dev->wl,\n\t\t\t       \"Out of order TX status report on DMA ring %d. Expected %d, but got %d\\n\",\n\t\t\t       ring->index, firstused, slot);\n\t\t\tif (dev->fw.opensource)\n\t\t\t\tb43_controller_restart(dev, \"Out of order TX\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\tops = ring->ops;\n\twhile (1) {\n\t\tB43_WARN_ON(slot < 0 || slot >= ring->nr_slots);\n\t\t \n\t\tops->idx2desc(ring, slot, &meta);\n\n\t\tif (b43_dma_ptr_is_poisoned(meta->skb)) {\n\t\t\tb43dbg(dev->wl, \"Poisoned TX slot %d (first=%d) \"\n\t\t\t       \"on ring %d\\n\",\n\t\t\t       slot, firstused, ring->index);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (meta->skb) {\n\t\t\tstruct b43_private_tx_info *priv_info =\n\t\t\t     b43_get_priv_tx_info(IEEE80211_SKB_CB(meta->skb));\n\n\t\t\tunmap_descbuffer(ring, meta->dmaaddr,\n\t\t\t\t\t meta->skb->len, 1);\n\t\t\tkfree(priv_info->bouncebuffer);\n\t\t\tpriv_info->bouncebuffer = NULL;\n\t\t} else {\n\t\t\tunmap_descbuffer(ring, meta->dmaaddr,\n\t\t\t\t\t b43_txhdr_size(dev), 1);\n\t\t}\n\n\t\tif (meta->is_last_fragment) {\n\t\t\tstruct ieee80211_tx_info *info;\n\n\t\t\tif (unlikely(!meta->skb)) {\n\t\t\t\t \n\t\t\t\tb43dbg(dev->wl, \"TX status unexpected NULL skb \"\n\t\t\t\t       \"at slot %d (first=%d) on ring %d\\n\",\n\t\t\t\t       slot, firstused, ring->index);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tinfo = IEEE80211_SKB_CB(meta->skb);\n\n\t\t\t \n\t\t\tif (unlikely(skip))\n\t\t\t\ttxstat = &fake;\n\t\t\telse\n\t\t\t\ttxstat = status;\n\n\t\t\tframe_succeed = b43_fill_txstatus_report(dev, info,\n\t\t\t\t\t\t\t\t txstat);\n#ifdef CONFIG_B43_DEBUG\n\t\t\tif (frame_succeed)\n\t\t\t\tring->nr_succeed_tx_packets++;\n\t\t\telse\n\t\t\t\tring->nr_failed_tx_packets++;\n\t\t\tring->nr_total_packet_tries += status->frame_count;\n#endif  \n\t\t\tieee80211_tx_status(dev->wl->hw, meta->skb);\n\n\t\t\t \n\t\t\tmeta->skb = B43_DMA_PTR_POISON;\n\t\t} else {\n\t\t\t \n\t\t\tif (unlikely(meta->skb)) {\n\t\t\t\tb43dbg(dev->wl, \"TX status unexpected non-NULL skb \"\n\t\t\t\t       \"at slot %d (first=%d) on ring %d\\n\",\n\t\t\t\t       slot, firstused, ring->index);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tring->used_slots--;\n\n\t\tif (meta->is_last_fragment && !skip) {\n\t\t\t \n\t\t\tbreak;\n\t\t}\n\t\tslot = next_slot(ring, slot);\n\t\tif (skip > 0)\n\t\t\t--skip;\n\t}\n\tif (ring->stopped) {\n\t\tB43_WARN_ON(free_slots(ring) < TX_SLOTS_PER_FRAME);\n\t\tring->stopped = false;\n\t}\n\n\tif (dev->wl->tx_queue_stopped[ring->queue_prio]) {\n\t\tdev->wl->tx_queue_stopped[ring->queue_prio] = false;\n\t} else {\n\t\t \n\t\tieee80211_wake_queue(dev->wl->hw, ring->queue_prio);\n\t\tif (b43_debug(dev, B43_DBG_DMAVERBOSE)) {\n\t\t\tb43dbg(dev->wl, \"Woke up TX ring %d\\n\", ring->index);\n\t\t}\n\t}\n\t \n\tieee80211_queue_work(dev->wl->hw, &dev->wl->tx_work);\n}\n\nstatic void dma_rx(struct b43_dmaring *ring, int *slot)\n{\n\tconst struct b43_dma_ops *ops = ring->ops;\n\tstruct b43_dmadesc_generic *desc;\n\tstruct b43_dmadesc_meta *meta;\n\tstruct b43_rxhdr_fw4 *rxhdr;\n\tstruct sk_buff *skb;\n\tu16 len;\n\tint err;\n\tdma_addr_t dmaaddr;\n\n\tdesc = ops->idx2desc(ring, *slot, &meta);\n\n\tsync_descbuffer_for_cpu(ring, meta->dmaaddr, ring->rx_buffersize);\n\tskb = meta->skb;\n\n\trxhdr = (struct b43_rxhdr_fw4 *)skb->data;\n\tlen = le16_to_cpu(rxhdr->frame_len);\n\tif (len == 0) {\n\t\tint i = 0;\n\n\t\tdo {\n\t\t\tudelay(2);\n\t\t\tbarrier();\n\t\t\tlen = le16_to_cpu(rxhdr->frame_len);\n\t\t} while (len == 0 && i++ < 5);\n\t\tif (unlikely(len == 0)) {\n\t\t\tdmaaddr = meta->dmaaddr;\n\t\t\tgoto drop_recycle_buffer;\n\t\t}\n\t}\n\tif (unlikely(b43_rx_buffer_is_poisoned(ring, skb))) {\n\t\t \n\t\tb43dbg(ring->dev->wl, \"DMA RX: Dropping poisoned buffer.\\n\");\n\t\tdmaaddr = meta->dmaaddr;\n\t\tgoto drop_recycle_buffer;\n\t}\n\tif (unlikely(len + ring->frameoffset > ring->rx_buffersize)) {\n\t\t \n\t\tint cnt = 0;\n\t\ts32 tmp = len;\n\n\t\twhile (1) {\n\t\t\tdesc = ops->idx2desc(ring, *slot, &meta);\n\t\t\t \n\t\t\tb43_poison_rx_buffer(ring, meta->skb);\n\t\t\tsync_descbuffer_for_device(ring, meta->dmaaddr,\n\t\t\t\t\t\t   ring->rx_buffersize);\n\t\t\t*slot = next_slot(ring, *slot);\n\t\t\tcnt++;\n\t\t\ttmp -= ring->rx_buffersize;\n\t\t\tif (tmp <= 0)\n\t\t\t\tbreak;\n\t\t}\n\t\tb43err(ring->dev->wl, \"DMA RX buffer too small \"\n\t\t       \"(len: %u, buffer: %u, nr-dropped: %d)\\n\",\n\t\t       len, ring->rx_buffersize, cnt);\n\t\tgoto drop;\n\t}\n\n\tdmaaddr = meta->dmaaddr;\n\terr = setup_rx_descbuffer(ring, desc, meta, GFP_ATOMIC);\n\tif (unlikely(err)) {\n\t\tb43dbg(ring->dev->wl, \"DMA RX: setup_rx_descbuffer() failed\\n\");\n\t\tgoto drop_recycle_buffer;\n\t}\n\n\tunmap_descbuffer(ring, dmaaddr, ring->rx_buffersize, 0);\n\tskb_put(skb, len + ring->frameoffset);\n\tskb_pull(skb, ring->frameoffset);\n\n\tb43_rx(ring->dev, skb, rxhdr);\ndrop:\n\treturn;\n\ndrop_recycle_buffer:\n\t \n\tb43_poison_rx_buffer(ring, skb);\n\tsync_descbuffer_for_device(ring, dmaaddr, ring->rx_buffersize);\n}\n\nvoid b43_dma_handle_rx_overflow(struct b43_dmaring *ring)\n{\n\tint current_slot, previous_slot;\n\n\tB43_WARN_ON(ring->tx);\n\n\t \n\t \n\tcurrent_slot = ring->ops->get_current_rxslot(ring);\n\tprevious_slot = prev_slot(ring, current_slot);\n\tring->ops->set_current_rxslot(ring, previous_slot);\n}\n\nvoid b43_dma_rx(struct b43_dmaring *ring)\n{\n\tconst struct b43_dma_ops *ops = ring->ops;\n\tint slot, current_slot;\n\tint used_slots = 0;\n\n\tB43_WARN_ON(ring->tx);\n\tcurrent_slot = ops->get_current_rxslot(ring);\n\tB43_WARN_ON(!(current_slot >= 0 && current_slot < ring->nr_slots));\n\n\tslot = ring->current_slot;\n\tfor (; slot != current_slot; slot = next_slot(ring, slot)) {\n\t\tdma_rx(ring, &slot);\n\t\tupdate_max_used_slots(ring, ++used_slots);\n\t}\n\twmb();\n\tops->set_current_rxslot(ring, slot);\n\tring->current_slot = slot;\n}\n\nstatic void b43_dma_tx_suspend_ring(struct b43_dmaring *ring)\n{\n\tB43_WARN_ON(!ring->tx);\n\tring->ops->tx_suspend(ring);\n}\n\nstatic void b43_dma_tx_resume_ring(struct b43_dmaring *ring)\n{\n\tB43_WARN_ON(!ring->tx);\n\tring->ops->tx_resume(ring);\n}\n\nvoid b43_dma_tx_suspend(struct b43_wldev *dev)\n{\n\tb43_power_saving_ctl_bits(dev, B43_PS_AWAKE);\n\tb43_dma_tx_suspend_ring(dev->dma.tx_ring_AC_BK);\n\tb43_dma_tx_suspend_ring(dev->dma.tx_ring_AC_BE);\n\tb43_dma_tx_suspend_ring(dev->dma.tx_ring_AC_VI);\n\tb43_dma_tx_suspend_ring(dev->dma.tx_ring_AC_VO);\n\tb43_dma_tx_suspend_ring(dev->dma.tx_ring_mcast);\n}\n\nvoid b43_dma_tx_resume(struct b43_wldev *dev)\n{\n\tb43_dma_tx_resume_ring(dev->dma.tx_ring_mcast);\n\tb43_dma_tx_resume_ring(dev->dma.tx_ring_AC_VO);\n\tb43_dma_tx_resume_ring(dev->dma.tx_ring_AC_VI);\n\tb43_dma_tx_resume_ring(dev->dma.tx_ring_AC_BE);\n\tb43_dma_tx_resume_ring(dev->dma.tx_ring_AC_BK);\n\tb43_power_saving_ctl_bits(dev, 0);\n}\n\nstatic void direct_fifo_rx(struct b43_wldev *dev, enum b43_dmatype type,\n\t\t\t   u16 mmio_base, bool enable)\n{\n\tu32 ctl;\n\n\tif (type == B43_DMA_64BIT) {\n\t\tctl = b43_read32(dev, mmio_base + B43_DMA64_RXCTL);\n\t\tctl &= ~B43_DMA64_RXDIRECTFIFO;\n\t\tif (enable)\n\t\t\tctl |= B43_DMA64_RXDIRECTFIFO;\n\t\tb43_write32(dev, mmio_base + B43_DMA64_RXCTL, ctl);\n\t} else {\n\t\tctl = b43_read32(dev, mmio_base + B43_DMA32_RXCTL);\n\t\tctl &= ~B43_DMA32_RXDIRECTFIFO;\n\t\tif (enable)\n\t\t\tctl |= B43_DMA32_RXDIRECTFIFO;\n\t\tb43_write32(dev, mmio_base + B43_DMA32_RXCTL, ctl);\n\t}\n}\n\n \nvoid b43_dma_direct_fifo_rx(struct b43_wldev *dev,\n\t\t\t    unsigned int engine_index, bool enable)\n{\n\tenum b43_dmatype type;\n\tu16 mmio_base;\n\n\ttype = b43_engine_type(dev);\n\n\tmmio_base = b43_dmacontroller_base(type, engine_index);\n\tdirect_fifo_rx(dev, type, mmio_base, enable);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}