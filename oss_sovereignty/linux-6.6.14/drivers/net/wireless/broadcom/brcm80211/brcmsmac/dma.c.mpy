{
  "module_name": "dma.c",
  "hash_id": "6b52c29a2527771148078e0835aed5bf4a70035ce48cb8341af66cd5e1c052ed",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireless/broadcom/brcm80211/brcmsmac/dma.c",
  "human_readable_source": " \n\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/pci.h>\n#include <net/cfg80211.h>\n#include <net/mac80211.h>\n\n#include <brcmu_utils.h>\n#include <aiutils.h>\n#include \"types.h\"\n#include \"main.h\"\n#include \"dma.h\"\n#include \"soc.h\"\n#include \"scb.h\"\n#include \"ampdu.h\"\n#include \"debug.h\"\n#include \"brcms_trace_events.h\"\n\n \n#define DMA64REGOFFS(field)\t\toffsetof(struct dma64regs, field)\n#define DMA64TXREGOFFS(di, field)\t(di->d64txregbase + DMA64REGOFFS(field))\n#define DMA64RXREGOFFS(di, field)\t(di->d64rxregbase + DMA64REGOFFS(field))\n\n \n#define D64RINGALIGN_BITS\t13\n#define\tD64MAXRINGSZ\t\t(1 << D64RINGALIGN_BITS)\n#define\tD64RINGALIGN\t\t(1 << D64RINGALIGN_BITS)\n\n#define\tD64MAXDD\t(D64MAXRINGSZ / sizeof(struct dma64desc))\n\n \n#define\tD64_XC_XE\t\t0x00000001\t \n#define\tD64_XC_SE\t\t0x00000002\t \n#define\tD64_XC_LE\t\t0x00000004\t \n#define\tD64_XC_FL\t\t0x00000010\t \n#define\tD64_XC_PD\t\t0x00000800\t \n#define\tD64_XC_AE\t\t0x00030000\t \n#define\tD64_XC_AE_SHIFT\t\t16\n\n \n#define\tD64_XP_LD_MASK\t\t0x00000fff\t \n\n \n#define\tD64_XS0_CD_MASK\t\t0x00001fff\t \n#define\tD64_XS0_XS_MASK\t\t0xf0000000\t \n#define\tD64_XS0_XS_SHIFT\t\t28\n#define\tD64_XS0_XS_DISABLED\t0x00000000\t \n#define\tD64_XS0_XS_ACTIVE\t0x10000000\t \n#define\tD64_XS0_XS_IDLE\t\t0x20000000\t \n#define\tD64_XS0_XS_STOPPED\t0x30000000\t \n#define\tD64_XS0_XS_SUSP\t\t0x40000000\t \n\n#define\tD64_XS1_AD_MASK\t\t0x00001fff\t \n#define\tD64_XS1_XE_MASK\t\t0xf0000000\t \n#define\tD64_XS1_XE_SHIFT\t\t28\n#define\tD64_XS1_XE_NOERR\t0x00000000\t \n#define\tD64_XS1_XE_DPE\t\t0x10000000\t \n#define\tD64_XS1_XE_DFU\t\t0x20000000\t \n#define\tD64_XS1_XE_DTE\t\t0x30000000\t \n#define\tD64_XS1_XE_DESRE\t0x40000000\t \n#define\tD64_XS1_XE_COREE\t0x50000000\t \n\n \n \n#define\tD64_RC_RE\t\t0x00000001\n \n#define\tD64_RC_RO_MASK\t\t0x000000fe\n#define\tD64_RC_RO_SHIFT\t\t1\n \n#define\tD64_RC_FM\t\t0x00000100\n \n#define\tD64_RC_SH\t\t0x00000200\n \n#define\tD64_RC_OC\t\t0x00000400\n \n#define\tD64_RC_PD\t\t0x00000800\n \n#define\tD64_RC_AE\t\t0x00030000\n#define\tD64_RC_AE_SHIFT\t\t16\n\n \n \n#define DMA_CTRL_PEN\t\t(1 << 0)\n \n#define DMA_CTRL_ROC\t\t(1 << 1)\n \n#define DMA_CTRL_RXMULTI\t(1 << 2)\n \n#define DMA_CTRL_UNFRAMED\t(1 << 3)\n\n \n#define\tD64_RP_LD_MASK\t\t0x00000fff\t \n\n \n#define\tD64_RS0_CD_MASK\t\t0x00001fff\t \n#define\tD64_RS0_RS_MASK\t\t0xf0000000\t \n#define\tD64_RS0_RS_SHIFT\t\t28\n#define\tD64_RS0_RS_DISABLED\t0x00000000\t \n#define\tD64_RS0_RS_ACTIVE\t0x10000000\t \n#define\tD64_RS0_RS_IDLE\t\t0x20000000\t \n#define\tD64_RS0_RS_STOPPED\t0x30000000\t \n#define\tD64_RS0_RS_SUSP\t\t0x40000000\t \n\n#define\tD64_RS1_AD_MASK\t\t0x0001ffff\t \n#define\tD64_RS1_RE_MASK\t\t0xf0000000\t \n#define\tD64_RS1_RE_SHIFT\t\t28\n#define\tD64_RS1_RE_NOERR\t0x00000000\t \n#define\tD64_RS1_RE_DPO\t\t0x10000000\t \n#define\tD64_RS1_RE_DFU\t\t0x20000000\t \n#define\tD64_RS1_RE_DTE\t\t0x30000000\t \n#define\tD64_RS1_RE_DESRE\t0x40000000\t \n#define\tD64_RS1_RE_COREE\t0x50000000\t \n\n \n#define\tD64_FA_OFF_MASK\t\t0xffff\t \n#define\tD64_FA_SEL_MASK\t\t0xf0000\t \n#define\tD64_FA_SEL_SHIFT\t16\n#define\tD64_FA_SEL_XDD\t\t0x00000\t \n#define\tD64_FA_SEL_XDP\t\t0x10000\t \n#define\tD64_FA_SEL_RDD\t\t0x40000\t \n#define\tD64_FA_SEL_RDP\t\t0x50000\t \n#define\tD64_FA_SEL_XFD\t\t0x80000\t \n#define\tD64_FA_SEL_XFP\t\t0x90000\t \n#define\tD64_FA_SEL_RFD\t\t0xc0000\t \n#define\tD64_FA_SEL_RFP\t\t0xd0000\t \n#define\tD64_FA_SEL_RSD\t\t0xe0000\t \n#define\tD64_FA_SEL_RSP\t\t0xf0000\t \n\n \n#define D64_CTRL_COREFLAGS\t0x0ff00000\t \n#define\tD64_CTRL1_EOT\t\t((u32)1 << 28)\t \n#define\tD64_CTRL1_IOC\t\t((u32)1 << 29)\t \n#define\tD64_CTRL1_EOF\t\t((u32)1 << 30)\t \n#define\tD64_CTRL1_SOF\t\t((u32)1 << 31)\t \n\n \n \n#define\tD64_CTRL2_BC_MASK\t0x00007fff\n \n#define\tD64_CTRL2_AE\t\t0x00030000\n#define\tD64_CTRL2_AE_SHIFT\t16\n \n#define D64_CTRL2_PARITY\t0x00040000\n\n \n#define\tD64_CTRL_CORE_MASK\t0x0ff00000\n\n#define D64_RX_FRM_STS_LEN\t0x0000ffff\t \n#define D64_RX_FRM_STS_OVFL\t0x00800000\t \n#define D64_RX_FRM_STS_DSCRCNT\t0x0f000000   \n#define D64_RX_FRM_STS_DATATYPE\t0xf0000000\t \n\n \n\n#define BCMEXTRAHDROOM 172\n\n#define\tMAXNAMEL\t8\t \n\n \n#define\tB2I(bytes, type)\t((bytes) / sizeof(type))\n#define\tI2B(index, type)\t((index) * sizeof(type))\n\n#define\tPCI32ADDR_HIGH\t\t0xc0000000\t \n#define\tPCI32ADDR_HIGH_SHIFT\t30\t \n\n#define\tPCI64ADDR_HIGH\t\t0x80000000\t \n#define\tPCI64ADDR_HIGH_SHIFT\t31\t \n\n \nstruct dma64desc {\n\t__le32 ctrl1;\t \n\t__le32 ctrl2;\t \n\t__le32 addrlow;\t \n\t__le32 addrhigh;  \n};\n\n \nstruct dma_info {\n\tstruct dma_pub dma;  \n\tchar name[MAXNAMEL];\t \n\n\tstruct bcma_device *core;\n\tstruct device *dmadev;\n\n\t \n\tstruct brcms_ampdu_session ampdu_session;\n\n\tbool dma64;\t \n\tbool addrext;\t \n\n\t \n\tuint d64txregbase;\n\t \n\tuint d64rxregbase;\n\t \n\tstruct dma64desc *txd64;\n\t \n\tstruct dma64desc *rxd64;\n\n\tu16 dmadesc_align;\t \n\n\tu16 ntxd;\t\t \n\tu16 txin;\t\t \n\tu16 txout;\t\t \n\t \n\tstruct sk_buff **txp;\n\t \n\tdma_addr_t txdpa;\n\t \n\tdma_addr_t txdpaorig;\n\tu16 txdalign;\t \n\tu32 txdalloc;\t \n\tu32 xmtptrbase;\t \n\n\tu16 nrxd;\t \n\tu16 rxin;\t \n\tu16 rxout;\t \n\t \n\tstruct sk_buff **rxp;\n\t \n\tdma_addr_t rxdpa;\n\t \n\tdma_addr_t rxdpaorig;\n\tu16 rxdalign;\t \n\tu32 rxdalloc;\t \n\tu32 rcvptrbase;\t \n\n\t \n\tunsigned int rxbufsize;\t \n\tuint rxextrahdrroom;\t \n\tuint nrxpost;\t\t \n\tunsigned int rxoffset;\t \n\t \n\tuint ddoffsetlow;\n\t \n\tuint ddoffsethigh;\n\t \n\tuint dataoffsetlow;\n\t \n\tuint dataoffsethigh;\n\t \n\tbool aligndesc_4k;\n};\n\n \nstatic u32 parity32(__le32 data)\n{\n\t \n\tu32 par_data = *(u32 *)&data;\n\n\tpar_data ^= par_data >> 16;\n\tpar_data ^= par_data >> 8;\n\tpar_data ^= par_data >> 4;\n\tpar_data ^= par_data >> 2;\n\tpar_data ^= par_data >> 1;\n\n\treturn par_data & 1;\n}\n\nstatic bool dma64_dd_parity(struct dma64desc *dd)\n{\n\treturn parity32(dd->addrlow ^ dd->addrhigh ^ dd->ctrl1 ^ dd->ctrl2);\n}\n\n \n\nstatic uint xxd(uint x, uint n)\n{\n\treturn x & (n - 1);  \n}\n\nstatic uint txd(struct dma_info *di, uint x)\n{\n\treturn xxd(x, di->ntxd);\n}\n\nstatic uint rxd(struct dma_info *di, uint x)\n{\n\treturn xxd(x, di->nrxd);\n}\n\nstatic uint nexttxd(struct dma_info *di, uint i)\n{\n\treturn txd(di, i + 1);\n}\n\nstatic uint prevtxd(struct dma_info *di, uint i)\n{\n\treturn txd(di, i - 1);\n}\n\nstatic uint nextrxd(struct dma_info *di, uint i)\n{\n\treturn rxd(di, i + 1);\n}\n\nstatic uint ntxdactive(struct dma_info *di, uint h, uint t)\n{\n\treturn txd(di, t-h);\n}\n\nstatic uint nrxdactive(struct dma_info *di, uint h, uint t)\n{\n\treturn rxd(di, t-h);\n}\n\nstatic uint _dma_ctrlflags(struct dma_info *di, uint mask, uint flags)\n{\n\tuint dmactrlflags;\n\n\tif (di == NULL)\n\t\treturn 0;\n\n\tdmactrlflags = di->dma.dmactrlflags;\n\tdmactrlflags &= ~mask;\n\tdmactrlflags |= flags;\n\n\t \n\tif (dmactrlflags & DMA_CTRL_PEN) {\n\t\tu32 control;\n\n\t\tcontrol = bcma_read32(di->core, DMA64TXREGOFFS(di, control));\n\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, control),\n\t\t      control | D64_XC_PD);\n\t\tif (bcma_read32(di->core, DMA64TXREGOFFS(di, control)) &\n\t\t    D64_XC_PD)\n\t\t\t \n\t\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, control),\n\t\t\t\t     control);\n\t\telse\n\t\t\t \n\t\t\tdmactrlflags &= ~DMA_CTRL_PEN;\n\t}\n\n\tdi->dma.dmactrlflags = dmactrlflags;\n\n\treturn dmactrlflags;\n}\n\nstatic bool _dma64_addrext(struct dma_info *di, uint ctrl_offset)\n{\n\tu32 w;\n\tbcma_set32(di->core, ctrl_offset, D64_XC_AE);\n\tw = bcma_read32(di->core, ctrl_offset);\n\tbcma_mask32(di->core, ctrl_offset, ~D64_XC_AE);\n\treturn (w & D64_XC_AE) == D64_XC_AE;\n}\n\n \nstatic bool _dma_isaddrext(struct dma_info *di)\n{\n\t \n\n\t \n\tif (di->d64txregbase != 0) {\n\t\tif (!_dma64_addrext(di, DMA64TXREGOFFS(di, control)))\n\t\t\tbrcms_dbg_dma(di->core,\n\t\t\t\t      \"%s: DMA64 tx doesn't have AE set\\n\",\n\t\t\t\t      di->name);\n\t\treturn true;\n\t} else if (di->d64rxregbase != 0) {\n\t\tif (!_dma64_addrext(di, DMA64RXREGOFFS(di, control)))\n\t\t\tbrcms_dbg_dma(di->core,\n\t\t\t\t      \"%s: DMA64 rx doesn't have AE set\\n\",\n\t\t\t\t      di->name);\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nstatic bool _dma_descriptor_align(struct dma_info *di)\n{\n\tu32 addrl;\n\n\t \n\tif (di->d64txregbase != 0) {\n\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, addrlow), 0xff0);\n\t\taddrl = bcma_read32(di->core, DMA64TXREGOFFS(di, addrlow));\n\t\tif (addrl != 0)\n\t\t\treturn false;\n\t} else if (di->d64rxregbase != 0) {\n\t\tbcma_write32(di->core, DMA64RXREGOFFS(di, addrlow), 0xff0);\n\t\taddrl = bcma_read32(di->core, DMA64RXREGOFFS(di, addrlow));\n\t\tif (addrl != 0)\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\n \nstatic void *dma_alloc_consistent(struct dma_info *di, uint size,\n\t\t\t\t  u16 align_bits, uint *alloced,\n\t\t\t\t  dma_addr_t *pap)\n{\n\tif (align_bits) {\n\t\tu16 align = (1 << align_bits);\n\t\tif (!IS_ALIGNED(PAGE_SIZE, align))\n\t\t\tsize += align;\n\t\t*alloced = size;\n\t}\n\treturn dma_alloc_coherent(di->dmadev, size, pap, GFP_ATOMIC);\n}\n\nstatic\nu8 dma_align_sizetobits(uint size)\n{\n\tu8 bitpos = 0;\n\twhile (size >>= 1)\n\t\tbitpos++;\n\treturn bitpos;\n}\n\n \nstatic void *dma_ringalloc(struct dma_info *di, u32 boundary, uint size,\n\t\t\t   u16 *alignbits, uint *alloced,\n\t\t\t   dma_addr_t *descpa)\n{\n\tvoid *va;\n\tu32 desc_strtaddr;\n\tu32 alignbytes = 1 << *alignbits;\n\n\tva = dma_alloc_consistent(di, size, *alignbits, alloced, descpa);\n\n\tif (NULL == va)\n\t\treturn NULL;\n\n\tdesc_strtaddr = (u32) roundup((unsigned long)va, alignbytes);\n\tif (((desc_strtaddr + size - 1) & boundary) != (desc_strtaddr\n\t\t\t\t\t\t\t& boundary)) {\n\t\t*alignbits = dma_align_sizetobits(size);\n\t\tdma_free_coherent(di->dmadev, size, va, *descpa);\n\t\tva = dma_alloc_consistent(di, size, *alignbits,\n\t\t\talloced, descpa);\n\t}\n\treturn va;\n}\n\nstatic bool dma64_alloc(struct dma_info *di, uint direction)\n{\n\tu16 size;\n\tuint ddlen;\n\tvoid *va;\n\tuint alloced = 0;\n\tu16 align;\n\tu16 align_bits;\n\n\tddlen = sizeof(struct dma64desc);\n\n\tsize = (direction == DMA_TX) ? (di->ntxd * ddlen) : (di->nrxd * ddlen);\n\talign_bits = di->dmadesc_align;\n\talign = (1 << align_bits);\n\n\tif (direction == DMA_TX) {\n\t\tva = dma_ringalloc(di, D64RINGALIGN, size, &align_bits,\n\t\t\t&alloced, &di->txdpaorig);\n\t\tif (va == NULL) {\n\t\t\tbrcms_dbg_dma(di->core,\n\t\t\t\t      \"%s: DMA_ALLOC_CONSISTENT(ntxd) failed\\n\",\n\t\t\t\t      di->name);\n\t\t\treturn false;\n\t\t}\n\t\talign = (1 << align_bits);\n\t\tdi->txd64 = (struct dma64desc *)\n\t\t\t\t\troundup((unsigned long)va, align);\n\t\tdi->txdalign = (uint) ((s8 *)di->txd64 - (s8 *) va);\n\t\tdi->txdpa = di->txdpaorig + di->txdalign;\n\t\tdi->txdalloc = alloced;\n\t} else {\n\t\tva = dma_ringalloc(di, D64RINGALIGN, size, &align_bits,\n\t\t\t&alloced, &di->rxdpaorig);\n\t\tif (va == NULL) {\n\t\t\tbrcms_dbg_dma(di->core,\n\t\t\t\t      \"%s: DMA_ALLOC_CONSISTENT(nrxd) failed\\n\",\n\t\t\t\t      di->name);\n\t\t\treturn false;\n\t\t}\n\t\talign = (1 << align_bits);\n\t\tdi->rxd64 = (struct dma64desc *)\n\t\t\t\t\troundup((unsigned long)va, align);\n\t\tdi->rxdalign = (uint) ((s8 *)di->rxd64 - (s8 *) va);\n\t\tdi->rxdpa = di->rxdpaorig + di->rxdalign;\n\t\tdi->rxdalloc = alloced;\n\t}\n\n\treturn true;\n}\n\nstatic bool _dma_alloc(struct dma_info *di, uint direction)\n{\n\treturn dma64_alloc(di, direction);\n}\n\nstruct dma_pub *dma_attach(char *name, struct brcms_c_info *wlc,\n\t\t\t   uint txregbase, uint rxregbase, uint ntxd, uint nrxd,\n\t\t\t   uint rxbufsize, int rxextheadroom,\n\t\t\t   uint nrxpost, uint rxoffset)\n{\n\tstruct si_pub *sih = wlc->hw->sih;\n\tstruct bcma_device *core = wlc->hw->d11core;\n\tstruct dma_info *di;\n\tu8 rev = core->id.rev;\n\tuint size;\n\tstruct si_info *sii = container_of(sih, struct si_info, pub);\n\n\t \n\tdi = kzalloc(sizeof(struct dma_info), GFP_ATOMIC);\n\tif (di == NULL)\n\t\treturn NULL;\n\n\tdi->dma64 =\n\t\t((bcma_aread32(core, BCMA_IOST) & SISF_DMA64) == SISF_DMA64);\n\n\t \n\tdi->core = core;\n\tdi->d64txregbase = txregbase;\n\tdi->d64rxregbase = rxregbase;\n\n\t \n\t_dma_ctrlflags(di, DMA_CTRL_ROC | DMA_CTRL_PEN, 0);\n\n\tbrcms_dbg_dma(di->core, \"%s: %s flags 0x%x ntxd %d nrxd %d \"\n\t\t      \"rxbufsize %d rxextheadroom %d nrxpost %d rxoffset %d \"\n\t\t      \"txregbase %u rxregbase %u\\n\", name, \"DMA64\",\n\t\t      di->dma.dmactrlflags, ntxd, nrxd, rxbufsize,\n\t\t      rxextheadroom, nrxpost, rxoffset, txregbase, rxregbase);\n\n\t \n\tstrncpy(di->name, name, MAXNAMEL);\n\tdi->name[MAXNAMEL - 1] = '\\0';\n\n\tdi->dmadev = core->dma_dev;\n\n\t \n\tdi->ntxd = (u16) ntxd;\n\tdi->nrxd = (u16) nrxd;\n\n\t \n\tdi->rxextrahdrroom =\n\t    (rxextheadroom == -1) ? BCMEXTRAHDROOM : rxextheadroom;\n\tif (rxbufsize > BCMEXTRAHDROOM)\n\t\tdi->rxbufsize = (u16) (rxbufsize - di->rxextrahdrroom);\n\telse\n\t\tdi->rxbufsize = (u16) rxbufsize;\n\n\tdi->nrxpost = (u16) nrxpost;\n\tdi->rxoffset = (u8) rxoffset;\n\n\t \n\tdi->ddoffsetlow = 0;\n\tdi->dataoffsetlow = 0;\n\t \n\tif (sii->icbus->hosttype == BCMA_HOSTTYPE_PCI) {\n\t\t \n\t\tdi->ddoffsetlow = 0;\n\t\tdi->ddoffsethigh = SI_PCIE_DMA_H32;\n\t}\n\tdi->dataoffsetlow = di->ddoffsetlow;\n\tdi->dataoffsethigh = di->ddoffsethigh;\n\n\t \n\tif ((core->id.id == BCMA_CORE_SDIO_DEV)\n\t    && ((rev > 0) && (rev <= 2)))\n\t\tdi->addrext = false;\n\telse if ((core->id.id == BCMA_CORE_I2S) &&\n\t\t ((rev == 0) || (rev == 1)))\n\t\tdi->addrext = false;\n\telse\n\t\tdi->addrext = _dma_isaddrext(di);\n\n\t \n\tdi->aligndesc_4k = _dma_descriptor_align(di);\n\tif (di->aligndesc_4k) {\n\t\tdi->dmadesc_align = D64RINGALIGN_BITS;\n\t\tif ((ntxd < D64MAXDD / 2) && (nrxd < D64MAXDD / 2))\n\t\t\t \n\t\t\tdi->dmadesc_align = D64RINGALIGN_BITS - 1;\n\t} else {\n\t\tdi->dmadesc_align = 4;\t \n\t}\n\n\tbrcms_dbg_dma(di->core, \"DMA descriptor align_needed %d, align %d\\n\",\n\t\t      di->aligndesc_4k, di->dmadesc_align);\n\n\t \n\tif (ntxd) {\n\t\tsize = ntxd * sizeof(void *);\n\t\tdi->txp = kzalloc(size, GFP_ATOMIC);\n\t\tif (di->txp == NULL)\n\t\t\tgoto fail;\n\t}\n\n\t \n\tif (nrxd) {\n\t\tsize = nrxd * sizeof(void *);\n\t\tdi->rxp = kzalloc(size, GFP_ATOMIC);\n\t\tif (di->rxp == NULL)\n\t\t\tgoto fail;\n\t}\n\n\t \n\tif (ntxd) {\n\t\tif (!_dma_alloc(di, DMA_TX))\n\t\t\tgoto fail;\n\t}\n\n\t \n\tif (nrxd) {\n\t\tif (!_dma_alloc(di, DMA_RX))\n\t\t\tgoto fail;\n\t}\n\n\tif ((di->ddoffsetlow != 0) && !di->addrext) {\n\t\tif (di->txdpa > SI_PCI_DMA_SZ) {\n\t\t\tbrcms_dbg_dma(di->core,\n\t\t\t\t      \"%s: txdpa 0x%x: addrext not supported\\n\",\n\t\t\t\t      di->name, (u32)di->txdpa);\n\t\t\tgoto fail;\n\t\t}\n\t\tif (di->rxdpa > SI_PCI_DMA_SZ) {\n\t\t\tbrcms_dbg_dma(di->core,\n\t\t\t\t      \"%s: rxdpa 0x%x: addrext not supported\\n\",\n\t\t\t\t      di->name, (u32)di->rxdpa);\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\t \n\tbrcms_c_ampdu_reset_session(&di->ampdu_session, wlc);\n\n\tbrcms_dbg_dma(di->core,\n\t\t      \"ddoffsetlow 0x%x ddoffsethigh 0x%x dataoffsetlow 0x%x dataoffsethigh 0x%x addrext %d\\n\",\n\t\t      di->ddoffsetlow, di->ddoffsethigh,\n\t\t      di->dataoffsetlow, di->dataoffsethigh,\n\t\t      di->addrext);\n\n\treturn (struct dma_pub *) di;\n\n fail:\n\tdma_detach((struct dma_pub *)di);\n\treturn NULL;\n}\n\nstatic inline void\ndma64_dd_upd(struct dma_info *di, struct dma64desc *ddring,\n\t     dma_addr_t pa, uint outidx, u32 *flags, u32 bufcount)\n{\n\tu32 ctrl2 = bufcount & D64_CTRL2_BC_MASK;\n\n\t \n\tif ((di->dataoffsetlow == 0) || !(pa & PCI32ADDR_HIGH)) {\n\t\tddring[outidx].addrlow = cpu_to_le32(pa + di->dataoffsetlow);\n\t\tddring[outidx].addrhigh = cpu_to_le32(di->dataoffsethigh);\n\t\tddring[outidx].ctrl1 = cpu_to_le32(*flags);\n\t\tddring[outidx].ctrl2 = cpu_to_le32(ctrl2);\n\t} else {\n\t\t \n\t\tu32 ae;\n\n\t\tae = (pa & PCI32ADDR_HIGH) >> PCI32ADDR_HIGH_SHIFT;\n\t\tpa &= ~PCI32ADDR_HIGH;\n\n\t\tctrl2 |= (ae << D64_CTRL2_AE_SHIFT) & D64_CTRL2_AE;\n\t\tddring[outidx].addrlow = cpu_to_le32(pa + di->dataoffsetlow);\n\t\tddring[outidx].addrhigh = cpu_to_le32(di->dataoffsethigh);\n\t\tddring[outidx].ctrl1 = cpu_to_le32(*flags);\n\t\tddring[outidx].ctrl2 = cpu_to_le32(ctrl2);\n\t}\n\tif (di->dma.dmactrlflags & DMA_CTRL_PEN) {\n\t\tif (dma64_dd_parity(&ddring[outidx]))\n\t\t\tddring[outidx].ctrl2 =\n\t\t\t     cpu_to_le32(ctrl2 | D64_CTRL2_PARITY);\n\t}\n}\n\n \nvoid dma_detach(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\t \n\tif (di->txd64)\n\t\tdma_free_coherent(di->dmadev, di->txdalloc,\n\t\t\t\t  ((s8 *)di->txd64 - di->txdalign),\n\t\t\t\t  (di->txdpaorig));\n\tif (di->rxd64)\n\t\tdma_free_coherent(di->dmadev, di->rxdalloc,\n\t\t\t\t  ((s8 *)di->rxd64 - di->rxdalign),\n\t\t\t\t  (di->rxdpaorig));\n\n\t \n\tkfree(di->txp);\n\tkfree(di->rxp);\n\n\t \n\tkfree(di);\n\n}\n\n \nstatic void\n_dma_ddtable_init(struct dma_info *di, uint direction, dma_addr_t pa)\n{\n\tif (!di->aligndesc_4k) {\n\t\tif (direction == DMA_TX)\n\t\t\tdi->xmtptrbase = pa;\n\t\telse\n\t\t\tdi->rcvptrbase = pa;\n\t}\n\n\tif ((di->ddoffsetlow == 0)\n\t    || !(pa & PCI32ADDR_HIGH)) {\n\t\tif (direction == DMA_TX) {\n\t\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, addrlow),\n\t\t\t\t     pa + di->ddoffsetlow);\n\t\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, addrhigh),\n\t\t\t\t     di->ddoffsethigh);\n\t\t} else {\n\t\t\tbcma_write32(di->core, DMA64RXREGOFFS(di, addrlow),\n\t\t\t\t     pa + di->ddoffsetlow);\n\t\t\tbcma_write32(di->core, DMA64RXREGOFFS(di, addrhigh),\n\t\t\t\t     di->ddoffsethigh);\n\t\t}\n\t} else {\n\t\t \n\t\tu32 ae;\n\n\t\t \n\t\tae = (pa & PCI32ADDR_HIGH) >> PCI32ADDR_HIGH_SHIFT;\n\t\tpa &= ~PCI32ADDR_HIGH;\n\n\t\tif (direction == DMA_TX) {\n\t\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, addrlow),\n\t\t\t\t     pa + di->ddoffsetlow);\n\t\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, addrhigh),\n\t\t\t\t     di->ddoffsethigh);\n\t\t\tbcma_maskset32(di->core, DMA64TXREGOFFS(di, control),\n\t\t\t\t       D64_XC_AE, (ae << D64_XC_AE_SHIFT));\n\t\t} else {\n\t\t\tbcma_write32(di->core, DMA64RXREGOFFS(di, addrlow),\n\t\t\t\t     pa + di->ddoffsetlow);\n\t\t\tbcma_write32(di->core, DMA64RXREGOFFS(di, addrhigh),\n\t\t\t\t     di->ddoffsethigh);\n\t\t\tbcma_maskset32(di->core, DMA64RXREGOFFS(di, control),\n\t\t\t\t       D64_RC_AE, (ae << D64_RC_AE_SHIFT));\n\t\t}\n\t}\n}\n\nstatic void _dma_rxenable(struct dma_info *di)\n{\n\tuint dmactrlflags = di->dma.dmactrlflags;\n\tu32 control;\n\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\tcontrol = D64_RC_RE | (bcma_read32(di->core,\n\t\t\t\t\t   DMA64RXREGOFFS(di, control)) &\n\t\t\t       D64_RC_AE);\n\n\tif ((dmactrlflags & DMA_CTRL_PEN) == 0)\n\t\tcontrol |= D64_RC_PD;\n\n\tif (dmactrlflags & DMA_CTRL_ROC)\n\t\tcontrol |= D64_RC_OC;\n\n\tbcma_write32(di->core, DMA64RXREGOFFS(di, control),\n\t\t((di->rxoffset << D64_RC_RO_SHIFT) | control));\n}\n\nvoid dma_rxinit(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\tif (di->nrxd == 0)\n\t\treturn;\n\n\tdi->rxin = di->rxout = 0;\n\n\t \n\tmemset(di->rxd64, '\\0', di->nrxd * sizeof(struct dma64desc));\n\n\t \n\tif (!di->aligndesc_4k)\n\t\t_dma_ddtable_init(di, DMA_RX, di->rxdpa);\n\n\t_dma_rxenable(di);\n\n\tif (di->aligndesc_4k)\n\t\t_dma_ddtable_init(di, DMA_RX, di->rxdpa);\n}\n\nstatic struct sk_buff *dma64_getnextrxp(struct dma_info *di, bool forceall)\n{\n\tuint i, curr;\n\tstruct sk_buff *rxp;\n\tdma_addr_t pa;\n\n\ti = di->rxin;\n\n\t \n\tif (i == di->rxout)\n\t\treturn NULL;\n\n\tcurr =\n\t    B2I(((bcma_read32(di->core,\n\t\t\t      DMA64RXREGOFFS(di, status0)) & D64_RS0_CD_MASK) -\n\t\t di->rcvptrbase) & D64_RS0_CD_MASK, struct dma64desc);\n\n\t \n\tif (!forceall && (i == curr))\n\t\treturn NULL;\n\n\t \n\trxp = di->rxp[i];\n\tdi->rxp[i] = NULL;\n\n\tpa = le32_to_cpu(di->rxd64[i].addrlow) - di->dataoffsetlow;\n\n\t \n\tdma_unmap_single(di->dmadev, pa, di->rxbufsize, DMA_FROM_DEVICE);\n\n\tdi->rxd64[i].addrlow = cpu_to_le32(0xdeadbeef);\n\tdi->rxd64[i].addrhigh = cpu_to_le32(0xdeadbeef);\n\n\tdi->rxin = nextrxd(di, i);\n\n\treturn rxp;\n}\n\nstatic struct sk_buff *_dma_getnextrxp(struct dma_info *di, bool forceall)\n{\n\tif (di->nrxd == 0)\n\t\treturn NULL;\n\n\treturn dma64_getnextrxp(di, forceall);\n}\n\n \nint dma_rx(struct dma_pub *pub, struct sk_buff_head *skb_list)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tstruct sk_buff_head dma_frames;\n\tstruct sk_buff *p, *next;\n\tuint len;\n\tuint pkt_len;\n\tint resid = 0;\n\tint pktcnt = 1;\n\n\tskb_queue_head_init(&dma_frames);\n next_frame:\n\tp = _dma_getnextrxp(di, false);\n\tif (p == NULL)\n\t\treturn 0;\n\n\tlen = le16_to_cpu(*(__le16 *) (p->data));\n\tbrcms_dbg_dma(di->core, \"%s: dma_rx len %d\\n\", di->name, len);\n\tdma_spin_for_len(len, p);\n\n\t \n\tpkt_len = min((di->rxoffset + len), di->rxbufsize);\n\t__skb_trim(p, pkt_len);\n\tskb_queue_tail(&dma_frames, p);\n\tresid = len - (di->rxbufsize - di->rxoffset);\n\n\t \n\tif (resid > 0) {\n\t\twhile ((resid > 0) && (p = _dma_getnextrxp(di, false))) {\n\t\t\tpkt_len = min_t(uint, resid, di->rxbufsize);\n\t\t\t__skb_trim(p, pkt_len);\n\t\t\tskb_queue_tail(&dma_frames, p);\n\t\t\tresid -= di->rxbufsize;\n\t\t\tpktcnt++;\n\t\t}\n\n#ifdef DEBUG\n\t\tif (resid > 0) {\n\t\t\tuint cur;\n\t\t\tcur =\n\t\t\t    B2I(((bcma_read32(di->core,\n\t\t\t\t\t      DMA64RXREGOFFS(di, status0)) &\n\t\t\t\t  D64_RS0_CD_MASK) - di->rcvptrbase) &\n\t\t\t\tD64_RS0_CD_MASK, struct dma64desc);\n\t\t\tbrcms_dbg_dma(di->core,\n\t\t\t\t      \"rxin %d rxout %d, hw_curr %d\\n\",\n\t\t\t\t      di->rxin, di->rxout, cur);\n\t\t}\n#endif\t\t\t\t \n\n\t\tif ((di->dma.dmactrlflags & DMA_CTRL_RXMULTI) == 0) {\n\t\t\tbrcms_dbg_dma(di->core, \"%s: bad frame length (%d)\\n\",\n\t\t\t\t      di->name, len);\n\t\t\tskb_queue_walk_safe(&dma_frames, p, next) {\n\t\t\t\tskb_unlink(p, &dma_frames);\n\t\t\t\tbrcmu_pkt_buf_free_skb(p);\n\t\t\t}\n\t\t\tdi->dma.rxgiants++;\n\t\t\tpktcnt = 1;\n\t\t\tgoto next_frame;\n\t\t}\n\t}\n\n\tskb_queue_splice_tail(&dma_frames, skb_list);\n\treturn pktcnt;\n}\n\nstatic bool dma64_rxidle(struct dma_info *di)\n{\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\tif (di->nrxd == 0)\n\t\treturn true;\n\n\treturn ((bcma_read32(di->core,\n\t\t\t     DMA64RXREGOFFS(di, status0)) & D64_RS0_CD_MASK) ==\n\t\t(bcma_read32(di->core, DMA64RXREGOFFS(di, ptr)) &\n\t\t D64_RS0_CD_MASK));\n}\n\nstatic bool dma64_txidle(struct dma_info *di)\n{\n\tif (di->ntxd == 0)\n\t\treturn true;\n\n\treturn ((bcma_read32(di->core,\n\t\t\t     DMA64TXREGOFFS(di, status0)) & D64_XS0_CD_MASK) ==\n\t\t(bcma_read32(di->core, DMA64TXREGOFFS(di, ptr)) &\n\t\t D64_XS0_CD_MASK));\n}\n\n \nbool dma_rxfill(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tstruct sk_buff *p;\n\tu16 rxin, rxout;\n\tu32 flags = 0;\n\tuint n;\n\tuint i;\n\tdma_addr_t pa;\n\tuint extra_offset = 0;\n\tbool ring_empty;\n\n\tring_empty = false;\n\n\t \n\n\trxin = di->rxin;\n\trxout = di->rxout;\n\n\tn = di->nrxpost - nrxdactive(di, rxin, rxout);\n\n\tbrcms_dbg_dma(di->core, \"%s: post %d\\n\", di->name, n);\n\n\tif (di->rxbufsize > BCMEXTRAHDROOM)\n\t\textra_offset = di->rxextrahdrroom;\n\n\tfor (i = 0; i < n; i++) {\n\t\t \n\t\tp = brcmu_pkt_buf_get_skb(di->rxbufsize + extra_offset);\n\n\t\tif (p == NULL) {\n\t\t\tbrcms_dbg_dma(di->core, \"%s: out of rxbufs\\n\",\n\t\t\t\t      di->name);\n\t\t\tif (i == 0 && dma64_rxidle(di)) {\n\t\t\t\tbrcms_dbg_dma(di->core, \"%s: ring is empty !\\n\",\n\t\t\t\t\t      di->name);\n\t\t\t\tring_empty = true;\n\t\t\t}\n\t\t\tdi->dma.rxnobuf++;\n\t\t\tbreak;\n\t\t}\n\t\t \n\t\tif (extra_offset)\n\t\t\tskb_pull(p, extra_offset);\n\n\t\t \n\t\t*(u32 *) (p->data) = 0;\n\n\t\tpa = dma_map_single(di->dmadev, p->data, di->rxbufsize,\n\t\t\t\t    DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(di->dmadev, pa)) {\n\t\t\tbrcmu_pkt_buf_free_skb(p);\n\t\t\treturn false;\n\t\t}\n\n\t\t \n\t\tdi->rxp[rxout] = p;\n\n\t\t \n\t\tflags = 0;\n\t\tif (rxout == (di->nrxd - 1))\n\t\t\tflags = D64_CTRL1_EOT;\n\n\t\tdma64_dd_upd(di, di->rxd64, pa, rxout, &flags,\n\t\t\t     di->rxbufsize);\n\t\trxout = nextrxd(di, rxout);\n\t}\n\n\tdi->rxout = rxout;\n\n\t \n\tbcma_write32(di->core, DMA64RXREGOFFS(di, ptr),\n\t      di->rcvptrbase + I2B(rxout, struct dma64desc));\n\n\treturn ring_empty;\n}\n\nvoid dma_rxreclaim(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tstruct sk_buff *p;\n\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\twhile ((p = _dma_getnextrxp(di, true)))\n\t\tbrcmu_pkt_buf_free_skb(p);\n}\n\nvoid dma_counterreset(struct dma_pub *pub)\n{\n\t \n\tpub->rxgiants = 0;\n\tpub->rxnobuf = 0;\n\tpub->txnobuf = 0;\n}\n\n \nunsigned long dma_getvar(struct dma_pub *pub, const char *name)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\n\tif (!strcmp(name, \"&txavail\"))\n\t\treturn (unsigned long)&(di->dma.txavail);\n\treturn 0;\n}\n\n \n\nvoid dma_txinit(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tu32 control = D64_XC_XE;\n\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\tif (di->ntxd == 0)\n\t\treturn;\n\n\tdi->txin = di->txout = 0;\n\tdi->dma.txavail = di->ntxd - 1;\n\n\t \n\tmemset(di->txd64, '\\0', (di->ntxd * sizeof(struct dma64desc)));\n\n\t \n\tif (!di->aligndesc_4k)\n\t\t_dma_ddtable_init(di, DMA_TX, di->txdpa);\n\n\tif ((di->dma.dmactrlflags & DMA_CTRL_PEN) == 0)\n\t\tcontrol |= D64_XC_PD;\n\tbcma_set32(di->core, DMA64TXREGOFFS(di, control), control);\n\n\t \n\tif (di->aligndesc_4k)\n\t\t_dma_ddtable_init(di, DMA_TX, di->txdpa);\n}\n\nvoid dma_txsuspend(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\tif (di->ntxd == 0)\n\t\treturn;\n\n\tbcma_set32(di->core, DMA64TXREGOFFS(di, control), D64_XC_SE);\n}\n\nvoid dma_txresume(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\n\tbrcms_dbg_dma(di->core, \"%s:\\n\", di->name);\n\n\tif (di->ntxd == 0)\n\t\treturn;\n\n\tbcma_mask32(di->core, DMA64TXREGOFFS(di, control), ~D64_XC_SE);\n}\n\nbool dma_txsuspended(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\n\treturn (di->ntxd == 0) ||\n\t       ((bcma_read32(di->core,\n\t\t\t     DMA64TXREGOFFS(di, control)) & D64_XC_SE) ==\n\t\tD64_XC_SE);\n}\n\nvoid dma_txreclaim(struct dma_pub *pub, enum txd_range range)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tstruct sk_buff *p;\n\n\tbrcms_dbg_dma(di->core, \"%s: %s\\n\",\n\t\t      di->name,\n\t\t      range == DMA_RANGE_ALL ? \"all\" :\n\t\t      range == DMA_RANGE_TRANSMITTED ? \"transmitted\" :\n\t\t      \"transferred\");\n\n\tif (di->txin == di->txout)\n\t\treturn;\n\n\twhile ((p = dma_getnexttxp(pub, range))) {\n\t\t \n\t\tif (!(di->dma.dmactrlflags & DMA_CTRL_UNFRAMED))\n\t\t\tbrcmu_pkt_buf_free_skb(p);\n\t}\n}\n\nbool dma_txreset(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tu32 status;\n\n\tif (di->ntxd == 0)\n\t\treturn true;\n\n\t \n\tbcma_write32(di->core, DMA64TXREGOFFS(di, control), D64_XC_SE);\n\tSPINWAIT(((status =\n\t\t   (bcma_read32(di->core, DMA64TXREGOFFS(di, status0)) &\n\t\t    D64_XS0_XS_MASK)) != D64_XS0_XS_DISABLED) &&\n\t\t  (status != D64_XS0_XS_IDLE) && (status != D64_XS0_XS_STOPPED),\n\t\t 10000);\n\n\tbcma_write32(di->core, DMA64TXREGOFFS(di, control), 0);\n\tSPINWAIT(((status =\n\t\t   (bcma_read32(di->core, DMA64TXREGOFFS(di, status0)) &\n\t\t    D64_XS0_XS_MASK)) != D64_XS0_XS_DISABLED), 10000);\n\n\t \n\tudelay(300);\n\n\treturn status == D64_XS0_XS_DISABLED;\n}\n\nbool dma_rxreset(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tu32 status;\n\n\tif (di->nrxd == 0)\n\t\treturn true;\n\n\tbcma_write32(di->core, DMA64RXREGOFFS(di, control), 0);\n\tSPINWAIT(((status =\n\t\t   (bcma_read32(di->core, DMA64RXREGOFFS(di, status0)) &\n\t\t    D64_RS0_RS_MASK)) != D64_RS0_RS_DISABLED), 10000);\n\n\treturn status == D64_RS0_RS_DISABLED;\n}\n\nstatic void dma_txenq(struct dma_info *di, struct sk_buff *p)\n{\n\tunsigned char *data;\n\tuint len;\n\tu16 txout;\n\tu32 flags = 0;\n\tdma_addr_t pa;\n\n\ttxout = di->txout;\n\n\tif (WARN_ON(nexttxd(di, txout) == di->txin))\n\t\treturn;\n\n\t \n\tdata = p->data;\n\tlen = p->len;\n\n\t \n\tpa = dma_map_single(di->dmadev, data, len, DMA_TO_DEVICE);\n\t \n\tif (dma_mapping_error(di->dmadev, pa)) {\n\t\tbrcmu_pkt_buf_free_skb(p);\n\t\treturn;\n\t}\n\t \n\tflags = D64_CTRL1_SOF | D64_CTRL1_IOC | D64_CTRL1_EOF;\n\tif (txout == (di->ntxd - 1))\n\t\tflags |= D64_CTRL1_EOT;\n\n\tdma64_dd_upd(di, di->txd64, pa, txout, &flags, len);\n\n\ttxout = nexttxd(di, txout);\n\n\t \n\tdi->txp[prevtxd(di, txout)] = p;\n\n\t \n\tdi->txout = txout;\n}\n\nstatic void ampdu_finalize(struct dma_info *di)\n{\n\tstruct brcms_ampdu_session *session = &di->ampdu_session;\n\tstruct sk_buff *p;\n\n\ttrace_brcms_ampdu_session(&session->wlc->hw->d11core->dev,\n\t\t\t\t  session->max_ampdu_len,\n\t\t\t\t  session->max_ampdu_frames,\n\t\t\t\t  session->ampdu_len,\n\t\t\t\t  skb_queue_len(&session->skb_list),\n\t\t\t\t  session->dma_len);\n\n\tif (WARN_ON(skb_queue_empty(&session->skb_list)))\n\t\treturn;\n\n\tbrcms_c_ampdu_finalize(session);\n\n\twhile (!skb_queue_empty(&session->skb_list)) {\n\t\tp = skb_dequeue(&session->skb_list);\n\t\tdma_txenq(di, p);\n\t}\n\n\tbcma_write32(di->core, DMA64TXREGOFFS(di, ptr),\n\t\t     di->xmtptrbase + I2B(di->txout, struct dma64desc));\n\tbrcms_c_ampdu_reset_session(session, session->wlc);\n}\n\nstatic void prep_ampdu_frame(struct dma_info *di, struct sk_buff *p)\n{\n\tstruct brcms_ampdu_session *session = &di->ampdu_session;\n\tint ret;\n\n\tret = brcms_c_ampdu_add_frame(session, p);\n\tif (ret == -ENOSPC) {\n\t\t \n\t\tampdu_finalize(di);\n\t\tret = brcms_c_ampdu_add_frame(session, p);\n\t}\n\n\tWARN_ON(ret);\n}\n\n \nstatic void dma_update_txavail(struct dma_info *di)\n{\n\t \n\tdi->dma.txavail = di->ntxd - ntxdactive(di, di->txin, di->txout) -\n\t\t\t  skb_queue_len(&di->ampdu_session.skb_list) - 1;\n}\n\n \nint dma_txfast(struct brcms_c_info *wlc, struct dma_pub *pub,\n\t       struct sk_buff *p)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tstruct brcms_ampdu_session *session = &di->ampdu_session;\n\tstruct ieee80211_tx_info *tx_info;\n\tbool is_ampdu;\n\n\t \n\tif (p->len == 0)\n\t\treturn 0;\n\n\t \n\tif (di->dma.txavail == 0 || nexttxd(di, di->txout) == di->txin)\n\t\tgoto outoftxd;\n\n\ttx_info = IEEE80211_SKB_CB(p);\n\tis_ampdu = tx_info->flags & IEEE80211_TX_CTL_AMPDU;\n\tif (is_ampdu)\n\t\tprep_ampdu_frame(di, p);\n\telse\n\t\tdma_txenq(di, p);\n\n\t \n\tdma_update_txavail(di);\n\n\t \n\tif (is_ampdu) {\n\t\t \n\t\tif (skb_queue_len(&session->skb_list) == session->max_ampdu_frames ||\n\t\t    di->dma.txavail == 0 || dma64_txidle(di))\n\t\t\tampdu_finalize(di);\n\t} else {\n\t\tbcma_write32(di->core, DMA64TXREGOFFS(di, ptr),\n\t\t\t     di->xmtptrbase + I2B(di->txout, struct dma64desc));\n\t}\n\n\treturn 0;\n\n outoftxd:\n\tbrcms_dbg_dma(di->core, \"%s: out of txds !!!\\n\", di->name);\n\tbrcmu_pkt_buf_free_skb(p);\n\tdi->dma.txavail = 0;\n\tdi->dma.txnobuf++;\n\treturn -ENOSPC;\n}\n\nvoid dma_txflush(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tstruct brcms_ampdu_session *session = &di->ampdu_session;\n\n\tif (!skb_queue_empty(&session->skb_list))\n\t\tampdu_finalize(di);\n}\n\nint dma_txpending(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\treturn ntxdactive(di, di->txin, di->txout);\n}\n\n \nvoid dma_kick_tx(struct dma_pub *pub)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tstruct brcms_ampdu_session *session = &di->ampdu_session;\n\n\tif (!skb_queue_empty(&session->skb_list) && dma64_txidle(di))\n\t\tampdu_finalize(di);\n}\n\n \nstruct sk_buff *dma_getnexttxp(struct dma_pub *pub, enum txd_range range)\n{\n\tstruct dma_info *di = container_of(pub, struct dma_info, dma);\n\tu16 start, end, i;\n\tu16 active_desc;\n\tstruct sk_buff *txp;\n\n\tbrcms_dbg_dma(di->core, \"%s: %s\\n\",\n\t\t      di->name,\n\t\t      range == DMA_RANGE_ALL ? \"all\" :\n\t\t      range == DMA_RANGE_TRANSMITTED ? \"transmitted\" :\n\t\t      \"transferred\");\n\n\tif (di->ntxd == 0)\n\t\treturn NULL;\n\n\ttxp = NULL;\n\n\tstart = di->txin;\n\tif (range == DMA_RANGE_ALL)\n\t\tend = di->txout;\n\telse {\n\t\tend = (u16) (B2I(((bcma_read32(di->core,\n\t\t\t\t\t       DMA64TXREGOFFS(di, status0)) &\n\t\t\t\t   D64_XS0_CD_MASK) - di->xmtptrbase) &\n\t\t\t\t D64_XS0_CD_MASK, struct dma64desc));\n\n\t\tif (range == DMA_RANGE_TRANSFERED) {\n\t\t\tactive_desc =\n\t\t\t\t(u16)(bcma_read32(di->core,\n\t\t\t\t\t\t  DMA64TXREGOFFS(di, status1)) &\n\t\t\t\t      D64_XS1_AD_MASK);\n\t\t\tactive_desc =\n\t\t\t    (active_desc - di->xmtptrbase) & D64_XS0_CD_MASK;\n\t\t\tactive_desc = B2I(active_desc, struct dma64desc);\n\t\t\tif (end != active_desc)\n\t\t\t\tend = prevtxd(di, active_desc);\n\t\t}\n\t}\n\n\tif ((start == 0) && (end > di->txout))\n\t\tgoto bogus;\n\n\tfor (i = start; i != end && !txp; i = nexttxd(di, i)) {\n\t\tdma_addr_t pa;\n\t\tuint size;\n\n\t\tpa = le32_to_cpu(di->txd64[i].addrlow) - di->dataoffsetlow;\n\n\t\tsize =\n\t\t    (le32_to_cpu(di->txd64[i].ctrl2) &\n\t\t     D64_CTRL2_BC_MASK);\n\n\t\tdi->txd64[i].addrlow = cpu_to_le32(0xdeadbeef);\n\t\tdi->txd64[i].addrhigh = cpu_to_le32(0xdeadbeef);\n\n\t\ttxp = di->txp[i];\n\t\tdi->txp[i] = NULL;\n\n\t\tdma_unmap_single(di->dmadev, pa, size, DMA_TO_DEVICE);\n\t}\n\n\tdi->txin = i;\n\n\t \n\tdma_update_txavail(di);\n\n\treturn txp;\n\n bogus:\n\tbrcms_dbg_dma(di->core, \"bogus curr: start %d end %d txout %d\\n\",\n\t\t      start, end, di->txout);\n\treturn NULL;\n}\n\n \nvoid dma_walk_packets(struct dma_pub *dmah, void (*callback_fnc)\n\t\t      (void *pkt, void *arg_a), void *arg_a)\n{\n\tstruct dma_info *di = container_of(dmah, struct dma_info, dma);\n\tuint i =   di->txin;\n\tuint end = di->txout;\n\tstruct sk_buff *skb;\n\tstruct ieee80211_tx_info *tx_info;\n\n\twhile (i != end) {\n\t\tskb = di->txp[i];\n\t\tif (skb != NULL) {\n\t\t\ttx_info = (struct ieee80211_tx_info *)skb->cb;\n\t\t\t(callback_fnc)(tx_info, arg_a);\n\t\t}\n\t\ti = nexttxd(di, i);\n\t}\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}