{
  "module_name": "ixp4xx_hss.c",
  "hash_id": "753f6567301a1716c23055de67bffce9a2ffab4a891a079566e230fd52788797",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wan/ixp4xx_hss.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/bitops.h>\n#include <linux/cdev.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/fs.h>\n#include <linux/hdlc.h>\n#include <linux/io.h>\n#include <linux/kernel.h>\n#include <linux/mfd/syscon.h>\n#include <linux/platform_device.h>\n#include <linux/poll.h>\n#include <linux/regmap.h>\n#include <linux/slab.h>\n#include <linux/gpio/consumer.h>\n#include <linux/of.h>\n#include <linux/soc/ixp4xx/npe.h>\n#include <linux/soc/ixp4xx/qmgr.h>\n#include <linux/soc/ixp4xx/cpu.h>\n\n \n#define IXP4XX_TIMER_FREQ\t66666000\n\n#define DEBUG_DESC\t\t0\n#define DEBUG_RX\t\t0\n#define DEBUG_TX\t\t0\n#define DEBUG_PKT_BYTES\t\t0\n#define DEBUG_CLOSE\t\t0\n\n#define DRV_NAME\t\t\"ixp4xx_hss\"\n\n#define PKT_EXTRA_FLAGS\t\t0  \n#define PKT_NUM_PIPES\t\t1  \n#define PKT_PIPE_FIFO_SIZEW\t4  \n\n#define RX_DESCS\t\t16  \n#define TX_DESCS\t\t16  \n\n#define POOL_ALLOC_SIZE\t\t(sizeof(struct desc) * (RX_DESCS + TX_DESCS))\n#define RX_SIZE\t\t\t(HDLC_MAX_MRU + 4)  \n#define MAX_CLOSE_WAIT\t\t1000  \n#define HSS_COUNT\t\t2\n#define FRAME_SIZE\t\t256  \n#define FRAME_OFFSET\t\t0\n#define MAX_CHANNELS\t\t(FRAME_SIZE / 8)\n\n#define NAPI_WEIGHT\t\t16\n\n \n#define HSS0_PKT_RX_QUEUE\t13\t \n#define HSS0_PKT_TX0_QUEUE\t14\t \n#define HSS0_PKT_TX1_QUEUE\t15\n#define HSS0_PKT_TX2_QUEUE\t16\n#define HSS0_PKT_TX3_QUEUE\t17\n#define HSS0_PKT_RXFREE0_QUEUE\t18\t \n#define HSS0_PKT_RXFREE1_QUEUE\t19\n#define HSS0_PKT_RXFREE2_QUEUE\t20\n#define HSS0_PKT_RXFREE3_QUEUE\t21\n#define HSS0_PKT_TXDONE_QUEUE\t22\t \n\n#define HSS1_PKT_RX_QUEUE\t0\n#define HSS1_PKT_TX0_QUEUE\t5\n#define HSS1_PKT_TX1_QUEUE\t6\n#define HSS1_PKT_TX2_QUEUE\t7\n#define HSS1_PKT_TX3_QUEUE\t8\n#define HSS1_PKT_RXFREE0_QUEUE\t1\n#define HSS1_PKT_RXFREE1_QUEUE\t2\n#define HSS1_PKT_RXFREE2_QUEUE\t3\n#define HSS1_PKT_RXFREE3_QUEUE\t4\n#define HSS1_PKT_TXDONE_QUEUE\t9\n\n#define NPE_PKT_MODE_HDLC\t\t0\n#define NPE_PKT_MODE_RAW\t\t1\n#define NPE_PKT_MODE_56KMODE\t\t2\n#define NPE_PKT_MODE_56KENDIAN_MSB\t4\n\n \n#define PKT_HDLC_IDLE_ONES\t\t0x1  \n#define PKT_HDLC_CRC_32\t\t\t0x2  \n#define PKT_HDLC_MSB_ENDIAN\t\t0x4  \n\n \n \n#define PCR_FRM_SYNC_ACTIVE_HIGH\t0x40000000\n#define PCR_FRM_SYNC_FALLINGEDGE\t0x80000000\n#define PCR_FRM_SYNC_RISINGEDGE\t\t0xC0000000\n\n \n#define PCR_FRM_SYNC_OUTPUT_FALLING\t0x20000000\n#define PCR_FRM_SYNC_OUTPUT_RISING\t0x30000000\n\n \n#define PCR_FCLK_EDGE_RISING\t\t0x08000000\n#define PCR_DCLK_EDGE_RISING\t\t0x04000000\n\n \n#define PCR_SYNC_CLK_DIR_OUTPUT\t\t0x02000000\n\n \n#define PCR_FRM_PULSE_DISABLED\t\t0x01000000\n\n  \n#define PCR_HALF_CLK_RATE\t\t0x00200000\n\n \n#define PCR_DATA_POLARITY_INVERT\t0x00100000\n\n \n#define PCR_MSB_ENDIAN\t\t\t0x00080000\n\n \n#define PCR_TX_PINS_OPEN_DRAIN\t\t0x00040000\n\n \n#define PCR_SOF_NO_FBIT\t\t\t0x00020000\n\n \n#define PCR_TX_DATA_ENABLE\t\t0x00010000\n\n \n#define PCR_TX_V56K_HIGH\t\t0x00002000\n#define PCR_TX_V56K_HIGH_IMP\t\t0x00004000\n\n \n#define PCR_TX_UNASS_HIGH\t\t0x00000800\n#define PCR_TX_UNASS_HIGH_IMP\t\t0x00001000\n\n \n#define PCR_TX_FB_HIGH_IMP\t\t0x00000400\n\n \n#define PCR_TX_56KE_BIT_0_UNUSED\t0x00000200\n\n \n#define PCR_TX_56KS_56K_DATA\t\t0x00000100\n\n \n \n#define CCR_NPE_HFIFO_2_HDLC\t\t0x04000000\n#define CCR_NPE_HFIFO_3_OR_4HDLC\t0x08000000\n\n \n#define CCR_LOOPBACK\t\t\t0x02000000\n\n \n#define CCR_SECOND_HSS\t\t\t0x01000000\n\n \n#define CLK42X_SPEED_EXP\t((0x3FF << 22) | (2 << 12) |   15)  \n\n#define CLK42X_SPEED_512KHZ\t((130 << 22) | (2 << 12) |   15)\n#define CLK42X_SPEED_1536KHZ\t((43 << 22) | (18 << 12) |   47)\n#define CLK42X_SPEED_1544KHZ\t((43 << 22) | (33 << 12) |  192)\n#define CLK42X_SPEED_2048KHZ\t((32 << 22) | (34 << 12) |   63)\n#define CLK42X_SPEED_4096KHZ\t((16 << 22) | (34 << 12) |  127)\n#define CLK42X_SPEED_8192KHZ\t((8 << 22) | (34 << 12) |  255)\n\n#define CLK46X_SPEED_512KHZ\t((130 << 22) | (24 << 12) |  127)\n#define CLK46X_SPEED_1536KHZ\t((43 << 22) | (152 << 12) |  383)\n#define CLK46X_SPEED_1544KHZ\t((43 << 22) | (66 << 12) |  385)\n#define CLK46X_SPEED_2048KHZ\t((32 << 22) | (280 << 12) |  511)\n#define CLK46X_SPEED_4096KHZ\t((16 << 22) | (280 << 12) | 1023)\n#define CLK46X_SPEED_8192KHZ\t((8 << 22) | (280 << 12) | 2047)\n\n \n\n \n#define TDMMAP_UNASSIGNED\t0\n#define TDMMAP_HDLC\t\t1\t \n#define TDMMAP_VOICE56K\t\t2\t \n#define TDMMAP_VOICE64K\t\t3\t \n\n \n#define HSS_CONFIG_TX_PCR\t0x00  \n#define HSS_CONFIG_RX_PCR\t0x04\n#define HSS_CONFIG_CORE_CR\t0x08  \n#define HSS_CONFIG_CLOCK_CR\t0x0C  \n#define HSS_CONFIG_TX_FCR\t0x10  \n#define HSS_CONFIG_RX_FCR\t0x14\n#define HSS_CONFIG_TX_LUT\t0x18  \n#define HSS_CONFIG_RX_LUT\t0x38\n\n \n \n#define PORT_CONFIG_WRITE\t\t0x40\n\n \n#define PORT_CONFIG_LOAD\t\t0x41\n\n \n#define PORT_ERROR_READ\t\t\t0x42\n\n \n#define PKT_PIPE_FLOW_ENABLE\t\t0x50\n#define PKT_PIPE_FLOW_DISABLE\t\t0x51\n#define PKT_NUM_PIPES_WRITE\t\t0x52\n#define PKT_PIPE_FIFO_SIZEW_WRITE\t0x53\n#define PKT_PIPE_HDLC_CFG_WRITE\t\t0x54\n#define PKT_PIPE_IDLE_PATTERN_WRITE\t0x55\n#define PKT_PIPE_RX_SIZE_WRITE\t\t0x56\n#define PKT_PIPE_MODE_WRITE\t\t0x57\n\n \n#define ERR_SHUTDOWN\t\t1  \n#define ERR_HDLC_ALIGN\t\t2  \n#define ERR_HDLC_FCS\t\t3  \n#define ERR_RXFREE_Q_EMPTY\t4  \n#define ERR_HDLC_TOO_LONG\t5  \n#define ERR_HDLC_ABORT\t\t6  \n#define ERR_DISCONNECTING\t7  \n\n#ifdef __ARMEB__\ntypedef struct sk_buff buffer_t;\n#define free_buffer dev_kfree_skb\n#define free_buffer_irq dev_consume_skb_irq\n#else\ntypedef void buffer_t;\n#define free_buffer kfree\n#define free_buffer_irq kfree\n#endif\n\nstruct port {\n\tstruct device *dev;\n\tstruct npe *npe;\n\tunsigned int txreadyq;\n\tunsigned int rxtrigq;\n\tunsigned int rxfreeq;\n\tunsigned int rxq;\n\tunsigned int txq;\n\tunsigned int txdoneq;\n\tstruct gpio_desc *cts;\n\tstruct gpio_desc *rts;\n\tstruct gpio_desc *dcd;\n\tstruct gpio_desc *dtr;\n\tstruct gpio_desc *clk_internal;\n\tstruct net_device *netdev;\n\tstruct napi_struct napi;\n\tbuffer_t *rx_buff_tab[RX_DESCS], *tx_buff_tab[TX_DESCS];\n\tstruct desc *desc_tab;\t \n\tdma_addr_t desc_tab_phys;\n\tunsigned int id;\n\tunsigned int clock_type, clock_rate, loopback;\n\tunsigned int initialized, carrier;\n\tu8 hdlc_cfg;\n\tu32 clock_reg;\n};\n\n \nstruct msg {\n#ifdef __ARMEB__\n\tu8 cmd, unused, hss_port, index;\n\tunion {\n\t\tstruct { u8 data8a, data8b, data8c, data8d; };\n\t\tstruct { u16 data16a, data16b; };\n\t\tstruct { u32 data32; };\n\t};\n#else\n\tu8 index, hss_port, unused, cmd;\n\tunion {\n\t\tstruct { u8 data8d, data8c, data8b, data8a; };\n\t\tstruct { u16 data16b, data16a; };\n\t\tstruct { u32 data32; };\n\t};\n#endif\n};\n\n \nstruct desc {\n\tu32 next;\t\t \n\n#ifdef __ARMEB__\n\tu16 buf_len;\t\t \n\tu16 pkt_len;\t\t \n\tu32 data;\t\t \n\tu8 status;\n\tu8 error_count;\n\tu16 __reserved;\n#else\n\tu16 pkt_len;\t\t \n\tu16 buf_len;\t\t \n\tu32 data;\t\t \n\tu16 __reserved;\n\tu8 error_count;\n\tu8 status;\n#endif\n\tu32 __reserved1[4];\n};\n\n#define rx_desc_phys(port, n)\t((port)->desc_tab_phys +\t\t\\\n\t\t\t\t (n) * sizeof(struct desc))\n#define rx_desc_ptr(port, n)\t(&(port)->desc_tab[n])\n\n#define tx_desc_phys(port, n)\t((port)->desc_tab_phys +\t\t\\\n\t\t\t\t ((n) + RX_DESCS) * sizeof(struct desc))\n#define tx_desc_ptr(port, n)\t(&(port)->desc_tab[(n) + RX_DESCS])\n\n \n\nstatic int ports_open;\nstatic struct dma_pool *dma_pool;\nstatic DEFINE_SPINLOCK(npe_lock);\n\n \n\nstatic inline struct port *dev_to_port(struct net_device *dev)\n{\n\treturn dev_to_hdlc(dev)->priv;\n}\n\n#ifndef __ARMEB__\nstatic inline void memcpy_swab32(u32 *dest, u32 *src, int cnt)\n{\n\tint i;\n\n\tfor (i = 0; i < cnt; i++)\n\t\tdest[i] = swab32(src[i]);\n}\n#endif\n\n \n\nstatic void hss_npe_send(struct port *port, struct msg *msg, const char *what)\n{\n\tu32 *val = (u32 *)msg;\n\n\tif (npe_send_message(port->npe, msg, what)) {\n\t\tpr_crit(\"HSS-%i: unable to send command [%08X:%08X] to %s\\n\",\n\t\t\tport->id, val[0], val[1], npe_name(port->npe));\n\t\tBUG();\n\t}\n}\n\nstatic void hss_config_set_lut(struct port *port)\n{\n\tstruct msg msg;\n\tint ch;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_CONFIG_WRITE;\n\tmsg.hss_port = port->id;\n\n\tfor (ch = 0; ch < MAX_CHANNELS; ch++) {\n\t\tmsg.data32 >>= 2;\n\t\tmsg.data32 |= TDMMAP_HDLC << 30;\n\n\t\tif (ch % 16 == 15) {\n\t\t\tmsg.index = HSS_CONFIG_TX_LUT + ((ch / 4) & ~3);\n\t\t\thss_npe_send(port, &msg, \"HSS_SET_TX_LUT\");\n\n\t\t\tmsg.index += HSS_CONFIG_RX_LUT - HSS_CONFIG_TX_LUT;\n\t\t\thss_npe_send(port, &msg, \"HSS_SET_RX_LUT\");\n\t\t}\n\t}\n}\n\nstatic void hss_config(struct port *port)\n{\n\tstruct msg msg;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_CONFIG_WRITE;\n\tmsg.hss_port = port->id;\n\tmsg.index = HSS_CONFIG_TX_PCR;\n\tmsg.data32 = PCR_FRM_PULSE_DISABLED | PCR_MSB_ENDIAN |\n\t\tPCR_TX_DATA_ENABLE | PCR_SOF_NO_FBIT;\n\tif (port->clock_type == CLOCK_INT)\n\t\tmsg.data32 |= PCR_SYNC_CLK_DIR_OUTPUT;\n\thss_npe_send(port, &msg, \"HSS_SET_TX_PCR\");\n\n\tmsg.index = HSS_CONFIG_RX_PCR;\n\tmsg.data32 ^= PCR_TX_DATA_ENABLE | PCR_DCLK_EDGE_RISING;\n\thss_npe_send(port, &msg, \"HSS_SET_RX_PCR\");\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_CONFIG_WRITE;\n\tmsg.hss_port = port->id;\n\tmsg.index = HSS_CONFIG_CORE_CR;\n\tmsg.data32 = (port->loopback ? CCR_LOOPBACK : 0) |\n\t\t(port->id ? CCR_SECOND_HSS : 0);\n\thss_npe_send(port, &msg, \"HSS_SET_CORE_CR\");\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_CONFIG_WRITE;\n\tmsg.hss_port = port->id;\n\tmsg.index = HSS_CONFIG_CLOCK_CR;\n\tmsg.data32 = port->clock_reg;\n\thss_npe_send(port, &msg, \"HSS_SET_CLOCK_CR\");\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_CONFIG_WRITE;\n\tmsg.hss_port = port->id;\n\tmsg.index = HSS_CONFIG_TX_FCR;\n\tmsg.data16a = FRAME_OFFSET;\n\tmsg.data16b = FRAME_SIZE - 1;\n\thss_npe_send(port, &msg, \"HSS_SET_TX_FCR\");\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_CONFIG_WRITE;\n\tmsg.hss_port = port->id;\n\tmsg.index = HSS_CONFIG_RX_FCR;\n\tmsg.data16a = FRAME_OFFSET;\n\tmsg.data16b = FRAME_SIZE - 1;\n\thss_npe_send(port, &msg, \"HSS_SET_RX_FCR\");\n\n\thss_config_set_lut(port);\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_CONFIG_LOAD;\n\tmsg.hss_port = port->id;\n\thss_npe_send(port, &msg, \"HSS_LOAD_CONFIG\");\n\n\tif (npe_recv_message(port->npe, &msg, \"HSS_LOAD_CONFIG\") ||\n\t     \n\t    msg.cmd != PORT_CONFIG_LOAD || msg.data32) {\n\t\tpr_crit(\"HSS-%i: HSS_LOAD_CONFIG failed\\n\", port->id);\n\t\tBUG();\n\t}\n\n\t \n\tnpe_recv_message(port->npe, &msg, \"FLUSH_IT\");\n}\n\nstatic void hss_set_hdlc_cfg(struct port *port)\n{\n\tstruct msg msg;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PKT_PIPE_HDLC_CFG_WRITE;\n\tmsg.hss_port = port->id;\n\tmsg.data8a = port->hdlc_cfg;  \n\tmsg.data8b = port->hdlc_cfg | (PKT_EXTRA_FLAGS << 3);  \n\thss_npe_send(port, &msg, \"HSS_SET_HDLC_CFG\");\n}\n\nstatic u32 hss_get_status(struct port *port)\n{\n\tstruct msg msg;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PORT_ERROR_READ;\n\tmsg.hss_port = port->id;\n\thss_npe_send(port, &msg, \"PORT_ERROR_READ\");\n\tif (npe_recv_message(port->npe, &msg, \"PORT_ERROR_READ\")) {\n\t\tpr_crit(\"HSS-%i: unable to read HSS status\\n\", port->id);\n\t\tBUG();\n\t}\n\n\treturn msg.data32;\n}\n\nstatic void hss_start_hdlc(struct port *port)\n{\n\tstruct msg msg;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PKT_PIPE_FLOW_ENABLE;\n\tmsg.hss_port = port->id;\n\tmsg.data32 = 0;\n\thss_npe_send(port, &msg, \"HSS_ENABLE_PKT_PIPE\");\n}\n\nstatic void hss_stop_hdlc(struct port *port)\n{\n\tstruct msg msg;\n\n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PKT_PIPE_FLOW_DISABLE;\n\tmsg.hss_port = port->id;\n\thss_npe_send(port, &msg, \"HSS_DISABLE_PKT_PIPE\");\n\thss_get_status(port);  \n}\n\nstatic int hss_load_firmware(struct port *port)\n{\n\tstruct msg msg;\n\tint err;\n\n\tif (port->initialized)\n\t\treturn 0;\n\n\tif (!npe_running(port->npe)) {\n\t\terr = npe_load_firmware(port->npe, npe_name(port->npe),\n\t\t\t\t\tport->dev);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\t \n\tmemset(&msg, 0, sizeof(msg));\n\tmsg.cmd = PKT_NUM_PIPES_WRITE;\n\tmsg.hss_port = port->id;\n\tmsg.data8a = PKT_NUM_PIPES;\n\thss_npe_send(port, &msg, \"HSS_SET_PKT_PIPES\");\n\n\tmsg.cmd = PKT_PIPE_FIFO_SIZEW_WRITE;\n\tmsg.data8a = PKT_PIPE_FIFO_SIZEW;\n\thss_npe_send(port, &msg, \"HSS_SET_PKT_FIFO\");\n\n\tmsg.cmd = PKT_PIPE_MODE_WRITE;\n\tmsg.data8a = NPE_PKT_MODE_HDLC;\n\t \n\t \n\thss_npe_send(port, &msg, \"HSS_SET_PKT_MODE\");\n\n\tmsg.cmd = PKT_PIPE_RX_SIZE_WRITE;\n\tmsg.data16a = HDLC_MAX_MRU;  \n\thss_npe_send(port, &msg, \"HSS_SET_PKT_RX_SIZE\");\n\n\tmsg.cmd = PKT_PIPE_IDLE_PATTERN_WRITE;\n\tmsg.data32 = 0x7F7F7F7F;  \n\thss_npe_send(port, &msg, \"HSS_SET_PKT_IDLE\");\n\n\tport->initialized = 1;\n\treturn 0;\n}\n\n \n\nstatic inline void debug_pkt(struct net_device *dev, const char *func,\n\t\t\t     u8 *data, int len)\n{\n#if DEBUG_PKT_BYTES\n\tint i;\n\n\tprintk(KERN_DEBUG \"%s: %s(%i)\", dev->name, func, len);\n\tfor (i = 0; i < len; i++) {\n\t\tif (i >= DEBUG_PKT_BYTES)\n\t\t\tbreak;\n\t\tprintk(\"%s%02X\", !(i % 4) ? \" \" : \"\", data[i]);\n\t}\n\tprintk(\"\\n\");\n#endif\n}\n\nstatic inline void debug_desc(u32 phys, struct desc *desc)\n{\n#if DEBUG_DESC\n\tprintk(KERN_DEBUG \"%X: %X %3X %3X %08X %X %X\\n\",\n\t       phys, desc->next, desc->buf_len, desc->pkt_len,\n\t       desc->data, desc->status, desc->error_count);\n#endif\n}\n\nstatic inline int queue_get_desc(unsigned int queue, struct port *port,\n\t\t\t\t int is_tx)\n{\n\tu32 phys, tab_phys, n_desc;\n\tstruct desc *tab;\n\n\tphys = qmgr_get_entry(queue);\n\tif (!phys)\n\t\treturn -1;\n\n\tBUG_ON(phys & 0x1F);\n\ttab_phys = is_tx ? tx_desc_phys(port, 0) : rx_desc_phys(port, 0);\n\ttab = is_tx ? tx_desc_ptr(port, 0) : rx_desc_ptr(port, 0);\n\tn_desc = (phys - tab_phys) / sizeof(struct desc);\n\tBUG_ON(n_desc >= (is_tx ? TX_DESCS : RX_DESCS));\n\tdebug_desc(phys, &tab[n_desc]);\n\tBUG_ON(tab[n_desc].next);\n\treturn n_desc;\n}\n\nstatic inline void queue_put_desc(unsigned int queue, u32 phys,\n\t\t\t\t  struct desc *desc)\n{\n\tdebug_desc(phys, desc);\n\tBUG_ON(phys & 0x1F);\n\tqmgr_put_entry(queue, phys);\n\t \n}\n\nstatic inline void dma_unmap_tx(struct port *port, struct desc *desc)\n{\n#ifdef __ARMEB__\n\tdma_unmap_single(&port->netdev->dev, desc->data,\n\t\t\t desc->buf_len, DMA_TO_DEVICE);\n#else\n\tdma_unmap_single(&port->netdev->dev, desc->data & ~3,\n\t\t\t ALIGN((desc->data & 3) + desc->buf_len, 4),\n\t\t\t DMA_TO_DEVICE);\n#endif\n}\n\nstatic void hss_hdlc_set_carrier(void *pdev, int carrier)\n{\n\tstruct net_device *netdev = pdev;\n\tstruct port *port = dev_to_port(netdev);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&npe_lock, flags);\n\tport->carrier = carrier;\n\tif (!port->loopback) {\n\t\tif (carrier)\n\t\t\tnetif_carrier_on(netdev);\n\t\telse\n\t\t\tnetif_carrier_off(netdev);\n\t}\n\tspin_unlock_irqrestore(&npe_lock, flags);\n}\n\nstatic void hss_hdlc_rx_irq(void *pdev)\n{\n\tstruct net_device *dev = pdev;\n\tstruct port *port = dev_to_port(dev);\n\n#if DEBUG_RX\n\tprintk(KERN_DEBUG \"%s: hss_hdlc_rx_irq\\n\", dev->name);\n#endif\n\tqmgr_disable_irq(port->rxq);\n\tnapi_schedule(&port->napi);\n}\n\nstatic int hss_hdlc_poll(struct napi_struct *napi, int budget)\n{\n\tstruct port *port = container_of(napi, struct port, napi);\n\tstruct net_device *dev = port->netdev;\n\tunsigned int rxq = port->rxq;\n\tunsigned int rxfreeq = port->rxfreeq;\n\tint received = 0;\n\n#if DEBUG_RX\n\tprintk(KERN_DEBUG \"%s: hss_hdlc_poll\\n\", dev->name);\n#endif\n\n\twhile (received < budget) {\n\t\tstruct sk_buff *skb;\n\t\tstruct desc *desc;\n\t\tint n;\n#ifdef __ARMEB__\n\t\tstruct sk_buff *temp;\n\t\tu32 phys;\n#endif\n\n\t\tn = queue_get_desc(rxq, port, 0);\n\t\tif (n < 0) {\n#if DEBUG_RX\n\t\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_poll\"\n\t\t\t       \" napi_complete\\n\", dev->name);\n#endif\n\t\t\tnapi_complete(napi);\n\t\t\tqmgr_enable_irq(rxq);\n\t\t\tif (!qmgr_stat_empty(rxq) &&\n\t\t\t    napi_reschedule(napi)) {\n#if DEBUG_RX\n\t\t\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_poll\"\n\t\t\t\t       \" napi_reschedule succeeded\\n\",\n\t\t\t\t       dev->name);\n#endif\n\t\t\t\tqmgr_disable_irq(rxq);\n\t\t\t\tcontinue;\n\t\t\t}\n#if DEBUG_RX\n\t\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_poll all done\\n\",\n\t\t\t       dev->name);\n#endif\n\t\t\treturn received;  \n\t\t}\n\n\t\tdesc = rx_desc_ptr(port, n);\n#if 0  \n\t\tif (desc->error_count)\n\t\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_poll status 0x%02X\"\n\t\t\t       \" errors %u\\n\", dev->name, desc->status,\n\t\t\t       desc->error_count);\n#endif\n\t\tskb = NULL;\n\t\tswitch (desc->status) {\n\t\tcase 0:\n#ifdef __ARMEB__\n\t\t\tskb = netdev_alloc_skb(dev, RX_SIZE);\n\t\t\tif (skb) {\n\t\t\t\tphys = dma_map_single(&dev->dev, skb->data,\n\t\t\t\t\t\t      RX_SIZE,\n\t\t\t\t\t\t      DMA_FROM_DEVICE);\n\t\t\t\tif (dma_mapping_error(&dev->dev, phys)) {\n\t\t\t\t\tdev_kfree_skb(skb);\n\t\t\t\t\tskb = NULL;\n\t\t\t\t}\n\t\t\t}\n#else\n\t\t\tskb = netdev_alloc_skb(dev, desc->pkt_len);\n#endif\n\t\t\tif (!skb)\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\tbreak;\n\t\tcase ERR_HDLC_ALIGN:\n\t\tcase ERR_HDLC_ABORT:\n\t\t\tdev->stats.rx_frame_errors++;\n\t\t\tdev->stats.rx_errors++;\n\t\t\tbreak;\n\t\tcase ERR_HDLC_FCS:\n\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tdev->stats.rx_errors++;\n\t\t\tbreak;\n\t\tcase ERR_HDLC_TOO_LONG:\n\t\t\tdev->stats.rx_length_errors++;\n\t\t\tdev->stats.rx_errors++;\n\t\t\tbreak;\n\t\tdefault:\t \n\t\t\tnetdev_err(dev, \"hss_hdlc_poll: status 0x%02X errors %u\\n\",\n\t\t\t\t   desc->status, desc->error_count);\n\t\t\tdev->stats.rx_errors++;\n\t\t}\n\n\t\tif (!skb) {\n\t\t\t \n\t\t\tdesc->buf_len = RX_SIZE;\n\t\t\tdesc->pkt_len = desc->status = 0;\n\t\t\tqueue_put_desc(rxfreeq, rx_desc_phys(port, n), desc);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n#ifdef __ARMEB__\n\t\ttemp = skb;\n\t\tskb = port->rx_buff_tab[n];\n\t\tdma_unmap_single(&dev->dev, desc->data,\n\t\t\t\t RX_SIZE, DMA_FROM_DEVICE);\n#else\n\t\tdma_sync_single_for_cpu(&dev->dev, desc->data,\n\t\t\t\t\tRX_SIZE, DMA_FROM_DEVICE);\n\t\tmemcpy_swab32((u32 *)skb->data, (u32 *)port->rx_buff_tab[n],\n\t\t\t      ALIGN(desc->pkt_len, 4) / 4);\n#endif\n\t\tskb_put(skb, desc->pkt_len);\n\n\t\tdebug_pkt(dev, \"hss_hdlc_poll\", skb->data, skb->len);\n\n\t\tskb->protocol = hdlc_type_trans(skb, dev);\n\t\tdev->stats.rx_packets++;\n\t\tdev->stats.rx_bytes += skb->len;\n\t\tnetif_receive_skb(skb);\n\n\t\t \n#ifdef __ARMEB__\n\t\tport->rx_buff_tab[n] = temp;\n\t\tdesc->data = phys;\n#endif\n\t\tdesc->buf_len = RX_SIZE;\n\t\tdesc->pkt_len = 0;\n\t\tqueue_put_desc(rxfreeq, rx_desc_phys(port, n), desc);\n\t\treceived++;\n\t}\n#if DEBUG_RX\n\tprintk(KERN_DEBUG \"hss_hdlc_poll: end, not all work done\\n\");\n#endif\n\treturn received;\t \n}\n\nstatic void hss_hdlc_txdone_irq(void *pdev)\n{\n\tstruct net_device *dev = pdev;\n\tstruct port *port = dev_to_port(dev);\n\tint n_desc;\n\n#if DEBUG_TX\n\tprintk(KERN_DEBUG DRV_NAME \": hss_hdlc_txdone_irq\\n\");\n#endif\n\twhile ((n_desc = queue_get_desc(port->txdoneq,\n\t\t\t\t\tport, 1)) >= 0) {\n\t\tstruct desc *desc;\n\t\tint start;\n\n\t\tdesc = tx_desc_ptr(port, n_desc);\n\n\t\tdev->stats.tx_packets++;\n\t\tdev->stats.tx_bytes += desc->pkt_len;\n\n\t\tdma_unmap_tx(port, desc);\n#if DEBUG_TX\n\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_txdone_irq free %p\\n\",\n\t\t       dev->name, port->tx_buff_tab[n_desc]);\n#endif\n\t\tfree_buffer_irq(port->tx_buff_tab[n_desc]);\n\t\tport->tx_buff_tab[n_desc] = NULL;\n\n\t\tstart = qmgr_stat_below_low_watermark(port->txreadyq);\n\t\tqueue_put_desc(port->txreadyq,\n\t\t\t       tx_desc_phys(port, n_desc), desc);\n\t\tif (start) {  \n#if DEBUG_TX\n\t\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_txdone_irq xmit\"\n\t\t\t       \" ready\\n\", dev->name);\n#endif\n\t\t\tnetif_wake_queue(dev);\n\t\t}\n\t}\n}\n\nstatic int hss_hdlc_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct port *port = dev_to_port(dev);\n\tunsigned int txreadyq = port->txreadyq;\n\tint len, offset, bytes, n;\n\tvoid *mem;\n\tu32 phys;\n\tstruct desc *desc;\n\n#if DEBUG_TX\n\tprintk(KERN_DEBUG \"%s: hss_hdlc_xmit\\n\", dev->name);\n#endif\n\n\tif (unlikely(skb->len > HDLC_MAX_MRU)) {\n\t\tdev_kfree_skb(skb);\n\t\tdev->stats.tx_errors++;\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tdebug_pkt(dev, \"hss_hdlc_xmit\", skb->data, skb->len);\n\n\tlen = skb->len;\n#ifdef __ARMEB__\n\toffset = 0;  \n\tbytes = len;\n\tmem = skb->data;\n#else\n\toffset = (int)skb->data & 3;  \n\tbytes = ALIGN(offset + len, 4);\n\tmem = kmalloc(bytes, GFP_ATOMIC);\n\tif (!mem) {\n\t\tdev_kfree_skb(skb);\n\t\tdev->stats.tx_dropped++;\n\t\treturn NETDEV_TX_OK;\n\t}\n\tmemcpy_swab32(mem, (u32 *)((uintptr_t)skb->data & ~3), bytes / 4);\n\tdev_kfree_skb(skb);\n#endif\n\n\tphys = dma_map_single(&dev->dev, mem, bytes, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&dev->dev, phys)) {\n#ifdef __ARMEB__\n\t\tdev_kfree_skb(skb);\n#else\n\t\tkfree(mem);\n#endif\n\t\tdev->stats.tx_dropped++;\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tn = queue_get_desc(txreadyq, port, 1);\n\tBUG_ON(n < 0);\n\tdesc = tx_desc_ptr(port, n);\n\n#ifdef __ARMEB__\n\tport->tx_buff_tab[n] = skb;\n#else\n\tport->tx_buff_tab[n] = mem;\n#endif\n\tdesc->data = phys + offset;\n\tdesc->buf_len = desc->pkt_len = len;\n\n\twmb();\n\tqueue_put_desc(port->txq, tx_desc_phys(port, n), desc);\n\n\tif (qmgr_stat_below_low_watermark(txreadyq)) {  \n#if DEBUG_TX\n\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_xmit queue full\\n\", dev->name);\n#endif\n\t\tnetif_stop_queue(dev);\n\t\t \n\t\tif (!qmgr_stat_below_low_watermark(txreadyq)) {\n#if DEBUG_TX\n\t\t\tprintk(KERN_DEBUG \"%s: hss_hdlc_xmit ready again\\n\",\n\t\t\t       dev->name);\n#endif\n\t\t\tnetif_wake_queue(dev);\n\t\t}\n\t}\n\n#if DEBUG_TX\n\tprintk(KERN_DEBUG \"%s: hss_hdlc_xmit end\\n\", dev->name);\n#endif\n\treturn NETDEV_TX_OK;\n}\n\nstatic int request_hdlc_queues(struct port *port)\n{\n\tint err;\n\n\terr = qmgr_request_queue(port->rxfreeq, RX_DESCS, 0, 0,\n\t\t\t\t \"%s:RX-free\", port->netdev->name);\n\tif (err)\n\t\treturn err;\n\n\terr = qmgr_request_queue(port->rxq, RX_DESCS, 0, 0,\n\t\t\t\t \"%s:RX\", port->netdev->name);\n\tif (err)\n\t\tgoto rel_rxfree;\n\n\terr = qmgr_request_queue(port->txq, TX_DESCS, 0, 0,\n\t\t\t\t \"%s:TX\", port->netdev->name);\n\tif (err)\n\t\tgoto rel_rx;\n\n\terr = qmgr_request_queue(port->txreadyq, TX_DESCS, 0, 0,\n\t\t\t\t \"%s:TX-ready\", port->netdev->name);\n\tif (err)\n\t\tgoto rel_tx;\n\n\terr = qmgr_request_queue(port->txdoneq, TX_DESCS, 0, 0,\n\t\t\t\t \"%s:TX-done\", port->netdev->name);\n\tif (err)\n\t\tgoto rel_txready;\n\treturn 0;\n\nrel_txready:\n\tqmgr_release_queue(port->txreadyq);\nrel_tx:\n\tqmgr_release_queue(port->txq);\nrel_rx:\n\tqmgr_release_queue(port->rxq);\nrel_rxfree:\n\tqmgr_release_queue(port->rxfreeq);\n\tprintk(KERN_DEBUG \"%s: unable to request hardware queues\\n\",\n\t       port->netdev->name);\n\treturn err;\n}\n\nstatic void release_hdlc_queues(struct port *port)\n{\n\tqmgr_release_queue(port->rxfreeq);\n\tqmgr_release_queue(port->rxq);\n\tqmgr_release_queue(port->txdoneq);\n\tqmgr_release_queue(port->txq);\n\tqmgr_release_queue(port->txreadyq);\n}\n\nstatic int init_hdlc_queues(struct port *port)\n{\n\tint i;\n\n\tif (!ports_open) {\n\t\tdma_pool = dma_pool_create(DRV_NAME, &port->netdev->dev,\n\t\t\t\t\t   POOL_ALLOC_SIZE, 32, 0);\n\t\tif (!dma_pool)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tport->desc_tab = dma_pool_zalloc(dma_pool, GFP_KERNEL,\n\t\t\t\t\t&port->desc_tab_phys);\n\tif (!port->desc_tab)\n\t\treturn -ENOMEM;\n\tmemset(port->rx_buff_tab, 0, sizeof(port->rx_buff_tab));  \n\tmemset(port->tx_buff_tab, 0, sizeof(port->tx_buff_tab));\n\n\t \n\tfor (i = 0; i < RX_DESCS; i++) {\n\t\tstruct desc *desc = rx_desc_ptr(port, i);\n\t\tbuffer_t *buff;\n\t\tvoid *data;\n#ifdef __ARMEB__\n\t\tbuff = netdev_alloc_skb(port->netdev, RX_SIZE);\n\t\tif (!buff)\n\t\t\treturn -ENOMEM;\n\t\tdata = buff->data;\n#else\n\t\tbuff = kmalloc(RX_SIZE, GFP_KERNEL);\n\t\tif (!buff)\n\t\t\treturn -ENOMEM;\n\t\tdata = buff;\n#endif\n\t\tdesc->buf_len = RX_SIZE;\n\t\tdesc->data = dma_map_single(&port->netdev->dev, data,\n\t\t\t\t\t    RX_SIZE, DMA_FROM_DEVICE);\n\t\tif (dma_mapping_error(&port->netdev->dev, desc->data)) {\n\t\t\tfree_buffer(buff);\n\t\t\treturn -EIO;\n\t\t}\n\t\tport->rx_buff_tab[i] = buff;\n\t}\n\n\treturn 0;\n}\n\nstatic void destroy_hdlc_queues(struct port *port)\n{\n\tint i;\n\n\tif (port->desc_tab) {\n\t\tfor (i = 0; i < RX_DESCS; i++) {\n\t\t\tstruct desc *desc = rx_desc_ptr(port, i);\n\t\t\tbuffer_t *buff = port->rx_buff_tab[i];\n\n\t\t\tif (buff) {\n\t\t\t\tdma_unmap_single(&port->netdev->dev,\n\t\t\t\t\t\t desc->data, RX_SIZE,\n\t\t\t\t\t\t DMA_FROM_DEVICE);\n\t\t\t\tfree_buffer(buff);\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < TX_DESCS; i++) {\n\t\t\tstruct desc *desc = tx_desc_ptr(port, i);\n\t\t\tbuffer_t *buff = port->tx_buff_tab[i];\n\n\t\t\tif (buff) {\n\t\t\t\tdma_unmap_tx(port, desc);\n\t\t\t\tfree_buffer(buff);\n\t\t\t}\n\t\t}\n\t\tdma_pool_free(dma_pool, port->desc_tab, port->desc_tab_phys);\n\t\tport->desc_tab = NULL;\n\t}\n\n\tif (!ports_open && dma_pool) {\n\t\tdma_pool_destroy(dma_pool);\n\t\tdma_pool = NULL;\n\t}\n}\n\nstatic irqreturn_t hss_hdlc_dcd_irq(int irq, void *data)\n{\n\tstruct net_device *dev = data;\n\tstruct port *port = dev_to_port(dev);\n\tint val;\n\n\tval = gpiod_get_value(port->dcd);\n\thss_hdlc_set_carrier(dev, val);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int hss_hdlc_open(struct net_device *dev)\n{\n\tstruct port *port = dev_to_port(dev);\n\tunsigned long flags;\n\tint i, err = 0;\n\tint val;\n\n\terr = hdlc_open(dev);\n\tif (err)\n\t\treturn err;\n\n\terr = hss_load_firmware(port);\n\tif (err)\n\t\tgoto err_hdlc_close;\n\n\terr = request_hdlc_queues(port);\n\tif (err)\n\t\tgoto err_hdlc_close;\n\n\terr = init_hdlc_queues(port);\n\tif (err)\n\t\tgoto err_destroy_queues;\n\n\tspin_lock_irqsave(&npe_lock, flags);\n\n\t \n\tval = gpiod_get_value(port->dcd);\n\thss_hdlc_set_carrier(dev, val);\n\n\t \n\terr = request_irq(gpiod_to_irq(port->dcd), hss_hdlc_dcd_irq, 0, \"IXP4xx HSS\", dev);\n\tif (err) {\n\t\tdev_err(&dev->dev, \"ixp4xx_hss: failed to request DCD IRQ (%i)\\n\", err);\n\t\tgoto err_unlock;\n\t}\n\n\t \n\tgpiod_set_value(port->dtr, 1);\n\tgpiod_set_value(port->rts, 1);\n\n\tspin_unlock_irqrestore(&npe_lock, flags);\n\n\t \n\tfor (i = 0; i < TX_DESCS; i++)\n\t\tqueue_put_desc(port->txreadyq,\n\t\t\t       tx_desc_phys(port, i), tx_desc_ptr(port, i));\n\n\tfor (i = 0; i < RX_DESCS; i++)\n\t\tqueue_put_desc(port->rxfreeq,\n\t\t\t       rx_desc_phys(port, i), rx_desc_ptr(port, i));\n\n\tnapi_enable(&port->napi);\n\tnetif_start_queue(dev);\n\n\tqmgr_set_irq(port->rxq, QUEUE_IRQ_SRC_NOT_EMPTY,\n\t\t     hss_hdlc_rx_irq, dev);\n\n\tqmgr_set_irq(port->txdoneq, QUEUE_IRQ_SRC_NOT_EMPTY,\n\t\t     hss_hdlc_txdone_irq, dev);\n\tqmgr_enable_irq(port->txdoneq);\n\n\tports_open++;\n\n\thss_set_hdlc_cfg(port);\n\thss_config(port);\n\n\thss_start_hdlc(port);\n\n\t \n\tnapi_schedule(&port->napi);\n\treturn 0;\n\nerr_unlock:\n\tspin_unlock_irqrestore(&npe_lock, flags);\nerr_destroy_queues:\n\tdestroy_hdlc_queues(port);\n\trelease_hdlc_queues(port);\nerr_hdlc_close:\n\thdlc_close(dev);\n\treturn err;\n}\n\nstatic int hss_hdlc_close(struct net_device *dev)\n{\n\tstruct port *port = dev_to_port(dev);\n\tunsigned long flags;\n\tint i, buffs = RX_DESCS;  \n\n\tspin_lock_irqsave(&npe_lock, flags);\n\tports_open--;\n\tqmgr_disable_irq(port->rxq);\n\tnetif_stop_queue(dev);\n\tnapi_disable(&port->napi);\n\n\thss_stop_hdlc(port);\n\n\twhile (queue_get_desc(port->rxfreeq, port, 0) >= 0)\n\t\tbuffs--;\n\twhile (queue_get_desc(port->rxq, port, 0) >= 0)\n\t\tbuffs--;\n\n\tif (buffs)\n\t\tnetdev_crit(dev, \"unable to drain RX queue, %i buffer(s) left in NPE\\n\",\n\t\t\t    buffs);\n\n\tbuffs = TX_DESCS;\n\twhile (queue_get_desc(port->txq, port, 1) >= 0)\n\t\tbuffs--;  \n\n\ti = 0;\n\tdo {\n\t\twhile (queue_get_desc(port->txreadyq, port, 1) >= 0)\n\t\t\tbuffs--;\n\t\tif (!buffs)\n\t\t\tbreak;\n\t} while (++i < MAX_CLOSE_WAIT);\n\n\tif (buffs)\n\t\tnetdev_crit(dev, \"unable to drain TX queue, %i buffer(s) left in NPE\\n\",\n\t\t\t    buffs);\n#if DEBUG_CLOSE\n\tif (!buffs)\n\t\tprintk(KERN_DEBUG \"Draining TX queues took %i cycles\\n\", i);\n#endif\n\tqmgr_disable_irq(port->txdoneq);\n\n\tfree_irq(gpiod_to_irq(port->dcd), dev);\n\t \n\tgpiod_set_value(port->dtr, 0);\n\tgpiod_set_value(port->rts, 0);\n\tspin_unlock_irqrestore(&npe_lock, flags);\n\n\tdestroy_hdlc_queues(port);\n\trelease_hdlc_queues(port);\n\thdlc_close(dev);\n\treturn 0;\n}\n\nstatic int hss_hdlc_attach(struct net_device *dev, unsigned short encoding,\n\t\t\t   unsigned short parity)\n{\n\tstruct port *port = dev_to_port(dev);\n\n\tif (encoding != ENCODING_NRZ)\n\t\treturn -EINVAL;\n\n\tswitch (parity) {\n\tcase PARITY_CRC16_PR1_CCITT:\n\t\tport->hdlc_cfg = 0;\n\t\treturn 0;\n\n\tcase PARITY_CRC32_PR1_CCITT:\n\t\tport->hdlc_cfg = PKT_HDLC_CRC_32;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic u32 check_clock(u32 timer_freq, u32 rate, u32 a, u32 b, u32 c,\n\t\t       u32 *best, u32 *best_diff, u32 *reg)\n{\n\t \n\tu64 new_rate;\n\tu32 new_diff;\n\n\tnew_rate = timer_freq * (u64)(c + 1);\n\tdo_div(new_rate, a * (c + 1) + b + 1);\n\tnew_diff = abs((u32)new_rate - rate);\n\n\tif (new_diff < *best_diff) {\n\t\t*best = new_rate;\n\t\t*best_diff = new_diff;\n\t\t*reg = (a << 22) | (b << 12) | c;\n\t}\n\treturn new_diff;\n}\n\nstatic void find_best_clock(u32 timer_freq, u32 rate, u32 *best, u32 *reg)\n{\n\tu32 a, b, diff = 0xFFFFFFFF;\n\n\ta = timer_freq / rate;\n\n\tif (a > 0x3FF) {  \n\t\tcheck_clock(timer_freq, rate, 0x3FF, 1, 1, best, &diff, reg);\n\t\treturn;\n\t}\n\tif (a == 0) {  \n\t\ta = 1;  \n\t\trate = timer_freq;\n\t}\n\n\tif (rate * a == timer_freq) {  \n\t\tcheck_clock(timer_freq, rate, a - 1, 1, 1, best, &diff, reg);\n\t\treturn;\n\t}\n\n\tfor (b = 0; b < 0x400; b++) {\n\t\tu64 c = (b + 1) * (u64)rate;\n\n\t\tdo_div(c, timer_freq - rate * a);\n\t\tc--;\n\t\tif (c >= 0xFFF) {  \n\t\t\tif (b == 0 &&  \n\t\t\t    !check_clock(timer_freq, rate, a - 1, 1, 1, best,\n\t\t\t\t\t &diff, reg))\n\t\t\t\treturn;\n\t\t\tcheck_clock(timer_freq, rate, a, b, 0xFFF, best,\n\t\t\t\t    &diff, reg);\n\t\t\treturn;\n\t\t}\n\t\tif (!check_clock(timer_freq, rate, a, b, c, best, &diff, reg))\n\t\t\treturn;\n\t\tif (!check_clock(timer_freq, rate, a, b, c + 1, best, &diff,\n\t\t\t\t reg))\n\t\t\treturn;\n\t}\n}\n\nstatic int hss_hdlc_set_clock(struct port *port, unsigned int clock_type)\n{\n\tswitch (clock_type) {\n\tcase CLOCK_DEFAULT:\n\tcase CLOCK_EXT:\n\t\tgpiod_set_value(port->clk_internal, 0);\n\t\treturn CLOCK_EXT;\n\tcase CLOCK_INT:\n\t\tgpiod_set_value(port->clk_internal, 1);\n\t\treturn CLOCK_INT;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic int hss_hdlc_ioctl(struct net_device *dev, struct if_settings *ifs)\n{\n\tconst size_t size = sizeof(sync_serial_settings);\n\tsync_serial_settings new_line;\n\tsync_serial_settings __user *line = ifs->ifs_ifsu.sync;\n\tstruct port *port = dev_to_port(dev);\n\tunsigned long flags;\n\tint clk;\n\n\tswitch (ifs->type) {\n\tcase IF_GET_IFACE:\n\t\tifs->type = IF_IFACE_V35;\n\t\tif (ifs->size < size) {\n\t\t\tifs->size = size;  \n\t\t\treturn -ENOBUFS;\n\t\t}\n\t\tmemset(&new_line, 0, sizeof(new_line));\n\t\tnew_line.clock_type = port->clock_type;\n\t\tnew_line.clock_rate = port->clock_rate;\n\t\tnew_line.loopback = port->loopback;\n\t\tif (copy_to_user(line, &new_line, size))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tcase IF_IFACE_SYNC_SERIAL:\n\tcase IF_IFACE_V35:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn -EPERM;\n\t\tif (copy_from_user(&new_line, line, size))\n\t\t\treturn -EFAULT;\n\n\t\tclk = new_line.clock_type;\n\t\thss_hdlc_set_clock(port, clk);\n\n\t\tif (clk != CLOCK_EXT && clk != CLOCK_INT)\n\t\t\treturn -EINVAL;\t \n\n\t\tif (new_line.loopback != 0 && new_line.loopback != 1)\n\t\t\treturn -EINVAL;\n\n\t\tport->clock_type = clk;  \n\t\tif (clk == CLOCK_INT) {\n\t\t\tfind_best_clock(IXP4XX_TIMER_FREQ,\n\t\t\t\t\tnew_line.clock_rate,\n\t\t\t\t\t&port->clock_rate, &port->clock_reg);\n\t\t} else {\n\t\t\tport->clock_rate = 0;\n\t\t\tport->clock_reg = CLK42X_SPEED_2048KHZ;\n\t\t}\n\t\tport->loopback = new_line.loopback;\n\n\t\tspin_lock_irqsave(&npe_lock, flags);\n\n\t\tif (dev->flags & IFF_UP)\n\t\t\thss_config(port);\n\n\t\tif (port->loopback || port->carrier)\n\t\t\tnetif_carrier_on(port->netdev);\n\t\telse\n\t\t\tnetif_carrier_off(port->netdev);\n\t\tspin_unlock_irqrestore(&npe_lock, flags);\n\n\t\treturn 0;\n\n\tdefault:\n\t\treturn hdlc_ioctl(dev, ifs);\n\t}\n}\n\n \n\nstatic const struct net_device_ops hss_hdlc_ops = {\n\t.ndo_open       = hss_hdlc_open,\n\t.ndo_stop       = hss_hdlc_close,\n\t.ndo_start_xmit = hdlc_start_xmit,\n\t.ndo_siocwandev = hss_hdlc_ioctl,\n};\n\nstatic int ixp4xx_hss_probe(struct platform_device *pdev)\n{\n\tstruct of_phandle_args queue_spec;\n\tstruct of_phandle_args npe_spec;\n\tstruct device *dev = &pdev->dev;\n\tstruct net_device *ndev;\n\tstruct device_node *np;\n\tstruct regmap *rmap;\n\tstruct port *port;\n\thdlc_device *hdlc;\n\tint err;\n\tu32 val;\n\n\t \n\trmap = syscon_regmap_lookup_by_compatible(\"syscon\");\n\tif (IS_ERR(rmap))\n\t\treturn dev_err_probe(dev, PTR_ERR(rmap),\n\t\t\t\t     \"failed to look up syscon\\n\");\n\n\tval = cpu_ixp4xx_features(rmap);\n\n\tif ((val & (IXP4XX_FEATURE_HDLC | IXP4XX_FEATURE_HSS)) !=\n\t    (IXP4XX_FEATURE_HDLC | IXP4XX_FEATURE_HSS)) {\n\t\tdev_err(dev, \"HDLC and HSS feature unavailable in platform\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tnp = dev->of_node;\n\n\tport = devm_kzalloc(dev, sizeof(*port), GFP_KERNEL);\n\tif (!port)\n\t\treturn -ENOMEM;\n\n\terr = of_parse_phandle_with_fixed_args(np, \"intel,npe-handle\", 1, 0,\n\t\t\t\t\t       &npe_spec);\n\tif (err)\n\t\treturn dev_err_probe(dev, err, \"no NPE engine specified\\n\");\n\t \n\tport->npe = npe_request(npe_spec.args[0] << 4);\n\tif (!port->npe) {\n\t\tdev_err(dev, \"unable to obtain NPE instance\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\t \n\terr = of_parse_phandle_with_fixed_args(np, \"intek,queue-chl-txready\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (err)\n\t\treturn dev_err_probe(dev, err, \"no txready queue phandle\\n\");\n\tport->txreadyq = queue_spec.args[0];\n\t \n\terr = of_parse_phandle_with_fixed_args(np, \"intek,queue-chl-rxtrig\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (err)\n\t\treturn dev_err_probe(dev, err, \"no rxtrig queue phandle\\n\");\n\tport->rxtrigq = queue_spec.args[0];\n\t \n\terr = of_parse_phandle_with_fixed_args(np, \"intek,queue-pkt-rx\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (err)\n\t\treturn dev_err_probe(dev, err, \"no RX queue phandle\\n\");\n\tport->rxq = queue_spec.args[0];\n\t \n\terr = of_parse_phandle_with_fixed_args(np, \"intek,queue-pkt-tx\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (err)\n\t\treturn dev_err_probe(dev, err, \"no RX queue phandle\\n\");\n\tport->txq = queue_spec.args[0];\n\t \n\terr = of_parse_phandle_with_fixed_args(np, \"intek,queue-pkt-rxfree\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (err)\n\t\treturn dev_err_probe(dev, err, \"no RX free queue phandle\\n\");\n\tport->rxfreeq = queue_spec.args[0];\n\t \n\terr = of_parse_phandle_with_fixed_args(np, \"intek,queue-pkt-txdone\", 1, 0,\n\t\t\t\t\t       &queue_spec);\n\tif (err)\n\t\treturn dev_err_probe(dev, err, \"no TX done queue phandle\\n\");\n\tport->txdoneq = queue_spec.args[0];\n\n\t \n\tport->cts = devm_gpiod_get(dev, \"cts\", GPIOD_OUT_LOW);\n\tif (IS_ERR(port->cts))\n\t\treturn dev_err_probe(dev, PTR_ERR(port->cts), \"unable to get CTS GPIO\\n\");\n\tport->rts = devm_gpiod_get(dev, \"rts\", GPIOD_OUT_LOW);\n\tif (IS_ERR(port->rts))\n\t\treturn dev_err_probe(dev, PTR_ERR(port->rts), \"unable to get RTS GPIO\\n\");\n\tport->dcd = devm_gpiod_get(dev, \"dcd\", GPIOD_IN);\n\tif (IS_ERR(port->dcd))\n\t\treturn dev_err_probe(dev, PTR_ERR(port->dcd), \"unable to get DCD GPIO\\n\");\n\tport->dtr = devm_gpiod_get(dev, \"dtr\", GPIOD_OUT_LOW);\n\tif (IS_ERR(port->dtr))\n\t\treturn dev_err_probe(dev, PTR_ERR(port->dtr), \"unable to get DTR GPIO\\n\");\n\tport->clk_internal = devm_gpiod_get(dev, \"clk-internal\", GPIOD_OUT_LOW);\n\tif (IS_ERR(port->clk_internal))\n\t\treturn dev_err_probe(dev, PTR_ERR(port->clk_internal),\n\t\t\t\t     \"unable to get CLK internal GPIO\\n\");\n\n\tndev = alloc_hdlcdev(port);\n\tport->netdev = alloc_hdlcdev(port);\n\tif (!port->netdev) {\n\t\terr = -ENOMEM;\n\t\tgoto err_plat;\n\t}\n\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\thdlc = dev_to_hdlc(ndev);\n\thdlc->attach = hss_hdlc_attach;\n\thdlc->xmit = hss_hdlc_xmit;\n\tndev->netdev_ops = &hss_hdlc_ops;\n\tndev->tx_queue_len = 100;\n\tport->clock_type = CLOCK_EXT;\n\tport->clock_rate = 0;\n\tport->clock_reg = CLK42X_SPEED_2048KHZ;\n\tport->id = pdev->id;\n\tport->dev = &pdev->dev;\n\tnetif_napi_add_weight(ndev, &port->napi, hss_hdlc_poll, NAPI_WEIGHT);\n\n\terr = register_hdlc_device(ndev);\n\tif (err)\n\t\tgoto err_free_netdev;\n\n\tplatform_set_drvdata(pdev, port);\n\n\tnetdev_info(ndev, \"initialized\\n\");\n\treturn 0;\n\nerr_free_netdev:\n\tfree_netdev(ndev);\nerr_plat:\n\tnpe_release(port->npe);\n\treturn err;\n}\n\nstatic int ixp4xx_hss_remove(struct platform_device *pdev)\n{\n\tstruct port *port = platform_get_drvdata(pdev);\n\n\tunregister_hdlc_device(port->netdev);\n\tfree_netdev(port->netdev);\n\tnpe_release(port->npe);\n\treturn 0;\n}\n\nstatic struct platform_driver ixp4xx_hss_driver = {\n\t.driver.name\t= DRV_NAME,\n\t.probe\t\t= ixp4xx_hss_probe,\n\t.remove\t\t= ixp4xx_hss_remove,\n};\nmodule_platform_driver(ixp4xx_hss_driver);\n\nMODULE_AUTHOR(\"Krzysztof Halasa\");\nMODULE_DESCRIPTION(\"Intel IXP4xx HSS driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS(\"platform:ixp4xx_hss\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}