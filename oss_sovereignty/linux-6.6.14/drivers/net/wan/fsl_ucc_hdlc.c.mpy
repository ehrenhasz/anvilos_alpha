{
  "module_name": "fsl_ucc_hdlc.c",
  "hash_id": "f1ec457771629b7f659c78daf3fa65f195cd1fc7b80098eb80961e6d88a3ad06",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wan/fsl_ucc_hdlc.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n#include <linux/dma-mapping.h>\n#include <linux/hdlc.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/irq.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/of_platform.h>\n#include <linux/platform_device.h>\n#include <linux/sched.h>\n#include <linux/skbuff.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/stddef.h>\n#include <soc/fsl/qe/qe_tdm.h>\n#include <uapi/linux/if_arp.h>\n\n#include \"fsl_ucc_hdlc.h\"\n\n#define DRV_DESC \"Freescale QE UCC HDLC Driver\"\n#define DRV_NAME \"ucc_hdlc\"\n\n#define TDM_PPPOHT_SLIC_MAXIN\n#define RX_BD_ERRORS (R_CD_S | R_OV_S | R_CR_S | R_AB_S | R_NO_S | R_LG_S)\n\nstatic int uhdlc_close(struct net_device *dev);\n\nstatic struct ucc_tdm_info utdm_primary_info = {\n\t.uf_info = {\n\t\t.tsa = 0,\n\t\t.cdp = 0,\n\t\t.cds = 1,\n\t\t.ctsp = 1,\n\t\t.ctss = 1,\n\t\t.revd = 0,\n\t\t.urfs = 256,\n\t\t.utfs = 256,\n\t\t.urfet = 128,\n\t\t.urfset = 192,\n\t\t.utfet = 128,\n\t\t.utftt = 0x40,\n\t\t.ufpt = 256,\n\t\t.mode = UCC_FAST_PROTOCOL_MODE_HDLC,\n\t\t.ttx_trx = UCC_FAST_GUMR_TRANSPARENT_TTX_TRX_NORMAL,\n\t\t.tenc = UCC_FAST_TX_ENCODING_NRZ,\n\t\t.renc = UCC_FAST_RX_ENCODING_NRZ,\n\t\t.tcrc = UCC_FAST_16_BIT_CRC,\n\t\t.synl = UCC_FAST_SYNC_LEN_NOT_USED,\n\t},\n\n\t.si_info = {\n#ifdef TDM_PPPOHT_SLIC_MAXIN\n\t\t.simr_rfsd = 1,\n\t\t.simr_tfsd = 2,\n#else\n\t\t.simr_rfsd = 0,\n\t\t.simr_tfsd = 0,\n#endif\n\t\t.simr_crt = 0,\n\t\t.simr_sl = 0,\n\t\t.simr_ce = 1,\n\t\t.simr_fe = 1,\n\t\t.simr_gm = 0,\n\t},\n};\n\nstatic struct ucc_tdm_info utdm_info[UCC_MAX_NUM];\n\nstatic int uhdlc_init(struct ucc_hdlc_private *priv)\n{\n\tstruct ucc_tdm_info *ut_info;\n\tstruct ucc_fast_info *uf_info;\n\tu32 cecr_subblock;\n\tu16 bd_status;\n\tint ret, i;\n\tvoid *bd_buffer;\n\tdma_addr_t bd_dma_addr;\n\ts32 riptr;\n\ts32 tiptr;\n\tu32 gumr;\n\n\tut_info = priv->ut_info;\n\tuf_info = &ut_info->uf_info;\n\n\tif (priv->tsa) {\n\t\tuf_info->tsa = 1;\n\t\tuf_info->ctsp = 1;\n\t\tuf_info->cds = 1;\n\t\tuf_info->ctss = 1;\n\t} else {\n\t\tuf_info->cds = 0;\n\t\tuf_info->ctsp = 0;\n\t\tuf_info->ctss = 0;\n\t}\n\n\t \n\tif (priv->hdlc_bus)\n\t\tuf_info->brkpt_support = 1;\n\n\tuf_info->uccm_mask = ((UCC_HDLC_UCCE_RXB | UCC_HDLC_UCCE_RXF |\n\t\t\t\tUCC_HDLC_UCCE_TXB) << 16);\n\n\tret = ucc_fast_init(uf_info, &priv->uccf);\n\tif (ret) {\n\t\tdev_err(priv->dev, \"Failed to init uccf.\");\n\t\treturn ret;\n\t}\n\n\tpriv->uf_regs = priv->uccf->uf_regs;\n\tucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\n\n\t \n\tif (priv->loopback) {\n\t\tdev_info(priv->dev, \"Loopback Mode\\n\");\n\t\t \n\t\tqe_setbrg(ut_info->uf_info.rx_clock, 20000000, 1);\n\n\t\tgumr = ioread32be(&priv->uf_regs->gumr);\n\t\tgumr |= (UCC_FAST_GUMR_LOOPBACK | UCC_FAST_GUMR_CDS |\n\t\t\t UCC_FAST_GUMR_TCI);\n\t\tgumr &= ~(UCC_FAST_GUMR_CTSP | UCC_FAST_GUMR_RSYN);\n\t\tiowrite32be(gumr, &priv->uf_regs->gumr);\n\t}\n\n\t \n\tif (priv->tsa)\n\t\tucc_tdm_init(priv->utdm, priv->ut_info);\n\n\t \n\tcecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\n\tret = qe_issue_cmd(QE_STOP_TX, cecr_subblock,\n\t\t\t   QE_CR_PROTOCOL_UNSPECIFIED, 0);\n\n\t \n\tiowrite32be(0, &priv->uf_regs->upsmr);\n\n\t \n\tif (priv->hdlc_bus) {\n\t\tu32 upsmr;\n\n\t\tdev_info(priv->dev, \"HDLC bus Mode\\n\");\n\t\tupsmr = ioread32be(&priv->uf_regs->upsmr);\n\n\t\t \n\t\tupsmr |= UCC_HDLC_UPSMR_RTE | UCC_HDLC_UPSMR_BUS |\n\t\t\t\tUCC_HDLC_UPSMR_CW8;\n\t\tiowrite32be(upsmr, &priv->uf_regs->upsmr);\n\n\t\t \n\t\tgumr = ioread32be(&priv->uf_regs->gumr);\n\t\tgumr &= ~(UCC_FAST_GUMR_CDS | UCC_FAST_GUMR_CTSP);\n\t\t \n\t\tgumr |= UCC_FAST_GUMR_SYNL_AUTO;\n\t\tiowrite32be(gumr, &priv->uf_regs->gumr);\n\t}\n\n\tpriv->rx_ring_size = RX_BD_RING_LEN;\n\tpriv->tx_ring_size = TX_BD_RING_LEN;\n\t \n\tpriv->rx_bd_base = dma_alloc_coherent(priv->dev,\n\t\t\tRX_BD_RING_LEN * sizeof(struct qe_bd),\n\t\t\t&priv->dma_rx_bd, GFP_KERNEL);\n\n\tif (!priv->rx_bd_base) {\n\t\tdev_err(priv->dev, \"Cannot allocate MURAM memory for RxBDs\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_uccf;\n\t}\n\n\t \n\tpriv->tx_bd_base = dma_alloc_coherent(priv->dev,\n\t\t\tTX_BD_RING_LEN * sizeof(struct qe_bd),\n\t\t\t&priv->dma_tx_bd, GFP_KERNEL);\n\n\tif (!priv->tx_bd_base) {\n\t\tdev_err(priv->dev, \"Cannot allocate MURAM memory for TxBDs\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_rx_bd;\n\t}\n\n\t \n\tpriv->ucc_pram_offset = qe_muram_alloc(sizeof(struct ucc_hdlc_param),\n\t\t\t\tALIGNMENT_OF_UCC_HDLC_PRAM);\n\n\tif (priv->ucc_pram_offset < 0) {\n\t\tdev_err(priv->dev, \"Can not allocate MURAM for hdlc parameter.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_tx_bd;\n\t}\n\n\tpriv->rx_skbuff = kcalloc(priv->rx_ring_size,\n\t\t\t\t  sizeof(*priv->rx_skbuff),\n\t\t\t\t  GFP_KERNEL);\n\tif (!priv->rx_skbuff) {\n\t\tret = -ENOMEM;\n\t\tgoto free_ucc_pram;\n\t}\n\n\tpriv->tx_skbuff = kcalloc(priv->tx_ring_size,\n\t\t\t\t  sizeof(*priv->tx_skbuff),\n\t\t\t\t  GFP_KERNEL);\n\tif (!priv->tx_skbuff) {\n\t\tret = -ENOMEM;\n\t\tgoto free_rx_skbuff;\n\t}\n\n\tpriv->skb_curtx = 0;\n\tpriv->skb_dirtytx = 0;\n\tpriv->curtx_bd = priv->tx_bd_base;\n\tpriv->dirty_tx = priv->tx_bd_base;\n\tpriv->currx_bd = priv->rx_bd_base;\n\tpriv->currx_bdnum = 0;\n\n\t \n\tcecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\n\tret = qe_issue_cmd(QE_ASSIGN_PAGE_TO_DEVICE, cecr_subblock,\n\t\t\t   QE_CR_PROTOCOL_UNSPECIFIED, priv->ucc_pram_offset);\n\n\tpriv->ucc_pram = (struct ucc_hdlc_param __iomem *)\n\t\t\t\t\tqe_muram_addr(priv->ucc_pram_offset);\n\n\t \n\tmemset_io(priv->ucc_pram, 0, sizeof(struct ucc_hdlc_param));\n\n\t \n\triptr = qe_muram_alloc(32, 32);\n\tif (riptr < 0) {\n\t\tdev_err(priv->dev, \"Cannot allocate MURAM mem for Receive internal temp data pointer\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_tx_skbuff;\n\t}\n\n\ttiptr = qe_muram_alloc(32, 32);\n\tif (tiptr < 0) {\n\t\tdev_err(priv->dev, \"Cannot allocate MURAM mem for Transmit internal temp data pointer\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_riptr;\n\t}\n\tif (riptr != (u16)riptr || tiptr != (u16)tiptr) {\n\t\tdev_err(priv->dev, \"MURAM allocation out of addressable range\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_tiptr;\n\t}\n\n\t \n\tiowrite16be(riptr, &priv->ucc_pram->riptr);\n\tiowrite16be(tiptr, &priv->ucc_pram->tiptr);\n\n\t \n\tiowrite16be(MAX_RX_BUF_LENGTH, &priv->ucc_pram->mrblr);\n\n\t \n\tiowrite32be(priv->dma_rx_bd, &priv->ucc_pram->rbase);\n\tiowrite32be(priv->dma_tx_bd, &priv->ucc_pram->tbase);\n\n\t \n\tiowrite32be(BMR_GBL | BMR_BIG_ENDIAN, &priv->ucc_pram->rstate);\n\tiowrite32be(BMR_GBL | BMR_BIG_ENDIAN, &priv->ucc_pram->tstate);\n\n\t \n\tiowrite32be(CRC_16BIT_MASK, &priv->ucc_pram->c_mask);\n\tiowrite32be(CRC_16BIT_PRES, &priv->ucc_pram->c_pres);\n\n\tiowrite16be(MAX_FRAME_LENGTH, &priv->ucc_pram->mflr);\n\tiowrite16be(DEFAULT_RFTHR, &priv->ucc_pram->rfthr);\n\tiowrite16be(DEFAULT_RFTHR, &priv->ucc_pram->rfcnt);\n\tiowrite16be(priv->hmask, &priv->ucc_pram->hmask);\n\tiowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr1);\n\tiowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr2);\n\tiowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr3);\n\tiowrite16be(DEFAULT_HDLC_ADDR, &priv->ucc_pram->haddr4);\n\n\t \n\tbd_buffer = dma_alloc_coherent(priv->dev,\n\t\t\t\t       (RX_BD_RING_LEN + TX_BD_RING_LEN) * MAX_RX_BUF_LENGTH,\n\t\t\t\t       &bd_dma_addr, GFP_KERNEL);\n\n\tif (!bd_buffer) {\n\t\tdev_err(priv->dev, \"Could not allocate buffer descriptors\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto free_tiptr;\n\t}\n\n\tpriv->rx_buffer = bd_buffer;\n\tpriv->tx_buffer = bd_buffer + RX_BD_RING_LEN * MAX_RX_BUF_LENGTH;\n\n\tpriv->dma_rx_addr = bd_dma_addr;\n\tpriv->dma_tx_addr = bd_dma_addr + RX_BD_RING_LEN * MAX_RX_BUF_LENGTH;\n\n\tfor (i = 0; i < RX_BD_RING_LEN; i++) {\n\t\tif (i < (RX_BD_RING_LEN - 1))\n\t\t\tbd_status = R_E_S | R_I_S;\n\t\telse\n\t\t\tbd_status = R_E_S | R_I_S | R_W_S;\n\n\t\tpriv->rx_bd_base[i].status = cpu_to_be16(bd_status);\n\t\tpriv->rx_bd_base[i].buf = cpu_to_be32(priv->dma_rx_addr + i * MAX_RX_BUF_LENGTH);\n\t}\n\n\tfor (i = 0; i < TX_BD_RING_LEN; i++) {\n\t\tif (i < (TX_BD_RING_LEN - 1))\n\t\t\tbd_status =  T_I_S | T_TC_S;\n\t\telse\n\t\t\tbd_status =  T_I_S | T_TC_S | T_W_S;\n\n\t\tpriv->tx_bd_base[i].status = cpu_to_be16(bd_status);\n\t\tpriv->tx_bd_base[i].buf = cpu_to_be32(priv->dma_tx_addr + i * MAX_RX_BUF_LENGTH);\n\t}\n\tdma_wmb();\n\n\treturn 0;\n\nfree_tiptr:\n\tqe_muram_free(tiptr);\nfree_riptr:\n\tqe_muram_free(riptr);\nfree_tx_skbuff:\n\tkfree(priv->tx_skbuff);\nfree_rx_skbuff:\n\tkfree(priv->rx_skbuff);\nfree_ucc_pram:\n\tqe_muram_free(priv->ucc_pram_offset);\nfree_tx_bd:\n\tdma_free_coherent(priv->dev,\n\t\t\t  TX_BD_RING_LEN * sizeof(struct qe_bd),\n\t\t\t  priv->tx_bd_base, priv->dma_tx_bd);\nfree_rx_bd:\n\tdma_free_coherent(priv->dev,\n\t\t\t  RX_BD_RING_LEN * sizeof(struct qe_bd),\n\t\t\t  priv->rx_bd_base, priv->dma_rx_bd);\nfree_uccf:\n\tucc_fast_free(priv->uccf);\n\n\treturn ret;\n}\n\nstatic netdev_tx_t ucc_hdlc_tx(struct sk_buff *skb, struct net_device *dev)\n{\n\thdlc_device *hdlc = dev_to_hdlc(dev);\n\tstruct ucc_hdlc_private *priv = (struct ucc_hdlc_private *)hdlc->priv;\n\tstruct qe_bd *bd;\n\tu16 bd_status;\n\tunsigned long flags;\n\t__be16 *proto_head;\n\n\tswitch (dev->type) {\n\tcase ARPHRD_RAWHDLC:\n\t\tif (skb_headroom(skb) < HDLC_HEAD_LEN) {\n\t\t\tdev->stats.tx_dropped++;\n\t\t\tdev_kfree_skb(skb);\n\t\t\tnetdev_err(dev, \"No enough space for hdlc head\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tskb_push(skb, HDLC_HEAD_LEN);\n\n\t\tproto_head = (__be16 *)skb->data;\n\t\t*proto_head = htons(DEFAULT_HDLC_HEAD);\n\n\t\tdev->stats.tx_bytes += skb->len;\n\t\tbreak;\n\n\tcase ARPHRD_PPP:\n\t\tproto_head = (__be16 *)skb->data;\n\t\tif (*proto_head != htons(DEFAULT_PPP_HEAD)) {\n\t\t\tdev->stats.tx_dropped++;\n\t\t\tdev_kfree_skb(skb);\n\t\t\tnetdev_err(dev, \"Wrong ppp header\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tdev->stats.tx_bytes += skb->len;\n\t\tbreak;\n\n\tcase ARPHRD_ETHER:\n\t\tdev->stats.tx_bytes += skb->len;\n\t\tbreak;\n\n\tdefault:\n\t\tdev->stats.tx_dropped++;\n\t\tdev_kfree_skb(skb);\n\t\treturn -ENOMEM;\n\t}\n\tnetdev_sent_queue(dev, skb->len);\n\tspin_lock_irqsave(&priv->lock, flags);\n\n\tdma_rmb();\n\t \n\tbd = priv->curtx_bd;\n\tbd_status = be16_to_cpu(bd->status);\n\t \n\tpriv->tx_skbuff[priv->skb_curtx] = skb;\n\n\t \n\tpriv->skb_curtx =\n\t    (priv->skb_curtx + 1) & TX_RING_MOD_MASK(TX_BD_RING_LEN);\n\n\t \n\tmemcpy(priv->tx_buffer + (be32_to_cpu(bd->buf) - priv->dma_tx_addr),\n\t       skb->data, skb->len);\n\n\t \n\tbd_status = (bd_status & T_W_S) | T_R_S | T_I_S | T_L_S | T_TC_S;\n\n\tbd->length = cpu_to_be16(skb->len);\n\tbd->status = cpu_to_be16(bd_status);\n\n\t \n\tif (!(bd_status & T_W_S))\n\t\tbd += 1;\n\telse\n\t\tbd = priv->tx_bd_base;\n\n\tif (bd == priv->dirty_tx) {\n\t\tif (!netif_queue_stopped(dev))\n\t\t\tnetif_stop_queue(dev);\n\t}\n\n\tpriv->curtx_bd = bd;\n\n\tspin_unlock_irqrestore(&priv->lock, flags);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic int hdlc_tx_restart(struct ucc_hdlc_private *priv)\n{\n\tu32 cecr_subblock;\n\n\tcecr_subblock =\n\t\tucc_fast_get_qe_cr_subblock(priv->ut_info->uf_info.ucc_num);\n\n\tqe_issue_cmd(QE_RESTART_TX, cecr_subblock,\n\t\t     QE_CR_PROTOCOL_UNSPECIFIED, 0);\n\treturn 0;\n}\n\nstatic int hdlc_tx_done(struct ucc_hdlc_private *priv)\n{\n\t \n\tstruct net_device *dev = priv->ndev;\n\tunsigned int bytes_sent = 0;\n\tint howmany = 0;\n\tstruct qe_bd *bd;\t\t \n\tu16 bd_status;\n\tint tx_restart = 0;\n\n\tdma_rmb();\n\tbd = priv->dirty_tx;\n\tbd_status = be16_to_cpu(bd->status);\n\n\t \n\twhile ((bd_status & T_R_S) == 0) {\n\t\tstruct sk_buff *skb;\n\n\t\tif (bd_status & T_UN_S) {  \n\t\t\tdev->stats.tx_fifo_errors++;\n\t\t\ttx_restart = 1;\n\t\t}\n\t\tif (bd_status & T_CT_S) {  \n\t\t\tdev->stats.tx_carrier_errors++;\n\t\t\ttx_restart = 1;\n\t\t}\n\n\t\t \n\t\t \n\t\t \n\n\t\tskb = priv->tx_skbuff[priv->skb_dirtytx];\n\t\tif (!skb)\n\t\t\tbreak;\n\t\thowmany++;\n\t\tbytes_sent += skb->len;\n\t\tdev->stats.tx_packets++;\n\t\tmemset(priv->tx_buffer +\n\t\t       (be32_to_cpu(bd->buf) - priv->dma_tx_addr),\n\t\t       0, skb->len);\n\t\tdev_consume_skb_irq(skb);\n\n\t\tpriv->tx_skbuff[priv->skb_dirtytx] = NULL;\n\t\tpriv->skb_dirtytx =\n\t\t    (priv->skb_dirtytx +\n\t\t     1) & TX_RING_MOD_MASK(TX_BD_RING_LEN);\n\n\t\t \n\t\tif (netif_queue_stopped(dev))\n\t\t\tnetif_wake_queue(dev);\n\n\t\t \n\t\tif (!(bd_status & T_W_S))\n\t\t\tbd += 1;\n\t\telse\n\t\t\tbd = priv->tx_bd_base;\n\t\tbd_status = be16_to_cpu(bd->status);\n\t}\n\tpriv->dirty_tx = bd;\n\n\tif (tx_restart)\n\t\thdlc_tx_restart(priv);\n\n\tnetdev_completed_queue(dev, howmany, bytes_sent);\n\treturn 0;\n}\n\nstatic int hdlc_rx_done(struct ucc_hdlc_private *priv, int rx_work_limit)\n{\n\tstruct net_device *dev = priv->ndev;\n\tstruct sk_buff *skb = NULL;\n\thdlc_device *hdlc = dev_to_hdlc(dev);\n\tstruct qe_bd *bd;\n\tu16 bd_status;\n\tu16 length, howmany = 0;\n\tu8 *bdbuffer;\n\n\tdma_rmb();\n\tbd = priv->currx_bd;\n\tbd_status = be16_to_cpu(bd->status);\n\n\t \n\twhile (!((bd_status & (R_E_S)) || (--rx_work_limit < 0))) {\n\t\tif (bd_status & (RX_BD_ERRORS)) {\n\t\t\tdev->stats.rx_errors++;\n\n\t\t\tif (bd_status & R_CD_S)\n\t\t\t\tdev->stats.collisions++;\n\t\t\tif (bd_status & R_OV_S)\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\tif (bd_status & R_CR_S)\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tif (bd_status & R_AB_S)\n\t\t\t\tdev->stats.rx_over_errors++;\n\t\t\tif (bd_status & R_NO_S)\n\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\tif (bd_status & R_LG_S)\n\t\t\t\tdev->stats.rx_length_errors++;\n\n\t\t\tgoto recycle;\n\t\t}\n\t\tbdbuffer = priv->rx_buffer +\n\t\t\t(priv->currx_bdnum * MAX_RX_BUF_LENGTH);\n\t\tlength = be16_to_cpu(bd->length);\n\n\t\tswitch (dev->type) {\n\t\tcase ARPHRD_RAWHDLC:\n\t\t\tbdbuffer += HDLC_HEAD_LEN;\n\t\t\tlength -= (HDLC_HEAD_LEN + HDLC_CRC_SIZE);\n\n\t\t\tskb = dev_alloc_skb(length);\n\t\t\tif (!skb) {\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\tskb_put(skb, length);\n\t\t\tskb->len = length;\n\t\t\tskb->dev = dev;\n\t\t\tmemcpy(skb->data, bdbuffer, length);\n\t\t\tbreak;\n\n\t\tcase ARPHRD_PPP:\n\t\tcase ARPHRD_ETHER:\n\t\t\tlength -= HDLC_CRC_SIZE;\n\n\t\t\tskb = dev_alloc_skb(length);\n\t\t\tif (!skb) {\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\n\t\t\tskb_put(skb, length);\n\t\t\tskb->len = length;\n\t\t\tskb->dev = dev;\n\t\t\tmemcpy(skb->data, bdbuffer, length);\n\t\t\tbreak;\n\t\t}\n\n\t\tdev->stats.rx_packets++;\n\t\tdev->stats.rx_bytes += skb->len;\n\t\thowmany++;\n\t\tif (hdlc->proto)\n\t\t\tskb->protocol = hdlc_type_trans(skb, dev);\n\t\tnetif_receive_skb(skb);\n\nrecycle:\n\t\tbd->status = cpu_to_be16((bd_status & R_W_S) | R_E_S | R_I_S);\n\n\t\t \n\t\tif (bd_status & R_W_S) {\n\t\t\tpriv->currx_bdnum = 0;\n\t\t\tbd = priv->rx_bd_base;\n\t\t} else {\n\t\t\tif (priv->currx_bdnum < (RX_BD_RING_LEN - 1))\n\t\t\t\tpriv->currx_bdnum += 1;\n\t\t\telse\n\t\t\t\tpriv->currx_bdnum = RX_BD_RING_LEN - 1;\n\n\t\t\tbd += 1;\n\t\t}\n\n\t\tbd_status = be16_to_cpu(bd->status);\n\t}\n\tdma_rmb();\n\n\tpriv->currx_bd = bd;\n\treturn howmany;\n}\n\nstatic int ucc_hdlc_poll(struct napi_struct *napi, int budget)\n{\n\tstruct ucc_hdlc_private *priv = container_of(napi,\n\t\t\t\t\t\t     struct ucc_hdlc_private,\n\t\t\t\t\t\t     napi);\n\tint howmany;\n\n\t \n\tspin_lock(&priv->lock);\n\thdlc_tx_done(priv);\n\tspin_unlock(&priv->lock);\n\n\thowmany = 0;\n\thowmany += hdlc_rx_done(priv, budget - howmany);\n\n\tif (howmany < budget) {\n\t\tnapi_complete_done(napi, howmany);\n\t\tqe_setbits_be32(priv->uccf->p_uccm,\n\t\t\t\t(UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS) << 16);\n\t}\n\n\treturn howmany;\n}\n\nstatic irqreturn_t ucc_hdlc_irq_handler(int irq, void *dev_id)\n{\n\tstruct ucc_hdlc_private *priv = (struct ucc_hdlc_private *)dev_id;\n\tstruct net_device *dev = priv->ndev;\n\tstruct ucc_fast_private *uccf;\n\tu32 ucce;\n\tu32 uccm;\n\n\tuccf = priv->uccf;\n\n\tucce = ioread32be(uccf->p_ucce);\n\tuccm = ioread32be(uccf->p_uccm);\n\tucce &= uccm;\n\tiowrite32be(ucce, uccf->p_ucce);\n\tif (!ucce)\n\t\treturn IRQ_NONE;\n\n\tif ((ucce >> 16) & (UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS)) {\n\t\tif (napi_schedule_prep(&priv->napi)) {\n\t\t\tuccm &= ~((UCCE_HDLC_RX_EVENTS | UCCE_HDLC_TX_EVENTS)\n\t\t\t\t  << 16);\n\t\t\tiowrite32be(uccm, uccf->p_uccm);\n\t\t\t__napi_schedule(&priv->napi);\n\t\t}\n\t}\n\n\t \n\tif (ucce >> 16 & UCC_HDLC_UCCE_BSY)\n\t\tdev->stats.rx_missed_errors++;\n\tif (ucce >> 16 & UCC_HDLC_UCCE_TXE)\n\t\tdev->stats.tx_errors++;\n\n\treturn IRQ_HANDLED;\n}\n\nstatic int uhdlc_ioctl(struct net_device *dev, struct if_settings *ifs)\n{\n\tconst size_t size = sizeof(te1_settings);\n\tte1_settings line;\n\tstruct ucc_hdlc_private *priv = netdev_priv(dev);\n\n\tswitch (ifs->type) {\n\tcase IF_GET_IFACE:\n\t\tifs->type = IF_IFACE_E1;\n\t\tif (ifs->size < size) {\n\t\t\tifs->size = size;  \n\t\t\treturn -ENOBUFS;\n\t\t}\n\t\tmemset(&line, 0, sizeof(line));\n\t\tline.clock_type = priv->clocking;\n\n\t\tif (copy_to_user(ifs->ifs_ifsu.sync, &line, size))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn hdlc_ioctl(dev, ifs);\n\t}\n}\n\nstatic int uhdlc_open(struct net_device *dev)\n{\n\tu32 cecr_subblock;\n\thdlc_device *hdlc = dev_to_hdlc(dev);\n\tstruct ucc_hdlc_private *priv = hdlc->priv;\n\tstruct ucc_tdm *utdm = priv->utdm;\n\tint rc = 0;\n\n\tif (priv->hdlc_busy != 1) {\n\t\tif (request_irq(priv->ut_info->uf_info.irq,\n\t\t\t\tucc_hdlc_irq_handler, 0, \"hdlc\", priv))\n\t\t\treturn -ENODEV;\n\n\t\tcecr_subblock = ucc_fast_get_qe_cr_subblock(\n\t\t\t\t\tpriv->ut_info->uf_info.ucc_num);\n\n\t\tqe_issue_cmd(QE_INIT_TX_RX, cecr_subblock,\n\t\t\t     QE_CR_PROTOCOL_UNSPECIFIED, 0);\n\n\t\tucc_fast_enable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\n\n\t\t \n\t\tif (priv->tsa)\n\t\t\tqe_setbits_8(&utdm->si_regs->siglmr1_h, 0x1 << utdm->tdm_port);\n\n\t\tpriv->hdlc_busy = 1;\n\t\tnetif_device_attach(priv->ndev);\n\t\tnapi_enable(&priv->napi);\n\t\tnetdev_reset_queue(dev);\n\t\tnetif_start_queue(dev);\n\n\t\trc = hdlc_open(dev);\n\t\tif (rc)\n\t\t\tuhdlc_close(dev);\n\t}\n\n\treturn rc;\n}\n\nstatic void uhdlc_memclean(struct ucc_hdlc_private *priv)\n{\n\tqe_muram_free(ioread16be(&priv->ucc_pram->riptr));\n\tqe_muram_free(ioread16be(&priv->ucc_pram->tiptr));\n\n\tif (priv->rx_bd_base) {\n\t\tdma_free_coherent(priv->dev,\n\t\t\t\t  RX_BD_RING_LEN * sizeof(struct qe_bd),\n\t\t\t\t  priv->rx_bd_base, priv->dma_rx_bd);\n\n\t\tpriv->rx_bd_base = NULL;\n\t\tpriv->dma_rx_bd = 0;\n\t}\n\n\tif (priv->tx_bd_base) {\n\t\tdma_free_coherent(priv->dev,\n\t\t\t\t  TX_BD_RING_LEN * sizeof(struct qe_bd),\n\t\t\t\t  priv->tx_bd_base, priv->dma_tx_bd);\n\n\t\tpriv->tx_bd_base = NULL;\n\t\tpriv->dma_tx_bd = 0;\n\t}\n\n\tif (priv->ucc_pram) {\n\t\tqe_muram_free(priv->ucc_pram_offset);\n\t\tpriv->ucc_pram = NULL;\n\t\tpriv->ucc_pram_offset = 0;\n\t }\n\n\tkfree(priv->rx_skbuff);\n\tpriv->rx_skbuff = NULL;\n\n\tkfree(priv->tx_skbuff);\n\tpriv->tx_skbuff = NULL;\n\n\tif (priv->uf_regs) {\n\t\tiounmap(priv->uf_regs);\n\t\tpriv->uf_regs = NULL;\n\t}\n\n\tif (priv->uccf) {\n\t\tucc_fast_free(priv->uccf);\n\t\tpriv->uccf = NULL;\n\t}\n\n\tif (priv->rx_buffer) {\n\t\tdma_free_coherent(priv->dev,\n\t\t\t\t  RX_BD_RING_LEN * MAX_RX_BUF_LENGTH,\n\t\t\t\t  priv->rx_buffer, priv->dma_rx_addr);\n\t\tpriv->rx_buffer = NULL;\n\t\tpriv->dma_rx_addr = 0;\n\t}\n\n\tif (priv->tx_buffer) {\n\t\tdma_free_coherent(priv->dev,\n\t\t\t\t  TX_BD_RING_LEN * MAX_RX_BUF_LENGTH,\n\t\t\t\t  priv->tx_buffer, priv->dma_tx_addr);\n\t\tpriv->tx_buffer = NULL;\n\t\tpriv->dma_tx_addr = 0;\n\t}\n}\n\nstatic int uhdlc_close(struct net_device *dev)\n{\n\tstruct ucc_hdlc_private *priv = dev_to_hdlc(dev)->priv;\n\tstruct ucc_tdm *utdm = priv->utdm;\n\tu32 cecr_subblock;\n\n\tnapi_disable(&priv->napi);\n\tcecr_subblock = ucc_fast_get_qe_cr_subblock(\n\t\t\t\tpriv->ut_info->uf_info.ucc_num);\n\n\tqe_issue_cmd(QE_GRACEFUL_STOP_TX, cecr_subblock,\n\t\t     (u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\n\tqe_issue_cmd(QE_CLOSE_RX_BD, cecr_subblock,\n\t\t     (u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\n\n\tif (priv->tsa)\n\t\tqe_clrbits_8(&utdm->si_regs->siglmr1_h, 0x1 << utdm->tdm_port);\n\n\tucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\n\n\tfree_irq(priv->ut_info->uf_info.irq, priv);\n\tnetif_stop_queue(dev);\n\tnetdev_reset_queue(dev);\n\tpriv->hdlc_busy = 0;\n\n\thdlc_close(dev);\n\n\treturn 0;\n}\n\nstatic int ucc_hdlc_attach(struct net_device *dev, unsigned short encoding,\n\t\t\t   unsigned short parity)\n{\n\tstruct ucc_hdlc_private *priv = dev_to_hdlc(dev)->priv;\n\n\tif (encoding != ENCODING_NRZ &&\n\t    encoding != ENCODING_NRZI)\n\t\treturn -EINVAL;\n\n\tif (parity != PARITY_NONE &&\n\t    parity != PARITY_CRC32_PR1_CCITT &&\n\t    parity != PARITY_CRC16_PR0_CCITT &&\n\t    parity != PARITY_CRC16_PR1_CCITT)\n\t\treturn -EINVAL;\n\n\tpriv->encoding = encoding;\n\tpriv->parity = parity;\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM\nstatic void store_clk_config(struct ucc_hdlc_private *priv)\n{\n\tstruct qe_mux __iomem *qe_mux_reg = &qe_immr->qmx;\n\n\t \n\tpriv->cmxsi1cr_h = ioread32be(&qe_mux_reg->cmxsi1cr_h);\n\tpriv->cmxsi1cr_l = ioread32be(&qe_mux_reg->cmxsi1cr_l);\n\n\t \n\tpriv->cmxsi1syr = ioread32be(&qe_mux_reg->cmxsi1syr);\n\n\t \n\tmemcpy_fromio(priv->cmxucr, qe_mux_reg->cmxucr, 4 * sizeof(u32));\n}\n\nstatic void resume_clk_config(struct ucc_hdlc_private *priv)\n{\n\tstruct qe_mux __iomem *qe_mux_reg = &qe_immr->qmx;\n\n\tmemcpy_toio(qe_mux_reg->cmxucr, priv->cmxucr, 4 * sizeof(u32));\n\n\tiowrite32be(priv->cmxsi1cr_h, &qe_mux_reg->cmxsi1cr_h);\n\tiowrite32be(priv->cmxsi1cr_l, &qe_mux_reg->cmxsi1cr_l);\n\n\tiowrite32be(priv->cmxsi1syr, &qe_mux_reg->cmxsi1syr);\n}\n\nstatic int uhdlc_suspend(struct device *dev)\n{\n\tstruct ucc_hdlc_private *priv = dev_get_drvdata(dev);\n\tstruct ucc_fast __iomem *uf_regs;\n\n\tif (!priv)\n\t\treturn -EINVAL;\n\n\tif (!netif_running(priv->ndev))\n\t\treturn 0;\n\n\tnetif_device_detach(priv->ndev);\n\tnapi_disable(&priv->napi);\n\n\tuf_regs = priv->uf_regs;\n\n\t \n\tpriv->gumr = ioread32be(&uf_regs->gumr);\n\tpriv->guemr = ioread8(&uf_regs->guemr);\n\n\tpriv->ucc_pram_bak = kmalloc(sizeof(*priv->ucc_pram_bak),\n\t\t\t\t\tGFP_KERNEL);\n\tif (!priv->ucc_pram_bak)\n\t\treturn -ENOMEM;\n\n\t \n\tmemcpy_fromio(priv->ucc_pram_bak, priv->ucc_pram,\n\t\t      sizeof(struct ucc_hdlc_param));\n\n\t \n\tstore_clk_config(priv);\n\n\t \n\tucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\n\n\treturn 0;\n}\n\nstatic int uhdlc_resume(struct device *dev)\n{\n\tstruct ucc_hdlc_private *priv = dev_get_drvdata(dev);\n\tstruct ucc_tdm *utdm;\n\tstruct ucc_tdm_info *ut_info;\n\tstruct ucc_fast __iomem *uf_regs;\n\tstruct ucc_fast_private *uccf;\n\tstruct ucc_fast_info *uf_info;\n\tint i;\n\tu32 cecr_subblock;\n\tu16 bd_status;\n\n\tif (!priv)\n\t\treturn -EINVAL;\n\n\tif (!netif_running(priv->ndev))\n\t\treturn 0;\n\n\tutdm = priv->utdm;\n\tut_info = priv->ut_info;\n\tuf_info = &ut_info->uf_info;\n\tuf_regs = priv->uf_regs;\n\tuccf = priv->uccf;\n\n\t \n\tiowrite8(priv->guemr, &uf_regs->guemr);\n\tiowrite32be(priv->gumr, &uf_regs->gumr);\n\n\t \n\tiowrite16be(uf_info->urfs, &uf_regs->urfs);\n\tiowrite16be(uf_info->urfet, &uf_regs->urfet);\n\tiowrite16be(uf_info->urfset, &uf_regs->urfset);\n\tiowrite16be(uf_info->utfs, &uf_regs->utfs);\n\tiowrite16be(uf_info->utfet, &uf_regs->utfet);\n\tiowrite16be(uf_info->utftt, &uf_regs->utftt);\n\t \n\tiowrite32be(uccf->ucc_fast_tx_virtual_fifo_base_offset, &uf_regs->utfb);\n\tiowrite32be(uccf->ucc_fast_rx_virtual_fifo_base_offset, &uf_regs->urfb);\n\n\t \n\tresume_clk_config(priv);\n\n\tiowrite32be(uf_info->uccm_mask, &uf_regs->uccm);\n\tiowrite32be(0xffffffff, &uf_regs->ucce);\n\n\tucc_fast_disable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\n\n\t \n\tif (priv->tsa)\n\t\tucc_tdm_init(priv->utdm, priv->ut_info);\n\n\t \n\tcecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\n\tqe_issue_cmd(QE_STOP_TX, cecr_subblock,\n\t\t     (u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\n\n\t \n\tiowrite32be(0, &uf_regs->upsmr);\n\n\t \n\tcecr_subblock = ucc_fast_get_qe_cr_subblock(uf_info->ucc_num);\n\tqe_issue_cmd(QE_ASSIGN_PAGE_TO_DEVICE, cecr_subblock,\n\t\t     QE_CR_PROTOCOL_UNSPECIFIED, priv->ucc_pram_offset);\n\n\tpriv->ucc_pram = (struct ucc_hdlc_param __iomem *)\n\t\t\t\tqe_muram_addr(priv->ucc_pram_offset);\n\n\t \n\tmemcpy_toio(priv->ucc_pram, priv->ucc_pram_bak,\n\t\t    sizeof(struct ucc_hdlc_param));\n\tkfree(priv->ucc_pram_bak);\n\n\t \n\tfor (i = 0; i < RX_BD_RING_LEN; i++) {\n\t\tif (i < (RX_BD_RING_LEN - 1))\n\t\t\tbd_status = R_E_S | R_I_S;\n\t\telse\n\t\t\tbd_status = R_E_S | R_I_S | R_W_S;\n\n\t\tpriv->rx_bd_base[i].status = cpu_to_be16(bd_status);\n\t\tpriv->rx_bd_base[i].buf = cpu_to_be32(priv->dma_rx_addr + i * MAX_RX_BUF_LENGTH);\n\t}\n\n\tfor (i = 0; i < TX_BD_RING_LEN; i++) {\n\t\tif (i < (TX_BD_RING_LEN - 1))\n\t\t\tbd_status =  T_I_S | T_TC_S;\n\t\telse\n\t\t\tbd_status =  T_I_S | T_TC_S | T_W_S;\n\n\t\tpriv->tx_bd_base[i].status = cpu_to_be16(bd_status);\n\t\tpriv->tx_bd_base[i].buf = cpu_to_be32(priv->dma_tx_addr + i * MAX_RX_BUF_LENGTH);\n\t}\n\tdma_wmb();\n\n\t \n\tif (priv->hdlc_busy == 1) {\n\t\tcecr_subblock = ucc_fast_get_qe_cr_subblock(\n\t\t\t\t\tpriv->ut_info->uf_info.ucc_num);\n\n\t\tqe_issue_cmd(QE_INIT_TX_RX, cecr_subblock,\n\t\t\t     (u8)QE_CR_PROTOCOL_UNSPECIFIED, 0);\n\n\t\tucc_fast_enable(priv->uccf, COMM_DIR_RX | COMM_DIR_TX);\n\n\t\t \n\t\tif (priv->tsa)\n\t\t\tqe_setbits_8(&utdm->si_regs->siglmr1_h, 0x1 << utdm->tdm_port);\n\t}\n\n\tnapi_enable(&priv->napi);\n\tnetif_device_attach(priv->ndev);\n\n\treturn 0;\n}\n\nstatic const struct dev_pm_ops uhdlc_pm_ops = {\n\t.suspend = uhdlc_suspend,\n\t.resume = uhdlc_resume,\n\t.freeze = uhdlc_suspend,\n\t.thaw = uhdlc_resume,\n};\n\n#define HDLC_PM_OPS (&uhdlc_pm_ops)\n\n#else\n\n#define HDLC_PM_OPS NULL\n\n#endif\nstatic void uhdlc_tx_timeout(struct net_device *ndev, unsigned int txqueue)\n{\n\tnetdev_err(ndev, \"%s\\n\", __func__);\n}\n\nstatic const struct net_device_ops uhdlc_ops = {\n\t.ndo_open       = uhdlc_open,\n\t.ndo_stop       = uhdlc_close,\n\t.ndo_start_xmit = hdlc_start_xmit,\n\t.ndo_siocwandev = uhdlc_ioctl,\n\t.ndo_tx_timeout\t= uhdlc_tx_timeout,\n};\n\nstatic int hdlc_map_iomem(char *name, int init_flag, void __iomem **ptr)\n{\n\tstruct device_node *np;\n\tstruct platform_device *pdev;\n\tstruct resource *res;\n\tstatic int siram_init_flag;\n\tint ret = 0;\n\n\tnp = of_find_compatible_node(NULL, NULL, name);\n\tif (!np)\n\t\treturn -EINVAL;\n\n\tpdev = of_find_device_by_node(np);\n\tif (!pdev) {\n\t\tpr_err(\"%pOFn: failed to lookup pdev\\n\", np);\n\t\tof_node_put(np);\n\t\treturn -EINVAL;\n\t}\n\n\tof_node_put(np);\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res) {\n\t\tret = -EINVAL;\n\t\tgoto error_put_device;\n\t}\n\t*ptr = ioremap(res->start, resource_size(res));\n\tif (!*ptr) {\n\t\tret = -ENOMEM;\n\t\tgoto error_put_device;\n\t}\n\n\t \n\tput_device(&pdev->dev);\n\n\tif (init_flag && siram_init_flag == 0) {\n\t\tmemset_io(*ptr, 0, resource_size(res));\n\t\tsiram_init_flag = 1;\n\t}\n\treturn  0;\n\nerror_put_device:\n\tput_device(&pdev->dev);\n\n\treturn ret;\n}\n\nstatic int ucc_hdlc_probe(struct platform_device *pdev)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\tstruct ucc_hdlc_private *uhdlc_priv = NULL;\n\tstruct ucc_tdm_info *ut_info;\n\tstruct ucc_tdm *utdm = NULL;\n\tstruct resource res;\n\tstruct net_device *dev;\n\thdlc_device *hdlc;\n\tint ucc_num;\n\tconst char *sprop;\n\tint ret;\n\tu32 val;\n\n\tret = of_property_read_u32_index(np, \"cell-index\", 0, &val);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Invalid ucc property\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tucc_num = val - 1;\n\tif (ucc_num > (UCC_MAX_NUM - 1) || ucc_num < 0) {\n\t\tdev_err(&pdev->dev, \": Invalid UCC num\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tmemcpy(&utdm_info[ucc_num], &utdm_primary_info,\n\t       sizeof(utdm_primary_info));\n\n\tut_info = &utdm_info[ucc_num];\n\tut_info->uf_info.ucc_num = ucc_num;\n\n\tsprop = of_get_property(np, \"rx-clock-name\", NULL);\n\tif (sprop) {\n\t\tut_info->uf_info.rx_clock = qe_clock_source(sprop);\n\t\tif ((ut_info->uf_info.rx_clock < QE_CLK_NONE) ||\n\t\t    (ut_info->uf_info.rx_clock > QE_CLK24)) {\n\t\t\tdev_err(&pdev->dev, \"Invalid rx-clock-name property\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tdev_err(&pdev->dev, \"Invalid rx-clock-name property\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tsprop = of_get_property(np, \"tx-clock-name\", NULL);\n\tif (sprop) {\n\t\tut_info->uf_info.tx_clock = qe_clock_source(sprop);\n\t\tif ((ut_info->uf_info.tx_clock < QE_CLK_NONE) ||\n\t\t    (ut_info->uf_info.tx_clock > QE_CLK24)) {\n\t\t\tdev_err(&pdev->dev, \"Invalid tx-clock-name property\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tdev_err(&pdev->dev, \"Invalid tx-clock-name property\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = of_address_to_resource(np, 0, &res);\n\tif (ret)\n\t\treturn -EINVAL;\n\n\tut_info->uf_info.regs = res.start;\n\tut_info->uf_info.irq = irq_of_parse_and_map(np, 0);\n\n\tuhdlc_priv = kzalloc(sizeof(*uhdlc_priv), GFP_KERNEL);\n\tif (!uhdlc_priv)\n\t\treturn -ENOMEM;\n\n\tdev_set_drvdata(&pdev->dev, uhdlc_priv);\n\tuhdlc_priv->dev = &pdev->dev;\n\tuhdlc_priv->ut_info = ut_info;\n\n\tuhdlc_priv->tsa = of_property_read_bool(np, \"fsl,tdm-interface\");\n\tuhdlc_priv->loopback = of_property_read_bool(np, \"fsl,ucc-internal-loopback\");\n\tuhdlc_priv->hdlc_bus = of_property_read_bool(np, \"fsl,hdlc-bus\");\n\n\tif (uhdlc_priv->tsa == 1) {\n\t\tutdm = kzalloc(sizeof(*utdm), GFP_KERNEL);\n\t\tif (!utdm) {\n\t\t\tret = -ENOMEM;\n\t\t\tdev_err(&pdev->dev, \"No mem to alloc ucc tdm data\\n\");\n\t\t\tgoto free_uhdlc_priv;\n\t\t}\n\t\tuhdlc_priv->utdm = utdm;\n\t\tret = ucc_of_parse_tdm(np, utdm, ut_info);\n\t\tif (ret)\n\t\t\tgoto free_utdm;\n\n\t\tret = hdlc_map_iomem(\"fsl,t1040-qe-si\", 0,\n\t\t\t\t     (void __iomem **)&utdm->si_regs);\n\t\tif (ret)\n\t\t\tgoto free_utdm;\n\t\tret = hdlc_map_iomem(\"fsl,t1040-qe-siram\", 1,\n\t\t\t\t     (void __iomem **)&utdm->siram);\n\t\tif (ret)\n\t\t\tgoto unmap_si_regs;\n\t}\n\n\tif (of_property_read_u16(np, \"fsl,hmask\", &uhdlc_priv->hmask))\n\t\tuhdlc_priv->hmask = DEFAULT_ADDR_MASK;\n\n\tret = uhdlc_init(uhdlc_priv);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Failed to init uhdlc\\n\");\n\t\tgoto undo_uhdlc_init;\n\t}\n\n\tdev = alloc_hdlcdev(uhdlc_priv);\n\tif (!dev) {\n\t\tret = -ENOMEM;\n\t\tpr_err(\"ucc_hdlc: unable to allocate memory\\n\");\n\t\tgoto undo_uhdlc_init;\n\t}\n\n\tuhdlc_priv->ndev = dev;\n\thdlc = dev_to_hdlc(dev);\n\tdev->tx_queue_len = 16;\n\tdev->netdev_ops = &uhdlc_ops;\n\tdev->watchdog_timeo = 2 * HZ;\n\thdlc->attach = ucc_hdlc_attach;\n\thdlc->xmit = ucc_hdlc_tx;\n\tnetif_napi_add_weight(dev, &uhdlc_priv->napi, ucc_hdlc_poll, 32);\n\tif (register_hdlc_device(dev)) {\n\t\tret = -ENOBUFS;\n\t\tpr_err(\"ucc_hdlc: unable to register hdlc device\\n\");\n\t\tgoto free_dev;\n\t}\n\n\treturn 0;\n\nfree_dev:\n\tfree_netdev(dev);\nundo_uhdlc_init:\n\tif (utdm)\n\t\tiounmap(utdm->siram);\nunmap_si_regs:\n\tif (utdm)\n\t\tiounmap(utdm->si_regs);\nfree_utdm:\n\tif (uhdlc_priv->tsa)\n\t\tkfree(utdm);\nfree_uhdlc_priv:\n\tkfree(uhdlc_priv);\n\treturn ret;\n}\n\nstatic int ucc_hdlc_remove(struct platform_device *pdev)\n{\n\tstruct ucc_hdlc_private *priv = dev_get_drvdata(&pdev->dev);\n\n\tuhdlc_memclean(priv);\n\n\tif (priv->utdm->si_regs) {\n\t\tiounmap(priv->utdm->si_regs);\n\t\tpriv->utdm->si_regs = NULL;\n\t}\n\n\tif (priv->utdm->siram) {\n\t\tiounmap(priv->utdm->siram);\n\t\tpriv->utdm->siram = NULL;\n\t}\n\tkfree(priv);\n\n\tdev_info(&pdev->dev, \"UCC based hdlc module removed\\n\");\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fsl_ucc_hdlc_of_match[] = {\n\t{\n\t.compatible = \"fsl,ucc-hdlc\",\n\t},\n\t{},\n};\n\nMODULE_DEVICE_TABLE(of, fsl_ucc_hdlc_of_match);\n\nstatic struct platform_driver ucc_hdlc_driver = {\n\t.probe\t= ucc_hdlc_probe,\n\t.remove\t= ucc_hdlc_remove,\n\t.driver\t= {\n\t\t.name\t\t= DRV_NAME,\n\t\t.pm\t\t= HDLC_PM_OPS,\n\t\t.of_match_table\t= fsl_ucc_hdlc_of_match,\n\t},\n};\n\nmodule_platform_driver(ucc_hdlc_driver);\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(DRV_DESC);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}