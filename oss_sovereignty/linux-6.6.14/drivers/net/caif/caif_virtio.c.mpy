{
  "module_name": "caif_virtio.c",
  "hash_id": "8808a6f8385ab3b003d6870da29caa12a102029751fe4630bd5a47c51136d458",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/caif/caif_virtio.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/if_arp.h>\n#include <linux/virtio.h>\n#include <linux/vringh.h>\n#include <linux/debugfs.h>\n#include <linux/spinlock.h>\n#include <linux/genalloc.h>\n#include <linux/interrupt.h>\n#include <linux/netdevice.h>\n#include <linux/rtnetlink.h>\n#include <linux/virtio_ids.h>\n#include <linux/virtio_caif.h>\n#include <linux/virtio_ring.h>\n#include <linux/dma-mapping.h>\n#include <net/caif/caif_dev.h>\n#include <linux/virtio_config.h>\n\nMODULE_LICENSE(\"GPL v2\");\nMODULE_AUTHOR(\"Vicram Arv\");\nMODULE_AUTHOR(\"Sjur Brendeland\");\nMODULE_DESCRIPTION(\"Virtio CAIF Driver\");\n\n \n#define CFV_DEFAULT_QUOTA 32\n\n \n#define CFV_DEF_MTU_SIZE 4096\n#define CFV_DEF_HEADROOM 32\n#define CFV_DEF_TAILROOM 32\n\n \n#define IP_HDR_ALIGN 4\n\n \nstruct cfv_napi_context {\n\tstruct vringh_kiov riov;\n\tunsigned short head;\n};\n\n \nstruct cfv_stats {\n\tu32 rx_napi_complete;\n\tu32 rx_napi_resched;\n\tu32 rx_nomem;\n\tu32 rx_kicks;\n\tu32 tx_full_ring;\n\tu32 tx_no_mem;\n\tu32 tx_flow_on;\n\tu32 tx_kicks;\n};\n\n \nstruct cfv_info {\n\tstruct caif_dev_common cfdev;\n\tstruct virtio_device *vdev;\n\tstruct vringh *vr_rx;\n\tstruct virtqueue *vq_tx;\n\tstruct net_device *ndev;\n\tunsigned int watermark_tx;\n\t \n\tspinlock_t tx_lock;\n\tstruct tasklet_struct tx_release_tasklet;\n\tstruct napi_struct napi;\n\tstruct cfv_napi_context ctx;\n\tu16 tx_hr;\n\tu16 rx_hr;\n\tu16 tx_tr;\n\tu16 rx_tr;\n\tu32 mtu;\n\tu32 mru;\n\tsize_t allocsz;\n\tvoid *alloc_addr;\n\tdma_addr_t alloc_dma;\n\tstruct gen_pool *genpool;\n\tunsigned long reserved_mem;\n\tsize_t reserved_size;\n\tstruct cfv_stats stats;\n\tstruct dentry *debugfs;\n};\n\n \nstruct buf_info {\n\tsize_t size;\n\tu8 *vaddr;\n};\n\n \nstatic void cfv_release_cb(struct virtqueue *vq_tx)\n{\n\tstruct cfv_info *cfv = vq_tx->vdev->priv;\n\n\t++cfv->stats.tx_kicks;\n\ttasklet_schedule(&cfv->tx_release_tasklet);\n}\n\nstatic void free_buf_info(struct cfv_info *cfv, struct buf_info *buf_info)\n{\n\tif (!buf_info)\n\t\treturn;\n\tgen_pool_free(cfv->genpool, (unsigned long) buf_info->vaddr,\n\t\t      buf_info->size);\n\tkfree(buf_info);\n}\n\n \nstatic void cfv_release_used_buf(struct virtqueue *vq_tx)\n{\n\tstruct cfv_info *cfv = vq_tx->vdev->priv;\n\tunsigned long flags;\n\n\tBUG_ON(vq_tx != cfv->vq_tx);\n\n\tfor (;;) {\n\t\tunsigned int len;\n\t\tstruct buf_info *buf_info;\n\n\t\t \n\t\tspin_lock_irqsave(&cfv->tx_lock, flags);\n\t\tbuf_info = virtqueue_get_buf(vq_tx, &len);\n\t\tspin_unlock_irqrestore(&cfv->tx_lock, flags);\n\n\t\t \n\t\tif (!buf_info)\n\t\t\tbreak;\n\n\t\tfree_buf_info(cfv, buf_info);\n\n\t\t \n\t\tif (cfv->vq_tx->num_free <= cfv->watermark_tx)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (cfv->reserved_mem == 0 && cfv->genpool)\n\t\t\tcfv->reserved_mem =\n\t\t\t\tgen_pool_alloc(cfv->genpool,\n\t\t\t\t\t       cfv->reserved_size);\n\n\t\t \n\t\tif (cfv->reserved_mem) {\n\t\t\tcfv->watermark_tx =\n\t\t\t\tvirtqueue_get_vring_size(cfv->vq_tx);\n\t\t\tnetif_tx_wake_all_queues(cfv->ndev);\n\t\t\t \n\t\t\tvirtqueue_disable_cb(cfv->vq_tx);\n\t\t\t++cfv->stats.tx_flow_on;\n\t\t} else {\n\t\t\t \n\t\t\tWARN_ON(cfv->watermark_tx >\n\t\t\t       virtqueue_get_vring_size(cfv->vq_tx));\n\t\t\tcfv->watermark_tx +=\n\t\t\t\tvirtqueue_get_vring_size(cfv->vq_tx) / 4;\n\t\t}\n\t}\n}\n\n \nstatic struct sk_buff *cfv_alloc_and_copy_skb(int *err,\n\t\t\t\t\t      struct cfv_info *cfv,\n\t\t\t\t\t      u8 *frm, u32 frm_len)\n{\n\tstruct sk_buff *skb;\n\tu32 cfpkt_len, pad_len;\n\n\t*err = 0;\n\t \n\tif (frm_len > cfv->mru || frm_len <= cfv->rx_hr + cfv->rx_tr) {\n\t\tnetdev_err(cfv->ndev,\n\t\t\t   \"Invalid frmlen:%u  mtu:%u hr:%d tr:%d\\n\",\n\t\t\t   frm_len, cfv->mru,  cfv->rx_hr,\n\t\t\t   cfv->rx_tr);\n\t\t*err = -EPROTO;\n\t\treturn NULL;\n\t}\n\n\tcfpkt_len = frm_len - (cfv->rx_hr + cfv->rx_tr);\n\tpad_len = (unsigned long)(frm + cfv->rx_hr) & (IP_HDR_ALIGN - 1);\n\n\tskb = netdev_alloc_skb(cfv->ndev, frm_len + pad_len);\n\tif (!skb) {\n\t\t*err = -ENOMEM;\n\t\treturn NULL;\n\t}\n\n\tskb_reserve(skb, cfv->rx_hr + pad_len);\n\n\tskb_put_data(skb, frm + cfv->rx_hr, cfpkt_len);\n\treturn skb;\n}\n\n \nstatic int cfv_rx_poll(struct napi_struct *napi, int quota)\n{\n\tstruct cfv_info *cfv = container_of(napi, struct cfv_info, napi);\n\tint rxcnt = 0;\n\tint err = 0;\n\tvoid *buf;\n\tstruct sk_buff *skb;\n\tstruct vringh_kiov *riov = &cfv->ctx.riov;\n\tunsigned int skb_len;\n\n\tdo {\n\t\tskb = NULL;\n\n\t\t \n\t\tif (riov->i == riov->used) {\n\t\t\tif (cfv->ctx.head != USHRT_MAX) {\n\t\t\t\tvringh_complete_kern(cfv->vr_rx,\n\t\t\t\t\t\t     cfv->ctx.head,\n\t\t\t\t\t\t     0);\n\t\t\t\tcfv->ctx.head = USHRT_MAX;\n\t\t\t}\n\n\t\t\terr = vringh_getdesc_kern(\n\t\t\t\tcfv->vr_rx,\n\t\t\t\triov,\n\t\t\t\tNULL,\n\t\t\t\t&cfv->ctx.head,\n\t\t\t\tGFP_ATOMIC);\n\n\t\t\tif (err <= 0)\n\t\t\t\tgoto exit;\n\t\t}\n\n\t\tbuf = phys_to_virt((unsigned long) riov->iov[riov->i].iov_base);\n\t\t \n\n\t\tskb = cfv_alloc_and_copy_skb(&err, cfv, buf,\n\t\t\t\t\t     riov->iov[riov->i].iov_len);\n\t\tif (unlikely(err))\n\t\t\tgoto exit;\n\n\t\t \n\t\tskb_len = skb->len;\n\t\tskb->protocol = htons(ETH_P_CAIF);\n\t\tskb_reset_mac_header(skb);\n\t\tskb->dev = cfv->ndev;\n\t\terr = netif_receive_skb(skb);\n\t\tif (unlikely(err)) {\n\t\t\t++cfv->ndev->stats.rx_dropped;\n\t\t} else {\n\t\t\t++cfv->ndev->stats.rx_packets;\n\t\t\tcfv->ndev->stats.rx_bytes += skb_len;\n\t\t}\n\n\t\t++riov->i;\n\t\t++rxcnt;\n\t} while (rxcnt < quota);\n\n\t++cfv->stats.rx_napi_resched;\n\tgoto out;\n\nexit:\n\tswitch (err) {\n\tcase 0:\n\t\t++cfv->stats.rx_napi_complete;\n\n\t\t \n\t\tnapi_complete(napi);\n\t\tif (unlikely(!vringh_notify_enable_kern(cfv->vr_rx)) &&\n\t\t    napi_schedule_prep(napi)) {\n\t\t\tvringh_notify_disable_kern(cfv->vr_rx);\n\t\t\t__napi_schedule(napi);\n\t\t}\n\t\tbreak;\n\n\tcase -ENOMEM:\n\t\t++cfv->stats.rx_nomem;\n\t\tdev_kfree_skb(skb);\n\t\t \n\t\tnapi_complete(napi);\n\t\tvringh_notify_enable_kern(cfv->vr_rx);\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tnetdev_warn(cfv->ndev, \"Bad ring, disable device\\n\");\n\t\tcfv->ndev->stats.rx_dropped = riov->used - riov->i;\n\t\tnapi_complete(napi);\n\t\tvringh_notify_disable_kern(cfv->vr_rx);\n\t\tnetif_carrier_off(cfv->ndev);\n\t\tbreak;\n\t}\nout:\n\tif (rxcnt && vringh_need_notify_kern(cfv->vr_rx) > 0)\n\t\tvringh_notify(cfv->vr_rx);\n\treturn rxcnt;\n}\n\nstatic void cfv_recv(struct virtio_device *vdev, struct vringh *vr_rx)\n{\n\tstruct cfv_info *cfv = vdev->priv;\n\n\t++cfv->stats.rx_kicks;\n\tvringh_notify_disable_kern(cfv->vr_rx);\n\tnapi_schedule(&cfv->napi);\n}\n\nstatic void cfv_destroy_genpool(struct cfv_info *cfv)\n{\n\tif (cfv->alloc_addr)\n\t\tdma_free_coherent(cfv->vdev->dev.parent->parent,\n\t\t\t\t  cfv->allocsz, cfv->alloc_addr,\n\t\t\t\t  cfv->alloc_dma);\n\n\tif (!cfv->genpool)\n\t\treturn;\n\tgen_pool_free(cfv->genpool,  cfv->reserved_mem,\n\t\t      cfv->reserved_size);\n\tgen_pool_destroy(cfv->genpool);\n\tcfv->genpool = NULL;\n}\n\nstatic int cfv_create_genpool(struct cfv_info *cfv)\n{\n\tint err;\n\n\t \n\terr = -ENOMEM;\n\tcfv->allocsz = (virtqueue_get_vring_size(cfv->vq_tx) *\n\t\t\t(ETH_DATA_LEN + cfv->tx_hr + cfv->tx_tr) * 11)/10;\n\tif (cfv->allocsz <= (num_possible_cpus() + 1) * cfv->ndev->mtu)\n\t\treturn -EINVAL;\n\n\tfor (;;) {\n\t\tif (cfv->allocsz <= num_possible_cpus() * cfv->ndev->mtu) {\n\t\t\tnetdev_info(cfv->ndev, \"Not enough device memory\\n\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tcfv->alloc_addr = dma_alloc_coherent(\n\t\t\t\t\t\tcfv->vdev->dev.parent->parent,\n\t\t\t\t\t\tcfv->allocsz, &cfv->alloc_dma,\n\t\t\t\t\t\tGFP_ATOMIC);\n\t\tif (cfv->alloc_addr)\n\t\t\tbreak;\n\n\t\tcfv->allocsz = (cfv->allocsz * 3) >> 2;\n\t}\n\n\tnetdev_dbg(cfv->ndev, \"Allocated %zd bytes from dma-memory\\n\",\n\t\t   cfv->allocsz);\n\n\t \n\tcfv->genpool = gen_pool_create(7, -1);\n\tif (!cfv->genpool)\n\t\tgoto err;\n\n\terr = gen_pool_add_virt(cfv->genpool, (unsigned long)cfv->alloc_addr,\n\t\t\t\t(phys_addr_t)virt_to_phys(cfv->alloc_addr),\n\t\t\t\tcfv->allocsz, -1);\n\tif (err)\n\t\tgoto err;\n\n\t \n\tcfv->reserved_size = num_possible_cpus() * cfv->ndev->mtu;\n\tcfv->reserved_mem = gen_pool_alloc(cfv->genpool,\n\t\t\t\t\t   cfv->reserved_size);\n\tif (!cfv->reserved_mem) {\n\t\terr = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\tcfv->watermark_tx = virtqueue_get_vring_size(cfv->vq_tx);\n\treturn 0;\nerr:\n\tcfv_destroy_genpool(cfv);\n\treturn err;\n}\n\n \nstatic int cfv_netdev_open(struct net_device *netdev)\n{\n\tstruct cfv_info *cfv = netdev_priv(netdev);\n\n\tif (cfv_create_genpool(cfv))\n\t\treturn -ENOMEM;\n\n\tnetif_carrier_on(netdev);\n\tnapi_enable(&cfv->napi);\n\n\t \n\tnapi_schedule(&cfv->napi);\n\treturn 0;\n}\n\n \nstatic int cfv_netdev_close(struct net_device *netdev)\n{\n\tstruct cfv_info *cfv = netdev_priv(netdev);\n\tunsigned long flags;\n\tstruct buf_info *buf_info;\n\n\t \n\tnetif_carrier_off(netdev);\n\tvirtqueue_disable_cb(cfv->vq_tx);\n\tvringh_notify_disable_kern(cfv->vr_rx);\n\tnapi_disable(&cfv->napi);\n\n\t \n\tcfv_release_used_buf(cfv->vq_tx);\n\tspin_lock_irqsave(&cfv->tx_lock, flags);\n\twhile ((buf_info = virtqueue_detach_unused_buf(cfv->vq_tx)))\n\t\tfree_buf_info(cfv, buf_info);\n\tspin_unlock_irqrestore(&cfv->tx_lock, flags);\n\n\t \n\tcfv_destroy_genpool(cfv);\n\treturn 0;\n}\n\n \nstatic struct buf_info *cfv_alloc_and_copy_to_shm(struct cfv_info *cfv,\n\t\t\t\t\t\t       struct sk_buff *skb,\n\t\t\t\t\t\t       struct scatterlist *sg)\n{\n\tstruct caif_payload_info *info = (void *)&skb->cb;\n\tstruct buf_info *buf_info = NULL;\n\tu8 pad_len, hdr_ofs;\n\n\tif (!cfv->genpool)\n\t\tgoto err;\n\n\tif (unlikely(cfv->tx_hr + skb->len + cfv->tx_tr > cfv->mtu)) {\n\t\tnetdev_warn(cfv->ndev, \"Invalid packet len (%d > %d)\\n\",\n\t\t\t    cfv->tx_hr + skb->len + cfv->tx_tr, cfv->mtu);\n\t\tgoto err;\n\t}\n\n\tbuf_info = kmalloc(sizeof(struct buf_info), GFP_ATOMIC);\n\tif (unlikely(!buf_info))\n\t\tgoto err;\n\n\t \n\thdr_ofs = cfv->tx_hr + info->hdr_len;\n\tpad_len = hdr_ofs & (IP_HDR_ALIGN - 1);\n\tbuf_info->size = cfv->tx_hr + skb->len + cfv->tx_tr + pad_len;\n\n\t \n\tbuf_info->vaddr = (void *)gen_pool_alloc(cfv->genpool, buf_info->size);\n\tif (unlikely(!buf_info->vaddr))\n\t\tgoto err;\n\n\t \n\tskb_copy_bits(skb, 0, buf_info->vaddr + cfv->tx_hr + pad_len, skb->len);\n\tsg_init_one(sg, buf_info->vaddr + pad_len,\n\t\t    skb->len + cfv->tx_hr + cfv->rx_hr);\n\n\treturn buf_info;\nerr:\n\tkfree(buf_info);\n\treturn NULL;\n}\n\n \nstatic netdev_tx_t cfv_netdev_tx(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct cfv_info *cfv = netdev_priv(netdev);\n\tstruct buf_info *buf_info;\n\tstruct scatterlist sg;\n\tunsigned long flags;\n\tbool flow_off = false;\n\tint ret;\n\n\t \n\tcfv_release_used_buf(cfv->vq_tx);\n\tspin_lock_irqsave(&cfv->tx_lock, flags);\n\n\t \n\tif (unlikely(cfv->vq_tx->num_free <= num_present_cpus())) {\n\t\tflow_off = true;\n\t\tcfv->stats.tx_full_ring++;\n\t}\n\n\t \n\tbuf_info = cfv_alloc_and_copy_to_shm(cfv, skb, &sg);\n\tif (unlikely(!buf_info)) {\n\t\tcfv->stats.tx_no_mem++;\n\t\tflow_off = true;\n\n\t\tif (cfv->reserved_mem && cfv->genpool) {\n\t\t\tgen_pool_free(cfv->genpool,  cfv->reserved_mem,\n\t\t\t\t      cfv->reserved_size);\n\t\t\tcfv->reserved_mem = 0;\n\t\t\tbuf_info = cfv_alloc_and_copy_to_shm(cfv, skb, &sg);\n\t\t}\n\t}\n\n\tif (unlikely(flow_off)) {\n\t\t \n\t\tcfv->watermark_tx = virtqueue_get_vring_size(cfv->vq_tx) / 4;\n\t\t \n\t\tvirtqueue_enable_cb(cfv->vq_tx);\n\t\tnetif_tx_stop_all_queues(netdev);\n\t}\n\n\tif (unlikely(!buf_info)) {\n\t\t \n\t\tnetdev_warn(cfv->ndev, \"Out of gen_pool memory\\n\");\n\t\tgoto err;\n\t}\n\n\tret = virtqueue_add_outbuf(cfv->vq_tx, &sg, 1, buf_info, GFP_ATOMIC);\n\tif (unlikely((ret < 0))) {\n\t\t \n\t\tnetdev_warn(cfv->ndev, \"Failed adding buffer to TX vring:%d\\n\",\n\t\t\t    ret);\n\t\tgoto err;\n\t}\n\n\t \n\tcfv->ndev->stats.tx_packets++;\n\tcfv->ndev->stats.tx_bytes += skb->len;\n\tspin_unlock_irqrestore(&cfv->tx_lock, flags);\n\n\t \n\tvirtqueue_kick(cfv->vq_tx);\n\n\tdev_kfree_skb(skb);\n\treturn NETDEV_TX_OK;\nerr:\n\tspin_unlock_irqrestore(&cfv->tx_lock, flags);\n\tcfv->ndev->stats.tx_dropped++;\n\tfree_buf_info(cfv, buf_info);\n\tdev_kfree_skb(skb);\n\treturn NETDEV_TX_OK;\n}\n\nstatic void cfv_tx_release_tasklet(struct tasklet_struct *t)\n{\n\tstruct cfv_info *cfv = from_tasklet(cfv, t, tx_release_tasklet);\n\tcfv_release_used_buf(cfv->vq_tx);\n}\n\nstatic const struct net_device_ops cfv_netdev_ops = {\n\t.ndo_open = cfv_netdev_open,\n\t.ndo_stop = cfv_netdev_close,\n\t.ndo_start_xmit = cfv_netdev_tx,\n};\n\nstatic void cfv_netdev_setup(struct net_device *netdev)\n{\n\tnetdev->netdev_ops = &cfv_netdev_ops;\n\tnetdev->type = ARPHRD_CAIF;\n\tnetdev->tx_queue_len = 100;\n\tnetdev->flags = IFF_POINTOPOINT | IFF_NOARP;\n\tnetdev->mtu = CFV_DEF_MTU_SIZE;\n\tnetdev->needs_free_netdev = true;\n}\n\n \nstatic inline void debugfs_init(struct cfv_info *cfv)\n{\n\tcfv->debugfs = debugfs_create_dir(netdev_name(cfv->ndev), NULL);\n\n\tdebugfs_create_u32(\"rx-napi-complete\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.rx_napi_complete);\n\tdebugfs_create_u32(\"rx-napi-resched\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.rx_napi_resched);\n\tdebugfs_create_u32(\"rx-nomem\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.rx_nomem);\n\tdebugfs_create_u32(\"rx-kicks\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.rx_kicks);\n\tdebugfs_create_u32(\"tx-full-ring\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.tx_full_ring);\n\tdebugfs_create_u32(\"tx-no-mem\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.tx_no_mem);\n\tdebugfs_create_u32(\"tx-kicks\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.tx_kicks);\n\tdebugfs_create_u32(\"tx-flow-on\", 0400, cfv->debugfs,\n\t\t\t   &cfv->stats.tx_flow_on);\n}\n\n \nstatic int cfv_probe(struct virtio_device *vdev)\n{\n\tvq_callback_t *vq_cbs = cfv_release_cb;\n\tvrh_callback_t *vrh_cbs = cfv_recv;\n\tconst char *names =  \"output\";\n\tconst char *cfv_netdev_name = \"cfvrt\";\n\tstruct net_device *netdev;\n\tstruct cfv_info *cfv;\n\tint err;\n\n\tnetdev = alloc_netdev(sizeof(struct cfv_info), cfv_netdev_name,\n\t\t\t      NET_NAME_UNKNOWN, cfv_netdev_setup);\n\tif (!netdev)\n\t\treturn -ENOMEM;\n\n\tcfv = netdev_priv(netdev);\n\tcfv->vdev = vdev;\n\tcfv->ndev = netdev;\n\n\tspin_lock_init(&cfv->tx_lock);\n\n\t \n\terr = -ENODEV;\n\tif (!vdev->vringh_config || !vdev->vringh_config->find_vrhs)\n\t\tgoto err;\n\n\terr = vdev->vringh_config->find_vrhs(vdev, 1, &cfv->vr_rx, &vrh_cbs);\n\tif (err)\n\t\tgoto err;\n\n\t \n\terr = virtio_find_vqs(vdev, 1, &cfv->vq_tx, &vq_cbs, &names, NULL);\n\tif (err)\n\t\tgoto err;\n\n\t \n\tif (vdev->config->get) {\n\t\tvirtio_cread(vdev, struct virtio_caif_transf_config, headroom,\n\t\t\t     &cfv->tx_hr);\n\t\tvirtio_cread(vdev, struct virtio_caif_transf_config, headroom,\n\t\t\t     &cfv->rx_hr);\n\t\tvirtio_cread(vdev, struct virtio_caif_transf_config, tailroom,\n\t\t\t     &cfv->tx_tr);\n\t\tvirtio_cread(vdev, struct virtio_caif_transf_config, tailroom,\n\t\t\t     &cfv->rx_tr);\n\t\tvirtio_cread(vdev, struct virtio_caif_transf_config, mtu,\n\t\t\t     &cfv->mtu);\n\t\tvirtio_cread(vdev, struct virtio_caif_transf_config, mtu,\n\t\t\t     &cfv->mru);\n\t} else {\n\t\tcfv->tx_hr = CFV_DEF_HEADROOM;\n\t\tcfv->rx_hr = CFV_DEF_HEADROOM;\n\t\tcfv->tx_tr = CFV_DEF_TAILROOM;\n\t\tcfv->rx_tr = CFV_DEF_TAILROOM;\n\t\tcfv->mtu = CFV_DEF_MTU_SIZE;\n\t\tcfv->mru = CFV_DEF_MTU_SIZE;\n\t}\n\n\tnetdev->needed_headroom = cfv->tx_hr;\n\tnetdev->needed_tailroom = cfv->tx_tr;\n\n\t \n\tvirtqueue_disable_cb(cfv->vq_tx);\n\n\tnetdev->mtu = cfv->mtu - cfv->tx_tr;\n\tvdev->priv = cfv;\n\n\t \n\tvringh_kiov_init(&cfv->ctx.riov, NULL, 0);\n\tcfv->ctx.head = USHRT_MAX;\n\tnetif_napi_add_weight(netdev, &cfv->napi, cfv_rx_poll,\n\t\t\t      CFV_DEFAULT_QUOTA);\n\n\ttasklet_setup(&cfv->tx_release_tasklet, cfv_tx_release_tasklet);\n\n\t \n\tnetif_carrier_off(netdev);\n\n\t \n\trtnl_lock();\n\n\t \n\terr = register_netdevice(netdev);\n\tif (err) {\n\t\trtnl_unlock();\n\t\tdev_err(&vdev->dev, \"Unable to register netdev (%d)\\n\", err);\n\t\tgoto err;\n\t}\n\n\tvirtio_device_ready(vdev);\n\n\trtnl_unlock();\n\n\tdebugfs_init(cfv);\n\n\treturn 0;\nerr:\n\tnetdev_warn(cfv->ndev, \"CAIF Virtio probe failed:%d\\n\", err);\n\n\tif (cfv->vr_rx)\n\t\tvdev->vringh_config->del_vrhs(cfv->vdev);\n\tif (cfv->vdev)\n\t\tvdev->config->del_vqs(cfv->vdev);\n\tfree_netdev(netdev);\n\treturn err;\n}\n\nstatic void cfv_remove(struct virtio_device *vdev)\n{\n\tstruct cfv_info *cfv = vdev->priv;\n\n\trtnl_lock();\n\tdev_close(cfv->ndev);\n\trtnl_unlock();\n\n\ttasklet_kill(&cfv->tx_release_tasklet);\n\tdebugfs_remove_recursive(cfv->debugfs);\n\n\tvringh_kiov_cleanup(&cfv->ctx.riov);\n\tvirtio_reset_device(vdev);\n\tvdev->vringh_config->del_vrhs(cfv->vdev);\n\tcfv->vr_rx = NULL;\n\tvdev->config->del_vqs(cfv->vdev);\n\tunregister_netdev(cfv->ndev);\n}\n\nstatic struct virtio_device_id id_table[] = {\n\t{ VIRTIO_ID_CAIF, VIRTIO_DEV_ANY_ID },\n\t{ 0 },\n};\n\nstatic unsigned int features[] = {\n};\n\nstatic struct virtio_driver caif_virtio_driver = {\n\t.feature_table\t\t= features,\n\t.feature_table_size\t= ARRAY_SIZE(features),\n\t.driver.name\t\t= KBUILD_MODNAME,\n\t.driver.owner\t\t= THIS_MODULE,\n\t.id_table\t\t= id_table,\n\t.probe\t\t\t= cfv_probe,\n\t.remove\t\t\t= cfv_remove,\n};\n\nmodule_virtio_driver(caif_virtio_driver);\nMODULE_DEVICE_TABLE(virtio, id_table);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}