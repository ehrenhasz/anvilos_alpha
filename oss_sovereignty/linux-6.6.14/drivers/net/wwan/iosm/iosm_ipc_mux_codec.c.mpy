{
  "module_name": "iosm_ipc_mux_codec.c",
  "hash_id": "336a100e1408586fc5a0ee29742c5c7e97405b0b975bdf1c8626a0101578c3ce",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wwan/iosm/iosm_ipc_mux_codec.c",
  "human_readable_source": "\n \n\n#include <linux/nospec.h>\n\n#include \"iosm_ipc_imem_ops.h\"\n#include \"iosm_ipc_mux_codec.h\"\n#include \"iosm_ipc_task_queue.h\"\n\n \nstatic int ipc_mux_tq_cmd_send(struct iosm_imem *ipc_imem, int arg, void *msg,\n\t\t\t       size_t size)\n{\n\tstruct iosm_mux *ipc_mux = ipc_imem->mux;\n\tconst struct mux_acb *acb = msg;\n\n\tskb_queue_tail(&ipc_mux->channel->ul_list, acb->skb);\n\tipc_imem_ul_send(ipc_mux->imem);\n\n\treturn 0;\n}\n\nstatic int ipc_mux_acb_send(struct iosm_mux *ipc_mux, bool blocking)\n{\n\tstruct completion *completion = &ipc_mux->channel->ul_sem;\n\tint ret = ipc_task_queue_send_task(ipc_mux->imem, ipc_mux_tq_cmd_send,\n\t\t\t\t\t   0, &ipc_mux->acb,\n\t\t\t\t\t   sizeof(ipc_mux->acb), false);\n\tif (ret) {\n\t\tdev_err(ipc_mux->dev, \"unable to send mux command\");\n\t\treturn ret;\n\t}\n\n\t \n\tif (blocking) {\n\t\tu32 wait_time_milliseconds = IPC_MUX_CMD_RUN_DEFAULT_TIMEOUT;\n\n\t\treinit_completion(completion);\n\n\t\tif (wait_for_completion_interruptible_timeout\n\t\t   (completion, msecs_to_jiffies(wait_time_milliseconds)) ==\n\t\t   0) {\n\t\t\tdev_err(ipc_mux->dev, \"ch[%d] timeout\",\n\t\t\t\tipc_mux->channel_id);\n\t\t\tipc_uevent_send(ipc_mux->imem->dev, UEVENT_MDM_TIMEOUT);\n\t\t\treturn -ETIMEDOUT;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n \nstatic void ipc_mux_acb_init(struct iosm_mux *ipc_mux)\n{\n\tstruct mux_acb *acb = &ipc_mux->acb;\n\tstruct mux_acbh *header;\n\n\theader = (struct mux_acbh *)(acb->skb)->data;\n\theader->block_length = cpu_to_le32(sizeof(struct mux_acbh));\n\theader->first_cmd_index = header->block_length;\n\theader->signature = cpu_to_le32(IOSM_AGGR_MUX_SIG_ACBH);\n\theader->sequence_nr = cpu_to_le16(ipc_mux->acb_tx_sequence_nr++);\n}\n\n \nstatic struct mux_cmdh *ipc_mux_acb_add_cmd(struct iosm_mux *ipc_mux, u32 cmd,\n\t\t\t\t\t    void *param, u32 param_size)\n{\n\tstruct mux_acbh *header;\n\tstruct mux_cmdh *cmdh;\n\tstruct mux_acb *acb;\n\n\tacb = &ipc_mux->acb;\n\theader = (struct mux_acbh *)(acb->skb)->data;\n\tcmdh = (struct mux_cmdh *)\n\t\t((acb->skb)->data + le32_to_cpu(header->block_length));\n\n\tcmdh->signature = cpu_to_le32(MUX_SIG_CMDH);\n\tcmdh->command_type = cpu_to_le32(cmd);\n\tcmdh->if_id = acb->if_id;\n\n\tacb->cmd = cmd;\n\tcmdh->cmd_len = cpu_to_le16(offsetof(struct mux_cmdh, param) +\n\t\t\t\t    param_size);\n\tcmdh->transaction_id = cpu_to_le32(ipc_mux->tx_transaction_id++);\n\tif (param)\n\t\tmemcpy(&cmdh->param, param, param_size);\n\n\tskb_put(acb->skb, le32_to_cpu(header->block_length) +\n\t\t\t\t\tle16_to_cpu(cmdh->cmd_len));\n\n\treturn cmdh;\n}\n\n \nstatic struct mux_lite_cmdh *ipc_mux_lite_add_cmd(struct iosm_mux *ipc_mux,\n\t\t\t\t\t\t  u32 cmd, struct mux_acb *acb,\n\t\t\t\t\t\t  void *param, u32 param_size)\n{\n\tstruct mux_lite_cmdh *cmdh = (struct mux_lite_cmdh *)acb->skb->data;\n\n\tcmdh->signature = cpu_to_le32(MUX_SIG_CMDH);\n\tcmdh->command_type = cpu_to_le32(cmd);\n\tcmdh->if_id = acb->if_id;\n\n\tacb->cmd = cmd;\n\n\tcmdh->cmd_len = cpu_to_le16(offsetof(struct mux_lite_cmdh, param) +\n\t\t\t\t    param_size);\n\tcmdh->transaction_id = cpu_to_le32(ipc_mux->tx_transaction_id++);\n\n\tif (param)\n\t\tmemcpy(&cmdh->param, param, param_size);\n\n\tskb_put(acb->skb, le16_to_cpu(cmdh->cmd_len));\n\n\treturn cmdh;\n}\n\nstatic int ipc_mux_acb_alloc(struct iosm_mux *ipc_mux)\n{\n\tstruct mux_acb *acb = &ipc_mux->acb;\n\tstruct sk_buff *skb;\n\tdma_addr_t mapping;\n\n\t \n\tskb = ipc_pcie_alloc_skb(ipc_mux->pcie, MUX_MAX_UL_ACB_BUF_SIZE,\n\t\t\t\t GFP_ATOMIC, &mapping, DMA_TO_DEVICE, 0);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\t \n\tacb->skb = skb;\n\n\tmemset(skb->data, 0, MUX_MAX_UL_ACB_BUF_SIZE);\n\n\treturn 0;\n}\n\nint ipc_mux_dl_acb_send_cmds(struct iosm_mux *ipc_mux, u32 cmd_type, u8 if_id,\n\t\t\t     u32 transaction_id, union mux_cmd_param *param,\n\t\t\t     size_t res_size, bool blocking, bool respond)\n{\n\tstruct mux_acb *acb = &ipc_mux->acb;\n\tunion mux_type_cmdh cmdh;\n\tint ret = 0;\n\n\tacb->if_id = if_id;\n\tret = ipc_mux_acb_alloc(ipc_mux);\n\tif (ret)\n\t\treturn ret;\n\n\tif (ipc_mux->protocol == MUX_LITE) {\n\t\tcmdh.ack_lite = ipc_mux_lite_add_cmd(ipc_mux, cmd_type, acb,\n\t\t\t\t\t\t     param, res_size);\n\n\t\tif (respond)\n\t\t\tcmdh.ack_lite->transaction_id =\n\t\t\t\t\tcpu_to_le32(transaction_id);\n\t} else {\n\t\t \n\t\tipc_mux_acb_init(ipc_mux);\n\t\tcmdh.ack_aggr = ipc_mux_acb_add_cmd(ipc_mux, cmd_type, param,\n\t\t\t\t\t\t    res_size);\n\n\t\tif (respond)\n\t\t\tcmdh.ack_aggr->transaction_id =\n\t\t\t\t\tcpu_to_le32(transaction_id);\n\t}\n\tret = ipc_mux_acb_send(ipc_mux, blocking);\n\n\treturn ret;\n}\n\nvoid ipc_mux_netif_tx_flowctrl(struct mux_session *session, int idx, bool on)\n{\n\t \n\tipc_wwan_tx_flowctrl(session->wwan, idx, on);\n}\n\nstatic int ipc_mux_dl_cmdresps_decode_process(struct iosm_mux *ipc_mux,\n\t\t\t\t\t      union mux_cmd_param param,\n\t\t\t\t\t      __le32 command_type, u8 if_id,\n\t\t\t\t\t      __le32 transaction_id)\n{\n\tstruct mux_acb *acb = &ipc_mux->acb;\n\n\tswitch (le32_to_cpu(command_type)) {\n\tcase MUX_CMD_OPEN_SESSION_RESP:\n\tcase MUX_CMD_CLOSE_SESSION_RESP:\n\t\t \n\t\tacb->got_param = param;\n\t\tbreak;\n\n\tcase MUX_LITE_CMD_FLOW_CTL_ACK:\n\t\t \n\t\tif (ipc_mux->protocol != MUX_LITE)\n\t\t\treturn -EINVAL;\n\n\t\tdev_dbg(ipc_mux->dev, \"if_id %u FLOW_CTL_ACK %u received\",\n\t\t\tif_id, le32_to_cpu(transaction_id));\n\t\tbreak;\n\n\tcase IOSM_AGGR_MUX_CMD_FLOW_CTL_ACK:\n\t\t \n\t\tif (ipc_mux->protocol == MUX_LITE)\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tacb->wanted_response = MUX_CMD_INVALID;\n\tacb->got_response = le32_to_cpu(command_type);\n\tcomplete(&ipc_mux->channel->ul_sem);\n\n\treturn 0;\n}\n\nstatic int ipc_mux_dl_cmds_decode_process(struct iosm_mux *ipc_mux,\n\t\t\t\t\t  union mux_cmd_param *param,\n\t\t\t\t\t  __le32 command_type, u8 if_id,\n\t\t\t\t\t  __le16 cmd_len, int size)\n{\n\tstruct mux_session *session;\n\tstruct hrtimer *adb_timer;\n\n\tdev_dbg(ipc_mux->dev, \"if_id[%d]: dlcmds decode process %d\",\n\t\tif_id, le32_to_cpu(command_type));\n\n\tswitch (le32_to_cpu(command_type)) {\n\tcase MUX_LITE_CMD_FLOW_CTL:\n\tcase IOSM_AGGR_MUX_CMD_FLOW_CTL_DISABLE:\n\n\t\tif (if_id >= IPC_MEM_MUX_IP_SESSION_ENTRIES) {\n\t\t\tdev_err(ipc_mux->dev, \"if_id [%d] not valid\",\n\t\t\t\tif_id);\n\t\t\treturn -EINVAL;  \n\t\t}\n\n\t\tsession = &ipc_mux->session[if_id];\n\t\tadb_timer = &ipc_mux->imem->adb_timer;\n\n\t\tif (param->flow_ctl.mask == cpu_to_le32(0xFFFFFFFF)) {\n\t\t\t \n\t\t\tif (cmd_len == cpu_to_le16(size))\n\t\t\t\tsession->flow_ctl_mask =\n\t\t\t\t\tle32_to_cpu(param->flow_ctl.mask);\n\t\t\telse\n\t\t\t\tsession->flow_ctl_mask = ~0;\n\t\t\t \n\t\t\tsession->net_tx_stop = true;\n\n\t\t\t \n\t\t\tif (ipc_mux->protocol == MUX_AGGREGATION) {\n\t\t\t\tipc_mux_ul_adb_finish(ipc_mux);\n\t\t\t\tipc_imem_hrtimer_stop(adb_timer);\n\t\t\t}\n\t\t\t \n\t\t\tsession->flow_ctl_en_cnt++;\n\t\t} else if (param->flow_ctl.mask == 0) {\n\t\t\t \n\t\t\tdev_dbg(ipc_mux->dev, \"if_id[%u] flow_ctl mask 0x%08X\",\n\t\t\t\tif_id, le32_to_cpu(param->flow_ctl.mask));\n\t\t\t \n\t\t\tif (cmd_len == cpu_to_le16(size))\n\t\t\t\tsession->flow_ctl_mask =\n\t\t\t\t\tle32_to_cpu(param->flow_ctl.mask);\n\t\t\telse\n\t\t\t\tsession->flow_ctl_mask = 0;\n\t\t\t \n\t\t\tsession->flow_ctl_dis_cnt++;\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\n\t\tipc_mux->acc_adb_size = 0;\n\t\tipc_mux->acc_payload_size = 0;\n\n\t\tdev_dbg(ipc_mux->dev, \"if_id[%u] FLOW CTRL 0x%08X\", if_id,\n\t\t\tle32_to_cpu(param->flow_ctl.mask));\n\t\tbreak;\n\n\tcase MUX_LITE_CMD_LINK_STATUS_REPORT:\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\n \nstatic void ipc_mux_dl_cmd_decode(struct iosm_mux *ipc_mux, struct sk_buff *skb)\n{\n\tstruct mux_lite_cmdh *cmdh = (struct mux_lite_cmdh *)skb->data;\n\t__le32 trans_id = cmdh->transaction_id;\n\tint size;\n\n\tif (ipc_mux_dl_cmdresps_decode_process(ipc_mux, cmdh->param,\n\t\t\t\t\t       cmdh->command_type, cmdh->if_id,\n\t\t\t\t\t       cmdh->transaction_id)) {\n\t\t \n\t\tsize = offsetof(struct mux_lite_cmdh, param) +\n\t\t\t\tsizeof(cmdh->param.flow_ctl);\n\t\tif (!ipc_mux_dl_cmds_decode_process(ipc_mux, &cmdh->param,\n\t\t\t\t\t\t    cmdh->command_type,\n\t\t\t\t\t\t    cmdh->if_id,\n\t\t\t\t\t\t    cmdh->cmd_len, size)) {\n\t\t\t \n\t\t\tunion mux_cmd_param *mux_cmd = NULL;\n\t\t\tsize_t size = 0;\n\t\t\tu32 cmd = MUX_LITE_CMD_LINK_STATUS_REPORT_RESP;\n\n\t\t\tif (cmdh->command_type ==\n\t\t\t    cpu_to_le32(MUX_LITE_CMD_LINK_STATUS_REPORT)) {\n\t\t\t\tmux_cmd = &cmdh->param;\n\t\t\t\tmux_cmd->link_status_resp.response =\n\t\t\t\t\tcpu_to_le32(MUX_CMD_RESP_SUCCESS);\n\t\t\t\t \n\t\t\t\tsize = sizeof(u32);\n\t\t\t} else if (cmdh->command_type ==\n\t\t\t\t   cpu_to_le32(MUX_LITE_CMD_FLOW_CTL)) {\n\t\t\t\tcmd = MUX_LITE_CMD_FLOW_CTL_ACK;\n\t\t\t} else {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (ipc_mux_dl_acb_send_cmds(ipc_mux, cmd, cmdh->if_id,\n\t\t\t\t\t\t     le32_to_cpu(trans_id),\n\t\t\t\t\t\t     mux_cmd, size, false,\n\t\t\t\t\t\t     true))\n\t\t\t\tdev_err(ipc_mux->dev,\n\t\t\t\t\t\"if_id %d: cmd send failed\",\n\t\t\t\t\tcmdh->if_id);\n\t\t}\n\t}\n}\n\n \nstatic int ipc_mux_net_receive(struct iosm_mux *ipc_mux, int if_id,\n\t\t\t       struct iosm_wwan *wwan, u32 offset,\n\t\t\t       u8 service_class, struct sk_buff *skb,\n\t\t\t       u32 pkt_len)\n{\n\tstruct sk_buff *dest_skb = skb_clone(skb, GFP_ATOMIC);\n\n\tif (!dest_skb)\n\t\treturn -ENOMEM;\n\n\tskb_pull(dest_skb, offset);\n\tskb_trim(dest_skb, pkt_len);\n\t \n\tdest_skb->priority = service_class;\n\n\treturn ipc_wwan_receive(wwan, dest_skb, false, if_id);\n}\n\n \nstatic void ipc_mux_dl_fcth_decode(struct iosm_mux *ipc_mux,\n\t\t\t\t   unsigned char *block)\n{\n\tstruct ipc_mem_lite_gen_tbl *fct = (struct ipc_mem_lite_gen_tbl *)block;\n\tstruct iosm_wwan *wwan;\n\tint ul_credits;\n\tint if_id;\n\n\tif (fct->vfl_length != sizeof(fct->vfl.nr_of_bytes)) {\n\t\tdev_err(ipc_mux->dev, \"unexpected FCT length: %d\",\n\t\t\tfct->vfl_length);\n\t\treturn;\n\t}\n\n\tif_id = fct->if_id;\n\tif (if_id >= IPC_MEM_MUX_IP_SESSION_ENTRIES) {\n\t\tdev_err(ipc_mux->dev, \"not supported if_id: %d\", if_id);\n\t\treturn;\n\t}\n\n\t \n\tif_id = array_index_nospec(if_id, IPC_MEM_MUX_IP_SESSION_ENTRIES);\n\twwan = ipc_mux->session[if_id].wwan;\n\tif (!wwan) {\n\t\tdev_err(ipc_mux->dev, \"session Net ID is NULL\");\n\t\treturn;\n\t}\n\n\tul_credits = le32_to_cpu(fct->vfl.nr_of_bytes);\n\n\tdev_dbg(ipc_mux->dev, \"Flow_Credit:: if_id[%d] Old: %d Grants: %d\",\n\t\tif_id, ipc_mux->session[if_id].ul_flow_credits, ul_credits);\n\n\t \n\tipc_mux->session[if_id].ul_flow_credits += ul_credits;\n\n\t \n\tif (ipc_mux->session[if_id].ul_flow_credits > 0) {\n\t\tipc_mux->session[if_id].net_tx_stop = false;\n\t\tipc_mux_netif_tx_flowctrl(&ipc_mux->session[if_id],\n\t\t\t\t\t  ipc_mux->session[if_id].if_id, false);\n\t}\n}\n\n \nstatic void ipc_mux_dl_adgh_decode(struct iosm_mux *ipc_mux,\n\t\t\t\t   struct sk_buff *skb)\n{\n\tu32 pad_len, packet_offset, adgh_len;\n\tstruct iosm_wwan *wwan;\n\tstruct mux_adgh *adgh;\n\tu8 *block = skb->data;\n\tint rc = 0;\n\tu8 if_id;\n\n\tadgh = (struct mux_adgh *)block;\n\n\tif (adgh->signature != cpu_to_le32(IOSM_AGGR_MUX_SIG_ADGH)) {\n\t\tdev_err(ipc_mux->dev, \"invalid ADGH signature received\");\n\t\treturn;\n\t}\n\n\tif_id = adgh->if_id;\n\tif (if_id >= IPC_MEM_MUX_IP_SESSION_ENTRIES) {\n\t\tdev_err(ipc_mux->dev, \"invalid if_id while decoding %d\", if_id);\n\t\treturn;\n\t}\n\n\t \n\tif_id = array_index_nospec(if_id, IPC_MEM_MUX_IP_SESSION_ENTRIES);\n\twwan = ipc_mux->session[if_id].wwan;\n\tif (!wwan) {\n\t\tdev_err(ipc_mux->dev, \"session Net ID is NULL\");\n\t\treturn;\n\t}\n\n\t \n\tpad_len =\n\t\tipc_mux->session[if_id].dl_head_pad_len - IPC_MEM_DL_ETH_OFFSET;\n\tpacket_offset = sizeof(*adgh) + pad_len;\n\n\tif_id += ipc_mux->wwan_q_offset;\n\tadgh_len = le16_to_cpu(adgh->length);\n\n\t \n\trc = ipc_mux_net_receive(ipc_mux, if_id, wwan, packet_offset,\n\t\t\t\t adgh->service_class, skb,\n\t\t\t\t adgh_len - packet_offset);\n\tif (rc) {\n\t\tdev_err(ipc_mux->dev, \"mux adgh decoding error\");\n\t\treturn;\n\t}\n\tipc_mux->session[if_id].flush = 1;\n}\n\nstatic void ipc_mux_dl_acbcmd_decode(struct iosm_mux *ipc_mux,\n\t\t\t\t     struct mux_cmdh *cmdh, int size)\n{\n\tu32 link_st  = IOSM_AGGR_MUX_CMD_LINK_STATUS_REPORT_RESP;\n\tu32 fctl_dis = IOSM_AGGR_MUX_CMD_FLOW_CTL_DISABLE;\n\tu32 fctl_ena = IOSM_AGGR_MUX_CMD_FLOW_CTL_ENABLE;\n\tu32 fctl_ack = IOSM_AGGR_MUX_CMD_FLOW_CTL_ACK;\n\tunion mux_cmd_param *cmd_p = NULL;\n\tu32 cmd = link_st;\n\tu32 trans_id;\n\n\tif (!ipc_mux_dl_cmds_decode_process(ipc_mux, &cmdh->param,\n\t\t\t\t\t    cmdh->command_type, cmdh->if_id,\n\t\t\t\t\t    cmdh->cmd_len, size)) {\n\t\tsize = 0;\n\t\tif (cmdh->command_type == cpu_to_le32(link_st)) {\n\t\t\tcmd_p = &cmdh->param;\n\t\t\tcmd_p->link_status_resp.response = MUX_CMD_RESP_SUCCESS;\n\t\t} else if ((cmdh->command_type == cpu_to_le32(fctl_ena)) ||\n\t\t\t\t(cmdh->command_type == cpu_to_le32(fctl_dis))) {\n\t\t\tcmd = fctl_ack;\n\t\t} else {\n\t\t\treturn;\n\t\t\t}\n\t\ttrans_id = le32_to_cpu(cmdh->transaction_id);\n\t\tipc_mux_dl_acb_send_cmds(ipc_mux, cmd, cmdh->if_id,\n\t\t\t\t\t trans_id, cmd_p, size, false, true);\n\t}\n}\n\n \nstatic void ipc_mux_dl_acb_decode(struct iosm_mux *ipc_mux, struct sk_buff *skb)\n{\n\tstruct mux_acbh *acbh;\n\tstruct mux_cmdh *cmdh;\n\tu32 next_cmd_index;\n\tu8 *block;\n\tint size;\n\n\tacbh = (struct mux_acbh *)(skb->data);\n\tblock = (u8 *)(skb->data);\n\n\tnext_cmd_index = le32_to_cpu(acbh->first_cmd_index);\n\tnext_cmd_index = array_index_nospec(next_cmd_index,\n\t\t\t\t\t    sizeof(struct mux_cmdh));\n\n\twhile (next_cmd_index != 0) {\n\t\tcmdh = (struct mux_cmdh *)&block[next_cmd_index];\n\t\tnext_cmd_index = le32_to_cpu(cmdh->next_cmd_index);\n\t\tif (ipc_mux_dl_cmdresps_decode_process(ipc_mux, cmdh->param,\n\t\t\t\t\t\t       cmdh->command_type,\n\t\t\t\t\t\t       cmdh->if_id,\n\t\t\t\t\t\t       cmdh->transaction_id)) {\n\t\t\tsize = offsetof(struct mux_cmdh, param) +\n\t\t\t\tsizeof(cmdh->param.flow_ctl);\n\t\t\tipc_mux_dl_acbcmd_decode(ipc_mux, cmdh, size);\n\t\t}\n\t}\n}\n\n \nstatic int mux_dl_process_dg(struct iosm_mux *ipc_mux, struct mux_adbh *adbh,\n\t\t\t     struct mux_adth_dg *dg, struct sk_buff *skb,\n\t\t\t     int if_id, int nr_of_dg)\n{\n\tu32 dl_head_pad_len = ipc_mux->session[if_id].dl_head_pad_len;\n\tu32 packet_offset, i, rc, dg_len;\n\n\tfor (i = 0; i < nr_of_dg; i++, dg++) {\n\t\tif (le32_to_cpu(dg->datagram_index)\n\t\t\t\t< sizeof(struct mux_adbh))\n\t\t\tgoto dg_error;\n\n\t\t \n\t\tif (le32_to_cpu(dg->datagram_index) >=\n\t\t\t\t\tle32_to_cpu(adbh->block_length)) {\n\t\t\tgoto dg_error;\n\t\t} else {\n\t\t\tpacket_offset =\n\t\t\t\tle32_to_cpu(dg->datagram_index) +\n\t\t\t\tdl_head_pad_len;\n\t\t\tdg_len = le16_to_cpu(dg->datagram_length);\n\t\t\t \n\t\t\trc = ipc_mux_net_receive(ipc_mux, if_id, ipc_mux->wwan,\n\t\t\t\t\t\t packet_offset,\n\t\t\t\t\t\t dg->service_class, skb,\n\t\t\t\t\t\t dg_len - dl_head_pad_len);\n\t\t\tif (rc)\n\t\t\t\tgoto dg_error;\n\t\t}\n\t}\n\treturn 0;\ndg_error:\n\treturn -1;\n}\n\n \nstatic void mux_dl_adb_decode(struct iosm_mux *ipc_mux,\n\t\t\t      struct sk_buff *skb)\n{\n\tstruct mux_adth_dg *dg;\n\tstruct iosm_wwan *wwan;\n\tstruct mux_adbh *adbh;\n\tstruct mux_adth *adth;\n\tint nr_of_dg, if_id;\n\tu32 adth_index;\n\tu8 *block;\n\n\tblock = skb->data;\n\tadbh = (struct mux_adbh *)block;\n\n\t \n\tadth_index = le32_to_cpu(adbh->first_table_index);\n\n\t \n\tif (adth_index < 1) {\n\t\tdev_err(ipc_mux->dev, \"unexpected empty ADB\");\n\t\tgoto adb_decode_err;\n\t}\n\n\t \n\twhile (adth_index) {\n\t\t \n\t\tadth = (struct mux_adth *)(block + adth_index);\n\n\t\t \n\t\tif_id = adth->if_id;\n\t\tif (if_id >= IPC_MEM_MUX_IP_SESSION_ENTRIES)\n\t\t\tgoto adb_decode_err;\n\n\t\tif_id = array_index_nospec(if_id,\n\t\t\t\t\t   IPC_MEM_MUX_IP_SESSION_ENTRIES);\n\n\t\t \n\t\twwan = ipc_mux->session[if_id].wwan;\n\t\tif (!wwan)\n\t\t\tgoto adb_decode_err;\n\n\t\t \n\t\tif (adth->signature != cpu_to_le32(IOSM_AGGR_MUX_SIG_ADTH))\n\t\t\tgoto adb_decode_err;\n\n\t\tif (le16_to_cpu(adth->table_length) < sizeof(struct mux_adth))\n\t\t\tgoto adb_decode_err;\n\n\t\t \n\t\tnr_of_dg = (le16_to_cpu(adth->table_length) -\n\t\t\t\t\tsizeof(struct mux_adth)) /\n\t\t\t\t\tsizeof(struct mux_adth_dg);\n\n\t\t \n\t\tif (nr_of_dg < 1) {\n\t\t\tdev_err(ipc_mux->dev,\n\t\t\t\t\"adthidx=%u,nr_of_dg=%d,next_tblidx=%u\",\n\t\t\t\tadth_index, nr_of_dg,\n\t\t\t\tle32_to_cpu(adth->next_table_index));\n\n\t\t\t \n\t\t\tadth_index = le32_to_cpu(adth->next_table_index);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tdg = adth->dg;\n\t\tif (mux_dl_process_dg(ipc_mux, adbh, dg, skb, if_id,\n\t\t\t\t      nr_of_dg) < 0)\n\t\t\tgoto adb_decode_err;\n\n\t\t \n\t\tipc_mux->session[if_id].flush = 1;\n\n\t\t \n\t\tadth_index = le32_to_cpu(adth->next_table_index);\n\t}\n\nadb_decode_err:\n\treturn;\n}\n\n \nvoid ipc_mux_dl_decode(struct iosm_mux *ipc_mux, struct sk_buff *skb)\n{\n\tu32 signature;\n\n\tif (!skb->data)\n\t\treturn;\n\n\t \n\tsignature = le32_to_cpup((__le32 *)skb->data);\n\n\tswitch (signature) {\n\tcase IOSM_AGGR_MUX_SIG_ADBH:\t \n\t\tmux_dl_adb_decode(ipc_mux, skb);\n\t\tbreak;\n\tcase IOSM_AGGR_MUX_SIG_ADGH:\n\t\tipc_mux_dl_adgh_decode(ipc_mux, skb);\n\t\tbreak;\n\tcase MUX_SIG_FCTH:\n\t\tipc_mux_dl_fcth_decode(ipc_mux, skb->data);\n\t\tbreak;\n\tcase IOSM_AGGR_MUX_SIG_ACBH:\t \n\t\tipc_mux_dl_acb_decode(ipc_mux, skb);\n\t\tbreak;\n\tcase MUX_SIG_CMDH:\n\t\tipc_mux_dl_cmd_decode(ipc_mux, skb);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(ipc_mux->dev, \"invalid ABH signature\");\n\t}\n\n\tipc_pcie_kfree_skb(ipc_mux->pcie, skb);\n}\n\nstatic int ipc_mux_ul_skb_alloc(struct iosm_mux *ipc_mux,\n\t\t\t\tstruct mux_adb *ul_adb, u32 type)\n{\n\t \n\tstruct sk_buff *skb = skb_dequeue(&ul_adb->free_list);\n\tu32 no_if = IPC_MEM_MUX_IP_SESSION_ENTRIES;\n\tu32 *next_tb_id;\n\tint qlt_size;\n\tu32 if_id;\n\n\tif (!skb)\n\t\treturn -EBUSY;  \n\n\t \n\tIPC_CB(skb)->op_type = (u8)UL_MUX_OP_ADB;\n\n\tswitch (type) {\n\tcase IOSM_AGGR_MUX_SIG_ADBH:\n\t\t \n\t\tul_adb->dest_skb = skb;\n\t\tul_adb->buf = skb->data;\n\t\tul_adb->size = IPC_MEM_MAX_ADB_BUF_SIZE;\n\n\t\t \n\t\tul_adb->if_cnt = 0;\n\t\tul_adb->payload_size = 0;\n\t\tul_adb->dg_cnt_total = 0;\n\n\t\t \n\t\tul_adb->adbh = (struct mux_adbh *)ul_adb->buf;\n\t\tmemset(ul_adb->adbh, 0, sizeof(struct mux_adbh));\n\t\tul_adb->adbh->signature = cpu_to_le32(IOSM_AGGR_MUX_SIG_ADBH);\n\t\tul_adb->adbh->block_length =\n\t\t\t\t\tcpu_to_le32(sizeof(struct mux_adbh));\n\t\tnext_tb_id = (unsigned int *)&ul_adb->adbh->first_table_index;\n\t\tul_adb->next_table_index = next_tb_id;\n\n\t\t \n\t\tmemset(ul_adb->dg, 0, sizeof(ul_adb->dg));\n\n\t\t \n\t\tfor (if_id = 0; if_id < no_if; if_id++) {\n\t\t\tul_adb->dg_count[if_id] = 0;\n\t\t\tul_adb->qlt_updated[if_id] = 0;\n\t\t}\n\t\tbreak;\n\n\tcase IOSM_AGGR_MUX_SIG_ADGH:\n\t\t \n\t\tul_adb->dest_skb = skb;\n\t\tul_adb->buf = skb->data;\n\t\tul_adb->size = IPC_MEM_MAX_DL_MUX_LITE_BUF_SIZE;\n\t\t \n\t\tul_adb->if_cnt = 0;\n\t\tul_adb->payload_size = 0;\n\t\tul_adb->dg_cnt_total = 0;\n\n\t\tul_adb->adgh = (struct mux_adgh *)skb->data;\n\t\tmemset(ul_adb->adgh, 0, sizeof(struct mux_adgh));\n\t\tbreak;\n\n\tcase MUX_SIG_QLTH:\n\t\tqlt_size = offsetof(struct ipc_mem_lite_gen_tbl, vfl) +\n\t\t\t   (MUX_QUEUE_LEVEL * sizeof(struct mux_lite_vfl));\n\n\t\tif (qlt_size > IPC_MEM_MAX_DL_MUX_LITE_BUF_SIZE) {\n\t\t\tdev_err(ipc_mux->dev,\n\t\t\t\t\"can't support. QLT size:%d SKB size: %d\",\n\t\t\t\tqlt_size, IPC_MEM_MAX_DL_MUX_LITE_BUF_SIZE);\n\t\t\treturn -ERANGE;\n\t\t}\n\n\t\tul_adb->qlth_skb = skb;\n\t\tmemset((ul_adb->qlth_skb)->data, 0, qlt_size);\n\t\tskb_put(skb, qlt_size);\n\t\tbreak;\n\t}\n\n\treturn 0;\n}\n\nstatic void ipc_mux_ul_adgh_finish(struct iosm_mux *ipc_mux)\n{\n\tstruct mux_adb *ul_adb = &ipc_mux->ul_adb;\n\tu16 adgh_len;\n\tlong long bytes;\n\tchar *str;\n\n\tif (!ul_adb->dest_skb) {\n\t\tdev_err(ipc_mux->dev, \"no dest skb\");\n\t\treturn;\n\t}\n\n\tadgh_len = le16_to_cpu(ul_adb->adgh->length);\n\tskb_put(ul_adb->dest_skb, adgh_len);\n\tskb_queue_tail(&ipc_mux->channel->ul_list, ul_adb->dest_skb);\n\tul_adb->dest_skb = NULL;\n\n\tif (ipc_mux->ul_flow == MUX_UL_ON_CREDITS) {\n\t\tstruct mux_session *session;\n\n\t\tsession = &ipc_mux->session[ul_adb->adgh->if_id];\n\t\tstr = \"available_credits\";\n\t\tbytes = (long long)session->ul_flow_credits;\n\n\t} else {\n\t\tstr = \"pend_bytes\";\n\t\tbytes = ipc_mux->ul_data_pend_bytes;\n\t\tipc_mux->ul_data_pend_bytes = ipc_mux->ul_data_pend_bytes +\n\t\t\t\t\t      adgh_len;\n\t}\n\n\tdev_dbg(ipc_mux->dev, \"UL ADGH: size=%u, if_id=%d, payload=%d, %s=%lld\",\n\t\tadgh_len, ul_adb->adgh->if_id, ul_adb->payload_size,\n\t\tstr, bytes);\n}\n\nstatic void ipc_mux_ul_encode_adth(struct iosm_mux *ipc_mux,\n\t\t\t\t   struct mux_adb *ul_adb, int *out_offset)\n{\n\tint i, qlt_size, offset = *out_offset;\n\tstruct mux_qlth *p_adb_qlt;\n\tstruct mux_adth_dg *dg;\n\tstruct mux_adth *adth;\n\tu16 adth_dg_size;\n\tu32 *next_tb_id;\n\n\tqlt_size = offsetof(struct mux_qlth, ql) +\n\t\t\tMUX_QUEUE_LEVEL * sizeof(struct mux_qlth_ql);\n\n\tfor (i = 0; i < ipc_mux->nr_sessions; i++) {\n\t\tif (ul_adb->dg_count[i] > 0) {\n\t\t\tadth_dg_size = offsetof(struct mux_adth, dg) +\n\t\t\t\t\tul_adb->dg_count[i] * sizeof(*dg);\n\n\t\t\t*ul_adb->next_table_index = offset;\n\t\t\tadth = (struct mux_adth *)&ul_adb->buf[offset];\n\t\t\tnext_tb_id = (unsigned int *)&adth->next_table_index;\n\t\t\tul_adb->next_table_index = next_tb_id;\n\t\t\toffset += adth_dg_size;\n\t\t\tadth->signature = cpu_to_le32(IOSM_AGGR_MUX_SIG_ADTH);\n\t\t\tadth->if_id = i;\n\t\t\tadth->table_length = cpu_to_le16(adth_dg_size);\n\t\t\tadth_dg_size -= offsetof(struct mux_adth, dg);\n\t\t\tmemcpy(adth->dg, ul_adb->dg[i], adth_dg_size);\n\t\t\tul_adb->if_cnt++;\n\t\t}\n\n\t\tif (ul_adb->qlt_updated[i]) {\n\t\t\t*ul_adb->next_table_index = offset;\n\t\t\tp_adb_qlt = (struct mux_qlth *)&ul_adb->buf[offset];\n\t\t\tul_adb->next_table_index =\n\t\t\t\t(u32 *)&p_adb_qlt->next_table_index;\n\t\t\tmemcpy(p_adb_qlt, ul_adb->pp_qlt[i], qlt_size);\n\t\t\toffset += qlt_size;\n\t\t}\n\t}\n\t*out_offset = offset;\n}\n\n \nvoid ipc_mux_ul_adb_finish(struct iosm_mux *ipc_mux)\n{\n\tbool ul_data_pend = false;\n\tstruct mux_adb *ul_adb;\n\tunsigned long flags;\n\tint offset;\n\n\tul_adb = &ipc_mux->ul_adb;\n\tif (!ul_adb->dest_skb)\n\t\treturn;\n\n\toffset = *ul_adb->next_table_index;\n\tipc_mux_ul_encode_adth(ipc_mux, ul_adb, &offset);\n\tul_adb->adbh->block_length = cpu_to_le32(offset);\n\n\tif (le32_to_cpu(ul_adb->adbh->block_length) > ul_adb->size) {\n\t\tul_adb->dest_skb = NULL;\n\t\treturn;\n\t}\n\n\t*ul_adb->next_table_index = 0;\n\tul_adb->adbh->sequence_nr = cpu_to_le16(ipc_mux->adb_tx_sequence_nr++);\n\tskb_put(ul_adb->dest_skb, le32_to_cpu(ul_adb->adbh->block_length));\n\n\tspin_lock_irqsave(&(&ipc_mux->channel->ul_list)->lock, flags);\n\t__skb_queue_tail(&ipc_mux->channel->ul_list,  ul_adb->dest_skb);\n\tspin_unlock_irqrestore(&(&ipc_mux->channel->ul_list)->lock, flags);\n\n\tul_adb->dest_skb = NULL;\n\t \n\tul_data_pend = ipc_imem_ul_write_td(ipc_mux->imem);\n\n\t \n\tif (ul_data_pend)\n\t\tipc_imem_td_update_timer_start(ipc_mux->imem);\n\n\tipc_mux->acc_adb_size +=  le32_to_cpu(ul_adb->adbh->block_length);\n\tipc_mux->acc_payload_size += ul_adb->payload_size;\n\tipc_mux->ul_data_pend_bytes += ul_adb->payload_size;\n}\n\n \nstatic bool ipc_mux_ul_adb_allocate(struct iosm_mux *ipc_mux,\n\t\t\t\t    struct mux_adb *adb, int *size_needed,\n\t\t\t\t    u32 type)\n{\n\tbool ret_val = false;\n\tint status;\n\n\tif (!adb->dest_skb) {\n\t\t \n\t\tstatus = ipc_mux_ul_skb_alloc(ipc_mux, adb, type);\n\t\tif (status)\n\t\t\t \n\t\t\tret_val = true;  \n\n\t\t \n\t\t*size_needed = 0;\n\t}\n\n\treturn ret_val;\n}\n\n \nstatic void ipc_mux_stop_tx_for_all_sessions(struct iosm_mux *ipc_mux)\n{\n\tstruct mux_session *session;\n\tint idx;\n\n\tfor (idx = 0; idx < IPC_MEM_MUX_IP_SESSION_ENTRIES; idx++) {\n\t\tsession = &ipc_mux->session[idx];\n\n\t\tif (!session->wwan)\n\t\t\tcontinue;\n\n\t\tsession->net_tx_stop = true;\n\t}\n}\n\n \nstatic bool ipc_mux_lite_send_qlt(struct iosm_mux *ipc_mux)\n{\n\tstruct ipc_mem_lite_gen_tbl *qlt;\n\tstruct mux_session *session;\n\tbool qlt_updated = false;\n\tint i;\n\tint qlt_size;\n\n\tif (!ipc_mux->initialized || ipc_mux->state != MUX_S_ACTIVE)\n\t\treturn qlt_updated;\n\n\tqlt_size = offsetof(struct ipc_mem_lite_gen_tbl, vfl) +\n\t\t   MUX_QUEUE_LEVEL * sizeof(struct mux_lite_vfl);\n\n\tfor (i = 0; i < IPC_MEM_MUX_IP_SESSION_ENTRIES; i++) {\n\t\tsession = &ipc_mux->session[i];\n\n\t\tif (!session->wwan || session->flow_ctl_mask)\n\t\t\tcontinue;\n\n\t\tif (ipc_mux_ul_skb_alloc(ipc_mux, &ipc_mux->ul_adb,\n\t\t\t\t\t MUX_SIG_QLTH)) {\n\t\t\tdev_err(ipc_mux->dev,\n\t\t\t\t\"no reserved mem to send QLT of if_id: %d\", i);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tqlt = (struct ipc_mem_lite_gen_tbl *)(ipc_mux->ul_adb.qlth_skb)\n\t\t\t      ->data;\n\t\tqlt->signature = cpu_to_le32(MUX_SIG_QLTH);\n\t\tqlt->length = cpu_to_le16(qlt_size);\n\t\tqlt->if_id = i;\n\t\tqlt->vfl_length = MUX_QUEUE_LEVEL * sizeof(struct mux_lite_vfl);\n\t\tqlt->reserved[0] = 0;\n\t\tqlt->reserved[1] = 0;\n\n\t\tqlt->vfl.nr_of_bytes = cpu_to_le32(session->ul_list.qlen);\n\n\t\t \n\t\tskb_queue_tail(&ipc_mux->channel->ul_list,\n\t\t\t       ipc_mux->ul_adb.qlth_skb);\n\n\t\tqlt_updated = true;\n\t\tipc_mux->ul_adb.qlth_skb = NULL;\n\t}\n\n\tif (qlt_updated)\n\t\t \n\t\t(void)ipc_imem_ul_write_td(ipc_mux->imem);\n\n\treturn qlt_updated;\n}\n\n \nstatic int ipc_mux_ul_bytes_credits_check(struct iosm_mux *ipc_mux,\n\t\t\t\t\t  struct mux_session *session,\n\t\t\t\t\t  struct sk_buff_head *ul_list,\n\t\t\t\t\t  int max_nr_of_pkts)\n{\n\tint pkts_to_send = 0;\n\tstruct sk_buff *skb;\n\tint credits = 0;\n\n\tif (ipc_mux->ul_flow == MUX_UL_ON_CREDITS) {\n\t\tcredits = session->ul_flow_credits;\n\t\tif (credits <= 0) {\n\t\t\tdev_dbg(ipc_mux->dev,\n\t\t\t\t\"FC::if_id[%d] Insuff.Credits/Qlen:%d/%u\",\n\t\t\t\tsession->if_id, session->ul_flow_credits,\n\t\t\t\tsession->ul_list.qlen);  \n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tcredits = IPC_MEM_MUX_UL_FLOWCTRL_HIGH_B -\n\t\t\t  ipc_mux->ul_data_pend_bytes;\n\t\tif (credits <= 0) {\n\t\t\tipc_mux_stop_tx_for_all_sessions(ipc_mux);\n\n\t\t\tdev_dbg(ipc_mux->dev,\n\t\t\t\t\"if_id[%d] encod. fail Bytes: %llu, thresh: %d\",\n\t\t\t\tsession->if_id, ipc_mux->ul_data_pend_bytes,\n\t\t\t\tIPC_MEM_MUX_UL_FLOWCTRL_HIGH_B);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t \n\tskb_queue_walk(ul_list, skb)\n\t{\n\t\tif (!(credits >= skb->len && pkts_to_send < max_nr_of_pkts))\n\t\t\tbreak;\n\t\tcredits -= skb->len;\n\t\tpkts_to_send++;\n\t}\n\n\treturn pkts_to_send;\n}\n\n \nstatic int ipc_mux_ul_adgh_encode(struct iosm_mux *ipc_mux, int session_id,\n\t\t\t\t  struct mux_session *session,\n\t\t\t\t  struct sk_buff_head *ul_list,\n\t\t\t\t  struct mux_adb *adb, int nr_of_pkts)\n{\n\tint offset = sizeof(struct mux_adgh);\n\tint adb_updated = -EINVAL;\n\tstruct sk_buff *src_skb;\n\tint aligned_size = 0;\n\tint nr_of_skb = 0;\n\tu32 pad_len = 0;\n\n\t \n\tnr_of_pkts = ipc_mux_ul_bytes_credits_check(ipc_mux, session, ul_list,\n\t\t\t\t\t\t    nr_of_pkts);\n\n\t \n\tif (nr_of_pkts <= 0)\n\t\treturn 0;\n\n\t \n\tif (session->ul_head_pad_len > IPC_MEM_DL_ETH_OFFSET)\n\t\tpad_len = session->ul_head_pad_len - IPC_MEM_DL_ETH_OFFSET;\n\n\t \n\twhile (nr_of_pkts > 0) {\n\t\t \n\t\tif (ipc_mux_ul_adb_allocate(ipc_mux, adb, &ipc_mux->size_needed,\n\t\t\t\t\t    IOSM_AGGR_MUX_SIG_ADGH)) {\n\t\t\tdev_err(ipc_mux->dev, \"no reserved memory for ADGH\");\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\t \n\t\tsrc_skb = skb_peek(ul_list);\n\t\tif (!src_skb) {\n\t\t\tdev_err(ipc_mux->dev,\n\t\t\t\t\"skb peek return NULL with count : %d\",\n\t\t\t\tnr_of_pkts);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\taligned_size = ALIGN((pad_len + src_skb->len), 4);\n\n\t\tipc_mux->size_needed = sizeof(struct mux_adgh) + aligned_size;\n\n\t\tif (ipc_mux->size_needed > adb->size) {\n\t\t\tdev_dbg(ipc_mux->dev, \"size needed %d, adgh size %d\",\n\t\t\t\tipc_mux->size_needed, adb->size);\n\t\t\t \n\t\t\treturn nr_of_skb ? 1 : 0;\n\t\t}\n\n\t\t \n\t\tmemcpy(adb->buf + offset + pad_len, src_skb->data,\n\t\t       src_skb->len);\n\n\t\tadb->adgh->signature = cpu_to_le32(IOSM_AGGR_MUX_SIG_ADGH);\n\t\tadb->adgh->if_id = session_id;\n\t\tadb->adgh->length =\n\t\t\tcpu_to_le16(sizeof(struct mux_adgh) + pad_len +\n\t\t\t\t    src_skb->len);\n\t\tadb->adgh->service_class = src_skb->priority;\n\t\tadb->adgh->next_count = --nr_of_pkts;\n\t\tadb->dg_cnt_total++;\n\t\tadb->payload_size += src_skb->len;\n\n\t\tif (ipc_mux->ul_flow == MUX_UL_ON_CREDITS)\n\t\t\t \n\t\t\tsession->ul_flow_credits -= src_skb->len;\n\n\t\t \n\t\tsrc_skb = skb_dequeue(ul_list);\n\t\tdev_kfree_skb(src_skb);\n\t\tnr_of_skb++;\n\n\t\tipc_mux_ul_adgh_finish(ipc_mux);\n\t}\n\n\tif (nr_of_skb) {\n\t\t \n\t\tif (ipc_mux->ul_flow == MUX_UL_ON_CREDITS ||\n\t\t    ipc_mux->ul_data_pend_bytes >=\n\t\t\t    IPC_MEM_MUX_UL_FLOWCTRL_LOW_B)\n\t\t\tadb_updated = ipc_mux_lite_send_qlt(ipc_mux);\n\t\telse\n\t\t\tadb_updated = 1;\n\n\t\t \n\t\t(void)ipc_imem_ul_write_td(ipc_mux->imem);\n\t}\n\n\treturn adb_updated;\n}\n\n \nvoid ipc_mux_ul_adb_update_ql(struct iosm_mux *ipc_mux, struct mux_adb *p_adb,\n\t\t\t      int session_id, int qlth_n_ql_size,\n\t\t\t      struct sk_buff_head *ul_list)\n{\n\tint qlevel = ul_list->qlen;\n\tstruct mux_qlth *p_qlt;\n\n\tp_qlt = (struct mux_qlth *)p_adb->pp_qlt[session_id];\n\n\t \n\tif (p_adb->qlt_updated[session_id] == 0) {\n\t\tp_qlt->signature = cpu_to_le32(MUX_SIG_QLTH);\n\t\tp_qlt->if_id = session_id;\n\t\tp_qlt->table_length = cpu_to_le16(qlth_n_ql_size);\n\t\tp_qlt->reserved = 0;\n\t\tp_qlt->reserved2 = 0;\n\t}\n\n\t \n\tp_qlt->ql.nr_of_bytes = cpu_to_le32(qlevel);\n\tp_adb->qlt_updated[session_id] = 1;\n}\n\n \nstatic int mux_ul_dg_update_tbl_index(struct iosm_mux *ipc_mux,\n\t\t\t\t      int session_id,\n\t\t\t\t      struct sk_buff_head *ul_list,\n\t\t\t\t      struct mux_adth_dg *dg,\n\t\t\t\t      int aligned_size,\n\t\t\t\t      u32 qlth_n_ql_size,\n\t\t\t\t      struct mux_adb *adb,\n\t\t\t\t      struct sk_buff *src_skb)\n{\n\tipc_mux_ul_adb_update_ql(ipc_mux, adb, session_id,\n\t\t\t\t qlth_n_ql_size, ul_list);\n\tipc_mux_ul_adb_finish(ipc_mux);\n\tif (ipc_mux_ul_adb_allocate(ipc_mux, adb, &ipc_mux->size_needed,\n\t\t\t\t    IOSM_AGGR_MUX_SIG_ADBH))\n\t\treturn -ENOMEM;\n\n\tipc_mux->size_needed = le32_to_cpu(adb->adbh->block_length);\n\n\tipc_mux->size_needed += offsetof(struct mux_adth, dg);\n\tipc_mux->size_needed += qlth_n_ql_size;\n\tipc_mux->size_needed += sizeof(*dg) + aligned_size;\n\treturn 0;\n}\n\n \nstatic int mux_ul_dg_encode(struct iosm_mux *ipc_mux, struct mux_adb *adb,\n\t\t\t    struct mux_adth_dg *dg,\n\t\t\t    struct sk_buff_head *ul_list,\n\t\t\t    struct sk_buff *src_skb, int session_id,\n\t\t\t    int pkt_to_send, u32 qlth_n_ql_size,\n\t\t\t    int *out_offset, int head_pad_len)\n{\n\tint aligned_size;\n\tint offset = *out_offset;\n\tunsigned long flags;\n\tint nr_of_skb = 0;\n\n\twhile (pkt_to_send > 0) {\n\t\t \n\t\tsrc_skb = skb_peek(ul_list);\n\t\tif (!src_skb) {\n\t\t\tdev_err(ipc_mux->dev,\n\t\t\t\t\"skb peek return NULL with count : %d\",\n\t\t\t\tpkt_to_send);\n\t\t\treturn -1;\n\t\t}\n\t\taligned_size = ALIGN((head_pad_len + src_skb->len), 4);\n\t\tipc_mux->size_needed += sizeof(*dg) + aligned_size;\n\n\t\tif (ipc_mux->size_needed > adb->size ||\n\t\t    ((ipc_mux->size_needed + ipc_mux->ul_data_pend_bytes) >=\n\t\t      IPC_MEM_MUX_UL_FLOWCTRL_HIGH_B)) {\n\t\t\t*adb->next_table_index = offset;\n\t\t\tif (mux_ul_dg_update_tbl_index(ipc_mux, session_id,\n\t\t\t\t\t\t       ul_list, dg,\n\t\t\t\t\t\t       aligned_size,\n\t\t\t\t\t\t       qlth_n_ql_size, adb,\n\t\t\t\t\t\t       src_skb) < 0)\n\t\t\t\treturn -ENOMEM;\n\t\t\tnr_of_skb = 0;\n\t\t\toffset = le32_to_cpu(adb->adbh->block_length);\n\t\t\t \n\t\t\tdg = adb->dg[session_id] + adb->dg_count[session_id];\n\t\t}\n\t\t \n\t\tmemcpy(adb->buf + offset + head_pad_len,\n\t\t       src_skb->data, src_skb->len);\n\t\t \n\t\tdg->datagram_index = cpu_to_le32(offset);\n\t\tdg->datagram_length = cpu_to_le16(src_skb->len + head_pad_len);\n\t\tdg->service_class = (((struct sk_buff *)src_skb)->priority);\n\t\tdg->reserved = 0;\n\t\tadb->dg_cnt_total++;\n\t\tadb->payload_size += le16_to_cpu(dg->datagram_length);\n\t\tdg++;\n\t\tadb->dg_count[session_id]++;\n\t\toffset += aligned_size;\n\t\t \n\t\tspin_lock_irqsave(&ul_list->lock, flags);\n\t\tsrc_skb = __skb_dequeue(ul_list);\n\t\tspin_unlock_irqrestore(&ul_list->lock, flags);\n\n\t\tdev_kfree_skb(src_skb);\n\t\tnr_of_skb++;\n\t\tpkt_to_send--;\n\t}\n\t*out_offset = offset;\n\treturn nr_of_skb;\n}\n\n \nstatic int mux_ul_adb_encode(struct iosm_mux *ipc_mux, int session_id,\n\t\t\t     struct mux_session *session,\n\t\t\t     struct sk_buff_head *ul_list, struct mux_adb *adb,\n\t\t\t     int pkt_to_send)\n{\n\tint adb_updated = -EINVAL;\n\tint head_pad_len, offset;\n\tstruct sk_buff *src_skb = NULL;\n\tstruct mux_adth_dg *dg;\n\tu32 qlth_n_ql_size;\n\n\t \n\tif (ipc_mux->ul_data_pend_bytes >=\n\t\tIPC_MEM_MUX_UL_FLOWCTRL_HIGH_B) {\n\t\tipc_mux_stop_tx_for_all_sessions(ipc_mux);\n\t\treturn adb_updated;\n\t}\n\n\tqlth_n_ql_size = offsetof(struct mux_qlth, ql) +\n\t\t\t MUX_QUEUE_LEVEL * sizeof(struct mux_qlth_ql);\n\thead_pad_len = session->ul_head_pad_len;\n\n\tif (session->ul_head_pad_len > IPC_MEM_DL_ETH_OFFSET)\n\t\thead_pad_len = session->ul_head_pad_len - IPC_MEM_DL_ETH_OFFSET;\n\n\tif (ipc_mux_ul_adb_allocate(ipc_mux, adb, &ipc_mux->size_needed,\n\t\t\t\t    IOSM_AGGR_MUX_SIG_ADBH))\n\t\treturn -ENOMEM;\n\n\toffset = le32_to_cpu(adb->adbh->block_length);\n\n\tif (ipc_mux->size_needed == 0)\n\t\tipc_mux->size_needed = offset;\n\n\t \n\tif (adb->dg_count[session_id] == 0) {\n\t\tipc_mux->size_needed += offsetof(struct mux_adth, dg);\n\t\tipc_mux->size_needed += qlth_n_ql_size;\n\t}\n\n\tdg = adb->dg[session_id] + adb->dg_count[session_id];\n\n\tif (mux_ul_dg_encode(ipc_mux, adb, dg, ul_list, src_skb,\n\t\t\t     session_id, pkt_to_send, qlth_n_ql_size, &offset,\n\t\t\t     head_pad_len) > 0) {\n\t\tadb_updated = 1;\n\t\t*adb->next_table_index = offset;\n\t\tipc_mux_ul_adb_update_ql(ipc_mux, adb, session_id,\n\t\t\t\t\t qlth_n_ql_size, ul_list);\n\t\tadb->adbh->block_length = cpu_to_le32(offset);\n\t}\n\n\treturn adb_updated;\n}\n\nbool ipc_mux_ul_data_encode(struct iosm_mux *ipc_mux)\n{\n\tstruct sk_buff_head *ul_list;\n\tstruct mux_session *session;\n\tint updated = 0;\n\tint session_id;\n\tint dg_n;\n\tint i;\n\n\tif (!ipc_mux || ipc_mux->state != MUX_S_ACTIVE ||\n\t    ipc_mux->adb_prep_ongoing)\n\t\treturn false;\n\n\tipc_mux->adb_prep_ongoing = true;\n\n\tfor (i = 0; i < IPC_MEM_MUX_IP_SESSION_ENTRIES; i++) {\n\t\tsession_id = ipc_mux->rr_next_session;\n\t\tsession = &ipc_mux->session[session_id];\n\n\t\t \n\t\tipc_mux->rr_next_session++;\n\t\tif (ipc_mux->rr_next_session >= IPC_MEM_MUX_IP_SESSION_ENTRIES)\n\t\t\tipc_mux->rr_next_session = 0;\n\n\t\tif (!session->wwan || session->flow_ctl_mask ||\n\t\t    session->net_tx_stop)\n\t\t\tcontinue;\n\n\t\tul_list = &session->ul_list;\n\n\t\t \n\t\tdg_n = skb_queue_len(ul_list);\n\t\tif (dg_n > MUX_MAX_UL_DG_ENTRIES)\n\t\t\tdg_n = MUX_MAX_UL_DG_ENTRIES;\n\n\t\tif (dg_n == 0)\n\t\t\t \n\t\t\tcontinue;\n\t\tif (ipc_mux->protocol == MUX_LITE)\n\t\t\tupdated = ipc_mux_ul_adgh_encode(ipc_mux, session_id,\n\t\t\t\t\t\t\t session, ul_list,\n\t\t\t\t\t\t\t &ipc_mux->ul_adb,\n\t\t\t\t\t\t\t dg_n);\n\t\telse\n\t\t\tupdated = mux_ul_adb_encode(ipc_mux, session_id,\n\t\t\t\t\t\t    session, ul_list,\n\t\t\t\t\t\t    &ipc_mux->ul_adb,\n\t\t\t\t\t\t    dg_n);\n\t}\n\n\tipc_mux->adb_prep_ongoing = false;\n\treturn updated == 1;\n}\n\n \nstatic int ipc_mux_get_payload_from_adb(struct iosm_mux *ipc_mux,\n\t\t\t\t\tstruct mux_adbh *p_adbh)\n{\n\tstruct mux_adth_dg *dg;\n\tstruct mux_adth *adth;\n\tu32 payload_size = 0;\n\tu32 next_table_idx;\n\tint nr_of_dg, i;\n\n\t \n\tnext_table_idx = le32_to_cpu(p_adbh->first_table_index);\n\n\tif (next_table_idx < sizeof(struct mux_adbh)) {\n\t\tdev_err(ipc_mux->dev, \"unexpected empty ADB\");\n\t\treturn payload_size;\n\t}\n\n\twhile (next_table_idx != 0) {\n\t\t \n\t\tadth = (struct mux_adth *)((u8 *)p_adbh + next_table_idx);\n\n\t\tif (adth->signature == cpu_to_le32(IOSM_AGGR_MUX_SIG_ADTH)) {\n\t\t\tnr_of_dg = (le16_to_cpu(adth->table_length) -\n\t\t\t\t\tsizeof(struct mux_adth)) /\n\t\t\t\t\tsizeof(struct mux_adth_dg);\n\n\t\t\tif (nr_of_dg <= 0)\n\t\t\t\treturn payload_size;\n\n\t\t\tdg = adth->dg;\n\n\t\t\tfor (i = 0; i < nr_of_dg; i++, dg++) {\n\t\t\t\tif (le32_to_cpu(dg->datagram_index) <\n\t\t\t\t\tsizeof(struct mux_adbh)) {\n\t\t\t\t\treturn payload_size;\n\t\t\t\t}\n\t\t\t\tpayload_size +=\n\t\t\t\t\tle16_to_cpu(dg->datagram_length);\n\t\t\t}\n\t\t}\n\t\tnext_table_idx = le32_to_cpu(adth->next_table_index);\n\t}\n\n\treturn payload_size;\n}\n\nvoid ipc_mux_ul_encoded_process(struct iosm_mux *ipc_mux, struct sk_buff *skb)\n{\n\tunion mux_type_header hr;\n\tu16 adgh_len;\n\tint payload;\n\n\tif (ipc_mux->protocol == MUX_LITE) {\n\t\thr.adgh = (struct mux_adgh *)skb->data;\n\t\tadgh_len = le16_to_cpu(hr.adgh->length);\n\t\tif (hr.adgh->signature == cpu_to_le32(IOSM_AGGR_MUX_SIG_ADGH) &&\n\t\t    ipc_mux->ul_flow == MUX_UL)\n\t\t\tipc_mux->ul_data_pend_bytes =\n\t\t\t\t\tipc_mux->ul_data_pend_bytes - adgh_len;\n\t} else {\n\t\thr.adbh = (struct mux_adbh *)(skb->data);\n\t\tpayload = ipc_mux_get_payload_from_adb(ipc_mux, hr.adbh);\n\t\tipc_mux->ul_data_pend_bytes -= payload;\n\t}\n\n\tif (ipc_mux->ul_flow == MUX_UL)\n\t\tdev_dbg(ipc_mux->dev, \"ul_data_pend_bytes: %lld\",\n\t\t\tipc_mux->ul_data_pend_bytes);\n\n\t \n\tskb_trim(skb, 0);\n\n\t \n\tskb_queue_tail((&ipc_mux->ul_adb.free_list), skb);\n}\n\n \nstatic int ipc_mux_tq_ul_trigger_encode(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t\tvoid *msg, size_t size)\n{\n\tstruct iosm_mux *ipc_mux = ipc_imem->mux;\n\tbool ul_data_pend = false;\n\n\t \n\tul_data_pend = ipc_mux_ul_data_encode(ipc_mux);\n\tif (ul_data_pend) {\n\t\tif (ipc_mux->protocol == MUX_AGGREGATION)\n\t\t\tipc_imem_adb_timer_start(ipc_mux->imem);\n\n\t\t \n\t\tipc_imem_td_update_timer_start(ipc_mux->imem);\n\t}\n\t \n\tipc_mux->ev_mux_net_transmit_pending = false;\n\n\treturn 0;\n}\n\nint ipc_mux_ul_trigger_encode(struct iosm_mux *ipc_mux, int if_id,\n\t\t\t      struct sk_buff *skb)\n{\n\tstruct mux_session *session = &ipc_mux->session[if_id];\n\tint ret = -EINVAL;\n\n\tif (ipc_mux->channel &&\n\t    ipc_mux->channel->state != IMEM_CHANNEL_ACTIVE) {\n\t\tdev_err(ipc_mux->dev,\n\t\t\t\"channel state is not IMEM_CHANNEL_ACTIVE\");\n\t\tgoto out;\n\t}\n\n\tif (!session->wwan) {\n\t\tdev_err(ipc_mux->dev, \"session net ID is NULL\");\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t \n\tif (skb_queue_len(&session->ul_list) >=\n\t    (session->net_tx_stop ?\n\t\t     IPC_MEM_MUX_UL_SESS_FCON_THRESHOLD :\n\t\t     (IPC_MEM_MUX_UL_SESS_FCON_THRESHOLD *\n\t\t      IPC_MEM_MUX_UL_SESS_FCOFF_THRESHOLD_FACTOR))) {\n\t\tipc_mux_netif_tx_flowctrl(session, session->if_id, true);\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\t \n\tskb_queue_tail(&session->ul_list, skb);\n\n\t \n\tif (!ipc_mux->ev_mux_net_transmit_pending) {\n\t\tipc_mux->ev_mux_net_transmit_pending = true;\n\t\tret = ipc_task_queue_send_task(ipc_mux->imem,\n\t\t\t\t\t       ipc_mux_tq_ul_trigger_encode, 0,\n\t\t\t\t\t       NULL, 0, false);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\tdev_dbg(ipc_mux->dev, \"mux ul if[%d] qlen=%d/%u, len=%d/%d, prio=%d\",\n\t\tif_id, skb_queue_len(&session->ul_list), session->ul_list.qlen,\n\t\tskb->len, skb->truesize, skb->priority);\n\tret = 0;\nout:\n\treturn ret;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}