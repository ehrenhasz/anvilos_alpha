{
  "module_name": "iosm_ipc_imem.c",
  "hash_id": "8833a38f51c9f6e106b0fb50659819fcad57803393f56a2564a61670681d27c0",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wwan/iosm/iosm_ipc_imem.c",
  "human_readable_source": "\n \n\n#include <linux/delay.h>\n\n#include \"iosm_ipc_chnl_cfg.h\"\n#include \"iosm_ipc_devlink.h\"\n#include \"iosm_ipc_flash.h\"\n#include \"iosm_ipc_imem.h\"\n#include \"iosm_ipc_port.h\"\n#include \"iosm_ipc_trace.h\"\n#include \"iosm_ipc_debugfs.h\"\n\n \nstatic int ipc_imem_check_wwan_ips(struct ipc_mem_channel *chnl)\n{\n\tif (chnl)\n\t\treturn chnl->ctype == IPC_CTYPE_WWAN &&\n\t\t       chnl->if_id == IPC_MEM_MUX_IP_CH_IF_ID;\n\treturn false;\n}\n\nstatic int ipc_imem_msg_send_device_sleep(struct iosm_imem *ipc_imem, u32 state)\n{\n\tunion ipc_msg_prep_args prep_args = {\n\t\t.sleep.target = 1,\n\t\t.sleep.state = state,\n\t};\n\n\tipc_imem->device_sleep = state;\n\n\treturn ipc_protocol_tq_msg_send(ipc_imem->ipc_protocol,\n\t\t\t\t\tIPC_MSG_PREP_SLEEP, &prep_args, NULL);\n}\n\nstatic bool ipc_imem_dl_skb_alloc(struct iosm_imem *ipc_imem,\n\t\t\t\t  struct ipc_pipe *pipe)\n{\n\t \n\tif (pipe->nr_of_queued_entries >= pipe->max_nr_of_queued_entries)\n\t\treturn false;\n\n\treturn ipc_protocol_dl_td_prepare(ipc_imem->ipc_protocol, pipe);\n}\n\n \nstatic int ipc_imem_tq_td_alloc_timer(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t      void *msg, size_t size)\n{\n\tbool new_buffers_available = false;\n\tbool retry_allocation = false;\n\tint i;\n\n\tfor (i = 0; i < IPC_MEM_MAX_CHANNELS; i++) {\n\t\tstruct ipc_pipe *pipe = &ipc_imem->channels[i].dl_pipe;\n\n\t\tif (!pipe->is_open || pipe->nr_of_queued_entries > 0)\n\t\t\tcontinue;\n\n\t\twhile (ipc_imem_dl_skb_alloc(ipc_imem, pipe))\n\t\t\tnew_buffers_available = true;\n\n\t\tif (pipe->nr_of_queued_entries == 0)\n\t\t\tretry_allocation = true;\n\t}\n\n\tif (new_buffers_available)\n\t\tipc_protocol_doorbell_trigger(ipc_imem->ipc_protocol,\n\t\t\t\t\t      IPC_HP_DL_PROCESS);\n\n\tif (retry_allocation) {\n\t\tipc_imem->hrtimer_period =\n\t\tktime_set(0, IPC_TD_ALLOC_TIMER_PERIOD_MS * 1000 * 1000ULL);\n\t\tif (!hrtimer_active(&ipc_imem->td_alloc_timer))\n\t\t\thrtimer_start(&ipc_imem->td_alloc_timer,\n\t\t\t\t      ipc_imem->hrtimer_period,\n\t\t\t\t      HRTIMER_MODE_REL);\n\t}\n\treturn 0;\n}\n\nstatic enum hrtimer_restart ipc_imem_td_alloc_timer_cb(struct hrtimer *hr_timer)\n{\n\tstruct iosm_imem *ipc_imem =\n\t\tcontainer_of(hr_timer, struct iosm_imem, td_alloc_timer);\n\t \n\tipc_task_queue_send_task(ipc_imem, ipc_imem_tq_td_alloc_timer, 0, NULL,\n\t\t\t\t 0, false);\n\treturn HRTIMER_NORESTART;\n}\n\n \nstatic int ipc_imem_tq_fast_update_timer_cb(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t\t    void *msg, size_t size)\n{\n\tipc_protocol_doorbell_trigger(ipc_imem->ipc_protocol,\n\t\t\t\t      IPC_HP_FAST_TD_UPD_TMR);\n\n\treturn 0;\n}\n\nstatic enum hrtimer_restart\nipc_imem_fast_update_timer_cb(struct hrtimer *hr_timer)\n{\n\tstruct iosm_imem *ipc_imem =\n\t\tcontainer_of(hr_timer, struct iosm_imem, fast_update_timer);\n\t \n\tipc_task_queue_send_task(ipc_imem, ipc_imem_tq_fast_update_timer_cb, 0,\n\t\t\t\t NULL, 0, false);\n\treturn HRTIMER_NORESTART;\n}\n\nstatic int ipc_imem_tq_adb_timer_cb(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t    void *msg, size_t size)\n{\n\tipc_mux_ul_adb_finish(ipc_imem->mux);\n\treturn 0;\n}\n\nstatic enum hrtimer_restart\nipc_imem_adb_timer_cb(struct hrtimer *hr_timer)\n{\n\tstruct iosm_imem *ipc_imem =\n\t\tcontainer_of(hr_timer, struct iosm_imem, adb_timer);\n\n\tipc_task_queue_send_task(ipc_imem, ipc_imem_tq_adb_timer_cb, 0,\n\t\t\t\t NULL, 0, false);\n\treturn HRTIMER_NORESTART;\n}\n\nstatic int ipc_imem_setup_cp_mux_cap_init(struct iosm_imem *ipc_imem,\n\t\t\t\t\t  struct ipc_mux_config *cfg)\n{\n\tipc_mmio_update_cp_capability(ipc_imem->mmio);\n\n\tif (ipc_imem->mmio->mux_protocol == MUX_UNKNOWN) {\n\t\tdev_err(ipc_imem->dev, \"Failed to get Mux capability.\");\n\t\treturn -EINVAL;\n\t}\n\n\tcfg->protocol = ipc_imem->mmio->mux_protocol;\n\n\tcfg->ul_flow = (ipc_imem->mmio->has_ul_flow_credit == 1) ?\n\t\t\t       MUX_UL_ON_CREDITS :\n\t\t\t       MUX_UL;\n\n\t \n\tcfg->instance_id = IPC_MEM_MUX_IP_CH_IF_ID;\n\n\treturn 0;\n}\n\nvoid ipc_imem_msg_send_feature_set(struct iosm_imem *ipc_imem,\n\t\t\t\t   unsigned int reset_enable, bool atomic_ctx)\n{\n\tunion ipc_msg_prep_args prep_args = { .feature_set.reset_enable =\n\t\t\t\t\t\t      reset_enable };\n\n\tif (atomic_ctx)\n\t\tipc_protocol_tq_msg_send(ipc_imem->ipc_protocol,\n\t\t\t\t\t IPC_MSG_PREP_FEATURE_SET, &prep_args,\n\t\t\t\t\t NULL);\n\telse\n\t\tipc_protocol_msg_send(ipc_imem->ipc_protocol,\n\t\t\t\t      IPC_MSG_PREP_FEATURE_SET, &prep_args);\n}\n\n \nvoid ipc_imem_td_update_timer_start(struct iosm_imem *ipc_imem)\n{\n\t \n\tif (!ipc_imem->enter_runtime || ipc_imem->td_update_timer_suspended) {\n\t\t \n\t\tipc_protocol_doorbell_trigger(ipc_imem->ipc_protocol,\n\t\t\t\t\t      IPC_HP_TD_UPD_TMR_START);\n\t\treturn;\n\t}\n\n\tif (!hrtimer_active(&ipc_imem->tdupdate_timer)) {\n\t\tipc_imem->hrtimer_period =\n\t\tktime_set(0, TD_UPDATE_DEFAULT_TIMEOUT_USEC * 1000ULL);\n\t\tif (!hrtimer_active(&ipc_imem->tdupdate_timer))\n\t\t\thrtimer_start(&ipc_imem->tdupdate_timer,\n\t\t\t\t      ipc_imem->hrtimer_period,\n\t\t\t\t      HRTIMER_MODE_REL);\n\t}\n}\n\nvoid ipc_imem_hrtimer_stop(struct hrtimer *hr_timer)\n{\n\tif (hrtimer_active(hr_timer))\n\t\thrtimer_cancel(hr_timer);\n}\n\n \nvoid ipc_imem_adb_timer_start(struct iosm_imem *ipc_imem)\n{\n\tif (!hrtimer_active(&ipc_imem->adb_timer)) {\n\t\tipc_imem->hrtimer_period =\n\t\t\tktime_set(0, IOSM_AGGR_MUX_ADB_FINISH_TIMEOUT_NSEC);\n\t\thrtimer_start(&ipc_imem->adb_timer,\n\t\t\t      ipc_imem->hrtimer_period,\n\t\t\t      HRTIMER_MODE_REL);\n\t}\n}\n\nbool ipc_imem_ul_write_td(struct iosm_imem *ipc_imem)\n{\n\tstruct ipc_mem_channel *channel;\n\tbool hpda_ctrl_pending = false;\n\tstruct sk_buff_head *ul_list;\n\tbool hpda_pending = false;\n\tstruct ipc_pipe *pipe;\n\tint i;\n\n\t \n\tfor (i = 0; i < ipc_imem->nr_of_channels; i++) {\n\t\tchannel = &ipc_imem->channels[i];\n\n\t\tif (channel->state != IMEM_CHANNEL_ACTIVE)\n\t\t\tcontinue;\n\n\t\tpipe = &channel->ul_pipe;\n\n\t\t \n\t\tul_list = &channel->ul_list;\n\n\t\t \n\t\tif (!ipc_imem_check_wwan_ips(channel)) {\n\t\t\thpda_ctrl_pending |=\n\t\t\t\tipc_protocol_ul_td_send(ipc_imem->ipc_protocol,\n\t\t\t\t\t\t\tpipe, ul_list);\n\t\t} else {\n\t\t\thpda_pending |=\n\t\t\t\tipc_protocol_ul_td_send(ipc_imem->ipc_protocol,\n\t\t\t\t\t\t\tpipe, ul_list);\n\t\t}\n\t}\n\n\t \n\tif (hpda_ctrl_pending) {\n\t\thpda_pending = false;\n\t\tipc_protocol_doorbell_trigger(ipc_imem->ipc_protocol,\n\t\t\t\t\t      IPC_HP_UL_WRITE_TD);\n\t}\n\n\treturn hpda_pending;\n}\n\nvoid ipc_imem_ipc_init_check(struct iosm_imem *ipc_imem)\n{\n\tint timeout = IPC_MODEM_BOOT_TIMEOUT;\n\n\tipc_imem->ipc_requested_state = IPC_MEM_DEVICE_IPC_INIT;\n\n\t \n\tipc_doorbell_fire(ipc_imem->pcie, IPC_DOORBELL_IRQ_IPC,\n\t\t\t  IPC_MEM_DEVICE_IPC_INIT);\n\t \n\tdo {\n\t\tif (ipc_mmio_get_ipc_state(ipc_imem->mmio) ==\n\t\t    ipc_imem->ipc_requested_state) {\n\t\t\t \n\t\t\tipc_mmio_config(ipc_imem->mmio);\n\n\t\t\t \n\t\t\tipc_imem->ipc_requested_state =\n\t\t\t\tIPC_MEM_DEVICE_IPC_RUNNING;\n\t\t\tipc_doorbell_fire(ipc_imem->pcie, IPC_DOORBELL_IRQ_IPC,\n\t\t\t\t\t  IPC_MEM_DEVICE_IPC_RUNNING);\n\n\t\t\treturn;\n\t\t}\n\t\tmsleep(20);\n\t} while (--timeout);\n\n\t \n\tdev_err(ipc_imem->dev, \"%s: ipc_status(%d) ne. IPC_MEM_DEVICE_IPC_INIT\",\n\t\tipc_imem_phase_get_string(ipc_imem->phase),\n\t\tipc_mmio_get_ipc_state(ipc_imem->mmio));\n\n\tipc_uevent_send(ipc_imem->dev, UEVENT_MDM_TIMEOUT);\n}\n\n \nstatic void ipc_imem_dl_skb_process(struct iosm_imem *ipc_imem,\n\t\t\t\t    struct ipc_pipe *pipe, struct sk_buff *skb)\n{\n\tu16 port_id;\n\n\tif (!skb)\n\t\treturn;\n\n\t \n\tswitch (pipe->channel->ctype) {\n\tcase IPC_CTYPE_CTRL:\n\t\tport_id = pipe->channel->channel_id;\n\t\tipc_pcie_addr_unmap(ipc_imem->pcie, IPC_CB(skb)->len,\n\t\t\t\t    IPC_CB(skb)->mapping,\n\t\t\t\t    IPC_CB(skb)->direction);\n\t\tif (port_id == IPC_MEM_CTRL_CHL_ID_7)\n\t\t\tipc_imem_sys_devlink_notify_rx(ipc_imem->ipc_devlink,\n\t\t\t\t\t\t       skb);\n\t\telse if (ipc_is_trace_channel(ipc_imem, port_id))\n\t\t\tipc_trace_port_rx(ipc_imem, skb);\n\t\telse\n\t\t\twwan_port_rx(ipc_imem->ipc_port[port_id]->iosm_port,\n\t\t\t\t     skb);\n\t\tbreak;\n\n\tcase IPC_CTYPE_WWAN:\n\t\tif (pipe->channel->if_id == IPC_MEM_MUX_IP_CH_IF_ID)\n\t\t\tipc_mux_dl_decode(ipc_imem->mux, skb);\n\t\tbreak;\n\tdefault:\n\t\tdev_err(ipc_imem->dev, \"Invalid channel type\");\n\t\tbreak;\n\t}\n}\n\n \nstatic void ipc_imem_dl_pipe_process(struct iosm_imem *ipc_imem,\n\t\t\t\t     struct ipc_pipe *pipe)\n{\n\ts32 cnt = 0, processed_td_cnt = 0;\n\tstruct ipc_mem_channel *channel;\n\tu32 head = 0, tail = 0;\n\tbool processed = false;\n\tstruct sk_buff *skb;\n\n\tchannel = pipe->channel;\n\n\tipc_protocol_get_head_tail_index(ipc_imem->ipc_protocol, pipe, &head,\n\t\t\t\t\t &tail);\n\tif (pipe->old_tail != tail) {\n\t\tif (pipe->old_tail < tail)\n\t\t\tcnt = tail - pipe->old_tail;\n\t\telse\n\t\t\tcnt = pipe->nr_of_entries - pipe->old_tail + tail;\n\t}\n\n\tprocessed_td_cnt = cnt;\n\n\t \n\twhile (cnt--) {\n\t\tskb = ipc_protocol_dl_td_process(ipc_imem->ipc_protocol, pipe);\n\n\t\t \n\t\tipc_imem_dl_skb_process(ipc_imem, pipe, skb);\n\t}\n\n\t \n\twhile (ipc_imem_dl_skb_alloc(ipc_imem, pipe))\n\t\tprocessed = true;\n\n\tif (processed && !ipc_imem_check_wwan_ips(channel)) {\n\t\t \n\t\tipc_protocol_doorbell_trigger(ipc_imem->ipc_protocol,\n\t\t\t\t\t      IPC_HP_DL_PROCESS);\n\t\tprocessed = false;\n\n\t\t \n\t\tipc_imem_hrtimer_stop(&ipc_imem->fast_update_timer);\n\t}\n\n\t \n\tif (processed && (processed_td_cnt == pipe->nr_of_entries - 1)) {\n\t\tipc_imem->hrtimer_period =\n\t\tktime_set(0, FORCE_UPDATE_DEFAULT_TIMEOUT_USEC * 1000ULL);\n\t\thrtimer_start(&ipc_imem->fast_update_timer,\n\t\t\t      ipc_imem->hrtimer_period, HRTIMER_MODE_REL);\n\t}\n\n\tif (ipc_imem->app_notify_dl_pend)\n\t\tcomplete(&ipc_imem->dl_pend_sem);\n}\n\n \nstatic void ipc_imem_ul_pipe_process(struct iosm_imem *ipc_imem,\n\t\t\t\t     struct ipc_pipe *pipe)\n{\n\tstruct ipc_mem_channel *channel;\n\tu32 tail = 0, head = 0;\n\tstruct sk_buff *skb;\n\ts32 cnt = 0;\n\n\tchannel = pipe->channel;\n\n\t \n\tipc_protocol_get_head_tail_index(ipc_imem->ipc_protocol, pipe, &head,\n\t\t\t\t\t &tail);\n\n\tif (pipe->old_tail != tail) {\n\t\tif (pipe->old_tail < tail)\n\t\t\tcnt = tail - pipe->old_tail;\n\t\telse\n\t\t\tcnt = pipe->nr_of_entries - pipe->old_tail + tail;\n\t}\n\n\t \n\twhile (cnt--) {\n\t\tskb = ipc_protocol_ul_td_process(ipc_imem->ipc_protocol, pipe);\n\n\t\tif (!skb)\n\t\t\tcontinue;\n\n\t\t \n\t\tif (IPC_CB(skb)->op_type == UL_USR_OP_BLOCKED)\n\t\t\tcomplete(&channel->ul_sem);\n\n\t\t \n\t\tif (IPC_CB(skb)->op_type == UL_MUX_OP_ADB) {\n\t\t\tif (channel->if_id == IPC_MEM_MUX_IP_CH_IF_ID)\n\t\t\t\tipc_mux_ul_encoded_process(ipc_imem->mux, skb);\n\t\t\telse\n\t\t\t\tdev_err(ipc_imem->dev,\n\t\t\t\t\t\"OP Type is UL_MUX, unknown if_id %d\",\n\t\t\t\t\tchannel->if_id);\n\t\t} else {\n\t\t\tipc_pcie_kfree_skb(ipc_imem->pcie, skb);\n\t\t}\n\t}\n\n\t \n\tif (ipc_imem_check_wwan_ips(pipe->channel))\n\t\tipc_mux_check_n_restart_tx(ipc_imem->mux);\n\n\tif (ipc_imem->app_notify_ul_pend)\n\t\tcomplete(&ipc_imem->ul_pend_sem);\n}\n\n \nstatic void ipc_imem_rom_irq_exec(struct iosm_imem *ipc_imem)\n{\n\tstruct ipc_mem_channel *channel;\n\n\tchannel = ipc_imem->ipc_devlink->devlink_sio.channel;\n\tipc_imem->rom_exit_code = ipc_mmio_get_rom_exit_code(ipc_imem->mmio);\n\tcomplete(&channel->ul_sem);\n}\n\n \nstatic int ipc_imem_tq_td_update_timer_cb(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t\t  void *msg, size_t size)\n{\n\tipc_protocol_doorbell_trigger(ipc_imem->ipc_protocol,\n\t\t\t\t      IPC_HP_TD_UPD_TMR);\n\treturn 0;\n}\n\n \nstatic void ipc_imem_slp_control_exec(struct iosm_imem *ipc_imem)\n{\n\t     \n\tif (ipc_protocol_pm_dev_sleep_handle(ipc_imem->ipc_protocol) &&\n\t    hrtimer_active(&ipc_imem->tdupdate_timer)) {\n\t\t \n\t\tipc_imem_tq_td_update_timer_cb(ipc_imem, 0, NULL, 0);\n\t\t \n\t\tipc_imem_hrtimer_stop(&ipc_imem->tdupdate_timer);\n\t\t \n\t\tipc_imem_hrtimer_stop(&ipc_imem->fast_update_timer);\n\t}\n}\n\n \nstatic int ipc_imem_tq_startup_timer_cb(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t\tvoid *msg, size_t size)\n{\n\t \n\tif (ipc_imem_phase_update(ipc_imem) != IPC_P_RUN)\n\t\treturn -EIO;\n\n\tif (ipc_mmio_get_ipc_state(ipc_imem->mmio) ==\n\t    IPC_MEM_DEVICE_IPC_UNINIT) {\n\t\tipc_imem->ipc_requested_state = IPC_MEM_DEVICE_IPC_INIT;\n\n\t\tipc_doorbell_fire(ipc_imem->pcie, IPC_DOORBELL_IRQ_IPC,\n\t\t\t\t  IPC_MEM_DEVICE_IPC_INIT);\n\n\t\tipc_imem->hrtimer_period = ktime_set(0, 100 * 1000UL * 1000ULL);\n\t\t \n\t\tif (!hrtimer_active(&ipc_imem->startup_timer))\n\t\t\thrtimer_start(&ipc_imem->startup_timer,\n\t\t\t\t      ipc_imem->hrtimer_period,\n\t\t\t\t      HRTIMER_MODE_REL);\n\t} else if (ipc_mmio_get_ipc_state(ipc_imem->mmio) ==\n\t\t   IPC_MEM_DEVICE_IPC_INIT) {\n\t\t \n\t\tipc_imem_hrtimer_stop(&ipc_imem->startup_timer);\n\n\t\t \n\t\tipc_mmio_config(ipc_imem->mmio);\n\t\tipc_imem->ipc_requested_state = IPC_MEM_DEVICE_IPC_RUNNING;\n\t\tipc_doorbell_fire(ipc_imem->pcie, IPC_DOORBELL_IRQ_IPC,\n\t\t\t\t  IPC_MEM_DEVICE_IPC_RUNNING);\n\t}\n\n\treturn 0;\n}\n\nstatic enum hrtimer_restart ipc_imem_startup_timer_cb(struct hrtimer *hr_timer)\n{\n\tenum hrtimer_restart result = HRTIMER_NORESTART;\n\tstruct iosm_imem *ipc_imem =\n\t\tcontainer_of(hr_timer, struct iosm_imem, startup_timer);\n\n\tif (ktime_to_ns(ipc_imem->hrtimer_period)) {\n\t\thrtimer_forward_now(&ipc_imem->startup_timer,\n\t\t\t\t    ipc_imem->hrtimer_period);\n\t\tresult = HRTIMER_RESTART;\n\t}\n\n\tipc_task_queue_send_task(ipc_imem, ipc_imem_tq_startup_timer_cb, 0,\n\t\t\t\t NULL, 0, false);\n\treturn result;\n}\n\n \nstatic enum ipc_mem_exec_stage\nipc_imem_get_exec_stage_buffered(struct iosm_imem *ipc_imem)\n{\n\treturn (ipc_imem->phase == IPC_P_RUN &&\n\t\tipc_imem->ipc_status == IPC_MEM_DEVICE_IPC_RUNNING) ?\n\t\t       ipc_protocol_get_ap_exec_stage(ipc_imem->ipc_protocol) :\n\t\t       ipc_mmio_get_exec_stage(ipc_imem->mmio);\n}\n\n \nstatic int ipc_imem_send_mdm_rdy_cb(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t    void *msg, size_t size)\n{\n\tenum ipc_mem_exec_stage exec_stage =\n\t\tipc_imem_get_exec_stage_buffered(ipc_imem);\n\n\tif (exec_stage == IPC_MEM_EXEC_STAGE_RUN)\n\t\tipc_uevent_send(ipc_imem->dev, UEVENT_MDM_READY);\n\n\treturn 0;\n}\n\n \nstatic void ipc_imem_run_state_worker(struct work_struct *instance)\n{\n\tstruct ipc_chnl_cfg chnl_cfg_port = { 0 };\n\tstruct ipc_mux_config mux_cfg;\n\tstruct iosm_imem *ipc_imem;\n\tu8 ctrl_chl_idx = 0;\n\tint ret;\n\n\tipc_imem = container_of(instance, struct iosm_imem, run_state_worker);\n\n\tif (ipc_imem->phase != IPC_P_RUN) {\n\t\tdev_err(ipc_imem->dev,\n\t\t\t\"Modem link down. Exit run state worker.\");\n\t\tgoto err_out;\n\t}\n\n\tif (test_and_clear_bit(IOSM_DEVLINK_INIT, &ipc_imem->flag))\n\t\tipc_devlink_deinit(ipc_imem->ipc_devlink);\n\n\tret = ipc_imem_setup_cp_mux_cap_init(ipc_imem, &mux_cfg);\n\tif (ret < 0)\n\t\tgoto err_out;\n\n\tipc_imem->mux = ipc_mux_init(&mux_cfg, ipc_imem);\n\tif (!ipc_imem->mux)\n\t\tgoto err_out;\n\n\tret = ipc_imem_wwan_channel_init(ipc_imem, mux_cfg.protocol);\n\tif (ret < 0)\n\t\tgoto err_ipc_mux_deinit;\n\n\tipc_imem->mux->wwan = ipc_imem->wwan;\n\n\twhile (ctrl_chl_idx < IPC_MEM_MAX_CHANNELS) {\n\t\tif (!ipc_chnl_cfg_get(&chnl_cfg_port, ctrl_chl_idx)) {\n\t\t\tipc_imem->ipc_port[ctrl_chl_idx] = NULL;\n\n\t\t\tif (ipc_imem->pcie->pci->device == INTEL_CP_DEVICE_7560_ID &&\n\t\t\t    chnl_cfg_port.wwan_port_type == WWAN_PORT_XMMRPC) {\n\t\t\t\tctrl_chl_idx++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (ipc_imem->pcie->pci->device == INTEL_CP_DEVICE_7360_ID &&\n\t\t\t    chnl_cfg_port.wwan_port_type == WWAN_PORT_MBIM) {\n\t\t\t\tctrl_chl_idx++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (chnl_cfg_port.wwan_port_type != WWAN_PORT_UNKNOWN) {\n\t\t\t\tipc_imem_channel_init(ipc_imem, IPC_CTYPE_CTRL,\n\t\t\t\t\t\t      chnl_cfg_port,\n\t\t\t\t\t\t      IRQ_MOD_OFF);\n\t\t\t\tipc_imem->ipc_port[ctrl_chl_idx] =\n\t\t\t\t\tipc_port_init(ipc_imem, chnl_cfg_port);\n\t\t\t}\n\t\t}\n\t\tctrl_chl_idx++;\n\t}\n\n\tipc_debugfs_init(ipc_imem);\n\n\tipc_task_queue_send_task(ipc_imem, ipc_imem_send_mdm_rdy_cb, 0, NULL, 0,\n\t\t\t\t false);\n\n\t \n\tsmp_mb__before_atomic();\n\n\tset_bit(FULLY_FUNCTIONAL, &ipc_imem->flag);\n\n\t \n\tsmp_mb__after_atomic();\n\n\treturn;\n\nerr_ipc_mux_deinit:\n\tipc_mux_deinit(ipc_imem->mux);\nerr_out:\n\tipc_uevent_send(ipc_imem->dev, UEVENT_CD_READY_LINK_DOWN);\n}\n\nstatic void ipc_imem_handle_irq(struct iosm_imem *ipc_imem, int irq)\n{\n\tenum ipc_mem_device_ipc_state curr_ipc_status;\n\tenum ipc_phase old_phase, phase;\n\tbool retry_allocation = false;\n\tbool ul_pending = false;\n\tint i;\n\n\tif (irq != IMEM_IRQ_DONT_CARE)\n\t\tipc_imem->ev_irq_pending[irq] = false;\n\n\t \n\told_phase = ipc_imem->phase;\n\n\tif (old_phase == IPC_P_OFF_REQ) {\n\t\tdev_dbg(ipc_imem->dev,\n\t\t\t\"[%s]: Ignoring MSI. Deinit sequence in progress!\",\n\t\t\tipc_imem_phase_get_string(old_phase));\n\t\treturn;\n\t}\n\n\t \n\tphase = ipc_imem_phase_update(ipc_imem);\n\n\tswitch (phase) {\n\tcase IPC_P_RUN:\n\t\tif (!ipc_imem->enter_runtime) {\n\t\t\t \n\t\t\tipc_imem->enter_runtime = 1;\n\n\t\t\t \n\t\t\tipc_imem_msg_send_device_sleep(ipc_imem,\n\t\t\t\t\t\t       ipc_imem->device_sleep);\n\n\t\t\tipc_imem_msg_send_feature_set(ipc_imem,\n\t\t\t\t\t\t      IPC_MEM_INBAND_CRASH_SIG,\n\t\t\t\t\t\t  true);\n\t\t}\n\n\t\tcurr_ipc_status =\n\t\t\tipc_protocol_get_ipc_status(ipc_imem->ipc_protocol);\n\n\t\t \n\t\tif (ipc_imem->ipc_status != curr_ipc_status) {\n\t\t\tipc_imem->ipc_status = curr_ipc_status;\n\n\t\t\tif (ipc_imem->ipc_status ==\n\t\t\t    IPC_MEM_DEVICE_IPC_RUNNING) {\n\t\t\t\tschedule_work(&ipc_imem->run_state_worker);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tipc_imem_slp_control_exec(ipc_imem);\n\t\tbreak;  \n\n\t\t \n\tcase IPC_P_OFF:\n\tcase IPC_P_OFF_REQ:\n\t\tdev_err(ipc_imem->dev, \"confused phase %s\",\n\t\t\tipc_imem_phase_get_string(phase));\n\t\treturn;\n\n\tcase IPC_P_PSI:\n\t\tif (old_phase != IPC_P_ROM)\n\t\t\tbreak;\n\n\t\tfallthrough;\n\t\t \n\n\tcase IPC_P_ROM:\n\t\t \n\t\tipc_imem_rom_irq_exec(ipc_imem);\n\t\treturn;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\t \n\tipc_protocol_msg_process(ipc_imem, irq);\n\n\t \n\tfor (i = 0; i < IPC_MEM_MAX_CHANNELS; i++) {\n\t\tstruct ipc_pipe *ul_pipe = &ipc_imem->channels[i].ul_pipe;\n\t\tstruct ipc_pipe *dl_pipe = &ipc_imem->channels[i].dl_pipe;\n\n\t\tif (dl_pipe->is_open &&\n\t\t    (irq == IMEM_IRQ_DONT_CARE || irq == dl_pipe->irq)) {\n\t\t\tipc_imem_dl_pipe_process(ipc_imem, dl_pipe);\n\n\t\t\tif (dl_pipe->nr_of_queued_entries == 0)\n\t\t\t\tretry_allocation = true;\n\t\t}\n\n\t\tif (ul_pipe->is_open)\n\t\t\tipc_imem_ul_pipe_process(ipc_imem, ul_pipe);\n\t}\n\n\t \n\tif (ipc_mux_ul_data_encode(ipc_imem->mux)) {\n\t\tipc_imem_td_update_timer_start(ipc_imem);\n\t\tif (ipc_imem->mux->protocol == MUX_AGGREGATION)\n\t\t\tipc_imem_adb_timer_start(ipc_imem);\n\t}\n\n\t \n\tul_pending |= ipc_imem_ul_write_td(ipc_imem);\n\n\t \n\tif (ul_pending) {\n\t\tipc_imem->hrtimer_period =\n\t\tktime_set(0, TD_UPDATE_DEFAULT_TIMEOUT_USEC * 1000ULL);\n\t\tif (!hrtimer_active(&ipc_imem->tdupdate_timer))\n\t\t\thrtimer_start(&ipc_imem->tdupdate_timer,\n\t\t\t\t      ipc_imem->hrtimer_period,\n\t\t\t\t      HRTIMER_MODE_REL);\n\t}\n\n\t \n\tif ((phase == IPC_P_PSI || phase == IPC_P_EBL) &&\n\t    ipc_imem->ipc_requested_state == IPC_MEM_DEVICE_IPC_RUNNING &&\n\t    ipc_mmio_get_ipc_state(ipc_imem->mmio) ==\n\t\t\t\t\t\tIPC_MEM_DEVICE_IPC_RUNNING) {\n\t\tcomplete(&ipc_imem->ipc_devlink->devlink_sio.channel->ul_sem);\n\t}\n\n\t \n\tipc_imem->ipc_requested_state = IPC_MEM_DEVICE_IPC_DONT_CARE;\n\n\tif (retry_allocation) {\n\t\tipc_imem->hrtimer_period =\n\t\tktime_set(0, IPC_TD_ALLOC_TIMER_PERIOD_MS * 1000 * 1000ULL);\n\t\tif (!hrtimer_active(&ipc_imem->td_alloc_timer))\n\t\t\thrtimer_start(&ipc_imem->td_alloc_timer,\n\t\t\t\t      ipc_imem->hrtimer_period,\n\t\t\t\t      HRTIMER_MODE_REL);\n\t}\n}\n\n \nstatic int ipc_imem_tq_irq_cb(struct iosm_imem *ipc_imem, int arg, void *msg,\n\t\t\t      size_t size)\n{\n\tipc_imem_handle_irq(ipc_imem, arg);\n\n\treturn 0;\n}\n\nvoid ipc_imem_ul_send(struct iosm_imem *ipc_imem)\n{\n\t \n\tif (ipc_imem_ul_write_td(ipc_imem))\n\t\tipc_imem_td_update_timer_start(ipc_imem);\n}\n\n \nstatic enum ipc_phase ipc_imem_phase_update_check(struct iosm_imem *ipc_imem,\n\t\t\t\t\t\t  enum ipc_mem_exec_stage stage)\n{\n\tswitch (stage) {\n\tcase IPC_MEM_EXEC_STAGE_BOOT:\n\t\tif (ipc_imem->phase != IPC_P_ROM) {\n\t\t\t \n\t\t\tipc_uevent_send(ipc_imem->dev, UEVENT_ROM_READY);\n\t\t}\n\n\t\tipc_imem->phase = IPC_P_ROM;\n\t\tbreak;\n\n\tcase IPC_MEM_EXEC_STAGE_PSI:\n\t\tipc_imem->phase = IPC_P_PSI;\n\t\tbreak;\n\n\tcase IPC_MEM_EXEC_STAGE_EBL:\n\t\tipc_imem->phase = IPC_P_EBL;\n\t\tbreak;\n\n\tcase IPC_MEM_EXEC_STAGE_RUN:\n\t\tif (ipc_imem->phase != IPC_P_RUN &&\n\t\t    ipc_imem->ipc_status == IPC_MEM_DEVICE_IPC_RUNNING) {\n\t\t\tipc_uevent_send(ipc_imem->dev, UEVENT_MDM_READY);\n\t\t}\n\t\tipc_imem->phase = IPC_P_RUN;\n\t\tbreak;\n\n\tcase IPC_MEM_EXEC_STAGE_CRASH:\n\t\tif (ipc_imem->phase != IPC_P_CRASH)\n\t\t\tipc_uevent_send(ipc_imem->dev, UEVENT_CRASH);\n\n\t\tipc_imem->phase = IPC_P_CRASH;\n\t\tbreak;\n\n\tcase IPC_MEM_EXEC_STAGE_CD_READY:\n\t\tif (ipc_imem->phase != IPC_P_CD_READY)\n\t\t\tipc_uevent_send(ipc_imem->dev, UEVENT_CD_READY);\n\t\tipc_imem->phase = IPC_P_CD_READY;\n\t\tbreak;\n\n\tdefault:\n\t\t \n\t\tipc_uevent_send(ipc_imem->dev, UEVENT_CD_READY_LINK_DOWN);\n\t\tbreak;\n\t}\n\n\treturn ipc_imem->phase;\n}\n\n \nstatic bool ipc_imem_pipe_open(struct iosm_imem *ipc_imem,\n\t\t\t       struct ipc_pipe *pipe)\n{\n\tunion ipc_msg_prep_args prep_args = {\n\t\t.pipe_open.pipe = pipe,\n\t};\n\n\tif (ipc_protocol_msg_send(ipc_imem->ipc_protocol,\n\t\t\t\t  IPC_MSG_PREP_PIPE_OPEN, &prep_args) == 0)\n\t\tpipe->is_open = true;\n\n\treturn pipe->is_open;\n}\n\n \nstatic int ipc_imem_tq_pipe_td_alloc(struct iosm_imem *ipc_imem, int arg,\n\t\t\t\t     void *msg, size_t size)\n{\n\tstruct ipc_pipe *dl_pipe = msg;\n\tbool processed = false;\n\tint i;\n\n\tfor (i = 0; i < dl_pipe->nr_of_entries - 1; i++)\n\t\tprocessed |= ipc_imem_dl_skb_alloc(ipc_imem, dl_pipe);\n\n\t \n\tif (processed)\n\t\tipc_protocol_doorbell_trigger(ipc_imem->ipc_protocol, arg);\n\n\treturn 0;\n}\n\nstatic enum hrtimer_restart\nipc_imem_td_update_timer_cb(struct hrtimer *hr_timer)\n{\n\tstruct iosm_imem *ipc_imem =\n\t\tcontainer_of(hr_timer, struct iosm_imem, tdupdate_timer);\n\n\tipc_task_queue_send_task(ipc_imem, ipc_imem_tq_td_update_timer_cb, 0,\n\t\t\t\t NULL, 0, false);\n\treturn HRTIMER_NORESTART;\n}\n\n \nenum ipc_phase ipc_imem_phase_update(struct iosm_imem *ipc_imem)\n{\n\tenum ipc_mem_exec_stage exec_stage =\n\t\t\t\tipc_imem_get_exec_stage_buffered(ipc_imem);\n\t \n\treturn ipc_imem->phase == IPC_P_OFF_REQ ?\n\t\t       ipc_imem->phase :\n\t\t       ipc_imem_phase_update_check(ipc_imem, exec_stage);\n}\n\nconst char *ipc_imem_phase_get_string(enum ipc_phase phase)\n{\n\tswitch (phase) {\n\tcase IPC_P_RUN:\n\t\treturn \"A-RUN\";\n\n\tcase IPC_P_OFF:\n\t\treturn \"A-OFF\";\n\n\tcase IPC_P_ROM:\n\t\treturn \"A-ROM\";\n\n\tcase IPC_P_PSI:\n\t\treturn \"A-PSI\";\n\n\tcase IPC_P_EBL:\n\t\treturn \"A-EBL\";\n\n\tcase IPC_P_CRASH:\n\t\treturn \"A-CRASH\";\n\n\tcase IPC_P_CD_READY:\n\t\treturn \"A-CD_READY\";\n\n\tcase IPC_P_OFF_REQ:\n\t\treturn \"A-OFF_REQ\";\n\n\tdefault:\n\t\treturn \"A-???\";\n\t}\n}\n\nvoid ipc_imem_pipe_close(struct iosm_imem *ipc_imem, struct ipc_pipe *pipe)\n{\n\tunion ipc_msg_prep_args prep_args = { .pipe_close.pipe = pipe };\n\n\tpipe->is_open = false;\n\tipc_protocol_msg_send(ipc_imem->ipc_protocol, IPC_MSG_PREP_PIPE_CLOSE,\n\t\t\t      &prep_args);\n\n\tipc_imem_pipe_cleanup(ipc_imem, pipe);\n}\n\nvoid ipc_imem_channel_close(struct iosm_imem *ipc_imem, int channel_id)\n{\n\tstruct ipc_mem_channel *channel;\n\n\tif (channel_id < 0 || channel_id >= ipc_imem->nr_of_channels) {\n\t\tdev_err(ipc_imem->dev, \"invalid channel id %d\", channel_id);\n\t\treturn;\n\t}\n\n\tchannel = &ipc_imem->channels[channel_id];\n\n\tif (channel->state == IMEM_CHANNEL_FREE) {\n\t\tdev_err(ipc_imem->dev, \"ch[%d]: invalid channel state %d\",\n\t\t\tchannel_id, channel->state);\n\t\treturn;\n\t}\n\n\t \n\tif (channel->state == IMEM_CHANNEL_RESERVED)\n\t\t \n\t\tgoto channel_free;\n\n\tif (ipc_imem->phase == IPC_P_RUN) {\n\t\tipc_imem_pipe_close(ipc_imem, &channel->ul_pipe);\n\t\tipc_imem_pipe_close(ipc_imem, &channel->dl_pipe);\n\t}\n\n\tipc_imem_pipe_cleanup(ipc_imem, &channel->ul_pipe);\n\tipc_imem_pipe_cleanup(ipc_imem, &channel->dl_pipe);\n\nchannel_free:\n\tipc_imem_channel_free(channel);\n}\n\nstruct ipc_mem_channel *ipc_imem_channel_open(struct iosm_imem *ipc_imem,\n\t\t\t\t\t      int channel_id, u32 db_id)\n{\n\tstruct ipc_mem_channel *channel;\n\n\tif (channel_id < 0 || channel_id >= IPC_MEM_MAX_CHANNELS) {\n\t\tdev_err(ipc_imem->dev, \"invalid channel ID: %d\", channel_id);\n\t\treturn NULL;\n\t}\n\n\tchannel = &ipc_imem->channels[channel_id];\n\n\tchannel->state = IMEM_CHANNEL_ACTIVE;\n\n\tif (!ipc_imem_pipe_open(ipc_imem, &channel->ul_pipe))\n\t\tgoto ul_pipe_err;\n\n\tif (!ipc_imem_pipe_open(ipc_imem, &channel->dl_pipe))\n\t\tgoto dl_pipe_err;\n\n\t \n\tif (ipc_task_queue_send_task(ipc_imem, ipc_imem_tq_pipe_td_alloc, db_id,\n\t\t\t\t     &channel->dl_pipe, 0, false)) {\n\t\tdev_err(ipc_imem->dev, \"td allocation failed : %d\", channel_id);\n\t\tgoto task_failed;\n\t}\n\n\t \n\treturn channel;\ntask_failed:\n\tipc_imem_pipe_close(ipc_imem, &channel->dl_pipe);\ndl_pipe_err:\n\tipc_imem_pipe_close(ipc_imem, &channel->ul_pipe);\nul_pipe_err:\n\tipc_imem_channel_free(channel);\n\treturn NULL;\n}\n\nvoid ipc_imem_pm_suspend(struct iosm_imem *ipc_imem)\n{\n\tipc_protocol_suspend(ipc_imem->ipc_protocol);\n}\n\nvoid ipc_imem_pm_s2idle_sleep(struct iosm_imem *ipc_imem, bool sleep)\n{\n\tipc_protocol_s2idle_sleep(ipc_imem->ipc_protocol, sleep);\n}\n\nvoid ipc_imem_pm_resume(struct iosm_imem *ipc_imem)\n{\n\tenum ipc_mem_exec_stage stage;\n\n\tif (ipc_protocol_resume(ipc_imem->ipc_protocol)) {\n\t\tstage = ipc_mmio_get_exec_stage(ipc_imem->mmio);\n\t\tipc_imem_phase_update_check(ipc_imem, stage);\n\t}\n}\n\nvoid ipc_imem_channel_free(struct ipc_mem_channel *channel)\n{\n\t \n\tchannel->state = IMEM_CHANNEL_FREE;\n}\n\nint ipc_imem_channel_alloc(struct iosm_imem *ipc_imem, int index,\n\t\t\t   enum ipc_ctype ctype)\n{\n\tstruct ipc_mem_channel *channel;\n\tint i;\n\n\t \n\tfor (i = 0; i < ipc_imem->nr_of_channels; i++) {\n\t\tchannel = &ipc_imem->channels[i];\n\t\tif (channel->ctype == ctype && channel->index == index)\n\t\t\tbreak;\n\t}\n\n\tif (i >= ipc_imem->nr_of_channels) {\n\t\tdev_dbg(ipc_imem->dev,\n\t\t\t\"no channel definition for index=%d ctype=%d\", index,\n\t\t\tctype);\n\t\treturn -ECHRNG;\n\t}\n\n\tif (ipc_imem->channels[i].state != IMEM_CHANNEL_FREE) {\n\t\tdev_dbg(ipc_imem->dev, \"channel is in use\");\n\t\treturn -EBUSY;\n\t}\n\n\tif (channel->ctype == IPC_CTYPE_WWAN &&\n\t    index == IPC_MEM_MUX_IP_CH_IF_ID)\n\t\tchannel->if_id = index;\n\n\tchannel->channel_id = index;\n\tchannel->state = IMEM_CHANNEL_RESERVED;\n\n\treturn i;\n}\n\nvoid ipc_imem_channel_init(struct iosm_imem *ipc_imem, enum ipc_ctype ctype,\n\t\t\t   struct ipc_chnl_cfg chnl_cfg, u32 irq_moderation)\n{\n\tstruct ipc_mem_channel *channel;\n\n\tif (chnl_cfg.ul_pipe >= IPC_MEM_MAX_PIPES ||\n\t    chnl_cfg.dl_pipe >= IPC_MEM_MAX_PIPES) {\n\t\tdev_err(ipc_imem->dev, \"invalid pipe: ul_pipe=%d, dl_pipe=%d\",\n\t\t\tchnl_cfg.ul_pipe, chnl_cfg.dl_pipe);\n\t\treturn;\n\t}\n\n\tif (ipc_imem->nr_of_channels >= IPC_MEM_MAX_CHANNELS) {\n\t\tdev_err(ipc_imem->dev, \"too many channels\");\n\t\treturn;\n\t}\n\n\tchannel = &ipc_imem->channels[ipc_imem->nr_of_channels];\n\tchannel->channel_id = ipc_imem->nr_of_channels;\n\tchannel->ctype = ctype;\n\tchannel->index = chnl_cfg.id;\n\tchannel->net_err_count = 0;\n\tchannel->state = IMEM_CHANNEL_FREE;\n\tipc_imem->nr_of_channels++;\n\n\tipc_imem_channel_update(ipc_imem, channel->channel_id, chnl_cfg,\n\t\t\t\tIRQ_MOD_OFF);\n\n\tskb_queue_head_init(&channel->ul_list);\n\n\tinit_completion(&channel->ul_sem);\n}\n\nvoid ipc_imem_channel_update(struct iosm_imem *ipc_imem, int id,\n\t\t\t     struct ipc_chnl_cfg chnl_cfg, u32 irq_moderation)\n{\n\tstruct ipc_mem_channel *channel;\n\n\tif (id < 0 || id >= ipc_imem->nr_of_channels) {\n\t\tdev_err(ipc_imem->dev, \"invalid channel id %d\", id);\n\t\treturn;\n\t}\n\n\tchannel = &ipc_imem->channels[id];\n\n\tif (channel->state != IMEM_CHANNEL_FREE &&\n\t    channel->state != IMEM_CHANNEL_RESERVED) {\n\t\tdev_err(ipc_imem->dev, \"invalid channel state %d\",\n\t\t\tchannel->state);\n\t\treturn;\n\t}\n\n\tchannel->ul_pipe.nr_of_entries = chnl_cfg.ul_nr_of_entries;\n\tchannel->ul_pipe.pipe_nr = chnl_cfg.ul_pipe;\n\tchannel->ul_pipe.is_open = false;\n\tchannel->ul_pipe.irq = IPC_UL_PIPE_IRQ_VECTOR;\n\tchannel->ul_pipe.channel = channel;\n\tchannel->ul_pipe.dir = IPC_MEM_DIR_UL;\n\tchannel->ul_pipe.accumulation_backoff = chnl_cfg.accumulation_backoff;\n\tchannel->ul_pipe.irq_moderation = irq_moderation;\n\tchannel->ul_pipe.buf_size = 0;\n\n\tchannel->dl_pipe.nr_of_entries = chnl_cfg.dl_nr_of_entries;\n\tchannel->dl_pipe.pipe_nr = chnl_cfg.dl_pipe;\n\tchannel->dl_pipe.is_open = false;\n\tchannel->dl_pipe.irq = IPC_DL_PIPE_IRQ_VECTOR;\n\tchannel->dl_pipe.channel = channel;\n\tchannel->dl_pipe.dir = IPC_MEM_DIR_DL;\n\tchannel->dl_pipe.accumulation_backoff = chnl_cfg.accumulation_backoff;\n\tchannel->dl_pipe.irq_moderation = irq_moderation;\n\tchannel->dl_pipe.buf_size = chnl_cfg.dl_buf_size;\n}\n\nstatic void ipc_imem_channel_reset(struct iosm_imem *ipc_imem)\n{\n\tint i;\n\n\tfor (i = 0; i < ipc_imem->nr_of_channels; i++) {\n\t\tstruct ipc_mem_channel *channel;\n\n\t\tchannel = &ipc_imem->channels[i];\n\n\t\tipc_imem_pipe_cleanup(ipc_imem, &channel->dl_pipe);\n\t\tipc_imem_pipe_cleanup(ipc_imem, &channel->ul_pipe);\n\n\t\tipc_imem_channel_free(channel);\n\t}\n}\n\nvoid ipc_imem_pipe_cleanup(struct iosm_imem *ipc_imem, struct ipc_pipe *pipe)\n{\n\tstruct sk_buff *skb;\n\n\t \n\tpipe->is_open = false;\n\n\t \n\twhile ((skb = skb_dequeue(&pipe->channel->ul_list)))\n\t\tipc_pcie_kfree_skb(ipc_imem->pcie, skb);\n\n\tipc_protocol_pipe_cleanup(ipc_imem->ipc_protocol, pipe);\n}\n\n \nstatic void ipc_imem_device_ipc_uninit(struct iosm_imem *ipc_imem)\n{\n\tint timeout = IPC_MODEM_UNINIT_TIMEOUT_MS;\n\tenum ipc_mem_device_ipc_state ipc_state;\n\n\t \n\tif (ipc_pcie_check_data_link_active(ipc_imem->pcie)) {\n\t\t \n\t\tipc_doorbell_fire(ipc_imem->pcie, IPC_DOORBELL_IRQ_IPC,\n\t\t\t\t  IPC_MEM_DEVICE_IPC_UNINIT);\n\t\tipc_state = ipc_mmio_get_ipc_state(ipc_imem->mmio);\n\n\t\t \n\t\twhile ((ipc_state <= IPC_MEM_DEVICE_IPC_DONT_CARE) &&\n\t\t       (ipc_state != IPC_MEM_DEVICE_IPC_UNINIT) &&\n\t\t       (timeout > 0)) {\n\t\t\tusleep_range(1000, 1250);\n\t\t\ttimeout--;\n\t\t\tipc_state = ipc_mmio_get_ipc_state(ipc_imem->mmio);\n\t\t}\n\t}\n}\n\nvoid ipc_imem_cleanup(struct iosm_imem *ipc_imem)\n{\n\tipc_imem->phase = IPC_P_OFF_REQ;\n\n\t \n\tipc_uevent_send(ipc_imem->dev, UEVENT_MDM_NOT_READY);\n\n\thrtimer_cancel(&ipc_imem->td_alloc_timer);\n\thrtimer_cancel(&ipc_imem->tdupdate_timer);\n\thrtimer_cancel(&ipc_imem->fast_update_timer);\n\thrtimer_cancel(&ipc_imem->startup_timer);\n\n\t \n\tcancel_work_sync(&ipc_imem->run_state_worker);\n\n\tif (test_and_clear_bit(FULLY_FUNCTIONAL, &ipc_imem->flag)) {\n\t\tipc_mux_deinit(ipc_imem->mux);\n\t\tipc_debugfs_deinit(ipc_imem);\n\t\tipc_wwan_deinit(ipc_imem->wwan);\n\t\tipc_port_deinit(ipc_imem->ipc_port);\n\t}\n\n\tif (test_and_clear_bit(IOSM_DEVLINK_INIT, &ipc_imem->flag))\n\t\tipc_devlink_deinit(ipc_imem->ipc_devlink);\n\n\tipc_imem_device_ipc_uninit(ipc_imem);\n\tipc_imem_channel_reset(ipc_imem);\n\n\tipc_protocol_deinit(ipc_imem->ipc_protocol);\n\tipc_task_deinit(ipc_imem->ipc_task);\n\n\tkfree(ipc_imem->ipc_task);\n\tkfree(ipc_imem->mmio);\n\n\tipc_imem->phase = IPC_P_OFF;\n}\n\n \nstatic int ipc_imem_config(struct iosm_imem *ipc_imem)\n{\n\tenum ipc_phase phase;\n\n\t \n\tinit_completion(&ipc_imem->ul_pend_sem);\n\n\tinit_completion(&ipc_imem->dl_pend_sem);\n\n\t \n\tipc_imem->ipc_status = IPC_MEM_DEVICE_IPC_UNINIT;\n\tipc_imem->enter_runtime = 0;\n\n\tphase = ipc_imem_phase_update(ipc_imem);\n\n\t \n\tswitch (phase) {\n\tcase IPC_P_ROM:\n\t\tipc_imem->hrtimer_period = ktime_set(0, 1000 * 1000 * 1000ULL);\n\t\t \n\t\tif (!hrtimer_active(&ipc_imem->startup_timer))\n\t\t\thrtimer_start(&ipc_imem->startup_timer,\n\t\t\t\t      ipc_imem->hrtimer_period,\n\t\t\t\t      HRTIMER_MODE_REL);\n\t\treturn 0;\n\n\tcase IPC_P_PSI:\n\tcase IPC_P_EBL:\n\tcase IPC_P_RUN:\n\t\t \n\t\tipc_imem->ipc_requested_state = IPC_MEM_DEVICE_IPC_UNINIT;\n\n\t\t \n\t\tif (ipc_imem->ipc_requested_state ==\n\t\t    ipc_mmio_get_ipc_state(ipc_imem->mmio)) {\n\t\t\tipc_imem_ipc_init_check(ipc_imem);\n\n\t\t\treturn 0;\n\t\t}\n\t\tdev_err(ipc_imem->dev,\n\t\t\t\"ipc_status(%d) != IPC_MEM_DEVICE_IPC_UNINIT\",\n\t\t\tipc_mmio_get_ipc_state(ipc_imem->mmio));\n\t\tbreak;\n\tcase IPC_P_CRASH:\n\tcase IPC_P_CD_READY:\n\t\tdev_dbg(ipc_imem->dev,\n\t\t\t\"Modem is in phase %d, reset Modem to collect CD\",\n\t\t\tphase);\n\t\treturn 0;\n\tdefault:\n\t\tdev_err(ipc_imem->dev, \"unexpected operation phase %d\", phase);\n\t\tbreak;\n\t}\n\n\tcomplete(&ipc_imem->dl_pend_sem);\n\tcomplete(&ipc_imem->ul_pend_sem);\n\tipc_imem->phase = IPC_P_OFF;\n\treturn -EIO;\n}\n\n \nstruct iosm_imem *ipc_imem_init(struct iosm_pcie *pcie, unsigned int device_id,\n\t\t\t\tvoid __iomem *mmio, struct device *dev)\n{\n\tstruct iosm_imem *ipc_imem = kzalloc(sizeof(*pcie->imem), GFP_KERNEL);\n\tenum ipc_mem_exec_stage stage;\n\n\tif (!ipc_imem)\n\t\treturn NULL;\n\n\t \n\tipc_imem->pcie = pcie;\n\tipc_imem->dev = dev;\n\n\tipc_imem->pci_device_id = device_id;\n\n\tipc_imem->cp_version = 0;\n\tipc_imem->device_sleep = IPC_HOST_SLEEP_ENTER_SLEEP;\n\n\t \n\tipc_imem->nr_of_channels = 0;\n\n\t \n\tipc_imem->mmio = ipc_mmio_init(mmio, ipc_imem->dev);\n\tif (!ipc_imem->mmio) {\n\t\tdev_err(ipc_imem->dev, \"failed to initialize mmio region\");\n\t\tgoto mmio_init_fail;\n\t}\n\n\tipc_imem->ipc_task = kzalloc(sizeof(*ipc_imem->ipc_task),\n\t\t\t\t     GFP_KERNEL);\n\n\t \n\tif (!ipc_imem->ipc_task)\n\t\tgoto ipc_task_fail;\n\n\tif (ipc_task_init(ipc_imem->ipc_task))\n\t\tgoto ipc_task_init_fail;\n\n\tipc_imem->ipc_task->dev = ipc_imem->dev;\n\n\tINIT_WORK(&ipc_imem->run_state_worker, ipc_imem_run_state_worker);\n\n\tipc_imem->ipc_protocol = ipc_protocol_init(ipc_imem);\n\n\tif (!ipc_imem->ipc_protocol)\n\t\tgoto protocol_init_fail;\n\n\t \n\tipc_imem->phase = IPC_P_OFF;\n\n\thrtimer_init(&ipc_imem->startup_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL);\n\tipc_imem->startup_timer.function = ipc_imem_startup_timer_cb;\n\n\thrtimer_init(&ipc_imem->tdupdate_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL);\n\tipc_imem->tdupdate_timer.function = ipc_imem_td_update_timer_cb;\n\n\thrtimer_init(&ipc_imem->fast_update_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL);\n\tipc_imem->fast_update_timer.function = ipc_imem_fast_update_timer_cb;\n\n\thrtimer_init(&ipc_imem->td_alloc_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL);\n\tipc_imem->td_alloc_timer.function = ipc_imem_td_alloc_timer_cb;\n\n\thrtimer_init(&ipc_imem->adb_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tipc_imem->adb_timer.function = ipc_imem_adb_timer_cb;\n\n\tif (ipc_imem_config(ipc_imem)) {\n\t\tdev_err(ipc_imem->dev, \"failed to initialize the imem\");\n\t\tgoto imem_config_fail;\n\t}\n\n\tstage = ipc_mmio_get_exec_stage(ipc_imem->mmio);\n\tif (stage == IPC_MEM_EXEC_STAGE_BOOT) {\n\t\t \n\t\tipc_imem->ipc_devlink = ipc_devlink_init(ipc_imem);\n\t\tif (!ipc_imem->ipc_devlink) {\n\t\t\tdev_err(ipc_imem->dev, \"Devlink register failed\");\n\t\t\tgoto imem_config_fail;\n\t\t}\n\n\t\tif (ipc_flash_link_establish(ipc_imem))\n\t\t\tgoto devlink_channel_fail;\n\n\t\tset_bit(IOSM_DEVLINK_INIT, &ipc_imem->flag);\n\t}\n\treturn ipc_imem;\ndevlink_channel_fail:\n\tipc_devlink_deinit(ipc_imem->ipc_devlink);\nimem_config_fail:\n\thrtimer_cancel(&ipc_imem->td_alloc_timer);\n\thrtimer_cancel(&ipc_imem->fast_update_timer);\n\thrtimer_cancel(&ipc_imem->tdupdate_timer);\n\thrtimer_cancel(&ipc_imem->startup_timer);\nprotocol_init_fail:\n\tcancel_work_sync(&ipc_imem->run_state_worker);\n\tipc_task_deinit(ipc_imem->ipc_task);\nipc_task_init_fail:\n\tkfree(ipc_imem->ipc_task);\nipc_task_fail:\n\tkfree(ipc_imem->mmio);\nmmio_init_fail:\n\tkfree(ipc_imem);\n\treturn NULL;\n}\n\nvoid ipc_imem_irq_process(struct iosm_imem *ipc_imem, int irq)\n{\n\t \n\tif (ipc_imem && !ipc_imem->ev_irq_pending[irq]) {\n\t\tipc_imem->ev_irq_pending[irq] = true;\n\t\tipc_task_queue_send_task(ipc_imem, ipc_imem_tq_irq_cb, irq,\n\t\t\t\t\t NULL, 0, false);\n\t}\n}\n\nvoid ipc_imem_td_update_timer_suspend(struct iosm_imem *ipc_imem, bool suspend)\n{\n\tipc_imem->td_update_timer_suspended = suspend;\n}\n\n \nstatic int ipc_imem_devlink_trigger_chip_info_cb(struct iosm_imem *ipc_imem,\n\t\t\t\t\t\t int arg, void *msg,\n\t\t\t\t\t\t size_t msgsize)\n{\n\tenum ipc_mem_exec_stage stage;\n\tstruct sk_buff *skb;\n\tint rc = -EINVAL;\n\tsize_t size;\n\n\t \n\tstage = ipc_mmio_get_exec_stage(ipc_imem->mmio);\n\tif (stage != IPC_MEM_EXEC_STAGE_BOOT) {\n\t\tdev_err(ipc_imem->dev,\n\t\t\t\"Execution_stage: expected BOOT, received = %X\", stage);\n\t\tgoto trigger_chip_info_fail;\n\t}\n\t \n\tsize = ipc_imem->mmio->chip_info_size;\n\tif (size > IOSM_CHIP_INFO_SIZE_MAX)\n\t\tgoto trigger_chip_info_fail;\n\n\tskb = ipc_pcie_alloc_local_skb(ipc_imem->pcie, GFP_ATOMIC, size);\n\tif (!skb) {\n\t\tdev_err(ipc_imem->dev, \"exhausted skbuf kernel DL memory\");\n\t\trc = -ENOMEM;\n\t\tgoto trigger_chip_info_fail;\n\t}\n\t \n\tipc_mmio_copy_chip_info(ipc_imem->mmio, skb_put(skb, size), size);\n\t \n\tdev_dbg(ipc_imem->dev, \"execution_stage[%X] eq. BOOT\", stage);\n\tipc_imem->phase = ipc_imem_phase_update(ipc_imem);\n\tipc_imem_sys_devlink_notify_rx(ipc_imem->ipc_devlink, skb);\n\trc = 0;\ntrigger_chip_info_fail:\n\treturn rc;\n}\n\nint ipc_imem_devlink_trigger_chip_info(struct iosm_imem *ipc_imem)\n{\n\treturn ipc_task_queue_send_task(ipc_imem,\n\t\t\t\t\tipc_imem_devlink_trigger_chip_info_cb,\n\t\t\t\t\t0, NULL, 0, true);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}