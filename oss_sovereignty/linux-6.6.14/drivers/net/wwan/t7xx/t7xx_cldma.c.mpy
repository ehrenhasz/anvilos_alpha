{
  "module_name": "t7xx_cldma.c",
  "hash_id": "478ad5fe8757eebaa1e3fbaeef72038baef1ec7a1a6219a55b1e661e3220d244",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wwan/t7xx/t7xx_cldma.c",
  "human_readable_source": "\n \n\n#include <linux/bits.h>\n#include <linux/delay.h>\n#include <linux/io.h>\n#include <linux/io-64-nonatomic-lo-hi.h>\n#include <linux/types.h>\n\n#include \"t7xx_cldma.h\"\n\n#define ADDR_SIZE\t8\n\nvoid t7xx_cldma_clear_ip_busy(struct t7xx_cldma_hw *hw_info)\n{\n\tu32 val;\n\n\tval = ioread32(hw_info->ap_pdn_base + REG_CLDMA_IP_BUSY);\n\tval |= IP_BUSY_WAKEUP;\n\tiowrite32(val, hw_info->ap_pdn_base + REG_CLDMA_IP_BUSY);\n}\n\n \nvoid t7xx_cldma_hw_restore(struct t7xx_cldma_hw *hw_info)\n{\n\tu32 ul_cfg;\n\n\tul_cfg = ioread32(hw_info->ap_pdn_base + REG_CLDMA_UL_CFG);\n\tul_cfg &= ~UL_CFG_BIT_MODE_MASK;\n\n\tif (hw_info->hw_mode == MODE_BIT_64)\n\t\tul_cfg |= UL_CFG_BIT_MODE_64;\n\telse if (hw_info->hw_mode == MODE_BIT_40)\n\t\tul_cfg |= UL_CFG_BIT_MODE_40;\n\telse if (hw_info->hw_mode == MODE_BIT_36)\n\t\tul_cfg |= UL_CFG_BIT_MODE_36;\n\n\tiowrite32(ul_cfg, hw_info->ap_pdn_base + REG_CLDMA_UL_CFG);\n\t \n\tiowrite32(UL_MEM_CHECK_DIS, hw_info->ap_pdn_base + REG_CLDMA_UL_MEM);\n\tiowrite32(DL_MEM_CHECK_DIS, hw_info->ap_pdn_base + REG_CLDMA_DL_MEM);\n}\n\nvoid t7xx_cldma_hw_start_queue(struct t7xx_cldma_hw *hw_info, unsigned int qno,\n\t\t\t       enum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\tu32 val;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_pdn_base + REG_CLDMA_DL_START_CMD :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_UL_START_CMD;\n\tval = qno == CLDMA_ALL_Q ? CLDMA_ALL_Q : BIT(qno);\n\tiowrite32(val, reg);\n}\n\nvoid t7xx_cldma_hw_start(struct t7xx_cldma_hw *hw_info)\n{\n\t \n\tiowrite32(TXRX_STATUS_BITMASK, hw_info->ap_pdn_base + REG_CLDMA_L2TIMCR0);\n\tiowrite32(TXRX_STATUS_BITMASK, hw_info->ap_ao_base + REG_CLDMA_L2RIMCR0);\n\t \n\tiowrite32(EMPTY_STATUS_BITMASK, hw_info->ap_pdn_base + REG_CLDMA_L2TIMCR0);\n\tiowrite32(EMPTY_STATUS_BITMASK, hw_info->ap_ao_base + REG_CLDMA_L2RIMCR0);\n}\n\nvoid t7xx_cldma_hw_reset(void __iomem *ao_base)\n{\n\tu32 val;\n\n\tval = ioread32(ao_base + REG_INFRA_RST2_SET);\n\tval |= RST2_PMIC_SW_RST_SET;\n\tiowrite32(val, ao_base + REG_INFRA_RST2_SET);\n\tval = ioread32(ao_base + REG_INFRA_RST4_SET);\n\tval |= RST4_CLDMA1_SW_RST_SET;\n\tiowrite32(val, ao_base + REG_INFRA_RST4_SET);\n\tudelay(1);\n\n\tval = ioread32(ao_base + REG_INFRA_RST4_CLR);\n\tval |= RST4_CLDMA1_SW_RST_CLR;\n\tiowrite32(val, ao_base + REG_INFRA_RST4_CLR);\n\tval = ioread32(ao_base + REG_INFRA_RST2_CLR);\n\tval |= RST2_PMIC_SW_RST_CLR;\n\tiowrite32(val, ao_base + REG_INFRA_RST2_CLR);\n}\n\nbool t7xx_cldma_tx_addr_is_set(struct t7xx_cldma_hw *hw_info, unsigned int qno)\n{\n\tu32 offset = REG_CLDMA_UL_START_ADDRL_0 + qno * ADDR_SIZE;\n\n\treturn ioread64(hw_info->ap_pdn_base + offset);\n}\n\nvoid t7xx_cldma_hw_set_start_addr(struct t7xx_cldma_hw *hw_info, unsigned int qno, u64 address,\n\t\t\t\t  enum mtk_txrx tx_rx)\n{\n\tu32 offset = qno * ADDR_SIZE;\n\tvoid __iomem *reg;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_ao_base + REG_CLDMA_DL_START_ADDRL_0 :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_UL_START_ADDRL_0;\n\tiowrite64(address, reg + offset);\n}\n\nvoid t7xx_cldma_hw_resume_queue(struct t7xx_cldma_hw *hw_info, unsigned int qno,\n\t\t\t\tenum mtk_txrx tx_rx)\n{\n\tvoid __iomem *base = hw_info->ap_pdn_base;\n\n\tif (tx_rx == MTK_RX)\n\t\tiowrite32(BIT(qno), base + REG_CLDMA_DL_RESUME_CMD);\n\telse\n\t\tiowrite32(BIT(qno), base + REG_CLDMA_UL_RESUME_CMD);\n}\n\nunsigned int t7xx_cldma_hw_queue_status(struct t7xx_cldma_hw *hw_info, unsigned int qno,\n\t\t\t\t\tenum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\tu32 mask, val;\n\n\tmask = qno == CLDMA_ALL_Q ? CLDMA_ALL_Q : BIT(qno);\n\treg = tx_rx == MTK_RX ? hw_info->ap_ao_base + REG_CLDMA_DL_STATUS :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_UL_STATUS;\n\tval = ioread32(reg);\n\n\treturn val & mask;\n}\n\nvoid t7xx_cldma_hw_tx_done(struct t7xx_cldma_hw *hw_info, unsigned int bitmask)\n{\n\tunsigned int ch_id;\n\n\tch_id = ioread32(hw_info->ap_pdn_base + REG_CLDMA_L2TISAR0);\n\tch_id &= bitmask;\n\t \n\tiowrite32(ch_id, hw_info->ap_pdn_base + REG_CLDMA_L2TISAR0);\n\tioread32(hw_info->ap_pdn_base + REG_CLDMA_L2TISAR0);\n}\n\nvoid t7xx_cldma_hw_rx_done(struct t7xx_cldma_hw *hw_info, unsigned int bitmask)\n{\n\tunsigned int ch_id;\n\n\tch_id = ioread32(hw_info->ap_pdn_base + REG_CLDMA_L2RISAR0);\n\tch_id &= bitmask;\n\t \n\tiowrite32(ch_id, hw_info->ap_pdn_base + REG_CLDMA_L2RISAR0);\n\tioread32(hw_info->ap_pdn_base + REG_CLDMA_L2RISAR0);\n}\n\nunsigned int t7xx_cldma_hw_int_status(struct t7xx_cldma_hw *hw_info, unsigned int bitmask,\n\t\t\t\t      enum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\tu32 val;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_pdn_base + REG_CLDMA_L2RISAR0 :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_L2TISAR0;\n\tval = ioread32(reg);\n\treturn val & bitmask;\n}\n\nvoid t7xx_cldma_hw_irq_dis_txrx(struct t7xx_cldma_hw *hw_info, unsigned int qno,\n\t\t\t\tenum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\tu32 val;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_ao_base + REG_CLDMA_L2RIMSR0 :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_L2TIMSR0;\n\tval = qno == CLDMA_ALL_Q ? CLDMA_ALL_Q : BIT(qno);\n\tiowrite32(val, reg);\n}\n\nvoid t7xx_cldma_hw_irq_dis_eq(struct t7xx_cldma_hw *hw_info, unsigned int qno, enum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\tu32 val;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_ao_base + REG_CLDMA_L2RIMSR0 :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_L2TIMSR0;\n\tval = qno == CLDMA_ALL_Q ? CLDMA_ALL_Q : BIT(qno);\n\tiowrite32(val << EQ_STA_BIT_OFFSET, reg);\n}\n\nvoid t7xx_cldma_hw_irq_en_txrx(struct t7xx_cldma_hw *hw_info, unsigned int qno,\n\t\t\t       enum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\tu32 val;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_ao_base + REG_CLDMA_L2RIMCR0 :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_L2TIMCR0;\n\tval = qno == CLDMA_ALL_Q ? CLDMA_ALL_Q : BIT(qno);\n\tiowrite32(val, reg);\n}\n\nvoid t7xx_cldma_hw_irq_en_eq(struct t7xx_cldma_hw *hw_info, unsigned int qno, enum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\tu32 val;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_ao_base + REG_CLDMA_L2RIMCR0 :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_L2TIMCR0;\n\tval = qno == CLDMA_ALL_Q ? CLDMA_ALL_Q : BIT(qno);\n\tiowrite32(val << EQ_STA_BIT_OFFSET, reg);\n}\n\n \nvoid t7xx_cldma_hw_init(struct t7xx_cldma_hw *hw_info)\n{\n\tu32 ul_cfg, dl_cfg;\n\n\tul_cfg = ioread32(hw_info->ap_pdn_base + REG_CLDMA_UL_CFG);\n\tdl_cfg = ioread32(hw_info->ap_ao_base + REG_CLDMA_DL_CFG);\n\t \n\tul_cfg &= ~UL_CFG_BIT_MODE_MASK;\n\tdl_cfg &= ~DL_CFG_BIT_MODE_MASK;\n\n\tif (hw_info->hw_mode == MODE_BIT_64) {\n\t\tul_cfg |= UL_CFG_BIT_MODE_64;\n\t\tdl_cfg |= DL_CFG_BIT_MODE_64;\n\t} else if (hw_info->hw_mode == MODE_BIT_40) {\n\t\tul_cfg |= UL_CFG_BIT_MODE_40;\n\t\tdl_cfg |= DL_CFG_BIT_MODE_40;\n\t} else if (hw_info->hw_mode == MODE_BIT_36) {\n\t\tul_cfg |= UL_CFG_BIT_MODE_36;\n\t\tdl_cfg |= DL_CFG_BIT_MODE_36;\n\t}\n\n\tiowrite32(ul_cfg, hw_info->ap_pdn_base + REG_CLDMA_UL_CFG);\n\tdl_cfg |= DL_CFG_UP_HW_LAST;\n\tiowrite32(dl_cfg, hw_info->ap_ao_base + REG_CLDMA_DL_CFG);\n\tiowrite32(0, hw_info->ap_ao_base + REG_CLDMA_INT_MASK);\n\tiowrite32(BUSY_MASK_MD, hw_info->ap_ao_base + REG_CLDMA_BUSY_MASK);\n\tiowrite32(UL_MEM_CHECK_DIS, hw_info->ap_pdn_base + REG_CLDMA_UL_MEM);\n\tiowrite32(DL_MEM_CHECK_DIS, hw_info->ap_pdn_base + REG_CLDMA_DL_MEM);\n}\n\nvoid t7xx_cldma_hw_stop_all_qs(struct t7xx_cldma_hw *hw_info, enum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_pdn_base + REG_CLDMA_DL_STOP_CMD :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_UL_STOP_CMD;\n\tiowrite32(CLDMA_ALL_Q, reg);\n}\n\nvoid t7xx_cldma_hw_stop(struct t7xx_cldma_hw *hw_info, enum mtk_txrx tx_rx)\n{\n\tvoid __iomem *reg;\n\n\treg = tx_rx == MTK_RX ? hw_info->ap_ao_base + REG_CLDMA_L2RIMSR0 :\n\t\t\t\thw_info->ap_pdn_base + REG_CLDMA_L2TIMSR0;\n\tiowrite32(TXRX_STATUS_BITMASK, reg);\n\tiowrite32(EMPTY_STATUS_BITMASK, reg);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}