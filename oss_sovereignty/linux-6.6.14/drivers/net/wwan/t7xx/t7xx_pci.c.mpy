{
  "module_name": "t7xx_pci.c",
  "hash_id": "0465e8e823def72738d866432b64089da4fd6f9607063ab8aebec6372825baa8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wwan/t7xx/t7xx_pci.c",
  "human_readable_source": "\n \n\n#include <linux/atomic.h>\n#include <linux/bits.h>\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/dma-mapping.h>\n#include <linux/gfp.h>\n#include <linux/interrupt.h>\n#include <linux/io.h>\n#include <linux/iopoll.h>\n#include <linux/jiffies.h>\n#include <linux/list.h>\n#include <linux/module.h>\n#include <linux/mutex.h>\n#include <linux/pci.h>\n#include <linux/pm.h>\n#include <linux/pm_runtime.h>\n#include <linux/pm_wakeup.h>\n#include <linux/spinlock.h>\n\n#include \"t7xx_mhccif.h\"\n#include \"t7xx_modem_ops.h\"\n#include \"t7xx_pci.h\"\n#include \"t7xx_pcie_mac.h\"\n#include \"t7xx_reg.h\"\n#include \"t7xx_state_monitor.h\"\n\n#define T7XX_PCI_IREG_BASE\t\t0\n#define T7XX_PCI_EREG_BASE\t\t2\n\n#define T7XX_INIT_TIMEOUT\t\t20\n#define PM_SLEEP_DIS_TIMEOUT_MS\t\t20\n#define PM_ACK_TIMEOUT_MS\t\t1500\n#define PM_AUTOSUSPEND_MS\t\t20000\n#define PM_RESOURCE_POLL_TIMEOUT_US\t10000\n#define PM_RESOURCE_POLL_STEP_US\t100\n\nenum t7xx_pm_state {\n\tMTK_PM_EXCEPTION,\n\tMTK_PM_INIT,\t\t \n\tMTK_PM_SUSPENDED,\n\tMTK_PM_RESUMED,\n};\n\nstatic void t7xx_dev_set_sleep_capability(struct t7xx_pci_dev *t7xx_dev, bool enable)\n{\n\tvoid __iomem *ctrl_reg = IREG_BASE(t7xx_dev) + T7XX_PCIE_MISC_CTRL;\n\tu32 value;\n\n\tvalue = ioread32(ctrl_reg);\n\n\tif (enable)\n\t\tvalue &= ~T7XX_PCIE_MISC_MAC_SLEEP_DIS;\n\telse\n\t\tvalue |= T7XX_PCIE_MISC_MAC_SLEEP_DIS;\n\n\tiowrite32(value, ctrl_reg);\n}\n\nstatic int t7xx_wait_pm_config(struct t7xx_pci_dev *t7xx_dev)\n{\n\tint ret, val;\n\n\tret = read_poll_timeout(ioread32, val,\n\t\t\t\t(val & T7XX_PCIE_RESOURCE_STS_MSK) == T7XX_PCIE_RESOURCE_STS_MSK,\n\t\t\t\tPM_RESOURCE_POLL_STEP_US, PM_RESOURCE_POLL_TIMEOUT_US, true,\n\t\t\t\tIREG_BASE(t7xx_dev) + T7XX_PCIE_RESOURCE_STATUS);\n\tif (ret == -ETIMEDOUT)\n\t\tdev_err(&t7xx_dev->pdev->dev, \"PM configuration timed out\\n\");\n\n\treturn ret;\n}\n\nstatic int t7xx_pci_pm_init(struct t7xx_pci_dev *t7xx_dev)\n{\n\tstruct pci_dev *pdev = t7xx_dev->pdev;\n\n\tINIT_LIST_HEAD(&t7xx_dev->md_pm_entities);\n\tmutex_init(&t7xx_dev->md_pm_entity_mtx);\n\tspin_lock_init(&t7xx_dev->md_pm_lock);\n\tinit_completion(&t7xx_dev->sleep_lock_acquire);\n\tinit_completion(&t7xx_dev->pm_sr_ack);\n\tinit_completion(&t7xx_dev->init_done);\n\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_INIT);\n\n\tdevice_init_wakeup(&pdev->dev, true);\n\tdev_pm_set_driver_flags(&pdev->dev, pdev->dev.power.driver_flags |\n\t\t\t\tDPM_FLAG_NO_DIRECT_COMPLETE);\n\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + DISABLE_ASPM_LOWPWR);\n\tpm_runtime_set_autosuspend_delay(&pdev->dev, PM_AUTOSUSPEND_MS);\n\tpm_runtime_use_autosuspend(&pdev->dev);\n\n\treturn t7xx_wait_pm_config(t7xx_dev);\n}\n\nvoid t7xx_pci_pm_init_late(struct t7xx_pci_dev *t7xx_dev)\n{\n\t \n\tt7xx_mhccif_mask_clr(t7xx_dev,\n\t\t\t     D2H_INT_DS_LOCK_ACK |\n\t\t\t     D2H_INT_SUSPEND_ACK |\n\t\t\t     D2H_INT_RESUME_ACK |\n\t\t\t     D2H_INT_SUSPEND_ACK_AP |\n\t\t\t     D2H_INT_RESUME_ACK_AP);\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + ENABLE_ASPM_LOWPWR);\n\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_RESUMED);\n\n\tpm_runtime_mark_last_busy(&t7xx_dev->pdev->dev);\n\tpm_runtime_allow(&t7xx_dev->pdev->dev);\n\tpm_runtime_put_noidle(&t7xx_dev->pdev->dev);\n\tcomplete_all(&t7xx_dev->init_done);\n}\n\nstatic int t7xx_pci_pm_reinit(struct t7xx_pci_dev *t7xx_dev)\n{\n\t \n\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_INIT);\n\n\tpm_runtime_get_noresume(&t7xx_dev->pdev->dev);\n\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + DISABLE_ASPM_LOWPWR);\n\treturn t7xx_wait_pm_config(t7xx_dev);\n}\n\nvoid t7xx_pci_pm_exp_detected(struct t7xx_pci_dev *t7xx_dev)\n{\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + DISABLE_ASPM_LOWPWR);\n\tt7xx_wait_pm_config(t7xx_dev);\n\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_EXCEPTION);\n}\n\nint t7xx_pci_pm_entity_register(struct t7xx_pci_dev *t7xx_dev, struct md_pm_entity *pm_entity)\n{\n\tstruct md_pm_entity *entity;\n\n\tmutex_lock(&t7xx_dev->md_pm_entity_mtx);\n\tlist_for_each_entry(entity, &t7xx_dev->md_pm_entities, entity) {\n\t\tif (entity->id == pm_entity->id) {\n\t\t\tmutex_unlock(&t7xx_dev->md_pm_entity_mtx);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tlist_add_tail(&pm_entity->entity, &t7xx_dev->md_pm_entities);\n\tmutex_unlock(&t7xx_dev->md_pm_entity_mtx);\n\treturn 0;\n}\n\nint t7xx_pci_pm_entity_unregister(struct t7xx_pci_dev *t7xx_dev, struct md_pm_entity *pm_entity)\n{\n\tstruct md_pm_entity *entity, *tmp_entity;\n\n\tmutex_lock(&t7xx_dev->md_pm_entity_mtx);\n\tlist_for_each_entry_safe(entity, tmp_entity, &t7xx_dev->md_pm_entities, entity) {\n\t\tif (entity->id == pm_entity->id) {\n\t\t\tlist_del(&pm_entity->entity);\n\t\t\tmutex_unlock(&t7xx_dev->md_pm_entity_mtx);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tmutex_unlock(&t7xx_dev->md_pm_entity_mtx);\n\n\treturn -ENXIO;\n}\n\nint t7xx_pci_sleep_disable_complete(struct t7xx_pci_dev *t7xx_dev)\n{\n\tstruct device *dev = &t7xx_dev->pdev->dev;\n\tint ret;\n\n\tret = wait_for_completion_timeout(&t7xx_dev->sleep_lock_acquire,\n\t\t\t\t\t  msecs_to_jiffies(PM_SLEEP_DIS_TIMEOUT_MS));\n\tif (!ret)\n\t\tdev_err_ratelimited(dev, \"Resource wait complete timed out\\n\");\n\n\treturn ret;\n}\n\n \nvoid t7xx_pci_disable_sleep(struct t7xx_pci_dev *t7xx_dev)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&t7xx_dev->md_pm_lock, flags);\n\tt7xx_dev->sleep_disable_count++;\n\tif (atomic_read(&t7xx_dev->md_pm_state) < MTK_PM_RESUMED)\n\t\tgoto unlock_and_complete;\n\n\tif (t7xx_dev->sleep_disable_count == 1) {\n\t\tu32 status;\n\n\t\treinit_completion(&t7xx_dev->sleep_lock_acquire);\n\t\tt7xx_dev_set_sleep_capability(t7xx_dev, false);\n\n\t\tstatus = ioread32(IREG_BASE(t7xx_dev) + T7XX_PCIE_RESOURCE_STATUS);\n\t\tif (status & T7XX_PCIE_RESOURCE_STS_MSK)\n\t\t\tgoto unlock_and_complete;\n\n\t\tt7xx_mhccif_h2d_swint_trigger(t7xx_dev, H2D_CH_DS_LOCK);\n\t}\n\tspin_unlock_irqrestore(&t7xx_dev->md_pm_lock, flags);\n\treturn;\n\nunlock_and_complete:\n\tspin_unlock_irqrestore(&t7xx_dev->md_pm_lock, flags);\n\tcomplete_all(&t7xx_dev->sleep_lock_acquire);\n}\n\n \nvoid t7xx_pci_enable_sleep(struct t7xx_pci_dev *t7xx_dev)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&t7xx_dev->md_pm_lock, flags);\n\tt7xx_dev->sleep_disable_count--;\n\tif (atomic_read(&t7xx_dev->md_pm_state) < MTK_PM_RESUMED)\n\t\tgoto unlock;\n\n\tif (t7xx_dev->sleep_disable_count == 0)\n\t\tt7xx_dev_set_sleep_capability(t7xx_dev, true);\n\nunlock:\n\tspin_unlock_irqrestore(&t7xx_dev->md_pm_lock, flags);\n}\n\nstatic int t7xx_send_pm_request(struct t7xx_pci_dev *t7xx_dev, u32 request)\n{\n\tunsigned long wait_ret;\n\n\treinit_completion(&t7xx_dev->pm_sr_ack);\n\tt7xx_mhccif_h2d_swint_trigger(t7xx_dev, request);\n\twait_ret = wait_for_completion_timeout(&t7xx_dev->pm_sr_ack,\n\t\t\t\t\t       msecs_to_jiffies(PM_ACK_TIMEOUT_MS));\n\tif (!wait_ret)\n\t\treturn -ETIMEDOUT;\n\n\treturn 0;\n}\n\nstatic int __t7xx_pci_pm_suspend(struct pci_dev *pdev)\n{\n\tenum t7xx_pm_id entity_id = PM_ENTITY_ID_INVALID;\n\tstruct t7xx_pci_dev *t7xx_dev;\n\tstruct md_pm_entity *entity;\n\tint ret;\n\n\tt7xx_dev = pci_get_drvdata(pdev);\n\tif (atomic_read(&t7xx_dev->md_pm_state) <= MTK_PM_INIT) {\n\t\tdev_err(&pdev->dev, \"[PM] Exiting suspend, modem in invalid state\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + DISABLE_ASPM_LOWPWR);\n\tret = t7xx_wait_pm_config(t7xx_dev);\n\tif (ret) {\n\t\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + ENABLE_ASPM_LOWPWR);\n\t\treturn ret;\n\t}\n\n\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_SUSPENDED);\n\tt7xx_pcie_mac_clear_int(t7xx_dev, SAP_RGU_INT);\n\tt7xx_dev->rgu_pci_irq_en = false;\n\n\tlist_for_each_entry(entity, &t7xx_dev->md_pm_entities, entity) {\n\t\tif (!entity->suspend)\n\t\t\tcontinue;\n\n\t\tret = entity->suspend(t7xx_dev, entity->entity_param);\n\t\tif (ret) {\n\t\t\tentity_id = entity->id;\n\t\t\tdev_err(&pdev->dev, \"[PM] Suspend error: %d, id: %d\\n\", ret, entity_id);\n\t\t\tgoto abort_suspend;\n\t\t}\n\t}\n\n\tret = t7xx_send_pm_request(t7xx_dev, H2D_CH_SUSPEND_REQ);\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"[PM] MD suspend error: %d\\n\", ret);\n\t\tgoto abort_suspend;\n\t}\n\n\tret = t7xx_send_pm_request(t7xx_dev, H2D_CH_SUSPEND_REQ_AP);\n\tif (ret) {\n\t\tt7xx_send_pm_request(t7xx_dev, H2D_CH_RESUME_REQ);\n\t\tdev_err(&pdev->dev, \"[PM] SAP suspend error: %d\\n\", ret);\n\t\tgoto abort_suspend;\n\t}\n\n\tlist_for_each_entry(entity, &t7xx_dev->md_pm_entities, entity) {\n\t\tif (entity->suspend_late)\n\t\t\tentity->suspend_late(t7xx_dev, entity->entity_param);\n\t}\n\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + ENABLE_ASPM_LOWPWR);\n\treturn 0;\n\nabort_suspend:\n\tlist_for_each_entry(entity, &t7xx_dev->md_pm_entities, entity) {\n\t\tif (entity_id == entity->id)\n\t\t\tbreak;\n\n\t\tif (entity->resume)\n\t\t\tentity->resume(t7xx_dev, entity->entity_param);\n\t}\n\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + ENABLE_ASPM_LOWPWR);\n\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_RESUMED);\n\tt7xx_pcie_mac_set_int(t7xx_dev, SAP_RGU_INT);\n\treturn ret;\n}\n\nstatic void t7xx_pcie_interrupt_reinit(struct t7xx_pci_dev *t7xx_dev)\n{\n\tt7xx_pcie_set_mac_msix_cfg(t7xx_dev, EXT_INT_NUM);\n\n\t \n\tiowrite32(MSIX_MSK_SET_ALL, IREG_BASE(t7xx_dev) + IMASK_HOST_MSIX_CLR_GRP0_0);\n\n\t \n\tt7xx_pcie_mac_interrupts_en(t7xx_dev);\n\tt7xx_pcie_mac_set_int(t7xx_dev, MHCCIF_INT);\n}\n\nstatic int t7xx_pcie_reinit(struct t7xx_pci_dev *t7xx_dev, bool is_d3)\n{\n\tint ret;\n\n\tret = pcim_enable_device(t7xx_dev->pdev);\n\tif (ret)\n\t\treturn ret;\n\n\tt7xx_pcie_mac_atr_init(t7xx_dev);\n\tt7xx_pcie_interrupt_reinit(t7xx_dev);\n\n\tif (is_d3) {\n\t\tt7xx_mhccif_init(t7xx_dev);\n\t\treturn t7xx_pci_pm_reinit(t7xx_dev);\n\t}\n\n\treturn 0;\n}\n\nstatic int t7xx_send_fsm_command(struct t7xx_pci_dev *t7xx_dev, u32 event)\n{\n\tstruct t7xx_fsm_ctl *fsm_ctl = t7xx_dev->md->fsm_ctl;\n\tstruct device *dev = &t7xx_dev->pdev->dev;\n\tint ret = -EINVAL;\n\n\tswitch (event) {\n\tcase FSM_CMD_STOP:\n\t\tret = t7xx_fsm_append_cmd(fsm_ctl, FSM_CMD_STOP, FSM_CMD_FLAG_WAIT_FOR_COMPLETION);\n\t\tbreak;\n\n\tcase FSM_CMD_START:\n\t\tt7xx_pcie_mac_clear_int(t7xx_dev, SAP_RGU_INT);\n\t\tt7xx_pcie_mac_clear_int_status(t7xx_dev, SAP_RGU_INT);\n\t\tt7xx_dev->rgu_pci_irq_en = true;\n\t\tt7xx_pcie_mac_set_int(t7xx_dev, SAP_RGU_INT);\n\t\tret = t7xx_fsm_append_cmd(fsm_ctl, FSM_CMD_START, 0);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (ret)\n\t\tdev_err(dev, \"Failure handling FSM command %u, %d\\n\", event, ret);\n\n\treturn ret;\n}\n\nstatic int __t7xx_pci_pm_resume(struct pci_dev *pdev, bool state_check)\n{\n\tstruct t7xx_pci_dev *t7xx_dev;\n\tstruct md_pm_entity *entity;\n\tu32 prev_state;\n\tint ret = 0;\n\n\tt7xx_dev = pci_get_drvdata(pdev);\n\tif (atomic_read(&t7xx_dev->md_pm_state) <= MTK_PM_INIT) {\n\t\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + ENABLE_ASPM_LOWPWR);\n\t\treturn 0;\n\t}\n\n\tt7xx_pcie_mac_interrupts_en(t7xx_dev);\n\tprev_state = ioread32(IREG_BASE(t7xx_dev) + T7XX_PCIE_PM_RESUME_STATE);\n\n\tif (state_check) {\n\t\t \n\t\tu32 atr_reg_val = ioread32(IREG_BASE(t7xx_dev) +\n\t\t\t\t\t   ATR_PCIE_WIN0_T0_ATR_PARAM_SRC_ADDR);\n\t\tif (prev_state == PM_RESUME_REG_STATE_L3 ||\n\t\t    (prev_state == PM_RESUME_REG_STATE_INIT &&\n\t\t     atr_reg_val == ATR_SRC_ADDR_INVALID)) {\n\t\t\tret = t7xx_send_fsm_command(t7xx_dev, FSM_CMD_STOP);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tret = t7xx_pcie_reinit(t7xx_dev, true);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tt7xx_clear_rgu_irq(t7xx_dev);\n\t\t\treturn t7xx_send_fsm_command(t7xx_dev, FSM_CMD_START);\n\t\t}\n\n\t\tif (prev_state == PM_RESUME_REG_STATE_EXP ||\n\t\t    prev_state == PM_RESUME_REG_STATE_L2_EXP) {\n\t\t\tif (prev_state == PM_RESUME_REG_STATE_L2_EXP) {\n\t\t\t\tret = t7xx_pcie_reinit(t7xx_dev, false);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\n\t\t\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_SUSPENDED);\n\t\t\tt7xx_dev->rgu_pci_irq_en = true;\n\t\t\tt7xx_pcie_mac_set_int(t7xx_dev, SAP_RGU_INT);\n\n\t\t\tt7xx_mhccif_mask_clr(t7xx_dev,\n\t\t\t\t\t     D2H_INT_EXCEPTION_INIT |\n\t\t\t\t\t     D2H_INT_EXCEPTION_INIT_DONE |\n\t\t\t\t\t     D2H_INT_EXCEPTION_CLEARQ_DONE |\n\t\t\t\t\t     D2H_INT_EXCEPTION_ALLQ_RESET |\n\t\t\t\t\t     D2H_INT_PORT_ENUM);\n\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (prev_state == PM_RESUME_REG_STATE_L2) {\n\t\t\tret = t7xx_pcie_reinit(t7xx_dev, false);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t} else if (prev_state != PM_RESUME_REG_STATE_L1 &&\n\t\t\t   prev_state != PM_RESUME_REG_STATE_INIT) {\n\t\t\tret = t7xx_send_fsm_command(t7xx_dev, FSM_CMD_STOP);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tt7xx_clear_rgu_irq(t7xx_dev);\n\t\t\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_SUSPENDED);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + DISABLE_ASPM_LOWPWR);\n\tt7xx_wait_pm_config(t7xx_dev);\n\n\tlist_for_each_entry(entity, &t7xx_dev->md_pm_entities, entity) {\n\t\tif (entity->resume_early)\n\t\t\tentity->resume_early(t7xx_dev, entity->entity_param);\n\t}\n\n\tret = t7xx_send_pm_request(t7xx_dev, H2D_CH_RESUME_REQ);\n\tif (ret)\n\t\tdev_err(&pdev->dev, \"[PM] MD resume error: %d\\n\", ret);\n\n\tret = t7xx_send_pm_request(t7xx_dev, H2D_CH_RESUME_REQ_AP);\n\tif (ret)\n\t\tdev_err(&pdev->dev, \"[PM] SAP resume error: %d\\n\", ret);\n\n\tlist_for_each_entry(entity, &t7xx_dev->md_pm_entities, entity) {\n\t\tif (entity->resume) {\n\t\t\tret = entity->resume(t7xx_dev, entity->entity_param);\n\t\t\tif (ret)\n\t\t\t\tdev_err(&pdev->dev, \"[PM] Resume entry ID: %d error: %d\\n\",\n\t\t\t\t\tentity->id, ret);\n\t\t}\n\t}\n\n\tt7xx_dev->rgu_pci_irq_en = true;\n\tt7xx_pcie_mac_set_int(t7xx_dev, SAP_RGU_INT);\n\tiowrite32(T7XX_L1_BIT(0), IREG_BASE(t7xx_dev) + ENABLE_ASPM_LOWPWR);\n\tpm_runtime_mark_last_busy(&pdev->dev);\n\tatomic_set(&t7xx_dev->md_pm_state, MTK_PM_RESUMED);\n\n\treturn ret;\n}\n\nstatic int t7xx_pci_pm_resume_noirq(struct device *dev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev);\n\tstruct t7xx_pci_dev *t7xx_dev;\n\n\tt7xx_dev = pci_get_drvdata(pdev);\n\tt7xx_pcie_mac_interrupts_dis(t7xx_dev);\n\n\treturn 0;\n}\n\nstatic void t7xx_pci_shutdown(struct pci_dev *pdev)\n{\n\t__t7xx_pci_pm_suspend(pdev);\n}\n\nstatic int t7xx_pci_pm_prepare(struct device *dev)\n{\n\tstruct pci_dev *pdev = to_pci_dev(dev);\n\tstruct t7xx_pci_dev *t7xx_dev;\n\n\tt7xx_dev = pci_get_drvdata(pdev);\n\tif (!wait_for_completion_timeout(&t7xx_dev->init_done, T7XX_INIT_TIMEOUT * HZ)) {\n\t\tdev_warn(dev, \"Not ready for system sleep.\\n\");\n\t\treturn -ETIMEDOUT;\n\t}\n\n\treturn 0;\n}\n\nstatic int t7xx_pci_pm_suspend(struct device *dev)\n{\n\treturn __t7xx_pci_pm_suspend(to_pci_dev(dev));\n}\n\nstatic int t7xx_pci_pm_resume(struct device *dev)\n{\n\treturn __t7xx_pci_pm_resume(to_pci_dev(dev), true);\n}\n\nstatic int t7xx_pci_pm_thaw(struct device *dev)\n{\n\treturn __t7xx_pci_pm_resume(to_pci_dev(dev), false);\n}\n\nstatic int t7xx_pci_pm_runtime_suspend(struct device *dev)\n{\n\treturn __t7xx_pci_pm_suspend(to_pci_dev(dev));\n}\n\nstatic int t7xx_pci_pm_runtime_resume(struct device *dev)\n{\n\treturn __t7xx_pci_pm_resume(to_pci_dev(dev), true);\n}\n\nstatic const struct dev_pm_ops t7xx_pci_pm_ops = {\n\t.prepare = t7xx_pci_pm_prepare,\n\t.suspend = t7xx_pci_pm_suspend,\n\t.resume = t7xx_pci_pm_resume,\n\t.resume_noirq = t7xx_pci_pm_resume_noirq,\n\t.freeze = t7xx_pci_pm_suspend,\n\t.thaw = t7xx_pci_pm_thaw,\n\t.poweroff = t7xx_pci_pm_suspend,\n\t.restore = t7xx_pci_pm_resume,\n\t.restore_noirq = t7xx_pci_pm_resume_noirq,\n\t.runtime_suspend = t7xx_pci_pm_runtime_suspend,\n\t.runtime_resume = t7xx_pci_pm_runtime_resume\n};\n\nstatic int t7xx_request_irq(struct pci_dev *pdev)\n{\n\tstruct t7xx_pci_dev *t7xx_dev;\n\tint ret = 0, i;\n\n\tt7xx_dev = pci_get_drvdata(pdev);\n\n\tfor (i = 0; i < EXT_INT_NUM; i++) {\n\t\tconst char *irq_descr;\n\t\tint irq_vec;\n\n\t\tif (!t7xx_dev->intr_handler[i])\n\t\t\tcontinue;\n\n\t\tirq_descr = devm_kasprintf(&pdev->dev, GFP_KERNEL, \"%s_%d\",\n\t\t\t\t\t   dev_driver_string(&pdev->dev), i);\n\t\tif (!irq_descr) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tirq_vec = pci_irq_vector(pdev, i);\n\t\tret = request_threaded_irq(irq_vec, t7xx_dev->intr_handler[i],\n\t\t\t\t\t   t7xx_dev->intr_thread[i], 0, irq_descr,\n\t\t\t\t\t   t7xx_dev->callback_param[i]);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev, \"Failed to request IRQ: %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (ret) {\n\t\twhile (i--) {\n\t\t\tif (!t7xx_dev->intr_handler[i])\n\t\t\t\tcontinue;\n\n\t\t\tfree_irq(pci_irq_vector(pdev, i), t7xx_dev->callback_param[i]);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int t7xx_setup_msix(struct t7xx_pci_dev *t7xx_dev)\n{\n\tstruct pci_dev *pdev = t7xx_dev->pdev;\n\tint ret;\n\n\t \n\tret = pci_alloc_irq_vectors(pdev, EXT_INT_NUM, EXT_INT_NUM, PCI_IRQ_MSIX);\n\tif (ret < 0) {\n\t\tdev_err(&pdev->dev, \"Failed to allocate MSI-X entry: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = t7xx_request_irq(pdev);\n\tif (ret) {\n\t\tpci_free_irq_vectors(pdev);\n\t\treturn ret;\n\t}\n\n\tt7xx_pcie_set_mac_msix_cfg(t7xx_dev, EXT_INT_NUM);\n\treturn 0;\n}\n\nstatic int t7xx_interrupt_init(struct t7xx_pci_dev *t7xx_dev)\n{\n\tint ret, i;\n\n\tif (!t7xx_dev->pdev->msix_cap)\n\t\treturn -EINVAL;\n\n\tret = t7xx_setup_msix(t7xx_dev);\n\tif (ret)\n\t\treturn ret;\n\n\t \n\tfor (i = 0; i < EXT_INT_NUM; i++)\n\t\tt7xx_pcie_mac_set_int(t7xx_dev, i);\n\n\treturn 0;\n}\n\nstatic void t7xx_pci_infracfg_ao_calc(struct t7xx_pci_dev *t7xx_dev)\n{\n\tt7xx_dev->base_addr.infracfg_ao_base = t7xx_dev->base_addr.pcie_ext_reg_base +\n\t\t\t\t\t      INFRACFG_AO_DEV_CHIP -\n\t\t\t\t\t      t7xx_dev->base_addr.pcie_dev_reg_trsl_addr;\n}\n\nstatic int t7xx_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\n{\n\tstruct t7xx_pci_dev *t7xx_dev;\n\tint ret;\n\n\tt7xx_dev = devm_kzalloc(&pdev->dev, sizeof(*t7xx_dev), GFP_KERNEL);\n\tif (!t7xx_dev)\n\t\treturn -ENOMEM;\n\n\tpci_set_drvdata(pdev, t7xx_dev);\n\tt7xx_dev->pdev = pdev;\n\n\tret = pcim_enable_device(pdev);\n\tif (ret)\n\t\treturn ret;\n\n\tpci_set_master(pdev);\n\n\tret = pcim_iomap_regions(pdev, BIT(T7XX_PCI_IREG_BASE) | BIT(T7XX_PCI_EREG_BASE),\n\t\t\t\t pci_name(pdev));\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Could not request BARs: %d\\n\", ret);\n\t\treturn -ENOMEM;\n\t}\n\n\tret = dma_set_mask(&pdev->dev, DMA_BIT_MASK(64));\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Could not set PCI DMA mask: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tret = dma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(64));\n\tif (ret) {\n\t\tdev_err(&pdev->dev, \"Could not set consistent PCI DMA mask: %d\\n\", ret);\n\t\treturn ret;\n\t}\n\n\tIREG_BASE(t7xx_dev) = pcim_iomap_table(pdev)[T7XX_PCI_IREG_BASE];\n\tt7xx_dev->base_addr.pcie_ext_reg_base = pcim_iomap_table(pdev)[T7XX_PCI_EREG_BASE];\n\n\tret = t7xx_pci_pm_init(t7xx_dev);\n\tif (ret)\n\t\treturn ret;\n\n\tt7xx_pcie_mac_atr_init(t7xx_dev);\n\tt7xx_pci_infracfg_ao_calc(t7xx_dev);\n\tt7xx_mhccif_init(t7xx_dev);\n\n\tret = t7xx_md_init(t7xx_dev);\n\tif (ret)\n\t\treturn ret;\n\n\tt7xx_pcie_mac_interrupts_dis(t7xx_dev);\n\n\tret = t7xx_interrupt_init(t7xx_dev);\n\tif (ret) {\n\t\tt7xx_md_exit(t7xx_dev);\n\t\treturn ret;\n\t}\n\n\tt7xx_pcie_mac_set_int(t7xx_dev, MHCCIF_INT);\n\tt7xx_pcie_mac_interrupts_en(t7xx_dev);\n\n\treturn 0;\n}\n\nstatic void t7xx_pci_remove(struct pci_dev *pdev)\n{\n\tstruct t7xx_pci_dev *t7xx_dev;\n\tint i;\n\n\tt7xx_dev = pci_get_drvdata(pdev);\n\tt7xx_md_exit(t7xx_dev);\n\n\tfor (i = 0; i < EXT_INT_NUM; i++) {\n\t\tif (!t7xx_dev->intr_handler[i])\n\t\t\tcontinue;\n\n\t\tfree_irq(pci_irq_vector(pdev, i), t7xx_dev->callback_param[i]);\n\t}\n\n\tpci_free_irq_vectors(t7xx_dev->pdev);\n}\n\nstatic const struct pci_device_id t7xx_pci_table[] = {\n\t{ PCI_DEVICE(PCI_VENDOR_ID_MEDIATEK, 0x4d75) },\n\t{ }\n};\nMODULE_DEVICE_TABLE(pci, t7xx_pci_table);\n\nstatic struct pci_driver t7xx_pci_driver = {\n\t.name = \"mtk_t7xx\",\n\t.id_table = t7xx_pci_table,\n\t.probe = t7xx_pci_probe,\n\t.remove = t7xx_pci_remove,\n\t.driver.pm = &t7xx_pci_pm_ops,\n\t.shutdown = t7xx_pci_shutdown,\n};\n\nmodule_pci_driver(t7xx_pci_driver);\n\nMODULE_AUTHOR(\"MediaTek Inc\");\nMODULE_DESCRIPTION(\"MediaTek PCIe 5G WWAN modem T7xx driver\");\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}