{
  "module_name": "t7xx_state_monitor.c",
  "hash_id": "af78457198bf1552d8d80545e5fd3c4f97b447885c53f30b9c2ef087a21b1083",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wwan/t7xx/t7xx_state_monitor.c",
  "human_readable_source": "\n \n\n#include <linux/bits.h>\n#include <linux/bitfield.h>\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/delay.h>\n#include <linux/err.h>\n#include <linux/gfp.h>\n#include <linux/iopoll.h>\n#include <linux/jiffies.h>\n#include <linux/kernel.h>\n#include <linux/kthread.h>\n#include <linux/list.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/wait.h>\n\n#include \"t7xx_hif_cldma.h\"\n#include \"t7xx_mhccif.h\"\n#include \"t7xx_modem_ops.h\"\n#include \"t7xx_pci.h\"\n#include \"t7xx_pcie_mac.h\"\n#include \"t7xx_port_proxy.h\"\n#include \"t7xx_reg.h\"\n#include \"t7xx_state_monitor.h\"\n\n#define FSM_DRM_DISABLE_DELAY_MS\t\t200\n#define FSM_EVENT_POLL_INTERVAL_MS\t\t20\n#define FSM_MD_EX_REC_OK_TIMEOUT_MS\t\t10000\n#define FSM_MD_EX_PASS_TIMEOUT_MS\t\t45000\n#define FSM_CMD_TIMEOUT_MS\t\t\t2000\n\nvoid t7xx_fsm_notifier_register(struct t7xx_modem *md, struct t7xx_fsm_notifier *notifier)\n{\n\tstruct t7xx_fsm_ctl *ctl = md->fsm_ctl;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ctl->notifier_lock, flags);\n\tlist_add_tail(&notifier->entry, &ctl->notifier_list);\n\tspin_unlock_irqrestore(&ctl->notifier_lock, flags);\n}\n\nvoid t7xx_fsm_notifier_unregister(struct t7xx_modem *md, struct t7xx_fsm_notifier *notifier)\n{\n\tstruct t7xx_fsm_notifier *notifier_cur, *notifier_next;\n\tstruct t7xx_fsm_ctl *ctl = md->fsm_ctl;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ctl->notifier_lock, flags);\n\tlist_for_each_entry_safe(notifier_cur, notifier_next, &ctl->notifier_list, entry) {\n\t\tif (notifier_cur == notifier)\n\t\t\tlist_del(&notifier->entry);\n\t}\n\tspin_unlock_irqrestore(&ctl->notifier_lock, flags);\n}\n\nstatic void fsm_state_notify(struct t7xx_modem *md, enum md_state state)\n{\n\tstruct t7xx_fsm_ctl *ctl = md->fsm_ctl;\n\tstruct t7xx_fsm_notifier *notifier;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ctl->notifier_lock, flags);\n\tlist_for_each_entry(notifier, &ctl->notifier_list, entry) {\n\t\tspin_unlock_irqrestore(&ctl->notifier_lock, flags);\n\t\tif (notifier->notifier_fn)\n\t\t\tnotifier->notifier_fn(state, notifier->data);\n\n\t\tspin_lock_irqsave(&ctl->notifier_lock, flags);\n\t}\n\tspin_unlock_irqrestore(&ctl->notifier_lock, flags);\n}\n\nvoid t7xx_fsm_broadcast_state(struct t7xx_fsm_ctl *ctl, enum md_state state)\n{\n\tctl->md_state = state;\n\n\t \n\tt7xx_port_proxy_md_status_notify(ctl->md->port_prox, state);\n\tfsm_state_notify(ctl->md, state);\n}\n\nstatic void fsm_finish_command(struct t7xx_fsm_ctl *ctl, struct t7xx_fsm_command *cmd, int result)\n{\n\tif (cmd->flag & FSM_CMD_FLAG_WAIT_FOR_COMPLETION) {\n\t\t*cmd->ret = result;\n\t\tcomplete_all(cmd->done);\n\t}\n\n\tkfree(cmd);\n}\n\nstatic void fsm_del_kf_event(struct t7xx_fsm_event *event)\n{\n\tlist_del(&event->entry);\n\tkfree(event);\n}\n\nstatic void fsm_flush_event_cmd_qs(struct t7xx_fsm_ctl *ctl)\n{\n\tstruct device *dev = &ctl->md->t7xx_dev->pdev->dev;\n\tstruct t7xx_fsm_event *event, *evt_next;\n\tstruct t7xx_fsm_command *cmd, *cmd_next;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ctl->command_lock, flags);\n\tlist_for_each_entry_safe(cmd, cmd_next, &ctl->command_queue, entry) {\n\t\tdev_warn(dev, \"Unhandled command %d\\n\", cmd->cmd_id);\n\t\tlist_del(&cmd->entry);\n\t\tfsm_finish_command(ctl, cmd, -EINVAL);\n\t}\n\tspin_unlock_irqrestore(&ctl->command_lock, flags);\n\n\tspin_lock_irqsave(&ctl->event_lock, flags);\n\tlist_for_each_entry_safe(event, evt_next, &ctl->event_queue, entry) {\n\t\tdev_warn(dev, \"Unhandled event %d\\n\", event->event_id);\n\t\tfsm_del_kf_event(event);\n\t}\n\tspin_unlock_irqrestore(&ctl->event_lock, flags);\n}\n\nstatic void fsm_wait_for_event(struct t7xx_fsm_ctl *ctl, enum t7xx_fsm_event_state event_expected,\n\t\t\t       enum t7xx_fsm_event_state event_ignore, int retries)\n{\n\tstruct t7xx_fsm_event *event;\n\tbool event_received = false;\n\tunsigned long flags;\n\tint cnt = 0;\n\n\twhile (cnt++ < retries && !event_received) {\n\t\tbool sleep_required = true;\n\n\t\tif (kthread_should_stop())\n\t\t\treturn;\n\n\t\tspin_lock_irqsave(&ctl->event_lock, flags);\n\t\tevent = list_first_entry_or_null(&ctl->event_queue, struct t7xx_fsm_event, entry);\n\t\tif (event) {\n\t\t\tevent_received = event->event_id == event_expected;\n\t\t\tif (event_received || event->event_id == event_ignore) {\n\t\t\t\tfsm_del_kf_event(event);\n\t\t\t\tsleep_required = false;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irqrestore(&ctl->event_lock, flags);\n\n\t\tif (sleep_required)\n\t\t\tmsleep(FSM_EVENT_POLL_INTERVAL_MS);\n\t}\n}\n\nstatic void fsm_routine_exception(struct t7xx_fsm_ctl *ctl, struct t7xx_fsm_command *cmd,\n\t\t\t\t  enum t7xx_ex_reason reason)\n{\n\tstruct device *dev = &ctl->md->t7xx_dev->pdev->dev;\n\n\tif (ctl->curr_state != FSM_STATE_READY && ctl->curr_state != FSM_STATE_STARTING) {\n\t\tif (cmd)\n\t\t\tfsm_finish_command(ctl, cmd, -EINVAL);\n\n\t\treturn;\n\t}\n\n\tctl->curr_state = FSM_STATE_EXCEPTION;\n\n\tswitch (reason) {\n\tcase EXCEPTION_HS_TIMEOUT:\n\t\tdev_err(dev, \"Boot Handshake failure\\n\");\n\t\tbreak;\n\n\tcase EXCEPTION_EVENT:\n\t\tdev_err(dev, \"Exception event\\n\");\n\t\tt7xx_fsm_broadcast_state(ctl, MD_STATE_EXCEPTION);\n\t\tt7xx_pci_pm_exp_detected(ctl->md->t7xx_dev);\n\t\tt7xx_md_exception_handshake(ctl->md);\n\n\t\tfsm_wait_for_event(ctl, FSM_EVENT_MD_EX_REC_OK, FSM_EVENT_MD_EX,\n\t\t\t\t   FSM_MD_EX_REC_OK_TIMEOUT_MS / FSM_EVENT_POLL_INTERVAL_MS);\n\t\tfsm_wait_for_event(ctl, FSM_EVENT_MD_EX_PASS, FSM_EVENT_INVALID,\n\t\t\t\t   FSM_MD_EX_PASS_TIMEOUT_MS / FSM_EVENT_POLL_INTERVAL_MS);\n\t\tbreak;\n\n\tdefault:\n\t\tdev_err(dev, \"Exception %d\\n\", reason);\n\t\tbreak;\n\t}\n\n\tif (cmd)\n\t\tfsm_finish_command(ctl, cmd, 0);\n}\n\nstatic int fsm_stopped_handler(struct t7xx_fsm_ctl *ctl)\n{\n\tctl->curr_state = FSM_STATE_STOPPED;\n\n\tt7xx_fsm_broadcast_state(ctl, MD_STATE_STOPPED);\n\treturn t7xx_md_reset(ctl->md->t7xx_dev);\n}\n\nstatic void fsm_routine_stopped(struct t7xx_fsm_ctl *ctl, struct t7xx_fsm_command *cmd)\n{\n\tif (ctl->curr_state == FSM_STATE_STOPPED) {\n\t\tfsm_finish_command(ctl, cmd, -EINVAL);\n\t\treturn;\n\t}\n\n\tfsm_finish_command(ctl, cmd, fsm_stopped_handler(ctl));\n}\n\nstatic void fsm_routine_stopping(struct t7xx_fsm_ctl *ctl, struct t7xx_fsm_command *cmd)\n{\n\tstruct t7xx_pci_dev *t7xx_dev;\n\tstruct cldma_ctrl *md_ctrl;\n\tint err;\n\n\tif (ctl->curr_state == FSM_STATE_STOPPED || ctl->curr_state == FSM_STATE_STOPPING) {\n\t\tfsm_finish_command(ctl, cmd, -EINVAL);\n\t\treturn;\n\t}\n\n\tmd_ctrl = ctl->md->md_ctrl[CLDMA_ID_MD];\n\tt7xx_dev = ctl->md->t7xx_dev;\n\n\tctl->curr_state = FSM_STATE_STOPPING;\n\tt7xx_fsm_broadcast_state(ctl, MD_STATE_WAITING_TO_STOP);\n\tt7xx_cldma_stop(md_ctrl);\n\n\tif (!ctl->md->rgu_irq_asserted) {\n\t\tt7xx_mhccif_h2d_swint_trigger(t7xx_dev, H2D_CH_DRM_DISABLE_AP);\n\t\t \n\t\tmsleep(FSM_DRM_DISABLE_DELAY_MS);\n\n\t\terr = t7xx_acpi_fldr_func(t7xx_dev);\n\t\tif (err)\n\t\t\tt7xx_mhccif_h2d_swint_trigger(t7xx_dev, H2D_CH_DEVICE_RESET);\n\t}\n\n\tfsm_finish_command(ctl, cmd, fsm_stopped_handler(ctl));\n}\n\nstatic void t7xx_fsm_broadcast_ready_state(struct t7xx_fsm_ctl *ctl)\n{\n\tif (ctl->md_state != MD_STATE_WAITING_FOR_HS2)\n\t\treturn;\n\n\tctl->md_state = MD_STATE_READY;\n\n\tfsm_state_notify(ctl->md, MD_STATE_READY);\n\tt7xx_port_proxy_md_status_notify(ctl->md->port_prox, MD_STATE_READY);\n}\n\nstatic void fsm_routine_ready(struct t7xx_fsm_ctl *ctl)\n{\n\tstruct t7xx_modem *md = ctl->md;\n\n\tctl->curr_state = FSM_STATE_READY;\n\tt7xx_fsm_broadcast_ready_state(ctl);\n\tt7xx_md_event_notify(md, FSM_READY);\n}\n\nstatic int fsm_routine_starting(struct t7xx_fsm_ctl *ctl)\n{\n\tstruct t7xx_modem *md = ctl->md;\n\tstruct device *dev;\n\n\tctl->curr_state = FSM_STATE_STARTING;\n\n\tt7xx_fsm_broadcast_state(ctl, MD_STATE_WAITING_FOR_HS1);\n\tt7xx_md_event_notify(md, FSM_START);\n\n\twait_event_interruptible_timeout(ctl->async_hk_wq,\n\t\t\t\t\t (md->core_md.ready && md->core_ap.ready) ||\n\t\t\t\t\t  ctl->exp_flg, HZ * 60);\n\tdev = &md->t7xx_dev->pdev->dev;\n\n\tif (ctl->exp_flg)\n\t\tdev_err(dev, \"MD exception is captured during handshake\\n\");\n\n\tif (!md->core_md.ready) {\n\t\tdev_err(dev, \"MD handshake timeout\\n\");\n\t\tif (md->core_md.handshake_ongoing)\n\t\t\tt7xx_fsm_append_event(ctl, FSM_EVENT_MD_HS2_EXIT, NULL, 0);\n\n\t\tfsm_routine_exception(ctl, NULL, EXCEPTION_HS_TIMEOUT);\n\t\treturn -ETIMEDOUT;\n\t} else if (!md->core_ap.ready) {\n\t\tdev_err(dev, \"AP handshake timeout\\n\");\n\t\tif (md->core_ap.handshake_ongoing)\n\t\t\tt7xx_fsm_append_event(ctl, FSM_EVENT_AP_HS2_EXIT, NULL, 0);\n\n\t\tfsm_routine_exception(ctl, NULL, EXCEPTION_HS_TIMEOUT);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\tt7xx_pci_pm_init_late(md->t7xx_dev);\n\tfsm_routine_ready(ctl);\n\treturn 0;\n}\n\nstatic void fsm_routine_start(struct t7xx_fsm_ctl *ctl, struct t7xx_fsm_command *cmd)\n{\n\tstruct t7xx_modem *md = ctl->md;\n\tu32 dev_status;\n\tint ret;\n\n\tif (!md)\n\t\treturn;\n\n\tif (ctl->curr_state != FSM_STATE_INIT && ctl->curr_state != FSM_STATE_PRE_START &&\n\t    ctl->curr_state != FSM_STATE_STOPPED) {\n\t\tfsm_finish_command(ctl, cmd, -EINVAL);\n\t\treturn;\n\t}\n\n\tctl->curr_state = FSM_STATE_PRE_START;\n\tt7xx_md_event_notify(md, FSM_PRE_START);\n\n\tret = read_poll_timeout(ioread32, dev_status,\n\t\t\t\t(dev_status & MISC_STAGE_MASK) == LINUX_STAGE, 20000, 2000000,\n\t\t\t\tfalse, IREG_BASE(md->t7xx_dev) + T7XX_PCIE_MISC_DEV_STATUS);\n\tif (ret) {\n\t\tstruct device *dev = &md->t7xx_dev->pdev->dev;\n\n\t\tfsm_finish_command(ctl, cmd, -ETIMEDOUT);\n\t\tdev_err(dev, \"Invalid device status 0x%lx\\n\", dev_status & MISC_STAGE_MASK);\n\t\treturn;\n\t}\n\n\tt7xx_cldma_hif_hw_init(md->md_ctrl[CLDMA_ID_AP]);\n\tt7xx_cldma_hif_hw_init(md->md_ctrl[CLDMA_ID_MD]);\n\tfsm_finish_command(ctl, cmd, fsm_routine_starting(ctl));\n}\n\nstatic int fsm_main_thread(void *data)\n{\n\tstruct t7xx_fsm_ctl *ctl = data;\n\tstruct t7xx_fsm_command *cmd;\n\tunsigned long flags;\n\n\twhile (!kthread_should_stop()) {\n\t\tif (wait_event_interruptible(ctl->command_wq, !list_empty(&ctl->command_queue) ||\n\t\t\t\t\t     kthread_should_stop()))\n\t\t\tcontinue;\n\n\t\tif (kthread_should_stop())\n\t\t\tbreak;\n\n\t\tspin_lock_irqsave(&ctl->command_lock, flags);\n\t\tcmd = list_first_entry(&ctl->command_queue, struct t7xx_fsm_command, entry);\n\t\tlist_del(&cmd->entry);\n\t\tspin_unlock_irqrestore(&ctl->command_lock, flags);\n\n\t\tswitch (cmd->cmd_id) {\n\t\tcase FSM_CMD_START:\n\t\t\tfsm_routine_start(ctl, cmd);\n\t\t\tbreak;\n\n\t\tcase FSM_CMD_EXCEPTION:\n\t\t\tfsm_routine_exception(ctl, cmd, FIELD_GET(FSM_CMD_EX_REASON, cmd->flag));\n\t\t\tbreak;\n\n\t\tcase FSM_CMD_PRE_STOP:\n\t\t\tfsm_routine_stopping(ctl, cmd);\n\t\t\tbreak;\n\n\t\tcase FSM_CMD_STOP:\n\t\t\tfsm_routine_stopped(ctl, cmd);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfsm_finish_command(ctl, cmd, -EINVAL);\n\t\t\tfsm_flush_event_cmd_qs(ctl);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint t7xx_fsm_append_cmd(struct t7xx_fsm_ctl *ctl, enum t7xx_fsm_cmd_state cmd_id, unsigned int flag)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct t7xx_fsm_command *cmd;\n\tunsigned long flags;\n\tint ret;\n\n\tcmd = kzalloc(sizeof(*cmd), flag & FSM_CMD_FLAG_IN_INTERRUPT ? GFP_ATOMIC : GFP_KERNEL);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&cmd->entry);\n\tcmd->cmd_id = cmd_id;\n\tcmd->flag = flag;\n\tif (flag & FSM_CMD_FLAG_WAIT_FOR_COMPLETION) {\n\t\tcmd->done = &done;\n\t\tcmd->ret = &ret;\n\t}\n\n\tspin_lock_irqsave(&ctl->command_lock, flags);\n\tlist_add_tail(&cmd->entry, &ctl->command_queue);\n\tspin_unlock_irqrestore(&ctl->command_lock, flags);\n\n\twake_up(&ctl->command_wq);\n\n\tif (flag & FSM_CMD_FLAG_WAIT_FOR_COMPLETION) {\n\t\tunsigned long wait_ret;\n\n\t\twait_ret = wait_for_completion_timeout(&done,\n\t\t\t\t\t\t       msecs_to_jiffies(FSM_CMD_TIMEOUT_MS));\n\t\tif (!wait_ret)\n\t\t\treturn -ETIMEDOUT;\n\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\n\nint t7xx_fsm_append_event(struct t7xx_fsm_ctl *ctl, enum t7xx_fsm_event_state event_id,\n\t\t\t  unsigned char *data, unsigned int length)\n{\n\tstruct device *dev = &ctl->md->t7xx_dev->pdev->dev;\n\tstruct t7xx_fsm_event *event;\n\tunsigned long flags;\n\n\tif (event_id <= FSM_EVENT_INVALID || event_id >= FSM_EVENT_MAX) {\n\t\tdev_err(dev, \"Invalid event %d\\n\", event_id);\n\t\treturn -EINVAL;\n\t}\n\n\tevent = kmalloc(sizeof(*event) + length, in_interrupt() ? GFP_ATOMIC : GFP_KERNEL);\n\tif (!event)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&event->entry);\n\tevent->event_id = event_id;\n\tevent->length = length;\n\n\tif (data && length)\n\t\tmemcpy(event->data, data, length);\n\n\tspin_lock_irqsave(&ctl->event_lock, flags);\n\tlist_add_tail(&event->entry, &ctl->event_queue);\n\tspin_unlock_irqrestore(&ctl->event_lock, flags);\n\n\twake_up_all(&ctl->event_wq);\n\treturn 0;\n}\n\nvoid t7xx_fsm_clr_event(struct t7xx_fsm_ctl *ctl, enum t7xx_fsm_event_state event_id)\n{\n\tstruct t7xx_fsm_event *event, *evt_next;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&ctl->event_lock, flags);\n\tlist_for_each_entry_safe(event, evt_next, &ctl->event_queue, entry) {\n\t\tif (event->event_id == event_id)\n\t\t\tfsm_del_kf_event(event);\n\t}\n\tspin_unlock_irqrestore(&ctl->event_lock, flags);\n}\n\nenum md_state t7xx_fsm_get_md_state(struct t7xx_fsm_ctl *ctl)\n{\n\tif (ctl)\n\t\treturn ctl->md_state;\n\n\treturn MD_STATE_INVALID;\n}\n\nunsigned int t7xx_fsm_get_ctl_state(struct t7xx_fsm_ctl *ctl)\n{\n\tif (ctl)\n\t\treturn ctl->curr_state;\n\n\treturn FSM_STATE_STOPPED;\n}\n\nint t7xx_fsm_recv_md_intr(struct t7xx_fsm_ctl *ctl, enum t7xx_md_irq_type type)\n{\n\tunsigned int cmd_flags = FSM_CMD_FLAG_IN_INTERRUPT;\n\n\tif (type == MD_IRQ_PORT_ENUM) {\n\t\treturn t7xx_fsm_append_cmd(ctl, FSM_CMD_START, cmd_flags);\n\t} else if (type == MD_IRQ_CCIF_EX) {\n\t\tctl->exp_flg = true;\n\t\twake_up(&ctl->async_hk_wq);\n\t\tcmd_flags |= FIELD_PREP(FSM_CMD_EX_REASON, EXCEPTION_EVENT);\n\t\treturn t7xx_fsm_append_cmd(ctl, FSM_CMD_EXCEPTION, cmd_flags);\n\t}\n\n\treturn -EINVAL;\n}\n\nvoid t7xx_fsm_reset(struct t7xx_modem *md)\n{\n\tstruct t7xx_fsm_ctl *ctl = md->fsm_ctl;\n\n\tfsm_flush_event_cmd_qs(ctl);\n\tctl->curr_state = FSM_STATE_STOPPED;\n\tctl->exp_flg = false;\n}\n\nint t7xx_fsm_init(struct t7xx_modem *md)\n{\n\tstruct device *dev = &md->t7xx_dev->pdev->dev;\n\tstruct t7xx_fsm_ctl *ctl;\n\n\tctl = devm_kzalloc(dev, sizeof(*ctl), GFP_KERNEL);\n\tif (!ctl)\n\t\treturn -ENOMEM;\n\n\tmd->fsm_ctl = ctl;\n\tctl->md = md;\n\tctl->curr_state = FSM_STATE_INIT;\n\tINIT_LIST_HEAD(&ctl->command_queue);\n\tINIT_LIST_HEAD(&ctl->event_queue);\n\tinit_waitqueue_head(&ctl->async_hk_wq);\n\tinit_waitqueue_head(&ctl->event_wq);\n\tINIT_LIST_HEAD(&ctl->notifier_list);\n\tinit_waitqueue_head(&ctl->command_wq);\n\tspin_lock_init(&ctl->event_lock);\n\tspin_lock_init(&ctl->command_lock);\n\tctl->exp_flg = false;\n\tspin_lock_init(&ctl->notifier_lock);\n\n\tctl->fsm_thread = kthread_run(fsm_main_thread, ctl, \"t7xx_fsm\");\n\treturn PTR_ERR_OR_ZERO(ctl->fsm_thread);\n}\n\nvoid t7xx_fsm_uninit(struct t7xx_modem *md)\n{\n\tstruct t7xx_fsm_ctl *ctl = md->fsm_ctl;\n\n\tif (!ctl)\n\t\treturn;\n\n\tif (ctl->fsm_thread)\n\t\tkthread_stop(ctl->fsm_thread);\n\n\tfsm_flush_event_cmd_qs(ctl);\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}