{
  "module_name": "t7xx_hif_cldma.h",
  "hash_id": "aa122d7a5c58eff1e476866e1f1dab7ef6a204e7c1100868741890cf10876a58",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wwan/t7xx/t7xx_hif_cldma.h",
  "human_readable_source": " \n\n#ifndef __T7XX_HIF_CLDMA_H__\n#define __T7XX_HIF_CLDMA_H__\n\n#include <linux/bits.h>\n#include <linux/device.h>\n#include <linux/dmapool.h>\n#include <linux/pci.h>\n#include <linux/skbuff.h>\n#include <linux/spinlock.h>\n#include <linux/wait.h>\n#include <linux/workqueue.h>\n#include <linux/types.h>\n\n#include \"t7xx_cldma.h\"\n#include \"t7xx_pci.h\"\n\n \nenum cldma_id {\n\tCLDMA_ID_MD,\n\tCLDMA_ID_AP,\n\tCLDMA_NUM\n};\n\nstruct cldma_gpd {\n\tu8 flags;\n\tu8 not_used1;\n\t__le16 rx_data_allow_len;\n\t__le32 next_gpd_ptr_h;\n\t__le32 next_gpd_ptr_l;\n\t__le32 data_buff_bd_ptr_h;\n\t__le32 data_buff_bd_ptr_l;\n\t__le16 data_buff_len;\n\t__le16 not_used2;\n};\n\nstruct cldma_request {\n\tstruct cldma_gpd *gpd;\t \n\tdma_addr_t gpd_addr;\t \n\tstruct sk_buff *skb;\n\tdma_addr_t mapped_buff;\n\tstruct list_head entry;\n};\n\nstruct cldma_ring {\n\tstruct list_head gpd_ring;\t \n\tunsigned int length;\t\t \n\tint pkt_size;\n};\n\nstruct cldma_queue {\n\tstruct cldma_ctrl *md_ctrl;\n\tenum mtk_txrx dir;\n\tunsigned int index;\n\tstruct cldma_ring *tr_ring;\n\tstruct cldma_request *tr_done;\n\tstruct cldma_request *rx_refill;\n\tstruct cldma_request *tx_next;\n\tint budget;\t\t\t \n\tspinlock_t ring_lock;\n\twait_queue_head_t req_wq;\t \n\tstruct workqueue_struct *worker;\n\tstruct work_struct cldma_work;\n};\n\nstruct cldma_ctrl {\n\tenum cldma_id hif_id;\n\tstruct device *dev;\n\tstruct t7xx_pci_dev *t7xx_dev;\n\tstruct cldma_queue txq[CLDMA_TXQ_NUM];\n\tstruct cldma_queue rxq[CLDMA_RXQ_NUM];\n\tunsigned short txq_active;\n\tunsigned short rxq_active;\n\tunsigned short txq_started;\n\tspinlock_t cldma_lock;  \n\t \n\tstruct dma_pool *gpd_dmapool;\n\tstruct cldma_ring tx_ring[CLDMA_TXQ_NUM];\n\tstruct cldma_ring rx_ring[CLDMA_RXQ_NUM];\n\tstruct md_pm_entity *pm_entity;\n\tstruct t7xx_cldma_hw hw_info;\n\tbool is_late_init;\n\tint (*recv_skb)(struct cldma_queue *queue, struct sk_buff *skb);\n};\n\n#define GPD_FLAGS_HWO\t\tBIT(0)\n#define GPD_FLAGS_IOC\t\tBIT(7)\n#define GPD_DMAPOOL_ALIGN\t16\n\n#define CLDMA_MTU\t\t3584\t \n\nint t7xx_cldma_alloc(enum cldma_id hif_id, struct t7xx_pci_dev *t7xx_dev);\nvoid t7xx_cldma_hif_hw_init(struct cldma_ctrl *md_ctrl);\nint t7xx_cldma_init(struct cldma_ctrl *md_ctrl);\nvoid t7xx_cldma_exit(struct cldma_ctrl *md_ctrl);\nvoid t7xx_cldma_switch_cfg(struct cldma_ctrl *md_ctrl);\nvoid t7xx_cldma_start(struct cldma_ctrl *md_ctrl);\nint t7xx_cldma_stop(struct cldma_ctrl *md_ctrl);\nvoid t7xx_cldma_reset(struct cldma_ctrl *md_ctrl);\nvoid t7xx_cldma_set_recv_skb(struct cldma_ctrl *md_ctrl,\n\t\t\t     int (*recv_skb)(struct cldma_queue *queue, struct sk_buff *skb));\nint t7xx_cldma_send_skb(struct cldma_ctrl *md_ctrl, int qno, struct sk_buff *skb);\nvoid t7xx_cldma_stop_all_qs(struct cldma_ctrl *md_ctrl, enum mtk_txrx tx_rx);\nvoid t7xx_cldma_clear_all_qs(struct cldma_ctrl *md_ctrl, enum mtk_txrx tx_rx);\n\n#endif  \n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}