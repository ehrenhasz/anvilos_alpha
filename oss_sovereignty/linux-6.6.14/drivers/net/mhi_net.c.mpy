{
  "module_name": "mhi_net.c",
  "hash_id": "187330a48950627d150a3f8f956a071fde9dd7460c3c70a0e0e7eba678348abb",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/mhi_net.c",
  "human_readable_source": "\n \n\n#include <linux/if_arp.h>\n#include <linux/mhi.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/skbuff.h>\n#include <linux/u64_stats_sync.h>\n\n#define MHI_NET_MIN_MTU\t\tETH_MIN_MTU\n#define MHI_NET_MAX_MTU\t\t0xffff\n#define MHI_NET_DEFAULT_MTU\t0x4000\n\nstruct mhi_net_stats {\n\tu64_stats_t rx_packets;\n\tu64_stats_t rx_bytes;\n\tu64_stats_t rx_errors;\n\tu64_stats_t tx_packets;\n\tu64_stats_t tx_bytes;\n\tu64_stats_t tx_errors;\n\tu64_stats_t tx_dropped;\n\tstruct u64_stats_sync tx_syncp;\n\tstruct u64_stats_sync rx_syncp;\n};\n\nstruct mhi_net_dev {\n\tstruct mhi_device *mdev;\n\tstruct net_device *ndev;\n\tstruct sk_buff *skbagg_head;\n\tstruct sk_buff *skbagg_tail;\n\tstruct delayed_work rx_refill;\n\tstruct mhi_net_stats stats;\n\tu32 rx_queue_sz;\n\tint msg_enable;\n\tunsigned int mru;\n};\n\nstruct mhi_device_info {\n\tconst char *netname;\n};\n\nstatic int mhi_ndo_open(struct net_device *ndev)\n{\n\tstruct mhi_net_dev *mhi_netdev = netdev_priv(ndev);\n\n\t \n\tschedule_delayed_work(&mhi_netdev->rx_refill, 0);\n\n\t \n\tnetif_carrier_on(ndev);\n\n\tnetif_start_queue(ndev);\n\n\treturn 0;\n}\n\nstatic int mhi_ndo_stop(struct net_device *ndev)\n{\n\tstruct mhi_net_dev *mhi_netdev = netdev_priv(ndev);\n\n\tnetif_stop_queue(ndev);\n\tnetif_carrier_off(ndev);\n\tcancel_delayed_work_sync(&mhi_netdev->rx_refill);\n\n\treturn 0;\n}\n\nstatic netdev_tx_t mhi_ndo_xmit(struct sk_buff *skb, struct net_device *ndev)\n{\n\tstruct mhi_net_dev *mhi_netdev = netdev_priv(ndev);\n\tstruct mhi_device *mdev = mhi_netdev->mdev;\n\tint err;\n\n\terr = mhi_queue_skb(mdev, DMA_TO_DEVICE, skb, skb->len, MHI_EOT);\n\tif (unlikely(err)) {\n\t\tnet_err_ratelimited(\"%s: Failed to queue TX buf (%d)\\n\",\n\t\t\t\t    ndev->name, err);\n\t\tdev_kfree_skb_any(skb);\n\t\tgoto exit_drop;\n\t}\n\n\tif (mhi_queue_is_full(mdev, DMA_TO_DEVICE))\n\t\tnetif_stop_queue(ndev);\n\n\treturn NETDEV_TX_OK;\n\nexit_drop:\n\tu64_stats_update_begin(&mhi_netdev->stats.tx_syncp);\n\tu64_stats_inc(&mhi_netdev->stats.tx_dropped);\n\tu64_stats_update_end(&mhi_netdev->stats.tx_syncp);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void mhi_ndo_get_stats64(struct net_device *ndev,\n\t\t\t\tstruct rtnl_link_stats64 *stats)\n{\n\tstruct mhi_net_dev *mhi_netdev = netdev_priv(ndev);\n\tunsigned int start;\n\n\tdo {\n\t\tstart = u64_stats_fetch_begin(&mhi_netdev->stats.rx_syncp);\n\t\tstats->rx_packets = u64_stats_read(&mhi_netdev->stats.rx_packets);\n\t\tstats->rx_bytes = u64_stats_read(&mhi_netdev->stats.rx_bytes);\n\t\tstats->rx_errors = u64_stats_read(&mhi_netdev->stats.rx_errors);\n\t} while (u64_stats_fetch_retry(&mhi_netdev->stats.rx_syncp, start));\n\n\tdo {\n\t\tstart = u64_stats_fetch_begin(&mhi_netdev->stats.tx_syncp);\n\t\tstats->tx_packets = u64_stats_read(&mhi_netdev->stats.tx_packets);\n\t\tstats->tx_bytes = u64_stats_read(&mhi_netdev->stats.tx_bytes);\n\t\tstats->tx_errors = u64_stats_read(&mhi_netdev->stats.tx_errors);\n\t\tstats->tx_dropped = u64_stats_read(&mhi_netdev->stats.tx_dropped);\n\t} while (u64_stats_fetch_retry(&mhi_netdev->stats.tx_syncp, start));\n}\n\nstatic const struct net_device_ops mhi_netdev_ops = {\n\t.ndo_open               = mhi_ndo_open,\n\t.ndo_stop               = mhi_ndo_stop,\n\t.ndo_start_xmit         = mhi_ndo_xmit,\n\t.ndo_get_stats64\t= mhi_ndo_get_stats64,\n};\n\nstatic void mhi_net_setup(struct net_device *ndev)\n{\n\tndev->header_ops = NULL;   \n\tndev->type = ARPHRD_RAWIP;\n\tndev->hard_header_len = 0;\n\tndev->addr_len = 0;\n\tndev->flags = IFF_POINTOPOINT | IFF_NOARP;\n\tndev->netdev_ops = &mhi_netdev_ops;\n\tndev->mtu = MHI_NET_DEFAULT_MTU;\n\tndev->min_mtu = MHI_NET_MIN_MTU;\n\tndev->max_mtu = MHI_NET_MAX_MTU;\n\tndev->tx_queue_len = 1000;\n}\n\nstatic struct sk_buff *mhi_net_skb_agg(struct mhi_net_dev *mhi_netdev,\n\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct sk_buff *head = mhi_netdev->skbagg_head;\n\tstruct sk_buff *tail = mhi_netdev->skbagg_tail;\n\n\t \n\tif (!head) {\n\t\tmhi_netdev->skbagg_head = skb;\n\t\treturn skb;\n\t}\n\n\tif (!skb_shinfo(head)->frag_list)\n\t\tskb_shinfo(head)->frag_list = skb;\n\telse\n\t\ttail->next = skb;\n\n\thead->len += skb->len;\n\thead->data_len += skb->len;\n\thead->truesize += skb->truesize;\n\n\tmhi_netdev->skbagg_tail = skb;\n\n\treturn mhi_netdev->skbagg_head;\n}\n\nstatic void mhi_net_dl_callback(struct mhi_device *mhi_dev,\n\t\t\t\tstruct mhi_result *mhi_res)\n{\n\tstruct mhi_net_dev *mhi_netdev = dev_get_drvdata(&mhi_dev->dev);\n\tstruct sk_buff *skb = mhi_res->buf_addr;\n\tint free_desc_count;\n\n\tfree_desc_count = mhi_get_free_desc_count(mhi_dev, DMA_FROM_DEVICE);\n\n\tif (unlikely(mhi_res->transaction_status)) {\n\t\tswitch (mhi_res->transaction_status) {\n\t\tcase -EOVERFLOW:\n\t\t\t \n\t\t\tnetdev_warn_once(mhi_netdev->ndev,\n\t\t\t\t\t \"Fragmented packets received, fix MTU?\\n\");\n\t\t\tskb_put(skb, mhi_res->bytes_xferd);\n\t\t\tmhi_net_skb_agg(mhi_netdev, skb);\n\t\t\tbreak;\n\t\tcase -ENOTCONN:\n\t\t\t \n\t\t\tdev_kfree_skb_any(skb);\n\t\t\treturn;\n\t\tdefault:\n\t\t\t \n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tu64_stats_update_begin(&mhi_netdev->stats.rx_syncp);\n\t\t\tu64_stats_inc(&mhi_netdev->stats.rx_errors);\n\t\t\tu64_stats_update_end(&mhi_netdev->stats.rx_syncp);\n\t\t}\n\t} else {\n\t\tskb_put(skb, mhi_res->bytes_xferd);\n\n\t\tif (mhi_netdev->skbagg_head) {\n\t\t\t \n\t\t\tskb = mhi_net_skb_agg(mhi_netdev, skb);\n\t\t\tmhi_netdev->skbagg_head = NULL;\n\t\t}\n\n\t\tswitch (skb->data[0] & 0xf0) {\n\t\tcase 0x40:\n\t\t\tskb->protocol = htons(ETH_P_IP);\n\t\t\tbreak;\n\t\tcase 0x60:\n\t\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tskb->protocol = htons(ETH_P_MAP);\n\t\t\tbreak;\n\t\t}\n\n\t\tu64_stats_update_begin(&mhi_netdev->stats.rx_syncp);\n\t\tu64_stats_inc(&mhi_netdev->stats.rx_packets);\n\t\tu64_stats_add(&mhi_netdev->stats.rx_bytes, skb->len);\n\t\tu64_stats_update_end(&mhi_netdev->stats.rx_syncp);\n\t\t__netif_rx(skb);\n\t}\n\n\t \n\tif (free_desc_count >= mhi_netdev->rx_queue_sz / 2)\n\t\tschedule_delayed_work(&mhi_netdev->rx_refill, 0);\n}\n\nstatic void mhi_net_ul_callback(struct mhi_device *mhi_dev,\n\t\t\t\tstruct mhi_result *mhi_res)\n{\n\tstruct mhi_net_dev *mhi_netdev = dev_get_drvdata(&mhi_dev->dev);\n\tstruct net_device *ndev = mhi_netdev->ndev;\n\tstruct mhi_device *mdev = mhi_netdev->mdev;\n\tstruct sk_buff *skb = mhi_res->buf_addr;\n\n\t \n\tdev_consume_skb_any(skb);\n\n\tu64_stats_update_begin(&mhi_netdev->stats.tx_syncp);\n\tif (unlikely(mhi_res->transaction_status)) {\n\t\t \n\t\tif (mhi_res->transaction_status == -ENOTCONN) {\n\t\t\tu64_stats_update_end(&mhi_netdev->stats.tx_syncp);\n\t\t\treturn;\n\t\t}\n\n\t\tu64_stats_inc(&mhi_netdev->stats.tx_errors);\n\t} else {\n\t\tu64_stats_inc(&mhi_netdev->stats.tx_packets);\n\t\tu64_stats_add(&mhi_netdev->stats.tx_bytes, mhi_res->bytes_xferd);\n\t}\n\tu64_stats_update_end(&mhi_netdev->stats.tx_syncp);\n\n\tif (netif_queue_stopped(ndev) && !mhi_queue_is_full(mdev, DMA_TO_DEVICE))\n\t\tnetif_wake_queue(ndev);\n}\n\nstatic void mhi_net_rx_refill_work(struct work_struct *work)\n{\n\tstruct mhi_net_dev *mhi_netdev = container_of(work, struct mhi_net_dev,\n\t\t\t\t\t\t      rx_refill.work);\n\tstruct net_device *ndev = mhi_netdev->ndev;\n\tstruct mhi_device *mdev = mhi_netdev->mdev;\n\tstruct sk_buff *skb;\n\tunsigned int size;\n\tint err;\n\n\tsize = mhi_netdev->mru ? mhi_netdev->mru : READ_ONCE(ndev->mtu);\n\n\twhile (!mhi_queue_is_full(mdev, DMA_FROM_DEVICE)) {\n\t\tskb = netdev_alloc_skb(ndev, size);\n\t\tif (unlikely(!skb))\n\t\t\tbreak;\n\n\t\terr = mhi_queue_skb(mdev, DMA_FROM_DEVICE, skb, size, MHI_EOT);\n\t\tif (unlikely(err)) {\n\t\t\tnet_err_ratelimited(\"%s: Failed to queue RX buf (%d)\\n\",\n\t\t\t\t\t    ndev->name, err);\n\t\t\tkfree_skb(skb);\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tcond_resched();\n\t}\n\n\t \n\tif (mhi_get_free_desc_count(mdev, DMA_FROM_DEVICE) == mhi_netdev->rx_queue_sz)\n\t\tschedule_delayed_work(&mhi_netdev->rx_refill, HZ / 2);\n}\n\nstatic int mhi_net_newlink(struct mhi_device *mhi_dev, struct net_device *ndev)\n{\n\tstruct mhi_net_dev *mhi_netdev;\n\tint err;\n\n\tmhi_netdev = netdev_priv(ndev);\n\n\tdev_set_drvdata(&mhi_dev->dev, mhi_netdev);\n\tmhi_netdev->ndev = ndev;\n\tmhi_netdev->mdev = mhi_dev;\n\tmhi_netdev->skbagg_head = NULL;\n\tmhi_netdev->mru = mhi_dev->mhi_cntrl->mru;\n\n\tINIT_DELAYED_WORK(&mhi_netdev->rx_refill, mhi_net_rx_refill_work);\n\tu64_stats_init(&mhi_netdev->stats.rx_syncp);\n\tu64_stats_init(&mhi_netdev->stats.tx_syncp);\n\n\t \n\terr = mhi_prepare_for_transfer(mhi_dev);\n\tif (err)\n\t\treturn err;\n\n\t \n\tmhi_netdev->rx_queue_sz = mhi_get_free_desc_count(mhi_dev, DMA_FROM_DEVICE);\n\n\terr = register_netdev(ndev);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}\n\nstatic void mhi_net_dellink(struct mhi_device *mhi_dev, struct net_device *ndev)\n{\n\tstruct mhi_net_dev *mhi_netdev = netdev_priv(ndev);\n\n\tunregister_netdev(ndev);\n\n\tmhi_unprepare_from_transfer(mhi_dev);\n\n\tkfree_skb(mhi_netdev->skbagg_head);\n\n\tfree_netdev(ndev);\n\n\tdev_set_drvdata(&mhi_dev->dev, NULL);\n}\n\nstatic int mhi_net_probe(struct mhi_device *mhi_dev,\n\t\t\t const struct mhi_device_id *id)\n{\n\tconst struct mhi_device_info *info = (struct mhi_device_info *)id->driver_data;\n\tstruct net_device *ndev;\n\tint err;\n\n\tndev = alloc_netdev(sizeof(struct mhi_net_dev), info->netname,\n\t\t\t    NET_NAME_PREDICTABLE, mhi_net_setup);\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tSET_NETDEV_DEV(ndev, &mhi_dev->dev);\n\n\terr = mhi_net_newlink(mhi_dev, ndev);\n\tif (err) {\n\t\tfree_netdev(ndev);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}\n\nstatic void mhi_net_remove(struct mhi_device *mhi_dev)\n{\n\tstruct mhi_net_dev *mhi_netdev = dev_get_drvdata(&mhi_dev->dev);\n\n\tmhi_net_dellink(mhi_dev, mhi_netdev->ndev);\n}\n\nstatic const struct mhi_device_info mhi_hwip0 = {\n\t.netname = \"mhi_hwip%d\",\n};\n\nstatic const struct mhi_device_info mhi_swip0 = {\n\t.netname = \"mhi_swip%d\",\n};\n\nstatic const struct mhi_device_id mhi_net_id_table[] = {\n\t \n\t{ .chan = \"IP_HW0\", .driver_data = (kernel_ulong_t)&mhi_hwip0 },\n\t \n\t{ .chan = \"IP_SW0\", .driver_data = (kernel_ulong_t)&mhi_swip0 },\n\t{}\n};\nMODULE_DEVICE_TABLE(mhi, mhi_net_id_table);\n\nstatic struct mhi_driver mhi_net_driver = {\n\t.probe = mhi_net_probe,\n\t.remove = mhi_net_remove,\n\t.dl_xfer_cb = mhi_net_dl_callback,\n\t.ul_xfer_cb = mhi_net_ul_callback,\n\t.id_table = mhi_net_id_table,\n\t.driver = {\n\t\t.name = \"mhi_net\",\n\t},\n};\n\nmodule_mhi_driver(mhi_net_driver);\n\nMODULE_AUTHOR(\"Loic Poulain <loic.poulain@linaro.org>\");\nMODULE_DESCRIPTION(\"Network over MHI\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}