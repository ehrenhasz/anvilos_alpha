{
  "module_name": "queueing.c",
  "hash_id": "7c9a4d98987c813270366a678b305bb81bbe2f77d3be3da284e5ff6cdfc39271",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireguard/queueing.c",
  "human_readable_source": "\n \n\n#include \"queueing.h\"\n#include <linux/skb_array.h>\n\nstruct multicore_worker __percpu *\nwg_packet_percpu_multicore_worker_alloc(work_func_t function, void *ptr)\n{\n\tint cpu;\n\tstruct multicore_worker __percpu *worker = alloc_percpu(struct multicore_worker);\n\n\tif (!worker)\n\t\treturn NULL;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tper_cpu_ptr(worker, cpu)->ptr = ptr;\n\t\tINIT_WORK(&per_cpu_ptr(worker, cpu)->work, function);\n\t}\n\treturn worker;\n}\n\nint wg_packet_queue_init(struct crypt_queue *queue, work_func_t function,\n\t\t\t unsigned int len)\n{\n\tint ret;\n\n\tmemset(queue, 0, sizeof(*queue));\n\tqueue->last_cpu = -1;\n\tret = ptr_ring_init(&queue->ring, len, GFP_KERNEL);\n\tif (ret)\n\t\treturn ret;\n\tqueue->worker = wg_packet_percpu_multicore_worker_alloc(function, queue);\n\tif (!queue->worker) {\n\t\tptr_ring_cleanup(&queue->ring, NULL);\n\t\treturn -ENOMEM;\n\t}\n\treturn 0;\n}\n\nvoid wg_packet_queue_free(struct crypt_queue *queue, bool purge)\n{\n\tfree_percpu(queue->worker);\n\tWARN_ON(!purge && !__ptr_ring_empty(&queue->ring));\n\tptr_ring_cleanup(&queue->ring, purge ? __skb_array_destroy_skb : NULL);\n}\n\n#define NEXT(skb) ((skb)->prev)\n#define STUB(queue) ((struct sk_buff *)&queue->empty)\n\nvoid wg_prev_queue_init(struct prev_queue *queue)\n{\n\tNEXT(STUB(queue)) = NULL;\n\tqueue->head = queue->tail = STUB(queue);\n\tqueue->peeked = NULL;\n\tatomic_set(&queue->count, 0);\n\tBUILD_BUG_ON(\n\t\toffsetof(struct sk_buff, next) != offsetof(struct prev_queue, empty.next) -\n\t\t\t\t\t\t\toffsetof(struct prev_queue, empty) ||\n\t\toffsetof(struct sk_buff, prev) != offsetof(struct prev_queue, empty.prev) -\n\t\t\t\t\t\t\t offsetof(struct prev_queue, empty));\n}\n\nstatic void __wg_prev_queue_enqueue(struct prev_queue *queue, struct sk_buff *skb)\n{\n\tWRITE_ONCE(NEXT(skb), NULL);\n\tWRITE_ONCE(NEXT(xchg_release(&queue->head, skb)), skb);\n}\n\nbool wg_prev_queue_enqueue(struct prev_queue *queue, struct sk_buff *skb)\n{\n\tif (!atomic_add_unless(&queue->count, 1, MAX_QUEUED_PACKETS))\n\t\treturn false;\n\t__wg_prev_queue_enqueue(queue, skb);\n\treturn true;\n}\n\nstruct sk_buff *wg_prev_queue_dequeue(struct prev_queue *queue)\n{\n\tstruct sk_buff *tail = queue->tail, *next = smp_load_acquire(&NEXT(tail));\n\n\tif (tail == STUB(queue)) {\n\t\tif (!next)\n\t\t\treturn NULL;\n\t\tqueue->tail = next;\n\t\ttail = next;\n\t\tnext = smp_load_acquire(&NEXT(next));\n\t}\n\tif (next) {\n\t\tqueue->tail = next;\n\t\tatomic_dec(&queue->count);\n\t\treturn tail;\n\t}\n\tif (tail != READ_ONCE(queue->head))\n\t\treturn NULL;\n\t__wg_prev_queue_enqueue(queue, STUB(queue));\n\tnext = smp_load_acquire(&NEXT(tail));\n\tif (next) {\n\t\tqueue->tail = next;\n\t\tatomic_dec(&queue->count);\n\t\treturn tail;\n\t}\n\treturn NULL;\n}\n\n#undef NEXT\n#undef STUB\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}