{
  "module_name": "peerlookup.c",
  "hash_id": "d4d5fc3550eb09f93877095f85bfa0ee377afc405ff6274c8f7fb238252990b8",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireguard/peerlookup.c",
  "human_readable_source": "\n \n\n#include \"peerlookup.h\"\n#include \"peer.h\"\n#include \"noise.h\"\n\nstatic struct hlist_head *pubkey_bucket(struct pubkey_hashtable *table,\n\t\t\t\t\tconst u8 pubkey[NOISE_PUBLIC_KEY_LEN])\n{\n\t \n\tconst u64 hash = siphash(pubkey, NOISE_PUBLIC_KEY_LEN, &table->key);\n\n\treturn &table->hashtable[hash & (HASH_SIZE(table->hashtable) - 1)];\n}\n\nstruct pubkey_hashtable *wg_pubkey_hashtable_alloc(void)\n{\n\tstruct pubkey_hashtable *table = kvmalloc(sizeof(*table), GFP_KERNEL);\n\n\tif (!table)\n\t\treturn NULL;\n\n\tget_random_bytes(&table->key, sizeof(table->key));\n\thash_init(table->hashtable);\n\tmutex_init(&table->lock);\n\treturn table;\n}\n\nvoid wg_pubkey_hashtable_add(struct pubkey_hashtable *table,\n\t\t\t     struct wg_peer *peer)\n{\n\tmutex_lock(&table->lock);\n\thlist_add_head_rcu(&peer->pubkey_hash,\n\t\t\t   pubkey_bucket(table, peer->handshake.remote_static));\n\tmutex_unlock(&table->lock);\n}\n\nvoid wg_pubkey_hashtable_remove(struct pubkey_hashtable *table,\n\t\t\t\tstruct wg_peer *peer)\n{\n\tmutex_lock(&table->lock);\n\thlist_del_init_rcu(&peer->pubkey_hash);\n\tmutex_unlock(&table->lock);\n}\n\n \nstruct wg_peer *\nwg_pubkey_hashtable_lookup(struct pubkey_hashtable *table,\n\t\t\t   const u8 pubkey[NOISE_PUBLIC_KEY_LEN])\n{\n\tstruct wg_peer *iter_peer, *peer = NULL;\n\n\trcu_read_lock_bh();\n\thlist_for_each_entry_rcu_bh(iter_peer, pubkey_bucket(table, pubkey),\n\t\t\t\t    pubkey_hash) {\n\t\tif (!memcmp(pubkey, iter_peer->handshake.remote_static,\n\t\t\t    NOISE_PUBLIC_KEY_LEN)) {\n\t\t\tpeer = iter_peer;\n\t\t\tbreak;\n\t\t}\n\t}\n\tpeer = wg_peer_get_maybe_zero(peer);\n\trcu_read_unlock_bh();\n\treturn peer;\n}\n\nstatic struct hlist_head *index_bucket(struct index_hashtable *table,\n\t\t\t\t       const __le32 index)\n{\n\t \n\treturn &table->hashtable[(__force u32)index &\n\t\t\t\t (HASH_SIZE(table->hashtable) - 1)];\n}\n\nstruct index_hashtable *wg_index_hashtable_alloc(void)\n{\n\tstruct index_hashtable *table = kvmalloc(sizeof(*table), GFP_KERNEL);\n\n\tif (!table)\n\t\treturn NULL;\n\n\thash_init(table->hashtable);\n\tspin_lock_init(&table->lock);\n\treturn table;\n}\n\n \n\n__le32 wg_index_hashtable_insert(struct index_hashtable *table,\n\t\t\t\t struct index_hashtable_entry *entry)\n{\n\tstruct index_hashtable_entry *existing_entry;\n\n\tspin_lock_bh(&table->lock);\n\thlist_del_init_rcu(&entry->index_hash);\n\tspin_unlock_bh(&table->lock);\n\n\trcu_read_lock_bh();\n\nsearch_unused_slot:\n\t \n\tentry->index = (__force __le32)get_random_u32();\n\thlist_for_each_entry_rcu_bh(existing_entry,\n\t\t\t\t    index_bucket(table, entry->index),\n\t\t\t\t    index_hash) {\n\t\tif (existing_entry->index == entry->index)\n\t\t\t \n\t\t\tgoto search_unused_slot;\n\t}\n\n\t \n\tspin_lock_bh(&table->lock);\n\thlist_for_each_entry_rcu_bh(existing_entry,\n\t\t\t\t    index_bucket(table, entry->index),\n\t\t\t\t    index_hash) {\n\t\tif (existing_entry->index == entry->index) {\n\t\t\tspin_unlock_bh(&table->lock);\n\t\t\t \n\t\t\tgoto search_unused_slot;\n\t\t}\n\t}\n\t \n\thlist_add_head_rcu(&entry->index_hash,\n\t\t\t   index_bucket(table, entry->index));\n\tspin_unlock_bh(&table->lock);\n\n\trcu_read_unlock_bh();\n\n\treturn entry->index;\n}\n\nbool wg_index_hashtable_replace(struct index_hashtable *table,\n\t\t\t\tstruct index_hashtable_entry *old,\n\t\t\t\tstruct index_hashtable_entry *new)\n{\n\tbool ret;\n\n\tspin_lock_bh(&table->lock);\n\tret = !hlist_unhashed(&old->index_hash);\n\tif (unlikely(!ret))\n\t\tgoto out;\n\n\tnew->index = old->index;\n\thlist_replace_rcu(&old->index_hash, &new->index_hash);\n\n\t \n\tINIT_HLIST_NODE(&old->index_hash);\nout:\n\tspin_unlock_bh(&table->lock);\n\treturn ret;\n}\n\nvoid wg_index_hashtable_remove(struct index_hashtable *table,\n\t\t\t       struct index_hashtable_entry *entry)\n{\n\tspin_lock_bh(&table->lock);\n\thlist_del_init_rcu(&entry->index_hash);\n\tspin_unlock_bh(&table->lock);\n}\n\n \nstruct index_hashtable_entry *\nwg_index_hashtable_lookup(struct index_hashtable *table,\n\t\t\t  const enum index_hashtable_type type_mask,\n\t\t\t  const __le32 index, struct wg_peer **peer)\n{\n\tstruct index_hashtable_entry *iter_entry, *entry = NULL;\n\n\trcu_read_lock_bh();\n\thlist_for_each_entry_rcu_bh(iter_entry, index_bucket(table, index),\n\t\t\t\t    index_hash) {\n\t\tif (iter_entry->index == index) {\n\t\t\tif (likely(iter_entry->type & type_mask))\n\t\t\t\tentry = iter_entry;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (likely(entry)) {\n\t\tentry->peer = wg_peer_get_maybe_zero(entry->peer);\n\t\tif (likely(entry->peer))\n\t\t\t*peer = entry->peer;\n\t\telse\n\t\t\tentry = NULL;\n\t}\n\trcu_read_unlock_bh();\n\treturn entry;\n}\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}