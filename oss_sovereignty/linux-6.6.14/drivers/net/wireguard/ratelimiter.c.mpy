{
  "module_name": "ratelimiter.c",
  "hash_id": "ed6e16be5a144c5972e242828d6f690a5020e546263543835800ed3b6c1e0ed4",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/wireguard/ratelimiter.c",
  "human_readable_source": "\n \n\n#include \"ratelimiter.h\"\n#include <linux/siphash.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <net/ip.h>\n\nstatic struct kmem_cache *entry_cache;\nstatic hsiphash_key_t key;\nstatic spinlock_t table_lock = __SPIN_LOCK_UNLOCKED(\"ratelimiter_table_lock\");\nstatic DEFINE_MUTEX(init_lock);\nstatic u64 init_refcnt;  \nstatic atomic_t total_entries = ATOMIC_INIT(0);\nstatic unsigned int max_entries, table_size;\nstatic void wg_ratelimiter_gc_entries(struct work_struct *);\nstatic DECLARE_DEFERRABLE_WORK(gc_work, wg_ratelimiter_gc_entries);\nstatic struct hlist_head *table_v4;\n#if IS_ENABLED(CONFIG_IPV6)\nstatic struct hlist_head *table_v6;\n#endif\n\nstruct ratelimiter_entry {\n\tu64 last_time_ns, tokens, ip;\n\tvoid *net;\n\tspinlock_t lock;\n\tstruct hlist_node hash;\n\tstruct rcu_head rcu;\n};\n\nenum {\n\tPACKETS_PER_SECOND = 20,\n\tPACKETS_BURSTABLE = 5,\n\tPACKET_COST = NSEC_PER_SEC / PACKETS_PER_SECOND,\n\tTOKEN_MAX = PACKET_COST * PACKETS_BURSTABLE\n};\n\nstatic void entry_free(struct rcu_head *rcu)\n{\n\tkmem_cache_free(entry_cache,\n\t\t\tcontainer_of(rcu, struct ratelimiter_entry, rcu));\n\tatomic_dec(&total_entries);\n}\n\nstatic void entry_uninit(struct ratelimiter_entry *entry)\n{\n\thlist_del_rcu(&entry->hash);\n\tcall_rcu(&entry->rcu, entry_free);\n}\n\n \nstatic void wg_ratelimiter_gc_entries(struct work_struct *work)\n{\n\tconst u64 now = ktime_get_coarse_boottime_ns();\n\tstruct ratelimiter_entry *entry;\n\tstruct hlist_node *temp;\n\tunsigned int i;\n\n\tfor (i = 0; i < table_size; ++i) {\n\t\tspin_lock(&table_lock);\n\t\thlist_for_each_entry_safe(entry, temp, &table_v4[i], hash) {\n\t\t\tif (unlikely(!work) ||\n\t\t\t    now - entry->last_time_ns > NSEC_PER_SEC)\n\t\t\t\tentry_uninit(entry);\n\t\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\t\thlist_for_each_entry_safe(entry, temp, &table_v6[i], hash) {\n\t\t\tif (unlikely(!work) ||\n\t\t\t    now - entry->last_time_ns > NSEC_PER_SEC)\n\t\t\t\tentry_uninit(entry);\n\t\t}\n#endif\n\t\tspin_unlock(&table_lock);\n\t\tif (likely(work))\n\t\t\tcond_resched();\n\t}\n\tif (likely(work))\n\t\tqueue_delayed_work(system_power_efficient_wq, &gc_work, HZ);\n}\n\nbool wg_ratelimiter_allow(struct sk_buff *skb, struct net *net)\n{\n\t \n\tconst u32 net_word = (unsigned long)net;\n\tstruct ratelimiter_entry *entry;\n\tstruct hlist_head *bucket;\n\tu64 ip;\n\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\tip = (u64 __force)ip_hdr(skb)->saddr;\n\t\tbucket = &table_v4[hsiphash_2u32(net_word, ip, &key) &\n\t\t\t\t   (table_size - 1)];\n\t}\n#if IS_ENABLED(CONFIG_IPV6)\n\telse if (skb->protocol == htons(ETH_P_IPV6)) {\n\t\t \n\t\tmemcpy(&ip, &ipv6_hdr(skb)->saddr, sizeof(ip));\n\t\tbucket = &table_v6[hsiphash_3u32(net_word, ip >> 32, ip, &key) &\n\t\t\t\t   (table_size - 1)];\n\t}\n#endif\n\telse\n\t\treturn false;\n\trcu_read_lock();\n\thlist_for_each_entry_rcu(entry, bucket, hash) {\n\t\tif (entry->net == net && entry->ip == ip) {\n\t\t\tu64 now, tokens;\n\t\t\tbool ret;\n\t\t\t \n\t\t\tspin_lock(&entry->lock);\n\t\t\tnow = ktime_get_coarse_boottime_ns();\n\t\t\ttokens = min_t(u64, TOKEN_MAX,\n\t\t\t\t       entry->tokens + now -\n\t\t\t\t\t       entry->last_time_ns);\n\t\t\tentry->last_time_ns = now;\n\t\t\tret = tokens >= PACKET_COST;\n\t\t\tentry->tokens = ret ? tokens - PACKET_COST : tokens;\n\t\t\tspin_unlock(&entry->lock);\n\t\t\trcu_read_unlock();\n\t\t\treturn ret;\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\tif (atomic_inc_return(&total_entries) > max_entries)\n\t\tgoto err_oom;\n\n\tentry = kmem_cache_alloc(entry_cache, GFP_KERNEL);\n\tif (unlikely(!entry))\n\t\tgoto err_oom;\n\n\tentry->net = net;\n\tentry->ip = ip;\n\tINIT_HLIST_NODE(&entry->hash);\n\tspin_lock_init(&entry->lock);\n\tentry->last_time_ns = ktime_get_coarse_boottime_ns();\n\tentry->tokens = TOKEN_MAX - PACKET_COST;\n\tspin_lock(&table_lock);\n\thlist_add_head_rcu(&entry->hash, bucket);\n\tspin_unlock(&table_lock);\n\treturn true;\n\nerr_oom:\n\tatomic_dec(&total_entries);\n\treturn false;\n}\n\nint wg_ratelimiter_init(void)\n{\n\tmutex_lock(&init_lock);\n\tif (++init_refcnt != 1)\n\t\tgoto out;\n\n\tentry_cache = KMEM_CACHE(ratelimiter_entry, 0);\n\tif (!entry_cache)\n\t\tgoto err;\n\n\t \n\ttable_size = (totalram_pages() > (1U << 30) / PAGE_SIZE) ? 8192 :\n\t\tmax_t(unsigned long, 16, roundup_pow_of_two(\n\t\t\t(totalram_pages() << PAGE_SHIFT) /\n\t\t\t(1U << 14) / sizeof(struct hlist_head)));\n\tmax_entries = table_size * 8;\n\n\ttable_v4 = kvcalloc(table_size, sizeof(*table_v4), GFP_KERNEL);\n\tif (unlikely(!table_v4))\n\t\tgoto err_kmemcache;\n\n#if IS_ENABLED(CONFIG_IPV6)\n\ttable_v6 = kvcalloc(table_size, sizeof(*table_v6), GFP_KERNEL);\n\tif (unlikely(!table_v6)) {\n\t\tkvfree(table_v4);\n\t\tgoto err_kmemcache;\n\t}\n#endif\n\n\tqueue_delayed_work(system_power_efficient_wq, &gc_work, HZ);\n\tget_random_bytes(&key, sizeof(key));\nout:\n\tmutex_unlock(&init_lock);\n\treturn 0;\n\nerr_kmemcache:\n\tkmem_cache_destroy(entry_cache);\nerr:\n\t--init_refcnt;\n\tmutex_unlock(&init_lock);\n\treturn -ENOMEM;\n}\n\nvoid wg_ratelimiter_uninit(void)\n{\n\tmutex_lock(&init_lock);\n\tif (!init_refcnt || --init_refcnt)\n\t\tgoto out;\n\n\tcancel_delayed_work_sync(&gc_work);\n\twg_ratelimiter_gc_entries(NULL);\n\trcu_barrier();\n\tkvfree(table_v4);\n#if IS_ENABLED(CONFIG_IPV6)\n\tkvfree(table_v6);\n#endif\n\tkmem_cache_destroy(entry_cache);\nout:\n\tmutex_unlock(&init_lock);\n}\n\n#include \"selftest/ratelimiter.c\"\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}