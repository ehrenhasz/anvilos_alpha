{
  "module_name": "fec_main.c",
  "hash_id": "857deed09a762769aab9b89d7fbfaf6292c2d7a6be2e345ffd9ce93eeedc81db",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/freescale/fec_main.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/pm_runtime.h>\n#include <linux/ptrace.h>\n#include <linux/errno.h>\n#include <linux/ioport.h>\n#include <linux/slab.h>\n#include <linux/interrupt.h>\n#include <linux/delay.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/in.h>\n#include <linux/ip.h>\n#include <net/ip.h>\n#include <net/page_pool/helpers.h>\n#include <net/selftests.h>\n#include <net/tso.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <linux/icmp.h>\n#include <linux/spinlock.h>\n#include <linux/workqueue.h>\n#include <linux/bitops.h>\n#include <linux/io.h>\n#include <linux/irq.h>\n#include <linux/clk.h>\n#include <linux/crc32.h>\n#include <linux/platform_device.h>\n#include <linux/mdio.h>\n#include <linux/phy.h>\n#include <linux/fec.h>\n#include <linux/of.h>\n#include <linux/of_device.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n#include <linux/regulator/consumer.h>\n#include <linux/if_vlan.h>\n#include <linux/pinctrl/consumer.h>\n#include <linux/gpio/consumer.h>\n#include <linux/prefetch.h>\n#include <linux/mfd/syscon.h>\n#include <linux/regmap.h>\n#include <soc/imx/cpuidle.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bpf_trace.h>\n\n#include <asm/cacheflush.h>\n\n#include \"fec.h\"\n\nstatic void set_multicast_list(struct net_device *ndev);\nstatic void fec_enet_itr_coal_set(struct net_device *ndev);\nstatic int fec_enet_xdp_tx_xmit(struct fec_enet_private *fep,\n\t\t\t\tint cpu, struct xdp_buff *xdp,\n\t\t\t\tu32 dma_sync_len);\n\n#define DRIVER_NAME\t\"fec\"\n\nstatic const u16 fec_enet_vlan_pri_to_queue[8] = {0, 0, 1, 1, 1, 2, 2, 2};\n\n \n#define FEC_ENET_FCE\t(1 << 5)\n#define FEC_ENET_RSEM_V\t0x84\n#define FEC_ENET_RSFL_V\t16\n#define FEC_ENET_RAEM_V\t0x8\n#define FEC_ENET_RAFL_V\t0x8\n#define FEC_ENET_OPD_V\t0xFFF0\n#define FEC_MDIO_PM_TIMEOUT  100  \n\n#define FEC_ENET_XDP_PASS          0\n#define FEC_ENET_XDP_CONSUMED      BIT(0)\n#define FEC_ENET_XDP_TX            BIT(1)\n#define FEC_ENET_XDP_REDIR         BIT(2)\n\nstruct fec_devinfo {\n\tu32 quirks;\n};\n\nstatic const struct fec_devinfo fec_imx25_info = {\n\t.quirks = FEC_QUIRK_USE_GASKET | FEC_QUIRK_MIB_CLEAR |\n\t\t  FEC_QUIRK_HAS_FRREG | FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_imx27_info = {\n\t.quirks = FEC_QUIRK_MIB_CLEAR | FEC_QUIRK_HAS_FRREG |\n\t\t  FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_imx28_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_SWAP_FRAME |\n\t\t  FEC_QUIRK_SINGLE_MDIO | FEC_QUIRK_HAS_RACC |\n\t\t  FEC_QUIRK_HAS_FRREG | FEC_QUIRK_CLEAR_SETUP_MII |\n\t\t  FEC_QUIRK_NO_HARD_RESET | FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_imx6q_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_HAS_GBIT |\n\t\t  FEC_QUIRK_HAS_BUFDESC_EX | FEC_QUIRK_HAS_CSUM |\n\t\t  FEC_QUIRK_HAS_VLAN | FEC_QUIRK_ERR006358 |\n\t\t  FEC_QUIRK_HAS_RACC | FEC_QUIRK_CLEAR_SETUP_MII |\n\t\t  FEC_QUIRK_HAS_PMQOS | FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_mvf600_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_HAS_RACC |\n\t\t  FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_imx6x_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_HAS_GBIT |\n\t\t  FEC_QUIRK_HAS_BUFDESC_EX | FEC_QUIRK_HAS_CSUM |\n\t\t  FEC_QUIRK_HAS_VLAN | FEC_QUIRK_HAS_AVB |\n\t\t  FEC_QUIRK_ERR007885 | FEC_QUIRK_BUG_CAPTURE |\n\t\t  FEC_QUIRK_HAS_RACC | FEC_QUIRK_HAS_COALESCE |\n\t\t  FEC_QUIRK_CLEAR_SETUP_MII | FEC_QUIRK_HAS_MULTI_QUEUES |\n\t\t  FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_imx6ul_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_HAS_GBIT |\n\t\t  FEC_QUIRK_HAS_BUFDESC_EX | FEC_QUIRK_HAS_CSUM |\n\t\t  FEC_QUIRK_HAS_VLAN | FEC_QUIRK_ERR007885 |\n\t\t  FEC_QUIRK_BUG_CAPTURE | FEC_QUIRK_HAS_RACC |\n\t\t  FEC_QUIRK_HAS_COALESCE | FEC_QUIRK_CLEAR_SETUP_MII |\n\t\t  FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_imx8mq_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_HAS_GBIT |\n\t\t  FEC_QUIRK_HAS_BUFDESC_EX | FEC_QUIRK_HAS_CSUM |\n\t\t  FEC_QUIRK_HAS_VLAN | FEC_QUIRK_HAS_AVB |\n\t\t  FEC_QUIRK_ERR007885 | FEC_QUIRK_BUG_CAPTURE |\n\t\t  FEC_QUIRK_HAS_RACC | FEC_QUIRK_HAS_COALESCE |\n\t\t  FEC_QUIRK_CLEAR_SETUP_MII | FEC_QUIRK_HAS_MULTI_QUEUES |\n\t\t  FEC_QUIRK_HAS_EEE | FEC_QUIRK_WAKEUP_FROM_INT2 |\n\t\t  FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_imx8qm_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_HAS_GBIT |\n\t\t  FEC_QUIRK_HAS_BUFDESC_EX | FEC_QUIRK_HAS_CSUM |\n\t\t  FEC_QUIRK_HAS_VLAN | FEC_QUIRK_HAS_AVB |\n\t\t  FEC_QUIRK_ERR007885 | FEC_QUIRK_BUG_CAPTURE |\n\t\t  FEC_QUIRK_HAS_RACC | FEC_QUIRK_HAS_COALESCE |\n\t\t  FEC_QUIRK_CLEAR_SETUP_MII | FEC_QUIRK_HAS_MULTI_QUEUES |\n\t\t  FEC_QUIRK_DELAYED_CLKS_SUPPORT | FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic const struct fec_devinfo fec_s32v234_info = {\n\t.quirks = FEC_QUIRK_ENET_MAC | FEC_QUIRK_HAS_GBIT |\n\t\t  FEC_QUIRK_HAS_BUFDESC_EX | FEC_QUIRK_HAS_CSUM |\n\t\t  FEC_QUIRK_HAS_VLAN | FEC_QUIRK_HAS_AVB |\n\t\t  FEC_QUIRK_ERR007885 | FEC_QUIRK_BUG_CAPTURE |\n\t\t  FEC_QUIRK_HAS_MDIO_C45,\n};\n\nstatic struct platform_device_id fec_devtype[] = {\n\t{\n\t\t \n\t\t.name = DRIVER_NAME,\n\t\t.driver_data = 0,\n\t}, {\n\t\t.name = \"imx25-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx25_info,\n\t}, {\n\t\t.name = \"imx27-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx27_info,\n\t}, {\n\t\t.name = \"imx28-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx28_info,\n\t}, {\n\t\t.name = \"imx6q-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx6q_info,\n\t}, {\n\t\t.name = \"mvf600-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_mvf600_info,\n\t}, {\n\t\t.name = \"imx6sx-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx6x_info,\n\t}, {\n\t\t.name = \"imx6ul-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx6ul_info,\n\t}, {\n\t\t.name = \"imx8mq-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx8mq_info,\n\t}, {\n\t\t.name = \"imx8qm-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_imx8qm_info,\n\t}, {\n\t\t.name = \"s32v234-fec\",\n\t\t.driver_data = (kernel_ulong_t)&fec_s32v234_info,\n\t}, {\n\t\t \n\t}\n};\nMODULE_DEVICE_TABLE(platform, fec_devtype);\n\nenum imx_fec_type {\n\tIMX25_FEC = 1,\t \n\tIMX27_FEC,\t \n\tIMX28_FEC,\n\tIMX6Q_FEC,\n\tMVF600_FEC,\n\tIMX6SX_FEC,\n\tIMX6UL_FEC,\n\tIMX8MQ_FEC,\n\tIMX8QM_FEC,\n\tS32V234_FEC,\n};\n\nstatic const struct of_device_id fec_dt_ids[] = {\n\t{ .compatible = \"fsl,imx25-fec\", .data = &fec_devtype[IMX25_FEC], },\n\t{ .compatible = \"fsl,imx27-fec\", .data = &fec_devtype[IMX27_FEC], },\n\t{ .compatible = \"fsl,imx28-fec\", .data = &fec_devtype[IMX28_FEC], },\n\t{ .compatible = \"fsl,imx6q-fec\", .data = &fec_devtype[IMX6Q_FEC], },\n\t{ .compatible = \"fsl,mvf600-fec\", .data = &fec_devtype[MVF600_FEC], },\n\t{ .compatible = \"fsl,imx6sx-fec\", .data = &fec_devtype[IMX6SX_FEC], },\n\t{ .compatible = \"fsl,imx6ul-fec\", .data = &fec_devtype[IMX6UL_FEC], },\n\t{ .compatible = \"fsl,imx8mq-fec\", .data = &fec_devtype[IMX8MQ_FEC], },\n\t{ .compatible = \"fsl,imx8qm-fec\", .data = &fec_devtype[IMX8QM_FEC], },\n\t{ .compatible = \"fsl,s32v234-fec\", .data = &fec_devtype[S32V234_FEC], },\n\t{   }\n};\nMODULE_DEVICE_TABLE(of, fec_dt_ids);\n\nstatic unsigned char macaddr[ETH_ALEN];\nmodule_param_array(macaddr, byte, NULL, 0);\nMODULE_PARM_DESC(macaddr, \"FEC Ethernet MAC address\");\n\n#if defined(CONFIG_M5272)\n \n#if defined(CONFIG_NETtel)\n#define\tFEC_FLASHMAC\t0xf0006006\n#elif defined(CONFIG_GILBARCONAP) || defined(CONFIG_SCALES)\n#define\tFEC_FLASHMAC\t0xf0006000\n#elif defined(CONFIG_CANCam)\n#define\tFEC_FLASHMAC\t0xf0020000\n#elif defined (CONFIG_M5272C3)\n#define\tFEC_FLASHMAC\t(0xffe04000 + 4)\n#elif defined(CONFIG_MOD5272)\n#define FEC_FLASHMAC\t0xffc0406b\n#else\n#define\tFEC_FLASHMAC\t0\n#endif\n#endif  \n\n \n#define PKT_MAXBUF_SIZE\t\t(round_down(2048 - 64, 64))\n#define PKT_MINBUF_SIZE\t\t64\n\n \n#define FEC_RACC_IPDIS\t\t(1 << 1)\n#define FEC_RACC_PRODIS\t\t(1 << 2)\n#define FEC_RACC_SHIFT16\tBIT(7)\n#define FEC_RACC_OPTIONS\t(FEC_RACC_IPDIS | FEC_RACC_PRODIS)\n\n \n#define FEC_MIB_CTRLSTAT_DISABLE\tBIT(31)\n\n \n#if defined(CONFIG_M523x) || defined(CONFIG_M527x) || defined(CONFIG_M528x) || \\\n    defined(CONFIG_M520x) || defined(CONFIG_M532x) || defined(CONFIG_ARM) || \\\n    defined(CONFIG_ARM64)\n#define\tOPT_FRAME_SIZE\t(PKT_MAXBUF_SIZE << 16)\n#else\n#define\tOPT_FRAME_SIZE\t0\n#endif\n\n \n#define FEC_MMFR_ST\t\t(1 << 30)\n#define FEC_MMFR_ST_C45\t\t(0)\n#define FEC_MMFR_OP_READ\t(2 << 28)\n#define FEC_MMFR_OP_READ_C45\t(3 << 28)\n#define FEC_MMFR_OP_WRITE\t(1 << 28)\n#define FEC_MMFR_OP_ADDR_WRITE\t(0)\n#define FEC_MMFR_PA(v)\t\t((v & 0x1f) << 23)\n#define FEC_MMFR_RA(v)\t\t((v & 0x1f) << 18)\n#define FEC_MMFR_TA\t\t(2 << 16)\n#define FEC_MMFR_DATA(v)\t(v & 0xffff)\n \n#define FEC_ECR_MAGICEN\t\t(1 << 2)\n#define FEC_ECR_SLEEP\t\t(1 << 3)\n\n#define FEC_MII_TIMEOUT\t\t30000  \n\n \n#define TX_TIMEOUT (2 * HZ)\n\n#define FEC_PAUSE_FLAG_AUTONEG\t0x1\n#define FEC_PAUSE_FLAG_ENABLE\t0x2\n#define FEC_WOL_HAS_MAGIC_PACKET\t(0x1 << 0)\n#define FEC_WOL_FLAG_ENABLE\t\t(0x1 << 1)\n#define FEC_WOL_FLAG_SLEEP_ON\t\t(0x1 << 2)\n\n \n#define FEC_MAX_TSO_SEGS\t100\n#define FEC_MAX_SKB_DESCS\t(FEC_MAX_TSO_SEGS * 2 + MAX_SKB_FRAGS)\n\n#define IS_TSO_HEADER(txq, addr) \\\n\t((addr >= txq->tso_hdrs_dma) && \\\n\t(addr < txq->tso_hdrs_dma + txq->bd.ring_size * TSO_HEADER_SIZE))\n\nstatic int mii_cnt;\n\nstatic struct bufdesc *fec_enet_get_nextdesc(struct bufdesc *bdp,\n\t\t\t\t\t     struct bufdesc_prop *bd)\n{\n\treturn (bdp >= bd->last) ? bd->base\n\t\t\t: (struct bufdesc *)(((void *)bdp) + bd->dsize);\n}\n\nstatic struct bufdesc *fec_enet_get_prevdesc(struct bufdesc *bdp,\n\t\t\t\t\t     struct bufdesc_prop *bd)\n{\n\treturn (bdp <= bd->base) ? bd->last\n\t\t\t: (struct bufdesc *)(((void *)bdp) - bd->dsize);\n}\n\nstatic int fec_enet_get_bd_index(struct bufdesc *bdp,\n\t\t\t\t struct bufdesc_prop *bd)\n{\n\treturn ((const char *)bdp - (const char *)bd->base) >> bd->dsize_log2;\n}\n\nstatic int fec_enet_get_free_txdesc_num(struct fec_enet_priv_tx_q *txq)\n{\n\tint entries;\n\n\tentries = (((const char *)txq->dirty_tx -\n\t\t\t(const char *)txq->bd.cur) >> txq->bd.dsize_log2) - 1;\n\n\treturn entries >= 0 ? entries : entries + txq->bd.ring_size;\n}\n\nstatic void swap_buffer(void *bufaddr, int len)\n{\n\tint i;\n\tunsigned int *buf = bufaddr;\n\n\tfor (i = 0; i < len; i += 4, buf++)\n\t\tswab32s(buf);\n}\n\nstatic void fec_dump(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct bufdesc *bdp;\n\tstruct fec_enet_priv_tx_q *txq;\n\tint index = 0;\n\n\tnetdev_info(ndev, \"TX ring dump\\n\");\n\tpr_info(\"Nr     SC     addr       len  SKB\\n\");\n\n\ttxq = fep->tx_queue[0];\n\tbdp = txq->bd.base;\n\n\tdo {\n\t\tpr_info(\"%3u %c%c 0x%04x 0x%08x %4u %p\\n\",\n\t\t\tindex,\n\t\t\tbdp == txq->bd.cur ? 'S' : ' ',\n\t\t\tbdp == txq->dirty_tx ? 'H' : ' ',\n\t\t\tfec16_to_cpu(bdp->cbd_sc),\n\t\t\tfec32_to_cpu(bdp->cbd_bufaddr),\n\t\t\tfec16_to_cpu(bdp->cbd_datlen),\n\t\t\ttxq->tx_buf[index].buf_p);\n\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\t\tindex++;\n\t} while (bdp != txq->bd.base);\n}\n\nstatic inline bool is_ipv4_pkt(struct sk_buff *skb)\n{\n\treturn skb->protocol == htons(ETH_P_IP) && ip_hdr(skb)->version == 4;\n}\n\nstatic int\nfec_enet_clear_csum(struct sk_buff *skb, struct net_device *ndev)\n{\n\t \n\tif (skb->ip_summed != CHECKSUM_PARTIAL)\n\t\treturn 0;\n\n\tif (unlikely(skb_cow_head(skb, 0)))\n\t\treturn -1;\n\n\tif (is_ipv4_pkt(skb))\n\t\tip_hdr(skb)->check = 0;\n\t*(__sum16 *)(skb->head + skb->csum_start + skb->csum_offset) = 0;\n\n\treturn 0;\n}\n\nstatic int\nfec_enet_create_page_pool(struct fec_enet_private *fep,\n\t\t\t  struct fec_enet_priv_rx_q *rxq, int size)\n{\n\tstruct bpf_prog *xdp_prog = READ_ONCE(fep->xdp_prog);\n\tstruct page_pool_params pp_params = {\n\t\t.order = 0,\n\t\t.flags = PP_FLAG_DMA_MAP | PP_FLAG_DMA_SYNC_DEV,\n\t\t.pool_size = size,\n\t\t.nid = dev_to_node(&fep->pdev->dev),\n\t\t.dev = &fep->pdev->dev,\n\t\t.dma_dir = xdp_prog ? DMA_BIDIRECTIONAL : DMA_FROM_DEVICE,\n\t\t.offset = FEC_ENET_XDP_HEADROOM,\n\t\t.max_len = FEC_ENET_RX_FRSIZE,\n\t};\n\tint err;\n\n\trxq->page_pool = page_pool_create(&pp_params);\n\tif (IS_ERR(rxq->page_pool)) {\n\t\terr = PTR_ERR(rxq->page_pool);\n\t\trxq->page_pool = NULL;\n\t\treturn err;\n\t}\n\n\terr = xdp_rxq_info_reg(&rxq->xdp_rxq, fep->netdev, rxq->id, 0);\n\tif (err < 0)\n\t\tgoto err_free_pp;\n\n\terr = xdp_rxq_info_reg_mem_model(&rxq->xdp_rxq, MEM_TYPE_PAGE_POOL,\n\t\t\t\t\t rxq->page_pool);\n\tif (err)\n\t\tgoto err_unregister_rxq;\n\n\treturn 0;\n\nerr_unregister_rxq:\n\txdp_rxq_info_unreg(&rxq->xdp_rxq);\nerr_free_pp:\n\tpage_pool_destroy(rxq->page_pool);\n\trxq->page_pool = NULL;\n\treturn err;\n}\n\nstatic struct bufdesc *\nfec_enet_txq_submit_frag_skb(struct fec_enet_priv_tx_q *txq,\n\t\t\t     struct sk_buff *skb,\n\t\t\t     struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct bufdesc *bdp = txq->bd.cur;\n\tstruct bufdesc_ex *ebdp;\n\tint nr_frags = skb_shinfo(skb)->nr_frags;\n\tint frag, frag_len;\n\tunsigned short status;\n\tunsigned int estatus = 0;\n\tskb_frag_t *this_frag;\n\tunsigned int index;\n\tvoid *bufaddr;\n\tdma_addr_t addr;\n\tint i;\n\n\tfor (frag = 0; frag < nr_frags; frag++) {\n\t\tthis_frag = &skb_shinfo(skb)->frags[frag];\n\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\t\tebdp = (struct bufdesc_ex *)bdp;\n\n\t\tstatus = fec16_to_cpu(bdp->cbd_sc);\n\t\tstatus &= ~BD_ENET_TX_STATS;\n\t\tstatus |= (BD_ENET_TX_TC | BD_ENET_TX_READY);\n\t\tfrag_len = skb_frag_size(&skb_shinfo(skb)->frags[frag]);\n\n\t\t \n\t\tif (frag == nr_frags - 1) {\n\t\t\tstatus |= (BD_ENET_TX_INTR | BD_ENET_TX_LAST);\n\t\t\tif (fep->bufdesc_ex) {\n\t\t\t\testatus |= BD_ENET_TX_INT;\n\t\t\t\tif (unlikely(skb_shinfo(skb)->tx_flags &\n\t\t\t\t\tSKBTX_HW_TSTAMP && fep->hwts_tx_en))\n\t\t\t\t\testatus |= BD_ENET_TX_TS;\n\t\t\t}\n\t\t}\n\n\t\tif (fep->bufdesc_ex) {\n\t\t\tif (fep->quirks & FEC_QUIRK_HAS_AVB)\n\t\t\t\testatus |= FEC_TX_BD_FTYPE(txq->bd.qid);\n\t\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\t\testatus |= BD_ENET_TX_PINS | BD_ENET_TX_IINS;\n\n\t\t\tebdp->cbd_bdu = 0;\n\t\t\tebdp->cbd_esc = cpu_to_fec32(estatus);\n\t\t}\n\n\t\tbufaddr = skb_frag_address(this_frag);\n\n\t\tindex = fec_enet_get_bd_index(bdp, &txq->bd);\n\t\tif (((unsigned long) bufaddr) & fep->tx_align ||\n\t\t\tfep->quirks & FEC_QUIRK_SWAP_FRAME) {\n\t\t\tmemcpy(txq->tx_bounce[index], bufaddr, frag_len);\n\t\t\tbufaddr = txq->tx_bounce[index];\n\n\t\t\tif (fep->quirks & FEC_QUIRK_SWAP_FRAME)\n\t\t\t\tswap_buffer(bufaddr, frag_len);\n\t\t}\n\n\t\taddr = dma_map_single(&fep->pdev->dev, bufaddr, frag_len,\n\t\t\t\t      DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&fep->pdev->dev, addr)) {\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetdev_err(ndev, \"Tx DMA memory map failed\\n\");\n\t\t\tgoto dma_mapping_error;\n\t\t}\n\n\t\tbdp->cbd_bufaddr = cpu_to_fec32(addr);\n\t\tbdp->cbd_datlen = cpu_to_fec16(frag_len);\n\t\t \n\t\twmb();\n\t\tbdp->cbd_sc = cpu_to_fec16(status);\n\t}\n\n\treturn bdp;\ndma_mapping_error:\n\tbdp = txq->bd.cur;\n\tfor (i = 0; i < frag; i++) {\n\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\t\tdma_unmap_single(&fep->pdev->dev, fec32_to_cpu(bdp->cbd_bufaddr),\n\t\t\t\t fec16_to_cpu(bdp->cbd_datlen), DMA_TO_DEVICE);\n\t}\n\treturn ERR_PTR(-ENOMEM);\n}\n\nstatic int fec_enet_txq_submit_skb(struct fec_enet_priv_tx_q *txq,\n\t\t\t\t   struct sk_buff *skb, struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint nr_frags = skb_shinfo(skb)->nr_frags;\n\tstruct bufdesc *bdp, *last_bdp;\n\tvoid *bufaddr;\n\tdma_addr_t addr;\n\tunsigned short status;\n\tunsigned short buflen;\n\tunsigned int estatus = 0;\n\tunsigned int index;\n\tint entries_free;\n\n\tentries_free = fec_enet_get_free_txdesc_num(txq);\n\tif (entries_free < MAX_SKB_FRAGS + 1) {\n\t\tdev_kfree_skb_any(skb);\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ndev, \"NOT enough BD for SG!\\n\");\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\t \n\tif (fec_enet_clear_csum(skb, ndev)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\t \n\tbdp = txq->bd.cur;\n\tlast_bdp = bdp;\n\tstatus = fec16_to_cpu(bdp->cbd_sc);\n\tstatus &= ~BD_ENET_TX_STATS;\n\n\t \n\tbufaddr = skb->data;\n\tbuflen = skb_headlen(skb);\n\n\tindex = fec_enet_get_bd_index(bdp, &txq->bd);\n\tif (((unsigned long) bufaddr) & fep->tx_align ||\n\t\tfep->quirks & FEC_QUIRK_SWAP_FRAME) {\n\t\tmemcpy(txq->tx_bounce[index], skb->data, buflen);\n\t\tbufaddr = txq->tx_bounce[index];\n\n\t\tif (fep->quirks & FEC_QUIRK_SWAP_FRAME)\n\t\t\tswap_buffer(bufaddr, buflen);\n\t}\n\n\t \n\taddr = dma_map_single(&fep->pdev->dev, bufaddr, buflen, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&fep->pdev->dev, addr)) {\n\t\tdev_kfree_skb_any(skb);\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ndev, \"Tx DMA memory map failed\\n\");\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tif (nr_frags) {\n\t\tlast_bdp = fec_enet_txq_submit_frag_skb(txq, skb, ndev);\n\t\tif (IS_ERR(last_bdp)) {\n\t\t\tdma_unmap_single(&fep->pdev->dev, addr,\n\t\t\t\t\t buflen, DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\treturn NETDEV_TX_OK;\n\t\t}\n\t} else {\n\t\tstatus |= (BD_ENET_TX_INTR | BD_ENET_TX_LAST);\n\t\tif (fep->bufdesc_ex) {\n\t\t\testatus = BD_ENET_TX_INT;\n\t\t\tif (unlikely(skb_shinfo(skb)->tx_flags &\n\t\t\t\tSKBTX_HW_TSTAMP && fep->hwts_tx_en))\n\t\t\t\testatus |= BD_ENET_TX_TS;\n\t\t}\n\t}\n\tbdp->cbd_bufaddr = cpu_to_fec32(addr);\n\tbdp->cbd_datlen = cpu_to_fec16(buflen);\n\n\tif (fep->bufdesc_ex) {\n\n\t\tstruct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;\n\n\t\tif (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP &&\n\t\t\tfep->hwts_tx_en))\n\t\t\tskb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;\n\n\t\tif (fep->quirks & FEC_QUIRK_HAS_AVB)\n\t\t\testatus |= FEC_TX_BD_FTYPE(txq->bd.qid);\n\n\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\testatus |= BD_ENET_TX_PINS | BD_ENET_TX_IINS;\n\n\t\tebdp->cbd_bdu = 0;\n\t\tebdp->cbd_esc = cpu_to_fec32(estatus);\n\t}\n\n\tindex = fec_enet_get_bd_index(last_bdp, &txq->bd);\n\t \n\ttxq->tx_buf[index].buf_p = skb;\n\n\t \n\twmb();\n\n\t \n\tstatus |= (BD_ENET_TX_READY | BD_ENET_TX_TC);\n\tbdp->cbd_sc = cpu_to_fec16(status);\n\n\t \n\tbdp = fec_enet_get_nextdesc(last_bdp, &txq->bd);\n\n\tskb_tx_timestamp(skb);\n\n\t \n\twmb();\n\ttxq->bd.cur = bdp;\n\n\t \n\twritel(0, txq->bd.reg_desc_active);\n\n\treturn 0;\n}\n\nstatic int\nfec_enet_txq_put_data_tso(struct fec_enet_priv_tx_q *txq, struct sk_buff *skb,\n\t\t\t  struct net_device *ndev,\n\t\t\t  struct bufdesc *bdp, int index, char *data,\n\t\t\t  int size, bool last_tcp, bool is_last)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct bufdesc_ex *ebdp = container_of(bdp, struct bufdesc_ex, desc);\n\tunsigned short status;\n\tunsigned int estatus = 0;\n\tdma_addr_t addr;\n\n\tstatus = fec16_to_cpu(bdp->cbd_sc);\n\tstatus &= ~BD_ENET_TX_STATS;\n\n\tstatus |= (BD_ENET_TX_TC | BD_ENET_TX_READY);\n\n\tif (((unsigned long) data) & fep->tx_align ||\n\t\tfep->quirks & FEC_QUIRK_SWAP_FRAME) {\n\t\tmemcpy(txq->tx_bounce[index], data, size);\n\t\tdata = txq->tx_bounce[index];\n\n\t\tif (fep->quirks & FEC_QUIRK_SWAP_FRAME)\n\t\t\tswap_buffer(data, size);\n\t}\n\n\taddr = dma_map_single(&fep->pdev->dev, data, size, DMA_TO_DEVICE);\n\tif (dma_mapping_error(&fep->pdev->dev, addr)) {\n\t\tdev_kfree_skb_any(skb);\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ndev, \"Tx DMA memory map failed\\n\");\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\tbdp->cbd_datlen = cpu_to_fec16(size);\n\tbdp->cbd_bufaddr = cpu_to_fec32(addr);\n\n\tif (fep->bufdesc_ex) {\n\t\tif (fep->quirks & FEC_QUIRK_HAS_AVB)\n\t\t\testatus |= FEC_TX_BD_FTYPE(txq->bd.qid);\n\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\testatus |= BD_ENET_TX_PINS | BD_ENET_TX_IINS;\n\t\tebdp->cbd_bdu = 0;\n\t\tebdp->cbd_esc = cpu_to_fec32(estatus);\n\t}\n\n\t \n\tif (last_tcp)\n\t\tstatus |= (BD_ENET_TX_LAST | BD_ENET_TX_TC);\n\tif (is_last) {\n\t\tstatus |= BD_ENET_TX_INTR;\n\t\tif (fep->bufdesc_ex)\n\t\t\tebdp->cbd_esc |= cpu_to_fec32(BD_ENET_TX_INT);\n\t}\n\n\tbdp->cbd_sc = cpu_to_fec16(status);\n\n\treturn 0;\n}\n\nstatic int\nfec_enet_txq_put_hdr_tso(struct fec_enet_priv_tx_q *txq,\n\t\t\t struct sk_buff *skb, struct net_device *ndev,\n\t\t\t struct bufdesc *bdp, int index)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint hdr_len = skb_tcp_all_headers(skb);\n\tstruct bufdesc_ex *ebdp = container_of(bdp, struct bufdesc_ex, desc);\n\tvoid *bufaddr;\n\tunsigned long dmabuf;\n\tunsigned short status;\n\tunsigned int estatus = 0;\n\n\tstatus = fec16_to_cpu(bdp->cbd_sc);\n\tstatus &= ~BD_ENET_TX_STATS;\n\tstatus |= (BD_ENET_TX_TC | BD_ENET_TX_READY);\n\n\tbufaddr = txq->tso_hdrs + index * TSO_HEADER_SIZE;\n\tdmabuf = txq->tso_hdrs_dma + index * TSO_HEADER_SIZE;\n\tif (((unsigned long)bufaddr) & fep->tx_align ||\n\t\tfep->quirks & FEC_QUIRK_SWAP_FRAME) {\n\t\tmemcpy(txq->tx_bounce[index], skb->data, hdr_len);\n\t\tbufaddr = txq->tx_bounce[index];\n\n\t\tif (fep->quirks & FEC_QUIRK_SWAP_FRAME)\n\t\t\tswap_buffer(bufaddr, hdr_len);\n\n\t\tdmabuf = dma_map_single(&fep->pdev->dev, bufaddr,\n\t\t\t\t\thdr_len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&fep->pdev->dev, dmabuf)) {\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetdev_err(ndev, \"Tx DMA memory map failed\\n\");\n\t\t\treturn NETDEV_TX_OK;\n\t\t}\n\t}\n\n\tbdp->cbd_bufaddr = cpu_to_fec32(dmabuf);\n\tbdp->cbd_datlen = cpu_to_fec16(hdr_len);\n\n\tif (fep->bufdesc_ex) {\n\t\tif (fep->quirks & FEC_QUIRK_HAS_AVB)\n\t\t\testatus |= FEC_TX_BD_FTYPE(txq->bd.qid);\n\t\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\t\testatus |= BD_ENET_TX_PINS | BD_ENET_TX_IINS;\n\t\tebdp->cbd_bdu = 0;\n\t\tebdp->cbd_esc = cpu_to_fec32(estatus);\n\t}\n\n\tbdp->cbd_sc = cpu_to_fec16(status);\n\n\treturn 0;\n}\n\nstatic int fec_enet_txq_submit_tso(struct fec_enet_priv_tx_q *txq,\n\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t   struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint hdr_len, total_len, data_left;\n\tstruct bufdesc *bdp = txq->bd.cur;\n\tstruct tso_t tso;\n\tunsigned int index = 0;\n\tint ret;\n\n\tif (tso_count_descs(skb) >= fec_enet_get_free_txdesc_num(txq)) {\n\t\tdev_kfree_skb_any(skb);\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ndev, \"NOT enough BD for TSO!\\n\");\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\t \n\tif (fec_enet_clear_csum(skb, ndev)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\n\t \n\thdr_len = tso_start(skb, &tso);\n\n\ttotal_len = skb->len - hdr_len;\n\twhile (total_len > 0) {\n\t\tchar *hdr;\n\n\t\tindex = fec_enet_get_bd_index(bdp, &txq->bd);\n\t\tdata_left = min_t(int, skb_shinfo(skb)->gso_size, total_len);\n\t\ttotal_len -= data_left;\n\n\t\t \n\t\thdr = txq->tso_hdrs + index * TSO_HEADER_SIZE;\n\t\ttso_build_hdr(skb, hdr, &tso, data_left, total_len == 0);\n\t\tret = fec_enet_txq_put_hdr_tso(txq, skb, ndev, bdp, index);\n\t\tif (ret)\n\t\t\tgoto err_release;\n\n\t\twhile (data_left > 0) {\n\t\t\tint size;\n\n\t\t\tsize = min_t(int, tso.size, data_left);\n\t\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\t\t\tindex = fec_enet_get_bd_index(bdp, &txq->bd);\n\t\t\tret = fec_enet_txq_put_data_tso(txq, skb, ndev,\n\t\t\t\t\t\t\tbdp, index,\n\t\t\t\t\t\t\ttso.data, size,\n\t\t\t\t\t\t\tsize == data_left,\n\t\t\t\t\t\t\ttotal_len == 0);\n\t\t\tif (ret)\n\t\t\t\tgoto err_release;\n\n\t\t\tdata_left -= size;\n\t\t\ttso_build_data(skb, &tso, size);\n\t\t}\n\n\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\t}\n\n\t \n\ttxq->tx_buf[index].buf_p = skb;\n\n\tskb_tx_timestamp(skb);\n\ttxq->bd.cur = bdp;\n\n\t \n\tif (!(fep->quirks & FEC_QUIRK_ERR007885) ||\n\t    !readl(txq->bd.reg_desc_active) ||\n\t    !readl(txq->bd.reg_desc_active) ||\n\t    !readl(txq->bd.reg_desc_active) ||\n\t    !readl(txq->bd.reg_desc_active))\n\t\twritel(0, txq->bd.reg_desc_active);\n\n\treturn 0;\n\nerr_release:\n\t \n\treturn ret;\n}\n\nstatic netdev_tx_t\nfec_enet_start_xmit(struct sk_buff *skb, struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint entries_free;\n\tunsigned short queue;\n\tstruct fec_enet_priv_tx_q *txq;\n\tstruct netdev_queue *nq;\n\tint ret;\n\n\tqueue = skb_get_queue_mapping(skb);\n\ttxq = fep->tx_queue[queue];\n\tnq = netdev_get_tx_queue(ndev, queue);\n\n\tif (skb_is_gso(skb))\n\t\tret = fec_enet_txq_submit_tso(txq, skb, ndev);\n\telse\n\t\tret = fec_enet_txq_submit_skb(txq, skb, ndev);\n\tif (ret)\n\t\treturn ret;\n\n\tentries_free = fec_enet_get_free_txdesc_num(txq);\n\tif (entries_free <= txq->tx_stop_threshold)\n\t\tnetif_tx_stop_queue(nq);\n\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic void fec_enet_bd_init(struct net_device *dev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(dev);\n\tstruct fec_enet_priv_tx_q *txq;\n\tstruct fec_enet_priv_rx_q *rxq;\n\tstruct bufdesc *bdp;\n\tunsigned int i;\n\tunsigned int q;\n\n\tfor (q = 0; q < fep->num_rx_queues; q++) {\n\t\t \n\t\trxq = fep->rx_queue[q];\n\t\tbdp = rxq->bd.base;\n\n\t\tfor (i = 0; i < rxq->bd.ring_size; i++) {\n\n\t\t\t \n\t\t\tif (bdp->cbd_bufaddr)\n\t\t\t\tbdp->cbd_sc = cpu_to_fec16(BD_ENET_RX_EMPTY);\n\t\t\telse\n\t\t\t\tbdp->cbd_sc = cpu_to_fec16(0);\n\t\t\tbdp = fec_enet_get_nextdesc(bdp, &rxq->bd);\n\t\t}\n\n\t\t \n\t\tbdp = fec_enet_get_prevdesc(bdp, &rxq->bd);\n\t\tbdp->cbd_sc |= cpu_to_fec16(BD_SC_WRAP);\n\n\t\trxq->bd.cur = rxq->bd.base;\n\t}\n\n\tfor (q = 0; q < fep->num_tx_queues; q++) {\n\t\t \n\t\ttxq = fep->tx_queue[q];\n\t\tbdp = txq->bd.base;\n\t\ttxq->bd.cur = bdp;\n\n\t\tfor (i = 0; i < txq->bd.ring_size; i++) {\n\t\t\t \n\t\t\tbdp->cbd_sc = cpu_to_fec16(0);\n\t\t\tif (txq->tx_buf[i].type == FEC_TXBUF_T_SKB) {\n\t\t\t\tif (bdp->cbd_bufaddr &&\n\t\t\t\t    !IS_TSO_HEADER(txq, fec32_to_cpu(bdp->cbd_bufaddr)))\n\t\t\t\t\tdma_unmap_single(&fep->pdev->dev,\n\t\t\t\t\t\t\t fec32_to_cpu(bdp->cbd_bufaddr),\n\t\t\t\t\t\t\t fec16_to_cpu(bdp->cbd_datlen),\n\t\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\t\tif (txq->tx_buf[i].buf_p)\n\t\t\t\t\tdev_kfree_skb_any(txq->tx_buf[i].buf_p);\n\t\t\t} else if (txq->tx_buf[i].type == FEC_TXBUF_T_XDP_NDO) {\n\t\t\t\tif (bdp->cbd_bufaddr)\n\t\t\t\t\tdma_unmap_single(&fep->pdev->dev,\n\t\t\t\t\t\t\t fec32_to_cpu(bdp->cbd_bufaddr),\n\t\t\t\t\t\t\t fec16_to_cpu(bdp->cbd_datlen),\n\t\t\t\t\t\t\t DMA_TO_DEVICE);\n\n\t\t\t\tif (txq->tx_buf[i].buf_p)\n\t\t\t\t\txdp_return_frame(txq->tx_buf[i].buf_p);\n\t\t\t} else {\n\t\t\t\tstruct page *page = txq->tx_buf[i].buf_p;\n\n\t\t\t\tif (page)\n\t\t\t\t\tpage_pool_put_page(page->pp, page, 0, false);\n\t\t\t}\n\n\t\t\ttxq->tx_buf[i].buf_p = NULL;\n\t\t\t \n\t\t\ttxq->tx_buf[i].type = FEC_TXBUF_T_SKB;\n\t\t\tbdp->cbd_bufaddr = cpu_to_fec32(0);\n\t\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\t\t}\n\n\t\t \n\t\tbdp = fec_enet_get_prevdesc(bdp, &txq->bd);\n\t\tbdp->cbd_sc |= cpu_to_fec16(BD_SC_WRAP);\n\t\ttxq->dirty_tx = bdp;\n\t}\n}\n\nstatic void fec_enet_active_rxring(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint i;\n\n\tfor (i = 0; i < fep->num_rx_queues; i++)\n\t\twritel(0, fep->rx_queue[i]->bd.reg_desc_active);\n}\n\nstatic void fec_enet_enable_ring(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct fec_enet_priv_tx_q *txq;\n\tstruct fec_enet_priv_rx_q *rxq;\n\tint i;\n\n\tfor (i = 0; i < fep->num_rx_queues; i++) {\n\t\trxq = fep->rx_queue[i];\n\t\twritel(rxq->bd.dma, fep->hwp + FEC_R_DES_START(i));\n\t\twritel(PKT_MAXBUF_SIZE, fep->hwp + FEC_R_BUFF_SIZE(i));\n\n\t\t \n\t\tif (i)\n\t\t\twritel(RCMR_MATCHEN | RCMR_CMP(i),\n\t\t\t       fep->hwp + FEC_RCMR(i));\n\t}\n\n\tfor (i = 0; i < fep->num_tx_queues; i++) {\n\t\ttxq = fep->tx_queue[i];\n\t\twritel(txq->bd.dma, fep->hwp + FEC_X_DES_START(i));\n\n\t\t \n\t\tif (i)\n\t\t\twritel(DMA_CLASS_EN | IDLE_SLOPE(i),\n\t\t\t       fep->hwp + FEC_DMA_CFG(i));\n\t}\n}\n\n \nstatic void\nfec_restart(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tu32 temp_mac[2];\n\tu32 rcntl = OPT_FRAME_SIZE | 0x04;\n\tu32 ecntl = 0x2;  \n\n\t \n\tif (fep->quirks & FEC_QUIRK_HAS_MULTI_QUEUES ||\n\t    ((fep->quirks & FEC_QUIRK_NO_HARD_RESET) && fep->link)) {\n\t\twritel(0, fep->hwp + FEC_ECNTRL);\n\t} else {\n\t\twritel(1, fep->hwp + FEC_ECNTRL);\n\t\tudelay(10);\n\t}\n\n\t \n\tmemcpy(&temp_mac, ndev->dev_addr, ETH_ALEN);\n\twritel((__force u32)cpu_to_be32(temp_mac[0]),\n\t       fep->hwp + FEC_ADDR_LOW);\n\twritel((__force u32)cpu_to_be32(temp_mac[1]),\n\t       fep->hwp + FEC_ADDR_HIGH);\n\n\t \n\twritel((0xffffffff & ~FEC_ENET_MII), fep->hwp + FEC_IEVENT);\n\n\tfec_enet_bd_init(ndev);\n\n\tfec_enet_enable_ring(ndev);\n\n\t \n\tif (fep->full_duplex == DUPLEX_FULL) {\n\t\t \n\t\twritel(0x04, fep->hwp + FEC_X_CNTRL);\n\t} else {\n\t\t \n\t\trcntl |= 0x02;\n\t\twritel(0x0, fep->hwp + FEC_X_CNTRL);\n\t}\n\n\t \n\twritel(fep->phy_speed, fep->hwp + FEC_MII_SPEED);\n\n#if !defined(CONFIG_M5272)\n\tif (fep->quirks & FEC_QUIRK_HAS_RACC) {\n\t\tu32 val = readl(fep->hwp + FEC_RACC);\n\n\t\t \n\t\tval |= FEC_RACC_SHIFT16;\n\t\tif (fep->csum_flags & FLAG_RX_CSUM_ENABLED)\n\t\t\t \n\t\t\tval |= FEC_RACC_OPTIONS;\n\t\telse\n\t\t\tval &= ~FEC_RACC_OPTIONS;\n\t\twritel(val, fep->hwp + FEC_RACC);\n\t\twritel(PKT_MAXBUF_SIZE, fep->hwp + FEC_FTRL);\n\t}\n#endif\n\n\t \n\tif (fep->quirks & FEC_QUIRK_ENET_MAC) {\n\t\t \n\t\trcntl |= 0x40000000 | 0x00000020;\n\n\t\t \n\t\tif (fep->phy_interface == PHY_INTERFACE_MODE_RGMII ||\n\t\t    fep->phy_interface == PHY_INTERFACE_MODE_RGMII_ID ||\n\t\t    fep->phy_interface == PHY_INTERFACE_MODE_RGMII_RXID ||\n\t\t    fep->phy_interface == PHY_INTERFACE_MODE_RGMII_TXID)\n\t\t\trcntl |= (1 << 6);\n\t\telse if (fep->phy_interface == PHY_INTERFACE_MODE_RMII)\n\t\t\trcntl |= (1 << 8);\n\t\telse\n\t\t\trcntl &= ~(1 << 8);\n\n\t\t \n\t\tif (ndev->phydev) {\n\t\t\tif (ndev->phydev->speed == SPEED_1000)\n\t\t\t\tecntl |= (1 << 5);\n\t\t\telse if (ndev->phydev->speed == SPEED_100)\n\t\t\t\trcntl &= ~(1 << 9);\n\t\t\telse\n\t\t\t\trcntl |= (1 << 9);\n\t\t}\n\t} else {\n#ifdef FEC_MIIGSK_ENR\n\t\tif (fep->quirks & FEC_QUIRK_USE_GASKET) {\n\t\t\tu32 cfgr;\n\t\t\t \n\t\t\twritel(0, fep->hwp + FEC_MIIGSK_ENR);\n\t\t\twhile (readl(fep->hwp + FEC_MIIGSK_ENR) & 4)\n\t\t\t\tudelay(1);\n\n\t\t\t \n\t\t\tcfgr = (fep->phy_interface == PHY_INTERFACE_MODE_RMII)\n\t\t\t\t? BM_MIIGSK_CFGR_RMII : BM_MIIGSK_CFGR_MII;\n\t\t\tif (ndev->phydev && ndev->phydev->speed == SPEED_10)\n\t\t\t\tcfgr |= BM_MIIGSK_CFGR_FRCONT_10M;\n\t\t\twritel(cfgr, fep->hwp + FEC_MIIGSK_CFGR);\n\n\t\t\t \n\t\t\twritel(2, fep->hwp + FEC_MIIGSK_ENR);\n\t\t}\n#endif\n\t}\n\n#if !defined(CONFIG_M5272)\n\t \n\tif ((fep->pause_flag & FEC_PAUSE_FLAG_ENABLE) ||\n\t    ((fep->pause_flag & FEC_PAUSE_FLAG_AUTONEG) &&\n\t     ndev->phydev && ndev->phydev->pause)) {\n\t\trcntl |= FEC_ENET_FCE;\n\n\t\t \n\t\twritel(FEC_ENET_RSEM_V, fep->hwp + FEC_R_FIFO_RSEM);\n\t\twritel(FEC_ENET_RSFL_V, fep->hwp + FEC_R_FIFO_RSFL);\n\t\twritel(FEC_ENET_RAEM_V, fep->hwp + FEC_R_FIFO_RAEM);\n\t\twritel(FEC_ENET_RAFL_V, fep->hwp + FEC_R_FIFO_RAFL);\n\n\t\t \n\t\twritel(FEC_ENET_OPD_V, fep->hwp + FEC_OPD);\n\t} else {\n\t\trcntl &= ~FEC_ENET_FCE;\n\t}\n#endif  \n\n\twritel(rcntl, fep->hwp + FEC_R_CNTRL);\n\n\t \n\tset_multicast_list(ndev);\n#ifndef CONFIG_M5272\n\twritel(0, fep->hwp + FEC_HASH_TABLE_HIGH);\n\twritel(0, fep->hwp + FEC_HASH_TABLE_LOW);\n#endif\n\n\tif (fep->quirks & FEC_QUIRK_ENET_MAC) {\n\t\t \n\t\tecntl |= (1 << 8);\n\t\t \n\t\twritel(1 << 8, fep->hwp + FEC_X_WMRK);\n\t}\n\n\tif (fep->bufdesc_ex)\n\t\tecntl |= (1 << 4);\n\n\tif (fep->quirks & FEC_QUIRK_DELAYED_CLKS_SUPPORT &&\n\t    fep->rgmii_txc_dly)\n\t\tecntl |= FEC_ENET_TXC_DLY;\n\tif (fep->quirks & FEC_QUIRK_DELAYED_CLKS_SUPPORT &&\n\t    fep->rgmii_rxc_dly)\n\t\tecntl |= FEC_ENET_RXC_DLY;\n\n#ifndef CONFIG_M5272\n\t \n\twritel(0 << 31, fep->hwp + FEC_MIB_CTRLSTAT);\n#endif\n\n\t \n\twritel(ecntl, fep->hwp + FEC_ECNTRL);\n\tfec_enet_active_rxring(ndev);\n\n\tif (fep->bufdesc_ex)\n\t\tfec_ptp_start_cyclecounter(ndev);\n\n\t \n\tif (fep->link)\n\t\twritel(FEC_DEFAULT_IMASK, fep->hwp + FEC_IMASK);\n\telse\n\t\twritel(0, fep->hwp + FEC_IMASK);\n\n\t \n\tif (fep->quirks & FEC_QUIRK_HAS_COALESCE)\n\t\tfec_enet_itr_coal_set(ndev);\n}\n\nstatic int fec_enet_ipc_handle_init(struct fec_enet_private *fep)\n{\n\tif (!(of_machine_is_compatible(\"fsl,imx8qm\") ||\n\t      of_machine_is_compatible(\"fsl,imx8qxp\") ||\n\t      of_machine_is_compatible(\"fsl,imx8dxl\")))\n\t\treturn 0;\n\n\treturn imx_scu_get_handle(&fep->ipc_handle);\n}\n\nstatic void fec_enet_ipg_stop_set(struct fec_enet_private *fep, bool enabled)\n{\n\tstruct device_node *np = fep->pdev->dev.of_node;\n\tu32 rsrc_id, val;\n\tint idx;\n\n\tif (!np || !fep->ipc_handle)\n\t\treturn;\n\n\tidx = of_alias_get_id(np, \"ethernet\");\n\tif (idx < 0)\n\t\tidx = 0;\n\trsrc_id = idx ? IMX_SC_R_ENET_1 : IMX_SC_R_ENET_0;\n\n\tval = enabled ? 1 : 0;\n\timx_sc_misc_set_control(fep->ipc_handle, rsrc_id, IMX_SC_C_IPG_STOP, val);\n}\n\nstatic void fec_enet_stop_mode(struct fec_enet_private *fep, bool enabled)\n{\n\tstruct fec_platform_data *pdata = fep->pdev->dev.platform_data;\n\tstruct fec_stop_mode_gpr *stop_gpr = &fep->stop_gpr;\n\n\tif (stop_gpr->gpr) {\n\t\tif (enabled)\n\t\t\tregmap_update_bits(stop_gpr->gpr, stop_gpr->reg,\n\t\t\t\t\t   BIT(stop_gpr->bit),\n\t\t\t\t\t   BIT(stop_gpr->bit));\n\t\telse\n\t\t\tregmap_update_bits(stop_gpr->gpr, stop_gpr->reg,\n\t\t\t\t\t   BIT(stop_gpr->bit), 0);\n\t} else if (pdata && pdata->sleep_mode_enable) {\n\t\tpdata->sleep_mode_enable(enabled);\n\t} else {\n\t\tfec_enet_ipg_stop_set(fep, enabled);\n\t}\n}\n\nstatic void fec_irqs_disable(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\twritel(0, fep->hwp + FEC_IMASK);\n}\n\nstatic void fec_irqs_disable_except_wakeup(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\twritel(0, fep->hwp + FEC_IMASK);\n\twritel(FEC_ENET_WAKEUP, fep->hwp + FEC_IMASK);\n}\n\nstatic void\nfec_stop(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tu32 rmii_mode = readl(fep->hwp + FEC_R_CNTRL) & (1 << 8);\n\tu32 val;\n\n\t \n\tif (fep->link) {\n\t\twritel(1, fep->hwp + FEC_X_CNTRL);  \n\t\tudelay(10);\n\t\tif (!(readl(fep->hwp + FEC_IEVENT) & FEC_ENET_GRA))\n\t\t\tnetdev_err(ndev, \"Graceful transmit stop did not complete!\\n\");\n\t}\n\n\t \n\tif (!(fep->wol_flag & FEC_WOL_FLAG_SLEEP_ON)) {\n\t\tif (fep->quirks & FEC_QUIRK_HAS_MULTI_QUEUES) {\n\t\t\twritel(0, fep->hwp + FEC_ECNTRL);\n\t\t} else {\n\t\t\twritel(1, fep->hwp + FEC_ECNTRL);\n\t\t\tudelay(10);\n\t\t}\n\t} else {\n\t\tval = readl(fep->hwp + FEC_ECNTRL);\n\t\tval |= (FEC_ECR_MAGICEN | FEC_ECR_SLEEP);\n\t\twritel(val, fep->hwp + FEC_ECNTRL);\n\t}\n\twritel(fep->phy_speed, fep->hwp + FEC_MII_SPEED);\n\twritel(FEC_DEFAULT_IMASK, fep->hwp + FEC_IMASK);\n\n\t \n\tif (fep->quirks & FEC_QUIRK_ENET_MAC &&\n\t\t!(fep->wol_flag & FEC_WOL_FLAG_SLEEP_ON)) {\n\t\twritel(2, fep->hwp + FEC_ECNTRL);\n\t\twritel(rmii_mode, fep->hwp + FEC_R_CNTRL);\n\t}\n}\n\n\nstatic void\nfec_timeout(struct net_device *ndev, unsigned int txqueue)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tfec_dump(ndev);\n\n\tndev->stats.tx_errors++;\n\n\tschedule_work(&fep->tx_timeout_work);\n}\n\nstatic void fec_enet_timeout_work(struct work_struct *work)\n{\n\tstruct fec_enet_private *fep =\n\t\tcontainer_of(work, struct fec_enet_private, tx_timeout_work);\n\tstruct net_device *ndev = fep->netdev;\n\n\trtnl_lock();\n\tif (netif_device_present(ndev) || netif_running(ndev)) {\n\t\tnapi_disable(&fep->napi);\n\t\tnetif_tx_lock_bh(ndev);\n\t\tfec_restart(ndev);\n\t\tnetif_tx_wake_all_queues(ndev);\n\t\tnetif_tx_unlock_bh(ndev);\n\t\tnapi_enable(&fep->napi);\n\t}\n\trtnl_unlock();\n}\n\nstatic void\nfec_enet_hwtstamp(struct fec_enet_private *fep, unsigned ts,\n\tstruct skb_shared_hwtstamps *hwtstamps)\n{\n\tunsigned long flags;\n\tu64 ns;\n\n\tspin_lock_irqsave(&fep->tmreg_lock, flags);\n\tns = timecounter_cyc2time(&fep->tc, ts);\n\tspin_unlock_irqrestore(&fep->tmreg_lock, flags);\n\n\tmemset(hwtstamps, 0, sizeof(*hwtstamps));\n\thwtstamps->hwtstamp = ns_to_ktime(ns);\n}\n\nstatic void\nfec_enet_tx_queue(struct net_device *ndev, u16 queue_id, int budget)\n{\n\tstruct\tfec_enet_private *fep;\n\tstruct xdp_frame *xdpf;\n\tstruct bufdesc *bdp;\n\tunsigned short status;\n\tstruct\tsk_buff\t*skb;\n\tstruct fec_enet_priv_tx_q *txq;\n\tstruct netdev_queue *nq;\n\tint\tindex = 0;\n\tint\tentries_free;\n\tstruct page *page;\n\tint frame_len;\n\n\tfep = netdev_priv(ndev);\n\n\ttxq = fep->tx_queue[queue_id];\n\t \n\tnq = netdev_get_tx_queue(ndev, queue_id);\n\tbdp = txq->dirty_tx;\n\n\t \n\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\n\twhile (bdp != READ_ONCE(txq->bd.cur)) {\n\t\t \n\t\trmb();\n\t\tstatus = fec16_to_cpu(READ_ONCE(bdp->cbd_sc));\n\t\tif (status & BD_ENET_TX_READY)\n\t\t\tbreak;\n\n\t\tindex = fec_enet_get_bd_index(bdp, &txq->bd);\n\n\t\tif (txq->tx_buf[index].type == FEC_TXBUF_T_SKB) {\n\t\t\tskb = txq->tx_buf[index].buf_p;\n\t\t\tif (bdp->cbd_bufaddr &&\n\t\t\t    !IS_TSO_HEADER(txq, fec32_to_cpu(bdp->cbd_bufaddr)))\n\t\t\t\tdma_unmap_single(&fep->pdev->dev,\n\t\t\t\t\t\t fec32_to_cpu(bdp->cbd_bufaddr),\n\t\t\t\t\t\t fec16_to_cpu(bdp->cbd_datlen),\n\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\tbdp->cbd_bufaddr = cpu_to_fec32(0);\n\t\t\tif (!skb)\n\t\t\t\tgoto tx_buf_done;\n\t\t} else {\n\t\t\t \n\t\t\tif (unlikely(!budget))\n\t\t\t\tbreak;\n\n\t\t\tif (txq->tx_buf[index].type == FEC_TXBUF_T_XDP_NDO) {\n\t\t\t\txdpf = txq->tx_buf[index].buf_p;\n\t\t\t\tif (bdp->cbd_bufaddr)\n\t\t\t\t\tdma_unmap_single(&fep->pdev->dev,\n\t\t\t\t\t\t\t fec32_to_cpu(bdp->cbd_bufaddr),\n\t\t\t\t\t\t\t fec16_to_cpu(bdp->cbd_datlen),\n\t\t\t\t\t\t\t DMA_TO_DEVICE);\n\t\t\t} else {\n\t\t\t\tpage = txq->tx_buf[index].buf_p;\n\t\t\t}\n\n\t\t\tbdp->cbd_bufaddr = cpu_to_fec32(0);\n\t\t\tif (unlikely(!txq->tx_buf[index].buf_p)) {\n\t\t\t\ttxq->tx_buf[index].type = FEC_TXBUF_T_SKB;\n\t\t\t\tgoto tx_buf_done;\n\t\t\t}\n\n\t\t\tframe_len = fec16_to_cpu(bdp->cbd_datlen);\n\t\t}\n\n\t\t \n\t\tif (status & (BD_ENET_TX_HB | BD_ENET_TX_LC |\n\t\t\t\t   BD_ENET_TX_RL | BD_ENET_TX_UN |\n\t\t\t\t   BD_ENET_TX_CSL)) {\n\t\t\tndev->stats.tx_errors++;\n\t\t\tif (status & BD_ENET_TX_HB)   \n\t\t\t\tndev->stats.tx_heartbeat_errors++;\n\t\t\tif (status & BD_ENET_TX_LC)   \n\t\t\t\tndev->stats.tx_window_errors++;\n\t\t\tif (status & BD_ENET_TX_RL)   \n\t\t\t\tndev->stats.tx_aborted_errors++;\n\t\t\tif (status & BD_ENET_TX_UN)   \n\t\t\t\tndev->stats.tx_fifo_errors++;\n\t\t\tif (status & BD_ENET_TX_CSL)  \n\t\t\t\tndev->stats.tx_carrier_errors++;\n\t\t} else {\n\t\t\tndev->stats.tx_packets++;\n\n\t\t\tif (txq->tx_buf[index].type == FEC_TXBUF_T_SKB)\n\t\t\t\tndev->stats.tx_bytes += skb->len;\n\t\t\telse\n\t\t\t\tndev->stats.tx_bytes += frame_len;\n\t\t}\n\n\t\t \n\t\tif (status & BD_ENET_TX_DEF)\n\t\t\tndev->stats.collisions++;\n\n\t\tif (txq->tx_buf[index].type == FEC_TXBUF_T_SKB) {\n\t\t\t \n\t\t\tif (unlikely(skb_shinfo(skb)->tx_flags & SKBTX_IN_PROGRESS &&\n\t\t\t\t     fep->hwts_tx_en) && fep->bufdesc_ex) {\n\t\t\t\tstruct skb_shared_hwtstamps shhwtstamps;\n\t\t\t\tstruct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;\n\n\t\t\t\tfec_enet_hwtstamp(fep, fec32_to_cpu(ebdp->ts), &shhwtstamps);\n\t\t\t\tskb_tstamp_tx(skb, &shhwtstamps);\n\t\t\t}\n\n\t\t\t \n\t\t\tnapi_consume_skb(skb, budget);\n\t\t} else if (txq->tx_buf[index].type == FEC_TXBUF_T_XDP_NDO) {\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t} else {  \n\t\t\t \n\t\t\tpage_pool_put_page(page->pp, page, 0, true);\n\t\t}\n\n\t\ttxq->tx_buf[index].buf_p = NULL;\n\t\t \n\t\ttxq->tx_buf[index].type = FEC_TXBUF_T_SKB;\n\ntx_buf_done:\n\t\t \n\t\twmb();\n\t\ttxq->dirty_tx = bdp;\n\n\t\t \n\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\n\t\t \n\t\tif (netif_tx_queue_stopped(nq)) {\n\t\t\tentries_free = fec_enet_get_free_txdesc_num(txq);\n\t\t\tif (entries_free >= txq->tx_wake_threshold)\n\t\t\t\tnetif_tx_wake_queue(nq);\n\t\t}\n\t}\n\n\t \n\tif (bdp != txq->bd.cur &&\n\t    readl(txq->bd.reg_desc_active) == 0)\n\t\twritel(0, txq->bd.reg_desc_active);\n}\n\nstatic void fec_enet_tx(struct net_device *ndev, int budget)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint i;\n\n\t \n\tfor (i = fep->num_tx_queues - 1; i >= 0; i--)\n\t\tfec_enet_tx_queue(ndev, i, budget);\n}\n\nstatic void fec_enet_update_cbd(struct fec_enet_priv_rx_q *rxq,\n\t\t\t\tstruct bufdesc *bdp, int index)\n{\n\tstruct page *new_page;\n\tdma_addr_t phys_addr;\n\n\tnew_page = page_pool_dev_alloc_pages(rxq->page_pool);\n\tWARN_ON(!new_page);\n\trxq->rx_skb_info[index].page = new_page;\n\n\trxq->rx_skb_info[index].offset = FEC_ENET_XDP_HEADROOM;\n\tphys_addr = page_pool_get_dma_addr(new_page) + FEC_ENET_XDP_HEADROOM;\n\tbdp->cbd_bufaddr = cpu_to_fec32(phys_addr);\n}\n\nstatic u32\nfec_enet_run_xdp(struct fec_enet_private *fep, struct bpf_prog *prog,\n\t\t struct xdp_buff *xdp, struct fec_enet_priv_rx_q *rxq, int cpu)\n{\n\tunsigned int sync, len = xdp->data_end - xdp->data;\n\tu32 ret = FEC_ENET_XDP_PASS;\n\tstruct page *page;\n\tint err;\n\tu32 act;\n\n\tact = bpf_prog_run_xdp(prog, xdp);\n\n\t \n\tsync = xdp->data_end - xdp->data;\n\tsync = max(sync, len);\n\n\tswitch (act) {\n\tcase XDP_PASS:\n\t\trxq->stats[RX_XDP_PASS]++;\n\t\tret = FEC_ENET_XDP_PASS;\n\t\tbreak;\n\n\tcase XDP_REDIRECT:\n\t\trxq->stats[RX_XDP_REDIRECT]++;\n\t\terr = xdp_do_redirect(fep->netdev, xdp, prog);\n\t\tif (unlikely(err))\n\t\t\tgoto xdp_err;\n\n\t\tret = FEC_ENET_XDP_REDIR;\n\t\tbreak;\n\n\tcase XDP_TX:\n\t\trxq->stats[RX_XDP_TX]++;\n\t\terr = fec_enet_xdp_tx_xmit(fep, cpu, xdp, sync);\n\t\tif (unlikely(err)) {\n\t\t\trxq->stats[RX_XDP_TX_ERRORS]++;\n\t\t\tgoto xdp_err;\n\t\t}\n\n\t\tret = FEC_ENET_XDP_TX;\n\t\tbreak;\n\n\tdefault:\n\t\tbpf_warn_invalid_xdp_action(fep->netdev, prog, act);\n\t\tfallthrough;\n\n\tcase XDP_ABORTED:\n\t\tfallthrough;     \n\n\tcase XDP_DROP:\n\t\trxq->stats[RX_XDP_DROP]++;\nxdp_err:\n\t\tret = FEC_ENET_XDP_CONSUMED;\n\t\tpage = virt_to_head_page(xdp->data);\n\t\tpage_pool_put_page(rxq->page_pool, page, sync, true);\n\t\tif (act != XDP_DROP)\n\t\t\ttrace_xdp_exception(fep->netdev, prog, act);\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n \nstatic int\nfec_enet_rx_queue(struct net_device *ndev, int budget, u16 queue_id)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct fec_enet_priv_rx_q *rxq;\n\tstruct bufdesc *bdp;\n\tunsigned short status;\n\tstruct  sk_buff *skb;\n\tushort\tpkt_len;\n\t__u8 *data;\n\tint\tpkt_received = 0;\n\tstruct\tbufdesc_ex *ebdp = NULL;\n\tbool\tvlan_packet_rcvd = false;\n\tu16\tvlan_tag;\n\tint\tindex = 0;\n\tbool\tneed_swap = fep->quirks & FEC_QUIRK_SWAP_FRAME;\n\tstruct bpf_prog *xdp_prog = READ_ONCE(fep->xdp_prog);\n\tu32 ret, xdp_result = FEC_ENET_XDP_PASS;\n\tu32 data_start = FEC_ENET_XDP_HEADROOM;\n\tint cpu = smp_processor_id();\n\tstruct xdp_buff xdp;\n\tstruct page *page;\n\tu32 sub_len = 4;\n\n#if !defined(CONFIG_M5272)\n\t \n\tif (fep->quirks & FEC_QUIRK_HAS_RACC) {\n\t\tdata_start += 2;\n\t\tsub_len += 2;\n\t}\n#endif\n\n#ifdef CONFIG_M532x\n\tflush_cache_all();\n#endif\n\trxq = fep->rx_queue[queue_id];\n\n\t \n\tbdp = rxq->bd.cur;\n\txdp_init_buff(&xdp, PAGE_SIZE, &rxq->xdp_rxq);\n\n\twhile (!((status = fec16_to_cpu(bdp->cbd_sc)) & BD_ENET_RX_EMPTY)) {\n\n\t\tif (pkt_received >= budget)\n\t\t\tbreak;\n\t\tpkt_received++;\n\n\t\twritel(FEC_ENET_RXF_GET(queue_id), fep->hwp + FEC_IEVENT);\n\n\t\t \n\t\tstatus ^= BD_ENET_RX_LAST;\n\t\tif (status & (BD_ENET_RX_LG | BD_ENET_RX_SH | BD_ENET_RX_NO |\n\t\t\t   BD_ENET_RX_CR | BD_ENET_RX_OV | BD_ENET_RX_LAST |\n\t\t\t   BD_ENET_RX_CL)) {\n\t\t\tndev->stats.rx_errors++;\n\t\t\tif (status & BD_ENET_RX_OV) {\n\t\t\t\t \n\t\t\t\tndev->stats.rx_fifo_errors++;\n\t\t\t\tgoto rx_processing_done;\n\t\t\t}\n\t\t\tif (status & (BD_ENET_RX_LG | BD_ENET_RX_SH\n\t\t\t\t\t\t| BD_ENET_RX_LAST)) {\n\t\t\t\t \n\t\t\t\tndev->stats.rx_length_errors++;\n\t\t\t\tif (status & BD_ENET_RX_LAST)\n\t\t\t\t\tnetdev_err(ndev, \"rcv is not +last\\n\");\n\t\t\t}\n\t\t\tif (status & BD_ENET_RX_CR)\t \n\t\t\t\tndev->stats.rx_crc_errors++;\n\t\t\t \n\t\t\tif (status & (BD_ENET_RX_NO | BD_ENET_RX_CL))\n\t\t\t\tndev->stats.rx_frame_errors++;\n\t\t\tgoto rx_processing_done;\n\t\t}\n\n\t\t \n\t\tndev->stats.rx_packets++;\n\t\tpkt_len = fec16_to_cpu(bdp->cbd_datlen);\n\t\tndev->stats.rx_bytes += pkt_len;\n\n\t\tindex = fec_enet_get_bd_index(bdp, &rxq->bd);\n\t\tpage = rxq->rx_skb_info[index].page;\n\t\tdma_sync_single_for_cpu(&fep->pdev->dev,\n\t\t\t\t\tfec32_to_cpu(bdp->cbd_bufaddr),\n\t\t\t\t\tpkt_len,\n\t\t\t\t\tDMA_FROM_DEVICE);\n\t\tprefetch(page_address(page));\n\t\tfec_enet_update_cbd(rxq, bdp, index);\n\n\t\tif (xdp_prog) {\n\t\t\txdp_buff_clear_frags_flag(&xdp);\n\t\t\t \n\t\t\txdp_prepare_buff(&xdp, page_address(page),\n\t\t\t\t\t data_start, pkt_len - sub_len, false);\n\t\t\tret = fec_enet_run_xdp(fep, xdp_prog, &xdp, rxq, cpu);\n\t\t\txdp_result |= ret;\n\t\t\tif (ret != FEC_ENET_XDP_PASS)\n\t\t\t\tgoto rx_processing_done;\n\t\t}\n\n\t\t \n\t\tskb = build_skb(page_address(page), PAGE_SIZE);\n\t\tif (unlikely(!skb)) {\n\t\t\tpage_pool_recycle_direct(rxq->page_pool, page);\n\t\t\tndev->stats.rx_dropped++;\n\n\t\t\tnetdev_err_once(ndev, \"build_skb failed!\\n\");\n\t\t\tgoto rx_processing_done;\n\t\t}\n\n\t\tskb_reserve(skb, data_start);\n\t\tskb_put(skb, pkt_len - sub_len);\n\t\tskb_mark_for_recycle(skb);\n\n\t\tif (unlikely(need_swap)) {\n\t\t\tdata = page_address(page) + FEC_ENET_XDP_HEADROOM;\n\t\t\tswap_buffer(data, pkt_len);\n\t\t}\n\t\tdata = skb->data;\n\n\t\t \n\t\tebdp = NULL;\n\t\tif (fep->bufdesc_ex)\n\t\t\tebdp = (struct bufdesc_ex *)bdp;\n\n\t\t \n\t\tvlan_packet_rcvd = false;\n\t\tif ((ndev->features & NETIF_F_HW_VLAN_CTAG_RX) &&\n\t\t    fep->bufdesc_ex &&\n\t\t    (ebdp->cbd_esc & cpu_to_fec32(BD_ENET_RX_VLAN))) {\n\t\t\t \n\t\t\tstruct vlan_hdr *vlan_header =\n\t\t\t\t\t(struct vlan_hdr *) (data + ETH_HLEN);\n\t\t\tvlan_tag = ntohs(vlan_header->h_vlan_TCI);\n\n\t\t\tvlan_packet_rcvd = true;\n\n\t\t\tmemmove(skb->data + VLAN_HLEN, data, ETH_ALEN * 2);\n\t\t\tskb_pull(skb, VLAN_HLEN);\n\t\t}\n\n\t\tskb->protocol = eth_type_trans(skb, ndev);\n\n\t\t \n\t\tif (fep->hwts_rx_en && fep->bufdesc_ex)\n\t\t\tfec_enet_hwtstamp(fep, fec32_to_cpu(ebdp->ts),\n\t\t\t\t\t  skb_hwtstamps(skb));\n\n\t\tif (fep->bufdesc_ex &&\n\t\t    (fep->csum_flags & FLAG_RX_CSUM_ENABLED)) {\n\t\t\tif (!(ebdp->cbd_esc & cpu_to_fec32(FLAG_RX_CSUM_ERROR))) {\n\t\t\t\t \n\t\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\t\t\t} else {\n\t\t\t\tskb_checksum_none_assert(skb);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (vlan_packet_rcvd)\n\t\t\t__vlan_hwaccel_put_tag(skb,\n\t\t\t\t\t       htons(ETH_P_8021Q),\n\t\t\t\t\t       vlan_tag);\n\n\t\tskb_record_rx_queue(skb, queue_id);\n\t\tnapi_gro_receive(&fep->napi, skb);\n\nrx_processing_done:\n\t\t \n\t\tstatus &= ~BD_ENET_RX_STATS;\n\n\t\t \n\t\tstatus |= BD_ENET_RX_EMPTY;\n\n\t\tif (fep->bufdesc_ex) {\n\t\t\tstruct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;\n\n\t\t\tebdp->cbd_esc = cpu_to_fec32(BD_ENET_RX_INT);\n\t\t\tebdp->cbd_prot = 0;\n\t\t\tebdp->cbd_bdu = 0;\n\t\t}\n\t\t \n\t\twmb();\n\t\tbdp->cbd_sc = cpu_to_fec16(status);\n\n\t\t \n\t\tbdp = fec_enet_get_nextdesc(bdp, &rxq->bd);\n\n\t\t \n\t\twritel(0, rxq->bd.reg_desc_active);\n\t}\n\trxq->bd.cur = bdp;\n\n\tif (xdp_result & FEC_ENET_XDP_REDIR)\n\t\txdp_do_flush_map();\n\n\treturn pkt_received;\n}\n\nstatic int fec_enet_rx(struct net_device *ndev, int budget)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint i, done = 0;\n\n\t \n\tfor (i = fep->num_rx_queues - 1; i >= 0; i--)\n\t\tdone += fec_enet_rx_queue(ndev, budget - done, i);\n\n\treturn done;\n}\n\nstatic bool fec_enet_collect_events(struct fec_enet_private *fep)\n{\n\tuint int_events;\n\n\tint_events = readl(fep->hwp + FEC_IEVENT);\n\n\t \n\tint_events &= ~FEC_ENET_MII;\n\n\twritel(int_events, fep->hwp + FEC_IEVENT);\n\n\treturn int_events != 0;\n}\n\nstatic irqreturn_t\nfec_enet_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *ndev = dev_id;\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tirqreturn_t ret = IRQ_NONE;\n\n\tif (fec_enet_collect_events(fep) && fep->link) {\n\t\tret = IRQ_HANDLED;\n\n\t\tif (napi_schedule_prep(&fep->napi)) {\n\t\t\t \n\t\t\twritel(0, fep->hwp + FEC_IMASK);\n\t\t\t__napi_schedule(&fep->napi);\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int fec_enet_rx_napi(struct napi_struct *napi, int budget)\n{\n\tstruct net_device *ndev = napi->dev;\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint done = 0;\n\n\tdo {\n\t\tdone += fec_enet_rx(ndev, budget - done);\n\t\tfec_enet_tx(ndev, budget);\n\t} while ((done < budget) && fec_enet_collect_events(fep));\n\n\tif (done < budget) {\n\t\tnapi_complete_done(napi, done);\n\t\twritel(FEC_DEFAULT_IMASK, fep->hwp + FEC_IMASK);\n\t}\n\n\treturn done;\n}\n\n \nstatic int fec_get_mac(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tunsigned char *iap, tmpaddr[ETH_ALEN];\n\tint ret;\n\n\t \n\tiap = macaddr;\n\n\t \n\tif (!is_valid_ether_addr(iap)) {\n\t\tstruct device_node *np = fep->pdev->dev.of_node;\n\t\tif (np) {\n\t\t\tret = of_get_mac_address(np, tmpaddr);\n\t\t\tif (!ret)\n\t\t\t\tiap = tmpaddr;\n\t\t\telse if (ret == -EPROBE_DEFER)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\t \n\tif (!is_valid_ether_addr(iap)) {\n#ifdef CONFIG_M5272\n\t\tif (FEC_FLASHMAC)\n\t\t\tiap = (unsigned char *)FEC_FLASHMAC;\n#else\n\t\tstruct fec_platform_data *pdata = dev_get_platdata(&fep->pdev->dev);\n\n\t\tif (pdata)\n\t\t\tiap = (unsigned char *)&pdata->mac;\n#endif\n\t}\n\n\t \n\tif (!is_valid_ether_addr(iap)) {\n\t\t*((__be32 *) &tmpaddr[0]) =\n\t\t\tcpu_to_be32(readl(fep->hwp + FEC_ADDR_LOW));\n\t\t*((__be16 *) &tmpaddr[4]) =\n\t\t\tcpu_to_be16(readl(fep->hwp + FEC_ADDR_HIGH) >> 16);\n\t\tiap = &tmpaddr[0];\n\t}\n\n\t \n\tif (!is_valid_ether_addr(iap)) {\n\t\t \n\t\tdev_err(&fep->pdev->dev, \"Invalid MAC address: %pM\\n\", iap);\n\t\teth_hw_addr_random(ndev);\n\t\tdev_info(&fep->pdev->dev, \"Using random MAC address: %pM\\n\",\n\t\t\t ndev->dev_addr);\n\t\treturn 0;\n\t}\n\n\t \n\teth_hw_addr_gen(ndev, iap, iap == macaddr ? fep->dev_id : 0);\n\n\treturn 0;\n}\n\n \n\n \nstatic void fec_enet_adjust_link(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct phy_device *phy_dev = ndev->phydev;\n\tint status_change = 0;\n\n\t \n\tif (!netif_running(ndev) || !netif_device_present(ndev)) {\n\t\tfep->link = 0;\n\t} else if (phy_dev->link) {\n\t\tif (!fep->link) {\n\t\t\tfep->link = phy_dev->link;\n\t\t\tstatus_change = 1;\n\t\t}\n\n\t\tif (fep->full_duplex != phy_dev->duplex) {\n\t\t\tfep->full_duplex = phy_dev->duplex;\n\t\t\tstatus_change = 1;\n\t\t}\n\n\t\tif (phy_dev->speed != fep->speed) {\n\t\t\tfep->speed = phy_dev->speed;\n\t\t\tstatus_change = 1;\n\t\t}\n\n\t\t \n\t\tif (status_change) {\n\t\t\tnapi_disable(&fep->napi);\n\t\t\tnetif_tx_lock_bh(ndev);\n\t\t\tfec_restart(ndev);\n\t\t\tnetif_tx_wake_all_queues(ndev);\n\t\t\tnetif_tx_unlock_bh(ndev);\n\t\t\tnapi_enable(&fep->napi);\n\t\t}\n\t} else {\n\t\tif (fep->link) {\n\t\t\tnapi_disable(&fep->napi);\n\t\t\tnetif_tx_lock_bh(ndev);\n\t\t\tfec_stop(ndev);\n\t\t\tnetif_tx_unlock_bh(ndev);\n\t\t\tnapi_enable(&fep->napi);\n\t\t\tfep->link = phy_dev->link;\n\t\t\tstatus_change = 1;\n\t\t}\n\t}\n\n\tif (status_change)\n\t\tphy_print_status(phy_dev);\n}\n\nstatic int fec_enet_mdio_wait(struct fec_enet_private *fep)\n{\n\tuint ievent;\n\tint ret;\n\n\tret = readl_poll_timeout_atomic(fep->hwp + FEC_IEVENT, ievent,\n\t\t\t\t\tievent & FEC_ENET_MII, 2, 30000);\n\n\tif (!ret)\n\t\twritel(FEC_ENET_MII, fep->hwp + FEC_IEVENT);\n\n\treturn ret;\n}\n\nstatic int fec_enet_mdio_read_c22(struct mii_bus *bus, int mii_id, int regnum)\n{\n\tstruct fec_enet_private *fep = bus->priv;\n\tstruct device *dev = &fep->pdev->dev;\n\tint ret = 0, frame_start, frame_addr, frame_op;\n\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tframe_op = FEC_MMFR_OP_READ;\n\tframe_start = FEC_MMFR_ST;\n\tframe_addr = regnum;\n\n\t \n\twritel(frame_start | frame_op |\n\t       FEC_MMFR_PA(mii_id) | FEC_MMFR_RA(frame_addr) |\n\t       FEC_MMFR_TA, fep->hwp + FEC_MII_DATA);\n\n\t \n\tret = fec_enet_mdio_wait(fep);\n\tif (ret) {\n\t\tnetdev_err(fep->netdev, \"MDIO read timeout\\n\");\n\t\tgoto out;\n\t}\n\n\tret = FEC_MMFR_DATA(readl(fep->hwp + FEC_MII_DATA));\n\nout:\n\tpm_runtime_mark_last_busy(dev);\n\tpm_runtime_put_autosuspend(dev);\n\n\treturn ret;\n}\n\nstatic int fec_enet_mdio_read_c45(struct mii_bus *bus, int mii_id,\n\t\t\t\t  int devad, int regnum)\n{\n\tstruct fec_enet_private *fep = bus->priv;\n\tstruct device *dev = &fep->pdev->dev;\n\tint ret = 0, frame_start, frame_op;\n\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tframe_start = FEC_MMFR_ST_C45;\n\n\t \n\twritel(frame_start | FEC_MMFR_OP_ADDR_WRITE |\n\t       FEC_MMFR_PA(mii_id) | FEC_MMFR_RA(devad) |\n\t       FEC_MMFR_TA | (regnum & 0xFFFF),\n\t       fep->hwp + FEC_MII_DATA);\n\n\t \n\tret = fec_enet_mdio_wait(fep);\n\tif (ret) {\n\t\tnetdev_err(fep->netdev, \"MDIO address write timeout\\n\");\n\t\tgoto out;\n\t}\n\n\tframe_op = FEC_MMFR_OP_READ_C45;\n\n\t \n\twritel(frame_start | frame_op |\n\t       FEC_MMFR_PA(mii_id) | FEC_MMFR_RA(devad) |\n\t       FEC_MMFR_TA, fep->hwp + FEC_MII_DATA);\n\n\t \n\tret = fec_enet_mdio_wait(fep);\n\tif (ret) {\n\t\tnetdev_err(fep->netdev, \"MDIO read timeout\\n\");\n\t\tgoto out;\n\t}\n\n\tret = FEC_MMFR_DATA(readl(fep->hwp + FEC_MII_DATA));\n\nout:\n\tpm_runtime_mark_last_busy(dev);\n\tpm_runtime_put_autosuspend(dev);\n\n\treturn ret;\n}\n\nstatic int fec_enet_mdio_write_c22(struct mii_bus *bus, int mii_id, int regnum,\n\t\t\t\t   u16 value)\n{\n\tstruct fec_enet_private *fep = bus->priv;\n\tstruct device *dev = &fep->pdev->dev;\n\tint ret, frame_start, frame_addr;\n\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\tframe_start = FEC_MMFR_ST;\n\tframe_addr = regnum;\n\n\t \n\twritel(frame_start | FEC_MMFR_OP_WRITE |\n\t       FEC_MMFR_PA(mii_id) | FEC_MMFR_RA(frame_addr) |\n\t       FEC_MMFR_TA | FEC_MMFR_DATA(value),\n\t       fep->hwp + FEC_MII_DATA);\n\n\t \n\tret = fec_enet_mdio_wait(fep);\n\tif (ret)\n\t\tnetdev_err(fep->netdev, \"MDIO write timeout\\n\");\n\n\tpm_runtime_mark_last_busy(dev);\n\tpm_runtime_put_autosuspend(dev);\n\n\treturn ret;\n}\n\nstatic int fec_enet_mdio_write_c45(struct mii_bus *bus, int mii_id,\n\t\t\t\t   int devad, int regnum, u16 value)\n{\n\tstruct fec_enet_private *fep = bus->priv;\n\tstruct device *dev = &fep->pdev->dev;\n\tint ret, frame_start;\n\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tframe_start = FEC_MMFR_ST_C45;\n\n\t \n\twritel(frame_start | FEC_MMFR_OP_ADDR_WRITE |\n\t       FEC_MMFR_PA(mii_id) | FEC_MMFR_RA(devad) |\n\t       FEC_MMFR_TA | (regnum & 0xFFFF),\n\t       fep->hwp + FEC_MII_DATA);\n\n\t \n\tret = fec_enet_mdio_wait(fep);\n\tif (ret) {\n\t\tnetdev_err(fep->netdev, \"MDIO address write timeout\\n\");\n\t\tgoto out;\n\t}\n\n\t \n\twritel(frame_start | FEC_MMFR_OP_WRITE |\n\t       FEC_MMFR_PA(mii_id) | FEC_MMFR_RA(devad) |\n\t       FEC_MMFR_TA | FEC_MMFR_DATA(value),\n\t       fep->hwp + FEC_MII_DATA);\n\n\t \n\tret = fec_enet_mdio_wait(fep);\n\tif (ret)\n\t\tnetdev_err(fep->netdev, \"MDIO write timeout\\n\");\n\nout:\n\tpm_runtime_mark_last_busy(dev);\n\tpm_runtime_put_autosuspend(dev);\n\n\treturn ret;\n}\n\nstatic void fec_enet_phy_reset_after_clk_enable(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct phy_device *phy_dev = ndev->phydev;\n\n\tif (phy_dev) {\n\t\tphy_reset_after_clk_enable(phy_dev);\n\t} else if (fep->phy_node) {\n\t\t \n\t\tphy_dev = of_phy_find_device(fep->phy_node);\n\t\tphy_reset_after_clk_enable(phy_dev);\n\t\tput_device(&phy_dev->mdio.dev);\n\t}\n}\n\nstatic int fec_enet_clk_enable(struct net_device *ndev, bool enable)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint ret;\n\n\tif (enable) {\n\t\tret = clk_prepare_enable(fep->clk_enet_out);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (fep->clk_ptp) {\n\t\t\tmutex_lock(&fep->ptp_clk_mutex);\n\t\t\tret = clk_prepare_enable(fep->clk_ptp);\n\t\t\tif (ret) {\n\t\t\t\tmutex_unlock(&fep->ptp_clk_mutex);\n\t\t\t\tgoto failed_clk_ptp;\n\t\t\t} else {\n\t\t\t\tfep->ptp_clk_on = true;\n\t\t\t}\n\t\t\tmutex_unlock(&fep->ptp_clk_mutex);\n\t\t}\n\n\t\tret = clk_prepare_enable(fep->clk_ref);\n\t\tif (ret)\n\t\t\tgoto failed_clk_ref;\n\n\t\tret = clk_prepare_enable(fep->clk_2x_txclk);\n\t\tif (ret)\n\t\t\tgoto failed_clk_2x_txclk;\n\n\t\tfec_enet_phy_reset_after_clk_enable(ndev);\n\t} else {\n\t\tclk_disable_unprepare(fep->clk_enet_out);\n\t\tif (fep->clk_ptp) {\n\t\t\tmutex_lock(&fep->ptp_clk_mutex);\n\t\t\tclk_disable_unprepare(fep->clk_ptp);\n\t\t\tfep->ptp_clk_on = false;\n\t\t\tmutex_unlock(&fep->ptp_clk_mutex);\n\t\t}\n\t\tclk_disable_unprepare(fep->clk_ref);\n\t\tclk_disable_unprepare(fep->clk_2x_txclk);\n\t}\n\n\treturn 0;\n\nfailed_clk_2x_txclk:\n\tif (fep->clk_ref)\n\t\tclk_disable_unprepare(fep->clk_ref);\nfailed_clk_ref:\n\tif (fep->clk_ptp) {\n\t\tmutex_lock(&fep->ptp_clk_mutex);\n\t\tclk_disable_unprepare(fep->clk_ptp);\n\t\tfep->ptp_clk_on = false;\n\t\tmutex_unlock(&fep->ptp_clk_mutex);\n\t}\nfailed_clk_ptp:\n\tclk_disable_unprepare(fep->clk_enet_out);\n\n\treturn ret;\n}\n\nstatic int fec_enet_parse_rgmii_delay(struct fec_enet_private *fep,\n\t\t\t\t      struct device_node *np)\n{\n\tu32 rgmii_tx_delay, rgmii_rx_delay;\n\n\t \n\tif (!of_property_read_u32(np, \"tx-internal-delay-ps\", &rgmii_tx_delay)) {\n\t\tif (rgmii_tx_delay != 0 && rgmii_tx_delay != 2000) {\n\t\t\tdev_err(&fep->pdev->dev, \"The only allowed RGMII TX delay values are: 0ps, 2000ps\");\n\t\t\treturn -EINVAL;\n\t\t} else if (rgmii_tx_delay == 2000) {\n\t\t\tfep->rgmii_txc_dly = true;\n\t\t}\n\t}\n\n\t \n\tif (!of_property_read_u32(np, \"rx-internal-delay-ps\", &rgmii_rx_delay)) {\n\t\tif (rgmii_rx_delay != 0 && rgmii_rx_delay != 2000) {\n\t\t\tdev_err(&fep->pdev->dev, \"The only allowed RGMII RX delay values are: 0ps, 2000ps\");\n\t\t\treturn -EINVAL;\n\t\t} else if (rgmii_rx_delay == 2000) {\n\t\t\tfep->rgmii_rxc_dly = true;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int fec_enet_mii_probe(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct phy_device *phy_dev = NULL;\n\tchar mdio_bus_id[MII_BUS_ID_SIZE];\n\tchar phy_name[MII_BUS_ID_SIZE + 3];\n\tint phy_id;\n\tint dev_id = fep->dev_id;\n\n\tif (fep->phy_node) {\n\t\tphy_dev = of_phy_connect(ndev, fep->phy_node,\n\t\t\t\t\t &fec_enet_adjust_link, 0,\n\t\t\t\t\t fep->phy_interface);\n\t\tif (!phy_dev) {\n\t\t\tnetdev_err(ndev, \"Unable to connect to phy\\n\");\n\t\t\treturn -ENODEV;\n\t\t}\n\t} else {\n\t\t \n\t\tfor (phy_id = 0; (phy_id < PHY_MAX_ADDR); phy_id++) {\n\t\t\tif (!mdiobus_is_registered_device(fep->mii_bus, phy_id))\n\t\t\t\tcontinue;\n\t\t\tif (dev_id--)\n\t\t\t\tcontinue;\n\t\t\tstrscpy(mdio_bus_id, fep->mii_bus->id, MII_BUS_ID_SIZE);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (phy_id >= PHY_MAX_ADDR) {\n\t\t\tnetdev_info(ndev, \"no PHY, assuming direct connection to switch\\n\");\n\t\t\tstrscpy(mdio_bus_id, \"fixed-0\", MII_BUS_ID_SIZE);\n\t\t\tphy_id = 0;\n\t\t}\n\n\t\tsnprintf(phy_name, sizeof(phy_name),\n\t\t\t PHY_ID_FMT, mdio_bus_id, phy_id);\n\t\tphy_dev = phy_connect(ndev, phy_name, &fec_enet_adjust_link,\n\t\t\t\t      fep->phy_interface);\n\t}\n\n\tif (IS_ERR(phy_dev)) {\n\t\tnetdev_err(ndev, \"could not attach to PHY\\n\");\n\t\treturn PTR_ERR(phy_dev);\n\t}\n\n\t \n\tif (fep->quirks & FEC_QUIRK_HAS_GBIT) {\n\t\tphy_set_max_speed(phy_dev, 1000);\n\t\tphy_remove_link_mode(phy_dev,\n\t\t\t\t     ETHTOOL_LINK_MODE_1000baseT_Half_BIT);\n#if !defined(CONFIG_M5272)\n\t\tphy_support_sym_pause(phy_dev);\n#endif\n\t}\n\telse\n\t\tphy_set_max_speed(phy_dev, 100);\n\n\tfep->link = 0;\n\tfep->full_duplex = 0;\n\n\tphy_dev->mac_managed_pm = true;\n\n\tphy_attached_info(phy_dev);\n\n\treturn 0;\n}\n\nstatic int fec_enet_mii_init(struct platform_device *pdev)\n{\n\tstatic struct mii_bus *fec0_mii_bus;\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tbool suppress_preamble = false;\n\tstruct device_node *node;\n\tint err = -ENXIO;\n\tu32 mii_speed, holdtime;\n\tu32 bus_freq;\n\n\t \n\tif ((fep->quirks & FEC_QUIRK_SINGLE_MDIO) && fep->dev_id > 0) {\n\t\t \n\t\tif (mii_cnt && fec0_mii_bus) {\n\t\t\tfep->mii_bus = fec0_mii_bus;\n\t\t\tmii_cnt++;\n\t\t\treturn 0;\n\t\t}\n\t\treturn -ENOENT;\n\t}\n\n\tbus_freq = 2500000;  \n\tnode = of_get_child_by_name(pdev->dev.of_node, \"mdio\");\n\tif (node) {\n\t\tof_property_read_u32(node, \"clock-frequency\", &bus_freq);\n\t\tsuppress_preamble = of_property_read_bool(node,\n\t\t\t\t\t\t\t  \"suppress-preamble\");\n\t}\n\n\t \n\tmii_speed = DIV_ROUND_UP(clk_get_rate(fep->clk_ipg), bus_freq * 2);\n\tif (fep->quirks & FEC_QUIRK_ENET_MAC)\n\t\tmii_speed--;\n\tif (mii_speed > 63) {\n\t\tdev_err(&pdev->dev,\n\t\t\t\"fec clock (%lu) too fast to get right mii speed\\n\",\n\t\t\tclk_get_rate(fep->clk_ipg));\n\t\terr = -EINVAL;\n\t\tgoto err_out;\n\t}\n\n\t \n\tholdtime = DIV_ROUND_UP(clk_get_rate(fep->clk_ipg), 100000000) - 1;\n\n\tfep->phy_speed = mii_speed << 1 | holdtime << 8;\n\n\tif (suppress_preamble)\n\t\tfep->phy_speed |= BIT(7);\n\n\tif (fep->quirks & FEC_QUIRK_CLEAR_SETUP_MII) {\n\t\t \n\t\twritel(0, fep->hwp + FEC_MII_DATA);\n\t}\n\n\twritel(fep->phy_speed, fep->hwp + FEC_MII_SPEED);\n\n\t \n\twritel(FEC_ENET_MII, fep->hwp + FEC_IEVENT);\n\n\tfep->mii_bus = mdiobus_alloc();\n\tif (fep->mii_bus == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\n\tfep->mii_bus->name = \"fec_enet_mii_bus\";\n\tfep->mii_bus->read = fec_enet_mdio_read_c22;\n\tfep->mii_bus->write = fec_enet_mdio_write_c22;\n\tif (fep->quirks & FEC_QUIRK_HAS_MDIO_C45) {\n\t\tfep->mii_bus->read_c45 = fec_enet_mdio_read_c45;\n\t\tfep->mii_bus->write_c45 = fec_enet_mdio_write_c45;\n\t}\n\tsnprintf(fep->mii_bus->id, MII_BUS_ID_SIZE, \"%s-%x\",\n\t\tpdev->name, fep->dev_id + 1);\n\tfep->mii_bus->priv = fep;\n\tfep->mii_bus->parent = &pdev->dev;\n\n\terr = of_mdiobus_register(fep->mii_bus, node);\n\tif (err)\n\t\tgoto err_out_free_mdiobus;\n\tof_node_put(node);\n\n\tmii_cnt++;\n\n\t \n\tif (fep->quirks & FEC_QUIRK_SINGLE_MDIO)\n\t\tfec0_mii_bus = fep->mii_bus;\n\n\treturn 0;\n\nerr_out_free_mdiobus:\n\tmdiobus_free(fep->mii_bus);\nerr_out:\n\tof_node_put(node);\n\treturn err;\n}\n\nstatic void fec_enet_mii_remove(struct fec_enet_private *fep)\n{\n\tif (--mii_cnt == 0) {\n\t\tmdiobus_unregister(fep->mii_bus);\n\t\tmdiobus_free(fep->mii_bus);\n\t}\n}\n\nstatic void fec_enet_get_drvinfo(struct net_device *ndev,\n\t\t\t\t struct ethtool_drvinfo *info)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tstrscpy(info->driver, fep->pdev->dev.driver->name,\n\t\tsizeof(info->driver));\n\tstrscpy(info->bus_info, dev_name(&ndev->dev), sizeof(info->bus_info));\n}\n\nstatic int fec_enet_get_regs_len(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct resource *r;\n\tint s = 0;\n\n\tr = platform_get_resource(fep->pdev, IORESOURCE_MEM, 0);\n\tif (r)\n\t\ts = resource_size(r);\n\n\treturn s;\n}\n\n \n#if defined(CONFIG_M523x) || defined(CONFIG_M527x) || defined(CONFIG_M528x) || \\\n\tdefined(CONFIG_M520x) || defined(CONFIG_M532x) || defined(CONFIG_ARM) || \\\n\tdefined(CONFIG_ARM64) || defined(CONFIG_COMPILE_TEST)\nstatic __u32 fec_enet_register_version = 2;\nstatic u32 fec_enet_register_offset[] = {\n\tFEC_IEVENT, FEC_IMASK, FEC_R_DES_ACTIVE_0, FEC_X_DES_ACTIVE_0,\n\tFEC_ECNTRL, FEC_MII_DATA, FEC_MII_SPEED, FEC_MIB_CTRLSTAT, FEC_R_CNTRL,\n\tFEC_X_CNTRL, FEC_ADDR_LOW, FEC_ADDR_HIGH, FEC_OPD, FEC_TXIC0, FEC_TXIC1,\n\tFEC_TXIC2, FEC_RXIC0, FEC_RXIC1, FEC_RXIC2, FEC_HASH_TABLE_HIGH,\n\tFEC_HASH_TABLE_LOW, FEC_GRP_HASH_TABLE_HIGH, FEC_GRP_HASH_TABLE_LOW,\n\tFEC_X_WMRK, FEC_R_BOUND, FEC_R_FSTART, FEC_R_DES_START_1,\n\tFEC_X_DES_START_1, FEC_R_BUFF_SIZE_1, FEC_R_DES_START_2,\n\tFEC_X_DES_START_2, FEC_R_BUFF_SIZE_2, FEC_R_DES_START_0,\n\tFEC_X_DES_START_0, FEC_R_BUFF_SIZE_0, FEC_R_FIFO_RSFL, FEC_R_FIFO_RSEM,\n\tFEC_R_FIFO_RAEM, FEC_R_FIFO_RAFL, FEC_RACC, FEC_RCMR_1, FEC_RCMR_2,\n\tFEC_DMA_CFG_1, FEC_DMA_CFG_2, FEC_R_DES_ACTIVE_1, FEC_X_DES_ACTIVE_1,\n\tFEC_R_DES_ACTIVE_2, FEC_X_DES_ACTIVE_2, FEC_QOS_SCHEME,\n\tRMON_T_DROP, RMON_T_PACKETS, RMON_T_BC_PKT, RMON_T_MC_PKT,\n\tRMON_T_CRC_ALIGN, RMON_T_UNDERSIZE, RMON_T_OVERSIZE, RMON_T_FRAG,\n\tRMON_T_JAB, RMON_T_COL, RMON_T_P64, RMON_T_P65TO127, RMON_T_P128TO255,\n\tRMON_T_P256TO511, RMON_T_P512TO1023, RMON_T_P1024TO2047,\n\tRMON_T_P_GTE2048, RMON_T_OCTETS,\n\tIEEE_T_DROP, IEEE_T_FRAME_OK, IEEE_T_1COL, IEEE_T_MCOL, IEEE_T_DEF,\n\tIEEE_T_LCOL, IEEE_T_EXCOL, IEEE_T_MACERR, IEEE_T_CSERR, IEEE_T_SQE,\n\tIEEE_T_FDXFC, IEEE_T_OCTETS_OK,\n\tRMON_R_PACKETS, RMON_R_BC_PKT, RMON_R_MC_PKT, RMON_R_CRC_ALIGN,\n\tRMON_R_UNDERSIZE, RMON_R_OVERSIZE, RMON_R_FRAG, RMON_R_JAB,\n\tRMON_R_RESVD_O, RMON_R_P64, RMON_R_P65TO127, RMON_R_P128TO255,\n\tRMON_R_P256TO511, RMON_R_P512TO1023, RMON_R_P1024TO2047,\n\tRMON_R_P_GTE2048, RMON_R_OCTETS,\n\tIEEE_R_DROP, IEEE_R_FRAME_OK, IEEE_R_CRC, IEEE_R_ALIGN, IEEE_R_MACERR,\n\tIEEE_R_FDXFC, IEEE_R_OCTETS_OK\n};\n \nstatic u32 fec_enet_register_offset_6ul[] = {\n\tFEC_IEVENT, FEC_IMASK, FEC_R_DES_ACTIVE_0, FEC_X_DES_ACTIVE_0,\n\tFEC_ECNTRL, FEC_MII_DATA, FEC_MII_SPEED, FEC_MIB_CTRLSTAT, FEC_R_CNTRL,\n\tFEC_X_CNTRL, FEC_ADDR_LOW, FEC_ADDR_HIGH, FEC_OPD, FEC_TXIC0, FEC_RXIC0,\n\tFEC_HASH_TABLE_HIGH, FEC_HASH_TABLE_LOW, FEC_GRP_HASH_TABLE_HIGH,\n\tFEC_GRP_HASH_TABLE_LOW, FEC_X_WMRK, FEC_R_DES_START_0,\n\tFEC_X_DES_START_0, FEC_R_BUFF_SIZE_0, FEC_R_FIFO_RSFL, FEC_R_FIFO_RSEM,\n\tFEC_R_FIFO_RAEM, FEC_R_FIFO_RAFL, FEC_RACC,\n\tRMON_T_DROP, RMON_T_PACKETS, RMON_T_BC_PKT, RMON_T_MC_PKT,\n\tRMON_T_CRC_ALIGN, RMON_T_UNDERSIZE, RMON_T_OVERSIZE, RMON_T_FRAG,\n\tRMON_T_JAB, RMON_T_COL, RMON_T_P64, RMON_T_P65TO127, RMON_T_P128TO255,\n\tRMON_T_P256TO511, RMON_T_P512TO1023, RMON_T_P1024TO2047,\n\tRMON_T_P_GTE2048, RMON_T_OCTETS,\n\tIEEE_T_DROP, IEEE_T_FRAME_OK, IEEE_T_1COL, IEEE_T_MCOL, IEEE_T_DEF,\n\tIEEE_T_LCOL, IEEE_T_EXCOL, IEEE_T_MACERR, IEEE_T_CSERR, IEEE_T_SQE,\n\tIEEE_T_FDXFC, IEEE_T_OCTETS_OK,\n\tRMON_R_PACKETS, RMON_R_BC_PKT, RMON_R_MC_PKT, RMON_R_CRC_ALIGN,\n\tRMON_R_UNDERSIZE, RMON_R_OVERSIZE, RMON_R_FRAG, RMON_R_JAB,\n\tRMON_R_RESVD_O, RMON_R_P64, RMON_R_P65TO127, RMON_R_P128TO255,\n\tRMON_R_P256TO511, RMON_R_P512TO1023, RMON_R_P1024TO2047,\n\tRMON_R_P_GTE2048, RMON_R_OCTETS,\n\tIEEE_R_DROP, IEEE_R_FRAME_OK, IEEE_R_CRC, IEEE_R_ALIGN, IEEE_R_MACERR,\n\tIEEE_R_FDXFC, IEEE_R_OCTETS_OK\n};\n#else\nstatic __u32 fec_enet_register_version = 1;\nstatic u32 fec_enet_register_offset[] = {\n\tFEC_ECNTRL, FEC_IEVENT, FEC_IMASK, FEC_IVEC, FEC_R_DES_ACTIVE_0,\n\tFEC_R_DES_ACTIVE_1, FEC_R_DES_ACTIVE_2, FEC_X_DES_ACTIVE_0,\n\tFEC_X_DES_ACTIVE_1, FEC_X_DES_ACTIVE_2, FEC_MII_DATA, FEC_MII_SPEED,\n\tFEC_R_BOUND, FEC_R_FSTART, FEC_X_WMRK, FEC_X_FSTART, FEC_R_CNTRL,\n\tFEC_MAX_FRM_LEN, FEC_X_CNTRL, FEC_ADDR_LOW, FEC_ADDR_HIGH,\n\tFEC_GRP_HASH_TABLE_HIGH, FEC_GRP_HASH_TABLE_LOW, FEC_R_DES_START_0,\n\tFEC_R_DES_START_1, FEC_R_DES_START_2, FEC_X_DES_START_0,\n\tFEC_X_DES_START_1, FEC_X_DES_START_2, FEC_R_BUFF_SIZE_0,\n\tFEC_R_BUFF_SIZE_1, FEC_R_BUFF_SIZE_2\n};\n#endif\n\nstatic void fec_enet_get_regs(struct net_device *ndev,\n\t\t\t      struct ethtool_regs *regs, void *regbuf)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tu32 __iomem *theregs = (u32 __iomem *)fep->hwp;\n\tstruct device *dev = &fep->pdev->dev;\n\tu32 *buf = (u32 *)regbuf;\n\tu32 i, off;\n\tint ret;\n#if defined(CONFIG_M523x) || defined(CONFIG_M527x) || defined(CONFIG_M528x) || \\\n\tdefined(CONFIG_M520x) || defined(CONFIG_M532x) || defined(CONFIG_ARM) || \\\n\tdefined(CONFIG_ARM64) || defined(CONFIG_COMPILE_TEST)\n\tu32 *reg_list;\n\tu32 reg_cnt;\n\n\tif (!of_machine_is_compatible(\"fsl,imx6ul\")) {\n\t\treg_list = fec_enet_register_offset;\n\t\treg_cnt = ARRAY_SIZE(fec_enet_register_offset);\n\t} else {\n\t\treg_list = fec_enet_register_offset_6ul;\n\t\treg_cnt = ARRAY_SIZE(fec_enet_register_offset_6ul);\n\t}\n#else\n\t \n\tstatic u32 *reg_list = fec_enet_register_offset;\n\tstatic const u32 reg_cnt = ARRAY_SIZE(fec_enet_register_offset);\n#endif\n\tret = pm_runtime_resume_and_get(dev);\n\tif (ret < 0)\n\t\treturn;\n\n\tregs->version = fec_enet_register_version;\n\n\tmemset(buf, 0, regs->len);\n\n\tfor (i = 0; i < reg_cnt; i++) {\n\t\toff = reg_list[i];\n\n\t\tif ((off == FEC_R_BOUND || off == FEC_R_FSTART) &&\n\t\t    !(fep->quirks & FEC_QUIRK_HAS_FRREG))\n\t\t\tcontinue;\n\n\t\toff >>= 2;\n\t\tbuf[off] = readl(&theregs[off]);\n\t}\n\n\tpm_runtime_mark_last_busy(dev);\n\tpm_runtime_put_autosuspend(dev);\n}\n\nstatic int fec_enet_get_ts_info(struct net_device *ndev,\n\t\t\t\tstruct ethtool_ts_info *info)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (fep->bufdesc_ex) {\n\n\t\tinfo->so_timestamping = SOF_TIMESTAMPING_TX_SOFTWARE |\n\t\t\t\t\tSOF_TIMESTAMPING_RX_SOFTWARE |\n\t\t\t\t\tSOF_TIMESTAMPING_SOFTWARE |\n\t\t\t\t\tSOF_TIMESTAMPING_TX_HARDWARE |\n\t\t\t\t\tSOF_TIMESTAMPING_RX_HARDWARE |\n\t\t\t\t\tSOF_TIMESTAMPING_RAW_HARDWARE;\n\t\tif (fep->ptp_clock)\n\t\t\tinfo->phc_index = ptp_clock_index(fep->ptp_clock);\n\t\telse\n\t\t\tinfo->phc_index = -1;\n\n\t\tinfo->tx_types = (1 << HWTSTAMP_TX_OFF) |\n\t\t\t\t (1 << HWTSTAMP_TX_ON);\n\n\t\tinfo->rx_filters = (1 << HWTSTAMP_FILTER_NONE) |\n\t\t\t\t   (1 << HWTSTAMP_FILTER_ALL);\n\t\treturn 0;\n\t} else {\n\t\treturn ethtool_op_get_ts_info(ndev, info);\n\t}\n}\n\n#if !defined(CONFIG_M5272)\n\nstatic void fec_enet_get_pauseparam(struct net_device *ndev,\n\t\t\t\t    struct ethtool_pauseparam *pause)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tpause->autoneg = (fep->pause_flag & FEC_PAUSE_FLAG_AUTONEG) != 0;\n\tpause->tx_pause = (fep->pause_flag & FEC_PAUSE_FLAG_ENABLE) != 0;\n\tpause->rx_pause = pause->tx_pause;\n}\n\nstatic int fec_enet_set_pauseparam(struct net_device *ndev,\n\t\t\t\t   struct ethtool_pauseparam *pause)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (!ndev->phydev)\n\t\treturn -ENODEV;\n\n\tif (pause->tx_pause != pause->rx_pause) {\n\t\tnetdev_info(ndev,\n\t\t\t\"hardware only support enable/disable both tx and rx\");\n\t\treturn -EINVAL;\n\t}\n\n\tfep->pause_flag = 0;\n\n\t \n\tfep->pause_flag |= pause->rx_pause ? FEC_PAUSE_FLAG_ENABLE : 0;\n\tfep->pause_flag |= pause->autoneg ? FEC_PAUSE_FLAG_AUTONEG : 0;\n\n\tphy_set_sym_pause(ndev->phydev, pause->rx_pause, pause->tx_pause,\n\t\t\t  pause->autoneg);\n\n\tif (pause->autoneg) {\n\t\tif (netif_running(ndev))\n\t\t\tfec_stop(ndev);\n\t\tphy_start_aneg(ndev->phydev);\n\t}\n\tif (netif_running(ndev)) {\n\t\tnapi_disable(&fep->napi);\n\t\tnetif_tx_lock_bh(ndev);\n\t\tfec_restart(ndev);\n\t\tnetif_tx_wake_all_queues(ndev);\n\t\tnetif_tx_unlock_bh(ndev);\n\t\tnapi_enable(&fep->napi);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct fec_stat {\n\tchar name[ETH_GSTRING_LEN];\n\tu16 offset;\n} fec_stats[] = {\n\t \n\t{ \"tx_dropped\", RMON_T_DROP },\n\t{ \"tx_packets\", RMON_T_PACKETS },\n\t{ \"tx_broadcast\", RMON_T_BC_PKT },\n\t{ \"tx_multicast\", RMON_T_MC_PKT },\n\t{ \"tx_crc_errors\", RMON_T_CRC_ALIGN },\n\t{ \"tx_undersize\", RMON_T_UNDERSIZE },\n\t{ \"tx_oversize\", RMON_T_OVERSIZE },\n\t{ \"tx_fragment\", RMON_T_FRAG },\n\t{ \"tx_jabber\", RMON_T_JAB },\n\t{ \"tx_collision\", RMON_T_COL },\n\t{ \"tx_64byte\", RMON_T_P64 },\n\t{ \"tx_65to127byte\", RMON_T_P65TO127 },\n\t{ \"tx_128to255byte\", RMON_T_P128TO255 },\n\t{ \"tx_256to511byte\", RMON_T_P256TO511 },\n\t{ \"tx_512to1023byte\", RMON_T_P512TO1023 },\n\t{ \"tx_1024to2047byte\", RMON_T_P1024TO2047 },\n\t{ \"tx_GTE2048byte\", RMON_T_P_GTE2048 },\n\t{ \"tx_octets\", RMON_T_OCTETS },\n\n\t \n\t{ \"IEEE_tx_drop\", IEEE_T_DROP },\n\t{ \"IEEE_tx_frame_ok\", IEEE_T_FRAME_OK },\n\t{ \"IEEE_tx_1col\", IEEE_T_1COL },\n\t{ \"IEEE_tx_mcol\", IEEE_T_MCOL },\n\t{ \"IEEE_tx_def\", IEEE_T_DEF },\n\t{ \"IEEE_tx_lcol\", IEEE_T_LCOL },\n\t{ \"IEEE_tx_excol\", IEEE_T_EXCOL },\n\t{ \"IEEE_tx_macerr\", IEEE_T_MACERR },\n\t{ \"IEEE_tx_cserr\", IEEE_T_CSERR },\n\t{ \"IEEE_tx_sqe\", IEEE_T_SQE },\n\t{ \"IEEE_tx_fdxfc\", IEEE_T_FDXFC },\n\t{ \"IEEE_tx_octets_ok\", IEEE_T_OCTETS_OK },\n\n\t \n\t{ \"rx_packets\", RMON_R_PACKETS },\n\t{ \"rx_broadcast\", RMON_R_BC_PKT },\n\t{ \"rx_multicast\", RMON_R_MC_PKT },\n\t{ \"rx_crc_errors\", RMON_R_CRC_ALIGN },\n\t{ \"rx_undersize\", RMON_R_UNDERSIZE },\n\t{ \"rx_oversize\", RMON_R_OVERSIZE },\n\t{ \"rx_fragment\", RMON_R_FRAG },\n\t{ \"rx_jabber\", RMON_R_JAB },\n\t{ \"rx_64byte\", RMON_R_P64 },\n\t{ \"rx_65to127byte\", RMON_R_P65TO127 },\n\t{ \"rx_128to255byte\", RMON_R_P128TO255 },\n\t{ \"rx_256to511byte\", RMON_R_P256TO511 },\n\t{ \"rx_512to1023byte\", RMON_R_P512TO1023 },\n\t{ \"rx_1024to2047byte\", RMON_R_P1024TO2047 },\n\t{ \"rx_GTE2048byte\", RMON_R_P_GTE2048 },\n\t{ \"rx_octets\", RMON_R_OCTETS },\n\n\t \n\t{ \"IEEE_rx_drop\", IEEE_R_DROP },\n\t{ \"IEEE_rx_frame_ok\", IEEE_R_FRAME_OK },\n\t{ \"IEEE_rx_crc\", IEEE_R_CRC },\n\t{ \"IEEE_rx_align\", IEEE_R_ALIGN },\n\t{ \"IEEE_rx_macerr\", IEEE_R_MACERR },\n\t{ \"IEEE_rx_fdxfc\", IEEE_R_FDXFC },\n\t{ \"IEEE_rx_octets_ok\", IEEE_R_OCTETS_OK },\n};\n\n#define FEC_STATS_SIZE\t\t(ARRAY_SIZE(fec_stats) * sizeof(u64))\n\nstatic const char *fec_xdp_stat_strs[XDP_STATS_TOTAL] = {\n\t\"rx_xdp_redirect\",            \n\t\"rx_xdp_pass\",                \n\t\"rx_xdp_drop\",                \n\t\"rx_xdp_tx\",                  \n\t\"rx_xdp_tx_errors\",           \n\t\"tx_xdp_xmit\",                \n\t\"tx_xdp_xmit_errors\",         \n};\n\nstatic void fec_enet_update_ethtool_stats(struct net_device *dev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(dev);\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(fec_stats); i++)\n\t\tfep->ethtool_stats[i] = readl(fep->hwp + fec_stats[i].offset);\n}\n\nstatic void fec_enet_get_xdp_stats(struct fec_enet_private *fep, u64 *data)\n{\n\tu64 xdp_stats[XDP_STATS_TOTAL] = { 0 };\n\tstruct fec_enet_priv_rx_q *rxq;\n\tint i, j;\n\n\tfor (i = fep->num_rx_queues - 1; i >= 0; i--) {\n\t\trxq = fep->rx_queue[i];\n\n\t\tfor (j = 0; j < XDP_STATS_TOTAL; j++)\n\t\t\txdp_stats[j] += rxq->stats[j];\n\t}\n\n\tmemcpy(data, xdp_stats, sizeof(xdp_stats));\n}\n\nstatic void fec_enet_page_pool_stats(struct fec_enet_private *fep, u64 *data)\n{\n#ifdef CONFIG_PAGE_POOL_STATS\n\tstruct page_pool_stats stats = {};\n\tstruct fec_enet_priv_rx_q *rxq;\n\tint i;\n\n\tfor (i = fep->num_rx_queues - 1; i >= 0; i--) {\n\t\trxq = fep->rx_queue[i];\n\n\t\tif (!rxq->page_pool)\n\t\t\tcontinue;\n\n\t\tpage_pool_get_stats(rxq->page_pool, &stats);\n\t}\n\n\tpage_pool_ethtool_stats_get(data, &stats);\n#endif\n}\n\nstatic void fec_enet_get_ethtool_stats(struct net_device *dev,\n\t\t\t\t       struct ethtool_stats *stats, u64 *data)\n{\n\tstruct fec_enet_private *fep = netdev_priv(dev);\n\n\tif (netif_running(dev))\n\t\tfec_enet_update_ethtool_stats(dev);\n\n\tmemcpy(data, fep->ethtool_stats, FEC_STATS_SIZE);\n\tdata += FEC_STATS_SIZE / sizeof(u64);\n\n\tfec_enet_get_xdp_stats(fep, data);\n\tdata += XDP_STATS_TOTAL;\n\n\tfec_enet_page_pool_stats(fep, data);\n}\n\nstatic void fec_enet_get_strings(struct net_device *netdev,\n\tu32 stringset, u8 *data)\n{\n\tint i;\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tfor (i = 0; i < ARRAY_SIZE(fec_stats); i++) {\n\t\t\tmemcpy(data, fec_stats[i].name, ETH_GSTRING_LEN);\n\t\t\tdata += ETH_GSTRING_LEN;\n\t\t}\n\t\tfor (i = 0; i < ARRAY_SIZE(fec_xdp_stat_strs); i++) {\n\t\t\tstrncpy(data, fec_xdp_stat_strs[i], ETH_GSTRING_LEN);\n\t\t\tdata += ETH_GSTRING_LEN;\n\t\t}\n\t\tpage_pool_ethtool_stats_get_strings(data);\n\n\t\tbreak;\n\tcase ETH_SS_TEST:\n\t\tnet_selftest_get_strings(data);\n\t\tbreak;\n\t}\n}\n\nstatic int fec_enet_get_sset_count(struct net_device *dev, int sset)\n{\n\tint count;\n\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\tcount = ARRAY_SIZE(fec_stats) + XDP_STATS_TOTAL;\n\t\tcount += page_pool_ethtool_stats_get_count();\n\t\treturn count;\n\n\tcase ETH_SS_TEST:\n\t\treturn net_selftest_get_count();\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void fec_enet_clear_ethtool_stats(struct net_device *dev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(dev);\n\tstruct fec_enet_priv_rx_q *rxq;\n\tint i, j;\n\n\t \n\twritel(FEC_MIB_CTRLSTAT_DISABLE, fep->hwp + FEC_MIB_CTRLSTAT);\n\n\tfor (i = 0; i < ARRAY_SIZE(fec_stats); i++)\n\t\twritel(0, fep->hwp + fec_stats[i].offset);\n\n\tfor (i = fep->num_rx_queues - 1; i >= 0; i--) {\n\t\trxq = fep->rx_queue[i];\n\t\tfor (j = 0; j < XDP_STATS_TOTAL; j++)\n\t\t\trxq->stats[j] = 0;\n\t}\n\n\t \n\twritel(0, fep->hwp + FEC_MIB_CTRLSTAT);\n}\n\n#else\t \n#define FEC_STATS_SIZE\t0\nstatic inline void fec_enet_update_ethtool_stats(struct net_device *dev)\n{\n}\n\nstatic inline void fec_enet_clear_ethtool_stats(struct net_device *dev)\n{\n}\n#endif  \n\n \nstatic int fec_enet_us_to_itr_clock(struct net_device *ndev, int us)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\treturn us * (fep->itr_clk_rate / 64000) / 1000;\n}\n\n \nstatic void fec_enet_itr_coal_set(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint rx_itr, tx_itr;\n\n\t \n\tif (!fep->rx_time_itr || !fep->rx_pkts_itr ||\n\t    !fep->tx_time_itr || !fep->tx_pkts_itr)\n\t\treturn;\n\n\t \n\trx_itr = FEC_ITR_CLK_SEL;\n\ttx_itr = FEC_ITR_CLK_SEL;\n\n\t \n\trx_itr |= FEC_ITR_ICFT(fep->rx_pkts_itr);\n\trx_itr |= FEC_ITR_ICTT(fec_enet_us_to_itr_clock(ndev, fep->rx_time_itr));\n\ttx_itr |= FEC_ITR_ICFT(fep->tx_pkts_itr);\n\ttx_itr |= FEC_ITR_ICTT(fec_enet_us_to_itr_clock(ndev, fep->tx_time_itr));\n\n\trx_itr |= FEC_ITR_EN;\n\ttx_itr |= FEC_ITR_EN;\n\n\twritel(tx_itr, fep->hwp + FEC_TXIC0);\n\twritel(rx_itr, fep->hwp + FEC_RXIC0);\n\tif (fep->quirks & FEC_QUIRK_HAS_MULTI_QUEUES) {\n\t\twritel(tx_itr, fep->hwp + FEC_TXIC1);\n\t\twritel(rx_itr, fep->hwp + FEC_RXIC1);\n\t\twritel(tx_itr, fep->hwp + FEC_TXIC2);\n\t\twritel(rx_itr, fep->hwp + FEC_RXIC2);\n\t}\n}\n\nstatic int fec_enet_get_coalesce(struct net_device *ndev,\n\t\t\t\t struct ethtool_coalesce *ec,\n\t\t\t\t struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (!(fep->quirks & FEC_QUIRK_HAS_COALESCE))\n\t\treturn -EOPNOTSUPP;\n\n\tec->rx_coalesce_usecs = fep->rx_time_itr;\n\tec->rx_max_coalesced_frames = fep->rx_pkts_itr;\n\n\tec->tx_coalesce_usecs = fep->tx_time_itr;\n\tec->tx_max_coalesced_frames = fep->tx_pkts_itr;\n\n\treturn 0;\n}\n\nstatic int fec_enet_set_coalesce(struct net_device *ndev,\n\t\t\t\t struct ethtool_coalesce *ec,\n\t\t\t\t struct kernel_ethtool_coalesce *kernel_coal,\n\t\t\t\t struct netlink_ext_ack *extack)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct device *dev = &fep->pdev->dev;\n\tunsigned int cycle;\n\n\tif (!(fep->quirks & FEC_QUIRK_HAS_COALESCE))\n\t\treturn -EOPNOTSUPP;\n\n\tif (ec->rx_max_coalesced_frames > 255) {\n\t\tdev_err(dev, \"Rx coalesced frames exceed hardware limitation\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (ec->tx_max_coalesced_frames > 255) {\n\t\tdev_err(dev, \"Tx coalesced frame exceed hardware limitation\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tcycle = fec_enet_us_to_itr_clock(ndev, ec->rx_coalesce_usecs);\n\tif (cycle > 0xFFFF) {\n\t\tdev_err(dev, \"Rx coalesced usec exceed hardware limitation\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tcycle = fec_enet_us_to_itr_clock(ndev, ec->tx_coalesce_usecs);\n\tif (cycle > 0xFFFF) {\n\t\tdev_err(dev, \"Tx coalesced usec exceed hardware limitation\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tfep->rx_time_itr = ec->rx_coalesce_usecs;\n\tfep->rx_pkts_itr = ec->rx_max_coalesced_frames;\n\n\tfep->tx_time_itr = ec->tx_coalesce_usecs;\n\tfep->tx_pkts_itr = ec->tx_max_coalesced_frames;\n\n\tfec_enet_itr_coal_set(ndev);\n\n\treturn 0;\n}\n\n \nstatic int fec_enet_us_to_tx_cycle(struct net_device *ndev, int us)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\treturn us * (fep->clk_ref_rate / 1000) / 1000;\n}\n\nstatic int fec_enet_eee_mode_set(struct net_device *ndev, bool enable)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct ethtool_eee *p = &fep->eee;\n\tunsigned int sleep_cycle, wake_cycle;\n\tint ret = 0;\n\n\tif (enable) {\n\t\tret = phy_init_eee(ndev->phydev, false);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tsleep_cycle = fec_enet_us_to_tx_cycle(ndev, p->tx_lpi_timer);\n\t\twake_cycle = sleep_cycle;\n\t} else {\n\t\tsleep_cycle = 0;\n\t\twake_cycle = 0;\n\t}\n\n\tp->tx_lpi_enabled = enable;\n\tp->eee_enabled = enable;\n\tp->eee_active = enable;\n\n\twritel(sleep_cycle, fep->hwp + FEC_LPI_SLEEP);\n\twritel(wake_cycle, fep->hwp + FEC_LPI_WAKE);\n\n\treturn 0;\n}\n\nstatic int\nfec_enet_get_eee(struct net_device *ndev, struct ethtool_eee *edata)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct ethtool_eee *p = &fep->eee;\n\n\tif (!(fep->quirks & FEC_QUIRK_HAS_EEE))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!netif_running(ndev))\n\t\treturn -ENETDOWN;\n\n\tedata->eee_enabled = p->eee_enabled;\n\tedata->eee_active = p->eee_active;\n\tedata->tx_lpi_timer = p->tx_lpi_timer;\n\tedata->tx_lpi_enabled = p->tx_lpi_enabled;\n\n\treturn phy_ethtool_get_eee(ndev->phydev, edata);\n}\n\nstatic int\nfec_enet_set_eee(struct net_device *ndev, struct ethtool_eee *edata)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct ethtool_eee *p = &fep->eee;\n\tint ret = 0;\n\n\tif (!(fep->quirks & FEC_QUIRK_HAS_EEE))\n\t\treturn -EOPNOTSUPP;\n\n\tif (!netif_running(ndev))\n\t\treturn -ENETDOWN;\n\n\tp->tx_lpi_timer = edata->tx_lpi_timer;\n\n\tif (!edata->eee_enabled || !edata->tx_lpi_enabled ||\n\t    !edata->tx_lpi_timer)\n\t\tret = fec_enet_eee_mode_set(ndev, false);\n\telse\n\t\tret = fec_enet_eee_mode_set(ndev, true);\n\n\tif (ret)\n\t\treturn ret;\n\n\treturn phy_ethtool_set_eee(ndev->phydev, edata);\n}\n\nstatic void\nfec_enet_get_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (fep->wol_flag & FEC_WOL_HAS_MAGIC_PACKET) {\n\t\twol->supported = WAKE_MAGIC;\n\t\twol->wolopts = fep->wol_flag & FEC_WOL_FLAG_ENABLE ? WAKE_MAGIC : 0;\n\t} else {\n\t\twol->supported = wol->wolopts = 0;\n\t}\n}\n\nstatic int\nfec_enet_set_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (!(fep->wol_flag & FEC_WOL_HAS_MAGIC_PACKET))\n\t\treturn -EINVAL;\n\n\tif (wol->wolopts & ~WAKE_MAGIC)\n\t\treturn -EINVAL;\n\n\tdevice_set_wakeup_enable(&ndev->dev, wol->wolopts & WAKE_MAGIC);\n\tif (device_may_wakeup(&ndev->dev))\n\t\tfep->wol_flag |= FEC_WOL_FLAG_ENABLE;\n\telse\n\t\tfep->wol_flag &= (~FEC_WOL_FLAG_ENABLE);\n\n\treturn 0;\n}\n\nstatic const struct ethtool_ops fec_enet_ethtool_ops = {\n\t.supported_coalesce_params = ETHTOOL_COALESCE_USECS |\n\t\t\t\t     ETHTOOL_COALESCE_MAX_FRAMES,\n\t.get_drvinfo\t\t= fec_enet_get_drvinfo,\n\t.get_regs_len\t\t= fec_enet_get_regs_len,\n\t.get_regs\t\t= fec_enet_get_regs,\n\t.nway_reset\t\t= phy_ethtool_nway_reset,\n\t.get_link\t\t= ethtool_op_get_link,\n\t.get_coalesce\t\t= fec_enet_get_coalesce,\n\t.set_coalesce\t\t= fec_enet_set_coalesce,\n#ifndef CONFIG_M5272\n\t.get_pauseparam\t\t= fec_enet_get_pauseparam,\n\t.set_pauseparam\t\t= fec_enet_set_pauseparam,\n\t.get_strings\t\t= fec_enet_get_strings,\n\t.get_ethtool_stats\t= fec_enet_get_ethtool_stats,\n\t.get_sset_count\t\t= fec_enet_get_sset_count,\n#endif\n\t.get_ts_info\t\t= fec_enet_get_ts_info,\n\t.get_wol\t\t= fec_enet_get_wol,\n\t.set_wol\t\t= fec_enet_set_wol,\n\t.get_eee\t\t= fec_enet_get_eee,\n\t.set_eee\t\t= fec_enet_set_eee,\n\t.get_link_ksettings\t= phy_ethtool_get_link_ksettings,\n\t.set_link_ksettings\t= phy_ethtool_set_link_ksettings,\n\t.self_test\t\t= net_selftest,\n};\n\nstatic void fec_enet_free_buffers(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tunsigned int i;\n\tstruct fec_enet_priv_tx_q *txq;\n\tstruct fec_enet_priv_rx_q *rxq;\n\tunsigned int q;\n\n\tfor (q = 0; q < fep->num_rx_queues; q++) {\n\t\trxq = fep->rx_queue[q];\n\t\tfor (i = 0; i < rxq->bd.ring_size; i++)\n\t\t\tpage_pool_put_full_page(rxq->page_pool, rxq->rx_skb_info[i].page, false);\n\n\t\tfor (i = 0; i < XDP_STATS_TOTAL; i++)\n\t\t\trxq->stats[i] = 0;\n\n\t\tif (xdp_rxq_info_is_reg(&rxq->xdp_rxq))\n\t\t\txdp_rxq_info_unreg(&rxq->xdp_rxq);\n\t\tpage_pool_destroy(rxq->page_pool);\n\t\trxq->page_pool = NULL;\n\t}\n\n\tfor (q = 0; q < fep->num_tx_queues; q++) {\n\t\ttxq = fep->tx_queue[q];\n\t\tfor (i = 0; i < txq->bd.ring_size; i++) {\n\t\t\tkfree(txq->tx_bounce[i]);\n\t\t\ttxq->tx_bounce[i] = NULL;\n\n\t\t\tif (!txq->tx_buf[i].buf_p) {\n\t\t\t\ttxq->tx_buf[i].type = FEC_TXBUF_T_SKB;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (txq->tx_buf[i].type == FEC_TXBUF_T_SKB) {\n\t\t\t\tdev_kfree_skb(txq->tx_buf[i].buf_p);\n\t\t\t} else if (txq->tx_buf[i].type == FEC_TXBUF_T_XDP_NDO) {\n\t\t\t\txdp_return_frame(txq->tx_buf[i].buf_p);\n\t\t\t} else {\n\t\t\t\tstruct page *page = txq->tx_buf[i].buf_p;\n\n\t\t\t\tpage_pool_put_page(page->pp, page, 0, false);\n\t\t\t}\n\n\t\t\ttxq->tx_buf[i].buf_p = NULL;\n\t\t\ttxq->tx_buf[i].type = FEC_TXBUF_T_SKB;\n\t\t}\n\t}\n}\n\nstatic void fec_enet_free_queue(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint i;\n\tstruct fec_enet_priv_tx_q *txq;\n\n\tfor (i = 0; i < fep->num_tx_queues; i++)\n\t\tif (fep->tx_queue[i] && fep->tx_queue[i]->tso_hdrs) {\n\t\t\ttxq = fep->tx_queue[i];\n\t\t\tdma_free_coherent(&fep->pdev->dev,\n\t\t\t\t\t  txq->bd.ring_size * TSO_HEADER_SIZE,\n\t\t\t\t\t  txq->tso_hdrs,\n\t\t\t\t\t  txq->tso_hdrs_dma);\n\t\t}\n\n\tfor (i = 0; i < fep->num_rx_queues; i++)\n\t\tkfree(fep->rx_queue[i]);\n\tfor (i = 0; i < fep->num_tx_queues; i++)\n\t\tkfree(fep->tx_queue[i]);\n}\n\nstatic int fec_enet_alloc_queue(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint i;\n\tint ret = 0;\n\tstruct fec_enet_priv_tx_q *txq;\n\n\tfor (i = 0; i < fep->num_tx_queues; i++) {\n\t\ttxq = kzalloc(sizeof(*txq), GFP_KERNEL);\n\t\tif (!txq) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto alloc_failed;\n\t\t}\n\n\t\tfep->tx_queue[i] = txq;\n\t\ttxq->bd.ring_size = TX_RING_SIZE;\n\t\tfep->total_tx_ring_size += fep->tx_queue[i]->bd.ring_size;\n\n\t\ttxq->tx_stop_threshold = FEC_MAX_SKB_DESCS;\n\t\ttxq->tx_wake_threshold = FEC_MAX_SKB_DESCS + 2 * MAX_SKB_FRAGS;\n\n\t\ttxq->tso_hdrs = dma_alloc_coherent(&fep->pdev->dev,\n\t\t\t\t\ttxq->bd.ring_size * TSO_HEADER_SIZE,\n\t\t\t\t\t&txq->tso_hdrs_dma,\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!txq->tso_hdrs) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto alloc_failed;\n\t\t}\n\t}\n\n\tfor (i = 0; i < fep->num_rx_queues; i++) {\n\t\tfep->rx_queue[i] = kzalloc(sizeof(*fep->rx_queue[i]),\n\t\t\t\t\t   GFP_KERNEL);\n\t\tif (!fep->rx_queue[i]) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto alloc_failed;\n\t\t}\n\n\t\tfep->rx_queue[i]->bd.ring_size = RX_RING_SIZE;\n\t\tfep->total_rx_ring_size += fep->rx_queue[i]->bd.ring_size;\n\t}\n\treturn ret;\n\nalloc_failed:\n\tfec_enet_free_queue(ndev);\n\treturn ret;\n}\n\nstatic int\nfec_enet_alloc_rxq_buffers(struct net_device *ndev, unsigned int queue)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct fec_enet_priv_rx_q *rxq;\n\tdma_addr_t phys_addr;\n\tstruct bufdesc\t*bdp;\n\tstruct page *page;\n\tint i, err;\n\n\trxq = fep->rx_queue[queue];\n\tbdp = rxq->bd.base;\n\n\terr = fec_enet_create_page_pool(fep, rxq, rxq->bd.ring_size);\n\tif (err < 0) {\n\t\tnetdev_err(ndev, \"%s failed queue %d (%d)\\n\", __func__, queue, err);\n\t\treturn err;\n\t}\n\n\tfor (i = 0; i < rxq->bd.ring_size; i++) {\n\t\tpage = page_pool_dev_alloc_pages(rxq->page_pool);\n\t\tif (!page)\n\t\t\tgoto err_alloc;\n\n\t\tphys_addr = page_pool_get_dma_addr(page) + FEC_ENET_XDP_HEADROOM;\n\t\tbdp->cbd_bufaddr = cpu_to_fec32(phys_addr);\n\n\t\trxq->rx_skb_info[i].page = page;\n\t\trxq->rx_skb_info[i].offset = FEC_ENET_XDP_HEADROOM;\n\t\tbdp->cbd_sc = cpu_to_fec16(BD_ENET_RX_EMPTY);\n\n\t\tif (fep->bufdesc_ex) {\n\t\t\tstruct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;\n\t\t\tebdp->cbd_esc = cpu_to_fec32(BD_ENET_RX_INT);\n\t\t}\n\n\t\tbdp = fec_enet_get_nextdesc(bdp, &rxq->bd);\n\t}\n\n\t \n\tbdp = fec_enet_get_prevdesc(bdp, &rxq->bd);\n\tbdp->cbd_sc |= cpu_to_fec16(BD_SC_WRAP);\n\treturn 0;\n\n err_alloc:\n\tfec_enet_free_buffers(ndev);\n\treturn -ENOMEM;\n}\n\nstatic int\nfec_enet_alloc_txq_buffers(struct net_device *ndev, unsigned int queue)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tunsigned int i;\n\tstruct bufdesc  *bdp;\n\tstruct fec_enet_priv_tx_q *txq;\n\n\ttxq = fep->tx_queue[queue];\n\tbdp = txq->bd.base;\n\tfor (i = 0; i < txq->bd.ring_size; i++) {\n\t\ttxq->tx_bounce[i] = kmalloc(FEC_ENET_TX_FRSIZE, GFP_KERNEL);\n\t\tif (!txq->tx_bounce[i])\n\t\t\tgoto err_alloc;\n\n\t\tbdp->cbd_sc = cpu_to_fec16(0);\n\t\tbdp->cbd_bufaddr = cpu_to_fec32(0);\n\n\t\tif (fep->bufdesc_ex) {\n\t\t\tstruct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;\n\t\t\tebdp->cbd_esc = cpu_to_fec32(BD_ENET_TX_INT);\n\t\t}\n\n\t\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\t}\n\n\t \n\tbdp = fec_enet_get_prevdesc(bdp, &txq->bd);\n\tbdp->cbd_sc |= cpu_to_fec16(BD_SC_WRAP);\n\n\treturn 0;\n\n err_alloc:\n\tfec_enet_free_buffers(ndev);\n\treturn -ENOMEM;\n}\n\nstatic int fec_enet_alloc_buffers(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tunsigned int i;\n\n\tfor (i = 0; i < fep->num_rx_queues; i++)\n\t\tif (fec_enet_alloc_rxq_buffers(ndev, i))\n\t\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < fep->num_tx_queues; i++)\n\t\tif (fec_enet_alloc_txq_buffers(ndev, i))\n\t\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic int\nfec_enet_open(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint ret;\n\tbool reset_again;\n\n\tret = pm_runtime_resume_and_get(&fep->pdev->dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tpinctrl_pm_select_default_state(&fep->pdev->dev);\n\tret = fec_enet_clk_enable(ndev, true);\n\tif (ret)\n\t\tgoto clk_enable;\n\n\t \n\tif (ndev->phydev && ndev->phydev->drv)\n\t\treset_again = false;\n\telse\n\t\treset_again = true;\n\n\t \n\n\tret = fec_enet_alloc_buffers(ndev);\n\tif (ret)\n\t\tgoto err_enet_alloc;\n\n\t \n\tfec_restart(ndev);\n\n\t \n\tif (reset_again)\n\t\tfec_enet_phy_reset_after_clk_enable(ndev);\n\n\t \n\tret = fec_enet_mii_probe(ndev);\n\tif (ret)\n\t\tgoto err_enet_mii_probe;\n\n\tif (fep->quirks & FEC_QUIRK_ERR006687)\n\t\timx6q_cpuidle_fec_irqs_used();\n\n\tif (fep->quirks & FEC_QUIRK_HAS_PMQOS)\n\t\tcpu_latency_qos_add_request(&fep->pm_qos_req, 0);\n\n\tnapi_enable(&fep->napi);\n\tphy_start(ndev->phydev);\n\tnetif_tx_start_all_queues(ndev);\n\n\tdevice_set_wakeup_enable(&ndev->dev, fep->wol_flag &\n\t\t\t\t FEC_WOL_FLAG_ENABLE);\n\n\treturn 0;\n\nerr_enet_mii_probe:\n\tfec_enet_free_buffers(ndev);\nerr_enet_alloc:\n\tfec_enet_clk_enable(ndev, false);\nclk_enable:\n\tpm_runtime_mark_last_busy(&fep->pdev->dev);\n\tpm_runtime_put_autosuspend(&fep->pdev->dev);\n\tpinctrl_pm_select_sleep_state(&fep->pdev->dev);\n\treturn ret;\n}\n\nstatic int\nfec_enet_close(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tphy_stop(ndev->phydev);\n\n\tif (netif_device_present(ndev)) {\n\t\tnapi_disable(&fep->napi);\n\t\tnetif_tx_disable(ndev);\n\t\tfec_stop(ndev);\n\t}\n\n\tphy_disconnect(ndev->phydev);\n\n\tif (fep->quirks & FEC_QUIRK_ERR006687)\n\t\timx6q_cpuidle_fec_irqs_unused();\n\n\tfec_enet_update_ethtool_stats(ndev);\n\n\tfec_enet_clk_enable(ndev, false);\n\tif (fep->quirks & FEC_QUIRK_HAS_PMQOS)\n\t\tcpu_latency_qos_remove_request(&fep->pm_qos_req);\n\n\tpinctrl_pm_select_sleep_state(&fep->pdev->dev);\n\tpm_runtime_mark_last_busy(&fep->pdev->dev);\n\tpm_runtime_put_autosuspend(&fep->pdev->dev);\n\n\tfec_enet_free_buffers(ndev);\n\n\treturn 0;\n}\n\n \n\n#define FEC_HASH_BITS\t6\t\t \n\nstatic void set_multicast_list(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct netdev_hw_addr *ha;\n\tunsigned int crc, tmp;\n\tunsigned char hash;\n\tunsigned int hash_high = 0, hash_low = 0;\n\n\tif (ndev->flags & IFF_PROMISC) {\n\t\ttmp = readl(fep->hwp + FEC_R_CNTRL);\n\t\ttmp |= 0x8;\n\t\twritel(tmp, fep->hwp + FEC_R_CNTRL);\n\t\treturn;\n\t}\n\n\ttmp = readl(fep->hwp + FEC_R_CNTRL);\n\ttmp &= ~0x8;\n\twritel(tmp, fep->hwp + FEC_R_CNTRL);\n\n\tif (ndev->flags & IFF_ALLMULTI) {\n\t\t \n\t\twritel(0xffffffff, fep->hwp + FEC_GRP_HASH_TABLE_HIGH);\n\t\twritel(0xffffffff, fep->hwp + FEC_GRP_HASH_TABLE_LOW);\n\n\t\treturn;\n\t}\n\n\t \n\tnetdev_for_each_mc_addr(ha, ndev) {\n\t\t \n\t\tcrc = ether_crc_le(ndev->addr_len, ha->addr);\n\n\t\t \n\t\thash = (crc >> (32 - FEC_HASH_BITS)) & 0x3f;\n\n\t\tif (hash > 31)\n\t\t\thash_high |= 1 << (hash - 32);\n\t\telse\n\t\t\thash_low |= 1 << hash;\n\t}\n\n\twritel(hash_high, fep->hwp + FEC_GRP_HASH_TABLE_HIGH);\n\twritel(hash_low, fep->hwp + FEC_GRP_HASH_TABLE_LOW);\n}\n\n \nstatic int\nfec_set_mac_address(struct net_device *ndev, void *p)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct sockaddr *addr = p;\n\n\tif (addr) {\n\t\tif (!is_valid_ether_addr(addr->sa_data))\n\t\t\treturn -EADDRNOTAVAIL;\n\t\teth_hw_addr_set(ndev, addr->sa_data);\n\t}\n\n\t \n\tif (!netif_running(ndev))\n\t\treturn 0;\n\n\twritel(ndev->dev_addr[3] | (ndev->dev_addr[2] << 8) |\n\t\t(ndev->dev_addr[1] << 16) | (ndev->dev_addr[0] << 24),\n\t\tfep->hwp + FEC_ADDR_LOW);\n\twritel((ndev->dev_addr[5] << 16) | (ndev->dev_addr[4] << 24),\n\t\tfep->hwp + FEC_ADDR_HIGH);\n\treturn 0;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\n \nstatic void fec_poll_controller(struct net_device *dev)\n{\n\tint i;\n\tstruct fec_enet_private *fep = netdev_priv(dev);\n\n\tfor (i = 0; i < FEC_IRQ_NUM; i++) {\n\t\tif (fep->irq[i] > 0) {\n\t\t\tdisable_irq(fep->irq[i]);\n\t\t\tfec_enet_interrupt(fep->irq[i], dev);\n\t\t\tenable_irq(fep->irq[i]);\n\t\t}\n\t}\n}\n#endif\n\nstatic inline void fec_enet_set_netdev_features(struct net_device *netdev,\n\tnetdev_features_t features)\n{\n\tstruct fec_enet_private *fep = netdev_priv(netdev);\n\tnetdev_features_t changed = features ^ netdev->features;\n\n\tnetdev->features = features;\n\n\t \n\tif (changed & NETIF_F_RXCSUM) {\n\t\tif (features & NETIF_F_RXCSUM)\n\t\t\tfep->csum_flags |= FLAG_RX_CSUM_ENABLED;\n\t\telse\n\t\t\tfep->csum_flags &= ~FLAG_RX_CSUM_ENABLED;\n\t}\n}\n\nstatic int fec_set_features(struct net_device *netdev,\n\tnetdev_features_t features)\n{\n\tstruct fec_enet_private *fep = netdev_priv(netdev);\n\tnetdev_features_t changed = features ^ netdev->features;\n\n\tif (netif_running(netdev) && changed & NETIF_F_RXCSUM) {\n\t\tnapi_disable(&fep->napi);\n\t\tnetif_tx_lock_bh(netdev);\n\t\tfec_stop(netdev);\n\t\tfec_enet_set_netdev_features(netdev, features);\n\t\tfec_restart(netdev);\n\t\tnetif_tx_wake_all_queues(netdev);\n\t\tnetif_tx_unlock_bh(netdev);\n\t\tnapi_enable(&fep->napi);\n\t} else {\n\t\tfec_enet_set_netdev_features(netdev, features);\n\t}\n\n\treturn 0;\n}\n\nstatic u16 fec_enet_select_queue(struct net_device *ndev, struct sk_buff *skb,\n\t\t\t\t struct net_device *sb_dev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tu16 vlan_tag = 0;\n\n\tif (!(fep->quirks & FEC_QUIRK_HAS_AVB))\n\t\treturn netdev_pick_tx(ndev, skb, NULL);\n\n\t \n\tif (eth_type_vlan(skb->protocol)) {\n\t\tstruct vlan_ethhdr *vhdr = skb_vlan_eth_hdr(skb);\n\n\t\tvlan_tag = ntohs(vhdr->h_vlan_TCI);\n\t \n\t} else if (skb_vlan_tag_present(skb)) {\n\t\tvlan_tag = skb->vlan_tci;\n\t} else {\n\t\treturn vlan_tag;\n\t}\n\n\treturn fec_enet_vlan_pri_to_queue[vlan_tag >> 13];\n}\n\nstatic int fec_enet_bpf(struct net_device *dev, struct netdev_bpf *bpf)\n{\n\tstruct fec_enet_private *fep = netdev_priv(dev);\n\tbool is_run = netif_running(dev);\n\tstruct bpf_prog *old_prog;\n\n\tswitch (bpf->command) {\n\tcase XDP_SETUP_PROG:\n\t\t \n\t\tif (fep->quirks & FEC_QUIRK_SWAP_FRAME)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif (!bpf->prog)\n\t\t\txdp_features_clear_redirect_target(dev);\n\n\t\tif (is_run) {\n\t\t\tnapi_disable(&fep->napi);\n\t\t\tnetif_tx_disable(dev);\n\t\t}\n\n\t\told_prog = xchg(&fep->xdp_prog, bpf->prog);\n\t\tif (old_prog)\n\t\t\tbpf_prog_put(old_prog);\n\n\t\tfec_restart(dev);\n\n\t\tif (is_run) {\n\t\t\tnapi_enable(&fep->napi);\n\t\t\tnetif_tx_start_all_queues(dev);\n\t\t}\n\n\t\tif (bpf->prog)\n\t\t\txdp_features_set_redirect_target(dev, false);\n\n\t\treturn 0;\n\n\tcase XDP_SETUP_XSK_POOL:\n\t\treturn -EOPNOTSUPP;\n\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic int\nfec_enet_xdp_get_tx_queue(struct fec_enet_private *fep, int index)\n{\n\tif (unlikely(index < 0))\n\t\treturn 0;\n\n\treturn (index % fep->num_tx_queues);\n}\n\nstatic int fec_enet_txq_xmit_frame(struct fec_enet_private *fep,\n\t\t\t\t   struct fec_enet_priv_tx_q *txq,\n\t\t\t\t   void *frame, u32 dma_sync_len,\n\t\t\t\t   bool ndo_xmit)\n{\n\tunsigned int index, status, estatus;\n\tstruct bufdesc *bdp;\n\tdma_addr_t dma_addr;\n\tint entries_free;\n\tu16 frame_len;\n\n\tentries_free = fec_enet_get_free_txdesc_num(txq);\n\tif (entries_free < MAX_SKB_FRAGS + 1) {\n\t\tnetdev_err_once(fep->netdev, \"NOT enough BD for SG!\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tbdp = txq->bd.cur;\n\tstatus = fec16_to_cpu(bdp->cbd_sc);\n\tstatus &= ~BD_ENET_TX_STATS;\n\n\tindex = fec_enet_get_bd_index(bdp, &txq->bd);\n\n\tif (ndo_xmit) {\n\t\tstruct xdp_frame *xdpf = frame;\n\n\t\tdma_addr = dma_map_single(&fep->pdev->dev, xdpf->data,\n\t\t\t\t\t  xdpf->len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(&fep->pdev->dev, dma_addr))\n\t\t\treturn -ENOMEM;\n\n\t\tframe_len = xdpf->len;\n\t\ttxq->tx_buf[index].buf_p = xdpf;\n\t\ttxq->tx_buf[index].type = FEC_TXBUF_T_XDP_NDO;\n\t} else {\n\t\tstruct xdp_buff *xdpb = frame;\n\t\tstruct page *page;\n\n\t\tpage = virt_to_page(xdpb->data);\n\t\tdma_addr = page_pool_get_dma_addr(page) +\n\t\t\t   (xdpb->data - xdpb->data_hard_start);\n\t\tdma_sync_single_for_device(&fep->pdev->dev, dma_addr,\n\t\t\t\t\t   dma_sync_len, DMA_BIDIRECTIONAL);\n\t\tframe_len = xdpb->data_end - xdpb->data;\n\t\ttxq->tx_buf[index].buf_p = page;\n\t\ttxq->tx_buf[index].type = FEC_TXBUF_T_XDP_TX;\n\t}\n\n\tstatus |= (BD_ENET_TX_INTR | BD_ENET_TX_LAST);\n\tif (fep->bufdesc_ex)\n\t\testatus = BD_ENET_TX_INT;\n\n\tbdp->cbd_bufaddr = cpu_to_fec32(dma_addr);\n\tbdp->cbd_datlen = cpu_to_fec16(frame_len);\n\n\tif (fep->bufdesc_ex) {\n\t\tstruct bufdesc_ex *ebdp = (struct bufdesc_ex *)bdp;\n\n\t\tif (fep->quirks & FEC_QUIRK_HAS_AVB)\n\t\t\testatus |= FEC_TX_BD_FTYPE(txq->bd.qid);\n\n\t\tebdp->cbd_bdu = 0;\n\t\tebdp->cbd_esc = cpu_to_fec32(estatus);\n\t}\n\n\t \n\tdma_wmb();\n\n\t \n\tstatus |= (BD_ENET_TX_READY | BD_ENET_TX_TC);\n\tbdp->cbd_sc = cpu_to_fec16(status);\n\n\t \n\tbdp = fec_enet_get_nextdesc(bdp, &txq->bd);\n\n\t \n\tdma_wmb();\n\n\ttxq->bd.cur = bdp;\n\n\t \n\twritel(0, txq->bd.reg_desc_active);\n\n\treturn 0;\n}\n\nstatic int fec_enet_xdp_tx_xmit(struct fec_enet_private *fep,\n\t\t\t\tint cpu, struct xdp_buff *xdp,\n\t\t\t\tu32 dma_sync_len)\n{\n\tstruct fec_enet_priv_tx_q *txq;\n\tstruct netdev_queue *nq;\n\tint queue, ret;\n\n\tqueue = fec_enet_xdp_get_tx_queue(fep, cpu);\n\ttxq = fep->tx_queue[queue];\n\tnq = netdev_get_tx_queue(fep->netdev, queue);\n\n\t__netif_tx_lock(nq, cpu);\n\n\t \n\ttxq_trans_cond_update(nq);\n\tret = fec_enet_txq_xmit_frame(fep, txq, xdp, dma_sync_len, false);\n\n\t__netif_tx_unlock(nq);\n\n\treturn ret;\n}\n\nstatic int fec_enet_xdp_xmit(struct net_device *dev,\n\t\t\t     int num_frames,\n\t\t\t     struct xdp_frame **frames,\n\t\t\t     u32 flags)\n{\n\tstruct fec_enet_private *fep = netdev_priv(dev);\n\tstruct fec_enet_priv_tx_q *txq;\n\tint cpu = smp_processor_id();\n\tunsigned int sent_frames = 0;\n\tstruct netdev_queue *nq;\n\tunsigned int queue;\n\tint i;\n\n\tqueue = fec_enet_xdp_get_tx_queue(fep, cpu);\n\ttxq = fep->tx_queue[queue];\n\tnq = netdev_get_tx_queue(fep->netdev, queue);\n\n\t__netif_tx_lock(nq, cpu);\n\n\t \n\ttxq_trans_cond_update(nq);\n\tfor (i = 0; i < num_frames; i++) {\n\t\tif (fec_enet_txq_xmit_frame(fep, txq, frames[i], 0, true) < 0)\n\t\t\tbreak;\n\t\tsent_frames++;\n\t}\n\n\t__netif_tx_unlock(nq);\n\n\treturn sent_frames;\n}\n\nstatic int fec_hwtstamp_get(struct net_device *ndev,\n\t\t\t    struct kernel_hwtstamp_config *config)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (!netif_running(ndev))\n\t\treturn -EINVAL;\n\n\tif (!fep->bufdesc_ex)\n\t\treturn -EOPNOTSUPP;\n\n\tfec_ptp_get(ndev, config);\n\n\treturn 0;\n}\n\nstatic int fec_hwtstamp_set(struct net_device *ndev,\n\t\t\t    struct kernel_hwtstamp_config *config,\n\t\t\t    struct netlink_ext_ack *extack)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (!netif_running(ndev))\n\t\treturn -EINVAL;\n\n\tif (!fep->bufdesc_ex)\n\t\treturn -EOPNOTSUPP;\n\n\treturn fec_ptp_set(ndev, config, extack);\n}\n\nstatic const struct net_device_ops fec_netdev_ops = {\n\t.ndo_open\t\t= fec_enet_open,\n\t.ndo_stop\t\t= fec_enet_close,\n\t.ndo_start_xmit\t\t= fec_enet_start_xmit,\n\t.ndo_select_queue       = fec_enet_select_queue,\n\t.ndo_set_rx_mode\t= set_multicast_list,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_tx_timeout\t\t= fec_timeout,\n\t.ndo_set_mac_address\t= fec_set_mac_address,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl_running,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= fec_poll_controller,\n#endif\n\t.ndo_set_features\t= fec_set_features,\n\t.ndo_bpf\t\t= fec_enet_bpf,\n\t.ndo_xdp_xmit\t\t= fec_enet_xdp_xmit,\n\t.ndo_hwtstamp_get\t= fec_hwtstamp_get,\n\t.ndo_hwtstamp_set\t= fec_hwtstamp_set,\n};\n\nstatic const unsigned short offset_des_active_rxq[] = {\n\tFEC_R_DES_ACTIVE_0, FEC_R_DES_ACTIVE_1, FEC_R_DES_ACTIVE_2\n};\n\nstatic const unsigned short offset_des_active_txq[] = {\n\tFEC_X_DES_ACTIVE_0, FEC_X_DES_ACTIVE_1, FEC_X_DES_ACTIVE_2\n};\n\n  \nstatic int fec_enet_init(struct net_device *ndev)\n{\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct bufdesc *cbd_base;\n\tdma_addr_t bd_dma;\n\tint bd_size;\n\tunsigned int i;\n\tunsigned dsize = fep->bufdesc_ex ? sizeof(struct bufdesc_ex) :\n\t\t\tsizeof(struct bufdesc);\n\tunsigned dsize_log2 = __fls(dsize);\n\tint ret;\n\n\tWARN_ON(dsize != (1 << dsize_log2));\n#if defined(CONFIG_ARM) || defined(CONFIG_ARM64)\n\tfep->rx_align = 0xf;\n\tfep->tx_align = 0xf;\n#else\n\tfep->rx_align = 0x3;\n\tfep->tx_align = 0x3;\n#endif\n\tfep->rx_pkts_itr = FEC_ITR_ICFT_DEFAULT;\n\tfep->tx_pkts_itr = FEC_ITR_ICFT_DEFAULT;\n\tfep->rx_time_itr = FEC_ITR_ICTT_DEFAULT;\n\tfep->tx_time_itr = FEC_ITR_ICTT_DEFAULT;\n\n\t \n\tret = dma_set_mask_and_coherent(&fep->pdev->dev, DMA_BIT_MASK(32));\n\tif (ret < 0) {\n\t\tdev_warn(&fep->pdev->dev, \"No suitable DMA available\\n\");\n\t\treturn ret;\n\t}\n\n\tret = fec_enet_alloc_queue(ndev);\n\tif (ret)\n\t\treturn ret;\n\n\tbd_size = (fep->total_tx_ring_size + fep->total_rx_ring_size) * dsize;\n\n\t \n\tcbd_base = dmam_alloc_coherent(&fep->pdev->dev, bd_size, &bd_dma,\n\t\t\t\t       GFP_KERNEL);\n\tif (!cbd_base) {\n\t\tret = -ENOMEM;\n\t\tgoto free_queue_mem;\n\t}\n\n\t \n\tret = fec_get_mac(ndev);\n\tif (ret)\n\t\tgoto free_queue_mem;\n\n\t \n\tfor (i = 0; i < fep->num_rx_queues; i++) {\n\t\tstruct fec_enet_priv_rx_q *rxq = fep->rx_queue[i];\n\t\tunsigned size = dsize * rxq->bd.ring_size;\n\n\t\trxq->bd.qid = i;\n\t\trxq->bd.base = cbd_base;\n\t\trxq->bd.cur = cbd_base;\n\t\trxq->bd.dma = bd_dma;\n\t\trxq->bd.dsize = dsize;\n\t\trxq->bd.dsize_log2 = dsize_log2;\n\t\trxq->bd.reg_desc_active = fep->hwp + offset_des_active_rxq[i];\n\t\tbd_dma += size;\n\t\tcbd_base = (struct bufdesc *)(((void *)cbd_base) + size);\n\t\trxq->bd.last = (struct bufdesc *)(((void *)cbd_base) - dsize);\n\t}\n\n\tfor (i = 0; i < fep->num_tx_queues; i++) {\n\t\tstruct fec_enet_priv_tx_q *txq = fep->tx_queue[i];\n\t\tunsigned size = dsize * txq->bd.ring_size;\n\n\t\ttxq->bd.qid = i;\n\t\ttxq->bd.base = cbd_base;\n\t\ttxq->bd.cur = cbd_base;\n\t\ttxq->bd.dma = bd_dma;\n\t\ttxq->bd.dsize = dsize;\n\t\ttxq->bd.dsize_log2 = dsize_log2;\n\t\ttxq->bd.reg_desc_active = fep->hwp + offset_des_active_txq[i];\n\t\tbd_dma += size;\n\t\tcbd_base = (struct bufdesc *)(((void *)cbd_base) + size);\n\t\ttxq->bd.last = (struct bufdesc *)(((void *)cbd_base) - dsize);\n\t}\n\n\n\t \n\tndev->watchdog_timeo = TX_TIMEOUT;\n\tndev->netdev_ops = &fec_netdev_ops;\n\tndev->ethtool_ops = &fec_enet_ethtool_ops;\n\n\twritel(FEC_RX_DISABLED_IMASK, fep->hwp + FEC_IMASK);\n\tnetif_napi_add(ndev, &fep->napi, fec_enet_rx_napi);\n\n\tif (fep->quirks & FEC_QUIRK_HAS_VLAN)\n\t\t \n\t\tndev->features |= NETIF_F_HW_VLAN_CTAG_RX;\n\n\tif (fep->quirks & FEC_QUIRK_HAS_CSUM) {\n\t\tnetif_set_tso_max_segs(ndev, FEC_MAX_TSO_SEGS);\n\n\t\t \n\t\tndev->features |= (NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM\n\t\t\t\t| NETIF_F_RXCSUM | NETIF_F_SG | NETIF_F_TSO);\n\t\tfep->csum_flags |= FLAG_RX_CSUM_ENABLED;\n\t}\n\n\tif (fep->quirks & FEC_QUIRK_HAS_MULTI_QUEUES) {\n\t\tfep->tx_align = 0;\n\t\tfep->rx_align = 0x3f;\n\t}\n\n\tndev->hw_features = ndev->features;\n\n\tif (!(fep->quirks & FEC_QUIRK_SWAP_FRAME))\n\t\tndev->xdp_features = NETDEV_XDP_ACT_BASIC |\n\t\t\t\t     NETDEV_XDP_ACT_REDIRECT;\n\n\tfec_restart(ndev);\n\n\tif (fep->quirks & FEC_QUIRK_MIB_CLEAR)\n\t\tfec_enet_clear_ethtool_stats(ndev);\n\telse\n\t\tfec_enet_update_ethtool_stats(ndev);\n\n\treturn 0;\n\nfree_queue_mem:\n\tfec_enet_free_queue(ndev);\n\treturn ret;\n}\n\n#ifdef CONFIG_OF\nstatic int fec_reset_phy(struct platform_device *pdev)\n{\n\tstruct gpio_desc *phy_reset;\n\tint msec = 1, phy_post_delay = 0;\n\tstruct device_node *np = pdev->dev.of_node;\n\tint err;\n\n\tif (!np)\n\t\treturn 0;\n\n\terr = of_property_read_u32(np, \"phy-reset-duration\", &msec);\n\t \n\tif (!err && msec > 1000)\n\t\tmsec = 1;\n\n\terr = of_property_read_u32(np, \"phy-reset-post-delay\", &phy_post_delay);\n\t \n\tif (!err && phy_post_delay > 1000)\n\t\treturn -EINVAL;\n\n\tphy_reset = devm_gpiod_get_optional(&pdev->dev, \"phy-reset\",\n\t\t\t\t\t    GPIOD_OUT_HIGH);\n\tif (IS_ERR(phy_reset))\n\t\treturn dev_err_probe(&pdev->dev, PTR_ERR(phy_reset),\n\t\t\t\t     \"failed to get phy-reset-gpios\\n\");\n\n\tif (!phy_reset)\n\t\treturn 0;\n\n\tif (msec > 20)\n\t\tmsleep(msec);\n\telse\n\t\tusleep_range(msec * 1000, msec * 1000 + 1000);\n\n\tgpiod_set_value_cansleep(phy_reset, 0);\n\n\tif (!phy_post_delay)\n\t\treturn 0;\n\n\tif (phy_post_delay > 20)\n\t\tmsleep(phy_post_delay);\n\telse\n\t\tusleep_range(phy_post_delay * 1000,\n\t\t\t     phy_post_delay * 1000 + 1000);\n\n\treturn 0;\n}\n#else  \nstatic int fec_reset_phy(struct platform_device *pdev)\n{\n\t \n\treturn 0;\n}\n#endif  \n\nstatic void\nfec_enet_get_queue_num(struct platform_device *pdev, int *num_tx, int *num_rx)\n{\n\tstruct device_node *np = pdev->dev.of_node;\n\n\t*num_tx = *num_rx = 1;\n\n\tif (!np || !of_device_is_available(np))\n\t\treturn;\n\n\t \n\tof_property_read_u32(np, \"fsl,num-tx-queues\", num_tx);\n\n\tof_property_read_u32(np, \"fsl,num-rx-queues\", num_rx);\n\n\tif (*num_tx < 1 || *num_tx > FEC_ENET_MAX_TX_QS) {\n\t\tdev_warn(&pdev->dev, \"Invalid num_tx(=%d), fall back to 1\\n\",\n\t\t\t *num_tx);\n\t\t*num_tx = 1;\n\t\treturn;\n\t}\n\n\tif (*num_rx < 1 || *num_rx > FEC_ENET_MAX_RX_QS) {\n\t\tdev_warn(&pdev->dev, \"Invalid num_rx(=%d), fall back to 1\\n\",\n\t\t\t *num_rx);\n\t\t*num_rx = 1;\n\t\treturn;\n\t}\n\n}\n\nstatic int fec_enet_get_irq_cnt(struct platform_device *pdev)\n{\n\tint irq_cnt = platform_irq_count(pdev);\n\n\tif (irq_cnt > FEC_IRQ_NUM)\n\t\tirq_cnt = FEC_IRQ_NUM;\t \n\telse if (irq_cnt == 2)\n\t\tirq_cnt = 1;\t \n\telse if (irq_cnt <= 0)\n\t\tirq_cnt = 1;\t \n\treturn irq_cnt;\n}\n\nstatic void fec_enet_get_wakeup_irq(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tif (fep->quirks & FEC_QUIRK_WAKEUP_FROM_INT2)\n\t\tfep->wake_irq = fep->irq[2];\n\telse\n\t\tfep->wake_irq = fep->irq[0];\n}\n\nstatic int fec_enet_init_stop_mode(struct fec_enet_private *fep,\n\t\t\t\t   struct device_node *np)\n{\n\tstruct device_node *gpr_np;\n\tu32 out_val[3];\n\tint ret = 0;\n\n\tgpr_np = of_parse_phandle(np, \"fsl,stop-mode\", 0);\n\tif (!gpr_np)\n\t\treturn 0;\n\n\tret = of_property_read_u32_array(np, \"fsl,stop-mode\", out_val,\n\t\t\t\t\t ARRAY_SIZE(out_val));\n\tif (ret) {\n\t\tdev_dbg(&fep->pdev->dev, \"no stop mode property\\n\");\n\t\tgoto out;\n\t}\n\n\tfep->stop_gpr.gpr = syscon_node_to_regmap(gpr_np);\n\tif (IS_ERR(fep->stop_gpr.gpr)) {\n\t\tdev_err(&fep->pdev->dev, \"could not find gpr regmap\\n\");\n\t\tret = PTR_ERR(fep->stop_gpr.gpr);\n\t\tfep->stop_gpr.gpr = NULL;\n\t\tgoto out;\n\t}\n\n\tfep->stop_gpr.reg = out_val[1];\n\tfep->stop_gpr.bit = out_val[2];\n\nout:\n\tof_node_put(gpr_np);\n\n\treturn ret;\n}\n\nstatic int\nfec_probe(struct platform_device *pdev)\n{\n\tstruct fec_enet_private *fep;\n\tstruct fec_platform_data *pdata;\n\tphy_interface_t interface;\n\tstruct net_device *ndev;\n\tint i, irq, ret = 0;\n\tconst struct of_device_id *of_id;\n\tstatic int dev_id;\n\tstruct device_node *np = pdev->dev.of_node, *phy_node;\n\tint num_tx_qs;\n\tint num_rx_qs;\n\tchar irq_name[8];\n\tint irq_cnt;\n\tstruct fec_devinfo *dev_info;\n\n\tfec_enet_get_queue_num(pdev, &num_tx_qs, &num_rx_qs);\n\n\t \n\tndev = alloc_etherdev_mqs(sizeof(struct fec_enet_private) +\n\t\t\t\t  FEC_STATS_SIZE, num_tx_qs, num_rx_qs);\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\n\t \n\tfep = netdev_priv(ndev);\n\n\tof_id = of_match_device(fec_dt_ids, &pdev->dev);\n\tif (of_id)\n\t\tpdev->id_entry = of_id->data;\n\tdev_info = (struct fec_devinfo *)pdev->id_entry->driver_data;\n\tif (dev_info)\n\t\tfep->quirks = dev_info->quirks;\n\n\tfep->netdev = ndev;\n\tfep->num_rx_queues = num_rx_qs;\n\tfep->num_tx_queues = num_tx_qs;\n\n#if !defined(CONFIG_M5272)\n\t \n\tif (fep->quirks & FEC_QUIRK_HAS_GBIT)\n\t\tfep->pause_flag |= FEC_PAUSE_FLAG_AUTONEG;\n#endif\n\n\t \n\tpinctrl_pm_select_default_state(&pdev->dev);\n\n\tfep->hwp = devm_platform_ioremap_resource(pdev, 0);\n\tif (IS_ERR(fep->hwp)) {\n\t\tret = PTR_ERR(fep->hwp);\n\t\tgoto failed_ioremap;\n\t}\n\n\tfep->pdev = pdev;\n\tfep->dev_id = dev_id++;\n\n\tplatform_set_drvdata(pdev, ndev);\n\n\tif ((of_machine_is_compatible(\"fsl,imx6q\") ||\n\t     of_machine_is_compatible(\"fsl,imx6dl\")) &&\n\t    !of_property_read_bool(np, \"fsl,err006687-workaround-present\"))\n\t\tfep->quirks |= FEC_QUIRK_ERR006687;\n\n\tret = fec_enet_ipc_handle_init(fep);\n\tif (ret)\n\t\tgoto failed_ipc_init;\n\n\tif (of_property_read_bool(np, \"fsl,magic-packet\"))\n\t\tfep->wol_flag |= FEC_WOL_HAS_MAGIC_PACKET;\n\n\tret = fec_enet_init_stop_mode(fep, np);\n\tif (ret)\n\t\tgoto failed_stop_mode;\n\n\tphy_node = of_parse_phandle(np, \"phy-handle\", 0);\n\tif (!phy_node && of_phy_is_fixed_link(np)) {\n\t\tret = of_phy_register_fixed_link(np);\n\t\tif (ret < 0) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"broken fixed-link specification\\n\");\n\t\t\tgoto failed_phy;\n\t\t}\n\t\tphy_node = of_node_get(np);\n\t}\n\tfep->phy_node = phy_node;\n\n\tret = of_get_phy_mode(pdev->dev.of_node, &interface);\n\tif (ret) {\n\t\tpdata = dev_get_platdata(&pdev->dev);\n\t\tif (pdata)\n\t\t\tfep->phy_interface = pdata->phy;\n\t\telse\n\t\t\tfep->phy_interface = PHY_INTERFACE_MODE_MII;\n\t} else {\n\t\tfep->phy_interface = interface;\n\t}\n\n\tret = fec_enet_parse_rgmii_delay(fep, np);\n\tif (ret)\n\t\tgoto failed_rgmii_delay;\n\n\tfep->clk_ipg = devm_clk_get(&pdev->dev, \"ipg\");\n\tif (IS_ERR(fep->clk_ipg)) {\n\t\tret = PTR_ERR(fep->clk_ipg);\n\t\tgoto failed_clk;\n\t}\n\n\tfep->clk_ahb = devm_clk_get(&pdev->dev, \"ahb\");\n\tif (IS_ERR(fep->clk_ahb)) {\n\t\tret = PTR_ERR(fep->clk_ahb);\n\t\tgoto failed_clk;\n\t}\n\n\tfep->itr_clk_rate = clk_get_rate(fep->clk_ahb);\n\n\t \n\tfep->clk_enet_out = devm_clk_get_optional(&pdev->dev, \"enet_out\");\n\tif (IS_ERR(fep->clk_enet_out)) {\n\t\tret = PTR_ERR(fep->clk_enet_out);\n\t\tgoto failed_clk;\n\t}\n\n\tfep->ptp_clk_on = false;\n\tmutex_init(&fep->ptp_clk_mutex);\n\n\t \n\tfep->clk_ref = devm_clk_get_optional(&pdev->dev, \"enet_clk_ref\");\n\tif (IS_ERR(fep->clk_ref)) {\n\t\tret = PTR_ERR(fep->clk_ref);\n\t\tgoto failed_clk;\n\t}\n\tfep->clk_ref_rate = clk_get_rate(fep->clk_ref);\n\n\t \n\tif (fep->rgmii_txc_dly || fep->rgmii_rxc_dly) {\n\t\tfep->clk_2x_txclk = devm_clk_get(&pdev->dev, \"enet_2x_txclk\");\n\t\tif (IS_ERR(fep->clk_2x_txclk))\n\t\t\tfep->clk_2x_txclk = NULL;\n\t}\n\n\tfep->bufdesc_ex = fep->quirks & FEC_QUIRK_HAS_BUFDESC_EX;\n\tfep->clk_ptp = devm_clk_get(&pdev->dev, \"ptp\");\n\tif (IS_ERR(fep->clk_ptp)) {\n\t\tfep->clk_ptp = NULL;\n\t\tfep->bufdesc_ex = false;\n\t}\n\n\tret = fec_enet_clk_enable(ndev, true);\n\tif (ret)\n\t\tgoto failed_clk;\n\n\tret = clk_prepare_enable(fep->clk_ipg);\n\tif (ret)\n\t\tgoto failed_clk_ipg;\n\tret = clk_prepare_enable(fep->clk_ahb);\n\tif (ret)\n\t\tgoto failed_clk_ahb;\n\n\tfep->reg_phy = devm_regulator_get_optional(&pdev->dev, \"phy\");\n\tif (!IS_ERR(fep->reg_phy)) {\n\t\tret = regulator_enable(fep->reg_phy);\n\t\tif (ret) {\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Failed to enable phy regulator: %d\\n\", ret);\n\t\t\tgoto failed_regulator;\n\t\t}\n\t} else {\n\t\tif (PTR_ERR(fep->reg_phy) == -EPROBE_DEFER) {\n\t\t\tret = -EPROBE_DEFER;\n\t\t\tgoto failed_regulator;\n\t\t}\n\t\tfep->reg_phy = NULL;\n\t}\n\n\tpm_runtime_set_autosuspend_delay(&pdev->dev, FEC_MDIO_PM_TIMEOUT);\n\tpm_runtime_use_autosuspend(&pdev->dev);\n\tpm_runtime_get_noresume(&pdev->dev);\n\tpm_runtime_set_active(&pdev->dev);\n\tpm_runtime_enable(&pdev->dev);\n\n\tret = fec_reset_phy(pdev);\n\tif (ret)\n\t\tgoto failed_reset;\n\n\tirq_cnt = fec_enet_get_irq_cnt(pdev);\n\tif (fep->bufdesc_ex)\n\t\tfec_ptp_init(pdev, irq_cnt);\n\n\tret = fec_enet_init(ndev);\n\tif (ret)\n\t\tgoto failed_init;\n\n\tfor (i = 0; i < irq_cnt; i++) {\n\t\tsnprintf(irq_name, sizeof(irq_name), \"int%d\", i);\n\t\tirq = platform_get_irq_byname_optional(pdev, irq_name);\n\t\tif (irq < 0)\n\t\t\tirq = platform_get_irq(pdev, i);\n\t\tif (irq < 0) {\n\t\t\tret = irq;\n\t\t\tgoto failed_irq;\n\t\t}\n\t\tret = devm_request_irq(&pdev->dev, irq, fec_enet_interrupt,\n\t\t\t\t       0, pdev->name, ndev);\n\t\tif (ret)\n\t\t\tgoto failed_irq;\n\n\t\tfep->irq[i] = irq;\n\t}\n\n\t \n\tfec_enet_get_wakeup_irq(pdev);\n\n\tret = fec_enet_mii_init(pdev);\n\tif (ret)\n\t\tgoto failed_mii_init;\n\n\t \n\tnetif_carrier_off(ndev);\n\tfec_enet_clk_enable(ndev, false);\n\tpinctrl_pm_select_sleep_state(&pdev->dev);\n\n\tndev->max_mtu = PKT_MAXBUF_SIZE - ETH_HLEN - ETH_FCS_LEN;\n\n\tret = register_netdev(ndev);\n\tif (ret)\n\t\tgoto failed_register;\n\n\tdevice_init_wakeup(&ndev->dev, fep->wol_flag &\n\t\t\t   FEC_WOL_HAS_MAGIC_PACKET);\n\n\tif (fep->bufdesc_ex && fep->ptp_clock)\n\t\tnetdev_info(ndev, \"registered PHC device %d\\n\", fep->dev_id);\n\n\tINIT_WORK(&fep->tx_timeout_work, fec_enet_timeout_work);\n\n\tpm_runtime_mark_last_busy(&pdev->dev);\n\tpm_runtime_put_autosuspend(&pdev->dev);\n\n\treturn 0;\n\nfailed_register:\n\tfec_enet_mii_remove(fep);\nfailed_mii_init:\nfailed_irq:\nfailed_init:\n\tfec_ptp_stop(pdev);\nfailed_reset:\n\tpm_runtime_put_noidle(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\tif (fep->reg_phy)\n\t\tregulator_disable(fep->reg_phy);\nfailed_regulator:\n\tclk_disable_unprepare(fep->clk_ahb);\nfailed_clk_ahb:\n\tclk_disable_unprepare(fep->clk_ipg);\nfailed_clk_ipg:\n\tfec_enet_clk_enable(ndev, false);\nfailed_clk:\nfailed_rgmii_delay:\n\tif (of_phy_is_fixed_link(np))\n\t\tof_phy_deregister_fixed_link(np);\n\tof_node_put(phy_node);\nfailed_stop_mode:\nfailed_ipc_init:\nfailed_phy:\n\tdev_id--;\nfailed_ioremap:\n\tfree_netdev(ndev);\n\n\treturn ret;\n}\n\nstatic void\nfec_drv_remove(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tstruct device_node *np = pdev->dev.of_node;\n\tint ret;\n\n\tret = pm_runtime_get_sync(&pdev->dev);\n\tif (ret < 0)\n\t\tdev_err(&pdev->dev,\n\t\t\t\"Failed to resume device in remove callback (%pe)\\n\",\n\t\t\tERR_PTR(ret));\n\n\tcancel_work_sync(&fep->tx_timeout_work);\n\tfec_ptp_stop(pdev);\n\tunregister_netdev(ndev);\n\tfec_enet_mii_remove(fep);\n\tif (fep->reg_phy)\n\t\tregulator_disable(fep->reg_phy);\n\n\tif (of_phy_is_fixed_link(np))\n\t\tof_phy_deregister_fixed_link(np);\n\tof_node_put(fep->phy_node);\n\n\t \n\tif (ret >= 0) {\n\t\tclk_disable_unprepare(fep->clk_ahb);\n\t\tclk_disable_unprepare(fep->clk_ipg);\n\t}\n\tpm_runtime_put_noidle(&pdev->dev);\n\tpm_runtime_disable(&pdev->dev);\n\n\tfree_netdev(ndev);\n}\n\nstatic int __maybe_unused fec_suspend(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint ret;\n\n\trtnl_lock();\n\tif (netif_running(ndev)) {\n\t\tif (fep->wol_flag & FEC_WOL_FLAG_ENABLE)\n\t\t\tfep->wol_flag |= FEC_WOL_FLAG_SLEEP_ON;\n\t\tphy_stop(ndev->phydev);\n\t\tnapi_disable(&fep->napi);\n\t\tnetif_tx_lock_bh(ndev);\n\t\tnetif_device_detach(ndev);\n\t\tnetif_tx_unlock_bh(ndev);\n\t\tfec_stop(ndev);\n\t\tif (!(fep->wol_flag & FEC_WOL_FLAG_ENABLE)) {\n\t\t\tfec_irqs_disable(ndev);\n\t\t\tpinctrl_pm_select_sleep_state(&fep->pdev->dev);\n\t\t} else {\n\t\t\tfec_irqs_disable_except_wakeup(ndev);\n\t\t\tif (fep->wake_irq > 0) {\n\t\t\t\tdisable_irq(fep->wake_irq);\n\t\t\t\tenable_irq_wake(fep->wake_irq);\n\t\t\t}\n\t\t\tfec_enet_stop_mode(fep, true);\n\t\t}\n\t\t \n\t\tfec_enet_clk_enable(ndev, false);\n\n\t\tfep->rpm_active = !pm_runtime_status_suspended(dev);\n\t\tif (fep->rpm_active) {\n\t\t\tret = pm_runtime_force_suspend(dev);\n\t\t\tif (ret < 0) {\n\t\t\t\trtnl_unlock();\n\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\trtnl_unlock();\n\n\tif (fep->reg_phy && !(fep->wol_flag & FEC_WOL_FLAG_ENABLE))\n\t\tregulator_disable(fep->reg_phy);\n\n\t \n\tif (fep->clk_enet_out || fep->reg_phy)\n\t\tfep->link = 0;\n\n\treturn 0;\n}\n\nstatic int __maybe_unused fec_resume(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint ret;\n\tint val;\n\n\tif (fep->reg_phy && !(fep->wol_flag & FEC_WOL_FLAG_ENABLE)) {\n\t\tret = regulator_enable(fep->reg_phy);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\trtnl_lock();\n\tif (netif_running(ndev)) {\n\t\tif (fep->rpm_active)\n\t\t\tpm_runtime_force_resume(dev);\n\n\t\tret = fec_enet_clk_enable(ndev, true);\n\t\tif (ret) {\n\t\t\trtnl_unlock();\n\t\t\tgoto failed_clk;\n\t\t}\n\t\tif (fep->wol_flag & FEC_WOL_FLAG_ENABLE) {\n\t\t\tfec_enet_stop_mode(fep, false);\n\t\t\tif (fep->wake_irq) {\n\t\t\t\tdisable_irq_wake(fep->wake_irq);\n\t\t\t\tenable_irq(fep->wake_irq);\n\t\t\t}\n\n\t\t\tval = readl(fep->hwp + FEC_ECNTRL);\n\t\t\tval &= ~(FEC_ECR_MAGICEN | FEC_ECR_SLEEP);\n\t\t\twritel(val, fep->hwp + FEC_ECNTRL);\n\t\t\tfep->wol_flag &= ~FEC_WOL_FLAG_SLEEP_ON;\n\t\t} else {\n\t\t\tpinctrl_pm_select_default_state(&fep->pdev->dev);\n\t\t}\n\t\tfec_restart(ndev);\n\t\tnetif_tx_lock_bh(ndev);\n\t\tnetif_device_attach(ndev);\n\t\tnetif_tx_unlock_bh(ndev);\n\t\tnapi_enable(&fep->napi);\n\t\tphy_init_hw(ndev->phydev);\n\t\tphy_start(ndev->phydev);\n\t}\n\trtnl_unlock();\n\n\treturn 0;\n\nfailed_clk:\n\tif (fep->reg_phy)\n\t\tregulator_disable(fep->reg_phy);\n\treturn ret;\n}\n\nstatic int __maybe_unused fec_runtime_suspend(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\n\tclk_disable_unprepare(fep->clk_ahb);\n\tclk_disable_unprepare(fep->clk_ipg);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused fec_runtime_resume(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct fec_enet_private *fep = netdev_priv(ndev);\n\tint ret;\n\n\tret = clk_prepare_enable(fep->clk_ahb);\n\tif (ret)\n\t\treturn ret;\n\tret = clk_prepare_enable(fep->clk_ipg);\n\tif (ret)\n\t\tgoto failed_clk_ipg;\n\n\treturn 0;\n\nfailed_clk_ipg:\n\tclk_disable_unprepare(fep->clk_ahb);\n\treturn ret;\n}\n\nstatic const struct dev_pm_ops fec_pm_ops = {\n\tSET_SYSTEM_SLEEP_PM_OPS(fec_suspend, fec_resume)\n\tSET_RUNTIME_PM_OPS(fec_runtime_suspend, fec_runtime_resume, NULL)\n};\n\nstatic struct platform_driver fec_driver = {\n\t.driver\t= {\n\t\t.name\t= DRIVER_NAME,\n\t\t.pm\t= &fec_pm_ops,\n\t\t.of_match_table = fec_dt_ids,\n\t\t.suppress_bind_attrs = true,\n\t},\n\t.id_table = fec_devtype,\n\t.probe\t= fec_probe,\n\t.remove_new = fec_drv_remove,\n};\n\nmodule_platform_driver(fec_driver);\n\nMODULE_LICENSE(\"GPL\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}