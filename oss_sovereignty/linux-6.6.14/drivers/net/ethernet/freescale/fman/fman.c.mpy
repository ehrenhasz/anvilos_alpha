{
  "module_name": "fman.c",
  "hash_id": "b243a5308a4c6944ee3fd7c992b3723678e203f699fd84015b1a154f0677d6ad",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/freescale/fman/fman.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/fsl/guts.h>\n#include <linux/platform_device.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/module.h>\n#include <linux/of_platform.h>\n#include <linux/clk.h>\n#include <linux/of_address.h>\n#include <linux/of_irq.h>\n#include <linux/interrupt.h>\n#include <linux/libfdt_env.h>\n\n#include \"fman.h\"\n#include \"fman_muram.h\"\n#include \"fman_keygen.h\"\n\n \n#define FMAN_LIODN_TBL\t\t\t64\t \n#define MAX_NUM_OF_MACS\t\t\t10\n#define FM_NUM_OF_FMAN_CTRL_EVENT_REGS\t4\n#define BASE_RX_PORTID\t\t\t0x08\n#define BASE_TX_PORTID\t\t\t0x28\n\n \n#define BMI_OFFSET\t\t0x00080000\n#define QMI_OFFSET\t\t0x00080400\n#define KG_OFFSET\t\t0x000C1000\n#define DMA_OFFSET\t\t0x000C2000\n#define FPM_OFFSET\t\t0x000C3000\n#define IMEM_OFFSET\t\t0x000C4000\n#define HWP_OFFSET\t\t0x000C7000\n#define CGP_OFFSET\t\t0x000DB000\n\n \n#define EX_DMA_BUS_ERROR\t\t0x80000000\n#define EX_DMA_READ_ECC\t\t\t0x40000000\n#define EX_DMA_SYSTEM_WRITE_ECC\t0x20000000\n#define EX_DMA_FM_WRITE_ECC\t\t0x10000000\n#define EX_FPM_STALL_ON_TASKS\t\t0x08000000\n#define EX_FPM_SINGLE_ECC\t\t0x04000000\n#define EX_FPM_DOUBLE_ECC\t\t0x02000000\n#define EX_QMI_SINGLE_ECC\t\t0x01000000\n#define EX_QMI_DEQ_FROM_UNKNOWN_PORTID\t0x00800000\n#define EX_QMI_DOUBLE_ECC\t\t0x00400000\n#define EX_BMI_LIST_RAM_ECC\t\t0x00200000\n#define EX_BMI_STORAGE_PROFILE_ECC\t0x00100000\n#define EX_BMI_STATISTICS_RAM_ECC\t0x00080000\n#define EX_IRAM_ECC\t\t\t0x00040000\n#define EX_MURAM_ECC\t\t\t0x00020000\n#define EX_BMI_DISPATCH_RAM_ECC\t0x00010000\n#define EX_DMA_SINGLE_PORT_ECC\t\t0x00008000\n\n \n \n#define DMA_MODE_BER\t\t\t0x00200000\n#define DMA_MODE_ECC\t\t\t0x00000020\n#define DMA_MODE_SECURE_PROT\t\t0x00000800\n#define DMA_MODE_AXI_DBG_MASK\t\t0x0F000000\n\n#define DMA_TRANSFER_PORTID_MASK\t0xFF000000\n#define DMA_TRANSFER_TNUM_MASK\t\t0x00FF0000\n#define DMA_TRANSFER_LIODN_MASK\t0x00000FFF\n\n#define DMA_STATUS_BUS_ERR\t\t0x08000000\n#define DMA_STATUS_READ_ECC\t\t0x04000000\n#define DMA_STATUS_SYSTEM_WRITE_ECC\t0x02000000\n#define DMA_STATUS_FM_WRITE_ECC\t0x01000000\n#define DMA_STATUS_FM_SPDAT_ECC\t0x00080000\n\n#define DMA_MODE_CACHE_OR_SHIFT\t\t30\n#define DMA_MODE_AXI_DBG_SHIFT\t\t\t24\n#define DMA_MODE_CEN_SHIFT\t\t\t13\n#define DMA_MODE_CEN_MASK\t\t\t0x00000007\n#define DMA_MODE_DBG_SHIFT\t\t\t7\n#define DMA_MODE_AID_MODE_SHIFT\t\t4\n\n#define DMA_THRESH_COMMQ_SHIFT\t\t\t24\n#define DMA_THRESH_READ_INT_BUF_SHIFT\t\t16\n#define DMA_THRESH_READ_INT_BUF_MASK\t\t0x0000003f\n#define DMA_THRESH_WRITE_INT_BUF_MASK\t\t0x0000003f\n\n#define DMA_TRANSFER_PORTID_SHIFT\t\t24\n#define DMA_TRANSFER_TNUM_SHIFT\t\t16\n\n#define DMA_CAM_SIZEOF_ENTRY\t\t\t0x40\n#define DMA_CAM_UNITS\t\t\t\t8\n\n#define DMA_LIODN_SHIFT\t\t16\n#define DMA_LIODN_BASE_MASK\t0x00000FFF\n\n \n#define FPM_EV_MASK_DOUBLE_ECC\t\t0x80000000\n#define FPM_EV_MASK_STALL\t\t0x40000000\n#define FPM_EV_MASK_SINGLE_ECC\t\t0x20000000\n#define FPM_EV_MASK_RELEASE_FM\t\t0x00010000\n#define FPM_EV_MASK_DOUBLE_ECC_EN\t0x00008000\n#define FPM_EV_MASK_STALL_EN\t\t0x00004000\n#define FPM_EV_MASK_SINGLE_ECC_EN\t0x00002000\n#define FPM_EV_MASK_EXTERNAL_HALT\t0x00000008\n#define FPM_EV_MASK_ECC_ERR_HALT\t0x00000004\n\n#define FPM_RAM_MURAM_ECC\t\t0x00008000\n#define FPM_RAM_IRAM_ECC\t\t0x00004000\n#define FPM_IRAM_ECC_ERR_EX_EN\t\t0x00020000\n#define FPM_MURAM_ECC_ERR_EX_EN\t0x00040000\n#define FPM_RAM_IRAM_ECC_EN\t\t0x40000000\n#define FPM_RAM_RAMS_ECC_EN\t\t0x80000000\n#define FPM_RAM_RAMS_ECC_EN_SRC_SEL\t0x08000000\n\n#define FPM_REV1_MAJOR_MASK\t\t0x0000FF00\n#define FPM_REV1_MINOR_MASK\t\t0x000000FF\n\n#define FPM_DISP_LIMIT_SHIFT\t\t24\n\n#define FPM_PRT_FM_CTL1\t\t\t0x00000001\n#define FPM_PRT_FM_CTL2\t\t\t0x00000002\n#define FPM_PORT_FM_CTL_PORTID_SHIFT\t24\n#define FPM_PRC_ORA_FM_CTL_SEL_SHIFT\t16\n\n#define FPM_THR1_PRS_SHIFT\t\t24\n#define FPM_THR1_KG_SHIFT\t\t16\n#define FPM_THR1_PLCR_SHIFT\t\t8\n#define FPM_THR1_BMI_SHIFT\t\t0\n\n#define FPM_THR2_QMI_ENQ_SHIFT\t\t24\n#define FPM_THR2_QMI_DEQ_SHIFT\t\t0\n#define FPM_THR2_FM_CTL1_SHIFT\t\t16\n#define FPM_THR2_FM_CTL2_SHIFT\t\t8\n\n#define FPM_EV_MASK_CAT_ERR_SHIFT\t1\n#define FPM_EV_MASK_DMA_ERR_SHIFT\t0\n\n#define FPM_REV1_MAJOR_SHIFT\t\t8\n\n#define FPM_RSTC_FM_RESET\t\t0x80000000\n#define FPM_RSTC_MAC0_RESET\t\t0x40000000\n#define FPM_RSTC_MAC1_RESET\t\t0x20000000\n#define FPM_RSTC_MAC2_RESET\t\t0x10000000\n#define FPM_RSTC_MAC3_RESET\t\t0x08000000\n#define FPM_RSTC_MAC8_RESET\t\t0x04000000\n#define FPM_RSTC_MAC4_RESET\t\t0x02000000\n#define FPM_RSTC_MAC5_RESET\t\t0x01000000\n#define FPM_RSTC_MAC6_RESET\t\t0x00800000\n#define FPM_RSTC_MAC7_RESET\t\t0x00400000\n#define FPM_RSTC_MAC9_RESET\t\t0x00200000\n\n#define FPM_TS_INT_SHIFT\t\t16\n#define FPM_TS_CTL_EN\t\t\t0x80000000\n\n \n#define BMI_INIT_START\t\t\t\t0x80000000\n#define BMI_ERR_INTR_EN_STORAGE_PROFILE_ECC\t0x80000000\n#define BMI_ERR_INTR_EN_LIST_RAM_ECC\t\t0x40000000\n#define BMI_ERR_INTR_EN_STATISTICS_RAM_ECC\t0x20000000\n#define BMI_ERR_INTR_EN_DISPATCH_RAM_ECC\t0x10000000\n#define BMI_NUM_OF_TASKS_MASK\t\t\t0x3F000000\n#define BMI_NUM_OF_EXTRA_TASKS_MASK\t\t0x000F0000\n#define BMI_NUM_OF_DMAS_MASK\t\t\t0x00000F00\n#define BMI_NUM_OF_EXTRA_DMAS_MASK\t\t0x0000000F\n#define BMI_FIFO_SIZE_MASK\t\t\t0x000003FF\n#define BMI_EXTRA_FIFO_SIZE_MASK\t\t0x03FF0000\n#define BMI_CFG2_DMAS_MASK\t\t\t0x0000003F\n#define BMI_CFG2_TASKS_MASK\t\t\t0x0000003F\n\n#define BMI_CFG2_TASKS_SHIFT\t\t16\n#define BMI_CFG2_DMAS_SHIFT\t\t0\n#define BMI_CFG1_FIFO_SIZE_SHIFT\t16\n#define BMI_NUM_OF_TASKS_SHIFT\t\t24\n#define BMI_EXTRA_NUM_OF_TASKS_SHIFT\t16\n#define BMI_NUM_OF_DMAS_SHIFT\t\t8\n#define BMI_EXTRA_NUM_OF_DMAS_SHIFT\t0\n\n#define BMI_FIFO_ALIGN\t\t\t0x100\n\n#define BMI_EXTRA_FIFO_SIZE_SHIFT\t16\n\n \n#define QMI_CFG_ENQ_EN\t\t\t0x80000000\n#define QMI_CFG_DEQ_EN\t\t\t0x40000000\n#define QMI_CFG_EN_COUNTERS\t\t0x10000000\n#define QMI_CFG_DEQ_MASK\t\t0x0000003F\n#define QMI_CFG_ENQ_MASK\t\t0x00003F00\n#define QMI_CFG_ENQ_SHIFT\t\t8\n\n#define QMI_ERR_INTR_EN_DOUBLE_ECC\t0x80000000\n#define QMI_ERR_INTR_EN_DEQ_FROM_DEF\t0x40000000\n#define QMI_INTR_EN_SINGLE_ECC\t\t0x80000000\n\n#define QMI_GS_HALT_NOT_BUSY\t\t0x00000002\n\n \n#define HWP_RPIMAC_PEN\t\t\t0x00000001\n\n \n#define IRAM_IADD_AIE\t\t\t0x80000000\n#define IRAM_READY\t\t\t0x80000000\n\n \n#define DEFAULT_CATASTROPHIC_ERR\t\t0\n#define DEFAULT_DMA_ERR\t\t\t\t0\n#define DEFAULT_AID_MODE\t\t\tFMAN_DMA_AID_OUT_TNUM\n#define DEFAULT_DMA_COMM_Q_LOW\t\t\t0x2A\n#define DEFAULT_DMA_COMM_Q_HIGH\t\t0x3F\n#define DEFAULT_CACHE_OVERRIDE\t\t\t0\n#define DEFAULT_DMA_CAM_NUM_OF_ENTRIES\t\t64\n#define DEFAULT_DMA_DBG_CNT_MODE\t\t0\n#define DEFAULT_DMA_SOS_EMERGENCY\t\t0\n#define DEFAULT_DMA_WATCHDOG\t\t\t0\n#define DEFAULT_DISP_LIMIT\t\t\t0\n#define DEFAULT_PRS_DISP_TH\t\t\t16\n#define DEFAULT_PLCR_DISP_TH\t\t\t16\n#define DEFAULT_KG_DISP_TH\t\t\t16\n#define DEFAULT_BMI_DISP_TH\t\t\t16\n#define DEFAULT_QMI_ENQ_DISP_TH\t\t16\n#define DEFAULT_QMI_DEQ_DISP_TH\t\t16\n#define DEFAULT_FM_CTL1_DISP_TH\t\t16\n#define DEFAULT_FM_CTL2_DISP_TH\t\t16\n\n#define DFLT_AXI_DBG_NUM_OF_BEATS\t\t1\n\n#define DFLT_DMA_READ_INT_BUF_LOW(dma_thresh_max_buf)\t\\\n\t((dma_thresh_max_buf + 1) / 2)\n#define DFLT_DMA_READ_INT_BUF_HIGH(dma_thresh_max_buf)\t\\\n\t((dma_thresh_max_buf + 1) * 3 / 4)\n#define DFLT_DMA_WRITE_INT_BUF_LOW(dma_thresh_max_buf)\t\\\n\t((dma_thresh_max_buf + 1) / 2)\n#define DFLT_DMA_WRITE_INT_BUF_HIGH(dma_thresh_max_buf)\\\n\t((dma_thresh_max_buf + 1) * 3 / 4)\n\n#define DMA_COMM_Q_LOW_FMAN_V3\t\t0x2A\n#define DMA_COMM_Q_LOW_FMAN_V2(dma_thresh_max_commq)\t\t\\\n\t((dma_thresh_max_commq + 1) / 2)\n#define DFLT_DMA_COMM_Q_LOW(major, dma_thresh_max_commq)\t\\\n\t((major == 6) ? DMA_COMM_Q_LOW_FMAN_V3 :\t\t\\\n\tDMA_COMM_Q_LOW_FMAN_V2(dma_thresh_max_commq))\n\n#define DMA_COMM_Q_HIGH_FMAN_V3\t0x3f\n#define DMA_COMM_Q_HIGH_FMAN_V2(dma_thresh_max_commq)\t\t\\\n\t((dma_thresh_max_commq + 1) * 3 / 4)\n#define DFLT_DMA_COMM_Q_HIGH(major, dma_thresh_max_commq)\t\\\n\t((major == 6) ? DMA_COMM_Q_HIGH_FMAN_V3 :\t\t\\\n\tDMA_COMM_Q_HIGH_FMAN_V2(dma_thresh_max_commq))\n\n#define TOTAL_NUM_OF_TASKS_FMAN_V3L\t59\n#define TOTAL_NUM_OF_TASKS_FMAN_V3H\t124\n#define DFLT_TOTAL_NUM_OF_TASKS(major, minor, bmi_max_num_of_tasks)\t\\\n\t((major == 6) ? ((minor == 1 || minor == 4) ?\t\t\t\\\n\tTOTAL_NUM_OF_TASKS_FMAN_V3L : TOTAL_NUM_OF_TASKS_FMAN_V3H) :\t\\\n\tbmi_max_num_of_tasks)\n\n#define DMA_CAM_NUM_OF_ENTRIES_FMAN_V3\t\t64\n#define DMA_CAM_NUM_OF_ENTRIES_FMAN_V2\t\t32\n#define DFLT_DMA_CAM_NUM_OF_ENTRIES(major)\t\t\t\\\n\t(major == 6 ? DMA_CAM_NUM_OF_ENTRIES_FMAN_V3 :\t\t\\\n\tDMA_CAM_NUM_OF_ENTRIES_FMAN_V2)\n\n#define FM_TIMESTAMP_1_USEC_BIT             8\n\n \n#define ERR_INTR_EN_DMA         0x00010000\n#define ERR_INTR_EN_FPM         0x80000000\n#define ERR_INTR_EN_BMI         0x00800000\n#define ERR_INTR_EN_QMI         0x00400000\n#define ERR_INTR_EN_MURAM       0x00040000\n#define ERR_INTR_EN_MAC0        0x00004000\n#define ERR_INTR_EN_MAC1        0x00002000\n#define ERR_INTR_EN_MAC2        0x00001000\n#define ERR_INTR_EN_MAC3        0x00000800\n#define ERR_INTR_EN_MAC4        0x00000400\n#define ERR_INTR_EN_MAC5        0x00000200\n#define ERR_INTR_EN_MAC6        0x00000100\n#define ERR_INTR_EN_MAC7        0x00000080\n#define ERR_INTR_EN_MAC8        0x00008000\n#define ERR_INTR_EN_MAC9        0x00000040\n\n#define INTR_EN_QMI             0x40000000\n#define INTR_EN_MAC0            0x00080000\n#define INTR_EN_MAC1            0x00040000\n#define INTR_EN_MAC2            0x00020000\n#define INTR_EN_MAC3            0x00010000\n#define INTR_EN_MAC4            0x00000040\n#define INTR_EN_MAC5            0x00000020\n#define INTR_EN_MAC6            0x00000008\n#define INTR_EN_MAC7            0x00000002\n#define INTR_EN_MAC8            0x00200000\n#define INTR_EN_MAC9            0x00100000\n#define INTR_EN_REV0            0x00008000\n#define INTR_EN_REV1            0x00004000\n#define INTR_EN_REV2            0x00002000\n#define INTR_EN_REV3            0x00001000\n#define INTR_EN_TMR             0x01000000\n\nenum fman_dma_aid_mode {\n\tFMAN_DMA_AID_OUT_PORT_ID = 0,\t\t   \n\tFMAN_DMA_AID_OUT_TNUM\t\t\t   \n};\n\nstruct fman_iram_regs {\n\tu32 iadd;\t \n\tu32 idata;\t \n\tu32 itcfg;\t \n\tu32 iready;\t \n};\n\nstruct fman_fpm_regs {\n\tu32 fmfp_tnc;\t\t \n\tu32 fmfp_prc;\t\t \n\tu32 fmfp_brkc;\t\t \n\tu32 fmfp_mxd;\t\t \n\tu32 fmfp_dist1;\t\t \n\tu32 fmfp_dist2;\t\t \n\tu32 fm_epi;\t\t \n\tu32 fm_rie;\t\t \n\tu32 fmfp_fcev[4];\t \n\tu32 res0030[4];\t\t \n\tu32 fmfp_cee[4];\t \n\tu32 res0050[4];\t\t \n\tu32 fmfp_tsc1;\t\t \n\tu32 fmfp_tsc2;\t\t \n\tu32 fmfp_tsp;\t\t \n\tu32 fmfp_tsf;\t\t \n\tu32 fm_rcr;\t\t \n\tu32 fmfp_extc;\t\t \n\tu32 fmfp_ext1;\t\t \n\tu32 fmfp_ext2;\t\t \n\tu32 fmfp_drd[16];\t \n\tu32 fmfp_dra;\t\t \n\tu32 fm_ip_rev_1;\t \n\tu32 fm_ip_rev_2;\t \n\tu32 fm_rstc;\t\t \n\tu32 fm_cld;\t\t \n\tu32 fm_npi;\t\t \n\tu32 fmfp_exte;\t\t \n\tu32 fmfp_ee;\t\t \n\tu32 fmfp_cev[4];\t \n\tu32 res00f0[4];\t\t \n\tu32 fmfp_ps[50];\t \n\tu32 res01c8[14];\t \n\tu32 fmfp_clfabc;\t \n\tu32 fmfp_clfcc;\t\t \n\tu32 fmfp_clfaval;\t \n\tu32 fmfp_clfbval;\t \n\tu32 fmfp_clfcval;\t \n\tu32 fmfp_clfamsk;\t \n\tu32 fmfp_clfbmsk;\t \n\tu32 fmfp_clfcmsk;\t \n\tu32 fmfp_clfamc;\t \n\tu32 fmfp_clfbmc;\t \n\tu32 fmfp_clfcmc;\t \n\tu32 fmfp_decceh;\t \n\tu32 res0230[116];\t \n\tu32 fmfp_ts[128];\t \n\tu32 res0600[0x400 - 384];\n};\n\nstruct fman_bmi_regs {\n\tu32 fmbm_init;\t\t \n\tu32 fmbm_cfg1;\t\t \n\tu32 fmbm_cfg2;\t\t \n\tu32 res000c[5];\t\t \n\tu32 fmbm_ievr;\t\t \n\tu32 fmbm_ier;\t\t \n\tu32 fmbm_ifr;\t\t \n\tu32 res002c[5];\t\t \n\tu32 fmbm_arb[8];\t \n\tu32 res0060[12];\t \n\tu32 fmbm_dtc[3];\t \n\tu32 res009c;\t\t \n\tu32 fmbm_dcv[3][4];\t \n\tu32 fmbm_dcm[3][4];\t \n\tu32 fmbm_gde;\t\t \n\tu32 fmbm_pp[63];\t \n\tu32 res0200;\t\t \n\tu32 fmbm_pfs[63];\t \n\tu32 res0300;\t\t \n\tu32 fmbm_spliodn[63];\t \n};\n\nstruct fman_qmi_regs {\n\tu32 fmqm_gc;\t\t \n\tu32 res0004;\t\t \n\tu32 fmqm_eie;\t\t \n\tu32 fmqm_eien;\t\t \n\tu32 fmqm_eif;\t\t \n\tu32 fmqm_ie;\t\t \n\tu32 fmqm_ien;\t\t \n\tu32 fmqm_if;\t\t \n\tu32 fmqm_gs;\t\t \n\tu32 fmqm_ts;\t\t \n\tu32 fmqm_etfc;\t\t \n\tu32 fmqm_dtfc;\t\t \n\tu32 fmqm_dc0;\t\t \n\tu32 fmqm_dc1;\t\t \n\tu32 fmqm_dc2;\t\t \n\tu32 fmqm_dc3;\t\t \n\tu32 fmqm_dfdc;\t\t \n\tu32 fmqm_dfcc;\t\t \n\tu32 fmqm_dffc;\t\t \n\tu32 fmqm_dcc;\t\t \n\tu32 res0050[7];\t\t \n\tu32 fmqm_tapc;\t\t \n\tu32 fmqm_dmcvc;\t\t \n\tu32 fmqm_difdcc;\t \n\tu32 fmqm_da1v;\t\t \n\tu32 res007c;\t\t \n\tu32 fmqm_dtc;\t\t \n\tu32 fmqm_efddd;\t\t \n\tu32 res0088[2];\t\t \n\tstruct {\n\t\tu32 fmqm_dtcfg1;\t \n\t\tu32 fmqm_dtval1;\t \n\t\tu32 fmqm_dtm1;\t\t \n\t\tu32 fmqm_dtc1;\t\t \n\t\tu32 fmqm_dtcfg2;\t \n\t\tu32 fmqm_dtval2;\t \n\t\tu32 fmqm_dtm2;\t\t \n\t\tu32 res001c;\t\t \n\t} dbg_traps[3];\t\t\t \n\tu8 res00f0[0x400 - 0xf0];\t \n};\n\nstruct fman_dma_regs {\n\tu32 fmdmsr;\t \n\tu32 fmdmmr;\t \n\tu32 fmdmtr;\t \n\tu32 fmdmhy;\t \n\tu32 fmdmsetr;\t \n\tu32 fmdmtah;\t \n\tu32 fmdmtal;\t \n\tu32 fmdmtcid;\t \n\tu32 fmdmra;\t \n\tu32 fmdmrd;\t \n\tu32 fmdmwcr;\t \n\tu32 fmdmebcr;\t \n\tu32 fmdmccqdr;\t \n\tu32 fmdmccqvr1;\t \n\tu32 fmdmccqvr2;\t \n\tu32 fmdmcqvr3;\t \n\tu32 fmdmcqvr4;\t \n\tu32 fmdmcqvr5;\t \n\tu32 fmdmsefrc;\t \n\tu32 fmdmsqfrc;\t \n\tu32 fmdmssrc;\t \n\tu32 fmdmdcr;\t \n\tu32 fmdmemsr;\t \n\tu32 res005c;\t \n\tu32 fmdmplr[FMAN_LIODN_TBL / 2];\t \n\tu32 res00e0[0x400 - 56];\n};\n\nstruct fman_hwp_regs {\n\tu32 res0000[0x844 / 4];\t\t \n\tu32 fmprrpimac;\t \n\tu32 res[(0x1000 - 0x848) / 4];\t \n};\n\n \nstruct fman_state_struct {\n\tu8 fm_id;\n\tu16 fm_clk_freq;\n\tstruct fman_rev_info rev_info;\n\tbool enabled_time_stamp;\n\tu8 count1_micro_bit;\n\tu8 total_num_of_tasks;\n\tu8 accumulated_num_of_tasks;\n\tu32 accumulated_fifo_size;\n\tu8 accumulated_num_of_open_dmas;\n\tu8 accumulated_num_of_deq_tnums;\n\tu32 exceptions;\n\tu32 extra_fifo_pool_size;\n\tu8 extra_tasks_pool_size;\n\tu8 extra_open_dmas_pool_size;\n\tu16 port_mfl[MAX_NUM_OF_MACS];\n\tu16 mac_mfl[MAX_NUM_OF_MACS];\n\n\t \n\tu32 fm_iram_size;\n\t \n\tu32 dma_thresh_max_commq;\n\tu32 dma_thresh_max_buf;\n\tu32 max_num_of_open_dmas;\n\t \n\tu32 qmi_max_num_of_tnums;\n\tu32 qmi_def_tnums_thresh;\n\t \n\tu32 bmi_max_num_of_tasks;\n\tu32 bmi_max_fifo_size;\n\t \n\tu32 fm_port_num_of_cg;\n\tu32 num_of_rx_ports;\n\tu32 total_fifo_size;\n\n\tu32 qman_channel_base;\n\tu32 num_of_qman_channels;\n\n\tstruct resource *res;\n};\n\n \nstruct fman_cfg {\n\tu8 disp_limit_tsh;\n\tu8 prs_disp_tsh;\n\tu8 plcr_disp_tsh;\n\tu8 kg_disp_tsh;\n\tu8 bmi_disp_tsh;\n\tu8 qmi_enq_disp_tsh;\n\tu8 qmi_deq_disp_tsh;\n\tu8 fm_ctl1_disp_tsh;\n\tu8 fm_ctl2_disp_tsh;\n\tint dma_cache_override;\n\tenum fman_dma_aid_mode dma_aid_mode;\n\tu32 dma_axi_dbg_num_of_beats;\n\tu32 dma_cam_num_of_entries;\n\tu32 dma_watchdog;\n\tu8 dma_comm_qtsh_asrt_emer;\n\tu32 dma_write_buf_tsh_asrt_emer;\n\tu32 dma_read_buf_tsh_asrt_emer;\n\tu8 dma_comm_qtsh_clr_emer;\n\tu32 dma_write_buf_tsh_clr_emer;\n\tu32 dma_read_buf_tsh_clr_emer;\n\tu32 dma_sos_emergency;\n\tint dma_dbg_cnt_mode;\n\tint catastrophic_err;\n\tint dma_err;\n\tu32 exceptions;\n\tu16 clk_freq;\n\tu32 cam_base_addr;\n\tu32 fifo_base_addr;\n\tu32 total_fifo_size;\n\tu32 total_num_of_tasks;\n\tu32 qmi_def_tnums_thresh;\n};\n\n#ifdef CONFIG_DPAA_ERRATUM_A050385\nstatic bool fman_has_err_a050385;\n#endif\n\nstatic irqreturn_t fman_exceptions(struct fman *fman,\n\t\t\t\t   enum fman_exceptions exception)\n{\n\tdev_dbg(fman->dev, \"%s: FMan[%d] exception %d\\n\",\n\t\t__func__, fman->state->fm_id, exception);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t fman_bus_error(struct fman *fman, u8 __maybe_unused port_id,\n\t\t\t\t  u64 __maybe_unused addr,\n\t\t\t\t  u8 __maybe_unused tnum,\n\t\t\t\t  u16 __maybe_unused liodn)\n{\n\tdev_dbg(fman->dev, \"%s: FMan[%d] bus error: port_id[%d]\\n\",\n\t\t__func__, fman->state->fm_id, port_id);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic inline irqreturn_t call_mac_isr(struct fman *fman, u8 id)\n{\n\tif (fman->intr_mng[id].isr_cb) {\n\t\tfman->intr_mng[id].isr_cb(fman->intr_mng[id].src_handle);\n\n\t\treturn IRQ_HANDLED;\n\t}\n\n\treturn IRQ_NONE;\n}\n\nstatic inline u8 hw_port_id_to_sw_port_id(u8 major, u8 hw_port_id)\n{\n\tu8 sw_port_id = 0;\n\n\tif (hw_port_id >= BASE_TX_PORTID)\n\t\tsw_port_id = hw_port_id - BASE_TX_PORTID;\n\telse if (hw_port_id >= BASE_RX_PORTID)\n\t\tsw_port_id = hw_port_id - BASE_RX_PORTID;\n\telse\n\t\tsw_port_id = 0;\n\n\treturn sw_port_id;\n}\n\nstatic void set_port_order_restoration(struct fman_fpm_regs __iomem *fpm_rg,\n\t\t\t\t       u8 port_id)\n{\n\tu32 tmp = 0;\n\n\ttmp = port_id << FPM_PORT_FM_CTL_PORTID_SHIFT;\n\n\ttmp |= FPM_PRT_FM_CTL2 | FPM_PRT_FM_CTL1;\n\n\t \n\tif (port_id % 2)\n\t\ttmp |= FPM_PRT_FM_CTL1 << FPM_PRC_ORA_FM_CTL_SEL_SHIFT;\n\telse\n\t\ttmp |= FPM_PRT_FM_CTL2 << FPM_PRC_ORA_FM_CTL_SEL_SHIFT;\n\n\tiowrite32be(tmp, &fpm_rg->fmfp_prc);\n}\n\nstatic void set_port_liodn(struct fman *fman, u8 port_id,\n\t\t\t   u32 liodn_base, u32 liodn_ofst)\n{\n\tu32 tmp;\n\n\tiowrite32be(liodn_ofst, &fman->bmi_regs->fmbm_spliodn[port_id - 1]);\n\tif (!IS_ENABLED(CONFIG_FSL_PAMU))\n\t\treturn;\n\t \n\ttmp = ioread32be(&fman->dma_regs->fmdmplr[port_id / 2]);\n\tif (port_id % 2) {\n\t\ttmp &= ~DMA_LIODN_BASE_MASK;\n\t\ttmp |= liodn_base;\n\t} else {\n\t\ttmp &= ~(DMA_LIODN_BASE_MASK << DMA_LIODN_SHIFT);\n\t\ttmp |= liodn_base << DMA_LIODN_SHIFT;\n\t}\n\tiowrite32be(tmp, &fman->dma_regs->fmdmplr[port_id / 2]);\n}\n\nstatic void enable_rams_ecc(struct fman_fpm_regs __iomem *fpm_rg)\n{\n\tu32 tmp;\n\n\ttmp = ioread32be(&fpm_rg->fm_rcr);\n\tif (tmp & FPM_RAM_RAMS_ECC_EN_SRC_SEL)\n\t\tiowrite32be(tmp | FPM_RAM_IRAM_ECC_EN, &fpm_rg->fm_rcr);\n\telse\n\t\tiowrite32be(tmp | FPM_RAM_RAMS_ECC_EN |\n\t\t\t    FPM_RAM_IRAM_ECC_EN, &fpm_rg->fm_rcr);\n}\n\nstatic void disable_rams_ecc(struct fman_fpm_regs __iomem *fpm_rg)\n{\n\tu32 tmp;\n\n\ttmp = ioread32be(&fpm_rg->fm_rcr);\n\tif (tmp & FPM_RAM_RAMS_ECC_EN_SRC_SEL)\n\t\tiowrite32be(tmp & ~FPM_RAM_IRAM_ECC_EN, &fpm_rg->fm_rcr);\n\telse\n\t\tiowrite32be(tmp & ~(FPM_RAM_RAMS_ECC_EN | FPM_RAM_IRAM_ECC_EN),\n\t\t\t    &fpm_rg->fm_rcr);\n}\n\nstatic void fman_defconfig(struct fman_cfg *cfg)\n{\n\tmemset(cfg, 0, sizeof(struct fman_cfg));\n\n\tcfg->catastrophic_err = DEFAULT_CATASTROPHIC_ERR;\n\tcfg->dma_err = DEFAULT_DMA_ERR;\n\tcfg->dma_aid_mode = DEFAULT_AID_MODE;\n\tcfg->dma_comm_qtsh_clr_emer = DEFAULT_DMA_COMM_Q_LOW;\n\tcfg->dma_comm_qtsh_asrt_emer = DEFAULT_DMA_COMM_Q_HIGH;\n\tcfg->dma_cache_override = DEFAULT_CACHE_OVERRIDE;\n\tcfg->dma_cam_num_of_entries = DEFAULT_DMA_CAM_NUM_OF_ENTRIES;\n\tcfg->dma_dbg_cnt_mode = DEFAULT_DMA_DBG_CNT_MODE;\n\tcfg->dma_sos_emergency = DEFAULT_DMA_SOS_EMERGENCY;\n\tcfg->dma_watchdog = DEFAULT_DMA_WATCHDOG;\n\tcfg->disp_limit_tsh = DEFAULT_DISP_LIMIT;\n\tcfg->prs_disp_tsh = DEFAULT_PRS_DISP_TH;\n\tcfg->plcr_disp_tsh = DEFAULT_PLCR_DISP_TH;\n\tcfg->kg_disp_tsh = DEFAULT_KG_DISP_TH;\n\tcfg->bmi_disp_tsh = DEFAULT_BMI_DISP_TH;\n\tcfg->qmi_enq_disp_tsh = DEFAULT_QMI_ENQ_DISP_TH;\n\tcfg->qmi_deq_disp_tsh = DEFAULT_QMI_DEQ_DISP_TH;\n\tcfg->fm_ctl1_disp_tsh = DEFAULT_FM_CTL1_DISP_TH;\n\tcfg->fm_ctl2_disp_tsh = DEFAULT_FM_CTL2_DISP_TH;\n}\n\nstatic int dma_init(struct fman *fman)\n{\n\tstruct fman_dma_regs __iomem *dma_rg = fman->dma_regs;\n\tstruct fman_cfg *cfg = fman->cfg;\n\tu32 tmp_reg;\n\n\t \n\n\t \n\ttmp_reg = (DMA_STATUS_BUS_ERR | DMA_STATUS_READ_ECC |\n\t\t   DMA_STATUS_SYSTEM_WRITE_ECC | DMA_STATUS_FM_WRITE_ECC);\n\tiowrite32be(ioread32be(&dma_rg->fmdmsr) | tmp_reg, &dma_rg->fmdmsr);\n\n\t \n\ttmp_reg = 0;\n\ttmp_reg |= cfg->dma_cache_override << DMA_MODE_CACHE_OR_SHIFT;\n\tif (cfg->exceptions & EX_DMA_BUS_ERROR)\n\t\ttmp_reg |= DMA_MODE_BER;\n\tif ((cfg->exceptions & EX_DMA_SYSTEM_WRITE_ECC) |\n\t    (cfg->exceptions & EX_DMA_READ_ECC) |\n\t    (cfg->exceptions & EX_DMA_FM_WRITE_ECC))\n\t\ttmp_reg |= DMA_MODE_ECC;\n\tif (cfg->dma_axi_dbg_num_of_beats)\n\t\ttmp_reg |= (DMA_MODE_AXI_DBG_MASK &\n\t\t\t((cfg->dma_axi_dbg_num_of_beats - 1)\n\t\t\t<< DMA_MODE_AXI_DBG_SHIFT));\n\n\ttmp_reg |= (((cfg->dma_cam_num_of_entries / DMA_CAM_UNITS) - 1) &\n\t\tDMA_MODE_CEN_MASK) << DMA_MODE_CEN_SHIFT;\n\ttmp_reg |= DMA_MODE_SECURE_PROT;\n\ttmp_reg |= cfg->dma_dbg_cnt_mode << DMA_MODE_DBG_SHIFT;\n\ttmp_reg |= cfg->dma_aid_mode << DMA_MODE_AID_MODE_SHIFT;\n\n\tiowrite32be(tmp_reg, &dma_rg->fmdmmr);\n\n\t \n\ttmp_reg = ((u32)cfg->dma_comm_qtsh_asrt_emer <<\n\t\tDMA_THRESH_COMMQ_SHIFT);\n\ttmp_reg |= (cfg->dma_read_buf_tsh_asrt_emer &\n\t\tDMA_THRESH_READ_INT_BUF_MASK) << DMA_THRESH_READ_INT_BUF_SHIFT;\n\ttmp_reg |= cfg->dma_write_buf_tsh_asrt_emer &\n\t\tDMA_THRESH_WRITE_INT_BUF_MASK;\n\n\tiowrite32be(tmp_reg, &dma_rg->fmdmtr);\n\n\t \n\ttmp_reg = ((u32)cfg->dma_comm_qtsh_clr_emer <<\n\t\tDMA_THRESH_COMMQ_SHIFT);\n\ttmp_reg |= (cfg->dma_read_buf_tsh_clr_emer &\n\t\tDMA_THRESH_READ_INT_BUF_MASK) << DMA_THRESH_READ_INT_BUF_SHIFT;\n\ttmp_reg |= cfg->dma_write_buf_tsh_clr_emer &\n\t\tDMA_THRESH_WRITE_INT_BUF_MASK;\n\n\tiowrite32be(tmp_reg, &dma_rg->fmdmhy);\n\n\t \n\tiowrite32be(cfg->dma_sos_emergency, &dma_rg->fmdmsetr);\n\n\t \n\tiowrite32be((cfg->dma_watchdog * cfg->clk_freq), &dma_rg->fmdmwcr);\n\n\tiowrite32be(cfg->cam_base_addr, &dma_rg->fmdmebcr);\n\n\t \n\tfman->cam_size =\n\t\t(u32)(fman->cfg->dma_cam_num_of_entries * DMA_CAM_SIZEOF_ENTRY);\n\tfman->cam_offset = fman_muram_alloc(fman->muram, fman->cam_size);\n\tif (IS_ERR_VALUE(fman->cam_offset)) {\n\t\tdev_err(fman->dev, \"%s: MURAM alloc for DMA CAM failed\\n\",\n\t\t\t__func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (fman->state->rev_info.major == 2) {\n\t\tu32 __iomem *cam_base_addr;\n\n\t\tfman_muram_free_mem(fman->muram, fman->cam_offset,\n\t\t\t\t    fman->cam_size);\n\n\t\tfman->cam_size = fman->cfg->dma_cam_num_of_entries * 72 + 128;\n\t\tfman->cam_offset = fman_muram_alloc(fman->muram,\n\t\t\t\t\t\t    fman->cam_size);\n\t\tif (IS_ERR_VALUE(fman->cam_offset)) {\n\t\t\tdev_err(fman->dev, \"%s: MURAM alloc for DMA CAM failed\\n\",\n\t\t\t\t__func__);\n\t\t\treturn -ENOMEM;\n\t\t}\n\n\t\tif (fman->cfg->dma_cam_num_of_entries % 8 ||\n\t\t    fman->cfg->dma_cam_num_of_entries > 32) {\n\t\t\tdev_err(fman->dev, \"%s: wrong dma_cam_num_of_entries\\n\",\n\t\t\t\t__func__);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tcam_base_addr = (u32 __iomem *)\n\t\t\tfman_muram_offset_to_vbase(fman->muram,\n\t\t\t\t\t\t   fman->cam_offset);\n\t\tiowrite32be(~((1 <<\n\t\t\t    (32 - fman->cfg->dma_cam_num_of_entries)) - 1),\n\t\t\t    cam_base_addr);\n\t}\n\n\tfman->cfg->cam_base_addr = fman->cam_offset;\n\n\treturn 0;\n}\n\nstatic void fpm_init(struct fman_fpm_regs __iomem *fpm_rg, struct fman_cfg *cfg)\n{\n\tu32 tmp_reg;\n\tint i;\n\n\t \n\n\ttmp_reg = (u32)(cfg->disp_limit_tsh << FPM_DISP_LIMIT_SHIFT);\n\tiowrite32be(tmp_reg, &fpm_rg->fmfp_mxd);\n\n\ttmp_reg = (((u32)cfg->prs_disp_tsh << FPM_THR1_PRS_SHIFT) |\n\t\t   ((u32)cfg->kg_disp_tsh << FPM_THR1_KG_SHIFT) |\n\t\t   ((u32)cfg->plcr_disp_tsh << FPM_THR1_PLCR_SHIFT) |\n\t\t   ((u32)cfg->bmi_disp_tsh << FPM_THR1_BMI_SHIFT));\n\tiowrite32be(tmp_reg, &fpm_rg->fmfp_dist1);\n\n\ttmp_reg =\n\t\t(((u32)cfg->qmi_enq_disp_tsh << FPM_THR2_QMI_ENQ_SHIFT) |\n\t\t ((u32)cfg->qmi_deq_disp_tsh << FPM_THR2_QMI_DEQ_SHIFT) |\n\t\t ((u32)cfg->fm_ctl1_disp_tsh << FPM_THR2_FM_CTL1_SHIFT) |\n\t\t ((u32)cfg->fm_ctl2_disp_tsh << FPM_THR2_FM_CTL2_SHIFT));\n\tiowrite32be(tmp_reg, &fpm_rg->fmfp_dist2);\n\n\t \n\ttmp_reg = 0;\n\t \n\ttmp_reg |= (FPM_EV_MASK_STALL | FPM_EV_MASK_DOUBLE_ECC |\n\t\t    FPM_EV_MASK_SINGLE_ECC);\n\t \n\tif (cfg->exceptions & EX_FPM_STALL_ON_TASKS)\n\t\ttmp_reg |= FPM_EV_MASK_STALL_EN;\n\tif (cfg->exceptions & EX_FPM_SINGLE_ECC)\n\t\ttmp_reg |= FPM_EV_MASK_SINGLE_ECC_EN;\n\tif (cfg->exceptions & EX_FPM_DOUBLE_ECC)\n\t\ttmp_reg |= FPM_EV_MASK_DOUBLE_ECC_EN;\n\ttmp_reg |= (cfg->catastrophic_err << FPM_EV_MASK_CAT_ERR_SHIFT);\n\ttmp_reg |= (cfg->dma_err << FPM_EV_MASK_DMA_ERR_SHIFT);\n\t \n\ttmp_reg |= FPM_EV_MASK_EXTERNAL_HALT;\n\t \n\ttmp_reg |= FPM_EV_MASK_ECC_ERR_HALT;\n\tiowrite32be(tmp_reg, &fpm_rg->fmfp_ee);\n\n\t \n\tfor (i = 0; i < FM_NUM_OF_FMAN_CTRL_EVENT_REGS; i++)\n\t\tiowrite32be(0xFFFFFFFF, &fpm_rg->fmfp_cev[i]);\n\n\t \n\t \n\t \n\ttmp_reg = (FPM_RAM_MURAM_ECC | FPM_RAM_IRAM_ECC);\n\n\tiowrite32be(tmp_reg, &fpm_rg->fm_rcr);\n\n\ttmp_reg = 0;\n\tif (cfg->exceptions & EX_IRAM_ECC) {\n\t\ttmp_reg |= FPM_IRAM_ECC_ERR_EX_EN;\n\t\tenable_rams_ecc(fpm_rg);\n\t}\n\tif (cfg->exceptions & EX_MURAM_ECC) {\n\t\ttmp_reg |= FPM_MURAM_ECC_ERR_EX_EN;\n\t\tenable_rams_ecc(fpm_rg);\n\t}\n\tiowrite32be(tmp_reg, &fpm_rg->fm_rie);\n}\n\nstatic void bmi_init(struct fman_bmi_regs __iomem *bmi_rg,\n\t\t     struct fman_cfg *cfg)\n{\n\tu32 tmp_reg;\n\n\t \n\n\t \n\ttmp_reg = cfg->fifo_base_addr;\n\ttmp_reg = tmp_reg / BMI_FIFO_ALIGN;\n\n\ttmp_reg |= ((cfg->total_fifo_size / FMAN_BMI_FIFO_UNITS - 1) <<\n\t\t    BMI_CFG1_FIFO_SIZE_SHIFT);\n\tiowrite32be(tmp_reg, &bmi_rg->fmbm_cfg1);\n\n\ttmp_reg = ((cfg->total_num_of_tasks - 1) & BMI_CFG2_TASKS_MASK) <<\n\t\t   BMI_CFG2_TASKS_SHIFT;\n\t \n\tiowrite32be(tmp_reg, &bmi_rg->fmbm_cfg2);\n\n\t \n\ttmp_reg = 0;\n\tiowrite32be(BMI_ERR_INTR_EN_LIST_RAM_ECC |\n\t\t    BMI_ERR_INTR_EN_STORAGE_PROFILE_ECC |\n\t\t    BMI_ERR_INTR_EN_STATISTICS_RAM_ECC |\n\t\t    BMI_ERR_INTR_EN_DISPATCH_RAM_ECC, &bmi_rg->fmbm_ievr);\n\n\tif (cfg->exceptions & EX_BMI_LIST_RAM_ECC)\n\t\ttmp_reg |= BMI_ERR_INTR_EN_LIST_RAM_ECC;\n\tif (cfg->exceptions & EX_BMI_STORAGE_PROFILE_ECC)\n\t\ttmp_reg |= BMI_ERR_INTR_EN_STORAGE_PROFILE_ECC;\n\tif (cfg->exceptions & EX_BMI_STATISTICS_RAM_ECC)\n\t\ttmp_reg |= BMI_ERR_INTR_EN_STATISTICS_RAM_ECC;\n\tif (cfg->exceptions & EX_BMI_DISPATCH_RAM_ECC)\n\t\ttmp_reg |= BMI_ERR_INTR_EN_DISPATCH_RAM_ECC;\n\tiowrite32be(tmp_reg, &bmi_rg->fmbm_ier);\n}\n\nstatic void qmi_init(struct fman_qmi_regs __iomem *qmi_rg,\n\t\t     struct fman_cfg *cfg)\n{\n\tu32 tmp_reg;\n\n\t \n\n\t \n\n\tiowrite32be(QMI_ERR_INTR_EN_DOUBLE_ECC | QMI_ERR_INTR_EN_DEQ_FROM_DEF,\n\t\t    &qmi_rg->fmqm_eie);\n\ttmp_reg = 0;\n\tif (cfg->exceptions & EX_QMI_DEQ_FROM_UNKNOWN_PORTID)\n\t\ttmp_reg |= QMI_ERR_INTR_EN_DEQ_FROM_DEF;\n\tif (cfg->exceptions & EX_QMI_DOUBLE_ECC)\n\t\ttmp_reg |= QMI_ERR_INTR_EN_DOUBLE_ECC;\n\t \n\tiowrite32be(tmp_reg, &qmi_rg->fmqm_eien);\n\n\ttmp_reg = 0;\n\t \n\tiowrite32be(QMI_INTR_EN_SINGLE_ECC, &qmi_rg->fmqm_ie);\n\tif (cfg->exceptions & EX_QMI_SINGLE_ECC)\n\t\ttmp_reg |= QMI_INTR_EN_SINGLE_ECC;\n\t \n\tiowrite32be(tmp_reg, &qmi_rg->fmqm_ien);\n}\n\nstatic void hwp_init(struct fman_hwp_regs __iomem *hwp_rg)\n{\n\t \n\tiowrite32be(HWP_RPIMAC_PEN, &hwp_rg->fmprrpimac);\n}\n\nstatic int enable(struct fman *fman, struct fman_cfg *cfg)\n{\n\tu32 cfg_reg = 0;\n\n\t \n\n\t \n\tcfg_reg = QMI_CFG_EN_COUNTERS;\n\n\t \n\tcfg_reg |= (cfg->qmi_def_tnums_thresh << 8) | cfg->qmi_def_tnums_thresh;\n\n\tiowrite32be(BMI_INIT_START, &fman->bmi_regs->fmbm_init);\n\tiowrite32be(cfg_reg | QMI_CFG_ENQ_EN | QMI_CFG_DEQ_EN,\n\t\t    &fman->qmi_regs->fmqm_gc);\n\n\treturn 0;\n}\n\nstatic int set_exception(struct fman *fman,\n\t\t\t enum fman_exceptions exception, bool enable)\n{\n\tu32 tmp;\n\n\tswitch (exception) {\n\tcase FMAN_EX_DMA_BUS_ERROR:\n\t\ttmp = ioread32be(&fman->dma_regs->fmdmmr);\n\t\tif (enable)\n\t\t\ttmp |= DMA_MODE_BER;\n\t\telse\n\t\t\ttmp &= ~DMA_MODE_BER;\n\t\t \n\t\tiowrite32be(tmp, &fman->dma_regs->fmdmmr);\n\t\tbreak;\n\tcase FMAN_EX_DMA_READ_ECC:\n\tcase FMAN_EX_DMA_SYSTEM_WRITE_ECC:\n\tcase FMAN_EX_DMA_FM_WRITE_ECC:\n\t\ttmp = ioread32be(&fman->dma_regs->fmdmmr);\n\t\tif (enable)\n\t\t\ttmp |= DMA_MODE_ECC;\n\t\telse\n\t\t\ttmp &= ~DMA_MODE_ECC;\n\t\tiowrite32be(tmp, &fman->dma_regs->fmdmmr);\n\t\tbreak;\n\tcase FMAN_EX_FPM_STALL_ON_TASKS:\n\t\ttmp = ioread32be(&fman->fpm_regs->fmfp_ee);\n\t\tif (enable)\n\t\t\ttmp |= FPM_EV_MASK_STALL_EN;\n\t\telse\n\t\t\ttmp &= ~FPM_EV_MASK_STALL_EN;\n\t\tiowrite32be(tmp, &fman->fpm_regs->fmfp_ee);\n\t\tbreak;\n\tcase FMAN_EX_FPM_SINGLE_ECC:\n\t\ttmp = ioread32be(&fman->fpm_regs->fmfp_ee);\n\t\tif (enable)\n\t\t\ttmp |= FPM_EV_MASK_SINGLE_ECC_EN;\n\t\telse\n\t\t\ttmp &= ~FPM_EV_MASK_SINGLE_ECC_EN;\n\t\tiowrite32be(tmp, &fman->fpm_regs->fmfp_ee);\n\t\tbreak;\n\tcase FMAN_EX_FPM_DOUBLE_ECC:\n\t\ttmp = ioread32be(&fman->fpm_regs->fmfp_ee);\n\t\tif (enable)\n\t\t\ttmp |= FPM_EV_MASK_DOUBLE_ECC_EN;\n\t\telse\n\t\t\ttmp &= ~FPM_EV_MASK_DOUBLE_ECC_EN;\n\t\tiowrite32be(tmp, &fman->fpm_regs->fmfp_ee);\n\t\tbreak;\n\tcase FMAN_EX_QMI_SINGLE_ECC:\n\t\ttmp = ioread32be(&fman->qmi_regs->fmqm_ien);\n\t\tif (enable)\n\t\t\ttmp |= QMI_INTR_EN_SINGLE_ECC;\n\t\telse\n\t\t\ttmp &= ~QMI_INTR_EN_SINGLE_ECC;\n\t\tiowrite32be(tmp, &fman->qmi_regs->fmqm_ien);\n\t\tbreak;\n\tcase FMAN_EX_QMI_DOUBLE_ECC:\n\t\ttmp = ioread32be(&fman->qmi_regs->fmqm_eien);\n\t\tif (enable)\n\t\t\ttmp |= QMI_ERR_INTR_EN_DOUBLE_ECC;\n\t\telse\n\t\t\ttmp &= ~QMI_ERR_INTR_EN_DOUBLE_ECC;\n\t\tiowrite32be(tmp, &fman->qmi_regs->fmqm_eien);\n\t\tbreak;\n\tcase FMAN_EX_QMI_DEQ_FROM_UNKNOWN_PORTID:\n\t\ttmp = ioread32be(&fman->qmi_regs->fmqm_eien);\n\t\tif (enable)\n\t\t\ttmp |= QMI_ERR_INTR_EN_DEQ_FROM_DEF;\n\t\telse\n\t\t\ttmp &= ~QMI_ERR_INTR_EN_DEQ_FROM_DEF;\n\t\tiowrite32be(tmp, &fman->qmi_regs->fmqm_eien);\n\t\tbreak;\n\tcase FMAN_EX_BMI_LIST_RAM_ECC:\n\t\ttmp = ioread32be(&fman->bmi_regs->fmbm_ier);\n\t\tif (enable)\n\t\t\ttmp |= BMI_ERR_INTR_EN_LIST_RAM_ECC;\n\t\telse\n\t\t\ttmp &= ~BMI_ERR_INTR_EN_LIST_RAM_ECC;\n\t\tiowrite32be(tmp, &fman->bmi_regs->fmbm_ier);\n\t\tbreak;\n\tcase FMAN_EX_BMI_STORAGE_PROFILE_ECC:\n\t\ttmp = ioread32be(&fman->bmi_regs->fmbm_ier);\n\t\tif (enable)\n\t\t\ttmp |= BMI_ERR_INTR_EN_STORAGE_PROFILE_ECC;\n\t\telse\n\t\t\ttmp &= ~BMI_ERR_INTR_EN_STORAGE_PROFILE_ECC;\n\t\tiowrite32be(tmp, &fman->bmi_regs->fmbm_ier);\n\t\tbreak;\n\tcase FMAN_EX_BMI_STATISTICS_RAM_ECC:\n\t\ttmp = ioread32be(&fman->bmi_regs->fmbm_ier);\n\t\tif (enable)\n\t\t\ttmp |= BMI_ERR_INTR_EN_STATISTICS_RAM_ECC;\n\t\telse\n\t\t\ttmp &= ~BMI_ERR_INTR_EN_STATISTICS_RAM_ECC;\n\t\tiowrite32be(tmp, &fman->bmi_regs->fmbm_ier);\n\t\tbreak;\n\tcase FMAN_EX_BMI_DISPATCH_RAM_ECC:\n\t\ttmp = ioread32be(&fman->bmi_regs->fmbm_ier);\n\t\tif (enable)\n\t\t\ttmp |= BMI_ERR_INTR_EN_DISPATCH_RAM_ECC;\n\t\telse\n\t\t\ttmp &= ~BMI_ERR_INTR_EN_DISPATCH_RAM_ECC;\n\t\tiowrite32be(tmp, &fman->bmi_regs->fmbm_ier);\n\t\tbreak;\n\tcase FMAN_EX_IRAM_ECC:\n\t\ttmp = ioread32be(&fman->fpm_regs->fm_rie);\n\t\tif (enable) {\n\t\t\t \n\t\t\tenable_rams_ecc(fman->fpm_regs);\n\t\t\t \n\t\t\ttmp |= FPM_IRAM_ECC_ERR_EX_EN;\n\t\t} else {\n\t\t\t \n\t\t\tdisable_rams_ecc(fman->fpm_regs);\n\t\t\ttmp &= ~FPM_IRAM_ECC_ERR_EX_EN;\n\t\t}\n\t\tiowrite32be(tmp, &fman->fpm_regs->fm_rie);\n\t\tbreak;\n\tcase FMAN_EX_MURAM_ECC:\n\t\ttmp = ioread32be(&fman->fpm_regs->fm_rie);\n\t\tif (enable) {\n\t\t\t \n\t\t\tenable_rams_ecc(fman->fpm_regs);\n\t\t\t \n\t\t\ttmp |= FPM_MURAM_ECC_ERR_EX_EN;\n\t\t} else {\n\t\t\t \n\t\t\tdisable_rams_ecc(fman->fpm_regs);\n\t\t\ttmp &= ~FPM_MURAM_ECC_ERR_EX_EN;\n\t\t}\n\t\tiowrite32be(tmp, &fman->fpm_regs->fm_rie);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n\nstatic void resume(struct fman_fpm_regs __iomem *fpm_rg)\n{\n\tu32 tmp;\n\n\ttmp = ioread32be(&fpm_rg->fmfp_ee);\n\t \n\ttmp &= ~(FPM_EV_MASK_DOUBLE_ECC |\n\t\t FPM_EV_MASK_STALL | FPM_EV_MASK_SINGLE_ECC);\n\ttmp |= FPM_EV_MASK_RELEASE_FM;\n\n\tiowrite32be(tmp, &fpm_rg->fmfp_ee);\n}\n\nstatic int fill_soc_specific_params(struct fman_state_struct *state)\n{\n\tu8 minor = state->rev_info.minor;\n\t \n\tswitch (state->rev_info.major) {\n\tcase 3:\n\t\tstate->bmi_max_fifo_size\t= 160 * 1024;\n\t\tstate->fm_iram_size\t\t= 64 * 1024;\n\t\tstate->dma_thresh_max_commq\t= 31;\n\t\tstate->dma_thresh_max_buf\t= 127;\n\t\tstate->qmi_max_num_of_tnums\t= 64;\n\t\tstate->qmi_def_tnums_thresh\t= 48;\n\t\tstate->bmi_max_num_of_tasks\t= 128;\n\t\tstate->max_num_of_open_dmas\t= 32;\n\t\tstate->fm_port_num_of_cg\t= 256;\n\t\tstate->num_of_rx_ports\t= 6;\n\t\tstate->total_fifo_size\t= 136 * 1024;\n\t\tbreak;\n\n\tcase 2:\n\t\tstate->bmi_max_fifo_size\t= 160 * 1024;\n\t\tstate->fm_iram_size\t\t= 64 * 1024;\n\t\tstate->dma_thresh_max_commq\t= 31;\n\t\tstate->dma_thresh_max_buf\t= 127;\n\t\tstate->qmi_max_num_of_tnums\t= 64;\n\t\tstate->qmi_def_tnums_thresh\t= 48;\n\t\tstate->bmi_max_num_of_tasks\t= 128;\n\t\tstate->max_num_of_open_dmas\t= 32;\n\t\tstate->fm_port_num_of_cg\t= 256;\n\t\tstate->num_of_rx_ports\t= 5;\n\t\tstate->total_fifo_size\t= 100 * 1024;\n\t\tbreak;\n\n\tcase 6:\n\t\tstate->dma_thresh_max_commq\t= 83;\n\t\tstate->dma_thresh_max_buf\t= 127;\n\t\tstate->qmi_max_num_of_tnums\t= 64;\n\t\tstate->qmi_def_tnums_thresh\t= 32;\n\t\tstate->fm_port_num_of_cg\t= 256;\n\n\t\t \n\t\tif (minor == 1 || minor == 4) {\n\t\t\tstate->bmi_max_fifo_size\t= 192 * 1024;\n\t\t\tstate->bmi_max_num_of_tasks\t= 64;\n\t\t\tstate->max_num_of_open_dmas\t= 32;\n\t\t\tstate->num_of_rx_ports\t\t= 5;\n\t\t\tif (minor == 1)\n\t\t\t\tstate->fm_iram_size\t= 32 * 1024;\n\t\t\telse\n\t\t\t\tstate->fm_iram_size\t= 64 * 1024;\n\t\t\tstate->total_fifo_size\t\t= 156 * 1024;\n\t\t}\n\t\t \n\t\telse if (minor == 0 || minor == 2 || minor == 3) {\n\t\t\tstate->bmi_max_fifo_size\t= 384 * 1024;\n\t\t\tstate->fm_iram_size\t\t= 64 * 1024;\n\t\t\tstate->bmi_max_num_of_tasks\t= 128;\n\t\t\tstate->max_num_of_open_dmas\t= 84;\n\t\t\tstate->num_of_rx_ports\t\t= 8;\n\t\t\tstate->total_fifo_size\t\t= 295 * 1024;\n\t\t} else {\n\t\t\tpr_err(\"Unsupported FManv3 version\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"Unsupported FMan version\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\nstatic bool is_init_done(struct fman_cfg *cfg)\n{\n\t \n\tif (!cfg)\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void free_init_resources(struct fman *fman)\n{\n\tif (fman->cam_offset)\n\t\tfman_muram_free_mem(fman->muram, fman->cam_offset,\n\t\t\t\t    fman->cam_size);\n\tif (fman->fifo_offset)\n\t\tfman_muram_free_mem(fman->muram, fman->fifo_offset,\n\t\t\t\t    fman->fifo_size);\n}\n\nstatic irqreturn_t bmi_err_event(struct fman *fman)\n{\n\tu32 event, mask, force;\n\tstruct fman_bmi_regs __iomem *bmi_rg = fman->bmi_regs;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tevent = ioread32be(&bmi_rg->fmbm_ievr);\n\tmask = ioread32be(&bmi_rg->fmbm_ier);\n\tevent &= mask;\n\t \n\tforce = ioread32be(&bmi_rg->fmbm_ifr);\n\tif (force & event)\n\t\tiowrite32be(force & ~event, &bmi_rg->fmbm_ifr);\n\t \n\tiowrite32be(event, &bmi_rg->fmbm_ievr);\n\n\tif (event & BMI_ERR_INTR_EN_STORAGE_PROFILE_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_BMI_STORAGE_PROFILE_ECC);\n\tif (event & BMI_ERR_INTR_EN_LIST_RAM_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_BMI_LIST_RAM_ECC);\n\tif (event & BMI_ERR_INTR_EN_STATISTICS_RAM_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_BMI_STATISTICS_RAM_ECC);\n\tif (event & BMI_ERR_INTR_EN_DISPATCH_RAM_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_BMI_DISPATCH_RAM_ECC);\n\n\treturn ret;\n}\n\nstatic irqreturn_t qmi_err_event(struct fman *fman)\n{\n\tu32 event, mask, force;\n\tstruct fman_qmi_regs __iomem *qmi_rg = fman->qmi_regs;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tevent = ioread32be(&qmi_rg->fmqm_eie);\n\tmask = ioread32be(&qmi_rg->fmqm_eien);\n\tevent &= mask;\n\n\t \n\tforce = ioread32be(&qmi_rg->fmqm_eif);\n\tif (force & event)\n\t\tiowrite32be(force & ~event, &qmi_rg->fmqm_eif);\n\t \n\tiowrite32be(event, &qmi_rg->fmqm_eie);\n\n\tif (event & QMI_ERR_INTR_EN_DOUBLE_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_QMI_DOUBLE_ECC);\n\tif (event & QMI_ERR_INTR_EN_DEQ_FROM_DEF)\n\t\tret = fman->exception_cb(fman,\n\t\t\t\t\t FMAN_EX_QMI_DEQ_FROM_UNKNOWN_PORTID);\n\n\treturn ret;\n}\n\nstatic irqreturn_t dma_err_event(struct fman *fman)\n{\n\tu32 status, mask, com_id;\n\tu8 tnum, port_id, relative_port_id;\n\tu16 liodn;\n\tstruct fman_dma_regs __iomem *dma_rg = fman->dma_regs;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tstatus = ioread32be(&dma_rg->fmdmsr);\n\tmask = ioread32be(&dma_rg->fmdmmr);\n\n\t \n\tif ((mask & DMA_MODE_BER) != DMA_MODE_BER)\n\t\tstatus &= ~DMA_STATUS_BUS_ERR;\n\n\t \n\tif ((mask & DMA_MODE_ECC) != DMA_MODE_ECC)\n\t\tstatus &= ~(DMA_STATUS_FM_SPDAT_ECC |\n\t\t\t    DMA_STATUS_READ_ECC |\n\t\t\t    DMA_STATUS_SYSTEM_WRITE_ECC |\n\t\t\t    DMA_STATUS_FM_WRITE_ECC);\n\n\t \n\tiowrite32be(status, &dma_rg->fmdmsr);\n\n\tif (status & DMA_STATUS_BUS_ERR) {\n\t\tu64 addr;\n\n\t\taddr = (u64)ioread32be(&dma_rg->fmdmtal);\n\t\taddr |= ((u64)(ioread32be(&dma_rg->fmdmtah)) << 32);\n\n\t\tcom_id = ioread32be(&dma_rg->fmdmtcid);\n\t\tport_id = (u8)(((com_id & DMA_TRANSFER_PORTID_MASK) >>\n\t\t\t       DMA_TRANSFER_PORTID_SHIFT));\n\t\trelative_port_id =\n\t\thw_port_id_to_sw_port_id(fman->state->rev_info.major, port_id);\n\t\ttnum = (u8)((com_id & DMA_TRANSFER_TNUM_MASK) >>\n\t\t\t    DMA_TRANSFER_TNUM_SHIFT);\n\t\tliodn = (u16)(com_id & DMA_TRANSFER_LIODN_MASK);\n\t\tret = fman->bus_error_cb(fman, relative_port_id, addr, tnum,\n\t\t\t\t\t liodn);\n\t}\n\tif (status & DMA_STATUS_FM_SPDAT_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_DMA_SINGLE_PORT_ECC);\n\tif (status & DMA_STATUS_READ_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_DMA_READ_ECC);\n\tif (status & DMA_STATUS_SYSTEM_WRITE_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_DMA_SYSTEM_WRITE_ECC);\n\tif (status & DMA_STATUS_FM_WRITE_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_DMA_FM_WRITE_ECC);\n\n\treturn ret;\n}\n\nstatic irqreturn_t fpm_err_event(struct fman *fman)\n{\n\tu32 event;\n\tstruct fman_fpm_regs __iomem *fpm_rg = fman->fpm_regs;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tevent = ioread32be(&fpm_rg->fmfp_ee);\n\t \n\tiowrite32be(event, &fpm_rg->fmfp_ee);\n\n\tif ((event & FPM_EV_MASK_DOUBLE_ECC) &&\n\t    (event & FPM_EV_MASK_DOUBLE_ECC_EN))\n\t\tret = fman->exception_cb(fman, FMAN_EX_FPM_DOUBLE_ECC);\n\tif ((event & FPM_EV_MASK_STALL) && (event & FPM_EV_MASK_STALL_EN))\n\t\tret = fman->exception_cb(fman, FMAN_EX_FPM_STALL_ON_TASKS);\n\tif ((event & FPM_EV_MASK_SINGLE_ECC) &&\n\t    (event & FPM_EV_MASK_SINGLE_ECC_EN))\n\t\tret = fman->exception_cb(fman, FMAN_EX_FPM_SINGLE_ECC);\n\n\treturn ret;\n}\n\nstatic irqreturn_t muram_err_intr(struct fman *fman)\n{\n\tu32 event, mask;\n\tstruct fman_fpm_regs __iomem *fpm_rg = fman->fpm_regs;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tevent = ioread32be(&fpm_rg->fm_rcr);\n\tmask = ioread32be(&fpm_rg->fm_rie);\n\n\t \n\tiowrite32be(event & ~FPM_RAM_IRAM_ECC, &fpm_rg->fm_rcr);\n\n\tif ((mask & FPM_MURAM_ECC_ERR_EX_EN) && (event & FPM_RAM_MURAM_ECC))\n\t\tret = fman->exception_cb(fman, FMAN_EX_MURAM_ECC);\n\n\treturn ret;\n}\n\nstatic irqreturn_t qmi_event(struct fman *fman)\n{\n\tu32 event, mask, force;\n\tstruct fman_qmi_regs __iomem *qmi_rg = fman->qmi_regs;\n\tirqreturn_t ret = IRQ_NONE;\n\n\tevent = ioread32be(&qmi_rg->fmqm_ie);\n\tmask = ioread32be(&qmi_rg->fmqm_ien);\n\tevent &= mask;\n\t \n\tforce = ioread32be(&qmi_rg->fmqm_if);\n\tif (force & event)\n\t\tiowrite32be(force & ~event, &qmi_rg->fmqm_if);\n\t \n\tiowrite32be(event, &qmi_rg->fmqm_ie);\n\n\tif (event & QMI_INTR_EN_SINGLE_ECC)\n\t\tret = fman->exception_cb(fman, FMAN_EX_QMI_SINGLE_ECC);\n\n\treturn ret;\n}\n\nstatic void enable_time_stamp(struct fman *fman)\n{\n\tstruct fman_fpm_regs __iomem *fpm_rg = fman->fpm_regs;\n\tu16 fm_clk_freq = fman->state->fm_clk_freq;\n\tu32 tmp, intgr, ts_freq, frac;\n\n\tts_freq = (u32)(1 << fman->state->count1_micro_bit);\n\t \n\n\tintgr = ts_freq / fm_clk_freq;\n\t \n\n\tfrac = ((ts_freq << 16) - (intgr << 16) * fm_clk_freq) / fm_clk_freq;\n\t \n\tif (((ts_freq << 16) - (intgr << 16) * fm_clk_freq) % fm_clk_freq)\n\t\tfrac++;\n\n\ttmp = (intgr << FPM_TS_INT_SHIFT) | (u16)frac;\n\tiowrite32be(tmp, &fpm_rg->fmfp_tsc2);\n\n\t \n\tiowrite32be(FPM_TS_CTL_EN, &fpm_rg->fmfp_tsc1);\n\tfman->state->enabled_time_stamp = true;\n}\n\nstatic int clear_iram(struct fman *fman)\n{\n\tstruct fman_iram_regs __iomem *iram;\n\tint i, count;\n\n\tiram = fman->base_addr + IMEM_OFFSET;\n\n\t \n\tiowrite32be(IRAM_IADD_AIE, &iram->iadd);\n\tcount = 100;\n\tdo {\n\t\tudelay(1);\n\t} while ((ioread32be(&iram->iadd) != IRAM_IADD_AIE) && --count);\n\tif (count == 0)\n\t\treturn -EBUSY;\n\n\tfor (i = 0; i < (fman->state->fm_iram_size / 4); i++)\n\t\tiowrite32be(0xffffffff, &iram->idata);\n\n\tiowrite32be(fman->state->fm_iram_size - 4, &iram->iadd);\n\tcount = 100;\n\tdo {\n\t\tudelay(1);\n\t} while ((ioread32be(&iram->idata) != 0xffffffff) && --count);\n\tif (count == 0)\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\nstatic u32 get_exception_flag(enum fman_exceptions exception)\n{\n\tu32 bit_mask;\n\n\tswitch (exception) {\n\tcase FMAN_EX_DMA_BUS_ERROR:\n\t\tbit_mask = EX_DMA_BUS_ERROR;\n\t\tbreak;\n\tcase FMAN_EX_DMA_SINGLE_PORT_ECC:\n\t\tbit_mask = EX_DMA_SINGLE_PORT_ECC;\n\t\tbreak;\n\tcase FMAN_EX_DMA_READ_ECC:\n\t\tbit_mask = EX_DMA_READ_ECC;\n\t\tbreak;\n\tcase FMAN_EX_DMA_SYSTEM_WRITE_ECC:\n\t\tbit_mask = EX_DMA_SYSTEM_WRITE_ECC;\n\t\tbreak;\n\tcase FMAN_EX_DMA_FM_WRITE_ECC:\n\t\tbit_mask = EX_DMA_FM_WRITE_ECC;\n\t\tbreak;\n\tcase FMAN_EX_FPM_STALL_ON_TASKS:\n\t\tbit_mask = EX_FPM_STALL_ON_TASKS;\n\t\tbreak;\n\tcase FMAN_EX_FPM_SINGLE_ECC:\n\t\tbit_mask = EX_FPM_SINGLE_ECC;\n\t\tbreak;\n\tcase FMAN_EX_FPM_DOUBLE_ECC:\n\t\tbit_mask = EX_FPM_DOUBLE_ECC;\n\t\tbreak;\n\tcase FMAN_EX_QMI_SINGLE_ECC:\n\t\tbit_mask = EX_QMI_SINGLE_ECC;\n\t\tbreak;\n\tcase FMAN_EX_QMI_DOUBLE_ECC:\n\t\tbit_mask = EX_QMI_DOUBLE_ECC;\n\t\tbreak;\n\tcase FMAN_EX_QMI_DEQ_FROM_UNKNOWN_PORTID:\n\t\tbit_mask = EX_QMI_DEQ_FROM_UNKNOWN_PORTID;\n\t\tbreak;\n\tcase FMAN_EX_BMI_LIST_RAM_ECC:\n\t\tbit_mask = EX_BMI_LIST_RAM_ECC;\n\t\tbreak;\n\tcase FMAN_EX_BMI_STORAGE_PROFILE_ECC:\n\t\tbit_mask = EX_BMI_STORAGE_PROFILE_ECC;\n\t\tbreak;\n\tcase FMAN_EX_BMI_STATISTICS_RAM_ECC:\n\t\tbit_mask = EX_BMI_STATISTICS_RAM_ECC;\n\t\tbreak;\n\tcase FMAN_EX_BMI_DISPATCH_RAM_ECC:\n\t\tbit_mask = EX_BMI_DISPATCH_RAM_ECC;\n\t\tbreak;\n\tcase FMAN_EX_MURAM_ECC:\n\t\tbit_mask = EX_MURAM_ECC;\n\t\tbreak;\n\tdefault:\n\t\tbit_mask = 0;\n\t\tbreak;\n\t}\n\n\treturn bit_mask;\n}\n\nstatic int get_module_event(enum fman_event_modules module, u8 mod_id,\n\t\t\t    enum fman_intr_type intr_type)\n{\n\tint event;\n\n\tswitch (module) {\n\tcase FMAN_MOD_MAC:\n\t\tif (intr_type == FMAN_INTR_TYPE_ERR)\n\t\t\tevent = FMAN_EV_ERR_MAC0 + mod_id;\n\t\telse\n\t\t\tevent = FMAN_EV_MAC0 + mod_id;\n\t\tbreak;\n\tcase FMAN_MOD_FMAN_CTRL:\n\t\tif (intr_type == FMAN_INTR_TYPE_ERR)\n\t\t\tevent = FMAN_EV_CNT;\n\t\telse\n\t\t\tevent = (FMAN_EV_FMAN_CTRL_0 + mod_id);\n\t\tbreak;\n\tcase FMAN_MOD_DUMMY_LAST:\n\t\tevent = FMAN_EV_CNT;\n\t\tbreak;\n\tdefault:\n\t\tevent = FMAN_EV_CNT;\n\t\tbreak;\n\t}\n\n\treturn event;\n}\n\nstatic int set_size_of_fifo(struct fman *fman, u8 port_id, u32 *size_of_fifo,\n\t\t\t    u32 *extra_size_of_fifo)\n{\n\tstruct fman_bmi_regs __iomem *bmi_rg = fman->bmi_regs;\n\tu32 fifo = *size_of_fifo;\n\tu32 extra_fifo = *extra_size_of_fifo;\n\tu32 tmp;\n\n\t \n\tif (extra_fifo && !fman->state->extra_fifo_pool_size)\n\t\tfman->state->extra_fifo_pool_size =\n\t\t\tfman->state->num_of_rx_ports * FMAN_BMI_FIFO_UNITS;\n\n\tfman->state->extra_fifo_pool_size =\n\t\tmax(fman->state->extra_fifo_pool_size, extra_fifo);\n\n\t \n\tif ((fman->state->accumulated_fifo_size + fifo) >\n\t    (fman->state->total_fifo_size -\n\t    fman->state->extra_fifo_pool_size)) {\n\t\tdev_err(fman->dev, \"%s: Requested fifo size and extra size exceed total FIFO size.\\n\",\n\t\t\t__func__);\n\t\treturn -EAGAIN;\n\t}\n\n\t \n\ttmp = (fifo / FMAN_BMI_FIFO_UNITS - 1) |\n\t       ((extra_fifo / FMAN_BMI_FIFO_UNITS) <<\n\t       BMI_EXTRA_FIFO_SIZE_SHIFT);\n\tiowrite32be(tmp, &bmi_rg->fmbm_pfs[port_id - 1]);\n\n\t \n\tfman->state->accumulated_fifo_size += fifo;\n\n\treturn 0;\n}\n\nstatic int set_num_of_tasks(struct fman *fman, u8 port_id, u8 *num_of_tasks,\n\t\t\t    u8 *num_of_extra_tasks)\n{\n\tstruct fman_bmi_regs __iomem *bmi_rg = fman->bmi_regs;\n\tu8 tasks = *num_of_tasks;\n\tu8 extra_tasks = *num_of_extra_tasks;\n\tu32 tmp;\n\n\tif (extra_tasks)\n\t\tfman->state->extra_tasks_pool_size =\n\t\tmax(fman->state->extra_tasks_pool_size, extra_tasks);\n\n\t \n\tif ((fman->state->accumulated_num_of_tasks + tasks) >\n\t    (fman->state->total_num_of_tasks -\n\t     fman->state->extra_tasks_pool_size)) {\n\t\tdev_err(fman->dev, \"%s: Requested num_of_tasks and extra tasks pool for fm%d exceed total num_of_tasks.\\n\",\n\t\t\t__func__, fman->state->fm_id);\n\t\treturn -EAGAIN;\n\t}\n\t \n\tfman->state->accumulated_num_of_tasks += tasks;\n\n\t \n\ttmp = ioread32be(&bmi_rg->fmbm_pp[port_id - 1]) &\n\t    ~(BMI_NUM_OF_TASKS_MASK | BMI_NUM_OF_EXTRA_TASKS_MASK);\n\ttmp |= ((u32)((tasks - 1) << BMI_NUM_OF_TASKS_SHIFT) |\n\t\t(u32)(extra_tasks << BMI_EXTRA_NUM_OF_TASKS_SHIFT));\n\tiowrite32be(tmp, &bmi_rg->fmbm_pp[port_id - 1]);\n\n\treturn 0;\n}\n\nstatic int set_num_of_open_dmas(struct fman *fman, u8 port_id,\n\t\t\t\tu8 *num_of_open_dmas,\n\t\t\t\tu8 *num_of_extra_open_dmas)\n{\n\tstruct fman_bmi_regs __iomem *bmi_rg = fman->bmi_regs;\n\tu8 open_dmas = *num_of_open_dmas;\n\tu8 extra_open_dmas = *num_of_extra_open_dmas;\n\tu8 total_num_dmas = 0, current_val = 0, current_extra_val = 0;\n\tu32 tmp;\n\n\tif (!open_dmas) {\n\t\t \n\t\ttmp = ioread32be(&bmi_rg->fmbm_pp[port_id - 1]);\n\t\tcurrent_extra_val = (u8)((tmp & BMI_NUM_OF_EXTRA_DMAS_MASK) >>\n\t\t\t\t\t BMI_EXTRA_NUM_OF_DMAS_SHIFT);\n\n\t\ttmp = ioread32be(&bmi_rg->fmbm_pp[port_id - 1]);\n\t\tcurrent_val = (u8)(((tmp & BMI_NUM_OF_DMAS_MASK) >>\n\t\t\t\t   BMI_NUM_OF_DMAS_SHIFT) + 1);\n\n\t\t \n\t\tfman->state->extra_open_dmas_pool_size =\n\t\t\t(u8)max(fman->state->extra_open_dmas_pool_size,\n\t\t\t\tcurrent_extra_val);\n\t\tfman->state->accumulated_num_of_open_dmas += current_val;\n\t\t*num_of_open_dmas = current_val;\n\t\t*num_of_extra_open_dmas = current_extra_val;\n\t\treturn 0;\n\t}\n\n\tif (extra_open_dmas > current_extra_val)\n\t\tfman->state->extra_open_dmas_pool_size =\n\t\t    (u8)max(fman->state->extra_open_dmas_pool_size,\n\t\t\t    extra_open_dmas);\n\n\tif ((fman->state->rev_info.major < 6) &&\n\t    (fman->state->accumulated_num_of_open_dmas - current_val +\n\t     open_dmas > fman->state->max_num_of_open_dmas)) {\n\t\tdev_err(fman->dev, \"%s: Requested num_of_open_dmas for fm%d exceeds total num_of_open_dmas.\\n\",\n\t\t\t__func__, fman->state->fm_id);\n\t\treturn -EAGAIN;\n\t} else if ((fman->state->rev_info.major >= 6) &&\n\t\t   !((fman->state->rev_info.major == 6) &&\n\t\t   (fman->state->rev_info.minor == 0)) &&\n\t\t   (fman->state->accumulated_num_of_open_dmas -\n\t\t   current_val + open_dmas >\n\t\t   fman->state->dma_thresh_max_commq + 1)) {\n\t\tdev_err(fman->dev, \"%s: Requested num_of_open_dmas for fm%d exceeds DMA Command queue (%d)\\n\",\n\t\t\t__func__, fman->state->fm_id,\n\t\t       fman->state->dma_thresh_max_commq + 1);\n\t\treturn -EAGAIN;\n\t}\n\n\tWARN_ON(fman->state->accumulated_num_of_open_dmas < current_val);\n\t \n\tfman->state->accumulated_num_of_open_dmas -= current_val;\n\tfman->state->accumulated_num_of_open_dmas += open_dmas;\n\n\tif (fman->state->rev_info.major < 6)\n\t\ttotal_num_dmas =\n\t\t    (u8)(fman->state->accumulated_num_of_open_dmas +\n\t\t    fman->state->extra_open_dmas_pool_size);\n\n\t \n\ttmp = ioread32be(&bmi_rg->fmbm_pp[port_id - 1]) &\n\t    ~(BMI_NUM_OF_DMAS_MASK | BMI_NUM_OF_EXTRA_DMAS_MASK);\n\ttmp |= (u32)(((open_dmas - 1) << BMI_NUM_OF_DMAS_SHIFT) |\n\t\t\t   (extra_open_dmas << BMI_EXTRA_NUM_OF_DMAS_SHIFT));\n\tiowrite32be(tmp, &bmi_rg->fmbm_pp[port_id - 1]);\n\n\t \n\tif (total_num_dmas) {\n\t\ttmp = ioread32be(&bmi_rg->fmbm_cfg2) & ~BMI_CFG2_DMAS_MASK;\n\t\ttmp |= (u32)(total_num_dmas - 1) << BMI_CFG2_DMAS_SHIFT;\n\t\tiowrite32be(tmp, &bmi_rg->fmbm_cfg2);\n\t}\n\n\treturn 0;\n}\n\nstatic int fman_config(struct fman *fman)\n{\n\tvoid __iomem *base_addr;\n\tint err;\n\n\tbase_addr = fman->dts_params.base_addr;\n\n\tfman->state = kzalloc(sizeof(*fman->state), GFP_KERNEL);\n\tif (!fman->state)\n\t\tgoto err_fm_state;\n\n\t \n\tfman->cfg = kzalloc(sizeof(*fman->cfg), GFP_KERNEL);\n\tif (!fman->cfg)\n\t\tgoto err_fm_drv;\n\n\t \n\tfman->muram =\n\t\tfman_muram_init(fman->dts_params.muram_res.start,\n\t\t\t\tresource_size(&fman->dts_params.muram_res));\n\tif (!fman->muram)\n\t\tgoto err_fm_soc_specific;\n\n\t \n\tfman->state->fm_id = fman->dts_params.id;\n\tfman->state->fm_clk_freq = fman->dts_params.clk_freq;\n\tfman->state->qman_channel_base = fman->dts_params.qman_channel_base;\n\tfman->state->num_of_qman_channels =\n\t\tfman->dts_params.num_of_qman_channels;\n\tfman->state->res = fman->dts_params.res;\n\tfman->exception_cb = fman_exceptions;\n\tfman->bus_error_cb = fman_bus_error;\n\tfman->fpm_regs = base_addr + FPM_OFFSET;\n\tfman->bmi_regs = base_addr + BMI_OFFSET;\n\tfman->qmi_regs = base_addr + QMI_OFFSET;\n\tfman->dma_regs = base_addr + DMA_OFFSET;\n\tfman->hwp_regs = base_addr + HWP_OFFSET;\n\tfman->kg_regs = base_addr + KG_OFFSET;\n\tfman->base_addr = base_addr;\n\n\tspin_lock_init(&fman->spinlock);\n\tfman_defconfig(fman->cfg);\n\n\tfman->state->extra_fifo_pool_size = 0;\n\tfman->state->exceptions = (EX_DMA_BUS_ERROR                 |\n\t\t\t\t\tEX_DMA_READ_ECC              |\n\t\t\t\t\tEX_DMA_SYSTEM_WRITE_ECC      |\n\t\t\t\t\tEX_DMA_FM_WRITE_ECC          |\n\t\t\t\t\tEX_FPM_STALL_ON_TASKS        |\n\t\t\t\t\tEX_FPM_SINGLE_ECC            |\n\t\t\t\t\tEX_FPM_DOUBLE_ECC            |\n\t\t\t\t\tEX_QMI_DEQ_FROM_UNKNOWN_PORTID |\n\t\t\t\t\tEX_BMI_LIST_RAM_ECC          |\n\t\t\t\t\tEX_BMI_STORAGE_PROFILE_ECC   |\n\t\t\t\t\tEX_BMI_STATISTICS_RAM_ECC    |\n\t\t\t\t\tEX_MURAM_ECC                 |\n\t\t\t\t\tEX_BMI_DISPATCH_RAM_ECC      |\n\t\t\t\t\tEX_QMI_DOUBLE_ECC            |\n\t\t\t\t\tEX_QMI_SINGLE_ECC);\n\n\t \n\tfman_get_revision(fman, &fman->state->rev_info);\n\n\terr = fill_soc_specific_params(fman->state);\n\tif (err)\n\t\tgoto err_fm_soc_specific;\n\n\t \n\tif (fman->state->rev_info.major >= 6)\n\t\tfman->cfg->dma_aid_mode = FMAN_DMA_AID_OUT_PORT_ID;\n\n\tfman->cfg->qmi_def_tnums_thresh = fman->state->qmi_def_tnums_thresh;\n\n\tfman->state->total_num_of_tasks =\n\t(u8)DFLT_TOTAL_NUM_OF_TASKS(fman->state->rev_info.major,\n\t\t\t\t    fman->state->rev_info.minor,\n\t\t\t\t    fman->state->bmi_max_num_of_tasks);\n\n\tif (fman->state->rev_info.major < 6) {\n\t\tfman->cfg->dma_comm_qtsh_clr_emer =\n\t\t(u8)DFLT_DMA_COMM_Q_LOW(fman->state->rev_info.major,\n\t\t\t\t\tfman->state->dma_thresh_max_commq);\n\n\t\tfman->cfg->dma_comm_qtsh_asrt_emer =\n\t\t(u8)DFLT_DMA_COMM_Q_HIGH(fman->state->rev_info.major,\n\t\t\t\t\t fman->state->dma_thresh_max_commq);\n\n\t\tfman->cfg->dma_cam_num_of_entries =\n\t\tDFLT_DMA_CAM_NUM_OF_ENTRIES(fman->state->rev_info.major);\n\n\t\tfman->cfg->dma_read_buf_tsh_clr_emer =\n\t\tDFLT_DMA_READ_INT_BUF_LOW(fman->state->dma_thresh_max_buf);\n\n\t\tfman->cfg->dma_read_buf_tsh_asrt_emer =\n\t\tDFLT_DMA_READ_INT_BUF_HIGH(fman->state->dma_thresh_max_buf);\n\n\t\tfman->cfg->dma_write_buf_tsh_clr_emer =\n\t\tDFLT_DMA_WRITE_INT_BUF_LOW(fman->state->dma_thresh_max_buf);\n\n\t\tfman->cfg->dma_write_buf_tsh_asrt_emer =\n\t\tDFLT_DMA_WRITE_INT_BUF_HIGH(fman->state->dma_thresh_max_buf);\n\n\t\tfman->cfg->dma_axi_dbg_num_of_beats =\n\t\tDFLT_AXI_DBG_NUM_OF_BEATS;\n\t}\n\n\treturn 0;\n\nerr_fm_soc_specific:\n\tkfree(fman->cfg);\nerr_fm_drv:\n\tkfree(fman->state);\nerr_fm_state:\n\tkfree(fman);\n\treturn -EINVAL;\n}\n\nstatic int fman_reset(struct fman *fman)\n{\n\tu32 count;\n\tint err = 0;\n\n\tif (fman->state->rev_info.major < 6) {\n\t\tiowrite32be(FPM_RSTC_FM_RESET, &fman->fpm_regs->fm_rstc);\n\t\t \n\t\tcount = 100;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t} while (((ioread32be(&fman->fpm_regs->fm_rstc)) &\n\t\t\t FPM_RSTC_FM_RESET) && --count);\n\t\tif (count == 0)\n\t\t\terr = -EBUSY;\n\n\t\tgoto _return;\n\t} else {\n#ifdef CONFIG_PPC\n\t\tstruct device_node *guts_node;\n\t\tstruct ccsr_guts __iomem *guts_regs;\n\t\tu32 devdisr2, reg;\n\n\t\t \n\t\tguts_node =\n\t\t\tof_find_compatible_node(NULL, NULL,\n\t\t\t\t\t\t\"fsl,qoriq-device-config-2.0\");\n\t\tif (!guts_node) {\n\t\t\tdev_err(fman->dev, \"%s: Couldn't find guts node\\n\",\n\t\t\t\t__func__);\n\t\t\tgoto guts_node;\n\t\t}\n\n\t\tguts_regs = of_iomap(guts_node, 0);\n\t\tif (!guts_regs) {\n\t\t\tdev_err(fman->dev, \"%s: Couldn't map %pOF regs\\n\",\n\t\t\t\t__func__, guts_node);\n\t\t\tgoto guts_regs;\n\t\t}\n#define FMAN1_ALL_MACS_MASK\t0xFCC00000\n#define FMAN2_ALL_MACS_MASK\t0x000FCC00\n\t\t \n\t\tdevdisr2 = ioread32be(&guts_regs->devdisr2);\n\t\tif (fman->dts_params.id == 0)\n\t\t\treg = devdisr2 & ~FMAN1_ALL_MACS_MASK;\n\t\telse\n\t\t\treg = devdisr2 & ~FMAN2_ALL_MACS_MASK;\n\n\t\t \n\t\tiowrite32be(reg, &guts_regs->devdisr2);\n#endif\n\n\t\t \n\t\tiowrite32be(FPM_RSTC_FM_RESET, &fman->fpm_regs->fm_rstc);\n\n\t\t \n\t\tcount = 100;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t} while (((ioread32be(&fman->fpm_regs->fm_rstc)) &\n\t\t\t FPM_RSTC_FM_RESET) && --count);\n\t\tif (count == 0) {\n#ifdef CONFIG_PPC\n\t\t\tiounmap(guts_regs);\n\t\t\tof_node_put(guts_node);\n#endif\n\t\t\terr = -EBUSY;\n\t\t\tgoto _return;\n\t\t}\n#ifdef CONFIG_PPC\n\n\t\t \n\t\tiowrite32be(devdisr2, &guts_regs->devdisr2);\n\n\t\tiounmap(guts_regs);\n\t\tof_node_put(guts_node);\n#endif\n\n\t\tgoto _return;\n\n#ifdef CONFIG_PPC\nguts_regs:\n\t\tof_node_put(guts_node);\nguts_node:\n\t\tdev_dbg(fman->dev, \"%s: Didn't perform FManV3 reset due to Errata A007273!\\n\",\n\t\t\t__func__);\n#endif\n\t}\n_return:\n\treturn err;\n}\n\nstatic int fman_init(struct fman *fman)\n{\n\tstruct fman_cfg *cfg = NULL;\n\tint err = 0, i, count;\n\n\tif (is_init_done(fman->cfg))\n\t\treturn -EINVAL;\n\n\tfman->state->count1_micro_bit = FM_TIMESTAMP_1_USEC_BIT;\n\n\tcfg = fman->cfg;\n\n\t \n\tif (fman->state->rev_info.major < 6)\n\t\tfman->state->exceptions &= ~FMAN_EX_BMI_DISPATCH_RAM_ECC;\n\n\tif (fman->state->rev_info.major >= 6)\n\t\tfman->state->exceptions &= ~FMAN_EX_QMI_SINGLE_ECC;\n\n\t \n\tmemset_io((void __iomem *)(fman->base_addr + CGP_OFFSET), 0,\n\t\t  fman->state->fm_port_num_of_cg);\n\n\t \n\tfor (i = 1; i < FMAN_LIODN_TBL; i++) {\n\t\tu32 liodn_base;\n\n\t\tfman->liodn_offset[i] =\n\t\t\tioread32be(&fman->bmi_regs->fmbm_spliodn[i - 1]);\n\t\tif (!IS_ENABLED(CONFIG_FSL_PAMU))\n\t\t\tcontinue;\n\t\tliodn_base = ioread32be(&fman->dma_regs->fmdmplr[i / 2]);\n\t\tif (i % 2) {\n\t\t\t \n\t\t\tliodn_base &= DMA_LIODN_BASE_MASK;\n\t\t} else {\n\t\t\t \n\t\t\tliodn_base >>= DMA_LIODN_SHIFT;\n\t\t\tliodn_base &= DMA_LIODN_BASE_MASK;\n\t\t}\n\t\tfman->liodn_base[i] = liodn_base;\n\t}\n\n\terr = fman_reset(fman);\n\tif (err)\n\t\treturn err;\n\n\tif (ioread32be(&fman->qmi_regs->fmqm_gs) & QMI_GS_HALT_NOT_BUSY) {\n\t\tresume(fman->fpm_regs);\n\t\t \n\t\tcount = 100;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t} while (((ioread32be(&fman->qmi_regs->fmqm_gs)) &\n\t\t\t QMI_GS_HALT_NOT_BUSY) && --count);\n\t\tif (count == 0)\n\t\t\tdev_warn(fman->dev, \"%s: QMI is in halt not busy state\\n\",\n\t\t\t\t __func__);\n\t}\n\n\tif (clear_iram(fman) != 0)\n\t\treturn -EINVAL;\n\n\tcfg->exceptions = fman->state->exceptions;\n\n\t \n\n\terr = dma_init(fman);\n\tif (err != 0) {\n\t\tfree_init_resources(fman);\n\t\treturn err;\n\t}\n\n\t \n\tfpm_init(fman->fpm_regs, fman->cfg);\n\n\t \n\t \n\tfman->fifo_offset = fman_muram_alloc(fman->muram,\n\t\t\t\t\t     fman->state->total_fifo_size);\n\tif (IS_ERR_VALUE(fman->fifo_offset)) {\n\t\tfree_init_resources(fman);\n\t\tdev_err(fman->dev, \"%s: MURAM alloc for BMI FIFO failed\\n\",\n\t\t\t__func__);\n\t\treturn -ENOMEM;\n\t}\n\n\tcfg->fifo_base_addr = fman->fifo_offset;\n\tcfg->total_fifo_size = fman->state->total_fifo_size;\n\tcfg->total_num_of_tasks = fman->state->total_num_of_tasks;\n\tcfg->clk_freq = fman->state->fm_clk_freq;\n\n\t \n\tbmi_init(fman->bmi_regs, fman->cfg);\n\n\t \n\tqmi_init(fman->qmi_regs, fman->cfg);\n\n\t \n\thwp_init(fman->hwp_regs);\n\n\t \n\tfman->keygen = keygen_init(fman->kg_regs);\n\tif (!fman->keygen)\n\t\treturn -EINVAL;\n\n\terr = enable(fman, cfg);\n\tif (err != 0)\n\t\treturn err;\n\n\tenable_time_stamp(fman);\n\n\tkfree(fman->cfg);\n\tfman->cfg = NULL;\n\n\treturn 0;\n}\n\nstatic int fman_set_exception(struct fman *fman,\n\t\t\t      enum fman_exceptions exception, bool enable)\n{\n\tu32 bit_mask = 0;\n\n\tif (!is_init_done(fman->cfg))\n\t\treturn -EINVAL;\n\n\tbit_mask = get_exception_flag(exception);\n\tif (bit_mask) {\n\t\tif (enable)\n\t\t\tfman->state->exceptions |= bit_mask;\n\t\telse\n\t\t\tfman->state->exceptions &= ~bit_mask;\n\t} else {\n\t\tdev_err(fman->dev, \"%s: Undefined exception (%d)\\n\",\n\t\t\t__func__, exception);\n\t\treturn -EINVAL;\n\t}\n\n\treturn set_exception(fman, exception, enable);\n}\n\n \nvoid fman_register_intr(struct fman *fman, enum fman_event_modules module,\n\t\t\tu8 mod_id, enum fman_intr_type intr_type,\n\t\t\tvoid (*isr_cb)(void *src_arg), void *src_arg)\n{\n\tint event = 0;\n\n\tevent = get_module_event(module, mod_id, intr_type);\n\tWARN_ON(event >= FMAN_EV_CNT);\n\n\t \n\tfman->intr_mng[event].isr_cb = isr_cb;\n\tfman->intr_mng[event].src_handle = src_arg;\n}\nEXPORT_SYMBOL(fman_register_intr);\n\n \nvoid fman_unregister_intr(struct fman *fman, enum fman_event_modules module,\n\t\t\t  u8 mod_id, enum fman_intr_type intr_type)\n{\n\tint event = 0;\n\n\tevent = get_module_event(module, mod_id, intr_type);\n\tWARN_ON(event >= FMAN_EV_CNT);\n\n\tfman->intr_mng[event].isr_cb = NULL;\n\tfman->intr_mng[event].src_handle = NULL;\n}\nEXPORT_SYMBOL(fman_unregister_intr);\n\n \nint fman_set_port_params(struct fman *fman,\n\t\t\t struct fman_port_init_params *port_params)\n{\n\tint err;\n\tunsigned long flags;\n\tu8 port_id = port_params->port_id, mac_id;\n\n\tspin_lock_irqsave(&fman->spinlock, flags);\n\n\terr = set_num_of_tasks(fman, port_params->port_id,\n\t\t\t       &port_params->num_of_tasks,\n\t\t\t       &port_params->num_of_extra_tasks);\n\tif (err)\n\t\tgoto return_err;\n\n\t \n\tif (port_params->port_type != FMAN_PORT_TYPE_RX) {\n\t\tu32 enq_th, deq_th, reg;\n\n\t\t \n\t\tfman->state->accumulated_num_of_deq_tnums +=\n\t\t\tport_params->deq_pipeline_depth;\n\t\tenq_th = (ioread32be(&fman->qmi_regs->fmqm_gc) &\n\t\t\t  QMI_CFG_ENQ_MASK) >> QMI_CFG_ENQ_SHIFT;\n\t\t \n\t\tif (enq_th >= (fman->state->qmi_max_num_of_tnums -\n\t\t    fman->state->accumulated_num_of_deq_tnums)) {\n\t\t\tenq_th =\n\t\t\tfman->state->qmi_max_num_of_tnums -\n\t\t\tfman->state->accumulated_num_of_deq_tnums - 1;\n\n\t\t\treg = ioread32be(&fman->qmi_regs->fmqm_gc);\n\t\t\treg &= ~QMI_CFG_ENQ_MASK;\n\t\t\treg |= (enq_th << QMI_CFG_ENQ_SHIFT);\n\t\t\tiowrite32be(reg, &fman->qmi_regs->fmqm_gc);\n\t\t}\n\n\t\tdeq_th = ioread32be(&fman->qmi_regs->fmqm_gc) &\n\t\t\t\t    QMI_CFG_DEQ_MASK;\n\t\t \n\t\tif ((deq_th <= fman->state->accumulated_num_of_deq_tnums) &&\n\t\t    (deq_th < fman->state->qmi_max_num_of_tnums - 1)) {\n\t\t\tdeq_th = fman->state->accumulated_num_of_deq_tnums + 1;\n\t\t\treg = ioread32be(&fman->qmi_regs->fmqm_gc);\n\t\t\treg &= ~QMI_CFG_DEQ_MASK;\n\t\t\treg |= deq_th;\n\t\t\tiowrite32be(reg, &fman->qmi_regs->fmqm_gc);\n\t\t}\n\t}\n\n\terr = set_size_of_fifo(fman, port_params->port_id,\n\t\t\t       &port_params->size_of_fifo,\n\t\t\t       &port_params->extra_size_of_fifo);\n\tif (err)\n\t\tgoto return_err;\n\n\terr = set_num_of_open_dmas(fman, port_params->port_id,\n\t\t\t\t   &port_params->num_of_open_dmas,\n\t\t\t\t   &port_params->num_of_extra_open_dmas);\n\tif (err)\n\t\tgoto return_err;\n\n\tset_port_liodn(fman, port_id, fman->liodn_base[port_id],\n\t\t       fman->liodn_offset[port_id]);\n\n\tif (fman->state->rev_info.major < 6)\n\t\tset_port_order_restoration(fman->fpm_regs, port_id);\n\n\tmac_id = hw_port_id_to_sw_port_id(fman->state->rev_info.major, port_id);\n\n\tif (port_params->max_frame_length >= fman->state->mac_mfl[mac_id]) {\n\t\tfman->state->port_mfl[mac_id] = port_params->max_frame_length;\n\t} else {\n\t\tdev_warn(fman->dev, \"%s: Port (%d) max_frame_length is smaller than MAC (%d) current MTU\\n\",\n\t\t\t __func__, port_id, mac_id);\n\t\terr = -EINVAL;\n\t\tgoto return_err;\n\t}\n\n\tspin_unlock_irqrestore(&fman->spinlock, flags);\n\n\treturn 0;\n\nreturn_err:\n\tspin_unlock_irqrestore(&fman->spinlock, flags);\n\treturn err;\n}\nEXPORT_SYMBOL(fman_set_port_params);\n\n \nint fman_reset_mac(struct fman *fman, u8 mac_id)\n{\n\tstruct fman_fpm_regs __iomem *fpm_rg = fman->fpm_regs;\n\tu32 msk, timeout = 100;\n\n\tif (fman->state->rev_info.major >= 6) {\n\t\tdev_err(fman->dev, \"%s: FMan MAC reset no available for FMan V3!\\n\",\n\t\t\t__func__);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tswitch (mac_id) {\n\tcase 0:\n\t\tmsk = FPM_RSTC_MAC0_RESET;\n\t\tbreak;\n\tcase 1:\n\t\tmsk = FPM_RSTC_MAC1_RESET;\n\t\tbreak;\n\tcase 2:\n\t\tmsk = FPM_RSTC_MAC2_RESET;\n\t\tbreak;\n\tcase 3:\n\t\tmsk = FPM_RSTC_MAC3_RESET;\n\t\tbreak;\n\tcase 4:\n\t\tmsk = FPM_RSTC_MAC4_RESET;\n\t\tbreak;\n\tcase 5:\n\t\tmsk = FPM_RSTC_MAC5_RESET;\n\t\tbreak;\n\tcase 6:\n\t\tmsk = FPM_RSTC_MAC6_RESET;\n\t\tbreak;\n\tcase 7:\n\t\tmsk = FPM_RSTC_MAC7_RESET;\n\t\tbreak;\n\tcase 8:\n\t\tmsk = FPM_RSTC_MAC8_RESET;\n\t\tbreak;\n\tcase 9:\n\t\tmsk = FPM_RSTC_MAC9_RESET;\n\t\tbreak;\n\tdefault:\n\t\tdev_warn(fman->dev, \"%s: Illegal MAC Id [%d]\\n\",\n\t\t\t __func__, mac_id);\n\t\treturn -EINVAL;\n\t}\n\n\t \n\tiowrite32be(msk, &fpm_rg->fm_rstc);\n\twhile ((ioread32be(&fpm_rg->fm_rstc) & msk) && --timeout)\n\t\tudelay(10);\n\n\tif (!timeout)\n\t\treturn -EIO;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(fman_reset_mac);\n\n \nint fman_set_mac_max_frame(struct fman *fman, u8 mac_id, u16 mfl)\n{\n\t \n\tif ((!fman->state->port_mfl[mac_id]) ||\n\t    (mfl <= fman->state->port_mfl[mac_id])) {\n\t\tfman->state->mac_mfl[mac_id] = mfl;\n\t} else {\n\t\tdev_warn(fman->dev, \"%s: MAC max_frame_length is larger than Port max_frame_length\\n\",\n\t\t\t __func__);\n\t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL(fman_set_mac_max_frame);\n\n \nu16 fman_get_clock_freq(struct fman *fman)\n{\n\treturn fman->state->fm_clk_freq;\n}\n\n \nu32 fman_get_bmi_max_fifo_size(struct fman *fman)\n{\n\treturn fman->state->bmi_max_fifo_size;\n}\nEXPORT_SYMBOL(fman_get_bmi_max_fifo_size);\n\n \nvoid fman_get_revision(struct fman *fman, struct fman_rev_info *rev_info)\n{\n\tu32 tmp;\n\n\ttmp = ioread32be(&fman->fpm_regs->fm_ip_rev_1);\n\trev_info->major = (u8)((tmp & FPM_REV1_MAJOR_MASK) >>\n\t\t\t\tFPM_REV1_MAJOR_SHIFT);\n\trev_info->minor = tmp & FPM_REV1_MINOR_MASK;\n}\nEXPORT_SYMBOL(fman_get_revision);\n\n \nu32 fman_get_qman_channel_id(struct fman *fman, u32 port_id)\n{\n\tint i;\n\n\tif (fman->state->rev_info.major >= 6) {\n\t\tstatic const u32 port_ids[] = {\n\t\t\t0x30, 0x31, 0x28, 0x29, 0x2a, 0x2b,\n\t\t\t0x2c, 0x2d, 0x2, 0x3, 0x4, 0x5, 0x7, 0x7\n\t\t};\n\n\t\tfor (i = 0; i < fman->state->num_of_qman_channels; i++) {\n\t\t\tif (port_ids[i] == port_id)\n\t\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tstatic const u32 port_ids[] = {\n\t\t\t0x30, 0x28, 0x29, 0x2a, 0x2b, 0x2c, 0x1,\n\t\t\t0x2, 0x3, 0x4, 0x5, 0x7, 0x7\n\t\t};\n\n\t\tfor (i = 0; i < fman->state->num_of_qman_channels; i++) {\n\t\t\tif (port_ids[i] == port_id)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (i == fman->state->num_of_qman_channels)\n\t\treturn 0;\n\n\treturn fman->state->qman_channel_base + i;\n}\nEXPORT_SYMBOL(fman_get_qman_channel_id);\n\n \nstruct resource *fman_get_mem_region(struct fman *fman)\n{\n\treturn fman->state->res;\n}\nEXPORT_SYMBOL(fman_get_mem_region);\n\n \n \n#define FSL_FM_RX_EXTRA_HEADROOM\t64\n#define FSL_FM_RX_EXTRA_HEADROOM_MIN\t16\n#define FSL_FM_RX_EXTRA_HEADROOM_MAX\t384\n\n \n#define FSL_FM_MAX_FRAME_SIZE\t\t\t1522\n#define FSL_FM_MAX_POSSIBLE_FRAME_SIZE\t\t9600\n#define FSL_FM_MIN_POSSIBLE_FRAME_SIZE\t\t64\n\n \nstatic int fsl_fm_rx_extra_headroom = FSL_FM_RX_EXTRA_HEADROOM;\nmodule_param(fsl_fm_rx_extra_headroom, int, 0);\nMODULE_PARM_DESC(fsl_fm_rx_extra_headroom, \"Extra headroom for Rx buffers\");\n\n \nstatic int fsl_fm_max_frm = FSL_FM_MAX_FRAME_SIZE;\nmodule_param(fsl_fm_max_frm, int, 0);\nMODULE_PARM_DESC(fsl_fm_max_frm, \"Maximum frame size, across all interfaces\");\n\n \nu16 fman_get_max_frm(void)\n{\n\tstatic bool fm_check_mfl;\n\n\tif (!fm_check_mfl) {\n\t\tif (fsl_fm_max_frm > FSL_FM_MAX_POSSIBLE_FRAME_SIZE ||\n\t\t    fsl_fm_max_frm < FSL_FM_MIN_POSSIBLE_FRAME_SIZE) {\n\t\t\tpr_warn(\"Invalid fsl_fm_max_frm value (%d) in bootargs, valid range is %d-%d. Falling back to the default (%d)\\n\",\n\t\t\t\tfsl_fm_max_frm,\n\t\t\t\tFSL_FM_MIN_POSSIBLE_FRAME_SIZE,\n\t\t\t\tFSL_FM_MAX_POSSIBLE_FRAME_SIZE,\n\t\t\t\tFSL_FM_MAX_FRAME_SIZE);\n\t\t\tfsl_fm_max_frm = FSL_FM_MAX_FRAME_SIZE;\n\t\t}\n\t\tfm_check_mfl = true;\n\t}\n\n\treturn fsl_fm_max_frm;\n}\nEXPORT_SYMBOL(fman_get_max_frm);\n\n \nint fman_get_rx_extra_headroom(void)\n{\n\tstatic bool fm_check_rx_extra_headroom;\n\n\tif (!fm_check_rx_extra_headroom) {\n\t\tif (fsl_fm_rx_extra_headroom > FSL_FM_RX_EXTRA_HEADROOM_MAX ||\n\t\t    fsl_fm_rx_extra_headroom < FSL_FM_RX_EXTRA_HEADROOM_MIN) {\n\t\t\tpr_warn(\"Invalid fsl_fm_rx_extra_headroom value (%d) in bootargs, valid range is %d-%d. Falling back to the default (%d)\\n\",\n\t\t\t\tfsl_fm_rx_extra_headroom,\n\t\t\t\tFSL_FM_RX_EXTRA_HEADROOM_MIN,\n\t\t\t\tFSL_FM_RX_EXTRA_HEADROOM_MAX,\n\t\t\t\tFSL_FM_RX_EXTRA_HEADROOM);\n\t\t\tfsl_fm_rx_extra_headroom = FSL_FM_RX_EXTRA_HEADROOM;\n\t\t}\n\n\t\tfm_check_rx_extra_headroom = true;\n\t\tfsl_fm_rx_extra_headroom = ALIGN(fsl_fm_rx_extra_headroom, 16);\n\t}\n\n\treturn fsl_fm_rx_extra_headroom;\n}\nEXPORT_SYMBOL(fman_get_rx_extra_headroom);\n\n \nstruct fman *fman_bind(struct device *fm_dev)\n{\n\treturn (struct fman *)(dev_get_drvdata(get_device(fm_dev)));\n}\nEXPORT_SYMBOL(fman_bind);\n\n#ifdef CONFIG_DPAA_ERRATUM_A050385\nbool fman_has_errata_a050385(void)\n{\n\treturn fman_has_err_a050385;\n}\nEXPORT_SYMBOL(fman_has_errata_a050385);\n#endif\n\nstatic irqreturn_t fman_err_irq(int irq, void *handle)\n{\n\tstruct fman *fman = (struct fman *)handle;\n\tu32 pending;\n\tstruct fman_fpm_regs __iomem *fpm_rg;\n\tirqreturn_t single_ret, ret = IRQ_NONE;\n\n\tif (!is_init_done(fman->cfg))\n\t\treturn IRQ_NONE;\n\n\tfpm_rg = fman->fpm_regs;\n\n\t \n\tpending = ioread32be(&fpm_rg->fm_epi);\n\tif (!pending)\n\t\treturn IRQ_NONE;\n\n\tif (pending & ERR_INTR_EN_BMI) {\n\t\tsingle_ret = bmi_err_event(fman);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_QMI) {\n\t\tsingle_ret = qmi_err_event(fman);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_FPM) {\n\t\tsingle_ret = fpm_err_event(fman);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_DMA) {\n\t\tsingle_ret = dma_err_event(fman);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MURAM) {\n\t\tsingle_ret = muram_err_intr(fman);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\n\t \n\tif (pending & ERR_INTR_EN_MAC0) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 0);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC1) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 1);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC2) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 2);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC3) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 3);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC4) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 4);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC5) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 5);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC6) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 6);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC7) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 7);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC8) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 8);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & ERR_INTR_EN_MAC9) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_ERR_MAC0 + 9);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\n\treturn ret;\n}\n\nstatic irqreturn_t fman_irq(int irq, void *handle)\n{\n\tstruct fman *fman = (struct fman *)handle;\n\tu32 pending;\n\tstruct fman_fpm_regs __iomem *fpm_rg;\n\tirqreturn_t single_ret, ret = IRQ_NONE;\n\n\tif (!is_init_done(fman->cfg))\n\t\treturn IRQ_NONE;\n\n\tfpm_rg = fman->fpm_regs;\n\n\t \n\tpending = ioread32be(&fpm_rg->fm_npi);\n\tif (!pending)\n\t\treturn IRQ_NONE;\n\n\tif (pending & INTR_EN_QMI) {\n\t\tsingle_ret = qmi_event(fman);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\n\t \n\tif (pending & INTR_EN_MAC0) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 0);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC1) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 1);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC2) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 2);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC3) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 3);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC4) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 4);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC5) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 5);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC6) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 6);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC7) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 7);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC8) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 8);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\tif (pending & INTR_EN_MAC9) {\n\t\tsingle_ret = call_mac_isr(fman, FMAN_EV_MAC0 + 9);\n\t\tif (single_ret == IRQ_HANDLED)\n\t\t\tret = IRQ_HANDLED;\n\t}\n\n\treturn ret;\n}\n\nstatic const struct of_device_id fman_muram_match[] = {\n\t{\n\t\t.compatible = \"fsl,fman-muram\"},\n\t{}\n};\nMODULE_DEVICE_TABLE(of, fman_muram_match);\n\nstatic struct fman *read_dts_node(struct platform_device *of_dev)\n{\n\tstruct fman *fman;\n\tstruct device_node *fm_node, *muram_node;\n\tstruct resource *res;\n\tu32 val, range[2];\n\tint err, irq;\n\tstruct clk *clk;\n\tu32 clk_rate;\n\tphys_addr_t phys_base_addr;\n\tresource_size_t mem_size;\n\n\tfman = kzalloc(sizeof(*fman), GFP_KERNEL);\n\tif (!fman)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfm_node = of_node_get(of_dev->dev.of_node);\n\n\terr = of_property_read_u32(fm_node, \"cell-index\", &val);\n\tif (err) {\n\t\tdev_err(&of_dev->dev, \"%s: failed to read cell-index for %pOF\\n\",\n\t\t\t__func__, fm_node);\n\t\tgoto fman_node_put;\n\t}\n\tfman->dts_params.id = (u8)val;\n\n\t \n\terr = platform_get_irq(of_dev, 0);\n\tif (err < 0)\n\t\tgoto fman_node_put;\n\tirq = err;\n\n\t \n\terr = platform_get_irq(of_dev, 1);\n\tif (err < 0)\n\t\tgoto fman_node_put;\n\tfman->dts_params.err_irq = err;\n\n\t \n\tres = platform_get_resource(of_dev, IORESOURCE_MEM, 0);\n\tif (!res) {\n\t\terr = -EINVAL;\n\t\tdev_err(&of_dev->dev, \"%s: Can't get FMan memory resource\\n\",\n\t\t\t__func__);\n\t\tgoto fman_node_put;\n\t}\n\n\tphys_base_addr = res->start;\n\tmem_size = resource_size(res);\n\n\tclk = of_clk_get(fm_node, 0);\n\tif (IS_ERR(clk)) {\n\t\terr = PTR_ERR(clk);\n\t\tdev_err(&of_dev->dev, \"%s: Failed to get FM%d clock structure\\n\",\n\t\t\t__func__, fman->dts_params.id);\n\t\tgoto fman_node_put;\n\t}\n\n\tclk_rate = clk_get_rate(clk);\n\tif (!clk_rate) {\n\t\terr = -EINVAL;\n\t\tdev_err(&of_dev->dev, \"%s: Failed to determine FM%d clock rate\\n\",\n\t\t\t__func__, fman->dts_params.id);\n\t\tgoto fman_node_put;\n\t}\n\t \n\tfman->dts_params.clk_freq = DIV_ROUND_UP(clk_rate, 1000000);\n\n\terr = of_property_read_u32_array(fm_node, \"fsl,qman-channel-range\",\n\t\t\t\t\t &range[0], 2);\n\tif (err) {\n\t\tdev_err(&of_dev->dev, \"%s: failed to read fsl,qman-channel-range for %pOF\\n\",\n\t\t\t__func__, fm_node);\n\t\tgoto fman_node_put;\n\t}\n\tfman->dts_params.qman_channel_base = range[0];\n\tfman->dts_params.num_of_qman_channels = range[1];\n\n\t \n\tmuram_node = of_find_matching_node(fm_node, fman_muram_match);\n\tif (!muram_node) {\n\t\terr = -EINVAL;\n\t\tdev_err(&of_dev->dev, \"%s: could not find MURAM node\\n\",\n\t\t\t__func__);\n\t\tgoto fman_free;\n\t}\n\n\terr = of_address_to_resource(muram_node, 0,\n\t\t\t\t     &fman->dts_params.muram_res);\n\tif (err) {\n\t\tof_node_put(muram_node);\n\t\tdev_err(&of_dev->dev, \"%s: of_address_to_resource() = %d\\n\",\n\t\t\t__func__, err);\n\t\tgoto fman_free;\n\t}\n\n\tof_node_put(muram_node);\n\n\terr = devm_request_irq(&of_dev->dev, irq, fman_irq, IRQF_SHARED,\n\t\t\t       \"fman\", fman);\n\tif (err < 0) {\n\t\tdev_err(&of_dev->dev, \"%s: irq %d allocation failed (error = %d)\\n\",\n\t\t\t__func__, irq, err);\n\t\tgoto fman_free;\n\t}\n\n\tif (fman->dts_params.err_irq != 0) {\n\t\terr = devm_request_irq(&of_dev->dev, fman->dts_params.err_irq,\n\t\t\t\t       fman_err_irq, IRQF_SHARED,\n\t\t\t\t       \"fman-err\", fman);\n\t\tif (err < 0) {\n\t\t\tdev_err(&of_dev->dev, \"%s: irq %d allocation failed (error = %d)\\n\",\n\t\t\t\t__func__, fman->dts_params.err_irq, err);\n\t\t\tgoto fman_free;\n\t\t}\n\t}\n\n\tfman->dts_params.res =\n\t\tdevm_request_mem_region(&of_dev->dev, phys_base_addr,\n\t\t\t\t\tmem_size, \"fman\");\n\tif (!fman->dts_params.res) {\n\t\terr = -EBUSY;\n\t\tdev_err(&of_dev->dev, \"%s: request_mem_region() failed\\n\",\n\t\t\t__func__);\n\t\tgoto fman_free;\n\t}\n\n\tfman->dts_params.base_addr =\n\t\tdevm_ioremap(&of_dev->dev, phys_base_addr, mem_size);\n\tif (!fman->dts_params.base_addr) {\n\t\terr = -ENOMEM;\n\t\tdev_err(&of_dev->dev, \"%s: devm_ioremap() failed\\n\", __func__);\n\t\tgoto fman_free;\n\t}\n\n\tfman->dev = &of_dev->dev;\n\n\terr = of_platform_populate(fm_node, NULL, NULL, &of_dev->dev);\n\tif (err) {\n\t\tdev_err(&of_dev->dev, \"%s: of_platform_populate() failed\\n\",\n\t\t\t__func__);\n\t\tgoto fman_free;\n\t}\n\n#ifdef CONFIG_DPAA_ERRATUM_A050385\n\tfman_has_err_a050385 =\n\t\tof_property_read_bool(fm_node, \"fsl,erratum-a050385\");\n#endif\n\n\treturn fman;\n\nfman_node_put:\n\tof_node_put(fm_node);\nfman_free:\n\tkfree(fman);\n\treturn ERR_PTR(err);\n}\n\nstatic int fman_probe(struct platform_device *of_dev)\n{\n\tstruct fman *fman;\n\tstruct device *dev;\n\tint err;\n\n\tdev = &of_dev->dev;\n\n\tfman = read_dts_node(of_dev);\n\tif (IS_ERR(fman))\n\t\treturn PTR_ERR(fman);\n\n\terr = fman_config(fman);\n\tif (err) {\n\t\tdev_err(dev, \"%s: FMan config failed\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (fman_init(fman) != 0) {\n\t\tdev_err(dev, \"%s: FMan init failed\\n\", __func__);\n\t\treturn -EINVAL;\n\t}\n\n\tif (fman->dts_params.err_irq == 0) {\n\t\tfman_set_exception(fman, FMAN_EX_DMA_BUS_ERROR, false);\n\t\tfman_set_exception(fman, FMAN_EX_DMA_READ_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_DMA_SYSTEM_WRITE_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_DMA_FM_WRITE_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_DMA_SINGLE_PORT_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_FPM_STALL_ON_TASKS, false);\n\t\tfman_set_exception(fman, FMAN_EX_FPM_SINGLE_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_FPM_DOUBLE_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_QMI_SINGLE_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_QMI_DOUBLE_ECC, false);\n\t\tfman_set_exception(fman,\n\t\t\t\t   FMAN_EX_QMI_DEQ_FROM_UNKNOWN_PORTID, false);\n\t\tfman_set_exception(fman, FMAN_EX_BMI_LIST_RAM_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_BMI_STORAGE_PROFILE_ECC,\n\t\t\t\t   false);\n\t\tfman_set_exception(fman, FMAN_EX_BMI_STATISTICS_RAM_ECC, false);\n\t\tfman_set_exception(fman, FMAN_EX_BMI_DISPATCH_RAM_ECC, false);\n\t}\n\n\tdev_set_drvdata(dev, fman);\n\n\tdev_dbg(dev, \"FMan%d probed\\n\", fman->dts_params.id);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fman_match[] = {\n\t{\n\t\t.compatible = \"fsl,fman\"},\n\t{}\n};\n\nMODULE_DEVICE_TABLE(of, fman_match);\n\nstatic struct platform_driver fman_driver = {\n\t.driver = {\n\t\t.name = \"fsl-fman\",\n\t\t.of_match_table = fman_match,\n\t},\n\t.probe = fman_probe,\n};\n\nstatic int __init fman_load(void)\n{\n\tint err;\n\n\tpr_debug(\"FSL DPAA FMan driver\\n\");\n\n\terr = platform_driver_register(&fman_driver);\n\tif (err < 0)\n\t\tpr_err(\"Error, platform_driver_register() = %d\\n\", err);\n\n\treturn err;\n}\nmodule_init(fman_load);\n\nstatic void __exit fman_unload(void)\n{\n\tplatform_driver_unregister(&fman_driver);\n}\nmodule_exit(fman_unload);\n\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_DESCRIPTION(\"Freescale DPAA Frame Manager driver\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}