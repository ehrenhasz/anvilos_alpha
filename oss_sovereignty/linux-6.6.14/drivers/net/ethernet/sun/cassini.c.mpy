{
  "module_name": "cassini.c",
  "hash_id": "50acc84bcec630d52c1eecb70603ee9ea13339a432c39fcc461ade206027aa37",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/sun/cassini.c",
  "human_readable_source": "\n \n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/vmalloc.h>\n#include <linux/ioport.h>\n#include <linux/pci.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/list.h>\n#include <linux/dma-mapping.h>\n\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/ethtool.h>\n#include <linux/crc32.h>\n#include <linux/random.h>\n#include <linux/mii.h>\n#include <linux/ip.h>\n#include <linux/tcp.h>\n#include <linux/mutex.h>\n#include <linux/firmware.h>\n\n#include <net/checksum.h>\n\n#include <linux/atomic.h>\n#include <asm/io.h>\n#include <asm/byteorder.h>\n#include <linux/uaccess.h>\n#include <linux/jiffies.h>\n\n#define CAS_NCPUS            num_online_cpus()\n\n#define cas_skb_release(x)  netif_rx(x)\n\n \n#define USE_HP_WORKAROUND\n#define HP_WORKAROUND_DEFAULT  \n#define CAS_HP_ALT_FIRMWARE   cas_prog_null  \n\n#include \"cassini.h\"\n\n#define USE_TX_COMPWB       \n#define USE_CSMA_CD_PROTO   \n#define USE_RX_BLANK        \n#undef USE_ENTROPY_DEV      \n\n \n#undef  USE_PCI_INTB\n#undef  USE_PCI_INTC\n#undef  USE_PCI_INTD\n#undef  USE_QOS\n\n#undef  USE_VPD_DEBUG        \n\n \n#define USE_PAGE_ORDER       \n#define RX_DONT_BATCH  0     \n#define RX_COPY_ALWAYS 0     \n#define RX_COPY_MIN    64    \n#undef  RX_COUNT_BUFFERS     \n\n#define DRV_MODULE_NAME\t\t\"cassini\"\n#define DRV_MODULE_VERSION\t\"1.6\"\n#define DRV_MODULE_RELDATE\t\"21 May 2008\"\n\n#define CAS_DEF_MSG_ENABLE\t  \\\n\t(NETIF_MSG_DRV\t\t| \\\n\t NETIF_MSG_PROBE\t| \\\n\t NETIF_MSG_LINK\t\t| \\\n\t NETIF_MSG_TIMER\t| \\\n\t NETIF_MSG_IFDOWN\t| \\\n\t NETIF_MSG_IFUP\t\t| \\\n\t NETIF_MSG_RX_ERR\t| \\\n\t NETIF_MSG_TX_ERR)\n\n \n#define CAS_TX_TIMEOUT\t\t\t(HZ)\n#define CAS_LINK_TIMEOUT                (22*HZ/10)\n#define CAS_LINK_FAST_TIMEOUT           (1)\n\n \n#define STOP_TRIES_PHY 1000\n#define STOP_TRIES     5000\n\n \n#define CAS_MIN_FRAME\t\t\t97\n#define CAS_1000MB_MIN_FRAME            255\n#define CAS_MIN_MTU                     60\n#define CAS_MAX_MTU                     min(((cp->page_size << 1) - 0x50), 9000)\n\n#if 1\n \n#else\n#define CAS_RESET_MTU                   1\n#define CAS_RESET_ALL                   2\n#define CAS_RESET_SPARE                 3\n#endif\n\nstatic char version[] =\n\tDRV_MODULE_NAME \".c:v\" DRV_MODULE_VERSION \" (\" DRV_MODULE_RELDATE \")\\n\";\n\nstatic int cassini_debug = -1;\t \nstatic int link_mode;\n\nMODULE_AUTHOR(\"Adrian Sun (asun@darksunrising.com)\");\nMODULE_DESCRIPTION(\"Sun Cassini(+) ethernet driver\");\nMODULE_LICENSE(\"GPL\");\nMODULE_FIRMWARE(\"sun/cassini.bin\");\nmodule_param(cassini_debug, int, 0);\nMODULE_PARM_DESC(cassini_debug, \"Cassini bitmapped debugging message enable value\");\nmodule_param(link_mode, int, 0);\nMODULE_PARM_DESC(link_mode, \"default link mode\");\n\n \n#define DEFAULT_LINKDOWN_TIMEOUT 5\n \nstatic int linkdown_timeout = DEFAULT_LINKDOWN_TIMEOUT;\nmodule_param(linkdown_timeout, int, 0);\nMODULE_PARM_DESC(linkdown_timeout,\n\"min reset interval in sec. for PCS linkdown issue; disabled if not positive\");\n\n \nstatic int link_transition_timeout;\n\n\n\nstatic u16 link_modes[] = {\n\tBMCR_ANENABLE,\t\t\t  \n\t0,\t\t\t\t  \n\tBMCR_SPEED100,\t\t\t  \n\tBMCR_FULLDPLX,\t\t\t  \n\tBMCR_SPEED100|BMCR_FULLDPLX,\t  \n\tCAS_BMCR_SPEED1000|BMCR_FULLDPLX  \n};\n\nstatic const struct pci_device_id cas_pci_tbl[] = {\n\t{ PCI_VENDOR_ID_SUN, PCI_DEVICE_ID_SUN_CASSINI,\n\t  PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0UL },\n\t{ PCI_VENDOR_ID_NS, PCI_DEVICE_ID_NS_SATURN,\n\t  PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0UL },\n\t{ 0, }\n};\n\nMODULE_DEVICE_TABLE(pci, cas_pci_tbl);\n\nstatic void cas_set_link_modes(struct cas *cp);\n\nstatic inline void cas_lock_tx(struct cas *cp)\n{\n\tint i;\n\n\tfor (i = 0; i < N_TX_RINGS; i++)\n\t\tspin_lock_nested(&cp->tx_lock[i], i);\n}\n\n \n#define cas_lock_all_save(cp, flags) \\\ndo { \\\n\tstruct cas *xxxcp = (cp); \\\n\tspin_lock_irqsave(&xxxcp->lock, flags); \\\n\tcas_lock_tx(xxxcp); \\\n} while (0)\n\nstatic inline void cas_unlock_tx(struct cas *cp)\n{\n\tint i;\n\n\tfor (i = N_TX_RINGS; i > 0; i--)\n\t\tspin_unlock(&cp->tx_lock[i - 1]);\n}\n\n#define cas_unlock_all_restore(cp, flags) \\\ndo { \\\n\tstruct cas *xxxcp = (cp); \\\n\tcas_unlock_tx(xxxcp); \\\n\tspin_unlock_irqrestore(&xxxcp->lock, flags); \\\n} while (0)\n\nstatic void cas_disable_irq(struct cas *cp, const int ring)\n{\n\t \n\tif (ring == 0) {\n\t\twritel(0xFFFFFFFF, cp->regs + REG_INTR_MASK);\n\t\treturn;\n\t}\n\n\t \n\tif (cp->cas_flags & CAS_FLAG_REG_PLUS) {\n\t\tswitch (ring) {\n#if defined (USE_PCI_INTB) || defined(USE_PCI_INTC) || defined(USE_PCI_INTD)\n#ifdef USE_PCI_INTB\n\t\tcase 1:\n#endif\n#ifdef USE_PCI_INTC\n\t\tcase 2:\n#endif\n#ifdef USE_PCI_INTD\n\t\tcase 3:\n#endif\n\t\t\twritel(INTRN_MASK_CLEAR_ALL | INTRN_MASK_RX_EN,\n\t\t\t       cp->regs + REG_PLUS_INTRN_MASK(ring));\n\t\t\tbreak;\n#endif\n\t\tdefault:\n\t\t\twritel(INTRN_MASK_CLEAR_ALL, cp->regs +\n\t\t\t       REG_PLUS_INTRN_MASK(ring));\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic inline void cas_mask_intr(struct cas *cp)\n{\n\tint i;\n\n\tfor (i = 0; i < N_RX_COMP_RINGS; i++)\n\t\tcas_disable_irq(cp, i);\n}\n\nstatic void cas_enable_irq(struct cas *cp, const int ring)\n{\n\tif (ring == 0) {  \n\t\twritel(INTR_TX_DONE, cp->regs + REG_INTR_MASK);\n\t\treturn;\n\t}\n\n\tif (cp->cas_flags & CAS_FLAG_REG_PLUS) {\n\t\tswitch (ring) {\n#if defined (USE_PCI_INTB) || defined(USE_PCI_INTC) || defined(USE_PCI_INTD)\n#ifdef USE_PCI_INTB\n\t\tcase 1:\n#endif\n#ifdef USE_PCI_INTC\n\t\tcase 2:\n#endif\n#ifdef USE_PCI_INTD\n\t\tcase 3:\n#endif\n\t\t\twritel(INTRN_MASK_RX_EN, cp->regs +\n\t\t\t       REG_PLUS_INTRN_MASK(ring));\n\t\t\tbreak;\n#endif\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n}\n\nstatic inline void cas_unmask_intr(struct cas *cp)\n{\n\tint i;\n\n\tfor (i = 0; i < N_RX_COMP_RINGS; i++)\n\t\tcas_enable_irq(cp, i);\n}\n\nstatic inline void cas_entropy_gather(struct cas *cp)\n{\n#ifdef USE_ENTROPY_DEV\n\tif ((cp->cas_flags & CAS_FLAG_ENTROPY_DEV) == 0)\n\t\treturn;\n\n\tbatch_entropy_store(readl(cp->regs + REG_ENTROPY_IV),\n\t\t\t    readl(cp->regs + REG_ENTROPY_IV),\n\t\t\t    sizeof(uint64_t)*8);\n#endif\n}\n\nstatic inline void cas_entropy_reset(struct cas *cp)\n{\n#ifdef USE_ENTROPY_DEV\n\tif ((cp->cas_flags & CAS_FLAG_ENTROPY_DEV) == 0)\n\t\treturn;\n\n\twritel(BIM_LOCAL_DEV_PAD | BIM_LOCAL_DEV_PROM | BIM_LOCAL_DEV_EXT,\n\t       cp->regs + REG_BIM_LOCAL_DEV_EN);\n\twriteb(ENTROPY_RESET_STC_MODE, cp->regs + REG_ENTROPY_RESET);\n\twriteb(0x55, cp->regs + REG_ENTROPY_RAND_REG);\n\n\t \n\tif (readb(cp->regs + REG_ENTROPY_RAND_REG) == 0)\n\t\tcp->cas_flags &= ~CAS_FLAG_ENTROPY_DEV;\n#endif\n}\n\n \nstatic u16 cas_phy_read(struct cas *cp, int reg)\n{\n\tu32 cmd;\n\tint limit = STOP_TRIES_PHY;\n\n\tcmd = MIF_FRAME_ST | MIF_FRAME_OP_READ;\n\tcmd |= CAS_BASE(MIF_FRAME_PHY_ADDR, cp->phy_addr);\n\tcmd |= CAS_BASE(MIF_FRAME_REG_ADDR, reg);\n\tcmd |= MIF_FRAME_TURN_AROUND_MSB;\n\twritel(cmd, cp->regs + REG_MIF_FRAME);\n\n\t \n\twhile (limit-- > 0) {\n\t\tudelay(10);\n\t\tcmd = readl(cp->regs + REG_MIF_FRAME);\n\t\tif (cmd & MIF_FRAME_TURN_AROUND_LSB)\n\t\t\treturn cmd & MIF_FRAME_DATA_MASK;\n\t}\n\treturn 0xFFFF;  \n}\n\nstatic int cas_phy_write(struct cas *cp, int reg, u16 val)\n{\n\tint limit = STOP_TRIES_PHY;\n\tu32 cmd;\n\n\tcmd = MIF_FRAME_ST | MIF_FRAME_OP_WRITE;\n\tcmd |= CAS_BASE(MIF_FRAME_PHY_ADDR, cp->phy_addr);\n\tcmd |= CAS_BASE(MIF_FRAME_REG_ADDR, reg);\n\tcmd |= MIF_FRAME_TURN_AROUND_MSB;\n\tcmd |= val & MIF_FRAME_DATA_MASK;\n\twritel(cmd, cp->regs + REG_MIF_FRAME);\n\n\t \n\twhile (limit-- > 0) {\n\t\tudelay(10);\n\t\tcmd = readl(cp->regs + REG_MIF_FRAME);\n\t\tif (cmd & MIF_FRAME_TURN_AROUND_LSB)\n\t\t\treturn 0;\n\t}\n\treturn -1;\n}\n\nstatic void cas_phy_powerup(struct cas *cp)\n{\n\tu16 ctl = cas_phy_read(cp, MII_BMCR);\n\n\tif ((ctl & BMCR_PDOWN) == 0)\n\t\treturn;\n\tctl &= ~BMCR_PDOWN;\n\tcas_phy_write(cp, MII_BMCR, ctl);\n}\n\nstatic void cas_phy_powerdown(struct cas *cp)\n{\n\tu16 ctl = cas_phy_read(cp, MII_BMCR);\n\n\tif (ctl & BMCR_PDOWN)\n\t\treturn;\n\tctl |= BMCR_PDOWN;\n\tcas_phy_write(cp, MII_BMCR, ctl);\n}\n\n \nstatic int cas_page_free(struct cas *cp, cas_page_t *page)\n{\n\tdma_unmap_page(&cp->pdev->dev, page->dma_addr, cp->page_size,\n\t\t       DMA_FROM_DEVICE);\n\t__free_pages(page->buffer, cp->page_order);\n\tkfree(page);\n\treturn 0;\n}\n\n#ifdef RX_COUNT_BUFFERS\n#define RX_USED_ADD(x, y)       ((x)->used += (y))\n#define RX_USED_SET(x, y)       ((x)->used  = (y))\n#else\n#define RX_USED_ADD(x, y) do { } while(0)\n#define RX_USED_SET(x, y) do { } while(0)\n#endif\n\n \nstatic cas_page_t *cas_page_alloc(struct cas *cp, const gfp_t flags)\n{\n\tcas_page_t *page;\n\n\tpage = kmalloc(sizeof(cas_page_t), flags);\n\tif (!page)\n\t\treturn NULL;\n\n\tINIT_LIST_HEAD(&page->list);\n\tRX_USED_SET(page, 0);\n\tpage->buffer = alloc_pages(flags, cp->page_order);\n\tif (!page->buffer)\n\t\tgoto page_err;\n\tpage->dma_addr = dma_map_page(&cp->pdev->dev, page->buffer, 0,\n\t\t\t\t      cp->page_size, DMA_FROM_DEVICE);\n\treturn page;\n\npage_err:\n\tkfree(page);\n\treturn NULL;\n}\n\n \nstatic void cas_spare_init(struct cas *cp)\n{\n\tspin_lock(&cp->rx_inuse_lock);\n\tINIT_LIST_HEAD(&cp->rx_inuse_list);\n\tspin_unlock(&cp->rx_inuse_lock);\n\n\tspin_lock(&cp->rx_spare_lock);\n\tINIT_LIST_HEAD(&cp->rx_spare_list);\n\tcp->rx_spares_needed = RX_SPARE_COUNT;\n\tspin_unlock(&cp->rx_spare_lock);\n}\n\n \nstatic void cas_spare_free(struct cas *cp)\n{\n\tstruct list_head list, *elem, *tmp;\n\n\t \n\tINIT_LIST_HEAD(&list);\n\tspin_lock(&cp->rx_spare_lock);\n\tlist_splice_init(&cp->rx_spare_list, &list);\n\tspin_unlock(&cp->rx_spare_lock);\n\tlist_for_each_safe(elem, tmp, &list) {\n\t\tcas_page_free(cp, list_entry(elem, cas_page_t, list));\n\t}\n\n\tINIT_LIST_HEAD(&list);\n#if 1\n\t \n\tspin_lock(&cp->rx_inuse_lock);\n\tlist_splice_init(&cp->rx_inuse_list, &list);\n\tspin_unlock(&cp->rx_inuse_lock);\n#else\n\tspin_lock(&cp->rx_spare_lock);\n\tlist_splice_init(&cp->rx_inuse_list, &list);\n\tspin_unlock(&cp->rx_spare_lock);\n#endif\n\tlist_for_each_safe(elem, tmp, &list) {\n\t\tcas_page_free(cp, list_entry(elem, cas_page_t, list));\n\t}\n}\n\n \nstatic void cas_spare_recover(struct cas *cp, const gfp_t flags)\n{\n\tstruct list_head list, *elem, *tmp;\n\tint needed, i;\n\n\t \n\n\t \n\tINIT_LIST_HEAD(&list);\n\tspin_lock(&cp->rx_inuse_lock);\n\tlist_splice_init(&cp->rx_inuse_list, &list);\n\tspin_unlock(&cp->rx_inuse_lock);\n\n\tlist_for_each_safe(elem, tmp, &list) {\n\t\tcas_page_t *page = list_entry(elem, cas_page_t, list);\n\n\t\t \n\t\tif (page_count(page->buffer) > 1)\n\t\t\tcontinue;\n\n\t\tlist_del(elem);\n\t\tspin_lock(&cp->rx_spare_lock);\n\t\tif (cp->rx_spares_needed > 0) {\n\t\t\tlist_add(elem, &cp->rx_spare_list);\n\t\t\tcp->rx_spares_needed--;\n\t\t\tspin_unlock(&cp->rx_spare_lock);\n\t\t} else {\n\t\t\tspin_unlock(&cp->rx_spare_lock);\n\t\t\tcas_page_free(cp, page);\n\t\t}\n\t}\n\n\t \n\tif (!list_empty(&list)) {\n\t\tspin_lock(&cp->rx_inuse_lock);\n\t\tlist_splice(&list, &cp->rx_inuse_list);\n\t\tspin_unlock(&cp->rx_inuse_lock);\n\t}\n\n\tspin_lock(&cp->rx_spare_lock);\n\tneeded = cp->rx_spares_needed;\n\tspin_unlock(&cp->rx_spare_lock);\n\tif (!needed)\n\t\treturn;\n\n\t \n\tINIT_LIST_HEAD(&list);\n\ti = 0;\n\twhile (i < needed) {\n\t\tcas_page_t *spare = cas_page_alloc(cp, flags);\n\t\tif (!spare)\n\t\t\tbreak;\n\t\tlist_add(&spare->list, &list);\n\t\ti++;\n\t}\n\n\tspin_lock(&cp->rx_spare_lock);\n\tlist_splice(&list, &cp->rx_spare_list);\n\tcp->rx_spares_needed -= i;\n\tspin_unlock(&cp->rx_spare_lock);\n}\n\n \nstatic cas_page_t *cas_page_dequeue(struct cas *cp)\n{\n\tstruct list_head *entry;\n\tint recover;\n\n\tspin_lock(&cp->rx_spare_lock);\n\tif (list_empty(&cp->rx_spare_list)) {\n\t\t \n\t\tspin_unlock(&cp->rx_spare_lock);\n\t\tcas_spare_recover(cp, GFP_ATOMIC);\n\t\tspin_lock(&cp->rx_spare_lock);\n\t\tif (list_empty(&cp->rx_spare_list)) {\n\t\t\tnetif_err(cp, rx_err, cp->dev,\n\t\t\t\t  \"no spare buffers available\\n\");\n\t\t\tspin_unlock(&cp->rx_spare_lock);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tentry = cp->rx_spare_list.next;\n\tlist_del(entry);\n\trecover = ++cp->rx_spares_needed;\n\tspin_unlock(&cp->rx_spare_lock);\n\n\t \n\tif ((recover & (RX_SPARE_RECOVER_VAL - 1)) == 0) {\n#if 1\n\t\tatomic_inc(&cp->reset_task_pending);\n\t\tatomic_inc(&cp->reset_task_pending_spare);\n\t\tschedule_work(&cp->reset_task);\n#else\n\t\tatomic_set(&cp->reset_task_pending, CAS_RESET_SPARE);\n\t\tschedule_work(&cp->reset_task);\n#endif\n\t}\n\treturn list_entry(entry, cas_page_t, list);\n}\n\n\nstatic void cas_mif_poll(struct cas *cp, const int enable)\n{\n\tu32 cfg;\n\n\tcfg  = readl(cp->regs + REG_MIF_CFG);\n\tcfg &= (MIF_CFG_MDIO_0 | MIF_CFG_MDIO_1);\n\n\tif (cp->phy_type & CAS_PHY_MII_MDIO1)\n\t\tcfg |= MIF_CFG_PHY_SELECT;\n\n\t \n\tif (enable) {\n\t\tcfg |= MIF_CFG_POLL_EN;\n\t\tcfg |= CAS_BASE(MIF_CFG_POLL_REG, MII_BMSR);\n\t\tcfg |= CAS_BASE(MIF_CFG_POLL_PHY, cp->phy_addr);\n\t}\n\twritel((enable) ? ~(BMSR_LSTATUS | BMSR_ANEGCOMPLETE) : 0xFFFF,\n\t       cp->regs + REG_MIF_MASK);\n\twritel(cfg, cp->regs + REG_MIF_CFG);\n}\n\n \nstatic void cas_begin_auto_negotiation(struct cas *cp,\n\t\t\t\t       const struct ethtool_link_ksettings *ep)\n{\n\tu16 ctl;\n#if 1\n\tint lcntl;\n\tint changed = 0;\n\tint oldstate = cp->lstate;\n\tint link_was_not_down = !(oldstate == link_down);\n#endif\n\t \n\tif (!ep)\n\t\tgoto start_aneg;\n\tlcntl = cp->link_cntl;\n\tif (ep->base.autoneg == AUTONEG_ENABLE) {\n\t\tcp->link_cntl = BMCR_ANENABLE;\n\t} else {\n\t\tu32 speed = ep->base.speed;\n\t\tcp->link_cntl = 0;\n\t\tif (speed == SPEED_100)\n\t\t\tcp->link_cntl |= BMCR_SPEED100;\n\t\telse if (speed == SPEED_1000)\n\t\t\tcp->link_cntl |= CAS_BMCR_SPEED1000;\n\t\tif (ep->base.duplex == DUPLEX_FULL)\n\t\t\tcp->link_cntl |= BMCR_FULLDPLX;\n\t}\n#if 1\n\tchanged = (lcntl != cp->link_cntl);\n#endif\nstart_aneg:\n\tif (cp->lstate == link_up) {\n\t\tnetdev_info(cp->dev, \"PCS link down\\n\");\n\t} else {\n\t\tif (changed) {\n\t\t\tnetdev_info(cp->dev, \"link configuration changed\\n\");\n\t\t}\n\t}\n\tcp->lstate = link_down;\n\tcp->link_transition = LINK_TRANSITION_LINK_DOWN;\n\tif (!cp->hw_running)\n\t\treturn;\n#if 1\n\t \n\tif (oldstate == link_up)\n\t\tnetif_carrier_off(cp->dev);\n\tif (changed  && link_was_not_down) {\n\t\t \n\t\tatomic_inc(&cp->reset_task_pending);\n\t\tatomic_inc(&cp->reset_task_pending_all);\n\t\tschedule_work(&cp->reset_task);\n\t\tcp->timer_ticks = 0;\n\t\tmod_timer(&cp->link_timer, jiffies + CAS_LINK_TIMEOUT);\n\t\treturn;\n\t}\n#endif\n\tif (cp->phy_type & CAS_PHY_SERDES) {\n\t\tu32 val = readl(cp->regs + REG_PCS_MII_CTRL);\n\n\t\tif (cp->link_cntl & BMCR_ANENABLE) {\n\t\t\tval |= (PCS_MII_RESTART_AUTONEG | PCS_MII_AUTONEG_EN);\n\t\t\tcp->lstate = link_aneg;\n\t\t} else {\n\t\t\tif (cp->link_cntl & BMCR_FULLDPLX)\n\t\t\t\tval |= PCS_MII_CTRL_DUPLEX;\n\t\t\tval &= ~PCS_MII_AUTONEG_EN;\n\t\t\tcp->lstate = link_force_ok;\n\t\t}\n\t\tcp->link_transition = LINK_TRANSITION_LINK_CONFIG;\n\t\twritel(val, cp->regs + REG_PCS_MII_CTRL);\n\n\t} else {\n\t\tcas_mif_poll(cp, 0);\n\t\tctl = cas_phy_read(cp, MII_BMCR);\n\t\tctl &= ~(BMCR_FULLDPLX | BMCR_SPEED100 |\n\t\t\t CAS_BMCR_SPEED1000 | BMCR_ANENABLE);\n\t\tctl |= cp->link_cntl;\n\t\tif (ctl & BMCR_ANENABLE) {\n\t\t\tctl |= BMCR_ANRESTART;\n\t\t\tcp->lstate = link_aneg;\n\t\t} else {\n\t\t\tcp->lstate = link_force_ok;\n\t\t}\n\t\tcp->link_transition = LINK_TRANSITION_LINK_CONFIG;\n\t\tcas_phy_write(cp, MII_BMCR, ctl);\n\t\tcas_mif_poll(cp, 1);\n\t}\n\n\tcp->timer_ticks = 0;\n\tmod_timer(&cp->link_timer, jiffies + CAS_LINK_TIMEOUT);\n}\n\n \nstatic int cas_reset_mii_phy(struct cas *cp)\n{\n\tint limit = STOP_TRIES_PHY;\n\tu16 val;\n\n\tcas_phy_write(cp, MII_BMCR, BMCR_RESET);\n\tudelay(100);\n\twhile (--limit) {\n\t\tval = cas_phy_read(cp, MII_BMCR);\n\t\tif ((val & BMCR_RESET) == 0)\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\treturn limit <= 0;\n}\n\nstatic void cas_saturn_firmware_init(struct cas *cp)\n{\n\tconst struct firmware *fw;\n\tconst char fw_name[] = \"sun/cassini.bin\";\n\tint err;\n\n\tif (PHY_NS_DP83065 != cp->phy_id)\n\t\treturn;\n\n\terr = request_firmware(&fw, fw_name, &cp->pdev->dev);\n\tif (err) {\n\t\tpr_err(\"Failed to load firmware \\\"%s\\\"\\n\",\n\t\t       fw_name);\n\t\treturn;\n\t}\n\tif (fw->size < 2) {\n\t\tpr_err(\"bogus length %zu in \\\"%s\\\"\\n\",\n\t\t       fw->size, fw_name);\n\t\tgoto out;\n\t}\n\tcp->fw_load_addr= fw->data[1] << 8 | fw->data[0];\n\tcp->fw_size = fw->size - 2;\n\tcp->fw_data = vmalloc(cp->fw_size);\n\tif (!cp->fw_data)\n\t\tgoto out;\n\tmemcpy(cp->fw_data, &fw->data[2], cp->fw_size);\nout:\n\trelease_firmware(fw);\n}\n\nstatic void cas_saturn_firmware_load(struct cas *cp)\n{\n\tint i;\n\n\tif (!cp->fw_data)\n\t\treturn;\n\n\tcas_phy_powerdown(cp);\n\n\t \n\tcas_phy_write(cp, DP83065_MII_MEM, 0x0);\n\n\t \n\tcas_phy_write(cp, DP83065_MII_REGE, 0x8ff9);\n\tcas_phy_write(cp, DP83065_MII_REGD, 0xbd);\n\tcas_phy_write(cp, DP83065_MII_REGE, 0x8ffa);\n\tcas_phy_write(cp, DP83065_MII_REGD, 0x82);\n\tcas_phy_write(cp, DP83065_MII_REGE, 0x8ffb);\n\tcas_phy_write(cp, DP83065_MII_REGD, 0x0);\n\tcas_phy_write(cp, DP83065_MII_REGE, 0x8ffc);\n\tcas_phy_write(cp, DP83065_MII_REGD, 0x39);\n\n\t \n\tcas_phy_write(cp, DP83065_MII_MEM, 0x1);\n\tcas_phy_write(cp, DP83065_MII_REGE, cp->fw_load_addr);\n\tfor (i = 0; i < cp->fw_size; i++)\n\t\tcas_phy_write(cp, DP83065_MII_REGD, cp->fw_data[i]);\n\n\t \n\tcas_phy_write(cp, DP83065_MII_REGE, 0x8ff8);\n\tcas_phy_write(cp, DP83065_MII_REGD, 0x1);\n}\n\n\n \nstatic void cas_phy_init(struct cas *cp)\n{\n\tu16 val;\n\n\t \n\tif (CAS_PHY_MII(cp->phy_type)) {\n\t\twritel(PCS_DATAPATH_MODE_MII,\n\t\t       cp->regs + REG_PCS_DATAPATH_MODE);\n\n\t\tcas_mif_poll(cp, 0);\n\t\tcas_reset_mii_phy(cp);  \n\n\t\tif (PHY_LUCENT_B0 == cp->phy_id) {\n\t\t\t \n\t\t\tcas_phy_write(cp, LUCENT_MII_REG, 0x8000);\n\t\t\tcas_phy_write(cp, MII_BMCR, 0x00f1);\n\t\t\tcas_phy_write(cp, LUCENT_MII_REG, 0x0);\n\n\t\t} else if (PHY_BROADCOM_B0 == (cp->phy_id & 0xFFFFFFFC)) {\n\t\t\t \n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG8, 0x0C20);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG7, 0x0012);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG5, 0x1804);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG7, 0x0013);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG5, 0x1204);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG7, 0x8006);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG5, 0x0132);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG7, 0x8006);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG5, 0x0232);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG7, 0x201F);\n\t\t\tcas_phy_write(cp, BROADCOM_MII_REG5, 0x0A20);\n\n\t\t} else if (PHY_BROADCOM_5411 == cp->phy_id) {\n\t\t\tval = cas_phy_read(cp, BROADCOM_MII_REG4);\n\t\t\tval = cas_phy_read(cp, BROADCOM_MII_REG4);\n\t\t\tif (val & 0x0080) {\n\t\t\t\t \n\t\t\t\tcas_phy_write(cp, BROADCOM_MII_REG4,\n\t\t\t\t\t      val & ~0x0080);\n\t\t\t}\n\n\t\t} else if (cp->cas_flags & CAS_FLAG_SATURN) {\n\t\t\twritel((cp->phy_type & CAS_PHY_MII_MDIO0) ?\n\t\t\t       SATURN_PCFG_FSI : 0x0,\n\t\t\t       cp->regs + REG_SATURN_PCFG);\n\n\t\t\t \n\t\t\tif (PHY_NS_DP83065 == cp->phy_id) {\n\t\t\t\tcas_saturn_firmware_load(cp);\n\t\t\t}\n\t\t\tcas_phy_powerup(cp);\n\t\t}\n\n\t\t \n\t\tval = cas_phy_read(cp, MII_BMCR);\n\t\tval &= ~BMCR_ANENABLE;\n\t\tcas_phy_write(cp, MII_BMCR, val);\n\t\tudelay(10);\n\n\t\tcas_phy_write(cp, MII_ADVERTISE,\n\t\t\t      cas_phy_read(cp, MII_ADVERTISE) |\n\t\t\t      (ADVERTISE_10HALF | ADVERTISE_10FULL |\n\t\t\t       ADVERTISE_100HALF | ADVERTISE_100FULL |\n\t\t\t       CAS_ADVERTISE_PAUSE |\n\t\t\t       CAS_ADVERTISE_ASYM_PAUSE));\n\n\t\tif (cp->cas_flags & CAS_FLAG_1000MB_CAP) {\n\t\t\t \n\t\t\tval  = cas_phy_read(cp, CAS_MII_1000_CTRL);\n\t\t\tval &= ~CAS_ADVERTISE_1000HALF;\n\t\t\tval |= CAS_ADVERTISE_1000FULL;\n\t\t\tcas_phy_write(cp, CAS_MII_1000_CTRL, val);\n\t\t}\n\n\t} else {\n\t\t \n\t\tu32 val;\n\t\tint limit;\n\n\t\twritel(PCS_DATAPATH_MODE_SERDES,\n\t\t       cp->regs + REG_PCS_DATAPATH_MODE);\n\n\t\t \n\t\tif (cp->cas_flags & CAS_FLAG_SATURN)\n\t\t\twritel(0, cp->regs + REG_SATURN_PCFG);\n\n\t\t \n\t\tval = readl(cp->regs + REG_PCS_MII_CTRL);\n\t\tval |= PCS_MII_RESET;\n\t\twritel(val, cp->regs + REG_PCS_MII_CTRL);\n\n\t\tlimit = STOP_TRIES;\n\t\twhile (--limit > 0) {\n\t\t\tudelay(10);\n\t\t\tif ((readl(cp->regs + REG_PCS_MII_CTRL) &\n\t\t\t     PCS_MII_RESET) == 0)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (limit <= 0)\n\t\t\tnetdev_warn(cp->dev, \"PCS reset bit would not clear [%08x]\\n\",\n\t\t\t\t    readl(cp->regs + REG_PCS_STATE_MACHINE));\n\n\t\t \n\t\twritel(0x0, cp->regs + REG_PCS_CFG);\n\n\t\t \n\t\tval  = readl(cp->regs + REG_PCS_MII_ADVERT);\n\t\tval &= ~PCS_MII_ADVERT_HD;\n\t\tval |= (PCS_MII_ADVERT_FD | PCS_MII_ADVERT_SYM_PAUSE |\n\t\t\tPCS_MII_ADVERT_ASYM_PAUSE);\n\t\twritel(val, cp->regs + REG_PCS_MII_ADVERT);\n\n\t\t \n\t\twritel(PCS_CFG_EN, cp->regs + REG_PCS_CFG);\n\n\t\t \n\t\twritel(PCS_SERDES_CTRL_SYNCD_EN,\n\t\t       cp->regs + REG_PCS_SERDES_CTRL);\n\t}\n}\n\n\nstatic int cas_pcs_link_check(struct cas *cp)\n{\n\tu32 stat, state_machine;\n\tint retval = 0;\n\n\t \n\tstat = readl(cp->regs + REG_PCS_MII_STATUS);\n\tif ((stat & PCS_MII_STATUS_LINK_STATUS) == 0)\n\t\tstat = readl(cp->regs + REG_PCS_MII_STATUS);\n\n\t \n\tif ((stat & (PCS_MII_STATUS_AUTONEG_COMP |\n\t\t     PCS_MII_STATUS_REMOTE_FAULT)) ==\n\t    (PCS_MII_STATUS_AUTONEG_COMP | PCS_MII_STATUS_REMOTE_FAULT))\n\t\tnetif_info(cp, link, cp->dev, \"PCS RemoteFault\\n\");\n\n\t \n\tstate_machine = readl(cp->regs + REG_PCS_STATE_MACHINE);\n\tif ((state_machine & PCS_SM_LINK_STATE_MASK) != SM_LINK_STATE_UP) {\n\t\tstat &= ~PCS_MII_STATUS_LINK_STATUS;\n\t} else if (state_machine & PCS_SM_WORD_SYNC_STATE_MASK) {\n\t\tstat |= PCS_MII_STATUS_LINK_STATUS;\n\t}\n\n\tif (stat & PCS_MII_STATUS_LINK_STATUS) {\n\t\tif (cp->lstate != link_up) {\n\t\t\tif (cp->opened) {\n\t\t\t\tcp->lstate = link_up;\n\t\t\t\tcp->link_transition = LINK_TRANSITION_LINK_UP;\n\n\t\t\t\tcas_set_link_modes(cp);\n\t\t\t\tnetif_carrier_on(cp->dev);\n\t\t\t}\n\t\t}\n\t} else if (cp->lstate == link_up) {\n\t\tcp->lstate = link_down;\n\t\tif (link_transition_timeout != 0 &&\n\t\t    cp->link_transition != LINK_TRANSITION_REQUESTED_RESET &&\n\t\t    !cp->link_transition_jiffies_valid) {\n\t\t\t \n\t\t\tretval = 1;\n\t\t\tcp->link_transition = LINK_TRANSITION_REQUESTED_RESET;\n\t\t\tcp->link_transition_jiffies = jiffies;\n\t\t\tcp->link_transition_jiffies_valid = 1;\n\t\t} else {\n\t\t\tcp->link_transition = LINK_TRANSITION_ON_FAILURE;\n\t\t}\n\t\tnetif_carrier_off(cp->dev);\n\t\tif (cp->opened)\n\t\t\tnetif_info(cp, link, cp->dev, \"PCS link down\\n\");\n\n\t\t \n\t\tif ((cp->cas_flags & CAS_FLAG_REG_PLUS) == 0) {\n\t\t\t \n\t\t\tstat = readl(cp->regs + REG_PCS_SERDES_STATE);\n\t\t\tif (stat == 0x03)\n\t\t\t\treturn 1;\n\t\t}\n\t} else if (cp->lstate == link_down) {\n\t\tif (link_transition_timeout != 0 &&\n\t\t    cp->link_transition != LINK_TRANSITION_REQUESTED_RESET &&\n\t\t    !cp->link_transition_jiffies_valid) {\n\t\t\t \n\t\t\tretval = 1;\n\t\t\tcp->link_transition = LINK_TRANSITION_REQUESTED_RESET;\n\t\t\tcp->link_transition_jiffies = jiffies;\n\t\t\tcp->link_transition_jiffies_valid = 1;\n\t\t} else {\n\t\t\tcp->link_transition = LINK_TRANSITION_STILL_FAILED;\n\t\t}\n\t}\n\n\treturn retval;\n}\n\nstatic int cas_pcs_interrupt(struct net_device *dev,\n\t\t\t     struct cas *cp, u32 status)\n{\n\tu32 stat = readl(cp->regs + REG_PCS_INTR_STATUS);\n\n\tif ((stat & PCS_INTR_STATUS_LINK_CHANGE) == 0)\n\t\treturn 0;\n\treturn cas_pcs_link_check(cp);\n}\n\nstatic int cas_txmac_interrupt(struct net_device *dev,\n\t\t\t       struct cas *cp, u32 status)\n{\n\tu32 txmac_stat = readl(cp->regs + REG_MAC_TX_STATUS);\n\n\tif (!txmac_stat)\n\t\treturn 0;\n\n\tnetif_printk(cp, intr, KERN_DEBUG, cp->dev,\n\t\t     \"txmac interrupt, txmac_stat: 0x%x\\n\", txmac_stat);\n\n\t \n\tif ((txmac_stat & MAC_TX_DEFER_TIMER) &&\n\t    !(txmac_stat & ~MAC_TX_DEFER_TIMER))\n\t\treturn 0;\n\n\tspin_lock(&cp->stat_lock[0]);\n\tif (txmac_stat & MAC_TX_UNDERRUN) {\n\t\tnetdev_err(dev, \"TX MAC xmit underrun\\n\");\n\t\tcp->net_stats[0].tx_fifo_errors++;\n\t}\n\n\tif (txmac_stat & MAC_TX_MAX_PACKET_ERR) {\n\t\tnetdev_err(dev, \"TX MAC max packet size error\\n\");\n\t\tcp->net_stats[0].tx_errors++;\n\t}\n\n\t \n\tif (txmac_stat & MAC_TX_COLL_NORMAL)\n\t\tcp->net_stats[0].collisions += 0x10000;\n\n\tif (txmac_stat & MAC_TX_COLL_EXCESS) {\n\t\tcp->net_stats[0].tx_aborted_errors += 0x10000;\n\t\tcp->net_stats[0].collisions += 0x10000;\n\t}\n\n\tif (txmac_stat & MAC_TX_COLL_LATE) {\n\t\tcp->net_stats[0].tx_aborted_errors += 0x10000;\n\t\tcp->net_stats[0].collisions += 0x10000;\n\t}\n\tspin_unlock(&cp->stat_lock[0]);\n\n\t \n\treturn 0;\n}\n\nstatic void cas_load_firmware(struct cas *cp, cas_hp_inst_t *firmware)\n{\n\tcas_hp_inst_t *inst;\n\tu32 val;\n\tint i;\n\n\ti = 0;\n\twhile ((inst = firmware) && inst->note) {\n\t\twritel(i, cp->regs + REG_HP_INSTR_RAM_ADDR);\n\n\t\tval = CAS_BASE(HP_INSTR_RAM_HI_VAL, inst->val);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_HI_MASK, inst->mask);\n\t\twritel(val, cp->regs + REG_HP_INSTR_RAM_DATA_HI);\n\n\t\tval = CAS_BASE(HP_INSTR_RAM_MID_OUTARG, inst->outarg >> 10);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_MID_OUTOP, inst->outop);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_MID_FNEXT, inst->fnext);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_MID_FOFF, inst->foff);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_MID_SNEXT, inst->snext);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_MID_SOFF, inst->soff);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_MID_OP, inst->op);\n\t\twritel(val, cp->regs + REG_HP_INSTR_RAM_DATA_MID);\n\n\t\tval = CAS_BASE(HP_INSTR_RAM_LOW_OUTMASK, inst->outmask);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_LOW_OUTSHIFT, inst->outshift);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_LOW_OUTEN, inst->outenab);\n\t\tval |= CAS_BASE(HP_INSTR_RAM_LOW_OUTARG, inst->outarg);\n\t\twritel(val, cp->regs + REG_HP_INSTR_RAM_DATA_LOW);\n\t\t++firmware;\n\t\t++i;\n\t}\n}\n\nstatic void cas_init_rx_dma(struct cas *cp)\n{\n\tu64 desc_dma = cp->block_dvma;\n\tu32 val;\n\tint i, size;\n\n\t \n\tval = CAS_BASE(RX_CFG_SWIVEL, RX_SWIVEL_OFF_VAL);\n\tval |= CAS_BASE(RX_CFG_DESC_RING, RX_DESC_RINGN_INDEX(0));\n\tval |= CAS_BASE(RX_CFG_COMP_RING, RX_COMP_RINGN_INDEX(0));\n\tif ((N_RX_DESC_RINGS > 1) &&\n\t    (cp->cas_flags & CAS_FLAG_REG_PLUS))   \n\t\tval |= CAS_BASE(RX_CFG_DESC_RING1, RX_DESC_RINGN_INDEX(1));\n\twritel(val, cp->regs + REG_RX_CFG);\n\n\tval = (unsigned long) cp->init_rxds[0] -\n\t\t(unsigned long) cp->init_block;\n\twritel((desc_dma + val) >> 32, cp->regs + REG_RX_DB_HI);\n\twritel((desc_dma + val) & 0xffffffff, cp->regs + REG_RX_DB_LOW);\n\twritel(RX_DESC_RINGN_SIZE(0) - 4, cp->regs + REG_RX_KICK);\n\n\tif (cp->cas_flags & CAS_FLAG_REG_PLUS) {\n\t\t \n\t\tval = (unsigned long) cp->init_rxds[1] -\n\t\t\t(unsigned long) cp->init_block;\n\t\twritel((desc_dma + val) >> 32, cp->regs + REG_PLUS_RX_DB1_HI);\n\t\twritel((desc_dma + val) & 0xffffffff, cp->regs +\n\t\t       REG_PLUS_RX_DB1_LOW);\n\t\twritel(RX_DESC_RINGN_SIZE(1) - 4, cp->regs +\n\t\t       REG_PLUS_RX_KICK1);\n\t}\n\n\t \n\tval = (unsigned long) cp->init_rxcs[0] -\n\t\t(unsigned long) cp->init_block;\n\twritel((desc_dma + val) >> 32, cp->regs + REG_RX_CB_HI);\n\twritel((desc_dma + val) & 0xffffffff, cp->regs + REG_RX_CB_LOW);\n\n\tif (cp->cas_flags & CAS_FLAG_REG_PLUS) {\n\t\t \n\t\tfor (i = 1; i < MAX_RX_COMP_RINGS; i++) {\n\t\t\tval = (unsigned long) cp->init_rxcs[i] -\n\t\t\t\t(unsigned long) cp->init_block;\n\t\t\twritel((desc_dma + val) >> 32, cp->regs +\n\t\t\t       REG_PLUS_RX_CBN_HI(i));\n\t\t\twritel((desc_dma + val) & 0xffffffff, cp->regs +\n\t\t\t       REG_PLUS_RX_CBN_LOW(i));\n\t\t}\n\t}\n\n\t \n\treadl(cp->regs + REG_INTR_STATUS_ALIAS);\n\twritel(INTR_RX_DONE | INTR_RX_BUF_UNAVAIL, cp->regs + REG_ALIAS_CLEAR);\n\n\t \n\tval  = CAS_BASE(RX_PAUSE_THRESH_OFF,\n\t\t\tcp->rx_pause_off / RX_PAUSE_THRESH_QUANTUM);\n\tval |= CAS_BASE(RX_PAUSE_THRESH_ON,\n\t\t\tcp->rx_pause_on / RX_PAUSE_THRESH_QUANTUM);\n\twritel(val, cp->regs + REG_RX_PAUSE_THRESH);\n\n\t \n\tfor (i = 0; i < 64; i++) {\n\t\twritel(i, cp->regs + REG_RX_TABLE_ADDR);\n\t\twritel(0x0, cp->regs + REG_RX_TABLE_DATA_LOW);\n\t\twritel(0x0, cp->regs + REG_RX_TABLE_DATA_MID);\n\t\twritel(0x0, cp->regs + REG_RX_TABLE_DATA_HI);\n\t}\n\n\t \n\twritel(0x0, cp->regs + REG_RX_CTRL_FIFO_ADDR);\n\twritel(0x0, cp->regs + REG_RX_IPP_FIFO_ADDR);\n\n\t \n#ifdef USE_RX_BLANK\n\tval = CAS_BASE(RX_BLANK_INTR_TIME, RX_BLANK_INTR_TIME_VAL);\n\tval |= CAS_BASE(RX_BLANK_INTR_PKT, RX_BLANK_INTR_PKT_VAL);\n\twritel(val, cp->regs + REG_RX_BLANK);\n#else\n\twritel(0x0, cp->regs + REG_RX_BLANK);\n#endif\n\n\t \n\t \n\tval = CAS_BASE(RX_AE_THRESH_COMP, RX_AE_COMP_VAL);\n\twritel(val, cp->regs + REG_RX_AE_THRESH);\n\tif (cp->cas_flags & CAS_FLAG_REG_PLUS) {\n\t\tval = CAS_BASE(RX_AE1_THRESH_FREE, RX_AE_FREEN_VAL(1));\n\t\twritel(val, cp->regs + REG_PLUS_RX_AE1_THRESH);\n\t}\n\n\t \n\twritel(0x0, cp->regs + REG_RX_RED);\n\n\t \n\tval = 0;\n\tif (cp->page_size == 0x1000)\n\t\tval = 0x1;\n\telse if (cp->page_size == 0x2000)\n\t\tval = 0x2;\n\telse if (cp->page_size == 0x4000)\n\t\tval = 0x3;\n\n\t \n\tsize = cp->dev->mtu + 64;\n\tif (size > cp->page_size)\n\t\tsize = cp->page_size;\n\n\tif (size <= 0x400)\n\t\ti = 0x0;\n\telse if (size <= 0x800)\n\t\ti = 0x1;\n\telse if (size <= 0x1000)\n\t\ti = 0x2;\n\telse\n\t\ti = 0x3;\n\n\tcp->mtu_stride = 1 << (i + 10);\n\tval  = CAS_BASE(RX_PAGE_SIZE, val);\n\tval |= CAS_BASE(RX_PAGE_SIZE_MTU_STRIDE, i);\n\tval |= CAS_BASE(RX_PAGE_SIZE_MTU_COUNT, cp->page_size >> (i + 10));\n\tval |= CAS_BASE(RX_PAGE_SIZE_MTU_OFF, 0x1);\n\twritel(val, cp->regs + REG_RX_PAGE_SIZE);\n\n\t \n\tif (&CAS_HP_FIRMWARE[0] == &cas_prog_null[0])\n\t\treturn;\n\n\tval = CAS_BASE(HP_CFG_NUM_CPU, CAS_NCPUS > 63 ? 0 : CAS_NCPUS);\n\tval |= HP_CFG_PARSE_EN | HP_CFG_SYN_INC_MASK;\n\tval |= CAS_BASE(HP_CFG_TCP_THRESH, HP_TCP_THRESH_VAL);\n\twritel(val, cp->regs + REG_HP_CFG);\n}\n\nstatic inline void cas_rxc_init(struct cas_rx_comp *rxc)\n{\n\tmemset(rxc, 0, sizeof(*rxc));\n\trxc->word4 = cpu_to_le64(RX_COMP4_ZERO);\n}\n\n \nstatic inline cas_page_t *cas_page_spare(struct cas *cp, const int index)\n{\n\tcas_page_t *page = cp->rx_pages[1][index];\n\tcas_page_t *new;\n\n\tif (page_count(page->buffer) == 1)\n\t\treturn page;\n\n\tnew = cas_page_dequeue(cp);\n\tif (new) {\n\t\tspin_lock(&cp->rx_inuse_lock);\n\t\tlist_add(&page->list, &cp->rx_inuse_list);\n\t\tspin_unlock(&cp->rx_inuse_lock);\n\t}\n\treturn new;\n}\n\n \nstatic cas_page_t *cas_page_swap(struct cas *cp, const int ring,\n\t\t\t\t const int index)\n{\n\tcas_page_t **page0 = cp->rx_pages[0];\n\tcas_page_t **page1 = cp->rx_pages[1];\n\n\t \n\tif (page_count(page0[index]->buffer) > 1) {\n\t\tcas_page_t *new = cas_page_spare(cp, index);\n\t\tif (new) {\n\t\t\tpage1[index] = page0[index];\n\t\t\tpage0[index] = new;\n\t\t}\n\t}\n\tRX_USED_SET(page0[index], 0);\n\treturn page0[index];\n}\n\nstatic void cas_clean_rxds(struct cas *cp)\n{\n\t \n        struct cas_rx_desc *rxd = cp->init_rxds[0];\n\tint i, size;\n\n\t \n\tfor (i = 0; i < N_RX_FLOWS; i++) {\n\t\tstruct sk_buff *skb;\n\t\twhile ((skb = __skb_dequeue(&cp->rx_flows[i]))) {\n\t\t\tcas_skb_release(skb);\n\t\t}\n\t}\n\n\t \n\tsize = RX_DESC_RINGN_SIZE(0);\n\tfor (i = 0; i < size; i++) {\n\t\tcas_page_t *page = cas_page_swap(cp, 0, i);\n\t\trxd[i].buffer = cpu_to_le64(page->dma_addr);\n\t\trxd[i].index  = cpu_to_le64(CAS_BASE(RX_INDEX_NUM, i) |\n\t\t\t\t\t    CAS_BASE(RX_INDEX_RING, 0));\n\t}\n\n\tcp->rx_old[0]  = RX_DESC_RINGN_SIZE(0) - 4;\n\tcp->rx_last[0] = 0;\n\tcp->cas_flags &= ~CAS_FLAG_RXD_POST(0);\n}\n\nstatic void cas_clean_rxcs(struct cas *cp)\n{\n\tint i, j;\n\n\t \n\tmemset(cp->rx_cur, 0, sizeof(*cp->rx_cur)*N_RX_COMP_RINGS);\n\tmemset(cp->rx_new, 0, sizeof(*cp->rx_new)*N_RX_COMP_RINGS);\n\tfor (i = 0; i < N_RX_COMP_RINGS; i++) {\n\t\tstruct cas_rx_comp *rxc = cp->init_rxcs[i];\n\t\tfor (j = 0; j < RX_COMP_RINGN_SIZE(i); j++) {\n\t\t\tcas_rxc_init(rxc + j);\n\t\t}\n\t}\n}\n\n#if 0\n \nstatic int cas_rxmac_reset(struct cas *cp)\n{\n\tstruct net_device *dev = cp->dev;\n\tint limit;\n\tu32 val;\n\n\t \n\twritel(cp->mac_rx_cfg & ~MAC_RX_CFG_EN, cp->regs + REG_MAC_RX_CFG);\n\tfor (limit = 0; limit < STOP_TRIES; limit++) {\n\t\tif (!(readl(cp->regs + REG_MAC_RX_CFG) & MAC_RX_CFG_EN))\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\tif (limit == STOP_TRIES) {\n\t\tnetdev_err(dev, \"RX MAC will not disable, resetting whole chip\\n\");\n\t\treturn 1;\n\t}\n\n\t \n\twritel(0, cp->regs + REG_RX_CFG);\n\tfor (limit = 0; limit < STOP_TRIES; limit++) {\n\t\tif (!(readl(cp->regs + REG_RX_CFG) & RX_CFG_DMA_EN))\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\tif (limit == STOP_TRIES) {\n\t\tnetdev_err(dev, \"RX DMA will not disable, resetting whole chip\\n\");\n\t\treturn 1;\n\t}\n\n\tmdelay(5);\n\n\t \n\twritel(SW_RESET_RX, cp->regs + REG_SW_RESET);\n\tfor (limit = 0; limit < STOP_TRIES; limit++) {\n\t\tif (!(readl(cp->regs + REG_SW_RESET) & SW_RESET_RX))\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\tif (limit == STOP_TRIES) {\n\t\tnetdev_err(dev, \"RX reset command will not execute, resetting whole chip\\n\");\n\t\treturn 1;\n\t}\n\n\t \n\tcas_clean_rxds(cp);\n\tcas_clean_rxcs(cp);\n\n\t \n\tcas_init_rx_dma(cp);\n\n\t \n\tval = readl(cp->regs + REG_RX_CFG);\n\twritel(val | RX_CFG_DMA_EN, cp->regs + REG_RX_CFG);\n\twritel(MAC_RX_FRAME_RECV, cp->regs + REG_MAC_RX_MASK);\n\tval = readl(cp->regs + REG_MAC_RX_CFG);\n\twritel(val | MAC_RX_CFG_EN, cp->regs + REG_MAC_RX_CFG);\n\treturn 0;\n}\n#endif\n\nstatic int cas_rxmac_interrupt(struct net_device *dev, struct cas *cp,\n\t\t\t       u32 status)\n{\n\tu32 stat = readl(cp->regs + REG_MAC_RX_STATUS);\n\n\tif (!stat)\n\t\treturn 0;\n\n\tnetif_dbg(cp, intr, cp->dev, \"rxmac interrupt, stat: 0x%x\\n\", stat);\n\n\t \n\tspin_lock(&cp->stat_lock[0]);\n\tif (stat & MAC_RX_ALIGN_ERR)\n\t\tcp->net_stats[0].rx_frame_errors += 0x10000;\n\n\tif (stat & MAC_RX_CRC_ERR)\n\t\tcp->net_stats[0].rx_crc_errors += 0x10000;\n\n\tif (stat & MAC_RX_LEN_ERR)\n\t\tcp->net_stats[0].rx_length_errors += 0x10000;\n\n\tif (stat & MAC_RX_OVERFLOW) {\n\t\tcp->net_stats[0].rx_over_errors++;\n\t\tcp->net_stats[0].rx_fifo_errors++;\n\t}\n\n\t \n\tspin_unlock(&cp->stat_lock[0]);\n\treturn 0;\n}\n\nstatic int cas_mac_interrupt(struct net_device *dev, struct cas *cp,\n\t\t\t     u32 status)\n{\n\tu32 stat = readl(cp->regs + REG_MAC_CTRL_STATUS);\n\n\tif (!stat)\n\t\treturn 0;\n\n\tnetif_printk(cp, intr, KERN_DEBUG, cp->dev,\n\t\t     \"mac interrupt, stat: 0x%x\\n\", stat);\n\n\t \n\tif (stat & MAC_CTRL_PAUSE_STATE)\n\t\tcp->pause_entered++;\n\n\tif (stat & MAC_CTRL_PAUSE_RECEIVED)\n\t\tcp->pause_last_time_recvd = (stat >> 16);\n\n\treturn 0;\n}\n\n\n \nstatic inline int cas_mdio_link_not_up(struct cas *cp)\n{\n\tu16 val;\n\n\tswitch (cp->lstate) {\n\tcase link_force_ret:\n\t\tnetif_info(cp, link, cp->dev, \"Autoneg failed again, keeping forced mode\\n\");\n\t\tcas_phy_write(cp, MII_BMCR, cp->link_fcntl);\n\t\tcp->timer_ticks = 5;\n\t\tcp->lstate = link_force_ok;\n\t\tcp->link_transition = LINK_TRANSITION_LINK_CONFIG;\n\t\tbreak;\n\n\tcase link_aneg:\n\t\tval = cas_phy_read(cp, MII_BMCR);\n\n\t\t \n\t\tval &= ~(BMCR_ANRESTART | BMCR_ANENABLE);\n\t\tval |= BMCR_FULLDPLX;\n\t\tval |= (cp->cas_flags & CAS_FLAG_1000MB_CAP) ?\n\t\t\tCAS_BMCR_SPEED1000 : BMCR_SPEED100;\n\t\tcas_phy_write(cp, MII_BMCR, val);\n\t\tcp->timer_ticks = 5;\n\t\tcp->lstate = link_force_try;\n\t\tcp->link_transition = LINK_TRANSITION_LINK_CONFIG;\n\t\tbreak;\n\n\tcase link_force_try:\n\t\t \n\t\tval = cas_phy_read(cp, MII_BMCR);\n\t\tcp->timer_ticks = 5;\n\t\tif (val & CAS_BMCR_SPEED1000) {  \n\t\t\tval &= ~CAS_BMCR_SPEED1000;\n\t\t\tval |= (BMCR_SPEED100 | BMCR_FULLDPLX);\n\t\t\tcas_phy_write(cp, MII_BMCR, val);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (val & BMCR_SPEED100) {\n\t\t\tif (val & BMCR_FULLDPLX)  \n\t\t\t\tval &= ~BMCR_FULLDPLX;\n\t\t\telse {  \n\t\t\t\tval &= ~BMCR_SPEED100;\n\t\t\t}\n\t\t\tcas_phy_write(cp, MII_BMCR, val);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\n\n \nstatic int cas_mii_link_check(struct cas *cp, const u16 bmsr)\n{\n\tint restart;\n\n\tif (bmsr & BMSR_LSTATUS) {\n\t\t \n\t\tif ((cp->lstate == link_force_try) &&\n\t\t    (cp->link_cntl & BMCR_ANENABLE)) {\n\t\t\tcp->lstate = link_force_ret;\n\t\t\tcp->link_transition = LINK_TRANSITION_LINK_CONFIG;\n\t\t\tcas_mif_poll(cp, 0);\n\t\t\tcp->link_fcntl = cas_phy_read(cp, MII_BMCR);\n\t\t\tcp->timer_ticks = 5;\n\t\t\tif (cp->opened)\n\t\t\t\tnetif_info(cp, link, cp->dev,\n\t\t\t\t\t   \"Got link after fallback, retrying autoneg once...\\n\");\n\t\t\tcas_phy_write(cp, MII_BMCR,\n\t\t\t\t      cp->link_fcntl | BMCR_ANENABLE |\n\t\t\t\t      BMCR_ANRESTART);\n\t\t\tcas_mif_poll(cp, 1);\n\n\t\t} else if (cp->lstate != link_up) {\n\t\t\tcp->lstate = link_up;\n\t\t\tcp->link_transition = LINK_TRANSITION_LINK_UP;\n\n\t\t\tif (cp->opened) {\n\t\t\t\tcas_set_link_modes(cp);\n\t\t\t\tnetif_carrier_on(cp->dev);\n\t\t\t}\n\t\t}\n\t\treturn 0;\n\t}\n\n\t \n\trestart = 0;\n\tif (cp->lstate == link_up) {\n\t\tcp->lstate = link_down;\n\t\tcp->link_transition = LINK_TRANSITION_LINK_DOWN;\n\n\t\tnetif_carrier_off(cp->dev);\n\t\tif (cp->opened)\n\t\t\tnetif_info(cp, link, cp->dev, \"Link down\\n\");\n\t\trestart = 1;\n\n\t} else if (++cp->timer_ticks > 10)\n\t\tcas_mdio_link_not_up(cp);\n\n\treturn restart;\n}\n\nstatic int cas_mif_interrupt(struct net_device *dev, struct cas *cp,\n\t\t\t     u32 status)\n{\n\tu32 stat = readl(cp->regs + REG_MIF_STATUS);\n\tu16 bmsr;\n\n\t \n\tif (CAS_VAL(MIF_STATUS_POLL_STATUS, stat) == 0)\n\t\treturn 0;\n\n\tbmsr = CAS_VAL(MIF_STATUS_POLL_DATA, stat);\n\treturn cas_mii_link_check(cp, bmsr);\n}\n\nstatic int cas_pci_interrupt(struct net_device *dev, struct cas *cp,\n\t\t\t     u32 status)\n{\n\tu32 stat = readl(cp->regs + REG_PCI_ERR_STATUS);\n\n\tif (!stat)\n\t\treturn 0;\n\n\tnetdev_err(dev, \"PCI error [%04x:%04x]\",\n\t\t   stat, readl(cp->regs + REG_BIM_DIAG));\n\n\t \n\tif ((stat & PCI_ERR_BADACK) &&\n\t    ((cp->cas_flags & CAS_FLAG_REG_PLUS) == 0))\n\t\tpr_cont(\" <No ACK64# during ABS64 cycle>\");\n\n\tif (stat & PCI_ERR_DTRTO)\n\t\tpr_cont(\" <Delayed transaction timeout>\");\n\tif (stat & PCI_ERR_OTHER)\n\t\tpr_cont(\" <other>\");\n\tif (stat & PCI_ERR_BIM_DMA_WRITE)\n\t\tpr_cont(\" <BIM DMA 0 write req>\");\n\tif (stat & PCI_ERR_BIM_DMA_READ)\n\t\tpr_cont(\" <BIM DMA 0 read req>\");\n\tpr_cont(\"\\n\");\n\n\tif (stat & PCI_ERR_OTHER) {\n\t\tint pci_errs;\n\n\t\t \n\t\tpci_errs = pci_status_get_and_clear_errors(cp->pdev);\n\n\t\tnetdev_err(dev, \"PCI status errors[%04x]\\n\", pci_errs);\n\t\tif (pci_errs & PCI_STATUS_PARITY)\n\t\t\tnetdev_err(dev, \"PCI parity error detected\\n\");\n\t\tif (pci_errs & PCI_STATUS_SIG_TARGET_ABORT)\n\t\t\tnetdev_err(dev, \"PCI target abort\\n\");\n\t\tif (pci_errs & PCI_STATUS_REC_TARGET_ABORT)\n\t\t\tnetdev_err(dev, \"PCI master acks target abort\\n\");\n\t\tif (pci_errs & PCI_STATUS_REC_MASTER_ABORT)\n\t\t\tnetdev_err(dev, \"PCI master abort\\n\");\n\t\tif (pci_errs & PCI_STATUS_SIG_SYSTEM_ERROR)\n\t\t\tnetdev_err(dev, \"PCI system error SERR#\\n\");\n\t\tif (pci_errs & PCI_STATUS_DETECTED_PARITY)\n\t\t\tnetdev_err(dev, \"PCI parity error\\n\");\n\t}\n\n\t \n\treturn 1;\n}\n\n \nstatic int cas_abnormal_irq(struct net_device *dev, struct cas *cp,\n\t\t\t    u32 status)\n{\n\tif (status & INTR_RX_TAG_ERROR) {\n\t\t \n\t\tnetif_printk(cp, rx_err, KERN_DEBUG, cp->dev,\n\t\t\t     \"corrupt rx tag framing\\n\");\n\t\tspin_lock(&cp->stat_lock[0]);\n\t\tcp->net_stats[0].rx_errors++;\n\t\tspin_unlock(&cp->stat_lock[0]);\n\t\tgoto do_reset;\n\t}\n\n\tif (status & INTR_RX_LEN_MISMATCH) {\n\t\t \n\t\tnetif_printk(cp, rx_err, KERN_DEBUG, cp->dev,\n\t\t\t     \"length mismatch for rx frame\\n\");\n\t\tspin_lock(&cp->stat_lock[0]);\n\t\tcp->net_stats[0].rx_errors++;\n\t\tspin_unlock(&cp->stat_lock[0]);\n\t\tgoto do_reset;\n\t}\n\n\tif (status & INTR_PCS_STATUS) {\n\t\tif (cas_pcs_interrupt(dev, cp, status))\n\t\t\tgoto do_reset;\n\t}\n\n\tif (status & INTR_TX_MAC_STATUS) {\n\t\tif (cas_txmac_interrupt(dev, cp, status))\n\t\t\tgoto do_reset;\n\t}\n\n\tif (status & INTR_RX_MAC_STATUS) {\n\t\tif (cas_rxmac_interrupt(dev, cp, status))\n\t\t\tgoto do_reset;\n\t}\n\n\tif (status & INTR_MAC_CTRL_STATUS) {\n\t\tif (cas_mac_interrupt(dev, cp, status))\n\t\t\tgoto do_reset;\n\t}\n\n\tif (status & INTR_MIF_STATUS) {\n\t\tif (cas_mif_interrupt(dev, cp, status))\n\t\t\tgoto do_reset;\n\t}\n\n\tif (status & INTR_PCI_ERROR_STATUS) {\n\t\tif (cas_pci_interrupt(dev, cp, status))\n\t\t\tgoto do_reset;\n\t}\n\treturn 0;\n\ndo_reset:\n#if 1\n\tatomic_inc(&cp->reset_task_pending);\n\tatomic_inc(&cp->reset_task_pending_all);\n\tnetdev_err(dev, \"reset called in cas_abnormal_irq [0x%x]\\n\", status);\n\tschedule_work(&cp->reset_task);\n#else\n\tatomic_set(&cp->reset_task_pending, CAS_RESET_ALL);\n\tnetdev_err(dev, \"reset called in cas_abnormal_irq\\n\");\n\tschedule_work(&cp->reset_task);\n#endif\n\treturn 1;\n}\n\n \n#define CAS_TABORT(x)      (((x)->cas_flags & CAS_FLAG_TARGET_ABORT) ? 2 : 1)\n#define CAS_ROUND_PAGE(x)  (((x) + PAGE_SIZE - 1) & PAGE_MASK)\nstatic inline int cas_calc_tabort(struct cas *cp, const unsigned long addr,\n\t\t\t\t  const int len)\n{\n\tunsigned long off = addr + len;\n\n\tif (CAS_TABORT(cp) == 1)\n\t\treturn 0;\n\tif ((CAS_ROUND_PAGE(off) - off) > TX_TARGET_ABORT_LEN)\n\t\treturn 0;\n\treturn TX_TARGET_ABORT_LEN;\n}\n\nstatic inline void cas_tx_ringN(struct cas *cp, int ring, int limit)\n{\n\tstruct cas_tx_desc *txds;\n\tstruct sk_buff **skbs;\n\tstruct net_device *dev = cp->dev;\n\tint entry, count;\n\n\tspin_lock(&cp->tx_lock[ring]);\n\ttxds = cp->init_txds[ring];\n\tskbs = cp->tx_skbs[ring];\n\tentry = cp->tx_old[ring];\n\n\tcount = TX_BUFF_COUNT(ring, entry, limit);\n\twhile (entry != limit) {\n\t\tstruct sk_buff *skb = skbs[entry];\n\t\tdma_addr_t daddr;\n\t\tu32 dlen;\n\t\tint frag;\n\n\t\tif (!skb) {\n\t\t\t \n\t\t\tentry = TX_DESC_NEXT(ring, entry);\n\t\t\tcontinue;\n\t\t}\n\n\t\t \n\t\tcount -= skb_shinfo(skb)->nr_frags +\n\t\t\t+ cp->tx_tiny_use[ring][entry].nbufs + 1;\n\t\tif (count < 0)\n\t\t\tbreak;\n\n\t\tnetif_printk(cp, tx_done, KERN_DEBUG, cp->dev,\n\t\t\t     \"tx[%d] done, slot %d\\n\", ring, entry);\n\n\t\tskbs[entry] = NULL;\n\t\tcp->tx_tiny_use[ring][entry].nbufs = 0;\n\n\t\tfor (frag = 0; frag <= skb_shinfo(skb)->nr_frags; frag++) {\n\t\t\tstruct cas_tx_desc *txd = txds + entry;\n\n\t\t\tdaddr = le64_to_cpu(txd->buffer);\n\t\t\tdlen = CAS_VAL(TX_DESC_BUFLEN,\n\t\t\t\t       le64_to_cpu(txd->control));\n\t\t\tdma_unmap_page(&cp->pdev->dev, daddr, dlen,\n\t\t\t\t       DMA_TO_DEVICE);\n\t\t\tentry = TX_DESC_NEXT(ring, entry);\n\n\t\t\t \n\t\t\tif (cp->tx_tiny_use[ring][entry].used) {\n\t\t\t\tcp->tx_tiny_use[ring][entry].used = 0;\n\t\t\t\tentry = TX_DESC_NEXT(ring, entry);\n\t\t\t}\n\t\t}\n\n\t\tspin_lock(&cp->stat_lock[ring]);\n\t\tcp->net_stats[ring].tx_packets++;\n\t\tcp->net_stats[ring].tx_bytes += skb->len;\n\t\tspin_unlock(&cp->stat_lock[ring]);\n\t\tdev_consume_skb_irq(skb);\n\t}\n\tcp->tx_old[ring] = entry;\n\n\t \n\tif (netif_queue_stopped(dev) &&\n\t    (TX_BUFFS_AVAIL(cp, ring) > CAS_TABORT(cp)*(MAX_SKB_FRAGS + 1)))\n\t\tnetif_wake_queue(dev);\n\tspin_unlock(&cp->tx_lock[ring]);\n}\n\nstatic void cas_tx(struct net_device *dev, struct cas *cp,\n\t\t   u32 status)\n{\n        int limit, ring;\n#ifdef USE_TX_COMPWB\n\tu64 compwb = le64_to_cpu(cp->init_block->tx_compwb);\n#endif\n\tnetif_printk(cp, intr, KERN_DEBUG, cp->dev,\n\t\t     \"tx interrupt, status: 0x%x, %llx\\n\",\n\t\t     status, (unsigned long long)compwb);\n\t \n\tfor (ring = 0; ring < N_TX_RINGS; ring++) {\n#ifdef USE_TX_COMPWB\n\t\t \n\t\tlimit = (CAS_VAL(TX_COMPWB_MSB, compwb) << 8) |\n\t\t\tCAS_VAL(TX_COMPWB_LSB, compwb);\n\t\tcompwb = TX_COMPWB_NEXT(compwb);\n#else\n\t\tlimit = readl(cp->regs + REG_TX_COMPN(ring));\n#endif\n\t\tif (cp->tx_old[ring] != limit)\n\t\t\tcas_tx_ringN(cp, ring, limit);\n\t}\n}\n\n\nstatic int cas_rx_process_pkt(struct cas *cp, struct cas_rx_comp *rxc,\n\t\t\t      int entry, const u64 *words,\n\t\t\t      struct sk_buff **skbref)\n{\n\tint dlen, hlen, len, i, alloclen;\n\tint off, swivel = RX_SWIVEL_OFF_VAL;\n\tstruct cas_page *page;\n\tstruct sk_buff *skb;\n\tvoid *crcaddr;\n\t__sum16 csum;\n\tchar *p;\n\n\thlen = CAS_VAL(RX_COMP2_HDR_SIZE, words[1]);\n\tdlen = CAS_VAL(RX_COMP1_DATA_SIZE, words[0]);\n\tlen  = hlen + dlen;\n\n\tif (RX_COPY_ALWAYS || (words[2] & RX_COMP3_SMALL_PKT))\n\t\talloclen = len;\n\telse\n\t\talloclen = max(hlen, RX_COPY_MIN);\n\n\tskb = netdev_alloc_skb(cp->dev, alloclen + swivel + cp->crc_size);\n\tif (skb == NULL)\n\t\treturn -1;\n\n\t*skbref = skb;\n\tskb_reserve(skb, swivel);\n\n\tp = skb->data;\n\tcrcaddr = NULL;\n\tif (hlen) {  \n\t\ti = CAS_VAL(RX_COMP2_HDR_INDEX, words[1]);\n\t\tpage = cp->rx_pages[CAS_VAL(RX_INDEX_RING, i)][CAS_VAL(RX_INDEX_NUM, i)];\n\t\toff = CAS_VAL(RX_COMP2_HDR_OFF, words[1]) * 0x100 +\n\t\t\tswivel;\n\n\t\ti = hlen;\n\t\tif (!dlen)  \n\t\t\ti += cp->crc_size;\n\t\tdma_sync_single_for_cpu(&cp->pdev->dev, page->dma_addr + off,\n\t\t\t\t\ti, DMA_FROM_DEVICE);\n\t\tmemcpy(p, page_address(page->buffer) + off, i);\n\t\tdma_sync_single_for_device(&cp->pdev->dev,\n\t\t\t\t\t   page->dma_addr + off, i,\n\t\t\t\t\t   DMA_FROM_DEVICE);\n\t\tRX_USED_ADD(page, 0x100);\n\t\tp += hlen;\n\t\tswivel = 0;\n\t}\n\n\n\tif (alloclen < (hlen + dlen)) {\n\t\tskb_frag_t *frag = skb_shinfo(skb)->frags;\n\n\t\t \n\t\ti = CAS_VAL(RX_COMP1_DATA_INDEX, words[0]);\n\t\tpage = cp->rx_pages[CAS_VAL(RX_INDEX_RING, i)][CAS_VAL(RX_INDEX_NUM, i)];\n\t\toff = CAS_VAL(RX_COMP1_DATA_OFF, words[0]) + swivel;\n\n\t\thlen = min(cp->page_size - off, dlen);\n\t\tif (hlen < 0) {\n\t\t\tnetif_printk(cp, rx_err, KERN_DEBUG, cp->dev,\n\t\t\t\t     \"rx page overflow: %d\\n\", hlen);\n\t\t\tdev_kfree_skb_irq(skb);\n\t\t\treturn -1;\n\t\t}\n\t\ti = hlen;\n\t\tif (i == dlen)   \n\t\t\ti += cp->crc_size;\n\t\tdma_sync_single_for_cpu(&cp->pdev->dev, page->dma_addr + off,\n\t\t\t\t\ti, DMA_FROM_DEVICE);\n\n\t\t \n\t\tswivel = 0;\n\t\tif (p == (char *) skb->data) {  \n\t\t\tmemcpy(p, page_address(page->buffer) + off,\n\t\t\t       RX_COPY_MIN);\n\t\t\tdma_sync_single_for_device(&cp->pdev->dev,\n\t\t\t\t\t\t   page->dma_addr + off, i,\n\t\t\t\t\t\t   DMA_FROM_DEVICE);\n\t\t\toff += RX_COPY_MIN;\n\t\t\tswivel = RX_COPY_MIN;\n\t\t\tRX_USED_ADD(page, cp->mtu_stride);\n\t\t} else {\n\t\t\tRX_USED_ADD(page, hlen);\n\t\t}\n\t\tskb_put(skb, alloclen);\n\n\t\tskb_shinfo(skb)->nr_frags++;\n\t\tskb->data_len += hlen - swivel;\n\t\tskb->truesize += hlen - swivel;\n\t\tskb->len      += hlen - swivel;\n\n\t\tskb_frag_fill_page_desc(frag, page->buffer, off, hlen - swivel);\n\t\t__skb_frag_ref(frag);\n\n\t\t \n\t\tif ((words[0] & RX_COMP1_SPLIT_PKT) && ((dlen -= hlen) > 0)) {\n\t\t\thlen = dlen;\n\t\t\toff = 0;\n\n\t\t\ti = CAS_VAL(RX_COMP2_NEXT_INDEX, words[1]);\n\t\t\tpage = cp->rx_pages[CAS_VAL(RX_INDEX_RING, i)][CAS_VAL(RX_INDEX_NUM, i)];\n\t\t\tdma_sync_single_for_cpu(&cp->pdev->dev,\n\t\t\t\t\t\tpage->dma_addr,\n\t\t\t\t\t\thlen + cp->crc_size,\n\t\t\t\t\t\tDMA_FROM_DEVICE);\n\t\t\tdma_sync_single_for_device(&cp->pdev->dev,\n\t\t\t\t\t\t   page->dma_addr,\n\t\t\t\t\t\t   hlen + cp->crc_size,\n\t\t\t\t\t\t   DMA_FROM_DEVICE);\n\n\t\t\tskb_shinfo(skb)->nr_frags++;\n\t\t\tskb->data_len += hlen;\n\t\t\tskb->len      += hlen;\n\t\t\tfrag++;\n\n\t\t\tskb_frag_fill_page_desc(frag, page->buffer, 0, hlen);\n\t\t\t__skb_frag_ref(frag);\n\t\t\tRX_USED_ADD(page, hlen + cp->crc_size);\n\t\t}\n\n\t\tif (cp->crc_size)\n\t\t\tcrcaddr = page_address(page->buffer) + off + hlen;\n\n\t} else {\n\t\t \n\t\tif (!dlen)\n\t\t\tgoto end_copy_pkt;\n\n\t\ti = CAS_VAL(RX_COMP1_DATA_INDEX, words[0]);\n\t\tpage = cp->rx_pages[CAS_VAL(RX_INDEX_RING, i)][CAS_VAL(RX_INDEX_NUM, i)];\n\t\toff = CAS_VAL(RX_COMP1_DATA_OFF, words[0]) + swivel;\n\t\thlen = min(cp->page_size - off, dlen);\n\t\tif (hlen < 0) {\n\t\t\tnetif_printk(cp, rx_err, KERN_DEBUG, cp->dev,\n\t\t\t\t     \"rx page overflow: %d\\n\", hlen);\n\t\t\tdev_kfree_skb_irq(skb);\n\t\t\treturn -1;\n\t\t}\n\t\ti = hlen;\n\t\tif (i == dlen)  \n\t\t\ti += cp->crc_size;\n\t\tdma_sync_single_for_cpu(&cp->pdev->dev, page->dma_addr + off,\n\t\t\t\t\ti, DMA_FROM_DEVICE);\n\t\tmemcpy(p, page_address(page->buffer) + off, i);\n\t\tdma_sync_single_for_device(&cp->pdev->dev,\n\t\t\t\t\t   page->dma_addr + off, i,\n\t\t\t\t\t   DMA_FROM_DEVICE);\n\t\tif (p == (char *) skb->data)  \n\t\t\tRX_USED_ADD(page, cp->mtu_stride);\n\t\telse\n\t\t\tRX_USED_ADD(page, i);\n\n\t\t \n\t\tif ((words[0] & RX_COMP1_SPLIT_PKT) && ((dlen -= hlen) > 0)) {\n\t\t\tp += hlen;\n\t\t\ti = CAS_VAL(RX_COMP2_NEXT_INDEX, words[1]);\n\t\t\tpage = cp->rx_pages[CAS_VAL(RX_INDEX_RING, i)][CAS_VAL(RX_INDEX_NUM, i)];\n\t\t\tdma_sync_single_for_cpu(&cp->pdev->dev,\n\t\t\t\t\t\tpage->dma_addr,\n\t\t\t\t\t\tdlen + cp->crc_size,\n\t\t\t\t\t\tDMA_FROM_DEVICE);\n\t\t\tmemcpy(p, page_address(page->buffer), dlen + cp->crc_size);\n\t\t\tdma_sync_single_for_device(&cp->pdev->dev,\n\t\t\t\t\t\t   page->dma_addr,\n\t\t\t\t\t\t   dlen + cp->crc_size,\n\t\t\t\t\t\t   DMA_FROM_DEVICE);\n\t\t\tRX_USED_ADD(page, dlen + cp->crc_size);\n\t\t}\nend_copy_pkt:\n\t\tif (cp->crc_size)\n\t\t\tcrcaddr = skb->data + alloclen;\n\n\t\tskb_put(skb, alloclen);\n\t}\n\n\tcsum = (__force __sum16)htons(CAS_VAL(RX_COMP4_TCP_CSUM, words[3]));\n\tif (cp->crc_size) {\n\t\t \n\t\tcsum = csum_fold(csum_partial(crcaddr, cp->crc_size,\n\t\t\t\t\t      csum_unfold(csum)));\n\t}\n\tskb->protocol = eth_type_trans(skb, cp->dev);\n\tif (skb->protocol == htons(ETH_P_IP)) {\n\t\tskb->csum = csum_unfold(~csum);\n\t\tskb->ip_summed = CHECKSUM_COMPLETE;\n\t} else\n\t\tskb_checksum_none_assert(skb);\n\treturn len;\n}\n\n\n \nstatic inline void cas_rx_flow_pkt(struct cas *cp, const u64 *words,\n\t\t\t\t   struct sk_buff *skb)\n{\n\tint flowid = CAS_VAL(RX_COMP3_FLOWID, words[2]) & (N_RX_FLOWS - 1);\n\tstruct sk_buff_head *flow = &cp->rx_flows[flowid];\n\n\t \n\t__skb_queue_tail(flow, skb);\n\tif (words[0] & RX_COMP1_RELEASE_FLOW) {\n\t\twhile ((skb = __skb_dequeue(flow))) {\n\t\t\tcas_skb_release(skb);\n\t\t}\n\t}\n}\n\n \nstatic void cas_post_page(struct cas *cp, const int ring, const int index)\n{\n\tcas_page_t *new;\n\tint entry;\n\n\tentry = cp->rx_old[ring];\n\n\tnew = cas_page_swap(cp, ring, index);\n\tcp->init_rxds[ring][entry].buffer = cpu_to_le64(new->dma_addr);\n\tcp->init_rxds[ring][entry].index  =\n\t\tcpu_to_le64(CAS_BASE(RX_INDEX_NUM, index) |\n\t\t\t    CAS_BASE(RX_INDEX_RING, ring));\n\n\tentry = RX_DESC_ENTRY(ring, entry + 1);\n\tcp->rx_old[ring] = entry;\n\n\tif (entry % 4)\n\t\treturn;\n\n\tif (ring == 0)\n\t\twritel(entry, cp->regs + REG_RX_KICK);\n\telse if ((N_RX_DESC_RINGS > 1) &&\n\t\t (cp->cas_flags & CAS_FLAG_REG_PLUS))\n\t\twritel(entry, cp->regs + REG_PLUS_RX_KICK1);\n}\n\n\n \nstatic int cas_post_rxds_ringN(struct cas *cp, int ring, int num)\n{\n\tunsigned int entry, last, count, released;\n\tint cluster;\n\tcas_page_t **page = cp->rx_pages[ring];\n\n\tentry = cp->rx_old[ring];\n\n\tnetif_printk(cp, intr, KERN_DEBUG, cp->dev,\n\t\t     \"rxd[%d] interrupt, done: %d\\n\", ring, entry);\n\n\tcluster = -1;\n\tcount = entry & 0x3;\n\tlast = RX_DESC_ENTRY(ring, num ? entry + num - 4: entry - 4);\n\treleased = 0;\n\twhile (entry != last) {\n\t\t \n\t\tif (page_count(page[entry]->buffer) > 1) {\n\t\t\tcas_page_t *new = cas_page_dequeue(cp);\n\t\t\tif (!new) {\n\t\t\t\t \n\t\t\t\tcp->cas_flags |= CAS_FLAG_RXD_POST(ring);\n\t\t\t\tif (!timer_pending(&cp->link_timer))\n\t\t\t\t\tmod_timer(&cp->link_timer, jiffies +\n\t\t\t\t\t\t  CAS_LINK_FAST_TIMEOUT);\n\t\t\t\tcp->rx_old[ring]  = entry;\n\t\t\t\tcp->rx_last[ring] = num ? num - released : 0;\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tspin_lock(&cp->rx_inuse_lock);\n\t\t\tlist_add(&page[entry]->list, &cp->rx_inuse_list);\n\t\t\tspin_unlock(&cp->rx_inuse_lock);\n\t\t\tcp->init_rxds[ring][entry].buffer =\n\t\t\t\tcpu_to_le64(new->dma_addr);\n\t\t\tpage[entry] = new;\n\n\t\t}\n\n\t\tif (++count == 4) {\n\t\t\tcluster = entry;\n\t\t\tcount = 0;\n\t\t}\n\t\treleased++;\n\t\tentry = RX_DESC_ENTRY(ring, entry + 1);\n\t}\n\tcp->rx_old[ring] = entry;\n\n\tif (cluster < 0)\n\t\treturn 0;\n\n\tif (ring == 0)\n\t\twritel(cluster, cp->regs + REG_RX_KICK);\n\telse if ((N_RX_DESC_RINGS > 1) &&\n\t\t (cp->cas_flags & CAS_FLAG_REG_PLUS))\n\t\twritel(cluster, cp->regs + REG_PLUS_RX_KICK1);\n\treturn 0;\n}\n\n\n \nstatic int cas_rx_ringN(struct cas *cp, int ring, int budget)\n{\n\tstruct cas_rx_comp *rxcs = cp->init_rxcs[ring];\n\tint entry, drops;\n\tint npackets = 0;\n\n\tnetif_printk(cp, intr, KERN_DEBUG, cp->dev,\n\t\t     \"rx[%d] interrupt, done: %d/%d\\n\",\n\t\t     ring,\n\t\t     readl(cp->regs + REG_RX_COMP_HEAD), cp->rx_new[ring]);\n\n\tentry = cp->rx_new[ring];\n\tdrops = 0;\n\twhile (1) {\n\t\tstruct cas_rx_comp *rxc = rxcs + entry;\n\t\tstruct sk_buff *skb;\n\t\tint type, len;\n\t\tu64 words[4];\n\t\tint i, dring;\n\n\t\twords[0] = le64_to_cpu(rxc->word1);\n\t\twords[1] = le64_to_cpu(rxc->word2);\n\t\twords[2] = le64_to_cpu(rxc->word3);\n\t\twords[3] = le64_to_cpu(rxc->word4);\n\n\t\t \n\t\ttype = CAS_VAL(RX_COMP1_TYPE, words[0]);\n\t\tif (type == 0)\n\t\t\tbreak;\n\n\t\t \n\t\tif (words[3] & RX_COMP4_ZERO) {\n\t\t\tbreak;\n\t\t}\n\n\t\t \n\t\tif (words[3] & (RX_COMP4_LEN_MISMATCH | RX_COMP4_BAD)) {\n\t\t\tspin_lock(&cp->stat_lock[ring]);\n\t\t\tcp->net_stats[ring].rx_errors++;\n\t\t\tif (words[3] & RX_COMP4_LEN_MISMATCH)\n\t\t\t\tcp->net_stats[ring].rx_length_errors++;\n\t\t\tif (words[3] & RX_COMP4_BAD)\n\t\t\t\tcp->net_stats[ring].rx_crc_errors++;\n\t\t\tspin_unlock(&cp->stat_lock[ring]);\n\n\t\t\t \n\t\tdrop_it:\n\t\t\tspin_lock(&cp->stat_lock[ring]);\n\t\t\t++cp->net_stats[ring].rx_dropped;\n\t\t\tspin_unlock(&cp->stat_lock[ring]);\n\t\t\tgoto next;\n\t\t}\n\n\t\tlen = cas_rx_process_pkt(cp, rxc, entry, words, &skb);\n\t\tif (len < 0) {\n\t\t\t++drops;\n\t\t\tgoto drop_it;\n\t\t}\n\n\t\t \n\t\tif (RX_DONT_BATCH || (type == 0x2)) {\n\t\t\t \n\t\t\tcas_skb_release(skb);\n\t\t} else {\n\t\t\tcas_rx_flow_pkt(cp, words, skb);\n\t\t}\n\n\t\tspin_lock(&cp->stat_lock[ring]);\n\t\tcp->net_stats[ring].rx_packets++;\n\t\tcp->net_stats[ring].rx_bytes += len;\n\t\tspin_unlock(&cp->stat_lock[ring]);\n\n\tnext:\n\t\tnpackets++;\n\n\t\t \n\t\tif (words[0] & RX_COMP1_RELEASE_HDR) {\n\t\t\ti = CAS_VAL(RX_COMP2_HDR_INDEX, words[1]);\n\t\t\tdring = CAS_VAL(RX_INDEX_RING, i);\n\t\t\ti = CAS_VAL(RX_INDEX_NUM, i);\n\t\t\tcas_post_page(cp, dring, i);\n\t\t}\n\n\t\tif (words[0] & RX_COMP1_RELEASE_DATA) {\n\t\t\ti = CAS_VAL(RX_COMP1_DATA_INDEX, words[0]);\n\t\t\tdring = CAS_VAL(RX_INDEX_RING, i);\n\t\t\ti = CAS_VAL(RX_INDEX_NUM, i);\n\t\t\tcas_post_page(cp, dring, i);\n\t\t}\n\n\t\tif (words[0] & RX_COMP1_RELEASE_NEXT) {\n\t\t\ti = CAS_VAL(RX_COMP2_NEXT_INDEX, words[1]);\n\t\t\tdring = CAS_VAL(RX_INDEX_RING, i);\n\t\t\ti = CAS_VAL(RX_INDEX_NUM, i);\n\t\t\tcas_post_page(cp, dring, i);\n\t\t}\n\n\t\t \n\t\tentry = RX_COMP_ENTRY(ring, entry + 1 +\n\t\t\t\t      CAS_VAL(RX_COMP1_SKIP, words[0]));\n#ifdef USE_NAPI\n\t\tif (budget && (npackets >= budget))\n\t\t\tbreak;\n#endif\n\t}\n\tcp->rx_new[ring] = entry;\n\n\tif (drops)\n\t\tnetdev_info(cp->dev, \"Memory squeeze, deferring packet\\n\");\n\treturn npackets;\n}\n\n\n \nstatic void cas_post_rxcs_ringN(struct net_device *dev,\n\t\t\t\tstruct cas *cp, int ring)\n{\n\tstruct cas_rx_comp *rxc = cp->init_rxcs[ring];\n\tint last, entry;\n\n\tlast = cp->rx_cur[ring];\n\tentry = cp->rx_new[ring];\n\tnetif_printk(cp, intr, KERN_DEBUG, dev,\n\t\t     \"rxc[%d] interrupt, done: %d/%d\\n\",\n\t\t     ring, readl(cp->regs + REG_RX_COMP_HEAD), entry);\n\n\t \n\twhile (last != entry) {\n\t\tcas_rxc_init(rxc + last);\n\t\tlast = RX_COMP_ENTRY(ring, last + 1);\n\t}\n\tcp->rx_cur[ring] = last;\n\n\tif (ring == 0)\n\t\twritel(last, cp->regs + REG_RX_COMP_TAIL);\n\telse if (cp->cas_flags & CAS_FLAG_REG_PLUS)\n\t\twritel(last, cp->regs + REG_PLUS_RX_COMPN_TAIL(ring));\n}\n\n\n\n \n#if defined(USE_PCI_INTC) || defined(USE_PCI_INTD)\nstatic inline void cas_handle_irqN(struct net_device *dev,\n\t\t\t\t   struct cas *cp, const u32 status,\n\t\t\t\t   const int ring)\n{\n\tif (status & (INTR_RX_COMP_FULL_ALT | INTR_RX_COMP_AF_ALT))\n\t\tcas_post_rxcs_ringN(dev, cp, ring);\n}\n\nstatic irqreturn_t cas_interruptN(int irq, void *dev_id)\n{\n\tstruct net_device *dev = dev_id;\n\tstruct cas *cp = netdev_priv(dev);\n\tunsigned long flags;\n\tint ring = (irq == cp->pci_irq_INTC) ? 2 : 3;\n\tu32 status = readl(cp->regs + REG_PLUS_INTRN_STATUS(ring));\n\n\t \n\tif (status == 0)\n\t\treturn IRQ_NONE;\n\n\tspin_lock_irqsave(&cp->lock, flags);\n\tif (status & INTR_RX_DONE_ALT) {  \n#ifdef USE_NAPI\n\t\tcas_mask_intr(cp);\n\t\tnapi_schedule(&cp->napi);\n#else\n\t\tcas_rx_ringN(cp, ring, 0);\n#endif\n\t\tstatus &= ~INTR_RX_DONE_ALT;\n\t}\n\n\tif (status)\n\t\tcas_handle_irqN(dev, cp, status, ring);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\treturn IRQ_HANDLED;\n}\n#endif\n\n#ifdef USE_PCI_INTB\n \nstatic inline void cas_handle_irq1(struct cas *cp, const u32 status)\n{\n\tif (status & INTR_RX_BUF_UNAVAIL_1) {\n\t\t \n\t\tcas_post_rxds_ringN(cp, 1, 0);\n\t\tspin_lock(&cp->stat_lock[1]);\n\t\tcp->net_stats[1].rx_dropped++;\n\t\tspin_unlock(&cp->stat_lock[1]);\n\t}\n\n\tif (status & INTR_RX_BUF_AE_1)\n\t\tcas_post_rxds_ringN(cp, 1, RX_DESC_RINGN_SIZE(1) -\n\t\t\t\t    RX_AE_FREEN_VAL(1));\n\n\tif (status & (INTR_RX_COMP_AF | INTR_RX_COMP_FULL))\n\t\tcas_post_rxcs_ringN(cp, 1);\n}\n\n \nstatic irqreturn_t cas_interrupt1(int irq, void *dev_id)\n{\n\tstruct net_device *dev = dev_id;\n\tstruct cas *cp = netdev_priv(dev);\n\tunsigned long flags;\n\tu32 status = readl(cp->regs + REG_PLUS_INTRN_STATUS(1));\n\n\t \n\tif (status == 0)\n\t\treturn IRQ_NONE;\n\n\tspin_lock_irqsave(&cp->lock, flags);\n\tif (status & INTR_RX_DONE_ALT) {  \n#ifdef USE_NAPI\n\t\tcas_mask_intr(cp);\n\t\tnapi_schedule(&cp->napi);\n#else\n\t\tcas_rx_ringN(cp, 1, 0);\n#endif\n\t\tstatus &= ~INTR_RX_DONE_ALT;\n\t}\n\tif (status)\n\t\tcas_handle_irq1(cp, status);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\treturn IRQ_HANDLED;\n}\n#endif\n\nstatic inline void cas_handle_irq(struct net_device *dev,\n\t\t\t\t  struct cas *cp, const u32 status)\n{\n\t \n\tif (status & INTR_ERROR_MASK)\n\t\tcas_abnormal_irq(dev, cp, status);\n\n\tif (status & INTR_RX_BUF_UNAVAIL) {\n\t\t \n\t\tcas_post_rxds_ringN(cp, 0, 0);\n\t\tspin_lock(&cp->stat_lock[0]);\n\t\tcp->net_stats[0].rx_dropped++;\n\t\tspin_unlock(&cp->stat_lock[0]);\n\t} else if (status & INTR_RX_BUF_AE) {\n\t\tcas_post_rxds_ringN(cp, 0, RX_DESC_RINGN_SIZE(0) -\n\t\t\t\t    RX_AE_FREEN_VAL(0));\n\t}\n\n\tif (status & (INTR_RX_COMP_AF | INTR_RX_COMP_FULL))\n\t\tcas_post_rxcs_ringN(dev, cp, 0);\n}\n\nstatic irqreturn_t cas_interrupt(int irq, void *dev_id)\n{\n\tstruct net_device *dev = dev_id;\n\tstruct cas *cp = netdev_priv(dev);\n\tunsigned long flags;\n\tu32 status = readl(cp->regs + REG_INTR_STATUS);\n\n\tif (status == 0)\n\t\treturn IRQ_NONE;\n\n\tspin_lock_irqsave(&cp->lock, flags);\n\tif (status & (INTR_TX_ALL | INTR_TX_INTME)) {\n\t\tcas_tx(dev, cp, status);\n\t\tstatus &= ~(INTR_TX_ALL | INTR_TX_INTME);\n\t}\n\n\tif (status & INTR_RX_DONE) {\n#ifdef USE_NAPI\n\t\tcas_mask_intr(cp);\n\t\tnapi_schedule(&cp->napi);\n#else\n\t\tcas_rx_ringN(cp, 0, 0);\n#endif\n\t\tstatus &= ~INTR_RX_DONE;\n\t}\n\n\tif (status)\n\t\tcas_handle_irq(dev, cp, status);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\treturn IRQ_HANDLED;\n}\n\n\n#ifdef USE_NAPI\nstatic int cas_poll(struct napi_struct *napi, int budget)\n{\n\tstruct cas *cp = container_of(napi, struct cas, napi);\n\tstruct net_device *dev = cp->dev;\n\tint i, enable_intr, credits;\n\tu32 status = readl(cp->regs + REG_INTR_STATUS);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cp->lock, flags);\n\tcas_tx(dev, cp, status);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\n\t \n\tenable_intr = 1;\n\tcredits = 0;\n\tfor (i = 0; i < N_RX_COMP_RINGS; i++) {\n\t\tint j;\n\t\tfor (j = 0; j < N_RX_COMP_RINGS; j++) {\n\t\t\tcredits += cas_rx_ringN(cp, j, budget / N_RX_COMP_RINGS);\n\t\t\tif (credits >= budget) {\n\t\t\t\tenable_intr = 0;\n\t\t\t\tgoto rx_comp;\n\t\t\t}\n\t\t}\n\t}\n\nrx_comp:\n\t \n\tspin_lock_irqsave(&cp->lock, flags);\n\tif (status)\n\t\tcas_handle_irq(dev, cp, status);\n\n#ifdef USE_PCI_INTB\n\tif (N_RX_COMP_RINGS > 1) {\n\t\tstatus = readl(cp->regs + REG_PLUS_INTRN_STATUS(1));\n\t\tif (status)\n\t\t\tcas_handle_irq1(dev, cp, status);\n\t}\n#endif\n\n#ifdef USE_PCI_INTC\n\tif (N_RX_COMP_RINGS > 2) {\n\t\tstatus = readl(cp->regs + REG_PLUS_INTRN_STATUS(2));\n\t\tif (status)\n\t\t\tcas_handle_irqN(dev, cp, status, 2);\n\t}\n#endif\n\n#ifdef USE_PCI_INTD\n\tif (N_RX_COMP_RINGS > 3) {\n\t\tstatus = readl(cp->regs + REG_PLUS_INTRN_STATUS(3));\n\t\tif (status)\n\t\t\tcas_handle_irqN(dev, cp, status, 3);\n\t}\n#endif\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\tif (enable_intr) {\n\t\tnapi_complete(napi);\n\t\tcas_unmask_intr(cp);\n\t}\n\treturn credits;\n}\n#endif\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void cas_netpoll(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\n\tcas_disable_irq(cp, 0);\n\tcas_interrupt(cp->pdev->irq, dev);\n\tcas_enable_irq(cp, 0);\n\n#ifdef USE_PCI_INTB\n\tif (N_RX_COMP_RINGS > 1) {\n\t\t \n\t}\n#endif\n#ifdef USE_PCI_INTC\n\tif (N_RX_COMP_RINGS > 2) {\n\t\t \n\t}\n#endif\n#ifdef USE_PCI_INTD\n\tif (N_RX_COMP_RINGS > 3) {\n\t\t \n\t}\n#endif\n}\n#endif\n\nstatic void cas_tx_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\n\tnetdev_err(dev, \"transmit timed out, resetting\\n\");\n\tif (!cp->hw_running) {\n\t\tnetdev_err(dev, \"hrm.. hw not running!\\n\");\n\t\treturn;\n\t}\n\n\tnetdev_err(dev, \"MIF_STATE[%08x]\\n\",\n\t\t   readl(cp->regs + REG_MIF_STATE_MACHINE));\n\n\tnetdev_err(dev, \"MAC_STATE[%08x]\\n\",\n\t\t   readl(cp->regs + REG_MAC_STATE_MACHINE));\n\n\tnetdev_err(dev, \"TX_STATE[%08x:%08x:%08x] FIFO[%08x:%08x:%08x] SM1[%08x] SM2[%08x]\\n\",\n\t\t   readl(cp->regs + REG_TX_CFG),\n\t\t   readl(cp->regs + REG_MAC_TX_STATUS),\n\t\t   readl(cp->regs + REG_MAC_TX_CFG),\n\t\t   readl(cp->regs + REG_TX_FIFO_PKT_CNT),\n\t\t   readl(cp->regs + REG_TX_FIFO_WRITE_PTR),\n\t\t   readl(cp->regs + REG_TX_FIFO_READ_PTR),\n\t\t   readl(cp->regs + REG_TX_SM_1),\n\t\t   readl(cp->regs + REG_TX_SM_2));\n\n\tnetdev_err(dev, \"RX_STATE[%08x:%08x:%08x]\\n\",\n\t\t   readl(cp->regs + REG_RX_CFG),\n\t\t   readl(cp->regs + REG_MAC_RX_STATUS),\n\t\t   readl(cp->regs + REG_MAC_RX_CFG));\n\n\tnetdev_err(dev, \"HP_STATE[%08x:%08x:%08x:%08x]\\n\",\n\t\t   readl(cp->regs + REG_HP_STATE_MACHINE),\n\t\t   readl(cp->regs + REG_HP_STATUS0),\n\t\t   readl(cp->regs + REG_HP_STATUS1),\n\t\t   readl(cp->regs + REG_HP_STATUS2));\n\n#if 1\n\tatomic_inc(&cp->reset_task_pending);\n\tatomic_inc(&cp->reset_task_pending_all);\n\tschedule_work(&cp->reset_task);\n#else\n\tatomic_set(&cp->reset_task_pending, CAS_RESET_ALL);\n\tschedule_work(&cp->reset_task);\n#endif\n}\n\nstatic inline int cas_intme(int ring, int entry)\n{\n\t \n\tif (!(entry & ((TX_DESC_RINGN_SIZE(ring) >> 1) - 1)))\n\t\treturn 1;\n\treturn 0;\n}\n\n\nstatic void cas_write_txd(struct cas *cp, int ring, int entry,\n\t\t\t  dma_addr_t mapping, int len, u64 ctrl, int last)\n{\n\tstruct cas_tx_desc *txd = cp->init_txds[ring] + entry;\n\n\tctrl |= CAS_BASE(TX_DESC_BUFLEN, len);\n\tif (cas_intme(ring, entry))\n\t\tctrl |= TX_DESC_INTME;\n\tif (last)\n\t\tctrl |= TX_DESC_EOF;\n\ttxd->control = cpu_to_le64(ctrl);\n\ttxd->buffer = cpu_to_le64(mapping);\n}\n\nstatic inline void *tx_tiny_buf(struct cas *cp, const int ring,\n\t\t\t\tconst int entry)\n{\n\treturn cp->tx_tiny_bufs[ring] + TX_TINY_BUF_LEN*entry;\n}\n\nstatic inline dma_addr_t tx_tiny_map(struct cas *cp, const int ring,\n\t\t\t\t     const int entry, const int tentry)\n{\n\tcp->tx_tiny_use[ring][tentry].nbufs++;\n\tcp->tx_tiny_use[ring][entry].used = 1;\n\treturn cp->tx_tiny_dvma[ring] + TX_TINY_BUF_LEN*entry;\n}\n\nstatic inline int cas_xmit_tx_ringN(struct cas *cp, int ring,\n\t\t\t\t    struct sk_buff *skb)\n{\n\tstruct net_device *dev = cp->dev;\n\tint entry, nr_frags, frag, tabort, tentry;\n\tdma_addr_t mapping;\n\tunsigned long flags;\n\tu64 ctrl;\n\tu32 len;\n\n\tspin_lock_irqsave(&cp->tx_lock[ring], flags);\n\n\t \n\tif (TX_BUFFS_AVAIL(cp, ring) <=\n\t    CAS_TABORT(cp)*(skb_shinfo(skb)->nr_frags + 1)) {\n\t\tnetif_stop_queue(dev);\n\t\tspin_unlock_irqrestore(&cp->tx_lock[ring], flags);\n\t\tnetdev_err(dev, \"BUG! Tx Ring full when queue awake!\\n\");\n\t\treturn 1;\n\t}\n\n\tctrl = 0;\n\tif (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tconst u64 csum_start_off = skb_checksum_start_offset(skb);\n\t\tconst u64 csum_stuff_off = csum_start_off + skb->csum_offset;\n\n\t\tctrl =  TX_DESC_CSUM_EN |\n\t\t\tCAS_BASE(TX_DESC_CSUM_START, csum_start_off) |\n\t\t\tCAS_BASE(TX_DESC_CSUM_STUFF, csum_stuff_off);\n\t}\n\n\tentry = cp->tx_new[ring];\n\tcp->tx_skbs[ring][entry] = skb;\n\n\tnr_frags = skb_shinfo(skb)->nr_frags;\n\tlen = skb_headlen(skb);\n\tmapping = dma_map_page(&cp->pdev->dev, virt_to_page(skb->data),\n\t\t\t       offset_in_page(skb->data), len, DMA_TO_DEVICE);\n\n\ttentry = entry;\n\ttabort = cas_calc_tabort(cp, (unsigned long) skb->data, len);\n\tif (unlikely(tabort)) {\n\t\t \n\t\tcas_write_txd(cp, ring, entry, mapping, len - tabort,\n\t\t\t      ctrl | TX_DESC_SOF, 0);\n\t\tentry = TX_DESC_NEXT(ring, entry);\n\n\t\tskb_copy_from_linear_data_offset(skb, len - tabort,\n\t\t\t      tx_tiny_buf(cp, ring, entry), tabort);\n\t\tmapping = tx_tiny_map(cp, ring, entry, tentry);\n\t\tcas_write_txd(cp, ring, entry, mapping, tabort, ctrl,\n\t\t\t      (nr_frags == 0));\n\t} else {\n\t\tcas_write_txd(cp, ring, entry, mapping, len, ctrl |\n\t\t\t      TX_DESC_SOF, (nr_frags == 0));\n\t}\n\tentry = TX_DESC_NEXT(ring, entry);\n\n\tfor (frag = 0; frag < nr_frags; frag++) {\n\t\tconst skb_frag_t *fragp = &skb_shinfo(skb)->frags[frag];\n\n\t\tlen = skb_frag_size(fragp);\n\t\tmapping = skb_frag_dma_map(&cp->pdev->dev, fragp, 0, len,\n\t\t\t\t\t   DMA_TO_DEVICE);\n\n\t\ttabort = cas_calc_tabort(cp, skb_frag_off(fragp), len);\n\t\tif (unlikely(tabort)) {\n\t\t\t \n\t\t\tcas_write_txd(cp, ring, entry, mapping, len - tabort,\n\t\t\t\t      ctrl, 0);\n\t\t\tentry = TX_DESC_NEXT(ring, entry);\n\t\t\tmemcpy_from_page(tx_tiny_buf(cp, ring, entry),\n\t\t\t\t\t skb_frag_page(fragp),\n\t\t\t\t\t skb_frag_off(fragp) + len - tabort,\n\t\t\t\t\t tabort);\n\t\t\tmapping = tx_tiny_map(cp, ring, entry, tentry);\n\t\t\tlen     = tabort;\n\t\t}\n\n\t\tcas_write_txd(cp, ring, entry, mapping, len, ctrl,\n\t\t\t      (frag + 1 == nr_frags));\n\t\tentry = TX_DESC_NEXT(ring, entry);\n\t}\n\n\tcp->tx_new[ring] = entry;\n\tif (TX_BUFFS_AVAIL(cp, ring) <= CAS_TABORT(cp)*(MAX_SKB_FRAGS + 1))\n\t\tnetif_stop_queue(dev);\n\n\tnetif_printk(cp, tx_queued, KERN_DEBUG, dev,\n\t\t     \"tx[%d] queued, slot %d, skblen %d, avail %d\\n\",\n\t\t     ring, entry, skb->len, TX_BUFFS_AVAIL(cp, ring));\n\twritel(entry, cp->regs + REG_TX_KICKN(ring));\n\tspin_unlock_irqrestore(&cp->tx_lock[ring], flags);\n\treturn 0;\n}\n\nstatic netdev_tx_t cas_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\n\t \n\tstatic int ring;\n\n\tif (skb_padto(skb, cp->min_frame_size))\n\t\treturn NETDEV_TX_OK;\n\n\t \n\tif (cas_xmit_tx_ringN(cp, ring++ & N_TX_RINGS_MASK, skb))\n\t\treturn NETDEV_TX_BUSY;\n\treturn NETDEV_TX_OK;\n}\n\nstatic void cas_init_tx_dma(struct cas *cp)\n{\n\tu64 desc_dma = cp->block_dvma;\n\tunsigned long off;\n\tu32 val;\n\tint i;\n\n\t \n#ifdef USE_TX_COMPWB\n\toff = offsetof(struct cas_init_block, tx_compwb);\n\twritel((desc_dma + off) >> 32, cp->regs + REG_TX_COMPWB_DB_HI);\n\twritel((desc_dma + off) & 0xffffffff, cp->regs + REG_TX_COMPWB_DB_LOW);\n#endif\n\n\t \n\tval =   TX_CFG_COMPWB_Q1 | TX_CFG_COMPWB_Q2 |\n\t\tTX_CFG_COMPWB_Q3 | TX_CFG_COMPWB_Q4 |\n\t\tTX_CFG_DMA_RDPIPE_DIS | TX_CFG_PACED_MODE |\n\t\tTX_CFG_INTR_COMPWB_DIS;\n\n\t \n\tfor (i = 0; i < MAX_TX_RINGS; i++) {\n\t\toff = (unsigned long) cp->init_txds[i] -\n\t\t\t(unsigned long) cp->init_block;\n\n\t\tval |= CAS_TX_RINGN_BASE(i);\n\t\twritel((desc_dma + off) >> 32, cp->regs + REG_TX_DBN_HI(i));\n\t\twritel((desc_dma + off) & 0xffffffff, cp->regs +\n\t\t       REG_TX_DBN_LOW(i));\n\t\t \n\t}\n\twritel(val, cp->regs + REG_TX_CFG);\n\n\t \n#ifdef USE_QOS\n\twritel(0x800, cp->regs + REG_TX_MAXBURST_0);\n\twritel(0x1600, cp->regs + REG_TX_MAXBURST_1);\n\twritel(0x2400, cp->regs + REG_TX_MAXBURST_2);\n\twritel(0x4800, cp->regs + REG_TX_MAXBURST_3);\n#else\n\twritel(0x800, cp->regs + REG_TX_MAXBURST_0);\n\twritel(0x800, cp->regs + REG_TX_MAXBURST_1);\n\twritel(0x800, cp->regs + REG_TX_MAXBURST_2);\n\twritel(0x800, cp->regs + REG_TX_MAXBURST_3);\n#endif\n}\n\n \nstatic inline void cas_init_dma(struct cas *cp)\n{\n\tcas_init_tx_dma(cp);\n\tcas_init_rx_dma(cp);\n}\n\nstatic void cas_process_mc_list(struct cas *cp)\n{\n\tu16 hash_table[16];\n\tu32 crc;\n\tstruct netdev_hw_addr *ha;\n\tint i = 1;\n\n\tmemset(hash_table, 0, sizeof(hash_table));\n\tnetdev_for_each_mc_addr(ha, cp->dev) {\n\t\tif (i <= CAS_MC_EXACT_MATCH_SIZE) {\n\t\t\t \n\t\t\twritel((ha->addr[4] << 8) | ha->addr[5],\n\t\t\t       cp->regs + REG_MAC_ADDRN(i*3 + 0));\n\t\t\twritel((ha->addr[2] << 8) | ha->addr[3],\n\t\t\t       cp->regs + REG_MAC_ADDRN(i*3 + 1));\n\t\t\twritel((ha->addr[0] << 8) | ha->addr[1],\n\t\t\t       cp->regs + REG_MAC_ADDRN(i*3 + 2));\n\t\t\ti++;\n\t\t}\n\t\telse {\n\t\t\t \n\t\t\tcrc = ether_crc_le(ETH_ALEN, ha->addr);\n\t\t\tcrc >>= 24;\n\t\t\thash_table[crc >> 4] |= 1 << (15 - (crc & 0xf));\n\t\t}\n\t}\n\tfor (i = 0; i < 16; i++)\n\t\twritel(hash_table[i], cp->regs + REG_MAC_HASH_TABLEN(i));\n}\n\n \nstatic u32 cas_setup_multicast(struct cas *cp)\n{\n\tu32 rxcfg = 0;\n\tint i;\n\n\tif (cp->dev->flags & IFF_PROMISC) {\n\t\trxcfg |= MAC_RX_CFG_PROMISC_EN;\n\n\t} else if (cp->dev->flags & IFF_ALLMULTI) {\n\t    \tfor (i=0; i < 16; i++)\n\t\t\twritel(0xFFFF, cp->regs + REG_MAC_HASH_TABLEN(i));\n\t\trxcfg |= MAC_RX_CFG_HASH_FILTER_EN;\n\n\t} else {\n\t\tcas_process_mc_list(cp);\n\t\trxcfg |= MAC_RX_CFG_HASH_FILTER_EN;\n\t}\n\n\treturn rxcfg;\n}\n\n \nstatic void cas_clear_mac_err(struct cas *cp)\n{\n\twritel(0, cp->regs + REG_MAC_COLL_NORMAL);\n\twritel(0, cp->regs + REG_MAC_COLL_FIRST);\n\twritel(0, cp->regs + REG_MAC_COLL_EXCESS);\n\twritel(0, cp->regs + REG_MAC_COLL_LATE);\n\twritel(0, cp->regs + REG_MAC_TIMER_DEFER);\n\twritel(0, cp->regs + REG_MAC_ATTEMPTS_PEAK);\n\twritel(0, cp->regs + REG_MAC_RECV_FRAME);\n\twritel(0, cp->regs + REG_MAC_LEN_ERR);\n\twritel(0, cp->regs + REG_MAC_ALIGN_ERR);\n\twritel(0, cp->regs + REG_MAC_FCS_ERR);\n\twritel(0, cp->regs + REG_MAC_RX_CODE_ERR);\n}\n\n\nstatic void cas_mac_reset(struct cas *cp)\n{\n\tint i;\n\n\t \n\twritel(0x1, cp->regs + REG_MAC_TX_RESET);\n\twritel(0x1, cp->regs + REG_MAC_RX_RESET);\n\n\t \n\ti = STOP_TRIES;\n\twhile (i-- > 0) {\n\t\tif (readl(cp->regs + REG_MAC_TX_RESET) == 0)\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\n\t \n\ti = STOP_TRIES;\n\twhile (i-- > 0) {\n\t\tif (readl(cp->regs + REG_MAC_RX_RESET) == 0)\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\n\tif (readl(cp->regs + REG_MAC_TX_RESET) |\n\t    readl(cp->regs + REG_MAC_RX_RESET))\n\t\tnetdev_err(cp->dev, \"mac tx[%d]/rx[%d] reset failed [%08x]\\n\",\n\t\t\t   readl(cp->regs + REG_MAC_TX_RESET),\n\t\t\t   readl(cp->regs + REG_MAC_RX_RESET),\n\t\t\t   readl(cp->regs + REG_MAC_STATE_MACHINE));\n}\n\n\n \nstatic void cas_init_mac(struct cas *cp)\n{\n\tconst unsigned char *e = &cp->dev->dev_addr[0];\n\tint i;\n\tcas_mac_reset(cp);\n\n\t \n\twritel(CAWR_RR_DIS, cp->regs + REG_CAWR);\n\n#if !defined(CONFIG_SPARC64) && !defined(CONFIG_ALPHA)\n\t \n\tif ((cp->cas_flags & CAS_FLAG_TARGET_ABORT) == 0)\n\t\twritel(INF_BURST_EN, cp->regs + REG_INF_BURST);\n#endif\n\n\twritel(0x1BF0, cp->regs + REG_MAC_SEND_PAUSE);\n\n\twritel(0x00, cp->regs + REG_MAC_IPG0);\n\twritel(0x08, cp->regs + REG_MAC_IPG1);\n\twritel(0x04, cp->regs + REG_MAC_IPG2);\n\n\t \n\twritel(0x40, cp->regs + REG_MAC_SLOT_TIME);\n\n\t \n\twritel(ETH_ZLEN + 4, cp->regs + REG_MAC_FRAMESIZE_MIN);\n\n\t \n\twritel(CAS_BASE(MAC_FRAMESIZE_MAX_BURST, 0x2000) |\n\t       CAS_BASE(MAC_FRAMESIZE_MAX_FRAME,\n\t\t\t(CAS_MAX_MTU + ETH_HLEN + 4 + 4)),\n\t       cp->regs + REG_MAC_FRAMESIZE_MAX);\n\n\t \n\tif ((cp->cas_flags & CAS_FLAG_SATURN) && cp->crc_size)\n\t\twritel(0x41, cp->regs + REG_MAC_PA_SIZE);\n\telse\n\t\twritel(0x07, cp->regs + REG_MAC_PA_SIZE);\n\twritel(0x04, cp->regs + REG_MAC_JAM_SIZE);\n\twritel(0x10, cp->regs + REG_MAC_ATTEMPT_LIMIT);\n\twritel(0x8808, cp->regs + REG_MAC_CTRL_TYPE);\n\n\twritel((e[5] | (e[4] << 8)) & 0x3ff, cp->regs + REG_MAC_RANDOM_SEED);\n\n\twritel(0, cp->regs + REG_MAC_ADDR_FILTER0);\n\twritel(0, cp->regs + REG_MAC_ADDR_FILTER1);\n\twritel(0, cp->regs + REG_MAC_ADDR_FILTER2);\n\twritel(0, cp->regs + REG_MAC_ADDR_FILTER2_1_MASK);\n\twritel(0, cp->regs + REG_MAC_ADDR_FILTER0_MASK);\n\n\t \n\tfor (i = 0; i < 45; i++)\n\t\twritel(0x0, cp->regs + REG_MAC_ADDRN(i));\n\n\twritel((e[4] << 8) | e[5], cp->regs + REG_MAC_ADDRN(0));\n\twritel((e[2] << 8) | e[3], cp->regs + REG_MAC_ADDRN(1));\n\twritel((e[0] << 8) | e[1], cp->regs + REG_MAC_ADDRN(2));\n\n\twritel(0x0001, cp->regs + REG_MAC_ADDRN(42));\n\twritel(0xc200, cp->regs + REG_MAC_ADDRN(43));\n\twritel(0x0180, cp->regs + REG_MAC_ADDRN(44));\n\n\tcp->mac_rx_cfg = cas_setup_multicast(cp);\n\n\tspin_lock(&cp->stat_lock[N_TX_RINGS]);\n\tcas_clear_mac_err(cp);\n\tspin_unlock(&cp->stat_lock[N_TX_RINGS]);\n\n\t \n\twritel(MAC_TX_FRAME_XMIT, cp->regs + REG_MAC_TX_MASK);\n\twritel(MAC_RX_FRAME_RECV, cp->regs + REG_MAC_RX_MASK);\n\n\t \n\twritel(0xffffffff, cp->regs + REG_MAC_CTRL_MASK);\n}\n\n \nstatic void cas_init_pause_thresholds(struct cas *cp)\n{\n\t \n\tif (cp->rx_fifo_size <= (2 * 1024)) {\n\t\tcp->rx_pause_off = cp->rx_pause_on = cp->rx_fifo_size;\n\t} else {\n\t\tint max_frame = (cp->dev->mtu + ETH_HLEN + 4 + 4 + 64) & ~63;\n\t\tif (max_frame * 3 > cp->rx_fifo_size) {\n\t\t\tcp->rx_pause_off = 7104;\n\t\t\tcp->rx_pause_on  = 960;\n\t\t} else {\n\t\t\tint off = (cp->rx_fifo_size - (max_frame * 2));\n\t\t\tint on = off - max_frame;\n\t\t\tcp->rx_pause_off = off;\n\t\t\tcp->rx_pause_on = on;\n\t\t}\n\t}\n}\n\nstatic int cas_vpd_match(const void __iomem *p, const char *str)\n{\n\tint len = strlen(str) + 1;\n\tint i;\n\n\tfor (i = 0; i < len; i++) {\n\t\tif (readb(p + i) != str[i])\n\t\t\treturn 0;\n\t}\n\treturn 1;\n}\n\n\n \nstatic int cas_get_vpd_info(struct cas *cp, unsigned char *dev_addr,\n\t\t\t    const int offset)\n{\n\tvoid __iomem *p = cp->regs + REG_EXPANSION_ROM_RUN_START;\n\tvoid __iomem *base, *kstart;\n\tint i, len;\n\tint found = 0;\n#define VPD_FOUND_MAC        0x01\n#define VPD_FOUND_PHY        0x02\n\n\tint phy_type = CAS_PHY_MII_MDIO0;  \n\tint mac_off  = 0;\n\n#if defined(CONFIG_SPARC)\n\tconst unsigned char *addr;\n#endif\n\n\t \n\twritel(BIM_LOCAL_DEV_PROM | BIM_LOCAL_DEV_PAD,\n\t       cp->regs + REG_BIM_LOCAL_DEV_EN);\n\n\t \n\tif (readb(p) != 0x55 || readb(p + 1) != 0xaa)\n\t\tgoto use_random_mac_addr;\n\n\t \n\tbase = NULL;\n\tfor (i = 2; i < EXPANSION_ROM_SIZE; i++) {\n\t\t \n\t\tif ((readb(p + i + 0) == 0x50) &&\n\t\t    (readb(p + i + 1) == 0x43) &&\n\t\t    (readb(p + i + 2) == 0x49) &&\n\t\t    (readb(p + i + 3) == 0x52)) {\n\t\t\tbase = p + (readb(p + i + 8) |\n\t\t\t\t    (readb(p + i + 9) << 8));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!base || (readb(base) != 0x82))\n\t\tgoto use_random_mac_addr;\n\n\ti = (readb(base + 1) | (readb(base + 2) << 8)) + 3;\n\twhile (i < EXPANSION_ROM_SIZE) {\n\t\tif (readb(base + i) != 0x90)  \n\t\t\tgoto use_random_mac_addr;\n\n\t\t \n\t\tlen = readb(base + i + 1) | (readb(base + i + 2) << 8);\n\n\t\t \n\t\tkstart = base + i + 3;\n\t\tp = kstart;\n\t\twhile ((p - kstart) < len) {\n\t\t\tint klen = readb(p + 2);\n\t\t\tint j;\n\t\t\tchar type;\n\n\t\t\tp += 3;\n\n\t\t\t \n\t\t\tif (readb(p) != 'I')\n\t\t\t\tgoto next;\n\n\t\t\t \n\t\t\ttype = readb(p + 3);\n\t\t\tif (type == 'B') {\n\t\t\t\tif ((klen == 29) && readb(p + 4) == 6 &&\n\t\t\t\t    cas_vpd_match(p + 5,\n\t\t\t\t\t\t  \"local-mac-address\")) {\n\t\t\t\t\tif (mac_off++ > offset)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\t \n\t\t\t\t\tfor (j = 0; j < 6; j++)\n\t\t\t\t\t\tdev_addr[j] =\n\t\t\t\t\t\t\treadb(p + 23 + j);\n\t\t\t\t\tgoto found_mac;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (type != 'S')\n\t\t\t\tgoto next;\n\n#ifdef USE_ENTROPY_DEV\n\t\t\tif ((klen == 24) &&\n\t\t\t    cas_vpd_match(p + 5, \"entropy-dev\") &&\n\t\t\t    cas_vpd_match(p + 17, \"vms110\")) {\n\t\t\t\tcp->cas_flags |= CAS_FLAG_ENTROPY_DEV;\n\t\t\t\tgoto next;\n\t\t\t}\n#endif\n\n\t\t\tif (found & VPD_FOUND_PHY)\n\t\t\t\tgoto next;\n\n\t\t\tif ((klen == 18) && readb(p + 4) == 4 &&\n\t\t\t    cas_vpd_match(p + 5, \"phy-type\")) {\n\t\t\t\tif (cas_vpd_match(p + 14, \"pcs\")) {\n\t\t\t\t\tphy_type = CAS_PHY_SERDES;\n\t\t\t\t\tgoto found_phy;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif ((klen == 23) && readb(p + 4) == 4 &&\n\t\t\t    cas_vpd_match(p + 5, \"phy-interface\")) {\n\t\t\t\tif (cas_vpd_match(p + 19, \"pcs\")) {\n\t\t\t\t\tphy_type = CAS_PHY_SERDES;\n\t\t\t\t\tgoto found_phy;\n\t\t\t\t}\n\t\t\t}\nfound_mac:\n\t\t\tfound |= VPD_FOUND_MAC;\n\t\t\tgoto next;\n\nfound_phy:\n\t\t\tfound |= VPD_FOUND_PHY;\n\nnext:\n\t\t\tp += klen;\n\t\t}\n\t\ti += len + 3;\n\t}\n\nuse_random_mac_addr:\n\tif (found & VPD_FOUND_MAC)\n\t\tgoto done;\n\n#if defined(CONFIG_SPARC)\n\taddr = of_get_property(cp->of_node, \"local-mac-address\", NULL);\n\tif (addr != NULL) {\n\t\tmemcpy(dev_addr, addr, ETH_ALEN);\n\t\tgoto done;\n\t}\n#endif\n\n\t \n\tpr_info(\"MAC address not found in ROM VPD\\n\");\n\tdev_addr[0] = 0x08;\n\tdev_addr[1] = 0x00;\n\tdev_addr[2] = 0x20;\n\tget_random_bytes(dev_addr + 3, 3);\n\ndone:\n\twritel(0, cp->regs + REG_BIM_LOCAL_DEV_EN);\n\treturn phy_type;\n}\n\n \nstatic void cas_check_pci_invariants(struct cas *cp)\n{\n\tstruct pci_dev *pdev = cp->pdev;\n\n\tcp->cas_flags = 0;\n\tif ((pdev->vendor == PCI_VENDOR_ID_SUN) &&\n\t    (pdev->device == PCI_DEVICE_ID_SUN_CASSINI)) {\n\t\tif (pdev->revision >= CAS_ID_REVPLUS)\n\t\t\tcp->cas_flags |= CAS_FLAG_REG_PLUS;\n\t\tif (pdev->revision < CAS_ID_REVPLUS02u)\n\t\t\tcp->cas_flags |= CAS_FLAG_TARGET_ABORT;\n\n\t\t \n\t\tif (pdev->revision < CAS_ID_REV2)\n\t\t\tcp->cas_flags |= CAS_FLAG_NO_HW_CSUM;\n\t} else {\n\t\t \n\t\tcp->cas_flags |= CAS_FLAG_REG_PLUS;\n\n\t\t \n\t\tif ((pdev->vendor == PCI_VENDOR_ID_NS) &&\n\t\t    (pdev->device == PCI_DEVICE_ID_NS_SATURN))\n\t\t\tcp->cas_flags |= CAS_FLAG_SATURN;\n\t}\n}\n\n\nstatic int cas_check_invariants(struct cas *cp)\n{\n\tstruct pci_dev *pdev = cp->pdev;\n\tu8 addr[ETH_ALEN];\n\tu32 cfg;\n\tint i;\n\n\t \n\tcp->page_order = 0;\n#ifdef USE_PAGE_ORDER\n\tif (PAGE_SHIFT < CAS_JUMBO_PAGE_SHIFT) {\n\t\t \n\t\tstruct page *page = alloc_pages(GFP_ATOMIC,\n\t\t\t\t\t\tCAS_JUMBO_PAGE_SHIFT -\n\t\t\t\t\t\tPAGE_SHIFT);\n\t\tif (page) {\n\t\t\t__free_pages(page, CAS_JUMBO_PAGE_SHIFT - PAGE_SHIFT);\n\t\t\tcp->page_order = CAS_JUMBO_PAGE_SHIFT - PAGE_SHIFT;\n\t\t} else {\n\t\t\tprintk(\"MTU limited to %d bytes\\n\", CAS_MAX_MTU);\n\t\t}\n\t}\n#endif\n\tcp->page_size = (PAGE_SIZE << cp->page_order);\n\n\t \n\tcp->tx_fifo_size = readl(cp->regs + REG_TX_FIFO_SIZE) * 64;\n\tcp->rx_fifo_size = RX_FIFO_SIZE;\n\n\t \n\tcp->phy_type = cas_get_vpd_info(cp, addr, PCI_SLOT(pdev->devfn));\n\teth_hw_addr_set(cp->dev, addr);\n\tif (cp->phy_type & CAS_PHY_SERDES) {\n\t\tcp->cas_flags |= CAS_FLAG_1000MB_CAP;\n\t\treturn 0;  \n\t}\n\n\t \n\tcfg = readl(cp->regs + REG_MIF_CFG);\n\tif (cfg & MIF_CFG_MDIO_1) {\n\t\tcp->phy_type = CAS_PHY_MII_MDIO1;\n\t} else if (cfg & MIF_CFG_MDIO_0) {\n\t\tcp->phy_type = CAS_PHY_MII_MDIO0;\n\t}\n\n\tcas_mif_poll(cp, 0);\n\twritel(PCS_DATAPATH_MODE_MII, cp->regs + REG_PCS_DATAPATH_MODE);\n\n\tfor (i = 0; i < 32; i++) {\n\t\tu32 phy_id;\n\t\tint j;\n\n\t\tfor (j = 0; j < 3; j++) {\n\t\t\tcp->phy_addr = i;\n\t\t\tphy_id = cas_phy_read(cp, MII_PHYSID1) << 16;\n\t\t\tphy_id |= cas_phy_read(cp, MII_PHYSID2);\n\t\t\tif (phy_id && (phy_id != 0xFFFFFFFF)) {\n\t\t\t\tcp->phy_id = phy_id;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\tpr_err(\"MII phy did not respond [%08x]\\n\",\n\t       readl(cp->regs + REG_MIF_STATE_MACHINE));\n\treturn -1;\n\ndone:\n\t \n\tcfg = cas_phy_read(cp, MII_BMSR);\n\tif ((cfg & CAS_BMSR_1000_EXTEND) &&\n\t    cas_phy_read(cp, CAS_MII_1000_EXTEND))\n\t\tcp->cas_flags |= CAS_FLAG_1000MB_CAP;\n\treturn 0;\n}\n\n \nstatic inline void cas_start_dma(struct cas *cp)\n{\n\tint i;\n\tu32 val;\n\tint txfailed = 0;\n\n\t \n\tval = readl(cp->regs + REG_TX_CFG) | TX_CFG_DMA_EN;\n\twritel(val, cp->regs + REG_TX_CFG);\n\tval = readl(cp->regs + REG_RX_CFG) | RX_CFG_DMA_EN;\n\twritel(val, cp->regs + REG_RX_CFG);\n\n\t \n\tval = readl(cp->regs + REG_MAC_TX_CFG) | MAC_TX_CFG_EN;\n\twritel(val, cp->regs + REG_MAC_TX_CFG);\n\tval = readl(cp->regs + REG_MAC_RX_CFG) | MAC_RX_CFG_EN;\n\twritel(val, cp->regs + REG_MAC_RX_CFG);\n\n\ti = STOP_TRIES;\n\twhile (i-- > 0) {\n\t\tval = readl(cp->regs + REG_MAC_TX_CFG);\n\t\tif ((val & MAC_TX_CFG_EN))\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\tif (i < 0) txfailed = 1;\n\ti = STOP_TRIES;\n\twhile (i-- > 0) {\n\t\tval = readl(cp->regs + REG_MAC_RX_CFG);\n\t\tif ((val & MAC_RX_CFG_EN)) {\n\t\t\tif (txfailed) {\n\t\t\t\tnetdev_err(cp->dev,\n\t\t\t\t\t   \"enabling mac failed [tx:%08x:%08x]\\n\",\n\t\t\t\t\t   readl(cp->regs + REG_MIF_STATE_MACHINE),\n\t\t\t\t\t   readl(cp->regs + REG_MAC_STATE_MACHINE));\n\t\t\t}\n\t\t\tgoto enable_rx_done;\n\t\t}\n\t\tudelay(10);\n\t}\n\tnetdev_err(cp->dev, \"enabling mac failed [%s:%08x:%08x]\\n\",\n\t\t   (txfailed ? \"tx,rx\" : \"rx\"),\n\t\t   readl(cp->regs + REG_MIF_STATE_MACHINE),\n\t\t   readl(cp->regs + REG_MAC_STATE_MACHINE));\n\nenable_rx_done:\n\tcas_unmask_intr(cp);  \n\twritel(RX_DESC_RINGN_SIZE(0) - 4, cp->regs + REG_RX_KICK);\n\twritel(0, cp->regs + REG_RX_COMP_TAIL);\n\n\tif (cp->cas_flags & CAS_FLAG_REG_PLUS) {\n\t\tif (N_RX_DESC_RINGS > 1)\n\t\t\twritel(RX_DESC_RINGN_SIZE(1) - 4,\n\t\t\t       cp->regs + REG_PLUS_RX_KICK1);\n\t}\n}\n\n \nstatic void cas_read_pcs_link_mode(struct cas *cp, int *fd, int *spd,\n\t\t\t\t   int *pause)\n{\n\tu32 val = readl(cp->regs + REG_PCS_MII_LPA);\n\t*fd     = (val & PCS_MII_LPA_FD) ? 1 : 0;\n\t*pause  = (val & PCS_MII_LPA_SYM_PAUSE) ? 0x01 : 0x00;\n\tif (val & PCS_MII_LPA_ASYM_PAUSE)\n\t\t*pause |= 0x10;\n\t*spd = 1000;\n}\n\n \nstatic void cas_read_mii_link_mode(struct cas *cp, int *fd, int *spd,\n\t\t\t\t   int *pause)\n{\n\tu32 val;\n\n\t*fd = 0;\n\t*spd = 10;\n\t*pause = 0;\n\n\t \n\tval = cas_phy_read(cp, MII_LPA);\n\tif (val & CAS_LPA_PAUSE)\n\t\t*pause = 0x01;\n\n\tif (val & CAS_LPA_ASYM_PAUSE)\n\t\t*pause |= 0x10;\n\n\tif (val & LPA_DUPLEX)\n\t\t*fd = 1;\n\tif (val & LPA_100)\n\t\t*spd = 100;\n\n\tif (cp->cas_flags & CAS_FLAG_1000MB_CAP) {\n\t\tval = cas_phy_read(cp, CAS_MII_1000_STATUS);\n\t\tif (val & (CAS_LPA_1000FULL | CAS_LPA_1000HALF))\n\t\t\t*spd = 1000;\n\t\tif (val & CAS_LPA_1000FULL)\n\t\t\t*fd = 1;\n\t}\n}\n\n \nstatic void cas_set_link_modes(struct cas *cp)\n{\n\tu32 val;\n\tint full_duplex, speed, pause;\n\n\tfull_duplex = 0;\n\tspeed = 10;\n\tpause = 0;\n\n\tif (CAS_PHY_MII(cp->phy_type)) {\n\t\tcas_mif_poll(cp, 0);\n\t\tval = cas_phy_read(cp, MII_BMCR);\n\t\tif (val & BMCR_ANENABLE) {\n\t\t\tcas_read_mii_link_mode(cp, &full_duplex, &speed,\n\t\t\t\t\t       &pause);\n\t\t} else {\n\t\t\tif (val & BMCR_FULLDPLX)\n\t\t\t\tfull_duplex = 1;\n\n\t\t\tif (val & BMCR_SPEED100)\n\t\t\t\tspeed = 100;\n\t\t\telse if (val & CAS_BMCR_SPEED1000)\n\t\t\t\tspeed = (cp->cas_flags & CAS_FLAG_1000MB_CAP) ?\n\t\t\t\t\t1000 : 100;\n\t\t}\n\t\tcas_mif_poll(cp, 1);\n\n\t} else {\n\t\tval = readl(cp->regs + REG_PCS_MII_CTRL);\n\t\tcas_read_pcs_link_mode(cp, &full_duplex, &speed, &pause);\n\t\tif ((val & PCS_MII_AUTONEG_EN) == 0) {\n\t\t\tif (val & PCS_MII_CTRL_DUPLEX)\n\t\t\t\tfull_duplex = 1;\n\t\t}\n\t}\n\n\tnetif_info(cp, link, cp->dev, \"Link up at %d Mbps, %s-duplex\\n\",\n\t\t   speed, full_duplex ? \"full\" : \"half\");\n\n\tval = MAC_XIF_TX_MII_OUTPUT_EN | MAC_XIF_LINK_LED;\n\tif (CAS_PHY_MII(cp->phy_type)) {\n\t\tval |= MAC_XIF_MII_BUFFER_OUTPUT_EN;\n\t\tif (!full_duplex)\n\t\t\tval |= MAC_XIF_DISABLE_ECHO;\n\t}\n\tif (full_duplex)\n\t\tval |= MAC_XIF_FDPLX_LED;\n\tif (speed == 1000)\n\t\tval |= MAC_XIF_GMII_MODE;\n\twritel(val, cp->regs + REG_MAC_XIF_CFG);\n\n\t \n\tval = MAC_TX_CFG_IPG_EN;\n\tif (full_duplex) {\n\t\tval |= MAC_TX_CFG_IGNORE_CARRIER;\n\t\tval |= MAC_TX_CFG_IGNORE_COLL;\n\t} else {\n#ifndef USE_CSMA_CD_PROTO\n\t\tval |= MAC_TX_CFG_NEVER_GIVE_UP_EN;\n\t\tval |= MAC_TX_CFG_NEVER_GIVE_UP_LIM;\n#endif\n\t}\n\t \n\n\t \n\tif ((speed == 1000) && !full_duplex) {\n\t\twritel(val | MAC_TX_CFG_CARRIER_EXTEND,\n\t\t       cp->regs + REG_MAC_TX_CFG);\n\n\t\tval = readl(cp->regs + REG_MAC_RX_CFG);\n\t\tval &= ~MAC_RX_CFG_STRIP_FCS;  \n\t\twritel(val | MAC_RX_CFG_CARRIER_EXTEND,\n\t\t       cp->regs + REG_MAC_RX_CFG);\n\n\t\twritel(0x200, cp->regs + REG_MAC_SLOT_TIME);\n\n\t\tcp->crc_size = 4;\n\t\t \n\t\tcp->min_frame_size = CAS_1000MB_MIN_FRAME;\n\n\t} else {\n\t\twritel(val, cp->regs + REG_MAC_TX_CFG);\n\n\t\t \n\t\tval = readl(cp->regs + REG_MAC_RX_CFG);\n\t\tif (full_duplex) {\n\t\t\tval |= MAC_RX_CFG_STRIP_FCS;\n\t\t\tcp->crc_size = 0;\n\t\t\tcp->min_frame_size = CAS_MIN_MTU;\n\t\t} else {\n\t\t\tval &= ~MAC_RX_CFG_STRIP_FCS;\n\t\t\tcp->crc_size = 4;\n\t\t\tcp->min_frame_size = CAS_MIN_FRAME;\n\t\t}\n\t\twritel(val & ~MAC_RX_CFG_CARRIER_EXTEND,\n\t\t       cp->regs + REG_MAC_RX_CFG);\n\t\twritel(0x40, cp->regs + REG_MAC_SLOT_TIME);\n\t}\n\n\tif (netif_msg_link(cp)) {\n\t\tif (pause & 0x01) {\n\t\t\tnetdev_info(cp->dev, \"Pause is enabled (rxfifo: %d off: %d on: %d)\\n\",\n\t\t\t\t    cp->rx_fifo_size,\n\t\t\t\t    cp->rx_pause_off,\n\t\t\t\t    cp->rx_pause_on);\n\t\t} else if (pause & 0x10) {\n\t\t\tnetdev_info(cp->dev, \"TX pause enabled\\n\");\n\t\t} else {\n\t\t\tnetdev_info(cp->dev, \"Pause is disabled\\n\");\n\t\t}\n\t}\n\n\tval = readl(cp->regs + REG_MAC_CTRL_CFG);\n\tval &= ~(MAC_CTRL_CFG_SEND_PAUSE_EN | MAC_CTRL_CFG_RECV_PAUSE_EN);\n\tif (pause) {  \n\t\tval |= MAC_CTRL_CFG_SEND_PAUSE_EN;\n\t\tif (pause & 0x01) {  \n\t\t\tval |= MAC_CTRL_CFG_RECV_PAUSE_EN;\n\t\t}\n\t}\n\twritel(val, cp->regs + REG_MAC_CTRL_CFG);\n\tcas_start_dma(cp);\n}\n\n \nstatic void cas_init_hw(struct cas *cp, int restart_link)\n{\n\tif (restart_link)\n\t\tcas_phy_init(cp);\n\n\tcas_init_pause_thresholds(cp);\n\tcas_init_mac(cp);\n\tcas_init_dma(cp);\n\n\tif (restart_link) {\n\t\t \n\t\tcp->timer_ticks = 0;\n\t\tcas_begin_auto_negotiation(cp, NULL);\n\t} else if (cp->lstate == link_up) {\n\t\tcas_set_link_modes(cp);\n\t\tnetif_carrier_on(cp->dev);\n\t}\n}\n\n \nstatic void cas_hard_reset(struct cas *cp)\n{\n\twritel(BIM_LOCAL_DEV_SOFT_0, cp->regs + REG_BIM_LOCAL_DEV_EN);\n\tudelay(20);\n\tpci_restore_state(cp->pdev);\n}\n\n\nstatic void cas_global_reset(struct cas *cp, int blkflag)\n{\n\tint limit;\n\n\t \n\tif (blkflag && !CAS_PHY_MII(cp->phy_type)) {\n\t\t \n\t\twritel((SW_RESET_TX | SW_RESET_RX | SW_RESET_BLOCK_PCS_SLINK),\n\t\t       cp->regs + REG_SW_RESET);\n\t} else {\n\t\twritel(SW_RESET_TX | SW_RESET_RX, cp->regs + REG_SW_RESET);\n\t}\n\n\t \n\tmdelay(3);\n\n\tlimit = STOP_TRIES;\n\twhile (limit-- > 0) {\n\t\tu32 val = readl(cp->regs + REG_SW_RESET);\n\t\tif ((val & (SW_RESET_TX | SW_RESET_RX)) == 0)\n\t\t\tgoto done;\n\t\tudelay(10);\n\t}\n\tnetdev_err(cp->dev, \"sw reset failed\\n\");\n\ndone:\n\t \n\twritel(BIM_CFG_DPAR_INTR_ENABLE | BIM_CFG_RMA_INTR_ENABLE |\n\t       BIM_CFG_RTA_INTR_ENABLE, cp->regs + REG_BIM_CFG);\n\n\t \n\twritel(0xFFFFFFFFU & ~(PCI_ERR_BADACK | PCI_ERR_DTRTO |\n\t\t\t       PCI_ERR_OTHER | PCI_ERR_BIM_DMA_WRITE |\n\t\t\t       PCI_ERR_BIM_DMA_READ), cp->regs +\n\t       REG_PCI_ERR_STATUS_MASK);\n\n\t \n\twritel(PCS_DATAPATH_MODE_MII, cp->regs + REG_PCS_DATAPATH_MODE);\n}\n\nstatic void cas_reset(struct cas *cp, int blkflag)\n{\n\tu32 val;\n\n\tcas_mask_intr(cp);\n\tcas_global_reset(cp, blkflag);\n\tcas_mac_reset(cp);\n\tcas_entropy_reset(cp);\n\n\t \n\tval = readl(cp->regs + REG_TX_CFG);\n\tval &= ~TX_CFG_DMA_EN;\n\twritel(val, cp->regs + REG_TX_CFG);\n\n\tval = readl(cp->regs + REG_RX_CFG);\n\tval &= ~RX_CFG_DMA_EN;\n\twritel(val, cp->regs + REG_RX_CFG);\n\n\t \n\tif ((cp->cas_flags & CAS_FLAG_TARGET_ABORT) ||\n\t    (&CAS_HP_ALT_FIRMWARE[0] == &cas_prog_null[0])) {\n\t\tcas_load_firmware(cp, CAS_HP_FIRMWARE);\n\t} else {\n\t\tcas_load_firmware(cp, CAS_HP_ALT_FIRMWARE);\n\t}\n\n\t \n\tspin_lock(&cp->stat_lock[N_TX_RINGS]);\n\tcas_clear_mac_err(cp);\n\tspin_unlock(&cp->stat_lock[N_TX_RINGS]);\n}\n\n \nstatic void cas_shutdown(struct cas *cp)\n{\n\tunsigned long flags;\n\n\t \n\tcp->hw_running = 0;\n\n\tdel_timer_sync(&cp->link_timer);\n\n\t \n#if 0\n\twhile (atomic_read(&cp->reset_task_pending_mtu) ||\n\t       atomic_read(&cp->reset_task_pending_spare) ||\n\t       atomic_read(&cp->reset_task_pending_all))\n\t\tschedule();\n\n#else\n\twhile (atomic_read(&cp->reset_task_pending))\n\t\tschedule();\n#endif\n\t \n\tcas_lock_all_save(cp, flags);\n\tcas_reset(cp, 0);\n\tif (cp->cas_flags & CAS_FLAG_SATURN)\n\t\tcas_phy_powerdown(cp);\n\tcas_unlock_all_restore(cp, flags);\n}\n\nstatic int cas_change_mtu(struct net_device *dev, int new_mtu)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\n\tdev->mtu = new_mtu;\n\tif (!netif_running(dev) || !netif_device_present(dev))\n\t\treturn 0;\n\n\t \n#if 1\n\tatomic_inc(&cp->reset_task_pending);\n\tif ((cp->phy_type & CAS_PHY_SERDES)) {\n\t\tatomic_inc(&cp->reset_task_pending_all);\n\t} else {\n\t\tatomic_inc(&cp->reset_task_pending_mtu);\n\t}\n\tschedule_work(&cp->reset_task);\n#else\n\tatomic_set(&cp->reset_task_pending, (cp->phy_type & CAS_PHY_SERDES) ?\n\t\t   CAS_RESET_ALL : CAS_RESET_MTU);\n\tpr_err(\"reset called in cas_change_mtu\\n\");\n\tschedule_work(&cp->reset_task);\n#endif\n\n\tflush_work(&cp->reset_task);\n\treturn 0;\n}\n\nstatic void cas_clean_txd(struct cas *cp, int ring)\n{\n\tstruct cas_tx_desc *txd = cp->init_txds[ring];\n\tstruct sk_buff *skb, **skbs = cp->tx_skbs[ring];\n\tu64 daddr, dlen;\n\tint i, size;\n\n\tsize = TX_DESC_RINGN_SIZE(ring);\n\tfor (i = 0; i < size; i++) {\n\t\tint frag;\n\n\t\tif (skbs[i] == NULL)\n\t\t\tcontinue;\n\n\t\tskb = skbs[i];\n\t\tskbs[i] = NULL;\n\n\t\tfor (frag = 0; frag <= skb_shinfo(skb)->nr_frags;  frag++) {\n\t\t\tint ent = i & (size - 1);\n\n\t\t\t \n\t\t\tdaddr = le64_to_cpu(txd[ent].buffer);\n\t\t\tdlen  =  CAS_VAL(TX_DESC_BUFLEN,\n\t\t\t\t\t le64_to_cpu(txd[ent].control));\n\t\t\tdma_unmap_page(&cp->pdev->dev, daddr, dlen,\n\t\t\t\t       DMA_TO_DEVICE);\n\n\t\t\tif (frag != skb_shinfo(skb)->nr_frags) {\n\t\t\t\ti++;\n\n\t\t\t\t \n\t\t\t\tent = i & (size - 1);\n\t\t\t\tif (cp->tx_tiny_use[ring][ent].used)\n\t\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\tdev_kfree_skb_any(skb);\n\t}\n\n\t \n\tmemset(cp->tx_tiny_use[ring], 0, size*sizeof(*cp->tx_tiny_use[ring]));\n}\n\n \nstatic inline void cas_free_rx_desc(struct cas *cp, int ring)\n{\n\tcas_page_t **page = cp->rx_pages[ring];\n\tint i, size;\n\n\tsize = RX_DESC_RINGN_SIZE(ring);\n\tfor (i = 0; i < size; i++) {\n\t\tif (page[i]) {\n\t\t\tcas_page_free(cp, page[i]);\n\t\t\tpage[i] = NULL;\n\t\t}\n\t}\n}\n\nstatic void cas_free_rxds(struct cas *cp)\n{\n\tint i;\n\n\tfor (i = 0; i < N_RX_DESC_RINGS; i++)\n\t\tcas_free_rx_desc(cp, i);\n}\n\n \nstatic void cas_clean_rings(struct cas *cp)\n{\n\tint i;\n\n\t \n\tmemset(cp->tx_old, 0, sizeof(*cp->tx_old)*N_TX_RINGS);\n\tmemset(cp->tx_new, 0, sizeof(*cp->tx_new)*N_TX_RINGS);\n\tfor (i = 0; i < N_TX_RINGS; i++)\n\t\tcas_clean_txd(cp, i);\n\n\t \n\tmemset(cp->init_block, 0, sizeof(struct cas_init_block));\n\tcas_clean_rxds(cp);\n\tcas_clean_rxcs(cp);\n}\n\n \nstatic inline int cas_alloc_rx_desc(struct cas *cp, int ring)\n{\n\tcas_page_t **page = cp->rx_pages[ring];\n\tint size, i = 0;\n\n\tsize = RX_DESC_RINGN_SIZE(ring);\n\tfor (i = 0; i < size; i++) {\n\t\tif ((page[i] = cas_page_alloc(cp, GFP_KERNEL)) == NULL)\n\t\t\treturn -1;\n\t}\n\treturn 0;\n}\n\nstatic int cas_alloc_rxds(struct cas *cp)\n{\n\tint i;\n\n\tfor (i = 0; i < N_RX_DESC_RINGS; i++) {\n\t\tif (cas_alloc_rx_desc(cp, i) < 0) {\n\t\t\tcas_free_rxds(cp);\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic void cas_reset_task(struct work_struct *work)\n{\n\tstruct cas *cp = container_of(work, struct cas, reset_task);\n#if 0\n\tint pending = atomic_read(&cp->reset_task_pending);\n#else\n\tint pending_all = atomic_read(&cp->reset_task_pending_all);\n\tint pending_spare = atomic_read(&cp->reset_task_pending_spare);\n\tint pending_mtu = atomic_read(&cp->reset_task_pending_mtu);\n\n\tif (pending_all == 0 && pending_spare == 0 && pending_mtu == 0) {\n\t\t \n\t\tatomic_dec(&cp->reset_task_pending);\n\t\treturn;\n\t}\n#endif\n\t \n\tif (cp->hw_running) {\n\t\tunsigned long flags;\n\n\t\t \n\t\tnetif_device_detach(cp->dev);\n\t\tcas_lock_all_save(cp, flags);\n\n\t\tif (cp->opened) {\n\t\t\t \n\t\t\tcas_spare_recover(cp, GFP_ATOMIC);\n\t\t}\n#if 1\n\t\t \n\t\tif (!pending_all && !pending_mtu)\n\t\t\tgoto done;\n#else\n\t\tif (pending == CAS_RESET_SPARE)\n\t\t\tgoto done;\n#endif\n\t\t \n#if 1\n\t\tcas_reset(cp, !(pending_all > 0));\n\t\tif (cp->opened)\n\t\t\tcas_clean_rings(cp);\n\t\tcas_init_hw(cp, (pending_all > 0));\n#else\n\t\tcas_reset(cp, !(pending == CAS_RESET_ALL));\n\t\tif (cp->opened)\n\t\t\tcas_clean_rings(cp);\n\t\tcas_init_hw(cp, pending == CAS_RESET_ALL);\n#endif\n\ndone:\n\t\tcas_unlock_all_restore(cp, flags);\n\t\tnetif_device_attach(cp->dev);\n\t}\n#if 1\n\tatomic_sub(pending_all, &cp->reset_task_pending_all);\n\tatomic_sub(pending_spare, &cp->reset_task_pending_spare);\n\tatomic_sub(pending_mtu, &cp->reset_task_pending_mtu);\n\tatomic_dec(&cp->reset_task_pending);\n#else\n\tatomic_set(&cp->reset_task_pending, 0);\n#endif\n}\n\nstatic void cas_link_timer(struct timer_list *t)\n{\n\tstruct cas *cp = from_timer(cp, t, link_timer);\n\tint mask, pending = 0, reset = 0;\n\tunsigned long flags;\n\n\tif (link_transition_timeout != 0 &&\n\t    cp->link_transition_jiffies_valid &&\n\t    time_is_before_jiffies(cp->link_transition_jiffies +\n\t      link_transition_timeout)) {\n\t\t \n\t\tcp->link_transition_jiffies_valid = 0;\n\t}\n\n\tif (!cp->hw_running)\n\t\treturn;\n\n\tspin_lock_irqsave(&cp->lock, flags);\n\tcas_lock_tx(cp);\n\tcas_entropy_gather(cp);\n\n\t \n#if 1\n\tif (atomic_read(&cp->reset_task_pending_all) ||\n\t    atomic_read(&cp->reset_task_pending_spare) ||\n\t    atomic_read(&cp->reset_task_pending_mtu))\n\t\tgoto done;\n#else\n\tif (atomic_read(&cp->reset_task_pending))\n\t\tgoto done;\n#endif\n\n\t \n\tif ((mask = (cp->cas_flags & CAS_FLAG_RXD_POST_MASK))) {\n\t\tint i, rmask;\n\n\t\tfor (i = 0; i < MAX_RX_DESC_RINGS; i++) {\n\t\t\trmask = CAS_FLAG_RXD_POST(i);\n\t\t\tif ((mask & rmask) == 0)\n\t\t\t\tcontinue;\n\n\t\t\t \n\t\t\tif (cas_post_rxds_ringN(cp, i, cp->rx_last[i]) < 0) {\n\t\t\t\tpending = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tcp->cas_flags &= ~rmask;\n\t\t}\n\t}\n\n\tif (CAS_PHY_MII(cp->phy_type)) {\n\t\tu16 bmsr;\n\t\tcas_mif_poll(cp, 0);\n\t\tbmsr = cas_phy_read(cp, MII_BMSR);\n\t\t \n\t\tbmsr = cas_phy_read(cp, MII_BMSR);\n\t\tcas_mif_poll(cp, 1);\n\t\treadl(cp->regs + REG_MIF_STATUS);  \n\t\treset = cas_mii_link_check(cp, bmsr);\n\t} else {\n\t\treset = cas_pcs_link_check(cp);\n\t}\n\n\tif (reset)\n\t\tgoto done;\n\n\t \n\tif ((readl(cp->regs + REG_MAC_TX_STATUS) & MAC_TX_FRAME_XMIT) == 0) {\n\t\tu32 val = readl(cp->regs + REG_MAC_STATE_MACHINE);\n\t\tu32 wptr, rptr;\n\t\tint tlm  = CAS_VAL(MAC_SM_TLM, val);\n\n\t\tif (((tlm == 0x5) || (tlm == 0x3)) &&\n\t\t    (CAS_VAL(MAC_SM_ENCAP_SM, val) == 0)) {\n\t\t\tnetif_printk(cp, tx_err, KERN_DEBUG, cp->dev,\n\t\t\t\t     \"tx err: MAC_STATE[%08x]\\n\", val);\n\t\t\treset = 1;\n\t\t\tgoto done;\n\t\t}\n\n\t\tval  = readl(cp->regs + REG_TX_FIFO_PKT_CNT);\n\t\twptr = readl(cp->regs + REG_TX_FIFO_WRITE_PTR);\n\t\trptr = readl(cp->regs + REG_TX_FIFO_READ_PTR);\n\t\tif ((val == 0) && (wptr != rptr)) {\n\t\t\tnetif_printk(cp, tx_err, KERN_DEBUG, cp->dev,\n\t\t\t\t     \"tx err: TX_FIFO[%08x:%08x:%08x]\\n\",\n\t\t\t\t     val, wptr, rptr);\n\t\t\treset = 1;\n\t\t}\n\n\t\tif (reset)\n\t\t\tcas_hard_reset(cp);\n\t}\n\ndone:\n\tif (reset) {\n#if 1\n\t\tatomic_inc(&cp->reset_task_pending);\n\t\tatomic_inc(&cp->reset_task_pending_all);\n\t\tschedule_work(&cp->reset_task);\n#else\n\t\tatomic_set(&cp->reset_task_pending, CAS_RESET_ALL);\n\t\tpr_err(\"reset called in cas_link_timer\\n\");\n\t\tschedule_work(&cp->reset_task);\n#endif\n\t}\n\n\tif (!pending)\n\t\tmod_timer(&cp->link_timer, jiffies + CAS_LINK_TIMEOUT);\n\tcas_unlock_tx(cp);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n}\n\n \nstatic void cas_tx_tiny_free(struct cas *cp)\n{\n\tstruct pci_dev *pdev = cp->pdev;\n\tint i;\n\n\tfor (i = 0; i < N_TX_RINGS; i++) {\n\t\tif (!cp->tx_tiny_bufs[i])\n\t\t\tcontinue;\n\n\t\tdma_free_coherent(&pdev->dev, TX_TINY_BUF_BLOCK,\n\t\t\t\t  cp->tx_tiny_bufs[i], cp->tx_tiny_dvma[i]);\n\t\tcp->tx_tiny_bufs[i] = NULL;\n\t}\n}\n\nstatic int cas_tx_tiny_alloc(struct cas *cp)\n{\n\tstruct pci_dev *pdev = cp->pdev;\n\tint i;\n\n\tfor (i = 0; i < N_TX_RINGS; i++) {\n\t\tcp->tx_tiny_bufs[i] =\n\t\t\tdma_alloc_coherent(&pdev->dev, TX_TINY_BUF_BLOCK,\n\t\t\t\t\t   &cp->tx_tiny_dvma[i], GFP_KERNEL);\n\t\tif (!cp->tx_tiny_bufs[i]) {\n\t\t\tcas_tx_tiny_free(cp);\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}\n\n\nstatic int cas_open(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tint hw_was_up, err;\n\tunsigned long flags;\n\n\tmutex_lock(&cp->pm_mutex);\n\n\thw_was_up = cp->hw_running;\n\n\t \n\tif (!cp->hw_running) {\n\t\t \n\t\tcas_lock_all_save(cp, flags);\n\t\t \n\t\tcas_reset(cp, 0);\n\t\tcp->hw_running = 1;\n\t\tcas_unlock_all_restore(cp, flags);\n\t}\n\n\terr = -ENOMEM;\n\tif (cas_tx_tiny_alloc(cp) < 0)\n\t\tgoto err_unlock;\n\n\t \n\tif (cas_alloc_rxds(cp) < 0)\n\t\tgoto err_tx_tiny;\n\n\t \n\tcas_spare_init(cp);\n\tcas_spare_recover(cp, GFP_KERNEL);\n\n\t \n\tif (request_irq(cp->pdev->irq, cas_interrupt,\n\t\t\tIRQF_SHARED, dev->name, (void *) dev)) {\n\t\tnetdev_err(cp->dev, \"failed to request irq !\\n\");\n\t\terr = -EAGAIN;\n\t\tgoto err_spare;\n\t}\n\n#ifdef USE_NAPI\n\tnapi_enable(&cp->napi);\n#endif\n\t \n\tcas_lock_all_save(cp, flags);\n\tcas_clean_rings(cp);\n\tcas_init_hw(cp, !hw_was_up);\n\tcp->opened = 1;\n\tcas_unlock_all_restore(cp, flags);\n\n\tnetif_start_queue(dev);\n\tmutex_unlock(&cp->pm_mutex);\n\treturn 0;\n\nerr_spare:\n\tcas_spare_free(cp);\n\tcas_free_rxds(cp);\nerr_tx_tiny:\n\tcas_tx_tiny_free(cp);\nerr_unlock:\n\tmutex_unlock(&cp->pm_mutex);\n\treturn err;\n}\n\nstatic int cas_close(struct net_device *dev)\n{\n\tunsigned long flags;\n\tstruct cas *cp = netdev_priv(dev);\n\n#ifdef USE_NAPI\n\tnapi_disable(&cp->napi);\n#endif\n\t \n\tmutex_lock(&cp->pm_mutex);\n\n\tnetif_stop_queue(dev);\n\n\t \n\tcas_lock_all_save(cp, flags);\n\tcp->opened = 0;\n\tcas_reset(cp, 0);\n\tcas_phy_init(cp);\n\tcas_begin_auto_negotiation(cp, NULL);\n\tcas_clean_rings(cp);\n\tcas_unlock_all_restore(cp, flags);\n\n\tfree_irq(cp->pdev->irq, (void *) dev);\n\tcas_spare_free(cp);\n\tcas_free_rxds(cp);\n\tcas_tx_tiny_free(cp);\n\tmutex_unlock(&cp->pm_mutex);\n\treturn 0;\n}\n\nstatic struct {\n\tconst char name[ETH_GSTRING_LEN];\n} ethtool_cassini_statnames[] = {\n\t{\"collisions\"},\n\t{\"rx_bytes\"},\n\t{\"rx_crc_errors\"},\n\t{\"rx_dropped\"},\n\t{\"rx_errors\"},\n\t{\"rx_fifo_errors\"},\n\t{\"rx_frame_errors\"},\n\t{\"rx_length_errors\"},\n\t{\"rx_over_errors\"},\n\t{\"rx_packets\"},\n\t{\"tx_aborted_errors\"},\n\t{\"tx_bytes\"},\n\t{\"tx_dropped\"},\n\t{\"tx_errors\"},\n\t{\"tx_fifo_errors\"},\n\t{\"tx_packets\"}\n};\n#define CAS_NUM_STAT_KEYS ARRAY_SIZE(ethtool_cassini_statnames)\n\nstatic struct {\n\tconst int offsets;\t \n} ethtool_register_table[] = {\n\t{-MII_BMSR},\n\t{-MII_BMCR},\n\t{REG_CAWR},\n\t{REG_INF_BURST},\n\t{REG_BIM_CFG},\n\t{REG_RX_CFG},\n\t{REG_HP_CFG},\n\t{REG_MAC_TX_CFG},\n\t{REG_MAC_RX_CFG},\n\t{REG_MAC_CTRL_CFG},\n\t{REG_MAC_XIF_CFG},\n\t{REG_MIF_CFG},\n\t{REG_PCS_CFG},\n\t{REG_SATURN_PCFG},\n\t{REG_PCS_MII_STATUS},\n\t{REG_PCS_STATE_MACHINE},\n\t{REG_MAC_COLL_EXCESS},\n\t{REG_MAC_COLL_LATE}\n};\n#define CAS_REG_LEN \tARRAY_SIZE(ethtool_register_table)\n#define CAS_MAX_REGS \t(sizeof (u32)*CAS_REG_LEN)\n\nstatic void cas_read_regs(struct cas *cp, u8 *ptr, int len)\n{\n\tu8 *p;\n\tint i;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cp->lock, flags);\n\tfor (i = 0, p = ptr; i < len ; i ++, p += sizeof(u32)) {\n\t\tu16 hval;\n\t\tu32 val;\n\t\tif (ethtool_register_table[i].offsets < 0) {\n\t\t\thval = cas_phy_read(cp,\n\t\t\t\t    -ethtool_register_table[i].offsets);\n\t\t\tval = hval;\n\t\t} else {\n\t\t\tval= readl(cp->regs+ethtool_register_table[i].offsets);\n\t\t}\n\t\tmemcpy(p, (u8 *)&val, sizeof(u32));\n\t}\n\tspin_unlock_irqrestore(&cp->lock, flags);\n}\n\nstatic struct net_device_stats *cas_get_stats(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tstruct net_device_stats *stats = cp->net_stats;\n\tunsigned long flags;\n\tint i;\n\tunsigned long tmp;\n\n\t \n\tif (!cp->hw_running)\n\t\treturn stats + N_TX_RINGS;\n\n\t \n\t \n\tspin_lock_irqsave(&cp->stat_lock[N_TX_RINGS], flags);\n\tstats[N_TX_RINGS].rx_crc_errors +=\n\t  readl(cp->regs + REG_MAC_FCS_ERR) & 0xffff;\n\tstats[N_TX_RINGS].rx_frame_errors +=\n\t\treadl(cp->regs + REG_MAC_ALIGN_ERR) &0xffff;\n\tstats[N_TX_RINGS].rx_length_errors +=\n\t\treadl(cp->regs + REG_MAC_LEN_ERR) & 0xffff;\n#if 1\n\ttmp = (readl(cp->regs + REG_MAC_COLL_EXCESS) & 0xffff) +\n\t\t(readl(cp->regs + REG_MAC_COLL_LATE) & 0xffff);\n\tstats[N_TX_RINGS].tx_aborted_errors += tmp;\n\tstats[N_TX_RINGS].collisions +=\n\t  tmp + (readl(cp->regs + REG_MAC_COLL_NORMAL) & 0xffff);\n#else\n\tstats[N_TX_RINGS].tx_aborted_errors +=\n\t\treadl(cp->regs + REG_MAC_COLL_EXCESS);\n\tstats[N_TX_RINGS].collisions += readl(cp->regs + REG_MAC_COLL_EXCESS) +\n\t\treadl(cp->regs + REG_MAC_COLL_LATE);\n#endif\n\tcas_clear_mac_err(cp);\n\n\t \n\tspin_lock(&cp->stat_lock[0]);\n\tstats[N_TX_RINGS].collisions        += stats[0].collisions;\n\tstats[N_TX_RINGS].rx_over_errors    += stats[0].rx_over_errors;\n\tstats[N_TX_RINGS].rx_frame_errors   += stats[0].rx_frame_errors;\n\tstats[N_TX_RINGS].rx_fifo_errors    += stats[0].rx_fifo_errors;\n\tstats[N_TX_RINGS].tx_aborted_errors += stats[0].tx_aborted_errors;\n\tstats[N_TX_RINGS].tx_fifo_errors    += stats[0].tx_fifo_errors;\n\tspin_unlock(&cp->stat_lock[0]);\n\n\tfor (i = 0; i < N_TX_RINGS; i++) {\n\t\tspin_lock(&cp->stat_lock[i]);\n\t\tstats[N_TX_RINGS].rx_length_errors +=\n\t\t\tstats[i].rx_length_errors;\n\t\tstats[N_TX_RINGS].rx_crc_errors += stats[i].rx_crc_errors;\n\t\tstats[N_TX_RINGS].rx_packets    += stats[i].rx_packets;\n\t\tstats[N_TX_RINGS].tx_packets    += stats[i].tx_packets;\n\t\tstats[N_TX_RINGS].rx_bytes      += stats[i].rx_bytes;\n\t\tstats[N_TX_RINGS].tx_bytes      += stats[i].tx_bytes;\n\t\tstats[N_TX_RINGS].rx_errors     += stats[i].rx_errors;\n\t\tstats[N_TX_RINGS].tx_errors     += stats[i].tx_errors;\n\t\tstats[N_TX_RINGS].rx_dropped    += stats[i].rx_dropped;\n\t\tstats[N_TX_RINGS].tx_dropped    += stats[i].tx_dropped;\n\t\tmemset(stats + i, 0, sizeof(struct net_device_stats));\n\t\tspin_unlock(&cp->stat_lock[i]);\n\t}\n\tspin_unlock_irqrestore(&cp->stat_lock[N_TX_RINGS], flags);\n\treturn stats + N_TX_RINGS;\n}\n\n\nstatic void cas_set_multicast(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tu32 rxcfg, rxcfg_new;\n\tunsigned long flags;\n\tint limit = STOP_TRIES;\n\n\tif (!cp->hw_running)\n\t\treturn;\n\n\tspin_lock_irqsave(&cp->lock, flags);\n\trxcfg = readl(cp->regs + REG_MAC_RX_CFG);\n\n\t \n\twritel(rxcfg & ~MAC_RX_CFG_EN, cp->regs + REG_MAC_RX_CFG);\n\twhile (readl(cp->regs + REG_MAC_RX_CFG) & MAC_RX_CFG_EN) {\n\t\tif (!limit--)\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\n\t \n\tlimit = STOP_TRIES;\n\trxcfg &= ~(MAC_RX_CFG_PROMISC_EN | MAC_RX_CFG_HASH_FILTER_EN);\n\twritel(rxcfg & ~MAC_RX_CFG_EN, cp->regs + REG_MAC_RX_CFG);\n\twhile (readl(cp->regs + REG_MAC_RX_CFG) & MAC_RX_CFG_HASH_FILTER_EN) {\n\t\tif (!limit--)\n\t\t\tbreak;\n\t\tudelay(10);\n\t}\n\n\t \n\tcp->mac_rx_cfg = rxcfg_new = cas_setup_multicast(cp);\n\trxcfg |= rxcfg_new;\n\twritel(rxcfg, cp->regs + REG_MAC_RX_CFG);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n}\n\nstatic void cas_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tstrscpy(info->driver, DRV_MODULE_NAME, sizeof(info->driver));\n\tstrscpy(info->version, DRV_MODULE_VERSION, sizeof(info->version));\n\tstrscpy(info->bus_info, pci_name(cp->pdev), sizeof(info->bus_info));\n}\n\nstatic int cas_get_link_ksettings(struct net_device *dev,\n\t\t\t\t  struct ethtool_link_ksettings *cmd)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tu16 bmcr;\n\tint full_duplex, speed, pause;\n\tunsigned long flags;\n\tenum link_state linkstate = link_up;\n\tu32 supported, advertising;\n\n\tadvertising = 0;\n\tsupported = SUPPORTED_Autoneg;\n\tif (cp->cas_flags & CAS_FLAG_1000MB_CAP) {\n\t\tsupported |= SUPPORTED_1000baseT_Full;\n\t\tadvertising |= ADVERTISED_1000baseT_Full;\n\t}\n\n\t \n\tspin_lock_irqsave(&cp->lock, flags);\n\tbmcr = 0;\n\tlinkstate = cp->lstate;\n\tif (CAS_PHY_MII(cp->phy_type)) {\n\t\tcmd->base.port = PORT_MII;\n\t\tcmd->base.phy_address = cp->phy_addr;\n\t\tadvertising |= ADVERTISED_TP | ADVERTISED_MII |\n\t\t\tADVERTISED_10baseT_Half |\n\t\t\tADVERTISED_10baseT_Full |\n\t\t\tADVERTISED_100baseT_Half |\n\t\t\tADVERTISED_100baseT_Full;\n\n\t\tsupported |=\n\t\t\t(SUPPORTED_10baseT_Half |\n\t\t\t SUPPORTED_10baseT_Full |\n\t\t\t SUPPORTED_100baseT_Half |\n\t\t\t SUPPORTED_100baseT_Full |\n\t\t\t SUPPORTED_TP | SUPPORTED_MII);\n\n\t\tif (cp->hw_running) {\n\t\t\tcas_mif_poll(cp, 0);\n\t\t\tbmcr = cas_phy_read(cp, MII_BMCR);\n\t\t\tcas_read_mii_link_mode(cp, &full_duplex,\n\t\t\t\t\t       &speed, &pause);\n\t\t\tcas_mif_poll(cp, 1);\n\t\t}\n\n\t} else {\n\t\tcmd->base.port = PORT_FIBRE;\n\t\tcmd->base.phy_address = 0;\n\t\tsupported   |= SUPPORTED_FIBRE;\n\t\tadvertising |= ADVERTISED_FIBRE;\n\n\t\tif (cp->hw_running) {\n\t\t\t \n\t\t\tbmcr = readl(cp->regs + REG_PCS_MII_CTRL);\n\t\t\tcas_read_pcs_link_mode(cp, &full_duplex,\n\t\t\t\t\t       &speed, &pause);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\n\tif (bmcr & BMCR_ANENABLE) {\n\t\tadvertising |= ADVERTISED_Autoneg;\n\t\tcmd->base.autoneg = AUTONEG_ENABLE;\n\t\tcmd->base.speed =  ((speed == 10) ?\n\t\t\t\t\t    SPEED_10 :\n\t\t\t\t\t    ((speed == 1000) ?\n\t\t\t\t\t     SPEED_1000 : SPEED_100));\n\t\tcmd->base.duplex = full_duplex ? DUPLEX_FULL : DUPLEX_HALF;\n\t} else {\n\t\tcmd->base.autoneg = AUTONEG_DISABLE;\n\t\tcmd->base.speed = ((bmcr & CAS_BMCR_SPEED1000) ?\n\t\t\t\t\t    SPEED_1000 :\n\t\t\t\t\t    ((bmcr & BMCR_SPEED100) ?\n\t\t\t\t\t     SPEED_100 : SPEED_10));\n\t\tcmd->base.duplex = (bmcr & BMCR_FULLDPLX) ?\n\t\t\tDUPLEX_FULL : DUPLEX_HALF;\n\t}\n\tif (linkstate != link_up) {\n\t\t \n\t\tif (cp->link_cntl & BMCR_ANENABLE) {\n\t\t\tcmd->base.speed = 0;\n\t\t\tcmd->base.duplex = 0xff;\n\t\t} else {\n\t\t\tcmd->base.speed = SPEED_10;\n\t\t\tif (cp->link_cntl & BMCR_SPEED100) {\n\t\t\t\tcmd->base.speed = SPEED_100;\n\t\t\t} else if (cp->link_cntl & CAS_BMCR_SPEED1000) {\n\t\t\t\tcmd->base.speed = SPEED_1000;\n\t\t\t}\n\t\t\tcmd->base.duplex = (cp->link_cntl & BMCR_FULLDPLX) ?\n\t\t\t\tDUPLEX_FULL : DUPLEX_HALF;\n\t\t}\n\t}\n\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported,\n\t\t\t\t\t\tsupported);\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.advertising,\n\t\t\t\t\t\tadvertising);\n\n\treturn 0;\n}\n\nstatic int cas_set_link_ksettings(struct net_device *dev,\n\t\t\t\t  const struct ethtool_link_ksettings *cmd)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tunsigned long flags;\n\tu32 speed = cmd->base.speed;\n\n\t \n\tif (cmd->base.autoneg != AUTONEG_ENABLE &&\n\t    cmd->base.autoneg != AUTONEG_DISABLE)\n\t\treturn -EINVAL;\n\n\tif (cmd->base.autoneg == AUTONEG_DISABLE &&\n\t    ((speed != SPEED_1000 &&\n\t      speed != SPEED_100 &&\n\t      speed != SPEED_10) ||\n\t     (cmd->base.duplex != DUPLEX_HALF &&\n\t      cmd->base.duplex != DUPLEX_FULL)))\n\t\treturn -EINVAL;\n\n\t \n\tspin_lock_irqsave(&cp->lock, flags);\n\tcas_begin_auto_negotiation(cp, cmd);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\treturn 0;\n}\n\nstatic int cas_nway_reset(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tunsigned long flags;\n\n\tif ((cp->link_cntl & BMCR_ANENABLE) == 0)\n\t\treturn -EINVAL;\n\n\t \n\tspin_lock_irqsave(&cp->lock, flags);\n\tcas_begin_auto_negotiation(cp, NULL);\n\tspin_unlock_irqrestore(&cp->lock, flags);\n\n\treturn 0;\n}\n\nstatic u32 cas_get_link(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\treturn cp->lstate == link_up;\n}\n\nstatic u32 cas_get_msglevel(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\treturn cp->msg_enable;\n}\n\nstatic void cas_set_msglevel(struct net_device *dev, u32 value)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tcp->msg_enable = value;\n}\n\nstatic int cas_get_regs_len(struct net_device *dev)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\treturn min_t(int, cp->casreg_len, CAS_MAX_REGS);\n}\n\nstatic void cas_get_regs(struct net_device *dev, struct ethtool_regs *regs,\n\t\t\t     void *p)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tregs->version = 0;\n\t \n\tcas_read_regs(cp, p, regs->len / sizeof(u32));\n}\n\nstatic int cas_get_sset_count(struct net_device *dev, int sset)\n{\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn CAS_NUM_STAT_KEYS;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void cas_get_strings(struct net_device *dev, u32 stringset, u8 *data)\n{\n\t memcpy(data, &ethtool_cassini_statnames,\n\t\t\t\t\t CAS_NUM_STAT_KEYS * ETH_GSTRING_LEN);\n}\n\nstatic void cas_get_ethtool_stats(struct net_device *dev,\n\t\t\t\t      struct ethtool_stats *estats, u64 *data)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tstruct net_device_stats *stats = cas_get_stats(cp->dev);\n\tint i = 0;\n\tdata[i++] = stats->collisions;\n\tdata[i++] = stats->rx_bytes;\n\tdata[i++] = stats->rx_crc_errors;\n\tdata[i++] = stats->rx_dropped;\n\tdata[i++] = stats->rx_errors;\n\tdata[i++] = stats->rx_fifo_errors;\n\tdata[i++] = stats->rx_frame_errors;\n\tdata[i++] = stats->rx_length_errors;\n\tdata[i++] = stats->rx_over_errors;\n\tdata[i++] = stats->rx_packets;\n\tdata[i++] = stats->tx_aborted_errors;\n\tdata[i++] = stats->tx_bytes;\n\tdata[i++] = stats->tx_dropped;\n\tdata[i++] = stats->tx_errors;\n\tdata[i++] = stats->tx_fifo_errors;\n\tdata[i++] = stats->tx_packets;\n\tBUG_ON(i != CAS_NUM_STAT_KEYS);\n}\n\nstatic const struct ethtool_ops cas_ethtool_ops = {\n\t.get_drvinfo\t\t= cas_get_drvinfo,\n\t.nway_reset\t\t= cas_nway_reset,\n\t.get_link\t\t= cas_get_link,\n\t.get_msglevel\t\t= cas_get_msglevel,\n\t.set_msglevel\t\t= cas_set_msglevel,\n\t.get_regs_len\t\t= cas_get_regs_len,\n\t.get_regs\t\t= cas_get_regs,\n\t.get_sset_count\t\t= cas_get_sset_count,\n\t.get_strings\t\t= cas_get_strings,\n\t.get_ethtool_stats\t= cas_get_ethtool_stats,\n\t.get_link_ksettings\t= cas_get_link_ksettings,\n\t.set_link_ksettings\t= cas_set_link_ksettings,\n};\n\nstatic int cas_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct cas *cp = netdev_priv(dev);\n\tstruct mii_ioctl_data *data = if_mii(ifr);\n\tunsigned long flags;\n\tint rc = -EOPNOTSUPP;\n\n\t \n\tmutex_lock(&cp->pm_mutex);\n\tswitch (cmd) {\n\tcase SIOCGMIIPHY:\t\t \n\t\tdata->phy_id = cp->phy_addr;\n\t\tfallthrough;\n\n\tcase SIOCGMIIREG:\t\t \n\t\tspin_lock_irqsave(&cp->lock, flags);\n\t\tcas_mif_poll(cp, 0);\n\t\tdata->val_out = cas_phy_read(cp, data->reg_num & 0x1f);\n\t\tcas_mif_poll(cp, 1);\n\t\tspin_unlock_irqrestore(&cp->lock, flags);\n\t\trc = 0;\n\t\tbreak;\n\n\tcase SIOCSMIIREG:\t\t \n\t\tspin_lock_irqsave(&cp->lock, flags);\n\t\tcas_mif_poll(cp, 0);\n\t\trc = cas_phy_write(cp, data->reg_num & 0x1f, data->val_in);\n\t\tcas_mif_poll(cp, 1);\n\t\tspin_unlock_irqrestore(&cp->lock, flags);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tmutex_unlock(&cp->pm_mutex);\n\treturn rc;\n}\n\n \nstatic void cas_program_bridge(struct pci_dev *cas_pdev)\n{\n\tstruct pci_dev *pdev = cas_pdev->bus->self;\n\tu32 val;\n\n\tif (!pdev)\n\t\treturn;\n\n\tif (pdev->vendor != 0x8086 || pdev->device != 0x537c)\n\t\treturn;\n\n\t \n\tpci_read_config_dword(pdev, 0x40, &val);\n\tval &= ~0x00040000;\n\tpci_write_config_dword(pdev, 0x40, val);\n\n\t \n\tpci_write_config_word(pdev, 0x50, (5 << 10) | 0x3ff);\n\n\t \n\tpci_write_config_word(pdev, 0x52,\n\t\t\t      (0x7 << 13) |\n\t\t\t      (0x7 << 10) |\n\t\t\t      (0x7 <<  7) |\n\t\t\t      (0x7 <<  4) |\n\t\t\t      (0xf <<  0));\n\n\t \n\tpci_write_config_byte(pdev, PCI_CACHE_LINE_SIZE, 0x08);\n\n\t \n\tpci_write_config_byte(pdev, PCI_LATENCY_TIMER, 0xff);\n}\n\nstatic const struct net_device_ops cas_netdev_ops = {\n\t.ndo_open\t\t= cas_open,\n\t.ndo_stop\t\t= cas_close,\n\t.ndo_start_xmit\t\t= cas_start_xmit,\n\t.ndo_get_stats \t\t= cas_get_stats,\n\t.ndo_set_rx_mode\t= cas_set_multicast,\n\t.ndo_eth_ioctl\t\t= cas_ioctl,\n\t.ndo_tx_timeout\t\t= cas_tx_timeout,\n\t.ndo_change_mtu\t\t= cas_change_mtu,\n\t.ndo_set_mac_address\t= eth_mac_addr,\n\t.ndo_validate_addr\t= eth_validate_addr,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= cas_netpoll,\n#endif\n};\n\nstatic int cas_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\n{\n\tstatic int cas_version_printed = 0;\n\tunsigned long casreg_len;\n\tstruct net_device *dev;\n\tstruct cas *cp;\n\tu16 pci_cmd;\n\tint i, err;\n\tu8 orig_cacheline_size = 0, cas_cacheline_size = 0;\n\n\tif (cas_version_printed++ == 0)\n\t\tpr_info(\"%s\", version);\n\n\terr = pci_enable_device(pdev);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Cannot enable PCI device, aborting\\n\");\n\t\treturn err;\n\t}\n\n\tif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\n\t\tdev_err(&pdev->dev, \"Cannot find proper PCI device \"\n\t\t       \"base address, aborting\\n\");\n\t\terr = -ENODEV;\n\t\tgoto err_out_disable_pdev;\n\t}\n\n\tdev = alloc_etherdev(sizeof(*cp));\n\tif (!dev) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out_disable_pdev;\n\t}\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\terr = pci_request_regions(pdev, dev->name);\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"Cannot obtain PCI resources, aborting\\n\");\n\t\tgoto err_out_free_netdev;\n\t}\n\tpci_set_master(pdev);\n\n\t \n\tpci_read_config_word(pdev, PCI_COMMAND, &pci_cmd);\n\tpci_cmd &= ~PCI_COMMAND_SERR;\n\tpci_cmd |= PCI_COMMAND_PARITY;\n\tpci_write_config_word(pdev, PCI_COMMAND, pci_cmd);\n\tif (pci_try_set_mwi(pdev))\n\t\tpr_warn(\"Could not enable MWI for %s\\n\", pci_name(pdev));\n\n\tcas_program_bridge(pdev);\n\n\t \n#if 1\n\tpci_read_config_byte(pdev, PCI_CACHE_LINE_SIZE,\n\t\t\t     &orig_cacheline_size);\n\tif (orig_cacheline_size < CAS_PREF_CACHELINE_SIZE) {\n\t\tcas_cacheline_size =\n\t\t\t(CAS_PREF_CACHELINE_SIZE < SMP_CACHE_BYTES) ?\n\t\t\tCAS_PREF_CACHELINE_SIZE : SMP_CACHE_BYTES;\n\t\tif (pci_write_config_byte(pdev,\n\t\t\t\t\t  PCI_CACHE_LINE_SIZE,\n\t\t\t\t\t  cas_cacheline_size)) {\n\t\t\tdev_err(&pdev->dev, \"Could not set PCI cache \"\n\t\t\t       \"line size\\n\");\n\t\t\tgoto err_out_free_res;\n\t\t}\n\t}\n#endif\n\n\n\t \n\terr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (err) {\n\t\tdev_err(&pdev->dev, \"No usable DMA configuration, aborting\\n\");\n\t\tgoto err_out_free_res;\n\t}\n\n\tcasreg_len = pci_resource_len(pdev, 0);\n\n\tcp = netdev_priv(dev);\n\tcp->pdev = pdev;\n#if 1\n\t \n\tcp->orig_cacheline_size = cas_cacheline_size ? orig_cacheline_size: 0;\n#endif\n\tcp->dev = dev;\n\tcp->msg_enable = (cassini_debug < 0) ? CAS_DEF_MSG_ENABLE :\n\t  cassini_debug;\n\n#if defined(CONFIG_SPARC)\n\tcp->of_node = pci_device_to_OF_node(pdev);\n#endif\n\n\tcp->link_transition = LINK_TRANSITION_UNKNOWN;\n\tcp->link_transition_jiffies_valid = 0;\n\n\tspin_lock_init(&cp->lock);\n\tspin_lock_init(&cp->rx_inuse_lock);\n\tspin_lock_init(&cp->rx_spare_lock);\n\tfor (i = 0; i < N_TX_RINGS; i++) {\n\t\tspin_lock_init(&cp->stat_lock[i]);\n\t\tspin_lock_init(&cp->tx_lock[i]);\n\t}\n\tspin_lock_init(&cp->stat_lock[N_TX_RINGS]);\n\tmutex_init(&cp->pm_mutex);\n\n\ttimer_setup(&cp->link_timer, cas_link_timer, 0);\n\n#if 1\n\t \n\tatomic_set(&cp->reset_task_pending, 0);\n\tatomic_set(&cp->reset_task_pending_all, 0);\n\tatomic_set(&cp->reset_task_pending_spare, 0);\n\tatomic_set(&cp->reset_task_pending_mtu, 0);\n#endif\n\tINIT_WORK(&cp->reset_task, cas_reset_task);\n\n\t \n\tif (link_mode >= 0 && link_mode < 6)\n\t\tcp->link_cntl = link_modes[link_mode];\n\telse\n\t\tcp->link_cntl = BMCR_ANENABLE;\n\tcp->lstate = link_down;\n\tcp->link_transition = LINK_TRANSITION_LINK_DOWN;\n\tnetif_carrier_off(cp->dev);\n\tcp->timer_ticks = 0;\n\n\t \n\tcp->regs = pci_iomap(pdev, 0, casreg_len);\n\tif (!cp->regs) {\n\t\tdev_err(&pdev->dev, \"Cannot map device registers, aborting\\n\");\n\t\tgoto err_out_free_res;\n\t}\n\tcp->casreg_len = casreg_len;\n\n\tpci_save_state(pdev);\n\tcas_check_pci_invariants(cp);\n\tcas_hard_reset(cp);\n\tcas_reset(cp, 0);\n\tif (cas_check_invariants(cp))\n\t\tgoto err_out_iounmap;\n\tif (cp->cas_flags & CAS_FLAG_SATURN)\n\t\tcas_saturn_firmware_init(cp);\n\n\tcp->init_block =\n\t\tdma_alloc_coherent(&pdev->dev, sizeof(struct cas_init_block),\n\t\t\t\t   &cp->block_dvma, GFP_KERNEL);\n\tif (!cp->init_block) {\n\t\tdev_err(&pdev->dev, \"Cannot allocate init block, aborting\\n\");\n\t\tgoto err_out_iounmap;\n\t}\n\n\tfor (i = 0; i < N_TX_RINGS; i++)\n\t\tcp->init_txds[i] = cp->init_block->txds[i];\n\n\tfor (i = 0; i < N_RX_DESC_RINGS; i++)\n\t\tcp->init_rxds[i] = cp->init_block->rxds[i];\n\n\tfor (i = 0; i < N_RX_COMP_RINGS; i++)\n\t\tcp->init_rxcs[i] = cp->init_block->rxcs[i];\n\n\tfor (i = 0; i < N_RX_FLOWS; i++)\n\t\tskb_queue_head_init(&cp->rx_flows[i]);\n\n\tdev->netdev_ops = &cas_netdev_ops;\n\tdev->ethtool_ops = &cas_ethtool_ops;\n\tdev->watchdog_timeo = CAS_TX_TIMEOUT;\n\n#ifdef USE_NAPI\n\tnetif_napi_add(dev, &cp->napi, cas_poll);\n#endif\n\tdev->irq = pdev->irq;\n\tdev->dma = 0;\n\n\t \n\tif ((cp->cas_flags & CAS_FLAG_NO_HW_CSUM) == 0)\n\t\tdev->features |= NETIF_F_HW_CSUM | NETIF_F_SG;\n\n\tdev->features |= NETIF_F_HIGHDMA;\n\n\t \n\tdev->min_mtu = CAS_MIN_MTU;\n\tdev->max_mtu = CAS_MAX_MTU;\n\n\tif (register_netdev(dev)) {\n\t\tdev_err(&pdev->dev, \"Cannot register net device, aborting\\n\");\n\t\tgoto err_out_free_consistent;\n\t}\n\n\ti = readl(cp->regs + REG_BIM_CFG);\n\tnetdev_info(dev, \"Sun Cassini%s (%sbit/%sMHz PCI/%s) Ethernet[%d] %pM\\n\",\n\t\t    (cp->cas_flags & CAS_FLAG_REG_PLUS) ? \"+\" : \"\",\n\t\t    (i & BIM_CFG_32BIT) ? \"32\" : \"64\",\n\t\t    (i & BIM_CFG_66MHZ) ? \"66\" : \"33\",\n\t\t    (cp->phy_type == CAS_PHY_SERDES) ? \"Fi\" : \"Cu\", pdev->irq,\n\t\t    dev->dev_addr);\n\n\tpci_set_drvdata(pdev, dev);\n\tcp->hw_running = 1;\n\tcas_entropy_reset(cp);\n\tcas_phy_init(cp);\n\tcas_begin_auto_negotiation(cp, NULL);\n\treturn 0;\n\nerr_out_free_consistent:\n\tdma_free_coherent(&pdev->dev, sizeof(struct cas_init_block),\n\t\t\t  cp->init_block, cp->block_dvma);\n\nerr_out_iounmap:\n\tmutex_lock(&cp->pm_mutex);\n\tif (cp->hw_running)\n\t\tcas_shutdown(cp);\n\tmutex_unlock(&cp->pm_mutex);\n\n\tvfree(cp->fw_data);\n\n\tpci_iounmap(pdev, cp->regs);\n\n\nerr_out_free_res:\n\tpci_release_regions(pdev);\n\n\t \n\tpci_write_config_byte(pdev, PCI_CACHE_LINE_SIZE, orig_cacheline_size);\n\nerr_out_free_netdev:\n\tfree_netdev(dev);\n\nerr_out_disable_pdev:\n\tpci_disable_device(pdev);\n\treturn -ENODEV;\n}\n\nstatic void cas_remove_one(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\tstruct cas *cp;\n\tif (!dev)\n\t\treturn;\n\n\tcp = netdev_priv(dev);\n\tunregister_netdev(dev);\n\n\tvfree(cp->fw_data);\n\n\tmutex_lock(&cp->pm_mutex);\n\tcancel_work_sync(&cp->reset_task);\n\tif (cp->hw_running)\n\t\tcas_shutdown(cp);\n\tmutex_unlock(&cp->pm_mutex);\n\n#if 1\n\tif (cp->orig_cacheline_size) {\n\t\t \n\t\tpci_write_config_byte(pdev, PCI_CACHE_LINE_SIZE,\n\t\t\t\t      cp->orig_cacheline_size);\n\t}\n#endif\n\tdma_free_coherent(&pdev->dev, sizeof(struct cas_init_block),\n\t\t\t  cp->init_block, cp->block_dvma);\n\tpci_iounmap(pdev, cp->regs);\n\tfree_netdev(dev);\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n}\n\nstatic int __maybe_unused cas_suspend(struct device *dev_d)\n{\n\tstruct net_device *dev = dev_get_drvdata(dev_d);\n\tstruct cas *cp = netdev_priv(dev);\n\tunsigned long flags;\n\n\tmutex_lock(&cp->pm_mutex);\n\n\t \n\tif (cp->opened) {\n\t\tnetif_device_detach(dev);\n\n\t\tcas_lock_all_save(cp, flags);\n\n\t\t \n\t\tcas_reset(cp, 0);\n\t\tcas_clean_rings(cp);\n\t\tcas_unlock_all_restore(cp, flags);\n\t}\n\n\tif (cp->hw_running)\n\t\tcas_shutdown(cp);\n\tmutex_unlock(&cp->pm_mutex);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused cas_resume(struct device *dev_d)\n{\n\tstruct net_device *dev = dev_get_drvdata(dev_d);\n\tstruct cas *cp = netdev_priv(dev);\n\n\tnetdev_info(dev, \"resuming\\n\");\n\n\tmutex_lock(&cp->pm_mutex);\n\tcas_hard_reset(cp);\n\tif (cp->opened) {\n\t\tunsigned long flags;\n\t\tcas_lock_all_save(cp, flags);\n\t\tcas_reset(cp, 0);\n\t\tcp->hw_running = 1;\n\t\tcas_clean_rings(cp);\n\t\tcas_init_hw(cp, 1);\n\t\tcas_unlock_all_restore(cp, flags);\n\n\t\tnetif_device_attach(dev);\n\t}\n\tmutex_unlock(&cp->pm_mutex);\n\treturn 0;\n}\n\nstatic SIMPLE_DEV_PM_OPS(cas_pm_ops, cas_suspend, cas_resume);\n\nstatic struct pci_driver cas_driver = {\n\t.name\t\t= DRV_MODULE_NAME,\n\t.id_table\t= cas_pci_tbl,\n\t.probe\t\t= cas_init_one,\n\t.remove\t\t= cas_remove_one,\n\t.driver.pm\t= &cas_pm_ops,\n};\n\nstatic int __init cas_init(void)\n{\n\tif (linkdown_timeout > 0)\n\t\tlink_transition_timeout = linkdown_timeout * HZ;\n\telse\n\t\tlink_transition_timeout = 0;\n\n\treturn pci_register_driver(&cas_driver);\n}\n\nstatic void __exit cas_cleanup(void)\n{\n\tpci_unregister_driver(&cas_driver);\n}\n\nmodule_init(cas_init);\nmodule_exit(cas_cleanup);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}