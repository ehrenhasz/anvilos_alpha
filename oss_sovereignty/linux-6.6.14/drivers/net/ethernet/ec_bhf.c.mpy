{
  "module_name": "ec_bhf.c",
  "hash_id": "c19da78bf443194d9ffddf14538ca8a7aa0ca9fef900381a2912b9beff6dd2e5",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/ec_bhf.c",
  "human_readable_source": "\n  \n\n \n\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/moduleparam.h>\n#include <linux/pci.h>\n#include <linux/init.h>\n\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ip.h>\n#include <linux/skbuff.h>\n#include <linux/hrtimer.h>\n#include <linux/interrupt.h>\n#include <linux/stat.h>\n\n#define TIMER_INTERVAL_NSEC\t20000\n\n#define INFO_BLOCK_SIZE\t\t0x10\n#define INFO_BLOCK_TYPE\t\t0x0\n#define INFO_BLOCK_REV\t\t0x2\n#define INFO_BLOCK_BLK_CNT\t0x4\n#define INFO_BLOCK_TX_CHAN\t0x4\n#define INFO_BLOCK_RX_CHAN\t0x5\n#define INFO_BLOCK_OFFSET\t0x8\n\n#define EC_MII_OFFSET\t\t0x4\n#define EC_FIFO_OFFSET\t\t0x8\n#define EC_MAC_OFFSET\t\t0xc\n\n#define MAC_FRAME_ERR_CNT\t0x0\n#define MAC_RX_ERR_CNT\t\t0x1\n#define MAC_CRC_ERR_CNT\t\t0x2\n#define MAC_LNK_LST_ERR_CNT\t0x3\n#define MAC_TX_FRAME_CNT\t0x10\n#define MAC_RX_FRAME_CNT\t0x14\n#define MAC_TX_FIFO_LVL\t\t0x20\n#define MAC_DROPPED_FRMS\t0x28\n#define MAC_CONNECTED_CCAT_FLAG\t0x78\n\n#define MII_MAC_ADDR\t\t0x8\n#define MII_MAC_FILT_FLAG\t0xe\n#define MII_LINK_STATUS\t\t0xf\n\n#define FIFO_TX_REG\t\t0x0\n#define FIFO_TX_RESET\t\t0x8\n#define FIFO_RX_REG\t\t0x10\n#define FIFO_RX_ADDR_VALID\t(1u << 31)\n#define FIFO_RX_RESET\t\t0x18\n\n#define DMA_CHAN_OFFSET\t\t0x1000\n#define DMA_CHAN_SIZE\t\t0x8\n\n#define DMA_WINDOW_SIZE_MASK\t0xfffffffc\n\n#define ETHERCAT_MASTER_ID\t0x14\n\nstatic const struct pci_device_id ids[] = {\n\t{ PCI_DEVICE(0x15ec, 0x5000), },\n\t{ 0, }\n};\nMODULE_DEVICE_TABLE(pci, ids);\n\nstruct rx_header {\n#define RXHDR_NEXT_ADDR_MASK\t0xffffffu\n#define RXHDR_NEXT_VALID\t(1u << 31)\n\t__le32 next;\n#define RXHDR_NEXT_RECV_FLAG\t0x1\n\t__le32 recv;\n#define RXHDR_LEN_MASK\t\t0xfffu\n\t__le16 len;\n\t__le16 port;\n\t__le32 reserved;\n\tu8 timestamp[8];\n} __packed;\n\n#define PKT_PAYLOAD_SIZE\t0x7e8\nstruct rx_desc {\n\tstruct rx_header header;\n\tu8 data[PKT_PAYLOAD_SIZE];\n} __packed;\n\nstruct tx_header {\n\t__le16 len;\n#define TX_HDR_PORT_0\t\t0x1\n#define TX_HDR_PORT_1\t\t0x2\n\tu8 port;\n\tu8 ts_enable;\n#define TX_HDR_SENT\t\t0x1\n\t__le32 sent;\n\tu8 timestamp[8];\n} __packed;\n\nstruct tx_desc {\n\tstruct tx_header header;\n\tu8 data[PKT_PAYLOAD_SIZE];\n} __packed;\n\n#define FIFO_SIZE\t\t64\n\nstatic long polling_frequency = TIMER_INTERVAL_NSEC;\n\nstruct bhf_dma {\n\tu8 *buf;\n\tsize_t len;\n\tdma_addr_t buf_phys;\n\n\tu8 *alloc;\n\tsize_t alloc_len;\n\tdma_addr_t alloc_phys;\n};\n\nstruct ec_bhf_priv {\n\tstruct net_device *net_dev;\n\tstruct pci_dev *dev;\n\n\tvoid __iomem *io;\n\tvoid __iomem *dma_io;\n\n\tstruct hrtimer hrtimer;\n\n\tint tx_dma_chan;\n\tint rx_dma_chan;\n\tvoid __iomem *ec_io;\n\tvoid __iomem *fifo_io;\n\tvoid __iomem *mii_io;\n\tvoid __iomem *mac_io;\n\n\tstruct bhf_dma rx_buf;\n\tstruct rx_desc *rx_descs;\n\tint rx_dnext;\n\tint rx_dcount;\n\n\tstruct bhf_dma tx_buf;\n\tstruct tx_desc *tx_descs;\n\tint tx_dcount;\n\tint tx_dnext;\n\n\tu64 stat_rx_bytes;\n\tu64 stat_tx_bytes;\n};\n\n#define PRIV_TO_DEV(priv) (&(priv)->dev->dev)\n\nstatic void ec_bhf_reset(struct ec_bhf_priv *priv)\n{\n\tiowrite8(0, priv->mac_io + MAC_FRAME_ERR_CNT);\n\tiowrite8(0, priv->mac_io + MAC_RX_ERR_CNT);\n\tiowrite8(0, priv->mac_io + MAC_CRC_ERR_CNT);\n\tiowrite8(0, priv->mac_io + MAC_LNK_LST_ERR_CNT);\n\tiowrite32(0, priv->mac_io + MAC_TX_FRAME_CNT);\n\tiowrite32(0, priv->mac_io + MAC_RX_FRAME_CNT);\n\tiowrite8(0, priv->mac_io + MAC_DROPPED_FRMS);\n\n\tiowrite8(0, priv->fifo_io + FIFO_TX_RESET);\n\tiowrite8(0, priv->fifo_io + FIFO_RX_RESET);\n\n\tiowrite8(0, priv->mac_io + MAC_TX_FIFO_LVL);\n}\n\nstatic void ec_bhf_send_packet(struct ec_bhf_priv *priv, struct tx_desc *desc)\n{\n\tu32 len = le16_to_cpu(desc->header.len) + sizeof(desc->header);\n\tu32 addr = (u8 *)desc - priv->tx_buf.buf;\n\n\tiowrite32((ALIGN(len, 8) << 24) | addr, priv->fifo_io + FIFO_TX_REG);\n}\n\nstatic int ec_bhf_desc_sent(struct tx_desc *desc)\n{\n\treturn le32_to_cpu(desc->header.sent) & TX_HDR_SENT;\n}\n\nstatic void ec_bhf_process_tx(struct ec_bhf_priv *priv)\n{\n\tif (unlikely(netif_queue_stopped(priv->net_dev))) {\n\t\t \n\t\tsmp_rmb();\n\n\t\tif (ec_bhf_desc_sent(&priv->tx_descs[priv->tx_dnext]))\n\t\t\tnetif_wake_queue(priv->net_dev);\n\t}\n}\n\nstatic int ec_bhf_pkt_received(struct rx_desc *desc)\n{\n\treturn le32_to_cpu(desc->header.recv) & RXHDR_NEXT_RECV_FLAG;\n}\n\nstatic void ec_bhf_add_rx_desc(struct ec_bhf_priv *priv, struct rx_desc *desc)\n{\n\tiowrite32(FIFO_RX_ADDR_VALID | ((u8 *)(desc) - priv->rx_buf.buf),\n\t\t  priv->fifo_io + FIFO_RX_REG);\n}\n\nstatic void ec_bhf_process_rx(struct ec_bhf_priv *priv)\n{\n\tstruct rx_desc *desc = &priv->rx_descs[priv->rx_dnext];\n\n\twhile (ec_bhf_pkt_received(desc)) {\n\t\tint pkt_size = (le16_to_cpu(desc->header.len) &\n\t\t\t       RXHDR_LEN_MASK) - sizeof(struct rx_header) - 4;\n\t\tu8 *data = desc->data;\n\t\tstruct sk_buff *skb;\n\n\t\tskb = netdev_alloc_skb_ip_align(priv->net_dev, pkt_size);\n\t\tif (skb) {\n\t\t\tskb_put_data(skb, data, pkt_size);\n\t\t\tskb->protocol = eth_type_trans(skb, priv->net_dev);\n\t\t\tpriv->stat_rx_bytes += pkt_size;\n\n\t\t\tnetif_rx(skb);\n\t\t} else {\n\t\t\tdev_err_ratelimited(PRIV_TO_DEV(priv),\n\t\t\t\t\t    \"Couldn't allocate a skb_buff for a packet of size %u\\n\",\n\t\t\t\t\t    pkt_size);\n\t\t}\n\n\t\tdesc->header.recv = 0;\n\n\t\tec_bhf_add_rx_desc(priv, desc);\n\n\t\tpriv->rx_dnext = (priv->rx_dnext + 1) % priv->rx_dcount;\n\t\tdesc = &priv->rx_descs[priv->rx_dnext];\n\t}\n}\n\nstatic enum hrtimer_restart ec_bhf_timer_fun(struct hrtimer *timer)\n{\n\tstruct ec_bhf_priv *priv = container_of(timer, struct ec_bhf_priv,\n\t\t\t\t\t\thrtimer);\n\tec_bhf_process_rx(priv);\n\tec_bhf_process_tx(priv);\n\n\tif (!netif_running(priv->net_dev))\n\t\treturn HRTIMER_NORESTART;\n\n\thrtimer_forward_now(timer, polling_frequency);\n\treturn HRTIMER_RESTART;\n}\n\nstatic int ec_bhf_setup_offsets(struct ec_bhf_priv *priv)\n{\n\tstruct device *dev = PRIV_TO_DEV(priv);\n\tunsigned block_count, i;\n\tvoid __iomem *ec_info;\n\n\tblock_count = ioread8(priv->io + INFO_BLOCK_BLK_CNT);\n\tfor (i = 0; i < block_count; i++) {\n\t\tu16 type = ioread16(priv->io + i * INFO_BLOCK_SIZE +\n\t\t\t\t    INFO_BLOCK_TYPE);\n\t\tif (type == ETHERCAT_MASTER_ID)\n\t\t\tbreak;\n\t}\n\tif (i == block_count) {\n\t\tdev_err(dev, \"EtherCAT master with DMA block not found\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tec_info = priv->io + i * INFO_BLOCK_SIZE;\n\n\tpriv->tx_dma_chan = ioread8(ec_info + INFO_BLOCK_TX_CHAN);\n\tpriv->rx_dma_chan = ioread8(ec_info + INFO_BLOCK_RX_CHAN);\n\n\tpriv->ec_io = priv->io + ioread32(ec_info + INFO_BLOCK_OFFSET);\n\tpriv->mii_io = priv->ec_io + ioread32(priv->ec_io + EC_MII_OFFSET);\n\tpriv->fifo_io = priv->ec_io + ioread32(priv->ec_io + EC_FIFO_OFFSET);\n\tpriv->mac_io = priv->ec_io + ioread32(priv->ec_io + EC_MAC_OFFSET);\n\n\treturn 0;\n}\n\nstatic netdev_tx_t ec_bhf_start_xmit(struct sk_buff *skb,\n\t\t\t\t     struct net_device *net_dev)\n{\n\tstruct ec_bhf_priv *priv = netdev_priv(net_dev);\n\tstruct tx_desc *desc;\n\tunsigned len;\n\n\tdesc = &priv->tx_descs[priv->tx_dnext];\n\n\tskb_copy_and_csum_dev(skb, desc->data);\n\tlen = skb->len;\n\n\tmemset(&desc->header, 0, sizeof(desc->header));\n\tdesc->header.len = cpu_to_le16(len);\n\tdesc->header.port = TX_HDR_PORT_0;\n\n\tec_bhf_send_packet(priv, desc);\n\n\tpriv->tx_dnext = (priv->tx_dnext + 1) % priv->tx_dcount;\n\n\tif (!ec_bhf_desc_sent(&priv->tx_descs[priv->tx_dnext])) {\n\t\t \n\t\tsmp_wmb();\n\n\t\tnetif_stop_queue(net_dev);\n\t}\n\n\tpriv->stat_tx_bytes += len;\n\n\tdev_kfree_skb(skb);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic int ec_bhf_alloc_dma_mem(struct ec_bhf_priv *priv,\n\t\t\t\tstruct bhf_dma *buf,\n\t\t\t\tint channel,\n\t\t\t\tint size)\n{\n\tint offset = channel * DMA_CHAN_SIZE + DMA_CHAN_OFFSET;\n\tstruct device *dev = PRIV_TO_DEV(priv);\n\tu32 mask;\n\n\tiowrite32(0xffffffff, priv->dma_io + offset);\n\n\tmask = ioread32(priv->dma_io + offset);\n\tmask &= DMA_WINDOW_SIZE_MASK;\n\n\t \n\tbuf->len = min_t(int, ~mask + 1, size);\n\tbuf->alloc_len = 2 * buf->len;\n\n\tbuf->alloc = dma_alloc_coherent(dev, buf->alloc_len, &buf->alloc_phys,\n\t\t\t\t\tGFP_KERNEL);\n\tif (buf->alloc == NULL) {\n\t\tdev_err(dev, \"Failed to allocate buffer\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tbuf->buf_phys = (buf->alloc_phys + buf->len) & mask;\n\tbuf->buf = buf->alloc + (buf->buf_phys - buf->alloc_phys);\n\n\tiowrite32(0, priv->dma_io + offset + 4);\n\tiowrite32(buf->buf_phys, priv->dma_io + offset);\n\n\treturn 0;\n}\n\nstatic void ec_bhf_setup_tx_descs(struct ec_bhf_priv *priv)\n{\n\tint i = 0;\n\n\tpriv->tx_dcount = priv->tx_buf.len / sizeof(struct tx_desc);\n\tpriv->tx_descs = (struct tx_desc *)priv->tx_buf.buf;\n\tpriv->tx_dnext = 0;\n\n\tfor (i = 0; i < priv->tx_dcount; i++)\n\t\tpriv->tx_descs[i].header.sent = cpu_to_le32(TX_HDR_SENT);\n}\n\nstatic void ec_bhf_setup_rx_descs(struct ec_bhf_priv *priv)\n{\n\tint i;\n\n\tpriv->rx_dcount = priv->rx_buf.len / sizeof(struct rx_desc);\n\tpriv->rx_descs = (struct rx_desc *)priv->rx_buf.buf;\n\tpriv->rx_dnext = 0;\n\n\tfor (i = 0; i < priv->rx_dcount; i++) {\n\t\tstruct rx_desc *desc = &priv->rx_descs[i];\n\t\tu32 next;\n\n\t\tif (i != priv->rx_dcount - 1)\n\t\t\tnext = (u8 *)(desc + 1) - priv->rx_buf.buf;\n\t\telse\n\t\t\tnext = 0;\n\t\tnext |= RXHDR_NEXT_VALID;\n\t\tdesc->header.next = cpu_to_le32(next);\n\t\tdesc->header.recv = 0;\n\t\tec_bhf_add_rx_desc(priv, desc);\n\t}\n}\n\nstatic int ec_bhf_open(struct net_device *net_dev)\n{\n\tstruct ec_bhf_priv *priv = netdev_priv(net_dev);\n\tstruct device *dev = PRIV_TO_DEV(priv);\n\tint err = 0;\n\n\tec_bhf_reset(priv);\n\n\terr = ec_bhf_alloc_dma_mem(priv, &priv->rx_buf, priv->rx_dma_chan,\n\t\t\t\t   FIFO_SIZE * sizeof(struct rx_desc));\n\tif (err) {\n\t\tdev_err(dev, \"Failed to allocate rx buffer\\n\");\n\t\tgoto out;\n\t}\n\tec_bhf_setup_rx_descs(priv);\n\n\terr = ec_bhf_alloc_dma_mem(priv, &priv->tx_buf, priv->tx_dma_chan,\n\t\t\t\t   FIFO_SIZE * sizeof(struct tx_desc));\n\tif (err) {\n\t\tdev_err(dev, \"Failed to allocate tx buffer\\n\");\n\t\tgoto error_rx_free;\n\t}\n\tiowrite8(0, priv->mii_io + MII_MAC_FILT_FLAG);\n\tec_bhf_setup_tx_descs(priv);\n\n\tnetif_start_queue(net_dev);\n\n\thrtimer_init(&priv->hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\n\tpriv->hrtimer.function = ec_bhf_timer_fun;\n\thrtimer_start(&priv->hrtimer, polling_frequency, HRTIMER_MODE_REL);\n\n\treturn 0;\n\nerror_rx_free:\n\tdma_free_coherent(dev, priv->rx_buf.alloc_len, priv->rx_buf.alloc,\n\t\t\t  priv->rx_buf.alloc_len);\nout:\n\treturn err;\n}\n\nstatic int ec_bhf_stop(struct net_device *net_dev)\n{\n\tstruct ec_bhf_priv *priv = netdev_priv(net_dev);\n\tstruct device *dev = PRIV_TO_DEV(priv);\n\n\thrtimer_cancel(&priv->hrtimer);\n\n\tec_bhf_reset(priv);\n\n\tnetif_tx_disable(net_dev);\n\n\tdma_free_coherent(dev, priv->tx_buf.alloc_len,\n\t\t\t  priv->tx_buf.alloc, priv->tx_buf.alloc_phys);\n\tdma_free_coherent(dev, priv->rx_buf.alloc_len,\n\t\t\t  priv->rx_buf.alloc, priv->rx_buf.alloc_phys);\n\n\treturn 0;\n}\n\nstatic void\nec_bhf_get_stats(struct net_device *net_dev,\n\t\t struct rtnl_link_stats64 *stats)\n{\n\tstruct ec_bhf_priv *priv = netdev_priv(net_dev);\n\n\tstats->rx_errors = ioread8(priv->mac_io + MAC_RX_ERR_CNT) +\n\t\t\t\tioread8(priv->mac_io + MAC_CRC_ERR_CNT) +\n\t\t\t\tioread8(priv->mac_io + MAC_FRAME_ERR_CNT);\n\tstats->rx_packets = ioread32(priv->mac_io + MAC_RX_FRAME_CNT);\n\tstats->tx_packets = ioread32(priv->mac_io + MAC_TX_FRAME_CNT);\n\tstats->rx_dropped = ioread8(priv->mac_io + MAC_DROPPED_FRMS);\n\n\tstats->tx_bytes = priv->stat_tx_bytes;\n\tstats->rx_bytes = priv->stat_rx_bytes;\n}\n\nstatic const struct net_device_ops ec_bhf_netdev_ops = {\n\t.ndo_start_xmit\t\t= ec_bhf_start_xmit,\n\t.ndo_open\t\t= ec_bhf_open,\n\t.ndo_stop\t\t= ec_bhf_stop,\n\t.ndo_get_stats64\t= ec_bhf_get_stats,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_set_mac_address\t= eth_mac_addr\n};\n\nstatic int ec_bhf_probe(struct pci_dev *dev, const struct pci_device_id *id)\n{\n\tstruct net_device *net_dev;\n\tstruct ec_bhf_priv *priv;\n\tvoid __iomem *dma_io;\n\tu8 addr[ETH_ALEN];\n\tvoid __iomem *io;\n\tint err = 0;\n\n\terr = pci_enable_device(dev);\n\tif (err)\n\t\treturn err;\n\n\tpci_set_master(dev);\n\n\terr = dma_set_mask_and_coherent(&dev->dev, DMA_BIT_MASK(32));\n\tif (err) {\n\t\tdev_err(&dev->dev,\n\t\t\t\"Required dma mask not supported, failed to initialize device\\n\");\n\t\tgoto err_disable_dev;\n\t}\n\n\terr = pci_request_regions(dev, \"ec_bhf\");\n\tif (err) {\n\t\tdev_err(&dev->dev, \"Failed to request pci memory regions\\n\");\n\t\tgoto err_disable_dev;\n\t}\n\n\tio = pci_iomap(dev, 0, 0);\n\tif (!io) {\n\t\tdev_err(&dev->dev, \"Failed to map pci card memory bar 0\");\n\t\terr = -EIO;\n\t\tgoto err_release_regions;\n\t}\n\n\tdma_io = pci_iomap(dev, 2, 0);\n\tif (!dma_io) {\n\t\tdev_err(&dev->dev, \"Failed to map pci card memory bar 2\");\n\t\terr = -EIO;\n\t\tgoto err_unmap;\n\t}\n\n\tnet_dev = alloc_etherdev(sizeof(struct ec_bhf_priv));\n\tif (net_dev == NULL) {\n\t\terr = -ENOMEM;\n\t\tgoto err_unmap_dma_io;\n\t}\n\n\tpci_set_drvdata(dev, net_dev);\n\tSET_NETDEV_DEV(net_dev, &dev->dev);\n\n\tnet_dev->features = 0;\n\tnet_dev->flags |= IFF_NOARP;\n\n\tnet_dev->netdev_ops = &ec_bhf_netdev_ops;\n\n\tpriv = netdev_priv(net_dev);\n\tpriv->net_dev = net_dev;\n\tpriv->io = io;\n\tpriv->dma_io = dma_io;\n\tpriv->dev = dev;\n\n\terr = ec_bhf_setup_offsets(priv);\n\tif (err < 0)\n\t\tgoto err_free_net_dev;\n\n\tmemcpy_fromio(addr, priv->mii_io + MII_MAC_ADDR, ETH_ALEN);\n\teth_hw_addr_set(net_dev, addr);\n\n\terr = register_netdev(net_dev);\n\tif (err < 0)\n\t\tgoto err_free_net_dev;\n\n\treturn 0;\n\nerr_free_net_dev:\n\tfree_netdev(net_dev);\nerr_unmap_dma_io:\n\tpci_iounmap(dev, dma_io);\nerr_unmap:\n\tpci_iounmap(dev, io);\nerr_release_regions:\n\tpci_release_regions(dev);\nerr_disable_dev:\n\tpci_disable_device(dev);\n\n\treturn err;\n}\n\nstatic void ec_bhf_remove(struct pci_dev *dev)\n{\n\tstruct net_device *net_dev = pci_get_drvdata(dev);\n\tstruct ec_bhf_priv *priv = netdev_priv(net_dev);\n\n\tunregister_netdev(net_dev);\n\n\tpci_iounmap(dev, priv->dma_io);\n\tpci_iounmap(dev, priv->io);\n\n\tfree_netdev(net_dev);\n\n\tpci_release_regions(dev);\n\tpci_disable_device(dev);\n}\n\nstatic struct pci_driver pci_driver = {\n\t.name\t\t= \"ec_bhf\",\n\t.id_table\t= ids,\n\t.probe\t\t= ec_bhf_probe,\n\t.remove\t\t= ec_bhf_remove,\n};\nmodule_pci_driver(pci_driver);\n\nmodule_param(polling_frequency, long, 0444);\nMODULE_PARM_DESC(polling_frequency, \"Polling timer frequency in ns\");\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Dariusz Marcinkiewicz <reksio@newterm.pl>\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}