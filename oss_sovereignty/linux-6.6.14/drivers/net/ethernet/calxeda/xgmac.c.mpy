{
  "module_name": "xgmac.c",
  "hash_id": "c995661275bf2cdce2c759b72fc0988f8acd61f6f9f84d8f6355e96bb0bd0a0b",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/calxeda/xgmac.c",
  "human_readable_source": "\n \n#include <linux/module.h>\n#include <linux/mod_devicetable.h>\n#include <linux/kernel.h>\n#include <linux/circ_buf.h>\n#include <linux/interrupt.h>\n#include <linux/etherdevice.h>\n#include <linux/platform_device.h>\n#include <linux/skbuff.h>\n#include <linux/ethtool.h>\n#include <linux/if.h>\n#include <linux/crc32.h>\n#include <linux/dma-mapping.h>\n#include <linux/slab.h>\n\n \n#define XGMAC_CONTROL\t\t0x00000000\t \n#define XGMAC_FRAME_FILTER\t0x00000004\t \n#define XGMAC_FLOW_CTRL\t\t0x00000018\t \n#define XGMAC_VLAN_TAG\t\t0x0000001C\t \n#define XGMAC_VERSION\t\t0x00000020\t \n#define XGMAC_VLAN_INCL\t\t0x00000024\t \n#define XGMAC_LPI_CTRL\t\t0x00000028\t \n#define XGMAC_LPI_TIMER\t\t0x0000002C\t \n#define XGMAC_TX_PACE\t\t0x00000030\t \n#define XGMAC_VLAN_HASH\t\t0x00000034\t \n#define XGMAC_DEBUG\t\t0x00000038\t \n#define XGMAC_INT_STAT\t\t0x0000003C\t \n#define XGMAC_ADDR_HIGH(reg)\t(0x00000040 + ((reg) * 8))\n#define XGMAC_ADDR_LOW(reg)\t(0x00000044 + ((reg) * 8))\n#define XGMAC_HASH(n)\t\t(0x00000300 + (n) * 4)  \n#define XGMAC_NUM_HASH\t\t16\n#define XGMAC_OMR\t\t0x00000400\n#define XGMAC_REMOTE_WAKE\t0x00000700\t \n#define XGMAC_PMT\t\t0x00000704\t \n#define XGMAC_MMC_CTRL\t\t0x00000800\t \n#define XGMAC_MMC_INTR_RX\t0x00000804\t \n#define XGMAC_MMC_INTR_TX\t0x00000808\t \n#define XGMAC_MMC_INTR_MASK_RX\t0x0000080c\t \n#define XGMAC_MMC_INTR_MASK_TX\t0x00000810\t \n\n \n#define XGMAC_MMC_TXOCTET_GB_LO\t0x00000814\n#define XGMAC_MMC_TXOCTET_GB_HI\t0x00000818\n#define XGMAC_MMC_TXFRAME_GB_LO\t0x0000081C\n#define XGMAC_MMC_TXFRAME_GB_HI\t0x00000820\n#define XGMAC_MMC_TXBCFRAME_G\t0x00000824\n#define XGMAC_MMC_TXMCFRAME_G\t0x0000082C\n#define XGMAC_MMC_TXUCFRAME_GB\t0x00000864\n#define XGMAC_MMC_TXMCFRAME_GB\t0x0000086C\n#define XGMAC_MMC_TXBCFRAME_GB\t0x00000874\n#define XGMAC_MMC_TXUNDERFLOW\t0x0000087C\n#define XGMAC_MMC_TXOCTET_G_LO\t0x00000884\n#define XGMAC_MMC_TXOCTET_G_HI\t0x00000888\n#define XGMAC_MMC_TXFRAME_G_LO\t0x0000088C\n#define XGMAC_MMC_TXFRAME_G_HI\t0x00000890\n#define XGMAC_MMC_TXPAUSEFRAME\t0x00000894\n#define XGMAC_MMC_TXVLANFRAME\t0x0000089C\n\n \n#define XGMAC_MMC_RXFRAME_GB_LO\t0x00000900\n#define XGMAC_MMC_RXFRAME_GB_HI\t0x00000904\n#define XGMAC_MMC_RXOCTET_GB_LO\t0x00000908\n#define XGMAC_MMC_RXOCTET_GB_HI\t0x0000090C\n#define XGMAC_MMC_RXOCTET_G_LO\t0x00000910\n#define XGMAC_MMC_RXOCTET_G_HI\t0x00000914\n#define XGMAC_MMC_RXBCFRAME_G\t0x00000918\n#define XGMAC_MMC_RXMCFRAME_G\t0x00000920\n#define XGMAC_MMC_RXCRCERR\t0x00000928\n#define XGMAC_MMC_RXRUNT\t0x00000930\n#define XGMAC_MMC_RXJABBER\t0x00000934\n#define XGMAC_MMC_RXUCFRAME_G\t0x00000970\n#define XGMAC_MMC_RXLENGTHERR\t0x00000978\n#define XGMAC_MMC_RXPAUSEFRAME\t0x00000988\n#define XGMAC_MMC_RXOVERFLOW\t0x00000990\n#define XGMAC_MMC_RXVLANFRAME\t0x00000998\n#define XGMAC_MMC_RXWATCHDOG\t0x000009a0\n\n \n#define XGMAC_DMA_BUS_MODE\t0x00000f00\t \n#define XGMAC_DMA_TX_POLL\t0x00000f04\t \n#define XGMAC_DMA_RX_POLL\t0x00000f08\t \n#define XGMAC_DMA_RX_BASE_ADDR\t0x00000f0c\t \n#define XGMAC_DMA_TX_BASE_ADDR\t0x00000f10\t \n#define XGMAC_DMA_STATUS\t0x00000f14\t \n#define XGMAC_DMA_CONTROL\t0x00000f18\t \n#define XGMAC_DMA_INTR_ENA\t0x00000f1c\t \n#define XGMAC_DMA_MISS_FRAME_CTR 0x00000f20\t \n#define XGMAC_DMA_RI_WDOG_TIMER\t0x00000f24\t \n#define XGMAC_DMA_AXI_BUS\t0x00000f28\t \n#define XGMAC_DMA_AXI_STATUS\t0x00000f2C\t \n#define XGMAC_DMA_HW_FEATURE\t0x00000f58\t \n\n#define XGMAC_ADDR_AE\t\t0x80000000\n\n \n#define XGMAC_PMT_POINTER_RESET\t0x80000000\n#define XGMAC_PMT_GLBL_UNICAST\t0x00000200\n#define XGMAC_PMT_WAKEUP_RX_FRM\t0x00000040\n#define XGMAC_PMT_MAGIC_PKT\t0x00000020\n#define XGMAC_PMT_WAKEUP_FRM_EN\t0x00000004\n#define XGMAC_PMT_MAGIC_PKT_EN\t0x00000002\n#define XGMAC_PMT_POWERDOWN\t0x00000001\n\n#define XGMAC_CONTROL_SPD\t0x40000000\t \n#define XGMAC_CONTROL_SPD_MASK\t0x60000000\n#define XGMAC_CONTROL_SPD_1G\t0x60000000\n#define XGMAC_CONTROL_SPD_2_5G\t0x40000000\n#define XGMAC_CONTROL_SPD_10G\t0x00000000\n#define XGMAC_CONTROL_SARC\t0x10000000\t \n#define XGMAC_CONTROL_SARK_MASK\t0x18000000\n#define XGMAC_CONTROL_CAR\t0x04000000\t \n#define XGMAC_CONTROL_CAR_MASK\t0x06000000\n#define XGMAC_CONTROL_DP\t0x01000000\t \n#define XGMAC_CONTROL_WD\t0x00800000\t \n#define XGMAC_CONTROL_JD\t0x00400000\t \n#define XGMAC_CONTROL_JE\t0x00100000\t \n#define XGMAC_CONTROL_LM\t0x00001000\t \n#define XGMAC_CONTROL_IPC\t0x00000400\t \n#define XGMAC_CONTROL_ACS\t0x00000080\t \n#define XGMAC_CONTROL_DDIC\t0x00000010\t \n#define XGMAC_CONTROL_TE\t0x00000008\t \n#define XGMAC_CONTROL_RE\t0x00000004\t \n\n \n#define XGMAC_FRAME_FILTER_PR\t0x00000001\t \n#define XGMAC_FRAME_FILTER_HUC\t0x00000002\t \n#define XGMAC_FRAME_FILTER_HMC\t0x00000004\t \n#define XGMAC_FRAME_FILTER_DAIF\t0x00000008\t \n#define XGMAC_FRAME_FILTER_PM\t0x00000010\t \n#define XGMAC_FRAME_FILTER_DBF\t0x00000020\t \n#define XGMAC_FRAME_FILTER_SAIF\t0x00000100\t \n#define XGMAC_FRAME_FILTER_SAF\t0x00000200\t \n#define XGMAC_FRAME_FILTER_HPF\t0x00000400\t \n#define XGMAC_FRAME_FILTER_VHF\t0x00000800\t \n#define XGMAC_FRAME_FILTER_VPF\t0x00001000\t \n#define XGMAC_FRAME_FILTER_RA\t0x80000000\t \n\n \n#define XGMAC_FLOW_CTRL_PT_MASK\t0xffff0000\t \n#define XGMAC_FLOW_CTRL_PT_SHIFT\t16\n#define XGMAC_FLOW_CTRL_DZQP\t0x00000080\t \n#define XGMAC_FLOW_CTRL_PLT\t0x00000020\t \n#define XGMAC_FLOW_CTRL_PLT_MASK 0x00000030\t \n#define XGMAC_FLOW_CTRL_UP\t0x00000008\t \n#define XGMAC_FLOW_CTRL_RFE\t0x00000004\t \n#define XGMAC_FLOW_CTRL_TFE\t0x00000002\t \n#define XGMAC_FLOW_CTRL_FCB_BPA\t0x00000001\t \n\n \n#define XGMAC_INT_STAT_PMTIM\t0x00800000\t \n#define XGMAC_INT_STAT_PMT\t0x0080\t\t \n#define XGMAC_INT_STAT_LPI\t0x0040\t\t \n\n \n#define DMA_BUS_MODE_SFT_RESET\t0x00000001\t \n#define DMA_BUS_MODE_DSL_MASK\t0x0000007c\t \n#define DMA_BUS_MODE_DSL_SHIFT\t2\t\t \n#define DMA_BUS_MODE_ATDS\t0x00000080\t \n\n \n#define DMA_BUS_MODE_PBL_MASK\t0x00003f00\t \n#define DMA_BUS_MODE_PBL_SHIFT\t8\n#define DMA_BUS_MODE_FB\t\t0x00010000\t \n#define DMA_BUS_MODE_RPBL_MASK\t0x003e0000\t \n#define DMA_BUS_MODE_RPBL_SHIFT\t17\n#define DMA_BUS_MODE_USP\t0x00800000\n#define DMA_BUS_MODE_8PBL\t0x01000000\n#define DMA_BUS_MODE_AAL\t0x02000000\n\n \n#define DMA_BUS_PR_RATIO_MASK\t0x0000c000\t \n#define DMA_BUS_PR_RATIO_SHIFT\t14\n#define DMA_BUS_FB\t\t0x00010000\t \n\n \n#define DMA_CONTROL_ST\t\t0x00002000\t \n#define DMA_CONTROL_SR\t\t0x00000002\t \n#define DMA_CONTROL_DFF\t\t0x01000000\t \n#define DMA_CONTROL_OSF\t\t0x00000004\t \n\n \n#define DMA_INTR_ENA_NIE\t0x00010000\t \n#define DMA_INTR_ENA_AIE\t0x00008000\t \n#define DMA_INTR_ENA_ERE\t0x00004000\t \n#define DMA_INTR_ENA_FBE\t0x00002000\t \n#define DMA_INTR_ENA_ETE\t0x00000400\t \n#define DMA_INTR_ENA_RWE\t0x00000200\t \n#define DMA_INTR_ENA_RSE\t0x00000100\t \n#define DMA_INTR_ENA_RUE\t0x00000080\t \n#define DMA_INTR_ENA_RIE\t0x00000040\t \n#define DMA_INTR_ENA_UNE\t0x00000020\t \n#define DMA_INTR_ENA_OVE\t0x00000010\t \n#define DMA_INTR_ENA_TJE\t0x00000008\t \n#define DMA_INTR_ENA_TUE\t0x00000004\t \n#define DMA_INTR_ENA_TSE\t0x00000002\t \n#define DMA_INTR_ENA_TIE\t0x00000001\t \n\n#define DMA_INTR_NORMAL\t\t(DMA_INTR_ENA_NIE | DMA_INTR_ENA_RIE | \\\n\t\t\t\t DMA_INTR_ENA_TUE | DMA_INTR_ENA_TIE)\n\n#define DMA_INTR_ABNORMAL\t(DMA_INTR_ENA_AIE | DMA_INTR_ENA_FBE | \\\n\t\t\t\t DMA_INTR_ENA_RWE | DMA_INTR_ENA_RSE | \\\n\t\t\t\t DMA_INTR_ENA_RUE | DMA_INTR_ENA_UNE | \\\n\t\t\t\t DMA_INTR_ENA_OVE | DMA_INTR_ENA_TJE | \\\n\t\t\t\t DMA_INTR_ENA_TSE)\n\n \n#define DMA_INTR_DEFAULT_MASK\t(DMA_INTR_NORMAL | DMA_INTR_ABNORMAL)\n\n \n#define DMA_STATUS_GMI\t\t0x08000000\t \n#define DMA_STATUS_GLI\t\t0x04000000\t \n#define DMA_STATUS_EB_MASK\t0x00380000\t \n#define DMA_STATUS_EB_TX_ABORT\t0x00080000\t \n#define DMA_STATUS_EB_RX_ABORT\t0x00100000\t \n#define DMA_STATUS_TS_MASK\t0x00700000\t \n#define DMA_STATUS_TS_SHIFT\t20\n#define DMA_STATUS_RS_MASK\t0x000e0000\t \n#define DMA_STATUS_RS_SHIFT\t17\n#define DMA_STATUS_NIS\t\t0x00010000\t \n#define DMA_STATUS_AIS\t\t0x00008000\t \n#define DMA_STATUS_ERI\t\t0x00004000\t \n#define DMA_STATUS_FBI\t\t0x00002000\t \n#define DMA_STATUS_ETI\t\t0x00000400\t \n#define DMA_STATUS_RWT\t\t0x00000200\t \n#define DMA_STATUS_RPS\t\t0x00000100\t \n#define DMA_STATUS_RU\t\t0x00000080\t \n#define DMA_STATUS_RI\t\t0x00000040\t \n#define DMA_STATUS_UNF\t\t0x00000020\t \n#define DMA_STATUS_OVF\t\t0x00000010\t \n#define DMA_STATUS_TJT\t\t0x00000008\t \n#define DMA_STATUS_TU\t\t0x00000004\t \n#define DMA_STATUS_TPS\t\t0x00000002\t \n#define DMA_STATUS_TI\t\t0x00000001\t \n\n \n#define MAC_ENABLE_TX\t\t0x00000008\t \n#define MAC_ENABLE_RX\t\t0x00000004\t \n\n \n#define XGMAC_OMR_TSF\t\t0x00200000\t \n#define XGMAC_OMR_FTF\t\t0x00100000\t \n#define XGMAC_OMR_TTC\t\t0x00020000\t \n#define XGMAC_OMR_TTC_MASK\t0x00030000\n#define XGMAC_OMR_RFD\t\t0x00006000\t \n#define XGMAC_OMR_RFD_MASK\t0x00007000\t \n#define XGMAC_OMR_RFA\t\t0x00000600\t \n#define XGMAC_OMR_RFA_MASK\t0x00000E00\t \n#define XGMAC_OMR_EFC\t\t0x00000100\t \n#define XGMAC_OMR_FEF\t\t0x00000080\t \n#define XGMAC_OMR_DT\t\t0x00000040\t \n#define XGMAC_OMR_RSF\t\t0x00000020\t \n#define XGMAC_OMR_RTC_256\t0x00000018\t \n#define XGMAC_OMR_RTC_MASK\t0x00000018\t \n\n \n#define DMA_HW_FEAT_TXCOESEL\t0x00010000\t \n\n#define XGMAC_MMC_CTRL_CNT_FRZ\t0x00000008\n\n \n#define MAX_DESC_BUF_SZ\t\t(0x2000 - 8)\n\n#define RXDESC_EXT_STATUS\t0x00000001\n#define RXDESC_CRC_ERR\t\t0x00000002\n#define RXDESC_RX_ERR\t\t0x00000008\n#define RXDESC_RX_WDOG\t\t0x00000010\n#define RXDESC_FRAME_TYPE\t0x00000020\n#define RXDESC_GIANT_FRAME\t0x00000080\n#define RXDESC_LAST_SEG\t\t0x00000100\n#define RXDESC_FIRST_SEG\t0x00000200\n#define RXDESC_VLAN_FRAME\t0x00000400\n#define RXDESC_OVERFLOW_ERR\t0x00000800\n#define RXDESC_LENGTH_ERR\t0x00001000\n#define RXDESC_SA_FILTER_FAIL\t0x00002000\n#define RXDESC_DESCRIPTOR_ERR\t0x00004000\n#define RXDESC_ERROR_SUMMARY\t0x00008000\n#define RXDESC_FRAME_LEN_OFFSET\t16\n#define RXDESC_FRAME_LEN_MASK\t0x3fff0000\n#define RXDESC_DA_FILTER_FAIL\t0x40000000\n\n#define RXDESC1_END_RING\t0x00008000\n\n#define RXDESC_IP_PAYLOAD_MASK\t0x00000003\n#define RXDESC_IP_PAYLOAD_UDP\t0x00000001\n#define RXDESC_IP_PAYLOAD_TCP\t0x00000002\n#define RXDESC_IP_PAYLOAD_ICMP\t0x00000003\n#define RXDESC_IP_HEADER_ERR\t0x00000008\n#define RXDESC_IP_PAYLOAD_ERR\t0x00000010\n#define RXDESC_IPV4_PACKET\t0x00000040\n#define RXDESC_IPV6_PACKET\t0x00000080\n#define TXDESC_UNDERFLOW_ERR\t0x00000001\n#define TXDESC_JABBER_TIMEOUT\t0x00000002\n#define TXDESC_LOCAL_FAULT\t0x00000004\n#define TXDESC_REMOTE_FAULT\t0x00000008\n#define TXDESC_VLAN_FRAME\t0x00000010\n#define TXDESC_FRAME_FLUSHED\t0x00000020\n#define TXDESC_IP_HEADER_ERR\t0x00000040\n#define TXDESC_PAYLOAD_CSUM_ERR\t0x00000080\n#define TXDESC_ERROR_SUMMARY\t0x00008000\n#define TXDESC_SA_CTRL_INSERT\t0x00040000\n#define TXDESC_SA_CTRL_REPLACE\t0x00080000\n#define TXDESC_2ND_ADDR_CHAINED\t0x00100000\n#define TXDESC_END_RING\t\t0x00200000\n#define TXDESC_CSUM_IP\t\t0x00400000\n#define TXDESC_CSUM_IP_PAYLD\t0x00800000\n#define TXDESC_CSUM_ALL\t\t0x00C00000\n#define TXDESC_CRC_EN_REPLACE\t0x01000000\n#define TXDESC_CRC_EN_APPEND\t0x02000000\n#define TXDESC_DISABLE_PAD\t0x04000000\n#define TXDESC_FIRST_SEG\t0x10000000\n#define TXDESC_LAST_SEG\t\t0x20000000\n#define TXDESC_INTERRUPT\t0x40000000\n\n#define DESC_OWN\t\t0x80000000\n#define DESC_BUFFER1_SZ_MASK\t0x00001fff\n#define DESC_BUFFER2_SZ_MASK\t0x1fff0000\n#define DESC_BUFFER2_SZ_OFFSET\t16\n\nstruct xgmac_dma_desc {\n\t__le32 flags;\n\t__le32 buf_size;\n\t__le32 buf1_addr;\t\t \n\t__le32 buf2_addr;\t\t \n\t__le32 ext_status;\n\t__le32 res[3];\n};\n\nstruct xgmac_extra_stats {\n\t \n\tunsigned long tx_jabber;\n\tunsigned long tx_frame_flushed;\n\tunsigned long tx_payload_error;\n\tunsigned long tx_ip_header_error;\n\tunsigned long tx_local_fault;\n\tunsigned long tx_remote_fault;\n\t \n\tunsigned long rx_watchdog;\n\tunsigned long rx_da_filter_fail;\n\tunsigned long rx_payload_error;\n\tunsigned long rx_ip_header_error;\n\t \n\tunsigned long tx_process_stopped;\n\tunsigned long rx_buf_unav;\n\tunsigned long rx_process_stopped;\n\tunsigned long tx_early;\n\tunsigned long fatal_bus_error;\n};\n\nstruct xgmac_priv {\n\tstruct xgmac_dma_desc *dma_rx;\n\tstruct sk_buff **rx_skbuff;\n\tunsigned int rx_tail;\n\tunsigned int rx_head;\n\n\tstruct xgmac_dma_desc *dma_tx;\n\tstruct sk_buff **tx_skbuff;\n\tunsigned int tx_head;\n\tunsigned int tx_tail;\n\tint tx_irq_cnt;\n\n\tvoid __iomem *base;\n\tunsigned int dma_buf_sz;\n\tdma_addr_t dma_rx_phy;\n\tdma_addr_t dma_tx_phy;\n\n\tstruct net_device *dev;\n\tstruct device *device;\n\tstruct napi_struct napi;\n\n\tint max_macs;\n\tstruct xgmac_extra_stats xstats;\n\n\tspinlock_t stats_lock;\n\tint pmt_irq;\n\tchar rx_pause;\n\tchar tx_pause;\n\tint wolopts;\n\tstruct work_struct tx_timeout_work;\n};\n\n \n#define XGMAC_MAX_MTU\t\t9000\n#define PAUSE_TIME\t\t0x400\n\n#define DMA_RX_RING_SZ\t\t256\n#define DMA_TX_RING_SZ\t\t128\n \n#define TX_THRESH\t\t(DMA_TX_RING_SZ/4)\n\n \n#define dma_ring_incr(n, s)\t(((n) + 1) & ((s) - 1))\n#define dma_ring_space(h, t, s)\tCIRC_SPACE(h, t, s)\n#define dma_ring_cnt(h, t, s)\tCIRC_CNT(h, t, s)\n\n#define tx_dma_ring_space(p) \\\n\tdma_ring_space((p)->tx_head, (p)->tx_tail, DMA_TX_RING_SZ)\n\n \nstatic inline void desc_set_buf_len(struct xgmac_dma_desc *p, u32 buf_sz)\n{\n\tif (buf_sz > MAX_DESC_BUF_SZ)\n\t\tp->buf_size = cpu_to_le32(MAX_DESC_BUF_SZ |\n\t\t\t(buf_sz - MAX_DESC_BUF_SZ) << DESC_BUFFER2_SZ_OFFSET);\n\telse\n\t\tp->buf_size = cpu_to_le32(buf_sz);\n}\n\nstatic inline int desc_get_buf_len(struct xgmac_dma_desc *p)\n{\n\tu32 len = le32_to_cpu(p->buf_size);\n\treturn (len & DESC_BUFFER1_SZ_MASK) +\n\t\t((len & DESC_BUFFER2_SZ_MASK) >> DESC_BUFFER2_SZ_OFFSET);\n}\n\nstatic inline void desc_init_rx_desc(struct xgmac_dma_desc *p, int ring_size,\n\t\t\t\t     int buf_sz)\n{\n\tstruct xgmac_dma_desc *end = p + ring_size - 1;\n\n\tmemset(p, 0, sizeof(*p) * ring_size);\n\n\tfor (; p <= end; p++)\n\t\tdesc_set_buf_len(p, buf_sz);\n\n\tend->buf_size |= cpu_to_le32(RXDESC1_END_RING);\n}\n\nstatic inline void desc_init_tx_desc(struct xgmac_dma_desc *p, u32 ring_size)\n{\n\tmemset(p, 0, sizeof(*p) * ring_size);\n\tp[ring_size - 1].flags = cpu_to_le32(TXDESC_END_RING);\n}\n\nstatic inline int desc_get_owner(struct xgmac_dma_desc *p)\n{\n\treturn le32_to_cpu(p->flags) & DESC_OWN;\n}\n\nstatic inline void desc_set_rx_owner(struct xgmac_dma_desc *p)\n{\n\t \n\tp->flags = cpu_to_le32(DESC_OWN);\n}\n\nstatic inline void desc_set_tx_owner(struct xgmac_dma_desc *p, u32 flags)\n{\n\tu32 tmpflags = le32_to_cpu(p->flags);\n\ttmpflags &= TXDESC_END_RING;\n\ttmpflags |= flags | DESC_OWN;\n\tp->flags = cpu_to_le32(tmpflags);\n}\n\nstatic inline void desc_clear_tx_owner(struct xgmac_dma_desc *p)\n{\n\tu32 tmpflags = le32_to_cpu(p->flags);\n\ttmpflags &= TXDESC_END_RING;\n\tp->flags = cpu_to_le32(tmpflags);\n}\n\nstatic inline int desc_get_tx_ls(struct xgmac_dma_desc *p)\n{\n\treturn le32_to_cpu(p->flags) & TXDESC_LAST_SEG;\n}\n\nstatic inline int desc_get_tx_fs(struct xgmac_dma_desc *p)\n{\n\treturn le32_to_cpu(p->flags) & TXDESC_FIRST_SEG;\n}\n\nstatic inline u32 desc_get_buf_addr(struct xgmac_dma_desc *p)\n{\n\treturn le32_to_cpu(p->buf1_addr);\n}\n\nstatic inline void desc_set_buf_addr(struct xgmac_dma_desc *p,\n\t\t\t\t     u32 paddr, int len)\n{\n\tp->buf1_addr = cpu_to_le32(paddr);\n\tif (len > MAX_DESC_BUF_SZ)\n\t\tp->buf2_addr = cpu_to_le32(paddr + MAX_DESC_BUF_SZ);\n}\n\nstatic inline void desc_set_buf_addr_and_size(struct xgmac_dma_desc *p,\n\t\t\t\t\t      u32 paddr, int len)\n{\n\tdesc_set_buf_len(p, len);\n\tdesc_set_buf_addr(p, paddr, len);\n}\n\nstatic inline int desc_get_rx_frame_len(struct xgmac_dma_desc *p)\n{\n\tu32 data = le32_to_cpu(p->flags);\n\tu32 len = (data & RXDESC_FRAME_LEN_MASK) >> RXDESC_FRAME_LEN_OFFSET;\n\tif (data & RXDESC_FRAME_TYPE)\n\t\tlen -= ETH_FCS_LEN;\n\n\treturn len;\n}\n\nstatic void xgmac_dma_flush_tx_fifo(void __iomem *ioaddr)\n{\n\tint timeout = 1000;\n\tu32 reg = readl(ioaddr + XGMAC_OMR);\n\twritel(reg | XGMAC_OMR_FTF, ioaddr + XGMAC_OMR);\n\n\twhile ((timeout-- > 0) && readl(ioaddr + XGMAC_OMR) & XGMAC_OMR_FTF)\n\t\tudelay(1);\n}\n\nstatic int desc_get_tx_status(struct xgmac_priv *priv, struct xgmac_dma_desc *p)\n{\n\tstruct xgmac_extra_stats *x = &priv->xstats;\n\tu32 status = le32_to_cpu(p->flags);\n\n\tif (!(status & TXDESC_ERROR_SUMMARY))\n\t\treturn 0;\n\n\tnetdev_dbg(priv->dev, \"tx desc error = 0x%08x\\n\", status);\n\tif (status & TXDESC_JABBER_TIMEOUT)\n\t\tx->tx_jabber++;\n\tif (status & TXDESC_FRAME_FLUSHED)\n\t\tx->tx_frame_flushed++;\n\tif (status & TXDESC_UNDERFLOW_ERR)\n\t\txgmac_dma_flush_tx_fifo(priv->base);\n\tif (status & TXDESC_IP_HEADER_ERR)\n\t\tx->tx_ip_header_error++;\n\tif (status & TXDESC_LOCAL_FAULT)\n\t\tx->tx_local_fault++;\n\tif (status & TXDESC_REMOTE_FAULT)\n\t\tx->tx_remote_fault++;\n\tif (status & TXDESC_PAYLOAD_CSUM_ERR)\n\t\tx->tx_payload_error++;\n\n\treturn -1;\n}\n\nstatic int desc_get_rx_status(struct xgmac_priv *priv, struct xgmac_dma_desc *p)\n{\n\tstruct xgmac_extra_stats *x = &priv->xstats;\n\tint ret = CHECKSUM_UNNECESSARY;\n\tu32 status = le32_to_cpu(p->flags);\n\tu32 ext_status = le32_to_cpu(p->ext_status);\n\n\tif (status & RXDESC_DA_FILTER_FAIL) {\n\t\tnetdev_dbg(priv->dev, \"XGMAC RX : Dest Address filter fail\\n\");\n\t\tx->rx_da_filter_fail++;\n\t\treturn -1;\n\t}\n\n\t \n\tif (!(status & RXDESC_FIRST_SEG) || !(status & RXDESC_LAST_SEG))\n\t\treturn -1;\n\n\t \n\tif ((status & RXDESC_FRAME_TYPE) && (status & RXDESC_EXT_STATUS) &&\n\t\t!(ext_status & RXDESC_IP_PAYLOAD_MASK))\n\t\tret = CHECKSUM_NONE;\n\n\tnetdev_dbg(priv->dev, \"rx status - frame type=%d, csum = %d, ext stat %08x\\n\",\n\t\t   (status & RXDESC_FRAME_TYPE) ? 1 : 0, ret, ext_status);\n\n\tif (!(status & RXDESC_ERROR_SUMMARY))\n\t\treturn ret;\n\n\t \n\tif (status & (RXDESC_DESCRIPTOR_ERR | RXDESC_OVERFLOW_ERR |\n\t\tRXDESC_GIANT_FRAME | RXDESC_LENGTH_ERR | RXDESC_CRC_ERR))\n\t\treturn -1;\n\n\tif (status & RXDESC_EXT_STATUS) {\n\t\tif (ext_status & RXDESC_IP_HEADER_ERR)\n\t\t\tx->rx_ip_header_error++;\n\t\tif (ext_status & RXDESC_IP_PAYLOAD_ERR)\n\t\t\tx->rx_payload_error++;\n\t\tnetdev_dbg(priv->dev, \"IP checksum error - stat %08x\\n\",\n\t\t\t   ext_status);\n\t\treturn CHECKSUM_NONE;\n\t}\n\n\treturn ret;\n}\n\nstatic inline void xgmac_mac_enable(void __iomem *ioaddr)\n{\n\tu32 value = readl(ioaddr + XGMAC_CONTROL);\n\tvalue |= MAC_ENABLE_RX | MAC_ENABLE_TX;\n\twritel(value, ioaddr + XGMAC_CONTROL);\n\n\tvalue = readl(ioaddr + XGMAC_DMA_CONTROL);\n\tvalue |= DMA_CONTROL_ST | DMA_CONTROL_SR;\n\twritel(value, ioaddr + XGMAC_DMA_CONTROL);\n}\n\nstatic inline void xgmac_mac_disable(void __iomem *ioaddr)\n{\n\tu32 value = readl(ioaddr + XGMAC_DMA_CONTROL);\n\tvalue &= ~(DMA_CONTROL_ST | DMA_CONTROL_SR);\n\twritel(value, ioaddr + XGMAC_DMA_CONTROL);\n\n\tvalue = readl(ioaddr + XGMAC_CONTROL);\n\tvalue &= ~(MAC_ENABLE_TX | MAC_ENABLE_RX);\n\twritel(value, ioaddr + XGMAC_CONTROL);\n}\n\nstatic void xgmac_set_mac_addr(void __iomem *ioaddr, const unsigned char *addr,\n\t\t\t       int num)\n{\n\tu32 data;\n\n\tif (addr) {\n\t\tdata = (addr[5] << 8) | addr[4] | (num ? XGMAC_ADDR_AE : 0);\n\t\twritel(data, ioaddr + XGMAC_ADDR_HIGH(num));\n\t\tdata = (addr[3] << 24) | (addr[2] << 16) | (addr[1] << 8) | addr[0];\n\t\twritel(data, ioaddr + XGMAC_ADDR_LOW(num));\n\t} else {\n\t\twritel(0, ioaddr + XGMAC_ADDR_HIGH(num));\n\t\twritel(0, ioaddr + XGMAC_ADDR_LOW(num));\n\t}\n}\n\nstatic void xgmac_get_mac_addr(void __iomem *ioaddr, unsigned char *addr,\n\t\t\t       int num)\n{\n\tu32 hi_addr, lo_addr;\n\n\t \n\thi_addr = readl(ioaddr + XGMAC_ADDR_HIGH(num));\n\tlo_addr = readl(ioaddr + XGMAC_ADDR_LOW(num));\n\n\t \n\taddr[0] = lo_addr & 0xff;\n\taddr[1] = (lo_addr >> 8) & 0xff;\n\taddr[2] = (lo_addr >> 16) & 0xff;\n\taddr[3] = (lo_addr >> 24) & 0xff;\n\taddr[4] = hi_addr & 0xff;\n\taddr[5] = (hi_addr >> 8) & 0xff;\n}\n\nstatic int xgmac_set_flow_ctrl(struct xgmac_priv *priv, int rx, int tx)\n{\n\tu32 reg;\n\tunsigned int flow = 0;\n\n\tpriv->rx_pause = rx;\n\tpriv->tx_pause = tx;\n\n\tif (rx || tx) {\n\t\tif (rx)\n\t\t\tflow |= XGMAC_FLOW_CTRL_RFE;\n\t\tif (tx)\n\t\t\tflow |= XGMAC_FLOW_CTRL_TFE;\n\n\t\tflow |= XGMAC_FLOW_CTRL_PLT | XGMAC_FLOW_CTRL_UP;\n\t\tflow |= (PAUSE_TIME << XGMAC_FLOW_CTRL_PT_SHIFT);\n\n\t\twritel(flow, priv->base + XGMAC_FLOW_CTRL);\n\n\t\treg = readl(priv->base + XGMAC_OMR);\n\t\treg |= XGMAC_OMR_EFC;\n\t\twritel(reg, priv->base + XGMAC_OMR);\n\t} else {\n\t\twritel(0, priv->base + XGMAC_FLOW_CTRL);\n\n\t\treg = readl(priv->base + XGMAC_OMR);\n\t\treg &= ~XGMAC_OMR_EFC;\n\t\twritel(reg, priv->base + XGMAC_OMR);\n\t}\n\n\treturn 0;\n}\n\nstatic void xgmac_rx_refill(struct xgmac_priv *priv)\n{\n\tstruct xgmac_dma_desc *p;\n\tdma_addr_t paddr;\n\tint bufsz = priv->dev->mtu + ETH_HLEN + ETH_FCS_LEN;\n\n\twhile (dma_ring_space(priv->rx_head, priv->rx_tail, DMA_RX_RING_SZ) > 1) {\n\t\tint entry = priv->rx_head;\n\t\tstruct sk_buff *skb;\n\n\t\tp = priv->dma_rx + entry;\n\n\t\tif (priv->rx_skbuff[entry] == NULL) {\n\t\t\tskb = netdev_alloc_skb_ip_align(priv->dev, bufsz);\n\t\t\tif (unlikely(skb == NULL))\n\t\t\t\tbreak;\n\n\t\t\tpaddr = dma_map_single(priv->device, skb->data,\n\t\t\t\t\t       priv->dma_buf_sz - NET_IP_ALIGN,\n\t\t\t\t\t       DMA_FROM_DEVICE);\n\t\t\tif (dma_mapping_error(priv->device, paddr)) {\n\t\t\t\tdev_kfree_skb_any(skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpriv->rx_skbuff[entry] = skb;\n\t\t\tdesc_set_buf_addr(p, paddr, priv->dma_buf_sz);\n\t\t}\n\n\t\tnetdev_dbg(priv->dev, \"rx ring: head %d, tail %d\\n\",\n\t\t\tpriv->rx_head, priv->rx_tail);\n\n\t\tpriv->rx_head = dma_ring_incr(priv->rx_head, DMA_RX_RING_SZ);\n\t\tdesc_set_rx_owner(p);\n\t}\n}\n\n \nstatic int xgmac_dma_desc_rings_init(struct net_device *dev)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tunsigned int bfsize;\n\n\t \n\tbfsize = ALIGN(dev->mtu + ETH_HLEN + ETH_FCS_LEN + NET_IP_ALIGN, 8);\n\n\tnetdev_dbg(priv->dev, \"mtu [%d] bfsize [%d]\\n\", dev->mtu, bfsize);\n\n\tpriv->rx_skbuff = kcalloc(DMA_RX_RING_SZ, sizeof(struct sk_buff *),\n\t\t\t\t  GFP_KERNEL);\n\tif (!priv->rx_skbuff)\n\t\treturn -ENOMEM;\n\n\tpriv->dma_rx = dma_alloc_coherent(priv->device,\n\t\t\t\t\t  DMA_RX_RING_SZ *\n\t\t\t\t\t  sizeof(struct xgmac_dma_desc),\n\t\t\t\t\t  &priv->dma_rx_phy,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!priv->dma_rx)\n\t\tgoto err_dma_rx;\n\n\tpriv->tx_skbuff = kcalloc(DMA_TX_RING_SZ, sizeof(struct sk_buff *),\n\t\t\t\t  GFP_KERNEL);\n\tif (!priv->tx_skbuff)\n\t\tgoto err_tx_skb;\n\n\tpriv->dma_tx = dma_alloc_coherent(priv->device,\n\t\t\t\t\t  DMA_TX_RING_SZ *\n\t\t\t\t\t  sizeof(struct xgmac_dma_desc),\n\t\t\t\t\t  &priv->dma_tx_phy,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!priv->dma_tx)\n\t\tgoto err_dma_tx;\n\n\tnetdev_dbg(priv->dev, \"DMA desc rings: virt addr (Rx %p, \"\n\t    \"Tx %p)\\n\\tDMA phy addr (Rx 0x%08x, Tx 0x%08x)\\n\",\n\t    priv->dma_rx, priv->dma_tx,\n\t    (unsigned int)priv->dma_rx_phy, (unsigned int)priv->dma_tx_phy);\n\n\tpriv->rx_tail = 0;\n\tpriv->rx_head = 0;\n\tpriv->dma_buf_sz = bfsize;\n\tdesc_init_rx_desc(priv->dma_rx, DMA_RX_RING_SZ, priv->dma_buf_sz);\n\txgmac_rx_refill(priv);\n\n\tpriv->tx_tail = 0;\n\tpriv->tx_head = 0;\n\tdesc_init_tx_desc(priv->dma_tx, DMA_TX_RING_SZ);\n\n\twritel(priv->dma_tx_phy, priv->base + XGMAC_DMA_TX_BASE_ADDR);\n\twritel(priv->dma_rx_phy, priv->base + XGMAC_DMA_RX_BASE_ADDR);\n\n\treturn 0;\n\nerr_dma_tx:\n\tkfree(priv->tx_skbuff);\nerr_tx_skb:\n\tdma_free_coherent(priv->device,\n\t\t\t  DMA_RX_RING_SZ * sizeof(struct xgmac_dma_desc),\n\t\t\t  priv->dma_rx, priv->dma_rx_phy);\nerr_dma_rx:\n\tkfree(priv->rx_skbuff);\n\treturn -ENOMEM;\n}\n\nstatic void xgmac_free_rx_skbufs(struct xgmac_priv *priv)\n{\n\tint i;\n\tstruct xgmac_dma_desc *p;\n\n\tif (!priv->rx_skbuff)\n\t\treturn;\n\n\tfor (i = 0; i < DMA_RX_RING_SZ; i++) {\n\t\tstruct sk_buff *skb = priv->rx_skbuff[i];\n\t\tif (skb == NULL)\n\t\t\tcontinue;\n\n\t\tp = priv->dma_rx + i;\n\t\tdma_unmap_single(priv->device, desc_get_buf_addr(p),\n\t\t\t\t priv->dma_buf_sz - NET_IP_ALIGN, DMA_FROM_DEVICE);\n\t\tdev_kfree_skb_any(skb);\n\t\tpriv->rx_skbuff[i] = NULL;\n\t}\n}\n\nstatic void xgmac_free_tx_skbufs(struct xgmac_priv *priv)\n{\n\tint i;\n\tstruct xgmac_dma_desc *p;\n\n\tif (!priv->tx_skbuff)\n\t\treturn;\n\n\tfor (i = 0; i < DMA_TX_RING_SZ; i++) {\n\t\tif (priv->tx_skbuff[i] == NULL)\n\t\t\tcontinue;\n\n\t\tp = priv->dma_tx + i;\n\t\tif (desc_get_tx_fs(p))\n\t\t\tdma_unmap_single(priv->device, desc_get_buf_addr(p),\n\t\t\t\t\t desc_get_buf_len(p), DMA_TO_DEVICE);\n\t\telse\n\t\t\tdma_unmap_page(priv->device, desc_get_buf_addr(p),\n\t\t\t\t       desc_get_buf_len(p), DMA_TO_DEVICE);\n\n\t\tif (desc_get_tx_ls(p))\n\t\t\tdev_kfree_skb_any(priv->tx_skbuff[i]);\n\t\tpriv->tx_skbuff[i] = NULL;\n\t}\n}\n\nstatic void xgmac_free_dma_desc_rings(struct xgmac_priv *priv)\n{\n\t \n\txgmac_free_rx_skbufs(priv);\n\txgmac_free_tx_skbufs(priv);\n\n\t \n\tif (priv->dma_tx) {\n\t\tdma_free_coherent(priv->device,\n\t\t\t\t  DMA_TX_RING_SZ * sizeof(struct xgmac_dma_desc),\n\t\t\t\t  priv->dma_tx, priv->dma_tx_phy);\n\t\tpriv->dma_tx = NULL;\n\t}\n\tif (priv->dma_rx) {\n\t\tdma_free_coherent(priv->device,\n\t\t\t\t  DMA_RX_RING_SZ * sizeof(struct xgmac_dma_desc),\n\t\t\t\t  priv->dma_rx, priv->dma_rx_phy);\n\t\tpriv->dma_rx = NULL;\n\t}\n\tkfree(priv->rx_skbuff);\n\tpriv->rx_skbuff = NULL;\n\tkfree(priv->tx_skbuff);\n\tpriv->tx_skbuff = NULL;\n}\n\n \nstatic void xgmac_tx_complete(struct xgmac_priv *priv)\n{\n\twhile (dma_ring_cnt(priv->tx_head, priv->tx_tail, DMA_TX_RING_SZ)) {\n\t\tunsigned int entry = priv->tx_tail;\n\t\tstruct sk_buff *skb = priv->tx_skbuff[entry];\n\t\tstruct xgmac_dma_desc *p = priv->dma_tx + entry;\n\n\t\t \n\t\tif (desc_get_owner(p))\n\t\t\tbreak;\n\n\t\tnetdev_dbg(priv->dev, \"tx ring: curr %d, dirty %d\\n\",\n\t\t\tpriv->tx_head, priv->tx_tail);\n\n\t\tif (desc_get_tx_fs(p))\n\t\t\tdma_unmap_single(priv->device, desc_get_buf_addr(p),\n\t\t\t\t\t desc_get_buf_len(p), DMA_TO_DEVICE);\n\t\telse\n\t\t\tdma_unmap_page(priv->device, desc_get_buf_addr(p),\n\t\t\t\t       desc_get_buf_len(p), DMA_TO_DEVICE);\n\n\t\t \n\t\tif (desc_get_tx_ls(p)) {\n\t\t\tdesc_get_tx_status(priv, p);\n\t\t\tdev_consume_skb_any(skb);\n\t\t}\n\n\t\tpriv->tx_skbuff[entry] = NULL;\n\t\tpriv->tx_tail = dma_ring_incr(entry, DMA_TX_RING_SZ);\n\t}\n\n\t \n\tsmp_mb();\n\tif (unlikely(netif_queue_stopped(priv->dev) &&\n\t    (tx_dma_ring_space(priv) > MAX_SKB_FRAGS)))\n\t\tnetif_wake_queue(priv->dev);\n}\n\nstatic void xgmac_tx_timeout_work(struct work_struct *work)\n{\n\tu32 reg, value;\n\tstruct xgmac_priv *priv =\n\t\tcontainer_of(work, struct xgmac_priv, tx_timeout_work);\n\n\tnapi_disable(&priv->napi);\n\n\twritel(0, priv->base + XGMAC_DMA_INTR_ENA);\n\n\tnetif_tx_lock(priv->dev);\n\n\treg = readl(priv->base + XGMAC_DMA_CONTROL);\n\twritel(reg & ~DMA_CONTROL_ST, priv->base + XGMAC_DMA_CONTROL);\n\tdo {\n\t\tvalue = readl(priv->base + XGMAC_DMA_STATUS) & 0x700000;\n\t} while (value && (value != 0x600000));\n\n\txgmac_free_tx_skbufs(priv);\n\tdesc_init_tx_desc(priv->dma_tx, DMA_TX_RING_SZ);\n\tpriv->tx_tail = 0;\n\tpriv->tx_head = 0;\n\twritel(priv->dma_tx_phy, priv->base + XGMAC_DMA_TX_BASE_ADDR);\n\twritel(reg | DMA_CONTROL_ST, priv->base + XGMAC_DMA_CONTROL);\n\n\twritel(DMA_STATUS_TU | DMA_STATUS_TPS | DMA_STATUS_NIS | DMA_STATUS_AIS,\n\t\tpriv->base + XGMAC_DMA_STATUS);\n\n\tnetif_tx_unlock(priv->dev);\n\tnetif_wake_queue(priv->dev);\n\n\tnapi_enable(&priv->napi);\n\n\t \n\twritel(DMA_INTR_DEFAULT_MASK, priv->base + XGMAC_DMA_STATUS);\n\twritel(DMA_INTR_DEFAULT_MASK, priv->base + XGMAC_DMA_INTR_ENA);\n}\n\nstatic int xgmac_hw_init(struct net_device *dev)\n{\n\tu32 value, ctrl;\n\tint limit;\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid __iomem *ioaddr = priv->base;\n\n\t \n\tctrl = readl(ioaddr + XGMAC_CONTROL) & XGMAC_CONTROL_SPD_MASK;\n\n\t \n\tvalue = DMA_BUS_MODE_SFT_RESET;\n\twritel(value, ioaddr + XGMAC_DMA_BUS_MODE);\n\tlimit = 15000;\n\twhile (limit-- &&\n\t\t(readl(ioaddr + XGMAC_DMA_BUS_MODE) & DMA_BUS_MODE_SFT_RESET))\n\t\tcpu_relax();\n\tif (limit < 0)\n\t\treturn -EBUSY;\n\n\tvalue = (0x10 << DMA_BUS_MODE_PBL_SHIFT) |\n\t\t(0x10 << DMA_BUS_MODE_RPBL_SHIFT) |\n\t\tDMA_BUS_MODE_FB | DMA_BUS_MODE_ATDS | DMA_BUS_MODE_AAL;\n\twritel(value, ioaddr + XGMAC_DMA_BUS_MODE);\n\n\twritel(0, ioaddr + XGMAC_DMA_INTR_ENA);\n\n\t \n\twritel(XGMAC_INT_STAT_PMTIM, ioaddr + XGMAC_INT_STAT);\n\n\t \n\twritel(0x0077000E, ioaddr + XGMAC_DMA_AXI_BUS);\n\n\tctrl |= XGMAC_CONTROL_DDIC | XGMAC_CONTROL_JE | XGMAC_CONTROL_ACS |\n\t\tXGMAC_CONTROL_CAR;\n\tif (dev->features & NETIF_F_RXCSUM)\n\t\tctrl |= XGMAC_CONTROL_IPC;\n\twritel(ctrl, ioaddr + XGMAC_CONTROL);\n\n\twritel(DMA_CONTROL_OSF, ioaddr + XGMAC_DMA_CONTROL);\n\n\t \n\twritel(XGMAC_OMR_TSF | XGMAC_OMR_RFD | XGMAC_OMR_RFA |\n\t\tXGMAC_OMR_RTC_256,\n\t\tioaddr + XGMAC_OMR);\n\n\t \n\twritel(1, ioaddr + XGMAC_MMC_CTRL);\n\treturn 0;\n}\n\n \nstatic int xgmac_open(struct net_device *dev)\n{\n\tint ret;\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid __iomem *ioaddr = priv->base;\n\n\t \n\tif (!is_valid_ether_addr(dev->dev_addr)) {\n\t\teth_hw_addr_random(dev);\n\t\tnetdev_dbg(priv->dev, \"generated random MAC address %pM\\n\",\n\t\t\tdev->dev_addr);\n\t}\n\n\tmemset(&priv->xstats, 0, sizeof(struct xgmac_extra_stats));\n\n\t \n\txgmac_hw_init(dev);\n\txgmac_set_mac_addr(ioaddr, dev->dev_addr, 0);\n\txgmac_set_flow_ctrl(priv, priv->rx_pause, priv->tx_pause);\n\n\tret = xgmac_dma_desc_rings_init(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t \n\txgmac_mac_enable(ioaddr);\n\n\tnapi_enable(&priv->napi);\n\tnetif_start_queue(dev);\n\n\t \n\twritel(DMA_INTR_DEFAULT_MASK, ioaddr + XGMAC_DMA_STATUS);\n\twritel(DMA_INTR_DEFAULT_MASK, ioaddr + XGMAC_DMA_INTR_ENA);\n\n\treturn 0;\n}\n\n \nstatic int xgmac_stop(struct net_device *dev)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\n\tif (readl(priv->base + XGMAC_DMA_INTR_ENA))\n\t\tnapi_disable(&priv->napi);\n\n\twritel(0, priv->base + XGMAC_DMA_INTR_ENA);\n\n\tnetif_tx_disable(dev);\n\n\t \n\txgmac_mac_disable(priv->base);\n\n\t \n\txgmac_free_dma_desc_rings(priv);\n\n\treturn 0;\n}\n\n \nstatic netdev_tx_t xgmac_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tunsigned int entry;\n\tint i;\n\tu32 irq_flag;\n\tint nfrags = skb_shinfo(skb)->nr_frags;\n\tstruct xgmac_dma_desc *desc, *first;\n\tunsigned int desc_flags;\n\tunsigned int len;\n\tdma_addr_t paddr;\n\n\tpriv->tx_irq_cnt = (priv->tx_irq_cnt + 1) & (DMA_TX_RING_SZ/4 - 1);\n\tirq_flag = priv->tx_irq_cnt ? 0 : TXDESC_INTERRUPT;\n\n\tdesc_flags = (skb->ip_summed == CHECKSUM_PARTIAL) ?\n\t\tTXDESC_CSUM_ALL : 0;\n\tentry = priv->tx_head;\n\tdesc = priv->dma_tx + entry;\n\tfirst = desc;\n\n\tlen = skb_headlen(skb);\n\tpaddr = dma_map_single(priv->device, skb->data, len, DMA_TO_DEVICE);\n\tif (dma_mapping_error(priv->device, paddr)) {\n\t\tdev_kfree_skb_any(skb);\n\t\treturn NETDEV_TX_OK;\n\t}\n\tpriv->tx_skbuff[entry] = skb;\n\tdesc_set_buf_addr_and_size(desc, paddr, len);\n\n\tfor (i = 0; i < nfrags; i++) {\n\t\tskb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\n\t\tlen = skb_frag_size(frag);\n\n\t\tpaddr = skb_frag_dma_map(priv->device, frag, 0, len,\n\t\t\t\t\t DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(priv->device, paddr))\n\t\t\tgoto dma_err;\n\n\t\tentry = dma_ring_incr(entry, DMA_TX_RING_SZ);\n\t\tdesc = priv->dma_tx + entry;\n\t\tpriv->tx_skbuff[entry] = skb;\n\n\t\tdesc_set_buf_addr_and_size(desc, paddr, len);\n\t\tif (i < (nfrags - 1))\n\t\t\tdesc_set_tx_owner(desc, desc_flags);\n\t}\n\n\t \n\tif (desc != first)\n\t\tdesc_set_tx_owner(desc, desc_flags |\n\t\t\tTXDESC_LAST_SEG | irq_flag);\n\telse\n\t\tdesc_flags |= TXDESC_LAST_SEG | irq_flag;\n\n\t \n\twmb();\n\tdesc_set_tx_owner(first, desc_flags | TXDESC_FIRST_SEG);\n\n\twritel(1, priv->base + XGMAC_DMA_TX_POLL);\n\n\tpriv->tx_head = dma_ring_incr(entry, DMA_TX_RING_SZ);\n\n\t \n\tsmp_mb();\n\tif (unlikely(tx_dma_ring_space(priv) <= MAX_SKB_FRAGS)) {\n\t\tnetif_stop_queue(dev);\n\t\t \n\t\tsmp_mb();\n\t\tif (tx_dma_ring_space(priv) > MAX_SKB_FRAGS)\n\t\t\tnetif_start_queue(dev);\n\t}\n\treturn NETDEV_TX_OK;\n\ndma_err:\n\tentry = priv->tx_head;\n\tfor ( ; i > 0; i--) {\n\t\tentry = dma_ring_incr(entry, DMA_TX_RING_SZ);\n\t\tdesc = priv->dma_tx + entry;\n\t\tpriv->tx_skbuff[entry] = NULL;\n\t\tdma_unmap_page(priv->device, desc_get_buf_addr(desc),\n\t\t\t       desc_get_buf_len(desc), DMA_TO_DEVICE);\n\t\tdesc_clear_tx_owner(desc);\n\t}\n\tdesc = first;\n\tdma_unmap_single(priv->device, desc_get_buf_addr(desc),\n\t\t\t desc_get_buf_len(desc), DMA_TO_DEVICE);\n\tdev_kfree_skb_any(skb);\n\treturn NETDEV_TX_OK;\n}\n\nstatic int xgmac_rx(struct xgmac_priv *priv, int limit)\n{\n\tunsigned int entry;\n\tunsigned int count = 0;\n\tstruct xgmac_dma_desc *p;\n\n\twhile (count < limit) {\n\t\tint ip_checksum;\n\t\tstruct sk_buff *skb;\n\t\tint frame_len;\n\n\t\tif (!dma_ring_cnt(priv->rx_head, priv->rx_tail, DMA_RX_RING_SZ))\n\t\t\tbreak;\n\n\t\tentry = priv->rx_tail;\n\t\tp = priv->dma_rx + entry;\n\t\tif (desc_get_owner(p))\n\t\t\tbreak;\n\n\t\tcount++;\n\t\tpriv->rx_tail = dma_ring_incr(priv->rx_tail, DMA_RX_RING_SZ);\n\n\t\t \n\t\tip_checksum = desc_get_rx_status(priv, p);\n\t\tif (ip_checksum < 0)\n\t\t\tcontinue;\n\n\t\tskb = priv->rx_skbuff[entry];\n\t\tif (unlikely(!skb)) {\n\t\t\tnetdev_err(priv->dev, \"Inconsistent Rx descriptor chain\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tpriv->rx_skbuff[entry] = NULL;\n\n\t\tframe_len = desc_get_rx_frame_len(p);\n\t\tnetdev_dbg(priv->dev, \"RX frame size %d, COE status: %d\\n\",\n\t\t\tframe_len, ip_checksum);\n\n\t\tskb_put(skb, frame_len);\n\t\tdma_unmap_single(priv->device, desc_get_buf_addr(p),\n\t\t\t\t priv->dma_buf_sz - NET_IP_ALIGN, DMA_FROM_DEVICE);\n\n\t\tskb->protocol = eth_type_trans(skb, priv->dev);\n\t\tskb->ip_summed = ip_checksum;\n\t\tif (ip_checksum == CHECKSUM_NONE)\n\t\t\tnetif_receive_skb(skb);\n\t\telse\n\t\t\tnapi_gro_receive(&priv->napi, skb);\n\t}\n\n\txgmac_rx_refill(priv);\n\n\treturn count;\n}\n\n \nstatic int xgmac_poll(struct napi_struct *napi, int budget)\n{\n\tstruct xgmac_priv *priv = container_of(napi,\n\t\t\t\t       struct xgmac_priv, napi);\n\tint work_done = 0;\n\n\txgmac_tx_complete(priv);\n\twork_done = xgmac_rx(priv, budget);\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(napi, work_done);\n\t\t__raw_writel(DMA_INTR_DEFAULT_MASK, priv->base + XGMAC_DMA_INTR_ENA);\n\t}\n\treturn work_done;\n}\n\n \nstatic void xgmac_tx_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tschedule_work(&priv->tx_timeout_work);\n}\n\n \nstatic void xgmac_set_rx_mode(struct net_device *dev)\n{\n\tint i;\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid __iomem *ioaddr = priv->base;\n\tunsigned int value = 0;\n\tu32 hash_filter[XGMAC_NUM_HASH];\n\tint reg = 1;\n\tstruct netdev_hw_addr *ha;\n\tbool use_hash = false;\n\n\tnetdev_dbg(priv->dev, \"# mcasts %d, # unicast %d\\n\",\n\t\t netdev_mc_count(dev), netdev_uc_count(dev));\n\n\tif (dev->flags & IFF_PROMISC)\n\t\tvalue |= XGMAC_FRAME_FILTER_PR;\n\n\tmemset(hash_filter, 0, sizeof(hash_filter));\n\n\tif (netdev_uc_count(dev) > priv->max_macs) {\n\t\tuse_hash = true;\n\t\tvalue |= XGMAC_FRAME_FILTER_HUC | XGMAC_FRAME_FILTER_HPF;\n\t}\n\tnetdev_for_each_uc_addr(ha, dev) {\n\t\tif (use_hash) {\n\t\t\tu32 bit_nr = ~ether_crc(ETH_ALEN, ha->addr) >> 23;\n\n\t\t\t \n\t\t\thash_filter[bit_nr >> 5] |= 1 << (bit_nr & 31);\n\t\t} else {\n\t\t\txgmac_set_mac_addr(ioaddr, ha->addr, reg);\n\t\t\treg++;\n\t\t}\n\t}\n\n\tif (dev->flags & IFF_ALLMULTI) {\n\t\tvalue |= XGMAC_FRAME_FILTER_PM;\n\t\tgoto out;\n\t}\n\n\tif ((netdev_mc_count(dev) + reg - 1) > priv->max_macs) {\n\t\tuse_hash = true;\n\t\tvalue |= XGMAC_FRAME_FILTER_HMC | XGMAC_FRAME_FILTER_HPF;\n\t} else {\n\t\tuse_hash = false;\n\t}\n\tnetdev_for_each_mc_addr(ha, dev) {\n\t\tif (use_hash) {\n\t\t\tu32 bit_nr = ~ether_crc(ETH_ALEN, ha->addr) >> 23;\n\n\t\t\t \n\t\t\thash_filter[bit_nr >> 5] |= 1 << (bit_nr & 31);\n\t\t} else {\n\t\t\txgmac_set_mac_addr(ioaddr, ha->addr, reg);\n\t\t\treg++;\n\t\t}\n\t}\n\nout:\n\tfor (i = reg; i <= priv->max_macs; i++)\n\t\txgmac_set_mac_addr(ioaddr, NULL, i);\n\tfor (i = 0; i < XGMAC_NUM_HASH; i++)\n\t\twritel(hash_filter[i], ioaddr + XGMAC_HASH(i));\n\n\twritel(value, ioaddr + XGMAC_FRAME_FILTER);\n}\n\n \nstatic int xgmac_change_mtu(struct net_device *dev, int new_mtu)\n{\n\t \n\tif (!netif_running(dev))\n\t\treturn 0;\n\n\t \n\txgmac_stop(dev);\n\tdev->mtu = new_mtu;\n\treturn xgmac_open(dev);\n}\n\nstatic irqreturn_t xgmac_pmt_interrupt(int irq, void *dev_id)\n{\n\tu32 intr_status;\n\tstruct net_device *dev = (struct net_device *)dev_id;\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid __iomem *ioaddr = priv->base;\n\n\tintr_status = __raw_readl(ioaddr + XGMAC_INT_STAT);\n\tif (intr_status & XGMAC_INT_STAT_PMT) {\n\t\tnetdev_dbg(priv->dev, \"received Magic frame\\n\");\n\t\t \n\t\treadl(ioaddr + XGMAC_PMT);\n\t}\n\treturn IRQ_HANDLED;\n}\n\nstatic irqreturn_t xgmac_interrupt(int irq, void *dev_id)\n{\n\tu32 intr_status;\n\tstruct net_device *dev = (struct net_device *)dev_id;\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tstruct xgmac_extra_stats *x = &priv->xstats;\n\n\t \n\tintr_status = __raw_readl(priv->base + XGMAC_DMA_STATUS);\n\tintr_status &= __raw_readl(priv->base + XGMAC_DMA_INTR_ENA);\n\t__raw_writel(intr_status, priv->base + XGMAC_DMA_STATUS);\n\n\t \n\t \n\tif (unlikely(intr_status & DMA_STATUS_AIS)) {\n\t\tif (intr_status & DMA_STATUS_TJT) {\n\t\t\tnetdev_err(priv->dev, \"transmit jabber\\n\");\n\t\t\tx->tx_jabber++;\n\t\t}\n\t\tif (intr_status & DMA_STATUS_RU)\n\t\t\tx->rx_buf_unav++;\n\t\tif (intr_status & DMA_STATUS_RPS) {\n\t\t\tnetdev_err(priv->dev, \"receive process stopped\\n\");\n\t\t\tx->rx_process_stopped++;\n\t\t}\n\t\tif (intr_status & DMA_STATUS_ETI) {\n\t\t\tnetdev_err(priv->dev, \"transmit early interrupt\\n\");\n\t\t\tx->tx_early++;\n\t\t}\n\t\tif (intr_status & DMA_STATUS_TPS) {\n\t\t\tnetdev_err(priv->dev, \"transmit process stopped\\n\");\n\t\t\tx->tx_process_stopped++;\n\t\t\tschedule_work(&priv->tx_timeout_work);\n\t\t}\n\t\tif (intr_status & DMA_STATUS_FBI) {\n\t\t\tnetdev_err(priv->dev, \"fatal bus error\\n\");\n\t\t\tx->fatal_bus_error++;\n\t\t}\n\t}\n\n\t \n\tif (intr_status & (DMA_STATUS_RI | DMA_STATUS_TU | DMA_STATUS_TI)) {\n\t\t__raw_writel(DMA_INTR_ABNORMAL, priv->base + XGMAC_DMA_INTR_ENA);\n\t\tnapi_schedule(&priv->napi);\n\t}\n\n\treturn IRQ_HANDLED;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\n \nstatic void xgmac_poll_controller(struct net_device *dev)\n{\n\tdisable_irq(dev->irq);\n\txgmac_interrupt(dev->irq, dev);\n\tenable_irq(dev->irq);\n}\n#endif\n\nstatic void\nxgmac_get_stats64(struct net_device *dev,\n\t\t  struct rtnl_link_stats64 *storage)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid __iomem *base = priv->base;\n\tu32 count;\n\n\tspin_lock_bh(&priv->stats_lock);\n\twritel(XGMAC_MMC_CTRL_CNT_FRZ, base + XGMAC_MMC_CTRL);\n\n\tstorage->rx_bytes = readl(base + XGMAC_MMC_RXOCTET_G_LO);\n\tstorage->rx_bytes |= (u64)(readl(base + XGMAC_MMC_RXOCTET_G_HI)) << 32;\n\n\tstorage->rx_packets = readl(base + XGMAC_MMC_RXFRAME_GB_LO);\n\tstorage->multicast = readl(base + XGMAC_MMC_RXMCFRAME_G);\n\tstorage->rx_crc_errors = readl(base + XGMAC_MMC_RXCRCERR);\n\tstorage->rx_length_errors = readl(base + XGMAC_MMC_RXLENGTHERR);\n\tstorage->rx_missed_errors = readl(base + XGMAC_MMC_RXOVERFLOW);\n\n\tstorage->tx_bytes = readl(base + XGMAC_MMC_TXOCTET_G_LO);\n\tstorage->tx_bytes |= (u64)(readl(base + XGMAC_MMC_TXOCTET_G_HI)) << 32;\n\n\tcount = readl(base + XGMAC_MMC_TXFRAME_GB_LO);\n\tstorage->tx_errors = count - readl(base + XGMAC_MMC_TXFRAME_G_LO);\n\tstorage->tx_packets = count;\n\tstorage->tx_fifo_errors = readl(base + XGMAC_MMC_TXUNDERFLOW);\n\n\twritel(0, base + XGMAC_MMC_CTRL);\n\tspin_unlock_bh(&priv->stats_lock);\n}\n\nstatic int xgmac_set_mac_address(struct net_device *dev, void *p)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid __iomem *ioaddr = priv->base;\n\tstruct sockaddr *addr = p;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(dev, addr->sa_data);\n\n\txgmac_set_mac_addr(ioaddr, dev->dev_addr, 0);\n\n\treturn 0;\n}\n\nstatic int xgmac_set_features(struct net_device *dev, netdev_features_t features)\n{\n\tu32 ctrl;\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid __iomem *ioaddr = priv->base;\n\tnetdev_features_t changed = dev->features ^ features;\n\n\tif (!(changed & NETIF_F_RXCSUM))\n\t\treturn 0;\n\n\tctrl = readl(ioaddr + XGMAC_CONTROL);\n\tif (features & NETIF_F_RXCSUM)\n\t\tctrl |= XGMAC_CONTROL_IPC;\n\telse\n\t\tctrl &= ~XGMAC_CONTROL_IPC;\n\twritel(ctrl, ioaddr + XGMAC_CONTROL);\n\n\treturn 0;\n}\n\nstatic const struct net_device_ops xgmac_netdev_ops = {\n\t.ndo_open = xgmac_open,\n\t.ndo_start_xmit = xgmac_xmit,\n\t.ndo_stop = xgmac_stop,\n\t.ndo_change_mtu = xgmac_change_mtu,\n\t.ndo_set_rx_mode = xgmac_set_rx_mode,\n\t.ndo_tx_timeout = xgmac_tx_timeout,\n\t.ndo_get_stats64 = xgmac_get_stats64,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller = xgmac_poll_controller,\n#endif\n\t.ndo_set_mac_address = xgmac_set_mac_address,\n\t.ndo_set_features = xgmac_set_features,\n};\n\nstatic int xgmac_ethtool_get_link_ksettings(struct net_device *dev,\n\t\t\t\t\t    struct ethtool_link_ksettings *cmd)\n{\n\tcmd->base.autoneg = 0;\n\tcmd->base.duplex = DUPLEX_FULL;\n\tcmd->base.speed = 10000;\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.supported, 0);\n\tethtool_convert_legacy_u32_to_link_mode(cmd->link_modes.advertising, 0);\n\treturn 0;\n}\n\nstatic void xgmac_get_pauseparam(struct net_device *netdev,\n\t\t\t\t      struct ethtool_pauseparam *pause)\n{\n\tstruct xgmac_priv *priv = netdev_priv(netdev);\n\n\tpause->rx_pause = priv->rx_pause;\n\tpause->tx_pause = priv->tx_pause;\n}\n\nstatic int xgmac_set_pauseparam(struct net_device *netdev,\n\t\t\t\t     struct ethtool_pauseparam *pause)\n{\n\tstruct xgmac_priv *priv = netdev_priv(netdev);\n\n\tif (pause->autoneg)\n\t\treturn -EINVAL;\n\n\treturn xgmac_set_flow_ctrl(priv, pause->rx_pause, pause->tx_pause);\n}\n\nstruct xgmac_stats {\n\tchar stat_string[ETH_GSTRING_LEN];\n\tint stat_offset;\n\tbool is_reg;\n};\n\n#define XGMAC_STAT(m)\t\\\n\t{ #m, offsetof(struct xgmac_priv, xstats.m), false }\n#define XGMAC_HW_STAT(m, reg_offset)\t\\\n\t{ #m, reg_offset, true }\n\nstatic const struct xgmac_stats xgmac_gstrings_stats[] = {\n\tXGMAC_STAT(tx_frame_flushed),\n\tXGMAC_STAT(tx_payload_error),\n\tXGMAC_STAT(tx_ip_header_error),\n\tXGMAC_STAT(tx_local_fault),\n\tXGMAC_STAT(tx_remote_fault),\n\tXGMAC_STAT(tx_early),\n\tXGMAC_STAT(tx_process_stopped),\n\tXGMAC_STAT(tx_jabber),\n\tXGMAC_STAT(rx_buf_unav),\n\tXGMAC_STAT(rx_process_stopped),\n\tXGMAC_STAT(rx_payload_error),\n\tXGMAC_STAT(rx_ip_header_error),\n\tXGMAC_STAT(rx_da_filter_fail),\n\tXGMAC_STAT(fatal_bus_error),\n\tXGMAC_HW_STAT(rx_watchdog, XGMAC_MMC_RXWATCHDOG),\n\tXGMAC_HW_STAT(tx_vlan, XGMAC_MMC_TXVLANFRAME),\n\tXGMAC_HW_STAT(rx_vlan, XGMAC_MMC_RXVLANFRAME),\n\tXGMAC_HW_STAT(tx_pause, XGMAC_MMC_TXPAUSEFRAME),\n\tXGMAC_HW_STAT(rx_pause, XGMAC_MMC_RXPAUSEFRAME),\n};\n#define XGMAC_STATS_LEN ARRAY_SIZE(xgmac_gstrings_stats)\n\nstatic void xgmac_get_ethtool_stats(struct net_device *dev,\n\t\t\t\t\t struct ethtool_stats *dummy,\n\t\t\t\t\t u64 *data)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tvoid *p = priv;\n\tint i;\n\n\tfor (i = 0; i < XGMAC_STATS_LEN; i++) {\n\t\tif (xgmac_gstrings_stats[i].is_reg)\n\t\t\t*data++ = readl(priv->base +\n\t\t\t\txgmac_gstrings_stats[i].stat_offset);\n\t\telse\n\t\t\t*data++ = *(u32 *)(p +\n\t\t\t\txgmac_gstrings_stats[i].stat_offset);\n\t}\n}\n\nstatic int xgmac_get_sset_count(struct net_device *netdev, int sset)\n{\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn XGMAC_STATS_LEN;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}\n\nstatic void xgmac_get_strings(struct net_device *dev, u32 stringset,\n\t\t\t\t   u8 *data)\n{\n\tint i;\n\tu8 *p = data;\n\n\tswitch (stringset) {\n\tcase ETH_SS_STATS:\n\t\tfor (i = 0; i < XGMAC_STATS_LEN; i++) {\n\t\t\tmemcpy(p, xgmac_gstrings_stats[i].stat_string,\n\t\t\t       ETH_GSTRING_LEN);\n\t\t\tp += ETH_GSTRING_LEN;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tWARN_ON(1);\n\t\tbreak;\n\t}\n}\n\nstatic void xgmac_get_wol(struct net_device *dev,\n\t\t\t       struct ethtool_wolinfo *wol)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\n\tif (device_can_wakeup(priv->device)) {\n\t\twol->supported = WAKE_MAGIC | WAKE_UCAST;\n\t\twol->wolopts = priv->wolopts;\n\t}\n}\n\nstatic int xgmac_set_wol(struct net_device *dev,\n\t\t\t      struct ethtool_wolinfo *wol)\n{\n\tstruct xgmac_priv *priv = netdev_priv(dev);\n\tu32 support = WAKE_MAGIC | WAKE_UCAST;\n\n\tif (!device_can_wakeup(priv->device))\n\t\treturn -ENOTSUPP;\n\n\tif (wol->wolopts & ~support)\n\t\treturn -EINVAL;\n\n\tpriv->wolopts = wol->wolopts;\n\n\tif (wol->wolopts) {\n\t\tdevice_set_wakeup_enable(priv->device, 1);\n\t\tenable_irq_wake(dev->irq);\n\t} else {\n\t\tdevice_set_wakeup_enable(priv->device, 0);\n\t\tdisable_irq_wake(dev->irq);\n\t}\n\n\treturn 0;\n}\n\nstatic const struct ethtool_ops xgmac_ethtool_ops = {\n\t.get_link = ethtool_op_get_link,\n\t.get_pauseparam = xgmac_get_pauseparam,\n\t.set_pauseparam = xgmac_set_pauseparam,\n\t.get_ethtool_stats = xgmac_get_ethtool_stats,\n\t.get_strings = xgmac_get_strings,\n\t.get_wol = xgmac_get_wol,\n\t.set_wol = xgmac_set_wol,\n\t.get_sset_count = xgmac_get_sset_count,\n\t.get_link_ksettings = xgmac_ethtool_get_link_ksettings,\n};\n\n \nstatic int xgmac_probe(struct platform_device *pdev)\n{\n\tint ret = 0;\n\tstruct resource *res;\n\tstruct net_device *ndev = NULL;\n\tstruct xgmac_priv *priv = NULL;\n\tu8 addr[ETH_ALEN];\n\tu32 uid;\n\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\tif (!res)\n\t\treturn -ENODEV;\n\n\tif (!request_mem_region(res->start, resource_size(res), pdev->name))\n\t\treturn -EBUSY;\n\n\tndev = alloc_etherdev(sizeof(struct xgmac_priv));\n\tif (!ndev) {\n\t\tret = -ENOMEM;\n\t\tgoto err_alloc;\n\t}\n\n\tSET_NETDEV_DEV(ndev, &pdev->dev);\n\tpriv = netdev_priv(ndev);\n\tplatform_set_drvdata(pdev, ndev);\n\tndev->netdev_ops = &xgmac_netdev_ops;\n\tndev->ethtool_ops = &xgmac_ethtool_ops;\n\tspin_lock_init(&priv->stats_lock);\n\tINIT_WORK(&priv->tx_timeout_work, xgmac_tx_timeout_work);\n\n\tpriv->device = &pdev->dev;\n\tpriv->dev = ndev;\n\tpriv->rx_pause = 1;\n\tpriv->tx_pause = 1;\n\n\tpriv->base = ioremap(res->start, resource_size(res));\n\tif (!priv->base) {\n\t\tnetdev_err(ndev, \"ioremap failed\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto err_io;\n\t}\n\n\tuid = readl(priv->base + XGMAC_VERSION);\n\tnetdev_info(ndev, \"h/w version is 0x%x\\n\", uid);\n\n\t \n\twritel(1, priv->base + XGMAC_ADDR_HIGH(31));\n\tif (readl(priv->base + XGMAC_ADDR_HIGH(31)) == 1)\n\t\tpriv->max_macs = 31;\n\telse\n\t\tpriv->max_macs = 7;\n\n\twritel(0, priv->base + XGMAC_DMA_INTR_ENA);\n\tndev->irq = platform_get_irq(pdev, 0);\n\tif (ndev->irq == -ENXIO) {\n\t\tnetdev_err(ndev, \"No irq resource\\n\");\n\t\tret = ndev->irq;\n\t\tgoto err_irq;\n\t}\n\n\tret = request_irq(ndev->irq, xgmac_interrupt, 0,\n\t\t\t  dev_name(&pdev->dev), ndev);\n\tif (ret < 0) {\n\t\tnetdev_err(ndev, \"Could not request irq %d - ret %d)\\n\",\n\t\t\tndev->irq, ret);\n\t\tgoto err_irq;\n\t}\n\n\tpriv->pmt_irq = platform_get_irq(pdev, 1);\n\tif (priv->pmt_irq == -ENXIO) {\n\t\tnetdev_err(ndev, \"No pmt irq resource\\n\");\n\t\tret = priv->pmt_irq;\n\t\tgoto err_pmt_irq;\n\t}\n\n\tret = request_irq(priv->pmt_irq, xgmac_pmt_interrupt, 0,\n\t\t\t  dev_name(&pdev->dev), ndev);\n\tif (ret < 0) {\n\t\tnetdev_err(ndev, \"Could not request irq %d - ret %d)\\n\",\n\t\t\tpriv->pmt_irq, ret);\n\t\tgoto err_pmt_irq;\n\t}\n\n\tdevice_set_wakeup_capable(&pdev->dev, 1);\n\tif (device_can_wakeup(priv->device))\n\t\tpriv->wolopts = WAKE_MAGIC;\t \n\n\tndev->hw_features = NETIF_F_SG | NETIF_F_HIGHDMA;\n\tif (readl(priv->base + XGMAC_DMA_HW_FEATURE) & DMA_HW_FEAT_TXCOESEL)\n\t\tndev->hw_features |= NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |\n\t\t\t\t     NETIF_F_RXCSUM;\n\tndev->features |= ndev->hw_features;\n\tndev->priv_flags |= IFF_UNICAST_FLT;\n\n\t \n\tndev->min_mtu = ETH_ZLEN - ETH_HLEN;\n\tndev->max_mtu = XGMAC_MAX_MTU;\n\n\t \n\txgmac_get_mac_addr(priv->base, addr, 0);\n\teth_hw_addr_set(ndev, addr);\n\tif (!is_valid_ether_addr(ndev->dev_addr))\n\t\tnetdev_warn(ndev, \"MAC address %pM not valid\",\n\t\t\t ndev->dev_addr);\n\n\tnetif_napi_add(ndev, &priv->napi, xgmac_poll);\n\tret = register_netdev(ndev);\n\tif (ret)\n\t\tgoto err_reg;\n\n\treturn 0;\n\nerr_reg:\n\tnetif_napi_del(&priv->napi);\n\tfree_irq(priv->pmt_irq, ndev);\nerr_pmt_irq:\n\tfree_irq(ndev->irq, ndev);\nerr_irq:\n\tiounmap(priv->base);\nerr_io:\n\tfree_netdev(ndev);\nerr_alloc:\n\trelease_mem_region(res->start, resource_size(res));\n\treturn ret;\n}\n\n \nstatic int xgmac_remove(struct platform_device *pdev)\n{\n\tstruct net_device *ndev = platform_get_drvdata(pdev);\n\tstruct xgmac_priv *priv = netdev_priv(ndev);\n\tstruct resource *res;\n\n\txgmac_mac_disable(priv->base);\n\n\t \n\tfree_irq(ndev->irq, ndev);\n\tfree_irq(priv->pmt_irq, ndev);\n\n\tunregister_netdev(ndev);\n\tnetif_napi_del(&priv->napi);\n\n\tiounmap(priv->base);\n\tres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\n\trelease_mem_region(res->start, resource_size(res));\n\n\tfree_netdev(ndev);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_PM_SLEEP\nstatic void xgmac_pmt(void __iomem *ioaddr, unsigned long mode)\n{\n\tunsigned int pmt = 0;\n\n\tif (mode & WAKE_MAGIC)\n\t\tpmt |= XGMAC_PMT_POWERDOWN | XGMAC_PMT_MAGIC_PKT_EN;\n\tif (mode & WAKE_UCAST)\n\t\tpmt |= XGMAC_PMT_POWERDOWN | XGMAC_PMT_GLBL_UNICAST;\n\n\twritel(pmt, ioaddr + XGMAC_PMT);\n}\n\nstatic int xgmac_suspend(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct xgmac_priv *priv = netdev_priv(ndev);\n\tu32 value;\n\n\tif (!ndev || !netif_running(ndev))\n\t\treturn 0;\n\n\tnetif_device_detach(ndev);\n\tnapi_disable(&priv->napi);\n\twritel(0, priv->base + XGMAC_DMA_INTR_ENA);\n\n\tif (device_may_wakeup(priv->device)) {\n\t\t \n\t\tvalue = readl(priv->base + XGMAC_DMA_CONTROL);\n\t\tvalue &= ~(DMA_CONTROL_ST | DMA_CONTROL_SR);\n\t\twritel(value, priv->base + XGMAC_DMA_CONTROL);\n\n\t\txgmac_pmt(priv->base, priv->wolopts);\n\t} else\n\t\txgmac_mac_disable(priv->base);\n\n\treturn 0;\n}\n\nstatic int xgmac_resume(struct device *dev)\n{\n\tstruct net_device *ndev = dev_get_drvdata(dev);\n\tstruct xgmac_priv *priv = netdev_priv(ndev);\n\tvoid __iomem *ioaddr = priv->base;\n\n\tif (!netif_running(ndev))\n\t\treturn 0;\n\n\txgmac_pmt(ioaddr, 0);\n\n\t \n\txgmac_mac_enable(ioaddr);\n\twritel(DMA_INTR_DEFAULT_MASK, ioaddr + XGMAC_DMA_STATUS);\n\twritel(DMA_INTR_DEFAULT_MASK, ioaddr + XGMAC_DMA_INTR_ENA);\n\n\tnetif_device_attach(ndev);\n\tnapi_enable(&priv->napi);\n\n\treturn 0;\n}\n#endif  \n\nstatic SIMPLE_DEV_PM_OPS(xgmac_pm_ops, xgmac_suspend, xgmac_resume);\n\nstatic const struct of_device_id xgmac_of_match[] = {\n\t{ .compatible = \"calxeda,hb-xgmac\", },\n\t{},\n};\nMODULE_DEVICE_TABLE(of, xgmac_of_match);\n\nstatic struct platform_driver xgmac_driver = {\n\t.driver = {\n\t\t.name = \"calxedaxgmac\",\n\t\t.of_match_table = xgmac_of_match,\n\t\t.pm = &xgmac_pm_ops,\n\t},\n\t.probe = xgmac_probe,\n\t.remove = xgmac_remove,\n};\n\nmodule_platform_driver(xgmac_driver);\n\nMODULE_AUTHOR(\"Calxeda, Inc.\");\nMODULE_DESCRIPTION(\"Calxeda 10G XGMAC driver\");\nMODULE_LICENSE(\"GPL v2\");\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}