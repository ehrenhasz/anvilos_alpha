{
  "module_name": "sundance.c",
  "hash_id": "0d7c1eda70f07a2bc27b0678d23f80f0bf6c3c9f2b136dd9c490b524895443fa",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/dlink/sundance.c",
  "human_readable_source": " \n \n\n#define DRV_NAME\t\"sundance\"\n\n \nstatic int debug = 1;\t\t\t \n \nstatic const int multicast_filter_limit = 32;\n\n \nstatic int rx_copybreak;\nstatic int flowctrl=1;\n\n \n#define MAX_UNITS 8\nstatic char *media[MAX_UNITS];\n\n\n \n\n \n#define TX_RING_SIZE\t32\n#define TX_QUEUE_LEN\t(TX_RING_SIZE - 1)  \n#define RX_RING_SIZE\t64\n#define RX_BUDGET\t32\n#define TX_TOTAL_SIZE\tTX_RING_SIZE*sizeof(struct netdev_desc)\n#define RX_TOTAL_SIZE\tRX_RING_SIZE*sizeof(struct netdev_desc)\n\n \n \n#define TX_TIMEOUT  (4*HZ)\n#define PKT_BUF_SZ\t\t1536\t \n\n \n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/string.h>\n#include <linux/timer.h>\n#include <linux/errno.h>\n#include <linux/ioport.h>\n#include <linux/interrupt.h>\n#include <linux/pci.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/skbuff.h>\n#include <linux/init.h>\n#include <linux/bitops.h>\n#include <linux/uaccess.h>\n#include <asm/processor.h>\t\t \n#include <asm/io.h>\n#include <linux/delay.h>\n#include <linux/spinlock.h>\n#include <linux/dma-mapping.h>\n#include <linux/crc32.h>\n#include <linux/ethtool.h>\n#include <linux/mii.h>\n\nMODULE_AUTHOR(\"Donald Becker <becker@scyld.com>\");\nMODULE_DESCRIPTION(\"Sundance Alta Ethernet driver\");\nMODULE_LICENSE(\"GPL\");\n\nmodule_param(debug, int, 0);\nmodule_param(rx_copybreak, int, 0);\nmodule_param_array(media, charp, NULL, 0);\nmodule_param(flowctrl, int, 0);\nMODULE_PARM_DESC(debug, \"Sundance Alta debug level (0-5)\");\nMODULE_PARM_DESC(rx_copybreak, \"Sundance Alta copy breakpoint for copy-only-tiny-frames\");\nMODULE_PARM_DESC(flowctrl, \"Sundance Alta flow control [0|1]\");\n\n \n\n \n#ifndef CONFIG_SUNDANCE_MMIO\n#define USE_IO_OPS 1\n#endif\n\nstatic const struct pci_device_id sundance_pci_tbl[] = {\n\t{ 0x1186, 0x1002, 0x1186, 0x1002, 0, 0, 0 },\n\t{ 0x1186, 0x1002, 0x1186, 0x1003, 0, 0, 1 },\n\t{ 0x1186, 0x1002, 0x1186, 0x1012, 0, 0, 2 },\n\t{ 0x1186, 0x1002, 0x1186, 0x1040, 0, 0, 3 },\n\t{ 0x1186, 0x1002, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 4 },\n\t{ 0x13F0, 0x0201, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 5 },\n\t{ 0x13F0, 0x0200, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 6 },\n\t{ }\n};\nMODULE_DEVICE_TABLE(pci, sundance_pci_tbl);\n\nenum {\n\tnetdev_io_size = 128\n};\n\nstruct pci_id_info {\n        const char *name;\n};\nstatic const struct pci_id_info pci_id_tbl[] = {\n\t{\"D-Link DFE-550TX FAST Ethernet Adapter\"},\n\t{\"D-Link DFE-550FX 100Mbps Fiber-optics Adapter\"},\n\t{\"D-Link DFE-580TX 4 port Server Adapter\"},\n\t{\"D-Link DFE-530TXS FAST Ethernet Adapter\"},\n\t{\"D-Link DL10050-based FAST Ethernet Adapter\"},\n\t{\"Sundance Technology Alta\"},\n\t{\"IC Plus Corporation IP100A FAST Ethernet Adapter\"},\n\t{ }\t \n};\n\n \n\n \nenum alta_offsets {\n\tDMACtrl = 0x00,\n\tTxListPtr = 0x04,\n\tTxDMABurstThresh = 0x08,\n\tTxDMAUrgentThresh = 0x09,\n\tTxDMAPollPeriod = 0x0a,\n\tRxDMAStatus = 0x0c,\n\tRxListPtr = 0x10,\n\tDebugCtrl0 = 0x1a,\n\tDebugCtrl1 = 0x1c,\n\tRxDMABurstThresh = 0x14,\n\tRxDMAUrgentThresh = 0x15,\n\tRxDMAPollPeriod = 0x16,\n\tLEDCtrl = 0x1a,\n\tASICCtrl = 0x30,\n\tEEData = 0x34,\n\tEECtrl = 0x36,\n\tFlashAddr = 0x40,\n\tFlashData = 0x44,\n\tWakeEvent = 0x45,\n\tTxStatus = 0x46,\n\tTxFrameId = 0x47,\n\tDownCounter = 0x18,\n\tIntrClear = 0x4a,\n\tIntrEnable = 0x4c,\n\tIntrStatus = 0x4e,\n\tMACCtrl0 = 0x50,\n\tMACCtrl1 = 0x52,\n\tStationAddr = 0x54,\n\tMaxFrameSize = 0x5A,\n\tRxMode = 0x5c,\n\tMIICtrl = 0x5e,\n\tMulticastFilter0 = 0x60,\n\tMulticastFilter1 = 0x64,\n\tRxOctetsLow = 0x68,\n\tRxOctetsHigh = 0x6a,\n\tTxOctetsLow = 0x6c,\n\tTxOctetsHigh = 0x6e,\n\tTxFramesOK = 0x70,\n\tRxFramesOK = 0x72,\n\tStatsCarrierError = 0x74,\n\tStatsLateColl = 0x75,\n\tStatsMultiColl = 0x76,\n\tStatsOneColl = 0x77,\n\tStatsTxDefer = 0x78,\n\tRxMissed = 0x79,\n\tStatsTxXSDefer = 0x7a,\n\tStatsTxAbort = 0x7b,\n\tStatsBcastTx = 0x7c,\n\tStatsBcastRx = 0x7d,\n\tStatsMcastTx = 0x7e,\n\tStatsMcastRx = 0x7f,\n\t \n\tRxStatus = 0x0c,\n};\n\n#define ASIC_HI_WORD(x)\t((x) + 2)\n\nenum ASICCtrl_HiWord_bit {\n\tGlobalReset = 0x0001,\n\tRxReset = 0x0002,\n\tTxReset = 0x0004,\n\tDMAReset = 0x0008,\n\tFIFOReset = 0x0010,\n\tNetworkReset = 0x0020,\n\tHostReset = 0x0040,\n\tResetBusy = 0x0400,\n};\n\n \nenum intr_status_bits {\n\tIntrSummary=0x0001, IntrPCIErr=0x0002, IntrMACCtrl=0x0008,\n\tIntrTxDone=0x0004, IntrRxDone=0x0010, IntrRxStart=0x0020,\n\tIntrDrvRqst=0x0040,\n\tStatsMax=0x0080, LinkChange=0x0100,\n\tIntrTxDMADone=0x0200, IntrRxDMADone=0x0400,\n};\n\n \nenum rx_mode_bits {\n\tAcceptAllIPMulti=0x20, AcceptMultiHash=0x10, AcceptAll=0x08,\n\tAcceptBroadcast=0x04, AcceptMulticast=0x02, AcceptMyPhys=0x01,\n};\n \nenum mac_ctrl0_bits {\n\tEnbFullDuplex=0x20, EnbRcvLargeFrame=0x40,\n\tEnbFlowCtrl=0x100, EnbPassRxCRC=0x200,\n};\nenum mac_ctrl1_bits {\n\tStatsEnable=0x0020,\tStatsDisable=0x0040, StatsEnabled=0x0080,\n\tTxEnable=0x0100, TxDisable=0x0200, TxEnabled=0x0400,\n\tRxEnable=0x0800, RxDisable=0x1000, RxEnabled=0x2000,\n};\n\n \nenum wake_event_bits {\n\tWakePktEnable = 0x01,\n\tMagicPktEnable = 0x02,\n\tLinkEventEnable = 0x04,\n\tWolEnable = 0x80,\n};\n\n \n \nstruct netdev_desc {\n\t__le32 next_desc;\n\t__le32 status;\n\tstruct desc_frag { __le32 addr, length; } frag;\n};\n\n \nenum desc_status_bits {\n\tDescOwn=0x8000,\n\tDescEndPacket=0x4000,\n\tDescEndRing=0x2000,\n\tLastFrag=0x80000000,\n\tDescIntrOnTx=0x8000,\n\tDescIntrOnDMADone=0x80000000,\n\tDisableAlign = 0x00000001,\n};\n\n#define PRIV_ALIGN\t15 \t \n \n#define MII_CNT\t\t4\nstruct netdev_private {\n\t \n\tstruct netdev_desc *rx_ring;\n\tstruct netdev_desc *tx_ring;\n\tstruct sk_buff* rx_skbuff[RX_RING_SIZE];\n\tstruct sk_buff* tx_skbuff[TX_RING_SIZE];\n        dma_addr_t tx_ring_dma;\n        dma_addr_t rx_ring_dma;\n\tstruct timer_list timer;\t\t \n\tstruct net_device *ndev;\t\t \n\t \n\tstruct {\n\t\tu64 tx_multiple_collisions;\n\t\tu64 tx_single_collisions;\n\t\tu64 tx_late_collisions;\n\t\tu64 tx_deferred;\n\t\tu64 tx_deferred_excessive;\n\t\tu64 tx_aborted;\n\t\tu64 tx_bcasts;\n\t\tu64 rx_bcasts;\n\t\tu64 tx_mcasts;\n\t\tu64 rx_mcasts;\n\t} xstats;\n\t \n\tspinlock_t lock;\n\tint msg_enable;\n\tint chip_id;\n\tunsigned int cur_rx, dirty_rx;\t\t \n\tunsigned int rx_buf_sz;\t\t\t \n\tstruct netdev_desc *last_tx;\t\t \n\tunsigned int cur_tx, dirty_tx;\n\t \n\tunsigned int flowctrl:1;\n\tunsigned int default_port:4;\t\t \n\tunsigned int an_enable:1;\n\tunsigned int speed;\n\tunsigned int wol_enabled:1;\t\t\t \n\tstruct tasklet_struct rx_tasklet;\n\tstruct tasklet_struct tx_tasklet;\n\tint budget;\n\tint cur_task;\n\t \n\tspinlock_t mcastlock;\t\t\t \n\tu16 mcast_filter[4];\n\t \n\tstruct mii_if_info mii_if;\n\tint mii_preamble_required;\n\tunsigned char phys[MII_CNT];\t\t \n\tstruct pci_dev *pci_dev;\n\tvoid __iomem *base;\n\tspinlock_t statlock;\n};\n\n \n#define EEPROM_SA_OFFSET\t0x10\n#define DEFAULT_INTR (IntrRxDMADone | IntrPCIErr | \\\n\t\t\tIntrDrvRqst | IntrTxDone | StatsMax | \\\n\t\t\tLinkChange)\n\nstatic int  change_mtu(struct net_device *dev, int new_mtu);\nstatic int  eeprom_read(void __iomem *ioaddr, int location);\nstatic int  mdio_read(struct net_device *dev, int phy_id, int location);\nstatic void mdio_write(struct net_device *dev, int phy_id, int location, int value);\nstatic int  mdio_wait_link(struct net_device *dev, int wait);\nstatic int  netdev_open(struct net_device *dev);\nstatic void check_duplex(struct net_device *dev);\nstatic void netdev_timer(struct timer_list *t);\nstatic void tx_timeout(struct net_device *dev, unsigned int txqueue);\nstatic void init_ring(struct net_device *dev);\nstatic netdev_tx_t start_tx(struct sk_buff *skb, struct net_device *dev);\nstatic int reset_tx (struct net_device *dev);\nstatic irqreturn_t intr_handler(int irq, void *dev_instance);\nstatic void rx_poll(struct tasklet_struct *t);\nstatic void tx_poll(struct tasklet_struct *t);\nstatic void refill_rx (struct net_device *dev);\nstatic void netdev_error(struct net_device *dev, int intr_status);\nstatic void netdev_error(struct net_device *dev, int intr_status);\nstatic void set_rx_mode(struct net_device *dev);\nstatic int __set_mac_addr(struct net_device *dev);\nstatic int sundance_set_mac_addr(struct net_device *dev, void *data);\nstatic struct net_device_stats *get_stats(struct net_device *dev);\nstatic int netdev_ioctl(struct net_device *dev, struct ifreq *rq, int cmd);\nstatic int  netdev_close(struct net_device *dev);\nstatic const struct ethtool_ops ethtool_ops;\n\nstatic void sundance_reset(struct net_device *dev, unsigned long reset_cmd)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base + ASICCtrl;\n\tint countdown;\n\n\t \n\tiowrite32 (reset_cmd | ioread32 (ioaddr), ioaddr);\n\t \n\tcountdown = 10 + 1;\n\twhile (ioread32 (ioaddr) & (ResetBusy << 16)) {\n\t\tif (--countdown == 0) {\n\t\t\tprintk(KERN_WARNING \"%s : reset not completed !!\\n\", dev->name);\n\t\t\tbreak;\n\t\t}\n\t\tudelay(100);\n\t}\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void sundance_poll_controller(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\n\tdisable_irq(np->pci_dev->irq);\n\tintr_handler(np->pci_dev->irq, dev);\n\tenable_irq(np->pci_dev->irq);\n}\n#endif\n\nstatic const struct net_device_ops netdev_ops = {\n\t.ndo_open\t\t= netdev_open,\n\t.ndo_stop\t\t= netdev_close,\n\t.ndo_start_xmit\t\t= start_tx,\n\t.ndo_get_stats \t\t= get_stats,\n\t.ndo_set_rx_mode\t= set_rx_mode,\n\t.ndo_eth_ioctl\t\t= netdev_ioctl,\n\t.ndo_tx_timeout\t\t= tx_timeout,\n\t.ndo_change_mtu\t\t= change_mtu,\n\t.ndo_set_mac_address \t= sundance_set_mac_addr,\n\t.ndo_validate_addr\t= eth_validate_addr,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller \t= sundance_poll_controller,\n#endif\n};\n\nstatic int sundance_probe1(struct pci_dev *pdev,\n\t\t\t   const struct pci_device_id *ent)\n{\n\tstruct net_device *dev;\n\tstruct netdev_private *np;\n\tstatic int card_idx;\n\tint chip_idx = ent->driver_data;\n\tint irq;\n\tint i;\n\tvoid __iomem *ioaddr;\n\tu16 mii_ctl;\n\tvoid *ring_space;\n\tdma_addr_t ring_dma;\n#ifdef USE_IO_OPS\n\tint bar = 0;\n#else\n\tint bar = 1;\n#endif\n\tint phy, phy_end, phy_idx = 0;\n\t__le16 addr[ETH_ALEN / 2];\n\n\tif (pci_enable_device(pdev))\n\t\treturn -EIO;\n\tpci_set_master(pdev);\n\n\tirq = pdev->irq;\n\n\tdev = alloc_etherdev(sizeof(*np));\n\tif (!dev)\n\t\treturn -ENOMEM;\n\tSET_NETDEV_DEV(dev, &pdev->dev);\n\n\tif (pci_request_regions(pdev, DRV_NAME))\n\t\tgoto err_out_netdev;\n\n\tioaddr = pci_iomap(pdev, bar, netdev_io_size);\n\tif (!ioaddr)\n\t\tgoto err_out_res;\n\n\tfor (i = 0; i < 3; i++)\n\t\taddr[i] =\n\t\t\tcpu_to_le16(eeprom_read(ioaddr, i + EEPROM_SA_OFFSET));\n\teth_hw_addr_set(dev, (u8 *)addr);\n\n\tnp = netdev_priv(dev);\n\tnp->ndev = dev;\n\tnp->base = ioaddr;\n\tnp->pci_dev = pdev;\n\tnp->chip_id = chip_idx;\n\tnp->msg_enable = (1 << debug) - 1;\n\tspin_lock_init(&np->lock);\n\tspin_lock_init(&np->statlock);\n\ttasklet_setup(&np->rx_tasklet, rx_poll);\n\ttasklet_setup(&np->tx_tasklet, tx_poll);\n\n\tring_space = dma_alloc_coherent(&pdev->dev, TX_TOTAL_SIZE,\n\t\t\t&ring_dma, GFP_KERNEL);\n\tif (!ring_space)\n\t\tgoto err_out_cleardev;\n\tnp->tx_ring = (struct netdev_desc *)ring_space;\n\tnp->tx_ring_dma = ring_dma;\n\n\tring_space = dma_alloc_coherent(&pdev->dev, RX_TOTAL_SIZE,\n\t\t\t&ring_dma, GFP_KERNEL);\n\tif (!ring_space)\n\t\tgoto err_out_unmap_tx;\n\tnp->rx_ring = (struct netdev_desc *)ring_space;\n\tnp->rx_ring_dma = ring_dma;\n\n\tnp->mii_if.dev = dev;\n\tnp->mii_if.mdio_read = mdio_read;\n\tnp->mii_if.mdio_write = mdio_write;\n\tnp->mii_if.phy_id_mask = 0x1f;\n\tnp->mii_if.reg_num_mask = 0x1f;\n\n\t \n\tdev->netdev_ops = &netdev_ops;\n\tdev->ethtool_ops = &ethtool_ops;\n\tdev->watchdog_timeo = TX_TIMEOUT;\n\n\t \n\tdev->min_mtu = ETH_MIN_MTU;\n\tdev->max_mtu = 8191;\n\n\tpci_set_drvdata(pdev, dev);\n\n\ti = register_netdev(dev);\n\tif (i)\n\t\tgoto err_out_unmap_rx;\n\n\tprintk(KERN_INFO \"%s: %s at %p, %pM, IRQ %d.\\n\",\n\t       dev->name, pci_id_tbl[chip_idx].name, ioaddr,\n\t       dev->dev_addr, irq);\n\n\tnp->phys[0] = 1;\t\t \n\tnp->mii_preamble_required++;\n\n\t \n\tif (sundance_pci_tbl[np->chip_id].device == 0x0200) {\n\t\tphy = 0;\n\t\tphy_end = 31;\n\t} else {\n\t\tphy = 1;\n\t\tphy_end = 32;\t \n\t}\n\tfor (; phy <= phy_end && phy_idx < MII_CNT; phy++) {\n\t\tint phyx = phy & 0x1f;\n\t\tint mii_status = mdio_read(dev, phyx, MII_BMSR);\n\t\tif (mii_status != 0xffff  &&  mii_status != 0x0000) {\n\t\t\tnp->phys[phy_idx++] = phyx;\n\t\t\tnp->mii_if.advertising = mdio_read(dev, phyx, MII_ADVERTISE);\n\t\t\tif ((mii_status & 0x0040) == 0)\n\t\t\t\tnp->mii_preamble_required++;\n\t\t\tprintk(KERN_INFO \"%s: MII PHY found at address %d, status \"\n\t\t\t\t   \"0x%4.4x advertising %4.4x.\\n\",\n\t\t\t\t   dev->name, phyx, mii_status, np->mii_if.advertising);\n\t\t}\n\t}\n\tnp->mii_preamble_required--;\n\n\tif (phy_idx == 0) {\n\t\tprintk(KERN_INFO \"%s: No MII transceiver found, aborting.  ASIC status %x\\n\",\n\t\t\t   dev->name, ioread32(ioaddr + ASICCtrl));\n\t\tgoto err_out_unregister;\n\t}\n\n\tnp->mii_if.phy_id = np->phys[0];\n\n\t \n\tnp->an_enable = 1;\n\tif (card_idx < MAX_UNITS) {\n\t\tif (media[card_idx] != NULL) {\n\t\t\tnp->an_enable = 0;\n\t\t\tif (strcmp (media[card_idx], \"100mbps_fd\") == 0 ||\n\t\t\t    strcmp (media[card_idx], \"4\") == 0) {\n\t\t\t\tnp->speed = 100;\n\t\t\t\tnp->mii_if.full_duplex = 1;\n\t\t\t} else if (strcmp (media[card_idx], \"100mbps_hd\") == 0 ||\n\t\t\t\t   strcmp (media[card_idx], \"3\") == 0) {\n\t\t\t\tnp->speed = 100;\n\t\t\t\tnp->mii_if.full_duplex = 0;\n\t\t\t} else if (strcmp (media[card_idx], \"10mbps_fd\") == 0 ||\n\t\t\t\t   strcmp (media[card_idx], \"2\") == 0) {\n\t\t\t\tnp->speed = 10;\n\t\t\t\tnp->mii_if.full_duplex = 1;\n\t\t\t} else if (strcmp (media[card_idx], \"10mbps_hd\") == 0 ||\n\t\t\t\t   strcmp (media[card_idx], \"1\") == 0) {\n\t\t\t\tnp->speed = 10;\n\t\t\t\tnp->mii_if.full_duplex = 0;\n\t\t\t} else {\n\t\t\t\tnp->an_enable = 1;\n\t\t\t}\n\t\t}\n\t\tif (flowctrl == 1)\n\t\t\tnp->flowctrl = 1;\n\t}\n\n\t \n\tif (ioread32 (ioaddr + ASICCtrl) & 0x80) {\n\t\t \n\t\tif (np->an_enable) {\n\t\t\tnp->speed = 100;\n\t\t\tnp->mii_if.full_duplex = 1;\n\t\t\tnp->an_enable = 0;\n\t\t}\n\t}\n\t \n\tmdio_write (dev, np->phys[0], MII_BMCR, BMCR_RESET);\n\tmdelay (300);\n\t \n\tif (np->flowctrl)\n\t\tmdio_write (dev, np->phys[0], MII_ADVERTISE, np->mii_if.advertising | 0x0400);\n\tmdio_write (dev, np->phys[0], MII_BMCR, BMCR_ANENABLE|BMCR_ANRESTART);\n\t \n\tif (!np->an_enable) {\n\t\tmii_ctl = 0;\n\t\tmii_ctl |= (np->speed == 100) ? BMCR_SPEED100 : 0;\n\t\tmii_ctl |= (np->mii_if.full_duplex) ? BMCR_FULLDPLX : 0;\n\t\tmdio_write (dev, np->phys[0], MII_BMCR, mii_ctl);\n\t\tprintk (KERN_INFO \"Override speed=%d, %s duplex\\n\",\n\t\t\tnp->speed, np->mii_if.full_duplex ? \"Full\" : \"Half\");\n\n\t}\n\n\t \n\t \n\tif (netif_msg_hw(np))\n\t\tprintk(\"ASIC Control is %x.\\n\", ioread32(ioaddr + ASICCtrl));\n\tsundance_reset(dev, 0x00ff << 16);\n\tif (netif_msg_hw(np))\n\t\tprintk(\"ASIC Control is now %x.\\n\", ioread32(ioaddr + ASICCtrl));\n\n\tcard_idx++;\n\treturn 0;\n\nerr_out_unregister:\n\tunregister_netdev(dev);\nerr_out_unmap_rx:\n\tdma_free_coherent(&pdev->dev, RX_TOTAL_SIZE,\n\t\tnp->rx_ring, np->rx_ring_dma);\nerr_out_unmap_tx:\n\tdma_free_coherent(&pdev->dev, TX_TOTAL_SIZE,\n\t\tnp->tx_ring, np->tx_ring_dma);\nerr_out_cleardev:\n\tpci_iounmap(pdev, ioaddr);\nerr_out_res:\n\tpci_release_regions(pdev);\nerr_out_netdev:\n\tfree_netdev (dev);\n\treturn -ENODEV;\n}\n\nstatic int change_mtu(struct net_device *dev, int new_mtu)\n{\n\tif (netif_running(dev))\n\t\treturn -EBUSY;\n\tdev->mtu = new_mtu;\n\treturn 0;\n}\n\n#define eeprom_delay(ee_addr)\tioread32(ee_addr)\n \nstatic int eeprom_read(void __iomem *ioaddr, int location)\n{\n\tint boguscnt = 10000;\t\t \n\tiowrite16(0x0200 | (location & 0xff), ioaddr + EECtrl);\n\tdo {\n\t\teeprom_delay(ioaddr + EECtrl);\n\t\tif (! (ioread16(ioaddr + EECtrl) & 0x8000)) {\n\t\t\treturn ioread16(ioaddr + EEData);\n\t\t}\n\t} while (--boguscnt > 0);\n\treturn 0;\n}\n\n \n#define mdio_delay() ioread8(mdio_addr)\n\nenum mii_reg_bits {\n\tMDIO_ShiftClk=0x0001, MDIO_Data=0x0002, MDIO_EnbOutput=0x0004,\n};\n#define MDIO_EnbIn  (0)\n#define MDIO_WRITE0 (MDIO_EnbOutput)\n#define MDIO_WRITE1 (MDIO_Data | MDIO_EnbOutput)\n\n \nstatic void mdio_sync(void __iomem *mdio_addr)\n{\n\tint bits = 32;\n\n\t \n\twhile (--bits >= 0) {\n\t\tiowrite8(MDIO_WRITE1, mdio_addr);\n\t\tmdio_delay();\n\t\tiowrite8(MDIO_WRITE1 | MDIO_ShiftClk, mdio_addr);\n\t\tmdio_delay();\n\t}\n}\n\nstatic int mdio_read(struct net_device *dev, int phy_id, int location)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *mdio_addr = np->base + MIICtrl;\n\tint mii_cmd = (0xf6 << 10) | (phy_id << 5) | location;\n\tint i, retval = 0;\n\n\tif (np->mii_preamble_required)\n\t\tmdio_sync(mdio_addr);\n\n\t \n\tfor (i = 15; i >= 0; i--) {\n\t\tint dataval = (mii_cmd & (1 << i)) ? MDIO_WRITE1 : MDIO_WRITE0;\n\n\t\tiowrite8(dataval, mdio_addr);\n\t\tmdio_delay();\n\t\tiowrite8(dataval | MDIO_ShiftClk, mdio_addr);\n\t\tmdio_delay();\n\t}\n\t \n\tfor (i = 19; i > 0; i--) {\n\t\tiowrite8(MDIO_EnbIn, mdio_addr);\n\t\tmdio_delay();\n\t\tretval = (retval << 1) | ((ioread8(mdio_addr) & MDIO_Data) ? 1 : 0);\n\t\tiowrite8(MDIO_EnbIn | MDIO_ShiftClk, mdio_addr);\n\t\tmdio_delay();\n\t}\n\treturn (retval>>1) & 0xffff;\n}\n\nstatic void mdio_write(struct net_device *dev, int phy_id, int location, int value)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *mdio_addr = np->base + MIICtrl;\n\tint mii_cmd = (0x5002 << 16) | (phy_id << 23) | (location<<18) | value;\n\tint i;\n\n\tif (np->mii_preamble_required)\n\t\tmdio_sync(mdio_addr);\n\n\t \n\tfor (i = 31; i >= 0; i--) {\n\t\tint dataval = (mii_cmd & (1 << i)) ? MDIO_WRITE1 : MDIO_WRITE0;\n\n\t\tiowrite8(dataval, mdio_addr);\n\t\tmdio_delay();\n\t\tiowrite8(dataval | MDIO_ShiftClk, mdio_addr);\n\t\tmdio_delay();\n\t}\n\t \n\tfor (i = 2; i > 0; i--) {\n\t\tiowrite8(MDIO_EnbIn, mdio_addr);\n\t\tmdio_delay();\n\t\tiowrite8(MDIO_EnbIn | MDIO_ShiftClk, mdio_addr);\n\t\tmdio_delay();\n\t}\n}\n\nstatic int mdio_wait_link(struct net_device *dev, int wait)\n{\n\tint bmsr;\n\tint phy_id;\n\tstruct netdev_private *np;\n\n\tnp = netdev_priv(dev);\n\tphy_id = np->phys[0];\n\n\tdo {\n\t\tbmsr = mdio_read(dev, phy_id, MII_BMSR);\n\t\tif (bmsr & 0x0004)\n\t\t\treturn 0;\n\t\tmdelay(1);\n\t} while (--wait > 0);\n\treturn -1;\n}\n\nstatic int netdev_open(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tconst int irq = np->pci_dev->irq;\n\tunsigned long flags;\n\tint i;\n\n\tsundance_reset(dev, 0x00ff << 16);\n\n\ti = request_irq(irq, intr_handler, IRQF_SHARED, dev->name, dev);\n\tif (i)\n\t\treturn i;\n\n\tif (netif_msg_ifup(np))\n\t\tprintk(KERN_DEBUG \"%s: netdev_open() irq %d\\n\", dev->name, irq);\n\n\tinit_ring(dev);\n\n\tiowrite32(np->rx_ring_dma, ioaddr + RxListPtr);\n\t \n\n\t \n\t__set_mac_addr(dev);\n#if IS_ENABLED(CONFIG_VLAN_8021Q)\n\tiowrite16(dev->mtu + 18, ioaddr + MaxFrameSize);\n#else\n\tiowrite16(dev->mtu + 14, ioaddr + MaxFrameSize);\n#endif\n\tif (dev->mtu > 2047)\n\t\tiowrite32(ioread32(ioaddr + ASICCtrl) | 0x0C, ioaddr + ASICCtrl);\n\n\t \n\n\tif (dev->if_port == 0)\n\t\tdev->if_port = np->default_port;\n\n\tspin_lock_init(&np->mcastlock);\n\n\tset_rx_mode(dev);\n\tiowrite16(0, ioaddr + IntrEnable);\n\tiowrite16(0, ioaddr + DownCounter);\n\t \n\tiowrite8(100, ioaddr + RxDMAPollPeriod);\n\tiowrite8(127, ioaddr + TxDMAPollPeriod);\n\t \n\tif (np->pci_dev->revision >= 0x14)\n\t\tiowrite8(0x01, ioaddr + DebugCtrl1);\n\tnetif_start_queue(dev);\n\n\tspin_lock_irqsave(&np->lock, flags);\n\treset_tx(dev);\n\tspin_unlock_irqrestore(&np->lock, flags);\n\n\tiowrite16 (StatsEnable | RxEnable | TxEnable, ioaddr + MACCtrl1);\n\n\t \n\tiowrite8(ioread8(ioaddr + WakeEvent) | 0x00, ioaddr + WakeEvent);\n\tnp->wol_enabled = 0;\n\n\tif (netif_msg_ifup(np))\n\t\tprintk(KERN_DEBUG \"%s: Done netdev_open(), status: Rx %x Tx %x \"\n\t\t\t   \"MAC Control %x, %4.4x %4.4x.\\n\",\n\t\t\t   dev->name, ioread32(ioaddr + RxStatus), ioread8(ioaddr + TxStatus),\n\t\t\t   ioread32(ioaddr + MACCtrl0),\n\t\t\t   ioread16(ioaddr + MACCtrl1), ioread16(ioaddr + MACCtrl0));\n\n\t \n\ttimer_setup(&np->timer, netdev_timer, 0);\n\tnp->timer.expires = jiffies + 3*HZ;\n\tadd_timer(&np->timer);\n\n\t \n\tiowrite16(DEFAULT_INTR, ioaddr + IntrEnable);\n\n\treturn 0;\n}\n\nstatic void check_duplex(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tint mii_lpa = mdio_read(dev, np->phys[0], MII_LPA);\n\tint negotiated = mii_lpa & np->mii_if.advertising;\n\tint duplex;\n\n\t \n\tif (!np->an_enable || mii_lpa == 0xffff) {\n\t\tif (np->mii_if.full_duplex)\n\t\t\tiowrite16 (ioread16 (ioaddr + MACCtrl0) | EnbFullDuplex,\n\t\t\t\tioaddr + MACCtrl0);\n\t\treturn;\n\t}\n\n\t \n\tduplex = (negotiated & 0x0100) || (negotiated & 0x01C0) == 0x0040;\n\tif (np->mii_if.full_duplex != duplex) {\n\t\tnp->mii_if.full_duplex = duplex;\n\t\tif (netif_msg_link(np))\n\t\t\tprintk(KERN_INFO \"%s: Setting %s-duplex based on MII #%d \"\n\t\t\t\t   \"negotiated capability %4.4x.\\n\", dev->name,\n\t\t\t\t   duplex ? \"full\" : \"half\", np->phys[0], negotiated);\n\t\tiowrite16(ioread16(ioaddr + MACCtrl0) | (duplex ? 0x20 : 0), ioaddr + MACCtrl0);\n\t}\n}\n\nstatic void netdev_timer(struct timer_list *t)\n{\n\tstruct netdev_private *np = from_timer(np, t, timer);\n\tstruct net_device *dev = np->mii_if.dev;\n\tvoid __iomem *ioaddr = np->base;\n\tint next_tick = 10*HZ;\n\n\tif (netif_msg_timer(np)) {\n\t\tprintk(KERN_DEBUG \"%s: Media selection timer tick, intr status %4.4x, \"\n\t\t\t   \"Tx %x Rx %x.\\n\",\n\t\t\t   dev->name, ioread16(ioaddr + IntrEnable),\n\t\t\t   ioread8(ioaddr + TxStatus), ioread32(ioaddr + RxStatus));\n\t}\n\tcheck_duplex(dev);\n\tnp->timer.expires = jiffies + next_tick;\n\tadd_timer(&np->timer);\n}\n\nstatic void tx_timeout(struct net_device *dev, unsigned int txqueue)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tunsigned long flag;\n\n\tnetif_stop_queue(dev);\n\ttasklet_disable_in_atomic(&np->tx_tasklet);\n\tiowrite16(0, ioaddr + IntrEnable);\n\tprintk(KERN_WARNING \"%s: Transmit timed out, TxStatus %2.2x \"\n\t\t   \"TxFrameId %2.2x,\"\n\t\t   \" resetting...\\n\", dev->name, ioread8(ioaddr + TxStatus),\n\t\t   ioread8(ioaddr + TxFrameId));\n\n\t{\n\t\tint i;\n\t\tfor (i=0; i<TX_RING_SIZE; i++) {\n\t\t\tprintk(KERN_DEBUG \"%02x %08llx %08x %08x(%02x) %08x %08x\\n\", i,\n\t\t\t\t(unsigned long long)(np->tx_ring_dma + i*sizeof(*np->tx_ring)),\n\t\t\t\tle32_to_cpu(np->tx_ring[i].next_desc),\n\t\t\t\tle32_to_cpu(np->tx_ring[i].status),\n\t\t\t\t(le32_to_cpu(np->tx_ring[i].status) >> 2) & 0xff,\n\t\t\t\tle32_to_cpu(np->tx_ring[i].frag.addr),\n\t\t\t\tle32_to_cpu(np->tx_ring[i].frag.length));\n\t\t}\n\t\tprintk(KERN_DEBUG \"TxListPtr=%08x netif_queue_stopped=%d\\n\",\n\t\t\tioread32(np->base + TxListPtr),\n\t\t\tnetif_queue_stopped(dev));\n\t\tprintk(KERN_DEBUG \"cur_tx=%d(%02x) dirty_tx=%d(%02x)\\n\",\n\t\t\tnp->cur_tx, np->cur_tx % TX_RING_SIZE,\n\t\t\tnp->dirty_tx, np->dirty_tx % TX_RING_SIZE);\n\t\tprintk(KERN_DEBUG \"cur_rx=%d dirty_rx=%d\\n\", np->cur_rx, np->dirty_rx);\n\t\tprintk(KERN_DEBUG \"cur_task=%d\\n\", np->cur_task);\n\t}\n\tspin_lock_irqsave(&np->lock, flag);\n\n\t \n\treset_tx(dev);\n\tspin_unlock_irqrestore(&np->lock, flag);\n\n\tdev->if_port = 0;\n\n\tnetif_trans_update(dev);  \n\tdev->stats.tx_errors++;\n\tif (np->cur_tx - np->dirty_tx < TX_QUEUE_LEN - 4) {\n\t\tnetif_wake_queue(dev);\n\t}\n\tiowrite16(DEFAULT_INTR, ioaddr + IntrEnable);\n\ttasklet_enable(&np->tx_tasklet);\n}\n\n\n \nstatic void init_ring(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tint i;\n\n\tnp->cur_rx = np->cur_tx = 0;\n\tnp->dirty_rx = np->dirty_tx = 0;\n\tnp->cur_task = 0;\n\n\tnp->rx_buf_sz = (dev->mtu <= 1520 ? PKT_BUF_SZ : dev->mtu + 16);\n\n\t \n\tfor (i = 0; i < RX_RING_SIZE; i++) {\n\t\tnp->rx_ring[i].next_desc = cpu_to_le32(np->rx_ring_dma +\n\t\t\t((i+1)%RX_RING_SIZE)*sizeof(*np->rx_ring));\n\t\tnp->rx_ring[i].status = 0;\n\t\tnp->rx_ring[i].frag.length = 0;\n\t\tnp->rx_skbuff[i] = NULL;\n\t}\n\n\t \n\tfor (i = 0; i < RX_RING_SIZE; i++) {\n\t\tstruct sk_buff *skb =\n\t\t\tnetdev_alloc_skb(dev, np->rx_buf_sz + 2);\n\t\tnp->rx_skbuff[i] = skb;\n\t\tif (skb == NULL)\n\t\t\tbreak;\n\t\tskb_reserve(skb, 2);\t \n\t\tnp->rx_ring[i].frag.addr = cpu_to_le32(\n\t\t\tdma_map_single(&np->pci_dev->dev, skb->data,\n\t\t\t\tnp->rx_buf_sz, DMA_FROM_DEVICE));\n\t\tif (dma_mapping_error(&np->pci_dev->dev,\n\t\t\t\t\tnp->rx_ring[i].frag.addr)) {\n\t\t\tdev_kfree_skb(skb);\n\t\t\tnp->rx_skbuff[i] = NULL;\n\t\t\tbreak;\n\t\t}\n\t\tnp->rx_ring[i].frag.length = cpu_to_le32(np->rx_buf_sz | LastFrag);\n\t}\n\tnp->dirty_rx = (unsigned int)(i - RX_RING_SIZE);\n\n\tfor (i = 0; i < TX_RING_SIZE; i++) {\n\t\tnp->tx_skbuff[i] = NULL;\n\t\tnp->tx_ring[i].status = 0;\n\t}\n}\n\nstatic void tx_poll(struct tasklet_struct *t)\n{\n\tstruct netdev_private *np = from_tasklet(np, t, tx_tasklet);\n\tunsigned head = np->cur_task % TX_RING_SIZE;\n\tstruct netdev_desc *txdesc =\n\t\t&np->tx_ring[(np->cur_tx - 1) % TX_RING_SIZE];\n\n\t \n\tfor (; np->cur_tx - np->cur_task > 0; np->cur_task++) {\n\t\tint entry = np->cur_task % TX_RING_SIZE;\n\t\ttxdesc = &np->tx_ring[entry];\n\t\tif (np->last_tx) {\n\t\t\tnp->last_tx->next_desc = cpu_to_le32(np->tx_ring_dma +\n\t\t\t\tentry*sizeof(struct netdev_desc));\n\t\t}\n\t\tnp->last_tx = txdesc;\n\t}\n\t \n\ttxdesc->status |= cpu_to_le32(DescIntrOnTx);\n\n\tif (ioread32 (np->base + TxListPtr) == 0)\n\t\tiowrite32 (np->tx_ring_dma + head * sizeof(struct netdev_desc),\n\t\t\tnp->base + TxListPtr);\n}\n\nstatic netdev_tx_t\nstart_tx (struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tstruct netdev_desc *txdesc;\n\tunsigned entry;\n\n\t \n\tentry = np->cur_tx % TX_RING_SIZE;\n\tnp->tx_skbuff[entry] = skb;\n\ttxdesc = &np->tx_ring[entry];\n\n\ttxdesc->next_desc = 0;\n\ttxdesc->status = cpu_to_le32 ((entry << 2) | DisableAlign);\n\ttxdesc->frag.addr = cpu_to_le32(dma_map_single(&np->pci_dev->dev,\n\t\t\t\tskb->data, skb->len, DMA_TO_DEVICE));\n\tif (dma_mapping_error(&np->pci_dev->dev,\n\t\t\t\ttxdesc->frag.addr))\n\t\t\tgoto drop_frame;\n\ttxdesc->frag.length = cpu_to_le32 (skb->len | LastFrag);\n\n\t \n\tnp->cur_tx++;\n\tmb();\n\t \n\ttasklet_schedule(&np->tx_tasklet);\n\n\t \n\tif (np->cur_tx - np->dirty_tx < TX_QUEUE_LEN - 1 &&\n\t    !netif_queue_stopped(dev)) {\n\t\t \n\t} else {\n\t\tnetif_stop_queue (dev);\n\t}\n\tif (netif_msg_tx_queued(np)) {\n\t\tprintk (KERN_DEBUG\n\t\t\t\"%s: Transmit frame #%d queued in slot %d.\\n\",\n\t\t\tdev->name, np->cur_tx, entry);\n\t}\n\treturn NETDEV_TX_OK;\n\ndrop_frame:\n\tdev_kfree_skb_any(skb);\n\tnp->tx_skbuff[entry] = NULL;\n\tdev->stats.tx_dropped++;\n\treturn NETDEV_TX_OK;\n}\n\n \nstatic int\nreset_tx (struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tstruct sk_buff *skb;\n\tint i;\n\n\t \n\tiowrite16 (TxDisable, ioaddr + MACCtrl1);\n\tsundance_reset(dev, (NetworkReset|FIFOReset|DMAReset|TxReset) << 16);\n\n\t \n\tfor (i = 0; i < TX_RING_SIZE; i++) {\n\t\tnp->tx_ring[i].next_desc = 0;\n\n\t\tskb = np->tx_skbuff[i];\n\t\tif (skb) {\n\t\t\tdma_unmap_single(&np->pci_dev->dev,\n\t\t\t\tle32_to_cpu(np->tx_ring[i].frag.addr),\n\t\t\t\tskb->len, DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\tnp->tx_skbuff[i] = NULL;\n\t\t\tdev->stats.tx_dropped++;\n\t\t}\n\t}\n\tnp->cur_tx = np->dirty_tx = 0;\n\tnp->cur_task = 0;\n\n\tnp->last_tx = NULL;\n\tiowrite8(127, ioaddr + TxDMAPollPeriod);\n\n\tiowrite16 (StatsEnable | RxEnable | TxEnable, ioaddr + MACCtrl1);\n\treturn 0;\n}\n\n \nstatic irqreturn_t intr_handler(int irq, void *dev_instance)\n{\n\tstruct net_device *dev = (struct net_device *)dev_instance;\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tint hw_frame_id;\n\tint tx_cnt;\n\tint tx_status;\n\tint handled = 0;\n\tint i;\n\n\tdo {\n\t\tint intr_status = ioread16(ioaddr + IntrStatus);\n\t\tiowrite16(intr_status, ioaddr + IntrStatus);\n\n\t\tif (netif_msg_intr(np))\n\t\t\tprintk(KERN_DEBUG \"%s: Interrupt, status %4.4x.\\n\",\n\t\t\t\t   dev->name, intr_status);\n\n\t\tif (!(intr_status & DEFAULT_INTR))\n\t\t\tbreak;\n\n\t\thandled = 1;\n\n\t\tif (intr_status & (IntrRxDMADone)) {\n\t\t\tiowrite16(DEFAULT_INTR & ~(IntrRxDone|IntrRxDMADone),\n\t\t\t\t\tioaddr + IntrEnable);\n\t\t\tif (np->budget < 0)\n\t\t\t\tnp->budget = RX_BUDGET;\n\t\t\ttasklet_schedule(&np->rx_tasklet);\n\t\t}\n\t\tif (intr_status & (IntrTxDone | IntrDrvRqst)) {\n\t\t\ttx_status = ioread16 (ioaddr + TxStatus);\n\t\t\tfor (tx_cnt=32; tx_status & 0x80; --tx_cnt) {\n\t\t\t\tif (netif_msg_tx_done(np))\n\t\t\t\t\tprintk\n\t\t\t\t\t    (\"%s: Transmit status is %2.2x.\\n\",\n\t\t\t\t     \tdev->name, tx_status);\n\t\t\t\tif (tx_status & 0x1e) {\n\t\t\t\t\tif (netif_msg_tx_err(np))\n\t\t\t\t\t\tprintk(\"%s: Transmit error status %4.4x.\\n\",\n\t\t\t\t\t\t\t   dev->name, tx_status);\n\t\t\t\t\tdev->stats.tx_errors++;\n\t\t\t\t\tif (tx_status & 0x10)\n\t\t\t\t\t\tdev->stats.tx_fifo_errors++;\n\t\t\t\t\tif (tx_status & 0x08)\n\t\t\t\t\t\tdev->stats.collisions++;\n\t\t\t\t\tif (tx_status & 0x04)\n\t\t\t\t\t\tdev->stats.tx_fifo_errors++;\n\t\t\t\t\tif (tx_status & 0x02)\n\t\t\t\t\t\tdev->stats.tx_window_errors++;\n\n\t\t\t\t\t \n\t\t\t\t\tif (tx_status & 0x10) {\t \n\t\t\t\t\t\t \n\t\t\t\t\t\tsundance_reset(dev, (NetworkReset|FIFOReset|TxReset) << 16);\n\t\t\t\t\t\t \n\t\t\t\t\t}\n\t\t\t\t\t \n\t\t\t\t\ti = 10;\n\t\t\t\t\tdo {\n\t\t\t\t\t\tiowrite16(ioread16(ioaddr + MACCtrl1) | TxEnable, ioaddr + MACCtrl1);\n\t\t\t\t\t\tif (ioread16(ioaddr + MACCtrl1) & TxEnabled)\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tmdelay(1);\n\t\t\t\t\t} while (--i);\n\t\t\t\t}\n\t\t\t\t \n\t\t\t\tiowrite16 (0, ioaddr + TxStatus);\n\t\t\t\tif (tx_cnt < 0) {\n\t\t\t\t\tiowrite32(5000, ioaddr + DownCounter);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\ttx_status = ioread16 (ioaddr + TxStatus);\n\t\t\t}\n\t\t\thw_frame_id = (tx_status >> 8) & 0xff;\n\t\t} else \t{\n\t\t\thw_frame_id = ioread8(ioaddr + TxFrameId);\n\t\t}\n\n\t\tif (np->pci_dev->revision >= 0x14) {\n\t\t\tspin_lock(&np->lock);\n\t\t\tfor (; np->cur_tx - np->dirty_tx > 0; np->dirty_tx++) {\n\t\t\t\tint entry = np->dirty_tx % TX_RING_SIZE;\n\t\t\t\tstruct sk_buff *skb;\n\t\t\t\tint sw_frame_id;\n\t\t\t\tsw_frame_id = (le32_to_cpu(\n\t\t\t\t\tnp->tx_ring[entry].status) >> 2) & 0xff;\n\t\t\t\tif (sw_frame_id == hw_frame_id &&\n\t\t\t\t\t!(le32_to_cpu(np->tx_ring[entry].status)\n\t\t\t\t\t& 0x00010000))\n\t\t\t\t\t\tbreak;\n\t\t\t\tif (sw_frame_id == (hw_frame_id + 1) %\n\t\t\t\t\tTX_RING_SIZE)\n\t\t\t\t\t\tbreak;\n\t\t\t\tskb = np->tx_skbuff[entry];\n\t\t\t\t \n\t\t\t\tdma_unmap_single(&np->pci_dev->dev,\n\t\t\t\t\tle32_to_cpu(np->tx_ring[entry].frag.addr),\n\t\t\t\t\tskb->len, DMA_TO_DEVICE);\n\t\t\t\tdev_consume_skb_irq(np->tx_skbuff[entry]);\n\t\t\t\tnp->tx_skbuff[entry] = NULL;\n\t\t\t\tnp->tx_ring[entry].frag.addr = 0;\n\t\t\t\tnp->tx_ring[entry].frag.length = 0;\n\t\t\t}\n\t\t\tspin_unlock(&np->lock);\n\t\t} else {\n\t\t\tspin_lock(&np->lock);\n\t\t\tfor (; np->cur_tx - np->dirty_tx > 0; np->dirty_tx++) {\n\t\t\t\tint entry = np->dirty_tx % TX_RING_SIZE;\n\t\t\t\tstruct sk_buff *skb;\n\t\t\t\tif (!(le32_to_cpu(np->tx_ring[entry].status)\n\t\t\t\t\t\t\t& 0x00010000))\n\t\t\t\t\tbreak;\n\t\t\t\tskb = np->tx_skbuff[entry];\n\t\t\t\t \n\t\t\t\tdma_unmap_single(&np->pci_dev->dev,\n\t\t\t\t\tle32_to_cpu(np->tx_ring[entry].frag.addr),\n\t\t\t\t\tskb->len, DMA_TO_DEVICE);\n\t\t\t\tdev_consume_skb_irq(np->tx_skbuff[entry]);\n\t\t\t\tnp->tx_skbuff[entry] = NULL;\n\t\t\t\tnp->tx_ring[entry].frag.addr = 0;\n\t\t\t\tnp->tx_ring[entry].frag.length = 0;\n\t\t\t}\n\t\t\tspin_unlock(&np->lock);\n\t\t}\n\n\t\tif (netif_queue_stopped(dev) &&\n\t\t\tnp->cur_tx - np->dirty_tx < TX_QUEUE_LEN - 4) {\n\t\t\t \n\t\t\tnetif_wake_queue (dev);\n\t\t}\n\t\t \n\t\tif (intr_status & (IntrPCIErr | LinkChange | StatsMax))\n\t\t\tnetdev_error(dev, intr_status);\n\t} while (0);\n\tif (netif_msg_intr(np))\n\t\tprintk(KERN_DEBUG \"%s: exiting interrupt, status=%#4.4x.\\n\",\n\t\t\t   dev->name, ioread16(ioaddr + IntrStatus));\n\treturn IRQ_RETVAL(handled);\n}\n\nstatic void rx_poll(struct tasklet_struct *t)\n{\n\tstruct netdev_private *np = from_tasklet(np, t, rx_tasklet);\n\tstruct net_device *dev = np->ndev;\n\tint entry = np->cur_rx % RX_RING_SIZE;\n\tint boguscnt = np->budget;\n\tvoid __iomem *ioaddr = np->base;\n\tint received = 0;\n\n\t \n\twhile (1) {\n\t\tstruct netdev_desc *desc = &(np->rx_ring[entry]);\n\t\tu32 frame_status = le32_to_cpu(desc->status);\n\t\tint pkt_len;\n\n\t\tif (--boguscnt < 0) {\n\t\t\tgoto not_done;\n\t\t}\n\t\tif (!(frame_status & DescOwn))\n\t\t\tbreak;\n\t\tpkt_len = frame_status & 0x1fff;\t \n\t\tif (netif_msg_rx_status(np))\n\t\t\tprintk(KERN_DEBUG \"  netdev_rx() status was %8.8x.\\n\",\n\t\t\t\t   frame_status);\n\t\tif (frame_status & 0x001f4000) {\n\t\t\t \n\t\t\tif (netif_msg_rx_err(np))\n\t\t\t\tprintk(KERN_DEBUG \"  netdev_rx() Rx error was %8.8x.\\n\",\n\t\t\t\t\t   frame_status);\n\t\t\tdev->stats.rx_errors++;\n\t\t\tif (frame_status & 0x00100000)\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\tif (frame_status & 0x00010000)\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\tif (frame_status & 0x00060000)\n\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\tif (frame_status & 0x00080000)\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tif (frame_status & 0x00100000) {\n\t\t\t\tprintk(KERN_WARNING \"%s: Oversized Ethernet frame,\"\n\t\t\t\t\t   \" status %8.8x.\\n\",\n\t\t\t\t\t   dev->name, frame_status);\n\t\t\t}\n\t\t} else {\n\t\t\tstruct sk_buff *skb;\n#ifndef final_version\n\t\t\tif (netif_msg_rx_status(np))\n\t\t\t\tprintk(KERN_DEBUG \"  netdev_rx() normal Rx pkt length %d\"\n\t\t\t\t\t   \", bogus_cnt %d.\\n\",\n\t\t\t\t\t   pkt_len, boguscnt);\n#endif\n\t\t\t \n\t\t\tif (pkt_len < rx_copybreak &&\n\t\t\t    (skb = netdev_alloc_skb(dev, pkt_len + 2)) != NULL) {\n\t\t\t\tskb_reserve(skb, 2);\t \n\t\t\t\tdma_sync_single_for_cpu(&np->pci_dev->dev,\n\t\t\t\t\t\tle32_to_cpu(desc->frag.addr),\n\t\t\t\t\t\tnp->rx_buf_sz, DMA_FROM_DEVICE);\n\t\t\t\tskb_copy_to_linear_data(skb, np->rx_skbuff[entry]->data, pkt_len);\n\t\t\t\tdma_sync_single_for_device(&np->pci_dev->dev,\n\t\t\t\t\t\tle32_to_cpu(desc->frag.addr),\n\t\t\t\t\t\tnp->rx_buf_sz, DMA_FROM_DEVICE);\n\t\t\t\tskb_put(skb, pkt_len);\n\t\t\t} else {\n\t\t\t\tdma_unmap_single(&np->pci_dev->dev,\n\t\t\t\t\tle32_to_cpu(desc->frag.addr),\n\t\t\t\t\tnp->rx_buf_sz, DMA_FROM_DEVICE);\n\t\t\t\tskb_put(skb = np->rx_skbuff[entry], pkt_len);\n\t\t\t\tnp->rx_skbuff[entry] = NULL;\n\t\t\t}\n\t\t\tskb->protocol = eth_type_trans(skb, dev);\n\t\t\t \n\t\t\tnetif_rx(skb);\n\t\t}\n\t\tentry = (entry + 1) % RX_RING_SIZE;\n\t\treceived++;\n\t}\n\tnp->cur_rx = entry;\n\trefill_rx (dev);\n\tnp->budget -= received;\n\tiowrite16(DEFAULT_INTR, ioaddr + IntrEnable);\n\treturn;\n\nnot_done:\n\tnp->cur_rx = entry;\n\trefill_rx (dev);\n\tif (!received)\n\t\treceived = 1;\n\tnp->budget -= received;\n\tif (np->budget <= 0)\n\t\tnp->budget = RX_BUDGET;\n\ttasklet_schedule(&np->rx_tasklet);\n}\n\nstatic void refill_rx (struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tint entry;\n\n\t \n\tfor (;(np->cur_rx - np->dirty_rx + RX_RING_SIZE) % RX_RING_SIZE > 0;\n\t\tnp->dirty_rx = (np->dirty_rx + 1) % RX_RING_SIZE) {\n\t\tstruct sk_buff *skb;\n\t\tentry = np->dirty_rx % RX_RING_SIZE;\n\t\tif (np->rx_skbuff[entry] == NULL) {\n\t\t\tskb = netdev_alloc_skb(dev, np->rx_buf_sz + 2);\n\t\t\tnp->rx_skbuff[entry] = skb;\n\t\t\tif (skb == NULL)\n\t\t\t\tbreak;\t\t \n\t\t\tskb_reserve(skb, 2);\t \n\t\t\tnp->rx_ring[entry].frag.addr = cpu_to_le32(\n\t\t\t\tdma_map_single(&np->pci_dev->dev, skb->data,\n\t\t\t\t\tnp->rx_buf_sz, DMA_FROM_DEVICE));\n\t\t\tif (dma_mapping_error(&np->pci_dev->dev,\n\t\t\t\t    np->rx_ring[entry].frag.addr)) {\n\t\t\t    dev_kfree_skb_irq(skb);\n\t\t\t    np->rx_skbuff[entry] = NULL;\n\t\t\t    break;\n\t\t\t}\n\t\t}\n\t\t \n\t\tnp->rx_ring[entry].frag.length =\n\t\t\tcpu_to_le32(np->rx_buf_sz | LastFrag);\n\t\tnp->rx_ring[entry].status = 0;\n\t}\n}\nstatic void netdev_error(struct net_device *dev, int intr_status)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tu16 mii_ctl, mii_advertise, mii_lpa;\n\tint speed;\n\n\tif (intr_status & LinkChange) {\n\t\tif (mdio_wait_link(dev, 10) == 0) {\n\t\t\tprintk(KERN_INFO \"%s: Link up\\n\", dev->name);\n\t\t\tif (np->an_enable) {\n\t\t\t\tmii_advertise = mdio_read(dev, np->phys[0],\n\t\t\t\t\t\t\t   MII_ADVERTISE);\n\t\t\t\tmii_lpa = mdio_read(dev, np->phys[0], MII_LPA);\n\t\t\t\tmii_advertise &= mii_lpa;\n\t\t\t\tprintk(KERN_INFO \"%s: Link changed: \",\n\t\t\t\t\tdev->name);\n\t\t\t\tif (mii_advertise & ADVERTISE_100FULL) {\n\t\t\t\t\tnp->speed = 100;\n\t\t\t\t\tprintk(\"100Mbps, full duplex\\n\");\n\t\t\t\t} else if (mii_advertise & ADVERTISE_100HALF) {\n\t\t\t\t\tnp->speed = 100;\n\t\t\t\t\tprintk(\"100Mbps, half duplex\\n\");\n\t\t\t\t} else if (mii_advertise & ADVERTISE_10FULL) {\n\t\t\t\t\tnp->speed = 10;\n\t\t\t\t\tprintk(\"10Mbps, full duplex\\n\");\n\t\t\t\t} else if (mii_advertise & ADVERTISE_10HALF) {\n\t\t\t\t\tnp->speed = 10;\n\t\t\t\t\tprintk(\"10Mbps, half duplex\\n\");\n\t\t\t\t} else\n\t\t\t\t\tprintk(\"\\n\");\n\n\t\t\t} else {\n\t\t\t\tmii_ctl = mdio_read(dev, np->phys[0], MII_BMCR);\n\t\t\t\tspeed = (mii_ctl & BMCR_SPEED100) ? 100 : 10;\n\t\t\t\tnp->speed = speed;\n\t\t\t\tprintk(KERN_INFO \"%s: Link changed: %dMbps ,\",\n\t\t\t\t\tdev->name, speed);\n\t\t\t\tprintk(\"%s duplex.\\n\",\n\t\t\t\t\t(mii_ctl & BMCR_FULLDPLX) ?\n\t\t\t\t\t\t\"full\" : \"half\");\n\t\t\t}\n\t\t\tcheck_duplex(dev);\n\t\t\tif (np->flowctrl && np->mii_if.full_duplex) {\n\t\t\t\tiowrite16(ioread16(ioaddr + MulticastFilter1+2) | 0x0200,\n\t\t\t\t\tioaddr + MulticastFilter1+2);\n\t\t\t\tiowrite16(ioread16(ioaddr + MACCtrl0) | EnbFlowCtrl,\n\t\t\t\t\tioaddr + MACCtrl0);\n\t\t\t}\n\t\t\tnetif_carrier_on(dev);\n\t\t} else {\n\t\t\tprintk(KERN_INFO \"%s: Link down\\n\", dev->name);\n\t\t\tnetif_carrier_off(dev);\n\t\t}\n\t}\n\tif (intr_status & StatsMax) {\n\t\tget_stats(dev);\n\t}\n\tif (intr_status & IntrPCIErr) {\n\t\tprintk(KERN_ERR \"%s: Something Wicked happened! %4.4x.\\n\",\n\t\t\t   dev->name, intr_status);\n\t\t \n\t}\n}\n\nstatic struct net_device_stats *get_stats(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tunsigned long flags;\n\tu8 late_coll, single_coll, mult_coll;\n\n\tspin_lock_irqsave(&np->statlock, flags);\n\t \n\tdev->stats.rx_missed_errors\t+= ioread8(ioaddr + RxMissed);\n\tdev->stats.tx_packets += ioread16(ioaddr + TxFramesOK);\n\tdev->stats.rx_packets += ioread16(ioaddr + RxFramesOK);\n\tdev->stats.tx_carrier_errors += ioread8(ioaddr + StatsCarrierError);\n\n\tmult_coll = ioread8(ioaddr + StatsMultiColl);\n\tnp->xstats.tx_multiple_collisions += mult_coll;\n\tsingle_coll = ioread8(ioaddr + StatsOneColl);\n\tnp->xstats.tx_single_collisions += single_coll;\n\tlate_coll = ioread8(ioaddr + StatsLateColl);\n\tnp->xstats.tx_late_collisions += late_coll;\n\tdev->stats.collisions += mult_coll\n\t\t+ single_coll\n\t\t+ late_coll;\n\n\tnp->xstats.tx_deferred += ioread8(ioaddr + StatsTxDefer);\n\tnp->xstats.tx_deferred_excessive += ioread8(ioaddr + StatsTxXSDefer);\n\tnp->xstats.tx_aborted += ioread8(ioaddr + StatsTxAbort);\n\tnp->xstats.tx_bcasts += ioread8(ioaddr + StatsBcastTx);\n\tnp->xstats.rx_bcasts += ioread8(ioaddr + StatsBcastRx);\n\tnp->xstats.tx_mcasts += ioread8(ioaddr + StatsMcastTx);\n\tnp->xstats.rx_mcasts += ioread8(ioaddr + StatsMcastRx);\n\n\tdev->stats.tx_bytes += ioread16(ioaddr + TxOctetsLow);\n\tdev->stats.tx_bytes += ioread16(ioaddr + TxOctetsHigh) << 16;\n\tdev->stats.rx_bytes += ioread16(ioaddr + RxOctetsLow);\n\tdev->stats.rx_bytes += ioread16(ioaddr + RxOctetsHigh) << 16;\n\n\tspin_unlock_irqrestore(&np->statlock, flags);\n\n\treturn &dev->stats;\n}\n\nstatic void set_rx_mode(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tu16 mc_filter[4];\t\t\t \n\tu32 rx_mode;\n\tint i;\n\n\tif (dev->flags & IFF_PROMISC) {\t\t\t \n\t\tmemset(mc_filter, 0xff, sizeof(mc_filter));\n\t\trx_mode = AcceptBroadcast | AcceptMulticast | AcceptAll | AcceptMyPhys;\n\t} else if ((netdev_mc_count(dev) > multicast_filter_limit) ||\n\t\t   (dev->flags & IFF_ALLMULTI)) {\n\t\t \n\t\tmemset(mc_filter, 0xff, sizeof(mc_filter));\n\t\trx_mode = AcceptBroadcast | AcceptMulticast | AcceptMyPhys;\n\t} else if (!netdev_mc_empty(dev)) {\n\t\tstruct netdev_hw_addr *ha;\n\t\tint bit;\n\t\tint index;\n\t\tint crc;\n\t\tmemset (mc_filter, 0, sizeof (mc_filter));\n\t\tnetdev_for_each_mc_addr(ha, dev) {\n\t\t\tcrc = ether_crc_le(ETH_ALEN, ha->addr);\n\t\t\tfor (index=0, bit=0; bit < 6; bit++, crc <<= 1)\n\t\t\t\tif (crc & 0x80000000) index |= 1 << bit;\n\t\t\tmc_filter[index/16] |= (1 << (index % 16));\n\t\t}\n\t\trx_mode = AcceptBroadcast | AcceptMultiHash | AcceptMyPhys;\n\t} else {\n\t\tiowrite8(AcceptBroadcast | AcceptMyPhys, ioaddr + RxMode);\n\t\treturn;\n\t}\n\tif (np->mii_if.full_duplex && np->flowctrl)\n\t\tmc_filter[3] |= 0x0200;\n\n\tfor (i = 0; i < 4; i++)\n\t\tiowrite16(mc_filter[i], ioaddr + MulticastFilter0 + i*2);\n\tiowrite8(rx_mode, ioaddr + RxMode);\n}\n\nstatic int __set_mac_addr(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tu16 addr16;\n\n\taddr16 = (dev->dev_addr[0] | (dev->dev_addr[1] << 8));\n\tiowrite16(addr16, np->base + StationAddr);\n\taddr16 = (dev->dev_addr[2] | (dev->dev_addr[3] << 8));\n\tiowrite16(addr16, np->base + StationAddr+2);\n\taddr16 = (dev->dev_addr[4] | (dev->dev_addr[5] << 8));\n\tiowrite16(addr16, np->base + StationAddr+4);\n\treturn 0;\n}\n\n \nstatic int sundance_set_mac_addr(struct net_device *dev, void *data)\n{\n\tconst struct sockaddr *addr = data;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\teth_hw_addr_set(dev, addr->sa_data);\n\t__set_mac_addr(dev);\n\n\treturn 0;\n}\n\nstatic const struct {\n\tconst char name[ETH_GSTRING_LEN];\n} sundance_stats[] = {\n\t{ \"tx_multiple_collisions\" },\n\t{ \"tx_single_collisions\" },\n\t{ \"tx_late_collisions\" },\n\t{ \"tx_deferred\" },\n\t{ \"tx_deferred_excessive\" },\n\t{ \"tx_aborted\" },\n\t{ \"tx_bcasts\" },\n\t{ \"rx_bcasts\" },\n\t{ \"tx_mcasts\" },\n\t{ \"rx_mcasts\" },\n};\n\nstatic int check_if_running(struct net_device *dev)\n{\n\tif (!netif_running(dev))\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic void get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tstrscpy(info->driver, DRV_NAME, sizeof(info->driver));\n\tstrscpy(info->bus_info, pci_name(np->pci_dev), sizeof(info->bus_info));\n}\n\nstatic int get_link_ksettings(struct net_device *dev,\n\t\t\t      struct ethtool_link_ksettings *cmd)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tspin_lock_irq(&np->lock);\n\tmii_ethtool_get_link_ksettings(&np->mii_if, cmd);\n\tspin_unlock_irq(&np->lock);\n\treturn 0;\n}\n\nstatic int set_link_ksettings(struct net_device *dev,\n\t\t\t      const struct ethtool_link_ksettings *cmd)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tint res;\n\tspin_lock_irq(&np->lock);\n\tres = mii_ethtool_set_link_ksettings(&np->mii_if, cmd);\n\tspin_unlock_irq(&np->lock);\n\treturn res;\n}\n\nstatic int nway_reset(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\treturn mii_nway_restart(&np->mii_if);\n}\n\nstatic u32 get_link(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\treturn mii_link_ok(&np->mii_if);\n}\n\nstatic u32 get_msglevel(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\treturn np->msg_enable;\n}\n\nstatic void set_msglevel(struct net_device *dev, u32 val)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tnp->msg_enable = val;\n}\n\nstatic void get_strings(struct net_device *dev, u32 stringset,\n\t\tu8 *data)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\tmemcpy(data, sundance_stats, sizeof(sundance_stats));\n}\n\nstatic int get_sset_count(struct net_device *dev, int sset)\n{\n\tswitch (sset) {\n\tcase ETH_SS_STATS:\n\t\treturn ARRAY_SIZE(sundance_stats);\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n}\n\nstatic void get_ethtool_stats(struct net_device *dev,\n\t\tstruct ethtool_stats *stats, u64 *data)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tint i = 0;\n\n\tget_stats(dev);\n\tdata[i++] = np->xstats.tx_multiple_collisions;\n\tdata[i++] = np->xstats.tx_single_collisions;\n\tdata[i++] = np->xstats.tx_late_collisions;\n\tdata[i++] = np->xstats.tx_deferred;\n\tdata[i++] = np->xstats.tx_deferred_excessive;\n\tdata[i++] = np->xstats.tx_aborted;\n\tdata[i++] = np->xstats.tx_bcasts;\n\tdata[i++] = np->xstats.rx_bcasts;\n\tdata[i++] = np->xstats.tx_mcasts;\n\tdata[i++] = np->xstats.rx_mcasts;\n}\n\n#ifdef CONFIG_PM\n\nstatic void sundance_get_wol(struct net_device *dev,\n\t\tstruct ethtool_wolinfo *wol)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tu8 wol_bits;\n\n\twol->wolopts = 0;\n\n\twol->supported = (WAKE_PHY | WAKE_MAGIC);\n\tif (!np->wol_enabled)\n\t\treturn;\n\n\twol_bits = ioread8(ioaddr + WakeEvent);\n\tif (wol_bits & MagicPktEnable)\n\t\twol->wolopts |= WAKE_MAGIC;\n\tif (wol_bits & LinkEventEnable)\n\t\twol->wolopts |= WAKE_PHY;\n}\n\nstatic int sundance_set_wol(struct net_device *dev,\n\tstruct ethtool_wolinfo *wol)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tu8 wol_bits;\n\n\tif (!device_can_wakeup(&np->pci_dev->dev))\n\t\treturn -EOPNOTSUPP;\n\n\tnp->wol_enabled = !!(wol->wolopts);\n\twol_bits = ioread8(ioaddr + WakeEvent);\n\twol_bits &= ~(WakePktEnable | MagicPktEnable |\n\t\t\tLinkEventEnable | WolEnable);\n\n\tif (np->wol_enabled) {\n\t\tif (wol->wolopts & WAKE_MAGIC)\n\t\t\twol_bits |= (MagicPktEnable | WolEnable);\n\t\tif (wol->wolopts & WAKE_PHY)\n\t\t\twol_bits |= (LinkEventEnable | WolEnable);\n\t}\n\tiowrite8(wol_bits, ioaddr + WakeEvent);\n\n\tdevice_set_wakeup_enable(&np->pci_dev->dev, np->wol_enabled);\n\n\treturn 0;\n}\n#else\n#define sundance_get_wol NULL\n#define sundance_set_wol NULL\n#endif  \n\nstatic const struct ethtool_ops ethtool_ops = {\n\t.begin = check_if_running,\n\t.get_drvinfo = get_drvinfo,\n\t.nway_reset = nway_reset,\n\t.get_link = get_link,\n\t.get_wol = sundance_get_wol,\n\t.set_wol = sundance_set_wol,\n\t.get_msglevel = get_msglevel,\n\t.set_msglevel = set_msglevel,\n\t.get_strings = get_strings,\n\t.get_sset_count = get_sset_count,\n\t.get_ethtool_stats = get_ethtool_stats,\n\t.get_link_ksettings = get_link_ksettings,\n\t.set_link_ksettings = set_link_ksettings,\n};\n\nstatic int netdev_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tint rc;\n\n\tif (!netif_running(dev))\n\t\treturn -EINVAL;\n\n\tspin_lock_irq(&np->lock);\n\trc = generic_mii_ioctl(&np->mii_if, if_mii(rq), cmd, NULL);\n\tspin_unlock_irq(&np->lock);\n\n\treturn rc;\n}\n\nstatic int netdev_close(struct net_device *dev)\n{\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\tstruct sk_buff *skb;\n\tint i;\n\n\t \n\ttasklet_kill(&np->rx_tasklet);\n\ttasklet_kill(&np->tx_tasklet);\n\tnp->cur_tx = 0;\n\tnp->dirty_tx = 0;\n\tnp->cur_task = 0;\n\tnp->last_tx = NULL;\n\n\tnetif_stop_queue(dev);\n\n\tif (netif_msg_ifdown(np)) {\n\t\tprintk(KERN_DEBUG \"%s: Shutting down ethercard, status was Tx %2.2x \"\n\t\t\t   \"Rx %4.4x Int %2.2x.\\n\",\n\t\t\t   dev->name, ioread8(ioaddr + TxStatus),\n\t\t\t   ioread32(ioaddr + RxStatus), ioread16(ioaddr + IntrStatus));\n\t\tprintk(KERN_DEBUG \"%s: Queue pointers were Tx %d / %d,  Rx %d / %d.\\n\",\n\t\t\t   dev->name, np->cur_tx, np->dirty_tx, np->cur_rx, np->dirty_rx);\n\t}\n\n\t \n\tiowrite16(0x0000, ioaddr + IntrEnable);\n\n\t \n\tiowrite32(0x500, ioaddr + DMACtrl);\n\n\t \n\tiowrite16(TxDisable | RxDisable | StatsDisable, ioaddr + MACCtrl1);\n\n\tfor (i = 2000; i > 0; i--) {\n\t\tif ((ioread32(ioaddr + DMACtrl) & 0xc000) == 0)\n\t\t\tbreak;\n\t\tmdelay(1);\n\t}\n\n\tiowrite16(GlobalReset | DMAReset | FIFOReset | NetworkReset,\n\t\t\tioaddr + ASIC_HI_WORD(ASICCtrl));\n\n\tfor (i = 2000; i > 0; i--) {\n\t\tif ((ioread16(ioaddr + ASIC_HI_WORD(ASICCtrl)) & ResetBusy) == 0)\n\t\t\tbreak;\n\t\tmdelay(1);\n\t}\n\n#ifdef __i386__\n\tif (netif_msg_hw(np)) {\n\t\tprintk(KERN_DEBUG \"  Tx ring at %8.8x:\\n\",\n\t\t\t   (int)(np->tx_ring_dma));\n\t\tfor (i = 0; i < TX_RING_SIZE; i++)\n\t\t\tprintk(KERN_DEBUG \" #%d desc. %4.4x %8.8x %8.8x.\\n\",\n\t\t\t\t   i, np->tx_ring[i].status, np->tx_ring[i].frag.addr,\n\t\t\t\t   np->tx_ring[i].frag.length);\n\t\tprintk(KERN_DEBUG \"  Rx ring %8.8x:\\n\",\n\t\t\t   (int)(np->rx_ring_dma));\n\t\tfor (i = 0; i <  4 ; i++) {\n\t\t\tprintk(KERN_DEBUG \" #%d desc. %4.4x %4.4x %8.8x\\n\",\n\t\t\t\t   i, np->rx_ring[i].status, np->rx_ring[i].frag.addr,\n\t\t\t\t   np->rx_ring[i].frag.length);\n\t\t}\n\t}\n#endif  \n\n\tfree_irq(np->pci_dev->irq, dev);\n\n\tdel_timer_sync(&np->timer);\n\n\t \n\tfor (i = 0; i < RX_RING_SIZE; i++) {\n\t\tnp->rx_ring[i].status = 0;\n\t\tskb = np->rx_skbuff[i];\n\t\tif (skb) {\n\t\t\tdma_unmap_single(&np->pci_dev->dev,\n\t\t\t\tle32_to_cpu(np->rx_ring[i].frag.addr),\n\t\t\t\tnp->rx_buf_sz, DMA_FROM_DEVICE);\n\t\t\tdev_kfree_skb(skb);\n\t\t\tnp->rx_skbuff[i] = NULL;\n\t\t}\n\t\tnp->rx_ring[i].frag.addr = cpu_to_le32(0xBADF00D0);  \n\t}\n\tfor (i = 0; i < TX_RING_SIZE; i++) {\n\t\tnp->tx_ring[i].next_desc = 0;\n\t\tskb = np->tx_skbuff[i];\n\t\tif (skb) {\n\t\t\tdma_unmap_single(&np->pci_dev->dev,\n\t\t\t\tle32_to_cpu(np->tx_ring[i].frag.addr),\n\t\t\t\tskb->len, DMA_TO_DEVICE);\n\t\t\tdev_kfree_skb(skb);\n\t\t\tnp->tx_skbuff[i] = NULL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic void sundance_remove1(struct pci_dev *pdev)\n{\n\tstruct net_device *dev = pci_get_drvdata(pdev);\n\n\tif (dev) {\n\t    struct netdev_private *np = netdev_priv(dev);\n\t    unregister_netdev(dev);\n\t    dma_free_coherent(&pdev->dev, RX_TOTAL_SIZE,\n\t\t    np->rx_ring, np->rx_ring_dma);\n\t    dma_free_coherent(&pdev->dev, TX_TOTAL_SIZE,\n\t\t    np->tx_ring, np->tx_ring_dma);\n\t    pci_iounmap(pdev, np->base);\n\t    pci_release_regions(pdev);\n\t    free_netdev(dev);\n\t}\n}\n\nstatic int __maybe_unused sundance_suspend(struct device *dev_d)\n{\n\tstruct net_device *dev = dev_get_drvdata(dev_d);\n\tstruct netdev_private *np = netdev_priv(dev);\n\tvoid __iomem *ioaddr = np->base;\n\n\tif (!netif_running(dev))\n\t\treturn 0;\n\n\tnetdev_close(dev);\n\tnetif_device_detach(dev);\n\n\tif (np->wol_enabled) {\n\t\tiowrite8(AcceptBroadcast | AcceptMyPhys, ioaddr + RxMode);\n\t\tiowrite16(RxEnable, ioaddr + MACCtrl1);\n\t}\n\n\tdevice_set_wakeup_enable(dev_d, np->wol_enabled);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused sundance_resume(struct device *dev_d)\n{\n\tstruct net_device *dev = dev_get_drvdata(dev_d);\n\tint err = 0;\n\n\tif (!netif_running(dev))\n\t\treturn 0;\n\n\terr = netdev_open(dev);\n\tif (err) {\n\t\tprintk(KERN_ERR \"%s: Can't resume interface!\\n\",\n\t\t\t\tdev->name);\n\t\tgoto out;\n\t}\n\n\tnetif_device_attach(dev);\n\nout:\n\treturn err;\n}\n\nstatic SIMPLE_DEV_PM_OPS(sundance_pm_ops, sundance_suspend, sundance_resume);\n\nstatic struct pci_driver sundance_driver = {\n\t.name\t\t= DRV_NAME,\n\t.id_table\t= sundance_pci_tbl,\n\t.probe\t\t= sundance_probe1,\n\t.remove\t\t= sundance_remove1,\n\t.driver.pm\t= &sundance_pm_ops,\n};\n\nmodule_pci_driver(sundance_driver);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}