{
  "module_name": "be_cmds.c",
  "hash_id": "d8c7ccf1de78525e83a4e572f89b9d39a84880a73d8fc06f1050c05e5c602382",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/emulex/benet/be_cmds.c",
  "human_readable_source": "\n \n\n#include <linux/module.h>\n#include \"be.h\"\n#include \"be_cmds.h\"\n\nconst char * const be_misconfig_evt_port_state[] = {\n\t\"Physical Link is functional\",\n\t\"Optics faulted/incorrectly installed/not installed - Reseat optics. If issue not resolved, replace.\",\n\t\"Optics of two types installed \u2013 Remove one optic or install matching pair of optics.\",\n\t\"Incompatible optics \u2013 Replace with compatible optics for card to function.\",\n\t\"Unqualified optics \u2013 Replace with Avago optics for Warranty and Technical Support.\",\n\t\"Uncertified optics \u2013 Replace with Avago-certified optics to enable link operation.\"\n};\n\nstatic char *be_port_misconfig_evt_severity[] = {\n\t\"KERN_WARN\",\n\t\"KERN_INFO\",\n\t\"KERN_ERR\",\n\t\"KERN_WARN\"\n};\n\nstatic char *phy_state_oper_desc[] = {\n\t\"Link is non-operational\",\n\t\"Link is operational\",\n\t\"\"\n};\n\nstatic struct be_cmd_priv_map cmd_priv_map[] = {\n\t{\n\t\tOPCODE_ETH_ACPI_WOL_MAGIC_CONFIG,\n\t\tCMD_SUBSYSTEM_ETH,\n\t\tBE_PRIV_LNKMGMT | BE_PRIV_VHADM |\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_COMMON_GET_FLOW_CONTROL,\n\t\tCMD_SUBSYSTEM_COMMON,\n\t\tBE_PRIV_LNKQUERY | BE_PRIV_VHADM |\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_COMMON_SET_FLOW_CONTROL,\n\t\tCMD_SUBSYSTEM_COMMON,\n\t\tBE_PRIV_LNKMGMT | BE_PRIV_VHADM |\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_ETH_GET_PPORT_STATS,\n\t\tCMD_SUBSYSTEM_ETH,\n\t\tBE_PRIV_LNKMGMT | BE_PRIV_VHADM |\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_COMMON_GET_PHY_DETAILS,\n\t\tCMD_SUBSYSTEM_COMMON,\n\t\tBE_PRIV_LNKMGMT | BE_PRIV_VHADM |\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_LOWLEVEL_HOST_DDR_DMA,\n\t\tCMD_SUBSYSTEM_LOWLEVEL,\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_LOWLEVEL_LOOPBACK_TEST,\n\t\tCMD_SUBSYSTEM_LOWLEVEL,\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_LOWLEVEL_SET_LOOPBACK_MODE,\n\t\tCMD_SUBSYSTEM_LOWLEVEL,\n\t\tBE_PRIV_DEVCFG | BE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_COMMON_SET_HSW_CONFIG,\n\t\tCMD_SUBSYSTEM_COMMON,\n\t\tBE_PRIV_DEVCFG | BE_PRIV_VHADM |\n\t\tBE_PRIV_DEVSEC\n\t},\n\t{\n\t\tOPCODE_COMMON_GET_EXT_FAT_CAPABILITIES,\n\t\tCMD_SUBSYSTEM_COMMON,\n\t\tBE_PRIV_DEVCFG\n\t}\n};\n\nstatic bool be_cmd_allowed(struct be_adapter *adapter, u8 opcode, u8 subsystem)\n{\n\tint i;\n\tint num_entries = ARRAY_SIZE(cmd_priv_map);\n\tu32 cmd_privileges = adapter->cmd_privileges;\n\n\tfor (i = 0; i < num_entries; i++)\n\t\tif (opcode == cmd_priv_map[i].opcode &&\n\t\t    subsystem == cmd_priv_map[i].subsystem)\n\t\t\tif (!(cmd_privileges & cmd_priv_map[i].priv_mask))\n\t\t\t\treturn false;\n\n\treturn true;\n}\n\nstatic inline void *embedded_payload(struct be_mcc_wrb *wrb)\n{\n\treturn wrb->payload.embedded_payload;\n}\n\nstatic int be_mcc_notify(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *mccq = &adapter->mcc_obj.q;\n\tu32 val = 0;\n\n\tif (be_check_error(adapter, BE_ERROR_ANY))\n\t\treturn -EIO;\n\n\tval |= mccq->id & DB_MCCQ_RING_ID_MASK;\n\tval |= 1 << DB_MCCQ_NUM_POSTED_SHIFT;\n\n\twmb();\n\tiowrite32(val, adapter->db + DB_MCCQ_OFFSET);\n\n\treturn 0;\n}\n\n \nstatic inline bool be_mcc_compl_is_new(struct be_mcc_compl *compl)\n{\n\tu32 flags;\n\n\tif (compl->flags != 0) {\n\t\tflags = le32_to_cpu(compl->flags);\n\t\tif (flags & CQE_FLAGS_VALID_MASK) {\n\t\t\tcompl->flags = flags;\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\n \nstatic inline void be_mcc_compl_use(struct be_mcc_compl *compl)\n{\n\tcompl->flags = 0;\n}\n\nstatic struct be_cmd_resp_hdr *be_decode_resp_hdr(u32 tag0, u32 tag1)\n{\n\tunsigned long addr;\n\n\taddr = tag1;\n\taddr = ((addr << 16) << 16) | tag0;\n\treturn (void *)addr;\n}\n\nstatic bool be_skip_err_log(u8 opcode, u16 base_status, u16 addl_status)\n{\n\tif (base_status == MCC_STATUS_NOT_SUPPORTED ||\n\t    base_status == MCC_STATUS_ILLEGAL_REQUEST ||\n\t    addl_status == MCC_ADDL_STATUS_TOO_MANY_INTERFACES ||\n\t    addl_status == MCC_ADDL_STATUS_INSUFFICIENT_VLANS ||\n\t    (opcode == OPCODE_COMMON_WRITE_FLASHROM &&\n\t    (base_status == MCC_STATUS_ILLEGAL_FIELD ||\n\t     addl_status == MCC_ADDL_STATUS_FLASH_IMAGE_CRC_MISMATCH)))\n\t\treturn true;\n\telse\n\t\treturn false;\n}\n\n \nstatic void be_async_cmd_process(struct be_adapter *adapter,\n\t\t\t\t struct be_mcc_compl *compl,\n\t\t\t\t struct be_cmd_resp_hdr *resp_hdr)\n{\n\tenum mcc_base_status base_status = base_status(compl->status);\n\tu8 opcode = 0, subsystem = 0;\n\n\tif (resp_hdr) {\n\t\topcode = resp_hdr->opcode;\n\t\tsubsystem = resp_hdr->subsystem;\n\t}\n\n\tif (opcode == OPCODE_LOWLEVEL_LOOPBACK_TEST &&\n\t    subsystem == CMD_SUBSYSTEM_LOWLEVEL) {\n\t\tcomplete(&adapter->et_cmd_compl);\n\t\treturn;\n\t}\n\n\tif (opcode == OPCODE_LOWLEVEL_SET_LOOPBACK_MODE &&\n\t    subsystem == CMD_SUBSYSTEM_LOWLEVEL) {\n\t\tcomplete(&adapter->et_cmd_compl);\n\t\treturn;\n\t}\n\n\tif ((opcode == OPCODE_COMMON_WRITE_FLASHROM ||\n\t     opcode == OPCODE_COMMON_WRITE_OBJECT) &&\n\t    subsystem == CMD_SUBSYSTEM_COMMON) {\n\t\tadapter->flash_status = compl->status;\n\t\tcomplete(&adapter->et_cmd_compl);\n\t\treturn;\n\t}\n\n\tif ((opcode == OPCODE_ETH_GET_STATISTICS ||\n\t     opcode == OPCODE_ETH_GET_PPORT_STATS) &&\n\t    subsystem == CMD_SUBSYSTEM_ETH &&\n\t    base_status == MCC_STATUS_SUCCESS) {\n\t\tbe_parse_stats(adapter);\n\t\tadapter->stats_cmd_sent = false;\n\t\treturn;\n\t}\n\n\tif (opcode == OPCODE_COMMON_GET_CNTL_ADDITIONAL_ATTRIBUTES &&\n\t    subsystem == CMD_SUBSYSTEM_COMMON) {\n\t\tif (base_status == MCC_STATUS_SUCCESS) {\n\t\t\tstruct be_cmd_resp_get_cntl_addnl_attribs *resp =\n\t\t\t\t\t\t\t(void *)resp_hdr;\n\t\t\tadapter->hwmon_info.be_on_die_temp =\n\t\t\t\t\t\tresp->on_die_temperature;\n\t\t} else {\n\t\t\tadapter->be_get_temp_freq = 0;\n\t\t\tadapter->hwmon_info.be_on_die_temp =\n\t\t\t\t\t\tBE_INVALID_DIE_TEMP;\n\t\t}\n\t\treturn;\n\t}\n}\n\nstatic int be_mcc_compl_process(struct be_adapter *adapter,\n\t\t\t\tstruct be_mcc_compl *compl)\n{\n\tenum mcc_base_status base_status;\n\tenum mcc_addl_status addl_status;\n\tstruct be_cmd_resp_hdr *resp_hdr;\n\tu8 opcode = 0, subsystem = 0;\n\n\t \n\tbe_dws_le_to_cpu(compl, 4);\n\n\tbase_status = base_status(compl->status);\n\taddl_status = addl_status(compl->status);\n\n\tresp_hdr = be_decode_resp_hdr(compl->tag0, compl->tag1);\n\tif (resp_hdr) {\n\t\topcode = resp_hdr->opcode;\n\t\tsubsystem = resp_hdr->subsystem;\n\t}\n\n\tbe_async_cmd_process(adapter, compl, resp_hdr);\n\n\tif (base_status != MCC_STATUS_SUCCESS &&\n\t    !be_skip_err_log(opcode, base_status, addl_status)) {\n\t\tif (base_status == MCC_STATUS_UNAUTHORIZED_REQUEST ||\n\t\t    addl_status == MCC_ADDL_STATUS_INSUFFICIENT_PRIVILEGES) {\n\t\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t\t \"VF is not privileged to issue opcode %d-%d\\n\",\n\t\t\t\t opcode, subsystem);\n\t\t} else {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"opcode %d-%d failed:status %d-%d\\n\",\n\t\t\t\topcode, subsystem, base_status, addl_status);\n\t\t}\n\t}\n\treturn compl->status;\n}\n\n \nstatic void be_async_link_state_process(struct be_adapter *adapter,\n\t\t\t\t\tstruct be_mcc_compl *compl)\n{\n\tstruct be_async_event_link_state *evt =\n\t\t\t(struct be_async_event_link_state *)compl;\n\n\t \n\tadapter->phy.link_speed = -1;\n\n\t \n\tif (!BEx_chip(adapter) &&\n\t    !(evt->port_link_status & LOGICAL_LINK_STATUS_MASK))\n\t\treturn;\n\n\t \n\tif (adapter->flags & BE_FLAGS_LINK_STATUS_INIT)\n\t\tbe_link_status_update(adapter,\n\t\t\t\t      evt->port_link_status & LINK_STATUS_MASK);\n}\n\nstatic void be_async_port_misconfig_event_process(struct be_adapter *adapter,\n\t\t\t\t\t\t  struct be_mcc_compl *compl)\n{\n\tstruct be_async_event_misconfig_port *evt =\n\t\t\t(struct be_async_event_misconfig_port *)compl;\n\tu32 sfp_misconfig_evt_word1 = le32_to_cpu(evt->event_data_word1);\n\tu32 sfp_misconfig_evt_word2 = le32_to_cpu(evt->event_data_word2);\n\tu8 phy_oper_state = PHY_STATE_OPER_MSG_NONE;\n\tstruct device *dev = &adapter->pdev->dev;\n\tu8 msg_severity = DEFAULT_MSG_SEVERITY;\n\tu8 phy_state_info;\n\tu8 new_phy_state;\n\n\tnew_phy_state =\n\t\t(sfp_misconfig_evt_word1 >> (adapter->hba_port_num * 8)) & 0xff;\n\n\tif (new_phy_state == adapter->phy_state)\n\t\treturn;\n\n\tadapter->phy_state = new_phy_state;\n\n\t \n\tif (!sfp_misconfig_evt_word2)\n\t\tgoto log_message;\n\n\tphy_state_info =\n\t\t(sfp_misconfig_evt_word2 >> (adapter->hba_port_num * 8)) & 0xff;\n\n\tif (phy_state_info & PHY_STATE_INFO_VALID) {\n\t\tmsg_severity = (phy_state_info & PHY_STATE_MSG_SEVERITY) >> 1;\n\n\t\tif (be_phy_unqualified(new_phy_state))\n\t\t\tphy_oper_state = (phy_state_info & PHY_STATE_OPER);\n\t}\n\nlog_message:\n\t \n\tif (be_phy_state_unknown(new_phy_state))\n\t\tdev_printk(be_port_misconfig_evt_severity[msg_severity], dev,\n\t\t\t   \"Port %c: Unrecognized Optics state: 0x%x. %s\",\n\t\t\t   adapter->port_name,\n\t\t\t   new_phy_state,\n\t\t\t   phy_state_oper_desc[phy_oper_state]);\n\telse\n\t\tdev_printk(be_port_misconfig_evt_severity[msg_severity], dev,\n\t\t\t   \"Port %c: %s %s\",\n\t\t\t   adapter->port_name,\n\t\t\t   be_misconfig_evt_port_state[new_phy_state],\n\t\t\t   phy_state_oper_desc[phy_oper_state]);\n\n\t \n\tif (be_phy_misconfigured(new_phy_state))\n\t\tadapter->flags |= BE_FLAGS_PHY_MISCONFIGURED;\n}\n\n \nstatic void be_async_grp5_cos_priority_process(struct be_adapter *adapter,\n\t\t\t\t\t       struct be_mcc_compl *compl)\n{\n\tstruct be_async_event_grp5_cos_priority *evt =\n\t\t\t(struct be_async_event_grp5_cos_priority *)compl;\n\n\tif (evt->valid) {\n\t\tadapter->vlan_prio_bmap = evt->available_priority_bmap;\n\t\tadapter->recommended_prio_bits =\n\t\t\tevt->reco_default_priority << VLAN_PRIO_SHIFT;\n\t}\n}\n\n \nstatic void be_async_grp5_qos_speed_process(struct be_adapter *adapter,\n\t\t\t\t\t    struct be_mcc_compl *compl)\n{\n\tstruct be_async_event_grp5_qos_link_speed *evt =\n\t\t\t(struct be_async_event_grp5_qos_link_speed *)compl;\n\n\tif (adapter->phy.link_speed >= 0 &&\n\t    evt->physical_port == adapter->port_num)\n\t\tadapter->phy.link_speed = le16_to_cpu(evt->qos_link_speed) * 10;\n}\n\n \nstatic void be_async_grp5_pvid_state_process(struct be_adapter *adapter,\n\t\t\t\t\t     struct be_mcc_compl *compl)\n{\n\tstruct be_async_event_grp5_pvid_state *evt =\n\t\t\t(struct be_async_event_grp5_pvid_state *)compl;\n\n\tif (evt->enabled) {\n\t\tadapter->pvid = le16_to_cpu(evt->tag) & VLAN_VID_MASK;\n\t\tdev_info(&adapter->pdev->dev, \"LPVID: %d\\n\", adapter->pvid);\n\t} else {\n\t\tadapter->pvid = 0;\n\t}\n}\n\n#define MGMT_ENABLE_MASK\t0x4\nstatic void be_async_grp5_fw_control_process(struct be_adapter *adapter,\n\t\t\t\t\t     struct be_mcc_compl *compl)\n{\n\tstruct be_async_fw_control *evt = (struct be_async_fw_control *)compl;\n\tu32 evt_dw1 = le32_to_cpu(evt->event_data_word1);\n\n\tif (evt_dw1 & MGMT_ENABLE_MASK) {\n\t\tadapter->flags |= BE_FLAGS_OS2BMC;\n\t\tadapter->bmc_filt_mask = le32_to_cpu(evt->event_data_word2);\n\t} else {\n\t\tadapter->flags &= ~BE_FLAGS_OS2BMC;\n\t}\n}\n\nstatic void be_async_grp5_evt_process(struct be_adapter *adapter,\n\t\t\t\t      struct be_mcc_compl *compl)\n{\n\tu8 event_type = (compl->flags >> ASYNC_EVENT_TYPE_SHIFT) &\n\t\t\t\tASYNC_EVENT_TYPE_MASK;\n\n\tswitch (event_type) {\n\tcase ASYNC_EVENT_COS_PRIORITY:\n\t\tbe_async_grp5_cos_priority_process(adapter, compl);\n\t\tbreak;\n\tcase ASYNC_EVENT_QOS_SPEED:\n\t\tbe_async_grp5_qos_speed_process(adapter, compl);\n\t\tbreak;\n\tcase ASYNC_EVENT_PVID_STATE:\n\t\tbe_async_grp5_pvid_state_process(adapter, compl);\n\t\tbreak;\n\t \n\tcase ASYNC_EVENT_FW_CONTROL:\n\t\tbe_async_grp5_fw_control_process(adapter, compl);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n}\n\nstatic void be_async_dbg_evt_process(struct be_adapter *adapter,\n\t\t\t\t     struct be_mcc_compl *cmp)\n{\n\tu8 event_type = 0;\n\tstruct be_async_event_qnq *evt = (struct be_async_event_qnq *)cmp;\n\n\tevent_type = (cmp->flags >> ASYNC_EVENT_TYPE_SHIFT) &\n\t\t\tASYNC_EVENT_TYPE_MASK;\n\n\tswitch (event_type) {\n\tcase ASYNC_DEBUG_EVENT_TYPE_QNQ:\n\t\tif (evt->valid)\n\t\t\tadapter->qnq_vid = le16_to_cpu(evt->vlan_tag);\n\t\tadapter->flags |= BE_FLAGS_QNQ_ASYNC_EVT_RCVD;\n\tbreak;\n\tdefault:\n\t\tdev_warn(&adapter->pdev->dev, \"Unknown debug event 0x%x!\\n\",\n\t\t\t event_type);\n\tbreak;\n\t}\n}\n\nstatic void be_async_sliport_evt_process(struct be_adapter *adapter,\n\t\t\t\t\t struct be_mcc_compl *cmp)\n{\n\tu8 event_type = (cmp->flags >> ASYNC_EVENT_TYPE_SHIFT) &\n\t\t\tASYNC_EVENT_TYPE_MASK;\n\n\tif (event_type == ASYNC_EVENT_PORT_MISCONFIG)\n\t\tbe_async_port_misconfig_event_process(adapter, cmp);\n}\n\nstatic inline bool is_link_state_evt(u32 flags)\n{\n\treturn ((flags >> ASYNC_EVENT_CODE_SHIFT) & ASYNC_EVENT_CODE_MASK) ==\n\t\t\tASYNC_EVENT_CODE_LINK_STATE;\n}\n\nstatic inline bool is_grp5_evt(u32 flags)\n{\n\treturn ((flags >> ASYNC_EVENT_CODE_SHIFT) & ASYNC_EVENT_CODE_MASK) ==\n\t\t\tASYNC_EVENT_CODE_GRP_5;\n}\n\nstatic inline bool is_dbg_evt(u32 flags)\n{\n\treturn ((flags >> ASYNC_EVENT_CODE_SHIFT) & ASYNC_EVENT_CODE_MASK) ==\n\t\t\tASYNC_EVENT_CODE_QNQ;\n}\n\nstatic inline bool is_sliport_evt(u32 flags)\n{\n\treturn ((flags >> ASYNC_EVENT_CODE_SHIFT) & ASYNC_EVENT_CODE_MASK) ==\n\t\tASYNC_EVENT_CODE_SLIPORT;\n}\n\nstatic void be_mcc_event_process(struct be_adapter *adapter,\n\t\t\t\t struct be_mcc_compl *compl)\n{\n\tif (is_link_state_evt(compl->flags))\n\t\tbe_async_link_state_process(adapter, compl);\n\telse if (is_grp5_evt(compl->flags))\n\t\tbe_async_grp5_evt_process(adapter, compl);\n\telse if (is_dbg_evt(compl->flags))\n\t\tbe_async_dbg_evt_process(adapter, compl);\n\telse if (is_sliport_evt(compl->flags))\n\t\tbe_async_sliport_evt_process(adapter, compl);\n}\n\nstatic struct be_mcc_compl *be_mcc_compl_get(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *mcc_cq = &adapter->mcc_obj.cq;\n\tstruct be_mcc_compl *compl = queue_tail_node(mcc_cq);\n\n\tif (be_mcc_compl_is_new(compl)) {\n\t\tqueue_tail_inc(mcc_cq);\n\t\treturn compl;\n\t}\n\treturn NULL;\n}\n\nvoid be_async_mcc_enable(struct be_adapter *adapter)\n{\n\tspin_lock_bh(&adapter->mcc_cq_lock);\n\n\tbe_cq_notify(adapter, adapter->mcc_obj.cq.id, true, 0);\n\tadapter->mcc_obj.rearm_cq = true;\n\n\tspin_unlock_bh(&adapter->mcc_cq_lock);\n}\n\nvoid be_async_mcc_disable(struct be_adapter *adapter)\n{\n\tspin_lock_bh(&adapter->mcc_cq_lock);\n\n\tadapter->mcc_obj.rearm_cq = false;\n\tbe_cq_notify(adapter, adapter->mcc_obj.cq.id, false, 0);\n\n\tspin_unlock_bh(&adapter->mcc_cq_lock);\n}\n\nint be_process_mcc(struct be_adapter *adapter)\n{\n\tstruct be_mcc_compl *compl;\n\tint num = 0, status = 0;\n\tstruct be_mcc_obj *mcc_obj = &adapter->mcc_obj;\n\n\tspin_lock(&adapter->mcc_cq_lock);\n\n\twhile ((compl = be_mcc_compl_get(adapter))) {\n\t\tif (compl->flags & CQE_FLAGS_ASYNC_MASK) {\n\t\t\tbe_mcc_event_process(adapter, compl);\n\t\t} else if (compl->flags & CQE_FLAGS_COMPLETED_MASK) {\n\t\t\tstatus = be_mcc_compl_process(adapter, compl);\n\t\t\tatomic_dec(&mcc_obj->q.used);\n\t\t}\n\t\tbe_mcc_compl_use(compl);\n\t\tnum++;\n\t}\n\n\tif (num)\n\t\tbe_cq_notify(adapter, mcc_obj->cq.id, mcc_obj->rearm_cq, num);\n\n\tspin_unlock(&adapter->mcc_cq_lock);\n\treturn status;\n}\n\n \nstatic int be_mcc_wait_compl(struct be_adapter *adapter)\n{\n#define mcc_timeout\t\t12000  \n\tint i, status = 0;\n\tstruct be_mcc_obj *mcc_obj = &adapter->mcc_obj;\n\n\tfor (i = 0; i < mcc_timeout; i++) {\n\t\tif (be_check_error(adapter, BE_ERROR_ANY))\n\t\t\treturn -EIO;\n\n\t\tlocal_bh_disable();\n\t\tstatus = be_process_mcc(adapter);\n\t\tlocal_bh_enable();\n\n\t\tif (atomic_read(&mcc_obj->q.used) == 0)\n\t\t\tbreak;\n\t\tusleep_range(500, 1000);\n\t}\n\tif (i == mcc_timeout) {\n\t\tdev_err(&adapter->pdev->dev, \"FW not responding\\n\");\n\t\tbe_set_error(adapter, BE_ERROR_FW);\n\t\treturn -EIO;\n\t}\n\treturn status;\n}\n\n \nstatic int be_mcc_notify_wait(struct be_adapter *adapter)\n{\n\tint status;\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_mcc_obj *mcc_obj = &adapter->mcc_obj;\n\tu32 index = mcc_obj->q.head;\n\tstruct be_cmd_resp_hdr *resp;\n\n\tindex_dec(&index, mcc_obj->q.len);\n\twrb = queue_index_node(&mcc_obj->q, index);\n\n\tresp = be_decode_resp_hdr(wrb->tag0, wrb->tag1);\n\n\tstatus = be_mcc_notify(adapter);\n\tif (status)\n\t\tgoto out;\n\n\tstatus = be_mcc_wait_compl(adapter);\n\tif (status == -EIO)\n\t\tgoto out;\n\n\tstatus = (resp->base_status |\n\t\t  ((resp->addl_status & CQE_ADDL_STATUS_MASK) <<\n\t\t   CQE_ADDL_STATUS_SHIFT));\nout:\n\treturn status;\n}\n\nstatic int be_mbox_db_ready_wait(struct be_adapter *adapter, void __iomem *db)\n{\n\tint msecs = 0;\n\tu32 ready;\n\n\tdo {\n\t\tif (be_check_error(adapter, BE_ERROR_ANY))\n\t\t\treturn -EIO;\n\n\t\tready = ioread32(db);\n\t\tif (ready == 0xffffffff)\n\t\t\treturn -1;\n\n\t\tready &= MPU_MAILBOX_DB_RDY_MASK;\n\t\tif (ready)\n\t\t\tbreak;\n\n\t\tif (msecs > 4000) {\n\t\t\tdev_err(&adapter->pdev->dev, \"FW not responding\\n\");\n\t\t\tbe_set_error(adapter, BE_ERROR_FW);\n\t\t\tbe_detect_error(adapter);\n\t\t\treturn -1;\n\t\t}\n\n\t\tmsleep(1);\n\t\tmsecs++;\n\t} while (true);\n\n\treturn 0;\n}\n\n \nstatic int be_mbox_notify_wait(struct be_adapter *adapter)\n{\n\tint status;\n\tu32 val = 0;\n\tvoid __iomem *db = adapter->db + MPU_MAILBOX_DB_OFFSET;\n\tstruct be_dma_mem *mbox_mem = &adapter->mbox_mem;\n\tstruct be_mcc_mailbox *mbox = mbox_mem->va;\n\tstruct be_mcc_compl *compl = &mbox->compl;\n\n\t \n\tstatus = be_mbox_db_ready_wait(adapter, db);\n\tif (status != 0)\n\t\treturn status;\n\n\tval |= MPU_MAILBOX_DB_HI_MASK;\n\t \n\tval |= (upper_32_bits(mbox_mem->dma) >> 2) << 2;\n\tiowrite32(val, db);\n\n\t \n\tstatus = be_mbox_db_ready_wait(adapter, db);\n\tif (status != 0)\n\t\treturn status;\n\n\tval = 0;\n\t \n\tval |= (u32)(mbox_mem->dma >> 4) << 2;\n\tiowrite32(val, db);\n\n\tstatus = be_mbox_db_ready_wait(adapter, db);\n\tif (status != 0)\n\t\treturn status;\n\n\t \n\tif (be_mcc_compl_is_new(compl)) {\n\t\tstatus = be_mcc_compl_process(adapter, &mbox->compl);\n\t\tbe_mcc_compl_use(compl);\n\t\tif (status)\n\t\t\treturn status;\n\t} else {\n\t\tdev_err(&adapter->pdev->dev, \"invalid mailbox completion\\n\");\n\t\treturn -1;\n\t}\n\treturn 0;\n}\n\nu16 be_POST_stage_get(struct be_adapter *adapter)\n{\n\tu32 sem;\n\n\tif (BEx_chip(adapter))\n\t\tsem  = ioread32(adapter->csr + SLIPORT_SEMAPHORE_OFFSET_BEx);\n\telse\n\t\tpci_read_config_dword(adapter->pdev,\n\t\t\t\t      SLIPORT_SEMAPHORE_OFFSET_SH, &sem);\n\n\treturn sem & POST_STAGE_MASK;\n}\n\nstatic int lancer_wait_ready(struct be_adapter *adapter)\n{\n#define SLIPORT_READY_TIMEOUT 30\n\tu32 sliport_status;\n\tint i;\n\n\tfor (i = 0; i < SLIPORT_READY_TIMEOUT; i++) {\n\t\tsliport_status = ioread32(adapter->db + SLIPORT_STATUS_OFFSET);\n\t\tif (sliport_status & SLIPORT_STATUS_RDY_MASK)\n\t\t\treturn 0;\n\n\t\tif (sliport_status & SLIPORT_STATUS_ERR_MASK &&\n\t\t    !(sliport_status & SLIPORT_STATUS_RN_MASK))\n\t\t\treturn -EIO;\n\n\t\tmsleep(1000);\n\t}\n\n\treturn sliport_status ? : -1;\n}\n\nint be_fw_wait_ready(struct be_adapter *adapter)\n{\n\tu16 stage;\n\tint status, timeout = 0;\n\tstruct device *dev = &adapter->pdev->dev;\n\n\tif (lancer_chip(adapter)) {\n\t\tstatus = lancer_wait_ready(adapter);\n\t\tif (status) {\n\t\t\tstage = status;\n\t\t\tgoto err;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tdo {\n\t\t \n\t\tif (BEx_chip(adapter) && be_virtfn(adapter))\n\t\t\treturn 0;\n\n\t\tstage = be_POST_stage_get(adapter);\n\t\tif (stage == POST_STAGE_ARMFW_RDY)\n\t\t\treturn 0;\n\n\t\tdev_info(dev, \"Waiting for POST, %ds elapsed\\n\", timeout);\n\t\tif (msleep_interruptible(2000)) {\n\t\t\tdev_err(dev, \"Waiting for POST aborted\\n\");\n\t\t\treturn -EINTR;\n\t\t}\n\t\ttimeout += 2;\n\t} while (timeout < 60);\n\nerr:\n\tdev_err(dev, \"POST timeout; stage=%#x\\n\", stage);\n\treturn -ETIMEDOUT;\n}\n\nstatic inline struct be_sge *nonembedded_sgl(struct be_mcc_wrb *wrb)\n{\n\treturn &wrb->payload.sgl[0];\n}\n\nstatic inline void fill_wrb_tags(struct be_mcc_wrb *wrb, unsigned long addr)\n{\n\twrb->tag0 = addr & 0xFFFFFFFF;\n\twrb->tag1 = upper_32_bits(addr);\n}\n\n \n \nstatic void be_wrb_cmd_hdr_prepare(struct be_cmd_req_hdr *req_hdr,\n\t\t\t\t   u8 subsystem, u8 opcode, int cmd_len,\n\t\t\t\t   struct be_mcc_wrb *wrb,\n\t\t\t\t   struct be_dma_mem *mem)\n{\n\tstruct be_sge *sge;\n\n\treq_hdr->opcode = opcode;\n\treq_hdr->subsystem = subsystem;\n\treq_hdr->request_length = cpu_to_le32(cmd_len - sizeof(*req_hdr));\n\treq_hdr->version = 0;\n\tfill_wrb_tags(wrb, (ulong)req_hdr);\n\twrb->payload_length = cmd_len;\n\tif (mem) {\n\t\twrb->embedded |= (1 & MCC_WRB_SGE_CNT_MASK) <<\n\t\t\tMCC_WRB_SGE_CNT_SHIFT;\n\t\tsge = nonembedded_sgl(wrb);\n\t\tsge->pa_hi = cpu_to_le32(upper_32_bits(mem->dma));\n\t\tsge->pa_lo = cpu_to_le32(mem->dma & 0xFFFFFFFF);\n\t\tsge->len = cpu_to_le32(mem->size);\n\t} else\n\t\twrb->embedded |= MCC_WRB_EMBEDDED_MASK;\n\tbe_dws_cpu_to_le(wrb, 8);\n}\n\nstatic void be_cmd_page_addrs_prepare(struct phys_addr *pages, u32 max_pages,\n\t\t\t\t      struct be_dma_mem *mem)\n{\n\tint i, buf_pages = min(PAGES_4K_SPANNED(mem->va, mem->size), max_pages);\n\tu64 dma = (u64)mem->dma;\n\n\tfor (i = 0; i < buf_pages; i++) {\n\t\tpages[i].lo = cpu_to_le32(dma & 0xFFFFFFFF);\n\t\tpages[i].hi = cpu_to_le32(upper_32_bits(dma));\n\t\tdma += PAGE_SIZE_4K;\n\t}\n}\n\nstatic inline struct be_mcc_wrb *wrb_from_mbox(struct be_adapter *adapter)\n{\n\tstruct be_dma_mem *mbox_mem = &adapter->mbox_mem;\n\tstruct be_mcc_wrb *wrb = &((struct be_mcc_mailbox *)(mbox_mem->va))->wrb;\n\n\tmemset(wrb, 0, sizeof(*wrb));\n\treturn wrb;\n}\n\nstatic struct be_mcc_wrb *wrb_from_mccq(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *mccq = &adapter->mcc_obj.q;\n\tstruct be_mcc_wrb *wrb;\n\n\tif (!mccq->created)\n\t\treturn NULL;\n\n\tif (atomic_read(&mccq->used) >= mccq->len)\n\t\treturn NULL;\n\n\twrb = queue_head_node(mccq);\n\tqueue_head_inc(mccq);\n\tatomic_inc(&mccq->used);\n\tmemset(wrb, 0, sizeof(*wrb));\n\treturn wrb;\n}\n\nstatic bool use_mcc(struct be_adapter *adapter)\n{\n\treturn adapter->mcc_obj.q.created;\n}\n\n \nstatic int be_cmd_lock(struct be_adapter *adapter)\n{\n\tif (use_mcc(adapter)) {\n\t\tmutex_lock(&adapter->mcc_lock);\n\t\treturn 0;\n\t} else {\n\t\treturn mutex_lock_interruptible(&adapter->mbox_lock);\n\t}\n}\n\n \nstatic void be_cmd_unlock(struct be_adapter *adapter)\n{\n\tif (use_mcc(adapter))\n\t\treturn mutex_unlock(&adapter->mcc_lock);\n\telse\n\t\treturn mutex_unlock(&adapter->mbox_lock);\n}\n\nstatic struct be_mcc_wrb *be_cmd_copy(struct be_adapter *adapter,\n\t\t\t\t      struct be_mcc_wrb *wrb)\n{\n\tstruct be_mcc_wrb *dest_wrb;\n\n\tif (use_mcc(adapter)) {\n\t\tdest_wrb = wrb_from_mccq(adapter);\n\t\tif (!dest_wrb)\n\t\t\treturn NULL;\n\t} else {\n\t\tdest_wrb = wrb_from_mbox(adapter);\n\t}\n\n\tmemcpy(dest_wrb, wrb, sizeof(*wrb));\n\tif (wrb->embedded & cpu_to_le32(MCC_WRB_EMBEDDED_MASK))\n\t\tfill_wrb_tags(dest_wrb, (ulong)embedded_payload(wrb));\n\n\treturn dest_wrb;\n}\n\n \nstatic int be_cmd_notify_wait(struct be_adapter *adapter,\n\t\t\t      struct be_mcc_wrb *wrb)\n{\n\tstruct be_mcc_wrb *dest_wrb;\n\tint status;\n\n\tstatus = be_cmd_lock(adapter);\n\tif (status)\n\t\treturn status;\n\n\tdest_wrb = be_cmd_copy(adapter, wrb);\n\tif (!dest_wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto unlock;\n\t}\n\n\tif (use_mcc(adapter))\n\t\tstatus = be_mcc_notify_wait(adapter);\n\telse\n\t\tstatus = be_mbox_notify_wait(adapter);\n\n\tif (!status)\n\t\tmemcpy(wrb, dest_wrb, sizeof(*wrb));\n\nunlock:\n\tbe_cmd_unlock(adapter);\n\treturn status;\n}\n\n \nint be_cmd_fw_init(struct be_adapter *adapter)\n{\n\tu8 *wrb;\n\tint status;\n\n\tif (lancer_chip(adapter))\n\t\treturn 0;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = (u8 *)wrb_from_mbox(adapter);\n\t*wrb++ = 0xFF;\n\t*wrb++ = 0x12;\n\t*wrb++ = 0x34;\n\t*wrb++ = 0xFF;\n\t*wrb++ = 0xFF;\n\t*wrb++ = 0x56;\n\t*wrb++ = 0x78;\n\t*wrb = 0xFF;\n\n\tstatus = be_mbox_notify_wait(adapter);\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\n \nint be_cmd_fw_clean(struct be_adapter *adapter)\n{\n\tu8 *wrb;\n\tint status;\n\n\tif (lancer_chip(adapter))\n\t\treturn 0;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = (u8 *)wrb_from_mbox(adapter);\n\t*wrb++ = 0xFF;\n\t*wrb++ = 0xAA;\n\t*wrb++ = 0xBB;\n\t*wrb++ = 0xFF;\n\t*wrb++ = 0xFF;\n\t*wrb++ = 0xCC;\n\t*wrb++ = 0xDD;\n\t*wrb = 0xFF;\n\n\tstatus = be_mbox_notify_wait(adapter);\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\nint be_cmd_eq_create(struct be_adapter *adapter, struct be_eq_obj *eqo)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_eq_create *req;\n\tstruct be_dma_mem *q_mem = &eqo->q.dma_mem;\n\tint status, ver = 0;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_EQ_CREATE, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\t \n\tif (!(BEx_chip(adapter) || lancer_chip(adapter)))\n\t\tver = 2;\n\n\treq->hdr.version = ver;\n\treq->num_pages =  cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));\n\n\tAMAP_SET_BITS(struct amap_eq_context, valid, req->context, 1);\n\t \n\tAMAP_SET_BITS(struct amap_eq_context, size, req->context, 0);\n\tAMAP_SET_BITS(struct amap_eq_context, count, req->context,\n\t\t      __ilog2_u32(eqo->q.len / 256));\n\tbe_dws_cpu_to_le(req->context, sizeof(req->context));\n\n\tbe_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_eq_create *resp = embedded_payload(wrb);\n\n\t\teqo->q.id = le16_to_cpu(resp->eq_id);\n\t\teqo->msix_idx =\n\t\t\t(ver == 2) ? le16_to_cpu(resp->msix_idx) : eqo->idx;\n\t\teqo->q.created = true;\n\t}\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\n \nint be_cmd_mac_addr_query(struct be_adapter *adapter, u8 *mac_addr,\n\t\t\t  bool permanent, u32 if_handle, u32 pmac_id)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_mac_query *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_MAC_QUERY, sizeof(*req), wrb,\n\t\t\t       NULL);\n\treq->type = MAC_ADDRESS_TYPE_NETWORK;\n\tif (permanent) {\n\t\treq->permanent = 1;\n\t} else {\n\t\treq->if_id = cpu_to_le16((u16)if_handle);\n\t\treq->pmac_id = cpu_to_le32(pmac_id);\n\t\treq->permanent = 0;\n\t}\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_mac_query *resp = embedded_payload(wrb);\n\n\t\tmemcpy(mac_addr, resp->mac.addr, ETH_ALEN);\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_pmac_add(struct be_adapter *adapter, const u8 *mac_addr,\n\t\t    u32 if_id, u32 *pmac_id, u32 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_pmac_add *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_PMAC_ADD, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->hdr.domain = domain;\n\treq->if_id = cpu_to_le32(if_id);\n\tmemcpy(req->mac_address, mac_addr, ETH_ALEN);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_pmac_add *resp = embedded_payload(wrb);\n\n\t\t*pmac_id = le32_to_cpu(resp->pmac_id);\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\n\tif (base_status(status) == MCC_STATUS_UNAUTHORIZED_REQUEST)\n\t\tstatus = -EPERM;\n\n\treturn status;\n}\n\n \nint be_cmd_pmac_del(struct be_adapter *adapter, u32 if_id, int pmac_id, u32 dom)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_pmac_del *req;\n\tint status;\n\n\tif (pmac_id == -1)\n\t\treturn 0;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_PMAC_DEL, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->hdr.domain = dom;\n\treq->if_id = cpu_to_le32(if_id);\n\treq->pmac_id = cpu_to_le32(pmac_id);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_cq_create(struct be_adapter *adapter, struct be_queue_info *cq,\n\t\t     struct be_queue_info *eq, bool no_delay, int coalesce_wm)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_cq_create *req;\n\tstruct be_dma_mem *q_mem = &cq->dma_mem;\n\tvoid *ctxt;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\tctxt = &req->context;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_CQ_CREATE, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->num_pages =  cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));\n\n\tif (BEx_chip(adapter)) {\n\t\tAMAP_SET_BITS(struct amap_cq_context_be, coalescwm, ctxt,\n\t\t\t      coalesce_wm);\n\t\tAMAP_SET_BITS(struct amap_cq_context_be, nodelay,\n\t\t\t      ctxt, no_delay);\n\t\tAMAP_SET_BITS(struct amap_cq_context_be, count, ctxt,\n\t\t\t      __ilog2_u32(cq->len / 256));\n\t\tAMAP_SET_BITS(struct amap_cq_context_be, valid, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_cq_context_be, eventable, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_cq_context_be, eqid, ctxt, eq->id);\n\t} else {\n\t\treq->hdr.version = 2;\n\t\treq->page_size = 1;  \n\n\t\t \n\t\tif (!lancer_chip(adapter))\n\t\t\tAMAP_SET_BITS(struct amap_cq_context_v2, coalescwm,\n\t\t\t\t      ctxt, coalesce_wm);\n\t\tAMAP_SET_BITS(struct amap_cq_context_v2, nodelay, ctxt,\n\t\t\t      no_delay);\n\t\tAMAP_SET_BITS(struct amap_cq_context_v2, count, ctxt,\n\t\t\t      __ilog2_u32(cq->len / 256));\n\t\tAMAP_SET_BITS(struct amap_cq_context_v2, valid, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_cq_context_v2, eventable, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_cq_context_v2, eqid, ctxt, eq->id);\n\t}\n\n\tbe_dws_cpu_to_le(ctxt, sizeof(req->context));\n\n\tbe_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_cq_create *resp = embedded_payload(wrb);\n\n\t\tcq->id = le16_to_cpu(resp->cq_id);\n\t\tcq->created = true;\n\t}\n\n\tmutex_unlock(&adapter->mbox_lock);\n\n\treturn status;\n}\n\nstatic u32 be_encoded_q_len(int q_len)\n{\n\tu32 len_encoded = fls(q_len);  \n\n\tif (len_encoded == 16)\n\t\tlen_encoded = 0;\n\treturn len_encoded;\n}\n\nstatic int be_cmd_mccq_ext_create(struct be_adapter *adapter,\n\t\t\t\t  struct be_queue_info *mccq,\n\t\t\t\t  struct be_queue_info *cq)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_mcc_ext_create *req;\n\tstruct be_dma_mem *q_mem = &mccq->dma_mem;\n\tvoid *ctxt;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\tctxt = &req->context;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_MCC_CREATE_EXT, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->num_pages = cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));\n\tif (BEx_chip(adapter)) {\n\t\tAMAP_SET_BITS(struct amap_mcc_context_be, valid, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_mcc_context_be, ring_size, ctxt,\n\t\t\t      be_encoded_q_len(mccq->len));\n\t\tAMAP_SET_BITS(struct amap_mcc_context_be, cq_id, ctxt, cq->id);\n\t} else {\n\t\treq->hdr.version = 1;\n\t\treq->cq_id = cpu_to_le16(cq->id);\n\n\t\tAMAP_SET_BITS(struct amap_mcc_context_v1, ring_size, ctxt,\n\t\t\t      be_encoded_q_len(mccq->len));\n\t\tAMAP_SET_BITS(struct amap_mcc_context_v1, valid, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_mcc_context_v1, async_cq_id,\n\t\t\t      ctxt, cq->id);\n\t\tAMAP_SET_BITS(struct amap_mcc_context_v1, async_cq_valid,\n\t\t\t      ctxt, 1);\n\t}\n\n\t \n\treq->async_event_bitmap[0] =\n\t\t\tcpu_to_le32(BIT(ASYNC_EVENT_CODE_LINK_STATE) |\n\t\t\t\t    BIT(ASYNC_EVENT_CODE_GRP_5) |\n\t\t\t\t    BIT(ASYNC_EVENT_CODE_QNQ) |\n\t\t\t\t    BIT(ASYNC_EVENT_CODE_SLIPORT));\n\n\tbe_dws_cpu_to_le(ctxt, sizeof(req->context));\n\n\tbe_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_mcc_create *resp = embedded_payload(wrb);\n\n\t\tmccq->id = le16_to_cpu(resp->id);\n\t\tmccq->created = true;\n\t}\n\tmutex_unlock(&adapter->mbox_lock);\n\n\treturn status;\n}\n\nstatic int be_cmd_mccq_org_create(struct be_adapter *adapter,\n\t\t\t\t  struct be_queue_info *mccq,\n\t\t\t\t  struct be_queue_info *cq)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_mcc_create *req;\n\tstruct be_dma_mem *q_mem = &mccq->dma_mem;\n\tvoid *ctxt;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\tctxt = &req->context;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_MCC_CREATE, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->num_pages = cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));\n\n\tAMAP_SET_BITS(struct amap_mcc_context_be, valid, ctxt, 1);\n\tAMAP_SET_BITS(struct amap_mcc_context_be, ring_size, ctxt,\n\t\t      be_encoded_q_len(mccq->len));\n\tAMAP_SET_BITS(struct amap_mcc_context_be, cq_id, ctxt, cq->id);\n\n\tbe_dws_cpu_to_le(ctxt, sizeof(req->context));\n\n\tbe_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_mcc_create *resp = embedded_payload(wrb);\n\n\t\tmccq->id = le16_to_cpu(resp->id);\n\t\tmccq->created = true;\n\t}\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\nint be_cmd_mccq_create(struct be_adapter *adapter,\n\t\t       struct be_queue_info *mccq, struct be_queue_info *cq)\n{\n\tint status;\n\n\tstatus = be_cmd_mccq_ext_create(adapter, mccq, cq);\n\tif (status && BEx_chip(adapter)) {\n\t\tdev_warn(&adapter->pdev->dev, \"Upgrade to F/W ver 2.102.235.0 \"\n\t\t\t\"or newer to avoid conflicting priorities between NIC \"\n\t\t\t\"and FCoE traffic\");\n\t\tstatus = be_cmd_mccq_org_create(adapter, mccq, cq);\n\t}\n\treturn status;\n}\n\nint be_cmd_txq_create(struct be_adapter *adapter, struct be_tx_obj *txo)\n{\n\tstruct be_mcc_wrb wrb = {0};\n\tstruct be_cmd_req_eth_tx_create *req;\n\tstruct be_queue_info *txq = &txo->q;\n\tstruct be_queue_info *cq = &txo->cq;\n\tstruct be_dma_mem *q_mem = &txq->dma_mem;\n\tint status, ver = 0;\n\n\treq = embedded_payload(&wrb);\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_TX_CREATE, sizeof(*req), &wrb, NULL);\n\n\tif (lancer_chip(adapter)) {\n\t\treq->hdr.version = 1;\n\t} else if (BEx_chip(adapter)) {\n\t\tif (adapter->function_caps & BE_FUNCTION_CAPS_SUPER_NIC)\n\t\t\treq->hdr.version = 2;\n\t} else {  \n\t\treq->hdr.version = 2;\n\t}\n\n\tif (req->hdr.version > 0)\n\t\treq->if_id = cpu_to_le16(adapter->if_handle);\n\treq->num_pages = PAGES_4K_SPANNED(q_mem->va, q_mem->size);\n\treq->ulp_num = BE_ULP1_NUM;\n\treq->type = BE_ETH_TX_RING_TYPE_STANDARD;\n\treq->cq_id = cpu_to_le16(cq->id);\n\treq->queue_size = be_encoded_q_len(txq->len);\n\tbe_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);\n\tver = req->hdr.version;\n\n\tstatus = be_cmd_notify_wait(adapter, &wrb);\n\tif (!status) {\n\t\tstruct be_cmd_resp_eth_tx_create *resp = embedded_payload(&wrb);\n\n\t\ttxq->id = le16_to_cpu(resp->cid);\n\t\tif (ver == 2)\n\t\t\ttxo->db_offset = le32_to_cpu(resp->db_offset);\n\t\telse\n\t\t\ttxo->db_offset = DB_TXULP1_OFFSET;\n\t\ttxq->created = true;\n\t}\n\n\treturn status;\n}\n\n \nint be_cmd_rxq_create(struct be_adapter *adapter,\n\t\t      struct be_queue_info *rxq, u16 cq_id, u16 frag_size,\n\t\t      u32 if_id, u32 rss, u8 *rss_id)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_eth_rx_create *req;\n\tstruct be_dma_mem *q_mem = &rxq->dma_mem;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_RX_CREATE, sizeof(*req), wrb, NULL);\n\n\treq->cq_id = cpu_to_le16(cq_id);\n\treq->frag_size = fls(frag_size) - 1;\n\treq->num_pages = 2;\n\tbe_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);\n\treq->interface_id = cpu_to_le32(if_id);\n\treq->max_frame_size = cpu_to_le16(BE_MAX_JUMBO_FRAME_SIZE);\n\treq->rss_queue = cpu_to_le32(rss);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_eth_rx_create *resp = embedded_payload(wrb);\n\n\t\trxq->id = le16_to_cpu(resp->id);\n\t\trxq->created = true;\n\t\t*rss_id = resp->rss_id;\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_q_destroy(struct be_adapter *adapter, struct be_queue_info *q,\n\t\t     int queue_type)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_q_destroy *req;\n\tu8 subsys = 0, opcode = 0;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\n\tswitch (queue_type) {\n\tcase QTYPE_EQ:\n\t\tsubsys = CMD_SUBSYSTEM_COMMON;\n\t\topcode = OPCODE_COMMON_EQ_DESTROY;\n\t\tbreak;\n\tcase QTYPE_CQ:\n\t\tsubsys = CMD_SUBSYSTEM_COMMON;\n\t\topcode = OPCODE_COMMON_CQ_DESTROY;\n\t\tbreak;\n\tcase QTYPE_TXQ:\n\t\tsubsys = CMD_SUBSYSTEM_ETH;\n\t\topcode = OPCODE_ETH_TX_DESTROY;\n\t\tbreak;\n\tcase QTYPE_RXQ:\n\t\tsubsys = CMD_SUBSYSTEM_ETH;\n\t\topcode = OPCODE_ETH_RX_DESTROY;\n\t\tbreak;\n\tcase QTYPE_MCCQ:\n\t\tsubsys = CMD_SUBSYSTEM_COMMON;\n\t\topcode = OPCODE_COMMON_MCC_DESTROY;\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, subsys, opcode, sizeof(*req), wrb,\n\t\t\t       NULL);\n\treq->id = cpu_to_le16(q->id);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tq->created = false;\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\n \nint be_cmd_rxq_destroy(struct be_adapter *adapter, struct be_queue_info *q)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_q_destroy *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_RX_DESTROY, sizeof(*req), wrb, NULL);\n\treq->id = cpu_to_le16(q->id);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tq->created = false;\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_if_create(struct be_adapter *adapter, u32 cap_flags, u32 en_flags,\n\t\t     u32 *if_handle, u32 domain)\n{\n\tstruct be_mcc_wrb wrb = {0};\n\tstruct be_cmd_req_if_create *req;\n\tint status;\n\n\treq = embedded_payload(&wrb);\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_INTERFACE_CREATE,\n\t\t\t       sizeof(*req), &wrb, NULL);\n\treq->hdr.domain = domain;\n\treq->capability_flags = cpu_to_le32(cap_flags);\n\treq->enable_flags = cpu_to_le32(en_flags);\n\treq->pmac_invalid = true;\n\n\tstatus = be_cmd_notify_wait(adapter, &wrb);\n\tif (!status) {\n\t\tstruct be_cmd_resp_if_create *resp = embedded_payload(&wrb);\n\n\t\t*if_handle = le32_to_cpu(resp->interface_id);\n\n\t\t \n\t\tif (BE3_chip(adapter) && be_virtfn(adapter))\n\t\t\tadapter->pmac_id[0] = le32_to_cpu(resp->pmac_id);\n\t}\n\treturn status;\n}\n\n \nint be_cmd_if_destroy(struct be_adapter *adapter, int interface_id, u32 domain)\n{\n\tstruct be_mcc_wrb wrb = {0};\n\tstruct be_cmd_req_if_destroy *req;\n\tint status;\n\n\tif (interface_id == -1)\n\t\treturn 0;\n\n\treq = embedded_payload(&wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_INTERFACE_DESTROY,\n\t\t\t       sizeof(*req), &wrb, NULL);\n\treq->hdr.domain = domain;\n\treq->interface_id = cpu_to_le32(interface_id);\n\n\tstatus = be_cmd_notify_wait(adapter, &wrb);\n\treturn status;\n}\n\n \nint be_cmd_get_stats(struct be_adapter *adapter, struct be_dma_mem *nonemb_cmd)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_hdr *hdr;\n\tint status = 0;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\thdr = nonemb_cmd->va;\n\n\tbe_wrb_cmd_hdr_prepare(hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_GET_STATISTICS, nonemb_cmd->size, wrb,\n\t\t\t       nonemb_cmd);\n\n\t \n\tif (BE2_chip(adapter))\n\t\thdr->version = 0;\n\tif (BE3_chip(adapter) || lancer_chip(adapter))\n\t\thdr->version = 1;\n\telse\n\t\thdr->version = 2;\n\n\tstatus = be_mcc_notify(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tadapter->stats_cmd_sent = true;\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint lancer_cmd_get_pport_stats(struct be_adapter *adapter,\n\t\t\t       struct be_dma_mem *nonemb_cmd)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct lancer_cmd_req_pport_stats *req;\n\tint status = 0;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_ETH_GET_PPORT_STATS,\n\t\t\t    CMD_SUBSYSTEM_ETH))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = nonemb_cmd->va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_GET_PPORT_STATS, nonemb_cmd->size,\n\t\t\t       wrb, nonemb_cmd);\n\n\treq->cmd_params.params.pport_num = cpu_to_le16(adapter->hba_port_num);\n\treq->cmd_params.params.reset_stats = 0;\n\n\tstatus = be_mcc_notify(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tadapter->stats_cmd_sent = true;\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic int be_mac_to_link_speed(int mac_speed)\n{\n\tswitch (mac_speed) {\n\tcase PHY_LINK_SPEED_ZERO:\n\t\treturn 0;\n\tcase PHY_LINK_SPEED_10MBPS:\n\t\treturn 10;\n\tcase PHY_LINK_SPEED_100MBPS:\n\t\treturn 100;\n\tcase PHY_LINK_SPEED_1GBPS:\n\t\treturn 1000;\n\tcase PHY_LINK_SPEED_10GBPS:\n\t\treturn 10000;\n\tcase PHY_LINK_SPEED_20GBPS:\n\t\treturn 20000;\n\tcase PHY_LINK_SPEED_25GBPS:\n\t\treturn 25000;\n\tcase PHY_LINK_SPEED_40GBPS:\n\t\treturn 40000;\n\t}\n\treturn 0;\n}\n\n \nint be_cmd_link_status_query(struct be_adapter *adapter, u16 *link_speed,\n\t\t\t     u8 *link_status, u32 dom)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_link_status *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\tif (link_status)\n\t\t*link_status = LINK_DOWN;\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_LINK_STATUS_QUERY,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\t \n\tif (!BE2_chip(adapter))\n\t\treq->hdr.version = 1;\n\n\treq->hdr.domain = dom;\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_link_status *resp = embedded_payload(wrb);\n\n\t\tif (link_speed) {\n\t\t\t*link_speed = resp->link_speed ?\n\t\t\t\t      le16_to_cpu(resp->link_speed) * 10 :\n\t\t\t\t      be_mac_to_link_speed(resp->mac_speed);\n\n\t\t\tif (!resp->logical_link_status)\n\t\t\t\t*link_speed = 0;\n\t\t}\n\t\tif (link_status)\n\t\t\t*link_status = resp->logical_link_status;\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_die_temperature(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_cntl_addnl_attribs *req;\n\tint status = 0;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_CNTL_ADDITIONAL_ATTRIBUTES,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\tstatus = be_mcc_notify(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_fat_dump_len(struct be_adapter *adapter, u32 *dump_size)\n{\n\tstruct be_mcc_wrb wrb = {0};\n\tstruct be_cmd_req_get_fat *req;\n\tint status;\n\n\treq = embedded_payload(&wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_MANAGE_FAT, sizeof(*req),\n\t\t\t       &wrb, NULL);\n\treq->fat_operation = cpu_to_le32(QUERY_FAT);\n\tstatus = be_cmd_notify_wait(adapter, &wrb);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_fat *resp = embedded_payload(&wrb);\n\n\t\tif (dump_size && resp->log_size)\n\t\t\t*dump_size = le32_to_cpu(resp->log_size) -\n\t\t\t\t\tsizeof(u32);\n\t}\n\treturn status;\n}\n\nint be_cmd_get_fat_dump(struct be_adapter *adapter, u32 buf_len, void *buf)\n{\n\tstruct be_dma_mem get_fat_cmd;\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_fat *req;\n\tu32 offset = 0, total_size, buf_size,\n\t\t\t\tlog_offset = sizeof(u32), payload_len;\n\tint status;\n\n\tif (buf_len == 0)\n\t\treturn 0;\n\n\ttotal_size = buf_len;\n\n\tget_fat_cmd.size = sizeof(struct be_cmd_req_get_fat) + 60 * 1024;\n\tget_fat_cmd.va = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t    get_fat_cmd.size,\n\t\t\t\t\t    &get_fat_cmd.dma, GFP_ATOMIC);\n\tif (!get_fat_cmd.va)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twhile (total_size) {\n\t\tbuf_size = min(total_size, (u32)60 * 1024);\n\t\ttotal_size -= buf_size;\n\n\t\twrb = wrb_from_mccq(adapter);\n\t\tif (!wrb) {\n\t\t\tstatus = -EBUSY;\n\t\t\tgoto err;\n\t\t}\n\t\treq = get_fat_cmd.va;\n\n\t\tpayload_len = sizeof(struct be_cmd_req_get_fat) + buf_size;\n\t\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t\t       OPCODE_COMMON_MANAGE_FAT, payload_len,\n\t\t\t\t       wrb, &get_fat_cmd);\n\n\t\treq->fat_operation = cpu_to_le32(RETRIEVE_FAT);\n\t\treq->read_log_offset = cpu_to_le32(log_offset);\n\t\treq->read_log_length = cpu_to_le32(buf_size);\n\t\treq->data_buffer_size = cpu_to_le32(buf_size);\n\n\t\tstatus = be_mcc_notify_wait(adapter);\n\t\tif (!status) {\n\t\t\tstruct be_cmd_resp_get_fat *resp = get_fat_cmd.va;\n\n\t\t\tmemcpy(buf + offset,\n\t\t\t       resp->data_buffer,\n\t\t\t       le32_to_cpu(resp->read_log_length));\n\t\t} else {\n\t\t\tdev_err(&adapter->pdev->dev, \"FAT Table Retrieve error\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\toffset += buf_size;\n\t\tlog_offset += buf_size;\n\t}\nerr:\n\tdma_free_coherent(&adapter->pdev->dev, get_fat_cmd.size,\n\t\t\t  get_fat_cmd.va, get_fat_cmd.dma);\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_fw_ver(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_fw_version *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_FW_VERSION, sizeof(*req), wrb,\n\t\t\t       NULL);\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_fw_version *resp = embedded_payload(wrb);\n\n\t\tstrscpy(adapter->fw_ver, resp->firmware_version_string,\n\t\t\tsizeof(adapter->fw_ver));\n\t\tstrscpy(adapter->fw_on_flash, resp->fw_on_flash_version_string,\n\t\t\tsizeof(adapter->fw_on_flash));\n\t}\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nstatic int __be_cmd_modify_eqd(struct be_adapter *adapter,\n\t\t\t       struct be_set_eqd *set_eqd, int num)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_modify_eq_delay *req;\n\tint status = 0, i;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_MODIFY_EQ_DELAY, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->num_eq = cpu_to_le32(num);\n\tfor (i = 0; i < num; i++) {\n\t\treq->set_eqd[i].eq_id = cpu_to_le32(set_eqd[i].eq_id);\n\t\treq->set_eqd[i].phase = 0;\n\t\treq->set_eqd[i].delay_multiplier =\n\t\t\t\tcpu_to_le32(set_eqd[i].delay_multiplier);\n\t}\n\n\tstatus = be_mcc_notify(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_modify_eqd(struct be_adapter *adapter, struct be_set_eqd *set_eqd,\n\t\t      int num)\n{\n\tint num_eqs, i = 0;\n\n\twhile (num) {\n\t\tnum_eqs = min(num, 8);\n\t\t__be_cmd_modify_eqd(adapter, &set_eqd[i], num_eqs);\n\t\ti += num_eqs;\n\t\tnum -= num_eqs;\n\t}\n\n\treturn 0;\n}\n\n \nint be_cmd_vlan_config(struct be_adapter *adapter, u32 if_id, u16 *vtag_array,\n\t\t       u32 num, u32 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_vlan_config *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_VLAN_CONFIG, sizeof(*req),\n\t\t\t       wrb, NULL);\n\treq->hdr.domain = domain;\n\n\treq->interface_id = if_id;\n\treq->untagged = BE_IF_FLAGS_UNTAGGED & be_if_cap_flags(adapter) ? 1 : 0;\n\treq->num_vlan = num;\n\tmemcpy(req->normal_vlan, vtag_array,\n\t       req->num_vlan * sizeof(vtag_array[0]));\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic int __be_cmd_rx_filter(struct be_adapter *adapter, u32 flags, u32 value)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_dma_mem *mem = &adapter->rx_filter;\n\tstruct be_cmd_req_rx_filter *req = mem->va;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\tmemset(req, 0, sizeof(*req));\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_NTWK_RX_FILTER, sizeof(*req),\n\t\t\t       wrb, mem);\n\n\treq->if_id = cpu_to_le32(adapter->if_handle);\n\treq->if_flags_mask = cpu_to_le32(flags);\n\treq->if_flags = (value == ON) ? req->if_flags_mask : 0;\n\n\tif (flags & BE_IF_FLAGS_MULTICAST) {\n\t\tint i;\n\n\t\t \n\t\treq->if_flags_mask |=\n\t\t\tcpu_to_le32(BE_IF_FLAGS_MCAST_PROMISCUOUS &\n\t\t\t\t    be_if_cap_flags(adapter));\n\t\treq->mcast_num = cpu_to_le32(adapter->mc_count);\n\t\tfor (i = 0; i < adapter->mc_count; i++)\n\t\t\tether_addr_copy(req->mcast_mac[i].byte,\n\t\t\t\t\tadapter->mc_list[i].mac);\n\t}\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_rx_filter(struct be_adapter *adapter, u32 flags, u32 value)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\n\tif ((flags & be_if_cap_flags(adapter)) != flags) {\n\t\tdev_warn(dev, \"Cannot set rx filter flags 0x%x\\n\", flags);\n\t\tdev_warn(dev, \"Interface is capable of 0x%x flags only\\n\",\n\t\t\t be_if_cap_flags(adapter));\n\t}\n\tflags &= be_if_cap_flags(adapter);\n\tif (!flags)\n\t\treturn -ENOTSUPP;\n\n\treturn __be_cmd_rx_filter(adapter, flags, value);\n}\n\n \nint be_cmd_set_flow_control(struct be_adapter *adapter, u32 tx_fc, u32 rx_fc)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_flow_control *req;\n\tint status;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_COMMON_SET_FLOW_CONTROL,\n\t\t\t    CMD_SUBSYSTEM_COMMON))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_FLOW_CONTROL, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->hdr.version = 1;\n\treq->tx_flow_control = cpu_to_le16((u16)tx_fc);\n\treq->rx_flow_control = cpu_to_le16((u16)rx_fc);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\n\tif (base_status(status) == MCC_STATUS_FEATURE_NOT_SUPPORTED)\n\t\treturn  -EOPNOTSUPP;\n\n\treturn status;\n}\n\n \nint be_cmd_get_flow_control(struct be_adapter *adapter, u32 *tx_fc, u32 *rx_fc)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_flow_control *req;\n\tint status;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_COMMON_GET_FLOW_CONTROL,\n\t\t\t    CMD_SUBSYSTEM_COMMON))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_FLOW_CONTROL, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_flow_control *resp =\n\t\t\t\t\t\tembedded_payload(wrb);\n\n\t\t*tx_fc = le16_to_cpu(resp->tx_flow_control);\n\t\t*rx_fc = le16_to_cpu(resp->rx_flow_control);\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_query_fw_cfg(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_query_fw_cfg *req;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_QUERY_FIRMWARE_CONFIG,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_query_fw_cfg *resp = embedded_payload(wrb);\n\n\t\tadapter->port_num = le32_to_cpu(resp->phys_port);\n\t\tadapter->function_mode = le32_to_cpu(resp->function_mode);\n\t\tadapter->function_caps = le32_to_cpu(resp->function_caps);\n\t\tadapter->asic_rev = le32_to_cpu(resp->asic_revision) & 0xFF;\n\t\tdev_info(&adapter->pdev->dev,\n\t\t\t \"FW config: function_mode=0x%x, function_caps=0x%x\\n\",\n\t\t\t adapter->function_mode, adapter->function_caps);\n\t}\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\n \nint be_cmd_reset_function(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_hdr *req;\n\tint status;\n\n\tif (lancer_chip(adapter)) {\n\t\tiowrite32(SLI_PORT_CONTROL_IP_MASK,\n\t\t\t  adapter->db + SLIPORT_CONTROL_OFFSET);\n\t\tstatus = lancer_wait_ready(adapter);\n\t\tif (status)\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Adapter in non recoverable error\\n\");\n\t\treturn status;\n\t}\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(req, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_FUNCTION_RESET, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\nint be_cmd_rss_config(struct be_adapter *adapter, u8 *rsstable,\n\t\t      u32 rss_hash_opts, u16 table_size, const u8 *rss_hkey)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_rss_config *req;\n\tint status;\n\n\tif (!(be_if_cap_flags(adapter) & BE_IF_FLAGS_RSS))\n\t\treturn 0;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_RSS_CONFIG, sizeof(*req), wrb, NULL);\n\n\treq->if_id = cpu_to_le32(adapter->if_handle);\n\treq->enable_rss = cpu_to_le16(rss_hash_opts);\n\treq->cpu_table_size_log2 = cpu_to_le16(fls(table_size) - 1);\n\n\tif (!BEx_chip(adapter))\n\t\treq->hdr.version = 1;\n\n\tmemcpy(req->cpu_table, rsstable, table_size);\n\tmemcpy(req->hash, rss_hkey, RSS_HASH_KEY_LEN);\n\tbe_dws_cpu_to_le(req->hash, sizeof(req->hash));\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_set_beacon_state(struct be_adapter *adapter, u8 port_num,\n\t\t\t    u8 bcn, u8 sts, u8 state)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_enable_disable_beacon *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_ENABLE_DISABLE_BEACON,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\treq->port_num = port_num;\n\treq->beacon_state = state;\n\treq->beacon_duration = bcn;\n\treq->status_duration = sts;\n\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_beacon_state(struct be_adapter *adapter, u8 port_num, u32 *state)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_beacon_state *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_BEACON_STATE, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->port_num = port_num;\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_beacon_state *resp =\n\t\t\t\t\t\tembedded_payload(wrb);\n\n\t\t*state = resp->beacon_state;\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_read_port_transceiver_data(struct be_adapter *adapter,\n\t\t\t\t      u8 page_num, u32 off, u32 len, u8 *data)\n{\n\tstruct be_dma_mem cmd;\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_port_type *req;\n\tint status;\n\n\tif (page_num > TR_PAGE_A2)\n\t\treturn -EINVAL;\n\n\tcmd.size = sizeof(struct be_cmd_resp_port_type);\n\tcmd.va = dma_alloc_coherent(&adapter->pdev->dev, cmd.size, &cmd.dma,\n\t\t\t\t    GFP_ATOMIC);\n\tif (!cmd.va) {\n\t\tdev_err(&adapter->pdev->dev, \"Memory allocation failed\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = cmd.va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_READ_TRANSRECV_DATA,\n\t\t\t       cmd.size, wrb, &cmd);\n\n\treq->port = cpu_to_le32(adapter->hba_port_num);\n\treq->page_num = cpu_to_le32(page_num);\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status && len > 0) {\n\t\tstruct be_cmd_resp_port_type *resp = cmd.va;\n\n\t\tmemcpy(data, resp->page_data + off, len);\n\t}\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\tdma_free_coherent(&adapter->pdev->dev, cmd.size, cmd.va, cmd.dma);\n\treturn status;\n}\n\nstatic int lancer_cmd_write_object(struct be_adapter *adapter,\n\t\t\t\t   struct be_dma_mem *cmd, u32 data_size,\n\t\t\t\t   u32 data_offset, const char *obj_name,\n\t\t\t\t   u32 *data_written, u8 *change_status,\n\t\t\t\t   u8 *addn_status)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct lancer_cmd_req_write_object *req;\n\tstruct lancer_cmd_resp_write_object *resp;\n\tvoid *ctxt = NULL;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\tadapter->flash_status = 0;\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err_unlock;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_WRITE_OBJECT,\n\t\t\t       sizeof(struct lancer_cmd_req_write_object), wrb,\n\t\t\t       NULL);\n\n\tctxt = &req->context;\n\tAMAP_SET_BITS(struct amap_lancer_write_obj_context,\n\t\t      write_length, ctxt, data_size);\n\n\tif (data_size == 0)\n\t\tAMAP_SET_BITS(struct amap_lancer_write_obj_context,\n\t\t\t      eof, ctxt, 1);\n\telse\n\t\tAMAP_SET_BITS(struct amap_lancer_write_obj_context,\n\t\t\t      eof, ctxt, 0);\n\n\tbe_dws_cpu_to_le(ctxt, sizeof(req->context));\n\treq->write_offset = cpu_to_le32(data_offset);\n\tstrscpy(req->object_name, obj_name, sizeof(req->object_name));\n\treq->descriptor_count = cpu_to_le32(1);\n\treq->buf_len = cpu_to_le32(data_size);\n\treq->addr_low = cpu_to_le32((cmd->dma +\n\t\t\t\t     sizeof(struct lancer_cmd_req_write_object))\n\t\t\t\t    & 0xFFFFFFFF);\n\treq->addr_high = cpu_to_le32(upper_32_bits(cmd->dma +\n\t\t\t\tsizeof(struct lancer_cmd_req_write_object)));\n\n\tstatus = be_mcc_notify(adapter);\n\tif (status)\n\t\tgoto err_unlock;\n\n\tmutex_unlock(&adapter->mcc_lock);\n\n\tif (!wait_for_completion_timeout(&adapter->et_cmd_compl,\n\t\t\t\t\t msecs_to_jiffies(60000)))\n\t\tstatus = -ETIMEDOUT;\n\telse\n\t\tstatus = adapter->flash_status;\n\n\tresp = embedded_payload(wrb);\n\tif (!status) {\n\t\t*data_written = le32_to_cpu(resp->actual_write_len);\n\t\t*change_status = resp->change_status;\n\t} else {\n\t\t*addn_status = resp->additional_status;\n\t}\n\n\treturn status;\n\nerr_unlock:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_query_cable_type(struct be_adapter *adapter)\n{\n\tu8 page_data[PAGE_DATA_LEN];\n\tint status;\n\n\tstatus = be_cmd_read_port_transceiver_data(adapter, TR_PAGE_A0,\n\t\t\t\t\t\t   0, PAGE_DATA_LEN, page_data);\n\tif (!status) {\n\t\tswitch (adapter->phy.interface_type) {\n\t\tcase PHY_TYPE_QSFP:\n\t\t\tadapter->phy.cable_type =\n\t\t\t\tpage_data[QSFP_PLUS_CABLE_TYPE_OFFSET];\n\t\t\tbreak;\n\t\tcase PHY_TYPE_SFP_PLUS_10GB:\n\t\t\tadapter->phy.cable_type =\n\t\t\t\tpage_data[SFP_PLUS_CABLE_TYPE_OFFSET];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tadapter->phy.cable_type = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn status;\n}\n\nint be_cmd_query_sfp_info(struct be_adapter *adapter)\n{\n\tu8 page_data[PAGE_DATA_LEN];\n\tint status;\n\n\tstatus = be_cmd_read_port_transceiver_data(adapter, TR_PAGE_A0,\n\t\t\t\t\t\t   0, PAGE_DATA_LEN, page_data);\n\tif (!status) {\n\t\tstrscpy(adapter->phy.vendor_name, page_data +\n\t\t\tSFP_VENDOR_NAME_OFFSET, SFP_VENDOR_NAME_LEN - 1);\n\t\tstrscpy(adapter->phy.vendor_pn,\n\t\t\tpage_data + SFP_VENDOR_PN_OFFSET,\n\t\t\tSFP_VENDOR_NAME_LEN - 1);\n\t}\n\n\treturn status;\n}\n\nstatic int lancer_cmd_delete_object(struct be_adapter *adapter,\n\t\t\t\t    const char *obj_name)\n{\n\tstruct lancer_cmd_req_delete_object *req;\n\tstruct be_mcc_wrb *wrb;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_DELETE_OBJECT,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\tstrscpy(req->object_name, obj_name, sizeof(req->object_name));\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint lancer_cmd_read_object(struct be_adapter *adapter, struct be_dma_mem *cmd,\n\t\t\t   u32 data_size, u32 data_offset, const char *obj_name,\n\t\t\t   u32 *data_read, u32 *eof, u8 *addn_status)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct lancer_cmd_req_read_object *req;\n\tstruct lancer_cmd_resp_read_object *resp;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err_unlock;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_READ_OBJECT,\n\t\t\t       sizeof(struct lancer_cmd_req_read_object), wrb,\n\t\t\t       NULL);\n\n\treq->desired_read_len = cpu_to_le32(data_size);\n\treq->read_offset = cpu_to_le32(data_offset);\n\tstrcpy(req->object_name, obj_name);\n\treq->descriptor_count = cpu_to_le32(1);\n\treq->buf_len = cpu_to_le32(data_size);\n\treq->addr_low = cpu_to_le32((cmd->dma & 0xFFFFFFFF));\n\treq->addr_high = cpu_to_le32(upper_32_bits(cmd->dma));\n\n\tstatus = be_mcc_notify_wait(adapter);\n\n\tresp = embedded_payload(wrb);\n\tif (!status) {\n\t\t*data_read = le32_to_cpu(resp->actual_read_len);\n\t\t*eof = le32_to_cpu(resp->eof);\n\t} else {\n\t\t*addn_status = resp->additional_status;\n\t}\n\nerr_unlock:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic int be_cmd_write_flashrom(struct be_adapter *adapter,\n\t\t\t\t struct be_dma_mem *cmd, u32 flash_type,\n\t\t\t\t u32 flash_opcode, u32 img_offset, u32 buf_size)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_write_flashrom *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\tadapter->flash_status = 0;\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err_unlock;\n\t}\n\treq = cmd->va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_WRITE_FLASHROM, cmd->size, wrb,\n\t\t\t       cmd);\n\n\treq->params.op_type = cpu_to_le32(flash_type);\n\tif (flash_type == OPTYPE_OFFSET_SPECIFIED)\n\t\treq->params.offset = cpu_to_le32(img_offset);\n\n\treq->params.op_code = cpu_to_le32(flash_opcode);\n\treq->params.data_buf_size = cpu_to_le32(buf_size);\n\n\tstatus = be_mcc_notify(adapter);\n\tif (status)\n\t\tgoto err_unlock;\n\n\tmutex_unlock(&adapter->mcc_lock);\n\n\tif (!wait_for_completion_timeout(&adapter->et_cmd_compl,\n\t\t\t\t\t msecs_to_jiffies(40000)))\n\t\tstatus = -ETIMEDOUT;\n\telse\n\t\tstatus = adapter->flash_status;\n\n\treturn status;\n\nerr_unlock:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic int be_cmd_get_flash_crc(struct be_adapter *adapter, u8 *flashed_crc,\n\t\t\t\tu16 img_optype, u32 img_offset, u32 crc_offset)\n{\n\tstruct be_cmd_read_flash_crc *req;\n\tstruct be_mcc_wrb *wrb;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_READ_FLASHROM, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->params.op_type = cpu_to_le32(img_optype);\n\tif (img_optype == OPTYPE_OFFSET_SPECIFIED)\n\t\treq->params.offset = cpu_to_le32(img_offset + crc_offset);\n\telse\n\t\treq->params.offset = cpu_to_le32(crc_offset);\n\n\treq->params.op_code = cpu_to_le32(FLASHROM_OPER_REPORT);\n\treq->params.data_buf_size = cpu_to_le32(0x4);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status)\n\t\tmemcpy(flashed_crc, req->crc, 4);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic char flash_cookie[2][16] = {\"*** SE FLAS\", \"H DIRECTORY *** \"};\n\nstatic bool phy_flashing_required(struct be_adapter *adapter)\n{\n\treturn (adapter->phy.phy_type == PHY_TYPE_TN_8022 &&\n\t\tadapter->phy.interface_type == PHY_TYPE_BASET_10GB);\n}\n\nstatic bool is_comp_in_ufi(struct be_adapter *adapter,\n\t\t\t   struct flash_section_info *fsec, int type)\n{\n\tint i = 0, img_type = 0;\n\tstruct flash_section_info_g2 *fsec_g2 = NULL;\n\n\tif (BE2_chip(adapter))\n\t\tfsec_g2 = (struct flash_section_info_g2 *)fsec;\n\n\tfor (i = 0; i < MAX_FLASH_COMP; i++) {\n\t\tif (fsec_g2)\n\t\t\timg_type = le32_to_cpu(fsec_g2->fsec_entry[i].type);\n\t\telse\n\t\t\timg_type = le32_to_cpu(fsec->fsec_entry[i].type);\n\n\t\tif (img_type == type)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\nstatic struct flash_section_info *get_fsec_info(struct be_adapter *adapter,\n\t\t\t\t\t\tint header_size,\n\t\t\t\t\t\tconst struct firmware *fw)\n{\n\tstruct flash_section_info *fsec = NULL;\n\tconst u8 *p = fw->data;\n\n\tp += header_size;\n\twhile (p < (fw->data + fw->size)) {\n\t\tfsec = (struct flash_section_info *)p;\n\t\tif (!memcmp(flash_cookie, fsec->cookie, sizeof(flash_cookie)))\n\t\t\treturn fsec;\n\t\tp += 32;\n\t}\n\treturn NULL;\n}\n\nstatic int be_check_flash_crc(struct be_adapter *adapter, const u8 *p,\n\t\t\t      u32 img_offset, u32 img_size, int hdr_size,\n\t\t\t      u16 img_optype, bool *crc_match)\n{\n\tu32 crc_offset;\n\tint status;\n\tu8 crc[4];\n\n\tstatus = be_cmd_get_flash_crc(adapter, crc, img_optype, img_offset,\n\t\t\t\t      img_size - 4);\n\tif (status)\n\t\treturn status;\n\n\tcrc_offset = hdr_size + img_offset + img_size - 4;\n\n\t \n\tif (!memcmp(crc, p + crc_offset, 4))\n\t\t*crc_match = true;\n\telse\n\t\t*crc_match = false;\n\n\treturn status;\n}\n\nstatic int be_flash(struct be_adapter *adapter, const u8 *img,\n\t\t    struct be_dma_mem *flash_cmd, int optype, int img_size,\n\t\t    u32 img_offset)\n{\n\tu32 flash_op, num_bytes, total_bytes = img_size, bytes_sent = 0;\n\tstruct be_cmd_write_flashrom *req = flash_cmd->va;\n\tint status;\n\n\twhile (total_bytes) {\n\t\tnum_bytes = min_t(u32, 32 * 1024, total_bytes);\n\n\t\ttotal_bytes -= num_bytes;\n\n\t\tif (!total_bytes) {\n\t\t\tif (optype == OPTYPE_PHY_FW)\n\t\t\t\tflash_op = FLASHROM_OPER_PHY_FLASH;\n\t\t\telse\n\t\t\t\tflash_op = FLASHROM_OPER_FLASH;\n\t\t} else {\n\t\t\tif (optype == OPTYPE_PHY_FW)\n\t\t\t\tflash_op = FLASHROM_OPER_PHY_SAVE;\n\t\t\telse\n\t\t\t\tflash_op = FLASHROM_OPER_SAVE;\n\t\t}\n\n\t\tmemcpy(req->data_buf, img, num_bytes);\n\t\timg += num_bytes;\n\t\tstatus = be_cmd_write_flashrom(adapter, flash_cmd, optype,\n\t\t\t\t\t       flash_op, img_offset +\n\t\t\t\t\t       bytes_sent, num_bytes);\n\t\tif (base_status(status) == MCC_STATUS_ILLEGAL_REQUEST &&\n\t\t    optype == OPTYPE_PHY_FW)\n\t\t\tbreak;\n\t\telse if (status)\n\t\t\treturn status;\n\n\t\tbytes_sent += num_bytes;\n\t}\n\treturn 0;\n}\n\n#define NCSI_UPDATE_LOG\t\"NCSI section update is not supported in FW ver %s\\n\"\nstatic bool be_fw_ncsi_supported(char *ver)\n{\n\tint v1[4] = {3, 102, 148, 0};  \n\tint v2[4];\n\tint i;\n\n\tif (sscanf(ver, \"%d.%d.%d.%d\", &v2[0], &v2[1], &v2[2], &v2[3]) != 4)\n\t\treturn false;\n\n\tfor (i = 0; i < 4; i++) {\n\t\tif (v1[i] < v2[i])\n\t\t\treturn true;\n\t\telse if (v1[i] > v2[i])\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}\n\n \nstatic int be_flash_BEx(struct be_adapter *adapter,\n\t\t\tconst struct firmware *fw,\n\t\t\tstruct be_dma_mem *flash_cmd, int num_of_images)\n{\n\tint img_hdrs_size = (num_of_images * sizeof(struct image_hdr));\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct flash_section_info *fsec = NULL;\n\tint status, i, filehdr_size, num_comp;\n\tconst struct flash_comp *pflashcomp;\n\tbool crc_match;\n\tconst u8 *p;\n\n\tstatic const struct flash_comp gen3_flash_types[] = {\n\t\t{ BE3_ISCSI_PRIMARY_IMAGE_START, OPTYPE_ISCSI_ACTIVE,\n\t\t\tBE3_COMP_MAX_SIZE, IMAGE_FIRMWARE_ISCSI},\n\t\t{ BE3_REDBOOT_START, OPTYPE_REDBOOT,\n\t\t\tBE3_REDBOOT_COMP_MAX_SIZE, IMAGE_BOOT_CODE},\n\t\t{ BE3_ISCSI_BIOS_START, OPTYPE_BIOS,\n\t\t\tBE3_BIOS_COMP_MAX_SIZE, IMAGE_OPTION_ROM_ISCSI},\n\t\t{ BE3_PXE_BIOS_START, OPTYPE_PXE_BIOS,\n\t\t\tBE3_BIOS_COMP_MAX_SIZE, IMAGE_OPTION_ROM_PXE},\n\t\t{ BE3_FCOE_BIOS_START, OPTYPE_FCOE_BIOS,\n\t\t\tBE3_BIOS_COMP_MAX_SIZE, IMAGE_OPTION_ROM_FCOE},\n\t\t{ BE3_ISCSI_BACKUP_IMAGE_START, OPTYPE_ISCSI_BACKUP,\n\t\t\tBE3_COMP_MAX_SIZE, IMAGE_FIRMWARE_BACKUP_ISCSI},\n\t\t{ BE3_FCOE_PRIMARY_IMAGE_START, OPTYPE_FCOE_FW_ACTIVE,\n\t\t\tBE3_COMP_MAX_SIZE, IMAGE_FIRMWARE_FCOE},\n\t\t{ BE3_FCOE_BACKUP_IMAGE_START, OPTYPE_FCOE_FW_BACKUP,\n\t\t\tBE3_COMP_MAX_SIZE, IMAGE_FIRMWARE_BACKUP_FCOE},\n\t\t{ BE3_NCSI_START, OPTYPE_NCSI_FW,\n\t\t\tBE3_NCSI_COMP_MAX_SIZE, IMAGE_NCSI},\n\t\t{ BE3_PHY_FW_START, OPTYPE_PHY_FW,\n\t\t\tBE3_PHY_FW_COMP_MAX_SIZE, IMAGE_FIRMWARE_PHY}\n\t};\n\n\tstatic const struct flash_comp gen2_flash_types[] = {\n\t\t{ BE2_ISCSI_PRIMARY_IMAGE_START, OPTYPE_ISCSI_ACTIVE,\n\t\t\tBE2_COMP_MAX_SIZE, IMAGE_FIRMWARE_ISCSI},\n\t\t{ BE2_REDBOOT_START, OPTYPE_REDBOOT,\n\t\t\tBE2_REDBOOT_COMP_MAX_SIZE, IMAGE_BOOT_CODE},\n\t\t{ BE2_ISCSI_BIOS_START, OPTYPE_BIOS,\n\t\t\tBE2_BIOS_COMP_MAX_SIZE, IMAGE_OPTION_ROM_ISCSI},\n\t\t{ BE2_PXE_BIOS_START, OPTYPE_PXE_BIOS,\n\t\t\tBE2_BIOS_COMP_MAX_SIZE, IMAGE_OPTION_ROM_PXE},\n\t\t{ BE2_FCOE_BIOS_START, OPTYPE_FCOE_BIOS,\n\t\t\tBE2_BIOS_COMP_MAX_SIZE, IMAGE_OPTION_ROM_FCOE},\n\t\t{ BE2_ISCSI_BACKUP_IMAGE_START, OPTYPE_ISCSI_BACKUP,\n\t\t\tBE2_COMP_MAX_SIZE, IMAGE_FIRMWARE_BACKUP_ISCSI},\n\t\t{ BE2_FCOE_PRIMARY_IMAGE_START, OPTYPE_FCOE_FW_ACTIVE,\n\t\t\tBE2_COMP_MAX_SIZE, IMAGE_FIRMWARE_FCOE},\n\t\t{ BE2_FCOE_BACKUP_IMAGE_START, OPTYPE_FCOE_FW_BACKUP,\n\t\t\t BE2_COMP_MAX_SIZE, IMAGE_FIRMWARE_BACKUP_FCOE}\n\t};\n\n\tif (BE3_chip(adapter)) {\n\t\tpflashcomp = gen3_flash_types;\n\t\tfilehdr_size = sizeof(struct flash_file_hdr_g3);\n\t\tnum_comp = ARRAY_SIZE(gen3_flash_types);\n\t} else {\n\t\tpflashcomp = gen2_flash_types;\n\t\tfilehdr_size = sizeof(struct flash_file_hdr_g2);\n\t\tnum_comp = ARRAY_SIZE(gen2_flash_types);\n\t\timg_hdrs_size = 0;\n\t}\n\n\t \n\tfsec = get_fsec_info(adapter, filehdr_size + img_hdrs_size, fw);\n\tif (!fsec) {\n\t\tdev_err(dev, \"Invalid Cookie. FW image may be corrupted\\n\");\n\t\treturn -1;\n\t}\n\tfor (i = 0; i < num_comp; i++) {\n\t\tif (!is_comp_in_ufi(adapter, fsec, pflashcomp[i].img_type))\n\t\t\tcontinue;\n\n\t\tif ((pflashcomp[i].optype == OPTYPE_NCSI_FW) &&\n\t\t    !be_fw_ncsi_supported(adapter->fw_ver)) {\n\t\t\tdev_info(dev, NCSI_UPDATE_LOG, adapter->fw_ver);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (pflashcomp[i].optype == OPTYPE_PHY_FW  &&\n\t\t    !phy_flashing_required(adapter))\n\t\t\tcontinue;\n\n\t\tif (pflashcomp[i].optype == OPTYPE_REDBOOT) {\n\t\t\tstatus = be_check_flash_crc(adapter, fw->data,\n\t\t\t\t\t\t    pflashcomp[i].offset,\n\t\t\t\t\t\t    pflashcomp[i].size,\n\t\t\t\t\t\t    filehdr_size +\n\t\t\t\t\t\t    img_hdrs_size,\n\t\t\t\t\t\t    OPTYPE_REDBOOT, &crc_match);\n\t\t\tif (status) {\n\t\t\t\tdev_err(dev,\n\t\t\t\t\t\"Could not get CRC for 0x%x region\\n\",\n\t\t\t\t\tpflashcomp[i].optype);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (crc_match)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tp = fw->data + filehdr_size + pflashcomp[i].offset +\n\t\t\timg_hdrs_size;\n\t\tif (p + pflashcomp[i].size > fw->data + fw->size)\n\t\t\treturn -1;\n\n\t\tstatus = be_flash(adapter, p, flash_cmd, pflashcomp[i].optype,\n\t\t\t\t  pflashcomp[i].size, 0);\n\t\tif (status) {\n\t\t\tdev_err(dev, \"Flashing section type 0x%x failed\\n\",\n\t\t\t\tpflashcomp[i].img_type);\n\t\t\treturn status;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic u16 be_get_img_optype(struct flash_section_entry fsec_entry)\n{\n\tu32 img_type = le32_to_cpu(fsec_entry.type);\n\tu16 img_optype = le16_to_cpu(fsec_entry.optype);\n\n\tif (img_optype != 0xFFFF)\n\t\treturn img_optype;\n\n\tswitch (img_type) {\n\tcase IMAGE_FIRMWARE_ISCSI:\n\t\timg_optype = OPTYPE_ISCSI_ACTIVE;\n\t\tbreak;\n\tcase IMAGE_BOOT_CODE:\n\t\timg_optype = OPTYPE_REDBOOT;\n\t\tbreak;\n\tcase IMAGE_OPTION_ROM_ISCSI:\n\t\timg_optype = OPTYPE_BIOS;\n\t\tbreak;\n\tcase IMAGE_OPTION_ROM_PXE:\n\t\timg_optype = OPTYPE_PXE_BIOS;\n\t\tbreak;\n\tcase IMAGE_OPTION_ROM_FCOE:\n\t\timg_optype = OPTYPE_FCOE_BIOS;\n\t\tbreak;\n\tcase IMAGE_FIRMWARE_BACKUP_ISCSI:\n\t\timg_optype = OPTYPE_ISCSI_BACKUP;\n\t\tbreak;\n\tcase IMAGE_NCSI:\n\t\timg_optype = OPTYPE_NCSI_FW;\n\t\tbreak;\n\tcase IMAGE_FLASHISM_JUMPVECTOR:\n\t\timg_optype = OPTYPE_FLASHISM_JUMPVECTOR;\n\t\tbreak;\n\tcase IMAGE_FIRMWARE_PHY:\n\t\timg_optype = OPTYPE_SH_PHY_FW;\n\t\tbreak;\n\tcase IMAGE_REDBOOT_DIR:\n\t\timg_optype = OPTYPE_REDBOOT_DIR;\n\t\tbreak;\n\tcase IMAGE_REDBOOT_CONFIG:\n\t\timg_optype = OPTYPE_REDBOOT_CONFIG;\n\t\tbreak;\n\tcase IMAGE_UFI_DIR:\n\t\timg_optype = OPTYPE_UFI_DIR;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn img_optype;\n}\n\nstatic int be_flash_skyhawk(struct be_adapter *adapter,\n\t\t\t    const struct firmware *fw,\n\t\t\t    struct be_dma_mem *flash_cmd, int num_of_images)\n{\n\tint img_hdrs_size = num_of_images * sizeof(struct image_hdr);\n\tbool crc_match, old_fw_img, flash_offset_support = true;\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct flash_section_info *fsec = NULL;\n\tu32 img_offset, img_size, img_type;\n\tu16 img_optype, flash_optype;\n\tint status, i, filehdr_size;\n\tconst u8 *p;\n\n\tfilehdr_size = sizeof(struct flash_file_hdr_g3);\n\tfsec = get_fsec_info(adapter, filehdr_size + img_hdrs_size, fw);\n\tif (!fsec) {\n\t\tdev_err(dev, \"Invalid Cookie. FW image may be corrupted\\n\");\n\t\treturn -EINVAL;\n\t}\n\nretry_flash:\n\tfor (i = 0; i < le32_to_cpu(fsec->fsec_hdr.num_images); i++) {\n\t\timg_offset = le32_to_cpu(fsec->fsec_entry[i].offset);\n\t\timg_size   = le32_to_cpu(fsec->fsec_entry[i].pad_size);\n\t\timg_type   = le32_to_cpu(fsec->fsec_entry[i].type);\n\t\timg_optype = be_get_img_optype(fsec->fsec_entry[i]);\n\t\told_fw_img = fsec->fsec_entry[i].optype == 0xFFFF;\n\n\t\tif (img_optype == 0xFFFF)\n\t\t\tcontinue;\n\n\t\tif (flash_offset_support)\n\t\t\tflash_optype = OPTYPE_OFFSET_SPECIFIED;\n\t\telse\n\t\t\tflash_optype = img_optype;\n\n\t\t \n\t\tif (old_fw_img)\n\t\t\tgoto flash;\n\n\t\tstatus = be_check_flash_crc(adapter, fw->data, img_offset,\n\t\t\t\t\t    img_size, filehdr_size +\n\t\t\t\t\t    img_hdrs_size, flash_optype,\n\t\t\t\t\t    &crc_match);\n\t\tif (base_status(status) == MCC_STATUS_ILLEGAL_REQUEST ||\n\t\t    base_status(status) == MCC_STATUS_ILLEGAL_FIELD) {\n\t\t\t \n\t\t\tif (flash_optype == OPTYPE_OFFSET_SPECIFIED) {\n\t\t\t\tflash_offset_support = false;\n\t\t\t\tgoto retry_flash;\n\t\t\t}\n\n\t\t\t \n\t\t\tdev_err(dev, \"Flash incomplete. Reset the server\\n\");\n\t\t\tdev_err(dev, \"Download FW image again after reset\\n\");\n\t\t\treturn -EAGAIN;\n\t\t} else if (status) {\n\t\t\tdev_err(dev, \"Could not get CRC for 0x%x region\\n\",\n\t\t\t\timg_optype);\n\t\t\treturn -EFAULT;\n\t\t}\n\n\t\tif (crc_match)\n\t\t\tcontinue;\n\nflash:\n\t\tp = fw->data + filehdr_size + img_offset + img_hdrs_size;\n\t\tif (p + img_size > fw->data + fw->size)\n\t\t\treturn -1;\n\n\t\tstatus = be_flash(adapter, p, flash_cmd, flash_optype, img_size,\n\t\t\t\t  img_offset);\n\n\t\t \n\t\tif (base_status(status) == MCC_STATUS_ILLEGAL_FIELD &&\n\t\t    flash_optype == OPTYPE_OFFSET_SPECIFIED) {\n\t\t\tflash_offset_support = false;\n\t\t\tgoto retry_flash;\n\t\t}\n\n\t\t \n\t\tif (old_fw_img &&\n\t\t    (base_status(status) == MCC_STATUS_ILLEGAL_FIELD ||\n\t\t     (img_optype == OPTYPE_UFI_DIR &&\n\t\t      base_status(status) == MCC_STATUS_FAILED))) {\n\t\t\tcontinue;\n\t\t} else if (status) {\n\t\t\tdev_err(dev, \"Flashing section type 0x%x failed\\n\",\n\t\t\t\timg_type);\n\n\t\t\tswitch (addl_status(status)) {\n\t\t\tcase MCC_ADDL_STATUS_MISSING_SIGNATURE:\n\t\t\t\tdev_err(dev,\n\t\t\t\t\t\"Digital signature missing in FW\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\tcase MCC_ADDL_STATUS_INVALID_SIGNATURE:\n\t\t\t\tdev_err(dev,\n\t\t\t\t\t\"Invalid digital signature in FW\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\tdefault:\n\t\t\t\treturn -EFAULT;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nint lancer_fw_download(struct be_adapter *adapter,\n\t\t       const struct firmware *fw)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct be_dma_mem flash_cmd;\n\tconst u8 *data_ptr = NULL;\n\tu8 *dest_image_ptr = NULL;\n\tsize_t image_size = 0;\n\tu32 chunk_size = 0;\n\tu32 data_written = 0;\n\tu32 offset = 0;\n\tint status = 0;\n\tu8 add_status = 0;\n\tu8 change_status;\n\n\tif (!IS_ALIGNED(fw->size, sizeof(u32))) {\n\t\tdev_err(dev, \"FW image size should be multiple of 4\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tflash_cmd.size = sizeof(struct lancer_cmd_req_write_object)\n\t\t\t\t+ LANCER_FW_DOWNLOAD_CHUNK;\n\tflash_cmd.va = dma_alloc_coherent(dev, flash_cmd.size, &flash_cmd.dma,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!flash_cmd.va)\n\t\treturn -ENOMEM;\n\n\tdest_image_ptr = flash_cmd.va +\n\t\t\t\tsizeof(struct lancer_cmd_req_write_object);\n\timage_size = fw->size;\n\tdata_ptr = fw->data;\n\n\twhile (image_size) {\n\t\tchunk_size = min_t(u32, image_size, LANCER_FW_DOWNLOAD_CHUNK);\n\n\t\t \n\t\tmemcpy(dest_image_ptr, data_ptr, chunk_size);\n\n\t\tstatus = lancer_cmd_write_object(adapter, &flash_cmd,\n\t\t\t\t\t\t chunk_size, offset,\n\t\t\t\t\t\t LANCER_FW_DOWNLOAD_LOCATION,\n\t\t\t\t\t\t &data_written, &change_status,\n\t\t\t\t\t\t &add_status);\n\t\tif (status)\n\t\t\tbreak;\n\n\t\toffset += data_written;\n\t\tdata_ptr += data_written;\n\t\timage_size -= data_written;\n\t}\n\n\tif (!status) {\n\t\t \n\t\tstatus = lancer_cmd_write_object(adapter, &flash_cmd,\n\t\t\t\t\t\t 0, offset,\n\t\t\t\t\t\t LANCER_FW_DOWNLOAD_LOCATION,\n\t\t\t\t\t\t &data_written, &change_status,\n\t\t\t\t\t\t &add_status);\n\t}\n\n\tdma_free_coherent(dev, flash_cmd.size, flash_cmd.va, flash_cmd.dma);\n\tif (status) {\n\t\tdev_err(dev, \"Firmware load error\\n\");\n\t\treturn be_cmd_status(status);\n\t}\n\n\tdev_info(dev, \"Firmware flashed successfully\\n\");\n\n\tif (change_status == LANCER_FW_RESET_NEEDED) {\n\t\tdev_info(dev, \"Resetting adapter to activate new FW\\n\");\n\t\tstatus = lancer_physdev_ctrl(adapter,\n\t\t\t\t\t     PHYSDEV_CONTROL_FW_RESET_MASK);\n\t\tif (status) {\n\t\t\tdev_err(dev, \"Adapter busy, could not reset FW\\n\");\n\t\t\tdev_err(dev, \"Reboot server to activate new FW\\n\");\n\t\t}\n\t} else if (change_status != LANCER_NO_RESET_NEEDED) {\n\t\tdev_info(dev, \"Reboot server to activate new FW\\n\");\n\t}\n\n\treturn 0;\n}\n\n \nstatic bool be_check_ufi_compatibility(struct be_adapter *adapter,\n\t\t\t\t       struct flash_file_hdr_g3 *fhdr)\n{\n\tif (!fhdr) {\n\t\tdev_err(&adapter->pdev->dev, \"Invalid FW UFI file\");\n\t\treturn false;\n\t}\n\n\t \n\tswitch (fhdr->build[0]) {\n\tcase BLD_STR_UFI_TYPE_SH:\n\t\tif (!skyhawk_chip(adapter))\n\t\t\treturn false;\n\t\tbreak;\n\tcase BLD_STR_UFI_TYPE_BE3:\n\t\tif (!BE3_chip(adapter))\n\t\t\treturn false;\n\t\tbreak;\n\tcase BLD_STR_UFI_TYPE_BE2:\n\t\tif (!BE2_chip(adapter))\n\t\t\treturn false;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\n\t \n\tif (BEx_chip(adapter) && fhdr->asic_type_rev == 0)\n\t\treturn adapter->asic_rev < 0x10;\n\telse\n\t\treturn (fhdr->asic_type_rev >= adapter->asic_rev);\n}\n\nint be_fw_download(struct be_adapter *adapter, const struct firmware *fw)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct flash_file_hdr_g3 *fhdr3;\n\tstruct image_hdr *img_hdr_ptr;\n\tint status = 0, i, num_imgs;\n\tstruct be_dma_mem flash_cmd;\n\n\tfhdr3 = (struct flash_file_hdr_g3 *)fw->data;\n\tif (!be_check_ufi_compatibility(adapter, fhdr3)) {\n\t\tdev_err(dev, \"Flash image is not compatible with adapter\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tflash_cmd.size = sizeof(struct be_cmd_write_flashrom);\n\tflash_cmd.va = dma_alloc_coherent(dev, flash_cmd.size, &flash_cmd.dma,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!flash_cmd.va)\n\t\treturn -ENOMEM;\n\n\tnum_imgs = le32_to_cpu(fhdr3->num_imgs);\n\tfor (i = 0; i < num_imgs; i++) {\n\t\timg_hdr_ptr = (struct image_hdr *)(fw->data +\n\t\t\t\t(sizeof(struct flash_file_hdr_g3) +\n\t\t\t\t i * sizeof(struct image_hdr)));\n\t\tif (!BE2_chip(adapter) &&\n\t\t    le32_to_cpu(img_hdr_ptr->imageid) != 1)\n\t\t\tcontinue;\n\n\t\tif (skyhawk_chip(adapter))\n\t\t\tstatus = be_flash_skyhawk(adapter, fw, &flash_cmd,\n\t\t\t\t\t\t  num_imgs);\n\t\telse\n\t\t\tstatus = be_flash_BEx(adapter, fw, &flash_cmd,\n\t\t\t\t\t      num_imgs);\n\t}\n\n\tdma_free_coherent(dev, flash_cmd.size, flash_cmd.va, flash_cmd.dma);\n\tif (!status)\n\t\tdev_info(dev, \"Firmware flashed successfully\\n\");\n\n\treturn status;\n}\n\nint be_cmd_enable_magic_wol(struct be_adapter *adapter, u8 *mac,\n\t\t\t    struct be_dma_mem *nonemb_cmd)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_acpi_wol_magic_config *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = nonemb_cmd->va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_ACPI_WOL_MAGIC_CONFIG, sizeof(*req),\n\t\t\t       wrb, nonemb_cmd);\n\tmemcpy(req->magic_mac, mac, ETH_ALEN);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_set_loopback(struct be_adapter *adapter, u8 port_num,\n\t\t\tu8 loopback_type, u8 enable)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_lmode *req;\n\tint status;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_LOWLEVEL_SET_LOOPBACK_MODE,\n\t\t\t    CMD_SUBSYSTEM_LOWLEVEL))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err_unlock;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_LOWLEVEL,\n\t\t\t       OPCODE_LOWLEVEL_SET_LOOPBACK_MODE, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->src_port = port_num;\n\treq->dest_port = port_num;\n\treq->loopback_type = loopback_type;\n\treq->loopback_state = enable;\n\n\tstatus = be_mcc_notify(adapter);\n\tif (status)\n\t\tgoto err_unlock;\n\n\tmutex_unlock(&adapter->mcc_lock);\n\n\tif (!wait_for_completion_timeout(&adapter->et_cmd_compl,\n\t\t\t\t\t msecs_to_jiffies(SET_LB_MODE_TIMEOUT)))\n\t\tstatus = -ETIMEDOUT;\n\n\treturn status;\n\nerr_unlock:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_loopback_test(struct be_adapter *adapter, u32 port_num,\n\t\t\t u32 loopback_type, u32 pkt_size, u32 num_pkts,\n\t\t\t u64 pattern)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_loopback_test *req;\n\tstruct be_cmd_resp_loopback_test *resp;\n\tint status;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_LOWLEVEL_LOOPBACK_TEST,\n\t\t\t    CMD_SUBSYSTEM_LOWLEVEL))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_LOWLEVEL,\n\t\t\t       OPCODE_LOWLEVEL_LOOPBACK_TEST, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->hdr.timeout = cpu_to_le32(15);\n\treq->pattern = cpu_to_le64(pattern);\n\treq->src_port = cpu_to_le32(port_num);\n\treq->dest_port = cpu_to_le32(port_num);\n\treq->pkt_size = cpu_to_le32(pkt_size);\n\treq->num_pkts = cpu_to_le32(num_pkts);\n\treq->loopback_type = cpu_to_le32(loopback_type);\n\n\tstatus = be_mcc_notify(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tmutex_unlock(&adapter->mcc_lock);\n\n\twait_for_completion(&adapter->et_cmd_compl);\n\tresp = embedded_payload(wrb);\n\tstatus = le32_to_cpu(resp->status);\n\n\treturn status;\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_ddr_dma_test(struct be_adapter *adapter, u64 pattern,\n\t\t\tu32 byte_cnt, struct be_dma_mem *cmd)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_ddrdma_test *req;\n\tint status;\n\tint i, j = 0;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_LOWLEVEL_HOST_DDR_DMA,\n\t\t\t    CMD_SUBSYSTEM_LOWLEVEL))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = cmd->va;\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_LOWLEVEL,\n\t\t\t       OPCODE_LOWLEVEL_HOST_DDR_DMA, cmd->size, wrb,\n\t\t\t       cmd);\n\n\treq->pattern = cpu_to_le64(pattern);\n\treq->byte_count = cpu_to_le32(byte_cnt);\n\tfor (i = 0; i < byte_cnt; i++) {\n\t\treq->snd_buff[i] = (u8)(pattern >> (j * 8));\n\t\tj++;\n\t\tif (j > 7)\n\t\t\tj = 0;\n\t}\n\n\tstatus = be_mcc_notify_wait(adapter);\n\n\tif (!status) {\n\t\tstruct be_cmd_resp_ddrdma_test *resp;\n\n\t\tresp = cmd->va;\n\t\tif ((memcmp(resp->rcv_buff, req->snd_buff, byte_cnt) != 0) ||\n\t\t    resp->snd_err) {\n\t\t\tstatus = -1;\n\t\t}\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_get_seeprom_data(struct be_adapter *adapter,\n\t\t\t    struct be_dma_mem *nonemb_cmd)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_seeprom_read *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = nonemb_cmd->va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SEEPROM_READ, sizeof(*req), wrb,\n\t\t\t       nonemb_cmd);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_get_phy_info(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_phy_info *req;\n\tstruct be_dma_mem cmd;\n\tint status;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_COMMON_GET_PHY_DETAILS,\n\t\t\t    CMD_SUBSYSTEM_COMMON))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\tcmd.size = sizeof(struct be_cmd_req_get_phy_info);\n\tcmd.va = dma_alloc_coherent(&adapter->pdev->dev, cmd.size, &cmd.dma,\n\t\t\t\t    GFP_ATOMIC);\n\tif (!cmd.va) {\n\t\tdev_err(&adapter->pdev->dev, \"Memory alloc failure\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\treq = cmd.va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_PHY_DETAILS, sizeof(*req),\n\t\t\t       wrb, &cmd);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_phy_info *resp_phy_info =\n\t\t\t\tcmd.va + sizeof(struct be_cmd_req_hdr);\n\n\t\tadapter->phy.phy_type = le16_to_cpu(resp_phy_info->phy_type);\n\t\tadapter->phy.interface_type =\n\t\t\tle16_to_cpu(resp_phy_info->interface_type);\n\t\tadapter->phy.auto_speeds_supported =\n\t\t\tle16_to_cpu(resp_phy_info->auto_speeds_supported);\n\t\tadapter->phy.fixed_speeds_supported =\n\t\t\tle16_to_cpu(resp_phy_info->fixed_speeds_supported);\n\t\tadapter->phy.misc_params =\n\t\t\tle32_to_cpu(resp_phy_info->misc_params);\n\n\t\tif (BE2_chip(adapter)) {\n\t\t\tadapter->phy.fixed_speeds_supported =\n\t\t\t\tBE_SUPPORTED_SPEED_10GBPS |\n\t\t\t\tBE_SUPPORTED_SPEED_1GBPS;\n\t\t}\n\t}\n\tdma_free_coherent(&adapter->pdev->dev, cmd.size, cmd.va, cmd.dma);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic int be_cmd_set_qos(struct be_adapter *adapter, u32 bps, u32 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_qos *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_QOS, sizeof(*req), wrb, NULL);\n\n\treq->hdr.domain = domain;\n\treq->valid_bits = cpu_to_le32(BE_QOS_BITS_NIC);\n\treq->max_bps_nic = cpu_to_le32(bps);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_get_cntl_attributes(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_cntl_attribs *req;\n\tstruct be_cmd_resp_cntl_attribs *resp;\n\tint status, i;\n\tint payload_len = max(sizeof(*req), sizeof(*resp));\n\tstruct mgmt_controller_attrib *attribs;\n\tstruct be_dma_mem attribs_cmd;\n\tu32 *serial_num;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\tmemset(&attribs_cmd, 0, sizeof(struct be_dma_mem));\n\tattribs_cmd.size = sizeof(struct be_cmd_resp_cntl_attribs);\n\tattribs_cmd.va = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t    attribs_cmd.size,\n\t\t\t\t\t    &attribs_cmd.dma, GFP_ATOMIC);\n\tif (!attribs_cmd.va) {\n\t\tdev_err(&adapter->pdev->dev, \"Memory allocation failure\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\twrb = wrb_from_mbox(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = attribs_cmd.va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_CNTL_ATTRIBUTES, payload_len,\n\t\t\t       wrb, &attribs_cmd);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tattribs = attribs_cmd.va + sizeof(struct be_cmd_resp_hdr);\n\t\tadapter->hba_port_num = attribs->hba_attribs.phy_port;\n\t\tserial_num = attribs->hba_attribs.controller_serial_number;\n\t\tfor (i = 0; i < CNTL_SERIAL_NUM_WORDS; i++)\n\t\t\tadapter->serial_num[i] = le32_to_cpu(serial_num[i]) &\n\t\t\t\t(BIT_MASK(16) - 1);\n\t\t \n\t\tif (BEx_chip(adapter))\n\t\t\tadapter->pf_num = attribs->hba_attribs.pci_funcnum;\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mbox_lock);\n\tif (attribs_cmd.va)\n\t\tdma_free_coherent(&adapter->pdev->dev, attribs_cmd.size,\n\t\t\t\t  attribs_cmd.va, attribs_cmd.dma);\n\treturn status;\n}\n\n \nint be_cmd_req_native_mode(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_func_cap *req;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_DRIVER_FUNCTION_CAP,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\treq->valid_cap_flags = cpu_to_le32(CAPABILITY_SW_TIMESTAMPS |\n\t\t\t\tCAPABILITY_BE3_NATIVE_ERX_API);\n\treq->cap_flags = cpu_to_le32(CAPABILITY_BE3_NATIVE_ERX_API);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_set_func_cap *resp = embedded_payload(wrb);\n\n\t\tadapter->be3_native = le32_to_cpu(resp->cap_flags) &\n\t\t\t\t\tCAPABILITY_BE3_NATIVE_ERX_API;\n\t\tif (!adapter->be3_native)\n\t\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t\t \"adapter not in advanced mode\\n\");\n\t}\nerr:\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_fn_privileges(struct be_adapter *adapter, u32 *privilege,\n\t\t\t     u32 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_fn_privileges *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_FN_PRIVILEGES, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->hdr.domain = domain;\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_fn_privileges *resp =\n\t\t\t\t\t\tembedded_payload(wrb);\n\n\t\t*privilege = le32_to_cpu(resp->privilege_mask);\n\n\t\t \n\t\tif (BEx_chip(adapter) && be_is_mc(adapter) &&\n\t\t    be_physfn(adapter))\n\t\t\t*privilege = MAX_PRIVILEGES;\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_set_fn_privileges(struct be_adapter *adapter, u32 privileges,\n\t\t\t     u32 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_fn_privileges *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_FN_PRIVILEGES, sizeof(*req),\n\t\t\t       wrb, NULL);\n\treq->hdr.domain = domain;\n\tif (lancer_chip(adapter))\n\t\treq->privileges_lancer = cpu_to_le32(privileges);\n\telse\n\t\treq->privileges = cpu_to_le32(privileges);\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_mac_from_list(struct be_adapter *adapter, u8 *mac,\n\t\t\t     bool *pmac_id_valid, u32 *pmac_id, u32 if_handle,\n\t\t\t     u8 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_mac_list *req;\n\tint status;\n\tint mac_count;\n\tstruct be_dma_mem get_mac_list_cmd;\n\tint i;\n\n\tmemset(&get_mac_list_cmd, 0, sizeof(struct be_dma_mem));\n\tget_mac_list_cmd.size = sizeof(struct be_cmd_resp_get_mac_list);\n\tget_mac_list_cmd.va = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t\t get_mac_list_cmd.size,\n\t\t\t\t\t\t &get_mac_list_cmd.dma,\n\t\t\t\t\t\t GFP_ATOMIC);\n\n\tif (!get_mac_list_cmd.va) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Memory allocation failure during GET_MAC_LIST\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto out;\n\t}\n\n\treq = get_mac_list_cmd.va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_MAC_LIST,\n\t\t\t       get_mac_list_cmd.size, wrb, &get_mac_list_cmd);\n\treq->hdr.domain = domain;\n\treq->mac_type = MAC_ADDRESS_TYPE_NETWORK;\n\tif (*pmac_id_valid) {\n\t\treq->mac_id = cpu_to_le32(*pmac_id);\n\t\treq->iface_id = cpu_to_le16(if_handle);\n\t\treq->perm_override = 0;\n\t} else {\n\t\treq->perm_override = 1;\n\t}\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_mac_list *resp =\n\t\t\t\t\t\tget_mac_list_cmd.va;\n\n\t\tif (*pmac_id_valid) {\n\t\t\tmemcpy(mac, resp->macid_macaddr.mac_addr_id.macaddr,\n\t\t\t       ETH_ALEN);\n\t\t\tgoto out;\n\t\t}\n\n\t\tmac_count = resp->true_mac_count + resp->pseudo_mac_count;\n\t\t \n\t\tfor (i = 0; i < mac_count; i++) {\n\t\t\tstruct get_list_macaddr *mac_entry;\n\t\t\tu16 mac_addr_size;\n\t\t\tu32 mac_id;\n\n\t\t\tmac_entry = &resp->macaddr_list[i];\n\t\t\tmac_addr_size = le16_to_cpu(mac_entry->mac_addr_size);\n\t\t\t \n\t\t\tif (mac_addr_size == sizeof(u32)) {\n\t\t\t\t*pmac_id_valid = true;\n\t\t\t\tmac_id = mac_entry->mac_addr_id.s_mac_id.mac_id;\n\t\t\t\t*pmac_id = le32_to_cpu(mac_id);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\t \n\t\t*pmac_id_valid = false;\n\t\tmemcpy(mac, resp->macaddr_list[0].mac_addr_id.macaddr,\n\t\t       ETH_ALEN);\n\t}\n\nout:\n\tmutex_unlock(&adapter->mcc_lock);\n\tdma_free_coherent(&adapter->pdev->dev, get_mac_list_cmd.size,\n\t\t\t  get_mac_list_cmd.va, get_mac_list_cmd.dma);\n\treturn status;\n}\n\nint be_cmd_get_active_mac(struct be_adapter *adapter, u32 curr_pmac_id,\n\t\t\t  u8 *mac, u32 if_handle, bool active, u32 domain)\n{\n\tif (!active)\n\t\tbe_cmd_get_mac_from_list(adapter, mac, &active, &curr_pmac_id,\n\t\t\t\t\t if_handle, domain);\n\tif (BEx_chip(adapter))\n\t\treturn be_cmd_mac_addr_query(adapter, mac, false,\n\t\t\t\t\t     if_handle, curr_pmac_id);\n\telse\n\t\t \n\t\treturn be_cmd_get_mac_from_list(adapter, mac, &active,\n\t\t\t\t\t\t&curr_pmac_id,\n\t\t\t\t\t\tif_handle, domain);\n}\n\nint be_cmd_get_perm_mac(struct be_adapter *adapter, u8 *mac)\n{\n\tint status;\n\tbool pmac_valid = false;\n\n\teth_zero_addr(mac);\n\n\tif (BEx_chip(adapter)) {\n\t\tif (be_physfn(adapter))\n\t\t\tstatus = be_cmd_mac_addr_query(adapter, mac, true, 0,\n\t\t\t\t\t\t       0);\n\t\telse\n\t\t\tstatus = be_cmd_mac_addr_query(adapter, mac, false,\n\t\t\t\t\t\t       adapter->if_handle, 0);\n\t} else {\n\t\tstatus = be_cmd_get_mac_from_list(adapter, mac, &pmac_valid,\n\t\t\t\t\t\t  NULL, adapter->if_handle, 0);\n\t}\n\n\treturn status;\n}\n\n \nint be_cmd_set_mac_list(struct be_adapter *adapter, u8 *mac_array,\n\t\t\tu8 mac_count, u32 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_mac_list *req;\n\tint status;\n\tstruct be_dma_mem cmd;\n\n\tmemset(&cmd, 0, sizeof(struct be_dma_mem));\n\tcmd.size = sizeof(struct be_cmd_req_set_mac_list);\n\tcmd.va = dma_alloc_coherent(&adapter->pdev->dev, cmd.size, &cmd.dma,\n\t\t\t\t    GFP_KERNEL);\n\tif (!cmd.va)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = cmd.va;\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_MAC_LIST, sizeof(*req),\n\t\t\t       wrb, &cmd);\n\n\treq->hdr.domain = domain;\n\treq->mac_count = mac_count;\n\tif (mac_count)\n\t\tmemcpy(req->mac, mac_array, ETH_ALEN * mac_count);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tdma_free_coherent(&adapter->pdev->dev, cmd.size, cmd.va, cmd.dma);\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_set_mac(struct be_adapter *adapter, u8 *mac, int if_id, u32 dom)\n{\n\tbool active_mac = false;\n\tu8 old_mac[ETH_ALEN];\n\tu32 pmac_id;\n\tint status;\n\n\tstatus = be_cmd_get_mac_from_list(adapter, old_mac, &active_mac,\n\t\t\t\t\t  &pmac_id, if_id, dom);\n\n\tif (!status && active_mac)\n\t\tbe_cmd_pmac_del(adapter, if_id, pmac_id, dom);\n\n\treturn be_cmd_set_mac_list(adapter, mac, mac ? 1 : 0, dom);\n}\n\nint be_cmd_set_hsw_config(struct be_adapter *adapter, u16 pvid,\n\t\t\t  u32 domain, u16 intf_id, u16 hsw_mode, u8 spoofchk)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_hsw_config *req;\n\tvoid *ctxt;\n\tint status;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_COMMON_SET_HSW_CONFIG,\n\t\t\t    CMD_SUBSYSTEM_COMMON))\n\t\treturn -EPERM;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\tctxt = &req->context;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_HSW_CONFIG, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->hdr.domain = domain;\n\tAMAP_SET_BITS(struct amap_set_hsw_context, interface_id, ctxt, intf_id);\n\tif (pvid) {\n\t\tAMAP_SET_BITS(struct amap_set_hsw_context, pvid_valid, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_set_hsw_context, pvid, ctxt, pvid);\n\t}\n\tif (hsw_mode) {\n\t\tAMAP_SET_BITS(struct amap_set_hsw_context, interface_id,\n\t\t\t      ctxt, adapter->hba_port_num);\n\t\tAMAP_SET_BITS(struct amap_set_hsw_context, pport, ctxt, 1);\n\t\tAMAP_SET_BITS(struct amap_set_hsw_context, port_fwd_type,\n\t\t\t      ctxt, hsw_mode);\n\t}\n\n\t \n\tif (!BEx_chip(adapter) && spoofchk) {\n\t\tAMAP_SET_BITS(struct amap_set_hsw_context, mac_spoofchk,\n\t\t\t      ctxt, spoofchk);\n\t\tAMAP_SET_BITS(struct amap_set_hsw_context, vlan_spoofchk,\n\t\t\t      ctxt, spoofchk);\n\t}\n\n\tbe_dws_cpu_to_le(req->context, sizeof(req->context));\n\tstatus = be_mcc_notify_wait(adapter);\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_hsw_config(struct be_adapter *adapter, u16 *pvid,\n\t\t\t  u32 domain, u16 intf_id, u8 *mode, bool *spoofchk)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_hsw_config *req;\n\tvoid *ctxt;\n\tint status;\n\tu16 vid;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\tctxt = &req->context;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_HSW_CONFIG, sizeof(*req), wrb,\n\t\t\t       NULL);\n\n\treq->hdr.domain = domain;\n\tAMAP_SET_BITS(struct amap_get_hsw_req_context, interface_id,\n\t\t      ctxt, intf_id);\n\tAMAP_SET_BITS(struct amap_get_hsw_req_context, pvid_valid, ctxt, 1);\n\n\tif (!BEx_chip(adapter) && mode) {\n\t\tAMAP_SET_BITS(struct amap_get_hsw_req_context, interface_id,\n\t\t\t      ctxt, adapter->hba_port_num);\n\t\tAMAP_SET_BITS(struct amap_get_hsw_req_context, pport, ctxt, 1);\n\t}\n\tbe_dws_cpu_to_le(req->context, sizeof(req->context));\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_hsw_config *resp =\n\t\t\t\t\t\tembedded_payload(wrb);\n\n\t\tbe_dws_le_to_cpu(&resp->context, sizeof(resp->context));\n\t\tvid = AMAP_GET_BITS(struct amap_get_hsw_resp_context,\n\t\t\t\t    pvid, &resp->context);\n\t\tif (pvid)\n\t\t\t*pvid = le16_to_cpu(vid);\n\t\tif (mode)\n\t\t\t*mode = AMAP_GET_BITS(struct amap_get_hsw_resp_context,\n\t\t\t\t\t      port_fwd_type, &resp->context);\n\t\tif (spoofchk)\n\t\t\t*spoofchk =\n\t\t\t\tAMAP_GET_BITS(struct amap_get_hsw_resp_context,\n\t\t\t\t\t      spoofchk, &resp->context);\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic bool be_is_wol_excluded(struct be_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\n\tif (be_virtfn(adapter))\n\t\treturn true;\n\n\tswitch (pdev->subsystem_device) {\n\tcase OC_SUBSYS_DEVICE_ID1:\n\tcase OC_SUBSYS_DEVICE_ID2:\n\tcase OC_SUBSYS_DEVICE_ID3:\n\tcase OC_SUBSYS_DEVICE_ID4:\n\t\treturn true;\n\tdefault:\n\t\treturn false;\n\t}\n}\n\nint be_cmd_get_acpi_wol_cap(struct be_adapter *adapter)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_acpi_wol_magic_config_v1 *req;\n\tint status = 0;\n\tstruct be_dma_mem cmd;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_ETH_ACPI_WOL_MAGIC_CONFIG,\n\t\t\t    CMD_SUBSYSTEM_ETH))\n\t\treturn -EPERM;\n\n\tif (be_is_wol_excluded(adapter))\n\t\treturn status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\tmemset(&cmd, 0, sizeof(struct be_dma_mem));\n\tcmd.size = sizeof(struct be_cmd_resp_acpi_wol_magic_config_v1);\n\tcmd.va = dma_alloc_coherent(&adapter->pdev->dev, cmd.size, &cmd.dma,\n\t\t\t\t    GFP_ATOMIC);\n\tif (!cmd.va) {\n\t\tdev_err(&adapter->pdev->dev, \"Memory allocation failure\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\twrb = wrb_from_mbox(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = cmd.va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,\n\t\t\t       OPCODE_ETH_ACPI_WOL_MAGIC_CONFIG,\n\t\t\t       sizeof(*req), wrb, &cmd);\n\n\treq->hdr.version = 1;\n\treq->query_options = BE_GET_WOL_CAP;\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_acpi_wol_magic_config_v1 *resp;\n\n\t\tresp = (struct be_cmd_resp_acpi_wol_magic_config_v1 *)cmd.va;\n\n\t\tadapter->wol_cap = resp->wol_settings;\n\n\t\t \n\t\tif (adapter->wol_cap & BE_WOL_CAP &&\n\t\t    !is_zero_ether_addr(resp->magic_mac))\n\t\t\tadapter->wol_en = true;\n\t}\nerr:\n\tmutex_unlock(&adapter->mbox_lock);\n\tif (cmd.va)\n\t\tdma_free_coherent(&adapter->pdev->dev, cmd.size, cmd.va,\n\t\t\t\t  cmd.dma);\n\treturn status;\n\n}\n\nint be_cmd_set_fw_log_level(struct be_adapter *adapter, u32 level)\n{\n\tstruct be_dma_mem extfat_cmd;\n\tstruct be_fat_conf_params *cfgs;\n\tint status;\n\tint i, j;\n\n\tmemset(&extfat_cmd, 0, sizeof(struct be_dma_mem));\n\textfat_cmd.size = sizeof(struct be_cmd_resp_get_ext_fat_caps);\n\textfat_cmd.va = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t   extfat_cmd.size, &extfat_cmd.dma,\n\t\t\t\t\t   GFP_ATOMIC);\n\tif (!extfat_cmd.va)\n\t\treturn -ENOMEM;\n\n\tstatus = be_cmd_get_ext_fat_capabilites(adapter, &extfat_cmd);\n\tif (status)\n\t\tgoto err;\n\n\tcfgs = (struct be_fat_conf_params *)\n\t\t\t(extfat_cmd.va + sizeof(struct be_cmd_resp_hdr));\n\tfor (i = 0; i < le32_to_cpu(cfgs->num_modules); i++) {\n\t\tu32 num_modes = le32_to_cpu(cfgs->module[i].num_modes);\n\n\t\tfor (j = 0; j < num_modes; j++) {\n\t\t\tif (cfgs->module[i].trace_lvl[j].mode == MODE_UART)\n\t\t\t\tcfgs->module[i].trace_lvl[j].dbg_lvl =\n\t\t\t\t\t\t\tcpu_to_le32(level);\n\t\t}\n\t}\n\n\tstatus = be_cmd_set_ext_fat_capabilites(adapter, &extfat_cmd, cfgs);\nerr:\n\tdma_free_coherent(&adapter->pdev->dev, extfat_cmd.size, extfat_cmd.va,\n\t\t\t  extfat_cmd.dma);\n\treturn status;\n}\n\nint be_cmd_get_fw_log_level(struct be_adapter *adapter)\n{\n\tstruct be_dma_mem extfat_cmd;\n\tstruct be_fat_conf_params *cfgs;\n\tint status, j;\n\tint level = 0;\n\n\tmemset(&extfat_cmd, 0, sizeof(struct be_dma_mem));\n\textfat_cmd.size = sizeof(struct be_cmd_resp_get_ext_fat_caps);\n\textfat_cmd.va = dma_alloc_coherent(&adapter->pdev->dev,\n\t\t\t\t\t   extfat_cmd.size, &extfat_cmd.dma,\n\t\t\t\t\t   GFP_ATOMIC);\n\n\tif (!extfat_cmd.va) {\n\t\tdev_err(&adapter->pdev->dev, \"%s: Memory allocation failure\\n\",\n\t\t\t__func__);\n\t\tgoto err;\n\t}\n\n\tstatus = be_cmd_get_ext_fat_capabilites(adapter, &extfat_cmd);\n\tif (!status) {\n\t\tcfgs = (struct be_fat_conf_params *)(extfat_cmd.va +\n\t\t\t\t\t\tsizeof(struct be_cmd_resp_hdr));\n\n\t\tfor (j = 0; j < le32_to_cpu(cfgs->module[0].num_modes); j++) {\n\t\t\tif (cfgs->module[0].trace_lvl[j].mode == MODE_UART)\n\t\t\t\tlevel = cfgs->module[0].trace_lvl[j].dbg_lvl;\n\t\t}\n\t}\n\tdma_free_coherent(&adapter->pdev->dev, extfat_cmd.size, extfat_cmd.va,\n\t\t\t  extfat_cmd.dma);\nerr:\n\treturn level;\n}\n\nint be_cmd_get_ext_fat_capabilites(struct be_adapter *adapter,\n\t\t\t\t   struct be_dma_mem *cmd)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_ext_fat_caps *req;\n\tint status;\n\n\tif (!be_cmd_allowed(adapter, OPCODE_COMMON_GET_EXT_FAT_CAPABILITIES,\n\t\t\t    CMD_SUBSYSTEM_COMMON))\n\t\treturn -EPERM;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = cmd->va;\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_EXT_FAT_CAPABILITIES,\n\t\t\t       cmd->size, wrb, cmd);\n\treq->parameter_type = cpu_to_le32(1);\n\n\tstatus = be_mbox_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\nint be_cmd_set_ext_fat_capabilites(struct be_adapter *adapter,\n\t\t\t\t   struct be_dma_mem *cmd,\n\t\t\t\t   struct be_fat_conf_params *configs)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_set_ext_fat_caps *req;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = cmd->va;\n\tmemcpy(&req->set_params, configs, sizeof(struct be_fat_conf_params));\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_EXT_FAT_CAPABILITIES,\n\t\t\t       cmd->size, wrb, cmd);\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_query_port_name(struct be_adapter *adapter)\n{\n\tstruct be_cmd_req_get_port_name *req;\n\tstruct be_mcc_wrb *wrb;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_PORT_NAME, sizeof(*req), wrb,\n\t\t\t       NULL);\n\tif (!BEx_chip(adapter))\n\t\treq->hdr.version = 1;\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_port_name *resp = embedded_payload(wrb);\n\n\t\tadapter->port_name = resp->port_name[adapter->hba_port_num];\n\t} else {\n\t\tadapter->port_name = adapter->hba_port_num + '0';\n\t}\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\n \nstatic struct be_nic_res_desc *be_get_nic_desc(u8 *buf, u32 desc_count,\n\t\t\t\t\t       bool get_vft, u8 pf_num)\n{\n\tstruct be_res_desc_hdr *hdr = (struct be_res_desc_hdr *)buf;\n\tstruct be_nic_res_desc *nic;\n\tint i;\n\n\tfor (i = 0; i < desc_count; i++) {\n\t\tif (hdr->desc_type == NIC_RESOURCE_DESC_TYPE_V0 ||\n\t\t    hdr->desc_type == NIC_RESOURCE_DESC_TYPE_V1) {\n\t\t\tnic = (struct be_nic_res_desc *)hdr;\n\n\t\t\tif ((pf_num == PF_NUM_IGNORE ||\n\t\t\t     nic->pf_num == pf_num) &&\n\t\t\t    (!get_vft || nic->flags & BIT(VFT_SHIFT)))\n\t\t\t\treturn nic;\n\t\t}\n\t\thdr->desc_len = hdr->desc_len ? : RESOURCE_DESC_SIZE_V0;\n\t\thdr = (void *)hdr + hdr->desc_len;\n\t}\n\treturn NULL;\n}\n\nstatic struct be_nic_res_desc *be_get_vft_desc(u8 *buf, u32 desc_count,\n\t\t\t\t\t       u8 pf_num)\n{\n\treturn be_get_nic_desc(buf, desc_count, true, pf_num);\n}\n\nstatic struct be_nic_res_desc *be_get_func_nic_desc(u8 *buf, u32 desc_count,\n\t\t\t\t\t\t    u8 pf_num)\n{\n\treturn be_get_nic_desc(buf, desc_count, false, pf_num);\n}\n\nstatic struct be_pcie_res_desc *be_get_pcie_desc(u8 *buf, u32 desc_count,\n\t\t\t\t\t\t u8 pf_num)\n{\n\tstruct be_res_desc_hdr *hdr = (struct be_res_desc_hdr *)buf;\n\tstruct be_pcie_res_desc *pcie;\n\tint i;\n\n\tfor (i = 0; i < desc_count; i++) {\n\t\tif (hdr->desc_type == PCIE_RESOURCE_DESC_TYPE_V0 ||\n\t\t    hdr->desc_type == PCIE_RESOURCE_DESC_TYPE_V1) {\n\t\t\tpcie = (struct be_pcie_res_desc *)hdr;\n\t\t\tif (pcie->pf_num == pf_num)\n\t\t\t\treturn pcie;\n\t\t}\n\n\t\thdr->desc_len = hdr->desc_len ? : RESOURCE_DESC_SIZE_V0;\n\t\thdr = (void *)hdr + hdr->desc_len;\n\t}\n\treturn NULL;\n}\n\nstatic struct be_port_res_desc *be_get_port_desc(u8 *buf, u32 desc_count)\n{\n\tstruct be_res_desc_hdr *hdr = (struct be_res_desc_hdr *)buf;\n\tint i;\n\n\tfor (i = 0; i < desc_count; i++) {\n\t\tif (hdr->desc_type == PORT_RESOURCE_DESC_TYPE_V1)\n\t\t\treturn (struct be_port_res_desc *)hdr;\n\n\t\thdr->desc_len = hdr->desc_len ? : RESOURCE_DESC_SIZE_V0;\n\t\thdr = (void *)hdr + hdr->desc_len;\n\t}\n\treturn NULL;\n}\n\nstatic void be_copy_nic_desc(struct be_resources *res,\n\t\t\t     struct be_nic_res_desc *desc)\n{\n\tres->max_uc_mac = le16_to_cpu(desc->unicast_mac_count);\n\tres->max_vlans = le16_to_cpu(desc->vlan_count);\n\tres->max_mcast_mac = le16_to_cpu(desc->mcast_mac_count);\n\tres->max_tx_qs = le16_to_cpu(desc->txq_count);\n\tres->max_rss_qs = le16_to_cpu(desc->rssq_count);\n\tres->max_rx_qs = le16_to_cpu(desc->rq_count);\n\tres->max_evt_qs = le16_to_cpu(desc->eq_count);\n\tres->max_cq_count = le16_to_cpu(desc->cq_count);\n\tres->max_iface_count = le16_to_cpu(desc->iface_count);\n\tres->max_mcc_count = le16_to_cpu(desc->mcc_count);\n\t \n\tres->if_cap_flags = le32_to_cpu(desc->cap_flags) &\n\t\t\t\tBE_IF_CAP_FLAGS_WANT;\n}\n\n \nint be_cmd_get_func_config(struct be_adapter *adapter, struct be_resources *res)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_func_config *req;\n\tint status;\n\tstruct be_dma_mem cmd;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\tmemset(&cmd, 0, sizeof(struct be_dma_mem));\n\tcmd.size = sizeof(struct be_cmd_resp_get_func_config);\n\tcmd.va = dma_alloc_coherent(&adapter->pdev->dev, cmd.size, &cmd.dma,\n\t\t\t\t    GFP_ATOMIC);\n\tif (!cmd.va) {\n\t\tdev_err(&adapter->pdev->dev, \"Memory alloc failure\\n\");\n\t\tstatus = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\twrb = wrb_from_mbox(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = cmd.va;\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_FUNC_CONFIG,\n\t\t\t       cmd.size, wrb, &cmd);\n\n\tif (skyhawk_chip(adapter))\n\t\treq->hdr.version = 1;\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_func_config *resp = cmd.va;\n\t\tu32 desc_count = le32_to_cpu(resp->desc_count);\n\t\tstruct be_nic_res_desc *desc;\n\n\t\t \n\t\tdesc = be_get_func_nic_desc(resp->func_param, desc_count,\n\t\t\t\t\t    PF_NUM_IGNORE);\n\t\tif (!desc) {\n\t\t\tstatus = -EINVAL;\n\t\t\tgoto err;\n\t\t}\n\n\t\t \n\t\tadapter->pf_num = desc->pf_num;\n\t\tadapter->vf_num = desc->vf_num;\n\n\t\tif (res)\n\t\t\tbe_copy_nic_desc(res, desc);\n\t}\nerr:\n\tmutex_unlock(&adapter->mbox_lock);\n\tif (cmd.va)\n\t\tdma_free_coherent(&adapter->pdev->dev, cmd.size, cmd.va,\n\t\t\t\t  cmd.dma);\n\treturn status;\n}\n\n \nstatic u16 be_get_nic_pf_num_list(u8 *buf, u32 desc_count, u16 *nic_pf_nums)\n{\n\tstruct be_res_desc_hdr *hdr = (struct be_res_desc_hdr *)buf;\n\tstruct be_pcie_res_desc *pcie = NULL;\n\tint i;\n\tu16 nic_pf_count = 0;\n\n\tfor (i = 0; i < desc_count; i++) {\n\t\tif (hdr->desc_type == PCIE_RESOURCE_DESC_TYPE_V0 ||\n\t\t    hdr->desc_type == PCIE_RESOURCE_DESC_TYPE_V1) {\n\t\t\tpcie = (struct be_pcie_res_desc *)hdr;\n\t\t\tif (pcie->pf_state && (pcie->pf_type == MISSION_NIC ||\n\t\t\t\t\t       pcie->pf_type == MISSION_RDMA)) {\n\t\t\t\tnic_pf_nums[nic_pf_count++] = pcie->pf_num;\n\t\t\t}\n\t\t}\n\n\t\thdr->desc_len = hdr->desc_len ? : RESOURCE_DESC_SIZE_V0;\n\t\thdr = (void *)hdr + hdr->desc_len;\n\t}\n\treturn nic_pf_count;\n}\n\n \nint be_cmd_get_profile_config(struct be_adapter *adapter,\n\t\t\t      struct be_resources *res,\n\t\t\t      struct be_port_resources *port_res,\n\t\t\t      u8 profile_type, u8 query, u8 domain)\n{\n\tstruct be_cmd_resp_get_profile_config *resp;\n\tstruct be_cmd_req_get_profile_config *req;\n\tstruct be_nic_res_desc *vf_res;\n\tstruct be_pcie_res_desc *pcie;\n\tstruct be_port_res_desc *port;\n\tstruct be_nic_res_desc *nic;\n\tstruct be_mcc_wrb wrb = {0};\n\tstruct be_dma_mem cmd;\n\tu16 desc_count;\n\tint status;\n\n\tmemset(&cmd, 0, sizeof(struct be_dma_mem));\n\tcmd.size = sizeof(struct be_cmd_resp_get_profile_config);\n\tcmd.va = dma_alloc_coherent(&adapter->pdev->dev, cmd.size, &cmd.dma,\n\t\t\t\t    GFP_ATOMIC);\n\tif (!cmd.va)\n\t\treturn -ENOMEM;\n\n\treq = cmd.va;\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_PROFILE_CONFIG,\n\t\t\t       cmd.size, &wrb, &cmd);\n\n\tif (!lancer_chip(adapter))\n\t\treq->hdr.version = 1;\n\treq->type = profile_type;\n\treq->hdr.domain = domain;\n\n\t \n\tif (query == RESOURCE_MODIFIABLE)\n\t\treq->type |= QUERY_MODIFIABLE_FIELDS_TYPE;\n\n\tstatus = be_cmd_notify_wait(adapter, &wrb);\n\tif (status)\n\t\tgoto err;\n\n\tresp = cmd.va;\n\tdesc_count = le16_to_cpu(resp->desc_count);\n\n\tif (port_res) {\n\t\tu16 nic_pf_cnt = 0, i;\n\t\tu16 nic_pf_num_list[MAX_NIC_FUNCS];\n\n\t\tnic_pf_cnt = be_get_nic_pf_num_list(resp->func_param,\n\t\t\t\t\t\t    desc_count,\n\t\t\t\t\t\t    nic_pf_num_list);\n\n\t\tfor (i = 0; i < nic_pf_cnt; i++) {\n\t\t\tnic = be_get_func_nic_desc(resp->func_param, desc_count,\n\t\t\t\t\t\t   nic_pf_num_list[i]);\n\t\t\tif (nic->link_param == adapter->port_num) {\n\t\t\t\tport_res->nic_pfs++;\n\t\t\t\tpcie = be_get_pcie_desc(resp->func_param,\n\t\t\t\t\t\t\tdesc_count,\n\t\t\t\t\t\t\tnic_pf_num_list[i]);\n\t\t\t\tport_res->max_vfs += le16_to_cpu(pcie->num_vfs);\n\t\t\t}\n\t\t}\n\t\tgoto err;\n\t}\n\n\tpcie = be_get_pcie_desc(resp->func_param, desc_count,\n\t\t\t\tadapter->pf_num);\n\tif (pcie)\n\t\tres->max_vfs = le16_to_cpu(pcie->num_vfs);\n\n\tport = be_get_port_desc(resp->func_param, desc_count);\n\tif (port)\n\t\tadapter->mc_type = port->mc_type;\n\n\tnic = be_get_func_nic_desc(resp->func_param, desc_count,\n\t\t\t\t   adapter->pf_num);\n\tif (nic)\n\t\tbe_copy_nic_desc(res, nic);\n\n\tvf_res = be_get_vft_desc(resp->func_param, desc_count,\n\t\t\t\t adapter->pf_num);\n\tif (vf_res)\n\t\tres->vf_if_cap_flags = vf_res->cap_flags;\nerr:\n\tif (cmd.va)\n\t\tdma_free_coherent(&adapter->pdev->dev, cmd.size, cmd.va,\n\t\t\t\t  cmd.dma);\n\treturn status;\n}\n\n \nstatic int be_cmd_set_profile_config(struct be_adapter *adapter, void *desc,\n\t\t\t\t     int size, int count, u8 version, u8 domain)\n{\n\tstruct be_cmd_req_set_profile_config *req;\n\tstruct be_mcc_wrb wrb = {0};\n\tstruct be_dma_mem cmd;\n\tint status;\n\n\tmemset(&cmd, 0, sizeof(struct be_dma_mem));\n\tcmd.size = sizeof(struct be_cmd_req_set_profile_config);\n\tcmd.va = dma_alloc_coherent(&adapter->pdev->dev, cmd.size, &cmd.dma,\n\t\t\t\t    GFP_ATOMIC);\n\tif (!cmd.va)\n\t\treturn -ENOMEM;\n\n\treq = cmd.va;\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_PROFILE_CONFIG, cmd.size,\n\t\t\t       &wrb, &cmd);\n\treq->hdr.version = version;\n\treq->hdr.domain = domain;\n\treq->desc_count = cpu_to_le32(count);\n\tmemcpy(req->desc, desc, size);\n\n\tstatus = be_cmd_notify_wait(adapter, &wrb);\n\n\tif (cmd.va)\n\t\tdma_free_coherent(&adapter->pdev->dev, cmd.size, cmd.va,\n\t\t\t\t  cmd.dma);\n\treturn status;\n}\n\n \nstatic void be_reset_nic_desc(struct be_nic_res_desc *nic)\n{\n\tmemset(nic, 0, sizeof(*nic));\n\tnic->unicast_mac_count = 0xFFFF;\n\tnic->mcc_count = 0xFFFF;\n\tnic->vlan_count = 0xFFFF;\n\tnic->mcast_mac_count = 0xFFFF;\n\tnic->txq_count = 0xFFFF;\n\tnic->rq_count = 0xFFFF;\n\tnic->rssq_count = 0xFFFF;\n\tnic->lro_count = 0xFFFF;\n\tnic->cq_count = 0xFFFF;\n\tnic->toe_conn_count = 0xFFFF;\n\tnic->eq_count = 0xFFFF;\n\tnic->iface_count = 0xFFFF;\n\tnic->link_param = 0xFF;\n\tnic->channel_id_param = cpu_to_le16(0xF000);\n\tnic->acpi_params = 0xFF;\n\tnic->wol_param = 0x0F;\n\tnic->tunnel_iface_count = 0xFFFF;\n\tnic->direct_tenant_iface_count = 0xFFFF;\n\tnic->bw_min = 0xFFFFFFFF;\n\tnic->bw_max = 0xFFFFFFFF;\n}\n\n \nstatic void be_reset_pcie_desc(struct be_pcie_res_desc *pcie)\n{\n\tmemset(pcie, 0, sizeof(*pcie));\n\tpcie->sriov_state = 0xFF;\n\tpcie->pf_state = 0xFF;\n\tpcie->pf_type = 0xFF;\n\tpcie->num_vfs = 0xFFFF;\n}\n\nint be_cmd_config_qos(struct be_adapter *adapter, u32 max_rate, u16 link_speed,\n\t\t      u8 domain)\n{\n\tstruct be_nic_res_desc nic_desc;\n\tu32 bw_percent;\n\tu16 version = 0;\n\n\tif (BE3_chip(adapter))\n\t\treturn be_cmd_set_qos(adapter, max_rate / 10, domain);\n\n\tbe_reset_nic_desc(&nic_desc);\n\tnic_desc.pf_num = adapter->pf_num;\n\tnic_desc.vf_num = domain;\n\tnic_desc.bw_min = 0;\n\tif (lancer_chip(adapter)) {\n\t\tnic_desc.hdr.desc_type = NIC_RESOURCE_DESC_TYPE_V0;\n\t\tnic_desc.hdr.desc_len = RESOURCE_DESC_SIZE_V0;\n\t\tnic_desc.flags = (1 << QUN_SHIFT) | (1 << IMM_SHIFT) |\n\t\t\t\t\t(1 << NOSV_SHIFT);\n\t\tnic_desc.bw_max = cpu_to_le32(max_rate / 10);\n\t} else {\n\t\tversion = 1;\n\t\tnic_desc.hdr.desc_type = NIC_RESOURCE_DESC_TYPE_V1;\n\t\tnic_desc.hdr.desc_len = RESOURCE_DESC_SIZE_V1;\n\t\tnic_desc.flags = (1 << IMM_SHIFT) | (1 << NOSV_SHIFT);\n\t\tbw_percent = max_rate ? (max_rate * 100) / link_speed : 100;\n\t\tnic_desc.bw_max = cpu_to_le32(bw_percent);\n\t}\n\n\treturn be_cmd_set_profile_config(adapter, &nic_desc,\n\t\t\t\t\t nic_desc.hdr.desc_len,\n\t\t\t\t\t 1, version, domain);\n}\n\nint be_cmd_set_sriov_config(struct be_adapter *adapter,\n\t\t\t    struct be_resources pool_res, u16 num_vfs,\n\t\t\t    struct be_resources *vft_res)\n{\n\tstruct {\n\t\tstruct be_pcie_res_desc pcie;\n\t\tstruct be_nic_res_desc nic_vft;\n\t} __packed desc;\n\n\t \n\tbe_reset_pcie_desc(&desc.pcie);\n\tdesc.pcie.hdr.desc_type = PCIE_RESOURCE_DESC_TYPE_V1;\n\tdesc.pcie.hdr.desc_len = RESOURCE_DESC_SIZE_V1;\n\tdesc.pcie.flags = BIT(IMM_SHIFT) | BIT(NOSV_SHIFT);\n\tdesc.pcie.pf_num = adapter->pdev->devfn;\n\tdesc.pcie.sriov_state = num_vfs ? 1 : 0;\n\tdesc.pcie.num_vfs = cpu_to_le16(num_vfs);\n\n\t \n\tbe_reset_nic_desc(&desc.nic_vft);\n\tdesc.nic_vft.hdr.desc_type = NIC_RESOURCE_DESC_TYPE_V1;\n\tdesc.nic_vft.hdr.desc_len = RESOURCE_DESC_SIZE_V1;\n\tdesc.nic_vft.flags = vft_res->flags | BIT(VFT_SHIFT) |\n\t\t\t     BIT(IMM_SHIFT) | BIT(NOSV_SHIFT);\n\tdesc.nic_vft.pf_num = adapter->pdev->devfn;\n\tdesc.nic_vft.vf_num = 0;\n\tdesc.nic_vft.cap_flags = cpu_to_le32(vft_res->vf_if_cap_flags);\n\tdesc.nic_vft.rq_count = cpu_to_le16(vft_res->max_rx_qs);\n\tdesc.nic_vft.txq_count = cpu_to_le16(vft_res->max_tx_qs);\n\tdesc.nic_vft.rssq_count = cpu_to_le16(vft_res->max_rss_qs);\n\tdesc.nic_vft.cq_count = cpu_to_le16(vft_res->max_cq_count);\n\n\tif (vft_res->max_uc_mac)\n\t\tdesc.nic_vft.unicast_mac_count =\n\t\t\t\t\tcpu_to_le16(vft_res->max_uc_mac);\n\tif (vft_res->max_vlans)\n\t\tdesc.nic_vft.vlan_count = cpu_to_le16(vft_res->max_vlans);\n\tif (vft_res->max_iface_count)\n\t\tdesc.nic_vft.iface_count =\n\t\t\t\tcpu_to_le16(vft_res->max_iface_count);\n\tif (vft_res->max_mcc_count)\n\t\tdesc.nic_vft.mcc_count = cpu_to_le16(vft_res->max_mcc_count);\n\n\treturn be_cmd_set_profile_config(adapter, &desc,\n\t\t\t\t\t 2 * RESOURCE_DESC_SIZE_V1, 2, 1, 0);\n}\n\nint be_cmd_manage_iface(struct be_adapter *adapter, u32 iface, u8 op)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_manage_iface_filters *req;\n\tint status;\n\n\tif (iface == 0xFFFFFFFF)\n\t\treturn -1;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_MANAGE_IFACE_FILTERS, sizeof(*req),\n\t\t\t       wrb, NULL);\n\treq->op = op;\n\treq->target_iface_id = cpu_to_le32(iface);\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_set_vxlan_port(struct be_adapter *adapter, __be16 port)\n{\n\tstruct be_port_res_desc port_desc;\n\n\tmemset(&port_desc, 0, sizeof(port_desc));\n\tport_desc.hdr.desc_type = PORT_RESOURCE_DESC_TYPE_V1;\n\tport_desc.hdr.desc_len = RESOURCE_DESC_SIZE_V1;\n\tport_desc.flags = (1 << IMM_SHIFT) | (1 << NOSV_SHIFT);\n\tport_desc.link_num = adapter->hba_port_num;\n\tif (port) {\n\t\tport_desc.nv_flags = NV_TYPE_VXLAN | (1 << SOCVID_SHIFT) |\n\t\t\t\t\t(1 << RCVID_SHIFT);\n\t\tport_desc.nv_port = swab16(port);\n\t} else {\n\t\tport_desc.nv_flags = NV_TYPE_DISABLED;\n\t\tport_desc.nv_port = 0;\n\t}\n\n\treturn be_cmd_set_profile_config(adapter, &port_desc,\n\t\t\t\t\t RESOURCE_DESC_SIZE_V1, 1, 1, 0);\n}\n\nint be_cmd_get_if_id(struct be_adapter *adapter, struct be_vf_cfg *vf_cfg,\n\t\t     int vf_num)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_get_iface_list *req;\n\tstruct be_cmd_resp_get_iface_list *resp;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_IFACE_LIST, sizeof(*resp),\n\t\t\t       wrb, NULL);\n\treq->hdr.domain = vf_num + 1;\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (!status) {\n\t\tresp = (struct be_cmd_resp_get_iface_list *)req;\n\t\tvf_cfg->if_handle = le32_to_cpu(resp->if_desc.if_id);\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nstatic int lancer_wait_idle(struct be_adapter *adapter)\n{\n#define SLIPORT_IDLE_TIMEOUT 30\n\tu32 reg_val;\n\tint status = 0, i;\n\n\tfor (i = 0; i < SLIPORT_IDLE_TIMEOUT; i++) {\n\t\treg_val = ioread32(adapter->db + PHYSDEV_CONTROL_OFFSET);\n\t\tif ((reg_val & PHYSDEV_CONTROL_INP_MASK) == 0)\n\t\t\tbreak;\n\n\t\tssleep(1);\n\t}\n\n\tif (i == SLIPORT_IDLE_TIMEOUT)\n\t\tstatus = -1;\n\n\treturn status;\n}\n\nint lancer_physdev_ctrl(struct be_adapter *adapter, u32 mask)\n{\n\tint status = 0;\n\n\tstatus = lancer_wait_idle(adapter);\n\tif (status)\n\t\treturn status;\n\n\tiowrite32(mask, adapter->db + PHYSDEV_CONTROL_OFFSET);\n\n\treturn status;\n}\n\n \nbool dump_present(struct be_adapter *adapter)\n{\n\tu32 sliport_status = 0;\n\n\tsliport_status = ioread32(adapter->db + SLIPORT_STATUS_OFFSET);\n\treturn !!(sliport_status & SLIPORT_STATUS_DIP_MASK);\n}\n\nint lancer_initiate_dump(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tint status;\n\n\tif (dump_present(adapter)) {\n\t\tdev_info(dev, \"Previous dump not cleared, not forcing dump\\n\");\n\t\treturn -EEXIST;\n\t}\n\n\t \n\tstatus = lancer_physdev_ctrl(adapter, PHYSDEV_CONTROL_FW_RESET_MASK |\n\t\t\t\t     PHYSDEV_CONTROL_DD_MASK);\n\tif (status < 0) {\n\t\tdev_err(dev, \"FW reset failed\\n\");\n\t\treturn status;\n\t}\n\n\tstatus = lancer_wait_idle(adapter);\n\tif (status)\n\t\treturn status;\n\n\tif (!dump_present(adapter)) {\n\t\tdev_err(dev, \"FW dump not generated\\n\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nint lancer_delete_dump(struct be_adapter *adapter)\n{\n\tint status;\n\n\tstatus = lancer_cmd_delete_object(adapter, LANCER_FW_DUMP_FILE);\n\treturn be_cmd_status(status);\n}\n\n \nint be_cmd_enable_vf(struct be_adapter *adapter, u8 domain)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_enable_disable_vf *req;\n\tint status;\n\n\tif (BEx_chip(adapter))\n\t\treturn 0;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_ENABLE_DISABLE_VF, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->hdr.domain = domain;\n\treq->enable = 1;\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_intr_set(struct be_adapter *adapter, bool intr_enable)\n{\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_intr_set *req;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_INTERRUPT_ENABLE, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\treq->intr_enabled = intr_enable;\n\n\tstatus = be_mbox_notify_wait(adapter);\n\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\n \nint be_cmd_get_active_profile(struct be_adapter *adapter, u16 *profile_id)\n{\n\tstruct be_cmd_req_get_active_profile *req;\n\tstruct be_mcc_wrb *wrb;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mbox_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mbox(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_GET_ACTIVE_PROFILE, sizeof(*req),\n\t\t\t       wrb, NULL);\n\n\tstatus = be_mbox_notify_wait(adapter);\n\tif (!status) {\n\t\tstruct be_cmd_resp_get_active_profile *resp =\n\t\t\t\t\t\t\tembedded_payload(wrb);\n\n\t\t*profile_id = le16_to_cpu(resp->active_profile_id);\n\t}\n\nerr:\n\tmutex_unlock(&adapter->mbox_lock);\n\treturn status;\n}\n\nstatic int\n__be_cmd_set_logical_link_config(struct be_adapter *adapter,\n\t\t\t\t int link_state, int version, u8 domain)\n{\n\tstruct be_cmd_req_set_ll_link *req;\n\tstruct be_mcc_wrb *wrb;\n\tu32 link_config = 0;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_LOGICAL_LINK_CONFIG,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\treq->hdr.version = version;\n\treq->hdr.domain = domain;\n\n\tif (link_state == IFLA_VF_LINK_STATE_ENABLE ||\n\t    link_state == IFLA_VF_LINK_STATE_AUTO)\n\t\tlink_config |= PLINK_ENABLE;\n\n\tif (link_state == IFLA_VF_LINK_STATE_AUTO)\n\t\tlink_config |= PLINK_TRACK;\n\n\treq->link_config = cpu_to_le32(link_config);\n\n\tstatus = be_mcc_notify_wait(adapter);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_cmd_set_logical_link_config(struct be_adapter *adapter,\n\t\t\t\t   int link_state, u8 domain)\n{\n\tint status;\n\n\tif (BE2_chip(adapter))\n\t\treturn -EOPNOTSUPP;\n\n\tstatus = __be_cmd_set_logical_link_config(adapter, link_state,\n\t\t\t\t\t\t  2, domain);\n\n\t \n\tif (base_status(status) == MCC_STATUS_ILLEGAL_REQUEST)\n\t\tstatus = __be_cmd_set_logical_link_config(adapter, link_state,\n\t\t\t\t\t\t\t  1, domain);\n\treturn status;\n}\n\nint be_cmd_set_features(struct be_adapter *adapter)\n{\n\tstruct be_cmd_resp_set_features *resp;\n\tstruct be_cmd_req_set_features *req;\n\tstruct be_mcc_wrb *wrb;\n\tint status;\n\n\tif (mutex_lock_interruptible(&adapter->mcc_lock))\n\t\treturn -1;\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\n\treq = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,\n\t\t\t       OPCODE_COMMON_SET_FEATURES,\n\t\t\t       sizeof(*req), wrb, NULL);\n\n\treq->features = cpu_to_le32(BE_FEATURE_UE_RECOVERY);\n\treq->parameter_len = cpu_to_le32(sizeof(struct be_req_ue_recovery));\n\treq->parameter.req.uer = cpu_to_le32(BE_UE_RECOVERY_UER_MASK);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tresp = embedded_payload(wrb);\n\n\tadapter->error_recovery.ue_to_poll_time =\n\t\tle16_to_cpu(resp->parameter.resp.ue2rp);\n\tadapter->error_recovery.ue_to_reset_time =\n\t\tle16_to_cpu(resp->parameter.resp.ue2sr);\n\tadapter->error_recovery.recovery_supported = true;\nerr:\n\t \n\tif (base_status(status) == MCC_STATUS_ILLEGAL_REQUEST ||\n\t    base_status(status) == MCC_STATUS_INVALID_LENGTH)\n\t\tdev_info(&adapter->pdev->dev,\n\t\t\t \"Adapter does not support HW error recovery\\n\");\n\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\n\nint be_roce_mcc_cmd(void *netdev_handle, void *wrb_payload,\n\t\t    int wrb_payload_size, u16 *cmd_status, u16 *ext_status)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev_handle);\n\tstruct be_mcc_wrb *wrb;\n\tstruct be_cmd_req_hdr *hdr = (struct be_cmd_req_hdr *)wrb_payload;\n\tstruct be_cmd_req_hdr *req;\n\tstruct be_cmd_resp_hdr *resp;\n\tint status;\n\n\tmutex_lock(&adapter->mcc_lock);\n\n\twrb = wrb_from_mccq(adapter);\n\tif (!wrb) {\n\t\tstatus = -EBUSY;\n\t\tgoto err;\n\t}\n\treq = embedded_payload(wrb);\n\tresp = embedded_payload(wrb);\n\n\tbe_wrb_cmd_hdr_prepare(req, hdr->subsystem,\n\t\t\t       hdr->opcode, wrb_payload_size, wrb, NULL);\n\tmemcpy(req, wrb_payload, wrb_payload_size);\n\tbe_dws_cpu_to_le(req, wrb_payload_size);\n\n\tstatus = be_mcc_notify_wait(adapter);\n\tif (cmd_status)\n\t\t*cmd_status = (status & 0xffff);\n\tif (ext_status)\n\t\t*ext_status = 0;\n\tmemcpy(wrb_payload, resp, sizeof(*resp) + resp->response_length);\n\tbe_dws_le_to_cpu(wrb_payload, sizeof(*resp) + resp->response_length);\nerr:\n\tmutex_unlock(&adapter->mcc_lock);\n\treturn status;\n}\nEXPORT_SYMBOL(be_roce_mcc_cmd);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}