{
  "module_name": "be_main.c",
  "hash_id": "b4e0ac8c27ee9b3a4e1793d88583fe9128add4dc03f45d38c964a4544cbe5377",
  "original_prompt": "Ingested from linux-6.6.14/drivers/net/ethernet/emulex/benet/be_main.c",
  "human_readable_source": "\n \n\n#include <linux/prefetch.h>\n#include <linux/module.h>\n#include \"be.h\"\n#include \"be_cmds.h\"\n#include <asm/div64.h>\n#include <linux/if_bridge.h>\n#include <net/busy_poll.h>\n#include <net/vxlan.h>\n\nMODULE_DESCRIPTION(DRV_DESC);\nMODULE_AUTHOR(\"Emulex Corporation\");\nMODULE_LICENSE(\"GPL\");\n\n \nstatic unsigned int num_vfs;\nmodule_param(num_vfs, uint, 0444);\nMODULE_PARM_DESC(num_vfs, \"Number of PCI VFs to initialize\");\n\nstatic ushort rx_frag_size = 2048;\nmodule_param(rx_frag_size, ushort, 0444);\nMODULE_PARM_DESC(rx_frag_size, \"Size of a fragment that holds rcvd data.\");\n\n \nstatic struct workqueue_struct *be_err_recovery_workq;\n\nstatic const struct pci_device_id be_dev_ids[] = {\n#ifdef CONFIG_BE2NET_BE2\n\t{ PCI_DEVICE(BE_VENDOR_ID, BE_DEVICE_ID1) },\n\t{ PCI_DEVICE(BE_VENDOR_ID, OC_DEVICE_ID1) },\n#endif  \n#ifdef CONFIG_BE2NET_BE3\n\t{ PCI_DEVICE(BE_VENDOR_ID, BE_DEVICE_ID2) },\n\t{ PCI_DEVICE(BE_VENDOR_ID, OC_DEVICE_ID2) },\n#endif  \n#ifdef CONFIG_BE2NET_LANCER\n\t{ PCI_DEVICE(EMULEX_VENDOR_ID, OC_DEVICE_ID3)},\n\t{ PCI_DEVICE(EMULEX_VENDOR_ID, OC_DEVICE_ID4)},\n#endif  \n#ifdef CONFIG_BE2NET_SKYHAWK\n\t{ PCI_DEVICE(EMULEX_VENDOR_ID, OC_DEVICE_ID5)},\n\t{ PCI_DEVICE(EMULEX_VENDOR_ID, OC_DEVICE_ID6)},\n#endif  \n\t{ 0 }\n};\nMODULE_DEVICE_TABLE(pci, be_dev_ids);\n\n \nstatic struct workqueue_struct *be_wq;\n\n \nstatic const char * const ue_status_low_desc[] = {\n\t\"CEV\",\n\t\"CTX\",\n\t\"DBUF\",\n\t\"ERX\",\n\t\"Host\",\n\t\"MPU\",\n\t\"NDMA\",\n\t\"PTC \",\n\t\"RDMA \",\n\t\"RXF \",\n\t\"RXIPS \",\n\t\"RXULP0 \",\n\t\"RXULP1 \",\n\t\"RXULP2 \",\n\t\"TIM \",\n\t\"TPOST \",\n\t\"TPRE \",\n\t\"TXIPS \",\n\t\"TXULP0 \",\n\t\"TXULP1 \",\n\t\"UC \",\n\t\"WDMA \",\n\t\"TXULP2 \",\n\t\"HOST1 \",\n\t\"P0_OB_LINK \",\n\t\"P1_OB_LINK \",\n\t\"HOST_GPIO \",\n\t\"MBOX \",\n\t\"ERX2 \",\n\t\"SPARE \",\n\t\"JTAG \",\n\t\"MPU_INTPEND \"\n};\n\n \nstatic const char * const ue_status_hi_desc[] = {\n\t\"LPCMEMHOST\",\n\t\"MGMT_MAC\",\n\t\"PCS0ONLINE\",\n\t\"MPU_IRAM\",\n\t\"PCS1ONLINE\",\n\t\"PCTL0\",\n\t\"PCTL1\",\n\t\"PMEM\",\n\t\"RR\",\n\t\"TXPB\",\n\t\"RXPP\",\n\t\"XAUI\",\n\t\"TXP\",\n\t\"ARM\",\n\t\"IPC\",\n\t\"HOST2\",\n\t\"HOST3\",\n\t\"HOST4\",\n\t\"HOST5\",\n\t\"HOST6\",\n\t\"HOST7\",\n\t\"ECRC\",\n\t\"Poison TLP\",\n\t\"NETC\",\n\t\"PERIPH\",\n\t\"LLTXULP\",\n\t\"D2P\",\n\t\"RCON\",\n\t\"LDMA\",\n\t\"LLTXP\",\n\t\"LLTXPB\",\n\t\"Unknown\"\n};\n\n#define BE_VF_IF_EN_FLAGS\t(BE_IF_FLAGS_UNTAGGED | \\\n\t\t\t\t BE_IF_FLAGS_BROADCAST | \\\n\t\t\t\t BE_IF_FLAGS_MULTICAST | \\\n\t\t\t\t BE_IF_FLAGS_PASS_L3L4_ERRORS)\n\nstatic void be_queue_free(struct be_adapter *adapter, struct be_queue_info *q)\n{\n\tstruct be_dma_mem *mem = &q->dma_mem;\n\n\tif (mem->va) {\n\t\tdma_free_coherent(&adapter->pdev->dev, mem->size, mem->va,\n\t\t\t\t  mem->dma);\n\t\tmem->va = NULL;\n\t}\n}\n\nstatic int be_queue_alloc(struct be_adapter *adapter, struct be_queue_info *q,\n\t\t\t  u16 len, u16 entry_size)\n{\n\tstruct be_dma_mem *mem = &q->dma_mem;\n\n\tmemset(q, 0, sizeof(*q));\n\tq->len = len;\n\tq->entry_size = entry_size;\n\tmem->size = len * entry_size;\n\tmem->va = dma_alloc_coherent(&adapter->pdev->dev, mem->size,\n\t\t\t\t     &mem->dma, GFP_KERNEL);\n\tif (!mem->va)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void be_reg_intr_set(struct be_adapter *adapter, bool enable)\n{\n\tu32 reg, enabled;\n\n\tpci_read_config_dword(adapter->pdev, PCICFG_MEMBAR_CTRL_INT_CTRL_OFFSET,\n\t\t\t      &reg);\n\tenabled = reg & MEMBAR_CTRL_INT_CTRL_HOSTINTR_MASK;\n\n\tif (!enabled && enable)\n\t\treg |= MEMBAR_CTRL_INT_CTRL_HOSTINTR_MASK;\n\telse if (enabled && !enable)\n\t\treg &= ~MEMBAR_CTRL_INT_CTRL_HOSTINTR_MASK;\n\telse\n\t\treturn;\n\n\tpci_write_config_dword(adapter->pdev,\n\t\t\t       PCICFG_MEMBAR_CTRL_INT_CTRL_OFFSET, reg);\n}\n\nstatic void be_intr_set(struct be_adapter *adapter, bool enable)\n{\n\tint status = 0;\n\n\t \n\tif (lancer_chip(adapter))\n\t\treturn;\n\n\tif (be_check_error(adapter, BE_ERROR_EEH))\n\t\treturn;\n\n\tstatus = be_cmd_intr_set(adapter, enable);\n\tif (status)\n\t\tbe_reg_intr_set(adapter, enable);\n}\n\nstatic void be_rxq_notify(struct be_adapter *adapter, u16 qid, u16 posted)\n{\n\tu32 val = 0;\n\n\tif (be_check_error(adapter, BE_ERROR_HW))\n\t\treturn;\n\n\tval |= qid & DB_RQ_RING_ID_MASK;\n\tval |= posted << DB_RQ_NUM_POSTED_SHIFT;\n\n\twmb();\n\tiowrite32(val, adapter->db + DB_RQ_OFFSET);\n}\n\nstatic void be_txq_notify(struct be_adapter *adapter, struct be_tx_obj *txo,\n\t\t\t  u16 posted)\n{\n\tu32 val = 0;\n\n\tif (be_check_error(adapter, BE_ERROR_HW))\n\t\treturn;\n\n\tval |= txo->q.id & DB_TXULP_RING_ID_MASK;\n\tval |= (posted & DB_TXULP_NUM_POSTED_MASK) << DB_TXULP_NUM_POSTED_SHIFT;\n\n\twmb();\n\tiowrite32(val, adapter->db + txo->db_offset);\n}\n\nstatic void be_eq_notify(struct be_adapter *adapter, u16 qid,\n\t\t\t bool arm, bool clear_int, u16 num_popped,\n\t\t\t u32 eq_delay_mult_enc)\n{\n\tu32 val = 0;\n\n\tval |= qid & DB_EQ_RING_ID_MASK;\n\tval |= ((qid & DB_EQ_RING_ID_EXT_MASK) << DB_EQ_RING_ID_EXT_MASK_SHIFT);\n\n\tif (be_check_error(adapter, BE_ERROR_HW))\n\t\treturn;\n\n\tif (arm)\n\t\tval |= 1 << DB_EQ_REARM_SHIFT;\n\tif (clear_int)\n\t\tval |= 1 << DB_EQ_CLR_SHIFT;\n\tval |= 1 << DB_EQ_EVNT_SHIFT;\n\tval |= num_popped << DB_EQ_NUM_POPPED_SHIFT;\n\tval |= eq_delay_mult_enc << DB_EQ_R2I_DLY_SHIFT;\n\tiowrite32(val, adapter->db + DB_EQ_OFFSET);\n}\n\nvoid be_cq_notify(struct be_adapter *adapter, u16 qid, bool arm, u16 num_popped)\n{\n\tu32 val = 0;\n\n\tval |= qid & DB_CQ_RING_ID_MASK;\n\tval |= ((qid & DB_CQ_RING_ID_EXT_MASK) <<\n\t\t\tDB_CQ_RING_ID_EXT_MASK_SHIFT);\n\n\tif (be_check_error(adapter, BE_ERROR_HW))\n\t\treturn;\n\n\tif (arm)\n\t\tval |= 1 << DB_CQ_REARM_SHIFT;\n\tval |= num_popped << DB_CQ_NUM_POPPED_SHIFT;\n\tiowrite32(val, adapter->db + DB_CQ_OFFSET);\n}\n\nstatic int be_dev_mac_add(struct be_adapter *adapter, const u8 *mac)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < adapter->uc_macs; i++) {\n\t\tif (ether_addr_equal(adapter->uc_list[i].mac, mac)) {\n\t\t\t \n\t\t\tadapter->pmac_id[0] = adapter->pmac_id[i + 1];\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\treturn be_cmd_pmac_add(adapter, mac, adapter->if_handle,\n\t\t\t       &adapter->pmac_id[0], 0);\n}\n\nstatic void be_dev_mac_del(struct be_adapter *adapter, int pmac_id)\n{\n\tint i;\n\n\t \n\tfor (i = 0; i < adapter->uc_macs; i++) {\n\t\tif (adapter->pmac_id[i + 1] == pmac_id)\n\t\t\treturn;\n\t}\n\tbe_cmd_pmac_del(adapter, adapter->if_handle, pmac_id, 0);\n}\n\nstatic int be_mac_addr_set(struct net_device *netdev, void *p)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct sockaddr *addr = p;\n\tint status;\n\tu8 mac[ETH_ALEN];\n\tu32 old_pmac_id = adapter->pmac_id[0];\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\t \n\tif (ether_addr_equal(addr->sa_data, adapter->dev_mac))\n\t\treturn 0;\n\n\t \n\tif (BEx_chip(adapter) && be_virtfn(adapter) &&\n\t    !check_privilege(adapter, BE_PRIV_FILTMGMT))\n\t\treturn -EPERM;\n\n\t \n\tif (!netif_running(netdev))\n\t\tgoto done;\n\n\t \n\tmutex_lock(&adapter->rx_filter_lock);\n\tstatus = be_dev_mac_add(adapter, (u8 *)addr->sa_data);\n\tif (!status) {\n\n\t\t \n\t\tif (adapter->pmac_id[0] != old_pmac_id)\n\t\t\tbe_dev_mac_del(adapter, old_pmac_id);\n\t}\n\n\tmutex_unlock(&adapter->rx_filter_lock);\n\t \n\tstatus = be_cmd_get_active_mac(adapter, adapter->pmac_id[0], mac,\n\t\t\t\t       adapter->if_handle, true, 0);\n\tif (status)\n\t\tgoto err;\n\n\t \n\tif (!ether_addr_equal(addr->sa_data, mac)) {\n\t\tstatus = -EPERM;\n\t\tgoto err;\n\t}\n\n\t \n\tether_addr_copy(adapter->dev_mac, addr->sa_data);\ndone:\n\teth_hw_addr_set(netdev, addr->sa_data);\n\tdev_info(dev, \"MAC address changed to %pM\\n\", addr->sa_data);\n\treturn 0;\nerr:\n\tdev_warn(dev, \"MAC address change to %pM failed\\n\", addr->sa_data);\n\treturn status;\n}\n\n \nstatic void *hw_stats_from_cmd(struct be_adapter *adapter)\n{\n\tif (BE2_chip(adapter)) {\n\t\tstruct be_cmd_resp_get_stats_v0 *cmd = adapter->stats_cmd.va;\n\n\t\treturn &cmd->hw_stats;\n\t} else if (BE3_chip(adapter)) {\n\t\tstruct be_cmd_resp_get_stats_v1 *cmd = adapter->stats_cmd.va;\n\n\t\treturn &cmd->hw_stats;\n\t} else {\n\t\tstruct be_cmd_resp_get_stats_v2 *cmd = adapter->stats_cmd.va;\n\n\t\treturn &cmd->hw_stats;\n\t}\n}\n\n \nstatic void *be_erx_stats_from_cmd(struct be_adapter *adapter)\n{\n\tif (BE2_chip(adapter)) {\n\t\tstruct be_hw_stats_v0 *hw_stats = hw_stats_from_cmd(adapter);\n\n\t\treturn &hw_stats->erx;\n\t} else if (BE3_chip(adapter)) {\n\t\tstruct be_hw_stats_v1 *hw_stats = hw_stats_from_cmd(adapter);\n\n\t\treturn &hw_stats->erx;\n\t} else {\n\t\tstruct be_hw_stats_v2 *hw_stats = hw_stats_from_cmd(adapter);\n\n\t\treturn &hw_stats->erx;\n\t}\n}\n\nstatic void populate_be_v0_stats(struct be_adapter *adapter)\n{\n\tstruct be_hw_stats_v0 *hw_stats = hw_stats_from_cmd(adapter);\n\tstruct be_pmem_stats *pmem_sts = &hw_stats->pmem;\n\tstruct be_rxf_stats_v0 *rxf_stats = &hw_stats->rxf;\n\tstruct be_port_rxf_stats_v0 *port_stats =\n\t\t\t\t\t&rxf_stats->port[adapter->port_num];\n\tstruct be_drv_stats *drvs = &adapter->drv_stats;\n\n\tbe_dws_le_to_cpu(hw_stats, sizeof(*hw_stats));\n\tdrvs->rx_pause_frames = port_stats->rx_pause_frames;\n\tdrvs->rx_crc_errors = port_stats->rx_crc_errors;\n\tdrvs->rx_control_frames = port_stats->rx_control_frames;\n\tdrvs->rx_in_range_errors = port_stats->rx_in_range_errors;\n\tdrvs->rx_frame_too_long = port_stats->rx_frame_too_long;\n\tdrvs->rx_dropped_runt = port_stats->rx_dropped_runt;\n\tdrvs->rx_ip_checksum_errs = port_stats->rx_ip_checksum_errs;\n\tdrvs->rx_tcp_checksum_errs = port_stats->rx_tcp_checksum_errs;\n\tdrvs->rx_udp_checksum_errs = port_stats->rx_udp_checksum_errs;\n\tdrvs->rxpp_fifo_overflow_drop = port_stats->rx_fifo_overflow;\n\tdrvs->rx_dropped_tcp_length = port_stats->rx_dropped_tcp_length;\n\tdrvs->rx_dropped_too_small = port_stats->rx_dropped_too_small;\n\tdrvs->rx_dropped_too_short = port_stats->rx_dropped_too_short;\n\tdrvs->rx_out_range_errors = port_stats->rx_out_range_errors;\n\tdrvs->rx_input_fifo_overflow_drop = port_stats->rx_input_fifo_overflow;\n\tdrvs->rx_dropped_header_too_small =\n\t\tport_stats->rx_dropped_header_too_small;\n\tdrvs->rx_address_filtered =\n\t\t\t\t\tport_stats->rx_address_filtered +\n\t\t\t\t\tport_stats->rx_vlan_filtered;\n\tdrvs->rx_alignment_symbol_errors =\n\t\tport_stats->rx_alignment_symbol_errors;\n\n\tdrvs->tx_pauseframes = port_stats->tx_pauseframes;\n\tdrvs->tx_controlframes = port_stats->tx_controlframes;\n\n\tif (adapter->port_num)\n\t\tdrvs->jabber_events = rxf_stats->port1_jabber_events;\n\telse\n\t\tdrvs->jabber_events = rxf_stats->port0_jabber_events;\n\tdrvs->rx_drops_no_pbuf = rxf_stats->rx_drops_no_pbuf;\n\tdrvs->rx_drops_no_erx_descr = rxf_stats->rx_drops_no_erx_descr;\n\tdrvs->forwarded_packets = rxf_stats->forwarded_packets;\n\tdrvs->rx_drops_mtu = rxf_stats->rx_drops_mtu;\n\tdrvs->rx_drops_no_tpre_descr = rxf_stats->rx_drops_no_tpre_descr;\n\tdrvs->rx_drops_too_many_frags = rxf_stats->rx_drops_too_many_frags;\n\tadapter->drv_stats.eth_red_drops = pmem_sts->eth_red_drops;\n}\n\nstatic void populate_be_v1_stats(struct be_adapter *adapter)\n{\n\tstruct be_hw_stats_v1 *hw_stats = hw_stats_from_cmd(adapter);\n\tstruct be_pmem_stats *pmem_sts = &hw_stats->pmem;\n\tstruct be_rxf_stats_v1 *rxf_stats = &hw_stats->rxf;\n\tstruct be_port_rxf_stats_v1 *port_stats =\n\t\t\t\t\t&rxf_stats->port[adapter->port_num];\n\tstruct be_drv_stats *drvs = &adapter->drv_stats;\n\n\tbe_dws_le_to_cpu(hw_stats, sizeof(*hw_stats));\n\tdrvs->pmem_fifo_overflow_drop = port_stats->pmem_fifo_overflow_drop;\n\tdrvs->rx_priority_pause_frames = port_stats->rx_priority_pause_frames;\n\tdrvs->rx_pause_frames = port_stats->rx_pause_frames;\n\tdrvs->rx_crc_errors = port_stats->rx_crc_errors;\n\tdrvs->rx_control_frames = port_stats->rx_control_frames;\n\tdrvs->rx_in_range_errors = port_stats->rx_in_range_errors;\n\tdrvs->rx_frame_too_long = port_stats->rx_frame_too_long;\n\tdrvs->rx_dropped_runt = port_stats->rx_dropped_runt;\n\tdrvs->rx_ip_checksum_errs = port_stats->rx_ip_checksum_errs;\n\tdrvs->rx_tcp_checksum_errs = port_stats->rx_tcp_checksum_errs;\n\tdrvs->rx_udp_checksum_errs = port_stats->rx_udp_checksum_errs;\n\tdrvs->rx_dropped_tcp_length = port_stats->rx_dropped_tcp_length;\n\tdrvs->rx_dropped_too_small = port_stats->rx_dropped_too_small;\n\tdrvs->rx_dropped_too_short = port_stats->rx_dropped_too_short;\n\tdrvs->rx_out_range_errors = port_stats->rx_out_range_errors;\n\tdrvs->rx_dropped_header_too_small =\n\t\tport_stats->rx_dropped_header_too_small;\n\tdrvs->rx_input_fifo_overflow_drop =\n\t\tport_stats->rx_input_fifo_overflow_drop;\n\tdrvs->rx_address_filtered = port_stats->rx_address_filtered;\n\tdrvs->rx_alignment_symbol_errors =\n\t\tport_stats->rx_alignment_symbol_errors;\n\tdrvs->rxpp_fifo_overflow_drop = port_stats->rxpp_fifo_overflow_drop;\n\tdrvs->tx_pauseframes = port_stats->tx_pauseframes;\n\tdrvs->tx_controlframes = port_stats->tx_controlframes;\n\tdrvs->tx_priority_pauseframes = port_stats->tx_priority_pauseframes;\n\tdrvs->jabber_events = port_stats->jabber_events;\n\tdrvs->rx_drops_no_pbuf = rxf_stats->rx_drops_no_pbuf;\n\tdrvs->rx_drops_no_erx_descr = rxf_stats->rx_drops_no_erx_descr;\n\tdrvs->forwarded_packets = rxf_stats->forwarded_packets;\n\tdrvs->rx_drops_mtu = rxf_stats->rx_drops_mtu;\n\tdrvs->rx_drops_no_tpre_descr = rxf_stats->rx_drops_no_tpre_descr;\n\tdrvs->rx_drops_too_many_frags = rxf_stats->rx_drops_too_many_frags;\n\tadapter->drv_stats.eth_red_drops = pmem_sts->eth_red_drops;\n}\n\nstatic void populate_be_v2_stats(struct be_adapter *adapter)\n{\n\tstruct be_hw_stats_v2 *hw_stats = hw_stats_from_cmd(adapter);\n\tstruct be_pmem_stats *pmem_sts = &hw_stats->pmem;\n\tstruct be_rxf_stats_v2 *rxf_stats = &hw_stats->rxf;\n\tstruct be_port_rxf_stats_v2 *port_stats =\n\t\t\t\t\t&rxf_stats->port[adapter->port_num];\n\tstruct be_drv_stats *drvs = &adapter->drv_stats;\n\n\tbe_dws_le_to_cpu(hw_stats, sizeof(*hw_stats));\n\tdrvs->pmem_fifo_overflow_drop = port_stats->pmem_fifo_overflow_drop;\n\tdrvs->rx_priority_pause_frames = port_stats->rx_priority_pause_frames;\n\tdrvs->rx_pause_frames = port_stats->rx_pause_frames;\n\tdrvs->rx_crc_errors = port_stats->rx_crc_errors;\n\tdrvs->rx_control_frames = port_stats->rx_control_frames;\n\tdrvs->rx_in_range_errors = port_stats->rx_in_range_errors;\n\tdrvs->rx_frame_too_long = port_stats->rx_frame_too_long;\n\tdrvs->rx_dropped_runt = port_stats->rx_dropped_runt;\n\tdrvs->rx_ip_checksum_errs = port_stats->rx_ip_checksum_errs;\n\tdrvs->rx_tcp_checksum_errs = port_stats->rx_tcp_checksum_errs;\n\tdrvs->rx_udp_checksum_errs = port_stats->rx_udp_checksum_errs;\n\tdrvs->rx_dropped_tcp_length = port_stats->rx_dropped_tcp_length;\n\tdrvs->rx_dropped_too_small = port_stats->rx_dropped_too_small;\n\tdrvs->rx_dropped_too_short = port_stats->rx_dropped_too_short;\n\tdrvs->rx_out_range_errors = port_stats->rx_out_range_errors;\n\tdrvs->rx_dropped_header_too_small =\n\t\tport_stats->rx_dropped_header_too_small;\n\tdrvs->rx_input_fifo_overflow_drop =\n\t\tport_stats->rx_input_fifo_overflow_drop;\n\tdrvs->rx_address_filtered = port_stats->rx_address_filtered;\n\tdrvs->rx_alignment_symbol_errors =\n\t\tport_stats->rx_alignment_symbol_errors;\n\tdrvs->rxpp_fifo_overflow_drop = port_stats->rxpp_fifo_overflow_drop;\n\tdrvs->tx_pauseframes = port_stats->tx_pauseframes;\n\tdrvs->tx_controlframes = port_stats->tx_controlframes;\n\tdrvs->tx_priority_pauseframes = port_stats->tx_priority_pauseframes;\n\tdrvs->jabber_events = port_stats->jabber_events;\n\tdrvs->rx_drops_no_pbuf = rxf_stats->rx_drops_no_pbuf;\n\tdrvs->rx_drops_no_erx_descr = rxf_stats->rx_drops_no_erx_descr;\n\tdrvs->forwarded_packets = rxf_stats->forwarded_packets;\n\tdrvs->rx_drops_mtu = rxf_stats->rx_drops_mtu;\n\tdrvs->rx_drops_no_tpre_descr = rxf_stats->rx_drops_no_tpre_descr;\n\tdrvs->rx_drops_too_many_frags = rxf_stats->rx_drops_too_many_frags;\n\tadapter->drv_stats.eth_red_drops = pmem_sts->eth_red_drops;\n\tif (be_roce_supported(adapter)) {\n\t\tdrvs->rx_roce_bytes_lsd = port_stats->roce_bytes_received_lsd;\n\t\tdrvs->rx_roce_bytes_msd = port_stats->roce_bytes_received_msd;\n\t\tdrvs->rx_roce_frames = port_stats->roce_frames_received;\n\t\tdrvs->roce_drops_crc = port_stats->roce_drops_crc;\n\t\tdrvs->roce_drops_payload_len =\n\t\t\tport_stats->roce_drops_payload_len;\n\t}\n}\n\nstatic void populate_lancer_stats(struct be_adapter *adapter)\n{\n\tstruct be_drv_stats *drvs = &adapter->drv_stats;\n\tstruct lancer_pport_stats *pport_stats = pport_stats_from_cmd(adapter);\n\n\tbe_dws_le_to_cpu(pport_stats, sizeof(*pport_stats));\n\tdrvs->rx_pause_frames = pport_stats->rx_pause_frames_lo;\n\tdrvs->rx_crc_errors = pport_stats->rx_crc_errors_lo;\n\tdrvs->rx_control_frames = pport_stats->rx_control_frames_lo;\n\tdrvs->rx_in_range_errors = pport_stats->rx_in_range_errors;\n\tdrvs->rx_frame_too_long = pport_stats->rx_frames_too_long_lo;\n\tdrvs->rx_dropped_runt = pport_stats->rx_dropped_runt;\n\tdrvs->rx_ip_checksum_errs = pport_stats->rx_ip_checksum_errors;\n\tdrvs->rx_tcp_checksum_errs = pport_stats->rx_tcp_checksum_errors;\n\tdrvs->rx_udp_checksum_errs = pport_stats->rx_udp_checksum_errors;\n\tdrvs->rx_dropped_tcp_length =\n\t\t\t\tpport_stats->rx_dropped_invalid_tcp_length;\n\tdrvs->rx_dropped_too_small = pport_stats->rx_dropped_too_small;\n\tdrvs->rx_dropped_too_short = pport_stats->rx_dropped_too_short;\n\tdrvs->rx_out_range_errors = pport_stats->rx_out_of_range_errors;\n\tdrvs->rx_dropped_header_too_small =\n\t\t\t\tpport_stats->rx_dropped_header_too_small;\n\tdrvs->rx_input_fifo_overflow_drop = pport_stats->rx_fifo_overflow;\n\tdrvs->rx_address_filtered =\n\t\t\t\t\tpport_stats->rx_address_filtered +\n\t\t\t\t\tpport_stats->rx_vlan_filtered;\n\tdrvs->rx_alignment_symbol_errors = pport_stats->rx_symbol_errors_lo;\n\tdrvs->rxpp_fifo_overflow_drop = pport_stats->rx_fifo_overflow;\n\tdrvs->tx_pauseframes = pport_stats->tx_pause_frames_lo;\n\tdrvs->tx_controlframes = pport_stats->tx_control_frames_lo;\n\tdrvs->jabber_events = pport_stats->rx_jabbers;\n\tdrvs->forwarded_packets = pport_stats->num_forwards_lo;\n\tdrvs->rx_drops_mtu = pport_stats->rx_drops_mtu_lo;\n\tdrvs->rx_drops_too_many_frags =\n\t\t\t\tpport_stats->rx_drops_too_many_frags_lo;\n}\n\nstatic void accumulate_16bit_val(u32 *acc, u16 val)\n{\n#define lo(x)\t\t\t(x & 0xFFFF)\n#define hi(x)\t\t\t(x & 0xFFFF0000)\n\tbool wrapped = val < lo(*acc);\n\tu32 newacc = hi(*acc) + val;\n\n\tif (wrapped)\n\t\tnewacc += 65536;\n\tWRITE_ONCE(*acc, newacc);\n}\n\nstatic void populate_erx_stats(struct be_adapter *adapter,\n\t\t\t       struct be_rx_obj *rxo, u32 erx_stat)\n{\n\tif (!BEx_chip(adapter))\n\t\trx_stats(rxo)->rx_drops_no_frags = erx_stat;\n\telse\n\t\t \n\t\taccumulate_16bit_val(&rx_stats(rxo)->rx_drops_no_frags,\n\t\t\t\t     (u16)erx_stat);\n}\n\nvoid be_parse_stats(struct be_adapter *adapter)\n{\n\tstruct be_erx_stats_v2 *erx = be_erx_stats_from_cmd(adapter);\n\tstruct be_rx_obj *rxo;\n\tint i;\n\tu32 erx_stat;\n\n\tif (lancer_chip(adapter)) {\n\t\tpopulate_lancer_stats(adapter);\n\t} else {\n\t\tif (BE2_chip(adapter))\n\t\t\tpopulate_be_v0_stats(adapter);\n\t\telse if (BE3_chip(adapter))\n\t\t\t \n\t\t\tpopulate_be_v1_stats(adapter);\n\t\telse\n\t\t\tpopulate_be_v2_stats(adapter);\n\n\t\t \n\t\tfor_all_rx_queues(adapter, rxo, i) {\n\t\t\terx_stat = erx->rx_drops_no_fragments[rxo->q.id];\n\t\t\tpopulate_erx_stats(adapter, rxo, erx_stat);\n\t\t}\n\t}\n}\n\nstatic void be_get_stats64(struct net_device *netdev,\n\t\t\t   struct rtnl_link_stats64 *stats)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_drv_stats *drvs = &adapter->drv_stats;\n\tstruct be_rx_obj *rxo;\n\tstruct be_tx_obj *txo;\n\tu64 pkts, bytes;\n\tunsigned int start;\n\tint i;\n\n\tfor_all_rx_queues(adapter, rxo, i) {\n\t\tconst struct be_rx_stats *rx_stats = rx_stats(rxo);\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&rx_stats->sync);\n\t\t\tpkts = rx_stats(rxo)->rx_pkts;\n\t\t\tbytes = rx_stats(rxo)->rx_bytes;\n\t\t} while (u64_stats_fetch_retry(&rx_stats->sync, start));\n\t\tstats->rx_packets += pkts;\n\t\tstats->rx_bytes += bytes;\n\t\tstats->multicast += rx_stats(rxo)->rx_mcast_pkts;\n\t\tstats->rx_dropped += rx_stats(rxo)->rx_drops_no_skbs +\n\t\t\t\t\trx_stats(rxo)->rx_drops_no_frags;\n\t}\n\n\tfor_all_tx_queues(adapter, txo, i) {\n\t\tconst struct be_tx_stats *tx_stats = tx_stats(txo);\n\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&tx_stats->sync);\n\t\t\tpkts = tx_stats(txo)->tx_pkts;\n\t\t\tbytes = tx_stats(txo)->tx_bytes;\n\t\t} while (u64_stats_fetch_retry(&tx_stats->sync, start));\n\t\tstats->tx_packets += pkts;\n\t\tstats->tx_bytes += bytes;\n\t}\n\n\t \n\tstats->rx_errors = drvs->rx_crc_errors +\n\t\tdrvs->rx_alignment_symbol_errors +\n\t\tdrvs->rx_in_range_errors +\n\t\tdrvs->rx_out_range_errors +\n\t\tdrvs->rx_frame_too_long +\n\t\tdrvs->rx_dropped_too_small +\n\t\tdrvs->rx_dropped_too_short +\n\t\tdrvs->rx_dropped_header_too_small +\n\t\tdrvs->rx_dropped_tcp_length +\n\t\tdrvs->rx_dropped_runt;\n\n\t \n\tstats->rx_length_errors = drvs->rx_in_range_errors +\n\t\tdrvs->rx_out_range_errors +\n\t\tdrvs->rx_frame_too_long;\n\n\tstats->rx_crc_errors = drvs->rx_crc_errors;\n\n\t \n\tstats->rx_frame_errors = drvs->rx_alignment_symbol_errors;\n\n\t \n\t \n\tstats->rx_fifo_errors = drvs->rxpp_fifo_overflow_drop +\n\t\t\t\tdrvs->rx_input_fifo_overflow_drop +\n\t\t\t\tdrvs->rx_drops_no_pbuf;\n}\n\nvoid be_link_status_update(struct be_adapter *adapter, u8 link_status)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tif (!(adapter->flags & BE_FLAGS_LINK_STATUS_INIT)) {\n\t\tnetif_carrier_off(netdev);\n\t\tadapter->flags |= BE_FLAGS_LINK_STATUS_INIT;\n\t}\n\n\tif (link_status)\n\t\tnetif_carrier_on(netdev);\n\telse\n\t\tnetif_carrier_off(netdev);\n\n\tnetdev_info(netdev, \"Link is %s\\n\", link_status ? \"Up\" : \"Down\");\n}\n\nstatic int be_gso_hdr_len(struct sk_buff *skb)\n{\n\tif (skb->encapsulation)\n\t\treturn skb_inner_tcp_all_headers(skb);\n\n\treturn skb_tcp_all_headers(skb);\n}\n\nstatic void be_tx_stats_update(struct be_tx_obj *txo, struct sk_buff *skb)\n{\n\tstruct be_tx_stats *stats = tx_stats(txo);\n\tu32 tx_pkts = skb_shinfo(skb)->gso_segs ? : 1;\n\t \n\tu32 dup_hdr_len = tx_pkts > 1 ? be_gso_hdr_len(skb) * (tx_pkts - 1) : 0;\n\n\tu64_stats_update_begin(&stats->sync);\n\tstats->tx_reqs++;\n\tstats->tx_bytes += skb->len + dup_hdr_len;\n\tstats->tx_pkts += tx_pkts;\n\tif (skb->encapsulation && skb->ip_summed == CHECKSUM_PARTIAL)\n\t\tstats->tx_vxlan_offload_pkts += tx_pkts;\n\tu64_stats_update_end(&stats->sync);\n}\n\n \nstatic u32 skb_wrb_cnt(struct sk_buff *skb)\n{\n\t \n\treturn 1 + (skb_headlen(skb) ? 1 : 0) + skb_shinfo(skb)->nr_frags;\n}\n\nstatic inline void wrb_fill(struct be_eth_wrb *wrb, u64 addr, int len)\n{\n\twrb->frag_pa_hi = cpu_to_le32(upper_32_bits(addr));\n\twrb->frag_pa_lo = cpu_to_le32(lower_32_bits(addr));\n\twrb->frag_len = cpu_to_le32(len & ETH_WRB_FRAG_LEN_MASK);\n\twrb->rsvd0 = 0;\n}\n\n \nstatic inline void wrb_fill_dummy(struct be_eth_wrb *wrb)\n{\n\twrb->frag_pa_hi = 0;\n\twrb->frag_pa_lo = 0;\n\twrb->frag_len = 0;\n\twrb->rsvd0 = 0;\n}\n\nstatic inline u16 be_get_tx_vlan_tag(struct be_adapter *adapter,\n\t\t\t\t     struct sk_buff *skb)\n{\n\tu8 vlan_prio;\n\tu16 vlan_tag;\n\n\tvlan_tag = skb_vlan_tag_get(skb);\n\tvlan_prio = skb_vlan_tag_get_prio(skb);\n\t \n\tif (!(adapter->vlan_prio_bmap & (1 << vlan_prio)))\n\t\tvlan_tag = (vlan_tag & ~VLAN_PRIO_MASK) |\n\t\t\t\tadapter->recommended_prio_bits;\n\n\treturn vlan_tag;\n}\n\n \nstatic u16 skb_inner_ip_proto(struct sk_buff *skb)\n{\n\treturn (inner_ip_hdr(skb)->version == 4) ?\n\t\tinner_ip_hdr(skb)->protocol : inner_ipv6_hdr(skb)->nexthdr;\n}\n\nstatic u16 skb_ip_proto(struct sk_buff *skb)\n{\n\treturn (ip_hdr(skb)->version == 4) ?\n\t\tip_hdr(skb)->protocol : ipv6_hdr(skb)->nexthdr;\n}\n\nstatic inline bool be_is_txq_full(struct be_tx_obj *txo)\n{\n\treturn atomic_read(&txo->q.used) + BE_MAX_TX_FRAG_COUNT >= txo->q.len;\n}\n\nstatic inline bool be_can_txq_wake(struct be_tx_obj *txo)\n{\n\treturn atomic_read(&txo->q.used) < txo->q.len / 2;\n}\n\nstatic inline bool be_is_tx_compl_pending(struct be_tx_obj *txo)\n{\n\treturn atomic_read(&txo->q.used) > txo->pend_wrb_cnt;\n}\n\nstatic void be_get_wrb_params_from_skb(struct be_adapter *adapter,\n\t\t\t\t       struct sk_buff *skb,\n\t\t\t\t       struct be_wrb_params *wrb_params)\n{\n\tu16 proto;\n\n\tif (skb_is_gso(skb)) {\n\t\tBE_WRB_F_SET(wrb_params->features, LSO, 1);\n\t\twrb_params->lso_mss = skb_shinfo(skb)->gso_size;\n\t\tif (skb_is_gso_v6(skb) && !lancer_chip(adapter))\n\t\t\tBE_WRB_F_SET(wrb_params->features, LSO6, 1);\n\t} else if (skb->ip_summed == CHECKSUM_PARTIAL) {\n\t\tif (skb->encapsulation) {\n\t\t\tBE_WRB_F_SET(wrb_params->features, IPCS, 1);\n\t\t\tproto = skb_inner_ip_proto(skb);\n\t\t} else {\n\t\t\tproto = skb_ip_proto(skb);\n\t\t}\n\t\tif (proto == IPPROTO_TCP)\n\t\t\tBE_WRB_F_SET(wrb_params->features, TCPCS, 1);\n\t\telse if (proto == IPPROTO_UDP)\n\t\t\tBE_WRB_F_SET(wrb_params->features, UDPCS, 1);\n\t}\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\tBE_WRB_F_SET(wrb_params->features, VLAN, 1);\n\t\twrb_params->vlan_tag = be_get_tx_vlan_tag(adapter, skb);\n\t}\n\n\tBE_WRB_F_SET(wrb_params->features, CRC, 1);\n}\n\nstatic void wrb_fill_hdr(struct be_adapter *adapter,\n\t\t\t struct be_eth_hdr_wrb *hdr,\n\t\t\t struct be_wrb_params *wrb_params,\n\t\t\t struct sk_buff *skb)\n{\n\tmemset(hdr, 0, sizeof(*hdr));\n\n\tSET_TX_WRB_HDR_BITS(crc, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, CRC));\n\tSET_TX_WRB_HDR_BITS(ipcs, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, IPCS));\n\tSET_TX_WRB_HDR_BITS(tcpcs, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, TCPCS));\n\tSET_TX_WRB_HDR_BITS(udpcs, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, UDPCS));\n\n\tSET_TX_WRB_HDR_BITS(lso, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, LSO));\n\tSET_TX_WRB_HDR_BITS(lso6, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, LSO6));\n\tSET_TX_WRB_HDR_BITS(lso_mss, hdr, wrb_params->lso_mss);\n\n\t \n\tSET_TX_WRB_HDR_BITS(event, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, VLAN_SKIP_HW));\n\tSET_TX_WRB_HDR_BITS(vlan, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, VLAN));\n\tSET_TX_WRB_HDR_BITS(vlan_tag, hdr, wrb_params->vlan_tag);\n\n\tSET_TX_WRB_HDR_BITS(num_wrb, hdr, skb_wrb_cnt(skb));\n\tSET_TX_WRB_HDR_BITS(len, hdr, skb->len);\n\tSET_TX_WRB_HDR_BITS(mgmt, hdr,\n\t\t\t    BE_WRB_F_GET(wrb_params->features, OS2BMC));\n}\n\nstatic void unmap_tx_frag(struct device *dev, struct be_eth_wrb *wrb,\n\t\t\t  bool unmap_single)\n{\n\tdma_addr_t dma;\n\tu32 frag_len = le32_to_cpu(wrb->frag_len);\n\n\n\tdma = (u64)le32_to_cpu(wrb->frag_pa_hi) << 32 |\n\t\t(u64)le32_to_cpu(wrb->frag_pa_lo);\n\tif (frag_len) {\n\t\tif (unmap_single)\n\t\t\tdma_unmap_single(dev, dma, frag_len, DMA_TO_DEVICE);\n\t\telse\n\t\t\tdma_unmap_page(dev, dma, frag_len, DMA_TO_DEVICE);\n\t}\n}\n\n \nstatic u32 be_tx_get_wrb_hdr(struct be_tx_obj *txo)\n{\n\tu32 head = txo->q.head;\n\n\tqueue_head_inc(&txo->q);\n\treturn head;\n}\n\n \nstatic void be_tx_setup_wrb_hdr(struct be_adapter *adapter,\n\t\t\t\tstruct be_tx_obj *txo,\n\t\t\t\tstruct be_wrb_params *wrb_params,\n\t\t\t\tstruct sk_buff *skb, u16 head)\n{\n\tu32 num_frags = skb_wrb_cnt(skb);\n\tstruct be_queue_info *txq = &txo->q;\n\tstruct be_eth_hdr_wrb *hdr = queue_index_node(txq, head);\n\n\twrb_fill_hdr(adapter, hdr, wrb_params, skb);\n\tbe_dws_cpu_to_le(hdr, sizeof(*hdr));\n\n\tBUG_ON(txo->sent_skb_list[head]);\n\ttxo->sent_skb_list[head] = skb;\n\ttxo->last_req_hdr = head;\n\tatomic_add(num_frags, &txq->used);\n\ttxo->last_req_wrb_cnt = num_frags;\n\ttxo->pend_wrb_cnt += num_frags;\n}\n\n \nstatic void be_tx_setup_wrb_frag(struct be_tx_obj *txo, dma_addr_t busaddr,\n\t\t\t\t int len)\n{\n\tstruct be_eth_wrb *wrb;\n\tstruct be_queue_info *txq = &txo->q;\n\n\twrb = queue_head_node(txq);\n\twrb_fill(wrb, busaddr, len);\n\tqueue_head_inc(txq);\n}\n\n \nstatic void be_xmit_restore(struct be_adapter *adapter,\n\t\t\t    struct be_tx_obj *txo, u32 head, bool map_single,\n\t\t\t    u32 copied)\n{\n\tstruct device *dev;\n\tstruct be_eth_wrb *wrb;\n\tstruct be_queue_info *txq = &txo->q;\n\n\tdev = &adapter->pdev->dev;\n\ttxq->head = head;\n\n\t \n\tqueue_head_inc(txq);\n\twhile (copied) {\n\t\twrb = queue_head_node(txq);\n\t\tunmap_tx_frag(dev, wrb, map_single);\n\t\tmap_single = false;\n\t\tcopied -= le32_to_cpu(wrb->frag_len);\n\t\tqueue_head_inc(txq);\n\t}\n\n\ttxq->head = head;\n}\n\n \nstatic u32 be_xmit_enqueue(struct be_adapter *adapter, struct be_tx_obj *txo,\n\t\t\t   struct sk_buff *skb,\n\t\t\t   struct be_wrb_params *wrb_params)\n{\n\tu32 i, copied = 0, wrb_cnt = skb_wrb_cnt(skb);\n\tstruct device *dev = &adapter->pdev->dev;\n\tbool map_single = false;\n\tu32 head;\n\tdma_addr_t busaddr;\n\tint len;\n\n\thead = be_tx_get_wrb_hdr(txo);\n\n\tif (skb->len > skb->data_len) {\n\t\tlen = skb_headlen(skb);\n\n\t\tbusaddr = dma_map_single(dev, skb->data, len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(dev, busaddr))\n\t\t\tgoto dma_err;\n\t\tmap_single = true;\n\t\tbe_tx_setup_wrb_frag(txo, busaddr, len);\n\t\tcopied += len;\n\t}\n\n\tfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\n\t\tconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\n\t\tlen = skb_frag_size(frag);\n\n\t\tbusaddr = skb_frag_dma_map(dev, frag, 0, len, DMA_TO_DEVICE);\n\t\tif (dma_mapping_error(dev, busaddr))\n\t\t\tgoto dma_err;\n\t\tbe_tx_setup_wrb_frag(txo, busaddr, len);\n\t\tcopied += len;\n\t}\n\n\tbe_tx_setup_wrb_hdr(adapter, txo, wrb_params, skb, head);\n\n\tbe_tx_stats_update(txo, skb);\n\treturn wrb_cnt;\n\ndma_err:\n\tadapter->drv_stats.dma_map_errors++;\n\tbe_xmit_restore(adapter, txo, head, map_single, copied);\n\treturn 0;\n}\n\nstatic inline int qnq_async_evt_rcvd(struct be_adapter *adapter)\n{\n\treturn adapter->flags & BE_FLAGS_QNQ_ASYNC_EVT_RCVD;\n}\n\nstatic struct sk_buff *be_insert_vlan_in_pkt(struct be_adapter *adapter,\n\t\t\t\t\t     struct sk_buff *skb,\n\t\t\t\t\t     struct be_wrb_params\n\t\t\t\t\t     *wrb_params)\n{\n\tbool insert_vlan = false;\n\tu16 vlan_tag = 0;\n\n\tskb = skb_share_check(skb, GFP_ATOMIC);\n\tif (unlikely(!skb))\n\t\treturn skb;\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\tvlan_tag = be_get_tx_vlan_tag(adapter, skb);\n\t\tinsert_vlan = true;\n\t}\n\n\tif (qnq_async_evt_rcvd(adapter) && adapter->pvid) {\n\t\tif (!insert_vlan) {\n\t\t\tvlan_tag = adapter->pvid;\n\t\t\tinsert_vlan = true;\n\t\t}\n\t\t \n\t\tBE_WRB_F_SET(wrb_params->features, VLAN_SKIP_HW, 1);\n\t}\n\n\tif (insert_vlan) {\n\t\tskb = vlan_insert_tag_set_proto(skb, htons(ETH_P_8021Q),\n\t\t\t\t\t\tvlan_tag);\n\t\tif (unlikely(!skb))\n\t\t\treturn skb;\n\t\t__vlan_hwaccel_clear_tag(skb);\n\t}\n\n\t \n\tif (adapter->qnq_vid) {\n\t\tvlan_tag = adapter->qnq_vid;\n\t\tskb = vlan_insert_tag_set_proto(skb, htons(ETH_P_8021Q),\n\t\t\t\t\t\tvlan_tag);\n\t\tif (unlikely(!skb))\n\t\t\treturn skb;\n\t\tBE_WRB_F_SET(wrb_params->features, VLAN_SKIP_HW, 1);\n\t}\n\n\treturn skb;\n}\n\nstatic bool be_ipv6_exthdr_check(struct sk_buff *skb)\n{\n\tstruct ethhdr *eh = (struct ethhdr *)skb->data;\n\tu16 offset = ETH_HLEN;\n\n\tif (eh->h_proto == htons(ETH_P_IPV6)) {\n\t\tstruct ipv6hdr *ip6h = (struct ipv6hdr *)(skb->data + offset);\n\n\t\toffset += sizeof(struct ipv6hdr);\n\t\tif (ip6h->nexthdr != NEXTHDR_TCP &&\n\t\t    ip6h->nexthdr != NEXTHDR_UDP) {\n\t\t\tstruct ipv6_opt_hdr *ehdr =\n\t\t\t\t(struct ipv6_opt_hdr *)(skb->data + offset);\n\n\t\t\t \n\t\t\tif (ehdr->hdrlen == 0xff)\n\t\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}\n\nstatic int be_vlan_tag_tx_chk(struct be_adapter *adapter, struct sk_buff *skb)\n{\n\treturn skb_vlan_tag_present(skb) || adapter->pvid || adapter->qnq_vid;\n}\n\nstatic int be_ipv6_tx_stall_chk(struct be_adapter *adapter, struct sk_buff *skb)\n{\n\treturn BE3_chip(adapter) && be_ipv6_exthdr_check(skb);\n}\n\nstatic struct sk_buff *be_lancer_xmit_workarounds(struct be_adapter *adapter,\n\t\t\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t\t\t  struct be_wrb_params\n\t\t\t\t\t\t  *wrb_params)\n{\n\tstruct vlan_ethhdr *veh = skb_vlan_eth_hdr(skb);\n\tunsigned int eth_hdr_len;\n\tstruct iphdr *ip;\n\n\t \n\teth_hdr_len = ntohs(skb->protocol) == ETH_P_8021Q ?\n\t\t\t\t\t\tVLAN_ETH_HLEN : ETH_HLEN;\n\tif (skb->len <= 60 &&\n\t    (lancer_chip(adapter) || BE3_chip(adapter) ||\n\t     skb_vlan_tag_present(skb)) && is_ipv4_pkt(skb)) {\n\t\tip = (struct iphdr *)ip_hdr(skb);\n\t\tif (unlikely(pskb_trim(skb, eth_hdr_len + ntohs(ip->tot_len))))\n\t\t\tgoto tx_drop;\n\t}\n\n\t \n\tif (be_pvid_tagging_enabled(adapter) &&\n\t    veh->h_vlan_proto == htons(ETH_P_8021Q))\n\t\tBE_WRB_F_SET(wrb_params->features, VLAN_SKIP_HW, 1);\n\n\t \n\tif (skb->ip_summed != CHECKSUM_PARTIAL &&\n\t    skb_vlan_tag_present(skb)) {\n\t\tskb = be_insert_vlan_in_pkt(adapter, skb, wrb_params);\n\t\tif (unlikely(!skb))\n\t\t\tgoto err;\n\t}\n\n\t \n\tif (unlikely(be_ipv6_tx_stall_chk(adapter, skb) &&\n\t\t     (adapter->pvid || adapter->qnq_vid) &&\n\t\t     !qnq_async_evt_rcvd(adapter)))\n\t\tgoto tx_drop;\n\n\t \n\tif (be_ipv6_tx_stall_chk(adapter, skb) &&\n\t    be_vlan_tag_tx_chk(adapter, skb)) {\n\t\tskb = be_insert_vlan_in_pkt(adapter, skb, wrb_params);\n\t\tif (unlikely(!skb))\n\t\t\tgoto err;\n\t}\n\n\treturn skb;\ntx_drop:\n\tdev_kfree_skb_any(skb);\nerr:\n\treturn NULL;\n}\n\nstatic struct sk_buff *be_xmit_workarounds(struct be_adapter *adapter,\n\t\t\t\t\t   struct sk_buff *skb,\n\t\t\t\t\t   struct be_wrb_params *wrb_params)\n{\n\tint err;\n\n\t \n\tif (skb->len <= 32) {\n\t\tif (skb_put_padto(skb, 36))\n\t\t\treturn NULL;\n\t}\n\n\tif (BEx_chip(adapter) || lancer_chip(adapter)) {\n\t\tskb = be_lancer_xmit_workarounds(adapter, skb, wrb_params);\n\t\tif (!skb)\n\t\t\treturn NULL;\n\t}\n\n\t \n\tWARN_ON_ONCE(skb->len > BE_MAX_GSO_SIZE);\n\terr = pskb_trim(skb, BE_MAX_GSO_SIZE);\n\tWARN_ON(err);\n\n\treturn skb;\n}\n\nstatic void be_xmit_flush(struct be_adapter *adapter, struct be_tx_obj *txo)\n{\n\tstruct be_queue_info *txq = &txo->q;\n\tstruct be_eth_hdr_wrb *hdr = queue_index_node(txq, txo->last_req_hdr);\n\n\t \n\tif (!(hdr->dw[2] & cpu_to_le32(TX_HDR_WRB_EVT)))\n\t\thdr->dw[2] |= cpu_to_le32(TX_HDR_WRB_EVT | TX_HDR_WRB_COMPL);\n\n\t \n\tif (!lancer_chip(adapter) && (txo->pend_wrb_cnt & 1)) {\n\t\twrb_fill_dummy(queue_head_node(txq));\n\t\tqueue_head_inc(txq);\n\t\tatomic_inc(&txq->used);\n\t\ttxo->pend_wrb_cnt++;\n\t\thdr->dw[2] &= ~cpu_to_le32(TX_HDR_WRB_NUM_MASK <<\n\t\t\t\t\t   TX_HDR_WRB_NUM_SHIFT);\n\t\thdr->dw[2] |= cpu_to_le32((txo->last_req_wrb_cnt + 1) <<\n\t\t\t\t\t  TX_HDR_WRB_NUM_SHIFT);\n\t}\n\tbe_txq_notify(adapter, txo, txo->pend_wrb_cnt);\n\ttxo->pend_wrb_cnt = 0;\n}\n\n \n\n#define DHCP_CLIENT_PORT\t68\n#define DHCP_SERVER_PORT\t67\n#define NET_BIOS_PORT1\t\t137\n#define NET_BIOS_PORT2\t\t138\n#define DHCPV6_RAS_PORT\t\t547\n\n#define is_mc_allowed_on_bmc(adapter, eh)\t\\\n\t(!is_multicast_filt_enabled(adapter) &&\t\\\n\t is_multicast_ether_addr(eh->h_dest) &&\t\\\n\t !is_broadcast_ether_addr(eh->h_dest))\n\n#define is_bc_allowed_on_bmc(adapter, eh)\t\\\n\t(!is_broadcast_filt_enabled(adapter) &&\t\\\n\t is_broadcast_ether_addr(eh->h_dest))\n\n#define is_arp_allowed_on_bmc(adapter, skb)\t\\\n\t(is_arp(skb) && is_arp_filt_enabled(adapter))\n\n#define is_arp(skb)\t(skb->protocol == htons(ETH_P_ARP))\n\n#define is_arp_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & (BMC_FILT_BROADCAST_ARP))\n\n#define is_dhcp_client_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & BMC_FILT_BROADCAST_DHCP_CLIENT)\n\n#define is_dhcp_srvr_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & BMC_FILT_BROADCAST_DHCP_SERVER)\n\n#define is_nbios_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & BMC_FILT_BROADCAST_NET_BIOS)\n\n#define is_ipv6_na_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask &\t\\\n\t\t\tBMC_FILT_MULTICAST_IPV6_NEIGH_ADVER)\n\n#define is_ipv6_ra_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & BMC_FILT_MULTICAST_IPV6_RA)\n\n#define is_ipv6_ras_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & BMC_FILT_MULTICAST_IPV6_RAS)\n\n#define is_broadcast_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & BMC_FILT_BROADCAST)\n\n#define is_multicast_filt_enabled(adapter)\t\\\n\t\t(adapter->bmc_filt_mask & BMC_FILT_MULTICAST)\n\nstatic bool be_send_pkt_to_bmc(struct be_adapter *adapter,\n\t\t\t       struct sk_buff **skb)\n{\n\tstruct ethhdr *eh = (struct ethhdr *)(*skb)->data;\n\tbool os2bmc = false;\n\n\tif (!be_is_os2bmc_enabled(adapter))\n\t\tgoto done;\n\n\tif (!is_multicast_ether_addr(eh->h_dest))\n\t\tgoto done;\n\n\tif (is_mc_allowed_on_bmc(adapter, eh) ||\n\t    is_bc_allowed_on_bmc(adapter, eh) ||\n\t    is_arp_allowed_on_bmc(adapter, (*skb))) {\n\t\tos2bmc = true;\n\t\tgoto done;\n\t}\n\n\tif ((*skb)->protocol == htons(ETH_P_IPV6)) {\n\t\tstruct ipv6hdr *hdr = ipv6_hdr((*skb));\n\t\tu8 nexthdr = hdr->nexthdr;\n\n\t\tif (nexthdr == IPPROTO_ICMPV6) {\n\t\t\tstruct icmp6hdr *icmp6 = icmp6_hdr((*skb));\n\n\t\t\tswitch (icmp6->icmp6_type) {\n\t\t\tcase NDISC_ROUTER_ADVERTISEMENT:\n\t\t\t\tos2bmc = is_ipv6_ra_filt_enabled(adapter);\n\t\t\t\tgoto done;\n\t\t\tcase NDISC_NEIGHBOUR_ADVERTISEMENT:\n\t\t\t\tos2bmc = is_ipv6_na_filt_enabled(adapter);\n\t\t\t\tgoto done;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (is_udp_pkt((*skb))) {\n\t\tstruct udphdr *udp = udp_hdr((*skb));\n\n\t\tswitch (ntohs(udp->dest)) {\n\t\tcase DHCP_CLIENT_PORT:\n\t\t\tos2bmc = is_dhcp_client_filt_enabled(adapter);\n\t\t\tgoto done;\n\t\tcase DHCP_SERVER_PORT:\n\t\t\tos2bmc = is_dhcp_srvr_filt_enabled(adapter);\n\t\t\tgoto done;\n\t\tcase NET_BIOS_PORT1:\n\t\tcase NET_BIOS_PORT2:\n\t\t\tos2bmc = is_nbios_filt_enabled(adapter);\n\t\t\tgoto done;\n\t\tcase DHCPV6_RAS_PORT:\n\t\t\tos2bmc = is_ipv6_ras_filt_enabled(adapter);\n\t\t\tgoto done;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\ndone:\n\t \n\tif (os2bmc)\n\t\t*skb = be_insert_vlan_in_pkt(adapter, *skb, NULL);\n\n\treturn os2bmc;\n}\n\nstatic netdev_tx_t be_xmit(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tu16 q_idx = skb_get_queue_mapping(skb);\n\tstruct be_tx_obj *txo = &adapter->tx_obj[q_idx];\n\tstruct be_wrb_params wrb_params = { 0 };\n\tbool flush = !netdev_xmit_more();\n\tu16 wrb_cnt;\n\n\tskb = be_xmit_workarounds(adapter, skb, &wrb_params);\n\tif (unlikely(!skb))\n\t\tgoto drop;\n\n\tbe_get_wrb_params_from_skb(adapter, skb, &wrb_params);\n\n\twrb_cnt = be_xmit_enqueue(adapter, txo, skb, &wrb_params);\n\tif (unlikely(!wrb_cnt)) {\n\t\tdev_kfree_skb_any(skb);\n\t\tgoto drop;\n\t}\n\n\t \n\tif (be_send_pkt_to_bmc(adapter, &skb)) {\n\t\tBE_WRB_F_SET(wrb_params.features, OS2BMC, 1);\n\t\twrb_cnt = be_xmit_enqueue(adapter, txo, skb, &wrb_params);\n\t\tif (unlikely(!wrb_cnt))\n\t\t\tgoto drop;\n\t\telse\n\t\t\tskb_get(skb);\n\t}\n\n\tif (be_is_txq_full(txo)) {\n\t\tnetif_stop_subqueue(netdev, q_idx);\n\t\ttx_stats(txo)->tx_stops++;\n\t}\n\n\tif (flush || __netif_subqueue_stopped(netdev, q_idx))\n\t\tbe_xmit_flush(adapter, txo);\n\n\treturn NETDEV_TX_OK;\ndrop:\n\ttx_stats(txo)->tx_drv_drops++;\n\t \n\tif (flush && txo->pend_wrb_cnt)\n\t\tbe_xmit_flush(adapter, txo);\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic void be_tx_timeout(struct net_device *netdev, unsigned int txqueue)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct be_tx_obj *txo;\n\tstruct sk_buff *skb;\n\tstruct tcphdr *tcphdr;\n\tstruct udphdr *udphdr;\n\tu32 *entry;\n\tint status;\n\tint i, j;\n\n\tfor_all_tx_queues(adapter, txo, i) {\n\t\tdev_info(dev, \"TXQ Dump: %d H: %d T: %d used: %d, qid: 0x%x\\n\",\n\t\t\t i, txo->q.head, txo->q.tail,\n\t\t\t atomic_read(&txo->q.used), txo->q.id);\n\n\t\tentry = txo->q.dma_mem.va;\n\t\tfor (j = 0; j < TX_Q_LEN * 4; j += 4) {\n\t\t\tif (entry[j] != 0 || entry[j + 1] != 0 ||\n\t\t\t    entry[j + 2] != 0 || entry[j + 3] != 0) {\n\t\t\t\tdev_info(dev, \"Entry %d 0x%x 0x%x 0x%x 0x%x\\n\",\n\t\t\t\t\t j, entry[j], entry[j + 1],\n\t\t\t\t\t entry[j + 2], entry[j + 3]);\n\t\t\t}\n\t\t}\n\n\t\tentry = txo->cq.dma_mem.va;\n\t\tdev_info(dev, \"TXCQ Dump: %d  H: %d T: %d used: %d\\n\",\n\t\t\t i, txo->cq.head, txo->cq.tail,\n\t\t\t atomic_read(&txo->cq.used));\n\t\tfor (j = 0; j < TX_CQ_LEN * 4; j += 4) {\n\t\t\tif (entry[j] != 0 || entry[j + 1] != 0 ||\n\t\t\t    entry[j + 2] != 0 || entry[j + 3] != 0) {\n\t\t\t\tdev_info(dev, \"Entry %d 0x%x 0x%x 0x%x 0x%x\\n\",\n\t\t\t\t\t j, entry[j], entry[j + 1],\n\t\t\t\t\t entry[j + 2], entry[j + 3]);\n\t\t\t}\n\t\t}\n\n\t\tfor (j = 0; j < TX_Q_LEN; j++) {\n\t\t\tif (txo->sent_skb_list[j]) {\n\t\t\t\tskb = txo->sent_skb_list[j];\n\t\t\t\tif (ip_hdr(skb)->protocol == IPPROTO_TCP) {\n\t\t\t\t\ttcphdr = tcp_hdr(skb);\n\t\t\t\t\tdev_info(dev, \"TCP source port %d\\n\",\n\t\t\t\t\t\t ntohs(tcphdr->source));\n\t\t\t\t\tdev_info(dev, \"TCP dest port %d\\n\",\n\t\t\t\t\t\t ntohs(tcphdr->dest));\n\t\t\t\t\tdev_info(dev, \"TCP sequence num %d\\n\",\n\t\t\t\t\t\t ntohs(tcphdr->seq));\n\t\t\t\t\tdev_info(dev, \"TCP ack_seq %d\\n\",\n\t\t\t\t\t\t ntohs(tcphdr->ack_seq));\n\t\t\t\t} else if (ip_hdr(skb)->protocol ==\n\t\t\t\t\t   IPPROTO_UDP) {\n\t\t\t\t\tudphdr = udp_hdr(skb);\n\t\t\t\t\tdev_info(dev, \"UDP source port %d\\n\",\n\t\t\t\t\t\t ntohs(udphdr->source));\n\t\t\t\t\tdev_info(dev, \"UDP dest port %d\\n\",\n\t\t\t\t\t\t ntohs(udphdr->dest));\n\t\t\t\t}\n\t\t\t\tdev_info(dev, \"skb[%d] %p len %d proto 0x%x\\n\",\n\t\t\t\t\t j, skb, skb->len, skb->protocol);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (lancer_chip(adapter)) {\n\t\tdev_info(dev, \"Initiating reset due to tx timeout\\n\");\n\t\tdev_info(dev, \"Resetting adapter\\n\");\n\t\tstatus = lancer_physdev_ctrl(adapter,\n\t\t\t\t\t     PHYSDEV_CONTROL_FW_RESET_MASK);\n\t\tif (status)\n\t\t\tdev_err(dev, \"Reset failed .. Reboot server\\n\");\n\t}\n}\n\nstatic inline bool be_in_all_promisc(struct be_adapter *adapter)\n{\n\treturn (adapter->if_flags & BE_IF_FLAGS_ALL_PROMISCUOUS) ==\n\t\t\tBE_IF_FLAGS_ALL_PROMISCUOUS;\n}\n\nstatic int be_set_vlan_promisc(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tint status;\n\n\tif (adapter->if_flags & BE_IF_FLAGS_VLAN_PROMISCUOUS)\n\t\treturn 0;\n\n\tstatus = be_cmd_rx_filter(adapter, BE_IF_FLAGS_VLAN_PROMISCUOUS, ON);\n\tif (!status) {\n\t\tdev_info(dev, \"Enabled VLAN promiscuous mode\\n\");\n\t\tadapter->if_flags |= BE_IF_FLAGS_VLAN_PROMISCUOUS;\n\t} else {\n\t\tdev_err(dev, \"Failed to enable VLAN promiscuous mode\\n\");\n\t}\n\treturn status;\n}\n\nstatic int be_clear_vlan_promisc(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tint status;\n\n\tstatus = be_cmd_rx_filter(adapter, BE_IF_FLAGS_VLAN_PROMISCUOUS, OFF);\n\tif (!status) {\n\t\tdev_info(dev, \"Disabling VLAN promiscuous mode\\n\");\n\t\tadapter->if_flags &= ~BE_IF_FLAGS_VLAN_PROMISCUOUS;\n\t}\n\treturn status;\n}\n\n \nstatic int be_vid_config(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tu16 vids[BE_NUM_VLANS_SUPPORTED];\n\tu16 num = 0, i = 0;\n\tint status = 0;\n\n\t \n\tif (adapter->netdev->flags & IFF_PROMISC)\n\t\treturn 0;\n\n\tif (adapter->vlans_added > be_max_vlans(adapter))\n\t\treturn be_set_vlan_promisc(adapter);\n\n\tif (adapter->if_flags & BE_IF_FLAGS_VLAN_PROMISCUOUS) {\n\t\tstatus = be_clear_vlan_promisc(adapter);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\t \n\tfor_each_set_bit(i, adapter->vids, VLAN_N_VID)\n\t\tvids[num++] = cpu_to_le16(i);\n\n\tstatus = be_cmd_vlan_config(adapter, adapter->if_handle, vids, num, 0);\n\tif (status) {\n\t\tdev_err(dev, \"Setting HW VLAN filtering failed\\n\");\n\t\t \n\t\tif (addl_status(status) == MCC_ADDL_STATUS_INSUFFICIENT_VLANS ||\n\t\t    addl_status(status) ==\n\t\t\t\tMCC_ADDL_STATUS_INSUFFICIENT_RESOURCES)\n\t\t\treturn be_set_vlan_promisc(adapter);\n\t}\n\treturn status;\n}\n\nstatic int be_vlan_add_vid(struct net_device *netdev, __be16 proto, u16 vid)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tint status = 0;\n\n\tmutex_lock(&adapter->rx_filter_lock);\n\n\t \n\tif (lancer_chip(adapter) && vid == 0)\n\t\tgoto done;\n\n\tif (test_bit(vid, adapter->vids))\n\t\tgoto done;\n\n\tset_bit(vid, adapter->vids);\n\tadapter->vlans_added++;\n\n\tstatus = be_vid_config(adapter);\ndone:\n\tmutex_unlock(&adapter->rx_filter_lock);\n\treturn status;\n}\n\nstatic int be_vlan_rem_vid(struct net_device *netdev, __be16 proto, u16 vid)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tint status = 0;\n\n\tmutex_lock(&adapter->rx_filter_lock);\n\n\t \n\tif (lancer_chip(adapter) && vid == 0)\n\t\tgoto done;\n\n\tif (!test_bit(vid, adapter->vids))\n\t\tgoto done;\n\n\tclear_bit(vid, adapter->vids);\n\tadapter->vlans_added--;\n\n\tstatus = be_vid_config(adapter);\ndone:\n\tmutex_unlock(&adapter->rx_filter_lock);\n\treturn status;\n}\n\nstatic void be_set_all_promisc(struct be_adapter *adapter)\n{\n\tbe_cmd_rx_filter(adapter, BE_IF_FLAGS_ALL_PROMISCUOUS, ON);\n\tadapter->if_flags |= BE_IF_FLAGS_ALL_PROMISCUOUS;\n}\n\nstatic void be_set_mc_promisc(struct be_adapter *adapter)\n{\n\tint status;\n\n\tif (adapter->if_flags & BE_IF_FLAGS_MCAST_PROMISCUOUS)\n\t\treturn;\n\n\tstatus = be_cmd_rx_filter(adapter, BE_IF_FLAGS_MCAST_PROMISCUOUS, ON);\n\tif (!status)\n\t\tadapter->if_flags |= BE_IF_FLAGS_MCAST_PROMISCUOUS;\n}\n\nstatic void be_set_uc_promisc(struct be_adapter *adapter)\n{\n\tint status;\n\n\tif (adapter->if_flags & BE_IF_FLAGS_PROMISCUOUS)\n\t\treturn;\n\n\tstatus = be_cmd_rx_filter(adapter, BE_IF_FLAGS_PROMISCUOUS, ON);\n\tif (!status)\n\t\tadapter->if_flags |= BE_IF_FLAGS_PROMISCUOUS;\n}\n\nstatic void be_clear_uc_promisc(struct be_adapter *adapter)\n{\n\tint status;\n\n\tif (!(adapter->if_flags & BE_IF_FLAGS_PROMISCUOUS))\n\t\treturn;\n\n\tstatus = be_cmd_rx_filter(adapter, BE_IF_FLAGS_PROMISCUOUS, OFF);\n\tif (!status)\n\t\tadapter->if_flags &= ~BE_IF_FLAGS_PROMISCUOUS;\n}\n\n \nstatic int be_uc_list_update(struct net_device *netdev,\n\t\t\t     const unsigned char *addr)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\n\tadapter->update_uc_list = true;\n\treturn 0;\n}\n\nstatic int be_mc_list_update(struct net_device *netdev,\n\t\t\t     const unsigned char *addr)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\n\tadapter->update_mc_list = true;\n\treturn 0;\n}\n\nstatic void be_set_mc_list(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct netdev_hw_addr *ha;\n\tbool mc_promisc = false;\n\tint status;\n\n\tnetif_addr_lock_bh(netdev);\n\t__dev_mc_sync(netdev, be_mc_list_update, be_mc_list_update);\n\n\tif (netdev->flags & IFF_PROMISC) {\n\t\tadapter->update_mc_list = false;\n\t} else if (netdev->flags & IFF_ALLMULTI ||\n\t\t   netdev_mc_count(netdev) > be_max_mc(adapter)) {\n\t\t \n\t\tmc_promisc = true;\n\t\tadapter->update_mc_list = false;\n\t} else if (adapter->if_flags & BE_IF_FLAGS_MCAST_PROMISCUOUS) {\n\t\t \n\t\tadapter->update_mc_list = true;\n\t}\n\n\tif (adapter->update_mc_list) {\n\t\tint i = 0;\n\n\t\t \n\t\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\t\tether_addr_copy(adapter->mc_list[i].mac, ha->addr);\n\t\t\ti++;\n\t\t}\n\t\tadapter->mc_count = netdev_mc_count(netdev);\n\t}\n\tnetif_addr_unlock_bh(netdev);\n\n\tif (mc_promisc) {\n\t\tbe_set_mc_promisc(adapter);\n\t} else if (adapter->update_mc_list) {\n\t\tstatus = be_cmd_rx_filter(adapter, BE_IF_FLAGS_MULTICAST, ON);\n\t\tif (!status)\n\t\t\tadapter->if_flags &= ~BE_IF_FLAGS_MCAST_PROMISCUOUS;\n\t\telse\n\t\t\tbe_set_mc_promisc(adapter);\n\n\t\tadapter->update_mc_list = false;\n\t}\n}\n\nstatic void be_clear_mc_list(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\t__dev_mc_unsync(netdev, NULL);\n\tbe_cmd_rx_filter(adapter, BE_IF_FLAGS_MULTICAST, OFF);\n\tadapter->mc_count = 0;\n}\n\nstatic int be_uc_mac_add(struct be_adapter *adapter, int uc_idx)\n{\n\tif (ether_addr_equal(adapter->uc_list[uc_idx].mac, adapter->dev_mac)) {\n\t\tadapter->pmac_id[uc_idx + 1] = adapter->pmac_id[0];\n\t\treturn 0;\n\t}\n\n\treturn be_cmd_pmac_add(adapter, adapter->uc_list[uc_idx].mac,\n\t\t\t       adapter->if_handle,\n\t\t\t       &adapter->pmac_id[uc_idx + 1], 0);\n}\n\nstatic void be_uc_mac_del(struct be_adapter *adapter, int pmac_id)\n{\n\tif (pmac_id == adapter->pmac_id[0])\n\t\treturn;\n\n\tbe_cmd_pmac_del(adapter, adapter->if_handle, pmac_id, 0);\n}\n\nstatic void be_set_uc_list(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct netdev_hw_addr *ha;\n\tbool uc_promisc = false;\n\tint curr_uc_macs = 0, i;\n\n\tnetif_addr_lock_bh(netdev);\n\t__dev_uc_sync(netdev, be_uc_list_update, be_uc_list_update);\n\n\tif (netdev->flags & IFF_PROMISC) {\n\t\tadapter->update_uc_list = false;\n\t} else if (netdev_uc_count(netdev) > (be_max_uc(adapter) - 1)) {\n\t\tuc_promisc = true;\n\t\tadapter->update_uc_list = false;\n\t}  else if (adapter->if_flags & BE_IF_FLAGS_PROMISCUOUS) {\n\t\t \n\t\tadapter->update_uc_list = true;\n\t}\n\n\tif (adapter->update_uc_list) {\n\t\t \n\t\ti = 0;\n\t\tnetdev_for_each_uc_addr(ha, netdev) {\n\t\t\tether_addr_copy(adapter->uc_list[i].mac, ha->addr);\n\t\t\ti++;\n\t\t}\n\t\tcurr_uc_macs = netdev_uc_count(netdev);\n\t}\n\tnetif_addr_unlock_bh(netdev);\n\n\tif (uc_promisc) {\n\t\tbe_set_uc_promisc(adapter);\n\t} else if (adapter->update_uc_list) {\n\t\tbe_clear_uc_promisc(adapter);\n\n\t\tfor (i = 0; i < adapter->uc_macs; i++)\n\t\t\tbe_uc_mac_del(adapter, adapter->pmac_id[i + 1]);\n\n\t\tfor (i = 0; i < curr_uc_macs; i++)\n\t\t\tbe_uc_mac_add(adapter, i);\n\t\tadapter->uc_macs = curr_uc_macs;\n\t\tadapter->update_uc_list = false;\n\t}\n}\n\nstatic void be_clear_uc_list(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint i;\n\n\t__dev_uc_unsync(netdev, NULL);\n\tfor (i = 0; i < adapter->uc_macs; i++)\n\t\tbe_uc_mac_del(adapter, adapter->pmac_id[i + 1]);\n\n\tadapter->uc_macs = 0;\n}\n\nstatic void __be_set_rx_mode(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\tmutex_lock(&adapter->rx_filter_lock);\n\n\tif (netdev->flags & IFF_PROMISC) {\n\t\tif (!be_in_all_promisc(adapter))\n\t\t\tbe_set_all_promisc(adapter);\n\t} else if (be_in_all_promisc(adapter)) {\n\t\t \n\t\tbe_vid_config(adapter);\n\t}\n\n\tbe_set_uc_list(adapter);\n\tbe_set_mc_list(adapter);\n\n\tmutex_unlock(&adapter->rx_filter_lock);\n}\n\nstatic void be_work_set_rx_mode(struct work_struct *work)\n{\n\tstruct be_cmd_work *cmd_work =\n\t\t\t\tcontainer_of(work, struct be_cmd_work, work);\n\n\t__be_set_rx_mode(cmd_work->adapter);\n\tkfree(cmd_work);\n}\n\nstatic int be_set_vf_mac(struct net_device *netdev, int vf, u8 *mac)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_vf_cfg *vf_cfg = &adapter->vf_cfg[vf];\n\tint status;\n\n\tif (!sriov_enabled(adapter))\n\t\treturn -EPERM;\n\n\tif (!is_valid_ether_addr(mac) || vf >= adapter->num_vfs)\n\t\treturn -EINVAL;\n\n\t \n\tif (ether_addr_equal(mac, vf_cfg->mac_addr))\n\t\treturn 0;\n\n\tif (BEx_chip(adapter)) {\n\t\tbe_cmd_pmac_del(adapter, vf_cfg->if_handle, vf_cfg->pmac_id,\n\t\t\t\tvf + 1);\n\n\t\tstatus = be_cmd_pmac_add(adapter, mac, vf_cfg->if_handle,\n\t\t\t\t\t &vf_cfg->pmac_id, vf + 1);\n\t} else {\n\t\tstatus = be_cmd_set_mac(adapter, mac, vf_cfg->if_handle,\n\t\t\t\t\tvf + 1);\n\t}\n\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev, \"MAC %pM set on VF %d Failed: %#x\",\n\t\t\tmac, vf, status);\n\t\treturn be_cmd_status(status);\n\t}\n\n\tether_addr_copy(vf_cfg->mac_addr, mac);\n\n\treturn 0;\n}\n\nstatic int be_get_vf_config(struct net_device *netdev, int vf,\n\t\t\t    struct ifla_vf_info *vi)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_vf_cfg *vf_cfg = &adapter->vf_cfg[vf];\n\n\tif (!sriov_enabled(adapter))\n\t\treturn -EPERM;\n\n\tif (vf >= adapter->num_vfs)\n\t\treturn -EINVAL;\n\n\tvi->vf = vf;\n\tvi->max_tx_rate = vf_cfg->tx_rate;\n\tvi->min_tx_rate = 0;\n\tvi->vlan = vf_cfg->vlan_tag & VLAN_VID_MASK;\n\tvi->qos = vf_cfg->vlan_tag >> VLAN_PRIO_SHIFT;\n\tmemcpy(&vi->mac, vf_cfg->mac_addr, ETH_ALEN);\n\tvi->linkstate = adapter->vf_cfg[vf].plink_tracking;\n\tvi->spoofchk = adapter->vf_cfg[vf].spoofchk;\n\n\treturn 0;\n}\n\nstatic int be_set_vf_tvt(struct be_adapter *adapter, int vf, u16 vlan)\n{\n\tstruct be_vf_cfg *vf_cfg = &adapter->vf_cfg[vf];\n\tu16 vids[BE_NUM_VLANS_SUPPORTED];\n\tint vf_if_id = vf_cfg->if_handle;\n\tint status;\n\n\t \n\tstatus = be_cmd_set_hsw_config(adapter, vlan, vf + 1, vf_if_id, 0, 0);\n\tif (status)\n\t\treturn status;\n\n\t \n\tvids[0] = 0;\n\tstatus = be_cmd_vlan_config(adapter, vf_if_id, vids, 1, vf + 1);\n\tif (!status)\n\t\tdev_info(&adapter->pdev->dev,\n\t\t\t \"Cleared guest VLANs on VF%d\", vf);\n\n\t \n\tif (vf_cfg->privileges & BE_PRIV_FILTMGMT) {\n\t\tstatus = be_cmd_set_fn_privileges(adapter, vf_cfg->privileges &\n\t\t\t\t\t\t  ~BE_PRIV_FILTMGMT, vf + 1);\n\t\tif (!status)\n\t\t\tvf_cfg->privileges &= ~BE_PRIV_FILTMGMT;\n\t}\n\treturn 0;\n}\n\nstatic int be_clear_vf_tvt(struct be_adapter *adapter, int vf)\n{\n\tstruct be_vf_cfg *vf_cfg = &adapter->vf_cfg[vf];\n\tstruct device *dev = &adapter->pdev->dev;\n\tint status;\n\n\t \n\tstatus = be_cmd_set_hsw_config(adapter, BE_RESET_VLAN_TAG_ID, vf + 1,\n\t\t\t\t       vf_cfg->if_handle, 0, 0);\n\tif (status)\n\t\treturn status;\n\n\t \n\tif (!(vf_cfg->privileges & BE_PRIV_FILTMGMT)) {\n\t\tstatus = be_cmd_set_fn_privileges(adapter, vf_cfg->privileges |\n\t\t\t\t\t\t  BE_PRIV_FILTMGMT, vf + 1);\n\t\tif (!status) {\n\t\t\tvf_cfg->privileges |= BE_PRIV_FILTMGMT;\n\t\t\tdev_info(dev, \"VF%d: FILTMGMT priv enabled\", vf);\n\t\t}\n\t}\n\n\tdev_info(dev,\n\t\t \"Disable/re-enable i/f in VM to clear Transparent VLAN tag\");\n\treturn 0;\n}\n\nstatic int be_set_vf_vlan(struct net_device *netdev, int vf, u16 vlan, u8 qos,\n\t\t\t  __be16 vlan_proto)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_vf_cfg *vf_cfg = &adapter->vf_cfg[vf];\n\tint status;\n\n\tif (!sriov_enabled(adapter))\n\t\treturn -EPERM;\n\n\tif (vf >= adapter->num_vfs || vlan > 4095 || qos > 7)\n\t\treturn -EINVAL;\n\n\tif (vlan_proto != htons(ETH_P_8021Q))\n\t\treturn -EPROTONOSUPPORT;\n\n\tif (vlan || qos) {\n\t\tvlan |= qos << VLAN_PRIO_SHIFT;\n\t\tstatus = be_set_vf_tvt(adapter, vf, vlan);\n\t} else {\n\t\tstatus = be_clear_vf_tvt(adapter, vf);\n\t}\n\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"VLAN %d config on VF %d failed : %#x\\n\", vlan, vf,\n\t\t\tstatus);\n\t\treturn be_cmd_status(status);\n\t}\n\n\tvf_cfg->vlan_tag = vlan;\n\treturn 0;\n}\n\nstatic int be_set_vf_tx_rate(struct net_device *netdev, int vf,\n\t\t\t     int min_tx_rate, int max_tx_rate)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct device *dev = &adapter->pdev->dev;\n\tint percent_rate, status = 0;\n\tu16 link_speed = 0;\n\tu8 link_status;\n\n\tif (!sriov_enabled(adapter))\n\t\treturn -EPERM;\n\n\tif (vf >= adapter->num_vfs)\n\t\treturn -EINVAL;\n\n\tif (min_tx_rate)\n\t\treturn -EINVAL;\n\n\tif (!max_tx_rate)\n\t\tgoto config_qos;\n\n\tstatus = be_cmd_link_status_query(adapter, &link_speed,\n\t\t\t\t\t  &link_status, 0);\n\tif (status)\n\t\tgoto err;\n\n\tif (!link_status) {\n\t\tdev_err(dev, \"TX-rate setting not allowed when link is down\\n\");\n\t\tstatus = -ENETDOWN;\n\t\tgoto err;\n\t}\n\n\tif (max_tx_rate < 100 || max_tx_rate > link_speed) {\n\t\tdev_err(dev, \"TX-rate must be between 100 and %d Mbps\\n\",\n\t\t\tlink_speed);\n\t\tstatus = -EINVAL;\n\t\tgoto err;\n\t}\n\n\t \n\tpercent_rate = link_speed / 100;\n\tif (skyhawk_chip(adapter) && (max_tx_rate % percent_rate)) {\n\t\tdev_err(dev, \"TX-rate must be a multiple of %d Mbps\\n\",\n\t\t\tpercent_rate);\n\t\tstatus = -EINVAL;\n\t\tgoto err;\n\t}\n\nconfig_qos:\n\tstatus = be_cmd_config_qos(adapter, max_tx_rate, link_speed, vf + 1);\n\tif (status)\n\t\tgoto err;\n\n\tadapter->vf_cfg[vf].tx_rate = max_tx_rate;\n\treturn 0;\n\nerr:\n\tdev_err(dev, \"TX-rate setting of %dMbps on VF%d failed\\n\",\n\t\tmax_tx_rate, vf);\n\treturn be_cmd_status(status);\n}\n\nstatic int be_set_vf_link_state(struct net_device *netdev, int vf,\n\t\t\t\tint link_state)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tint status;\n\n\tif (!sriov_enabled(adapter))\n\t\treturn -EPERM;\n\n\tif (vf >= adapter->num_vfs)\n\t\treturn -EINVAL;\n\n\tstatus = be_cmd_set_logical_link_config(adapter, link_state, vf+1);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Link state change on VF %d failed: %#x\\n\", vf, status);\n\t\treturn be_cmd_status(status);\n\t}\n\n\tadapter->vf_cfg[vf].plink_tracking = link_state;\n\n\treturn 0;\n}\n\nstatic int be_set_vf_spoofchk(struct net_device *netdev, int vf, bool enable)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_vf_cfg *vf_cfg = &adapter->vf_cfg[vf];\n\tu8 spoofchk;\n\tint status;\n\n\tif (!sriov_enabled(adapter))\n\t\treturn -EPERM;\n\n\tif (vf >= adapter->num_vfs)\n\t\treturn -EINVAL;\n\n\tif (BEx_chip(adapter))\n\t\treturn -EOPNOTSUPP;\n\n\tif (enable == vf_cfg->spoofchk)\n\t\treturn 0;\n\n\tspoofchk = enable ? ENABLE_MAC_SPOOFCHK : DISABLE_MAC_SPOOFCHK;\n\n\tstatus = be_cmd_set_hsw_config(adapter, 0, vf + 1, vf_cfg->if_handle,\n\t\t\t\t       0, spoofchk);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Spoofchk change on VF %d failed: %#x\\n\", vf, status);\n\t\treturn be_cmd_status(status);\n\t}\n\n\tvf_cfg->spoofchk = enable;\n\treturn 0;\n}\n\nstatic void be_aic_update(struct be_aic_obj *aic, u64 rx_pkts, u64 tx_pkts,\n\t\t\t  ulong now)\n{\n\taic->rx_pkts_prev = rx_pkts;\n\taic->tx_reqs_prev = tx_pkts;\n\taic->jiffies = now;\n}\n\nstatic int be_get_new_eqd(struct be_eq_obj *eqo)\n{\n\tstruct be_adapter *adapter = eqo->adapter;\n\tint eqd, start;\n\tstruct be_aic_obj *aic;\n\tstruct be_rx_obj *rxo;\n\tstruct be_tx_obj *txo;\n\tu64 rx_pkts = 0, tx_pkts = 0;\n\tulong now;\n\tu32 pps, delta;\n\tint i;\n\n\taic = &adapter->aic_obj[eqo->idx];\n\tif (!adapter->aic_enabled) {\n\t\tif (aic->jiffies)\n\t\t\taic->jiffies = 0;\n\t\teqd = aic->et_eqd;\n\t\treturn eqd;\n\t}\n\n\tfor_all_rx_queues_on_eq(adapter, eqo, rxo, i) {\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&rxo->stats.sync);\n\t\t\trx_pkts += rxo->stats.rx_pkts;\n\t\t} while (u64_stats_fetch_retry(&rxo->stats.sync, start));\n\t}\n\n\tfor_all_tx_queues_on_eq(adapter, eqo, txo, i) {\n\t\tdo {\n\t\t\tstart = u64_stats_fetch_begin(&txo->stats.sync);\n\t\t\ttx_pkts += txo->stats.tx_reqs;\n\t\t} while (u64_stats_fetch_retry(&txo->stats.sync, start));\n\t}\n\n\t \n\tnow = jiffies;\n\tif (!aic->jiffies || time_before(now, aic->jiffies) ||\n\t    rx_pkts < aic->rx_pkts_prev ||\n\t    tx_pkts < aic->tx_reqs_prev) {\n\t\tbe_aic_update(aic, rx_pkts, tx_pkts, now);\n\t\treturn aic->prev_eqd;\n\t}\n\n\tdelta = jiffies_to_msecs(now - aic->jiffies);\n\tif (delta == 0)\n\t\treturn aic->prev_eqd;\n\n\tpps = (((u32)(rx_pkts - aic->rx_pkts_prev) * 1000) / delta) +\n\t\t(((u32)(tx_pkts - aic->tx_reqs_prev) * 1000) / delta);\n\teqd = (pps / 15000) << 2;\n\n\tif (eqd < 8)\n\t\teqd = 0;\n\teqd = min_t(u32, eqd, aic->max_eqd);\n\teqd = max_t(u32, eqd, aic->min_eqd);\n\n\tbe_aic_update(aic, rx_pkts, tx_pkts, now);\n\n\treturn eqd;\n}\n\n \nstatic u32 be_get_eq_delay_mult_enc(struct be_eq_obj *eqo)\n{\n\tstruct be_adapter *adapter = eqo->adapter;\n\tstruct be_aic_obj *aic = &adapter->aic_obj[eqo->idx];\n\tulong now = jiffies;\n\tint eqd;\n\tu32 mult_enc;\n\n\tif (!adapter->aic_enabled)\n\t\treturn 0;\n\n\tif (jiffies_to_msecs(now - aic->jiffies) < 1)\n\t\teqd = aic->prev_eqd;\n\telse\n\t\teqd = be_get_new_eqd(eqo);\n\n\tif (eqd > 100)\n\t\tmult_enc = R2I_DLY_ENC_1;\n\telse if (eqd > 60)\n\t\tmult_enc = R2I_DLY_ENC_2;\n\telse if (eqd > 20)\n\t\tmult_enc = R2I_DLY_ENC_3;\n\telse\n\t\tmult_enc = R2I_DLY_ENC_0;\n\n\taic->prev_eqd = eqd;\n\n\treturn mult_enc;\n}\n\nvoid be_eqd_update(struct be_adapter *adapter, bool force_update)\n{\n\tstruct be_set_eqd set_eqd[MAX_EVT_QS];\n\tstruct be_aic_obj *aic;\n\tstruct be_eq_obj *eqo;\n\tint i, num = 0, eqd;\n\n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\taic = &adapter->aic_obj[eqo->idx];\n\t\teqd = be_get_new_eqd(eqo);\n\t\tif (force_update || eqd != aic->prev_eqd) {\n\t\t\tset_eqd[num].delay_multiplier = (eqd * 65)/100;\n\t\t\tset_eqd[num].eq_id = eqo->q.id;\n\t\t\taic->prev_eqd = eqd;\n\t\t\tnum++;\n\t\t}\n\t}\n\n\tif (num)\n\t\tbe_cmd_modify_eqd(adapter, set_eqd, num);\n}\n\nstatic void be_rx_stats_update(struct be_rx_obj *rxo,\n\t\t\t       struct be_rx_compl_info *rxcp)\n{\n\tstruct be_rx_stats *stats = rx_stats(rxo);\n\n\tu64_stats_update_begin(&stats->sync);\n\tstats->rx_compl++;\n\tstats->rx_bytes += rxcp->pkt_size;\n\tstats->rx_pkts++;\n\tif (rxcp->tunneled)\n\t\tstats->rx_vxlan_offload_pkts++;\n\tif (rxcp->pkt_type == BE_MULTICAST_PACKET)\n\t\tstats->rx_mcast_pkts++;\n\tif (rxcp->err)\n\t\tstats->rx_compl_err++;\n\tu64_stats_update_end(&stats->sync);\n}\n\nstatic inline bool csum_passed(struct be_rx_compl_info *rxcp)\n{\n\t \n\treturn (rxcp->tcpf || rxcp->udpf) && rxcp->l4_csum &&\n\t\t(rxcp->ip_csum || rxcp->ipv6) && !rxcp->err;\n}\n\nstatic struct be_rx_page_info *get_rx_page_info(struct be_rx_obj *rxo)\n{\n\tstruct be_adapter *adapter = rxo->adapter;\n\tstruct be_rx_page_info *rx_page_info;\n\tstruct be_queue_info *rxq = &rxo->q;\n\tu32 frag_idx = rxq->tail;\n\n\trx_page_info = &rxo->page_info_tbl[frag_idx];\n\tBUG_ON(!rx_page_info->page);\n\n\tif (rx_page_info->last_frag) {\n\t\tdma_unmap_page(&adapter->pdev->dev,\n\t\t\t       dma_unmap_addr(rx_page_info, bus),\n\t\t\t       adapter->big_page_size, DMA_FROM_DEVICE);\n\t\trx_page_info->last_frag = false;\n\t} else {\n\t\tdma_sync_single_for_cpu(&adapter->pdev->dev,\n\t\t\t\t\tdma_unmap_addr(rx_page_info, bus),\n\t\t\t\t\trx_frag_size, DMA_FROM_DEVICE);\n\t}\n\n\tqueue_tail_inc(rxq);\n\tatomic_dec(&rxq->used);\n\treturn rx_page_info;\n}\n\n \nstatic void be_rx_compl_discard(struct be_rx_obj *rxo,\n\t\t\t\tstruct be_rx_compl_info *rxcp)\n{\n\tstruct be_rx_page_info *page_info;\n\tu16 i, num_rcvd = rxcp->num_rcvd;\n\n\tfor (i = 0; i < num_rcvd; i++) {\n\t\tpage_info = get_rx_page_info(rxo);\n\t\tput_page(page_info->page);\n\t\tmemset(page_info, 0, sizeof(*page_info));\n\t}\n}\n\n \nstatic void skb_fill_rx_data(struct be_rx_obj *rxo, struct sk_buff *skb,\n\t\t\t     struct be_rx_compl_info *rxcp)\n{\n\tstruct be_rx_page_info *page_info;\n\tu16 i, j;\n\tu16 hdr_len, curr_frag_len, remaining;\n\tu8 *start;\n\n\tpage_info = get_rx_page_info(rxo);\n\tstart = page_address(page_info->page) + page_info->page_offset;\n\tprefetch(start);\n\n\t \n\tcurr_frag_len = min(rxcp->pkt_size, rx_frag_size);\n\n\tskb->len = curr_frag_len;\n\tif (curr_frag_len <= BE_HDR_LEN) {  \n\t\tmemcpy(skb->data, start, curr_frag_len);\n\t\t \n\t\tput_page(page_info->page);\n\t\tskb->data_len = 0;\n\t\tskb->tail += curr_frag_len;\n\t} else {\n\t\thdr_len = ETH_HLEN;\n\t\tmemcpy(skb->data, start, hdr_len);\n\t\tskb_shinfo(skb)->nr_frags = 1;\n\t\tskb_frag_fill_page_desc(&skb_shinfo(skb)->frags[0],\n\t\t\t\t\tpage_info->page,\n\t\t\t\t\tpage_info->page_offset + hdr_len,\n\t\t\t\t\tcurr_frag_len - hdr_len);\n\t\tskb->data_len = curr_frag_len - hdr_len;\n\t\tskb->truesize += rx_frag_size;\n\t\tskb->tail += hdr_len;\n\t}\n\tpage_info->page = NULL;\n\n\tif (rxcp->pkt_size <= rx_frag_size) {\n\t\tBUG_ON(rxcp->num_rcvd != 1);\n\t\treturn;\n\t}\n\n\t \n\tremaining = rxcp->pkt_size - curr_frag_len;\n\tfor (i = 1, j = 0; i < rxcp->num_rcvd; i++) {\n\t\tpage_info = get_rx_page_info(rxo);\n\t\tcurr_frag_len = min(remaining, rx_frag_size);\n\n\t\t \n\t\tif (page_info->page_offset == 0) {\n\t\t\t \n\t\t\tj++;\n\t\t\tskb_frag_fill_page_desc(&skb_shinfo(skb)->frags[j],\n\t\t\t\t\t\tpage_info->page,\n\t\t\t\t\t\tpage_info->page_offset,\n\t\t\t\t\t\tcurr_frag_len);\n\t\t\tskb_shinfo(skb)->nr_frags++;\n\t\t} else {\n\t\t\tput_page(page_info->page);\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[j],\n\t\t\t\t\t  curr_frag_len);\n\t\t}\n\n\t\tskb->len += curr_frag_len;\n\t\tskb->data_len += curr_frag_len;\n\t\tskb->truesize += rx_frag_size;\n\t\tremaining -= curr_frag_len;\n\t\tpage_info->page = NULL;\n\t}\n\tBUG_ON(j > MAX_SKB_FRAGS);\n}\n\n \nstatic void be_rx_compl_process(struct be_rx_obj *rxo, struct napi_struct *napi,\n\t\t\t\tstruct be_rx_compl_info *rxcp)\n{\n\tstruct be_adapter *adapter = rxo->adapter;\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct sk_buff *skb;\n\n\tskb = netdev_alloc_skb_ip_align(netdev, BE_RX_SKB_ALLOC_SIZE);\n\tif (unlikely(!skb)) {\n\t\trx_stats(rxo)->rx_drops_no_skbs++;\n\t\tbe_rx_compl_discard(rxo, rxcp);\n\t\treturn;\n\t}\n\n\tskb_fill_rx_data(rxo, skb, rxcp);\n\n\tif (likely((netdev->features & NETIF_F_RXCSUM) && csum_passed(rxcp)))\n\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\telse\n\t\tskb_checksum_none_assert(skb);\n\n\tskb->protocol = eth_type_trans(skb, netdev);\n\tskb_record_rx_queue(skb, rxo - &adapter->rx_obj[0]);\n\tif (netdev->features & NETIF_F_RXHASH)\n\t\tskb_set_hash(skb, rxcp->rss_hash, PKT_HASH_TYPE_L3);\n\n\tskb->csum_level = rxcp->tunneled;\n\tskb_mark_napi_id(skb, napi);\n\n\tif (rxcp->vlanf)\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), rxcp->vlan_tag);\n\n\tnetif_receive_skb(skb);\n}\n\n \nstatic void be_rx_compl_process_gro(struct be_rx_obj *rxo,\n\t\t\t\t    struct napi_struct *napi,\n\t\t\t\t    struct be_rx_compl_info *rxcp)\n{\n\tstruct be_adapter *adapter = rxo->adapter;\n\tstruct be_rx_page_info *page_info;\n\tstruct sk_buff *skb = NULL;\n\tu16 remaining, curr_frag_len;\n\tu16 i, j;\n\n\tskb = napi_get_frags(napi);\n\tif (!skb) {\n\t\tbe_rx_compl_discard(rxo, rxcp);\n\t\treturn;\n\t}\n\n\tremaining = rxcp->pkt_size;\n\tfor (i = 0, j = -1; i < rxcp->num_rcvd; i++) {\n\t\tpage_info = get_rx_page_info(rxo);\n\n\t\tcurr_frag_len = min(remaining, rx_frag_size);\n\n\t\t \n\t\tif (i == 0 || page_info->page_offset == 0) {\n\t\t\t \n\t\t\tj++;\n\t\t\tskb_frag_fill_page_desc(&skb_shinfo(skb)->frags[j],\n\t\t\t\t\t\tpage_info->page,\n\t\t\t\t\t\tpage_info->page_offset,\n\t\t\t\t\t\tcurr_frag_len);\n\t\t} else {\n\t\t\tput_page(page_info->page);\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[j],\n\t\t\t\t\t  curr_frag_len);\n\t\t}\n\n\t\tskb->truesize += rx_frag_size;\n\t\tremaining -= curr_frag_len;\n\t\tmemset(page_info, 0, sizeof(*page_info));\n\t}\n\tBUG_ON(j > MAX_SKB_FRAGS);\n\n\tskb_shinfo(skb)->nr_frags = j + 1;\n\tskb->len = rxcp->pkt_size;\n\tskb->data_len = rxcp->pkt_size;\n\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\tskb_record_rx_queue(skb, rxo - &adapter->rx_obj[0]);\n\tif (adapter->netdev->features & NETIF_F_RXHASH)\n\t\tskb_set_hash(skb, rxcp->rss_hash, PKT_HASH_TYPE_L3);\n\n\tskb->csum_level = rxcp->tunneled;\n\n\tif (rxcp->vlanf)\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), rxcp->vlan_tag);\n\n\tnapi_gro_frags(napi);\n}\n\nstatic void be_parse_rx_compl_v1(struct be_eth_rx_compl *compl,\n\t\t\t\t struct be_rx_compl_info *rxcp)\n{\n\trxcp->pkt_size = GET_RX_COMPL_V1_BITS(pktsize, compl);\n\trxcp->vlanf = GET_RX_COMPL_V1_BITS(vtp, compl);\n\trxcp->err = GET_RX_COMPL_V1_BITS(err, compl);\n\trxcp->tcpf = GET_RX_COMPL_V1_BITS(tcpf, compl);\n\trxcp->udpf = GET_RX_COMPL_V1_BITS(udpf, compl);\n\trxcp->ip_csum = GET_RX_COMPL_V1_BITS(ipcksm, compl);\n\trxcp->l4_csum = GET_RX_COMPL_V1_BITS(l4_cksm, compl);\n\trxcp->ipv6 = GET_RX_COMPL_V1_BITS(ip_version, compl);\n\trxcp->num_rcvd = GET_RX_COMPL_V1_BITS(numfrags, compl);\n\trxcp->pkt_type = GET_RX_COMPL_V1_BITS(cast_enc, compl);\n\trxcp->rss_hash = GET_RX_COMPL_V1_BITS(rsshash, compl);\n\tif (rxcp->vlanf) {\n\t\trxcp->qnq = GET_RX_COMPL_V1_BITS(qnq, compl);\n\t\trxcp->vlan_tag = GET_RX_COMPL_V1_BITS(vlan_tag, compl);\n\t}\n\trxcp->port = GET_RX_COMPL_V1_BITS(port, compl);\n\trxcp->tunneled =\n\t\tGET_RX_COMPL_V1_BITS(tunneled, compl);\n}\n\nstatic void be_parse_rx_compl_v0(struct be_eth_rx_compl *compl,\n\t\t\t\t struct be_rx_compl_info *rxcp)\n{\n\trxcp->pkt_size = GET_RX_COMPL_V0_BITS(pktsize, compl);\n\trxcp->vlanf = GET_RX_COMPL_V0_BITS(vtp, compl);\n\trxcp->err = GET_RX_COMPL_V0_BITS(err, compl);\n\trxcp->tcpf = GET_RX_COMPL_V0_BITS(tcpf, compl);\n\trxcp->udpf = GET_RX_COMPL_V0_BITS(udpf, compl);\n\trxcp->ip_csum = GET_RX_COMPL_V0_BITS(ipcksm, compl);\n\trxcp->l4_csum = GET_RX_COMPL_V0_BITS(l4_cksm, compl);\n\trxcp->ipv6 = GET_RX_COMPL_V0_BITS(ip_version, compl);\n\trxcp->num_rcvd = GET_RX_COMPL_V0_BITS(numfrags, compl);\n\trxcp->pkt_type = GET_RX_COMPL_V0_BITS(cast_enc, compl);\n\trxcp->rss_hash = GET_RX_COMPL_V0_BITS(rsshash, compl);\n\tif (rxcp->vlanf) {\n\t\trxcp->qnq = GET_RX_COMPL_V0_BITS(qnq, compl);\n\t\trxcp->vlan_tag = GET_RX_COMPL_V0_BITS(vlan_tag, compl);\n\t}\n\trxcp->port = GET_RX_COMPL_V0_BITS(port, compl);\n\trxcp->ip_frag = GET_RX_COMPL_V0_BITS(ip_frag, compl);\n}\n\nstatic struct be_rx_compl_info *be_rx_compl_get(struct be_rx_obj *rxo)\n{\n\tstruct be_eth_rx_compl *compl = queue_tail_node(&rxo->cq);\n\tstruct be_rx_compl_info *rxcp = &rxo->rxcp;\n\tstruct be_adapter *adapter = rxo->adapter;\n\n\t \n\tif (compl->dw[offsetof(struct amap_eth_rx_compl_v1, valid) / 32] == 0)\n\t\treturn NULL;\n\n\trmb();\n\tbe_dws_le_to_cpu(compl, sizeof(*compl));\n\n\tif (adapter->be3_native)\n\t\tbe_parse_rx_compl_v1(compl, rxcp);\n\telse\n\t\tbe_parse_rx_compl_v0(compl, rxcp);\n\n\tif (rxcp->ip_frag)\n\t\trxcp->l4_csum = 0;\n\n\tif (rxcp->vlanf) {\n\t\t \n\t\tif (be_is_qnq_mode(adapter) && !rxcp->qnq)\n\t\t\trxcp->vlanf = 0;\n\n\t\tif (!lancer_chip(adapter))\n\t\t\trxcp->vlan_tag = swab16(rxcp->vlan_tag);\n\n\t\tif (adapter->pvid == (rxcp->vlan_tag & VLAN_VID_MASK) &&\n\t\t    !test_bit(rxcp->vlan_tag, adapter->vids))\n\t\t\trxcp->vlanf = 0;\n\t}\n\n\t \n\tcompl->dw[offsetof(struct amap_eth_rx_compl_v1, valid) / 32] = 0;\n\n\tqueue_tail_inc(&rxo->cq);\n\treturn rxcp;\n}\n\nstatic inline struct page *be_alloc_pages(u32 size, gfp_t gfp)\n{\n\tu32 order = get_order(size);\n\n\tif (order > 0)\n\t\tgfp |= __GFP_COMP;\n\treturn  alloc_pages(gfp, order);\n}\n\n \nstatic void be_post_rx_frags(struct be_rx_obj *rxo, gfp_t gfp, u32 frags_needed)\n{\n\tstruct be_adapter *adapter = rxo->adapter;\n\tstruct be_rx_page_info *page_info = NULL, *prev_page_info = NULL;\n\tstruct be_queue_info *rxq = &rxo->q;\n\tstruct page *pagep = NULL;\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct be_eth_rx_d *rxd;\n\tu64 page_dmaaddr = 0, frag_dmaaddr;\n\tu32 posted, page_offset = 0, notify = 0;\n\n\tpage_info = &rxo->page_info_tbl[rxq->head];\n\tfor (posted = 0; posted < frags_needed && !page_info->page; posted++) {\n\t\tif (!pagep) {\n\t\t\tpagep = be_alloc_pages(adapter->big_page_size, gfp);\n\t\t\tif (unlikely(!pagep)) {\n\t\t\t\trx_stats(rxo)->rx_post_fail++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpage_dmaaddr = dma_map_page(dev, pagep, 0,\n\t\t\t\t\t\t    adapter->big_page_size,\n\t\t\t\t\t\t    DMA_FROM_DEVICE);\n\t\t\tif (dma_mapping_error(dev, page_dmaaddr)) {\n\t\t\t\tput_page(pagep);\n\t\t\t\tpagep = NULL;\n\t\t\t\tadapter->drv_stats.dma_map_errors++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tpage_offset = 0;\n\t\t} else {\n\t\t\tget_page(pagep);\n\t\t\tpage_offset += rx_frag_size;\n\t\t}\n\t\tpage_info->page_offset = page_offset;\n\t\tpage_info->page = pagep;\n\n\t\trxd = queue_head_node(rxq);\n\t\tfrag_dmaaddr = page_dmaaddr + page_info->page_offset;\n\t\trxd->fragpa_lo = cpu_to_le32(frag_dmaaddr & 0xFFFFFFFF);\n\t\trxd->fragpa_hi = cpu_to_le32(upper_32_bits(frag_dmaaddr));\n\n\t\t \n\t\tif ((page_offset + rx_frag_size + rx_frag_size) >\n\t\t\t\t\tadapter->big_page_size) {\n\t\t\tpagep = NULL;\n\t\t\tpage_info->last_frag = true;\n\t\t\tdma_unmap_addr_set(page_info, bus, page_dmaaddr);\n\t\t} else {\n\t\t\tdma_unmap_addr_set(page_info, bus, frag_dmaaddr);\n\t\t}\n\n\t\tprev_page_info = page_info;\n\t\tqueue_head_inc(rxq);\n\t\tpage_info = &rxo->page_info_tbl[rxq->head];\n\t}\n\n\t \n\tif (pagep) {\n\t\tprev_page_info->last_frag = true;\n\t\tdma_unmap_addr_set(prev_page_info, bus, page_dmaaddr);\n\t}\n\n\tif (posted) {\n\t\tatomic_add(posted, &rxq->used);\n\t\tif (rxo->rx_post_starved)\n\t\t\trxo->rx_post_starved = false;\n\t\tdo {\n\t\t\tnotify = min(MAX_NUM_POST_ERX_DB, posted);\n\t\t\tbe_rxq_notify(adapter, rxq->id, notify);\n\t\t\tposted -= notify;\n\t\t} while (posted);\n\t} else if (atomic_read(&rxq->used) == 0) {\n\t\t \n\t\trxo->rx_post_starved = true;\n\t}\n}\n\nstatic inline void be_update_tx_err(struct be_tx_obj *txo, u8 status)\n{\n\tswitch (status) {\n\tcase BE_TX_COMP_HDR_PARSE_ERR:\n\t\ttx_stats(txo)->tx_hdr_parse_err++;\n\t\tbreak;\n\tcase BE_TX_COMP_NDMA_ERR:\n\t\ttx_stats(txo)->tx_dma_err++;\n\t\tbreak;\n\tcase BE_TX_COMP_ACL_ERR:\n\t\ttx_stats(txo)->tx_spoof_check_err++;\n\t\tbreak;\n\t}\n}\n\nstatic inline void lancer_update_tx_err(struct be_tx_obj *txo, u8 status)\n{\n\tswitch (status) {\n\tcase LANCER_TX_COMP_LSO_ERR:\n\t\ttx_stats(txo)->tx_tso_err++;\n\t\tbreak;\n\tcase LANCER_TX_COMP_HSW_DROP_MAC_ERR:\n\tcase LANCER_TX_COMP_HSW_DROP_VLAN_ERR:\n\t\ttx_stats(txo)->tx_spoof_check_err++;\n\t\tbreak;\n\tcase LANCER_TX_COMP_QINQ_ERR:\n\t\ttx_stats(txo)->tx_qinq_err++;\n\t\tbreak;\n\tcase LANCER_TX_COMP_PARITY_ERR:\n\t\ttx_stats(txo)->tx_internal_parity_err++;\n\t\tbreak;\n\tcase LANCER_TX_COMP_DMA_ERR:\n\t\ttx_stats(txo)->tx_dma_err++;\n\t\tbreak;\n\tcase LANCER_TX_COMP_SGE_ERR:\n\t\ttx_stats(txo)->tx_sge_err++;\n\t\tbreak;\n\t}\n}\n\nstatic struct be_tx_compl_info *be_tx_compl_get(struct be_adapter *adapter,\n\t\t\t\t\t\tstruct be_tx_obj *txo)\n{\n\tstruct be_queue_info *tx_cq = &txo->cq;\n\tstruct be_tx_compl_info *txcp = &txo->txcp;\n\tstruct be_eth_tx_compl *compl = queue_tail_node(tx_cq);\n\n\tif (compl->dw[offsetof(struct amap_eth_tx_compl, valid) / 32] == 0)\n\t\treturn NULL;\n\n\t \n\trmb();\n\tbe_dws_le_to_cpu(compl, sizeof(*compl));\n\n\ttxcp->status = GET_TX_COMPL_BITS(status, compl);\n\ttxcp->end_index = GET_TX_COMPL_BITS(wrb_index, compl);\n\n\tif (txcp->status) {\n\t\tif (lancer_chip(adapter)) {\n\t\t\tlancer_update_tx_err(txo, txcp->status);\n\t\t\t \n\t\t\tif (txcp->status == LANCER_TX_COMP_LSO_ERR ||\n\t\t\t    txcp->status == LANCER_TX_COMP_PARITY_ERR ||\n\t\t\t    txcp->status == LANCER_TX_COMP_SGE_ERR)\n\t\t\t\tbe_set_error(adapter, BE_ERROR_TX);\n\t\t} else {\n\t\t\tbe_update_tx_err(txo, txcp->status);\n\t\t}\n\t}\n\n\tif (be_check_error(adapter, BE_ERROR_TX))\n\t\treturn NULL;\n\n\tcompl->dw[offsetof(struct amap_eth_tx_compl, valid) / 32] = 0;\n\tqueue_tail_inc(tx_cq);\n\treturn txcp;\n}\n\nstatic u16 be_tx_compl_process(struct be_adapter *adapter,\n\t\t\t       struct be_tx_obj *txo, u16 last_index)\n{\n\tstruct sk_buff **sent_skbs = txo->sent_skb_list;\n\tstruct be_queue_info *txq = &txo->q;\n\tstruct sk_buff *skb = NULL;\n\tbool unmap_skb_hdr = false;\n\tstruct be_eth_wrb *wrb;\n\tu16 num_wrbs = 0;\n\tu32 frag_index;\n\n\tdo {\n\t\tif (sent_skbs[txq->tail]) {\n\t\t\t \n\t\t\tif (skb)\n\t\t\t\tdev_consume_skb_any(skb);\n\t\t\tskb = sent_skbs[txq->tail];\n\t\t\tsent_skbs[txq->tail] = NULL;\n\t\t\tqueue_tail_inc(txq);   \n\t\t\tnum_wrbs++;\n\t\t\tunmap_skb_hdr = true;\n\t\t}\n\t\twrb = queue_tail_node(txq);\n\t\tfrag_index = txq->tail;\n\t\tunmap_tx_frag(&adapter->pdev->dev, wrb,\n\t\t\t      (unmap_skb_hdr && skb_headlen(skb)));\n\t\tunmap_skb_hdr = false;\n\t\tqueue_tail_inc(txq);\n\t\tnum_wrbs++;\n\t} while (frag_index != last_index);\n\tdev_consume_skb_any(skb);\n\n\treturn num_wrbs;\n}\n\n \nstatic inline int events_get(struct be_eq_obj *eqo)\n{\n\tstruct be_eq_entry *eqe;\n\tint num = 0;\n\n\tdo {\n\t\teqe = queue_tail_node(&eqo->q);\n\t\tif (eqe->evt == 0)\n\t\t\tbreak;\n\n\t\trmb();\n\t\teqe->evt = 0;\n\t\tnum++;\n\t\tqueue_tail_inc(&eqo->q);\n\t} while (true);\n\n\treturn num;\n}\n\n \nstatic void be_eq_clean(struct be_eq_obj *eqo)\n{\n\tint num = events_get(eqo);\n\n\tbe_eq_notify(eqo->adapter, eqo->q.id, false, true, num, 0);\n}\n\n \nstatic void be_rxq_clean(struct be_rx_obj *rxo)\n{\n\tstruct be_queue_info *rxq = &rxo->q;\n\tstruct be_rx_page_info *page_info;\n\n\twhile (atomic_read(&rxq->used) > 0) {\n\t\tpage_info = get_rx_page_info(rxo);\n\t\tput_page(page_info->page);\n\t\tmemset(page_info, 0, sizeof(*page_info));\n\t}\n\tBUG_ON(atomic_read(&rxq->used));\n\trxq->tail = 0;\n\trxq->head = 0;\n}\n\nstatic void be_rx_cq_clean(struct be_rx_obj *rxo)\n{\n\tstruct be_queue_info *rx_cq = &rxo->cq;\n\tstruct be_rx_compl_info *rxcp;\n\tstruct be_adapter *adapter = rxo->adapter;\n\tint flush_wait = 0;\n\n\t \n\tfor (;;) {\n\t\trxcp = be_rx_compl_get(rxo);\n\t\tif (!rxcp) {\n\t\t\tif (lancer_chip(adapter))\n\t\t\t\tbreak;\n\n\t\t\tif (flush_wait++ > 50 ||\n\t\t\t    be_check_error(adapter,\n\t\t\t\t\t   BE_ERROR_HW)) {\n\t\t\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t\t\t \"did not receive flush compl\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbe_cq_notify(adapter, rx_cq->id, true, 0);\n\t\t\tmdelay(1);\n\t\t} else {\n\t\t\tbe_rx_compl_discard(rxo, rxcp);\n\t\t\tbe_cq_notify(adapter, rx_cq->id, false, 1);\n\t\t\tif (rxcp->num_rcvd == 0)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\t \n\tbe_cq_notify(adapter, rx_cq->id, false, 0);\n}\n\nstatic void be_tx_compl_clean(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tu16 cmpl = 0, timeo = 0, num_wrbs = 0;\n\tstruct be_tx_compl_info *txcp;\n\tstruct be_queue_info *txq;\n\tu32 end_idx, notified_idx;\n\tstruct be_tx_obj *txo;\n\tint i, pending_txqs;\n\n\t \n\tdo {\n\t\tpending_txqs = adapter->num_tx_qs;\n\n\t\tfor_all_tx_queues(adapter, txo, i) {\n\t\t\tcmpl = 0;\n\t\t\tnum_wrbs = 0;\n\t\t\ttxq = &txo->q;\n\t\t\twhile ((txcp = be_tx_compl_get(adapter, txo))) {\n\t\t\t\tnum_wrbs +=\n\t\t\t\t\tbe_tx_compl_process(adapter, txo,\n\t\t\t\t\t\t\t    txcp->end_index);\n\t\t\t\tcmpl++;\n\t\t\t}\n\t\t\tif (cmpl) {\n\t\t\t\tbe_cq_notify(adapter, txo->cq.id, false, cmpl);\n\t\t\t\tatomic_sub(num_wrbs, &txq->used);\n\t\t\t\ttimeo = 0;\n\t\t\t}\n\t\t\tif (!be_is_tx_compl_pending(txo))\n\t\t\t\tpending_txqs--;\n\t\t}\n\n\t\tif (pending_txqs == 0 || ++timeo > 10 ||\n\t\t    be_check_error(adapter, BE_ERROR_HW))\n\t\t\tbreak;\n\n\t\tmdelay(1);\n\t} while (true);\n\n\t \n\tfor_all_tx_queues(adapter, txo, i) {\n\t\ttxq = &txo->q;\n\n\t\tif (atomic_read(&txq->used)) {\n\t\t\tdev_info(dev, \"txq%d: cleaning %d pending tx-wrbs\\n\",\n\t\t\t\t i, atomic_read(&txq->used));\n\t\t\tnotified_idx = txq->tail;\n\t\t\tend_idx = txq->tail;\n\t\t\tindex_adv(&end_idx, atomic_read(&txq->used) - 1,\n\t\t\t\t  txq->len);\n\t\t\t \n\t\t\tnum_wrbs = be_tx_compl_process(adapter, txo, end_idx);\n\t\t\tatomic_sub(num_wrbs, &txq->used);\n\t\t\tBUG_ON(atomic_read(&txq->used));\n\t\t\ttxo->pend_wrb_cnt = 0;\n\t\t\t \n\t\t\ttxq->head = notified_idx;\n\t\t\ttxq->tail = notified_idx;\n\t\t}\n\t}\n}\n\nstatic void be_evt_queues_destroy(struct be_adapter *adapter)\n{\n\tstruct be_eq_obj *eqo;\n\tint i;\n\n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\tif (eqo->q.created) {\n\t\t\tbe_eq_clean(eqo);\n\t\t\tbe_cmd_q_destroy(adapter, &eqo->q, QTYPE_EQ);\n\t\t\tnetif_napi_del(&eqo->napi);\n\t\t\tfree_cpumask_var(eqo->affinity_mask);\n\t\t}\n\t\tbe_queue_free(adapter, &eqo->q);\n\t}\n}\n\nstatic int be_evt_queues_create(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *eq;\n\tstruct be_eq_obj *eqo;\n\tstruct be_aic_obj *aic;\n\tint i, rc;\n\n\t \n\tadapter->num_evt_qs = min_t(u16, num_irqs(adapter),\n\t\t\t\t    max(adapter->cfg_num_rx_irqs,\n\t\t\t\t\tadapter->cfg_num_tx_irqs));\n\n\tadapter->aic_enabled = true;\n\n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\tint numa_node = dev_to_node(&adapter->pdev->dev);\n\n\t\taic = &adapter->aic_obj[i];\n\t\teqo->adapter = adapter;\n\t\teqo->idx = i;\n\t\taic->max_eqd = BE_MAX_EQD;\n\n\t\teq = &eqo->q;\n\t\trc = be_queue_alloc(adapter, eq, EVNT_Q_LEN,\n\t\t\t\t    sizeof(struct be_eq_entry));\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\trc = be_cmd_eq_create(adapter, eqo);\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tif (!zalloc_cpumask_var(&eqo->affinity_mask, GFP_KERNEL))\n\t\t\treturn -ENOMEM;\n\t\tcpumask_set_cpu(cpumask_local_spread(i, numa_node),\n\t\t\t\teqo->affinity_mask);\n\t\tnetif_napi_add(adapter->netdev, &eqo->napi, be_poll);\n\t}\n\treturn 0;\n}\n\nstatic void be_mcc_queues_destroy(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *q;\n\n\tq = &adapter->mcc_obj.q;\n\tif (q->created)\n\t\tbe_cmd_q_destroy(adapter, q, QTYPE_MCCQ);\n\tbe_queue_free(adapter, q);\n\n\tq = &adapter->mcc_obj.cq;\n\tif (q->created)\n\t\tbe_cmd_q_destroy(adapter, q, QTYPE_CQ);\n\tbe_queue_free(adapter, q);\n}\n\n \nstatic int be_mcc_queues_create(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *q, *cq;\n\n\tcq = &adapter->mcc_obj.cq;\n\tif (be_queue_alloc(adapter, cq, MCC_CQ_LEN,\n\t\t\t   sizeof(struct be_mcc_compl)))\n\t\tgoto err;\n\n\t \n\tif (be_cmd_cq_create(adapter, cq, &mcc_eqo(adapter)->q, true, 0))\n\t\tgoto mcc_cq_free;\n\n\tq = &adapter->mcc_obj.q;\n\tif (be_queue_alloc(adapter, q, MCC_Q_LEN, sizeof(struct be_mcc_wrb)))\n\t\tgoto mcc_cq_destroy;\n\n\tif (be_cmd_mccq_create(adapter, q, cq))\n\t\tgoto mcc_q_free;\n\n\treturn 0;\n\nmcc_q_free:\n\tbe_queue_free(adapter, q);\nmcc_cq_destroy:\n\tbe_cmd_q_destroy(adapter, cq, QTYPE_CQ);\nmcc_cq_free:\n\tbe_queue_free(adapter, cq);\nerr:\n\treturn -1;\n}\n\nstatic void be_tx_queues_destroy(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *q;\n\tstruct be_tx_obj *txo;\n\tu8 i;\n\n\tfor_all_tx_queues(adapter, txo, i) {\n\t\tq = &txo->q;\n\t\tif (q->created)\n\t\t\tbe_cmd_q_destroy(adapter, q, QTYPE_TXQ);\n\t\tbe_queue_free(adapter, q);\n\n\t\tq = &txo->cq;\n\t\tif (q->created)\n\t\t\tbe_cmd_q_destroy(adapter, q, QTYPE_CQ);\n\t\tbe_queue_free(adapter, q);\n\t}\n}\n\nstatic int be_tx_qs_create(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *cq;\n\tstruct be_tx_obj *txo;\n\tstruct be_eq_obj *eqo;\n\tint status, i;\n\n\tadapter->num_tx_qs = min(adapter->num_evt_qs, adapter->cfg_num_tx_irqs);\n\n\tfor_all_tx_queues(adapter, txo, i) {\n\t\tcq = &txo->cq;\n\t\tstatus = be_queue_alloc(adapter, cq, TX_CQ_LEN,\n\t\t\t\t\tsizeof(struct be_eth_tx_compl));\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tu64_stats_init(&txo->stats.sync);\n\t\tu64_stats_init(&txo->stats.sync_compl);\n\n\t\t \n\t\teqo = &adapter->eq_obj[i % adapter->num_evt_qs];\n\t\tstatus = be_cmd_cq_create(adapter, cq, &eqo->q, false, 3);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tstatus = be_queue_alloc(adapter, &txo->q, TX_Q_LEN,\n\t\t\t\t\tsizeof(struct be_eth_wrb));\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tstatus = be_cmd_txq_create(adapter, txo);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\tnetif_set_xps_queue(adapter->netdev, eqo->affinity_mask,\n\t\t\t\t    eqo->idx);\n\t}\n\n\tdev_info(&adapter->pdev->dev, \"created %d TX queue(s)\\n\",\n\t\t adapter->num_tx_qs);\n\treturn 0;\n}\n\nstatic void be_rx_cqs_destroy(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *q;\n\tstruct be_rx_obj *rxo;\n\tint i;\n\n\tfor_all_rx_queues(adapter, rxo, i) {\n\t\tq = &rxo->cq;\n\t\tif (q->created)\n\t\t\tbe_cmd_q_destroy(adapter, q, QTYPE_CQ);\n\t\tbe_queue_free(adapter, q);\n\t}\n}\n\nstatic int be_rx_cqs_create(struct be_adapter *adapter)\n{\n\tstruct be_queue_info *eq, *cq;\n\tstruct be_rx_obj *rxo;\n\tint rc, i;\n\n\tadapter->num_rss_qs =\n\t\t\tmin(adapter->num_evt_qs, adapter->cfg_num_rx_irqs);\n\n\t \n\tif (adapter->num_rss_qs < 2)\n\t\tadapter->num_rss_qs = 0;\n\n\tadapter->num_rx_qs = adapter->num_rss_qs + adapter->need_def_rxq;\n\n\t \n\tif (adapter->num_rx_qs == 0)\n\t\tadapter->num_rx_qs = 1;\n\n\tadapter->big_page_size = (1 << get_order(rx_frag_size)) * PAGE_SIZE;\n\tfor_all_rx_queues(adapter, rxo, i) {\n\t\trxo->adapter = adapter;\n\t\tcq = &rxo->cq;\n\t\trc = be_queue_alloc(adapter, cq, RX_CQ_LEN,\n\t\t\t\t    sizeof(struct be_eth_rx_compl));\n\t\tif (rc)\n\t\t\treturn rc;\n\n\t\tu64_stats_init(&rxo->stats.sync);\n\t\teq = &adapter->eq_obj[i % adapter->num_evt_qs].q;\n\t\trc = be_cmd_cq_create(adapter, cq, eq, false, 3);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tdev_info(&adapter->pdev->dev,\n\t\t \"created %d RX queue(s)\\n\", adapter->num_rx_qs);\n\treturn 0;\n}\n\nstatic irqreturn_t be_intx(int irq, void *dev)\n{\n\tstruct be_eq_obj *eqo = dev;\n\tstruct be_adapter *adapter = eqo->adapter;\n\tint num_evts = 0;\n\n\t \n\tif (napi_schedule_prep(&eqo->napi)) {\n\t\tnum_evts = events_get(eqo);\n\t\t__napi_schedule(&eqo->napi);\n\t\tif (num_evts)\n\t\t\teqo->spurious_intr = 0;\n\t}\n\tbe_eq_notify(adapter, eqo->q.id, false, true, num_evts, 0);\n\n\t \n\tif (num_evts || eqo->spurious_intr++ == 0)\n\t\treturn IRQ_HANDLED;\n\telse\n\t\treturn IRQ_NONE;\n}\n\nstatic irqreturn_t be_msix(int irq, void *dev)\n{\n\tstruct be_eq_obj *eqo = dev;\n\n\tbe_eq_notify(eqo->adapter, eqo->q.id, false, true, 0, 0);\n\tnapi_schedule(&eqo->napi);\n\treturn IRQ_HANDLED;\n}\n\nstatic inline bool do_gro(struct be_rx_compl_info *rxcp)\n{\n\treturn (rxcp->tcpf && !rxcp->err && rxcp->l4_csum) ? true : false;\n}\n\nstatic int be_process_rx(struct be_rx_obj *rxo, struct napi_struct *napi,\n\t\t\t int budget)\n{\n\tstruct be_adapter *adapter = rxo->adapter;\n\tstruct be_queue_info *rx_cq = &rxo->cq;\n\tstruct be_rx_compl_info *rxcp;\n\tu32 work_done;\n\tu32 frags_consumed = 0;\n\n\tfor (work_done = 0; work_done < budget; work_done++) {\n\t\trxcp = be_rx_compl_get(rxo);\n\t\tif (!rxcp)\n\t\t\tbreak;\n\n\t\t \n\t\tif (unlikely(rxcp->num_rcvd == 0))\n\t\t\tgoto loop_continue;\n\n\t\t \n\t\tif (unlikely(!rxcp->pkt_size)) {\n\t\t\tbe_rx_compl_discard(rxo, rxcp);\n\t\t\tgoto loop_continue;\n\t\t}\n\n\t\t \n\t\tif (unlikely(rxcp->port != adapter->port_num &&\n\t\t\t     !lancer_chip(adapter))) {\n\t\t\tbe_rx_compl_discard(rxo, rxcp);\n\t\t\tgoto loop_continue;\n\t\t}\n\n\t\tif (do_gro(rxcp))\n\t\t\tbe_rx_compl_process_gro(rxo, napi, rxcp);\n\t\telse\n\t\t\tbe_rx_compl_process(rxo, napi, rxcp);\n\nloop_continue:\n\t\tfrags_consumed += rxcp->num_rcvd;\n\t\tbe_rx_stats_update(rxo, rxcp);\n\t}\n\n\tif (work_done) {\n\t\tbe_cq_notify(adapter, rx_cq->id, true, work_done);\n\n\t\t \n\t\tif (atomic_read(&rxo->q.used) < RX_FRAGS_REFILL_WM &&\n\t\t    !rxo->rx_post_starved)\n\t\t\tbe_post_rx_frags(rxo, GFP_ATOMIC,\n\t\t\t\t\t max_t(u32, MAX_RX_POST,\n\t\t\t\t\t       frags_consumed));\n\t}\n\n\treturn work_done;\n}\n\n\nstatic void be_process_tx(struct be_adapter *adapter, struct be_tx_obj *txo,\n\t\t\t  int idx)\n{\n\tint num_wrbs = 0, work_done = 0;\n\tstruct be_tx_compl_info *txcp;\n\n\twhile ((txcp = be_tx_compl_get(adapter, txo))) {\n\t\tnum_wrbs += be_tx_compl_process(adapter, txo, txcp->end_index);\n\t\twork_done++;\n\t}\n\n\tif (work_done) {\n\t\tbe_cq_notify(adapter, txo->cq.id, true, work_done);\n\t\tatomic_sub(num_wrbs, &txo->q.used);\n\n\t\t \n\t\tif (__netif_subqueue_stopped(adapter->netdev, idx) &&\n\t\t    be_can_txq_wake(txo)) {\n\t\t\tnetif_wake_subqueue(adapter->netdev, idx);\n\t\t}\n\n\t\tu64_stats_update_begin(&tx_stats(txo)->sync_compl);\n\t\ttx_stats(txo)->tx_compl += work_done;\n\t\tu64_stats_update_end(&tx_stats(txo)->sync_compl);\n\t}\n}\n\nint be_poll(struct napi_struct *napi, int budget)\n{\n\tstruct be_eq_obj *eqo = container_of(napi, struct be_eq_obj, napi);\n\tstruct be_adapter *adapter = eqo->adapter;\n\tint max_work = 0, work, i, num_evts;\n\tstruct be_rx_obj *rxo;\n\tstruct be_tx_obj *txo;\n\tu32 mult_enc = 0;\n\n\tnum_evts = events_get(eqo);\n\n\tfor_all_tx_queues_on_eq(adapter, eqo, txo, i)\n\t\tbe_process_tx(adapter, txo, i);\n\n\t \n\tfor_all_rx_queues_on_eq(adapter, eqo, rxo, i) {\n\t\twork = be_process_rx(rxo, napi, budget);\n\t\tmax_work = max(work, max_work);\n\t}\n\n\tif (is_mcc_eqo(eqo))\n\t\tbe_process_mcc(adapter);\n\n\tif (max_work < budget) {\n\t\tnapi_complete_done(napi, max_work);\n\n\t\t \n\t\tif (skyhawk_chip(adapter))\n\t\t\tmult_enc = be_get_eq_delay_mult_enc(eqo);\n\n\t\tbe_eq_notify(adapter, eqo->q.id, true, false, num_evts,\n\t\t\t     mult_enc);\n\t} else {\n\t\t \n\t\tbe_eq_notify(adapter, eqo->q.id, false, false, num_evts, 0);\n\t}\n\treturn max_work;\n}\n\nvoid be_detect_error(struct be_adapter *adapter)\n{\n\tu32 ue_lo = 0, ue_hi = 0, ue_lo_mask = 0, ue_hi_mask = 0;\n\tu32 sliport_status = 0, sliport_err1 = 0, sliport_err2 = 0;\n\tstruct device *dev = &adapter->pdev->dev;\n\tu16 val;\n\tu32 i;\n\n\tif (be_check_error(adapter, BE_ERROR_HW))\n\t\treturn;\n\n\tif (lancer_chip(adapter)) {\n\t\tsliport_status = ioread32(adapter->db + SLIPORT_STATUS_OFFSET);\n\t\tif (sliport_status & SLIPORT_STATUS_ERR_MASK) {\n\t\t\tbe_set_error(adapter, BE_ERROR_UE);\n\t\t\tsliport_err1 = ioread32(adapter->db +\n\t\t\t\t\t\tSLIPORT_ERROR1_OFFSET);\n\t\t\tsliport_err2 = ioread32(adapter->db +\n\t\t\t\t\t\tSLIPORT_ERROR2_OFFSET);\n\t\t\t \n\t\t\tif (sliport_err1 == SLIPORT_ERROR_FW_RESET1 &&\n\t\t\t    sliport_err2 == SLIPORT_ERROR_FW_RESET2) {\n\t\t\t\tdev_info(dev, \"Reset is in progress\\n\");\n\t\t\t} else {\n\t\t\t\tdev_err(dev, \"Error detected in the card\\n\");\n\t\t\t\tdev_err(dev, \"ERR: sliport status 0x%x\\n\",\n\t\t\t\t\tsliport_status);\n\t\t\t\tdev_err(dev, \"ERR: sliport error1 0x%x\\n\",\n\t\t\t\t\tsliport_err1);\n\t\t\t\tdev_err(dev, \"ERR: sliport error2 0x%x\\n\",\n\t\t\t\t\tsliport_err2);\n\t\t\t}\n\t\t}\n\t} else {\n\t\tue_lo = ioread32(adapter->pcicfg + PCICFG_UE_STATUS_LOW);\n\t\tue_hi = ioread32(adapter->pcicfg + PCICFG_UE_STATUS_HIGH);\n\t\tue_lo_mask = ioread32(adapter->pcicfg +\n\t\t\t\t      PCICFG_UE_STATUS_LOW_MASK);\n\t\tue_hi_mask = ioread32(adapter->pcicfg +\n\t\t\t\t      PCICFG_UE_STATUS_HI_MASK);\n\n\t\tue_lo = (ue_lo & ~ue_lo_mask);\n\t\tue_hi = (ue_hi & ~ue_hi_mask);\n\n\t\tif (ue_lo || ue_hi) {\n\t\t\t \n\t\t\tif (BE3_chip(adapter)) {\n\t\t\t\tval = be_POST_stage_get(adapter);\n\t\t\t\tif ((val & POST_STAGE_FAT_LOG_START)\n\t\t\t\t     != POST_STAGE_FAT_LOG_START &&\n\t\t\t\t    (val & POST_STAGE_ARMFW_UE)\n\t\t\t\t     != POST_STAGE_ARMFW_UE &&\n\t\t\t\t    (val & POST_STAGE_RECOVERABLE_ERR)\n\t\t\t\t     != POST_STAGE_RECOVERABLE_ERR)\n\t\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tdev_err(dev, \"Error detected in the adapter\");\n\t\t\tbe_set_error(adapter, BE_ERROR_UE);\n\n\t\t\tfor (i = 0; ue_lo; ue_lo >>= 1, i++) {\n\t\t\t\tif (ue_lo & 1)\n\t\t\t\t\tdev_err(dev, \"UE: %s bit set\\n\",\n\t\t\t\t\t\tue_status_low_desc[i]);\n\t\t\t}\n\t\t\tfor (i = 0; ue_hi; ue_hi >>= 1, i++) {\n\t\t\t\tif (ue_hi & 1)\n\t\t\t\t\tdev_err(dev, \"UE: %s bit set\\n\",\n\t\t\t\t\t\tue_status_hi_desc[i]);\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void be_msix_disable(struct be_adapter *adapter)\n{\n\tif (msix_enabled(adapter)) {\n\t\tpci_disable_msix(adapter->pdev);\n\t\tadapter->num_msix_vec = 0;\n\t\tadapter->num_msix_roce_vec = 0;\n\t}\n}\n\nstatic int be_msix_enable(struct be_adapter *adapter)\n{\n\tunsigned int i, max_roce_eqs;\n\tstruct device *dev = &adapter->pdev->dev;\n\tint num_vec;\n\n\t \n\tif (be_roce_supported(adapter)) {\n\t\tmax_roce_eqs =\n\t\t\tbe_max_func_eqs(adapter) - be_max_nic_eqs(adapter);\n\t\tmax_roce_eqs = min(max_roce_eqs, num_online_cpus());\n\t\tnum_vec = be_max_any_irqs(adapter) + max_roce_eqs;\n\t} else {\n\t\tnum_vec = max(adapter->cfg_num_rx_irqs,\n\t\t\t      adapter->cfg_num_tx_irqs);\n\t}\n\n\tfor (i = 0; i < num_vec; i++)\n\t\tadapter->msix_entries[i].entry = i;\n\n\tnum_vec = pci_enable_msix_range(adapter->pdev, adapter->msix_entries,\n\t\t\t\t\tMIN_MSIX_VECTORS, num_vec);\n\tif (num_vec < 0)\n\t\tgoto fail;\n\n\tif (be_roce_supported(adapter) && num_vec > MIN_MSIX_VECTORS) {\n\t\tadapter->num_msix_roce_vec = num_vec / 2;\n\t\tdev_info(dev, \"enabled %d MSI-x vector(s) for RoCE\\n\",\n\t\t\t adapter->num_msix_roce_vec);\n\t}\n\n\tadapter->num_msix_vec = num_vec - adapter->num_msix_roce_vec;\n\n\tdev_info(dev, \"enabled %d MSI-x vector(s) for NIC\\n\",\n\t\t adapter->num_msix_vec);\n\treturn 0;\n\nfail:\n\tdev_warn(dev, \"MSIx enable failed\\n\");\n\n\t \n\tif (be_virtfn(adapter))\n\t\treturn num_vec;\n\treturn 0;\n}\n\nstatic inline int be_msix_vec_get(struct be_adapter *adapter,\n\t\t\t\t  struct be_eq_obj *eqo)\n{\n\treturn adapter->msix_entries[eqo->msix_idx].vector;\n}\n\nstatic int be_msix_register(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct be_eq_obj *eqo;\n\tint status, i, vec;\n\n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\tsprintf(eqo->desc, \"%s-q%d\", netdev->name, i);\n\t\tvec = be_msix_vec_get(adapter, eqo);\n\t\tstatus = request_irq(vec, be_msix, 0, eqo->desc, eqo);\n\t\tif (status)\n\t\t\tgoto err_msix;\n\n\t\tirq_update_affinity_hint(vec, eqo->affinity_mask);\n\t}\n\n\treturn 0;\nerr_msix:\n\tfor (i--; i >= 0; i--) {\n\t\teqo = &adapter->eq_obj[i];\n\t\tfree_irq(be_msix_vec_get(adapter, eqo), eqo);\n\t}\n\tdev_warn(&adapter->pdev->dev, \"MSIX Request IRQ failed - err %d\\n\",\n\t\t status);\n\tbe_msix_disable(adapter);\n\treturn status;\n}\n\nstatic int be_irq_register(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint status;\n\n\tif (msix_enabled(adapter)) {\n\t\tstatus = be_msix_register(adapter);\n\t\tif (status == 0)\n\t\t\tgoto done;\n\t\t \n\t\tif (be_virtfn(adapter))\n\t\t\treturn status;\n\t}\n\n\t \n\tnetdev->irq = adapter->pdev->irq;\n\tstatus = request_irq(netdev->irq, be_intx, IRQF_SHARED, netdev->name,\n\t\t\t     &adapter->eq_obj[0]);\n\tif (status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"INTx request IRQ failed - err %d\\n\", status);\n\t\treturn status;\n\t}\ndone:\n\tadapter->isr_registered = true;\n\treturn 0;\n}\n\nstatic void be_irq_unregister(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tstruct be_eq_obj *eqo;\n\tint i, vec;\n\n\tif (!adapter->isr_registered)\n\t\treturn;\n\n\t \n\tif (!msix_enabled(adapter)) {\n\t\tfree_irq(netdev->irq, &adapter->eq_obj[0]);\n\t\tgoto done;\n\t}\n\n\t \n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\tvec = be_msix_vec_get(adapter, eqo);\n\t\tirq_update_affinity_hint(vec, NULL);\n\t\tfree_irq(vec, eqo);\n\t}\n\ndone:\n\tadapter->isr_registered = false;\n}\n\nstatic void be_rx_qs_destroy(struct be_adapter *adapter)\n{\n\tstruct rss_info *rss = &adapter->rss_info;\n\tstruct be_queue_info *q;\n\tstruct be_rx_obj *rxo;\n\tint i;\n\n\tfor_all_rx_queues(adapter, rxo, i) {\n\t\tq = &rxo->q;\n\t\tif (q->created) {\n\t\t\t \n\t\t\tif (lancer_chip(adapter)) {\n\t\t\t\tbe_rx_cq_clean(rxo);\n\t\t\t\tif (atomic_read(&q->used) == 0)\n\t\t\t\t\tbe_post_rx_frags(rxo, GFP_KERNEL,\n\t\t\t\t\t\t\t MAX_RX_POST);\n\t\t\t}\n\n\t\t\tbe_cmd_rxq_destroy(adapter, q);\n\t\t\tbe_rx_cq_clean(rxo);\n\t\t\tbe_rxq_clean(rxo);\n\t\t}\n\t\tbe_queue_free(adapter, q);\n\t}\n\n\tif (rss->rss_flags) {\n\t\trss->rss_flags = RSS_ENABLE_NONE;\n\t\tbe_cmd_rss_config(adapter, rss->rsstable, rss->rss_flags,\n\t\t\t\t  128, rss->rss_hkey);\n\t}\n}\n\nstatic void be_disable_if_filters(struct be_adapter *adapter)\n{\n\t \n\tif (!BEx_chip(adapter) || !be_virtfn(adapter) ||\n\t    check_privilege(adapter, BE_PRIV_FILTMGMT)) {\n\t\tbe_dev_mac_del(adapter, adapter->pmac_id[0]);\n\t\teth_zero_addr(adapter->dev_mac);\n\t}\n\n\tbe_clear_uc_list(adapter);\n\tbe_clear_mc_list(adapter);\n\n\t \n\tif (lancer_chip(adapter)) {\n\t\tbe_cmd_rx_filter(adapter, BE_IF_ALL_FILT_FLAGS, OFF);\n\t\tadapter->if_flags &= ~BE_IF_ALL_FILT_FLAGS;\n\t}\n}\n\nstatic int be_close(struct net_device *netdev)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_eq_obj *eqo;\n\tint i;\n\n\t \n\tif (!(adapter->flags & BE_FLAGS_SETUP_DONE))\n\t\treturn 0;\n\n\t \n\tflush_workqueue(be_wq);\n\n\tbe_disable_if_filters(adapter);\n\n\tif (adapter->flags & BE_FLAGS_NAPI_ENABLED) {\n\t\tfor_all_evt_queues(adapter, eqo, i) {\n\t\t\tnapi_disable(&eqo->napi);\n\t\t}\n\t\tadapter->flags &= ~BE_FLAGS_NAPI_ENABLED;\n\t}\n\n\tbe_async_mcc_disable(adapter);\n\n\t \n\tnetif_tx_disable(netdev);\n\tbe_tx_compl_clean(adapter);\n\n\tbe_rx_qs_destroy(adapter);\n\n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\tif (msix_enabled(adapter))\n\t\t\tsynchronize_irq(be_msix_vec_get(adapter, eqo));\n\t\telse\n\t\t\tsynchronize_irq(netdev->irq);\n\t\tbe_eq_clean(eqo);\n\t}\n\n\tbe_irq_unregister(adapter);\n\n\treturn 0;\n}\n\nstatic int be_rx_qs_create(struct be_adapter *adapter)\n{\n\tstruct rss_info *rss = &adapter->rss_info;\n\tu8 rss_key[RSS_HASH_KEY_LEN];\n\tstruct be_rx_obj *rxo;\n\tint rc, i, j;\n\n\tfor_all_rx_queues(adapter, rxo, i) {\n\t\trc = be_queue_alloc(adapter, &rxo->q, RX_Q_LEN,\n\t\t\t\t    sizeof(struct be_eth_rx_d));\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tif (adapter->need_def_rxq || !adapter->num_rss_qs) {\n\t\trxo = default_rxo(adapter);\n\t\trc = be_cmd_rxq_create(adapter, &rxo->q, rxo->cq.id,\n\t\t\t\t       rx_frag_size, adapter->if_handle,\n\t\t\t\t       false, &rxo->rss_id);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tfor_all_rss_queues(adapter, rxo, i) {\n\t\trc = be_cmd_rxq_create(adapter, &rxo->q, rxo->cq.id,\n\t\t\t\t       rx_frag_size, adapter->if_handle,\n\t\t\t\t       true, &rxo->rss_id);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\n\tif (be_multi_rxq(adapter)) {\n\t\tfor (j = 0; j < RSS_INDIR_TABLE_LEN; j += adapter->num_rss_qs) {\n\t\t\tfor_all_rss_queues(adapter, rxo, i) {\n\t\t\t\tif ((j + i) >= RSS_INDIR_TABLE_LEN)\n\t\t\t\t\tbreak;\n\t\t\t\trss->rsstable[j + i] = rxo->rss_id;\n\t\t\t\trss->rss_queue[j + i] = i;\n\t\t\t}\n\t\t}\n\t\trss->rss_flags = RSS_ENABLE_TCP_IPV4 | RSS_ENABLE_IPV4 |\n\t\t\tRSS_ENABLE_TCP_IPV6 | RSS_ENABLE_IPV6;\n\n\t\tif (!BEx_chip(adapter))\n\t\t\trss->rss_flags |= RSS_ENABLE_UDP_IPV4 |\n\t\t\t\tRSS_ENABLE_UDP_IPV6;\n\n\t\tnetdev_rss_key_fill(rss_key, RSS_HASH_KEY_LEN);\n\t\trc = be_cmd_rss_config(adapter, rss->rsstable, rss->rss_flags,\n\t\t\t\t       RSS_INDIR_TABLE_LEN, rss_key);\n\t\tif (rc) {\n\t\t\trss->rss_flags = RSS_ENABLE_NONE;\n\t\t\treturn rc;\n\t\t}\n\n\t\tmemcpy(rss->rss_hkey, rss_key, RSS_HASH_KEY_LEN);\n\t} else {\n\t\t \n\t\trss->rss_flags = RSS_ENABLE_NONE;\n\t}\n\n\n\t \n\tfor_all_rx_queues(adapter, rxo, i)\n\t\tbe_post_rx_frags(rxo, GFP_KERNEL, RX_Q_LEN - 1);\n\n\treturn 0;\n}\n\nstatic int be_enable_if_filters(struct be_adapter *adapter)\n{\n\tint status;\n\n\tstatus = be_cmd_rx_filter(adapter, BE_IF_FILT_FLAGS_BASIC, ON);\n\tif (status)\n\t\treturn status;\n\n\t \n\tif (!ether_addr_equal(adapter->dev_mac, adapter->netdev->dev_addr)) {\n\t\tint old_pmac_id = -1;\n\n\t\t \n\t\tif (!is_zero_ether_addr(adapter->dev_mac))\n\t\t\told_pmac_id = adapter->pmac_id[0];\n\n\t\tstatus = be_dev_mac_add(adapter, adapter->netdev->dev_addr);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\t \n\t\tif (old_pmac_id >= 0 && old_pmac_id != adapter->pmac_id[0])\n\t\t\tbe_dev_mac_del(adapter, old_pmac_id);\n\n\t\tether_addr_copy(adapter->dev_mac, adapter->netdev->dev_addr);\n\t}\n\n\tif (adapter->vlans_added)\n\t\tbe_vid_config(adapter);\n\n\t__be_set_rx_mode(adapter);\n\n\treturn 0;\n}\n\nstatic int be_open(struct net_device *netdev)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_eq_obj *eqo;\n\tstruct be_rx_obj *rxo;\n\tstruct be_tx_obj *txo;\n\tu8 link_status;\n\tint status, i;\n\n\tstatus = be_rx_qs_create(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = be_enable_if_filters(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = be_irq_register(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tfor_all_rx_queues(adapter, rxo, i)\n\t\tbe_cq_notify(adapter, rxo->cq.id, true, 0);\n\n\tfor_all_tx_queues(adapter, txo, i)\n\t\tbe_cq_notify(adapter, txo->cq.id, true, 0);\n\n\tbe_async_mcc_enable(adapter);\n\n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\tnapi_enable(&eqo->napi);\n\t\tbe_eq_notify(adapter, eqo->q.id, true, true, 0, 0);\n\t}\n\tadapter->flags |= BE_FLAGS_NAPI_ENABLED;\n\n\tstatus = be_cmd_link_status_query(adapter, NULL, &link_status, 0);\n\tif (!status)\n\t\tbe_link_status_update(adapter, link_status);\n\n\tnetif_tx_start_all_queues(netdev);\n\n\tudp_tunnel_nic_reset_ntf(netdev);\n\n\treturn 0;\nerr:\n\tbe_close(adapter->netdev);\n\treturn -EIO;\n}\n\nstatic void be_vf_eth_addr_generate(struct be_adapter *adapter, u8 *mac)\n{\n\tu32 addr;\n\n\taddr = jhash(adapter->netdev->dev_addr, ETH_ALEN, 0);\n\n\tmac[5] = (u8)(addr & 0xFF);\n\tmac[4] = (u8)((addr >> 8) & 0xFF);\n\tmac[3] = (u8)((addr >> 16) & 0xFF);\n\t \n\tmemcpy(mac, adapter->netdev->dev_addr, 3);\n}\n\n \nstatic int be_vf_eth_addr_config(struct be_adapter *adapter)\n{\n\tu32 vf;\n\tint status = 0;\n\tu8 mac[ETH_ALEN];\n\tstruct be_vf_cfg *vf_cfg;\n\n\tbe_vf_eth_addr_generate(adapter, mac);\n\n\tfor_all_vfs(adapter, vf_cfg, vf) {\n\t\tif (BEx_chip(adapter))\n\t\t\tstatus = be_cmd_pmac_add(adapter, mac,\n\t\t\t\t\t\t vf_cfg->if_handle,\n\t\t\t\t\t\t &vf_cfg->pmac_id, vf + 1);\n\t\telse\n\t\t\tstatus = be_cmd_set_mac(adapter, mac, vf_cfg->if_handle,\n\t\t\t\t\t\tvf + 1);\n\n\t\tif (status)\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Mac address assignment failed for VF %d\\n\",\n\t\t\t\tvf);\n\t\telse\n\t\t\tmemcpy(vf_cfg->mac_addr, mac, ETH_ALEN);\n\n\t\tmac[5] += 1;\n\t}\n\treturn status;\n}\n\nstatic int be_vfs_mac_query(struct be_adapter *adapter)\n{\n\tint status, vf;\n\tu8 mac[ETH_ALEN];\n\tstruct be_vf_cfg *vf_cfg;\n\n\tfor_all_vfs(adapter, vf_cfg, vf) {\n\t\tstatus = be_cmd_get_active_mac(adapter, vf_cfg->pmac_id,\n\t\t\t\t\t       mac, vf_cfg->if_handle,\n\t\t\t\t\t       false, vf+1);\n\t\tif (status)\n\t\t\treturn status;\n\t\tmemcpy(vf_cfg->mac_addr, mac, ETH_ALEN);\n\t}\n\treturn 0;\n}\n\nstatic void be_vf_clear(struct be_adapter *adapter)\n{\n\tstruct be_vf_cfg *vf_cfg;\n\tu32 vf;\n\n\tif (pci_vfs_assigned(adapter->pdev)) {\n\t\tdev_warn(&adapter->pdev->dev,\n\t\t\t \"VFs are assigned to VMs: not disabling VFs\\n\");\n\t\tgoto done;\n\t}\n\n\tpci_disable_sriov(adapter->pdev);\n\n\tfor_all_vfs(adapter, vf_cfg, vf) {\n\t\tif (BEx_chip(adapter))\n\t\t\tbe_cmd_pmac_del(adapter, vf_cfg->if_handle,\n\t\t\t\t\tvf_cfg->pmac_id, vf + 1);\n\t\telse\n\t\t\tbe_cmd_set_mac(adapter, NULL, vf_cfg->if_handle,\n\t\t\t\t       vf + 1);\n\n\t\tbe_cmd_if_destroy(adapter, vf_cfg->if_handle, vf + 1);\n\t}\n\n\tif (BE3_chip(adapter))\n\t\tbe_cmd_set_hsw_config(adapter, 0, 0,\n\t\t\t\t      adapter->if_handle,\n\t\t\t\t      PORT_FWD_TYPE_PASSTHRU, 0);\ndone:\n\tkfree(adapter->vf_cfg);\n\tadapter->num_vfs = 0;\n\tadapter->flags &= ~BE_FLAGS_SRIOV_ENABLED;\n}\n\nstatic void be_clear_queues(struct be_adapter *adapter)\n{\n\tbe_mcc_queues_destroy(adapter);\n\tbe_rx_cqs_destroy(adapter);\n\tbe_tx_queues_destroy(adapter);\n\tbe_evt_queues_destroy(adapter);\n}\n\nstatic void be_cancel_worker(struct be_adapter *adapter)\n{\n\tif (adapter->flags & BE_FLAGS_WORKER_SCHEDULED) {\n\t\tcancel_delayed_work_sync(&adapter->work);\n\t\tadapter->flags &= ~BE_FLAGS_WORKER_SCHEDULED;\n\t}\n}\n\nstatic void be_cancel_err_detection(struct be_adapter *adapter)\n{\n\tstruct be_error_recovery *err_rec = &adapter->error_recovery;\n\n\tif (!be_err_recovery_workq)\n\t\treturn;\n\n\tif (adapter->flags & BE_FLAGS_ERR_DETECTION_SCHEDULED) {\n\t\tcancel_delayed_work_sync(&err_rec->err_detection_work);\n\t\tadapter->flags &= ~BE_FLAGS_ERR_DETECTION_SCHEDULED;\n\t}\n}\n\n \nstatic int be_vxlan_set_port(struct net_device *netdev, unsigned int table,\n\t\t\t     unsigned int entry, struct udp_tunnel_info *ti)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct device *dev = &adapter->pdev->dev;\n\tint status;\n\n\tstatus = be_cmd_manage_iface(adapter, adapter->if_handle,\n\t\t\t\t     OP_CONVERT_NORMAL_TO_TUNNEL);\n\tif (status) {\n\t\tdev_warn(dev, \"Failed to convert normal interface to tunnel\\n\");\n\t\treturn status;\n\t}\n\tadapter->flags |= BE_FLAGS_VXLAN_OFFLOADS;\n\n\tstatus = be_cmd_set_vxlan_port(adapter, ti->port);\n\tif (status) {\n\t\tdev_warn(dev, \"Failed to add VxLAN port\\n\");\n\t\treturn status;\n\t}\n\tadapter->vxlan_port = ti->port;\n\n\tnetdev->hw_enc_features |= NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |\n\t\t\t\t   NETIF_F_TSO | NETIF_F_TSO6 |\n\t\t\t\t   NETIF_F_GSO_UDP_TUNNEL;\n\n\tdev_info(dev, \"Enabled VxLAN offloads for UDP port %d\\n\",\n\t\t be16_to_cpu(ti->port));\n\treturn 0;\n}\n\nstatic int be_vxlan_unset_port(struct net_device *netdev, unsigned int table,\n\t\t\t       unsigned int entry, struct udp_tunnel_info *ti)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\n\tif (adapter->flags & BE_FLAGS_VXLAN_OFFLOADS)\n\t\tbe_cmd_manage_iface(adapter, adapter->if_handle,\n\t\t\t\t    OP_CONVERT_TUNNEL_TO_NORMAL);\n\n\tif (adapter->vxlan_port)\n\t\tbe_cmd_set_vxlan_port(adapter, 0);\n\n\tadapter->flags &= ~BE_FLAGS_VXLAN_OFFLOADS;\n\tadapter->vxlan_port = 0;\n\n\tnetdev->hw_enc_features = 0;\n\treturn 0;\n}\n\nstatic const struct udp_tunnel_nic_info be_udp_tunnels = {\n\t.set_port\t= be_vxlan_set_port,\n\t.unset_port\t= be_vxlan_unset_port,\n\t.flags\t\t= UDP_TUNNEL_NIC_INFO_MAY_SLEEP |\n\t\t\t  UDP_TUNNEL_NIC_INFO_OPEN_ONLY,\n\t.tables\t\t= {\n\t\t{ .n_entries = 1, .tunnel_types = UDP_TUNNEL_TYPE_VXLAN, },\n\t},\n};\n\nstatic void be_calculate_vf_res(struct be_adapter *adapter, u16 num_vfs,\n\t\t\t\tstruct be_resources *vft_res)\n{\n\tstruct be_resources res = adapter->pool_res;\n\tu32 vf_if_cap_flags = res.vf_if_cap_flags;\n\tstruct be_resources res_mod = {0};\n\tu16 num_vf_qs = 1;\n\n\t \n\tif (num_vfs) {\n\t\t \n\t\tnum_vf_qs = min(SH_VF_MAX_NIC_EQS,\n\t\t\t\tres.max_rss_qs / (num_vfs + 1));\n\n\t\t \n\t\tif (num_vfs >= be_max_pf_pool_rss_tables(adapter))\n\t\t\tnum_vf_qs = 1;\n\t}\n\n\t \n\tbe_cmd_get_profile_config(adapter, &res_mod, NULL, ACTIVE_PROFILE_TYPE,\n\t\t\t\t  RESOURCE_MODIFIABLE, 0);\n\n\t \n\tif (res_mod.vf_if_cap_flags & BE_IF_FLAGS_RSS) {\n\t\tvft_res->flags |= BIT(IF_CAPS_FLAGS_VALID_SHIFT);\n\t\tif (num_vf_qs > 1) {\n\t\t\tvf_if_cap_flags |= BE_IF_FLAGS_RSS;\n\t\t\tif (res.if_cap_flags & BE_IF_FLAGS_DEFQ_RSS)\n\t\t\t\tvf_if_cap_flags |= BE_IF_FLAGS_DEFQ_RSS;\n\t\t} else {\n\t\t\tvf_if_cap_flags &= ~(BE_IF_FLAGS_RSS |\n\t\t\t\t\t     BE_IF_FLAGS_DEFQ_RSS);\n\t\t}\n\t} else {\n\t\tnum_vf_qs = 1;\n\t}\n\n\tif (res_mod.vf_if_cap_flags & BE_IF_FLAGS_VLAN_PROMISCUOUS) {\n\t\tvft_res->flags |= BIT(IF_CAPS_FLAGS_VALID_SHIFT);\n\t\tvf_if_cap_flags &= ~BE_IF_FLAGS_VLAN_PROMISCUOUS;\n\t}\n\n\tvft_res->vf_if_cap_flags = vf_if_cap_flags;\n\tvft_res->max_rx_qs = num_vf_qs;\n\tvft_res->max_rss_qs = num_vf_qs;\n\tvft_res->max_tx_qs = res.max_tx_qs / (num_vfs + 1);\n\tvft_res->max_cq_count = res.max_cq_count / (num_vfs + 1);\n\n\t \n\tif (res_mod.max_uc_mac == FIELD_MODIFIABLE)\n\t\tvft_res->max_uc_mac = res.max_uc_mac / (num_vfs + 1);\n\n\tif (res_mod.max_vlans == FIELD_MODIFIABLE)\n\t\tvft_res->max_vlans = res.max_vlans / (num_vfs + 1);\n\n\tif (res_mod.max_iface_count == FIELD_MODIFIABLE)\n\t\tvft_res->max_iface_count = res.max_iface_count / (num_vfs + 1);\n\n\tif (res_mod.max_mcc_count == FIELD_MODIFIABLE)\n\t\tvft_res->max_mcc_count = res.max_mcc_count / (num_vfs + 1);\n}\n\nstatic void be_if_destroy(struct be_adapter *adapter)\n{\n\tbe_cmd_if_destroy(adapter, adapter->if_handle,  0);\n\n\tkfree(adapter->pmac_id);\n\tadapter->pmac_id = NULL;\n\n\tkfree(adapter->mc_list);\n\tadapter->mc_list = NULL;\n\n\tkfree(adapter->uc_list);\n\tadapter->uc_list = NULL;\n}\n\nstatic int be_clear(struct be_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tstruct  be_resources vft_res = {0};\n\n\tbe_cancel_worker(adapter);\n\n\tflush_workqueue(be_wq);\n\n\tif (sriov_enabled(adapter))\n\t\tbe_vf_clear(adapter);\n\n\t \n\tif (skyhawk_chip(adapter) && be_physfn(adapter) &&\n\t    !pci_vfs_assigned(pdev)) {\n\t\tbe_calculate_vf_res(adapter,\n\t\t\t\t    pci_sriov_get_totalvfs(pdev),\n\t\t\t\t    &vft_res);\n\t\tbe_cmd_set_sriov_config(adapter, adapter->pool_res,\n\t\t\t\t\tpci_sriov_get_totalvfs(pdev),\n\t\t\t\t\t&vft_res);\n\t}\n\n\tbe_vxlan_unset_port(adapter->netdev, 0, 0, NULL);\n\n\tbe_if_destroy(adapter);\n\n\tbe_clear_queues(adapter);\n\n\tbe_msix_disable(adapter);\n\tadapter->flags &= ~BE_FLAGS_SETUP_DONE;\n\treturn 0;\n}\n\nstatic int be_vfs_if_create(struct be_adapter *adapter)\n{\n\tstruct be_resources res = {0};\n\tu32 cap_flags, en_flags, vf;\n\tstruct be_vf_cfg *vf_cfg;\n\tint status;\n\n\t \n\tcap_flags = BE_VF_IF_EN_FLAGS;\n\n\tfor_all_vfs(adapter, vf_cfg, vf) {\n\t\tif (!BE3_chip(adapter)) {\n\t\t\tstatus = be_cmd_get_profile_config(adapter, &res, NULL,\n\t\t\t\t\t\t\t   ACTIVE_PROFILE_TYPE,\n\t\t\t\t\t\t\t   RESOURCE_LIMITS,\n\t\t\t\t\t\t\t   vf + 1);\n\t\t\tif (!status) {\n\t\t\t\tcap_flags = res.if_cap_flags;\n\t\t\t\t \n\t\t\t\tcap_flags &= ~BE_IF_FLAGS_VLAN_PROMISCUOUS;\n\t\t\t}\n\t\t}\n\n\t\t \n\t\ten_flags = cap_flags & BE_VF_IF_EN_FLAGS;\n\t\tstatus = be_cmd_if_create(adapter, cap_flags, en_flags,\n\t\t\t\t\t  &vf_cfg->if_handle, vf + 1);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\treturn 0;\n}\n\nstatic int be_vf_setup_init(struct be_adapter *adapter)\n{\n\tstruct be_vf_cfg *vf_cfg;\n\tint vf;\n\n\tadapter->vf_cfg = kcalloc(adapter->num_vfs, sizeof(*vf_cfg),\n\t\t\t\t  GFP_KERNEL);\n\tif (!adapter->vf_cfg)\n\t\treturn -ENOMEM;\n\n\tfor_all_vfs(adapter, vf_cfg, vf) {\n\t\tvf_cfg->if_handle = -1;\n\t\tvf_cfg->pmac_id = -1;\n\t}\n\treturn 0;\n}\n\nstatic int be_vf_setup(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct be_vf_cfg *vf_cfg;\n\tint status, old_vfs, vf;\n\tbool spoofchk;\n\n\told_vfs = pci_num_vf(adapter->pdev);\n\n\tstatus = be_vf_setup_init(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tif (old_vfs) {\n\t\tfor_all_vfs(adapter, vf_cfg, vf) {\n\t\t\tstatus = be_cmd_get_if_id(adapter, vf_cfg, vf);\n\t\t\tif (status)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\tstatus = be_vfs_mac_query(adapter);\n\t\tif (status)\n\t\t\tgoto err;\n\t} else {\n\t\tstatus = be_vfs_if_create(adapter);\n\t\tif (status)\n\t\t\tgoto err;\n\n\t\tstatus = be_vf_eth_addr_config(adapter);\n\t\tif (status)\n\t\t\tgoto err;\n\t}\n\n\tfor_all_vfs(adapter, vf_cfg, vf) {\n\t\t \n\t\tstatus = be_cmd_get_fn_privileges(adapter, &vf_cfg->privileges,\n\t\t\t\t\t\t  vf + 1);\n\t\tif (!status && !(vf_cfg->privileges & BE_PRIV_FILTMGMT)) {\n\t\t\tstatus = be_cmd_set_fn_privileges(adapter,\n\t\t\t\t\t\t\t  vf_cfg->privileges |\n\t\t\t\t\t\t\t  BE_PRIV_FILTMGMT,\n\t\t\t\t\t\t\t  vf + 1);\n\t\t\tif (!status) {\n\t\t\t\tvf_cfg->privileges |= BE_PRIV_FILTMGMT;\n\t\t\t\tdev_info(dev, \"VF%d has FILTMGMT privilege\\n\",\n\t\t\t\t\t vf);\n\t\t\t}\n\t\t}\n\n\t\t \n\t\tif (!old_vfs)\n\t\t\tbe_cmd_config_qos(adapter, 0, 0, vf + 1);\n\n\t\tstatus = be_cmd_get_hsw_config(adapter, NULL, vf + 1,\n\t\t\t\t\t       vf_cfg->if_handle, NULL,\n\t\t\t\t\t       &spoofchk);\n\t\tif (!status)\n\t\t\tvf_cfg->spoofchk = spoofchk;\n\n\t\tif (!old_vfs) {\n\t\t\tbe_cmd_enable_vf(adapter, vf + 1);\n\t\t\tbe_cmd_set_logical_link_config(adapter,\n\t\t\t\t\t\t       IFLA_VF_LINK_STATE_AUTO,\n\t\t\t\t\t\t       vf+1);\n\t\t}\n\t}\n\n\tif (!old_vfs) {\n\t\tstatus = pci_enable_sriov(adapter->pdev, adapter->num_vfs);\n\t\tif (status) {\n\t\t\tdev_err(dev, \"SRIOV enable failed\\n\");\n\t\t\tadapter->num_vfs = 0;\n\t\t\tgoto err;\n\t\t}\n\t}\n\n\tif (BE3_chip(adapter)) {\n\t\t \n\t\tstatus = be_cmd_set_hsw_config(adapter, 0, 0,\n\t\t\t\t\t       adapter->if_handle,\n\t\t\t\t\t       PORT_FWD_TYPE_VEB, 0);\n\t\tif (status)\n\t\t\tgoto err;\n\t}\n\n\tadapter->flags |= BE_FLAGS_SRIOV_ENABLED;\n\treturn 0;\nerr:\n\tdev_err(dev, \"VF setup failed\\n\");\n\tbe_vf_clear(adapter);\n\treturn status;\n}\n\n \n\nstatic u8 be_convert_mc_type(u32 function_mode)\n{\n\tif (function_mode & VNIC_MODE && function_mode & QNQ_MODE)\n\t\treturn vNIC1;\n\telse if (function_mode & QNQ_MODE)\n\t\treturn FLEX10;\n\telse if (function_mode & VNIC_MODE)\n\t\treturn vNIC2;\n\telse if (function_mode & UMC_ENABLED)\n\t\treturn UMC;\n\telse\n\t\treturn MC_NONE;\n}\n\n \nstatic void BEx_get_resources(struct be_adapter *adapter,\n\t\t\t      struct be_resources *res)\n{\n\tbool use_sriov = adapter->num_vfs ? 1 : 0;\n\n\tif (be_physfn(adapter))\n\t\tres->max_uc_mac = BE_UC_PMAC_COUNT;\n\telse\n\t\tres->max_uc_mac = BE_VF_UC_PMAC_COUNT;\n\n\tadapter->mc_type = be_convert_mc_type(adapter->function_mode);\n\n\tif (be_is_mc(adapter)) {\n\t\t \n\t\tif (be_is_qnq_mode(adapter))\n\t\t\tres->max_vlans = BE_NUM_VLANS_SUPPORTED/8;\n\t\telse\n\t\t\t \n\t\t\tres->max_vlans = (BE_NUM_VLANS_SUPPORTED / 4) - 1;\n\t} else {\n\t\tres->max_vlans = BE_NUM_VLANS_SUPPORTED;\n\t}\n\n\tres->max_mcast_mac = BE_MAX_MC;\n\n\t \n\tif (BE2_chip(adapter) || use_sriov ||  (adapter->port_num > 1) ||\n\t    be_virtfn(adapter) ||\n\t    (be_is_mc(adapter) &&\n\t     !(adapter->function_caps & BE_FUNCTION_CAPS_RSS))) {\n\t\tres->max_tx_qs = 1;\n\t} else if (adapter->function_caps & BE_FUNCTION_CAPS_SUPER_NIC) {\n\t\tstruct be_resources super_nic_res = {0};\n\n\t\t \n\t\tbe_cmd_get_profile_config(adapter, &super_nic_res, NULL,\n\t\t\t\t\t  ACTIVE_PROFILE_TYPE, RESOURCE_LIMITS,\n\t\t\t\t\t  0);\n\t\t \n\t\tres->max_tx_qs = super_nic_res.max_tx_qs ? : BE3_MAX_TX_QS;\n\t} else {\n\t\tres->max_tx_qs = BE3_MAX_TX_QS;\n\t}\n\n\tif ((adapter->function_caps & BE_FUNCTION_CAPS_RSS) &&\n\t    !use_sriov && be_physfn(adapter))\n\t\tres->max_rss_qs = (adapter->be3_native) ?\n\t\t\t\t\t   BE3_MAX_RSS_QS : BE2_MAX_RSS_QS;\n\tres->max_rx_qs = res->max_rss_qs + 1;\n\n\tif (be_physfn(adapter))\n\t\tres->max_evt_qs = (be_max_vfs(adapter) > 0) ?\n\t\t\t\t\tBE3_SRIOV_MAX_EVT_QS : BE3_MAX_EVT_QS;\n\telse\n\t\tres->max_evt_qs = 1;\n\n\tres->if_cap_flags = BE_IF_CAP_FLAGS_WANT;\n\tres->if_cap_flags &= ~BE_IF_FLAGS_DEFQ_RSS;\n\tif (!(adapter->function_caps & BE_FUNCTION_CAPS_RSS))\n\t\tres->if_cap_flags &= ~BE_IF_FLAGS_RSS;\n}\n\nstatic void be_setup_init(struct be_adapter *adapter)\n{\n\tadapter->vlan_prio_bmap = 0xff;\n\tadapter->phy.link_speed = -1;\n\tadapter->if_handle = -1;\n\tadapter->be3_native = false;\n\tadapter->if_flags = 0;\n\tadapter->phy_state = BE_UNKNOWN_PHY_STATE;\n\tif (be_physfn(adapter))\n\t\tadapter->cmd_privileges = MAX_PRIVILEGES;\n\telse\n\t\tadapter->cmd_privileges = MIN_PRIVILEGES;\n}\n\n \nstatic void be_calculate_pf_pool_rss_tables(struct be_adapter *adapter)\n{\n\tstruct be_port_resources port_res = {0};\n\tu8 rss_tables_on_port;\n\tu16 max_vfs = be_max_vfs(adapter);\n\n\tbe_cmd_get_profile_config(adapter, NULL, &port_res, SAVED_PROFILE_TYPE,\n\t\t\t\t  RESOURCE_LIMITS, 0);\n\n\trss_tables_on_port = MAX_PORT_RSS_TABLES - port_res.nic_pfs;\n\n\t \n\tadapter->pool_res.max_rss_tables =\n\t\tmax_vfs * rss_tables_on_port / port_res.max_vfs;\n}\n\nstatic int be_get_sriov_config(struct be_adapter *adapter)\n{\n\tstruct be_resources res = {0};\n\tint max_vfs, old_vfs;\n\n\tbe_cmd_get_profile_config(adapter, &res, NULL, ACTIVE_PROFILE_TYPE,\n\t\t\t\t  RESOURCE_LIMITS, 0);\n\n\t \n\tif (BE3_chip(adapter) && !res.max_vfs) {\n\t\tmax_vfs = pci_sriov_get_totalvfs(adapter->pdev);\n\t\tres.max_vfs = max_vfs > 0 ? min(MAX_VFS, max_vfs) : 0;\n\t}\n\n\tadapter->pool_res = res;\n\n\t \n\told_vfs = pci_num_vf(adapter->pdev);\n\tif (old_vfs) {\n\t\tdev_info(&adapter->pdev->dev, \"%d VFs are already enabled\\n\",\n\t\t\t old_vfs);\n\n\t\tadapter->pool_res.max_vfs =\n\t\t\tpci_sriov_get_totalvfs(adapter->pdev);\n\t\tadapter->num_vfs = old_vfs;\n\t}\n\n\tif (skyhawk_chip(adapter) && be_max_vfs(adapter) && !old_vfs) {\n\t\tbe_calculate_pf_pool_rss_tables(adapter);\n\t\tdev_info(&adapter->pdev->dev,\n\t\t\t \"RSS can be enabled for all VFs if num_vfs <= %d\\n\",\n\t\t\t be_max_pf_pool_rss_tables(adapter));\n\t}\n\treturn 0;\n}\n\nstatic void be_alloc_sriov_res(struct be_adapter *adapter)\n{\n\tint old_vfs = pci_num_vf(adapter->pdev);\n\tstruct  be_resources vft_res = {0};\n\tint status;\n\n\tbe_get_sriov_config(adapter);\n\n\tif (!old_vfs)\n\t\tpci_sriov_set_totalvfs(adapter->pdev, be_max_vfs(adapter));\n\n\t \n\tif (skyhawk_chip(adapter) && be_max_vfs(adapter) && !old_vfs) {\n\t\tbe_calculate_vf_res(adapter, 0, &vft_res);\n\t\tstatus = be_cmd_set_sriov_config(adapter, adapter->pool_res, 0,\n\t\t\t\t\t\t &vft_res);\n\t\tif (status)\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Failed to optimize SRIOV resources\\n\");\n\t}\n}\n\nstatic int be_get_resources(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tstruct be_resources res = {0};\n\tint status;\n\n\t \n\tif (BEx_chip(adapter)) {\n\t\tBEx_get_resources(adapter, &res);\n\t} else {\n\t\tstatus = be_cmd_get_func_config(adapter, &res);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\t \n\t\tif (res.max_rss_qs && res.max_rss_qs == res.max_rx_qs &&\n\t\t    !(res.if_cap_flags & BE_IF_FLAGS_DEFQ_RSS))\n\t\t\tres.max_rss_qs -= 1;\n\t}\n\n\t \n\tres.max_nic_evt_qs = be_roce_supported(adapter) ?\n\t\t\t\tres.max_evt_qs / 2 : res.max_evt_qs;\n\tadapter->res = res;\n\n\t \n\tadapter->need_def_rxq = (be_if_cap_flags(adapter) &\n\t\t\t\t BE_IF_FLAGS_DEFQ_RSS) ? 0 : 1;\n\n\tdev_info(dev, \"Max: txqs %d, rxqs %d, rss %d, eqs %d, vfs %d\\n\",\n\t\t be_max_txqs(adapter), be_max_rxqs(adapter),\n\t\t be_max_rss(adapter), be_max_nic_eqs(adapter),\n\t\t be_max_vfs(adapter));\n\tdev_info(dev, \"Max: uc-macs %d, mc-macs %d, vlans %d\\n\",\n\t\t be_max_uc(adapter), be_max_mc(adapter),\n\t\t be_max_vlans(adapter));\n\n\t \n\tadapter->cfg_num_rx_irqs =\n\t\t\t\tmin_t(u16, netif_get_num_default_rss_queues(),\n\t\t\t\t      be_max_qp_irqs(adapter));\n\tadapter->cfg_num_tx_irqs = adapter->cfg_num_rx_irqs;\n\treturn 0;\n}\n\nstatic int be_get_config(struct be_adapter *adapter)\n{\n\tint status, level;\n\tu16 profile_id;\n\n\tstatus = be_cmd_get_cntl_attributes(adapter);\n\tif (status)\n\t\treturn status;\n\n\tstatus = be_cmd_query_fw_cfg(adapter);\n\tif (status)\n\t\treturn status;\n\n\tif (!lancer_chip(adapter) && be_physfn(adapter))\n\t\tbe_cmd_get_fat_dump_len(adapter, &adapter->fat_dump_len);\n\n\tif (BEx_chip(adapter)) {\n\t\tlevel = be_cmd_get_fw_log_level(adapter);\n\t\tadapter->msg_enable =\n\t\t\tlevel <= FW_LOG_LEVEL_DEFAULT ? NETIF_MSG_HW : 0;\n\t}\n\n\tbe_cmd_get_acpi_wol_cap(adapter);\n\tpci_enable_wake(adapter->pdev, PCI_D3hot, adapter->wol_en);\n\tpci_enable_wake(adapter->pdev, PCI_D3cold, adapter->wol_en);\n\n\tbe_cmd_query_port_name(adapter);\n\n\tif (be_physfn(adapter)) {\n\t\tstatus = be_cmd_get_active_profile(adapter, &profile_id);\n\t\tif (!status)\n\t\t\tdev_info(&adapter->pdev->dev,\n\t\t\t\t \"Using profile 0x%x\\n\", profile_id);\n\t}\n\n\treturn 0;\n}\n\nstatic int be_mac_setup(struct be_adapter *adapter)\n{\n\tu8 mac[ETH_ALEN];\n\tint status;\n\n\tif (is_zero_ether_addr(adapter->netdev->dev_addr)) {\n\t\tstatus = be_cmd_get_perm_mac(adapter, mac);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\teth_hw_addr_set(adapter->netdev, mac);\n\t\tmemcpy(adapter->netdev->perm_addr, mac, ETH_ALEN);\n\n\t\t \n\t\tif (BEx_chip(adapter) && be_virtfn(adapter))\n\t\t\tmemcpy(adapter->dev_mac, mac, ETH_ALEN);\n\t}\n\n\treturn 0;\n}\n\nstatic void be_schedule_worker(struct be_adapter *adapter)\n{\n\tqueue_delayed_work(be_wq, &adapter->work, msecs_to_jiffies(1000));\n\tadapter->flags |= BE_FLAGS_WORKER_SCHEDULED;\n}\n\nstatic void be_destroy_err_recovery_workq(void)\n{\n\tif (!be_err_recovery_workq)\n\t\treturn;\n\n\tdestroy_workqueue(be_err_recovery_workq);\n\tbe_err_recovery_workq = NULL;\n}\n\nstatic void be_schedule_err_detection(struct be_adapter *adapter, u32 delay)\n{\n\tstruct be_error_recovery *err_rec = &adapter->error_recovery;\n\n\tif (!be_err_recovery_workq)\n\t\treturn;\n\n\tqueue_delayed_work(be_err_recovery_workq, &err_rec->err_detection_work,\n\t\t\t   msecs_to_jiffies(delay));\n\tadapter->flags |= BE_FLAGS_ERR_DETECTION_SCHEDULED;\n}\n\nstatic int be_setup_queues(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint status;\n\n\tstatus = be_evt_queues_create(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = be_tx_qs_create(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = be_rx_cqs_create(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = be_mcc_queues_create(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = netif_set_real_num_rx_queues(netdev, adapter->num_rx_qs);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = netif_set_real_num_tx_queues(netdev, adapter->num_tx_qs);\n\tif (status)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tdev_err(&adapter->pdev->dev, \"queue_setup failed\\n\");\n\treturn status;\n}\n\nstatic int be_if_create(struct be_adapter *adapter)\n{\n\tu32 en_flags = BE_IF_FLAGS_RSS | BE_IF_FLAGS_DEFQ_RSS;\n\tu32 cap_flags = be_if_cap_flags(adapter);\n\n\t \n\tadapter->pmac_id = kcalloc(be_max_uc(adapter),\n\t\t\t\t   sizeof(*adapter->pmac_id), GFP_KERNEL);\n\tif (!adapter->pmac_id)\n\t\treturn -ENOMEM;\n\n\tadapter->mc_list = kcalloc(be_max_mc(adapter),\n\t\t\t\t   sizeof(*adapter->mc_list), GFP_KERNEL);\n\tif (!adapter->mc_list)\n\t\treturn -ENOMEM;\n\n\tadapter->uc_list = kcalloc(be_max_uc(adapter),\n\t\t\t\t   sizeof(*adapter->uc_list), GFP_KERNEL);\n\tif (!adapter->uc_list)\n\t\treturn -ENOMEM;\n\n\tif (adapter->cfg_num_rx_irqs == 1)\n\t\tcap_flags &= ~(BE_IF_FLAGS_DEFQ_RSS | BE_IF_FLAGS_RSS);\n\n\ten_flags &= cap_flags;\n\t \n\treturn be_cmd_if_create(adapter, be_if_cap_flags(adapter), en_flags,\n\t\t\t\t  &adapter->if_handle, 0);\n}\n\nint be_update_queues(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint status;\n\n\tif (netif_running(netdev)) {\n\t\t \n\t\tnetif_tx_lock_bh(netdev);\n\t\t \n\t\tnetif_carrier_off(netdev);\n\t\tnetif_tx_unlock_bh(netdev);\n\n\t\tbe_close(netdev);\n\t}\n\n\tbe_cancel_worker(adapter);\n\n\t \n\tif (!adapter->num_msix_roce_vec)\n\t\tbe_msix_disable(adapter);\n\n\tbe_clear_queues(adapter);\n\tstatus = be_cmd_if_destroy(adapter, adapter->if_handle,  0);\n\tif (status)\n\t\treturn status;\n\n\tif (!msix_enabled(adapter)) {\n\t\tstatus = be_msix_enable(adapter);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\tstatus = be_if_create(adapter);\n\tif (status)\n\t\treturn status;\n\n\tstatus = be_setup_queues(adapter);\n\tif (status)\n\t\treturn status;\n\n\tbe_schedule_worker(adapter);\n\n\t \n\tadapter->if_flags &= ~BE_IF_FLAGS_ALL_PROMISCUOUS;\n\n\tif (netif_running(netdev))\n\t\tstatus = be_open(netdev);\n\n\treturn status;\n}\n\nstatic inline int fw_major_num(const char *fw_ver)\n{\n\tint fw_major = 0, i;\n\n\ti = sscanf(fw_ver, \"%d.\", &fw_major);\n\tif (i != 1)\n\t\treturn 0;\n\n\treturn fw_major;\n}\n\n \nstatic bool be_reset_required(struct be_adapter *adapter)\n{\n\tif (be_error_recovering(adapter))\n\t\treturn true;\n\telse\n\t\treturn pci_num_vf(adapter->pdev) == 0;\n}\n\n \nstatic int be_func_init(struct be_adapter *adapter)\n{\n\tint status;\n\n\tstatus = be_fw_wait_ready(adapter);\n\tif (status)\n\t\treturn status;\n\n\t \n\tbe_clear_error(adapter, BE_CLEAR_ALL);\n\n\tif (be_reset_required(adapter)) {\n\t\tstatus = be_cmd_reset_function(adapter);\n\t\tif (status)\n\t\t\treturn status;\n\n\t\t \n\t\tmsleep(100);\n\t}\n\n\t \n\tstatus = be_cmd_fw_init(adapter);\n\tif (status)\n\t\treturn status;\n\n\t \n\tbe_intr_set(adapter, true);\n\n\treturn 0;\n}\n\nstatic int be_setup(struct be_adapter *adapter)\n{\n\tstruct device *dev = &adapter->pdev->dev;\n\tint status;\n\n\tstatus = be_func_init(adapter);\n\tif (status)\n\t\treturn status;\n\n\tbe_setup_init(adapter);\n\n\tif (!lancer_chip(adapter))\n\t\tbe_cmd_req_native_mode(adapter);\n\n\t \n\tif (!BEx_chip(adapter)) {\n\t\tstatus = be_cmd_get_func_config(adapter, NULL);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\n\tstatus = be_get_config(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tif (!BE2_chip(adapter) && be_physfn(adapter))\n\t\tbe_alloc_sriov_res(adapter);\n\n\tstatus = be_get_resources(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tstatus = be_msix_enable(adapter);\n\tif (status)\n\t\tgoto err;\n\n\t \n\tstatus = be_if_create(adapter);\n\tif (status)\n\t\tgoto err;\n\n\t \n\trtnl_lock();\n\tstatus = be_setup_queues(adapter);\n\trtnl_unlock();\n\tif (status)\n\t\tgoto err;\n\n\tbe_cmd_get_fn_privileges(adapter, &adapter->cmd_privileges, 0);\n\n\tstatus = be_mac_setup(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tbe_cmd_get_fw_ver(adapter);\n\tdev_info(dev, \"FW version is %s\\n\", adapter->fw_ver);\n\n\tif (BE2_chip(adapter) && fw_major_num(adapter->fw_ver) < 4) {\n\t\tdev_err(dev, \"Firmware on card is old(%s), IRQs may not work\",\n\t\t\tadapter->fw_ver);\n\t\tdev_err(dev, \"Please upgrade firmware to version >= 4.0\\n\");\n\t}\n\n\tstatus = be_cmd_set_flow_control(adapter, adapter->tx_fc,\n\t\t\t\t\t adapter->rx_fc);\n\tif (status)\n\t\tbe_cmd_get_flow_control(adapter, &adapter->tx_fc,\n\t\t\t\t\t&adapter->rx_fc);\n\n\tdev_info(&adapter->pdev->dev, \"HW Flow control - TX:%d RX:%d\\n\",\n\t\t adapter->tx_fc, adapter->rx_fc);\n\n\tif (be_physfn(adapter))\n\t\tbe_cmd_set_logical_link_config(adapter,\n\t\t\t\t\t       IFLA_VF_LINK_STATE_AUTO, 0);\n\n\t \n\tif (BE3_chip(adapter))\n\t\tbe_cmd_set_hsw_config(adapter, 0, 0, adapter->if_handle,\n\t\t\t\t      PORT_FWD_TYPE_PASSTHRU, 0);\n\n\tif (adapter->num_vfs)\n\t\tbe_vf_setup(adapter);\n\n\tstatus = be_cmd_get_phy_info(adapter);\n\tif (!status && be_pause_supported(adapter))\n\t\tadapter->phy.fc_autoneg = 1;\n\n\tif (be_physfn(adapter) && !lancer_chip(adapter))\n\t\tbe_cmd_set_features(adapter);\n\n\tbe_schedule_worker(adapter);\n\tadapter->flags |= BE_FLAGS_SETUP_DONE;\n\treturn 0;\nerr:\n\tbe_clear(adapter);\n\treturn status;\n}\n\n#ifdef CONFIG_NET_POLL_CONTROLLER\nstatic void be_netpoll(struct net_device *netdev)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\tstruct be_eq_obj *eqo;\n\tint i;\n\n\tfor_all_evt_queues(adapter, eqo, i) {\n\t\tbe_eq_notify(eqo->adapter, eqo->q.id, false, true, 0, 0);\n\t\tnapi_schedule(&eqo->napi);\n\t}\n}\n#endif\n\nint be_load_fw(struct be_adapter *adapter, u8 *fw_file)\n{\n\tconst struct firmware *fw;\n\tint status;\n\n\tif (!netif_running(adapter->netdev)) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Firmware load not allowed (interface is down)\\n\");\n\t\treturn -ENETDOWN;\n\t}\n\n\tstatus = request_firmware(&fw, fw_file, &adapter->pdev->dev);\n\tif (status)\n\t\tgoto fw_exit;\n\n\tdev_info(&adapter->pdev->dev, \"Flashing firmware file %s\\n\", fw_file);\n\n\tif (lancer_chip(adapter))\n\t\tstatus = lancer_fw_download(adapter, fw);\n\telse\n\t\tstatus = be_fw_download(adapter, fw);\n\n\tif (!status)\n\t\tbe_cmd_get_fw_ver(adapter);\n\nfw_exit:\n\trelease_firmware(fw);\n\treturn status;\n}\n\nstatic int be_ndo_bridge_setlink(struct net_device *dev, struct nlmsghdr *nlh,\n\t\t\t\t u16 flags, struct netlink_ext_ack *extack)\n{\n\tstruct be_adapter *adapter = netdev_priv(dev);\n\tstruct nlattr *attr, *br_spec;\n\tint rem;\n\tint status = 0;\n\tu16 mode = 0;\n\n\tif (!sriov_enabled(adapter))\n\t\treturn -EOPNOTSUPP;\n\n\tbr_spec = nlmsg_find_attr(nlh, sizeof(struct ifinfomsg), IFLA_AF_SPEC);\n\tif (!br_spec)\n\t\treturn -EINVAL;\n\n\tnla_for_each_nested(attr, br_spec, rem) {\n\t\tif (nla_type(attr) != IFLA_BRIDGE_MODE)\n\t\t\tcontinue;\n\n\t\tmode = nla_get_u16(attr);\n\t\tif (BE3_chip(adapter) && mode == BRIDGE_MODE_VEPA)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif (mode != BRIDGE_MODE_VEPA && mode != BRIDGE_MODE_VEB)\n\t\t\treturn -EINVAL;\n\n\t\tstatus = be_cmd_set_hsw_config(adapter, 0, 0,\n\t\t\t\t\t       adapter->if_handle,\n\t\t\t\t\t       mode == BRIDGE_MODE_VEPA ?\n\t\t\t\t\t       PORT_FWD_TYPE_VEPA :\n\t\t\t\t\t       PORT_FWD_TYPE_VEB, 0);\n\t\tif (status)\n\t\t\tgoto err;\n\n\t\tdev_info(&adapter->pdev->dev, \"enabled switch mode: %s\\n\",\n\t\t\t mode == BRIDGE_MODE_VEPA ? \"VEPA\" : \"VEB\");\n\n\t\treturn status;\n\t}\nerr:\n\tdev_err(&adapter->pdev->dev, \"Failed to set switch mode %s\\n\",\n\t\tmode == BRIDGE_MODE_VEPA ? \"VEPA\" : \"VEB\");\n\n\treturn status;\n}\n\nstatic int be_ndo_bridge_getlink(struct sk_buff *skb, u32 pid, u32 seq,\n\t\t\t\t struct net_device *dev, u32 filter_mask,\n\t\t\t\t int nlflags)\n{\n\tstruct be_adapter *adapter = netdev_priv(dev);\n\tint status = 0;\n\tu8 hsw_mode;\n\n\t \n\tif (BEx_chip(adapter) || lancer_chip(adapter)) {\n\t\t \n\t\tif (!pci_sriov_get_totalvfs(adapter->pdev))\n\t\t\treturn 0;\n\t\thsw_mode = PORT_FWD_TYPE_VEB;\n\t} else {\n\t\tstatus = be_cmd_get_hsw_config(adapter, NULL, 0,\n\t\t\t\t\t       adapter->if_handle, &hsw_mode,\n\t\t\t\t\t       NULL);\n\t\tif (status)\n\t\t\treturn 0;\n\n\t\tif (hsw_mode == PORT_FWD_TYPE_PASSTHRU)\n\t\t\treturn 0;\n\t}\n\n\treturn ndo_dflt_bridge_getlink(skb, pid, seq, dev,\n\t\t\t\t       hsw_mode == PORT_FWD_TYPE_VEPA ?\n\t\t\t\t       BRIDGE_MODE_VEPA : BRIDGE_MODE_VEB,\n\t\t\t\t       0, 0, nlflags, filter_mask, NULL);\n}\n\nstatic struct be_cmd_work *be_alloc_work(struct be_adapter *adapter,\n\t\t\t\t\t void (*func)(struct work_struct *))\n{\n\tstruct be_cmd_work *work;\n\n\twork = kzalloc(sizeof(*work), GFP_ATOMIC);\n\tif (!work) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"be_work memory allocation failed\\n\");\n\t\treturn NULL;\n\t}\n\n\tINIT_WORK(&work->work, func);\n\twork->adapter = adapter;\n\treturn work;\n}\n\nstatic netdev_features_t be_features_check(struct sk_buff *skb,\n\t\t\t\t\t   struct net_device *dev,\n\t\t\t\t\t   netdev_features_t features)\n{\n\tstruct be_adapter *adapter = netdev_priv(dev);\n\tu8 l4_hdr = 0;\n\n\tif (skb_is_gso(skb)) {\n\t\t \n\t\tif (!skyhawk_chip(adapter) && is_ipv6_ext_hdr(skb))\n\t\t\tfeatures &= ~NETIF_F_TSO6;\n\n\t\t \n\t\tif (lancer_chip(adapter) &&\n\t\t    (skb_shinfo(skb)->gso_size < 256 ||\n\t\t     skb_shinfo(skb)->gso_segs == 1))\n\t\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\t}\n\n\t \n\tfeatures = vlan_features_check(skb, features);\n\tif (!skb->encapsulation ||\n\t    !(adapter->flags & BE_FLAGS_VXLAN_OFFLOADS))\n\t\treturn features;\n\n\t \n\tswitch (vlan_get_protocol(skb)) {\n\tcase htons(ETH_P_IP):\n\t\tl4_hdr = ip_hdr(skb)->protocol;\n\t\tbreak;\n\tcase htons(ETH_P_IPV6):\n\t\tl4_hdr = ipv6_hdr(skb)->nexthdr;\n\t\tbreak;\n\tdefault:\n\t\treturn features;\n\t}\n\n\tif (l4_hdr != IPPROTO_UDP ||\n\t    skb->inner_protocol_type != ENCAP_TYPE_ETHER ||\n\t    skb->inner_protocol != htons(ETH_P_TEB) ||\n\t    skb_inner_mac_header(skb) - skb_transport_header(skb) !=\n\t\tsizeof(struct udphdr) + sizeof(struct vxlanhdr) ||\n\t    !adapter->vxlan_port ||\n\t    udp_hdr(skb)->dest != adapter->vxlan_port)\n\t\treturn features & ~(NETIF_F_CSUM_MASK | NETIF_F_GSO_MASK);\n\n\treturn features;\n}\n\nstatic int be_get_phys_port_id(struct net_device *dev,\n\t\t\t       struct netdev_phys_item_id *ppid)\n{\n\tint i, id_len = CNTL_SERIAL_NUM_WORDS * CNTL_SERIAL_NUM_WORD_SZ + 1;\n\tstruct be_adapter *adapter = netdev_priv(dev);\n\tu8 *id;\n\n\tif (MAX_PHYS_ITEM_ID_LEN < id_len)\n\t\treturn -ENOSPC;\n\n\tppid->id[0] = adapter->hba_port_num + 1;\n\tid = &ppid->id[1];\n\tfor (i = CNTL_SERIAL_NUM_WORDS - 1; i >= 0;\n\t     i--, id += CNTL_SERIAL_NUM_WORD_SZ)\n\t\tmemcpy(id, &adapter->serial_num[i], CNTL_SERIAL_NUM_WORD_SZ);\n\n\tppid->id_len = id_len;\n\n\treturn 0;\n}\n\nstatic void be_set_rx_mode(struct net_device *dev)\n{\n\tstruct be_adapter *adapter = netdev_priv(dev);\n\tstruct be_cmd_work *work;\n\n\twork = be_alloc_work(adapter, be_work_set_rx_mode);\n\tif (work)\n\t\tqueue_work(be_wq, &work->work);\n}\n\nstatic const struct net_device_ops be_netdev_ops = {\n\t.ndo_open\t\t= be_open,\n\t.ndo_stop\t\t= be_close,\n\t.ndo_start_xmit\t\t= be_xmit,\n\t.ndo_set_rx_mode\t= be_set_rx_mode,\n\t.ndo_set_mac_address\t= be_mac_addr_set,\n\t.ndo_get_stats64\t= be_get_stats64,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_vlan_rx_add_vid\t= be_vlan_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= be_vlan_rem_vid,\n\t.ndo_set_vf_mac\t\t= be_set_vf_mac,\n\t.ndo_set_vf_vlan\t= be_set_vf_vlan,\n\t.ndo_set_vf_rate\t= be_set_vf_tx_rate,\n\t.ndo_get_vf_config\t= be_get_vf_config,\n\t.ndo_set_vf_link_state  = be_set_vf_link_state,\n\t.ndo_set_vf_spoofchk    = be_set_vf_spoofchk,\n\t.ndo_tx_timeout\t\t= be_tx_timeout,\n#ifdef CONFIG_NET_POLL_CONTROLLER\n\t.ndo_poll_controller\t= be_netpoll,\n#endif\n\t.ndo_bridge_setlink\t= be_ndo_bridge_setlink,\n\t.ndo_bridge_getlink\t= be_ndo_bridge_getlink,\n\t.ndo_features_check\t= be_features_check,\n\t.ndo_get_phys_port_id   = be_get_phys_port_id,\n};\n\nstatic void be_netdev_init(struct net_device *netdev)\n{\n\tstruct be_adapter *adapter = netdev_priv(netdev);\n\n\tnetdev->hw_features |= NETIF_F_SG | NETIF_F_TSO | NETIF_F_TSO6 |\n\t\tNETIF_F_GSO_UDP_TUNNEL |\n\t\tNETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM | NETIF_F_RXCSUM |\n\t\tNETIF_F_HW_VLAN_CTAG_TX;\n\tif ((be_if_cap_flags(adapter) & BE_IF_FLAGS_RSS))\n\t\tnetdev->hw_features |= NETIF_F_RXHASH;\n\n\tnetdev->features |= netdev->hw_features |\n\t\tNETIF_F_HW_VLAN_CTAG_RX | NETIF_F_HW_VLAN_CTAG_FILTER |\n\t\tNETIF_F_HIGHDMA;\n\n\tnetdev->vlan_features |= NETIF_F_SG | NETIF_F_TSO | NETIF_F_TSO6 |\n\t\tNETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM;\n\n\tnetdev->priv_flags |= IFF_UNICAST_FLT;\n\n\tnetdev->flags |= IFF_MULTICAST;\n\n\tnetif_set_tso_max_size(netdev, BE_MAX_GSO_SIZE - ETH_HLEN);\n\n\tnetdev->netdev_ops = &be_netdev_ops;\n\n\tnetdev->ethtool_ops = &be_ethtool_ops;\n\n\tif (!lancer_chip(adapter) && !BEx_chip(adapter) && !be_is_mc(adapter))\n\t\tnetdev->udp_tunnel_nic_info = &be_udp_tunnels;\n\n\t \n\tnetdev->min_mtu = BE_MIN_MTU;\n\tnetdev->max_mtu = BE_MAX_MTU;\n}\n\nstatic void be_cleanup(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\n\trtnl_lock();\n\tnetif_device_detach(netdev);\n\tif (netif_running(netdev))\n\t\tbe_close(netdev);\n\trtnl_unlock();\n\n\tbe_clear(adapter);\n}\n\nstatic int be_resume(struct be_adapter *adapter)\n{\n\tstruct net_device *netdev = adapter->netdev;\n\tint status;\n\n\tstatus = be_setup(adapter);\n\tif (status)\n\t\treturn status;\n\n\trtnl_lock();\n\tif (netif_running(netdev))\n\t\tstatus = be_open(netdev);\n\trtnl_unlock();\n\n\tif (status)\n\t\treturn status;\n\n\tnetif_device_attach(netdev);\n\n\treturn 0;\n}\n\nstatic void be_soft_reset(struct be_adapter *adapter)\n{\n\tu32 val;\n\n\tdev_info(&adapter->pdev->dev, \"Initiating chip soft reset\\n\");\n\tval = ioread32(adapter->pcicfg + SLIPORT_SOFTRESET_OFFSET);\n\tval |= SLIPORT_SOFTRESET_SR_MASK;\n\tiowrite32(val, adapter->pcicfg + SLIPORT_SOFTRESET_OFFSET);\n}\n\nstatic bool be_err_is_recoverable(struct be_adapter *adapter)\n{\n\tstruct be_error_recovery *err_rec = &adapter->error_recovery;\n\tunsigned long initial_idle_time =\n\t\tmsecs_to_jiffies(ERR_RECOVERY_IDLE_TIME);\n\tunsigned long recovery_interval =\n\t\tmsecs_to_jiffies(ERR_RECOVERY_INTERVAL);\n\tu16 ue_err_code;\n\tu32 val;\n\n\tval = be_POST_stage_get(adapter);\n\tif ((val & POST_STAGE_RECOVERABLE_ERR) != POST_STAGE_RECOVERABLE_ERR)\n\t\treturn false;\n\tue_err_code = val & POST_ERR_RECOVERY_CODE_MASK;\n\tif (ue_err_code == 0)\n\t\treturn false;\n\n\tdev_err(&adapter->pdev->dev, \"Recoverable HW error code: 0x%x\\n\",\n\t\tue_err_code);\n\n\tif (time_before_eq(jiffies - err_rec->probe_time, initial_idle_time)) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot recover within %lu sec from driver load\\n\",\n\t\t\tjiffies_to_msecs(initial_idle_time) / MSEC_PER_SEC);\n\t\treturn false;\n\t}\n\n\tif (err_rec->last_recovery_time && time_before_eq(\n\t\tjiffies - err_rec->last_recovery_time, recovery_interval)) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot recover within %lu sec from last recovery\\n\",\n\t\t\tjiffies_to_msecs(recovery_interval) / MSEC_PER_SEC);\n\t\treturn false;\n\t}\n\n\tif (ue_err_code == err_rec->last_err_code) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Cannot recover from a consecutive TPE error\\n\");\n\t\treturn false;\n\t}\n\n\terr_rec->last_recovery_time = jiffies;\n\terr_rec->last_err_code = ue_err_code;\n\treturn true;\n}\n\nstatic int be_tpe_recover(struct be_adapter *adapter)\n{\n\tstruct be_error_recovery *err_rec = &adapter->error_recovery;\n\tint status = -EAGAIN;\n\tu32 val;\n\n\tswitch (err_rec->recovery_state) {\n\tcase ERR_RECOVERY_ST_NONE:\n\t\terr_rec->recovery_state = ERR_RECOVERY_ST_DETECT;\n\t\terr_rec->resched_delay = ERR_RECOVERY_UE_DETECT_DURATION;\n\t\tbreak;\n\n\tcase ERR_RECOVERY_ST_DETECT:\n\t\tval = be_POST_stage_get(adapter);\n\t\tif ((val & POST_STAGE_RECOVERABLE_ERR) !=\n\t\t    POST_STAGE_RECOVERABLE_ERR) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Unrecoverable HW error detected: 0x%x\\n\", val);\n\t\t\tstatus = -EINVAL;\n\t\t\terr_rec->resched_delay = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tdev_err(&adapter->pdev->dev, \"Recoverable HW error detected\\n\");\n\n\t\t \n\t\tif (adapter->pf_num == 0) {\n\t\t\terr_rec->recovery_state = ERR_RECOVERY_ST_RESET;\n\t\t\terr_rec->resched_delay = err_rec->ue_to_reset_time -\n\t\t\t\t\tERR_RECOVERY_UE_DETECT_DURATION;\n\t\t\tbreak;\n\t\t}\n\n\t\terr_rec->recovery_state = ERR_RECOVERY_ST_PRE_POLL;\n\t\terr_rec->resched_delay = err_rec->ue_to_poll_time -\n\t\t\t\t\tERR_RECOVERY_UE_DETECT_DURATION;\n\t\tbreak;\n\n\tcase ERR_RECOVERY_ST_RESET:\n\t\tif (!be_err_is_recoverable(adapter)) {\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Failed to meet recovery criteria\\n\");\n\t\t\tstatus = -EIO;\n\t\t\terr_rec->resched_delay = 0;\n\t\t\tbreak;\n\t\t}\n\t\tbe_soft_reset(adapter);\n\t\terr_rec->recovery_state = ERR_RECOVERY_ST_PRE_POLL;\n\t\terr_rec->resched_delay = err_rec->ue_to_poll_time -\n\t\t\t\t\terr_rec->ue_to_reset_time;\n\t\tbreak;\n\n\tcase ERR_RECOVERY_ST_PRE_POLL:\n\t\terr_rec->recovery_state = ERR_RECOVERY_ST_REINIT;\n\t\terr_rec->resched_delay = 0;\n\t\tstatus = 0;\t\t\t \n\t\tbreak;\n\n\tdefault:\n\t\tstatus = -EINVAL;\n\t\terr_rec->resched_delay = 0;\n\t\tbreak;\n\t}\n\n\treturn status;\n}\n\nstatic int be_err_recover(struct be_adapter *adapter)\n{\n\tint status;\n\n\tif (!lancer_chip(adapter)) {\n\t\tif (!adapter->error_recovery.recovery_supported ||\n\t\t    adapter->priv_flags & BE_DISABLE_TPE_RECOVERY)\n\t\t\treturn -EIO;\n\t\tstatus = be_tpe_recover(adapter);\n\t\tif (status)\n\t\t\tgoto err;\n\t}\n\n\t \n\tstatus = be_fw_wait_ready(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tadapter->flags |= BE_FLAGS_TRY_RECOVERY;\n\n\tbe_cleanup(adapter);\n\n\tstatus = be_resume(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tadapter->flags &= ~BE_FLAGS_TRY_RECOVERY;\n\nerr:\n\treturn status;\n}\n\nstatic void be_err_detection_task(struct work_struct *work)\n{\n\tstruct be_error_recovery *err_rec =\n\t\t\tcontainer_of(work, struct be_error_recovery,\n\t\t\t\t     err_detection_work.work);\n\tstruct be_adapter *adapter =\n\t\t\tcontainer_of(err_rec, struct be_adapter,\n\t\t\t\t     error_recovery);\n\tu32 resched_delay = ERR_RECOVERY_DETECTION_DELAY;\n\tstruct device *dev = &adapter->pdev->dev;\n\tint recovery_status;\n\n\tbe_detect_error(adapter);\n\tif (!be_check_error(adapter, BE_ERROR_HW))\n\t\tgoto reschedule_task;\n\n\trecovery_status = be_err_recover(adapter);\n\tif (!recovery_status) {\n\t\terr_rec->recovery_retries = 0;\n\t\terr_rec->recovery_state = ERR_RECOVERY_ST_NONE;\n\t\tdev_info(dev, \"Adapter recovery successful\\n\");\n\t\tgoto reschedule_task;\n\t} else if (!lancer_chip(adapter) && err_rec->resched_delay) {\n\t\t \n\t\tif (adapter->pf_num == 0 &&\n\t\t    err_rec->recovery_state > ERR_RECOVERY_ST_DETECT)\n\t\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\t\"Adapter recovery in progress\\n\");\n\t\tresched_delay = err_rec->resched_delay;\n\t\tgoto reschedule_task;\n\t} else if (lancer_chip(adapter) && be_virtfn(adapter)) {\n\t\t \n\t\tdev_err(dev, \"Re-trying adapter recovery\\n\");\n\t\tgoto reschedule_task;\n\t} else if (lancer_chip(adapter) && err_rec->recovery_retries++ <\n\t\t   ERR_RECOVERY_MAX_RETRY_COUNT) {\n\t\t \n\t\tdev_err(&adapter->pdev->dev, \"Re-trying adapter recovery\\n\");\n\t\tresched_delay = ERR_RECOVERY_RETRY_DELAY;\n\t\tgoto reschedule_task;\n\t} else {\n\t\tdev_err(dev, \"Adapter recovery failed\\n\");\n\t\tdev_err(dev, \"Please reboot server to recover\\n\");\n\t}\n\n\treturn;\n\nreschedule_task:\n\tbe_schedule_err_detection(adapter, resched_delay);\n}\n\nstatic void be_log_sfp_info(struct be_adapter *adapter)\n{\n\tint status;\n\n\tstatus = be_cmd_query_sfp_info(adapter);\n\tif (!status) {\n\t\tdev_err(&adapter->pdev->dev,\n\t\t\t\"Port %c: %s Vendor: %s part no: %s\",\n\t\t\tadapter->port_name,\n\t\t\tbe_misconfig_evt_port_state[adapter->phy_state],\n\t\t\tadapter->phy.vendor_name,\n\t\t\tadapter->phy.vendor_pn);\n\t}\n\tadapter->flags &= ~BE_FLAGS_PHY_MISCONFIGURED;\n}\n\nstatic void be_worker(struct work_struct *work)\n{\n\tstruct be_adapter *adapter =\n\t\tcontainer_of(work, struct be_adapter, work.work);\n\tstruct be_rx_obj *rxo;\n\tint i;\n\n\tif (be_physfn(adapter) &&\n\t    MODULO(adapter->work_counter, adapter->be_get_temp_freq) == 0)\n\t\tbe_cmd_get_die_temperature(adapter);\n\n\t \n\tif (!netif_running(adapter->netdev)) {\n\t\tlocal_bh_disable();\n\t\tbe_process_mcc(adapter);\n\t\tlocal_bh_enable();\n\t\tgoto reschedule;\n\t}\n\n\tif (!adapter->stats_cmd_sent) {\n\t\tif (lancer_chip(adapter))\n\t\t\tlancer_cmd_get_pport_stats(adapter,\n\t\t\t\t\t\t   &adapter->stats_cmd);\n\t\telse\n\t\t\tbe_cmd_get_stats(adapter, &adapter->stats_cmd);\n\t}\n\n\tfor_all_rx_queues(adapter, rxo, i) {\n\t\t \n\t\tif (rxo->rx_post_starved)\n\t\t\tbe_post_rx_frags(rxo, GFP_KERNEL, MAX_RX_POST);\n\t}\n\n\t \n\tif (!skyhawk_chip(adapter))\n\t\tbe_eqd_update(adapter, false);\n\n\tif (adapter->flags & BE_FLAGS_PHY_MISCONFIGURED)\n\t\tbe_log_sfp_info(adapter);\n\nreschedule:\n\tadapter->work_counter++;\n\tqueue_delayed_work(be_wq, &adapter->work, msecs_to_jiffies(1000));\n}\n\nstatic void be_unmap_pci_bars(struct be_adapter *adapter)\n{\n\tif (adapter->csr)\n\t\tpci_iounmap(adapter->pdev, adapter->csr);\n\tif (adapter->db)\n\t\tpci_iounmap(adapter->pdev, adapter->db);\n\tif (adapter->pcicfg && adapter->pcicfg_mapped)\n\t\tpci_iounmap(adapter->pdev, adapter->pcicfg);\n}\n\nstatic int db_bar(struct be_adapter *adapter)\n{\n\tif (lancer_chip(adapter) || be_virtfn(adapter))\n\t\treturn 0;\n\telse\n\t\treturn 4;\n}\n\nstatic int be_roce_map_pci_bars(struct be_adapter *adapter)\n{\n\tif (skyhawk_chip(adapter)) {\n\t\tadapter->roce_db.size = 4096;\n\t\tadapter->roce_db.io_addr = pci_resource_start(adapter->pdev,\n\t\t\t\t\t\t\t      db_bar(adapter));\n\t\tadapter->roce_db.total_size = pci_resource_len(adapter->pdev,\n\t\t\t\t\t\t\t       db_bar(adapter));\n\t}\n\treturn 0;\n}\n\nstatic int be_map_pci_bars(struct be_adapter *adapter)\n{\n\tstruct pci_dev *pdev = adapter->pdev;\n\tu8 __iomem *addr;\n\tu32 sli_intf;\n\n\tpci_read_config_dword(adapter->pdev, SLI_INTF_REG_OFFSET, &sli_intf);\n\tadapter->sli_family = (sli_intf & SLI_INTF_FAMILY_MASK) >>\n\t\t\t\tSLI_INTF_FAMILY_SHIFT;\n\tadapter->virtfn = (sli_intf & SLI_INTF_FT_MASK) ? 1 : 0;\n\n\tif (BEx_chip(adapter) && be_physfn(adapter)) {\n\t\tadapter->csr = pci_iomap(pdev, 2, 0);\n\t\tif (!adapter->csr)\n\t\t\treturn -ENOMEM;\n\t}\n\n\taddr = pci_iomap(pdev, db_bar(adapter), 0);\n\tif (!addr)\n\t\tgoto pci_map_err;\n\tadapter->db = addr;\n\n\tif (skyhawk_chip(adapter) || BEx_chip(adapter)) {\n\t\tif (be_physfn(adapter)) {\n\t\t\t \n\t\t\taddr = pci_iomap(pdev, BE2_chip(adapter) ? 1 : 0, 0);\n\t\t\tif (!addr)\n\t\t\t\tgoto pci_map_err;\n\t\t\tadapter->pcicfg = addr;\n\t\t\tadapter->pcicfg_mapped = true;\n\t\t} else {\n\t\t\tadapter->pcicfg = adapter->db + SRIOV_VF_PCICFG_OFFSET;\n\t\t\tadapter->pcicfg_mapped = false;\n\t\t}\n\t}\n\n\tbe_roce_map_pci_bars(adapter);\n\treturn 0;\n\npci_map_err:\n\tdev_err(&pdev->dev, \"Error in mapping PCI BARs\\n\");\n\tbe_unmap_pci_bars(adapter);\n\treturn -ENOMEM;\n}\n\nstatic void be_drv_cleanup(struct be_adapter *adapter)\n{\n\tstruct be_dma_mem *mem = &adapter->mbox_mem_alloced;\n\tstruct device *dev = &adapter->pdev->dev;\n\n\tif (mem->va)\n\t\tdma_free_coherent(dev, mem->size, mem->va, mem->dma);\n\n\tmem = &adapter->rx_filter;\n\tif (mem->va)\n\t\tdma_free_coherent(dev, mem->size, mem->va, mem->dma);\n\n\tmem = &adapter->stats_cmd;\n\tif (mem->va)\n\t\tdma_free_coherent(dev, mem->size, mem->va, mem->dma);\n}\n\n \nstatic int be_drv_init(struct be_adapter *adapter)\n{\n\tstruct be_dma_mem *mbox_mem_alloc = &adapter->mbox_mem_alloced;\n\tstruct be_dma_mem *mbox_mem_align = &adapter->mbox_mem;\n\tstruct be_dma_mem *rx_filter = &adapter->rx_filter;\n\tstruct be_dma_mem *stats_cmd = &adapter->stats_cmd;\n\tstruct device *dev = &adapter->pdev->dev;\n\tint status = 0;\n\n\tmbox_mem_alloc->size = sizeof(struct be_mcc_mailbox) + 16;\n\tmbox_mem_alloc->va = dma_alloc_coherent(dev, mbox_mem_alloc->size,\n\t\t\t\t\t\t&mbox_mem_alloc->dma,\n\t\t\t\t\t\tGFP_KERNEL);\n\tif (!mbox_mem_alloc->va)\n\t\treturn -ENOMEM;\n\n\tmbox_mem_align->size = sizeof(struct be_mcc_mailbox);\n\tmbox_mem_align->va = PTR_ALIGN(mbox_mem_alloc->va, 16);\n\tmbox_mem_align->dma = PTR_ALIGN(mbox_mem_alloc->dma, 16);\n\n\trx_filter->size = sizeof(struct be_cmd_req_rx_filter);\n\trx_filter->va = dma_alloc_coherent(dev, rx_filter->size,\n\t\t\t\t\t   &rx_filter->dma, GFP_KERNEL);\n\tif (!rx_filter->va) {\n\t\tstatus = -ENOMEM;\n\t\tgoto free_mbox;\n\t}\n\n\tif (lancer_chip(adapter))\n\t\tstats_cmd->size = sizeof(struct lancer_cmd_req_pport_stats);\n\telse if (BE2_chip(adapter))\n\t\tstats_cmd->size = sizeof(struct be_cmd_req_get_stats_v0);\n\telse if (BE3_chip(adapter))\n\t\tstats_cmd->size = sizeof(struct be_cmd_req_get_stats_v1);\n\telse\n\t\tstats_cmd->size = sizeof(struct be_cmd_req_get_stats_v2);\n\tstats_cmd->va = dma_alloc_coherent(dev, stats_cmd->size,\n\t\t\t\t\t   &stats_cmd->dma, GFP_KERNEL);\n\tif (!stats_cmd->va) {\n\t\tstatus = -ENOMEM;\n\t\tgoto free_rx_filter;\n\t}\n\n\tmutex_init(&adapter->mbox_lock);\n\tmutex_init(&adapter->mcc_lock);\n\tmutex_init(&adapter->rx_filter_lock);\n\tspin_lock_init(&adapter->mcc_cq_lock);\n\tinit_completion(&adapter->et_cmd_compl);\n\n\tpci_save_state(adapter->pdev);\n\n\tINIT_DELAYED_WORK(&adapter->work, be_worker);\n\n\tadapter->error_recovery.recovery_state = ERR_RECOVERY_ST_NONE;\n\tadapter->error_recovery.resched_delay = 0;\n\tINIT_DELAYED_WORK(&adapter->error_recovery.err_detection_work,\n\t\t\t  be_err_detection_task);\n\n\tadapter->rx_fc = true;\n\tadapter->tx_fc = true;\n\n\t \n\tadapter->be_get_temp_freq = 64;\n\n\treturn 0;\n\nfree_rx_filter:\n\tdma_free_coherent(dev, rx_filter->size, rx_filter->va, rx_filter->dma);\nfree_mbox:\n\tdma_free_coherent(dev, mbox_mem_alloc->size, mbox_mem_alloc->va,\n\t\t\t  mbox_mem_alloc->dma);\n\treturn status;\n}\n\nstatic void be_remove(struct pci_dev *pdev)\n{\n\tstruct be_adapter *adapter = pci_get_drvdata(pdev);\n\n\tif (!adapter)\n\t\treturn;\n\n\tbe_roce_dev_remove(adapter);\n\tbe_intr_set(adapter, false);\n\n\tbe_cancel_err_detection(adapter);\n\n\tunregister_netdev(adapter->netdev);\n\n\tbe_clear(adapter);\n\n\tif (!pci_vfs_assigned(adapter->pdev))\n\t\tbe_cmd_reset_function(adapter);\n\n\t \n\tbe_cmd_fw_clean(adapter);\n\n\tbe_unmap_pci_bars(adapter);\n\tbe_drv_cleanup(adapter);\n\n\tpci_release_regions(pdev);\n\tpci_disable_device(pdev);\n\n\tfree_netdev(adapter->netdev);\n}\n\nstatic ssize_t be_hwmon_show_temp(struct device *dev,\n\t\t\t\t  struct device_attribute *dev_attr,\n\t\t\t\t  char *buf)\n{\n\tstruct be_adapter *adapter = dev_get_drvdata(dev);\n\n\t \n\tif (adapter->hwmon_info.be_on_die_temp == BE_INVALID_DIE_TEMP)\n\t\treturn -EIO;\n\telse\n\t\treturn sprintf(buf, \"%u\\n\",\n\t\t\t       adapter->hwmon_info.be_on_die_temp * 1000);\n}\n\nstatic SENSOR_DEVICE_ATTR(temp1_input, 0444,\n\t\t\t  be_hwmon_show_temp, NULL, 1);\n\nstatic struct attribute *be_hwmon_attrs[] = {\n\t&sensor_dev_attr_temp1_input.dev_attr.attr,\n\tNULL\n};\n\nATTRIBUTE_GROUPS(be_hwmon);\n\nstatic char *mc_name(struct be_adapter *adapter)\n{\n\tchar *str = \"\";\t \n\n\tswitch (adapter->mc_type) {\n\tcase UMC:\n\t\tstr = \"UMC\";\n\t\tbreak;\n\tcase FLEX10:\n\t\tstr = \"FLEX10\";\n\t\tbreak;\n\tcase vNIC1:\n\t\tstr = \"vNIC-1\";\n\t\tbreak;\n\tcase nPAR:\n\t\tstr = \"nPAR\";\n\t\tbreak;\n\tcase UFP:\n\t\tstr = \"UFP\";\n\t\tbreak;\n\tcase vNIC2:\n\t\tstr = \"vNIC-2\";\n\t\tbreak;\n\tdefault:\n\t\tstr = \"\";\n\t}\n\n\treturn str;\n}\n\nstatic inline char *func_name(struct be_adapter *adapter)\n{\n\treturn be_physfn(adapter) ? \"PF\" : \"VF\";\n}\n\nstatic inline char *nic_name(struct pci_dev *pdev)\n{\n\tswitch (pdev->device) {\n\tcase OC_DEVICE_ID1:\n\t\treturn OC_NAME;\n\tcase OC_DEVICE_ID2:\n\t\treturn OC_NAME_BE;\n\tcase OC_DEVICE_ID3:\n\tcase OC_DEVICE_ID4:\n\t\treturn OC_NAME_LANCER;\n\tcase BE_DEVICE_ID2:\n\t\treturn BE3_NAME;\n\tcase OC_DEVICE_ID5:\n\tcase OC_DEVICE_ID6:\n\t\treturn OC_NAME_SH;\n\tdefault:\n\t\treturn BE_NAME;\n\t}\n}\n\nstatic int be_probe(struct pci_dev *pdev, const struct pci_device_id *pdev_id)\n{\n\tstruct be_adapter *adapter;\n\tstruct net_device *netdev;\n\tint status = 0;\n\n\tstatus = pci_enable_device(pdev);\n\tif (status)\n\t\tgoto do_none;\n\n\tstatus = pci_request_regions(pdev, DRV_NAME);\n\tif (status)\n\t\tgoto disable_dev;\n\tpci_set_master(pdev);\n\n\tnetdev = alloc_etherdev_mqs(sizeof(*adapter), MAX_TX_QS, MAX_RX_QS);\n\tif (!netdev) {\n\t\tstatus = -ENOMEM;\n\t\tgoto rel_reg;\n\t}\n\tadapter = netdev_priv(netdev);\n\tadapter->pdev = pdev;\n\tpci_set_drvdata(pdev, adapter);\n\tadapter->netdev = netdev;\n\tSET_NETDEV_DEV(netdev, &pdev->dev);\n\n\tstatus = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\n\tif (status) {\n\t\tdev_err(&pdev->dev, \"Could not set PCI DMA Mask\\n\");\n\t\tgoto free_netdev;\n\t}\n\n\tstatus = be_map_pci_bars(adapter);\n\tif (status)\n\t\tgoto free_netdev;\n\n\tstatus = be_drv_init(adapter);\n\tif (status)\n\t\tgoto unmap_bars;\n\n\tstatus = be_setup(adapter);\n\tif (status)\n\t\tgoto drv_cleanup;\n\n\tbe_netdev_init(netdev);\n\tstatus = register_netdev(netdev);\n\tif (status != 0)\n\t\tgoto unsetup;\n\n\tbe_roce_dev_add(adapter);\n\n\tbe_schedule_err_detection(adapter, ERR_DETECTION_DELAY);\n\tadapter->error_recovery.probe_time = jiffies;\n\n\t \n\tif (be_physfn(adapter) && IS_ENABLED(CONFIG_BE2NET_HWMON)) {\n\t\tadapter->hwmon_info.hwmon_dev =\n\t\t\tdevm_hwmon_device_register_with_groups(&pdev->dev,\n\t\t\t\t\t\t\t       DRV_NAME,\n\t\t\t\t\t\t\t       adapter,\n\t\t\t\t\t\t\t       be_hwmon_groups);\n\t\tadapter->hwmon_info.be_on_die_temp = BE_INVALID_DIE_TEMP;\n\t}\n\n\tdev_info(&pdev->dev, \"%s: %s %s port %c\\n\", nic_name(pdev),\n\t\t func_name(adapter), mc_name(adapter), adapter->port_name);\n\n\treturn 0;\n\nunsetup:\n\tbe_clear(adapter);\ndrv_cleanup:\n\tbe_drv_cleanup(adapter);\nunmap_bars:\n\tbe_unmap_pci_bars(adapter);\nfree_netdev:\n\tfree_netdev(netdev);\nrel_reg:\n\tpci_release_regions(pdev);\ndisable_dev:\n\tpci_disable_device(pdev);\ndo_none:\n\tdev_err(&pdev->dev, \"%s initialization failed\\n\", nic_name(pdev));\n\treturn status;\n}\n\nstatic int __maybe_unused be_suspend(struct device *dev_d)\n{\n\tstruct be_adapter *adapter = dev_get_drvdata(dev_d);\n\n\tbe_intr_set(adapter, false);\n\tbe_cancel_err_detection(adapter);\n\n\tbe_cleanup(adapter);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused be_pci_resume(struct device *dev_d)\n{\n\tstruct be_adapter *adapter = dev_get_drvdata(dev_d);\n\tint status = 0;\n\n\tstatus = be_resume(adapter);\n\tif (status)\n\t\treturn status;\n\n\tbe_schedule_err_detection(adapter, ERR_DETECTION_DELAY);\n\n\treturn 0;\n}\n\n \nstatic void be_shutdown(struct pci_dev *pdev)\n{\n\tstruct be_adapter *adapter = pci_get_drvdata(pdev);\n\n\tif (!adapter)\n\t\treturn;\n\n\tbe_roce_dev_shutdown(adapter);\n\tcancel_delayed_work_sync(&adapter->work);\n\tbe_cancel_err_detection(adapter);\n\n\tnetif_device_detach(adapter->netdev);\n\n\tbe_cmd_reset_function(adapter);\n\n\tpci_disable_device(pdev);\n}\n\nstatic pci_ers_result_t be_eeh_err_detected(struct pci_dev *pdev,\n\t\t\t\t\t    pci_channel_state_t state)\n{\n\tstruct be_adapter *adapter = pci_get_drvdata(pdev);\n\n\tdev_err(&adapter->pdev->dev, \"EEH error detected\\n\");\n\n\tbe_roce_dev_remove(adapter);\n\n\tif (!be_check_error(adapter, BE_ERROR_EEH)) {\n\t\tbe_set_error(adapter, BE_ERROR_EEH);\n\n\t\tbe_cancel_err_detection(adapter);\n\n\t\tbe_cleanup(adapter);\n\t}\n\n\tif (state == pci_channel_io_perm_failure)\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\n\tpci_disable_device(pdev);\n\n\t \n\tif (pdev->devfn == 0)\n\t\tssleep(30);\n\n\treturn PCI_ERS_RESULT_NEED_RESET;\n}\n\nstatic pci_ers_result_t be_eeh_reset(struct pci_dev *pdev)\n{\n\tstruct be_adapter *adapter = pci_get_drvdata(pdev);\n\tint status;\n\n\tdev_info(&adapter->pdev->dev, \"EEH reset\\n\");\n\n\tstatus = pci_enable_device(pdev);\n\tif (status)\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\n\tpci_set_master(pdev);\n\tpci_restore_state(pdev);\n\n\t \n\tdev_info(&adapter->pdev->dev,\n\t\t \"Waiting for FW to be ready after EEH reset\\n\");\n\tstatus = be_fw_wait_ready(adapter);\n\tif (status)\n\t\treturn PCI_ERS_RESULT_DISCONNECT;\n\n\tbe_clear_error(adapter, BE_CLEAR_ALL);\n\treturn PCI_ERS_RESULT_RECOVERED;\n}\n\nstatic void be_eeh_resume(struct pci_dev *pdev)\n{\n\tint status = 0;\n\tstruct be_adapter *adapter = pci_get_drvdata(pdev);\n\n\tdev_info(&adapter->pdev->dev, \"EEH resume\\n\");\n\n\tpci_save_state(pdev);\n\n\tstatus = be_resume(adapter);\n\tif (status)\n\t\tgoto err;\n\n\tbe_roce_dev_add(adapter);\n\n\tbe_schedule_err_detection(adapter, ERR_DETECTION_DELAY);\n\treturn;\nerr:\n\tdev_err(&adapter->pdev->dev, \"EEH resume failed\\n\");\n}\n\nstatic int be_pci_sriov_configure(struct pci_dev *pdev, int num_vfs)\n{\n\tstruct be_adapter *adapter = pci_get_drvdata(pdev);\n\tstruct be_resources vft_res = {0};\n\tint status;\n\n\tif (!num_vfs)\n\t\tbe_vf_clear(adapter);\n\n\tadapter->num_vfs = num_vfs;\n\n\tif (adapter->num_vfs == 0 && pci_vfs_assigned(pdev)) {\n\t\tdev_warn(&pdev->dev,\n\t\t\t \"Cannot disable VFs while they are assigned\\n\");\n\t\treturn -EBUSY;\n\t}\n\n\t \n\tif (skyhawk_chip(adapter) && !pci_num_vf(pdev)) {\n\t\tbe_calculate_vf_res(adapter, adapter->num_vfs,\n\t\t\t\t    &vft_res);\n\t\tstatus = be_cmd_set_sriov_config(adapter, adapter->pool_res,\n\t\t\t\t\t\t adapter->num_vfs, &vft_res);\n\t\tif (status)\n\t\t\tdev_err(&pdev->dev,\n\t\t\t\t\"Failed to optimize SR-IOV resources\\n\");\n\t}\n\n\tstatus = be_get_resources(adapter);\n\tif (status)\n\t\treturn be_cmd_status(status);\n\n\t \n\trtnl_lock();\n\tstatus = be_update_queues(adapter);\n\trtnl_unlock();\n\tif (status)\n\t\treturn be_cmd_status(status);\n\n\tif (adapter->num_vfs)\n\t\tstatus = be_vf_setup(adapter);\n\n\tif (!status)\n\t\treturn adapter->num_vfs;\n\n\treturn 0;\n}\n\nstatic const struct pci_error_handlers be_eeh_handlers = {\n\t.error_detected = be_eeh_err_detected,\n\t.slot_reset = be_eeh_reset,\n\t.resume = be_eeh_resume,\n};\n\nstatic SIMPLE_DEV_PM_OPS(be_pci_pm_ops, be_suspend, be_pci_resume);\n\nstatic struct pci_driver be_driver = {\n\t.name = DRV_NAME,\n\t.id_table = be_dev_ids,\n\t.probe = be_probe,\n\t.remove = be_remove,\n\t.driver.pm = &be_pci_pm_ops,\n\t.shutdown = be_shutdown,\n\t.sriov_configure = be_pci_sriov_configure,\n\t.err_handler = &be_eeh_handlers\n};\n\nstatic int __init be_init_module(void)\n{\n\tint status;\n\n\tif (rx_frag_size != 8192 && rx_frag_size != 4096 &&\n\t    rx_frag_size != 2048) {\n\t\tprintk(KERN_WARNING DRV_NAME\n\t\t\t\" : Module param rx_frag_size must be 2048/4096/8192.\"\n\t\t\t\" Using 2048\\n\");\n\t\trx_frag_size = 2048;\n\t}\n\n\tif (num_vfs > 0) {\n\t\tpr_info(DRV_NAME \" : Module param num_vfs is obsolete.\");\n\t\tpr_info(DRV_NAME \" : Use sysfs method to enable VFs\\n\");\n\t}\n\n\tbe_wq = create_singlethread_workqueue(\"be_wq\");\n\tif (!be_wq) {\n\t\tpr_warn(DRV_NAME \"workqueue creation failed\\n\");\n\t\treturn -1;\n\t}\n\n\tbe_err_recovery_workq =\n\t\tcreate_singlethread_workqueue(\"be_err_recover\");\n\tif (!be_err_recovery_workq)\n\t\tpr_warn(DRV_NAME \"Could not create error recovery workqueue\\n\");\n\n\tstatus = pci_register_driver(&be_driver);\n\tif (status) {\n\t\tdestroy_workqueue(be_wq);\n\t\tbe_destroy_err_recovery_workq();\n\t}\n\treturn status;\n}\nmodule_init(be_init_module);\n\nstatic void __exit be_exit_module(void)\n{\n\tpci_unregister_driver(&be_driver);\n\n\tbe_destroy_err_recovery_workq();\n\n\tif (be_wq)\n\t\tdestroy_workqueue(be_wq);\n}\nmodule_exit(be_exit_module);\n",
  "logic_map": {},
  "failure_modes": [],
  "crash_correlation_map": {}
}